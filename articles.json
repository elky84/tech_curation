[
  {
    "id": 1,
    "imageUrl": "",
    "title": "Extension Manager updates in Visual Studio",
    "description": "The latest updates in Visual Studio 2022 introduced features specifically designed to improve how you manage extensions. These updates offer tools that help you automate processes, provide detailed controls for configuration, and enhance the user interface to streamline your development workflows. Seamless auto updates Visual Studio now automatically triggers updates whenever you open the Extension […]\nThe post Extension Manager updates in Visual Studio appeared first on Visual Studio Blog.",
    "reviews": [],
    "syllabus": [],
    "link": "https://devblogs.microsoft.com/visualstudio/extension-manager-updates-in-visual-studio/",
    "pubDate": "Mon, 02 Jun 2025 18:13:24 +0000",
    "creator": "Javier De la Garza",
    "categories": [
      "Extensibility",
      "Visual Studio",
      "Extensions",
      "Updates",
      "visualstudio.extensibility"
    ]
  },
  {
    "id": 2,
    "imageUrl": "",
    "title": "체외충격파 시술에 대해",
    "description": "수영은 매우 안전한 운동지만, 그래도 오래 하다보면 자잘한 부상이 생기기 마련이다. 주로 어깨, 발꿈치, 가슴(흉통), 무릎, 발목을 주로 다치는데, 이 중에서 어깨나 무릎, 발목의 부상의 경우에는 체외충격파 시술이 상당히 좋은 듯 하다.\n \n수영을 하면서 가장 심각한 부상은 회전근개를 다쳤을 때였다. 배영과 접영을 열심히 하다가 어느 순간 통증이 있었는데 무식하게 기록을 더 줄여보겠다고 열심히 했었다. 결국 한쪽 어깨가 컵을 떨어뜨릴 정도로 악화된 상태로 병원에 갔다. 그 외에 한의원이나 여러가지도 있었는데, 솔직히 인대가 다친 것에는 한의원이 전혀 도움이 되지 않았다. 가장 좋은 치료는 재활의학과에서 놔주는 신경차단술 주사 치료와 체외충격파였다. 특히 체외충격파는 부위에 따라 5~10회 정도 받는데, 1주일에 1~2회씩 받았다. 시술 받을 때는 아프기만 하고 별다른 효과가 없어 보였는데, 3개월쯤 지나면 갑자기 좋아지는 것이 느껴졌고, 6개월쯤 지났을 때는 거의 완치에 가까울 정도로 통증이 사라졌다. 의사가 초음파로 치료 전후를 보여줬는데, 치료 후에는 염증이나 부종이 완전히 사라졌음을 알 수 있었다. 관절의 가동범위도 통증이 사라져서 그런지 매우 좋아졌다.\n \n체외충격파 시술의 강도\n체외충격파 시술을 받을 때는 강도를 무조건 강하게 하기보다는 약하게 하는 것도 괜찮다. 괜히 강하게 하는게 좋다고 생각해서 고통을 참으면서 시술받으면 나중에 오히려 몸살이 난다. 따라서 너무 아픈 것 같다면 치료사에게 강도를 낮춰달라고 하는게 좋다.\n \n체외충격파는 무조건 집중형\n체외충격파는 집중형과 방사형이 있는데, 대부분은 집중형을 사용하지만 발뒷꿈치에는 방사형을 많이 사용하는 것 같다. 하지만 솔직히 방사형은 효과가 별로였다. 나중에 효과를 못보니까 의사도 집중형으로 바꿔서 치료하자고 하였다. 물론 시술시 고통은 집중형이 훨씬 더 강하다. 방사형은 고통이라기보단 뭐로 긁는듯한 느낌이라 통증의 종류가 좀 다르다.\n체외충격파 집중형 vs 방사형\n\n\n검색해보면 근육통쪽에는 방사형이 더 좋다고 하는데, 근육통 때문에 체외충격파를 할 정도는 겪어본 적이 없어서 어떤 경우에 주로 사용하는지는 모르겠다.\n \n결론\n인대나 관절쪽이 다쳤을때 체외충격파 시술은 고통은 있지만 매우 효과적이며, 최소 5~10회정도를 추천한다. 개인적 경험이지만 정형외과보다는 재활의학과쪽이 좀 더 세밀하게 진료를 봐준다. 그리고 효과는 3개월 이후부터 서서히 발생하며, 6개월 정도 지나면 완치에 가깝게 통증이 사라지는 것 같다. 달리 말하면 꾹 참고 시술을 1개월만 받으면(보통 주2회니까 1개월이면 8회 시술), 3개월 이후부터는 운동을 해도 아프지 않을 것이다.",
    "reviews": [],
    "syllabus": [],
    "link": "http://sunyzero.tistory.com/314",
    "pubDate": "Sat, 31 May 2025 18:54:59 +0900",
    "creator": "sunyzero",
    "categories": [
      "취미 관련/수영",
      "수영 부상",
      "체외충격파"
    ]
  },
  {
    "id": 3,
    "imageUrl": "",
    "title": "쿠팡을 이용한 결과",
    "description": "쿠팡에서의 제품 구입 패턴을 바꿔야겠다.\n와우회원을 탈퇴하거나 네이버 쇼핑과 잘 믹스 해야겠다.\n이유는 이렇다.\n- 저품질, 불만족스러운 제품을 많이 사게 됐다. 리뷰를 꼼꼼히 보고 샀지만, 쉽게 망가지거나 금방 해져버리는 물건들이 많았다. 흔히 말하는 ‘불만족-알리택갈이’ 제품의 구매 비중이 점점 늘어났다는 얘기다. 특히 생활용품에서 이런 불만족이 컸다. 쿠팡이 그런 제품을 일부러 권한 건 아니지만, 문방구 앞 달고나처럼 달콤한 유혹을 뿌리칠 수 없었다.\n- 로켓배송은 사실 필요가 없었다. 구입 이력을 보니 ‘꼭 오늘, 내일 필요해!’라는 제품은 하나도 없었다. 당일이나 하루 만에 도착하는 배송이 편리하다는 착각에 빠져 있었던 것이다. 쾌락과 편리함의 경계를 제대로 구분하지 못한 탓이 크다.\n- 내 기준에 맞는 제품은 대부분 로켓배송이 아니거나, 가격에서 이점이 없다.\n- 쿠팡플레이는 애초에 보지 않는다.",
    "reviews": [],
    "syllabus": [],
    "link": "https://hodolman.tistory.com/76",
    "pubDate": "Sun, 1 Jun 2025 23:39:39 +0900",
    "creator": "호돌맨",
    "categories": [
      "우당탕탕 대모험"
    ]
  },
  {
    "id": 4,
    "imageUrl": "",
    "title": "Microsoft, Anthropic과 협력하여 모델 컨텍스트 프로토콜용 공식 C# SDK 개발",
    "description": "No description available",
    "reviews": [],
    "syllabus": [],
    "link": "https://jacking75.github.io/NET_20250604/",
    "pubDate": "Wed, 04 Jun 2025 00:00:00 +0900",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 5,
    "imageUrl": "",
    "title": "AI-Powered Learning, Part 2: Get Unstuck With AI Hints in Python and Kotlin Tasks",
    "description": "In our previous post, we introduced AI-powered machine translation and inline theory definitions to help make learning smoother and more accessible. Today, we’re excited to share the next big step in bringing intelligent assistance to your programming journey: AI hints. This feature is designed especially for beginners who may get stuck while solving coding tasks […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/education/2025/06/02/ai-hints-plugin/",
    "pubDate": "Mon, 02 Jun 2025 08:32:54 +0000",
    "creator": "Julia Amatuni",
    "categories": [
      "ai-assistant",
      "jetbrains-academy",
      "jetbrains-academy-plugin",
      "jetbrains-ai",
      "kotlin",
      "learning-courses",
      "jetbrainsacademy",
      "ai-assistance",
      "ide-plugin",
      "learning",
      "news",
      "release"
    ]
  },
  {
    "id": 6,
    "imageUrl": "",
    "title": "수이 앱토스 MOVE 언어를 배워봅시다.",
    "description": "배울땐 수이 보다 앱토스가 자료가 더 좋습니다.\n영상도 앱토스 쪽이 많습니다.\n수이는 그냥 유럽이 밀어주는 코인인 느낌이라 더 유명한거 같군요\n그래서 앱토스로 배우는걸 추천드리구요\n \n아래의 영상 설명이 잘되어있습니다.\n영상: https://www.youtube.com/watch?v=giUgccl02-4&list=PLLkrq2VBYc1aMSahgDWehzjhEOXJnLG9C&index=1\n\n\n\n \n자동완성 기능이 없는 상대라 배우기 어렵습니다.\n진짜로 매우 ....\n커서에서도 정상적인 코딩을 못해주는 상태입니다.\n언어에 제약도 많구요\n \n그만큼 코인에서 쓰기 좋습니다.\n기능 많아봐야 무한루프 걸다 죽는 일이 많기 때문에 차라리 기능이 없는게 좋습니다.",
    "reviews": [],
    "syllabus": [],
    "link": "http://serverdown.tistory.com/1338",
    "pubDate": "Sun, 1 Jun 2025 17:37:46 +0900",
    "creator": "SIDNFT",
    "categories": [
      "프로그래밍/개발메모",
      "Move",
      "수이",
      "앱토스",
      "코인"
    ]
  },
  {
    "id": 7,
    "imageUrl": "",
    "title": "악역영애 4컷 만화 - 5화, 등교 시작인데스와~★",
    "description": "No description available",
    "reviews": [],
    "syllabus": [],
    "link": "https://bbs.ruliweb.com/news/board/11/read/2315",
    "pubDate": "Wed, 04 Jun 2025 19:09:01 +0900",
    "creator": "｜RULIWEB｜",
    "categories": [
      "웹툰"
    ]
  },
  {
    "id": 8,
    "imageUrl": "",
    "title": "What’s Next for RubyMine",
    "description": "Hello everyone! The RubyMine 2025.2 Early Access Program is already available! In this blog post, we’ll share the upcoming features and updates planned for this release cycle. What’s coming in RubyMine 2025.2? Debugger improvements We’re introducing a number of changes aimed at enhancing the debugger installation experience. The entire process will now take less time, […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/ruby/2025/06/what-s-next-for-rubymine/",
    "pubDate": "Tue, 03 Jun 2025 07:55:54 +0000",
    "creator": "Alexey Varfolomeev",
    "categories": [
      "eap",
      "rubymine",
      "new-features"
    ]
  },
  {
    "id": 9,
    "imageUrl": "",
    "title": "AI스트레스, 다들 없으세요?",
    "description": "저는 국내 대형 카드사에 재직 중입니다. 금융회사가 다 그렇듯 상당히 보수적이고 변화에 늦은 편이죠. 그런데 작년 말 갑자기 회사 안에 AI 본부가 생겼습니다. AI가 화두긴 화두인가 봅니다. 세상이 변하고 있으니 빨리 쫓아가야죠.  그런데 제가 불려 들어갔습니다. 그냥도 아니고 팀장입니다. (제가요? 왜요? 라고 요즘 MZ들 하는 말 저도 해 보고 싶었습니다만…) 네, 작년 말 이후로 갑자기 […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://ppss.kr/archives/268818",
    "pubDate": "Mon, 02 Jun 2025 03:06:01 +0000",
    "creator": "길진세",
    "categories": [
      "IT",
      "사회"
    ]
  },
  {
    "id": 10,
    "imageUrl": "",
    "title": "Gemma3 기반 Ollama 활용 AI 에이전트 개발 핵심 Function Call 실습",
    "description": "이 글은 AI 에이전트 개발 시 필수적인 함수호출 방법을 오픈소스를 이용해 구현해 본다. 이를 위해, Gemma3 기반 Ollama 활용 Function Call 실습 내용을 소개하고 실행 결과를 확인한다. 아울러, 이런 함수호출 방식의 한계점을 개선하기 위한 솔류션을 나눔한다.\n\n\nAI 에이전트 내부 Function call 메커니즘(Akriti, 2025)\n\n\n개발 환경\n개발 환경은 다음과 같다. 미리 설치, 가입한다.\n\nollama:  https://ollama.com/download/windows\ngemma3: https://ollama.com/search\nserper 서비스: 가입. https://serper.dev/dashboard \n\n설치되어 있다면, 다음 명령을 터미널에서 실행한다.\nollama pull gemma3:4b\n\n\n이제 다음과 같이 모델을 실행해 볼 수 있다. \n\n\n\n\n참고로, GPU VRAM 등을 고려해 다음 모델을 사용할 수 도 있다.\n\n\n\n처리 프로세스\n이 실습 프로그램의 프로세스는 다음과 같다.\n\n\nGradio 앱이 시작되면, 사용자의 입력이 발생하고 이 입력은 process_message 함수에 전달된다. 이 함수는 사용자의 메시지를 chat_history에 추가하여 대화 기록을 저장한다. 이후 모델에게 전달할 대화 문맥을 구성하기 위해 messages 리스트가 생성된다.\n\n\n그 다음 단계에서는 ollama.chat 함수를 통해 언어 모델에게 응답을 요청하게 되며, 이 응답 내에 함수 호출이 포함되어 있는지를 확인한다. 만약 응답에 함수 호출이 포함되어 있다면, 이를 parse_function_call 함수를 통해 파싱한다.\n\n\n파싱된 함수가 google_search라면, 모델이 검색을 원한다고 판단하여 검색 쿼리를 추출하고 검색 수행 예정임을 사용자에게 안내하는 메시지를 추가한다. 이후 실제로 google_search 함수를 실행하여 외부 검색을 수행한다.\n\n\n검색 결과는 다시 chat_history에 저장되며, 이 결과를 바탕으로 언어 모델에게 재질문을 하여 더 정확하고 완성된 응답을 유도한다. 모델이 생성한 최종 응답은 chat_history에 마지막으로 추가되고, 이 전체 대화 기록이 사용자에게 반환된다.\n\n\n이 구조는 사용자의 질의에 따라 외부 정보까지 능동적으로 검색하고 반영할 수 있는 LLM 기반 AI 에이전트의 대표적인 흐름을 보여준다.\n\n\n다음은 이 순서도를 보여준다.\n\n\n\n구현\n우선, 필요한 라이브러리를 임포트한다. \n\nimport gradio as gr\nimport ollama\nimport requests, json, os\nfrom dotenv import load_dotenv\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, Dict, Any, List\n\nload_dotenv()\nSERPER_API_KEY = os.getenv('SERPER_API_KEY')\n\n\n\n그리고, 사용하는 API 키를 가져온다. 이를 위해, 미리 .env 파일을 다음과 같이 만들어 놓고, 해당 API를 입력해 놓야야 한다.\n\n# .env\nSERPER_API_KEY=<YOUR API KEY>\n\n\n\n파라메터에서 검색 질의문, 함수호출명과 파라메터를 정의한다. 아울러, 질의 결과를 명확히 데이터항목으로 추출하기 위해서 검색 결과가 될 데이타항목(타이틀, 링크, 스닙펫) 형식을 pydantic의 basemodel을 이용해 명확히 정의한다.\n\nclass SearchParameters(BaseModel):\n    query: str = Field(..., description=\"Search term to look up\")\n\nclass FunctionCall(BaseModel):\n    name: str\n    parameters: Dict[str, Any]\n\nclass SearchResult(BaseModel):\n    title: str\n    link: str\n    snippet: str\n\n    def to_string(self) -> str:\n        return f\"Title: {self.title}\\nLink: {self.link}\\nSnippet: {self.snippet}\"\n\ndef google_search(query: str) -> SearchResult:\n    \"\"\"Perform a Google search using Serper.dev API\"\"\"\n    try:\n        url = \"https://google.serper.dev/search\"\n        payload = json.dumps({\"q\": query})\n        headers = {\n            'X-API-KEY': SERPER_API_KEY,\n            'Content-Type': 'application/json'\n        }\n        \n        response = requests.post(url, headers=headers, data=payload)\n        response.raise_for_status()  # 잘못된 상태 코드에 대해 예외 발생\n        \n        results = response.json()\n        \n        if not results.get('organic'):\n            raise ValueError(\"No search results found.\")\n            \n        first_result = results['organic'][0]\n        return SearchResult(\n            title=first_result.get('title', 'No title'),\n            link=first_result.get('link', 'No link'),\n            snippet=first_result.get('snippet', 'No snippet available.')\n        )\n    except Exception as e:\n        print(f\"Search error: {str(e)}\")\n        raise\n\ndef parse_function_call(response: str) -> Optional[FunctionCall]:\n    \"\"\"Parse the model's response to extract function calls\"\"\"\n    try:\n        # Clean the response and find JSON structure\n        response = response.strip()\n        start_idx = response.find('{')\n        end_idx = response.rfind('}') + 1\n        \n        if start_idx == -1 or end_idx == 0:\n            return None\n            \n        json_str = response[start_idx:end_idx]\n        data = json.loads(json_str)\n        return FunctionCall(**data)\n    except Exception as e:\n        print(f\"Error parsing function call: {str(e)}\")\n        return None\n\n\n\ngemma에 지시할 시스템 프롬프트 명령을 정의한다. SYSTEM_MESSAGE는 이 챗봇이 어떻게 동작해야 하는지, 그리고 어떤 기준으로 답변을 해야 하는지에 대한 지침을 제공하는 역할을 한다. 이 메시지는 챗봇이 2023년까지의 정보를 학습한 AI 어시스턴트임을 명확히 하고, 사용자의 질문에 대해 가능한 경우에는 바로 답변을 하되, 최신 정보나 불확실한 내용, 시의성이 있는 질문에 대해서는 반드시 검색 기능을 활용해야 함을 명시한다. 이전 대화 내용이 함께 입력으로 주어지기 때문에, 챗봇은 이 대화 맥락을 참고하여 일관성 있고 상황에 맞는 답변을 해야 한다고 안내한다.\n\n\n검색이 필요한 상황과 그렇지 않은 상황을 구체적으로 구분하여, 챗봇이 임의로 정보를 추정하거나 추가하지 않고, 검색 결과에 기반한 사실만을 간결하게 전달하도록 유도한다. 검색이 필요한 경우에는 정해진 JSON 형식으로만 응답하도록 하여, 시스템이 함수 호출 방식으로 검색을 처리할 수 있게 한다.\n\n# System message for the model\nSYSTEM_MESSAGE = \"\"\"You are an AI assistant with training data up to 2023. Answer questions directly when possible, and use search when necessary.\n\nYou will receive previous conversation messages as part of the input. Use these prior messages to maintain context and provide coherent, context-aware answers.\n\nDECISION PROCESS:\n1. For historical events (pre-2023):\n   → Answer directly from your training data\n\n2. For 2023 events:\n   → If you have clear knowledge → Answer directly\n   → If uncertain about details → Use search\n\n3. For current events (post-2023):\n   → Always use search\n\n4. For timeless information (scientific facts, concepts, etc.):\n   → Answer directly from your training data\n\nIMPORTANT: ALWAYS USE SEARCH when the question:\n- Contains terms like \"current\", \"latest\", \"now\", \"present\", \"today\", \"recent\"\n- Asks about \"who is\" someone in a position that changes (champion, president, CEO, etc.)\n- Requests information that might have changed since 2023\n- Doesn't specify a time period for time-sensitive information\n\nWHEN TO SEARCH:\n- Events after 2023\n- Uncertain details about 2023 events\n- Current status of changing information\n- Real-time data\n\nFUNCTION CALL FORMAT:\nWhen you need to search, respond WITH ONLY THE JSON OBJECT, no other text, no backticks:\n{\n    \"name\": \"google_search\",\n    \"parameters\": {\n        \"query\": \"your search query\"\n    }\n}\n\nSEARCH FUNCTION:\n{\n    \"name\": \"google_search\",\n    \"description\": \"Search for real-time information\",\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"Search term\"\n            }\n        },\n        \"required\": [\"query\"]\n    }\n}\n\nRESPONSE GUIDELINES:\n1. Only include facts from search results\n2. Never add dates not in search results\n3. No assumptions about timing or events\n4. Quote dates exactly as they appear\n5. Keep responses concise and factual\"\"\"\n\n\n\n이제 process_message 함수를 구현한다. 이 함수는 사용자의 입력과 기존 채팅 기록을 받아 AI 모델과의 대화 흐름을 관리하는 역할을 한다.\n\n\n먼저 사용자의 메시지를 채팅 기록에 추가하고, 이전 대화 내용(메모리)을 추출하여 시스템 메시지와 함께 모델에 전달할 메시지 목록을 구성한다. 이 메시지 목록을 Ollama 모델에 전달하여 응답을 받는다. 모델의 응답이 함수 호출(JSON) 형태라면, 그 내용을 파싱하여 검색이 필요한 경우 검색 쿼리를 추출한다.\n\n\n검색이 필요하다고 판단되면, 검색 중임을 알리는 메시지를 채팅 기록에 추가하고, 실제로 검색을 수행한다. 검색 결과를 다시 채팅 기록에 반영한 뒤, 이 결과를 포함한 새로운 메시지 목록을 만들어 모델에 전달하여 최종 답변을 받는다. 최종적으로 받은 답변 역시 채팅 기록에 추가한다.\n\n\n검색이 필요하지 않은 경우에는 모델의 응답을 바로 채팅 기록에 추가한다. 이 과정에서 각 단계별로 최신 채팅 기록을 반환하여, 사용자 인터페이스가 실시간으로 대화 상태를 갱신할 수 있도록 한다.\n함수 실행 중 오류가 발생하면, 오류 메시지를 채팅 기록에 추가하여 사용자에게 알린다.\n\n\n# Model name\nMODEL_NAME = \"gemma3\"\n\ndef process_message(user_input, chat_history):\n    \"\"\"Process user message and update chat history\"\"\"\n    try:\n        # 사용자 메시지를 기록에 추가\n        chat_history.append({\"role\": \"user\", \"content\": user_input})\n        search_info = None\n        memory = chat_history[:-1] if len(chat_history) > 1 else []\n        messages = [{\"role\": \"system\", \"content\": SYSTEM_MESSAGE}] + memory + [{\"role\": \"user\", \"content\": user_input}]\n        \n        # 모델로부터 응답 받기\n        response = ollama.chat(\n            model=MODEL_NAME,\n            messages=messages\n        )\n        \n        model_response = response['message']['content']\n        \n        # 함수 호출로 응답을 파싱 시도\n        function_call = parse_function_call(model_response)\n        \n        if function_call and function_call.name == \"google_search\":\n            # 검색 파라미터 검증\n            search_params = SearchParameters(**function_call.parameters)\n            search_query = search_params.query\n            \n            # 검색 정보 기록에 추가\n            search_info = f\"Searching for: {search_query}\"\n            chat_history.append({\"role\": \"assistant\", \"content\": search_info})\n            yield chat_history\n            \n            # 검색 실행\n            search_result = google_search(search_query)\n            \n            # 검색 결과로 정보 업데이트\n            search_info = f\"Searched for: {search_query}\\n\\n📊 Result:\\n{search_result.to_string()}\"\n            chat_history[-1] = {\"role\": \"assistant\", \"content\": search_info}\n            yield chat_history\n\n            memory = chat_history[:]\n            messages = [{\"role\": \"system\", \"content\": SYSTEM_MESSAGE}] + memory + [\n                {\"role\": \"user\", \"content\": f\"Based on the search results: {search_result.to_string()}\"}\n            ]            \n\n            # 검색 결과를 포함해 모델로부터 최종 응답 받기\n            final_response = ollama.chat(\n                model=MODEL_NAME,\n                messages=messages\n            )\n            \n            assistant_response = final_response['message']['content']\n        else:\n            # 함수 호출이 없으면 직접 응답 반환\n            assistant_response = model_response\n        \n        # 최종 응답을 기록에 업데이트\n        if search_info:\n            # Add both search info and final response\n            chat_history.append({\"role\": \"assistant\", \"content\": f\" Response:\\n{assistant_response}\"})\n        else:\n            # Just add assistant response\n            chat_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n        \n        yield chat_history\n            \n    except Exception as e:\n        error_msg = f\"An error occurred: {str(e)}\"\n        chat_history.append({\"role\": \"assistant\", \"content\": error_msg})\n        yield chat_history\n\n\n\n이제 Gradio UI 를 정의하고, 메인 엔트리에서 이 앱을 실행한다.\n\n\n# Gradio 인터페이스 생성\nwith gr.Blocks(css=\"footer {visibility: hidden}\") as demo:\n    gr.Markdown(\"\"\"\n    # Agent based on Gemma3 using Function Call\n    \n\n    \"\"\")\n    \n    chatbot = gr.Chatbot(\n        height=500,\n        show_label=False,\n        avatar_images=(None, \"https://api.dicebear.com/9.x/identicon/svg?seed=Mason\"),\n        type=\"messages\"\n    )\n    \n    with gr.Row():\n        msg = gr.Textbox(\n            scale=5,\n            show_label=False,\n            placeholder=\"Ask me anything...\",\n            container=False\n        )\n        submit_btn = gr.Button(\"Send\", scale=1)\n    \n    with gr.Row():\n        clear_btn = gr.Button(\"Clear Chat\")\n    \n\n    # 이벤트 핸들러 설정\n    msg.submit(\n        process_message,\n        [msg, chatbot],\n        [chatbot],\n    )\n    \n    submit_btn.click(\n        process_message,\n        [msg, chatbot],\n        [chatbot],\n    )\n    \n    clear_btn.click(\n        lambda: [],\n        None,\n        chatbot,\n        queue=False\n    )\n    \n    # 메시지 전송 후 텍스트박스 비우기\n    msg.submit(lambda: \"\", None, msg)\n    submit_btn.click(lambda: \"\", None, msg)\n\nif __name__ == \"__main__\":\n    demo.launch(inbrowser=True, share=True) \n\n\n\n실행\n앞에 구현된 앱을 실행한다. 그리고, 적절한 질문을 입력해 본다. 다음과 같이 실행되면 성공한 것이다.\n\n\n\n\n펑션콜 문제 개선 방법\n실제로 질의해보면 불명확한 프롬프트 입력 등에서 부적절한 함수 호출이 수행되는 것을 알 수 있다. 이를 개선하기 위해 다음 사항을 고려한다.\n\n프롬프트 설계의 명확성\n\n함수 호출이 필요한 상황, 호출 방식(JSON 포맷 등), 호출 예시를 SYSTEM_MESSAGE에 명확하게 안내해야 한다. 함수 호출이 아닌 일반 답변을 하면 안 된다는 점을 반복적으로 강조한다.\n예시 프롬프트:\n\"질문에 답변하기 위해 함수 호출이 필요하다고 판단되면 반드시 아래 JSON 형식으로만 응답하라. 다른 텍스트나 설명은 절대 포함하지 마라.\"\n\n함수 정의의 구체성\n\n함수의 목적, 파라미터, 반환값, 사용 예시를 상세하게 기술한다. 각 파라미터의 타입, 필수 여부, 설명을 명확히 한다. 함수가 처리할 수 없는 입력(예: 빈 문자열, 잘못된 타입 등)에 대한 예외 상황도 명시한다.\n\n예시 기반 Few-shot Prompting\n\nSYSTEM_MESSAGE 또는 user message에 함수 호출이 필요한 질문과 그에 대한 올바른 함수 호출 예시를 여러 개 포함시킨다. 예시가 많을수록 모델이 패턴을 더 잘 학습한다.\n\n함수 호출 실패 시 재시도 로직\n\n모델이 함수 호출을 하지 않거나 잘못된 형식으로 응답하면, 내부적으로 \"함수 호출이 필요합니다. 반드시 JSON 형식으로만 응답하세요.\"와 같은 추가 프롬프트로 재요청한다.\n\n출력 파싱의 견고성\n\n모델이 JSON 외의 텍스트를 섞어서 반환할 수 있으므로, 파싱 로직에서 JSON 부분만 추출하거나, 불완전한 JSON도 최대한 보완해서 파싱하도록 한다.\n\n함수 호출 의도 강화 프롬프트\n\nSYSTEM_MESSAGE에 \"함수 호출이 필요한 상황에서는 반드시 함수 호출을 우선적으로 고려하라\"는 문구를 추가한다. \"만약 함수 호출이 필요하지 않다고 판단되면, 그 이유를 설명하지 말고 바로 답변만 하라.\" 등 불필요한 설명을 억제한다.\n\n모델 버전 및 파라미터 최적화\n\n최신 GPT-4 Turbo 등 함수 호출에 최적화된 모델을 사용한다. temperature, top_p 등 파라미터를 낮춰 일관된 응답을 유도한다. \n\n함수 호출 실패 케이스 수집 및 개선 \n\n\n실제 사용자 입력 중 함수 호출이 누락된 사례를 수집하여, SYSTEM_MESSAGE나 예시 프롬프트를 지속적으로 개선한다.\n\n이외에 잘 활용되는 함수에 대한 파인튜닝을 수행해 본다. \n\n마무리\n본 글은 ollama 를 이용한 gemma3 모델을 로딩해 Agent 개발 시 핵심이 되는 function call을 구현해 보았다. 실행해 보면 알겠지만, 펑션콜은 프롬프트 입력에 따라 민감하게 동작한다는 것을 알 수 있다. 그러므로, 함수 호출 방식은 절절히 튜닝되어야 한다는 것을 알 수 있다. \n\n\n레퍼런스\n\nFunction calling with Gemma3 using Ollama | by Arjun Prabhulal | Google Cloud - Community | Mar, 2025 | Medium | Google Cloud - Community\nEnhancing Gemma 3’s Capabilities with Fine-Tuning for Function Calling | by Akriti Upadhyay | May, 2025 | Medium\nGeneral AI agent framework for smart buildings based on  large language models and ReAct strategy\nOpen-Source Tools for Agents | Data Science Collective\nThe Era of High-Paying Tech Jobs is Over | by Somnath Singh | Level Up Coding\nAGI-Edgerunners/LLM-Agents-Papers: A repo lists papers related to LLM based agent\nLLM for Optimisation in 3-D Space: A comparison with Deterministic optimisation methods | by Peter Eze | Crayon Data & AI | Medium\nDemystifying Generative AI Agents | by Dr Sokratis Kartakis | Google Cloud - Community | Medium\ncookbook/quickstarts/Function_calling.ipynb at main · google-gemini/cookbook",
    "reviews": [],
    "syllabus": [],
    "link": "http://daddynkidsmakers.blogspot.com/2025/06/gemma3-ollama-function-call.html",
    "pubDate": "2025-06-04T06:56:00.000Z",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 11,
    "imageUrl": "",
    "title": "GitHub Copilot의 Visual Studio 자동 문서 댓글 생성 기능 소개",
    "description": "No description available",
    "reviews": [],
    "syllabus": [],
    "link": "https://jacking75.github.io/ai-github_copilot_20250602/",
    "pubDate": "Mon, 02 Jun 2025 00:00:00 +0900",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 12,
    "imageUrl": "",
    "title": "dotInsights | June 2025",
    "description": "Did you know? The Original Name of .NET Was “Next Generation Windows Services (NGWS)“. Before Microsoft officially named it “.NET,” the platform was internally referred to as NGWS: Next Generation Windows Services. The name “.NET” was adopted in the late 1990s to emphasize the platform’s focus on web-based development and interoperability, as opposed to being […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/dotnet/2025/06/03/dotinsights-june-2025/",
    "pubDate": "Tue, 03 Jun 2025 13:31:32 +0000",
    "creator": "Rachel Appel",
    "categories": [
      "net-tools",
      "dotinsights"
    ]
  },
  {
    "id": 13,
    "imageUrl": "",
    "title": "Junie and RubyMine: Your Winning Combo",
    "description": "Junie, a powerful AI coding agent from JetBrains, is available in RubyMine! Install the plugin and try it out now! Why Junie is a game-changer Unlike other AI coding agents, Junie leverages the robust power of JetBrains IDEs and reliable large language models (LLMs) to deliver exceptional results with high precision. According to SWE-bench Verified, […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/ruby/2025/06/junie-and-rubymine-your-winning-combo/",
    "pubDate": "Tue, 03 Jun 2025 07:55:50 +0000",
    "creator": "Alexey Varfolomeev",
    "categories": [
      "jetbrains-ai",
      "rubymine",
      "ai",
      "ai-agent",
      "junie"
    ]
  },
  {
    "id": 14,
    "imageUrl": "",
    "title": "Get Answers to Your KMP Questions",
    "description": "During the Closing Panel at KotlinConf 2025, we received many questions about Kotlin Multiplatform (KMP), but unfortunately didn’t have time to address them all live. So we’ve decided to answer the most popular ones in a follow-up blog post. Will IntelliJ IDEA and Android Studio support full Swift navigation, completion, etc., for iOS code, or […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/kotlin/2025/06/get-answers-to-your-kmp-questions/",
    "pubDate": "Mon, 02 Jun 2025 06:37:10 +0000",
    "creator": "Anton Makeev",
    "categories": [
      "multiplatform"
    ]
  },
  {
    "id": 15,
    "imageUrl": "",
    "title": "앱 개발 개척시대",
    "description": "AI 시대에는 개발자가 유리한가?\n다 똑같다고 생각합니다. 모두가 같은 출발선.\n제가 공부한 모든 컴퓨터 공학 지식의 가치를 0으로 설정했습니다.\n서부 개척시대에서 요이땅 하고 땅따먹기를 하러 가는 느낌입니다.\n어쩌면 이게 제 개발자 경력의 마지막은 아닐까?\n\n\n함께 읽으면 좋은 글:\n1인 개발자 전성시대\n1인 개발이란 전쟁터에서 혼자 살아남는 것",
    "reviews": [],
    "syllabus": [],
    "link": "https://jeho.page/essay/2025/06/05/at-the-app-development-race.html",
    "pubDate": "2025-06-05T02:44:00.000Z",
    "creator": "Unknown",
    "categories": []
  }
]