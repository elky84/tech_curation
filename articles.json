[
  {
    "id": 1,
    "imageUrl": "",
    "title": "Title Launch Observability at Netflix Scale",
    "description": "No description available",
    "reviews": [],
    "syllabus": [],
    "link": "https://netflixtechblog.com/title-launch-observability-at-netflix-scale-8efe69ebd653?source=rss----2615bd06b42e---4",
    "pubDate": "Wed, 05 Mar 2025 01:24:53 GMT",
    "creator": "Netflix Technology Blog",
    "categories": [
      "system-design-concepts",
      "netflix",
      "software-engineering",
      "observability"
    ]
  },
  {
    "id": 2,
    "imageUrl": "",
    "title": "IntelliJ IDEA 2025.1 Beta Is Out! ",
    "description": "IntelliJ IDEA 2025.1 Beta is now available! This means we’re in the final stretch before the major release, and you can try out all the new features and improvements right now. You can download this version from our website, update directly from within the IDE, use the free Toolbox App, or install it via snap […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/idea/2025/03/intellij-idea-2025-1-beta/",
    "pubDate": "Wed, 05 Mar 2025 17:16:21 +0000",
    "creator": "Maria Kosukhina",
    "categories": [
      "eap",
      "2025-1-eap",
      "intellij-idea-2025-1",
      "intellij-idea-2025-1-eap"
    ]
  },
  {
    "id": 3,
    "imageUrl": "",
    "title": "성급한 널 처리의 오류",
    "description": "절대 죽지 않는 프로그램을 짜고 싶었습니다. 널 처리만 잘하면 된다고 생각했습니다.\n첫 회사에 입사해서 윈도우 클라이언트 프로그램을 부여받았습니다.\n맨티스라는 도구에 버그가 올라오면 내가 고칠 수 있는 게 있을까 신이 나서 찾아 고쳤습니다.\n대부분 널 포인터만 감싸면 고쳐지는 에러였습니다.\n26살의 신입사원답게 아주 재빨랐습니다.\n\nif (pData != NULL)\n  return;\n\n\n그리고 다시 재현해 보고 더 이상 죽지 않으면 Fixed로 변경.\n저는 이걸 성급한 널 처리의 오류라고 부르고 싶습니다.\n경험이 쌓이면서 이게 그리 쉬운 문제가 아니라는 걸 알았습니다.\n\nASSERT(pData);\n\n\nASSERT 같은 코드를 왜 쓰는지도 그쯤에야 깨달았습니다. (학생 때는 도무지 이해가 되지 않았습니다)\n이후로는 변수가 널이어야 하는 경우와 절대 널이어선 안 되는 경우를 엄격하게 구분하기 시작했습니다. 애초에 널 상태를 만들지 않으려 애썼습니다.\n변수를 처음 선언할 때부터.\nDB 스키마를 만들 때부터.\n서버에서 클라이언트에 데이터를 내려줄 때도 함부로 null 을 사용하지 않았습니다.\nC/C++처럼 낡은 언어와는 다르게 요즘 언어들은 nullable 혹은 optional 타입 기능을 제공하는 것 같습니다.\n\n함께 읽으면 좋은 글:\n메모리를 해제하기 전에 왜 널 체크를 하는걸까?",
    "reviews": [],
    "syllabus": [],
    "link": "https://jeho.page/essay/2025/03/11/fallacy-of-hasty-null-handling.html",
    "pubDate": "2025-03-10T23:17:00.000Z",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 4,
    "imageUrl": "",
    "title": "IntelliJ IDEA’s Blog Feedback 2025",
    "description": "Over the years, the IntelliJ IDEA blog has become your go-to hub for expert insights, handy tips, and tech inspiration. But we want more – we’re heading to perfection, and we need your ideas to get there. Fill out this survey to let us know what rocks and what could be even better. It only […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/idea/2025/03/intellij-idea-s-blog-feedback-2025/",
    "pubDate": "Mon, 10 Mar 2025 10:13:32 +0000",
    "creator": "Irina Mariasova",
    "categories": [
      "news",
      "blogs",
      "intellij-idea"
    ]
  },
  {
    "id": 5,
    "imageUrl": "",
    "title": "Livestream: Essential Tools for JetBrains IDE Plugin Development",
    "description": "Join us for an insightful session on the top tools every plugin developer should know. IntelliJ Platform Developer Advocates Yann Cébron and Jakub Chrzanowski will walk you through essential utilities that streamline plugin development for JetBrains IDEs. During the webinar, you will discover how: No matter your level of experience, this webinar will equip you […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/platform/2025/03/livestream-essential-tools-for-jetbrains-ide-plugin-developmentlivestream/",
    "pubDate": "Mon, 10 Mar 2025 16:52:03 +0000",
    "creator": "Elena Kerpeleva",
    "categories": [
      "plugin-development",
      "intellij",
      "livestreams",
      "marketplace",
      "news",
      "busy-plugin-developers",
      "jetbrains-marketplace",
      "livestream"
    ]
  },
  {
    "id": 6,
    "imageUrl": "",
    "title": "방향이 바겼다. 미국 주식은 안된다. / 중국 유럽 주식 / 미국 채권 / 2025-03-07",
    "description": "영상: https://www.youtube.com/watch?v=vsSWm_-PnqM\n\n\n\n18분에 나오는 스샷\n\n\n \n요약\n미국 주식도 안좋고 달러도 안좋습니다. \n금 / 유럼 + 중국 주식 / 미국 채권은 좋습니다.\n \nTIGER 차이나항셍테크\nKIWOOM 차이나내수소비TOP CSI\n에셋플러스 차이나일등기업포커스10액티브\nKodex 미국30년국채액티브(H)",
    "reviews": [],
    "syllabus": [],
    "link": "http://serverdown.tistory.com/1173",
    "pubDate": "Fri, 7 Mar 2025 17:56:24 +0900",
    "creator": "SIDNFT",
    "categories": [
      "투자"
    ]
  },
  {
    "id": 7,
    "imageUrl": "",
    "title": "토스, ‘미키 17’ 개봉 캠페인 성료…534만 회 참여",
    "description": "이제 영화 광고도 토스로",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.toss.im/article/MICKEY17",
    "pubDate": "Thu, 06 Mar 2025 01:00:00 GMT",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 8,
    "imageUrl": "",
    "title": "A case for QLC SSDs in the data center",
    "description": "The growth of data and need for increased power efficiency are leading to innovative storage solutions. HDDs have been growing in density, but not performance, and TLC flash remains at a price point that is restrictive for scaling.  QLC technology addresses these challenges by forming a middle tier between HDDs and TLC SSDs.   QLC [...]\nRead More...\nThe post A case for QLC SSDs in the data center appeared first on Engineering at Meta.",
    "reviews": [],
    "syllabus": [],
    "link": "https://engineering.fb.com/2025/03/04/data-center-engineering/a-case-for-qlc-ssds-in-the-data-center/",
    "pubDate": "Tue, 04 Mar 2025 17:00:26 +0000",
    "creator": "Unknown",
    "categories": [
      "Data Center Engineering"
    ]
  },
  {
    "id": 9,
    "imageUrl": "",
    "title": "Trino로 타임아웃 개선하기",
    "description": "![NHN Cloud_meetup banner_trino_202502-01_900.png](https://image.toast.com/aaaadh/real/2025/techblog/NHN%20Cloudmeetup%20bannertrino20250201900.png)\r\r\n\r\r\n# 들어가며\r\r\n안녕하세요. NHN Cloud의 클라우드AI팀 이태형입니다.\r\r\n로그 데이터가 쌓일수록 조회 속도가 느려지는 문제, 한 번쯤 겪어 보셨을 텐데요. 이 글에서는 이러한 문제를 해결하기 위해 저희 팀에서 Trino를 도입하여 성능을 개선한 과정을 공유해 보려 합니다. 재미있게 읽어 주세요! \r\r\n\r\r\n# 개요: NHN AppGuard\r\r\n[NHN AppGuard](https://www.nhncloud.com/kr/service/security/nhn-appguard) 서비스에 Trino를 적용한 이야기를 드릴 예정이라서 먼저 해당 서비스를 소개하겠습니다.\r\r\n\r\r\nNHN AppGuard는 모바일 애플리케이션을 보호하기 위해 사용자의 이상 행위를 탐지하거나 차단하는 모바일 앱 보안 솔루션입니다. NHN AppGuard의 서버는 탐지/차단 로그를 안전하게 저장하고, 각종 조건 검색과 대시보드를 제공합니다.\r\r\n\r\r\n![Trino_1.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino1.png)\r\r\n\r\r\n## NHN AppGuard 로그\r\r\n\r\r\nNHN AppGuard는 평균 600만개/일 가량의 로그를 수집하고 있습니다. 이러한 로그는 NHN AppGuard 로그 워크플로에 따라 DB에 적재됩니다.\r\r\n\r\r\n![Trino_2_900.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino2900.png)\r\r\n\r\r\n## 이슈 발생\r\r\n\r\r\n대부분의 쿼리가 월 단위 집계 성격을 띠는 이유로 질의 대상 row 가 1억 건이 넘는 경우가 많아 이슈가 발생했습니다.\r\r\n발생한 이슈는 아래와 같습니다.\r\r\n\r\r\n1. 검색 조건 변경 시 대시보드 화면에서 타임아웃 발생\r\r\n![Trino_3.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino3.png)\r\r\n2. 집계 쿼리가 수행되는 새벽 시간대에 slow query 발생\r\r\n![Trino_4.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino4.png)\r\r\n\r\r\n## 일반적인 해결 방안\r\r\n\r\r\n위 이슈들은 결국 쿼리의 성능이 원인이기 때문에 먼저 쿼리 최적화를 수행했습니다.\r\r\n\r\r\n1. index 문제\r\r\n    1. 쿼리 검수를 통해 index의 순서를 변경하고\r\r\n    2. 의도한 index가 적용되도록 쿼리에 index hint를 추가했습니다.\r\r\n2. 쿼리의 문제\r\r\n    1. 한 달 기간 전체 데이터를 스캔하는 쿼리를 당일 증가분만 조회하도록 수정하고\r\r\n    2. 대시보드를 매번 조회하지 않고 일 배치 작업으로 미리 계산해 둔 데이터를 조회하고\r\r\n    3. 조회 가능한 기간을 제한했습니다.\r\r\n\r\r\n이러한 최적화를 통해 일시적으로 이슈가 해소되었습니다.\r\r\n하지만 NHN AppGuard의 로그는 점차 늘어나고, 집계할 데이터의 종류도 증가했으며, 조회 기간 감소에 대한 불만이 발생하여 다른 접근이 필요했습니다.\r\r\n\r\r\n## 로그 저장소 검토\r\r\n\r\r\nMySQL을 대신해 로그를 저장하기에 적절한 로그 저장소를 검토했습니다.\r\r\n\r\r\n1. Elasticsearch (LNCS)\r\r\n    1. 검색에 좋은 성능\r\r\n    2. 상품 스펙상 최대 120일 저장 제한\r\r\n2. Trino (DataQuery)\r\r\n    1. 복잡한 집계 쿼리에 좋은 성능\r\r\n    2. 여러 데이터 소스 간 federation 지원\r\r\n    3. 저장 기간 제한 없음\r\r\n\r\r\nNHN AppGuard는 로그의 저장 기간을 기존 90일에서 늘리는 것을 계획하고 있었고, 무엇보다 대부분의 쿼리가 집계 성격을 많이 띠어 Trino가 적절하다고 판단했습니다.\r\r\n\r\r\n# Trino와 DataQuery\r\r\n\r\r\n## Trino란\r\r\n\r\r\n[Trino 공식 홈페이지](https://trino.io)를 보면 아래와 같은 문구를 찾을 수 있습니다.\r\r\n\r\r\n> Trino, a query engine that runs at ludicrous speed\r\r\n> Fast distributed SQL query engine for big data analytics that helps you explore your data universe.\r\r\n\r\r\n키워드를 뽑아 보면 아래와 같습니다.\r\r\n\r\r\n1. Fast - 빠르다\r\r\n2. Distributed - 분산 처리한다\r\r\n3. analytics - 분석에 적절하다\r\r\n\r\r\n## Trino 특징\r\r\n\r\r\n마찬가지로 [Trino 공식 홈페이지](https://trino.io)에서는 아래와 같은 특징을 소개합니다.\r\r\n![Trino_5.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino5.png)\r\r\n\r\r\n여기서도 키워드를 뽑아보면 아래와 같습니다.\r\r\n\r\r\n1. distributed: 분산 처리로 빠르고\r\r\n2. ANSI SQL: 표준 SQL 을 호환하여 현재 쿼리문을 수정할 필요가 없고\r\r\n3. S3: OBS에 저장하여 스토리지 비용을 줄일 수 있고\r\r\n4. Query Federation: OBS의 데이터와 MySQL 데이터를 하나의 쿼리로 join할 수 있다.\r\r\n\r\r\n## Trino 동작 원리\r\r\n\r\r\nTrino의 동작 원리는 [Presto: SQL on Everything](https://trino.io/Presto_SQL_on_Everything.pdf)라는 논문에 자세히 소개하고 있습니다.\r\r\n해당 논문의 일부를 가볍게 살펴보겠습니다.\r\r\n\r\r\n### 구조도\r\r\n![Trino_6.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino6.png)\r\r\n\r\r\nTrino는 하나의 Coordinator 노드와 여러 개의 Worker 노드로 구성됩니다. Coordinator 노드는 쿼리의 인입 지점으로 admit, parsing, planning, optimizing, orchestration 등을 수행하고, worker node는 query processing을 담당합니다.\r\r\n\r\r\n### 요청 처리 순서\r\r\n\r\r\nCoordinator 노드가 분산 처리를 계획하면 worker node가 병렬로 처리해서 복잡한 쿼리가 더 빠르게 실행되는 원리입니다.\r\r\n\r\r\n1. client → coordinator: http request (SQL stmt)\r\r\n2. coordinator: evaluate request(parsing, analyzing, **optimizing distributed execution plan**)\r\r\n3. coordinator: plan to worker\r\r\n    1. task 생성\r\r\n    2. **splits** 생성(addressable chunk in external storage)\r\r\n    3. splits을 task에 할당\r\r\n4. worker: run task\r\r\n    1. fetching splits\r\r\n    2. 다른 worker에서 생성한 intermediate data 처리\r\r\n        1. worker 간에는 intermediate data를 memory에 저장하여 공유\r\r\n        2. **shuffle**이 발생할 수 있음\r\r\n             \\*shuffle = node 간 데이터 재분배\r\r\n    3. query의 shape에 따라 모든 데이터를 처리하지 않고 반환\r\r\n\r\r\n## Trino 쿼리 실행 예시\r\r\n\r\r\n### 그림으로 살펴보기\r\r\n* 쿼리문\r\r\n![Trino_7.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino7.png)\r\r\n\r\r\n* logical plan\r\r\n![Trino_8.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino8.png)\r\r\n\r\r\n* distributed plan (stage)\r\r\n![Trino_9.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino9.png)\r\r\n\r\r\n* optimized plan (pipeline, parallelism)\r\r\n![Trino_10.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino10.png)\r\r\n\r\r\n\r\r\n### 실행 순서\r\r\n\r\r\n1. Planner: SQL → SQL syntax tree → Logical Planning (IR 생성)\r\r\n    * IR = Intermediate Representation\r\r\n2. Optimizer: Logical Plan → evaluate transformation rules → **optimize** → Physical Structure\r\r\n    * transformation rules = sub-tree query plan + transformation\r\r\n    * 사용되는 optimizing 기법 = predicate and limit pushdown, column pruning, decorrelation, table and column statistics 기반 cost-based 최적화\r\r\n        * Data Layouts = Connector Data Layout API로 얻어내는 위치, 파티션, 정렬, 그룹화, 인덱스\r\r\n        * Predicate Pushdown = connector에 따른 filtering 최적화\r\r\n            * \\*pushdown : 읽어야 하는 데이터를 줄이는 것\r\r\n            * \\***Predicate Pushdown** : 조회 조건에 맞는 데이터만 읽는 것\r\r\n        * **Inter**-node Parallelism = stage 단위의 병렬 실행\r\r\n        * **Intra**-node Parallelism = stage 내에서 single node의 thread에 걸친 병렬 실행\r\r\n3. Scheduler: Stage Scheduling → Task Scheduling → Split Scheduling\r\r\n    * Task Scheduling = Leaf Stage / Intermediate Stage 분리하여 배치\r\r\n4. Query Execution = Local Data Flow → Shuffles → Writes\r\r\n\r\r\n## DataQuery\r\r\n\r\r\n[NHN Cloud의 DataQuery](https://www.nhncloud.com/kr/service/data-analytics/dataquery?lang=ko) 서비스는 위에서 소개한 Trino를 기반으로 대규모 데이터에 대해 쿼리를 실행할 수 있는 서비스입니다.\r\r\n이를 통해 원하는 클러스터 스펙을 지정하고 연결할 데이터 소스만 작성하면 Trino의 복잡한 설치와 설정 과정 없이 사용이 가능합니다.\r\r\n\r\r\n# Trino 적용 - 개념\r\r\nTrino를 적용하기 위해 알아야 할 개념을 소개합니다.\r\r\n\r\r\n## 데이터 소스 선정\r\r\nTrino는 여러 종류의 데이터 소스를 지원합니다.\r\r\n\r\r\nNHN AppGuard는 로그 저장 기간 증가를 계획하고 있어 저장 비용을 절약하기 위해 OBS를 데이터 소스로 선정하였습니다.\r\r\nOBS 데이터 소스를 사용하는 경우 데이터의 타입도 Parquet, JSON, ORC, CSV, Text 중에 선택해 주어야 해서, 위와 동일한 이유로 Parquet 파일 포맷을 선택하였습니다.\r\r\n\r\r\n### Apache Parquet\r\r\n\r\r\n[Apache Parquet 홈페이지](https://parquet.apache.org)에는 Parquet를 아래와 같이 설명합니다.\r\r\n\r\r\n> Apache Parquet is an open source, column-oriented data file format designed for efficient data storage and retrieval. It provides efficient data compression and encoding schemes with enhanced performance to handle complex data in bulk. Parquet is available in multiple languages including Java, C++, Python, etc...\r\r\n\r\r\n여기서도 키워드를 뽑아보면 아래와 같습니다.\r\r\n\r\r\n* column-oriented data\r\r\n* efficient data storage and retrieval\r\r\n* efficient data compression\r\r\n* encoding schema\r\r\n* handle complex data in bulk\r\r\n\r\r\ncolumn-oriented data의 설명은 아래의 그림을 보시면 이해가 쉽습니다.\r\r\n![Trino_11.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino11.png)\r\r\n(Source: [https://devidea.tistory.com/92](https://devidea.tistory.com/92))\r\r\n\r\r\n동일한 타입의 데이터가 나열되기 때문에 압축 효율이 높아지는 효과가 있습니다.\r\r\n또한 footer에 데이터에 대한 메타데이터를 저장해 두어 reader에게 데이터에 대한 힌트를 주어 조회 성능을 높입니다.\r\r\n\r\r\n![Trino_12.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino12.png)\r\r\n(source: [https://parquet.apache.org/docs/file-format/](https://parquet.apache.org/docs/file-format/))\r\r\n\r\r\n## 구상안\r\r\n\r\r\nparquet는 columnar한 형식이기 때문에 row 단위로 데이터를 append하는 것은 비효율적입니다. 그러므로 데이터를 모아서 parquet 형식으로 파일을 생성하는 것이 효율적입니다. 이를 위해 NHN AppGuard에서는 3가지 구성 방법을 고려했고 3번째 안을 선택했습니다.\r\r\n\r\r\n1. micro batch\r\r\n    1. kafka → log-batch → create parquet / 1 minute → save obs → obs\r\r\n    2. trino는 OBS를 사용하는 경우 파일 기반으로 동작하기 때문에 파일의 개수가 많아지면 비효율적입니다.\r\r\n    3. 1분 단위로 파일을 쓸 경우 작은 파일이 많아져 조회 성능이 현저히 떨어지기 때문에 선택하지 않았습니다.\r\r\n2. hourly batch\r\r\n    1. kafka → log-batch → create parquet / 1 hour (save data in memory or redis) → save obs → obs\r\r\n    2. 메모리에 저장하는 경우 데이터 유실의 리스크가 걱정되었고\r\r\n    3. NHN AppGuard는 redis를 사용하고 있지 않아 trino와 redis 두 컴포넌트의 추가로 인한 운영 복잡도 증가가 부담되어 선택하지 않았습니다.\r\r\n3. **중간 DB 사용 - MySQL**\r\r\n    1. kafka → log-batch → save to mysql → mysql → tier down in daily-batch → save obs → obs\r\r\n    2. 기존에 사용하던 MySQL 구성을 변경하지 않아 수정 소요가 적었고\r\r\n    3. MySQL을 통해 실시간 데이터 또한 조회할 수 있어 실시간 데이터 조회가 쉬워 선택하였습니다.\r\r\n\r\r\n### 구성도\r\r\n\r\r\n* AS-IS\r\r\n![Trino_13_900.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino13900.png)\r\r\n\r\r\n* TO-BE\r\r\n![Trino_14_900.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino14900.png)\r\r\n\r\r\n\r\r\n### tier down 개념\r\r\n\r\r\nElasticSearch는 데이터의 역할 또는 접근 빈도에 따라 노드를 분배하는 기법으로 Data Tiering 을 사용합니다.\r\r\n\r\r\n![Trino_15.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino15.png)\r\r\n(source: [https://www.linkedin.com/pulse/navigating-data-tiers-optimizing-costs-reducing-risk-boosting-lim-yfeyc](https://www.linkedin.com/pulse/navigating-data-tiers-optimizing-costs-reducing-risk-boosting-lim-yfeyc))\r\r\n\r\r\n이렇게 tier를 적용한 데이터를 높은 티어에서 낮은 티어로 낮추는 것을 tier down이라고 부릅니다. hot tier는 일반적으로 성능이 좋고 반응이 빠르지만 비용이 비싸고, cold tier는 반응은 조금 느리지만 비용이 저렴한 저장소를 사용합니다.\r\r\n\r\r\nNHN AppGuard에서는 MySQL을 hot tier, Trino를 cold tier로 정의하고 daily-batch에서 MySQL 데이터를 Parquet로 변환해 Trino에 삽입시키는 작업을 tier down으로 정의했습니다.\r\r\n\r\r\n### Parquet 파일 생성 방법\r\r\n\r\r\nParquet는 원래 HDFS에 쓰는 용도로 고안되어서 Parquet 파일을 직접 쓰려면 `org.apache.hadoop:hadoop-common:3.3.6`과 같은 hdfs writer에 세그먼트 관리, 열 압축 등의 기능을 구현해야 합니다. 이러한 작업을 피하기 위해 일반적으로 Spark 등의 외부 컴포넌트를 쓰거나 avro 포맷의 파일을 거쳤다가 parquet로 변환하는 방법을 사용합니다.\r\r\n\r\r\n[Apache Avro](https://avro.apache.org)는 data를 serialize하기에 좋은 포맷으로 스키마를 갖습니다.\r\r\nParquetFileWriter를 지원하기 때문에 손쉽게 변환이 가능합니다.\r\r\n\r\r\n> Apache Avro™ is the leading serialization format for record data, and first choice for streaming data pipelines. It offers excellent schema evolution, and has implementations for the JVM (Java, Kotlin, Scala, …), Python, C/C++/C#, PHP, Ruby, Rust, JavaScript, and even Perl.\r\r\n\r\r\n# Trino 적용 - 구현\r\r\n\r\r\n## tier down 구현\r\r\n\r\r\n### 논리 구조\r\r\n![Trino_16_900.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino16900.png)\r\r\n\r\r\n\r\r\n### Trino 테이블 생성\r\r\n\r\r\nTrino 데이터 소스로 OBS를 사용하는 경우 Hive를 사용하기 때문에 HQL을 사용해야 합니다. HQL 또한 SQL 표준을 따르기 때문에 거의 유사하지만 묵시적 형 변환과 같은 편의 기능을 지원하지 않고, with 문의 external location, partitioned_by 등의 옵션이 추가됩니다.\r\r\n\r\r\n```sql\r\r\nCREATE TABLE log\r\r\n (\r\r\n    seq              bigint, \r\r\n    log_time         timestamp,\r\r\n    // 생략 \r\r\n    log_date         date,\r\r\n    appkey           varchar(64),\r\r\n ) \r\r\n WITH ( \r\r\n    format = 'Parquet',\r\r\n    external_location = 's3a://data-query/log',\r\r\n    partitioned_by = ARRAY['appkey','date']\r\r\n);\r\r\n```\r\r\n\r\r\n### avro schema 작성\r\r\n\r\r\n```javascript\r\r\n{\r\r\n  \"type\" : \"record\",\r\r\n  \"name\" : \"log\",\r\r\n  \"namespace\" : \"avro\",\r\r\n  \"fields\" : [\r\r\n    { \"name\" : \"seq\", \"type\" : \"long\" },\r\r\n    { \"name\" : \"log_time\", \"type\" : [ \"null\", \"string\" ], \"default\" : null },\r\r\n    // 생략\r\r\n  ]\r\r\n}\r\r\n```\r\r\n\r\r\n### tier down process\r\r\n![Trino_17.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino17.png)\r\r\n데이터를 메모리에 올려서 변환하기 때문에 장비와 데이터에 따라 적절한 페이징을 적용해야 합니다.\r\r\n\r\r\n### convert to parquet\r\r\n![Trino_18.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino18.png)\r\r\navro 변환은 apache avro 모듈의 schema.from 함수로 쉽게 변환이 가능합니다. parquet는 apache parquet 모듈의 PositionOutputStream 객체의 writer를 구현하여 변환할 수 있습니다.\r\r\n\r\r\n### 다른 방법은 없을까?\r\r\nCTAS(Create Table As Select)가 가장 쉬운 방법입니다. 수행 시간은 위 방법과 비슷하게 소요되지만 용량이 30% 정도 더 효율적인 것으로 확인하였습니다. 하지만 DataQuery에서 사내 DB를 아직 데이터 소스로 지원하지 않아 현재는 사용이 어렵습니다.\r\r\n여기에서는 방법만 소개하겠습니다.\r\r\n\r\r\n```sql\r\r\nCREATE TABLE obs.test.log_ctas\r\r\n    WITH (\r\r\n        format = 'Parquet',\r\r\n        external_location = 's3a://ctas-test/log-ctas',\r\r\n        partitioned_by = ARRAY['log_date', 'appkey']\r\r\n        )\r\r\nAS\r\r\nselect seq,\r\r\n// 생략\r\r\n       cast(log_time as date) as log_date,\r\r\n       appkey\r\r\nfrom \"mysql\".log\r\r\nwhere log_time >= date '2024-11-01'\r\r\n  and log_time < date '2024-11-02';\r\r\n```\r\r\n\r\r\n## 실시간 데이터 union 구현\r\r\n\r\r\n### 논리 구성도\r\r\n![Trino_19_900.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino19900.png)\r\r\n1. cold data에 마지막으로 저장된 시간을 조회하고\r\r\n2. cold data와 hot data를 조회해\r\r\n3. join / union 하여 응답합니다.\r\r\n\r\r\n### Data 조회\r\r\n\r\r\nCold - max cold data 기준 왼쪽을 조회합니다.\r\r\n![Trino_20.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino20.png)\r\r\n\r\r\nHot - max cold data 기준 오른쪽을 조회합니다.\r\r\n![Trino_21.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino21.png)\r\r\n\r\r\n### Data Join / Union\r\r\n\r\r\n집계의 경우 toMap과 id 값을 이용해 Join 합니다.\r\r\n![Trino_22.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino22.png)\r\r\n\r\r\n단순 조회의 경우 stream.concat으로 Union 합니다.\r\r\n![Trino_23.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino23.png)\r\r\n\r\r\n# 성능 테스트\r\r\n\r\r\n## 환경\r\r\n\r\r\n* DataQuery 스펙: c2m8 * 3\r\r\n* DataQuery 데이터는(log_date, appKey) 파티셔닝 되어 있고\r\r\n    * 참고 \\*partition = RDBMS의 index 와 유사. parquet 가 저장된 경로를 의미\r\r\n        ![Trino_24.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino24.png)\r\r\n* MySQL 데이터는 일 단위로 파티셔닝되어 있습니다.\r\r\n* MySQL 데이터는 log\\_time, appkey 각각의 인덱스와 (log\\_time, appkey) 복합 index 가 적용되어 있습니다.\r\r\n\r\r\n## 데이터 조회\r\r\n\r\r\n이슈 대응 등의 이유로 개발자가 쿼리 엔진에 자주 질의하는 **일반 쿼리**와 서비스에서 사용하는 **서비스 쿼리**로 구분하여 테스트했습니다.\r\r\n\r\r\n### 일반 쿼리\r\r\n\r\r\n단순한 select \\* 조회는 mysql이 7배가량 빠르고, count 등의 집계 함수가 포함된 쿼리는 DataQuery가 적게는 4배에서 6배가량 빠른 양상을 보였습니다.\r\r\nTrino + Parquet 조합은 열 기반 데이터 포맷으로 인한 행 조회의 비효율성, Trino의 쿼리 플래닝과 file fetch에서의 오버헤드로 인해 단순한 행 조회가 느리기 때문입니다.\r\r\n\r\r\n| 쿼리 | dataquery | mysql |\r\r\n| --- | --------- | ----- |\r\r\n| **단순** 조회 (select \\* limit 500) | 1 s 151 ms | 148 ms |\r\r\n| **count** 조회 (select count(\\*) 한 달 | 8 s 957 ms | 30.987 s |\r\r\n| filter - appkey \\& log\\_time **행 조회** | 1 s 323 ms | 393 ms |\r\r\n| filter - appkey \\& log\\_time **count** | 349 ms | 14.662 s |\r\r\n| group by - appkey 하루 | 814 ms | 2.385 s |\r\r\n| group by - appkey 한 달 | 18 s 530 ms | 2m 15s 538ms |\r\r\n\r\r\n### NHN AppGuard 서비스 쿼리\r\r\n\r\r\nDataQuery가 전반적으로 10배 정도 빨랐습니다.\r\r\n이상 행위 탐지 현황의 한 달치 데이터는 MySQL에서 30분 이상 소요되어 조회할 수 없었지만 DataQuery는 36초만에 조회하였습니다.\r\r\n\r\r\n| 쿼리 | dataquery | mysql |\r\r\n| --- | --------- | ----- |\r\r\n| 이상행위 탐지현황 - limit 50 하루 | 1 s 696 ms | 9.676s |\r\r\n| 이상행위 탐지현황 - limit 50 한 달 | 6 s 468 ms | 6m 19s 459ms |\r\r\n| 이상행위 탐지현황 report - 하루 | 7.06s | 21s 890ms |\r\r\n| 이상행위 탐지현황 report - 한 달 | 36.81s | **조회 불가(30분 이상)** |\r\r\n| 로그 조회 - 하루 | 1 s 531 ms | 7s 264ms |\r\r\n| 로그 조회 - 한 달 | 5 s 728 ms | 5m 58s 381ms |\r\r\n\r\r\n### Parquet 크기별 비교\r\r\n\r\r\nappkey로 파티션 되기 때문에 appkey별 로그 양이 달라 로그 개수에 따른 성능 차이를 비교해 보았습니다. 로그 수 기준 중위의 appkey까지도 MySQL이 더 빠른 양상을 보였습니다. 2-300ms가량의 차이를 보이는 만큼 로그가 적은 사용자 입장에서는 데이터가 없는데 굼뜨다는 느낌을 받을 수 있습니다. 이에 반해 로그 수가 평균을 넘어가면 MySQL은 30초가 넘어가는 응답을 보여 콘솔에서 서비스하기에 어려운 반응 속도를 보입니다.\r\r\n\r\r\n| 대시보드 조회 쿼리 | DataQuery | MySQL |\r\r\n| ---------- | --------- | ----- |\r\r\n| 데이터 없음 | 267 ms | 102 ms |\r\r\n| 최소 | 365 ms | 100 ms |\r\r\n| 중위 | 610 ms | 168 ms |\r\r\n| 평균 | 505 ms | 34 s 24 ms |\r\r\n| 최대 | 15s 85 ms | 10 m 23 s 982 ms |\r\r\n\r\r\n## 성능 테스트 결론\r\r\n\r\r\n1. 행 전체 조회, 데이터가 적은 경우는 MySQL이 빠르다.\r\r\n    1. 100ms VS 500ms의 차이 → **참을만하다.**\r\r\n2. 집계 조회, 데이터가 많은 경우에는 DataQuery가 빠르다.\r\r\n    1. 수십 초 VS 수 분 차이 → **참을 수 없다.**\r\r\n\r\r\n# 결과\r\r\n\r\r\n## 좋아졌나요?\r\r\n\r\r\n1. 이상 행위 탐지 현황의 30일치 데이터를 조회하지 못하던 고객이 이제 조회할 수 있게 되었습니다.\r\r\n2. 2024년 초 공개한 NHN AppGuard public api는 MySQL로는 30분 이상 소요되어 개발이 어려웠는데, DataQuery를 통해 7초 이내로 조회하여 개발할 수 있었습니다.\r\r\n3. 내부 집계 시간이 38m36s → 22m16s로 약 43% 개선했습니다.\r\r\n4. mysql에서의 집계로 인한 slow query가 제거되어 일 배치로 인한 서비스의 영향성이 없어졌습니다.\r\r\n5. 집계 연산이 빨라져서 집계 데이터의 종류를 늘리는 것에 부담이 없어졌습니다.\r\r\n6. 스토리지 비용 감소로 데이터 저장 기간을 60일에서 1년으로 늘렸습니다.\r\r\n\r\r\n## 나쁜 점은 없나요?\r\r\n\r\r\n1. 대시보드의 기본 응답 속도가 300ms 정도 느려졌습니다.\r\r\n2. tier down 실패 시 집계, 미터링 등에 영향을 주기 때문에 모니터링 요소가 늘어났습니다.\r\r\n3. DataQuery와 OBS 비용이 추가되었습니다. (대략 100만 원/월)\r\r\n\r\r\n## 앞으로 해야 할 것이 있을까요?\r\r\n\r\r\n1. 일 단위 tier down을 시간 단위로 변경하는 것을 고민하고 있습니다.\r\r\n2. 고객 로그 수에 따라 적절한 쿼리 엔진을 사용하도록 최적화하는 부분에 대해 고민하고 있습니다.\r\r\n\r\r\n\r\r\n\r\r\n이상 NHN AppGuard에 Trino를 적용해 본 과정과 결과에 대해 정리하였습니다. 도움이 되셨길 바라며, 긴 글을 읽어 주셔서 감사합니다. \r\r\n\r\r\n[![NHN Cloud_meetup banner_footer_gray_202408_900.png](https://image.toast.com/aaaadh/real/2025/techblog/NHN%20Cloudmeetup%20bannerfootergray202408900.png)](https://www.nhncloud.com/kr)",
    "reviews": [],
    "syllabus": [],
    "link": "https://meetup.nhncloud.com/posts/391",
    "pubDate": "Tue, 04 Mar 2025 02:22:40 GMT",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 10,
    "imageUrl": "",
    "title": "지각하지 않던 사람들",
    "description": "딸을 학교에 보내고 돌아오며 저의 학창 시절이 떠올랐습니다.\n인생을 더 살면서 사소해 보이는 작은 약속을 잘 지키는 것이 얼마나 중요한지 깨닫게 되었습니다.\n어쩌면 아내의 이런 모습들이 저에게 좋은 영향을 끼친 것 아닐까?\n그럼에도 불구하고 최근 몇 년 간 약속 시간에 늦은 적이 몇 번 있음을 고백합니다.\n다시 회사에 간다면 걱정되는 한 가지는 바로 이 출근 시간입니다.\n한 편으로 몇 년 동안 한 번도 지각하지 않던 동료들도 떠오릅니다.\n\n함께 읽으면 좋은 글:\n가장 행복했던 출근길\n출근길의 강제 독서",
    "reviews": [],
    "syllabus": [],
    "link": "https://jeho.page/essay/2025/03/06/time-to-work.html",
    "pubDate": "2025-03-06T02:54:00.000Z",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 11,
    "imageUrl": "",
    "title": "Try The New Toolbox App 2.6 EAP With Remote Development Support",
    "description": "With the latest update, the Toolbox App now supports remote development, allowing you to manage your JetBrains tools and projects both locally and on remote servers. This allows you to connect to cross-platform hosts, including Windows, macOS, and Linux, and use integrated OpenSSH for secure and customizable SSH connections. You can download the latest Toolbox […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/toolbox-app/2025/03/try-the-new-toolbox-app-2-6-eap-with-remote-development-support/",
    "pubDate": "Thu, 06 Mar 2025 10:45:29 +0000",
    "creator": "Ivan Kuzmin",
    "categories": [
      "jetbrains-toolbox",
      "toolbox-app"
    ]
  },
  {
    "id": 12,
    "imageUrl": "",
    "title": "Visual Studio 17.12의 디버거 및 진단 업데이트",
    "description": "No description available",
    "reviews": [],
    "syllabus": [],
    "link": "https://jacking75.github.io/VS_20250309/",
    "pubDate": "Sun, 09 Mar 2025 00:00:00 +0900",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 13,
    "imageUrl": "",
    "title": "AI Assistant Comes to Kotlin Developers in Android Studio",
    "description": "Kotlin developers can now enhance their workflows in Android Studio with the new JetBrains AI Assistant plugin, which is now available in Beta. This plugin offers AI-powered coding assistance, including code suggestions, AI-driven explanations, refactorings, commit message generation, and more – all within Android Studio. Backed by large language models (LLMs) from both JetBrains and […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/ai/2025/03/ai-assistant-comes-to-kotlin-developers-in-android-studio/",
    "pubDate": "Mon, 10 Mar 2025 14:34:32 +0000",
    "creator": "Anna Maltseva",
    "categories": [
      "ai-assistant",
      "android-studio",
      "jetbrains-ai",
      "kotlin"
    ]
  },
  {
    "id": 14,
    "imageUrl": "",
    "title": "대출 이자 줄이는 3가지 방법",
    "description": "금리인하요구권부터 대환대출까지 개념 정리",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.toss.im/article/loan-101-interest-rate",
    "pubDate": "Fri, 07 Mar 2025 01:03:00 GMT",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 15,
    "imageUrl": "",
    "title": "토스페이 3월 할인 이벤트와 쿠폰 혜택 총정리",
    "description": "지그재그, GS25, 알리익스프레스 할인·적립 쿠폰까지, 토스페이 2025년 3월 혜택 확인하기",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.toss.im/article/tosspay-2025-03",
    "pubDate": "Wed, 05 Mar 2025 01:11:00 GMT",
    "creator": "Unknown",
    "categories": []
  }
]