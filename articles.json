[
  {
    "id": 1,
    "imageUrl": "",
    "title": "MPS 2025.1 Is Out!",
    "description": "MPS 2025.1 allows the build language to serve as a target for code generation. This version also introduces visual and performance enhancements to the Project tool window’s Logical view, several useful improvements to the UI, and numerous platform updates. DOWNLOAD MPS 2025.1 What’s new Let’s check out all the new features waiting for you in […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/mps/2025/05/mps-2025-1-is-out/",
    "pubDate": "Wed, 14 May 2025 11:55:25 +0000",
    "creator": "Vaclav Pech",
    "categories": [
      "releases",
      "release"
    ]
  },
  {
    "id": 2,
    "imageUrl": "",
    "title": "ReAct 에이전트 프레임웍 내부 코드 구조 개발해보기",
    "description": "ReAct(Reasoning and Acting) 에이전트 구조는 대형 언어 모델(LLM)을 기반으로 도구 호출 기능을 통합한 지능형 에이전트 시스템을 구현하는 설계 방식이다. 사용자의 지시를 추론하고 필요한 경우 외부 도구를 호출하여 목표를 달성하는 능력을 지니며, 최근 AutoGPT, BabyAGI, Manus 등 다양한 오픈소스 프로젝트에서 채택되고 있다. 이 글에서는  ReAct 에이전트 프레임웍 내부 코드 구조를 직접 개발해본다. 아울러, ReAct 에이전트의 문제점들을 살펴보고 솔류션을 생각해본다. \n\n\n\n\nReAct Agent 구조(AI Agents Crash Course—Part 10 (With Implementation)\n\nReAct 구조 \nReAct 시퀀스 처리 구조는 LLM 기반 에이전트가 사고(Think), 행동(Act), 관찰(Observe), 결론(Final)의 단계로 사용자 질의에 응답하는 체계적 프로세스이다. 이 구조는 복잡한 문제 해결을 위해 LLM이 도구와 상호작용하면서 점진적으로 정답을 유도해내도록 설계되었다.\n다음은 해당 코드에서 구현된 ReAct 시퀀스의 흐름이다.\n\n\nThink\n\n\n\nAct\n\n필요하다고 판단되면 Act: ToolName[Input] 또는 Act: ToolName(Input) 형식으로 도구 호출을 지시한다. 이 지시문은 정규표현식으로 감지되어 실제 도구 실행이 트리거된다.\nObserve\nObserve: 접두사를 붙여 기록된다. 이 결과는 이후 컨텍스트에 포함되어 다음 LLM 호출의 입력으로 사용된다.\nFinal\nFinal Answer: 형식으로 최종 응답을 제공한다. 이는 루프를 종료시키는 조건이기도 하며, 에이전트의 실행 결과로 사용자에게 출력된다.\n\n\n\n\n이러한 시퀀스를 통해 LLM은 단순히 한 번에 답변하는 것이 아니라, 도구를 여러 번 사용하고 그 결과를 반영하며 점진적으로 정확한 응답에 도달한다.\nReAct 에이전트 내부 코드 구현해보기\n앞서 언급된 개념을 고려해 ReAct 에이전트의 핵심적인 코드만 구현해 본다. 다음과 같이 관련 라이브러리를 설치한다.\npip install langchain \n다음과 같이 코드를 구현한다. \n\nimport re, os\nfrom langchain.tools import Tool\nfrom langchain_community.tools.tavily_search import TavilySearchResults\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.schema import HumanMessage\nfrom dotenv import load_dotenv\n\n\nload_dotenv()\n\n\n# Calculator function\ndef calculator(input_str: str) -> str:\n    try:\n        result = eval(input_str)\n        return str(result)\n    except Exception as e:\n        return f\"Error: {e}\"\n\n\ndef FireCrawlResults(max_results=3, search_type=\"web\"):\n    from langchain_community.tools.fire_crawl import FireCrawlResults\n    return FireCrawlResults(max_results=max_results, search_type=search_type) # TBD\n\n\n# Initialize tools\ntools = [\n    Tool(\n        name=\"Calculator\",\n        func=calculator,\n        description=\"Evaluates mathematical expressions. Input should be a valid Python expression.\"\n    ),\n    TavilySearchResults(max_results=3, search_type=\"web\"),\n    # FireCrawlResults(max_results=3, search_type=\"web\"),\n]\n\n\n# Function to extract tool prototype info\ndef get_tools_info(tools):\n    info_list = []\n    for tool in tools:\n        # Try to get function signature if possible\n        if hasattr(tool, \"func\"):\n            proto = f\"{tool.name}(input: str)\"\n        else:\n            proto = f\"{tool.name}(input: str)\"\n        desc = getattr(tool, \"description\", \"No description.\")\n        info_list.append(f\"- {proto}: {desc}\")\n    return \"\\n\".join(info_list)\n\n\n# Initialize the language model\nllm = ChatOpenAI(temperature=0, model=\"gpt-4\", max_tokens=4000)\nanswer_validation_llm = ChatOpenAI(temperature=0, model=\"gpt-4-turbo\", max_tokens=4000)\n\n\n# Prompt template for ReAct\nprompt_template = \"\"\"\nInstruction: {instruct}\nIMPORTANT: If you do not know the answer, do not use 'Final Answer', just say 'I don't know'.\n\n\nTools you can use:\n{tools}\n\n\nContext:\n{context}\n\n\nQuery:\n{query}\n\n\nYou should follow the ReAct pattern:\n- Think: Reason about the question or next step.\n- Act: If needed, use a tool in the format Act: <tool>[<input>].\n- Observe: Note the result of the action.\n- Final: Give the final answer in the format Final Answer: <answer>.\n\"\"\"\n\n\nanswer_validation_prompt = \"\"\"\nQuestion: {question}\nAnswer: {answer}\nIs the answer relevant and correct for the question? Reply only with \"yes\" or \"no\" and a short reason.\n\"\"\"\n\n\nclass ReActAgent:\n    def __init__(self, llm, tools, prompt_template):\n        self.llm = llm\n        self.tools = {tool.name: tool for tool in tools}\n        self.prompt_template = prompt_template\n        self.tools_info = get_tools_info(tools)\n\n\n    def validate_answer(self, question, answer):\n        prompt = answer_validation_prompt.format(question=question, answer=answer)\n        messages = [HumanMessage(content=prompt)]\n        output = answer_validation_llm(messages)\n        response = output.content.strip().lower()\n        return response.startswith(\"yes\"), response\n\n\n    def run(self, input_query: str):\n        history = []\n        while True:\n            prompt = self.prompt_template.format(\n                instruct=\"Answer the question in detail using ReAct reasoning.\",\n                tools=self.tools_info,\n                context=\"\\n\".join(history),\n                query=input_query\n            )\n            messages = [HumanMessage(content=prompt)]\n            output = self.llm(messages)\n            response = output.content.strip()\n            history.append(response)\n\n\n            # Check for Final Answer\n            final_match = re.search(r\"Final Answer:\\s*(.*)\", response, re.IGNORECASE)\n            if final_match:\n                answer = final_match.group(1)\n                # is_valid, validation_msg = self.validate_answer(input_query, answer) # TBD. 실제 react 코드 확인.\n                # if is_valid:\n                return answer\n\n\n            # Detect action\n            action_match = re.search(r\"Act:\\s*(\\w+)[\\[\\(](.*)[\\]\\)]\", response)\n            if action_match:\n                action_name = action_match.group(1)\n                action_input = action_match.group(2)\n                print(f\"Action detected: {action_name} with input: {action_input}\")\n\n\n                tool = self.tools.get(action_name)\n                if not tool:\n                    history.append(f\"Observe: Unknown tool: {action_name}\")\n                    continue\n                action_input = action_input.replace(\"'\", \"\").replace('\"', \"\")   \n                result = tool.run(action_input)\n                history.append(f\"Observe: {result}\")\n            else:\n                # If no action and no final answer, just continue (could be Think step)\n                continue\n\n\nagent = ReActAgent(llm=llm, tools=tools, prompt_template=prompt_template)\n\n\ndef test():\n    query = \"What is the result of 12 * (3 + 4)?\"\n    result = agent.run(query)\n    print(result)\n\n\n    query = \"What is the capital of France?\"\n    result = agent.run(query)\n    print(result)\n\n\n    query = \"In web, What is Taewook kang's paper about Geo BIM using BIM and GIS?\"\n    result = agent.run(query)\n    print(result)\n\n\ndef main():\n    print(\"ReAct Agent is ready to use.\")\n    print(\"Available tools:\")\n    for tool in agent.tools_info.split(\"\\n\"):\n        print(tool)\n\n\n    # test()\n\n\n    print(\"\\nInteractive mode:\")\n    while True:\n        query = input(\"Enter your query (or 'exit' to quit): \")\n        if query.lower() == \"exit\":\n            break\n        result = agent.run(query)\n        print(result)\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n이 코드는 ReAct 시퀀스를 중심으로 구성되어 있다. ReAct란 LLM이 단순한 질의응답을 넘어서서, 생각하고 도구를 사용하고 그 결과를 바탕으로 다시 추론한 뒤 최종적인 답을 내리는 일련의 추론 패턴이다. 이 흐름은 크게 네 단계로 나뉜다. \n첫째, Think 단계에서는 주어진 질문에 대해 어떻게 접근할지를 LLM이 서술적으로 사고한다. 둘째, Act 단계에서는 필요하다고 판단한 도구를 지정된 형식으로 호출한다. 이때 Act: ToolName[Input] 형식을 사용한다. 셋째, Observe 단계에서는 실행된 도구의 결과를 받아 LLM의 다음 추론에 포함될 수 있도록 기록한다. 넷째, Final 단계에서는 Final Answer: 답변 형식으로 최종 결론을 도출한다.\n이러한 시퀀스를 실제로 구현하기 위해 코드에서는 특정 정규표현식을 사용하여 각 단계를 감지하고 분기 처리한다. 예를 들어, Act 단계는 Act:라는 키워드를 통해 감지되고, 대응되는 도구 이름과 입력값이 추출된다. 대응되는 도구가 존재하면 해당 함수나 객체의 run 메서드를 호출하여 결과를 얻고, 이를 Observe로 기록하여 다음 프롬프트 생성 시 문맥으로 전달한다. Final Answer가 감지되면 그 값을 최종 출력으로 반환하면서 루프를 종료한다.\n코드는 먼저 환경변수를 불러오고, 수학 계산용 calculator 함수와 웹 검색용 Tavily 도구를 정의하고 tools 목록에 등록한다. 각 도구는 Tool 객체로 구성되며, name, func, description 속성을 갖는다. 이 도구들의 인터페이스 정보는 get_tools_info 함수를 통해 LLM 프롬프트에 전달할 수 있는 형식으로 변환된다.\nReActAgent 클래스는 핵심 로직을 담당한다. 생성자에서는 도구를 이름으로 접근 가능하도록 딕셔너리 형태로 구성하며, 프롬프트 템플릿에 포함할 도구 설명을 자동으로 생성한다. run 메서드는 LLM과의 대화를 이끄는 루프이다. 사용자의 입력 쿼리를 바탕으로 Think부터 Final 단계까지의 응답을 순차적으로 생성하고, 도구 호출이 필요한 경우 자동으로 감지하여 실행한다.\nLLM은 ChatOpenAI 클래스를 통해 초기화되며, 주 모델과 검증용 모델이 따로 구성된다. 현재 코드는 검증 부분이 주석 처리되어 있어 정답 검증은 수행되지 않지만 validate_answer 메서드는 존재한다. 해당 메서드는 question과 answer를 받아 프롬프트에 삽입하고 gpt-4-turbo 모델로부터 응답을 받아 yes 또는 no 여부와 사유를 반환한다.\n\n\n\n\n\n\nmain 함수는 인터랙티브한 사용자 입력을 받아 ReActAgent를 호출하는 실행 루틴이다. 사용자가 exit이라고 입력할 때까지 질의를 받고 응답을 출력하는 루프를 구성한다. 이로써 ReActAgent는 반복적인 질의응답 상황에서도 도구를 활용하여 논리적 사고 과정을 수행하고, 외부 정보에 기반한 정답을 도출할 수 있도록 설계되어 있다.\n주요 문제 유형\nReAct 기반 에이전트는 구현 및 실전 적용 과정에서 여러 구조적 문제와 비효율이 발생한다. 이러한 문제 사례를 분석하고, 실제 커뮤니티에서 공유된 해결 전략과 함께 개선 방향을 확인해 본다.\n추론 오류\n\n에이전트가 잘못된 전제나 문맥에 기반하여 부적절한 도구를 선택하거나 오답을 도출하는 문제가 빈번히 발생한다. 이는 LLM의 한계와 프롬프트 설계 미비, 또는 이전 상태 정보의 왜곡에 기인한다.\n반복 및 루프 문제\n\n에이전트가 목표에 도달하지 못하고 동일한 행동을 반복 수행하는 루프에 빠지는 문제가 자주 발생한다. 이는 max_steps 제한이 없거나, 실패 판단 기준이 모호한 경우에 두드러진다.\n결과 검증 실패\n\n에이전트가 도출한 결과가 부정확하거나 무의미함에도 불구하고, 이를 최종 결과로 판단하고 종료되는 문제가 있다. 이는 정답 여부를 평가할 수 있는 검증 메커니즘의 부재 혹은 Verifier LLM의 오판 때문이다.\n지연 및 비용 문제\n\nReAct 구조는 추론 Think, 행동 Act, 검증 Verify 단계에서 각각 LLM 호출이 필요하므로 응답 지연이 누적되며, 고성능 모델 사용 시 비용 또한 급증하게 된다.\n상태 관리 실패\n\n에이전트가 이전 문맥을 적절히 유지하지 못하거나, 기억을 잘못 참조하여 추론에 실패하는 경우가 있다. 이는 memory overflow, context 길이 초과 등으로 인해 발생한다.\n해외 커뮤니티 보고 사례\nReddit, GitHub, Hacker News 등 해외 커뮤니티에서는 위 문제들이 반복적으로 보고되고 있다. 주요 사례는 다음과 같다\nr/React 에서는 Langchain의 늦은 React 에이전트 성능에 대한 문제가 제기된 적이 있다. 이런 사례는 수도 없이 많다.\nr/AutoGPT에서는 도구 호출 반복, final answer 오류 등 루프와 검증 문제를 다룬 글들이 다수 존재한다.\n\nr/MachineLearning에서는 hallucination 문제, tool selection 오류에 대한 토론이 있다\n\n이는 ReAct 구조의 본질적인 설계 한계와 관련되며, 이를 보완하기 위한 다양한 시도들이 커뮤니티에서 논의되고 있다\n해결 방안\nVerifier LLM의 도입\n\n추론 결과에 대해 별도의 고성능 LLM을 사용하여 정답 여부를 판단하도록 구성하는 방식이다 예를 들어 GPT 35 기반 ReAct 에이전트를 GPT 4 기반 Verifier로 보완하는 사례가 있다\nConfidence 기반 조건 실행\n\nLLM이 응답에 대한 신뢰도 confidence score를 함께 출력하도록 하고, 일정 기준 미만일 경우에만 검증자 호출 또는 재시도를 수행하는 방식이다\n행동 다양성 유도 및 페널티 적용\n\n같은 도구를 반복 호출하지 않도록 행동 선택 시 다양성을 보장하거나 페널티 기반 scoring 방식을 적용한다\n결과 품질 기반 Soft Fallback 적용\n\n결과가 일정 기준 미달일 경우 완료 실패 메시지를 출력하거나, 대체 응답을 제공하는 방식으로 흐름을 마무리한다\n도메인 기반 grounding 기법\n\n도메인 특화 지식을 embedding하거나 retriever를 통해 grounding context를 제공함으로써 hallucination을 감소시키는 방식이다\nLLM 처리 지연 보완을 위한 전략\nReAct 구조에서는 LLM을 여러 번 호출하는 구조로 인해 응답 시간이 증가하는 문제가 발생한다. 이를 해결하기 위한 보완 전략은 다음과 같다\n첫째, 동일한 LLM을 사용하는 것이 아니라 추론 단계는 경량 LLM을 사용하고 검증 단계는 고성능 LLM을 사용하는 방식으로 역할 분리를 통해 효율을 높이는 방안이 있다\n둘째, LLM의 confidence score를 이용하여 신뢰도가 충분히 높은 경우에는 검증 단계를 생략함으로써 전체 호출 횟수를 줄일 수 있다\n셋째, 여러 행동 중 하나를 선택할 때 prefetch 또는 batch decoding 방식을 사용하여 예측을 병렬적으로 수행하면 전체 응답 지연을 줄일 수 있다\n넷째, 반복되는 도구 호출에 대해서는 캐싱 메커니즘을 도입하거나 결과를 저장하여 재활용함으로써 불필요한 호출을 방지할 수 있다\n다섯째, 검증자 역할을 하는 LLM을 완전한 LLM이 아니라 룰 기반 평가기 또는 소형 모델로 대체하여 빠르게 판단하게 하는 방식도 고려할 수 있다\n코드 기반 구현 예시 요약\nReAct 기반 구조는 보통 다음 흐름으로 구성된다\n\n\n사용자 입력 수신\n\nLLM을 통해 행동 계획 수립 Think\n\n해당 도구 실행 Act\n\n결과 수신 후 Verifier를 통해 정답 여부 판단 Verify\n\n정답 시 종료, 실패 시 재시도 또는 fallback 처리\n\n\n이러한 구조는 Python 코드로 구현할 수 있으며, 각 함수는 다음과 같은 역할을 수행한다\n\n\nthink goal 행동 계획 생성\n\nact action 도구 실행 및 결과 수신\n\nverify result, goal 결과 검증\n\nrun goal 전체 흐름 통제 및 반복 로직 포함\n\n\n결론\nReAct 기반 에이전트는 고도의 자율성을 지닌 시스템이나, 구조적으로 여러 한계가 존재한다. 특히 결과 검증 실패, 반복 루프, hallucination, 비용 증가 문제는 실제 운영 및 서비스화에 있어 큰 장애 요인이 된다. 이를 해결하기 위해서는 검증자 LLM 도입, confidence 기반 흐름 제어, 도구 호출의 다양성 보장, grounding 및 fallback 전략이 함께 설계될 수 있다.\n\n\n부록: 보고서 형식 AI 에이전트 패턴\nReAct 에이전트는 Reasoning and Acting의 약어로, LLM이 툴과 상호작용하며 문제를 해결하는 패턴이다. 이 구조는 인간처럼 사고하고, 필요한 정보를 외부 도구에서 검색하거나 계산을 수행한 뒤, 최종적으로 응답을 생성한다. 이로 인해 복잡한 질의나 멀티스텝 추론이 필요한 경우에 적합한 패턴으로 여겨진다. 그러나 이러한 장점에도 불구하고, LLM이 여러 차례 호출되고 툴도 반복적으로 작동하므로 응답 시간이 느려지고, API 사용량 증가로 인해 비용이 상승하는 단점이 존재한다.\n한편 단순히 보고서를 생성하는 용도로 LLM을 사용하는 경우라면, 복잡한 Reasoning이나 여러 번의 외부 툴 호출은 필요하지 않다. 이때는 ReAct 에이전트를 사용하는 것이 오히려 비효율적이며, 불필요한 구조적 복잡성과 지연을 유발한다. 따라서 보고서 자동 생성이라는 목적에 최적화된 에이전트 구조는 단일 호출 기반 구조가 적합하다.\n\n\n\n\n이 구조는 Single-Shot LLM Invocation 패턴으로 명명된다. 이 방식은 LLM을 한 번만 호출하여 입력된 요구 사항에 맞는 보고서를 즉시 생성한다. 별도의 도구 호출이나 intermediate step 없이 하나의 잘 설계된 프롬프트를 중심으로 전체 작업이 이루어진다. 이 패턴은 속도가 빠르고, 처리 흐름이 단순하며, LLM API 호출 횟수를 최소화하므로 비용이 낮다. 특히 단일 보고서, 요약, 이메일 초안, 블로그 콘텐츠와 같은 목적에 적합하며, 사용자의 입력 내용에 따라 문서 포맷이나 톤을 조정하는 것만으로 충분한 성능을 발휘한다.\n단일 호출 구조는 별도의 외부 툴이나 체인을 필요로 하지 않기 때문에 LangChain이나 ReAct 구조 없이도 Python 코드 수준에서 간단히 구현이 가능하다. 예를 들어, 사용자가 요구사항을 입력하면 그에 맞는 템플릿 기반 프롬프트를 작성하고, 이를 LLM에 전달해 한 번에 결과를 반환받는 방식이다. 이러한 프롬프트에 보고서의 형식, 어조, 길이 등을 명시하면, 결과물의 일관성과 품질도 충분히 확보할 수 있다.\n이 외에도 필요에 따라 Plan-and-Write 패턴을 고려할 수 있다. 이 패턴은 먼저 전체 문서의 개요를 작성한 뒤, 각 항목에 따라 내용을 생성하는 방식이다. 좀 더 명확한 구성과 섹션 구분이 필요할 때 유용하다. 통계 수치나 외부 데이터를 포함해야 할 경우에는 Toolformer와 같이 선택적으로 툴을 호출하는 패턴을 도입할 수 있다. 마지막으로 문서가 일정한 형식을 유지해야 하거나 후처리를 자동화해야 할 때는 Structured Prompting 패턴을 사용할 수 있으며, JSON 또는 Markdown 형식으로 문서 구조를 고정하여 일관성을 높인다.\n\n\n\n\n\n\n결론적으로, 보고서 자동 생성처럼 복잡한 추론이나 외부 툴 연동이 불필요한 작업에는 ReAct와 같은 다단계 에이전트 구조는 적합하지 않다. 대신 단일 LLM 호출로 작업을 완료하는 Single-Shot 방식이 가장 효율적이며, 프롬프트 최적화만으로 높은 품질의 결과를 얻을 수 있다. \n부록: AI 에이전트 오케스트레이션\n사용자 질문에 따라 적절한 에이전트 패턴을 선택하기 위해서는 입력의 목적과 복잡성을 빠르게 분류할 수 있는 에이전트 오케스트레이션 메커니즘이 필요하다. 다음 의사코드는 솔류션을 보여준다. \n\ndef classify_input(user_input):\n    if \"보고서\" in user_input or \"작성해\" in user_input:\n        return \"simple_generation\"\n    if \"json\" in user_input or \"표로\" in user_input:\n        return \"structured_output\"\n    if \"비교해\" in user_input or \"어떤게 더 나아\" in user_input:\n        return \"tool_assisted\"\n    if \"계산\" in user_input or any(op in user_input for op in \"+-*/\"):\n        return \"tool_assisted\"\n    return \"multi_step_reasoning\"\n\n\n\ndef classify_input(user_input):\n    result = rule_based_classifier(user_input)\n    if result == \"unknown\":\n        return llm_classifier(user_input)\n    return result\n\n\n여기서는 classify_input 함수가 사용되며, 이 함수는 사용자의 입력 문장을 분석하여 어떤 처리 패턴이 적합한지를 판단하는 역할을 수행한다. 하지만 이 함수 자체가 느리거나 LLM 호출을 과도하게 유발하면 전체 시스템의 응답성이 떨어지므로, 이를 빠르게 실행할 수 있는 설계가 중요하다.\nclassify_input을 빠르게 실행하기 위한 방법은 크게 세 가지로 구분된다. 첫 번째는 경량 LLM을 사용하는 방식이다. 이 방법은 GPT-3.5 Turbo, Claude Instant, DistilBERT 등의 속도가 빠른 경량 언어 모델을 활용하여 입력을 분류하는 방식이다. 프롬프트는 미리 정의된 범주 중에서 입력이 어떤 태스크 유형에 해당하는지를 선택하게 하며, 이에 따라 적절한 패턴으로 연결된다. 이 방식은 유연하고 적응력이 높지만, 여전히 LLM 호출이기 때문에 응답 속도에 영향을 줄 수 있다. 그럼에도 불구하고 ReAct 등 복잡한 구조보다는 훨씬 빠르고 저비용이다.\n두 번째 방식은 규칙 기반 분류 방식이다. 이는 키워드 기반으로 입력 문장을 빠르게 분류하는 방법으로, 예를 들어 ‘보고서’, ‘작성해’ 등의 단어가 포함되어 있으면 단순 생성 태스크로 간주하고, ‘비교’, ‘계산’, ‘표로’ 등의 단어가 있으면 툴 기반 또는 구조화된 출력을 요구하는 태스크로 분류하는 것이다. 이 방식은 매우 빠르며, 수 마이크로초 이내에 실행이 가능하고, 비용도 발생하지 않는다. 그러나 복잡한 문장이나 여러 의미가 섞인 문장에 대해서는 정확하게 분류하지 못할 위험이 있다.\n세 번째는 하이브리드 방식이다. 이 방식은 앞서 언급한 규칙 기반 분류기를 우선 사용하고, 그 결과가 불확실하거나 unknown일 경우에만 경량 LLM을 호출하여 보완 분류를 수행한다. 이 구조는 속도와 정확도 사이의 균형을 잡기 위해 매우 현실적인 대안이며, 실제로 OpenAI API 기반 에이전트나 LangChain의 라우팅 모듈에서도 유사한 방식이 채택된다. 구현은 상대적으로 복잡할 수 있으나, 전체 시스템의 응답성과 품질을 함께 유지할 수 있는 방법이다.\n\n\n\n\n\n결론적으로 classify_input 함수를 빠르게 실행하기 위해서는 입력의 유형과 빈도에 따라 최적화 전략을 선택해야 한다. 단순한 텍스트 입력이 반복되는 시스템에서는 규칙 기반 분류기로 충분하며, 복합 입력이 자주 등장하는 환경에서는 하이브리드 분류기를 설계하는 것이 이상적이다.",
    "reviews": [],
    "syllabus": [],
    "link": "http://daddynkidsmakers.blogspot.com/2025/05/react.html",
    "pubDate": "2025-05-18T05:02:00.000Z",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 3,
    "imageUrl": "",
    "title": "디아2 요르단의 반지 주음",
    "description": "레더 악몽 안다리엘 잡다 나왔습니다.\n안다리엘이 이것저것 잘 주네요\n거의 20년 플레이하는동안 처음 주워봤습니다. ㅎㅎ\n\n\n야만용사로 하는데 마법 아이템 발견 확율이 높지 않군요 \n100% 되는줄 알았는데 \n아무튼 잘나오네요",
    "reviews": [],
    "syllabus": [],
    "link": "http://serverdown.tistory.com/1318",
    "pubDate": "Wed, 14 May 2025 12:10:55 +0900",
    "creator": "SIDNFT",
    "categories": [
      "게임"
    ]
  },
  {
    "id": 4,
    "imageUrl": "",
    "title": "토스, 2025년 1분기 연결 영업수익 5,679억 원…전년 동기 대비 29.1% 성장",
    "description": "연결 영업이익 709억 원, 연결 당기순이익 489억 원으로 흑자 기조 이어가",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.toss.im/article/251Q",
    "pubDate": "Thu, 15 May 2025 07:00:00 GMT",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 5,
    "imageUrl": "",
    "title": "2025-05-17 (토) 개발일지 / 서버 죽음 / 개인정보처리방침",
    "description": "1. 죽은 웹서버 원인 파악\n일어나보니 웹서버가 죽어있었습니다.\n누가 /?XDEBUG_SESSION_START=phpstorm\n이런식으로 호출했나봅니다.\nphpstorm 의 취약점을 노리는 걸까요\n제 express 서버는 없는 파일에 대한 예외처리가 없어서 프로그램이 종료되었습니다.\nENOENT: no such file or directory, open '/home/gunil/pto/node-sidnft-firebase/pi4server/public/?XDEBUG_SESSION_START=phpstorm' \n    path: \"/home/gunil/pto/node-sidnft-firebase/pi4server/public/?XDEBUG_SESSION_START=phpstorm\", \n syscall: \"open\", \n   errno: -2, \n    code: \"ENOENT\"\n \n\n\n아래에 catch 가 있지만 이곳으로 예외가 오진 않습니다.\nfs.createReadStream\n함수는 await 로 실행되는게 아니라서 다른 분기를 타는 것이겠지요\n전용 에러 처리함수인 on(\"error\" ~~~) f를 추가로 넣었습니다.\n \n2. 신규 앱 심사  거부 사유 체크\n\n\n오래전에 웹 페이지를 만들고 관리를 안했는데\n개인정보처리방침 부분은 날림으로 만들었습니다..\n\" 개인정보처리방침\" 이라는 문구가 표시되어야하고 ....\n타이틀에도 표시하라고 본문에도 영어/한국어 다 적었습니다.\n타이틀 수정은 자바스크립트로\ndocument.title = \"~~~\";\n 이런식으로 하면 바로 바꼈습니다.\n추가로 혹시나 해서 개인정보처리방침 URL 도 수정해서 다시 검토 신청 했습니다.",
    "reviews": [],
    "syllabus": [],
    "link": "http://serverdown.tistory.com/1324",
    "pubDate": "Sat, 17 May 2025 13:03:56 +0900",
    "creator": "SIDNFT",
    "categories": [
      "프로그래밍/개발메모",
      "Express",
      "업데이트",
      "작업일지"
    ]
  },
  {
    "id": 6,
    "imageUrl": "",
    "title": "ReSharper Comes to Microsoft Visual Studio Code: Public Preview Now Open",
    "description": "For the past 20 years, ReSharper has been the legendary .NET productivity tool that changed how millions of developers explore, write, and improve their code in Microsoft Visual Studio. Today, we’re bringing this transformative experience to a new environment. ReSharper is now available as an extension for Visual Studio Code. Whether VS Code is your […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/dotnet/2025/05/19/resharper-comes-to-microsoft-visual-studio-code/",
    "pubDate": "Mon, 19 May 2025 11:10:42 +0000",
    "creator": "Sasha Ivanova",
    "categories": [
      "net-tools",
      "news",
      "releases",
      "resharper",
      "eap",
      "lsp",
      "public-preview",
      "release",
      "resharper-for-vs-code",
      "visual-studio-code",
      "vs-code"
    ]
  },
  {
    "id": 7,
    "imageUrl": "",
    "title": "미즈노 배드민턴화 정리",
    "description": "웨이브 팡2\n\n\n웨이브팡 EL2\n\n\n스텔스 네오2\n\n\n클로 네오2\n\n\n클로3\n\n\n65z3\n\n\n65z4",
    "reviews": [],
    "syllabus": [],
    "link": "https://hodolman.tistory.com/75",
    "pubDate": "Sun, 18 May 2025 19:33:54 +0900",
    "creator": "호돌맨",
    "categories": [
      "우당탕탕 대모험"
    ]
  },
  {
    "id": 8,
    "imageUrl": "",
    "title": "Qodana’s New Insights Dashboard Provides Cross-Project Code Analysis Data",
    "description": "Managing code quality can be a challenge in itself, even without the complexity of multiple projects. Thanks to our new Insights dashboard you can now get a near-instant overview of the code quality and performance of all your projects whenever you need it, without having to constantly switch between projects. Get Qodana Who is it […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/qodana/2025/05/insights-dashboard-cross-project-code-analysis/",
    "pubDate": "Mon, 19 May 2025 19:20:34 +0000",
    "creator": "Kerry Beetge",
    "categories": [
      "releases",
      "code-quality",
      "dashboards",
      "qodana"
    ]
  },
  {
    "id": 9,
    "imageUrl": "",
    "title": "2025-05-16 (금) 개발일지",
    "description": "1. 앨릭서 시작\n영상과 버전이 달라서 명령어가 이상하게 동작했다.\n큰일이다.\n \n영상: https://www.youtube.com/watch?v=IiIgm_yaoOA&t=1578s\n\n\n\n영상의; 상황\n\n\n내 상태\n$ elixir -v \nErlang/OTP 27 [erts-15.2.7] [source] [64-bit] [smp:12:12] [ds:12:12:10] [async-threads:1] [jit:ns] \nElixir 1.18.3 (compiled with Erlang/OTP 25)\n \n설치 페이지에서 제공되는 버전\n설치페이지: https://elixir-lang.org/install.html#windows\n\n\niex 하면 프로그램가능한 상태가 되어야하는데 나는 추가 명령어를 오청받고 있다.\n컴터 재부팅하니 영상처럼 프로그램 가능한 상태로 돌아왔다.\n다행이다.\n \n \n \n \n2. 비트액스 홈페이지 개선\n기기별 가성비 추천을 해주려는데 아직은 보기 불편하다.\n해시레이트 / 소비전력 => 성능\n성능 / 가격 => 가성비\n이런식으로 표시해야겠다.\n가격이 중요하니 유저들보고 가격 넣으라고 하면 좋을꺼 같다.\n수정전 \n\n\n화면엔 안보이지만  가로로 스크롤도 표시되고 잇다.\n화면크기보다 큰 페이지가 표시되는거 같다.\n \n고친 후\n\n\n왜이케 비였냐...\n이상한 가로 스크롤 자꾸 생겨서 보기 안좋았다.\n페이지 시작할때 이거 두개를 넣어줘서 해결했는데 모든 사이트에 적용해야겠다.\n\n\n \n \n3. apps 의 모바일 표시가 이상하다.\n\n\n위에 비트액스랑 동일한 문제인데.\n같이 수정해줘야겠다.\n수정후:\n결과 페이지: https://apps.sidnft.com/\n \n수정후 영상: https://youtu.be/z5BdUTrJC8w\n\n\n\n1. 좌우 스크롤을 제거함 (화면 크기보다 큰 무언가가 있어서 제거했음)\n2. 모바일 해상도 대응\n완성도좀 높이자!",
    "reviews": [],
    "syllabus": [],
    "link": "http://serverdown.tistory.com/1323",
    "pubDate": "Fri, 16 May 2025 12:46:59 +0900",
    "creator": "SIDNFT",
    "categories": [
      "프로그래밍/개발메모",
      "개발일지"
    ]
  },
  {
    "id": 10,
    "imageUrl": "",
    "title": "🎉 Visual Studio 2022 v17.14 is now generally available!",
    "description": "We’re thrilled to announce the general availability of Visual Studio 2022 version 17.14! This release continues our mission to empower developers with faster, smarter, and more productive tools across all workloads. There is so much for developers to love in this release, so be sure to check out the release notes for the full list. […]\nThe post 🎉 Visual Studio 2022 v17.14 is now generally available! appeared first on Visual Studio Blog.",
    "reviews": [],
    "syllabus": [],
    "link": "https://devblogs.microsoft.com/visualstudio/visual-studio-2022-v17-14-is-now-generally-available/",
    "pubDate": "Tue, 13 May 2025 17:24:25 +0000",
    "creator": "Mads Kristensen",
    "categories": [
      "Accessibility",
      "Artificial Intelligence",
      "Debug",
      "Git",
      "GitHub Copilot",
      "Performance",
      "Productivity",
      "Visual Studio",
      "Agent Mode",
      "Debugging and Diagnostics",
      "Next Edits Suggestion"
    ]
  },
  {
    "id": 11,
    "imageUrl": "",
    "title": "토스, 국내 최초 ‘한도 높은 신용카드 찾기’ 전 카드사 입점 완료",
    "description": "금융소비자 선택 폭 넓어져",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.toss.im/article/card",
    "pubDate": "Thu, 15 May 2025 04:28:00 GMT",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 12,
    "imageUrl": "",
    "title": "프로세스를 촘촘하게 만드는 사람",
    "description": "최근에 쿠팡의 조직 문화에 대해 이야기를 나눌 기회가 있었다.\n쿠팡의 인재론은 한 축은 실적, 한 축은 가치관으로 평가한다.\n실적이 좋고 가치관이 훌륭한 사람은 스타(star),\n실적도 안 되고 가치관이 엉망인 사람은 개(dog)다.\n실적은 안 좋고 가치관이 잘 맞는 사람은 물음표(?)다.\n가장 문제는 실적이 좋지만 가치관이 안 맞는 사람이다.\n이런 사람은 독(poison)으로 분류한다.\n장기적으로 독을 밀어내고 물음표를 과감하게 기용할 수 있는 혜안이 필요하다.\n문화가 항상 앞서야 한다.\n회사에 핵심 가치가 필요한 이유다.\n쿠팡을 다녀본 적은 없지만, 각자가 경험한 조직들을 기준으로 이 스타(star), 개(dog), 물음표(?), 독(poison) 에 대해 나눴다.\n그러다 어떤 사람이 독(poison) 인가에 대한 질문이 나왔다.\n이에 대해 여러 이야기가 나왔지만, 나는 \"프로세스/제도를 더 촘촘하게 만드는 사람이 독인것 같다\" 는 이야기를 했다.\n바쁘게 일 하느라 저녁 식사를 제때 못하는 분들을 위해 회사가 김밥을 준비했다.\n\"저녁 식사 못하고 야근하신 분들은 김밥 드세요\" 라는 회사의 공지가 나왔다.\n일부의 사람이 30분 야근을 하면서 퇴근길에 이 김밥을 챙겨가기 시작했다.\n김밥의 양이 부족해서 원래 목적이였던 사람들은 여전히 제때 끼니를 챙기지 못했다.\n이후에는 김밥을 가져갈 수 있는 조건이 하나둘씩 생기기 시작했다.\n9시 이후 퇴근 하시는 분들만 가져갈 수 있습니다.\n김밥 수령하신 분들은 이름을 작성해주세요.\n대리 수령은 안됩니다.\n등등.\n하나둘씩 김밥을 먹을 수 있는 조건들이 촘촘하게 만들어지기 시작하니 이제는 진짜 김밥을 먹길 바랬던 대상자들도 먹지 않게 되었다.\n\"김밥을 먹으면 8시까지 무조건 야근 해야하는구나\"\n\"김밥 하나 먹으려고 너무 짜친다 그냥 안먹고 일 하련다\" 등등의 이유로 말이다.\n소수의 오남용 하는 사람들로 조직의 프로세스, 제도는 더 촘촘하게 만들어진다.\n그리고 촘촘하게 만들수록 조직은 제대로 굴러가기 힘들고 짜치는 조직이 되어간다.\n누군가는 이렇게 얘기할 수도 있다.\n\"아니 김밥 그거 얼마나 한다고 넉넉하게 준비하면 되지 뭐 이렇게 치사하게 구냐\" 라고.\n근데 김밥이라는건 조직에서 관리하는 일종의 리소스를 표현한 것 뿐이다.\n회사의 모든 리소스는 항상 제한된 상황에서 운영된다.\n아무리 필요한 사람이 있더라도 의도와 다르게 오남용하는 것까지 고려해서 충분한 리소스가 확보되어야만 모든 프로세스와 제도가 도입되어야하는 것인가?\n아무리 필요한 사람이 있더라도 그만큼의 리소스가 확보되지 않으면 도입을 못하는 것인가?\n그건 아닐 것이다.\n더 열정적으로 일을 하는 사람들이 있다면 그들을 위해 지원해야할 것들이 있다면 더 지원해야하고, 프로세스와 제도는 더 느슨하게, 더 자유롭게 활용할 수 있도록 해야한다.\n그렇지만 특정 몇 명으로 인해 프로세스와 제도가 계속해서 촘촘하게 만들어진다면 그들은 조직을 망치는 사람들로서 경계해야한다.\n\"기준이 모호하니깐 사람들이 프로세스를 악용한다\" 라는 이야기는 반은 맞지만 반은 맞지 않다.\n기준을 명확하게 만들려고, \"이럴때는 이렇게 하셔야 하고, 저럴때는 저렇게 하셔야 합니다\" 라는 형태로 프로세스가 계속해서 촘촘하게 만들어지는 것이 더 성과내기 좋은 조직이란 말인가?\n\"프로세스가 모호하다고 느껴질 때 그때 개인의 이득이 되는 선택을 하느냐, 전체에 이득이 되는 선택을 하느냐\"에 따라 프로세스가 더 촘촘해지기도 하고, 더 느슨해지기도 한다.\n프로세스가 모든 상황에 대해서 정확하게 가이드를 할 순 없다.\n프로세스가 촘촘할수록 개인별 역량과 도전은 제한받을 수 밖에 없다.\n프로세스 혹은 제도는 최소한의 기본을 가지고 있고,\n대부분의 가치판단이 모호할 때는 회사의 문화, 가치관에 따라 개인이 결정하는 것이 훨씬 더 좋다고 생각한다.\n결국 제도는 기본과 원칙에 충실하게 만들되, 문화, 가치관에 대한 교육에 좀 더 집중하는 편이 맞는 경우가 훨씬 많은 것 같다.",
    "reviews": [],
    "syllabus": [],
    "link": "https://jojoldu.tistory.com/829",
    "pubDate": "Tue, 20 May 2025 09:27:40 +0900",
    "creator": "향로 (기억보단 기록을)",
    "categories": [
      "생각정리",
      "배민",
      "스타트업",
      "인프런",
      "조직문화",
      "쿠팡"
    ]
  },
  {
    "id": 13,
    "imageUrl": "",
    "title": "이커머스와 홈쇼핑이 선택한 커머스 AI 솔루션 ‘에이플러스AI’: 버즈니 남상협 대표 인터뷰",
    "description": "이승환: 자기소개 부탁드립니다. 남상협: 버즈니 대표 남상협입니다. 여러 홈쇼핑을 한데 모아 보는 앱 ‘홈쇼핑모아’를 운영하고 있고요. 이를 운영하며 쌓아온 여러 커머스AI 기술을 B2B로 보급하고 있습니다. 바로 ‘에이플러스AI’라는 버즈니의 신규 AI 비즈니스인데요. 현재 론칭 1년 만에 CJ온스타일 등 홈쇼핑 및 주요 이커머스사 10곳에 커머스AI 기술 공급 계약을 체결했습니다. AI 비즈니스 부문은 작년에 10배 정도 성장했고, 올해도 […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://ppss.kr/archives/269388",
    "pubDate": "Thu, 15 May 2025 02:00:20 +0000",
    "creator": "리승환",
    "categories": [
      "IT",
      "마케팅",
      "스타트업",
      "인터뷰"
    ]
  },
  {
    "id": 14,
    "imageUrl": "",
    "title": "개발자의 장애 공유 문화",
    "description": "카카오에 처음 들어가서 놀랐던 또 한 가지는 장애를 공유하는 문화였습니다.\n작고 큰 장애들이 자주 발생했습니다.\n와, 이 사람들 특이한 사람들이네. 이런 건 살다 살다 처음 보는군.\n장애 공유 글에는 항상 좋아요가 많이 달렸습니다.\n자신의 얼간이 짓을 솔직하게 쓰면 쓸수록 좋아요가 더 많이 달렸습니다.\n원인과 후속 조치, 여전히 가시지 않는 의문점들에 대해 댓글로 논의하기도 했습니다만…\n자신이 발생시킨 장애를 전 직원들에게 공유한다는 것이 절대 쉬운 일이 아닙니다.\n아 오늘도 장애 공유 써야 되네, 젠장. 뭐 일하다 보면 장애 낼 수도 있는 거지.\n카카오에서보다 더 놀랐던 기억도 납니다.\nGitLab 장애.\nrm -rf로 프로덕션 데이터베이스 전체를 날려먹었던가?\n와, 진짜 미친 사람들이 여기 있었구나. 저걸 회사의 다른 동료들이 아무도 뭐라 하지 않는 건가? 아니, 어쩌면 의도적으로 저렇게 공유하기로 한 건가?\n\n함께 읽으면 좋은 글:\n서비스 텐션\n서버 비용을 아끼던 사람들 (feat. 카카오 옛날 이야기)\n카톡 서버 개발의 추억",
    "reviews": [],
    "syllabus": [],
    "link": "https://jeho.page/essay/2025/05/15/failure-sharing.html",
    "pubDate": "2025-05-14T17:30:00.000Z",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 15,
    "imageUrl": "",
    "title": "토스, Apple App Store에 토스페이로 간편결제 지원한다",
    "description": "토스페이로 편리하고 안전하게 Apple 서비스 구독 및 구입 가능해져",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.toss.im/article/appletosspay",
    "pubDate": "Fri, 16 May 2025 01:23:00 GMT",
    "creator": "Unknown",
    "categories": []
  }
]