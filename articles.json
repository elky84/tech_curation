[
  {
    "id": 1,
    "imageUrl": "",
    "title": "[MULTI] 절반만 성공한 실험, 엘든 링: 밤의 통치자",
    "description": "No description available",
    "reviews": [],
    "syllabus": [],
    "link": "https://bbs.ruliweb.com/news/board/11/read/2314",
    "pubDate": "Wed, 04 Jun 2025 16:12:50 +0900",
    "creator": "「RULIWEB」",
    "categories": [
      "리뷰"
    ]
  },
  {
    "id": 2,
    "imageUrl": "",
    "title": "IntelliJ IDEA 2025.1.2 Is Out!",
    "description": "IntelliJ IDEA 2025.1.2 has arrived with several valuable fixes. You can update to this version from inside the IDE, using the Toolbox App, or using snaps if you are a Ubuntu user. You can also download it from our website. Here are the most notable updates included in this version: To find out more details about the […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/idea/2025/06/intellij-idea-2025-1-2/",
    "pubDate": "Wed, 04 Jun 2025 14:08:58 +0000",
    "creator": "Maria Kosukhina",
    "categories": [
      "releases",
      "bug-fix-update",
      "intellij-idea-2025-1",
      "intellij-idea-2025-1-2-2"
    ]
  },
  {
    "id": 3,
    "imageUrl": "",
    "title": "대환대출로 신용대출 이자 줄일 수 있어요",
    "description": "이자 부담 줄일 수 있는 신용대출 갈아타기",
    "reviews": [],
    "syllabus": [],
    "link": "https://toss.im/tossfeed/article/tossmoment-11",
    "pubDate": "Thu, 05 Jun 2025 06:31:00 GMT",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 4,
    "imageUrl": "",
    "title": "Extension Manager updates in Visual Studio",
    "description": "The latest updates in Visual Studio 2022 introduced features specifically designed to improve how you manage extensions. These updates offer tools that help you automate processes, provide detailed controls for configuration, and enhance the user interface to streamline your development workflows. Seamless auto updates Visual Studio now automatically triggers updates whenever you open the Extension […]\nThe post Extension Manager updates in Visual Studio appeared first on Visual Studio Blog.",
    "reviews": [],
    "syllabus": [],
    "link": "https://devblogs.microsoft.com/visualstudio/extension-manager-updates-in-visual-studio/",
    "pubDate": "Mon, 02 Jun 2025 18:13:24 +0000",
    "creator": "Javier De la Garza",
    "categories": [
      "Extensibility",
      "Visual Studio",
      "Extensions",
      "Updates",
      "visualstudio.extensibility"
    ]
  },
  {
    "id": 5,
    "imageUrl": "",
    "title": "Help Predict the Future of AI in Software Development!",
    "description": "Ever wanted to share your ideas about AI and have a chance at winning prizes at the same time? As a company dedicated to creating the best possible solutions for software development, we at JetBrains want to know what you think about AI in software development.  In this post, we tell you more about the […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/research/2025/06/predict-the-future-of-ai-in-software-development/",
    "pubDate": "Mon, 02 Jun 2025 11:45:27 +0000",
    "creator": "Katie Fraser",
    "categories": [
      "research",
      "ai-in-software-development",
      "forecasting-platform",
      "jetbrains-research",
      "prediction-market",
      "tournament"
    ]
  },
  {
    "id": 6,
    "imageUrl": "",
    "title": "악역영애 4컷 만화 - 5화, 등교 시작인데스와~★",
    "description": "No description available",
    "reviews": [],
    "syllabus": [],
    "link": "https://bbs.ruliweb.com/news/board/11/read/2315",
    "pubDate": "Wed, 04 Jun 2025 19:09:01 +0900",
    "creator": "｜RULIWEB｜",
    "categories": [
      "웹툰"
    ]
  },
  {
    "id": 7,
    "imageUrl": "",
    "title": "코드 품질 개선 기법 14편: 책임을 부여하는 오직 하나의 책임",
    "description": "이 글은 2024년 2월 22일에 일본어로 먼저 발행된 기사를 번역한 글입니다.안녕하세요. 커뮤니케이션 앱 LINE의 모바일 클라이언트를 개발하고 있는 Ishikawa입니다.저희 ...",
    "reviews": [],
    "syllabus": [],
    "link": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-14",
    "pubDate": "Wed, 04 Jun 2025 02:00:00 GMT",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 8,
    "imageUrl": "",
    "title": "Cursor 에서 유용한 Setting",
    "description": "개요\n많은 개발자들이 바이브 코딩의 툴로서 Cursor를 선택하고 있습니다. 특히 VSCode에 익숙한 개발자라면 동일한 인터페이스로 더 높은 생산성을 얻을 수 있기 때문에 Cursor를 선택합니다.\n오늘은 Cursor 사용시 설정하면 좋을 Setting에 대해 알아보겠습니다.\n@Docs\nCursor에서 채팅하거나 코드 생성시 참고할만한 공식 문서를 지정할 수 있습니다. 채팅 시 @<문서명> 을 치고 질문을 하면 해당 문서를 참고해서 답변을 생성합니다.\n\n만약 Cursor가 제공하는 문서에 내가 원하는 문서가 없다면, @doc 을 하면 맨 하단에 Add new doc이 나옵니다.\n\n그 다음 원하는 공식문서를 추가하면 앞으로 채팅에서 공식문서를 참고할 수 있습니다.\n\n\n\nCursor Rules\nCursor에서 답변이나 코드를 생성할 때 참고해야할 나만의 룰이 있다면 프로젝트 폴더에 .cursorrules 파일을 만들어 프롬프트를 입력해보세요. 그럼 커서가 해당 프롬프트를 참고해서 코드를 생성합니다.\n저는 Cursor Rule에 다음과 같은 내용을 작성합니다.\nCoding Conventions\nImport 문 구조\n자주 사용하는 패키지 (langchain, langgraph 등)\nUI/ Styling (Shadcn, Tailwind 등을 사용해)\nPrivacy Mode\n내 코드가 모델 학습에 활용되지 않도록 설정을 원한다면 프라이버시 모드를 활성화해야합니다.\nCursor Setting > Privacy에 가면 Privacy Mode를 설정할 수 있습니다.\n프라이버시 모드\n설정에서 \"Privacy Mode\" 활성화 시 데이터 저장이 전혀 되지 않음\n코드는 저장되거나 학습되지 않음\n일반 모드 (Privacy Mode OFF)\n원격 측정, 사용 데이터, 코드베이스 데이터 수집\n프롬프트, 에디터 작업, 코드 스니펫, 저장소 파일, 코드 편집 내용 포함\n자동완성 사용 시 Fireworks(추론 제공업체)가 추론 속도 개선을 위해 프롬프트 수집 가능\n마무리\n이처럼 몇가지 설정을 한다면 Cursor는 내가 원하는 정보와 Rule에 맞춰서 코드 생성 및 채팅 답변을 생성해줍니다. 다음 시간에는 Cursor에서 사용하기 좋은 MCP Tool과 Extension을 소개해보도록 하겠습니다.",
    "reviews": [],
    "syllabus": [],
    "link": "https://velog.io/@mdy0102/Cursor-%EC%97%90%EC%84%9C-%EC%9C%A0%EC%9A%A9%ED%95%9C-Setting",
    "pubDate": "Sun, 08 Jun 2025 09:16:16 GMT",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 9,
    "imageUrl": "",
    "title": "Microsoft, Anthropic과 협력하여 모델 컨텍스트 프로토콜용 공식 C# SDK 개발",
    "description": "No description available",
    "reviews": [],
    "syllabus": [],
    "link": "https://jacking75.github.io/NET_20250604/",
    "pubDate": "Wed, 04 Jun 2025 00:00:00 +0900",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 10,
    "imageUrl": "",
    "title": "Context Collection Competition by JetBrains and Mistral AI",
    "description": "Build smarter code completions and compete for a share of USD 12,000! In AI-enabled IDEs, code completion quality heavily depends on how well the IDE understands the surrounding code – the context. That context is everything, and we want your help to find the best way to collect it. Join JetBrains and Mistral AI at […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/ai/2025/06/context-collection-competition/",
    "pubDate": "Mon, 02 Jun 2025 12:13:43 +0000",
    "creator": "Dmitry Ustalov",
    "categories": [
      "jetbrains-ai",
      "research",
      "news"
    ]
  },
  {
    "id": 11,
    "imageUrl": "",
    "title": "AI-Powered Learning, Part 2: Get Unstuck With AI Hints in Python and Kotlin Tasks",
    "description": "In our previous post, we introduced AI-powered machine translation and inline theory definitions to help make learning smoother and more accessible. Today, we’re excited to share the next big step in bringing intelligent assistance to your programming journey: AI hints. This feature is designed especially for beginners who may get stuck while solving coding tasks […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/education/2025/06/02/ai-hints-plugin/",
    "pubDate": "Mon, 02 Jun 2025 08:32:54 +0000",
    "creator": "Julia Amatuni",
    "categories": [
      "ai-assistant",
      "jetbrains-academy",
      "jetbrains-academy-plugin",
      "jetbrains-ai",
      "kotlin",
      "learning-courses",
      "jetbrainsacademy",
      "ai-assistance",
      "ide-plugin",
      "learning",
      "news",
      "release"
    ]
  },
  {
    "id": 12,
    "imageUrl": "",
    "title": "제미나이 멀티모달로 고품질 맛집 블로그 콘텐츠 초고속 제작 방법, 무료 지침 공개",
    "description": "스마트폰 속 음식 사진, 블로그 수익으로 바꾸는 비법! 용량 부족 걱정 없이 애드센스 수익까지 얻는 맛집 블로그, AI가 알아서 만들어줘요!\n\n\n \n 스마트폰에 쌓여만 가는 수많은 음식 사진들, 용량 부족 경고가 뜨면 결국 아깝지만 지워야 하죠?   그런데 이 사진들을 전문적인 맛집 블로그로 올리고, 여기에 애드센스 수익까지 얻는다면 금상첨화 아닐까요? 지금 보고 계신 이 블로그 포스팅처럼 말이죠!\n놀라지 마세요. 이 모든 걸 이번에도 제미나이로 가능합니다! 제가 지난번에 제미나이를 활용한 초고속 블로그 글쓰기 영상을 올렸는데요, 정말 많은 분들이 \"실제로 그 지침을 어떻게 만드는지\" 알고 싶다고 하셔서 이번에는 그 비하인드를 공개하는 심화 강의를 준비했습니다.  \n \n우리가 AI와 효과적으로 대화하기 위해서는 그저 \"맛집 글 써줘\"라고 하는 것보다 훨씬 더 체계적인 접근이 필요해요. 정확한 지시와 명확한 가이드라인이 있어야 원하는 결과를 얻을 수 있죠. 그래서 오늘은 이 특별한 '젬 지침'을 만드는 과정까지 여러분께 낱낱이 공개하려고 합니다! 그리고 이번 지침의 핵심에는 단순 글쓰기가 아닌 제미나이의 멀티모달 기능이 있습니다. 이 기능이 왜 혁명적인지, 어떻게 하면 이를 최대한 활용할 수 있는지 함께 알아보겠습니다.\n \nAI 멀티모달 기능의 이해와 활용  \n여러분, 예전 AI는 텍스트만 읽을 수 있었어요. 하지만 최근에는 많은 LLM 모델들이 사진도 보고, 영상도 이해하는 '멀티모달' 능력을 갖추게 되었습니다. 마치 우리가 식당에서 메뉴를 선택할 때 사진과 설명을 함께 보는 것처럼요! 멀티모달이란 쉽게 말해서 다양한 형태의 정보를 동시에 이해하고 처리할 수 있는 인공지능 기술을 의미하는데요. 예를 들어 맛집 사진을 AI에게 보여주면, 예전의 AI는 \"이것은 사진입니다\"라고만 인식했지만, 멀티모달 기능이 있으면 \"이 사진은 식당 내부이고, 테이블 위에는 해물칼국수가 있으며, 옆에는 김치가 놓여있고, 사람들이 즐겁게 식사하고 있네요\"라고 더 자세하고 종합적으로 이해할 수 있게 된 거죠.\n \n여기서 재미있는 점은 AI가 이제 '맥락'을 읽을 수 있다는 거예요. 식당 내부 사진, 음식 사진, 메뉴판을 보고 \"아, 이건 맛집 리뷰를 위한 사진들이구나\"라고 파악합니다. 그래서 여러분이 찍은 맛집 사진을 몇 장만 넣어줘도 전문 블로거가 쓴 것 같은 리뷰를 뚝딱 만들어내는 것이 가능해진 겁니다.\n  알아두세요!\nAI가 아무리 똑똑해도 여러분의 머릿속 생각을 알아서 척척 맞춰주진 않아요. 구체적인 지시가 없으면, 기대한 결과가 나오기 어렵습니다.\n \n프롬프트 엔지니어링의 중요성 (기본적인 시도와 한계)  \n자, 이제 기본적인 방법으로 한번 시도해보겠습니다. 제가 천안에 사는데, 최근에 방문한 회사 근처 \"성거산 시골 막국수\"라는 곳의 사진 일곱 장을 준비했습니다. 이 사진들을 제미나이에 업로드하고 간단하게 \"이 사진들로 맛집 블로그 포스팅을 작성해줘\"라고 요청해보겠습니다. 천안 오시면 꼭 한 번 방문해 보세요. 맛있어요!!\n음... 나쁘지 않지만 뭔가 아쉬워요. '성거산 막국수: 막국수와 찰떡궁합 보쌈 맛집!'이라는 제목으로 기본적인 정보는 잘 담았지만, 뭔가 차별화된 느낌이 부족합니다. '식당은 넓은 주차 공간을 갖추고 있어, 차량으로 방문하기에 정말 편리했어요' '내부로 들어서니 생각보다 훨씬 넓고 쾌적한 공간이 펼쳐졌습니다'처럼 정보는 있지만 독자의 감성을 자극하는 생생한 묘사가 부족하죠.\n구분\n설명\n기대 효과\n\n\n\n\n명확한 역할 부여\n\"너는 지금부터 맛집 블로거야!\"\n글의 톤앤매너와 방향 설정\n\n\n구체적인 목표 제시\n\"사진 분석해서 생생한 맛집 리뷰 써줘.\"\nAI가 나아가야 할 명확한 길 제시\n\n\n결과 형식 지정\n\"HTML 코드로, 특정 스타일 적용해서.\"\n일관성 있고 사용 가능한 결과물 도출\n\n\n\n이럴 때 프롬프트 엔지니어링이 효과적인 것이죠. 프롬프트 엔지니어링은 AI에게 어떤 요청을 할 때, 원하는 결과물을 얻기 위해 질문이나 요청을 효과적으로 설계하는 기술입니다. 간단히 말해 AI와 잘 소통하는 방법을 찾는 거죠. 프롬프트 엔지니어링의 핵심은 AI에게 명확한 역할, 목표, 형식을 제공하는 것입니다. 이 프롬프트 엔지니어링을 기반으로 젬 지침을 만드는 것이죠.\n⚠️ 주의하세요!\nAI가 아무리 똑똑해도 여러분의 머릿속 생각을 알아서 척척 맞춰주지 않습니다. 구체적인 지시가 없으면, 기대한 결과가 나오기 어렵다는 점을 꼭 기억하세요!\n \nGoogle AI Studio 활용 (젬 지침 제작 환경)  \n오늘 저는 이 젬 지침을 제미나이 2.5 모델을 이용해 만들려고 합니다. 하지만 제미나이 사이트가 아닌 AI Studio라는 곳에서 지침을 만들게요.\n  AI Studio는?\nGoogle AI Studio는 구글에서 제공하는 개발자 친화적인 플랫폼으로, AI 모델을 더 세밀하게 제어하고 실험할 수 있는 공간입니다. 개발자, 학생, 연구자들이 프롬프트를 테스트하고 최적화하며, API 통합까지 준비할 수 있는 전문적인 환경이죠. AI Studio도 무료로 사용할 수 있습니다.\n특히 구글의 다양한 최신 AI 모델들을 가장 빨리 만날 수 있으니, 영상 설명란의 링크로 접속하셔서, 다양한 경험을 해 보세요. 흥미로운 사실은, 제가 이번에는 파라미터 조정 없이 기본값으로 진행했는데도 일반 제미나이와 결과가 달랐다는 점입니다. 왜 그럴까요?\nAI Studio vs. 일반 제미나이 차이점\n1) 첫 번째 단계: AI Studio는 기본 Temperature(창의성) 값이 1.0으로 설정되어 있어 더 다양하고 창의적인 결과물 생성\n2) 두 번째 단계: 일반 제미나이는 일관된 답변을 위해 이 값을 더 낮게 설정 가능\n→ AI Studio는 모델의 '날 것 그대로'의 동작을 확인하고 제어하는 데 중점을 둡니다. 따라서, 전문적인 콘텐츠 제작이나 복잡한 지침을 만들 때는 AI Studio에서 작업하는 것을 추천합니다.\n \n맛집 블로그 프롬프트 제작 과정 (1차 및 2차 수정)  ‍ ‍ \n자, 이제 본격적으로 맛집 블로그용 지침을 만들어 보겠습니다! AI STUDIO에 방문하신 후 우측에서 최신 AI 모델을 선택합니다. 아까 얘기한 것처럼 하단에 파라메터는 그대로 두고 첫 번째 프롬프트를 입력할게요. \"사용자 입력 정보와 사진을 기반으로 멀티모달 기능을 최대한 활용하여 구글 상위노출에 최적화된 맛집탐방 블로그 기사를 생성하고 그 결과물을 HTML 코드로 생성하는 젬 지침을 만들어\" 라고 요청하면 바로 맛집 블로거를 위한 지침을 생성합니다.\n  알아두세요!\n1차 요청에서는 사용자에게 너무 많은 정보를 요구했습니다. 식당명, 주소, 키워드, 한 줄 평 등. 편리하게 쓰려고 AI를 활용하는데, 정보 입력에 시간을 다 쓰면 본말이 전도됩니다.\n그래서 두 번째 요청에서는 복잡한 질문만 단순화했습니다. \"사용자에게 묻는 질문이 너무 많아. 처음에 식당명/지역, 주문음식/추가음식, 주변음식/반찬, 후식, 방문배경, 사진을 요청하면서 시작하고, 사용자가 입력을 하면 나머지 정보는 사진을 분석해서 대신 작성하게 지침을 수정해\" 이런 식으로 사용자가 5가지 질문과 사진 업로드만으로 맛집 블로그를 작성할 수 있도록 만들었어요. 중요한 점은, 제미나이의 멀티모달 기능을 활용해 사진을 직접 분석하여 블로그 내용에 반영하도록 한 것이죠.\n \n젬 지침 등록 및 테스트  \n자, 이렇게 해서 나온 2차 결과물을, 제미나이로 돌아가서 젬 지침에 등록을 하고, 결과를 확인해볼게요. 젬 관리자의 샘 젬 만들기에서 예를 들어 제목을 \"맛집 블로그 전문가\"라고 입력을 합니다.\n사례 주인공의 상황: '성거산 시골 막국수' 테스트\n1. 식당명/지역: 천안 성거, 성거산 시골 막국수\n2. 주문음식/추가음식: 비빔 막국수와 수육\n계산 과정: 간편한 입력으로 결과 확인\n1) 3. 주변 음식/반찬: 주변 음식 코너가 따로 있고 셀프임\n2) 4. 후식: 후식 없음\n최종 결과: 블로그 글 자동 생성!\n- 5. 방문배경: 5월 중순 26도의 이른 더위 점심시간. 팀원들과 점심 식사\n- 사진 업로드 → AI가 알아서 블로그 글 생성\n이런 식으로 결과를 확인하고 수정할 부분을 계속해서 AI와 대화를 해 나가면서 완성형으로 만들어 가는 것입니다. 완벽한 결과물은 처음부터 나오지 않습니다. AI와 지속적인 대화를 통해 결과를 확인하고 수정해나가는 '반복 최적화' 과정이 핵심입니다. 제가 이전 영상에서 공유해드린 지침들도 수십 번의 시행착오와 세밀한 조정을 거쳐 완성된 것들이랍니다.\n \n결과물 개선 (HTML 구조 및 디자인 문제점 해결)  \n자, 지금 우리가 받은 결과물을 살펴보면 세 가지 중요한 문제점이 보입니다. 이런 세부 사항들이 블로그 포스팅의 품질을 좌우하게 됩니다.\nHTML 코드 생성 문제: HTML 코드가 코드 블록 안에 제대로 생성되지 않았습니다.\n불완전한 HTML 구조: HTML이 완전한 형태의 웹페이지 구조(HTML, HEAD, BODY 태그 포함)로 표시되고 있습니다. 이는 블로그에 붙여넣을 때 구조적 충돌을 일으킵니다. 블로그 플랫폼은 이미 이 태그들을 가지고 있기 때문이죠.\nH1 태그 중복 문제: 블로그 플랫폼에서는 제목을 별도로 입력하는 필드가 있기 때문에, 본문 내에 H1 태그가 있으면 중복 제목이 생겨 SEO에 좋지 않고 디자인도 깨질 수 있습니다.\n이런 경우, AI에게 '블로그 본문에 추가해야 하므로 헤드, 바디 태그와 에이치원 태그가 없는 인라인 스타일로 변경해주세요. 제목은 별도로 입력할 것입니다.'라고 요청하세요. 그러면 블로그 플랫폼에 바로 붙여넣을 수 있는 최적화된 HTML 코드를 받을 수 있습니다. 위의 2가지 문제 개선을 위해, 1. 이 지침의 출력물 중 HTML 코드로 생성되는 결과물은 \"코드 블록\"으로 출력해, 2. 블로그 본문에 추가해야 하므로 헤드, 바디 태그와 에이치원 태그가 없는 인라인 스타일로 변경해. 라고 다시 지침 수정을 요청합니다.\n \n자, 수정된 지침으로 생성된 결과물을 보면 인라인 스타일의 에이치티엠엘 코드가 코드블록에서 생성되는 것을 확인할 수 있습니다. 그런데 이번엔 디자인이 별로입니다. 이럴 때는 \"좀 더 시각화된 결과물이 나올 수 있게 디자인을 개선해줘\" 또는 구체적인 디자인 지침을 주거나 이전 영상에서 소개한 디자인 템플릿을 업로드하고 \"첨부 디자인 스타일로 반영되게 수정해\"라고 요청하셔도 될 거 같습니다. 아, 그리고 디자인만 보시려면, 젬을 수정할 필요 없이, AI STUDIO의 수정된 지침의 코드만 복사해서 코드펜으로 가서 확인하면 됩니다.\n \n \n맛집 블로그 생성 지침 핵심 요약!\n✨ 프롬프트 엔지니어링: AI와 잘 소통하는 기술. 명확한 역할, 목표, 형식을 제공하여 원하는 결과물을 얻는 것이 핵심이죠.\n  멀티모달 기능 활용: 사진을 직접 분석해서 생생한 리뷰를 작성하도록 지시! 단순히 텍스트를 생성하는 것을 넘어, 시각 정보까지 통합하여 블로그 글의 퀄리티를 높입니다.\n  HTML 구조 및 디자인 최적화:\nHTML = (SEO 최적화) + (인라인 스타일) + (H1 태그 제외)\n ‍  반복 최적화의 중요성: 완벽한 결과물은 한 번에 나오지 않아요! AI와 지속적으로 대화하고, 결과를 수정하며 더 나은 지침을 만들어가는 과정이 필요합니다.\n이 지침으로 여러분도 전문 맛집 블로거로 거듭나세요!  \n자주 묻는 질문 ❓\nQ: 제미나이 멀티모달 기능은 어떤 점에서 혁신적인가요?\nA:   예전 AI는 텍스트만 이해했지만, 멀티모달 기능은 사진, 영상 등 다양한 형태의 정보를 동시에 이해하고 처리할 수 있어, AI가 맥락을 파악하고 더 풍부하고 정확한 콘텐츠를 생성할 수 있게 합니다.\nQ: AI Studio를 사용하는 이유가 무엇인가요?\nA:   AI Studio는 구글의 최신 AI 모델을 가장 먼저 접하고, Temperature(창의성) 값 등을 세밀하게 조정하며 프롬프트를 테스트하고 최적화할 수 있는 개발자 친화적인 환경을 제공합니다.\nQ: 블로그 포스팅용 HTML 코드를 생성할 때 주의할 점은?\nA:   블로그 플랫폼의 구조와 충돌하지 않도록 HEAD, BODY 태그와 H1 태그를 제외한 인라인 스타일로 코드를 생성해야 합니다.\nQ: 맛집 블로그를 위한 '젬 지침'은 어떻게 만드나요?\nA:   AI Studio에서 프롬프트 엔지니어링을 활용하여 AI에게 명확한 역할, 목표, 형식을 부여하고, 사용자가 최소한의 정보만 입력해도 되는 방식으로 반복 최적화 과정을 거쳐 만듭니다.\nQ: 완성된 블로그 콘텐츠를 어떻게 활용할 수 있나요?\nA:   생성된 고품질의 블로그 포스팅을 꾸준히 업로드하여 블로그 방문자를 늘리고, 애드센스 수익을 창출하며, 스마트폰 용량 확보와 맛집 기록까지 일석삼조의 효과를 누릴 수 있습니다.\nGEM 무료 지침 다운 로드\n반응형\n\n    \n    (adsbygoogle = window.adsbygoogle || []).push({});\n  \n\n    \n\n    \n맛집 블로그 생성 GEM 지침.zip\n0.01MB",
    "reviews": [],
    "syllabus": [],
    "link": "http://muzbox.tistory.com/483604",
    "pubDate": "Sun, 8 Jun 2025 14:28:03 +0900",
    "creator": "어떤오후의 프리웨어 이야기",
    "categories": [
      "AI, 미래기술/AI 챗봇 및 지침 무료 배포",
      "ai 멀티모달",
      "google ai studio",
      "html 블로그",
      "SEO 최적화",
      "맛집 블로그",
      "블로그 수익",
      "제미나이",
      "지침 생성",
      "콘텐츠 제작",
      "프롬프트 엔지니어링"
    ]
  },
  {
    "id": 13,
    "imageUrl": "",
    "title": "Get Answers to Your KMP Questions",
    "description": "During the Closing Panel at KotlinConf 2025, we received many questions about Kotlin Multiplatform (KMP), but unfortunately didn’t have time to address them all live. So we’ve decided to answer the most popular ones in a follow-up blog post. Will IntelliJ IDEA and Android Studio support full Swift navigation, completion, etc., for iOS code, or […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/kotlin/2025/06/get-answers-to-your-kmp-questions/",
    "pubDate": "Mon, 02 Jun 2025 06:37:10 +0000",
    "creator": "Anton Makeev",
    "categories": [
      "multiplatform"
    ]
  },
  {
    "id": 14,
    "imageUrl": "",
    "title": "학습 플랫폼과 AI",
    "description": "아래는 저희 제품팀 전체에게 공유한 내용 중 일부를 정리해서 공유합니다.\n\n최근에 팀원과 함께 AI 요약 노트를 어떻게 제공할지에 대해 논의 논의하는 시간을 가졌다.  \n여러 아이디어가 나왔는데, 퀴즈를 풀기 전에 요약 내용을 꼭 숙지 하도록 장치를 두는 것은 놓치지 말았으면 한다는 것을 조건으로 두었다.\n다만, 그걸 덜 불편하게, 자연스럽게 전달할 수 있도록 고민을 더 할 필요는 있다고도 덧붙였다.  \n퀴즈를 풀려면 요약 노트를 꼭 봐야하는 것이 불편할 수 있다.\n바로 퀴즈 풀고 싶은데, 요약 노트가 한번 등장하면 퀴즈까지 가는 퍼널이 증가하는 것이고, 고객은 최소 1번 이상은 클릭을 더 해야하니 퀴즈 자체가 목적인 분들께는 좀 더 귀찮은 요소가 될 수 있다.\n그렇다 해도 잘 정리된 요약 노트를 보게 하는 것은 꼭 필수 과정으로 들어가야한다고 이야기드렸다.\n고객이 불편해하는 것들은 모두 다 편한 것으로 개선하는 것도 중요하다고 생각한다.\n그런 면에서는 넷플릭스, 에이비앤비, 유튜브에서 배울 점이 많다.\n다만, 그것보다 더 양보할 수 없는 중요한 점이 있는데, 그건 바로 우리 플랫폼의 근본 목적인 고객의 학습 이다.    \n아무리 편하더라도 그게 수강생분들의 학습, 성장에 전혀 도움이 안된다면 그건 우리의 목표에 방해되는 기능이다.  \n설령 조금 불편하더라도 훨씬 더 고객이 원하는 교육, 성장, 학습의 목표를 잘 달성할 수 있게하는 장치라면 그걸 지향해야하고 그로 인해 발생하는 불편한 점을 최대한 상쇄시키는 것이 저희 같은 제품가들이 해야하는 고민이라는 것이다.  \n(틀릴 수도 있지만) 요즘 AI 제품들에 대한 내 생각도 여기에서의 연장선에 있다.  \n요즘 여러 오픈카톡방과 커뮤니티에서 \"모든 서비스가 채팅 UI만 남고 다른 UI/UX는 모두 사라질 것이다\" 라는 이야기를 공공연하게 꺼내곤 한다.    \n그런 면에서 우리 학습 강의실 내에도 AI 채팅을 넣는 것고 고려해볼 수 있다.  \n다만, 이 부분에 대해서는 가능하면 최대한 유보하는 입장이다.\n제품가로서 제품에 대한 고민이 너무 날카롭지 않고 무딘 감각으로 느껴지기 때문이다.  \n좋은 학습 플랫폼이라면 개개인이 갖고 있는 백그라운드에 따라 학습 성과가 천차만별이 되는 것을 최대한 지양해야하고, 백그라운드가 부족하더라도 최대한 많은 것을 가져갈 수 있는 방향으로 제품을 만들어야 한다고 생각한다.  \n물론 자질이 훌륭한 분들의 상방선을 열어두고 극대화 하는 것도 중요하지만 그런 분들은 학습 플랫폼의 도움 없이도 혼자서도 잘 할 수 있는 분들이기에 오히려 우리 같은 플랫폼의 도움이 필요로 하지 않는다.\n진짜 우리의 도움이 필요한 분들은 부족한 백그라운드로 인해서 배우는데 어려움이 있거나 효율이 떨어지는 분들이다.\n그들에게 학습에 대한 레버리지를 줄 수 있는 것을 지향해야한다고 보는 것이다.  \n그런 면에서 AI 채팅으로 모르는 것을 물어보세요 라는 것은 이 관점에서는 불합격인 제품이라고 본다.\n왜냐면 프롬프트 역량에 따라 학습 효율이 천차만별로 나뉘기 때문이다.  \n지금도 대다수의 많은 사람들은 AI 채팅을 통해 제대로 학습하는 사람은 극 소수이다.\n희노애락으로 AI를 쓰시는 분들은 많지만, 여전히 많은 분들이 학습하기 위해 AI를 쓰는 경우는 전체 인구에 비하면 소수이다.\nAI는 틀린 답을 낸다고 생각해서 적당히 질문하다가 원하는 답이 안나와서 \"에잇\" 하고 다시 기존의 검색 서비스를 이용하시거나 AI가 틀린 답을 낸 건지도 모르고 사용 하시는 분들도 많다.\n혹은 여전히 AI를 쓰지 않는 분들도 많다.  \n이런 관점에서는 개인의 프롬프트 역량에 따라 정확한 답변을 받을 수 있을 확률이 달라지는 AI 채팅이란 기능이 진짜 백그라운드가 부족한, 독학이 어려운 분들에게 도움이 되는 제품인가?   \n\"AA\" 라는 주제를 공부하려고 강의를 결제했는데, 그 주제를 잘 공부하기 위해서는 AI 프롬프트를 자세히 공부해야한다 라는 것이 과연 학습 플랫폼이 고객에게 전달해야할 가치인가? 라는 근본적인 의문인 것이다.  \n이는 얼핏보면 AI 이전 시대의 '영어' 와 비슷한 것 같단 생각도 든다.  \n영어를 잘 한다면 전세계의 모든 지식을 쉽게 배울 수 있다.\n강의에서 전달하고자 하는 내용을 모두 영어로 설명한다면 관련된 내용을 추가적으로 찾아볼때도 훨씬 더 편하게 찾아 볼 수 있다.\n모든 용어가 다 원래의 용어 그대로를 사용할테니 더 정확한 설명이 될 것이고, 영어로 배운 사람은 이후에도 그 주제에 대해서는 훨씬 더 정확히, 훨씬 더 확장성 있게 학습을 한 상태가 된다.  \n근데 그 서비스가 과연 학습 성장을 평등하게 제공한 것인가?\n그 서비스는 영어를 잘 아는 사람들만을 위한 서비스이다.  \n학습 성장 평등을 지향하는 우리 같은 학습 플랫폼은 영어, 프롬프트 역량이 부족해도 잘 배울 수 있는 환경을 만드는 것에 집중해야 한다는 생각이 요즘 더 강하게 들었다.    \nAI는 사업과 제품에 있어서 큰 곱하기 효과를 주는 것은 맞는데, 이것 자체가 제품이나 사업이 되어서는 안된다.  \n특히나 그 기능이 정말로 우리가 깊은 고민 없이 그냥 남들이 하니깐 하는 정도 수준에서의 기능이라면 더더욱 그 방향은 위험하다고 본다.  \n그건 뭘 위한 것인지 목표 없이 단순히 AI를 붙이고 '해줘'에 가까운 것인데, 그런건 좋은 제품의 기준에는 전혀 합당하다고 보진 않는다.  \n발전 방향도 어색하다고 본다.\nAI 채팅의 답변이 좋으려면 그만큼 더 좋은 모델을 사용해야한다.\n근데 좋은 모델을 사용할수록 대부분 BEP를 맞추기 힘들다.\n그 많은 AI 토큰 비용을 다 플랫폼이 부담해야하고, 그러다 보면 플랫폼 수수료는 더욱 더 높아진다.  \n그렇다면 저렴한 모델을 고객에게 제공하고 별로인 AI 모델인데 쓸려면 써라 정도의 스탠스를 가지고 가는 것도 너무 웃긴다.\n어차피 만족할만한 답변은 나오지 않는데 고객은 그걸 왜 써야하나.\n반면 이런 기능들은 좋다.  \n\"이 내용을 어디선가 봤는데, 그게 어느 강의의 어느 영상이였는지 모르겠다\" 라면 그걸 쉽게 찾을 수 있는 검색\n방금 전에 강사님이 \"이 내용은 다른 강의에서 자세히 이야기 하고 있으니 그 강의를 수강해보세요\" 라고 하는데 그게 어느 강의의 어느 영상 몇분째 인지 알려주는 학습 도우미\n\"남들을 가르치는 것이 가장 좋은 학습 방법\" 이라는 기준으로 방금 배운 내용을 토대로 누군갈 가르쳐보는 경험을 줄 수 있는 환경\n이런 기능들은 목표가 뚜렷하고 프롬프트 등의 백그라운드 지식과 관계없이 학습을 더 잘할 수 있도록 나름의 고민과 여러 학습 효과에 대한 자료를 기반으로 했기 때문에 좋다.\n고객이 학습을 하는데 있어 방해되는 요소가 자연스레 해소 되는 것이기도 한다.  \n물론 이런 예시들을 전부 \"AI 채팅으로 물어보도록 하면 되지 않냐\" 고 할 수도 있다.\n그건 세상에서 가장 똑똑한 과외 선생님을 붙여도 서울대를 못가는 수많은 학생들과 같다.  \n\"내가 뭘 모르는지도 모르고, 뭘 물어봐야하는지도 모르는\" 대다수의 학생들에겐 적합하지 않다.  \n고객에게 \"이런 것도 질문하세요\", \"저런 것도 질문하세요\" 라고 하기 보다는 고객 스스로도 몰랐던 학습의 방해 요소들이 제품 안에서 자연스럽게 해결되고, 성장을 가속할 수 있는 장치가 자연스럽게 적용 되어있는 것 이 가장 좋다.  \n종국에는 \"인프런 써보기 전에는 몰랐는데 인프런 써보고 나니깐 다른 서비스는 못쓰겠다\" 라는 이야기가 나올 수 있다고 믿고 있다.  \n우리가 해야할 것은, AI를 어떻게하면 잘 사용할 수 있을지는 우리의 고민으로 가져오고, 고객들은 AI를 얼마나 잘 사용하는지에 관계없이 원했던 것 이상으로 성장시켜드리는 것이다.  \n그래서 직접 학습자가 되어보는 것이 중요하다.  \n나는 어떤 환경에서 학습이 잘 되었나,  \n나는 아예 처음 접하는 것을 배울때 어떻게 배우나,  \n내가 가장 만족스러웠던 학습 경험은 어떤 것이었나 등등  \n스스로가 고객이 되어서 \"있으면 좋은 것\" 이 아니라, \"이게 진짜 공부하는데 있어서 큰 도움이 되었다\" 라는 것을 계속해서 고민하고 시도해보는 것이 인프랩의 제품 팀으로서 중요하다.  \n그래서 이 부분에 대해 꼭 명심하고 어떤 제품을 만들던 좀 더 날카롭게 고민해야하는 시기인 것 같다.",
    "reviews": [],
    "syllabus": [],
    "link": "http://jojoldu.tistory.com/831",
    "pubDate": "Sun, 8 Jun 2025 10:17:54 +0900",
    "creator": "향로 (기억보단 기록을)",
    "categories": [
      "생각정리",
      "AI",
      "ai 채팅",
      "GPT",
      "교육 플랫폼",
      "인프런",
      "학습"
    ]
  },
  {
    "id": 15,
    "imageUrl": "",
    "title": "Gemma3 기반 Ollama 활용 AI 에이전트 개발 핵심 Function Call 구현해보기",
    "description": "이 글은 AI 에이전트(Agent) 개발 시 필수적인 함수호출 방법을 오픈소스를 이용해 구현해 본다. 이를 위해, Gemma3(젬마) LLM(Large Language Model) 기반 Ollama 활용 Function Call(펑션콜) 실습 내용을 소개하고 실행 결과를 확인한다. 아울러, 이런 함수호출 방식의 한계점을 개선하기 위한 솔류션을 나눔한다. 이 실습의 결과는 다음과 같다. \n\n\n이 글은 다음 내용을 포함한다.\n\nAI 에이전트 구현을 위한 함수 호출 방법\nOllama 를 통한 Gemma3 사용법\n채팅 형식 프롬프트 및 메모리 사용법\nGradio 기반 웹 앱 개발\nFunction call 의 한계와 솔류션\n\n\nAI 에이전트 내부 Function call 메커니즘(Akriti, 2025)\n\n\n이 글의 구현 코드는 다음 링크에서 확인할 수 있다.\n\nmac999/AI_agent_simple_function_call\n\nGemma3 모델 특징\n\nGemma 3는 구글이 개발해  2025년 3월 10일에 출시한 LLM으로, 차세대 경량 오픈 멀티모달 AI 모델로, 텍스트와 이미지를 동시에 처리할 수 있는 기능을 갖추고 있다. 이 모델은 다양한 크기와 사양으로 제공되어 단일 GPU 또는 TPU 환경에서도 실행 가능하다.\nGemma 3는 1B, 4B, 12B, 27B의 네 가지 모델 크기로 제공되며, 각각 10억, 40억, 120억, 270억 개의 파라미터를 갖추고 있다. 1B 모델은 텍스트 전용으로 32K 토큰의 입력 컨텍스트를 지원하고, 4B, 12B, 27B 모델은 멀티모달 기능을 지원하며 128K 토큰의 입력 컨텍스트를 처리할 수 있다. 이는 이전 Gemma 모델보다 16배 확장된 크기로, 훨씬 더 많은 양의 정보를 한 번에 처리할 수 있게 해준다.\n이 모델은 텍스트와 이미지 데이터를 동시에 처리하고 이해하는 멀티모달 기능을 제공한다. 이미지 해석, 객체 인식, 시각적 질의응답 등 다양한 작업을 수행할 수 있으며, 텍스트 기반 작업에 시각적 정보를 효과적으로 활용할 수 있도록 지원한다. \n\n\n\n\n  \nWelcome Gemma 3: Google's all new multimodal, multilingual, long context open LLM\n\nGemma 3는 140개 이상의 언어를 지원하여 전 세계 다양한 언어 사용자를 대상으로 하는 AI 애플리케이션 개발에 매우 유리하다. 사용자는 자신의 모국어로 Gemma 3와 상호작용할 수 있으며, 다국어 기반의 텍스트 분석 및 생성 작업도 효율적으로 수행할 수 있다.\n이 모델은 다양한 작업 수행 능력을 갖추고 있다. 질문 답변, 텍스트 요약, 논리적 추론, 창의적인 텍스트 형식 생성(시, 스크립트, 코드, 마케팅 문구, 이메일 초안 등), 이미지 데이터 분석 및 추출 등 광범위한 자연어 처리 및 컴퓨터 비전 관련 작업을 수행할 수 있다. 또한, 함수 호출 및 구조화된 출력을 지원하여 개발자들이 특정 작업을 자동화하고 에이전트 기반의 경험을 구축하는 데 도움을 준다.\nGemma 3는 다양한 도구 및 프레임워크와 원활하게 통합된다. Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM, Gemma.cpp 등 다양한 개발 도구 및 프레임워크와 호환되어 개발자들이 자신이 익숙한 환경에서 Gemma 3를 쉽게 활용하고 실험할 수 있다.\n이 모델은 다양한 벤치마크 테스트에서 동급 모델 대비 최첨단 성능을 입증했다. 특히, Chatbot Arena Elo Score에서 1338점을 기록하며, 여러 오픈 소스 및 상용 모델보다 높은 성능을 보였다. \nGemma 3는 오픈 모델로, 개방형 가중치를 제공하여 사용자가 자유롭게 조정하고 배포할 수 있다. Kaggle과 Hugging Face에서 다운로드 가능하며, Creative Commons 및 Apache 2.0 라이선스를 따름으로써, 개발자와 연구자에게 VLM 기술에 대한 접근성을 높여준다.\n\n개발 환경\n개발 환경은 다음과 같다. 미리 설치, 가입한다.\n\nollama:  https://ollama.com/download/windows\ngemma3: https://ollama.com/search\nserper 서비스: 가입. https://serper.dev/dashboard \n\n설치되어 있다면, 다음 명령을 터미널에서 실행한다.\nollama pull gemma3:4b\n\n\n\ngemma3:4b GPU VRAM 소모량\n\n\n이제 다음과 같이 모델을 실행해 볼 수 있다. \n\n\n\n\n참고로, GPU VRAM 등을 고려해 더 성능이 좋은 파라메터수 많은 대형 모델을 사용할 수도 있다.\n\n\ngemma3 지원 모델들\n\n처리 프로세스\n이 실습 프로그램의 프로세스는 다음과 같다.\n\n\nGradio 앱이 시작되면, 사용자의 입력이 발생하고 이 입력은 process_message 함수에 전달된다. 이 함수는 사용자의 메시지를 chat_history에 추가하여 대화 기록을 저장한다. 이후 모델에게 전달할 대화 문맥을 구성하기 위해 messages 리스트가 생성된다.\n\n\n그 다음 단계에서는 ollama.chat 함수를 통해 언어 모델에게 응답을 요청하게 되며, 이 응답 내에 함수 호출이 포함되어 있는지를 확인한다. 만약 응답에 함수 호출이 포함되어 있다면, 이를 parse_function_call 함수를 통해 파싱한다.\n\n\n파싱된 함수가 google_search라면, 모델이 검색을 원한다고 판단하여 검색 쿼리를 추출하고 검색 수행 예정임을 사용자에게 안내하는 메시지를 추가한다. 이후 실제로 google_search 함수를 실행하여 외부 검색을 수행한다.\n\n\n검색 결과는 다시 chat_history에 저장되며, 이 결과를 바탕으로 언어 모델에게 재질문을 하여 더 정확하고 완성된 응답을 유도한다. 모델이 생성한 최종 응답은 chat_history에 마지막으로 추가되고, 이 전체 대화 기록이 사용자에게 반환된다.\n\n\n이 구조는 사용자의 질의에 따라 외부 정보까지 능동적으로 검색하고 반영할 수 있는 LLM 기반 AI 에이전트의 대표적인 흐름을 보여준다.\n\n\n다음은 이 순서도를 보여준다.\n\n\n\n구현하기\n터미널에서 다음 라이브러리를 설치한다.\npip install langchain-core langchain-openai gradio ollama requests python-dotenv pydantic\n\n\n새로운 파이썬 파일(코드 참고)을 생성한 후, 우선, 필요한 라이브러리를 임포트한다. \n\nimport gradio as gr\nimport ollama\nimport requests, json, os\nfrom dotenv import load_dotenv\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, Dict, Any, List\n\nload_dotenv()\nSERPER_API_KEY = os.getenv('SERPER_API_KEY')\n\n\n\n그리고, 사용하는 API 키를 가져온다. 이를 위해, 미리 .env 파일을 다음과 같이 만들어 놓고, 해당 API를 입력해 놓야야 한다.\n\n# .env\nSERPER_API_KEY=<YOUR API KEY>\n\n\n\n파라메터에서 검색 질의문, 함수호출명과 파라메터를 정의한다. 아울러, 질의 결과를 명확히 데이터항목으로 추출하기 위해서 검색 결과가 될 데이타항목(타이틀, 링크, 스닙펫) 형식을 pydantic의 basemodel을 이용해 명확히 정의한다. 그리고, LLM 호출 결과를 펑션콜이 가능한 형식으로 변환하기 위한 파싱 함수인 parse_function_call 을 정의한다.\n\nclass SearchParameters(BaseModel):\n    query: str = Field(..., description=\"Search term to look up\")\n\nclass FunctionCall(BaseModel):\n    name: str\n    parameters: Dict[str, Any]\n\nclass SearchResult(BaseModel):\n    title: str\n    link: str\n    snippet: str\n\n    def to_string(self) -> str:\n        return f\"Title: {self.title}\\nLink: {self.link}\\nSnippet: {self.snippet}\"\n\ndef google_search(query: str) -> SearchResult:\n    \"\"\"Perform a Google search using Serper.dev API\"\"\"\n    try:\n        url = \"https://google.serper.dev/search\"\n        payload = json.dumps({\"q\": query})\n        headers = {\n            'X-API-KEY': SERPER_API_KEY,\n            'Content-Type': 'application/json'\n        }\n        \n        response = requests.post(url, headers=headers, data=payload)\n        response.raise_for_status()  # 잘못된 상태 코드에 대해 예외 발생\n        \n        results = response.json()\n        \n        if not results.get('organic'):\n            raise ValueError(\"No search results found.\")\n            \n        first_result = results['organic'][0]\n        return SearchResult(\n            title=first_result.get('title', 'No title'),\n            link=first_result.get('link', 'No link'),\n            snippet=first_result.get('snippet', 'No snippet available.')\n        )\n    except Exception as e:\n        print(f\"Search error: {str(e)}\")\n        raise\n\ndef parse_function_call(response: str) -> Optional[FunctionCall]:\n    \"\"\"Parse the model's response to extract function calls\"\"\"\n    try:\n        # Clean the response and find JSON structure\n        response = response.strip()\n        start_idx = response.find('{')\n        end_idx = response.rfind('}') + 1\n        \n        if start_idx == -1 or end_idx == 0:\n            return None\n            \n        json_str = response[start_idx:end_idx]\n        data = json.loads(json_str)\n        return FunctionCall(**data)\n    except Exception as e:\n        print(f\"Error parsing function call: {str(e)}\")\n        return None\n\n\n\ngemma에 지시할 시스템 프롬프트 명령을 정의한다. prompt_system_message는 이 챗봇이 어떻게 동작해야 하는지, 그리고 어떤 기준으로 답변을 해야 하는지에 대한 지침을 제공하는 역할을 한다. 이 메시지는 챗봇이 2024년까지의 정보를 학습한 AI 어시스턴트임을 명확히 하고, 사용자의 질문에 대해 가능한 경우에는 바로 답변을 하되, 최신 정보나 불확실한 내용, 시의성이 있는 질문에 대해서는 반드시 펑션콜을 통해 검색 기능을 활용해야 함을 명시한다. 이전 대화 내용이 함께 입력으로 주어지기 때문에, 챗봇은 이 대화 맥락을 참고하여 일관성 있고 상황에 맞는 답변을 해야 한다고 안내한다. 참고로, 준수해야 할 gemma3의 function call 형식은 다음과 같다. \n\ngemini-samples/examples/gemma-function-calling.ipynb at main · philschmid/gemini-samples\n\n검색이 필요한 상황과 그렇지 않은 상황을 구체적으로 구분하여, 챗봇이 임의로 정보를 추정하거나 추가하지 않고, 검색 결과에 기반한 사실만을 간결하게 전달하도록 유도한다. 검색이 필요한 경우에는 정해진 JSON 형식으로만 응답하도록 하여, 시스템이 함수 호출 방식으로 검색을 처리할 수 있게 한다.\n\n# 프롬프트 시스템 메세지 정의\nprompt_system_message = \"\"\"You are an AI assistant with training data up to 2024. Answer questions directly when possible, and use search when necessary.\n\nYou will receive previous conversation messages as part of the input. Use these prior messages to maintain context and provide coherent, context-aware answers.\n\nDECISION PROCESS:\n1. For historical events before 2024:\n   - Answer directly from your training data.\n2. For events in 2024:\n   - If you are certain, answer directly.\n   - If you are unsure, use search.\n3. For events after 2024 or current/recent information:\n   - Always use search.\n4. For timeless information (scientific facts, concepts, etc.):\n   - Answer directly from your training data.\n\nALWAYS USE SEARCH if the question:\n- Contains words like \"current\", \"latest\", \"now\", \"present\", \"today\", \"recent\"\n- Asks about someone in a changing position (champion, president, CEO, etc.)\n- Requests information that might have changed since 2024\n- Is time-sensitive and does not specify a time period\n\nFUNCTION CALL FORMAT:\nWhen you need to search, respond WITH ONLY THE JSON OBJECT, no other text, no backticks:\n{\n    \"name\": \"google_search\",\n    \"parameters\": {\n        \"query\": \"your search query\"\n    }\n}\n\nSEARCH FUNCTION:\n{\n    \"name\": \"google_search\",\n    \"description\": \"Search for real-time information\",\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"Search term\"\n            }\n        },\n        \"required\": [\"query\"]\n    }\n}\n\nWHEN ANSWERING BASED ON SEARCH RESULTS:\n- Use ONLY facts found in the search results below.\n- Do NOT add any dates or information not present in the search results.\n- Do NOT make assumptions about timing or events.\n- Quote dates exactly as they appear in the results.\n- Keep your answer concise and factual.\n\"\"\"\n\n\n\ngemma에 전달할 메시지는 프롬프트 지시문, 사용자 질문을 포함한 이전 채팅 이력 메시지 등을 모두 포함한다. 이를 ollama LLM 에 전달할 수 있는 형식으로 변환하는 함수를 다음과 같이 준비한다. \n\n# 메시지 리스트를 생성하는 함수\ndef filter_memory(memory):\n    \"\"\"assistant의 검색 안내 메시지를 memory에서 제외\"\"\"\n    return [\n        msg for msg in memory\n        if not (\n            msg[\"role\"] == \"assistant\" and (\n                msg[\"content\"].startswith(\"Searching for:\") or\n                msg[\"content\"].startswith(\"Searched for:\")\n            )\n        )\n    ]\n\ndef build_messages(chat_history, user_input=None, prompt_system_message=prompt_system_message, N=6, search_result=None):\n    \"\"\"\n    최근 N개 메시지와 system 메시지를 합쳐 messages 리스트를 만듭니다.\n    search_result가 있으면, user_input 대신 검색 결과 기반 프롬프트를 추가합니다.\n    \"\"\"\n    memory = chat_history[-N:] if len(chat_history) > N else chat_history[:-1]\n    filtered_memory = filter_memory(memory)\n    messages = [{\"role\": \"system\", \"content\": prompt_system_message}] + filtered_memory\n    if search_result is not None:\n        messages.append({\n            \"role\": \"user\",\n            \"content\": (\n                \"Refer to the following search result and provide a concise, factual answer based only on this information:\\n\"\n                f\"{search_result.to_string()}\"\n            )\n        })\n    elif user_input is not None:\n        messages.append({\"role\": \"user\", \"content\": user_input})\n    return messages\n\n\n\n\n이제 process_message 함수를 구현한다. 이 함수는 사용자의 입력과 기존 채팅 기록을 받아 AI 모델과의 대화 흐름을 관리하는 역할을 한다.\n\n\n먼저 사용자의 메시지를 채팅 기록에 추가하고, 이전 대화 내용(메모리)을 추출하여 시스템 메시지와 함께 모델에 전달할 메시지 목록을 구성한다. 이 메시지 목록을 Ollama 모델에 전달하여 응답을 받는다. 모델의 응답이 함수 호출(JSON) 형태라면, 그 내용을 파싱하여 검색이 필요한 경우 검색 쿼리를 추출한다.\n\n\n검색이 필요하다고 판단되면, 검색 중임을 알리는 메시지를 채팅 기록에 추가하고, 실제로 검색을 수행한다. 검색 결과를 다시 채팅 기록에 반영한 뒤, 이 결과를 포함한 새로운 메시지 목록을 만들어 모델에 전달하여 최종 답변을 받는다. 최종적으로 받은 답변 역시 채팅 기록에 추가한다.\n\n\n검색이 필요하지 않은 경우에는 모델의 응답을 바로 채팅 기록에 추가한다. 이 과정에서 각 단계별로 최신 채팅 기록을 반환하여, 사용자 인터페이스가 실시간으로 대화 상태를 갱신할 수 있도록 한다.\n함수 실행 중 오류가 발생하면, 오류 메시지를 채팅 기록에 추가하여 사용자에게 알린다.\n\n# Model name\nMODEL_NAME = \"gemma3\"\n\ndef process_message(user_input, chat_history):\n    \"\"\"Process user message and update chat history\"\"\"\n    try:\n        # 사용자 메시지를 기록에 추가\n        chat_history.append({\"role\": \"user\", \"content\": user_input})\n        search_info = None\n\n        # 최근 N개 메시지만 memory에 포함 (예: 최근 6개)\n        N = 6\n        messages = build_messages(chat_history, user_input=user_input, N=N)\n\n        # 모델로부터 응답 받기\n        response = ollama.chat(\n            model=MODEL_NAME,\n            messages=messages       \n        )\n        \n        model_response = response['message']['content']\n        \n        # 함수 호출로 응답을 파싱 시도\n        function_call = parse_function_call(model_response)\n        \n        if function_call and function_call.name == \"google_search\":\n            # 검색 파라미터 검증\n            search_params = SearchParameters(**function_call.parameters)\n            search_query = search_params.query\n            \n            # 검색 정보 기록에 추가\n            search_info = f\"Searching for: {search_query}\"\n            chat_history.append({\"role\": \"assistant\", \"content\": search_info})\n            yield chat_history\n            \n            # 검색 실행\n            search_result = google_search(search_query)\n            \n            # 검색 결과로 정보 업데이트\n            search_info = f\"Searched for: {search_query}\\n\\nResult:\\n{search_result.to_string()}\"\n            chat_history[-1] = {\"role\": \"assistant\", \"content\": search_info}\n            yield chat_history\n\n            # 검색 결과 기반 메시지 생성\n            messages = build_messages(chat_history, N=N, search_result=search_result)\n      \n            # 검색 결과를 포함해 모델로부터 최종 응답 받기\n            final_response = ollama.chat(\n                model=MODEL_NAME,\n                messages=messages\n            )\n            \n            assistant_response = final_response['message']['content']\n        else:\n            # 함수 호출이 없으면 직접 응답 반환\n            assistant_response = model_response\n        \n        # 최종 응답을 기록에 업데이트\n        if search_info:\n            chat_history.append({\"role\": \"assistant\", \"content\": f\" Response:\\n{assistant_response}\"})\n        else:\n            chat_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n        \n        yield chat_history\n            \n    except Exception as e:\n        error_msg = f\"An error occurred: {str(e)}\"\n        chat_history.append({\"role\": \"assistant\", \"content\": error_msg})\n        yield chat_history\n\n\n\n\n이제 Gradio UI 를 정의하고, 메인 엔트리에서 이 앱을 실행한다.\n\n\n# Gradio 인터페이스 생성\nwith gr.Blocks(css=\"footer {visibility: hidden}\") as demo:\n    gr.Markdown(\"\"\"\n    # Agent based on Gemma3 using Function Call\n    \n\n    \"\"\")\n    \n    chatbot = gr.Chatbot(\n        height=500,\n        show_label=False,\n        avatar_images=(None, \"https://api.dicebear.com/9.x/identicon/svg?seed=Mason\"),\n        type=\"messages\"\n    )\n    \n    with gr.Row():\n        msg = gr.Textbox(\n            scale=5,\n            show_label=False,\n            placeholder=\"Ask me anything...\",\n            container=False\n        )\n        submit_btn = gr.Button(\"Send\", scale=1)\n    \n    with gr.Row():\n        clear_btn = gr.Button(\"Clear Chat\")\n    \n\n    # 이벤트 핸들러 설정\n    msg.submit(\n        process_message,\n        [msg, chatbot],\n        [chatbot],\n    )\n    \n    submit_btn.click(\n        process_message,\n        [msg, chatbot],\n        [chatbot],\n    )\n    \n    clear_btn.click(\n        lambda: [],\n        None,\n        chatbot,\n        queue=False\n    )\n    \n    # 메시지 전송 후 텍스트박스 비우기\n    msg.submit(lambda: \"\", None, msg)\n    submit_btn.click(lambda: \"\", None, msg)\n\nif __name__ == \"__main__\":\n    demo.launch(inbrowser=True, share=True) \n\n\n\n실행\n앞에 구현된 앱을 실행한다. 그리고, 적절한 질문을 입력해 본다. 다음과 같이 실행되면 성공한 것이다.\n\n\n\n\n펑션콜 문제 개선 방법\n실제로 질의해보면 불명확한 프롬프트 입력 등에서 부적절한 함수 호출이 수행되는 것을 알 수 있다. 이를 개선하기 위해 다음 사항을 고려한다.\n\n프롬프트 설계의 명확성\n\n함수 호출이 필요한 상황, 호출 방식(JSON 포맷 등), 호출 예시를 SYSTEM_MESSAGE에 명확하게 안내해야 한다. 함수 호출이 아닌 일반 답변을 하면 안 된다는 점을 반복적으로 강조한다.\n예시 프롬프트:\n\"질문에 답변하기 위해 함수 호출이 필요하다고 판단되면 반드시 아래 JSON 형식으로만 응답하라. 다른 텍스트나 설명은 절대 포함하지 마라.\"\n\n함수 정의의 구체성\n\n함수의 목적, 파라미터, 반환값, 사용 예시를 상세하게 기술한다. 각 파라미터의 타입, 필수 여부, 설명을 명확히 한다. 함수가 처리할 수 없는 입력(예: 빈 문자열, 잘못된 타입 등)에 대한 예외 상황도 명시한다.\n\n예시 기반 Few-shot Prompting\n\nSYSTEM_MESSAGE 또는 user message에 함수 호출이 필요한 질문과 그에 대한 올바른 함수 호출 예시를 여러 개 포함시킨다. 예시가 많을수록 모델이 패턴을 더 잘 학습한다.\n\n함수 호출 실패 시 재시도 로직\n\n모델이 함수 호출을 하지 않거나 잘못된 형식으로 응답하면, 내부적으로 \"함수 호출이 필요합니다. 반드시 JSON 형식으로만 응답하세요.\"와 같은 추가 프롬프트로 재요청한다.\n\n출력 파싱의 견고성\n\n모델이 JSON 외의 텍스트를 섞어서 반환할 수 있으므로, 파싱 로직에서 JSON 부분만 추출하거나, 불완전한 JSON도 최대한 보완해서 파싱하도록 한다.\n\n함수 호출 의도 강화 프롬프트\n\nSYSTEM_MESSAGE에 \"함수 호출이 필요한 상황에서는 반드시 함수 호출을 우선적으로 고려하라\"는 문구를 추가한다. \"만약 함수 호출이 필요하지 않다고 판단되면, 그 이유를 설명하지 말고 바로 답변만 하라.\" 등 불필요한 설명을 억제한다.\n\n모델 버전 및 파라미터 최적화\n\n최신 GPT-4 Turbo 등 함수 호출에 최적화된 모델을 사용한다. temperature, top_p 등 파라미터를 낮춰 일관된 응답을 유도한다. \n\n함수 호출 실패 케이스 수집 및 개선 \n\n\n실제 사용자 입력 중 함수 호출이 누락된 사례를 수집하여, SYSTEM_MESSAGE나 예시 프롬프트를 지속적으로 개선한다.\n\n이외에 잘 활용되는 함수에 대한 파인튜닝을 수행해 본다. \n\n마무리\n본 글은 ollama 를 이용한 gemma3 모델을 로딩해 Agent 개발 시 핵심이 되는 function call을 구현해 보았다. 실행해 보면 알겠지만, 펑션콜은 프롬프트 입력에 따라 민감하게 동작한다는 것을 알 수 있다. 그러므로, 함수 호출 방식은 적절히 LLM 오케스트레이션 및 튜닝되어야 한다는 것을 알 수 있다. \n\n\n레퍼런스\n\nWelcome Gemma 3: Google's all new multimodal, multilingual, long context open LLM\ngemini-samples/examples/gemma-function-calling.ipynb at main · philschmid/gemini-samples\nFunction calling with Gemma3 using Ollama | by Arjun Prabhulal | Google Cloud - Community | Mar, 2025 | Medium | Google Cloud - Community\nEnhancing Gemma 3’s Capabilities with Fine-Tuning for Function Calling | by Akriti Upadhyay | May, 2025 | Medium\nGeneral AI agent framework for smart buildings based on  large language models and ReAct strategy\nOpen-Source Tools for Agents | Data Science Collective\nThe Era of High-Paying Tech Jobs is Over | by Somnath Singh | Level Up Coding\nAGI-Edgerunners/LLM-Agents-Papers: A repo lists papers related to LLM based agent\nLLM for Optimisation in 3-D Space: A comparison with Deterministic optimisation methods | by Peter Eze | Crayon Data & AI | Medium\nDemystifying Generative AI Agents | by Dr Sokratis Kartakis | Google Cloud - Community | Medium\ncookbook/quickstarts/Function_calling.ipynb at main · google-gemini/cookbook",
    "reviews": [],
    "syllabus": [],
    "link": "http://daddynkidsmakers.blogspot.com/2025/06/gemma3-ollama-function-call.html",
    "pubDate": "2025-06-04T06:56:00.000Z",
    "creator": "Unknown",
    "categories": []
  }
]