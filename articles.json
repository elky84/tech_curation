[
  {
    "id": 1,
    "imageUrl": "",
    "title": "[MULTI] 즐거움 가득한 드퀘의 전설의 숲, 판타지 라이프 i",
    "description": "No description available",
    "reviews": [],
    "syllabus": [],
    "link": "https://bbs.ruliweb.com/news/board/11/read/2317",
    "pubDate": "Thu, 05 Jun 2025 18:25:23 +0900",
    "creator": "(RULIWEB`Д')/",
    "categories": [
      "리뷰"
    ]
  },
  {
    "id": 2,
    "imageUrl": "",
    "title": "토스, 근로복지공단과 상생형 직장어린이집 업무 협약",
    "description": "오는 12월까지 직장어린이집 설립… 인근 중소기업 자녀에게도 개방",
    "reviews": [],
    "syllabus": [],
    "link": "https://toss.im/tossfeed/article/Preschool",
    "pubDate": "Mon, 09 Jun 2025 09:04:00 GMT",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 3,
    "imageUrl": "",
    "title": "최고의 사무실은 바로 우리집 방구석",
    "description": "집에서는 도저히 일이 안 된다는 사람들을 많이 봤습니다.\n저도 그 기분을 압니다.\n다행히 저는 집에서도 집중을 잘 하는 편입니다.\n커다란 모니터도 2개나 있고, 책상과 의자의 높이, 키보드, 온도/습도. 소음.\n집에서 일을 잘하는 건 타고난 게 아닙니다. 하다보면 습관이 되어 편해지는 것.\n강력 추천하는 사무실은 바로 자기집 방구석입니다.\n\n함께 읽으면 좋은 글:\n사무실의 고요함이 너무 좋아\n1인 개발자 전성시대",
    "reviews": [],
    "syllabus": [],
    "link": "https://jeho.page/essay/2025/06/09/my-office-is-my-room.html",
    "pubDate": "2025-06-09T02:44:00.000Z",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 4,
    "imageUrl": "",
    "title": "제미나이 멀티모달로 고품질 맛집 블로그 콘텐츠 초고속 제작 방법, 무료 지침 공개",
    "description": "스마트폰 속 음식 사진, 블로그 수익으로 바꾸는 비법! 용량 부족 걱정 없이 애드센스 수익까지 얻는 맛집 블로그, AI가 알아서 만들어줘요!\n\n\n \n 스마트폰에 쌓여만 가는 수많은 음식 사진들, 용량 부족 경고가 뜨면 결국 아깝지만 지워야 하죠?   그런데 이 사진들을 전문적인 맛집 블로그로 올리고, 여기에 애드센스 수익까지 얻는다면 금상첨화 아닐까요? 지금 보고 계신 이 블로그 포스팅처럼 말이죠!\n놀라지 마세요. 이 모든 걸 이번에도 제미나이로 가능합니다! 제가 지난번에 제미나이를 활용한 초고속 블로그 글쓰기 영상을 올렸는데요, 정말 많은 분들이 \"실제로 그 지침을 어떻게 만드는지\" 알고 싶다고 하셔서 이번에는 그 비하인드를 공개하는 심화 강의를 준비했습니다.  \n \n우리가 AI와 효과적으로 대화하기 위해서는 그저 \"맛집 글 써줘\"라고 하는 것보다 훨씬 더 체계적인 접근이 필요해요. 정확한 지시와 명확한 가이드라인이 있어야 원하는 결과를 얻을 수 있죠. 그래서 오늘은 이 특별한 '젬 지침'을 만드는 과정까지 여러분께 낱낱이 공개하려고 합니다! 그리고 이번 지침의 핵심에는 단순 글쓰기가 아닌 제미나이의 멀티모달 기능이 있습니다. 이 기능이 왜 혁명적인지, 어떻게 하면 이를 최대한 활용할 수 있는지 함께 알아보겠습니다.\n \nAI 멀티모달 기능의 이해와 활용  \n여러분, 예전 AI는 텍스트만 읽을 수 있었어요. 하지만 최근에는 많은 LLM 모델들이 사진도 보고, 영상도 이해하는 '멀티모달' 능력을 갖추게 되었습니다. 마치 우리가 식당에서 메뉴를 선택할 때 사진과 설명을 함께 보는 것처럼요! 멀티모달이란 쉽게 말해서 다양한 형태의 정보를 동시에 이해하고 처리할 수 있는 인공지능 기술을 의미하는데요. 예를 들어 맛집 사진을 AI에게 보여주면, 예전의 AI는 \"이것은 사진입니다\"라고만 인식했지만, 멀티모달 기능이 있으면 \"이 사진은 식당 내부이고, 테이블 위에는 해물칼국수가 있으며, 옆에는 김치가 놓여있고, 사람들이 즐겁게 식사하고 있네요\"라고 더 자세하고 종합적으로 이해할 수 있게 된 거죠.\n \n여기서 재미있는 점은 AI가 이제 '맥락'을 읽을 수 있다는 거예요. 식당 내부 사진, 음식 사진, 메뉴판을 보고 \"아, 이건 맛집 리뷰를 위한 사진들이구나\"라고 파악합니다. 그래서 여러분이 찍은 맛집 사진을 몇 장만 넣어줘도 전문 블로거가 쓴 것 같은 리뷰를 뚝딱 만들어내는 것이 가능해진 겁니다.\n  알아두세요!\nAI가 아무리 똑똑해도 여러분의 머릿속 생각을 알아서 척척 맞춰주진 않아요. 구체적인 지시가 없으면, 기대한 결과가 나오기 어렵습니다.\n \n프롬프트 엔지니어링의 중요성 (기본적인 시도와 한계)  \n자, 이제 기본적인 방법으로 한번 시도해보겠습니다. 제가 천안에 사는데, 최근에 방문한 회사 근처 \"성거산 시골 막국수\"라는 곳의 사진 일곱 장을 준비했습니다. 이 사진들을 제미나이에 업로드하고 간단하게 \"이 사진들로 맛집 블로그 포스팅을 작성해줘\"라고 요청해보겠습니다. 천안 오시면 꼭 한 번 방문해 보세요. 맛있어요!!\n음... 나쁘지 않지만 뭔가 아쉬워요. '성거산 막국수: 막국수와 찰떡궁합 보쌈 맛집!'이라는 제목으로 기본적인 정보는 잘 담았지만, 뭔가 차별화된 느낌이 부족합니다. '식당은 넓은 주차 공간을 갖추고 있어, 차량으로 방문하기에 정말 편리했어요' '내부로 들어서니 생각보다 훨씬 넓고 쾌적한 공간이 펼쳐졌습니다'처럼 정보는 있지만 독자의 감성을 자극하는 생생한 묘사가 부족하죠.\n구분\n설명\n기대 효과\n\n\n\n\n명확한 역할 부여\n\"너는 지금부터 맛집 블로거야!\"\n글의 톤앤매너와 방향 설정\n\n\n구체적인 목표 제시\n\"사진 분석해서 생생한 맛집 리뷰 써줘.\"\nAI가 나아가야 할 명확한 길 제시\n\n\n결과 형식 지정\n\"HTML 코드로, 특정 스타일 적용해서.\"\n일관성 있고 사용 가능한 결과물 도출\n\n\n\n이럴 때 프롬프트 엔지니어링이 효과적인 것이죠. 프롬프트 엔지니어링은 AI에게 어떤 요청을 할 때, 원하는 결과물을 얻기 위해 질문이나 요청을 효과적으로 설계하는 기술입니다. 간단히 말해 AI와 잘 소통하는 방법을 찾는 거죠. 프롬프트 엔지니어링의 핵심은 AI에게 명확한 역할, 목표, 형식을 제공하는 것입니다. 이 프롬프트 엔지니어링을 기반으로 젬 지침을 만드는 것이죠.\n⚠️ 주의하세요!\nAI가 아무리 똑똑해도 여러분의 머릿속 생각을 알아서 척척 맞춰주지 않습니다. 구체적인 지시가 없으면, 기대한 결과가 나오기 어렵다는 점을 꼭 기억하세요!\n \nGoogle AI Studio 활용 (젬 지침 제작 환경)  \n오늘 저는 이 젬 지침을 제미나이 2.5 모델을 이용해 만들려고 합니다. 하지만 제미나이 사이트가 아닌 AI Studio라는 곳에서 지침을 만들게요.\n  AI Studio는?\nGoogle AI Studio는 구글에서 제공하는 개발자 친화적인 플랫폼으로, AI 모델을 더 세밀하게 제어하고 실험할 수 있는 공간입니다. 개발자, 학생, 연구자들이 프롬프트를 테스트하고 최적화하며, API 통합까지 준비할 수 있는 전문적인 환경이죠. AI Studio도 무료로 사용할 수 있습니다.\n특히 구글의 다양한 최신 AI 모델들을 가장 빨리 만날 수 있으니, 영상 설명란의 링크로 접속하셔서, 다양한 경험을 해 보세요. 흥미로운 사실은, 제가 이번에는 파라미터 조정 없이 기본값으로 진행했는데도 일반 제미나이와 결과가 달랐다는 점입니다. 왜 그럴까요?\nAI Studio vs. 일반 제미나이 차이점\n1) 첫 번째 단계: AI Studio는 기본 Temperature(창의성) 값이 1.0으로 설정되어 있어 더 다양하고 창의적인 결과물 생성\n2) 두 번째 단계: 일반 제미나이는 일관된 답변을 위해 이 값을 더 낮게 설정 가능\n→ AI Studio는 모델의 '날 것 그대로'의 동작을 확인하고 제어하는 데 중점을 둡니다. 따라서, 전문적인 콘텐츠 제작이나 복잡한 지침을 만들 때는 AI Studio에서 작업하는 것을 추천합니다.\n \n맛집 블로그 프롬프트 제작 과정 (1차 및 2차 수정)  ‍ ‍ \n자, 이제 본격적으로 맛집 블로그용 지침을 만들어 보겠습니다! AI STUDIO에 방문하신 후 우측에서 최신 AI 모델을 선택합니다. 아까 얘기한 것처럼 하단에 파라메터는 그대로 두고 첫 번째 프롬프트를 입력할게요. \"사용자 입력 정보와 사진을 기반으로 멀티모달 기능을 최대한 활용하여 구글 상위노출에 최적화된 맛집탐방 블로그 기사를 생성하고 그 결과물을 HTML 코드로 생성하는 젬 지침을 만들어\" 라고 요청하면 바로 맛집 블로거를 위한 지침을 생성합니다.\n  알아두세요!\n1차 요청에서는 사용자에게 너무 많은 정보를 요구했습니다. 식당명, 주소, 키워드, 한 줄 평 등. 편리하게 쓰려고 AI를 활용하는데, 정보 입력에 시간을 다 쓰면 본말이 전도됩니다.\n그래서 두 번째 요청에서는 복잡한 질문만 단순화했습니다. \"사용자에게 묻는 질문이 너무 많아. 처음에 식당명/지역, 주문음식/추가음식, 주변음식/반찬, 후식, 방문배경, 사진을 요청하면서 시작하고, 사용자가 입력을 하면 나머지 정보는 사진을 분석해서 대신 작성하게 지침을 수정해\" 이런 식으로 사용자가 5가지 질문과 사진 업로드만으로 맛집 블로그를 작성할 수 있도록 만들었어요. 중요한 점은, 제미나이의 멀티모달 기능을 활용해 사진을 직접 분석하여 블로그 내용에 반영하도록 한 것이죠.\n \n젬 지침 등록 및 테스트  \n자, 이렇게 해서 나온 2차 결과물을, 제미나이로 돌아가서 젬 지침에 등록을 하고, 결과를 확인해볼게요. 젬 관리자의 샘 젬 만들기에서 예를 들어 제목을 \"맛집 블로그 전문가\"라고 입력을 합니다.\n사례 주인공의 상황: '성거산 시골 막국수' 테스트\n1. 식당명/지역: 천안 성거, 성거산 시골 막국수\n2. 주문음식/추가음식: 비빔 막국수와 수육\n계산 과정: 간편한 입력으로 결과 확인\n1) 3. 주변 음식/반찬: 주변 음식 코너가 따로 있고 셀프임\n2) 4. 후식: 후식 없음\n최종 결과: 블로그 글 자동 생성!\n- 5. 방문배경: 5월 중순 26도의 이른 더위 점심시간. 팀원들과 점심 식사\n- 사진 업로드 → AI가 알아서 블로그 글 생성\n이런 식으로 결과를 확인하고 수정할 부분을 계속해서 AI와 대화를 해 나가면서 완성형으로 만들어 가는 것입니다. 완벽한 결과물은 처음부터 나오지 않습니다. AI와 지속적인 대화를 통해 결과를 확인하고 수정해나가는 '반복 최적화' 과정이 핵심입니다. 제가 이전 영상에서 공유해드린 지침들도 수십 번의 시행착오와 세밀한 조정을 거쳐 완성된 것들이랍니다.\n \n결과물 개선 (HTML 구조 및 디자인 문제점 해결)  \n자, 지금 우리가 받은 결과물을 살펴보면 세 가지 중요한 문제점이 보입니다. 이런 세부 사항들이 블로그 포스팅의 품질을 좌우하게 됩니다.\nHTML 코드 생성 문제: HTML 코드가 코드 블록 안에 제대로 생성되지 않았습니다.\n불완전한 HTML 구조: HTML이 완전한 형태의 웹페이지 구조(HTML, HEAD, BODY 태그 포함)로 표시되고 있습니다. 이는 블로그에 붙여넣을 때 구조적 충돌을 일으킵니다. 블로그 플랫폼은 이미 이 태그들을 가지고 있기 때문이죠.\nH1 태그 중복 문제: 블로그 플랫폼에서는 제목을 별도로 입력하는 필드가 있기 때문에, 본문 내에 H1 태그가 있으면 중복 제목이 생겨 SEO에 좋지 않고 디자인도 깨질 수 있습니다.\n이런 경우, AI에게 '블로그 본문에 추가해야 하므로 헤드, 바디 태그와 에이치원 태그가 없는 인라인 스타일로 변경해주세요. 제목은 별도로 입력할 것입니다.'라고 요청하세요. 그러면 블로그 플랫폼에 바로 붙여넣을 수 있는 최적화된 HTML 코드를 받을 수 있습니다. 위의 2가지 문제 개선을 위해, 1. 이 지침의 출력물 중 HTML 코드로 생성되는 결과물은 \"코드 블록\"으로 출력해, 2. 블로그 본문에 추가해야 하므로 헤드, 바디 태그와 에이치원 태그가 없는 인라인 스타일로 변경해. 라고 다시 지침 수정을 요청합니다.\n \n자, 수정된 지침으로 생성된 결과물을 보면 인라인 스타일의 에이치티엠엘 코드가 코드블록에서 생성되는 것을 확인할 수 있습니다. 그런데 이번엔 디자인이 별로입니다. 이럴 때는 \"좀 더 시각화된 결과물이 나올 수 있게 디자인을 개선해줘\" 또는 구체적인 디자인 지침을 주거나 이전 영상에서 소개한 디자인 템플릿을 업로드하고 \"첨부 디자인 스타일로 반영되게 수정해\"라고 요청하셔도 될 거 같습니다. 아, 그리고 디자인만 보시려면, 젬을 수정할 필요 없이, AI STUDIO의 수정된 지침의 코드만 복사해서 코드펜으로 가서 확인하면 됩니다.\n \n \n맛집 블로그 생성 지침 핵심 요약!\n✨ 프롬프트 엔지니어링: AI와 잘 소통하는 기술. 명확한 역할, 목표, 형식을 제공하여 원하는 결과물을 얻는 것이 핵심이죠.\n  멀티모달 기능 활용: 사진을 직접 분석해서 생생한 리뷰를 작성하도록 지시! 단순히 텍스트를 생성하는 것을 넘어, 시각 정보까지 통합하여 블로그 글의 퀄리티를 높입니다.\n  HTML 구조 및 디자인 최적화:\nHTML = (SEO 최적화) + (인라인 스타일) + (H1 태그 제외)\n ‍  반복 최적화의 중요성: 완벽한 결과물은 한 번에 나오지 않아요! AI와 지속적으로 대화하고, 결과를 수정하며 더 나은 지침을 만들어가는 과정이 필요합니다.\n이 지침으로 여러분도 전문 맛집 블로거로 거듭나세요!  \n자주 묻는 질문 ❓\nQ: 제미나이 멀티모달 기능은 어떤 점에서 혁신적인가요?\nA:   예전 AI는 텍스트만 이해했지만, 멀티모달 기능은 사진, 영상 등 다양한 형태의 정보를 동시에 이해하고 처리할 수 있어, AI가 맥락을 파악하고 더 풍부하고 정확한 콘텐츠를 생성할 수 있게 합니다.\nQ: AI Studio를 사용하는 이유가 무엇인가요?\nA:   AI Studio는 구글의 최신 AI 모델을 가장 먼저 접하고, Temperature(창의성) 값 등을 세밀하게 조정하며 프롬프트를 테스트하고 최적화할 수 있는 개발자 친화적인 환경을 제공합니다.\nQ: 블로그 포스팅용 HTML 코드를 생성할 때 주의할 점은?\nA:   블로그 플랫폼의 구조와 충돌하지 않도록 HEAD, BODY 태그와 H1 태그를 제외한 인라인 스타일로 코드를 생성해야 합니다.\nQ: 맛집 블로그를 위한 '젬 지침'은 어떻게 만드나요?\nA:   AI Studio에서 프롬프트 엔지니어링을 활용하여 AI에게 명확한 역할, 목표, 형식을 부여하고, 사용자가 최소한의 정보만 입력해도 되는 방식으로 반복 최적화 과정을 거쳐 만듭니다.\nQ: 완성된 블로그 콘텐츠를 어떻게 활용할 수 있나요?\nA:   생성된 고품질의 블로그 포스팅을 꾸준히 업로드하여 블로그 방문자를 늘리고, 애드센스 수익을 창출하며, 스마트폰 용량 확보와 맛집 기록까지 일석삼조의 효과를 누릴 수 있습니다.\nGEM 무료 지침 다운 로드\n반응형\n\n    \n    (adsbygoogle = window.adsbygoogle || []).push({});\n  \n\n    \n\n    \n맛집 블로그 생성 GEM 지침.zip\n0.01MB",
    "reviews": [],
    "syllabus": [],
    "link": "http://muzbox.tistory.com/483604",
    "pubDate": "Sun, 8 Jun 2025 14:28:03 +0900",
    "creator": "어떤오후의 프리웨어 이야기",
    "categories": [
      "AI, 미래기술/AI 챗봇 및 지침 무료 배포",
      "ai 멀티모달",
      "google ai studio",
      "html 블로그",
      "SEO 최적화",
      "맛집 블로그",
      "블로그 수익",
      "제미나이",
      "지침 생성",
      "콘텐츠 제작",
      "프롬프트 엔지니어링"
    ]
  },
  {
    "id": 5,
    "imageUrl": "",
    "title": "농구를 넘어 글로벌 콘텐츠 플랫폼이 된 NBA",
    "description": "데이터와 콘텐츠로 진화하는 스포츠 리그",
    "reviews": [],
    "syllabus": [],
    "link": "https://toss.im/tossfeed/article/moneyball-3",
    "pubDate": "Thu, 05 Jun 2025 06:00:00 GMT",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 6,
    "imageUrl": "",
    "title": "Deploy JetBrains Mellum Your Way: Now Available via NVIDIA NIM",
    "description": "Deploy Mellum as a production-grade LLM inside your own infrastructure – with NVIDIA. JetBrains Mellum – our open, focused LLM specialized on code completion – is now available to run as a containerized microservice on NVIDIA AI Factories. Using the new NVIDIA universal LLM NIM container, Mellum can be deployed in minutes on any NVIDIA-accelerated […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/ai/2025/06/deploy-jetbrains-mellum-your-way-now-available-via-nvidia-nim/",
    "pubDate": "Wed, 11 Jun 2025 11:15:00 +0000",
    "creator": "Conrad Schwellnus",
    "categories": [
      "jetbrains-ai",
      "news",
      "partners",
      "ai",
      "mellum",
      "partnership"
    ]
  },
  {
    "id": 7,
    "imageUrl": "",
    "title": "높은 성능의 AI 에이전트 구현을 위한 Gemma3 Function call 파인튜닝",
    "description": "이 글은 높은 성능의 AI 에이전트 구현을 위한 Gemma3 Function call 파인튜닝 방법을 설명한다.\n\n\n\nAI 에이전트에서 Function Call 개념\n\n\n준비물\n이 글은 gemma3를 이용해 function call 데이터셋을 튜닝한다. 해당 모델과 파일은 다음 링크를 참고한다.\n\ngoogle/gemma-3-4b-it · Hugging Face\n\nSalesforce/xlam-function-calling-60k · Datasets at Hugging Face\n\n\n모델을 사용하기 전에 google로부터 다음과 같이 사용 허가(grant)를 얻는다.\n\n\ngoogle/gemma-3-4b-it · Hugging Face\n\n\n터미널에서 다음처럼 패키지 설치한다.\n\npip install \"torch>=2.4.0\" tensorboard flash-attn\npip install git+https://github.com/huggingface/transformers@v4.49.0\npip install --upgrade datasets==3.3.2 accelerate==1.4.0 evaluate==0.4.3  bitsandbytes==0.45.3 trl==0.15.2 peft==0.14.0 protobuf==3.20.3  sentencepiece\n\n\n혹시 윈도우에서 다음과 같이 에러 발생하면 긴파일명 에러가 발생한 것이다.\n\n\n\nregedit 실행해 다음 레지스트리에서 오른쪽에서 LongPathsEnabled를 더블 클릭한 후 값(Data)을 1로 변경하고 확인한다.\n\nHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\FileSystem\n\n\n펑션콜 데이터셋 구조\n다음은 펑션콜 CoT 구조 데이터셋 예시이다.\n\n\nSalesforce/xlam-function-calling-60k · Datasets at Hugging Face\n\n\n\n모델 튜닝 코드 구현\n튜닝 코드를 다음과 같이 코딩한다. 우선, 라이브러리를 임포트한다.\n\nimport torch, json, gc, os\nfrom transformers import AutoTokenizer, Gemma3ForConditionalGeneration, BitsAndBytesConfig, set_seed\nfrom datasets import load_dataset\nfrom trl import SFTTrainer, SFTConfig\nfrom peft import LoraConfig, PeftModel, PeftConfig\nfrom enum import Enum\nfrom huggingface_hub import login\nfrom dotenv import load_dotenv\n\n\n\nAPI키, 모델 경로 등 기본 설정한다. 단, API키는 프로젝트에 .env 파일을 추가하고 HF_API_KEY=<허깅페이스 API KEY>가  내용에 포함되어 있어야 한다. 모델은 본인의 VRAM 크기를 고려해 설정한다. 참고로, 이 코드는 가장 작은 VRAM 을 사용하는 gemma-3-4b-it를 사용한다.\n\nload_dotenv()\nhf_token = os.getenv(\"HF_API_KEY\")\nlogin(token=hf_token)\n\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n\nseed = 42\nset_seed(seed)\n\ntorch_dtype = torch.bfloat16 if torch.cuda.get_device_capability()[0] >= 8 else torch.float16\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel_name = \"google/gemma-3-4b-it\"\ndataset_name = \"Salesforce/xlam-function-calling-60k\"\n\n\n\n모델 튜닝 파라메터를 설정한다. attn_implementation은 트랜스포머 어텐션 연산의 성능을 개선하기 위한 옵션이다. 적절히 선택하되, 환경 상 해당 알고리즘이 동작되지 않는다면 eager 옵션을 선택한다.\n\nmodel_kwargs = dict(\n    attn_implementation=\"flash_attention_2\", # \"eager\", \"sdpa\", \"flash_attention\", \"flash_attention_2\"\n    torch_dtype=torch_dtype,\n    device_map=\"auto\",\n    quantization_config=BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_use_double_quant=True,\n        bnb_4bit_quant_type='nf4',\n        bnb_4bit_compute_dtype=torch_dtype,\n        bnb_4bit_quant_storage=torch_dtype,\n        llm_int8_enable_fp32_cpu_offload=True\n    )\n)\n\nmodel = Gemma3ForConditionalGeneration.from_pretrained(model_name, **model_kwargs)\n\n\n\n함수호출을 위한 모델 튜닝에 필요한 특수 토큰을 정의한다.\n\nclass ToolCallSpacialTokens(str, Enum):\n    tools = \"<tools>\"\n    eotools = \"</tools>\"\n    think = \"<think>\"\n    eothink = \"</think>\"\n    tool_call=\"<tool_call>\"\n    eotool_call=\"</tool_call>\"\n    tool_response=\"<tool_response>\"\n    eotool_response=\"</tool_response>\"\n    pad_token = \"<pad>\"\n    eos_token = \"<eos>\"\n\n    @classmethod\n    def list(cls):\n        return [c.value for c in cls]\n\ntokenizer = AutoTokenizer.from_pretrained(\n    model_name,\n    pad_token=ToolCallSpacialTokens.pad_token.value,\n    additional_special_tokens=ToolCallSpacialTokens.list()\n)\n\n\n\n토큰 엠베딩 차원을 리사이즈한다.\n\ntokenizer.chat_template = \"\"\"{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{{ '<start_of_turn>' + message['role'] + '\\n' + message['content'] | trim + '<end_of_turn><eos>\\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\\n'}}{% endif %}\"\"\"\n\nmodel.resize_token_embeddings(len(tokenizer))\nmodel.to(device)\n\n\n\n모델튜닝을 위해 학습데이터를 모델에 맞게 전처리한다.\n\ndef preprocess(sample):\n    try:\n        tools = json.loads(sample[\"tools\"])\n        answers = json.loads(sample[\"answers\"])\n        user_query = sample[\"query\"]\n    except Exception as e:\n        print(\"Error decoding JSON:\", sample)\n        raise e\n\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": (\n                \"You have access to the following tools:\\n\\n\"\n                + \"\\n\\n\".join(f\"- {tool['name']}: {tool['description']}\" for tool in tools)\n                + \"\\n\\nUser query:\\n\" + user_query\n            )\n        },\n        {\n            \"role\": \"assistant\",\n            \"content\": \"\\n\".join(\n                f\"<function_call>\\n{json.dumps(answer)}\\n</function_call>\"\n                for answer in answers\n            )\n        }\n    ]\n\n    return {\n        \"text\": tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n    }\n\ndataset = load_dataset(dataset_name)\ndataset = dataset[\"train\"].map(preprocess, remove_columns=[\"id\", \"query\", \"answers\", \"tools\"])\ndataset = dataset.train_test_split(0.1)\nprint(dataset)\n\nprint(dataset[\"train\"][19][\"text\"])\n\n\n\n파인튜닝을 위해 LoRA와 SFT 설정한다.\n\npeft_config = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0.05,\n    r=16,\n    bias=\"none\",\n    target_modules=\"all-linear\",\n    task_type=\"CAUSAL_LM\",\n    modules_to_save=[\"lm_head\", \"embed_tokens\"] # make sure to save the lm_head and embed_tokens as you train the special tokens\n)\n\ntraining_arguments = SFTConfig(\n    output_dir=\"gemma-3-4b-it-thinking-function_calling-V0\",\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=32,\n    save_strategy=\"epoch\",\n    eval_strategy=\"epoch\",\n    logging_steps=50,\n    learning_rate=3e-4,\n    max_grad_norm=0.3,\n    weight_decay=0.1,\n    warmup_ratio=0.03,\n    lr_scheduler_type=\"constant\",\n    report_to=None,\n    bf16=True,\n    optim=\"paged_adamw_8bit\",\n    torch_compile=False,\n    push_to_hub=False,\n    num_train_epochs=3,\n    gradient_checkpointing=True,\n    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n    packing=False,\n    max_seq_length=512,\n    dataset_kwargs={\n        \"add_special_tokens\": False,\n        \"append_concat_token\": True,\n    }\n)\n\ntorch.cuda.empty_cache()\ntorch.cuda.ipc_collect()\ngc.collect()\n\n\n\n학습하고 결과를 저장한다.\n\ntrainer = SFTTrainer(\n    model=model,\n    args=training_arguments,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    # tokenizer=tokenizer,\n    peft_config=peft_config,\n)\n\ntrainer.train()\ntrainer.save_model()\n\n\n\n정상적으로 실행되면, 다음과 같이 함수 호출 데이터셋을 학습할 것이다.\n\n\n\n\nHF에 파인튜닝된 모델을 업로드한다. 그리고, 다시 다운로드하여 평가모드로 모델을 오픈한다.\n\n\ntrainer.push_to_hub(f'mac999/gemma-3-4b-it-thinking-function_calling-V0-{seed}', commit_message=\"Pushing fine-tuned model with function calling capabilities\")\n\ntokenizer.eos_token = \"<eos>\"\ntokenizer.push_to_hub(f\"mac999/\", token=True)\n\npeft_model_id = f\"mac999/gemma-3-4b-it-thinking-function_calling-V0-{seed}\" \ndevice = \"auto\"\nconfig = PeftConfig.from_pretrained(peft_model_id)\nmodel = Gemma3ForConditionalGeneration.from_pretrained(\"google/gemma-3-4b-it\",\n                                             device_map=\"auto\",\n                                             )\ntokenizer = AutoTokenizer.from_pretrained(peft_model_id)\nmodel.resize_token_embeddings(len(tokenizer))\nmodel = PeftModel.from_pretrained(model, peft_model_id)\nmodel.to(torch.bfloat16)\nmodel.eval()\n\n\n\n\n파인튜닝이 제대로되었는 지 function call을 테스트해본다.\n\nprompt = \"\"\"<bos><start_of_turn>user\nYou have access to the following tools:\n\n- numerical_derivative: Estimate the derivative of a mathematical function\n\nUser query:\nI need to estimate the derivative of the function y = sin(x) at x = π/4 and x = π. Can you help with that?<end_of_turn><eos>\n<start_of_turn>assistant\n\"\"\"\n\ninputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False).to(model.device)\n\noutputs = model.generate(\n    **inputs,\n    max_new_tokens=256,\n    do_sample=True,\n    temperature=0.01,\n    top_p=0.95,\n    repetition_penalty=1.1,\n    eos_token_id=tokenizer.eos_token_id\n)\n\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=False)\nprint(response)\n\n\n\n마무리\n파인튜닝 전과 후를 비교해 보면, 확실히 데이터셋에 있는 함수호출 방식이 제대로 생성되는 것을 확인할 수 있을 것이다.\n\n레퍼런스\n\nEnhancing Gemma 3’s Capabilities with Fine-Tuning for Function Calling | by Akriti Upadhyay | May, 2025 | Medium\nGeneral AI agent framework for smart buildings based on large language models and ReAct strategy\nOpen-Source Tools for Agents | Data Science Collective\nThe Era of High-Paying Tech Jobs is Over | by Somnath Singh | Level Up Coding\nAGI-Edgerunners/LLM-Agents-Papers: A repo lists papers related to LLM based agent\nAPIGen - Distilabel Docs\nAymanTarig/function-calling-v0.2-with-r1-cot · Datasets at Hugging Face\nBenchmarking Agent Tool Use",
    "reviews": [],
    "syllabus": [],
    "link": "http://daddynkidsmakers.blogspot.com/2025/06/ai-gemma3-function-call.html",
    "pubDate": "2025-06-06T10:33:00.000Z",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 8,
    "imageUrl": "",
    "title": "What Is Penetration Testing? Types, Processes, Tools, And Why It’s All Worth It",
    "description": "Penetration testing (or “pen testing”) is an authorized, simulated cyberattack designed to test the security of a production system. Ethical hackers perform penetration tests, emulating the behavior of cybercriminals to evaluate your software’s security and identify any weaknesses. During a pen test, these cybersecurity specialists use a range of techniques to attack a system. Once […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/teamcity/2025/06/what-is-penetration-testing/",
    "pubDate": "Mon, 09 Jun 2025 14:03:04 +0000",
    "creator": "Olga Bedrina",
    "categories": [
      "security",
      "testing",
      "best-practices"
    ]
  },
  {
    "id": 9,
    "imageUrl": "",
    "title": "Next edit suggestions available in Visual Studio GitHub Copilot",
    "description": "GitHub Copilot code completions, or gray text, are specialized in autocompleting unfinished code or providing helpful template code. In reality, coding activities are more diverse than writing new code. What if Copilot could better assist your coding not only with code generation, but your code editing activities as well? We are excited to announce next […]\nThe post Next edit suggestions available in Visual Studio GitHub Copilot appeared first on Visual Studio Blog.",
    "reviews": [],
    "syllabus": [],
    "link": "https://devblogs.microsoft.com/visualstudio/next-edit-suggestions-available-in-visual-studio-github-copilot/",
    "pubDate": "Mon, 09 Jun 2025 15:00:39 +0000",
    "creator": "Simona Liao",
    "categories": [
      "Artificial Intelligence",
      "GitHub Copilot",
      "Productivity",
      "Visual Studio",
      "Copilot",
      "Next Edits Suggestion"
    ]
  },
  {
    "id": 10,
    "imageUrl": "",
    "title": "깔끔한 이메일 주소",
    "description": "이메일 주소가 깔끔한 사람을 보면 좋은 느낌이 듭니다.\n그렇지 않고 한글 이름을 영어로 rlawogh(김재호) 한다거나,\n가장 인상적이었던 이메일은 r@google.com 였습니다.\n롭 파이크.\n깔끔한 이메일을 보면 이 사람은 신중하고 좋은 결정을 하는 사람이라는 생각이 듭니다.  \nP.S 저는 wlsdudtm 라는 이메일을 쓰는 동생에게 메일 주소 좀 바꾸라고 잔소리를 하곤 합니다.\n\n함께 읽으면 좋은 글:\n가장 기쁜 이메일",
    "reviews": [],
    "syllabus": [],
    "link": "https://jeho.page/essay/2025/06/09/neat-email-address.html",
    "pubDate": "2025-06-09T09:48:00.000Z",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 11,
    "imageUrl": "",
    "title": "영어 레벨의 함정 - 영포자 일병 구출작전 by 다독",
    "description": "\"한 배에서 아롱이 다롱이 난다.\" 라는 이야기 처럼, 우리 둘째는 첫째와 아주 많이 다릅니다. 성격, 외모 뿐 아니라, 좋아하는 것도, 잘하는 것도 아주 다릅니다. 그 중, 요즘 제가 신경을 많이 쓰는 부분은 언어에 대한 감각입니다.  어려서 부터, 영어를 좋아하고 쉽게 깨우친 오빠와 달리, 둘째는 오빠 보다 더 빨리 시작했고, 많은 시간을 썼음에도 불구",
    "reviews": [],
    "syllabus": [],
    "link": "https://brunch.co.kr/@@34qN/44",
    "pubDate": "Mon, 09 Jun 2025 07:25:19 GMT",
    "creator": "Reasontobe",
    "categories": []
  },
  {
    "id": 12,
    "imageUrl": "",
    "title": "대환대출로 신용대출 이자 줄일 수 있어요",
    "description": "이자 부담 줄일 수 있는 신용대출 갈아타기",
    "reviews": [],
    "syllabus": [],
    "link": "https://toss.im/tossfeed/article/tossmoment-11",
    "pubDate": "Thu, 05 Jun 2025 06:31:00 GMT",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 13,
    "imageUrl": "",
    "title": "SQL and NoSQL Query langauge support come to ReSharper!",
    "description": "ReSharper’s query language support for SQL and NoSQL provides C# developers with a more convenient way to work with SQL and NoSQL code directly in Visual Studio with ReSharper, supporting multiple SQL dialects beyond just T-SQL. It includes syntax highlighting, code analysis, auto-completion, and quick fixes to boost efficiency and catch issues early. Based on […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/dotnet/2025/06/10/sql-and-nosql-query-langauge-support-come-to-resharper/",
    "pubDate": "Tue, 10 Jun 2025 08:46:00 +0000",
    "creator": "Rachel Appel",
    "categories": [
      "net-tools",
      "data",
      "datagrip",
      "eap",
      "nosql",
      "query-language",
      "resharper",
      "sql"
    ]
  },
  {
    "id": 14,
    "imageUrl": "",
    "title": "(꽤 중요한) 투자자와의 소통",
    "description": "전에 내가 ‘투자자와 소통하기’라는 글을 썼다. 우리가 일하는 분야는 워낙 페이스가 빨라서 과거에 맞다고 했던 내용이 현재는 완전히 틀릴 수도 있고, 과거에 틀렸다고 했던 내용이 현재는 완전히 맞을 수도 있다. 하지만, 6년 전에 썼던 이 글은, 과거에도 맞았고 지금은 더 오지게 맞는 내용이라서 아무리 강조해도 지나치지가 않기 때문에, 비슷한 내용의 글을 한 번 더 쓴다.(...)",
    "reviews": [],
    "syllabus": [],
    "link": "https://www.thestartupbible.com/2025/06/why-regular-communication-with-your-investors-matters-more-than-you-think.html",
    "pubDate": "Wed, 11 Jun 2025 21:27:00 +0000",
    "creator": "Kihong Bae",
    "categories": [
      "Uncategorized",
      "FoundersAtWork",
      "fundraising",
      "general",
      "people",
      "Strong",
      "vc"
    ]
  },
  {
    "id": 15,
    "imageUrl": "",
    "title": "Kotlin for Server-Side Development: Community Content Roundup #2",
    "description": "The Kotlin community keeps delivering valuable content for server-side development. From gRPC best practices to hands-on Ktor tutorials and Spring integrations, here are the latest highlights. 📖 [Article] Kotlin Tips and Tricks You May Not Know: #6 — Inject Functions in Spring Boot – Elena van Engelen-Maslova shares how to inject functions in Spring Boot […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/kotlin/2025/06/kotlin-for-server-side-development-community-content-roundup-2/",
    "pubDate": "Tue, 10 Jun 2025 11:06:26 +0000",
    "creator": "Alyona Chernyaeva",
    "categories": []
  }
]