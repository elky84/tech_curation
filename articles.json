[
  {
    "id": 1,
    "imageUrl": "",
    "title": "악역영애 4컷 만화 - 37화, 찾으러가는데스와",
    "description": "No description available",
    "reviews": [],
    "syllabus": [],
    "link": "https://bbs.ruliweb.com/news/board/11/read/2414",
    "pubDate": "Wed, 28 Jan 2026 23:40:22 +0900",
    "creator": "｜RULIWEB｜",
    "categories": [
      "웹툰"
    ]
  },
  {
    "id": 2,
    "imageUrl": "",
    "title": "집중력 저하 시대, NotebookLM으로 '느린 읽기' 습관 재부팅하는 비법",
    "description": "넘쳐나는 정보의 홍수 속에서 우리는 점점 더 짧은 집중력을 갖게 됩니다. 길고 복잡한 글 앞에서 쉽게 좌절하고, 피상적인 이해에 만족하곤 하죠. 이제는 달라져야 합니다. 이 글은 구글 NotebookLM을 활용해 '느린 읽기' 습관을 되찾고, 정보의 깊이를 완전히 내 것으로 만드는 혁신적인 방법을 제안합니다. 단순한 요약을 넘어, 진정한 사고의 파트너로서 NotebookLM이 여러분의 지적 성장에 어떻게 기여하는지 함께 탐구해 보세요.\n\n\n혹시 이런 경험 없으신가요? 분명 중요하고 흥미로운 글인데, 몇 문단 읽기도 전에 스크롤을 내리거나 다른 탭으로 넘어가 버리는 경험 말이에요. 텍스트가 조금만 어려워져도 금세 집중력을 잃고, 결국엔 “다 읽긴 읽었는데… 뭘 읽었지?” 하는 허무함에 사로잡히곤 하죠. 솔직히 말씀드리면,  저는 이런 현상이 점점 더 심해지는 것 같다고 느껴요. 긴 에세이, 깊이 있는 보도 자료, 연구 기반의 글들을 마치 SNS 피드처럼 쓱 훑어보고 넘기는 습관이 우리에게 너무나도 익숙해져 버린 거죠.\n저 역시 다르지 않았습니다. 수많은 글들을 북마크에 쌓아두고 “나중에 읽어야지” 하면서도, 결국엔 제대로 소화하지 못하는 날들이 이어졌죠. 그러다 문득 깨달았어요. 익숙함이 곧 이해는 아니라는 사실을요. 단순히 읽는 행위를 넘어, 진정으로 내용을 내 것으로 만들고 싶다는 갈증이 커졌습니다. 처음에는 더 좋은 노트 필기법을 찾아 헤맸고, 다음에는 구글 NotebookLM이라는 도구를 만났습니다. 그리고 이 도구를 ‘느린 읽기’의 강력한 동반자로 활용하기 시작했죠. 이미 수많은 글들을 NotebookLM으로 처리하고 있었기에, 이걸 장문 글에 적용하는 것은 저에게 아주 자연스러운 실험이자 전환점이었습니다.\n  집중력 저하 시대, 왜 ‘느린 읽기’가 필요한가요?\n생각해 보면, 현대 사회는 우리에게 끊임없이 '빠르게'를 요구합니다. 정보의 양은 폭발적으로 증가하고, 우리는 그 속도에 발맞추지 못하면 뒤처질 것 같은 불안감에 시달리죠. 하지만 정말 역설적으로, 이럴 때일수록 '느리게' 읽는 습관이 더욱 중요해진다고 저는 생각합니다. 빠르게 훑고 지나가버리는 것은 결코 진정한 학습이나 사고의 확장을 가져다주지 못해요. 오히려 미묘한 맥락, 숨겨진 전제, 그리고 깊은 통찰을 놓치게 만들 뿐입니다.\n느린 읽기는 단순히 속도를 늦추는 것을 넘어선, 하나의 사고방식의 전환입니다. 텍스트와 진정으로 대화하고, 저자의 의도를 파고들며, 나아가 나 자신만의 관점을 형성하는 과정이죠. 이 과정에서 필요한 것이 바로 '인내심'입니다. 그런데 이 인내심, 혼자서 기르기 정말 어렵지 않나요? 그래서 저는 NotebookLM을 활용해 이 여정을 함께할 파트너를 만들기로 했습니다.\n  NotebookLM, 요약 도구를 넘어선 ‘사고의 동반자’로\n  요약 기계에서 벗어나 깊이 있는 이해로\n많은 분들이 NotebookLM을 ‘빠르게 답을 얻기 위한 요약 도구’로 활용하실 거예요. 문서를 업로드하고, 요약을 요청한 다음, 핵심만 쓱 훑어보는 방식 말이죠. 물론 이런 활용법도 유용하지만, 솔직히 이건 우리가 다른 콘텐츠를 소비하는 성급한 방식과 크게 다르지 않다고 봅니다. 저 역시 그랬고요. 그러다 어느 순간, 이렇게 얻은 지식은 뇌리에 오래 남지 않는다는 좌절감을 느끼기 시작했습니다. 이 경험이 저를 변화시켰어요.\n저는 NotebookLM에 전체 문서를 요약해 달라는 요청을 멈췄습니다. 대신, 제가 인내심을 가지고 장문의 글을 읽는 동안 함께 걸어가는 ‘읽기 파트너’로 대하기 시작했죠. 지름길을 찾는 대신, 목적지에 도달하는 여정 자체를 중요하게 여기는 방식으로요. 목표는 더 이상 속도가 아니었습니다. 요약 과정에서 사라질 수 있는 모든 미묘한 뉘앙스, 숨겨진 의미까지 완벽하게 이해할 만큼 충분히 콘텐츠와 함께 머무는 것. 그것이 저의 새로운 목표가 되었어요.\n\n\n  텍스트 중심 접근: 하나의 글로 하나의 노트를!\n이러한 새로운 읽기 및 학습 시스템을 구축하기 위해, 저는 길거나 까다로운 텍스트 하나당 별도의 NotebookLM 노트북을 하나씩 만들어요. 예를 들어, 경제학 논문 하나를 읽을 때 그 논문만을 위한 노트북을 따로 만드는 식이죠. 이 ‘단일 텍스트 중심 접근’은 생각보다 훨씬 중요합니다. 왜냐하면 이렇게 해야만 글의 맥락을 온전히 유지할 수 있고, 아직 충분히 이해되지 않은 아이디어가 마구잡이로 섞여 혼란이 가중되는 것을 막을 수 있거든요. 하나의 기사나 PDF가 NotebookLM에서 저의 연구와 학습을 위한 지식 기반을 구축하는 출발점이 되는 셈이죠.\n⚙️ 느린 읽기를 강제하는 나만의 맞춤 지침\n제가 NotebookLM을 ‘느린 읽기 파트너’로 활용할 수 있었던 핵심적인 이유 중 하나는 바로 간단한 ‘사용자 지정 지침(Custom Instruction)’ 덕분입니다. NotebookLM의 ‘Configure notebook > Custom’ 메뉴에서 자신만의 지침을 입력할 수 있는데, 제 설정은 대략 이렇습니다.\n\n\n  나만의 NotebookLM 맞춤 지침 예시\n너는 나의 느린 읽기 파트너다. 내가 명시적으로 요청하지 않는 한, 전체 섹션을 요약하지 말 것.\n내가 문단을 붙여넣으면, 그것을 신중하게 바꿔 말해 주고, 전제(assumptions)를 드러내며, 모호한 부분을 강조해 달라.\n결론보다 질문을 우선해 달라.\n이 단 한 가지 지침이 NotebookLM과의 모든 대화 톤을 완전히 바꿔 놓았어요. 때로는 NotebookLM의 속도를 늦추는 ‘과속 방지턱’처럼 작동해서, 제가 텍스트에 더 오래 머물게 해 줍니다. NotebookLM은 제가 잠시 멈춰 서서, 글이 던지는 질문들을 깊이 곱씹어 보도록 만들어요. 덕분에 저는 피상적인 이해를 넘어, 글의 심층적인 구조와 의미를 탐구할 수 있게 됩니다.\n  한 문단씩 뜯어보기: ‘혼란’을 ‘진전’으로 만드는 비법\n✍️ 지름길을 거부하는 탐구적 프롬프트 활용\n첫 번째 읽기에서는 NotebookLM이 제안하는 질문들을 활용해 전체적인 맥락을 한번 훑어봅니다. 중요한 것은 두 번째 읽기부터예요. 정말 복잡하고 어려운 글을 만났을 때, 저는 주요 출처를 선택 해제한 상태에서 한 문단 또는 몇 개의 문단만 NotebookLM에 붙여넣습니다. 이처럼 제한적으로 접근하는 것은 의도적인 전략입니다. 어려운 글은 종종 몇 문장 안에 여러 아이디어를 압축해 담고 있는데, 우리가 너무 빠르게 읽으면 피상적인 해석에 머물러 핵심을 놓치기 쉽거든요. 한 문단씩 천천히 읽으면 자연스럽게 속도가 느려질 수밖에 없습니다.\nNotebookLM의 기본 질문을 그대로 사용하는 대신, 저는 저만의 ‘후속 탐구 질문’을 던집니다. 예를 들어, 이런 식이죠.\n이 문단의 복잡성을 알아차리도록 신중한 독자를 강제로 느리게 만들 다섯 가지 탐구 질문을 생성해 달라.\n이 문단은 독자나 더 넓은 맥락에 대해 어떤 전제를 깔고 있는가?\n이 논증의 어느 부분이 앞선 텍스트의 섹션들에 가장 크게 의존하는가?\n이 문단은 훑어읽을 경우 어떻게 오해될 수 있는가?\n사려 깊은 비평가는 여기서 무엇을 문제 삼을까?\n이러한 프롬프트들은 제 이해의 엄청난 공백을 여과 없이 드러냅니다. 그런데 이게 바로 목적이에요! 질문과 함께 다시 읽을 때, 혼란은 더 이상 실패처럼 느껴지지 않고, 오히려 진정한 진전처럼 느껴지기 시작합니다. 시간이 지나면서 저는 미묘하지만 중요한 변화를 알아차렸어요. 한 문단을 세 번째로 읽을 때는 더 이상 단순히 ‘저자가 무엇을 말하는가?’를 묻지 않고, ‘왜 이런 방식으로 말했는가?’라는 관점에 초점을 맞추게 된다는 점이죠. 저자의 의도와 배경까지 파고드는 겁니다.\n\n\n\n\n\n구분\n빠른 훑어읽기 (Superficial Reading)\nNotebookLM 활용 느린 읽기 (Deep Reading)\n\n\n\n\n목표\n정보의 핵심 파악, 빠른 소비\n맥락, 뉘앙스, 저자의 의도 심층 이해\n\n\n활용 방식\n요약 기능 위주, 자동 질문 활용\n문단별 탐구 프롬프트, 맞춤 지침\n\n\n결과\n피상적인 이해, 빠른 망각\n깊이 있는 지식 축적, 비판적 사고력 증진\n\n\n\n✅ 능동적 마이크로 드릴: 이해를 위한 작은 근육 운동\n  수동적 노트 대신 짧고 집중적인 연습으로\n전통적인 노트 필기 방식, 특히 복잡한 자료 앞에서는 한계를 드러내는 경우가 많습니다. 하이라이트를 아무리 쳐도 쌓이기만 할 뿐, 실제 이해로 이어지지 않는 경우가 허다하죠. 요약 역시 뉘앙스를 죽이고 핵심을 뭉뚱그려 버리기 일쑤고요. 더 나쁜 것은, 단순히 읽거나 훑어보는 것만으로도 ‘내가 이해하고 있다’는 착각에 빠지기 쉽다는 점입니다. 저는 이런 함정을 피하기 위해 새로운 방법을 찾았습니다.\n저는 각 주요 섹션을 읽고 난 뒤, NotebookLM에게 작고 표적화된 ‘마이크로 드릴(Micro Drill)’을 생성해 달라고 요청합니다. 이것들은 전통적인 의미의 학습 보조 도구라기보다는, NotebookLM의 강력한 학습 기능을 활용해 저의 약한 이해 포인트를 초기에 드러내는 역할을 해요. 제가 자주 사용하는 프롬프트는 다음과 같습니다.\n이 논증을 정말로 이해했는지 확인하는 세 문항 퀴즈를 생성해 달라.\n이 섹션을 주장과 이유를 연결하는 “왜–왜냐하면” 사슬로 바꿔 달라.\n하나의 전제가 제거되면 이 섹션에서 어떤 아이디어가 무너질까?\n이 마이크로 드릴들이 정말 효과적인 이유는 그 ‘범위’에 있습니다. 즉시 완료할 수 있을 만큼 짧지만, 동시에 제 이해의 공백을 명확히 드러낼 만큼 충분히 까다롭죠. 만약 막히는 지점이 생긴다면, 저는 억지로 앞으로 밀고 나가지 않습니다. 대신, 마찰을 일으킨 바로 그 문단으로 돌아가 다시 읽으며 문제의 핵심을 파고들어요.\n⚠️ 주의하세요!\n막히는 부분이 생겼을 때 절대 서둘러 넘어가거나 ‘이해한 척’하지 마세요. 그 부분이 바로 여러분의 깊은 이해를 방해하는 지점입니다. 다시 돌아가 꼼꼼히 확인하고 질문하는 습관을 들이는 것이 중요해요.\n제가 직접 만든 퀴즈 프롬프트는 NotebookLM의 기본 퀴즈나 플래시카드 도구와는 다른 결과물을 내놓습니다. 물론 NotebookLM의 기본 도구들도 글 전체를 다 읽은 뒤 최종 점검용으로 사용하기에 가치가 있지만, 제가 만든 마이크로 드릴은 실시간으로 제 이해도를 점검하고 사고를 강제하는 상호작용형 테스트에 가깝습니다. 덕분에 저는 훨씬 더 능동적으로 텍스트와 씨름하며 지식을 쌓아갈 수 있게 되었어요.\n\n\n\n  핵심 요약\n1. NotebookLM을 요약 도구가 아닌 '느린 읽기 파트너'로 인식하고, 질문을 우선시하는 맞춤 지침을 설정하세요.\n2. 복잡한 텍스트는 한 문단씩 집중적으로 읽으며, 지름길 프롬프트를 통해 저자의 숨겨진 전제와 미묘한 뉘앙스를 파악하세요.\n3. 각 섹션 뒤에 짧은 '마이크로 드릴'을 활용해 능동적으로 이해도를 점검하고, 약한 부분을 즉시 보완하세요.\n4. 결정적인 요소는 '인내심'! 작은 단위로 시작하여 점진적으로 느린 읽기 습관을 길러나가세요.\n이러한 전략을 통해 NotebookLM은 단순한 정보 처리 도구를 넘어, 여러분의 사고를 심화시키고 진정한 지식 습득을 돕는 강력한 조력자가 될 것입니다.\n✨ 느린 읽기는 하루하루 다시 길러갈 수 있는 기술\n이런 방식으로 NotebookLM을 활용한다고 해서 글을 더 빨리 끝내게 된 것은 아닙니다. 아니, 정확히 말하면, 더 빨리 끝내기보다는 글 속으로 다시 돌아오게 만드는 힘을 얻었습니다. 유튜브 긴 재생목록으로 학습할 때도 비슷한 접근법을 사용하고 있는데, 확실히 이해도가 남달라요. 속도를 늦추고, 범위를 제한하며, 더 나은 질문을 끊임없이 던지면, 다시 읽는 행위 자체가 호기심을 자극하고 즐거움을 주는 과정이 됩니다.\n물론, 어떤 AI 도구도 대신해 줄 수 없는 한 가지 필수 요소가 있습니다. 바로 ‘인내심’입니다. 처음부터 완벽하게 모든 글에 적용하려 하지 마세요. 어려운 텍스트를 위해 NotebookLM을 사용해 보고 싶다면, 작게 시작하는 것이 중요해요. 하나의 긴 기사, 그중에서도 하나의 문단, 딱 한 번의 ‘다시 읽기’부터 시작해 보세요. 그것만으로도 2026년 여러분의 깊이 읽는 습관을 재부팅하기에 충분할 겁니다. 새로운 지적 여정을 응원합니다!\n❓ 자주 묻는 질문 (FAQ)\nQ1: NotebookLM의 ‘느린 읽기’ 방법이 모든 유형의 글에 효과적인가요?\nA1: 아니요, 이 방법은 주로 복잡하거나 깊이 있는 이해가 필요한 장문의 텍스트에 특히 효과적입니다. 뉴스 기사나 짧은 정보성 글에는 일반적인 NotebookLM의 요약 기능을 활용하는 것이 더 효율적일 수 있습니다. 중요한 것은 글의 목적과 자신의 학습 목표에 맞춰 유연하게 적용하는 것입니다.\nQ2: NotebookLM 맞춤 지침을 설정하는 것이 정말 큰 차이를 만드나요?\nA2: 네, 예상보다 훨씬 큰 차이를 만듭니다. 맞춤 지침은 NotebookLM이 여러분의 의도에 맞춰 정보를 처리하고 응답하도록 유도하여, 단순한 답변을 넘어 사고를 촉진하는 파트너 역할을 수행하게 합니다. ‘질문을 우선해 달라’는 지침이 특히 효과적이에요.\nQ3: ‘마이크로 드릴’이 전통적인 퀴즈와 다른 점은 무엇인가요?\nA3: 마이크로 드릴은 짧고 특정 섹션에 집중하며, 정답을 맞히기보다 이해의 공백을 드러내고 사고를 유도하는 데 중점을 둡니다. 전통적인 퀴즈가 전체적인 지식 점검이라면, 마이크로 드릴은 실시간으로 미묘한 이해 부족을 파고드는 ‘근육 운동’에 가깝습니다.\nQ4: ‘느린 읽기’ 습관을 들이는 데 가장 중요한 것은 무엇인가요?\nA4: 가장 중요한 것은 ‘인내심’과 ‘작게 시작하는 용기’입니다. 처음부터 완벽하려 하기보다, 작은 성공 경험을 통해 점진적으로 습관을 확장해 나가는 것이 중요해요. 혼란을 실패로 여기지 않고, 더 깊이 파고들 기회로 삼는 태도가 필요합니다.\n\n\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"NotebookLM의 ‘느린 읽기’ 방법이 모든 유형의 글에 효과적인가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"아니요, 이 방법은 주로 복잡하거나 깊이 있는 이해가 필요한 장문의 텍스트에 특히 효과적입니다. 뉴스 기사나 짧은 정보성 글에는 일반적인 NotebookLM의 요약 기능을 활용하는 것이 더 효율적일 수 있습니다. 중요한 것은 글의 목적과 자신의 학습 목표에 맞춰 유연하게 적용하는 것입니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"NotebookLM 맞춤 지침을 설정하는 것이 정말 큰 차이를 만드나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"네, 예상보다 훨씬 큰 차이를 만듭니다. 맞춤 지침은 NotebookLM이 여러분의 의도에 맞춰 정보를 처리하고 응답하도록 유도하여, 단순한 답변을 넘어 사고를 촉진하는 파트너 역할을 수행하게 합니다. ‘질문을 우선해 달라’는 지침이 특히 효과적이에요.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"‘마이크로 드릴’이 전통적인 퀴즈와 다른 점은 무엇인가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"마이크로 드릴은 짧고 특정 섹션에 집중하며, 정답을 맞히기보다 이해의 공백을 드러내고 사고를 유도하는 데 중점을 둡니다. 전통적인 퀴즈가 전체적인 지식 점검이라면, 마이크로 드릴은 실시간으로 미묘한 이해 부족을 파고드는 ‘근육 운동’에 가깝습니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"‘느린 읽기’ 습관을 들이는 데 가장 중요한 것은 무엇인가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"가장 중요한 것은 ‘인내심’과 ‘작게 시작하는 용기’입니다. 처음부터 완벽하려 하기보다, 작은 성공 경험을 통해 점진적으로 습관을 확장해 나가는 것이 중요해요. 혼란을 실패로 여기지 않고, 더 깊이 파고들 기회로 삼는 태도가 필요합니다.\"\n      }\n    }\n  ]\n}",
    "reviews": [],
    "syllabus": [],
    "link": "https://muzbox.tistory.com/483705",
    "pubDate": "Thu, 29 Jan 2026 16:03:54 +0900",
    "creator": "어떤오후의 프리웨어 이야기",
    "categories": [
      "AI, 미래기술/AI 인사이트",
      "AI활용법",
      "notebooklm",
      "느린읽기",
      "독서습관",
      "디지털독서",
      "생산성도구",
      "심층독서",
      "정보과부하",
      "집중력향상",
      "학습전략"
    ]
  },
  {
    "id": 3,
    "imageUrl": "",
    "title": "코드 품질 개선 기법 30편: (투명한) 운명의 붉은 실",
    "description": "이 글은 2024년 6월 20일에 일본어로 먼저 발행된 기사를 번역한 글입니다.LY Corporation은 높은 개발 생산성을 유지하기 위해 코드 품질 및 개발 문화 개선에 힘쓰고...",
    "reviews": [],
    "syllabus": [],
    "link": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-30",
    "pubDate": "Fri, 23 Jan 2026 08:00:00 GMT",
    "creator": "Unknown",
    "categories": []
  },
  {
    "id": 4,
    "imageUrl": "",
    "title": "A Year of Creator Wins: Highlights from the JetBrains Content Creators Program 2025",
    "description": "With more than 200 new members joining the JetBrains Content Creator community, we were bound to hear some exciting new things from them in 2025. Our members were steadily increasing in number, honing their YouTube videos, tirelessly keeping up with the posting schedule, and providing JetBrains perks directly to their audiences. But the real results […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/blog/2026/01/27/content-creators-wins/",
    "pubDate": "Tue, 27 Jan 2026 09:44:39 +0000",
    "creator": "Boris Ageev",
    "categories": [
      "community",
      "community-support",
      "content-creators-program",
      "rider"
    ]
  },
  {
    "id": 5,
    "imageUrl": "",
    "title": "Building AI Agents in Kotlin – Part 5: Teaching Agents to Forget",
    "description": "Previously in this series: Agents eventually run out of context. When they do, they crash, and you lose everything mid-task. We’ve been running GPT-5 Codex since Part 1. It scores 0.58 on SWE-bench Verified. We tried Claude Sonnet 4.5 next, which scored 0.6 and ran faster on most tasks. But complex problems hit Claude’s 200K […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/ai/2026/01/building-ai-agents-in-kotlin-part-5-teaching-agents-to-forget/",
    "pubDate": "Mon, 26 Jan 2026 16:09:12 +0000",
    "creator": "Fatimazahra El Akkary",
    "categories": [
      "kotlin",
      "tutorials",
      "ai",
      "ai-agents"
    ]
  },
  {
    "id": 6,
    "imageUrl": "",
    "title": "R&amp;D 합격은 성과지표(KPI)에서 갈린다. - 창업(스타트업)",
    "description": "1. 왜 R&D 지원사업은 '성과지표'에서 합격이 갈릴까  처음 R&D를 신청하는 스타트업 대표님들이 가장 많이 놓치는 지점은 한 가지입니다. 정부 R&D는 '좋은 기술' 자체보다 예산 투입의 결과를 '증명 가능한 형태'로 설계했는지를 봅니다.  평가위원 입장에서 사업계획서는 결국 아래 질문에 대한 답입니다.  이 과제는 무엇을 만들고(산출물) 어떤 기준으",
    "reviews": [],
    "syllabus": [],
    "link": "https://brunch.co.kr/@@LOc/327",
    "pubDate": "Fri, 23 Jan 2026 03:32:32 GMT",
    "creator": "고명환",
    "categories": []
  },
  {
    "id": 7,
    "imageUrl": "",
    "title": "The AI Evolution of Graph Search at Netflix",
    "description": "No description available",
    "reviews": [],
    "syllabus": [],
    "link": "https://netflixtechblog.com/the-ai-evolution-of-graph-search-at-netflix-d416ec5b1151?source=rss----2615bd06b42e---4",
    "pubDate": "Mon, 26 Jan 2026 19:01:27 GMT",
    "creator": "Netflix Technology Blog",
    "categories": [
      "search-engines",
      "graphql",
      "software-engineering",
      "ai",
      "llm"
    ]
  },
  {
    "id": 8,
    "imageUrl": "",
    "title": "AI로 레거시 환경 개선하기",
    "description": "요즘의 개발자 채용은 채용하는 팀과 채용하지 않는 팀으로 완전히 나뉘어 있다.\n비즈니스 속도가 안정권에 들어섰고, 레거시가 충분히 해소된 팀은 개발자 채용을 거의 하지 않는다.\n누군가 퇴사를 해도 그 자리를 채우지 않는다.\n반면, 여전히 비즈니스 속도를 내는 팀은 공격적으로 개발자를 채용하고 있다.\n이런 속도를 유지하는 팀은 기술 부채와 레거시를 계속해서 쌓이는 것으로만 보며, 해결해야 할 대상으로 보지 않는다.\n지금의 인원으로 속도가 점점 떨어진다면, 더 많은 개발자를 채용함으로써 계속해서 그 속도를 유지한다.\n속도를 최우선으로 하면서 쌓이는 부채보다 비즈니스 성장이 떨어지는 것이 더 무서운 일이기 때문이다.\n개발자를 공격적으로 채용하고 있으니 그만큼 개발문화와 개발 환경이 좋을 것이라 예상했으나 첫 온보딩때 그 예상은 산산히 부서진다.\n해당 프로젝트의 히스토리를 아는 개발자는 모두 퇴사한 상태라 알려줄 사람이 없다.\n개발/정책 문서가 없어서 흩어진 슬랙 메시지, 극 초기의 컨셉만 담은 노션의 몇 안되는 페이지들, 주석이 없는 애플리케이션 코드, comment가 없는 테이블 스키마 등을 보면서 분석해야 한다.\n시스템 구조를 알 수 있는 방법이 없어 지금 호출하고 있는 API에 신규 속성을 추가하려면 누구와 이야기해야 할지, 어느 프로젝트를 봐야 할지도 알 수 없다.\n테스트 코드가 없어 지금의 이 코드를 수정하면 무슨 일이 벌어질지 알 수 없다. 테스트 코드를 넣자니 인풋/아웃풋이 무엇이어야 하는지조차 알 수가 없다.\n히스토리와 기능이 전혀 분석이 되지 않는 상태에서 PO/PM은 새로운 기능에 대해 요구사항 분석과 언제까지 가능한지 일정을 알려달라 한다.\n기술 리더는 기술 부채를 해결하는 것 보다 제품지표/비즈니스 성과에 대해서 더 중요하다고 이야기한다. 레거시를 해결할 시간 따위 여기선 별도로 할당 받을 수 없는 상황이다.\n이렇게 레거시가 가득한 환경에선 도저히 일할 수 없을 것 같다는 생각이 매일 출근마다 머릿속을 가득 채운다.\n하지만, 지금의 개발자를 채용하는 대부분의 회사는 이렇게 레거시가 가득할 확률이 높다.\n그렇지 않으면 이미 많은 개발자가 있음에도 더 많은 개발자를 채용할 이유가 요즘에 찾기가 어렵기 때문이다.\n\"레거시 코드 활용 전략\", \"리팩토링 데이터베이스\" 등 점진적으로 레거시를 해소할 여러 노하우가 담긴 책들이 많다.\n하지만, 이 책을 지금 읽어보고 현재의 내 상황에 하나하나 대입하기엔 시간이 너무 부족하다.\n수습 기간의 카운트다운은 이미 시작되었다.\n조직에서는 새로 합류한 나에 대한 평가를 계속해서 하고 있는 상황에서, \"레거시가 심해서 도저히 일할 수가 없어요\"라고만 말할 수도 없다.\n그렇게 얘기했다가는 이 사람들이 나와 함께 할 필요가 없어지니.\n막막한 이 상황을 도대체 어디서부터 풀어나가야 할까?\n다행히 이제는 개발자에겐 AI라는 막강한 도구가 있다.\n개발자를 적극적으로 채용하는 회사로 합류하는 모든 개발자들에겐 레거시 환경과 기술 부채 환경은 기본값으로 봐야한다.\n그리고 그런 막막한 상황에서 우린 AI의 도움을 어떻게 받을 것인지를 고민해야 한다.\n기존 코드를 분석해서 기능 명세서를 만드는 것도,\n로그를 분석해서 테스트 코드를 만드는 것도,\n암호 같던 PO/PM의 기획서를 분석하는 것도,\n예전이라면 며칠씩 걸릴 것 같던 레거시 분석 + 기존 기능 수정이 이제는 단 몇시간만에 해결될 수 있는 상황이다.\n근데 레거시에 어떻게 AI의 도움을 받을 것인지도 공부해야 할 대상이 아닌가?\n이번에 재민님의 레거시와 AI 활용편 강의가 출시되었다.\n재민님은 17년차 개발자로, 토스페이먼츠 기술이사(Director of Engineering), 우아한형제들 서버 개발자 등을 거치며 레거시가 가득한 수많은 상황을 경험하고 해결해온 시니어이다.\n그리고 이젠 어떻게 하면 AI의 도움을 받으며 레거시 해결과 비즈니스 속도감을 유지하는지에 대해 노하우를 나누어 주신다.\n딱 9시간이면 \"막막한 레거시 환경에서 어떻게 적응하고 성과를 낼 것인가\" 에 대해 재민님의 노하우를 배워볼 수 있다.\n새 회사에, 새 팀에 합류해야 할 개발자분들이나,\n현재 기술 부채가 있는 환경에서 일하고 있는 개발자분들이라면 이번 재민님의 강의를 적극 추천한다.\nhttps://inf.run/ZzaQn\n현재 얼리버드로 30% 할인 중이니 할인 기회를 놓치지 않으시길 추천드린다.",
    "reviews": [],
    "syllabus": [],
    "link": "https://jojoldu.tistory.com/859",
    "pubDate": "Mon, 26 Jan 2026 10:22:35 +0900",
    "creator": "향로 (기억보단 기록을)",
    "categories": [
      "생각정리",
      "기술 부채",
      "김재민",
      "레거시",
      "레거시코드 활용 전략",
      "리팩토링 데이터베이스",
      "토스"
    ]
  },
  {
    "id": 9,
    "imageUrl": "",
    "title": "JIGCAT 프로젝트 작업중 - 고양이 직소 퍼즐",
    "description": "직소 퍼즐 소스를 다른팀에다 만들어줬는데\n제 프로젝트에도 하나 만들어봤습니다.\n관리툴로 그림을 올리면 \n앱에 적용되게 만드는게 목표입니다.\n \nv1 ~ 6 \n서버에 이미지를 올리면 게임 스테이지에 표시되는게 목표였습니다.\n미완성이라 보여줄게 없습니다.\n \nv7 - 2026-01-30\n- 광고 / 배너 + 전면\n- 메인화면 배경에 클리어한 그림 표시\n영상: https://www.youtube.com/shorts/z0Zk7W0JVco",
    "reviews": [],
    "syllabus": [],
    "link": "https://serverdown.tistory.com/1566",
    "pubDate": "Thu, 29 Jan 2026 19:19:10 +0900",
    "creator": "SIDNFT",
    "categories": [
      "프로그래밍/자작",
      "1인개발",
      "1인게임",
      "JIGCAT",
      "부업",
      "인디게임"
    ]
  },
  {
    "id": 10,
    "imageUrl": "",
    "title": "일관성 있는 Agentic AI Workflow를 팀 프로젝트에 적용하는 법 #2",
    "description": "전편에서 제안한 원칙들을 어떻게 팀 프로젝트에 적용하는지에 대해 Claude Code Plugin / Skills / Hooks를 이용하여 구체적인 예시를 살펴본다. 케이스: LLM의 작업 진행사항을 이슈 트래커와 동기화하기 언젠가 AI의 개발 산출물이 인간의 수준을 아득히 뛰어넘는 날이 오면 더 이상 작업 이력을 추적할 필요가 없어지는 시점이 올지도 모른다.하지만 인간지능과 인공지능이 공동의 산출물을 함께 작업하는 현시점에서는 기존의 방식대로 […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://01010011.blog/2026/01/30/how-to-build-a-consistent-agentic-ai-workflow-for-team-projects-2/",
    "pubDate": "Fri, 30 Jan 2026 01:07:34 +0000",
    "creator": "bahamoth",
    "categories": [
      "programming"
    ]
  },
  {
    "id": 11,
    "imageUrl": "",
    "title": "How We Made Variable Inspections 87 Times Faster for Unreal Engine in Rider",
    "description": "If you’ve ever expanded a complex Unreal Engine variable in Rider’s debugger and had time to contemplate your life choices, this post is for you. We’ve rewritten our expression evaluator, and the results are dramatic: Variable inspection is up to 87 times faster on warm runs and 16 times faster on cold ones. The debugger […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/dotnet/2026/01/26/how-we-made-variable-inspections-87-times-faster-for-unreal-engine-in-rider/",
    "pubDate": "Mon, 26 Jan 2026 13:08:53 +0000",
    "creator": "Sasha Korepanov",
    "categories": [
      "net-tools",
      "rider",
      "eap",
      "game-debugging",
      "game-development",
      "lldb",
      "unreal-engine"
    ]
  },
  {
    "id": 12,
    "imageUrl": "",
    "title": "Rust vs JavaScript & TypeScript: performance, WebAssembly, and developer experience",
    "description": "TL;DR Rust and JavaScript/TypeScript (JS/TS) are often perceived as rivals, but in reality, they’re complementary languages that serve different purposes and excel across different domains. They were designed with different goals in mind, which dictate the best use cases for each. JavaScript/TypeScript offers benefits such as unmatched flexibility, a massive ecosystem, and rapid iteration. Meanwhile, […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/rust/2026/01/27/rust-vs-javascript-typescript/",
    "pubDate": "Tue, 27 Jan 2026 11:22:01 +0000",
    "creator": "Irina Mihajlovic",
    "categories": [
      "comparison",
      "javascript",
      "rustrover",
      "rust"
    ]
  },
  {
    "id": 13,
    "imageUrl": "",
    "title": "ACP Agent Registry Is Live: Find and Connect AI Coding Agents in Your JetBrains IDE",
    "description": "AI coding agents are multiplying fast. Some of the most common ones include Gemini CLI, Claude Code, Auggie, OpenCode, and Copilot, and more are being released every day. Each comes with its own unique strengths, specific setups, and varying levels of editor support. Keeping track of what’s out there, let alone getting it running in your […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/ai/2026/01/acp-agent-registry/",
    "pubDate": "Wed, 28 Jan 2026 14:56:05 +0000",
    "creator": "Jan-Niklas Wortmann",
    "categories": [
      "ai-assistant",
      "news",
      "acp"
    ]
  },
  {
    "id": 14,
    "imageUrl": "",
    "title": "Vendor Lock-In vs. Strategic Partnership for Your CI/CD",
    "description": "This article was brought to you by Jakkie Koekemoer & Shweta, draft.dev. Traditional wisdom in the dev world is that once you opt for proprietary APIs or vendor-specific tooling, migrating to alternative platforms is costly or impractical to adopt in the future. That’s why engineering teams have considered vendor lock-in a trap. You end up […]",
    "reviews": [],
    "syllabus": [],
    "link": "https://blog.jetbrains.com/teamcity/2026/01/vendor-lock-in-vs-strategic-partnership/",
    "pubDate": "Wed, 28 Jan 2026 12:19:21 +0000",
    "creator": "Dmitrii Korovin",
    "categories": [
      "best-practices",
      "teamcity-2",
      "devopspains",
      "jenkins"
    ]
  },
  {
    "id": 15,
    "imageUrl": "",
    "title": "Rust at Scale: An Added Layer of Security for WhatsApp",
    "description": "WhatsApp has adopted and rolled out a new layer of security for users – built with Rust – as part of its effort to harden defenses against malware threats. WhatsApp’s experience creating and distributing our media consistency library in Rust to billions of devices and browsers proves Rust is production ready at a global scale. [...]\nRead More...\nThe post Rust at Scale: An Added Layer of Security for WhatsApp appeared first on Engineering at Meta.",
    "reviews": [],
    "syllabus": [],
    "link": "https://engineering.fb.com/2026/01/27/security/rust-at-scale-security-whatsapp/",
    "pubDate": "Tue, 27 Jan 2026 15:00:09 +0000",
    "creator": "Unknown",
    "categories": [
      "Security & Privacy",
      "WhatsApp"
    ]
  }
]