[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Augustin Popa",
        "title": "What’s New in vcpkg (November 2024)",
        "link": "https://devblogs.microsoft.com/cppblog/whats-new-in-vcpkg-november-2024/",
        "pubDate": "Sat, 23 Nov 2024 19:40:27 +0000",
        "content:encodedSnippet": "This blog post summarizes changes to the vcpkg package manager as part of the 2024.11.16 registry release, 2024-11-12 tool release, as well as changes to vcpkg documentation throughout November. This release includes a command line option to force vcpkg to use classic mode even if a manifest file is found along with bug fixes.\nSome stats for this period:\nThere are now 2,508 total ports available in the vcpkg curated registry. A port is a versioned recipe for building a package from source, such as a C or C++ library.\n20 new ports were added to the curated registry.\n185 updates were made to existing ports. As always, we validate each change to a port by building all other ports that depend on or are depended by the library that is being updated for our 13 main triplets.\n88 contributors made commits (not counting the vcpkg maintainers).\nThe main vcpkg repo has over 6,400 forks and 23,300 stars on GitHub.\nvcpkg changelog (2024.11.16 release)\nThe following changes were made in November:\nAdded a command line option called –classic, which instructs vcpkg to skip looking for a manifest and run in classic mode, even if a manifest file exists in the directory hierarchy. Useful for multi-project codebases where some submodules may want run vcpkg in classic mode, while others do not (PR: Microsoft/vcpkg-tool#1535).\nFixed a bug where vcpkg was claiming that certain builds were failing due to the x-block-origin option (PR: Microsoft/vcpkg-tool#1513).\nOther minor bug fixes.\nDocumentation changes\nAdded documentation for new –classic command line option (PR: Microsoft/vcpkg-docs#423).\nUpdated overlay port documentation to clarify how overlay ports in subdirectories are handled by vcpkg (PR: Microsoft/vcpkg-docs#422).\nOther minor fixes (thanks @bansan85, @dg0yt, and @woopelderly!).\nIf you have any suggestions for our documentation, please submit an issue in our GitHub repo or see the box at the bottom of a particular article.\n\nTotal ports available for tested triplets\ntriplet\nports available\n\n\nx64-windows\n2,389\n\n\nx86-windows\n2,261\n\n\nx64-windows-static\n2,259\n\n\nx64-windows-static-md\n2,305\n\n\narm64-windows\n1,978\n\n\nx64-uwp\n1,319\n\n\narm64-uwp\n1,287\n\n\nx64-linux\n2,362\n\n\nx64-osx\n2,234\n\n\narm64-osx\n2,152\n\n\narm-neon-android\n1,646\n\n\nx64-android\n1,722\n\n\narm64-android\n1,695\n\n\n\nWhile vcpkg supports a much larger variety of target platforms and architectures (as community triplets), the list above is validated exhaustively to ensure updated ports don’t break other ports in the catalog.\nThank you to our contributors\nvcpkg couldn’t be where it is today without contributions from our open-source community. Thank you for your continued support! The following people contributed to the vcpkg, vcpkg-tool, or vcpkg-docs repos in this release (listed alphabetically by GitHub username):\n17steen\nADKaster\nAenBleidd\nagl-alexglopez\nalagoutte\nalbertony\nalfredh\naluaces\naminya\nandre-nguyen\nankurvdev\nAnyOldName3\nautoantwort\nazure-sdk\nbansan85\nblavallee\nbraindigitalis\nbuck-yeh\nbw-hro\nc8ef\ncenit\nDanAlbert\ndaniele77\nDeishelon\ndg0yt\ndonny-dont\neao197\neclipse0922\nelsid\nerikyuzwa\ng-maxime\ngavinltomra\nHisuianZoroark69\nHoneybunch\nhuangqinjin\nlrineau\nJacobBarthelmeh\nJanWilczek\njgillis\njiayuehua\njll63\nJoergAtGithub\njohnwason\njreichel-nvidia\nmbeutel\nmetsma\nmichaelmigliore\nmikaellindemann\nmiyanyan\nmyd7349\nn-taka\nnetheril96\nNeumann-A\nnickdademo\nnirvn\nnlogozzo\noleg-derevenetz\nOsyotr\npedrolcl\nPoldraunic\nrinechran\nrinrab\nrogerqcify\nrtzoeller\nscotthart\nSHIINASAMA\nSidneyCogdill\nsimolis3\nskypjack\nsssooonnnggg\nstemann\nSunBlack\nswebb2066\nszhorvat\ntalregev\nteo-tsirpanis\nTerentyev\ntheblackunknown\nThomas1664\ntomwillow\nTradias\ntraversaro\nwalbourn\nwaywardmonkeys\nwinsoft666\nwolfgitpr\nwoopelderly\nxiaozhuai\nLearn more\nYou can find the main release notes on GitHub. Recent updates to the vcpkg tool can be viewed on the vcpkg-tool Releases page. To contribute to vcpkg documentation, visit the vcpkg-docs repo. If you’re new to vcpkg or curious about how a package manager can make your life easier as a C/C++ developer, check out the vcpkg website – vcpkg.io.\nIf you would like to contribute to vcpkg and its library catalog, or want to give us feedback on anything, check out our GitHub repo. Please report bugs or request updates to ports in our issue tracker or join more general discussion in our discussion forum.\nThe post What’s New in vcpkg (November 2024) appeared first on C++ Team Blog.",
        "dc:creator": "Augustin Popa",
        "comments": "https://devblogs.microsoft.com/cppblog/whats-new-in-vcpkg-november-2024/#respond",
        "content": "<p>This blog post summarizes changes to the vcpkg package manager as part of the 2024.11.16 registry release, 2024-11-12 tool release, as well as changes to vcpkg documentation throughout November. This release includes a command line option to force vcpkg to use classic mode even if a manifest file is found along with bug fixes. Some [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/whats-new-in-vcpkg-november-2024/\">What’s New in vcpkg (November 2024)</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "This blog post summarizes changes to the vcpkg package manager as part of the 2024.11.16 registry release, 2024-11-12 tool release, as well as changes to vcpkg documentation throughout November. This release includes a command line option to force vcpkg to use classic mode even if a manifest file is found along with bug fixes. Some […]\nThe post What’s New in vcpkg (November 2024) appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34955",
        "categories": [
          "C++",
          "Vcpkg",
          "vcpkg;CPP"
        ],
        "isoDate": "2024-11-23T19:40:27.000Z"
      }
    ]
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Sequence learning: A paradigm shift for personalized ads recommendations",
        "link": "https://engineering.fb.com/2024/11/19/data-infrastructure/sequence-learning-personalized-ads-recommendations/",
        "pubDate": "Tue, 19 Nov 2024 17:00:43 +0000",
        "content:encodedSnippet": "AI plays a fundamental role in creating valuable connections between people and advertisers within Meta’s family of apps. Meta’s ad recommendation engine, powered by deep learning recommendation models (DLRMs), has been instrumental in delivering personalized ads to people. Key to this success was incorporating thousands of human-engineered signals or features in the DLRM-based recommendation system.\nDespite training on vast amounts of data, there are limitations to current DLRM-based ads recommendations with manual feature engineering due to the inability of DLRMs to leverage sequential information from people’s experience data. To better capture the experiential behavior, the ads recommendation models have undergone foundational transformations along two dimensions:\n\n\nEvent-based learning: learning representations directly from a person’s engagement and conversion events rather than traditional human-engineered features.\nLearning from sequences: developing new sequence learning architectures to replace traditional DLRM neural network architectures.\nBy incorporating these advancements from the fields of natural language understanding and computer vision, Meta’s next-generation ads recommendation engine addresses the limitations of traditional DLRMs, resulting in more relevant ads for people, higher value for advertisers, and better infrastructure efficiency.\nThese innovations have enabled our ads system to develop a deeper understanding of people’s behavior before and after converting on an ad, enabling us to infer the next set of relevant ads. Since launch, the new ads recommendation system has improved ads prediction accuracy – leading to higher value for advertisers and 2-4% more conversions on select segments.\nThe limits of DLRMs for ads recommendations\nMeta’s DLRMs for personalized ads rely on a wide array of signals to understand people’s purchase intent and preferences. DLRMs have revolutionized learning from sparse features, which capture a person’s interactions on entities like Facebook pages, which have massive cardinalities often in the billions. The success of DLRMs is founded on their ability to learn generalizable, high dimensional representations, i.e., embeddings from sparse features. \nTo leverage tens of thousands of such features, various strategies are employed to combine features, transform intermediate representations, and compose the final outputs. Further, sparse features are built by aggregating attributes across a person’s actions over various time windows with different data sources and aggregation schemes. \nSome examples of legacy sparse features thus engineered would be:\n\n\nAds that a person clicked in the last N days → [Ad-id1, Ad-id2, Ad-id3, …, Ad-idN]\nFacebook pages a person visited in the past M days with a score of how many visits on each page  → [(Page-id1, 45), (Page-id2, 30), (Page-id3, 8), …]\n\n\nHuman-engineered sparse features, as described above, have been a cornerstone for personalized recommendations with DLRMs for several years. But this approach has limitations:\n\n\nLoss of sequential information: Sequence information, i.e., the order of a person’s events, can provide valuable insights for better ads recommendations relevant to a person’s behavior. Sparse feature aggregations lose the sequential information in a person’s journeys.\nLoss of granular information: Fine-grained information like collocation of attributes in the same event is lost as features are aggregated across events.\nReliance on human intuition: Human intuition is unlikely to recognize non-intuitive, complex interactions and patterns from vast quantities of data.\nRedundant feature space: Multiple variants of features get created with different aggregation schemes. Though providing incremental value, overlapping aggregations increase compute and storage costs and make feature management cumbersome.\nPeople’s interests evolve over time with continuously evolving and dynamic intents. Such complexities are hard to model with handcrafted features. Modeling these inter-dynamics helps achieve a deeper understanding of a person’s behavior over time for better ad recommendations. \nA paradigm shift with learning from sequences for recommendation systems\nMeta’s new system for ads recommendations uses sequence learning at its core. This necessitated a complete redesign of the ads recommendations system across data storage, feature input formats, and model architecture. The redesign required building a new people-centric infrastructure, training and serving optimization for state-of-the-art sequence learning architectures, and model/system codesign for efficient scaling.\nEvent-based features\nEvent-based features (EBFs) are the building blocks for the new sequence learning models. EBFs – an upgrade to traditional features – standardizes heterogeneous inputs to sequence learning models along three dimensions:\nEvent streams: the data stream for an EBF, e.g. the sequence of recent ads people engaged with or the sequence of pages people liked.\nSequence length defines how many recent events are incorporated from each stream and is determined by the importance of each stream.\nEvent Information: captures semantic and contextual information about each event in the stream such as the ad category a person engaged with and the timestamp of the event.\nEach EBF is a single coherent object that captures all key information about an event. EBFs allow us to incorporate rich information and scale inputs systematically. EBF sequences replace legacy sparse features as the main inputs to the recommendation models. When combined with event models described below, EBFs have ushered in a departure from human-engineered feature aggregations.\n\nSequence modeling with EBFs\nAn event model synthesizes event embeddings from event attributes. It learns embeddings for each attribute and uses linear compression to summarize them into a single event attributed-based embedding. Events are timestamp encoded to capture their recency and temporal order. The event model combines timestamp encoding with the synthesized event attribute-based embedding to produce the final event-level representation – thus translating an EBF sequence into an event embedding sequence.\nThis is akin to how language models use embeddings to represent words. The difference is that EBFs have a vocabulary that is many orders of magnitude larger than a natural language because they come from heterogeneous event streams and encompass millions of entities.\nThe event embeddings from the event model are then fed into the sequence model at the center of the next-generation ads recommendation system. The event sequence model is a person level event summarization model that consumes sequential event embeddings. It utilizes state-of-the-art attention mechanisms to synthesize the event embeddings to a predefined number of  embeddings that are keyed by the ad to be ranked. With techniques like multi-headed attention pooling, the complexity of the self-attention module is reduced from O(N*N) to O(M*N) . M is a tunable parameter and N is the maximum event sequence length.\nThe following figure illustrates the differences between DLRMs with a human-engineered features paradigm (left) and the sequence modeling paradigm with EBFs (right) from a person’s event flow perspective.\n\nScaling the new sequence learning paradigm\nFollowing the redesign to shift from sparse feature learning to event-based sequence learning, the next focus was scaling across two domains — scaling the sequence learning architecture and scaling event sequences to be longer and richer.\nScaling sequence learning architectures\nA custom transformer architecture that incorporates complex feature encoding schemes to fully model sequential information was developed to enable faster exploration and adoption of state-of-the-art techniques for recommendation systems. The main challenge with this architectural approach is achieving the performance and efficiency requirements for production. A request to Meta’s ads recommendation system has to rank thousands of ads in a few hundred milliseconds.\nTo scale representation learning for higher fidelity, the existing sum pooling approach was replaced with a new architecture that learned feature interactions from unpooled embeddings. Whereas the prior system based on aggregated features was highly optimized for fixed length embeddings that are pooled by simple methods like averaging, sequence learning introduces new challenges because different people have different event lengths. Longer variable length event sequences, represented by jagged embedding tensors and unpooled embeddings, result in larger compute and communication costs with higher variance.\n\nThis challenge of growing costs is addressed by adopting hardware codesign innovations for supporting jagged tensors, namely:\n\n\nNative PyTorch capabilities to support Jagged tensors.\nKernel-level optimization for processing Jagged tensors on GPUs.\nA Jagged Flash Attention module to support Flash Attention on Jagged tensors.\n\n\nScaling with longer, richer sequences\nMeta’s next-generation recommendation system’s ability to learn directly from event sequences to better understand people’s preferences is further enhanced with longer sequences and richer event attributes.\nSequence scaling entailed:\n\n\nScaling with longer sequences: Increasing sequence lengths gives deeper insights and context about a person’s interests. Techniques like multi-precision quantization and value-based sampling techniques are used to efficiently scale sequence length.\nScaling with richer semantics: EBFs enable us to capture richer semantic signals about each event e.g. through multimodal content embeddings. Customized vector quantization techniques are used to efficiently encode the embedding attributes of each event. This yields a more informative representation of the final event embedding.\nThe impact and future of sequence learning\nThe event sequence learning paradigm has been widely adopted across Meta’s ads systems, resulting in gains in ad relevance and performance, more efficient infrastructure, and accelerated research velocity. Coupled with our focus on advanced transformer architectures, event sequence learning has reshaped Meta’s approach to ads recommendation systems. \nGoing forward, the focus will be on further scaling event sequences by 100X, developing more efficient sequence modeling architectures like linear attention and state space models, key-value (KV) cache optimization, and multimodal enrichment of event sequences.\nAcknowledgements\nWe would like to thank Neeraj Bhatia, Zhirong Chen, Parshva Doshi, Jonathan Herbach, Yuxi Hu, Abha Jain, Kun Jiang, Santanu Kolay, Boyang Li,  Hong Li, Paolo Massimi, Sandeep Pandey, Dinesh Ramasamy, Ketan Singh, Doris Wang, Rengan Xu, Junjie Yang, and the entire event sequence learning team involved in the development and productionization of the next-generation sequencing learning-based ads recommendation system.\nThe post Sequence learning: A paradigm shift for personalized ads recommendations appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>AI plays a fundamental role in creating valuable connections between people and advertisers within Meta’s family of apps. Meta’s ad recommendation engine, powered by deep learning recommendation models (DLRMs), has been instrumental in delivering personalized ads to people. Key to this success was incorporating thousands of human-engineered signals or features in the DLRM-based recommendation system. [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/11/19/data-infrastructure/sequence-learning-personalized-ads-recommendations/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/11/19/data-infrastructure/sequence-learning-personalized-ads-recommendations/\">Sequence learning: A paradigm shift for personalized ads recommendations</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "AI plays a fundamental role in creating valuable connections between people and advertisers within Meta’s family of apps. Meta’s ad recommendation engine, powered by deep learning recommendation models (DLRMs), has been instrumental in delivering personalized ads to people. Key to this success was incorporating thousands of human-engineered signals or features in the DLRM-based recommendation system. [...]\nRead More...\nThe post Sequence learning: A paradigm shift for personalized ads recommendations appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21954",
        "categories": [
          "Data Infrastructure",
          "ML Applications",
          "Production Engineering"
        ],
        "isoDate": "2024-11-19T17:00:43.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "eBay News Team",
        "title": "Introducing eBay Evo: The Evolution of eBay’s Brand and Design System",
        "link": "https://innovation.ebayinc.com/tech/features/ebay-evo-the-evolution-of-ebays-brand-and-design-system/",
        "pubDate": "Mon, 18 Nov 2024 00:00:00 -0800",
        "dc:creator": "eBay News Team",
        "content": "<div style=\"margin-bottom: 10px;\"><img src=\"https://static.ebayinc.com/static/assets/Uploads/Blog/Posts/_resampled/FitWzIwMCwxMTNd/Overview-Still.jpg?fs=aa44968bd70eed27\" width=\"200\" height=\"113\" alt=\"Introducing eBay Evo: The Evolution of eBay’s Brand and Design System\" /></div><div>Developed in-house, Evo enhances the customer experience through a modern and simplified approach.</div>",
        "contentSnippet": "Developed in-house, Evo enhances the customer experience through a modern and simplified approach.",
        "guid": "https://innovation.ebayinc.com/tech/features/ebay-evo-the-evolution-of-ebays-brand-and-design-system/",
        "categories": [
          "article"
        ],
        "isoDate": "2024-11-18T08:00:00.000Z"
      }
    ]
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Irina Mariasova",
        "title": "JetBrains AI Assistant Integrates Google Gemini and Local LLMs",
        "link": "https://blog.jetbrains.com/ai/2024/11/jetbrains-ai-assistant-integrates-google-gemini-and-local-llms/",
        "pubDate": "Fri, 22 Nov 2024 14:55:23 +0000",
        "content:encodedSnippet": "We’ve now added Gemini 1.5 Pro and Gemini 1.5 Flash to the lineup of LLMs used by JetBrains AI Assistant. These LLMs join forces with OpenAI models and local models. \nWhat’s special about Google models?\nGemini 1.5 Pro and 1.5 Flash on Google Cloud’s Vertex AI will deliver advanced reasoning and impressive performance, unlocking several new use cases. Gemini Flash 1.5 will specifically help when cost efficiency at high volume and low latency is paramount.  \nHow to try Google models\nStarting from the 2024.3 version of JetBrains AI Assistant, you can pick your preferred LLM right in the AI chat. This expanded selection allows you to customize the AI chat’s responses to your specific workflow, offering a more adaptable and personalized experience. \n\n\n\n\nLocal model support via Ollama\nIn addition to cloud-based models, you can now connect the AI chat to local models available through Ollama. This is particularly useful if you need more control over your AI models, and it offers enhanced privacy, flexibility, and the ability to run models on local hardware.\nTo add an Ollama model to the chat, enable Ollama support in AI Assistant’s settings and configure the connection to your Ollama instance. \n\n\n\n\nExplore these new models, and let us know what you think! 🌟",
        "dc:creator": "Irina Mariasova",
        "content": "We’ve now added Gemini 1.5 Pro and Gemini 1.5 Flash to the lineup of LLMs used by JetBrains AI Assistant. These LLMs join forces with OpenAI models and local models. What’s special about Google models? Gemini 1.5 Pro and 1.5 Flash on Google Cloud’s Vertex AI will deliver advanced reasoning and impressive performance, unlocking several [&#8230;]",
        "contentSnippet": "We’ve now added Gemini 1.5 Pro and Gemini 1.5 Flash to the lineup of LLMs used by JetBrains AI Assistant. These LLMs join forces with OpenAI models and local models. What’s special about Google models? Gemini 1.5 Pro and 1.5 Flash on Google Cloud’s Vertex AI will deliver advanced reasoning and impressive performance, unlocking several […]",
        "guid": "https://blog.jetbrains.com/?post_type=ai&p=529591",
        "categories": [
          "news",
          "gemini",
          "google",
          "jetbrains-ai",
          "mellum"
        ],
        "isoDate": "2024-11-22T14:55:23.000Z"
      },
      {
        "creator": "Oleg Zinovyev",
        "title": "CLion Nova Improvements, Debug Servers, OpenCV Image Viewer, and Zephyr West Debugging in CLion 2024.3",
        "link": "https://blog.jetbrains.com/clion/2024/11/2024-3-available/",
        "pubDate": "Wed, 20 Nov 2024 11:40:48 +0000",
        "content:encodedSnippet": "CLion 2024.3 is now available. This latest version of the JetBrains IDE for C and C++ includes the following key features and updates:\nConsiderable improvements to the new language engine, CLion Nova.\nNew Debug Servers configuration option.\nOpenCV image viewer.\nAbility to attach the debugger to an unstarted process.\nDebugging support for Zephyr West.\n\n\n\n\nYou can download CLion 2024.3 from the link below, via the Toolbox App, as a snap package if you’re using Ubuntu, or via a patch update from version 2024.2.\nDOWNLOAD CLION 2024.3\nCLion Nova\nIn this release, our new language engine, CLion Nova, has received many important enhancements, including various language-specific and UI updates and several memory usage optimizations. We’ve also provided improved language support for modern C++ features.\nFurthermore, to simplify the transition from CLion Classic to CLion Nova, we’ve added a toggle switch to both the Welcome screen and the Configuration menu.\n\n\n\n\nCall for feedback on CLion Nova\nThe performance of CLion Nova now exceeds that of CLion Classic by an even greater margin. It’s smoother and more responsive, even on larger projects with hundreds of thousands of lines of code. That’s why we’ve added even more convenient ways for you to switch to CLion Nova. \nHowever, we realize that some CLion Classic users are not ready to make the switch. Before we make CLion Nova the default engine for everyone, we would like to understand why some users prefer CLion Classic over CLion Nova. We would therefore appreciate it if you could share your feedback with us via Help | Submit Feedback… in the main IDE menu. We’ll review it carefully and try to resolve any critical issues that might prevent you from getting the most out of CLion Nova.\nMemory usage improvements\nVarious improvements have vastly reduced CLion Nova’s memory usage and improved overall IDE performance. This is especially noticeable in large projects like Chromium ones.\n\n\n\n\nFor example, when we compared the memory usage of a Chromium project in CLion Nova 2024.2 with the same project in 2024.3, we saw that the IDE frontend used 51% less memory in the new version, and the IDE backend used 15% less. In short, this means the IDE has become more responsive and quicker to launch.\nCall hierarchy\nThe function call hierarchy is now available when using CLion Nova in the Hierarchy tool window. It displays caller and callee hierarchies, visually representing how your functions interact and highlighting recursive calls with the corresponding icon.\n\n                        \n\n\nTo see the call hierarchy of a function, select it in the editor, and then click Navigate | Call Hierarchy from the main menu or use the shortcut ⌃⌥H (macOS) or Ctrl+Alt+H (Windows/Linux).\nPredefined code styles from other projects\nOne of the most requested features we’ve added to this release is predefined code styles from other projects such as LLVM, GNU, Qt, and Google. This allows you to follow popular style guides for code structure rules, naming conventions, and other C++ areas where consistency is crucial. You can select your preferred style via Settings | Editor | Code Style | C/C++ | Set from….\n\n\n\n\nQuick Definition support\nThe Quick Definition popup reveals where and how function, class, method, and other project symbols are defined. To call it, place the caret at a symbol in the editor and press ⌥Space (macOS) or Ctrl+Shift+| (Windows/Linux). You can also access it from the main menu via View | Quick Definition.\n\n                        \n\n\nEmbedded development\nIn this release, we have continued to expand CLion’s functionality to meet the diverse needs of embedded developers. Major updates for embedded development include debug servers, the ability to edit peripheral register values, and support for debugging West projects.\nDebug servers experimental\nWe’ve introduced a new Debug Servers configuration option to simplify the setup of debugging for embedded and remote development. Located in Settings | Debugger, this dedicated section allows you to configure a debug server for the specific debug probe and use it to run or debug the build target.\nTo enable the configuration option, go to Settings | Advanced Settings | Debugger. You can select Edit Debug Servers from the main toolbar switcher or go to Settings | Debugger and open the Debug Servers dialog to configure a debug server.\n\n                        \n\n\nPlease be aware that this is an experimental feature, and it doesn’t work with PlatformIO yet. There is, however, a workaround. We encourage you to give it a try and share your feedback with us. Additionally, we are more than willing to arrange a brief call to understand your specific use cases and challenges better.\nDebugging support for Zephyr West\nNow, you can natively debug Zephyr projects that use the West meta-tool directly in CLion. When you import your Zephyr West project, a West run/debug configuration is automatically created in the Run/Debug Configurations switcher. You can also create a new run/debug configuration by selecting Run | Edit Configurations… from the main menu, clicking +, and selecting a West template:\n\n\n\n\nOnce configured, the new West run/debug configuration will be available in the Run/Debug Configurations switcher, and you can use it to run a debug session.\nEditable peripheral register values\nWhen debugging board peripherals like timers, communication interfaces, or GPIO ports, you can now instantly observe the results of your modifications by editing peripheral registers directly in the Peripherals pane.\n\n\n\n\nYou can test different configurations and device states on the go without recompiling your code or reloading your application or board.\nSupport for MISRA C++:2023 with CLion Nova\nThe MISRA guidelines are indispensable in the development of safety-critical systems. In this release, CLion’s static analysis toolset gets a significant portion of MISRA C++:2023 checks specifically targeted at C++17.\n\n\n\n\nDebugger\nCLion’s debugger has received several updates, the most important of which are an OpenCV image viewer, the ability to attach the debugger to an unstarted process, a formatted view for strings with structured data, and new bundled GDB (15.2) and LLDB (19.1.3) debuggers.\nOpenCV image viewer\nIf you’re developing an ML application that uses the OpenCV library, you can now view a two-dimensional OpenCV array as an image while debugging the application. The image opens in a separate dialog with multiple editing options.\n\n                        \n\n\nThe OpenCV image viewer simplifies image processing inspection during application debugging. It’s also more convenient than alternative methods like saving an image to the hard drive or writing extra code to display it in a popup window.\nAbility to attach the debugger to an unstarted process\nAttaching the debugger to an unstarted local process is helpful when one part of your project is written in C++ and runs in CLion, while another is written in another language and runs in an external environment.\nTo try the feature:\nSet a breakpoint in your code.\nSelect Run | Attach to an Unstarted Process… from the main menu.\nIn the Command line field, add a pattern to find the process using wildcard characters: *process_name*.\nSelect the options you need.\nSelect a debugger to attach.\nThe debugger will start watching the process.\n\n\n\n                                                \n                        \n\n\nOnce the external process starts, the debugger will attach to it. From there, the debugging session will continue as normal, with the program running and halting at the breakpoints you have set.\nFormatted view for strings with JSON, XML, or HTML data\nWhen debugging strings containing JSON, XML, or HTML data, or newline characters, you can view them formatted according to their code style directly in the debugger. This means you no longer need to copy unformatted values into a third-party tool for examination. \nWhen debugging, click View next to a variable to see the structured or raw data in a separate window.\n\n\n\n\nOther enhancements\nThis release also includes a number of user experience improvements, such as renewed cloud completion, a new project status widget, and an updated UI for the new terminal. We’ve also updated the CMake bundle to 3.30.5.\nRenewed cloud completion powered by AI Assistant \nThe enhanced JetBrains AI Assistant plugin, featuring our internally trained LLM for C++, has significantly improved the speed and intelligence of CLion’s cloud code completion. AI Assistant now provides more usage scenarios, better suffix matching, and more correct code fragment completions.\nOne of the most significant enhancements is multiline code completion, which brings syntax highlighting and the ability to incrementally accept code suggestions. \n\n                        \n\n\nMultiline code completion operates alongside standard code completion and Full Line Code Completion (the latter uses the local LLM and doesn’t require sending data to the cloud). It allows you to review and accept suggestions incrementally. Additionally, you can accept suggestions word by word using the shortcut ⌥→ on macOS or Ctrl+→ on Windows. \nProject status widget\nCLion’s project status notifications inform you of potential problems with your project configuration and offer ways to resolve them. In the previous CLion version, 2024.2, these notifications were displayed as yellow banners in the editor until the problem was resolved. They were irrelevant for some users – for example, those who just wanted to open a .cpp file from a third-party project to read the code. Having a notification banner hanging in the editor all the time is unnecessary in such cases.\nFor this release, we’ve moved project status notifications from the top of the editor to a new widget in the status bar.\n\n\n\n\nNow, the notification that your file doesn’t belong to any project won’t appear until you hover over the ⚠️ icon. When you click on the icon, the widget will offer to fix the problem. This makes notifications less distracting while still keeping the information accessible to those who want it.\nUpdated UI for the new terminal\nThe new terminal’s interface has been redesigned to be more compact by reducing padding. This change maximizes screen space, making it easier to view and work with commands while keeping everything readable and clear. \n\n\n\n\nHighlighted occurrences of selected text\nBy default, CLion now highlights every instance of the text you select in any file type, not just .c and .cpp files. This change makes it much simpler to track where your selected text appears throughout the file. \n\n\n\n\nTry CLion and give us your feedback\nWe invite you to give CLion 2024.3 a try. If you have an active subscription, you can update it right away. New to CLion? Start your free 30-day trial today and dive into all its features and improvements immediately.\nWe value your feedback! If you have anything to share or if you run into any problems, please let us know through our issue tracker.\nDOWNLOAD CLION 2024.3\nYour CLion team\nJetBrains\nThe Drive to Develop",
        "dc:creator": "Oleg Zinovyev",
        "content": "CLion 2024.3 is now available. This latest version of the JetBrains IDE for C and C++ includes the following key features and updates: You can download CLion 2024.3 from the link below, via the Toolbox App, as a snap package if you’re using Ubuntu, or via a patch update from version 2024.2. DOWNLOAD CLION 2024.3 [&#8230;]",
        "contentSnippet": "CLion 2024.3 is now available. This latest version of the JetBrains IDE for C and C++ includes the following key features and updates: You can download CLion 2024.3 from the link below, via the Toolbox App, as a snap package if you’re using Ubuntu, or via a patch update from version 2024.2. DOWNLOAD CLION 2024.3 […]",
        "guid": "https://blog.jetbrains.com/?post_type=clion&p=527231",
        "categories": [
          "news",
          "releases",
          "ai-assistant",
          "clionnova",
          "debugger",
          "embedded",
          "misra",
          "opencv",
          "zephyr-west"
        ],
        "isoDate": "2024-11-20T11:40:48.000Z"
      },
      {
        "creator": "Mukul Mantosh",
        "title": "Deploying Go Apps with Kubernetes",
        "link": "https://blog.jetbrains.com/go/2024/11/20/deploying-go-apps-with-kubernetes/",
        "pubDate": "Wed, 20 Nov 2024 11:24:31 +0000",
        "content:encodedSnippet": "We live in a world where things change at a rapid pace, and the latest and greatest quickly becomes outdated. The same goes for deploying applications to servers. You used to have to physically travel to a data center to deploy your changes. Later on, we moved to VMs. Then containers came along and changed the game again.\nContainers have been widely adopted by most industries, and one of the most popular containerization tools is Docker. However, as complexity grew, people started looking for orchestration tools that were effective at scale, performed load balancing, self-healed, and more. There were many contenders in the competition, like Apache Mesos, HashiCorp Nomad, and Docker Swarm, but Kubernetes has thrived for a long time due to its robust ecosystem, extensive community support, scalability, and ability to manage complex, distributed applications across multiple environments.\n\n\n\n\nSource: drgarcia1986.medium.com\nKubernetes is an open-source container orchestration platform that automates the deployment, scaling, and management of containerized applications. Originally developed by Google, it is now maintained by the CNCF.\nKubernetes is one of the largest open-source projects to date. With over a decade of development, its maturity is undeniable, boasting more than 88,000 contributors. Check out the 10 Years of Kubernetes blog post for more insights.\nIn this tutorial, we are going to create a Go application and prepare it to run inside a Kubernetes cluster. \nLet’s get started!\nCreating a Go application in GoLand\nIn this tutorial, we’ll start by creating a basic Go application which performs CRUD operations. We’ll then containerize the application and deploy it to the local Kubernetes cluster using Docker Desktop.\nYou can access the source code used in this tutorial here.\nTo create your project, launch GoLand and click New Project. \nProvide necessary information such as the project name, GOROOT, and environment variables.\nEven if you don’t have the Go SDK installed on your system, GoLand will assist you in downloading the correct SDK.\n\n\n\n\nThen click Create.\nInstalling packages\nGorilla Mux\nOnce the project has been created, install Gorilla. The Gorilla Mux package is among the most widely used routers. It offers functionalities for route matching, serving static files, supporting middleware and websockets, managing CORS requests, and testing handlers.\nInstalling it from GoLand is simple and straightforward. Just import the package name, and the IDE will prompt you to install it.\n\n\n\n\nAlternatively, you can use the default method by accessing the Terminal and executing the following command:\ngo get -u github.com/gorilla/mux\n\n\n\n\nGORM\nGORM is an Object Relational Mapping (ORM) library for Go. It simplifies database interactions by making it easier for developers to work with database records and perform CRUD (Create, Read, Update, Delete) operations.\n*NOTE: We will be using the Postgres driver.\nTo install, run the following command in the Terminal:\ngo get -u gorm.io/gorm\ngo get -u gorm.io/driver/postgres\nAlternatively, you can also directly mention the package in the go.mod file and GoLand will take care of the installation.\n\n\n\n\n\n\n\n\nNOTE: When you see // indirect next to a dependency in the require block of your go.mod file, it indicates that your project does not import this package directly in its code, but some other package that your project imports does. \nBuilding core business functions\nNow, we have installed the core packages required to build the application. It’s time to start writing the core business logic. \nDatabase\nLet’s begin with the database.\nCreate a database.go file under project root. \n\n\n\n\nLet’s break it down step-by-step. \nIn this section we are managing a database client using the GORM library for Postgres.\nDBClient: This is an interface with two method signatures:\nReady(): This function returns a boolean value based on whether the database is ready or not. \nRunMigration(): This function performs database migrations. \n\n\n\n\n\nClient: This is a concrete type Client that implements the DBClient interface. It contains a single db *gorm.DB field which points to a gorm.DB instance.\n\n\n\n\n\nNext, in the Ready method we perform a RAW SQL query to check database readiness. It will return a boolean response (true or false). \n\n\n\n\n\nUnder RunMigration, we first check whether the database is ready. If successful, we proceed to invoke the AutoMigrate method provided by GORM to apply migrations to the database schema. As noted in the comment, we need to register the model to run the migration. We haven’t created a model yet, but don’t worry – we’ll get to that shortly. \n\n\n\n\n\nThe NewDBClient function constructs a database connection from environment variables, creating a Client that can be used to interact with the database.\n\n\n\n\nThe database section is done. Now let’s create our user model. \nUser model\nCreate a model.go file under the project root. \n\n\n\n\n\n\n\n\nHere you can see the User struct with fields ID, Name, Email, and Age, each annotated with JSON tags for serialization and GORM tags for database constraints, including primary key, uniqueness, and non-null constraints.\nThese tags specify database constraints and behaviors using GORM:\ngorm:\"primaryKey\": The ID field is the primary key.\ngorm:\"not null\": The Name and Email fields cannot be NULL in the database.\ngorm:\"unique\": The Email must be unique across the database table.\nNow we need to pass the User model to the AutoMigrate function which we discussed earlier. \n\n\n\n\nServer\nWe have implemented the database and the user model, so now it’s time to construct the mux server. \nCreate the server.go and routes.go files under the project root.\n\n\n\n\nWe’ll just leave this routes.go file empty for now, and we’ll cover what to do with it in the next section when we start defining HTTP handlers.\n\n\n\n\nLet’s break down the ‘server.go’ file step-by-step.\n\n\n\n\nThe Server interface declares two methods: \n– Start() error: Starts the server and returns any errors that pop up. \n– routes(): Defines the server routes.\n\n\n\n\nThe MuxServer struct implements the Server interface. \nIt contains: \n– gorilla *mux.Router: An instance of Gorilla Mux Router. \n– Client: An embedded field pointing to a database client. \n\n\n\n\nNewServer is a constructor function that creates and initializes a MuxServer instance. \n It accepts a Client which refers to a database client. \n A new MuxServer is created with: \n– A new router from mux.NewRouter(). \n– The provided db client. \n– The server.routes()method is called to set up the routes. \n\n\n\n\nThe Start method takes care of starting up the HTTP server and listening on port 8080. \n\n\n\n\nWe haven’t defined any HTTP handlers yet, which is why the routes function is currently empty. \nLet’s take care of that now.\n\n\n\n\nHTTP handlers\nCreate a new file called controller.go under the project root. \n\n\n\n\nOnce you’ve created the file, go ahead and open model.go and add the following struct:\n\n\n\n\nThe UserParam struct serves as a data transfer object (DTO) specifically for input handling, often seen in web APIs or web forms. \nSeparation of Concerns:\nThe User struct represents the data structure of a user entity in the system, which corresponds directly to the database schema. The UserParam struct is used for handling input validation and data transfer, particularly from HTTP requests.\nSecurity:\nYou’ll have better control over your data by separating fields into two categories: (1) information received from requests (like user input), and (2) information stored in the database. This gives you control over what data is exposed, enhances security by filtering out sensitive info, and ensures you only transfer necessary data between layers. \nLet’s go ahead and start implementing the HTTP handlers. \nHead back into the controller.go file.\n\n\n\n\nLet’s break it down step-by-step. We are going to implement the basic CRUD (Create, Read, Update, and Delete) operations on the User model. \nAdd User\nTo create a new user and add it to the database.\n\n\n\n\nList Users\nTo list all users from the database.\n\n\n\n\nUpdate User\nTo update an existing user’s details.\n\n\n\n\nDelete User\nTo delete an existing user.\n\n\n\n\nNow, it’s time to update the routes. \n\n\n\n\nIn this function, we’ll set up various kinds of routes (GET, POST, PUT and DELETE) to handle requests.\n\n\n\n\nRunning the application\nWe’re almost done! It’s time to define the entry point of the application where we can initialize the database, run migrations, and start the server.\nCreate a new file called main.go under the project root.\n\n\n\n\nAs you can see from the code below, we are initializing the database client, running database migration, and starting up the server. \n\n\n\n\nNow, it’s time to start the server. Before that, make sure you are running a local instance of Postgres. I will use Docker to spin up a postgres container.\nRun the following command in the Terminal:\ndocker run --name goland-k8s-demo -p 5432:5432 -e POSTGRES_PASSWORD=********** -d postgres\n\n\n\n\nOnce the container is up and running, go ahead and modify the Run Configuration. \n\n\n\n\nAdd these variables to the Environment field, as shown in the image below:\nDB_HOST\nDB_USERNAME\nDB_PASSWORD\nDB_NAME\nDB_PORT\n\n\n\n\n\n\n\n\nOnce done, apply the changes.\nClick the play icon to start the application. \n\n\n\n\n\n\n\n\nOnce the application is running, navigate to http-client | apis.http.\nYou can play around with the REST APIs directly from the IDE itself. \n\n\n\n\nDiving into K8s\nNow that we have developed the entire application,  it’s time to deploy the application inside the Kubernetes cluster. \nThe process starts with creating the Dockerfile.\nDockerfile\nA Dockerfile is a text document that contains a set of instructions for building a Docker image. It defines how the image should be constructed, including the base image to use, the files to include, and any commands to run during the build process.\nCreate a new file under project root and name it “Dockerfile”.\nSimply follow the steps I’ve outlined to build the Docker image. I’ll walk you through it step by step.\n\n\n\n\n\n\n\n\nFROM golang:1.23-alpine AS builder\nStarts with golang:1.23-alpine as the base image and labels the stage as builder.\nWORKDIR /app\nSet the working directory to /app.\nCOPY . .\nCopies the entire current directory (.) into the /app directory.\nRUN CGO_ENABLED=0 GOOS=linux go build -o go_k8s\nRuns the Go build command to compile the application. \nCGO_ENABLED=0 disables CGO (CGO enables the creation of Go packages that call C code).\n GOOS=linux sets the target OS to Linux. \nThe output binary is named go_k8s.\n\n\n\n\nFROM gcr.io/distroless/base\nUses a minimal distroless base image for the final container, focusing on security by excluding unnecessary components. To learn more about distroless images, check this out. \nWORKDIR /app\nSets the working directory to /app in the final stage.\nCOPY --from=builder /app/go_k8s .\nCopies the go_k8s binary from the /app directory of the builder stage into the /app directory of the final image.\nCMD [\"./go_k8s\"]\nSets the command to run when the container starts, which is the go_k8s binary.\nThe final image is kept as small and secure as possible, containing only the Go application binary without any unnecessary build tools or dependencies.\nGo ahead and build the Docker image. \nClick Run ‘Dockerfile’.\nNote: Before running, make sure the Docker daemon is running in the background. For this tutorial we are going to be using Docker Desktop.\n\n\n\n\nOnce the image is successfully built, push the image to the Docker registry.\nRight-click the image tag and select Edit Configuration.\n\n\n\n\nProvide the image tag and apply the changes.\nNote:\nBefore pushing, make sure to change the image tag based on the Docker repository which you have created in DockerHub.\nThe image tag should follow the format <hub-user>/<repo-name>[:<tag>]. Follow the steps to create repositories.\nIn this example, the tag mukulmantosh/go_k8s:1.0 is for demonstration only and may change based on your account type. Here, mukulmantosh represents the user, while go_k8s is the repository name and 1.0 is the specified tag.\n\n\n\n\n\n\n\n\n\nMake sure to re-run the build process. \n\n\n\n\nYou can see that the image tag has been applied. \n\n\n\n\nIt’s time to push the image. \nRight-click on the image tag, then select Push Image.\n\n\n\n\nClick Add and provide your Docker registry information.\n\n\n\n\n\n\n\n\nOnce successfully authenticated, click OK to push the image.\n\n\n\n\nOnce the image is successfully pushed, you can observe the changes in DockerHub. \n\n\n\n\nWell, the image is built and pushed. Now it’s time to work on the second part – writing the Kubernetes YAML files. \nWriting K8s manifests\nThis part of the tutorial covers how to deploy applications to local Kubernetes clusters.\nIn this tutorial, we have utilized Docker Desktop, though you can also opt for Minikube or Kind.\nIf you’ve chosen Docker Desktop as your preferred platform for running Kubernetes, be sure to enable Kubernetes in the settings by clicking the Enable Kubernetes checkbox.\n\n\n\n\nOnce Kubernetes is up and running, it’s time to create a namespace.\nWhat is a namespace?\nIn Kubernetes, a namespace is a logical partitioning of the cluster that allows you to divide resources and organize them into groups. Namespaces enable multiple teams or projects to share the same cluster while maintaining isolation and avoiding naming conflicts.\n\n\n\n\nSource: belowthemalt.com\nBegin by creating a directory called k8s in the root of your project.\nNext, create a new file and name it ns.yaml.\nNOTE: A Kubernetes manifest is typically written in YAML or JSON format and outlines various parameters for the resource, including its type, metadata, and specifications.\n\n\n\n\nThis YAML file would create a namespace named go-k8s-demo in your Kubernetes cluster.\nLet’s break it down.\napiVersion: v1: This specifies the API version of the Kubernetes resource. In this case, v1 indicates that the resource is using version 1 of the Kubernetes API.\nkind: Namespace: This indicates the type of Kubernetes resource being defined. It can be Deployment, Service, etc.\nmetadata: This section holds metadata about the Kubernetes resource. Metadata usually includes details like the name, labels, and annotations.\nIf you type the following command in the Terminal, it will show you lists of the API resources available in the Kubernetes cluster. \nkubectl api-resources\n\n\n\n\nOkay – you’ve created the YAML file. Now it’s time to execute it. \nThere are two ways you can create a namespace:\nIf you prefer using the Terminal, you can run this command:\nkubectl create ns go-k8s-demo\nOr, you can apply a file by running this command:\ncd k8s\nkubectl apply -f ns.yaml\nBoth methods will create the same namespace.\nCreating a namespace with GoLand\nYou also have the option of doing this in GoLand. Yes, you read that right, you can play with your Kubernetes clusters directly from the GoLand IDE. \nAs a side note, if you’re using GoLand 2024.2 or later, the Kubernetes plugin is already bundled with the IDE, so you don’t need to install it separately.\nOpen the Service tool window  by going to View | Tool Windows | Services.\n\n\n\n\nRight-click on Kubernetes | Add Clusters | From Default Directory.\n\n\n\n\nSelect docker-desktop and click Add Clusters.\n\n\n\n\nYou will see docker-desktop as your newly added cluster. Click the play icon to connect to it.\n\n\n\n\n\n\n\n\nReturn to the YAML file and hover over the top right corner of the screen and click Apply to Cluster to set your cluster to docker-desktop.\nOnce done, apply the changes.\n\n\n\n\nThe namespace is successfully created. \n\n\n\n\nWe will now switch to the newly created namespace to easily view the applications running within it.\n\n\n\n\n\n\n\n\nYou might be asking, “This works with a local cluster, but what about connecting to an external one?” Good news! You can do that as well.\n\n\n\n\nYou can also modify the paths for the kubectl and helm executables. Additionally, you have the option to customize Kubernetes configuration files at either the global or project level.\n\n\n\n\n\n\n\n\nDatabase and K8s\nThe namespace has been created. Now let’s start working on the database.\nPersistentVolume\nWe are going to create a persistent volume. A PersistentVolume (PV) in Kubernetes provides storage for your application’s pods. Think of it as a storage space that exists independently of any specific application.\nUnlike regular storage that disappears when an application stops, a PersistentVolume retains the data, making it suitable for applications that need to save files or databases.\nCreate a new folder called db in the project root, and then add a new file named pv.yaml inside it.\n\n\n\n\nThis YAML configuration defines a PersistentVolume named postgres-pv with 1 GB of storage. It is associated with the postgres application and can be accessed as read-write by one node at a time. The volume is stored locally on the host at the path /data/db.\nPersistentVolumeClaim\nCreate a new file called pvc.yaml under db.\nA PersistentVolumeClaim (PVC) in Kubernetes is a request for storage by a user or application. It allows you to specify how much storage you need and what characteristics it should have, such as access modes (like read/write).\n\n\n\n\nIn this YAML configuration we are creating a PVC in the go-k8s-demo namespace requesting 1 GiB of storage with a ReadWriteOnce access mode using the manual storage class.\nConfigMap\nCreate a new file cm.yaml under db.\nA ConfigMap in Kubernetes is a resource used to store configuration data in a key-value format. It allows you to separate configuration from application code, making it easier to manage and modify settings without needing to rebuild your application.\n\n\n\n\nDeployment\nA Deployment in Kubernetes is a resource used to manage and orchestrate the deployment of applications. It allows you to define how many instances of your application (called Pods) you want to run, and it ensures that they are running as expected.\nCreate a new file deploy.yaml under db.\n\n\n\n\nThis YAML file defines a deployment of a single PostgreSQL container running version 17.0, which exposes port 5432 and runs only one instance. It loads environment variables from a ConfigMap and uses a PersistentVolume to store data. \nService\nA Service in Kubernetes is an abstraction that defines a logical set of pods and a way to access them. It provides a stable endpoint for your applications, making it easier to communicate with groups of pods.\n\n\n\n\nSource: kubernetes.io\nCreate a new file svc.yaml under db.\n\n\n\n\nIn this YAML file we have defined a Kubernetes Service named postgres-service. The Service exposes port 5432 and routes traffic to the pods labeled with app: postgres-db, so it will allow other applications within the cluster to connect to the database.\nLaunching DB\nWe now have all of the configuration files needed to start the database. Let’s execute them.\nThere are two methods to do this.\nFirst, open the Terminal, navigate to the db directory, and run the following command:\ncd db\nkubectl apply -f .\nTo see the current status of your pods, you can run the following command:\nkubectl get pods -n go-k8s-demo\n\n\n\n\nThe second option is quite easy with GoLand. You don’t need to remember the commands – just the follow along with the video below:\n\n\n\n\nApplication and K8s\nNow that the database is up and running, it’s time to prepare our backend application.\nBegin by creating an app folder inside the k8s directory.\nConfigMap\nCreate a new file called cm.yaml under app.\nEnter the required database credentials.\nNOTE:\nGrab the credentials from db/cm.yaml that you defined earlier when creating the database pod.\npostgres-service under DB_HOST refers to the db/svc.yaml service we created earlier.\n\n\n\n\n\n\n\n\n\n\n\n\nDeployment\nNow let’s move on to the deployment. \nCreate a new file called deploy.yaml under app. \n\n\n\n\n\n\n\n\nIn this YAML file we define a Kubernetes deployment that runs a single replica of a pod, which contains a single container using the mukulmantosh/go_k8s:1.0 image. The container exposes port 8080 and gets its environment variables from a ConfigMap named app-cm.\nService\nNow let’s wrap up the last file. \nCreate a file called svc.yaml under app.\n\n\n\n\nTo summarize, we set up a service named app-service that allows external traffic to reach your application running in the cluster through port 30004. Requests received here are forwarded to port 8080 on the application pods.\nTesting\nNow let’s deploy our application and start testing it out. \nThe process is going to be exactly the same as what we did for the database.\nNavigate to the app directory and run the following command:\ncd app\nkubectl apply -f .\nAlternatively, you can do this in GoLand, which is quite easy and straightforward. \n\n\n\n\nYou can also check the status of your application by running the following command:\nkubectl get pods -n go-k8s-demo\n\n\n\n\nLet’s test out the application by sending an HTTP request.\n\n\n\n\n\n\n\n\nThe application works!\nThis was just a brief demonstration of how to use Kubernetes with Go, but there are many more possibilities to explore.\nReferences\nIf you already have a strong grasp of Kubernetes and want to learn how to deploy in a live cluster, take a look at my tutorial on deploying Go apps in Google Kubernetes Engine.",
        "dc:creator": "Mukul Mantosh",
        "content": "We live in a world where things change at a rapid pace, and the latest and greatest quickly becomes outdated. The same goes for deploying applications to servers. You used to have to physically travel to a data center to deploy your changes. Later on, we moved to VMs. Then containers came along and changed [&#8230;]",
        "contentSnippet": "We live in a world where things change at a rapid pace, and the latest and greatest quickly becomes outdated. The same goes for deploying applications to servers. You used to have to physically travel to a data center to deploy your changes. Later on, we moved to VMs. Then containers came along and changed […]",
        "guid": "https://blog.jetbrains.com/?post_type=go&p=528858",
        "categories": [
          "tutorials",
          "go",
          "goland",
          "kubernetes"
        ],
        "isoDate": "2024-11-20T11:24:31.000Z"
      },
      {
        "creator": "Anton Yalyshev",
        "title": "State of Kotlin Scripting 2024",
        "link": "https://blog.jetbrains.com/kotlin/2024/11/state-of-kotlin-scripting-2024/",
        "pubDate": "Tue, 19 Nov 2024 16:07:29 +0000",
        "content:encodedSnippet": "Update: we made some updates to the original post to accurately reflect the state of Custom Scripting and to avoid misinterpretations.\nTL;DR: Kotlin scripting remains an essential part of the Kotlin infrastructure. We continue to support it in the experimental state, and we are concluding certain experiments and reducing the number of scripting-related technologies that we provide and actively develop.\nKotlin scripting is the technology that enables executing Kotlin code as scripts without prior compilation or packaging into executables. In addition, several extension mechanisms exist to facilitate the usage of Kotlin for specific applications, such as configuring build tools. On top of that, REPL functionality, which is closely related to scripting, is available for Kotlin in various forms (including, for example, Kotlin Notebook).\nAll these technologies can be found in Kotlin and other JetBrains projects. Some of them are well known, others are barely used, but all require a noticeable amount of attention from the team.\nThe evolution of scripting in Kotlin\nScripting was introduced into Kotlin long ago as an experiment to investigate new ways of using the language. Since then, the development has been driven by the demand of external and internal adopters, as well as some experiments born inside our team. Over time, we accumulated a lot of functionality related to scripting in our codebase, and the effort required to support it grew quite significantly. Therefore, at some point, we started to review the functionality we have, how it is used inside and outside of JetBrains, and how we can distill it into a reasonable minimal subset that we are willing to support and develop without breaking too many existing use cases.\nThis blog post attempts to summarize our findings, explain our decisions, and outline the future directions in this area. We hope it will clarify the future of scripting in Kotlin and give the community a solid basis for making technical decisions. \nWhile we already have a firm roadmap for the immediate future, we welcome and appreciate your feedback and ideas for further improvements. We are especially interested in hearing about any particular use cases for scripting that you may have. We encourage you to use comments here or create YouTrack issues describing your scenarios and how the announced changes may affect them. Your insights are invaluable to us and will play a crucial role in shaping our future plans for the language’s development.\nContribute Your Feedback and Ideas\nBasic scripting\nWe conducted some research into scripting usage in the past and concluded that besides a few main adoptions, like Gradle build scripts, there is a relatively small number of known uses for scripting and REPL. This might be attributable to various factors, but the result is nonetheless clear: The functionality is not as popular as we had anticipated.\nSome technological problems could (and will) be addressed, but there are some inherent issues with attempting to position Kotlin as a scripting language. \nIn particular, Kotlin is not an interpreted language, and it cannot achieve the user experience typical for dedicated scripting languages. To achieve the current script-like behavior, we compile the code under the hood. The compilation process is quite intensive because the Kotlin compiler was not designed for such scenarios. \nThat is why we made the following decision:\nAlthough we will continue to provide generalized support for scripting in Kotlin, which includes compilation and evaluation of basic `.kts` files, as well as custom scripting (more about this below), we are not prepared to recommend Kotlin scripting as a generally applicable scripting solution, for example, as a replacement for Bash or Python.\nOn the other hand, we believe there are many new usage scenarios where, despite the known limitations, the use of Kotlin scripting could be beneficial. There are also several other potential use cases that we would like to explore further.\nCustom script types\nThe most powerful scripting solutions require extension mechanisms that allow for the customization of script compilation and evaluation. One of the most prominent examples is Gradle Kotlin DSL, where the Custom Scripting API is used to bring Kotlin language with traditional Gradle DSL to build scripts. This brings us to the second decision:\nWe will continue to support the Custom Scripting API (an unofficial name for a set of APIs for customizing script compilation and evaluation, as well as APIs for embedding script hosts into third-party applications). Therefore:\nWe are concentrating our efforts on improving the user experience with a few known use cases, in particular Gradle Kotlin DSL and select others.\nOutside these use cases, the API remains in the experimental state. Hence, things like documentation and IDE support for generic custom script support may continue to lag behind.\nMain.kts\nIn addition to the basic and custom scripting, we would like to continue supporting `.main.kts` scripts. The `.main.kts` scripts were initially developed to demonstrate the utility of the Custom Scripting API. However, with its support of dependencies and other features, it was adopted by many users as a default Kotlin scripting solution. Therefore, the next decision is:\nWe will continue to develop the `.main.kts` script type, which is already helpful for simple automation tasks. We have plans to extend its functionality and streamline IDE support. Such scripts continue to be supported out of the box in the Kotlin compiler and the Kotlin plugin for IntelliJ IDEA.\nKotlin REPL\nThe default REPL implementation has been a part of the Kotlin compiler (`kotlinc`) and Kotlin plugin for IntelliJ IDEA since the first release. Still, the functionality is limited, and improving it was never a priority for the team. Therefore, the user experience is not on par with the general Kotlin user experience in IntelliJ IDEA. We made several attempts to spin off alternative REPL implementations (e.g. the Kotlin Interactive Shell), but unfortunately, these never gained enough traction.\nMeanwhile, we are improving the Kotlin Notebook plugin for IntelliJ IDEA, which offers a smooth, extensive, and interactive experience working in Kotlin. With Kotlin Notebook, you can develop and experiment with Kotlin code, receive immediate outputs, and visualize data. We believe that it is an excellent replacement for all our current REPL solutions. \nBesides that, IntelliJ IDEA provides Kotlin Scratch files, where you can quickly prototype your code. Therefore:\nWe plan to sunset the default REPL implementations in the Kotlin compiler and the IntelliJ IDEA plugin.\nCLI REPL (via `kotlinc`) will continue to function at least until the release of Kotlin 2.3, but its operation will be limited to compatibility mode, i.e. with the `-language-version 1.9` option set (and may require an opt-in flag starting from release 2.2). \nThe default Kotlin REPL in the IntelliJ IDEA plugin will be removed in one of the next IntelliJ IDEA releases. \nWe will continue to promote the Kotlin Notebook plugin and IDE Scratch files as solutions for interactive Kotlin development.\nThis decision places some uncertainty on the external REPL implementations, like the Kotlin Interactive Shell. Although we plan to keep some REPL-related functionality in the compiler and Custom Scripting API (not least because solutions like Kotlin Notebook rely on them), with a final switch to the K2 compiler, a significant portion of this functionality will be changed or dropped, so it may require substantial effort to rewrite such implementations to the changed APIs. \nOther technologies based on Kotlin scripting\nBesides these main areas, there are a few other related technologies and APIs for scripting that we are currently supporting. We believe the cases explicitly mentioned above cover a majority of possible user needs. Therefore, we plan to drop most other scripting-related components and libraries from the compiler and IntelliJ IDEA. In particular:\nJSR-223 support – considering that the original JSR is in the withdrawn state, we do not believe supporting the de-facto obsolete API makes sense. The existing implementation will continue to function at least until the release of Kotlin 2.3 in the language version 1.9 compatibility mode (but we may consider renaming the artifact to raise awareness of the planned changes), and it will be dropped after that.\n`KotlinScriptMojo` – a Maven plugin that supports script execution during the Maven build. We did not find evidence of enough usages to keep maintaining it, so we plan to drop it in one of the next Kotlin releases.\n`kotlin-scripting-ide-services` – a library for implementing code completion functionality, mainly for REPL implementations. It is currently used in projects like Kotlin Interactive. It is heavily based on the infrastructure of the pre-K2 compiler and cannot be easily ported to the K2 version. Therefore, it will most likely stop working around the release of Kotlin 2.3 and will be removed from the codebase. We may consider reimplementing similar functionality on top of K2 in the future, but for now, this is not something we are actively pursuing.\nMoving forward\nWe hope the focused approach will allow us to move forward and provide a better experience with widely used scripting technologies. At the same time, it will free some resources for exciting language features and applications. We encourage you to share your use cases for scripting and appreciate your feedback on these changes and how they may affect your work.\nShare Your Feedback and Use Cases\nWhat else to read\nKotlin Notebook – documentation\nKotlin DSL Is Now the Default for New Gradle Builds",
        "dc:creator": "Anton Yalyshev",
        "content": "Update: we made some updates to the original post to accurately reflect the state of Custom Scripting and to avoid misinterpretations. TL;DR: Kotlin scripting remains an essential part of the Kotlin infrastructure. We continue to support it in the experimental state, and we are concluding certain experiments and reducing the number of scripting-related technologies that [&#8230;]",
        "contentSnippet": "Update: we made some updates to the original post to accurately reflect the state of Custom Scripting and to avoid misinterpretations. TL;DR: Kotlin scripting remains an essential part of the Kotlin infrastructure. We continue to support it in the experimental state, and we are concluding certain experiments and reducing the number of scripting-related technologies that […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=527650",
        "categories": [
          "ecosystem",
          "news",
          "kotlin-scripting"
        ],
        "isoDate": "2024-11-19T16:07:29.000Z"
      },
      {
        "creator": "Helen Scott",
        "title": "Code Faster with JetBrains AI in PyCharm",
        "link": "https://blog.jetbrains.com/pycharm/2024/11/code-faster-with-jetbrains-ai-in-pycharm/",
        "pubDate": "Tue, 19 Nov 2024 15:25:51 +0000",
        "content:encodedSnippet": "PyCharm 2024.3 comes with many improvements to JetBrains AI to help you code faster. I’m going to walk you through some of these updates in this blog post. \n\n\n\n\n\n\nNatural language inline AI prompt\nYou can now use JetBrains AI by typing straight into your editor in natural language without opening the AI Assistant tool window. If you use either IntelliJ IDEA or PyCharm, you might already be familiar with natural language AI prompts, but let me walk you through the process. \nIf you’re typing in the gutter you can start typing your request straight into the editor, and then press Tab. Here’s an example of one such request:\nwrite a script to capture a date input from a user and print it out prefixed by a message stating that their birthday is on that date.\nYou can then iterate on the initial input by clicking on the purple block in the gutter or by pressing ⌘\\ or Ctrl+\\ and pressing Enter:\nadd error handling so that when a birthday is in the future, we dont accept it\n\n\n\n\nYou can use  ⌘\\ or Ctrl+\\ to keep iterating until you’re happy with the result. For example, we can use the prompt:\nprint out the day of the week as well as their birthday date\nAnd then: \nchange the format of day_of_week to short\n\n\n\n\nThis feature is available for Python, JavaScript, TypeScript, JSON, and YAML files.\nLet’s look at some more examples. We can get JetBrains AI Assistant to help us generate new code with a prompt like this:\nWrite code that lists the latest polls, shows poll details, handles voting, updates votes, and displays poll results, ensuring only published polls are accessible.\n\n\n\n\nOr add some error handling to our code:\nAdd edge case handling to this code\n\n\n\n\nRemember, context is everything. Where you start your natural language prompt is important, as PyCharm uses the placement of your caret to figure out the context. You don’t need to prefix your query with a ? or $ if you start typing in the gutter because the context is the file, but if your caret is indented, you’ll need to start your query with the ? or $ character so PyCharm knows you’re crafting a natural language query.\nIn this example, we want to refactor existing code, so we need to prefix our query with the ? character:\n?create a dedicated function for printing the schedule and remove the code from here\n\n\n\n\n\n          \n        Try JetBrains AI for free\n    \n\n\n\n\nRunning code in the Python console\nWe know that JetBrains AI can generate code for you, but now you can run that code in the Python console without leaving the AI Assistant tool window by clicking the green run arrow.\nFor example, let’s say you have the following prompt:\nCreate a python script that asks for a birthday date in standard format yyy-MM-dd then converts it and prints it back out in a written format such as 22nd January 1991 \nYou can now click the green run arrow on the top-right of the code snippet to run it in your Python console:\n\n\n\n\nEven more features\nIn addition to the new functionality for natural language and code completion for PyCharm highlighted above, there are several other improvements to JetBrains AI. \nFaster code completion\nWe have introduced a new model for faster cloud-based completion with AI Assistant which is showing very promising results.\n\n\n\n\nFaster documentation\nIf documentation isn’t your thing, you can now hand off writing your Python docstrings to JetBrains AI. If you type either single or double quotes to enter a docstring and then press Return, you’ll see a prompt that says Generate with AI Assistant. Click that prompt and let JetBrains AI generate the documentation for you:\n\n\n\n\nHelp at your fingertips\nWe all need a little help now and again, and we can get JetBrains AI to help us here too. We’ve added a /docs prompt to the JetBrains AI tool window. This prompt will query the PyCharm documentation to save you from switching out of the context you’re working in!\n\n\n\n\nAbility to choose your LLM\nFor AI Chat, you can now select a different LLM from the drop-down menu in the chat window itself. There are lots of options for you to choose from:\n\n\n\n\nMore context in Jupyter notebooks\nWe’ve also improved how JetBrains AI works for data scientists. JetBrains AI now recognizes DataFrames and variables in your notebook. You can prefix your DataFrame or variable with # so that JetBrains AI considers it as part of the context. \n\n\n\n\nSummary\nJetBrains AI is available inside PyCharm, right where you need it. This release brings many improvements, from writing in natural language inside the editor and running AI-generated Python snippets in the console to generating documentation. \nRemember, if you’re in the gutter, you can start typing in natural language and then press Tab to get AI Assistant to generate the code. If you’re inside a method or function, you need to prefix your natural language query with either ? or $. You can then iterate on the generated code as many times as you like as you build out your new functionality and explore further.\n      \n        Try JetBrains AI for free",
        "dc:creator": "Helen Scott",
        "content": "PyCharm 2024.3 comes with many improvements to JetBrains AI to help you code faster. I’m going to walk you through some of these updates in this blog post.&#160; Natural language inline AI prompt You can now use JetBrains AI by typing straight into your editor in natural language without opening the AI Assistant tool window. [&#8230;]",
        "contentSnippet": "PyCharm 2024.3 comes with many improvements to JetBrains AI to help you code faster. I’m going to walk you through some of these updates in this blog post.  Natural language inline AI prompt You can now use JetBrains AI by typing straight into your editor in natural language without opening the AI Assistant tool window. […]",
        "guid": "https://blog.jetbrains.com/?post_type=pycharm&p=527669",
        "categories": [
          "ai-assistant",
          "productivity"
        ],
        "isoDate": "2024-11-19T15:25:51.000Z"
      },
      {
        "creator": "Aleksandra Zdrojowa",
        "title": "New Module Layout for sbt Projects",
        "link": "https://blog.jetbrains.com/scala/2024/11/19/new-module-layout-for-sbt/",
        "pubDate": "Tue, 19 Nov 2024 15:00:19 +0000",
        "content:encodedSnippet": "Try out the enhanced sbt integration with IntelliJ Scala Plugin 2024.3\nWe’re introducing a new mode that better represents the structure of sbt projects in IntelliJ IDEA by organizing main and test sources into separate modules. The improved layout resolves several issues with compilation and highlighting. It also allows using different compiler options for main and test sources.\nWe strongly encourage you to try out this new functionality and share your feedback! Enable it via Settings | Build, Execution, Deployment | Build Tools | sbt and select Create separate modules for production and test sources.\nTechnical background\nEach build tool has its own model to represent the project – this includes concepts of modules, dependencies, and much more.When the project is imported to IntelliJ IDEA, it is essential to translate this model into the IDE’s internal model, which may not perfectly align with the build tool’s structure.\nImproperly mapping a given build tool’s model to IntelliJ IDEA’s model can lead to issues, such as code compiling when it shouldn’t (or vice versa) and incorrect highlighting.\nA significant challenge when mapping the sbt model was the limited distinction between main and test sources. When managing dependencies between two modules, all sources from the dependent module were added to the parent module, making it impossible to include only the main sources. Another issue was configuring separate compiler options for main and test sources.\nTo address these issues, a new approach has been developed for mapping the sbt model to IntelliJ IDEA – creating separate modules for main and test sources.\n\n\n\n\nHow it works\nFor each project declared in the sbt build, two additional modules are created: main and test. They contain the main and test sources, respectively.\n\n\n\n\n\nWhen the project is reloaded in the new mode, each run configuration that references a module should switch to the corresponding main or test module. This happens automatically when the new mode is activated. In very rare cases, it may not be possible to change the modules in the run configurations automatically. If this happens, a notification will appear, giving you the option to update the run configurations manually. If you miss the notification, you can still update the run configurations by explicitly using the Update Run Configurations to the new module naming scheme action.\n\n\n\n\n\nKey improvements\nThese examples illustrate the most noticeable changes. However, enabling the new mode also allows for many other improvements, such as more accurate handling of transitive dependencies, support for compile->test dependencies, and better management of -internal configurations.\n\n\n\n\nDifferent compiler options for Compile and Test scopes\nsbt allows you to declare different compiler options in various configuration scopes. The new project model in IntelliJ IDEA now leverages this capability by recognizing compiler options declared in the Test scope, allowing you to configure different options for Compile and Test scopes in the IDE.\nFor example, if you configure scalacOptions in an sbt project like this:\nTest / scalacOptions += \"-Ywarn-value-discard\"\nthen warnings about discarded values will only be displayed in the test sources.\n\nIf you configure the options in the Compile scope like this:\nCompile / scalacOptions += \"-Ywarn-value-discard\"\nthen warnings can be displayed both in the main and test sources.\n\n\n\n\n\nCompile scope project dependencies\nKeeping main and test sources in separate modules allows for a more accurate representation of dependencies. This is particularly significant for classpath dependencies, which are always per-configuration in sbt.\nLet’s consider a very common dependency example:\ncore.dependsOn(foo)\nwhich is always resolved to \ncore.dependsOn(foo %”compile->compile”)\nWhen separate modules for main and sources are created, this dependency resolves so that both core.main and core.test modules contain only the core.foo.main dependency. None of the core modules has foo.test in its dependencies, which is a proper sbt representation.\n\n\nIt’s worth mentioning that in the old implementation, the core module included the entire foo module. This meant that core test sources had access to foo test sources.\n\n\n\n\nHow to enable this feature\nAs this feature is currently in Beta, it is not enabled by default. Enable it via Settings | Build, Execution, Deployment | Build Tools | sbt and select Create separate modules for production and test sources.\n\n\n\n\n\nFeedback\nWe need your feedback! If you encounter any bugs in this feature, please report them to our YouTrack. If you have any questions, feel free to ask them on in our Discord.\nHappy developing!\nThe IntelliJ Scala Plugin team",
        "dc:creator": "Aleksandra Zdrojowa",
        "content": "Try out the enhanced sbt integration with IntelliJ Scala Plugin 2024.3 We’re introducing a new mode that better represents the structure of sbt projects in IntelliJ IDEA by organizing main and test sources into separate modules. The improved layout resolves several issues with compilation and highlighting. It also allows using different compiler options for main [&#8230;]",
        "contentSnippet": "Try out the enhanced sbt integration with IntelliJ Scala Plugin 2024.3 We’re introducing a new mode that better represents the structure of sbt projects in IntelliJ IDEA by organizing main and test sources into separate modules. The improved layout resolves several issues with compilation and highlighting. It also allows using different compiler options for main […]",
        "guid": "https://blog.jetbrains.com/?post_type=scala&p=527952",
        "categories": [
          "intellij",
          "sbt",
          "scala"
        ],
        "isoDate": "2024-11-19T15:00:19.000Z"
      },
      {
        "creator": "Vaclav Pech",
        "title": "The MPS 2024.3 Early Access Program Is Open",
        "link": "https://blog.jetbrains.com/mps/2024/11/the-mps-2024-1-eap-has-started-2-2/",
        "pubDate": "Tue, 19 Nov 2024 13:07:36 +0000",
        "content:encodedSnippet": "The first EAP build of MPS 2024.3 is now ready for you to download and try!\nDOWNLOAD MPS 2024.3 EAP\nThe new version includes numerous fixes and improvements. Here are the two major ones that deserve special attention:\nIcon handling\nIcons and images that use a path relative to the module are no longer copied during generation next to the places of their individual usage. Instead, they are copied to the distribution module once as image files and are available for use at this single location. This has two immediate benefits: avoiding the duplication of image files to save disk space and the ability to access the images both from the distribution and from the source module.\nConstant icons\nIn addition to the existing TextIcon and FileIcon concepts, a new ConstantFieldIcon concept has become available. It allows an icon to be specified by reference to a concrete static field declaration holding an instance of javax.swing.Icon.\nTextGen binary outcome\nInspired by the need for the improved handling of icon files, there is now a new mechanism to produce binary output during the TextGen process instead of text. The new API consists of a write operation that directly manipulates data as instances of byte[].\nNumerous bug fixes\nYou can find a full list of the issues we’ve fixed here.\nThis is only the first EAP release. We will keep adding more features and bigfixes to MPS 2024.3, so stay tuned!\nYour JetBrains MPS team",
        "dc:creator": "Vaclav Pech",
        "content": "The first EAP build of MPS 2024.3 is now ready for you to download and try! DOWNLOAD MPS 2024.3 EAP The new version includes numerous fixes and improvements. Here are the two major ones that deserve special attention: Icon handling Icons and images that use a path relative to the module are no longer copied [&#8230;]",
        "contentSnippet": "The first EAP build of MPS 2024.3 is now ready for you to download and try! DOWNLOAD MPS 2024.3 EAP The new version includes numerous fixes and improvements. Here are the two major ones that deserve special attention: Icon handling Icons and images that use a path relative to the module are no longer copied […]",
        "guid": "https://blog.jetbrains.com/?post_type=mps&p=528203",
        "categories": [
          "releases",
          "eap",
          "release"
        ],
        "isoDate": "2024-11-19T13:07:36.000Z"
      },
      {
        "creator": "Siva Katamreddy",
        "title": "From Code to Clarity With the Redesigned Structure Tool Window",
        "link": "https://blog.jetbrains.com/idea/2024/11/from-code-to-clarity-with-the-redesigned-structure-tool-window/",
        "pubDate": "Tue, 19 Nov 2024 13:06:12 +0000",
        "content:encodedSnippet": "Developers usually spend more time reading existing code than writing new code. To understand the existing codebase of an application, developers spend a good amount of time looking at how various frameworks and libraries are configured and how different components interact with each other.\nWhile developing JetBrains AI Assistant, we enriched prompts with context extracted from file links and dependencies. This context proved valuable for both AI and human understanding.\nIn this article, you will learn:\nHow our R&D on AI Assistant led to redesigning the Structure tool window.\nHow to use the new Structure tool window’s Logical view to explore and understand your existing codebase.\nHow you can perform various context-relevant actions from the Structure tool window itself.\nBackground\nAI assistants can produce disappointing results when asked to generate or explain code. This is because they can lack the rich context that developers are aware of. A project is not just code. It’s a complex interplay of components, both explicit like method calls, and implicit, defined by the framework being used. Understanding these intricate connections is crucial for accurate AI assistance.\nTo get the best results from AI Assistant, we need to describe all this context to it. This same context would be invaluable for developers. In IntelliJ IDEA, the main code navigation tool is the Project tool window. It provides a code-level view of the project, including folders, packages, and files. Though familiar, the Project tool window doesn’t show links between code components. Developers have to figure those out themselves by looking for class usages for explicit links and reading the framework documentation for implicit ones.\nUnsurprisingly, IntelliJ IDEA knows a lot about project internals. While implementing support for a language or framework in the IDE, we, as developers, have to understand how a technology works under the hood. For example, if you open a file from the project implemented with the Spring Boot framework, you’ll see components like bean indicators, injection points, and web API endpoints.\nWe recently introduced an internal API to implement domain context providers – code that can collect extended information about a project structure, used tech stack, etc. The first step was to provide better context for AI Assistant. We conducted R&D by seamlessly enriching prompts with the information from domain providers – this showed good results!\nThe second step involved using this information to show the code structure from the framework perspective. In IntelliJ IDEA, the Structure tool window presents the structure of a selected file. We decided to enhance this window and add a Logical view, which illustrates the file structure from the framework point of view. This means that you can now see how a selected piece of code, such as a file or class, is connected to other parts of the application. This context is sometimes more valuable than the code itself because it helps you understand how an application works.\nStructure tool window redesign\nLet’s explore a Spring Boot application to learn how the new Structure tool window provides better insights into your application by providing a logical structure of the components, indicating how they all work together.\nThe entry point of any Spring Boot application is the main application class annotated with @SpringBootApplication. The class code’s physical structure is simple:\n@SpringBootApplication\npublic class BlogApplication {\n\n\tpublic static void main(String[] args) {\n\t\tSpringApplication.run(BlogApplication.class, args);\n\t}\n}\n\nThe magic of Spring Boot is hidden in bean configurations – classes that instantiate required services based on various conditions and put them into the Spring context. Now, we can see it!\n\nDomain context providers know which configurations are scanned and which beans are instantiated by bean configuration – it’s all revealed in the structure.\nNow, let’s take a look at how the Structure tool window shows the logical view of a Spring Boot REST controller.\n\nThe Structure tool window displays the autowired Spring beans in the Autowires node and the API endpoints defined in the controller class. When you click on any API endpoint, you will be taken to that method in the editor. You can also click on the API gutter icon to invoke that API endpoint in the HTTP Client.\nThe Spring Framework provides event publishing and consuming capabilities using ApplicationEventPublisher. If the selected Spring bean publishes events using ApplicationEventPublisher, you can see these details under the Publishers node.\n\nSimilarly, if the Spring bean implements event listeners using @EventListener, the listeners’ details are shown under the Listeners node.\n\nLet’s take another example: JPA entities.\nThe Structure tool window also provides a Logical view of JPA entities by providing a lot of context, such as the column mappings, relationship with other entities, Spring Data JPA repositories associated with the entity, and related DTOs and projections:\n\nIf you select the Entity node, you can see the DDL gutter icon which you can use to generate an SQL script to create the table.\nSimilarly, IntelliJ IDEA provides a Logical view for other Spring components like MVC controllers, services, repositories, and configuration classes.\n\nConclusion\nAn application’s complex structure consists of various parts, including code, dependencies, build processes, and deployment scripts. A solid grasp of the connections between these components is crucial for a comprehensive understanding of the application’s architecture and functionality. \nBy introducing domain context providers, we can explain the code structure from another point of view, revealing hidden framework-specific connections between various components. This can be useful for AI Assistant, so its answers could be improved, as well as for developers to help them understand the code better.\nThe redesigned Structure tool window’s Logical view allows you to see the application structure and navigate through linked components. The context-specific actions associated with the selected component make it easy to perform various tasks right from the Structure tool window itself.\nCurrently, the IDE supports Jakarta EE and Spring, and we plan to expand this support to other technologies like frameworks, build tools, and Docker configuration files.\nYou can find the official documentation for Logical structure here .\nThe redesigned Structure tool window is available in IntelliJ IDEA Ultimate 2024.3, and the context-relevant actions support will be available from version 2024.3.1. You can install the latest version of the IDE from the JetBrains Toolbox App, or you can download and install it from our website.\nDownload IntelliJ IDEA",
        "dc:creator": "Siva Katamreddy",
        "content": "Developers usually spend more time reading existing code than writing new code. To understand the existing codebase of an application, developers spend a good amount of time looking at how various frameworks and libraries are configured and how different components interact with each other. While developing JetBrains AI Assistant, we enriched prompts with context extracted [&#8230;]",
        "contentSnippet": "Developers usually spend more time reading existing code than writing new code. To understand the existing codebase of an application, developers spend a good amount of time looking at how various frameworks and libraries are configured and how different components interact with each other. While developing JetBrains AI Assistant, we enriched prompts with context extracted […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=524902",
        "categories": [
          "idea",
          "java",
          "jetbrains-ai",
          "ai-assistant",
          "spring-boot"
        ],
        "isoDate": "2024-11-19T13:06:12.000Z"
      },
      {
        "creator": "Elena Kerpeleva",
        "title": "Busy Plugin Developers Newsletter – Q3 2024",
        "link": "https://blog.jetbrains.com/platform/2024/11/busy-plugin-developers-newsletter-q3-2024/",
        "pubDate": "Mon, 18 Nov 2024 20:39:43 +0000",
        "content:encodedSnippet": "⭐️ Community highlights\nJetBrains Plugin Developer Conf 2024: Kicking off our first event\nOn November 7, we hosted the first-ever JetBrains Plugin Developer Conf, a virtual event dedicated entirely to plugin development for JetBrains products.\n\n\n\n\nThe conference brought together JetBrains experts and plugin developers to explore a wide range of topics, including developing and launching plugins on JetBrains Marketplace, plugin localization, handling user feedback, plugin testing, building collaborative plugins, and more. Attendees also got a glimpse into our future plans for Marketplace and the latest tooling updates.\nMissed the event? You can watch the recording here.\n⭐️ Marketplace updates\nSpecial offers are now displayed on the Pricing Tab\nPaid plugin authors can now display discounts on the Pricing Tab, with the previous price crossed out. To set up a special offer, reach out to the JetBrains Marketplace Support team. Learn more in our documentation. \n\n\n\n\n\n\n\n\nSales report update\nWe’ve made some improvements to our sales report. You can now filter reports by month, and the table includes detailed information about purchased licenses. Additionally, the full report can be downloaded as a .csv file. \n\n\n\n\nMore new UI Icons for your plugins\nWe’ve added over 1,000 new UI icons to the IntelliJ Platform Icons library. These icons are tailored to the new UI and come with Apache 2.0 licensing. You can also use our Figma library to design your own custom icons. Get all the details in this blog post. \nMigrating your IntelliJ IDEA Kotlin plugin to K2 Mode\nIf your plugin code depends on the Kotlin K1 plugin API, this news is for you. Starting from IntelliJ 2024.2.1, you need to migrate to the Kotlin K2 mode. Otherwise, your plugin might not work properly when K2 mode is enabled. Learn more about how to migrate in this blog post.\n⭐️ Plugin development tooling updates\nIntelliJ Platform Plugin Template 2.0.2\nThe IntelliJ Platform Plugin Template is a repository that streamlines the initial stages of plugin development for IntelliJ-based IDEs. The latest update upgrades the Gradle Wrapper to 8.10.2, sets the platformVersion to 2023.3.8, and updates key dependencies. Check out the release notes for more details. \nIntelliJ Plugin Verifier 1.379\nPlugin Verifier Version 1.379 adds the ability to ignore restrictions on the internal com.intellij.languageBundle extension point, improved handling for malformed annotation descriptors with obfuscation, and support for composite action names with namespaces in TeamCity Actions. This update also removes duplicate vendor checks for JetBrains plugins, unifies plugin problem classification, and fixes an issue with empty dotnet plugin names. Check out the changelog for more details.\nIntelliJ Platform Gradle Plugin 2.0 is out\nVersion 2.0 of the IntelliJ Platform Gradle Plugin is now available. This updated plugin for the Gradle build system simplifies the configuration of environments for building, testing, verifying, and publishing plugins for IntelliJ-based IDEs.  Find all of the details here. \n⭐️ Useful resources\nThreading Model and Background Processes\nThe revamped Threading Model page provides updated guidance on managing concurrency in the IntelliJ Platform, detailing UI thread restrictions, background tasks, and thread safety to help developers build responsive, stable plugins. \nThe new Background Processes page complements this with best practices for handling asynchronous tasks, using progress indicators, and creating cancelable tasks for enhanced user experience and performance.\nWorkspace Model\nThe Workspace Model article introduces plugin developers to the Workspace Model in the IntelliJ Platform, highlighting its architecture, data handling capabilities, and interaction with the Project Model. It explains how to use the Workspace Model to efficiently store, manage, and access project-related data.",
        "dc:creator": "Elena Kerpeleva",
        "content": "⭐️ Community highlights JetBrains Plugin Developer Conf 2024: Kicking off our first event On November 7, we hosted the first-ever JetBrains Plugin Developer Conf, a virtual event dedicated entirely to plugin development for JetBrains products. The conference brought together JetBrains experts and plugin developers to explore a wide range of topics, including developing and launching [&#8230;]",
        "contentSnippet": "⭐️ Community highlights JetBrains Plugin Developer Conf 2024: Kicking off our first event On November 7, we hosted the first-ever JetBrains Plugin Developer Conf, a virtual event dedicated entirely to plugin development for JetBrains products. The conference brought together JetBrains experts and plugin developers to explore a wide range of topics, including developing and launching […]",
        "guid": "https://blog.jetbrains.com/?post_type=platform&p=527916",
        "categories": [
          "marketplace",
          "news",
          "busy-plugin-developers"
        ],
        "isoDate": "2024-11-18T20:39:43.000Z"
      },
      {
        "creator": "Alexandra Charikova",
        "title": "Let’s meet at Slush 2024 in Helsinki!",
        "link": "https://blog.jetbrains.com/blog/2024/11/18/let-s-meet-at-slush-2024-in-helsinki/",
        "pubDate": "Mon, 18 Nov 2024 18:26:29 +0000",
        "content:encodedSnippet": "Meet with our JetBrains for Startups team at Slush 2024 in Helsinki on November 20–21!\nThis November, our JetBrains team is returning for the third year in a row to the most founder-focused event on Earth. Join us at booth 7A2 to discuss how our tools can accelerate your startup’s growth, win exclusive swag, or simply drop by to say hello!\nOur team will be there to talk about AI, scaling startups, and the future of development. In addition, we’ll be showcasing our latest AI-powered tools, including IDEs, AI Assistant, and YouTrack. You can also catch a glimpse of the new tools, special partner offers, and exclusive resources that have been added to our JetBrains Startup Program. Whether you are building your first MVP, scaling up, or refining your product, our tools can support you in the process.\nYou can also learn more about our Partner Program for incubators, accelerators, and investors – a unique opportunity to bring JetBrains tools to your portfolio companies. To meet with us, book a slot via the Slush Platform, reach out at startups@jetbrains.com, or simply stop by our booth.\nDon’t miss our special activities, including a Wheel of Fortune with special prizes to be won!\n\n\n\n\nWhere to find us:\nHall: 7 | Booth: 7A2, near the Builder Stage and Mentoring Area\nVenue: Messukeskus Helsinki\n\n\n\n\nLearn more about our programs for startups:\nJetBrains Startup Program\nJetBrains Partner Program for incubators, accelerators and investors\nWe look forward to connecting with you at Slush 2024 and exploring how JetBrains can help bring your ideas to life. See you there!",
        "dc:creator": "Alexandra Charikova",
        "content": "Meet with our JetBrains for Startups team at Slush 2024 in Helsinki on November 20–21! This November, our JetBrains team is returning for the third year in a row to the most founder-focused event on Earth. Join us at booth 7A2 to discuss how our tools can accelerate your startup’s growth, win exclusive swag, or [&#8230;]",
        "contentSnippet": "Meet with our JetBrains for Startups team at Slush 2024 in Helsinki on November 20–21! This November, our JetBrains team is returning for the third year in a row to the most founder-focused event on Earth. Join us at booth 7A2 to discuss how our tools can accelerate your startup’s growth, win exclusive swag, or […]",
        "guid": "https://blog.jetbrains.com/?post_type=blog&p=528503",
        "categories": [
          "events",
          "startup-offer",
          "startups"
        ],
        "isoDate": "2024-11-18T18:26:29.000Z"
      },
      {
        "creator": "Teodor Irkhin",
        "title": "Kotlin K2 Mode Becomes Stable",
        "link": "https://blog.jetbrains.com/idea/2024/11/k2-mode-becomes-stable/",
        "pubDate": "Mon, 18 Nov 2024 14:16:21 +0000",
        "content:encodedSnippet": "In IntelliJ IDEA 2024.3, K2 mode is out of Beta and is now Stable and ready for general use. K2 mode significantly improves Kotlin code analysis stability, memory consumption efficiency, and the IDE’s overall performance, and it supports Kotlin 2.1 language features.\nBackground\nK2 mode in IntelliJ IDEA was developed to address limitations in the previous version of the Kotlin plugin, including various performance and stability issues. It aims to enhance the efficiency of the Kotlin plugin for IntelliJ IDEA by improving code analysis stability and performance while reducing UI freezes. Additionally, K2 mode enables support for new language features that will be introduced in Kotlin 2.1 and later versions.\nCompatibility\nIntelliJ IDEA’s K2 mode doesn’t depend on the Kotlin compiler version specified in the project’s build settings. K2 mode represents an almost complete rewrite of Kotlin support within the IDE. The name “K2” reflects that the Kotlin plugin includes an internal version of the K2 Kotlin compiler, which it uses for code analysis, while K1 mode uses the K1 compiler. The version of the Kotlin compiler bundled in IntelliJ IDEA is entirely independent of the version specified in the project’s build file, though it may affect the range of supported Kotlin versions in projects.\nHow to enable K2 mode\nTo enable K2 mode, go to Preferences/Settings | Languages & Frameworks | Kotlin and select the Enable K2 mode checkbox.\n\n\n\n\nResults\nAdoption\nSince the 2024.2 release, K2 mode (Beta) has shown adoption rates of 15% – and this number is growing weekly. K2 mode was enabled by default starting with 2024.3 EAP 1, and 86% of developers who tried it are still using it.\nPerformance\nWith the new architecture, K2 mode has vast potential for future enhancements, and we already have improvements in Kotlin code analysis, completion, and navigation speed. \nThere are benchmarks that we use to measure the performance of the most popular IntelliJ IDEA features. These benchmarks work on real codebases, including open-source and internal projects. Here are some of the projects we measured the performance on:\nIntelliJ IDEA: the IntelliJ IDEA Ultimate’s source code (closed source)\nkotlinx.coroutines https://github.com/Kotlin/kotlinx.coroutines \nKtor: https://github.com/ktorio/ktor\n\n\n\n\nBelow are the results. Lower is better.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnsupported functionality \nSome third-party IntelliJ IDEA plugins that depend on the Kotlin plugin may be currently unavailable because of recent changes to the Kotlin plugin API. We’re actively working on supporting plugin authors to make their plugins compatible with K2 mode as quickly as possible. For more information, please refer to our detailed migration guide.\nSome functionality like Kotlin scratch file support, as well as some minor inspections, intention actions, and quick-fixes are still in progress and will be supported in the next version.\nPlans for the future\nBy the 2025.1 version, we plan to make K2 mode the default option.\nWith the new architecture, we’ve broken the ceiling of previous limitations, and we now have many new ways to improve the future performance of the Kotlin plugin. We’ll continue to make it more performant, memory-efficient, and stable to make your experience smoother. While K2 mode is a powerful tool, it’s important to note that it won’t address all challenges immediately, but it does provide a great foundation from which we can make further improvements! \nThe future of Kotlin awaits!",
        "dc:creator": "Teodor Irkhin",
        "content": "In IntelliJ IDEA 2024.3, K2 mode is out of Beta and is now Stable and ready for general use. K2 mode significantly improves Kotlin code analysis stability, memory consumption efficiency, and the IDE’s overall performance, and it supports Kotlin 2.1 language features. Background K2 mode in IntelliJ IDEA was developed to address limitations in the [&#8230;]",
        "contentSnippet": "In IntelliJ IDEA 2024.3, K2 mode is out of Beta and is now Stable and ready for general use. K2 mode significantly improves Kotlin code analysis stability, memory consumption efficiency, and the IDE’s overall performance, and it supports Kotlin 2.1 language features. Background K2 mode in IntelliJ IDEA was developed to address limitations in the […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=527536",
        "categories": [
          "idea",
          "kotlin",
          "news",
          "intelij-idea",
          "k2"
        ],
        "isoDate": "2024-11-18T14:16:21.000Z"
      },
      {
        "creator": "Kerry Beetge",
        "title": "Qodana Case Studies: How Moovit Prevents Production Incidents With Code Analysis by Qodana",
        "link": "https://blog.jetbrains.com/qodana/2024/11/qodana-case-studies-moovit/",
        "pubDate": "Mon, 18 Nov 2024 13:03:28 +0000",
        "content:encodedSnippet": "Moovit – a popular commuter app serving 1.5 billion users in over 3,500 cities – has become a critical part of people’s daily transit since its inception in 2012. \nAs with any large-scale application, the Moovit team has to maintain a clean and sustainable codebase to limit outages and ensure a smooth and effective service for its widespread user base. This also had to be achieved within a team that included users of Java, Spring, Jenkins, and IntelliJ IDEA. \nTechnically, this requires:\nNull pointer detection and finding other flaws that can cause outages.\nReducing production issues in the development stage.\nEnforcing critical code rules, team-wide.\nEnhancing developer productivity and adopting best practices.\n\n\n\n\nPaving the road to production readiness with Qodana\nAfter careful deliberation, Moovit selected Qodana. They were impressed by its strong integration capabilities, competitive pricing, and high level of customization – a combination of features they couldn’t find with another provider. Once these important boxes were checked, the Moovit team used Qodana to:\nHelp run quick scans for early issue detection.\nCreate custom rules and configurations suited to their use case. \nImprove scalability and cost-effectiveness throughout the development process. \nThe result?\n“In the long term, it has stabilized our production system and allowed developers to avoid fixing issues too late in the pipeline. We’re seeing the shift of the paradigm, where development teams follow the policies and save a few sleepless nights with Qodana.”\n\n            \nAmit Weinblum\n                                                                Infrastructure Team Leader at Moovit\n                                    \nView the official case study below for more information on the project and how Moovit benefited from prioritizing code quality with Qodana and IntelliJ IDEA. You can also view other Qodana case studies for more information on how your team can benefit from Qodana. \nView Case Study",
        "dc:creator": "Kerry Beetge",
        "content": "Moovit – a popular commuter app serving 1.5 billion users in over 3,500 cities – has become a critical part of people’s daily transit since its inception in 2012.&#160; As with any large-scale application, the Moovit team has to maintain a clean and sustainable codebase to limit outages and ensure a smooth and effective service [&#8230;]",
        "contentSnippet": "Moovit – a popular commuter app serving 1.5 billion users in over 3,500 cities – has become a critical part of people’s daily transit since its inception in 2012.  As with any large-scale application, the Moovit team has to maintain a clean and sustainable codebase to limit outages and ensure a smooth and effective service […]",
        "guid": "https://blog.jetbrains.com/?post_type=qodana&p=527652",
        "categories": [
          "case-study-qodana",
          "idea",
          "qodana",
          "casestudy",
          "intellijidea"
        ],
        "isoDate": "2024-11-18T13:03:28.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": [
      {
        "creator": "Kidai Kwon",
        "title": "Building a User Signals Platform at Airbnb",
        "link": "https://medium.com/airbnb-engineering/building-a-user-signals-platform-at-airbnb-b236078ec82b?source=rss----53c7c27702d5---4",
        "pubDate": "Wed, 20 Nov 2024 19:27:27 GMT",
        "content:encodedSnippet": "How Airbnb built a stream processing platform to power user personalization.\nBy: Kidai Kwon, Pavan Tambay, Xinrui Hua, Soumyadip (Soumo) Banerjee, Phanindra (Phani) Ganti\n\nOverview\nUnderstanding user actions is critical for delivering a more personalized product experience. In this blog, we will explore how Airbnb developed a large-scale, near real-time stream processing platform for capturing and understanding user actions, which enables multiple teams to easily leverage real-time user activities. Additionally, we will discuss the challenges encountered and valuable insights gained from operating a large-scale stream processing platform.\nBackground\nAirbnb connects millions of guests with unique homes and experiences worldwide. To help guests make the best travel decisions, providing personalized experiences throughout the booking process is essential. Guests may move through various stages — browsing destinations, planning trips, wishlisting, comparing listings, and finally booking. At each stage, Airbnb can enhance the guest experience through tailored interactions, both within the app and through notifications.\nThis personalization can range from understanding recent user activities, like searches and viewed homes, to segmenting users based on their trip intent and stage. A robust infrastructure is essential for processing extensive user engagement data and delivering insights in near real-time. Additionally, it’s important to platformize the infrastructure so that other teams can contribute to deriving user insights, especially since many engineering teams are not familiar with stream processing.\nAirbnb’s User Signals Platform (USP) is designed to leverage user engagement data to provide personalized product experiences with many goals:\n\nAbility to store both real-time and historic data about users’ engagement across the site.\nAbility to query data for both online use cases and offline data analyses.\nAbility to support online serving use cases with real-time data, with an end-to-end streaming latency of less than 1 second.\nAbility to support asynchronous computations to derive user understanding data, such as user segments and session engagement.\nAbility to allow various teams to easily define pipelines to capture user activities.\n\nUSP System Architecture\nUSP consists of a data pipeline layer and an online serving layer. The data pipeline layer is based on the Lambda architecture with an online streaming component that processes Kafka events near real-time and an offline component for data correction and backfill. The online serving layer performs read time operations by querying the Key Value (KV) store, written at the data pipeline layer. At a high-level, the below diagram demonstrates the lifecycle of user events produced by Airbnb applications that are transformed via Flink, stored in the KV store, then served via the service layer:\nFigure 1. USP System Architecture Overview\nKey design choices that were made:\n\nWe chose Flink streaming over Spark streaming because we previously experienced event delays with Spark due to the difference between micro-batch streaming (Spark streaming), which processes data streams as a series of small batch jobs, and event-based streaming (Flink), which processes event by event.\nWe decided to store transformed data in an append-only manner in the KV store with the event processing timestamp as a version. This greatly reduces complexity because with at-least once processing, it guarantees idempotency even if the same events are processed multiple times via stream processing or batch processing.\nWe used a config based developer workflow to generate job templates and allow developers to define transforms, which are shared between Flink and batch jobs in order to make the USP developer friendly, especially to other teams that are not familiar with Flink operations.\n\nUSP Capabilities\nUSP supports several types of user event processing based on the above streaming architecture. The diagram below is a detailed view of various user event processing flows within USP. Source Kafka events from user activities are first transformed into User Signals, which are written to the KV store for querying purposes and also emitted as Kafka events. These transform Kafka events are consumed by user understanding jobs (such as User Segments, Session Engagements) to trigger asynchronous computations. The USP service layer handles online query requests by querying the KV store and performing any other query time operations.\nFigure 2. USP Capabilities Flow\nUser Signals\nUser signals correspond to a list of recent user activities that are queryable by signal type, start time, and end time. Searches, home views, and bookings are example signal types. When creating a new User Signal, the developer defines a config that specifies the source Kafka event and the transform class. Below is an example User Signal definition with a config and a user-defined transform class.\n- name: example_signal\n  type: simple\n  signal_class: com.airbnb.usp.api.ExampleSignal\n  event_sources:\n  - kafka_topic: example_source_event\n    transform: com.airbnb.usp.transforms.ExampleSignalTransform\npublic class ExampleSignalTransform extends AbstractSignalTransform {\n  @Override\n  public boolean isValidEvent(ExampleSourceEvent event) {\n  }\n  @Override\n  public ExampleSignal transform(ExampleSourceEvent event) {\n  }\n}\nDevelopers can also specify a join signal, which allows joining multiple source Kafka events with a specified join key near real-time via stateful streaming with RocksDB as a state store.\n- name: example_join_signal\n  type: left_join\n  signal_class: com.airbnb.usp.api.ExampleJoinSignal\n  transform: com.airbnb.usp.transforms.ExampleJoinSignalTransform\n  left_event_source:\n    kafka_topic: example_left_source_event\n    join_key_field: example_join_key\n  right_event_source:\n    kafka_topic: example_right_source_event\n    join_key_field: example_join_key\nOnce the config and the transform class are defined for a signal, developers run a script to auto-generate Flink configurations, backfill batch files, and alert files like below:\n$ python3 setup_signal.py --signal example_signal\nGenerates:\n# Flink configuration related\n[1] ../flink/signals/flink-jobs.yaml\n[2] ../flink/signals/example_signal-streaming.conf\n# Backfill related files\n[3] ../batch/example_signal-batch.py\n# Alerts related files\n[4] ../alerts/example_signal-events_written_anomaly.yaml\n[5] ../alerts/example_signal-overall_latency_high.yaml\n[6] ../alerts/example_signal-overall_success_rate_low.yaml\nUser Segments\nUser Segments provide the ability to define user cohorts near real-time with different triggering criteria for compute and various start and expiration conditions. The user-defined transform exposes several abstract methods which developers can simply implement the business logic without having to worry about streaming components.\nFor example, the active trip planner is a User Segment that assigns guests into the segment as soon as the guest performs a search and removes the guests from the segment after 14 days of inactivity or once the guest makes a booking. Below are abstract methods that the developer will implement to create the active trip planner User Segment:\n\ninSegment: Given the triggered User Signals, check if the given user is in the segment.\ngetStartTimestamp: Define the start time when the given user will be in the segment. For example, when the user starts a search on Airbnb, the start time will be set to the search timestamp and the user will be immediately placed in this user segment.\ngetExpirationTimestamp: Define the end time when the given user will be out of the segment. For example, when the user performs a search, the user will be in the segment for the next 14 days until the next triggering User Signal arrives, then the expiration time will be updated accordingly.\n\npublic class ExampleSegmentTransform extends AbstractSegmentTransform {\n  @Override\n  protected boolean inSegment(List<Signal> inputSignals) {\n  }\n  @Override\n  public Instant getStartTimestamp(List<Signal> inputSignals) {\n  }\n  @Override\n  public Instant getExpirationTimestamp(List<Signal> inputSignals) {\n  }\n}\nSession Engagements\nThe session engagement Flink job enables developers to group and analyze a series of short-term user actions, known as session engagements, to gain insights into holistic user behavior within a specific timeframe. For example, understanding the photos of homes the guest viewed in the current session would be useful to derive the guest preference for the upcoming trip.\nAs transform Kafka events from User Signals get ingested, the job splits the stream into keyed streams by user id as a key to allow the computation to be performed in parallel.\nThe job employs various windowing techniques, such as sliding windows and session windows, to trigger computations based on aggregated user actions within these windows. Sliding windows continuously advance by a specified time interval, while session windows dynamically adjust based on user activity patterns. For example, as a user browses multiple listings on the Airbnb app, a sliding window of size 10 minutes that slides every 5 minutes is used to analyze the user’s short term engagement to generate the user’s short term trip preference.\nThe asynchronous compute pattern empowers developers to execute resource intensive operations, such as running ML models or making service calls, without disrupting the real-time processing pipeline. This approach ensures that computed user understanding data is efficiently stored and readily available for rapid querying from the KV store.\nFigure 3. Session Engagements Flow\nFlink Operations\nUSP is a stream processing platform built for developers. Below are some of the learnings from operating hundreds of Flink jobs.\nMetrics\nWe use various latency metrics to measure the performance of streaming jobs.\n\nEvent Latency: From when the user events are generated from applications to when the transformed events are written to the KV store.\nIngestion Latency: From when the user events arrive at the Kafka cluster to when the transformed events are written to the KV store.\nJob Latency: From when the Flink job starts processing source Kafka events to when the transformed events are written to the KV store.\nTransform Latency: From when the Flink job starts processing source Kafka events to when the Flink job finishes the transformation.\nFigure 4. Flink Job Metrics\nEvent Latency is the end-to-end latency measuring when the generated user action becomes queryable. This metric can be difficult to control because if the Flink job relies on client side events, the events themselves may not be readily ingestible due to the slow network on the client device or the batching of the logs on the client device for performance. With these reasons, it’s also preferable to rely on server side events over client side events for the source user events, only if the comparables are available.\nIngestion Latency is the main metric we monitor. This also covers various issues that can happen in different stages such as overloaded Kafka topics and latency issues when writing to the KV store (from client pool issues, rate limits, service instability).\nImproving Flink Job stability with standby Task Managers\nFlink is a distributed system that runs on a single Job Manager that orchestrates tasks in different Task Managers that act as actual workers. When a Flink job is ingesting a Kafka topic, different partitions of the Kafka topic are assigned to different Task Managers. If one Task Manager fails, incoming Kafka events from the partitions assigned to that task manager will be blocked until a new replacement task manager is created. Unlike the online service horizontal scaling where pods can be simply replaced with traffic rebalancing, Flink assigns fixed partitions of input Kafka topics to Task Managers without auto reassignment. This creates large backlogs of events from those Kafka partitions from the failed Task Manager, while other Task Managers are still processing events from other partitions.\nIn order to reduce this downtime, we provision extra hot-standby pods. In the diagram below, on the left side, the job is running at a stable state with four Task Managers with one Task Manager (Task Manager 5) as a hot-standby. On the right side, in case of the Task Manager 4 failure, the standby Task Manager 5 immediately starts processing tasks for the terminated pod, instead of waiting for the new pod to spin up. Eventually another standby pod will be created. In this way, we can achieve better stability with a small cost of having standby pods.\nFigure 5. Flink Job Manager And Task Manager Setup\nConclusion\nOver the last several years, USP has played a crucial role as a platform empowering numerous teams to achieve product personalization. Currently, USP processes over 1 million events per second across 100+ Flink jobs and the USP service serves 70k queries per second. For future work, we are looking into different types of asynchronous compute patterns via Flink to improve performance.\nAcknowledgments\nUSP is a collaborative effort between Airbnb’s Search Infrastructure and Stream Infrastructure, particularly Derrick Chie, Ran Zhang, Yi Li. Big thanks to our former teammates who contributed to this work: Emily Hsia, Youssef Francis, Swaroop Jagadish, Brandon Bevans, Zhi Feng, Wei Sun, Alex Tian, Wei Hou.\n\nBuilding a User Signals Platform at Airbnb was originally published in The Airbnb Tech Blog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Kidai Kwon",
        "guid": "https://medium.com/p/b236078ec82b",
        "categories": [
          "personalization",
          "technology",
          "machine-learning",
          "engineering",
          "ai"
        ],
        "isoDate": "2024-11-20T19:27:27.000Z"
      }
    ]
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Amy Nguyen",
        "title": "Top 5 GitHub Copilot Features in Visual Studio from Microsoft Ignite 2024",
        "link": "https://devblogs.microsoft.com/visualstudio/top-5-github-copilot-features-in-visual-studio-from-microsoft-ignite-2024/",
        "pubDate": "Fri, 22 Nov 2024 13:00:25 +0000",
        "content:encodedSnippet": "At this year’s Microsoft Ignite, it was truly exciting to see Scott, Dalia, and Jessie demo some of the most innovative features of GitHub Copilot that are transforming the developer experience in Visual Studio. From the breakout session, we highlighted five standout features that are pushing productivity to the next level. Whether you’re working on complex edits or crafting custom workflows, these tools showcase how AI can elevate your coding game in ways you never thought possible.\nWatch the Ignite Session Here\n\n*Note: It will take 24-48 hours after the session for the recording to be uploaded.\n1. Copilot Edits: Collaborative Iterations\n\nIt was amazing to see Copilot Edits in action. This new editing surface is designed for seamless multi-file changes, making large-scale updates across your project feel effortless. Imagine needing to redesign your UI or implement logic that spans multiple files—Copilot handles it by generating a change plan tailored to your goals, without the usual headache of tracking dependencies manually.\nWhat makes this feature transformative is how Copilot analyzes your codebase, identifies the necessary edits through multiple files, and iterates on those changes while maintaining the context from your conversation history. And the best part? Visual Studio’s inline code previews let you review, modify, or accept suggestions directly in the IDE, making complex updates feel more like a smooth collaboration than a solo effort. This iterative approach ensures that Copilot evolves alongside your intentions, keeping you in control while streamlining your updates.\n2. Vision: Code Smarter with Contextual Understanding\n\nThis feature blew us away with its ability to process images and screenshots, allowing GitHub Copilot to instantly grasp your intentions, without the hassle of going back and forth, tediously describing UI changes.\nFor instance, when updating a UI, you can simply paste screenshots of the current and desired states into Copilot. It analyzes the differences, determines the necessary changes, and suggests edits tailored to your goals. Vision bridges the gap between visual inputs and actionable suggestions, empowering developers to handle visually-oriented tasks with ease. It truly makes Copilot feel like a collaborative partner in your workflow.\n3. Icebreakers: A Launchpad for Productivity\n\nWe all know that getting started can sometimes feel like the hardest part, but Icebreakers make it so much easier. These curated starter prompts, like “Refactor my code” or “Add a new feature,” inspire action and guide your initial steps when facing common coding challenges. Seeing Scott demo how Icebreakers now support more complex, multi-step workflows was incredible. They seamlessly integrate with Copilot Edits, enabling actionable plans for even the most intricate tasks.\nWhether you’re navigating an unfamiliar codebase or tackling a large project, Icebreakers reduce cognitive load, giving you a clear starting point and boosting productivity right from the get-go. It was exciting to see how this feature now helps developers take control of complex tasks and move forward with confidence.\n4. Function Calling: Bridging Gaps in Logic\n\nFunction Calling, which enhances GitHub Copilot’s ability to provide precise recommendations by automatically determining the relevant context and tools based on your natural language prompts. Copilot seamlessly integrates the necessary context, saving you time and effort.\nFunction Calling streamlines the process by dynamically accessing open files and project structure, eliminating the need to manually specify paths. This makes debugging and integration faster and more efficient. Watching them demo this feature was a highlight, as they showed how quickly developers can go from idea to implementation with Copilot’s context-aware functionality!\n5. Custom Instructions: Your Copilot, Your Way\n\nCustom Instructions allow Copilot to adapt to your unique team workflow. No two teams are alike, and seeing Jessie demonstrate how you can fine-tune Copilot’s behavior to align with your team’s coding conventions and communication style was truly amazing!\nWith Custom Instructions, you can add team-specific practices to your Copilot instructions file, ensuring consistency across your codebase. This feature is a game-changer for teams who want to make their workflow more efficient while ensuring alignment with best practices.\nYour New Development Sidekick\nThe advancements showcased at Ignite reaffirm GitHub Copilot’s role as a transformative tool for developers. From simplifying multi-file edits to embracing team-specific workflows, these features show how AI can be both powerful and adaptable.\nTry these features in Visual Studio today and see how GitHub Copilot can help you code smarter, faster, and with more confidence.\nWhich feature are you most excited to try? Let us know in the comments below!\nDownload Visual Studio 2022\n\nThe post Top 5 GitHub Copilot Features in Visual Studio from Microsoft Ignite 2024 appeared first on Visual Studio Blog.",
        "dc:creator": "Amy Nguyen",
        "content": "<p>At this year’s Microsoft Ignite, it was truly exciting to see Scott, Dalia, and Jessie demo some of the most innovative features of GitHub Copilot that are transforming the developer experience in Visual Studio. From the breakout session, we highlighted five standout features that are pushing productivity to the next level. Whether you&#8217;re working on [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/top-5-github-copilot-features-in-visual-studio-from-microsoft-ignite-2024/\">Top 5 GitHub Copilot Features in Visual Studio from Microsoft Ignite 2024</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "At this year’s Microsoft Ignite, it was truly exciting to see Scott, Dalia, and Jessie demo some of the most innovative features of GitHub Copilot that are transforming the developer experience in Visual Studio. From the breakout session, we highlighted five standout features that are pushing productivity to the next level. Whether you’re working on […]\nThe post Top 5 GitHub Copilot Features in Visual Studio from Microsoft Ignite 2024 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251478",
        "categories": [
          "Copilot",
          "GitHub Copilot",
          "Productivity",
          "Visual Studio",
          "Ignite"
        ],
        "isoDate": "2024-11-22T13:00:25.000Z"
      },
      {
        "creator": "Mads Kristensen",
        "title": "Making you more productive with Visual Studio v17.12",
        "link": "https://devblogs.microsoft.com/visualstudio/making-you-more-productive-with-visual-studio-v17-12/",
        "pubDate": "Thu, 21 Nov 2024 13:00:47 +0000",
        "content:encodedSnippet": "The 12th update to Visual Studio 2022 is packed with lots of exciting new features that users have been asking for! Here are some of the awesome highlights from this release that are some of my personal favorites. For all the details, be sure to check out our release notes.\nCopy from the Error List\nYou see an error in the Error List that you don’t know how to fix. So, you select it and hit Ctrl+C to copy the description for a web search. After you’ve pasted it into the search engine, you realize it copied all column headers and row values instead of just the description. Now you must delete everything except the error description before you can perform the web search. This is cumbersome, but now we have a fix!\n\nWhen you copy an error from the Error List using Ctrl+C, only the description is copied to the clipboard. This makes it easier to search for the error online or share it with others.\nYou can still copy the entire row by right-clicking the error and selecting Copy Row from the context menu or hitting Ctrl+Shift+C.\nIf what you wanted to do with the error description was to do a web search, then just hit Ctrl+F1 to search for information about the error online.\nGo to line anywhere in code search\nSometimes you know that there’s an issue on a certain line in your code and you want to get to it quickly. Maybe you were told about an error being thrown on line 43 of some file, or you want to get to the bottom of a specific file.\nCode search now supports quick navigation to a specific line in your code.\nOpen Code Search and go to a line in the current document by using colon + line number. For example, :39 will navigate to line 39 in the active file.\n\nYou can also go to a line in a different document by using file name + colon + line number. For example, Order:43 will navigate to line 43 in Order.cs. If you don’t specify the exact file name, then the search will try to find the best match.\n\nDock the code search window\nIf you need Code or Feature Search to stay out of your way, you now have more control over the behavior of the search window.\nYou can now dock the search window and perform tool window actions with it, like Solution Explorer and others.\n\nAfter opening Code Search or Feature Search, click on the box icon at the top right to convert it into a tool window. You may choose to dock it elsewhere, pop it out, auto-hide, etc. You can revert to the dismissible window by closing the tool window and reopening search.\n\nWe’ve also simplified and cleaned up the previewing experience in search. There is now one button, indicated with an eye icon, to toggle the preview on and off.\n\nThe position of the preview panel will also adjust based on the dimensions of the search window.\n\nRefresh the Find results\nWe heard from a lot of users that it’s frustrating having to reopen the Find window and go through the motions of redoing a search to get updated results. Maybe you just refactored some code and want to confirm everything has been changed as expected, or you pulled some recent changes and need your recent Find operation to reflect those updates.\nAfter completing Find in Files, you will now have the option to Refresh the Find results in the window. You’ll get your updated results without having to redo the search.\n\nWe’ve also redesigned the former Repeat Find option to distinguish it from Refresh. It is now represented as Modify Find with a pencil icon. This button will still reopen Find in Files with the same search criteria you used for that results window.\n\nCopy files between instances\nWe are excited to introduce a highly requested feature in Visual Studio! You can now seamlessly copy and paste code files and folders between different Visual Studio instances using the Solution Explorer. Simply select the desired file or folder, use Ctrl+C or Ctrl+X, switch to another Visual Studio instance, and use Ctrl+V to include those files or folders in your new solution. All changes will be accurately reflected in the file system.\nIn addition to copying and pasting, you can also drag the files and folders from one instance of Visual Studio to another.\n\nPreviously, this functionality was available only for a few project types, but we have now expanded it to include all the major project types in Visual Studio.\nMulti-project launch configuration\nThe Multi-Project Launch Configuration feature allows you to set up and save profiles for launching specific projects within a multi-project solution in predefined states for debugging.\n\nThis simplifies the process of working with complex solutions, improves debugging efficiency, and enables easy sharing of configurations among team members.\nThank you!\nWe deeply appreciate your valuable feedback and feature requests, which have been instrumental in shaping these updates. Your insights have a profound impact on our development process, and we are committed to continually enhancing your experience with Visual Studio. We encourage you to keep sharing your thoughts and suggestions, as they are vital in helping us make Visual Studio the best it can be. Thank you for your continued support and collaboration.\nHappy Coding!\nThe post Making you more productive with Visual Studio v17.12 appeared first on Visual Studio Blog.",
        "dc:creator": "Mads Kristensen",
        "content": "<p>The 12th update to Visual Studio 2022 is packed with lots of exciting new features that users have been asking for! Here are some of the awesome highlights from this release that are some of my personal favorites. For all the details, be sure to check out our release notes. Copy from the Error List [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/making-you-more-productive-with-visual-studio-v17-12/\">Making you more productive with Visual Studio v17.12</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "The 12th update to Visual Studio 2022 is packed with lots of exciting new features that users have been asking for! Here are some of the awesome highlights from this release that are some of my personal favorites. For all the details, be sure to check out our release notes. Copy from the Error List […]\nThe post Making you more productive with Visual Studio v17.12 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251450",
        "categories": [
          "Accessibility",
          "Productivity",
          "Visual Studio",
          "Search"
        ],
        "isoDate": "2024-11-21T13:00:47.000Z"
      },
      {
        "creator": "Mads Kristensen",
        "title": "Copy files across instances of Visual Studio",
        "link": "https://devblogs.microsoft.com/visualstudio/copy-files-across-instances-of-visual-studio/",
        "pubDate": "Wed, 20 Nov 2024 13:00:30 +0000",
        "content:encodedSnippet": "Transferring code files between different instances of Visual Studio has often been a tedious task. To simplify this process, Visual Studio 2022 now includes a feature that allows you to easily copy and paste code files and folders between instances using the Solution Explorer. This enhancement aims to streamline workflow and save time.\n\nUntil now, moving code files and folders between different Visual Studio instances has been a hassle. Developers often had to manually relocate files, risking errors and inefficiencies in their workflow. With the new copy and paste functionality, this problem is now a thing of the past. Visual Studio 2022 makes it easier to manage your code files, regardless of the project type.\nHow the Feature Works\nThe process is straightforward:\nSelect the desired file or folder: Navigate to the Solution Explorer and choose the code file or folder you wish to transfer.\nUse Ctrl+C or Ctrl+X: Copy or cut the selected file or folder.\nSwitch to another Visual Studio instance: Open the instance where you want to paste the file or folder.\nUse Ctrl+V: Paste the file or folder. All changes will be accurately reflected in the file system.\nAdditionally, you can also drag and drop files and folders between instances, providing even more flexibility in how you manage your projects.\nExpanded Functionality\nPreviously, this feature was limited to a few specific project types. However, in response to your feedback, we’ve expanded this functionality to include all major project types in Visual Studio. Whether you are working on a web application, a desktop application, or a complex multi-project solution, you can now benefit from this streamlined capability.\nContinuous Improvement\nWe are committed to making Visual Studio the best development environment available. Your feedback is invaluable to us, and it directly influences the improvements we make. This new feature is a testament to our dedication to listening to our users and enhancing their development experience.\nThank you for your continued support and feedback. Together, we are making Visual Studio better every day.\nThe post Copy files across instances of Visual Studio appeared first on Visual Studio Blog.",
        "dc:creator": "Mads Kristensen",
        "content": "<p>Transferring code files between different instances of Visual Studio has often been a tedious task. To simplify this process, Visual Studio 2022 now includes a feature that allows you to easily copy and paste code files and folders between instances using the Solution Explorer. This enhancement aims to streamline workflow and save time. Until now, [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/copy-files-across-instances-of-visual-studio/\">Copy files across instances of Visual Studio</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Transferring code files between different instances of Visual Studio has often been a tedious task. To simplify this process, Visual Studio 2022 now includes a feature that allows you to easily copy and paste code files and folders between instances using the Solution Explorer. This enhancement aims to streamline workflow and save time. Until now, […]\nThe post Copy files across instances of Visual Studio appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251424",
        "categories": [
          "Productivity",
          "Visual Studio"
        ],
        "isoDate": "2024-11-20T13:00:30.000Z"
      },
      {
        "creator": "Tina Schrepfer (LI)",
        "title": "VisualStudio.Extensibility 17.12: CodeLens support is here!",
        "link": "https://devblogs.microsoft.com/visualstudio/visualstudio-extensibility-17-12-codelens-support-is-here/",
        "pubDate": "Tue, 19 Nov 2024 15:28:38 +0000",
        "content:encodedSnippet": "We continue to invest in the VisualStudio.Extensibility SDK to allow users like you to create extensions that run faster and smoother than ever before! VisualStudio.Extensibility helps you build extensions that run outside the main Visual Studio IDE process for improved performance and reliability, and can be installed without the need to restart Visual Studio. Additional benefits include a sleek and intuitive .NET 8-based API and comprehensive, well-maintained documentation to help you develop amazing extensions faster than ever before.\nThis 17.12 release builds on our previous releases and brings support for CodeLens in the editor. We’ve also addressed feedback from early users and revamped the output window API to make it easier to use.\nGet Started with VisualStudio.Extensibility\n\nFor the latest up-to-date docs and installation instructions, visit https://aka.ms/VisualStudio.Extensibility. We encourage you to report bugs and suggest features via the issue tracker on our GitHub repo, where you can also find extension samples to help you get started.\nWhat’s new for VisualStudio.Extensibility?\nOur 17.12 release of VisualStudio.Extensibility includes the following features:\nCustomized CodeLens experience in the Visual Studio editor by adding your own CodeLens provider (currently released as experimental API)\nRevamped output window API for better discoverability and ease of use\nAdditional diagnostics information for debugging VisualStudio.Extensibility extensions\nAs with previous releases, we continuously update our documentation to reflect the latest features in version 17.12. We have also prepared a comprehensive guide that outlines the three different extensibility models for Visual Studio. This guide explains why VisualStudio.Extensibility is the ideal choice for those new to writing extensions.\nProvide your own CodeLens experience\nCodeLens is an experience in the Visual Studio editor that allows developers like you to stay focused on your work and get contextual information about your code without ever leaving the editor. Using CodeLens, you can quickly find all references of code or see the pass rate of unit tests. With the release of 17.12, extenders can now create a custom CodeLens on supported languages provided by Visual Studio! CodeLens support in VisualStudio.Extensibility goes beyond what the Visual Studio SDK (VSSDK) offers in that it not only allows for custom UI to be displayed for your CodeLens; it also offers a way for users to interact with your custom CodeLens through invokable CodeLens.\nCheck out this sample to learn how you can create a custom interactive word counter CodeLens using this new API. The sample extension allows you to define what to search for and count its occurrences in a C# method block, all from the context of CodeLens!\n\nTo get started on creating your own CodeLens provider, please review our documentation here. CodeLens support is currently released as an experimental API. We welcome questions and suggestions on the API as we work to stabilize it. Note that we currently only allow CodeLenses to be added to existing languages supported by Visual Studio. Stay tuned for when we enable CodeLens support for arbitrary files.\nAccess the output window with ease\nDuring 17.12, we revamped the APIs for writing to Visual Studio’s output window. The original APIs were one of the first APIs we migrated from VSSDK to VisualStudio.Extensibility and had started to show their age. In the time we’ve been working on the new model, we’ve iterated on the principles of API design and refined them. Looking back at the original output window APIs, we realized that they did not meet our standards for simplicity and ease of use. In the revamp, we abstracted away concepts like resource IDs and channels to provide a simpler interface, and we gave users multiple ways to write to the output window, including writing using string, TextWriter, or PipeWriter. Check out the updated docs and sample to see how you can utilize the new and improved APIs!\nGiven that these original APIs were marked as preview, we changed them in accordance with our preview API guidance. For more information about breaking changes, refer to the Breaking Changes article.\nDebug your extensions more easily\nWith this release, we’ve also updated the diagnostics explorer to better assist you in debugging VisualStudio.Extensibility extensions. We separated the diagnostics pages into 2 groups – extension centric and platform centric. This separation makes it simpler to find information specific to your extension versus information that’s about the underlying Visual Studio platform to get more contextual data.\n\n\nOur documentation goes into detail on what each of these pages provide. You can download the latest version of the diagnostics explorer from the Marketplace here.\nWe want to hear from you!\nSince embarking on this journey to provide a new extensibility model for Visual Studio, our goal has always been to keep our ecosystem partners engaged. Besides regular blog posts like this one to update our customers of the latest additions to VisualStudio.Extensibility, we also have extensive and up-to-date documentation on how to use the APIs, as well as media content that gives a quick overview of VisualStudio.Extensibility. We also have 2 different channels for customers to interact with us to either report issues or suggest new features:\nGitHub: Our GitHub page is the primary destination for extenders to ask questions or report issues with respect to creating extensions for Visual Studio. While we try our best to answer questions, we can’t always get to them in real time. Our goal is to eventually have the GitHub page be something that the community can help answer each other’s questions. That can only happen if more extenders adopt VisualStudio.Extensibility to build their extensions.\nDeveloper Community: We primarily use Developer Community to track feature requests. Occasionally, we’ll get issues created in our GitHub page that are related to a feature not yet implemented in VisualStudio.Extensibility. Our practice is to then turn that issue into a suggestion ticket and use that ticket to track upvotes and post updates. In our most recent releases, we closed 2 of these suggestion tickets with the implementation of settings last release, and the support for code lens this release. We encourage you to review the current list of feature requests for VisualStudio.Extensibility and upvote any most relevant to your scenarios.\nKeep those questions and suggestions coming! There are many things we take into consideration when planning our roadmap, but rest assured that customer feedback is something that’s always top of mind for us.\nStay connected with the Visual Studio team by following us on YouTube, Twitter, LinkedIn, Twitch and on Microsoft Learn.\nThe post VisualStudio.Extensibility 17.12: CodeLens support is here! appeared first on Visual Studio Blog.",
        "dc:creator": "Tina Schrepfer (LI)",
        "content": "<p>We continue to invest in the VisualStudio.Extensibility SDK to allow users like you to create extensions that run faster and smoother than ever before! VisualStudio.Extensibility helps you build extensions that run outside the main Visual Studio IDE process for improved performance and reliability, and can be installed without the need to restart Visual Studio. Additional [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/visualstudio-extensibility-17-12-codelens-support-is-here/\">VisualStudio.Extensibility 17.12: CodeLens support is here!</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "We continue to invest in the VisualStudio.Extensibility SDK to allow users like you to create extensions that run faster and smoother than ever before! VisualStudio.Extensibility helps you build extensions that run outside the main Visual Studio IDE process for improved performance and reliability, and can be installed without the need to restart Visual Studio. Additional […]\nThe post VisualStudio.Extensibility 17.12: CodeLens support is here! appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251397",
        "categories": [
          "Extensibility",
          "Visual Studio",
          "CodeLens",
          "Extensions",
          "Visual Studio 2022"
        ],
        "isoDate": "2024-11-19T15:28:38.000Z"
      },
      {
        "creator": "Jessie Houghton",
        "title": "Git tooling updates in Visual Studio 17.12",
        "link": "https://devblogs.microsoft.com/visualstudio/git-tooling-updates-in-visual-studio-17-12/",
        "pubDate": "Mon, 18 Nov 2024 15:37:56 +0000",
        "content:encodedSnippet": "We are thrilled to announce the latest updates to Git tooling in Visual Studio, designed to enhance your development experience and streamline your workflow. These new features are in direct response to user feedback, ensuring that you have the tools you need to be more productive and efficient. For the full list, check out the release notes.\nPull request drafts and templates\nYou can now create pull request drafts and start your descriptions with GitHub templates in Visual Studio. These were the two top requests for the create a pull request experience.\nDraft PRs\nUse the drop-down menu on the Create button to Create as Draft.\n\nPR Templates\nYour default PR template will be used when creating a new PR for both GitHub and Azure DevOps. Learn more about how to add a PR template to your repository in the GitHub documentation and Azure DevOps documentation.\nCreate internal GitHub repos\nVisual Studio now supports internal repos for your GitHub organizations. We also included guidance for each type of repository to give you more clarity on the visibility of the new project depending on which account you’re using.\n\nCopy Git link\nWhenever you share a few lines of code with a colleague, it can often be useful for them to get extra context from your repository. However, if they’re working on something else it can take too long and disrupt their work to checkout your branch.\nNow, you can highlight the code you want to share in your editor, open the context menu with a right click, and under the Git submenu get a shareable link to your code in GitHub or Azure DevOps. This makes it simple and easy to collaborate, and it smooths the flow between the IDE and your remote repos on the web.\n\nYou can also get shareable links directly from commit history. This allows for code not currently checked out or code that exists in previous iterations to be referenced just as effortlessly.\n\nCustomize AI Git commit message\nNow you can add additional instructions to the prompt for generating your Git commit message with GitHub Copilot. This allows you to customize the commit message to better fit your workflow and team’s standards. You can specify the number of lines to generate, the length of the lines, and even provide a sample commit style. Edit the message in the Tools > Options > Copilot > Source Control > Commit message additional instructions: prompt field.\n\nGit multi-repo support\nYou can now create pull requests and link work items in multi-repo scenarios. For both GitHub and Azure DevOps, we support your integrations when you use the repository picker to focus on a particular repository in your multi-repo scenarios.\n\nKeep sharing your feedback!\nWe are continuously striving to improve and adapt to your needs, and your feedback is invaluable in this process. Thank you for your continued feedback and support. Your insights help us shape the tools and features that make your development experience more efficient and enjoyable.\nThe post Git tooling updates in Visual Studio 17.12 appeared first on Visual Studio Blog.",
        "dc:creator": "Jessie Houghton",
        "content": "<p>We are thrilled to announce the latest updates to Git tooling in Visual Studio, designed to enhance your development experience and streamline your workflow. These new features are in direct response to user feedback, ensuring that you have the tools you need to be more productive and efficient. For the full list, check out the [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/git-tooling-updates-in-visual-studio-17-12/\">Git tooling updates in Visual Studio 17.12</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "We are thrilled to announce the latest updates to Git tooling in Visual Studio, designed to enhance your development experience and streamline your workflow. These new features are in direct response to user feedback, ensuring that you have the tools you need to be more productive and efficient. For the full list, check out the […]\nThe post Git tooling updates in Visual Studio 17.12 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251381",
        "categories": [
          "Git",
          "Team and Development",
          "Visual Studio",
          "Git Integration",
          "Multi-repo"
        ],
        "isoDate": "2024-11-18T15:37:56.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": [
      {
        "creator": "sunyzero",
        "title": "AMD 내장 그래픽 튜닝 (7840HS) - 아드레날린 메모리 옵티마이저",
        "link": "http://sunyzero.tistory.com/305",
        "pubDate": "Sat, 23 Nov 2024 10:08:26 +0900",
        "author": "sunyzero",
        "comments": "http://sunyzero.tistory.com/305#entry305comment",
        "content": "<p data-ke-size=\"size16\">AMD CPU중에는 내장 그래픽을 가진 경우가 많은데, 대표적으로 5600G나 7834HS, <a title=\"7840HS mini pic\" href=\"https://sunyzero.tistory.com/298\" target=\"_blank\" rel=\"noopener\">7840HS</a> 같은 CPU가 있다. 이들은 전용 그래픽 메모리가 없기 때문에 메인 메모리인 RAM를 대신 사용한다. 비디오 메모리는 많으면 좋지만 그렇다고 메인 메모리의 대부분을 비디오 메모리로 사용하면 시스템이 굴러가지 못한다. 따라서 AMD 내장 그래픽 시스템은 메인 메모리의 일부를 비디오 전용 메모리로 예약해두고 사용하고, 만일 비디오 메모리가 부족하면 그때그때 메인 메모리를 조금씩 차용해서 쓰도록 되어있다. 하지만 비디오 메모리가 부족할 때 메인 메모리의 파편화나 각종 이유 때문에 즉시 차용되지 못하면 프로그램에서 팅기거나 작동하던 멈출 수 있다. </p>\n<p data-ke-size=\"size16\">이를 해결하기 위해 AMD는 그래픽 드라이버 프로그램 아드레날린(adrenalin)에서 <span style=\"background-color: #9feec3;\">메모리 옵티마이저</span>라는 기능을 제공하는데, 여기서는 \"<span style=\"background-color: #ffc9af;\">생산성</span>\"과 \"<span style=\"background-color: #f6e199;\">게임</span>\"의 2가지 옵션을 제공한다.</p>\n<p data-ke-size=\"size16\">메모리 옵티마이저의 \"<span style=\"background-color: #ffc9af;\">생산성</span>\" 옵션은 일반적인 사무 프로그램을 사용하는 사용자를 대상으로 해서 비디오 메모리를 작은 사이즈로 예약한다. 따라서 메인 메모리를 덜 사용한다. 그 대신 비디오 메모리를 많이 사용하는 게임이라든지 영상 관련 프로그램은 제대로 작동하지 않는다. 심지어 작동하다가 멈추거나 죽을 수도 있다.</p>\n<p data-ke-size=\"size16\">메모리 옵티마이저의 \"<span style=\"background-color: #f6e199;\">게임</span>\" 옵션은 반대로 게임이나 영상 프로그램을 사용하는 경우에 대비해서 비디오 메모리를 좀 더 큰 사이즈로 예약한다. 따라서 메인 메모리를 더 많이 사용하므로, 사용가능한 메인 메모리가 줄어든다.(보통 1~2GiB 정도 줄어든다.) 그 대신에 비디오 메모리를 많이 사용하는 게임에서도 끊김이 덜하고 팅기지도 않는다. <span style=\"background-color: #9feec3;\">그런데 일반 사용자라고 하더라도 메모리가 최소 16~32GB를 많이 사용할텐데, 이런 경우에는 게임 옵션으로 두는게 그래픽이 부드러워지고 더 좋았다. 굳이 게임을 하는 경우가 아니라고 해도 \"게임\" 옵션으로 맞춰두고 사용하는 것이 좋다고 생각된다</span>.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">1. 메모리 옵티마이저</h2>\n<p data-ke-size=\"size16\">먼저 아드레날린이 설치되어있어야 한다. AMD 사이트에서 프로세서와 그래픽 드라이버를 받아서 설치하면 된다. 설치 후 아드레날린을 찾아서 실행한다. 그리고 실행 후 \"성능\"을 선택하고 튜닝쪽으로 가면 다음 그림처럼 메모리 옵티마이저를 볼 수 있다. 아래는 기본값인 \"<span style=\"background-color: #ffc9af;\">생산성</span>\"으로 선택된 것을 보여주고 있다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"7840hs 780M memory optimizer productive - amd adrenalin.png\" data-origin-width=\"1297\" data-origin-height=\"635\"><span data-url=\"https://blog.kakaocdn.net/dn/FaTzL/btsKS9SIaAy/h5noyeUf9M7gjGom2Vj6x0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/FaTzL/btsKS9SIaAy/h5noyeUf9M7gjGom2Vj6x0/img.png\" data-alt=\"아드레날린(adrenalin) - 메모리 옵티마이저(Memory optimizer) - 생산성(Productive)\"><img src=\"https://blog.kakaocdn.net/dn/FaTzL/btsKS9SIaAy/h5noyeUf9M7gjGom2Vj6x0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FFaTzL%2FbtsKS9SIaAy%2Fh5noyeUf9M7gjGom2Vj6x0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"7840hs 780M memory optimizer productive - amd adrenalin.png\" data-origin-width=\"1297\" data-origin-height=\"635\"/></span><figcaption>아드레날린(adrenalin) - 메모리 옵티마이저(Memory optimizer) - 생산성(Productive)</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">메모리 옵티마이저가 생산성으로 선택되어있는 경우에 제어판의 디스플레이 상태를 보면 아래 그림과 같다. (참고로 해당 시스템은 총 메모리가 32GB이다) 그림에 보면 전용 비디오 메모리는 <span style=\"background-color: #ffc9af;\">448MB</span>임을 볼 수 있다. 즉 미리 잡혀있는 전용 비디오 메모리가 겨우 0.5기가 바이트도 안되는 것이다. 공유 메모리가 16GB지만 이 부분을 다 쓸 수 있다는 것은 아니고, 쓸 가능성이 있다고 봐야한다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"7840hs 780M memory optimizer productive - vram 448MB.png\" data-origin-width=\"796\" data-origin-height=\"1007\"><span data-url=\"https://blog.kakaocdn.net/dn/ZEKQQ/btsKUHm6NTq/GCilcVbMYXfJzxsf6XVmN1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ZEKQQ/btsKUHm6NTq/GCilcVbMYXfJzxsf6XVmN1/img.png\" data-alt=\"제어판 - 그래픽스 속성 - 메모리 옵티마이저 - 생산성 옵션 선택\"><img src=\"https://blog.kakaocdn.net/dn/ZEKQQ/btsKUHm6NTq/GCilcVbMYXfJzxsf6XVmN1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FZEKQQ%2FbtsKUHm6NTq%2FGCilcVbMYXfJzxsf6XVmN1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"7840hs 780M memory optimizer productive - vram 448MB.png\" data-origin-width=\"796\" data-origin-height=\"1007\"/></span><figcaption>제어판 - 그래픽스 속성 - 메모리 옵티마이저 - 생산성 옵션 선택</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">비디오 메모리는 Ctrl + Shift + ESC를 눌러 작업 관리자에서 살펴봐도 메모리 상태를 볼 수 있다. 아래를 보면 전용 메모리 448메가중에 아무것도 안해도 273메가를 사용하고 있음을 볼 수 있다. 벌써 절반 이상이 소진된 것이다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"7840hs 780M memory optimizer productive - 작업관리자 GPU.png\" data-origin-width=\"1212\" data-origin-height=\"1105\"><span data-url=\"https://blog.kakaocdn.net/dn/9O5x3/btsKS3L1fsf/k18geptJfkVAveqE221jF0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/9O5x3/btsKS3L1fsf/k18geptJfkVAveqE221jF0/img.png\" data-alt=\"작업관리자 - GPU - 메모리 옵티마이저 생산성 옵션 선택\"><img src=\"https://blog.kakaocdn.net/dn/9O5x3/btsKS3L1fsf/k18geptJfkVAveqE221jF0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F9O5x3%2FbtsKS3L1fsf%2Fk18geptJfkVAveqE221jF0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"7840hs 780M memory optimizer productive - 작업관리자 GPU.png\" data-origin-width=\"1212\" data-origin-height=\"1105\"/></span><figcaption>작업관리자 - GPU - 메모리 옵티마이저 생산성 옵션 선택</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000; text-align: start;\" data-ke-size=\"size26\">2. 메모리 옵티마이저 : \"게임\" 변경</h2>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\">메모리 옵티마이저를 \"게임\"으로 변경해보자. 변경하면 꼭&nbsp;<span style=\"background-color: #ffc9af;\">재부팅을 해야 적용된다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"7840hs 780M memory optimizer game - amd adrenalin.jpg\" data-origin-width=\"1296\" data-origin-height=\"505\"><span data-url=\"https://blog.kakaocdn.net/dn/8CUD9/btsKVs34uFf/vDB0kQG8Pi6O9j9MwzPWjk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/8CUD9/btsKVs34uFf/vDB0kQG8Pi6O9j9MwzPWjk/img.jpg\" data-alt=\"아드레날린(adrenalin) - 메모리 옵티마이저(Memory optimizer) - 게임(Game)\"><img src=\"https://blog.kakaocdn.net/dn/8CUD9/btsKVs34uFf/vDB0kQG8Pi6O9j9MwzPWjk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F8CUD9%2FbtsKVs34uFf%2FvDB0kQG8Pi6O9j9MwzPWjk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"7840hs 780M memory optimizer game - amd adrenalin.jpg\" data-origin-width=\"1296\" data-origin-height=\"505\"/></span><figcaption>아드레날린(adrenalin) - 메모리 옵티마이저(Memory optimizer) - 게임(Game)</figcaption>\n</figure>\n</p>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\">메모리 옵티마이저를 게임으로 변경하고 제어판 디스플레이 상태를 보면 아래 그림과 같다. (참고로 해당 시스템은 총 메모리가 32기가이다) 그림에 보면 이제 전용 비디오 메모리는 4096MB, 즉 4GB 임을 볼 수 있다. 이렇게 해두면 대부분의 게임이나 영상 프로그램도 잘 돌아가고, 팅김이 없어진다. (16GB메모리인 경우에는 아마도 더 적게 잡힐 가능성이 있다)</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"7840hs 780M memory optimizer game - vram 4096MB.jpg\" data-origin-width=\"1207\" data-origin-height=\"792\"><span data-url=\"https://blog.kakaocdn.net/dn/b6KTJr/btsKUlYSAGp/Husihae9nCgggj9vERL0fK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/b6KTJr/btsKUlYSAGp/Husihae9nCgggj9vERL0fK/img.jpg\" data-alt=\"제어판 - 그래픽스 속성 - 메모리 옵티마이저 - 게임 옵션 선택\"><img src=\"https://blog.kakaocdn.net/dn/b6KTJr/btsKUlYSAGp/Husihae9nCgggj9vERL0fK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb6KTJr%2FbtsKUlYSAGp%2FHusihae9nCgggj9vERL0fK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"7840hs 780M memory optimizer game - vram 4096MB.jpg\" data-origin-width=\"1207\" data-origin-height=\"792\"/></span><figcaption>제어판 - 그래픽스 속성 - 메모리 옵티마이저 - 게임 옵션 선택</figcaption>\n</figure>\n</p>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\">비디오 메모리는 Ctrl + Shift + ESC를 눌러 작업 관리자에서 살펴봐도 메모리 상태를 볼 수 있다. 아래 그림을 보면 전용 메모리 4.0GB중에 아무것도 안해도 0.3GB를 사용하고 있음을 볼 수 있다. 그리고 이제 떳떳하게 말할 수 있어졌다. 아직도 신에게는 3.7GB의 메모리가 남아있습니다라고... </p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"7840hs 780M memory optimizer game - 작업관리자 GPU.png\" data-origin-width=\"1186\" data-origin-height=\"1081\"><span data-url=\"https://blog.kakaocdn.net/dn/bOYxQC/btsKSSDCOfM/YptZ2H3QLX4DL4RaLuyUR1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bOYxQC/btsKSSDCOfM/YptZ2H3QLX4DL4RaLuyUR1/img.png\" data-alt=\"작업관리자 - GPU - 메모리 옵티마이저 게임 옵션 선택\"><img src=\"https://blog.kakaocdn.net/dn/bOYxQC/btsKSSDCOfM/YptZ2H3QLX4DL4RaLuyUR1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbOYxQC%2FbtsKSSDCOfM%2FYptZ2H3QLX4DL4RaLuyUR1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"7840hs 780M memory optimizer game - 작업관리자 GPU.png\" data-origin-width=\"1186\" data-origin-height=\"1081\"/></span><figcaption>작업관리자 - GPU - 메모리 옵티마이저 게임 옵션 선택</figcaption>\n</figure>\n</p>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #333333; text-align: start;\" data-ke-size=\"size26\">3. 결론</h2>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\"><span>AMD 내장 그래픽을 사용한다면 아드레날린의 메모리 옵티마이저를 \"게임\"으로 변경하는 것이 좋다. 끝.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">2024.11.23 초안</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "AMD CPU중에는 내장 그래픽을 가진 경우가 많은데, 대표적으로 5600G나 7834HS, 7840HS 같은 CPU가 있다. 이들은 전용 그래픽 메모리가 없기 때문에 메인 메모리인 RAM를 대신 사용한다. 비디오 메모리는 많으면 좋지만 그렇다고 메인 메모리의 대부분을 비디오 메모리로 사용하면 시스템이 굴러가지 못한다. 따라서 AMD 내장 그래픽 시스템은 메인 메모리의 일부를 비디오 전용 메모리로 예약해두고 사용하고, 만일 비디오 메모리가 부족하면 그때그때 메인 메모리를 조금씩 차용해서 쓰도록 되어있다. 하지만 비디오 메모리가 부족할 때 메인 메모리의 파편화나 각종 이유 때문에 즉시 차용되지 못하면 프로그램에서 팅기거나 작동하던 멈출 수 있다. \n이를 해결하기 위해 AMD는 그래픽 드라이버 프로그램 아드레날린(adrenalin)에서 메모리 옵티마이저라는 기능을 제공하는데, 여기서는 \"생산성\"과 \"게임\"의 2가지 옵션을 제공한다.\n메모리 옵티마이저의 \"생산성\" 옵션은 일반적인 사무 프로그램을 사용하는 사용자를 대상으로 해서 비디오 메모리를 작은 사이즈로 예약한다. 따라서 메인 메모리를 덜 사용한다. 그 대신 비디오 메모리를 많이 사용하는 게임이라든지 영상 관련 프로그램은 제대로 작동하지 않는다. 심지어 작동하다가 멈추거나 죽을 수도 있다.\n메모리 옵티마이저의 \"게임\" 옵션은 반대로 게임이나 영상 프로그램을 사용하는 경우에 대비해서 비디오 메모리를 좀 더 큰 사이즈로 예약한다. 따라서 메인 메모리를 더 많이 사용하므로, 사용가능한 메인 메모리가 줄어든다.(보통 1~2GiB 정도 줄어든다.) 그 대신에 비디오 메모리를 많이 사용하는 게임에서도 끊김이 덜하고 팅기지도 않는다. 그런데 일반 사용자라고 하더라도 메모리가 최소 16~32GB를 많이 사용할텐데, 이런 경우에는 게임 옵션으로 두는게 그래픽이 부드러워지고 더 좋았다. 굳이 게임을 하는 경우가 아니라고 해도 \"게임\" 옵션으로 맞춰두고 사용하는 것이 좋다고 생각된다.\n \n \n1. 메모리 옵티마이저\n먼저 아드레날린이 설치되어있어야 한다. AMD 사이트에서 프로세서와 그래픽 드라이버를 받아서 설치하면 된다. 설치 후 아드레날린을 찾아서 실행한다. 그리고 실행 후 \"성능\"을 선택하고 튜닝쪽으로 가면 다음 그림처럼 메모리 옵티마이저를 볼 수 있다. 아래는 기본값인 \"생산성\"으로 선택된 것을 보여주고 있다.\n아드레날린(adrenalin) - 메모리 옵티마이저(Memory optimizer) - 생산성(Productive)\n\n\n메모리 옵티마이저가 생산성으로 선택되어있는 경우에 제어판의 디스플레이 상태를 보면 아래 그림과 같다. (참고로 해당 시스템은 총 메모리가 32GB이다) 그림에 보면 전용 비디오 메모리는 448MB임을 볼 수 있다. 즉 미리 잡혀있는 전용 비디오 메모리가 겨우 0.5기가 바이트도 안되는 것이다. 공유 메모리가 16GB지만 이 부분을 다 쓸 수 있다는 것은 아니고, 쓸 가능성이 있다고 봐야한다.\n제어판 - 그래픽스 속성 - 메모리 옵티마이저 - 생산성 옵션 선택\n\n\n \n비디오 메모리는 Ctrl + Shift + ESC를 눌러 작업 관리자에서 살펴봐도 메모리 상태를 볼 수 있다. 아래를 보면 전용 메모리 448메가중에 아무것도 안해도 273메가를 사용하고 있음을 볼 수 있다. 벌써 절반 이상이 소진된 것이다.\n작업관리자 - GPU - 메모리 옵티마이저 생산성 옵션 선택\n\n\n \n2. 메모리 옵티마이저 : \"게임\" 변경\n메모리 옵티마이저를 \"게임\"으로 변경해보자. 변경하면 꼭 재부팅을 해야 적용된다.\n아드레날린(adrenalin) - 메모리 옵티마이저(Memory optimizer) - 게임(Game)\n\n\n메모리 옵티마이저를 게임으로 변경하고 제어판 디스플레이 상태를 보면 아래 그림과 같다. (참고로 해당 시스템은 총 메모리가 32기가이다) 그림에 보면 이제 전용 비디오 메모리는 4096MB, 즉 4GB 임을 볼 수 있다. 이렇게 해두면 대부분의 게임이나 영상 프로그램도 잘 돌아가고, 팅김이 없어진다. (16GB메모리인 경우에는 아마도 더 적게 잡힐 가능성이 있다)\n제어판 - 그래픽스 속성 - 메모리 옵티마이저 - 게임 옵션 선택\n\n\n비디오 메모리는 Ctrl + Shift + ESC를 눌러 작업 관리자에서 살펴봐도 메모리 상태를 볼 수 있다. 아래 그림을 보면 전용 메모리 4.0GB중에 아무것도 안해도 0.3GB를 사용하고 있음을 볼 수 있다. 그리고 이제 떳떳하게 말할 수 있어졌다. 아직도 신에게는 3.7GB의 메모리가 남아있습니다라고... \n작업관리자 - GPU - 메모리 옵티마이저 게임 옵션 선택\n\n\n \n3. 결론\nAMD 내장 그래픽을 사용한다면 아드레날린의 메모리 옵티마이저를 \"게임\"으로 변경하는 것이 좋다. 끝.\n \n2024.11.23 초안",
        "guid": "http://sunyzero.tistory.com/305",
        "categories": [
          "컴퓨터 관련/윈도 패밀리",
          "7840hs",
          "amd 그래픽 게임용",
          "amd 내장 그래픽 최적화",
          "firebat mn56",
          "아드레날린 메모리 옵티마이저"
        ],
        "isoDate": "2024-11-23T01:08:26.000Z"
      }
    ]
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": [
      {
        "title": "간단한 LLM 기반 멀티 에이전트 시스템 만들어보기",
        "link": "http://daddynkidsmakers.blogspot.com/2024/11/llm.html",
        "pubDate": "2024-11-23T11:54:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">이 글은&nbsp;간단한 LLM 기반 멀티 에이전트 시스템 만드는 방법을 나눔한다.<br /></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEineMk2AGeAfb1q767pz7fv8W3zgLMz1fe5-cU6d0SivZJzxuVeTBSUXVJ1-psyaKfas-aiNRIWl1CHzHAy875fRqIV0qxzXC1xDXCYvixefxKzDZ4NF_DEGCXAXHcHQ-FSL4M93jKeWKSyaP6XJnQv3kDSB1i_TuM-iY7wC9xEEFuNqijYBVW9FPfC1T63\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"1294\" data-original-width=\"2000\" height=\"378\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEineMk2AGeAfb1q767pz7fv8W3zgLMz1fe5-cU6d0SivZJzxuVeTBSUXVJ1-psyaKfas-aiNRIWl1CHzHAy875fRqIV0qxzXC1xDXCYvixefxKzDZ4NF_DEGCXAXHcHQ-FSL4M93jKeWKSyaP6XJnQv3kDSB1i_TuM-iY7wC9xEEFuNqijYBVW9FPfC1T63=w585-h378\" width=\"585\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEiz54Z6mq5gHaTFFWi0NhLngaK-TUk4-q71elNMv96-JyBifTVo3EeBvNzaNj18O_62O_lKB52ms0Iv00JJbz1O6oNCRzZUFfyUOFYBP2N0iQ0qxEfE-ahXSPbFJpwQ_-IDFcm291naAF_c0dO60qtTmkFpAfCaCud7cZ1mOOVK0_Monmvs1j-VckpCghkS\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"420\" data-original-width=\"1000\" height=\"134\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEiz54Z6mq5gHaTFFWi0NhLngaK-TUk4-q71elNMv96-JyBifTVo3EeBvNzaNj18O_62O_lKB52ms0Iv00JJbz1O6oNCRzZUFfyUOFYBP2N0iQ0qxEfE-ahXSPbFJpwQ_-IDFcm291naAF_c0dO60qtTmkFpAfCaCud7cZ1mOOVK0_Monmvs1j-VckpCghkS\" width=\"320\" /></a></div><br /><br /></div><div style=\"text-align: left;\">레퍼런스</div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><a href=\"https://dev.to/ngonidzashe/chat-with-your-csv-visualize-your-data-with-langchain-and-streamlit-ej7\">Chat with your CSV: Visualize Your Data with Langchain and Streamlit - DEV Community</a></li><li><a href=\"https://www.youtube.com/watch?v=YIiY567oZxg&amp;list=PL6A819C46558586E9&amp;index=5\">Ollama와 Gemini 모델을 활용한 CSV/SQL 데이터 QA RAG 시스템 만들기</a></li><li><a href=\"https://langchain-ai.github.io/langgraph/tutorials/multi_agent/agent_supervisor/\">Multi-agent supervisor</a></li><li><a href=\"https://blog.langchain.dev/agent-protocol-interoperability-for-llm-agents/\">Agent Protocol: Interoperability for LLM agents</a></li><li><a href=\"https://shaikhmubin.medium.com/multi-agent-hedge-fund-simulation-with-langchain-and-langgraph-64060aabe711\">Multi-Agent Hedge Fund Simulation with LangChain and LangGraph | by Mubin Shaikh | Nov, 2024 | Medium</a></li><li><a href=\"https://arxiv.org/html/2411.08899v1\">FinVision: A Multi-Agent Framework for Stock Market Prediction</a></li><li><a href=\"https://blog.streamlit.io/langchain-tutorial-5-build-an-ask-the-data-app/\">LangChain tutorial #5: Build an Ask the Data app</a></li><li><a href=\"https://blog.gopenai.com/building-a-multi-pdf-rag-chatbot-langchain-streamlit-with-code-d21d0a1cf9e5\">Building a Multi PDF RAG Chatbot: Langchain, Streamlit with code | by Paras Madan | GoPenAI</a></li><li><a href=\"https://www.kaggle.com/code/sasakitetsuya/pdf-q-a-app-by-langchain-and-streamlit\">PDF Q&amp;A App by LangChain and Streamlit</a></li></ul></div>",
        "contentSnippet": "이 글은 간단한 LLM 기반 멀티 에이전트 시스템 만드는 방법을 나눔한다.\n\n\n\n\n\n\n\n레퍼런스\n\nChat with your CSV: Visualize Your Data with Langchain and Streamlit - DEV Community\nOllama와 Gemini 모델을 활용한 CSV/SQL 데이터 QA RAG 시스템 만들기\nMulti-agent supervisor\nAgent Protocol: Interoperability for LLM agents\nMulti-Agent Hedge Fund Simulation with LangChain and LangGraph | by Mubin Shaikh | Nov, 2024 | Medium\nFinVision: A Multi-Agent Framework for Stock Market Prediction\nLangChain tutorial #5: Build an Ask the Data app\nBuilding a Multi PDF RAG Chatbot: Langchain, Streamlit with code | by Paras Madan | GoPenAI\nPDF Q&A App by LangChain and Streamlit",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-3273090753094149136",
        "isoDate": "2024-11-23T11:54:00.000Z"
      }
    ]
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권영재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김상훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": [
      {
        "title": "나의 세번쨰 컴퓨터",
        "link": "https://elky84.github.io/2024/11/24/my_third_computer/",
        "pubDate": "Sun, 24 Nov 2024 00:00:00 +0000",
        "content": "<p>MMX166은 금새 느려졌다.</p>\n\n<p>게임은 계속 발전했고, 두루넷 개통으로 드디어 상시 인터넷을 쓸 수 있게 됐지만 내 컴퓨터는 너무 느렸다.</p>\n\n<p>2000년 드디어 세번째 컴퓨터를 맞추게 되었는데 셀러론 III 700MHz 에 <a href=\"https://ko.wikipedia.org/wiki/S3_%EC%84%B8%EB%B9%84%EC%A7%80\">S3 세비지 - 위키백과, 우리 모두의 백과사전</a> 중에서 Savage 4였는데, AMD Radeon의 분전과  사실상 독점인 nVidia이 대표적 그래픽 카드인 지금과 달리 당시만해도 다양한 회사의 그래픽 카드가 존재했는데, 마이너한 그래픽 카드보니 호환성 이슈로 많은 3D 게임에서 깨짐 현상의 슬픔을 함께한 컴퓨터였다. 당시 조립 PC 업체에서 예산에 맞춰 적당한 컴퓨터를 구매했는데, 이 때의 충격으로 하드웨어 공부를 시작한 계기가 되기도 했다.</p>\n\n<p>특히 당시 나는 리니지를 아주 열심히 했었는데, 로딩도 길고 종종 멈추다보니 의문사가 많아졌고 이를 바탕으로 누나들을 설득해 리니지 아이템을 판 돈이 컴퓨터 구입 자금이 되었다.</p>\n\n<blockquote>\n  <p>대학 신입생 때도 방학 때 다른 알바가 아닌 짧은 방학 기간에 짬짬이 리니지 아이템 판 돈으로 용돈과 학비 일부를 충당했었다.\n어지간한 알바보다 수익이 좋아서 알바 대신 하게 된 것인데, 지금의 리니지와 다르게 당시의 리니지는 돈을 벌 수 있는 게임이었다.</p>\n</blockquote>\n\n<p>수익은 좋았지만 리니지를 하면서 오는 현타가 었다보니 이 컴퓨터를 가지고 다른 것들을 많이 했는데, 에뮬레이터 사이트를 만들거나, 개발 관련 홈페이지, 게임 팬 페이지를 만들곤 했다.</p>\n\n<p>완성도가 만족스러운 퀄리티는 아니였지만 프로그래밍을 배운 목적이 그러했듯 여러 공모전 제출 용도로 게임을 만든 시기기도 하다.</p>\n\n<hr />\n\n<p>2000년대 초는 에뮬레이터가 급격히 발전한 시기기도 했다.</p>\n\n<p>물론 90년대 후반부터 에뮬레이터가 대중화 되긴 했지만, 2000년대 초반은 플레이스테이션 에뮬레이터 Bleem 등의 논란, CPS를 지원했던 Callus, CPS2 복호화를 통한 finalburn, MAME의 발전, 닌텐도 64 (UltraHLE부터 시작되어 Project 64 등), 네오지오 등이 그리 오래 되지 않은 현세대기거나 아주 비싼 롬팩을 사야하거나, 기판 세팅을 해야 되는 어려움을 겪던 게임기를 손쉽게 즐길 수 있게 됐던 시기기도 하다.</p>\n\n<p>이를 통해 구경만 했던 닌텐도 64의 슈퍼 마리오 64를 플레이하게 됐는데, 3차원이 제대로 느껴지는 충격을 가져다 준 첫 게임이었다랄까?</p>\n\n<p>또한 2D에서도 엄청난 수준의 레벨 디자인을 보여줬던 마리오가, 제한된 스테이지 구성을 지루하지 않게 만들어주는 별 모으기 기반의 반복 플레이가 지루하지 않게 너무나도 잘 만들어서, 아주 오랜 시간 즐기게 됐다.</p>\n\n<p>그리고 그 이후 패미컴이나 슈퍼 패미컴, MAME 에뮬레이터 게임을 다수 즐겼다.</p>\n\n<p>아이러니 하게도 이 시기에 게임도 많이 했음에도, 프로그래밍 경험도 많이 늘게 됐는데, 주로 재밌게 즐긴 게임의 클론 게임을 만들어 보는 방식으로 실습을 이어나가는 것이 유의미하게 작용했었다.</p>\n\n<p>고전 게임이지만 퀄리티는 상당했던 게임이 많다보니, 클론 게임이라지만 그 게임의 모든 요소를 따라한다기 보다는 몇가지 로직을 구현한다거나, 프로토타이핑 수준에 가까웠고, 어떠한 시스템을 이렇게 구현했을까 하는 자의적 해석이 곁들여진 역설계에 가깝긴 했지만, 이 경험이 이후 게임 개발자로서의 삶에 긍정적인 영향을 주었다.</p>\n\n<hr />\n\n<p>당시 재밌게 즐긴 PC 게임들도 참 많다. 모두 언급하긴 어렵지만</p>\n\n<h2 id=\"문명-3\">문명 3</h2>\n\n<p><a href=\"https://www.youtube.com/watch?v=3KVSCwQASbM\">[옛날PC] 문명3 컴플리트 (Sid Meier’s Civilization 3 Complete)</a></p>\n<ul>\n  <li>당시에 용산을 자주 갔는데, 틴 케이스에 들어있던 버전을 샀었다</li>\n  <li>문명 1, 2를 안해보고 3로 입문했는데….</li>\n</ul>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/3KVSCwQASbM?wmode=opaque\" frameborder=\"0\" allowfullscreen=\"\"></iframe>\n\n<h2 id=\"악튜러스\">악튜러스</h2>\n\n<p><a href=\"https://www.youtube.com/watch?v=ngMxhN6pWfg&amp;list=PLzRx55cOIP4sC8tqMf946_OsloGDo-_WP\">[악튜러스_타임어택] 악튜러스 스피드런 2시간4분 (사용가능한 모든 버그 활용)</a></p>\n<ul>\n  <li>여러 역사에 의해 소프트맥스보다는 손노리파였다보니까 구입하게 됐다</li>\n  <li>초판, 재판 둘다 구매 했었는데 2D 스프라이트 + 3D 배경이라는 조합이 실제 체감으로도 나쁘지 않아서 지금도 종종 고전 게임 플레이 하는 분들이 자주 선택하는 게임</li>\n</ul>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ngMxhN6pWfg?wmode=opaque\" frameborder=\"0\" allowfullscreen=\"\"></iframe>\n\n<h2 id=\"히어로즈-오브-마이트-앤-매직-3\">히어로즈 오브 마이트 앤 매직 3</h2>\n\n<p><a href=\"https://www.youtube.com/watch?v=FW3ULCBOV2w\">우리의 주말을 삭제했던 악마의 게임 - 히어로즈 오브 마이트 앤 매직 3</a></p>\n<ul>\n  <li>1편부터 조금씩 했고, 2편도 친구 집에서 꽤 길게 했으나 3편이야 말로 그 정수 같은 게임이었다.</li>\n  <li>쉐도우 오브 데스는 지금도 팬들 사이에서 화자 될만한 명작인데 나 역시 쉐도우 오브 데스와 같은 재미는 이 시리즈에서 다시 못만날줄은 몰랐다.</li>\n</ul>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/FW3ULCBOV2w?wmode=opaque\" frameborder=\"0\" allowfullscreen=\"\"></iframe>\n\n<h2 id=\"챔피언-쉽-매니저-2002-k리그\">챔피언 쉽 매니저 2002 K리그</h2>\n\n<p><a href=\"https://www.youtube.com/watch?v=R6fnjdEDmXk\">Championship Manager 01/02 - Youth Team Premier League! - 1</a></p>\n<ul>\n  <li>영상은 CM01/02인데, 나는 정발됐던 CM2002 K리그 버전으로 입문했다.</li>\n  <li>월드컵의 영향을 받아 즐기게 됐었는데, 이외에도 피파 03, 피파 월드컵 2002도 즐기면서 축구를 좋아하게 됐기 이후의 CM버전이나 FM도 열심히 즐기게 됐다.</li>\n</ul>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/R6fnjdEDmXk?wmode=opaque\" frameborder=\"0\" allowfullscreen=\"\"></iframe>\n\n<h2 id=\"워크래프트-3\">워크래프트 3</h2>\n\n<p><a href=\"https://www.youtube.com/watch?v=MKgREM7JO8w\">[War3]야인시대특별판 완전공략</a></p>\n<ul>\n  <li>재밌긴했는데 게임 템포가 길고, 운영이 너무 중요한 게임 스타일이 어려움을 느끼게 됐었다.</li>\n  <li>야인시대 드라마가 워낙 인기일 때라 야인시대, DOTA, 타워 디펜스 등의 MOD도 많이 즐겼다</li>\n</ul>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/MKgREM7JO8w?wmode=opaque\" frameborder=\"0\" allowfullscreen=\"\"></iframe>\n\n<h2 id=\"디아블로-2\">디아블로 2</h2>\n\n<p><a href=\"https://www.youtube.com/watch?v=0nCWJW1s5Jw\">디아블로2클래식 궁금하시죠? 이렇습니다 【디아블로2클래식 Diablo2classic】 - YouTube</a></p>\n<ul>\n  <li>디아블로 2의 국템 시절부터 짬짬이 즐겼는데, 하도 서버 이슈도 많고 복사 이슈도 많고 해서 카우방 돌면서 노는 재미로 했었다.</li>\n</ul>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/0nCWJW1s5Jw?wmode=opaque\" frameborder=\"0\" allowfullscreen=\"\"></iframe>\n\n<h2 id=\"퀘이크-3-아레나\">퀘이크 3 아레나</h2>\n\n<p><a href=\"https://www.youtube.com/watch?v=Jse88q0k_28\">퀘이크 3 : 아레나 - 퀘이크 1 리마스터 기념으로 오래간만에 돌려봤습니다.</a></p>\n<ul>\n  <li>사실 98년도부터 PC방에서 많이 즐겼던 게임인데, 당시 컴퓨터로는 잘 안돌아갔다보니 새로 산 컴퓨터에서 종종 즐겼다.</li>\n  <li>퀘이크3는 워낙 넷플 방식도 다양하게 즐길 수 있다보니까, 하이퍼 슈팅 게임 답게 가볍게 즐기기 좋았다.</li>\n</ul>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Jse88q0k_28?wmode=opaque\" frameborder=\"0\" allowfullscreen=\"\"></iframe>\n\n<hr />\n\n<p>에뮬레이터 이야기를 조금 더 하자면, 2001년 즈음 당시의 화두는 CPS2 에뮬레이터였다.</p>\n\n<p>CPS2가 뭐냐면, 캡콤의 아케이드 시스템으로써 오락실용 기판이라고 봐도 무방하겠다.</p>\n\n<p>이름이 2인 만큼 CPS1도 존재했는데, CPS1은 Callus와 같은 에뮬레이터를 통해 이미 널리 퍼진 상태였으나, CPS2의 경우 강력한 암호화/복호화 체계로 에뮬레이션 되지 않고 있었다.</p>\n\n<p>자살 배터리로 유명한 이 방식은, 게임 데이터를 복호화 하기 위한 키를 배터리에 심어두었고, 배터리가 방전되면 게임 실행이 불가능해져 캡콤에 보내 복원 받아야만 하는 구조였다.</p>\n\n<table>\n  <tbody>\n    <tr>\n      <td>[How Capcom’s clever CPS2 Arcade Game Copy Protection stopped bootleg games</td>\n      <td>MVG](https://www.youtube.com/watch?v=vCtXZM8iG-o)</td>\n    </tr>\n  </tbody>\n</table>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/vCtXZM8iG-o?wmode=opaque\" frameborder=\"0\" allowfullscreen=\"\"></iframe>\n\n<p><a href=\"https://arcadehacker.blogspot.com/2017/03/a-journey-into-capcoms-cps2-silicon.html\">Arcade Hacker: A Journey Into Capcom’s CPS2 Silicon - Part 1</a></p>\n\n<p>이로 인해 당시 컴퓨터 사양으로 충분히 에뮬레이션 가능했고, 대중화 되었던 CPS2, 네오지오 등과 달리 복호화가 불가능해 쓸모 없는 롬 파일만 돌아다닐 뿐이었는데, 보안 취약점으로 암호화 되지 않은 롬 덤프에 성공하게 되고, CPS1가 유사한 점이 많은 CPS2 에뮬레이터는 금새 완성도가 높아져, FInalBurn, Kawaks 등의 에뮬레이터를 통해 플레이 가능해지게 됐었다.</p>\n\n<p>당시만 해도 PS1이 현역 기기였는데, 이를 에뮬레이터 관련 소송과 단속이 시작되면서, 자연스레 에뮬레이터 사이트들은 음지로 사라지거나, 고전 게임이라는 카테고리로 묶어서 현세대기가 아닌 게임 위주로 공유되는 분위기로 바뀌기 시작했다.</p>\n\n<hr />\n\n<p>에뮬레이터 이야기를 많이 했는데, 당시 내가 워낙 마이너한 그래픽 카드를 썼다보니, 패키지 게임에 비해서 에뮬레이터에서의 호환성은 극악이었다.</p>\n\n<p>이때를 계기로 그래픽 카드, CPU, 램 등 하드웨어에 익숙해지고 공부하게 되는 계기가 되었는데 이 부분이 추후 개발자로 일하면서도 도움이 되었으니 아이러니 한 일이 아닐 수 없다.</p>\n\n<p>종종 겜덕, 컴덕이 프로그래머로 전직하게 되는데 나도 그런 케이스라고도 볼 수 있을 거 같다.</p>\n",
        "contentSnippet": "MMX166은 금새 느려졌다.\n게임은 계속 발전했고, 두루넷 개통으로 드디어 상시 인터넷을 쓸 수 있게 됐지만 내 컴퓨터는 너무 느렸다.\n2000년 드디어 세번째 컴퓨터를 맞추게 되었는데 셀러론 III 700MHz 에 S3 세비지 - 위키백과, 우리 모두의 백과사전 중에서 Savage 4였는데, AMD Radeon의 분전과  사실상 독점인 nVidia이 대표적 그래픽 카드인 지금과 달리 당시만해도 다양한 회사의 그래픽 카드가 존재했는데, 마이너한 그래픽 카드보니 호환성 이슈로 많은 3D 게임에서 깨짐 현상의 슬픔을 함께한 컴퓨터였다. 당시 조립 PC 업체에서 예산에 맞춰 적당한 컴퓨터를 구매했는데, 이 때의 충격으로 하드웨어 공부를 시작한 계기가 되기도 했다.\n특히 당시 나는 리니지를 아주 열심히 했었는데, 로딩도 길고 종종 멈추다보니 의문사가 많아졌고 이를 바탕으로 누나들을 설득해 리니지 아이템을 판 돈이 컴퓨터 구입 자금이 되었다.\n대학 신입생 때도 방학 때 다른 알바가 아닌 짧은 방학 기간에 짬짬이 리니지 아이템 판 돈으로 용돈과 학비 일부를 충당했었다.\n어지간한 알바보다 수익이 좋아서 알바 대신 하게 된 것인데, 지금의 리니지와 다르게 당시의 리니지는 돈을 벌 수 있는 게임이었다.\n수익은 좋았지만 리니지를 하면서 오는 현타가 었다보니 이 컴퓨터를 가지고 다른 것들을 많이 했는데, 에뮬레이터 사이트를 만들거나, 개발 관련 홈페이지, 게임 팬 페이지를 만들곤 했다.\n완성도가 만족스러운 퀄리티는 아니였지만 프로그래밍을 배운 목적이 그러했듯 여러 공모전 제출 용도로 게임을 만든 시기기도 하다.\n2000년대 초는 에뮬레이터가 급격히 발전한 시기기도 했다.\n물론 90년대 후반부터 에뮬레이터가 대중화 되긴 했지만, 2000년대 초반은 플레이스테이션 에뮬레이터 Bleem 등의 논란, CPS를 지원했던 Callus, CPS2 복호화를 통한 finalburn, MAME의 발전, 닌텐도 64 (UltraHLE부터 시작되어 Project 64 등), 네오지오 등이 그리 오래 되지 않은 현세대기거나 아주 비싼 롬팩을 사야하거나, 기판 세팅을 해야 되는 어려움을 겪던 게임기를 손쉽게 즐길 수 있게 됐던 시기기도 하다.\n이를 통해 구경만 했던 닌텐도 64의 슈퍼 마리오 64를 플레이하게 됐는데, 3차원이 제대로 느껴지는 충격을 가져다 준 첫 게임이었다랄까?\n또한 2D에서도 엄청난 수준의 레벨 디자인을 보여줬던 마리오가, 제한된 스테이지 구성을 지루하지 않게 만들어주는 별 모으기 기반의 반복 플레이가 지루하지 않게 너무나도 잘 만들어서, 아주 오랜 시간 즐기게 됐다.\n그리고 그 이후 패미컴이나 슈퍼 패미컴, MAME 에뮬레이터 게임을 다수 즐겼다.\n아이러니 하게도 이 시기에 게임도 많이 했음에도, 프로그래밍 경험도 많이 늘게 됐는데, 주로 재밌게 즐긴 게임의 클론 게임을 만들어 보는 방식으로 실습을 이어나가는 것이 유의미하게 작용했었다.\n고전 게임이지만 퀄리티는 상당했던 게임이 많다보니, 클론 게임이라지만 그 게임의 모든 요소를 따라한다기 보다는 몇가지 로직을 구현한다거나, 프로토타이핑 수준에 가까웠고, 어떠한 시스템을 이렇게 구현했을까 하는 자의적 해석이 곁들여진 역설계에 가깝긴 했지만, 이 경험이 이후 게임 개발자로서의 삶에 긍정적인 영향을 주었다.\n당시 재밌게 즐긴 PC 게임들도 참 많다. 모두 언급하긴 어렵지만\n문명 3\n[옛날PC] 문명3 컴플리트 (Sid Meier’s Civilization 3 Complete)\n당시에 용산을 자주 갔는데, 틴 케이스에 들어있던 버전을 샀었다\n문명 1, 2를 안해보고 3로 입문했는데….\n\n\n악튜러스\n[악튜러스_타임어택] 악튜러스 스피드런 2시간4분 (사용가능한 모든 버그 활용)\n여러 역사에 의해 소프트맥스보다는 손노리파였다보니까 구입하게 됐다\n초판, 재판 둘다 구매 했었는데 2D 스프라이트 + 3D 배경이라는 조합이 실제 체감으로도 나쁘지 않아서 지금도 종종 고전 게임 플레이 하는 분들이 자주 선택하는 게임\n\n\n히어로즈 오브 마이트 앤 매직 3\n우리의 주말을 삭제했던 악마의 게임 - 히어로즈 오브 마이트 앤 매직 3\n1편부터 조금씩 했고, 2편도 친구 집에서 꽤 길게 했으나 3편이야 말로 그 정수 같은 게임이었다.\n쉐도우 오브 데스는 지금도 팬들 사이에서 화자 될만한 명작인데 나 역시 쉐도우 오브 데스와 같은 재미는 이 시리즈에서 다시 못만날줄은 몰랐다.\n\n\n챔피언 쉽 매니저 2002 K리그\nChampionship Manager 01/02 - Youth Team Premier League! - 1\n영상은 CM01/02인데, 나는 정발됐던 CM2002 K리그 버전으로 입문했다.\n월드컵의 영향을 받아 즐기게 됐었는데, 이외에도 피파 03, 피파 월드컵 2002도 즐기면서 축구를 좋아하게 됐기 이후의 CM버전이나 FM도 열심히 즐기게 됐다.\n\n\n워크래프트 3\n[War3]야인시대특별판 완전공략\n재밌긴했는데 게임 템포가 길고, 운영이 너무 중요한 게임 스타일이 어려움을 느끼게 됐었다.\n야인시대 드라마가 워낙 인기일 때라 야인시대, DOTA, 타워 디펜스 등의 MOD도 많이 즐겼다\n\n\n디아블로 2\n디아블로2클래식 궁금하시죠? 이렇습니다 【디아블로2클래식 Diablo2classic】 - YouTube\n디아블로 2의 국템 시절부터 짬짬이 즐겼는데, 하도 서버 이슈도 많고 복사 이슈도 많고 해서 카우방 돌면서 노는 재미로 했었다.\n\n\n퀘이크 3 아레나\n퀘이크 3 : 아레나 - 퀘이크 1 리마스터 기념으로 오래간만에 돌려봤습니다.\n사실 98년도부터 PC방에서 많이 즐겼던 게임인데, 당시 컴퓨터로는 잘 안돌아갔다보니 새로 산 컴퓨터에서 종종 즐겼다.\n퀘이크3는 워낙 넷플 방식도 다양하게 즐길 수 있다보니까, 하이퍼 슈팅 게임 답게 가볍게 즐기기 좋았다.\n\n\n\n\n에뮬레이터 이야기를 조금 더 하자면, 2001년 즈음 당시의 화두는 CPS2 에뮬레이터였다.\nCPS2가 뭐냐면, 캡콤의 아케이드 시스템으로써 오락실용 기판이라고 봐도 무방하겠다.\n이름이 2인 만큼 CPS1도 존재했는데, CPS1은 Callus와 같은 에뮬레이터를 통해 이미 널리 퍼진 상태였으나, CPS2의 경우 강력한 암호화/복호화 체계로 에뮬레이션 되지 않고 있었다.\n자살 배터리로 유명한 이 방식은, 게임 데이터를 복호화 하기 위한 키를 배터리에 심어두었고, 배터리가 방전되면 게임 실행이 불가능해져 캡콤에 보내 복원 받아야만 하는 구조였다.\n[How Capcom’s clever CPS2 Arcade Game Copy Protection stopped bootleg games\n      MVG](https://www.youtube.com/watch?v=vCtXZM8iG-o)\n    \n\n\nArcade Hacker: A Journey Into Capcom’s CPS2 Silicon - Part 1\n이로 인해 당시 컴퓨터 사양으로 충분히 에뮬레이션 가능했고, 대중화 되었던 CPS2, 네오지오 등과 달리 복호화가 불가능해 쓸모 없는 롬 파일만 돌아다닐 뿐이었는데, 보안 취약점으로 암호화 되지 않은 롬 덤프에 성공하게 되고, CPS1가 유사한 점이 많은 CPS2 에뮬레이터는 금새 완성도가 높아져, FInalBurn, Kawaks 등의 에뮬레이터를 통해 플레이 가능해지게 됐었다.\n당시만 해도 PS1이 현역 기기였는데, 이를 에뮬레이터 관련 소송과 단속이 시작되면서, 자연스레 에뮬레이터 사이트들은 음지로 사라지거나, 고전 게임이라는 카테고리로 묶어서 현세대기가 아닌 게임 위주로 공유되는 분위기로 바뀌기 시작했다.\n에뮬레이터 이야기를 많이 했는데, 당시 내가 워낙 마이너한 그래픽 카드를 썼다보니, 패키지 게임에 비해서 에뮬레이터에서의 호환성은 극악이었다.\n이때를 계기로 그래픽 카드, CPU, 램 등 하드웨어에 익숙해지고 공부하게 되는 계기가 되었는데 이 부분이 추후 개발자로 일하면서도 도움이 되었으니 아이러니 한 일이 아닐 수 없다.\n종종 겜덕, 컴덕이 프로그래머로 전직하게 되는데 나도 그런 케이스라고도 볼 수 있을 거 같다.",
        "guid": "https://elky84.github.io/2024/11/24/my_third_computer/",
        "categories": [
          "1997년",
          "추억"
        ],
        "isoDate": "2024-11-24T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": [
      {
        "title": "Kotlin Coroutines Flow의 Cold/Hot flow(Stream)의 데이터 흐름(Data flow) 이해해 보기",
        "link": "https://thdev.tech/dataflow/2024/11/23/Flow-Data-flow/",
        "pubDate": "Sat, 23 Nov 2024 00:00:00 +0000",
        "content": "<p>이전 글에서 <a href=\"https://thdev.tech/dataflow/2024/11/09/Data-flow/\">데이터 흐름(Data flow)을 이해해 보는 데 있어 필요한 것은? 짝퉁 개발자처럼 논하기</a>란 주제로 글을 작성했다.</p>\n\n<p>이번 글에서는 이 글에 나온 내용 중 Coroutines Flow에 대한 데이터 흐름을 이해하기 위한 글을 작성해 보았다.</p>\n\n<h3>이 글에서는</h3>\n<ul>\n  <li>Coroutines Flow</li>\n  <li>지속적인 흐름</li>\n  <li>Cold/Hot stream</li>\n  <li>ReactiveX에서 제공하는 subject에 대해서 이해하기</li>\n</ul>\n\n<!--more-->\n\n<h2>Coroutines Flow</h2>\n\n<p><a href=\"https://kotlinlang.org/docs/flow.html\">Asynchronous Flow - link</a>는 공식 문서에 나온 설명을 그대로 가져왔다.</p>\n\n<blockquote>\n  <p>A suspending function asynchronously returns a single value, but how can we return multiple asynchronously computed values? This is where Kotlin Flows come in.</p>\n</blockquote>\n\n<p>supend 함수는 비동기적인 값을 불러올 순 있지만 지속적인 값의 흐름을 가지지는 않는다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">suspend</span> <span class=\"k\">fun</span> <span class=\"nf\">featchData</span><span class=\"p\">()</span> <span class=\"p\">=</span> <span class=\"cm\">/* 생략 */</span>\n\n<span class=\"k\">fun</span> <span class=\"nf\">main</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"nf\">featchData</span><span class=\"p\">())</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>이런 흐름은 사실 누구나 이해하기 쉽다. main 함수에서 featchData()를 호출하면 응답이 딱 1번 온다는 것이다.</p>\n\n<p>그럼 이를 2회로 반복하면? main 함수에 한 줄 더 추가하거나, (0..1).forEach {}처럼 자동화할 수 있다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">suspend</span> <span class=\"k\">fun</span> <span class=\"nf\">featchData</span><span class=\"p\">()</span> <span class=\"p\">=</span> <span class=\"cm\">/* 생략 */</span>\n\n<span class=\"k\">fun</span> <span class=\"nf\">main</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"nf\">featchData</span><span class=\"p\">())</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"nf\">featchData</span><span class=\"p\">())</span> <span class=\"c1\">// 1회 더 추가</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p><br /></p>\n\n<h2>지속적인 흐름</h2>\n\n<p>flow를 통한 지속적인 흐름을 만든다는 것은 아래와 같다.</p>\n\n<ul>\n  <li>함수를 호출한다.</li>\n  <li>Flow<T>로 생성한 객체를 리턴 받는다.</T></li>\n  <li>구독(collect) 한다.\n    <ul>\n      <li>collect()을 하기 전에도 새로운 데이터 흐름이 있다.</li>\n      <li>collect()을 해야만 새로운 데이터 흐름이 시작한다.</li>\n    </ul>\n  </li>\n</ul>\n\n<p>flow를 활용하는 방식에서의 지속적인 흐름은 이와 같다.</p>\n\n<p>이를 아무나 이해할 수 있는 내용이 뭐가 있을까?</p>\n\n<ul>\n  <li>collect() 하기 전에도 새로운 데이터 흐름이 있다.\n    <ul>\n      <li>물은 흐른다.</li>\n      <li>스트리밍 서비스를 월 결제한다.</li>\n    </ul>\n  </li>\n  <li>collect() 해야 만 새로운 데이터 흐름이 시작된다.\n    <ul>\n      <li>커피를 주문한다.</li>\n      <li>음식을 주문한다.</li>\n    </ul>\n  </li>\n</ul>\n\n<p>위의 예들이 맞을 수도 있고, 엄밀히 따지면 적합한 예가 아닐 수 있지만 대략 구분해 보면 이와 같을 수 있다.</p>\n\n<p>결국 이미 있는 걸 필요할 때만 받아쓴다로 표현할 수 있는 것을 HotFlow(HotStream)으로 칭하고, 새로운 줌의 발생으로 만들기 시작한다는 ColdFlow(ColdStream)으로 칭한다.</p>\n\n<p><br /></p>\n\n<h2>ColdFlow</h2>\n\n<p>ColdFlow인 flow {}에 대한 코드가 아래와 같다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kd\">val</span> <span class=\"py\">flow</span> <span class=\"p\">=</span> <span class=\"nf\">flow</span> <span class=\"p\">{</span>\n    <span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"o\">..</span><span class=\"mi\">6</span><span class=\"p\">).</span><span class=\"nf\">forEach</span> <span class=\"p\">{</span>\n        <span class=\"nf\">emit</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">)</span>\n        <span class=\"nf\">delay</span><span class=\"p\">(</span><span class=\"mi\">1_000L</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"c1\">// collect 1</span>\n<span class=\"n\">flow</span>\n    <span class=\"p\">.</span><span class=\"nf\">onEach</span> <span class=\"p\">{</span> <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">launchIn</span><span class=\"p\">(</span><span class=\"n\">viewModelScope</span><span class=\"p\">)</span>\n\n<span class=\"nf\">delay</span><span class=\"p\">(</span><span class=\"mi\">2_000L</span><span class=\"p\">)</span> <span class=\"c1\">// 2초 후 구독</span>\n\n<span class=\"c1\">// collect 2</span>\n<span class=\"n\">flow</span>\n    <span class=\"p\">.</span><span class=\"nf\">onEach</span> <span class=\"p\">{</span> <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">launchIn</span><span class=\"p\">(</span><span class=\"n\">viewModelScope</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>이에 대한 출력 결과는 아래와 같다.</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">1(new), 2, 1(new), 3, 2, 4, 3, 5, 4, 6, 5, 6</code></p>\n\n<p>각각을 보면 1-6까지 정상 출력함을 알 수 있다.</p>\n\n<p>이를 그림으로 표현하면 아래와 같다.</p>\n\n<p><img src=\"/images/posts/2024/Flow-Data-flow/sample_01.png\" alt=\"sample_01\" /></p>\n\n<p>flow에서의 데이터 흐름은 결국 collect 전에는 아무런 시작을 하지 않음을 알 수 있다.</p>\n\n<p><br /></p>\n\n<h2>ReactiveX의 HotStream</h2>\n\n<p>HotFlow는 collect 과는 상관없이 물이 흘러가듯 언제나 흘러가고 있다.</p>\n\n<p>구독 시점을 기준으로 이전의 데이터 흐름부터 시작할지 항상 새로운 흐름만 받을지가 다를 뿐이다.</p>\n\n<p>ReactiveX에는 이런 형태의 함수가 총 4가지 있는데 아래와 같다.</p>\n\n<h3>AsyncSubject</h3>\n\n<p>구독한 시점의 마지막 값을 방출하고, 새로운 구독이 발생해도 역시 마지막 값을 방출한다.(항상 최신의 마지막만 제공한다)</p>\n\n<p><img src=\"/images/posts/2024/Flow-Data-flow/sample_02.png\" alt=\"sample_02\" /></p>\n\n<h3>BehaviorSubject</h3>\n\n<p>구독한 시점의 최근 데이터 1개와 이후 데이터 흐름을 받을 수 있다.</p>\n\n<p><img src=\"/images/posts/2024/Flow-Data-flow/sample_03.png\" alt=\"sample_03\" /></p>\n\n<h3>PublishSubject</h3>\n\n<p>구독한 시점 이후의 최신 데이터를 순차 흐름을 받을 수 있다.</p>\n\n<p><img src=\"/images/posts/2024/Flow-Data-flow/sample_04.png\" alt=\"sample_04\" /></p>\n\n<h3>ReplaySubject</h3>\n\n<p>구독 시점 앞서 발생한 모든 값을 다시 받을 수 있다.</p>\n\n<p><img src=\"/images/posts/2024/Flow-Data-flow/sample_05.png\" alt=\"sample_05\" /></p>\n\n<p><a href=\"https://reactivex.io/documentation/subject.html\">ReactiveX - Subject - link</a></p>\n\n<p>ReactiveX에는 4가지의 Subject가 HotStream에 해당하는데 방식도 다양하다. Flow에서는 크게 2가지를 제공한다.</p>\n\n<ul>\n  <li>StateFlow : 구독한 시점의 최근 데이터 1개와 이후 데이터 흐름을 받을 수 있다.</li>\n  <li>SharedFlow : SharedFlow의 옵션을 통해 구독 시점을 다양하게 관리할 수 있으며, 동일한 값 역시 방출이 가능하다.</li>\n</ul>\n\n<p>StateFlow는 상태를 관리하기 위한 최적의 상태를 제공해 주기 위해 추가되었는데 ReactiveX에서 PublishSubject와 동일함을 알 수 있다.</p>\n\n<p>엄밀히 따지면 RectiveX Subject와는 다른 부분이 존재하지만 이해도를 높이기 위해 그림을 포함하였다.</p>\n\n<p><br /></p>\n\n<h2>Flow의 HotFlow(HotStream)</h2>\n\n<p>Flow에는 HotStream으로 2개를 제공 있다.</p>\n\n<h3>StateFlow</h3>\n\n<p>StateFlow는 equals, hashCode가 같은 경우 방출하지 않으며, 구독 시점 최근 마지막 데이터 1개와 이후 흐름을 받을 수 있다.</p>\n\n<p>1개의 StateFlow와 2개의 <code class=\"language-plaintext highlighter-rouge\">collect()</code>하는 코드를 아래와 같이 구현하였다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kd\">val</span> <span class=\"py\">stateFlow</span> <span class=\"p\">=</span> <span class=\"nc\">MutableStateFlow</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n\n<span class=\"c1\">// collect 1</span>\n<span class=\"n\">stateFlow</span>\n    <span class=\"p\">.</span><span class=\"nf\">onEach</span> <span class=\"p\">{</span> <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">launchIn</span><span class=\"p\">(</span><span class=\"n\">viewModelScope</span><span class=\"p\">)</span>\n\n<span class=\"nf\">delay</span><span class=\"p\">(</span><span class=\"mi\">500</span><span class=\"p\">)</span>\n\n<span class=\"n\">stateFlow</span><span class=\"p\">.</span><span class=\"n\">value</span> <span class=\"p\">=</span> <span class=\"mi\">0</span>\n\n<span class=\"nf\">delay</span><span class=\"p\">(</span><span class=\"mi\">1_000L</span><span class=\"p\">)</span>\n\n<span class=\"c1\">// collect 2</span>\n<span class=\"n\">stateFlow</span>\n    <span class=\"p\">.</span><span class=\"nf\">onEach</span> <span class=\"p\">{</span> <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">launchIn</span><span class=\"p\">(</span><span class=\"n\">viewModelScope</span><span class=\"p\">)</span>\n\n<span class=\"nf\">delay</span><span class=\"p\">(</span><span class=\"mi\">500</span><span class=\"p\">)</span>\n<span class=\"n\">stateFlow</span><span class=\"p\">.</span><span class=\"n\">value</span> <span class=\"p\">=</span> <span class=\"mi\">1</span>\n<span class=\"nf\">delay</span><span class=\"p\">(</span><span class=\"mi\">500</span><span class=\"p\">)</span>\n<span class=\"n\">stateFlow</span><span class=\"p\">.</span><span class=\"n\">value</span> <span class=\"p\">=</span> <span class=\"mi\">2</span>\n</code></pre></div></div>\n\n<p>이 코드의 실행 결과는 아래와 같다.</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">0(first) 0(reaply) 1(new) 1(new) 2(new) 2(new)</code></p>\n\n<p>이에 대한 도식화 결과가 다음과 같다.</p>\n\n<p><img src=\"/images/posts/2024/Flow-Data-flow/sample_06.png\" alt=\"sample_06\" /></p>\n\n<p><br /></p>\n\n<h4>StateFlow를 좀 더 알아보면</h4>\n\n<p>StateFlow는 내부에서 <code class=\"language-plaintext highlighter-rouge\">private val _state = atomic(initialState) // T | NULL</code>을 활용하여 처리하고 있다. atomic은 멀티 스레드 환경에서 하나의 변수에 대한 동시 접근 시 데이터의 일관성을 보장하기 위한 메커니즘이 적용되어 있다.</p>\n\n<p>Android 개발에서 가장 많이 활용하고 있는 StateFlow는 atomic 적용되어 있기 때문에 Thread safe를 보장한다.</p>\n\n<blockquote>\n  <p>다른 이야기지만 일부 아키텍처 패턴 글에 해당 패턴을 사용하면 Thread safe라는 표현을 쓰는 경우가 있다. StateFlow를 기본 사용하는 경우는 어떤 아키텍처 패턴을 쓰던 StateFlow가 thread safe를 제공하는 것이지 해당 패턴에서 thread safe를 지켜주었다는 표현은 잘못된 표현이다.</p>\n</blockquote>\n\n<p>그리고 값을 update 하는 경우는 2가지 기법을 활용할 수 있다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kd\">val</span> <span class=\"py\">stateFlow</span> <span class=\"p\">=</span> <span class=\"nc\">MutableStateFlow</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n\n<span class=\"c1\">// update 사용하는 케이스</span>\n<span class=\"n\">stateFlow</span><span class=\"p\">.</span><span class=\"nf\">update</span> <span class=\"p\">{</span> <span class=\"n\">newValue</span> <span class=\"p\">}</span>\n\n<span class=\"c1\">// setValue</span>\n<span class=\"n\">stateFlow</span><span class=\"p\">.</span><span class=\"n\">value</span> <span class=\"p\">=</span> <span class=\"n\">newValue</span>\n</code></pre></div></div>\n\n<p>각각에 대한 내부 코드를 조금 살펴보면</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// update 함수</span>\n<span class=\"k\">public</span> <span class=\"k\">inline</span> <span class=\"k\">fun</span> <span class=\"p\">&lt;</span><span class=\"nc\">T</span><span class=\"p\">&gt;</span> <span class=\"nf\">MutableStateFlow</span><span class=\"p\">&lt;</span><span class=\"nc\">T</span><span class=\"p\">&gt;.</span><span class=\"nf\">update</span><span class=\"p\">(</span><span class=\"n\">function</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"nc\">T</span><span class=\"p\">)</span> <span class=\"p\">-&gt;</span> <span class=\"nc\">T</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">while</span> <span class=\"p\">(</span><span class=\"k\">true</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n        <span class=\"kd\">val</span> <span class=\"py\">prevValue</span> <span class=\"p\">=</span> <span class=\"n\">value</span>\n        <span class=\"kd\">val</span> <span class=\"py\">nextValue</span> <span class=\"p\">=</span> <span class=\"nf\">function</span><span class=\"p\">(</span><span class=\"n\">prevValue</span><span class=\"p\">)</span>\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nf\">compareAndSet</span><span class=\"p\">(</span><span class=\"n\">prevValue</span><span class=\"p\">,</span> <span class=\"n\">nextValue</span><span class=\"p\">))</span> <span class=\"p\">{</span>\n            <span class=\"k\">return</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"c1\">// property setValue</span>\n<span class=\"k\">public</span> <span class=\"k\">override</span> <span class=\"kd\">var</span> <span class=\"py\">value</span><span class=\"p\">:</span> <span class=\"nc\">T</span>\n    <span class=\"k\">get</span><span class=\"p\">()</span> <span class=\"p\">=</span> <span class=\"nc\">NULL</span><span class=\"p\">.</span><span class=\"nf\">unbox</span><span class=\"p\">(</span><span class=\"n\">_state</span><span class=\"p\">.</span><span class=\"n\">value</span><span class=\"p\">)</span>\n    <span class=\"k\">set</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"nf\">updateState</span><span class=\"p\">(</span><span class=\"k\">null</span><span class=\"p\">,</span> <span class=\"n\">value</span> <span class=\"o\">?:</span> <span class=\"nc\">NULL</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p><code class=\"language-plaintext highlighter-rouge\">update</code> 함수는 compareAndSet을 호출하고 있고, setValue는 updateState()를 호출하고 있지만 사실 둘 다 <code class=\"language-plaintext highlighter-rouge\">updateState</code> 함수를 호출하고 있다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">override</span> <span class=\"k\">fun</span> <span class=\"nf\">compareAndSet</span><span class=\"p\">(</span><span class=\"n\">expect</span><span class=\"p\">:</span> <span class=\"nc\">T</span><span class=\"p\">,</span> <span class=\"n\">update</span><span class=\"p\">:</span> <span class=\"nc\">T</span><span class=\"p\">):</span> <span class=\"nc\">Boolean</span> <span class=\"p\">=</span>\n    <span class=\"nf\">updateState</span><span class=\"p\">(</span><span class=\"n\">expect</span> <span class=\"o\">?:</span> <span class=\"nc\">NULL</span><span class=\"p\">,</span> <span class=\"n\">update</span> <span class=\"o\">?:</span> <span class=\"nc\">NULL</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>update를 쓰나 property <code class=\"language-plaintext highlighter-rouge\">.value</code>를 바로 바꾸나 둘 다 thread safe 하게 값을 변경한다는 점이다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nf\">updateState</span><span class=\"p\">(</span><span class=\"n\">expectedState</span><span class=\"p\">:</span> <span class=\"nc\">Any</span><span class=\"p\">?,</span> <span class=\"n\">newState</span><span class=\"p\">:</span> <span class=\"nc\">Any</span><span class=\"p\">):</span> <span class=\"nc\">Boolean</span> <span class=\"p\">{</span>\n    <span class=\"c1\">// 생략</span>\n    <span class=\"nf\">synchronized</span><span class=\"p\">(</span><span class=\"k\">this</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// 생략</span>\n    <span class=\"p\">}</span>\n    \n    <span class=\"k\">while</span> <span class=\"p\">(</span><span class=\"k\">true</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// 생략</span>\n        <span class=\"nf\">synchronized</span><span class=\"p\">(</span><span class=\"k\">this</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n            <span class=\"c1\">// 생략</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p><br /></p>\n\n<h3>SharedFlow</h3>\n\n<p>이번엔 SharedFlow이다. SharedFlow는 특이하게도 3가지 기본 옵션을 제공하고 있어서 다양한 방식의 사용이 가능하다.</p>\n\n<p><a href=\"https://kotlinlang.org/api/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines.flow/-shared-flow/\">kotlin coroutines SharedFlow - link</a></p>\n\n<ul>\n  <li>extraBufferCapacity : 기본 설정은 0, 버퍼는 1개를 기본 제공하는데, 여기에 N 개의 추가 버퍼를 적용할 수 있다.</li>\n  <li>replay : 기본 설정은 0, 새로운 구독 시점에 마지막 N 개의 아이템을 replay 한다.</li>\n  <li>onBufferOverflow : 기본값은 SUSPEND이고, DROP_OLDEST 목록 중 이전 값을 제거하거나, DROP_LATEST 목록 중 어느 값이 버려지는지 중요하지 않은 경우</li>\n</ul>\n\n<p>drop_latest은 해석이 애매해서 원문을 그대로 적어둔다.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>This option can be used in rare advanced scenarios where all elements that are expected to enter the buffer are equal, so it is not important which of them get thrown away.\n</code></pre></div></div>\n\n<p>SharedFlow로는 다음의 시나리오가 모두 가능하다.</p>\n\n<ul>\n  <li>구독 시점 이후 최신 데이터 만 받을 수 있다.(ReactiveX PublishSubject)</li>\n</ul>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// suspend로 활용하고, emit 만 활용하는 경우</span>\n<span class=\"kd\">val</span> <span class=\"py\">mutableSharedFlow</span><span class=\"p\">&lt;</span><span class=\"nc\">Int</span><span class=\"p\">&gt;()</span>\n</code></pre></div></div>\n\n<ul>\n  <li>구독 시점 최근 데이터 1개 또는 N 개를 replay 받고, 이후 흐름을 받을 수 있다.(ReactiveX BehaviorSubject, ReplaySubject)</li>\n</ul>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// suspend로 활용하고, emit 만 활용하는 경우</span>\n<span class=\"kd\">val</span> <span class=\"py\">mutableSharedFlow</span><span class=\"p\">&lt;</span><span class=\"nc\">Int</span><span class=\"p\">&gt;(</span>\n    <span class=\"n\">extraBufferCapacity</span> <span class=\"p\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"n\">replay</span> <span class=\"p\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"c1\">// or N</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\">// DROP_OLDEST tryEmit으로 emit하는 경우</span>\n<span class=\"kd\">val</span> <span class=\"py\">mutableSharedFlow</span><span class=\"p\">&lt;</span><span class=\"nc\">Int</span><span class=\"p\">&gt;(</span>\n    <span class=\"n\">extraBufferCapacity</span> <span class=\"p\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"n\">replay</span> <span class=\"p\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"c1\">// or N</span>\n    <span class=\"n\">onBufferOverflow</span> <span class=\"p\">=</span> <span class=\"nc\">BufferOverflow</span><span class=\"p\">.</span><span class=\"nc\">DROP_OLDEST</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n</code></pre></div></div>\n\n<ul>\n  <li>구독 시점 최근 데이터 중 가장 마지막의 데이터부터 받는다.(ReactiveX AsyncSubject)</li>\n</ul>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// DROP_OLDEST tryEmit으로 emit하는 경우</span>\n<span class=\"kd\">val</span> <span class=\"py\">mutableSharedFlow</span><span class=\"p\">&lt;</span><span class=\"nc\">Int</span><span class=\"p\">&gt;(</span>\n    <span class=\"n\">extraBufferCapacity</span> <span class=\"p\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"n\">onBufferOverflow</span> <span class=\"p\">=</span> <span class=\"nc\">BufferOverflow</span><span class=\"p\">.</span><span class=\"nc\">DROP_OLDEST</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>앞에서 언급한 ReactiveX의 4가지 모두를 자유롭게 사용할 수 있기에 옵션만 잘 활용해도 동일한 결과를 얻을 수 있다.</p>\n\n<h4>샘플 코드라서 비밀은 있다(문제가 있다)</h4>\n\n<p>위 코드에는 하나의 비밀이 숨겨져있는데, emit/tryEmit을 선택하여 사용해야 하며, 이에 따라 결과가 달라진다는 점이다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kd\">val</span> <span class=\"py\">sharedFlow</span> <span class=\"p\">=</span> <span class=\"nc\">MutableSharedFlow</span><span class=\"p\">&lt;</span><span class=\"nc\">Int</span><span class=\"p\">&gt;(</span>\n    <span class=\"n\">extraBufferCapacity</span> <span class=\"p\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"n\">replay</span> <span class=\"p\">=</span> <span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"n\">onBufferOverflow</span> <span class=\"p\">=</span> <span class=\"nc\">BufferOverflow</span><span class=\"p\">.</span><span class=\"nc\">DROP_OLDEST</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">sharedFlow</span><span class=\"p\">.</span><span class=\"nf\">tryEmit</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"n\">sharedFlow</span><span class=\"p\">.</span><span class=\"nf\">tryEmit</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"n\">sharedFlow</span>\n    <span class=\"p\">.</span><span class=\"nf\">onEach</span> <span class=\"p\">{</span> <span class=\"n\">i</span> <span class=\"p\">-&gt;</span>\n        <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"index $i\"</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">launchIn</span><span class=\"p\">(</span><span class=\"k\">this</span><span class=\"p\">)</span>\n\n<span class=\"n\">sharedFlow</span><span class=\"p\">.</span><span class=\"nf\">tryEmit</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"n\">sharedFlow</span><span class=\"p\">.</span><span class=\"nf\">tryEmit</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>이 코드에 대한 기대 결과는 <code class=\"language-plaintext highlighter-rouge\">1(replay), 2(replay), 3(new), 4(new)</code>라고 생각할 수 있지만 실제 결과는 <code class=\"language-plaintext highlighter-rouge\">3(replay), 4(replay)</code>란 결과가 나온다.</p>\n\n<p>이는 laucnIn(collect)으로 stream 구독을 시작하였지만 구독에 대한 시간이 필요하며, emit/tryEmit을 연속으로 처리했기 때문에 마지막 emit 값 3, 4 replay로 값이 전달되어 출력됨을 디버그를 통해 확인할 수 있다.</p>\n\n<p>추가로 emit 함수에는 아래와 같이 tryEmit과 emitSuspend를 사용하고 있지만 디버그 해보면 대부분 tryEmit에서 완료되어 fast-path 처리하고 끝난다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">override</span> <span class=\"k\">suspend</span> <span class=\"k\">fun</span> <span class=\"nf\">emit</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">:</span> <span class=\"nc\">T</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nf\">tryEmit</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">))</span> <span class=\"k\">return</span> <span class=\"c1\">// fast-path</span>\n    <span class=\"nf\">emitSuspend</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>이런 코드를 작성하지는 않겠지만 replay만 동작하고 끝날 수 있기에 샘플 코드에서는 다음과 같이 수정하였다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kd\">val</span> <span class=\"py\">sharedFlow</span> <span class=\"p\">=</span> <span class=\"nc\">MutableSharedFlow</span><span class=\"p\">&lt;</span><span class=\"nc\">Int</span><span class=\"p\">&gt;(</span>\n    <span class=\"n\">extraBufferCapacity</span> <span class=\"p\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"n\">replay</span> <span class=\"p\">=</span> <span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"n\">onBufferOverflow</span> <span class=\"p\">=</span> <span class=\"nc\">BufferOverflow</span><span class=\"p\">.</span><span class=\"nc\">DROP_OLDEST</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">sharedFlow</span><span class=\"p\">.</span><span class=\"nf\">tryEmit</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"n\">sharedFlow</span><span class=\"p\">.</span><span class=\"nf\">tryEmit</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"n\">sharedFlow</span>\n    <span class=\"p\">.</span><span class=\"nf\">onEach</span> <span class=\"p\">{</span> <span class=\"n\">i</span> <span class=\"p\">-&gt;</span>\n        <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"index $i\"</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">launchIn</span><span class=\"p\">(</span><span class=\"k\">this</span><span class=\"p\">)</span>\n\n<span class=\"nf\">delay</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"c1\">// 대기시간을 줘야 한다.</span>\n<span class=\"n\">sharedFlow</span><span class=\"p\">.</span><span class=\"nf\">tryEmit</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"n\">sharedFlow</span><span class=\"p\">.</span><span class=\"nf\">tryEmit</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>이와 같이 대기시간을 1ms 정도 주면 결과가 <code class=\"language-plaintext highlighter-rouge\">3, 4</code>에서 <code class=\"language-plaintext highlighter-rouge\">1(replay), 2(replay), 3(new), 4(new)</code>를 순서대로 동작시켜준다.</p>\n\n<p>emit으로 변경한다 해도 동일한 결과가 나오는데, emit을 연속으로 하였기 때문에 구독 이전의 값들이 사실상 의미가 없다는 점이다.</p>\n\n<p><br /></p>\n\n<h2>시나리오 1</h2>\n\n<p>StateFlow와 SharedFlow에 대해서 설명하였는데 그래서 어떻게 쓰는 것이 좋을까? 이 둘을 같이 사용하는 것이 가능할까?</p>\n\n<p>GitHub 사용자 검색 api를 활용한 예이다.</p>\n\n<p><a href=\"https://github.com/taehwandev/GithubUserSearch\">GitHub GithubUserSearch - link</a></p>\n\n<p>이 코드가 실시간 갱신을 사용하기 위한 시나리오를 가지고 ColdFlow와 HotFlow를 연속적으로 사용하기 위한 코드에 대한 설명이다.</p>\n\n<p>이미 과거에 작성했던 글과 연속적으로 같은 설명이라서 이 글에서는 생략하고 넘어가겠다.</p>\n\n<p><a href=\"https://thdev.tech/android/2023/10/15/Android-GitHubSample-01/\">Android에서 flow를 통한 실시간 데이터 갱신에 대한 정리 - link</a></p>\n\n<p><br /></p>\n\n<h2>시나리오 2</h2>\n\n<p>사용자가 동의하기 버튼과 확인 버튼을 누르기 전에는 데이터를 불러올 수 없으며, check에 대한 상태는 실시간 갱신되어야 하며, 버튼은 사용자가 누르기 전에는 액션 할 수 없다.</p>\n\n<p>suspend로 작성하면 버튼을 누르면 suspend 함수를 호출해 주면 끝이다.</p>\n\n<p>이를 지속적인 흐름으로 가져가고 싶다면 일단 시나리오를 구분해야 한다.</p>\n\n<ul>\n  <li>사용자의 동의 버튼 누르는 행동은 언제나 일어난다.\n    <ul>\n      <li>StateFlow를 활용해 true/false를 관리한다.</li>\n    </ul>\n  </li>\n  <li>사용자가 확인 버튼을 누를 수 있는 경우는 동의한 경우에만 실행하도록 대기한다.\n    <ul>\n      <li>SharedFlow와 앞선 StateFlow를 동시에 true 인지 체크가 필요하다.</li>\n    </ul>\n  </li>\n</ul>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// 동의 버튼에 대한 처리</span>\n<span class=\"kd\">val</span> <span class=\"py\">agree</span> <span class=\"p\">=</span> <span class=\"nc\">MutableStateFlow</span><span class=\"p\">(</span><span class=\"k\">false</span><span class=\"p\">)</span>\n\n<span class=\"c1\">// 사용자 버튼 클릭을 처리하기 위함</span>\n<span class=\"kd\">val</span> <span class=\"py\">ok</span> <span class=\"p\">=</span> <span class=\"nc\">MutableSharedFlow</span><span class=\"p\">&lt;</span><span class=\"nc\">Boolean</span><span class=\"p\">&gt;(</span>\n    <span class=\"n\">extraBufferCapacity</span> <span class=\"p\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"n\">onBufferOverflow</span> <span class=\"p\">=</span> <span class=\"nc\">BufferOverflow</span><span class=\"p\">.</span><span class=\"nc\">DROP_OLDEST</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>코드의 순서가 어디가 먼저일까? agree 되었을 경우 button이 눌러짐을 대기해야 할까? button은 눌러질 수 있지만 agree를 체크하고 나서 실행해야 할까?</p>\n\n<p>이런 시나리오라면 코드는 달라질 수 있지만 전자에 대한 시나리오 코드를 적어보겠다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">agree</span> <span class=\"c1\">// 1</span>\n    <span class=\"p\">.</span><span class=\"nf\">onEach</span> <span class=\"p\">{</span> <span class=\"n\">isAgree</span> <span class=\"p\">-&gt;</span>\n        <span class=\"n\">_uiState</span><span class=\"p\">.</span><span class=\"nf\">update</span> <span class=\"p\">{</span>\n            <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"nf\">copy</span><span class=\"p\">(</span>\n                <span class=\"n\">isAgree</span> <span class=\"p\">=</span> <span class=\"n\">isAgree</span><span class=\"p\">,</span>\n            <span class=\"p\">)</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">filter</span> <span class=\"p\">{</span> <span class=\"n\">it</span> <span class=\"p\">}</span> <span class=\"c1\">// 2</span>\n    <span class=\"p\">.</span><span class=\"nf\">flatMapLatest</span> <span class=\"p\">{</span> <span class=\"n\">agree</span> <span class=\"p\">-&gt;</span> <span class=\"c1\">// 3</span>\n        <span class=\"n\">ok</span> <span class=\"c1\">// ok event는 true 말곤 올게 없어서 필터하지 않음</span>\n            <span class=\"p\">.</span><span class=\"nf\">map</span> <span class=\"p\">{</span> <span class=\"n\">agree</span> <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">map</span> <span class=\"p\">{</span>\n        <span class=\"n\">repository</span><span class=\"p\">.</span><span class=\"nf\">updateAgree</span><span class=\"p\">()</span> <span class=\"c1\">// 4</span>\n    <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">retryWhen</span> <span class=\"p\">{</span> <span class=\"n\">_</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"p\">-&gt;</span> <span class=\"k\">true</span> <span class=\"p\">}</span> <span class=\"c1\">// 5</span>\n    <span class=\"p\">.</span><span class=\"nf\">flowOn</span><span class=\"p\">(</span><span class=\"nc\">Disatpcher</span><span class=\"p\">.</span><span class=\"nc\">IO</span><span class=\"p\">)</span>\n    <span class=\"p\">.</span><span class=\"nf\">launchIn</span><span class=\"p\">(</span><span class=\"n\">viewModelScope</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<ol>\n  <li>사용자 동의는 true/false로 언제나 일어난다.</li>\n  <li>만약 agree true 이면 filter를 통과한다.</li>\n  <li>flatMapLatest는 2번 true 이면 통과되어 ok에 대한 이벤트를 받을 수 있다.</li>\n  <li>3번의 이벤트가 발생하지 않는 이상 이 코드는 동작하지 않는다.</li>\n</ol>\n\n<p>만약 network fail이 발생하고, 재시도 가능한 상태를 둔다고 하더라도 이 코드는 3번에서 사용자의 액션을 받기 전에는 동작하지 않는다. 그렇기에 그만큼 간단한 코드로 예외 처리할 수 있다.</p>\n\n<ol>\n  <li>4번의 네트워크 실패 케이스가 발생하면 5번 <code class=\"language-plaintext highlighter-rouge\">retryWhen</code>으로 이동한다.</li>\n  <li>재시도에 대한 사용자에게 알릴 수 있다. 5번에서 true 값을 사용했기에 1번부터 다시 시작한다.</li>\n  <li>이전의 값이 true이기 때문에 true를 다시 방출한다.</li>\n  <li>true이기에 filter 통과한다.</li>\n  <li>사용자의 새로운 액션을 대기한다.</li>\n</ol>\n\n<p><code class=\"language-plaintext highlighter-rouge\">retryWhen</code>이 동작하더라도 3번의 아무런 액션이 없기 때문이 이 코드는 멈춘다. 예외 처리에 대한 자세한 내용은 이전에 작성한 글을 참고하시길</p>\n\n<p><a href=\"https://thdev.tech/kotlin/2023/04/13/Kotlin-Flow-Retry/\">Kotlin flow의 예외 처리(catch), 재시도(retry, retryWhen) 살펴보기 - link</a></p>\n\n<p><br /></p>\n\n<h2>마무리</h2>\n\n<p>StateFlow와 SharedFlow에 대한 데이터 흐름을 알아보고, 2가지 시나리오를 기반으로 간단한 코드를 적어보았다.</p>\n\n",
        "contentSnippet": "이전 글에서 데이터 흐름(Data flow)을 이해해 보는 데 있어 필요한 것은? 짝퉁 개발자처럼 논하기란 주제로 글을 작성했다.\n이번 글에서는 이 글에 나온 내용 중 Coroutines Flow에 대한 데이터 흐름을 이해하기 위한 글을 작성해 보았다.\n이 글에서는\nCoroutines Flow\n지속적인 흐름\nCold/Hot stream\nReactiveX에서 제공하는 subject에 대해서 이해하기\nCoroutines Flow\nAsynchronous Flow - link는 공식 문서에 나온 설명을 그대로 가져왔다.\nA suspending function asynchronously returns a single value, but how can we return multiple asynchronously computed values? This is where Kotlin Flows come in.\nsupend 함수는 비동기적인 값을 불러올 순 있지만 지속적인 값의 흐름을 가지지는 않는다.\n\nsuspend fun featchData() = /* 생략 */\n\nfun main() {\n    println(featchData())\n}\n\n\n이런 흐름은 사실 누구나 이해하기 쉽다. main 함수에서 featchData()를 호출하면 응답이 딱 1번 온다는 것이다.\n그럼 이를 2회로 반복하면? main 함수에 한 줄 더 추가하거나, (0..1).forEach {}처럼 자동화할 수 있다.\n\nsuspend fun featchData() = /* 생략 */\n\nfun main() {\n    println(featchData())\n    println(featchData()) // 1회 더 추가\n}\n\n\n\n지속적인 흐름\nflow를 통한 지속적인 흐름을 만든다는 것은 아래와 같다.\n함수를 호출한다.\nFlow로 생성한 객체를 리턴 받는다.\n구독(collect) 한다.\n    \ncollect()을 하기 전에도 새로운 데이터 흐름이 있다.\ncollect()을 해야만 새로운 데이터 흐름이 시작한다.\nflow를 활용하는 방식에서의 지속적인 흐름은 이와 같다.\n이를 아무나 이해할 수 있는 내용이 뭐가 있을까?\ncollect() 하기 전에도 새로운 데이터 흐름이 있다.\n    \n물은 흐른다.\n스트리밍 서비스를 월 결제한다.\ncollect() 해야 만 새로운 데이터 흐름이 시작된다.\n    \n커피를 주문한다.\n음식을 주문한다.\n위의 예들이 맞을 수도 있고, 엄밀히 따지면 적합한 예가 아닐 수 있지만 대략 구분해 보면 이와 같을 수 있다.\n결국 이미 있는 걸 필요할 때만 받아쓴다로 표현할 수 있는 것을 HotFlow(HotStream)으로 칭하고, 새로운 줌의 발생으로 만들기 시작한다는 ColdFlow(ColdStream)으로 칭한다.\n\nColdFlow\nColdFlow인 flow {}에 대한 코드가 아래와 같다.\n\nval flow = flow {\n    (1..6).forEach {\n        emit(it)\n        delay(1_000L)\n    }\n}\n\n// collect 1\nflow\n    .onEach { println(it) }\n    .launchIn(viewModelScope)\n\ndelay(2_000L) // 2초 후 구독\n\n// collect 2\nflow\n    .onEach { println(it) }\n    .launchIn(viewModelScope)\n\n\n이에 대한 출력 결과는 아래와 같다.\n1(new), 2, 1(new), 3, 2, 4, 3, 5, 4, 6, 5, 6\n각각을 보면 1-6까지 정상 출력함을 알 수 있다.\n이를 그림으로 표현하면 아래와 같다.\n\nflow에서의 데이터 흐름은 결국 collect 전에는 아무런 시작을 하지 않음을 알 수 있다.\n\nReactiveX의 HotStream\nHotFlow는 collect 과는 상관없이 물이 흘러가듯 언제나 흘러가고 있다.\n구독 시점을 기준으로 이전의 데이터 흐름부터 시작할지 항상 새로운 흐름만 받을지가 다를 뿐이다.\nReactiveX에는 이런 형태의 함수가 총 4가지 있는데 아래와 같다.\nAsyncSubject\n구독한 시점의 마지막 값을 방출하고, 새로운 구독이 발생해도 역시 마지막 값을 방출한다.(항상 최신의 마지막만 제공한다)\n\nBehaviorSubject\n구독한 시점의 최근 데이터 1개와 이후 데이터 흐름을 받을 수 있다.\n\nPublishSubject\n구독한 시점 이후의 최신 데이터를 순차 흐름을 받을 수 있다.\n\nReplaySubject\n구독 시점 앞서 발생한 모든 값을 다시 받을 수 있다.\n\nReactiveX - Subject - link\nReactiveX에는 4가지의 Subject가 HotStream에 해당하는데 방식도 다양하다. Flow에서는 크게 2가지를 제공한다.\nStateFlow : 구독한 시점의 최근 데이터 1개와 이후 데이터 흐름을 받을 수 있다.\nSharedFlow : SharedFlow의 옵션을 통해 구독 시점을 다양하게 관리할 수 있으며, 동일한 값 역시 방출이 가능하다.\nStateFlow는 상태를 관리하기 위한 최적의 상태를 제공해 주기 위해 추가되었는데 ReactiveX에서 PublishSubject와 동일함을 알 수 있다.\n엄밀히 따지면 RectiveX Subject와는 다른 부분이 존재하지만 이해도를 높이기 위해 그림을 포함하였다.\n\nFlow의 HotFlow(HotStream)\nFlow에는 HotStream으로 2개를 제공 있다.\nStateFlow\nStateFlow는 equals, hashCode가 같은 경우 방출하지 않으며, 구독 시점 최근 마지막 데이터 1개와 이후 흐름을 받을 수 있다.\n1개의 StateFlow와 2개의 collect()하는 코드를 아래와 같이 구현하였다.\n\nval stateFlow = MutableStateFlow(0)\n\n// collect 1\nstateFlow\n    .onEach { println(it) }\n    .launchIn(viewModelScope)\n\ndelay(500)\n\nstateFlow.value = 0\n\ndelay(1_000L)\n\n// collect 2\nstateFlow\n    .onEach { println(it) }\n    .launchIn(viewModelScope)\n\ndelay(500)\nstateFlow.value = 1\ndelay(500)\nstateFlow.value = 2\n\n\n이 코드의 실행 결과는 아래와 같다.\n0(first) 0(reaply) 1(new) 1(new) 2(new) 2(new)\n이에 대한 도식화 결과가 다음과 같다.\n\n\nStateFlow를 좀 더 알아보면\nStateFlow는 내부에서 private val _state = atomic(initialState) // T | NULL을 활용하여 처리하고 있다. atomic은 멀티 스레드 환경에서 하나의 변수에 대한 동시 접근 시 데이터의 일관성을 보장하기 위한 메커니즘이 적용되어 있다.\nAndroid 개발에서 가장 많이 활용하고 있는 StateFlow는 atomic 적용되어 있기 때문에 Thread safe를 보장한다.\n다른 이야기지만 일부 아키텍처 패턴 글에 해당 패턴을 사용하면 Thread safe라는 표현을 쓰는 경우가 있다. StateFlow를 기본 사용하는 경우는 어떤 아키텍처 패턴을 쓰던 StateFlow가 thread safe를 제공하는 것이지 해당 패턴에서 thread safe를 지켜주었다는 표현은 잘못된 표현이다.\n그리고 값을 update 하는 경우는 2가지 기법을 활용할 수 있다.\n\nval stateFlow = MutableStateFlow(0)\n\n// update 사용하는 케이스\nstateFlow.update { newValue }\n\n// setValue\nstateFlow.value = newValue\n\n\n각각에 대한 내부 코드를 조금 살펴보면\n\n// update 함수\npublic inline fun <T> MutableStateFlow<T>.update(function: (T) -> T) {\n    while (true) {\n        val prevValue = value\n        val nextValue = function(prevValue)\n        if (compareAndSet(prevValue, nextValue)) {\n            return\n        }\n    }\n}\n\n// property setValue\npublic override var value: T\n    get() = NULL.unbox(_state.value)\n    set(value) { updateState(null, value ?: NULL) }\n\n\nupdate 함수는 compareAndSet을 호출하고 있고, setValue는 updateState()를 호출하고 있지만 사실 둘 다 updateState 함수를 호출하고 있다.\n\noverride fun compareAndSet(expect: T, update: T): Boolean =\n    updateState(expect ?: NULL, update ?: NULL)\n\n\nupdate를 쓰나 property .value를 바로 바꾸나 둘 다 thread safe 하게 값을 변경한다는 점이다.\n\nprivate fun updateState(expectedState: Any?, newState: Any): Boolean {\n    // 생략\n    synchronized(this) {\n        // 생략\n    }\n    \n    while (true) {\n        // 생략\n        synchronized(this) {\n            // 생략\n        }\n    }\n}\n\n\n\nSharedFlow\n이번엔 SharedFlow이다. SharedFlow는 특이하게도 3가지 기본 옵션을 제공하고 있어서 다양한 방식의 사용이 가능하다.\nkotlin coroutines SharedFlow - link\nextraBufferCapacity : 기본 설정은 0, 버퍼는 1개를 기본 제공하는데, 여기에 N 개의 추가 버퍼를 적용할 수 있다.\nreplay : 기본 설정은 0, 새로운 구독 시점에 마지막 N 개의 아이템을 replay 한다.\nonBufferOverflow : 기본값은 SUSPEND이고, DROP_OLDEST 목록 중 이전 값을 제거하거나, DROP_LATEST 목록 중 어느 값이 버려지는지 중요하지 않은 경우\ndrop_latest은 해석이 애매해서 원문을 그대로 적어둔다.\n\nThis option can be used in rare advanced scenarios where all elements that are expected to enter the buffer are equal, so it is not important which of them get thrown away.\n\n\nSharedFlow로는 다음의 시나리오가 모두 가능하다.\n구독 시점 이후 최신 데이터 만 받을 수 있다.(ReactiveX PublishSubject)\n\n// suspend로 활용하고, emit 만 활용하는 경우\nval mutableSharedFlow<Int>()\n\n\n구독 시점 최근 데이터 1개 또는 N 개를 replay 받고, 이후 흐름을 받을 수 있다.(ReactiveX BehaviorSubject, ReplaySubject)\n\n// suspend로 활용하고, emit 만 활용하는 경우\nval mutableSharedFlow<Int>(\n    extraBufferCapacity = 1,\n    replay = 1, // or N\n)\n\n// DROP_OLDEST tryEmit으로 emit하는 경우\nval mutableSharedFlow<Int>(\n    extraBufferCapacity = 1,\n    replay = 1, // or N\n    onBufferOverflow = BufferOverflow.DROP_OLDEST,\n)\n\n\n구독 시점 최근 데이터 중 가장 마지막의 데이터부터 받는다.(ReactiveX AsyncSubject)\n\n// DROP_OLDEST tryEmit으로 emit하는 경우\nval mutableSharedFlow<Int>(\n    extraBufferCapacity = 1,\n    onBufferOverflow = BufferOverflow.DROP_OLDEST,\n)\n\n\n앞에서 언급한 ReactiveX의 4가지 모두를 자유롭게 사용할 수 있기에 옵션만 잘 활용해도 동일한 결과를 얻을 수 있다.\n샘플 코드라서 비밀은 있다(문제가 있다)\n위 코드에는 하나의 비밀이 숨겨져있는데, emit/tryEmit을 선택하여 사용해야 하며, 이에 따라 결과가 달라진다는 점이다.\n\nval sharedFlow = MutableSharedFlow<Int>(\n    extraBufferCapacity = 1,\n    replay = 2,\n    onBufferOverflow = BufferOverflow.DROP_OLDEST,\n)\n\nsharedFlow.tryEmit(0)\nsharedFlow.tryEmit(1)\n\nsharedFlow\n    .onEach { i ->\n        println(\"index $i\")\n    }\n    .launchIn(this)\n\nsharedFlow.tryEmit(3)\nsharedFlow.tryEmit(4)\n\n\n이 코드에 대한 기대 결과는 1(replay), 2(replay), 3(new), 4(new)라고 생각할 수 있지만 실제 결과는 3(replay), 4(replay)란 결과가 나온다.\n이는 laucnIn(collect)으로 stream 구독을 시작하였지만 구독에 대한 시간이 필요하며, emit/tryEmit을 연속으로 처리했기 때문에 마지막 emit 값 3, 4 replay로 값이 전달되어 출력됨을 디버그를 통해 확인할 수 있다.\n추가로 emit 함수에는 아래와 같이 tryEmit과 emitSuspend를 사용하고 있지만 디버그 해보면 대부분 tryEmit에서 완료되어 fast-path 처리하고 끝난다.\n\noverride suspend fun emit(value: T) {\n    if (tryEmit(value)) return // fast-path\n    emitSuspend(value)\n}\n\n\n이런 코드를 작성하지는 않겠지만 replay만 동작하고 끝날 수 있기에 샘플 코드에서는 다음과 같이 수정하였다.\n\nval sharedFlow = MutableSharedFlow<Int>(\n    extraBufferCapacity = 1,\n    replay = 2,\n    onBufferOverflow = BufferOverflow.DROP_OLDEST,\n)\n\nsharedFlow.tryEmit(0)\nsharedFlow.tryEmit(1)\n\nsharedFlow\n    .onEach { i ->\n        println(\"index $i\")\n    }\n    .launchIn(this)\n\ndelay(1) // 대기시간을 줘야 한다.\nsharedFlow.tryEmit(3)\nsharedFlow.tryEmit(4)\n\n\n이와 같이 대기시간을 1ms 정도 주면 결과가 3, 4에서 1(replay), 2(replay), 3(new), 4(new)를 순서대로 동작시켜준다.\nemit으로 변경한다 해도 동일한 결과가 나오는데, emit을 연속으로 하였기 때문에 구독 이전의 값들이 사실상 의미가 없다는 점이다.\n\n시나리오 1\nStateFlow와 SharedFlow에 대해서 설명하였는데 그래서 어떻게 쓰는 것이 좋을까? 이 둘을 같이 사용하는 것이 가능할까?\nGitHub 사용자 검색 api를 활용한 예이다.\nGitHub GithubUserSearch - link\n이 코드가 실시간 갱신을 사용하기 위한 시나리오를 가지고 ColdFlow와 HotFlow를 연속적으로 사용하기 위한 코드에 대한 설명이다.\n이미 과거에 작성했던 글과 연속적으로 같은 설명이라서 이 글에서는 생략하고 넘어가겠다.\nAndroid에서 flow를 통한 실시간 데이터 갱신에 대한 정리 - link\n\n시나리오 2\n사용자가 동의하기 버튼과 확인 버튼을 누르기 전에는 데이터를 불러올 수 없으며, check에 대한 상태는 실시간 갱신되어야 하며, 버튼은 사용자가 누르기 전에는 액션 할 수 없다.\nsuspend로 작성하면 버튼을 누르면 suspend 함수를 호출해 주면 끝이다.\n이를 지속적인 흐름으로 가져가고 싶다면 일단 시나리오를 구분해야 한다.\n사용자의 동의 버튼 누르는 행동은 언제나 일어난다.\n    \nStateFlow를 활용해 true/false를 관리한다.\n사용자가 확인 버튼을 누를 수 있는 경우는 동의한 경우에만 실행하도록 대기한다.\n    \nSharedFlow와 앞선 StateFlow를 동시에 true 인지 체크가 필요하다.\n\n// 동의 버튼에 대한 처리\nval agree = MutableStateFlow(false)\n\n// 사용자 버튼 클릭을 처리하기 위함\nval ok = MutableSharedFlow<Boolean>(\n    extraBufferCapacity = 1,\n    onBufferOverflow = BufferOverflow.DROP_OLDEST,\n)\n\n\n코드의 순서가 어디가 먼저일까? agree 되었을 경우 button이 눌러짐을 대기해야 할까? button은 눌러질 수 있지만 agree를 체크하고 나서 실행해야 할까?\n이런 시나리오라면 코드는 달라질 수 있지만 전자에 대한 시나리오 코드를 적어보겠다.\n\nagree // 1\n    .onEach { isAgree ->\n        _uiState.update {\n            it.copy(\n                isAgree = isAgree,\n            )\n        }\n    }\n    .filter { it } // 2\n    .flatMapLatest { agree -> // 3\n        ok // ok event는 true 말곤 올게 없어서 필터하지 않음\n            .map { agree }\n    }\n    .map {\n        repository.updateAgree() // 4\n    }\n    .retryWhen { _, _ -> true } // 5\n    .flowOn(Disatpcher.IO)\n    .launchIn(viewModelScope)\n\n\n사용자 동의는 true/false로 언제나 일어난다.\n만약 agree true 이면 filter를 통과한다.\nflatMapLatest는 2번 true 이면 통과되어 ok에 대한 이벤트를 받을 수 있다.\n3번의 이벤트가 발생하지 않는 이상 이 코드는 동작하지 않는다.\n만약 network fail이 발생하고, 재시도 가능한 상태를 둔다고 하더라도 이 코드는 3번에서 사용자의 액션을 받기 전에는 동작하지 않는다. 그렇기에 그만큼 간단한 코드로 예외 처리할 수 있다.\n4번의 네트워크 실패 케이스가 발생하면 5번 retryWhen으로 이동한다.\n재시도에 대한 사용자에게 알릴 수 있다. 5번에서 true 값을 사용했기에 1번부터 다시 시작한다.\n이전의 값이 true이기 때문에 true를 다시 방출한다.\ntrue이기에 filter 통과한다.\n사용자의 새로운 액션을 대기한다.\nretryWhen이 동작하더라도 3번의 아무런 액션이 없기 때문이 이 코드는 멈춘다. 예외 처리에 대한 자세한 내용은 이전에 작성한 글을 참고하시길\nKotlin flow의 예외 처리(catch), 재시도(retry, retryWhen) 살펴보기 - link\n\n마무리\nStateFlow와 SharedFlow에 대한 데이터 흐름을 알아보고, 2가지 시나리오를 기반으로 간단한 코드를 적어보았다.",
        "guid": "https://thdev.tech/dataflow/2024/11/23/Flow-Data-flow/",
        "isoDate": "2024-11-23T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕홍",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": [
      {
        "creator": "bahamoth",
        "title": "호랑이는 죽어서 가죽을 남기고, 프로그램은 죽어서 덤프를 남긴다.",
        "link": "https://01010011.blog/2024/11/20/%ed%98%b8%eb%9e%91%ec%9d%b4%eb%8a%94-%ec%a3%bd%ec%96%b4%ec%84%9c-%ea%b0%80%ec%a3%bd%ec%9d%84-%eb%82%a8%ea%b8%b0%ea%b3%a0-%ed%94%84%eb%a1%9c%ea%b7%b8%eb%9e%a8%ec%9d%80-%ec%a3%bd%ec%96%b4%ec%84%9c/",
        "pubDate": "Wed, 20 Nov 2024 12:59:33 +0000",
        "content:encodedSnippet": "서론\n아무리 소프트웨어를 잘 만들었더라도 구동중인 프로그램이 사용자 환경에서 비정상 종료되는 문제는 필연적이다.\n속된 말로 ‘프로그램이 죽는’ 현상이 이러한 비정상 종료에 해당하는데, 개발자 입장에서는 왜 이러한 ‘죽음’이 발생하는지 파악이 어렵다. 왜냐하면 개발자의 PC에서는 프로그램이 죽지 않기 때문이다.(It works on my machine)\n너무도 다양한 사용자 환경은 기상천외한 문제를 일으킨다.(바닐라 아이스크림 알러지가 있는 자동차)\n이러한 안타까운 죽음의 원인을 부검하기 위해, 개발자는 프로그램이 실행되었던 주변환경에 대한 다양한 정보를 수집한다. 허나 아무리 다양한 주변 정보를 수집한다 하더라도 직접적인 사인은 시체를 확인해야만 하듯, 프로그램이 비정상 종료된 원인은 크래시가 발생한 시점에 메모리에 적재된 스냅샷을 확인해야만 한다.\n그렇다. 호랑이는 죽어서 가죽을 남기고 한우는 죽어서 T본 스테이크를 남기듯, 프로그램은 죽어서 메모리 덤프를 남긴다. 이 글에서는 메모리 덤프가 무엇인지 알아보고, 다양한 사용자 환경에서 덤프를 수집하고 처리하기 위해 어떤 과정들이 이뤄지는지를 알아보겠다.\n프로그램의 생애주기(정상종료 vs 비정상종료)​\n프로그램의 비정상 종료가 무엇인지 설명하려면 정상적으로 실행되어 종료되는 상황이 어떤 흐름으로 진행되는지 알아둘 필요가 있다.\n먼저 소스코드가 실행가능한 프로그램으로 변환되는 과정을 개략적으로 살펴보자. 컴파일러는 소스코드를 역할에 따라 다양한 중간형태(=Object File)로 변환한다.\n다음은 Linux의 Object File 형식이다. 다른 플랫폼의 경우 명칭이 좀 다를 수 있으나 개념은 크게 다르지 않다.\n\n\n\n\n출처: https://cs4157.github.io/www/2024-1/lect/15-elf-intro.html\ntext section: 컴파일 타겟 머신에서 실행 가능한 기계어 코드\ndata section: 초기화된 전역변수/static 변수\nbss section: 초기화되지 않은 전역변수의 메타정보\n그밖에: 읽기 전용(rodata)나 심볼테이블(symtab) relocation 정보(rel.text/rel.data) 등등\n이 중간형태의 Object file들이 실행가능한 형태의 Executable file로 결합이 되어야 비로소 최종적인 프로그램의 형태가 된다.\nJava나 Python, Typescript 같은 Managed 환경은 동작방식도 다르고, 이 글의 메인 주제인 Crash Dump를 (웬만하면)남기지 않기 때문에 여기서는 다루지 않는다.\n프로그램이 실행되기 위해서는 Object file들을 결합 후 메모리에 적재하여야 한다. 이 과정에서 링커는 여러 오브젝트 파일을 하나의 실행 파일로 결합하고, 로더는 이 실행 파일을 메모리에 적재한다. 이 실행파일 형식은 플랫폼에 따라 다르다.\nWindows: PE(Portable Executable)\nLinux: ELF(Executable and Linkable Format)\nmacOS: Mach-O(Mach Object)\n프로그램이 메모리에 적재되었을 때 text / data / bss 같은 영역의 크기는 고정적이다. 한편, 프로그램이 동작함에 따라 동적으로 크기가 늘었다 줄었다 하는 영역이 있는데, TLS(Thread Local Storage)에서 자라나는 콜스택이나 힙이 그러한 예이다. 콜스택은 함수 호출 시 스택 프레임을 추가하고, 함수 종료 시 제거하는 구조다. 힙은 프로그램 실행 중 메모리를 할당하고 해제하는 영역이다.\n프로그램의 특정 기능을 사용하기 위해 버튼을 누르거나, 화면을 터치하는 등의 행위를 하면 그 기능을 수행하기 위해 구성된 함수들이 차례대로 호출된다. 때로는 크기가 얼마나 될지 모르는 데이터를 읽고 쓰는 작업이 필요하기도 하다. 이 과정에서 콜스택과 힙이 자라나게 된다.\n정상적인 사용자 시나리오에서는 프로그램이 모든 작업을 마치고 종료될 때, 콜스택과 힙에 할당된 모든 메모리가 정리되고, 모든 리소스는 OS에 반환된다. 이로써 프로그램은 정상 종료 상태에 진입하게 된다.\nAlt + X 나 Ctrl + C 로 프로세스를 중단시키는 것도 정상 종료의 범주에 들어야 할까? 관점에 따라 다르겠지만 일단 필자가 글을 통해 다루려는건 회복 불가능한 상태에 진입한 프로그램이다. Alt + X 나 Ctrl + C로 프로그램을 종료한다는건 사용자의 의도에 의해 프로그램이 종료되는 것이므로 이 글에서는 정상 종료로 간주한다.\n하지만 프로그램이 예기치 못한 상황에 직면하면 비정상 종료가 발생할 수 있다. 이는 마치 사람이 가서는 안 되는 곳 – 군사분계선 바깥 지역이나 은행 금고 등 -에 발을 들이거나, 다른 사람들에게 치명적인 피해를 입히는 행위를 했을 때 정부가 이를 제재하고 감옥으로 보내는 것과 비슷하다. 마찬가지로 OS도 시스템의 안정성을 위해 계약되지 않은 행위를 하는 프로그램을 강제로 종료시킨다. 시스템 메모리의 보호된 영역 또는 잘못된 주소를 참조하거나, 리소스를 과도하게 점유하는 경우 운영체제는 해당 프로그램을 강제로 종료하는데, 이것이 우리가 흔히 말하는 크래시이다.\n예외처리​\n이러한 갑작스러운 비정상 종료를 제어하기 위해 프로그래밍 언어와 운영체제는 예외처리 수단을 제공한다. 이 글에서는 OS 수준의 예외처리에 대해서만 다룬다.\nWindows: SEH(Structured Exception Handling)\nLinux: Signal\nmacOS: Mach Exception & Signal(Mach Exception의 우선순위가 더 높음)\n비교 표: 플랫폼별 관리 예외/신호\n\n문제 유형Windows (SEH)Linux (Signals)macOS (Mach + Signals)\n\n잘못된 메모리 접근STATUS_ACCESS_VIOLATIONSIGSEGV, SIGBUSSIGSEGV, SIGBUS, EXC_BAD_ACCESS\n스택 오버플로우STATUS_STACK_OVERFLOWSIGSEGV (간접적으로 발생)SIGSEGV (간접적으로 발생)\n잘못된 명령어STATUS_ILLEGAL_INSTRUCTIONSIGILLSIGILL, EXC_BAD_INSTRUCTION\n0으로 나누기 등STATUS_FLOAT_DIVIDE_BY_ZEROSIGFPESIGFPE, EXC_ARITHMETIC\n리소스 초과STATUS_INSUFFICIENT_RESOURCESSIGXCPU, SIGXFSZSIGXCPU, SIGXFSZ\n\n\n\n\n\nOS 별로 서로 다른 덤프 포맷​\n크래시가 발생하면 운영체제는 메모리 스냅샷을 기록하여 디버깅과 원인 분석에 활용한다. 그러나 각 운영체제는 크래시 시점의 메모리 상태를 저장하는 방식과 포맷이 서로 다르다. 각 OS는 고유의 덤프 포맷을 사용하여 크래시 상황을 분석하는 데 필요한 정보를 제공한다.\n1. Windows\nMinidump: Windows 운영체제는 Minidump 포맷을 사용하여 크래시 정보를 저장한다. Minidump는 크래시 원인을 분석하는 데 필요한 최소한의 정보를 포함하며, 파일 크기가 작아 전송과 분석이 용이하다. 보통은 힙을 포함하지 않으며, 옵션으로 힙 영역을 포함시키더라도 전체 내용을 포함하지 않기 때문에 파일 크기가 상대적으로 작다.\nFull Dump: 전체 메모리 덤프를 포함하여 크래시 시점의 모든 메모리 상태를 기록한다. 힙, 전역변수, 확장 레지스터, 기타 리소스 등의 모든 내용을 포함하여 파일 크기가 크고 분석이 복잡할 수 있다.\n2. Linux\nCore Dump: Linux 운영체제는 Core Dump 포맷을 사용하여 크래시 정보를 저장한다. Core Dump는 프로세스의 메모리 이미지와 레지스터 상태를 포함하며, 디버깅에 유용한 정보를 제공한다. 그러나 파일 크기가 크고 다루기 어려운 경우가 많다.\n3. macOS\nApple Crash Report: macOS는 Apple Crash Report 포맷을 사용하여 크래시 정보를 저장한다. 이 포맷은 크래시 시점의 스택 트레이스, 메모리 내용, 레지스터 상태 등을 포함하며, 분석을 위해 Xcode와 같은 도구와 함께 사용된다.\n4. Android\nTombstone: Android 운영체제는 Tombstone 포맷을 사용하여 크래시 정보를 저장한다. Tombstone은 크래시 시점의 스택 트레이스, 메모리 내용, 레지스터 상태 등을 포함하며, adb와 같은 도구를 사용하여 분석할 수 있다.\n이렇듯 각 운영체제의 덤프 포맷은 크래시 원인 분석에 필요한 정보를 제공하지만, 그 구조가 다르기 때문에 크로스 플랫폼 환경에서 어플리케이션을 배포하는 개발자는 파편화된 덤프 포맷을 일일이 관리해야 한다. 이는 고통스러운 작업이기에 덤프를 다루는 일관된 방법이 필요해지는 이유가 된다.\nMinidump Format 과 Chromium Breakpad Project​\n지금까지 우리가 알아본 것을 요약하면,\n프로그램은 정상적으로 실행되다가 예기치 못한 상황에 직면하면 비정상 종료한다.\n운영체제는 비정상 종료 시점의 메모리 스냅샷을 저장하여 디버깅과 원인 분석에 활용한다.\n각 운영체제는 프로그램의 메모리 적재 방식이 서로 다르며, 크래시 덤프 포맷도 다르다.\n또한 각 운영체제마다 예외를 처리하는 방식도 다르다.\n브라우저나 JVM, .NET 처럼 크로스 플랫폼 환경에서도 동일한 방식의 동작을 보장하는 레이어를 지닌 어플리케이션은 위와 같은 크래시 덤프의 수집 및 분석 시 파편화 문제가 크게 체감되지 않을 수 있다. 허나 여러 플랫폼 타겟을 지원하는 네이티브 어플리케이션의 경우, 이러한 크래시 파편화는 개발자가 문제를 찾기 어렵게 한다.\n2008년 9월, 구글은 Chromium이라는 오픈소스 웹브라우저 프로젝트를 발표하였는데, 이 프로젝트의 주요 목표 중 하나는 모든 플랫폼에서 일관된 사용자 경험을 제공하는데 있었다. 필연적으로 여러 플랫폼에서 발생하는 크래시 정보를 효과적으로 수집하고 분석하기 위한 수단이 필요했는데, 이를 위한 Chromium의 해결책이 바로 Breakpad Project이다.\nMicrosoft의 Minidump 포맷은 Breakpad에서 크로스플랫폼 환경에서 일관된 크래시 덤프 수집을 위해 채택한 형식이다. Breakpad Processor 디자인 문서에 따르면 왜 Minidump 포맷을 선택하였는지에 대한 이유가 자세히 기술되어 있다.\n경량화된 포맷: Minidump는 크래시 원인을 분석하는 데 필요한 최소한의 정보만을 포함하며, 파일 크기가 작아 전송과 분석이 용이하다.\n확장성: 다양한 CPU 아키텍처 및 운영체제를 지원하도록 설계되었으며, 다른 포맷들과는 다르게 확장이 용이하다.\n검증된 도구: Minidump 포맷은 Windows 운영체제에서 수 년간 검증된 포맷이기 때문에 안정성이 높으며, MS의 디버깅 도구들을 활용할 수 있다.\n눈치빠른 사람들은 여기서 아직 해결되지 못한 파편화 문제를 알아챌 것이다. 바로 Debugging Symbol인데, Minidump를 쓰더라도 플랫폼 별로 서로 다른 Symbol 포맷은 여전히 문제가 된다.\n이에 대한 Breakpad의 해법은 각 플랫폼의 Symbol을 Breakpad 만의 Human-Readable한 고유의 Symbol Format으로 변환하는 것이다.\n아래 그림은 Breakpad 프로젝트가 어떻게 동작하는지에 대한 개략적인 flow를 보여준다.\n\n\n\n\nBreakpad의 한계와 이를 개선하는 프로젝트들(Crashpad, Rust-Minidump)\n\n\n\n\nBreakpad Client를 사용해보면 가끔씩 제대로 된 덤프가 수집되지 않는 경우가 있다. Breakpad Client가 덤프를 생성할 충분한 시간을 확보하지 못하거나, 덤프 생성 중에 프로세스가 비정상 종료되는 경우가 그 예이다. 앞서 그림을 보면 Breakpad Client는 사용자의 어플리케이션 프로세스 내부에서 동작하도록 설계되어 있는데, 어플리케이션이 종료되는 상황에서는 Breakpad Client가 덤프를 생성할 충분한 시간을 확보하지 못할 수도 있다.\nCrashpad는 이러한 한계를 극복하기 위한 개선 프로젝트로, 별도의 Crash 수집 및 전송을 담당하는 Handler Process를 구성하여 이 문제를 해결하였다.\n\n\n\n\n한편, Chromium의 Breakpad가 쌓아놓은 유산을 토대로 RIIR(Re-write It in Rust)한 Rust-Minidump 프로젝트도 주목할 만 하다. 2017년 luser라는 개발자가 Rust User Forum에 처음으로 소개한 이 프로젝트는 Rust 언어로 작성하였다는 것 만으로도 다양한 장점(메모리 안정성, 속도, 사용 편의성)을 갖고 있을 뿐 아니라 Rust Crate의 확장성을 활용하여 사용자가 원하는 기능을 쉽게 추가할 수도 있다. 덤프 분석 결과물을 JSON 형태로 출력해주는 편의 기능이나 cli 도구도 제공하므로 덤프 분석을 원하는 개발자들은 다양한 용도로 활용이 가능할 것이다.\n결론​\n지금까지 크로스플랫폼 환경에서 발생하는 다양한 덤프를 수집하기 위해 알아야 하는 배경지식과, 파편화 문제를 해결해주는 Breakpad 프로젝트를 위시한 Crashpad, Rust-Minidump 등에 대해 알아보았다. 대개는 Sentry나 Google Crashlytics 등의 Managed Service를 사용하느라 직접 어플리케이션 덤프를 수집하고 분석할 일이 많지 않겠지만 어느 정도 규모가 있는 서비스를 운영, 직접 덤프를 수집하여야만 하는 개발자에게 이 글이 도움이 되길 바란다.",
        "dc:creator": "bahamoth",
        "comments": "https://01010011.blog/2024/11/20/%ed%98%b8%eb%9e%91%ec%9d%b4%eb%8a%94-%ec%a3%bd%ec%96%b4%ec%84%9c-%ea%b0%80%ec%a3%bd%ec%9d%84-%eb%82%a8%ea%b8%b0%ea%b3%a0-%ed%94%84%eb%a1%9c%ea%b7%b8%eb%9e%a8%ec%9d%80-%ec%a3%bd%ec%96%b4%ec%84%9c/#respond",
        "content": "서론 아무리 소프트웨어를 잘 만들었더라도 구동중인 프로그램이 사용자 환경에서 비정상 종료되는 문제는 필연적이다. 속된 말로 &#8216;프로그램이 죽는&#8217; 현상이 이러한 비정상 종료에 해당하는데, 개발자 입장에서는 왜 이러한 &#8216;죽음&#8217;이 발생하는지 파악이 어렵다. 왜냐하면 개발자의 PC에서는 프로그램이 죽지 않기 때문이다.(It works on my machine)너무도 다양한 사용자 환경은 기상천외한 문제를 일으킨다.(바닐라 아이스크림 알러지가 있는 자동차) 이러한 안타까운 죽음의 원인을 [&#8230;]",
        "contentSnippet": "서론 아무리 소프트웨어를 잘 만들었더라도 구동중인 프로그램이 사용자 환경에서 비정상 종료되는 문제는 필연적이다. 속된 말로 ‘프로그램이 죽는’ 현상이 이러한 비정상 종료에 해당하는데, 개발자 입장에서는 왜 이러한 ‘죽음’이 발생하는지 파악이 어렵다. 왜냐하면 개발자의 PC에서는 프로그램이 죽지 않기 때문이다.(It works on my machine)너무도 다양한 사용자 환경은 기상천외한 문제를 일으킨다.(바닐라 아이스크림 알러지가 있는 자동차) 이러한 안타까운 죽음의 원인을 […]",
        "guid": "https://01010011.blog/?p=2209",
        "categories": [
          "programming"
        ],
        "isoDate": "2024-11-20T12:59:33.000Z"
      }
    ]
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김놀부",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "안드로이드 추천 앱, 추천 어플 (24.11.25) 일본어공부, 동영상편집, Filmora, 노트, 일기장, 가계부, 신년 운세, 사주",
        "link": "http://muzbox.tistory.com/483502",
        "pubDate": "Mon, 25 Nov 2024 08:47:19 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483502#entry483502comment",
        "content": "<p data-ke-size=\"size16\">구글 플레이 스토어의 수많은 앱 중, 유용하고 안전한 앱을 엄선해 매주 소개합니다. 신뢰할 수 있는 앱 리뷰를 확인하세요.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"추천앱 241125.png\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/bPGHrk/btsKU6tSmYm/z4RZntBCA6gEn1eRYaF4fK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bPGHrk/btsKU6tSmYm/z4RZntBCA6gEn1eRYaF4fK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bPGHrk/btsKU6tSmYm/z4RZntBCA6gEn1eRYaF4fK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbPGHrk%2FbtsKU6tSmYm%2Fz4RZntBCA6gEn1eRYaF4fK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"안드로이드 추천 앱, 추천 어플 (24.11.25)\" data-filename=\"추천앱 241125.png\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;안드로이드 앱스토어인 구글 플레이 스토어에는 하루에도 엄청난 수의 앱과 게임이 신규로 등록됩니다. 이 모든앱들을 사용자가 확인하고 양질의 앱을 선택하는 것이 사실상 불가능 하다는 얘기죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">또한, 최근들어 강화되었다 하지만 여전히 구글 플레이스토어에는 유해한 앱들이 사라지지 않고 이들 앱으로 피해를 보는 사용자도 많습니다.본 블로그에서는 일주일에 한번정도 운영자가 직접 유용하고 편리한 앱을 엄선하여 소개합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: center;\" data-ke-size=\"size16\"><span style=\"color: #ee2323;\"><b>'어떤오후의 프리웨어 이야기'에서 추천하는 2024년 11월 25일자 '안드로이드 추천 앱'입니다.</b></span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000;\" data-ke-size=\"size26\"><b>1. 일본어&nbsp;공부&nbsp;-&nbsp;히라가나/가타가나&nbsp;-&nbsp;HeyJapan<br /></b></h2>\n<p data-ke-size=\"size16\">&nbsp;기초부터 고급까지 일본어를 학습할 수 있도록 돕는 종합 학습 앱입니다. 하루 15분씩 학습하면 3개월 내에 일본어 실력 향상을 기대할 수 있습니다. 히라가나, 가타카나, 한자 등 일본어 알파벳을 효과적으로 배우며, 기본 문자 사용 능력을 익히고 정확한 발음을 연습할 수 있습니다. <br /><br />Shibi&nbsp;채팅&nbsp;기능을&nbsp;통해&nbsp;간단한&nbsp;회화부터&nbsp;복잡한&nbsp;회화까지&nbsp;실생활&nbsp;의사소통&nbsp;능력을&nbsp;키울&nbsp;수&nbsp;있습니다.&nbsp;Shibi가&nbsp;상황을&nbsp;제시하고&nbsp;질문하며&nbsp;자연스럽게&nbsp;어휘와&nbsp;문법을&nbsp;적용하는&nbsp;연습을&nbsp;돕습니다.&nbsp;듣기&nbsp;및&nbsp;반복&nbsp;기능을&nbsp;통해&nbsp;정확한&nbsp;발음을&nbsp;익히는&nbsp;데도&nbsp;효과적입니다. <br /><br />어휘와&nbsp;문법&nbsp;학습은&nbsp;이미지와&nbsp;플래시카드를&nbsp;활용해&nbsp;쉽고&nbsp;빠르게&nbsp;진행됩니다.&nbsp;문법과&nbsp;예문을&nbsp;함께&nbsp;제공하여&nbsp;암기&nbsp;효율을&nbsp;높이며,&nbsp;학습&nbsp;게임으로&nbsp;복습과&nbsp;정리를&nbsp;지원합니다.&nbsp;999개&nbsp;이상의&nbsp;어휘와&nbsp;다양한&nbsp;문법&nbsp;지식을&nbsp;체계적으로&nbsp;배울&nbsp;수&nbsp;있습니다. <br /><br />JLPT&nbsp;시험&nbsp;준비를&nbsp;위한&nbsp;고품질&nbsp;문제와&nbsp;해설도&nbsp;제공됩니다.&nbsp;실제&nbsp;시험과&nbsp;유사한&nbsp;구조의&nbsp;문제와&nbsp;지속적인&nbsp;업데이트를&nbsp;통해&nbsp;각&nbsp;레벨에&nbsp;맞는&nbsp;준비를&nbsp;할&nbsp;수&nbsp;있습니다. <br /><br />HeyJapan은&nbsp;개인&nbsp;맞춤형&nbsp;학습&nbsp;경로를&nbsp;제공하며,&nbsp;임무를&nbsp;완료할&nbsp;때마다&nbsp;배지를&nbsp;통해&nbsp;학습&nbsp;동기를&nbsp;부여합니다.&nbsp;이&nbsp;배지는&nbsp;학습&nbsp;성과를&nbsp;인정하며&nbsp;꾸준한&nbsp;학습을&nbsp;장려합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"HeyJapan.jpg\" data-origin-width=\"1635\" data-origin-height=\"2895\"><span data-url=\"https://blog.kakaocdn.net/dn/44lTC/btsKT6H87Cl/8ZrYG1ZaBgL4NK3hnaCvBk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/44lTC/btsKT6H87Cl/8ZrYG1ZaBgL4NK3hnaCvBk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/44lTC/btsKT6H87Cl/8ZrYG1ZaBgL4NK3hnaCvBk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F44lTC%2FbtsKT6H87Cl%2F8ZrYG1ZaBgL4NK3hnaCvBk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"700\" height=\"1239\" data-filename=\"HeyJapan.jpg\" data-origin-width=\"1635\" data-origin-height=\"2895\"/></span></figure>\n</p>\n<figure id=\"og_1732491882247\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"일본어 공부 - 히라가나/가타가나 - HeyJapan - Google Play 앱\" data-og-description=\"히라가나와 가타카나 알파벳부터 일본어 회화, 문법 및 JLPT N5~N3 시험 준비까지 일본어를 종합적으로 배우십시오.\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.eup.heyjapan\" data-og-url=\"https://play.google.com/store/apps/details?id=com.eup.heyjapan&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/R3LXt/hyXC8ZS9RD/urOdQreY7KXQVmxjvzjZRK/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/bQfFOl/hyXC86DVqv/kJg3lMoCnvKYeVsiRjoAB0/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/Y1DX1/hyXDnW2l3d/xd60ZBpXCa5YFQvbCKo9Q1/img.png?width=240&amp;height=240&amp;face=0_0_240_240\"><a href=\"https://play.google.com/store/apps/details?id=com.eup.heyjapan\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.eup.heyjapan\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/R3LXt/hyXC8ZS9RD/urOdQreY7KXQVmxjvzjZRK/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/bQfFOl/hyXC86DVqv/kJg3lMoCnvKYeVsiRjoAB0/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/Y1DX1/hyXDnW2l3d/xd60ZBpXCa5YFQvbCKo9Q1/img.png?width=240&amp;height=240&amp;face=0_0_240_240');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">일본어 공부 - 히라가나/가타가나 - HeyJapan - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">히라가나와 가타카나 알파벳부터 일본어 회화, 문법 및 JLPT N5~N3 시험 준비까지 일본어를 종합적으로 배우십시오.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000;\" data-ke-size=\"size26\"><b>2. Filmora&nbsp;-&nbsp;간편한&nbsp;동영상&nbsp;편집&nbsp;앱<br /></b></h2>\n<p data-ke-size=\"size16\">&nbsp;직관적인 인터페이스와 강력한 기능을 통해 누구나 손쉽게 고퀄리티 영상을 제작할 수 있는 도구입니다. 1000개 이상의 음악과 5000개 이상의 스티커 및 필터, 다양한 템플릿을 활용해 TikTok, Instagram Reels, YouTube 등 플랫폼에 최적화된 영상을 빠르게 제작할 수 있습니다. 자르기, 병합, 속도 조절, 디스플레이 조정 등 전문가 수준의 편집 기능을 제공하며, AI 자동 편집으로 시간을 절약하면서도 완성도 높은 영상을 만들 수 있습니다. <br /><br />음악과&nbsp;오디오&nbsp;편집&nbsp;기능도&nbsp;뛰어나&nbsp;저작권&nbsp;걱정&nbsp;없이&nbsp;다양한&nbsp;음향&nbsp;효과와&nbsp;음악을&nbsp;사용할&nbsp;수&nbsp;있습니다.&nbsp;보이스&nbsp;오버&nbsp;기능과&nbsp;오디오&nbsp;파일&nbsp;불러오기,&nbsp;오디오&nbsp;추출&nbsp;및&nbsp;편집&nbsp;기능은&nbsp;더욱&nbsp;생생한&nbsp;콘텐츠&nbsp;제작을&nbsp;지원하며,&nbsp;오디오&nbsp;비트&nbsp;자동&nbsp;감지&nbsp;기능으로&nbsp;영상과&nbsp;음향을&nbsp;완벽히&nbsp;조합할&nbsp;수&nbsp;있습니다. <br /><br />다양한&nbsp;스티커,&nbsp;필터,&nbsp;자막&nbsp;기능을&nbsp;활용하면&nbsp;영상에&nbsp;개성과&nbsp;생동감을&nbsp;더할&nbsp;수&nbsp;있습니다.&nbsp;크로마키,&nbsp;마스킹,&nbsp;키프레임&nbsp;같은&nbsp;고급&nbsp;편집&nbsp;도구를&nbsp;통해&nbsp;더욱&nbsp;정교한&nbsp;편집이&nbsp;가능하며,&nbsp;SNS&nbsp;맞춤&nbsp;크기&nbsp;조정&nbsp;기능으로&nbsp;모든&nbsp;플랫폼에서&nbsp;손쉽게&nbsp;공유할&nbsp;수&nbsp;있습니다.&nbsp;Filmora는&nbsp;초보자부터&nbsp;전문가까지&nbsp;모두를&nbsp;만족시키는&nbsp;영상&nbsp;편집&nbsp;도구로,&nbsp;창의적이고&nbsp;편리한&nbsp;작업&nbsp;환경을&nbsp;제공합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Filmora.jpg\" data-origin-width=\"1635\" data-origin-height=\"2895\"><span data-url=\"https://blog.kakaocdn.net/dn/ckDfn8/btsKU4W61ra/nJVue0i6UjuB6x0n3V0BD1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/ckDfn8/btsKU4W61ra/nJVue0i6UjuB6x0n3V0BD1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/ckDfn8/btsKU4W61ra/nJVue0i6UjuB6x0n3V0BD1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FckDfn8%2FbtsKU4W61ra%2FnJVue0i6UjuB6x0n3V0BD1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"700\" height=\"1239\" data-filename=\"Filmora.jpg\" data-origin-width=\"1635\" data-origin-height=\"2895\"/></span></figure>\n</p>\n<figure id=\"og_1732491893854\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Filmora - 간편한 동영상 편집 앱 - Google Play 앱\" data-og-description=\"음악, 스티커, 효과, 잘라 내기, 비디오 병합, 비디오 트림이 포함된 유튜브용 최고의 영상 편집앱\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.wondershare.filmorago\" data-og-url=\"https://play.google.com/store/apps/details?id=com.wondershare.filmorago&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/lphly/hyXDb98oLm/3vzatwOPE4rtjWKEsxKh21/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/bt1nB8/hyXDkstyoy/JydIl8ofKVXsujrrPQMh1k/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/kGuLC/hyXDj1oabw/b5ji7akOUjOJw6JkKKZvd1/img.jpg?width=480&amp;height=360&amp;face=215_88_268_146\"><a href=\"https://play.google.com/store/apps/details?id=com.wondershare.filmorago\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.wondershare.filmorago\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/lphly/hyXDb98oLm/3vzatwOPE4rtjWKEsxKh21/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/bt1nB8/hyXDkstyoy/JydIl8ofKVXsujrrPQMh1k/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/kGuLC/hyXDj1oabw/b5ji7akOUjOJw6JkKKZvd1/img.jpg?width=480&amp;height=360&amp;face=215_88_268_146');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Filmora - 간편한 동영상 편집 앱 - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">음악, 스티커, 효과, 잘라 내기, 비디오 병합, 비디오 트림이 포함된 유튜브용 최고의 영상 편집앱</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000;\" data-ke-size=\"size26\"><b>3. PenCake&nbsp;-&nbsp;심플한&nbsp;글쓰기&nbsp;노트&nbsp;일기장</b></h2>\n<p data-ke-size=\"size16\">&nbsp;일상, 여행, 취미, 소설 등 다양한 형태의 이야기를 기록하고 간직할 수 있는 글쓰기 플랫폼입니다. 심플하고 직관적인 디자인으로 구성되어 사용자가 글쓰기에 온전히 집중할 수 있는 환경을 제공합니다. 최소한의 UI를 통해 깔끔하고 아름다운 방식으로 이야기를 작성할 수 있으며, 주제별로 이야기를 분류할 수 있어 체계적인 기록이 가능합니다. <br /><br />이&nbsp;플랫폼은&nbsp;자동&nbsp;저장,&nbsp;변경&nbsp;이력&nbsp;복원,&nbsp;삭제된&nbsp;글&nbsp;보관&nbsp;등&nbsp;안전한&nbsp;데이터&nbsp;관리&nbsp;기능을&nbsp;제공하며,&nbsp;iCloud와&nbsp;Google&nbsp;Drive를&nbsp;통해&nbsp;기기&nbsp;간&nbsp;동기화도&nbsp;지원합니다.&nbsp;프리미엄&nbsp;사용자에게는&nbsp;자동&nbsp;동기화와&nbsp;다양한&nbsp;고급&nbsp;기능이&nbsp;제공되어&nbsp;더욱&nbsp;편리한&nbsp;글쓰기가&nbsp;가능합니다. <br /><br />Pencake는&nbsp;높은&nbsp;가독성을&nbsp;위해&nbsp;예쁘고&nbsp;읽기&nbsp;편한&nbsp;폰트를&nbsp;제공하며,&nbsp;긴&nbsp;글&nbsp;작성&nbsp;시에도&nbsp;지연&nbsp;없이&nbsp;원활하게&nbsp;작동합니다.&nbsp;마크다운&nbsp;기능으로&nbsp;서식을&nbsp;지정할&nbsp;수&nbsp;있으며,&nbsp;PC&nbsp;버전과&nbsp;모바일&nbsp;버전&nbsp;간의&nbsp;완벽한&nbsp;연동을&nbsp;지원해&nbsp;생산성을&nbsp;높일&nbsp;수&nbsp;있습니다. <br /><br />추가적으로&nbsp;글자수와&nbsp;단어수&nbsp;표시,&nbsp;검색&nbsp;기능,&nbsp;캡션&nbsp;삽입,&nbsp;비밀번호&nbsp;잠금,&nbsp;다크&nbsp;모드&nbsp;등&nbsp;다양한&nbsp;편의&nbsp;기능을&nbsp;제공하여&nbsp;글쓰기를&nbsp;더욱&nbsp;즐겁고&nbsp;편리하게&nbsp;만들어&nbsp;줍니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"PenCake.jpg\" data-origin-width=\"1635\" data-origin-height=\"2895\"><span data-url=\"https://blog.kakaocdn.net/dn/bo00I5/btsKUGoPS4o/qBjxBlpFk0I6nFVIO5E4C0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bo00I5/btsKUGoPS4o/qBjxBlpFk0I6nFVIO5E4C0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bo00I5/btsKUGoPS4o/qBjxBlpFk0I6nFVIO5E4C0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbo00I5%2FbtsKUGoPS4o%2FqBjxBlpFk0I6nFVIO5E4C0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"700\" height=\"1239\" data-filename=\"PenCake.jpg\" data-origin-width=\"1635\" data-origin-height=\"2895\"/></span></figure>\n</p>\n<figure id=\"og_1732491904462\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"PenCake - 심플한 글쓰기 노트 일기장 - Google Play 앱\" data-og-description=\"미니멀하고 깔끔한 글쓰기 노트\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.diffathy.bbapp\" data-og-url=\"https://play.google.com/store/apps/details?id=com.diffathy.bbapp&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/yWHv8/hyXC95w2wM/k6GKcgzYqRefAxJvFgEAx0/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/c8J4Y0/hyXDfLuBiA/KD2RARF7ndMnidCfu4MAWK/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/t52zZ/hyXC86DVrD/8KqNy0OSJC4uWHlEtMLY8k/img.png?width=240&amp;height=240&amp;face=0_0_240_240\"><a href=\"https://play.google.com/store/apps/details?id=com.diffathy.bbapp\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.diffathy.bbapp\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/yWHv8/hyXC95w2wM/k6GKcgzYqRefAxJvFgEAx0/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/c8J4Y0/hyXDfLuBiA/KD2RARF7ndMnidCfu4MAWK/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/t52zZ/hyXC86DVrD/8KqNy0OSJC4uWHlEtMLY8k/img.png?width=240&amp;height=240&amp;face=0_0_240_240');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">PenCake - 심플한 글쓰기 노트 일기장 - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">미니멀하고 깔끔한 글쓰기 노트</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000;\" data-ke-size=\"size26\"><b>4. 비주얼&nbsp;가계부<br /></b></h2>\n<p data-ke-size=\"size16\">&nbsp;은행 및 카드 내역 문자를 자동으로 입력하고, 지출 내용을 스마트하게 분류해 사용자가 별도의 입력 없이 편리하게 가계부를 관리할 수 있도록 도와줍니다. 다양한 차트와 그래프를 통해 지출 내역을 시각적으로 확인할 수 있으며, 일러스트 메시지를 통해 직관적이고 재미있는 사용자 경험을 제공합니다. <br /><br />예산&nbsp;대비&nbsp;실제&nbsp;지출&nbsp;상황을&nbsp;실시간으로&nbsp;알림받을&nbsp;수&nbsp;있으며,&nbsp;남은&nbsp;예산에&nbsp;따라&nbsp;푸시&nbsp;알림을&nbsp;제공해&nbsp;예산&nbsp;초과를&nbsp;방지하고&nbsp;지출을&nbsp;효과적으로&nbsp;통제할&nbsp;수&nbsp;있습니다.&nbsp;또한,&nbsp;외식,&nbsp;음주,&nbsp;문화생활&nbsp;등&nbsp;생활패턴을&nbsp;분석하고,&nbsp;한&nbsp;달&nbsp;평균&nbsp;유가&nbsp;정보&nbsp;등을&nbsp;산출해&nbsp;소비&nbsp;습관을&nbsp;파악할&nbsp;수&nbsp;있는&nbsp;기능도&nbsp;포함되어&nbsp;있습니다. <br /><br />구글&nbsp;캘린더와&nbsp;연동해&nbsp;지출&nbsp;내역이&nbsp;기록된&nbsp;보조&nbsp;캘린더를&nbsp;생성할&nbsp;수&nbsp;있으며,&nbsp;이를&nbsp;통해&nbsp;캘린더에서&nbsp;실시간으로&nbsp;가계부를&nbsp;확인하고&nbsp;체계적인&nbsp;지출&nbsp;관리가&nbsp;가능합니다.&nbsp;이&nbsp;가계부는&nbsp;자동화와&nbsp;시각화를&nbsp;통해&nbsp;사용자가&nbsp;효율적으로&nbsp;재정을&nbsp;관리할&nbsp;수&nbsp;있는&nbsp;최적의&nbsp;도구입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"비주얼 가계부.jpg\" data-origin-width=\"1635\" data-origin-height=\"2895\"><span data-url=\"https://blog.kakaocdn.net/dn/FSnEb/btsKVwToowN/1lOO8ZE5ULALyRdrc0Mpr1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/FSnEb/btsKVwToowN/1lOO8ZE5ULALyRdrc0Mpr1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/FSnEb/btsKVwToowN/1lOO8ZE5ULALyRdrc0Mpr1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FFSnEb%2FbtsKVwToowN%2F1lOO8ZE5ULALyRdrc0Mpr1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"700\" height=\"1239\" data-filename=\"비주얼 가계부.jpg\" data-origin-width=\"1635\" data-origin-height=\"2895\"/></span></figure>\n</p>\n<figure id=\"og_1732491917982\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"비주얼 가계부 - Google Play 앱\" data-og-description=\"스마트폰과 PC에서 완벽한 기기간 동기화 지원 자동으로 기록하고 분류하는 비주얼 가계부!\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.tenqube.qlip\" data-og-url=\"https://play.google.com/store/apps/details?id=com.tenqube.qlip&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/clpgFq/hyXC8S7pcQ/0j2m5PFJrhOUUYmjm6aUP1/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/hYgUl/hyXC9dpVsb/CZHMQKX4U2x7xmUeJzywRk/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/cux3r1/hyXDelupkX/hPuZIUfkXWHxkML0FW4w90/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360\"><a href=\"https://play.google.com/store/apps/details?id=com.tenqube.qlip\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.tenqube.qlip\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/clpgFq/hyXC8S7pcQ/0j2m5PFJrhOUUYmjm6aUP1/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/hYgUl/hyXC9dpVsb/CZHMQKX4U2x7xmUeJzywRk/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/cux3r1/hyXDelupkX/hPuZIUfkXWHxkML0FW4w90/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">비주얼 가계부 - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">스마트폰과 PC에서 완벽한 기기간 동기화 지원 자동으로 기록하고 분류하는 비주얼 가계부!</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000;\" data-ke-size=\"size26\"><b>5. 포스텔러&nbsp;-&nbsp;신년운세,&nbsp;사주,&nbsp;타로,&nbsp;궁합,&nbsp;점성술</b></h2>\n<p data-ke-size=\"size16\">포스텔러는&nbsp;전&nbsp;국민이&nbsp;선택한&nbsp;운세&nbsp;플랫폼으로,&nbsp;개인별&nbsp;맞춤&nbsp;운세를&nbsp;제공하는&nbsp;전문&nbsp;앱입니다.&nbsp;네이버와&nbsp;카카오&nbsp;출신의&nbsp;기획자와&nbsp;개발자들이&nbsp;자체적으로&nbsp;구축한&nbsp;사주&nbsp;및&nbsp;점성술&nbsp;분석&nbsp;시스템을&nbsp;기반으로,&nbsp;860만&nbsp;명의&nbsp;데이터를&nbsp;반영해&nbsp;다양한&nbsp;운세&nbsp;콘텐츠를&nbsp;제공합니다.&nbsp;사용자&nbsp;평점&nbsp;5점&nbsp;만점에&nbsp;4.8점을&nbsp;기록하며,&nbsp;높은&nbsp;신뢰도와&nbsp;품질을&nbsp;자랑합니다. <br /><br />2025년&nbsp;을사년&nbsp;신년운세는&nbsp;체계적인&nbsp;데이터를&nbsp;활용해&nbsp;재물운,&nbsp;연애운&nbsp;등&nbsp;상세한&nbsp;운세&nbsp;풀이와&nbsp;월별&nbsp;운세&nbsp;흐름을&nbsp;제공합니다.&nbsp;이&nbsp;밖에도&nbsp;정통&nbsp;사주,&nbsp;토정비결,&nbsp;타로,&nbsp;점성술,&nbsp;자미두수&nbsp;등&nbsp;다양한&nbsp;운세를&nbsp;100~200쪽&nbsp;분량의&nbsp;풍부한&nbsp;해석으로&nbsp;만나볼&nbsp;수&nbsp;있습니다. <br /><br />포스텔러는&nbsp;매월&nbsp;업데이트되는&nbsp;신규&nbsp;콘텐츠와&nbsp;무료로&nbsp;즐길&nbsp;수&nbsp;있는&nbsp;고퀄리티&nbsp;운세를&nbsp;포함하여&nbsp;누적&nbsp;6,000건&nbsp;이상의&nbsp;콘텐츠를&nbsp;보유하고&nbsp;있습니다.&nbsp;총&nbsp;46개의&nbsp;주제별/장르별&nbsp;운세가&nbsp;제공되며,&nbsp;사용자는&nbsp;개인별&nbsp;맞춤&nbsp;운세를&nbsp;추천받고,&nbsp;마이페이트북을&nbsp;통해&nbsp;본&nbsp;운세를&nbsp;다시&nbsp;확인할&nbsp;수&nbsp;있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"포스텔러.jpg\" data-origin-width=\"1635\" data-origin-height=\"2895\"><span data-url=\"https://blog.kakaocdn.net/dn/bMTSM6/btsKTFcX5Gs/EmgyKVOKGSEiF2ku8AVeM0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bMTSM6/btsKTFcX5Gs/EmgyKVOKGSEiF2ku8AVeM0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bMTSM6/btsKTFcX5Gs/EmgyKVOKGSEiF2ku8AVeM0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbMTSM6%2FbtsKTFcX5Gs%2FEmgyKVOKGSEiF2ku8AVeM0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"700\" height=\"1239\" data-filename=\"포스텔러.jpg\" data-origin-width=\"1635\" data-origin-height=\"2895\"/></span></figure>\n</p>\n<figure id=\"og_1732491932185\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"포스텔러 - 신년운세, 사주, 타로, 궁합, 점성술 - Google Play 앱\" data-og-description=\"860만 유저가 믿고보는 용한점집 포스텔러 2025 을사년 신년운세를 만나보세요\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.un7qi3.forceteller\" data-og-url=\"https://play.google.com/store/apps/details?id=com.un7qi3.forceteller&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/jPTeq/hyXDgcwhEE/cClJK0zgb6JetCzkL7HokK/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/C8Bkw/hyXDf5MvK8/tZKOcJrucrpE09aivKjj2K/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/PuDMY/hyXzJf9J7h/vrbnv5khAVBKbsK5n9op21/img.jpg?width=526&amp;height=257&amp;face=0_0_526_257\"><a href=\"https://play.google.com/store/apps/details?id=com.un7qi3.forceteller\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.un7qi3.forceteller\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/jPTeq/hyXDgcwhEE/cClJK0zgb6JetCzkL7HokK/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/C8Bkw/hyXDf5MvK8/tZKOcJrucrpE09aivKjj2K/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/PuDMY/hyXzJf9J7h/vrbnv5khAVBKbsK5n9op21/img.jpg?width=526&amp;height=257&amp;face=0_0_526_257');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">포스텔러 - 신년운세, 사주, 타로, 궁합, 점성술 - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">860만 유저가 믿고보는 용한점집 포스텔러 2025 을사년 신년운세를 만나보세요</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "구글 플레이 스토어의 수많은 앱 중, 유용하고 안전한 앱을 엄선해 매주 소개합니다. 신뢰할 수 있는 앱 리뷰를 확인하세요.\n\n\n \n 안드로이드 앱스토어인 구글 플레이 스토어에는 하루에도 엄청난 수의 앱과 게임이 신규로 등록됩니다. 이 모든앱들을 사용자가 확인하고 양질의 앱을 선택하는 것이 사실상 불가능 하다는 얘기죠.\n \n또한, 최근들어 강화되었다 하지만 여전히 구글 플레이스토어에는 유해한 앱들이 사라지지 않고 이들 앱으로 피해를 보는 사용자도 많습니다.본 블로그에서는 일주일에 한번정도 운영자가 직접 유용하고 편리한 앱을 엄선하여 소개합니다.\n \n'어떤오후의 프리웨어 이야기'에서 추천하는 2024년 11월 25일자 '안드로이드 추천 앱'입니다.\n \n1. 일본어 공부 - 히라가나/가타가나 - HeyJapan\n\n 기초부터 고급까지 일본어를 학습할 수 있도록 돕는 종합 학습 앱입니다. 하루 15분씩 학습하면 3개월 내에 일본어 실력 향상을 기대할 수 있습니다. 히라가나, 가타카나, 한자 등 일본어 알파벳을 효과적으로 배우며, 기본 문자 사용 능력을 익히고 정확한 발음을 연습할 수 있습니다. \nShibi 채팅 기능을 통해 간단한 회화부터 복잡한 회화까지 실생활 의사소통 능력을 키울 수 있습니다. Shibi가 상황을 제시하고 질문하며 자연스럽게 어휘와 문법을 적용하는 연습을 돕습니다. 듣기 및 반복 기능을 통해 정확한 발음을 익히는 데도 효과적입니다. \n어휘와 문법 학습은 이미지와 플래시카드를 활용해 쉽고 빠르게 진행됩니다. 문법과 예문을 함께 제공하여 암기 효율을 높이며, 학습 게임으로 복습과 정리를 지원합니다. 999개 이상의 어휘와 다양한 문법 지식을 체계적으로 배울 수 있습니다. \nJLPT 시험 준비를 위한 고품질 문제와 해설도 제공됩니다. 실제 시험과 유사한 구조의 문제와 지속적인 업데이트를 통해 각 레벨에 맞는 준비를 할 수 있습니다. \nHeyJapan은 개인 맞춤형 학습 경로를 제공하며, 임무를 완료할 때마다 배지를 통해 학습 동기를 부여합니다. 이 배지는 학습 성과를 인정하며 꾸준한 학습을 장려합니다.\n\n\n\n \n일본어 공부 - 히라가나/가타가나 - HeyJapan - Google Play 앱\n히라가나와 가타카나 알파벳부터 일본어 회화, 문법 및 JLPT N5~N3 시험 준비까지 일본어를 종합적으로 배우십시오.\nplay.google.com\n\n \n \n \n \n2. Filmora - 간편한 동영상 편집 앱\n\n 직관적인 인터페이스와 강력한 기능을 통해 누구나 손쉽게 고퀄리티 영상을 제작할 수 있는 도구입니다. 1000개 이상의 음악과 5000개 이상의 스티커 및 필터, 다양한 템플릿을 활용해 TikTok, Instagram Reels, YouTube 등 플랫폼에 최적화된 영상을 빠르게 제작할 수 있습니다. 자르기, 병합, 속도 조절, 디스플레이 조정 등 전문가 수준의 편집 기능을 제공하며, AI 자동 편집으로 시간을 절약하면서도 완성도 높은 영상을 만들 수 있습니다. \n음악과 오디오 편집 기능도 뛰어나 저작권 걱정 없이 다양한 음향 효과와 음악을 사용할 수 있습니다. 보이스 오버 기능과 오디오 파일 불러오기, 오디오 추출 및 편집 기능은 더욱 생생한 콘텐츠 제작을 지원하며, 오디오 비트 자동 감지 기능으로 영상과 음향을 완벽히 조합할 수 있습니다. \n다양한 스티커, 필터, 자막 기능을 활용하면 영상에 개성과 생동감을 더할 수 있습니다. 크로마키, 마스킹, 키프레임 같은 고급 편집 도구를 통해 더욱 정교한 편집이 가능하며, SNS 맞춤 크기 조정 기능으로 모든 플랫폼에서 손쉽게 공유할 수 있습니다. Filmora는 초보자부터 전문가까지 모두를 만족시키는 영상 편집 도구로, 창의적이고 편리한 작업 환경을 제공합니다.\n\n\n\n \nFilmora - 간편한 동영상 편집 앱 - Google Play 앱\n음악, 스티커, 효과, 잘라 내기, 비디오 병합, 비디오 트림이 포함된 유튜브용 최고의 영상 편집앱\nplay.google.com\n\n \n \n \n \n \n \n3. PenCake - 심플한 글쓰기 노트 일기장\n 일상, 여행, 취미, 소설 등 다양한 형태의 이야기를 기록하고 간직할 수 있는 글쓰기 플랫폼입니다. 심플하고 직관적인 디자인으로 구성되어 사용자가 글쓰기에 온전히 집중할 수 있는 환경을 제공합니다. 최소한의 UI를 통해 깔끔하고 아름다운 방식으로 이야기를 작성할 수 있으며, 주제별로 이야기를 분류할 수 있어 체계적인 기록이 가능합니다. \n이 플랫폼은 자동 저장, 변경 이력 복원, 삭제된 글 보관 등 안전한 데이터 관리 기능을 제공하며, iCloud와 Google Drive를 통해 기기 간 동기화도 지원합니다. 프리미엄 사용자에게는 자동 동기화와 다양한 고급 기능이 제공되어 더욱 편리한 글쓰기가 가능합니다. \nPencake는 높은 가독성을 위해 예쁘고 읽기 편한 폰트를 제공하며, 긴 글 작성 시에도 지연 없이 원활하게 작동합니다. 마크다운 기능으로 서식을 지정할 수 있으며, PC 버전과 모바일 버전 간의 완벽한 연동을 지원해 생산성을 높일 수 있습니다. \n추가적으로 글자수와 단어수 표시, 검색 기능, 캡션 삽입, 비밀번호 잠금, 다크 모드 등 다양한 편의 기능을 제공하여 글쓰기를 더욱 즐겁고 편리하게 만들어 줍니다.\n\n\n\n \nPenCake - 심플한 글쓰기 노트 일기장 - Google Play 앱\n미니멀하고 깔끔한 글쓰기 노트\nplay.google.com\n\n \n \n \n \n \n \n4. 비주얼 가계부\n\n 은행 및 카드 내역 문자를 자동으로 입력하고, 지출 내용을 스마트하게 분류해 사용자가 별도의 입력 없이 편리하게 가계부를 관리할 수 있도록 도와줍니다. 다양한 차트와 그래프를 통해 지출 내역을 시각적으로 확인할 수 있으며, 일러스트 메시지를 통해 직관적이고 재미있는 사용자 경험을 제공합니다. \n예산 대비 실제 지출 상황을 실시간으로 알림받을 수 있으며, 남은 예산에 따라 푸시 알림을 제공해 예산 초과를 방지하고 지출을 효과적으로 통제할 수 있습니다. 또한, 외식, 음주, 문화생활 등 생활패턴을 분석하고, 한 달 평균 유가 정보 등을 산출해 소비 습관을 파악할 수 있는 기능도 포함되어 있습니다. \n구글 캘린더와 연동해 지출 내역이 기록된 보조 캘린더를 생성할 수 있으며, 이를 통해 캘린더에서 실시간으로 가계부를 확인하고 체계적인 지출 관리가 가능합니다. 이 가계부는 자동화와 시각화를 통해 사용자가 효율적으로 재정을 관리할 수 있는 최적의 도구입니다.\n\n\n\n \n비주얼 가계부 - Google Play 앱\n스마트폰과 PC에서 완벽한 기기간 동기화 지원 자동으로 기록하고 분류하는 비주얼 가계부!\nplay.google.com\n\n \n \n \n \n \n \n5. 포스텔러 - 신년운세, 사주, 타로, 궁합, 점성술\n포스텔러는 전 국민이 선택한 운세 플랫폼으로, 개인별 맞춤 운세를 제공하는 전문 앱입니다. 네이버와 카카오 출신의 기획자와 개발자들이 자체적으로 구축한 사주 및 점성술 분석 시스템을 기반으로, 860만 명의 데이터를 반영해 다양한 운세 콘텐츠를 제공합니다. 사용자 평점 5점 만점에 4.8점을 기록하며, 높은 신뢰도와 품질을 자랑합니다. \n2025년 을사년 신년운세는 체계적인 데이터를 활용해 재물운, 연애운 등 상세한 운세 풀이와 월별 운세 흐름을 제공합니다. 이 밖에도 정통 사주, 토정비결, 타로, 점성술, 자미두수 등 다양한 운세를 100~200쪽 분량의 풍부한 해석으로 만나볼 수 있습니다. \n포스텔러는 매월 업데이트되는 신규 콘텐츠와 무료로 즐길 수 있는 고퀄리티 운세를 포함하여 누적 6,000건 이상의 콘텐츠를 보유하고 있습니다. 총 46개의 주제별/장르별 운세가 제공되며, 사용자는 개인별 맞춤 운세를 추천받고, 마이페이트북을 통해 본 운세를 다시 확인할 수 있습니다.\n\n\n\n \n포스텔러 - 신년운세, 사주, 타로, 궁합, 점성술 - Google Play 앱\n860만 유저가 믿고보는 용한점집 포스텔러 2025 을사년 신년운세를 만나보세요\nplay.google.com",
        "guid": "http://muzbox.tistory.com/483502",
        "categories": [
          "ANDROID &amp; 모바일/추천 무료 앱",
          "Filmora",
          "가계부",
          "노트",
          "동영상편집",
          "무료앱",
          "사주",
          "신년 운세",
          "안드로이드앱",
          "일기장",
          "일본어공부"
        ],
        "isoDate": "2024-11-24T23:47:19.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "이어폰 잭, 스마트폰에서 사라지는 이유",
        "link": "http://muzbox.tistory.com/483501",
        "pubDate": "Wed, 20 Nov 2024 11:15:22 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483501#entry483501comment",
        "content": "<p data-ke-size=\"size16\">아이폰부터 안드로이드까지 스마트폰에서 이어폰 잭이 사라지는 이유와 그에 따른 변화, 대안 기술 및 여전히 이어폰 잭을 탑재하는 기기의 트렌드를 살펴봅니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"500\" data-origin-height=\"333\"><span data-url=\"https://blog.kakaocdn.net/dn/cXrZxI/btsKPT8PUJM/OGoJSdoiqwtPnHIaWZloqK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cXrZxI/btsKPT8PUJM/OGoJSdoiqwtPnHIaWZloqK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cXrZxI/btsKPT8PUJM/OGoJSdoiqwtPnHIaWZloqK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcXrZxI%2FbtsKPT8PUJM%2FOGoJSdoiqwtPnHIaWZloqK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"이어폰 잭, 스마트폰에서 사라지는 이유\" data-origin-width=\"500\" data-origin-height=\"333\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;스마트폰은 현대인의 일상에서 빼놓을 수 없는 존재가 되었습니다. 이와 함께 이어폰은 음악 감상, 영상 시청, 게임 플레이 등 다양한 활동에서 중요한 도구로 자리 잡았습니다. 과거에는 이어폰 잭이 스마트폰에 필수적으로 포함되었지만, 최근에는 이어폰 잭이 사라지고 무선 이어폰이 그 자리를 대체하고 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이러한 변화는 단순히 기술 발전 때문만이 아니라, 스마트폰 제조사들의 설계와 제품 전략에 따른 결과입니다. 이어폰 잭이 사라진 이유와 이러한 변화가 소비자와 기술 산업에 미친 영향을 살펴보는 것은 흥미로운 주제입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이번 포스팅에서는 이어폰 잭의 퇴장 배경, 이어폰 잭이 여전히 필요한 이유, 그리고 앞으로의 기술 전망을 깊이 있게 살펴보겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>이어폰 잭의 퇴장 이유</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #f89009;\"><i><b>1. 스마트폰 디자인과 기능의 진화</b></i></span></h3>\n<p data-ke-size=\"size16\">&nbsp;이어폰 잭이 사라진 가장 큰 이유 중 하나는 <b>스마트폰 설계의 혁신</b>입니다. 스마트폰 내부 공간은 매우 한정적이며, 이어폰 잭은 크기와 구조상 많은 공간을 차지합니다. 이를 제거함으로써 스마트폰 제조사들은 더 얇고 가벼운 디자인을 실현하고, 확보된 공간을 활용해 더 큰 배터리나 향상된 카메라 센서를 추가할 수 있게 되었습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;예를 들어, 2016년 애플은 <b>아이폰 7</b>에서 이어폰 잭을 제거하며 이 공간을 방수 및 방진 기능 강화에 활용했습니다. 또한 이 모델을 통해 블루투스 연결 무선 이어폰인 <b>에어팟</b>을 발표하며 무선 기술 도입을 대중화했습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"500\" data-origin-height=\"375\"><span data-url=\"https://blog.kakaocdn.net/dn/cDnq21/btsKOb4chKb/2auVt0lR8mD9fXoJmAY57K/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cDnq21/btsKOb4chKb/2auVt0lR8mD9fXoJmAY57K/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cDnq21/btsKOb4chKb/2auVt0lR8mD9fXoJmAY57K/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcDnq21%2FbtsKOb4chKb%2F2auVt0lR8mD9fXoJmAY57K%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"500\" data-origin-height=\"375\"/></span></figure>\n</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #f89009;\"><i><b>2. 무선 기술의 발전</b></i></span></h3>\n<p data-ke-size=\"size16\">이어폰 잭의 퇴장은 무선 기술의 급격한 발전과 맞물려 있습니다. 블루투스 5.0 기술은 연결 안정성과 음질을 크게 개선했으며, 이를 통해 소비자들은 유선 이어폰에 비해 더욱 편리한 무선 이어폰을 선택하게 되었습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">또한 무선 이어폰의 보급이 확대되면서 가격도 다양해졌습니다. 초기에는 고가의 제품만 있었지만, 현재는 저렴한 무선 이어폰도 쉽게 구입할 수 있어 소비자의 선택지가 넓어졌습니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #f89009;\"><b>3. 새로운 수익 모델 창출</b></span></h3>\n<p data-ke-size=\"size16\">제조사 입장에서는 이어폰 잭 제거가 새로운 수익 창출 기회로 작용하기도 합니다. 애플이 에어팟을 통해 시장에서 성공을 거둔 것처럼, 제조사들은 자사 브랜드의 무선 이어폰을 소비자에게 판매하며 추가적인 매출을 올릴 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>여전히 이어폰 잭을 사용하는 스마트폰</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #f89009;\"><i><b>1. 실용성과 가성비를 중시하는 저가형 스마트폰</b></i></span></h3>\n<p data-ke-size=\"size16\">&nbsp;이어폰 잭이 사라지고 있는 와중에도, 일부 제조사들은 저가형 스마트폰에 이어폰 잭을 유지하고 있습니다. 이 스마트폰은 주로 <b>고령층 사용자</b>나 <b>경제적 여유가 부족한 계층</b>을 겨냥합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이러한 사용자층은 무선 이어폰의 사용법을 익히는 데 어려움을 느끼거나, 고가의 무선 이어폰을 구입하기 부담스러워합니다. 예를 들어, 일본의 <b>arrows We2</b>와 같은 스마트폰은 이어폰 잭을 유지함으로써 이들의 필요를 충족합니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #f89009;\"><i><b>2. 고음질을 중시하는 오디오 전문 스마트폰</b></i></span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1149\" data-origin-height=\"616\"><span data-url=\"https://blog.kakaocdn.net/dn/dphqQ9/btsKN5QIKb7/9Iz2Ka4rm1KveW5Ch41xR1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dphqQ9/btsKN5QIKb7/9Iz2Ka4rm1KveW5Ch41xR1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dphqQ9/btsKN5QIKb7/9Iz2Ka4rm1KveW5Ch41xR1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdphqQ9%2FbtsKN5QIKb7%2F9Iz2Ka4rm1KveW5Ch41xR1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"700\" height=\"375\" data-origin-width=\"1149\" data-origin-height=\"616\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;음질에 민감한 사용자들 사이에서는 여전히 유선 이어폰이 선호됩니다. 특히, 소니의 <b>Xperia 1 II</b>와 같은 스마트폰은 이어폰 잭을 유지하며 고품질 오디오 경험을 제공합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">소니는 자사의 강력한 오디오 기술을 활용해 <b>하이파이 음원</b>이나 <b>하이레졸루션 오디오</b>를 즐기고자 하는 사용자들에게 특별한 경험을 제공합니다. 이는 오디오 애호가들이 여전히 유선 이어폰을 선호하는 이유와 맞닿아 있습니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #f89009;\"><i><b>3. 게임 성능을 강조하는 게이밍 스마트폰</b></i></span></h3>\n<p data-ke-size=\"size16\">게이밍 스마트폰은 이어폰 잭을 필수적으로 포함하는 경우가 많습니다. 무선 연결은 지연 문제가 발생하기 쉬운데, 이는 <b>리듬 게임</b>이나 <b>슈팅 게임</b>과 같은 정확한 타이밍이 중요한 게임에서 치명적일 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>ASUS ROG Phone</b> 시리즈는 이러한 이유로 유선 이어폰 연결을 지원하며, 게이머들에게 최고의 성능을 제공합니다. 이는 게이밍 환경에서 유선 이어폰의 중요성을 잘 보여주는 사례입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>앞으로의 기술 전망</b></span></h2>\n<p data-ke-size=\"size16\">이어폰 잭의 퇴장은 기술과 소비자 트렌드의 변화에 따른 자연스러운 흐름으로 보입니다. 그러나 특정 사용자층의 요구는 여전히 존재하며, 이어폰 잭을 완전히 제거하는 것은 쉽지 않아 보입니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #f89009;\"><i><b>1. 혼합형 스마트폰의 등장</b></i></span></h3>\n<p data-ke-size=\"size16\">앞으로는 이어폰 잭과 무선 기술을 혼합하여 제공하는 스마트폰이 증가할 가능성이 있습니다. 이는 소비자에게 선택의 자유를 제공하고, 특정 니즈를 충족하기 위한 전략이 될 것입니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #f89009;\"><i><b>2. 블루투스 기술의 추가 발전</b></i></span></h3>\n<p data-ke-size=\"size16\">무선 연결의 지연 문제와 음질 저하를 극복하기 위해 블루투스 기술은 계속 발전하고 있습니다. 특히, <b>aptX Adaptive</b>나 <b>LDAC</b>와 같은 고급 코덱은 무선 환경에서도 뛰어난 음질을 제공하며, 유선의 필요성을 점점 줄여 나갈 것입니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #f89009;\"><i><b>3. 사용자 맞춤형 경험</b></i></span></h3>\n<p data-ke-size=\"size16\">스마트폰 제조사들은 이어폰 잭과 무선 기술의 공존을 넘어, 소비자 개개인의 라이프스타일에 맞춘 제품을 선보일 가능성이 큽니다. 이는 맞춤형 기능과 액세서리를 통해 이루어질 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>마치며</b></span></h2>\n<p data-ke-size=\"size16\">&nbsp;스마트폰에서 이어폰 잭이 사라지는 현상은 단순한 기술적 변화라기보다, 산업의 흐름과 소비자 니즈의 복합적인 결과입니다. 이어폰 잭의 제거는 스마트폰 설계와 성능에 긍정적인 영향을 미쳤고, 무선 기술의 대중화를 가속화했습니다. 하지만 여전히 이어폰 잭을 필요로 하는 소비자가 존재하며, 특정 사용자층과 제품 카테고리에서는 이어폰 잭이 유지되고 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1062\" data-origin-height=\"750\"><span data-url=\"https://blog.kakaocdn.net/dn/bne3VS/btsKPNOlMRK/Jl50GmJUyaRDjy1QlfbusK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bne3VS/btsKPNOlMRK/Jl50GmJUyaRDjy1QlfbusK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bne3VS/btsKPNOlMRK/Jl50GmJUyaRDjy1QlfbusK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbne3VS%2FbtsKPNOlMRK%2FJl50GmJUyaRDjy1QlfbusK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"스마트폰 오디오잭\" width=\"700\" height=\"494\" data-origin-width=\"1062\" data-origin-height=\"750\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;이어폰 잭의 퇴장과 무선 기술의 부상은 단순히 기술적 편의성을 넘어, 우리의 라이프스타일에 직접적인 변화를 가져왔습니다. 무선 이어폰은 더 자유롭고 간편한 사용을 제공하지만, 유선 이어폰만이 줄 수 있는 고음질과 안정성은 무시할 수 없는 장점으로 남아 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;앞으로의 기술 발전이 이러한 장점을 모두 아우를 수 있을지, 그리고 스마트폰 제조사들이 어떤 전략을 펼칠지 기대됩니다. 여러분도 스마트폰을 선택할 때, 자신의 사용 패턴과 라이프스타일에 맞는 기능을 꼼꼼히 따져 보세요. 기술은 우리 삶을 편리하게 해주는 도구일 뿐, 궁극적인 결정권은 항상 여러분에게 있다는 점을 잊지 마시길 바랍니다.  </p>",
        "contentSnippet": "아이폰부터 안드로이드까지 스마트폰에서 이어폰 잭이 사라지는 이유와 그에 따른 변화, 대안 기술 및 여전히 이어폰 잭을 탑재하는 기기의 트렌드를 살펴봅니다.\n\n\n \n 스마트폰은 현대인의 일상에서 빼놓을 수 없는 존재가 되었습니다. 이와 함께 이어폰은 음악 감상, 영상 시청, 게임 플레이 등 다양한 활동에서 중요한 도구로 자리 잡았습니다. 과거에는 이어폰 잭이 스마트폰에 필수적으로 포함되었지만, 최근에는 이어폰 잭이 사라지고 무선 이어폰이 그 자리를 대체하고 있습니다.\n \n이러한 변화는 단순히 기술 발전 때문만이 아니라, 스마트폰 제조사들의 설계와 제품 전략에 따른 결과입니다. 이어폰 잭이 사라진 이유와 이러한 변화가 소비자와 기술 산업에 미친 영향을 살펴보는 것은 흥미로운 주제입니다.\n \n이번 포스팅에서는 이어폰 잭의 퇴장 배경, 이어폰 잭이 여전히 필요한 이유, 그리고 앞으로의 기술 전망을 깊이 있게 살펴보겠습니다.\n \n \n이어폰 잭의 퇴장 이유\n1. 스마트폰 디자인과 기능의 진화\n 이어폰 잭이 사라진 가장 큰 이유 중 하나는 스마트폰 설계의 혁신입니다. 스마트폰 내부 공간은 매우 한정적이며, 이어폰 잭은 크기와 구조상 많은 공간을 차지합니다. 이를 제거함으로써 스마트폰 제조사들은 더 얇고 가벼운 디자인을 실현하고, 확보된 공간을 활용해 더 큰 배터리나 향상된 카메라 센서를 추가할 수 있게 되었습니다.\n \n 예를 들어, 2016년 애플은 아이폰 7에서 이어폰 잭을 제거하며 이 공간을 방수 및 방진 기능 강화에 활용했습니다. 또한 이 모델을 통해 블루투스 연결 무선 이어폰인 에어팟을 발표하며 무선 기술 도입을 대중화했습니다.\n\n\n2. 무선 기술의 발전\n이어폰 잭의 퇴장은 무선 기술의 급격한 발전과 맞물려 있습니다. 블루투스 5.0 기술은 연결 안정성과 음질을 크게 개선했으며, 이를 통해 소비자들은 유선 이어폰에 비해 더욱 편리한 무선 이어폰을 선택하게 되었습니다.\n \n또한 무선 이어폰의 보급이 확대되면서 가격도 다양해졌습니다. 초기에는 고가의 제품만 있었지만, 현재는 저렴한 무선 이어폰도 쉽게 구입할 수 있어 소비자의 선택지가 넓어졌습니다.\n3. 새로운 수익 모델 창출\n제조사 입장에서는 이어폰 잭 제거가 새로운 수익 창출 기회로 작용하기도 합니다. 애플이 에어팟을 통해 시장에서 성공을 거둔 것처럼, 제조사들은 자사 브랜드의 무선 이어폰을 소비자에게 판매하며 추가적인 매출을 올릴 수 있습니다.\n \n \n여전히 이어폰 잭을 사용하는 스마트폰\n1. 실용성과 가성비를 중시하는 저가형 스마트폰\n 이어폰 잭이 사라지고 있는 와중에도, 일부 제조사들은 저가형 스마트폰에 이어폰 잭을 유지하고 있습니다. 이 스마트폰은 주로 고령층 사용자나 경제적 여유가 부족한 계층을 겨냥합니다.\n \n이러한 사용자층은 무선 이어폰의 사용법을 익히는 데 어려움을 느끼거나, 고가의 무선 이어폰을 구입하기 부담스러워합니다. 예를 들어, 일본의 arrows We2와 같은 스마트폰은 이어폰 잭을 유지함으로써 이들의 필요를 충족합니다.\n2. 고음질을 중시하는 오디오 전문 스마트폰\n\n\n \n 음질에 민감한 사용자들 사이에서는 여전히 유선 이어폰이 선호됩니다. 특히, 소니의 Xperia 1 II와 같은 스마트폰은 이어폰 잭을 유지하며 고품질 오디오 경험을 제공합니다.\n \n소니는 자사의 강력한 오디오 기술을 활용해 하이파이 음원이나 하이레졸루션 오디오를 즐기고자 하는 사용자들에게 특별한 경험을 제공합니다. 이는 오디오 애호가들이 여전히 유선 이어폰을 선호하는 이유와 맞닿아 있습니다.\n3. 게임 성능을 강조하는 게이밍 스마트폰\n게이밍 스마트폰은 이어폰 잭을 필수적으로 포함하는 경우가 많습니다. 무선 연결은 지연 문제가 발생하기 쉬운데, 이는 리듬 게임이나 슈팅 게임과 같은 정확한 타이밍이 중요한 게임에서 치명적일 수 있습니다.\n \nASUS ROG Phone 시리즈는 이러한 이유로 유선 이어폰 연결을 지원하며, 게이머들에게 최고의 성능을 제공합니다. 이는 게이밍 환경에서 유선 이어폰의 중요성을 잘 보여주는 사례입니다.\n \n \n앞으로의 기술 전망\n이어폰 잭의 퇴장은 기술과 소비자 트렌드의 변화에 따른 자연스러운 흐름으로 보입니다. 그러나 특정 사용자층의 요구는 여전히 존재하며, 이어폰 잭을 완전히 제거하는 것은 쉽지 않아 보입니다.\n1. 혼합형 스마트폰의 등장\n앞으로는 이어폰 잭과 무선 기술을 혼합하여 제공하는 스마트폰이 증가할 가능성이 있습니다. 이는 소비자에게 선택의 자유를 제공하고, 특정 니즈를 충족하기 위한 전략이 될 것입니다.\n2. 블루투스 기술의 추가 발전\n무선 연결의 지연 문제와 음질 저하를 극복하기 위해 블루투스 기술은 계속 발전하고 있습니다. 특히, aptX Adaptive나 LDAC와 같은 고급 코덱은 무선 환경에서도 뛰어난 음질을 제공하며, 유선의 필요성을 점점 줄여 나갈 것입니다.\n3. 사용자 맞춤형 경험\n스마트폰 제조사들은 이어폰 잭과 무선 기술의 공존을 넘어, 소비자 개개인의 라이프스타일에 맞춘 제품을 선보일 가능성이 큽니다. 이는 맞춤형 기능과 액세서리를 통해 이루어질 것입니다.\n \n \n마치며\n 스마트폰에서 이어폰 잭이 사라지는 현상은 단순한 기술적 변화라기보다, 산업의 흐름과 소비자 니즈의 복합적인 결과입니다. 이어폰 잭의 제거는 스마트폰 설계와 성능에 긍정적인 영향을 미쳤고, 무선 기술의 대중화를 가속화했습니다. 하지만 여전히 이어폰 잭을 필요로 하는 소비자가 존재하며, 특정 사용자층과 제품 카테고리에서는 이어폰 잭이 유지되고 있습니다.\n\n\n \n 이어폰 잭의 퇴장과 무선 기술의 부상은 단순히 기술적 편의성을 넘어, 우리의 라이프스타일에 직접적인 변화를 가져왔습니다. 무선 이어폰은 더 자유롭고 간편한 사용을 제공하지만, 유선 이어폰만이 줄 수 있는 고음질과 안정성은 무시할 수 없는 장점으로 남아 있습니다.\n \n 앞으로의 기술 발전이 이러한 장점을 모두 아우를 수 있을지, 그리고 스마트폰 제조사들이 어떤 전략을 펼칠지 기대됩니다. 여러분도 스마트폰을 선택할 때, 자신의 사용 패턴과 라이프스타일에 맞는 기능을 꼼꼼히 따져 보세요. 기술은 우리 삶을 편리하게 해주는 도구일 뿐, 궁극적인 결정권은 항상 여러분에게 있다는 점을 잊지 마시길 바랍니다.",
        "guid": "http://muzbox.tistory.com/483501",
        "categories": [
          "ANDROID &amp; 모바일/안드로이드 꿀팁",
          "게이밍기기",
          "무선기술",
          "무선이어폰",
          "블루투스5",
          "블루투스이어폰",
          "스마트폰",
          "오디오마니아",
          "오디오잭",
          "이어폰잭"
        ],
        "isoDate": "2024-11-20T02:15:22.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "｜RULIWEB｜",
        "title": "[게임툰] 폰으로 즐기는 포케카 배틀! 포켓몬 카드 게임 Pocket",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2268",
        "pubDate": "Fri, 22 Nov 2024 20:25:52 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/24/11/22/193539d2e4651ad6b.jpg\">",
        "contentSnippet": "",
        "categories": [
          "게임툰"
        ],
        "isoDate": "2024-11-22T11:25:52.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": [
      {
        "title": "원온원 6년의 기록: 시행착오와 배움들",
        "link": "https://zzsza.github.io/diary/2024/11/24/one-on-ones-lessons-learned/",
        "pubDate": "Sun, 24 Nov 2024 00:00:00 +0000",
        "content": "<ul>\n  <li>이 글은 원온원에 대해 작성한 글입니다\n    <ul>\n      <li>6년 동안 진행한 원온원의 시행착오와 배움들을 기록했습니다</li>\n    </ul>\n  </li>\n  <li>키워드 : 원온원 미팅, 원온원 질문, 원온원 템플릿, 원온원 주제</li>\n</ul>\n\n<hr />\n\n<h1 id=\"들어가며\">들어가며</h1>\n<ul>\n  <li>저는 3년차(2019년)에 팀장 역할을 맡으며 생각보다 빠르게 원온원을 진행해야 했습니다</li>\n  <li>‘어떻게 해야 팀원분들과 제가 모두 만족할 수 있는 원온원을 할 수 있을까?’에 대해 계속 고민하고 여러 내용을 학습하고 다양한 시도를 하며 시행 착오를 겪었습니다\n    <ul>\n      <li>처음 원온원을 할 때를 떠올리면 막막한 감정이 있었고, 좋은 원온원 시간을 가지지 못했던 것 같아요</li>\n      <li>좋은 원온원을 ‘팀원분이 만족스럽게 대화를 끝낼 수 있는가? 무엇을 해야할지 떠올렸는가?’로 정의했습니다</li>\n    </ul>\n  </li>\n  <li>처음 팀장을 하던 시기엔 월에 3~4명과 원온원을 하다가, 시간이 흘러 조직에서 역할이 변경되어 월에 30~40명과 원온원을 진행했습니다\n    <ul>\n      <li>그리고 요즘에도 멘토링, 회사 데이터팀 코칭, 경영진 원온원을 진행하고 있습니다</li>\n    </ul>\n  </li>\n  <li>그동안 원온원 역량 상승을 위해 시도했던 경험들에 대해 작성하려고 합니다</li>\n  <li>참고로 <a href=\"https://zzsza.github.io/diary/2020/04/26/novice-leader-retrospect/\">초보 개발 팀장의 1년 회고 - 좋은 팀장이 되기 위한 노력들</a>이란 글에 팀장의 역할과 제가 시도한 점들에 대해 정리했습니다</li>\n  <li>이 글은 제 경험담을 기반으로 작성한 글이고, 이게 정답이다!라는 이야기를 하고 싶은 것이 아닙니다\n    <ul>\n      <li>앞으로도 계속 원온원을 하면서 경험이 계속 늘어날 것 같아요.</li>\n      <li>관련 경험이나 의견 남겨주실 분이 계시다면 남겨주셔요</li>\n    </ul>\n  </li>\n</ul>\n\n<p><br /><br /></p>\n\n<h1 id=\"원온원의-정의와-목적\">원온원의 정의와 목적</h1>\n<ul>\n  <li>원온원은 단어 그대로 1:1로 이야기하는 것을 의미하며, 팀원분이 더 발전된 형태로 업무를 할 수 있도록 서로 이야기를 나누는 자리\n    <ul>\n      <li>주로 팀장님과 팀원이 일대일로 만나 이야기하는 시간</li>\n    </ul>\n  </li>\n  <li>원온원은 다양한 관점으로 진행할 수 있음\n    <ul>\n      <li>정기적인 원온원 : 주기적으로 시간을 잡아서 이야기를 하는 경우</li>\n      <li>도움이 필요해서 요청하는 원온원 : 특정 문제에 대한 고민을 이야기하고 싶어 팀원분이 요청하는 경우</li>\n    </ul>\n  </li>\n  <li><strong>원온원의 목적은 ‘팀원의 발전을 돕는 것’이라 생각</strong>\n    <ul>\n      <li>다양한 관점으로 이야기할 수 있는데, 저는 주로 커리어 관점, 업무 관점, 인간 관점으로 이야기(단순히 회사 한정으로만 생각하지 않음. 거시적인 그 사람의 삶에 대해 이야기)</li>\n      <li>커리어 관점 : 팀원의 커리어를 같이 설계, 역량 개발을 어떻게 할지 이야기</li>\n      <li>업무 관점 : 현재 진행하는 업무에 얼마나 몰입하고 있는지, 어려움이 있는지</li>\n      <li>인간 관점 : 어떤 인생을 살고 싶은가, 스스로에 대한 메타인지</li>\n      <li>기타 : 팀원분이 원하시는 관점이 있다면 그 관점으로 이야기</li>\n    </ul>\n  </li>\n</ul>\n\n<p><br /><br /></p>\n\n<h1 id=\"원온원-역량의-발전-과정\">원온원 역량의 발전 과정</h1>\n<ul>\n  <li>이해를 위해 원온원 레벨을 정의하고, 그 과정의 경험담과 시도했던 것들을 공유</li>\n  <li>레벨은 이해를 위해 정의한 것이고, 꼭 이걸 충족해야 하는 것은 아님</li>\n</ul>\n\n<p><br /><br /></p>\n\n<h2 id=\"lv-1-초기--질문-리스트에-의존한-시기\">Lv 1. 초기 : 질문 리스트에 의존한 시기</h2>\n<h3 id=\"상황context\">상황(Context)</h3>\n<ul>\n  <li>3년차 때 팀장을 하면서 생각보다 빠른 시기에 원온원을 진행해야 했음</li>\n  <li>처음엔 참 막막했음. 원온원을 해본 적이 없는데 어떻게 해야할까?</li>\n  <li>그래서 일단 어떻게 질문을 해야할지 고민했음. 많은 분들이 처음 시도하면 이렇게 하실 것 같음</li>\n  <li>구글에 1 on 1 question list, 원온원 질문, 원온원 템플릿 등을 검색하며 질문을 모았음</li>\n</ul>\n\n<h3 id=\"경험담\">경험담</h3>\n<ul>\n  <li>원온원 질문 리스트를 기반으로 원온원을 진행했는데, 기계적으로 하는 느낌이 들었음</li>\n  <li><strong>깊게 대화하는 느낌보단 체크 리스트가 있고 그걸 하나씩 물어보는 제 모습을 보게 됨</strong></li>\n  <li>A라는 질문에 대해 다 했으면 B로 넘어가고, B에 대해 이야기하면 C에 대해 넘어가며 겉 이야기를 계속 하는 것 같았음</li>\n  <li>나와 팀원 둘 다에게 소모적인 시간이라고 생각했음</li>\n</ul>\n\n<h3 id=\"이-시기의-시도\">이 시기의 시도</h3>\n<ul>\n  <li><strong>원온원의 본질에 대해 고민함. 원온원 질문이 아닌 본질적으로 사람을 어떻게 도와야 할까?에 대한 생각을 하며 관련 서적을 많이 읽음</strong></li>\n  <li>그렇다면 도움을 어떻게 잘 줄 수 있을까? 도움에 대해 정의하고, 그 정의에 맞게 Action Item을 실행하기로 다짐함\n    <ul>\n      <li>이 과정에서 에드거 샤인님의 헬핑이란 책이 큰 도움이 되었음</li>\n      <li>최근 <a href=\"https://www.yes24.com/Product/Goods/138722152\">리더의 돕는 법</a>이란 제목으로 다시 출간되었음</li>\n      <li>이 책을 읽고, 실제로 경험도 하면서 점점 나만의 원칙, 기준이 생겼음</li>\n    </ul>\n  </li>\n  <li>헬핑 책 외에도 도움이 되었던 것은 동기면담, 코칭, 사람 심리, 화법 학습\n    <ul>\n      <li>동기면담에 대한 내용은 <a href=\"https://zzsza.github.io/etc/2020/08/15/miti-workshop-review/\">MITI 동기면담 워크샵 후기</a> 이 글에 내용을 작성했는데, 동기면담을 배우고 1 on 1을 더 잘 수행할 수 있게 됨</li>\n      <li>동기면담은 동기를 이끌어내는 의사소통 스타일, 내담자와 상담 기록을 특정 코드로 부호화함</li>\n      <li>면담의 효과를 평가할 수 있게 됨</li>\n    </ul>\n  </li>\n  <li>또 떠오르는 책은 <a href=\"https://www.yes24.com/Product/Goods/11520753\">상자 밖에 있는 사람</a>\n    <ul>\n      <li>이 책을 읽고 다른 사람을 어떻게 이해해야 할지, 나의 관점으로만 생각하지 말고 다른 사람의 관점에서 생각할 수 있게 됨</li>\n      <li>팀장을 처음 하는 분들에게 꼭 추천하는 책</li>\n    </ul>\n  </li>\n  <li>시도를 하며 깨달은 점\n    <ul>\n      <li><strong>“어떤” 것을 질문하는 것보단 팀원을 이해하고, 팀원을 잘 돕는 것이 핵심이라 생각했음. 자주 할 수 있는 질문 리스트가 있지만 너무 질문에 얽매이지 않아도 된다는 것을 느꼈음</strong></li>\n      <li><strong>팀원을 내가 어떻게 도울 수 있을까?라는 생각을 하면서 원온원을 진행하니 부담감도 줄어들고 어떻게 대화를 해야할지 떠오르게 되었음</strong></li>\n      <li>질문 리스트 자체보다, 질문 리스트에 작성한 사람은 왜 이 질문을 하게 되었을까?를 생각하니 도움이 되었음</li>\n      <li>에드거 샤인님은 도움을 다음과 같이 정의함 : <strong>“도움은 한 사람이 다른 사람의 문제를 해결하거나 상황을 개선하기 위해 지식, 자원, 감정적 지지를 제공하는 사회적 상호작용 과정”</strong>\n        <ul>\n          <li>문제에 대해 초점을 맞추고 감정적 지지를 제공한다는 점을 인상 깊게 봄</li>\n          <li>단순히 일방적인 것이 아닌 상호작용 과정이라는 것도 중요한 포인트</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n</ul>\n\n<p><br /><br /></p>\n\n<h2 id=\"lv-2-본질에-집중한-시기\">Lv 2. 본질에 집중한 시기</h2>\n<h3 id=\"상황context-1\">상황(Context)</h3>\n<ul>\n  <li>Lv 1의 역량 상승을 위한 시도에 나온 것처럼 본질에 집중하니, 이제 원온원 시간을 ‘팀원분은 어떤 도움이 필요할까?’를 생각하며 대화를 진행함</li>\n  <li>마음가짐이 달라지니 저도 마음이 편해지고, 더 진심을 다할 수 있었음</li>\n  <li>내가 말을 더 많이 하는게 아닌, 팀원분이 더 이야기를 할 수 있는 환경을 만들려고 했음\n    <ul>\n      <li>서로 이야기를 잘 진행하려면 서로에게 신뢰가 필요하다고 생각했음</li>\n      <li>나만 이야기하는 것이 아닌, 상호작용 과정이므로 어떻게 해야 서로 잘 이야기를 할 수 있을까?도 고민함</li>\n    </ul>\n  </li>\n</ul>\n\n<h3 id=\"경험담-1\">경험담</h3>\n<ul>\n  <li>팀원분이 어떤 내용을 이야기하는 것이 어려울 수 있어서 최초엔 요즘 어떤지를 물어봄</li>\n  <li><strong>최근 1달 동안 어떤지를 숫자로 표현해달라고 했음. 0~10점</strong>\n    <ul>\n      <li>매달 이 질문으로 시작하며 점수의 상승이 어떻게 되는지 파악함</li>\n      <li><strong>처음엔 단일 점수로 물어봤는데, 시간이 지나면서 개인 삶 관점과 회사 관점으로 점수를 나눠서 물어봄</strong></li>\n      <li>이렇게 하면 <strong>점수가 올라가거나 내려갈 때, 왜 그런지 물어볼 수 있음. 그러면 어떤 사건이 나타날 수 있고, 이야기를 전개할 때 좋은 힌트</strong>가 됨</li>\n      <li>이 과정을 오래 반복하면(같은 분과 원온원을 1년 이상 진행하면) 점수의 상승, 하락에 대한 요인을 생각할 수 있음. 점수가 상승하거나 하락할 때는 비슷한 관점이 발견되는 경우도 있었고, 이 부분을 정리해서 공유하면 팀원분이 스스로 이 부분에 대해 인지할 수 있었음</li>\n    </ul>\n  </li>\n  <li>점수를 기록한 후, <strong>“오늘 시간에 다루고 싶은 내용이 있으신가요?”라고 질문함</strong>\n    <ul>\n      <li>팀원분이 스스로 다루고 싶은 소재에 대해 언급하고, 그 소재에 기반해 대화를 진행함</li>\n      <li>소재가 없는 경우엔 닫힌 질문보단 열린 질문(단답이 아닌 여러 관점으로 이야기를 할 수 있는 질문)을 사용함</li>\n    </ul>\n  </li>\n  <li><strong>서로에 대한 이해가 충분히 있을 경우, 대화가 잘 진행되는 느낌을 받음</strong>\n    <ul>\n      <li>원온원을 처음 진행할 때, 업무에 대한 내용을 이야기하는 것보다 서로에 대해 이해하는 시간을 가짐. 어떻게 살아왔는지, 어떤 사람인지 등</li>\n      <li>물어보는 내용이 내가 경험한 내용이라면, 과거의 내 생각을 공유했음. 그 시기에 블로그에 작성한 글이 있다면 글을 공유하면서 저도 과거에 비슷한 생각을 했다고 말함</li>\n    </ul>\n  </li>\n  <li>팀원분이 원온원을 하면서 기록하느라 집중하지 못하는 경우도 있었음\n    <ul>\n      <li><strong>저는 타자 속도가 600~800타 정도 되어서 말하면서 기록하는 것이 어렵지 않음. 그래서 아예 제가 기록을 다 하고, 팀원분은 자신의 이야기만 집중할 수 있는 환경을 마련함</strong></li>\n      <li>처음엔 노션 페이지를 만들고, 원온원이 끝날 때 공유하는 형태로 진행하다가 추후엔 팀원마다 스프레드시트를 만들고, 그 스프레드시트를 같이 보면서 이야기함. 이렇게 진행할 경우 팀원분이 자신의 의도가 잘 기록되었는가(=제가 제대로 이해했는가)를 빠르게 확인할 수 있어서 대화 중간에 내용을 수정함</li>\n    </ul>\n  </li>\n  <li><strong>팀원분이 도움을 받을 준비가 되었는지도 중요했음. 도움을 받고 싶다는 생각이 없다면 잘 진행되지 않았음</strong>\n    <ul>\n      <li>이럴 땐 차라리 짧게 끝내고 추후에 고민이 있다면 말씀해달라고 요청했음</li>\n    </ul>\n  </li>\n</ul>\n\n<h3 id=\"이-시기의-시도-1\">이 시기의 시도</h3>\n<ul>\n  <li><strong>신뢰란 무엇인가</strong>에 대해 고민함\n    <ul>\n      <li>어떻게 해야 신뢰를 할 수 있을까?</li>\n      <li>신뢰에 대한 연구는 과거에 많이 진행되어 있어서, 많이 언급되는 신뢰 모델을 찾아봄</li>\n      <li>데니스 레이나의 신뢰 모델. <a href=\"https://www.amazon.com/Trust-Betrayal-Workplace-Relationships-Organization/dp/1626562571\">Trust and Betrayal in the Workplace: Building Effective Relationships in Your Organization 책</a>\n        <ul>\n          <li>신뢰는 상호작용을 통해 형성되고, 시간을 두고 점진적으로 발전함</li>\n          <li>신뢰의 핵심 요소\n            <ul>\n              <li>역량 신뢰(Competence Trust)</li>\n              <li>계약적 신뢰(Contractual Trust)</li>\n              <li>소통 신뢰(Communication Trust)</li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n      <li>스티븐 코비의 신뢰 모델. <a href=\"https://www.yes24.com/Product/Goods/3502454\">신뢰의 속도 책</a>\n        <ul>\n          <li>신뢰의 핵심 요소\n            <ul>\n              <li>성실성</li>\n              <li>의도</li>\n              <li>능력</li>\n              <li>성과</li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n      <li>여러 관점을 보면서 나는 어떤 신뢰를 획득했을까?를 고민함</li>\n    </ul>\n  </li>\n  <li><strong>Lv 1 때 역량 상승을 위한 시도는 책이나 영상을 봤다면, 이젠 많이 시도함. 많은 경험을 쌓으려고 함</strong>\n    <ul>\n      <li>동기면담과 비폭력 대화 내용을 학습해서, 원온원을 할 때 어떤 방식으로 이야기를 전개하는지 나의 화법은 어떠했는지를 점검함\n        <ul>\n          <li>면담 내용을 기록했기에 다시 보면서 점검할 수 있었고, 가끔은 팀원에게 허락을 구해 면담 내용을 녹음하고 다시 들어보며 복기함</li>\n          <li>다시 들어보니까 더 객관적으로 느껴지고, 아 이런 타이밍엔 이렇게 했었으면 더 좋았겠다를 기록함</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n  <li>동기면담의 총점(Global Score)과 행동 점수(Behavior Counts)를 파악함\n    <ul>\n      <li>총점 : 부호를 기록하는 사람이 임상가와 내담자의 전반적인 상호작용을 5점으로 표시. 총 4가지 부분을 확인함\n        <ul>\n          <li>변화 대화 일구기(Cultivating Change Talk) : 변화의 방향으로 대화를 진행하는가?</li>\n          <li>유지 대화 완화하기(Softening Sustain Talk) : 현 상황을 유지하는 유지 대화를 최소화</li>\n          <li>파트너쉽(Partnership) : 동등한 파트너끼리 인터뷰하는 것처럼 행동함(상호 커뮤니케이션이 얼마나 있는지 등)</li>\n          <li>공감(Empathy) : 면담가가 내담자의 세계관을 적극적으로 이해하고 노력하는 정도를 측정</li>\n          <li>여기선 내가 말한 내용을 기록했지만, 동기면담을 공부하신 다른 분들과 교차 검증을 하면 좋았을 것 같음</li>\n        </ul>\n      </li>\n      <li>행동 점수(Behavior Counts)\n        <ul>\n          <li>행동 점수는 정보제공, 설득하기, 질문, 단순 반영/복합 반영, 인정하기, 협동 구하기, 자율성 강조하기, 직면 등의 요소를 확인</li>\n          <li>자세한 내용은 <a href=\"https://zzsza.github.io/etc/2020/08/15/miti-workshop-review/\">MITI 워크샵 후기</a> 글에서 확인할 수 있음</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n  <li><strong>과거에 시도했던 내용들을 복기하며 ‘어떻게 진행하자’라는 기준, 원칙을 세움</strong>\n    <ul>\n      <li>(1) 문제를 명확하게 이해하기 전에는 성급하게 이야기를 시작하지 말자</li>\n      <li>(2) 말하는 내용이 진짜 문제인가 꼭 확인하자. 때론 진짜 문제가 숨겨진 경우가 있음</li>\n      <li>(3) 가치 판단이라고 판단할 수 있는 표현은 피하자.</li>\n      <li>(4) 문제 해결은 개인이 스스로 진행해야 하는 것을 언급하자</li>\n      <li>(5) 대화가 잘 진행되지 않는 것 같으면 중간에 물어보자 : “지금 어떤 생각이 드세요?”</li>\n      <li>(6) 마냥 잘 될것이라는 이야기만 하지 말자. 현실적으로 생각해보자</li>\n      <li>(7) 진심을 다 하고 있다는 것을 느낄 수 있도록 집중하자</li>\n      <li>(8) 갑자기 원온원 요청이 오면 어떻게 해서라도 시간을 확보해서 이야기</li>\n      <li>(9) 원온원 시간엔 슬랙 알람이 오지 않도록 슬랙 아예 끄기. 집중하는 환경 만들기</li>\n      <li>(10) 내가 이야기를 많이 하고 있는 것 같으면 멈추자(많이 하는 경우도 있겠지만)</li>\n    </ul>\n  </li>\n</ul>\n\n<p><br /><br /></p>\n\n<h2 id=\"lv-3--맥락에-기반한-개인화된-원온원을-시도한-시기\">Lv 3.  맥락에 기반한 개인화된 원온원을 시도한 시기</h2>\n<h3 id=\"상황context-2\">상황(Context)</h3>\n<ul>\n  <li>원온원을 진행하면서 같은 질문이나 같은 반응에 대해 사람마다 다르게 반응하는 것을 느낌\n    <ul>\n      <li>사람마다 적절한 질문이 있을 수 있겠다 싶었고, 그 사람의 맥락을 잘 이해할수록 적절한 반응으로 이야기를 할 수 있었음</li>\n    </ul>\n  </li>\n  <li>마치 추천 시스템처럼 그 사람의 메타 정보를 알아두면 좋겠다 싶었음</li>\n  <li>면담 내용을 기록하는 스프레드시트를 개선해 개인의 맥락을 기록할 수 있도록 개선함</li>\n</ul>\n\n<h3 id=\"경험담-2\">경험담</h3>\n<ul>\n  <li>여러 성격 검사 결과를 보면서 개인에 대해 이해할 수 있도록 하면서, 특정 맥락에서 어떻게 생각하는지를 파악함\n    <ul>\n      <li>MBTI, Big5, 에니어그램, 갤럽의 강점 검사 등을 토대로 이야기를 진행함. 무료로 할 수 있는 것 위주로 진행하고 유료 검사는 내 결과를 보여줌</li>\n    </ul>\n  </li>\n  <li>성격 외에 과거에 팀원이 수행한 업무, 할 수 있는 업무 종류도 기록함. 전 회사에서 했던 경험들도 알면 도움이 되는 경우도 있어서 같이 이야기함</li>\n  <li>팀원이 생각하는 강점, 보완할 점도 이야기하고 앞으로 어떤 것을 해보고 싶은지 이야기함\n    <ul>\n      <li>어떤 경우엔 앞으로 하고 싶은 것이 없는 경우도 있는데, 그건 문제가 아니라고 답변함. 경험을 하다가 나중에 의미를 찾는 경우도 있었음\n        <ul>\n          <li>이런 경우엔 지금에 충실해서 일을 진행하자고 이야기 함</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n  <li>그 외에는 어떤 상황에 동기부여를 얻는가, 스트레스를 해소하는 방법이 있는가, 멘탈 관리법 등 살면서 한번쯤 경험할 수 있는 것들에 대해 이야기 함</li>\n  <li>이런 내용을 충분히 인지하니 팀원의 큰 방향성을 인지하며 원온원에선 미시적인 관점을 주로 이야기함</li>\n  <li>여기서 사용한 템플릿은 아래 구체적인 가이드에 공유할 예정</li>\n  <li>이 시기에 원온원을 해야하는 인원이 10명, 20명 이상이 되면서 <strong>“팀장의 에너지”가 굉장히 중요한 것을 깨달음</strong>\n    <ul>\n      <li>내가 에너지가 없는 상황에서 원온원을 진행하면 만족스럽지 않은 원온원이 되는 경우가 있었음</li>\n      <li>에너지가 있는 상황을 만들고, 여유를 만들고 원온원에 참여함</li>\n      <li>원온원 일정을 몰아서 하지 않고, 하루에 최대 2-3명만 진행하고 일정을 분산했음</li>\n    </ul>\n  </li>\n  <li><strong>팀원분에게 “제가 어떻게 해드리면 좋을까요?”라고 질문함</strong>\n    <ul>\n      <li>어떤 분들은 같이 이야기를 하면서 정리를 해주세요도 있고, 어떤 분들은 구체적인 피드백을 요청하는 경우도 있음</li>\n      <li>고민에 대해서 이야기하기 전에 “이 대화가 잘 끝나면 어떤 모습이면 좋겠어요?”라는 질문을 하면서 상상하고, 그 상상을 실현하기 위해 제가 어떻게 해볼까요?라는 질문을 하기도 함. 때론 직접적으로 물어보는 것보다 이렇게 말하는 것이 효과적이였음</li>\n    </ul>\n  </li>\n</ul>\n\n<h3 id=\"이-시기의-시도-2\">이 시기의 시도</h3>\n<ul>\n  <li>원온원을 해야하는 분들이 많아져서 내가 반복해서 사용하는 시간이 늘어남(=운영 리소스 증가)\n    <ul>\n      <li>예를 들어 개인마다 스프레드시트를 따로 관리해서 새로운 탭을 추가해야 했음</li>\n      <li>이걸 한번에 할 수 있게 템플릿 시트를 만들고, Apps Script를 사용해 여러 스프레드시트에 일괄적으로 반영하도록 개발함</li>\n      <li>간단하게 URL 시트에 개인 별로 스프레드시트 URL을 저장하고, 면담 템플릿을 복사해서 개인 별 스프레드시트에 들어가서 복사하도록 구현함</li>\n    </ul>\n  </li>\n  <li><strong>여유를 가진 상태로 원온원에 참여하도록 일정을 조정하고, 1회 일정이 아닌 반복된 일정을 추가함</strong>\n    <ul>\n      <li>나중에 하시죠!라고 하면 까먹는 경우가 많아서 반복해서 했음</li>\n      <li>하루에 최대 2-3명을 진행하고 원온원 직전엔 30분 정도 버퍼 시간을 두고 과거에 작성한 내용을 읽고 들어감</li>\n      <li>과거에 했던 이야기가 반복되면 ‘오 그거 몇달 전에 이야기한 내용과 유사하네요’라고 말해줌</li>\n    </ul>\n  </li>\n  <li>사람마다 다 생각하는 것이 다르다고 생각하고, 어떤 일에 정답은 없다는 것을 항상 생각했음</li>\n</ul>\n\n<p><br /><br /></p>\n\n<h2 id=\"lv-4-조직-전체의-원온원-프레임워크-개발\">Lv 4. 조직 전체의 원온원 프레임워크 개발</h2>\n<h3 id=\"상황context-3\">상황(Context)</h3>\n<ul>\n  <li>팀장에서 상위의 조직장 역할을 하면서, 팀장님들이 원온원을 잘 진행할 수 있도록 돕는게 중요하다고 생각했음</li>\n  <li>내가 인지하는 원온원 프레임워크를 만들어도, <strong>이 내용을 팀장님들에게 잘 전이하는 것이 중요함</strong></li>\n  <li>그러나 과거 경험이 다 다르기 때문에 어떻게 해야할지 고민함\n    <ul>\n      <li>나만의 프레임워크를 정리하면서, 일단 팀장님과 리더십 원온원을 진행함</li>\n      <li>팀장님의 원온원 면담이나 팀장 역할을 하면서 하는 고민들에 대해 이야기를 나눔</li>\n      <li>그러면서 팀장님의 리더십을 개발할 수 있도록 도움</li>\n    </ul>\n  </li>\n  <li>이 부분에 대한 것은 경영진분들과 컨설팅, 코칭을 할 때 필요한 것을 느낌</li>\n</ul>\n\n<h3 id=\"경험담-3\">경험담</h3>\n<ul>\n  <li>팀장님의 경험담을 잘 정리하고, 팀장님마다 고유한 리더십 역량을 개발하도록 도움\n    <ul>\n      <li>앞서 팀장님도 과거 원온원을 통해 개인에 대한 이해를 서로 진행한 경우가 많아 이 부분이 수월하게 진행되었음</li>\n    </ul>\n  </li>\n  <li>조직의 특성도 고려하는 것이 필요함\n    <ul>\n      <li>개발 조직과 데이터, AI 조직의 지향점이 다를 수 있고 데이터, AI 조직도 회사마다 다양할 수 있음</li>\n      <li>우리 조직의 특성을 충분히 고민하고 어떻게 이야기를 하는게 좋은지 작성하는게 필요함(대표적인 예시 : 우리가 정의하는 좋은 원온원은?)</li>\n    </ul>\n  </li>\n  <li>원온원 프레임워크를 만드는 것도 중요하지만, 이 프레임워크가 왜 만들어졌는지까지 인지하게 하는 것이 중요함\n    <ul>\n      <li>그 과정에서 팀장 워크샵 등을 진행하는 것이 필요하고, 어떻게 이 내용을 잘 전이할까?가 더 중요한 요소라 생각함</li>\n    </ul>\n  </li>\n  <li>이 때 커리어 프레임워크을 보면서 참고함. 원온원 프레임워크와 다르지만 커리어 프레임워크처럼 기대하는 부분을 명확히 하면 좋을까?란 생각을 했음. 이 부분에 대해서는 아직 계속 개선하고 있는 중. 이런 부분에 대해 이야기를 같이 하실 분이 있다면 이야기 나눠보고 싶네요\n    <ul>\n      <li><a href=\"https://dropbox.github.io/dbx-career-framework/\">드랍박스의 커리어 프레임워크</a></li>\n    </ul>\n  </li>\n</ul>\n\n<p><br /><br /></p>\n\n<h2 id=\"그-이후\">그 이후</h2>\n<ul>\n  <li>Lv 4. 이후엔 무엇이 있을까?란 생각을 해봤는데, <strong>Lv 5는 조직을 넘어서서 내가 속한 산업에서 사람들이 원온원을 잘 진행할 수 있게 돕는 것이란 생각했음</strong>\n    <ul>\n      <li>이 과정엔 책을 쓰는 것도 있고, 글을 쓰는 것도 있고 다양할 것 같음</li>\n    </ul>\n  </li>\n  <li>그러나 Lv 2~4도 매우 어렵기 때문에 앞선 부분에 대해 역량 상승에 집중하는 것이 필요하다고 생각함</li>\n</ul>\n\n<p><br /><br /></p>\n\n<h1 id=\"원온원-실천을-위한-구체적인-가이드\">원온원 실천을 위한 구체적인 가이드</h1>\n<h2 id=\"원온원-프로세스--어떤-흐름으로-대화하면-좋을까\">원온원 프로세스 : 어떤 흐름으로 대화하면 좋을까?</h2>\n<ul>\n  <li>이 프로세스는 제가 여러번 진행하면서 정해진 흐름입니다. 정답은 아니고 저의 흐름이라고 생각해주시면 됩니다</li>\n  <li><strong>체크인(5~10분)</strong> : 요즘 어떻게 지내는가? 요즘 기분이나 상태를 점수로 표현하면?\n    <ul>\n      <li>점수가 상승한 이유, 하락한 이유는?</li>\n    </ul>\n  </li>\n  <li><strong>대화(40분)</strong>\n    <ul>\n      <li>오늘 다루고 싶은 소재가 있는지 질문\n        <ul>\n          <li>팀원이 이야기를 하고 싶어하는 소재로 진행</li>\n        </ul>\n      </li>\n      <li>바로 답변을 주는 것보단 왜 그런지, 어떤 감정이였는지 등을 주로 물어봄</li>\n    </ul>\n  </li>\n  <li><strong>마무리(10분)</strong>\n    <ul>\n      <li>오늘 어떠했는지? 물어봄</li>\n      <li>Action Item 정하기 : 다음 원온원 주기까지 할 일 딱 1개만 정해보기. 여러개 정하는 것보다 1개만 하는 것이 좋다고 생각함</li>\n    </ul>\n  </li>\n  <li><strong>오늘 소감 작성 요청</strong>\n    <ul>\n      <li>이 부분은 선택적으로 진행하는데, <strong>특정 슬랙 채널에 오늘 대화해서 어떤 것을 느꼈고 어떤 배움이 있었는지 공유 요청함 -&gt; 다른 분들에게도 영감을 줄 수 있음</strong></li>\n      <li>원온원을 하다보면 비슷한 고민을 하는 경우가 있어서 이 내용이 계속 살아있길 바랬음. 본인이 공개하고 싶은 수준으로 정리해서(개인의 이야기는 줄이고 깨달음 위주로) 채널에 공유하면 도움이 되었음</li>\n      <li>이렇게 해서 원온원의 가치를 계속 인지할 수 있게 되었음\n        <ul>\n          <li>사람들이 어떻게 느끼는지 명시적으로 공유해서 원온원의 효과를 인지하고, 서로에게 도움을 줄 수 있는 환경 마련</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n  <li>원온원을 진행하는 회차에 따라서 내용을 다르게 전개함\n    <ul>\n      <li>1회차 땐 서로에 대한 이해</li>\n      <li>2회차 땐 회사에 잘 적응하고 있는지</li>\n      <li>그 후엔 팀원분이 하고 싶은 소재 위주</li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/e3k9kh8xxxppridwbjrcc/2024-11-24-4.37.44.png?rlkey=9c8aettjy0xxfqlb7o0r9zu44&amp;raw=1\" /></p>\n\n<p><br /></p>\n\n<h2 id=\"원온원-템플릿\">원온원 템플릿</h2>\n<ul>\n  <li>개인 정보(메타 정보) 기록 : 서로에 대해 잘 이해하기 위함</li>\n  <li>노션을 사용해서 기록도 해보고, 구글 독스로도 해봄. 길어질수록 보기 편한 것은 스프레드시트라서 스프레드시트를 사용 중</li>\n  <li>면담 템플릿은 간단하게 유지하고, 특정 시점에 하고 싶은 질문이 있다면 추가하거나 팀원이 이야기하고 싶은 소재를 위주로 전개함\n    <ul>\n      <li>생각보다 간단하게 유지함</li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/s/22nqxren9mo0hjd/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-11-24%20%EC%98%A4%ED%9B%84%202.36.14.png?raw=1\" /></p>\n\n<p><img src=\"https://www.dropbox.com/s/nnx1fancjcx78sm/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-11-24%20%EC%98%A4%ED%9B%84%202.37.44.png?raw=1\" /></p>\n\n<p><br /></p>\n\n<h2 id=\"그-외-원온원-관련-생각과-tip\">그 외 원온원 관련 생각과 TIP</h2>\n<ul>\n  <li>원온원 주기는 2주에 1번도 가능하고, 1달에 1번도 가능함\n    <ul>\n      <li>시간도 30분, 1시간 등 다양함</li>\n      <li>정답은 없고 여러번 반복하면서 최적화하는 관점이 필요함</li>\n      <li>2주는 정말 빠르게 온다고 생각해서 1달을 선택했고, 저는 30분보단 60분은 되어야 충분히 대화를 진행해서 60분으로 진행함\n        <ul>\n          <li>대화를 잘 하는 분들은 30분만에 모든 것을 진행할 수 있다고 하는데 저는 저만의 스타일로 60분을 선택</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n  <li>조직에서 겸직으로 인해 원온원을 동시에 다른 사람에게 받는 분이 있을 수 있는데, 이럴 땐 시기를 조절하려고 함. 비슷한 시기에 원온원을 하는 것보단 간격을 두고 하는 것이 좋다고 생각했음</li>\n  <li>대화 과정에서 정답을 만들지 말기\n    <ul>\n      <li><strong>가치 판단을 하는 순간 대화가 어려워질 수 있음. 가치 판단보다는 중립적인 생각을 가지며 팀원에게 관심을 갖기(왜 그렇게 생각하셨나요?)</strong></li>\n      <li>누군가가 이럴 때 그럴 수 있다, 그 사람의 맥락은 무엇인가? 물어봐야 함</li>\n      <li><strong>때론 그냥 기다리는 것도 방법. 너무 빠르게 답변을 하라고 하면 압박이 생길 수 있음</strong>. 기다리는 시간도 필요하다고 생각하기(답답해서 다른 질문으로 넘어가지 말고 팀원의 템포를 기다려주기)</li>\n    </ul>\n  </li>\n  <li><strong>너무 성장 지향적으로 이야기하는 것이 아닌 여러 관점이 있다고 이야기하기</strong>\n    <ul>\n      <li>너무 성장 성장!하는 것보단 사람마다 시기가 있고, 템포가 있으니 그렇게 가도 괜찮다고 말하는 것이 좋았음</li>\n      <li>너무 성장을 이야기하면 성장을 강요하게 되는 느낌도 들었음</li>\n    </ul>\n  </li>\n  <li><strong>원온원을 어떻게 진행하고 있는지 회고하는 것도 추천</strong>\n    <ul>\n      <li>주기적으로 내가 어떻게 하는가, 내게 원온원을 받은 분들이 어떻게 살아가는가? 고민해보기</li>\n    </ul>\n  </li>\n  <li><strong>나의 원온원 스타일 파악하기</strong>\n    <ul>\n      <li>처음엔 일반적인 원온원 스타일로 탐색했다가 점점 나만의 방식을 찾기</li>\n      <li>내가 어떤 사람과 이야기를 할 때 좋은가? 고민해보기</li>\n      <li>더 나아가서 도식화를 해도 좋음</li>\n      <li>저는 어떤 대화를 할 때, 수렴을 잘 하는 스타일. 발산을 잘하는 분이 계시다면 내가 수렴을 해서 정리해줌</li>\n    </ul>\n  </li>\n  <li><strong>너무 형식에 얽매이지 말고 유연하게 대응하기</strong>. 대화를 하다가 갑자기 더 중요하다고 생각나는 것이 있다고 하면 그 주제에 대해 다루기\n    <ul>\n      <li>어떻게 보면 메타몽처럼 상대방에 맞게 변신해서 대응하는 것</li>\n    </ul>\n  </li>\n  <li>어떤 내용에 대해서 내가 해결할 수 있는 것이 없는 경우가 있음(조직적인 구조로 인해)\n    <ul>\n      <li>이런 경우가 반복된다면 그 내용을 정리해서 상급자에게 전달하는 것도 중간 관리자의 중요한 역할이라 생각함</li>\n      <li>문제를 그냥 방치하지 말고, 어떻게든 해결하기 위한 시도를 작게라도 해보기</li>\n    </ul>\n  </li>\n</ul>\n\n<p><br /><br /></p>\n\n<h1 id=\"정리\">정리</h1>\n<ul>\n  <li>원온원에 정답이 있다기보단, 나의 스타일을 파악하고 팀원분의 이야기를 잘 들어주면서 그 사람을 잘 돕는 것이 핵심이라 생각함</li>\n  <li>처음엔 어렵지만, 원온원에 대해 계속 생각하면서 발전하면 된다고 생각</li>\n  <li>처음엔 누구나 원온원이 어려움</li>\n  <li>저도 계속 경험하면서 저만의 기준이 생기고 있는 것. 시간이 지나면서 위에 작성한 내용이 다 달라질 수도 있음</li>\n</ul>\n\n<p><br /><br /></p>\n\n<h1 id=\"참고-자료\">참고 자료</h1>\n<ul>\n  <li>김창준님, 변신철님이 주관해주신 MITI 동기 면담 워크샵\n    <ul>\n      <li>후기 : <a href=\"https://zzsza.github.io/etc/2020/08/15/miti-workshop-review/\">MITI 워크샵 후기</a></li>\n      <li>저는 김창준님, 변신철님이 운영하시는 <a href=\"https://www.ac2.kr/\">AC2</a> 과정을 수강하고 많은 깨달음을 얻었습니다. 그냥 경험하고 있던 것들을 잘 정리할 수 있는 계기가 되었습니다. 관심이 있으신 분들은 과정 살펴보시는 것도 추천해요</li>\n    </ul>\n  </li>\n  <li><a href=\"https://www.yes24.com/Product/Goods/138722152\">리더의 돕는 법</a></li>\n  <li><a href=\"https://www.amazon.com/Trust-Betrayal-Workplace-Relationships-Organization/dp/1626562571\">Trust and Betrayal in the Workplace: Building Effective Relationships in Your Organization 책</a></li>\n  <li><a href=\"https://www.yes24.com/Product/Goods/3502454\">신뢰의 속도 책</a></li>\n  <li>백종화님의 <a href=\"https://www.yes24.com/Product/Goods/128090592\">원온원 책</a></li>\n  <li><a href=\"https://www.yes24.com/Product/Goods/11520753\">상자 밖에 있는 사람 책</a></li>\n  <li><a href=\"https://github.com/raylene/eng-handbook/blob/master/management/guide-to-1-1s.md\">Guide to 1 on 1s</a></li>\n  <li><a href=\"https://github.com/VGraupera/1on1-questions\">1 on 1 Questions</a></li>\n  <li><a href=\"https://github.com/ajahne/one-on-ones\">One on Ones</a></li>\n</ul>\n\n<p><br /><br /></p>\n\n<hr />\n\n<ul>\n  <li>글 작성하는데 걸린 시간 : 7시간 3분\n    <ul>\n      <li>하고자 하는 이야기, 개요 정리 : 38분</li>\n      <li>초안 글 작성 : 1시간 35분</li>\n      <li>클로드와  셀프 글 피드백 : 40분</li>\n      <li>2차 글 작성 : 4시간 10분</li>\n    </ul>\n  </li>\n  <li>회고\n    <ul>\n      <li>처음에 목차를 생각하지 않고 경험을 다 작성하니 너무 구조화가 되지 않아 방향성을 잡기 어려웠음</li>\n      <li>클로드와 피드백을 하면서 더 괜찮은 목차를 만들며 내용을 재구성함</li>\n      <li>필요한 내용 위주로 남기고, 삭제에 집중함</li>\n      <li>Action Item\n        <ul>\n          <li>역시 처음부터 목차를 작성하는게 좋음</li>\n          <li>작성하고 싶은 모든 내용에 집중하지 말고 핵심 위주로 정리하기</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n</ul>\n\n",
        "contentSnippet": "이 글은 원온원에 대해 작성한 글입니다\n    \n6년 동안 진행한 원온원의 시행착오와 배움들을 기록했습니다\n키워드 : 원온원 미팅, 원온원 질문, 원온원 템플릿, 원온원 주제\n들어가며\n저는 3년차(2019년)에 팀장 역할을 맡으며 생각보다 빠르게 원온원을 진행해야 했습니다\n‘어떻게 해야 팀원분들과 제가 모두 만족할 수 있는 원온원을 할 수 있을까?’에 대해 계속 고민하고 여러 내용을 학습하고 다양한 시도를 하며 시행 착오를 겪었습니다\n    \n처음 원온원을 할 때를 떠올리면 막막한 감정이 있었고, 좋은 원온원 시간을 가지지 못했던 것 같아요\n좋은 원온원을 ‘팀원분이 만족스럽게 대화를 끝낼 수 있는가? 무엇을 해야할지 떠올렸는가?’로 정의했습니다\n처음 팀장을 하던 시기엔 월에 3~4명과 원온원을 하다가, 시간이 흘러 조직에서 역할이 변경되어 월에 30~40명과 원온원을 진행했습니다\n    \n그리고 요즘에도 멘토링, 회사 데이터팀 코칭, 경영진 원온원을 진행하고 있습니다\n그동안 원온원 역량 상승을 위해 시도했던 경험들에 대해 작성하려고 합니다\n참고로 초보 개발 팀장의 1년 회고 - 좋은 팀장이 되기 위한 노력들이란 글에 팀장의 역할과 제가 시도한 점들에 대해 정리했습니다\n이 글은 제 경험담을 기반으로 작성한 글이고, 이게 정답이다!라는 이야기를 하고 싶은 것이 아닙니다\n    \n앞으로도 계속 원온원을 하면서 경험이 계속 늘어날 것 같아요.\n관련 경험이나 의견 남겨주실 분이 계시다면 남겨주셔요\n\n\n\n원온원의 정의와 목적\n원온원은 단어 그대로 1:1로 이야기하는 것을 의미하며, 팀원분이 더 발전된 형태로 업무를 할 수 있도록 서로 이야기를 나누는 자리\n    \n주로 팀장님과 팀원이 일대일로 만나 이야기하는 시간\n원온원은 다양한 관점으로 진행할 수 있음\n    \n정기적인 원온원 : 주기적으로 시간을 잡아서 이야기를 하는 경우\n도움이 필요해서 요청하는 원온원 : 특정 문제에 대한 고민을 이야기하고 싶어 팀원분이 요청하는 경우\n원온원의 목적은 ‘팀원의 발전을 돕는 것’이라 생각\n    \n다양한 관점으로 이야기할 수 있는데, 저는 주로 커리어 관점, 업무 관점, 인간 관점으로 이야기(단순히 회사 한정으로만 생각하지 않음. 거시적인 그 사람의 삶에 대해 이야기)\n커리어 관점 : 팀원의 커리어를 같이 설계, 역량 개발을 어떻게 할지 이야기\n업무 관점 : 현재 진행하는 업무에 얼마나 몰입하고 있는지, 어려움이 있는지\n인간 관점 : 어떤 인생을 살고 싶은가, 스스로에 대한 메타인지\n기타 : 팀원분이 원하시는 관점이 있다면 그 관점으로 이야기\n\n\n\n원온원 역량의 발전 과정\n이해를 위해 원온원 레벨을 정의하고, 그 과정의 경험담과 시도했던 것들을 공유\n레벨은 이해를 위해 정의한 것이고, 꼭 이걸 충족해야 하는 것은 아님\n\n\n\nLv 1. 초기 : 질문 리스트에 의존한 시기\n상황(Context)\n3년차 때 팀장을 하면서 생각보다 빠른 시기에 원온원을 진행해야 했음\n처음엔 참 막막했음. 원온원을 해본 적이 없는데 어떻게 해야할까?\n그래서 일단 어떻게 질문을 해야할지 고민했음. 많은 분들이 처음 시도하면 이렇게 하실 것 같음\n구글에 1 on 1 question list, 원온원 질문, 원온원 템플릿 등을 검색하며 질문을 모았음\n경험담\n원온원 질문 리스트를 기반으로 원온원을 진행했는데, 기계적으로 하는 느낌이 들었음\n깊게 대화하는 느낌보단 체크 리스트가 있고 그걸 하나씩 물어보는 제 모습을 보게 됨\nA라는 질문에 대해 다 했으면 B로 넘어가고, B에 대해 이야기하면 C에 대해 넘어가며 겉 이야기를 계속 하는 것 같았음\n나와 팀원 둘 다에게 소모적인 시간이라고 생각했음\n이 시기의 시도\n원온원의 본질에 대해 고민함. 원온원 질문이 아닌 본질적으로 사람을 어떻게 도와야 할까?에 대한 생각을 하며 관련 서적을 많이 읽음\n그렇다면 도움을 어떻게 잘 줄 수 있을까? 도움에 대해 정의하고, 그 정의에 맞게 Action Item을 실행하기로 다짐함\n    \n이 과정에서 에드거 샤인님의 헬핑이란 책이 큰 도움이 되었음\n최근 리더의 돕는 법이란 제목으로 다시 출간되었음\n이 책을 읽고, 실제로 경험도 하면서 점점 나만의 원칙, 기준이 생겼음\n헬핑 책 외에도 도움이 되었던 것은 동기면담, 코칭, 사람 심리, 화법 학습\n    \n동기면담에 대한 내용은 MITI 동기면담 워크샵 후기 이 글에 내용을 작성했는데, 동기면담을 배우고 1 on 1을 더 잘 수행할 수 있게 됨\n동기면담은 동기를 이끌어내는 의사소통 스타일, 내담자와 상담 기록을 특정 코드로 부호화함\n면담의 효과를 평가할 수 있게 됨\n또 떠오르는 책은 상자 밖에 있는 사람\n    \n이 책을 읽고 다른 사람을 어떻게 이해해야 할지, 나의 관점으로만 생각하지 말고 다른 사람의 관점에서 생각할 수 있게 됨\n팀장을 처음 하는 분들에게 꼭 추천하는 책\n시도를 하며 깨달은 점\n    \n“어떤” 것을 질문하는 것보단 팀원을 이해하고, 팀원을 잘 돕는 것이 핵심이라 생각했음. 자주 할 수 있는 질문 리스트가 있지만 너무 질문에 얽매이지 않아도 된다는 것을 느꼈음\n팀원을 내가 어떻게 도울 수 있을까?라는 생각을 하면서 원온원을 진행하니 부담감도 줄어들고 어떻게 대화를 해야할지 떠오르게 되었음\n질문 리스트 자체보다, 질문 리스트에 작성한 사람은 왜 이 질문을 하게 되었을까?를 생각하니 도움이 되었음\n에드거 샤인님은 도움을 다음과 같이 정의함 : “도움은 한 사람이 다른 사람의 문제를 해결하거나 상황을 개선하기 위해 지식, 자원, 감정적 지지를 제공하는 사회적 상호작용 과정”\n        \n문제에 대해 초점을 맞추고 감정적 지지를 제공한다는 점을 인상 깊게 봄\n단순히 일방적인 것이 아닌 상호작용 과정이라는 것도 중요한 포인트\n\n\n\nLv 2. 본질에 집중한 시기\n상황(Context)\nLv 1의 역량 상승을 위한 시도에 나온 것처럼 본질에 집중하니, 이제 원온원 시간을 ‘팀원분은 어떤 도움이 필요할까?’를 생각하며 대화를 진행함\n마음가짐이 달라지니 저도 마음이 편해지고, 더 진심을 다할 수 있었음\n내가 말을 더 많이 하는게 아닌, 팀원분이 더 이야기를 할 수 있는 환경을 만들려고 했음\n    \n서로 이야기를 잘 진행하려면 서로에게 신뢰가 필요하다고 생각했음\n나만 이야기하는 것이 아닌, 상호작용 과정이므로 어떻게 해야 서로 잘 이야기를 할 수 있을까?도 고민함\n경험담\n팀원분이 어떤 내용을 이야기하는 것이 어려울 수 있어서 최초엔 요즘 어떤지를 물어봄\n최근 1달 동안 어떤지를 숫자로 표현해달라고 했음. 0~10점\n    \n매달 이 질문으로 시작하며 점수의 상승이 어떻게 되는지 파악함\n처음엔 단일 점수로 물어봤는데, 시간이 지나면서 개인 삶 관점과 회사 관점으로 점수를 나눠서 물어봄\n이렇게 하면 점수가 올라가거나 내려갈 때, 왜 그런지 물어볼 수 있음. 그러면 어떤 사건이 나타날 수 있고, 이야기를 전개할 때 좋은 힌트가 됨\n이 과정을 오래 반복하면(같은 분과 원온원을 1년 이상 진행하면) 점수의 상승, 하락에 대한 요인을 생각할 수 있음. 점수가 상승하거나 하락할 때는 비슷한 관점이 발견되는 경우도 있었고, 이 부분을 정리해서 공유하면 팀원분이 스스로 이 부분에 대해 인지할 수 있었음\n점수를 기록한 후, “오늘 시간에 다루고 싶은 내용이 있으신가요?”라고 질문함\n    \n팀원분이 스스로 다루고 싶은 소재에 대해 언급하고, 그 소재에 기반해 대화를 진행함\n소재가 없는 경우엔 닫힌 질문보단 열린 질문(단답이 아닌 여러 관점으로 이야기를 할 수 있는 질문)을 사용함\n서로에 대한 이해가 충분히 있을 경우, 대화가 잘 진행되는 느낌을 받음\n    \n원온원을 처음 진행할 때, 업무에 대한 내용을 이야기하는 것보다 서로에 대해 이해하는 시간을 가짐. 어떻게 살아왔는지, 어떤 사람인지 등\n물어보는 내용이 내가 경험한 내용이라면, 과거의 내 생각을 공유했음. 그 시기에 블로그에 작성한 글이 있다면 글을 공유하면서 저도 과거에 비슷한 생각을 했다고 말함\n팀원분이 원온원을 하면서 기록하느라 집중하지 못하는 경우도 있었음\n    \n저는 타자 속도가 600~800타 정도 되어서 말하면서 기록하는 것이 어렵지 않음. 그래서 아예 제가 기록을 다 하고, 팀원분은 자신의 이야기만 집중할 수 있는 환경을 마련함\n처음엔 노션 페이지를 만들고, 원온원이 끝날 때 공유하는 형태로 진행하다가 추후엔 팀원마다 스프레드시트를 만들고, 그 스프레드시트를 같이 보면서 이야기함. 이렇게 진행할 경우 팀원분이 자신의 의도가 잘 기록되었는가(=제가 제대로 이해했는가)를 빠르게 확인할 수 있어서 대화 중간에 내용을 수정함\n팀원분이 도움을 받을 준비가 되었는지도 중요했음. 도움을 받고 싶다는 생각이 없다면 잘 진행되지 않았음\n    \n이럴 땐 차라리 짧게 끝내고 추후에 고민이 있다면 말씀해달라고 요청했음\n이 시기의 시도\n신뢰란 무엇인가에 대해 고민함\n    \n어떻게 해야 신뢰를 할 수 있을까?\n신뢰에 대한 연구는 과거에 많이 진행되어 있어서, 많이 언급되는 신뢰 모델을 찾아봄\n데니스 레이나의 신뢰 모델. Trust and Betrayal in the Workplace: Building Effective Relationships in Your Organization 책\n        \n신뢰는 상호작용을 통해 형성되고, 시간을 두고 점진적으로 발전함\n신뢰의 핵심 요소\n            \n역량 신뢰(Competence Trust)\n계약적 신뢰(Contractual Trust)\n소통 신뢰(Communication Trust)\n스티븐 코비의 신뢰 모델. 신뢰의 속도 책\n        \n신뢰의 핵심 요소\n            \n성실성\n의도\n능력\n성과\n여러 관점을 보면서 나는 어떤 신뢰를 획득했을까?를 고민함\nLv 1 때 역량 상승을 위한 시도는 책이나 영상을 봤다면, 이젠 많이 시도함. 많은 경험을 쌓으려고 함\n    \n동기면담과 비폭력 대화 내용을 학습해서, 원온원을 할 때 어떤 방식으로 이야기를 전개하는지 나의 화법은 어떠했는지를 점검함\n        \n면담 내용을 기록했기에 다시 보면서 점검할 수 있었고, 가끔은 팀원에게 허락을 구해 면담 내용을 녹음하고 다시 들어보며 복기함\n다시 들어보니까 더 객관적으로 느껴지고, 아 이런 타이밍엔 이렇게 했었으면 더 좋았겠다를 기록함\n동기면담의 총점(Global Score)과 행동 점수(Behavior Counts)를 파악함\n    \n총점 : 부호를 기록하는 사람이 임상가와 내담자의 전반적인 상호작용을 5점으로 표시. 총 4가지 부분을 확인함\n        \n변화 대화 일구기(Cultivating Change Talk) : 변화의 방향으로 대화를 진행하는가?\n유지 대화 완화하기(Softening Sustain Talk) : 현 상황을 유지하는 유지 대화를 최소화\n파트너쉽(Partnership) : 동등한 파트너끼리 인터뷰하는 것처럼 행동함(상호 커뮤니케이션이 얼마나 있는지 등)\n공감(Empathy) : 면담가가 내담자의 세계관을 적극적으로 이해하고 노력하는 정도를 측정\n여기선 내가 말한 내용을 기록했지만, 동기면담을 공부하신 다른 분들과 교차 검증을 하면 좋았을 것 같음\n행동 점수(Behavior Counts)\n        \n행동 점수는 정보제공, 설득하기, 질문, 단순 반영/복합 반영, 인정하기, 협동 구하기, 자율성 강조하기, 직면 등의 요소를 확인\n자세한 내용은 MITI 워크샵 후기 글에서 확인할 수 있음\n과거에 시도했던 내용들을 복기하며 ‘어떻게 진행하자’라는 기준, 원칙을 세움\n    \n(1) 문제를 명확하게 이해하기 전에는 성급하게 이야기를 시작하지 말자\n(2) 말하는 내용이 진짜 문제인가 꼭 확인하자. 때론 진짜 문제가 숨겨진 경우가 있음\n(3) 가치 판단이라고 판단할 수 있는 표현은 피하자.\n(4) 문제 해결은 개인이 스스로 진행해야 하는 것을 언급하자\n(5) 대화가 잘 진행되지 않는 것 같으면 중간에 물어보자 : “지금 어떤 생각이 드세요?”\n(6) 마냥 잘 될것이라는 이야기만 하지 말자. 현실적으로 생각해보자\n(7) 진심을 다 하고 있다는 것을 느낄 수 있도록 집중하자\n(8) 갑자기 원온원 요청이 오면 어떻게 해서라도 시간을 확보해서 이야기\n(9) 원온원 시간엔 슬랙 알람이 오지 않도록 슬랙 아예 끄기. 집중하는 환경 만들기\n(10) 내가 이야기를 많이 하고 있는 것 같으면 멈추자(많이 하는 경우도 있겠지만)\n\n\n\nLv 3.  맥락에 기반한 개인화된 원온원을 시도한 시기\n상황(Context)\n원온원을 진행하면서 같은 질문이나 같은 반응에 대해 사람마다 다르게 반응하는 것을 느낌\n    \n사람마다 적절한 질문이 있을 수 있겠다 싶었고, 그 사람의 맥락을 잘 이해할수록 적절한 반응으로 이야기를 할 수 있었음\n마치 추천 시스템처럼 그 사람의 메타 정보를 알아두면 좋겠다 싶었음\n면담 내용을 기록하는 스프레드시트를 개선해 개인의 맥락을 기록할 수 있도록 개선함\n경험담\n여러 성격 검사 결과를 보면서 개인에 대해 이해할 수 있도록 하면서, 특정 맥락에서 어떻게 생각하는지를 파악함\n    \nMBTI, Big5, 에니어그램, 갤럽의 강점 검사 등을 토대로 이야기를 진행함. 무료로 할 수 있는 것 위주로 진행하고 유료 검사는 내 결과를 보여줌\n성격 외에 과거에 팀원이 수행한 업무, 할 수 있는 업무 종류도 기록함. 전 회사에서 했던 경험들도 알면 도움이 되는 경우도 있어서 같이 이야기함\n팀원이 생각하는 강점, 보완할 점도 이야기하고 앞으로 어떤 것을 해보고 싶은지 이야기함\n    \n어떤 경우엔 앞으로 하고 싶은 것이 없는 경우도 있는데, 그건 문제가 아니라고 답변함. 경험을 하다가 나중에 의미를 찾는 경우도 있었음\n        \n이런 경우엔 지금에 충실해서 일을 진행하자고 이야기 함\n그 외에는 어떤 상황에 동기부여를 얻는가, 스트레스를 해소하는 방법이 있는가, 멘탈 관리법 등 살면서 한번쯤 경험할 수 있는 것들에 대해 이야기 함\n이런 내용을 충분히 인지하니 팀원의 큰 방향성을 인지하며 원온원에선 미시적인 관점을 주로 이야기함\n여기서 사용한 템플릿은 아래 구체적인 가이드에 공유할 예정\n이 시기에 원온원을 해야하는 인원이 10명, 20명 이상이 되면서 “팀장의 에너지”가 굉장히 중요한 것을 깨달음\n    \n내가 에너지가 없는 상황에서 원온원을 진행하면 만족스럽지 않은 원온원이 되는 경우가 있었음\n에너지가 있는 상황을 만들고, 여유를 만들고 원온원에 참여함\n원온원 일정을 몰아서 하지 않고, 하루에 최대 2-3명만 진행하고 일정을 분산했음\n팀원분에게 “제가 어떻게 해드리면 좋을까요?”라고 질문함\n    \n어떤 분들은 같이 이야기를 하면서 정리를 해주세요도 있고, 어떤 분들은 구체적인 피드백을 요청하는 경우도 있음\n고민에 대해서 이야기하기 전에 “이 대화가 잘 끝나면 어떤 모습이면 좋겠어요?”라는 질문을 하면서 상상하고, 그 상상을 실현하기 위해 제가 어떻게 해볼까요?라는 질문을 하기도 함. 때론 직접적으로 물어보는 것보다 이렇게 말하는 것이 효과적이였음\n이 시기의 시도\n원온원을 해야하는 분들이 많아져서 내가 반복해서 사용하는 시간이 늘어남(=운영 리소스 증가)\n    \n예를 들어 개인마다 스프레드시트를 따로 관리해서 새로운 탭을 추가해야 했음\n이걸 한번에 할 수 있게 템플릿 시트를 만들고, Apps Script를 사용해 여러 스프레드시트에 일괄적으로 반영하도록 개발함\n간단하게 URL 시트에 개인 별로 스프레드시트 URL을 저장하고, 면담 템플릿을 복사해서 개인 별 스프레드시트에 들어가서 복사하도록 구현함\n여유를 가진 상태로 원온원에 참여하도록 일정을 조정하고, 1회 일정이 아닌 반복된 일정을 추가함\n    \n나중에 하시죠!라고 하면 까먹는 경우가 많아서 반복해서 했음\n하루에 최대 2-3명을 진행하고 원온원 직전엔 30분 정도 버퍼 시간을 두고 과거에 작성한 내용을 읽고 들어감\n과거에 했던 이야기가 반복되면 ‘오 그거 몇달 전에 이야기한 내용과 유사하네요’라고 말해줌\n사람마다 다 생각하는 것이 다르다고 생각하고, 어떤 일에 정답은 없다는 것을 항상 생각했음\n\n\n\nLv 4. 조직 전체의 원온원 프레임워크 개발\n상황(Context)\n팀장에서 상위의 조직장 역할을 하면서, 팀장님들이 원온원을 잘 진행할 수 있도록 돕는게 중요하다고 생각했음\n내가 인지하는 원온원 프레임워크를 만들어도, 이 내용을 팀장님들에게 잘 전이하는 것이 중요함\n그러나 과거 경험이 다 다르기 때문에 어떻게 해야할지 고민함\n    \n나만의 프레임워크를 정리하면서, 일단 팀장님과 리더십 원온원을 진행함\n팀장님의 원온원 면담이나 팀장 역할을 하면서 하는 고민들에 대해 이야기를 나눔\n그러면서 팀장님의 리더십을 개발할 수 있도록 도움\n이 부분에 대한 것은 경영진분들과 컨설팅, 코칭을 할 때 필요한 것을 느낌\n경험담\n팀장님의 경험담을 잘 정리하고, 팀장님마다 고유한 리더십 역량을 개발하도록 도움\n    \n앞서 팀장님도 과거 원온원을 통해 개인에 대한 이해를 서로 진행한 경우가 많아 이 부분이 수월하게 진행되었음\n조직의 특성도 고려하는 것이 필요함\n    \n개발 조직과 데이터, AI 조직의 지향점이 다를 수 있고 데이터, AI 조직도 회사마다 다양할 수 있음\n우리 조직의 특성을 충분히 고민하고 어떻게 이야기를 하는게 좋은지 작성하는게 필요함(대표적인 예시 : 우리가 정의하는 좋은 원온원은?)\n원온원 프레임워크를 만드는 것도 중요하지만, 이 프레임워크가 왜 만들어졌는지까지 인지하게 하는 것이 중요함\n    \n그 과정에서 팀장 워크샵 등을 진행하는 것이 필요하고, 어떻게 이 내용을 잘 전이할까?가 더 중요한 요소라 생각함\n이 때 커리어 프레임워크을 보면서 참고함. 원온원 프레임워크와 다르지만 커리어 프레임워크처럼 기대하는 부분을 명확히 하면 좋을까?란 생각을 했음. 이 부분에 대해서는 아직 계속 개선하고 있는 중. 이런 부분에 대해 이야기를 같이 하실 분이 있다면 이야기 나눠보고 싶네요\n    \n드랍박스의 커리어 프레임워크\n\n\n\n그 이후\nLv 4. 이후엔 무엇이 있을까?란 생각을 해봤는데, Lv 5는 조직을 넘어서서 내가 속한 산업에서 사람들이 원온원을 잘 진행할 수 있게 돕는 것이란 생각했음\n    \n이 과정엔 책을 쓰는 것도 있고, 글을 쓰는 것도 있고 다양할 것 같음\n그러나 Lv 2~4도 매우 어렵기 때문에 앞선 부분에 대해 역량 상승에 집중하는 것이 필요하다고 생각함\n\n\n\n원온원 실천을 위한 구체적인 가이드\n원온원 프로세스 : 어떤 흐름으로 대화하면 좋을까?\n이 프로세스는 제가 여러번 진행하면서 정해진 흐름입니다. 정답은 아니고 저의 흐름이라고 생각해주시면 됩니다\n체크인(5~10분) : 요즘 어떻게 지내는가? 요즘 기분이나 상태를 점수로 표현하면?\n    \n점수가 상승한 이유, 하락한 이유는?\n대화(40분)\n    \n오늘 다루고 싶은 소재가 있는지 질문\n        \n팀원이 이야기를 하고 싶어하는 소재로 진행\n바로 답변을 주는 것보단 왜 그런지, 어떤 감정이였는지 등을 주로 물어봄\n마무리(10분)\n    \n오늘 어떠했는지? 물어봄\nAction Item 정하기 : 다음 원온원 주기까지 할 일 딱 1개만 정해보기. 여러개 정하는 것보다 1개만 하는 것이 좋다고 생각함\n오늘 소감 작성 요청\n    \n이 부분은 선택적으로 진행하는데, 특정 슬랙 채널에 오늘 대화해서 어떤 것을 느꼈고 어떤 배움이 있었는지 공유 요청함 -> 다른 분들에게도 영감을 줄 수 있음\n원온원을 하다보면 비슷한 고민을 하는 경우가 있어서 이 내용이 계속 살아있길 바랬음. 본인이 공개하고 싶은 수준으로 정리해서(개인의 이야기는 줄이고 깨달음 위주로) 채널에 공유하면 도움이 되었음\n이렇게 해서 원온원의 가치를 계속 인지할 수 있게 되었음\n        \n사람들이 어떻게 느끼는지 명시적으로 공유해서 원온원의 효과를 인지하고, 서로에게 도움을 줄 수 있는 환경 마련\n원온원을 진행하는 회차에 따라서 내용을 다르게 전개함\n    \n1회차 땐 서로에 대한 이해\n2회차 땐 회사에 잘 적응하고 있는지\n그 후엔 팀원분이 하고 싶은 소재 위주\n\n\n원온원 템플릿\n개인 정보(메타 정보) 기록 : 서로에 대해 잘 이해하기 위함\n노션을 사용해서 기록도 해보고, 구글 독스로도 해봄. 길어질수록 보기 편한 것은 스프레드시트라서 스프레드시트를 사용 중\n면담 템플릿은 간단하게 유지하고, 특정 시점에 하고 싶은 질문이 있다면 추가하거나 팀원이 이야기하고 싶은 소재를 위주로 전개함\n    \n생각보다 간단하게 유지함\n\n\n\n그 외 원온원 관련 생각과 TIP\n원온원 주기는 2주에 1번도 가능하고, 1달에 1번도 가능함\n    \n시간도 30분, 1시간 등 다양함\n정답은 없고 여러번 반복하면서 최적화하는 관점이 필요함\n2주는 정말 빠르게 온다고 생각해서 1달을 선택했고, 저는 30분보단 60분은 되어야 충분히 대화를 진행해서 60분으로 진행함\n        \n대화를 잘 하는 분들은 30분만에 모든 것을 진행할 수 있다고 하는데 저는 저만의 스타일로 60분을 선택\n조직에서 겸직으로 인해 원온원을 동시에 다른 사람에게 받는 분이 있을 수 있는데, 이럴 땐 시기를 조절하려고 함. 비슷한 시기에 원온원을 하는 것보단 간격을 두고 하는 것이 좋다고 생각했음\n대화 과정에서 정답을 만들지 말기\n    \n가치 판단을 하는 순간 대화가 어려워질 수 있음. 가치 판단보다는 중립적인 생각을 가지며 팀원에게 관심을 갖기(왜 그렇게 생각하셨나요?)\n누군가가 이럴 때 그럴 수 있다, 그 사람의 맥락은 무엇인가? 물어봐야 함\n때론 그냥 기다리는 것도 방법. 너무 빠르게 답변을 하라고 하면 압박이 생길 수 있음. 기다리는 시간도 필요하다고 생각하기(답답해서 다른 질문으로 넘어가지 말고 팀원의 템포를 기다려주기)\n너무 성장 지향적으로 이야기하는 것이 아닌 여러 관점이 있다고 이야기하기\n    \n너무 성장 성장!하는 것보단 사람마다 시기가 있고, 템포가 있으니 그렇게 가도 괜찮다고 말하는 것이 좋았음\n너무 성장을 이야기하면 성장을 강요하게 되는 느낌도 들었음\n원온원을 어떻게 진행하고 있는지 회고하는 것도 추천\n    \n주기적으로 내가 어떻게 하는가, 내게 원온원을 받은 분들이 어떻게 살아가는가? 고민해보기\n나의 원온원 스타일 파악하기\n    \n처음엔 일반적인 원온원 스타일로 탐색했다가 점점 나만의 방식을 찾기\n내가 어떤 사람과 이야기를 할 때 좋은가? 고민해보기\n더 나아가서 도식화를 해도 좋음\n저는 어떤 대화를 할 때, 수렴을 잘 하는 스타일. 발산을 잘하는 분이 계시다면 내가 수렴을 해서 정리해줌\n너무 형식에 얽매이지 말고 유연하게 대응하기. 대화를 하다가 갑자기 더 중요하다고 생각나는 것이 있다고 하면 그 주제에 대해 다루기\n    \n어떻게 보면 메타몽처럼 상대방에 맞게 변신해서 대응하는 것\n어떤 내용에 대해서 내가 해결할 수 있는 것이 없는 경우가 있음(조직적인 구조로 인해)\n    \n이런 경우가 반복된다면 그 내용을 정리해서 상급자에게 전달하는 것도 중간 관리자의 중요한 역할이라 생각함\n문제를 그냥 방치하지 말고, 어떻게든 해결하기 위한 시도를 작게라도 해보기\n\n\n\n정리\n원온원에 정답이 있다기보단, 나의 스타일을 파악하고 팀원분의 이야기를 잘 들어주면서 그 사람을 잘 돕는 것이 핵심이라 생각함\n처음엔 어렵지만, 원온원에 대해 계속 생각하면서 발전하면 된다고 생각\n처음엔 누구나 원온원이 어려움\n저도 계속 경험하면서 저만의 기준이 생기고 있는 것. 시간이 지나면서 위에 작성한 내용이 다 달라질 수도 있음\n\n\n\n참고 자료\n김창준님, 변신철님이 주관해주신 MITI 동기 면담 워크샵\n    \n후기 : MITI 워크샵 후기\n저는 김창준님, 변신철님이 운영하시는 AC2 과정을 수강하고 많은 깨달음을 얻었습니다. 그냥 경험하고 있던 것들을 잘 정리할 수 있는 계기가 되었습니다. 관심이 있으신 분들은 과정 살펴보시는 것도 추천해요\n리더의 돕는 법\nTrust and Betrayal in the Workplace: Building Effective Relationships in Your Organization 책\n신뢰의 속도 책\n백종화님의 원온원 책\n상자 밖에 있는 사람 책\nGuide to 1 on 1s\n1 on 1 Questions\nOne on Ones\n\n\n\n\n\n\n  \n글 작성하는데 걸린 시간 : 7시간 3분\n    \n하고자 하는 이야기, 개요 정리 : 38분\n초안 글 작성 : 1시간 35분\n클로드와  셀프 글 피드백 : 40분\n2차 글 작성 : 4시간 10분\n회고\n    \n처음에 목차를 생각하지 않고 경험을 다 작성하니 너무 구조화가 되지 않아 방향성을 잡기 어려웠음\n클로드와 피드백을 하면서 더 괜찮은 목차를 만들며 내용을 재구성함\n필요한 내용 위주로 남기고, 삭제에 집중함\nAction Item\n        \n역시 처음부터 목차를 작성하는게 좋음\n작성하고 싶은 모든 내용에 집중하지 말고 핵심 위주로 정리하기",
        "guid": "https://zzsza.github.io/diary/2024/11/24/one-on-ones-lessons-learned/",
        "categories": [
          "diary",
          "diary"
        ],
        "isoDate": "2024-11-24T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "비트액스 채굴 성공 사례 / Bitaxe",
        "link": "http://serverdown.tistory.com/1002",
        "pubDate": "Mon, 25 Nov 2024 09:52:42 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1002#entry1002comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=gNRD1r7kbRA&amp;t=5s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=gNRD1r7kbRA&amp;t=5s</a></p>\n<p data-ke-size=\"size16\">화면에 표시가 되네요</p>\n<p data-ke-size=\"size16\">잘 볼 수 없는 현상이라 가져왔습니다.</p>\n<p data-ke-size=\"size16\">CK Pool 은 당첨되면 수수료 떼고 자동으로 넣어주는걸로 알고 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=gNRD1r7kbRA&t=5s\n화면에 표시가 되네요\n잘 볼 수 없는 현상이라 가져왔습니다.\nCK Pool 은 당첨되면 수수료 떼고 자동으로 넣어주는걸로 알고 있습니다.",
        "guid": "http://serverdown.tistory.com/1002",
        "categories": [
          "투자",
          "bitaxe",
          "비트액스",
          "오블완",
          "채굴",
          "티스토리챌린지"
        ],
        "isoDate": "2024-11-25T00:52:42.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "홀수해에는 한국입니다. / 코스피 / 코스닥",
        "link": "http://serverdown.tistory.com/1001",
        "pubDate": "Mon, 25 Nov 2024 00:30:26 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1001#entry1001comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=i_ysw-mVoR4\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=i_ysw-mVoR4</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=i_ysw-mVoR4\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cU5hDM/hyXDlkymzH/r3ulV0GGXpx4XmLH2hgcbK/img.jpg?width=1280&amp;height=720&amp;face=868_132_972_246,https://scrap.kakaocdn.net/dn/tagBQ/hyXzSqFNWk/qw1glQXPPkDOp0uocyYtXk/img.jpg?width=1280&amp;height=720&amp;face=868_132_972_246\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"1351. 2025년 코스피 3000 간다, 당신만 모른다!\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/i_ysw-mVoR4\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">할투 채널에서는 언제나 통계적인 분석을 내놓습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">다시 홀수해가 왔습니다.</p>\n<p data-ke-size=\"size16\">그리고 어김없이 홀수해가 오면 한국을 추천합니다.</p>\n<p data-ke-size=\"size16\">주가라는게 항상 떨어질 순 없습니다.</p>\n<p data-ke-size=\"size16\">바닥을치면 멋진 반등이 일어날 수 있습니다.</p>\n<p data-ke-size=\"size16\">급락과 급등은 같이 옵니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">7분40초 - 국장이 오른다고하면 매국노 쌍놈 소리를 들을 수 있습니다.</p>\n<p data-ke-size=\"size16\">8분25초 - 그러나 한국주식은 홀수, 홀수해</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">코인을 놓치신분은 이번귀해에 한국주시에...</p>\n<p data-ke-size=\"size16\">개별주 힘드시면 코스피 코스닥 레버리지도 좋습니다. 3-4월에 내리세요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이차전지쪽에 관심이 있으시다면 아래의 종목을 유심히 봐주세요</p>\n<p data-ke-size=\"size16\">에코프로비엠<br />덕산테코피아<br />엔켐<br />SKC</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">그리고 금양</h2>\n<p data-ke-size=\"size16\">금양은 베터리양산 뉴스가 나오면다면 반드시 올라타셔야합니다.<br />온갖 나쁜 뉴스로 주가가 엉망이된 기업입니다.</p>\n<p data-ke-size=\"size16\">언론에서는 사기 회사로 찍어버렸고 맹공격을 펼쳤습니다.<br />2차전지 양산 못할꺼라는 비관적인 평가를 받고있습니다.</p>\n<p data-ke-size=\"size16\">콩고 / 몽골 광산등에도 불신의 목소리가 강합니다.</p>\n<p data-ke-size=\"size16\">제 생각으론 이런 불신들을 회사가 깨부숴주면 크게 갈 수 있을 것으로 보입니다.</p>\n<p data-ke-size=\"size16\">지금 사라고 하기엔 저도 좀 확신이 없어서 ...<br />기사로 확인될 때마다 추매 하는게 좋을꺼 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=i_ysw-mVoR4\n\n\n\n할투 채널에서는 언제나 통계적인 분석을 내놓습니다.\n \n다시 홀수해가 왔습니다.\n그리고 어김없이 홀수해가 오면 한국을 추천합니다.\n주가라는게 항상 떨어질 순 없습니다.\n바닥을치면 멋진 반등이 일어날 수 있습니다.\n급락과 급등은 같이 옵니다.\n \n7분40초 - 국장이 오른다고하면 매국노 쌍놈 소리를 들을 수 있습니다.\n8분25초 - 그러나 한국주식은 홀수, 홀수해\n \n코인을 놓치신분은 이번귀해에 한국주시에...\n개별주 힘드시면 코스피 코스닥 레버리지도 좋습니다. 3-4월에 내리세요\n \n이차전지쪽에 관심이 있으시다면 아래의 종목을 유심히 봐주세요\n에코프로비엠\n덕산테코피아\n엔켐\nSKC\n \n그리고 금양\n금양은 베터리양산 뉴스가 나오면다면 반드시 올라타셔야합니다.\n온갖 나쁜 뉴스로 주가가 엉망이된 기업입니다.\n언론에서는 사기 회사로 찍어버렸고 맹공격을 펼쳤습니다.\n2차전지 양산 못할꺼라는 비관적인 평가를 받고있습니다.\n콩고 / 몽골 광산등에도 불신의 목소리가 강합니다.\n제 생각으론 이런 불신들을 회사가 깨부숴주면 크게 갈 수 있을 것으로 보입니다.\n지금 사라고 하기엔 저도 좀 확신이 없어서 ...\n기사로 확인될 때마다 추매 하는게 좋을꺼 같습니다.",
        "guid": "http://serverdown.tistory.com/1001",
        "categories": [
          "투자"
        ],
        "isoDate": "2024-11-24T15:30:26.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "사건사고 / 아파트 거실의 대형 어항 파손 사건의 결말",
        "link": "http://serverdown.tistory.com/1000",
        "pubDate": "Sun, 24 Nov 2024 23:29:39 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1000#entry1000comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=RmXCdn54EB8\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=RmXCdn54EB8</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=RmXCdn54EB8\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/dfoHWF/hyXDiVD2L3/qqWLsUjv0jV9hbd4nuToB1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/c8fnbH/hyXDbWwepZ/CEFflXt8eaLCBlC0FNiIkk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"[단독] 2m 초대형 어항 \" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/RmXCdn54EB8\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">집에 대형어항을 설치했습니다.&nbsp;</p>\n<p data-ke-size=\"size16\">아주 근사해보입니다.</p>\n<p data-ke-size=\"size16\">그리곤 터졌죠 물고기는 전멸 한 사건입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">결론 영상: <a href=\"https://www.youtube.com/watch?v=lGD6h6eQ_kE\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=lGD6h6eQ_kE</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=lGD6h6eQ_kE\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cTTzJ3/hyXDldLLDl/fU6JP8gV0RJyzbi3NbQNzk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/bEg0xy/hyXC86zm5g/djqD5C0zpNlTuViQgqWBuK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"드디어 판결나왔네요. 우리가 몰랐던 가정집 어항 폭발 사건의 전말과 결과\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/lGD6h6eQ_kE\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">업체가 승리하였습니다.</p>\n<p data-ke-size=\"size16\">집 소유자 말만 들으면 안된다는 것을 깨닳았습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">1. 설치후 1년반이 지났다.<br />2. 아파트 바닥이 2cm 정도 내려 앉았다. (이거 개심각)<br />3. 업체는 위험하다고 알렸으나 집주인은 \"괜찮겠죠\" 라고 넘어가버렸군요.<br />&nbsp; &nbsp; &nbsp;(검나 약하게 알려줬습니다. 내일당장 문제가 될꺼라고 호통을 쳐야할 판에)</p>\n<p data-ke-size=\"size16\">이런 조건들이 추가로 있었구요.<br />뉴스에는 객관정인 정보 없이 억울함을 호소 합니다.</p>\n<p data-ke-size=\"size16\">저도 이것만 봤을땐 와 억울 하겠다. 생각했었는데.</p>\n<p data-ke-size=\"size16\">그럼 그러치 였습니다.</p>\n<p data-ke-size=\"size16\">어항 파손의 전말은 아파트에 버틸수 없을 만큼의 어항을 집안에 설치했구요<br />그것 때문에 바닥이 조금씩 내려와 기울어진거 같습니다.</p>\n<p data-ke-size=\"size16\">집주인은 뒷면이 기울어졌는데 앞면이 터졌으니 어항 불량이라고 하는데<br />이것은 비과학적인 추측이며 어드 곳이 터지든 상관 없는 상태였습니다.</p>\n<p data-ke-size=\"size16\">어항 업체의 문제는 돈 준다고 좋다고 설치해줬다는거 정도 인거 같습니다.</p>\n<p data-ke-size=\"size16\">엉망진창인 사건이였습니다<br />과학적 사고가 필요하다는 것을 알았습니다.</p>\n<p data-ke-size=\"size16\">그리오 언제나 자신들이 유리한 내용만 뉴스에 나온단 것을 다시한번 깨닳았습니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=RmXCdn54EB8\n\n\n\n \n집에 대형어항을 설치했습니다. \n아주 근사해보입니다.\n그리곤 터졌죠 물고기는 전멸 한 사건입니다.\n \n결론 영상: https://www.youtube.com/watch?v=lGD6h6eQ_kE\n\n\n\n \n업체가 승리하였습니다.\n집 소유자 말만 들으면 안된다는 것을 깨닳았습니다.\n \n1. 설치후 1년반이 지났다.\n2. 아파트 바닥이 2cm 정도 내려 앉았다. (이거 개심각)\n3. 업체는 위험하다고 알렸으나 집주인은 \"괜찮겠죠\" 라고 넘어가버렸군요.\n     (검나 약하게 알려줬습니다. 내일당장 문제가 될꺼라고 호통을 쳐야할 판에)\n이런 조건들이 추가로 있었구요.\n뉴스에는 객관정인 정보 없이 억울함을 호소 합니다.\n저도 이것만 봤을땐 와 억울 하겠다. 생각했었는데.\n그럼 그러치 였습니다.\n어항 파손의 전말은 아파트에 버틸수 없을 만큼의 어항을 집안에 설치했구요\n그것 때문에 바닥이 조금씩 내려와 기울어진거 같습니다.\n집주인은 뒷면이 기울어졌는데 앞면이 터졌으니 어항 불량이라고 하는데\n이것은 비과학적인 추측이며 어드 곳이 터지든 상관 없는 상태였습니다.\n어항 업체의 문제는 돈 준다고 좋다고 설치해줬다는거 정도 인거 같습니다.\n엉망진창인 사건이였습니다\n과학적 사고가 필요하다는 것을 알았습니다.\n그리오 언제나 자신들이 유리한 내용만 뉴스에 나온단 것을 다시한번 깨닳았습니다.",
        "guid": "http://serverdown.tistory.com/1000",
        "categories": [
          "유튜브"
        ],
        "isoDate": "2024-11-24T14:29:39.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "익스팬스 요약 / 미드 / SF",
        "link": "http://serverdown.tistory.com/999",
        "pubDate": "Sun, 24 Nov 2024 23:02:53 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/999#entry999comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=yW4Mp13acMo&amp;list=WL&amp;index=3\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=yW4Mp13acMo&amp;list=WL&amp;index=3</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=yW4Mp13acMo\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/jcGcB/hyXDgQ2I7x/rmhIy8pOagbXg4mDQcfnU0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/zx4Da/hyXDj1iWMm/KdCiCJDi3kXUlti7EvYB4k/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"총 제작비 6000억, 우주판 반지의 제왕이라 불리는 하드SF 드라마《익스팬스》시즌 1-6 결말까지 \" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/yW4Mp13acMo\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">재밌고를 떠나서 너무 깁니다.</p>\n<p data-ke-size=\"size16\">시즌6 ㄷㄷㄷ</p>\n<p data-ke-size=\"size16\">요약된걸로 때워봅니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">지구와 화성에 인류가 살고 있으며</p>\n<p data-ke-size=\"size16\">우주로 점점 식민지를 늘려가는 상태입니다.</p>\n<p data-ke-size=\"size16\">화성이 지구를 지배하려고 여러 무기와 생화학무기를 준비했고 조금씩 공격 들어가는 시점에서 드라마가 시작합니다.</p>\n<p data-ke-size=\"size16\">여러가지 우주 과학 지식도 나오고 재미는 있지만</p>\n<p data-ke-size=\"size16\">다 보기엔 쉽지 않습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=yW4Mp13acMo&list=WL&index=3\n\n\n\n재밌고를 떠나서 너무 깁니다.\n시즌6 ㄷㄷㄷ\n요약된걸로 때워봅니다.\n \n지구와 화성에 인류가 살고 있으며\n우주로 점점 식민지를 늘려가는 상태입니다.\n화성이 지구를 지배하려고 여러 무기와 생화학무기를 준비했고 조금씩 공격 들어가는 시점에서 드라마가 시작합니다.\n여러가지 우주 과학 지식도 나오고 재미는 있지만\n다 보기엔 쉽지 않습니다.",
        "guid": "http://serverdown.tistory.com/999",
        "categories": [
          "유튜브",
          "SF",
          "미드",
          "오블완",
          "티스토리챌린지"
        ],
        "isoDate": "2024-11-24T14:02:53.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "기업살인과 댓글부대 / PD수첩 / 선동 하는 방법",
        "link": "http://serverdown.tistory.com/998",
        "pubDate": "Sat, 23 Nov 2024 04:13:44 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/998#entry998comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=BgBLY1B2irk\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=BgBLY1B2irk</a></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=BgBLY1B2irk\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/BzzzQ/hyXzPmZmBG/SyT5pWuvD7ft2zMl8MP5K0/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360,https://scrap.kakaocdn.net/dn/chrXsZ/hyXDgJYaEH/pFoxxcAjKX8WQrAdP4MQ11/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360\" data-video-width=\"480\" data-video-height=\"360\" data-video-origin-width=\"480\" data-video-origin-height=\"360\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"[PD수첩] 기업살인과 댓글부대 - 2024년 4월 2일 밤 9시\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/BgBLY1B2irk\" width=\"480\" height=\"360\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">경쟁 기업이 여러가지를 조작했군요.</p>\n<p data-ke-size=\"size16\">여기서 알 수 있는 사실은</p>\n<p data-ke-size=\"size16\">댓글을 1년 조작하는데는 2,500만원 정도들고</p>\n<p data-ke-size=\"size16\">맘카페를 조작하면 경쟁자를 제거할 수 있군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">예전 회사에서 신사업으로 키드 레스토랑 카페를 하려고 했는데</p>\n<p data-ke-size=\"size16\">1년쯤 하니까 이상한 일이 마구 생기더군요.</p>\n<p data-ke-size=\"size16\">아이가 레스토랑에서 다쳤다던지 (그날도 아니고 아니고 다음날 와서)<br />먹고 배탈 나싸던지&nbsp; (혼자만)</p>\n<p data-ke-size=\"size16\">탕시엔 cctv 같은게 없었는데 지금 생각해보면 정말 이상한 현상이였는데<br />몇년 지나보니 경쟁사에서 공격한거 같다는 소문이 있었습니다.</p>\n<p data-ke-size=\"size16\">아무튼 신사업은 1년 더하고 접었던걸로 기억납니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상 마지막엔 법으로 어쩌구 하는데</p>\n<p data-ke-size=\"size16\">매번드는 생각이 법이 없어서 이런일이 난게 아닙니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">제 시간 내에 처리되지 않아서 일이 커지는걸 막을 수 없었던 것입니다.</p>\n<p data-ke-size=\"size16\">믿었던 인증 기관은 공작에 당해 인증을 취소하질 않나.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">PD 수첩은 매번 법을 어쩌구 하는데</p>\n<p data-ke-size=\"size16\">제 경험상 이말은 \"안될껄?\" 이라는 듯 입니다.<br />단지 마지막에 훈훈하게 끝내고 싶었던 것이겠죠..</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"676\" data-origin-height=\"199\"><span data-url=\"https://blog.kakaocdn.net/dn/dzftVL/btsKVyXten4/bHAXzqv0bebWqI3PkqHrxK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dzftVL/btsKVyXten4/bHAXzqv0bebWqI3PkqHrxK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dzftVL/btsKVyXten4/bHAXzqv0bebWqI3PkqHrxK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdzftVL%2FbtsKVyXten4%2FbHAXzqv0bebWqI3PkqHrxK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"676\" data-origin-height=\"199\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">올해 제가 당했던 인버스 사건입니다.</p>\n<p data-ke-size=\"size16\">금투세가 주식시장을 약화시기고 있는 가운데 굳이 \"우린 세금 겆을 것이다., 떨어질꺼 같으면 인버스 사라\" 라고 한 사건입니다.&nbsp;</p>\n<p data-ke-size=\"size16\">모든것은 본인들이 이기기위해 무엇이든 한다는 것입니다. <br />그것이 나라 팔아먹는 일이라도 이기는 것이 중요하기 때문입니다. <br />그것이 국회의원이라도 다르지 않았던거 같습니다.</p>\n<p data-ke-size=\"size16\">결국 단기적으로는 저 시점으로 해서 인버스를 사는게 맞았습니다.<br />코인과 미국 주식을 사는게 맞았던 것이죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">목적이 분명한 사람의 행동은 놀랍도록 강력합니다.</p>\n<p data-ke-size=\"size16\">그게 좋은일이 아니더라도 ...</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=BgBLY1B2irk\n \n\n\n\n경쟁 기업이 여러가지를 조작했군요.\n여기서 알 수 있는 사실은\n댓글을 1년 조작하는데는 2,500만원 정도들고\n맘카페를 조작하면 경쟁자를 제거할 수 있군요\n \n예전 회사에서 신사업으로 키드 레스토랑 카페를 하려고 했는데\n1년쯤 하니까 이상한 일이 마구 생기더군요.\n아이가 레스토랑에서 다쳤다던지 (그날도 아니고 아니고 다음날 와서)\n먹고 배탈 나싸던지  (혼자만)\n탕시엔 cctv 같은게 없었는데 지금 생각해보면 정말 이상한 현상이였는데\n몇년 지나보니 경쟁사에서 공격한거 같다는 소문이 있었습니다.\n아무튼 신사업은 1년 더하고 접었던걸로 기억납니다.\n \n영상 마지막엔 법으로 어쩌구 하는데\n매번드는 생각이 법이 없어서 이런일이 난게 아닙니다.\n \n제 시간 내에 처리되지 않아서 일이 커지는걸 막을 수 없었던 것입니다.\n믿었던 인증 기관은 공작에 당해 인증을 취소하질 않나.\n \nPD 수첩은 매번 법을 어쩌구 하는데\n제 경험상 이말은 \"안될껄?\" 이라는 듯 입니다.\n단지 마지막에 훈훈하게 끝내고 싶었던 것이겠죠..\n \n\n\n올해 제가 당했던 인버스 사건입니다.\n금투세가 주식시장을 약화시기고 있는 가운데 굳이 \"우린 세금 겆을 것이다., 떨어질꺼 같으면 인버스 사라\" 라고 한 사건입니다. \n모든것은 본인들이 이기기위해 무엇이든 한다는 것입니다. \n그것이 나라 팔아먹는 일이라도 이기는 것이 중요하기 때문입니다. \n그것이 국회의원이라도 다르지 않았던거 같습니다.\n결국 단기적으로는 저 시점으로 해서 인버스를 사는게 맞았습니다.\n코인과 미국 주식을 사는게 맞았던 것이죠.\n \n목적이 분명한 사람의 행동은 놀랍도록 강력합니다.\n그게 좋은일이 아니더라도 ...",
        "guid": "http://serverdown.tistory.com/998",
        "categories": [
          "유튜브",
          "선동",
          "오블완",
          "조작",
          "티스토리챌린지"
        ],
        "isoDate": "2024-11-22T19:13:44.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "삼국지 납득이 된다 / 신해석 삼국지 / 일본 / 영화",
        "link": "http://serverdown.tistory.com/997",
        "pubDate": "Fri, 22 Nov 2024 18:19:50 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/997#entry997comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=go62t6k_SyU&amp;t=59s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=go62t6k_SyU&amp;t=59s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=go62t6k_SyU\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bLDJvf/hyXzIagh4x/Avyun9KZbq5wi1leAi6JN1/img.jpg?width=1280&amp;height=720&amp;face=238_254_730_590,https://scrap.kakaocdn.net/dn/cmBYUd/hyXDhoxMZJ/vzy2jivI4hcQxjlFlkIXk0/img.jpg?width=1280&amp;height=720&amp;face=238_254_730_590\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"약빨고 B급으로 만든 코미디 인 줄 알았는데 ㅋㅋㅋ 의외로 말이 되는 느낌의 니뽄 삼국지\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/go62t6k_SyU\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">넷플리스에 있다구</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=go62t6k_SyU&t=59s\n\n\n\n넷플리스에 있다구",
        "guid": "http://serverdown.tistory.com/997",
        "categories": [
          "유튜브",
          "일드"
        ],
        "isoDate": "2024-11-22T09:19:50.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "맛탱이가 간 두개의 코인을 사서 묵혀두자 / LUNC / FTT",
        "link": "http://serverdown.tistory.com/996",
        "pubDate": "Fri, 22 Nov 2024 13:55:02 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/996#entry996comment",
        "content": "<p data-ke-size=\"size16\">주요 메이저 종목은 비트코인, 리플, 도지코인 입니다.</p>\n<p data-ke-size=\"size16\">수익이 나셨다면 맛탱이가 간 코인들을 조금 사모아요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=3Yg7AQ_QYfs\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=3Yg7AQ_QYfs</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=3Yg7AQ_QYfs\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cDjrdD/hyXDdfj3VH/LmoFdKBz6DUgxuaBIJryU1/img.jpg?width=480&amp;height=360&amp;face=385_210_430_259,https://scrap.kakaocdn.net/dn/bK0ELk/hyXDgb2BVT/QSlpj8R0eyyUtVjzH1IZmK/img.jpg?width=480&amp;height=360&amp;face=385_210_430_259\" data-video-width=\"480\" data-video-height=\"360\" data-video-origin-width=\"480\" data-video-origin-height=\"360\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"권도형은 도대체 왜 몬테네그로에서 나오지 못하고 있는가\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/3Yg7AQ_QYfs\" width=\"480\" height=\"360\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">영상은 업비트 재상장인데 이런 맛탱이간 뉴스가 압니다.</p>\n<p data-ke-size=\"size16\">이분은 예전부터 루나 클래식을 부르짓었습니다.</p>\n<p data-ke-size=\"size16\">제가 찾아온 코인은 LUNC / FTT 입니다.</p>\n<p data-ke-size=\"size16\">LUNC 는 2년전에 망한 루나사태의 그 코인의 다음버전입니다. 원본은 완전 망해서 없어졌습니다.</p>\n<p data-ke-size=\"size16\">그리고 FTT 는 FTX 사태로 망한 그 거래소의 지분을 상징하는 코인입니다.</p>\n<p data-ke-size=\"size16\">이 두개는 망한 채권 같은것입니다.</p>\n<p data-ke-size=\"size16\">그만큼 가격이 떨어져있구요</p>\n<p data-ke-size=\"size16\">이게 왜 오르냐 한다면</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">LUNC <span style=\"text-align: start;\"><span>&nbsp;</span>/ 바이낸스에 있습니다.</span></h2>\n<p data-ke-size=\"size16\">영상에 보시면 루나는 망했기 때문에 회사 지분을 모두 소각해야한다는 법원의 판단이 나올 수 있습니다.</p>\n<p data-ke-size=\"size16\">소각되면 수량이 줄어들게 되겠죠</p>\n<p data-ke-size=\"size16\">법원의 판단으로 가는 계획이구요.</p>\n<p data-ke-size=\"size16\">권도형은 현재 감오에 있구요.</p>\n<p data-ke-size=\"size16\">비트코인이 오름으로서 그가 숨겨놓은 자산도 올랐을 가능성이 있습니다.</p>\n<p data-ke-size=\"size16\">당시 루나는 거의 가치를 상실했기 때문에 본인 자금으로 매꾸면 피해복구가 가능할 수도 있습니다.</p>\n<p data-ke-size=\"size16\">이부분은 거의 10년 쯤 소요될 것같군요.</p>\n<p data-ke-size=\"size16\">그러면 더 자산이 올라와 있어서 피해복구가 쉬워질것입니다.</p>\n<p data-ke-size=\"size16\">시간과의 싸음이라는 뜻입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">FTT / 바이낸스에 있습니다.</p>\n<p data-ke-size=\"size16\">뽀글이도 감옥에 가긴했는데</p>\n<p data-ke-size=\"size16\">FTX 를 다시 살릴 가능성이 있습니다.&nbsp;</p>\n<p data-ke-size=\"size16\">뽀글이는 권도형과 다르게 실제로 떡상할 회사들을 투자했습니다. 대표적으로 스페이스X 죠</p>\n<p data-ke-size=\"size16\">그래서 그의 실제 자산이 올라버려서 피해 복구가 가능할 것으로 판단됩니다.</p>\n<p data-ke-size=\"size16\">그러다보면 FTX 도 다시 살아날 수 있겠죠</p>\n<p data-ke-size=\"size16\">현재 FTX 는 거의 98% 폭락했습니다.</p>\n<p data-ke-size=\"size16\">이것도 사서 그냥 묵혀 두면 살아나지 않는가 하는 마음으로 살짝 투자해볼 필요가 있겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">그리고 베이비도지코인</h2>\n<p data-ke-size=\"size16\">80% 를 소각할까 고민중에 있습니다.</p>\n<p data-ke-size=\"size16\">시바이누의 상승도 엄청난양의 소각 뉴스 이후에 일어났습니다.</p>\n<p data-ke-size=\"size16\">소각이 결정된다면 엄청나게 오를 가능성이 있습니다.</p>\n<p data-ke-size=\"size16\">소간 할까 한지 1년쯤 지난거 같군요.</p>\n<p data-ke-size=\"size16\">언젠간 하겠죠</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">투가 권고 사항</h2>\n<p data-ke-size=\"size16\">소개해드린 투자 상품은 극도로 위험하며 부실한 자산입니다.</p>\n<p data-ke-size=\"size16\">전자산의 1% 이하로만 투자하는게 원칙입니다.</p>\n<p data-ke-size=\"size16\">그리고 시간을 녹이세요 1~10년이 걸릴 수 있습니다.</p>\n<p data-ke-size=\"size16\">이런 자산은 욕심부리시면 안되니 절대로 많은 비중을 들고계시면 안되고 특히 떨어진다고 물타셔도 안됩니다.</p>\n<p data-ke-size=\"size16\">얼마나 떨어질지 예상이 불가능 합니다.</p>\n<p data-ke-size=\"size16\">시간을 녹이세요!</p>",
        "contentSnippet": "주요 메이저 종목은 비트코인, 리플, 도지코인 입니다.\n수익이 나셨다면 맛탱이가 간 코인들을 조금 사모아요\n \n영상: https://www.youtube.com/watch?v=3Yg7AQ_QYfs\n\n\n\n영상은 업비트 재상장인데 이런 맛탱이간 뉴스가 압니다.\n이분은 예전부터 루나 클래식을 부르짓었습니다.\n제가 찾아온 코인은 LUNC / FTT 입니다.\nLUNC 는 2년전에 망한 루나사태의 그 코인의 다음버전입니다. 원본은 완전 망해서 없어졌습니다.\n그리고 FTT 는 FTX 사태로 망한 그 거래소의 지분을 상징하는 코인입니다.\n이 두개는 망한 채권 같은것입니다.\n그만큼 가격이 떨어져있구요\n이게 왜 오르냐 한다면\n \nLUNC  / 바이낸스에 있습니다.\n영상에 보시면 루나는 망했기 때문에 회사 지분을 모두 소각해야한다는 법원의 판단이 나올 수 있습니다.\n소각되면 수량이 줄어들게 되겠죠\n법원의 판단으로 가는 계획이구요.\n권도형은 현재 감오에 있구요.\n비트코인이 오름으로서 그가 숨겨놓은 자산도 올랐을 가능성이 있습니다.\n당시 루나는 거의 가치를 상실했기 때문에 본인 자금으로 매꾸면 피해복구가 가능할 수도 있습니다.\n이부분은 거의 10년 쯤 소요될 것같군요.\n그러면 더 자산이 올라와 있어서 피해복구가 쉬워질것입니다.\n시간과의 싸음이라는 뜻입니다.\n \nFTT / 바이낸스에 있습니다.\n뽀글이도 감옥에 가긴했는데\nFTX 를 다시 살릴 가능성이 있습니다. \n뽀글이는 권도형과 다르게 실제로 떡상할 회사들을 투자했습니다. 대표적으로 스페이스X 죠\n그래서 그의 실제 자산이 올라버려서 피해 복구가 가능할 것으로 판단됩니다.\n그러다보면 FTX 도 다시 살아날 수 있겠죠\n현재 FTX 는 거의 98% 폭락했습니다.\n이것도 사서 그냥 묵혀 두면 살아나지 않는가 하는 마음으로 살짝 투자해볼 필요가 있겠습니다.\n \n그리고 베이비도지코인\n80% 를 소각할까 고민중에 있습니다.\n시바이누의 상승도 엄청난양의 소각 뉴스 이후에 일어났습니다.\n소각이 결정된다면 엄청나게 오를 가능성이 있습니다.\n소간 할까 한지 1년쯤 지난거 같군요.\n언젠간 하겠죠\n \n투가 권고 사항\n소개해드린 투자 상품은 극도로 위험하며 부실한 자산입니다.\n전자산의 1% 이하로만 투자하는게 원칙입니다.\n그리고 시간을 녹이세요 1~10년이 걸릴 수 있습니다.\n이런 자산은 욕심부리시면 안되니 절대로 많은 비중을 들고계시면 안되고 특히 떨어진다고 물타셔도 안됩니다.\n얼마나 떨어질지 예상이 불가능 합니다.\n시간을 녹이세요!",
        "guid": "http://serverdown.tistory.com/996",
        "categories": [
          "투자",
          "babydoge",
          "FTT",
          "lunc",
          "코인",
          "투자"
        ],
        "isoDate": "2024-11-22T04:55:02.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "자율주행 시대가 오면 자동차회사들의 미래는 ... / 깁학주 교수",
        "link": "http://serverdown.tistory.com/995",
        "pubDate": "Fri, 22 Nov 2024 00:23:19 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/995#entry995comment",
        "content": "<p data-ke-size=\"size16\">전체 내용은 내년에 좋을만한 주식을 추천해주시네요<br />2024-11-22 이니 날짜 참고해주시구요. 이상한 시기에 보시고 투자하시면 큰일납니다.</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">자율주행 및 차사고가 안나는 사회 이야기는 너무 먼 이야기니까 투자에 반영하진 마시구요</span></p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://youtu.be/mhm5GkKR8pY?t=2228\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://youtu.be/mhm5GkKR8pY?t=2228</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=mhm5GkKR8pY\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cHZMYh/hyXzJmCzNx/jkdjlPHW7XnTbiozgGkbkK/img.jpg?width=1280&amp;height=720&amp;face=166_396_1152_568,https://scrap.kakaocdn.net/dn/bvlxpi/hyXzVHk5tE/w63m7mPZOUWIKM400Gg720/img.jpg?width=1280&amp;height=720&amp;face=166_396_1152_568\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\" [19시 생방송] 돌고 도는 순환매 장세...변동성은 더 극대화 (김학주, 곽상준, 김민수, 유영화) |\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/mhm5GkKR8pY\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">37분에 나옵니다.</p>\n<p data-ke-size=\"size16\">자율주행이 가능해지면 이런 문제들이 생깁니다.</p>\n<p data-ke-size=\"size16\">1. 차를 가질 필요가 있는가?<br />부르면 올테고<br />주차안해도 되고</p>\n<p data-ke-size=\"size16\">2. 사고가 안나게 되면<br />안전성이 약화되면서 아무나 차를 만들 수 있게됨<br /><br /></p>\n<p data-ke-size=\"size16\">먼 미래 였지만 트럼프 - 일론 머스크가 엮이게 되면서 자율주행 택시가 잘 될것 같습니다.</p>\n<p data-ke-size=\"size16\">한 결국 시간이 지나서 자동차 사고가 0 이되어버린다면&nbsp;</p>\n<p data-ke-size=\"size16\">차를 종이로 만들어도 팔 수 있는 시대가 되지 않겠냐 하는 망상을 해볼 수도 있습니다.</p>\n<p data-ke-size=\"size16\">그때가 올꺼라고 확신하는 분이셨습니다.</p>\n<p data-ke-size=\"size16\">지금은 신차 팔아야죠</p>\n<p data-ke-size=\"size16\">나중엔 UAM 이나 도시 설계를 해야할 수도 있겠군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "전체 내용은 내년에 좋을만한 주식을 추천해주시네요\n2024-11-22 이니 날짜 참고해주시구요. 이상한 시기에 보시고 투자하시면 큰일납니다.\n자율주행 및 차사고가 안나는 사회 이야기는 너무 먼 이야기니까 투자에 반영하진 마시구요\n영상: https://youtu.be/mhm5GkKR8pY?t=2228\n\n\n\n37분에 나옵니다.\n자율주행이 가능해지면 이런 문제들이 생깁니다.\n1. 차를 가질 필요가 있는가?\n부르면 올테고\n주차안해도 되고\n2. 사고가 안나게 되면\n안전성이 약화되면서 아무나 차를 만들 수 있게됨\n\n먼 미래 였지만 트럼프 - 일론 머스크가 엮이게 되면서 자율주행 택시가 잘 될것 같습니다.\n한 결국 시간이 지나서 자동차 사고가 0 이되어버린다면 \n차를 종이로 만들어도 팔 수 있는 시대가 되지 않겠냐 하는 망상을 해볼 수도 있습니다.\n그때가 올꺼라고 확신하는 분이셨습니다.\n지금은 신차 팔아야죠\n나중엔 UAM 이나 도시 설계를 해야할 수도 있겠군요",
        "guid": "http://serverdown.tistory.com/995",
        "categories": [
          "유튜브",
          "오블완",
          "자동차",
          "자율주행",
          "티스토리챌린지"
        ],
        "isoDate": "2024-11-21T15:23:19.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "RG556 / 스트리트 파이터 3 실행해보기",
        "link": "http://serverdown.tistory.com/994",
        "pubDate": "Thu, 21 Nov 2024 22:14:55 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/994#entry994comment",
        "content": "<p data-ke-size=\"size16\">처음에 사서 제대로 실행이 안되길래 포기했다 거의 3달만아에 다시 도전하였습니다.</p>\n<p data-ke-size=\"size16\">잘못된 설명으로 고생한거였더군요</p>\n<p data-ke-size=\"size16\">FB Neo CPS3 라는게 있는데 이게 아니였습니다.</p>\n<p data-ke-size=\"size16\">레딧 질문: <a href=\"https://www.reddit.com/r/PlaystationClassic/comments/f3r73l/help_running_street_fighter_3_new_generation_on/?rdt=52304\">Help running Street Fighter 3 New Generation on RetroArch (FB 2012 core) : r/PlaystationClassic</a></p>\n<figure id=\"og_1732194561100\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"From the PlaystationClassic community on Reddit\" data-og-description=\"Explore this post and more from the PlaystationClassic community\" data-og-host=\"www.reddit.com\" data-og-source-url=\"https://www.reddit.com/r/PlaystationClassic/comments/f3r73l/help_running_street_fighter_3_new_generation_on/?rdt=52304\" data-og-url=\"https://www.reddit.com/r/PlaystationClassic/comments/f3r73l/help_running_street_fighter_3_new_generation_on/?rdt=52304\" data-og-image=\"https://scrap.kakaocdn.net/dn/3CCyy/hyXDmJX4Ky/mC8RNdA1dxi16xFxmbCVOk/img.jpg?width=1120&amp;height=584&amp;face=0_0_1120_584,https://scrap.kakaocdn.net/dn/xrnBS/hyXDkrUBKs/r5kf6umB5GhrEMik9aefg0/img.jpg?width=1120&amp;height=584&amp;face=0_0_1120_584\"><a href=\"https://www.reddit.com/r/PlaystationClassic/comments/f3r73l/help_running_street_fighter_3_new_generation_on/?rdt=52304\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.reddit.com/r/PlaystationClassic/comments/f3r73l/help_running_street_fighter_3_new_generation_on/?rdt=52304\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/3CCyy/hyXDmJX4Ky/mC8RNdA1dxi16xFxmbCVOk/img.jpg?width=1120&amp;height=584&amp;face=0_0_1120_584,https://scrap.kakaocdn.net/dn/xrnBS/hyXDkrUBKs/r5kf6umB5GhrEMik9aefg0/img.jpg?width=1120&amp;height=584&amp;face=0_0_1120_584');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">From the PlaystationClassic community on Reddit</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Explore this post and more from the PlaystationClassic community</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.reddit.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">여기에선 FB Neo 를 고르라는데<br />밑에 누구는 FBA NEO 라고 하고 정신없습니다.</p>\n<p data-ke-size=\"size16\">정답은 Final Burn NEO 였습니다. ㅎㅎ</p>\n<p data-ke-size=\"size16\">롬은 여기에 있군요: <a href=\"https://wowroms.com/en/roms/mame/street-fighter-iii-new-generation-asia-clone/106260.html\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://wowroms.com/en/roms/mame/street-fighter-iii-new-generation-asia-clone/106260.html</a></p>\n<p data-ke-size=\"size16\">이 사이트에 많은 롬을 제공해줍니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">1. RetroArch 를 실행합니다.</p>\n<p data-ke-size=\"size16\">2. 코어를&nbsp; FinalBurn NEO 으로 선택합니다.</p>\n<p data-ke-size=\"size16\">3. 다운로드한 스파3 파일을 선택합니다.</p>\n<p data-ke-size=\"size16\">4. 압축파일을 선택 <br />(첫번째 선택지가 압축파일 내부를 보겠냐는 거 같군요)</p>\n<p data-ke-size=\"size16\">게임 실행됩니당 굿굿</p>\n<p data-ke-size=\"size16\">버튼도 설정해야되서<br />나중에 스샷 넣어서 좀더 제대로 써야겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "처음에 사서 제대로 실행이 안되길래 포기했다 거의 3달만아에 다시 도전하였습니다.\n잘못된 설명으로 고생한거였더군요\nFB Neo CPS3 라는게 있는데 이게 아니였습니다.\n레딧 질문: Help running Street Fighter 3 New Generation on RetroArch (FB 2012 core) : r/PlaystationClassic\n\n \nFrom the PlaystationClassic community on Reddit\nExplore this post and more from the PlaystationClassic community\nwww.reddit.com\n\n여기에선 FB Neo 를 고르라는데\n밑에 누구는 FBA NEO 라고 하고 정신없습니다.\n정답은 Final Burn NEO 였습니다. ㅎㅎ\n롬은 여기에 있군요: https://wowroms.com/en/roms/mame/street-fighter-iii-new-generation-asia-clone/106260.html\n이 사이트에 많은 롬을 제공해줍니다.\n \n1. RetroArch 를 실행합니다.\n2. 코어를  FinalBurn NEO 으로 선택합니다.\n3. 다운로드한 스파3 파일을 선택합니다.\n4. 압축파일을 선택 \n(첫번째 선택지가 압축파일 내부를 보겠냐는 거 같군요)\n게임 실행됩니당 굿굿\n버튼도 설정해야되서\n나중에 스샷 넣어서 좀더 제대로 써야겠습니다.",
        "guid": "http://serverdown.tistory.com/994",
        "categories": [
          "게임",
          "rg556",
          "게임"
        ],
        "isoDate": "2024-11-21T13:14:55.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "비트코인으로 미국 정부 부채를 해결하는 시나리오 / BTC / USDT",
        "link": "http://serverdown.tistory.com/993",
        "pubDate": "Thu, 21 Nov 2024 16:32:01 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/993#entry993comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=yn2al5DxFb0\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=yn2al5DxFb0</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=yn2al5DxFb0\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/LmoKx/hyXDit2Acd/NSAv52wk0jDTscR1xRyxN1/img.jpg?width=1280&amp;height=720&amp;face=146_54_1142_380,https://scrap.kakaocdn.net/dn/txWrg/hyXzNCuEla/JktiCpeQygYIjsN3zADbLk/img.jpg?width=1280&amp;height=720&amp;face=146_54_1142_380\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"트럼프의 전략자산 핵심은...비트코인 결국 '여기'까지 올라간다 (오태민) | 인포맥스라이브 202411\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/yn2al5DxFb0\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">미국 국채 수요 때문입니다.</p>\n<p data-ke-size=\"size16\">여기서 핵심은 정부부채를 줄이는게 아닙니다. \"해결하겠다\" 입니다.</p>\n<p data-ke-size=\"size16\">미국이 미국 국채를 금리 인상없이 발행할 수 만 있다면 정부부채는 게속 늘어도 괜찮습니다.</p>\n<p data-ke-size=\"size16\">그런데 비트코인인가?</p>\n<p data-ke-size=\"size16\">그것은 바로 USDT 때문입니다.</p>\n<h2 data-ke-size=\"size26\">USDT 와 미국 국채의 관계</h2>\n<p data-ke-size=\"size16\">대부분의 코인은 USDT 로 거래합니다. 코인 시장이 커진다면 USDT 총발행량은 증가하게 되겠죠</p>\n<p data-ke-size=\"size16\">USDT 운영 원칙은 발행량 만큼 달러를 보유하는 것입니다.</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">USDT 재단도 달러만 가지고 있으면 이자 수익이 없어서 투자를 합니다.</span></p>\n<p data-ke-size=\"size16\">대부분을 국채에 투자하기 했습니다.&nbsp;한때 중국 / 홍콩 부동산도 투자하고 있었는데 미국 정부로 부터 혼난적이 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">즉 코인 시장이 커지면 미국 국채의 수료를 창출하게 되는 것이죠</p>\n<p data-ke-size=\"size16\">심지어 이건 가상 자산이라 얼마든지 가격이 올라도 문제가 없고 다른 코인도 역시 커져도 상관없습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">중국</h2>\n<p data-ke-size=\"size16\">중국인들은 정부를 믿지 않았습니다.</p>\n<p data-ke-size=\"size16\">수천년 동안 그래왔었죠.&nbsp;</p>\n<p data-ke-size=\"size16\">좀 살만해지면 재산을 겆어가거나 전쟁으로 목슴을 갈아넣거나 했습니다.</p>\n<p data-ke-size=\"size16\">현재도 그런 상황인 것은 동일하구요.</p>\n<p data-ke-size=\"size16\">그래서 비트코인가격이 오르면 중국인들은 어떻게든 자국의 위안화로 비트코인을 사려고 할 것입니다.</p>\n<p data-ke-size=\"size16\">결국 중국 정부의 부는 해외로 유출 되고</p>\n<p data-ke-size=\"size16\">비트코인이 커지면 다시 미국의 국채 수요 증가로 이어집니다.</p>\n<h2 data-ke-size=\"size26\">결론</h2>\n<p data-ke-size=\"size16\">미국은 백년전엔 금을 달러와 엮었고<br />50년전엔 석유를 달러와 엮었습니다.<br />지금은 비트코인을 달러와 엮었습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=yn2al5DxFb0\n\n\n\n \n미국 국채 수요 때문입니다.\n여기서 핵심은 정부부채를 줄이는게 아닙니다. \"해결하겠다\" 입니다.\n미국이 미국 국채를 금리 인상없이 발행할 수 만 있다면 정부부채는 게속 늘어도 괜찮습니다.\n그런데 비트코인인가?\n그것은 바로 USDT 때문입니다.\nUSDT 와 미국 국채의 관계\n대부분의 코인은 USDT 로 거래합니다. 코인 시장이 커진다면 USDT 총발행량은 증가하게 되겠죠\nUSDT 운영 원칙은 발행량 만큼 달러를 보유하는 것입니다.\nUSDT 재단도 달러만 가지고 있으면 이자 수익이 없어서 투자를 합니다.\n대부분을 국채에 투자하기 했습니다. 한때 중국 / 홍콩 부동산도 투자하고 있었는데 미국 정부로 부터 혼난적이 있습니다.\n \n즉 코인 시장이 커지면 미국 국채의 수료를 창출하게 되는 것이죠\n심지어 이건 가상 자산이라 얼마든지 가격이 올라도 문제가 없고 다른 코인도 역시 커져도 상관없습니다.\n \n중국\n중국인들은 정부를 믿지 않았습니다.\n수천년 동안 그래왔었죠. \n좀 살만해지면 재산을 겆어가거나 전쟁으로 목슴을 갈아넣거나 했습니다.\n현재도 그런 상황인 것은 동일하구요.\n그래서 비트코인가격이 오르면 중국인들은 어떻게든 자국의 위안화로 비트코인을 사려고 할 것입니다.\n결국 중국 정부의 부는 해외로 유출 되고\n비트코인이 커지면 다시 미국의 국채 수요 증가로 이어집니다.\n결론\n미국은 백년전엔 금을 달러와 엮었고\n50년전엔 석유를 달러와 엮었습니다.\n지금은 비트코인을 달러와 엮었습니다.",
        "guid": "http://serverdown.tistory.com/993",
        "categories": [
          "코인",
          "비트코인"
        ],
        "isoDate": "2024-11-21T07:32:01.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": [
      {
        "creator": "ZeroCho",
        "title": "제일 처음 커밋 앞에 커밋 추가하기",
        "link": "https://www.zerocho.com/category/Git/post/673cc471d44b1e6d6a984f49",
        "pubDate": "Tue, 19 Nov 2024 17:01:37 GMT",
        "dc:creator": "ZeroCho",
        "content": "이 게시글은 첫 커밋 앞에 다른 커밋을 추가하는 방법을 다룹니다.\n기존 커밋 히스토리가 A - B - C - D라면(A가 제일 오래된 첫 커밋) Z - A - B - C - D처럼 제일 앞에 Z를 끼워넣는 것이죠.\n왜 이런 짓을 하는 걸까요? 다양한 이유가 있겠으나 저는 중간 커밋 수정하기 를 할 때 첫 커밋은 수정이 안 되는 것을 발견했습니다. 그래서 첫 커밋 앞에 빈 커밋(Z) 하나를 추가한 뒤에 두 번째 커밋이 된 A를 수정하는 것이죠. 다른 이유를 찾으셨다면 댓글로 남겨주세요!\n방법은 다음과 같습니다.\ngit checkout --orphan tempgit rm -rf .git commit --allow-empty -m 'Z'git rebase --onto temp --root maingit branch -d temp \nZ(첫 커밋 메시지)나 main(현재 브랜치 이름) 부분은 여러분의 상황에 맞게 바꾸시면 됩니다. 다른 것들은 그대로 입력하세요.\n간단한 원리를 설명하자면 다음과 같습니다. 처음에 기존 브랜치와 완벽하게 분리된 빈 브랜치(orphan branch) temp를 생성하고, 현재 파일을 전부 지웁니다(git rm -rf .)\n현재 아무 파일/폴더가 없는데 --allow-empty 옵션을 사용해서 새로운 커밋 Z를 하나 만듭니다. 그러고나서 temp 브랜치 커밋 위에 main 브랜치의 커밋을 쌓는 겁니다. 그래서 Z 위에 A - B - C - D 가 올라갈 수 있게 됩니다. 이후에 temp 브랜치를 지우고 main 브랜치로 돌아가는 것입니다.\n",
        "contentSnippet": "이 게시글은 첫 커밋 앞에 다른 커밋을 추가하는 방법을 다룹니다.\n기존 커밋 히스토리가 A - B - C - D라면(A가 제일 오래된 첫 커밋) Z - A - B - C - D처럼 제일 앞에 Z를 끼워넣는 것이죠.\n왜 이런 짓을 하는 걸까요? 다양한 이유가 있겠으나 저는 중간 커밋 수정하기 를 할 때 첫 커밋은 수정이 안 되는 것을 발견했습니다. 그래서 첫 커밋 앞에 빈 커밋(Z) 하나를 추가한 뒤에 두 번째 커밋이 된 A를 수정하는 것이죠. 다른 이유를 찾으셨다면 댓글로 남겨주세요!\n방법은 다음과 같습니다.\ngit checkout --orphan tempgit rm -rf .git commit --allow-empty -m 'Z'git rebase --onto temp --root maingit branch -d temp \nZ(첫 커밋 메시지)나 main(현재 브랜치 이름) 부분은 여러분의 상황에 맞게 바꾸시면 됩니다. 다른 것들은 그대로 입력하세요.\n간단한 원리를 설명하자면 다음과 같습니다. 처음에 기존 브랜치와 완벽하게 분리된 빈 브랜치(orphan branch) temp를 생성하고, 현재 파일을 전부 지웁니다(git rm -rf .)\n현재 아무 파일/폴더가 없는데 --allow-empty 옵션을 사용해서 새로운 커밋 Z를 하나 만듭니다. 그러고나서 temp 브랜치 커밋 위에 main 브랜치의 커밋을 쌓는 겁니다. 그래서 Z 위에 A - B - C - D 가 올라갈 수 있게 됩니다. 이후에 temp 브랜치를 지우고 main 브랜치로 돌아가는 것입니다.",
        "guid": "https://www.zerocho.com/category/Git/post/673cc471d44b1e6d6a984f49",
        "categories": [
          "Git"
        ],
        "isoDate": "2024-11-19T17:01:37.000Z"
      }
    ]
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": []
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "한상곤 - Sigmadream",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "Poetry를 이용한 멀티 프로젝트 Python 애플리케이션 개발 방법",
        "link": "https://techblog.lycorp.co.jp/ko/python-multi-project-application-with-poetry",
        "pubDate": "Tue, 19 Nov 2024 02:00:00 GMT",
        "content": "들어가며\n안녕하세요. LINE GAME Platform Dev2 팀의 이현섭, 이형중입니다. LINE GAME Platform에서는 게임 개발에 필요한 다양한 플랫폼 서비스를 개발...",
        "contentSnippet": "들어가며\n안녕하세요. LINE GAME Platform Dev2 팀의 이현섭, 이형중입니다. LINE GAME Platform에서는 게임 개발에 필요한 다양한 플랫폼 서비스를 개발...",
        "guid": "https://techblog.lycorp.co.jp/ko/python-multi-project-application-with-poetry",
        "isoDate": "2024-11-19T02:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": [
      {
        "title": "논문 - Scaling Memcached at Facebook: A look at the complexities of Caching",
        "link": "https://velog.io/@sweet_sumin/%EB%85%BC%EB%AC%B8-Scaling-Memcached-at-Facebook-A-look-at-the-complexities-of-Caching",
        "pubDate": "Sun, 24 Nov 2024 03:08:08 GMT",
        "content": "<p>논문 읽기 스터디를 하고 있는데, 이번엔 나의 발표차례여서 해당 논문을 정리한 내용을 공유하려고 한다. 논문 이외에 조사한 내용도 포함되어 있으니 혹시 잘못된 정보가 존재한다면 피드백은 언제나 환영!!</p>\n<h3 id=\"등장-배경---facebook의-상황\">등장 배경 - facebook의 상황</h3>\n<p>Facebook은 매일 수억 명의 사용자로부터 발생하는 막대한 읽기/쓰기 요청을 처리해야 한다. 이를 위해 대규모 데이터를 빠르게 처리하고 실시간으로 사용자 경험을 제공하는 것이 필수적이다. 기존의 데이터베이스 시스템만으로는 이러한 규모를 감당하기 어렵기 때문에, <strong>Memcached</strong>를 기반으로 한 분산 캐싱 시스템을 구축했다.</p>\n<ul>\n<li>초당 수십억 요청을 처리해야 하는 대규모 소셜 네트워크 인프라.</li>\n<li>데이터베이스 부하 증가로 인해 응답 시간 지연 발생.</li>\n<li>전 세계 사용자에게 실시간 데이터 제공 필요.</li>\n</ul>\n<h3 id=\"memcache\">memcache</h3>\n<p>메모리 내 데이터를 빠르게 저장하고 읽는데 사용되는 해시 테이블 기반 시스템</p>\n<p>facebook에서 memcache란?</p>\n<ul>\n<li>인메모리 캐싱 솔루션 → 읽기/쓰기 요청 경감 및 데어터 접근 속도 향상</li>\n<li>분산 키-값 저장소</li>\n</ul>\n<h3 id=\"facebook에서의-memcache-아키텍처\">facebook에서의 memcache 아키텍처</h3>\n<p>Facebook은 Memcached를 단순히 한 대의 서버에서 사용하는 것이 아니라, 여러 서버로 확장하여 클러스터화했다. 데이터는 일관된 해싱 기법을 통해 여러 Memcached 서버에 분산 저장되며, 클라이언트는 Memcached를 먼저 조회한 후 캐시 미스일 경우 데이터베이스에서 데이터를 가져오도록 설계되었다.</p>\n<ul>\n<li>기본 구조\n1)  master- slave 구조\n  <img src=\"https://velog.velcdn.com/images/sweet_sumin/post/ecb7a5b9-5ba9-4b38-9ea1-856f26a54c95/image.png\" alt=\"\">\n2)  일관된 해싱을 통해 키 분산\n3) 모든 웹서버는 짧은 시간 내에 모든 memcache 서버와 통신\n(all to all 통신 패턴→ 병목 현상, incast congestion의 원인)</li>\n</ul>\n<ul>\n<li>읽기 및 쓰기 경로</li>\n</ul>\n<pre><code>- **읽기**: Memcache 조회 → 캐시 미스 시 데이터베이스 접근.\n- **쓰기**: 데이터베이스 업데이트 후 Memcache 캐시 삭제(무효화).</code></pre><p><img src=\"https://velog.velcdn.com/images/sweet_sumin/post/a7d9844f-75bc-497f-9438-d6fc14c46efe/image.png\" alt=\"\"></p>\n<h2 id=\"주요-기술-및-최적화\">주요 기술 및 최적화</h2>\n<h3 id=\"📌-병렬-요청-및-일괄-처리\">📌 병렬 요청 및 일괄 처리</h3>\n<p>Facebook의 <strong>Memcache 클라이언트</strong>가 <strong>네트워크 효율성을 극대화하고 요청 지연 시간을 최소화하기 위해 구현한 전략</strong></p>\n<ol>\n<li><p>병렬 요청 </p>\n<p> <strong>문제</strong></p>\n<ul>\n<li><p>Facebook의 한 사용자 요청(예: 피드 로드)은 Memcache에서 <strong>수백 개의 키를 요청</strong>하는 작업으로 이루어질 수 있다. (한 요청 = 여러 memcache 조회)</p>\n</li>\n<li><p>이러한 요청을 하나씩 순차적으로 처리하면 네트워크 왕복(Round-Trip Time, RTT)이 증가하여 응답 시간이 길어진다.</p>\n</li>\n<li><p><em>해결 방법*</em></p>\n</li>\n<li><p>요청 간의 <strong>의존 관계</strong>를 분석하여 병렬로 처리 가능한 요청을 동시에 실행.</p>\n</li>\n<li><p>의존 관계를 DAG(Directed Acyclic Graph, 방향 비순환 그래프)로 나타내어 요청을 설계:</p>\n<ul>\n<li>예: 요청 A가 요청 B에 의존하지 않는다면 두 요청을 병렬로 실행 가능.</li>\n<li>요청 B가 요청 A의 결과를 필요로 한다면, A를 완료한 후에 B를 실행.</li>\n<li>DAG 구조<ul>\n<li>DAG(Directed Acyclic Graph) :  <strong>방향성 비순환 그래프</strong></li>\n<li>데이터 또는 작업의 의존 관계를 나타내는 데 사용</li>\n<li>Facebook의 Memcache 클라이언트가 요청을 병렬 처리하는 데 중요한 역할</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<blockquote>\n<p>💡 예시</p>\n</blockquote>\n<ul>\n<li>Facebook 뉴스피드 로드 시:<pre><code>   1) 게시물 데이터를 가져오기 위한 요청(A).</code></pre>   2) 각 게시물의 댓글 데이터를 가져오는 요청(B, C, D).\n   3) 댓글 좋아요 수 데이터를 가져오는 요청(E, F).<pre><code>이처럼 요청 간 **의존 관계**가 있을 경우, 순차적으로 처리하면 성능이 저하</code></pre><blockquote>\n</blockquote>\n</li>\n<li>DAG 구조의 적용 : 의존 관계를 <strong>DAG로 표현</strong>하여 병렬로 실행 가능한 요청을 구분<pre><code>          - A → (B, C, D) → (E, F).\n          - 요청 A가 완료된 후, 요청 B, C, D를 병렬로 실행.\n          - B, C, D가 완료되면, 요청 E와 F를 병렬로 실행.</code></pre><blockquote>\n</blockquote>\n</li>\n<li>결과<ul>\n<li>요청의 네트워크 왕복 횟수를 최소화하여 <strong>응답 시간을 단축</strong>.</li>\n<li>많은 사용자 요청을 빠르게 처리할 수 있는 병렬 처리가 가능해짐.</li>\n</ul>\n</li>\n</ul>\n<ol start=\"2\">\n<li><p>요청 일괄 처리</p>\n<p> <strong>문제:</strong></p>\n<ul>\n<li><p>Memcache는 단일 요청마다 네트워크 비용이 발생하므로, <strong>많은 키를 개별 요청으로 보낼 경우 네트워크와 서버 부하가 증가한다</strong></p>\n</li>\n<li><p><em>해결 방법:*</em></p>\n</li>\n<li><p>여러 키를 한 번의 요청으로 묶어서 일괄 처리(Batch) 형태로 서버에 전송.</p>\n<ul>\n<li>예: 24개의 키를 요청해야 할 경우, 24번의 개별 요청 대신 <strong>한 번의 요청으로 묶어서 처리</strong>.</li>\n</ul>\n</li>\n<li><p>클라이언트는 <strong>병렬로 묶인 요청 배치</strong>를 Memcache 서버에 보냄으로써 네트워크 부하를 줄임.</p>\n</li>\n<li><p><em>결과:*</em></p>\n</li>\n<li><p>평균적으로 한 번의 요청에 <strong>24개의 키</strong>를 포함.</p>\n</li>\n<li><p>서버와 클라이언트 간 네트워크 왕복(RTT)이 감소.</p>\n</li>\n<li><p>네트워크 패킷 수를 줄여 <strong>네트워크 대역폭</strong>을 절약.</p>\n</li>\n</ul>\n</li>\n</ol>\n<blockquote>\n<p>💡 사례 예시\n사용자가 Facebook 뉴스피드 로드 요청 시</p>\n</blockquote>\n<ol>\n<li><strong>병렬 처리:</strong><ul>\n<li>뉴스피드의 각 게시물, 댓글, 좋아요 데이터를 독립적으로 병렬 요청.</li>\n</ul>\n</li>\n<li><strong>일괄 처리:</strong><ul>\n<li>게시물 100개에 대한 데이터를 한 번의 요청으로 Memcache에서 가져옴.</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"📌-클라이언트-서버-통신의-최적화-방식\">📌 클라이언트-서버 통신의 최적화 방식</h3>\n<p>배경</p>\n<ul>\n<li>Facebook의 Memcache 시스템에서 <strong>웹 서버</strong>(클라이언트)는 Memcache 서버에 자주 요청을 보낸다.</li>\n<li>이때 <strong>클라이언트와 서버 간의 통신</strong>은 효율적이어야 하고, 지연 시간을 최소화해야 한다.</li>\n<li>초기 설계에서는 <strong>서버 간 통신</strong>이 필요하지 않았지만, 클라이언트와 서버 간의 통신에서 <strong>최적화가 필요</strong>했기 때문에 다양한 방법이 도입됨</li>\n</ul>\n<p>방식</p>\n<ul>\n<li>Memcache는 <strong>서버 간의 직접적인 통신을 하지 않는다</strong><ul>\n<li><strong>Memcache 서버들</strong>은 서로 <strong>상호작용하지 않고</strong>, 각 클라이언트(웹 서버)가 여러 Memcache 서버에 직접 접근</li>\n<li>모든 복잡한 로직(예: 요청 라우팅, 오류 처리 등)은 <strong>클라이언트</strong>(웹 서버)에서 처리</li>\n</ul>\n</li>\n<li><strong>상태 없는(stateless)</strong> 시스템</li>\n<li>클라이언트(웹 서버)는 요청을 여러 Memcache 서버로 보낼 때, 여러 작업을 동시에 할 수 있도록 <strong>복잡한 로직</strong>을 처리</li>\n<li><strong>UDP와 TCP</strong>를 사용하여 통신 → 네트워크 대역폭 최적화<ul>\n<li>UDP : 읽기 요청 - 연결을 설정하지 않고 빠르게 데이터를 전송할 수 있기 때문에</li>\n<li>TCP : 쓰기 요청 - <strong>데이터 일관성</strong>을 보장해야 하기 때문에 <strong>신뢰성 있는 전송</strong>이 필요</li>\n</ul>\n</li>\n<li><strong>incast congestion</strong>을 방지하기 위한 흐름 제어(flow control)가 적용<ul>\n<li><strong>incast congestion :</strong> 여러 클라이언트가 동시에 많은 요청을 서버에 보내면서 네트워크가 과부하되는 현상</li>\n<li><strong>슬라이딩 윈도우</strong> 방식을 사용하여 동시에 보낼 수 있는 요청 수를 제한</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"📌-부하-감소를-위한-방법\">📌 부하 감소를 위한 방법</h3>\n<p><strong>Memcache 시스템</strong>을 사용하여 서버의 부하를 어떻게 줄일까?</p>\n<p>Memcache 시스템은 <strong>읽기 요청</strong>이 매우 많고, <strong>캐시 미스</strong>(캐시에서 찾지 못한 데이터를 데이터베이스에서 다시 가져오는 작업)가 발생할 때마다 <strong>데이터베이스 부하</strong>가 증가</p>\n<ol>\n<li><p>Leases (리스)</p>\n<p> stale sets와 Thundering herds를 해결하기 위한 메커니즘</p>\n<ul>\n<li>stale sets: 캐시된 값이 최신 상태가 아니어서 데이터가 불일치할 때 발생하는 문제.</li>\n<li>Thundering herds: 특정 키가 자주 읽고 쓰여서 여러 클라이언트가 동시에 캐시를 갱신하려고 시도하는 상황에서 발생하는 문제.</li>\n<li>Leases <strong>메커니즘</strong>:<ul>\n<li>Memcache 인스턴스는 클라이언트에게 Leases <strong>토큰</strong>(64비트 값)을 부여.<ul>\n<li>클라이언트가 캐시 누락을 경험할 때 데이터를 캐시에 다시 설정하기 위함</li>\n<li>토큰 : 클라이언트가 원래 요청한 특정 키에 바인딩된 값</li>\n</ul>\n</li>\n<li><strong>리스가 유효할 때만</strong> 클라이언트가 Memcache에 데이터를 다시 쓸 수 있다.</li>\n<li>리스를 통해 <strong>동시 데이터 업데이트</strong>로 인한 불일치를 방지하고, 여러 클라이언트가 같은 데이터를 동시에 수정하는 문제를 해결</li>\n</ul>\n</li>\n<li><strong>결과:</strong><ul>\n<li><strong>캐시 세트</strong>가 발생하는 것을 방지하여 <strong>데이터 일관성</strong> 유지.</li>\n<li><strong>스램 문제</strong>를 해결해 데이터베이스 부하를 감소시킴.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<blockquote>\n<p> 💡 예시\n    Facebook에서 사용자가 피드를 로드할 때, 각 게시물의 좋아요 수를 Memcache에서 캐시하고 있다. 여러 사용자가 동일한 게시물을 동시에 좋아요를 눌렀다면, 좋아요 수를 업데이트하려는 여러 요청이 동시에 들어오게 될 수 있다.</p>\n<ul>\n<li>리스가 없는 경우 (문제 발생):</li>\n</ul>\n<ol>\n<li><strong>사용자 A</strong>와 <strong>사용자 B</strong>가 동시에 같은 게시물에 대해 좋아요를 누른다.<ol start=\"2\">\n<li>두 사용자가 Memcache에서 캐시된 좋아요 수를 조회하고, 캐시 미스가 발생하여 데이터베이스에서 값을 가져온다.</li>\n</ol>\n</li>\n<li>데이터베이스에서 가져온 값은 <strong>기존 값</strong>이고, 두 사용자가 <strong>동시에</strong> 좋아요 수를 증가시킨다.</li>\n<li>두 사용자가 각각 Memcache에 업데이트를 하게 되면, 최신 상태의 데이터가 아니므로 <strong>일관성</strong>이 깨지게 된다.</li>\n</ol>\n<ul>\n<li>리스 적용 후 (문제 해결)</li>\n</ul>\n<ol>\n<li><strong>사용자 A</strong>가 첫 번째로 Memcache에서 캐시된 좋아요 수를 조회.</li>\n<li>Memcache는 좋아요 수를 새로 갱신할 수 있는 <strong>리스 토큰</strong>을 사용자 A에게 할당.</li>\n<li>사용자 A는 해당 데이터를 갱신하고, 리스 토큰을 이용해 Memcache에 값을 설정.</li>\n<li><strong>사용자 B</strong>가 동일한 게시물의 좋아요 수를 조회할 때, 이미 리스 토큰이 만료되지 않은 <strong>사용자 A</strong>에게만 데이터 갱신 권한이 있기 때문에, 사용자 B는 데이터를 다시 가져와 갱신을 시도할 수 없다.</li>\n<li>사용자 B는 새로운 리스 토큰을 요청하고, 사용자 A의 갱신 작업이 완료되면 데이터베이스에서 최신 값을 가져와 업데이트.</li>\n</ol>\n<ul>\n<li>결과\n<strong>리스 메커니즘</strong> 덕분에 <strong>사용자 A</strong>만 해당 데이터를 갱신할 수 있으며, <strong>사용자 B</strong>는 갱신 권한을 얻기 전까지 기다린다.\n이를 통해 <strong>데이터 일관성</strong>을 유지하고, <strong>스램 문제</strong>를 해결하며, <strong>데이터베이스 부하</strong>도 줄인다.</li>\n</ul>\n</blockquote>\n<ol start=\"2\">\n<li>Memcache Pools</li>\n</ol>\n<p>Memcache 서버는 <strong>여러 워크로드</strong>(작업 부하)를 처리할 수 있지만, 서로 다른 데이터 접근 패턴과 메모리 사용량을 가진 워크로드가 한 풀 안에서 상호작용하면 성능이 저하될 수 있다.</p>\n<ul>\n<li>예를 들어, 자주 변경되는 데이터와 드물게 접근되는 데이터가 같은 Memcache 풀에 있으면, 자주 변경되는 데이터로 인해 드물게 접근되는 데이터가 메모리에서 지워질 수 있다.</li>\n<li><strong>Memcache 풀</strong>:<ul>\n<li>Memcache 서버를 여러 개의 <strong>별도 풀</strong>로 나누어 사용<ul>\n<li><strong>wildcard pool</strong>: 일반적인 캐시 데이터를 저장. 자주 업데이트되지 않는 데이터</li>\n<li><strong>app-specific pool</strong>: 자주 변하는 데이터를 저장.</li>\n<li><strong>replicated pool</strong>: 읽기 요청이 많은 데이터를 저장.</li>\n<li><strong>regional pool</strong>: 지역적 특성이 있는 데이터를 저장.</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>결과:</strong><ul>\n<li><strong>서로 다른 데이터를 분리</strong>하여 풀에 저장함으로써, 각 데이터 유형에 맞는 최적화된 메모리 관리와 성능 향상을 이끌어낼 수 있다</li>\n<li><strong>서로 다른 데이터 유형</strong>이 <strong>메모리 풀 간섭 없이</strong> 저장되므로, 성능이 향상되고 효율적인 <strong>메모리 사용</strong>이 가능</li>\n</ul>\n</li>\n</ul>\n<ol start=\"3\">\n<li>Replication\n특정 키가 <strong>자주 요청</strong>되는 경우, 여러 Memcache 서버에 복제본을 만들어 <strong>데이터 접근 시간</strong>을 단축시키는 기법</li>\n</ol>\n<ul>\n<li>복제된 데이터를 <strong>여러 Memcache 서버에 분산 저장</strong>하여, 읽기 요청이 한 서버에 몰리는 것을 방지.</li>\n<li>데이터베이스 요청이 많아지는 시점에 복제를 통해 <strong>다중 서버에서 동시에 데이터 제공</strong>이 가능</li>\n</ul>\n<h3 id=\"📌-글로벌-확장\">📌 글로벌 확장</h3>\n<p>Memcache 시스템이 <strong>글로벌 사용자</strong>에게 안정적이고 빠른 서비스를 제공하였나</p>\n<ol>\n<li><strong>지역 기반 설계</strong>:</li>\n</ol>\n<ul>\n<li>facebook은 <strong>글로벌 사용자</strong>에게 빠르고 일관된 응답을 제공하기 위해, Memcache를 <strong>지역별로 분산</strong>하여 배치</li>\n<li><strong>지역 단위</strong>로 캐시 데이터를 관리하고, <strong>서버 간의 데이터 전파 시간</strong>을 줄여 응답 시간을 최적화</li>\n<li><strong>각 지역별 클러스터</strong>:<ul>\n<li>Facebook은 <strong>지역별 클러스터</strong>를 구성하여, <strong>서버들이 같은 지역 내에서만 통신</strong>하도록 설계.</li>\n<li>예를 들어, <strong>북미, 유럽, 아시아</strong> 등 각 대륙별로 독립적인 Memcache 클러스터를 운영.</li>\n<li><strong>각 지역에 서버를 배치</strong>하여, 사용자 요청이 발생할 때 <strong>가장 가까운 서버</strong>에서 데이터를 처리하도록 하여 <strong>응답 시간</strong>을 최소화.</li>\n</ul>\n</li>\n<li><strong>글로벌 서버 분산</strong>:<ul>\n<li>데이터는 여러 서버에 <strong>복제</strong>되어 저장. 각 지역에 <strong>복제된 데이터</strong>를 두어, 한 지역에서 장애가 발생하더라도 다른 지역에서 <strong>백업 데이터</strong>를 빠르게 사용할 수 있게 된다.</li>\n</ul>\n</li>\n</ul>\n<ol start=\"2\">\n<li><strong>클러스터 분할 (Sharding)</strong> : 효율적인 확장</li>\n</ol>\n<p><strong>샤딩</strong>은 Memcache 서버를 여러 개의 작은 <strong>서브 클러스터</strong>로 나누는 방식으로, 각 클러스터가 <strong>데이터의 일부분만 담당</strong>하도록 한다.</p>\n<ol>\n<li><strong>데이터 일관성 (Data Consistency)</strong> : 다양한 지역에 배포된 서버들이 동일한 데이터를 제공. </li>\n</ol>\n<ul>\n<li><p>캐시 일관성 유지</p>\n<ul>\n<li>Facebook은 <strong>일관성 있는 데이터</strong>를 보장하기 위해 <strong>원격 캐시</strong> 및 <strong>데이터 동기화</strong> 전략을 사용.<ul>\n<li>각 서버가 다른 지역에 있는 서버들과 <strong>주기적으로 데이터를 동기화</strong>하여, 최신 데이터를 여러 지역에서 동일하게 제공.</li>\n<li><strong>데이터베이스</strong>에서 변경된 사항은 <strong>캐시에서 무효화</strong>된 후, 새로 갱신된 데이터를 다시 캐시로 가져오는 방식으로 일관성을 유지.</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>데이터 전파 및 복제</p>\n<ul>\n<li>데이터베이스의 <strong>변경 사항</strong>은 <strong>복제된 Memcache 서버</strong>에 자동으로 전파.</li>\n<li><strong>동기 복제</strong> 또는 <strong>비동기 복제</strong> 방식을 사용하여 각 지역 서버에 <strong>실시간 데이터 동기화</strong>를 구현.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"📌-단일-서버-개선-사항\">📌 단일 서버 개선 사항</h3>\n<ul>\n<li><p>멀티스레드 구현</p>\n</li>\n<li><p>Adaptive Slab Allocator 적용\nMemcache 서버에서 메모리를 <strong>고정 크기 블록</strong>으로 할당할 경우, <strong>메모리 낭비</strong>가 발생할 수 있음. 특히 작은 크기의 데이터나 자주 변하는 데이터에 대해서는 비효율적인 메모리 사용이 문제이다.</p>\n<ul>\n<li>메모리 할당을 <strong>동적으로 최적화</strong></li>\n<li>작은 데이터는 작은 크기의 슬랩을 사용하고, 큰 데이터는 더 큰 슬랩을 할당하여 <strong>메모리 사용 효율</strong>을 높임</li>\n</ul>\n</li>\n<li><p>LRU(Least Recently Used) 캐시 정책 개선\nMemcache는 기본적으로 <strong>LRU(Least Recently Used)</strong> 정책을 사용하여 오래된 데이터를 삭제하고 새로운 데이터를 저장하는 방식으로 동작 → <strong>데이터 삭제</strong>가 발생할 때 불필요한 연산이 발생\n<strong>LRU 알고리즘</strong>을 개선하여 <strong>캐시의 유효성</strong>을 최적화하고, 불필요한 삭제를 최소화</p>\n</li>\n<li><p>비동기 요청 처리 도입</p>\n</li>\n<li><p>네트워크 지연 시간 감소</p>\n</li>\n<li><p>메모리 효율성 향상</p>\n</li>\n</ul>\n<h2 id=\"그래서-redis랑-어떤차이가-있는-건데-🤔\">그래서 Redis랑 어떤차이가 있는 건데? 🤔</h2>\n<h3 id=\"데이터-구조\">데이터 구조</h3>\n<ul>\n<li><p>Redis: 다양한 데이터 구조를 지원.</p>\n<ul>\n<li>문자열 (String)</li>\n<li>리스트 (List)</li>\n<li>집합 (Set)</li>\n<li>정렬된 집합 (Sorted Set)</li>\n<li>해시 (Hash)</li>\n<li>비트맵, 하이퍼로그로그 등 고급 자료 구조</li>\n</ul>\n</li>\n<li><blockquote>\n<p>이를 통해 복잡한 데이터 연산을 인메모리에서 처리할 수 있다.</p>\n</blockquote>\n</li>\n<li><p>Memcached:\n단순히 key-value 쌍의 데이터를 문자열 또는 바이너리 형태로 저장.</p>\n</li>\n<li><blockquote>\n<p>구조가 간단하여 캐싱 이외의 복잡한 작업에는 부적합.</p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"영속성-persistence\">영속성 (Persistence)</h3>\n<ul>\n<li><p>Redis:데이터 영속성을 지원.</p>\n<ul>\n<li>RDB (주기적으로 데이터 덤프)</li>\n<li>AOF (명령 로그 기록)</li>\n</ul>\n</li>\n<li><blockquote>\n<p>캐시로뿐만 아니라 데이터베이스로도 활용 가능.</p>\n</blockquote>\n</li>\n<li><p>Memcached:영속성을 지원하지 않는다.</p>\n</li>\n<li><blockquote>\n<p>메모리가 날아가면 데이터도 손실.</p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"클러스터링-clustering\">클러스터링 (Clustering)</h3>\n<ul>\n<li><p>Redis:Redis 클러스터를 통해 샤딩과 복제를 지원.</p>\n</li>\n<li><blockquote>\n<p>확장성이 높으며, 고가용성을 위한 설정이 가능합니다.</p>\n</blockquote>\n</li>\n<li><p>Memcached:\n클러스터링을 자체적으로 지원하지 않는다.</p>\n</li>\n<li><blockquote>\n<p>클라이언트 라이브러리를 사용해 샤딩 구현.</p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"성능\">성능</h3>\n<ul>\n<li><p>Redis:\n다양한 데이터 구조와 기능으로 인해 특정 상황에서 오버헤드가 발생할 수 있습니다.\n하지만 대부분의 경우 성능은 매우 뛰어나다.</p>\n</li>\n<li><p>Memcached:\n단순한 구조 덕분에 읽기/쓰기 성능이 매우 빠르다.</p>\n</li>\n<li><blockquote>\n<p>단순 캐싱 용도라면 Redis보다 약간 더 나은 성능을 보일 수 있다.</p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"사례\">사례</h3>\n<ul>\n<li>Redis: 세션 관리, 실시간 분석 (e.g., 순위, 카운터), 메시지 큐, Pub/Sub 시스템, 복잡한 데이터 구조 캐싱</li>\n<li>Memcached:단순 데이터 캐싱, 웹 페이지 렌더링 속도 개선,자주 변경되지 않는 데이터 저장</li>\n</ul>\n<h3 id=\"메모리-관리\">메모리 관리</h3>\n<ul>\n<li><p>Redis:</p>\n<ul>\n<li>LRU(Least Recently Used) 정책으로 메모리 관리.</li>\n<li>사용자가 메모리 사용량을 세부적으로 제어 가능.</li>\n</ul>\n</li>\n<li><p>Memcached:\n메모리 블록 단위로 데이터를 저장하며, 메모리 초과 시 오래된 데이터를 자동 삭제.</p>\n</li>\n</ul>\n<blockquote>\n<p>정리하자면, \nRedis는 다양한 데이터 구조와 영속성을 지원하며, 데이터베이스나 메시지 브로커 등으로도 활용 가능. 복잡한 작업에 적합하다.\nMemcached는 단순한 데이터 캐싱에 특화되어 있으며, 빠르고 가볍다</p>\n</blockquote>\n<p>논문 링크 : <a href=\"https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf\">https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf</a></p>\n",
        "contentSnippet": "논문 읽기 스터디를 하고 있는데, 이번엔 나의 발표차례여서 해당 논문을 정리한 내용을 공유하려고 한다. 논문 이외에 조사한 내용도 포함되어 있으니 혹시 잘못된 정보가 존재한다면 피드백은 언제나 환영!!\n등장 배경 - facebook의 상황\nFacebook은 매일 수억 명의 사용자로부터 발생하는 막대한 읽기/쓰기 요청을 처리해야 한다. 이를 위해 대규모 데이터를 빠르게 처리하고 실시간으로 사용자 경험을 제공하는 것이 필수적이다. 기존의 데이터베이스 시스템만으로는 이러한 규모를 감당하기 어렵기 때문에, Memcached를 기반으로 한 분산 캐싱 시스템을 구축했다.\n초당 수십억 요청을 처리해야 하는 대규모 소셜 네트워크 인프라.\n데이터베이스 부하 증가로 인해 응답 시간 지연 발생.\n전 세계 사용자에게 실시간 데이터 제공 필요.\nmemcache\n메모리 내 데이터를 빠르게 저장하고 읽는데 사용되는 해시 테이블 기반 시스템\nfacebook에서 memcache란?\n인메모리 캐싱 솔루션 → 읽기/쓰기 요청 경감 및 데어터 접근 속도 향상\n분산 키-값 저장소\nfacebook에서의 memcache 아키텍처\nFacebook은 Memcached를 단순히 한 대의 서버에서 사용하는 것이 아니라, 여러 서버로 확장하여 클러스터화했다. 데이터는 일관된 해싱 기법을 통해 여러 Memcached 서버에 분산 저장되며, 클라이언트는 Memcached를 먼저 조회한 후 캐시 미스일 경우 데이터베이스에서 데이터를 가져오도록 설계되었다.\n기본 구조\n1)  master- slave 구조\n  \n2)  일관된 해싱을 통해 키 분산\n3) 모든 웹서버는 짧은 시간 내에 모든 memcache 서버와 통신\n(all to all 통신 패턴→ 병목 현상, incast congestion의 원인)\n읽기 및 쓰기 경로\n- **읽기**: Memcache 조회 → 캐시 미스 시 데이터베이스 접근.\n- **쓰기**: 데이터베이스 업데이트 후 Memcache 캐시 삭제(무효화).\n\n주요 기술 및 최적화\n📌 병렬 요청 및 일괄 처리\nFacebook의 Memcache 클라이언트가 네트워크 효율성을 극대화하고 요청 지연 시간을 최소화하기 위해 구현한 전략\n병렬 요청 \n 문제\nFacebook의 한 사용자 요청(예: 피드 로드)은 Memcache에서 수백 개의 키를 요청하는 작업으로 이루어질 수 있다. (한 요청 = 여러 memcache 조회)\n이러한 요청을 하나씩 순차적으로 처리하면 네트워크 왕복(Round-Trip Time, RTT)이 증가하여 응답 시간이 길어진다.\n해결 방법*\n요청 간의 의존 관계를 분석하여 병렬로 처리 가능한 요청을 동시에 실행.\n의존 관계를 DAG(Directed Acyclic Graph, 방향 비순환 그래프)로 나타내어 요청을 설계:\n예: 요청 A가 요청 B에 의존하지 않는다면 두 요청을 병렬로 실행 가능.\n요청 B가 요청 A의 결과를 필요로 한다면, A를 완료한 후에 B를 실행.\nDAG 구조\nDAG(Directed Acyclic Graph) :  방향성 비순환 그래프\n데이터 또는 작업의 의존 관계를 나타내는 데 사용\nFacebook의 Memcache 클라이언트가 요청을 병렬 처리하는 데 중요한 역할\n💡 예시\nFacebook 뉴스피드 로드 시:\n   1) 게시물 데이터를 가져오기 위한 요청(A).\n   2) 각 게시물의 댓글 데이터를 가져오는 요청(B, C, D).\n   3) 댓글 좋아요 수 데이터를 가져오는 요청(E, F).\n이처럼 요청 간 **의존 관계**가 있을 경우, 순차적으로 처리하면 성능이 저하\n\n\n\nDAG 구조의 적용 : 의존 관계를 DAG로 표현하여 병렬로 실행 가능한 요청을 구분\n          - A → (B, C, D) → (E, F).\n          - 요청 A가 완료된 후, 요청 B, C, D를 병렬로 실행.\n          - B, C, D가 완료되면, 요청 E와 F를 병렬로 실행.\n\n\n\n결과\n요청의 네트워크 왕복 횟수를 최소화하여 응답 시간을 단축.\n많은 사용자 요청을 빠르게 처리할 수 있는 병렬 처리가 가능해짐.\n요청 일괄 처리\n 문제:\nMemcache는 단일 요청마다 네트워크 비용이 발생하므로, 많은 키를 개별 요청으로 보낼 경우 네트워크와 서버 부하가 증가한다\n해결 방법:*\n여러 키를 한 번의 요청으로 묶어서 일괄 처리(Batch) 형태로 서버에 전송.\n예: 24개의 키를 요청해야 할 경우, 24번의 개별 요청 대신 한 번의 요청으로 묶어서 처리.\n클라이언트는 병렬로 묶인 요청 배치를 Memcache 서버에 보냄으로써 네트워크 부하를 줄임.\n결과:*\n평균적으로 한 번의 요청에 24개의 키를 포함.\n서버와 클라이언트 간 네트워크 왕복(RTT)이 감소.\n네트워크 패킷 수를 줄여 네트워크 대역폭을 절약.\n💡 사례 예시\n사용자가 Facebook 뉴스피드 로드 요청 시\n병렬 처리:\n뉴스피드의 각 게시물, 댓글, 좋아요 데이터를 독립적으로 병렬 요청.\n일괄 처리:\n게시물 100개에 대한 데이터를 한 번의 요청으로 Memcache에서 가져옴.\n📌 클라이언트-서버 통신의 최적화 방식\n배경\nFacebook의 Memcache 시스템에서 웹 서버(클라이언트)는 Memcache 서버에 자주 요청을 보낸다.\n이때 클라이언트와 서버 간의 통신은 효율적이어야 하고, 지연 시간을 최소화해야 한다.\n초기 설계에서는 서버 간 통신이 필요하지 않았지만, 클라이언트와 서버 간의 통신에서 최적화가 필요했기 때문에 다양한 방법이 도입됨\n방식\nMemcache는 서버 간의 직접적인 통신을 하지 않는다\nMemcache 서버들은 서로 상호작용하지 않고, 각 클라이언트(웹 서버)가 여러 Memcache 서버에 직접 접근\n모든 복잡한 로직(예: 요청 라우팅, 오류 처리 등)은 클라이언트(웹 서버)에서 처리\n상태 없는(stateless) 시스템\n클라이언트(웹 서버)는 요청을 여러 Memcache 서버로 보낼 때, 여러 작업을 동시에 할 수 있도록 복잡한 로직을 처리\nUDP와 TCP를 사용하여 통신 → 네트워크 대역폭 최적화\nUDP : 읽기 요청 - 연결을 설정하지 않고 빠르게 데이터를 전송할 수 있기 때문에\nTCP : 쓰기 요청 - 데이터 일관성을 보장해야 하기 때문에 신뢰성 있는 전송이 필요\nincast congestion을 방지하기 위한 흐름 제어(flow control)가 적용\nincast congestion : 여러 클라이언트가 동시에 많은 요청을 서버에 보내면서 네트워크가 과부하되는 현상\n슬라이딩 윈도우 방식을 사용하여 동시에 보낼 수 있는 요청 수를 제한\n📌 부하 감소를 위한 방법\nMemcache 시스템을 사용하여 서버의 부하를 어떻게 줄일까?\nMemcache 시스템은 읽기 요청이 매우 많고, 캐시 미스(캐시에서 찾지 못한 데이터를 데이터베이스에서 다시 가져오는 작업)가 발생할 때마다 데이터베이스 부하가 증가\nLeases (리스)\n stale sets와 Thundering herds를 해결하기 위한 메커니즘\nstale sets: 캐시된 값이 최신 상태가 아니어서 데이터가 불일치할 때 발생하는 문제.\nThundering herds: 특정 키가 자주 읽고 쓰여서 여러 클라이언트가 동시에 캐시를 갱신하려고 시도하는 상황에서 발생하는 문제.\nLeases 메커니즘:\nMemcache 인스턴스는 클라이언트에게 Leases 토큰(64비트 값)을 부여.\n클라이언트가 캐시 누락을 경험할 때 데이터를 캐시에 다시 설정하기 위함\n토큰 : 클라이언트가 원래 요청한 특정 키에 바인딩된 값\n리스가 유효할 때만 클라이언트가 Memcache에 데이터를 다시 쓸 수 있다.\n리스를 통해 동시 데이터 업데이트로 인한 불일치를 방지하고, 여러 클라이언트가 같은 데이터를 동시에 수정하는 문제를 해결\n결과:\n캐시 세트가 발생하는 것을 방지하여 데이터 일관성 유지.\n스램 문제를 해결해 데이터베이스 부하를 감소시킴.\n 💡 예시\n    Facebook에서 사용자가 피드를 로드할 때, 각 게시물의 좋아요 수를 Memcache에서 캐시하고 있다. 여러 사용자가 동일한 게시물을 동시에 좋아요를 눌렀다면, 좋아요 수를 업데이트하려는 여러 요청이 동시에 들어오게 될 수 있다.\n리스가 없는 경우 (문제 발생):\n사용자 A와 사용자 B가 동시에 같은 게시물에 대해 좋아요를 누른다.\n두 사용자가 Memcache에서 캐시된 좋아요 수를 조회하고, 캐시 미스가 발생하여 데이터베이스에서 값을 가져온다.\n데이터베이스에서 가져온 값은 기존 값이고, 두 사용자가 동시에 좋아요 수를 증가시킨다.\n두 사용자가 각각 Memcache에 업데이트를 하게 되면, 최신 상태의 데이터가 아니므로 일관성이 깨지게 된다.\n리스 적용 후 (문제 해결)\n사용자 A가 첫 번째로 Memcache에서 캐시된 좋아요 수를 조회.\nMemcache는 좋아요 수를 새로 갱신할 수 있는 리스 토큰을 사용자 A에게 할당.\n사용자 A는 해당 데이터를 갱신하고, 리스 토큰을 이용해 Memcache에 값을 설정.\n사용자 B가 동일한 게시물의 좋아요 수를 조회할 때, 이미 리스 토큰이 만료되지 않은 사용자 A에게만 데이터 갱신 권한이 있기 때문에, 사용자 B는 데이터를 다시 가져와 갱신을 시도할 수 없다.\n사용자 B는 새로운 리스 토큰을 요청하고, 사용자 A의 갱신 작업이 완료되면 데이터베이스에서 최신 값을 가져와 업데이트.\n결과\n리스 메커니즘 덕분에 사용자 A만 해당 데이터를 갱신할 수 있으며, 사용자 B는 갱신 권한을 얻기 전까지 기다린다.\n이를 통해 데이터 일관성을 유지하고, 스램 문제를 해결하며, 데이터베이스 부하도 줄인다.\nMemcache Pools\nMemcache 서버는 여러 워크로드(작업 부하)를 처리할 수 있지만, 서로 다른 데이터 접근 패턴과 메모리 사용량을 가진 워크로드가 한 풀 안에서 상호작용하면 성능이 저하될 수 있다.\n예를 들어, 자주 변경되는 데이터와 드물게 접근되는 데이터가 같은 Memcache 풀에 있으면, 자주 변경되는 데이터로 인해 드물게 접근되는 데이터가 메모리에서 지워질 수 있다.\nMemcache 풀:\nMemcache 서버를 여러 개의 별도 풀로 나누어 사용\nwildcard pool: 일반적인 캐시 데이터를 저장. 자주 업데이트되지 않는 데이터\napp-specific pool: 자주 변하는 데이터를 저장.\nreplicated pool: 읽기 요청이 많은 데이터를 저장.\nregional pool: 지역적 특성이 있는 데이터를 저장.\n결과:\n서로 다른 데이터를 분리하여 풀에 저장함으로써, 각 데이터 유형에 맞는 최적화된 메모리 관리와 성능 향상을 이끌어낼 수 있다\n서로 다른 데이터 유형이 메모리 풀 간섭 없이 저장되므로, 성능이 향상되고 효율적인 메모리 사용이 가능\nReplication\n특정 키가 자주 요청되는 경우, 여러 Memcache 서버에 복제본을 만들어 데이터 접근 시간을 단축시키는 기법\n복제된 데이터를 여러 Memcache 서버에 분산 저장하여, 읽기 요청이 한 서버에 몰리는 것을 방지.\n데이터베이스 요청이 많아지는 시점에 복제를 통해 다중 서버에서 동시에 데이터 제공이 가능\n📌 글로벌 확장\nMemcache 시스템이 글로벌 사용자에게 안정적이고 빠른 서비스를 제공하였나\n지역 기반 설계:\nfacebook은 글로벌 사용자에게 빠르고 일관된 응답을 제공하기 위해, Memcache를 지역별로 분산하여 배치\n지역 단위로 캐시 데이터를 관리하고, 서버 간의 데이터 전파 시간을 줄여 응답 시간을 최적화\n각 지역별 클러스터:\nFacebook은 지역별 클러스터를 구성하여, 서버들이 같은 지역 내에서만 통신하도록 설계.\n예를 들어, 북미, 유럽, 아시아 등 각 대륙별로 독립적인 Memcache 클러스터를 운영.\n각 지역에 서버를 배치하여, 사용자 요청이 발생할 때 가장 가까운 서버에서 데이터를 처리하도록 하여 응답 시간을 최소화.\n글로벌 서버 분산:\n데이터는 여러 서버에 복제되어 저장. 각 지역에 복제된 데이터를 두어, 한 지역에서 장애가 발생하더라도 다른 지역에서 백업 데이터를 빠르게 사용할 수 있게 된다.\n클러스터 분할 (Sharding) : 효율적인 확장\n샤딩은 Memcache 서버를 여러 개의 작은 서브 클러스터로 나누는 방식으로, 각 클러스터가 데이터의 일부분만 담당하도록 한다.\n데이터 일관성 (Data Consistency) : 다양한 지역에 배포된 서버들이 동일한 데이터를 제공. \n캐시 일관성 유지\nFacebook은 일관성 있는 데이터를 보장하기 위해 원격 캐시 및 데이터 동기화 전략을 사용.\n각 서버가 다른 지역에 있는 서버들과 주기적으로 데이터를 동기화하여, 최신 데이터를 여러 지역에서 동일하게 제공.\n데이터베이스에서 변경된 사항은 캐시에서 무효화된 후, 새로 갱신된 데이터를 다시 캐시로 가져오는 방식으로 일관성을 유지.\n데이터 전파 및 복제\n데이터베이스의 변경 사항은 복제된 Memcache 서버에 자동으로 전파.\n동기 복제 또는 비동기 복제 방식을 사용하여 각 지역 서버에 실시간 데이터 동기화를 구현.\n📌 단일 서버 개선 사항\n멀티스레드 구현\nAdaptive Slab Allocator 적용\nMemcache 서버에서 메모리를 고정 크기 블록으로 할당할 경우, 메모리 낭비가 발생할 수 있음. 특히 작은 크기의 데이터나 자주 변하는 데이터에 대해서는 비효율적인 메모리 사용이 문제이다.\n메모리 할당을 동적으로 최적화\n작은 데이터는 작은 크기의 슬랩을 사용하고, 큰 데이터는 더 큰 슬랩을 할당하여 메모리 사용 효율을 높임\nLRU(Least Recently Used) 캐시 정책 개선\nMemcache는 기본적으로 LRU(Least Recently Used) 정책을 사용하여 오래된 데이터를 삭제하고 새로운 데이터를 저장하는 방식으로 동작 → 데이터 삭제가 발생할 때 불필요한 연산이 발생\nLRU 알고리즘을 개선하여 캐시의 유효성을 최적화하고, 불필요한 삭제를 최소화\n비동기 요청 처리 도입\n네트워크 지연 시간 감소\n메모리 효율성 향상\n그래서 Redis랑 어떤차이가 있는 건데? 🤔\n데이터 구조\nRedis: 다양한 데이터 구조를 지원.\n문자열 (String)\n리스트 (List)\n집합 (Set)\n정렬된 집합 (Sorted Set)\n해시 (Hash)\n비트맵, 하이퍼로그로그 등 고급 자료 구조\n\n이를 통해 복잡한 데이터 연산을 인메모리에서 처리할 수 있다.\nMemcached:\n단순히 key-value 쌍의 데이터를 문자열 또는 바이너리 형태로 저장.\n\n구조가 간단하여 캐싱 이외의 복잡한 작업에는 부적합.\n영속성 (Persistence)\nRedis:데이터 영속성을 지원.\nRDB (주기적으로 데이터 덤프)\nAOF (명령 로그 기록)\n\n캐시로뿐만 아니라 데이터베이스로도 활용 가능.\nMemcached:영속성을 지원하지 않는다.\n\n메모리가 날아가면 데이터도 손실.\n클러스터링 (Clustering)\nRedis:Redis 클러스터를 통해 샤딩과 복제를 지원.\n\n확장성이 높으며, 고가용성을 위한 설정이 가능합니다.\nMemcached:\n클러스터링을 자체적으로 지원하지 않는다.\n\n클라이언트 라이브러리를 사용해 샤딩 구현.\n성능\nRedis:\n다양한 데이터 구조와 기능으로 인해 특정 상황에서 오버헤드가 발생할 수 있습니다.\n하지만 대부분의 경우 성능은 매우 뛰어나다.\nMemcached:\n단순한 구조 덕분에 읽기/쓰기 성능이 매우 빠르다.\n\n단순 캐싱 용도라면 Redis보다 약간 더 나은 성능을 보일 수 있다.\n사례\nRedis: 세션 관리, 실시간 분석 (e.g., 순위, 카운터), 메시지 큐, Pub/Sub 시스템, 복잡한 데이터 구조 캐싱\nMemcached:단순 데이터 캐싱, 웹 페이지 렌더링 속도 개선,자주 변경되지 않는 데이터 저장\n메모리 관리\nRedis:\nLRU(Least Recently Used) 정책으로 메모리 관리.\n사용자가 메모리 사용량을 세부적으로 제어 가능.\nMemcached:\n메모리 블록 단위로 데이터를 저장하며, 메모리 초과 시 오래된 데이터를 자동 삭제.\n정리하자면, \nRedis는 다양한 데이터 구조와 영속성을 지원하며, 데이터베이스나 메시지 브로커 등으로도 활용 가능. 복잡한 작업에 적합하다.\nMemcached는 단순한 데이터 캐싱에 특화되어 있으며, 빠르고 가볍다\n논문 링크 : https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf",
        "guid": "https://velog.io/@sweet_sumin/%EB%85%BC%EB%AC%B8-Scaling-Memcached-at-Facebook-A-look-at-the-complexities-of-Caching",
        "isoDate": "2024-11-24T03:08:08.000Z"
      }
    ]
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "작은 점",
        "link": "https://www.thestartupbible.com/2024/11/everyone-is-fighting-their-own-battle-in-their-tiny-world.html",
        "pubDate": "Sun, 24 Nov 2024 21:41:00 +0000",
        "content:encodedSnippet": "요새 창업가들에게 참 힘든 시기이다. 나도 이 블로그에서 좋지 않은 경기에 대해서 너무 오랫동안, 그리고 너무 많이 포스팅했고, 내가 이런 글을 쓰지 않아도 모든 창업가들과 투자자들은 지난 2년 동안 매일 직접 몸으로 이 현실을 체험하고 있다.\n나는 이 어려운 시기에 VC라는 업에 대해서 더 많이 생각하고, 고민하고, 그리고 이 업의 본질에 대해서 배우고 있어서, 힘들지만, 오히려 더 의미 있고 보람찬 시간을 보내고 있다. 아무것도 모를 적엔, VC라는 업은 그냥 스타트업에 투자만 잘하면 되는거라고 생각했다. 물론, 투자에서 가장 중요한 건, 종류를 막론하고 좋은 투자 대상을 발굴해서 좋은 조건에 투자하는 것이다. 결국 여기서 모든 게 시작되니까. 하지만, 최근 몇 년 동안 배우면서 느끼는 건, VC라는 업의 진짜 본질은 투자한 회사가 어려울 때, 그 회사와 같이 싸우고, 경영진들과 같이 고민하고, 해결하기 힘든 문제에 대한 해답을 같이 찾는 것이라는 점이다. 실은, 투자하는 건 VC의 업무 중 가장 쉽고, 누구나 다 할 수 있지만, 이 회사들이 망가지거나, 힘든 상황을 겪고 있을 때 – 그리고 투자를 해본 사람들은 누구나 다 안다. 힘들지 않거나, 망가지지 않는 스타트업은 없다는 걸 – 같이 이 문제를 해결하기 위해서 고민하고 노력하는 게 가장 어렵고, 오히려 더 중요한 VC의 업무라고 생각한다. 그 누구도 남이 듣기 싫어하는 소리를 하고, 남이 건드리지 않는 똥을 치우고 싶진 않지만, VC의 본질은 바로 이런 일을 솔선수범해서 하는 것이다.\n그런데 이게 굉장히 힘든 일이다. 실은 내가 아는 대부분의 VC는 이런 궂은일을 안 하려고 한다. 세월이 좋고, 회사가 잘 되면 모두 다 본인들이 잘 투자했고, 잘 관리했고, 그리고 그 회사를 “키웠다”라고 너도나도 한마디씩 하지만, 아주 골치 아픈 일이 발생하면 너도나도 모른척하고 도망가기에 바쁘다. 이게 사람의 습성이고, VC라고 다르지 않다. 우리도 투자사에 골치 아픈 일이 발생하면 그냥 모른척하고, 미루고, 도망가고 싶지만, 이렇게 하는 건 그 누구에게도 도움이 안 되고, 결국엔 우리 스스로 엄청나게 후회하는 결과가 발생할 것이라는 걸 너무 잘 알기 때문에, 그냥 정면 돌파를 시도한다. 정면 돌파는 참 괴롭고 힘들지만, 하다 보면 문제가 잘 해결되는 운 좋은 경우도 있고, 잘 안되더라도 기분이 찜찜하진 않다.\n회사의 대표도 이런 비장한 마음이고, 투자사이자 이사회 멤버인 우리도 비장한 마음으로 정면 돌파를 시도하는 아주 골치 아픈 이슈가 요새 하나 있다. 실은, 나도 이렇게 골치가 아픈데, 우리 투자사 대표는 오죽하겠나. 이분과 이런 회사 이야기를 하면, 그렇게 어려운 일을 많이 겪은 분도 요새 스트레스가 커서, 이 불안한 마음을 가라앉히기 위해 여러 가지 새로운 시도를 하고 있는데 집에서 시간 날 때마다 지구본을 본다고 한다.\n파란 구슬 같은 지구본을 보면서 스스로에게 이 거대한 우주 속에 지구는 정말 작은 구슬 같은 존재이고, 이 작은 지구에서 본인은 정말 작은 점 같은 존재이고, 이 작은 점의 걱정과 고민은 정말 아무것도 아니라는 최면을 스스로에게 건다고 한다. 이렇게 몇 번 지구본을 보면서 스스로에게 이런 위안을 하면, 그나마 불안이 조금 사라지면서 다시 지옥 같은 현실을 직면할 수 있는 용기가 생긴다고 한다.\n이후에 나도 불안과 스트레스가 너무 크면, 지구본을 보면서 “나는 이 지구상에 점과 같은 존재다. 점과 같은 존재가 느끼는 불안과 스트레스는 정말 아무것도 아니다.”라는 말을 스스로에게 몇 번 해봤는데, 솔직히 나한테는 그렇게 큰 도움이 되진 않는 것 같다. 불안, 스트레스, 그리고 고민의 크기는 상대적이고, 그 크기와는 상관없이 우리 모두 매 순간 우리만의 크고 작은 전쟁을 치르고 있다. 누군가는 나에게 “우크라이나랑 중동에선 매일 사람들이 죽고 있고, 그 사람들의 불안과 스트레스에 비하면 너는 아무것도 아닌데, 뭘 그렇게 걱정하냐?”라고 물어볼 수 있지만, 나에게는 지금 이 시점에 나한테 닥친 고민이 세상에서 제일 큰 고민거리고, 내가 싸워야 하는 나만의 생사가 걸린 전쟁이다. 하지만, 위에서 말 한, 큰 세상의 작은 점 하나가 겪는 더 작은 시련이라는 관점에서 나의 불안을 바라보는 건 스트레스 완화를 위한 괜찮은 방법의 하나인 것 같다. 계속 연습하고 스스로에게 주문을 외워야 한다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/11/everyone-is-fighting-their-own-battle-in-their-tiny-world.html#respond",
        "content": "요새 창업가들에게 참 힘든 시기이다. 나도 이 블로그에서 좋지 않은 경기에 대해서 너무 오랫동안, 그리고 너무 많이 포스팅했고, 내가 이런 글을 쓰지 않아도 모든 창업가들과 투자자들은 지난 2년 동안 매일 직접 몸으로 이 현실을 체험하고 있다. 나는 이 어려운 시기에 VC라는 업에 대해서 더 많이 생각하고, 고민하고, 그리고 이 업의 본질에 대해서 배우고 있어서, 힘들지만,(...)",
        "contentSnippet": "요새 창업가들에게 참 힘든 시기이다. 나도 이 블로그에서 좋지 않은 경기에 대해서 너무 오랫동안, 그리고 너무 많이 포스팅했고, 내가 이런 글을 쓰지 않아도 모든 창업가들과 투자자들은 지난 2년 동안 매일 직접 몸으로 이 현실을 체험하고 있다. 나는 이 어려운 시기에 VC라는 업에 대해서 더 많이 생각하고, 고민하고, 그리고 이 업의 본질에 대해서 배우고 있어서, 힘들지만,(...)",
        "guid": "https://www.thestartupbible.com/?p=9268",
        "categories": [
          "Uncategorized",
          "failure",
          "FoundersAtWork",
          "Strong",
          "vc"
        ],
        "isoDate": "2024-11-24T21:41:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "한국 제품",
        "link": "https://www.thestartupbible.com/2024/11/rise-of-the-korean-products-and-brands.html",
        "pubDate": "Wed, 20 Nov 2024 21:36:00 +0000",
        "content:encodedSnippet": "우리가 투자를 시작한 게 2012년인데, 이때부터 ‘한류’라는 말이 있었고, 한국인과 한국 제품이 드디어 한국을 벗어나서 세계 시장으로 나갈 수 있는 발판이 마련됐다고 이야기했었다. “Taking Korea global”이라는 말을 지난 10년 동안 너도나도 했지만, 솔직히 지금까진 말만큼 멋지게 실현되진 않았다. “지금까진.”\n작년, 그리고 올해 내내 미국, 유럽, 동남아, 일본을 여러 번 다니면서 내가 확실히 느낀 건, 이제 정말로 한국이 세계 시장으로 아주 자신 있게 나갈 수 있는 시점이 됐다는 점이다. 전에 ‘제2의 한류’라는 말을 내가 했는데, 이제 한국은 전 세계의 문화에 영향을 주는 global cultural force가 됐다. 인류 역사상 전 세계의 문화에 영향을 주는 cultural force가 된 국가는 아주 오랜 시간 동안 강대국의 지위를 유지했고, 그 기간 더 발전해서 더 강대국이 된 사례가 매우 많다. 나는 한국이 이런 기운과 기회를 잘 활용해서 비록 땅덩어리는 작고 인구도 작지만, 엄청나게 잘 살고, 다른 나라의 존경을 받는 초강대국이 되길 바란다.\n한국이 global cultural force가 되면서 한국의 창업가들에겐 좋은 기회가 생기고 있고, 이들을 지원하는 우리 같은 VC에게도 큰 기회가 생기고 있다. 최근에 미국을 2주 정도 돌아다녔는데, 어디 가나 한국 브랜드와 제품이 인기가 많다는 걸 직접 실감할 수 있었다. 심지어 작은 시골 도시에 가도 한국 음악, 드라마, 화장품, 음식, 그리고 자동차에 대한 인기와 관심이 너무 많았는데, 이게 참 놀라웠다. “한국이 어떻게 이렇게 인기 있는 나라가 됐을까?”라는 질문을 스스로에게 여러 번 할 정도였다. 한강 작가의 노벨 문학상 수상도 참 신기한 게, 전 세계 8,000만 명만 하는 비주류 언어인 한국어로 평생 책을 쓴 작가가 노벨 문학상을 받았다는 건, 한국과 한국어가 대단한 global cultural force라고밖에 설명할 수 없다.\n왜 이렇게 한국은 하드웨어, 소프트웨어, 콘텐츠, 브랜드를 이렇게 잘 만들까? 나는 이게 한국의 DNA에 깊게 박혀 있는 경쟁과 생존본능 때문이라고 생각한다. 한국은 아주 작은 나라다. 이 작은 나라에서 5,000만 명이 다닥다닥 붙어 살면서 남들보다 더 성공하기 위해 정말 빡세게 경쟁한다. 가끔 이 과한 경쟁의식이 부정적인 결과를 만들지만, 어쨌든 한국은 전 세계에서 가장 열심히 일하고, 가장 치열하게 살고, 가장 남보다 더 잘하기 위해서 수단과 방법을 가리지 않고 사는 사람들이 많은 국가이다. 좋든 싫든, 이건 우리의 타고난 기질이자 환경이다.\n이렇게 경쟁이 치열한 곳에서 만들어졌고, 이 치열한 시장에서 팔리고 있고, 여기서 살아남을 수 있다면 기본적으로 좋은 제품이다. 그래서 한국에서 잘 되는 제품이 미국과 같은 해외 시장으로 진출하면, 기본적으로 잘 될 가능성이 높다. 엄청 까다롭고, 엄청 치열하고, 엄청나게 경쟁하고, 동시에 엄청나게 잘 사는 소비자들이 많은 한국 시장에서 팔린다면, 제품 자체는 이미 입증된 것이다. 소비자들은 지갑으로 투표하는데, 지갑으로 투표하기 위한 기본 조건은 품질이기 때문이다.\n그러면, 왜 모든 한국의 제품이 미국 시장에서 대박 나지 않나? 왜 일부만 잘 되고, 대부분 실패하는가?\n어떤 제품과 회사는 한국에서 증명되기도 전에 너무 일찍 해외 진출을 시도하는데, 제품도 준비가 덜 됐고, 이 덜 준비된 제품을 마케팅하고 판매할 사람들도 준비가 덜 된 경우가 많다. 이런 회사는 미국 시장에서 백전백패한다.\n하지만, 이미 한국에서 품질이 증명된 제품도 미국 시장에서 실패하는 경우가 너무 많다. 여기서 우리가 말하는 globalization의 어려움이 작용하는 것이다. 제품은 좋지만, 이걸 다른 시장의 다른 소비자들에게 홍보하고 판매하기 위해서는 미세 조정을 많이 해야 하는데, 미국 시장을 잘 모르는 분들은 이 미세 조정을 어떻게 해야 하는지 감을 잘 못 잡는다. 이 미세조정에 수백억 원 또는 수천억 원을 투자하고, 결국엔 미국 시장에서 철수한 한국 회사들도 너무 많은 걸 보면, 이게 참 어려운 일인 것 같다.\n하지만, 내가 이번에 미국 시장에서 봤던 가능성은, 위에서 말했듯이 Korea라는 나라의 이미지 자체가 너무 좋아지고, 동시에 global cultural force가 되고 있기 때문에, 한국 제품과 브랜드가 미국 시장에서 거쳐야 하는 미세조정의 폭이 점점 더 좁아지고 있다는 점이다. 심지어 어떤 제품은 포장지에 한글이 그대로 적혔는데도 불티나게 팔리고 있었다.\n지난 20년 동안 말만 많고 결과는 별로였던 “Taking Korea global”. 이제 정말 그 타이밍이 온 것 같다. 제2의 한류를 타고 더 많은 한국 회사와 제품이 해외 시장을 – 특히 북미 시장 – 쓰나미같이 강타해서 글로벌 무대를 찢어버리는 이 움직임에 스트롱도 큰 기여를 할 수 있길 바란다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/11/rise-of-the-korean-products-and-brands.html#comments",
        "content": "우리가 투자를 시작한 게 2012년인데, 이때부터 ‘한류’라는 말이 있었고, 한국인과 한국 제품이 드디어 한국을 벗어나서 세계 시장으로 나갈 수 있는 발판이 마련됐다고 이야기했었다. “Taking Korea global”이라는 말을 지난 10년 동안 너도나도 했지만, 솔직히 지금까진 말만큼 멋지게 실현되진 않았다. “지금까진.” 작년, 그리고 올해 내내 미국, 유럽, 동남아, 일본을 여러 번 다니면서 내가 확실히 느낀 건, 이제(...)",
        "contentSnippet": "우리가 투자를 시작한 게 2012년인데, 이때부터 ‘한류’라는 말이 있었고, 한국인과 한국 제품이 드디어 한국을 벗어나서 세계 시장으로 나갈 수 있는 발판이 마련됐다고 이야기했었다. “Taking Korea global”이라는 말을 지난 10년 동안 너도나도 했지만, 솔직히 지금까진 말만큼 멋지게 실현되진 않았다. “지금까진.” 작년, 그리고 올해 내내 미국, 유럽, 동남아, 일본을 여러 번 다니면서 내가 확실히 느낀 건, 이제(...)",
        "guid": "https://www.thestartupbible.com/?p=9275",
        "categories": [
          "Uncategorized",
          "FoundersAtWork",
          "global",
          "korea",
          "Strong"
        ],
        "isoDate": "2024-11-20T21:36:00.000Z"
      }
    ]
  },
  {
    "name": "Build a Great Product",
    "category": "개인",
    "posts": []
  },
  {
    "name": "지금 써보러 갑니다",
    "category": "개인",
    "posts": []
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": [
      {
        "title": "Redlock 알고리즘 알아보기",
        "link": "https://hudi.blog/redlock-algorithm/",
        "pubDate": "Sat, 23 Nov 2024 00:00:00 GMT",
        "content:encodedSnippet": "블로그에 글을 오랜만에 쓴다. 요즘 공부한 대부분의 내용은 개인 옵시디언에 작성하고 있어서, 블로그 같이 공개적인 공간에 글을 발행할 일이 없었는데, 의식적으로 블로그에도 글을 써보려 해야겠다.\n최근에 Redlock 알고리즘에 대해서 가볍게 공부했는데, 이 내용을 정리해본다.\n\n분산 락이 보장해야하는 속성\n레디스 공식 문서에서는 아래와 같이 분산락이 보장해야하는 3가지 속성에 대해 제시한다.\n상호 배제 (Mutual Exclusion) : 특정 시점에 하나의 클라이언트만 락을 획득할 수 있어야 함\n교착 상태 없음 (Deadlock Free) : 먼저 락을 획득한 클라이언트가 장애(다운, 네트워크 단절 등)가 발생하더라도 락을 획득할 수 있어야 함\n내결함성 (Fault Tolerance) : Redis 노드의 과반수가 동작중이라면 클라이언트는 락을 획득/해제가 가능해야함\nRedlock 알고리즘은 어떻게 위 3가지 요건을 만족했는지 알아보자.\n\nRedlock 등장 배경\nRedlock 알고리즘이 어떤 문제를 해결하기 위해 등장했는지, Redlock 등장 이전의 분산락 구현 방식과 그 문제점을 알아보자.\n\n1. 단일 Redis 인스턴스의 문제\n\n    \n      \n    \n  \n  \n    \n    출처 : https://www.baeldung.com/cs/distributed-systems-prevent-single-point-failure\n  \nRedis 를 사용해서 락을 구현하는 가장 간단한 방법은 단일 Redis 인스턴스를 구성하는 방법이다. 락을 획득하고자 하는 클라이언트는 단일 Redis 인스턴스에서 키를 생성하고 TTL을 설정한다. 이 상태에서 다른 클라이언트가 락을 획득하려하면, 이미 해당 키가 설정되어 있으므로 실패한다. 이후 임계 영역 (Critical Section) 에서 작업을 마친 클라이언트는, 자신이 Redis 에 설정했던 키를 제거하여 락을 해제한다.\nRedis는 기본적으로 싱글 쓰레드로 동작 하기 때문에, 분산 환경에서의 경합을 크게 고려하지 않고도 간단하게 분산락을 구현할 수 있다.\n하지만, 문제는 단일 Redis 인스턴스는 단일 장애점(Single Point of Failure) 이라는 점이다. Redis 인스턴스에서 장애가 발생해 죽어버리면, 어떤 클라이언트도 임계 영역에서 작업을 수행할 수 없게 된다. 곤란한 일이다.\n\n2. Master-Slave 복제 아키텍처의 문제\n단일 Redis 인스턴스는 앞서 알아보았듯, 단일 장애점으로 인한 가용성 문제가 존재한다. 그렇다면, Master-Slave 복제 아키텍처를 사용하여 가용성을 높이는 방법을 사용하면 어떨까? 좋은 아이디어 같아 보인다. 적용해보자.\nMaster-Slave 로 Redis 를 구성했는데, 어느날 Master 노드에 장애가 발생했다. 다행히 Failover 메커니즘에 의해 Slave 가 Master 로 승격되면서, 장애는 빠르게 회복되었다. 그런데, 이상한 현상이 발생하였다. 장애가 발생한 당시, 2개의 클라이언트가 동시에 리소스에 접근하여 동시성 이슈가 발생한 것이었다. 왜 이런일이 발생했을까?\n\n    \n      \n    \n  \n  \n    \n    출처 : https://medium.com/@anil.goyal0057/distributed-locking-mechanism-using-redis-26c17d9f3d5f\n  \n이 문제는 Redis 의 복제 방식으로 인해 발생한다. Redis 는 비동기 복제 방식을 사용한다. 아래와 같은 시나리오를 생각해보자.\nClient A가 마스터에서 락을 획득함\nMaster에서 키에 대한 쓰기가 발생했지만, Slave로 복제되기 전에 마스터 노드가 다운됨\nSlave 노드가 새로운 Master로 승격됨\nClient B가 새로운 마스터로부터 락을 획득함\n이와 같은 상황을 복제 지연으로 인한 쓰기 유실 (Write Loss) 이라고 부른다. 이런 쓰기 유실이 발생한다면, 서로 다른 두 클라이언트가 동시에 임계 영역에 진입해 상호 배제 원칙이 위배될 수 있다.\nRedis 의 WAIT 명령을 사용하면 해결할 수 있을 것 같지만, WAIT 을 사용하다고 하더라도 동기 복제를 완전히 보장하지 않는다. WAIT 은 쓰기 명령이 Replica 로 도달하여 ACK 응답을 받은 시점 까지만 보장하며, 실제로 Replica 에 정상적으로 데이터가 쓰여지는 것 까지 보장하지 않는다. 또한 WAIT 에 timeout 을 설정하면, 일정 시간동안 ACK 응답을 받지 못했을 때, ACK 응답을 기다리는 것을 포기하고 다음 명령을 실행한다.\n즉, WAIT 을 사용하더라도 여전히 쓰기 유실이 발생할 가능성은 존재한다.\n\nRedlock 의 등장\n앞서 알아본 것 처럼, 단일 인스턴스를 사용하던 Master-Slave 복제 아키텍처 방식을 사용하던 Redis 는 높은 수준의 신뢰성을 제공하지 않는다. Redlock 을 사용하면, SPOF로 인한 가용성 문제와 복제 지연으로 인한 쓰기 유실 문제를 해결하면서, 안전하게 락을 제공할 수 있다.\n\n    \n      \n    \n  \n  \n    \n    출처 : https://careers.saigontechnology.com/blog-detail/implement-distributed-lock-for-a-microservices-software-system\n  \nRedlock 의 핵심 아이디어는 정족수(Quorum)이다. 정족수란, 회의나 투표가 유효하게 진행되기 위해 필요한 최소한의 참석 인원을 말한다. Redlock 에서도 이 의미는 동일하게 사용된다.\nRedlock 을 사용하기 위해서는 다수(일반적으로 5개)의 독립적인 (Standalone) Redis 인스턴스가 필요하다. 클라이언트는 이 Redis 노드 모두에게 순차적으로 락을 요청한다. 그리고 정족수(N/2 + 1) 이상의 노드들로부터 락을 획득했다면, 클라이언트는 자신이 락을 획득했다고 간주하고 임계 영역에 진입해 작업을 수행한다.\n일정 수 이상의 노드들로부터 락을 획득하면, 리소스의 락을 획득한 것으로 인정되므로, 일부 노드가 다운된 상태여도 문제 없다. 따라서 가용성 문제와 쓰기 유실 문제를 모두 해결할 수 있다.\nRedlock 을 위해 구성된 Redis 노드들은 같은 클러스터에 참여하거나, 복제를 하는 등 서로 연관되어 있어서는 안되며, 완전히 독립되어야 한다.\n이제 Redlock 알고리즘에 대해서 더 자세히 알아보자.\n\nRedlock 알고리즘\n\n1. 현재 시각을 ms 단위로 가져옴\n이 시간은 락 획득에 걸린 시간을 계산하기 위해 사용된다.\n\n2. 클라이언트는 모든 N개의 마스터 노드로부터 순차적으로 락 획득을 시도\n이떄, 클라이언트는 해당 키에 랜덤한 값을 저장한다. 아래에서 자세히 설명하겠지만, 이 랜덤 값은 락을 획득한 클라이언트만이 해당 락을 해제할 수 있도록 보장한다.\n특정 Redis 노드에 락이 이미 걸려있다면, 즉시 다음 노드로 넘어간다. 이런 상황이 발생했다면, 해당 클라이언트는 다른 클라이언트와 락 획득 경쟁이 발생한 상황일 것이다.\n\n3. 락 설정시 타임아웃을 적용\n클라이언트는 각 Redis 인스턴스에 락을 설정할 때, 한 노드를 너무 오래기다리지 않도록 타임아웃을 설정한다. 예를 들어, TTL이 10초 정도라면, 타임아웃은 5~50ms 정도로 작게 설정한다. 이렇게 하면, Redis 노드가 설령 다운된 상황이라도 오래 기다리지 않고 바로 다음 노드로 넘어갈 수 있다.\n\n4. 락 획득 성공 여부 판단\n클라이언트는 모든 Redis 노드로부터 락 설정 시도를 마치고, 과반수(N/2 + 1) 이상의 인스턴스에서 락을 획득 했는지 확인한다. 과반수 이상의 Redis 노드로부터 락을 설정하는데 성공했다면, 클라이언트는 자신이 락 획득에 성공했다고 판단한다.\n\n5. 락 유효 시간 계산\n클라이언트는 락 유효 시간(Lock Validity Time)을 계산한다. 락 유효 시간은 이름 그대로 락이 유효한 시간을 나타내며, 클라이언트는 락 유효 시간 만큼 임계영역에서 작업을 할 수 있다. 락 유효 시간은 아래와 같이 계산한다.\nLockValidityTime=TTL−(T2−T1)Lock Validity Time = TTL - (T2 - T1)LockValidityTime=TTL−(T2−T1)\n각 변수의 의미는 아래와 같다.\nTTL : Redis 키에 설정된 TTL. 이는 락의 초기 유효 시간을 나타낸다.\nT1 : 최초 노드에서 Key가 SET 된 최악의 시각 (첫번째 노드에 통신하기 전에 얻어온 시각)\nT2 : 마지막 노드에서 Key가 SET 된 최악의 시각 (마지막 노드로부터 응답을 받은 시각)\n(T2−T1)(T2 - T1)(T2−T1) 은 클라이언트가 락을 획득하는 데 소요된 총 시간으로, 이 시간이 길어질수록 실제로 락을 보유할 수 있는 시간이 줄어든다.\n\n6. 락 획득 실패 시 처리\n만약 클라이언트가 락 획득에 실패한 경우, 모든 Redis 인스턴스에서 락을 해제한다.\n\nRedlock 의 실제 구현\n레디스 공식 문서에서는 Redlock 구현 방식을 아래와 같이 제시한다.\n\n1. Redis 명령으로 락 획득\n클라이언트는 아래와 같은 SET 명령을 수행하여 락을 획득한다.\nSET resource_name my_random_value NX PX 30000\n\n\nNX : 키가 존재하지 않을 때만 값을 설정한다.\nPX : 키의 TTL을 밀리세컨드 단위로 설정한다.\n\n2. Lua Script 를 사용하여 락 해제\n락 해제 작업을 Atomic 하게 수행하기 위해, 클라이언트는 아래와 같은 Lua Script 를 실행하여 락을 해제한다.\nif redis.call(\"get\", KEYS[1]) == ARGV[1] then\n\treturn redis.call(\"del\", KEYS[1])\nelse\n\treturn 0\nend\n\n\nKEYS[1] : 해제하려는 락의 Key 를 지정. 여기서는 resource_name 에 해당하는 값을 전달한다.\nARGV[1] : Lua Script 에서 사용할 인자의 값. 여기서는 my_random_value 에 해당하는 값을 전달한다.\n\nmy_random_value 가 무엇인가?\n여기에서 my_random_value 라는 랜덤한 값이 등장한다. 이 값은 락을 획득한 클라이언트만이 락을 해제할 수 있도록 보장하는데 사용된다.\n만약 레디스 키에 대한 DEL 명령을 누구나 실행할 수 있다면, 락을 획득하지 않은 클라이언트가 임의로 락을 해제하고 자신이 락을 획득할 수 있게 되고, 이는 상호 배제의 위반이다.\n이를 방지 하기 위해서, 락을 설정할 때 클라이언트가 랜덤 값을 생성하고, 락 Key의 Value 로 사용한다. 그리고 락을 해제할 때, 자신이 생성한 랜덤 값을 제시해서, 일치하는 경우에만 락을 해제한다 (Lua Script 의 로직). 이는 클라이언트가 락의 소유권을 증명하는 일종의 비밀번호라고 할 수 있다.\n\nRedlock 주의점\n\nClock Drift 문제\nRedlock 알고리즘에서 Redis 노드들 그리고 클라이언트 간에 동기화된 시계 (Synchronized Clock)가 존재하지 않는다. 그리고 Redlock 알고리즘은 참여자간의 로컬 시간이 거의 동일한 속도로 갱신된다는 가정에 의존한다.\n하지만 현실에서는 로컬 시계가 정확한 속도로 동작하지 않는 Clock Drift 현상으로, 시스템 내부 시계가 실제 시간과 불일치하는 현상이 발생할 수 있다. 이런 현상은 하드웨어 문제, 운영체제 스케줄링 문제 등 다양한 원인으로 인해 발생할 수 있다.\n\nClock Drift 발생 시나리오\nClock Drift 현상이 발생하면, 한 Redis 노드에서는 락이 유효하다고 판단하는 반면, 다른 노드에서는 해당 락이 이미 만료되었다고 판단할 수 있다. 예를 들자면, 아래와 같은 시나리오이다.\n5개의 레디스 노드가 존재하고, 3개의 노드에서 락을 획득하면, 락이 유효한 상황\n클라이언트 1은 A, B, C 노드에서 락을 획득했으나, 네트워크 에러로 D와 E 노드에서 실패\n노드 C의 시계가 클럭 드리프트로 인해, 시간이 미래로 점프했고, 조기에 TTL이 만료됨\n이 시점에 클라이언트 2가 C, D, E 에서 락을 획득함\n\nMIN_VALIDITY\n따라서, 클라이언트는 락 유효 시간에서 클럭 드리프트를 보정한 값인 MIN_VALIDITY 를 계산하고, 자신이 획득한 락의 안정성을 판단해야한다.\nMIN_VALIDITY 는 아래와 같이 계산한다.\nMIN_VALIDITY=TTL−(T2−T1)−CLOCK_DRIFTMIN\\_VALIDITY = TTL - (T2 - T1) - CLOCK\\_DRIFTMIN_VALIDITY=TTL−(T2−T1)−CLOCK_DRIFT\n클라이언트는 이와 같이 MIN_VALIDITY 를 계산하고, 아래와 같이 락 안정성에 대해 판단한다.\nMIN_VALIDITY 가 음수거나 너무 짧다면 : 락이 불안정하다고 판단하고, 사용을 중단하거나 락을 해제한다.\nMIN_VALIDITY 가 충분히 크다면 : 락이 안정적이라고 판단하고 작업을 진행한다.\n\nCLOCK_DRIFT 계산\n그렇다면, CLOCK_DRIFT 는 어떻게 계산할까? 일반적으로 CLOCK_DRIFT_FACTOR 라는 값을 활용하여 CLOCK_DRIFT 값을 계산한다. 산식은 아래와 같다.\nCLOCK_DRIFT=TTL∗CLOCK_DRIFT_FACTOR+δCLOCK\\_DRIFT = TTL * CLOCK\\_DRIFT\\_FACTOR + δCLOCK_DRIFT=TTL∗CLOCK_DRIFT_FACTOR+δ\n일반적으로 CLOCK_DRIFT_FACTOR 의 값은 1%로 설정하는데, 이는 네트워크 시간 프로토콜(NTP)을 통한 시계 동기화의 정확도에 기반한다고 한다.\nNTP의 정확도에 대한 연구에 따르면, NTP를 통해 동기화된 시스템 간의 시계 오차는 일반적으로 수 밀리초에서 수십 밀리초 수준으로, 전체 시간의 약 0.01%에서 0.1%에 해당한다고 한다. 따라서, 보수적인 접근으로 1%를 CLOCK_DRIFT_FACTOR 로 설정하여 시계 드리프트를 고려하는 것이 일반적이다.\n\nSplit-brain Condition\n클라이언트가 락을 획득하는데 실패한 경우, 재시도 정책에 따라 락 획득을 재시도할 수 있다. 그런데 만약 재시도 하려는 클라이언트가 많다면, 동시에 재시도 요청이 쇄도하는 Retry Storm 이 발생할 것이다. 이렇게 리소스에 대해 경쟁하면, 계속해서 충돌이 발생하고, 그 어떤 클라이언트도 과반수 이상의 인스턴스에서 락을 획득할 수 없다. 이런 상황을 Split-brain 상태라고 부른다.\n이를 해결하기 위해서, 레디스 공식 문서는 아래의 3가지 방법을 제시한다.\n랜덤 딜레이 : 클라이언트들이 동일한 시간에 동시에 시도하지 않도록, 재시도 간격을 무작위로 적용하여 타이밍을 분산시킨다.\n멀티 플렉싱 : 클라이언트는 모든 Redis 인스턴스에 병렬로 동시에 락 요청을 보낸다. 락 요청 속도가 빨라지면, 여러 클라이언트가 동시에 요청하는 Time Window 가 줄어들어, Split-brain 가능성이 감소한다.\n빠른 락 해제 : 클라이언트가 과반수 락 획득에 실패했다면, 즉시 부분적으로 획득한 락을 해제해야한다. 다른 클라이언트가 락을 요청할 때 키 만료를 기다리지 않도록 해, 락 충돌 가능성을 줄이고 가용성을 높인다.\n\n애플리케이션 중단 및 네트워크 지연으로 인한 문제\n만약 락을 획득한 클라이언트가 Full GC로 인한 Stop-the-world 가 발생하는 등 긴 지연에 걸리거나, 네트워크 지연이 발생한 경우, 지연이 해소되는 동안 TTL이 먼저 만료되는 상황이 발생할 수 있다. 이 경우 기존 클라이언트의 지연이 해소되기 전에, 다른 클라이언트가 락을 획득하고 임계 영역에 진입할 수 있다.\n이런 상황에서 지연된 애플리케이션이 다시 복구되었을 때, 자신의 락이 만료됨을 인지 못한다면, 그대로 임계 영역에서 다시 작업을 이어나갈 수 있고, 이는 상호 배제의 위반이다.",
        "content": "블로그에 글을 오랜만에 쓴다. 요즘 공부한 대부분의 내용은 개인 옵시디언에 작성하고 있어서, 블로그 같이 공개적인 공간에 글을 발행할 일이 없었는데, 의식적으로 블로그에도 글을 써보려 해야겠다. 최근에 Redlock…",
        "contentSnippet": "블로그에 글을 오랜만에 쓴다. 요즘 공부한 대부분의 내용은 개인 옵시디언에 작성하고 있어서, 블로그 같이 공개적인 공간에 글을 발행할 일이 없었는데, 의식적으로 블로그에도 글을 써보려 해야겠다. 최근에 Redlock…",
        "guid": "https://hudi.blog/redlock-algorithm/",
        "isoDate": "2024-11-23T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "소득공제 40% 혜택에 카드사용실적 반영까지 : 충전식 카드형 온누리상품권",
        "link": "https://blog.toss.im/article/money-policies-30",
        "pubDate": "Fri, 22 Nov 2024 03:58:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}온누리상품권을 더 쉽고 편하게 사용하는 방법을 소개합니다. 온누리상품권은 5천원, 1만원, 3만 원권 단위로 구매해 사용할 수 있는 소상공인시장 진흥공단에서 발행하는 지류상품권이에요. 액면가의 10% 할인된 금액으로 구매할 수 있고, 전통시장이나 다양한 상점에서 사용할 수 있어요.\n이런 온누리상품권을 종이 상품권이 없어도 언제 어디서든 사용할 수 있는 방법이 있는데요. 온누리상품권 모바일 앱에 내 카드를 등록 후 금액을 충전하고, 평소처럼 카드를 사용하면 돼요. 카드로 결제해도 온누리 상품권 할인혜택은 그대로 누릴 수 있어요.\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}지류 상품권과 마찬가지로 10% 할인가로 금액을 충전할 수 있어요. 10만 원을 충전하고 싶으면 9만 원만 결제하면 돼요. 전통시장 소득공제 혜택(최대 40%)과 온라인상품권 충전금액은 카드 사용실적에도 반영돼요. 평소 현금보다 카드 사용이 많은 소비자라면 더 유리하겠죠?\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n가입방법\n.css-hokoge{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;counter-reset:numberedList;}.css-hokoge ul,.css-hokoge ol{margin:16px 0 0;}.css-hokoge>li{counter-increment:numberedList;margin-bottom:16px;padding-left:24px;}.css-hokoge>li:last-of-type{margin-bottom:0;}.css-hokoge>li>span{position:relative;}.css-hokoge>li>span>:first-child::before{content:counter(numberedList) '.';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n온누리상품권 앱 다운로드 후 본인 명의의 신용카드나 체크카드*등록  \n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*신한, 현대, 삼성, 농협, 하나, 비씨, 국민, 롯데\n충전할 계좌를 선택하고 원하는 금액 입력\n\n충전 가능한 최대 금액은 월 200만 원이에요. 다만 충전액을 초과해 결제할 경우엔 전액이 일반카드로 결제되니 이 점 유의하세요. \n만약 온누리상품권을 자주 사용한다면 이런 경우에 대비해 ‘자동충전’ 기능을 활용하면 좋아요. 원하는 금액과 날짜를 설정해놓으면 잔액을 일정 금액 이상으로 늘 유지할 수 있어요. 매번 사용액을 신경쓰며 충전할 필요 없이 편리하게 사용이 가능해요.\n온누리상품권을 사용할 수 있는 가맹점도 앱에서 확인할 수 있어요. 앱에서 ‘가맹점 찾기’ 탭을 누르면 내 주변의 온누리상품권 사용처를 알 수 있고 ‘지도로 보기’를 누르면 위치까지 한눈에 파악할 수 있어요. 지역별·시장별 매장까지 검색할 수 있어요.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}Edit 이지영 Graphic 조수희 이제현",
        "content": "온누리상품권을 가장 쉽게  쓰는 방법을 소개해요.",
        "contentSnippet": "온누리상품권을 가장 쉽게  쓰는 방법을 소개해요.",
        "guid": "https://blog.toss.im/article/money-policies-30",
        "isoDate": "2024-11-22T03:58:00.000Z"
      },
      {
        "title": "연말정산 세액공제, 올해 마지막 절세 기회를 놓치지 마세요",
        "link": "https://blog.toss.im/article/economic-terms-37-year-end-tax-adjustment",
        "pubDate": "Thu, 21 Nov 2024 02:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-8atqhb{width:100%;}.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}이 글에서 알 수 있는 것들\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1kxrhf3{white-space:pre-wrap;}연말정산으로 세금을 환급받을 수 있는 실전 꿀팁\n소득공제와 세액공제 대체 어떻게 다른지?\n퇴직연금 실물이전 서비스 활용법\n\n.css-1c1qox8{font-size:30px;letter-spacing:0em;line-height:1.55;font-weight:bold;color:var(--adaptiveGrey900);margin:40px 0 4px;}\n.css-p4abj2{display:contents;line-height:1.55;}🔖 이번 주 경제 용어\n연말정산 세액공제\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n이번 주 경제 용어는 노후에 잘 살기 위해 필요한 정보예요.\n\n.css-1pgssrp{max-width:100%;border-radius:16px;}\n연말정산에서 산출된 세금에서 일정 금액을 직접 차감하는 방식이에요.\n\n\n어느새 2024년도 한 달밖에 남지 않았습니다. 올해가 다 가기 전에 해야 할 일이 무엇이 남았을까요? 만나야 할 사람도 떠오르고, 쓰지 못했던 휴가도 떠오릅니다. 재테크도 제대로 못 한 것 같아 아쉬운 마음도 들고요. 하지만 아직 희망이 하나 남아있어요. 바로 ‘연말정산’입니다. 올해는 연말정산을 조금 더 일찍 준비해 보시죠.\n연말정산은 근로소득자가 1년간 납부한 세금과 실제 납부해야 하는 세금을 비교하여 조정하는 절차입니다. 같은 연봉을 받더라도, 연말정산을 어떻게 준비하느냐에 따라 돌려받을 수 있는 세금의 차이가 크게 날 수 있는 거죠.\n올해 연말정산은 내년 1월 국세청의 '연말정산 간소화 서비스'가 오픈되면 시작되지만, 세금을 좀더 환급받고 싶다면 소득공제와 세액공제 항목을 12월 31일 전까지 미리 챙겨두는 것이 좋습니다.\n소득공제와 세액공제는 그렇게 어려운 개념이 아닙니다. 쉽게 말해 소득공제는 연 소득에서 일정 금액을 빼서 세금을 줄이는 것이고, 세액공제는 이미 계산된 세금에서 일정 금액을 빼주는 것입니다.\n고연봉자분들은 과세표준 구간이 높기 때문에 소득공제를 잘 활용해서 세율을 낮추는 것이 유리하고, 일반 연봉자분들은 세액공제를 통해 내야 할 세금을 줄이는 것이 더 효과적일 수 있습니다.\n\n소득공제 대상: 인적공제, 특별소득공제, 개인연금저축(2001년 이전 가입자만 가능), 주택마련저축, 신용카드 사용금액, 주택청약종합저축 등\n세액공제 대상: 교육비, 의료비, 보장성 보험료, 연금저축, 개인형 퇴직연금 등\n\n그런데 지금 소득공제를 받겠다고 가족 구성원을 늘릴 수도 없고, 세액공제를 받겠다고 교육비나 의료비를 마구 쓸 수도 없습니다. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}그렇다면 가장 현실적인 절세 방법은 무엇일까요? 바로 ‘연금’을 활용하여 세액공제를 받는 겁니다.\n대표적으로 연금저축과 퇴직연금 관련 금융상품을 활용하는 건데요. 개인연금으로 세액공제를 받을 수 있는 납입 한도는 최대 900만 원입니다. 연금저축펀드는 600만 원까지, 개인형퇴직연금(IRP)을 포함하면 900만 원까지 납입할 수 있으며, 이를 모두 채우면 최소 118만 8천 원에서 최대 148만 5천 원까지 환급받을 수 있습니다.\n\n.css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}🔗 함께 읽으면 좋은 아티클: 연금저축 vs IRP 내게 맞는 노후대비 연금 상품은?\n\n\n.css-2yhypk{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);font-style:italic;-webkit-text-decoration:underline!important;text-decoration:underline!important;}“은행이자보단 더 줘야할 것 아냐”...갈아타기 시작된 퇴직연금, 운용 잘하는 곳 어디?\n(매일경제 2024.10.31)\n퇴직연금 상품을 중도해지 없이 다른 금융사로 손쉽게 이전할 수 있는 현물(실물)이전 제도가 오늘부터 시행된다. 400조원 규모의 퇴직연금 시장을 둘러싼 금융사간 경쟁이 치열해질 전망이다.\n31일 금융권에 따르면 이날부터 퇴직연금 현물이전 제도가 본격 시행된다. 앞서 고용노동부·금융감독원·한국예탁결제원 등이 지난해 2월 태스크포스팀을 구성해 관련제도 마련에 나선지 1년8개월 만이다.\n퇴직연금 현물 이전 제도는 말 그대로 현재 퇴직연금 계좌에서 굴리는 상품을 해지하지 않고, 현 상태로 다른 금융사 계좌로 옮길 수 있게 하는 것이다. 퇴직연금 가입자가 수익률이 더 높은 금융사로 쉽게 이동할 수 있도록 선택권을 보장하기 위한 조치다. (중략)\n\n\n연말정산을 잘 활용하면 꽤 큰 금액을 환급받을 수 있습니다. 매년 찾아오는 절세 기회를 미리 준비하는 것이 중요해요.\n특히 이번에 도입된 ‘퇴직연금 실물이전 서비스’를 통해 기존 퇴직연금 상품을 다른 금융사로 쉽게 옮길 수 있게 되면서, 이왕 드는 퇴직연금을 더 나은 수익률을 제공하는 금융사로 이전하기가 한층 쉬워졌습니다. 만약 퇴직연금이 오랫동안 방치되어 있었다면 이번 기회를 활용해 다양한 금융사의 수익률과 수수료를 비교해 보고, 더 좋은 조건을 제공하는 곳으로 옮겨보세요. 단순히 금융사를 바꾸는 것만으로도 노후 자금을 크게 늘릴 수 있는 기회가 될 것입니다.\n기존에도 퇴직연금을 다른 금융사로 옮길 수 있었지만, 기존 상품을 매도하고 다시 매수해야 하는 번거로움과 손실 위험 때문에 많은 분들이 망설이셨습니다. 그러나 이제 퇴직연금 실물이전 서비스를 통해 이에 대한 부담이 크게 줄어들었습니다. 퇴직연금을 더 높은 수익률을 제공하는 금융사로 옮기는 것이 훨씬 간편해졌고, 이는 금융사 간 경쟁을 촉진시켜 우리 같은 고객들에게 더욱 유리한 환경을 만들어줄 것입니다.\n그렇다면 실물이전 서비스를 어떻게 활용해야 할까요? 우선적으로 할 일은 현재 내 퇴직연금 계좌를 확인하는 것입니다. 내 퇴직연금이 어디에 있는지, 어떤 상품에 투자되고 있는지를 파악하고, 현재 수익률이 어느 정도인지 확인해야 합니다. 만약 지금 운용 중인 상품이 수익률이 좋지 않거나, 다른 금융사에 비해 상대적으로 높은 수수료를 부과하고 있다면 이전을 고려하시는 게 좋겠습니다.\n\n💡 퇴직연금 실물이전 서비스 이용하려면?\n\n이전할 금융기관 선택 및 계좌 개설 → 실물이전 가능 상품 확인 → 기존 금융기관에 실물이전 신청 → 이전 절차 진행 및 완료\n퇴직연금 실물이전은 동일한 유형의 퇴직연금 제도(DB↔DB, DC↔DC, IRP↔IRP) 간에만 가능해요.\n이전하려는 금융기관에서 동일한 상품을 취급하지 않는 경우, 실물이전이 불가능할 수 있어요.\n\n\n\n.css-1lvcgm8{padding:22px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;border-radius:20px;}\n.css-13ko30i{width:375px;}토스에서 퇴직연금 손쉽게 옮기기\n\n연금저축펀드: 개인이 노후를 대비해 가입할 수 있는 연금 상품으로, 세액 공제를 받을 수 있어요. 100%까지 위험 투자 상품 운용이 가능하며, 납입한 금액에 대해 일정 금액의 세금을 공제받을 수 있습니다.\nDC형 퇴직연금: 확정기여형 퇴직연금 제도로, 회사가 근로자에게 일정 금액을 퇴직연금으로 납입하면, 그 금액을 근로자가 직접 운용하여 수익을 얻는 방식이에요. 근로자가 운용 결과에 따라 연금의 수익이 달라질 수 있습니다.\nIRP(개인형퇴직연금): 근로자가 퇴직 후의 노후 생활을 대비하기 위해 운용하는 퇴직연금 계좌. 70%까지 위험 상품에 투자할 수 있고 세액공제 혜택도 받을 수 있어서, 연금저축과 더불어 노후 자금을 마련하는 데에 유리해요.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 금혜원 Graphic 조수희 이동건",
        "content": "세금 환급을 위한 마지막 한 달, 놓치지 말아야 할 준비사항 총정리",
        "contentSnippet": "세금 환급을 위한 마지막 한 달, 놓치지 말아야 할 준비사항 총정리",
        "guid": "https://blog.toss.im/article/economic-terms-37-year-end-tax-adjustment",
        "isoDate": "2024-11-21T02:00:00.000Z"
      },
      {
        "title": "토스인컴, ‘숨은 환급액 찾기’ 서비스 이용 고객 대상 토스포인트 지급 이벤트",
        "link": "https://blog.toss.im/article/tossincome-event",
        "pubDate": "Thu, 21 Nov 2024 01:30:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}비바리퍼블리카(이하 토스)의 자회사 토스인컴(대표 박일용)이 셀프 세금관리 서비스인 ‘숨은 환급액 찾기’ 를 이용하는 고객을 대상으로 토스포인트 지급 이벤트를 연다고 21일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n숨은 환급액 찾기 서비스를 통해 예상 환급액을 확인한 뒤 두 개의 카드 중 당첨 카드를 고르면 예상 환급액 만큼 토스포인트를 받을 수 있는 이벤트다. 신고까지 마쳐야 토스포인트를 지급하며 신고를 취소한 경우 지급된 토스포인트는 회수된다.\n이벤트는 다음 달 17일 까지 한 달간 진행한다. 단, 예산 소진 시 이벤트가 조기 종료될 수 있다. 당첨 카드를 뽑지 못하거나 예상 환급액이 없는 고객은 랜덤 포인트를 받을 수 있다.\n토스인컴의 숨은 환급액 찾기 서비스를 이용하기 위해서는 토스 앱 > 전체 탭 > ‘세금・납부・민원’ 카테고리 > ‘내 환급액 확인하기’로 들어가거나 토스 앱 상단 돋보기 아이콘을 눌러 ‘숨은 환급액 찾기’ 또는 ‘세이브잇’을 검색하면 된다.\n한편 토스인컴은 토스가 지난 5월 세이브잇 운영사 택사스소프트를 인수하면서 출범했다. 숨은 환급액 찾기 서비스는 기한 후 신고 뿐 아니라 경정청구를 지원하고 중소기업 취업자 소득세 감면 등 다양한 항목의 셀프 신고를 지원하는 것이 특징이다.\n토스인컴 관계자는 “세금관리는 매일 써야 할 서비스는 아니지만, 금융 생활에서 반드시 마주치게 되는 영역”이라며 “토스인컴은 개인이 스스로 해결하기 어려운 세무 영역의 불편을 해소하고 누구나 쉽고 정확하게 세금 정산을 할 수 있는 세상을 만들어 가겠다”고 말했다.",
        "content": " 예상 환급액 조회하고 당첨 카드 고르면 예상 환급액 만큼 토스포인트 지급",
        "contentSnippet": "예상 환급액 조회하고 당첨 카드 고르면 예상 환급액 만큼 토스포인트 지급",
        "guid": "https://blog.toss.im/article/tossincome-event",
        "isoDate": "2024-11-21T01:30:00.000Z"
      },
      {
        "title": "토스 유튜브 채널 '머니그라피', 팝업 이벤트 개최",
        "link": "https://blog.toss.im/article/moneygraphy-popup",
        "pubDate": "Wed, 20 Nov 2024 01:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}오프라인에서 경험하는 머니그라피… 12월 6일부터 8일까지 성수동에서 열려\nB주류경제학 등 상시 전시와 7개의 라이브 토크쇼로 구성\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n모바일 금융 서비스 '토스'를 운영하는 비바리퍼블리카(이하 토스)가 자사 유튜브 채널 '머니그라피’의 팝업 이벤트를 12월 6일(금)부터 8일(일)까지 개최한다고 20일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n머니그라피는 2021년 9월 첫 영상을 시작으로 취향과 경제를 잇는 콘텐츠를 선보이고 있다. 소비문화 이면의 경제 이야기를 다루는 ‘B주류경제학’, 음악 산업에 관해 이야기하는 ‘머니 코드’, 한국의 소비문화와 트렌드를 탐구하는 ‘K’s스터디’ 등 다양한 시리즈가 사랑을 받으며 개설 3년여 만에 구독자가 36만 명을 넘어섰다.\n이번 팝업 이벤트는 12월 6일부터 8일까지 사흘간 성수동 세원정밀 창고에서 열린다. 공간은 차고(개러지, Garage) 콘셉트로 꾸미고 B주류경제학, 머니 코드, K’s스터디 등 크게 세 개의 파트로 구성했다. B주류경제학 스튜디오를 그대로 구현해 놓은 포토존부터 미공개 클립을 확인할 수 있는 비디오 렌털숍, 제작 현장을 간접 체험할 수 있는 편집실, 머니 코드 레코드숍, K's스터디 문방구 등 머니그라피를 다양한 방법으로 체험할 수 있다. 이에 더해 포토카드, 포스터, 티셔츠, 양말, 모자 등 브랜딩 굿즈도 판매해 팬심을 공략한다.\n예약 후 참여할 수 있는 7개의 라이브 토크쇼도 마련했다. 팝업 공간의 한 쪽에 라이브 스테이지를 설치, 사흘간 다양한 테마의 토크쇼를 운영한다. 첫째 날인 6일에는 K’s스터디를 테마로 진행자인 존박과 레오가 출연하는 세션이 열린다. B주류경제학을 테마로 하는 둘째 날에는 프로그램에 출연 중인 이재용 회계사와 토스 김창선 PD가 총 네 개의 토크쇼를 진행한다. 마지막 날인 8일에는 머니 코드를 테마로 진행자인 룩삼과 우키팝이 출연한다. 오후 6시 30분부터는 피날레로 넉살X까데호, 힙노시스테라피의 미니 콘서트도 연다.\n머니그라피 채널 연출을 총괄하는 토스 백순도 PD는 “머니그라피는 온라인 공간에서 시청자들과 활발하게 소통해오며 커온 채널이기에 오프라인에서 직접 만날 수 있는 기회를 마련하고 싶었다”라며 “다양한 프로그램과 즐길 거리를 준비한 만큼, 머니그라피를 사랑해 주시는 많은 분들이 방문해 주시기를 바란다”라고 전했다.\n미니 콘서트를 제외한 라이브 토크쇼는 11월 22일(금) 오후 6시에 머니그라피 유튜브 채널에서 선착순으로 참가 신청이 가능하다. 1인당 세션별로 1회만 신청이 가능하며, 각 세션별로 선착순 모집한다. 미니 콘서트는 현장에서 접수를 받는다. 팝업 이벤트와 관련된 자세한 사항은 머니그라피 유튜브 채널 내 커뮤니티 탭 혹은 토스 공식 인스타그램에서 확인할 수 있다.",
        "content": "12월 6일부터 8일까지 성수동에서 운영",
        "contentSnippet": "12월 6일부터 8일까지 성수동에서 운영",
        "guid": "https://blog.toss.im/article/moneygraphy-popup",
        "isoDate": "2024-11-20T01:00:00.000Z"
      },
      {
        "title": "우리나라는 노벨문학상을 또 받을 수 있을까?",
        "link": "https://blog.toss.im/article/monthly-tosspick-2024-10",
        "pubDate": "Tue, 19 Nov 2024 00:58:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}따뜻한 축하의 마음들이 거대한 파도처럼\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1kxrhf3{white-space:pre-wrap;}10월 10일 저녁, 평소엔 쥐 죽은 듯 조용한 카톡이 갑자기 시끌벅적해졌습니다. 한강 작가의 노벨문학상 수상 소식이 전해지자 초등학교 동창, 대학 동기, 회사 동료들 채팅방까지 ‘대박’과 ‘감동’이 쏟아졌어요. 예고 없이 찾아온 대한민국의 첫 노벨문학상 소식에 ‘따뜻한 축하의 마음들이 거대한 파도처럼’* 퍼져나갔죠.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*한강 작가는 수상 직후 서면으로 “하루 동안 거대한 파도처럼 따뜻한 축하의 마음들이 전해져 온 것도 저를 놀라게 했다. 마음 깊이 감사드린다.”는 짧은 소감을 밝혔습니다.\n한강 작가의 노벨문학상 수상은 모두의 예상을 뛰어넘는 일이었습니다. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}스웨덴 한림원이 2012년부터 남녀를 번갈아 수상자로 선정했기 때문에 올해는 여성 작가가 유력하다고 봤지만, 후보로 주목받던 중국의 찬쉐를 제치고 한강이 선택된 것은 놀라움 그 자체였죠. 뉴욕타임스도 “한강의 수상은 서프라이즈”라며 출판가 역시 예상치 못했던 결과라고 전했습니다.\n온라인 반응 역시 기쁨과 환희로 넘쳤습니다. ‘오늘부터 ‘문송합니다’ 금지’, ‘국문과 졸업하면 무엇을 하냐고? 노벨문학상을 받는 거다!’ 같은 유쾌한 반응들이 넘쳤고, 노벨문학상 수상작을 원서로 읽을 수 있다는 뿌듯함도 더해졌죠.\n6일 만에 달성한 대형 출판사의 1년 매출\n노벨문학상 수상 이후 지금까지 출판 시장은 모처럼 활기를 되찾았습니다. 온라인 서점은 접속자가 몰려 마비되고, 오프라인 서점에서는 ‘오픈런’까지 이어졌죠. 인쇄소는 행복한 비명을 지르며 밤새 기계를 돌렸지만, 폭발적인 수요를 따라가지 못해 중고 앱에서는 한강 작가의 단행본이 14만 원까지 올라오기도 하고요.\n수상 단 6일 만에 한강 작가의 책은 100만 부가 판매되었습니다. 이 시기 예상 매출액이 유명 출판사의 한 해 매출 전체와 비슷하다고 하니, 한국 출판 시장에 그야말로 ‘기적’이 찾아온 셈입니다. 뿐만 아니라, 한강 작가의 도서를 제외한 국내 도서 판매량도 전년 대비 7% 증가하며 출판 업계에 활기를 불어넣었습니다.\n하지만 이런 경사 속에서도 동네 서점들은 큰 어려움을 겪어야 했는데요. 도·소매를 함께하는 대형 서점이 사실상 출판 유통을 독점해 한강 작가의 책을 찍어내고 판매하는 사이, 동네 책방들은 책을 구하지 못해 손님들을 되돌려 보내야 했거든요.\n논란이 계속되자 교보문고는 한강 작가의 책을 10월 22일부터 31일까지 한시적으로 판매하지 않고, 해당 기간 입고된 책은 모두 동네 서점에 공급하기로 결정했습니다. 노벨문학상은 한국의 ‘도서 유통 구조’까지 다시 한 번 돌아보게 했죠.\n매월 하나의 키워드를 선정해 경제적 시선으로 질문을 던져보는 <월간 토스픽>. 이번 달은 한강 작가의 《소년이 온다》를 편집한 김선영 편집자와 함께합니다. 한강 작가님과 함께 울어버린 비하인드부터 책 한 권을 팔면 출판사는 얼마를 남기는지, 출판업계의 수익 구조와 다음 노벨문학상 후보로 주목하면 좋을 작가들까지 살펴봅니다.\n\n\n우리나라는 노벨문학상을 또 받을 수 있을까?\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n🎙️ Interviewee 김선영\n\n한국문학 편집자로 활동하며 다수의 시집과 소설책을 만들었다. 책임편집을 맡은 주요 작품으로는 《소년이 온다》 《피프티 피플》 《달까지 가자》 《연년세세》 《철도원 삼대》 등이 있다. 현재는 출판사 .css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}핀드에서 '오래 간직할 책, 오래 기억될 이야기'를 모토로 책을 만들며 책 읽는 즐거움을 더하는 방법을 궁리하고 있다. 쓴 책으로 《아무튼, 스윙》이 있다.\n\n우리가 좋은 문학 작품을 \n만나기까지 벌어지는 일\n노벨문학상 발표 직후에 《소년이 온다》 담당 편집자임을 밝히며 축하 게시물을 올리셨지요. 기분이 어떠셨나요?\n막히는 강변북로 위에서 지루하게 운전을 하고 있었는데, 정신이 번쩍 들었습니다. 한강 작가님의 대표작을 함께 만든 편집자로서 이미 큰 자부심을 갖고 있었고, ‘언젠가 한국에서도 노벨문학상을 받는 날이 온다면 한강 작가님이 받을 것 같다’고 생각했지만 올해일 거라고는 생각지 못했어요. 덕분에 《소년이 온다》의 편집자로서 덩달아 저도 많은 축하를 받았습니다. 그날 이후 \"한국문학, 만세!\"를 여러 번 외쳤어요.\n편집자가 책의 시작부터 끝까지 모든 과정을 책임진다는 점은 어느 분야나 비슷하겠지만, 특히 문학 편집자는 소설이 출간되기까지 어떤 역할을 하게 되는지 궁금합니다.\n문학 작품은 작가의 세계를 인정한 상태에서 출간 결정을 하는 것이라서 먼저 아이템을 제안하는 경우보다는 ‘작가가 쓰고자 하는 이야기’에서 출발하는 때가 많아요. 대신 편집자는 작품의 전체 흐름을 보고 피드백하며 수정을 같이 해나가게 됩니다. 한 인물이 갑자기 개연성 없는 행동을 한다든지, 결말에 와서 이야기를 끌어온 힘이 떨어졌다든지 하면 원고의 첫 번째 독자로서 작가와 대화도 많이 나눠요.\n작가나 작품마다 해야 하는 역할도 달라져서 초교(첫 교정)를 시작할 때는 늘 떨려요. 처음 담당하는 작가의 작품이면 전작들을 읽어보면서 문체나 톤을 공부하고 그에 맞는 편집을 합니다. 특정 장면에서 조금 더 정확하게 표현할 수 있는 단어를 함께 찾기도 하고, 소설집의 경우에는 몇년간 쌓아온 단편들의 순서를 잡고, 작품들을 아우를 수 있는 제목도 붙이죠. 그러다 때로는 어떤 단편의 소재나 세계관을 살려 장편으로 써보실 것을 제안하기도 해요. 《채식주의자》가 이전작인 단편 〈내 여자의 열매〉에서 상상력을 극대화해 탄생하게 된 작품인 것처럼요.\n《소년이 온다》의 작업 과정은 어땠나요?\n《소년이 온다》는 창비의 문학블로그 ‘창문’에서 2013년에 먼저 공개했어요. 무려 매일 연재였죠. 문예지가 새롭게 독자를 만나는 방법이 한창 블로그나 웹진일 때가 있었거든요. 정세랑 작가의 《피프티 피플》, 천운영 작가의 《생강》 등도 모두 창문에서의 연재로 선보인 작품이에요. 신문에 연재하는 것처럼 월요일부터 금요일까지 매일 올려야 하다 보니까 힘든 마감도 많았는데 한강 작가님은 미리 원고를 꽤 보내주셔서 제가 여유롭게 편집하고 임의로 분량을 나눠서 올릴 수 있었어요.\n뵌 적은 없지만 왠지 인터뷰만 봐도 원고가 준비되어 있지 않으면 연재 시작을 안 하실 것 같아요.\n맞아요. 큰 틀이 잡혀 있었고, 아무리 늦어도 몇 주 전에는 원고가 들어왔어요. 그렇게 2014년 1월까지 연재하며 초고를 마련하고 몇달 시간을 가지면서 수정한 뒤 2014년 5월에 출간했어요. 그 기간 동안 편집부 의견도 드려서 뒷부분 수정도 좀 있었고요.\n《소년이 온다》 작업 후에 기억에 남는 일이 있으신가요?\n《소년이 온다》는 제게도 각별한 작품이었는지, 10년이 지났는데도 책을 만들고 작가님과 소통하던 많은 장면들이 오래 남아 있어요. 책이 출간되고 나서 작가가 직접 낭독하는 오디오북을 제작하기 위해 스튜디오에서 만났는데, 1장을 녹음하다가 한강 작가님과 스태프 모두가 눈물이 터지는 바람에 녹음을 멈춘 적이 있었어요. 한참을 쉬다가 결국 한 권 낭독은 불가능하다는 걸 알고 녹음을 중단했습니다. 작품 속 인물의 목소리를 한강 작가님의 음성으로 들으니 더 애틋했어요. 이런 호흡과 감정으로 쓰셨구나를 느낀 순간 다 같이 울어버렸습니다.\n노벨문학상이 발표되고 한강 작가님의 작품을 출간한 출판사들까지도 화제에 올랐죠. 창비, 문학동네, 문학과지성사, 모두 우리나라를 대표하는 문학 출판사들이더라고요. 한국 문학계는 대형 출판사만 유명한 작가의 작품을 낼 수 있는 환경인가요?\n그렇지는 않아요. 만약 한 출판사의 문예지로 등단을 했다면 7~10편 정도의 단편 소설이 쌓였을 때 보통은 등단한 출판사에서 첫 소설집을 내요. 그러고 나면 다른 출판사들에게도 기회가 생깁니다. 그 작가의 초기작을 보고 너무 좋았다면 가능성을 보고 작품이 아직 다 모이지 않았지만 미리 출간 제안을 해서 두 번째 소설집 계약을 해두는 거예요.\n문예지가 있는 곳, 혹은 작품을 아직 못 봤어도 투자할 수 있는 여력이 되는 곳은 대부분 규모가 큰 출판사이다 보니까 좋은 작가의 작품을 가져가게 될 가능성이 큰 것은 맞죠. 그런데 요즘은 작은 출판사가 신선한 기획을 많이들 하고 있어서 알려진 소설가들이 규모가 작은 곳에서 소설집이나 에세이를 내는 경우도 늘고 있어요. 레제에서 출간한 김연수 작가의 《너무나 많은 여름이》처럼 늘 호흡 맞추던 편집자가 독립해서 함께한 케이스도 있고, 프란츠에서 출간한 김애란, 김연수, 윤성희, 은희경, 편혜영 작가의 《음악소설집》은 안정적인 기획을 보여주는 소규모 출판사의 재밌는 시도라 응원하는 마음이에요.\n만약 1인 출판사를 한다면 저도 좋은 문학 작품을 낼 수 있나요?\n다른 곳보다 빠르게 제안할 수 있도록 작품을 알아보는 눈, 이전 작업에서 쌓은 신뢰관계, 충분히 투자할 수 있는 돈. 셋 중 하나가 있으면 가능하지요. 다만 셋 중 셋이 다 있더라도 고려해야 할 것은 소설이 시간이 많이 필요한 작업이라는 점이에요. 좋은 작가들은 앞으로 쓸 작품이 서너 편씩 이미 계약되어 있어요. 그럼 저는 다섯 번째에 줄을 서는 거죠.\n최근 실제로 이런 대화를 한 적이 있어요. 친한 작가에게 “우리도 같이 작업하자”고 했더니 “너무 좋은데 계약이 많이 쌓여 있다”고 하더라고요. 지금부터 장편 소설 다섯 편이 나오려면 최소 10년은 걸리잖아요? 그래서 저도 얘기했어요. “10년 금방이더라. 그럼 우리는 10년 뒤에 작업하는 걸로 하자.”\n농담처럼 얘기했지만 사실 농담이 아니라는 걸 서로 너무 잘 알고 있어요. 작가에 대한 믿음으로 10년 뒤를 계약하는 게 엄청난 것처럼 보이지만 살아남는다면 무엇이든 가능하니까요. 작가는 글 쓰기를 멈추지 않고, 출판사는 잘 살아남기를 멈추지 않아서 언젠가는 만나는 것, 이게 지금 저에게는 가장 큰 숙제예요. \n작가, 출판사, 서점은 \n책 한 권 팔면 얼마를 벌까\n‘살아남기’에 대해 말씀하시니 출판시장 이야기를 안 할 수 없는데요, 한강 작가님의 작품들이 일주일 만에 100만 부 판매를 돌파했다는 게 알려졌을 때, 온라인 커뮤니티에 “이 100만 부의 예상 매출액이 유명 출판사의 한 해 매출 전체와 비슷하다”는 글이 떠돌았어요. 댓글에서는 “그 출판사 좋아하는데 그거밖에 안 되냐”는 반응들이 있었고요.\n‘업계에서 손에 꼽히게 인지도 높은 브랜드의 매출이 그 정도?’라고 생각하실 테니 이해가 되는 반응이에요. 아마 그 매출에서 출판사가 실제로 남길 수 있는 비율을 알면 더 놀라실 텐데요… 10%도 안 되는 경우가 허다합니다.\n\n\n〈.css-114ityv{white-space:pre-wrap;cursor:pointer;-webkit-text-decoration:underline!important;text-decoration:underline!important;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}B주류경제학 - 출판 편〉에서 살펴본 주요 출판사들의 손익계산서를 들여다보면, 매출액에서 인건비 등 각종 비용을 제하고 남는 영업이익률이 1~18%였으며 평균적으로 10% 안쪽이라는 것을 확인할 수 있어요. 이것도 대형 출판사로 꼽히는 곳들의 손익임을 고려하면, 영상의 제목 ‘재무쟁이는 이해를 포기한 산업’이 이해되고 맙니다. (출처=머니그라피)\n책 한 권이 팔리면 얼마 남게 되는지 더 자세히 알려주실 수 있을까요?\n보통 책이 나오면 40% 정도가 도소매 서점 수수료로 나가고 출판사에 60%가 남아요. 그 안에서 20~25% 정도가 제작비와 유통·물류비로 나가고, 저자 인세 10%를 드립니다. 그럼 다시 남은 20~25%를 출판사 매출(마진)로 볼 수 있고, 출판사는 그 안에서 다시 책 마케팅비, 디자인비, 인건비 등을 써요. 그러다 보면 영업이 잘된 출판사는 10% 이상, 안 된 출판사는 10% 미만이 남게 됩니다.\n요즘 중쇄 찍기가 힘들다고들 하잖아요? 그런데 저처럼 소규모 출판사는 한 권당 제작원가가 더 비싸기 때문에 1쇄만 다 팔아서는 영업이익 남기기가 힘들어요. 그럼에도 좋은 책을 만들어서 2쇄부터 조금씩 수익을 남겨야 하는 거죠. 제 인건비도 그때부터 발생한다고 봐야 해요.\n\n\n정가가 15,000원인 책 한 권을 팔았을 때 출판사는 1,500원도 못 남기는 경우도 많겠네요.\n그렇죠. 저는 출판사 입장에서 말씀드렸지만 비율이 가장 큰 서점 마진도 영업이익률이 높기는 힘들어요. 우선 30~45% 안에 독자분들께 해드리는 가격 할인 10%, 마일리지 등 간접적으로 해주는 할인 5%가 들어가 있어요. 그게 도서정가제*에서 정한 할인의 상한선이고요. 그럼 서점에게도 15~30%가 남죠? 그 안에서 당일 배송도 해드려야 하고, 인건비 등 비용을 쓰고 수익을 남겨야 합니다.\n*도서정가제: 책값 인하 경쟁이 과열되는 것을 방지하고 문화상품을 보호하기 위해 정해진 비율 이상으로 책을 할인 할 수 없게 한 제도.\n\n이런 구조이기 때문에 아무리 유명한 작가라도 인세가 10%인 것이겠죠? 인센티브, 혹은 전자책·장르물 등의 높은 인세는 예외로 두고요.\n저자 인세가 10%로 동일하다는 것은 출판계에 자리 잡은 합리적이고 공평한 시스템이라고 생각해요. 다만 ‘몇년 동안 한 작품을 써냈을 때 받을 수 있는 보상으로 적당한가?’를 작가 입장에서 계산해보면 너무 적은 것도 사실이죠. 15,000원짜리 책을 냈을 때 한 권이 팔리면 1,500원을 받아요. 신입사원 초봉 3천만 원만큼 벌려면 2만 권이 팔려야 합니다. 그런데 2만 부 팔리는 책은 너무 적고, 초판 1쇄 2천 부를 겨우 다 팔았다면 3백만 원을 벌어요. 그 책을 3년간 썼다면 연봉 1백만 원이죠. 웬만해서는 전업작가를 하기 힘든 게 현실이고요.\n책값이 너무 저렴하다 보니 ‘적은 마진’이라는 짐을 출판사, 서점, 작가가 나눠 지고 있는 것 같아요.\n일반적인 단행본의 평균 가격이 15,000원 미만에서 이제는 1만 원 후반대~2만 원대*로 올랐고, 서점의 무료 배송 기준도 10,000원에서 15,000원으로 올랐지만 여전히 다른 비용 상승에 비하면 책값은 너무 싸요. 예를 들어 종잇값과 인쇄비 등 제작비는 정말 많이 올랐거든요.\n*2023년 발행 도서의 평균 가격은 1만 8,633원으로 전년 대비 4.3% 올랐다.(출처=대한출판문화협회의 '2023년 기준 한국 출판생산 통계')\n책을 즐겨 읽는 사람들이 줄어들어서 출판시장 자체가 작아지고 있는 것이 가장 근본적인 문제이겠지만, 매출을 낼 수 있는 단가(책값)가 비용에 비해 낮다는 것도 고질적인 문제예요. 동시에 책은 학습·교양 등의 목적으로 사치재보다는 필수재로 여겨지는 성격을 가지고 있어요. 그러므로 가격 저항이 센 편이라서 갑자기 올리기는 어렵고 민감한 부분이기도 합니다.\n한강 작가님 또한 작은 서점을 운영 중이었다는 게 알려져서 화제였지요. 한편 대형서점과 동네서점의 책 공급 관련 갈등도 불거졌고요. ‘제2의 한강’이 나오려면 출판 생태계가 건강하게 돌아가고, 다양성이 지켜져서 좋은 작가, 좋은 작품 풀이 넓어져야 할 텐데, 그러기 위해 어떤 것들이 필요하다고 생각하시는지요?\n두 가지를 꼽을 수 있어요. 첫 번째는 소비적인 가격 경쟁을 막고 다양한 시도가 가능한 환경을 만들기 위해서 도서정가제가 잘 지켜지는 것, 두 번째는 세상에 너무나 다양한 책이 있으니 취향에 맞거나 필요한 책을 발견해서 읽어보고 그 좋은 경험을 잊지 못하는 독자들이 늘어나는 것이에요.\n노벨문학상 수상작을 원서로 읽는 기쁨이 우리에게 찾아왔어요. 출판계로서는 듬뿍 관심을 받는 드문 기회였는데, 이번 기회에 ‘책 읽는 것 너무 좋다’를 경험하는 독자들이 많이 생길 수 있을까요?\n많은 분들이 한강 작가의 책을 샀지만 마냥 쉬운 작품들은 아니라서 갑자기 한 권을 다 읽어내기 어려울 수 있어요. 《채식주의자》가 힘들었다면 잠시 내려놓고 다른 책을 읽어보면 돼요. 저는 사적인 애정까지 조금 담아서 《소년이 온다》를 추천하고 싶고, 한강 작가님은 수상 후 인터뷰에서 \"모든 작가는 자신의 가장 최근 작품을 좋아한다. 따라서 나의 가장 최근 작품인 《작별하지 않는다》가 시작이 될 수 있기를 바란다\"고 하셨어요. 이제 곧 겨울이 오니까 《흰》도 계절의 분위기와 잘 어울릴 거예요.\n그러다 한강 작가님이 최근에 읽었다고 밝힌 조해진 작가의 《빛과 멜로디》, 김애란 작가의 《이중 하나는 거짓말》로 넘어가 보셔도 좋고, 뭐가 재밌을지 잘 모르겠다면 동네서점에 찾아가보셔도 좋아요. 그럼 또 다른 취향이 묻어나는 추천을 받을 수 있거든요.\n같이 읽는 경험을 해보는 것도 권하고 싶어요. 같은 책을 읽은 다른 사람의 언어로 해석하는 걸 듣고, 여러 세계가 겹쳐지면서 내 세계가 풍부해지는 경험이 되게 좋아요. 관심 있는 작가가 있으면 북토크도 가보고, 어느 날은 가방에 책도 챙겨서 나와보고요. 읽다 말아도 괜찮으니 책 읽기를 포기하지 않으셨으면 하는 마음이에요.\n올해 노벨문학상은 ‘아시아 여성 작가’ 차례라며 중국 작가 찬쉐가 가장 유력한 후보로 꼽혔었지요. 또 다른 후보로는 노르웨이의 욘 포세, 호주의 제럴드 머네인, 캐나다 시인 앤 카슨 등이 있었던 한편 한국 작가는 상위권에 없었다는 것도 이야깃거리였어요. 해외에서 K-문학 열풍은 이제 진짜 시작이 아닐까 싶은데, 어떤 작가들이 다음 노벨문학상 후보로 거론되나요?\n한강 작가의 수상을 계기로 더 많은 한국 문학 작품이 번역되면 앞으로 더 많은 기회가 오겠죠. 김혜순 시인, 황석영 작가는 늘 수상 가능성이 있는 분들이고, 개인적으로는 《단 한 사람》을 쓴 최진영 작가, 《여름과 루비》를 쓴 박연준 작가, 《자두》를 쓴 이주혜 작가를 눈여겨 봐주셨으면 해요.\n대표님도 눈여겨 보고 있는 작가들의 작품을 출간할 계획인가요?\n네, 자유롭게 작업하려고 소규모 출판을 시작했으니 재밌는 시도 많이 해봐야죠. 오래된 작품을 복원하는 것, 지금 좋은 작품 세계를 보여주는 작가들과 함께 작업하는 것, 그리고 글이 좋지만 한번도 책을 내보지 않은 분들 발굴해서 ‘첫 책’을 탄생시키는 것, 세 가지 일을 계속하려고 합니다.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nInterview・Edit 주소은, 이지영 Graphic 조수희, 이제현",
        "content": "월간 토스픽 10. 노벨문학상과 K-문학",
        "contentSnippet": "월간 토스픽 10. 노벨문학상과 K-문학",
        "guid": "https://blog.toss.im/article/monthly-tosspick-2024-10",
        "isoDate": "2024-11-19T00:58:00.000Z"
      },
      {
        "title": "부자는 반드시 사회에 환원해야 할까?",
        "link": "https://blog.toss.im/article/everyday-economics-20-noblesse-oblige",
        "pubDate": "Mon, 18 Nov 2024 01:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}이 글에서 알 수 있는 것들\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1kxrhf3{white-space:pre-wrap;}연말에 자주 들리는 부자들의 기부 소식, 세금 회피가 목적이라 봐야 할까?\n부자들에게 사회적 환원을 강제하는 것, 이중 과세라 봐야 할까?\n부자가 된 개인, 기업이 사회에 기여하는 방법엔 어떤 것들이 있을까?\n\n\n.css-94on8q{white-space:pre-wrap;color:#c770e4;font-weight:bold;}에디터 G (이하 G): 교수님, ‘전 세계에서 가장 부자인 사람’이라는 말을 들으면, 누가 가장 먼저 떠오르시나요?\n.css-12p6bv8{white-space:pre-wrap;color:#15c47e;font-weight:bold;}교수 K (이하 K): 실제 부자 순위는 매년 달라지지만, 세계 최고의 부자라고 하면 역시나 ‘빌 게이츠’의 이름이 가장 먼저 생각나지 않을까 싶습니다.\n다들 잘 알고 있는 것처럼, 빌 게이츠는 마이크로소프트를 창업해 막대한 부를 쌓았는데요. 2024년 기준으로 그의 재산은 약 1,056억 달러로, 원화로는 무려 145조 원에 이른답니다.\nG: 정말 어마어마한 부를 창출해낸 부자네요. 세계 최고의 부자들로 이름이 알려진 사람들 중에서도 빌 게이츠가 특별한 이유가 있을까요? 교수님은 어떻게 생각하세요?\nK: 여러가지 이유가 있겠지만, 빌 게이츠가 특별하게 거론되는 이유는 다양한 기부 활동을 해왔기 때문인 것 같습니다. 빌 게이츠와 전 부인인 멀린다 게이츠는 빌 & 멀린다 게이츠 재단(Bill & Melinda Gates Foundation)을 설립하여, 전 세계의 질병 퇴치, 빈곤 문제 해결, 교육 기회 확대 등을 위해 수백억 달러를 기부해 왔어요. \n워런 버핏도 빌 게이츠와 손을 잡고 ‘더 기빙 플레지(the giving pledge)’ 캠페인을 통해 자신의 재산을 사회에 환원하기로 약속했으며, 이후에 많은 부자들이 동참하게 됩니다.\nG: 많은 부를 쌓은 사람들이 자신들의 재산을 자발적으로 사회에 환원하는 것은 멋진 일인 것 같아요. 사회에 긍정적인 영향을 가져다 주니까요.\nK: 맞아요. 하지만 한편으로는 부유층의 기부를 바라보는 부정적인 시각도 일부 존재합니다. 예를 들면, 부유층의 자선 활동이 세금 감면 등 경제적 혜택을 가져다 주기 때문에 이뤄진다는 거예요. 기부가 공익보다는 부유층의 개인적 선호와 영향력 확대에 사용될 가능성이 있다는 점에서, ‘진정한 의미의 사회적 환원인지’를 묻는 것이죠.\nG: 아하, 기부나 자선 사업의 근본적인 이유에 의문을 제기하는 입장이겠군요. 실제로 연예인이나 공인이 기부를 했다는 기사가 뜨면 “세금 회피가 목적이겠네”는 댓글이 종종 보이더라고요.\nK: 에디터 님은 어떻게 생각하세요? 많은 부를 축적한 개인이나 기업이 반드시 사회에 환원해야 할까요? 이 질문에 대해 찬성과 반대의 두 입장으로 나누어서 한번 살펴보도록 할게요.\n\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n1. 찬성 입장: \n부유한 개인이나 기업은 반드시 사회에 환원해야 한다.\nK: 가장 먼저 생각해 볼 수 있는 것은 .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}‘공공재의 이용에 따른 사회적 책임’입니다. 현재의 경제 체제 하에서는 어떤 개인이나 기업도 온전히 자신의 힘만으로 부를 쌓았다고 주장할 수 없습니다. 어떤 식으로든 우리 사회가 무상으로 제공하는 공공 인프라를 이용해서 부를 축적했기 때문에, 자신의 재산 일부를 환원함으로써 사회적 책임을 다할 의무가 있다는 것이죠.\nG: 그렇겠네요. 개인이든 기업이든 사회를 함께 살아가는 구성원들이 힘을 합쳐 만든 인프라의 덕을 보는 것이니까요.\nK: 이 논리의 핵심은 바로 공공재입니다. 경제학에서는 재화를 경합성(rivalry)과 배제성(excludability)이라는 두 가지 기준을 사용해 분류하곤 하는데요. 여기서 ‘경합성’은 특정 재화에 대한 나의 소비가 다른 소비자의 사용에 영향을 미치는지를 의미하고요. ‘배제성’은 특정 개인이나 집단이 그 재화를 사용하지 못하도록 배제할 수 있는지를 의미합니다.\n이 두 가지 기준을 이용하면, 아래 그림과 같이 재화를 네 가지 유형으로 나눌 수 있어요.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\nG: 들어본 것도 있고 처음 접하는 것도 있네요. 각 재화에 대해 좀더 자세히 설명해주실 수 있을까요?\nK: 그럼요. 먼저, 사유재(private goods)는 개인이 소유하고 사용하는 상품, 서비스를 말해요. 내가 돈을 주고 사면 다른 사람은 못 쓰는 물건이라 생각하면 됩니다. 우리가 시장에서 일반적으로 사고 파는 상품들이 대부분 여기에 속해요.\n사유재는 개인이 완전히 소유하고 관리할 수 있는 재화라서, 한 사람이 사용하면 다른 사람의 사용이 제한되는 등 경합성이 강한 편입니다. 그리고 가격을 지불해야만 소비할 수 있기 때문에 배제성도 강해요.\n두번째로 공공재(public goods)는 사유재와 완전히 반대예요. 누구나 자유롭게 이용할 수 있는 상품, 서비스죠. 아무나 이용할 수 있고, 그 누가 사용하더라도 다른 사람에게 큰 영향을 미치지 않습니다. 우리가 길에서 흔히 볼 수 있는 가로등, 누구나 들어갈 수 있는 공원, 정부가 국민을 위해 제공하는 국방 등이 공공재에 해당하죠.\n공공재는 누군가 소비하더라도 다른 사람이 동일한 재화를 소비하는 데에 제한이 없습니다. 경합성이 약해요. 또한 대가를 지불하지 않은 사람도 자유롭게 사용할 수 있기 때문에 배제성 또한 약합니다. 시장에서는 공급이 이루어지지 않기 때문에 주로 정부가 제공하게 돼요.\nG: 사유재, 공공재는 일상에서 늘 사용하고 있는 재화네요. 이해가 쉬워졌어요. 클럽재, 공유자원은 어떤건가요?\nK: 그 둘도 설명을 들어보시면 익숙한 개념일 거예요. 클럽재(club goods)는 제한된 일부 사람들만 이용할 수 있는 상품이나 서비스를 말해요. 클럽에 속한 ‘회원’들만 이용할 수 있는 시설이나 서비스 같은 건데요. 티빙이나 넷플릭스 같은 유료 OTT 서비스, 헬스클럽이나 골프장 등이 여기에 속합니다.\n클럽재는 경합성이 약하기 때문에, 특정 시점에 모든 사람들이 꽉 채워 사용하지 않는 이상 회원들이 다같이 이용할 수 있습니다. 즉, 여러 사람이 동시에 이용해도 서비스나 재화의 질이 크게 저하되지 않아요. 그러나 일정 비용을 내야만 사용할 수 있기 때문에 이용 권한이 제한되어 있어요. 누구나 사용할 수는 없다는 측면에서 배제성은 강합니다. 공공재와 사유재의 중간쯤 되는 재화라 보시면 돼요.\n마지막으로 공유자원(common resources)은 모두가 이용할 수 있지만, 사용할수록 줄어드는 재화를 말해요. 누구나 자유롭게 이용할 수 있지만, 덮어놓고 사용하면 부족해질 수 있는 자원이에요. 어업 자원(물고기)나 공공 목초지나 숲, 바다, 강물 등이 여기에 속합니다.\n공유자원은 경합성이 강하기 때문에, 한 사람이 소비하면 양이 줄어들어요. 다른 사람의 소비에 영향을 미치는 것이죠. 그리고 배제성은 약해서 누구나 자유롭게 돈을 내지 않고도 사용할 수 있습니다. 이런 재화는 ‘공유지의 비극(tragedy of commons)’이라 불리는 과잉 소비 문제가 발생할 수 있기 때문에, 이를 관리하기 위해 정부 개입이나 규제가 필요할 때가 많아요.\nG: 우리 사회를 이루고 있는 재화를 크게 네 가지로 나눠볼 수 있겠군요. 이번 아티클에서는 특히 ‘공공재’를 주목할 필요가 있을 것 같아요.\nK: 맞습니다. 부자들이 부를 축적하는 과정에서 무상으로 사용할 수 있는 것이 바로 공공재이기 때문인데요. 공공재의 주요 예시로는 교통 인프라, 법과 치안 시스템, 공교육 제도 등이 있습니다. 이러한 공공재는 개인이나 기업이 별도의 비용을 부담할 필요가 없기 때문에, 경제적 성공을 이루는 중요한 기반이 될 수 있습니다.\n실제로 많은 기업이 부를 축적하는 과정에서 이러한 공공재를 활용했습니다. 예를 들어, 대형 전자상거래 기업은 물류의 신속성과 효율성을 극대화하기 위해 도로와 공항 등의 교통 인프라를 필수적으로 사용합니다.\n이러한 인프라는 정부가 유지하고 관리하는데요. 기업은 이 공공재를 통해 물류 비용을 절감하고 빠른 배송 서비스를 제공할 수 있습니다. 이러한 교통망이 없었다면 물류 비용은 크게 증가했을테고, 소비자와의 접근성이 떨어지니 경쟁력 또한 낮아졌을 것입니다.\nG: 그렇겠네요. 이미 정부가 깔아둔 도로나 교통 인프라 덕분에 기업의 물류 시스템이 작동할 수 있는 것이니까요.\nK: 또한 많은 기업들이 법적 시스템을 통해 지적 재산권을 보호받고 있습니다. 막대한 비용을 쏟아 부은 연구 개발의 성과를 특허로 보호받음으로써, 경쟁력 있는 기술을 유지할 수 있는 것이죠. 기업의 혁신과 기술 보호에 꼭 필요한 안정적인 법과 치안 시스템은 세금으로 운영되는 대표적인 공공재입니다.\n공교육 제도 또한 넓게 보면 기업들이 이용할 수 있는 공공재라 할 수 있습니다. 기업이 지속적으로 성장하고 기술 혁신을 이루어내기 위해서는 우수한 인적 자원이 필수적인데요. 한 명의 우수한 인적 자원을 양성하기 위해서는 초등학교부터 대학교까지 오랜 시간이 소요됩니다. 이 과정에서 공적 재원이 투입된 공교육 제도가 중요한 역할을 하고 있죠.\nG: 공공재 관점에서 보면, 부자가 된 개인이나 기업은 무상으로 제공된 교통 인프라, 법과 치안 시스템, 교육 제도 등을 활용하여 부를 축적해 왔다고 할 수 있겠군요.\nK: 이러한 공공재는 단순히 개인의 성공을 위해 존재하는 것이 아닙니다. 사회 전체를 위해 제공되는 자원이죠. 따라서 부유층이 자신의 부를 사회에 환원함으로써, 자신들이 얻은 이익을 다시 사회에 투자하는 것은 공공재 활용에 상응하는 사회적 책임으로 볼 수 있는 것입니다.\n한편, ‘경제적 안정성과 소득 불평등 관점’에서 부의 환원에 대해 생각해 볼 수도 있습니다. 소득 불평등이 심화되면 경제 성장이 둔화될 수 있습니다.\n이 때 부유한 개인이나 기업이 자신들의 부를 사회에 환원하면, 단기적으로는 자산이 줄어들 수 있지만 장기적으로는 소득의 재분배를 통해 중산층의 소비 능력을 강화시킴으로써 경제적 불안정성을 줄이고 경제 성장에도 기여할 수 있습니다.\n결국 부의 사회적 환원을 통해 경제 전체의 파이를 키우게 되면, 나중에는 부자들에게 긍정적인 부메랑이 되어 돌아온다는 입장인 것이죠.\n\n2. 반대 입장: \n부유한 개인이나 기업이 사회에 환원할 필요는 없다.\nG:.css-1mgq6qf{white-space:pre-wrap;color:#c770e4;} 찬성 입장에 대해 충분히 이해가 됐어요. 반대 입장은 어떤 관점에서 살펴보면 될까요?\nK: 부유한 개인이나 기업에게 사회적 환원을 강제하는 것은 자유 시장 경제 원칙을 훼손할 수 있다는 관점입니다.\n자본주의 시스템에서는 개인과 기업이 자신의 노력과 창의성을 통해 부를 축적하는 것이 장려됩니다. 강제적 환원은 경제적인 동기 부여를 약화시키고, 기업가 정신(entrepreneurship)을 저해할 수 있다는 것이죠.\n또한 예전에 ‘.css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}왜 세금은 소득에 따라 달라질까?’ 아티클에서 살펴본 것처럼, 부자들은 이미 상당한 수준의 소득세와 법인세 등을 납부하고 있습니다. 그리고 이들이 납부한 세금은 공공재 투자를 비롯하여 다양한 방식으로 사회에 기여하고 있죠.\nG: 아하, 이러한 상황에서 이들에게 사회적 환원을 강제하는 것은 일종의 이중 과세가 될 수 있다는 것이겠네요.\nK: 그렇습니다. 그리고 이러한 시각에서는 부의 사회적 환원이 도덕적·윤리적 의무로 간주될 수는 있지만, 법적·경제적 의무로 강제되어서는 안된다고 말합니다. 누구나 자신의 자산을 어떻게 사용할지에 대한 선택권을 갖고 있을 뿐만 아니라, 자신에게 맞는 방법으로 사회에 기여하는 것이 더 효율적이기 때문이죠.\n예를 들면, 스티브 잡스는 다른 세계적인 부자들과 비교했을 때 공개적인 방식을 통한 자선 활동에는 크게 관여하지 않은 것으로 알려져 있습니다. 그러나 그는 애플을 통해 혁신적인 제품을 개발하고 사람들에게 많은 영감을 주었으며, 경제 성장에 기여하기도 했습니다. 스티브 잡스의 사례는 굳이 개인적인 기부가 아니더라도 기업 활동을 통해 얼마든지 사회에 더 큰 기여를 할 수 있음을 보여줍니다.\n지금까지 많은 부를 축적한 사람이나 기업이 사회에 반드시 환원을 해야하는지에 대한 찬성과 반대의 논리를 살펴봤는데요.\n정리해보면 찬성 입장은 (1) 부유층의 사회적 책임과 (2) 불평등 완화 등을 강조하며 환원의 필요성을 주장합니다. 반면, 반대 입장은 (1) 자유 시장 원칙과 이중 과세, (2) 자발적 기부의 중요성 등의 이유로 사회적 환원을 강요하는 것에 반대합니다.\n결론적으로, 부의 사회적 환원 문제는 단순히 \"해야 한다\" 혹은 \"하지 말아야 한다\"로 나뉠 수 없는 까다로운 경제적·윤리적 논쟁이라고 할 수 있겠습니다. 여러분의 생각은 어떤가요?\n.css-13d8cj1{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;margin:24px 0 8px;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:var(--adaptiveGrey700);}\n.css-1dzrkjz{width:16px;margin-right:8px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}\n.svg-icon-wrapper{position:relative;display:inline-block;width:24px;height:24px;}.svg-icon-wrapper >.svg-icon:empty+.svg-icon-fallback{visibility:visible;z-index:inherit;}.svg-icon{color:var(--adaptiveGrey900);display:inline-block;width:24px;height:24px;display:block;width:100%;height:100%;}.svg-icon svg,.svg-icon img{display:block;width:100%;height:100%;}.svg-icon--hide{display:none;}.svg-icon-fallback{position:absolute;left:0;right:0;top:0;z-index:z-index(hidden);visibility:hidden;display:block;width:100%;height:100%;}.svg-icon-fallback--show{visibility:visible;z-index:inherit;}\n참고자료\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 금혜원 Graphic 조수희 이제현",
        "content": "찬성과 반대 입장에서 각각 어떤 논리를 펼치는지 살펴볼게요.",
        "contentSnippet": "찬성과 반대 입장에서 각각 어떤 논리를 펼치는지 살펴볼게요.",
        "guid": "https://blog.toss.im/article/everyday-economics-20-noblesse-oblige",
        "isoDate": "2024-11-18T01:00:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]