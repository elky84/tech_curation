[
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Marian Luparu",
        "title": "New release cadence and support lifecycle for Microsoft C++ Build Tools",
        "link": "https://devblogs.microsoft.com/cppblog/new-release-cadence-and-support-lifecycle-for-msvc-build-tools/",
        "pubDate": "Mon, 24 Nov 2025 15:00:25 +0000",
        "content:encodedSnippet": "Starting with Visual Studio 2026, we are introducing a new support lifecycle for the Microsoft C++ (MSVC) Build Tools. We are also updating the MSVC release cadence.\nAs Visual Studio moves to a Modern Lifecycle with monthly feature updates and an annual new version, decoupling the compiler from the IDE offers you the best of both worlds – rapid iteration in the IDE and predictable, long-term stability for the build tools. This approach brings you the latest C++ advancements across both IDE and build tools while helping you maintain secure and compliant build environments, with enterprise-grade support, and flexible upgrades at your own pace.\nIn this post, we outline the key changes, what stays the same, and how we will help your organization with this transition.\nSummary of the MSVC release and support lifecycle changes\nVisual Studio 2026 version 18.0 released November 11 with MSVC version 14.50. This version of MSVC will be a long-term support release (LTS).\nWhat’s changing?\nStarting with this release, we are separating the lifecycle of MSVC from Visual Studio and adopting the Modern Lifecycle Policy.\n\nThese changes are specific to the Microsoft C++ Build Tools, which is the collection of Windows C++ compiler tools (e.g., cl.exe, link.exe), C and C++ libraries (STL, ATL/MFC, OpenMP, etc.), and VC Runtime redistributable files. These components are usually installed under [VS Folder]\\VC\\Tools\\MSVC\\14.NN.NNNNN\\.\nCadence: MSVC will ship a new release every six months (in May and November), as part of the Visual Studio monthly feature update released on the Stable channel, with 9 months of support.\nLong-Term Support (LTS): Every two years, we will designate the November release as an MSVC LTS release, receiving 3 years of support with bug fixes, security updates, and compatibility improvements.\nAvailability: All releases, including MSVC previews, will be available on the Stable Channel and the Insiders Channel for users to opt-in.\nThe following diagram depicts what our MSVC release schedule may look like for the upcoming years.\nImage: MSVC release cadence and support lifecycle (Illustrative timeline only: actual release dates are subject to change and will be officially announced through our regular channels)\nWhat stays the same?\nMSVC acquisition in Visual Studio: Visual Studio will continue to be the primary way to install MSVC using both the full Visual Studio IDE install or the Visual Studio Build Tools install.\nAccess to multiple versions of MSVC: Visual Studio continues to offer multiple MSVC versions, including unsupported ones for a limited time, allowing you to update your IDE while independently installing the build tools versions your project require.\nC++ binary compatibility: MSVC 14.50 will continue to be ABI compatible with MSVC versions dating back to Visual Studio 2015, allowing your team to more easily migrate between MSVC versions, independently of your other C++ dependencies.\nC++ Redistributable (VCRedist) follows the lifecycle of the MSVC Build Tools they ship with and continues to be a binary-compatible in-place upgrade (meaning that newer versions of VCRedist will replace older ones without breaking existing applications that were originally built with older versions).\nSupport for earlier MSVC releases: The MSVC versions that shipped with Visual Studio 2022 and earlier will continue to be supported according to the lifecycle of Visual Studio in which they first shipped. The new modern support lifecycle applies only to MSVC version 14.50 and up.\nSupport for other VS components: No other components installed by Visual Studio e.g., other toolsets, libraries, SDKs, or frameworks are impacted by this change.\nDrivers for change\nPreviously, MSVC followed Visual Studio’s support policy and release schedule. With Visual Studio 2026, MSVC’s lifecycle will prioritize stability, compliance, and modernization to better serve your needs. This shift allows us to deliver more predictable long-term support, help teams stay compliant with evolving regulations, and simplify upgrades with new tooling, all while reducing fragmentation and investing in secure, modern C++ practices:\nNew Visual Studio 2026 release cadence: Visual Studio will now be released monthly rather than quarterly, introducing new productivity features and AI workflows more frequently. As the IDE moves faster, we recognize that most customers won’t benefit from MSVC releases on the same new cadence as the IDE. To reflect this preference for stability, MSVC build tools will have a decoupled, less frequent release schedule. And for anyone that wants to move faster between MSVC versions, you can take advantage of our MSVC Preview releases that will be available in Visual Studio on both Insiders and Stable channels.\nAlign with .NET long-term support: .NET is already following a modern lifecycle policy. .NET 10 shipped this November, and it is an LTS release for .NET customers. For simplicity and convenience, we are aligning the MSVC build tools LTS schedule to the .NET LTS schedule by designating our November release (MSVC 14.50) as an LTS release.\nGetting current and compliant: Regulations like CyberEO (US) and CRA (EU) require up-to-date tools to secure the software supply chains. Meeting standards, such as NIST and CISA, means depending on outdated compilers is no longer acceptable. These standards are continually evolving to address new security challenges, making regular tool updates essential to maintain compliance. Updating to the latest tools also enables access to more secure and modern coding practices to tackle current threats.\nMore value with less fragmentation: Supporting 10-year-old compilers has become increasingly complex. Focusing on fewer MSVC versions lets us maintain the service and security updates you’ve come to expect while investing more towards improving C++ standards conformance, code safety, and performance.\nWith these reasons in mind, our goal is to modernize the MSVC lifecycle in a way that encourages agility and innovation while providing the best possible support for your enterprise needs.\nHelping your team upgrade\nTo keep your development environment up-to-date and secure, we recommend adopting a regular toolset upgrade rhythm aligned with our MSVC release cadence. We understand that upgrading can present challenges and comes with costs, especially for teams that haven’t prioritized frequent updates before. Based on your feedback, we’re investing in tools and workflows to make moving to the latest version easier, faster, and more predictable:\nImproved Upgrade Workflow in Visual Studio: Visual Studio 2026 introduces a more flexible upgrade experience called Setup Assistant that decouples toolset upgrades from the initial toolset acquisition experience, streamlining side-by-side installations of missing toolsets.\nThe overlap of support windows makes migrations easier, whether you upgrade with every release or stick with LTS. You get a one-year overlap for LTS versions and a three-month overlap for regular releases, giving you time to upgrade while staying supported.\nC++ Binary Compatibility for MSVC 14.50: It’s also easy to incrementally upgrade your solutions, taking full advantage of our ABI compatibility guarantee for MSVC 14.50. You don’t need to rebuild all your projects and all your external dependencies at once. And for your third party open-source dependencies, you can count on the vcpkg package manager to rebuild them using the latest toolset.\nGitHub Copilot app modernization for C++: We’re also introducing a new AI-assisted toolset upgrade experience in Visual Studio as a Private Preview. This new functionality can, for example, adjust project settings, enable new recommended warnings or security flags, and even modify source code to eliminate classes of errors introduced by stricter compliance in our compiler. If you are interested, you can sign up for the Private Preview of our GitHub Copilot app modernization for C++ today.\nSign up for the GitHub Copilot app modernization for C++ Private Preview waitlist\n\nLooking ahead\nThank you for being a valued C++ customer. If you have any questions about how the new MSVC support lifecycle and release cadence may impact your team, you can reach out to us at vcupgrade@microsoft.com.\nWith the latest MSVC release alongside Visual Studio 2026, we’re excited to bring you significant performance enhancements, improved standards conformance and enhanced security features. Upgrade to MSVC Build Tools version 14.50 today, try these improvements, and share any suggestions via the Help > Send Feedback experience in Visual Studio.\nThe post New release cadence and support lifecycle for Microsoft C++ Build Tools appeared first on C++ Team Blog.",
        "dc:creator": "Marian Luparu",
        "comments": "https://devblogs.microsoft.com/cppblog/new-release-cadence-and-support-lifecycle-for-msvc-build-tools/#comments",
        "content": "<p>Starting with Visual Studio 2026, we are introducing a new support lifecycle for the Microsoft C++ (MSVC) Build Tools. We are also updating the MSVC release cadence. As Visual Studio moves to a Modern Lifecycle with monthly feature updates and an annual new version, decoupling the compiler from the IDE offers you the best of [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/new-release-cadence-and-support-lifecycle-for-msvc-build-tools/\">New release cadence and support lifecycle for Microsoft C++ Build Tools</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "Starting with Visual Studio 2026, we are introducing a new support lifecycle for the Microsoft C++ (MSVC) Build Tools. We are also updating the MSVC release cadence. As Visual Studio moves to a Modern Lifecycle with monthly feature updates and an annual new version, decoupling the compiler from the IDE offers you the best of […]\nThe post New release cadence and support lifecycle for Microsoft C++ Build Tools appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=36126",
        "categories": [
          "C++",
          "Visual Studio",
          "MSVC",
          "Upgrade",
          "visual studio",
          "visual studio 2026"
        ],
        "isoDate": "2025-11-24T15:00:25.000Z"
      }
    ]
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Zoomer: Powering AI Performance at Meta’s Scale Through Intelligent Debugging and Optimization",
        "link": "https://engineering.fb.com/2025/11/21/data-infrastructure/zoomer-powering-ai-performance-meta-intelligent-debugging-optimization/",
        "pubDate": "Fri, 21 Nov 2025 21:00:15 +0000",
        "content:encodedSnippet": "We’re introducing Zoomer, Meta’s comprehensive, automated debugging and optimization platform for AI. \nZoomer works across all of our training and inference workloads at Meta and provides deep performance insights that enable energy savings, workflow acceleration, and efficiency gains in our AI infrastructure. \nZoomer has delivered training time reductions, and significant QPS improvements, making it the de-facto tool for AI performance optimization across Meta’s entire AI infrastructure.\nAt the scale that Meta’s AI infrastructure operates, poor performance debugging can lead to massive energy inefficiency, increased operational costs, and suboptimal hardware utilization across hundreds of thousands of GPUs. The fundamental challenge is achieving maximum computational efficiency while minimizing waste. Every percentage point of utilization improvement translates to significant capacity gains that can be redirected to innovation and growth.\nZoomer is Meta’s automated, one-stop-shop platform for performance profiling, debugging, analysis, and optimization of AI training and inference workloads. Since its inception, Zoomer has become the de-facto tool across Meta for GPU workload optimization, generating tens of thousands of profiling reports daily for teams across all of our apps. \nWhy Debugging Performance Matters\nOur AI infrastructure supports large-scale and advanced workloads across a global fleet of GPU clusters, continually evolving to meet the growing scale and complexity of generative AI.\nAt the training level it supports a diverse range of workloads, including powering models for ads ranking, content recommendations, and GenAI features.  \nAt the inference level, we serve hundreds of trillions of AI model executions per day.\nOperating at this scale means putting a high priority on eliminating GPU underutilization. Training inefficiencies delay model iterations and product launches, while inference bottlenecks limit our ability to serve user requests at scale. Removing resource waste and accelerating workflows helps us train larger models more efficiently, serve more users, and reduce our environmental footprint.\nAI Performance Optimization Using Zoomer\nZoomer is an automated debugging and optimization platform that works across all of our AI model types (ads recommendations, GenAI, computer vision, etc.) and both training and inference paradigms, providing deep performance insights that enable energy savings, workflow acceleration, and efficiency gains.  \nZoomer’s architecture consists of three essential layers that work together to deliver comprehensive AI performance insights: \nInfrastructure and Platform Layer\nThe foundation provides the enterprise-grade scalability and reliability needed to profile workloads across Meta’s massive infrastructure. This includes distributed storage systems using Manifold (Meta’s blob storage platform) for trace data, fault-tolerant processing pipelines that handle huge trace files, and low-latency data collection with automatic profiling triggers across thousands of hosts simultaneously. The platform maintains high availability and scale through redundant processing workers and can handle huge numbers of profiling requests during peak usage periods.\nAnalytics and Insights Engine\nThe core intelligence layer delivers deep analytical capabilities through multiple specialized analyzers. This includes: GPU trace analysis via Kineto integration and NVIDIA DCGM, CPU profiling through StrobeLight integration, host-level metrics analysis via dyno telemetry, communication pattern analysis for distributed training, straggler detection across distributed ranks, memory allocation profiling (including GPU memory snooping), request/response profiling for inference workloads, and much more. The engine automatically detects performance anti-patterns and also provides actionable recommendations.\nVisualization and User Interface Layer\nThe presentation layer transforms complex performance data into intuitive, actionable insights. This includes interactive timeline visualizations showing GPU activity across thousands of ranks, multi-iteration analysis for long-running training workloads, drill-down dashboards with percentile analysis across devices, trace data visualization integrated with Perfetto for kernel-level inspection, heat map visualizations for identifying outliers across GPU deployments, and automated insight summaries that highlight critical bottlenecks and optimization opportunities.\nThe three essential layers of Zoomer’s architecture.\nHow Zoomer Profiling Works: From Trigger to Insights\nUnderstanding how Zoomer conducts a complete performance analysis provides insight into its sophisticated approach to AI workload optimization.\nProfiling Trigger Mechanisms\nZoomer operates through both automatic and on-demand profiling strategies tailored to different workload types. For training workloads, which involve multiple iterations and can run for days or weeks, Zoomer automatically triggers profiling around iteration 550-555 to capture stable-state performance while avoiding startup noise. For inference workloads, profiling can be triggered on-demand for immediate debugging or through integration with automated load testing and benchmarking systems for continuous monitoring.\nComprehensive Data Capture\nDuring each profiling session, Zoomer simultaneously collects multiple data streams to build a holistic performance picture: \nGPU Performance Metrics: SM utilization, GPU memory utilization, GPU busy time, memory bandwidth, Tensor Core utilization, power consumption, clock frequencies, and power consumption data via DCGM integration.\nDetailed Execution Traces: Kernel-level GPU operations, memory transfers, CUDA API calls, and communication collectives via PyTorch Profiler and Kineto.\nHost-Level Performance Data: CPU utilization, memory usage, network I/O, storage access patterns, and system-level bottlenecks via dyno telemetry.\nApplication-Level Annotations: Training iterations, forward/backward passes, optimizer steps, data loading phases, and custom user annotations.\nInference-Specific Data: Rate of inference requests, server latency, active requests, GPU memory allocation patterns, request latency breakdowns via Strobelight’s Crochet profiler, serving parameter analysis, and thrift request-level profiling.\nCommunication Analysis: NCCL collective operations, inter-node communication patterns, and network utilization for distributed workloads\nDistributed Analysis Pipeline\nRaw profiling data flows through sophisticated processing systems that deliver multiple types of automated analysis including:\nStraggler Detection: Identifies slow ranks in distributed training through comparative analysis of execution timelines and communication patterns.\nBottleneck Analysis: Automatically detects CPU-bound, GPU-bound, memory-bound, or communication-bound performance issues.\nCritical Path Analysis: Systematically identifies the longest execution paths to focus optimization efforts on highest-impact opportunities.\nAnti-Pattern Detection: Rule-based systems that identify common efficiency issues and generate specific recommendations.\nParallelism Analysis: Deep understanding of tensor, pipeline, data, and expert parallelism interactions for large-scale distributed training.\nMemory Analysis: Comprehensive analysis of GPU memory usage patterns, allocation tracking, and leak detection.\nLoad Imbalance Analysis: Detects workload distribution issues across distributed ranks and recommendations for optimization.\nMulti-Format Output Generation\nResults are presented through multiple interfaces tailored to different user needs: interactive timeline visualizations showing activity across all ranks and hosts, comprehensive metrics dashboards with drill-down capabilities and percentile analysis, trace viewers integrated with Perfetto for detailed kernel inspection, automated insights summaries highlighting key bottlenecks and recommendations, and actionable notebooks that users can clone to rerun jobs with suggested optimizations.\nSpecialized Workload Support\nFor massive distributed training for specialized workloads, like GenAI, Zoomer contains a purpose-built platform supporting LLM workloads that offers specialized capabilities including GPU efficiency heat maps and N-dimensional parallelism visualization. For inference, specialized analysis covers everything from single GPU models, soon expanding to massive distributed inference across thousands of servers.\nA Glimpse Into Advanced Zoomer Capabilities\nZoomer offers an extensive suite of advanced capabilities designed for different AI workload types and scales. While a comprehensive overview of all features would require multiple blog posts, here’s a glimpse at some of the most compelling capabilities that demonstrate Zoomer’s depth:\nTraining Powerhouse Features:\nStraggler Analysis: Helps identify ranks in distributed training jobs that are significantly slower than others, causing overall job delays due to synchronization bottlenecks. Zoomer provides information that helps diagnose root causes like sharding imbalance or hardware issues.\nCritical Path Analysis: Identification of the longest execution paths in PyTorch applications, enabling accurate performance improvement projections. \nAdvanced Trace Manipulation: Sophisticated tools for compression, filtering, combination, and segmentation of massive trace files (2GB+ per rank), enabling analysis of previously impossible-to-process large-scale training jobs\nInference Excellence Features:\nSingle-Click QPS Optimization: A workflow that identifies bottlenecks and triggers automated load tests with one click, reducing optimization time while delivering QPS improvements of +2% to +50% across different models, depending on model characteristics. \nRequest-Level Deep Dive: Integration with Crochet profiler provides Thrift request-level analysis, enabling identification of queue time bottlenecks and serving inefficiencies that traditional metrics miss.\nRealtime Memory Profiling: GPU memory allocation tracking, providing live insights into memory leaks, allocation patterns, and optimization opportunities.\nGenAI Specialized Features:\nLLM Zoomer for Scale: A purpose-built platform supporting 100k+ GPU workloads with N-dimensional parallelism visualization, GPU efficiency heat maps across thousands of devices, and specialized analysis for tensor, pipeline, data, and expert parallelism interactions.\nPost-Training Workflow Support: Enhanced capabilities for GenAI post-training tasks including SFT, DPO, and ARPG workflows with generator and trainer profiling separation.\nUniversal Intelligence Features:\nHolistic Trace Analysis (HTA): Advanced framework for diagnosing distributed training bottlenecks across communication overhead, workload imbalance, and kernel inefficiencies, with automatic load balancing recommendations.\nZoomer Actionable Recommendations Engine (Zoomer AR): Automated detection of efficiency anti-patterns with machine learning-driven recommendation systems that generate auto-fix diffs, optimization notebooks, and one-click job re-launches with suggested improvements.\nMulti-Hardware Profiling: Native support across NVIDIA GPUs, AMD MI300X, MTIA, and CPU-only workloads with consistent analysis and optimization recommendations regardless of hardware platform.\nZoomer’s Optimization Impact: From Debugging to Energy Efficiency\nPerformance debugging with Zoomer creates a cascading effect that transforms low-level optimizations into massive efficiency gains. \nThe optimization pathway flows from: identifying bottlenecks → improving key metrics → accelerating workflows → reducing resource consumption → saving energy and costs.\nZoomer’s Training Optimization Pipeline\nZoomer’s training analysis identifies bottlenecks in GPU utilization, memory bandwidth, and communication patterns. \nExample of Training Efficiency Wins: \nAlgorithmic Optimizations: We delivered power savings through systematic efficiency improvements across the training fleet, by fixing reliability issues for low efficiency jobs.\nTraining Time Reduction Success: In 2024, we observed a 75% training time reduction for Ads relevance models, leading to 78% reduction in power consumption.\nMemory Optimizations: One-line code changes for performance issues due to inefficient memory copy identified by Zoomer, delivered 20% QPS improvements with minimal engineering effort. \nInference Optimization Pipeline:\nInference debugging focuses on latency reduction, throughput optimization, and serving efficiency. Zoomer identifies opportunities in kernel execution, memory access patterns, and serving parameter tuning to maximize requests per GPU.\nInference Efficiency Wins:\nGPU and CPU Serving parameters Improvements: Automated GPU and CPU bottleneck identification and parameter tuning, leading to 10% to 45% reduction in power consumption.\nQPS Optimization: GPU trace analysis used to boost serving QPS and optimize serving capacity.\nZoomer’s GenAI and Large-Scale Impact\nFor massive distributed workloads, even small optimizations compound dramatically. 32k GPU benchmark optimizations achieved 30% speedups through broadcast issue resolution, while 64k GPU configurations delivered 25% speedups in just one day of optimization.\nThe Future of AI Performance Debugging\nAs AI workloads expand in size and complexity, Zoomer is advancing to meet new challenges focused on several innovation fronts: broadening unified performance insights across heterogeneous hardware (including MTIA and next-gen accelerators), building advanced analyzers for proactive optimization, enabling inference performance tuning through serving param optimization, and democratizing optimization with automated, intuitive tools for all engineers. As Meta’s AI infrastructure continues its rapid growth, Zoomer plays an important role in helping us innovate efficiently and sustainably. \nThe post Zoomer: Powering AI Performance at Meta’s Scale Through Intelligent Debugging and Optimization appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>We’re introducing Zoomer, Meta’s comprehensive, automated debugging and optimization platform for AI.  Zoomer works across all of our training and inference workloads at Meta and provides deep performance insights that enable energy savings, workflow acceleration, and efficiency gains in our AI infrastructure.  Zoomer has delivered training time reductions, and significant QPS improvements, making it the [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/11/21/data-infrastructure/zoomer-powering-ai-performance-meta-intelligent-debugging-optimization/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/11/21/data-infrastructure/zoomer-powering-ai-performance-meta-intelligent-debugging-optimization/\">Zoomer: Powering AI Performance at Meta&#8217;s Scale Through Intelligent Debugging and Optimization</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "We’re introducing Zoomer, Meta’s comprehensive, automated debugging and optimization platform for AI.  Zoomer works across all of our training and inference workloads at Meta and provides deep performance insights that enable energy savings, workflow acceleration, and efficiency gains in our AI infrastructure.  Zoomer has delivered training time reductions, and significant QPS improvements, making it the [...]\nRead More...\nThe post Zoomer: Powering AI Performance at Meta’s Scale Through Intelligent Debugging and Optimization appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=23436",
        "categories": [
          "Data Center Engineering",
          "Data Infrastructure",
          "ML Applications"
        ],
        "isoDate": "2025-11-21T21:00:15.000Z"
      },
      {
        "creator": "",
        "title": "Key Transparency Comes to Messenger",
        "link": "https://engineering.fb.com/2025/11/20/security/key-transparency-comes-to-messenger/",
        "pubDate": "Thu, 20 Nov 2025 17:00:21 +0000",
        "content:encodedSnippet": "We’re excited to share another advancement in the security of your conversations on Messenger: the launch of key transparency verification for end-to-end encrypted chats. \nThis new feature enables an additional level of assurance that only you — and the people you’re communicating with — can see or listen to what is sent, and that no one else, not even Meta, can do so.\nEnd-to-end encryption on Messenger already ensures that the content of your direct messages and calls are protected from the moment they leave your device to the moment they reach the receiver’s device. As part of our end-to-end encrypted chat platform, we believe it’s also important that anyone can verify that the public keys (used by the sender’s device for encrypting each message) belong to the intended recipients and haven’t been tampered with.\nThis launch builds upon the valuable work and experiences shared by others in the industry. WhatsApp’s implementation of key transparency in 2023 demonstrated the feasibility of this technology for large-scale encrypted messaging. We’ve extended these pioneering efforts in our Messenger implementation to deliver a robust and reliable solution with similar security properties.\nWhat Is Key Transparency?\nKey transparency provides messaging users with a verifiable and auditable record of public keys. It allows them to confirm that their conversations are indeed encrypted with the correct keys for their contacts, and that these keys haven’t been maliciously swapped by a compromised server. This means you can be more confident that your messages are only accessible to the people you intend to communicate with.\n\nYou can already check your keys for end-to-end encrypted chats on Messenger, but this can be cumbersome for people who have logged in to Messenger on multiple devices, each of which has its own key. Moreover, these keys change when new devices are added or are re-registered, which necessitates another check of the key every time this happens. \nTo address this, we’ve added a new security feature, based on key transparency, that allows users to verify these keys without having to compare them manually with their contacts. Of course, anyone who wishes to continue manually verifying their keys is free to do so.\nHow We’re Handling Messenger Keys at Scale\nOur key transparency implementation leverages the Auditable Key Directory (AKD) library, mirroring the system already in place for WhatsApp. This system allows Meta to securely distribute and verify users’ public keys. To further enhance the security of this process, we use Cloudflare’s key transparency auditor to provide an additional layer of verification, ensuring that the distribution of keys is transparent and verifiable by anyone. Cloudflare’s auditor maintains a live log of the latest entries on the Key Transparency Dashboard, for both the WhatsApp and Messenger directories.\nImplementing key transparency on the scale of Messenger presented unique engineering challenges. One significant factor was the sheer volume and frequency of key updates. Messenger indexes keys for each and every device someone has logged in on, which means that a single user often has multiple, frequently-changing keys associated with their account.\nThis increased complexity leads to a much higher frequency of key updates being sequenced into our key transparency directory. Currently, we’re observing an epoch frequency of approximately 2 minutes per publish, with hundreds of thousands of new keys added in each epoch. Since we began indexing, our database has already grown to billions of key entries. We’ve implemented a number of advancements in our infrastructure and libraries to help manage this massive and constantly growing dataset, while ensuring high availability and real-time verification:\nWe improved the algorithmic efficiency of the existing key lookup and verification operations in the AKD library by optimizing for smaller proof sizes, even as the number of updates (versions) for a single key grows. Previously, these proofs grew linearly with the height of the transparency tree, which was still difficult to manage given the number of nodes in the tree.\nWe also updated our existing infrastructure to be more resilient to temporary outages and improved the process for recovering from long delays in key sequencing. These improvements were adapted from lessons learned from running WhatsApp’s key transparency log for the past two years.\nWith key transparency now live on Messenger, users will have the ability to automatically verify the authenticity of their contacts’ encryption keys for one-on-one chats. This represents another step forward in our ongoing investment in providing a secure and private service. \nStay tuned for more updates as we continue to enhance the security and privacy of end-to-end encryption in Messenger.\nThe post Key Transparency Comes to Messenger appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>We&#8217;re excited to share another advancement in the security of your conversations on Messenger: the launch of key transparency verification for end-to-end encrypted chats.  This new feature enables an additional level of assurance that only you — and the people you&#8217;re communicating with — can see or listen to what is sent, and that no [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/11/20/security/key-transparency-comes-to-messenger/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/11/20/security/key-transparency-comes-to-messenger/\">Key Transparency Comes to Messenger</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "We’re excited to share another advancement in the security of your conversations on Messenger: the launch of key transparency verification for end-to-end encrypted chats.  This new feature enables an additional level of assurance that only you — and the people you’re communicating with — can see or listen to what is sent, and that no [...]\nRead More...\nThe post Key Transparency Comes to Messenger appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=23382",
        "categories": [
          "Security & Privacy"
        ],
        "isoDate": "2025-11-20T17:00:21.000Z"
      },
      {
        "creator": "",
        "title": "Efficient Optimization With Ax, an Open Platform for Adaptive Experimentation",
        "link": "https://engineering.fb.com/2025/11/18/open-source/efficient-optimization-ax-open-platform-adaptive-experimentation/",
        "pubDate": "Tue, 18 Nov 2025 17:00:24 +0000",
        "content:encodedSnippet": "We’ve released Ax 1.0, an open-source platform that uses machine learning to automatically guide complex, resource-intensive experimentation.\nAx is used at scale across Meta to improve AI models, tune production infrastructure, and accelerate advances in ML and even hardware design.\nOur accompanying paper, “Ax: A Platform for Adaptive Experimentation” explains Ax’s architecture, methodology, and how it compares to other state-of-the-art black-box optimization libraries.\nHow can researchers effectively understand and optimize AI models or systems that have a vast number of possible configurations? This is a challenge that is particularly prevalent in domains characterized by complex, interacting systems, such as modern AI development and deployment. Optimizing under these settings demands experimentation, and efficiency is of the utmost importance when evaluating a single configuration is extremely resource- and/or time-intensive.\nAdaptive experimentation offers a solution to this problem by actively proposing new configurations for sequential evaluation, leveraging insights gained from previous evaluations\nThis year, we released version 1.0 of Ax, an open source adaptive experimentation platform that leverages machine learning to guide and automate the experimentation process. Ax employs Bayesian optimization to enable researchers and developers to conduct efficient experiments, identifying optimal configurations to optimize their systems and processes.\nIn conjunction with this major release, we published a paper titled, “Ax: A Platform for Adaptive Experimentation” that explores Ax’s core architecture, provides a deeper explanation of the methodology powering the optimization, and compares Ax’s performance against other black-box optimization libraries.\nAx has been successfully applied across various disciplines at Meta, including:\nTraditional machine learning tasks, such as hyperparameter optimization and architecture search.\nAddressing key challenges in GenAI, including discovering optimal data mixtures for training AI models.\nTuning infrastructure or compiler flags in production settings.\nOptimizing design parameters in physical engineering tasks, such as designing AR/VR devices.\nBy utilizing Ax, developers can employ state-of-the-art methodology to conduct complex experiments, ultimately gaining a deeper understanding and optimizing their underlying systems.\nHow to Get Started With Ax\nTo start using Ax to efficiently tune parameters in complex systems install the latest version of the library via `pip install ax-platform` and visit the Ax website for a quickstart guide, tutorials, and deep dives on the methods that Ax uses under the hood.\nAx Is for Real World Experimentation\nAdaptive experiments are incredibly useful, but can be challenging to run. Not only do these experiments require the use of sophisticated machine learning methods to drive the optimization, they also demand specialized infrastructure for managing experiment state, automating orchestration, providing useful analysis and diagnostics, and more. Additionally, the goals of any given experiment are often more complex than simply improving a single metric. In practice experimentation is usually a careful balance between multiple objective metrics subject to multiple constraints and guardrails.\nWe built Ax to empower users to easily configure and run these dynamic experiments using state-of-the-art techniques, and to provide a robust and mature platform for researchers to integrate cutting-edge methods directly into production systems.\nAx for Understanding\nIn addition to finding optimal configurations efficiently, Ax is a powerful tool for understanding the underlying system being optimized. Ax provides a suite of analyses (plots, tables, etc) which helps its users understand how the optimization is progressing over time, tradeoffs between different metrics via a Pareto frontier, visualize the effect of one or two parameters across the input space, and explain how much each input parameter contributes to the results (via sensitivity analysis). \nThese tools allow experimenters to walk away with both an optimal configuration to deploy to production and a deeper understanding of their system, which can inform decisions moving forward.\n   \nHow Ax Works\nBy default Ax uses Bayesian optimization, an effective adaptive experimentation method that excels at balancing exploration – learning how new configurations  perform, and exploitation – refining configurations previously observed to be good. Ax relies on BoTorch for its implementation of Bayesian optimization components.\n\nBayesian optimization is an iterative approach to solving the global optimization problem  which does not assume any information about the form of the function f. In practice, this means optimizing systems by evaluating some candidate configurations  (i.e., trying some configurations out and measuring their effect), building a surrogate model using this data, using that surrogate to identify the most promising configuration to evaluate next, and repeating until an optimal solution has been found or the experimental budget is exhausted.\nUnder typical settings Ax uses a Gaussian process (GP) as the  surrogate model during the Bayesian optimization loop, a flexible model which can make predictions while quantifying uncertainty and is especially effective with very few data points. Ax then uses an acquisition function from a family called expected improvement (EI) to suggest the next candidate configurations to evaluate by capturing the expected value of any new configuration compared to the best previously evaluated configuration.\nThe following animation shows this loop with a GP modeling the goal metric plotted above in blue and EI plotted below in black; the highest value of EI informs the next value of x to evaluate. Once the new value of x has been evaluated, the GP is re-fit with the new data point and we calculate the next EI value.\n\nThis 1-dimensional example can be expanded for many input and output dimensions, allowing Ax to optimize problems with many (potentially hundreds) of tunable parameters and outcomes. In fact, higher-dimensional settings, in which covering the search space becomes exponentially more costly, is where the surrogate-based approach really shines compared to other approaches.\nYou can read more about Bayesian optimization on Ax website’s Introduction to Bayesian Optimization page.\nHow We Use Ax at Meta\nAx has been deployed at scale at Meta to solve some of the company’s most challenging optimization problems. Thousands of developers at Meta use Ax for tasks like hyperparameter optimization and architecture search for AI models, tuning parameters for online recommender and ranking models, infrastructure optimizations, and simulation optimization for AR and VR hardware design.\nThese experiments optimize nuanced goals and leverage sophisticated algorithms. For instance, we’ve used multi-objective optimization to simultaneously improve a machine learning model’s accuracy while minimizing its resource usage. When researchers were tasked with shrinking natural language models to fit on the first generation of  Ray-Ban Stories they used Ax to search for models that optimally traded off size and performance. Additionally, Meta engineers use constrained optimization techniques for tuning recommender systems to optimize key metrics while avoiding regressions in others.\nRecently, Ax was used to design new faster curing, low carbon concrete mixes that were deployed at one of our data center construction sites. These new mixes are playing an important role in advancing our goal of net zero emissions in 2030.\nWe see problems across every domain where the ultimate quality of a system is affected by parameters whose interactions are complex to reason about without experimentation and where experimentation has a meaningful cost: Ax addresses these challenges by employing a data-driven approach to adapt experiments as they unfold, enabling us to solve these problems efficiently and effectively.\nThe Future of Ax\nWe are always working to improve Ax by building new features for representing innovative experiment designs, exciting new optimization methods, or integrations for using Ax with external platforms. Ax is proud to be open source (MIT license), and we invite both the practitioner and research communities to contribute to the project whether that be through improved surrogate models or acquisition  functions,  extensions used for individual research applications that may benefit the larger community, or simply bug fixes or improvements to the core capabilities. Please reach out to the team via Github Issues.\nRead the Paper\nAx: A Platform for Adaptive Experimentation\nTo learn more about Meta Open Source, visit our website, subscribe to our YouTube channel, or follow us on Facebook, Threads, X, Bluesky and LinkedIn.\nAcknowledgements\nAx was created by Meta’s Adaptive Experimentation team: Sebastian Ament, Eytan Bakshy, Max Balandat, Bernie Beckerman, Sait Cakmak, Cesar Cardoso, Ethan Che, Sam Daulton, David Eriksson, Mia Garrard, Matthew Grange, Carl Hvarfner, Paschal Igusti, Lena Kashtelyan, Cristian Lara, Ben Letham, Andy Lin, Jerry Lin, Jihao Andreas Lin, Samuel Müller, Miles Olson, Eric Onofrey, Shruti Patel, Elizabeth Santorella, Sunny Shen, Louis Tiao, and Kaiwen Wu.\nThe post Efficient Optimization With Ax, an Open Platform for Adaptive Experimentation appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>We’ve released Ax 1.0, an open-source platform that uses machine learning to automatically guide complex, resource-intensive experimentation. Ax is used at scale across Meta to improve AI models, tune production infrastructure, and accelerate advances in ML and even hardware design. Our accompanying paper, &#8220;Ax: A Platform for Adaptive Experimentation&#8221; explains Ax’s architecture, methodology, and how it [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/11/18/open-source/efficient-optimization-ax-open-platform-adaptive-experimentation/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/11/18/open-source/efficient-optimization-ax-open-platform-adaptive-experimentation/\">Efficient Optimization With Ax, an Open Platform for Adaptive Experimentation</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "We’ve released Ax 1.0, an open-source platform that uses machine learning to automatically guide complex, resource-intensive experimentation. Ax is used at scale across Meta to improve AI models, tune production infrastructure, and accelerate advances in ML and even hardware design. Our accompanying paper, “Ax: A Platform for Adaptive Experimentation” explains Ax’s architecture, methodology, and how it [...]\nRead More...\nThe post Efficient Optimization With Ax, an Open Platform for Adaptive Experimentation appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=23315",
        "categories": [
          "Open Source"
        ],
        "isoDate": "2025-11-18T17:00:24.000Z"
      },
      {
        "creator": "",
        "title": "Announcing the Completion of the Core 2Africa System: Building the Future of Connectivity Together",
        "link": "https://engineering.fb.com/2025/11/17/connectivity/core-2africa-system-completion-future-connectivity/",
        "pubDate": "Tue, 18 Nov 2025 06:00:58 +0000",
        "content:encodedSnippet": "Connecting Africa and the World\nWe’re excited to share the completion of the core 2Africa infrastructure, the world’s longest open access subsea cable system. 2Africa is a landmark subsea cable system that sets a new standard for global connectivity. This project is the result of years of collaboration, innovation, and a shared vision to connect communities, accelerate economic growth, and enable transformative digital experiences across Africa and beyond.\ndocument.createElement('video');\nhttps://engineering.fb.com/wp-content/uploads/2025/11/2Africa_Impact_Captions_1920x1080_Stereo_MPEG-4-1.mp4\n \nUnprecedented Scale and Reach\n2Africa is the first cable to connect East and West Africa in a continuous system and link Africa to the Middle East, South Asia, and Europe. With a current reach of 33 countries and still counting, we’re enabling connectivity for 3 billion people across Africa, Europe, and Asia – more than 30% of the world’s population. This scale is unprecedented and we are proud to have partnered with stakeholders across the ecosystem to deliver new levels of connectivity at such scale.\nThe 2Africa Subsea Cable reaches 3 continents and lands in 33 countries, connecting over 3 billion people.\nBuilding 2Africa: Partnership, Scale, and Open Access\nAfrica’s digital future depends on robust, scalable infrastructure built in partnership with local communities and stakeholders. As demand for high-speed internet grows, a consortium of global partners led by Meta, including Bayobab (MTN Group), center3 (stc), CMI, Orange, Telecom Egypt, Vodafone Group, and WIOCC, came together to design and invest in what would become the world’s longest open access subsea cable system. With the Pearls extension scheduled to go live in 2026, 2Africa’s complete system length of 45,000 kilometers is longer than the equivalent of the Earth’s circumference. \nRealizing this vision required close collaboration across both private and public sectors. We managed the project and facilitated engagement with local partners for cable landing, construction, and regulatory processes. The deployment spanned 50 jurisdictions and nearly six years of work, relying on the active engagement of regulators and policymakers to navigate requirements and keep progress on track.\nThe consortium’s shared goal is to develop an open, inclusive network that fosters competition, supports innovation, and unlocks new opportunities for millions. This open-access model ensures that multiple service providers can leverage the infrastructure, accelerating digital transformation and AI adoption across the region. New partners including Bharti Airtel and MainOne (an Equinix Company) collaborated on specific segments and data center integration, further expanding the cable’s impact and reach.\nEngineering Innovation and Overcoming Challenges\nBuilding 2Africa required us to push the boundaries of what’s possible in subsea infrastructure. We deployed advanced spatial division multiplexing (SDM) technology, supporting up to 16 fiber pairs per cable. This is double the capacity of older systems. It is the first 16-fiber-pair subsea cable to fully connect Africa. We incorporated undersea optical wavelength switching, enabling flexible bandwidth management and supporting evolving demands for AI, cloud, and high-bandwidth applications.\n\nWe increased 2Africa’s burial depth by 50% over previous systems and carefully routed the cable to avoid seabed hazards such as seamounts at hot brine pools, improving resilience and network availability. The system features two independent trunk powering architectures across its West, East, and Mediterranean segments, optimizing capacity and providing additional resiliency against electrical faults. Our branching unit switching capability allowed us to optimize for trunk capacity and reliability by utilizing routes much further offshore from hazards such as the Congo Canyon turbidity currents, while efficiently serving branches to West African nations. To further ensure the integrity and reach of the cable, we engineered compatible crossing solutions for over 60 oil and gas pipelines. \n\nOver the course of construction, we deployed 35 offshore vessels, amounting to nearly 32 years of vessel operations, while dedicated shore-end operations required even more inshore vessels, locally mobilized for cable pulling, guarding, security, and dive support. In remote locations, we imported and mobilized specialist equipment such as dive decompression chambers and shore-end burial tooling to locally operated vessels.\nEconomic Impact and Community Transformation\n2Africa is delivering a step change in international bandwidth for Africa, with technical capacity that far exceeds previous systems. For example, on the West segment, stretching from England to South Africa, and landing in countries such as Senegal, Ghana, Cote d’Ivoire, Nigeria, Gabon, the Republic of Congo, DRC, and Angola, the cable supports 21 terabits per second (Tbps) per fiber pair, with 8 fiber pairs on the trunk. This results in a total trunk capacity of up to 180 Tbps. \nBut what does 180 Tbps mean for people?\nTo put in perspective:\n180 Tbps is enough to stream over 36 million HD movies simultaneously (assuming 5 megabits per second (Mbps) per stream).\nFor an individual, this means the potential to download 15,000 full-length Nollywood films (each about 1.5 GB) per second, or enable students to access a remote university’s full library in a minute.\nFor a city like Lagos, it means millions of people can video call, stream, and work online at the same time – without experiencing slowdowns or congestion.\nThis massive capacity ensures a near-limitless supply of international internet bandwidth, allowing internet service providers (ISPs) and mobile network operators (MNOs) to secure capacity at much lower wholesale prices. This creates market competition, redundancy, and supports modern digital infrastructure including cloud services, data centers, and 5G deployment. \nThe impact is profound: 2Africa is expected to contribute up to 36.9 billion US dollars to Africa’s GDP within just the first two to three years of operation. The cable’s arrival will boost job creation, entrepreneurship, and innovation hubs in connected regions. Evidence from previous cable landings shows that fast internet access increases employment rates, improves productivity, and supports shifts toward higher-skill occupations. \nMeta’s vision is to empower African entrepreneurs, creators, and businesses to innovate and collaborate. By partnering with policymakers, regulators, and stakeholders, we advance Africa’s digital transformation and support its position as an emerging major player in the global digital economy.\nBuilding Connections, Empowering Progress\nThe completion of 2Africa is a defining moment for Africa’s digital future. By leading the design, funding, and deployment of the world’s longest subsea cable system to date, we are building the infrastructure that will power transformative new experiences, drive economic growth, and connect billions of people. We are laying the foundation for the next generation of digital experiences. This subsea cable will enable faster, more reliable internet and support AI-driven services through digital access.\n2Africa is part of Meta’s mission to build the future of human connection, opening more pathways for communities across Africa to help shape and play a critical role in the next chapter of the global digital economy. \nThe post Announcing the Completion of the Core 2Africa System: Building the Future of Connectivity Together appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Connecting Africa and the World We’re excited to share the completion of the core 2Africa infrastructure, the world&#8217;s longest open access subsea cable system. 2Africa is a landmark subsea cable system that sets a new standard for global connectivity. This project is the result of years of collaboration, innovation, and a shared vision to connect [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/11/17/connectivity/core-2africa-system-completion-future-connectivity/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/11/17/connectivity/core-2africa-system-completion-future-connectivity/\">Announcing the Completion of the Core 2Africa System: Building the Future of Connectivity Together</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Connecting Africa and the World We’re excited to share the completion of the core 2Africa infrastructure, the world’s longest open access subsea cable system. 2Africa is a landmark subsea cable system that sets a new standard for global connectivity. This project is the result of years of collaboration, innovation, and a shared vision to connect [...]\nRead More...\nThe post Announcing the Completion of the Core 2Africa System: Building the Future of Connectivity Together appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=23313",
        "categories": [
          "Connectivity"
        ],
        "isoDate": "2025-11-18T06:00:58.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Ekaterina Petrova",
        "title": "The Ultimate KMP Watchlist: Level Up Your Skills in 10 Talks",
        "link": "https://blog.jetbrains.com/kotlin/2025/11/the-ultimate-kmp-watchlist/",
        "pubDate": "Mon, 24 Nov 2025 16:44:40 +0000",
        "content:encodedSnippet": "The best way to skip the “beginner mistakes” phase is to learn from the teams who have already solved them at scale.\nFor Week 3 of KMP Level Up, we’ve curated the Top 10 KotlinConf talks that cover the full spectrum of adoption, from massive production case studies to deep dives into the compiler. Whether you are looking for architectural inspiration, hard data to convince your stakeholders, or just want to understand the engineering magic under the hood, the answers are out there.\n\n\n\n\nHere is your KMP marathon for the week.\n🌍 Part 1: Production Case Studies\nTheory is nice, but does it scale? These teams proved it does.\nDuolingo + KMP: A Case Study in Productivity |  John Rodriguez & Johnny Ye (2025)\nDuolingo ships weekly to 40M+ daily users across Android, iOS, and Web. Shipping that fast requires efficiency. This talk breaks down their specific rubric for deciding what to share, from Video Calls to Math lessons, and how they handle the velocity required to ship constantly without breaking platform quality.\nLeveraging KMP for Navigation in the McDonald’s App  | Cas van Luijtelaar & Anthony Bassey (2025)\nMost teams start by sharing the data layer, but McDonald’s went much further. They use KMP to drive the navigation state itself. In this talk, they show how they keep the UI 100% native (Compose & SwiftUI) but let the shared KMP layer decide where to go and what data to pass, effectively creating a scalable “dumb client” architecture.\nTwo Years with KMP: From Zero to 55% Shared Code | Rodrigo Sicarelli (2024)\nStoneCo is a fintech giant serving 4 million users. This isn’t a “hello world” story; it’s about training 130 mobile engineers to shift their paradigm. They break down how they achieved 55% code sharing across two massive apps and the measurable impact on developer satisfaction and velocity.\nMeetup with KMM Libraries | Colin Lee (2023)\nIf you are overwhelmed by the library ecosystem, watch this. Colin walks through the transition from a legacy codebase to a greenfield KMP app. He highlights the specific stack that saved them (Apollo GraphQL, SQLDelight, Moko Resources) and how they survived the initial “panic” from the iOS team to reach a point where everyone loves the shared workflow.\n\n\n\n\n🛠️ Part 2: Getting Your Hands Dirty\nOkay, you’re inspired. Now let’s look at the code.\nCompose Multiplatform for iOS: Ready for Production | Sebastian Aigner (2025)\nCompose Multiplatform is no longer experimental—it’s stable on iOS. Sebastian gives you the tour of the ecosystem, showing how to build production-grade UIs that share rendering logic while still feeling at home on Apple devices. Perfect for understanding the current state of the art.\nConfetti: Building a Conference App in 40 Minutes | John O’Reilly & Martin Bonnin (2023)\nThis is a live-coding masterclass in “Full Stack Kotlin.” Watch John and Martin build a working app from scratch in real-time. They spin up a Spring Boot backend with GraphQL, generate type-safe Kotlin models on the client with Apollo, and wire it up to native UIs (Compose & SwiftUI). It’s the best demo of how tight the loop can be when you use Kotlin end-to-end.\n\n\n\n\n🍎 Part 3: The iOS Perspective\nBecause your iOS teammates need to love this too.\nKMP in Action: A Production Case Study | Annyce Davis (2024)\nConvincing an iOS team is often the hardest part of adoption. Annyce details Meetup’s migration, specifically focusing on the “WIIFM” (What’s In It For Me) factor for skeptical engineers. The killer insight: after migrating networking to KMP, their iOS app actually got faster because it inherited optimized caching logic that was previously missing.\nKotlin Multiplatform for iOS Developers | Salomon Brys (2023)\nKMP is often pitched to Android devs, but what about the other side of the aisle? Salomon steps “behind enemy lines” to explain KMP from an iOS perspective. He covers the toolchain, the limitations, and how to create a workflow that doesn’t make iOS developers feel like second-class citizens.\nℹ️ The ecosystem has grown significantly since 2023. New features like experimental Swift Export now allow idiomatic Swift calls without Objective-C headers. However, Salomon’s core advice on team dynamics and workflow remains essential viewing.\n\n\n\n\n🤿 Part 4: The Deep Dive\nFor those who want to see how the magic trick is performed.\nUsing C & native platforms in Kotlin: Building a multi-platform advanced library | Salomon Brys (2024)\nSometimes you need to go low-level. Using cryptography as an excuse, this talk demonstrates how to build an advanced library that links against native C dependencies, aligns JNI with Kotlin/Native C-interop, and connects to Swift SDKs. Essential viewing for library authors.\nImplementing Compose Hot Reload | Sebastian Sellmair (2025)\nHot Reload is a productivity game-changer, but implementing it on the JVM required deep engineering work. Sebastian breaks down the journey, from fighting ClassLoaders to patching the Kotlin Compiler to handle “shifting lambda names.” A fascinating look under the hood of the tooling we take for granted.\n📺 Want to watch them all in one go? We’ve compiled every talk from this list into a single KMP Level Up Playlist on YouTube. Save it to your library and start your marathon.\n\n\n\n\n\n\n\n🎫 Join us in the Real World\nThese talks represent the current state of the art, but the ecosystem is moving fast. The best way to stay ahead is to be where the conversations happen.\nKotlinConf 2026 tickets are on sale now! Come meet these speakers, ask the hard questions, and see the future of KMP before it hits YouTube.\nGet Your Ticket",
        "dc:creator": "Ekaterina Petrova",
        "content": "The best way to skip the &#8220;beginner mistakes&#8221; phase is to learn from the teams who have already solved them at scale. For Week 3 of KMP Level Up, we’ve curated the Top 10 KotlinConf talks that cover the full spectrum of adoption, from massive production case studies to deep dives into the compiler. Whether [&#8230;]",
        "contentSnippet": "The best way to skip the “beginner mistakes” phase is to learn from the teams who have already solved them at scale. For Week 3 of KMP Level Up, we’ve curated the Top 10 KotlinConf talks that cover the full spectrum of adoption, from massive production case studies to deep dives into the compiler. Whether […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=661307",
        "categories": [
          "multiplatform"
        ],
        "isoDate": "2025-11-24T16:44:40.000Z"
      },
      {
        "creator": "Joffrey Bion",
        "title": "Amper Update, November 2025 – Extensibility Preview",
        "link": "https://blog.jetbrains.com/amper/2025/11/amper-update-november-2025/",
        "pubDate": "Mon, 24 Nov 2025 14:47:36 +0000",
        "content:encodedSnippet": "Amper 0.9.0 is out, and it brings the first version of our extensibility prototype! Read on for all of the details, and see the release notes for the full list of changes and bug fixes.\nTo get support for Amper’s latest features, use IntelliJ IDEA 2025.3 Beta (or newer).\nNew Amper website\nWe revamped our documentation and turned it into a brand new website! You no longer have to read Markdown files on GitHub. We hope you’ll enjoy the new structure, as well as the navigation and search functionality.\nCheck it out at https://amper.org.\n\n\n\n\nExtensibility preview\nIt’s finally here: our first preview of Amper’s extensibility!\nOur philosophy is to give a “batteries included” experience to our users, and this is why we want Amper to cover the most common use cases out of the box. However, a lot of projects have special needs, and the built-in behavior falls short eventually. To address this, Amper now offers the option to write custom tasks and expose them to your modules via plugins.\nNote: Only local plugins are supported at the moment, but we will soon add the ability to publish and share plugins.\nIn Amper 0.9.0, you can create modules with the new jvm/amper-plugin product type. These modules contain the Kotlin code implementing your custom tasks, and a plugin.yaml file to register your tasks and their inputs and outputs.\nWhy do you need to use both Kotlin and YAML? As usual with Amper, tooling is paramount. Thanks to this approach, you will get nice diagnostics in case you make mistakes with your task wiring. Don’t worry, though, navigating between YAML and Kotlin is already seamless with the current basic IDE support.\n\n\n\n\nTask dependencies are automatically inferred based on inputs and outputs, and task avoidance is already available by default. Inputs can be simple scalar values or files, or even your module’s compile or runtime classpath – thanks to the built-in Classpath type. Outputs can be regular files, but they can also be registered as generated sources or resources so the rest of the build takes them into account.\nBuild your own plugin from scratch by following our plugin quick-start guide, and tell us what you think in our Slack channel or in a YouTrack issue.\nPlease bear in mind that this preview is incomplete, and many more features will come in the future, including:\nThe ability to publish plugins and share them with other projects.\nTemplates that are bundled with your plugin to add configuration to the consumer module.\nReduced boilerplate when writing tasks that are only used in a single module.\nServices and libraries for common task-authoring needs.\nMore IDE quick-fixes and intention actions.\n\n\n\n\nLearn more about the current and future state in our plugin documentation.\nDependency resolution performance improvements\nThe dependency resolution phase was previously a performance bottleneck, especially during IDE import and sync.\nEven though all downloaded files are locally cached and reused, building the dependency graph itself takes time, as Amper needs to read all the local pom.xml and Gradle metadata files. Amper now caches the dependency graph itself and reuses it when your dependencies haven’t changed, which can sometimes save tens of seconds on hot caches!\nThere is certainly more we can do here, and we’ll continue improving dependency resolution performance, so stay tuned!\nIncremental compilation for Java\nAmper has had task avoidance since day one, which means that it skips the whole compilation task of a module if its sources and dependencies haven’t changed. However, this doesn’t help if you have a large module with lots of sources, because any change in any file will cause the recompilation of the whole module.\nThis is where incremental compilation comes in. In Amper 0.9.0, you can use our incremental Java compilation engine, which recompiles only what’s necessary based on the exact changes in the module sources. Any change in your sources will still cause the compilation task to run, but now the task itself will be faster.\nTo enable this feature, simply add the following to your module.yaml file:\nsettings:\n  java:\n    compileIncrementally: true\nMaven-like layout support\nAmper’s default directory layout is simple and concise, and we love it. That said, we do understand that transitioning from Maven or Gradle is quite tedious and error-prone if it involves moving all files around. This is particularly painful if you want to try out Amper in a separate long-lived Git branch and get updates from your main branch.\nAs of Amper 0.9.0, you can choose to keep your sources and resources in the conventional Maven directory layout, so you don’t have to move your existing files immediately:\n\nTo do so, add layout: maven-like to your module.yaml file. If you intend to do this for all your modules, use a template to handle this in a central place.\nNote: The maven-like layout is only available for the “jvm/app” and “jvm/lib” product types.\nLibrary catalog at the project root\nAmper now supports placing your Gradle-style version catalog (libs.versions.toml) in the project root instead of in the gradle folder. Of course, you are free to keep using gradle/libs.versions.toml if you want to keep compatibility with your Gradle layout.\nIn the IDE, using intention actions to extract dependencies to a new catalog will now create the catalog in the project root.\nNote: You can only use a single library catalog for your project, so you have to pick one of the locations.\nIDE improvements\nAuto-sync of the project configuration\nChanges to your Amper configuration files are now automatically taken into account, which means you no longer need to manually click the Sync  button!\nThis was made possible by the improvements in dependency resolution caching we’ve seen above.\nIf syncing involves downloading new dependencies or other lengthy processes, you’ll see a progress indicator in the status bar; otherwise, the sync should be seamless.\n\n\n\n                    \nNote: This behavior can be configured for the current project in “Settings | Build, Execution, Deployment | Build Tools”. If you want to change the default for future new projects, you can do so in “Settings | Advanced Settings | Build Tools. Amper”.\nSync details\nThe Build tool window now provides more insights into the stages of the sync process, and shows errors and warnings arising from them.\n\n\nIDE assistance for setting the main class\nYou can configure the entrypoint of a jvm/app module using settings.jvm.mainClass. Finding the fully-qualified name of your main class is never fun, though. This is why IntelliJ IDEA now provides completion for it directly in your YAML file!\nThe completion list includes all class names that have a valid main function. By default, only classes present in the module itself are shown, but you can also invoke completion a second time to get results from your dependencies too:\n\n\n\n\nThat’s not all. IntelliJ IDEA also provides assistance with navigation and resolution, and it will even warn you about the infamous missing Kt suffix when referring to the class Kotlin generates for top-level main functions.\n\nImproved quick-fix for overridden catalog versions\nAmper warns you when your module doesn’t get the requested version of a dependency because of dependency conflicts. However, when this happens with a library catalog dependency, it isn’t obvious what the fix should be, as it depends on your intent.\nTo address this issue, IntelliJ IDEA now offers two different quick-fixes: one to replace the catalog reference with an explicit version in the problematic module, and one to update the version in the catalog itself. Use Alt+Enter or click the More actions… option in the warning tooltip to access these fixes:\n\n\n\n\n\nDedicated color theme settings\nYou can now customize the colors in your Amper YAML files.\nHead over to File | Settings | Editor | Color Scheme | Amper and get creative!\n\nUpdated default versions\nWe updated some of our default versions for toolchains and frameworks:\nKotlin 2.2.21\nCompose Hot Reload 1.0.0-rc01\nKSP 2.3.0\nJUnit Platform 6.0.1\n\n\n\n\nAlso, the default value for settings.jvm.release is now 21.\nTry Amper 0.9.0\nTo update an existing project, use the ./amper update command.\nTo get started with Amper, check out our Getting started guide. Take a look at some examples, follow a tutorial, or read the comprehensive user guide depending on your learning style.\nTry Amper\n                                                    \nShare your feedback\nAmper is still experimental and under active development. You can provide feedback about your experience by joining the discussion in the Kotlinlang Slack’s #amper channel or sharing your suggestions and ideas in a YouTrack issue. Your input and use cases help shape the future of Amper!",
        "dc:creator": "Joffrey Bion",
        "content": "Amper 0.9.0 is out, and it brings the first version of our extensibility prototype! Read on for all of the details, and see the release notes for the full list of changes and bug fixes. To get support for Amper’s latest features, use IntelliJ IDEA 2025.3 Beta (or newer). New Amper website We revamped our [&#8230;]",
        "contentSnippet": "Amper 0.9.0 is out, and it brings the first version of our extensibility prototype! Read on for all of the details, and see the release notes for the full list of changes and bug fixes. To get support for Amper’s latest features, use IntelliJ IDEA 2025.3 Beta (or newer). New Amper website We revamped our […]",
        "guid": "https://blog.jetbrains.com/?post_type=amper&p=660786",
        "isoDate": "2025-11-24T14:47:36.000Z"
      },
      {
        "creator": "Alyona Chernyaeva",
        "title": "Scaling Kotlin Adoption Across Your Organization",
        "link": "https://blog.jetbrains.com/kotlin/2025/11/scaling-kotlin-adoption-across-your-organization/",
        "pubDate": "Mon, 24 Nov 2025 11:42:14 +0000",
        "content:encodedSnippet": "Guest post by Urs Peter, Senior Software Engineer and JetBrains-certified Kotlin Trainer. For readers who’d like a more structured way to build Kotlin skills, Urs also leads the Kotlin Upskill Program at Xebia Academy.\nThis is the fifth post in The Ultimate Guide to Successfully Adopting Kotlin in a Java-Dominated Environment, a series that follows how Kotlin adoption grows among real teams, from a single developer’s curiosity to company-wide transformation.\nAll parts in the series:\nGetting Started With Kotlin for Java Developers\nEvaluating Kotlin in Real Projects\nGrowing Kotlin Adoption in Your Company\nHelping Decision-Makers Say Yes to Kotlin\nScaling Kotlin Adoption Across Your Organization\nSuccess Factors for Large-Scale Kotlin Adoption\nGaining developer buy-in and management support for Kotlin is a significant milestone, but it’s not the finish line. The real challenge begins when you’re faced with existing Java codebases that need to coexist with or transition to Kotlin. How do you navigate this hybrid world effectively?\nThe key to managing legacy codebases is developing a strategy that aligns with your organizational goals and operational realities. Here’s a proven approach that has worked out well in practice.\nApplication lifecycle strategy\nDifferent applications require different approaches based on their lifecycle phase. Let’s examine three distinct categories:\nEnd-of-life applications\nStrategy: Leave them alone.\nIf an application is scheduled for retirement, there’s no business case for migration. Keep these systems in Java and focus your energy where it matters most. The cost of migration will never be justified by the remaining lifespan of the application.\nNew systems\nStrategy: Default to Kotlin.\nIn organizations where Kotlin adoption is complete, greenfield projects naturally start with Kotlin. If the adoption process is in progress, teams often get the choice between Java and Kotlin. Choose wisely ;-).\nActive applications\nStrategy: Pragmatic, feature-driven migration.\nActive applications are the ones that require careful consideration: Rewriting for the sake of rewriting is a tough sell to your Product Owner. Instead, combine migration efforts with new feature development. This approach provides tangible business value while modernizing your codebase. The different attack angles we already discussed in the section: Extend/Convert an existing Java application.\nJava-to-Kotlin conversion approaches\nWhen converting Java to Kotlin, you have several options, each with distinct trade-offs:\n1. Complete rewrite\nBest for: Small codebases \nChallenge: Time-intensive for larger systems\nRewriting a codebase from scratch gives you the cleanest, most idiomatic Kotlin code. This approach is suitable for small codebases, like a MicroService. For large codebases, this approach generally tends to be prohibitively expensive.\n2. IDE auto-conversion with manual refinement\nBest for: Medium codebases with dedicated refactoring time\nChallenge: Manual refinements are mandatory \nIntelliJ IDEA’s Convert Java to Kotlin feature provides a literal translation that’s far from idiomatic. Consider this example:\nTake 1: \nJava\nrecord Developer(\n       String name,\n       List<String> languages,\n       String name,\n) {}\nRaw auto-conversion result:\nKotlin\n@JvmRecord\ndata class Developer(\n   val name: String?,\n   val languages: MutableList<String?>?\n)\nThis conversion has several issues:\nEverything becomes nullable (overly defensive).\nJava Collections become Kotlin’s MutableList instead of  Kotlin’s default read-only List.\nImproving the conversion with jspecify annotations:\nLuckily, for the conversion of all Java types to Nullable types in Kotlin, there is a remedy in the form of @NonNull/@Nullable annotations. Different options are available; the most modern one is jspecify, which has recently also been officially supported by Spring:\n<dependency>\n   <groupId>org.jspecify</groupId>\n   <artifactId>jspecify</artifactId>\n   <version>1.0.0</version>\n</dependency>\n\nimplementation(\"org.jspecify:jspecify:1.0.0\")\nWith jspecify, we can annotate the Java code with @Nullable and @NonNull.\nTake 2: \nJava\nimport org.jspecify.annotations.NonNull;\nimport org.jspecify.annotations.Nullable;\n\nrecord Developer(\n       @NonNull String name, \n       @NonNull List<@NonNull String> languages,\n       @Nullable String email\n) {}\nNow the auto-conversion produces much better results:\nKotlin\n@JvmRecord\ndata class Developer(\n   //😃 non-null as requested\n   val name: String, \n   //😃 both, collection and type are non-null\n  val languages: MutableList<String>,\n   //😃 nullable as requested\n  val email: String?, \n)\nLimitations of the auto conversion approach:\nEven with jspecify annotations, complex Java patterns don’t translate well. Consider this auto-converted code example shown in section: 3. No more checked Exceptions, yet safer code in Kotlin:\nKotlin\nfun downloadAndGetLargestFile(urls: MutableList<String>): String? {\n     //🤨 using Stream, instead of Kotlin Collections\n     val contents = urls.stream().map { urlStr: String? ->\n     //🤨 still using Optional, rather than Nullable types\n     //🤨 var but we want val!\n     var optional: Optional<URL>\n     //🤨 useless try-catch, no need to catch in Kotlin\n     try {\n         optional = Optional.of(URI(urlStr).toURL())\n     } catch (e: URISyntaxException) {\n           optional = Optional.empty<URL>()\n     } catch (e: MalformedURLException) {\n           optional = Optional.empty<URL>()\n     }\n     optional\n   }.filter { it!!.isPresent() }//🤨 discouraged !! to force conversion to non-null\n    .map {it.get() }\n    .map { url: URL ->\n      //🤨 useless try-catch, no need to catch in Kotlin\n      try {\n        url.openStream().use { `is` -> \n           String(`is`.readAllBytes(), StandardCharsets.UTF_8)\n        }\n      } catch (e: IOException) {\n         throw IllegalArgumentException(e)\n       }\n    }.toList()\n   //🤨 usage of Java collections…\n   return Collections.max(contents)\n}\nThe autoconversion is far away from the desired, idiomatic result:\nKotlin\nfun downloadAndGetLargestFile(urls: List<String>): String? =\n   urls.mapNotNull {\n       runCatching { URI(it).toURL() }.getOrNull()\n   }.maxOfOrNull{ it.openStream().use{ it.reader().readText() } }\nThe auto-conversion provides a starting point, but significant manual refinement and knowledge of idiomatic Kotlin is required to achieve truly idiomatic Kotlin.\n3. AI-assisted conversion\nBest for: Larger codebases with robust testing infrastructure\nChallenge: Manual review required\nAI can potentially produce more idiomatic results than basic auto-conversion, but success requires careful preparation:\nPrerequisites:\nComprehensive testing coverage: Since LLMs are unpredictable, you need reliable tests to catch AI hallucinations.\nWell-crafted system prompts: Create detailed instructions for idiomatic Kotlin conversions that are aligned with your standards. You can use this system prompt as a starting point.\nExtensive code review: AI output requires a thorough review for logical and idiomatic correctness, which can be mentally taxing for large codebases.\nUsing the proposed system prompt to guide the conversion, the result is quite satisfying, yet not perfect:\nKotlin\nfun downloadAndGetLargestFile(urls: List<String>): String? {\n   val contents = urls\n      .mapNotNull { \n            urlStr -> runCatching { URI(urlStr).toURL() }.getOrNull() \n      }.mapNotNull { url -> runCatching { \n            url.openStream().use { it.readAllBytes().toString(UTF_8)\n         } \n      }.getOrNull() }\n\n   return contents.maxOrNull()\n}\n4. Auto-conversion at scale\nBest for: Massive codebases requiring systematic transformation\nCurrently, there’s no official tooling for converting Java codebases to idiomatic Kotlin at scale. However, both Meta and Uber have successfully tackled this challenge for their Android codebases using approaches that work equally well for backend applications. The following documentation and talks provide insights into how Meta and Uber approach this quest:\nMeta’s approach:                                                                                    \n \nStrategy: Rule-based, deterministic transformation\nResources:                                                                                               \n\nEngineering blog post\nConference talk                           \nUber’s approach:                                                                                 \n \nStrategy: Rule-based, deterministic transformation using AI to generate conversion rules\nResource: KotlinConf presentation\nBoth companies succeeded by creating systematic, repeatable processes rather than relying on manual conversion or simple automation. Their rule-based approaches ensure consistency and quality across millions of lines of code.\nImportant: Converting Java to Kotlin at scale introduces a challenge on the social level: to be reliable, you still want ‘the human in the loop’ reviewing the generated code. However, if not planned carefully, Engineers can easily be overwhelmed by the flood of pull requests resulting from the automated conversion. Therefore, the social impact needs to be considered carefully. \nRemember, successful large-scale Kotlin adoption isn’t just about converting code – it’s about building team expertise, establishing coding standards, and creating sustainable processes that deliver long-term value to your organization.\nShort recap on when to use which approach:\nSmall application or being rewritten anyway?\n→ Rewrite in Kotlin (1)\n\nMedium codebases with dedicated refactoring time or team learning Kotlin?\n→ Intellij IDEA Auto-Conversion + refine (start with tests first) (2)\n\n\n\n\nMid/large code with repeated patterns and good tests?\n→ AI-assisted approach (3) \n\nOrg-level migration to Kotlin across many services?\n→ Auto-Conversion at scale with concrete plan (platform-led) (4)\nUnlock Kotlin’s full potential\nKotlin makes developers productive fast. Its concise syntax, safety features, and rich standard library help many developers write better code within weeks – often through self-study or on-the-job learning. But without guidance, many fall into the trap of using Kotlin in a Java-like way: sticking to mutable structures, verbose patterns, and missing out on idiomatic features.\nReaching the next level\nReaching the next level – embracing immutability, expression-oriented code, DSLs, and structured concurrency with Coroutines (with or without Virtual Threads) – is where many developers get stuck.\nAt this stage, I’ve found that external training makes a far greater difference than self-study. Even developers with years of Kotlin experience often benefit from focused coaching to adopt idiomatic patterns and unlock the language’s full potential.\n\n\n\n\nTo Kotlin or Not to Kotlin: What Kind of Company Do You Want to Be?\nUltimately, the decision to adopt Kotlin reflects your engineering culture. Do you value the:\nTraditional approach (Java): Conservative, ceremonial, stable.\nProgressive approach (Kotlin): Pragmatic, modern, adaptive.\nBoth have their merits. Java will get the job done. Kotlin will likely get it done better, with happier developers and fewer bugs. The question isn’t whether Kotlin is better – it’s whether your organization is ready to invest in being better.\nThe journey from that first Kotlin test to organization-wide adoption isn’t always smooth, but with the right approach, it’s remarkably predictable. Start small, prove value, build community, and scale thoughtfully.\nYour developers – current and future – will thank you.\nUrs Peter\nUrs is a seasoned software engineer, solution architect, conference speaker, and trainer with over 20 years of experience in building resilient, scalable, and mission-critical systems, mostly involving Kotlin and Scala.\nBesides his job as a consultant, he is also a passionate trainer and author of a great variety of courses ranging from language courses for Kotlin and Scala to architectural trainings such as Microservices and Event-Driven Architectures.\nAs a people person by nature, he loves to share knowledge and inspire and get inspired by peers on meetups and conferences. Urs is a JetBrains certified Kotlin trainer.",
        "dc:creator": "Alyona Chernyaeva",
        "content": "Guest post by Urs Peter, Senior Software Engineer and JetBrains-certified Kotlin Trainer. For readers who’d like a more structured way to build Kotlin skills, Urs also leads the&#160;Kotlin Upskill Program at Xebia Academy. This is the fifth post in The Ultimate Guide to Successfully Adopting Kotlin in a Java-Dominated Environment, a series that follows how [&#8230;]",
        "contentSnippet": "Guest post by Urs Peter, Senior Software Engineer and JetBrains-certified Kotlin Trainer. For readers who’d like a more structured way to build Kotlin skills, Urs also leads the Kotlin Upskill Program at Xebia Academy. This is the fifth post in The Ultimate Guide to Successfully Adopting Kotlin in a Java-Dominated Environment, a series that follows how […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=655951",
        "isoDate": "2025-11-24T11:42:14.000Z"
      },
      {
        "creator": "Andrey Belyaev",
        "title": "Spring Boot 4: Leaner, Safer Apps and a New Kotlin Baseline",
        "link": "https://blog.jetbrains.com/idea/2025/11/spring-boot-4/",
        "pubDate": "Thu, 20 Nov 2025 20:11:35 +0000",
        "content:encodedSnippet": "Spring Boot 4.0 has officially landed. At JetBrains, we’ve been tracking the updates since the first milestones to ensure that IntelliJ IDEA delivers a smooth and reliable development experience.\nWhile many of the core capabilities come directly from Spring Framework 7, Spring Boot remains the adoption enabler that brings everything together: sensible defaults, consistent configuration, unified starters, and the familiar lightning-fast productivity when creating applications.\nAs the most popular framework in the Java world, Spring Boot also helps developers move from older JDK versions to newer ones that offer better performance, more efficient garbage collectors, and modern language features.\nThis major Spring Boot release introduces cleaner modularization to reduce memory usage, improved observability with Micrometer, JSpecify as the standard null-safety library, and many other small improvements that streamline daily development.\nFor JetBrains, the biggest news in Spring Boot 4 is that Kotlin 2.2 is now the official baseline version for the framework. This milestone is the result of a long-standing collaboration between the JetBrains Kotlin team and the Spring Framework team.\nLet’s take a closer look at Spring Boot 4’s new features through the lens of Kotlin 2.2. \nNullability\nThe Kotlin compiler and IntelliJ IDEA now support JSpecify annotations natively. You will receive a compiler warning if you use JSpecify-annotated Java code incorrectly. In addition, IntelliJ IDEA will warn you if you try to assign a Java variable annotated with @Nullable to a non-nullable variable in Kotlin, and vice versa. \nFor example, for the Java interface:\n@NullMarked\n\npublic interface QuoteProvider {\n\n    Quote findQuote(String text);\n\n}\nA Kotlin implementation must return a non-nullable Quote object from the overridden findQuote() method:\n\n\n\n\nYou’ll see the following error message:\n\n\n\n\nIntelliJ IDEA detects the issue and suggests changing the return type to non-nullable. JSpecify is now the default library for nullability checks across all Spring projects. This means that when you create a Spring Boot 4 project in Kotlin, you can be sure that the framework types that you use are null-aware. \nAPI versioning\nAPI versioning in Kotlin works much the same way as in Java. Thanks to Spring’s well-designed API versioning mechanism, adding a version takes only a few lines of configuration and a single annotation attribute. In Kotlin, the versioned API looks just as straightforward:\n@RestController\n\n@RequestMapping(\"/api\", produces = [MediaType.APPLICATION_JSON_VALUE])\n\nclass QuoteController(private val klient: QuoteKlient) {\n\n    @GetMapping(\"quote\", version = \"1.0\")\n\n    fun fetchRandomQuote(): ResponseEntity<Quote> = \nResponseEntity.ok(klient.fetchRandomQuote())\n\n    @GetMapping(\"quote\", version = \"2.0\")\n\n    fun fetchRandomQuotes(): ResponseEntity<List<Quote>> = \nResponseEntity.ok(klient.fetchRandomQuotes())\n\n}\nThere’s nothing fancy here, just the usual Kotlin conciseness, with IntelliJ IDEA inspections helping you configure and validate version formats. \nBean registration\nBean registration is one of the areas where Kotlin truly shines. Thanks to its expressiveness and extensibility, it provides a powerful DSL for registering beans dynamically when the regular @ConditionalOn… annotation family is insufficient.\nFor example, instead of the following Java code:\npublic class QuoteProviderRegistrar implements BeanRegistrar {\n    @Override\n\n    public void register(BeanRegistry registry, Environment env) {\n\n        registry.registerBean(\"quoteProviderDb\", QuoteProviderDb.class);\n\n        registry.registerBean(\"quoteProviderFallback\",\n\n                QuoteProviderFallback.class,\n\n                spec -> {\n\n                    spec.fallback();\n\n                    spec.order(1);\n\n                }\n\n        );\n\n    }\n\n}\nYou can write a more elegant version without all the .class calls and lambda boilerplate:\nclass KuoteProviderRegistrar : BeanRegistrarDsl({\n\n    registerBean<QuoteProviderDb>(\"quoteProviderDb\")\n\n    registerBean<QuoteProviderFallback>(\n\n        name = \"quoteProviderFallback\",\n\n        fallback = true,\n\n        order = 1\n\n    )\n\n})\nMuch cleaner, right? \nConclusion\nSpring Boot is the most popular framework for Java development – and for good reason. With Spring Boot 4 establishing Kotlin 2.2 as the baseline and offering first-class support, we expect to see even broader Kotlin adoption among backend developers who want to use the latest language features. \nYou can try Spring Boot 4 in the 2025.3 Beta release or wait for the stable version, which is expected in early December.\nAt JetBrains, we continue to work closely with the Spring Framework team to ensure Kotlin remains well-integrated and fully supported in the Spring ecosystem.",
        "dc:creator": "Andrey Belyaev",
        "content": "Spring Boot 4.0 has officially landed. At JetBrains, we’ve been tracking the updates since the first milestones to ensure that IntelliJ IDEA delivers a smooth and reliable development experience. While many of the core capabilities come directly from Spring Framework 7, Spring Boot remains the adoption enabler that brings everything together: sensible defaults, consistent configuration, [&#8230;]",
        "contentSnippet": "Spring Boot 4.0 has officially landed. At JetBrains, we’ve been tracking the updates since the first milestones to ensure that IntelliJ IDEA delivers a smooth and reliable development experience. While many of the core capabilities come directly from Spring Framework 7, Spring Boot remains the adoption enabler that brings everything together: sensible defaults, consistent configuration, […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=660362",
        "categories": [
          "news",
          "spring-boot",
          "spring-boot-4"
        ],
        "isoDate": "2025-11-20T20:11:35.000Z"
      },
      {
        "creator": "Julia Shashkova",
        "title": "IntelliJ IDEA 2025.2.5 Is Out!",
        "link": "https://blog.jetbrains.com/idea/2025/11/intellij-idea-2025-2-5/",
        "pubDate": "Thu, 20 Nov 2025 19:45:59 +0000",
        "content:encodedSnippet": "We’ve just released IntelliJ IDEA 2025.2.5.\nYou can update to this version from inside the IDE, using the Toolbox App, or using snaps if you are a Ubuntu user. You can also download it from our website.\nHere are the most notable updates:\nThe IDE now correctly processes API calls when the Docker Engine is updated to v29. [IJPL-217878]\nGradle 9.x projects with a Spring Boot now run as expected using the Gradle Runner. [IDEA-379009]\nResolved an issue where the IDE could hang when scanning HTTP request files containing certain JSON structures. [IJPL-212853]\nThe GitLab plugin now correctly handles large pipeline IDs. [IJPL-217571]\nTo find out more details about the issues resolved, please refer to the release notes.\nIf you encounter any bugs, please report them to our issue tracker.\nHappy developing!",
        "dc:creator": "Julia Shashkova",
        "content": "We’ve just released IntelliJ IDEA 2025.2.5. You can update to this version from inside the IDE, using the Toolbox App, or using snaps if you are a Ubuntu user. You can also download it from our website. Here are the most notable updates: To find out more details about the issues resolved, please refer to [&#8230;]",
        "contentSnippet": "We’ve just released IntelliJ IDEA 2025.2.5. You can update to this version from inside the IDE, using the Toolbox App, or using snaps if you are a Ubuntu user. You can also download it from our website. Here are the most notable updates: To find out more details about the issues resolved, please refer to […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=660635",
        "categories": [
          "releases",
          "bug-fix-update",
          "intellij-idea",
          "intellij-idea-2025-2"
        ],
        "isoDate": "2025-11-20T19:45:59.000Z"
      },
      {
        "creator": "Sasha Ivanova",
        "title": "More Updates and Fixes for ReSharper and Rider 2025.3",
        "link": "https://blog.jetbrains.com/dotnet/2025/11/20/resharper-rider-2025-3-0-2/",
        "pubDate": "Thu, 20 Nov 2025 16:04:23 +0000",
        "content:encodedSnippet": "A second set of updates and bug fixes for the 2025.3 release of ReSharper and Rider has just been made public. \nLet’s take a look at what’s been improved.\nReSharper 2025.3.0.2 \nVisual Studio 2026 no longer displays the warning that ReSharper uses the deprecated IQuickInfoBroker API. [RSRP-502236]\nFixed an issue where MSTest v4 tests were duplicated in the Unit Test Explorer. [RSRP-502145]\nAutomatic import of missing namespaces now works correctly again. [RSRP-502252] \nWe’ve fixed false positive analysis warnings for get-only setters in .NET projects. [RSRP-502278]\nExternal services for grammar, spelling, and SQL analysis now start correctly when multiple Visual Studio instances are open simultaneously. [RSRP-502249]\nIcons for context actions and inspection configuration are now visually distinct again in the Alt + Enter menu. [RSRP-502012]\nThe license agreement dialog for language dictionaries now displays correctly when the Windows dark theme is used. [RSRP-502248] \nFixed a crash caused by a stack overflow in C# code analysis when resolving overloaded operators. [RSRP-502244]\nFor the full list of issues resolved in this build, please refer to our issue tracker.\nDownload ReSharper 2025.3.0.2\n                                                    \nRider 2025.3.0.2 \nAuthentication for private Azure DevOps NuGet feeds now works correctly again. [RIDER-132336]\nRider now correctly uses the user’s installed .NET SDK instead of its own bundled one when compiling projects. [RIDER-131155]\nAutomatic import of missing namespaces now works correctly again. [RSRP-502252] \nWe’ve fixed false positive analysis warnings for get-only setters in .NET projects. [RSRP-502278]\nFixed a crash caused by a stack overflow in C# code analysis when resolving overloaded operators. [RSRP-502244]\nErrors caused by missing or incomplete results from source generators have been resolved. Projects using .NET source generators or libraries like Vogen now load and analyze correctly without showing false red code. [RIDER-132269]\nQuick-fixes that rely on Roslyn analyzers now work correctly with the Microsoft.CodeAnalysis.CodeStyle package. [RIDER-132263]\nWe’ve also resolved a couple of issues that used to cause long freezes. [RIDER-132136, RIDER-130284]\nFor the full list of issues we’ve resolved in this build, please refer to our issue tracker.\nDownload Rider 2025.3.0.2",
        "dc:creator": "Sasha Ivanova",
        "content": "A second set of updates and bug fixes for the 2025.3 release of&#160;ReSharper&#160;and&#160;Rider&#160;has just been made public.&#160; Let’s take a look at what’s been improved. ReSharper 2025.3.0.2&#160; For the full list of issues resolved in this build, please refer to our issue tracker. Rider 2025.3.0.2 For the full list of issues we’ve resolved in this [&#8230;]",
        "contentSnippet": "A second set of updates and bug fixes for the 2025.3 release of ReSharper and Rider has just been made public.  Let’s take a look at what’s been improved. ReSharper 2025.3.0.2  For the full list of issues resolved in this build, please refer to our issue tracker. Rider 2025.3.0.2 For the full list of issues we’ve resolved in this […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=660447",
        "categories": [
          "net-tools",
          "resharper",
          "rider",
          "junie"
        ],
        "isoDate": "2025-11-20T16:04:23.000Z"
      },
      {
        "creator": "Regina Muradova",
        "title": "Learn AI-Assisted Programming With Junie: Free Courses From JetBrains Academy and Nebius",
        "link": "https://blog.jetbrains.com/education/2025/11/20/learn-ai-assisted-programming-with-junie-free-courses-from-jetbrains-academy-and-nebius/",
        "pubDate": "Thu, 20 Nov 2025 12:09:26 +0000",
        "content:encodedSnippet": "For over 25 years, JetBrains has been driven by a desire to make developers more productive and enhance the developer experience by providing smarter, more efficient tools. JetBrains Academy advances this mission by empowering learners to study computer science and gain hands-on experience with the professional tools they’ll use in their future careers.\nAI is becoming a standard in software development. At JetBrains, we design AI to empower developers. Take Junie, our smart coding agent, for example. It’s a reliable collaborator that fits into developers’ IDE and adapts to their workflow to support the way they build and enhance the full development experience. \nTogether with our partner Nebius, an AI cloud platform known for its expertise in high-performance and AI-first workloads, we’re distilling this expertise into a course series demonstrating how to work with AI effectively.\nSTART FOR FREE\n                                                    \nThis course series on AI-assisted programming includes two free courses focused on Junie, each exploring a different side of AI-assisted programming:\nCoding With Junie – a practical course where you’ll build and test projects directly inside JetBrains IDEs.\nAI Agents as Your Team – a deeper look into how AI agents work and how to collaborate with them in real-life projects.\n\n\n\n\n\nWe’re not just teaching developers how to use new tools, we’re helping them understand how AI fits into their everyday work, so they can stay creative, confident, and in control.\nCourse #1: Coding With Junie\nBuild, test, and debug with AI in JetBrains IDEs\nIn our new free Coding With Junie course, you’ll explore how to work with the AI coding agent inside JetBrains IDEs. You’ll install Junie, explore its built-in tools, and complete hands-on tasks that show how AI can help you build, test, and maintain real projects.\nSTART FOR FREE\n                                                    \nWhat you’ll learn\nBuild your first real project with Junie. Install Junie in your IDE, and use it to build your own project from scratch. See how it generates and runs code step by step.\nEffective prompting. Learn how to write prompts that get better results. Build an AI-powered web app that analyzes food images using Nebius vision models and discover how context improves accuracy.\nPlan and document features. Guide AI with advanced planning: set project guidelines, break feature design down into smaller steps with Ask mode, and generate documentation to improve performance and consistency.\nDebug, test, and automate with AI. Use Junie for debugging and creating tests. You’ll see how AI can simplify testing and maintenance while keeping you in control of your code.\nEach chapter includes short videos, examples, and practical exercises that focus on real development workflows.\n\n\n\n\nCourse #2: AI Agents as Your Team\nUnderstand how AI agents actually work and how to collaborate with them\nIf you’ve explored Coding With Junie, you’ve already seen how AI can empower you directly inside your IDE. The next step is to understand what’s happening behind the scenes.AI Agents as Your Team explores how agents actually work, how they make decisions, and how you can use them safely and effectively.\nGET STARTED\n                                                    \nWhat you’ll learn\nHow AI agents are built. Understand the architecture behind LLM-powered agents and how they operate under the hood.\nHow to increase productivity. Apply practical playbooks to achieve significant gains with today’s agent technologies.\nHow to navigate risks. Identify and mitigate challenges like bias, hallucination, or poor observability.\nHow to stay ahead. Build confidence as AI agents evolve and integrate more deeply into modern stacks.\n\n\n\n\nContinue learning with our AI-Assisted Programming series\nThese are just two of the courses in the 10-part free AI-Assisted Programming series, created by JetBrains Academy and Nebius Academy. Together, these courses help you understand how AI enhances every stage of software development – from coding and refactoring to DevOps and automation.\nThe full program includes:\n10 courses on AI coding and DevOps\n25 hands-on tasks\n1 capstone project\nAround 20 hours of self-paced learning\n\n\n\n\nWho is it for?\nThis course series is ideal for:\nSoftware developers looking to future-proof their skills and explore the practical side of AI.\nJunior engineers who want to learn how to build with AI tools.\nTeam leads and managers seeking ways to safely and effectively introduce AI into their development workflows.\nAll you need to get started is a junior-level understanding of any programming language.\nGET STARTED\n                                                    \nHappy learning!\nJetBrains Academy team",
        "dc:creator": "Regina Muradova",
        "content": "For over 25 years, JetBrains has been driven by a desire to make developers more productive and enhance the developer experience by providing smarter, more efficient tools. JetBrains Academy advances this mission by empowering learners to study computer science and gain hands-on experience with the professional tools they’ll use in their future careers. AI is [&#8230;]",
        "contentSnippet": "For over 25 years, JetBrains has been driven by a desire to make developers more productive and enhance the developer experience by providing smarter, more efficient tools. JetBrains Academy advances this mission by empowering learners to study computer science and gain hands-on experience with the professional tools they’ll use in their future careers. AI is […]",
        "guid": "https://blog.jetbrains.com/?post_type=education&p=660502",
        "categories": [
          "ai-assistant",
          "coding",
          "education",
          "jetbrains-academy",
          "learning-courses",
          "news",
          "ai-agents",
          "ai-code-completion",
          "ai-assisted-programming",
          "junie",
          "online-learning"
        ],
        "isoDate": "2025-11-20T12:09:26.000Z"
      },
      {
        "creator": "Anna Maltseva",
        "title": "Gemini 3 Pro Is Now Available in JetBrains IDEs",
        "link": "https://blog.jetbrains.com/ai/2025/11/gemini-3-pro-is-now-available-in-jetbrains-ides/",
        "pubDate": "Tue, 18 Nov 2025 16:12:47 +0000",
        "content:encodedSnippet": "The latest AI model from Google, Gemini 3 Pro, is now live in JetBrains IDEs. From day one, it powers AI Chat and Junie, our coding agent, giving you smarter reasoning, stronger instruction following, and seamless integration into your workflow.\n\n\n\n\n\n\nWhat’s new\nGemini 3 Pro shows clear improvements that matter in day-to-day development:\nUnderstands your codebase and adapts to your style. Gemini 3 Pro learns from your code to replicate your project’s conventions, so changes feel native to your repository and pass review with fewer edits.\nFollows instructions precisely. Built to reason across text, code, and visuals, Gemini 3 Pro understands complex prompts and long documents and delivers more accurate results.\nExcels at frontend development. Gemini 3 Pro shows major progress in multimodal frontend generation and complex UI work.\nOverall, it’s strong at planning and executing multi-step tasks, handling complex instructions, and reasoning across multiple contexts – helping you move from idea to production-ready code faster.\nSee Gemini 3 Pro and Junie in action\nTo demonstrate how Gemini 3 Pro and Junie handle real creative workflows, we built a full landing page experience starting from nothing but a sketch. We uploaded the sketch, provided a detailed prompt, and let Gemini 3 Pro interpret the structure, layout, and visual hierarchy.\nUsing these instructions, Junie, our coding agent, generated the first functional version of the landing page. The output included a clean layout, responsive sections, and components directly inferred from the sketch.\nNext, we asked Gemini 3 Pro and Junie to refine the page and “make it fancy”, transforming the rough structure into a polished, interactive design inspired by modern AI product websites like Adaline.ai. The agent applied animations, smooth transitions, and an elevated visual style while keeping the original structure intact. This clearly shows Gemini 3 Pro’s strong multimodal understanding and Junie’s ability to turn raw ideas into production-ready interfaces. See the result below:\n\n\n\n\nHow to try Gemini 3 Pro in your IDE\nTo access Gemini 3 Pro, you’ll need an active JetBrains AI subscription. If you don’t have one, you can start a free trial directly from your IDE – open the JetBrains AI widget in your IDE, start the installation, and follow the on-screen instructions. Once activated, you can try it in:\nAI Chat: Simply start a new chat – the model is set to Auto.\nJunie: Open Junie’s settings (Settings | Junie | Models) and choose Gemini 3 Pro. (Make sure you have the latest version of the Junie plugin installed.)\n\n\n\n\nGive it a try and let us know what you think in the comments!",
        "dc:creator": "Anna Maltseva",
        "content": "The latest AI model from Google, Gemini 3 Pro, is now live in JetBrains IDEs. From day one, it powers AI Chat and Junie, our coding agent, giving you smarter reasoning, stronger instruction following, and seamless integration into your workflow. What’s new Gemini 3 Pro shows clear improvements that matter in day-to-day development: Overall, it’s [&#8230;]",
        "contentSnippet": "The latest AI model from Google, Gemini 3 Pro, is now live in JetBrains IDEs. From day one, it powers AI Chat and Junie, our coding agent, giving you smarter reasoning, stronger instruction following, and seamless integration into your workflow. What’s new Gemini 3 Pro shows clear improvements that matter in day-to-day development: Overall, it’s […]",
        "guid": "https://blog.jetbrains.com/?post_type=ai&p=659908",
        "categories": [
          "news",
          "ai-in-ides",
          "gemini"
        ],
        "isoDate": "2025-11-18T16:12:47.000Z"
      },
      {
        "creator": "Vaclav Pech",
        "title": "The Second Release of MPS 2025.3 Early Access Program",
        "link": "https://blog.jetbrains.com/mps/2025/11/the-mps-2025-3-eap2/",
        "pubDate": "Tue, 18 Nov 2025 15:45:59 +0000",
        "content:encodedSnippet": "Starting today, you can download the second EAP release for MPS 2025.3 and try all the latest updates.\nDOWNLOAD MPS 2025.3 EAP 2\nThis release includes several noteworthy improvements:\nJavaDoc language overhaul\nThe JavaDoc language has been completely migrated to use the jetbrains.mps.lang.text language for text representation and editing. This change should have minimal impact on the overall user experience. However, it fixes numerous problems:\nThe editing experience is now consistent with other MPS languages that use jetbrains.mps.lang.text, such as BaseLanguage comments or structure language documentation. Find more information about editing text on the documentation facet page.\nText can be copied and pasted between JavaDoc, BaseLanguage comments, language documentation comments, and other places where jetbrains.mps.lang.text is used. Copy/pasting a piece of plain text also works.\nText can now include styling like bold or italics. This styling gets generated as HTML tags in the resulting Java source files.\nAlong the way, several problems associated with the JavaDoc language have been resolved:\nThe description for block tags was changed to use jetbrains.mps.lang.text instead of string properties, so the same edit/copy/paste/style functionality is available inside block tags.\nBlock tags now support multiple lines of description.\nBoth block tags and inline tags are now correctly parsed from Java sources.\nA new {@literal …} inline tag was added as mandated by the Java language specification.\nCode inside CodeSnippet correctly resolves local variables.\nNodeWrapper correctly textgens the contained nodes.\n\nPaste as JavaDoc action available in BaseLanguage\nIn addition to the existing Paste as Java Statement and Paste as Class Content actions, the redesigned JavaDoc language supports a new action that enables easy pasting of textual JavaDoc code into BaseLanguage. Most importantly, this new action ensures that your JavaDoc code is properly parsed into JavaDoc text lines, block tags, and inline tags, including potential reference resolutions (e.g. for the @param or {@link } tags).\n\nThis new Paste as JavaDoc action parses the text from the clipboard and pastes it into a JavaDoc comment at the current position of the cursor. If the cursor is not positioned within an existing JavaDoc comment, the action attaches the parsed JavaDoc elements to the following field/method/class definition’s JavaDoc, creating a new JavaDoc file for them, if needed.\n\nContributions to generator plans\nWe’ve made some major improvements to generator plans, enhancing the user’s experience with complex model transformations. A new notion of PlanContribution supersedes and completely replaces the experimental fork as functionality that we introduced back in 2024.1.\ntargetFacet (see jetbrains.mps.generator.extensions.common model), which tells <mps.make> which GenerationTargetFacet/ModuleFacet to consult when determining an appropriate output location for a model.\n\nConditional forks with generator plans\nBoth the fork step and a PlanContribution in a generator plan support conditional activation. It’s now possible to activate certain branches of a plan only when certain criteria are met. At the moment, MPS comes with a conditional statement that checks the values of specified plan parameters. We intend to eventually extend statements to support logical operations (and/or), as well as other potential operations, while maintaining a strict interpretation of generator plans (i.e. no BaseLanguage code in plans).\nParameterDeclaration classes. Values for these parameters can be contributed using a PlanParameterContributor extension point. MPS comes with a few predefined parameters that are usable straight out of the box – see the jetbrains.mps.generator.extensions.common model for full details of these.\n\nUsing keyboard shortcuts in the Project view\nThe process of creating new elements in the Logical pane of the Project view using keyboard shortcuts has been significantly improved. New modules, models, and nodes can now be introduced without the use of a mouse.\nYou can also check out the blog post announcing the previous 2025.3 EAP 1 version to find out more about the improvements brought to you by that release.\nYou can find the full list of issues we’ve fixed here.\nYour JetBrains MPS team",
        "dc:creator": "Vaclav Pech",
        "content": "Starting today, you can download the second EAP release for MPS 2025.3 and try all the latest updates. DOWNLOAD MPS 2025.3 EAP 2 This release includes several noteworthy improvements: JavaDoc language overhaul The JavaDoc language has been completely migrated to use the jetbrains.mps.lang.text language for text representation and editing. This change should have minimal impact [&#8230;]",
        "contentSnippet": "Starting today, you can download the second EAP release for MPS 2025.3 and try all the latest updates. DOWNLOAD MPS 2025.3 EAP 2 This release includes several noteworthy improvements: JavaDoc language overhaul The JavaDoc language has been completely migrated to use the jetbrains.mps.lang.text language for text representation and editing. This change should have minimal impact […]",
        "guid": "https://blog.jetbrains.com/?post_type=mps&p=658766",
        "categories": [
          "releases",
          "eap",
          "release"
        ],
        "isoDate": "2025-11-18T15:45:59.000Z"
      },
      {
        "creator": "Alyona Chernyaeva",
        "title": "Helping Decision‑Makers Say Yes to Kotlin",
        "link": "https://blog.jetbrains.com/kotlin/2025/11/helping-decision-makers-say-yes-to-kotlin/",
        "pubDate": "Tue, 18 Nov 2025 12:11:19 +0000",
        "content:encodedSnippet": "Guest post by Urs Peter, Senior Software Engineer and JetBrains-certified Kotlin Trainer. For readers who’d like a more structured way to build Kotlin skills, Urs also leads the Kotlin Upskill Program at Xebia Academy.\nThis is the fourth post in The Ultimate Guide to Successfully Adopting Kotlin in a Java-Dominated Environment, a series that follows how Kotlin adoption grows among real teams, from a single developer’s curiosity to company-wide transformation.\nAll parts in the series:\nGetting Started With Kotlin for Java Developers\nEvaluating Kotlin in Real Projects\nGrowing Kotlin Adoption in Your Company\nHelping Decision‑Makers Say Yes to Kotlin\nScaling Kotlin Adoption Across Your Organization\nPersuading Management: Building the Business Case for Kotlin\nOnce you have achieved a critical mass of Kotlin supporters, presenting a compelling business case to management requires moving beyond code demonstrations to hard data and strategic considerations.\nMarket momentum and industry validation\nKotlin has demonstrated remarkable growth, with 2.5 million developers worldwide now using the language. This represents sustained adoption since Google’s pivotal 2017 announcement declaring Kotlin the official language for Android development, followed by Spring Boot’s embrace of Kotlin as a first-class citizen.\nSource: Keynote KotlinConf 2025\nThe momentum has accelerated significantly. Spring Boot, which commands approximately 90% of the backend market share, formalized a strategic partnership with JetBrains in 2025 – a clear signal of Kotlin’s enterprise viability and long-term trajectory.\nFraming the strategic decision\nWhile these adoption metrics demonstrate Kotlin’s market validation, management decisions require a comprehensive cost-benefit analysis. Technology adoption at scale involves significant investments in training, tooling, and potential migration efforts. The key is presenting both the tangible benefits and realistic implementation costs, allowing leadership to make an informed strategic decision rather than a purely technical one.\nThe business gains unlocked by embracing Kotlin\nThese are the business gains when choosing Kotlin:\n\nAdvantageDetailsBusiness/Team impact\n~30% less code. Better code clarity.~30% less to write, read, fix, and maintain.➜ Increased productivity.\n➜ Improved maintainability.\n25% fewer bugs thanks to safety featuresKotlin reduces defects out of the box – no extra skills required – through features like null safety, safe APIs, and sensible defaults.➜ Better quality – happier customers and developers.\n➜ More time for new features.\n➜ Faster time-to-market.\nInvest in just one new language: KotlinKeep existing frameworks (e.g. SpringBoot, Micronaut, Quarkus).➜ Framework knowledge is preserved.\nBetter choice for AIKotlin is more AI-friendly due to noise reduction, clarity, fluency, and more, which aligns with how LLMs process code.➜ Better productivity with AI, which is increasingly influencing coding.\nFully interoperable with JavaKotlin is fully interoperable with Java; no rewrite of libraries required.➜ Investments based on Java are preserved.\nWell supportedBacked by strong players: JetBrains, Google, and Meta.➜ Future-proof choice.\nGradual adoptionKotlin supports incremental migration paths.➜ No “Big Bang” needed.\nIncrease in developer happinessIn surveys and studies, Kotlin developers consistently report better developer experience and higher job satisfaction.➜ Attract new developers.\n➜ Better retention 😃😃😃.\nFaster audit, safer complianceKotlin’s type safety, immutability, and clear data structures make systems easier to trace, validate, and certify. These qualities support transparent and reliable software processes across regulated domains. For a real-world example, see Kotlin in Payment Gateways and Fintech: A Strategic Fit for 2026 Architectures.➜ Easier internal and external audits.  \n➜ Lower compliance effort and risk. \n➜ Greater organizational transparency.\n\n\n\n\n\nSome words on developer happiness\nLooking at my career, I was greatly rewarded for letting go of my attachment to the seemingly safe career choice of Java. Daily, I’m empowered with a language that is a joy to work with and helps me express what I want to achieve in the best possible way, concisely, safely, and productively. \nIt’s a fact that, personally, I’ve become a happier developer (human ;-)?) using Kotlin. Though this is subjective, developer satisfaction data tells the same unmistakable story:\nBackend developers who migrate from Java to Kotlin report dramatically higher happiness levels across every major industry survey. \nStack Overflow’s Developer Survey data shows Kotlin consistently ranking among the top five most loved languages at ~63% satisfaction, significantly outpacing Java’s ~54% rating.\nThe Mercedes-Benz.io backend team documented “significantly more concise code than Java, reducing boilerplate and improving readability” while achieving measurable productivity gains in their microservices architecture.\nTyler Russell, a backend developer with 15 years of Java experience, reports after four years with Kotlin: “I really like Kotlin… it feels like it enables productivity significantly more than it hinders it”, and never wants to return to Java.\nCorporate Kotlin to Java backend migrations demonstrate that these happiness improvements scale effectively across enterprise environments. \nN26’s backend engineering team converted 60% of their microservices to Kotlin within two years, reporting enhanced developer satisfaction and reduced production issues.\nING’s five-year backend adoption journey shows sustained organic growth, with 8% of their 20,000+ technical staff repositories now using Kotlin, demonstrating that developers voluntarily choose Kotlin when given the option.\nThe cost / return on investment of embracing Kotlin:\nThese are the investments required for choosing Kotlin. \n\nInvestment DescriptionExpected Return / Impact\nDeveloper trainingTraining sessions, workshops, and onboarding materials.➜ Experienced developers new to Kotlin are productive in 2–3 weeks.\n➜ ROI in ~1–4 months.\nCodebase migration (if applicable)A gradual rewrite or a mixed Kotlin/Java code setup strategy is required.➜ No need for big bang rewrite\n➜ Maintains delivery speed.\nKnowledge sharingInternal Kotlin champions, brown bag sessions, shared repos with examples.➜ Faster team-wide adoption.\n➜ Reuse of best practices.\nHiring / upskillingHire Kotlin-experienced devs or upskill existing Java devs.➜ Higher retention.\n➜ Broader talent pool.\n\n\n\n\n\nOne of the most common concerns when considering Kotlin adoption is the perceived shortage of experienced Kotlin developers. But rather than a roadblock, this can be a strategic advantage:\n✅ Fast upskilling for Java developers\nKotlin is designed to be intuitive for Java developers. With the right guidance, most can become productive in just 2–3 weeks.\n✅ Kotlin attracts high-quality developers\nThose who actively pursue Kotlin are often curious, modern, and quality-driven – traits you want in your engineering team.\n✅ Kotlin enhances your company image\nAdopting Kotlin signals that you embrace modern, forward-looking technology, which helps attract top-tier talent.\n✅ Kotlin boosts developer happiness and retention\nKotlin developers consistently report higher job satisfaction, making it easier to retain engaged and motivated team members.\nIn short: Kotlin isn’t just a smart tech choice – it’s a strategic people decision.\nUp next in the series\nWe shift focus from convincing developers to persuading decision-makers. The next post shows how to build a compelling business case for Kotlin adoption, grounded in real data and measurable outcomes. You’ll learn how to translate developer wins into management arguments, link productivity gains to cost savings, and demonstrate why Kotlin is more than a technical upgrade – it’s a strategic move for teams and companies alike.\nUrs Peter\nUrs is a seasoned software engineer, solution architect, conference speaker, and trainer with over 20 years of experience in building resilient, scalable, and mission-critical systems, mostly involving Kotlin and Scala.\nBesides his job as a consultant, he is also a passionate trainer and author of a great variety of courses ranging from language courses for Kotlin and Scala to architectural trainings such as Microservices and Event-Driven Architectures.\nAs a people person by nature, he loves to share knowledge and inspire and get inspired by peers on meetups and conferences. Urs is a JetBrains certified Kotlin trainer.",
        "dc:creator": "Alyona Chernyaeva",
        "content": "Guest post by Urs Peter, Senior Software Engineer and JetBrains-certified Kotlin Trainer. For readers who’d like a more structured way to build Kotlin skills, Urs also leads the&#160;Kotlin Upskill Program at Xebia Academy. This is the fourth post in The Ultimate Guide to Successfully Adopting Kotlin in a Java-Dominated Environment, a series that follows how [&#8230;]",
        "contentSnippet": "Guest post by Urs Peter, Senior Software Engineer and JetBrains-certified Kotlin Trainer. For readers who’d like a more structured way to build Kotlin skills, Urs also leads the Kotlin Upskill Program at Xebia Academy. This is the fourth post in The Ultimate Guide to Successfully Adopting Kotlin in a Java-Dominated Environment, a series that follows how […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=655947",
        "isoDate": "2025-11-18T12:11:19.000Z"
      },
      {
        "creator": "Lena Morozova",
        "title": "Open Source in Focus: Projects We’re Proud to Support",
        "link": "https://blog.jetbrains.com/blog/2025/11/18/open-source-in-focus-projects-we-re-proud-to-support/",
        "pubDate": "Tue, 18 Nov 2025 12:07:29 +0000",
        "content:encodedSnippet": "At JetBrains, we love seeing the developer community grow and thrive. That’s why we support open-source projects that make a real difference — the ones that help developers learn, build, and create better software together. We’re proud to back open-source maintainers with free licenses and to contribute to initiatives that strengthen the ecosystem and the people behind it.\nIn this post, we highlight five open‑source projects from different ecosystems, written in established languages like Python and JavaScript or fast‑growing ones like Rust. Different as they are, each shares the same goal: elevating the developer experience. Together, they show how the right tools boost productivity and make workflows more enjoyable.\nRatatui\nBorn as the community-driven successor to the discontinued tui-rs library, Ratatui brings elegance to terminal UIs. It’s modular, ergonomic, and designed to help developers build interactive dashboards, widgets, and even embedded interfaces that go beyond the terminal.\nJetBrains IDEs help me focus on the code rather than the tooling. They’re self-contained, so I don’t need to configure much to get started – they just work. With powerful code highlighting, automatic fixes, refactorings, and structural search, I can easily jump around the codebase and make edits.\n— Orhun Parmaksız, Ratatui Core Maintainer\nThe upcoming 0.30.0 release focuses on modularity, splitting the main crate into smaller, independently usable packages. This change simplifies maintenance and makes it easier to use widgets in other contexts. And with new no_std support, Ratatui is expanding to power a wide range of use cases beyond the terminal.\nDjango\nIf Ratatui brings usability to the terminal, Django brings it to the web. Originally created in 2003 to meet both fast-paced newsroom deadlines and the demands of experienced developers, Django remains the go-to framework for “perfectionists with deadlines”. It eliminates repetitive tasks, enforces clean, pragmatic design, and provides built-in solutions for security, scalability, and database management – helping developers write less code and achieve more.\nJetBrains IDEs, especially PyCharm, boost productivity with built-in Django support – including project templates, automatic settings detection, and model-to-database migrations – as well as integrated debugging and testing tools that simplify finding and fixing issues. The version control integration also makes it easier for contributors to refine and polish their work.\n— Sarah Boyce, Django Fellow\nBacked by a thriving global community, Django’s roadmap includes composite primary key support, built-in CSP integration, and a focus on making Django accessible by default. Every eight-month release delivers incremental improvements while maintaining backward compatibility – clear proof that long-term stability and innovation can coexist.\nJHipster\nBoth Django and JHipster help developers move fast, but they take different paths. JHipster began as the “anti-mullet stack” – serious in the back, party in the front – created to help developers quickly bootstrap full-stack applications with Spring on the backend and Angular.js on the frontend. Today, it’s still one of the most comprehensive open-source generators, offering a complete full-stack solution with built-in security, performance, and best practices.\nJHipster has always been about great productivity and great tooling, so naturally, we’ve always been IntelliJ IDEA fans – we even have our own JHipster IntelliJ IDEA plugin! What I love most is the clean UI, the performance, and all the plugins that make my life so much easier. I use Maven and Docker support all the time, and they’re both absolutely top-notch.\n— Julien Dubois, JHipster Creator\nThe project is now split into two teams – JHipster Classic, which focuses on the original full-stack generator written in JavaScript, and JHipster Lite, which develops a modernized, DDD-oriented version written in Java and targeted primarily at the backend. This structure allows the community to experiment more freely and attract new contributors.\nAs AI-assisted generation evolves, JHipster’s mission remains the same: empowering developers with the latest cutting-edge technology and a true full-stack approach.\nBiome\nOnce the structure is in place, consistency becomes the next challenge. That’s where Biome, a modern, all-in-one toolchain for maintaining web projects, comes in. It supports every major web language and maintains a consistent experience between the CLI and the editor. The goal of its creators was simple: make a tool that can handle everything from development to production, with fewer dependencies, less setup time, faster CI runs, and clear, helpful diagnostics.\nI’m a long-term user of JetBrains IDEs! RustRover has greatly improved since launch – its debugging features and new JavaScript module mean I can maintain all Biome projects, even our Astro-based website, in a single IDE. It’s great that JetBrains really listens to users and their feedback.\n— Emanuele Stoppa, Biome Creator\nBiome’s roadmap includes adding Markdown support, type inference, .d.ts file generation, JSDoc support, and embedded-language support. As a community-led project, Biome welcomes contributions of all kinds – every bit of help makes a difference.\nVuestic UI\nWhen it’s time to polish the frontend, Vuestic UI takes over. This open-source project focuses on accessibility, theming, and a delightful developer experience. Built for Vue 3, it offers a flexible, easy-to-use component library that scales effortlessly from quick prototypes to enterprise-grade dashboards.\nThe right development environment makes a huge difference when building complex open-source tools like Vuestic UI and Vuestic Admin. Our team relies on JetBrains IDEs every day for their best-in-class refactoring tools that let us make bold changes with confidence, fast and reliable code navigation, and rock-solid performance. Most of what we need works right out of the box – no extra plugins or setup required. For us, JetBrains isn’t just a preference – it’s a productivity multiplier.\n— Maxim Kobetz, Senior Vue.js Developer\nAfter 12 years in frontend development, WebStorm – along with IntelliJ IDEA and PyCharm – has always been my trusted toolkit. Even now, when I’m not coding every day, I know I can rely on WebStorm for quick tweaks – every update feels smooth and never disrupts my workflow. It’s intuitive, beautiful, and just works the way I expect it to. I know switching IDEs is always a time sink, but with JetBrains, it’s absolutely worth it – you’ll never want to switch again.\n— Anastasiia Zvenigorodskaia, Community Manager at Vuestic UI & Vuestic Admin\nThese projects showcase a common truth: Great developer experience happens when tools get out of your way. With JetBrains IDEs enhancing everything from code navigation to collaboration, these teams turn ideas into usable, elegant tools.\nExplore these projects, contribute if you can, or start your own! RustRover, WebStorm, and PyCharm are free for open-source development and ready to help you code, collaborate, and contribute.\nDownload RustRover\n                                                                Download WebStorm\n                                                                Download PyCharm\n                                    \nMore from this series\n                                                        \nCLion and the Open-Source Community: Growing Together\nFrom the beginning, CLion has been shaped by the needs of C and C++ developers around the world. Our cross-platform IDE was built to simplify development, boost productivity, and make working with C++ more enjoyable.\n\n\n\nWe’re excited to take the next step in our ongoing collaboration with the commun…\nRead the post\n                            \n                                                        \nHow PhpStorm Helps Maintain PHP Open-Source Projects: Interviews and Real-World Examples\nThe PHP ecosystem is driven by passionate developers building tools that power everything from content management systems right the way through to testing libraries and database layers. Behind each project is a dedicated team working to modernize code, improve performance, and move the ecosystem for…\nRead the post\n                            \n                                                        \nHow Java Open-Source Projects Use IntelliJ IDEA: Real-World Examples – Part 1\nAt JetBrains, we build tools to help developers stay focused and productive, and we’re especially proud when those tools help power the open-source projects that developers around the world rely on every day. Shaping the direction of Java development, such projects contribute substantially to the vi…\nRead the post\n                            \n                                                        \nHow Java Open-Source Projects Use IntelliJ IDEA: Real-World Examples – Part 2\nIn Part 1 of this series, we introduced some of the Java community’s most recognized open-source projects. Now, we’re back with more standouts: projects that speed up builds, strengthen testing, and simplify working with modern web stacks. And as always, IntelliJ IDEA helps maintainers move faster, …\nRead the post",
        "dc:creator": "Lena Morozova",
        "content": "At JetBrains, we love seeing the developer community grow and thrive. That’s why we support open-source projects that make a real difference — the ones that help developers learn, build, and create better software together. We’re proud to back open-source maintainers with free licenses and to contribute to initiatives that strengthen the ecosystem and the [&#8230;]",
        "contentSnippet": "At JetBrains, we love seeing the developer community grow and thrive. That’s why we support open-source projects that make a real difference — the ones that help developers learn, build, and create better software together. We’re proud to back open-source maintainers with free licenses and to contribute to initiatives that strengthen the ecosystem and the […]",
        "guid": "https://blog.jetbrains.com/?post_type=blog&p=659334",
        "categories": [
          "community",
          "rustrover",
          "community-support",
          "intellij-idea",
          "open-source-program",
          "oss-projects",
          "pycharm",
          "webstorm"
        ],
        "isoDate": "2025-11-18T12:07:29.000Z"
      }
    ]
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Paul Chapman",
        "title": "Visual Studio – Built for the Speed of Modern Development",
        "link": "https://devblogs.microsoft.com/visualstudio/visual-studio-built-for-the-speed-of-modern-development/",
        "pubDate": "Mon, 24 Nov 2025 15:00:06 +0000",
        "content:encodedSnippet": "The release of Visual Studio 2026 two weeks ago marks the next evolution in Microsoft’s 50-year commitment to deliver the tools that developers love and enterprises trust, built to move at the pace of modern development. Software development is moving faster than ever, and Visual Studio is evolving right along with you.\nToday, we’re announcing an important step forward in the lifecycle and release cadence for Visual Studio. Visual Studio will be a continuously updated modern IDE designed to deliver innovation as soon as it is ready, while maintaining the reliability and stability you count on every day. We’ll deliver this through monthly feature updates and a new annual major release.\nWhy We’re Modernizing\nVisual Studio now innovates at the pace of modern software. Whether you build desktop apps, cloud services, games, web APIs, or AI agents, the IDE will now ship the latest performance and capability improvements every month, with GitHub Copilot experiences always up to date.\nWe also heard the request for frictionless updates. Your existing projects, solutions, and extensions continue to work as they do today. We’re maintaining a high compatibility bar across monthly and annual releases, so you stay productive while the IDE evolves in place and your builds remain stable.\nBecause the IDE is decoupled from the build tools, these changes do not require you to modify existing projects or rebuild working applications. Visual Studio updates monthly, but your .NET or C++ compiler build tools, runtimes, and extensions continue to work exactly as before. Build tools and SDKs have their own multi-year lifecycles, so your build environment remains stable even as the IDE gets new features.\nBuilt for Modern Development\nSince Visual Studio 2017, we have been steadily increasing our release cadence, delivering quarterly feature updates, servicing releases, and flexible build tools choices. With Visual Studio 2026, we are taking the next step, moving to a modern support lifecycle that keeps you on the latest tools and features automatically.\nThis new approach means:\nFeature updates every month, not every quarter.\nA new annual version each year, released in November alongside the .NET release.\nPredictable servicing and support under the Modern Support Lifecycle, with one year of monthly feature updates followed by one year of security fixes.\nUpdate to the latest release to remain supported and serviced with new features, fixes, and security updates.\nIt is all about giving you updates as soon as they are ready.\nBuild Tools Freedom – You Are in Control\nWith these changes to how Visual Studio is updated and supported, it’s equally important to understand how build tools and components fit into this new model.\nWe know every team moves at its own pace. Visual Studio continues to carry a wide range of build tools and components to target the platforms you’ve come to expect. With multiple supported versions of these build tools included, you can choose when to move your projects forward. You can adopt the latest compiler, runtime, or SDK on your schedule while still benefiting from IDE improvements and AI features each month.\nThese build tools, SDKs, and runtimes are available under their own support lifecycles. For example, modern .NET releases every year, with Standard Term Support (STS) for 2 years and Long-Term Support (LTS) support for 3 years. The lifecycle for .NET Framework is tied to the Windows release in which it ships.\nFor C++ developers, we are also decoupling the Microsoft C++ (MSVC) compilers and Build Tools from the Visual Studio lifecycle. This lets the compiler team ship faster, more agile updates every six months, with long-term supported versions every 2 years. For more details, see today’s blog post on the new MSVC lifecycle.\nInsiders and Stable Channels\nTo support this faster cadence, starting with Visual Studio 2026 two channels are available:\nInsiders Channel – Try upcoming features first, share feedback, and help shape what is next. To install go to https://visualstudio.microsoft.com/insiders/. (Insiders replaces the “Preview” Channel previously available.)\nStable Channel – Get validated, production-ready features every month. To install, go to https://visualstudio.microsoft.com/downloads/. (Stable replaces the “Current” Channel previously available.)\nFeatures that appear in the Insiders Channel will roll into the Stable Channel when they’re ready for broad adoption. If you are on Stable, you will receive a monthly feature update and servicing releases as needed. (For more information, see Visual Studio Channels and Release Rhythm and Visual Studio Product Lifecycle and Servicing.)\nEach year, the IDE will update to the next annual version, for example next November, Visual Studio 2026 will update in place to Visual Studio 2027, with no disruption to your environment.\nOur enterprise customers at times need more flexibility in when they schedule updates. To ensure they are fully supported, we’ll also offer a side-by-side Long-Term-Servicing Channel (LTSC) for the prior annual release. The LTSC provides security servicing for 1 year. For example, in November of 2026, you will be able to choose to switch to the Visual Studio 2026 LTS Channel to remain on a static feature set for an additional year.\nHowever, it’s important to note that Visual Studio LTSC is not necessary to maintain your project in a known state. If your project uses .NET 10 or MSVC 14.50 that ship with Visual Studio 2026, when you update to Visual Studio 2027 those build tools will still be available, and your projects should just build as before.\nFlexible Licensing and Registration\nThese changes for Visual Studio result in a shift in how we handle product registration. There are no changes to Visual Studio Community, it remains free for open-source projects, education, and small organizations. (See the license for details.)\nFor the Professional and Enterprise editions, if you have a Visual Studio Subscription, there’s no change to the registration process. You will continue signing in as before and automatically receive updates through the modern lifecycle or obtain your product key from the Visual Studio Subscribers portal. If you use a stand-alone Professional license, you simply purchase the new annual version each year. Product keys will continue to work for that annual version, and new keys will unlock the next year’s release.\nAdditionally, there are no changes to the lifecycle for Visual Studio 2022, Visual Studio 2019, and Visual Studio 2017.\nAlways Current, Always Ready\nVisual Studio 2026 marks the start of a new era, an IDE that is modern, intelligent, and continuously improving. You will spend less time waiting for updates and more time building great software with the latest tools.\nWe are excited for you to experience this new cadence, share your feedback, and help shape the future of Visual Studio. The journey continues, and Visual Studio will be right there with you, every month, every release.\nThe post Visual Studio – Built for the Speed of Modern Development appeared first on Visual Studio Blog.",
        "dc:creator": "Paul Chapman",
        "content": "<p>Visual Studio will adopt the Modern Support Lifecycle as a continuously updated IDE designed to deliver innovation as soon as it is ready, while maintaining the reliability and stability you count on every day with control over your build tools choices. </p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/visual-studio-built-for-the-speed-of-modern-development/\">Visual Studio – Built for the Speed of Modern Development</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Visual Studio will adopt the Modern Support Lifecycle as a continuously updated IDE designed to deliver innovation as soon as it is ready, while maintaining the reliability and stability you count on every day with control over your build tools choices. \nThe post Visual Studio – Built for the Speed of Modern Development appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=254976",
        "categories": [
          "Visual Studio",
          "Announcement",
          "lifecycle",
          "Support",
          "Visual Studio 2026"
        ],
        "isoDate": "2025-11-24T15:00:06.000Z"
      },
      {
        "creator": "Jason Chlus",
        "title": "Spend Less Time Upgrading, More Time Coding in Visual Studio 2026",
        "link": "https://devblogs.microsoft.com/visualstudio/spend-less-time-upgrading-more-time-coding-in-visual-studio-2026/",
        "pubDate": "Tue, 18 Nov 2025 17:00:27 +0000",
        "content:encodedSnippet": "In the past, moving to the next major version of Visual Studio could take hours, sometimes days, to recreate your dev environment the way you like it. Visual Studio 2026 makes it easier than ever to stay current with the latest productivity features, performance improvements, and security fixes all without disrupting your flow. With the new Visual Studio install experience, you can effortlessly recreate your previous Visual Studio 2022 environment. Your workloads, SDKs, toolsets, extensions and settings are automatically copied and configured, so everything you need to build and continue developing your project is ready the moment you open Visual Studio 2026.\nWith support for multiple toolsets and SDK versions, Visual Studio 2026 lets you update the IDE independently from your project dependencies. Keep your environment modern and secure, while maintaining full compatibility with your existing builds.\nInstall Visual Studio 2026 from the installer Available tab or download the bootstrapper.\n\nThe new install experience\nThe new Visual Studio Installer is built to make upgrading seamless. It detects your existing Visual Studio 2022 setup and can rebuild it in Visual Studio 2026, including workloads, toolsets, SDKs, extensions, and settings. You’ll spend less time setting up and more time writing code.\nIf you’re setting up on a new machine, simply import your .vsconfig file (which captures your favorite workloads, toolsets, SDKs and extensions) and pair it with your .vssettings file to recreate your previous Visual Studio environment exactly the way you like it.\n\nSetup Assistant (in-IDE dependency acquisition)\nWhen you load a project in Visual Studio 2026, the new Setup Assistant automatically detects the dependencies your project targets. With support for multiple toolsets and SDKs, you can quickly retarget your project to the latest version, or, if needed, install any specific missing dependencies with just a few clicks.\nFor C++ developers – the Setup Assistant identifies MSVC Build Tools and Windows SDKs your project targets. You can retarget your project to the latest version or install any missing components with a single click directly in the Visual Studio Installer.\n\nFor more details check out the C++ blog post: Blog Post – Upgrading Your Projects.docx\nFor .NET developers (based on your feedback) – If your project uses a pinned global.json, Setup Assistant provides a link matching the pinned .NET SDK, for quick installation in your browser.\n\nGitHub Copilot app modernization now built into Visual Studio\nThe GitHub Copilot app modernization agent is an AI-powered tool in Visual Studio that helps you upgrade your projects to newer versions and migrate them to Azure. It automatically detects outdated dependencies and target frameworks, provides guided recommendations, and makes real-time code changes, so you can modernize your code without interruptions. Migrating to Azure unlocks scalability, security, and operational efficiency for your projects.\nHow to get started:\nOpen your project or solution in Visual Studio, then launch the Modernization Agent by right-clicking your project or solution and selecting Modernize, or type @modernize in Copilot Chat with your upgrade or migration request.\nWhen new SDKs or toolsets become available, you can easily retarget your entire solution or specific projects with the Setup Assistant. Simply reopen this tab via Project > Retarget solution, or right click your solution/project and select Retarget solution. This makes it simple to modernize projects.\nSee live examples\nC++ modernization by Michael Price\n.NET modernization video by Brady Gaster and Cathy Sulivan\nVisual Studio is shipping faster\nVisual Studio 2026 will get updates on the Stable channel every month, bringing new features, performance improvements, security and bug fixes to you faster than ever.\nInstall Visual Studio 2026 Stable\n\nVisual Studio Insiders will get updates even faster, helping us iterate with you in real time. With this new cadence and rapid iteration speed you’ll always have the latest.\nInstall Visual Studio Insiders\n\nAlways current with Visual Studio 2026\nTo make updating effortless, Visual Studio 2026 introduces Update on Close. When you finish your session, Visual Studio will download and install updates after you close the IDE, so you’ll always start your next session with the latest features, fixes, and improvements.\nThis is enabled by default for Community and Team Explorer and on the Insiders Channel. For Enterprise and Professional editions on the Stable Channel, you can turn it on by navigating to Tools > Options > Environment > More Settings > Product Updates and select the “Always update on close” checkbox.\n\nYou are always in control\nIf something doesn’t go as planned, Visual Studio 2026 keeps you in control:\nImproved repair detects and resolves incomplete installations automatically.\nA quick rollback returns you to your previous environment in minutes.\nSide-by-side installs let you keep Visual Studio 2022 and 2026 on the same machine.\nYou’re always in control, knowing your productivity and stability are protected. Visual Studio provides options to move forward or revert with minimal risk.\nWhen Should You Upgrade?\nThe best time is now. Visual Studio 2026 is our most performant, reliable, and productive IDE yet with the easiest upgrade experience we’ve ever delivered.\nGet faster installs, monthly feature updates, smarter dependency management, and an environment built to keep you focused on writing great code, not maintaining your setup.\nTry Visual Studio 2026 today and see how seamless upgrading can be.\nInstall Visual Studio 2026 Stable from the Installer Available tab or download the bootstrapper.\nThe post Spend Less Time Upgrading, More Time Coding in Visual Studio 2026 appeared first on Visual Studio Blog.",
        "dc:creator": "Jason Chlus",
        "comments": "https://devblogs.microsoft.com/visualstudio/spend-less-time-upgrading-more-time-coding-in-visual-studio-2026/#comments",
        "content": "<p>In the past, moving to the next major version of Visual Studio could take hours, sometimes days, to recreate your dev environment the way you like it. Visual Studio 2026 makes it easier than ever to stay current with the latest productivity features, performance improvements, and security fixes all without disrupting your flow. With the [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/spend-less-time-upgrading-more-time-coding-in-visual-studio-2026/\">Spend Less Time Upgrading, More Time Coding in Visual Studio 2026</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "In the past, moving to the next major version of Visual Studio could take hours, sometimes days, to recreate your dev environment the way you like it. Visual Studio 2026 makes it easier than ever to stay current with the latest productivity features, performance improvements, and security fixes all without disrupting your flow. With the […]\nThe post Spend Less Time Upgrading, More Time Coding in Visual Studio 2026 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=254942",
        "categories": [
          "Copilot",
          "Installation and Updates",
          "Productivity",
          "Visual Studio",
          "Modernization",
          "Setup",
          "Updates",
          "Visual Studio 2026"
        ],
        "isoDate": "2025-11-18T17:00:27.000Z"
      }
    ]
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": [
      {
        "creator": "권용진",
        "title": "11/20 삼성전자 사내 강연 - 그래서 스테이블코인이 뭔데 저자 강연",
        "link": "https://brunch.co.kr/@@H9i/92",
        "pubDate": "Sun, 23 Nov 2025 19:20:50 GMT",
        "author": "권용진",
        "content": "감사하게도 국내 최고의 IT 기업인 삼성전자의 모바일 사업부에서 &lt;그래서 스테이블코인이 뭔데&gt;와 관련한 강연을 하게 되었습니다.  무려 200명 이상의 임직원 분들이 참여해주셨습니다. 사내 방송국에서 온라인 강연을 하였는데, 이렇게 많은 분들이 참여할줄 몰랐어서 당황하였습니다.     확실히 엔지니어분들과 테크 현업에 계신 분들이다보니 질문의 수준이 굉장하<img src= \"https://img1.daumcdn.net/thumb/R1280x0.fjpg/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FH9i%2Fimage%2FCm5FNwa7kicKwvRPFQNoIqMb2kE.HEIC\" width=\"500\" />",
        "contentSnippet": "감사하게도 국내 최고의 IT 기업인 삼성전자의 모바일 사업부에서 <그래서 스테이블코인이 뭔데>와 관련한 강연을 하게 되었습니다.  무려 200명 이상의 임직원 분들이 참여해주셨습니다. 사내 방송국에서 온라인 강연을 하였는데, 이렇게 많은 분들이 참여할줄 몰랐어서 당황하였습니다.     확실히 엔지니어분들과 테크 현업에 계신 분들이다보니 질문의 수준이 굉장하",
        "guid": "https://brunch.co.kr/@@H9i/92",
        "isoDate": "2025-11-23T19:20:50.000Z"
      }
    ]
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": [
      {
        "creator": "고명환",
        "title": "테슬라 FSD v14 출시 임박, 자율주행의 새 시대",
        "link": "https://brunch.co.kr/@@LOc/315",
        "pubDate": "Fri, 21 Nov 2025 03:26:09 GMT",
        "author": "고명환",
        "content": "테슬라 FSD v14, 왜 중요한가? 테슬라가 곧 출시 할 테슬라 FSD v14는 단순한 업데이트를 넘어 자율주행 상용화의 분수령으로 평가받고 있습니다. 일론 머스크는 &nbsp;&quot;14.2 버전부터는 차양이 마치 감각을 가진 존재처럼 느껴질 것&quot; 이라고 강조했습니다. 이는 단순한 마케팅 문구가 아니라, 실제 AI모델의 성능이 이전 세대와 비교할 수 없을 만큼 향상되<img src= \"https://img1.daumcdn.net/thumb/R1280x0.fjpg/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FA4teChF_g3vNrWnvZr500twxupw\" width=\"500\" />",
        "contentSnippet": "테슬라 FSD v14, 왜 중요한가? 테슬라가 곧 출시 할 테슬라 FSD v14는 단순한 업데이트를 넘어 자율주행 상용화의 분수령으로 평가받고 있습니다. 일론 머스크는  \"14.2 버전부터는 차양이 마치 감각을 가진 존재처럼 느껴질 것\" 이라고 강조했습니다. 이는 단순한 마케팅 문구가 아니라, 실제 AI모델의 성능이 이전 세대와 비교할 수 없을 만큼 향상되",
        "guid": "https://brunch.co.kr/@@LOc/315",
        "isoDate": "2025-11-21T03:26:09.000Z"
      }
    ]
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "「RULIWEB」",
        "title": "[MULTI] 로마의 패권은 바다에 있다, 아노 117: 팍스 로마나",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2392",
        "pubDate": "Mon, 24 Nov 2025 13:57:20 +0900",
        "author": "「RULIWEB」",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/25/11/24/19ab4267b3f4cacdc.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2025-11-24T04:57:20.000Z"
      },
      {
        "creator": "［RULIWEB］",
        "title": "[MULTI] 이제는 희귀해진 무난함 그리고 필드쟁의 외통수, 아이온 2",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2391",
        "pubDate": "Mon, 24 Nov 2025 11:53:50 +0900",
        "author": "［RULIWEB］",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/25/11/24/19ab3c79d755104c1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2025-11-24T02:53:50.000Z"
      },
      {
        "creator": "｜RULIWEB｜",
        "title": "악역영애 4컷 만화 - 27화, 위기인데스와 ②",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2390",
        "pubDate": "Wed, 19 Nov 2025 20:22:29 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/25/11/19/19a9bd95a4051ad6b.jpg\">",
        "contentSnippet": "",
        "categories": [
          "웹툰"
        ],
        "isoDate": "2025-11-19T11:22:29.000Z"
      },
      {
        "creator": "｜RULIWEB｜",
        "title": "익숙하고도 새로운 모습, 포켓몬 레전즈 Z-A",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2389",
        "pubDate": "Tue, 18 Nov 2025 16:39:03 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/25/11/18/19a95e01d5c51ad6b.jpg\">",
        "contentSnippet": "",
        "categories": [
          "게임툰"
        ],
        "isoDate": "2025-11-18T07:39:03.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "Central Dogma 컨트롤 플레인으로 LY Corporation의 수천 개 서비스를 연결하기",
        "link": "https://techblog.lycorp.co.jp/ko/connecting-thousands-of-services-with-central-dogma-control-plane",
        "pubDate": "Fri, 21 Nov 2025 06:30:00 GMT",
        "content": "이 글은 Tech-Verse 2025에서 발표된 Central Dogma Control Plane으로 LY Corporation의 수천 개 서비스를 연결하기 세션을 글로 옮긴 것입...",
        "contentSnippet": "이 글은 Tech-Verse 2025에서 발표된 Central Dogma Control Plane으로 LY Corporation의 수천 개 서비스를 연결하기 세션을 글로 옮긴 것입...",
        "guid": "https://techblog.lycorp.co.jp/ko/connecting-thousands-of-services-with-central-dogma-control-plane",
        "isoDate": "2025-11-21T06:30:00.000Z"
      },
      {
        "title": "코드 품질 개선 기법 24편: 유산의 가치",
        "link": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-24",
        "pubDate": "Fri, 21 Nov 2025 02:00:00 GMT",
        "content": "이 글은 2024년 5월 9일에 일본어로 먼저 발행된 기사를 번역한 글입니다.LY Corporation은 높은 개발 생산성을 유지하기 위해 코드 품질 및 개발 문화 개선에 힘쓰고 ...",
        "contentSnippet": "이 글은 2024년 5월 9일에 일본어로 먼저 발행된 기사를 번역한 글입니다.LY Corporation은 높은 개발 생산성을 유지하기 위해 코드 품질 및 개발 문화 개선에 힘쓰고 ...",
        "guid": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-24",
        "isoDate": "2025-11-21T02:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "소비자 DNA",
        "link": "https://www.thestartupbible.com/2025/11/koreas-consumer-dna.html",
        "pubDate": "Sun, 23 Nov 2025 21:21:00 +0000",
        "content:encodedSnippet": "2주 전에 잠깐 동경에 갔었는데, 과거부터 친분이 있던 일본 VC들과 다양한 이야기를 했다. 자연스럽게 한국과 일본의 스타트업 생태계 이야기를 특히 많이 했는데, 한국에 집중적으로 투자하는 나 같은 VC는 당연히 일본 시장보단 한국 스타트업 시장이 더 좋다고 믿지만, 내가 만난 일본 VC들도 대부분 한국의 벤처생태계를 부러워하는 느낌을 강하게 받았다. 어떤 일본 VC는 대놓고 나에게 한국 벤처생태계를 볼 때마다 너무나 부럽고, 일본도 한국 시장과 창업가들로부터 A부터 Z까지 모든 걸 적극적으로 배워야 한다고 주장했다.\n일본의 상장 시장의 크기는 한국의 3.5배 정도가 된다. 상당히 크고, 난 한국이 조만간 일본의 상장 시장 규모를 뛰어넘을 것이라고 확신하지만 현재의 이 규모는 상당히 부럽다. 그런데 내가 만난 일본 VC들은 오히려 한국의 역동적이고 큰 IPO 시장이 부럽다고 이야기했다. 무슨 말인지 더 구체적으로 물어보니, 일본의 상장 시장은 크지만, 자세히 보면 tech IPO는 질보단 양으로 만들어지고 있다는 게 이들의 답변이다. 한국 창업가들은 꿈과 야망이 상대적으로 커서 항상 아주 큰 IPO를 꿈꾸면서 사업을 하는데 – 물론, 그렇다고 IPO를 다 하는 것도 아니고, 해도 큰 IPO가 되는 건 아니지만 – 일본 창업가들은 사업하다가 어느 시점에 그냥 작은 IPO를 하는 게 요샌 유행같이 번지고 있다고 했다. 한 1,000억 정도의 IPO를 하면 창업가들은 그래도 잘 먹고 잘살 수 있고, 일본에서 이런 작은 IPO를 하는 게 상대적으로 쉽기 때문에 너도나도 적당한 규모로 사업을 키우고 IPO를 한다고 들었다. 창업가들은 돈을 벌어서 좋지만, 이 회사에 투자한 VC는 큰 재미를 못 보고, 계속 창업가들의 꿈과 야망이 이렇게 줄어들면 일본 스타트업 생태계는 큰 성장을 할 수 없다는 우려를 대화 내내 표시했다. 정확하게 “작은 IPO가 하나씩 될 때마다 일본 창업가들의 야망도 하나씩 줄어드는 것 같다.”라는 말을 했는데, 곰곰이 생각해 보면 일리가 있는 말 같다.\n그리고 일본 VC들로부터 내가 반복적으로 들었던 주제이자, 이들이 한국에 대해서 가장 부러워하는 게 한국인들의 “소비자 DNA(Consumer DNA)”였다. 한국 시장엔 소비자 DNA가 매우 강하게 자리 잡고 있는데, 이는 우리가 네이버, 쿠팡, 카카오, 토스, 당근, 배달의 민족 등과 같은 좋은 자체 B2C 유니콘을 끊임없이 만들고 제품화할 수 있는 이유다. 그리고 계속 이렇게 좋은 소비자 제품들이 시장에 출시되면, 한국인 특유의 경쟁심과 질투가 발동하면서 계속 더 좋은 기능, 더 좋은 UI/UX, 더 좋은 가격의 경쟁 제품들이 나오면서 “양이 질을 만드는” 효과가 극대화된다.\n일본은 이 소비자 DNA가 점점 더 사라져서 이젠 거의 없다는 이야기를 들었다. 일본 창업가들은 대부분 B2B에만 집중하기 때문에 일본을 대표하는 일본의 B2C 제품이 한국과 같이 많지도 않고 다양하지도 않다. 하지만, 인구도 많고 시장이 크기 때문에 일본의 소비자 시장은 외국 회사들의 놀이터가 됐다. 검색은 구글, 동영상은 유튜브, 지도는 구글맵스, 이커머스는 아마존, 택시 호출은 우버 등, 일본을 지배하고 있는 대부분의 B2C 제품은 외산 제품들이다. 그러면서 내가 들었던 말은 일본은 전 세계에서 외국 B2C 소프트웨어 회사들이 가장 쉽게 진출할 수 있는, 가장 큰 시장이 될 것이고됐고, 이들은 일본의 소비자 DNA가 완전히 사라지는 것에 대한 걱정과 아쉬움을 많이 표시했다.\n그리고 한국은 여기서 멈추지 않고 계속 진화하고 발전하고 있다. 우리만의 소비자 DNA를 기반으로 케이팝, 케이푸드, 케이뷰티, 케이콘텐츠와 같은 새로운 무형의 소비자 DNA가 만들어지고 있고, 이 무형의 한국의 문화가 현재 일본 시장을 완전히 쓰나미같이 덮치고 있다. 실은 일본도 한 때는 다른 나라의 문화에 큰 영향을 미쳤는데, 지금은 이게 다 죽었고, 오히려 한국 문화가 과거 일본 문화보다 더 커지고 있는데, 이게 모두 다 일본의 소비자 DNA의 소멸로 인한 아주 좋지 않은 결과라는 결론을 이분은 내렸다.\n물론, 한두 명의 일본 VC가 일본과 한국의 시장을 아주 정확하게 파악하는 것도 아니고, 시장 현황을 일반화할 수도 없지만, 10년 넘게 일본에서 투자하고 있는 VC들에게 이날 내가 들었던 내용만을 기반으로 결론을 내려보면, B2C 분야에서는 한국 창업가들이 일본 시장을 접수할 수 있다는 것이다. 우리가 잘하는 B2C로 시작하지만, 남에게 지는 걸 배 아파하는 한국인 특유의 경쟁심과 질투심으로 결국엔 B2B 사업도 일본 시장에서 더 잘할 수 있을거라 믿는다. 정말로 더 많은 한국 창업가들이 일본 시장에 진출해서 거대한 사업을 만들 수 있길 바란다.\n마지막으로,,,내 친구이자 VC인 일본 투자자가 한국 시장이 부럽다고 하는 가장 큰 이유는 결국엔 우리의 창업가들이다. 한 골 먹으면 두 골을 넣어야지 직성이 풀리는 우리 특유의 성깔?, 절대로 죽지 않고 생존하는 바퀴벌레력, 이 모든 게 한국의 강점이라고 생각한다. 내가 전에 여러 번 포스팅 했지만, 이 강점을 우린 계속 살려야 하고, 이 강점을 살리기 위해서는 더 치열하게, 그리고 열심히 일해야 한다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/11/koreas-consumer-dna.html#respond",
        "content": "2주 전에 잠깐 동경에 갔었는데, 과거부터 친분이 있던 일본 VC들과 다양한 이야기를 했다. 자연스럽게 한국과 일본의 스타트업 생태계 이야기를 특히 많이 했는데, 한국에 집중적으로 투자하는 나 같은 VC는 당연히 일본 시장보단 한국 스타트업 시장이 더 좋다고 믿지만, 내가 만난 일본 VC들도 대부분 한국의 벤처생태계를 부러워하는 느낌을 강하게 받았다. 어떤 일본 VC는 대놓고 나에게 한국 벤처생태계를(...)",
        "contentSnippet": "2주 전에 잠깐 동경에 갔었는데, 과거부터 친분이 있던 일본 VC들과 다양한 이야기를 했다. 자연스럽게 한국과 일본의 스타트업 생태계 이야기를 특히 많이 했는데, 한국에 집중적으로 투자하는 나 같은 VC는 당연히 일본 시장보단 한국 스타트업 시장이 더 좋다고 믿지만, 내가 만난 일본 VC들도 대부분 한국의 벤처생태계를 부러워하는 느낌을 강하게 받았다. 어떤 일본 VC는 대놓고 나에게 한국 벤처생태계를(...)",
        "guid": "https://www.thestartupbible.com/?p=9621",
        "categories": [
          "Uncategorized",
          "B2C",
          "brand",
          "consumer",
          "FoundersAtWork",
          "inspiring",
          "korea",
          "vc"
        ],
        "isoDate": "2025-11-23T21:21:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "새로운 세상, 새로운 시각, 새로운 생각",
        "link": "https://www.thestartupbible.com/2025/11/different-thinking-for-the-whacky-new-world.html",
        "pubDate": "Wed, 19 Nov 2025 21:29:00 +0000",
        "content:encodedSnippet": "요새 한국의 어린이들 10명에게 나중에 커서 뭐 하고 싶은지 물어보면 절반 이상이 연예인, 가수 또는 유튜버가 되고 싶다고 대답한다는 이야기를 전에 어디서 들었다. 관련 자료를 찾아보려고 했는데, 공식적인 시장 조사 자료는 없지만 한국 사회의 분위기를 보면 대충 맞을 것 같고 아마도 몇 년 후에는 이렇게 대답하는 어린이들이 10명 중 10명이 될 것 같은 느낌도 든다.\n나이가 좀 있는 분들과의 식사 자리였는데, 당시 모임에서 대부분 한국의 장래가 어둡고, 요새 젊은 애들 정말 문제가 많다는 분위기 속에서 이런 이야기가 나오긴 했는데 솔직히 나는 이게 그렇게 한국의 미래에 나쁜 영향을 미칠 건 아니라고 했던 기억이 난다. 내가 초등학생일 때 “너희 장래 희망이 뭐니? (너희 커서 뭐가 되고 싶니?)”라고 물어보면 대부분 대통령, 과학자, 교수님, 의사, 변호사, 경찰관, 소방관, 올림픽 금메달리스트 등과 같은 사회에서 전반적으로 존경받고, 좋고 안정적으로 인식되는 직업을 택했다. 나도 아마도 과학자라고 항상 대답했던 것 같은데, 지금 생각해 보면 솔직히 내가 원하는 것보단 주위 사람들이 바라던 답을 했던 것 같다.\n연예인과 유튜버가 과연 과학자나 대통령보다 못 한 직업일까? 일단 위에서 이야기한 모임에 있던 분들 대부분은 그렇게 생각했던 것 같다. 실은 나도 몇 년 전까지만 해도 연예인과 유튜버는 제대로 된 직업이 아니라고 생각했었지만, 이젠 완전히 생각이 바뀌었다. 정확히 말하자면 그동안 보고 검토했던 사업들과 빠르게 변하고 있는 세상 때문에 바뀌기도 했지만, 내가 스스로 내 생각과 인식을 바꾸기 위해서 부단히 노력하기도 했다. 어쨌든, 나는 위의 모임에서 왜 유튜버, 인플루언서 등을 지칭하는 크리에이터라는 업종이 우리가 아는 일반적인 직장과 크게 다르지 않고 실은 왜 훨씬 더 좋은 직업인지 열심히 내 생각을 말했고, 그분들에게 계속 이런 고리타분한 생각을 하면 빠르게 변하는 세상에서 점점 더 도태될 수밖에 없다는 경고도 여러 번 날렸다.\n우리 아버지 세대, 그리고 우리 세대 초반까지만 해도 돈을 벌 수 있는 유일한 수단은 회사에 출근하는 것이었다. 9시에 출근해서 6시에 퇴근하는 게 남과 내가 생각하는, 합법적으로 돈을 벌 수 있는 정상적인 직장 생활이었다. 그런데 요새 우리는 회사로 출근은커녕, 침대에서 잠옷 입고 전 세계 1억 명을 대상으로 말도 안 되는 이야기와 행동을 하면서 연 매출 10억 원을 만들 수 있는, 나같이 올드한 세대가 봤을 땐 참으로 신기한 세상에 살고 있다. 그리고 앞으로 이런 변화와 신기함은 계속 가속화될 것이다. 우리가 만나는 창업가들을 보면서 나는 이 변화를 직접 매일매일 느낄 수 있다. 왜냐하면 점점 더 많은 창업가와 이들이 하는 사업에 대해서 듣다 보면 가장 먼저 떠오르는 생각은, “이게 뭐야 ?”이고, 어떤 사업은 내가 전혀 이해할 수가 없기 때문이다.\n실은, 이런 창업가와 사업을 접할 때마다 “이런 건 사업이 아냐. 제대로 된 직장 경험도 없는 어린애가 폰 앞에서 말도 안 되는 이야기 하는 걸 누가 봐.”라고 생각하면서 그냥 무시하고 패스하는 게 속 편할 수도 있지만, 새로운 시각과 생각으로 모든 걸 바라봐야 한다는 걸 나는 잘 알기 때문에, 불편하기도 하지만 열심히 노력하고 있다.\n새로운 세상에는 새로운 시각과 새로운 생각이 필요하다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/11/different-thinking-for-the-whacky-new-world.html#comments",
        "content": "요새 한국의 어린이들 10명에게 나중에 커서 뭐 하고 싶은지 물어보면 절반 이상이 연예인, 가수 또는 유튜버가 되고 싶다고 대답한다는 이야기를 전에 어디서 들었다. 관련 자료를 찾아보려고 했는데, 공식적인 시장 조사 자료는 없지만 한국 사회의 분위기를 보면 대충 맞을 것 같고 아마도 몇 년 후에는 이렇게 대답하는 어린이들이 10명 중 10명이 될 것 같은 느낌도 든다.(...)",
        "contentSnippet": "요새 한국의 어린이들 10명에게 나중에 커서 뭐 하고 싶은지 물어보면 절반 이상이 연예인, 가수 또는 유튜버가 되고 싶다고 대답한다는 이야기를 전에 어디서 들었다. 관련 자료를 찾아보려고 했는데, 공식적인 시장 조사 자료는 없지만 한국 사회의 분위기를 보면 대충 맞을 것 같고 아마도 몇 년 후에는 이렇게 대답하는 어린이들이 10명 중 10명이 될 것 같은 느낌도 든다.(...)",
        "guid": "https://www.thestartupbible.com/?p=9619",
        "categories": [
          "Uncategorized",
          "creator",
          "FoundersAtWork",
          "general",
          "inspiring",
          "media"
        ],
        "isoDate": "2025-11-19T21:29:00.000Z"
      }
    ]
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "토스는 왜 밴드 ADOY(아도이), 아티스트 16팀과 ‘뮤직비디오’를 만들었을까?",
        "link": "https://toss.im/tossfeed/article/outsight-spectrum",
        "pubDate": "Mon, 24 Nov 2025 07:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}토스가 뮤직비디오 〈Spectrum〉을 선보였습니다. 국대 대표 인디밴드 ‘아도이(ADOY)’가 음악을 맡았고, 16팀의 비주얼 아티스트가 함께했습니다. 2D, 3D, 실사, AI, 일러스트 등 서로 다른 장르의 작품들을 하나의 영상으로 엮어냈어요. 토스는 왜 갑자기 뮤직비디오를 만들었을까요? \n이번 뮤직비디오는 토스의 새로운 브랜드 이니셔티브인 ‘토스임팩트’의 시작을 알리는 브랜드 필름이기도 합니다. 토스임팩트는 사용자가 만나는 토스의 다양한 서비스가 품고 있는 맥락과 의미를 이야기해요. 쉽고 간편한 서비스를 넘어, .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}토스가 어떤 생각으로 세상의 문제를 바라보고 긍정적인 변화에 기여하고자 하는지를 가장 토스다운 방식으로 전하고자 합니다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}토스임팩트의 키비주얼과 슬로건. \n이 새로운 출발을 숫자나 성과가 아닌, 진심 어린 방식으로 전하고 싶었습니다. 조금 더 나은 세상에 대한 기대와 희망이 떠오르길 바랐어요. 그래서 뮤직비디오를 선택했습니다. 음악은 사람의 마음을 가장 빠르게 여는 언어니까요.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}어떤 세상에 살고 싶나요?\n\n뮤직비디오 〈Spectrum〉은 ‘토스가 만들어갈 세상’을 이야기하지 않습니다. 대신 ‘당신이 꿈꾸는 세상은 어떤 모습인가요?’라는 질문을 던졌어요. 이 질문은 곧 K-Pop, 인디음악 분야에서 유망주로 주목받는 16팀의 비주얼 아티스트들에게 전해졌고, 그 순간부터 이야기는 훨씬 다채로워졌어요.\n누군가는 걱정과 갈등 없는 세상을, 누군가는 땀의 가치를 잃지 않는 세상을, 또 누군가는 작은 엉뚱함이 허용되는 세상을 떠올렸어요. 각자의 상상과 바람이 모여 뮤직비디오 〈Spectrum〉이 완성되었습니다. 토스는 누구나 자신이 바라는 꿈과 세상을 이야기할 수 있고, 그 작은 이야기들이 모여 세상이 조금씩 달라질 수 있다고 믿어요. 〈Spectrum〉은 그 믿음을 담은, ‘함께 상상하는 미래’의 기록이기도 합니다. 이렇게 모인 상상의 조각들은 토스가 앞으로 그려갈 세상의 밑그림이 되어줄 거예요.\n〈Spectrum〉을 함께한 16팀의 비주얼 아티스트와 아트워크를 소개합니다. \n\n\nThe Shape That Changes — 변하는 형태\n김연우 .css-wi4a2c{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;font-weight:bold;}@yeonnukm\n디지털 아티스트·그래픽 디자이너. 젠틀몬스터에서 3D 콘텐츠를 기획·제작한다. 주로 자연물의 구조와 움직임에서 영감을 받아 작업하며, 디지털과 현실 양쪽에서 그 물성을 재현하고 확장하는 방법을 탐구한다.\n작가의 말\n말려 있던 형태들이 천천히 풀리고, 닫혀 있던 봉오리가 서서히 열리며 형태를 바꾸는 순간을 담았습니다. 식물의 개화 과정을 단순한 생장으로 보기보다, 환경의 리듬에 맞춰 스스로 변해가는 생명의 형태로 바라봤어요. 우리 역시 변화 속에 있습니다. 변화 앞에서 두렵기도 하고 조급해지기도 하지만, 결국 변화된 모습보다 변화의 과정 자체가 더 아름답다고 믿습니다.\n\nMusic Spreads All Around\n이희찬 @heechaney\n일러스트레이터·그래픽디자이너. 자신과 주변의 세계와의 관계에 관심을 두고, 이를 시각적 형태로 표현하는 작업을 주로 하고 있다.\n작가의 말\n인종, 성별, 종과 관계없이 모두가 하나의 공간 안에서 근심과 걱정 없이 편안하게 음악을 듣는 풍경을 그려내고자 했습니다. 정체를 알 수 없는 구조물들 사이에서 실재하지 않는 동물들과 함께 눈을 감고 음악을 즐기며 휴식을 취하는 사람들. ‘좋은 음악’의 기준도 저마다 다르지만, 그 차이마저 인정하며 다 함께 음악을 향유하는 세상을 꿈꿉니다. 작업은 와우산지키미 .css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}@wowsangongtoe 와 함께 완성했습니다.\n\nFly, you fools\nHwang Jaehwan @hwangjaehwane\n애니메이션 감독. 머릿속 창의적인 상상들이 흩어지지 않도록, 움직이는 이미지로 만들어 내는 일을 한다. 세상을 다채롭게 만들고, 히데오 코지마처럼 독창적인 세계관을 만들길 꿈꾼다.\n작가의 말\n움직이지 않아도 많은 것을 할 수 있는 시대에, '육체가 살아있다'는 감각을 잊지 않는 세상을 이야기 하고 싶었습니다. 편리함이 커질수록 우리는 몸을 덜 쓰게 되고, 그만큼 생각도 식어가는 것 같아요. 심장이 뛰고, 근육이 찢어지고, 뜨거운 땀이 흐르는 순간이야말로 인간을 인간답게 만든다고 믿습니다. 애니메이션을 통해 들끓는 생명력과 원초적 에너지를 보여드리고 싶었습니다.\n\nIn Between\n토이카 @9toika9\n서울을 기반으로 활동하는 작가 토이카는 ‘괴물’이라는 상징과 캐릭터를 통해 자아와 감정의 형상을 탐구한다. 디지털과 회화, 애니메이션을 넘나들며 존재가 드러나는 순간과 그 변형의 과정을 시각화한다.\n작가의 말\n‘어떤 세상에 살고 싶나요?’라는 질문은 잊고 살던 마음속 생각들을 다시 꺼내게 해주었습니다. 살아오며 저는 싫어하던 것을 결국 좋아하게 되고, 좋아하던 것을 결국 싫어하게 되는 경험을 반복해왔습니다. 어쩌면 제가 좋아하는 것이 실은 두려워하는 것이고, 제가 싫어하는 것이 실은 정말 사랑하는 것일지도 몰라요. 저의 세상은 그렇게 끊임없이 모순되고, 서로 닮아가며 변해간다는 걸 배우고 있습니다.\n그리고 그런 세상이 좋습니다. 그게 제가 원하던 세상입니다. 뮤직비디오 작업을 통해 경계가 흐려지고, 서로의 형태가 스며드는 세상을 표현하고자 했습니다.\n\n작은 것들의 맛 The Taste of Small Things\nDonkeysoo @donkeysoo\n뉴욕과 서울을 기반으로 활동하는 믹스미디어 애니메이터. 클레이 스톱모션을 중심으로 K-Pop 아티스트들과 뮤직비디오 협업을 진행하며, 뉴욕에서는 조각과 애니메이션 중심의 전시 활동을 이어오고 있다. 어린 시절의 공상과 노스탤지아에서 영감을 받아 다양한 재료와 기법으로 새로운 애니메이션 세계를 탐구한다.\n작가의 말\n요즘 들어 현실이 너무 또렷하고, 때로는 냉정하게 느껴질 때가 있습니다. 상상이 들어갈 틈이 없을 만큼 선명한 세상 속에서, 틈을 살짝 벌려 조금이라도 엉뚱함을 집어넣고 싶었습니다. 제가 가장 좋아하는 영화 <녹차의 맛> 속에는 예기치 않은 장소에서 이상한 포즈를 취하는 인물들이 등장합니다. 그들을 볼 때마다 묘한 해방감과 자유를 느껴왔습니다. 미묘하지만 확실히 이상한 그들이 허용되는 세상에 살고 싶다는 생각이 들었습니다. \n이번 작업은 오랫동안 시도해보고 싶었던 ‘현실 속 클레이 애니메이션’을 구현한 프로젝트입니다. 클레이의 말랑하고 유연한 특성을 살려, 자유롭게 몸을 움직이는 캐릭터들을 만들며 저 또한 함께 포즈를 취해보며 엉뚱함이 가진 에너지를 몸으로 느낄 수 있었습니다. 관객들이 제 작품을 보고 어린 시절로 잠깐 돌아간 것처럼, 자신만의 작은 ‘엉뚱의 틈’을 느꼈으면 좋겠습니다. 적어도 제 작품을 마주하는 순간만큼은 마음껏 유치해지고 이상해졌으면 좋겠어요.\n\n충돌않는 충돌\n황보나현 @hwangbonahyun\nAI 아티스트. 현실과 비현실 사이의 묘한 경계선 위에서 AI를 기반으로 여러 시각 실험을 이어간다.\n작가의 말\n‘사람은 하나의 우주이고, 사람과 사람이 만나는 것은 서로 다른 거대한 우주가 만나는 일’, 그리고 ‘대혐오의 시대’. 이 두 문장에서 작업을 시작했습니다. 두 개의 큰 우주가 만나도 ‘혐오’로 가득 차지 않는 세상이 되길, 그런 비통한 단어에서 벗어난 세상이 다시 찾아오길 바라는 마음으로요. 다른 빛이 만나 새로운 색을 만들 듯, 다른 존재들이 충돌하지 않고 스며드는 순간을 꿈꿉니다. .그곳엔 경계도, 혐오도 없을 거예요.\n\nEndless Bloom\nANREAL지현 @an_realphoto\nAI와 상상을 도구 삼아 이미지 너머의 가능성을 실험한다. 예측보다는 가능성, 완성보다는 흐름을 믿으며 질문을 품고 자신만의 세계를 쌓아간다. 스튜디오 ANREAL(언리얼)을 운영하며 국내외 브랜드와 협업 프로젝트를 진행하고, 독립출판사 ANREAL INDEX(언리얼인덱스)를 통해 새로운 언어와 관계를 탐구하고 있다.\n작가의 말\n제가 꿈꾸는 세상은 새로운 가능성이 끊임없이 열리는 곳입니다. 고요한 연못을 따라 스스로를 발견하고, 그 속으로 빨려 들어가듯 현실의 무게를 벗어나 자유롭게 유영합니다. 그 여정 속에서 마주하는 비현실적인 자연은 모험과 우연, 환상과 발견이 어우러진 다채로운 확장의 세계를 상징합니다.\n우리가 바라보는 세상은 끊임없이 변화하지만, 우리 안의 ‘감각’은 언제나 그 자리에서 우리를 새로운 세계로 이끕니다. 잠시 멈춰 각자의 감각을 통해 세상을 바라보세요.\n\n몰입\n박지현 @designarchiveclef\n일러스트를 기반으로 믹스미디어 작업을 한다. 수작업과 디지털 작업의 조합으로 만들어지는 다양한 이미지들을 스톱모션 영상으로 전개하고 있다.\n작가의 말\n이번 작업에서는 온전히 자신의 선택으로 이루어지는 몰입과 발산의 순간을 담았습니다. 살아가는 데 필요한 수많은 조건과 규칙 아래에서, 몰입의 대상을 찾는 것은 해방감을 찾는 일과도 같습니다. 몰입은 미래를 기대하게 만드는 힘이 있습니다. 형태를 불문하고, 누구에게나 눈을 반짝이게 만드는 것들이 있다고 생각합니다. 다양한 몰입을 경험하고 공유하는 세상을 꿈꿉니다.\n\nWE NEED SOME LOVE\n러프초이 @rough_choi\n사진과 영상을 오가며 음악 패션 분야에서 작업을 이어오고 있다. 최근에는 힙노시스 테라피(HYPNOSIS THERAPY)의 〈UMJIGYEO! (MOVE!)〉 뮤직비디오를 연출했다.\n작가의 말\n수많은 불빛들을 모아 문장을 만들었습니다. 작은 불빛 하나하나는 도시에 살아가는 한 사람을 의미합니다. 각자의 자리에서 빛나던 불빛을 모아 하나의 메시지를 전하고자 했습니다. 직접 제작한 보케 필터를 통해 빛을 단어 형태로 담아 낼수 있었습니다. 작은 불빛들이 모여 도시를 밝히지만, 정작 그 속에 있는 우리는 서로를 비추지 않고 있는 것 같습니다. 우리가 더 사랑하고 서로를 비출 수 있는 세상에 살고 싶습니다.\n\n놀이터\n키숄 @kitschbaba\n갖고 싶은 장면들만을 모아 멋대로 바꾸고 연결하기를 즐기는 시각 작업자. 자신만의 향수를 감각하면서도 가보지 않은 길들에 호기심을 더하는 태도로 살아간다. 그 과정에서 포착하는 이미지들을 통해 자신이 속한 현실을 가장 가까우면서도 가장 멀게 그려낸다.\n작가의 말\n끌림을 거부하지 않고, 그 감정을 포착하고 때로는 불안정하더라도 연결하고 싶었어요. 진짜의 시간들과 조형물들이 제 감각으로 담기고 편집된 후, 다른 작가들의 작업과 함께 연결된다면 이질적으로 보이더라도 결국은 하나로 이어질 수 있다고 믿었습니다. 그 믿음 속에서, 불안함과 기대를 함께 안고 작업했습니다. 함께 올라탄 이 세상을 놀이터라 생각하고 즐기고 싶어요. 고통스러운 부분들도 더 큰 아름다움 안에 속한다고 믿는 요즘입니다.\n\nSingularity\nmareykrap @mareykrap\n패션디자인과 섬유미술을 전공했지만 2018년부터는 줄곧 그림을 그린다. 현실에 없는 장면을 그리며, 현실을 그릴 때에도 비틀어 비현실적으로 전환한다. 세계를 그린다는 일은 보이지 않던 것을 존재하게 만드는 일이며, 작가의 삶을 다루는 태도와도 닮아 있다. 지금은 K-pop 뮤직비디오와 그림 속에 그 세계가 놓여 있지만, 다른 매체로도 세계를 확장해갈 계획이다.\n작가의 말\n모두가 같은 모양과 자세로 멈춰 있는 세상. 아무도 움직이지 않고, 무채색으로 생명이 꺼져있습니다. 정지 속에서 단 하나의 존재가 미세하게 떨리자, 우주의 푸른 기운이 깃들고 자아가 깨어납니다. 그 푸름은 전염처럼 번져 잊힌 꿈들을 깨우고 세상은 다시 돌기 시작합니다. 개성의 각성은 세상에 생명을 불어넣습니다. 모든 존재가 각자 다른 푸른빛으로 물듭니다. 존재들은 제각기 다른 속도로 떠오르고, 각자의 우주로 확장된 그 흩어짐이 새로운 세상의 빅뱅이 됩니다.\n개성은 서로를 물들이지만, 복제되지는 않는 세상을 표현했습니다. 다른 빛으로 공존하며 번져나가 더 넓은 세상을 만드는 것을 꿈꿉니다.\n\n감각의 흐름 속 빛나는 찰나\n페이퍼 컴퍼니 @qaqer.comqany\n콜라주를 통해 서로 다른 이미지를 엮고, 협업과 실험으로 새로운 시각 경험을 만들어가는 비주얼 스튜디오. 음악, 브랜드, 영상 등 다양한 영역 속에서 유쾌한 감각으로 낯선 조합을 탐구하며, 이미지의 틈새에서 새로운 이야기를 찾아낸다.\n작가의 말\n이 작품은 각자의 취향과 취미, 저마다의 개성을 중심으로 펼쳐지는 작은 순간들을 시각적으로 담아냅니다. 아날로그 방식을 택한 이유는 행복과 낭만이 멀리 있지 않음을, 마음만 먹으면 큰 도움 없이도 손끝에서 시작될 수 있음을 보여주기 위함입니다. 손으로 직접 엮고 빚어내는 과정 속에서 느껴지는 따뜻함과 소소한 기쁨, 그리고 각자가 만들어내는 다채로운 감각의 흐름을 시각적으로 표현했습니다. 일상 속 가까운 곳에서 피어나는 작은 세계들을 마주하며, 여러분이 자신만의 감각과 순간을 떠올릴 수 있기를 바랍니다. Analog Never Die!\n\n나의 우주\nFOM FOM @fom__fom__\n3D 애니메이션과 일러스트레이션을 기반으로 활동한다. 뮤직비디오, 단편 애니메이션, 에디토리얼 프로젝트를 통해 꿈과 현실의 경계에 존재하는 이야기를 시각화한다. 낯설지만 익숙한 감정의 순간을 화면에 담아, 보는 이가 자신의 기억과 감정을 투영할 수 있는 세계를 만든다.\n작가의 말\n각자의 머릿속에는 자신만의 우주가 존재한다고 생각합니다. 이 작품은 ‘모자’를 머릿속의 상징으로 설정하고, 그 안에 각자의 이야기로 채워진 공간을 상상했습니다. 주인공이 모자를 벗는 순간, 그 안에서 또 다른 자신과 상상의 친구들이 나타나 별과 음표가 떠다니는 음악의 세계로 비상합니다. 이 장면은 현실과 상상의 경계가 스며드는 찰나를 포착하며, 내면의 감정이 빛과 소리로 피어나는 순간을 담고 있습니다.\n‘모자를 벗는 행위’는 자신의 내면을 열어 상상의 세계를 펼치는 용기의 표현이자, 마음속 우주가 현실로 이어지는 순간을 상징합니다. 우리 모두 잠시 현실을 벗어나 마음속에서 피어나는 빛과 음악을 따라가며, 자신의 세계를 즐겁게 마주하는 시간이 되었으면 합니다.\n\n손 안의 우주\n돌돌보이 @doldolboys\n3D 캐릭터 아티스트. 동시대 대중문화의 감각을 즉흥적 몽타주로 재구성한다.\n작가의 말\n각자의 세상을 품은 불안한 모습의 빛들이 소년을 향합니다. 그들은 저마다 고립된 세상 속 자신의 목소리만 낼 뿐이었습니다. 충돌하는 빛들은 소년의 손안에서 다양한 세상, 모든 것의 가능성을 느낍니다. 모든 빛들이 교차하고 스며들어 경계는 소멸하고, 세상은 조화와 평화가 깃든 하나의 순간으로 이어집니다. \n프리즘을 통과하며 펼쳐지는 색처럼, 다양한 삶이 만나 교차하고 공감하는 평화로운 세상이 펼쳐지길 바랍니다. 당신도 손안에 작은 우주를 품고 있다는 걸 기억하세요.\n\nClose-up\nEEHOSOO @eehosoo\n패션, 영상, 전시, 음악 등 다양한 분야에서 시각 기반의 아트워크와 영상 작업을 이어가고 있다. 최근에는 선미의 컴백 트레일러를 제작하며 독창적인 영상 연출을 선보였다.\n작가의 말\n랜덤한 상황에서 만들어지는 우연성에 요새 빠져있어서 AI로 작업을 했어요. 미래를 그리기보다, 당장 내 눈앞에 존재할 수 있는 유토피아를 보여주고 싶었어요. 완벽한 소통과 관계를 이룰 수 있는 세상에 살길 꿈꿉니다.\n\n악수 Handshake\n조경욱 @kyeongwookjo\n에스파, NCT 127의 초기 비주얼 작업을 비롯해 여러 아티스트들의 뮤직비디오 애니메이션을 그려왔다. 이미지와 움직임을 통해 감정을 시각화하는 작업을 즐기며, 감각과 리듬으로 이야기를 전한다.\n작가의 말\n최근 들어 필요에 의해 이루어지는 관계들에 회의감을 느꼈습니다. 그 감정과 경험을 ‘악수’라는 행위로 은유했습니다. 찰나의 마주침 같은 인사가 아닌, 서로의 심장을 내어주는 진심 어린 교감과 공감, 그리고 사랑 같은 것들이 결국 세상을 더 나은 방향으로 이끈다고 생각했습니다. 작품은 전쟁과 사고, 재난이 뒤섞인 어수선한 세상에서 시작해 다양한 사람들이 함께 살아가는 평화로운 세계로 향합니다. 그 변화를 짧지만 강렬한 이미지로 표현하고자 했습니다.\n여러 아티스트와 함께 콜라보할 기회는 흔치 않은데, 즐겁고 의미 있는 시간이었습니다. 이 영상을 보신 분들이 잠시라도 좋은 기분을 느끼신다면 저도 행복할 것 같습니다. 따뜻하고 반짝이는 연말 보내시길 바랍니다.",
        "content": "토스임팩트 뮤직비디오 〈Spectrum〉에 담긴 작가들의 메시지",
        "contentSnippet": "토스임팩트 뮤직비디오 〈Spectrum〉에 담긴 작가들의 메시지",
        "guid": "https://toss.im/tossfeed/article/outsight-spectrum",
        "isoDate": "2025-11-24T07:00:00.000Z"
      },
      {
        "title": "7년 이상 연체자라면? 새도약기금 확인해보세요",
        "link": "https://toss.im/tossfeed/article/money-policies-54",
        "pubDate": "Thu, 20 Nov 2025 07:02:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}지난 10월 1일, 장기 연체로 어려움을 겪는 취약계층과 소상공인을 돕기 위해 새도약기금이 새롭게 시작됐어요. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}향후 1년 동안 누구나 지원 대상이라면 따로 신청하지 않아도 순차적으로 도움을 받을 수 있어요.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}새도약기금이란?\n상환능력이 낮은 장기 연체자의 금융권 연체채권을 매입해 소각하거나 채무를 조정해주는 제도\n지원 대상\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n7년 이상 연체* + 5천만 원 이하* 개인 연체자(개인 사업자 포함)\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*7년 이상 연체: 2018년 6월 19일 이전에 연체가 시작되었거나 기존 채무조정 후 실효한 경우(2025년 6월 19일 발표 기준)\n*5천만 원 이하: 금융회사별 원금 합산 기준(연체이자 불포함)\n금융회사 및 공공기관 보유 금융채권*\n*사행성·유흥업 관련 채권, 외국인 채권 등은 제외\n\n지원 내용\n.css-hokoge{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;counter-reset:numberedList;}.css-hokoge ul,.css-hokoge ol{margin:16px 0 0;}.css-hokoge>li{counter-increment:numberedList;margin-bottom:16px;padding-left:24px;}.css-hokoge>li:last-of-type{margin-bottom:0;}.css-hokoge>li>span{position:relative;}.css-hokoge>li>span>:first-child::before{content:counter(numberedList) '.';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n채권이 매입되면 바로 추심이 중단돼요.\n개인파산처럼 상환 능력이 없을 경우, 채무가 ‘소각’돼요 (1년 이내)\n- 기초생활수급자, 장애연금수령자(중증), 생활조정수당·생계지원금 수급자(보훈 대상자)는 별도 심사없이 소각돼요.\n상환 능력이 부족한 경우, ‘강화된 채무조정’이 적용돼요.\n- 기준 중위소득 60%를 넘거나, 회수 가능한 자산은 있지만 채무가 더 많은 경우.\n- 원금 30~80% 감면, 최장 10년 분할상환, 이자 전액 감면, 상환유예 최대 3년 등이 적용돼요.\n상환 능력이 있는 경우, 추심이 다시 진행되거나 상환 요구가 있어요.\n- 기준 중위소득 125%를 넘거나, 보유 자산이 채무보다 많은 경우에 해당돼요.\n\n지원 방법\n새도약기금은 따로 신청할 필요가 없어요. 상환능력 심사가 끝나면 정부가 각 채무자에게 개별적으로 알려드려요.\n주요 일정은 아래와 같아요.\n\n장기 연체채권 매입: 2025년 10월 ~ 2026년 10월\n상환능력 심사: 2025년 11월 ~ 2027년 6월\n채무 소각·조정: 2025년 12월~\n\n.css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}새도약기금 홈페이지에서 내 채무가 매입되었는지 여부와 상환능력 심사 결과, 채무 소각 여부 등을 조회할 수 있어요.\n문의\n\n새도약기금 콜센터 1660-0705 (평일 9시~18시)\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 권민지 이지영 Graphic 이제현",
        "content": "최대 원금 80% 감면부터 소각까지 지원해드려요.",
        "contentSnippet": "최대 원금 80% 감면부터 소각까지 지원해드려요.",
        "guid": "https://toss.im/tossfeed/article/money-policies-54",
        "isoDate": "2025-11-20T07:02:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]