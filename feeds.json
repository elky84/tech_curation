[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": [
      {
        "creator": "사소한 것들의 역사",
        "title": "비전공자도 이해할 수 있는 웹 개발의 역사",
        "link": "https://ppss.kr/archives/257673",
        "pubDate": "Fri, 22 Aug 2025 01:16:53 +0000",
        "content:encodedSnippet": "동영상이나, 음성 따위의 각종 멀티미디어를 이용하는 인터넷을 이르는 말. = 월드 와이드 웹.\n국립국어원 표준국어대사전\n \n시작하며\n요즘 글이 뜸했습니다. 사실 뉴스레터 서비스가 유료로 전환되고 나니, 예전처럼 손이 잘 안 가게 되네요. (한 번 발송할 때 마다 치킨 한 마리값이 사라집니다..ㅠㅠ)\n그래서 역사 콘텐츠를 텍스트가 아닌 다른 방식으로 즐길 수 있는 방법을 알아보고 있는데요, 그중 하나가 웹사이트였습니다. 그렇게 코딩을 시작하게 되었는데요. 코딩을 하며 배우는 웹의 기술들이 어떤 배경으로 탄생했는지가 궁금해지더라구요. 그래서 역사를 조사해 보았습니다.\n최대한 개발 지식이 없는 분들도 이해하실 수 있도록 글을 구성해 보았지만, 아무래도 다루는 내용이 조금 전문적이다 보니 쉽지는 않네요. 그리고 웹의 역사는 정말 방대하더라구요. 프론트엔드를 중점적으로 조사했는데, 그럼에도 분량 조절에는 완전히 실패했습니다. 시간 나실 때 천천히 읽어주시면 감사하겠습니다.\n \n1. 웹의 기반: 하이퍼텍스트\n웹의 출발점은 ‘하이퍼텍스트’라는 개념에서 시작됩니다. 하이퍼텍스트는 1963년, 테드 넬슨(Ted Nelson)이 책이나 문서처럼 선형적으로만 정보를 읽는 방식에서 벗어나 인간 사고처럼 자유롭게 연결되고 탐색 가능한 정보 구조를 만들고자 진행했던 ‘제너두(Xanadu)’라는 프로젝트에서 처음 사용됩니다. 모든 문서를 상호 연결하고, 문서의 부분 인용과 출처·변경 기록까지 영구적으로 추적할 수 있는 하이퍼텍스트 네트워크를 목표로 했습니다.\n이후 1967년, 브라운대학교의 앤드리스 반 댐(Andries van Dam)과 함께 실제로 하이퍼텍스트 편집 시스템을 구현하면서, 컴퓨터 기반의 하이퍼텍스트 시스템이 현실화되기 시작했습니다.\n\n1980년대에는 워드프로세서처럼 문서를 다루는 프로그램이 점점 발전하면서, 하이퍼텍스트 기능을 포함한 다양한 소프트웨어가 등장했습니다. 특히 1987년 애플이 발표한 ‘하이퍼카드(HyperCard)’는 프로그래밍 지식이 없어도 사용자가 직접 인터페이스를 만들고 멀티미디어 요소를 넣을 수 있는 환경을 제공하며 하이퍼텍스트 기술의 대중화를 이끌었습니다.\n \n2. 웹과 HTML의 등장\n\n1991년, 유럽입자물리연구소(CERN)의 물리학자 팀 버너스 리(Tim Berners-Lee)는 연구자들 간의 정보 공유를 위해 새로운 시스템을 제안합니다. 이 시스템은 인터넷 위에 하이퍼텍스트 기술을 얹는 형태로, 논문과 데이터를 연결하고 접근할 수 있게 만드는 것이 목적이었습니다. 바로 오늘날 우리가 사용하는 월드 와이드 웹(World Wide Web, WWW)의 시작입니다.\n기존 인터넷은 이메일, 파일 전송 등 통신 기능에 초점을 맞췄지만, 웹은 처음으로 콘텐츠 중심의 구조를 인터넷에 도입하며 인터넷 사용자의 범위와 목적을 크게 넓히는 계기가 되었습니다.\n이 웹 시스템의 핵심 구성 요소는 HTML(HyperText Markup Language)이었습니다. HTML은 웹페이지의 구조를 기술하는 언어로, 하이퍼링크를 포함한 텍스트, 이미지, 레이아웃 등의 요소를 브라우저에 표시할 수 있게 합니다.\n \n3. WWW vs 고퍼\n\n하지만 웹이 처음 등장했을 때는 생각보다 큰 주목을 받지 못했습니다. 논문 중심의 정보 공유라는 목적은 대중에게는 와 닿지 않았기 때문입니다. 대신, 1991년 미국 미네소타주립대학에서 만들어진 ‘고퍼(Gopher)’라는 다른 서비스가 인기 끌고 있었죠. 고퍼는 텍스트 기반 메뉴를 통해 원하는 정보를 찾아가는 구조로, 네트워크 속도가 느린 당시 환경에서도 빠르고 안정적인 성능을 제공했습니다.\n\n반면 웹은 이미지 기반의 인터페이스라서 느린 연결 환경에서 비효율적이었습니다. 특히 웹은 고성능 워크스테이션 ‘넥스트(NeXT)’ 컴퓨터의 운영체제인 ‘넥스트스텝(NeXTSTEP)’에서만 구현되었는데, 문제는 NeXT 컴퓨터가 많이 팔리지 않았다는 것이었죠. 웹이 널리 쓰이기 위해서는 다양한 운영체제에서 동작할 수 있도록 해야 했습니다.\n \n4. 웹브라우저의 등장과 서버의 탄생\n\n1993년, 시카고의 NCSA(국립 슈퍼컴퓨터 응용센터)에서 아르바이트를 하던 마크 앤드리센(Marc Andreessen)은 NCSA 소속 프로그래머인 에릭 비나(Eric Bina)와 함께 유닉스를 지원하는 웹 브라우저 ‘모자이크(Mosaic)’를 개발합니다.\n모자이크는 마우스를 이용해 인터넷을 탐색할 수 있는 클릭 인터페이스를 제공한 최초 브라우저로, 일반 사용자들도 손쉽게 웹을 사용할 수 있도록 만든 획기적인 프로그램이었습니다. 모자이크의 가능성을 확인한 NCSA는 인력을 보강해 같은 해 윈도우와 매킨토시 버전도 출시했습니다.\n그 결과 단 두 달 만에 100만 건이 넘는 다운로드를 기록하며 큰 성공을 거두었습니다. 이로써 웹은 고퍼를 제치고 대중화의 길에 들어서게 됩니다.\n웹이 대중에게 퍼지기 시작하면서 사람들은 단순히 문서를 읽는 데 그치지 않고, 직접 글을 남기거나 검색을 하는 등 웹과의 상호작용을 원하게 됩니다. 이렇게 사용자의 요청을 받아 서버가 실시간으로 처리해 주는 기능이 필요해졌고, 그에 따라 웹 서버에서 정보를 처리해 다시 웹페이지에 반영하는 ‘백엔드 기술’이 등장하게 됩니다.\n이때 등장한 기술이 NCSA에서 만들어진 CGI(Common Gateway Interface)입니다. 사용자가 웹페이지에서 입력을 보내면, 서버는 그 정보를 받아 CGI 프로그램을 실행해 결과를 만든 뒤 다시 웹페이지로 돌려보내는 방식이었죠.\n \n5. 1차 브라우저 전쟁 넷스케이프 vs 익스플로러 – CSS, Javascript, DOM\n\n모자이크의 성공에도 불구하고 모자이크 개발을 주도했던 아르바이트생 앤드리센은 정식 개발팀에 포함되지 못했고, 앤드리센은 NCSA를 떠나 넷스케이프(Netscape)를 창업합니다. 그리고 1994년 10월, ‘넷스케이프 네비게이터(Netscape Navigator)’라는 웹 브라우저를 출시합니다.\n‘넷스케이프 네비게이터’는 상업적인 용도가 아니라면 누구나 무료로 사용할 수 있었습니다. 덕분에 출시한 지 3개월도 채 되지 않아 200만 건이 넘는 다운로드를 기록하며 폭발적인 반응을 일으켰고, 넷스케이프 네비게이터는 웹의 상징이 되었죠.\n\n이 상황을 지켜보고 있던 마이크로소프트는 모자이크 브라우저에 라이선스 비용을 지불하고 ‘인터넷 익스플로러(Internet Explorer)’를 개발하여 1995년 브라우저 경쟁에 뛰어들었죠. 인터넷 익스플로러 2.0부터는 브라우저를 무료 제공을 하며 공격적으로 마케팅합니다.\n넷스케이프도 이에 맞서며 경쟁이 치열해집니다. 특히 1996년에는 웹사이트에서 사용자와 상호작용할 수 있게 해주는 JavaScript를 개발해 넷스케이프 네비게이터 2에 탑재합니다. 이에 질세라 MS도 같은 해 Jscript를 개발해 인터넷 익스플로러 3.0에 탑재하고, 뿐만 아니라 CSS(Cascading Style Sheets)라는 웹 디자인 기술을 도입해 주목받았죠. CSS는 HTML 내부에 직접 스타일을 입력하던 비효율적인 구조를 해결하며 웹의 시각적 표현을 풍부하게 만들어 주었습니다.\n\nJavaScript와 JScript 덕분에 웹사이트는 버튼 클릭, 마우스 오버 같은 간단한 인터랙션을 구현할 수 있게 되었습니다. 그러나 이때까지는 웹페이지의 구조나 내용 자체를 자유롭게 제어하긴 어려웠습니다.\n이를 해결하기 위한 기술로 등장한 것이 바로 DOM(Document Object Model)입니다. DOM은 웹페이지의 내용을 계층적 구조로 표현하여, 자바스크립트가 특정 요소를 선택하고 조작할 수 있도록 해주었습니다. 덕분에 사용자가 글자를 입력하면 그 값을 검사하거나, 버튼을 누르면 화면 구성이 바뀌거나, 필요한 부분만 서버에서 불러오는 기능도 가능해졌습니다.\n1997년 넷스케이프와 마이크로소프트가 각각 DOM 기능이 확장된 새로운 브라우저(Netscape Navigator 4.0과 IE 4.0)를 출시하면서 동적인 웹(DHTML)이 본격화됩니다. 하지만 두 회사가 DOM을 각기 다르게 만들었기 때문에, 한 웹사이트가 브라우저마다 다르게 보이거나 제대로 작동하지 않는 문제가 있었죠. 이런 문제를 ‘크로스 브라우징 이슈’라고 부릅니다.\n이러한 혼란은 웹 표준화의 필요성을 절감하게 했고, 이후 W3C와 같은 기구가 등장해 HTML, CSS, DOM 등의 명확한 명세를 정립하게 되는 계기로 작용합니다.\n\n익스플로러와 넷스케이프의 대결은 1997년에 종지부를 찍게 됩니다. MS가 Windows 98에 기본 브라우저로 인터넷 익스플로러를 탑재했습니다. 이미 브라우저가 깔려 있는 컴퓨터 사용자들은 굳이 다른 브라우저를 다운로드할 이유가 없기 때문에 넷스케이프의 점유율은 급감합니다.\n넷스케이프는 익스플로러와의 경쟁에서 밀려 결국 1998년, 미국의 큰 통신회사인 AOL에 42억 달러에 회사를 넘깁니다. 이후 인터넷 익스플로러는 독주를 이어가며 2002년에는 점유율 96%까지 올라가게 됩니다.\n \n6. 야후, 아마존 등의 등장 – PHP, JSP\n\n웹이 단순한 문서 공유의 도구를 넘어 일상 속 서비스 플랫폼으로 진화한 결정적인 전환점은 포털과 전자상거래의 등장입니다. 1994년 스탠퍼드 대학의 제리 양(Jerry Yang)과 데이빗 파일로(David Filo)는 인터넷 상의 수많은 웹사이트를 주제별로 분류한 디렉토리인 Jerry and David’s Guide to the World Wide Web를 만들었고, 이는 곧 ’야후(Yahoo!)’로 발전합니다. 야후는 단순한 링크 모음이 아닌, 정보를 분류하고 검색할 수 있는 웹의 첫 포털 개념을 대중에게 선보였죠.\n같은 시기 제프 베조스가 창업한 아마존은 책을 판매하는 온라인 쇼핑몰로 시작해, 웹을 통해 상품을 사고팔 수 있다는 인식을 확산시켰습니다. 이베이, 알리바바 같은 플랫폼도 비슷한 시기에 출범하며 웹은 정보 탐색에서 ‘상거래와 사용자 서비스’ 중심으로 패러다임을 바꾸기 시작합니다.\n이런 변화는 웹이 단순히 정적인 문서를 보여주는 수준에서 벗어나, 사용자 계정, 장바구니, 검색, 결제 등 실시간 데이터 처리가 필요해졌다는 의미였습니다. 즉, 웹의 동작 방식은 ‘프론트엔드’뿐 아니라, 사용자의 요청을 받아 처리하는 ‘서버 기술(백엔드)’의 발전이 필수였죠.\n기존에는 CGI(Common Gateway Interface)를 통해 이러한 요청을 처리했지만, CGI 방식은 매 요청마다 외부 프로그램을 새로 실행해야 했기에 서버에 부담이 컸고, 대규모 서비스 확장에도 적합하지 않았습니다. 이런 제약을 극복하기 위해 등장한 대표적인 기술이 바로 PHP와 Java Servlet입니다.\n\nPHP는 1995년 라스무스 러도프(Rasmus Lerdorf)가 개인 홈페이지 방문자 수를 집계하려 만든 도구에서 출발했습니다. HTML에 직접 프로그래밍 코드를 삽입할 수 있다는 특징 덕분에 빠르게 확산되었고, 설치가 간편하고 학습 난이도가 낮아 개인 블로그나 중소형 웹사이트에서 널리 쓰였습니다. 특히 WordPress와 같은 콘텐츠 관리 시스템(CMS)의 기반 언어로 채택되면서 웹의 보편적 도구로 자리잡게 됩니다.\n\n반면, 기업이나 금융권 등에서는 더 정교하고 안정적인 웹 기술이 필요했습니다. 이에 선 마이크로시스템즈(Sun Microsystems)는 1997년 Java 언어를 바탕으로 Java Servlet을 발표합니다. Java는 원래 가전제품에 사용되는 임베디드 소프트웨어를 위해 만들어졌는데, 이를 웹에 맞게 개량한 것이 Java Servlet이었죠.\nServlet은 CGI 방식의 비효율을 극복해, 서버 메모리를 효과적으로 관리하고 요청에 빠르게 응답할 수 있는 구조를 제공했습니다. 이후 JSP(Java Server Pages)가 등장하면서 Java 기반의 웹 서비스 구축도 본격화됩니다. 이같은 서버 측 기술의 발전으로 웹은 사용자의 요청에 따라 실시간으로 콘텐츠를 생성하고 처리할 수 있게 되었습니다.\n하지만 서버에서 데이터를 만들어도, 그것을 사용자 화면에 효율적으로 반영하는 방법이 미흡했죠. 당시 웹에서는 사용자의 요청이 있을 때마다 전체 페이지를 새로 불러왔기 때문에, 화면이 깜빡이거나 로딩 시간이 길어지는 등 사용자 경험이 크게 저하되었습니다. 특히 빠른 반응이 핵심인 전자상거래나 검색 서비스에서는 치명적인 한계로 작용했습니다.\n \n7. 구글 맵이 보여준 혁신: Ajax\n\n이러한 문제를 해결하고, 서버에서 생성된 데이터를 더 효율적으로 브라우저에 전달하기 위해 1999년에 등장한 기술이 Ajax(Asynchronous JavaScript and XML)였습니다. Ajax는 기존처럼 페이지 전체를 새로 고치지 않고도, 서버와 주고받는 데이터를 바탕으로 화면의 일부만을 바꿀 수 있게 해주는 기술입니다. 즉, 매번 전체 페이지를 갱신하는 것이 아닌 특정 영역만을 빠르게 바꿀 수 있게 된 것이죠. 이로 인해 부드러운 전환과 빠른 반응이 가능한 웹이 열린 것입니다.\n\nAjax는 2005년 Google Maps를 통해 전 세계 사용자에게 각인됩니다. Google Maps는 웹 기반임에도 데스크탑 소프트웨어처럼 자연스러운 스크롤과 빠른 줌 기능, 실시간 탐색을 제공해, Ajax의 혁신을 보여주었죠.\n \n8. 브라우저 춘추전국시대 – Flash, JQuery\n\n인터넷 익스플로러는 브라우저 시장을 장악했지만, 표준을 무시한 독자적인 구현, 잦은 보안 문제, 기능 업데이트 중단 등으로 비판을 받기 시작합니다. 이에 따라 대안 브라우저들이 등장합니다.\n2004년, 모질라 재단은 오픈소스 기반의 Firefox를 출시해 빠른 속도, 탭 브라우징, 확장 기능 등으로 주목을 받았고, 애플도 WebKit 엔진을 기반으로 Safari를 개발해 Mac OS에 기본 탑재했죠. 그 결과, Firefox, Safari, Opera 등 다양한 브라우저들이 공존하는 ‘브라우저 춘추전국시대’로 접어들게 됩니다.\n\n하지만 각 브라우저가 HTML, CSS, JavaScript를 해석하고 실행하는 방식이 제각각이었습니다. 이 시기에 주목받은 것이 Flash였습니다. Flash는 독립 실행 환경으로 브라우저와 상관없이 일관된 사용자 경험을 보장했고, 복잡한 애니메이션, 음악, 동영상 등을 손쉽게 구현할 수 있어 웹 기반 게임, 광고, 멀티미디어 사이트 등에서 널리 사용되었습니다.\n\nFlash, Sliverlight와 같은 외부 플러그인을 사용하지 않고 브라우저 간의 호환성 문제를 보다 근본적으로 해결한 것은 jQuery입니다. 2006년 존 레식(John Resig)에 의해 만들어진 jQuery는 복잡한 자바스크립트 기능을 간단한 문법으로 사용할 수 있게 해주었고, 브라우저마다 다른 DOM, 이벤트 처리, Ajax 방식의 차이를 통일된 방식으로 다룰 수 있게 해주는 API(기능 호출 방식)를 제공했습니다. 이를 통해 개발자는 복잡한 크로스 브라우징 문제를 걱정하지 않고, 웹의 동작을 더 쉽게 제어할 수 있게 되었습니다.\n \n9. Flash 가고 HTML5 온다\nFlash나 Silverlight 같은 별도의 플러그인에 의존한 멀티미디어 재생은 보안에 취약하고, 모바일 기기와의 호환도 떨어졌으며, 성능 문제도 잦았습니다.\n이런 문제를 해결하기 위해 HTML의 새로운 버전인 HTML5가 개발되었고, 2008년 초안이 공개된 뒤 2014년 정식 표준으로 채택됩니다. HTML5는 단순히 웹페이지의 구조를 구성하는 언어를 넘어, 웹 자체를 하나의 앱 실행 환경으로 발전시키기 위한 핵심 기술로 자리잡습니다.\nHTML5를 통해 브라우저만으로도 동영상과 음악을 재생할 수 있고, 캔버스를 활용한 그래픽 표현이나 사용자 위치 정보 활용, 드래그 앤 드롭 같은 다양한 상호작용 기능도 구현할 수 있게 되었습니다. 웹페이지의 구조도 더 명확하게 나눌 수 있게 되어, 사용자 경험과 접근성도 함께 향상되었죠. 결과적으로 HTML5는 웹을 단순한 문서 공유 도구에서 ‘앱이 실행되는 플랫폼’으로 바꾸는 전환점이 됩니다.\n특히 2010년, 애플이 아이폰에서 Flash 지원을 중단한다고 발표하면서 플러그인 중심의 웹 기술은 급속히 쇠퇴하고, HTML5 중심의 표준 웹 기술이 주류로 자리잡게 됩니다.\n \n10. 빠르고 간편해지는 백엔드 개발\n웹 개발은 점점 복잡해졌고, 이에 따라 웹 개발자들은 더 많은 기능을 더 빠른 시간 안에 구현해야 했죠. 이 과정에서 PHP는 개발 속도는 빠르지만 유지보수가 어렵고, Java는 안정성은 뛰어나지만 설정이 복잡하고 개발 속도가 느린 구조적인 한계에 부딪히게 됩니다.\n\n이런 상황에서 새로운 접근을 제시한 것이 바로 Ruby on Rails입니다. 2004년 데이비드 하이네마이어 한슨(David Heinemeier Hansson)이 만든 Rails는 Ruby 언어를 기반으로, 반복적인 코드를 줄이고 구성 요소를 표준화하며, 데이터베이스와의 연동까지 자동화하는 기능을 제공합니다. GitHub, Shopify, Twitter 같은 서비스들이 초기에 Rails를 채택하면서 그 영향력은 더욱 커졌습니다.\n\n비슷한 시기, Python 기반의 Django도 등장합니다. 원래는 지역 신문사의 콘텐츠 관리 시스템을 위해 개발되었지만, 빠른 개발과 보안 중심 설계 덕분에 교육기관, 언론사, 콘텐츠 서비스 등에서 널리 사용됩니다.\nDjango는 기본적으로 관리자 화면이 자동 생성되며, 복잡한 SQL문을 직접 작성하지 않고 파이썬 문법으로 데이터를 조작할 수 있었고, 템플릿 시스템까지 제공하며 웹 전반의 구조를 깔끔하게 정리할 수 있었습니다.\n이처럼 Ruby on Rails와 Django는 복잡한 서버 개발을 간결하게 만들었고, 웹 개발이 ‘빠른 프로토타입 제작 → 반복적 개선’이라는 새로운 문화로 변화하는 데 핵심적인 역할을 했습니다.\n \n11. 브라우저 시장을 제패한 크롬\n2000년대 중반, 구글은 더 이상 단순한 검색 서비스 기업이 아니라, 웹 자체를 하나의 운영체제처럼 만들겠다는 비전을 세우게 됩니다. 사용자 대부분이 웹 브라우저를 켜고 제일 먼저 방문하는 곳이 구글이었기에, 웹이 OS처럼 작동한다면 구글은 그 출발점에 설 수 있었죠.\n\n이를 위해 구글은 문서 작성(Google Docs), 이메일(Gmail), 캘린더 같은 웹 기반 소프트웨어를 차례로 개발합니다. 하지만 웹 애플리케이션을 제대로 작동시키기 위해서는 당시 브라우저의 성능으로는 한계가 있었습니다. 이에 구글은 스스로 브라우저를 만들기로 결정하고, 브라우저의 핵심 구성 요소인 자바스크립트 엔진도 직접 새로 개발하기로 합니다.\n그렇게 2008년 V8 JavaScript 엔진이 등장합니다. V8은 기존 엔진들과 달리 코드를 한 줄씩 해석하는 방식이 아니라, 전체 코드를 기계어로 바꿔 실행하는 JIT(Just-In-Time) 컴파일 방식을 채택합니다. 이로써 자바스크립트의 실행 속도가 획기적으로 빨라졌고, 브라우저에서 실제 데스크톱 앱에 가까운 복잡한 기능도 가능해졌습니다. 또한 멀티코어 CPU 환경에 최적화된 병렬 처리 기술도 적용되었죠.\n\nV8 엔진은 애플의 오픈소스 렌더링 엔진인 WebKit과 결합되어 같은 해 ‘크롬Chrome’ 브라우저로 완성됩니다. 크롬은 빠른 속도와 강력한 디버깅 도구, 간결한 사용자 인터페이스로 개발자와 일반 사용자 모두에게 큰 인기를 끌었고, 당시 인터넷 익스플로러가 독점하던 브라우저 시장에서 속도와 안정성, 개발 친화성을 무기로 빠르게 점유율을 확보해나갑니다. 2012년에는 세계 브라우저 점유율 1위로 올라서며 웹 개발의 새로운 표준 환경을 만들어갑니다.\n \n12. JavaScript할 줄 알죠? 이제 서버도 개발하세요: Node.js\n\n2009년, 라이언 달Ryan Dahl 은 구글의 V8 JavaScript 엔진을 기반으로 서버에서도 JavaScript를 실행할 수 있는 기술인 ‘Node.js’를 발표합니다. 이전까지는 브라우저(클라이언트)는 JavaScript, 서버는 PHP, Java, Python 같은 언어로 나뉘어 개발하는 것이 일반적이었지만, Node.js의 등장으로 한 명의 개발자가 프론트엔드와 백엔드를 모두 자바스크립트로 개발할 수 있는 시대가 열립니다. 따라서 빠른 개발과 인력 절감이 중요한 스타트업 환경에서 특히 큰 주목을 받게 됩니다.\nNode.js의 또 다른 혁신은 서버 작동 방식 자체를 바꿨다는 점입니다. 기존 서버는 요청이 들어올 때마다 새로운 프로세스나 스레드를 생성해 처리했지만, 이는 많은 사용자가 동시에 접속하면 서버에 과부하를 일으키기 쉬웠습니다. Node.js는 하나의 프로세스로 수천 개의 요청을 효율적으로 처리할 수 있도록 했습니다. 이 구조는 채팅, 알림, 실시간 데이터 처리 등 동시성이 중요한 서비스에 최적화되어 있었습니다.\n\n이러한 구조적 혁신과 함께 Node.js 생태계를 탄탄하게 만든 또 하나의 요소는 npm(Node Package Manager)이었습니다. 개발자는 자신이 만든 라이브러리나 도구를 npm에 등록하고, 다른 개발자는 이를 간편하게 설치해 사용할 수 있었죠. 이로 인해 JavaScript 기반의 수많은 유틸리티와 프레임워크가 빠르게 확산되었습니다.\n \n13. 복잡한 UI의 페이스북: React\n\n2000년대 후반, 페이스북은 전 세계 수억 명의 사용자를 확보하며 빠르게 성장합니다. 사용자가 늘어날수록 웹사이트가 처리해야 할 데이터도 많아지고, 사용자의 행동에 따라 화면을 실시간으로 반응시키는 일이 중요해졌습니다. 그러나 당시 주류였던 jQuery 기반의 방식은 화면 구성 요소를 일일이 제어해야 했고, 복잡한 UI에서는 유지보수와 성능 모두에 한계가 있었습니다.\n\n이 문제를 해결하기 위해 페이스북은 2013년, React라는 UI 라이브러리를 오픈소스로 공개합니다. React는 웹 화면을 ‘컴포넌트’라는 작은 단위로 나눠서 개발할 수 있게 만들었고, 각 컴포넌트는 상태(state)와 전달받은 데이터(props)를 바탕으로 화면을 그리도록 설계되었습니다.\n가장 혁신적인 점은 실제 화면(DOM)을 직접 조작하지 않고, 가상의 화면 구조인 Virtual DOM을 사용한다는 점이었습니다. Virtual DOM은 실제 DOM보다 훨씬 가볍기 때문에 빠르게 화면의 변화를 계산할 수 있었고, 변경이 필요한 부분만을 선별해 실제 DOM에 반영함으로써 효율적인 렌더링이 가능했습니다. 이를 통해 React는 복잡한 UI를 다루는 데 필요한 속도와 관리 편의성을 모두 갖추게 되었고, 곧 프론트엔드 개발의 새로운 표준으로 자리잡게 됩니다.\n \n14. React, Angular, Vue 삼국지\n\n페이스북이 React를 공개하기 전, 2010년에 구글은 이미 AngularJS라는 혁신적인 프레임워크를 선보였습니다.\nAngularJS는 기존 웹 개발에서 사용자가 입력하면 자바스크립트로 직접 DOM을 찾아서 내용을 바꿔야 했던 것과 달리 화면에 보여줄 내용을 미리 템플릿화해두고, 사용자가 그 안에 넣을 데이터만 바꾸면, 알아서 화면이 갱신되는 구조였어요. 이런 방식을 ‘양방향 바인딩’이라고 부릅니다. 하지만 이를 위해 AngularJS는 화면이 바뀌었는지를 주기적으로 계속 확인해야 했기에 페이지가 복잡해질수록 느려지고, 성능 문제도 생겼습니다.\n이런 한계를 극복하려고, 구글은 2016년 완전히 새롭게 만든 Angular 2를 발표합니다. Angular 2는 React의 컴포넌트 방식을 도입합니다. 그리고 Zone.js라는 기술을 이용해 변화가 생길 가능성이 있는 순간에만 화면의 변화를 감지해 성능 문제도 해결하죠. 하지만 기존 AngularJS와 호환되지 않아 기존 사용자들이 이탈했고, 구조가 복잡하고 배우기도 어려워 신규 유저 유입도 쉽지 않았습니다.\n\n이러한 Angular의 복잡함과 React의 JSX 문법에 익숙하지 않은 개발자들 사이에서 새로운 대안으로 떠오른 것이 Vue.js입니다. Vue는 구글의 개발자 에반 유(Evan You)가 React와 Angular의 장점만을 취합해 만든 프레임워크입니다. React처럼 컴포넌트 기반 구조를 따르되, HTML 중심의 템플릿 문법을 사용해 진입 장벽을 낮췄고, 상태 관리, 라우팅, 빌드 도구 등을 공식적으로 지원하면서 점진적 도입이 가능한 구조로 설계되었습니다.\n덕분에 Vue는 소규모 팀과 개인 개발자를 중심으로 빠르게 확산되며, Angular, React와 함께 프론트엔드 삼국지를 형성하게 됩니다.\n \n15. 메타 프레임워크의 시대: Next.js\nReact, Angular, Vue는 화면을 구성하는 데 강력했지만, 웹 애플리케이션 전체를 구축하기에는 부족한 점이 있었습니다. 예를 들어, 화면 이동(라우팅), 서버에서의 데이터 처리, 검색엔진 최적화(SEO) 같은 기능은 따로 구현해야 했기 때문입니다.\n\n이 문제를 해결하고자 등장한 것이 바로 Next.js입니다. 2016년 Vercel에서 발표된 Next.js는 React를 기반으로 하지만, 페이지 단위 라우팅, 서버사이드 렌더링(SSR), 정적 사이트 생성(SSG), 이미지 최적화, SEO 기능 등을 내장해, 복잡한 설정 없이 전체 웹사이트를 효율적으로 구성할 수 있게 해줍니다.\n이처럼 UI 도구에 그치지 않고, 백엔드와 배포까지 포괄하는 프레임워크*를 ‘메타 프레임워크(meta-framework)’라고 부릅니다. Next.js 이후 Vue 기반의 Nuxt.js, Svelte 기반의 SvelteKit, Solid 기반의 SolidStart 등도 등장하며 웹 개발의 흐름은 ‘통합과 자동화’로 진화해가고 있습니다.\n이 과정에서 또 하나 주목받은 기술이 있습니다. 바로 Svelte입니다. 기존 프레임워크들이 브라우저에서 Virtual DOM을 통해 DOM을 갱신한 반면, Svelte는 개발자가 작성한 코드를 컴파일 시점에 실제 DOM 조작 코드로 바꿔주는 방식입니다. 즉, 브라우저가 무겁게 계산하지 않아도 되고, Virtual DOM도 필요 없게 되는 것이죠. Svelte는 이런 점에서 프레임워크가 아니라 컴파일러에 더 가깝고, DOM을 ‘언제, 어떻게 바꿀지’에 대한 고민을 아예 없애버리는 접근으로 새로운 흐름을 만들어가고 있습니다.\n* 프레임워크\n자주 사용하는 기능들을 미리 구조화해 놓은 일종의 도구 모음입니다. 즉, 개발자가 일일이 기본부터 만들 필요 없이, 정해진 틀 안에서 빠르고 일관되게 개발할 수 있도록 돕는 도구이죠.\n이 글에서 언급된 프레임워크는 Ruby on Rails, Django, React, Angular, Vue, NEXT.js입니다.\n\n \nReference\n정지훈. (2014). 거의 모든 인터넷의 역사. 메디치미디어\n정지훈. (2025). 거의 모든 IT의 역사. 메디치미디어\n이동준. (2023). 자바스크립트(JavaScript)의 탄생 이유와 역사.\n안정현. (2021). [Web] 웹 서비스의 역사와 발전.\n김민정. (2022). 웹 브라우저의 역사.\n김민상. (2021). 짧게 써보는 웹 프론트엔드의 역사.\n원문: 사소한 것들의 역사\n이 필자의 다른 글 읽기\n네가 실험한 것을 어떻게 믿음?: 실험실의 역사\n전쟁에서 기업으로, 기업에서 가정으로 이동해 온 컴퓨터의 역사\n22kg→ 1kg의 다이어트 성공기: 노트북의 역사",
        "enclosure": {
          "type": "image/jpeg",
          "length": "0",
          "url": "https://ppss.kr/wp-content/uploads/2025/08/000.jpg"
        },
        "dc:creator": "사소한 것들의 역사",
        "content": "동영상이나, 음성 따위의 각종 멀티미디어를 이용하는 인터넷을 이르는 말. = 월드 와이드 웹. 국립국어원 표준국어대사전 &#160; 시작하며 요즘 글이 뜸했습니다. 사실 뉴스레터 서비스가 유료로 전환되고 나니, 예전처럼 손이 잘 안 가게 되네요. (한 번 발송할 때 마다 치킨 한 마리값이 사라집니다..ㅠㅠ) 그래서 역사 콘텐츠를 텍스트가 아닌 다른 방식으로 즐길 수 있는 방법을 알아보고 있는데요, 그중 [&#8230;]",
        "contentSnippet": "동영상이나, 음성 따위의 각종 멀티미디어를 이용하는 인터넷을 이르는 말. = 월드 와이드 웹. 국립국어원 표준국어대사전   시작하며 요즘 글이 뜸했습니다. 사실 뉴스레터 서비스가 유료로 전환되고 나니, 예전처럼 손이 잘 안 가게 되네요. (한 번 발송할 때 마다 치킨 한 마리값이 사라집니다..ㅠㅠ) 그래서 역사 콘텐츠를 텍스트가 아닌 다른 방식으로 즐길 수 있는 방법을 알아보고 있는데요, 그중 […]",
        "guid": "http://3.36.87.144/?p=257673",
        "categories": [
          "IT",
          "역사"
        ],
        "isoDate": "2025-08-22T01:16:53.000Z"
      }
    ]
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Enabling Kotlin incremental compilation on Buck2",
        "link": "https://engineering.fb.com/2025/08/26/open-source/enabling-kotlin-incremental-compilation-on-buck2/",
        "pubDate": "Tue, 26 Aug 2025 16:00:52 +0000",
        "content:encodedSnippet": "The Kotlin incremental compiler has been a true gem for developers chasing faster compilation since its introduction in build tools. Now, we’re excited to bring its benefits to Buck2 –  Meta’s build system – to unlock even more speed and efficiency for Kotlin developers.\n\nUnlike a traditional compiler that recompiles an entire module every time, an incremental compiler focuses only on what was changed. This cuts down compilation time in a big way, especially when modules contain a large number of source files.\nBuck2 promotes small modules as a key strategy for achieving fast build times. Our codebase followed that principle closely, and for a long time, it worked well. With only a handful of files in each module, and Buck2’s support for fast incremental builds and parallel execution, incremental compilation didn’t seem like something we needed.\nBut, let’s be real: Codebases grow, teams change, and reality sometimes drifts away from the original plan. Over time, some modules started getting bigger – either from legacy or just organic growth. And while big modules were still the exception, they started having quite an impact on build times.\nSo we gave the Kotlin incremental compiler a closer look – and we’re glad we did. The results? Some critical modules now build up to 3x faster. That’s a big win for developer productivity and overall build happiness. \nCurious about how we made it all work in Buck2? Keep reading. We’ll walk you through the steps we took to bring the Kotlin incremental compiler to life in our Android toolchain.\nStep 1: Integrating Kotlin’s Build Tools API\nAs of Kotlin 2.2.0, the only guaranteed public contract to use the compiler is through the command-line interface (CLI). But since the CLI doesn’t support incremental compilation (at least for now), it didn’t meet our needs. Alternatively, we could integrate the Kotlin incremental compiler directly via the internal compiler’s components – APIs that are technically accessible but not intended for public use. However, relying on them would’ve made our toolchain fragile and likely to break with every Kotlin update since there’s no guarantee of backward compatibility. That didn’t seem like the right path either.\nThen we came across the Build Tools API (KEEP), introduced in Kotlin 1.9.20 as the official integration point for the compiler – including support for incremental compilation. Although the API was still marked as experimental, we decided to give it a try. We knew it would eventually stabilize, and saw it as a great opportunity to get in early, provide feedback, and help shape its direction. Compared to using internal components, it offered a far more sustainable and future-proof approach to integration.\n Depending on kotlin-compiler? Watch out!\nIn the Java world, a shaded library is a modified version of the library where the class and package names are changed. This process – called shading – is a handy way to avoid classpath conflicts, prevent version clashes between libraries, and keeps internal details from leaking out.\nHere’s quick example:\n\n\nUnshaded (original) class: com.intellij.util.io.DataExternalizer\nShaded class: org.jetbrains.kotlin.com.intellij.util.io.DataExternalizer\nThe Build Tools API depends on the shaded version of the Kotlin compiler (kotlin-compiler-embeddable). But our Android toolchain was historically built with the unshaded one (kotlin-compiler). That mismatch led to java.lang.NoClassDefFoundError crashes when testing the integration because the shaded classes simply weren’t on the classpath.\nReplacing the unshaded compiler across the entire Android toolchain would’ve been a big effort. So to keep moving forward, we went with a quick workaround: We unshaded the Build Tools API instead.  Using the jarjar library, we stripped the org.jetbrains.kotlin prefix from class names and rebuilt the library.\nDon’t worry, once we had a working prototype and confirmed everything behaved as expected, we circled back and did it right – fully migrating our toolchain to use the shaded Kotlin compiler. That brought us back in line with the API’s expectations and gave us a more stable setup for the future.\nStep 2: Keeping previous output around for the incremental compiler\nTo compile incrementally, the Kotlin compiler needs access to the output from the previous build. Simple enough, but Buck2 deletes that output by default before rebuilding a module. \nWith incremental actions, you can configure Buck2 to skip the automatic cleanup of previous outputs. This gives your build actions access to everything from the last run. The tradeoff is that it’s now up to you to figure out what’s still useful and manually clean up the rest. It’s a bit more work, but it’s exactly what we needed to make incremental compilation possible.\nStep 3: Making the incremental compiler cache relocatable\nAt first, this might not seem like a big deal. You’re not planning to move your codebase around, so why worry about making the cache relocatable, right?\nWell… that’s until you realize you’re no longer in a tiny team, and you’re definitely not the only one building the project. Suddenly, it does matter.\nBuck2 supports distributed builds, which means your builds don’t have to run only on your local machine. They can be executed elsewhere, with the results sent back to you. And if your compiler cache isn’t relocatable, this setup can quickly lead to trouble – from conflicting overloads to strange ambiguity errors caused by mismatched paths in cached data.\nSo we made sure to configure the root project directory and the build directory explicitly in the incremental compilation settings. This keeps the compiler cache stable and reliable, no matter who runs the build or where it happens.\nStep 4: Configuring the incremental compiler\nIn a nutshell, to decide what needs to be recompiled, the Kotlin incremental compiler looks for changes in two places:\n\n\nFiles within the module being rebuilt.\nThe module’s dependencies.\nOnce the changes are found, the compiler figures out which files in the module are affected – whether by direct edits or through updated dependencies – and recompiles only those.\nTo get this process rolling, the compiler needs just a little nudge to understand how much work it really has to do.\nSo let’s give it that nudge!\nTracking changes inside the module\nWhen it comes to tracking changes, you’ve got two options: You can either let the compiler do its magic and detect changes automatically, or you can give it a hand by passing a list of modified files yourself. The first option is great if you don’t know which files have changed or if you just want to get something working quickly (like we did during prototyping). However, if you’re on a Kotlin version earlier than 2.1.20, you have to provide this information yourself. Automatic source change detection via the Build Tools API isn’t available prior to that. Even with newer versions, if the build tool already has the change list before compilation, it’s still worth using it to optimize the process.\nThis is where Buck’s incremental actions come in handy again! Not only can we preserve the output from the previous run, but we also get hash digests for every action input. By comparing those hashes with the ones from the last build, we can generate a list of changed files. From there, we pass that list to the compiler to kick off incremental compilation right away – no need for the compiler to do any change detection on its own.\nTracking changes in dependencies\nSometimes it’s not the module itself that changes, it’s something the module depends on. In these cases, the compiler relies on classpath snapshot. These snapshots capture the Application Binary Interface (ABI) of a library. By comparing the current snapshots to the previous one, the compiler can detect changes in dependencies and figure out which files in your module are affected. This adds an extra layer of filtering on top of standard compilation avoidance.\nIn Buck2, we added a dedicated action to generate classpath snapshots from library outputs. This artifact is then passed as an input to the consuming module, right alongside the library’s compiled output. The best part? Since it’s a separate action, it can be run remotely or be pulled from cache, so your machine doesn’t have to do the heavy lifting of extracting ABI at this step.\n\nIf, after all, only your module changes but your dependencies do not, the API also lets you skip the snapshot comparison entirely if your build tool handles the dependency analysis on its own. Since we already had the necessary data from Buck2’s incremental actions, adding this optimization was almost free.\nStep 5: Making compiler plugins work with the incremental compiler\nOne of the biggest challenges we faced when integrating the incremental compiler was making it play nicely with our custom compiler plugins, many of which are important to our build optimization strategy. This step was necessary for unlocking the full performance benefits of incremental compilation, but it came with two major issues we needed to solve.\n Problem 1: Incomplete results\nAs we already know, the input to the incremental compiler does not have to include all Kotlin source files. Our plugins weren’t designed for this and ended up producing incomplete results when run on just a subset of files. We had to make them incremental as well so they could handle partial inputs correctly.\n\n Problem 2: Multiple rounds of Compilation\nThe Kotlin incremental compiler doesn’t just recompile the files that changed in a module. It may also need to recompile other files in the same module that are affected by those changes. Figuring out the exact set of affected files is tricky, especially when circular dependencies come into play. To handle this, the incremental compiler approximates the affected set by compiling in multiple rounds within a single build.\nCurious how that works under the hood? The Kotlin blog on fast compilation has a great deep dive that’s worth checking out.\nThis behavior comes with a side effect, though. Since the compiler may run in multiple rounds with different sets of files, compiler plugins can also be triggered multiple times, each time with a different input. That can be problematic, as later plugin runs may override outputs produced by earlier ones. To avoid this, we updated our plugins to accumulate their results across rounds rather than replacing them.\n\nStep 6: Verifying the functionality of annotation processors\nMost of our annotation processors use Kotlin Symbol Processing (KSP2), which made this step pretty smooth. KSP2 is designed as a standalone tool that uses the Kotlin Analysis API to analyze source code. Unlike compiler plugins, it runs independently from the standard compilation flow. Thanks to this setup, we were able to continue using KSP2 without any changes.\n Bonus: KSP2 comes with its own built-in incremental processing support. It’s fully self-contained and doesn’t depend on the incremental compiler at all. \nBefore we adopted KSP2 (or when we were using an older version of the Kotlin Annotation Processing Tool (KAPT), which operates as a plugin) our annotation processors ran in a separate step dedicated solely to annotation processing. That step ran before the main compilation and was always non-incremental.\nStep 7: Enabling compilation against ABI\nTo maximize cache hits, Buck2 builds Android modules against the class ABI instead of the full JAR. For Kotlin targets, we use the jvm-abi-gen compiler plugin to generate class ABI during compilation.\nBut once we turned on incremental compilation, a couple of new challenges popped up:\nThe jvm-abi-gen plugin currently lacks direct support for incremental compilation, which ties back to the issues we mentioned earlier with compiler plugins.\nABI extraction now happens twice – once during compilation via jvm-abi-gen, and again when the incremental compiler creates classpath snapshots.\nIn theory, both problems could be solved by switching to full JAR compilation and relying on classpath snapshots to maintain cache hits. While that could work in principle, it would mean giving up some of the build optimizations we’ve already got in place – a trade-off that needs careful evaluation before making any changes.\nFor now, we’ve implemented a custom (yet suboptimal) solution that merges the newly generated ABI with the previous result. It gets the job done, but we’re still actively exploring better long-term alternatives.\nIdeally, we’d be able to reuse the information already collected for classpath snapshot or, even better, have this kind of support built directly into the Kotlin compiler. There’s an open ticket for that: KT-62881. Fingers crossed!\nStep 8: Testing\nMeasuring the impact of build changes is not an easy task. Benchmarking is great for getting a sense of a feature’s potential, but it doesn’t always reflect how things perform in “the real world.” Pre/post testing can help with that, but it’s tough to isolate the impact of a single change, especially when you’re not the only one pushing code. \nWe set up A/B testing to overcome these obstacles and measure the true impact of the Kotlin incremental compiler on Meta’s codebase with high confidence. It took a bit of extra work to keep the cache healthy across variants, but it gave us a clean, isolated view of how much difference the incremental compiler really made at scale.\nWe started with the largest modules –  the ones we already knew were slowing builds the most. Given their size and known impact, we expected to see benefits quickly. And sure enough, we did.\nThe impact of incremental compilation \nThe graph below shows early results on how enabling incremental compilation for selected targets impacts their local build times during incremental builds over a 4-week period. This includes not just compilation, but also annotation processing, and a few other optimisations we’ve added along the way.\nWith incremental compilation, we’ve seen about a 30% improvement for the average developer. And for modules without annotation processing, the speed nearly doubled. That was more than enough to convince us that the incremental compiler is here to stay. \n\nWhat’s next\nKotlin incremental compilation is now supported in Buck2, and we’re actively rolling it out across our codebase! For now, it’s available for internal use only, but we’re working on bringing it to the recently introduced open source toolchain as well.\nBut that’s not all! We’re also exploring ways to expand incrementality across the entire Android toolchain, including tools like Kosabi (the Kotlin counterpart to Jasabi), to deliver even faster build times and even better developer experience.\nTo learn more about Meta Open Source, visit our open source site, subscribe to our YouTube channel, or follow us on Facebook, Threads, X and LinkedIn.\nThe post Enabling Kotlin incremental compilation on Buck2 appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>The Kotlin incremental compiler has been a true gem for developers chasing faster compilation since its introduction in build tools. Now, we’re excited to bring its benefits to Buck2 –  Meta’s build system – to unlock even more speed and efficiency for Kotlin developers. Unlike a traditional compiler that recompiles an entire module every time, [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/08/26/open-source/enabling-kotlin-incremental-compilation-on-buck2/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/08/26/open-source/enabling-kotlin-incremental-compilation-on-buck2/\">Enabling Kotlin incremental compilation on Buck2</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "The Kotlin incremental compiler has been a true gem for developers chasing faster compilation since its introduction in build tools. Now, we’re excited to bring its benefits to Buck2 –  Meta’s build system – to unlock even more speed and efficiency for Kotlin developers. Unlike a traditional compiler that recompiles an entire module every time, [...]\nRead More...\nThe post Enabling Kotlin incremental compilation on Buck2 appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=22830",
        "categories": [
          "Open Source"
        ],
        "isoDate": "2025-08-26T16:00:52.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Ksenia Shneyveys",
        "title": "How Kotlin Notebook Helps You Teach Programming",
        "link": "https://blog.jetbrains.com/kotlin/2025/08/how-kotlin-notebook-helps-teach-programming/",
        "pubDate": "Tue, 26 Aug 2025 19:21:30 +0000",
        "content:encodedSnippet": "Kotlin Notebook is a great tool for educators who want to teach programming in a more hands-on way. It lets you combine runnable code, Markdown textual explanations, and visualizations in one interactive environment. There’s no need to switch between multiple windows with slides, live demos, and IDEs during lectures. You can use a single notebook to write, explain, and run Kotlin code – all in one place.\nWe spoke with Anastasiia Birillo, the Head of the Education Research Group at JetBrains and former Kotlin lecturer at Constructor University in Bremen, and Kotlin Notebook Team Lead Ilya Muradyan to see how the notebooks are actually used in classes.\nAnastasiia has made her course notebooks publicly available. Check out the full notebook directory. For comparison, see the ‘Programming in Kotlin’ public materials – a slide-based course format.\nKotlin notebooks rely on the Kotlin Notebook plugin, which is bundled and enabled in IntelliJ IDEA by default, making setup simple.\nReal classroom use\nIn her course at Constructor University, Anastasiia used notebooks to teach programming in Kotlin. Each topic was built around a structured notebook with organized chapters consisting of Kotlin code cells with immediate outputs and explanations written in Markdown. Students watched her walk through the material live and had a copy of the notebook to rerun everything on their own.\n“I wanted students to see the whole idea, not just disconnected snippets. Kotlin notebooks made that possible. It worked really well for the interactive format of lectures with examples, prototypes, and concept exploration – they complemented IntelliJ IDEA for larger projects and practice.”\n\n            \nAnastasiia Birillo\n                                                                Head of the Education Research Group at JetBrains and former Kotlin lecturer at Constructor University in Bremen\n                                    \nExplore real teaching notebooks used at Constructor University. Here are a few shared by Anastasia:\nCollections\nObject-Oriented Programming\nGenerics\nWhy teach with notebooks\nIncremental execution\nKotlin notebooks support cell-based execution, allowing you to show language constructs and code snippets in an isolated way, debugging, testing, and rerunning chunks of code without restarting your whole script. This structure makes them ideal for live demos, debugging, or step-by-step teaching and live walk-throughs.\n“Kotlin notebooks gave structure to my lectures,” Anastasiia says. “Students could focus on the concepts instead of reading whole code snippets.”\nMarkdown + code\nNotebooks combine different types of data in a single interactive space. Want to mix runnable code snippets with explanations and visualizations? Kotlin Notebook helps bring programming concepts to life!\nEasy setup and sharing\nEverything can be easily launched in preset environments. This is especially useful for online classes, where students engage with notebooks shared with them via GitHub with minimal tech overhead. You can also easily share your work between other clients supporting notebooks – see the README for more details. \nTry it yourself: Sample notebooks\nKotlin Notebook is an incredibly effective tool for explaining code and exploring concepts in a structured, runnable way. \n“Thousands of developers already use notebooks for their everyday tasks. We think they address educators’ needs pretty well. Give the notebooks a try and share your feedback with us.”\n\n            \nIlya Muradyan\n                                                                Kotlin Notebook Team Lead\n                                    \nIf you teach Kotlin, run programming workshops, or just want a better way to demo code, give Kotlin notebooks a try. They offer fast setup, more focused lessons, runnable lectures, and support for code, text, and visuals in one file. \nHave you used Kotlin Notebook in your classroom or project? Let us know at education@kotlinlang.org. We’d love to hear how you are using it!",
        "dc:creator": "Ksenia Shneyveys",
        "content": "Kotlin Notebook is a great tool for educators who want to teach programming in a more hands-on way. It lets you combine runnable code, Markdown textual explanations, and visualizations in one interactive environment. There’s no need to switch between multiple windows with slides, live demos, and IDEs during lectures. You can use a single notebook [&#8230;]",
        "contentSnippet": "Kotlin Notebook is a great tool for educators who want to teach programming in a more hands-on way. It lets you combine runnable code, Markdown textual explanations, and visualizations in one interactive environment. There’s no need to switch between multiple windows with slides, live demos, and IDEs during lectures. You can use a single notebook […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=594750",
        "categories": [
          "news",
          "education",
          "education-research",
          "kotlin-notebook"
        ],
        "isoDate": "2025-08-26T19:21:30.000Z"
      },
      {
        "creator": "Olga Bedrina",
        "title": "How to Build a CI/CD Pipeline for iOS Projects",
        "link": "https://blog.jetbrains.com/teamcity/2025/08/cicd-for-ios/",
        "pubDate": "Tue, 26 Aug 2025 15:52:42 +0000",
        "content:encodedSnippet": "This article was brought to you by Kumar Harsh, draft.dev.\nDeveloping and releasing iOS applications involves navigating a complex web of code signing, provisioning profiles, multiple iOS versions, and stringent App Store guidelines/requirements. \nWithout an automated continuous integration, continuous delivery and/or deployment (CI/CD) pipeline, these challenges can lead to slower release cycles, increased errors, and inconsistent workflows.\nJetBrains TeamCity Cloud is an iOS DevOps CI/CD solution with support for Swift and Objective-C, macOS build agents, seamless integration with Xcode, and advanced configuration options via YAML. TeamCity simplifies the process of building, testing, and deploying iOS applications.\nIn this article, you will learn how to set up an end-to-end CI/CD pipeline for your iOS projects using TeamCity Cloud. It covers everything from integrating version control systems (VCSs) and automating builds with fastlane to signing and packaging your apps and deploying them to TestFlight.\nUnderstanding the iOS CI/CD pipeline\nA well-structured CI/CD pipeline for iOS applications automates repetitive tasks and ensures high-quality, consistent releases. Before you start building the pipeline, let’s break down the typical stages of an iOS pipeline and how TeamCity Cloud supports each part of the process.\nCode checkout and version control integration\nA typical pipeline begins with fetching the latest changes from your version control system (VCS), such as GitHub, GitLab, or Bitbucket. TeamCity offers built-in integrations for popular VCS providers, allowing you to easily connect your repository and configure access credentials.\n\n\n\n\nYou can set up build triggers so that the pipeline runs automatically on every push or pull request or commit to specific branches. This ensures your project is always tested against the latest code changes.\nBuilding iOS applications with Xcode\nOnce the code is checked out, the next step is to build the project. You can use either the default xcodebuild command line tool or any third-party tool, such as fastlane. In this step, the build tool compiles the source code, assembles resources, and generates the app bundle.\nYou can define build steps for different configurations—such as Debug, Release, or custom schemes—directly in TeamCity. When used with TeamCity Build Parameters, you can reuse the same pipeline for multiple configurations.\nWith Matrix Build on TeamCity, you can even take this a step further and generate multiple builds in parallel using a combination of values for your build parameters. This gives you the flexibility to target multiple environments or testing scenarios.\nExample of matrix builds in TeamCity\n\n\n\nTesting across multiple iOS versions\nTo maintain code quality and prevent regressions, you should always consider including automated testing. TeamCity optimizes automated tests through its parallel testing capabilities. It allows you to test across multiple simulated iOS versions and device configurations simultaneously, reducing feedback cycles and ensuring broader coverage.\nStatic code analysis and code coverage reporting\nStatic code analysis helps catch issues early in the development cycle. You can integrate tools like SwiftLint as build steps to enforce style and coding conventions.\nFor deeper insights, TeamCity supports code-quality tools, like JetBrains Qodana, and can generate code coverage reports to help evaluate test completeness and identify untested areas of your codebase.\nSigning and packaging (IPA files)\nOne of the more intricate parts of iOS CI/CD is managing code signing. Modern iOS DevOps practices recommend using a Git-based or file bucket-based store for certificates and keys. \nPopular tools, like fastlane, offer out-of-the-box support to implement and use these practices conveniently. You can always use git (with SSH authentication) or the AWS CLI tool to connect to your private certificates store from inside your pipelines and sign your apps as needed.\nDeploying to TestFlight or the App Store\nFinally, once your app is built, tested, and signed, it’s ready to be distributed. Tools like fastlane can automate the upload of your IPA files to TestFlight or the App Store from within your pipelines. Y\nou might need to configure App Store Connect or Apple’s application-specific passwords to make this work. But it makes it very easy to push changes to a dedicated TestFlight branch in your VCS repo, which are then uploaded to TestFlight within minutes.\nYou can also configure separate workflows for beta and production releases, include postdeployment notifications for your team, and monitor the deployment status via TeamCity’s dashboards.\nNow that you understand the usual components that make up an iOS pipeline, it’s time to build one yourself! Here’s a rough overview of what this pipeline does:\n\n\n\n\nPrerequisites\nYou’ll need the following before you can move ahead:\nAccess to a TeamCity server or TeamCity Cloud with Mac build agents. Feel free to create a TeamCity Cloud trial account here.\nAn iOS project hosted on GitHub. You can use one of your own projects or fork this one to your repo to follow along.\nAn Apple Developer Program account.\nAccess to the App Store Connect platform.\nfastlane installed locally.\nAn Amazon Web Service (AWS) Simple Storage Service (S3) bucket to store app-signing certificates and profiles.\nSetting up the iOS project\nThis tutorial uses fastlane to define the workflows that will be automated with TeamCity. It’s a popular mobile DevOps tool used across iOS and Android projects.\nInitializing fastlane\nOnce you have cloned the forked repo locally and set up fastlane, run the following command in a terminal inside your project directory:\nfastlane init\nSelect Automate beta distribution to TestFlight as the answer for What would you like to use fastlane for? \nThe CLI will then ask for your Apple ID username and attempt to log in to your App Store Connect account. Once it’s logged in, it will create a fastlane/ folder inside your project directory along with an Appfile. \nThis Appfile will contain the details about your project that you will supply during the fastlane init process. These details can include the app bundle, your Apple ID email, and your Apple Developer team ID.\nNote that for now, fastlane init will hard-code these values in the Appfile, but before pushing the fastlane files to your repo, you should replace these with environment variables; you’ll learn how to do this later in the tutorial.\nSetting up the beta lane\nNext, you need to paste the following contents into fastlane/Fastfile:\ndefault_platform(:ios)\n\nbefore_all do\n  create_keychain(\n    name: \"keychain\",\n    password: \"password\",\n    default_keychain: true,\n    unlock: true,\n    timeout: 3600,\n    lock_when_sleeps: false\n  )\n  match(type: \"appstore\", keychain_name: \"keychain\", keychain_password: \"password\", readonly: true)\nend\n\n\nplatform :ios do\n  desc \"Build and upload to TestFlight\"\n  lane :beta do |options|\n    # Increment build number\n    increment_build_number(xcodeproj: \"Facto.xcodeproj\")\n    \n    # Build the app\n    build_app(\n      scheme: \"Facto\",\n      configuration: \"Release\",\n      export_method: \"app-store\",\n      export_options: {\n        provisioningProfiles: {\n          \"dev.draft.Facto\" => \"Facto Distribution\"\n        }\n      }\n    )\n\n    api_key = app_store_connect_api_key(\n      key_id: options[:key_id],\n      issuer_id: options[:issuer_id],\n      key_filepath: File.absolute_path(\"tmp/AuthKey.p8\"),\n      duration: 1200,\n      in_house: false\n    )\n        \n    # Upload to TestFlight\n    pilot(\n      api_key: api_key,\n      skip_waiting_for_build_processing: true,\n      skip_submission: true\n    )\n    \n  end\nend\nThe Fastfile is where you define lanes—automated workflows that fastlane will run for you. The Fastfile above sets up a lane called beta to build and upload your iOS app to TestFlight.\nThe default_platform(:ios) statement tells fastlane that you’re working with an iOS project, so all lanes will assume this unless otherwise specified.\nThe before_all block runs before any lane is executed. It carries out two tasks before running any lanes:\ncreate_keychain: This creates and unlocks a temporary keychain for your build. This is safer and cleaner than using your login keychain directly. In CI systems, this is a mandatory step as the runner environment often doesn’t ship with a keychain.\nmatch: This uses match to fetch the appropriate App Store provisioning profile from a shared certificate repo and installs it into the keychain. readonly: true ensures that no new profiles are created during the process.\nThe beta lane is your main automation workflow. You’ll run this in TeamCity when you’re ready to build the app and push it to TestFlight.\nEach step in this lane performs a part of the TestFlight release process:\nincrement_build_number(xcodeproj: \"Facto.xcodeproj\") automatically increases the build number in your Xcode project. This is required for each TestFlight upload.\nbuild_app(...) builds your iOS app for distribution. It uses the Facto scheme based on the example app provided above, but please make sure to update it to your app’s scheme. Next, it uses the Release configuration and exports the app for the App Store (export_method: \"app-store\"). It also specifies the correct provisioning profile to use for the given bundle identifier. Make sure to update this to match your provisioning profile.\napi_key = app_store_connect_api_key(...) loads a private API key (named AuthKey.p8) to authenticate securely with App Store Connect. The key ID and issuer ID are passed in via options, so you can keep secrets outside the code. You will need to set these up in the CI system before you can run the beta lane.\nFinally, pilot(...) uploads the build to TestFlight using the previously generated api_key. It doesn’t wait for Apple’s build processing to finish or submit the build for App Review, which makes sense during internal testing.\nThis Fastfile allows you to simply call fastlane beta in your TeamCity job after setting up the necessary credentials and have fastlane take care of all deployment tasks.\nConfiguring fastlane match\nNow that your Fastfile is set up, the next step is to configure match, which will handle code signing for you. Code signing is a necessary part of the iOS build and distribution process, and match helps automate it in a safe and scalable way, which is especially useful when working in CI environments like TeamCity.\nTo do that, run the following in your project directory:\nfastlane match init\nThis command will guide you through a short process of configuring a few match preferences and will create a Matchfile for you at the end.\nAs part of this process, fastlane will prompt you to choose a storage backend. For this tutorial, select S3. Here’s why:\nEasier setup: Git-based storage typically requires configuring SSH keys or access tokens in your CI pipeline, which can be tedious and error-prone.\nBetter access control: With S3, you can use IAM roles, bucket policies, or presigned URLs to control who can access signing assets tightly.\nMore secure: S3 eliminates the need to expose or manage SSH credentials and can integrate with cloud-native security tooling for auditing and access logging.\nOnce the Matchfile is created, make sure to fill in your S3 bucket’s name in the s3_bucket(\"\") statement in the file.\nRun the following command to store your certificates and profiles in this bucket using match:\nfastlane match appstore\nThis command tells fastlane to generate or download the necessary signing certificates and provisioning profiles for App Store distribution.\nOnce that’s done, fastlane will upload your certificates and provisioning profiles to the S3 bucket and automatically pull them down during builds. You won’t need to manage or manually install signing files anymore; match will do it for you.\nAt this point, you should update your Appfile to remove the hard-coded credentials that fastlane init created. Storing sensitive values directly in configuration files poses a security risk if they’re accidentally committed to version control. \nInstead, you’ll use environment variables to supply these values securely. Replace the contents of the fastlane/Appfile file with the following:\napp_identifier ENV[\"APP_IDENTIFIER\"]\napple_id ENV[\"APPLE_ID\"]\nteam_id ENV[\"TEAM_ID\"]\nAt this point, you are ready to start building a TeamCity pipeline. Make sure to commit the fastlane folder and its contents (Appfile, Fastfile, and Matchfile) to your app’s GitHub repo before moving ahead.\nCreate a new project in TeamCity Cloud\nNow that your iOS project is set up with fastlane, it’s time to create a new project in TeamCity Cloud. This will be the foundation of your CI/CD pipeline.\nLet’s start with a project creation. Head over to your TeamCity Cloud instance and click the + sign in the menu on the left. Click Manually, choose the name for your project, and TeamCity will automatically fill out the Project ID for you. Then click Create:\n\n\n\n\nYou’ll then see the project overview page. Here, you can set up VCS roots for the project, define parameters and other settings. You can also choose whether you want to create a pipeline for the project or use a build configuration.\nHere’s a short description how the two differ:\nPipeline: A simplified alternative to build configurations linked in a build chain. Features a smart visual editor and allows you to use YAML for configuration-as-code.\nBuild configuration: Build configurations and pipelines represent actual CI/CD routines. A build configuration stores a sequence of build steps (basic operations to be performed during a build run), and settings required to execute these steps. \nIn this tutorial, we’ll proceed with pipelines. Click the + Create pipeline button in the UI.\n\n\n\n\nOn the next step, search for the repo that you forked. After you select the repo, you’ll see a few more fields on the page:\n\n\n\n\nHere, set a name for the pipeline and leave the other options as defaults. Once that’s done, click Create. This will create the pipeline for you. \nAlso, since you selected the default options when choosing the repo and creating the pipeline (set Default branch to main and Branches to monitor to All branches), this pipeline will be configured to run whenever a commit is pushed to any branch on the repo. You can change this option later if you want, though.\nOnce the pipeline is created, you’ll be navigated to the pipeline editor view, with options to create build configurations, add build steps, configure triggers, and set up your iOS deployment workflow:\n\n\n\n\nYou can now start configuring your jobs!\nConfigure build job\nYou’ll notice that an empty job has already been created for you with the name Job 1. You will update this job to set up your iOS development credentials and run the fastlane beta command.\nFirst of all, you need to set the runner for the job. By default, TeamCity runs jobs on a Linux-based runner. However, you need a macOS-based runner for building iOS projects, so in the right pane under Runs On, search for and select macOS 14 Sonoma Medium Arm64 as the runner:\n\n\n\n\nNext, in the Steps section of the same pane, click Script to add a new script-based step. This is where you will write the script for your fastlane beta call.\nName the step as Push beta and paste the following script in the Script content field:\nexport AWS_ACCESS_KEY_ID=%AWS_ACCESS_KEY_ID%\nexport AWS_SECRET_ACCESS_KEY=%AWS_SECRET_ACCESS_KEY%\nexport AWS_REGION=%AWS_REGION%\n\nmkdir -p fastlane/tmp\n\naws secretsmanager get-secret-value \\\n    --secret-id ASC_KEY \\\n    --output text \\\n    --query SecretString | base64 -d -o fastlane/tmp/AuthKey.p8\n\nexport KEY_ID=`aws secretsmanager get-secret-value \\\n    --secret-id ASC_KEY_ID \\\n    --output text \\\n    --query 'SecretString' | cut -d '\"' -f4`\n                   \nexport ISSUER_ID=`aws secretsmanager get-secret-value \\\n    --secret-id ASC_ISSUER_ID \\\n    --output text \\\n    --query 'SecretString' | cut -d '\"' -f4`\n\nexport APP_IDENTIFIER=`aws secretsmanager get-secret-value \\\n    --secret-id APP_IDENTIFIER \\\n    --output text \\\n    --query 'SecretString' | cut -d '\"' -f4`\n\nexport APPLE_ID=`aws secretsmanager get-secret-value \\\n    --secret-id APPLE_ID \\\n    --output text \\\n    --query 'SecretString' | cut -d '\"' -f4`\n\nexport MATCH_PASSWORD=`aws secretsmanager get-secret-value \\\n    --secret-id MATCH_PASSWORD \\\n    --output text \\\n    --query 'SecretString' | cut -d '\"' -f4`\n\nexport TEAM_ID=`aws secretsmanager get-secret-value \\\n    --secret-id TEAM_ID \\\n    --output text \\\n    --query 'SecretString' | cut -d '\"' -f4`\n\nbundle install\n\nbundle exec fastlane beta \\\n    key_id:\"$KEY_ID\" \\\n    issuer_id:\"$ISSUER_ID\"\n\n\n\n\nLet’s take a moment to understand what this script does:\nAWS credentials setup:\nexport AWS_ACCESS_KEY_ID=%AWS_ACCESS_KEY_ID%\nexport AWS_SECRET_ACCESS_KEY=%AWS_SECRET_ACCESS_KEY%\nexport AWS_REGION=%AWS_REGION%\nThese lines set up AWS credentials that will be used to access AWS Secrets Manager. The %VARIABLE% syntax is TeamCity’s way of referencing build parameters.\nApp Store Connect key setup:\nmkdir -p fastlane/tmp\naws secretsmanager get-secret-value \\\n    --secret-id ASC_KEY \\\n    --output text \\\n    --query SecretString | base64 -d -o fastlane/tmp/AuthKey.p8\nThis creates a temporary directory for the App Store Connect API key and downloads it from AWS Secrets Manager. The key is stored in Base64 format and needs to be decoded.\nEnvironment variables from Secrets:\nexport KEY_ID=`aws secretsmanager get-secret-value \\\n    --secret-id ASC_KEY_ID \\\n    --output text \\\n    --query 'SecretString' | cut -d '\"' -f4`\nThis pattern is repeated for all sensitive values (ISSUER_ID, APP_IDENTIFIER, APPLE_ID, MATCH_PASSWORD, and TEAM_ID). Each secret is retrieved from AWS Secrets Manager and stored as an environment variable. The cut -d '\"' -f4 command extracts the actual value from the JSON response.\nDependencies and execution:\nbundle install\nbundle exec fastlane beta \\\n    key_id:\"$KEY_ID\" \\\n    issuer_id:\"$ISSUER_ID\"\nFinally, the script installs Ruby dependencies using Bundler and runs the beta lane with the necessary parameters.\nThis approach has several security benefits:\nSensitive credentials are stored in AWS Secrets Manager, not in TeamCity.\nThe App Store Connect API key is only temporarily available during the build.\nAll sensitive values are passed as environment variables, not command line arguments.\nYou are able to use these tools (aws, bundle, base64, etc.) without having to install them because TeamCity-hosted runners ship with a list of preinstalled software.\nNote that using an external, secure credentials manager is always recommended in production environments, which is why it has been demonstrated above. \nHowever, if you just want to set up the pipeline quickly, you can choose to skip the next section and supply the credentials through TeamCity build parameters. But please make sure to always use credential managers in production.\nSet up AWS Secrets\nBefore you can run this script, you’ll need to set up the following secrets in AWS Secrets Manager:\nASC_KEY: Your App Store Connect API key file (.p8) in Base64 format\nASC_KEY_ID: Your App Store Connect API key ID\nASC_ISSUER_ID: Your App Store Connect API issuer ID\nAPP_IDENTIFIER: Your app’s bundle identifier\nAPPLE_ID: Your Apple ID email\nMATCH_PASSWORD: Password for encrypting/decrypting certificates in match\nTEAM_ID: Your Apple Developer team ID\nYou can follow this guide to create secrets through the AWS console. Make sure these secrets are set up correctly before moving ahead:\n\n\n\n\nSet up build parameters\nTo access these secrets from your pipeline, you need to provide the aws CLI tool with an access key and secret pair that has the necessary permissions to access the secret.\nNote that in TeamCity On-Premises, you can instead use the AWS Connection to provide your pipeline with a method to connect with your AWS resources with temporary credentials instead of exposing static ones.\nYou’ll need to set up three build parameters:\nAWS_ACCESS_KEY_ID: Your AWS access key\nAWS_SECRET_ACCESS_KEY: Your AWS secret key\nAWS_REGION: The AWS region where your secrets are stored (eg us-east-1)\nOnce you have generated these, head over to your pipeline details page and click Pipeline settings above Job Details:\n\n\n\n\nThe right pane will now show pipeline configuration details. You can find both parameters and secrets on this page. TeamCity secrets are build parameters whose actual values are stored securely by TeamCity, hidden away from the web UI, logs, YAML configurations, and other locations.\nYou will notice a + icon next to No Secrets. Click it to add new secrets. Add the secrets listed above. Once that’s done, here’s what the pipeline settings page should look like:\n\n\n\n\nWith these configurations in place, your build job is ready to run. When triggered, it will:\nset up the necessary Apple development credentials from AWS;\ndownload and configure the App Store Connect API key; and\nrun fastlane to build and deploy your app to TestFlight.\nTesting the pipeline\nTo trigger a build, you can either push a new commit to the repo or click the purple Run button at the top right of the TeamCity web portal. It should trigger a new build for you and take you to the build details page. In about four minutes, the build should complete running successfully:\n\n\n\n\nYou can explore the build logs in the right panel to understand how the build processed and read any warning, info, or error messages that were generated. TeamCity groups logs by steps, and searching for and downloading log files is a straightforward process.\nOnce the build completes successfully, you should receive an email from App Store Connect on the email address linked to your Apple ID:\n\n\n\n\nIf you log in to your App Store Connect portal, you will see the new version ready to be rolled out for testing:\n\n\n\n\nThis means that your iOS pipeline is working correctly!\nConclusion\nIn this guide, you learned how to build a modern CI/CD pipeline for iOS applications using TeamCity Cloud and fastlane, thus automating your entire workflow from local development to TestFlight deployment. \nThe result is a fully automated pipeline that picks up commits, runs builds, uploads to TestFlight, and provides complete visibility through dashboards, which creates a repeatable workflow that reduces manual effort, eliminates common errors, and ensures consistent app delivery.\nWhile this tutorial focused on TestFlight deployment, the same setup can be extended to include test automation, static analysis, App Store deployment, and team notifications. With TeamCity Cloud’s advanced features — such as live test reporting, matrix builds, and build chains — you have all the tools you need to scale your iOS delivery process as your app and team grow.\n\n                                \nStart a free trial",
        "dc:creator": "Olga Bedrina",
        "content": "This article was brought to you by Kumar Harsh, draft.dev. Developing and releasing iOS applications involves navigating a complex web of code signing, provisioning profiles, multiple iOS versions, and stringent App Store guidelines/requirements. Without an automated continuous integration, continuous delivery and/or deployment (CI/CD) pipeline, these challenges can lead to slower release cycles, increased errors, and [&#8230;]",
        "contentSnippet": "This article was brought to you by Kumar Harsh, draft.dev. Developing and releasing iOS applications involves navigating a complex web of code signing, provisioning profiles, multiple iOS versions, and stringent App Store guidelines/requirements. Without an automated continuous integration, continuous delivery and/or deployment (CI/CD) pipeline, these challenges can lead to slower release cycles, increased errors, and […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=594006",
        "categories": [
          "ios",
          "tutorials",
          "how-to",
          "tutorial"
        ],
        "isoDate": "2025-08-26T15:52:42.000Z"
      },
      {
        "creator": "Dmitry Pogrebnoy",
        "title": "Unveiling Ruby Debuggers: byebug, debug gem, and the Power of RubyMine",
        "link": "https://blog.jetbrains.com/ruby/2025/08/unveiling-ruby-debuggers-byebug-debug-gem-and-the-power-of-rubymine/",
        "pubDate": "Tue, 26 Aug 2025 07:11:53 +0000",
        "content:encodedSnippet": "Hello, Ruby developers!\nWhether you are a seasoned Ruby developer or just getting started, mastering the debugger will save you time and frustration when tracking down bugs. At RubyMine, we’ve spent years building debugging tools for Ruby. In this blog series, we’re sharing some of the insights we’ve gained along the way.\nIn this post, we’ll take a closer look at the internal workings of byebug and the debug gem, comparing their unique approaches, strengths, and limitations. We’ll also break down the architecture of the RubyMine debugger to see how it works. Finally, we’ll conduct an experiment to test the performance of these debuggers and find out which one comes out on top.\nThis is the third post in a series inspired by Demystifying Debuggers, a talk by Dmitry Pogrebnoy, RubyMine Team Lead, presented at EuRuKo 2024, RubyKaigi 2025 and RubyConf Africa 2025. In this post, we go deeper into how Ruby debuggers work under the hood and share insights about Ruby debuggers.\nIf you haven’t seen the earlier posts yet, we recommend starting there:\nMastering Ruby Debugging: From puts to Professional Tools\nInside Ruby Debuggers: TracePoint, Instruction Sequence, and CRuby API\nPrefer watching? You can also check out the original talk here: 🎥 Dmitry Pogrebnoy, “Demystifying Debugger”\nLet’s dive into the internals!\nIs the debugger an essential tool for Ruby developers?\nBefore we jump into how debuggers work, let’s take a step back and ask: How often do Ruby developers actually use a debugger? The answer might surprise you.\nThe need for and reliance on a debugger can vary greatly depending on the programming language and framework you’re using. It’s also influenced by the preferences of the developer community and the specific needs of the domain. Some developers might use a debugger all the time, while others might prefer different tools or methods for troubleshooting. Some of these tools were covered in the first post in the series.\nUnfortunately, there aren’t any reliable public stats on how often Ruby developers use debuggers overall. But thanks to anonymous usage data from RubyMine users, we can still get a rough sense of how common debugger usage is in real-world projects.\nThe pie chart below shows how often RubyMine users run their code using a debugger compared to other types of run configurations. These numbers come from anonymous usage stats collected in RubyMine 2025.1.\n\nAs we can see, almost every third run in RubyMine is a debugger run. This demonstrates just how essential and fundamental the debugger has become for professional Ruby developers. That’s why the RubyMine team tries to provide the smoothest possible debugger experience that will enhance your efforts in investigating problems.\nHow do Ruby debuggers work internally?\nIn the previous section, we covered the main building blocks of Ruby debuggers. Now it’s time to see how these components are applied in real-world tools. In this section, we’ll start with the byebug gem, then move on to the debug gem, and finally take a look at the RubyMine debugger. Let’s begin with byebug!\nSimplified model of the byebug debugger\nbyebug is a simple Ruby debugger. It provides essential features like breakpoints, basic stepping, and variable inspection. By default, it offers a command-line interface (CLI) for debugging, but there’s also an option to install and configure a plugin for GUI support in code editors. \nTo start a debugging session with byebug, you typically need to modify your project’s source code by inserting byebug statements, or run commands manually in the terminal, which require some adjustments to your project setup, especially when working with Rails applications.\nLet’s take a look at the simplified model of how byebug works. This code in the model should be executed before any code of the application that we are going to debug.\nbreakpoints = [] # list of breakpoints\ntracepoints = [] # contains a single tracepoint for each event type\n\n\n# For every type of tracepoint event\ntracepoints &lt;&lt; TracePoint.trace(:line) do |tp|\n breakpoint = breakpoints.find do |b|\n   tp.path == b.path &amp;&amp; tp.lineno == b.lineno\n end\n\n\n if breakpoint\n   handle_breakpoint(breakpoint)\n end\nend\n\n\n# Ordinal code execution\n# ...\nLet’s examine how this works. At its core, byebug maintains two important lists — one for storing breakpoints set by the user throughout the debugging session, and another for tracepoints. TracePoint is a instrumentation technology in Ruby that works by intercepting specific runtime events such as method calls, line executions, or exception raises and executing custom code when these events occur. Take a look at our previous blog post for more details.\nbyebug has one TracePoint for each type of event it tracks — one for line events, one for call events, and so on. Each TracePoint in the list follows a similar pattern. When a trace event occurs at runtime, the corresponding TracePoint is triggered, and byebug checks whether there’s a breakpoint set at that location by comparing file paths and line numbers. If a breakpoint is found, byebug pauses program execution and hands control to the developer, who can then inspect variables, step through code, evaluate expressions, or perform other debugger actions. If no breakpoint is found, execution simply continues until the next trace event, where the same process is repeated. This is how byebug detects breakpoints and stops at them during runtime.\nIt is a simple yet effective approach that works well and allows developers to debug their code. However, it comes with one major drawback — performance.\nWith each event emitted during program execution, byebug has to perform breakpoint checks — even when there’s only a single breakpoint set in the entire application. This means that if you place just one breakpoint somewhere in your code, the debugger will still check for breakpoint matches on every single trace event. It’s like having a security guard check every room in a building when you only need to monitor one specific door.\nConsequently, these constant checks add significant computational overhead when running code with byebug. Our performance tests show that applications can run more than 20 times slower under byebug compared to normal execution. This performance impact makes byebug challenging to use with complex real-world Rails applications, where execution time really matters. Fortunately, more modern debugging solutions have found ways to address this limitation.\nPerformant debug gem and TracePoint improvement\nOur next tool is the debug gem — a debugger designed for modern Ruby versions starting from 2.7. It provides CLI by default, but you can also set it up with a plugin to get GUI in code editors.\nJust like byebug, the debug gem requires you to modify your code by adding binding.break statements to start a debugging session. Alternatively, you can run it manually from the terminal, which may require some additional project configuration, especially in Rails applications.\nThe debug gem completely solves the significant performance limitation described in the previous section. Before we start with the debug gem, let’s take a look at the main feature that helped to overcome the performance problem.\nThe magic behind the strong performance of the debug gem is related to the TracePoint update that was released in Ruby 2.6 back in 2018.\nThis improvement added a key feature — TracePoints could now be targeted to specific lines of code or specific instruction sequences. No more checking for breakpoints on every event. Instead, TracePoints would only trigger exactly where breakpoints were set, solving the performance problem.\nLet’s look at a practical example of how this feature works.\ndef say_hello = puts \"Hello Ruby developers!\"\ndef say_goodbye = puts \"Goodbye Ruby developers!\"\n\n\niseq = RubyVM::InstructionSequence.of(method(:say_hello))\ntrace = TracePoint.new(:call) do |tp|\n puts \"Calling method '#{tp.method_id}'\"\nend\n\n\ntrace.enable(target: iseq)\n\n\nsay_hello\nsay_goodbye\n# => Calling method 'say_hello'\n# => Hello Ruby developers!\n# => Goodbye Ruby developers!\nHere we have two methods — say_hello and say_goodbye. The key change is that we’re targeting our TracePoint specifically to the instruction sequence of the first method only.\nLooking at the output in the comments, we can see how powerful and precise targeted TracePoints are. The TracePoint is triggered only for say_hello but is completely ignored for say_goodbye — exactly what we needed. This level of control is a major improvement over the old approach where TracePoints would fire for every method indiscriminately.\nThis example demonstrates a simplified version of how the debug gem uses TracePoint under the hood. Unlike byebug, which maintains a general-purpose list of TracePoints and checks every single trace event against all breakpoints, the debug gem takes a more efficient and targeted approach. It creates a dedicated TracePoint for each individual breakpoint and binds it directly to the corresponding location in the code — either a specific line or an instruction sequence.\nThis means the TracePoint will only trigger when that exact location is executed, eliminating the need for constant runtime checks across unrelated code paths. As a result, the debug gem introduces significantly less overhead and performs much better in practice. This difference becomes especially noticeable in large Ruby codebases or performance-sensitive environments, where byebug’s frequent event scanning can lead to substantial slowdowns.\nDespite its significant advantages, this TracePoint improvement wasn’t backported to Ruby versions before 2.6. As a result, the debug gem only supports Ruby 2.7 and newer versions where additional fixes for the TracePoint improvement were released. This circumstance leaves projects running on older Ruby versions without access to this powerful debugging tool, even though they might still need advanced debugging capabilities for investigating complex issues.\nStarting with Ruby 3.1, the debug gem is bundled as the default debugger. It’s an excellent starting point for many Ruby developers — especially those who haven’t yet explored more advanced tools like the RubyMine debugger to meet their growing need for a better debugging experience and more powerful capabilities.\nHow is the RubyMine debugger structured?\nAs we’ve seen, both popular open-source Ruby debuggers have their limitations. Byebug suffers from performance issues that make it impractical for large applications, while the debug gem doesn’t support Ruby versions before 2.7. This can be frustrating for professional developers who need reliable debugging capabilities across different Ruby versions. The RubyMine debugger solves these problems by supporting Ruby versions from 2.3 onwards, covering practically any Ruby version your application might use.\nOne significant benefit that sets the RubyMine debugger apart is that it doesn’t have any performance issues and maintains excellent speed even on older Ruby versions. This feature makes the RubyMine debugger the go-to debugging tool for professional Ruby developers, regardless of their project’s specific requirements.\nAnother advantage is a straightforward debugging experience, with all features available immediately after setup. There’s no need to modify your project configuration, install and configure extra plugins, or manage terminal commands to start debugging. It works even with production size Rails applications and lets you focus on solving problems rather than setting up tools.\nIn addition, the RubyMine debugger offers smart stepping — a feature that lets you step into a specific method when there are multiple calls on the same line. Instead of always entering the first call, it highlights all available options so you can choose the one you want. It’s especially useful for debugging chained or complex expressions — a level of control that other Ruby debuggers don’t offer.\nThe RubyMine debugger provides versatile debugging capabilities and a productivity-focused debugger experience. If you haven’t tried the RubyMine debugger yet, it’s definitely worth a chance.\nLet’s take a closer look at the architecture of the RubyMine debugger and how it’s built to be such a powerful tool.\nGeneral RubyMine debugger architecture\nThis is a high-level architecture of the RubyMine debugger.\n\nLet’s examine the diagram to understand how the RubyMine debugger works internally. The architecture consists of three main parts that work together to provide a smooth debugging experience.\nThe first component is the debase gem — the core backend of the RubyMine debugger. Written as a C extension, it handles all low-level operations like retrieving execution contexts, managing stack frames, and manipulating instruction sequences. This backend is responsible for direct interaction with Ruby internals, which makes it a convenient and efficient interface for other debugger components.\nThe second part is the ruby-debug-ide gem, which serves as the internal debugger frontend. This critical piece manages the communication between RubyMine and the backend by establishing and maintaining their connection. It handles the message protocol and processes commands coming from RubyMine. Additionally, it’s responsible for creating readable text representations of Ruby objects that developers will see in the RubyMine debugger Tool Window.\nFinally, there’s RubyMine itself. Its primary role is to provide a smooth and productive debugging experience. Most of the debugger features that enhance developer productivity — like smart stepping, inline-debugger values, and frames and breakpoints management — are mainly implemented at this level. The IDE also handles communication with the debugger frontend by sending commands and processing responses. \nHaving three separate parts with clear interfaces between them brings several key benefits. This modular structure significantly reduces the overall system complexity, making it easier to maintain and less prone to bugs. Each component can be developed independently and at its own pace, which streamlines development and makes maintenance more efficient.\nThe real RubyMine debugger architecture\nThe architecture we’ve discussed is a simplified view of the RubyMine debugger. While it helps you understand the core concepts, the real-world implementation has additional layers of complexity. Let’s dive deeper and explore how the actual system is structured.\n\nInstead of a single branch of debugger gems, there are two separate branches of debugger gems — a top branch and a bottom branch — each specified for different Ruby versions.\nThe top branch supports Ruby versions 2.3 through 2.7. These gems use several clever low-level hacks to achieve high performance without the TracePoint improvements we discussed earlier. While these hacks work effectively, they make the gems harder to maintain and extend. Still, this approach ensures excellent debugging capabilities for legacy Ruby applications.\nThe challenges of maintaining and extending the top branch gems led to the creation of the bottom branch of gems. This branch is designed specifically for modern Ruby and ensures a smooth debugging experience with Ruby versions 3.0 and onwards. Unlike the top branch, these gems don’t rely on low-level hacks. Instead, they leverage modern Ruby APIs and the improved TracePoint mechanism, resulting in a cleaner and more maintainable codebase. This approach not only simplifies the implementation but also makes it easier to add new features and support new Ruby versions.\nHaving two separate branches for different Ruby versions helps us keep the RubyMine debugger maintainable and performant. It lets us support legacy versions while steadily raising the quality bar and reliability of the debugging experience for modern Ruby.\nWhich debugger is the most performant?\nBefore we dive into performance, let’s quickly recap what we’ve covered so far. We began with an in-depth look at how the byebug debugger works internally and where it falls short. Then, we examined how the debug gem takes a different approach to overcome those limitations. Finally, we explored the architecture of the RubyMine Debugger and the advantages it brings to the table.\nNow, it’s time to ask the big practical question: which of these debuggers performs best?\nRather than guess, let’s put these debuggers to the test with a straightforward benchmarking experiment.\ndef fib(n)\n raise if n < 0 # place a breakpoint on this line\n return n if n < 2\n fib(n - 1) + fib(n - 2)\nend\n\n\nrequire 'benchmark'\nTOTAL_RUNS = 100\ntotal_time = TOTAL_RUNS.times.sum do\n Benchmark.realtime { fib(40) }\nend\n\n\nputs \"Avg real time elapsed: #{total_time/TOTAL_RUNS}\"\nWe use the Fibonacci method with an added condition specifically to set a breakpoint. Although the breakpoint is never hit, it allows us to measure how simply having a breakpoint in place can impact the performance of each debugger. To run the experiment, we used the benchmark gem and averaged the execution time over 100 runs to get stable, meaningful results.\nLet’s state the Ruby debugger and Ruby versions for that experiment to get reproducible results.\n\nRuby 2.6.10Ruby 3.4.2\nbyebug – 11.1.3debug gem – 1.10.0\nRubyMine debugger\n    • ruby-debug-ide – 2.3.24\n    • debase – 2.3.15 RubyMine debugger\n    • ruby-debug-ide – 3.0.2\n    • debase – 3.0.2\n\n\n\n\n\nFor this experiment, we’ll use the latest available versions of Ruby and debugger gems at the time of writing. We define two test groups based on Ruby versions they support. One for Ruby 2.6.10, representing older versions, and one for Ruby 3.4.2, representing modern versions. The Ruby 2.6.10 group includes byebug. The Ruby 3.4.2 group features the debug gem. The RubyMine debugger is included in both groups, but it uses different gem versions optimized for the respective Ruby version.\nLet’s run the benchmark and see how each debugger performs.\n\nRuby 2.6.10Ruby 3.4.2\nOriginal run17.7 sec15.8 sec\nbyebug529.1 sec✕\ndebug gem✕15.8 sec\nRubyMine debugger17.7 sec15.8 sec\n\n\n\n\n\nLet’s first examine the results for the older Ruby version. The most striking observation is the performance of byebug. The benchmark shows it runs about 30 times slower than the original code without any debugger attached — a significant performance hit that makes it impractical for debugging complex applications.\nOn the other hand, the RubyMine debugger shows no noticeable performance impact on older Ruby versions. This means that for applications running on older Ruby versions, particularly production applications, the RubyMine debugger stands out as the only practical option for effective debugging. While having limited choices isn’t ideal, this is the reality when working with older Ruby versions.\nLooking at a modern Ruby version group, the situation is much better. Both the RubyMine debugger and debug gem show excellent performance with no noticeable slowdown. This gives developers the freedom to choose either tool based on their specific needs and preferences. The availability of multiple performant debuggers empowers Ruby developers to choose the best tool for their situation and makes the Ruby debugging ecosystem stronger.\nOverall, the RubyMine debugger delivers consistently high performance across both old and new Ruby versions, while byebug significantly slows down execution and is impractical for complex applications. On newer Ruby versions, the debug gem matches RubyMine in speed, giving developers an open-source alternative.\nConclusion\nDebugging is a practical skill for every Ruby developer, and understanding the inner workings of Ruby debuggers can help you recognize each debugger’s limitations, choose the right tool for your needs, and avoid common pitfalls. In this post, we’ve examined the internal mechanics of Ruby debuggers like byebug, the debug gem, and the RubyMine debugger, highlighting the advantages and downsides of their approaches.\nByebug and the debug gem both offer basic debugging features like breakpoints, stepping, and variable inspection. The debug gem delivers significantly better performance than byebug, but it only supports Ruby versions 2.7 and newer. Byebug, on the other hand, works with older Ruby versions but tends to be much slower — especially in larger projects.\nThe RubyMine debugger stands out by combining the best of both worlds. It supports a wide range of Ruby versions, delivers strong performance across all of them, and offers a smooth, reliable debugging experience — even in complex Rails applications. On top of the basic features, RubyMine includes advanced capabilities like smart stepping, inline variable values, and more. You can explore the full set of features in the RubyMine debugging documentation.\nWe hope this post has helped clarify how Ruby debuggers work internally and provided useful insights for improving your debugging workflow.\nHappy coding, and may your bugs be rare and simple to squash!\nThe RubyMine team",
        "dc:creator": "Dmitry Pogrebnoy",
        "content": "Hello, Ruby developers! Whether you are a seasoned Ruby developer or just getting started, mastering the debugger will save you time and frustration when tracking down bugs. At RubyMine, we’ve spent years building debugging tools for Ruby. In this blog series, we’re sharing some of the insights we’ve gained along the way. In this post, [&#8230;]",
        "contentSnippet": "Hello, Ruby developers! Whether you are a seasoned Ruby developer or just getting started, mastering the debugger will save you time and frustration when tracking down bugs. At RubyMine, we’ve spent years building debugging tools for Ruby. In this blog series, we’re sharing some of the insights we’ve gained along the way. In this post, […]",
        "guid": "https://blog.jetbrains.com/?post_type=ruby&p=594034",
        "categories": [
          "rubymine"
        ],
        "isoDate": "2025-08-26T07:11:53.000Z"
      },
      {
        "creator": "Ekaterina Petrova",
        "title": "What’s Next for Kotlin Multiplatform and Compose Multiplatform – August 2025 Update",
        "link": "https://blog.jetbrains.com/kotlin/2025/08/kmp-roadmap-aug-2025/",
        "pubDate": "Mon, 25 Aug 2025 18:47:41 +0000",
        "content:encodedSnippet": "This post outlines our priorities and the general direction for our Kotlin Multiplatform and Compose Multiplatform projects over the next six to twelve months. Our goals for Kotlin Multiplatform are closely aligned with those detailed in the Kotlin roadmap. Be sure to check it out for more context around the direction we’re heading.\nKey priorities\nKotlin Multiplatform spans many areas, from language features and target-specific compilation to our IDE plugin. It’s a lot to track, so here are the three key priorities that guide our work:\n\n\n\n\n\nMake the iOS target a pleasure to work with\nWhile the iOS target matures, the developer experience still has room for improvement. Build speed remains a common Kotlin/Native concern, so we’re addressing it by fixing key issues to speed up builds across project types. We’ll also continue developing the experimental Swift Export feature to provide a better experience when calling Kotlin code from Swift.\n\n\n\n\nEnable more use cases for the web targets\nKotlin/JS already powers robust web apps, and Kotlin/Wasm is on track to be able to do the same soon. By promoting Compose for Web and Kotlin/Wasm to Beta, we expect to see pioneers starting to ship small- to medium-sized apps to production. We’re also enhancing JavaScript export to improve business logic sharing across platforms.\n\n\n\n\nImprove the developer experience in the IDE\nFollowing the first release of the Kotlin Multiplatform plugin earlier this year, we’re working to expand support with Windows and Linux versions, improved Swift integration, and essential web tooling. Our goal is to make IntelliJ IDEA and Android Studio exceptional environments for multiplatform development.\nCompose Multiplatform\nRelease Compose Multiplatform for Web in Beta\nThis Beta version embodies our commitment to support and evolve the existing APIs of Compose Multiplatform for Web. Most essential APIs will be available, enabling early adopters to confidently move to production with the existing feature set. After this Beta release, we will keep working on the remaining Compose APIs and further performance improvements. We heavily depend on your feedback, so please reach out on the Kotlinlang slack or report any issues on YouTrack.\nMake more ecosystem components available for Compose Multiplatform\nGoogle has developed excellent Jetpack libraries, which are already available for Android. We’re collaborating closely with Google to make more Jetpack libraries, such as Navigation 3 and Paging 3, available for Compose Multiplatform.\nImplement new text input on iOS \nThis new text input implementation provides a more native appearance and behavior. Additionally, it encompasses features like selection, magnification, integration with writing tools and text toolbar actions such as AutoFill and Passwords.\nCommonize Compose @Preview annotations\nOur goal is to simplify the use of @Preview annotations. Currently, there are three distinct @Preview annotations across different packages, making it challenging to determine the correct combination of annotation, platform, and IDE. \nKotlin Multiplatform IDE plugin\nSupport for Windows and Linux in the Kotlin Multiplatform IDE plugin\nWe’ve heard your requests and will be releasing the Kotlin Multiplatform plugin for Windows and Linux as well. On these platforms, you’ll be able to create KMP projects with the wizard, rely on preflight checks, use Compose Hot Reload and easily run apps for Android, web, desktop, and server. Due to Apple tooling restrictions, Swift support and iOS run configs won’t be available.\nImprove the Swift development experience with the Kotlin Multiplatform IDE plugin\nWe’re targeting several key improvements for Swift development:\nThe generated Kotlin code for Apple frameworks will be extended with documentation.\nThe quick documentation (QuickDoc) feature will be improved to consistently display documentation for Swift or Objective-C libraries imported through cinterop. \nSupport for Swift 6.2 and Xcode 26 will be added.\nWe’ll improve more advanced features like renaming, cross-navigation, and finding usages across languages. \nGeneral and quality improvements\nWe’re improving the KMP project wizard to better support both application and library developers.\nIntegrate web target workflows, including the JavaScript debugger, run configurations, and more options in the KMP project wizard.\nFor Compose Previews, we’re investing in better error reporting, automatic inspections, and analytics to improve reliability.\nUpgrading dependencies shouldn’t be a guessing game. We plan to introduce and maintain a compatibility matrix to clarify which IDE, Gradle plugin, and library versions work well together.\nKotlin/Native\nReducing Kotlin/Native build times \nTo reduce Kotlin/Native build times, we’re working on multiple areas:\nWe’re extending our performance analysis of all compilation phases across real-world projects, helping us identify and prevent regressions. \nWe’re optimizing the compiler internals, focusing specifically on build speed. \nLastly, we will replace the frequently misused kotlin.native.cacheKind property with a safer alternative to avoid unintentional build slowdowns.\nContinued development of Swift Export\nIn the short term, our goal for Swift Export is to match the capabilities you already have with Objective-C export. In addition, we plan to add built-in support for suspend functions and Flow in Swift Export, supporting concurrency on Apple platforms. In 2026, we aim for a stable release covering most features essential for idiomatic interoperability between Swift and Kotlin.\nKotlin/JS\nFallback to Kotlin/JS for Compose for Web\nAs part of the Compose for Web Beta, we will be introducing a compatibility mode using Kotlin/JS as a fallback. This broadens browser support for Compose for Web, which defaults to Kotlin/Wasm for performance. The fallback allows apps to run on older browsers that don’t support modern Wasm features like garbage collection or exception handling.\nExtending the capabilities of JavaScript Export\nWe’re improving how Kotlin declarations are exported to and consumed from JavaScript:\nExporting suspend functions (KT-56281)\nExporting value classes (KT-72198)\nExporting typealiases (KT-49795)\nAdding documentation to generated .d.ts files (KT-56493)\nAllowing Kotlin interfaces to be implemented from TypeScript\nKotlin/Wasm\nBeta release of the Kotlin/Wasm target\nTo promote Kotlin/Wasm to Beta, we aim to:\nImplement numerous compiler fixes focused on semantics and the developer experience\nReview and improve the quality of the standard library for Wasm\nAdd experimental annotations to interop APIs\nIntroduce toolchain improvements:\n\nProject sources will be served by default during development\nToolchain npm dependencies will be isolated from project dependencies\nSupport for multi-module compilation\nWe’re adding multi-module compilation support in Kotlin/Wasm to enable dynamic loading, plugin systems, and better build performance. This allows applications to load UI components on demand and benefit from improved caching and parallelization at build time.\nBuild tooling\nMaking Gradle build configurations more beginner friendly\nGradle is powerful but often overwhelming. To make KMP easier for beginners, we’ll allow dependencies to be declared at the project level and automatically propagate to all source sets, like in JVM and Android projects. We’re also working on a prototype for a new declarative Kotlin-based Gradle DSL via an ecosystem plugin to simplify build scripts and improve IDE support.\nReducing the effort to publish KMP libraries\nWe’re stabilizing klib cross-compilation across platforms, enabling you to build your library on continuous integration platforms without requiring macOS machines. We’re also simplifying the dependencies model and layout by removing unused features like partial downloads and multi-host publishing. Together, these changes will make multiplatform libraries easier to publish, consume, and integrate with third-party tools.\nProviding a Build tools API\nWe’re developing the Kotlin Build tools API as a unified entry point for build systems to integrate with Kotlin. This will reduce duplicated work, align feature behavior across tools, and make adding new build systems like Bazel or Buck much easier. \nFaster builds and imports with Gradle\nWe’re adding support for Gradle’s experimental Isolated Projects mode enabling parallel configuration for faster builds on large projects. We’re also aware of imports being rather slow and resource heavy. We will refine our benchmarks and fix bottlenecks, which should result in a smoother development experience.\nDocumentation and onboarding\nLearning a new technology can be challenging, but good guidance makes the path easier. Our current documentation focuses on beginners and basic scenarios, so we’ll expand it to cover real-world migrations of existing Android apps to Kotlin and Compose Multiplatform. With Klibs.io, we’re also making it easier to find the right libraries, which we’ll continue to develop and integrate into our guidance.",
        "dc:creator": "Ekaterina Petrova",
        "content": "This post outlines our priorities and the general direction for our Kotlin Multiplatform and Compose Multiplatform projects over the next six to twelve months. Our goals for Kotlin Multiplatform are closely aligned with those detailed in the Kotlin roadmap. Be sure to check it out for more context around the direction we&#8217;re heading. Key priorities [&#8230;]",
        "contentSnippet": "This post outlines our priorities and the general direction for our Kotlin Multiplatform and Compose Multiplatform projects over the next six to twelve months. Our goals for Kotlin Multiplatform are closely aligned with those detailed in the Kotlin roadmap. Be sure to check it out for more context around the direction we’re heading. Key priorities […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=593433",
        "categories": [
          "multiplatform",
          "kotlin-multiplatform"
        ],
        "isoDate": "2025-08-25T18:47:41.000Z"
      },
      {
        "creator": "Cheuk Ting Ho",
        "title": "Fine-Tuning and Deploying GPT Models Using Hugging Face Transformers",
        "link": "https://blog.jetbrains.com/pycharm/2025/08/fine-tuning-and-deploying-gpt-models-using-hugging-face-transformers/",
        "pubDate": "Mon, 25 Aug 2025 11:01:26 +0000",
        "content:encodedSnippet": "Hugging Face is currently a household name for machine learning researchers and enthusiasts. One of their biggest successes is Transformers, a model-definition framework for machine learning models in text, computer vision, audio, and video. Because of the vast repository of state-of-the-art machine learning models available on the Hugging Face Hub and the compatibility of Transformers with the majority of training frameworks, it is widely used for inference and model training.\nWhy do we want to fine-tune an AI model?\nFine-tuning AI models is crucial for tailoring their performance to specific tasks and datasets, enabling them to achieve higher accuracy and efficiency compared to using a general-purpose model. By adapting a pre-trained model, fine-tuning reduces the need for training from scratch, saving time and resources. It also allows for better handling of specific formats, nuances, and edge cases within a particular domain, leading to more reliable and tailored outputs.\nIn this blog post, we will fine-tune a GPT model with mathematical reasoning so it better handles math questions.\nUsing models from Hugging Face\nWhen using PyCharm, we can easily browse and add any models from Hugging Face. In a new Python file, from the Code menu at the top, select Insert HF Model.\n\n\n\n\nIn the menu that opens, you can browse models by category or start typing in the search bar at the top. When you select a model, you can see its description on the right.\n\n\n\n\nWhen you click Use Model, you will see a code snippet added to your file. And that’s it – You’re ready to start using your Hugging Face model.\n\n\n\n\nGPT (Generative Pre-Trained Transformer) models\nGPT models are very popular on the Hugging Face Hub, but what are they? GPTs are trained models that understand natural language and generate high-quality text. They are mainly used in tasks related to textual entailment, question answering, semantic similarity, and document classification. The most famous example is ChatGPT, created by OpenAI.\nA lot of OpenAI GPT models are available on the Hugging Face Hub, and we will learn how to use these models with Transformers, fine-tune them with our own data, and deploy them in an application.\nBenefits of using Transformers\nTransformers, together with other tools provided by Hugging Face, provides high-level tools for fine-tuning any sophisticated deep learning model. Instead of requiring you to fully understand a given model’s architecture and tokenization method, these tools help make models “plug and play” with any compatible training data, while also providing a large amount of customization in tokenization and training.\nTransformers in action\nTo get a closer look at Transformers in action, let’s see how we can use it to interact with a GPT model.\nInference using a pretrained model with a pipeline\nAfter selecting and adding the OpenAI GPT-2 model to the code, this is what we’ve got:\nfrom transformers import pipeline\n\n\npipe = pipeline(\"text-generation\", model=\"openai-community/gpt2\")\nBefore we can use it, we need to make a few preparations. First, we need to install a machine learning framework. In this example, we chose PyTorch. You can install it easily via the Python Packages window in PyCharm.\n\n\n\n\nThen we need to install Transformers using the `torch` option. You can do that by using the terminal – open it using the button on the left or use the ⌥ F12 (MacOS) or Alt + F12 (Windows) hotkey.\n\n\n\n\nIn the terminal, since we are using uv, we use the following commands to add it as a dependency and install it:\nuv add “transformers[torch]”\nuv sync\nIf you are using pip:\npip install “transformers[torch]”\nWe will also install a couple more libraries that we will need later, including python-dotenv, datasets, notebook, and ipywidgets. You can use either of the methods above to install them.\nAfter that, it may be best to add a GPU device to speed up the model. Depending on what you have on your machine, you can add it by setting the device parameter in pipeline. Since I am using a Mac M2 machine, I can set device=\"mps\" like this:\npipe = pipeline(\"text-generation\", model=\"openai-community/gpt2\", device=\"mps\")\nIf you have CUDA GPUs you can also set device=\"cuda\".\nNow that we’ve set up our pipeline, let’s try it out with a simple prompt:\nfrom transformers import pipeline\n\n\npipe = pipeline(\"text-generation\", model=\"openai-community/gpt2\", device=\"mps\")\n\n\nprint(pipe(\"A rectangle has a perimeter of 20 cm. If the length is 6 cm, what is the width?\", max_new_tokens=200))\nRun the script with the Run button () at the top:\n\n\n\n\nThe result will look something like this:\n[{'generated_text': 'A rectangle has a perimeter of 20 cm. If the length is 6 cm, what is the width?\\n\\nA rectangle has a perimeter of 20 cm. If the length is 6 cm, what is the width? A rectangle has a perimeter of 20 cm. If the width is 6 cm, what is the width? A rectangle has a perimeter of 20 cm. If the width is 6 cm, what is the width? A rectangle has a perimeter of 20 cm. If the width is 6 cm, what is the width?\\n\\nA rectangle has a perimeter of 20 cm. If the width is 6 cm, what is the width? A rectangle has a perimeter of 20 cm. If the width is 6 cm, what is the width? A rectangle has a perimeter of 20 cm. If the width is 6 cm, what is the width? A rectangle has a perimeter of 20 cm. If the width is 6 cm, what is the width?\\n\\nA rectangle has a perimeter of 20 cm. If the width is 6 cm, what is the width? A rectangle has a perimeter'}]\nThere isn’t much reasoning in this at all, only a bunch of nonsense. \nYou may also see this warning:\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThis is the default setting.You can also manually add it as below, so this warning disappears, but we don’t have to worry about it too much at this stage.\nprint(pipe(\"A rectangle has a perimeter of 20 cm. If the length is 6 cm, what is the width?\", max_new_tokens=200, pad_token_id=pipe.tokenizer.eos_token_id))\nNow that we’ve seen how GPT-2 behaves out of the box, let’s see if we can make it better at math reasoning with some fine-tuning.\nLoad and prepare a dataset from the Hugging Face Hub\nBefore we work on the GPT model, we first need training data. Let’s see how to get a dataset from the Hugging Face Hub.\nIf you haven’t already, sign up for a Hugging Face account and create an access token. We only need a `read` token for now. Store your token in a `.env` file, like so:\nHF_TOKEN=your-hugging-face-access-token\nWe will use this Math Reasoning Dataset, which has text describing some math reasoning. We will fine-tune our GPT model with this dataset so it can solve math problems more effectively.\nLet’s create a new Jupyter notebook, which we’ll use for fine-tuning because it lets us run different code snippets one by one and monitor the progress.\nIn the first cell, we use this script to load the dataset from the Hugging Face Hub:\nfrom datasets import load_dataset\nfrom dotenv import load_dotenv\nimport os\n\n\nload_dotenv()\ndataset = load_dataset(\"Cheukting/math-meta-reasoning-cleaned\", token=os.getenv(\"HF_TOKEN\"))\ndataset\nRun this cell (it may take a while, depending on your internet speed), which will download the dataset. When it’s done, we can have a look at the result:\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'text', 'token_count'],\n        num_rows: 987485\n    })\n})\n\n\n\n\nIf you are curious and want to have a peek at the data, you can do so in PyCharm. Open the Jupyter Variables window using the button on the right:\n\n\n\n\nExpand dataset and you will see the View as DataFrame option next to dataset[‘train’]:\n\n\n\n\nClick on it to take a look at the data in the Data View tool window:\n\n\n\n\nNext, we will tokenize the text in the dataset:\nfrom transformers import GPT2Tokenizer\n\n\ntokenizer = GPT2Tokenizer.from_pretrained(\"openai-community/gpt2\")\ntokenizer.pad_token = tokenizer.eos_token\n\n\ndef tokenize_function(examples):\n   return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=512)\n\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\nHere we use the GPT-2 tokenizer and set the pad_token to be the eos_token, which is the token indicating the end of line. After that, we will tokenize the text with a function. It may take a while the first time you run it, but after that it will be cached and will be faster if you have to run the cell again.\nThe dataset has almost 1 million rows for training. If you have enough computing power to process all of them, you can use them all. However, in this demonstration we’re training locally on a laptop, so I’d better only use a small portion!\ntokenized_datasets_split = tokenized_datasets[\"train\"].shard(num_shards=100, index=0).train_test_split(test_size=0.2, shuffle=True)\ntokenized_datasets_split\nHere I take only 1% of the data, and then perform train_test_split to split the dataset into two:\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'text', 'token_count', 'input_ids', 'attention_mask'],\n        num_rows: 7900\n    })\n    test: Dataset({\n        features: ['id', 'text', 'token_count', 'input_ids', 'attention_mask'],\n        num_rows: 1975\n    })\n})\n\n\n\n\nNow we are ready to fine-tune the GPT-2 model.\nFine-tune a GPT model\nIn the next empty cell, we will set our training arguments:\nfrom transformers import TrainingArguments\ntraining_args = TrainingArguments(\n   output_dir='./results',\n   num_train_epochs=5,\n   per_device_train_batch_size=8,\n   per_device_eval_batch_size=8,\n   warmup_steps=100,\n   weight_decay=0.01,\n   save_steps = 500,\n   logging_steps=100,\n   dataloader_pin_memory=False\n)\nMost of them are pretty standard for fine-tuning a model. However, depending on your computer setup, you may want to tweak a few things:\nBatch size – Finding the optimal batch size is important, since the larger the batch size is, the faster the training goes. However, there is a limit to how much memory is available for your CPU or GPU, so you may find there’s an upper threshold.\nEpochs – Having more epochs causes the training to take longer. You can decide how many epochs you need.\nSave steps – Save steps determine how often a checkpoint will be saved to disk. If the training is slow and there is a chance that it will stop unexpectedly, then you may want to save more often ( set this value lower).\n After we’ve configured our settings, we will put the trainer together in the next cell:\nfrom transformers import Trainer, DataCollatorForLanguageModeling\n\n\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n\n\ntrainer = Trainer(\n   model=model,\n   args=training_args,\n   train_dataset=tokenized_datasets_split['train'],\n   eval_dataset=tokenized_datasets_split['test'],\n   data_collator=data_collator,\n)\n\n\ntrainer.train(resume_from_checkpoint=False)\nWe set `resume_from_checkpoint=False`, but you can set it to `True` to continue from the last checkpoint if the training is interrupted.\nAfter the training finishes, we will evaluate and save the model:\ntrainer.evaluate(tokenized_datasets_split['test'])\ntrainer.save_model(\"./trained_model\")\nWe can now use the trained model in the pipeline. Let’s switch back to `model.py`, where we have used a pipeline with a pretrained model:\nfrom transformers import pipeline\n\n\npipe = pipeline(\"text-generation\", model=\"openai-community/gpt2\", device=\"mps\")\n\n\nprint(pipe(\"A rectangle has a perimeter of 20 cm. If the length is 6 cm, what is the width?\", max_new_tokens=200, pad_token_id=pipe.tokenizer.eos_token_id))\nNow let’s change `model=”openai-community/gpt2″` to `model=”./trained_model”` and see what we get:\n[{'generated_text': \"A rectangle has a perimeter of 20 cm. If the length is 6 cm, what is the width?\\nAlright, let me try to solve this problem as a student, and I'll let my thinking naturally fall into the common pitfall as described.\\n\\n---\\n\\n**Step 1: Attempting the Problem (falling into the pitfall)**\\n\\nWe have a rectangle with perimeter 20 cm. The length is 6 cm. We want the width.\\n\\nFirst, I need to find the area under the rectangle.\\n\\nLet’s set \\\\( A = 20 - 12 \\\\), where \\\\( A \\\\) is the perimeter.\\n\\n**Area under a rectangle:**  \\n\\\\[\\nA = (20-12)^2 + ((-12)^2)^2 = 20^2 + 12^2 = 24\\n\\\\]\\n\\nSo, \\\\( 24 = (20-12)^2 = 27 \\\\).\\n\\nNow, I’ll just divide both sides by 6 to find the area under the rectangle.\\n\"}]\nUnfortunately, it still does not solve the problem. However, it did come up with some mathematical formulas and reasoning that it didn’t use before. If you want, you can try fine-tuning the model a bit more with the data we didn’t use.\nIn the next section, we will see how we can deploy a fine-tuned model to API endpoints using both the tools provided by Hugging Face and FastAPI.\nDeploying a fine-tuned model\nThe easiest way to deploy a model in a server backend is to use FastAPI. Previously, I wrote a blog post about deploying a machine learning model with Fast API. While we won’t go into the same level of detail here, we will go over how to deploy our fine-tuned model.\nWith the help of Junie, we’ve created some scripts which you can see here. These scripts let us deploy a server backend with FastAPI endpoints. \nThere are some new dependencies that we need to add:\nuv add fastapi pydantic uvicorn\nuv sync\nLet’s have a look at some interesting points in the scripts, in `main.py`:\n# Initialize FastAPI app\napp = FastAPI(\n   title=\"Text Generation API\",\n   description=\"API for generating text using a fine-tuned model\",\n   version=\"1.0.0\"\n)\n\n\n# Initialize the model pipeline\ntry:\n   pipe = pipeline(\"text-generation\", model=\"../trained_model\", device=\"mps\")\nexcept Exception as e:\n   # Fallback to CPU if MPS is not available\n   try:\n       pipe = pipeline(\"text-generation\", model=\"../trained_model\", device=\"cpu\")\n   except Exception as e:\n       print(f\"Error loading model: {e}\")\n       pipe = None\nAfter initializing the app, the script will try to load the model into a pipeline. If a Metal GPU is not available, it will fall back to using the CPU. If you have a CUDA GPU instead of a Metal GPU, you can change `mps` to `cuda`.\n# Request model\nclass TextGenerationRequest(BaseModel):\n   prompt: str\n   max_new_tokens: int = 200\n  \n# Response model\nclass TextGenerationResponse(BaseModel):\n   generated_text: str\nTwo new classes are created, inheriting from Pydantic’s `BaseModel`.\nWe can also inspect our endpoints with the Endpoints tool window. Click on the globe next to `app = FastAPI` on line 11 and select Show All Endpoints.\n\n\n\n\nWe have three endpoints. Since the root endpoint is just a welcome message, we will look at the other two.\n@app.post(\"/generate\", response_model=TextGenerationResponse)\nasync def generate_text(request: TextGenerationRequest):\n   \"\"\"\n   Generate text based on the provided prompt.\n  \n   Args:\n       request: TextGenerationRequest containing the prompt and generation parameters\n      \n   Returns:\n       TextGenerationResponse with the generated text\n   \"\"\"\n   if pipe is None:\n       raise HTTPException(status_code=500, detail=\"Model not loaded properly\")\n  \n   try:\n       result = pipe(\n           request.prompt,\n           max_new_tokens=request.max_new_tokens,\n           pad_token_id=pipe.tokenizer.eos_token_id\n       )\n      \n       # Extract the generated text from the result\n       generated_text = result[0]['generated_text']\n      \n       return TextGenerationResponse(generated_text=generated_text)\n   except Exception as e:\n       raise HTTPException(status_code=500, detail=f\"Error generating text: {str(e)}\")\n\n\n\n\nThe `/generate` endpoint collects the request prompt and generates the response text with the model.\n@app.get(\"/health\")\nasync def health_check():\n   \"\"\"Check if the API and model are working properly.\"\"\"\n   if pipe is None:\n       raise HTTPException(status_code=500, detail=\"Model not loaded\")\n   return {\"status\": \"healthy\", \"model_loaded\": True}\nThe `/health` endpoint checks whether the model is loaded correctly. This can be useful if the client-side application needs to check before making the other endpoint available in its UI.\nIn `run.py`, we use uvicorn to run the server:\nimport uvicorn\n\n\nif __name__ == \"__main__\":\n   uvicorn.run(\"main:app\", host=\"0.0.0.0\", port=8000, reload=True)\nWhen we run this script, the server will be started at http://0.0.0.0:8000/.\nAfter we start running the server, we can go to http://0.0.0.0:8000/docs to test out the endpoints. \n\nWe can try this with the `/generate` endpoint:\n{\n  \"prompt\": \"5 people give each other a present. How many presents are given altogether?\",\n  \"max_new_tokens\": 300\n}\nThis is the response we get:\n{\n  \"generated_text\": \"5 people give each other a present. How many presents are given altogether?\\nAlright, let's try to solve the problem:\\n\\n**Problem**  \\n1. Each person gives each other a present. How many presents are given altogether?\\n2. How many \\\"gift\\\" are given altogether?\\n\\n**Common pitfall**  \\nAssuming that each present is a \\\"gift\\\" without considering the implications of the original condition.\\n\\n---\\n\\n### Step 1: Attempting the problem (falling into the pitfall)\\n\\nOkay, so I have two people giving each other a present, and I want to know how many are present. I remember that there are three types of gifts—gifts, gins, and ginses.\\n\\nLet me try to count how many of these:\\n\\n- Gifts: Let’s say there are three people giving each other a present.\\n- Gins: Let’s say there are three people giving each other a present.\\n- Ginses: Let’s say there are three people giving each other a present.\\n\\nSo, total gins and ginses would be:\\n\\n- Gins: \\\\( 2 \\\\times 3 = 1 \\\\), \\\\( 2 \\\\times 1 = 2 \\\\), \\\\( 1 \\\\times 1 = 1 \\\\), \\\\( 1 \\\\times 2 = 2 \\\\), so \\\\( 2 \\\\times 3 = 4 \\\\).\\n- Ginses: \\\\( 2 \\\\times 3 = 6 \\\\), \\\\(\"\n}\n\n\n\n\n\n\n\n\nFeel free to experiment with other requests.\nConclusion and next steps\nNow that you have successfully fine-tuned an LLM model like GPT-2 with a math reasoning dataset and deployed it with FastAPI, you can fine-tune a lot more of the open-source LLMs available on the Hugging Face Hub. You can experiment with fine-tuning other LLM models with either the open-source data there or your own datasets. If you want to (and the license of the original model allows), you can also upload your fine-tuned model on the Hugging Face Hub. Check out their documentation for how to do that.\nOne last remark regarding using or fine-tuning models with resources on the Hugging Face Hub – make sure to read the licenses of any model or dataset that you use to understand the conditions for working with those resources. Is it allowed to be used commercially? Do you need to credit the resources used?\nIn future blog posts, we will keep exploring more code examples involving Python, AI, machine learning, and data visualization.\nIn my opinion, PyCharm provides best-in-class Python support that ensures both speed and accuracy. Benefit from the smartest code completion, PEP 8 compliance checks, intelligent refactorings, and a variety of inspections to meet all your coding needs. As demonstrated in this blog post, PyCharm provides integration with the Hugging Face Hub, allowing you to browse and use models without leaving the IDE. This makes it suitable for a wide range of AI and LLM fine-tuning projects.\nDownload PyCharm Now",
        "dc:creator": "Cheuk Ting Ho",
        "content": "Hugging Face is currently a household name for machine learning researchers and enthusiasts. One of their biggest successes is Transformers, a model-definition framework for machine learning models in text, computer vision, audio, and video. Because of the vast repository of state-of-the-art machine learning models available on the Hugging Face Hub and the compatibility of Transformers [&#8230;]",
        "contentSnippet": "Hugging Face is currently a household name for machine learning researchers and enthusiasts. One of their biggest successes is Transformers, a model-definition framework for machine learning models in text, computer vision, audio, and video. Because of the vast repository of state-of-the-art machine learning models available on the Hugging Face Hub and the compatibility of Transformers […]",
        "guid": "https://blog.jetbrains.com/?post_type=pycharm&p=592844",
        "categories": [
          "data-science",
          "how-tos",
          "gpt",
          "hugging-face",
          "machine-learning"
        ],
        "isoDate": "2025-08-25T11:01:26.000Z"
      },
      {
        "creator": "Alina Dolgikh",
        "title": "Kotlin on the Backend – What’s New From KotlinConf 2025",
        "link": "https://blog.jetbrains.com/kotlin/2025/08/kotlin-on-the-backend-what-s-new-from-kotlinconf-2025/",
        "pubDate": "Fri, 22 Aug 2025 15:02:47 +0000",
        "content:encodedSnippet": "KotlinConf 2025 has firmly placed server-side Kotlin in the spotlight, and rightly so. Between Spring collaboration, an upgraded ecosystem, performance boosts, AI tooling, and the adoption of the language by big companies, this is Kotlin at its (backend) best. Here’s a breakdown of what was announced, what’s new, and what you absolutely must check out from the recordings of the server-side talks at KotlinConf 2025.\nThe biggest news was traditionally covered in the keynote and followed up by talks over two days. \nOne of the revelations from the keynote that received many positive reactions was that half of Kotlin users are using the language for backend development. This isn’t a sudden shift but something we have observed over the years in the past Kotlin Census and Developer Ecosystem reports.\nCheck out why developers continue to choose Kotlin for the backend in 2025 in the teaser video linked below, in which engineers from five major tech companies share their Kotlin journeys.\n\n\n\n\n\n\nThe full stories will be published soon on the Kotlin YouTube channel. \nA Strategic Partnership With Spring\nThe JetBrains and Spring teams announced a strategic partnership. The roadmap highlights include a complete null-safety guarantee for Kotlin and Spring apps, official Kotlin‑centric Spring tutorials and documentation, enhanced reflection performance using kotlinx.reflect, and evolving configuration DSLs.\nTwo sessions provided a deeper look into the world of Kotlin and Spring and its upcoming directions for development.\nRod Johnson, Spring’s original creator, spoke on why Kotlin with Spring delivers faster development with better maintainability. Spring Framework core committer Sébastien Deleuze presented updates in Spring Boot 4 that further refine Kotlin support, from annotation processing to coroutine integration.\n\n\n\n\n\n\n\n\n\n\n\n\n\nKtor: Built for Modern Scalable Backends\nKtor continues to evolve into a powerful, modern framework for scalable applications. The recent update introduced built-in support for dependency injection with coroutine-based lifecycle management, and a new HTMX module for smoother server-driven UI development. Other notable additions include support for suspendable application modules, Unix domain sockets for the CIO engine, and a Gradle version catalog for easier dependency management. \nCurrently, the team is working on the API documentation, starting with OpenAPI support.\nFor those working with Ktor (or planning to), these talks are must-watches:\n\n\n\n\n\n\n🎥 TalkPresenterWhy It Matters\nSimplifying Full-Stack Kotlin: A Fresh Take With HTMX and KtorAnders SveenChallenge the modern full-stack complexity and see how to build dynamic web apps with Ktor, HTMX, and kotlinx.html without SPA overhead.\nCoroutines and Structured Concurrency in KtorSimon VergauwenMaster robust and maintainable asynchronous patterns in real-world Ktor services.\nEvent-Driven Analytics: Building Real-Time Dashboards With Apache Flink and KtorViktor GamovLearn how to move beyond REST by using Apache Flink and Ktor to build real-time analytics dashboards with reactive, event-driven architecture. \n\n\n\n\n\nKotlin and AI with Koog, Mellum, and Junie\nJetBrains introduced a trio of AI tools designed for Kotlin development, including practical support for server-side tasks.\nKoog – a Kotlin-based framework designed to build and run AI agents entirely in idiomatic Kotlin. \nMellum – the JetBrains’ in-house LLM, which is now open-sourced and fine-tuned for code generation and intelligent assistance.\nJunie – the JetBrains AI coding agent integrated in your favorite IDE and able to target complex Kotlin development across server, mobile, and web domains. It’s now available in GitHub as part of the Early Access Program. Join the waitlist to try it for free.\n\n🎥 TalkPresenterWhy It Matters\nBuilding AI Agents in Kotlin with Koog Vadim BriliantovAn overview of AI agents, their building blocks, workflows, and how to build them effectively in Kotlin from the JetBrains AI Agents Platform tech lead.\nKotlin’s Gam[e]bit: LLM-less AI for Board GamesDmitro KuretsDiscover how Kotlin can power AI without relying on large language models.\nFrom 0 to h-AI-ro: high-speed track to AI for Kotlin developersUrs PeterThis talk gives you a clear and practical understanding of key terminology, concepts, and frameworks relevant to the Kotlin ecosystem in the world of AI\nBuilding an Agentic Platform with Kotlin: Powering one of Europe’s Largest LLM BotPatrick WhelanA look at some of the design decisions of the Arc framework, an open-sourced Kotlin-based AI framework, which will provide you with an understanding of the challenges in building an LLM application at this scale\nLangChain4j With QuarkusMax Rydahl Andersen, Konstantin PavlovThe talk explores tools integration, dependencies management, and Kotlin’s idiomatic features, helping to simplify AI workflows.\n\n\n\n\n\nA New Milestone: Exposed 1.0\nAfter substantial restructuring, Exposed 1.0 (now in Beta) delivers on its promise of a type‑safe, expressive, and idiomatic Kotlin SQL library. \nWith added support for full R2DBC, enabling non-blocking database operations through suspending functions and flows, new SQL features, improved onboarding materials, and a new IDE plugin, it removes friction from database operations while enhancing safety and maintainability. \nChantale Loncle’s talk dives into the details of what’s new and what’s next. Check it out below.\n\n\n\n\n\n\nWin With Kotlin Notebook\nRoman Belov, the lead of Kotlin Moonshots projects, shared a fun yet practical example of Kotlin Notebook in action: finding the longest possible sailing route in 24 hours without repeating waypoints. With Kotlin Notebook, even complex logic becomes intuitive and visual. Watch the talk to learn the full story!\n\n\n\n\n\n\nhttp4k: Pure Kotlin, Protocol Agnostic\nThe talk Full Stream Ahead: Breaking Protocol Barriers With http4k showcased a fully functional, coroutine-based approach to server-side development that sidesteps servlets entirely. It emphasized composability, lightweight design, and streaming I/O with functional purity.\n\n\n\n\n\n\nOther Server-Side-Related Talks\n\n🎥 TalkPresenterWhy It Matters\nThat’s Unpossible – A Full-Stack Side Project Webapp (Including a High-Fidelity UI!) All in Kotlin\nDan KimA practical walkthrough of building a fully functional web app entirely in Kotlin, from backend to high-fidelity UI.\n\nIoT Development With KotlinErik HellmanA hands-on look at building IoT applications using Kotlin, with key technologies and integration strategies.\nTaming Asynchronous Beasts: Debugging and Performance Tuning in a Coroutine World\nMarcin MoskałaAn expert-level deep dive into coroutine debugging and performance tuning from the author of Kotlin Coroutines: Deep Dive.\n\nKotlin Multiplatform’s Cross-Platform Brilliance at Norway’s 377-Year-Old National Postal ServiceAnshika KoulA real-world case study of Posten Bring, detailing how the national postal service used Kotlin on all platforms to modernize logistics at scale.\nKotlin Clean Architecture for Serverless: Business Logic You Can Take AnywhereElena van EngelenA clean architecture approach to structuring serverless Kotlin apps, focused on portable business logic across cloud providers.\nFrom Data to Insights: Building a Bluesky Bot powered by AIRaphael De LioHow to quickly collect, process, and analyze data using Kotlin – demonstrated via a Bluesky bot that extracts insights from real-time streams.\n\n\n\n\n\nThat wraps up our curated list of backend-focused talks at KotlinConf 2025. Explore them all via the conference website or mobile app, and share your favorites with the community.\nKotlin’s Backend Momentum\nKotlinConf 2025 made it unmistakably clear: Kotlin continues to thrive in server-side development. It’s pragmatic, loved by engineers, and increasingly adopted across infrastructures and domains from Spring and Flink to Kafka and serverless platforms. Much of this progress is powered by exceptional tooling from JetBrains, including intelligent IDE support and new AI integrations. \nThat being said, the biggest engine behind Kotlin’s evolution is the community: library maintainers, open-source contributors, companies scaling Kotlin in production, and speakers sharing hard-earned lessons. Thank you all very much, we wouldn’t be where we are without you!\nIf you’re evaluating Kotlin for backend development in 2025, now’s the time to give it a serious look. And if you’re already building with Kotlin – thank you! You’re shaping the future of a language that grows stronger with every contribution.",
        "dc:creator": "Alina Dolgikh",
        "content": "KotlinConf 2025 has firmly placed server-side Kotlin in the spotlight, and rightly so. Between Spring collaboration, an upgraded ecosystem, performance boosts, AI tooling, and the adoption of the language by big companies, this is Kotlin at its (backend) best. Here&#8217;s a breakdown of what was announced, what’s new, and what you absolutely must check out [&#8230;]",
        "contentSnippet": "KotlinConf 2025 has firmly placed server-side Kotlin in the spotlight, and rightly so. Between Spring collaboration, an upgraded ecosystem, performance boosts, AI tooling, and the adoption of the language by big companies, this is Kotlin at its (backend) best. Here’s a breakdown of what was announced, what’s new, and what you absolutely must check out […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=593682",
        "categories": [
          "community",
          "kotlinconf",
          "news",
          "server-side"
        ],
        "isoDate": "2025-08-22T15:02:47.000Z"
      },
      {
        "creator": "Vlad Ivoninskii",
        "title": "Google Drive Integration, Python 3.11 in Conda Environments, and Security improvements in Datalore 2025.4",
        "link": "https://blog.jetbrains.com/datalore/2025/08/22/google-drive-integration-python-3-11-in-conda-environments-and-security-improvements-in-datalore-2025-4/",
        "pubDate": "Fri, 22 Aug 2025 10:12:33 +0000",
        "content:encodedSnippet": "Datalore 2025.4 is now available, bringing support for Google Drive folders as data connections, Python 3.11 in conda environments, and a dozen of small behind-the-scenes enhancements and bug fixes.\nThese updates are already available for Datalore Cloud users, and Datalore On-Premises users can get them by updating their Datalore instance.\nGoogle Drive integration\nAt Datalore, we strive to help all data teams make the most of their data – no matter where it is stored. That’s why we’ve expanded our set of database and cloud storage connectors to include Google Drive folders. Even if your team doesn’t store data in cloud buckets and prefers Google Workspace, your notebooks can always point to the latest version of CSV, JSON, Parquet, and other files without manual exports and re-uploads. \nLearn more about connecting to Google Drive from Datalore.\n\n\n\n\nPython versions in conda environments\nThe default Python interpreter in conda environments now uses Python 3.11, so that you can benefit from better performance, security, and support for library compatibility. \nIf your project in Datalore On-Premises depends on older or custom packages, you can build and use a custom image tailored to your exact needs. In Datalore Cloud, you can select the Python version that best fits your stack requirements when creating a notebook.\nSecurity\nIn this release, we made Datalore even more secure. We introduced multiple security improvements, including fixes for CSRF- and XSS-related vulnerabilities, ensuring stronger protection for your Datalore instances. We also resolved a rare issue that could prevent interactive tables from displaying correctly and addressed problems affecting Plotly chart rendering.\nMore features are on the horizon, so keep an eye out for what’s next!\n      \n      Update to 2025.4",
        "dc:creator": "Vlad Ivoninskii",
        "content": "Datalore 2025.4 is now available, bringing support for Google Drive folders as data connections, Python 3.11 in conda environments, and a dozen of small behind-the-scenes enhancements and bug fixes. These updates are already available for Datalore Cloud users, and Datalore On-Premises users can get them by updating their Datalore instance. Google Drive integration At Datalore, [&#8230;]",
        "contentSnippet": "Datalore 2025.4 is now available, bringing support for Google Drive folders as data connections, Python 3.11 in conda environments, and a dozen of small behind-the-scenes enhancements and bug fixes. These updates are already available for Datalore Cloud users, and Datalore On-Premises users can get them by updating their Datalore instance. Google Drive integration At Datalore, […]",
        "guid": "https://blog.jetbrains.com/?post_type=datalore&p=591840",
        "categories": [
          "release"
        ],
        "isoDate": "2025-08-22T10:12:33.000Z"
      }
    ]
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Mads Kristensen",
        "title": "The Visual Studio August Update is here – smarter AI, better debugging, and more control",
        "link": "https://devblogs.microsoft.com/visualstudio/the-visual-studio-august-update-is-here-smarter-ai-better-debugging-and-more-control/",
        "pubDate": "Tue, 26 Aug 2025 18:22:28 +0000",
        "content:encodedSnippet": "The August 2025 update for Visual Studio 2022 (v17.14) is now available, and it’s all about helping developers stay focused, productive, and in control. Whether you’re building games, tuning performance, or exploring AI, this release brings meaningful improvements that make everyday development smoother and smarter.\n\nGPT-5 support now available\nWe’re excited to announce that GPT-5 is now available in Visual Studio, bringing the latest advancements in AI directly to your development environment. With GPT-5 integration, you can leverage more powerful, accurate, and context-aware code suggestions and chat experiences. Whether you’re writing complex algorithms, refactoring large codebases, or brainstorming new features, GPT-5 helps you move faster and with greater confidence.\n\nConnect your entire stack with MCP\nWe’re excited to announce that MCP (Model Context Protocol) support is now generally available in Visual Studio. MCP is a powerful protocol that connects AI agents to external tools – like databases, code search, and deployment systems – without needing custom integrations for each one. Think of it as the HTTP of tool connectivity.\nWith this release, Visual Studio makes it easier than ever to manage and connect to MCP servers:\nOAuth support for any provider: Authenticate with any OAuth provider directly from Visual Studio using the new authorization spec.\nOne-click server install from the web: Add MCP servers with a single click from supported repositories – no more manual JSON editing.\nNew server add flow: Use the green plus button in the Copilot Chat tool picker to quickly configure and connect to new servers.\nGovernance controls: Organizations can now manage MCP access via GitHub policy settings for better compliance and control.\n\nThis update makes MCP a first-class experience in Visual Studio, helping teams unlock richer, real-time context across their entire engineering stack.\nSmarter Copilot Chat with better context\nCopilot Chat can now more reliably surface relevant code snippets. It now uses improved semantic code search to better identify when a query should trigger a code lookup. When that context is detected, it searches across your solution or workspace to retrieve the most relevant snippets, even from natural language descriptions, reducing the need to manually navigate your codebase.\n\nSign Up for Copilot with Google\nGetting started with Copilot is now easier than ever. You can sign up using your Google account directly from Visual Studio. It’s a fast, frictionless way to get up and running with AI-powered coding-no extra setup required.\n\nBring your own AI model to Chat\nWant more control over your AI experience? You can now connect your own language models to Visual Studio Chat using API keys from OpenAI, Google, or Anthropic. This gives you the flexibility to choose the model that best fits your workflow, whether you’re optimizing for performance, privacy, or experimentation.\n\nUnified debugging for Unreal Engine\nIf you’re working in C++ with Unreal Engine, debugging just got a major upgrade. Visual Studio now lets you debug Blueprint and native code together in a single session. You’ll see Blueprint data in the call stack and locals window, and you can even set breakpoints directly in Blueprint code.\n\nThis makes it easier to trace interactions and fix issues across both scripting layers.\nCopilot Suggestions when you want them\nPrefer a quieter editor? You can now disable automatic Copilot suggestions and trigger them manually with keyboard shortcuts. This gives you full control over when suggestions appear, helping you stay focused when you need to and get help when you want it.\nCleaner editing with collapsed suggestions\nNext Edit Suggestions (NES) are now hidden by default. Instead of popping up automatically, they appear as a subtle margin indicator when relevant. You decide when to engage, keeping your editor clean and distraction-free.\n\nAccept code completions partially\nHave you ever wanted to only accept the first couple words or lines of a Copilot code completions instead of accepting the whole thing? We are excited to announce that you will now be able to partially accept a completion word by word or line by line!\nGit context in Copilot Chat\nCopilot Chat now understands your Git history. You can reference commits and uncommitted changes directly in chat to summarize work, explain updates, or generate tests-all without leaving the editor.\n\nThis makes it easier to stay in flow while reviewing or refining your code.\nBuilt with your feedback\nMany of the features and fixes in this release come directly from the Developer Community. Your suggestions and bug reports continue to shape Visual Studio, and we’re grateful for your input. You can explore all the community-driven updates and fixes in the release notes.\nThanks again for your feedback and support. We’re excited to keep building Visual Studio with you-one update at a time. Let us know what you think, and as always, happy coding!\nThe post The Visual Studio August Update is here – smarter AI, better debugging, and more control appeared first on Visual Studio Blog.",
        "dc:creator": "Mads Kristensen",
        "comments": "https://devblogs.microsoft.com/visualstudio/the-visual-studio-august-update-is-here-smarter-ai-better-debugging-and-more-control/#comments",
        "content": "<p>The August 2025 update for Visual Studio 2022 (v17.14) is now available, and it’s all about helping developers stay focused, productive, and in control. Whether you&#8217;re building games, tuning performance, or exploring AI, this release brings meaningful improvements that make everyday development smoother and smarter. GPT-5 support now available We&#8217;re excited to announce that GPT-5 [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/the-visual-studio-august-update-is-here-smarter-ai-better-debugging-and-more-control/\">The Visual Studio August Update is here &#8211; smarter AI, better debugging, and more control</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "The August 2025 update for Visual Studio 2022 (v17.14) is now available, and it’s all about helping developers stay focused, productive, and in control. Whether you’re building games, tuning performance, or exploring AI, this release brings meaningful improvements that make everyday development smoother and smarter. GPT-5 support now available We’re excited to announce that GPT-5 […]\nThe post The Visual Studio August Update is here – smarter AI, better debugging, and more control appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=254076",
        "categories": [
          "Copilot",
          "Debug",
          "Git",
          "GitHub Copilot",
          "Productivity",
          "Visual Studio",
          "C++",
          "MCP",
          "Models",
          "Next Edits Suggestion",
          "Sign in"
        ],
        "isoDate": "2025-08-26T18:22:28.000Z"
      },
      {
        "creator": "Yun Jung Choi",
        "title": "GitHub Copilot for Azure (Preview) Launches in Visual Studio 2022 with Azure MCP Support",
        "link": "https://devblogs.microsoft.com/visualstudio/github-copilot-for-azure-preview-launches-in-visual-studio-2022-with-azure-mcp-support/",
        "pubDate": "Mon, 25 Aug 2025 18:36:28 +0000",
        "content:encodedSnippet": "The GitHub Copilot for Azure extension is now in Public Preview for Visual Studio 2022 (17.14+). It brings a curated set of Azure developer tools—exposed through the Azure MCP server—directly into GitHub Copilot Agent Mode in Visual Studio. The extension automatically installs and manages the Azure MCP server, so you can query resources, diagnose issues, deploy with azd, and run Azure CLI commands—all from the Copilot Chat.\nTry GitHub Copilot for Azure\n\nShip Azure features without leaving Visual Studio. Agent-powered, MCP-enabled, no extra setup.\n\nWhat’s in the Public Preview?\nZero-setup Azure MCP server\nThe extension automatically downloads and starts the Azure MCP server the first time you open Copilot Chat—no manual install required. (You’ll see it in the tools list in Agent Mode.)\n(Note: the MCP server version included with the extension may occasionally trail the latest upstream release by a few versions.)\nAgent Mode + Azure tools\nLet Copilot pick the right tools for your goal—or choose specific tools from the toolbox in the Copilot Chat window. Typical tasks include: list and inspect resources, diagnose issues, pull app logs, deploy with azd, run Azure CLI commands, and more.\nBroad Azure coverage via MCP tools\nThe suite of tools allows interaction with:\n Azure App Configuration\n Azure Best Practices\n Azure CLI Extension\n Azure Container Registry (ACR)\n Azure Cosmos DB (NoSQL Databases)\n Azure Data Explorer\n Azure Database for PostgreSQL – Flexible Server\n Azure Developer CLI (azd) Extension\n Azure Deploy\n Azure Function App\n Azure Key Vault\n Azure Kubernetes Service (AKS)\n Azure SQL Database, Elastic Pool, and Server\n Azure Storage\n…and many more!\nSee the full, continuously updated list in the Azure MCP server docs.\nGet started\nPrerequisites\nVisual Studio 2022 17.14 or later (Agent Mode + MCP support)\nAn active GitHub Copilot subscription and Copilot Chat enabled in Visual Studio\nA Microsoft account with access to an Azure subscription (or start free below)\nInstall & set up\nInstall the \nGitHub Copilot for Azure (Preview)\n extension for Visual Studio 2022.\nThe extension starts the Azure MCP server automatically—no manual setup required.\nOpen Copilot Chat and select Agent Mode.\n\n\n\nClick Select tools and check to enable the Azure Extension.\n\n\n\n\n\n\nIn your prompts, include resource details for best results (subscription, resource group, resource name).\nNew to Azure? Sign up free and get $200 in credit to explore services\nTry these example prompts\nThese examples assume you’re in Agent Mode with Azure tools enabled. Add subscription and resource group names where helpful.\n“Do I have any webapps in my current subscription?”\n“Look for a WebApp named `<appname>`. Does it have any recent downtime?”\n“Find what tenants I have access to and what I’m currently using.”\n“Provide the weburls for these ACA apps.”\nWhat’s next?\nWe’re committed to continuously expanding the Azure toolset and deepening the integration with Visual Studio, all on top of the robust MCP foundation that is now generally available in Visual Studio. If you’re already using GitHub Copilot, we encourage you to try out GitHub Copilot for Azure and experience the new capabilities firsthand. Your feedback is invaluable—let us know which Azure scenarios you’d like to automate next and help shape the future of GitHub Copilot for Azure!\nLearn how to share feedback in Visual Studio 2022\nAdditional learning\nModel Context Protocol (MCP) is Now Generally Available in Visual Studio  – Visual Studio Blog\nAgent mode is now generally available with MCP support – Visual Studio Blog\nCustomizing GitHub Copilot in Visual Studio with Custom Instructions (Part 5 of 8) | Microsoft Learn\nThe post GitHub Copilot for Azure (Preview) Launches in Visual Studio 2022 with Azure MCP Support appeared first on Visual Studio Blog.",
        "dc:creator": "Yun Jung Choi",
        "comments": "https://devblogs.microsoft.com/visualstudio/github-copilot-for-azure-preview-launches-in-visual-studio-2022-with-azure-mcp-support/#comments",
        "content": "<p>The GitHub Copilot for Azure extension is now in Public Preview for Visual Studio 2022 (17.14+). It brings a curated set of Azure developer tools—exposed through the Azure MCP server—directly into GitHub Copilot Agent Mode in Visual Studio. The extension automatically installs and manages the Azure MCP server, so you can query resources, diagnose issues, [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/github-copilot-for-azure-preview-launches-in-visual-studio-2022-with-azure-mcp-support/\">GitHub Copilot for Azure (Preview) Launches in Visual Studio 2022 with Azure MCP Support</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "The GitHub Copilot for Azure extension is now in Public Preview for Visual Studio 2022 (17.14+). It brings a curated set of Azure developer tools—exposed through the Azure MCP server—directly into GitHub Copilot Agent Mode in Visual Studio. The extension automatically installs and manages the Azure MCP server, so you can query resources, diagnose issues, […]\nThe post GitHub Copilot for Azure (Preview) Launches in Visual Studio 2022 with Azure MCP Support appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=253992",
        "categories": [
          "Azure",
          "Cloud",
          "Copilot",
          "Visual Studio",
          "Agent Mode",
          "agents",
          "GitHub Copilot",
          "LLM",
          "MCP",
          "microsoft",
          "Model Context Protocol",
          "Visual Studio 2022"
        ],
        "isoDate": "2025-08-25T18:36:28.000Z"
      },
      {
        "creator": "Simona Liao",
        "title": "Better Control over Your Copilot Code Suggestions",
        "link": "https://devblogs.microsoft.com/visualstudio/better-control-over-your-copilot-code-suggestions/",
        "pubDate": "Thu, 21 Aug 2025 16:00:37 +0000",
        "content:encodedSnippet": "Copilot code completions and suggestions in the editor speed you up in your daily programming and coding activities, at every keystroke. They help you finish the line you’re typing or anticipate your next edit, making your workflow smoother and faster. At the same time, editor is where you focus and put in the deep work. Based on your feedback, we understand how important it is to strike the right balance between helpful suggestions and maintaining control over your attention and workspace.\nWe’re excited to share features that give you enhanced control over your Copilot experience, so you can decide when suggestions show up and how much you accept, right inside your editor. These features are all available to you now, starting Visual Studio 2022 17.14.13 (August 2025).\nMinimize Distractions When Coding\nDo you prefer a quieter editor when actively thinking and coding? We have a few options in Visual Studio to help you stay focused on programming and still have Copilot assistance available for you when you are ready to review them.\n1. No completions while typing\nBy default, completion is requested at every keystroke you type to provide just-in-time support. We learned from you that it could show up too quickly sometimes and interfere with your typing. You can pause code completions when you are quickly typing out the code.  Go to Tools -> Options -> IntelliCode -> Advanced and turn on wait for pauses in typing before showing whole line completions. This will add a debounce to request code completions when you are typing, so you will not see the completions quickly showing and disappearing while you are typing fast.\n2. Only receive code completions when you request it\nYou can now disable automatic completions popping on and trigger them manually with keyboard shortcuts. This gives you full control over when suggestions appear, helping you stay focused when you need to and get help when you want it.\nConfigure the trigger for code completions in Tools > Options > IntelliCode > General. The default experience is Automatically generate code completions in the Editor and you can uncheck this setting to only receive suggestions when you explicitly request them by pressing Alt + , or Alt + .. If there are multiple code suggestions available after requesting, you can cycle through them by pressing Alt + , or Alt + .as well.\nWhen triggered with the keyboard shortcuts, a thinking hint bar will appear at your cursor position to indicate that Copilot is generating code suggestions. If no suggestions are returned, the hint bar will disappear after a few seconds. If suggestions are available, you can accept them by pressing Tab.\ndocument.createElement('video');\n\n3. Hide next edit suggestions and review them when you are ready\nNext edit suggestions predict the next edit you will make based on your previous code edits. Sometimes these suggestions can be a bit distracting when appearing unexpectedly, and now you can hide NES by default and only review them when you want to.\nNES will still be triggered based on your edits and when there is an available NES ready for you to review, a margin indicator will appear in the gutter space, pointing at the line that it has a suggestion for. To view this suggestion, you can either:\n\nClick the margin indicator or\nPress Tab\n\nand the suggestion will be displayed. Then, after viewing the suggestions, you can press Tab again to accept it or press ESC to dismiss it. After you accept a suggestion, any related suggestions will automatically appear again, as you might find them useful too. Any other new suggestions that are not related to your previously accepted suggestion will be hidden again.\nFor example, in the video below, after changing Point to Point3D, a NES is available but not displayed directly. The margin indicator and hint bar show that there is a suggestion on line 4 and then I clicked on the indicator to review it.\n[video mp4=\"https://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2025/08/NEScollapsemode.mp4\"]https://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2025/08/completions-on-demand.mp4\n\n3. Hide next edit suggestions and only preview when you are ready\nNext edit suggestions predict the next edit you will make based on your previous code edits. Sometimes these suggestions can be a bit distracting when appearing unexpectedly, and now you can hide NES by default and only review them when you want to.\nNES will still be triggered based on your edits and when there is an available NES ready for you to review, a margin indicator will appear in the gutter space, pointing at the line that it has a suggestion for. To view this suggestion, you can either:\nClick the margin indicator or\nPress Tab\nand the suggestion will be displayed. Then, after viewing the suggestions, you can press Tab again to accept it or press ESC to dismiss it. After you accept a suggestion, any related suggestions will automatically appear again, as you might find them useful too. Any other new suggestions that are not related to your previously accepted suggestion will be hidden again.\nFor example, in the video below, after changing Point to Point3D, a NES is available but not displayed directly. The margin indicator and hint bar show that there is a suggestion on line 4 and then I clicked on the indicator to review it.\nhttps://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2025/08/NEScollapsemode.mp4\n\nTo try out this experience, go to Tools > Options > GitHub > Copilot > Copilot Completions and check Collapse Next Edit Suggestions.\nPartially Accept a Code Suggestion\nHave you ever wanted to only accept the first couple words or lines of a Copilot code completions instead of accepting the whole thing? We are excited to announce that you will now be able to partially accept a code completion word by word or line by line!\nWhen having a Copilot code completion in the editor…\nUse the shortcut Ctrl + Right Arrow to accept one word at a time,\nUse the shortcut Ctrl + Down Arrow to accept one line at a time.\nYou can also use the margin indicator to accept the completion partially. When clicking on the margin indicator, it will have options for partial accepts too.\nhttps://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2025/08/partial-accept.mp4\n\nNow you will have more fine-grained control over how much code completions you would like to accept instead of having to accept the entire suggestions and edit afterwards. Please try it out and let us know what you think!\nNote: Partial accept overrides the existing functionality that bind to these shortcuts. If you would like to turn it off, please go to Tools > Options > IntelliCode > Advanced > Whole-line completions\nThanks for sharing your feedback!\nWe worked on these improvements because of your valuable feedback shared with us through Developer Community (Copilot completions are too intrusive – Developer Community,  Ability to partially accept GitHub Copilot suggestions – Developer Community) and product surveys. We truly appreciate your input—it helps us build better experiences. Please try out these ways to fine-tune Copilot suggestions in your editor and let us know how we can keep making it better for you!\nCheck out the new Visual Studio Hub\nStay connected with everything Visual Studio in one place! Visit the Visual Studio Hub for the latest release notes, YouTube videos, social updates, and community discussions.\nAppreciation for your feedback\nYour feedback helps us improve Visual Studio, making it an even more powerful tool for developers. We are immensely grateful for your contributions and look forward to your continued support. By sharing your thoughts, ideas, and any issues you encounter through Developer Community, you help us improve and shape the future of Visual Studio.\nThe post Better Control over Your Copilot Code Suggestions appeared first on Visual Studio Blog.",
        "enclosure": {
          "url": "https://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2025/08/NEScollapsemode.mp4",
          "length": "8022472",
          "type": "video/mp4"
        },
        "dc:creator": "Simona Liao",
        "comments": "https://devblogs.microsoft.com/visualstudio/better-control-over-your-copilot-code-suggestions/#comments",
        "content": "<p>Copilot code completions and suggestions in the editor speed you up in your daily programming and coding activities, at every keystroke. They help you finish the line you&#8217;re typing or anticipate your next edit, making your workflow smoother and faster. At the same time, editor is where you focus and put in the deep work. [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/better-control-over-your-copilot-code-suggestions/\">Better Control over Your Copilot Code Suggestions</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Copilot code completions and suggestions in the editor speed you up in your daily programming and coding activities, at every keystroke. They help you finish the line you’re typing or anticipate your next edit, making your workflow smoother and faster. At the same time, editor is where you focus and put in the deep work. […]\nThe post Better Control over Your Copilot Code Suggestions appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=253975",
        "categories": [
          "GitHub Copilot",
          "Visual Studio",
          "Visual Studio 2022"
        ],
        "isoDate": "2025-08-21T16:00:37.000Z"
      },
      {
        "creator": "Rhea Patel, Samruddhi Khandale",
        "title": "Bring Your Own Model to Chat in Visual Studio",
        "link": "https://devblogs.microsoft.com/visualstudio/bring-your-own-model-visual-studio-chat/",
        "pubDate": "Wed, 20 Aug 2025 15:40:20 +0000",
        "content:encodedSnippet": "We’re excited to announce that you can now bring your own language model into Visual Studio Chat.\nYou can connect API keys from providers (OpenAI, Anthropic, and Google) to access a wider range of models. This makes it easy to test the latest releases, customize workflows, or run on infrastructure you control.\nTry it out in Visual Studio\n\nWhat it unlocks\nChoice – Access more than just the built-in defaults, and try new models the moment they drop.\nCustomization – Pick models that align with your security, infra, or performance needs.\nControl – Manage usage, quotas, and billing directly with your provider.\nFlexibility – Switch seamlessly between Copilot’s built-in models and your own.\n\nGetting started\nIf you already have an API key from OpenAI, Anthropic, or Google, setup takes just a minute:\nOpen the Chat Window in Visual Studio.\nSelect Manage Models from the model picker.\nChoose your provider and paste your API key.\nPick from the preset list, or enter a model name.\nThat’s it—your model will now show up in the picker.\nThis feature is not currently available for Copilot Business or Copilot Enterprise users. \n\nA few important considerations:\nThis feature currently applies only to Chat in Visual Studio (not completions, commit messages, or other AI features).\nModel capabilities vary—some may not support advanced features like tool use or vision inputs.\nCertain services (embeddings, repo indexing, intent detection) will still run through Copilot’s API.\nOutput from third-party models comes directly from the provider and may not pass through Copilot’s responsible AI filters.\nTry it out in Visual Studio\n\nThis is just the beginning. We’re expanding support for additional model providers soon, and we look forward to seeing how you use this feature and which models you choose.\nThe post Bring Your Own Model to Chat in Visual Studio appeared first on Visual Studio Blog.",
        "dc:creator": "Rhea Patel, Samruddhi Khandale",
        "comments": "https://devblogs.microsoft.com/visualstudio/bring-your-own-model-visual-studio-chat/#comments",
        "content": "<p>We’re excited to announce that you can now bring your own language model into Visual Studio Chat. You can connect API keys from providers (OpenAI, Anthropic, and Google) to access a wider range of models. This makes it easy to test the latest releases, customize workflows, or run on infrastructure you control. What it unlocks [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/bring-your-own-model-visual-studio-chat/\">Bring Your Own Model to Chat in Visual Studio</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "We’re excited to announce that you can now bring your own language model into Visual Studio Chat. You can connect API keys from providers (OpenAI, Anthropic, and Google) to access a wider range of models. This makes it easy to test the latest releases, customize workflows, or run on infrastructure you control. What it unlocks […]\nThe post Bring Your Own Model to Chat in Visual Studio appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=253946",
        "categories": [
          "Copilot",
          "Anthropic",
          "Artificial Intelligence",
          "BYOK",
          "Claude",
          "Gemini",
          "Google",
          "GPT",
          "Key",
          "Models",
          "OpenAI",
          "Visual Studio"
        ],
        "isoDate": "2025-08-20T15:40:20.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": [
      {
        "creator": "sunyzero",
        "title": "크롬 흰색창 혹은 흰색스크린 오류",
        "link": "http://sunyzero.tistory.com/318",
        "pubDate": "Sun, 24 Aug 2025 22:05:21 +0900",
        "author": "sunyzero",
        "comments": "http://sunyzero.tistory.com/318#entry318comment",
        "content": "<p data-ke-size=\"size16\">윈도 업데이트 후 크롬 브라우저가 온통 하얀색으로 나왔다. 해당 증상은 ANGLE graphics backend를 OpenGL을 사용하면서 그래픽 가속을 켜놓은 경우에만 발생하는 것으로 보인다. 따라서 ANGLE graphics backend 설정을 Default로 재설정해주면 해결할 수 있다. 아래는 ANGLE 설정을 재설정하는 방법이다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">1. 크롬의 흰색창 증상</h2>\n<p data-ke-size=\"size16\">증상은 아래처럼 Chrome browser 실행시 그냥 하얀 화면, 흰색창으로 나타나는 경우이다. 진짜 아무것도 보이지 않는다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"chrome_whitewindow_1.png\" data-origin-width=\"2007\" data-origin-height=\"1510\"><span data-url=\"https://blog.kakaocdn.net/dn/NeQRG/btsP35jX7xm/kHtDlXaxwIQ88AaU1tMUA1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/NeQRG/btsP35jX7xm/kHtDlXaxwIQ88AaU1tMUA1/img.png\" data-alt=\"Chrome white screen\"><img src=\"https://blog.kakaocdn.net/dn/NeQRG/btsP35jX7xm/kHtDlXaxwIQ88AaU1tMUA1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FNeQRG%2FbtsP35jX7xm%2FkHtDlXaxwIQ88AaU1tMUA1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"2007\" height=\"1510\" data-filename=\"chrome_whitewindow_1.png\" data-origin-width=\"2007\" data-origin-height=\"1510\"/></span><figcaption>Chrome white screen</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">2. 해결 방법</h2>\n<p data-ke-size=\"size16\">먼저 어떻게 해서든지 크롬 화면이 나오도록 실행해야 하는데, 이는 그래픽 가속을 끄는 옵션을 사용하면 된다. 먼저 실행된 크롬 브라우저를 종료한다. 대충 흰색 창의 우측 상단 X 마크가 있을 법한 위치를 눌러서 크롬을 닫는다. 혹은 창 선택 후 Alt+F4로 닫아도 된다.</p>\n<p data-ke-size=\"size16\">크롬이 닫힌 뒤에 Powershell을 하나 실행시킨다. 실행은 \"윈도우 + R\"키를 눌러서 나온 실행 창에서 powershell이라고 치면 된다. Powershell 에서 크롬이 설치된 디렉토리로 이동하는데, 경로는 보통 \"C:\\Program Files\\Google\\Chrome\\Application\" 이다. 아래처럼 cd (change directory) 명령을 사용하면 된다. 오타를 낼 것 같다면 Tab키를 사용해서 자동완성으로 디렉토리를 찾아가면 편리하다.</p>\n<pre id=\"code_1756039781195\" class=\"shell\" data-ke-language=\"shell\" data-ke-type=\"codeblock\"><code>cd \"C:\\Program Files\\Google\\Chrome\\Application\"</code></pre>\n<p data-ke-size=\"size16\">이제 해당 디렉토리에서 <span style=\"background-color: #f6e199;\">crhome.exe --disable-gpu</span> 명령으로 크롬을 실행한다. 아래는 powershell에서 명령하는 모습을 캡쳐한 그림 파일이다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"chrome_whitewindow_2.png\" data-origin-width=\"1721\" data-origin-height=\"226\"><span data-url=\"https://blog.kakaocdn.net/dn/seeLn/btsP24r5CZB/9SBoKk1PxTkK11VCjso7FK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/seeLn/btsP24r5CZB/9SBoKk1PxTkK11VCjso7FK/img.png\" data-alt=\"Chome disable gpu option\"><img src=\"https://blog.kakaocdn.net/dn/seeLn/btsP24r5CZB/9SBoKk1PxTkK11VCjso7FK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FseeLn%2FbtsP24r5CZB%2F9SBoKk1PxTkK11VCjso7FK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1721\" height=\"226\" data-filename=\"chrome_whitewindow_2.png\" data-origin-width=\"1721\" data-origin-height=\"226\"/></span><figcaption>Chome disable gpu option</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">이렇게 하면 이제 크롬 화면이 보일 것이다. 임시로 띄운 것이므로 여기서 설정을 손봐야 한다. 먼저 주소창에서 <span style=\"background-color: #f6e199;\">chrome://flags</span>를 실행한다. 그리고 주소창 아래의 돋보기 검색창에 <span style=\"background-color: #9feec3;\">ANGLE</span>을 타이핑하면 <span style=\"background-color: #9feec3;\">Choose ANGLE graphics backend</span>가 보일 것이다. 이 값이 Default가 아닌 OpenGL 같은 다른 값으로 되어있을 것이다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1301\" data-origin-height=\"530\"><span data-url=\"https://blog.kakaocdn.net/dn/bt3x36/btsP4oKlYYC/HR8RqUFVrsULUXUKNwJDd0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bt3x36/btsP4oKlYYC/HR8RqUFVrsULUXUKNwJDd0/img.png\" data-alt=\"chrome flags - Choose ANGLE graphics backend - OpenGL\"><img src=\"https://blog.kakaocdn.net/dn/bt3x36/btsP4oKlYYC/HR8RqUFVrsULUXUKNwJDd0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbt3x36%2FbtsP4oKlYYC%2FHR8RqUFVrsULUXUKNwJDd0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1301\" height=\"530\" data-origin-width=\"1301\" data-origin-height=\"530\"/></span><figcaption>chrome flags - Choose ANGLE graphics backend - OpenGL</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">이제 default로 값을 변경한 뒤에 크롬창 우측 하단에 재시작을 눌러주면 재시작 되면서 제대로 작동 될 것이다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"chrome_whitewindow_4.png\" data-origin-width=\"1311\" data-origin-height=\"557\"><span data-url=\"https://blog.kakaocdn.net/dn/HUMXz/btsP3ysTkzY/HGLNKXM4uFYrkraHUW5KYk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/HUMXz/btsP3ysTkzY/HGLNKXM4uFYrkraHUW5KYk/img.png\" data-alt=\"chrome flags - Choose ANGLE graphics backend - Default\"><img src=\"https://blog.kakaocdn.net/dn/HUMXz/btsP3ysTkzY/HGLNKXM4uFYrkraHUW5KYk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FHUMXz%2FbtsP3ysTkzY%2FHGLNKXM4uFYrkraHUW5KYk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1311\" height=\"557\" data-filename=\"chrome_whitewindow_4.png\" data-origin-width=\"1311\" data-origin-height=\"557\"/></span><figcaption>chrome flags - Choose ANGLE graphics backend - Default</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">만일 이렇게 설정 한뒤에도 계속 흰색창 화면이 나온다면 앞의 <span style=\"color: #333333; text-align: start;\"><span>&nbsp;</span></span><span style=\"background-color: #f6e199;\">crhome.exe --disable-gpu</span> 로 실행한 뒤에 \"<span style=\"background-color: #9feec3;\">설정</span>\"에서 \"<span style=\"background-color: #9feec3;\">시스템</span>\"의 \"<span style=\"background-color: #9feec3;\">가능한 경우 그래픽 가속 사용</span>\"을 꺼두는 방법 밖에 없다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1002\" data-origin-height=\"355\"><span data-url=\"https://blog.kakaocdn.net/dn/HvmnQ/btsP4d26QFh/NNjS7Cr77jXGkvQAJNP0i0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/HvmnQ/btsP4d26QFh/NNjS7Cr77jXGkvQAJNP0i0/img.png\" data-alt=\"크롬 - 설정 - 시스템 - 가능한 경우 그래픽 가속 사용\"><img src=\"https://blog.kakaocdn.net/dn/HvmnQ/btsP4d26QFh/NNjS7Cr77jXGkvQAJNP0i0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FHvmnQ%2FbtsP4d26QFh%2FNNjS7Cr77jXGkvQAJNP0i0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1002\" height=\"355\" data-origin-width=\"1002\" data-origin-height=\"355\"/></span><figcaption>크롬 - 설정 - 시스템 - 가능한 경우 그래픽 가속 사용</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">현재 문제가 발생한 이유는 OpenGL관련 부분이나 DirectX 부분을 업데이트하면서 뭔가 꼬인 것이 아닐까 하는 의심이 든다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">히스토리</h2>\n<p data-ke-size=\"size16\">2025.08.24 처음 글 씀</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "윈도 업데이트 후 크롬 브라우저가 온통 하얀색으로 나왔다. 해당 증상은 ANGLE graphics backend를 OpenGL을 사용하면서 그래픽 가속을 켜놓은 경우에만 발생하는 것으로 보인다. 따라서 ANGLE graphics backend 설정을 Default로 재설정해주면 해결할 수 있다. 아래는 ANGLE 설정을 재설정하는 방법이다.\n \n1. 크롬의 흰색창 증상\n증상은 아래처럼 Chrome browser 실행시 그냥 하얀 화면, 흰색창으로 나타나는 경우이다. 진짜 아무것도 보이지 않는다.\nChrome white screen\n\n\n \n2. 해결 방법\n먼저 어떻게 해서든지 크롬 화면이 나오도록 실행해야 하는데, 이는 그래픽 가속을 끄는 옵션을 사용하면 된다. 먼저 실행된 크롬 브라우저를 종료한다. 대충 흰색 창의 우측 상단 X 마크가 있을 법한 위치를 눌러서 크롬을 닫는다. 혹은 창 선택 후 Alt+F4로 닫아도 된다.\n크롬이 닫힌 뒤에 Powershell을 하나 실행시킨다. 실행은 \"윈도우 + R\"키를 눌러서 나온 실행 창에서 powershell이라고 치면 된다. Powershell 에서 크롬이 설치된 디렉토리로 이동하는데, 경로는 보통 \"C:\\Program Files\\Google\\Chrome\\Application\" 이다. 아래처럼 cd (change directory) 명령을 사용하면 된다. 오타를 낼 것 같다면 Tab키를 사용해서 자동완성으로 디렉토리를 찾아가면 편리하다.\ncd \"C:\\Program Files\\Google\\Chrome\\Application\"\n이제 해당 디렉토리에서 crhome.exe --disable-gpu 명령으로 크롬을 실행한다. 아래는 powershell에서 명령하는 모습을 캡쳐한 그림 파일이다.\nChome disable gpu option\n\n\n이렇게 하면 이제 크롬 화면이 보일 것이다. 임시로 띄운 것이므로 여기서 설정을 손봐야 한다. 먼저 주소창에서 chrome://flags를 실행한다. 그리고 주소창 아래의 돋보기 검색창에 ANGLE을 타이핑하면 Choose ANGLE graphics backend가 보일 것이다. 이 값이 Default가 아닌 OpenGL 같은 다른 값으로 되어있을 것이다.\nchrome flags - Choose ANGLE graphics backend - OpenGL\n\n\n이제 default로 값을 변경한 뒤에 크롬창 우측 하단에 재시작을 눌러주면 재시작 되면서 제대로 작동 될 것이다.\nchrome flags - Choose ANGLE graphics backend - Default\n\n\n만일 이렇게 설정 한뒤에도 계속 흰색창 화면이 나온다면 앞의  crhome.exe --disable-gpu 로 실행한 뒤에 \"설정\"에서 \"시스템\"의 \"가능한 경우 그래픽 가속 사용\"을 꺼두는 방법 밖에 없다.\n크롬 - 설정 - 시스템 - 가능한 경우 그래픽 가속 사용\n\n\n현재 문제가 발생한 이유는 OpenGL관련 부분이나 DirectX 부분을 업데이트하면서 뭔가 꼬인 것이 아닐까 하는 의심이 든다.\n \n \n히스토리\n2025.08.24 처음 글 씀",
        "guid": "http://sunyzero.tistory.com/318",
        "categories": [
          "컴퓨터 관련/윈도 패밀리",
          "Chrome disable GPU",
          "chrome OpenGL",
          "Chrome white screen window",
          "Chrome 그래픽 가속",
          "가능한 경우 그래픽 가속 사용 문제",
          "크롬 흰색스크린 문제",
          "크롬 흰색창 문제"
        ],
        "isoDate": "2025-08-24T13:05:21.000Z"
      }
    ]
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": [
      {
        "title": "Text, wav 를 통한 입술 모양 이미지 생성 방법",
        "link": "http://daddynkidsmakers.blogspot.com/2025/08/text-wav.html",
        "pubDate": "2025-08-22T21:31:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\"><div>이 글은 Text, wav 를 통한 입술 모양 이미지 생성 방법을 간략히 정리해 본다.</div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEj5HHRDaxKkRuRRKdYEwzTbmy-MkLswKGTH4fbDjH1l3_mcP8CRiLiFUpDMM7vw7nzASxFkG-vgWaUGclY1QxFOhG6n4Yys6PjRm8t55wTQJYt4A29hymEQI_8cwMQCZH3Gyxmf-6x4Yygszrs9F6peTFbjgJ0uxmYBlB_ztt7fQoxeIMpvNa4A7sz99-6B\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"482\" data-original-width=\"880\" height=\"175\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEj5HHRDaxKkRuRRKdYEwzTbmy-MkLswKGTH4fbDjH1l3_mcP8CRiLiFUpDMM7vw7nzASxFkG-vgWaUGclY1QxFOhG6n4Yys6PjRm8t55wTQJYt4A29hymEQI_8cwMQCZH3Gyxmf-6x4Yygszrs9F6peTFbjgJ0uxmYBlB_ztt7fQoxeIMpvNa4A7sz99-6B\" width=\"320\" /></a></div><br /></div><div><b>서론</b></div><div>디지털 휴먼 및 가상 아바타 기술의 발전에 따라, 텍스트 입력에 대한 실시간 립 애니메이션 생성 기술의 중요성이 증대되고 있다. 전통적인 방식은 텍스트로부터 완전한 오디오 파일을 생성한 후, 해당 파일을 기반으로 비디오 프레임을 합성하는 배치(Batch) 처리 방식을 채택한다. 그러나 이 방식은 오디오 파일 생성과 비디오 렌더링에 소요되는 시간으로 인해 상당한 지연(Latency)이 발생하며, 실시간 상호작용 애플리케이션에는 부적합하다. 본 글은 실시간 텍스트립싱크를 구현하기 위한 핵심 기술 요소를 분석한다.</div><div><br /></div><div><b>실시간 립싱크 구현을 위한 핵심 파이프라인</b></div><div>실시간 립싱크 시스템은 단일 모델이 아닌, 두 가지 핵심 기술이 순차적으로 결합된 파이프라인(Pipeline) 구조로 구현된다.</div><div><br /></div><div>1.&nbsp; 스트리밍 텍스트음성 변환 (Streaming TexttoSpeech, TTS)</div><div>&nbsp;실시간성을 확보하기 위한 첫 번째 단계는 스트리밍 TTS 엔진이다. 이는 입력 텍스트를 완성된 오디오 파일로 변환하는 것이 아니라, 연속적인 오디오 데이터 스트림(Stream)으로 즉시 생성하는 기술이다. 텍스트가 입력되는 즉시 오디오 청크(Chunk)가 생성되어 파이프라인의 후속 단계로 전달되므로, 전체 문장이 끝날 때까지 기다릴 필요가 없다. 이는 전체 지연 시간을 최소화하는 데 결정적인 역할을 한다.</div><div><br /></div><div>2.&nbsp; 저지연 얼굴 애니메이션 (Lowlatency Facial Animation)</div><div>&nbsp; &nbsp; 두 번째 단계는 스트리밍 TTS로부터 전달받은 오디오 청크를 입력받아, 이에 상응하는 입 모양 애니메이션을 즉각적으로 생성하는 모델이다. 이 모델은 오디오 파형, 음소(Phoneme), 또는 음성 특징(Feature)을 분석하여 얼굴 모델의 특정 파라미터를 제어한다. 여기서 핵심은 최소한의 연산으로 최대한 자연스러운 움직임을 생성하여, 오디오와 시각적 출력 사이의 동기화를 유지하는 것이다.</div><div><br /></div><div><b>구현 방식에 따른 기술적 접근</b></div><div>실시간 립싱크는 요구되는 성능과 사용 가능한 하드웨어 자원에 따라 다양한 접근 방식이 존재한다.</div><div><br /></div><div>1. 고성능 GPU 기반 솔루션: NVIDIA Riva 및 Audio2Face</div><div>NVIDIA에서 제공하는 이 솔루션은 현재 가장 높은 수준의 실시간성과 품질을 제공하는 산업 표준으로 평가된다. NVIDIA Riva는 고성종 스트리밍 TTS 엔진의 역할을 수행하며, Audio2Face는 Riva로부터 생성된 오디오 스트림을 입력받아 3D 아바타의 얼굴 메쉬(Mesh)를 실시간으로 정교하게 제어한다. 이 방식은 RTX 시리즈 이상의 고성능 GPU를 요구하지만, 매우 낮은 지연 시간과 사실적인 표정 변화를 구현할 수 있다는 장점이 있다.</div><div><br /></div><div>2. 경량화 오픈소스 모델 조합</div><div>제한된 하드웨어 환경에서는 경량화된 오픈소스 모델을 조합하여 시스템을 구축할 수 있다. 예를 들어, 빠른 추론 속도를 보이는 LivePortrait 또는 Wav2Lip과 같은 얼굴 애니메이션 모델과 PiperTTS와 같은 경량 스트리밍 TTS 엔진을 결합하는 방식이다. 이 접근법은 시스템의 전체적인 연산량을 줄여 소비자용 GPU 또는 CPU 환경에서도 실시간 처리를 가능하게 하는 것을 목표로 한다. 다만, 각 구성 요소를 연결하고 최적화하는 추가적인 개발 과정이 요구된다.</div><div><br /></div><div><b>MediaPipe</b></div><div>MediaPipe 라이브러리는 립싱크 시스템 구축에 있어 중요한 기반 기술을 제공한다. MediaPipe의 Face Landmarker 기능은 이미지나 비디오 프레임에서 478개의 3D 얼굴 랜드마크와 52개의 블렌드셰이프(Blendshapes)를 정밀하게 추출한다. 블렌드셰이프는 '입 벌리기', '미소' 등 특정 표정의 강도를 수치화한 데이터로, 3D 모델을 제어하는 표준 파라미터로 사용된다.</div><div><br /></div><div>그러나 MediaPipe 자체는 오디오 데이터를 해석하여 립싱크 애니메이션을 생성하는 기능을 포함하고 있지 않다. MediaPipe는 단지 얼굴의 기하학적 구조와 표정을 '표현'하고 '측정'하는 도구일 뿐이다. 따라서 MediaPipe를 활용한 립싱크 시스템을 구축하기 위해서는, 오디오 스트림을 입력받아 이에 상응하는 블렌드셰이프 값을 예측하는 별도의 '오디오투블렌드셰이프(AudiotoBlendshape)' 변환 모델이 반드시 필요하다. 이 모델이 오디오 분석 엔진의 역할을 수행하며, MediaPipe는 그 결과를 받아 시각적으로 렌더링하는 후처리단에 위치하게 된다.</div><div><br /></div><div><b>결론</b></div><div>실시간 텍스트 기반 립싱크는 단순한 모델 하나가 아닌, 스트리밍 TTS와 저지연 얼굴 애니메이션 모델이 유기적으로 결합된 파이프라인을 통해 구현되는 복합적인 기술이다. 고성능 환경에서는 NVIDIA의 솔루션이, 자원이 제한된 환경에서는 경량화된 오픈소스 모델들의 조합이 효과적인 대안이 될 수 있다. MediaPipe와 같은 라이브러리는 얼굴 애니메이션의 최종 출력단을 담당하는 핵심적인 구성 요소이지만, 그 자체만으로는 완전한 립싱크 솔루션이 될 수 없으며 오디오를 해석하는 별도의 AI 모델과의 연동이 필수적이다.&nbsp;</div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b>레퍼런스</b></div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><a href=\"https://ai.google.dev/edge/mediapipe/solutions/vision/face_landmarker?hl=ko\">얼굴 특징 감지 가이드 &nbsp;|&nbsp; Google AI Edge &nbsp;|&nbsp; Google AI for Developers</a></li><li><a href=\"https://github.com/nikitansg/Face-detection-mediapipe/blob/main/Mediapipe-Face-Detector.ipynb\">Face-detection-mediapipe/Mediapipe-Face-Detector.ipynb at main · nikitansg/Face-detection-mediapipe</a></li><li><a href=\"https://github.com/KwaiVGI/LivePortrait\">LivePortrait: Bring portraits to life!</a></li><li><a href=\"https://github.com/OpenTalker/SadTalker\">SadTalker: [CVPR 2023] SadTalker：Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation</a></li><li><a href=\"https://github.com/Rudrabha/Wav2Lip\">Wav2Lip: This repository contains the codes of \"A Lip Sync Expert Is All You Need for Speech to Lip Generation In the Wild\", published at ACM Multimedia 2020. For HD commercial model, please try out Sync Labs</a></li><li><a href=\"https://github.com/rhasspy/piper\">piper: A fast, local neural text to speech system</a></li><li><a href=\"https://github.com/TMElyralab/MuseTalk?tab=readme-ov-file#input-video\">TMElyralab/MuseTalk: MuseTalk: Real-Time High Quality Lip Synchorization with Latent Space Inpainting</a></li><li><a href=\"https://github.com/ali-vilab/dreamtalk\">dreamtalk: Official implementations for paper: DreamTalk: When Expressive Talking Head Generation Meets Diffusion Probabilistic Models</a></li><li><a href=\"https://build.nvidia.com/nvidia/audio2face-3d/api\">audio2face-3d Model by NVIDIA | NVIDIA NIM</a></li><li><a href=\"https://github.com/psyai-net/EmoTalk_release\">EmoTalk_release: This is the official source for our ICCV 2023 paper \"EmoTalk: Speech-Driven Emotional Disentanglement for 3D Face Animation\"</a></li></ul></div>",
        "contentSnippet": "이 글은 Text, wav 를 통한 입술 모양 이미지 생성 방법을 간략히 정리해 본다.\n\n\n\n서론\n디지털 휴먼 및 가상 아바타 기술의 발전에 따라, 텍스트 입력에 대한 실시간 립 애니메이션 생성 기술의 중요성이 증대되고 있다. 전통적인 방식은 텍스트로부터 완전한 오디오 파일을 생성한 후, 해당 파일을 기반으로 비디오 프레임을 합성하는 배치(Batch) 처리 방식을 채택한다. 그러나 이 방식은 오디오 파일 생성과 비디오 렌더링에 소요되는 시간으로 인해 상당한 지연(Latency)이 발생하며, 실시간 상호작용 애플리케이션에는 부적합하다. 본 글은 실시간 텍스트립싱크를 구현하기 위한 핵심 기술 요소를 분석한다.\n\n\n실시간 립싱크 구현을 위한 핵심 파이프라인\n실시간 립싱크 시스템은 단일 모델이 아닌, 두 가지 핵심 기술이 순차적으로 결합된 파이프라인(Pipeline) 구조로 구현된다.\n\n\n1.  스트리밍 텍스트음성 변환 (Streaming TexttoSpeech, TTS)\n 실시간성을 확보하기 위한 첫 번째 단계는 스트리밍 TTS 엔진이다. 이는 입력 텍스트를 완성된 오디오 파일로 변환하는 것이 아니라, 연속적인 오디오 데이터 스트림(Stream)으로 즉시 생성하는 기술이다. 텍스트가 입력되는 즉시 오디오 청크(Chunk)가 생성되어 파이프라인의 후속 단계로 전달되므로, 전체 문장이 끝날 때까지 기다릴 필요가 없다. 이는 전체 지연 시간을 최소화하는 데 결정적인 역할을 한다.\n\n\n2.  저지연 얼굴 애니메이션 (Lowlatency Facial Animation)\n    두 번째 단계는 스트리밍 TTS로부터 전달받은 오디오 청크를 입력받아, 이에 상응하는 입 모양 애니메이션을 즉각적으로 생성하는 모델이다. 이 모델은 오디오 파형, 음소(Phoneme), 또는 음성 특징(Feature)을 분석하여 얼굴 모델의 특정 파라미터를 제어한다. 여기서 핵심은 최소한의 연산으로 최대한 자연스러운 움직임을 생성하여, 오디오와 시각적 출력 사이의 동기화를 유지하는 것이다.\n\n\n구현 방식에 따른 기술적 접근\n실시간 립싱크는 요구되는 성능과 사용 가능한 하드웨어 자원에 따라 다양한 접근 방식이 존재한다.\n\n\n1. 고성능 GPU 기반 솔루션: NVIDIA Riva 및 Audio2Face\nNVIDIA에서 제공하는 이 솔루션은 현재 가장 높은 수준의 실시간성과 품질을 제공하는 산업 표준으로 평가된다. NVIDIA Riva는 고성종 스트리밍 TTS 엔진의 역할을 수행하며, Audio2Face는 Riva로부터 생성된 오디오 스트림을 입력받아 3D 아바타의 얼굴 메쉬(Mesh)를 실시간으로 정교하게 제어한다. 이 방식은 RTX 시리즈 이상의 고성능 GPU를 요구하지만, 매우 낮은 지연 시간과 사실적인 표정 변화를 구현할 수 있다는 장점이 있다.\n\n\n2. 경량화 오픈소스 모델 조합\n제한된 하드웨어 환경에서는 경량화된 오픈소스 모델을 조합하여 시스템을 구축할 수 있다. 예를 들어, 빠른 추론 속도를 보이는 LivePortrait 또는 Wav2Lip과 같은 얼굴 애니메이션 모델과 PiperTTS와 같은 경량 스트리밍 TTS 엔진을 결합하는 방식이다. 이 접근법은 시스템의 전체적인 연산량을 줄여 소비자용 GPU 또는 CPU 환경에서도 실시간 처리를 가능하게 하는 것을 목표로 한다. 다만, 각 구성 요소를 연결하고 최적화하는 추가적인 개발 과정이 요구된다.\n\n\nMediaPipe\nMediaPipe 라이브러리는 립싱크 시스템 구축에 있어 중요한 기반 기술을 제공한다. MediaPipe의 Face Landmarker 기능은 이미지나 비디오 프레임에서 478개의 3D 얼굴 랜드마크와 52개의 블렌드셰이프(Blendshapes)를 정밀하게 추출한다. 블렌드셰이프는 '입 벌리기', '미소' 등 특정 표정의 강도를 수치화한 데이터로, 3D 모델을 제어하는 표준 파라미터로 사용된다.\n\n\n그러나 MediaPipe 자체는 오디오 데이터를 해석하여 립싱크 애니메이션을 생성하는 기능을 포함하고 있지 않다. MediaPipe는 단지 얼굴의 기하학적 구조와 표정을 '표현'하고 '측정'하는 도구일 뿐이다. 따라서 MediaPipe를 활용한 립싱크 시스템을 구축하기 위해서는, 오디오 스트림을 입력받아 이에 상응하는 블렌드셰이프 값을 예측하는 별도의 '오디오투블렌드셰이프(AudiotoBlendshape)' 변환 모델이 반드시 필요하다. 이 모델이 오디오 분석 엔진의 역할을 수행하며, MediaPipe는 그 결과를 받아 시각적으로 렌더링하는 후처리단에 위치하게 된다.\n\n\n결론\n실시간 텍스트 기반 립싱크는 단순한 모델 하나가 아닌, 스트리밍 TTS와 저지연 얼굴 애니메이션 모델이 유기적으로 결합된 파이프라인을 통해 구현되는 복합적인 기술이다. 고성능 환경에서는 NVIDIA의 솔루션이, 자원이 제한된 환경에서는 경량화된 오픈소스 모델들의 조합이 효과적인 대안이 될 수 있다. MediaPipe와 같은 라이브러리는 얼굴 애니메이션의 최종 출력단을 담당하는 핵심적인 구성 요소이지만, 그 자체만으로는 완전한 립싱크 솔루션이 될 수 없으며 오디오를 해석하는 별도의 AI 모델과의 연동이 필수적이다. \n\n\n레퍼런스\n\n얼굴 특징 감지 가이드  |  Google AI Edge  |  Google AI for Developers\nFace-detection-mediapipe/Mediapipe-Face-Detector.ipynb at main · nikitansg/Face-detection-mediapipe\nLivePortrait: Bring portraits to life!\nSadTalker: [CVPR 2023] SadTalker：Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation\nWav2Lip: This repository contains the codes of \"A Lip Sync Expert Is All You Need for Speech to Lip Generation In the Wild\", published at ACM Multimedia 2020. For HD commercial model, please try out Sync Labs\npiper: A fast, local neural text to speech system\nTMElyralab/MuseTalk: MuseTalk: Real-Time High Quality Lip Synchorization with Latent Space Inpainting\ndreamtalk: Official implementations for paper: DreamTalk: When Expressive Talking Head Generation Meets Diffusion Probabilistic Models\naudio2face-3d Model by NVIDIA | NVIDIA NIM\nEmoTalk_release: This is the official source for our ICCV 2023 paper \"EmoTalk: Speech-Driven Emotional Disentanglement for 3D Face Animation\"",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-7460978912231468540",
        "isoDate": "2025-08-22T21:31:00.000Z"
      },
      {
        "title": "Coding 기반 애니메이션 생성 방법",
        "link": "http://daddynkidsmakers.blogspot.com/2025/08/coding.html",
        "pubDate": "2025-08-21T10:21:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">이 글은&nbsp;Coding 기반 애니메이션 생성 방법을 보여준다.</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEiJPrI7VJcPL3jgL4aRzTpLiZk-uXHwBs_EjZnb1YuMnjOxdNA0EcD_eWtmwEsQ2HFZ9IiUvMUKVdxROyRu7eqDpu1HZgoIPHR46ivJlxxhunETQuCAjaCIGWXkd2aZujUiL3CNgsX3oLPNb7Mx7xs_wNeYUPEHefMMnM6ap8s4Bpg0lTTkafGzLQTkxPJm\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"284\" data-original-width=\"633\" height=\"144\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEiJPrI7VJcPL3jgL4aRzTpLiZk-uXHwBs_EjZnb1YuMnjOxdNA0EcD_eWtmwEsQ2HFZ9IiUvMUKVdxROyRu7eqDpu1HZgoIPHR46ivJlxxhunETQuCAjaCIGWXkd2aZujUiL3CNgsX3oLPNb7Mx7xs_wNeYUPEHefMMnM6ap8s4Bpg0lTTkafGzLQTkxPJm\" width=\"320\" /></a></div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><iframe allowfullscreen='allowfullscreen' webkitallowfullscreen='webkitallowfullscreen' mozallowfullscreen='mozallowfullscreen' width='320' height='266' src='https://www.blogger.com/video.g?token=AD6v5dxFb8_iq4jQkOEkKlsQ-aDxLgUG1LAS3V-kOo0FyI24tg7bQb6CJ0WZTtja4qHkuad-3uFOqIMkliynaDMN8w' class='b-hbp-video b-uploaded' frameborder='0'></iframe></div><br /><div style=\"background-color: #1f1f1f; color: #cccccc; font-family: Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; line-height: 16px; white-space: pre;\"><div><span style=\"color: #c586c0;\">from</span> manim <span style=\"color: #c586c0;\">import</span> <span style=\"color: #d4d4d4;\">*</span></div><br /><div><span style=\"color: #569cd6;\">class</span> <span style=\"color: #4ec9b0;\">SquareToCircle</span>(<span style=\"color: #4ec9b0;\">Scene</span>):</div><div>&nbsp; &nbsp; <span style=\"color: #569cd6;\">def</span> <span style=\"color: #dcdcaa;\">construct</span>(<span style=\"color: #9cdcfe;\">self</span>):</div><div>&nbsp; &nbsp; &nbsp; &nbsp; circle <span style=\"color: #d4d4d4;\">=</span> Circle()</div><div>&nbsp; &nbsp; &nbsp; &nbsp; square <span style=\"color: #d4d4d4;\">=</span> Square()</div><div>&nbsp; &nbsp; &nbsp; &nbsp; square.flip(RIGHT)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; square.rotate(<span style=\"color: #d4d4d4;\">-</span><span style=\"color: #b5cea8;\">3</span> <span style=\"color: #d4d4d4;\">*</span> TAU <span style=\"color: #d4d4d4;\">/</span> <span style=\"color: #b5cea8;\">8</span>)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; circle.set_fill(PINK, <span style=\"color: #9cdcfe;\">opacity</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">0.5</span>)</div><br /><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #569cd6;\">self</span>.play(Create(square))</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #569cd6;\">self</span>.play(Transform(square, circle))</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #569cd6;\">self</span>.play(FadeOut(square))</div></div><div style=\"text-align: left;\"><br /></div><b>레퍼런스<br /></b><ul style=\"text-align: left;\"><li><a href=\"https://github.com/manimCommunity/manim\">ManimCommunity/manim: A community-maintained Python framework for creating mathematical animations.</a></li><li><a href=\"https://vrew.ai/en/\">Vrew: Edit Less, Create More | All-in-One AI Video Editor</a></li><li><a href=\"https://www.youtube.com/watch?v=bVV7KhGGAoQ\">Diffusion Transformer</a></li></ul></div>",
        "contentSnippet": "이 글은 Coding 기반 애니메이션 생성 방법을 보여준다.\n\n\n\n\n\nfrom manim import *\n\nclass SquareToCircle(Scene):\n    def construct(self):\n        circle = Circle()\n        square = Square()\n        square.flip(RIGHT)\n        square.rotate(-3 * TAU / 8)\n        circle.set_fill(PINK, opacity=0.5)\n\n        self.play(Create(square))\n        self.play(Transform(square, circle))\n        self.play(FadeOut(square))\n\n\n레퍼런스\n\nManimCommunity/manim: A community-maintained Python framework for creating mathematical animations.\nVrew: Edit Less, Create More | All-in-One AI Video Editor\nDiffusion Transformer",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-4605171217715702650",
        "isoDate": "2025-08-21T10:21:00.000Z"
      }
    ]
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "VIM vs AWK - 2nd",
        "link": "https://kangmyounghun.blogspot.com/2025/08/vim-vs-awk-2nd.html",
        "pubDate": "2025-08-24T04:04:00.002Z",
        "author": "강명훈",
        "content": "<div>강의 이해를 위해 요구되는 사전 지식들.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhsw93YWXT9F8smWJ6OHl9uOG0t7P2n6WMaDk1b6jO-zEjYm6H_qBeZ724yze7zFjkuDH-JtwcrEPGQ71hyphenhyphen-5tOioNtbxKNGAyjMb1vaYDge-DgyfKAmskwwhsh5V2A6NsNMZ_H3pcgn3fbr6QWV__5lPVm6D1nLkZDzsj_IGnQuyU-TzvVA8ZALHXQrQi2/s1348/pre.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"542\" data-original-width=\"1348\" height=\"161\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhsw93YWXT9F8smWJ6OHl9uOG0t7P2n6WMaDk1b6jO-zEjYm6H_qBeZ724yze7zFjkuDH-JtwcrEPGQ71hyphenhyphen-5tOioNtbxKNGAyjMb1vaYDge-DgyfKAmskwwhsh5V2A6NsNMZ_H3pcgn3fbr6QWV__5lPVm6D1nLkZDzsj_IGnQuyU-TzvVA8ZALHXQrQi2/w400-h161/pre.png\" width=\"400\" /></a></div><div><br /></div><div>필수 요건으로로 못박고 싶지만 그랬다간 망할까봐 권장으로 타협. 출강 기관 측은 아예 빼자고 하는데 그러고 싶진 않다. 내 강의 정체성이기 때문.</div><div><br /></div><span><a name='more'></a></span><div><b><span style=\"font-size: x-large;\">세상 모든 데이터는 문자열</span></b></div><div><br /></div><div>SQL이든 <span style=\"font-size: x-small;\">(엘라스틱/스플렁크 등의)</span> NoSQL이든, 세상 모든 DB는 문자열 데이터를 깎고 다듬어 테이블 구조로 바꾸는 전처리 작업을 필수로 거친다. 그래야 데이터 분석을 시작할 수 있으니까.</div><blockquote><blockquote style=\"text-align: center;\"><i><a href=\"https://kangmyounghun.blogspot.com/2016/06/blog-post_12.html\" target=\"_blank\">데이터는 테이블이다</a></i></blockquote><span style=\"font-size: x-small;\"></span></blockquote><br />데이터를 분석하려면 <strike><span style=\"font-size: x-small;\">엘라스틱이나 스플렁크가 아닌</span></strike> 데이터를 잘 알아야 한다. <span style=\"font-size: x-small;\">(의미 파악은 기본이고)</span> 전체적인 구조는 어떤지, 내 목적에 맞는 범위는 어딘지, 그 범위의 데이터를 어떻게 가공해야 원하는 분석이 가능한지에 대한 감을 잡을 수 있어야 한다. 이런 감각을 일깨워주는 가장 확실한 방법은 결국 데이터를 직접 만져보는 것.&nbsp;<div><i><a href=\"goog_933725584\"></a></i><blockquote style=\"text-align: center;\"><i><a href=\"https://www.joongang.co.kr/article/23409057\" target=\"_blank\">프로젝트에서 데이터의 공간 변환, 공간 탐색 등의 전문적 단계에 진입하기 전에 학생들에게 데이터를 가지고 온갖 자질구레한 관찰을 해보도록 강제한다. 데이터의 질감을 느끼는 단계다. 이 과정에서 통찰과 관점이 생긴다</a></i></blockquote></div><div><br /></div><div>이런 경험을 가장 쉽게 할 수 있는 환경이 바로 리눅스. 목적에 맞는 셋팅을 시도하는 과정에서 기본 편집기인 VIM을 사용할 수밖에 없으니까.&nbsp;</div><div><br /></div><div><b><span style=\"font-size: x-large;\">문자열 데이터를 다루는 감을 익히는 데 문자열 편집기보다 더 좋은 툴이 있을까?&nbsp;</span></b></div><div><br /></div><div>꼭 VIM 때문에만 리눅스 경험을 주문하는 것도 아니다. 사실 리눅스는 운영체제 자체가 문자열 데이터 처리를 위한 종합선물세트라고 해도 과언이 아니기 때문.</div><div><br /></div>\n<div>웹로그 메소드 발생 내역</div>\n<div class=\"colorscripter-code\" style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; overflow: auto; position: relative;\"><table cellpadding=\"0\" cellspacing=\"0\" class=\"colorscripter-code-table\" style=\"background-color: #fafafa; border-radius: 4px; border: none; margin: 0px; padding: 0px;\"><tbody><tr><td style=\"padding: 6px 0px; text-align: left;\"><div style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; line-height: 130%; margin: 0px; padding: 0px;\"><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">root@MHKANG:~<span style=\"color: #999999;\">#&nbsp;awk&nbsp;'{print&nbsp;$6}'&nbsp;2014.log&nbsp;|                             </span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;awk&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>F&nbsp;<span style=\"color: #63a35c;\">'\"'</span>&nbsp;<span style=\"color: #63a35c;\">'{print&nbsp;$2}'</span>&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;sort&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>u</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">CONNECT</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">GET</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">HEAD</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">POST</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">quit</div></div><div style=\"font-size: 9px; font-style: italic; margin-right: 5px; margin-top: -13px; text-align: right;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: #e5e5e5text-decoration:none;\" target=\"_blank\">Colored by Color Scripter</a></div></td><td style=\"padding: 0px 2px 4px 0px; vertical-align: bottom;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: white; text-decoration: none;\" target=\"_blank\"><span style=\"background-color: #e5e5e5; border-radius: 10px; color: white; font-size: 9px; padding: 1px; word-break: normal;\">cs</span></a></td></tr></tbody></table></div>\n<div><br /></div>\n<div>메소드 고유개수1</div>\n<div class=\"colorscripter-code\" style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; overflow: auto; position: relative;\"><table cellpadding=\"0\" cellspacing=\"0\" class=\"colorscripter-code-table\" style=\"background-color: #fafafa; border-radius: 4px; border: none; margin: 0px; padding: 0px;\"><tbody><tr><td style=\"padding: 6px 0px; text-align: left;\"><div style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; line-height: 130%; margin: 0px; padding: 0px;\"><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">root@MHKANG:~<span style=\"color: #999999;\">#&nbsp;awk&nbsp;'{print&nbsp;$6}'&nbsp;2014.log&nbsp;|                             </span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;awk&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>F&nbsp;<span style=\"color: #63a35c;\">'\"'</span>&nbsp;<span style=\"color: #63a35c;\">'{print&nbsp;$2}'</span>&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;sort&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>u&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;wc&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>l</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0099cc;\">6</span></div></div><div style=\"font-size: 9px; font-style: italic; margin-right: 5px; margin-top: -13px; text-align: right;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: #e5e5e5text-decoration:none;\" target=\"_blank\">Colored by Color Scripter</a></div></td><td style=\"padding: 0px 2px 4px 0px; vertical-align: bottom;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: white; text-decoration: none;\" target=\"_blank\"><span style=\"background-color: #e5e5e5; border-radius: 10px; color: white; font-size: 9px; padding: 1px; word-break: normal;\">cs</span></a></td></tr></tbody></table></div>\n<div><br /></div>\n<div>메소드 고유개수2</div>\n<div class=\"colorscripter-code\" style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; overflow: auto; position: relative;\"><table cellpadding=\"0\" cellspacing=\"0\" class=\"colorscripter-code-table\" style=\"background-color: #fafafa; border-radius: 4px; border: none; margin: 0px; padding: 0px;\"><tbody><tr><td style=\"padding: 6px 0px; text-align: left;\"><div style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; line-height: 130%; margin: 0px; padding: 0px;\"><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">root@MHKANG:~<span style=\"color: #999999;\">#&nbsp;awk&nbsp;'{print&nbsp;$6}'&nbsp;2014.log&nbsp;|                             </span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;awk&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>F&nbsp;<span style=\"color: #63a35c;\">'\"'</span>&nbsp;<span style=\"color: #63a35c;\">'{print&nbsp;$2}'</span>&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;awk&nbsp;<span style=\"color: #63a35c;\">'arr[$1]==\"\"&nbsp;{arr[$1]=\"x\"}&nbsp;END&nbsp;{print&nbsp;length(arr)}'</span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0099cc;\">6</span></div></div><div style=\"font-size: 9px; font-style: italic; margin-right: 5px; margin-top: -13px; text-align: right;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: #e5e5e5text-decoration:none;\" target=\"_blank\">Colored by Color Scripter</a></div></td><td style=\"padding: 0px 2px 4px 0px; vertical-align: bottom;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: white; text-decoration: none;\" target=\"_blank\"><span style=\"background-color: #e5e5e5; border-radius: 10px; color: white; font-size: 9px; padding: 1px; word-break: normal;\">cs</span></a></td></tr></tbody></table></div>\n<div><br /></div>\n<div>변수 고유개수</div>\n<div class=\"colorscripter-code\" style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; overflow: auto; position: relative;\"><table cellpadding=\"0\" cellspacing=\"0\" class=\"colorscripter-code-table\" style=\"background-color: #fafafa; border-radius: 4px; border: none; margin: 0px; padding: 0px;\"><tbody><tr><td style=\"padding: 6px 0px; text-align: left;\"><div style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; line-height: 130%; margin: 0px; padding: 0px;\"><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">root@MHKANG:~<span style=\"color: #999999;\">#&nbsp;awk&nbsp;'{if&nbsp;($7&nbsp;~&nbsp;/\\?/)&nbsp;print&nbsp;$7}'&nbsp;2014.log&nbsp;|              </span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;awk&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>F&nbsp;<span style=\"color: #63a35c;\">'?'</span>&nbsp;<span style=\"color: #63a35c;\">'{print&nbsp;$2}'</span>&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;sort&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>u&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;wc&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>l</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0099cc;\">63349</span></div></div><div style=\"font-size: 9px; font-style: italic; margin-right: 5px; margin-top: -13px; text-align: right;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: #e5e5e5text-decoration:none;\" target=\"_blank\">Colored by Color Scripter</a></div></td><td style=\"padding: 0px 2px 4px 0px; vertical-align: bottom;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: white; text-decoration: none;\" target=\"_blank\"><span style=\"background-color: #e5e5e5; border-radius: 10px; color: white; font-size: 9px; padding: 1px; word-break: normal;\">cs</span></a></td></tr></tbody></table></div>\n<div><br /></div>\n<div>변수 고유개수 차원 축소1</div>\n<div class=\"colorscripter-code\" style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; overflow: auto; position: relative;\"><table cellpadding=\"0\" cellspacing=\"0\" class=\"colorscripter-code-table\" style=\"background-color: #fafafa; border-radius: 4px; border: none; margin: 0px; padding: 0px;\"><tbody><tr><td style=\"padding: 6px 0px; text-align: left;\"><div style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; line-height: 130%; margin: 0px; padding: 0px;\"><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">root@MHKANG:~<span style=\"color: #999999;\">#&nbsp;awk&nbsp;'{if&nbsp;($7&nbsp;~&nbsp;/\\?/)&nbsp;print&nbsp;$7}'&nbsp;2014.log&nbsp;|             &nbsp;</span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;awk&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>F&nbsp;<span style=\"color: #63a35c;\">'?'</span>&nbsp;<span style=\"color: #63a35c;\">'{print&nbsp;$2}'</span>&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span>&nbsp;</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;sed&nbsp;<span style=\"color: #63a35c;\">'s/[0-9]//g'</span>&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span>&nbsp;</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;sort&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>u&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span>&nbsp;</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;wc&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>l</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0099cc;\">330</span></div></div><div style=\"font-size: 9px; font-style: italic; margin-right: 5px; margin-top: -13px; text-align: right;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: #e5e5e5text-decoration:none;\" target=\"_blank\">Colored by Color Scripter</a></div></td><td style=\"padding: 0px 2px 4px 0px; vertical-align: bottom;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: white; text-decoration: none;\" target=\"_blank\"><span style=\"background-color: #e5e5e5; border-radius: 10px; color: white; font-size: 9px; padding: 1px; word-break: normal;\">cs</span></a></td></tr></tbody></table></div>\n<div><br /></div><div>변수 고유개수 차원 축소2</div>\n<div class=\"colorscripter-code\" style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; overflow: auto; position: relative;\"><table cellpadding=\"0\" cellspacing=\"0\" class=\"colorscripter-code-table\" style=\"background-color: #fafafa; border-radius: 4px; border: none; margin: 0px; padding: 0px;\"><tbody><tr><td style=\"padding: 6px 0px; text-align: left;\"><div style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; line-height: 130%; margin: 0px; padding: 0px;\"><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">root@MHKANG:~<span style=\"color: #999999;\">#&nbsp;awk&nbsp;'{if&nbsp;($7&nbsp;~&nbsp;/\\?/)&nbsp;print&nbsp;$7}'&nbsp;2014.log&nbsp;|&nbsp;             </span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;awk&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>F&nbsp;<span style=\"color: #63a35c;\">'?'</span>&nbsp;<span style=\"color: #63a35c;\">'{print&nbsp;$2}'</span>&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span>&nbsp;</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;awk&nbsp;<span style=\"color: #63a35c;\">'{gsub(\"[0-9]\",&nbsp;\"\")}1'</span>&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span>&nbsp;</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;sort&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>u&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span>&nbsp;</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;wc&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>l</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0099cc;\">330</span></div></div><div style=\"font-size: 9px; font-style: italic; margin-right: 5px; margin-top: -13px; text-align: right;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: #e5e5e5text-decoration:none;\" target=\"_blank\">Colored by Color Scripter</a></div></td><td style=\"padding: 0px 2px 4px 0px; vertical-align: bottom;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: white; text-decoration: none;\" target=\"_blank\"><span style=\"background-color: #e5e5e5; border-radius: 10px; color: white; font-size: 9px; padding: 1px; word-break: normal;\">cs</span></a></td></tr></tbody></table></div>\n<div><br /></div>\n<div>이런 경험이 쌓이고 모여 데이터를 다루는 감각을 키워준다. 그런데 이 모든 작업이 VIM이라는 하나의 툴에서 다 가능하다. 정규표현식 지원 범위도 훨씬 넓다.</div><div><br /></div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg3VOMoSs-U2o0bkxu43iFAEJ_rJfOtii3m0NO4rdZ9vpoU7o0yUhXT2EWDZD9JCu2TBmfm-pBRd3sGp-GrEzmsSC0zgNDR7KoSmf63GvzfKc2EtkNCke48a3GzINWsyRyZeHhSfHdLNbZaaBkS7u13j1qUjneeclgNmzGZ61XFjz_s0yTCA7kaEPe6BlHl/s627/4a37d798-cb48-423c-a096-812ff4b848f6.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"627\" data-original-width=\"480\" height=\"320\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg3VOMoSs-U2o0bkxu43iFAEJ_rJfOtii3m0NO4rdZ9vpoU7o0yUhXT2EWDZD9JCu2TBmfm-pBRd3sGp-GrEzmsSC0zgNDR7KoSmf63GvzfKc2EtkNCke48a3GzINWsyRyZeHhSfHdLNbZaaBkS7u13j1qUjneeclgNmzGZ61XFjz_s0yTCA7kaEPe6BlHl/s320/4a37d798-cb48-423c-a096-812ff4b848f6.png\" width=\"245\" /></a></div><br /></div><div><b>관련 글</b></div><div><ul style=\"text-align: left;\"><li><a href=\"https://kangmyounghun.blogspot.com/2025/07/vim-vs-awk.html\">VIM vs AWK</a></li><li><a href=\"http://kangmyounghun.blogspot.kr/2016/07/vim.html\" target=\"\">VIM 사용 설명서</a></li></ul></div>",
        "contentSnippet": "강의 이해를 위해 요구되는 사전 지식들.\n\n\n\n\n\n필수 요건으로로 못박고 싶지만 그랬다간 망할까봐 권장으로 타협. 출강 기관 측은 아예 빼자고 하는데 그러고 싶진 않다. 내 강의 정체성이기 때문.\n\n\n세상 모든 데이터는 문자열\n\n\nSQL이든 (엘라스틱/스플렁크 등의) NoSQL이든, 세상 모든 DB는 문자열 데이터를 깎고 다듬어 테이블 구조로 바꾸는 전처리 작업을 필수로 거친다. 그래야 데이터 분석을 시작할 수 있으니까.\n\n데이터는 테이블이다\n\n데이터를 분석하려면 엘라스틱이나 스플렁크가 아닌 데이터를 잘 알아야 한다. (의미 파악은 기본이고) 전체적인 구조는 어떤지, 내 목적에 맞는 범위는 어딘지, 그 범위의 데이터를 어떻게 가공해야 원하는 분석이 가능한지에 대한 감을 잡을 수 있어야 한다. 이런 감각을 일깨워주는 가장 확실한 방법은 결국 데이터를 직접 만져보는 것. \n\n프로젝트에서 데이터의 공간 변환, 공간 탐색 등의 전문적 단계에 진입하기 전에 학생들에게 데이터를 가지고 온갖 자질구레한 관찰을 해보도록 강제한다. 데이터의 질감을 느끼는 단계다. 이 과정에서 통찰과 관점이 생긴다\n\n\n이런 경험을 가장 쉽게 할 수 있는 환경이 바로 리눅스. 목적에 맞는 셋팅을 시도하는 과정에서 기본 편집기인 VIM을 사용할 수밖에 없으니까. \n\n\n문자열 데이터를 다루는 감을 익히는 데 문자열 편집기보다 더 좋은 툴이 있을까? \n\n\n꼭 VIM 때문에만 리눅스 경험을 주문하는 것도 아니다. 사실 리눅스는 운영체제 자체가 문자열 데이터 처리를 위한 종합선물세트라고 해도 과언이 아니기 때문.\n\n\n웹로그 메소드 발생 내역\n\n\nroot@MHKANG:~# awk '{print $6}' 2014.log |                             \n> awk -F '\"' '{print $2}' |\n> sort -u\n-\nCONNECT\nGET\nHEAD\nPOST\nquit\n\nColored by Color Scripter\ncs\n\n\n\n\n메소드 고유개수1\n\n\nroot@MHKANG:~# awk '{print $6}' 2014.log |                             \n> awk -F '\"' '{print $2}' |\n> sort -u |\n> wc -l\n6\n\nColored by Color Scripter\ncs\n\n\n\n\n메소드 고유개수2\n\n\nroot@MHKANG:~# awk '{print $6}' 2014.log |                             \n> awk -F '\"' '{print $2}' |\n> awk 'arr[$1]==\"\" {arr[$1]=\"x\"} END {print length(arr)}'\n6\n\nColored by Color Scripter\ncs\n\n\n\n\n변수 고유개수\n\n\nroot@MHKANG:~# awk '{if ($7 ~ /\\?/) print $7}' 2014.log |              \n> awk -F '?' '{print $2}' |\n> sort -u |\n> wc -l\n63349\n\nColored by Color Scripter\ncs\n\n\n\n\n변수 고유개수 차원 축소1\n\n\nroot@MHKANG:~# awk '{if ($7 ~ /\\?/) print $7}' 2014.log |              \n> awk -F '?' '{print $2}' | \n> sed 's/[0-9]//g' | \n> sort -u | \n> wc -l\n330\n\nColored by Color Scripter\ncs\n\n\n\n\n변수 고유개수 차원 축소2\n\n\nroot@MHKANG:~# awk '{if ($7 ~ /\\?/) print $7}' 2014.log |              \n> awk -F '?' '{print $2}' | \n> awk '{gsub(\"[0-9]\", \"\")}1' | \n> sort -u | \n> wc -l\n330\n\nColored by Color Scripter\ncs\n\n\n\n\n이런 경험이 쌓이고 모여 데이터를 다루는 감각을 키워준다. 그런데 이 모든 작업이 VIM이라는 하나의 툴에서 다 가능하다. 정규표현식 지원 범위도 훨씬 넓다.\n\n\n\n\n관련 글\n\nVIM vs AWK\nVIM 사용 설명서",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-6996994550640788536",
        "isoDate": "2025-08-24T04:04:00.002Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": [
      {
        "creator": "고명환",
        "title": "'국민 명함앱' 리멤버 5,000억대 M&amp;A&nbsp; - 왜 지금, 왜 이 가격인가?",
        "link": "https://brunch.co.kr/@@LOc/309",
        "pubDate": "Thu, 21 Aug 2025 03:00:10 GMT",
        "author": "고명환",
        "content": "1. 딜 한눈에 보기(Deal snapshot)  거래 구조 : 글로벌 PEF EQT가 기존 최대주주 아크앤파트너스(Ark &amp; Partners)의 경영권 지분(약 47%)을 인수하는 SPA 체결. 지분 100% 기준 기업가치 &lsquo;5,000억대 중반&rsquo; 평가. 타 주요 주주(라인플러스, 사람인HR) 지분 협의 병행. 성과 트랙 : 아크는 2021년 말 약 1,0<img src= \"https://img1.daumcdn.net/thumb/R1280x0.fjpg/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FzV99s2cEjhUKawRldIZ1fDGniqI.JPG\" width=\"500\" />",
        "contentSnippet": "1. 딜 한눈에 보기(Deal snapshot)  거래 구조 : 글로벌 PEF EQT가 기존 최대주주 아크앤파트너스(Ark & Partners)의 경영권 지분(약 47%)을 인수하는 SPA 체결. 지분 100% 기준 기업가치 ‘5,000억대 중반’ 평가. 타 주요 주주(라인플러스, 사람인HR) 지분 협의 병행. 성과 트랙 : 아크는 2021년 말 약 1,0",
        "guid": "https://brunch.co.kr/@@LOc/309",
        "isoDate": "2025-08-21T03:00:10.000Z"
      }
    ]
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "콘텐츠 제작 혁명! 무료 GPTS 3종으로 초고속, 고품질 콘텐츠 만드는 법",
        "link": "http://muzbox.tistory.com/483647",
        "pubDate": "Mon, 25 Aug 2025 19:08:36 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483647#entry483647comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #3c4043;\">\n<div style=\"background-color: #e8f4fd; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">단 하나의 아이디어, 사진, 혹은 링크만으로도 전문가 수준의 콘텐츠를 뚝딱! 제가 직접 개발한 <b>무료 GPTS 3종</b>으로 인스타그램, 스레드 맞춤 콘텐츠는 물론, AI 음악 작곡, 그리고 SEO 최적화 블로그 글까지 초고속으로, 그것도 고품질로 만드는 비법을 공개합니다. 콘텐츠 제작의 새로운 지평을 경험해보세요!</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✨ 콘텐츠 제작, 왜 이렇게 어려울까요?</b></h2>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"무료GPTS 3종공개.jpeg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/biHiV8/btsP4g0tCiw/eNrCa81Lt63UMDeldqRh9K/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/biHiV8/btsP4g0tCiw/eNrCa81Lt63UMDeldqRh9K/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/biHiV8/btsP4g0tCiw/eNrCa81Lt63UMDeldqRh9K/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbiHiV8%2FbtsP4g0tCiw%2FeNrCa81Lt63UMDeldqRh9K%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"콘텐츠 제작 혁명! 무료 GPTS 3종으로 초고속, 고품질 콘텐츠 만드는 법\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"무료GPTS 3종공개.jpeg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;정말 많은 분들이 콘텐츠 제작의 어려움에 공감하실 거예요. 어떤 플랫폼에 맞춰서 글을 써야 할지, 눈길을 사로잡는 이미지는 어떻게 만들지, 심지어는 나만의 배경 음악까지&hellip; 창작의 과정은 늘 끝없는 고민과 시행착오의 연속이었습니다. 제가 겪어본 바로는, 아이디어가 있어도 그걸 현실로 구현하는 과정에서 지쳐버리는 경우가 정말 많았죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">하지만 오늘, 이러한 고충을 한 번에 날려버릴 수 있는 제가 직접 만든 <b>세 가지 특별한 GPTS</b>를 소개해 드릴까 합니다. 이 도구들은 단순한 글쓰기 보조를 넘어, 각 플랫폼의 특성에 맞춰 콘텐츠를 최적화하고, 복잡한 음악 생성 프롬프트를 자동으로 만들어주며, 심지어는 SEO까지 고려한 블로그 포스트를 HTML 코드로 척척 완성해 준답니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이제는 아이디어나 사진 한 장, 아니면 그저 블로그 링크 하나만으로도 각 분야의 전문가처럼 콘텐츠를 손쉽게 제작할 수 있는 새로운 시대가 열렸다고 해도 과언이 아닙니다. 많은 분들이 '지피티팍인데 왜 GPT만 소개하나요?'라고 궁금해하실 텐데요. 기존 챗GPT 사용자분들이 많고, GPT를 활용한 무료 연재 기획의 일환으로 이번 GPTS들을 먼저 선보이게 되었습니다. 자, 그럼 바로 시작해볼까요?</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  챗 지피티, 인스타 앤 쓰레드 맞춤 콘텐츠 제작소: 플랫폼별 최적화의 마법</b></h2>\n<p data-ke-size=\"size16\">&nbsp;첫 번째로 소개해 드릴 GPTS는 바로 <b>'챗 지피티, 인스타 앤 쓰레드 맞춤 콘텐츠 제작소'</b>입니다. 이 GPTS의 핵심은 <b>플랫폼별 맞춤화</b>예요. 같은 내용이라도 쓰레드와 인스타그램에서는 전혀 다른 접근 방식이 필요하다는 것을 여러분도 잘 아실 거예요. 이 GPTS는 사용자의 요청에 따라 \"어떤 플랫폼에 맞춰 드릴까요?\"라고 물어보며, 마치 플랫폼 전문가처럼 콘텐츠를 재구성해줍니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; font-weight: 600;\" data-ke-size=\"size23\">✔️ 쓰레드(Threads) 콘텐츠 제작의 비밀</h3>\n<p data-ke-size=\"size16\">쓰레드는 정말 빠르게 정보를 소비하는 플랫폼이죠? 그래서 이 GPTS는 <b>간결하고 강렬한 문장</b>으로 콘텐츠를 만듭니다. 제가 직접 써보니, 경어체 대신 친근한 반말체를 사용하고, 사용자의 주의를 즉시 끌 수 있는 임팩트 있는 '후크 메시지'로 시작해서 핵심 정보를 번호로 나열하는 방식이 정말 효과적이더라구요.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; font-weight: 600;\" data-ke-size=\"size23\">✔️ 인스타그램(Instagram) 감성 콘텐츠의 완성</h3>\n<p data-ke-size=\"size16\">반면 인스타그램은 시각적 요소와 커뮤니티가 중심입니다. 그래서 이 GPTS는 <b>친근한 경어체</b>를 사용해 팔로워들과 대화하듯 접근하고, 텍스트뿐만 아니라 <b>이미지 컨셉까지 함께 제안</b>해줍니다. 인포그래픽과 상세한 캡션, 그리고 필수 해시태그까지, 그야말로 완성형 콘텐츠를 만들어주는 거죠. 솔직히 저도 매번 놀랍니다.</p>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>GPTS 활용 Tip:</b> 단 하나의 아이디어, 블로그 링크, 혹은 사진만으로도 인스타그램과 쓰레드에 최적화된 콘텐츠를 만들 수 있어요. 블로그 포스팅 후 쓰레드에 요약 내용을 올릴 때 정말 편리하답니다!</div>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; font-weight: 600;\" data-ke-size=\"size23\">실제 작동 사례 살펴보기</h3>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>명언 콘텐츠 제작:</b> 대화창에 \"마음 챙김 명언 2개\"를 입력한 후 인스타그램을 선택하면, 명언과 함께 인스타그램에 적합한 메시지, 해시태그가 작성되고 이미지 생성 여부를 물어봅니다. 몇 가지 질문에 응답하면 메시지에 맞는 이미지 생성 프롬프트가 출력되고, 잠시 후 멋진 이미지가 생성됩니다.</li>\n<li><b>블로그 요약 &amp; 공유:</b> 블로그 주소를 입력하면 기사를 요약하고 플랫폼 선택을 요청합니다. 쓰레드를 선택하면 이모지와 함께 쓰레드에 적합한 후크 메시지가 생성되고, 이미지 생성도 가능하죠.</li>\n<li><b>사진 기반 메시지:</b> 사진을 업로드하고 적합한 메시지를 요청한 뒤 인스타그램을 선택하면, 사진을 분석해 사진에 맞는 메시지와 해시태그를 인스타그램 형식에 맞춰 출력해줍니다. 정말 스마트하지 않나요?</li>\n</ul>\n<p data-ke-size=\"size16\">보신 것처럼, 이 GPTS는 단순히 글을 쓰는 것을 넘어, 각 플랫폼의 특성을 정확히 이해하고 최적의 콘텐츠를 완성해 줍니다. 이제 여러분의 콘텐츠 제작이 훨씬 더 스마트해질 거예요!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h4 data-ke-size=\"size20\"><i><span style=\"color: #ef5369;\"><b>챗GPT 인스타 &amp; 쓰레드 맞춤 콘텐츠 제작소 바로가기</b></span></i></h4>\n<figure id=\"og_1756116397686\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"ChatGPT - 챗GPT 인스타 &amp; 쓰레드 맞춤 콘텐츠 제작소\" data-og-description=\"이야기를 들어주고, 배우고, 도전하는 대화형 AI 시스템\" data-og-host=\"chatgpt.com\" data-og-source-url=\"https://chatgpt.com/g/g-sPwysm1aN-caesgpt-inseuta-sseuredeu-majcum-kontenceu-jejagso\" data-og-url=\"https://chatgpt.com/?locale=ko-KR\" data-og-image=\"\"><a href=\"https://chatgpt.com/g/g-sPwysm1aN-caesgpt-inseuta-sseuredeu-majcum-kontenceu-jejagso\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://chatgpt.com/g/g-sPwysm1aN-caesgpt-inseuta-sseuredeu-majcum-kontenceu-jejagso\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">ChatGPT - 챗GPT 인스타 &amp; 쓰레드 맞춤 콘텐츠 제작소</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">이야기를 들어주고, 배우고, 도전하는 대화형 AI 시스템</p>\n<p class=\"og-host\" data-ke-size=\"size16\">chatgpt.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  수노 4.5 프롬프트 제네레이터: 나만의 AI 음악 작곡가</b></h2>\n<p data-ke-size=\"size16\">두 번째 GPTS는 바로 <b>'수노 4.5 프롬프트 제네레이터'</b>입니다. 이 GPTS는 수노(Suno) 부문에서 글로벌 5위를 자랑하고, 'AI로 노래를 만들어 1억 번 남자'가 사용했다는 바로 그 도구입니다. 말 그대로 AI 음악 작곡의 혁명을 가져왔다고 할 수 있죠.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; font-weight: 600;\" data-ke-size=\"size23\">수노 4.5, 무엇이 달라졌나?</h3>\n<p data-ke-size=\"size16\">최고의 인공지능 프롬프트 기반 음악 생성 서비스인 수노가 버전 4.5로 업데이트되면서, 이전 4.0 버전과는 완전히 다른 차원의 프롬프트가 필요해졌습니다. 기존 4.0은 간결한 형태로 기본적인 음악 특성에만 집중했지만, 4.5부터는 <b>음향 텍스처, 악기 간 상호작용, 섹션별 전개</b>까지 구체적으로 설명하는 <b>전문적이고 세밀한 프롬프트</b>가 필수적이 되었죠. 바로 이러한 변화에 대응하기 위해 이 GPTS를 만들게 되었습니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; font-weight: 600;\" data-ke-size=\"size23\">90가지 히트곡 장르 데이터베이스의 힘</h3>\n<p data-ke-size=\"size16\">이 GPTS의 가장 특별한 기능은 바로 <b>글로벌 대표 히트곡 아흔 가지 장르별 데이터베이스</b>를 활용한다는 점입니다. 제가 직접 조사하고 정리한 PDF 문서에는 각 장르별 수노 프롬프트 예시와 구조 형식이 담겨 있는데, 이 GPTS는 사용자의 키워드에 가장 적합한 구조를 자동으로 찾아 적용해줍니다. 가사 생성 원리도 체계적이라, 프롬프트 생성 후 가사가 필요한지 물어보고 요청하면 해당 장르에 맞는 구조를 PDF에서 찾아 참조하여 멋진 가사를 만들어냅니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; font-weight: 600;\" data-ke-size=\"size23\">나만의 곡 만들기, 어렵지 않아요!</h3>\n<div style=\"background-color: #e8f0fe; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">\n<p data-ke-size=\"size16\">채팅창에 다음과 같이 입력해 보세요:</p>\n<ul style=\"margin-top: 10px; padding-left: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px;\"><b>'새로운 아침을 운동과 함께 시작하면서 듣는 시티팝 뮤직'</b></li>\n<li style=\"margin-bottom: 5px;\"><b>'마블 어벤저스 주제곡 느낌' (연주곡)</b></li>\n<li><b>'나훈아의 고향역' (가수와 곡 스타일)</b></li>\n</ul>\n</div>\n<p data-ke-size=\"size16\">이런 요청사항에 적합한 음악 생성 프롬프트(4.0 및 4.5 버전)가 생성되고, 가사 생성 여부를 묻습니다. 한국어 가사를 요청하면 아흔 가지 노래 목록에서 적합한 구조를 찾아 가사를 생성해줍니다. 심지어 '나훈아의 고향역'처럼 유명한 곡은 트로트 장르임을 인식하고 한국 고전 트로트 스타일의 프롬프트와 가사를 생성해내는 것을 보고 정말 놀랐습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이제 수노로 가서 GPTS가 생성한 음악 스타일, 노래 제목, 그리고 가사를 붙여넣고 생성 버튼만 누르면 작업 완료! 누구나 마음속에 품고 있던 자신만의 노래를 세상 밖으로 꺼내기가 막막하셨다면, '수노 4.5 프롬프트 제네레이터'가 여러분의 숨겨진 음악적 재능을 깨워줄 겁니다. 지금 바로 여러분의 이야기를 노래로 만들어보세요. 저도 얼마 전에 이 기능을 이용해서 기념일 축하곡을 만들었는데, 반응이 정말 좋았어요!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h4 data-ke-size=\"size20\"><span style=\"color: #ef5369;\"><i><b>Suno 4.5 Prompt Generator 바로가기</b></i></span></h4>\n<figure id=\"og_1756116424686\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"ChatGPT - Suno 4.5 Prompt Generator\" data-og-description=\"이야기를 들어주고, 배우고, 도전하는 대화형 AI 시스템\" data-og-host=\"chatgpt.com\" data-og-source-url=\"https://chatgpt.com/g/g-681480f8a4688191b94abd2af3c3390a-suno-4-5-prompt-generator\" data-og-url=\"https://chatgpt.com/?locale=ko-KR\" data-og-image=\"\"><a href=\"https://chatgpt.com/g/g-681480f8a4688191b94abd2af3c3390a-suno-4-5-prompt-generator\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://chatgpt.com/g/g-681480f8a4688191b94abd2af3c3390a-suno-4-5-prompt-generator\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">ChatGPT - Suno 4.5 Prompt Generator</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">이야기를 들어주고, 배우고, 도전하는 대화형 AI 시스템</p>\n<p class=\"og-host\" data-ke-size=\"size16\">chatgpt.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✍️ 시각화 블로그 기사 생성 GPTS: SEO 최적화 블로그 자동화</b></h2>\n<p data-ke-size=\"size16\">마지막으로 소개해 드릴 GPTS는 바로 <b>'시각화 블로그 기사 생성 GPTS'</b>입니다. 이 도구는 사용자가 간단한 주제나 키워드만 입력하면, <b>완전한 HTML 형식의 고품질 블로그 포스트</b>를 자동으로 생성해주는, 제가 정말 애정하는 GPTS입니다.</p>\n<div style=\"background-color: #fce8e6; border-left: 4px solid #d93025; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">⚠️ <b>중요 소식:</b> 그동안 HTML 소스 배포에 컨텍스트 용량 부족의 어려움이 있었지만, 이번 <b>GPT-5 업데이트</b>로 문제가 해결되어 챗GPT에서도 동일한 수준의 HTML 블로그 기사 생성이 가능해졌습니다! 플러스 사용자 기준으로 기존 8K 토큰에서 32K 토큰으로 약 4배 증가한 덕분이죠. 이제 3,000자 분량의 HTML 블로그 포스트를 한 번에 완성할 수 있어요.</div>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; font-weight: 600;\" data-ke-size=\"size23\">GPTs의 4단계 HTML 생성 원리</h3>\n<p data-ke-size=\"size16\">이 GPTS는 총 4단계의 체계적인 과정을 거쳐 블로그 기사를 HTML로 생성합니다. 정말 효율적이죠!</p>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>카테고리 선택:</b> 블로그 주제를 정하지 못했다면, 먼저 분야별 주제를 요청해 보세요. 재정 투자, IT 기술 등 총 8개의 카테고리 중 선택하면 GPT가 적절한 주제를 제안합니다.</li>\n<li><b>주제 보강 검토:</b> 선택된 주제가 사용자가 요청한 분량(글자 수)에 적합한지 검토합니다. 만약 분량이 부족할 것으로 예상되면, GPT가 주제를 보강해서 제안해줍니다. 이 과정이 글의 완성도를 높이는 데 아주 중요해요.</li>\n<li><b>컬러 테마 선택:</b> 총 10가지 컬러 테마 중에서 선택합니다. 이 테마에 따라 HTML 소스에 적용될 색상이 결정되어 시각적으로 아름다운 블로그를 만들 수 있습니다.</li>\n<li><b>HTML 생성:</b> 선택된 테마에 맞는 완전한 HTML 코드를 생성합니다. HTML 생성 완료 후에는 핵심 키워드, 대표 이미지 생성 프롬프트, SEO 최적화 제목 5개 등의 추가 정보와 함께 <b>스키마까지 자동으로 출력</b>되어 완벽한 SEO 최적화가 가능합니다.</li>\n</ol>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; font-weight: 600;\" data-ke-size=\"size23\">어떻게 활용할 수 있을까요?</h3>\n<p data-ke-size=\"size16\">카테고리를 선택하여 진행하거나, 바로 주제를 입력하는 두 가지 방식으로 활용할 수 있습니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>카테고리 선택 예시:</b> 첫 화면에서 '분야별 블로그 주제를 제안해줘'를 클릭한 후, 예를 들어 2번 'IT, 기술' 분야를 선택합니다. GPT가 IT 관련 주제를 보여주는데, 여기서 하나를 선택하면 분량이 부족할 경우 주제를 자동으로 보강해줍니다. 그 다음 컬러 테마를 선택하면 바로 기사 작성 계획을 보여주며 HTML 기사를 생성합니다.</li>\n<li><b>주제 직접 입력 예시:</b> 대화창에 \"건강한 사람들의 아침 루틴\"과 같은 주제를 직접 입력해 보세요. 그러면 카테고리 선택 때와 동일하게 분량 조절을 위해 주제를 보강하고, 컬러 테마 선택 후 바로 기사를 작성합니다. 만약 생성된 기사 분량이 생각보다 적다면, \"관련된 섹션을 2개 더 추가하고 기사를 확장해\"라고 요청하여 풍부한 내용의 기사를 만들 수 있습니다.</li>\n</ul>\n<p data-ke-size=\"size16\">이처럼 '시각화 블로그 기사 생성 GPTS'를 활용하면 몇 번의 클릭과 간단한 요청만으로 <b>SEO까지 완벽하게 최적화된 고품질의 블로그 포스트</b>를 손쉽게 완성할 수 있습니다. 코드펜에서 결과물을 확인해보면, 정말 문제없이 기사가 잘 작성된 것을 볼 수 있을 거예요. 블로그 콘텐츠 제작의 효율을 극대화하고 싶다면 이 강력한 도구를 꼭 사용해보시길 바랍니다!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h4 data-ke-size=\"size20\"><span style=\"color: #ef5369;\"><i><b>시각화 블로그 기사 생성 바로가기</b></i></span></h4>\n<figure id=\"og_1756116453697\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"ChatGPT - 시각화 블로그 기사 생성\" data-og-description=\"이야기를 들어주고, 배우고, 도전하는 대화형 AI 시스템\" data-og-host=\"chatgpt.com\" data-og-source-url=\"https://chatgpt.com/g/g-68a79cc071288191b22eeb89edeb0608-sigaghwa-beulrogeu-gisa-saengseong\" data-og-url=\"https://chatgpt.com/?locale=ko-KR\" data-og-image=\"\"><a href=\"https://chatgpt.com/g/g-68a79cc071288191b22eeb89edeb0608-sigaghwa-beulrogeu-gisa-saengseong\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://chatgpt.com/g/g-68a79cc071288191b22eeb89edeb0608-sigaghwa-beulrogeu-gisa-saengseong\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">ChatGPT - 시각화 블로그 기사 생성</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">이야기를 들어주고, 배우고, 도전하는 대화형 AI 시스템</p>\n<p class=\"og-host\" data-ke-size=\"size16\">chatgpt.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<style>\n    /* This style block ensures the summary card is responsive on mobile devices. */\n    @media (max-width: 768px) {\n        .single-summary-card {\n            padding: 18px !important;\n        }\n        .single-summary-card .card-header-icon {\n            font-size: 28px !important;\n            margin-right: 10px !important;\n        }\n        .single-summary-card .card-header h3 {\n            font-size: 20px !important;\n        }\n        .single-summary-card .card-content {\n            font-size: 15px !important;\n            line-height: 1.5 !important;\n        }\n        .single-summary-card .card-content .section {\n            margin-bottom: 8px !important;\n        }\n        .single-summary-card .card-footer {\n            font-size: 13px !important;\n            padding-top: 10px !important;\n        }\n    }\n    @media (max-width: 480px) {\n        .single-summary-card {\n            padding: 15px !important;\n        }\n        .single-summary-card .card-header-icon {\n            font-size: 26px !important;\n        }\n        .single-summary-card .card-header h3 {\n            font-size: 18px !important;\n        }\n        .single-summary-card .card-content {\n            font-size: 14px !important;\n            line-height: 1.4 !important;\n        }\n        .single-summary-card .card-content .section {\n            margin-bottom: 6px !important;\n        }\n        .single-summary-card .card-footer {\n            font-size: 12px !important;\n            padding-top: 8px !important;\n        }\n    }\n</style>\n<div class=\"single-summary-card-container\" style=\"font-family: 'Noto Sans KR', sans-serif; display: flex; justify-content: center; align-items: center; padding: 20px 10px; background-color: transparent; margin: 20px 0;\">\n<div class=\"single-summary-card\" style=\"width: 100%; max-width: 700px; background-color: #f8f9fa; border-radius: 12px; box-shadow: 0 6px 18px rgba(0,0,0,0.12); padding: 25px; display: flex; flex-direction: column; overflow: hidden; border: 1px solid #dadce0; box-sizing: border-box; height: auto;\">\n<div class=\"card-header\" style=\"display: flex; align-items: center; border-bottom: 2px solid #1a73e8; padding-bottom: 12px; margin-bottom: 12px;\"><span style=\"font-size: 34px; color: #1a73e8; margin-right: 14px;\" class=\"card-header-icon\"> </span>\n<h3 style=\"font-size: 26px; color: #1a73e8; margin: 0; line-height: 1.3; font-weight: bold;\" data-ke-size=\"size23\">핵심 요약</h3>\n</div>\n<div class=\"card-content\" style=\"flex-grow: 1; display: flex; flex-direction: column; justify-content: space-around; font-size: 17px; line-height: 1.65; color: #3c4043;\">\n<div class=\"section\" style=\"margin-bottom: 10px;\"><b>✨ 첫 번째 핵심:</b> <b>무료 GPTS 3종으로 콘텐츠 제작의 모든 고민을 해결!</b></div>\n<div class=\"section\" style=\"margin-bottom: 10px;\"><b>  두 번째 핵심:</b> <b>플랫폼(인스타/쓰레드) 맞춤 콘텐츠, AI가 자동으로 최적화.</b></div>\n<div class=\"section\" style=\"margin-bottom: 10px;\"><b>  세 번째 핵심:</b> <b>수노 4.5 프롬프트 제네레이터로 전문적인 AI 음악 손쉽게 작곡.</b></div>\n<div class=\"section\" style=\"margin-bottom: 10px;\"><b> &zwj;  네 번째 핵심:</b> <b>GPT-5의 힘으로 SEO 최적화 HTML 블로그를 한 번에 생성.</b></div>\n</div>\n<div class=\"card-footer\" style=\"font-size: 14px; color: #5f6368; text-align: center; padding-top: 12px; border-top: 1px dashed #dadce0; margin-top: auto;\">이 GPTS들은 여러분의 시간과 노력을 절약하고 창의력을 극대화하는 데 도움을 줄 것입니다.</div>\n</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<div style=\"margin-bottom: 15px;\">\n<h3 style=\"font-size: 18px; color: #004d99; margin: 15px 0 8px; font-weight: 600;\" data-ke-size=\"size23\">Q1: 소개된 GPTS들은 모두 무료로 사용할 수 있나요?</h3>\n<p data-ke-size=\"size16\">A1: 네, 제가 직접 만든 이 3가지 GPTS는 모두 무료로 사용할 수 있도록 공개되었습니다. 챗GPT 플러스 사용자라면 누구든지 접근하여 활용할 수 있습니다. 단, 수노와 같은 외부 서비스 이용 시 해당 서비스의 정책에 따라 비용이 발생할 수 있습니다.</p>\n</div>\n<div style=\"margin-bottom: 15px;\">\n<h3 style=\"font-size: 18px; color: #004d99; margin: 15px 0 8px; font-weight: 600;\" data-ke-size=\"size23\">Q2: 블로그 기사 생성 GPTS가 HTML 코드를 생성한다고 했는데, 추가적인 편집이 필요한가요?</h3>\n<p data-ke-size=\"size16\">A2: 이 GPTS는 SEO에 최적화된 완전한 HTML 코드를 생성해주므로, 기본적인 구조와 스타일은 바로 사용할 수 있습니다. 물론, 개인의 브랜드 아이덴티티나 특정 디자인 요구사항에 맞춰 세부적인 편집이나 추가 스타일링을 하는 것은 얼마든지 가능하며, 코드펜에서 미리 확인하고 수정하는 것을 추천합니다.</p>\n</div>\n<div style=\"margin-bottom: 15px;\">\n<h3 style=\"font-size: 18px; color: #004d99; margin: 15px 0 8px; font-weight: 600;\" data-ke-size=\"size23\">Q3: 수노 4.5 프롬프트 제네레이터로 만든 음악은 상업적으로 이용할 수 있나요?</h3>\n<p data-ke-size=\"size16\">A3: 수노 4.5 프롬프트 제네레이터는 수노 서비스를 활용하여 음악을 만드는 것을 돕는 도구입니다. 생성된 음악의 상업적 이용 가능 여부는 수노(Suno) 서비스의 라이선스 및 이용 약관에 따라 달라지므로, 수노 공식 웹사이트에서 관련 정책을 확인하시는 것이 가장 정확합니다.</p>\n</div>\n<script type=\"application/ld+json\">\n  {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n      {\n        \"@type\": \"Question\",\n        \"name\": \"소개된 GPTS들은 모두 무료로 사용할 수 있나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"네, 제가 직접 만든 이 3가지 GPTS는 모두 무료로 사용할 수 있도록 공개되었습니다. 챗GPT 플러스 사용자라면 누구든지 접근하여 활용할 수 있습니다. 단, 수노와 같은 외부 서비스 이용 시 해당 서비스의 정책에 따라 비용이 발생할 수 있습니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"블로그 기사 생성 GPTS가 HTML 코드를 생성한다고 했는데, 추가적인 편집이 필요한가요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"이 GPTS는 SEO에 최적화된 완전한 HTML 코드를 생성해주므로, 기본적인 구조와 스타일은 바로 사용할 수 있습니다. 물론, 개인의 브랜드 아이덴티티나 특정 디자인 요구사항에 맞춰 세부적인 편집이나 추가 스타일링을 하는 것은 얼마든지 가능하며, 코드펜에서 미리 확인하고 수정하는 것을 추천합니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"수노 4.5 프롬프트 제네레이터로 만든 음악은 상업적으로 이용할 수 있나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"수노 4.5 프롬프트 제네레이터는 수노 서비스를 활용하여 음악을 만드는 것을 돕는 도구입니다. 생성된 음악의 상업적 이용 가능 여부는 수노(Suno) 서비스의 라이선스 및 이용 약관에 따라 달라지므로, 수노 공식 웹사이트에서 관련 정책을 확인하시는 것이 가장 정확합니다.\"\n        }\n      }\n    ]\n  }\n  </script>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>마무리하며: 콘텐츠 제작의 미래, 여러분의 손에!</b></h2>\n<p data-ke-size=\"size16\">이번 포스팅에서는 SNS 맞춤 콘텐츠 제작부터 AI 음악 작곡, 그리고 SEO에 최적화된 블로그 자동 생성까지, 여러분의 콘텐츠 제작을 훨씬 더 스마트하고 효율적으로 만들어 줄 <b>3가지 무료 GPTS</b>를 소개해 드렸습니다. 솔직히 저도 이 도구들을 만들면서 '와, 정말 여기까지 왔구나' 하고 감탄했거든요.</p>\n<p data-ke-size=\"size16\">이 GPTS들이 여러분의 창작 활동에 새로운 활력을 불어넣고, 시간과 노력을 절약하는 데 큰 도움이 되기를 진심으로 바랍니다. 콘텐츠 제작의 부담을 덜고, 더 많은 아이디어를 자유롭게 펼쳐나가시길 응원합니다!</p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=BgIQHYykMds\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/fyOqA/hyZC24SV1F/ocw11tJky5keBYm0cOsIB0/img.jpg?width=1280&amp;height=720&amp;face=706_116_890_318,https://scrap.kakaocdn.net/dn/oq6dh/hyZDWwcw0d/UTjRFK4m0IXBpsgkkzyWi0/img.jpg?width=1280&amp;height=720&amp;face=706_116_890_318\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"이 무료 GPTS 3개면, 당신도 오늘부터 콘텐츠 전문가가 됩니다 (SNS, AI음악, 블로그 자동화) | 챗GPT \" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/BgIQHYykMds\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n</div>",
        "contentSnippet": "단 하나의 아이디어, 사진, 혹은 링크만으로도 전문가 수준의 콘텐츠를 뚝딱! 제가 직접 개발한 무료 GPTS 3종으로 인스타그램, 스레드 맞춤 콘텐츠는 물론, AI 음악 작곡, 그리고 SEO 최적화 블로그 글까지 초고속으로, 그것도 고품질로 만드는 비법을 공개합니다. 콘텐츠 제작의 새로운 지평을 경험해보세요!\n✨ 콘텐츠 제작, 왜 이렇게 어려울까요?\n\n\n \n 정말 많은 분들이 콘텐츠 제작의 어려움에 공감하실 거예요. 어떤 플랫폼에 맞춰서 글을 써야 할지, 눈길을 사로잡는 이미지는 어떻게 만들지, 심지어는 나만의 배경 음악까지… 창작의 과정은 늘 끝없는 고민과 시행착오의 연속이었습니다. 제가 겪어본 바로는, 아이디어가 있어도 그걸 현실로 구현하는 과정에서 지쳐버리는 경우가 정말 많았죠.\n \n하지만 오늘, 이러한 고충을 한 번에 날려버릴 수 있는 제가 직접 만든 세 가지 특별한 GPTS를 소개해 드릴까 합니다. 이 도구들은 단순한 글쓰기 보조를 넘어, 각 플랫폼의 특성에 맞춰 콘텐츠를 최적화하고, 복잡한 음악 생성 프롬프트를 자동으로 만들어주며, 심지어는 SEO까지 고려한 블로그 포스트를 HTML 코드로 척척 완성해 준답니다.\n \n이제는 아이디어나 사진 한 장, 아니면 그저 블로그 링크 하나만으로도 각 분야의 전문가처럼 콘텐츠를 손쉽게 제작할 수 있는 새로운 시대가 열렸다고 해도 과언이 아닙니다. 많은 분들이 '지피티팍인데 왜 GPT만 소개하나요?'라고 궁금해하실 텐데요. 기존 챗GPT 사용자분들이 많고, GPT를 활용한 무료 연재 기획의 일환으로 이번 GPTS들을 먼저 선보이게 되었습니다. 자, 그럼 바로 시작해볼까요?\n  챗 지피티, 인스타 앤 쓰레드 맞춤 콘텐츠 제작소: 플랫폼별 최적화의 마법\n 첫 번째로 소개해 드릴 GPTS는 바로 '챗 지피티, 인스타 앤 쓰레드 맞춤 콘텐츠 제작소'입니다. 이 GPTS의 핵심은 플랫폼별 맞춤화예요. 같은 내용이라도 쓰레드와 인스타그램에서는 전혀 다른 접근 방식이 필요하다는 것을 여러분도 잘 아실 거예요. 이 GPTS는 사용자의 요청에 따라 \"어떤 플랫폼에 맞춰 드릴까요?\"라고 물어보며, 마치 플랫폼 전문가처럼 콘텐츠를 재구성해줍니다.\n✔️ 쓰레드(Threads) 콘텐츠 제작의 비밀\n쓰레드는 정말 빠르게 정보를 소비하는 플랫폼이죠? 그래서 이 GPTS는 간결하고 강렬한 문장으로 콘텐츠를 만듭니다. 제가 직접 써보니, 경어체 대신 친근한 반말체를 사용하고, 사용자의 주의를 즉시 끌 수 있는 임팩트 있는 '후크 메시지'로 시작해서 핵심 정보를 번호로 나열하는 방식이 정말 효과적이더라구요.\n✔️ 인스타그램(Instagram) 감성 콘텐츠의 완성\n반면 인스타그램은 시각적 요소와 커뮤니티가 중심입니다. 그래서 이 GPTS는 친근한 경어체를 사용해 팔로워들과 대화하듯 접근하고, 텍스트뿐만 아니라 이미지 컨셉까지 함께 제안해줍니다. 인포그래픽과 상세한 캡션, 그리고 필수 해시태그까지, 그야말로 완성형 콘텐츠를 만들어주는 거죠. 솔직히 저도 매번 놀랍니다.\n  GPTS 활용 Tip: 단 하나의 아이디어, 블로그 링크, 혹은 사진만으로도 인스타그램과 쓰레드에 최적화된 콘텐츠를 만들 수 있어요. 블로그 포스팅 후 쓰레드에 요약 내용을 올릴 때 정말 편리하답니다!\n실제 작동 사례 살펴보기\n명언 콘텐츠 제작: 대화창에 \"마음 챙김 명언 2개\"를 입력한 후 인스타그램을 선택하면, 명언과 함께 인스타그램에 적합한 메시지, 해시태그가 작성되고 이미지 생성 여부를 물어봅니다. 몇 가지 질문에 응답하면 메시지에 맞는 이미지 생성 프롬프트가 출력되고, 잠시 후 멋진 이미지가 생성됩니다.\n블로그 요약 & 공유: 블로그 주소를 입력하면 기사를 요약하고 플랫폼 선택을 요청합니다. 쓰레드를 선택하면 이모지와 함께 쓰레드에 적합한 후크 메시지가 생성되고, 이미지 생성도 가능하죠.\n사진 기반 메시지: 사진을 업로드하고 적합한 메시지를 요청한 뒤 인스타그램을 선택하면, 사진을 분석해 사진에 맞는 메시지와 해시태그를 인스타그램 형식에 맞춰 출력해줍니다. 정말 스마트하지 않나요?\n보신 것처럼, 이 GPTS는 단순히 글을 쓰는 것을 넘어, 각 플랫폼의 특성을 정확히 이해하고 최적의 콘텐츠를 완성해 줍니다. 이제 여러분의 콘텐츠 제작이 훨씬 더 스마트해질 거예요!\n \n챗GPT 인스타 & 쓰레드 맞춤 콘텐츠 제작소 바로가기\n\n \nChatGPT - 챗GPT 인스타 & 쓰레드 맞춤 콘텐츠 제작소\n이야기를 들어주고, 배우고, 도전하는 대화형 AI 시스템\nchatgpt.com\n\n \n  수노 4.5 프롬프트 제네레이터: 나만의 AI 음악 작곡가\n두 번째 GPTS는 바로 '수노 4.5 프롬프트 제네레이터'입니다. 이 GPTS는 수노(Suno) 부문에서 글로벌 5위를 자랑하고, 'AI로 노래를 만들어 1억 번 남자'가 사용했다는 바로 그 도구입니다. 말 그대로 AI 음악 작곡의 혁명을 가져왔다고 할 수 있죠.\n수노 4.5, 무엇이 달라졌나?\n최고의 인공지능 프롬프트 기반 음악 생성 서비스인 수노가 버전 4.5로 업데이트되면서, 이전 4.0 버전과는 완전히 다른 차원의 프롬프트가 필요해졌습니다. 기존 4.0은 간결한 형태로 기본적인 음악 특성에만 집중했지만, 4.5부터는 음향 텍스처, 악기 간 상호작용, 섹션별 전개까지 구체적으로 설명하는 전문적이고 세밀한 프롬프트가 필수적이 되었죠. 바로 이러한 변화에 대응하기 위해 이 GPTS를 만들게 되었습니다.\n90가지 히트곡 장르 데이터베이스의 힘\n이 GPTS의 가장 특별한 기능은 바로 글로벌 대표 히트곡 아흔 가지 장르별 데이터베이스를 활용한다는 점입니다. 제가 직접 조사하고 정리한 PDF 문서에는 각 장르별 수노 프롬프트 예시와 구조 형식이 담겨 있는데, 이 GPTS는 사용자의 키워드에 가장 적합한 구조를 자동으로 찾아 적용해줍니다. 가사 생성 원리도 체계적이라, 프롬프트 생성 후 가사가 필요한지 물어보고 요청하면 해당 장르에 맞는 구조를 PDF에서 찾아 참조하여 멋진 가사를 만들어냅니다.\n나만의 곡 만들기, 어렵지 않아요!\n채팅창에 다음과 같이 입력해 보세요:\n'새로운 아침을 운동과 함께 시작하면서 듣는 시티팝 뮤직'\n'마블 어벤저스 주제곡 느낌' (연주곡)\n'나훈아의 고향역' (가수와 곡 스타일)\n이런 요청사항에 적합한 음악 생성 프롬프트(4.0 및 4.5 버전)가 생성되고, 가사 생성 여부를 묻습니다. 한국어 가사를 요청하면 아흔 가지 노래 목록에서 적합한 구조를 찾아 가사를 생성해줍니다. 심지어 '나훈아의 고향역'처럼 유명한 곡은 트로트 장르임을 인식하고 한국 고전 트로트 스타일의 프롬프트와 가사를 생성해내는 것을 보고 정말 놀랐습니다.\n \n이제 수노로 가서 GPTS가 생성한 음악 스타일, 노래 제목, 그리고 가사를 붙여넣고 생성 버튼만 누르면 작업 완료! 누구나 마음속에 품고 있던 자신만의 노래를 세상 밖으로 꺼내기가 막막하셨다면, '수노 4.5 프롬프트 제네레이터'가 여러분의 숨겨진 음악적 재능을 깨워줄 겁니다. 지금 바로 여러분의 이야기를 노래로 만들어보세요. 저도 얼마 전에 이 기능을 이용해서 기념일 축하곡을 만들었는데, 반응이 정말 좋았어요!\n \nSuno 4.5 Prompt Generator 바로가기\n\n \nChatGPT - Suno 4.5 Prompt Generator\n이야기를 들어주고, 배우고, 도전하는 대화형 AI 시스템\nchatgpt.com\n\n \n✍️ 시각화 블로그 기사 생성 GPTS: SEO 최적화 블로그 자동화\n마지막으로 소개해 드릴 GPTS는 바로 '시각화 블로그 기사 생성 GPTS'입니다. 이 도구는 사용자가 간단한 주제나 키워드만 입력하면, 완전한 HTML 형식의 고품질 블로그 포스트를 자동으로 생성해주는, 제가 정말 애정하는 GPTS입니다.\n⚠️ 중요 소식: 그동안 HTML 소스 배포에 컨텍스트 용량 부족의 어려움이 있었지만, 이번 GPT-5 업데이트로 문제가 해결되어 챗GPT에서도 동일한 수준의 HTML 블로그 기사 생성이 가능해졌습니다! 플러스 사용자 기준으로 기존 8K 토큰에서 32K 토큰으로 약 4배 증가한 덕분이죠. 이제 3,000자 분량의 HTML 블로그 포스트를 한 번에 완성할 수 있어요.\nGPTs의 4단계 HTML 생성 원리\n이 GPTS는 총 4단계의 체계적인 과정을 거쳐 블로그 기사를 HTML로 생성합니다. 정말 효율적이죠!\n카테고리 선택: 블로그 주제를 정하지 못했다면, 먼저 분야별 주제를 요청해 보세요. 재정 투자, IT 기술 등 총 8개의 카테고리 중 선택하면 GPT가 적절한 주제를 제안합니다.\n주제 보강 검토: 선택된 주제가 사용자가 요청한 분량(글자 수)에 적합한지 검토합니다. 만약 분량이 부족할 것으로 예상되면, GPT가 주제를 보강해서 제안해줍니다. 이 과정이 글의 완성도를 높이는 데 아주 중요해요.\n컬러 테마 선택: 총 10가지 컬러 테마 중에서 선택합니다. 이 테마에 따라 HTML 소스에 적용될 색상이 결정되어 시각적으로 아름다운 블로그를 만들 수 있습니다.\nHTML 생성: 선택된 테마에 맞는 완전한 HTML 코드를 생성합니다. HTML 생성 완료 후에는 핵심 키워드, 대표 이미지 생성 프롬프트, SEO 최적화 제목 5개 등의 추가 정보와 함께 스키마까지 자동으로 출력되어 완벽한 SEO 최적화가 가능합니다.\n어떻게 활용할 수 있을까요?\n카테고리를 선택하여 진행하거나, 바로 주제를 입력하는 두 가지 방식으로 활용할 수 있습니다.\n카테고리 선택 예시: 첫 화면에서 '분야별 블로그 주제를 제안해줘'를 클릭한 후, 예를 들어 2번 'IT, 기술' 분야를 선택합니다. GPT가 IT 관련 주제를 보여주는데, 여기서 하나를 선택하면 분량이 부족할 경우 주제를 자동으로 보강해줍니다. 그 다음 컬러 테마를 선택하면 바로 기사 작성 계획을 보여주며 HTML 기사를 생성합니다.\n주제 직접 입력 예시: 대화창에 \"건강한 사람들의 아침 루틴\"과 같은 주제를 직접 입력해 보세요. 그러면 카테고리 선택 때와 동일하게 분량 조절을 위해 주제를 보강하고, 컬러 테마 선택 후 바로 기사를 작성합니다. 만약 생성된 기사 분량이 생각보다 적다면, \"관련된 섹션을 2개 더 추가하고 기사를 확장해\"라고 요청하여 풍부한 내용의 기사를 만들 수 있습니다.\n이처럼 '시각화 블로그 기사 생성 GPTS'를 활용하면 몇 번의 클릭과 간단한 요청만으로 SEO까지 완벽하게 최적화된 고품질의 블로그 포스트를 손쉽게 완성할 수 있습니다. 코드펜에서 결과물을 확인해보면, 정말 문제없이 기사가 잘 작성된 것을 볼 수 있을 거예요. 블로그 콘텐츠 제작의 효율을 극대화하고 싶다면 이 강력한 도구를 꼭 사용해보시길 바랍니다!\n \n시각화 블로그 기사 생성 바로가기\n\n \nChatGPT - 시각화 블로그 기사 생성\n이야기를 들어주고, 배우고, 도전하는 대화형 AI 시스템\nchatgpt.com\n\n \n \n핵심 요약\n✨ 첫 번째 핵심: 무료 GPTS 3종으로 콘텐츠 제작의 모든 고민을 해결!\n  두 번째 핵심: 플랫폼(인스타/쓰레드) 맞춤 콘텐츠, AI가 자동으로 최적화.\n  세 번째 핵심: 수노 4.5 프롬프트 제네레이터로 전문적인 AI 음악 손쉽게 작곡.\n ‍  네 번째 핵심: GPT-5의 힘으로 SEO 최적화 HTML 블로그를 한 번에 생성.\n이 GPTS들은 여러분의 시간과 노력을 절약하고 창의력을 극대화하는 데 도움을 줄 것입니다.\n❓ 자주 묻는 질문 (FAQ)\nQ1: 소개된 GPTS들은 모두 무료로 사용할 수 있나요?\nA1: 네, 제가 직접 만든 이 3가지 GPTS는 모두 무료로 사용할 수 있도록 공개되었습니다. 챗GPT 플러스 사용자라면 누구든지 접근하여 활용할 수 있습니다. 단, 수노와 같은 외부 서비스 이용 시 해당 서비스의 정책에 따라 비용이 발생할 수 있습니다.\nQ2: 블로그 기사 생성 GPTS가 HTML 코드를 생성한다고 했는데, 추가적인 편집이 필요한가요?\nA2: 이 GPTS는 SEO에 최적화된 완전한 HTML 코드를 생성해주므로, 기본적인 구조와 스타일은 바로 사용할 수 있습니다. 물론, 개인의 브랜드 아이덴티티나 특정 디자인 요구사항에 맞춰 세부적인 편집이나 추가 스타일링을 하는 것은 얼마든지 가능하며, 코드펜에서 미리 확인하고 수정하는 것을 추천합니다.\nQ3: 수노 4.5 프롬프트 제네레이터로 만든 음악은 상업적으로 이용할 수 있나요?\nA3: 수노 4.5 프롬프트 제네레이터는 수노 서비스를 활용하여 음악을 만드는 것을 돕는 도구입니다. 생성된 음악의 상업적 이용 가능 여부는 수노(Suno) 서비스의 라이선스 및 이용 약관에 따라 달라지므로, 수노 공식 웹사이트에서 관련 정책을 확인하시는 것이 가장 정확합니다.\n마무리하며: 콘텐츠 제작의 미래, 여러분의 손에!\n이번 포스팅에서는 SNS 맞춤 콘텐츠 제작부터 AI 음악 작곡, 그리고 SEO에 최적화된 블로그 자동 생성까지, 여러분의 콘텐츠 제작을 훨씬 더 스마트하고 효율적으로 만들어 줄 3가지 무료 GPTS를 소개해 드렸습니다. 솔직히 저도 이 도구들을 만들면서 '와, 정말 여기까지 왔구나' 하고 감탄했거든요.\n이 GPTS들이 여러분의 창작 활동에 새로운 활력을 불어넣고, 시간과 노력을 절약하는 데 큰 도움이 되기를 진심으로 바랍니다. 콘텐츠 제작의 부담을 덜고, 더 많은 아이디어를 자유롭게 펼쳐나가시길 응원합니다!",
        "guid": "http://muzbox.tistory.com/483647",
        "categories": [
          "AI, 미래기술/AI 챗봇 및 지침 무료 배포",
          "AI 블로그 생성",
          "ai 음악 작곡",
          "GPT-5 활용",
          "seo 최적화 블로그",
          "무료 gpts",
          "수노 AI 프롬프트",
          "쓰레드 마케팅",
          "인스타그램 콘텐츠 제작",
          "콘텐츠 마케팅 도구",
          "콘텐츠 제작 ai"
        ],
        "isoDate": "2025-08-25T10:08:36.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "클로드(Claude)가 내 이메일 습관을 바꾼 방법: 놀랍도록 쉬운 AI 활용법",
        "link": "http://muzbox.tistory.com/483646",
        "pubDate": "Mon, 25 Aug 2025 10:22:21 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483646#entry483646comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #3c4043;\">\n<div style=\"background-color: #e8f4fd; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">매일 쏟아지는 이메일 홍수 속에서 중요한 내용을 놓치진 않으셨나요? 오늘은 AI 비서 클로드(Claude)가 어떻게 제 이메일 습관을 완전히 바꿔 놓았는지, 그리고 이메일 과부하에서 벗어나 더 효율적인 업무 생활을 시작할 수 있게 도와주었는지 솔직한 후기를 들려드릴게요. 생각보다 훨씬 쉽고 강력한 경험에 깜짝 놀라실 거예요!</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  클로드, 이메일을 '읽고' '이해하다'니!</b></h2>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"클로드가 내 이메일 습관을 바꾼 방법.jpeg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/bFbhBx/btsP4r8a5hN/Kh3J9aZ3GsaSAs3XpKk3ok/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bFbhBx/btsP4r8a5hN/Kh3J9aZ3GsaSAs3XpKk3ok/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bFbhBx/btsP4r8a5hN/Kh3J9aZ3GsaSAs3XpKk3ok/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbFbhBx%2FbtsP4r8a5hN%2FKh3J9aZ3GsaSAs3XpKk3ok%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"클로드(Claude)가 내 이메일 습관을 바꾼 방법: 놀랍도록 쉬운 AI 활용법\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"클로드가 내 이메일 습관을 바꾼 방법.jpeg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;솔직히 고백하자면, 저는 제 이메일함을 한동안 거의 포기 상태로 방치하고 있었어요. 중요한 메일과 광고 메일이 뒤섞여 있어 일일이 확인하는 게 너무 번거로웠거든요. 그러다 문득, 클로드(Claude)의 <b>커넥터(Connectors) 기능</b>에 대한 소식을 듣게 되었죠. 과연 이 AI 챗봇이 제 혼돈의 이메일함을 정리해 줄 수 있을까, 반신반의하면서도 한번 시도해 보기로 했어요. 결과는&hellip; 기대 이상이었습니다.<br /><br /></p>\n<p data-ke-size=\"size16\">클로드의 커넥터 기능은 단순히 채팅 인터페이스를 넘어, AI를 다양한 외부 서비스와 연결해주는 생산성 허브로 변모시켰어요. 이메일, 캘린더 앱부터 결제 프로세서, 심지어 디자인 툴까지 수십 가지 서비스와 연결할 수 있더라고요. 물론, 이 멋진 기능은 유료 클로드 플랜(Max, Team, Enterprise, Pro) 사용자에게만 제공됩니다. 무료 티어에서는 대부분의 커넥터에 접근할 수 없다는 점은 참고하셔야 할 것 같아요.</p>\n<h3 data-ke-size=\"size23\">  <b>Gmail 연동, 생각보다 너무 쉬웠어요!</b></h3>\n<p data-ke-size=\"size16\">저는 처음에 API 설정 같은 복잡한 과정을 예상했어요. 그런데 막상 해보니, 웬걸? <b>채 1분도 걸리지 않아 Gmail 연동이 완료</b>되더라고요. 아래 간단한 절차를 따라 했더니 금세 끝났습니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"01.png\" data-origin-width=\"1000\" data-origin-height=\"600\"><span data-url=\"https://blog.kakaocdn.net/dn/OwfYP/btsP4HCW8s3/uj9KEUF2k7NAFDCKOHBET0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/OwfYP/btsP4HCW8s3/uj9KEUF2k7NAFDCKOHBET0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/OwfYP/btsP4HCW8s3/uj9KEUF2k7NAFDCKOHBET0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FOwfYP%2FbtsP4HCW8s3%2Fuj9KEUF2k7NAFDCKOHBET0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1000\" height=\"600\" data-filename=\"01.png\" data-origin-width=\"1000\" data-origin-height=\"600\"/></span></figure>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"02.png\" data-origin-width=\"995\" data-origin-height=\"599\"><span data-url=\"https://blog.kakaocdn.net/dn/mrlIH/btsP2KOe9VX/MKMUUyFt0unOmOCQbVhahK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/mrlIH/btsP2KOe9VX/MKMUUyFt0unOmOCQbVhahK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/mrlIH/btsP2KOe9VX/MKMUUyFt0unOmOCQbVhahK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FmrlIH%2FbtsP2KOe9VX%2FMKMUUyFt0unOmOCQbVhahK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"995\" height=\"599\" data-filename=\"02.png\" data-origin-width=\"995\" data-origin-height=\"599\"/></span></figure>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"03.png\" data-origin-width=\"989\" data-origin-height=\"594\"><span data-url=\"https://blog.kakaocdn.net/dn/c4HfCS/btsP3BpIJZk/E1SOwToKQ3OjAc83rIkzm1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/c4HfCS/btsP3BpIJZk/E1SOwToKQ3OjAc83rIkzm1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/c4HfCS/btsP3BpIJZk/E1SOwToKQ3OjAc83rIkzm1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc4HfCS%2FbtsP3BpIJZk%2FE1SOwToKQ3OjAc83rIkzm1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"989\" height=\"594\" data-filename=\"03.png\" data-origin-width=\"989\" data-origin-height=\"594\"/></span></figure>\n\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>Gmail과 클로드 연결 방법:</b>\n<ol style=\"margin-top: 10px; padding-left: 20px;\" data-ke-list-type=\"decimal\">\n<li style=\"margin-bottom: 5px;\">클로드에 접속해 좌측 하단의 '설정(Settings)'으로 이동합니다.</li>\n<li style=\"margin-bottom: 5px;\">메뉴 옵션에서 '커넥터(Connectors)'를 클릭합니다.</li>\n<li style=\"margin-bottom: 5px;\">아래로 스크롤하여 '커넥터 찾아보기(Browse Connectors)'를 선택합니다.</li>\n<li style=\"margin-bottom: 5px;\">목록에서 'Gmail'을 찾아 '+' 버튼을 클릭합니다.</li>\n<li style=\"margin-bottom: 5px;\">'계속(Continue)'을 클릭하고 클로드에게 Gmail 계정 접근 권한을 부여합니다.</li>\n<li style=\"margin-bottom: 5px;\">Google 인증 시스템의 메시지에 따라 필요한 권한을 승인합니다.</li>\n</ol>\n</div>\n<p data-ke-size=\"size16\">기술적인 부분에서는 <b>OAuth 2.0</b>을 사용해서 인증하더라고요. 클로드는 제 비밀번호를 저장하지 않고, 언제든지 Google 계정 설정을 통해 철회할 수 있는 임시 액세스 토큰을 얻는 방식이었어요. 개인 정보 보호에 신경 썼다는 점에서 안심이 되었습니다.<br /><br /></p>\n<p data-ke-size=\"size16\">정말 놀라웠던 점은 클로드가 단순히 텍스트를 읽는 것을 넘어 이메일의 <b>문맥을 이해하는 능력</b>이었어요. 대화 스레드를 인식하고, 후속 조치 패턴을 파악하며, 홍보성 이메일과 정말 중요한 메시지를 구별해내는 모습은 정말 인상 깊었습니다.</p>\n<p data-ke-size=\"size16\">다른 구글 서비스와의 연동도 유용했습니다. 구글 드라이브에서 문서 변경 사항을 요약해주는 것처럼, 클로드는 이메일과 캘린더 약속을 교차 참조하여 커뮤니케이션의 전체 맥락을 파악해주더군요. 업무용 앱과 연결하니 그 유용성이 더욱 빛을 발했어요. Gmail, Google 캘린더, Asana 사이를 오갈 필요 없이 클로드 인터페이스 하나로 모든 것을 처리할 수 있었죠.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✨ 놀라울 만큼 똑똑한 클로드의 이메일 요약 기능</b></h2>\n<p data-ke-size=\"size16\">클로드를 Gmail에 연결하고 나서, 저는 실제 상황에서 그 요약 기능을 시험해보기로 했어요. 솔직히 다른 AI 도구들이 종종 중요한 세부 사항을 놓치는 일반적인 요약을 제공하는 경우가 많아서 큰 기대를 하지는 않았습니다. 하지만 클로드는 저의 예상을 완전히 뒤엎었습니다.<br /><br /></p>\n<p data-ke-size=\"size16\">클로드의 이메일 요약은 단순한 텍스트 추출을 넘어섭니다. 문맥을 이해하고, 메시지 간의 관계를 파악하며, 정보성 내용과 조치가 필요한 내용을 정확히 구분하더라고요. 이건 정말 '똑똑하다'는 표현이 딱 맞는 것 같아요.<br /><br /></p>\n<p data-ke-size=\"size16\">저는 몇 가지 프롬프트로 클로드를 테스트해보았어요. 예를 들어, 이렇게 물어봤죠. <b>\"이번 주에 제가 답장해야 할 이메일은 뭐가 있을까요?\"</b> 그러자 클로드는 놀랍게도, 당장 조치가 필요한 클라이언트 문의 메일 2개를 정확히 식별해냈습니다. 반면, 제가 원했던 대로 홍보성 콘텐츠나 영수증, 뉴스레터, 자동 보안 알림 등은 완벽하게 걸러냈어요.<br /><br /></p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"963\" data-origin-height=\"582\"><span data-url=\"https://blog.kakaocdn.net/dn/JWzDZ/btsP4nkrWRU/yjrNlSlaPYfuU9k5MVQEwk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/JWzDZ/btsP4nkrWRU/yjrNlSlaPYfuU9k5MVQEwk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/JWzDZ/btsP4nkrWRU/yjrNlSlaPYfuU9k5MVQEwk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FJWzDZ%2FbtsP4nkrWRU%2FyjrNlSlaPYfuU9k5MVQEwk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"963\" height=\"582\" data-origin-width=\"963\" data-origin-height=\"582\"/></span></figure>\n\n<p data-ke-size=\"size16\"><br />조금 더 광범위한 질문도 해봤습니다. <b>\"지난 3일간 받은 이메일 중 주요 안건이 뭔가요?\"</b> 클로드는 다음과 같이 깔끔하게 정리해주더군요.</p>\n<ul style=\"list-style-type: disc; margin-left: 20px; color: #3c4043;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px;\">신규 프로젝트 진행 상황 업데이트</li>\n<li style=\"margin-bottom: 5px;\">주요 협력사와의 미팅 및 계약 관련 내용</li>\n<li style=\"margin-bottom: 5px;\">내부 시스템 개선을 위한 팀원 의견 수렴</li>\n</ul>\n<p data-ke-size=\"size16\">제가 일일이 메시지를 스크롤하며 패턴을 찾으려 애썼던 것보다 훨씬 더 유용했어요. 정말 시간을 엄청나게 절약할 수 있었죠.<br /><br /></p>\n<p data-ke-size=\"size16\">그리고 가장 중요한 테스트는 이거였어요. <b>\"혹시 지난 한 달간 제가 놓쳤을 만한 중요한 이메일이 있을까요?\"</b> 이 질문에 클로드는 제가 미처 확인하지 못했던 한 협업 제안 메일과 중요한 청구서 마감일 알림 메일을 찾아내 플래그를 달아주었어요. 만약 클로드가 아니었다면 큰 문제로 이어질 뻔한 상황이었죠. 단순히 읽는 것을 넘어, 마치 비서처럼 중요한 내용을 짚어주는 기능에 정말 감탄했습니다.<br /><br /></p>\n<p data-ke-size=\"size16\">특히 길고 복잡한 이메일 스레드를 요약해달라고 요청했을 때도 빛을 발했어요. 예를 들어, 프로젝트 지연에 대한 장황한 논의가 담긴 메일 스레드에서 클로드는 핵심 결정 사항과 다음 조치 항목만 정확히 추출해내고, 불필요한 논의는 깔끔하게 무시했습니다. 이게 바로 '해석'이죠, 단순한 정보 나열이 아니라요!</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  그렇지만 알아둬야 할 몇 가지 한계점</b></h2>\n<p data-ke-size=\"size16\">클로드의 이메일 통합 기능은 전반적으로 매우 만족스러웠지만, 완벽하지는 않았습니다. 몇 가지 알아두어야 할 점들이 있어요.</p>\n<div style=\"background-color: #fce8e6; border-left: 4px solid #d93025; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">⚠️ <b>클로드 이메일 통합의 한계:</b>\n<ul style=\"margin-top: 10px; padding-left: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px;\">클로드는 이메일을 <b>읽고 분석만 할 뿐, 직접 보내거나 예약할 수는 없습니다.</b> (아직까지는요!)</li>\n<li style=\"margin-bottom: 5px;\">이메일에 삽입된 <b>이미지는 현재 인식하지 못합니다.</b> 텍스트 기반 정보만 처리 가능해요.</li>\n<li style=\"margin-bottom: 5px;\">가장 눈에 띄는 것은 <b>속도</b>입니다. 간단한 요청은 빠르지만, 상세한 분석이나 방대한 양의 메일을 처리할 때는 조금 느리게 느껴질 수 있어요.</li>\n<li style=\"margin-bottom: 5px;\"><b>개인 정보 보호 문제</b>도 고려해야 합니다. Anthropic은 데이터를 학습에 사용하지 않는다고 명시했지만, 이메일이 AI에 의해 처리된다는 점은 인지하고 있어야겠죠.</li>\n<li style=\"margin-bottom: 5px;\"><b>복잡한 형식의 이메일</b>, 특히 디자인이 복잡한 마케팅 이메일은 문맥을 파악하는 데 어려움을 겪을 수 있습니다.</li>\n<li style=\"margin-bottom: 5px;\"><b>프롬프트 작성 능력</b>이 중요해요. 모호한 요청은 일반적인 결과를 낳고, 구체적인 요청은 훨씬 더 나은 통찰력을 제공합니다.</li>\n</ul>\n</div>\n<p data-ke-size=\"size16\">하지만 제 경험상, 클로드가 이메일 관리에서 절약해주는 시간은 가끔 발생하는 속도 저하나 형식 관련 문제점보다 훨씬 더 가치가 있었습니다. 만약 여러분도 이메일 과부하로 고통받고 있다면, 클로드는 분명 '인박스 제로(Inbox Zero)'를 달성하는 데 큰 도움을 줄 수 있을 거예요. 다만, 여러분의 판단과 검토를 완전히 대체하기보다는 <b>강력한 이메일 비서</b>로 활용하는 것이 가장 현명하다고 생각합니다.</p>\n<style>\n    /* This style block ensures the summary card is responsive on mobile devices. */\n    @media (max-width: 768px) {\n        .single-summary-card {\n            padding: 18px !important;\n        }\n        .single-summary-card .card-header-icon {\n            font-size: 28px !important;\n            margin-right: 10px !important;\n        }\n        .single-summary-card .card-header h3 {\n            font-size: 20px !important;\n        }\n        .single-summary-card .card-content {\n            font-size: 15px !important;\n            line-height: 1.5 !important;\n        }\n        .single-summary-card .card-content .section {\n            margin-bottom: 8px !important;\n        }\n        .single-summary-card .card-footer {\n            font-size: 13px !important;\n            padding-top: 10px !important;\n        }\n    }\n    @media (max-width: 480px) {\n        .single-summary-card {\n            padding: 15px !important;\n        }\n        .single-summary-card .card-header-icon {\n            font-size: 26px !important;\n        }\n        .single-summary-card .card-header h3 {\n            font-size: 18px !important;\n        }\n        .single-summary-card .card-content {\n            font-size: 14px !important;\n            line-height: 1.4 !important;\n        }\n        .single-summary-card .card-content .section {\n            margin-bottom: 6px !important;\n        }\n        .single-summary-card .card-footer {\n            font-size: 12px !important;\n            padding-top: 8px !important;\n        }\n    }\n</style>\n<div class=\"single-summary-card-container\" style=\"font-family: 'Noto Sans KR', sans-serif; display: flex; justify-content: center; align-items: center; padding: 20px 10px; background-color: transparent; margin: 20px 0;\">\n<div class=\"single-summary-card\" style=\"width: 100%; max-width: 700px; background-color: #f8f9fa; border-radius: 12px; box-shadow: 0 6px 18px rgba(0,0,0,0.12); padding: 25px; display: flex; flex-direction: column; overflow: hidden; border: 1px solid #dadce0; box-sizing: border-box; height: auto;\">\n<div class=\"card-header\" style=\"display: flex; align-items: center; border-bottom: 2px solid #1a73e8; padding-bottom: 12px; margin-bottom: 12px;\"><span style=\"font-size: 34px; color: #1a73e8; margin-right: 14px;\" class=\"card-header-icon\"> </span>\n<h3 style=\"font-size: 26px; color: #1a73e8; margin: 0; line-height: 1.3; font-weight: bold;\" data-ke-size=\"size23\">핵심 요약</h3>\n</div>\n<div class=\"card-content\" style=\"flex-grow: 1; display: flex; flex-direction: column; justify-content: space-around; font-size: 17px; line-height: 1.65; color: #3c4043;\">\n<div class=\"section\" style=\"margin-bottom: 10px;\"><b>✨ 첫 번째 핵심:</b> <b>클로드 커넥터로 Gmail을 손쉽게 연결, 단 1분 만에 AI 이메일 비서 설정 완료!</b></div>\n<div class=\"section\" style=\"margin-bottom: 10px;\"><b>  두 번째 핵심:</b> <b>클로드는 이메일의 문맥을 이해하고, 중요한 내용과 불필요한 광고를 정확히 구분하여 요약합니다.</b></div>\n<div class=\"section\" style=\"margin-bottom: 10px;\"><b>  세 번째 핵심:</b> <b>\"놓쳤을 중요한 메일\"을 찾아주어 업무 효율을 극대화하고, 위기 상황을 사전에 방지합니다.</b></div>\n<div class=\"section\" style=\"margin-bottom: 10px;\"><b> &zwj;  네 번째 핵심:</b> <b>일부 한계점(송신 불가, 이미지 미인식 등)이 있지만, 이메일 과부하 해결에 탁월한 보조 도구입니다.</b></div>\n</div>\n<div class=\"card-footer\" style=\"font-size: 14px; color: #5f6368; text-align: center; padding-top: 12px; border-top: 1px dashed #dadce0; margin-top: auto;\">클로드 유료 플랜 사용자라면 지금 바로 이메일 지옥에서 탈출할 기회! 여러분의 생산성을 한 단계 업그레이드해보세요.</div>\n</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-top: 20px; margin-bottom: 10px;\" data-ke-size=\"size23\"><b>Q1: 클로드의 이메일 요약 기능은 무료로 사용할 수 있나요?</b></h3>\n<p style=\"margin-bottom: 15px; color: #3c4043;\" data-ke-size=\"size16\"><b>A1:</b> 아쉽게도 클로드의 커넥터 기능은 유료 플랜(Max, Team, Enterprise, Pro)에서만 제공됩니다. 이메일 연동 및 요약 기능을 사용하시려면 유료 구독이 필요합니다.</p>\n</div>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-top: 20px; margin-bottom: 10px;\" data-ke-size=\"size23\"><b>Q2: 클로드가 제 이메일 내용을 학습에 사용하나요?</b></h3>\n<p style=\"margin-bottom: 15px; color: #3c4043;\" data-ke-size=\"size16\"><b>A2:</b> Anthropic은 클로드가 커넥터를 통해 처리하는 사용자 데이터를 모델 학습에 사용하지 않는다고 밝히고 있습니다. 개인 정보 보호 정책을 준수하며, 사용자는 언제든지 Gmail 접근 권한을 철회할 수 있습니다.</p>\n</div>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-top: 20px; margin-bottom: 10px;\" data-ke-size=\"size23\"><b>Q3: 클로드가 이메일에서 놓치는 정보는 없나요?</b></h3>\n<p style=\"margin-bottom: 15px; color: #3c4043;\" data-ke-size=\"size16\"><b>A3:</b> 클로드는 이메일의 문맥을 깊이 이해하고 중요한 내용을 잘 요약하지만, 몇 가지 한계점이 있습니다. 예를 들어, 이메일에 삽입된 이미지는 현재 인식하지 못하며, 매우 복잡한 형식의 마케팅 이메일은 문맥 파악에 어려움을 겪을 수 있습니다. 또한, 사용자 판단을 완전히 대체하기보다는 보조 도구로 활용하는 것이 좋습니다.</p>\n</div>\n<script type=\"application/ld+json\">\n  {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n      {\n        \"@type\": \"Question\",\n        \"name\": \"클로드의 이메일 요약 기능은 무료로 사용할 수 있나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"아쉽게도 클로드의 커넥터 기능은 유료 플랜(Max, Team, Enterprise, Pro)에서만 제공됩니다. 이메일 연동 및 요약 기능을 사용하시려면 유료 구독이 필요합니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"클로드가 제 이메일 내용을 학습에 사용하나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"Anthropic은 클로드가 커넥터를 통해 처리하는 사용자 데이터를 모델 학습에 사용하지 않는다고 밝히고 있습니다. 개인 정보 보호 정책을 준수하며, 사용자는 언제든지 Gmail 접근 권한을 철회할 수 있습니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"클로드가 이메일에서 놓치는 정보는 없나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"클로드는 이메일의 문맥을 깊이 이해하고 중요한 내용을 잘 요약하지만, 몇 가지 한계점이 있습니다. 예를 들어, 이메일에 삽입된 이미지는 현재 인식하지 못하며, 매우 복잡한 형식의 마케팅 이메일은 문맥 파악에 어려움을 겪을 수 있습니다. 또한, 사용자 판단을 완전히 대체하기보다는 보조 도구로 활용하는 것이 좋습니다.\"\n        }\n      }\n    ]\n  }\n  </script>\n<p data-ke-size=\"size16\">이메일 과부하로 지쳐있던 저에게 클로드의 이메일 통합 기능은 정말이지 한 줄기 빛과 같았어요. 이메일 관리에 들이던 시간을 절약하고, 더 중요한 일에 집중할 수 있게 된 거죠. 여러분도 이메일 스트레스에서 벗어나 생산성을 높이고 싶다면, 클로드를 활용한 스마트한 이메일 관리에 도전해보시는 건 어떨까요? 분명 후회하지 않으실 거예요!</p>\n</div>",
        "contentSnippet": "매일 쏟아지는 이메일 홍수 속에서 중요한 내용을 놓치진 않으셨나요? 오늘은 AI 비서 클로드(Claude)가 어떻게 제 이메일 습관을 완전히 바꿔 놓았는지, 그리고 이메일 과부하에서 벗어나 더 효율적인 업무 생활을 시작할 수 있게 도와주었는지 솔직한 후기를 들려드릴게요. 생각보다 훨씬 쉽고 강력한 경험에 깜짝 놀라실 거예요!\n  클로드, 이메일을 '읽고' '이해하다'니!\n\n\n \n 솔직히 고백하자면, 저는 제 이메일함을 한동안 거의 포기 상태로 방치하고 있었어요. 중요한 메일과 광고 메일이 뒤섞여 있어 일일이 확인하는 게 너무 번거로웠거든요. 그러다 문득, 클로드(Claude)의 커넥터(Connectors) 기능에 대한 소식을 듣게 되었죠. 과연 이 AI 챗봇이 제 혼돈의 이메일함을 정리해 줄 수 있을까, 반신반의하면서도 한번 시도해 보기로 했어요. 결과는… 기대 이상이었습니다.\n\n클로드의 커넥터 기능은 단순히 채팅 인터페이스를 넘어, AI를 다양한 외부 서비스와 연결해주는 생산성 허브로 변모시켰어요. 이메일, 캘린더 앱부터 결제 프로세서, 심지어 디자인 툴까지 수십 가지 서비스와 연결할 수 있더라고요. 물론, 이 멋진 기능은 유료 클로드 플랜(Max, Team, Enterprise, Pro) 사용자에게만 제공됩니다. 무료 티어에서는 대부분의 커넥터에 접근할 수 없다는 점은 참고하셔야 할 것 같아요.\n  Gmail 연동, 생각보다 너무 쉬웠어요!\n저는 처음에 API 설정 같은 복잡한 과정을 예상했어요. 그런데 막상 해보니, 웬걸? 채 1분도 걸리지 않아 Gmail 연동이 완료되더라고요. 아래 간단한 절차를 따라 했더니 금세 끝났습니다.\n\n\n\n\n  Gmail과 클로드 연결 방법:\n\n클로드에 접속해 좌측 하단의 '설정(Settings)'으로 이동합니다.\n메뉴 옵션에서 '커넥터(Connectors)'를 클릭합니다.\n아래로 스크롤하여 '커넥터 찾아보기(Browse Connectors)'를 선택합니다.\n목록에서 'Gmail'을 찾아 '+' 버튼을 클릭합니다.\n'계속(Continue)'을 클릭하고 클로드에게 Gmail 계정 접근 권한을 부여합니다.\nGoogle 인증 시스템의 메시지에 따라 필요한 권한을 승인합니다.\n기술적인 부분에서는 OAuth 2.0을 사용해서 인증하더라고요. 클로드는 제 비밀번호를 저장하지 않고, 언제든지 Google 계정 설정을 통해 철회할 수 있는 임시 액세스 토큰을 얻는 방식이었어요. 개인 정보 보호에 신경 썼다는 점에서 안심이 되었습니다.\n\n정말 놀라웠던 점은 클로드가 단순히 텍스트를 읽는 것을 넘어 이메일의 문맥을 이해하는 능력이었어요. 대화 스레드를 인식하고, 후속 조치 패턴을 파악하며, 홍보성 이메일과 정말 중요한 메시지를 구별해내는 모습은 정말 인상 깊었습니다.\n다른 구글 서비스와의 연동도 유용했습니다. 구글 드라이브에서 문서 변경 사항을 요약해주는 것처럼, 클로드는 이메일과 캘린더 약속을 교차 참조하여 커뮤니케이션의 전체 맥락을 파악해주더군요. 업무용 앱과 연결하니 그 유용성이 더욱 빛을 발했어요. Gmail, Google 캘린더, Asana 사이를 오갈 필요 없이 클로드 인터페이스 하나로 모든 것을 처리할 수 있었죠.\n✨ 놀라울 만큼 똑똑한 클로드의 이메일 요약 기능\n클로드를 Gmail에 연결하고 나서, 저는 실제 상황에서 그 요약 기능을 시험해보기로 했어요. 솔직히 다른 AI 도구들이 종종 중요한 세부 사항을 놓치는 일반적인 요약을 제공하는 경우가 많아서 큰 기대를 하지는 않았습니다. 하지만 클로드는 저의 예상을 완전히 뒤엎었습니다.\n\n클로드의 이메일 요약은 단순한 텍스트 추출을 넘어섭니다. 문맥을 이해하고, 메시지 간의 관계를 파악하며, 정보성 내용과 조치가 필요한 내용을 정확히 구분하더라고요. 이건 정말 '똑똑하다'는 표현이 딱 맞는 것 같아요.\n\n저는 몇 가지 프롬프트로 클로드를 테스트해보았어요. 예를 들어, 이렇게 물어봤죠. \"이번 주에 제가 답장해야 할 이메일은 뭐가 있을까요?\" 그러자 클로드는 놀랍게도, 당장 조치가 필요한 클라이언트 문의 메일 2개를 정확히 식별해냈습니다. 반면, 제가 원했던 대로 홍보성 콘텐츠나 영수증, 뉴스레터, 자동 보안 알림 등은 완벽하게 걸러냈어요.\n\n\n\n\n조금 더 광범위한 질문도 해봤습니다. \"지난 3일간 받은 이메일 중 주요 안건이 뭔가요?\" 클로드는 다음과 같이 깔끔하게 정리해주더군요.\n신규 프로젝트 진행 상황 업데이트\n주요 협력사와의 미팅 및 계약 관련 내용\n내부 시스템 개선을 위한 팀원 의견 수렴\n제가 일일이 메시지를 스크롤하며 패턴을 찾으려 애썼던 것보다 훨씬 더 유용했어요. 정말 시간을 엄청나게 절약할 수 있었죠.\n\n그리고 가장 중요한 테스트는 이거였어요. \"혹시 지난 한 달간 제가 놓쳤을 만한 중요한 이메일이 있을까요?\" 이 질문에 클로드는 제가 미처 확인하지 못했던 한 협업 제안 메일과 중요한 청구서 마감일 알림 메일을 찾아내 플래그를 달아주었어요. 만약 클로드가 아니었다면 큰 문제로 이어질 뻔한 상황이었죠. 단순히 읽는 것을 넘어, 마치 비서처럼 중요한 내용을 짚어주는 기능에 정말 감탄했습니다.\n\n특히 길고 복잡한 이메일 스레드를 요약해달라고 요청했을 때도 빛을 발했어요. 예를 들어, 프로젝트 지연에 대한 장황한 논의가 담긴 메일 스레드에서 클로드는 핵심 결정 사항과 다음 조치 항목만 정확히 추출해내고, 불필요한 논의는 깔끔하게 무시했습니다. 이게 바로 '해석'이죠, 단순한 정보 나열이 아니라요!\n  그렇지만 알아둬야 할 몇 가지 한계점\n클로드의 이메일 통합 기능은 전반적으로 매우 만족스러웠지만, 완벽하지는 않았습니다. 몇 가지 알아두어야 할 점들이 있어요.\n⚠️ 클로드 이메일 통합의 한계:\n\n클로드는 이메일을 읽고 분석만 할 뿐, 직접 보내거나 예약할 수는 없습니다. (아직까지는요!)\n이메일에 삽입된 이미지는 현재 인식하지 못합니다. 텍스트 기반 정보만 처리 가능해요.\n가장 눈에 띄는 것은 속도입니다. 간단한 요청은 빠르지만, 상세한 분석이나 방대한 양의 메일을 처리할 때는 조금 느리게 느껴질 수 있어요.\n개인 정보 보호 문제도 고려해야 합니다. Anthropic은 데이터를 학습에 사용하지 않는다고 명시했지만, 이메일이 AI에 의해 처리된다는 점은 인지하고 있어야겠죠.\n복잡한 형식의 이메일, 특히 디자인이 복잡한 마케팅 이메일은 문맥을 파악하는 데 어려움을 겪을 수 있습니다.\n프롬프트 작성 능력이 중요해요. 모호한 요청은 일반적인 결과를 낳고, 구체적인 요청은 훨씬 더 나은 통찰력을 제공합니다.\n하지만 제 경험상, 클로드가 이메일 관리에서 절약해주는 시간은 가끔 발생하는 속도 저하나 형식 관련 문제점보다 훨씬 더 가치가 있었습니다. 만약 여러분도 이메일 과부하로 고통받고 있다면, 클로드는 분명 '인박스 제로(Inbox Zero)'를 달성하는 데 큰 도움을 줄 수 있을 거예요. 다만, 여러분의 판단과 검토를 완전히 대체하기보다는 강력한 이메일 비서로 활용하는 것이 가장 현명하다고 생각합니다.\n \n핵심 요약\n✨ 첫 번째 핵심: 클로드 커넥터로 Gmail을 손쉽게 연결, 단 1분 만에 AI 이메일 비서 설정 완료!\n  두 번째 핵심: 클로드는 이메일의 문맥을 이해하고, 중요한 내용과 불필요한 광고를 정확히 구분하여 요약합니다.\n  세 번째 핵심: \"놓쳤을 중요한 메일\"을 찾아주어 업무 효율을 극대화하고, 위기 상황을 사전에 방지합니다.\n ‍  네 번째 핵심: 일부 한계점(송신 불가, 이미지 미인식 등)이 있지만, 이메일 과부하 해결에 탁월한 보조 도구입니다.\n클로드 유료 플랜 사용자라면 지금 바로 이메일 지옥에서 탈출할 기회! 여러분의 생산성을 한 단계 업그레이드해보세요.\n❓ 자주 묻는 질문 (FAQ)\nQ1: 클로드의 이메일 요약 기능은 무료로 사용할 수 있나요?\nA1: 아쉽게도 클로드의 커넥터 기능은 유료 플랜(Max, Team, Enterprise, Pro)에서만 제공됩니다. 이메일 연동 및 요약 기능을 사용하시려면 유료 구독이 필요합니다.\nQ2: 클로드가 제 이메일 내용을 학습에 사용하나요?\nA2: Anthropic은 클로드가 커넥터를 통해 처리하는 사용자 데이터를 모델 학습에 사용하지 않는다고 밝히고 있습니다. 개인 정보 보호 정책을 준수하며, 사용자는 언제든지 Gmail 접근 권한을 철회할 수 있습니다.\nQ3: 클로드가 이메일에서 놓치는 정보는 없나요?\nA3: 클로드는 이메일의 문맥을 깊이 이해하고 중요한 내용을 잘 요약하지만, 몇 가지 한계점이 있습니다. 예를 들어, 이메일에 삽입된 이미지는 현재 인식하지 못하며, 매우 복잡한 형식의 마케팅 이메일은 문맥 파악에 어려움을 겪을 수 있습니다. 또한, 사용자 판단을 완전히 대체하기보다는 보조 도구로 활용하는 것이 좋습니다.\n이메일 과부하로 지쳐있던 저에게 클로드의 이메일 통합 기능은 정말이지 한 줄기 빛과 같았어요. 이메일 관리에 들이던 시간을 절약하고, 더 중요한 일에 집중할 수 있게 된 거죠. 여러분도 이메일 스트레스에서 벗어나 생산성을 높이고 싶다면, 클로드를 활용한 스마트한 이메일 관리에 도전해보시는 건 어떨까요? 분명 후회하지 않으실 거예요!",
        "guid": "http://muzbox.tistory.com/483646",
        "categories": [
          "AI, 미래기술/AI 인사이트",
          "ai 생산성 도구",
          "AI 이메일 관리",
          "anthropic claude",
          "스마트 이메일 비서",
          "이메일 과부하 해결",
          "이메일 자동 분류",
          "지메일 AI 통합",
          "클로드 사용 후기",
          "클로드 이메일 요약",
          "클로드 커넥터"
        ],
        "isoDate": "2025-08-25T01:22:21.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "이제는 클로드(Claude) 시대! ChatGPT를 능가하는 AI 챗봇의 숨겨진 5가지 능력",
        "link": "http://muzbox.tistory.com/483645",
        "pubDate": "Thu, 21 Aug 2025 13:56:34 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483645#entry483645comment",
        "content": "<p data-ke-size=\"size8\">&nbsp;</p>\n<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #263238;\">\n<div style=\"background-color: #e0f7fa; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">많은 분들이 여전히 ChatGPT를 주로 사용하시죠? 그런데 초기 아이디어 자동 생성부터 깔끔한 답변, 사용자 맞춤 인터페이스까지, 클로드(Claude) AI가 ChatGPT보다 더 탁월한 5가지 비결을 공개합니다. 당신의 작업 효율을 극대화할 새로운 AI 파트너, 클로드를 만나보세요!</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"gpt보다 클로드.jpeg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/c6RXl9/btsP0QsXwJQ/KD2YSKtwFDHXEVDh6Rq8l1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/c6RXl9/btsP0QsXwJQ/KD2YSKtwFDHXEVDh6Rq8l1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/c6RXl9/btsP0QsXwJQ/KD2YSKtwFDHXEVDh6Rq8l1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc6RXl9%2FbtsP0QsXwJQ%2FKD2YSKtwFDHXEVDh6Rq8l1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"이제는 클로드(Claude) 시대! ChatGPT를 능가하는 AI 챗봇의 숨겨진 5가지 능력\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"gpt보다 클로드.jpeg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;AI 챗봇 하면 여전히 ChatGPT를 가장 먼저 떠올리시는 분들이 많으실 거예요. 저 역시 그랬습니다. 처음에는 ChatGPT가 거의 유일한 선택지라고 생각했죠. 그런데 말이죠, 세상엔 정말 좋은 AI 대안들이 많다는 걸 직접 경험하고 깨달았습니다. 특히 오늘 소개해드릴 <u><b><span style=\"color: #006dd7;\"><a style=\"color: #006dd7;\" href=\"https://claude.ai/\" target=\"_blank\" rel=\"noopener\">'클로드(Claude) AI'</a></span></b></u>는 초기 아이디어 구상부터 작업의 효율성까지, 여러분의 기대를 뛰어넘는 놀라운 경험을 선사할 거예요. 과연 클로드가 어떻게 여러분의 창의적인 작업을 '자동 생성'하는 비결을 가지고 있는지, 저와 함께 자세히 알아볼까요?</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✨ 1. 더 나은 초기 아이디어 자동 생성</b></h2>\n<p data-ke-size=\"size16\">음, 혹시 ChatGPT를 쓰다가 '이거, 뭘 물어봐야 할지 막막한데?' 싶었던 경험 없으세요? 특히 빈 대화창을 마주할 때 말이죠. 물론 ChatGPT의 '커스텀 GPT' 기능에서는 초기 프롬프트가 잘 나오긴 해요. 사실 이 기능, 정말 과소평가되어 있다고 생각합니다. 아이디어가 잘 떠오르지 않을 때 정말 유용하죠. 하지만 일반 대화에서는 이런 시작 프롬프트가 잘 제공되지 않아서 아쉬울 때가 많아요. 심지어 마이크로소프트의 코파일럿(Copilot)이 이 점에서는 더 낫다고 느낄 때도 있습니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"917\" data-origin-height=\"545\"><span data-url=\"https://blog.kakaocdn.net/dn/bswcdq/btsP0TpHUFi/GgM6iUvdR9ooS3sw246zyK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bswcdq/btsP0TpHUFi/GgM6iUvdR9ooS3sw246zyK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bswcdq/btsP0TpHUFi/GgM6iUvdR9ooS3sw246zyK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbswcdq%2FbtsP0TpHUFi%2FGgM6iUvdR9ooS3sw246zyK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"917\" height=\"545\" data-origin-width=\"917\" data-origin-height=\"545\"/></span></figure>\n\n<div style=\"background-color: #e0f7fa; border-left: 4px solid #00796b; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>클로드의 차별점:</b> 클로드(Claude)는 새 대화를 시작할 때마다 여러 개의 초기 프롬프트 옵션을 제공하며, 이 프롬프트들을 다양한 카테고리(예: 클로드의 추천, 일상생활)로 깔끔하게 분류해 놓아 사용자의 아이디어 발상을 효과적으로 돕습니다.</div>\n<p data-ke-size=\"size16\">그런데 클로드(Claude)는 시작부터 다릅니다. 새 대화를 시작할 때마다 여러 개의 초기 프롬프트 옵션을 제공해주죠. 단순히 많은 것뿐만 아니라, 이 프롬프트들을 다양한 카테고리로 깔끔하게 분류해 놓았다는 점이 정말 인상적입니다. 예를 들어, '클로드의 추천(Claude's choice)' 섹션에서는 '새로운 관점 발견하기' 같은 조금 독특하면서도 영감을 주는 주제들을 만날 수 있어요. 또 '일상생활(Life stuff)' 섹션에서는 아침 루틴 팁이나 기념일 계획 같은 실용적인 아이디어들도 얻을 수 있습니다. 저는 개인적으로 이런 세심한 배려가 클로드를 더 자주 찾게 만드는 이유 중 하나라고 생각해요.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  2. 훨씬 더 이해하기 쉬운 답변</b></h2>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"934\" data-origin-height=\"592\"><span data-url=\"https://blog.kakaocdn.net/dn/bFvXZo/btsPZ46rMUK/AsTZmyQpudzCtPw8BHc2EK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bFvXZo/btsPZ46rMUK/AsTZmyQpudzCtPw8BHc2EK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bFvXZo/btsPZ46rMUK/AsTZmyQpudzCtPw8BHc2EK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbFvXZo%2FbtsPZ46rMUK%2FAsTZmyQpudzCtPw8BHc2EK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"934\" height=\"592\" data-origin-width=\"934\" data-origin-height=\"592\"/></span></figure>\n\n<p data-ke-size=\"size16\">ChatGPT, 솔직히 정말 디테일한 답변을 잘 만들어냅니다. 특히 '심층 연구(Deep Research)' 같은 기능은 정말 감탄스럽죠. 기본적인 질문을 하더라도, 개요 기반으로 답변해달라고 요청하면 엄청나게 상세한 내용을 얻을 수 있습니다. 정보의 양 자체는 정말 풍부해요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">하지만 제가 좀 아쉽다고 느끼는 부분이 있습니다. 바로 정보의 <b>'가독성'</b>이에요. 때때로 ChatGPT의 답변은 너무 많은 정보가 한꺼번에 쏟아져 나와서 복잡하게 느껴질 때가 있습니다. 저는 개인적으로 표 형식의 정보를 선호하는데, 그럼에도 불구하고 어떤 답변들은 너무 복잡해서 따라가기 어려울 때가 종종 있었어요. 마치 정보의 숲에 길을 잃는 기분이랄까요?  <br /><br /></p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"921\" data-origin-height=\"543\"><span data-url=\"https://blog.kakaocdn.net/dn/bmMTCA/btsPZjwba2k/Ipim4E3NxSmaMcNdrk2dm0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bmMTCA/btsPZjwba2k/Ipim4E3NxSmaMcNdrk2dm0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bmMTCA/btsPZjwba2k/Ipim4E3NxSmaMcNdrk2dm0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbmMTCA%2FbtsPZjwba2k%2FIpim4E3NxSmaMcNdrk2dm0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"921\" height=\"543\" data-origin-width=\"921\" data-origin-height=\"543\"/></span></figure>\n\n<p data-ke-size=\"size16\">반면에 클로드는 답변을 거의 언제나 <b>'훨씬 더 이해하기 쉬운'</b> 형식으로 제공합니다. 깔끔하게 정리된 문단, 중요한 내용은 명확하게 구분되어 있어서 한눈에 쏙쏙 들어와요. 덕분에 내용을 파악하는 데 드는 시간이 훨씬 줄어들고, 제가 얻고 싶은 핵심 정보를 명확하게 이해할 수 있죠. 복잡한 내용을 빠르게 파악하고 싶을 때, 클로드가 정말 빛을 발합니다.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✍️ 3. 탁월한 글쓰기 맞춤 설정 기능</b></h2>\n<p data-ke-size=\"size16\">ChatGPT가 많은 부분에서 뛰어나지만, 개인적으로 <b>'글쓰기'</b> 영역에서는 아직 좀 부족하다고 생각합니다. 물론 새롭게 업데이트되는 모델들이 마케팅에서 강조하는 만큼 완벽한 수준은 아닌 것 같아요. 'ChatGPT Canvas' 같은 도구도 괜찮긴 하지만, 다른 AI 도구들에 비하면 글쓰기 맞춤 설정 기능이 아쉽다는 생각이 들었습니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"921\" data-origin-height=\"553\"><span data-url=\"https://blog.kakaocdn.net/dn/cosVz8/btsP0YEop97/RkbcPBkQWt1CCkJJhoUqX1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cosVz8/btsP0YEop97/RkbcPBkQWt1CCkJJhoUqX1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cosVz8/btsP0YEop97/RkbcPBkQWt1CCkJJhoUqX1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcosVz8%2FbtsP0YEop97%2FRkbcPBkQWt1CCkJJhoUqX1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"921\" height=\"553\" data-origin-width=\"921\" data-origin-height=\"553\"/></span></figure>\n\n<p data-ke-size=\"size16\">클로드는 글쓰기 관련해서 정말 다양한 기능을 제공합니다. 우선 <b>'스타일 변경'</b> 기능이 압권이에요. '간결하게', '설명적으로', '공식적으로' 같은 사전 설정된 옵션은 물론, 저만의 맞춤 스타일을 직접 만들거나 기존 스타일을 편집할 수도 있습니다. 이건 ChatGPT의 '지시사항'과 비슷하다고 볼 수도 있지만, 클로드에서는 훨씬 더 명확하고 직관적으로 느껴졌어요. 마치 나만의 비서에게 글쓰기 스타일을 세세하게 알려주는 느낌이랄까요?</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">클로드로 글을 쓰는 게 즐거운 또 다른 이유는 <b>'사전 설정된 제안'</b>에서 선택할 수 있다는 점입니다. 콘텐츠를 편집하는 옵션도 있고, 심지어 콘텐츠 캘린더나 교육 자료 같은 것을 개발하는 데도 활용할 수 있죠. 물론 저는 AI가 모든 글을 대신 쓰는 것에 대해서는 아직 회의적입니다만, 아이디어의 <b>'윤곽'을 잡는 데는 클로드가 정말 탁월하다</b>고 확신합니다. 거의 대부분의 경우, 저는 ChatGPT 대신 클로드를 사용할 것을 추천하고 싶어요.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  4. 더 깔끔한 인터페이스와 외관 맞춤 설정</b></h2>\n<p data-ke-size=\"size16\">&nbsp;솔직히 ChatGPT의 인터페이스도 처음 출시되었을 때에 비하면 많이 좋아졌죠. 특히 <b>'프로젝트(Projects)'</b> 기능은 정말 필수적인 기능이라고 생각합니다. 하지만 동시에, 여전히 클로드 같은 다른 AI 도구에 비해 부족한 부분이 있다고 느낍니다.</p>\n<p data-ke-size=\"size16\">ChatGPT는 '프로젝트' 기능을 제외하고는 인터페이스 맞춤 설정 옵션이 그리 많지 않아요. 제가 ChatGPT를 사용하면서 가장 아쉬웠던 점 중 하나였습니다. 그래서 클로드를 처음 사용했을 때 정말 기뻤던 기억이 납니다.</p>\n<div style=\"background-color: #ffebee; border-left: 4px solid #c62828; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">⚠️ <b>주의:</b> 클로드에는 아직 ChatGPT의 '프로젝트'와 같은 강력한 대화 정리 기능은 없습니다. 하지만 인터페이스 외관 맞춤 설정 기능으로 사용자의 편의성을 높이는 데 중점을 둡니다.</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"921\" data-origin-height=\"520\"><span data-url=\"https://blog.kakaocdn.net/dn/bRchBP/btsP0NwfR72/3qhRZJPLkOHbbkYEq1QRr1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bRchBP/btsP0NwfR72/3qhRZJPLkOHbbkYEq1QRr1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bRchBP/btsP0NwfR72/3qhRZJPLkOHbbkYEq1QRr1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbRchBP%2FbtsP0NwfR72%2F3qhRZJPLkOHbbkYEq1QRr1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"921\" height=\"520\" data-origin-width=\"921\" data-origin-height=\"520\"/></span></figure>\n\n<p data-ke-size=\"size16\">&nbsp;물론 클로드에는 '프로젝트' 같은 기능이 없다는 점은 아쉽긴 해요 (개인적으로는 이런 기능이 추가되면 정말 좋을 것 같아요!). 하지만 인터페이스를 사용자 입맛에 맞게 조절하는 데 있어서는 정말 최고입니다. 예를 들어, 다양한 글꼴 중에서 선택할 수 있어요. 그리고 전반적으로 클로드 인터페이스의 색상 조합과 전체적인 디자인이 ChatGPT보다 훨씬 더 좋다고 생각합니다. ChatGPT는 약간 '유틸리티적'이고 기능에만 초점을 맞춘 느낌이라면, 클로드는 사용 자체가 정말 <b>'즐겁다'</b>는 느낌을 줍니다. 시각적인 편안함이 작업 효율에도 영향을 미친다고 생각해요.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  5. 깃허브(GitHub) 통합 및 편리한 채팅 관리&nbsp;</b></h2>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"924\" data-origin-height=\"480\"><span data-url=\"https://blog.kakaocdn.net/dn/Bry99/btsPZhkQqQ3/Na75pnmoZCVDwNNyZpDjI1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Bry99/btsPZhkQqQ3/Na75pnmoZCVDwNNyZpDjI1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/Bry99/btsPZhkQqQ3/Na75pnmoZCVDwNNyZpDjI1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FBry99%2FbtsPZhkQqQ3%2FNa75pnmoZCVDwNNyZpDjI1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"924\" height=\"480\" data-origin-width=\"924\" data-origin-height=\"480\"/></span></figure>\n\n<p data-ke-size=\"size16\">&nbsp;코딩은 사람들이 클로드를 사용하는 가장 흔한 이유 중 하나이고, 제 생각엔 이 부분에서도 클로드가 ChatGPT보다 더 적합한 도구입니다. 기본적으로 클로드 아티팩트(Claude Artifacts) 내에서 프롬프트를 선택하고 코드를 작성할 수 있는 옵션이 있죠. 여기에 더해, 클로드는 <b>깃허브(GitHub)와 통합</b>됩니다!  </p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">깃허브 통합 기능을 활용하면 자신의 리포지토리(저장소)를 클로드 앱에 연결할 수 있어요. 원하는 리포지토리를 선택해서 클로드로 가져오기만 하면 되죠. 덕분에 코딩 관련 작업이 훨씬 쉬워집니다. 개발자분들이라면 이 기능의 가치를 더 크게 느끼실 거예요. 협업에도 유리하고, 코드 분석이나 개선에도 큰 도움이 될 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"911\" data-origin-height=\"571\"><span data-url=\"https://blog.kakaocdn.net/dn/c0LKNr/btsPZZRAHwZ/LkWDiqEjIXEjaDb1d3RQ9K/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/c0LKNr/btsPZZRAHwZ/LkWDiqEjIXEjaDb1d3RQ9K/img.png\"><img src=\"https://blog.kakaocdn.net/dn/c0LKNr/btsPZZRAHwZ/LkWDiqEjIXEjaDb1d3RQ9K/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc0LKNr%2FbtsPZZRAHwZ%2FLkWDiqEjIXEjaDb1d3RQ9K%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"911\" height=\"571\" data-origin-width=\"911\" data-origin-height=\"571\"/></span></figure>\n\n<p data-ke-size=\"size16\">그리고 이건 제가 개인적으로 정말 사랑하는 기능인데요, 바로 <b>'채팅 일괄 삭제'</b> 기능입니다! ChatGPT의 '프로젝트' 기능이 대화 정리에 도움이 되긴 하지만, 여전히 채팅을 한 번에 여러 개 삭제할 수 없다는 점이 너무 불편했어요. 일일이 지우는 건 정말 지루하고 시간이 많이 걸리는 작업이라, 결국 필요 없는 대화들이 계속 쌓이게 되더라고요. 이 문제를 해결하는 가장 쉬운 방법이 바로 '일괄 삭제'인데, ChatGPT는 아직 이 기능이 없어서 아쉽습니다. 하지만 클로드는 이 기능을 제공합니다! 각 대화 옆의 체크박스를 선택하고 <b>'선택 항목 삭제'</b>를 누르기만 하면 끝이에요. 깔끔하게 정리된 작업 공간은 기분까지 좋게 만들죠. ✨</p>\n<style>\n        /* This style block ensures the summary card is responsive on mobile devices. */\n        @media (max-width: 768px) {\n            .single-summary-card {\n                padding: 18px !important;\n            }\n            .single-summary-card .card-header-icon {\n                font-size: 28px !important;\n                margin-right: 10px !important;\n            }\n            .single-summary-card .card-header h3 {\n                font-size: 20px !important;\n            }\n            .single-summary-card .card-content {\n                font-size: 15px !important;\n                line-height: 1.5 !important;\n            }\n            .single-summary-card .card-content .section {\n                margin-bottom: 8px !important;\n            }\n            .single-summary-card .card-footer {\n                font-size: 13px !important;\n                padding-top: 10px !important;\n            }\n        }\n        @media (max-width: 480px) {\n            .single-summary-card {\n                padding: 15px !important;\n            }\n            .single-summary-card .card-header-icon {\n                font-size: 26px !important;\n            }\n            .single-summary-card .card-header h3 {\n                font-size: 18px !important;\n            }\n            .single-summary-card .card-content {\n                font-size: 14px !important;\n                line-height: 1.4 !important;\n            }\n            .single-summary-card .card-content .section {\n                margin-bottom: 6px !important;\n            }\n            .single-summary-card .card-footer {\n                font-size: 12px !important;\n                padding-top: 8px !important;\n            }\n        }\n    </style>\n<div class=\"single-summary-card-container\" style=\"font-family: 'Noto Sans KR', sans-serif; display: flex; justify-content: center; align-items: center; padding: 20px 10px; background-color: transparent; margin: 20px 0;\">\n<div class=\"single-summary-card\" style=\"width: 100%; max-width: 700px; background-color: #eceff1; border-radius: 12px; box-shadow: 0 6px 18px rgba(0,0,0,0.12); padding: 25px; display: flex; flex-direction: column; overflow: hidden; border: 1px solid #b0bec5; box-sizing: border-box; height: auto;\">\n<div class=\"card-header\" style=\"display: flex; align-items: center; border-bottom: 2px solid #00796b; padding-bottom: 12px; margin-bottom: 12px;\"><span style=\"font-size: 34px; color: #00796b; margin-right: 14px;\" class=\"card-header-icon\"> </span>\n<h3 style=\"font-size: 26px; color: #00796b; margin: 0; line-height: 1.3; font-weight: bold;\" data-ke-size=\"size23\">핵심 요약</h3>\n</div>\n<div class=\"card-content\" style=\"flex-grow: 1; display: flex; flex-direction: column; justify-content: space-around; font-size: 17px; line-height: 1.65; color: #263238;\">\n<div class=\"section\" style=\"margin-bottom: 10px;\"><b>✨ 첫 번째 핵심:</b> <b>클로드는 대화 시작 시 다양한 카테고리별 초기 프롬프트를 제공하여 아이디어 생성을 돕습니다.</b></div>\n<div class=\"section\" style=\"margin-bottom: 10px;\"><b>  두 번째 핵심:</b> <b>ChatGPT보다 훨씬 깔끔하고 이해하기 쉬운 답변 형식으로 정보 파악이 용이합니다.</b></div>\n<div class=\"section\" style=\"margin-bottom: 10px;\"><b>  세 번째 핵심:</b> <b>글쓰기 스타일 맞춤 설정, 사전 제안 등 강력한 글쓰기 보조 기능으로 아웃라인 구성에 탁월합니다.</b></div>\n<div class=\"section\" style=\"margin-bottom: 10px;\"><b> &zwj;  네 번째 핵심:</b> <b>사용자 친화적인 인터페이스 디자인과 깃허브 통합, 채팅 일괄 삭제 등 편리한 기능들을 제공합니다.</b></div>\n</div>\n<div class=\"card-footer\" style=\"font-size: 14px; color: #607d8b; text-align: center; padding-top: 12px; border-top: 1px dashed #b0bec5; margin-top: auto;\">클로드를 통해 더 스마트하고 효율적인 AI 활용을 경험해보세요!</div>\n</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<p style=\"color: #263238;\" data-ke-size=\"size16\"><b>Q1: 클로드가 ChatGPT보다 초기 아이디어 생성에 더 좋다고 하는 이유는 무엇인가요?</b></p>\n<p style=\"color: #263238;\" data-ke-size=\"size16\">A1: 클로드는 새로운 대화를 시작할 때 다양한 카테고리로 분류된 초기 프롬프트 옵션을 제공하여 사용자가 질문을 시작하기 전에 아이디어를 얻고 생각을 확장하는 데 도움을 줍니다. ChatGPT는 커스텀 GPT 외에는 이런 기능이 부족합니다.</p>\n<p style=\"color: #263238;\" data-ke-size=\"size16\"><b>Q2: 클로드의 답변 가독성이 뛰어나다고 했는데, 어떤 점이 다른가요?</b></p>\n<p style=\"color: #263238;\" data-ke-size=\"size16\">A2: 클로드는 복잡한 정보를 깔끔하고 구조화된 형태로 제시하여 한눈에 내용을 파악하기 쉽게 합니다. 반면 ChatGPT는 정보의 양이 많을 때 다소 복잡하게 느껴질 수 있습니다.</p>\n<p style=\"color: #263238;\" data-ke-size=\"size16\"><b>Q3: 글쓰기 기능에서 클로드가 ChatGPT보다 뛰어난 점은 무엇인가요?</b></p>\n<p style=\"color: #263238;\" data-ke-size=\"size16\">A3: 클로드는 글쓰기 스타일 변경(간결, 설명, 공식 등) 기능과 맞춤 스타일 생성, 그리고 콘텐츠 편집 및 개발을 위한 사전 설정 제안 등을 제공하여 글의 아웃라인을 잡거나 특정 톤앤매너에 맞춰 글을 작성할 때 유용합니다.</p>\n<p style=\"color: #263238;\" data-ke-size=\"size16\"><b>Q4: 클로드의 인터페이스 외관 맞춤 설정은 어떤 특징이 있나요?</b></p>\n<p style=\"color: #263238;\" data-ke-size=\"size16\">A4: 클로드는 다양한 글꼴 옵션을 제공하며, 전반적인 색상 조합과 디자인이 사용자 친화적이고 시각적으로 편안함을 줍니다. ChatGPT에 비해 더 개인화된 작업 환경을 만들 수 있습니다.</p>\n<script type=\"application/ld+json\">\n    {\n      \"@context\": \"https://schema.org\",\n      \"@type\": \"FAQPage\",\n      \"mainEntity\": [\n        {\n          \"@type\": \"Question\",\n          \"name\": \"클로드가 ChatGPT보다 초기 아이디어 생성에 더 좋다고 하는 이유는 무엇인가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"클로드는 새로운 대화를 시작할 때 다양한 카테고리로 분류된 초기 프롬프트 옵션을 제공하여 사용자가 질문을 시작하기 전에 아이디어를 얻고 생각을 확장하는 데 도움을 줍니다. ChatGPT는 커스텀 GPT 외에는 이런 기능이 부족합니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"클로드의 답변 가독성이 뛰어나다고 했는데, 어떤 점이 다른가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"클로드는 복잡한 정보를 깔끔하고 구조화된 형태로 제시하여 한눈에 내용을 파악하기 쉽게 합니다. 반면 ChatGPT는 정보의 양이 많을 때 다소 복잡하게 느껴질 수 있습니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"글쓰기 기능에서 클로드가 ChatGPT보다 뛰어난 점은 무엇인가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"클로드는 글쓰기 스타일 변경(간결, 설명, 공식 등) 기능과 맞춤 스타일 생성, 그리고 콘텐츠 편집 및 개발을 위한 사전 설정 제안 등을 제공하여 글의 아웃라인을 잡거나 특정 톤앤매너에 맞춰 글을 작성할 때 유용합니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"클로드의 인터페이스 외관 맞춤 설정은 어떤 특징이 있나요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"클로드는 다양한 글꼴 옵션을 제공하며, 전반적인 색상 조합과 디자인이 사용자 친화적이고 시각적으로 편안함을 줍니다. ChatGPT에 비해 더 개인화된 작업 환경을 만들 수 있습니다.\"\n          }\n        }\n      ]\n    }\n    </script>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">결론적으로, ChatGPT가 여전히 강력한 AI 도구인 것은 분명합니다. 하지만 제가 직접 경험해본 결과, 초기 아이디어 자동 생성, 가독성 높은 답변, 풍부한 글쓰기 맞춤 설정, 사용자 친화적인 인터페이스, 그리고 개발자를 위한 깃허브 통합과 편리한 채팅 관리 기능까지, 클로드가 여러 면에서 ChatGPT를 능가하는 <b>'숨겨진 보석'</b>이라는 생각이 듭니다. 특히 AI를 활용해 새로운 아이디어를 얻거나, 복잡한 정보를 깔끔하게 정리하고 싶은 분들에게 클로드는 정말 매력적인 대안이 될 수 있을 거예요. 여러분도 이 똑똑한 AI 대안을 직접 경험해보시고, 여러분의 작업 방식을 한 단계 업그레이드해보시는 건 어떨까요? 분명 후회하지 않으실 겁니다!  </p>\n</div>",
        "contentSnippet": "많은 분들이 여전히 ChatGPT를 주로 사용하시죠? 그런데 초기 아이디어 자동 생성부터 깔끔한 답변, 사용자 맞춤 인터페이스까지, 클로드(Claude) AI가 ChatGPT보다 더 탁월한 5가지 비결을 공개합니다. 당신의 작업 효율을 극대화할 새로운 AI 파트너, 클로드를 만나보세요!\n\n\n \n AI 챗봇 하면 여전히 ChatGPT를 가장 먼저 떠올리시는 분들이 많으실 거예요. 저 역시 그랬습니다. 처음에는 ChatGPT가 거의 유일한 선택지라고 생각했죠. 그런데 말이죠, 세상엔 정말 좋은 AI 대안들이 많다는 걸 직접 경험하고 깨달았습니다. 특히 오늘 소개해드릴 '클로드(Claude) AI'는 초기 아이디어 구상부터 작업의 효율성까지, 여러분의 기대를 뛰어넘는 놀라운 경험을 선사할 거예요. 과연 클로드가 어떻게 여러분의 창의적인 작업을 '자동 생성'하는 비결을 가지고 있는지, 저와 함께 자세히 알아볼까요?\n✨ 1. 더 나은 초기 아이디어 자동 생성\n음, 혹시 ChatGPT를 쓰다가 '이거, 뭘 물어봐야 할지 막막한데?' 싶었던 경험 없으세요? 특히 빈 대화창을 마주할 때 말이죠. 물론 ChatGPT의 '커스텀 GPT' 기능에서는 초기 프롬프트가 잘 나오긴 해요. 사실 이 기능, 정말 과소평가되어 있다고 생각합니다. 아이디어가 잘 떠오르지 않을 때 정말 유용하죠. 하지만 일반 대화에서는 이런 시작 프롬프트가 잘 제공되지 않아서 아쉬울 때가 많아요. 심지어 마이크로소프트의 코파일럿(Copilot)이 이 점에서는 더 낫다고 느낄 때도 있습니다.\n\n\n  클로드의 차별점: 클로드(Claude)는 새 대화를 시작할 때마다 여러 개의 초기 프롬프트 옵션을 제공하며, 이 프롬프트들을 다양한 카테고리(예: 클로드의 추천, 일상생활)로 깔끔하게 분류해 놓아 사용자의 아이디어 발상을 효과적으로 돕습니다.\n그런데 클로드(Claude)는 시작부터 다릅니다. 새 대화를 시작할 때마다 여러 개의 초기 프롬프트 옵션을 제공해주죠. 단순히 많은 것뿐만 아니라, 이 프롬프트들을 다양한 카테고리로 깔끔하게 분류해 놓았다는 점이 정말 인상적입니다. 예를 들어, '클로드의 추천(Claude's choice)' 섹션에서는 '새로운 관점 발견하기' 같은 조금 독특하면서도 영감을 주는 주제들을 만날 수 있어요. 또 '일상생활(Life stuff)' 섹션에서는 아침 루틴 팁이나 기념일 계획 같은 실용적인 아이디어들도 얻을 수 있습니다. 저는 개인적으로 이런 세심한 배려가 클로드를 더 자주 찾게 만드는 이유 중 하나라고 생각해요.\n  2. 훨씬 더 이해하기 쉬운 답변\n\n\nChatGPT, 솔직히 정말 디테일한 답변을 잘 만들어냅니다. 특히 '심층 연구(Deep Research)' 같은 기능은 정말 감탄스럽죠. 기본적인 질문을 하더라도, 개요 기반으로 답변해달라고 요청하면 엄청나게 상세한 내용을 얻을 수 있습니다. 정보의 양 자체는 정말 풍부해요.\n \n하지만 제가 좀 아쉽다고 느끼는 부분이 있습니다. 바로 정보의 '가독성'이에요. 때때로 ChatGPT의 답변은 너무 많은 정보가 한꺼번에 쏟아져 나와서 복잡하게 느껴질 때가 있습니다. 저는 개인적으로 표 형식의 정보를 선호하는데, 그럼에도 불구하고 어떤 답변들은 너무 복잡해서 따라가기 어려울 때가 종종 있었어요. 마치 정보의 숲에 길을 잃는 기분이랄까요?  \n\n\n\n반면에 클로드는 답변을 거의 언제나 '훨씬 더 이해하기 쉬운' 형식으로 제공합니다. 깔끔하게 정리된 문단, 중요한 내용은 명확하게 구분되어 있어서 한눈에 쏙쏙 들어와요. 덕분에 내용을 파악하는 데 드는 시간이 훨씬 줄어들고, 제가 얻고 싶은 핵심 정보를 명확하게 이해할 수 있죠. 복잡한 내용을 빠르게 파악하고 싶을 때, 클로드가 정말 빛을 발합니다.\n✍️ 3. 탁월한 글쓰기 맞춤 설정 기능\nChatGPT가 많은 부분에서 뛰어나지만, 개인적으로 '글쓰기' 영역에서는 아직 좀 부족하다고 생각합니다. 물론 새롭게 업데이트되는 모델들이 마케팅에서 강조하는 만큼 완벽한 수준은 아닌 것 같아요. 'ChatGPT Canvas' 같은 도구도 괜찮긴 하지만, 다른 AI 도구들에 비하면 글쓰기 맞춤 설정 기능이 아쉽다는 생각이 들었습니다.\n\n\n클로드는 글쓰기 관련해서 정말 다양한 기능을 제공합니다. 우선 '스타일 변경' 기능이 압권이에요. '간결하게', '설명적으로', '공식적으로' 같은 사전 설정된 옵션은 물론, 저만의 맞춤 스타일을 직접 만들거나 기존 스타일을 편집할 수도 있습니다. 이건 ChatGPT의 '지시사항'과 비슷하다고 볼 수도 있지만, 클로드에서는 훨씬 더 명확하고 직관적으로 느껴졌어요. 마치 나만의 비서에게 글쓰기 스타일을 세세하게 알려주는 느낌이랄까요?\n \n클로드로 글을 쓰는 게 즐거운 또 다른 이유는 '사전 설정된 제안'에서 선택할 수 있다는 점입니다. 콘텐츠를 편집하는 옵션도 있고, 심지어 콘텐츠 캘린더나 교육 자료 같은 것을 개발하는 데도 활용할 수 있죠. 물론 저는 AI가 모든 글을 대신 쓰는 것에 대해서는 아직 회의적입니다만, 아이디어의 '윤곽'을 잡는 데는 클로드가 정말 탁월하다고 확신합니다. 거의 대부분의 경우, 저는 ChatGPT 대신 클로드를 사용할 것을 추천하고 싶어요.\n  4. 더 깔끔한 인터페이스와 외관 맞춤 설정\n 솔직히 ChatGPT의 인터페이스도 처음 출시되었을 때에 비하면 많이 좋아졌죠. 특히 '프로젝트(Projects)' 기능은 정말 필수적인 기능이라고 생각합니다. 하지만 동시에, 여전히 클로드 같은 다른 AI 도구에 비해 부족한 부분이 있다고 느낍니다.\nChatGPT는 '프로젝트' 기능을 제외하고는 인터페이스 맞춤 설정 옵션이 그리 많지 않아요. 제가 ChatGPT를 사용하면서 가장 아쉬웠던 점 중 하나였습니다. 그래서 클로드를 처음 사용했을 때 정말 기뻤던 기억이 납니다.\n⚠️ 주의: 클로드에는 아직 ChatGPT의 '프로젝트'와 같은 강력한 대화 정리 기능은 없습니다. 하지만 인터페이스 외관 맞춤 설정 기능으로 사용자의 편의성을 높이는 데 중점을 둡니다.\n\n\n 물론 클로드에는 '프로젝트' 같은 기능이 없다는 점은 아쉽긴 해요 (개인적으로는 이런 기능이 추가되면 정말 좋을 것 같아요!). 하지만 인터페이스를 사용자 입맛에 맞게 조절하는 데 있어서는 정말 최고입니다. 예를 들어, 다양한 글꼴 중에서 선택할 수 있어요. 그리고 전반적으로 클로드 인터페이스의 색상 조합과 전체적인 디자인이 ChatGPT보다 훨씬 더 좋다고 생각합니다. ChatGPT는 약간 '유틸리티적'이고 기능에만 초점을 맞춘 느낌이라면, 클로드는 사용 자체가 정말 '즐겁다'는 느낌을 줍니다. 시각적인 편안함이 작업 효율에도 영향을 미친다고 생각해요.\n  5. 깃허브(GitHub) 통합 및 편리한 채팅 관리 \n\n\n 코딩은 사람들이 클로드를 사용하는 가장 흔한 이유 중 하나이고, 제 생각엔 이 부분에서도 클로드가 ChatGPT보다 더 적합한 도구입니다. 기본적으로 클로드 아티팩트(Claude Artifacts) 내에서 프롬프트를 선택하고 코드를 작성할 수 있는 옵션이 있죠. 여기에 더해, 클로드는 깃허브(GitHub)와 통합됩니다!  \n \n깃허브 통합 기능을 활용하면 자신의 리포지토리(저장소)를 클로드 앱에 연결할 수 있어요. 원하는 리포지토리를 선택해서 클로드로 가져오기만 하면 되죠. 덕분에 코딩 관련 작업이 훨씬 쉬워집니다. 개발자분들이라면 이 기능의 가치를 더 크게 느끼실 거예요. 협업에도 유리하고, 코드 분석이나 개선에도 큰 도움이 될 수 있습니다.\n \n\n\n그리고 이건 제가 개인적으로 정말 사랑하는 기능인데요, 바로 '채팅 일괄 삭제' 기능입니다! ChatGPT의 '프로젝트' 기능이 대화 정리에 도움이 되긴 하지만, 여전히 채팅을 한 번에 여러 개 삭제할 수 없다는 점이 너무 불편했어요. 일일이 지우는 건 정말 지루하고 시간이 많이 걸리는 작업이라, 결국 필요 없는 대화들이 계속 쌓이게 되더라고요. 이 문제를 해결하는 가장 쉬운 방법이 바로 '일괄 삭제'인데, ChatGPT는 아직 이 기능이 없어서 아쉽습니다. 하지만 클로드는 이 기능을 제공합니다! 각 대화 옆의 체크박스를 선택하고 '선택 항목 삭제'를 누르기만 하면 끝이에요. 깔끔하게 정리된 작업 공간은 기분까지 좋게 만들죠. ✨\n \n핵심 요약\n✨ 첫 번째 핵심: 클로드는 대화 시작 시 다양한 카테고리별 초기 프롬프트를 제공하여 아이디어 생성을 돕습니다.\n  두 번째 핵심: ChatGPT보다 훨씬 깔끔하고 이해하기 쉬운 답변 형식으로 정보 파악이 용이합니다.\n  세 번째 핵심: 글쓰기 스타일 맞춤 설정, 사전 제안 등 강력한 글쓰기 보조 기능으로 아웃라인 구성에 탁월합니다.\n ‍  네 번째 핵심: 사용자 친화적인 인터페이스 디자인과 깃허브 통합, 채팅 일괄 삭제 등 편리한 기능들을 제공합니다.\n클로드를 통해 더 스마트하고 효율적인 AI 활용을 경험해보세요!\n❓ 자주 묻는 질문 (FAQ)\nQ1: 클로드가 ChatGPT보다 초기 아이디어 생성에 더 좋다고 하는 이유는 무엇인가요?\nA1: 클로드는 새로운 대화를 시작할 때 다양한 카테고리로 분류된 초기 프롬프트 옵션을 제공하여 사용자가 질문을 시작하기 전에 아이디어를 얻고 생각을 확장하는 데 도움을 줍니다. ChatGPT는 커스텀 GPT 외에는 이런 기능이 부족합니다.\nQ2: 클로드의 답변 가독성이 뛰어나다고 했는데, 어떤 점이 다른가요?\nA2: 클로드는 복잡한 정보를 깔끔하고 구조화된 형태로 제시하여 한눈에 내용을 파악하기 쉽게 합니다. 반면 ChatGPT는 정보의 양이 많을 때 다소 복잡하게 느껴질 수 있습니다.\nQ3: 글쓰기 기능에서 클로드가 ChatGPT보다 뛰어난 점은 무엇인가요?\nA3: 클로드는 글쓰기 스타일 변경(간결, 설명, 공식 등) 기능과 맞춤 스타일 생성, 그리고 콘텐츠 편집 및 개발을 위한 사전 설정 제안 등을 제공하여 글의 아웃라인을 잡거나 특정 톤앤매너에 맞춰 글을 작성할 때 유용합니다.\nQ4: 클로드의 인터페이스 외관 맞춤 설정은 어떤 특징이 있나요?\nA4: 클로드는 다양한 글꼴 옵션을 제공하며, 전반적인 색상 조합과 디자인이 사용자 친화적이고 시각적으로 편안함을 줍니다. ChatGPT에 비해 더 개인화된 작업 환경을 만들 수 있습니다.\n \n결론적으로, ChatGPT가 여전히 강력한 AI 도구인 것은 분명합니다. 하지만 제가 직접 경험해본 결과, 초기 아이디어 자동 생성, 가독성 높은 답변, 풍부한 글쓰기 맞춤 설정, 사용자 친화적인 인터페이스, 그리고 개발자를 위한 깃허브 통합과 편리한 채팅 관리 기능까지, 클로드가 여러 면에서 ChatGPT를 능가하는 '숨겨진 보석'이라는 생각이 듭니다. 특히 AI를 활용해 새로운 아이디어를 얻거나, 복잡한 정보를 깔끔하게 정리하고 싶은 분들에게 클로드는 정말 매력적인 대안이 될 수 있을 거예요. 여러분도 이 똑똑한 AI 대안을 직접 경험해보시고, 여러분의 작업 방식을 한 단계 업그레이드해보시는 건 어떨까요? 분명 후회하지 않으실 겁니다!",
        "guid": "http://muzbox.tistory.com/483645",
        "categories": [
          "AI, 미래기술/AI 인사이트",
          "ai 글쓰기 도구",
          "ai 생산성",
          "AI 아이디어 생성",
          "chatgpt 대안",
          "Claude vs ChatGPT",
          "생성형 ai 활용",
          "업무 효율 AI",
          "인공지능 챗봇",
          "초기 아이디어 발상",
          "클로드 ai"
        ],
        "isoDate": "2025-08-21T04:56:34.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "샤말란의눈",
        "title": "[MULTI] 게임스컴 2025, 공식 방송 및 관련 기사 종합",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2349",
        "pubDate": "Mon, 25 Aug 2025 08:19:51 +0900",
        "author": "샤말란의눈",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/25/07/09/197ef69a13b13b2a1.png\">",
        "contentSnippet": "",
        "categories": [
          "특집"
        ],
        "isoDate": "2025-08-24T23:19:51.000Z"
      },
      {
        "creator": "｜RULIWEB｜",
        "title": "악역영애 4컷 만화 - 15화, 배고픈데스와",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2348",
        "pubDate": "Wed, 20 Aug 2025 20:54:58 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i1.ruliweb.com/thumb/25/08/20/198c7549ea451ad6b.jpg\">",
        "contentSnippet": "",
        "categories": [
          "웹툰"
        ],
        "isoDate": "2025-08-20T11:54:58.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": [
      {
        "title": "내가 가본 우리나라 앱 개발 뒷 이야기",
        "link": "https://jeho.page/essay/2025/08/27/my-korea-map.html",
        "pubDate": "2025-08-26T15:59:00.000Z",
        "author": "김재호",
        "content": "<p>며칠 전 공개했던 <a href=\"/essay/2025/08/01/my-korea-map.html\">내가 가본 우리나라</a> 웹사이트를 앱으로도 만들어봤습니다.<br />\n<a href=\"https://play.google.com/store/apps/details?id=com.my.koreamap&amp;hl=ko\">안드로이드</a>, <a href=\"https://apps.apple.com/kr/app/id6749817480\">아이폰</a> 그리고 맥 앱까지. (맥은 아직 심사 중이에요)</p>\n\n<p>간단한 아이디어였고 제가 쓰고 싶은 마음에 만들기도 했지만,<br />\n레일즈 8을 좀 더 알아보고자 하는 마음.<br />\n제 기술 스택을 정돈해 보고 싶은 마음이 있었어요.</p>\n\n<p>루비 온 레일즈, Vue.js, React<br />\nSwiftUI, 플러터, React Native, Universal Windows Platform</p>\n\n<p>계속 이렇게 공부만 하면서 왔다 갔다 해야 하나?<br />\n좀 잘 정리해서 내 주력 스택을 확정시킬 순 없을까?</p>\n\n<p>루비 온 레일즈 8의 기본 기능을 최대한 활용해 보고 싶었습니다.</p>\n<ul>\n  <li>Hotwire, Stimulus, Turbo, importmap을 통한 외부 종속성 없는 자바스크립트 환경.</li>\n  <li>Kamal 을 통한 배포.</li>\n  <li>Solid Queue를 통한 백그라운드 작업.</li>\n  <li>Solid Cache 캐싱.</li>\n  <li>sqlite와 홈서버로 프로덕션 환경 운영해 보기.</li>\n  <li><del>Hotwire Native를 통한 모바일 앱 개발까지.</del></li>\n</ul>\n\n<p>웹사이트를 다 만들고 나서 아주 홀가분했습니다. Hotwire에 대해 거의 아는 게 없었지만 AI 덕분에 수월했어요.<br />\nReact 같은 걸 쓸 필요가 있나? 하는 생각을 많이 했습니다. Webpack이나 Vite 같은 피곤한 도구들 안 봐도 되는 것도 정말 좋았고요.</p>\n\n<p>모바일 앱을 만들기 위해 <a href=\"https://native.hotwired.dev/\">Hotwire Native</a>와 이틀 정도 씨름하다가…<br />\n이건 도저히 안 되겠다. 더러워서 못 해먹겠다 하고 포기했습니다.</p>\n\n<p>결국 플러터를 선택해서 안드로이드, 아이폰, 맥 앱을 만들었습니다.<br />\n총 코드는 90% 정도가 레일즈이고 10% 정도가 플러터.</p>\n\n<p>클로드 코드로만 작업했고, 제가 직접 코드에 관여한 부분은 없었던 것 같아요.<br />\n클로드 코드를 사용할 때는 <a href=\"/essay/2025/07/23/context-swiching.html\">여러 작업을 병렬로 안 하고 최대한 순차적으로</a> 진행하려고 노력했습니다.<br />\n다른 프로젝트도 신경 쓰지 않고요. 안 그러면 제 머리가 따라갈 수 없어서.  <br />\n여담이지만 저는 클로드 코드에 mcp도 하나도 연결하지 않았고, 남들이 만든 agents.md 같은 것들도 잘 보지 않습니다. 노땅이 다 된 것 같아요.</p>\n\n<p>규모가 작은 앱이긴 하지만, 이번 작업으로 이 스택에 자신감이 생겼습니다.<br />\n앞으로도 새로운 서비스 만들 땐 이렇게 만들지 않을까 싶습니다. 😁\n<br />\n<br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2023/01/04/dont-say-ruby-is-slow.html\">루비가 느리다고?</a></li>\n  <li><a href=\"/essay/2024/04/29/home-server.html\">집에서 서버를 운영하는 게 가능한가요?</a></li>\n  <li><a href=\"/essay/2025/08/11/solo-developer.html\">진짜 1인 개발자 전성시대</a></li>\n</ul>",
        "contentSnippet": "며칠 전 공개했던 내가 가본 우리나라 웹사이트를 앱으로도 만들어봤습니다.\n안드로이드, 아이폰 그리고 맥 앱까지. (맥은 아직 심사 중이에요)\n간단한 아이디어였고 제가 쓰고 싶은 마음에 만들기도 했지만,\n루비 온 레일즈, Vue.js, React\n계속 이렇게 공부만 하면서 왔다 갔다 해야 하나?\n루비 온 레일즈 8의 기본 기능을 최대한 활용해 보고 싶었습니다.\nHotwire, Stimulus, Turbo, importmap을 통한 외부 종속성 없는 자바스크립트 환경.\nKamal 을 통한 배포.\nSolid Queue를 통한 백그라운드 작업.\nSolid Cache 캐싱.\nsqlite와 홈서버로 프로덕션 환경 운영해 보기.\nHotwire Native를 통한 모바일 앱 개발까지.\n웹사이트를 다 만들고 나서 아주 홀가분했습니다. Hotwire에 대해 거의 아는 게 없었지만 AI 덕분에 수월했어요.\n모바일 앱을 만들기 위해 Hotwire Native와 이틀 정도 씨름하다가…\n결국 플러터를 선택해서 안드로이드, 아이폰, 맥 앱을 만들었습니다.\n클로드 코드로만 작업했고, 제가 직접 코드에 관여한 부분은 없었던 것 같아요.\n여러 작업을 병렬로 안 하고 최대한 순차적으로 진행하려고 노력했습니다.\n규모가 작은 앱이긴 하지만, 이번 작업으로 이 스택에 자신감이 생겼습니다.\n함께 읽으면 좋은 글:\n루비가 느리다고?\n집에서 서버를 운영하는 게 가능한가요?\n진짜 1인 개발자 전성시대",
        "summary": "며칠 전 공개했던 내가 가본 우리나라 웹사이트를 앱으로도 만들어봤습니다. 안드로이드, 아이폰 그리고 맥 앱까지. (맥은 아직 심사 중이에요)",
        "id": "https://jeho.page/essay/2025/08/27/my-korea-map",
        "isoDate": "2025-08-26T15:59:00.000Z"
      }
    ]
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "유니티 옷감 머리 가슴 구현 / 매지카 클로우즈 애셋 / Magica Cloth",
        "link": "http://serverdown.tistory.com/1383",
        "pubDate": "Tue, 26 Aug 2025 20:59:15 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1383#entry1383comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"802\" data-origin-height=\"494\"><span data-url=\"https://blog.kakaocdn.net/dn/mbf6T/btsP564JOjY/aMF2BwYv7sdwPF6Fb21HJ0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/mbf6T/btsP564JOjY/aMF2BwYv7sdwPF6Fb21HJ0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/mbf6T/btsP564JOjY/aMF2BwYv7sdwPF6Fb21HJ0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fmbf6T%2FbtsP564JOjY%2FaMF2BwYv7sdwPF6Fb21HJ0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"802\" height=\"494\" data-origin-width=\"802\" data-origin-height=\"494\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">장점은 리깅 없이 구현할 수 있다는 것입니다.</p>\n<p data-ke-size=\"size16\">Boing 으로 해봤는데 Boing 은 뼈가 있어야합니다.</p>\n<p data-ke-size=\"size16\">불편하기도하고 옷감 퀄리티도 나지 않습니다.&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=Md-NCpkwt_Y\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=Md-NCpkwt_Y</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=Md-NCpkwt_Y\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bfpeVP/hyZC4IIetR/6d2XMHOPXBeQjeG0ykhO80/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/dzhnL4/hyZCYaGiQK/Nn4EhU6bCquRK1hbTPgxS0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"[유니티] Magica Cloth 2 에셋 소개 및 사용 방법.\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/Md-NCpkwt_Y\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상 참고하시구요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"441\" data-origin-height=\"182\"><span data-url=\"https://blog.kakaocdn.net/dn/dQOmxk/btsP7A4MPCO/K4tKdIAnhkFmsGevUcwU90/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dQOmxk/btsP7A4MPCO/K4tKdIAnhkFmsGevUcwU90/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dQOmxk/btsP7A4MPCO/K4tKdIAnhkFmsGevUcwU90/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdQOmxk%2FbtsP7A4MPCO%2FK4tKdIAnhkFmsGevUcwU90%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"441\" height=\"182\" data-origin-width=\"441\" data-origin-height=\"182\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">저는 할인 할때 사둡니다.</p>\n<p data-ke-size=\"size16\">버튜버에도 쓸 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "장점은 리깅 없이 구현할 수 있다는 것입니다.\nBoing 으로 해봤는데 Boing 은 뼈가 있어야합니다.\n불편하기도하고 옷감 퀄리티도 나지 않습니다. \n \n영상: https://www.youtube.com/watch?v=Md-NCpkwt_Y\n\n\n\n \n영상 참고하시구요\n \n\n\n저는 할인 할때 사둡니다.\n버튜버에도 쓸 수 있습니다.",
        "guid": "http://serverdown.tistory.com/1383",
        "categories": [
          "프로그래밍/유니티 에셋 리뷰",
          "매지카",
          "옷감",
          "유니티"
        ],
        "isoDate": "2025-08-26T11:59:15.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "게임 양산으로 대박이난 인디개발사 / 아울캐미 랩스 Owlchemy Labs",
        "link": "http://serverdown.tistory.com/1382",
        "pubDate": "Mon, 25 Aug 2025 17:41:35 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1382#entry1382comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"960\" data-origin-height=\"384\"><span data-url=\"https://blog.kakaocdn.net/dn/bYZCaK/btsP6LkAvkM/umnUqXKMmXAMNZH4Za3ru0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bYZCaK/btsP6LkAvkM/umnUqXKMmXAMNZH4Za3ru0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bYZCaK/btsP6LkAvkM/umnUqXKMmXAMNZH4Za3ru0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbYZCaK%2FbtsP6LkAvkM%2FumnUqXKMmXAMNZH4Za3ru0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"960\" height=\"384\" data-origin-width=\"960\" data-origin-height=\"384\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=VDFBVXhHYwc\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=VDFBVXhHYwc</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=VDFBVXhHYwc\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/v20Y0/hyZC4ayGT5/Gw4g09daumzv0NUmedjpV0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/hUwiJ/hyZDXojZA9/7hik49W5czNk41uUzkbstk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"앱스토어를 떠도는 쓰레기 게임들의 충격적 정체\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/VDFBVXhHYwc\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">똥게임들에 환멸을 느껴 게임을 자동으로 만들고</p>\n<p data-ke-size=\"size16\">배포하는 프로그램을 만들어 어마어마한 양의 게임을 출시한 이팀은 ...</p>\n<h2 data-ke-size=\"size26\">성공했습니다.</h2>\n<p data-ke-size=\"size16\">그들의 성공스토리를 배워봅시다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=VDFBVXhHYwc\n\n\n\n \n똥게임들에 환멸을 느껴 게임을 자동으로 만들고\n배포하는 프로그램을 만들어 어마어마한 양의 게임을 출시한 이팀은 ...\n성공했습니다.\n그들의 성공스토리를 배워봅시다.",
        "guid": "http://serverdown.tistory.com/1382",
        "categories": [
          "유튜브",
          "인디게임"
        ],
        "isoDate": "2025-08-25T08:41:35.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "카지노에서 왠 파판 브금이 ...",
        "link": "http://serverdown.tistory.com/1381",
        "pubDate": "Mon, 25 Aug 2025 12:33:09 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1381#entry1381comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"491\" data-origin-height=\"344\"><span data-url=\"https://blog.kakaocdn.net/dn/b7adwK/btsP4cJYJMO/z0umpvVbGtCrNTZgZQyvZK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/b7adwK/btsP4cJYJMO/z0umpvVbGtCrNTZgZQyvZK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/b7adwK/btsP4cJYJMO/z0umpvVbGtCrNTZgZQyvZK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb7adwK%2FbtsP4cJYJMO%2Fz0umpvVbGtCrNTZgZQyvZK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"491\" height=\"344\" data-origin-width=\"491\" data-origin-height=\"344\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=J2ZGFyysmLQ\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=J2ZGFyysmLQ</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=J2ZGFyysmLQ\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/ScFYI/hyZDWCTAM0/KBeUBIKLZr0kJfqO4LAvv1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/mBX8d/hyZDb8uL7d/HWkjN0vHFJCSJC4MtYke81/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"종로구보다 작은 도시 마카오에 도박에 죽고 도박에 사는 한국인들 밀착 취재! | KBS 20040528 방송\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/J2ZGFyysmLQ\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">4:44 에 나옵니다.</p>\n<p data-ke-size=\"size16\">파판x 브금 같군요</p>\n<p data-ke-size=\"size16\">세기말 분위기 나는군욥</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=J2ZGFyysmLQ\n\n\n\n4:44 에 나옵니다.\n파판x 브금 같군요\n세기말 분위기 나는군욥",
        "guid": "http://serverdown.tistory.com/1381",
        "categories": [
          "유튜브",
          "카지노"
        ],
        "isoDate": "2025-08-25T03:33:09.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "신기한 컴퓨터 아이오프너 / 피자 키를 누르면 피자가 주문된다. / i-Opener 아이오프너",
        "link": "http://serverdown.tistory.com/1380",
        "pubDate": "Sun, 24 Aug 2025 18:22:40 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1380#entry1380comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1100\" data-origin-height=\"438\"><span data-url=\"https://blog.kakaocdn.net/dn/bq1jRa/btsP5E6ndXI/k54UsKMe3z6LyFZUDcuO00/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bq1jRa/btsP5E6ndXI/k54UsKMe3z6LyFZUDcuO00/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bq1jRa/btsP5E6ndXI/k54UsKMe3z6LyFZUDcuO00/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbq1jRa%2FbtsP5E6ndXI%2Fk54UsKMe3z6LyFZUDcuO00%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1100\" height=\"438\" data-origin-width=\"1100\" data-origin-height=\"438\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">아이오프너는 90년대 후반 나온 컴퓨터 입니다.</p>\n<p data-ke-size=\"size16\">IT 버블 전에 나왔으시 신기한 물건이겠죠</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">키보드에 피자 키가 있다고 합니다. ㄷㄷ</p>\n<p data-ke-size=\"size16\">누르면 피자가 주문된다는군요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=IxpbNF8_bCM\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=IxpbNF8_bCM</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=IxpbNF8_bCM\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/H1AaL/hyZDS8e4PO/ImoJ2HIo78Kl2YBDoG67bk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/bDvSPE/hyZzKjHE7b/JoM9P71ZAq3QdOPPEEKp9k/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"9만 9천원 (99$) 에 팔던 컴퓨터 때문에 벌어진 10만 달러 소송, 아이오프너 사건\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/IxpbNF8_bCM\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 제품은 99 달러에 저렴하게 팔고</p>\n<p data-ke-size=\"size16\">인터넷통신비를 받아서 수익을 내려고 했습니다.</p>\n<p data-ke-size=\"size16\">전용 인터넷을 써야 동작하도록 만들긴했지만 ... 양덕들이 그만</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">하지만 제품을 뜯어본 사람들이 개조해서 일반 컴퓨터 처럼 쓰기 시작함에 따라</p>\n<p data-ke-size=\"size16\">손해가 나버린 비운의 컴퓨터 입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">전용 인터넷을 사용해주지않으면 당연히 사업이 정상적으로 운영될 수 없었기 때문에</p>\n<p data-ke-size=\"size16\">망해서 사라져 버렸습니다.</p>\n<p data-ke-size=\"size16\">안타깝군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">아이오프너 실기 영상: <a href=\"https://www.youtube.com/watch?v=gvlCM9bnhMo\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=gvlCM9bnhMo</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=gvlCM9bnhMo\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/brOZD9/hyZC3h7TVZ/3yIXef2HebKcqZBe2yU6V1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/JNboA/hyZDStEc1g/QZ5b8fnBJJDcn8qrVzZd2k/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"i-Opener - The $99 Computer That Cost a Company Millions\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/gvlCM9bnhMo\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "아이오프너는 90년대 후반 나온 컴퓨터 입니다.\nIT 버블 전에 나왔으시 신기한 물건이겠죠\n \n키보드에 피자 키가 있다고 합니다. ㄷㄷ\n누르면 피자가 주문된다는군요.\n \n영상: https://www.youtube.com/watch?v=IxpbNF8_bCM\n\n\n\n \n이 제품은 99 달러에 저렴하게 팔고\n인터넷통신비를 받아서 수익을 내려고 했습니다.\n전용 인터넷을 써야 동작하도록 만들긴했지만 ... 양덕들이 그만\n \n하지만 제품을 뜯어본 사람들이 개조해서 일반 컴퓨터 처럼 쓰기 시작함에 따라\n손해가 나버린 비운의 컴퓨터 입니다.\n \n전용 인터넷을 사용해주지않으면 당연히 사업이 정상적으로 운영될 수 없었기 때문에\n망해서 사라져 버렸습니다.\n안타깝군요\n \n \n \n \n아이오프너 실기 영상: https://www.youtube.com/watch?v=gvlCM9bnhMo",
        "guid": "http://serverdown.tistory.com/1380",
        "categories": [
          "유튜브"
        ],
        "isoDate": "2025-08-24T09:22:40.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "무한 애너지 획득을 위한 탄계",
        "link": "http://serverdown.tistory.com/1379",
        "pubDate": "Sun, 24 Aug 2025 00:22:04 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1379#entry1379comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"468\" data-origin-height=\"335\"><span data-url=\"https://blog.kakaocdn.net/dn/cgFc6t/btsP4iJVvsN/A1EXNPnUKPKFksHrtIaTyk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cgFc6t/btsP4iJVvsN/A1EXNPnUKPKFksHrtIaTyk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cgFc6t/btsP4iJVvsN/A1EXNPnUKPKFksHrtIaTyk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcgFc6t%2FbtsP4iJVvsN%2FA1EXNPnUKPKFksHrtIaTyk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"468\" height=\"335\" data-origin-width=\"468\" data-origin-height=\"335\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=daRSa6YZKyg\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=daRSa6YZKyg</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=daRSa6YZKyg\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bgGtxW/hyZC9CtZ0w/DWfjeph8lzafXzzdWPMGx1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/eGcOme/hyZzxq5FYb/l1tBVisEd9HWBdKzYhHo50/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"핵융합 상용화를 앞당길 뿐 아니라 인류가 처한 문제들을 해결해낼 혁신 기술\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/daRSa6YZKyg\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">원자력 발전은 지구에 있는걸 다 캐봐야 만년 정도 갑니다.</p>\n<p data-ke-size=\"size16\">하지막 핵폐기물은 5만년을 기다려야하기 때문에 무한희 쓸 수는 없습니다.</p>\n<p data-ke-size=\"size16\">그래서 영상에서는</p>\n<p data-ke-size=\"size16\">핵발전소를 돌린 전기로 입자가속기를 돌려 지구에서 삼중수소를 만드는 방법을 소개하고 있습니다.</p>\n<p data-ke-size=\"size16\">핵육합 발전은 아직 상용회되진 않았지만 이것까지 된다면</p>\n<p data-ke-size=\"size16\">핵발전소로 삼중수소를 만들고&nbsp;</p>\n<p data-ke-size=\"size16\">삼중수소로 핵융합발전을 하고</p>\n<p data-ke-size=\"size16\">전기로 공기중에 이산화 탄소로 석유까지 만들고 나면 무한 루프가 완성됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">거기다 무중성자 핵융합까지가면 그냥 바다물로 핵융합이 되기 때문에 위의 절차를 다 뛰어 넘을 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상에서 논란점은 에너지만 무한하다면 공기중의 이산화탄소를 석유로 돌릴 수 있다는거 ...</p>\n<p data-ke-size=\"size16\">와 쩐다..</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=daRSa6YZKyg\n\n\n\n \n원자력 발전은 지구에 있는걸 다 캐봐야 만년 정도 갑니다.\n하지막 핵폐기물은 5만년을 기다려야하기 때문에 무한희 쓸 수는 없습니다.\n그래서 영상에서는\n핵발전소를 돌린 전기로 입자가속기를 돌려 지구에서 삼중수소를 만드는 방법을 소개하고 있습니다.\n핵육합 발전은 아직 상용회되진 않았지만 이것까지 된다면\n핵발전소로 삼중수소를 만들고 \n삼중수소로 핵융합발전을 하고\n전기로 공기중에 이산화 탄소로 석유까지 만들고 나면 무한 루프가 완성됩니다.\n \n거기다 무중성자 핵융합까지가면 그냥 바다물로 핵융합이 되기 때문에 위의 절차를 다 뛰어 넘을 수 있습니다.\n \n영상에서 논란점은 에너지만 무한하다면 공기중의 이산화탄소를 석유로 돌릴 수 있다는거 ...\n와 쩐다..",
        "guid": "http://serverdown.tistory.com/1379",
        "categories": [
          "유튜브",
          "핵융합"
        ],
        "isoDate": "2025-08-23T15:22:04.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "망하는 도시에 모여든다. / 탕핑족의 밝은 미래 / 은퇴사연",
        "link": "http://serverdown.tistory.com/1378",
        "pubDate": "Sat, 23 Aug 2025 18:09:12 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1378#entry1378comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"610\" data-origin-height=\"338\"><span data-url=\"https://blog.kakaocdn.net/dn/5Kx5n/btsP4bqv2ab/8lyRlfL8vPuKqorvkvMzY0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/5Kx5n/btsP4bqv2ab/8lyRlfL8vPuKqorvkvMzY0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/5Kx5n/btsP4bqv2ab/8lyRlfL8vPuKqorvkvMzY0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F5Kx5n%2FbtsP4bqv2ab%2F8lyRlfL8vPuKqorvkvMzY0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"610\" height=\"338\" data-origin-width=\"610\" data-origin-height=\"338\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=JsMQvfApluk\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=JsMQvfApluk</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=JsMQvfApluk\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/mn8Qw/hyZC4VorQN/1wnCPkN06WwwKZAq9qItuk/img.jpg?width=1280&amp;height=720&amp;face=108_64_196_160,https://scrap.kakaocdn.net/dn/UjfKe/hyZDRuCduf/wLiVKSvRpiX4u5797VYM2k/img.jpg?width=1280&amp;height=720&amp;face=108_64_196_160\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"중국 몰락한 도시에서 일어나고 있는 기괴한 현상! 후이저우!\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/JsMQvfApluk\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">탕핑족이란</h2>\n<p data-ke-size=\"size16\">누워있는 사람이라는 뜻으로 중국 공산당의 영향을 벗어나기위해 아무것도 하지 않는 사람을 의미합니다.</p>\n<p data-ke-size=\"size16\">중국 공산당은 무슨일을하든 온갖명목의 세금과 벌금으로 뜻어가기 때문에 사화활동을 아예 안해버리는 방법을 씁니다.</p>\n<p data-ke-size=\"size16\">만약 활동을 한다해도 최소금액만 사용하고 고 나중을위해 모읍니다.+</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"text-align: start;\">중국의 부동산 몰락</span></h2>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">중국은 코로나이후 최악의 부동산 침체를 겪고 있습니다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">그러다보니 일부지역의 아파트 가격은 -90% 까지도 내려갔다고 합니다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">중국의 망한도시중에 관광지는 새로운 시장이 형성되고 있다고 합니다.</span></p>\n<p data-ke-size=\"size16\">쫄딱 망해서 월세를 포함해 모든 물가가 떡락하다보니 탕핑 족들이 이곳으로 모이고 있다고 합니다.</p>\n<p data-ke-size=\"size16\">월 50만원 이하로 생활한다고 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">부동산 소유자들에게는 나쁜일이겠지만</p>\n<p data-ke-size=\"size16\">물가가 낮아짐에 따라 사람이 모여들고 저렴한 생활이 가능하다고 합니다.</p>\n<p data-ke-size=\"size16\">그러다보니 시장도 돌아가고 도시가 정상적으로 돌아가게 되었다는</p>\n<p data-ke-size=\"size16\">훈훈한 이야기 였습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">어느곳이나 바닥을 치면 좋아지기 마련이거 같습니다..</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=JsMQvfApluk\n\n\n\n \n탕핑족이란\n누워있는 사람이라는 뜻으로 중국 공산당의 영향을 벗어나기위해 아무것도 하지 않는 사람을 의미합니다.\n중국 공산당은 무슨일을하든 온갖명목의 세금과 벌금으로 뜻어가기 때문에 사화활동을 아예 안해버리는 방법을 씁니다.\n만약 활동을 한다해도 최소금액만 사용하고 고 나중을위해 모읍니다.+\n \n중국의 부동산 몰락\n중국은 코로나이후 최악의 부동산 침체를 겪고 있습니다.\n그러다보니 일부지역의 아파트 가격은 -90% 까지도 내려갔다고 합니다.\n중국의 망한도시중에 관광지는 새로운 시장이 형성되고 있다고 합니다.\n쫄딱 망해서 월세를 포함해 모든 물가가 떡락하다보니 탕핑 족들이 이곳으로 모이고 있다고 합니다.\n월 50만원 이하로 생활한다고 합니다.\n \n부동산 소유자들에게는 나쁜일이겠지만\n물가가 낮아짐에 따라 사람이 모여들고 저렴한 생활이 가능하다고 합니다.\n그러다보니 시장도 돌아가고 도시가 정상적으로 돌아가게 되었다는\n훈훈한 이야기 였습니다.\n \n \n어느곳이나 바닥을 치면 좋아지기 마련이거 같습니다..",
        "guid": "http://serverdown.tistory.com/1378",
        "categories": [
          "유튜브",
          "은퇴",
          "중국",
          "탕핑족"
        ],
        "isoDate": "2025-08-23T09:09:12.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "케이팝 문화는 아타리 쇼크 처럼 될 가능성이 있다.",
        "link": "http://serverdown.tistory.com/1377",
        "pubDate": "Fri, 22 Aug 2025 20:43:52 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1377#entry1377comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"200\" data-origin-height=\"250\"><span data-url=\"https://blog.kakaocdn.net/dn/boO3aa/btsP13tuR8U/l8uOKZWF6kYRS2Ubd4qS00/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/boO3aa/btsP13tuR8U/l8uOKZWF6kYRS2Ubd4qS00/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/boO3aa/btsP13tuR8U/l8uOKZWF6kYRS2Ubd4qS00/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FboO3aa%2FbtsP13tuR8U%2Fl8uOKZWF6kYRS2Ubd4qS00%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"200\" height=\"250\" data-origin-width=\"200\" data-origin-height=\"250\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=LyQ5hhm90B4\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=LyQ5hhm90B4</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=LyQ5hhm90B4\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/nHbjK/hyZyfRHiX2/PZBfDUrTjGIgTPRhamEtg0/img.jpg?width=1280&amp;height=720&amp;face=30_184_518_390,https://scrap.kakaocdn.net/dn/cFBrES/hyZDMmrbhE/aks0my1REfgo0muHmK0WZ0/img.jpg?width=1280&amp;height=720&amp;face=30_184_518_390\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"영화에 나오는 한글이 미국에서 난리난 이유 | 케데헌이 만들어낸 미국의 사회 현상 | 해외반응\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/LyQ5hhm90B4\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">내용 중에 아타리쇼크가 나옵니다.</p>\n<p data-ke-size=\"size16\">무슨 이야기냐하면</p>\n<p data-ke-size=\"size16\">돈이되는걸 알게 되면 미디어가 어마어마한 양이 양산이 되는데</p>\n<p data-ke-size=\"size16\">그러면 돈만 먹으려고 떨어지는 퀄리티로 양상이 되며 나중에 버린다는 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">헐리우드에 중국 자본이 들어갈때도 영화에 역활이 엉성한 중국 배우가 나오면서</p>\n<p data-ke-size=\"size16\">퀀리티가 떨어지는 현상이 있었는데 그런식인거 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">꼭 그렇게 된다기 보다는 잘못되기 시작한다면</p>\n<p data-ke-size=\"size16\">이 문제로 잘못될 가능성이 있다고 보시면됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">10년후에나 있을일일 수도 있으니</p>\n<p data-ke-size=\"size16\">주의해야합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=LyQ5hhm90B4\n\n\n\n \n \n내용 중에 아타리쇼크가 나옵니다.\n무슨 이야기냐하면\n돈이되는걸 알게 되면 미디어가 어마어마한 양이 양산이 되는데\n그러면 돈만 먹으려고 떨어지는 퀄리티로 양상이 되며 나중에 버린다는 것입니다.\n \n헐리우드에 중국 자본이 들어갈때도 영화에 역활이 엉성한 중국 배우가 나오면서\n퀀리티가 떨어지는 현상이 있었는데 그런식인거 같습니다.\n \n꼭 그렇게 된다기 보다는 잘못되기 시작한다면\n이 문제로 잘못될 가능성이 있다고 보시면됩니다.\n \n10년후에나 있을일일 수도 있으니\n주의해야합니다.",
        "guid": "http://serverdown.tistory.com/1377",
        "categories": [
          "유튜브"
        ],
        "isoDate": "2025-08-22T11:43:52.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": [
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "조직에서 부대끼기",
        "link": "http://jojoldu.tistory.com/842",
        "pubDate": "Thu, 21 Aug 2025 08:29:36 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "http://jojoldu.tistory.com/842#entry842comment",
        "content": "<p>요즘 한수희 작가님의 에세이 - <a href=\"https://product.kyobobook.co.kr/detail/S000211600335\">오늘도 우리는 나선으로 걷는다</a> 를 짬짬이 시간 날때마다 읽고 있는데요.<br>아래 문장이 생각보다 기억에 오래 남아서 공유드리고 싶었어요 </p>\n<blockquote data-ke-style=\"style2\"><p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Serif KR';\"><p><strong>나와 말이 안 통하는 사람, 내 말에 토를 다는 사람, 나를 기분 나쁘게 하는 사람을 만나는 건 정말 짜증 나는 일이다</strong>.<br>심지어 그런 사람들과 매일 얼굴을 맞대고 일까지 해야 하다니, 그건 얼마나 큰 고통인가.<br>하지만 그들이 없다면 내가 어떤 사람인지 알 수 있을까? 인간의 개성은 타인과 내가 부딪치는 경계에서 마찰흔처럼 드러난다.<br>자기만의 방에 갇힌 채 내 좁은 시야 안에 들어오는 것들만을 세상의 전부로 여기지 않기 위하여,<br>내 인생만 망했다는 착각에서 헤어나기 위하여,<br>자기 자신을 있는 그대로 받아들이기 위하여<br><strong>우리는 오늘도 문을 열고 타인과 지지고 볶는 삶을 향해 한 발을 내딛는 것이다</strong></p>\n</span></p></blockquote><p>저는 개인주의 성향이 강하고, 글쓰기나 독서 같이 혼자 하는 활동을 좋아하고, 원래 직업도 개발자이기도 했어서 1인 기업이나 솔로프리너로의 진로는 고민하지 않는지 질문을 많이 받는데요.<br>그럴때마다 혼자서는 성과를 잘 내지 못하고, 같이 있을때 성과를 잘 내는 사람인걸 지난 커리어동안 잘 알게되서 조직 내에서의 나로서 성과를 내는것에 집중하고 있다고 답변 드리곤 했어요.  </p>\n<p>예전엔 좋은 커리어를 쌓은 뒤, 컨설팅이나 1인기업으로 빠지는 것에 대해 고민하기도 했는데,<br>조직 안에서 이런 저런 여러 사람들과 부딪치면서 살면서 사실은 같이 있을때 훨씬 더 잘할 수 있는 사람임을 알게 되어서 이제는 그런 고민을 하지는 않게 되었어요.  </p>\n<p>그런 의미에서 조직 생활은 저 스스로가 어떤 사람인지, 내가 생각한 나와 진짜 나는 어떻게 다른지 알 수 있는 좋은 시간들인 것 같단 생각을 유독 많이 하고 있습니다.</p>\n<p>비단 저 책 뿐만 아니라 되게 많은 부분에서 마음 속 한뼘 돌아볼 여유를 주는 책은 정말 많습니다.<br>너무 마음이 복잡할땐 &quot;일기&quot; 같은 남의 생각(에세이) 을 엿보시면 아마도 그런 여유를 얻으실 수 있으실 것 같아요.  </p>\n<p>무더운 날씨,<br>척박한 주변 환경 등에서도<br>조직 혹은 사람에게서의 온기는 얻을 수 있다고 생각합니다.<br>오늘도 다들 작은 온기라도 얻어가실 수 있는 하루가 되시길 바랄게요!</p>\n<blockquote data-ke-style=\"style2\"><p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Serif KR';\"><p>조직에서도 좋은 소식들을 들려드릴 수 있도록 계속 노력하겠습니다.</p>\n</span></p></blockquote>",
        "contentSnippet": "요즘 한수희 작가님의 에세이 - 오늘도 우리는 나선으로 걷는다 를 짬짬이 시간 날때마다 읽고 있는데요.\n아래 문장이 생각보다 기억에 오래 남아서 공유드리고 싶었어요 \n\n나와 말이 안 통하는 사람, 내 말에 토를 다는 사람, 나를 기분 나쁘게 하는 사람을 만나는 건 정말 짜증 나는 일이다.\n심지어 그런 사람들과 매일 얼굴을 맞대고 일까지 해야 하다니, 그건 얼마나 큰 고통인가.\n하지만 그들이 없다면 내가 어떤 사람인지 알 수 있을까? 인간의 개성은 타인과 내가 부딪치는 경계에서 마찰흔처럼 드러난다.\n자기만의 방에 갇힌 채 내 좁은 시야 안에 들어오는 것들만을 세상의 전부로 여기지 않기 위하여,\n내 인생만 망했다는 착각에서 헤어나기 위하여,\n자기 자신을 있는 그대로 받아들이기 위하여\n우리는 오늘도 문을 열고 타인과 지지고 볶는 삶을 향해 한 발을 내딛는 것이다\n\n저는 개인주의 성향이 강하고, 글쓰기나 독서 같이 혼자 하는 활동을 좋아하고, 원래 직업도 개발자이기도 했어서 1인 기업이나 솔로프리너로의 진로는 고민하지 않는지 질문을 많이 받는데요.\n그럴때마다 혼자서는 성과를 잘 내지 못하고, 같이 있을때 성과를 잘 내는 사람인걸 지난 커리어동안 잘 알게되서 조직 내에서의 나로서 성과를 내는것에 집중하고 있다고 답변 드리곤 했어요.  \n예전엔 좋은 커리어를 쌓은 뒤, 컨설팅이나 1인기업으로 빠지는 것에 대해 고민하기도 했는데,\n조직 안에서 이런 저런 여러 사람들과 부딪치면서 살면서 사실은 같이 있을때 훨씬 더 잘할 수 있는 사람임을 알게 되어서 이제는 그런 고민을 하지는 않게 되었어요.  \n그런 의미에서 조직 생활은 저 스스로가 어떤 사람인지, 내가 생각한 나와 진짜 나는 어떻게 다른지 알 수 있는 좋은 시간들인 것 같단 생각을 유독 많이 하고 있습니다.\n비단 저 책 뿐만 아니라 되게 많은 부분에서 마음 속 한뼘 돌아볼 여유를 주는 책은 정말 많습니다.\n너무 마음이 복잡할땐 \"일기\" 같은 남의 생각(에세이) 을 엿보시면 아마도 그런 여유를 얻으실 수 있으실 것 같아요.  \n무더운 날씨,\n척박한 주변 환경 등에서도\n조직 혹은 사람에게서의 온기는 얻을 수 있다고 생각합니다.\n오늘도 다들 작은 온기라도 얻어가실 수 있는 하루가 되시길 바랄게요!\n\n조직에서도 좋은 소식들을 들려드릴 수 있도록 계속 노력하겠습니다.",
        "guid": "http://jojoldu.tistory.com/842",
        "categories": [
          "생각정리",
          "인프런",
          "조직생활",
          "터틀넥프레스",
          "한수희"
        ],
        "isoDate": "2025-08-20T23:29:36.000Z"
      }
    ]
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": [
      {
        "creator": "megayuchi",
        "title": "nano-banana  테스트 후기",
        "link": "https://megayuchi.com/2025/08/21/7152/",
        "pubDate": "Thu, 21 Aug 2025 08:20:02 +0000",
        "content:encodedSnippet": "​\n강의 만들어야 하지만 집중도 안되고 해서 몇 일 째 nano-banana 갖고 노는 중이다. 내 게임 캐릭터와 피규어의 이미지를 소스로 이런 저런 시도들을 해보고 있는데 나름 괜찮게 뽑히는 경우도 있음.\n근데 한방에 간단하게 나오는 경우는 없고, 짧은 시간 안에 원하는 결과물이 나와도 워낙 저해상도라서 후작업에 엄청 시간이 많이 들어갔다.\n​\n\n\n\n현재 nano-banana을 직접 사용할 수 있는 방법은 없는 것으로 알고 있다. https://lmarena.ai 에서 ai모델간 배틀을 시켜보면 랜덤하게 nano-banana모델을 사용한다. 통계적으로 한 30% – 50%정도는 사용하는 듯 하다.\n​\n\n\n\n1) 피규어 이미지나 캐릭터 캡처 이미지를 넣고 원하는 포즈 나올때까지 프롬프트와 이미지 조합을 바꿔가며 시도.\n2) 원하는 포즈 나오면 그 이미지로 원하는 그림풍 나올때까지 계속 시도.\n3) 원하는 분위기 나오면 얼굴 크롭해서 비슷한 그림풍이 나올때까지 계속 시도. 얼굴만 따로 잘라서 돌리는 이유는 lmarena가 출력하는 결과물이 너무 저해상도라서 캐릭터 얼굴의 디테일이 다 무너짐. 눈이 치명적이고 특히 속눈썹은 원본에서 살아있더라도 lmarena 거치면 다 사라진다. 얼굴을 크롭해서 결과물 사이즈보다 작게 만들어서 넣으면 최종 결과물에서 디테일을 어느 정도 보존할 수 있다.\n4) 머리칼의 형태가 무너지는 경우들이 있는데 이것도 머리칼이 나오게 크롭해서 집어넣고 원하는 형태가 나올때까지 돌린다.\n5)이렇게 여러 조각들의 이미지를 얻은 다음 얘네들을 ai업스케일로 2x나 4x로 업스케일\n6) 업스케일된 이미지들을 포토샵에서 모아서 붙이기. 이음매쪽은 당연히 안맞기 때문에 노가다 작업 엄청 해야한다. 절반까진 오바고 1/4 정도는 새로 그리다시피 했다. 이 모든 작업에서 포토샵에서 편집하는 시간이 제일 오래 걸렸다.\n​\n\n\n\n[결론]\nnano-banana의 이미지 생성 품질이 뛰어나다는건 인정. 하지만 완벽과 거리가 멀고 우연에 상당히 좌우되며 삑사리도 적지 않다. 보정에 정말 시간 많이 들어갔다.\n스팀에 게임 업로드 하려고 해도 패키지 일러스트를 첨부해야 하는데 요샌 기준이 빡빡해져서 게임 캡쳐샷 넣으면 리젝당한다. 나같은 돈없는 인디 개발자들은 나노바나나 같은 ai가 도움이 된다.\n근데 아트 팀원이 있거나 외주비용 쓸 수 있으면 사람한테 시킬거다. 내 결론은 그렇다. 사람한테 시키는게 시간이나 품질이나 훨 낫다.",
        "dc:creator": "megayuchi",
        "comments": "https://megayuchi.com/2025/08/21/7152/#respond",
        "content": "​ 강의 만들어야 하지만 집중도 안되고 해서 몇 일 째 nano-banana 갖고 노는 중이다. 내 게임 캐릭터와 피규어의 이미지를 소스로 이런 저런 시도들을 해보고 있는데 나름 괜찮게 뽑히는 경우도 있음. 근데 한방에 간단하게 나오는 경우는 없고, 짧은 시간 안에 원하는 결과물이 나와도 워낙 저해상도라서 후작업에 엄청 시간이 많이 들어갔다. ​ 현재 nano-banana을 직접 사용할 수 &#8230; <a class=\"more-link\" href=\"https://megayuchi.com/2025/08/21/7152/\">More <span class=\"screen-reader-text\">nano-banana  테스트 후기</span></a>",
        "contentSnippet": "​ 강의 만들어야 하지만 집중도 안되고 해서 몇 일 째 nano-banana 갖고 노는 중이다. 내 게임 캐릭터와 피규어의 이미지를 소스로 이런 저런 시도들을 해보고 있는데 나름 괜찮게 뽑히는 경우도 있음. 근데 한방에 간단하게 나오는 경우는 없고, 짧은 시간 안에 원하는 결과물이 나와도 워낙 저해상도라서 후작업에 엄청 시간이 많이 들어갔다. ​ 현재 nano-banana을 직접 사용할 수 … More nano-banana  테스트 후기",
        "guid": "http://megayuchi.com/?p=7152",
        "categories": [
          "IT",
          "Pub",
          "ai",
          "nano-banana"
        ],
        "isoDate": "2025-08-21T08:20:02.000Z"
      }
    ]
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": [
      {
        "title": "의미에 맞는 href 사용",
        "link": "https://hyeonseok.com/blog/942",
        "pubDate": "Sun, 24 Aug 2025 15:39:59 GMT",
        "content": "<p>링크에 <code>onclick</code> 핸들러를 달 때 <code>href</code>에 <code>#</code>을 많이 사용하는데 특이하게 <code>http://</code>를 사용한 경우를 봤다. 딱히 신경쓰지 않고 있었는데 이로 인한 버그가 리포팅됐다.</p>\r\n\r\n<p><img src=\"/static/blog/semantic-href.png\" class=\"major\" alt=\"페이지 표시 오류가 발생한 사파리 브라우저\" /> 사파리는 링크를 롱탭해서 프리뷰를 볼 수 있는데 <code>http://</code>로 <code>href</code> 값을 정하면 프리뷰에서 오류가 발생한다. 이 외에도 새탭을 연다든가 북마크로 저장을 한다든가 할 때도 오류가 발생할 것이다.</p>\r\n\r\n<p><code>href</code> 값이 필요 없는 경우에는 <code>&lt;button&gt;</code> 요소를 사용하도록 하자. HTML의 의미가 왜 중요한지 말해주는 또 하나의 사례라고 할 수 있겠다.</p>",
        "contentSnippet": "링크에 onclick 핸들러를 달 때 href에 #을 많이 사용하는데 특이하게 http://를 사용한 경우를 봤다. 딱히 신경쓰지 않고 있었는데 이로 인한 버그가 리포팅됐다.\n\r\n\r\n 사파리는 링크를 롱탭해서 프리뷰를 볼 수 있는데 http://로 href 값을 정하면 프리뷰에서 오류가 발생한다. 이 외에도 새탭을 연다든가 북마크로 저장을 한다든가 할 때도 오류가 발생할 것이다.\n\r\n\r\nhref 값이 필요 없는 경우에는 <button> 요소를 사용하도록 하자. HTML의 의미가 왜 중요한지 말해주는 또 하나의 사례라고 할 수 있겠다.",
        "guid": "https://hyeonseok.com/blog/942",
        "isoDate": "2025-08-24T15:39:59.000Z"
      },
      {
        "title": "클라우드 플레어 뒤에 있는 웹서버에서 사용자 IP를 로그로 남기기",
        "link": "https://hyeonseok.com/blog/941",
        "pubDate": "Sat, 23 Aug 2025 22:10:51 GMT",
        "content": "<p>클라우드 플레어 뒤에 있는 웹서버의 로그를 보니 클라우드 플에어 프록시 서버의 IP를 남기고 있다. 클라우드 플레어는 <code>CF-Connecting-IP</code>로 실제 IP를 넘겨주고 있어서 이것을 이용하게 설정할 필요가 있다.</p>\r\n\r\n<p>엔진엑스의 <code>real_ip</code> 모듈을 사용하면 특정 IP 범위의 요청에서 <code>$remote_addr</code>의 값을 변경할 수 있게 해 준다. 클라우드 플레어의 IP 범위는 <a href=\"https://www.cloudflare.com/ips-v4/\">https://www.cloudflare.com/ips-v4/</a> 주소에서 텍스트 형태로 제공하고 있다. 이 것을 엔진엑스에서 <code>set_real_ip_from</code>으로 추가하고 클라우드 플레어가 전달해주는 실제 IP로 덮어 써주면 된다.</p>\r\n\r\n<pre><code>http {\r\n    set_real_ip_from 173.245.48.0/20;\r\n    set_real_ip_from 103.21.244.0/22;\r\n    set_real_ip_from 103.22.200.0/22;\r\n    set_real_ip_from 103.31.4.0/22;\r\n    set_real_ip_from 141.101.64.0/18;\r\n    set_real_ip_from 108.162.192.0/18;\r\n    set_real_ip_from 190.93.240.0/20;\r\n    set_real_ip_from 188.114.96.0/20;\r\n    set_real_ip_from 197.234.240.0/22;\r\n    set_real_ip_from 198.41.128.0/17;\r\n    set_real_ip_from 162.158.0.0/15;\r\n    set_real_ip_from 104.16.0.0/13;\r\n    set_real_ip_from 104.24.0.0/14;\r\n    set_real_ip_from 172.64.0.0/13;\r\n    set_real_ip_from 131.0.72.0/22;\r\n\r\n    real_ip_header CF-Connecting-IP;\r\n    ...\r\n}</code></pre>\r\n\r\n<p>이렇게 하면 로그 템플릿의 <code>$remote_addr</code>이 클라우드 플레어가 전달해주는 IP로 치환되어 저장되게 된다.</p>",
        "contentSnippet": "클라우드 플레어 뒤에 있는 웹서버의 로그를 보니 클라우드 플에어 프록시 서버의 IP를 남기고 있다. 클라우드 플레어는 CF-Connecting-IP로 실제 IP를 넘겨주고 있어서 이것을 이용하게 설정할 필요가 있다.\n\r\n\r\n엔진엑스의 real_ip 모듈을 사용하면 특정 IP 범위의 요청에서 $remote_addr의 값을 변경할 수 있게 해 준다. 클라우드 플레어의 IP 범위는 https://www.cloudflare.com/ips-v4/ 주소에서 텍스트 형태로 제공하고 있다. 이 것을 엔진엑스에서 set_real_ip_from으로 추가하고 클라우드 플레어가 전달해주는 실제 IP로 덮어 써주면 된다.\n\r\n\r\nhttp {\r\n    set_real_ip_from 173.245.48.0/20;\r\n    set_real_ip_from 103.21.244.0/22;\r\n    set_real_ip_from 103.22.200.0/22;\r\n    set_real_ip_from 103.31.4.0/22;\r\n    set_real_ip_from 141.101.64.0/18;\r\n    set_real_ip_from 108.162.192.0/18;\r\n    set_real_ip_from 190.93.240.0/20;\r\n    set_real_ip_from 188.114.96.0/20;\r\n    set_real_ip_from 197.234.240.0/22;\r\n    set_real_ip_from 198.41.128.0/17;\r\n    set_real_ip_from 162.158.0.0/15;\r\n    set_real_ip_from 104.16.0.0/13;\r\n    set_real_ip_from 104.24.0.0/14;\r\n    set_real_ip_from 172.64.0.0/13;\r\n    set_real_ip_from 131.0.72.0/22;\r\n\r\n    real_ip_header CF-Connecting-IP;\r\n    ...\r\n}\n\r\n\r\n이렇게 하면 로그 템플릿의 $remote_addr이 클라우드 플레어가 전달해주는 IP로 치환되어 저장되게 된다.",
        "guid": "https://hyeonseok.com/blog/941",
        "isoDate": "2025-08-23T22:10:51.000Z"
      }
    ]
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": []
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "안티들의 말은 무시해라",
        "link": "https://www.thestartupbible.com/2025/08/dont-listen-to-your-haters.html",
        "pubDate": "Sun, 24 Aug 2025 21:26:00 +0000",
        "content:encodedSnippet": "얼마 전에 요새 큰 고민이 있는 우리 투자사 대표와 이야기를 했다. 사업은 그냥 나쁘지 않게 진행되고 있는데, 이 회사의 제품에 대한 악플과 형편없는 리뷰 때문에 밤잠을 설치고 있었다.\n아마도 이런 고민을 하거나, 한 번 정도는 해 본 대표들이 있을 것이다. 특히나 일반 고객과 실물 시장과의 접점이 훨씬 많은 B2C 서비스 또는 먹고, 입고, 바르는 제품을 만들어서 판매하는 브랜드/D2C 스타트업을 운영하는 분이라면 엄청난 악플과 제품 리뷰를 쏟아내는 안티들에게 시달려 본 경험이 있을 것이다.\n이런 분들에게 내가 해주고 싶은 조언은 다음과 같다.\n우리 회사와 제품에 대한 안 좋은 피드백이 단순 증오성 내용이 아니라, 실제 우리 제품을 자주 사용하는 고객의 애정이 어린 피드백이라면, 그리고 정말로 이분들이 우리 회사와 제품의 미래를 걱정한다면, 이런 충고, 리뷰, 피드백은 아주 적극적으로 듣고, 수용하고, 반영하는 노력을 해야 한다. 이런 분들이 우리 제품을 구매하고 사용하고, 결국엔 우리 회사가 계속 존재하게 만들어 주는 고마운 찐팬이기 때문이다. 그리고 이런 분들이 남기는 글이나 영상은 그냥 봐도 회사와 제품에 대한 애정이 보일 것이다.\n하지만, 처음부터 끝까지 특별한 논리와 내용도 없이 주구장창 우리 제품과 회사를 욕하는 증오성 피드백이라면 – 그리고 이런 건 그냥 보면 알 수 있다 – 그냥 무시하면 된다. 어차피 이런 사람들은 우리의 팬도 아니고 고객도 아니고 그냥 우리의 안티다. 아마도 우리 제품을 한 번 정도 써봤거나, 아니면 아예 써보지도 않고 그냥 악감정으로 특별한 이유 없이 이런 증오성 악플과 혹평을 하는 것일 텐데 이런 사람들은 우리 회사에 전혀 도움이 안 되는 인간들이다.\n우리 제품을 구매하는 건 우리의 팬이지, 우리의 안티들이 아니다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/08/dont-listen-to-your-haters.html#respond",
        "content": "얼마 전에 요새 큰 고민이 있는 우리 투자사 대표와 이야기를 했다. 사업은 그냥 나쁘지 않게 진행되고 있는데, 이 회사의 제품에 대한 악플과 형편없는 리뷰 때문에 밤잠을 설치고 있었다. 아마도 이런 고민을 하거나, 한 번 정도는 해 본 대표들이 있을 것이다. 특히나 일반 고객과 실물 시장과의 접점이 훨씬 많은 B2C 서비스 또는 먹고, 입고, 바르는 제품을(...)",
        "contentSnippet": "얼마 전에 요새 큰 고민이 있는 우리 투자사 대표와 이야기를 했다. 사업은 그냥 나쁘지 않게 진행되고 있는데, 이 회사의 제품에 대한 악플과 형편없는 리뷰 때문에 밤잠을 설치고 있었다. 아마도 이런 고민을 하거나, 한 번 정도는 해 본 대표들이 있을 것이다. 특히나 일반 고객과 실물 시장과의 접점이 훨씬 많은 B2C 서비스 또는 먹고, 입고, 바르는 제품을(...)",
        "guid": "https://www.thestartupbible.com/?p=9540",
        "categories": [
          "Uncategorized",
          "B2C",
          "brand",
          "FoundersAtWork"
        ],
        "isoDate": "2025-08-24T21:26:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "엄격한 사랑",
        "link": "https://www.thestartupbible.com/2025/08/tough-love.html",
        "pubDate": "Wed, 20 Aug 2025 21:23:00 +0000",
        "content:encodedSnippet": "American Idol을 시작으로 수많은 원조 오디션 프로그램의 프로듀서이자 전세계에서 가장 뛰어난 음악 사업가 중 한 명인 사이먼 코웰의 팟캐스트를 얼마 전에 참 재미있게 들었다. 요샌 그나마 나아진 것 같은데, 이분이 몇 년 전 오디션 프로그램에서 참가자 평가하는 것을 본 분이라면 듣는 사람이 민망하고 미안할 정도로 차갑고 독하다는 것을 모두 다 인정할 것이다. 나도 빙빙 돌려 말하지 않고 솔직하게 말하는 straight shooter 스타일이지만, 코웰씨의 악평을 듣다 보면 나는 참 천사 같은 사람이라는 생각이 들 정도다.\n그래서 나는 이분을 볼 때마다 미디어에서 본인의 이미지를 만들기 위해서 저렇게 싸가지 없게 행동하는 걸로 이해했다. 원래 사람이 저렇게 독하게 생각하고 말하는 거라면, 저 분한테 욕먹는 참가자도 힘들겠지만, 저분도 세상 사는 게 쉽지 않을 거라는 생각이 들었기 때문이다. 그런데 인터뷰를 들어보니 이분은 원래 이렇게 가혹하고 냉정하게 생각하고 행동하는데, 이게 상대방을 무시하거나 싫어해서가 아니라 오히려 상대방을 존중하고 사랑하기 때문이라고 한다. 상대방에 대한 자신의 ‘tough love’를 이런 방식으로 표현한다고 한다.\n이분이 같이 오디션 심사를 하다 보면 어떤 심사위원은 참가자가 정말로 재능이 없고 노래도 못 부르는데, 앞에서는 “노래 정말 잘하시네요. 조금만 다듬으면 좋은 가수가 될 수 있을 것 같습니다.”라고 칭찬하면서 뒤에서는 “최악의 가수네”라고 하는 걸 자주 봤다고 한다. 그리고 본인은 이런 사람들이 세상에서 제일 싫다고 한다. 일단 정직하지 않기 때문에 싫다고 하고, 심사위원이 이런 이야기를 하면 이걸 듣는 사람 입장에서는 정말로 본인이 조금만 더 연습하면 좋은 가수가 될 수 있다는 심한 착각을 해서, 절대로 가수가 될 수 없는 목소리를 가졌지만, 자칫 잘못하면 그 심사위원의 말 때문에 평생 돈과 시간 낭비를 해서 인생 자체를 완전히 망칠 수 있기 때문이다. 그래서 본인은 이런 참가자에겐 아예 면전에서 솔직하게 가수의 재능이 없어서 이 길 말고 다른 커리어를 찾아보라고 하는 게 장기적으로 봤을 땐 상대방에게 훨씬 더 도움이 되는 말이라고 한다. 즉, 이분은 무대에 있는 분을 혐오하는 게 아니라, 오히려 더 존경하기 때문에 이렇게 엄격한 사랑으로 자신의 감정을 솔직하게 표현하는 게 훨씬 더 인류의 발전에 이롭다고 생각하고 있는 것 같다.\n나도 코웰씨의 말과 태도에 전적으로 동의한다. 나는 가수 오디션을 심사하는 사람은 아니지만, 수많은 창업가들과 만나고 이들의 사업에 투자할지 고민한다. 물론, 누가 언제 유니콘을 만들진 아무도 모르지만, 아예 안 될 것 같은 사업 아이템이나 아예 사업을 할 자질이 없는 창업가는 미팅 후 15분 정도면 어느 정도 파악이 된다고 생각한다.\n그럼, 이분들에겐 나는 어떻게 할까?\n첫 번째 방법은 – 그리고 이게 서로에게 싫은 소리 안 하고 나도 편한 방법이다 – 그냥 아주 좋은 사업 같고, 내부적으로 이야기해 보고 다시 연락하겠다면서 잠수 타는 것이다. 어차피 다시 볼 사람은 아니고, 우리가 투자 안 할 건데, 굳이 이분이 듣기 싫은 소리를 해서 감정 상하게 하고 나도 싫은 소리 하기 싫은 게 모든 사람들의 디폴트 태도이다. 하지만, 이건 상대방에 대한 예의는 아니다. 왜냐하면 대부분의 창업가는 투자자들의 조언을 상당히 진지하고 진중하게 받아들인다. 완벽과는 거리가 멀고 개선해야 할 점 투성이인 비즈니스와 창업가의 태도가 너무나 명확하게 보이는데 “너무 좋으니까 계속 열심히 하면 우리가 투자 검토하겠다”라는 맘에도 없는 말을 하면, 정말로 이 말을 믿고 지금 하는 것을 하던 대로 할 확률이 크기 때문이다. 그러면서 이분은 시간과 돈을 낭비하고, 인생을 낭비할 수도 있기 때문이다.\n두 번째 방법은 코웰씨와 같이 대놓고 면전에서 이 사업은 문제가 있어서 안 될 것 같다고 하거나, 아니면 내가 봤을 때 당신은 창업할 준비가 안 된 것 같다고 아주 솔직하게 말해준다. 물론, 이 말은 무례하게 하거나, 갑의 자세로 하는 게 아니라, 공손하고 예의 바르게 해야 한다. 나는 항상 이 두 번째 방법의 선상에서 내 솔직한 생각과 피드백을 창업가들에게 전달하려고 노력한다. 그런데 나도 사람이고, 상대방도 사람인지라, 최대한 예의 바르게 내 생각을 전달하려고 하지만, 가끔씩자주 상대방의 기분을 상하게 하고 자존심에 기스를 내는 경우가 있다. 그리고 어떤 창업가들은 그 자리에서 대놓고 나에게 정말 무례하고 어떻게 이런 말을 본인에게 할 수 있냐고 감정적으로 격하게 따지기도 한다.\n이런 상황이 벌어지면, 나도 속으로 내가 굳이 왜 잘 알지도 못하고, 오늘 처음 만났고, 아마도 앞으로 안 만날지도 모르는 이분에게 이런 말을 해서 이런 상황을 만들었을까,,,라는 후회를 하기도 하고 그냥 앞으로는 무조건 좋은게 좋다는 태도로 “굉장히 좋습니다.” , “열심히 하시면 됩니다.” , “내부적으로 검토해 볼게요.”라는 말로 일단 그 상황을 모면한 후에 다시는 연락하지 말까 하는 생각도 한다.\n하지만, 절대로 이렇게 하지 않는다. 왜냐하면 되는 사업이든 아니든, 이상한 창업가이든 아니든, 내 앞에서 열심히 사업을 설명하는 이 사람은 나를 만나기 위해서 두 달을 기다린 사람도 있고, 우리가 대단한 VC는 아니지만, 창업가의 입장에서 투자자라는 존재 자체가 굉장히 어렵고 긴장하게 만드는 존재라서 이 미팅을 준비하는 과정에서 엄청난 고민과 연습을 했을 확률이 크기 때문이다. 그리고 어떤 창업가들은 나와 단 한 시간의 미팅을 위해서 지방에서 서울로 올라온 분들도 있는데, 내가 이분들을 위해서 보여줄 수 있는 최소한의 예의는 바로 서로의 시간을 낭비하지 않고 아주 냉정하고 솔직하게 내 의견과 조언을 제공하는 것이다.\n개인적인 감정은 전혀 없다. 내가 처음 만나는 사람인데 어떻게 개인적인 감정이 생길 수가 있을까. 하지만, 나는 이분에 대한 같은 사람으로서의 예의를 표시하는 가장 좋은 방법은 위에서 말한 tough love라고 굳게 믿고 있다.\n나도 남에게 돈을 받아서 투자하는데, 우리에게 투자하는 잠재 LP 중 “스트롱 너무 좋아요. 내부적으로 이야기하고 바로 검토 시작할게요.”라고 면전에서는 이야기하지만, 이후 몇 달 동안 연락조차 안 되는 사람들도 많다. 나는 이런 사람들이 정말 싫다. 오히려 내 앞에서 내 눈을 똑바로 보면서 “스트롱은 이런 점이 별로다” , “나는 한국 시장이 정말 아닌 것 같다.” , “배기홍 너는 정말 쓰레기 같은 파트너야(아, 이런 말을 들은 적은 한 번도 없다. 그냥 극단적인 예시다.)” 뭐 이런 말을 해주면서 스트롱에 투자하지 않겠다고 하는 분들이 오히려 더 고맙다. 이런 분들과는 오히려 장기적으로 투명하고 솔직한 관계를 맺어 갈 수 있기 때문이다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/08/tough-love.html#comments",
        "content": "American Idol을 시작으로 수많은 원조 오디션 프로그램의 프로듀서이자 전세계에서 가장 뛰어난 음악 사업가 중 한 명인 사이먼 코웰의 팟캐스트를 얼마 전에 참 재미있게 들었다. 요샌 그나마 나아진 것 같은데, 이분이 몇 년 전 오디션 프로그램에서 참가자 평가하는 것을 본 분이라면 듣는 사람이 민망하고 미안할 정도로 차갑고 독하다는 것을 모두 다 인정할 것이다. 나도 빙빙 돌려(...)",
        "contentSnippet": "American Idol을 시작으로 수많은 원조 오디션 프로그램의 프로듀서이자 전세계에서 가장 뛰어난 음악 사업가 중 한 명인 사이먼 코웰의 팟캐스트를 얼마 전에 참 재미있게 들었다. 요샌 그나마 나아진 것 같은데, 이분이 몇 년 전 오디션 프로그램에서 참가자 평가하는 것을 본 분이라면 듣는 사람이 민망하고 미안할 정도로 차갑고 독하다는 것을 모두 다 인정할 것이다. 나도 빙빙 돌려(...)",
        "guid": "https://www.thestartupbible.com/?p=9538",
        "categories": [
          "Uncategorized",
          "entertainment",
          "failure",
          "FoundersAtWork",
          "media",
          "Strong",
          "vc"
        ],
        "isoDate": "2025-08-20T21:23:00.000Z"
      }
    ]
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "토스인사이트, 첫 보고서 '스테이블코인: 새로운 금융 인프라의 부상' 발간  ",
        "link": "https://toss.im/tossfeed/article/39889",
        "pubDate": "Mon, 25 Aug 2025 22:55:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}스테이블코인 3부작 중 첫 번째… 금융·산업·정책 관점을 아우르는 분석\n산업 가치사슬·비즈니스 사례·글로벌 규제 동향을 체계적으로 정리\n정책 당국·금융기관·연구자에게 지속적 담론 및 전략 수립 기반 제공\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n토스(운영사 비바리퍼블리카, 대표 이승건)의 금융경영연구소 ‘토스인사이트(Toss Insight, 대표 손병두)’가 첫 보고서 ‘스테이블코인: 새로운 금융 인프라의 부상’을 발간했다고 26일 밝혔다. 총 3부작으로 기획된 스테이블코인 시리즈의 첫 권은 총론 성격으로, 금융·산업·정책 관점을 아우르는 분석을 담았다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n\n이번 보고서는 스테이블코인을 단순한 가상자산이 아닌, 금융정책과 민간 혁신이 교차하는 새로운 과제로 바라본다. 글로벌 차원에서 금융시스템의 안정성과 발전 방향이 논의되는 가운데, 무엇보다 사실관계를 정리하고 좌표계를 세우는 작업이 필요하다는 문제 의식에서 출발했다. 이를 위해 화폐이론·금융경제학·산업조직론의 관점을 교차 적용해 스테이블코인의 구조와 작동 원리를 종합적으로 다뤘다.\n보고서는 스테이블코인의 정의와 주요 특징을 정리하고, 이어 시장 현황과 확장 배경을 짚는다. 나아가 스테이블코인의 세 가지 가치사슬인 ▲인프라 산업 ▲발행·유통 산업 ▲응용 솔루션 산업을 분석한다. 이후 글로벌 발행사와 금융기업의 실제 사례와 규제 동향까지 폭넓게 조명한다.\n토스인사이트는 이번 보고서를 통해 스테이블코인이 지닌 기회와 과제를 균형 있게 짚어냈다. 특히 정책 당국과 금융기관, 연구 현장에서 참고할 수 있는 분석과 인사이트를 담아 디지털 화폐 시대에 필요한 정책적·산업적 대응 전략 마련에 기여할 것으로 기대하고 있다.\n홍기훈 토스인사이트 연구소장은 “스테이블코인은 기존 금융 체계와 디지털 경제를 연결하는 중요한 고리로 주목받고 있다”며 “이번 보고서가 스테이블코인에 대한 건설적 논의와 정책적 대응 방안을 설계하는 데 기초 자료로 활용되기를 바란다”고 밝혔다.\n한편, 토스인사이트는 핀테크 업권을 중심으로 금융 관련 정책을 분석하고 트렌드를 연구하는 기관이다. 금융산업 전반에 유의미한 메시지를 전달하고, 금융기관으로서 토스의 사회적 기여도를 높이기 위해 설립됐다. 이번 보고서를 시작으로, 스테이블코인의 ‘규제·감독 편’과 ‘비즈니스 전략 편’을 순차적으로 발간해 시리즈를 완성할 예정이다.\n\n.css-1qimhyf{white-space:pre-wrap;color:var(--adaptiveGrey500);}현재 보고서는 임시 채널인 토스피드를 통해 공개되며, 토스인사이트 공식 홈페이지가 오픈되면 이후 발간되는 보고서들은 해당 홈페이지에서 확인하실 수 있습니다. \n.css-1lvcgm8{padding:22px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;border-radius:20px;}\n.css-13ko30i{width:375px;}보고서 링크",
        "content": "토스의 금융경영연구소 토스인사이트 분석력이 담긴 첫 보고서 발간",
        "contentSnippet": "토스의 금융경영연구소 토스인사이트 분석력이 담긴 첫 보고서 발간",
        "guid": "https://toss.im/tossfeed/article/39889",
        "isoDate": "2025-08-25T22:55:00.000Z"
      },
      {
        "title": "토스페이먼츠, 항공예약발권시스템(GDS) 간편결제 국내 첫 도입",
        "link": "https://toss.im/tossfeed/article/GDS",
        "pubDate": "Mon, 25 Aug 2025 13:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}글로벌 3대 GDS 운영사 ‘세이버’ 및 ‘놀유니버스’와 기술 제휴\n이용자 편의성 제고, 여행사·항공사 매출 증대 기대\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n비바리퍼블리카(토스)의 전자지급결제대행(PG) 계열사 토스페이먼츠(대표 임한욱)가 세이버(Sabre) 및 놀유니버스와 기술 제휴를 맺고 항공예약발권시스템(GDS, Global Distribution System)에 간편결제를 도입했다고 25일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n세이버는 전 세계 항공사와 여행사를 연결하는 글로벌 3대 GDS 중 하나다. 160여 개 국가에서 매년 수십억 건의 예약과 발권을 처리하고 있다. 그동안 항공사 개별 홈페이지와 앱에서는 간편결제가 보편화됐지만, GDS 시스템에서는 여전히 신용카드 번호를 직접 입력하는 방식의 결제만 가능해 이용자 불편이 컸다.\n이번 제휴로 국내 최초로 세이버 예약 시스템에서도 간편결제가 가능해졌다. 고객의 카드 정보를 수집하지 않아 민감 정보의 노출 위험도 최소화했다. 이용자들은 몇 번의 터치만으로 안전하고 편리한 결제 환경을 누릴 수 있게 됐다. 이는 여행·항공 업계 전반의 디지털 결제 혁신을 앞당길 것으로 기대된다.\n첫 적용 사례는 놀유니버스가 운영하는 여행 플랫폼 ‘NOL 인터파크투어’다. 놀유니버스와 토스페이먼츠의 기술 협업으로 주요 간편결제 서비스 중 하나인 토스의 ‘토스페이’를 통한 항공권 결제가 적용됐다. 토스페이먼츠는 내년 상반기까지 네이버페이, 카카오페이 등 다른 간편결제 서비스도 세이버 시스템과 추가 연동할 예정이다.\n토스페이먼츠 관계자는 “간편결제 도입으로 이용자들은 항공권 구매 채널과 관계없이 빠르고 간편한 결제 경험을 누릴 수 있게 됐다”며 “놀유니버스를 시작으로 더 많은 여행사와 항공사가 고객 만족과 매출 성장을 이룰 수 있도록 결제 혁신을 지속 확산하겠다”고 말했다.",
        "content": " NOL 인터파크투어에 토스페이 항공권 결제 적용",
        "contentSnippet": "NOL 인터파크투어에 토스페이 항공권 결제 적용",
        "guid": "https://toss.im/tossfeed/article/GDS",
        "isoDate": "2025-08-25T13:00:00.000Z"
      },
      {
        "title": "소비쿠폰 8월 안에 다 쓰면 최대 5만 원 쿠폰 받을 수 있어요.",
        "link": "https://toss.im/tossfeed/article/money-policies-48",
        "pubDate": "Fri, 22 Aug 2025 01:09:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}1차 민생회복 소비쿠폰을 신용·체크카드로 받아서 .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}8월 31일까지 다 쓰면, 최대 5만 원 상당의 쿠폰을 받을 수 있는 이벤트에 자동 응모돼요. 이 이벤트는 카드사가 공동으로 진행하는 행사로, 총 31만 명의 당첨자를 선정할 예정이에요. \n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}당첨 금액\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n5만 원 (1만 명)\n1만 원 (10만 명)\n5천 원 (20만 명)\n\n이벤트 응모 방법\n아래 조건을 만족했다면, 따로 신청하지 않아도 자동으로 응모돼요.\n\n소비쿠폰을 카드사로 신청한 사람\n2025년 8월 31일까지 1차 소비쿠폰을 전액 사용한 사람\n\n당첨 결과는 9월 중, 각 카드사를 통해 안내받을 수 있어요. 당첨을 통해 지급받은 추가쿠폰은 기존 소비쿠폰과 동일하게 연 매출 30억 원 이하 소상공인 가맹점에서 쓸 수 있어요. 대형마트, 백화점, 온라인 쇼핑몰, 프랜차이즈 직영점 등에서는 사용할 수 없어요.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 권민지 이지영 Graphic 이제현",
        "content": "따로 신청하지 않아도 자동으로 응모돼요",
        "contentSnippet": "따로 신청하지 않아도 자동으로 응모돼요",
        "guid": "https://toss.im/tossfeed/article/money-policies-48",
        "isoDate": "2025-08-22T01:09:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]