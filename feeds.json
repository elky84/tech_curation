[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Accelerating on-device ML on Meta’s family of apps with ExecuTorch",
        "link": "https://engineering.fb.com/2025/07/28/android/executorch-on-device-ml-meta-family-of-apps/",
        "pubDate": "Mon, 28 Jul 2025 20:30:33 +0000",
        "content:encodedSnippet": "ExecuTorch is the PyTorch inference framework for edge devices developed by Meta with support from industry leaders like Arm, Apple, and Qualcomm. \nRunning machine learning (ML) models on-device is increasingly important for Meta’s family of apps (FoA). These on-device models improve latency, maintain user privacy by keeping data on users’ devices, and enable offline functionality.\nWe’re showcasing some of the on-device AI features, powered by ExecuTorch, that are serving billions of people on Instagram, WhatsApp, Messenger, and Facebook.\nThese rollouts have significantly improved the performance and efficiency of on-device ML models in Meta’s FoA and eased the research to production path.\nOver the past year, we’ve rolled out ExecuTorch, an open-source solution for on-device inference on mobile and edge devices, across our family of apps (FoA) and seen significant improvements in model performance, privacy enhancement, and latency over our previous on-device machine learning (ML) stack.\nExecuTorch was built in collaboration with industry leaders and uses PyTorch 2.x technologies to convert models into a stable and compact representation for efficient on-device deployment. Its compact runtime, modularity, and extensibility make it easy for developers to choose and customize components – ensuring portability across platforms, compatibility with PyTorch, and high performance.\nAdopting ExecuTorch has helped us enhance our user experiences in our products and services used by billions of people all over the world.\nThe following are just a few examples of the various ML models on our apps on Android and iOS devices that ExecuTorch supports.\nEnabling Cutouts on Instagram\nCutouts is one of Instagram’s latest features for creative expression and storytelling. It lets people transform photos and videos of their favorite moments into animated, personalized stickers that they can share via Reels or Stories. We migrated the Cutouts feature in Instagram to run with ExecuTorch by enabling SqueezeSAM, a lightweight version of the Meta Segment Anything Model (SAM). For both Android and iOS, ExecuTorch was significantly faster compared to the older stack, translating into increases in Cutouts’ daily active users (DAU). \nExecuTorch enables Instagram’s Cutouts feature to run faster and more efficiently for both on-device sticker generation (left) and creating overlays on a photo. (right)\nImproving video and call quality on WhatsApp\nWhatsApp needs to be usable and reliable regardless of your network connection bandwidth. To achieve this, we developed bandwidth estimation models, tailored for various platforms. These models help detect and utilize available network bandwidth, optimizing video streaming quality without compromising the smoothness of video calls.  \nThese models need to be highly accurate and run as efficiently as possible. By leveraging ExecuTorch, we have observed improvements for the bandwidth estimation models in performance, reliability, and efficiency metrics. Specifically, we reduced the model load time and average inference time substantially while reducing app not responsive (ANR) metrics. Along the way, we further strengthened  security guarantees compared to the older PyTorch mobile framework by adding fuzzing tests, which involve supplying invalid or random inputs to a program and monitoring for exceptions. With the positive signal from these releases, we are now migrating several other key WhatsApp models, such as ones for on-device noise-canceling and video enhancement, to ExecuTorch as well. \nHere, Messenger’s language identification model (Lid) restricts the prompt language to English for Meta AI’s Imagine feature.\nShipping on-device ML for end-to-end encryption on Messenger\nEnd-to-end encryption (E2EE) on Messenger ensures that no one except you and the people you’re talking to can see your messages, not even Meta. ExecuTorch has enabled E2EE on Messenger by moving server side models to run on-device, allowing data transfers to remain encrypted.\nTo enable E2EE, we migrated and deployed several models, including an on-device language identification (LID) model on Messenger. LID is a Messenger model that detects the language of given text and enables various downstream tasks, including translation, message summarization, and personalized content recommendations. With ExecuTorch, on-device LID is significantly faster and conserves server and network capacity. \nTo preserve Messenger’s E2EE environment, we have also leveraged ExecuTorch to move other Messenger models on-device, including one for optimizing video calling quality (similar to WhatsApp’s bandwidth estimation models) and another for image cutouts (similar to Cutouts on Instagram). These shifts resulted in improved infrastructure efficiency by freeing up capacity and enabling us to scale these features globally. \nBackground music recommendations for Facebook\nFacebook employs a core AI model called SceneX that performs a variety of tasks, including image recognition/categorization, captioning, creating AI-generated backgrounds for images, and image safety checks. Shifting SceneX to ExecuTorch now allows it to enhance people’s Facebook Stories by suggesting background music based on images.\nWith the ExecuTorch rollout, we saw performance improvements in SceneX across the board from low- to high-end devices compared to the older stack. Several other models, including which enhance image quality and perform background noise reduction during calls, are now in various stages of A/B testing. \nBuilding the future of on-device AI with the ExecuTorch Community\nWe hope the results we’ve seen leveraging ExecuTorch to help solve some of Meta’s on-device ML challenges at scale will be encouraging to the rest of the industry. We invite you to contribute to ExecuTorch and share feedback on our GitHub page. You can also join our growing community on the ExecuTorch Discord server.\nWe look forward to driving more innovation in on-device ML and shaping the future of on-device AI together with the community.\nThe post Accelerating on-device ML on Meta’s family of apps with ExecuTorch appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>ExecuTorch is the PyTorch inference framework for edge devices developed by Meta with support from industry leaders like Arm, Apple, and Qualcomm.  Running machine learning (ML) models on-device is increasingly important for Meta’s family of apps (FoA). These on-device models improve latency, maintain user privacy by keeping data on users’ devices, and enable offline functionality. [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/07/28/android/executorch-on-device-ml-meta-family-of-apps/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/07/28/android/executorch-on-device-ml-meta-family-of-apps/\">Accelerating on-device ML on Meta’s family of apps with ExecuTorch</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "ExecuTorch is the PyTorch inference framework for edge devices developed by Meta with support from industry leaders like Arm, Apple, and Qualcomm.  Running machine learning (ML) models on-device is increasingly important for Meta’s family of apps (FoA). These on-device models improve latency, maintain user privacy by keeping data on users’ devices, and enable offline functionality. [...]\nRead More...\nThe post Accelerating on-device ML on Meta’s family of apps with ExecuTorch appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=22759",
        "categories": [
          "Android",
          "iOS",
          "Open Source"
        ],
        "isoDate": "2025-07-28T20:30:33.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Hanna Yakush",
        "title": "The Laravel Idea Plugin is Now Free for PhpStorm Users",
        "link": "https://blog.jetbrains.com/phpstorm/2025/07/laravel-idea-is-now-free/",
        "pubDate": "Wed, 30 Jul 2025 16:53:03 +0000",
        "content:encodedSnippet": "Starting July 30, 2025, we’re making Laravel Idea free for PhpStorm users. If you already have the Laravel Idea plugin installed, you get full access to all plugin features at no extra cost.\nLaravel Idea is the smartest Laravel development environment based on PhpStorm. Developed by Adel Faizrakhmanov, the plugin has 1.5M+ downloads from JetBrains Marketplace and is highly appreciated by Laravel developers. It extends PhpStorm’s built-in Laravel support with a variety of developer productivity features, including:\nPowerful code generation.\nAdvanced routing, validation, request fields, gates and policies, configs, translations, views, and a lot of other completion features.\nExcellent understanding of the Eloquent ORM.\nFull Blade component support.\nSupport for Livewire, Inertia.js, Dusk, Laravel modules, and other third-party packages.\n    \n“When I started Laravel Idea, I couldn’t even dream that it would be included in PhpStorm! And now… It’s happening! I’m very happy that it has become more accessible for Laravel developers.\n\r\n\r\nMy team and I will continue working on Laravel Idea the same way as before. Besides that, we will work closely with the PhpStorm team on many features, like AI, native support for Laravel magic, etc.”\n\n            \nAdel Faizrakhmanov\n                                                                Creator of Laravel Idea\n                                    \nTo install the Laravel Idea plugin in PhpStorm, go to Settings | Plugins and search for the plugin in the Marketplace tab.\n\n\n\n\nAfter installation, you can configure the plugin settings via Settings | Languages & Frameworks | Laravel Idea.\nWhy PhpStorm IDE for Laravel development?\nPhpStorm is recommended by Laravel for working on Laravel projects. Besides the Laravel Idea plugin, PhpStorm provides Laravel developers with loads of developer productivity features out of the box, including:\nJunie, your AI coding agent by JetBrains for professional tasks. \nBuilt-in support for Laravel Pint, Pest, Larastan, and Artisan CLI commands.\nSyntax highlighting and code completion in Blade templates and .env files. \nIDE support for JavaScript/TypeScript frameworks, including Tailwind, Vue, and React, and databases. \nBest-in-class tools for code navigation and refactoring.\n\n\n\n\n\n\nThe Laravel Idea plugin will eventually be bundled with PhpStorm and available to the IDE users out of the box.\n“I’m really excited that full Laravel support is now more accessible than ever for our users. We’ve worked hard to make PhpStorm the best IDE for Laravel development, and making Laravel Idea available for free is a big step forward.”\n\n            \nArtemy Pestretsov\n                                                                Product Leader at PhpStorm\n                                    \nLearn more about Laravel support in PhpStorm on our website.\nFAQ\nI have an IntelliJ Ultimate subscription, do I also get the Laravel Idea plugin for free?\nYes, the Laravel Idea plugin is now also available to IntelliJ Ultimate users for free.\nIs there any compensation for already purchased Laravel Idea licenses?\nIndividual PhpStorm users who purchased a monthly or yearly personal Laravel Idea license on May 1, 2025, or later are eligible for compensation in the form of a 50% discount on the next renewal of their personal PhpStorm subscription. This compensatory discount will be applied in your JetBrains Account automatically at the billing date of the next subscription renewal.\nWhy aren’t all active Laravel Idea subscriptions eligible for compensation?\nMay 1, 2025, marks the date we internally decided to make the Laravel Idea plugin part of PhpStorm and started working on it. We believe it’s fair to provide compensation to the users who purchased licenses after that date, as we had not announced this decision publicly at that time. Users who purchased the yearly license before did so when we were still operating under the third-party plugin business terms. \nCan I get a refund for my Laravel Idea purchase?\nYes, you can apply for a refund. To do so, please contact our Sales team and send us the order reference number, invoice number, or other purchase-related information. For more information about refunds, see the Licensing and Purchasing FAQ page.\nMy licensing case is not addressed in this FAQ. What should I do?\nPlease contact our Support team at phpstorm-support@jetbrains.com and provide the details of your case.",
        "dc:creator": "Hanna Yakush",
        "content": "Starting July 30, 2025, we’re making Laravel Idea free for PhpStorm users. If you already have the Laravel Idea plugin installed, you get full access to all plugin features at no extra cost. Laravel Idea is the smartest Laravel development environment based on PhpStorm. Developed by Adel Faizrakhmanov, the plugin has 1.5M+ downloads from JetBrains [&#8230;]",
        "contentSnippet": "Starting July 30, 2025, we’re making Laravel Idea free for PhpStorm users. If you already have the Laravel Idea plugin installed, you get full access to all plugin features at no extra cost. Laravel Idea is the smartest Laravel development environment based on PhpStorm. Developed by Adel Faizrakhmanov, the plugin has 1.5M+ downloads from JetBrains […]",
        "guid": "https://blog.jetbrains.com/?post_type=phpstorm&p=585748",
        "categories": [
          "news",
          "laravel",
          "laravel-idea"
        ],
        "isoDate": "2025-07-30T16:53:03.000Z"
      },
      {
        "creator": "Katie Fraser",
        "title": "Helping Students Get Unstuck: AI-Based Hints for Online Learning",
        "link": "https://blog.jetbrains.com/research/2025/07/ai-hints-for-online-learning/",
        "pubDate": "Wed, 30 Jul 2025 10:10:55 +0000",
        "content:encodedSnippet": "In online learning environments, tasks can often stump students, which can be challenging to navigate since teachers can’t always be there to help. Our Education Research team develops innovative features for education tools and recently built a smart AI-based hints tool that provides personalized feedback for students who might need help solving tasks. This tool goes beyond the automated hints common in massive open online courses (MOOCs) and delivers tailored, effective guidance that helps students move forward. \nTry the plugin!\n                                    \nIn this post, we will:\nExplore the currently available options for automated assistance in MOOCs.\nPresent our AI-based hint system, showing how it works and what’s technically interesting about it.\nDiscuss how students evaluated the plugin and what’s up next in this research stream.\nLearning in online courses\nIn its early days, distance learning was intended for people who were unable to attend classroom lectures, usually full-time workers, military personnel, and those in remote regions. The model has been around for some centuries already: people could take so-called correspondence courses per post, documented as early as the 1720s in Boston, Massachusetts, USA. Sir Isaac Pitman offered correspondence courses with feedback in the mid 1800s from Gloucestershire, UK, and universities were not far behind: students could obtain a degree through the University of London starting in 1858, regardless of whether they lived in London or not. \nLet’s zoom ahead to 2000, when online institutions like the University of Phoenix in the USA and The Open University in the UK had already been offering online courses to obtain degrees for about 30 years. As technology became more advanced and the infrastructure evolved for better access to affordable and fast internet, online courses surged in popularity.  \nThe importance of feedback\nThe first MOOC is often credited to Stephen Downes and George Siemens, who in 2008 made it possible for more than 2000 students online to attend their course in addition to the 25 students at the University of Manitoba campus in Canada. Since then, and especially during the pandemic, MOOCs have become more popular, with many available platforms. For example, there are platforms from universities like MIT and Harvard (their non-profit consortium is now edX and includes many more partners) and private companies like Udacity and Coursera. JetBrains offers its own project-based courses through JetBrains Academy, where learners can build tech skills using the same tools developers rely on every day.\n\nCourse catalog\n                                    \nAlready the online, often asynchronous, nature of such largely-attended courses poses a problem for helping students in a personalized way. We know that feedback is essential to the learning process, and that there are different types of feedback (see, for example, The Power of Feedback and this review specifically on automated feedback types). Courses with high matriculation numbers, whether on campus or online, often include automated assessments. Sometimes these courses additionally include smaller tutoring sessions, where feedback may be more personalized. Those students receiving both automated and personalized feedback are more likely to improve their learning than those receiving only automated feedback, as confirmed in, e.g., this 2024 paper.\nRecently, researchers have started developing automated ways to provide students with more personalized feedback, such as predefining rules or templates, using systems based on previous student submissions, or incorporating large language models (see this recent overview for more details). Here we focus on the landscape of a particular type of assistance for students learning programming online, next-step hint generation, and explore the approaches currently available.\nProviding hints to students in online learning\nNext-step hint generation is a powerful approach that provides students with targeted, incremental guidance to help them progress through their courses. So when stuck, they are presented with what specific, small step will help them proceed. Once that step is completed, and if they need another hint, another step will be given. For example, a student could be stuck on a programming task and cannot figure out why. To help, the hint could suggest something like the following:\n“Add a for loop that iterates over the indices of the ‘secret’ string.”\nHints can be generated as text like in the example above, (pseudo-)code, or a combination of both. Research has shown that only one type of feedback is not enough, and that students learn better when there are several levels like text and code. Instead of only pointing out errors or giving full solutions, they offer adaptive suggestions, include text explanations, and nudge learners toward the next logical step. Hints break down complex tasks into manageable pieces and encourage independent problem-solving, making them an essential tool for personalized learning support.\nWith the recent onset of large language models (LLMs), a few researchers have been exploring the possibilities of combining the open APIs of LLMs, such as gpt-3.5 and gpt-4, with personalized feedback generation. This type of approach comes with the benefit that researchers do not need a large amount of data on student submissions. So far there exist only a handful of these types of systems. Examples of a few tools can be found in the table below, including information about the hint type, where the tool can be used, and features; see this 2022 state-of-the-art review for more details.\n\nThe first two tools, CodeHelp and CodeAid, use gpt-3.5, while CS50.ai uses gpt-4. All tools in the table above only use the LLM directly; that is, there is no additional output processing. Without this processing, potential inaccuracies (such as hallucinations or ignored prompt instructions) can arise, thereby compromising the hint quality. The tools also require students to craft their own prompts, adding an extra challenge for students, especially beginners who are already known to struggle with seeking help.\nTo address such challenges, our research team developed a tool with the following features:\nPart of the course’s integrated development environment (IDE)\nBoth text and code hints\nProcessing of the LLM-generated code\nAI-based hints for in-IDE Learning\nOur researchers from the Education Research lab recently developed an AI-based tool for the open-source JetBrains Academy plugin. This research is a part of the PhD work of the lab’s head, Anastasiia Birillo, completed under the supervision of Dr. Hieke Keuning in the Software Technology for Learning and Teaching Group at Utrecht University. \nThe JetBrains Academy plugin is an extension for JetBrains IDEs, created specifically to support in-IDE learning. The plugin adapts the IDE window by adding a course structure panel, course progress bar, task description panel with theory, explanations, and non-coding types of assignments, and a check button for running tests predefined by the course author. There are already over 50 courses compatible with this format, and any third-party educator can add their own compatible course. \nCheck it out!\n                                    \nThe plugin provides different assignment types, and these tasks can be isolated or combined within a larger project. The types of tasks can be categorized as:\nTheoretical: concepts explained in a text or a video form with related quiz questions or coding tasks\nPractical: a quiz or a programming assignment\nWith the combination of the hint tool with the plugin, students learn programming languages by coding and simultaneously receiving personalized feedback, all within the IDE. If you are interested in what students and developers think about in-IDE learning, check out this recent paper where our researchers conducted interviews to learn about just that. \nHow our hint system works\nBefore getting into the technical features that set our AI-based hint tool apart from tools like the ones mentioned above, let’s look at how the tool works. Here are a few basic technical features:\nThe system uses gpt-4o for all LLM interactions.\nThe system generates both text and code hints.\nIt was originally designed for Kotlin and this version has been validated (see below). \nA Python version was developed later and is already available in the JetBrains Academy plugin.\nIn the example image below, a student is creating a program to simulate the game Hangman, where a user can try to guess a word by inputting letters. The current task requires the student to implement a complex function, generateNewUserWord. In the example, the student has already defined newUserWord and separator, but they don’t know how to implement the part of the function concerning already guessed letters. \n\n\n\n\nTo get help with the task, the student can request a hint by clicking the blue check button at the bottom (below the text hint). Clicking this button runs test cases, checks whether the code compiles, and displays the following two elements:\nThe text hint, on the bottom right side, marked with a pink rectangle\nThe highlighted position in the code, marked with a green rectangle\nThe highlighting feature is an important part of the design because (i) the hint system should be complex enough to help students with tasks longer than one function, and (ii) when there is a long file and the student is stuck anyway, it might not be obvious where to apply the hint. \nWithin the textual hint window, there is also a show in code link. As suggested by its name, it provides the student access to the code hint, which appears as a window with highlighted differences between the student’s code and the solution code. This can be seen in the following screenshot, where the code hint is marked in pink.\n\n\n\n\nOn the lower right side of the above image, rows 31–32 are highlighted in green. In this case, these rows represent what is missing from the student’s code, namely, the for loop which should iterate over the indices of the secret string, as stated in the text hint. \nFrom this code hint, the student can choose to accept the hint (found on the top of the above image), in which case the suggested changes are automatically applied, or cancel the hint and return to their own solution to manually modify it. This means the code hint provides bottom-out help, or the exact code needed to progress to the next step. As you can see in the example above, the code hint does not provide the content of the for loop, so the student has a chance to continue on their own.\nStudents may request a next-step hint at any time during the task, except when the task is already solved. The hints can help the students proceed with the task, or fix a test or compilation errors. There is currently no limitation on the number of hint requests in the plugin’s current version; JetBrains Academy is a MOOC platform where students voluntarily participate in courses, so it is ultimately up to them how they want to learn.\nNot only does the in-IDE course format provide students with a professional environment to build their coding skills, it is also a good environment for implementing a novel next-step hint system. For one, the programming assignments can be complex, and the IDE conveniently provides several crucial features, such as an API for static analysis and code quality analysis, the topic of the next subsection.\nCode hint quality improvement in the IDE\nOne might think that because the text hint is shown first to the students, the hint system must also internally generate the text hint before the code one. According to this 2024 paper, as well as our own internal validation reported in §5 of our paper, a hint system delivers much better results when it generates the code hint before the text hint.\nWith code as the main entity, we can apply cool IDE features to improve the code instead of just showing an unprocessed hint to the student. For the code processing, we used static analysis and code quality analysis. The figure below depicts the internal system pipeline.\n\n\n\n\nA key feature of our approach is that we process the LLM-generated code using static analysis and code quality analysis, so that the code is examined without executing the program. Automated tools like those found in our JetBrains IDEs can scan a project’s code to check for vulnerabilities such as:\nProgramming errors\nCoding standard violations\nUndefined values\nSyntax violations\nOur AI-based hint system uses an LLM to generate code based on the student’s code and any error information. However, LLMs are inherently unreliable, having the well-known potential to produce hallucinations (see this 2024 paper and this other 2024 paper for recent research), and we wanted the hints provided to students to be the most accurate possible. The combination of in-IDE code processing and generating the code hint before the text hint enabled us to create a tool with high hint accuracy. \nThe code processing included ensuring code quality and controlling hint size, among other improvements (more details are available in the paper). The following list describes each in more detail: \nTo improve the quality of the generated code, we used the IDE’s code quality inspections for optimizing code and for correcting common security and style issues. We selected 30 Kotlin inspections for which automatic fixes are available. The following code blocks show an example:\nmonth >= && month <= 12\nThe comparison code from above gets transformed into a Kotlin range as below.\n1..12\nLLMs do not always comprehend that only one step needs to be generated, even within one function. We believe that a good hint provides one logical action, not multiple ones at a time. To control the hint size, we developed some heuristics (more details can be found in the paper’s supplementary material). The figure below shows an example with additive statement isolation.\n\n\n\n\nBy processing the LLM-generated code before the student sees the hint, we can greatly improve the hint’s quality. This quality control gives our hint system an advantage over previously developed tools.\nHint system evaluation by students\nIn addition to the quality control described in the previous subsection, we validated the quality of the systems with experts and got feedback from students who used the tool in a course. In this subsection, we will only talk about the student validation; the details of the expert validation can be found in §5 of our paper. \nAs described above, hints have been developed for many MOOCs but less so for in-IDE courses, meaning that the MOOC-hint format is well-studied, while the in-IDE-hint format is not. Considering this, plus the fact that the IDE setting is inherently complex, we were interested in finding out how best to show text hints.\nTo find out, we conducted a user experience study, containing 15-minute comparative usability interviews with nine students of varying degrees of experience in programming.  \nFrom the interviews, we learned that students prefer having:\nThe hint in the same context as the task, in contrast to the hint in the code window\nThe relevant position highlighted in the code\nOn top of how to best show text hints, we were interested in what they thought about the usefulness and ease of use of the provided hints, both by looking at usage data and by asking the students directly. The data comes from fourteen students who completed five to six projects in the in-IDE Kotlin Onboarding: Introduction course, available in the JetBrains Academy catalog. More specifically, we used the KOALA tool to collect in-IDE activity data from the students who agreed to participate, followed by a qualitative assessment with open-ended questions.\nOverall, we collected 64,512 code snippets; if you are interested in the dataset for research purposes, you can contact our team.  The data indicated that:\nStudents requested text hints 191 times. \nOf those 191 times, students requested to see a code hint about half the time (101). \nRequest distribution across the course’s projects varied: the first basic projects contained less hint-requesting data than the later projects. \nIn the qualitative survey, 14 students were asked why they requested a hint, and could give multiple answers. The figure below shows the four most popular reasons for choosing a hint.\n\n\n\n\nAs seen in the figure above, the students reported using the hint system for its purpose, as well as for their own curiosity. There is additionally room for improvement with respect to compilation errors. \nWe also asked them further questions. Insights from their responses are summarized in the following:\nWhen asked what they did when the hint was unclear, 11 of the 14 students said they then tried to solve the task on their own, without searching online or asking an LLM. \nHalf of the students said they preferred to see a combination of both text and code hints, which aligns with what we saw in the TaskTracker data, where about half of the students requested both text and code hints.\nA key insight from the interviews was that the hint system is most helpful for beginner students. The hint tool is more helpful than searching online, because students at that level do not know what to search for or what prompt to use to ask an LLM. The flipside of this is that more advanced students prefer a chat-based interface, as in CS50.ai (see above), suggesting that a future version of our system would benefit from combining hints with a chat feature.  In general, the students gave positive feedback on our hints system, with many indicating that they would be interested in continuing to use it for future courses. \nWatch this space for a follow-up study, where we analyzed how another set of students used the hint tool. This work looks specifically at where any pain points might arise, and what can be done to improve students’ learning experience. \nIn the meantime, if you are interested in collaborating with our Education Research team, you can find more information on their website.",
        "dc:creator": "Katie Fraser",
        "content": "In online learning environments, tasks can often stump students, which can be challenging to navigate since teachers can’t always be there to help. Our Education Research team develops innovative features for education tools and recently built a smart AI-based hints tool that provides personalized feedback for students who might need help solving tasks. This tool [&#8230;]",
        "contentSnippet": "In online learning environments, tasks can often stump students, which can be challenging to navigate since teachers can’t always be there to help. Our Education Research team develops innovative features for education tools and recently built a smart AI-based hints tool that provides personalized feedback for students who might need help solving tasks. This tool […]",
        "guid": "https://blog.jetbrains.com/?post_type=research&p=586440",
        "categories": [
          "jetbrains-academy",
          "research",
          "ai",
          "ai-based-hints",
          "education-research",
          "jetbrains-research"
        ],
        "isoDate": "2025-07-30T10:10:55.000Z"
      },
      {
        "creator": "Richie Mitish",
        "title": "DataGrip 2025.2: Database Object Context in the AI Chat, Introspection by Levels for PostgreSQL and MS SQL Server, and More!",
        "link": "https://blog.jetbrains.com/datagrip/2025/07/29/datagrip-2025-2-database-object-context-in-the-ai-chat-introspection-by-levels-for-postgresql-and-ms-sql-server-and-more/",
        "pubDate": "Tue, 29 Jul 2025 15:36:53 +0000",
        "content:encodedSnippet": "DataGrip 2025.2 introduces a set of new features to elevate your development experience. In this version, introspection by levels is now supported for PostgreSQL and Microsoft SQL Server, giving you greater control over the metadata loaded for these databases. For PostgreSQL, a smart refresh mechanism has been implemented to significantly reduce the time spent refreshing schema. Database objects can now be attached to the AI chat for a specific context, and AI Assistant provides cloud-based code completion for your scripts. Our data editor and code editor have also received several improvements, including editable multi-table JOIN results and a floating toolbar displaying a set of context-based and AI-driven actions. Let’s take a look at what it has to offer.\n\n\n\n\n\n\n\nDownload DataGrip 2025.2 \nAI Assistant features\nPreviously, it was only possible to attach entire database schemas to the AI chat. Now, you can attach specific database objects by mentioning them with @dbObject: or #dbObject: in the input field.\n\n\n\n\nWith cloud-based code completion, DataGrip can autocomplete single lines, blocks of code, and even entire scripts in real time based on the available context. The generated SQL is similar to how you would write your statements, matching your style and naming conventions.\n\n\n\n\nConnectivity\nWe’ve made the introspection by levels feature available for PostgreSQL and Microsoft SQL Server databases. For PostgreSQL, the smart refresh feature has now been implemented, as well:\nIntrospection by levels allows DataGrip to automatically adjust the amount of loaded metadata based on the database size. \nWith smart refresh, only the objects that could potentially be modified when a given query is executed are refreshed.\n\n\n\n\nFor SQLite, you can now access and work with database files in WSL, as we have addressed the issue in WSL that was causing database files to be locked once you access them.\n\n\n\n\nWhen setting up a connection to MongoDB, you can now specify the way read operations are routed to the members of a MongoDB replica set, and even define which replica set should be used.\n\n\n\n\nWorking with data\nIn our data editor, the result set grid for SELECT queries with JOIN clauses is now editable. You can use this feature to change the cell values right in the query result grid, preview the generated DML, and submit your changes to the database.\n\n\n\n\nWe have also implemented a grid heatmap. Use one of the two available color schemes to highlight cells based on their values.\n\n\n\n\nYou can clear local filters for all columns in your grid by using just one action from the Find Action popup.\n\n\n\n\nCode editor\nIn our code editor, you can invoke a set of context-based and AI-driven actions simply by selecting a piece of code and using the floating toolbar that appears.\n\n\n\n\nUse the Cancel Running Statement button in the gutter to cancel a running statement in the editor. To see the button, hover over the progress icon.\n\n\n\n\nWe have addressed the inconvenience of data sources being detached from SQL files when the IDE is restarted. Data sources now stay attached to files. In addition, the Files tool window displays the attached data source names next to the SQL file names in the file tree.\n\n\n\n\nThe code reformatting popup message now includes a handy link to the SQL code style settings page in the IDE’s Settings dialog.\n\n\n\n\nIf you’re interested in upgrading to DataGrip 2025.2, or if you have any questions or suggestions, here are a few links you might find useful:\nDownload DataGrip 2025.2.\nVisit our What’s New page for the full list of improvements.\nContact us on X.\nReport any bugs to our issue tracker.\n\n\n\n\nThe DataGrip team",
        "dc:creator": "Richie Mitish",
        "content": "DataGrip 2025.2 introduces a set of new features to elevate your development experience. In this version, introspection by levels is now supported for PostgreSQL and Microsoft SQL Server, giving you greater control over the metadata loaded for these databases. For PostgreSQL, a smart refresh mechanism has been implemented to significantly reduce the time spent refreshing [&#8230;]",
        "contentSnippet": "DataGrip 2025.2 introduces a set of new features to elevate your development experience. In this version, introspection by levels is now supported for PostgreSQL and Microsoft SQL Server, giving you greater control over the metadata loaded for these databases. For PostgreSQL, a smart refresh mechanism has been implemented to significantly reduce the time spent refreshing […]",
        "guid": "https://blog.jetbrains.com/?post_type=datagrip&p=582960",
        "categories": [
          "news",
          "releases",
          "newsletter"
        ],
        "isoDate": "2025-07-29T15:36:53.000Z"
      },
      {
        "creator": "Daniela Bentrup",
        "title": "Koog: Building and Scaling AI Agents – Join Our Livestream Series",
        "link": "https://blog.jetbrains.com/ai/2025/07/koog-building-and-scaling-ai-agents-join-our-livestream-series/",
        "pubDate": "Tue, 29 Jul 2025 13:15:35 +0000",
        "content:encodedSnippet": "Are you ready to dive into the world of AI agents and create your own from scratch? We’ve got just the thing for you! Join us this August for a two-part livestream series about Koog, JetBrains’ open-source agentic framework that empowers developers to build AI agents entirely in Kotlin.\nWhether you’re a Kotlin developer or simply curious about building intelligent systems, this series will guide you from the basics to advanced use cases.\nEvent details\nLivestream series: Koog: Building and scaling AI agents in Kotlin\n🗓️ August 12 and 18, 2025\n🕒 3:00 pm UTC\nRegister now\n\n\n\n\nSession 1: Kickstarting AI agent development in Kotlin with Koog\nAugust 12th, 2025 – 3:00 pm UTC\nIn this first session, we’ll introduce you to the fundamentals of Koog, an open-source agentic framework to seamlessly build and run robust, scalable, and production-ready AI agents across all platforms – from backend services to Android, JVM, and in-browser environments.\nHere’s what you’ll learn:\nWhat is Koog, including its philosophy, vision, and growing ecosystem.\nWhy choose Kotlin for AI agent development.\nWhat Koog’s core architecture and agent model looks like under the hood.\nHow to build and run your first “Hello Agent” with minimal setup.\nWhether you’re a Kotlin developer or an AI enthusiast, you’ll find this session insightful.\nSession 2: Building smarter AI agents with Koog\nAugust 18th, 2025 – 3:00 pm UTC\nIn the second livestream, we’ll go beyond the basics and explore how Koog enables intelligent, traceable, and tool-augmented behavior.\nWhat you’ll learn:\nHow Koog agents work with context and how you can control their behavior.\nHow to use the built-in tracing features for debugging and observability.\nWays to integrate external tools and APIs to extend agent capabilities.\nHow to build a trip planning agent.\nJoin us to discover why Koog is perfect for developers ready to move from simple agents to dynamic, stateful, and explainable systems – all in pure Kotlin.\nWhy attend?\nGain hands-on insight into JetBrains’ cutting-edge Kotlin-based framework, learn directly from the creators of Koog, and ask questions and share feedback in real time. Don’t miss this opportunity to develop your skills and build powerful AI agents with ease.\nWe look forward to seeing you there!\nRegister now",
        "dc:creator": "Daniela Bentrup",
        "content": "Are you ready to dive into the world of AI agents and create your own from scratch? We’ve got just the thing for you! Join us this August for a two-part livestream series about Koog, JetBrains’ open-source agentic framework that empowers developers to build AI agents entirely in Kotlin. Whether you&#8217;re a Kotlin developer or [&#8230;]",
        "contentSnippet": "Are you ready to dive into the world of AI agents and create your own from scratch? We’ve got just the thing for you! Join us this August for a two-part livestream series about Koog, JetBrains’ open-source agentic framework that empowers developers to build AI agents entirely in Kotlin. Whether you’re a Kotlin developer or […]",
        "guid": "https://blog.jetbrains.com/?post_type=ai&p=584947",
        "categories": [
          "livestreams",
          "ai",
          "ai-agents",
          "webinars"
        ],
        "isoDate": "2025-07-29T13:15:35.000Z"
      },
      {
        "creator": "Ksenia Shneyveys",
        "title": "JetBrains x ICPC: The 2024–2025 Season at a Glance",
        "link": "https://blog.jetbrains.com/blog/2025/07/29/jetbrains-icpc-2024-2025-season/",
        "pubDate": "Tue, 29 Jul 2025 12:35:41 +0000",
        "content:encodedSnippet": "JetBrains has long supported the International Collegiate Programming Contest (ICPC), one of the world’s most respected competitive programming contests. Since 2017, we’ve been the ICPC Global Programming Tools Sponsor, providing professional IDEs such as IntelliJ IDEA, PyCharm, and CLion, along with Kotlin, one of the official ICPC programming languages.\nWe’ve been expanding our reach: Last year, JetBrains’ involvement with the ICPC engaged more than 50,000 students and coaches from over 3,000 universities in 111 countries. We visited new regions, launched new activities, and strengthened our engagement with local communities, students, and educators. As part of our participation in 400+ on-site competitions ranging from regional qualifiers to the world finals, we provided JetBrains tools, hosted booths, gave lectures, ran challenges, recruited interns, presented our new AI products, and supported this brilliant community.\nHere’s a look at where we’ve been and what we’ve done to support ICPC participants globally.\nWorld Finals\nLast year featured an unprecedented three ICPC World Finals. We wrote about the two simultaneous ICPC World Finals in Luxor and the ICPC World Finals in Astana.\nEurope\nWe started the 2025 season by visiting key regional contests. These regional contests are particularly close to our hearts, as they represent the first step for many students on their journey to the World Finals. \n\n\n\n\nWe attended the Southwestern Europe Regional Contest (SWERC), the Northwestern Europe Regional Contest (NWERC), the Central Europe Regional Contest (CERC), the Southeastern Europe Regional Contest (SEERC), and the European Championship.\n\n\n\n\nA standout moment occurred at the European Championship: the Sigma++ team from our partner institution Neapolis University Pafos earned a bronze medal and advanced to the next World Finals! Congratulations!\nAt our booth, the blind coding challenge was a hit – inspired by the tech session we hosted in Egypt. Watch the original video to see it in action with famous ICPC contestants like ‘tourist’, ‘ecnerwala’, ‘pashka’, and ‘Egor’.\n\n\n\n\n\n\nAsia\nWe had a strong presence in Asia, attending major events in person.\nAt the Asia East Continent Final (China), our colleagues gave a talk and connected with educators from the continent’s top 30 universities.\nAt the Asia Amritapuri Regional Contest (India), we joined the largest ICPC event in India, which was attended by 217 teams.\nOur tools were used across Japan, Southeast Asia, and Central Asia – even when we couldn’t attend in person.\nThe Americas\nIn this region, the Southern California Regional contest stood out – we were the only on-site sponsor, giving talks, hosting booths, and sharing resources with over 100 teams and 30+ coaches.\nWe also participated in the North America Championship (NAC), which is attended by leading schools like MIT, Stanford, Harvard, and a number of other top universities. JetBrains gave talks and had a booth at the showcase.\n\n\n\n\nICPC competitors are among the top minds in programming: Many now work at leading AI labs or start their own companies. By giving them the right tools early on, JetBrains helps them learn faster and work smarter. \nEven when we can’t attend in person, JetBrains is still prominently visible. JetBrains IDEs are installed on contest machines, and Kotlin is one of the languages open to participants. We are represented by branding on printed materials – venue branding, press walls, banners, brochures, the famous ICPC balloons, and the uniforms of everyone involved.\nWe are proud to support one of the most talented programming communities in the world.\nSee you at the next contest!",
        "dc:creator": "Ksenia Shneyveys",
        "content": "JetBrains has long supported the International Collegiate Programming Contest (ICPC), one of the world&#8217;s most respected competitive programming contests. Since 2017, we’ve been the ICPC Global Programming Tools Sponsor, providing professional IDEs such as IntelliJ IDEA, PyCharm, and CLion, along with Kotlin, one of the official ICPC programming languages. We’ve been expanding our reach: Last [&#8230;]",
        "contentSnippet": "JetBrains has long supported the International Collegiate Programming Contest (ICPC), one of the world’s most respected competitive programming contests. Since 2017, we’ve been the ICPC Global Programming Tools Sponsor, providing professional IDEs such as IntelliJ IDEA, PyCharm, and CLion, along with Kotlin, one of the official ICPC programming languages. We’ve been expanding our reach: Last […]",
        "guid": "https://blog.jetbrains.com/?post_type=blog&p=586374",
        "categories": [
          "news",
          "competitive-programming",
          "events",
          "icpc"
        ],
        "isoDate": "2025-07-29T12:35:41.000Z"
      },
      {
        "creator": "Cheuk Ting Ho",
        "title": "Faster Python: Unlocking the Python Global Interpreter Lock",
        "link": "https://blog.jetbrains.com/pycharm/2025/07/faster-python-unlocking-the-python-global-interpreter-lock/",
        "pubDate": "Tue, 29 Jul 2025 10:41:17 +0000",
        "content:encodedSnippet": "What is Python’s Global Interpreter Lock (GIL)?\n“Global Interpreter Lock” (or “GIL”) is a familiar term in the Python community. It is a well-known Python feature. But what exactly is a GIL?\nIf you have experience with other programming languages (Rust, for example), you may already know what a mutex is. It’s an abbreviation for “mutual exclusion”. A mutex ensures that data can only be accessed by one thread at a time. This prevents data from being modified by multiple threads at once. You might think of it as a type of “lock” – it blocks all threads from accessing data, except for the one thread that holds the key.\nThe GIL is technically a mutex. It lets only one thread have access to the Python interpreter at a time. I sometimes imagine it as a steering wheel for Python. You never want to have more than one person in control of the wheel! Then again, a group of people on a road trip will often switch drivers. This is kind of like handing off interpreter access to a different thread.\nBecause of its GIL, Python does not allow true multithreaded processes. This feature has sparked debates in the past decade, and there have been many attempts to make Python faster by removing the GIL and allowing multithreaded processes. Recently in Python 3.13, an option to have a way to use Python without the GIL, sometimes known as no-GIL or free-threaded Python, has been put in place. Thus begins a new era of Python programming.\nWhy was the GIL there in the first place?\nIf the GIL is so unpopular, why was it implemented in the first place? There are actually benefits to having a GIL. In other programming languages with true multithreading, sometimes issues are caused by more than one thread modifying data, with the final outcome depending on which thread or process finishes first. This is called a “race condition”. Languages like Rust are often hard to learn because programmers have to use mutexes to prevent race conditions.\nIn Python, all objects have a reference counter to keep track of how many other objects require information from them. If the reference counter reaches zero, since we know there is no race condition in Python due to the GIL, we can confidently declare that the object is no longer needed and can be garbage-collected.\nWhen Python was first released in 1991, most personal computers only had one core, and not many programmers were requesting support for multithreading. Having a GIL solves many problems in program implementation and can also make code easy to maintain. Therefore, a GIL was added by Guido van Rossum (the creator of Python) in 1992.\nFast-forward to 2025: Personal computers have multicore processers and thus way more computing power. We can take advantage of this extra power to achieve true concurrency without getting rid of the GIL.\nLater in this post, we’ll break down the process of removing it. But for now, let’s look at how true concurrency works with the GIL in place.\nMultiprocessing in Python\nBefore we take a deep dive into the process of removing the GIL, let’s have a look at how Python developers can achieve true concurrency using the multiprocessing library. The multiprocessing standard library offers both local and remote concurrency, effectively side-stepping the Global Interpreter Lock by using subprocesses instead of threads. In this way, the multiprocessing module allows the programmer to fully leverage multiple processors on a given machine.\nHowever, to perform multiprocessing, we’ll have to design our program a bit differently. Let’s have a look at the following example of how to use the multiprocessing library in Python.\nRemember our async burger restaurant from part 1 of the blog series:\nimport asyncio\n\nimport time\n\nasync def make_burger(order_num):\n\n    print(f\"Preparing burger #{order_num}...\")\n\n    await asyncio.sleep(5) # time for making the burger\n\n    print(f\"Burger made #{order_num}\")\n\nasync def main():\n\n    order_queue = []\n\n    for i in range(3):\n\n        order_queue.append(make_burger(i))\n\n    await asyncio.gather(*(order_queue))\n\nif __name__ == \"__main__\":\n\n    s = time.perf_counter()\n\n    asyncio.run(main())\n\n    elapsed = time.perf_counter() - s\n\n    print(f\"Orders completed in {elapsed:0.2f} seconds.\")\n\n\n\n\nWe can use the multiprocessing library to do the same, for example:\nimport multiprocessing\n\n\nimport time\n\n\ndef make_burger(order_num):\n\n\n   print(f\"Preparing burger #{order_num}...\")\n\n\n   time.sleep(5) # time for making the burger\n\n\n   print(f\"Burger made #{order_num}\")\n\n\n\n\nif __name__ == \"__main__\":\n\n\n   print(\"Number of available CPU:\", multiprocessing.cpu_count())\n\n\n\n\n   s = time.perf_counter()\n\n\n   all_processes = []\n\n\n   for i in range(3):\n       process = multiprocessing.Process(target=make_burger, args=(i,))\n       process.start()\n       all_processes.append(process)\n\n\n   for process in all_processes:\n       process.join()\n\n\n   elapsed = time.perf_counter() - s\n\n\n   print(f\"Orders completed in {elapsed:0.2f} seconds.\")\n\n\n\n\nAs you may recall, a lot of the methods in multiprocessing are very similar to threading. To see the difference in multiprocessing, let’s explore a more complex use case:\nimport multiprocessing\nimport time\nimport queue\n\n\n\n\ndef make_burger(order_num, item_made):\n   name = multiprocessing.current_process().name\n   print(f\"{name} is preparing burger #{order_num}...\")\n   time.sleep(5)  # time for making burger\n   item_made.put(f\"Burger #{order_num}\")\n   print(f\"Burger #{order_num} made by {name}\")\n\n\n\n\ndef make_fries(order_num, item_made):\n   name = multiprocessing.current_process().name\n   print(f\"{name} is preparing fries #{order_num}...\")\n   time.sleep(2)  # time for making fries\n   item_made.put(f\"Fries #{order_num}\")\n   print(f\"Fries #{order_num} made by {name}\")\n\n\n\n\ndef working(task_queue, item_made, order_num, lock):\n   break_count = 0\n   name = multiprocessing.current_process().name\n   while True:\n       try:\n           task = task_queue.get_nowait()\n       except queue.Empty:\n           print(f\"{name} has nothing to do...\")\n           if break_count > 1:\n               break  # stop if idle for too long\n           else:\n               break_count += 1\n           time.sleep(1)\n       else:\n           lock.acquire()\n           try:\n               current_num = order_num.value\n               order_num.value = current_num + 1\n           finally:\n               lock.release()\n           task(current_num, item_made)\n           break_count = 0\n\n\n\n\nif __name__ == \"__main__\":\n\n\n   print(\"Welcome to Pyburger! Please place your order.\")\n\n\n   burger_num = input(\"Number of burgers:\")\n   fries_num = input(\"Number of fries:\")\n\n\n   s = time.perf_counter()\n\n\n   task_queue = multiprocessing.Queue()\n   item_made = multiprocessing.Queue()\n   order_num = multiprocessing.Value(\"i\", 0)\n   lock = multiprocessing.Lock()\n\n\n   for i in range(int(burger_num)):\n       task_queue.put(make_burger)\n   for i in range(int(fries_num)):\n       task_queue.put(make_fries)\n\n\n   staff1 = multiprocessing.Process(\n       target=working,\n       name=\"John\",\n       args=(\n           task_queue,\n           item_made,\n           order_num,\n           lock,\n       ),\n   )\n   staff2 = multiprocessing.Process(\n       target=working,\n       name=\"Jane\",\n       args=(\n           task_queue,\n           item_made,\n           order_num,\n           lock,\n       ),\n   )\n\n\n   staff1.start()\n   staff2.start()\n\n\n   staff1.join()\n   staff2.join()\n\n\n   print(\"All tasks finished. Closing now.\")\n   print(\"Items created are:\")\n\n\n   while not item_made.empty():\n       print(item_made.get())\n\n\n   elapsed = time.perf_counter() - s\n\n\n   print(f\"Orders completed in {elapsed:0.2f} seconds.\")\n\n\n\n\nHere’s the output we get:\nWelcome to Pyburger! Please place your order.\nNumber of burgers:3\nNumber of fries:2\nJane has nothing to do...\nJohn is preparing burger #0...\nJane is preparing burger #1...\nBurger #0 made by John\nJohn is preparing burger #2...\nBurger #1 made by Jane\nJane is preparing fries #3...\nFries #3 made by Jane\nJane is preparing fries #4...\nBurger #2 made by John\nJohn has nothing to do...\nFries #4 made by Jane\nJane has nothing to do...\nJohn has nothing to do...\nJane has nothing to do...\nJohn has nothing to do...\nJane has nothing to do...\nAll tasks finished. Closing now.\nItems created are:\nBurger #0\nBurger #1\nFries #3\nBurger #2\nFries #4\nOrders completed in 12.21 seconds.\n\n\n\n\nNote that there are some limitations in multiprocessing that lead to the above code being designed this way. Let’s go over them one by one.\nFirst, remember that we previously had make_burger and make_fries functions to generate a function with the correct order_num:\ndef make_burger(order_num):\n   def making_burger():\n       logger.info(f\"Preparing burger #{order_num}...\")\n       time.sleep(5)  # time for making burger\n       logger.info(f\"Burger made #{order_num}\")\n\n\n   return making_burger\n\n\n\n\ndef make_fries(order_num):\n   def making_fries():\n       logger.info(f\"Preparing fries #{order_num}...\")\n       time.sleep(2)  # time for making fries\n       logger.info(f\"Fries made #{order_num}\")\n\n\n   return making_fries\n\n\n\n\nWe cannot do the same while using multiprocessing. An attempt to do so will give us an error along the lines of:\nAttributeError: Can't get local object 'make_burger.<locals>.making_burger'\nThe reason is that multiprocessing uses pickle, which can only serialize top-module-level functions in general. This is one of the limitations of multiprocessing.\nSecond, notice in the example code snippet above using multiprocessing, we do not use any global variables for shared data. For example, we can’t use global variables for item_made and order_num. To share data between different processes, special class objects like Queue and Value from the multiprocessing library are used and passed to the processes as arguments.\nGenerally speaking, sharing data and states between different processes is not encouraged, as it can cause a lot more issues. In our example above, we have to use a Lock to ensure the value of order_num can only be accessed and incremented by one process at a time. Without the Lock, the order number of the item can be messed up like this:\nItems created are:\n\nBurger #0\nBurger #0\nFries #2\nBurger #1\nFries #3\n\n\n\n\nHere’s how you’d use a lock to avoid trouble:\n           lock.acquire()\n           try:\n               current_num = order_num.value\n               order_num.value = current_num + 1\n           finally:\n               lock.release()\n           task(current_num, item_made)\n\n\n\n\nTo learn more about how to use the multiprocessing standard library, you can peruse the documentation here.\nRemoving the GIL\nThe removal of the GIL has been a topic for almost a decade. In 2016, at the Python Language Summit, Larry Hastings presented his thoughts on performing a “GIL-ectomy” on the CPython interpreter and the progress he’d made with this idea [1]. This was a pioneering attempt to remove the Python GIL. In 2021, Sam Gross reignited the discussion about removing the GIL [2], and that led to PEP 703 – Making the Global Interpreter Lock Optional in CPython in 2023.\nAs we can see, the removal of the GIL is by no means a rushed decision and has been the subject of considerable debate within the community. As demonstrated by the above examples of multiprocessing (and PEP 703, linked above), when the guarantee provided by the GIL is removed, things get complicated fast.\n[1]: https://lwn.net/Articles/689548/\n[2]: https://lwn.net/ml/python-dev/CAGr09bSrMNyVNLTvFq-h6t38kTxqTXfgxJYApmbEWnT71L74-g@mail.gmail.com/\nReference counting\nWhen the GLI is present, reference counting and garbage collection are more straightforward. When only one thread at a time has access to Python objects, we can rely on straightforward non-atomic reference counting and remove the object when the reference count reaches zero.\nRemoving the GIL makes things tricky. We can no longer use non-atomic reference counting, as that does not guarantee thread safety. Things can go wrong if multiple threads are performing multiple increments and decrements of the reference on the Python object at the same time. Ideally, atomic reference counting would be used to guarantee thread safety. But this method suffers from high overhead, and efficiency is hampered when there are a lot of threads.\nThe solution is to use biased reference counting, which also guarantees thread safety. The idea is to bias each object towards an owner thread, which is the thread accessing that object most of the time. Owner threads can perform non-atomic reference counting on the objects they own, while other threads are required to perform atomic reference counting on those objects. This method is preferable to plain atomic reference counting because most objects are only accessed by one thread most of the time. We can cut down on execution overhead by allowing the owner thread to perform non-atomic reference counting.\n\n\n\n\nIn addition, some commonly used Python objects, such as True, False, small integers, and some interned strings, are made immortal. Here, “immortal” just means the objects will remain in the program for its entire lifetime, thus they don’t require reference counting.\nGarbage collection\nWe also have to modify the way garbage collection is done. Instead of decreasing the reference count immediately when the reference is released and removing the object immediately when the reference count reaches zero, a technique called “deferred reference counting” is used. \nWhen the reference count needs to be decreased, the object is stored in a table, which will be double-checked to see whether this decrement in the reference count is accurate or not. This avoids removing the object prematurely when it is still being referenced, which can happen without the GIL, since reference counting is not as straightforward as with the GIL. This complicates the garbage collection process, as garbage collection may need to traverse each thread’s stack for each thread’s own reference counting.\nAnother thing to consider: The reference count needs to be stable during garbage collection. If an object is about to be discarded but then suddenly gets referenced, this will cause serious issues. Because of that, during the garbage collection cycle, it will have to “stop the world” to provide thread-safety guarantees.\nMemory allocation\nWhen the GIL is there to ensure thread safety, the Python internal memory allocator pymalloc is used. But without the GIL, we’ll need a new memory allocator. Sam Gross proposed mimalloc in the PEP, which is a general-purpose allocator created by Daan Leijen and maintained by Microsoft. It’s a good choice because it’s thread-safe and has good performance on small objects.\nMimalloc fills its heap with pages and pages with blocks. Each page contains blocks, and the blocks within each page are all the same size. By adding some restrictions on the list and dict access, the garbage collector does not have to maintain a linked list to find all objects and it also allows read access to the list and dict without acquiring the lock.\n\n\n\n\nThere are more details about removing the GIL, but it is impossible to cover them all here. You can check out PEP 703 – Making the Global Interpreter Lock Optional in CPython for a complete breakdown.\nDifference in performance with and without the GIL\nAs Python 3.13 provides a free-threaded option, we can compare the performance of the standard version of Python 3.13 to the free-threaded version.\nInstall thread-free Python\nWe’ll use pyenv to install both versions: the standard (e.g. 3.13.5) and the free-threaded version (e.g. 3.13.5t). \nAlternatively, you can also use the installers on Python.org. Make sure you select the Customize option during installation and check the additional box to install free-threaded Python (see the example in this blog post).\nAfter installing both versions, we can add them as interpreters in a PyCharm project.\nFirst, click on the name of your Python interpreter on the bottom right.\n\n\n\n\nSelect Add New Interpreter in the menu and then Add Local Interpreter.\n\n\n\n\nChoose Select existing, wait for the interpreter path to load (which may take a while if you have a lot of interpreters like I do), and then select the new interpreter you just installed from the drop-down Python path menu.\n\n\n\n\nClick OK to add it. Repeat the same steps for the other interpreter. Now, when you click on the interpreter name at the bottom right again, you will see multiple Python 3.13 interpreters, just like in the image above.\nTesting with a CPU-bounded process\nNext, we need a script to test the different versions. Remember, we explained in part 1 of this blog post series that to speed up CPU-bounded processes, we need true multithreading. To see if removing the GIL will enable true multithreading and make Python faster, we can test with a CPU-bounded process on multiple threads. Here is the script I asked Junie to generate (with some final adjustments by me):\nimport time\nimport multiprocessing  # Kept for CPU count\nfrom concurrent.futures import ThreadPoolExecutor\nimport sys\n\n\n\n\ndef is_prime(n):\n   \"\"\"Check if a number is prime (CPU-intensive operation).\"\"\"\n   if n <= 1:\n       return False\n   if n <= 3:\n       return True\n   if n % 2 == 0 or n % 3 == 0:\n       return False\n   i = 5\n   while i * i <= n:\n       if n % i == 0 or n % (i + 2) == 0:\n           return False\n       i += 6\n   return True\n\n\n\n\ndef count_primes(start, end):\n   \"\"\"Count prime numbers in a range.\"\"\"\n   count = 0\n   for num in range(start, end):\n       if is_prime(num):\n           count += 1\n   return count\n\n\n\n\ndef run_single_thread(range_size, num_chunks):\n   \"\"\"Run the prime counting task in a single thread.\"\"\"\n   chunk_size = range_size // num_chunks\n   total_count = 0\n\n\n   start_time = time.time()\n\n\n   for i in range(num_chunks):\n       start = i * chunk_size + 1\n       end = (i + 1) * chunk_size + 1 if i < num_chunks - 1 else range_size + 1\n       total_count += count_primes(start, end)\n\n\n   end_time = time.time()\n\n\n   return total_count, end_time - start_time\n\n\n\n\ndef thread_task(start, end):\n   \"\"\"Task function for threads.\"\"\"\n   return count_primes(start, end)\n\n\n\n\ndef run_multi_thread(range_size, num_threads, num_chunks):\n   \"\"\"Run the prime counting task using multiple threads.\"\"\"\n   chunk_size = range_size // num_chunks\n   total_count = 0\n\n\n   start_time = time.time()\n\n\n   with ThreadPoolExecutor(max_workers=num_threads) as executor:\n       futures = []\n       for i in range(num_chunks):\n           start = i * chunk_size + 1\n           end = (i + 1) * chunk_size + 1 if i < num_chunks - 1 else range_size + 1\n           futures.append(executor.submit(thread_task, start, end))\n\n\n       for future in futures:\n           total_count += future.result()\n\n\n   end_time = time.time()\n\n\n   return total_count, end_time - start_time\n\n\n\n\ndef main():\n   # Fixed parameters\n   range_size = 1000000  # Range of numbers to check for primes\n   num_chunks = 16       # Number of chunks to divide the work into\n   num_threads = 4       # Fixed number of threads for multi-threading test\n\n\n   print(f\"Python version: {sys.version}\")\n   print(f\"CPU count: {multiprocessing.cpu_count()}\")\n   print(f\"Range size: {range_size}\")\n   print(f\"Number of chunks: {num_chunks}\")\n   print(\"-\" * 60)\n\n\n   # Run single-threaded version as baseline\n   print(\"Running single-threaded version (baseline)...\")\n   count, single_time = run_single_thread(range_size, num_chunks)\n   print(f\"Found {count} primes in {single_time:.4f} seconds\")\n   print(\"-\" * 60)\n\n\n   # Run multi-threaded version with fixed number of threads\n   print(f\"Running multi-threaded version with {num_threads} threads...\")\n   count, thread_time = run_multi_thread(range_size, num_threads, num_chunks)\n   speedup = single_time / thread_time\n   print(f\"Found {count} primes in {thread_time:.4f} seconds (speedup: {speedup:.2f}x)\")\n   print(\"-\" * 60)\n\n\n   # Summary\n   print(\"SUMMARY:\")\n   print(f\"{'Threads':<10} {'Time (s)':<12} {'Speedup':<10}\")\n   print(f\"{'1 (baseline)':<10} {single_time:<12.4f} {'1.00x':<10}\")\n   print(f\"{num_threads:<10} {thread_time:<12.4f} {speedup:.2f}x\")\n\n\nif __name__ == \"__main__\":\n   main()\n\n\n\n\nTo make it easier to run the script with different Python interpreters, we can add a custom run script to our PyCharm project.\nAt the top, select Edit Configurations… from the drop-down menu next to the Run button ().\n\nClick on the + button in the top left, then choose Python from the Add New Configuration drop-down menu.\n\n\n\n\nChoose a name that will allow you to tell which specific interpreter is being used, e.g. 3.13.5 versus 3.15.3t. Pick the right interpreter and add the name of the testing script like this:\n\n\n\n\nAdd two configurations, one for each interpreter. Then click OK.\nNow we can easily select and run the test script with or without the GIL by selecting the configuration and clicking the Run button ()  at the top.\nComparing the results\nThis is the result I got when running the standard version 3.13.5 with the GIL:\nPython version: 3.13.5 (main, Jul 10 2025, 20:33:15) [Clang 17.0.0 (clang-1700.0.13.5)]\nCPU count: 8\nRange size: 1000000\nNumber of chunks: 16\n------------------------------------------------------------\nRunning single-threaded version (baseline)...\nFound 78498 primes in 1.1930 seconds\n------------------------------------------------------------\nRunning multi-threaded version with 4 threads...\nFound 78498 primes in 1.2183 seconds (speedup: 0.98x)\n------------------------------------------------------------\nSUMMARY:\nThreads    Time (s)     Speedup   \n1 (baseline) 1.1930       1.00x     \n4          1.2183       0.98x\n\n\n\n\nAs you see, there is no significant change in speed when running the version with 4 threads compared to the single-threaded baseline. Let’s see what we get when running the free-threaded version 3.13.5t:\nPython version: 3.13.5 experimental free-threading build (main, Jul 10 2025, 20:36:28) [Clang 17.0.0 (clang-1700.0.13.5)]\nCPU count: 8\nRange size: 1000000\nNumber of chunks: 16\n------------------------------------------------------------\nRunning single-threaded version (baseline)...\nFound 78498 primes in 1.5869 seconds\n------------------------------------------------------------\nRunning multi-threaded version with 4 threads...\nFound 78498 primes in 0.4662 seconds (speedup: 3.40x)\n------------------------------------------------------------\nSUMMARY:\nThreads    Time (s)     Speedup   \n1 (baseline) 1.5869       1.00x     \n4          0.4662       3.40x\n\n\n\n\nThis time, the speed was over 3 times as high. Notice that in both cases there is an overhead for multithreading. Therefore, even with true multithreading, the speed is not 4 times as high with 4 threads.\nConclusion\nIn part 2 of the Faster Python blog post series, we discussed the reason behind having the Python GIL in the past, side-stepping the limitation of the GIL using multiprocessing, and the process and effect of removing the GIL.\nAs of this blog post, the free-threaded version of Python is still not the default. However, with the adoption of the community and third-party libraries, the community is expecting the free-threaded version of Python to be the standard in the future. It has been announced that Python 3.14 will include a free-threaded version that will be past the experimental stage but still optional.\nPyCharm provides best-in-class Python support to ensure both speed and accuracy. Benefit from the smartest code completion, PEP 8 compliance checks, intelligent refactorings, and a variety of inspections to meet all of your coding needs. As demonstrated in this blog post, PyCharm provides custom settings for Python interpreters and run configurations, allowing you to switch between interpreters with only a few clicks, making it suitable for a wide range of Python projects.\nDownload PyCharm Now",
        "dc:creator": "Cheuk Ting Ho",
        "content": "What is Python&#8217;s Global Interpreter Lock (GIL)? “Global Interpreter Lock” (or “GIL”) is a familiar term in the Python community. It is a well-known Python feature. But what exactly is a GIL? If you have experience with other programming languages (Rust, for example), you may already know what a mutex is. It’s an abbreviation for [&#8230;]",
        "contentSnippet": "What is Python’s Global Interpreter Lock (GIL)? “Global Interpreter Lock” (or “GIL”) is a familiar term in the Python community. It is a well-known Python feature. But what exactly is a GIL? If you have experience with other programming languages (Rust, for example), you may already know what a mutex is. It’s an abbreviation for […]",
        "guid": "https://blog.jetbrains.com/?post_type=pycharm&p=585495",
        "categories": [
          "how-tos",
          "tutorials",
          "multithreading",
          "python"
        ],
        "isoDate": "2025-07-29T10:41:17.000Z"
      },
      {
        "creator": "Ekaterina Petrova",
        "title": "Ship, Share, and Win: The Kotlin Multiplatform Award at Shipaton 2025",
        "link": "https://blog.jetbrains.com/kotlin/2025/07/kmp-shipaton/",
        "pubDate": "Tue, 29 Jul 2025 07:27:01 +0000",
        "content:encodedSnippet": "There’s nothing quite like the thrill of shipping an app and turning an idea into something real that people can use. This summer, you’ve got the perfect chance to capture that feeling at RevenueCat Shipaton 2025 — a two-month global hackathon focused on launching new mobile apps (August 1 to September 30). \nAnd for Kotlin developers, the timing couldn’t be better.\nWith Compose Multiplatform for iOS now stable and production-ready (more in our blog) , it’s the perfect moment to dive in. Whether you’re a seasoned pro ready to show off your skills or just curious to try Compose Multiplatform for the first time — this is your chance.\nWhat is RevenueCat Shipaton?\nThe rules are simple:\nBuild a brand‑new mobile app in eight weeks. \nIntegrate the RevenueCat SDK to power at least one in-app or web purchase (and of course, they have a great SDK for Kotlin Multiplatform)\nShip it to the App Store or Google Play before the deadline.\nFull details are on the official Devpost page.\n🏆 Introducing the Kotlin Multiplatform Reach Award\nKotlin Multiplatform and Compose Multiplatform together give you the power to build apps for both iOS and Android from a single codebase, saving you precious time. But this isn’t just about quick prototypes.\nIt’s about creating something that scales. KMP isn’t a black box: you get full access to native APIs and can mix in platform-specific UI whenever needed. The app you build at Shipaton won’t hit a wall — it’s a solid foundation for your next big thing.\nWe’re excited to see what teams can create with that kind of power, and how they’ll bring their ideas to life across platforms. As Gold Sponsors of Shipaton, we wanted to introduce a category that celebrates not just technical skill, but also the spirit of sharing that makes the Kotlin community so special.\n🏆 The Kotlin Multiplatform Reach Award \nFor the team that ships the best, uncompromising app on both iOS and Android with Kotlin Multiplatform and/or Compose Multiplatform. Bonus points will be awarded for teams that also share their development journey with the community.\nThis award comes with a $55,000 prize pool, distributed among the top five teams:\n1st Place: $20,000\n2nd Place: $15,000\n3rd Place: $10,000\n4th Place: $5,000\n5th Place: $5,000\nTo be eligible (on top of the main Shipaton rules), your submission should include:\nA short description of your experience building with Kotlin and Compose Multiplatform. We suggest answering questions like:\n\nWhat was your biggest “aha!” moment or favorite time-saver?\nWhat surprised you most about the development process?\nWhat was the biggest challenge you overcame?\nOR, for bonus points, a link to your public “development story.” This can be a blog post, X/Twitter thread, LinkedIn article, video, or any other format you prefer.\n\n\n\n\nBy participating, you’re also competing for your share of the event’s massive $350,000+ total prize pool. It’s a fantastic opportunity to win multiple awards with a single app.\n🪄 Your Secret Weapon: Junie, the AI coding agent\nTo give you an extra edge, we’re launching Ship with Junie — an exclusive program for Shipaton participants. We’re looking for 20 developers who want to build their Kotlin Multiplatform project with help from Junie, the AI coding agent by JetBrains, available in IntelliJ IDEA and Android Studio.\nHere’s how it works: 20 selected participants will get full access to Junie for the entire two-month hackathon. In return, we’ll ask you to share your journey publicly (via blog post, video, or social media) and give us direct, private feedback.\nYou’ll get a teammate who never sleeps — and a chance to share your journey with the community.\nApply to Ship with Junie\n         \n🚀 Ready to Build? Your Starter Kit\nHere are the resources you need to get started with Kotlin and Compose Multiplatform today:\nShipaton 2025 – Full Hackathon Info on Devpost\nWhat is Compose Multiplatform? – The perfect starting point to understand the fundamentals.\nGet Started Tutorial – Your hands-on guide to creating your first Compose Multiplatform app.\nOfficial Samples – Explore a repository of sample projects to see how different features are implemented.\nKMP Awesome – An awesome list that curates the best Kotlin Multiplatform libraries, tools and more.\nJunie, the AI coding agent – Learn more about your future AI pair-programmer.\nThe stage is set. The tools are ready. We can’t wait to see what you create!\nHappy shipping.",
        "dc:creator": "Ekaterina Petrova",
        "content": "There’s nothing quite like the thrill of shipping an app and turning an idea into something real that people can use. This summer, you’ve got the perfect chance to capture that feeling at RevenueCat Shipaton 2025 — a two-month global hackathon focused on launching new mobile apps (August 1 to September 30). And for Kotlin [&#8230;]",
        "contentSnippet": "There’s nothing quite like the thrill of shipping an app and turning an idea into something real that people can use. This summer, you’ve got the perfect chance to capture that feeling at RevenueCat Shipaton 2025 — a two-month global hackathon focused on launching new mobile apps (August 1 to September 30). And for Kotlin […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=586069",
        "categories": [
          "multiplatform"
        ],
        "isoDate": "2025-07-29T07:27:01.000Z"
      },
      {
        "creator": "Denis Domanskii",
        "title": "When Tool-Calling Becomes an Addiction: Debugging LLM Patterns in Koog",
        "link": "https://blog.jetbrains.com/ai/2025/07/when-tool-calling-becomes-an-addiction-debugging-llm-patterns-in-koog/",
        "pubDate": "Mon, 28 Jul 2025 13:33:14 +0000",
        "content:encodedSnippet": "I was testing my agent built on Koog, JetBrains’ open-source framework for building AI agents in Kotlin. I fed it a task from SWE-bench-Verified, a real-world GitHub issue that tests whether AI can actually write code.\nFor the first 100 messages, everything looked promising. The agent methodically explored the codebase, identified bugs, wrote test cases, and attempted fixes. But as the conversation grew, it hit a fundamental limitation: the context window.\nEvery LLM has a maximum context size (the total amount of text it can process simultaneously). When your agent’s conversation history approaches this limit, you need to compress it somehow. Simply truncating old messages loses critical information, while generic summarization often misses essential details.\nKoog’s approach is more sophisticated. It extracts facts according to specific concepts you define, replacing the entire conversation history with these distilled insights:\nRetrieveFactsFromHistory(\n   Concept(\n       \"project-structure\",\n       \"What is the project structure of this project?\",\n       FactType.MULTIPLE\n   ),\n   Concept(\n       \"important-achievements\",\n       \"What has been achieved during the execution of this current agent\",\n       FactType.MULTIPLE\n   ),\n   Concept(\n       \"pending-tasks-and-issues\",\n       \"What are the immediate next steps planned or required? Are there any unresolved questions, issues, decisions to be made, or blockers encountered?\",\n       FactType.MULTIPLE\n   )\n   // ... more concepts\n)\n\n\n\n\nWhen compression was triggered, the agent should have continued working with extracted facts like “The bug is in sympy/parsing/latex/_parse_latex.py” and “Tests are located in sympy/parsing/tests/“. Instead, it started the entire task from scratch, as if suffering from complete amnesia.\nSomething was broken in our compression logic, so it was time to debug.\nThe investigation\n\n\n\n\nFirst, I looked at what we were sending to the LLM using our fact extraction logic. After ~100 chat messages of tool calls and results, I found the following:\nUser: Based on our previous conversation, what are the key facts about \"project-structure\" (What is the structure of this project?)\nThis was our initial implementation, and it was probably the most obvious approach – just ask the LLM to extract facts. Simple, right?\nWe should’ve gotten a summary, but instead we got this:\nAssistant: tool_name=report_plan(...)\nIt was not a summary, but another tool call. Suddenly, the amnesia made sense. Instead of useful facts, the compressed history contained gibberish like tool_name=report_plan(...). No wonder the agent started over – it had no meaningful information about its previous work.\n\nAsk for a summary, and the model responds with another tool call.\nThat raised a more disturbing question: Why was the LLM responding with tool calls when I explicitly asked for a summary?\nMy first thought was that maybe the available tools were confusing it. I tried sending an empty tool list to explicitly prevent any tool calls.\nThe response?\nAssistant: Tool call: read_dir(\"./src\")\nIt was calling tools that didn’t even exist anymore.\nThings were quickly getting weird. Maybe the system prompt was the culprit? My original agent system prompt read, “You’re a developer. Solve the user’s task, write tests, etc.” Could it be that this was overriding the summarization request?\nI tried making the summarization instruction the system prompt and demoting the original system message to a user message (as you can’t have two system messages).\nBut the tool calls just kept coming.\nThen I stopped to take a proper look at the message pattern:\nSystem: You are a developer, help the user complete their task... \nUser: Latex parsing of fractions yields wrong expression... \nTool call: read_dir(\".\") \nTool result: [directory contents] \nTool call: read_file(\"./README.md\") \nTool result: [file contents] \nTool call: write_file(\"./test/reproduce.py\", ...) \nTool result: File created successfully \nTool call: run_command(\"python -m pytest\") \nTool result: Tests failed \n[... 96 more tool calls and results ...] \nUser: Summarize the conversation above focusing on the following... \n\n\n\n\nThen it hit me – it wasn’t ignoring my instructions. After 100 examples of the pattern Tool call → Tool result → Tool call → Tool result, the model had learned that this conversation had exactly one acceptable response format: more tool calls.\nThe pattern prison\nFew-shot learning is one of our most powerful prompt engineering techniques. You show the model a few examples of input-output pairs, and it learns the pattern. We use it deliberately all the time.\nBut we’d created an implicit few-shot example without meaning to. Think about it from the model’s perspective. It’s seen 100 consecutive examples of:\nReceive a message\nRespond with a tool call\nReceive a tool result\nRespond with another tool call\nBy message 101, this pattern was so deeply reinforced that even explicit contrary instructions couldn’t break through. The model’s attention mechanism – the system determining what parts of the context to focus on – locked entirely onto the tool-calling pattern.\nI even found instances where the model tried to comply, but couldn’t escape the pattern. One response was:\nTool call: write_file(\n path=\"summary.txt\",\n content=\"Here is the summary of modified files: ...\"\n)\n\n\n\n\nIt was writing the summary, but as a file operation. The pattern was so strong that it reshaped the response format even when trying to follow the new instructions.\nBreaking free\nThe solution required thinking structurally, not semantically. We needed to break the messages’ pattern, not just add better instructions.\nThe key insight is that LLMs process conversations using special tokens (like < |im_start| > and < |im_end| >) that mark message boundaries. These tokens are part of their training, teaching them to recognize the structure of multi-turn conversations. When the model sees 100 instances of these tokens in a rigid pattern, it learns that this is how this conversation must continue.\nMy fix was to combine all messages into a single string, wrapped in custom XML-like tags:\nval combinedChatHistory = buildString {\n   append(\"<conversation_to_extract_facts>\\n\")\n   messages.forEach { message ->\n       when (message) {\n           is ToolCall -> append(\"<tool_call>${message.content}</tool_call>\\n\")\n           is ToolResult -> append(\"<tool_result>${message.content}</tool_result>\\n\")\n           // ... handle other message types\n       }\n   }\n   append(\"</conversation_to_extract_facts>\\n\")\n}\nThen build the final prompt:\nPrompt.build(id = \"swe-agent\") { \n   system (\"Summarize the content inside <conversation_to_extract_facts> focusing on 'project-structure' (What is the structure of this project?).\") \n   user (combinedChatHistory) \n}\nThis worked immediately. Here’s what changed:\nBefore: 100+ individual messages, each reinforcing the tool-calling pattern, followed by a user request.\nAfter: Just two messages in total: a system instruction to compress the history and the wrapped conversation data.\nTo the LLM, our XML tags are just content, not structural message boundaries. This let it finally “hear” the summarization request instead of being trapped in the learned pattern.\nThe final piece\n\n\n\n\nBreaking the pattern was only half the solution. Even with working compression, the agent acted confused after resuming. It would read the compressed facts, then start exploring the project from scratch, more efficiently thanks to the insights, but still from the beginning.\nOnce I considered it, the problem became obvious – we never told the agent what had happened. From its perspective, it suddenly saw a project summary it didn’t remember creating, almost like you or I waking up with someone else’s notes on our desk.\nThis revealed another quirk of LLM psychology. The fix was surprisingly elegant – have the agent explain the situation to itself:\nSystem: You are a developer, help the user complete their task... \n\nUser: Latex parsing of fractions yields wrong expression... \n\nAssistant: I was actively working on this task when I needed to compress my memory due to context limits. \nHere's what I accomplished so far: \n[summary of progress, modified files, current state] \nI'm ready to continue from where I left off.\n\nUser: Great, please continue.\n\n\n\n\nTwo subtle things make this work:\nSelf-trust: By having the Assistant role explain the situation, we leverage the model’s tendency to trust and maintain consistency with its own statements. Information from itself is more believable than external claims about what happened.\n\n\n\n\nNatural continuation: The final user message (“Great, please continue”) provides a natural prompt for action. If we ended with the assistant’s explanation, the model might consider the conversation complete, as no user response often signals the end of an interaction.\nThe agent seamlessly picked up where it left off, understanding why they lost all the chat history.\nWhat this means\nThis behavior reveals something fundamental about how LLMs process context. The context window isn’t just memory – it’s active training data that shapes behavior in real time. When patterns in that context are strong enough, they can override explicit instructions.\nFor anyone building agents or long-running LLM applications:\nWatch your patterns: Repetitive message structures create behavioral ruts. If your agent needs to do different types of tasks, ensure variety in your message patterns.\nStructure beats instructions: When you need to break a pattern, changing the structure (like our XML wrapping) is more potent than adding more instructions.\nSelf-consistency is powerful: LLMs strongly maintain consistency with their previous statements, which can be used to maintain continuity across context boundaries.\nThe fix is now part of Koog’s compression system. When you call RetrieveFactsFromHistory(...), it handles all of this automatically, breaking patterns, preserving context, and maintaining continuity. You don’t need to think about any of it – all you need to do is provide your concepts.\nIf you’re curious about the implementation details, the pull request is public.\nDenis Domanskii is an engineer at JetBrains working on AI agents. When he’s not teaching LLMs to forget their habits, he’s probably creating new ones.\nCo-authored by Claude Opus 4 from Anthropic, who spent 100 messages helping craft this article without once trying to call a non-existent tool. Progress! – Claude",
        "dc:creator": "Denis Domanskii",
        "content": "I was testing my agent built on Koog, JetBrains&#8217; open-source framework for building AI agents in Kotlin. I fed it a task from SWE-bench-Verified, a real-world GitHub issue that tests whether AI can actually write code. For the first 100 messages, everything looked promising. The agent methodically explored the codebase, identified bugs, wrote test cases, [&#8230;]",
        "contentSnippet": "I was testing my agent built on Koog, JetBrains’ open-source framework for building AI agents in Kotlin. I fed it a task from SWE-bench-Verified, a real-world GitHub issue that tests whether AI can actually write code. For the first 100 messages, everything looked promising. The agent methodically explored the codebase, identified bugs, wrote test cases, […]",
        "guid": "https://blog.jetbrains.com/?post_type=ai&p=585271",
        "categories": [
          "jetbrains-ai",
          "ai",
          "ai-agents"
        ],
        "isoDate": "2025-07-28T13:33:14.000Z"
      },
      {
        "creator": "Vitaly Bragilevsky",
        "title": "100 Exercises to Learn Rust: RustRover Edition",
        "link": "https://blog.jetbrains.com/education/2025/07/28/rust-exercises-rustrover/",
        "pubDate": "Mon, 28 Jul 2025 12:33:09 +0000",
        "content:encodedSnippet": "Mainmatter’s Luca Palmieri’s 100 Exercises to Learn Rust have helped thousands of developers deepen their Rust skills. Now this outstanding course is available right inside RustRover, JetBrains’ powerful Rust IDE! That means no setup headaches and no switching between websites and terminals – just hands-on Rust practice with full IDE support.\nIn this post, I’ll share my impressions of the course, walk you through what it’s like to learn Rust directly in RustRover, and offer a few practical tips to get the most out of the experience.\nTAKE THE COURSE\n                                    \nWhat you’ll learn from the exercises\nIn this course, you’ll learn all about Rust, starting from the basics like variable and control flow (if, match, and loops) to more advanced topics like traits, memory management, data structures, and even concurrency. While learning these topics, you’ll be implementing elements of a software project management system.\nThe 100 Exercises to Learn Rust course follows the learning-by-doing approach: First you learn a bite-sized piece of theory, then solve a tailor-made assignment. While the exercises are not particularly hard, they give you a good idea of the kinds of tasks you’ll be working on in real projects.\nYou don’t need any prior experience with Rust. You start from scratch, and then, thanks to the course’s project-based structure and step-by-step progression, you build on what you’ve already learned.\nThe course author, Luca Palmieri, has vast experience teaching Rust using these materials, so you can rest assured that the approach actually works.\nPracticing Rust in an IDE\nLuca’s original course consists of a website with theory lessons and a GitHub repository with the exercises. In RustRover, you can access both in one place:\nExperience seamless Rust learning: Read theory, solve problems, and check your solutions – right in RustRover\n\n\n\nThe great thing about doing this in RustRover is that, throughout this process, you get the full IDE experience. This means you can see the compiler errors and get help fixing them, debug your code, easily navigate between the course sections, get AI assistance, and check your solutions. And if you’re in serious trouble, you can even cheat and peek at the author’s solutions! Not that you would do that, of course. Getting your code to work the right way is where all the fun is! That said, once you’re happy with your solution, it might be useful to compare it with the author’s suggested solution.\nOne of the hidden advantages of taking this course inside RustRover is that you’re not just learning Rust – you’re also learning how to work productively in a professional-grade IDE. Every exercise is a chance to explore not just what your code does, but how your tools can help you understand and improve it. For example:\nRan into an error? RustRover can help you fix it with quick-fixes, AI suggestions, and even compiler-driven hints – right where the error appears.\nGot stuck on a bug? Step through your code with the built-in debugger. You’ll see variable values change and understand where things go wrong.\nCurious about how your project is structured? Navigate between files, track recent edits, and use search tools to move around faster.\nWant to edit your configuration? RustRover understands Cargo.toml, too – so it helps with suggestions, errors, and formatting even in your project settings.\nAs you go through the course, don’t just accept what the IDE shows you. Ask why. Why did it suggest this fix? Why is that warning showing up? Why does the compiler behave differently in debug vs. release mode? Exploring these questions deepens your understanding of Rust and builds fluency in the development environment you’ll likely use on real-world projects. By the time you’ve finished the exercises, you won’t just know more Rust – you’ll also have leveled up your tooling skills without even realizing it.\nHow to get started\nDownload and install RustRover. Then, enable its educational functionality: On the Welcome screen, go to the Learn tab, find the Learn to program widget, and click Enable Access.\nOnce access is enabled, click the Get Started button and select 100 Exercises to Learn Rust from the list. Alternatively, access the course by going to File | Learn and Teach | Browse Courses.\nRustRover is completely free for educational purposes, plus it supports Rust beginners with plenty of tailor-made features, all of which makes it the perfect tool for taking this course. Once you’re done with the course, you might also be interested in more recommendations on how to advance your Rust knowledge.\nSo, are you ready to become a Rustacean? With 100 practical exercises and a helpful IDE at your side, there’s no better way to get started.\nTAKE THE COURSE\n                                    \nHappy learning!",
        "dc:creator": "Vitaly Bragilevsky",
        "content": "Mainmatter&#8217;s Luca Palmieri&#8217;s 100 Exercises to Learn Rust have helped thousands of developers deepen their Rust skills. Now this outstanding course is available right inside RustRover, JetBrains’ powerful Rust IDE! That means no setup headaches and no switching between websites and terminals – just hands-on Rust practice with full IDE support. In this post, I’ll [&#8230;]",
        "contentSnippet": "Mainmatter’s Luca Palmieri’s 100 Exercises to Learn Rust have helped thousands of developers deepen their Rust skills. Now this outstanding course is available right inside RustRover, JetBrains’ powerful Rust IDE! That means no setup headaches and no switching between websites and terminals – just hands-on Rust practice with full IDE support. In this post, I’ll […]",
        "guid": "https://blog.jetbrains.com/?post_type=education&p=584128",
        "categories": [
          "jetbrains-academy",
          "learning-courses",
          "learn-programming",
          "rust",
          "rustrover"
        ],
        "isoDate": "2025-07-28T12:33:09.000Z"
      },
      {
        "creator": "Arseniy Terekhov",
        "title": "Interprocedural Analysis: Catch nil Dereferences Before They Crash Your Code",
        "link": "https://blog.jetbrains.com/go/2025/07/28/interprocedural-analysis-catch-nil-dereferences-before-they-crash-your-code/",
        "pubDate": "Mon, 28 Jul 2025 12:24:03 +0000",
        "content:encodedSnippet": "The upcoming GoLand 2025.2 release introduces a powerful set of new features and improvements designed to help you write safer, more reliable Go code. If you’d like a full breakdown of all the updates, be sure to check out the release notes. \nIn this post, we’ll focus on one of the most significant new features: interprocedural code analysis for detecting nil pointer dereferences. By helping you catch subtle bugs that often slip through code reviews and tests, this improvement makes your production code more stable and easier to maintain.\nThe GoLand team has put a lot of effort into delivering deeper, smarter static analysis to improve your development experience and help prevent those frustrating runtime panics. If you want to try this feature in your IDE, you can clone the following project from GitHub.\nnil pointer dereference in Go\nOne of the most common pain points in the Go programming language is nil pointer dereference, and nearly every Go developer has encountered it at some point. Despite Go’s simplicity and strong static typing, nil remains a source of subtle and often critical bugs.\nThe impact of a nil dereference can be severe, especially in production environments. A single unexpected dereference can crash an entire service, bringing down an API or worker process with little to no warning. \nIn Go, even more subtle issues can arise. Writing to a nil channel, for instance, can cause a goroutine to be blocked forever, potentially leading to deadlocks and cascading system failures. Attempting to access fields on an uninitialized nil pointer will result in an immediate panic. These kinds of errors are easy to overlook and hard to trace back once deployed.\nWhile some nil dereference issues can be caught through careful code review or testing, that’s not always enough. In fast-paced development cycles or large codebases, it’s easy for subtle nil-related bugs to slip through. Ideally, such issues should be detected automatically and as early as possible when writing the code.\nThis is where static code analysis comes in. GoLand already includes a built-in nil dereference inspection that performs local intraprocedural analysis. It works well for many common scenarios, detecting when a pointer might be nil within the scope of a single function.\nHowever, the current analysis only works within individual functions. It does not follow how values move between functions, so it can miss problems that involve multiple calls. These more complex cases are common in real-world Go code and are often the most dangerous. To catch them, we’ve implemented something more powerful: interprocedural code analysis.\nInterprocedural code analysis\nInterprocedural analysis, also called global analysis, helps you understand how values move through function calls. It looks beyond a single function to follow data across files and packages. In contrast, intraprocedural or local analysis only checks what happens inside one function. Local problems are often easy to catch by reviewing a single function. But global problems are harder to find because the source of an issue, such as a nil value, might be far from where it causes an error. That is why interprocedural analysis is especially useful for detecting nil dereference issues.\nFollowing the flow: Understanding nil dereferences\nNow let’s take a look at an example. This code looks pretty straightforward. We create a user using a constructor and print its fields. But the analysis gives us a warning: user.Age might cause a nil dereference.\n\n\n\n\nLet’s try to investigate this manually. To understand what’s going on, we need to look at how the NewUser function is implemented. It is defined in a different file called model.go.\n\n\n\n\nThis constructor looks a bit strange: NewUser returns nil if an error occurs, but in main, we use the result without checking. This creates a potential nil dereference.\nTo fix this, we can rewrite NewUser to return both a result and an error – the more idiomatic Go style.\n\n\n\n\n\nNow the code is safer. We check for an error before accessing user, so there is no risk of dereferencing nil. Although this code looks correct, we still see the same warning.\nTo figure out what’s going on, let’s dig in deeper and take a closer look at the implementation of CreateUser.\n\n\n\n\n\nHere we find the second cause of the problem.\nIn the CreateUser function, there is a case where the code returns nil for both the user and the error.\n\n\n\n\nThis is a fairly common mistake in error handling. Returning nil without an error makes it look like everything went fine, while in reality the result is not valid. The caller checks only the error, sees that it is nil, and then tries to use the result. In our example, this leads to a crash when the code accesses user.Age.\nWe can fix this by returning an actual error when the input is not valid:\n\n\n\n\nWith this change, the code becomes correct, and the inspection no longer reports a nil dereference.\nFinding issues like this by hand can be slow and frustrating, especially in large projects. The place where a nil value is created might be far from where it causes a problem.\nThat is why GoLand highlights such issues right in the editor as soon as they are detected. For these warnings, we offer a dedicated context action: Explain potential nil dereference. This action opens the Data Flow Analysis tool window, where you get a step-by-step explanation of how the nil value flows through the code and where it is eventually used. This makes it much easier to understand and fix the issue without searching through the entire codebase.\n\n\n\n\nWhen nil slips through: Catching unsafe arguments and receivers\nOur analysis does more than track return values. It can also reason about parameter nilability by understanding whether a function expects a non-nil argument or can safely accept nil. This is particularly useful for catching cases where a nil value is unintentionally passed to a function that doesn’t handle it properly.\nLet’s take a look at another example:\n\n\n\n\n\nHere we call the Copy method on a user. At the same time, we pass nil as the context, assuming it is safe to do so. \nBut the inspection shows a warning: The context argument might cause a nil dereference as we pass a nil value as the context. Let’s check the implementation of the Copy method:\n\n\n\n\nIn this code, the method accesses ctx.isDebugEnabled without checking whether ctx is nil. If ctx is nil, the program will panic at runtime.\nTo fix this, we can make the ctx parameter nil-safe by adding an explicit nil check before accessing its fields.\n\n\n\n\n\nWith this change, the code becomes safe, and the warning at the call site disappears.\n\n\n\n\n\nHowever, that is not the only problem. The analysis also reports a potential nil dereference related to the user variable.\nTo understand why, we can use the Explain potential nil dereference action.\n\n\n\n\nThe process function allows user to be nil, and we pass it to Copy without checking. \nInside the Copy method, the receiver u is used before being checked. Specifically, u is passed to the logUserEvent function, where a dereference occurs when accessing the u.Name field. Therefore, if the user variable in the process function is nil, a nil dereference will occur.\nThese examples demonstrate that nil dereference issues are often subtle and easy to overlook. Even if the code looks clean and idiomatic, small assumptions can lead to runtime crashes. Tracing the root cause manually can be surprisingly tricky, especially when the origin of the nil value is created far from the place where it is used, separated from the dereference by multiple function calls, files, or packages.\nThis is where interprocedural analysis helps. It tracks how nil values move through function calls. Instead of guessing where the problem started, you can clearly see the full path from the origin to the point of dereference.\nQuick documentation now shows nilability information\nNilability analysis in GoLand is not just for highlighting issues in the editor. As you’ve already seen, our analysis can determine whether a function might return nil, and whether it’s safe to pass nil as an argument to a particular parameter. As the analysis understands how functions are expected to behave, we decided to make this information easy to access. That’s why we’ve integrated nilability information directly into the quick documentation popup.\nLet’s go back to the first example from earlier, before we applied any fixes. If we place the caret on the NewUser function and trigger the quick documentation, we will see a section called Nilability info. It shows the nilability of the function parameters and the return value. In this example, the function may return a nil result, and the quick documentation popup tells us that clearly.\n\n\n\n\nThe same feature works for parameters and receivers. In the second example, also before applying any fixes, the Nilability info section shows us that both the receiver u and the parameter ctx of the function are expected to be non-nil.\n\n\n\n\n\nThis small addition makes a big difference. With a quick lookup, you get an overview of important details, which can help you write safer code and reduce the risk of unexpected nil dereferences. However, keep in mind that not all cases are covered by the analysis, so always review the code carefully.\nLimitations and trade-offs\nThe first version of this analysis is simple and careful on purpose. It does not try to catch every possible nil dereference, and that is intentional. We’ve focused on the most common and important cases, aiming to keep false positives to a minimum. We’ll keep improving the analysis over time, adding new cases carefully. Our goal is to catch more problems without adding unnecessary noise.\nAvoid panics; embrace safety\nInterprocedural code analysis makes it much easier to catch and fix nil pointer dereference issues early. By tracking nil values across functions, files, and packages, this analysis makes it easier to understand the root causes of potential bugs before they hit production, reducing downtime and preventing costly incidents. \nWe’re excited to continue refining and expanding these capabilities in future updates. Stay tuned – and as always, we’d love to hear your feedback!\nThe GoLand Team",
        "dc:creator": "Arseniy Terekhov",
        "content": "The upcoming GoLand 2025.2 release introduces a powerful set of new features and improvements designed to help you write safer, more reliable Go code. If you&#8217;d like a full breakdown of all the updates, be sure to check out the release notes.&#160; In this post, we’ll focus on one of the most significant new features: [&#8230;]",
        "contentSnippet": "The upcoming GoLand 2025.2 release introduces a powerful set of new features and improvements designed to help you write safer, more reliable Go code. If you’d like a full breakdown of all the updates, be sure to check out the release notes.  In this post, we’ll focus on one of the most significant new features: […]",
        "guid": "https://blog.jetbrains.com/?post_type=go&p=583312",
        "categories": [
          "features",
          "goland-2025-2"
        ],
        "isoDate": "2025-07-28T12:24:03.000Z"
      },
      {
        "creator": "Yulia Zozulya",
        "title": "Bringing Remote Closer to Local: 2025.2 Highlights",
        "link": "https://blog.jetbrains.com/platform/2025/07/bringing-remote-closer-to-local-2025-2-highlights/",
        "pubDate": "Mon, 28 Jul 2025 10:48:56 +0000",
        "content:encodedSnippet": "Our goal is to make remote development with JetBrains IDEs feel just as reliable and consistent as working locally does. Recently, we’ve made progress towards this goal in core areas like the editor, tool windows, plugin behavior, and settings synchronization. \nEditor\n\n\n\n\nAll the changes made to the editor in the 2025.2 release are based on a single underlying idea: to make remote editing feel as seamless and responsive as working locally.\nWe improved the way the editor opens in remote sessions. To reduce the perceived delay between user action and UI feedback, we’ve changed how fast different UI elements appear when opening a file. Now, when a file is opened in a remote session, the editor tab appears immediately, first with the tab frame and file name, followed by the file content as soon as it’s available.\nWe’re also experimenting with a skeleton view for cases where the editor content cannot be displayed fast enough, with the goal of making the UI feel more responsive. Once the data arrives, the skeleton is seamlessly replaced by the actual file content. Please share your feedback on this change!\n\n\n\n\nTo improve responsiveness, we’ve moved several basic editor actions to the frontend:\nThe clipboard now reliably captures the correct selection when copy-pasting, even when actions happen quickly.\nIdentifier highlighting under the caret now feels faster thanks to frontend caching. The first time something is highlighted, it’s calculated on the backend, but repeated highlights appear instantly while the file stays open.\n\n\n\n\nUsing the Java plugin as an example, we’ve made progress toward smarter frontend execution by moving more functionality to the frontend. This includes:\nCode selection and navigation (brace matching and word selection).\nStatement and element movement (up/down and left/right).\nCode formatting and indentation.\nSmart Enter processing.\nSimple highlighting.\n\n\n\n\nThanks to these changes, the caret now moves much more predictably, even after smart backend updates are applied.\nWe’ve also extended this approach to SQL, JSON, YAML, TOML, and Ruby, which are now all available in the released version.\nThere is more work ongoing for upcoming releases, including native-feeling remote development support for other programming languages.\nDebugger\nWe’ve started rolling out a split frontend/backend architecture for the debugger. One of the biggest advantages is that the debugger is less coupled with the network delay. For instance, if you place or delete a breakpoint, it will be applied immediately, with a subsequent interaction with the backend. We’ve also added support for core debugging features like frames, variables, watches, and more, and we’re continuing to work on developing additional features. \nWhile not all functionality is in place yet, the current implementation is fully usable, and the missing features don’t block core debugging workflows.\nTerminal\nThe initial implementation of the split terminal was written between 2024.3 and 2025.1. We finally enabled it by default in 2025.2. The new release fixed many issues related to the previous version of the terminal, and the change was highly anticipated by many individual and corporate customers.\nThese updates improve the current experience and lay the foundation for future enhancements, ensuring new features will now work natively in remote development mode.\nPlatform functional windows\nPopups with long or dynamic lists have historically performed poorly in remote development scenarios, especially over unstable or high-latency connections. The redesigned versions now provide the same native-level performance when working remotely as they do when working locally, offering smooth scrolling and instant selection, even on slower or less reliable networks.\nSearch Everywhere: The most used features are now fully supported, and the popup performs smoothly in remote development scenarios.\nFind in Files: This popup now feels fast and responsive, and several long-standing issues have been resolved.\nGit Branch widget: We’ve improved this widget’s performance and responsiveness under high latency.\n\n\n\n\n\n\n\n\nPlugin experience\nWith the latest release, we introduced synchronization of plugins between the client and the host. The IDE now installs the necessary plugins on the client machine based on the host’s setup and vice versa. This allows the development environment to remain consistent with minimal user involvement. The synchronization behavior can be configured depending on the security requirements in specific companies.\nIDE settings\nWe fixed an issue where various project settings were lost between IDE restarts. Recent updates make sure that selected UI and project-specific settings are preserved so that you can resume work exactly where you left off.\nHere’s what now persists correctly:\nIDE window size and position.\nLayout and state of tool windows.\nOpen files and their order.\nTool window-specific settings, such as appearance and behavior in the Project view.\nToolbox and remote development\nRemote development support in Toolbox was released in April, and while there’s still room for improvement, early feedback has been very positive. Several companies have confirmed that using Toolbox significantly improves connection stability.\nIn synthetic tests, we observed connection performance improvements of 1.5x or more:\n\n\n\n\nIn addition to performance gains, Toolbox supports OpenSSH, works with any major remote host’s OS (not just Linux, but Windows and macOS, too), and lets you manage everything from setup to updates in the same way you handle your IDEs locally. This results in a smoother remote workflow that’s built for how you actually work. You can read more about remote development with Toolbox in our recent blog post.\nWe’ve also added a new feature: If Toolbox is running, you can now see remote projects in the Recent Projects popup, right alongside your local projects.\nOther important improvements\nThis year, we focused on improving core functionality – frequently used windows, actions, and better separation of components and languages between the frontend and backend. Our goal is to build a unified architecture that works consistently in both monolith and remote development environments.\nThat said, there are still some tricky parts of the IDE stack to tackle, like syncing keymaps, color schemes, and other settings.\nWe’ve also fixed several bugs. Here are some of the most important ones:\nIJPL-168465/Client-forgets-keymap-periodically\nIJPL-167788/State-of-splitted-editors-isnt-restored-after-reconnecting-to-the-session\nIJPL-166434/Project-View-only-Project-and-Packages-views-are-available-in-RemDev\nIJPL-170464/Clicking-the-Select-opened-File-in-the-project-tree-on-a-file-of-an-external-lib-does-not-work\nIJPL-168465/Client-forgets-keymap-periodically",
        "dc:creator": "Yulia Zozulya",
        "content": "Our goal is to make remote development with JetBrains IDEs feel just as reliable and consistent as working locally does. Recently, we’ve made progress towards this goal in core areas like the editor, tool windows, plugin behavior, and settings synchronization.&#160; Editor All the changes made to the editor in the 2025.2 release are based on [&#8230;]",
        "contentSnippet": "Our goal is to make remote development with JetBrains IDEs feel just as reliable and consistent as working locally does. Recently, we’ve made progress towards this goal in core areas like the editor, tool windows, plugin behavior, and settings synchronization.  Editor All the changes made to the editor in the 2025.2 release are based on […]",
        "guid": "https://blog.jetbrains.com/?post_type=platform&p=585366",
        "categories": [
          "intellij-platform",
          "news",
          "2025-2",
          "remote-development"
        ],
        "isoDate": "2025-07-28T10:48:56.000Z"
      },
      {
        "creator": "Sasha Ivanova",
        "title": "Upcoming Changes to JetBrains .NET Tools",
        "link": "https://blog.jetbrains.com/dotnet/2025/07/25/upcoming-changes-to-dotnet-tools/",
        "pubDate": "Fri, 25 Jul 2025 13:02:34 +0000",
        "content:encodedSnippet": "We’re making some changes to our .NET tools, and we want to give you an overview of what’s happening and the reasons behind the changes. Some features you might be using are being discontinued or transformed, while others are getting significant refinements. We believe that these changes will allow us to build better tools for everyone. \nWhat’s driving these changes\nOver the past year, we’ve been listening closely to our community through user surveys and interviews, as well as analyzing detailed usage statistics across our .NET tools. This data has given us valuable insights into how developers actually use our tools and where we should focus our development efforts.\nThe picture that emerged was clear: while we’ve built many powerful features over the years, some are underutilized, while others have tremendous potential that we haven’t fully realized. This led us to make some strategic decisions about streamlining our offerings to deliver more value where it matters most.\nChanges in the 2025.2 release\nStreamlining dotCover\nThe standalone dotCover tool will also receive significant streamlining to improve performance and reduce complexity. We’ve modernized the command-line runner, consolidating commands under a unified dotcover cover interface and transitioning from XML-based configuration files to simpler plain-text argument files. \nWe’ve also removed some rarely-used filtering options (method and class filters, file path filters, and in-source comment filters) and discontinued support for legacy application types, including IIS Express, WCF, WinRT, and external .NET processes. These changes significantly reduce overhead and allow our team to concentrate on the core coverage scenarios that matter most to modern .NET development workflows.\nEnd of code coverage for Mono and Unity projects in Rider\nRider 2025.2 will no longer provide coverage analysis for Mono and Unity projects via dotCover. Analyzing the low usage numbers, we realized that it significantly increases the technical debt for the team, which is now focused on performance improvements and branch coverage. \nWe plan to restore coverage analysis for Unity projects once Unity migrates to CoreCLR (expected after Unity 7 LTS). The list of available target application types in the cover application dialog will be reduced to .NET, .NET Core, Windows Service, and IIS.\nTeamCity extension for Visual Studio\nWe’ll be discontinuing the TeamCity extension for Visual Studio as part of our efforts to streamline tooling and focus on the most impactful developer experiences. While we understand this may affect some workflows, this decision enables us to concentrate on delivering better performance and more sustainable tool ecosystems.\nChanges coming in 2025.3\nTo make sure our development efforts deliver the most value, we’re adjusting how some features are maintained and delivered in Rider, based on actual usage patterns and technical considerations. \nDynamic Program Analysis (DPA) in Rider\nDPA is evolving. In Rider 2025.3, it will cease to be available as a separate tool, and instead, its analytical capabilities will be further integrated into the Monitoring tool. With this change, we aim to provide you with a powerful performance analysis experience while keeping your workflow simple. The DPA capabilities inside the Monitoring tool will be available under the dotUltimate license, alongside the already-integrated dotTrace and dotMemory profilers.\nWe’re here to help\nWe recognize some of these changes might affect established workflows. Our Support team is ready to help you find the best solutions for your specific needs. If these changes significantly impact your work or if you have suggestions for how we can better serve your development needs, please don’t hesitate to reach out.\nWhat’s your vision for dotUltimate?\nThese changes will help us free up significant development capacity and direct it towards improvements that matter most to our users. You can expect to see continued performance enhancements, stability improvements, and feature refinements that make development more productive and enjoyable.\nAs always, your feedback shapes our roadmap. Tell us about your vision for the dotUltimate set of tools! Is there anything missing from your toolbox that we could provide? Perhaps, you’d like to see some other JetBrains products be covered by this subscription? Share your ideas in the comments, on our issue trackers, and on our social media pages.",
        "dc:creator": "Sasha Ivanova",
        "content": "We&#8217;re making some changes to our .NET tools, and we want to give you an overview of what&#8217;s happening and the reasons behind the changes. Some features you might be using are being discontinued or transformed, while others are getting significant refinements. We believe that these changes will allow us to build better tools for [&#8230;]",
        "contentSnippet": "We’re making some changes to our .NET tools, and we want to give you an overview of what’s happening and the reasons behind the changes. Some features you might be using are being discontinued or transformed, while others are getting significant refinements. We believe that these changes will allow us to build better tools for […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=585327",
        "categories": [
          "net-tools",
          "rider",
          "dotcover",
          "dotultimate",
          "teamcity"
        ],
        "isoDate": "2025-07-25T13:02:34.000Z"
      }
    ]
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Jim Harrer",
        "title": "Watch Live: Visual Studio Toolbox at VS LIVE! Redmond 2025",
        "link": "https://devblogs.microsoft.com/visualstudio/watch-live-visual-studio-toolbox-at-vs-live-redmond-2025/",
        "pubDate": "Tue, 29 Jul 2025 15:28:53 +0000",
        "content:encodedSnippet": "Join Robert Green and Leslie Richardson for a full day of live sessions, demos, and interviews.\nLive from Microsoft HQ – Stream Tuesday’s Sessions with Visual Studio Toolbox!\nOn Tuesday, August 5, join us for a special edition of Visual Studio Toolbox Live—broadcast from VS LIVE! Redmond and hosted by Leslie Richardson and Robert Green. You’ll get a full day of Microsoft-led sessions, live studio commentary, behind-the-scenes interviews, and exclusive insights straight from campus.\n Click here to set a YouTube reminder so you don’t miss a moment.\n What You’ll See on Tuesday\nWe’re streaming five sessions led by Microsoft product teams across Visual Studio, Azure, GitHub Copilot, and .NET. Whether you’re looking to boost your daily productivity or build your next-gen AI app, this day is packed with learning.\n 8:00 AM – Getting the Most out of the Latest in Visual Studio\nHarshada Hole & Jessie Houghton, Microsoft\nSee the newest productivity boosts, AI-assisted debugging, and smarter Git tools—plus how to make them work for your day-to-day workflow.\n 9:30 AM – Build Next-Gen AI Apps with .NET and Azure\nJon Galloway, Microsoft\nDiscover the latest SDKs, patterns, and frameworks for building intelligent cloud-native applications.\n 11:15 AM – Keynote: The Future of Visual Studio\nMads Kristensen, Microsoft\nGet inspired as Mads shows off what’s new and what’s coming next for developers building with Visual Studio.\n 1:30 PM – Getting the Most Out of .NET Development with Visual Studio\nAllie Barry & Wendy Breiding, Microsoft\nTips, tricks, and GitHub Copilot techniques to boost your .NET development efficiency and code quality.\n 3:00 PM – Building Mobile & Desktop Apps with .NET MAUIDavid Ortinau, Microsoft\nExplore how to build stunning cross-platform apps with .NET MAUI using Visual Studio’s latest live tooling and project templates.\n Hosted Live from the Studio\nBetween each session, we’ll cut to the Visual Studio Toolbox studio with Robert and Leslie, featuring:\nLive Q&A from the YouTube chat\nGuest drop-ins from our Microsoft speakers\nCommentary and context to help you apply what you just saw\nAnd maybe a few surprises…\n Have a question during the stream? Drop it in the chat—Robert and Leslie might feature it live!\n How to Watch\n Watch the Full Livestream on YouTube\nCatch all five Microsoft-led sessions, plus live studio hosting from Robert Green and Leslie Richardson.\n Watch Live on YouTube\n(Streaming begins Tuesday, August 5 at 8:00 AM PT)\n Get the Backstage Pass with Krezzia & Lydia\nWant to see what it’s like behind the scenes at VS LIVE! Redmond?\nFollow Krezzia Basilio and Lydia Yong, Microsoft FTEs from the Aspire Undergrad Program, as they bring you backstage interviews, speaker walk-and-talks, reaction clips, and stories from the event floor.\nThis is your unofficial, unscripted, attendee-level view of the action—from greenroom to keynote to closing time.\n Follow on TikTok\n Follow on LinkedIn\n Catch the Sessions On-Demand (After August 11)\nCan’t join live? No problem—on-demand recordings of many Microsoft-led sessions will be available a few days after the event.\n Want More Toolbox?\nVisual Studio Toolbox is your go-to show for weekly tips, tools, and demos straight from the product team and engineering experts. From debugging hacks to Copilot walkthroughs, it’s where devs stay current without falling behind.\n Explore Visual Studio Toolbox Episodes\nWe’ll See You on August 5\nThis is more than just a livestream—it’s a chance to learn directly from the people who build the tools you use every day. We hope you’ll tune in, join the chat, and spend a day with us at Microsoft HQ.\n—Jim\nThe post Watch Live: Visual Studio Toolbox at VS LIVE! Redmond 2025 appeared first on Visual Studio Blog.",
        "dc:creator": "Jim Harrer",
        "comments": "https://devblogs.microsoft.com/visualstudio/watch-live-visual-studio-toolbox-at-vs-live-redmond-2025/#comments",
        "content": "<p>Join Robert Green and Leslie Richardson for a full day of live sessions, demos, and interviews. Live from Microsoft HQ – Stream Tuesday’s Sessions with Visual Studio Toolbox! On Tuesday, August 5, join us for a special edition of Visual Studio Toolbox Live—broadcast from VS LIVE! Redmond and hosted by Leslie Richardson and Robert Green. [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/watch-live-visual-studio-toolbox-at-vs-live-redmond-2025/\">Watch Live: Visual Studio Toolbox at VS LIVE! Redmond 2025</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Join Robert Green and Leslie Richardson for a full day of live sessions, demos, and interviews. Live from Microsoft HQ – Stream Tuesday’s Sessions with Visual Studio Toolbox! On Tuesday, August 5, join us for a special edition of Visual Studio Toolbox Live—broadcast from VS LIVE! Redmond and hosted by Leslie Richardson and Robert Green. […]\nThe post Watch Live: Visual Studio Toolbox at VS LIVE! Redmond 2025 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=253722",
        "categories": [
          "Visual Studio"
        ],
        "isoDate": "2025-07-29T15:28:53.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": [
      {
        "creator": "고명환",
        "title": "이스라엘 스타트업 성공 전략&nbsp;",
        "link": "https://brunch.co.kr/@@LOc/301",
        "pubDate": "Wed, 30 Jul 2025 03:00:07 GMT",
        "author": "고명환",
        "content": "이스라엘은 전 세계에서 Startup Nation으로 불릴 만큼 창업과 혁신이 활발한 국가입니다. 인구는 1,000만 명도 되지 않지만, 나스닥 성장 기업 수는 미국과 중국에 이어 세계 3위권입니다. 첨단기술, 글로벌 네트워크, 정부의 강력한 지원 덕분에 세계 스타틑업 허브로 자리매김했습니다. 이번 포스팅에서는 이스라엘 스타트업 생태계의 특징, 정부 지원제<img src= \"https://img1.daumcdn.net/thumb/R1280x0.fjpg/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FtA33dBms7YUdQSx8Fi582LYyRWk.JPG\" width=\"500\" />",
        "contentSnippet": "이스라엘은 전 세계에서 Startup Nation으로 불릴 만큼 창업과 혁신이 활발한 국가입니다. 인구는 1,000만 명도 되지 않지만, 나스닥 성장 기업 수는 미국과 중국에 이어 세계 3위권입니다. 첨단기술, 글로벌 네트워크, 정부의 강력한 지원 덕분에 세계 스타틑업 허브로 자리매김했습니다. 이번 포스팅에서는 이스라엘 스타트업 생태계의 특징, 정부 지원제",
        "guid": "https://brunch.co.kr/@@LOc/301",
        "isoDate": "2025-07-30T03:00:07.000Z"
      },
      {
        "creator": "고명환",
        "title": "캐나다 스타트업 생태계 완벽 가이드&nbsp; - 창업 지원정책, 투자전략까지",
        "link": "https://brunch.co.kr/@@LOc/300",
        "pubDate": "Tue, 29 Jul 2025 03:00:06 GMT",
        "author": "고명환",
        "content": "글로벌 스타트업 시장에서 개나다는 혁신과 안정성을 동시에 갖춘 나라로 각광받고 있습니다. 특히, AI(인공지능), 핀테크, 클린테크, 헬스케어 등 첨단 기술 분야에서 세계적인 허브 역할을 하고 있으며, 정부 주도의 창업 지원제도와 다문화 사회 기반 덕분에 해외 창업자들에게도 매력적인 시장입니다. 이번 포스팅에서는 캐나다 스타트업 생태계, 지원제도, 주요 도<img src= \"https://img1.daumcdn.net/thumb/R1280x0.fjpg/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FOkC79XCZ21FfksyeDUEUdEEY768.JPG\" width=\"500\" />",
        "contentSnippet": "글로벌 스타트업 시장에서 개나다는 혁신과 안정성을 동시에 갖춘 나라로 각광받고 있습니다. 특히, AI(인공지능), 핀테크, 클린테크, 헬스케어 등 첨단 기술 분야에서 세계적인 허브 역할을 하고 있으며, 정부 주도의 창업 지원제도와 다문화 사회 기반 덕분에 해외 창업자들에게도 매력적인 시장입니다. 이번 포스팅에서는 캐나다 스타트업 생태계, 지원제도, 주요 도",
        "guid": "https://brunch.co.kr/@@LOc/300",
        "isoDate": "2025-07-29T03:00:06.000Z"
      },
      {
        "creator": "고명환",
        "title": "ChatGPT 에이전트 기능 완전 정복! - AI 비서 시대의 시작과 활용법 &amp; 사용방법",
        "link": "https://brunch.co.kr/@@LOc/299",
        "pubDate": "Fri, 25 Jul 2025 02:00:10 GMT",
        "author": "고명환",
        "content": "1. ChatGPT 에이전트 기능이란? 2025년 OpenAI가 공개한 ChatGPT 에어전트 기능은 기존의 대화형 AI를 넘어 목표를 설정하면 스스로 실행하는 AI비서로 진화한 기능입니다. 즉, 사용자가 단순히 질문을 던지는 것이 아니라, &quot;정해둔 목표를 달성하기 위해 AI가 여러 단계를 자동으로 수행&quot;합니다. 이 기능은 업무 자동화, 데이터 분석, 콘텐<img src= \"https://img1.daumcdn.net/thumb/R1280x0.fjpg/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2F3oAP2n9wjOZHvX1lRhb6ytirRAs.JPG\" width=\"500\" />",
        "contentSnippet": "1. ChatGPT 에이전트 기능이란? 2025년 OpenAI가 공개한 ChatGPT 에어전트 기능은 기존의 대화형 AI를 넘어 목표를 설정하면 스스로 실행하는 AI비서로 진화한 기능입니다. 즉, 사용자가 단순히 질문을 던지는 것이 아니라, \"정해둔 목표를 달성하기 위해 AI가 여러 단계를 자동으로 수행\"합니다. 이 기능은 업무 자동화, 데이터 분석, 콘텐",
        "guid": "https://brunch.co.kr/@@LOc/299",
        "isoDate": "2025-07-25T02:00:10.000Z"
      },
      {
        "creator": "고명환",
        "title": "2025년 자율주행 전쟁 - 테슬라 로보택시 VS BYD&nbsp;God&rsquo;s&nbsp;Eye, 누가 앞서가나?",
        "link": "https://brunch.co.kr/@@LOc/298",
        "pubDate": "Thu, 24 Jul 2025 03:00:07 GMT",
        "author": "고명환",
        "content": "자율주행 기술은 2025년 현재 자동차 산업의 판도를 바꾸는 핵심 트렌드입니다. 특히 테슬라(Tesla)와 BYT는 각기 다른 전략과 기술로 글로벌 시장에서 경쟁 중입니다. 오늘은 두 기업의 핵심 기술, 상업화 전략, 안정성, 그리고 미래 전망을 심층 분석해보겠습니다.  1. 테슬라 로보택시 : 완전 자율을 향한 도전 테슬라는 2025년 6월, 텍사스 오스<img src= \"https://img1.daumcdn.net/thumb/R1280x0.fjpg/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2F4vAWVUGKxyhjLbuuwBui0XJfWn4.JPG\" width=\"500\" />",
        "contentSnippet": "자율주행 기술은 2025년 현재 자동차 산업의 판도를 바꾸는 핵심 트렌드입니다. 특히 테슬라(Tesla)와 BYT는 각기 다른 전략과 기술로 글로벌 시장에서 경쟁 중입니다. 오늘은 두 기업의 핵심 기술, 상업화 전략, 안정성, 그리고 미래 전망을 심층 분석해보겠습니다.  1. 테슬라 로보택시 : 완전 자율을 향한 도전 테슬라는 2025년 6월, 텍사스 오스",
        "guid": "https://brunch.co.kr/@@LOc/298",
        "isoDate": "2025-07-24T03:00:07.000Z"
      }
    ]
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "노코드 AI 앱 개발 : Google Opal로 유튜브 요약 및 기사 자동 생성 하기",
        "link": "http://muzbox.tistory.com/483629",
        "pubDate": "Fri, 25 Jul 2025 08:16:03 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483629#entry483629comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 8-00px; margin: 0 auto; font-size: 16px; box-sizing: border-box;\">\n<p data-ke-size=\"size8\">&nbsp;</p>\n<div style=\"background-color: #f5f5f5; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\"><b>AI 미니 앱, 복잡한 코딩 없이 만들 수 있을까?</b> Google Opal로 당신의 아이디어를 현실로!</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"opal1.png\" data-origin-width=\"1136\" data-origin-height=\"703\"><span data-url=\"https://blog.kakaocdn.net/dn/MiJxS/btsPy0I1Lva/86fksqLfWVekasGVsp7VQ0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/MiJxS/btsPy0I1Lva/86fksqLfWVekasGVsp7VQ0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/MiJxS/btsPy0I1Lva/86fksqLfWVekasGVsp7VQ0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FMiJxS%2FbtsPy0I1Lva%2F86fksqLfWVekasGVsp7VQ0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"Google Opal로 유튜브 요약 및 기사 자동 생성 하기\" loading=\"lazy\" width=\"1136\" height=\"703\" data-filename=\"opal1.png\" data-origin-width=\"1136\" data-origin-height=\"703\"/></span></figure>\n\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">&nbsp;혹시 머릿속에 번뜩이는 아이디어가 있는데, 그걸 현실로 만들려면 복잡한 코딩을 해야 한다는 생각에 지레 포기한 적 있으신가요? 제가 딱 그랬어요. 막연하게 '이런 AI 도구가 있으면 정말 좋겠다!' 생각만 했지, 개발은 엄두도 못 냈죠. 그런데 <span style=\"background-color: #fffde7; padding: 2px 4px; border-radius: 3px;\">Google Opal</span>을 만나고 나서는 생각이 싹 바뀌었답니다! 이 글에서는 Google Opal이 대체 뭔지, 그리고 어떻게 우리의 아이디어를 손쉽게 AI 앱으로 바꿔주는지 자세히 알려드릴게요.&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #eaeaea; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>Google Opal, 도대체 뭘까요?&nbsp;</b></h2>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">Google Opal(<a href=\"https://opal.withgoogle.com/\" target=\"_blank\" rel=\"noopener\"><u><span style=\"color: #006dd7;\"><b>opal.withgoogle.com</b></span></u></a>)은 한마디로 <span style=\"background-color: #fffde7; padding: 2px 4px; border-radius: 3px;\">자연어를 사용해서 미니 AI 앱을 만들고, 편집하고, 공유할 수 있는 Google의 실험적인 플랫폼</span>이에요. 코딩을 몰라도 내가 원하는 AI 기능을 직접 만들어 볼 수 있다는 게 정말 매력적이죠. 저는 처음에 &lsquo;이게 정말 가능하다고?&rsquo; 싶었는데, 직접 써보니 생각보다 훨씬 쉽더라고요.</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">보통 AI 앱을 만들려면 파이썬 같은 프로그래밍 언어도 배워야 하고, 데이터도 준비해야 하고&hellip; 머리 아픈 일이 한두 가지가 아니잖아요? 그런데 Opal은 그런 복잡한 과정들을 확 줄여줘요. 그냥 <span style=\"background-color: #fffde7; padding: 2px 4px; border-radius: 3px;\">우리 일상 언어로 명령을 내리면</span>, 그걸 AI가 알아듣고 앱으로 만들어주는 방식이랄까요? 정말 신기하더라고요.</p>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\"><b>  알아두세요!</b><br />Opal은 Google의 실험적인 도구로, AI 기반 애플리케이션을 간단하게 구축하는 데 초점을 맞추고 있어요. 사이트에 접속하면 'Sign in'을 통해 로그인할 수 있답니다.</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #eaeaea; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>어떤 기능들을 지원하나요?&nbsp;</b></h2>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">Opal은 단순한 앱 제작을 넘어 다양한 기능들을 제공해서 사용자가 더 쉽게 AI 앱을 만들고 관리할 수 있도록 돕습니다. 제가 써보니 특히 <span style=\"background-color: #fffde7; padding: 2px 4px; border-radius: 3px;\">시각화 기능</span>이 정말 좋았어요. 앱의 구조를 한눈에 볼 수 있어서 뭔가 머릿속에 그림이 그려진달까요?</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">가장 핵심적인 기능들을 표로 정리해봤어요. 이 기능들 덕분에 코딩 지식이 없는 저도 꽤 근사한 AI 미니 앱을 만들어 볼 수 있었답니다.</p>\n<h3 style=\"font-size: 18px; color: #1a73e8; margin: 20px 0 10px;\" data-ke-size=\"size23\"><b>Google Opal 주요 기능</b></h3>\n<table style=\"width: 100%; border-collapse: collapse; margin: 20px 0;\" data-ke-align=\"alignLeft\">\n<thead>\n<tr>\n<th style=\"padding: 12px; text-align: left; border: 1px solid #ddd; background-color: #f5f5f5; font-weight: bold;\">구분</th>\n<th style=\"padding: 12px; text-align: left; border: 1px solid #ddd; background-color: #f5f5f5; font-weight: bold;\">설명</th>\n<th style=\"padding: 12px; text-align: left; border: 1px solid #ddd; background-color: #f5f5f5; font-weight: bold;\">장점</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">미니 AI 앱 구축</td>\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">자연어 명령으로 앱 생성 및 편집</td>\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">복잡한 코딩 없이 직관적 개발</td>\n</tr>\n<tr style=\"background-color: #f9f9f9;\">\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">편집 및 공유</td>\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">생성된 앱 수정 및 다른 사용자와 공유</td>\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">협업 용이, 아이디어 확장 가능</td>\n</tr>\n<tr>\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">시각화</td>\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">연결된 단계의 그래프 형태로 앱 구조 표현</td>\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">AI 흐름 직관적 이해, 디버깅 용이</td>\n</tr>\n<tr style=\"background-color: #f9f9f9;\">\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">Google Workspace 통합</td>\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">Gmail, Docs 등과 연동하여 자동화</td>\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">업무 생산성 극대화, 반복 작업 감소</td>\n</tr>\n</tbody>\n</table>\n<div style=\"background-color: #ffebee; border-left: 4px solid #f44336; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\"><b>⚠️ 주의하세요!</b><br />Opal은 아직 Google의 실험적인 도구예요. 기능이 계속 추가되고 변경될 수 있으니 최신 정보를 확인하는 게 중요하겠죠?</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #eaeaea; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>n8n이나 Make와는 무엇이 다를까요?&nbsp;</b></h2>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">제가 Opal을 처음 접했을 때 '어? 이거 n8n이나 Make랑 비슷한 거 아니야?' 싶었어요. <span style=\"background-color: #fffde7; padding: 2px 4px; border-radius: 3px;\">시각적인 인터페이스에서 노드(블록)를 연결해서 워크플로우를 만든다는 점</span>에서는 확실히 비슷하더라고요. 여러분도 그렇게 생각하셨죠? 하지만! 목적과 구성 요소에서 결정적인 차이가 있답니다.</p>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">쉽게 말해서, n8n이나 Make는 이미 만들어진 <span style=\"background-color: #fffde7; padding: 2px 4px; border-radius: 3px;\">레고 블록(Gmail, Slack 등)을 설명서대로 연결해서 멋진 디오라마(자동화 흐름)를 만드는 것</span>과 같아요. 각 블록은 이미 기능이 정해져 있죠. 반면에 Google Opal은 <span style=\"background-color: #fffde7; padding: 2px 4px; border-radius: 3px;\">찰흙(AI 모델)을 주무르고, 모양을 다듬고, 색을 칠하는 각 단계를 연결해서 세상에 없던 새로운 피규어(AI 앱)를 만드는 것</span>과 비슷해요. 재료의 특성을 활용해서 완전히 새로운 걸 창조하는 거죠!</p>\n<h3 style=\"font-size: 18px; color: #1a73e8; margin: 20px 0 10px;\" data-ke-size=\"size23\"><b>Opal vs n8n/Make 주요 차이점</b></h3>\n<table style=\"width: 100%; border-collapse: collapse; margin: 20px 0;\" data-ke-align=\"alignLeft\">\n<thead>\n<tr>\n<th style=\"padding: 12px; text-align: left; border: 1px solid #ddd; background-color: #f5f5f5; font-weight: bold;\">구분</th>\n<th style=\"padding: 12px; text-align: left; border: 1px solid #ddd; background-color: #f5f5f5; font-weight: bold;\">Google Opal</th>\n<th style=\"padding: 12px; text-align: left; border: 1px solid #ddd; background-color: #f5f5f5; font-weight: bold;\">n8n / Make</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">핵심 목적</td>\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">자연어 기반 미니 AI 앱 제작</td>\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">기존 앱/서비스 간 프로세스 자동화</td>\n</tr>\n<tr style=\"background-color: #f9f9f9;\">\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">주요 구성 요소</td>\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">AI의 행동을 정의하는 논리 블록</td>\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">특정 앱의 기능(API) 블록</td>\n</tr>\n<tr>\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">결과물</td>\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">독립적인 AI 프로그램 (예: 블로그 글 생성기)</td>\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">자동화된 업무 흐름 (예: 이메일 알림)</td>\n</tr>\n<tr style=\"background-color: #f9f9f9;\">\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">주요 사용자</td>\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">간단한 AI 툴을 만들고 싶은 창작자, 기획자</td>\n<td style=\"padding: 12px; text-align: left; border: 1px solid #ddd;\">반복 업무를 줄이고 싶은 마케터, 비즈니스 운영자</td>\n</tr>\n</tbody>\n</table>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\"><b>  알아두세요!</b><br />결론적으로, '블록을 시각적으로 연결한다'는 방법론은 동일하지만, 그 블록의 내용물이 'AI의 논리'인지 '기존 앱의 기능'인지, 그래서 최종 목표가 '새로운 AI 앱 개발'인지 '기존 업무 자동화'인지가 근본적으로 다르답니다.</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #eaeaea; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>실전 예시: 유튜브 영상을 블로그 기사로 만드는 앱&nbsp;</b></h2>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">Google Opal은 정말 다양한 AI 미니 앱을 만들 수 있는 잠재력을 가지고 있어요. 제가 개인적으로 가장 만들어보고 싶었던 기능 중 하나는 바로 <span style=\"background-color: #fffde7; padding: 2px 4px; border-radius: 3px;\">'유튜브 영상을 블로그 기사로 만드는 앱'</span>이에요. 요즘 유튜브에 정말 좋은 정보들이 많잖아요? 그런데 그걸 블로그 글로 정리하려면 시간도 많이 들고 번거롭더라고요.</p>\n<div style=\"background-color: #f5f5f5; padding: 15px; border-radius: 8px; margin: 20px 0;\">\n<h3 style=\"font-size: 18px; color: #333; margin: 0 0 10px;\" data-ke-size=\"size23\"><b>사례 소개: 유튜브 요약 블로그 포스터 생성 AI</b></h3>\n<ul style=\"margin: 0 0 15px 20px; padding: 0;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px;\"><b>목표:</b> 유튜브 영상 URL을 입력하면, 영상 내용을 요약하고 이를 바탕으로 블로그 기사 초안을 생성해주는 앱</li>\n<li style=\"margin-bottom: 5px;\"><b>주요 기능:</b> 유튜브 영상 스크립트 추출, AI를 통한 핵심 내용 요약, 블로그 형식에 맞는 글 초안 생성 (서론, 본론, 결론 포함), 관련 이미지 프롬프트 제안</li>\n</ul>\n<h3 style=\"font-size: 18px; color: #333; margin: 15px 0 10px;\" data-ke-size=\"size23\"><b>Opal에서의 과정 (예상)</b></h3>\n<p style=\"margin-bottom: 8px;\" data-ke-size=\"size16\">1) <b>시작 블록:</b> '사용자에게 유튜브 영상 URL 입력받기'</p>\n<p style=\"margin-bottom: 8px;\" data-ke-size=\"size16\">2) <b>데이터 처리 블록:</b> '입력된 URL에서 영상 스크립트 추출 및 텍스트 변환'</p>\n<p style=\"margin-bottom: 8px;\" data-ke-size=\"size16\">3) <b>AI 분석 블록:</b> '추출된 스크립트에서 핵심 내용, 주요 키워드, 주제 파악 후 텍스트 요약'</p>\n<p style=\"margin-bottom: 8px;\" data-ke-size=\"size16\">4) <b>생성 블록:</b> '요약된 내용을 바탕으로 블로그 기사 초안 생성 (HTML 형식 포함)'</p>\n<p style=\"margin-bottom: 0;\" data-ke-size=\"size16\">5) <b>출력 블록:</b> '생성된 블로그 기사 초안과 대표 이미지 생성 프롬프트 제공'</p>\n</div>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"kakaotv\" data-video-url=\"https://tv.kakao.com/v/456795906\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/PFivs/hyZnhPjxKJ/KpyyBu1E0VQurS3DlYQBF1/img.jpg?width=1908&amp;height=926&amp;face=0_0_1908_926,https://scrap.kakaocdn.net/dn/rSHUl/hyZnljS5AQ/m61LKdq5X3um0iNRcQ76w1/img.jpg?width=1908&amp;height=926&amp;face=0_0_1908_926\" data-video-width=\"860\" data-video-height=\"417\" data-video-origin-width=\"860\" data-video-origin-height=\"417\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"'어떤오후의 프리웨어 이야기 (유용한 IT정보)'에서 업로드한 동영상\" data-video-play-service=\"daum_tistory\" data-original-url=\"\"><iframe src=\"https://play-tv.kakao.com/embed/player/cliplink/456795906?service=daum_tistory\" width=\"860\" height=\"417\" frameborder=\"0\" allowfullscreen=\"true\"></iframe>\n<figcaption>opal로 유튜브 영상을 블로그 기사로 만드는 앱&nbsp; 만들기</figcaption>\n</figure>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">&nbsp;이런 앱이 있다면 정말 편리하겠죠? Opal은 이렇게 <span style=\"background-color: #fffde7; padding: 2px 4px; border-radius: 3px;\">복잡해 보이는 작업도 단계별로 쪼개어 AI의 도움을 받아 쉽게 자동화</span>할 수 있도록 도와줘요. 유튜브 크리에이터나 블로거들에게 정말 혁신적인 도구가 될 수 있을 것 같아요!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #eaeaea; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>마무리: 핵심 내용 요약&nbsp;</b></h2>\n<p style=\"margin-bottom: 15px;\" data-ke-size=\"size16\">오늘은 Google의 실험적인 프로젝트, Opal에 대해 알아봤는데요. 어떠셨나요? 복잡한 코딩 없이도 자연어만으로 나만의 AI 미니 앱을 만들 수 있다는 점이 정말 흥미롭지 않나요?</p>\n<div style=\"border-top: 1px dashed #ddd; margin: 30px 0;\">&nbsp;</div>\n<style>\n        .single-summary-card-container {\n            font-family: 'Noto Sans KR', sans-serif;\n            display: flex;\n            justify-content: center;\n            align-items: center;\n            padding: 20px 10px;\n            background-color: #f0f2f5;\n            margin: 20px 0;\n        }\n        .single-summary-card {\n            width: 100%;\n            max-width: 700px;\n            background-color: #ffffff;\n            border-radius: 12px;\n            box-shadow: 0 6px 18px rgba(0,0,0,0.12);\n            padding: 25px;\n            display: flex;\n            flex-direction: column;\n            overflow: hidden;\n            border: 1px solid #e0e0e0;\n            box-sizing: border-box;\n            height: auto;\n            min-height: unset;\n        }\n        .single-summary-card .card-header {\n            display: flex;\n            align-items: center;\n            border-bottom: 2px solid #1a73e8;\n            padding-bottom: 12px;\n            margin-bottom: 12px;\n        }\n        .single-summary-card .card-header-icon {\n            font-size: 34px;\n            color: #1a73e8;\n            margin-right: 14px;\n        }\n        .single-summary-card .card-header h3 {\n            font-size: 26px;\n            color: #1a73e8;\n            margin: 0;\n            line-height: 1.3;\n            font-weight: 700;\n        }\n        .single-summary-card .card-content {\n            flex-grow: 1;\n            display: flex;\n            flex-direction: column;\n            justify-content: space-around;\n            font-size: 17px;\n            line-height: 1.65;\n            color: #333;\n        }\n        .single-summary-card .card-content .section {\n            margin-bottom: 10px;\n        }\n        .single-summary-card .card-content strong {\n            color: #005cb2;\n            font-weight: 600;\n        }\n        .single-summary-card .card-content .highlight {\n            background-color: #fffde7;\n            padding: 2px 4px;\n            border-radius: 3px;\n            font-weight: bold;\n        }\n        .single-summary-card .card-content .formula {\n            background-color: #e8f4fd;\n            padding: 6px 10px;\n            border-radius: 4px;\n            font-size: 0.9em;\n            text-align: center;\n            margin-top: 5px;\n            color: #155724;\n        }\n        .single-summary-card .card-footer {\n            font-size: 14px;\n            color: #777;\n            text-align: center;\n            padding-top: 12px;\n            border-top: 1px dashed #ddd;\n            margin-top: auto;\n        }\n\n        /* 모바일 맞춤 조정 */\n        @media (max-width: 768px) {\n            .single-summary-card {\n                padding: 18px;\n                height: auto;\n                min-height: unset;\n            }\n            .single-summary-card .card-header-icon {\n                font-size: 28px;\n                margin-right: 10px;\n            }\n            .single-summary-card .card-header h3 {\n                font-size: 20px;\n            }\n            .single-summary-card .card-content {\n                font-size: 15px;\n                line-height: 1.5;\n            }\n            .single-summary-card .card-content .section {\n                margin-bottom: 8px;\n            }\n            .single-summary-card .card-content .formula {\n                padding: 5px 8px;\n                font-size: 0.85em;\n            }\n            .single-summary-card .card-footer {\n                font-size: 13px;\n                padding-top: 10px;\n            }\n        }\n\n        @media (max-width: 480px) {\n            .single-summary-card {\n                padding: 15px;\n            }\n            .single-summary-card .card-header-icon {\n                font-size: 26px;\n            }\n            .single-summary-card .card-header h3 {\n                font-size: 18px;\n            }\n            .single-summary-card .card-content {\n                font-size: 14px;\n                line-height: 1.4;\n            }\n            .single-summary-card .card-content .section {\n                margin-bottom: 6px;\n            }\n            .single-summary-card .card-content .formula {\n                padding: 4px 6px;\n                font-size: 0.8em;\n            }\n            .single-summary-card .card-footer {\n                font-size: 12px;\n                padding-top: 8px;\n            }\n        }\n    </style>\n<div class=\"single-summary-card-container\">\n<div class=\"single-summary-card\">\n<div class=\"card-header\"><span class=\"card-header-icon\"> </span>\n<h3 data-ke-size=\"size23\">Google Opal 핵심 요약</h3>\n</div>\n<div class=\"card-content\">\n<div class=\"section\"><b>✨ AI 앱의 민주화:</b> <span class=\"highlight\">복잡한 코딩 없이 자연어로 AI 미니 앱을 만들 수 있어요!</span> 아이디어를 빠르게 현실로.</div>\n<div class=\"section\"><b>  직관적인 시각화:</b> <span class=\"highlight\">단계별 그래프로 AI 앱의 흐름을 한눈에!</span> 개발 과정이 훨씬 쉬워져요.</div>\n<div class=\"section\"><b>  자동화와 차별점:</b> 기존 자동화 툴과 달리 <span class=\"highlight\">새로운 AI 앱을 '창조'하는 데 집중!</span> 단순 연결을 넘어섭니다.</div>\n<div class=\"section\"><b>  Google Workspace 통합:</b> <span class=\"highlight\">Gmail, Docs 등과 연동하여 업무 효율 극대화!</span> 반복 작업은 이제 그만.</div>\n</div>\n<div class=\"card-footer\">궁금한 점이 있다면 언제든지 댓글로 물어봐 주세요! 함께 AI 시대를 만들어가요!  </div>\n</div>\n</div>\n<h2 style=\"font-size: 22px; color: #1a73e8; margin: 30px 0 15px; padding-bottom: 8px; border-bottom: 2px solid #eaeaea;\" data-ke-size=\"size26\"><b>자주 묻는 질문 ❓</b></h2>\n<div style=\"margin: 30px 0;\">\n<div style=\"margin-bottom: 20px;\">\n<div style=\"font-weight: bold; margin-bottom: 5px;\">Q: Google Opal은 유료 서비스인가요?</div>\n<div style=\"padding-left: 15px;\">A: 현재 opal.withgoogle.com은 Google의 실험적인 프로젝트로, 별도의 요금 정보는 제공되고 있지 않습니다. Google 계정으로 로그인하여 사용 가능합니다.</div>\n</div>\n<div style=\"margin-bottom: 20px;\">\n<div style=\"font-weight: bold; margin-bottom: 5px;\">Q: 코딩 지식이 전혀 없어도 사용할 수 있나요?</div>\n<div style=\"padding-left: 15px;\">A: 네, Opal은 자연어 기반으로 AI 앱을 구축할 수 있도록 설계되어 있어 코딩 지식이 없어도 충분히 사용 가능합니다.</div>\n</div>\n<div style=\"margin-bottom: 20px;\">\n<div style=\"font-weight: bold; margin-bottom: 5px;\">Q: 만든 AI 앱을 상업적으로 활용할 수 있나요?</div>\n<div style=\"padding-left: 15px;\">A: Opal은 실험적인 도구이므로, 상업적 활용에 대한 정책은 Google의 공식 발표를 확인하는 것이 중요합니다.</div>\n</div>\n<div style=\"margin-bottom: 20px;\">\n<div style=\"font-weight: bold; margin-bottom: 5px;\">Q: Google Workspace와의 통합은 어떤 장점이 있나요?</div>\n<div style=\"padding-left: 15px;\">A: Gmail, Docs, Sheets 등 Google Workspace 앱과 연동하여 AI 기반의 워크플로를 자동화하고, 접근 관리 및 보안을 강화하며, 협업 효율성을 높여줍니다.</div>\n</div>\n<div style=\"margin-bottom: 20px;\">\n<div style=\"font-weight: bold; margin-bottom: 5px;\">Q: Opal과 n8n/Make의 가장 큰 차이점은 무엇인가요?</div>\n<div style=\"padding-left: 15px;\">A: Opal은 '새로운 AI 앱 자체를 만드는 것'에 중점을 둔 반면, n8n/Make는 '기존 앱/서비스 간의 프로세스를 자동화하는 것'에 중점을 둡니다.</div>\n</div>\n</div>\n<script type=\"application/ld+json\">\n    {\n        \"@context\": \"https://schema.org\",\n        \"@type\": \"FAQPage\",\n        \"mainEntity\": [\n            {\n                \"@type\": \"Question\",\n                \"name\": \"Google Opal은 유료 서비스인가요?\",\n                \"acceptedAnswer\": {\n                    \"@type\": \"Answer\",\n                    \"text\": \"  현재 opal.withgoogle.com은 Google의 실험적인 프로젝트로, 별도의 요금 정보는 제공되고 있지 않습니다. Google 계정으로 로그인하여 사용 가능합니다.\"\n                }\n            },\n            {\n                \"@type\": \"Question\",\n                \"name\": \"코딩 지식이 전혀 없어도 사용할 수 있나요?\",\n                \"acceptedAnswer\": {\n                    \"@type\": \"Answer\",\n                    \"text\": \"  네, Opal은 자연어 기반으로 AI 앱을 구축할 수 있도록 설계되어 있어 코딩 지식이 없어도 충분히 사용 가능합니다.\"\n                }\n            },\n            {\n                \"@type\": \"Question\",\n                \"name\": \"만든 AI 앱을 상업적으로 활용할 수 있나요?\",\n                \"acceptedAnswer\": {\n                    \"@type\": \"Answer\",\n                    \"text\": \"  Opal은 실험적인 도구이므로, 상업적 활용에 대한 정책은 Google의 공식 발표를 확인하는 것이 중요합니다.\"\n                }\n            },\n            {\n                \"@type\": \"Question\",\n                \"name\": \"Google Workspace와의 통합은 어떤 장점이 있나요?\",\n                \"acceptedAnswer\": {\n                    \"@type\": \"Answer\",\n                    \"text\": \"  Gmail, Docs, Sheets 등 Google Workspace 앱과 연동하여 AI 기반의 워크플로를 자동화하고, 접근 관리 및 보안을 강화하며, 협업 효율성을 높여줍니다.\"\n                }\n            },\n            {\n                \"@type\": \"Question\",\n                \"name\": \"Opal과 n8n/Make의 가장 큰 차이점은 무엇인가요?\",\n                \"acceptedAnswer\": {\n                    \"@type\": \"Answer\",\n                    \"text\": \"  Opal은 '새로운 AI 앱 자체를 만드는 것'에 중점을 둔 반면, n8n/Make는 '기존 앱/서비스 간의 프로세스를 자동화하는 것'에 중점을 둡니다.\"\n                }\n            }\n        ]\n    }\n    </script>\n</div>",
        "contentSnippet": "AI 미니 앱, 복잡한 코딩 없이 만들 수 있을까? Google Opal로 당신의 아이디어를 현실로!\n\n\n \n 혹시 머릿속에 번뜩이는 아이디어가 있는데, 그걸 현실로 만들려면 복잡한 코딩을 해야 한다는 생각에 지레 포기한 적 있으신가요? 제가 딱 그랬어요. 막연하게 '이런 AI 도구가 있으면 정말 좋겠다!' 생각만 했지, 개발은 엄두도 못 냈죠. 그런데 Google Opal을 만나고 나서는 생각이 싹 바뀌었답니다! 이 글에서는 Google Opal이 대체 뭔지, 그리고 어떻게 우리의 아이디어를 손쉽게 AI 앱으로 바꿔주는지 자세히 알려드릴게요. \n \nGoogle Opal, 도대체 뭘까요? \nGoogle Opal(opal.withgoogle.com)은 한마디로 자연어를 사용해서 미니 AI 앱을 만들고, 편집하고, 공유할 수 있는 Google의 실험적인 플랫폼이에요. 코딩을 몰라도 내가 원하는 AI 기능을 직접 만들어 볼 수 있다는 게 정말 매력적이죠. 저는 처음에 ‘이게 정말 가능하다고?’ 싶었는데, 직접 써보니 생각보다 훨씬 쉽더라고요.\n \n보통 AI 앱을 만들려면 파이썬 같은 프로그래밍 언어도 배워야 하고, 데이터도 준비해야 하고… 머리 아픈 일이 한두 가지가 아니잖아요? 그런데 Opal은 그런 복잡한 과정들을 확 줄여줘요. 그냥 우리 일상 언어로 명령을 내리면, 그걸 AI가 알아듣고 앱으로 만들어주는 방식이랄까요? 정말 신기하더라고요.\n  알아두세요!\nOpal은 Google의 실험적인 도구로, AI 기반 애플리케이션을 간단하게 구축하는 데 초점을 맞추고 있어요. 사이트에 접속하면 'Sign in'을 통해 로그인할 수 있답니다.\n \n어떤 기능들을 지원하나요? \nOpal은 단순한 앱 제작을 넘어 다양한 기능들을 제공해서 사용자가 더 쉽게 AI 앱을 만들고 관리할 수 있도록 돕습니다. 제가 써보니 특히 시각화 기능이 정말 좋았어요. 앱의 구조를 한눈에 볼 수 있어서 뭔가 머릿속에 그림이 그려진달까요?\n가장 핵심적인 기능들을 표로 정리해봤어요. 이 기능들 덕분에 코딩 지식이 없는 저도 꽤 근사한 AI 미니 앱을 만들어 볼 수 있었답니다.\nGoogle Opal 주요 기능\n구분\n설명\n장점\n\n\n\n\n미니 AI 앱 구축\n자연어 명령으로 앱 생성 및 편집\n복잡한 코딩 없이 직관적 개발\n\n\n편집 및 공유\n생성된 앱 수정 및 다른 사용자와 공유\n협업 용이, 아이디어 확장 가능\n\n\n시각화\n연결된 단계의 그래프 형태로 앱 구조 표현\nAI 흐름 직관적 이해, 디버깅 용이\n\n\nGoogle Workspace 통합\nGmail, Docs 등과 연동하여 자동화\n업무 생산성 극대화, 반복 작업 감소\n\n\n\n⚠️ 주의하세요!\nOpal은 아직 Google의 실험적인 도구예요. 기능이 계속 추가되고 변경될 수 있으니 최신 정보를 확인하는 게 중요하겠죠?\n \nn8n이나 Make와는 무엇이 다를까요? \n제가 Opal을 처음 접했을 때 '어? 이거 n8n이나 Make랑 비슷한 거 아니야?' 싶었어요. 시각적인 인터페이스에서 노드(블록)를 연결해서 워크플로우를 만든다는 점에서는 확실히 비슷하더라고요. 여러분도 그렇게 생각하셨죠? 하지만! 목적과 구성 요소에서 결정적인 차이가 있답니다.\n쉽게 말해서, n8n이나 Make는 이미 만들어진 레고 블록(Gmail, Slack 등)을 설명서대로 연결해서 멋진 디오라마(자동화 흐름)를 만드는 것과 같아요. 각 블록은 이미 기능이 정해져 있죠. 반면에 Google Opal은 찰흙(AI 모델)을 주무르고, 모양을 다듬고, 색을 칠하는 각 단계를 연결해서 세상에 없던 새로운 피규어(AI 앱)를 만드는 것과 비슷해요. 재료의 특성을 활용해서 완전히 새로운 걸 창조하는 거죠!\nOpal vs n8n/Make 주요 차이점\n구분\nGoogle Opal\nn8n / Make\n\n\n\n\n핵심 목적\n자연어 기반 미니 AI 앱 제작\n기존 앱/서비스 간 프로세스 자동화\n\n\n주요 구성 요소\nAI의 행동을 정의하는 논리 블록\n특정 앱의 기능(API) 블록\n\n\n결과물\n독립적인 AI 프로그램 (예: 블로그 글 생성기)\n자동화된 업무 흐름 (예: 이메일 알림)\n\n\n주요 사용자\n간단한 AI 툴을 만들고 싶은 창작자, 기획자\n반복 업무를 줄이고 싶은 마케터, 비즈니스 운영자\n\n\n\n  알아두세요!\n결론적으로, '블록을 시각적으로 연결한다'는 방법론은 동일하지만, 그 블록의 내용물이 'AI의 논리'인지 '기존 앱의 기능'인지, 그래서 최종 목표가 '새로운 AI 앱 개발'인지 '기존 업무 자동화'인지가 근본적으로 다르답니다.\n \n실전 예시: 유튜브 영상을 블로그 기사로 만드는 앱 \nGoogle Opal은 정말 다양한 AI 미니 앱을 만들 수 있는 잠재력을 가지고 있어요. 제가 개인적으로 가장 만들어보고 싶었던 기능 중 하나는 바로 '유튜브 영상을 블로그 기사로 만드는 앱'이에요. 요즘 유튜브에 정말 좋은 정보들이 많잖아요? 그런데 그걸 블로그 글로 정리하려면 시간도 많이 들고 번거롭더라고요.\n사례 소개: 유튜브 요약 블로그 포스터 생성 AI\n목표: 유튜브 영상 URL을 입력하면, 영상 내용을 요약하고 이를 바탕으로 블로그 기사 초안을 생성해주는 앱\n주요 기능: 유튜브 영상 스크립트 추출, AI를 통한 핵심 내용 요약, 블로그 형식에 맞는 글 초안 생성 (서론, 본론, 결론 포함), 관련 이미지 프롬프트 제안\nOpal에서의 과정 (예상)\n1) 시작 블록: '사용자에게 유튜브 영상 URL 입력받기'\n2) 데이터 처리 블록: '입력된 URL에서 영상 스크립트 추출 및 텍스트 변환'\n3) AI 분석 블록: '추출된 스크립트에서 핵심 내용, 주요 키워드, 주제 파악 후 텍스트 요약'\n4) 생성 블록: '요약된 내용을 바탕으로 블로그 기사 초안 생성 (HTML 형식 포함)'\n5) 출력 블록: '생성된 블로그 기사 초안과 대표 이미지 생성 프롬프트 제공'\n\nopal로 유튜브 영상을 블로그 기사로 만드는 앱  만들기\n\n 이런 앱이 있다면 정말 편리하겠죠? Opal은 이렇게 복잡해 보이는 작업도 단계별로 쪼개어 AI의 도움을 받아 쉽게 자동화할 수 있도록 도와줘요. 유튜브 크리에이터나 블로거들에게 정말 혁신적인 도구가 될 수 있을 것 같아요!\n \n마무리: 핵심 내용 요약 \n오늘은 Google의 실험적인 프로젝트, Opal에 대해 알아봤는데요. 어떠셨나요? 복잡한 코딩 없이도 자연어만으로 나만의 AI 미니 앱을 만들 수 있다는 점이 정말 흥미롭지 않나요?\n \n \nGoogle Opal 핵심 요약\n✨ AI 앱의 민주화: 복잡한 코딩 없이 자연어로 AI 미니 앱을 만들 수 있어요! 아이디어를 빠르게 현실로.\n  직관적인 시각화: 단계별 그래프로 AI 앱의 흐름을 한눈에! 개발 과정이 훨씬 쉬워져요.\n  자동화와 차별점: 기존 자동화 툴과 달리 새로운 AI 앱을 '창조'하는 데 집중! 단순 연결을 넘어섭니다.\n  Google Workspace 통합: Gmail, Docs 등과 연동하여 업무 효율 극대화! 반복 작업은 이제 그만.\n궁금한 점이 있다면 언제든지 댓글로 물어봐 주세요! 함께 AI 시대를 만들어가요!  \n자주 묻는 질문 ❓\nQ: Google Opal은 유료 서비스인가요?\nA: 현재 opal.withgoogle.com은 Google의 실험적인 프로젝트로, 별도의 요금 정보는 제공되고 있지 않습니다. Google 계정으로 로그인하여 사용 가능합니다.\nQ: 코딩 지식이 전혀 없어도 사용할 수 있나요?\nA: 네, Opal은 자연어 기반으로 AI 앱을 구축할 수 있도록 설계되어 있어 코딩 지식이 없어도 충분히 사용 가능합니다.\nQ: 만든 AI 앱을 상업적으로 활용할 수 있나요?\nA: Opal은 실험적인 도구이므로, 상업적 활용에 대한 정책은 Google의 공식 발표를 확인하는 것이 중요합니다.\nQ: Google Workspace와의 통합은 어떤 장점이 있나요?\nA: Gmail, Docs, Sheets 등 Google Workspace 앱과 연동하여 AI 기반의 워크플로를 자동화하고, 접근 관리 및 보안을 강화하며, 협업 효율성을 높여줍니다.\nQ: Opal과 n8n/Make의 가장 큰 차이점은 무엇인가요?\nA: Opal은 '새로운 AI 앱 자체를 만드는 것'에 중점을 둔 반면, n8n/Make는 '기존 앱/서비스 간의 프로세스를 자동화하는 것'에 중점을 둡니다.\n\n\n\n    {\n        \"@context\": \"https://schema.org\",\n        \"@type\": \"FAQPage\",\n        \"mainEntity\": [\n            {\n                \"@type\": \"Question\",\n                \"name\": \"Google Opal은 유료 서비스인가요?\",\n                \"acceptedAnswer\": {\n                    \"@type\": \"Answer\",\n                    \"text\": \"  현재 opal.withgoogle.com은 Google의 실험적인 프로젝트로, 별도의 요금 정보는 제공되고 있지 않습니다. Google 계정으로 로그인하여 사용 가능합니다.\"\n                }\n            },\n            {\n                \"@type\": \"Question\",\n                \"name\": \"코딩 지식이 전혀 없어도 사용할 수 있나요?\",\n                \"acceptedAnswer\": {\n                    \"@type\": \"Answer\",\n                    \"text\": \"  네, Opal은 자연어 기반으로 AI 앱을 구축할 수 있도록 설계되어 있어 코딩 지식이 없어도 충분히 사용 가능합니다.\"\n                }\n            },\n            {\n                \"@type\": \"Question\",\n                \"name\": \"만든 AI 앱을 상업적으로 활용할 수 있나요?\",\n                \"acceptedAnswer\": {\n                    \"@type\": \"Answer\",\n                    \"text\": \"  Opal은 실험적인 도구이므로, 상업적 활용에 대한 정책은 Google의 공식 발표를 확인하는 것이 중요합니다.\"\n                }\n            },\n            {\n                \"@type\": \"Question\",\n                \"name\": \"Google Workspace와의 통합은 어떤 장점이 있나요?\",\n                \"acceptedAnswer\": {\n                    \"@type\": \"Answer\",\n                    \"text\": \"  Gmail, Docs, Sheets 등 Google Workspace 앱과 연동하여 AI 기반의 워크플로를 자동화하고, 접근 관리 및 보안을 강화하며, 협업 효율성을 높여줍니다.\"\n                }\n            },\n            {\n                \"@type\": \"Question\",\n                \"name\": \"Opal과 n8n/Make의 가장 큰 차이점은 무엇인가요?\",\n                \"acceptedAnswer\": {\n                    \"@type\": \"Answer\",\n                    \"text\": \"  Opal은 '새로운 AI 앱 자체를 만드는 것'에 중점을 둔 반면, n8n/Make는 '기존 앱/서비스 간의 프로세스를 자동화하는 것'에 중점을 둡니다.\"\n                }\n            }\n        ]\n    }",
        "guid": "http://muzbox.tistory.com/483629",
        "categories": [
          "AI, 미래기술/AI 인사이트",
          "AI 미니 앱",
          "ai 앱 개발",
          "Google Opal",
          "Google Workspace 통합",
          "노코드 ai",
          "블로그 기사 생성",
          "생산성 향상",
          "업무 자동화",
          "유튜브 요약",
          "자연어 처리"
        ],
        "isoDate": "2025-07-24T23:16:03.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "｜RULIWEB｜",
        "title": "악역영애 4컷 만화는 한 주 쉬어갑니다.",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2339",
        "pubDate": "Wed, 30 Jul 2025 13:13:05 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/25/07/30/198595d633551ad6b.png\">",
        "contentSnippet": "",
        "categories": [
          "웹툰"
        ],
        "isoDate": "2025-07-30T04:13:05.000Z"
      },
      {
        "creator": "(RULIWEB`Д')/",
        "title": "[MULTI] 싱글·멀티 다 잡은 쌍수호박 무협 오픈월드, 연운",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2338",
        "pubDate": "Wed, 30 Jul 2025 12:04:16 +0900",
        "author": "(RULIWEB`Д')/",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/25/07/30/19859472cf44c329e.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2025-07-30T03:04:16.000Z"
      },
      {
        "creator": "｜RULIWEB｜",
        "title": "나는 이 아이를 본적이 있어요!! - 프린세스 메이커: 예언의 아이들",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2337",
        "pubDate": "Tue, 29 Jul 2025 19:42:05 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i1.ruliweb.com/thumb/25/07/29/19855c41c4651ad6b.png\">",
        "contentSnippet": "",
        "categories": [
          "게임툰"
        ],
        "isoDate": "2025-07-29T10:42:05.000Z"
      },
      {
        "creator": "［RULIWEB］",
        "title": "밀도 있는 공방과 강렬한 액션이 가져오는 손맛, 팬텀 블레이드 제로",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2336",
        "pubDate": "Sat, 26 Jul 2025 23:00:18 +0900",
        "author": "［RULIWEB］",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/25/07/26/1984700e9a75104c1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "프리뷰"
        ],
        "isoDate": "2025-07-26T14:00:18.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": [
      {
        "title": "C++ - char* 및 std::string의 액세스 속도와 최적화 영향",
        "link": "https://jacking75.github.io/Cpp_20250730/",
        "pubDate": "Wed, 30 Jul 2025 00:00:00 +0900",
        "content": "<iframe width=\"1024\" height=\"1024\" src=\"https://docs.google.com/document/d/e/2PACX-1vQvoo2ASPfeK_o46a8iSyF0L-3CwrlckwRY9m0QGbi35QbNapFBalZNlLgTiMYOp6fzIY6dJk9gGsJN/pub?embedded=true\"></iframe>\n\n",
        "contentSnippet": "",
        "guid": "https://jacking75.github.io/Cpp_20250730/",
        "isoDate": "2025-07-29T15:00:00.000Z"
      },
      {
        "title": "AI와 같이 만드는 프로그래밍 책",
        "link": "https://jacking75.github.io/programming_20250727/",
        "pubDate": "Sun, 27 Jul 2025 00:00:00 +0900",
        "content": "<p>올해는 의도적으로 프로그래밍에 AI를 활용하려고 여러가지 해보고 있습니다.<br />\nAI와 같이 새로운 기술을 학습하고, 코드를 분석하고, 코딩을 하고, 책을 만들고 있습니다.</p>\n\n<p>특히 책의 경우 내가 다 적으려면 많은 시간이 걸려서 언제나 생각만 하지 실제로는 못하는 경우가 자주 있었는데 AI에게 어떤 책을 만들어야 할지 요구하고, AI가 만든 내용을 내가 편집자 입자에서 편집하고, 또 공동 저자 입장에서 필요한 글을 쓰면서 예전 보다 아주 수월하게 책을 만들고 있습니다.<br />\n물론 아직은 AI가 완벽하지 않아서 사람이 개입해서 조정(편집 등)을 해야하기 때문에 완전 공짜로 되는 것은 아닙니다. 그리고 기술적 지식이 있어야 AI에게 요구하고, 내용을 확인하고 편집해야 합니다.</p>\n\n<p>여러 책을 가 집필은 했지만 공개하려면 이것저것 손을 봐야해서 현재는 아래 두권만 만들었습니다.</p>\n<ul>\n  <li>게임 서버 개발자가 알아야할 네트워크 이론</li>\n  <li>게임 서버 개발자 알아야할 TCP/IP Windows 소켓_프로그래밍</li>\n</ul>\n\n<p><a href=\"https://github.com/jacking75/programming-books-with-ai\">AI 와 같이 만든 프로그래밍 책</a> 에 있습니다.</p>\n\n<p>그리고 이전부터 가능하면 주말에 유튜브 영상(빠르고 쉽게 만들기 위해 무편집으로)을 올리고 있습니다. 목표는 매주 1개씩 만드는 것이지만 그렇게는 잘 안되더군요^^;<br />\n<a href=\"https://www.youtube.com/channel/UCBi0jCTCZUJMWGQrrvVmVRQ\">YOYTUBE</a></p>\n\n<p>책을 쓰고 싶지만 하기 어려운분들은 AI와 같이 해보시기 바랍니다^^</p>\n",
        "contentSnippet": "올해는 의도적으로 프로그래밍에 AI를 활용하려고 여러가지 해보고 있습니다.\n특히 책의 경우 내가 다 적으려면 많은 시간이 걸려서 언제나 생각만 하지 실제로는 못하는 경우가 자주 있었는데 AI에게 어떤 책을 만들어야 할지 요구하고, AI가 만든 내용을 내가 편집자 입자에서 편집하고, 또 공동 저자 입장에서 필요한 글을 쓰면서 예전 보다 아주 수월하게 책을 만들고 있습니다.\n여러 책을 가 집필은 했지만 공개하려면 이것저것 손을 봐야해서 현재는 아래 두권만 만들었습니다.\n게임 서버 개발자가 알아야할 네트워크 이론\n게임 서버 개발자 알아야할 TCP/IP Windows 소켓_프로그래밍\nAI 와 같이 만든 프로그래밍 책 에 있습니다.\n그리고 이전부터 가능하면 주말에 유튜브 영상(빠르고 쉽게 만들기 위해 무편집으로)을 올리고 있습니다. 목표는 매주 1개씩 만드는 것이지만 그렇게는 잘 안되더군요^^;\nYOYTUBE\n책을 쓰고 싶지만 하기 어려운분들은 AI와 같이 해보시기 바랍니다^^",
        "guid": "https://jacking75.github.io/programming_20250727/",
        "isoDate": "2025-07-26T15:00:00.000Z"
      }
    ]
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "삼성 테슬라 수주의 이미와 관련 종목들",
        "link": "http://serverdown.tistory.com/1367",
        "pubDate": "Tue, 29 Jul 2025 20:53:30 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1367#entry1367comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"351\" data-origin-height=\"144\"><span data-url=\"https://blog.kakaocdn.net/dn/dLjFi5/btsPBjDpBsB/rWLz2rZABzIbsKYUtuHWl0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dLjFi5/btsPBjDpBsB/rWLz2rZABzIbsKYUtuHWl0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dLjFi5/btsPBjDpBsB/rWLz2rZABzIbsKYUtuHWl0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdLjFi5%2FbtsPBjDpBsB%2FrWLz2rZABzIbsKYUtuHWl0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"351\" height=\"144\" data-origin-width=\"351\" data-origin-height=\"144\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=TFrBvpRJmjE\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=TFrBvpRJmjE</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=TFrBvpRJmjE\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/ciLwXQ/hyZqUFH5jo/fspKrxvIEkCKkDVJQTZvi0/img.jpg?width=1280&amp;height=720&amp;face=80_128_1082_512,https://scrap.kakaocdn.net/dn/SSiWu/hyZqQJ3jVY/VMc0pkiVP4soJi0bOiMTsK/img.jpg?width=1280&amp;height=720&amp;face=80_128_1082_512\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"삼성파운드리 진짜 수혜주는 이 종목입니다. !!!\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/TFrBvpRJmjE\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">개인적으로 초보는 관련주 투자 하지마세요<br />위아래로 왔다갔다 장난아니라 내리면 팔고 오르면 사고를 반복할 수 있습니다.<br />그냥 이렇게 돌아가는구나 정도로 소액으로 여러회사를 분할 매수 해보시길 추천드립니다.</p>\n<p data-ke-size=\"size16\">사고팔고의 기술을 배워볼 좋은 시기입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이번 수주는 27년 양상을 목표로 받은 것입니다.</p>\n<p data-ke-size=\"size16\">옵티머스 (로봇) 용 반도체 인거 같습니다.</p>\n<p data-ke-size=\"size16\">이걸 시작으로 더많은 수주가 이어질 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">단순 목표는 삼성전자를 양산 시점 까지 잘 가지고 가자 입니다.</p>\n<p data-ke-size=\"size16\">내리면 더사고 오르면 약간 팔고를 반복하면 될것 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=TFrBvpRJmjE\n\n\n\n \n \n개인적으로 초보는 관련주 투자 하지마세요\n위아래로 왔다갔다 장난아니라 내리면 팔고 오르면 사고를 반복할 수 있습니다.\n그냥 이렇게 돌아가는구나 정도로 소액으로 여러회사를 분할 매수 해보시길 추천드립니다.\n사고팔고의 기술을 배워볼 좋은 시기입니다.\n \n이번 수주는 27년 양상을 목표로 받은 것입니다.\n옵티머스 (로봇) 용 반도체 인거 같습니다.\n이걸 시작으로 더많은 수주가 이어질 것입니다.\n \n단순 목표는 삼성전자를 양산 시점 까지 잘 가지고 가자 입니다.\n내리면 더사고 오르면 약간 팔고를 반복하면 될것 같습니다.",
        "guid": "http://serverdown.tistory.com/1367",
        "categories": [
          "투자",
          "삼성전자"
        ],
        "isoDate": "2025-07-29T11:53:30.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "코믹스의 검열과 판타스틱4",
        "link": "http://serverdown.tistory.com/1366",
        "pubDate": "Mon, 28 Jul 2025 11:27:54 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1366#entry1366comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=tIQ6mexXIp4&amp;t=162s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=tIQ6mexXIp4&amp;t=162s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=tIQ6mexXIp4\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bMcNd2/hyZqUSSAOB/JamgXUhQ1cWuIb7KC9JBW1/img.jpg?width=1280&amp;height=720&amp;face=286_90_1058_364,https://scrap.kakaocdn.net/dn/PmUAo/hyZqQXeSGb/knZwLkIvv5MLz8dvWbrL20/img.jpg?width=1280&amp;height=720&amp;face=286_90_1058_364\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"《판타스틱 4》보기전 세계관 총정리! 판4 멤버+빌런들의 탄생과 과거, 원작 코믹스 제작 배경까\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/tIQ6mexXIp4\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">코믹스의 역사에 대해 이야기 해주는 영상입니다.</p>\n<p data-ke-size=\"size16\">2차세계대전까지는 나치 때려잡는 만화는 폭력적이더라도 문제가 되지 않았는데</p>\n<p data-ke-size=\"size16\">1950년대가 되자 그럴 수 없었나봅니다.</p>\n<p data-ke-size=\"size16\">아이들에게 영향을 준다는 이유로&nbsp;&nbsp;검열하게 됩니다.</p>\n<p data-ke-size=\"size16\">악마 좀비 늑대인간 흡혈귀가 안된다고하네요</p>\n<p data-ke-size=\"size16\">그리고 마법 요소도 ... (뭐냣)</p>\n<p data-ke-size=\"size16\">아무튼 이 상황에서도 만화는 살길을 찾아야했고 그래서 과학과 연관시키는 쪽으로 발전했다고 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">내용이 재밌어서 끝까지 봤네요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=tIQ6mexXIp4&t=162s\n\n\n\n \n코믹스의 역사에 대해 이야기 해주는 영상입니다.\n2차세계대전까지는 나치 때려잡는 만화는 폭력적이더라도 문제가 되지 않았는데\n1950년대가 되자 그럴 수 없었나봅니다.\n아이들에게 영향을 준다는 이유로  검열하게 됩니다.\n악마 좀비 늑대인간 흡혈귀가 안된다고하네요\n그리고 마법 요소도 ... (뭐냣)\n아무튼 이 상황에서도 만화는 살길을 찾아야했고 그래서 과학과 연관시키는 쪽으로 발전했다고 합니다.\n \n내용이 재밌어서 끝까지 봤네요",
        "guid": "http://serverdown.tistory.com/1366",
        "categories": [
          "유튜브"
        ],
        "isoDate": "2025-07-28T02:27:54.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "이번주 우공이산 / 1/3 토막이나도 팔지않는 마음",
        "link": "http://serverdown.tistory.com/1365",
        "pubDate": "Sat, 26 Jul 2025 12:13:16 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1365#entry1365comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"424\" data-origin-height=\"245\"><span data-url=\"https://blog.kakaocdn.net/dn/LoNVa/btsPB4dcaXm/ymSRh9Ix9qo5P0W4q7rV50/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/LoNVa/btsPB4dcaXm/ymSRh9Ix9qo5P0W4q7rV50/img.png\"><img src=\"https://blog.kakaocdn.net/dn/LoNVa/btsPB4dcaXm/ymSRh9Ix9qo5P0W4q7rV50/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FLoNVa%2FbtsPB4dcaXm%2FymSRh9Ix9qo5P0W4q7rV50%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"424\" height=\"245\" data-origin-width=\"424\" data-origin-height=\"245\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=pGZTFccEGVQ\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=pGZTFccEGVQ</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=pGZTFccEGVQ\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/MXhl6/hyZne6i2og/ZoxQ2loHemgkJwZ6QLiGA0/img.jpg?width=1280&amp;height=720&amp;face=380_122_606_368,https://scrap.kakaocdn.net/dn/bKlF3o/hyZm8dWm4N/ONX5UsFnuMtwxysLnVl1Pk/img.jpg?width=1280&amp;height=720&amp;face=380_122_606_368\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"지금 이 시대! 혁명의 시대를 읽어내면 돈이 보인다\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/pGZTFccEGVQ\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">결국 시진핑은 털렸고<br />중국의 덤핑 생산은 막혔습니다.<br />LG화학은 중국과의 특허 소송에서 이겼습니다.</p>\n<p data-ke-size=\"size16\">다 맞췄지만 주가는 k-베터리 레볼루션 이전 가격보다 낮아졌습니다.</p>\n<p data-ke-size=\"size16\">저는 거의 3년을 들고 버텼구요 (1년 상승 + 2년하락 기간)<br />결국 아직도 마이너스인 상태입니다.</p>\n<p data-ke-size=\"size16\">어찌보면 어리석은 짓이기도 하고 속았다고 느낄 수도 있을 것입니다.</p>\n<p data-ke-size=\"size16\">하지만 저는 그렇게 생각하지 않습니다.</p>\n<p data-ke-size=\"size16\">아무리 생각해도 베터리가 주요 에너지 저장 수단이되며<br />중국의 이상한 정책은 막을 내릴 것이라고 생각합니다.</p>\n<p data-ke-size=\"size16\">그래서 못판 것이겠죠</p>\n<p data-ke-size=\"size16\">문제라고 하면 주위사람들에게 이렇게 이야기하고 다녀서<br />많은사람들이 같이 물리게 되었다는 점입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">이번주 영상에서 배울 점</h2>\n<p data-ke-size=\"size16\">버핏이 코카콜라에 들어간시점은 공산국가가 몰락하던 시점이였고<br />그때는 이것이 성장주 였다는 것입니다.</p>\n<p data-ke-size=\"size16\">지나고보면 왜그랬는지 이유는 모르게 되고 쌀때 잘샀네 가 되겠지만<br />들어갈때 아이이디어는 그런게 아니라는 것입니다.</p>\n<p data-ke-size=\"size16\">그리고 최고가에서 1/3 토막이 나는 시절도 있었지만 버핏은 팔지 않았습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1015\" data-origin-height=\"721\"><span data-url=\"https://blog.kakaocdn.net/dn/bmk3XK/btsPzTxLuxa/WbKChIkQopT2gnX8mkKb51/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bmk3XK/btsPzTxLuxa/WbKChIkQopT2gnX8mkKb51/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bmk3XK/btsPzTxLuxa/WbKChIkQopT2gnX8mkKb51/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbmk3XK%2FbtsPzTxLuxa%2FWbKChIkQopT2gnX8mkKb51%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1015\" height=\"721\" data-origin-width=\"1015\" data-origin-height=\"721\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">(조금은 팔았을듯)</p>\n<p data-ke-size=\"size16\">거의 기간이 10년 상승 10년하락이군요</p>\n<p data-ke-size=\"size16\">우리는 버핏 처럼 많이 맞출 필요가 없습니다.<br />인생에 단 한번만 맞추더라도 은퇴가능합니다.</p>\n<p data-ke-size=\"size16\">저도 하락하는 2차전지를 2년동안 물을 탔습니다.<br />아주 많이 빠졌을때 물을 거하게 타서 그런지 이젠 0% 대 수익권에 도달했습니다.</p>\n<p data-ke-size=\"size16\">하지만 몇번의 흔들기가 더 생기면 또 마이너스로 갈 것입니다.</p>\n<p data-ke-size=\"size16\">몇년전엔 그런것들을 견디지 못하고 약간의 수익만 나면 팔아버렸습니다.</p>\n<p data-ke-size=\"size16\">박순혁작가와의 3년동안 큰 깨닳음을 얻었습니다.</p>\n<p data-ke-size=\"size16\">이대로 짤짤이 하면서 살지<br />부자로 은퇴할지를 결정해야할 순간이 온것 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">미래를 보는 눈</h2>\n<p data-ke-size=\"size16\">투자로 부자가 되려면 시장의 이상현상을 잘 파악해야하고 미래에 어떻게 될 것인지를 예상해야합니다.</p>\n<p data-ke-size=\"size16\">현재는 미국에서 원자력관련 뉴스가 쏟아지고 있는데 이것은 AI 혁명으로 인한 전력 수요 때문입니다.<br />그래서 정책이 그방향으로 가다보니 뉴스가 그에 맞게 쏟아지는 것입니다.</p>\n<p data-ke-size=\"size16\">이런 점에서 뉴스조차도 예상할 수 있는 것 같습니다.</p>\n<p data-ke-size=\"size16\">온난화 문제도 더이상 참을 수 없을 정도로 위기가 왔습니다.<br />홍수나 가뭄피해는 나날이 강해지고 있고 사람의 인식은 언젠가 바뀔 것입니다.</p>\n<p data-ke-size=\"size16\">자율주행도 상용화에 많이 근접했구요</p>\n<p data-ke-size=\"size16\">충전하기 귀찮은게 단점이지만 <br />시간이 지나면 충전하지 않고 빌려쓰는 시대가 와서 이 문제를 보완할 것입니다.<br />(주차난도 해소할 수 있구요)</p>\n<p data-ke-size=\"size16\">길이 맞다고해도 주가가 바로 상승하지 않습니다.<br />하지만 지금 오르지 않느다면 그것은 싼것입니다.</p>\n<p data-ke-size=\"size16\">싼것을 사는 일은 언제나 좋은 투자입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=pGZTFccEGVQ\n\n\n\n \n결국 시진핑은 털렸고\n중국의 덤핑 생산은 막혔습니다.\nLG화학은 중국과의 특허 소송에서 이겼습니다.\n다 맞췄지만 주가는 k-베터리 레볼루션 이전 가격보다 낮아졌습니다.\n저는 거의 3년을 들고 버텼구요 (1년 상승 + 2년하락 기간)\n결국 아직도 마이너스인 상태입니다.\n어찌보면 어리석은 짓이기도 하고 속았다고 느낄 수도 있을 것입니다.\n하지만 저는 그렇게 생각하지 않습니다.\n아무리 생각해도 베터리가 주요 에너지 저장 수단이되며\n중국의 이상한 정책은 막을 내릴 것이라고 생각합니다.\n그래서 못판 것이겠죠\n문제라고 하면 주위사람들에게 이렇게 이야기하고 다녀서\n많은사람들이 같이 물리게 되었다는 점입니다.\n \n이번주 영상에서 배울 점\n버핏이 코카콜라에 들어간시점은 공산국가가 몰락하던 시점이였고\n그때는 이것이 성장주 였다는 것입니다.\n지나고보면 왜그랬는지 이유는 모르게 되고 쌀때 잘샀네 가 되겠지만\n들어갈때 아이이디어는 그런게 아니라는 것입니다.\n그리고 최고가에서 1/3 토막이 나는 시절도 있었지만 버핏은 팔지 않았습니다.\n\n\n(조금은 팔았을듯)\n거의 기간이 10년 상승 10년하락이군요\n우리는 버핏 처럼 많이 맞출 필요가 없습니다.\n인생에 단 한번만 맞추더라도 은퇴가능합니다.\n저도 하락하는 2차전지를 2년동안 물을 탔습니다.\n아주 많이 빠졌을때 물을 거하게 타서 그런지 이젠 0% 대 수익권에 도달했습니다.\n하지만 몇번의 흔들기가 더 생기면 또 마이너스로 갈 것입니다.\n몇년전엔 그런것들을 견디지 못하고 약간의 수익만 나면 팔아버렸습니다.\n박순혁작가와의 3년동안 큰 깨닳음을 얻었습니다.\n이대로 짤짤이 하면서 살지\n부자로 은퇴할지를 결정해야할 순간이 온것 같습니다.\n \n미래를 보는 눈\n투자로 부자가 되려면 시장의 이상현상을 잘 파악해야하고 미래에 어떻게 될 것인지를 예상해야합니다.\n현재는 미국에서 원자력관련 뉴스가 쏟아지고 있는데 이것은 AI 혁명으로 인한 전력 수요 때문입니다.\n그래서 정책이 그방향으로 가다보니 뉴스가 그에 맞게 쏟아지는 것입니다.\n이런 점에서 뉴스조차도 예상할 수 있는 것 같습니다.\n온난화 문제도 더이상 참을 수 없을 정도로 위기가 왔습니다.\n홍수나 가뭄피해는 나날이 강해지고 있고 사람의 인식은 언젠가 바뀔 것입니다.\n자율주행도 상용화에 많이 근접했구요\n충전하기 귀찮은게 단점이지만 \n시간이 지나면 충전하지 않고 빌려쓰는 시대가 와서 이 문제를 보완할 것입니다.\n(주차난도 해소할 수 있구요)\n길이 맞다고해도 주가가 바로 상승하지 않습니다.\n하지만 지금 오르지 않느다면 그것은 싼것입니다.\n싼것을 사는 일은 언제나 좋은 투자입니다.",
        "guid": "http://serverdown.tistory.com/1365",
        "categories": [
          "투자"
        ],
        "isoDate": "2025-07-26T03:13:16.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "우주 반도체 ? / 인튜이티브 머신스 / LUNR",
        "link": "http://serverdown.tistory.com/1364",
        "pubDate": "Fri, 25 Jul 2025 19:12:51 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1364#entry1364comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=zKITQmGryYY\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=zKITQmGryYY</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=zKITQmGryYY\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/btz9OF/hyZqR9lNib/UBDrtg5qzUcMKKrHzC2Yk1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/uJuGd/hyZnfYlKYR/8E8OPIkascvT7tQQ8ivBmk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"우주에서 반도체를 만든다고? 인튜이티브 머신스 (LUNR) 주가 급등 이유\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/zKITQmGryYY\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이런 산업이 있었군요</p>\n<p data-ke-size=\"size16\">우주에서 생산을 하는 방식인데 아주 정밀한 물질은 중력의 영향을 받는 곳에서 만들면 문제가 생긴다고 합니다.</p>\n<p data-ke-size=\"size16\">그래서 우주에서 만드는 것도 좋은 방법이라고 하네요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">뉴스 ㅋㅋㅋ</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1248\" data-origin-height=\"245\"><span data-url=\"https://blog.kakaocdn.net/dn/c49pga/btsPziEtiZY/ymVtxT3gVbeOxx3kxGT011/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/c49pga/btsPziEtiZY/ymVtxT3gVbeOxx3kxGT011/img.png\"><img src=\"https://blog.kakaocdn.net/dn/c49pga/btsPziEtiZY/ymVtxT3gVbeOxx3kxGT011/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc49pga%2FbtsPziEtiZY%2FymVtxT3gVbeOxx3kxGT011%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1248\" height=\"245\" data-origin-width=\"1248\" data-origin-height=\"245\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">인튜이티브 머신즈는 공돌이 회사라 그런지 신가한 뉴스가 많습니다.</p>\n<p data-ke-size=\"size16\">달 탐사 로봇인가 냉장고 같이 생긴 기기를 달에 보냈다가 넘어지는 바람에 버린 경력이 있습니다.<br />넘어지면 안테나를 세울 수 없어서 통신이 불가능하다고 들었습니다.</p>\n<p data-ke-size=\"size16\">뭐야 허접인가 했는데 또다른 신기한 사업을하네요</p>\n<p data-ke-size=\"size16\">우주에서 반도체 웨이퍼를 만든다거나 약품을 만드는 일을 한다고 합니다.</p>\n<p data-ke-size=\"size16\">이럴러면 생산 기기를 우주에 보내야하고</p>\n<p data-ke-size=\"size16\">지구 - 우주간 물건 배달 사업을 해야합니다.</p>\n<p data-ke-size=\"size16\">그것을 하겠다는 것이죠</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상보시면 재밌으니 한번 봐주시구요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">주가 차트</h2>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1005\" data-origin-height=\"735\"><span data-url=\"https://blog.kakaocdn.net/dn/bejH42/btsPzTRHJVo/4vgNh7VkKh7QD2EN7sKRw1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bejH42/btsPzTRHJVo/4vgNh7VkKh7QD2EN7sKRw1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bejH42/btsPzTRHJVo/4vgNh7VkKh7QD2EN7sKRw1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbejH42%2FbtsPzTRHJVo%2F4vgNh7VkKh7QD2EN7sKRw1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1005\" height=\"735\" data-origin-width=\"1005\" data-origin-height=\"735\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">2023년에 상장했구요</p>\n<p data-ke-size=\"size16\">차트도 기묘하게 이상한 모양이군요</p>\n<p data-ke-size=\"size16\">전형적인 돈 못버는 기업일꺼 같지만</p>\n<p data-ke-size=\"size16\">아무튼 오르면 되는거니까요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">관심을 가져봐야겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=zKITQmGryYY\n\n\n\n \n이런 산업이 있었군요\n우주에서 생산을 하는 방식인데 아주 정밀한 물질은 중력의 영향을 받는 곳에서 만들면 문제가 생긴다고 합니다.\n그래서 우주에서 만드는 것도 좋은 방법이라고 하네요\n \n뉴스 ㅋㅋㅋ\n\n\n인튜이티브 머신즈는 공돌이 회사라 그런지 신가한 뉴스가 많습니다.\n달 탐사 로봇인가 냉장고 같이 생긴 기기를 달에 보냈다가 넘어지는 바람에 버린 경력이 있습니다.\n넘어지면 안테나를 세울 수 없어서 통신이 불가능하다고 들었습니다.\n뭐야 허접인가 했는데 또다른 신기한 사업을하네요\n우주에서 반도체 웨이퍼를 만든다거나 약품을 만드는 일을 한다고 합니다.\n이럴러면 생산 기기를 우주에 보내야하고\n지구 - 우주간 물건 배달 사업을 해야합니다.\n그것을 하겠다는 것이죠\n \n영상보시면 재밌으니 한번 봐주시구요\n \n \n주가 차트\n \n\n\n2023년에 상장했구요\n차트도 기묘하게 이상한 모양이군요\n전형적인 돈 못버는 기업일꺼 같지만\n아무튼 오르면 되는거니까요\n \n관심을 가져봐야겠습니다.",
        "guid": "http://serverdown.tistory.com/1364",
        "categories": [
          "투자"
        ],
        "isoDate": "2025-07-25T10:12:51.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "저나백스 (진통제) 제조사 주가 왜이케 안가 / 버텍스 파마슈티컬스 / VRTX",
        "link": "http://serverdown.tistory.com/1363",
        "pubDate": "Thu, 24 Jul 2025 16:10:31 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1363#entry1363comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=xG06MXIwh8U&amp;t=180s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=xG06MXIwh8U&amp;t=180s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=xG06MXIwh8U\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/czXyme/hyZm7FR02C/oJ8K7rwNoW01AF2jiUQl3k/img.jpg?width=1280&amp;height=720&amp;face=888_112_1064_304\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"아편보다 강력한데&hellip; 중독은 없다? 20년 만에 나온 진통제 혁명! 저나백스, 경쟁자가 없다.ㅣ장홍\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/xG06MXIwh8U\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상만 보면 최초 최고의 약물이 나왔는데</p>\n<p data-ke-size=\"size16\">이상하게 주가가 안가네요</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"824\" data-origin-height=\"379\"><span data-url=\"https://blog.kakaocdn.net/dn/lL8At/btsPw1a969Z/kkE9XG6mCJMJMSSN3nFkP0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/lL8At/btsPw1a969Z/kkE9XG6mCJMJMSSN3nFkP0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/lL8At/btsPw1a969Z/kkE9XG6mCJMJMSSN3nFkP0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FlL8At%2FbtsPw1a969Z%2FkkE9XG6mCJMJMSSN3nFkP0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"824\" height=\"379\" data-origin-width=\"824\" data-origin-height=\"379\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">1년치 차트입니다. 아직 움직이지 않는군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1011\" data-origin-height=\"373\"><span data-url=\"https://blog.kakaocdn.net/dn/MFYSR/btsPw1Cb3Ch/ZvMm4C2O15UMyW1pHQ7AQ1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/MFYSR/btsPw1Cb3Ch/ZvMm4C2O15UMyW1pHQ7AQ1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/MFYSR/btsPw1Cb3Ch/ZvMm4C2O15UMyW1pHQ7AQ1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FMFYSR%2FbtsPw1Cb3Ch%2FZvMm4C2O15UMyW1pHQ7AQ1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1011\" height=\"373\" data-origin-width=\"1011\" data-origin-height=\"373\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">36년치 차트인데 차트 이쁘네요</p>\n<p data-ke-size=\"size16\">그냥 장투 해볼까 싶기도</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">아직 안알려져서 안가는게 아닌가 싶어서 글써봅니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=xG06MXIwh8U&t=180s\n\n\n\n \n \n영상만 보면 최초 최고의 약물이 나왔는데\n이상하게 주가가 안가네요\n\n\n1년치 차트입니다. 아직 움직이지 않는군요\n \n\n\n36년치 차트인데 차트 이쁘네요\n그냥 장투 해볼까 싶기도\n \n아직 안알려져서 안가는게 아닌가 싶어서 글써봅니다.",
        "guid": "http://serverdown.tistory.com/1363",
        "isoDate": "2025-07-24T07:10:31.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": [
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "코펜하겐에서 개최된 Kotlin Conf 2025",
        "link": "https://jojoldu.tistory.com/840",
        "pubDate": "Tue, 29 Jul 2025 08:23:35 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "https://jojoldu.tistory.com/840#entry840comment",
        "content": "<p data-ke-size=\"size16\">최근 <a href=\"https://www.youtube.com/watch?v=yE9-ENNbXsU\">인재전쟁 1부 공대에 미친 중국</a> 영상을 봤다.</p>\n<p data-ke-size=\"size16\">소프트웨어 엔지니어로 일하다보면 중국의 기술력이 정말 뛰어나다는 것을 흔하게 느낄 수 있지만, 특히 이번 영상에서는 그 격차를 심하게 느끼게 된다.</p>\n<p data-ke-size=\"size16\">1부 영상의 마지막에 다음과 같은 충격적인 메세지가 나온다.</p>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">'올해 중국 가오카오엔(수능) 1,335만 명이 응시했다.<br />그 중 선별된 <b>약 5%의 최상위 인재</b>만이 국가가 지정한 명문대 이공계에 입학한다.<br />이들은 약 <b>90만명</b>,<br /><b>작년 우리나라 전체 수능 응시생의 두 배</b>이다.'</p>\n</blockquote>\n<p data-ke-size=\"size16\">우리나라는 모국어로 된 콘텐츠가 많다.<br />누구나 배울 수 있도록 가능하면 해외의 좋은 내용들도 번역하고, 국내의 많은 작가, 현업 실무자분들이 노하우를 만들어서 배포해주신다.</p>\n<p data-ke-size=\"size16\">근데 그게 미국, 중국과는 차이가 있다.<br />전세계에서 영어로 노하우가 공유되고 있고,<br />14억 인구로 중국어로 된 기술에 관한 노하우가 공유된다.</p>\n<p data-ke-size=\"size16\">우리나라에서만 사용되는 한국어로, 5천만의 인구 안에서 만들어지는 노하우는 영어, 중국어에 비해 양적으로 부족한 부분이 많다.</p>\n<p data-ke-size=\"size16\">그러다보니 배우고 싶은게 있다면 영어나 중국어를 통해 배우거나, <b>그런 지식이나 노하우가 있는지조차 모르고 넘어가는 경우</b>도 많다.</p>\n<p data-ke-size=\"size16\">단적인 예로 프로그래밍 기술들이 그렇다.</p>\n<p data-ke-size=\"size16\">코틀린은 이제 타입스크립트와 더불어서 다양한 분야에서 적극적으로 활용되는 프로그래밍 언어다.<br />안드로이드 개발자분들은 훨씬 전부터 자바에서 코틀린으로 주력 언어를 교체하였고,<br />백엔드 서버 개발자분들 역시 자바-스프링 조합에서 코틀린-스프링 조합을 계속해서 늘려나가고 있다.<br />코틀린 멀티플랫폼 (Kotlin Multiplatform, KMP) 으로 다양한 운영체제에서 실행되는 애플리케이션을 개발하는 사례도 조금씩 생기고 있다.</p>\n<p data-ke-size=\"size16\">언어의 관심과 점유율은 계속해서 증가하지만, 실제 커뮤니티 활성화는 그렇지 않다.<br />국내에는 코틀린을 주제로 한 수천명이 모이는 행사가 없다.</p>\n<p data-ke-size=\"size16\">AI 컨퍼런스 혹은 직무에 대한 컨퍼런스는 천명이상 규모도 종종 개최되지만 코틀린이나 타입스크립트 등은 그런 대형 컨퍼런스의 소주제로 일부 세션을 담당하는 정도이다.</p>\n<p data-ke-size=\"size16\"><b>웹/앱 서비스의 대부분이 코틀린과 타입스크립트로 통일 되는 상황</b>이라는게 믿기지 않을정도로 국내의 커뮤니티는 활성화되어있지 않다.<br />그런 커뮤니티를 직접적으로 이끌 운영진들도 필요하고,<br />해당 기술이 회사의 핵심 Key라고 생각해서 컨퍼런스를 후원하는 큰 회사들도 있어야 한다.<br />하지만 국내에서는 어렵다.</p>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">그나마 스프링은 예전부터 KSUG라는 핵심 커뮤니티가 활성화 되어있기에 매년 서로의 경험을 공유할 수 있는 자리가 있다.<br />이 외 기술에 대해서는 대형 벤더사의 기술 (애플, 안드로이드 등) 을 다루는 커뮤니티가 아니라면 거의 없다.</p>\n</blockquote>\n<p data-ke-size=\"size16\">그러다보니 인터넷을 통해, 사내 동료들을 통해 배우거나 소식을 전달받는 것이 현재의 코틀린 학습 방법이 된다.</p>\n<p data-ke-size=\"size16\">반면, 해외는 그렇지 않다.<br />KotlinConf 뿐만 아니라 Spring I/O, Spring One, FigmaConfig, NextConifg 등 전세계의 전문가들이 모여서 그들의 경험을 매년 공유하고 있다.</p>\n<p data-ke-size=\"size16\">코틀린 언어를 만든 젯브레인이 매년 개최하는 KotlinConf는 전세계의 수많은 코틀린 개발자들이 지식과 경험을 나누는 세계 최대의 코틀린 컨퍼런스이다.</p>\n<p data-ke-size=\"size16\">올해 개최된 <a href=\"https://kotlinconf.com/\">KotlinConf 2025</a> 는 코펜하겐에서 진행되었다.<br />한국에서 참여하기에는 너무나 어렵다.</p>\n<p data-ke-size=\"size16\">국내에서는 기초 자료 외에는 거의 찾아보기도 힘든 <b>Ktor, KMP (Kotlin Multiplatform, KMP), Kotlin In AI Agent 에 대한 풍부한 실전 사례</b>나 Compose, Coroutine 에 대한 실전 최적화 노하우 등이 공유되고 있다.</p>\n<p data-ke-size=\"size16\"><a href=\"https://2025.kotlinconf.com/talks/812209/\">Kotlin Worst Practices &mdash; How to Maximize Your Hassle</a> 세션은 지금 당장 얻어갈 수 있는 Kotlin 에서 좋은 코드를 작성하는 방법들이 공유되는데 이건 초급~중급 개발자분들 모두가 알아두면 좋은 내용들이었다.</p>\n<p data-ke-size=\"size16\">그 외에도 전세계 수많은 개발팀이 Kotlin을 다양한 분야에서 글로벌 트래픽안에서 사용하면서 발생하는 수많은 문제들을 해결한 노하우를 올해도 전파했다.</p>\n<p data-ke-size=\"size16\">누구는 지구 반대편에서 글로벌한 트래픽 경험 내에서 코틀린 사용 경험과 새로운 기술에 대한 발표와 토론을 나누고 있고,<br />누구는 GPT와 공식 문서로만 배우고 있다면 이건 불평등 하지 않나? 라는 생각이 들었다.</p>\n<p data-ke-size=\"size16\">인프런의 비전은 \"성장 기회의 평등\" 이다.<br />우린 <b>누구에게나 성장 기회 자체는 평등하게 제공하고 싶다</b>.<br /><b>제공했는데 선택하지 않는 것은 우리 몫이 아니지만, 최소한 기회는 평등하게 주고 싶다</b>.</p>\n<p data-ke-size=\"size16\">우린 중국, 미국과는 다르다.<br />그러니깐 콘텐츠 번역에 집중해야한다고 생각했다.</p>\n<p data-ke-size=\"size16\">젯브레인과는 예전부터 인연이 있었다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>젯브레인 한국 사용자 모임</li>\n<li>젯브레인 컨퍼런스 발표</li>\n<li><a href=\"https://www.inflearn.com/course/intellij-guide?inst=241a0171\">IntelliJ IDEA 강의</a></li>\n</ul>\n<p data-ke-size=\"size16\">등을 살려 젯브레인에 연락을 했다.</p>\n<p data-ke-size=\"size16\">올해 개최된 \"<b>KotlinConf 2025를 한국어로 번역과 더빙을 해서 인프런에서 모두에게 무료로 공유하고 싶다</b>\"고.<br />앞으로도 <b>젯브레인이 공유하는 수많은 글로벌 노하우와 지식들은 계속해서 인프런에서 한국의 개발자들을 위해 제공</b>하고 싶다고.</p>\n<p data-ke-size=\"size16\">감사하게도 젯브레인측에서는 <b>젯브레인의 콘텐츠에 대해서 한국어 독점을 인프런이 할 수 있게 해주셨다</b>.</p>\n<p data-ke-size=\"size16\">한국어/일본어/베트남어로 자막과 더빙을 생성하고 많은 검수를 마치고 드디어 Kotlin Conf 2025를 오픈하게 되었다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><a href=\"http://bit.ly/3INtDnn\">인프런 - KotlinConf 2025</a></li>\n</ul>\n<p data-ke-size=\"size16\">\"전세계의 수많은 코틀린 개발자들은 이런것들을 고민하고 있구나\"<br />\"코틀린 내 여러 생태계들의 최적화는 이런식으로 하는구나\"<br />\"한국에서 생소한 이 기술이 해외에서는 이미 많이들 쓰고 있구나\"<br />등 정말로 좋은 주제의 세션들이 많다.</p>\n<p data-ke-size=\"size16\">이걸 이제 국내의 개발자분들께 제공할 수 있게 되어서 너무나 기쁘다.</p>\n<p data-ke-size=\"size16\">물론 \"번역, 더빙에 들어가는 비용, 공수 등이 있는데 수익화가 전혀 안되는 이 작업을 왜 하는가?\" 에 대한 질문도 받았다.<br />그렇지만, \"우리가 아니면 이걸 할 곳이 있을까?\" 하는 생각이 제일 컸다.<br />어찌되었든 <b>한국어로 된 지식 공유는 한계가 있고, 글로벌로 공유되는 노하우와 지식에서 자꾸 국내는 멀어지는 것을 해결해야 한다</b>는 생각이 강하게 있어서 손실 비용에 대해서는 감수하기로 했다.</p>\n<p data-ke-size=\"size16\">글로벌과 국내가 멀어지는 현상은 젯브레인과의 협업만으로 해결할 수는 없다.<br />더 많은 글로벌 기업과 지식 공유에 있어 협업을 할 예정이다.</p>\n<p data-ke-size=\"size16\">Spring One, Spring/IO, Figma Config, Next.js Config 등 전세계에서 열리는 수많은 컨퍼런스들을 원하는 장소에서 원하는 언어로, 가장 편한 방법으로 경험할 수 있게 하고 싶다.</p>\n<p data-ke-size=\"size16\">이 생태계에 정말 큰 족적을 남기고 싶다.</p>",
        "contentSnippet": "최근 인재전쟁 1부 공대에 미친 중국 영상을 봤다.\n소프트웨어 엔지니어로 일하다보면 중국의 기술력이 정말 뛰어나다는 것을 흔하게 느낄 수 있지만, 특히 이번 영상에서는 그 격차를 심하게 느끼게 된다.\n1부 영상의 마지막에 다음과 같은 충격적인 메세지가 나온다.\n'올해 중국 가오카오엔(수능) 1,335만 명이 응시했다.\n그 중 선별된 약 5%의 최상위 인재만이 국가가 지정한 명문대 이공계에 입학한다.\n이들은 약 90만명,\n작년 우리나라 전체 수능 응시생의 두 배이다.'\n우리나라는 모국어로 된 콘텐츠가 많다.\n누구나 배울 수 있도록 가능하면 해외의 좋은 내용들도 번역하고, 국내의 많은 작가, 현업 실무자분들이 노하우를 만들어서 배포해주신다.\n근데 그게 미국, 중국과는 차이가 있다.\n전세계에서 영어로 노하우가 공유되고 있고,\n14억 인구로 중국어로 된 기술에 관한 노하우가 공유된다.\n우리나라에서만 사용되는 한국어로, 5천만의 인구 안에서 만들어지는 노하우는 영어, 중국어에 비해 양적으로 부족한 부분이 많다.\n그러다보니 배우고 싶은게 있다면 영어나 중국어를 통해 배우거나, 그런 지식이나 노하우가 있는지조차 모르고 넘어가는 경우도 많다.\n단적인 예로 프로그래밍 기술들이 그렇다.\n코틀린은 이제 타입스크립트와 더불어서 다양한 분야에서 적극적으로 활용되는 프로그래밍 언어다.\n안드로이드 개발자분들은 훨씬 전부터 자바에서 코틀린으로 주력 언어를 교체하였고,\n백엔드 서버 개발자분들 역시 자바-스프링 조합에서 코틀린-스프링 조합을 계속해서 늘려나가고 있다.\n코틀린 멀티플랫폼 (Kotlin Multiplatform, KMP) 으로 다양한 운영체제에서 실행되는 애플리케이션을 개발하는 사례도 조금씩 생기고 있다.\n언어의 관심과 점유율은 계속해서 증가하지만, 실제 커뮤니티 활성화는 그렇지 않다.\n국내에는 코틀린을 주제로 한 수천명이 모이는 행사가 없다.\nAI 컨퍼런스 혹은 직무에 대한 컨퍼런스는 천명이상 규모도 종종 개최되지만 코틀린이나 타입스크립트 등은 그런 대형 컨퍼런스의 소주제로 일부 세션을 담당하는 정도이다.\n웹/앱 서비스의 대부분이 코틀린과 타입스크립트로 통일 되는 상황이라는게 믿기지 않을정도로 국내의 커뮤니티는 활성화되어있지 않다.\n그런 커뮤니티를 직접적으로 이끌 운영진들도 필요하고,\n해당 기술이 회사의 핵심 Key라고 생각해서 컨퍼런스를 후원하는 큰 회사들도 있어야 한다.\n하지만 국내에서는 어렵다.\n그나마 스프링은 예전부터 KSUG라는 핵심 커뮤니티가 활성화 되어있기에 매년 서로의 경험을 공유할 수 있는 자리가 있다.\n이 외 기술에 대해서는 대형 벤더사의 기술 (애플, 안드로이드 등) 을 다루는 커뮤니티가 아니라면 거의 없다.\n그러다보니 인터넷을 통해, 사내 동료들을 통해 배우거나 소식을 전달받는 것이 현재의 코틀린 학습 방법이 된다.\n반면, 해외는 그렇지 않다.\nKotlinConf 뿐만 아니라 Spring I/O, Spring One, FigmaConfig, NextConifg 등 전세계의 전문가들이 모여서 그들의 경험을 매년 공유하고 있다.\n코틀린 언어를 만든 젯브레인이 매년 개최하는 KotlinConf는 전세계의 수많은 코틀린 개발자들이 지식과 경험을 나누는 세계 최대의 코틀린 컨퍼런스이다.\n올해 개최된 KotlinConf 2025 는 코펜하겐에서 진행되었다.\n한국에서 참여하기에는 너무나 어렵다.\n국내에서는 기초 자료 외에는 거의 찾아보기도 힘든 Ktor, KMP (Kotlin Multiplatform, KMP), Kotlin In AI Agent 에 대한 풍부한 실전 사례나 Compose, Coroutine 에 대한 실전 최적화 노하우 등이 공유되고 있다.\nKotlin Worst Practices — How to Maximize Your Hassle 세션은 지금 당장 얻어갈 수 있는 Kotlin 에서 좋은 코드를 작성하는 방법들이 공유되는데 이건 초급~중급 개발자분들 모두가 알아두면 좋은 내용들이었다.\n그 외에도 전세계 수많은 개발팀이 Kotlin을 다양한 분야에서 글로벌 트래픽안에서 사용하면서 발생하는 수많은 문제들을 해결한 노하우를 올해도 전파했다.\n누구는 지구 반대편에서 글로벌한 트래픽 경험 내에서 코틀린 사용 경험과 새로운 기술에 대한 발표와 토론을 나누고 있고,\n누구는 GPT와 공식 문서로만 배우고 있다면 이건 불평등 하지 않나? 라는 생각이 들었다.\n인프런의 비전은 \"성장 기회의 평등\" 이다.\n우린 누구에게나 성장 기회 자체는 평등하게 제공하고 싶다.\n제공했는데 선택하지 않는 것은 우리 몫이 아니지만, 최소한 기회는 평등하게 주고 싶다.\n우린 중국, 미국과는 다르다.\n그러니깐 콘텐츠 번역에 집중해야한다고 생각했다.\n젯브레인과는 예전부터 인연이 있었다.\n젯브레인 한국 사용자 모임\n젯브레인 컨퍼런스 발표\nIntelliJ IDEA 강의\n등을 살려 젯브레인에 연락을 했다.\n올해 개최된 \"KotlinConf 2025를 한국어로 번역과 더빙을 해서 인프런에서 모두에게 무료로 공유하고 싶다\"고.\n앞으로도 젯브레인이 공유하는 수많은 글로벌 노하우와 지식들은 계속해서 인프런에서 한국의 개발자들을 위해 제공하고 싶다고.\n감사하게도 젯브레인측에서는 젯브레인의 콘텐츠에 대해서 한국어 독점을 인프런이 할 수 있게 해주셨다.\n한국어/일본어/베트남어로 자막과 더빙을 생성하고 많은 검수를 마치고 드디어 Kotlin Conf 2025를 오픈하게 되었다.\n인프런 - KotlinConf 2025\n\"전세계의 수많은 코틀린 개발자들은 이런것들을 고민하고 있구나\"\n\"코틀린 내 여러 생태계들의 최적화는 이런식으로 하는구나\"\n\"한국에서 생소한 이 기술이 해외에서는 이미 많이들 쓰고 있구나\"\n등 정말로 좋은 주제의 세션들이 많다.\n이걸 이제 국내의 개발자분들께 제공할 수 있게 되어서 너무나 기쁘다.\n물론 \"번역, 더빙에 들어가는 비용, 공수 등이 있는데 수익화가 전혀 안되는 이 작업을 왜 하는가?\" 에 대한 질문도 받았다.\n그렇지만, \"우리가 아니면 이걸 할 곳이 있을까?\" 하는 생각이 제일 컸다.\n어찌되었든 한국어로 된 지식 공유는 한계가 있고, 글로벌로 공유되는 노하우와 지식에서 자꾸 국내는 멀어지는 것을 해결해야 한다는 생각이 강하게 있어서 손실 비용에 대해서는 감수하기로 했다.\n글로벌과 국내가 멀어지는 현상은 젯브레인과의 협업만으로 해결할 수는 없다.\n더 많은 글로벌 기업과 지식 공유에 있어 협업을 할 예정이다.\nSpring One, Spring/IO, Figma Config, Next.js Config 등 전세계에서 열리는 수많은 컨퍼런스들을 원하는 장소에서 원하는 언어로, 가장 편한 방법으로 경험할 수 있게 하고 싶다.\n이 생태계에 정말 큰 족적을 남기고 싶다.",
        "guid": "https://jojoldu.tistory.com/840",
        "categories": [
          "생각정리",
          "kotlinconf2025",
          "젯브레인",
          "코틀린",
          "코틀린 성능 개선",
          "코틀린 최적화",
          "코틀린 컨퍼런스"
        ],
        "isoDate": "2025-07-28T23:23:35.000Z"
      },
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "#100일 챌린지",
        "link": "https://jojoldu.tistory.com/839",
        "pubDate": "Mon, 28 Jul 2025 08:49:09 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "https://jojoldu.tistory.com/839#entry839comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"1.jpg\" data-origin-width=\"300\" data-origin-height=\"466\"><span data-url=\"https://blog.kakaocdn.net/dn/Kadvb/btsPAV208dr/Y0mNogiFaUCbUo7m3eUzA1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/Kadvb/btsPAV208dr/Y0mNogiFaUCbUo7m3eUzA1/img.jpg\" data-alt=\"https://product.kyobobook.co.kr/detail/S000217034649\"><img src=\"https://blog.kakaocdn.net/dn/Kadvb/btsPAV208dr/Y0mNogiFaUCbUo7m3eUzA1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FKadvb%2FbtsPAV208dr%2FY0mNogiFaUCbUo7m3eUzA1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"300\" height=\"466\" data-filename=\"1.jpg\" data-origin-width=\"300\" data-origin-height=\"466\"/></span><figcaption>https://product.kyobobook.co.kr/detail/S000217034649</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">종립님이 재밌게 보시길래 토요일에 책을 배송 받아서 하루종일 이 책만 봤다.</p>\n<p data-ke-size=\"size16\">2023년 10월 28일부터 2024년 2월 4일까지 100일간 GPT의 도움을 받아 게임, 유틸리티 프로그램 등 매일 1개의 완성된 애플리케이션 결과물을 트위터 (X) 에 공유했던 <a href=\"https://x.com/Luna_SE_Jp\">오츠카 아미</a>님의 이야기를 담은 에세이다.</p>\n<p data-ke-size=\"size16\">예전에 하야마 아마리님의 \"스물아홉 생일, 1년 후 죽기로 결심했다\" 를 읽으면서도 느낀건데 실제 본인의 경험담을 기반으로 한 일본의 에세이가 가진 특유의 느낌이 있다.<br />어려운 문장 없이, 과한 감정 표현 없이 담백하게 상황과 감정을 전달한다.</p>\n<p data-ke-size=\"size16\">아무리 GPT의 도움을 받았다고 해도 개발을 전혀 모르는 상경대 재학생이 매일 매일 하루도 빠짐 없이 온전히 작동하는 프로그래밍 결과물을 만든다는 것은 정말 대단하다.<br />그래서 이 책은 \"<b>요즘 같은 AI 시대에 프로그래밍을 어떻게 배워야 할 것인가</b>\" 를 실제 개인의 경험으로 소개한다고 느껴진다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>일단은 만들고 싶은 프로그램을 어떻게든 만든다.</li>\n<li>그걸 만들다가 막히는 부분이 있으면 그걸 해결하는데 필요한 공부를 한다.</li>\n<li>결국 완성 혹은 개선을 한다.</li>\n</ul>\n<p data-ke-size=\"size16\">재밌는 점은 컴퓨터공학에 필요한 전공 지식을 이 과정을 통해서도 배운다는 것이다.<br />개발을 전혀 몰랐지만 100일간의 챌린지를 하면서 GPT가 제대로 이해할 수 있게 전달하기 위해, GPT가 내놓은 결과물을 이해하기 위해 프로그래밍에 필요한 지식들을 하나둘씩 배워간다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>클래스와 객체지향 프로그래밍</li>\n<li>상태 관리</li>\n<li>UML과 클래스 다이어그램</li>\n<li>디자인 패턴</li>\n<li>선형 대수</li>\n<li>이산 수학</li>\n</ul>\n<p data-ke-size=\"size16\">등등.</p>\n<p data-ke-size=\"size16\">모든 것을 AI가 생각하도록 위임하는게 아니라, 위임을 위한 기본 지식은 본인이 익혀야하는 점을 잘 보여준 사례 같았다.</p>\n<p data-ke-size=\"size16\">앞으로 프로그래밍은 어떻게 배워야 하는가에 대해 생각할거리를 많이 던져주었다.</p>\n<p data-ke-size=\"size16\">이 책의 많은 리뷰가 AI의 도움으로 얼마나 많은 일을 할 수 있는지, 혹은 100일 동안 끊임없이 한 노력이 얼마나 대단한지 등을 칭찬한다..</p>\n<p data-ke-size=\"size16\">근데 나는 그것 보다는 <b>매일 트위터에 본인의 작업물을 공유한 것까지를 목표로 했다는 것</b>에 관심이 갔다.</p>\n<p data-ke-size=\"size16\">예전부터 무언가 배움이 필요할 땐, 배우는 그대로 블로그에 정리해서 외부에 공유를 했다.<br />남에게 공유하기 위해서는 최소한의 퀄리티를 보장해야하는 압박감과 남들과 한 약속이 있으니 어떻게든 끝까지 해내야하는 등 여러 불편한 점이 결국 내가 원하는 목적지에 도달하게 만든다는 것을 알기 때문이였다.</p>\n<p data-ke-size=\"size16\">마찬가지로 인스타그램에 매일 매일 몸무게, 운동하는 모습, 식단을 공유하는 사람은 다이어트 성공 확률이 높다고 한다.</p>\n<p data-ke-size=\"size16\">원하는 실력을 갖추기 전까지 외부에 공유하지 않는 사람은 목표 달성이 어려운 경우를 자주 목격 한다.<br />아직은 많이 어설프더라도 남들에게 자신의 결과물을 알리고, 남들이 웃더라도 부끄러워하지 않고 태연하게 하나씩 해내는 사람은 결국 목표를 달성했다.<br />다이어트, 운동, 노래 등이 아닌 프로그래밍으로도 그 사례를 보여주어서 너무 반가웠다.</p>\n<p data-ke-size=\"size16\">\"요즘 같은 시대에 어떻게 프로그래밍을 배워야 하나요?\" 라는 고민을 하는 분들께 추천해줄만한 책이 생긴 것 같다.<br />이제 막 프로그래밍을 시작하는 아이가 있는 어른들에게는 한번쯤 읽어보라고 추천하고 싶다.<br />특히 이제 막 시작한 그 아이에게도 말이다.</p>",
        "contentSnippet": "https://product.kyobobook.co.kr/detail/S000217034649\n\n\n종립님이 재밌게 보시길래 토요일에 책을 배송 받아서 하루종일 이 책만 봤다.\n2023년 10월 28일부터 2024년 2월 4일까지 100일간 GPT의 도움을 받아 게임, 유틸리티 프로그램 등 매일 1개의 완성된 애플리케이션 결과물을 트위터 (X) 에 공유했던 오츠카 아미님의 이야기를 담은 에세이다.\n예전에 하야마 아마리님의 \"스물아홉 생일, 1년 후 죽기로 결심했다\" 를 읽으면서도 느낀건데 실제 본인의 경험담을 기반으로 한 일본의 에세이가 가진 특유의 느낌이 있다.\n어려운 문장 없이, 과한 감정 표현 없이 담백하게 상황과 감정을 전달한다.\n아무리 GPT의 도움을 받았다고 해도 개발을 전혀 모르는 상경대 재학생이 매일 매일 하루도 빠짐 없이 온전히 작동하는 프로그래밍 결과물을 만든다는 것은 정말 대단하다.\n그래서 이 책은 \"요즘 같은 AI 시대에 프로그래밍을 어떻게 배워야 할 것인가\" 를 실제 개인의 경험으로 소개한다고 느껴진다.\n일단은 만들고 싶은 프로그램을 어떻게든 만든다.\n그걸 만들다가 막히는 부분이 있으면 그걸 해결하는데 필요한 공부를 한다.\n결국 완성 혹은 개선을 한다.\n재밌는 점은 컴퓨터공학에 필요한 전공 지식을 이 과정을 통해서도 배운다는 것이다.\n개발을 전혀 몰랐지만 100일간의 챌린지를 하면서 GPT가 제대로 이해할 수 있게 전달하기 위해, GPT가 내놓은 결과물을 이해하기 위해 프로그래밍에 필요한 지식들을 하나둘씩 배워간다.\n클래스와 객체지향 프로그래밍\n상태 관리\nUML과 클래스 다이어그램\n디자인 패턴\n선형 대수\n이산 수학\n등등.\n모든 것을 AI가 생각하도록 위임하는게 아니라, 위임을 위한 기본 지식은 본인이 익혀야하는 점을 잘 보여준 사례 같았다.\n앞으로 프로그래밍은 어떻게 배워야 하는가에 대해 생각할거리를 많이 던져주었다.\n이 책의 많은 리뷰가 AI의 도움으로 얼마나 많은 일을 할 수 있는지, 혹은 100일 동안 끊임없이 한 노력이 얼마나 대단한지 등을 칭찬한다..\n근데 나는 그것 보다는 매일 트위터에 본인의 작업물을 공유한 것까지를 목표로 했다는 것에 관심이 갔다.\n예전부터 무언가 배움이 필요할 땐, 배우는 그대로 블로그에 정리해서 외부에 공유를 했다.\n남에게 공유하기 위해서는 최소한의 퀄리티를 보장해야하는 압박감과 남들과 한 약속이 있으니 어떻게든 끝까지 해내야하는 등 여러 불편한 점이 결국 내가 원하는 목적지에 도달하게 만든다는 것을 알기 때문이였다.\n마찬가지로 인스타그램에 매일 매일 몸무게, 운동하는 모습, 식단을 공유하는 사람은 다이어트 성공 확률이 높다고 한다.\n원하는 실력을 갖추기 전까지 외부에 공유하지 않는 사람은 목표 달성이 어려운 경우를 자주 목격 한다.\n아직은 많이 어설프더라도 남들에게 자신의 결과물을 알리고, 남들이 웃더라도 부끄러워하지 않고 태연하게 하나씩 해내는 사람은 결국 목표를 달성했다.\n다이어트, 운동, 노래 등이 아닌 프로그래밍으로도 그 사례를 보여주어서 너무 반가웠다.\n\"요즘 같은 시대에 어떻게 프로그래밍을 배워야 하나요?\" 라는 고민을 하는 분들께 추천해줄만한 책이 생긴 것 같다.\n이제 막 프로그래밍을 시작하는 아이가 있는 어른들에게는 한번쯤 읽어보라고 추천하고 싶다.\n특히 이제 막 시작한 그 아이에게도 말이다.",
        "guid": "https://jojoldu.tistory.com/839",
        "categories": [
          "도서",
          "100일 챌린지",
          "AI",
          "오츠카 아미",
          "요즘 프로그래밍"
        ],
        "isoDate": "2025-07-27T23:49:09.000Z"
      },
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "애증의 스프링 배치와 요즘 듣는 강의",
        "link": "https://jojoldu.tistory.com/838",
        "pubDate": "Sat, 26 Jul 2025 13:55:15 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "https://jojoldu.tistory.com/838#entry838comment",
        "content": "<p data-ke-size=\"size16\"><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">스프링 배치 (Spring Batch) 는 나에겐 애증의 기술이다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">포털 서비스에서 실시간 API와 캐싱에 최대한 집중하다가,</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"> </span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">(푸드) 커머스로 이직하고 나서 결제/정산 시스템을 다루다보니 배치 애플리케이션 작성이 너무 많이 필요했다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">그래서 스프링 배치를 공부하게 되었는데, 막상 자료가 너무 없었다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">정제된 책은 모두 다 해외 서적이였는데 그것 조차 8년전, 10년전이였다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">예전 선배님들이 공부하시던 자료는 이제는 기한이 지나 이제 커뮤니티에 남지 않았고,</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">공식 문서 외에는 대부분이 튜토리얼에 지나지 않았다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">실제 환경에서 겪어야 할 문제들을 Spring MVC, Spring Data 만큼 상세하게 정리된 자료들이 많지 않았다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">그래서 그때부터 나만의 Spring Batch In Action 시리즈를 써보자는 생각에</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"> </span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">현업에서 만난 문제들을 하나하나 정리하고,</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">새로 합류하는 팀원들을 위해 기초부터 차근차근 튜토리얼도 작성했다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">대형 서비스를 다루다보면 API 외에도 배치 애플리케이션 구현이 전체 기능의 절반을 이룰때도 있다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">이때 내가 정리한 자료들이 그 분들에게 큰 도움이 되길 바랬고,</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">실제로 많은 분들이 좋아해주셨다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">지금은 더이상 스프링 배치를 적극적으로 사용하고 있진 않지만</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"> </span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">(일부 시스템에서 사용하고 있다)</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">그래도 여전히 나는 스프링 배치 기술에 관심이 많다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">그만큼 애정을 쏟은 기술이니깐.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">그래서 누군가 스프링 배치 관련되서 정제된 자료를 공유하면 애정있게 자료들을 본다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">특히 그게 단순한 튜토리얼을 넘어 자신만의 경험과 스타일로 녹여냈다면 전우를 만난것처럼 기쁘다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">MVC, Data 에 관련된 자료가 대부분인 한국에서 Batch, Security 와 같이 정말 필요한데 많이들 관심 갖지 않는 기술에 대한 덕후들의 공감대라고 해야하나?</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"> </span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">그런면에서 <a href=\"https://inf.run/AQQCW\" target=\"_blank\" rel=\"noopener\">최근에 되게 재밌게 보고 있는 스프링 배치 강의</a>가 있다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">영상 강의가 아니라 텍스트 강의인데,</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"> </span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">왜 텍스트를 선택할 수 밖에 없었는지를 강의 초반부터 설명하는데 ㅋㅋ</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">컨셉이 아주 명확하다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"></span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"1.png\" data-origin-width=\"520\" data-origin-height=\"438\"><span data-url=\"https://blog.kakaocdn.net/dn/Fcmck/btsPAfAKsec/VD7DLr1kpo4k5CFqPGoFuk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Fcmck/btsPAfAKsec/VD7DLr1kpo4k5CFqPGoFuk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/Fcmck/btsPAfAKsec/VD7DLr1kpo4k5CFqPGoFuk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FFcmck%2FbtsPAfAKsec%2FVD7DLr1kpo4k5CFqPGoFuk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"520\" height=\"438\" data-filename=\"1.png\" data-origin-width=\"520\" data-origin-height=\"438\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">최근에 봤던 여러 스프링 배치 콘텐츠 중에서는 가장 재밌게 보고 있다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">설명도 아주 유쾌하게 하시고,</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"> </span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">보는 사람으로 하여금 나도 이 컨셉에 빠지고 싶다는 생각을 하게 만든다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">소개하는 내용도 실제 실무에서 필요한 대부분의 내용들을 다 처리하고 있다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">가격 역시 아주 훌륭하고.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">기본적으로 스프링 배치는 재밌는 기술은 아니다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">웹 기술이 아니여서 눈에 확확 보이는 것도 없고, console과 DB 저장 결과가 달라지는 것 외에는 확인할 방법이 마땅치 않다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">(그래서 테스트 코드를 적극적으로 사용해야하지만.)</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">그렇지만 일정 규모이상에서는 꼭 다뤄야할 기술 중 하나이다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">그간 배워온 웹 기술과는 전혀 반대편에 있는 이 기술을 가장 재밌게 배울 수 있는 강의라는 생각에 주변에 많이 추천하고 싶다.</span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span>강의보러가기: <a href=\"https://inf.run/AQQCW\" target=\"_blank\" rel=\"noopener\">https://inf.run/AQQCW</a><span style=\"background-color: #ffffff; color: #000000; text-align: start;\"><br /></span><span style=\"background-color: #ffffff; color: #000000; text-align: start;\">(본 게시물은 파트너스 활동의 일환으로 소정의 수수료를 받을 수 있습니다.)</span></p>",
        "contentSnippet": "스프링 배치 (Spring Batch) 는 나에겐 애증의 기술이다.\n포털 서비스에서 실시간 API와 캐싱에 최대한 집중하다가, \n(푸드) 커머스로 이직하고 나서 결제/정산 시스템을 다루다보니 배치 애플리케이션 작성이 너무 많이 필요했다.\n그래서 스프링 배치를 공부하게 되었는데, 막상 자료가 너무 없었다.\n정제된 책은 모두 다 해외 서적이였는데 그것 조차 8년전, 10년전이였다.\n예전 선배님들이 공부하시던 자료는 이제는 기한이 지나 이제 커뮤니티에 남지 않았고,\n공식 문서 외에는 대부분이 튜토리얼에 지나지 않았다.\n실제 환경에서 겪어야 할 문제들을 Spring MVC, Spring Data 만큼 상세하게 정리된 자료들이 많지 않았다.\n\n그래서 그때부터 나만의 Spring Batch In Action 시리즈를 써보자는 생각에 \n현업에서 만난 문제들을 하나하나 정리하고,\n새로 합류하는 팀원들을 위해 기초부터 차근차근 튜토리얼도 작성했다.\n\n대형 서비스를 다루다보면 API 외에도 배치 애플리케이션 구현이 전체 기능의 절반을 이룰때도 있다.\n이때 내가 정리한 자료들이 그 분들에게 큰 도움이 되길 바랬고,\n실제로 많은 분들이 좋아해주셨다.\n\n지금은 더이상 스프링 배치를 적극적으로 사용하고 있진 않지만 \n(일부 시스템에서 사용하고 있다)\n그래도 여전히 나는 스프링 배치 기술에 관심이 많다.\n그만큼 애정을 쏟은 기술이니깐.\n\n그래서 누군가 스프링 배치 관련되서 정제된 자료를 공유하면 애정있게 자료들을 본다.\n특히 그게 단순한 튜토리얼을 넘어 자신만의 경험과 스타일로 녹여냈다면 전우를 만난것처럼 기쁘다.\nMVC, Data 에 관련된 자료가 대부분인 한국에서 Batch, Security 와 같이 정말 필요한데 많이들 관심 갖지 않는 기술에 대한 덕후들의 공감대라고 해야하나? \n\n그런면에서 최근에 되게 재밌게 보고 있는 스프링 배치 강의가 있다.\n영상 강의가 아니라 텍스트 강의인데, \n왜 텍스트를 선택할 수 밖에 없었는지를 강의 초반부터 설명하는데 ㅋㅋ\n컨셉이 아주 명확하다.\n\n\n\n\n최근에 봤던 여러 스프링 배치 콘텐츠 중에서는 가장 재밌게 보고 있다.\n설명도 아주 유쾌하게 하시고, \n보는 사람으로 하여금 나도 이 컨셉에 빠지고 싶다는 생각을 하게 만든다.\n소개하는 내용도 실제 실무에서 필요한 대부분의 내용들을 다 처리하고 있다.\n가격 역시 아주 훌륭하고.\n\n기본적으로 스프링 배치는 재밌는 기술은 아니다.\n웹 기술이 아니여서 눈에 확확 보이는 것도 없고, console과 DB 저장 결과가 달라지는 것 외에는 확인할 방법이 마땅치 않다.\n(그래서 테스트 코드를 적극적으로 사용해야하지만.)\n\n그렇지만 일정 규모이상에서는 꼭 다뤄야할 기술 중 하나이다.\n그간 배워온 웹 기술과는 전혀 반대편에 있는 이 기술을 가장 재밌게 배울 수 있는 강의라는 생각에 주변에 많이 추천하고 싶다.\n\n강의보러가기: https://inf.run/AQQCW\n(본 게시물은 파트너스 활동의 일환으로 소정의 수수료를 받을 수 있습니다.)",
        "guid": "https://jojoldu.tistory.com/838",
        "categories": [
          "생각정리",
          "Inflearn",
          "Spring",
          "Spring Batch",
          "스프링 배치",
          "인프런"
        ],
        "isoDate": "2025-07-26T04:55:15.000Z"
      }
    ]
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": [
      {
        "creator": "megayuchi",
        "title": "non-raid구성+raid 구성을 위해 VMD Controller 부분적으로 활성화하기",
        "link": "https://megayuchi.com/2025/07/30/non-raid%ea%b5%ac%ec%84%b1raid-%ea%b5%ac%ec%84%b1%ec%9d%84-%ec%9c%84%ed%95%b4-vmd-controller-%eb%b6%80%eb%b6%84%ec%a0%81%ec%9c%bc%eb%a1%9c-%ed%99%9c%ec%84%b1%ed%99%94%ed%95%98%ea%b8%b0/",
        "pubDate": "Wed, 30 Jul 2025 10:18:42 +0000",
        "content:encodedSnippet": "여차저차 해서 결국 970 EVO 1TB가 2개 남는 상황이 됐다.\n이미 메인 데스크탑은 990Pro 2TB에 OS와 필요한 어플들 설치를  끝낸 상황이므로 이건 그대로 두고 970EVO 2개를 raid로 묶어서 추가하고 싶다.\n990 Pro에 OS설치할 때는 먼저 사용하던 RAID를 해제하고(VMD Controller 비활성화) AHCI모드로 돌려놓은 상태에서 990 pro에 Windows를 설치했었다.\n이 상태에서 SSD 2개를 추가해서 RAID묶겠다고 VMD Controller를 켜면 Windows 부팅이 안된다. 부팅하다가 boot device를 인식하지 못한다며 실패한다.\nWindows에 VMD드라이버(intel RST 드라이버)가 설치되지 않았기 때문이다. VMD Controller를 활성화하기 전에 Windows에 드라이버를 설치해줘야 한다.\n그런데 VMD Controller를 활성화하기 전에 intel RST드라이버를 설치하려고 해도 하드웨어적으로 VMD 장치가 확인되지 않기 때문에(활성화되어있지 않기 때문에) Windows에서 드라이버 설치가 안된다.\n부분적으로 2개 슬롯만 VMD 모드로 돌릴 수 있으면 좋겠다고 생각했는데 찾아보니 메인보드에 기능이 있다. OS설치된 SSD는 제외시키고 다른 2개의 SSD만 VMD Controller제어로 두고 부팅하면 부팅도 정상적으로 되고 RST드라이버도 설치 가능하다. 물론 2개의 SSD는 당장은 잡히지 않는다. RST드라이버를 설치한 후에는 VMD제어로 둔 SSD 2개도 다 인식된다.\n이후 다시 bios셋업으로 들어가서 raid로 묶으면 된다.\n이전에는 RAID로 묶을 때면 VMD Global Map을 켜 둔 상태로 두었다. 이게 기본상태였기 때문이다. 딱히 신경쓰진 않았가. 하지만 이렇게 하면 모든 PCI Root Port가 VMD Controller관리하로 들어간다.\nVMD Global Map을 끄면 PCI Root Port별로 VMD를 사용할지 AHCI모드를 사용할지 결정할 수 있다. 포트별로 Bus/Device/Fuction id가 표시되는데 이것으로 어떤 ssd를 제외시킬지 식별할 수 있다. 내 SSD가 어느 Root Port에 붙어있는지는 Windows 장치관리자에서 확인하면 된다.\n이렇게 해서 최종적으로 데탑은 990pro + 970evo x 2 raid0로 세팅을 완료했다.",
        "dc:creator": "megayuchi",
        "comments": "https://megayuchi.com/2025/07/30/non-raid%ea%b5%ac%ec%84%b1raid-%ea%b5%ac%ec%84%b1%ec%9d%84-%ec%9c%84%ed%95%b4-vmd-controller-%eb%b6%80%eb%b6%84%ec%a0%81%ec%9c%bc%eb%a1%9c-%ed%99%9c%ec%84%b1%ed%99%94%ed%95%98%ea%b8%b0/#respond",
        "content": "여차저차 해서 결국 970 EVO 1TB가 2개 남는 상황이 됐다. 이미 메인 데스크탑은 990Pro 2TB에 OS와 필요한 어플들 설치를 끝낸 상황이므로 이건 그대로 두고 970EVO 2개를 raid로 묶어서 추가하고 싶다. 990 Pro에 OS설치할 때는 먼저 사용하던 RAID를 해제하고(VMD Controller 비활성화) AHCI모드로 돌려놓은 상태에서 990 pro에 Windows를 설치했었다. 이 상태에서 SSD 2개를 추가해서 RAID묶겠다고 VMD Controller를 &#8230; <a class=\"more-link\" href=\"https://megayuchi.com/2025/07/30/non-raid%ea%b5%ac%ec%84%b1raid-%ea%b5%ac%ec%84%b1%ec%9d%84-%ec%9c%84%ed%95%b4-vmd-controller-%eb%b6%80%eb%b6%84%ec%a0%81%ec%9c%bc%eb%a1%9c-%ed%99%9c%ec%84%b1%ed%99%94%ed%95%98%ea%b8%b0/\">More <span class=\"screen-reader-text\">non-raid구성+raid 구성을 위해 VMD Controller 부분적으로&#160;활성화하기</span></a>",
        "contentSnippet": "여차저차 해서 결국 970 EVO 1TB가 2개 남는 상황이 됐다. 이미 메인 데스크탑은 990Pro 2TB에 OS와 필요한 어플들 설치를 끝낸 상황이므로 이건 그대로 두고 970EVO 2개를 raid로 묶어서 추가하고 싶다. 990 Pro에 OS설치할 때는 먼저 사용하던 RAID를 해제하고(VMD Controller 비활성화) AHCI모드로 돌려놓은 상태에서 990 pro에 Windows를 설치했었다. 이 상태에서 SSD 2개를 추가해서 RAID묶겠다고 VMD Controller를 … More non-raid구성+raid 구성을 위해 VMD Controller 부분적으로 활성화하기",
        "guid": "http://megayuchi.com/?p=7133",
        "categories": [
          "IT",
          "Pub",
          "컴퓨터일반",
          "RAID",
          "ssd",
          "Windows"
        ],
        "isoDate": "2025-07-30T10:18:42.000Z"
      },
      {
        "creator": "megayuchi",
        "title": "Resizable Bar & D3D12 GPU Upload Heaps",
        "link": "https://megayuchi.com/2025/07/27/resizable-bar-d3d12-gpu-upload-heaps/",
        "pubDate": "Sun, 27 Jul 2025 02:50:50 +0000",
        "content:encodedSnippet": "이전에 한번 발표했던 D3D12 GPU Upload Heaps 주제에 대해서 자료를 보강해서 최근에 다시 기술방송을 진행했습니다.",
        "dc:creator": "megayuchi",
        "comments": "https://megayuchi.com/2025/07/27/resizable-bar-d3d12-gpu-upload-heaps/#respond",
        "content": "이전에 한번 발표했던 D3D12 GPU Upload Heaps 주제에 대해서 자료를 보강해서 최근에 다시 기술방송을 진행했습니다.",
        "contentSnippet": "이전에 한번 발표했던 D3D12 GPU Upload Heaps 주제에 대해서 자료를 보강해서 최근에 다시 기술방송을 진행했습니다.",
        "guid": "http://megayuchi.com/?p=7127",
        "categories": [
          "Development",
          "D3D12",
          "DIrectX",
          "DirectX12",
          "DX12",
          "Game Development",
          "Game Engine Development",
          "GPU"
        ],
        "isoDate": "2025-07-27T02:50:50.000Z"
      }
    ]
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "DDD를 Merchant 시스템 구축에 활용한 사례를 소개합니다",
        "link": "https://techblog.lycorp.co.jp/ko/applying-ddd-to-merchant-system-development",
        "pubDate": "Mon, 28 Jul 2025 02:30:00 GMT",
        "content": "이제는 꽤나 대중적인 방법론으로 자리 잡은 DDD(domain driven design)는 도메인을 중심으로 소프트웨어를 모델링하는 데 중점을 둔 설계 접근 방식입니다.저는 DDD...",
        "contentSnippet": "이제는 꽤나 대중적인 방법론으로 자리 잡은 DDD(domain driven design)는 도메인을 중심으로 소프트웨어를 모델링하는 데 중점을 둔 설계 접근 방식입니다.저는 DDD...",
        "guid": "https://techblog.lycorp.co.jp/ko/applying-ddd-to-merchant-system-development",
        "isoDate": "2025-07-28T02:30:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": [
      {
        "title": "좋아요 멱등성: 올리브영, 무신사, 컬리는 어떻게 다르게 구현했을까?",
        "link": "https://velog.io/@sweet_sumin/%EC%A2%8B%EC%95%84%EC%9A%94-%EB%A9%B1%EB%93%B1%EC%84%B1-%EC%98%AC%EB%A6%AC%EB%B8%8C%EC%98%81-%EB%AC%B4%EC%8B%A0%EC%82%AC-%EC%BB%AC%EB%A6%AC%EB%8A%94-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%8B%A4%EB%A5%B4%EA%B2%8C-%EA%B5%AC%ED%98%84%ED%96%88%EC%9D%84%EA%B9%8C",
        "pubDate": "Fri, 25 Jul 2025 01:39:46 GMT",
        "content": "<p>개발자라면 한번쯤 들어봤을 멱등성~! 최근에 좋아요를 구현해보려고 하는데 각기 다른 서비스들은 과연 어떻게 구현하고 있을까가 궁금했다. 그래서 오늘은 &#39;좋아요&#39; 기능을 예시로 파고 들어가보려고 한다. 특히 올리브영,무신사,컬리가 멱등성을 보장하는 방식이 다른 것을 확인할 수 있었다. </p>\n<h1 id=\"멱등성이란\">멱등성이란?</h1>\n<p>멱등성은 같은 작업을 여러번 수행하더라도 항상 동일하게 유지되는 성질이다. 사용자의 실수로 버튼을 여러번 누르거나, 네트워크 불안정으로 요청이 중복 전송될때 시스템이 오작동하지 않도록 방지하는 중요한 개념이다. 즉, 좋아요 기능을 예시로 들자면, 좋아요를 여러번 눌러도 좋아요 개수가 계속 늘어나거나, 이미 좋아요를 취소했는데 다시 취소 요청이 들어와도 오류가 나지 않아야 한다는 의미이다. </p>\n<h1 id=\"비교\">비교</h1>\n<h2 id=\"올리브영\">올리브영</h2>\n<p>: POST (개별 액션 엔드포인트)\n올리브영은 좋아요(찜하기) 등록과 취소를 각각 다른 POST 엔드포인트를 통해 명확하게 구분하여 처리한다.</p>\n<h3 id=\"구현-방식-분석\">구현 방식 분석</h3>\n<ul>\n<li><p>좋아요(찜하기) 등록:</p>\n<ul>\n<li>메서드: POST</li>\n<li>엔드포인트: <a href=\"https://www.oliveyoung.co.kr/store/mypage/getWishListJson.do\">https://www.oliveyoung.co.kr/store/mypage/getWishListJson.do</a></li>\n<li>사용자가 상품을 찜할 때 이 엔드포인트로 요청을 보낸다.\n<img src=\"https://velog.velcdn.com/images/sweet_sumin/post/5fd1a8d0-dd01-4f47-9602-b76e18b08afc/image.png\" alt=\"\"></li>\n</ul>\n</li>\n<li><p>좋아요(찜하기) 취소:</p>\n<ul>\n<li>메서드: POST</li>\n<li>엔드포인트: <a href=\"https://www.oliveyoung.co.kr/store/mypage/delWishLstAjax.do\">https://www.oliveyoung.co.kr/store/mypage/delWishLstAjax.do</a></li>\n<li>사용자가 찜한 상품을 취소할 때 이 엔드포인트로 요청을 보낸다.\n<img src=\"https://velog.velcdn.com/images/sweet_sumin/post/51c04b49-403e-45ab-b4f3-b92170018806/image.png\" alt=\"\"><h3 id=\"장점\">장점</h3>\n</li>\n</ul>\n</li>\n<li><p>명확한 액션 구분: 각 API가 수행하는 액션(등록/삭제)이 URL에 명시적으로 드러나 개발자가 이해하기 쉽다. API의 목적이 URL에 담겨 직관적이다.</p>\n</li>\n<li><p>클라이언트의 명시적 제어: 클라이언트가 &#39;등록&#39;과 &#39;취소&#39;를 명확히 구분하여 요청을 보낼 수 있다.</p>\n</li>\n</ul>\n<h3 id=\"멱등성-보장\">멱등성 보장</h3>\n<p>POST는 본래 멱등성이 보장되지 않는다. 따라서 올리브영은 서버 측에서 다음과 같은 방식으로 멱등성을 보장할 것이라 &#39;예상&#39; 한다.</p>\n<ul>\n<li><p>등록 요청 시: 이미 해당 상품이 사용자의 찜 목록에 있다면, 중복으로 추가하지 않고 성공 응답을 반환한다. 데이터베이스의 고유 제약 조건(Unique Constraint)을 활용하여 중복 저장을 방지하는 것이 일반적이다.</p>\n</li>\n<li><p>취소 요청 시: 해당 상품이 찜 목록에 없다면, 삭제할 것이 없으므로 아무것도 하지 않고 성공 응답을 반환한다.</p>\n</li>\n<li><p>동시성 제어: 여러 번의 요청이 거의 동시에 들어올 경우, 서버는 내부적으로 트랜잭션 또는 락(Lock)을 통해 한 번의 처리만 보장한다.</p>\n</li>\n</ul>\n<h2 id=\"무신사\">무신사</h2>\n<p>: POST (단일 엔드포인트 &amp; Body로 액션 구분)\n무신사는 &#39;좋아요(찜하기)&#39; 등록과 취소를 하나의 POST 엔드포인트로 처리하되, 요청 본문(Body)의 데이터로 실제 수행할 액션(등록 또는 취소)을 구분한다.</p>\n<h3 id=\"구현-방식-분석-1\">구현 방식 분석</h3>\n<ul>\n<li>메서드: POST</li>\n<li>엔드포인트: <a href=\"https://log.data.musinsa.com/log/user-event/v2_cart_purchase_like\">https://log.data.musinsa.com/log/user-event/v2_cart_purchase_like</a>\n<img src=\"https://velog.velcdn.com/images/sweet_sumin/post/6087340c-ae5f-4bf9-92af-0167dc078faf/image.png\" alt=\"\"></li>\n</ul>\n<ul>\n<li><p>액션 구분: 등록시</p>\n<ul>\n<li>요청 본문 data 내에 event_name: &quot;add_to_wishlist&quot; 포함\n<img src=\"https://velog.velcdn.com/images/sweet_sumin/post/40ece9f9-888c-4022-b66d-cfa2a661aa90/image.png\" alt=\"\"></li>\n</ul>\n</li>\n<li><p>액션 구분: 취소 시</p>\n<ul>\n<li>요청 본문 data 내에 event_name: &quot;remove_from_wishlist&quot; 포함\n<img src=\"https://velog.velcdn.com/images/sweet_sumin/post/4a137a2a-e912-4943-b4a9-fd6cd9acc425/image.png\" alt=\"\"></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"장점-1\">장점</h3>\n<ul>\n<li><p>단일 API 엔드포인트: 클라이언트가 &#39;찜하기&#39; 관련 기능을 하나의 URL로 관리할 수 있다.</p>\n<h3 id=\"멱등성-보장-1\">멱등성 보장</h3>\n<p>POST는 멱등성을 가지지 않으므로, 무신사도 서버 측에서 멱등성을 보장해야 한다. 이는 올리브영의 개별 POST 엔드포인트 방식과 유사할 것이라 예상한다.</p>\n</li>\n<li><p>요청 본문 분석: 서버는 event_name 값을 확인하여 &#39;add&#39; 요청인지 &#39;remove&#39; 요청인지 파악한다.</p>\n</li>\n<li><p>현재 상태 확인 및 조건부 처리:</p>\n<ul>\n<li>add_to_wishlist 요청 시: 이미 찜 목록에 있다면 중복 추가하지 않고 성공 응답.</li>\n<li>remove_from_wishlist 요청 시: 찜 목록에 없다면 삭제하지 않고 성공 응답.</li>\n</ul>\n</li>\n<li><p>동시성 제어: 여러 번의 중복 요청에 대해 데이터 정합성을 유지하기 위한 서버 내부 로직(고유 제약, 락 등)이 필요하다.</p>\n</li>\n</ul>\n<h1 id=\"컬리\">컬리</h1>\n<p>: PUT (단일 엔드포인트 &amp; Body로 상태 변경)\n컬리는 &#39;좋아요(찜하기)&#39; 상태 변경을 PUT 메서드를 사용하고, 요청 본문(Body)에 최종적인 찜 상태를 true 또는 false로 명시하는 방식을 사용한다.</p>\n<h2 id=\"구현-방식-분석-2\">구현 방식 분석</h2>\n<ul>\n<li><p>메서드: PUT</p>\n</li>\n<li><p>엔드포인트: <a href=\"https://api.kurly.com/member/proxy/pick/v1/picks/products/%7BproductId%7D\">https://api.kurly.com/member/proxy/pick/v1/picks/products/{productId}</a> ( {productId}는 실제 상품 ID)\n<img src=\"https://velog.velcdn.com/images/sweet_sumin/post/87ed3d65-4a1f-4ed0-a158-0c2790b5d49d/image.png\" alt=\"\"></p>\n</li>\n<li><p>상태 구분:</p>\n</li>\n</ul>\n<p>찜하기 설정 시: 요청 본문 {&quot;is_pick&quot;: true}\n<img src=\"https://velog.velcdn.com/images/sweet_sumin/post/909ef081-3786-4d56-9cc7-d461e8e0490d/image.png\" alt=\"\"></p>\n<p>찜하기 해제 시: 요청 본문 {&quot;is_pick&quot;: false}\n<img src=\"https://velog.velcdn.com/images/sweet_sumin/post/b3627e84-0840-479a-96f0-3009c70832b7/image.png\" alt=\"\"></p>\n<h3 id=\"장점-2\">장점</h3>\n<p>PUT 메서드의 멱등성 활용: PUT 메서드는 자원의 전체를 갱신하는 의미를 가지며 그 자체가 멱등성을 보장한다. 같은 요청을 여러 번 보내도 자원의 최종 상태(찜 여부)는 항상 동일하게 유지된다. 이는 서버 측 멱등성 구현 부담을 줄여준다.</p>\n<p>단일 API 엔드포인트 &amp; 상태 주도: 클라이언트는 현재 찜 상태와 관계없이 원하는 최종 상태만 is_pick: true 또는 is_pick: false로 전달하면 된다. 클라이언트 로직이 비교적 간결하다.</p>\n<h3 id=\"멱등성-보장-2\">멱등성 보장</h3>\n<p>PUT 메서드 자체가 멱등성을 보장하므로, 서버는 요청 본문의 is_pick 값에 따라 단순히 해당 상품의 찜 상태를 &#39;설정&#39; 또는 &#39;해제&#39;하면 된다. 중복 요청이 들어와도 결과는 동일하다.</p>\n<h2 id=\"그렇다면-어떤-방법이-더-나을까\">그렇다면, 어떤 방법이 &#39;더&#39; 나을까?</h2>\n<p>세 가지 방법 모두 멱등성을 성공적으로 보장한다. 어떤 방법이 &#39;더 좋다&#39;고 단정하기는 어려우며, 이는 API 설계 철학, 개발팀의 선호도, 그리고 서비스의 특성에 따라 달라질 수 있다.</p>\n<ul>\n<li><p>올리브영의 POST (개별 액션): API의 명시성과 직관성을 중요하게 생각하는 경우 유리하다. 각 URL이 어떤 액션을 수행하는지 명확하다. POST의 멱등성은 서버 측에서 견고하게 처리해야 한다.</p>\n</li>\n<li><p>무신사의 POST (단일 &amp; Body 구분): 단일 엔드포인트를 선호하면서도 POST 메서드를 사용해야 할 때 선택할 수 있는 방식이다. 특히 이벤트 로깅 시스템과 연동이 필요할 때 유용할 수 있다. 역시 POST 멱등성은 서버가 보장한다.</p>\n</li>\n<li><p>컬리의 PUT (단일 &amp; Body로 상태 변경): HTTP 메서드의 멱등성 속성을 적극적으로 활용하여 서버 측 구현의 복잡성을 줄이고 싶을 때 이상적이다. &#39;찜하기&#39; 상태를 특정 리소스의 속성으로 보고 이를 업데이트하는 RESTful 한 방식에 가깝다.</p>\n</li>\n</ul>\n<p>궁극적으로 중요한 것은 어떤 방식을 선택하든 시스템의 신뢰성을 위해 멱등성이 완벽하게 보장되도록 설계하고 구현하는 것이라 생각한다. 다만 흥미로웠던 점은 같은 기능이 각기 서비스마다 다른 형태를 보였다는 것이다. 이를 통해 같은 방향을 추구하지만 정답이 없음을 다시한번 느꼈다. </p>\n",
        "contentSnippet": "개발자라면 한번쯤 들어봤을 멱등성~! 최근에 좋아요를 구현해보려고 하는데 각기 다른 서비스들은 과연 어떻게 구현하고 있을까가 궁금했다. 그래서 오늘은 '좋아요' 기능을 예시로 파고 들어가보려고 한다. 특히 올리브영,무신사,컬리가 멱등성을 보장하는 방식이 다른 것을 확인할 수 있었다. \n멱등성이란?\n멱등성은 같은 작업을 여러번 수행하더라도 항상 동일하게 유지되는 성질이다. 사용자의 실수로 버튼을 여러번 누르거나, 네트워크 불안정으로 요청이 중복 전송될때 시스템이 오작동하지 않도록 방지하는 중요한 개념이다. 즉, 좋아요 기능을 예시로 들자면, 좋아요를 여러번 눌러도 좋아요 개수가 계속 늘어나거나, 이미 좋아요를 취소했는데 다시 취소 요청이 들어와도 오류가 나지 않아야 한다는 의미이다. \n비교\n올리브영\n: POST (개별 액션 엔드포인트)\n올리브영은 좋아요(찜하기) 등록과 취소를 각각 다른 POST 엔드포인트를 통해 명확하게 구분하여 처리한다.\n구현 방식 분석\n좋아요(찜하기) 등록:\n메서드: POST\n엔드포인트: https://www.oliveyoung.co.kr/store/mypage/getWishListJson.do\n사용자가 상품을 찜할 때 이 엔드포인트로 요청을 보낸다.\n\n좋아요(찜하기) 취소:\n메서드: POST\n엔드포인트: https://www.oliveyoung.co.kr/store/mypage/delWishLstAjax.do\n사용자가 찜한 상품을 취소할 때 이 엔드포인트로 요청을 보낸다.\n\n장점\n명확한 액션 구분: 각 API가 수행하는 액션(등록/삭제)이 URL에 명시적으로 드러나 개발자가 이해하기 쉽다. API의 목적이 URL에 담겨 직관적이다.\n클라이언트의 명시적 제어: 클라이언트가 '등록'과 '취소'를 명확히 구분하여 요청을 보낼 수 있다.\n멱등성 보장\nPOST는 본래 멱등성이 보장되지 않는다. 따라서 올리브영은 서버 측에서 다음과 같은 방식으로 멱등성을 보장할 것이라 '예상' 한다.\n등록 요청 시: 이미 해당 상품이 사용자의 찜 목록에 있다면, 중복으로 추가하지 않고 성공 응답을 반환한다. 데이터베이스의 고유 제약 조건(Unique Constraint)을 활용하여 중복 저장을 방지하는 것이 일반적이다.\n취소 요청 시: 해당 상품이 찜 목록에 없다면, 삭제할 것이 없으므로 아무것도 하지 않고 성공 응답을 반환한다.\n동시성 제어: 여러 번의 요청이 거의 동시에 들어올 경우, 서버는 내부적으로 트랜잭션 또는 락(Lock)을 통해 한 번의 처리만 보장한다.\n무신사\n: POST (단일 엔드포인트 & Body로 액션 구분)\n무신사는 '좋아요(찜하기)' 등록과 취소를 하나의 POST 엔드포인트로 처리하되, 요청 본문(Body)의 데이터로 실제 수행할 액션(등록 또는 취소)을 구분한다.\n구현 방식 분석\n메서드: POST\n엔드포인트: https://log.data.musinsa.com/log/user-event/v2_cart_purchase_like\n\n액션 구분: 등록시\n요청 본문 data 내에 event_name: \"add_to_wishlist\" 포함\n\n액션 구분: 취소 시\n요청 본문 data 내에 event_name: \"remove_from_wishlist\" 포함\n\n장점\n단일 API 엔드포인트: 클라이언트가 '찜하기' 관련 기능을 하나의 URL로 관리할 수 있다.\n멱등성 보장\nPOST는 멱등성을 가지지 않으므로, 무신사도 서버 측에서 멱등성을 보장해야 한다. 이는 올리브영의 개별 POST 엔드포인트 방식과 유사할 것이라 예상한다.\n요청 본문 분석: 서버는 event_name 값을 확인하여 'add' 요청인지 'remove' 요청인지 파악한다.\n현재 상태 확인 및 조건부 처리:\nadd_to_wishlist 요청 시: 이미 찜 목록에 있다면 중복 추가하지 않고 성공 응답.\nremove_from_wishlist 요청 시: 찜 목록에 없다면 삭제하지 않고 성공 응답.\n동시성 제어: 여러 번의 중복 요청에 대해 데이터 정합성을 유지하기 위한 서버 내부 로직(고유 제약, 락 등)이 필요하다.\n컬리\n: PUT (단일 엔드포인트 & Body로 상태 변경)\n컬리는 '좋아요(찜하기)' 상태 변경을 PUT 메서드를 사용하고, 요청 본문(Body)에 최종적인 찜 상태를 true 또는 false로 명시하는 방식을 사용한다.\n구현 방식 분석\n메서드: PUT\n엔드포인트: https://api.kurly.com/member/proxy/pick/v1/picks/products/{productId} ( {productId}는 실제 상품 ID)\n\n상태 구분:\n찜하기 설정 시: 요청 본문 {\"is_pick\": true}\n\n찜하기 해제 시: 요청 본문 {\"is_pick\": false}\n\n장점\nPUT 메서드의 멱등성 활용: PUT 메서드는 자원의 전체를 갱신하는 의미를 가지며 그 자체가 멱등성을 보장한다. 같은 요청을 여러 번 보내도 자원의 최종 상태(찜 여부)는 항상 동일하게 유지된다. 이는 서버 측 멱등성 구현 부담을 줄여준다.\n단일 API 엔드포인트 & 상태 주도: 클라이언트는 현재 찜 상태와 관계없이 원하는 최종 상태만 is_pick: true 또는 is_pick: false로 전달하면 된다. 클라이언트 로직이 비교적 간결하다.\n멱등성 보장\nPUT 메서드 자체가 멱등성을 보장하므로, 서버는 요청 본문의 is_pick 값에 따라 단순히 해당 상품의 찜 상태를 '설정' 또는 '해제'하면 된다. 중복 요청이 들어와도 결과는 동일하다.\n그렇다면, 어떤 방법이 '더' 나을까?\n세 가지 방법 모두 멱등성을 성공적으로 보장한다. 어떤 방법이 '더 좋다'고 단정하기는 어려우며, 이는 API 설계 철학, 개발팀의 선호도, 그리고 서비스의 특성에 따라 달라질 수 있다.\n올리브영의 POST (개별 액션): API의 명시성과 직관성을 중요하게 생각하는 경우 유리하다. 각 URL이 어떤 액션을 수행하는지 명확하다. POST의 멱등성은 서버 측에서 견고하게 처리해야 한다.\n무신사의 POST (단일 & Body 구분): 단일 엔드포인트를 선호하면서도 POST 메서드를 사용해야 할 때 선택할 수 있는 방식이다. 특히 이벤트 로깅 시스템과 연동이 필요할 때 유용할 수 있다. 역시 POST 멱등성은 서버가 보장한다.\n컬리의 PUT (단일 & Body로 상태 변경): HTTP 메서드의 멱등성 속성을 적극적으로 활용하여 서버 측 구현의 복잡성을 줄이고 싶을 때 이상적이다. '찜하기' 상태를 특정 리소스의 속성으로 보고 이를 업데이트하는 RESTful 한 방식에 가깝다.\n궁극적으로 중요한 것은 어떤 방식을 선택하든 시스템의 신뢰성을 위해 멱등성이 완벽하게 보장되도록 설계하고 구현하는 것이라 생각한다. 다만 흥미로웠던 점은 같은 기능이 각기 서비스마다 다른 형태를 보였다는 것이다. 이를 통해 같은 방향을 추구하지만 정답이 없음을 다시한번 느꼈다.",
        "guid": "https://velog.io/@sweet_sumin/%EC%A2%8B%EC%95%84%EC%9A%94-%EB%A9%B1%EB%93%B1%EC%84%B1-%EC%98%AC%EB%A6%AC%EB%B8%8C%EC%98%81-%EB%AC%B4%EC%8B%A0%EC%82%AC-%EC%BB%AC%EB%A6%AC%EB%8A%94-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%8B%A4%EB%A5%B4%EA%B2%8C-%EA%B5%AC%ED%98%84%ED%96%88%EC%9D%84%EA%B9%8C",
        "isoDate": "2025-07-25T01:39:46.000Z"
      }
    ]
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "국도에서 고속도로로",
        "link": "https://www.thestartupbible.com/2025/07/re-entering-the-freeway.html",
        "pubDate": "Wed, 30 Jul 2025 21:35:00 +0000",
        "content:encodedSnippet": "전에 한번 비슷한 이야기를 한 적이 있는데, 내가 봤을 때 지금이 시의적절한 타이밍이라서 다시 한번 내 생각을 포스팅해 본다.\n2022년 후반부터 시작된 벤처 겨울은 아직도 진행 중이지만, 이제 최악의 추위로부터 우린 조금씩 멀어지고 있지 않나 싶다. AI 투자 덕분에 외형적으론 글로벌 벤처 투자는 2024년 Q3($57B)부터 2025년 Q1($121B) 까지 연속 3사분기 상승 중이다. 실은 벤처투자가 증가하고 있다는 건 VC들에게 자금을 제공하는 LP들도 더 활발하게 투자하고 있다는 간접적인 증거이기 때문에 여러모로 좋은 시그널이다. 하지만, 너무 많은 돈이 극소수의 AI 회사에 투입되고 있다는 건 – 예를 들면, 2025년 Q1 전체 글로벌 벤처 투자금 $121B 중 거의 3분의 1인 $40B이 OpenAI 단 한 개의 회사에 투입됐다 – 아직도 뭔가 불안하고 찜찜하지만, 어쨌든 부정적인 것보단 긍정적인 신호라고 생각한다.\n한국도 여기저기서 긍정적인 소식이 들려온다. 새로운 정부가 AI에 100조 원을 투자하겠다고 발표했고, 벤처 투자 생태계에도 40조 원가량의 자금을 투입하겠다고 했다. 솔직히 말해서 이 돈을 어디서 어떻게 조달할진 잘 모르겠지만, 긍정적인 소식이며, 하반기에는 유동성이 조금씩 풀리지 않을까 기대한다. 정부가 벤처 투자를 리딩하는 건 장기적으론 부정적인 면도 많지만, 반면에 현재와 같은 위기 상황에서는 정부가 이렇게 시원하게 쏘는 것만큼 단기적으론 좋은 방법도 없다고 생각한다.\n이런 시그널이 보이는 분위기에서 요새 나는 우리 창업가분들에게 다음과 같은 조언을 하고 있다.\n첫째, 2022년 후반부터 성장보단 생존과 수익성에 집중하고 있는 회사 중, 아직도 비용을 못 줄여서 매달 마이너스가 나고, 명확하게 공식화할 수 없는 PMF와 비즈니스 모델을 못 찾은 분들에겐 계속하던 대로 성장보단 생존에 집중하라고 한다. 이런 회사들은 아직도 한 달 벌어 한 달 먹고사는 곳들이 많아서 계속 비용 절감과 비즈니스 모델 확립에 집중해야 한다. 운전에 비유하자면, 고속도로보단 계속 국도로 달리는 것이다. 국도에서 가속하지 말고, 정속 주행을 통해서 기름을 아끼는 전략이다. 하지만, 조금씩 천천히 앞으로 가곤 있다.\n둘째, 2022년 후반부터 성장보단 생존과 수익성에 집중하면서 지난 3년 동안 비용 절감에 성공해서 흑자 전환을 했고, 어떻게 하면 확실하게 돈을 벌 수 있는지 공식화할 수 있는 비즈니스 모델과 PMF를 찾았다면, 이제 다시 서서히 성장에 대해 고민해 보라고 한다. 운전에 비유하자면, 이제 국도를 서서히 벗어나면서 다시 고속도로에 진입해서 악셀러레이터를 힘차게 밟아보는 것이다. 하지만, 그렇다고 대책 없이 돈을 써서 마이너스를 내면서 성장하라는 조언은 아니다. 지금까지 만들어 놓은 좋은 비즈니스 모델을 돈을 버는 프레임 안에서 더 가속하라는 조언이다.\n이렇게 국도에서 다시 고속도로로 진입하려면 돈도 더 필요하고, 어쩌면 사람도 더 필요한데, 이보다 더 중요한 건, 창업가의 마인드와 태도의 180도 변화이다. 너무 오랫동안 국도만 달렸기 때문에 다시 고속도로로 진입해서 그동안 시속 50km를 넘지 않았던 악셀러레이터를 더 밟아서 80km 이상으로 달려야 하는데, 다시 성장 모드로 마인드를 바꾸는 게 쉽지 않다. 회사의 전략과 방향을 180도 다르게 설정하는 데에도 switching cost가 발생하지만, 실은 가장 극복하기 어려운 건 창업가의 두려움이다. 이미 지난 3년 동안 돈이 없으면 얼마나 사업이 힘들어지는지 뼈저리게 경험하고 배웠기 때문에 다시 성장에 집중하는 게 너무 공포스러울 수도 있을 것이다. 성장에 집중하려면, 펀드레이징도 다시 해야 하고, 더 많은 돈을 써야 하는데, 혹시라도 이렇게 하는 과정에서 돈을 다 써서 다시 힘든 시점이 오면, 그땐 다시 한번 어려움을 극복할 수 있는 체력과 정신력이 남아 있을지,,,그 생각만 해도 공황장애가 오기 때문이다.\n아직 제대로 된 비즈니스 모델을 못 찾았다면, 계속 비용 절감하면서 생존에 집중해라. 이런 사업이면 어차피 고속도로에 진입해도 속력도 못 내고 금세 연료가 떨어져서 멈출 것이다. 하지만, 이제 돈을 확실하게 벌 수 있는 사업을 만들었다면 위에서 말한 두려움을 떨쳐내고 과감하게 고속도로에 진입해라. 그리고 다시 쌩쌩 달릴 수 있는 방법을 찾아야 한다. 어차피 스타트업이란 어느 시점엔 성장을 해야 하는데, 이미 3년이라는 시간을 까먹었기 때문에 따라잡아야 하는 거리가 상당히 많이 남았을 것이다. 다시 한번 용기를 내어보자.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/07/re-entering-the-freeway.html#respond",
        "content": "전에 한번 비슷한 이야기를 한 적이 있는데, 내가 봤을 때 지금이 시의적절한 타이밍이라서 다시 한번 내 생각을 포스팅해 본다. 2022년 후반부터 시작된 벤처 겨울은 아직도 진행 중이지만, 이제 최악의 추위로부터 우린 조금씩 멀어지고 있지 않나 싶다. AI 투자 덕분에 외형적으론 글로벌 벤처 투자는 2024년 Q3($57B)부터 2025년 Q1($121B) 까지 연속 3사분기 상승 중이다. 실은 벤처투자가 증가하고(...)",
        "contentSnippet": "전에 한번 비슷한 이야기를 한 적이 있는데, 내가 봤을 때 지금이 시의적절한 타이밍이라서 다시 한번 내 생각을 포스팅해 본다. 2022년 후반부터 시작된 벤처 겨울은 아직도 진행 중이지만, 이제 최악의 추위로부터 우린 조금씩 멀어지고 있지 않나 싶다. AI 투자 덕분에 외형적으론 글로벌 벤처 투자는 2024년 Q3($57B)부터 2025년 Q1($121B) 까지 연속 3사분기 상승 중이다. 실은 벤처투자가 증가하고(...)",
        "guid": "https://www.thestartupbible.com/?p=9514",
        "categories": [
          "Uncategorized",
          "failure",
          "FoundersAtWork",
          "fundraising",
          "technology"
        ],
        "isoDate": "2025-07-30T21:35:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "네 시작은 미약하나,,,",
        "link": "https://www.thestartupbible.com/2025/07/though-your-beginning-was-small.html",
        "pubDate": "Sun, 27 Jul 2025 21:35:00 +0000",
        "content:encodedSnippet": "2025년 7월 15일은 한국의 국민 앱 중 하나가 된 당근의 창립 10주년이었다. 원래 이런 걸 잘 안 챙기는 회사인데, 10년이라는 기간은 나름 대단한 마일스톤이라서 한강 세빛둥둥섬에서 10주년 행사를 했다. 나도 초대받아서 잠깐 참석했는데, 마치 내가 만든 회사인 것처럼 너무 자랑스럽고 뿌듯해서, 기록 차원에서 여기에 몇 자 남겨본다.\n일단 세빛둥둥섬 주차장에서 봤을 때, 멀리서부터 거대한 당근 로고가 보였고, 당근 현수막이 걸린 입구를 걸어가는데, 여러 가지 생각이 내 머릿속과 기억을 스치면서, “와, 당근이 이제 괴물이 됐구나.(좋은 의미로).”라는 말이 나도 모르게 나올 정도로 그 규모에 압도당했다. 행사장 안에 들어가서, 엄청나게 많은 임직원분에 다시 한번 압도당했다. 강당을 꽉 채운 당근 임직원분들의 규모가 500명이었는데, 회사의 월간 업데이트에 항상 임직원 수를 알려주지만, PDF 상의 ‘500명’ 숫자를 보는 것과 직접 이렇게 500명을 한자리에서 보는 건 완전히 다른 경험이었다.\n우리는 당근에 2016년도 12월에 투자했다. 카카오벤처스, 캡스톤파트너스와 스트롱이 당근의 첫 번째 기관 투자자였는데, 내 기억으론 당시 당근은 8명의 작은 팀이었다. 내 기억으론, 이 8명의 첫 번째인가 두 번째 사무실이 판교의 꼬마 빌딩의 2층 공간이었는데, 들어갈 때 슬리퍼로 갈아 신는 아주 아담한 사무실이었고, 이것도 내 기억이긴 한데, 한겨울엔 창문 사이로 외풍이 불어서 약간 춥기도 했던 그런 곳이었다. 사람의 뇌는 첫인상을 강력하게 기억한다고 하는데, 나는 당근을 생각하면 항상 판교의 이 작은 사무실의 8명의 이미지가 가장 먼저 생각난다.\n이 8명이 있던 회사가 500명이 넘은 회사가 됐다. 그 많은 임직원분을 보니 뭔가 비현실적이기까지 했는데, 이분들이 발산하는 에너지가 마치 아우라를 만드는 것 같다는 착각까지 할 정도로 역동적인 행사장이었다.\n당근의 시작은 미약했다. 내가 처음부터 봤기 때문에 잘 안다. 그 끝은 창대할까? 그건 아직은 잘 모르겠지만, 지금까진 아주 잘하고 있다. 하지만, 끝을 보려면 아직 한참 멀었다. 왜냐하면 이 회사는 이제 막 시동이 걸렸고, extraordinary한 회사로 가는 당근의 여정은 이제 막 시작했기 때문이다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/07/though-your-beginning-was-small.html#respond",
        "content": "2025년 7월 15일은 한국의 국민 앱 중 하나가 된 당근의 창립 10주년이었다. 원래 이런 걸 잘 안 챙기는 회사인데, 10년이라는 기간은 나름 대단한 마일스톤이라서 한강 세빛둥둥섬에서 10주년 행사를 했다. 나도 초대받아서 잠깐 참석했는데, 마치 내가 만든 회사인 것처럼 너무 자랑스럽고 뿌듯해서, 기록 차원에서 여기에 몇 자 남겨본다. 일단 세빛둥둥섬 주차장에서 봤을 때, 멀리서부터 거대한 당근(...)",
        "contentSnippet": "2025년 7월 15일은 한국의 국민 앱 중 하나가 된 당근의 창립 10주년이었다. 원래 이런 걸 잘 안 챙기는 회사인데, 10년이라는 기간은 나름 대단한 마일스톤이라서 한강 세빛둥둥섬에서 10주년 행사를 했다. 나도 초대받아서 잠깐 참석했는데, 마치 내가 만든 회사인 것처럼 너무 자랑스럽고 뿌듯해서, 기록 차원에서 여기에 몇 자 남겨본다. 일단 세빛둥둥섬 주차장에서 봤을 때, 멀리서부터 거대한 당근(...)",
        "guid": "https://www.thestartupbible.com/?p=9509",
        "categories": [
          "Uncategorized",
          "B2C",
          "FoundersAtWork",
          "korea",
          "mobile",
          "people",
          "Strong"
        ],
        "isoDate": "2025-07-27T21:35:00.000Z"
      }
    ]
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "토스, ‘2025 토스 NEXT 개발자 챌린지’ 접수 시작 ",
        "link": "https://toss.im/tossfeed/article/2025next",
        "pubDate": "Wed, 30 Jul 2025 05:09:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}신입 개발자 위한 실력 중심 채용 프로그램… 총 5개 분야에서 최대 50명 영입 목표\n오는 8월 7일까지 10일 간 서류 접수… 8월 9일 코딩 테스트 및 과제 전형 진행\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n토스(운영사 비바리퍼블리카, 대표 이승건)가 경력 3년 이하 개발자를 채용하는 '2025 토스 NEXT 개발자 챌린지(이하 NEXT 개발자 챌린지)' 서류 접수를 29일부터 시작했다고 30일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n올해로 6회째를 맞은 'NEXT 개발자 챌린지'는 신입 개발자를 위한 실력 중심의 채용 프로그램이다. 개발 과제를 통해 자신의 역량과 업무 적합성을 직접 입증할 수 있다는 점이 특징이다. 실제로 해당 전형을 통해 입사한 팀원들은 서비스 개선, 핵심 기능 개발 등 실질적인 업무에 즉시 투입된다. 때문에 NEXT 개발자 챌린지는 실무 이력과 관계없이 기술적 가능성을 확인할 수 있는 채용 경로로 자리잡고 있다.\n이번 채용은 최대 50명 영입을 목표로 한다. 모집 직군은 △서버(Server) △프론트엔드(Frontend) △안드로이드 △iOS △노드제이에스(Node.js) 개발 등 5개다. 특히 올해는 토스인컴이 처음으로 참여해 토스, 토스증권, 토스뱅크, 토스플레이스을 포함한 5개의 토스 계열 법인이 함께한다.\n서류 접수는 오는 8월 7일 23시 59분까지 NEXT 개발자 챌린지 공식 홈페이지에서 할 수 있다. 8월 9일에는 서류 제출자를 대상으로 온라인 코딩 테스트를 비롯한 개발 과제 전형이 진행된다. 과제는 실제 서비스 운영을 함께할 개발자를 찾기 위한 실무 중심 문제로 구성된다.\n전형 결과는 서버 직군이 8월 18일, 그 외 4개 직군의 경우 8월 12일에 발표된다. 이후 전형은 직무 인터뷰, 문화적합성 인터뷰, 레퍼런스 체크 순서로 이어지며, 직군에 따라 사전 과제 전형이 추가될 수 있다. 최종 합격자는 10월 중순에 입사할 예정이다.\n토스 관계자는 \"NEXT 개발자 챌린지’는 경력보다 문제 해결력을 중시하는 토스 채용 원칙이 반영된 성공적인 인재 발굴 사례”라며, \"앞으로도 토스는 실력과 잠재력을 갖춘 핵심 인재를 적극 확보하고, 역량을 마음껏 펼칠 수 있는 환경을 제공해 서비스 경쟁력을 높여 가겠다”고 밝혔다.\n한편, 전형에 대한 보다 자세한 내용은 ‘2025 토스 NEXT 개발자 챌린지’ 공식 홈페이지에서 확인 가능하다. 해당 페이지에서는 채용 전형 안내와 본 프로그램을 통해 토스에 합류한 팀원들의 인터뷰 아티클 및 후기 영상이 함께 제공된다.",
        "content": "총 5개 분야에서 경력 3년 이하 개발자 최대 50명 영입 목표",
        "contentSnippet": "총 5개 분야에서 경력 3년 이하 개발자 최대 50명 영입 목표",
        "guid": "https://toss.im/tossfeed/article/2025next",
        "isoDate": "2025-07-30T05:09:00.000Z"
      },
      {
        "title": "토스, 넵튠과 ‘HTML5 게임 챌린지’ 개최",
        "link": "https://toss.im/tossfeed/article/HTML5",
        "pubDate": "Tue, 29 Jul 2025 16:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}HTML5 창작 게임 공모…8월 25일부터 11월 3일까지 참가 접수\n개인부터 팀 단위 스튜디오까지 누구나 참여 가능…총 상금 7천만원\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n모바일 금융 플랫폼 토스(운영사 비바리퍼블리카, 대표 이승건)가 모바일 게임사 넵튠과 공동으로 게임 공모전 ‘토스 HTML5 게임 챌린지 with 넵튠’을 개최한다고 30일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n이번 공모전은 창의적인 게임 콘텐츠를 발굴하고 지원하기 위해 마련됐다. 공동 주최사인 넵튠은 ‘무한의 계단’, ‘고양이 스낵바’ 등이 대표작인 모바일 게임 전문 기업으로, 창의성과 대중성을 바탕으로 다양한 캐주얼 게임을 개발해왔다.\n공모 대상은 HTML5 기반으로 제작된 창작 게임이다. 고스톱이나 오목 등 보드 게임류를 제외한 하이퍼 캐주얼 게임부터 RPG 장르까지 자유롭게 출품할 수 있다. 개인 개발자, 팀 단위의 소규모 스튜디오 등 누구나 참여할 수 있으며 출품 수나 참가 횟수에는 제한이 없다.\n참가 접수는 2025년 8월 25일부터 11월 3일까지 진행된다. 앱인토스 홈페이지 내 공식 콘솔을 통해 게임 빌드를 제출하면 된다. 출품작은 제3자의 지식재산권을 침해하지 않은 순수 창작물이어야 하며, 참가자에게 모든 IP 권리가 귀속되어 있어야 한다. 출품 이후 게임 라이브를 위해서는 게임 연령 등급을 필수로 받아야 한다.\n접수 기간 종료 후 11월 24일부터 약 3주간의 심사를 거쳐 최종 수상작이 발표될 예정이다. 총 상금은 7천만 원 규모로 1등에게는 3천만 원, 2등 2천만 원, 3등 1천만 원이 수여되며, 장려상 5개 팀에게는 각 200만 원씩 지급한다.\n또한 퍼블리싱 계약 체결이나 추진 중인 이력이 없는 비상업용 게임은 넵튠과 IP 퍼블리싱 딜을 추진할 수 있는 후보로도 선정할 예정이다.\n이번 공모전은 토스가 운영하는 앱인앱 서비스 ‘앱인토스(Apps in Toss)’의 게임 파트너 생태계를 확대하고자 기획됐다. 앱인토스는 외부 파트너사의 웹 및 앱 서비스를 토스 앱 내에서 실행할 수 있도록 개방한 것으로, 2900만 토스 가입자를 대상으로 서비스를 론칭할 수 있는 기회를 제공한다.\n토스 관계자는 “HTML5 게임은 설치 없이 곧바로 실행할 수 있어 사용자 접근성이 뛰어나고, 색다른 즐거움을 제공할 수 있는 콘텐츠로 주목받고 있다”며 “이번 챌린지를 통해 국내 개발자들의 창의적인 게임들이 앱인토스를 통해 유저와 만날 수 있도록 적극 지원할 것”이라고 밝혔다.",
        "content": "HTML5 게임 개발자라면 누구나 도전하세요",
        "contentSnippet": "HTML5 게임 개발자라면 누구나 도전하세요",
        "guid": "https://toss.im/tossfeed/article/HTML5",
        "isoDate": "2025-07-29T16:00:00.000Z"
      },
      {
        "title": "토스, 차보험비교추천2.0 출시 100일",
        "link": "https://toss.im/tossfeed/article/_car_",
        "pubDate": "Sun, 27 Jul 2025 17:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}전 분기 대비 누적 가입자 수 2배 늘어...일간 서비스 활성 사용자 수는 20배 증가\n교통 카드 번호 자동 불러오기 기능 추가...토스 만보기로 보험료 산정도 정교하게\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n토스(운영사 비바리퍼블리카, 대표 이승건)는 ‘차보험비교추천 서비스 2.0’ 도입 100일을 맞아, 토스를 통해 자동차보험에 가입한 누적 이용자 수가 전 분기 대비 2배 증가했다고 28일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n‘차보험비교추천 서비스 2.0’은 금융위원회의 정책에 따라 보험사 온라인 채널과 플랫폼에서 동일한 요율로 자동차보험을 비교하고 가입할 수 있도록 개선된 서비스다. 토스는 지난 4월 19일부터 동일 요율을 전면 적용하며 본격적으로 서비스를 시작했다.\n이에 따라 토스 앱으로 차보험을 비교ᐧ가입한 이용자 수는 올해 2분기 기준, 1분기 대비 약 2배 증가했다. 이 가운데 가입자 10명 중 7명은 기존보다 더 저렴한 보험료를 추천받은 것으로 나타났다.\n이용자들의 관심도 빠르게 확산되고 있다. 6월 30일 기준, 일간 활성 사용자 수(DAU)는 서비스 개편 전인 2월 말과 비교해 약 20배 증가했다. 같은 기간 월간 활성 사용자 수(MAU)도 약 6배 성장하며, 토스에서 자동차보험을 비교ᐧ추천받는 이용자의 비중이 높아지고 있다.\n사용자 경험도 한층 개선됐다. 7월부터는 대중교통할인 특약 가입 시 카드 번호를 직접 입력하지 않아도 자동으로 불러오는 기능을 추가했다. 토스 만보기를 사용하는 유저는 더 정교한 보험료 산출이 가능하다.\n또한 토스는 사용자 중심의 편리한 UI/UX를 적용해, 이용자의 약 64%가 제휴사 가입 페이지로 전환되는 높은 클릭률을 기록하고 있다.\n현재 토스는 삼성화재다이렉트보험, DB손해보험, 현대해상다이렉트보험, KB손해보험, 메리츠화재보험, 캐롯손해보험, AXA다이렉트보험, 하나손해보험, 흥국화재보험, 롯데손해보험 등 총 10개 주요 보험사와 제휴해 다양한 상품을 한눈에 비교ᐧ가입할 수 있는 환경을 제공하고 있다.\n토스 관계자는 “보험사와 플랫폼 간 동일 요율 적용이 자동차보험 활성화 수 증가에 주된 요인으로 작용한 것 같다”며 “토스는 앞으로도 사용자 경험을 지속적으로 개선해, 더 많은 이용자가 실질적인 혜택을 체감할 수 있도록 노력할 것”이라고 밝혔다.",
        "content": "가입자 수 2배 증가",
        "contentSnippet": "가입자 수 2배 증가",
        "guid": "https://toss.im/tossfeed/article/_car_",
        "isoDate": "2025-07-27T17:00:00.000Z"
      },
      {
        "title": "토스플레이스, 프론트 단말기로 ‘민생회복 소비쿠폰’ 사용처 한눈에",
        "link": "https://toss.im/tossfeed/article/placecoupon",
        "pubDate": "Sun, 27 Jul 2025 15:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}맹점 프론트 화면에서 ‘소비쿠폰’ 스티커 표시 기능 적용\n프론트 꾸미기 기능 통해 소비쿠폰 사용 매장 직접 홍보도\n토스프론트 단말기에서 민생회복 소비쿠폰 사용도 가능\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n비바리퍼블리카(토스)의 결제 단말기 및 포스(POS) 솔루션 공급 자회사 토스플레이스(대표 최재호)가 토스프론트 단말기 화면에 ‘민생회복 소비쿠폰’ 스티커를 표시할 수 있는 기능을 적용했다고 28일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n이번 업데이트를 통해 가맹점은 토스프론트 화면에 ‘민생회복 소비쿠폰’ 스티커를 띄워, 쿠폰 사용 가능 매장임을 손님에게 자연스럽게 알릴 수 있다. 덕분에 소비자는 주문과 동시에 쿠폰 사용 여부를 바로 확인할 수 있고, 가맹점은 별도 설명 없이도 안내가 가능해져 편의성이 높아질 것으로 기대된다.\n스티커 노출 외에도 프론트 꾸미기 기능을 통해 가맹점은 쿠폰 사용 가능 매장임을 자유롭게 알릴 수 있다. 예를 들어, 매장의 인테리어나 콘셉트에 어울리는 이미지, 문구, 색상 등을 단말기 화면에 직접 설정해 가게만의 분위기를 해치지 않으면서도 자연스럽게 쿠폰 사용처임을 홍보할 수 있다.\n뿐만 아니라, 토스프론트 단말기에서는 민생회복 소비쿠폰 사용도 가능하다. 민생회복 소비쿠폰은 정부가 경기 활성화를 위해 국민에게 일정 금액을 선지급하는 소비 지원 정책으로, 전통시장·식당·미용실 등 사용 가능 업종이 지정돼 있다. 때문에 실제 사용할 수 있는지 직관적으로 확인 가능한 안내가 중요한 상황이다.\n토스플레이스 관계자는 “가맹점들이 소비 쿠폰 사용 가능 매장임을 홍보하고 싶어하는 수요를 파악하여 이를 적극적으로 알릴 수 있도록 기능을 보완했다”며 “앞으로도 토스플레이스는 다양한 정책 및 제도에 맞춰 소상공인의 가게 운영에 도움이 될 수 있도록 지속적으로 노력할 예정이다”고 밝혔다.",
        "content": "토스프론트 단말기에서 민생회복 소비쿠폰 사용도 가능",
        "contentSnippet": "토스프론트 단말기에서 민생회복 소비쿠폰 사용도 가능",
        "guid": "https://toss.im/tossfeed/article/placecoupon",
        "isoDate": "2025-07-27T15:00:00.000Z"
      },
      {
        "title": "토스 메이커스 컨퍼런스 25 성황리 종료",
        "link": "https://toss.im/tossfeed/article/tmc25__",
        "pubDate": "Sat, 26 Jul 2025 16:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}서비스 개발 관련 직군 모은 대규모 ‘통합 기술 컨퍼런스’로 화제\n126명의 102개 발표 세션 및 참여형 프로그램 운영… 4,500명 참가에 긍정적 반응 이끌어\n기술 컨퍼런스를 넘어 메이커 커뮤니티의 시작점으로 지속적 확장 예정\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n토스(운영사 비바리퍼블리카, 대표 이승건)가 ‘토스 메이커스 컨퍼런스 25(Toss Makers Conference 25, 이하 TMC 25)’를 성황리에 마쳤다고 27일 밝혔다. 지난 23일부터 25일까지 3일간 삼성동 코엑스 그랜드볼룸에서 열린 이 행사에는 총 4,500명이 참여했다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\nTMC 25는 다양한 서비스 개발 관련 직군을 ‘메이커’라는 이름으로 모은 첫 번째 기술 컨퍼런스다. 이는 직군의 경계보다 제품과 사용자 경험을 우선시하는 토스 조직 문화를 반영한 결과다. 이에 제품 책임자(Product Owner, PO), 디자이너(Designer), 엔지니어(Engineer), 데이터 애널리스트(Data Analyst, DA) 등 5개의 토스 계열 법인 소속 메이커가 각자의 관점에서 어떻게 문제를 정의하고 해결했는지를 현장에서 직접 설명했다.\n\n특히 이번 행사는 126인의 연사와 102개의 실전 중심 발표 세션이라는 규모감으로 화제를 모았다. 실제로 참가 신청 열흘만에 12,000명 이상이 몰리며 높은 관심을 입증했다. 현장에서는 프로덕트, 디자인, 엔지니어링 직군을 이끄는 리더들의 오프닝 세션을 시작으로, ▲서비스 개발 사례를 다루는 메인 세션, ▲일하는 방식에 대한 소프트 세션, ▲발표자와 참석자가 직접 소통하는 네트워킹 세션을 통해 토스의 방대한 도전과 실전 경험을 진솔하게 나눴다.\n\n또한 토스는 ‘참석자와 함께 만드는 기술 컨퍼런스’를 표방하며 다양한 참여형 이벤트를 운영했다. 발표 장표와 메모지를 선택해 자신만의 인사이트를 정리하는 ‘메이커스 노트(Maker’s Note)’ 만들기, 내게 맞는 직군 유형을 알아보는 ‘메이커 스타일 테스트(Maker Style Test)’, 기술 역량을 문구와 함께 사진으로 남길 수 있는 거울 포토존 등 메이커들이 주체적으로 참여 경험을 확장할 수 있는 프로그램들이 마련됐다.\n\n참석자 반응도 긍정적이었다. 설문조사 결과, 응답자 10명 중 9명이 ‘다음 행사에도 참여하겠다’고 답했다. 참석자들은 “다른 개발 컨퍼런스에서 다루지 않는 실패 사례도 자세히 설명해 도움이 됐다”, “데이터 기반 의사결정, 사용자 중심 설계, 빠른 실험 등 토스의 제품 중심 문화가 어떻게 실무에서 구현되는지 알 수 있었다”고 소감을 밝혔다. 인기 발표 세션으로는 ‘토스 PO가 기능이 아닌 흐름을 설계하는 이유’, ‘토스에서 가장 안 좋은 경험 만들기’, ‘주식모으기 서비스로 살펴보는 대용량 트래픽 처리 노하우’ 등이 꼽혔다.\n토스 관계자는 “제품을 중심으로 사고하고, 일하고, 협업하는 조직 문화는 토스의 경쟁력”이라며, “토스는 TMC가 단순한 기술 컨퍼런스를 넘어, 메이커들이 일하는 방식과 문제 해결 철학을 공유하는 커뮤니티로 자리잡을 수 있도록 지속적으로 확장하겠다”라고 밝혔다.\n한편, 토스는 더 많은 메이커와 실전 사례를 공유하기 위해 8월 30일부터 ‘토스 챌린저스(Toss Challengers)’ 유튜브 채널을 통해 ‘TMC 25 발표 다시보기’ 영상을 공개한다.",
        "content": "토스가 일하는 방식, 무대에 오르다",
        "contentSnippet": "토스가 일하는 방식, 무대에 오르다",
        "guid": "https://toss.im/tossfeed/article/tmc25__",
        "isoDate": "2025-07-26T16:00:00.000Z"
      },
      {
        "title": "토스, 삼성화재 다이렉트와 ‘365연간 해외여행보험’ 단독 출시",
        "link": "https://toss.im/tossfeed/article/365-travel-insurance",
        "pubDate": "Fri, 25 Jul 2025 10:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}플랫폼 중 토스에서만 판매…한 번 가입으로 1년간 보장\n상해ᐧ질병ᐧ도난ᐧ지연 등 여행 중 다양한 위험 보장…가입 시 토스포인트 10% 캐시백\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n토스(운영사 비바리퍼블리카, 대표 이승건)가 삼성화재 다이렉트와 제휴해 ‘365연간 해외여행보험’ 상품을 단독 출시한다고 25일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n이 상품은 플랫폼 중 토스에서만 가입할 수 있는 전용 상품으로, 연 1회 가입만으로 1년 동안 해외여행을 떠날 때 마다 자동으로 보험 혜택이 적용된다. 매번 가입할 필요 없어, 자주 해외를 오가는 고객에게 특히 실용적이다. 한 번의 여행에 대해 보험이 적용되는 기간은 최대 31일이며, 보험 기간이 끝난 이후에 돌아오는 일정이라도 출발일 기준 31일까지 보장을 받을 수 있다.\n예를 들어, 30대 여성이 ‘토스전용플랜’에 가입하면 보험료 약 3만 원으로 해외에서 발생할 수 있는 상해, 질병은 최대 3000만 원, 휴대품 파손ᐧ도난은 최대 100만 원까지 보장받을 수 있다. 또한 항공기 및 수하물 지연, 여권 분실로 인한 재발급 비용 등 여행 중 빈번하게 발생하는 상황까지 폭넓게 커버한다.\n‘토스전용플랜’은 삼성화재 다이렉트의 상품과는 보험료와 보장 금액에서 차별화된 구성이다. 동일한 보장 항목이라도 설계에 따라 보장 금액이 다르며, 가입부터 보장 내역까지 전 과정을 토스 앱에서 간편하게 진행할 수 있다.\n2인 이상 동반 가입 시 10% 할인 혜택이 제공되며, 토스 앱을 통해 가입하면 보험료의 10%를 토스포인트로 돌려받을 수 있다.\n토스 관계자는 “올 상반기 국제선 이용객 수가 전년 대비 7.4% 증가하며 사상 최대치를 기록했다”며 “해외여행이 일상화된 만큼 출국 전마다 보험에 가입하는 번거로움을 줄이고자 연간 자동 보장형 상품을 준비했다”고 밝혔다.",
        "content": "플랫폼 중 토스에서만 판매…한 번 가입으로 1년간 보장 ",
        "contentSnippet": "플랫폼 중 토스에서만 판매…한 번 가입으로 1년간 보장",
        "guid": "https://toss.im/tossfeed/article/365-travel-insurance",
        "isoDate": "2025-07-25T10:00:00.000Z"
      },
      {
        "title": "앱인토스, 당신의 아이디어가 토스의 2,900만 유저에게 닿는 방법",
        "link": "https://toss.im/tossfeed/article/outsight-appsintoss",
        "pubDate": "Fri, 25 Jul 2025 05:55:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}토스팀은 바깥 세상과 사람을 유심히 관찰하고 대화를 나눠요. 거기서 배운 것들을 토스가 만드는 제품과 일하는 문화에 녹여내고요. 내적인 통찰만큼이나 외부 세계를 지각하고 소통하는 힘 역시 중요하다고 믿기 때문입니다. 아웃사이트 13화는 토스의 주요 전략인 앱인토스의 배경과 미래를 앱인토스 신사업팀 리더 황지만님(이하 신사업팀 황지만)과 제품팀 PO 권순우님(이하 제품팀 권순우)께 들어본 이야기를 담았어요.\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n토스는 지난 10년간 금융의 장벽을 허물어왔습니다. 불편한 송금은 편리하게, 어려운 투자는 쉽게, 복잡한 은행 업무는 간단하게 만들며 2,900만 유저의 신뢰를 얻었죠. 그리고 25년 2월, 토스는 출범 10주년을 맞아 “앞으로는 일상 슈퍼앱으로 도약하겠다”는 더 큰 도전을 예고했습니다. 동시에 그동안 “토스가 쌓아온 성장 노하우와 내부 인프라를 외부에 공개하겠다”고도 선언했어요.\n이러한 토스의 야심찬 목표를 위해 택한 전략이 바로, '앱인토스(Apps in Toss)'입니다.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}누구나 만들고 누구나 성공할 수 있는\n미니앱 생태계를 꿈꾸다\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n앱인토스는 토스 앱 안에서 누구나 자신만의 서비스를 만들고 성장시킬 수 있는 미니앱 생태계입니다. 파트너사는 게임부터 생활 서비스까지 다양한 영역*의 서비스를 앱인앱 구조로 토스에서 선보일 수 있어요. 앱인앱(App-in-App)구조란, 유저가 별도로 앱을 설치하지 않아도 토스 내에 있는 파트너사의 서비스를 바로 사용할 수 있는 방식을 의미해요. 파트너사는 설치, 가입 등 퍼널 없이도 유저를 바로 얻을 수 있다는 장점이 있어요.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*사행성, 성인물, 토스의 서비스 방향성이나 고객 신뢰에 어긋나는 일부 경우에는 론칭이 제한될 수 있어요.\n이러한 앱인앱 구조를 적용한 미니앱 플랫폼은 이미 글로벌에서 Wechat(위챗), Gojek(고젝), Grab(그랩) 등 다양한 성공 사례*가 있을 만큼, 파트너사와 유저 모두에게 유용한 플랫폼으로 검증되었어요. 앱인토스는 미니앱 영역을 제공하는 기존 사례에서 한 단계 더 나아갑니다. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}파트너사의 실질적인 성장을 돕는 토스의 내부 인프라를 공개한다는 점이 핵심적인 차별점이거든요.\n*위챗(메신저), 고젝(차량 공유 서비스), 그랩(라이드셰어링)에서 각각 출발해 미니앱을 통해 쇼핑, 결제, 생활 서비스 등 종합 라이프스타일 플랫폼으로 확장 및 진화했어요.\n앱인토스에서는 지난 10년간 축적한 성장 방정식이 담긴 개발 도구, 디자인 시스템, 마케팅 솔루션, 데이터 대시보드까지 서비스 론칭부터 유저와 만나는 전 과정에서 필요한 성장 도구를 모두 제공해요. 이렇게 만든 좋은 서비스들은 자연스럽게 토스에 노출되며 2,900만 유저에게 직접 닿게 되죠. 결국 파트너사는 토스의 검증된 성장 도구를 활용해 빠르게 성장하고, 유저는 더 좋은 서비스를 경험하고, 토스는 다양한 서비스로 더욱 풍성해지는 상호 성장 구조를 만드는 것이 앱인토스의 핵심입니다.\n좋은 서비스가 유저에게 \n오랫동안, 더 많이 닿을 수 있도록\n앱인토스를 기획한 배경에는 파트너사들이 실제로 성장할 수 있는 환경을 만들고 싶다는 토스의 장기적이고도 전략적 판단이 있습니다.\n.css-2sk6rv{font-size:19px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);white-space:pre-wrap;margin:24px 0;padding-left:20px;position:relative;}.css-2sk6rv::before{content:'';display:block;position:absolute;top:4px;left:0;width:2px;height:calc(100% - 4px * 2);padding:4px 0;background-color:var(--adaptiveGrey800);}\n.css-120saye{white-space:pre-wrap;font-style:italic;font-weight:bold;}“좋은 서비스들 중에서 조직 체력을 충분히 갖추지 못한 탓에, 성장의 한계를 겪는 상황들을 종종 봤어요. 내부적으로 여러 이야기를 나누면서 ‘좋은 서비스가 유저에게 충분히 닿을 수 있는 환경을 만들어주면 서비스는 더 좋은 경험을 제공하는 본질에 집중하게 되고, 그 결과 앱 생태계가 더욱 활성화될 수 있지 않을까?’라는 생각에 이르렀죠. 이러한 논의 끝에 앱인토스라는 형태가 만들어졌습니다.” - 제품팀 권순우.css-7mseny>*{margin-left:0;margin-right:0;}.css-7mseny>:last-child{margin-bottom:0;}blockquote>.css-7mseny:first-child>:first-child{margin-top:0;}\n“토스 밖에 이미 좋은 서비스들이 많잖아요. 내부 인력이 서비스를 하나씩 만드는 것보다 앱인토스 구조가 토스를 훨씬 빠르고 풍성하게 만드는 방법이라고 생각했습니다.” - 신사업팀 황지만 \n결국 앱인토스는 토스가 가진 인프라와 노하우를 개방함으로써 좋은 서비스들이 더 많은 사람에게 닿을 수 있도록 돕고, 토스 생태계 전체가 더욱 풍성해지는 선순환 구조를 만들어내고자 하는 진심이 담긴 결과물입니다.\n10년 노하우가 담긴 \n토스의 성장 도구를 모두 공개합니다\n앱인토스를 통해 공개하는 모든 내부 인프라는 토스의 제품 철학(Product Principle, 줄여서 PP)을 바탕으로 만들어졌습니다. 인프라를 활용하면 유저가 토스를 이용할 때 일관되게 느끼는 ‘빠르다, 쉽다, 편하다’는 매끄러운 경험을 미니앱에서도 구현할 수 있어요.\n어떻게 이런 일이 가능할까요? TDS(토스 디자인 시스템)와 앱 빌더*를 활용해 토스의 제품 철학이 자동으로 적용되도록 설계했기 때문이에요.\n*앱 빌더는 토스의 내부 디자인 툴을 부르는 명칭으로, 앱인토스에서는 이러한 디자인 시스템을 직접 활용할 수 있어요. \n덕분에 파트너사가 별도로 토스의 제품 철학을 학습하지 않아도, 도구 자체에 토스 제품 디자이너들의 노하우와 원칙이 내재되어 파트너사의 서비스에 자연스럽게 구현됩니다.\n여기서 한 걸음 더 나아가, 각 직군이 필요로 하는 전문 도구들도 함께 제공해요. 기획자는 TUBA*를 통해 MVP 제작에 필요한 유저 테스트부터 빠른 이터레이션까지 시행할 수 있어요. 아침에 실험을 세팅하고 저녁에 결과를 즉시 확인하며 제품 개선 과정을 체계적으로 진행할 수 있죠.\n*TUBA란 Toss User Behavior Analyzer의 축약어로, 토스 유저 행동 분석 툴이라는 의미예요. 토스의 유저 행동을 데이터로 분석할 수 있는 토스 내부 인프라입니다. 아래 이미지처럼 직접 캠페인을 세팅하고 푸시를 보내는데 활용할 수도 있어요.\n\n엔지니어는 토스가 제공하는 SDK(개발 도구 모음)와 다양한 개발 인프라를 활용해 기존보다 훨씬 쉽게 구현할 수 있고요. 마케터라면 직접 2,900만 유저 중 서비스에 적합한 타겟을 설정하고 푸시를 발송할 수도 있어요. 동시에 유저 리텐션, 퍼널 전환율, 코호트 분석 등 다양한 지표를 수집해 데이터 기반 의사 결정까지 가능합니다. \n이 결과 토스 유저들은 앱 구석구석에서 미니앱을 만날 수가 있습니다. 구체적으로는 ‘전체’ 탭에 있는 게임 홈, 미니앱 홈은 물론 토스 서비스 맥락과 닿아 있는 서비스 화면이나 관련 검색어 입력 시에도 파트너사의 서비스를 만나고 이용할 수 있게 되죠. \n\n또한 초기 서비스, 스타트업들이 가장 어려워하는 고객 획득 과정(AARRR) 단계에서 앱 다운로드와 회원 가입, 결제수단 등록과 같은 과정을 토스 인증과 토스페이로 한번에 해결할 수 있습니다.\n“실제로 유저 인터뷰를 해보면 ‘멤버십 혜택은 좋은데, 초반에 설치하고 로그인하는 과정이 번거로워서 이용을 망설이는’ 경우가 있다고 해요. 이런 유저들을 잡고 싶은 파트너에게 특히 앱인토스가 유용할 것으로 생각합니다.” - 제품팀 권순우 \n앱인토스에서 유저가 서비스를 발견하는 방식을 설계할 때 가장 중요하게 고려한 점은 바로 유저의 편의성과 서비스로의 즉각적인 전환이었습니다. 이를 위해 서비스를 소개할 때 브랜드명보다 기능 설명을 먼저 배치하는 전략을 택했어요.\n이는 토스의 핵심 제품 철학 중 하나인 ‘Value First, Cost Later’ 원칙을 구현한 것이에요. 유저가 얻을 수 있는 가치를 먼저 명확히 제시하여 즉각적인 전환을 유도하는 앱인토스만의 설계 철학이죠.\n파트너사의 브랜드 성장도 함께 고려합니다. 유저가 미니앱 이용 시 해당 브랜드로 이동한다는 안내가 명확히 표시되고, 재사용 시에는 브랜드명이 우선 노출되어 브랜드 인지도 향상에도 기여해요.\n\n이처럼 앱인토스 팀은 파트너사가 진짜 필요로 하는 것을 깊이 이해하기 위해, 끊임없이 탐색합니다. 파트너사들이 그로스 차원에서 고민하는 것과 실제 과정을 이해하기 위해 정기적으로 그룹 인터뷰를 진행하고, 파트너사와의 직접적인 소통을 통해 해상도 높은 니즈 파악을 위해 노력해요.\n개인부터 기업까지 \n모두 성장할 수 있어요\n앱인토스는 현재 1인 개발자부터 이름만 들으면 아는 브랜드까지 다양한 규모의 파트너사가 함께 하고 있어요. 규모를 불문하고 모든 파트너가 성장할 수 있는 환경을 제공하고 있기 때문입니다.\n1인 개발자와 초기 스타트업에게는 앱인토스가 강력한 성장 동력이 됩니다. 일반적으로 해당 규모에서 구축하기 어려운 마케팅 도구와 데이터 분석 시스템, 결제 인프라를 제품 초기부터 활용할 수 있거든요.\n중간 규모의 기업에게는 효율적인 실험 환경을 제공합니다. 새로운 서비스나 기능을 테스트할 때 필요한 복잡한 준비 과정과 초기 비용 부담 없이, 빠르게 시장 검증을 진행할 수 있어요.\n이미 시장에서 인지도가 있는 브랜드에게는 새로운 추가 매출의 기회를 제공합니다. 파트너사는 앱인토스 내에서 자체적으로 인앱 결제를 통한 유료 서비스나 광고를 운영할 수 있어 추가적인 매출 창출이 가능합니다.\n이처럼 토스가 앱인토스를 통해 그리고 있는 건 단순한 미니앱 플랫폼이 아닙니다. 좋은 아이디어를 가진 사람이라면 누구나, 규모와 상관없이 성공할 수 있는 기회를 만들고자 합니다.\n이미 앱인토스를 적극적으로 활용하며 좋은 성과를 얻은 사례도 있어요. 해외 송금 전문 핀테크 기업 .css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}‘모인’은 신규 가입자가 약 40% 증가하고, 부동산 인공지능 에이전트 서비스 기업인 ‘안전집사’는 앱인토스에서 서비스 출시 후 유저 트래픽의 90%가 앱인토스로 발생하는 결과도 얻게 되었어요.\n‘앱인토스만으로 IPO까지’\n토스가 그리는 앱인토스의 미래 \n\"앱인토스와 함께하는 파트너사들이 앱인토스만으로 기업 공개(IPO)까지 성공했으면 좋겠어요.\" - 제품팀 권순우\n앱인토스는 메이커들이 성장할 수 있는 최적의 환경을 조성하고, 그들의 성공이 곧 토스의 성공으로 이어지는 구조를 만들고 있습니다.\n더 나아가 유튜브 서비스가 활성화 되며 자연스럽게 크리에이터를 돕는 회사나 지원 서비스가 생겨났듯, 앱인토스 파트너사를 돕는 2차 사업자들이 자연스럽게 등장하는 완전한 생태계를 기대하고 있어요. 그때야 비로소 진정한 성장 생태계가 완성되는 거죠.\n현재는 여정의 첫 단계에 불과하지만, 토스는 이 비전을 빠르게 현실로 만들어낼 계획입니다. 기존 글로벌 성공 사례를 비춰보았을 때 성숙한 미니앱 생태계가 구축되는 데 약 5년이 걸렸는데, 토스는 더 빠른 속도로 그 목표를 달성하기 위해 전력으로 노력 중이에요.\n2,900만 유저에게 \n여러분의 서비스를 선보일 준비가 되셨나요?\n현재 앱인토스는 베타 서비스를 통해 다양한 파트너사를 모집하고 있습니다. 게임부터 생활 서비스까지 다양한 분야의 좋은 아이디어가 있다면 누구나 도전할 수 있어요.\n\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nGraphic 이은호 이제현",
        "content": "토스가 10년 노하우를 모두에게 공개하는 이유",
        "contentSnippet": "토스가 10년 노하우를 모두에게 공개하는 이유",
        "guid": "https://toss.im/tossfeed/article/outsight-appsintoss",
        "isoDate": "2025-07-25T05:55:00.000Z"
      },
      {
        "title": "달러 자산 투자 왜 필요할까? 초보자도 할 수 있는 글로벌 분산 투자 전략",
        "link": "https://toss.im/tossfeed/article/money-skills-2",
        "pubDate": "Fri, 25 Jul 2025 03:34:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}달러 자산 투자란?\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1kxrhf3{white-space:pre-wrap;}예전에는 미국 여행을 준비할 때가 아니면 개인이 원·달러 환율에 신경 쓸 일이 많지 않았습니다. 하지만 최근 몇 년 사이 미국 주식 투자자가 급격히 늘어나면서 자연스럽게 환율에 관한 관심도 높아졌죠. 환율이 낮을 때 환전하면 수익률 측면에서 유리하기 때문입니다.\n미국 주식과 같이 ‘달러(USD)’로 표시된 금융 자산에 투자하는 것을 달러 자산 투자라고 부릅니다. 그렇다면 왜 달러에 투자할까요? 달러는 글로벌 기축통화✱로, 전 세계적으로 수요가 많은 자산입니다. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}각국의 중앙은행은 국제 결제, 환율 안정, 금융위기 대응을 위해 달러 자산을 보유하고, 기업이나 개인은 무역, 투자, 송금 등의 목적으로 달러 자산이 필요합니다. 즉, 달러는 전 세계에 수요가 있는 기축통화로서 신뢰할 수 있는 투자 대상으로 평가받는 것이죠.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}✱기축통화: 국제 외환 시장에서 금융 거래, 결제, 자산 보유 등의 중심이 되는 통화를 뜻합니다. 대표적으로 미국 달러가 이에 속해요. 더 자세한 내용은 ‘.css-114ityv{white-space:pre-wrap;cursor:pointer;-webkit-text-decoration:underline!important;text-decoration:underline!important;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}미국 달러, 어떻게 기축통화가 됐을까?’를 참고하세요.\n달러 자산 투자는 단순히 달러가 저렴할 때 사고 비쌀 때 팔아서 차익을 노리는 환테크뿐 아니라, 미국 주식, 채권, ETF(상장지수펀드), REITs(부동산 투자신탁), 달러 예금 등에 이르는 투자 방식을 포괄합니다.\n달러 자산 투자에 관심 가져야 하는 이유\n큰 수익률을 보이는 특정 종목들 때문에 미국 주식 투자를 시작하는 경우가 많지만, 근본적으로 우리는 왜 달러 자산 투자에 관심을 가질까요? 한마디로 정리하면, 원화 중심으로 구성된 자산 포트폴리오에 달러 자산을 일부 편입함으로써 통화 분산 효과를 얻고 글로벌 투자 기회를 넓힐 수 있기 때문입니다. 이는 한국 자산을 대체한다기보다 보완적 접근이라고 할 수 있죠.\n① 인플레이션과 원화 가치 하락 방어 효과\n요즘 물가가 오르고 있다는 걸 체감하고 계시죠? 마트에서 사는 과일도, 밖에서 사먹는 냉면 한 그릇도 훌쩍 높아진 가격으로 우리를 놀라게 합니다. 이처럼 예전과 같은 물건이나 서비스라도 가격을 더 줘야 하는 현상을 인플레이션이라고 합니다.\n인플레이션이 발생하는 첫 번째 이유는 시중에 돈이 너무 많이 풀렸기 때문입니다. 정부가 침체된 내수 경기를 활성화시키기 위해 돈을 계속 풀면, 그만큼 돈의 가치는 떨어지고 물가는 오르게 돼요. 둘째, 중동의 지정학적 리스크로 유가가 상승한 탓에 전반적으로 물가가 오르고 있습니다. 셋째, 원화 가치가 낮아졌기 때문입니다. 우리나라 경제가 불안해지거나, 정치·외교적인 이슈가 생기면 → 외국 투자자들이 원화를 팔고 빠져나가서 → 환율이 올라가고 → 수입하는 원자재나 물품 가격이 비싸지면서 → 물가도 덩달아 오르게 됩니다.\n이럴 때 달러 자산은 큰 효과를 발휘합니다. 내 자산의 일부를 달러 자산으로 보유하고 있으면 원화 가치가 떨어지더라도 전체 자산의 가치를 방어할 수 있습니다. 예를 들어, 전 재산을 원화로만 가지고 있는 사람은 인플레이션이 올 때 실질 자산 가치가 줄어들지만, 달러 자산 비중을 일부 확보한 경우 환율 변동이 손실을 일부 상쇄해 줄 가능성이 있으니까요.\n② 글로벌 분산 투자\n한국 경제는 저성장·고령화 등 구조적 변화를 겪고 있는 가운데, 글로벌 교역 환경과 통상 정책 변수에 따라 산업별 기회와 리스크가 동시에 존재합니다. 이런 상황에서 우리가 가진 자산 대부분이 원화로만 묶여 있다면 위험할 수 있습니다. 부동산도 원화 자산이고, 월급도 원화로 받고, 예금도 원화로 넣잖아요. 그런데 만약 원화 가치가 떨어지거나 우리 경제가 위태로운 시기가 오면 우리 자산 전체가 함께 흔들리게 됩니다. \n이럴 때 떠올릴 수 있는 것이 글로벌 분산 투자입니다. ‘달걀을 한 바구니에 담지 말라’는 말처럼 자산을 여러 나라에 투자할 필요가 있습니다. 그중에서도 달러 자산은 미국이라는 가장 큰 경제 시장에 투자할 수 있는 대표적인 방법입니다. 무턱대고 한국 자산을 줄이기보다는 전체 포트폴리오에서 지역·통화 다변화를 고려해 보자는 취지입니다.\n③ 환차익 기대\n원·달러 환율은 오르락내리락을 반복합니다. 긴 흐름으로 보면 달러가 원화보다 강했던 시기가 여러 번 있었고, 그때 ‘환차익’을 얻을 수도 있었습니다. 앞으로도 성장률 차이, 글로벌 자금 이동, 지정학 변수 등에 따라 달러 강세가 나타날 수 있지만, 이는 어디까지나 가능성일 뿐 확정된 미래는 아닙니다.\n여기서 환차익이란, 쉽게 말해 달러 가격이 오를 때 생기는 이익을 말합니다. 예를 들어, 1달러가 1,200원일 때 투자해서 1,400원이 되었을 때 달러를 팔면 200원만큼 환차익을 얻을 수 있으며, 현재 환차익에 대해 세금은 부과되지 않습니다.\n④ 장기적인 자산 증식\n미국 주식 시장은 역사적으로 장기적인 성장 추세를 보여왔습니다. 대공황, 1·2차 세계 대전, 2008년 금융위기, 코로나19 팬데믹 같은 큰 충격이 있어도 이내 회복세를 보였고, 결국엔 더 크게 성장했습니다. 이건 단순한 운이 아니라 미국이라는 나라의 시스템과 기업 생태계에 대한 신뢰가 있기 때문에 가능한 일이었죠. \n실제로 미국 대형주를 대표하는 S&P 500 지수는 지난 수십 년간 연평균 약 7~10%의 수익률을 기록해 왔습니다. 다만 과거 수익률이 미래를 보장하지 않는다는 점, 투자 시점에 따라 수익률이 크게 달라질 수 있다는 점을 유의해야 합니다.\n달러 자산 투자에 대해 궁금한 5가지\nQ1. 언제 사고팔아야 하나요?\n→ 시장은 언제 오르고 내릴지 예측하기 어렵습니다. 따라서 단기적인 가격 변동에 일희일비하기보다는 장기적인 관점에서 꾸준히 투자하는 것이 중요합니다. 만약 비용 평균법✱을 활용해 정기적으로 일정 금액을 투자하면, 환율과 시장의 변동성 리스크를 분산할 수 있습니다. 시장의 타이밍을 맞추려 하기보다는 시장에 지속적으로 참가하는 것이 더 나은 투자 결과로 이어질 가능성이 높습니다.\n✱비용 평균법(Cost Averaging): 일정 금액을 정기적으로 투자해 시장 변동성을 완화하고 평균 매입 단가를 낮추는 전략\nQ2. 초보자는 어떤 달러 자산에 투자하는 게 좋을까요?\n→ 투자자의 위험 선호도와 목표에 따라 선택이 달라집니다. 안정성을 추구한다면 미국 국채나 배당주 ETF(예: SCHD, SPYD, VYM)가 적합합니다. 성장성을 원한다면 기술주 중심의 ETF(예: QQQ)나 개별 주식(예: 엔비디아, 테슬라, 메타 등)에 투자할 수 있습니다. 초보자는 S&P500 지수 ETF(예: VOO, SPY)처럼 시장 전반을 추종하는 상품을 선택하는 것이 더 잘 맞을 수 있고요.\nQ3. 달러의 기축통화 지위가 약화되고 있는 것은 아닌가요?\n→ 중국과 일본이 미국 국채를 매도하고 '탈달러' 움직임을 보이는 등 달러 패권에 대한 의구심이 제기되기도 합니다. 그러나 아직은 달러를 대체할 만큼 신뢰받는 자산이 마땅치 않아 미국의 대체 불가능한 지위는 당분간 유지될 가능성이 높습니다.\nQ4. 달러 자산도 변동성이 높은데 괜찮을까요?\n→ 모든 투자에는 위험이 따릅니다. 원금 보장 상품이 아닌 이상 시장의 변동성은 자연스러운 현상입니다. 중요한 것은 단기적인 변동에 흔들리지 않고 장기적인 성장 가능성을 믿고 투자하는 것이겠죠. 개인 투자자는 분산 투자와 적립식 투자를 통해 리스크를 관리하고 심리적 불안을 줄이는 것이 필요합니다.\nQ5. 미국 주식 투자 시 어떤 비용이 드나요?\n→ 미국 주식에 투자할 때 발생하는 주요 비용은 거래 수수료, 환전 수수료, 그리고 세금 등이 있습니다.\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n거래 수수료: 해외주식 거래 수수료는 보통 거래금액의 0.2~0.5% 수준\n환전 수수료: 은행 1.75% 수준, 증권사 1% 수준\n세금: 해외 주식을 매도했을 시 양도소득세 22%(연 250만 원 공제)\n\n실제로 달러 자산 투자를 해보는 법\n가장 흔한 달러 자산 투자인 미국 주식과 ETF 투자 외, 다른 방법 2가지를 소개합니다.\n(1) 달러 예금 또는 달러 RP\n소극적으로 달러 자산 보유를 원한다면 주식 투자보다 달러 예금 또는 달러RP가 잘 맞을 수 있어요.\n\n달러 예금: 말 그대로 달러로 예치하는 예금 상품입니다. 은행에 달러 통장을 만들어 일정 기간 달러를 예치하면 이자를 받을 수 있죠. 안정성이 높고 원금 보장이 된다는 게 가장 큰 특징입니다.\n달러 RP(환매조건부채권): RP는 증권사가 보유한 국공채 등을 담보로 단기적으로 달러를 맡기고 약정한 수익률을 받는 투자 상품입니다. 예금보다는 약간 위험이 따르지만, 금리가 예금보다 높고 짧은 기간 운용이 가능해 자금 회전에 유리합니다. 단, 원금 보장이 되지 않으며 원금 손실 가능성도 존재합니다.\n\n(2) 미국 국채에 투자하기\n미국 국채에 가장 쉽게 투자하는 방법은 증권사 앱의 ‘해외채권’ 메뉴를 이용하는 것입니다. 1년, 2년, 10년 등 원하는 만기와 금리를 확인하고 채권을 매수하면 됩니다. 최근 몇 년간 단기 미국 국채 금리가 국내 단기 예금 대비 경쟁력 있는 수준을 보였던 시기가 있었으나, 금리 수준은 시점에 따라 크게 달라지므로 거래 직전 확인이 필수입니다.\n또 다른 방법으로는 미국 국채 ETF에 투자하는 것이 있습니다. 대표적인 ETF로는 TLT(장기), IEF(중기), SHY(단기) 등이 있죠. 보통 장기채는 금리 변화에 민감해 변동성이 크고, 단기채는 비교적 안정적인 편이기 때문에 자신의 투자 목적과 성향에 맞게 선택하는 것이 중요합니다.\n※ 채권은 만기까지 보유하면 원금과 이자를 받을 수 있지만, 중간에 매도할 경우에는 손실을 볼 수 있으므로 유의해야 합니다.\n달러 자산 투자는 단순한 수익 추구를 넘어 변화무쌍한 글로벌 경제 속에서 나의 자산을 지키고 성장시킬 수 있는 전략적 선택지입니다. 그러니 단기적인 시장 변동에 연연하기보다는 자신에게 맞는 투자 원칙을 세우고 꾸준히 실행하는 것이 중요합니다. 분산 투자와 적립식 투자를 통해 위험을 관리하고, 장기적인 안목으로 시장의 큰 흐름을 읽어 나간다면 분명 달러 자산은 전체 포트폴리오의 보완재 역할을 해줄 것입니다.\n\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 주소은 Graphic 이은호\n해당 콘텐츠는 2025.07.25. 기준으로 작성되었습니다.\n– 특정 기업명을 언급한 것은 예시와 설명을 위한 목적이며, 이는 투자 권유나 종목 추천을 위한 것이 아닙니다.\n– 상기 정보는 투자 상품의 판매나 권유를 위하여 제작된 것이 아닙니다. 투자자의 투자 결과에 대한 법적 자료로 사용될 수 없습니다.",
        "content": "미국 주식 외에도 달러 자산에 투자하는 몇 가지 방법",
        "contentSnippet": "미국 주식 외에도 달러 자산에 투자하는 몇 가지 방법",
        "guid": "https://toss.im/tossfeed/article/money-skills-2",
        "isoDate": "2025-07-25T03:34:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]