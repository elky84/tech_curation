[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Sy Brand",
        "title": "Pure Virtual C++ 2025: Full Schedule",
        "link": "https://devblogs.microsoft.com/cppblog/pure-virtual-cpp-2025-full-schedule/",
        "pubDate": "Tue, 15 Apr 2025 12:15:38 +0000",
        "content:encodedSnippet": "Pure Virtual C++ is our free, one-day, virtual conference for the whole C++ community. This year, it is running on the 30th April. We’re pleased to announce the schedule of live talks:\n14:00 UTC: Welcome to v1.0 of the meta::[[verse]]! with Inbal Levi\n14:30 UTC: Proxy: Next Generation Polymorphism with Mingxin Wang\n15:00 UTC: Making unfamiliar C++ code familiar with GitHub Copilot with Sinem Akinci\n15:30 UTC: C++ Modules Myth Busting with Cameron DaCamara\n16:00 UTC: constexpr everything?! with Hana Dusíková\nYou can find abstracts for all the talks and register for the conference with the button below.\nKeep an eye out for on-demand pre-conference content coming soon on YouTube.\nRegister for Free\n\nThe post Pure Virtual C++ 2025: Full Schedule appeared first on C++ Team Blog.",
        "dc:creator": "Sy Brand",
        "comments": "https://devblogs.microsoft.com/cppblog/pure-virtual-cpp-2025-full-schedule/#respond",
        "content": "<p>Pure Virtual C++ is our free, one-day, virtual conference for the whole C++ community. This year, it is running on the 30th April. We&#8217;re pleased to announce the schedule of live talks: 14:00 UTC: Welcome to v1.0 of the meta::[[verse]]! with Inbal Levi 14:30 UTC: Proxy: Next Generation Polymorphism with Mingxin Wang 15:00 UTC: Making [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/pure-virtual-cpp-2025-full-schedule/\">Pure Virtual C++ 2025: Full Schedule</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "Pure Virtual C++ is our free, one-day, virtual conference for the whole C++ community. This year, it is running on the 30th April. We’re pleased to announce the schedule of live talks: 14:00 UTC: Welcome to v1.0 of the meta::[[verse]]! with Inbal Levi 14:30 UTC: Proxy: Next Generation Polymorphism with Mingxin Wang 15:00 UTC: Making […]\nThe post Pure Virtual C++ 2025: Full Schedule appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=35386",
        "categories": [
          "C++"
        ],
        "isoDate": "2025-04-15T12:15:38.000Z"
      }
    ]
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Kerry Beetge",
        "title": "Big News! JetBrains Qodana’s Code Quality Plugin Is Now Available for Visual Studio",
        "link": "https://blog.jetbrains.com/qodana/2025/04/visual-studio-plugin/",
        "pubDate": "Wed, 16 Apr 2025 15:24:15 +0000",
        "content:encodedSnippet": "It’s no secret that Qodana is a team tool that JetBrains designed to integrate seamlessly with its suite of IDEs, but every team and tech stack is different. One common question remains: “What about other members of our team who still use VS Code or Visual Studio?” To help with this problem, we decided to provide a more integrated offering that can truly bolster code quality for the average development team.\nWe already have a VS Code extension, so it was time to get to work on a Visual Studio version. The team has now completed this task, and you can now download Qodana’s code quality plugin for Visual Studio via the Resharper Installer. \nReSharper Installer\n\n\n\n\nPlug in and play – Why Try The Visual Studio Plugin for Quality?\n✓ Identify code issues, bugs, and vulnerabilities.\n✓ Run code analysis in your CI pipeline.\n✓ See issues in Visual Studio while you work.\n\n\n\n\nJoin the Qodana Community\nReach out to qodana-support@jetbrains.com or follow us on X and LinkedIn for code quality updates. You can also view the documentation for more information on the extension, what Qodana is capable of, and how static code analysis works.\nReSharper Installer",
        "dc:creator": "Kerry Beetge",
        "content": "It’s no secret that Qodana is a team tool that JetBrains designed to integrate seamlessly with its suite of IDEs, but every team and tech stack is different. One common question remains: “What about other members of our team who still use VS Code or Visual Studio?” To help with this problem, we decided to [&#8230;]",
        "contentSnippet": "It’s no secret that Qodana is a team tool that JetBrains designed to integrate seamlessly with its suite of IDEs, but every team and tech stack is different. One common question remains: “What about other members of our team who still use VS Code or Visual Studio?” To help with this problem, we decided to […]",
        "guid": "https://blog.jetbrains.com/?post_type=qodana&p=550905",
        "categories": [
          "plugin-highlights",
          "plugins",
          "qodana",
          "release",
          "visual-studio"
        ],
        "isoDate": "2025-04-16T15:24:15.000Z"
      },
      {
        "creator": "Dmitrii Korovin",
        "title": "TeamCity 2025.03.1 Bug Fix Is Now Available!",
        "link": "https://blog.jetbrains.com/teamcity/2025/04/teamcity-2025-03-1-bug-fix/",
        "pubDate": "Wed, 16 Apr 2025 14:00:08 +0000",
        "content:encodedSnippet": "The first bug-fix update for version 2025.03, TeamCity On-Premises 2025.03.1, is out and ready to be installed on your servers! This update ships around 30 bug fixes, performance enhancements, and security patches. We highly recommend upgrading to keep your system secure and optimized. The list of resolved issues includes:\nInfinite scrolling in custom reports;\nIssues related to Git LFS;\nMissing “Docker Info” tab;\nFlicking project pages, and more.\nSee TeamCity 2025.03.1 Upgrade Notes for the complete list.\nWhy update?\nStaying up to date with minor releases ensures your TeamCity instance benefits from the following:\nPerformance improvements.\nBetter compatibility with integrations.\nFaster, more stable builds.\nEnhanced security for your workflows.\nCompatibility\nTeamCity 2025.03.1 shares the same data format as all 2025.03.x releases. You can upgrade or downgrade within this series without the need for backup and restoration.\nHow to upgrade\nUse the automatic update feature in your current TeamCity version.\nDownload the latest version directly from the JetBrains website.\nPull the updated TeamCity Docker image.\nNeed help?\nThank you for reporting issues and providing feedback! If you have questions or run into any problems, please let us know via the TeamCity Forum or Issue Tracker.\nHappy building!",
        "dc:creator": "Dmitrii Korovin",
        "content": "The first bug-fix update for version 2025.03, TeamCity On-Premises 2025.03.1, is out and ready to be installed on your servers! This update ships around 30 bug fixes, performance enhancements, and security patches. We highly recommend upgrading to keep your system secure and optimized. The list of resolved issues includes: See TeamCity 2025.03.1 Upgrade Notes for [&#8230;]",
        "contentSnippet": "The first bug-fix update for version 2025.03, TeamCity On-Premises 2025.03.1, is out and ready to be installed on your servers! This update ships around 30 bug fixes, performance enhancements, and security patches. We highly recommend upgrading to keep your system secure and optimized. The list of resolved issues includes: See TeamCity 2025.03.1 Upgrade Notes for […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=560679",
        "categories": [
          "bug-fix"
        ],
        "isoDate": "2025-04-16T14:00:08.000Z"
      },
      {
        "creator": "Evgenia Verbina",
        "title": "PyCharm 2025.1: Unified PyCharm, Free AI Tier, Junie Release, and More!",
        "link": "https://blog.jetbrains.com/pycharm/2025/04/pycharm-2025-1/",
        "pubDate": "Wed, 16 Apr 2025 13:58:00 +0000",
        "content:encodedSnippet": "PyCharm 2025.1 brings major updates to improve your development experience.\nPyCharm is now a unified product, combining PyCharm Professional and Community Edition. Version 2025.1 also brings a free AI tier, the public release of Junie, the launch of Cadence, significant Jupyter enhancements, support for Hatch, Data Wrangler, and many other improvements.\nGet the latest version from our download page or update through our free Toolbox App. \nDownload now\n                                                    \nRead this blog post to learn more about the updates. \nPrefer video? Get an overview of the major news and improvements in this video:\n\n\n\n\n\n\nPyCharm is now one powerful, unified product!\nPyCharm is now one powerful, unified product! Its core functionality, including Jupyter Notebook support, will be free, and a Pro subscription with additional features will be available. \nStarting with the 2025.1 release, every user will get instant access to a free one-month Pro trial, so you’ll be able to access all of PyCharm’s advanced features right away. After the trial, you can choose whether to continue with a Pro subscription or keep using the core features for free. Learn more about the change in this blog post.\nJunie – your personal coding agent Pro\nJunie, the coding agent by JetBrains, is now available in PyCharm via JetBrains AI. Junie autonomously plans, writes, refines, and tests code to make your development experience smooth, efficient, and enjoyable. It handles tedious tasks like restructuring code, creating tests, and implementing refinements, so you can focus on bigger challenges and innovation. \n\n\n\n\nPyCharm goes AI\nJetBrains AI has received a major upgrade, bringing both AI Assistant and the coding agent Junie under a single subscription. With this release, all JetBrains AI features are accessible for free in PyCharm Pro, with unlimited use for some, such as code completion and local model support, and limited credit-based access to others. \n\n\n\n\nWe’re also introducing a new subscription system that makes it easy to scale up as needed with the AI Pro and AI Ultimate tiers. Other highlights of this release include smarter completion, advanced context awareness, and support for Claude 3.7 Sonnet and Gemini 2.0 Flash. Head to the What’s New page to learn more about the latest AI features.\nCadence – effortless cloud execution for ML workflows Pro\nWe’re introducing Cadence. You can now run your machine learning code on powerful cloud hardware directly from PyCharm in minutes – no complex setup or cloud expertise is required. The Cadence plugin simplifies ML workflows, allowing you to focus on your code while leveraging scalable computing resources. \n\n\n\n\n\n\nData Wrangler Pro\nWe’ve implemented Data Wrangler, a powerful tool to help Python data professionals streamline data manipulation and focus on higher-level analysis. Use the interactive UI to perform common dataframe transformations – like filtering, cleaning, handling outliers, and more – without writing repetitive code. \nYou can view and explore column statistics, generate Python code for transformations automatically, track the history of changes, export data easily, and insert transformations as new cells in your notebook.\n\n\n\n\nSQL cells in notebooks Pro\nPyCharm 2025.1 introduces SQL cells. This new cell type allows you to query databases, dataframes, and attached CSV files in Jupyter notebooks and automatically save query results to pandas DataFrames.\n\n\n\n\nWe’ve also introduced many other improvements to enhance the Jupyter notebook experience. Learn more about them in the What’s New.\nSupport for Hatch\nWe’re introducing support for Hatch, a modern and extensible Python project manager from the Python Packaging Authority (PyPA). Hatch can automatically migrate setuptools configurations, create isolated environments, and run and publish builds, making Python package management more efficient. \n\n\n\n\nPyCharm also allows you to create new projects managed by Hatch. The IDE will automatically recognize Hatch projects when they are imported from a local machine or a remote source.\nDownload now\n                                                    \nLooking for more?\nVisit our What’s New page to learn about other 2025.1 features and the latest bug fixes.\nRead the release notes for the full breakdown of the changes.\nIf you encounter any problems, please report them via our issue tracker so we can address them promptly.\nWe’d love to hear your feedback on PyCharm 2025.1 – leave your comments below or connect with us on X.",
        "dc:creator": "Evgenia Verbina",
        "content": "PyCharm 2025.1 brings major updates to improve your development experience. PyCharm is now a unified product, combining PyCharm Professional and Community Edition. Version 2025.1 also brings a free AI tier, the public release of Junie, the launch of Cadence, significant Jupyter enhancements, support for Hatch, Data Wrangler, and many other improvements. Get the latest version [&#8230;]",
        "contentSnippet": "PyCharm 2025.1 brings major updates to improve your development experience. PyCharm is now a unified product, combining PyCharm Professional and Community Edition. Version 2025.1 also brings a free AI tier, the public release of Junie, the launch of Cadence, significant Jupyter enhancements, support for Hatch, Data Wrangler, and many other improvements. Get the latest version […]",
        "guid": "https://blog.jetbrains.com/?post_type=pycharm&p=559287",
        "isoDate": "2025-04-16T13:58:00.000Z"
      },
      {
        "creator": "Stanislav Garkusha",
        "title": "DataSpell 2025.1: JetBrains Data Wrangler AI Agent, No-Code Data Preparation Flow, AI Quick Charts, and More!",
        "link": "https://blog.jetbrains.com/dataspell/2025/04/dataspell-2025-1-jetbrains-data-wrangler-ai-agent-no-code-data-preparation-flow-ai-quick-charts-and-more/",
        "pubDate": "Wed, 16 Apr 2025 13:18:50 +0000",
        "content:encodedSnippet": "We’re thrilled to introduce DataSpell 2025.1, the first major release of 2025. This update focuses on making data cleaning and preparation more intuitive and efficient than ever before. \n\n\n\n\n\n\n\nDownload DataSpell 2025.1 \nJetBrains Data Wrangler AI agent\nWith Data Wrangler, you can choose between a no-code flow or full AI automation. Easily toggle between:\nAI chat interaction: Ask AI to analyze your data, and it will suggest transformations you can apply with a single click.\n\n\n\n\n\nNo-code UI: For those who prefer a hands-on approach, work with the Data tool window or table data viewer to start data transformations without writing a line of code.\n\n\n\n\n\nOnce your data is ready, export the transformations in various formats or as code for future use.\n\n\n\n\nNo-code flow for data preparation\nOur new Data tool window consolidates database connections, data warehouse links, and attached files so you can manage them all in one place. The Data Preview pane ensures you’re always working with exactly the data you need, while the no-code import cell makes it even easier to bring new files into your notebooks.\n\n\n\n\nEnhanced Jupyter notebooks features\nWe’ve upgraded the Jupyter experience with:\nImproved debugger: Includes Run to caret and automatic line-by-line debugging for cells without breakpoints.\n\n\n\n\nVisual enhancements: Drag and drop to reorder cells, easily commit notebooks without outputs, enjoy new color options for backgrounds, and get a clearer Markdown editing experience.\n\n\n\n\nKernel management: Shut down kernels right from the main toolbar.\n\n\n\n\nAI quick charts for tables Generate chart previews with a single click. AI Assistant uses dataframe metadata to suggest visualizations, which appear directly in the table’s widget. Accept a suggestion and instantly insert the chart code into your notebook.\nAI Assistant updates\nAI Assistant now also supports more cutting-edge LLMs.\n\n\n\n\n\nWeb search: Use the /web command in AI Assistant to fetch documentation and troubleshooting resources without leaving your IDE. \n\n\n\n\nIf you’re interested in upgrading to DataSpell 2025.1, or if you have any questions or suggestions, here are a few links you might find useful:\nDownload DataSpell 2025.1.\nVisit our What’s New page for the full list of improvements.\nContact us on X.\nReport any bugs to our issue tracker.\nWe hope you enjoy this release and look forward to hearing your feedback!\nThe DataSpell team",
        "dc:creator": "Stanislav Garkusha",
        "content": "We’re thrilled to introduce DataSpell 2025.1, the first major release of 2025. This update focuses on making data cleaning and preparation more intuitive and efficient than ever before. Download DataSpell 2025.1 JetBrains Data Wrangler AI agent With Data Wrangler, you can choose between a no-code flow or full AI automation. Easily toggle between: No-code flow [&#8230;]",
        "contentSnippet": "We’re thrilled to introduce DataSpell 2025.1, the first major release of 2025. This update focuses on making data cleaning and preparation more intuitive and efficient than ever before. Download DataSpell 2025.1 JetBrains Data Wrangler AI agent With Data Wrangler, you can choose between a no-code flow or full AI automation. Easily toggle between: No-code flow […]",
        "guid": "https://blog.jetbrains.com/?post_type=dataspell&p=559834",
        "isoDate": "2025-04-16T13:18:50.000Z"
      },
      {
        "creator": "Hanna Yakush",
        "title": "PhpStorm 2025.1 Is Now Available",
        "link": "https://blog.jetbrains.com/phpstorm/2025/04/phpstorm-2025-1-is-now-available/",
        "pubDate": "Wed, 16 Apr 2025 13:18:22 +0000",
        "content:encodedSnippet": "This release is a major update that includes improvements in PHPStan annotations, Xdebug, and WordPress  support, an AI Free tier and new subscription system for JetBrains AI, and more.\nDownload PhpStorm 2025.1\n\n\n\n\nPHP\nCode completion for @phpstan-type and @phpstan-import-type \nThis release improves PhpStorm’s PHPStan annotation support, introducing code completion for array shape aliases in @phpstan-type and @phpstan-import-type. Using the local type aliases defined in PHPDoc’s @phpstan-type annotation (or referenced in the @phpstan-import-type annotation), the IDE autocompletes array keys in class bodies.\n\n\n\n\nSupport for nested variables in .env files\nVersion 2025.1 extends PhpStorm’s .env file support to include nested variables syntax. Code completion, navigation between declarations and usages, inspections, and quick-fixes now also work for environment variables wrapped in ${…}.\n\n\n\n\nDebugging\nOption to install Xdebug from the CLI Interpreters window\nPhpStorm simplifies Xdebug setup in many ways, including by detecting when the debugger is not installed for the PHP interpreter that’s in use. If Xdebug is missing, in PhpStorm 2025.1, you can have it downloaded and installed automatically right from the CLI Interpreters dialog. \n\n\n\n\nXdebug Helper browser extension now maintained by JetBrains\nJetBrains has teamed up with Fraser Chapman to publish and maintain an official Xdebug toggler for Chrome and Firefox browsers. The Xdebug Helper by JetBrains extension is open source and developed by Fraser, but committing to its testing and release allows us to make sure you are provided with reliable tools for interruption-free debugging.\nWordPress\nWordPress support on project startup\nIn order to provide support for WordPress projects, PhpStorm needs to know the path to the WordPress core installation on your machine. While you were previously prompted to specify this path manually on project startup, starting with version 2025.1, PhpStorm attempts to discover the path and automatically enables support for the WordPress framework.\n\n\n\n\nIf it’s unable to detect the path, the IDE will open the PHP | Frameworks settings page so you can provide the required information.\nJetBrains AI\nAlongside PhpStorm, JetBrains AI Assistant has received a major update. Now, all JetBrains AI features are available for free in PhpStorm and other JetBrains IDEs, offering unlimited access to code completion and local model support, with credit-based limits for other features.\nWe’re also introducing a new subscription system that makes it easy to scale up as needed with the AI Pro and AI Ultimate tiers.\nLearn more\n\n\n\n\nExpanded selection of LLMs in chat\nThe AI model selection in the chat has just been expanded! Now, you can take full control of your AI experience by choosing from the latest and most advanced language models, including Claude 3.7 Sonnet and Gemini 2.0 Flash.\n\n\n\n\nAnd we’re not stopping here! JetBrains is committed to continuously integrating AI models to ensure you have access to the most up-to-date AI technologies.\nImproved context awareness in chat\nLocal and cloud LLMs can now leverage PhpStorm’s indexing data on the PHP methods used in your project. This allows AI Assistant to improve the quality and relevance of code snippets generated in the chat.\nOffline mode: Work with local models\nAI Assistant gives you the flexibility to work with local models offline or leverage cloud-based AI processing. With the new offline mode, you can now work without an internet connection while still benefiting from AI-powered coding assistance. Use local models via Ollama or LM Studio for chat, code generation, commit messages, inline documentation, and more.\n\n\n\n\nMulti-file changes in edit mode Beta\nEditing multiple files has never been easier! AI Assistant now supports multi-file edits in the chat, suggesting changes across your project while leveraging retrieval-augmented generation (RAG) to locate the most relevant files. Reduce repetitive tasks and implement modifications across multiple files with a single interaction.\n\n\n\n\nApply snippets from chat\nNow, when the AI chat suggests a code snippet, you can use the Apply button to automatically find the optimal place to insert the newly generated code – no more manual copy-pasting. This feature significantly streamlines your workflow.\n\n\n\n\nSmarter AI context awareness\nAI Assistant now understands your entire project better, using advanced RAG to surface the most relevant files, methods, and classes. In addition, the context now includes recently accessed files, making interactions even more relevant to your workflow. Because you can now also add or remove attachments sent as context, you maintain full control over the AI’s context.\nExclude files from AI context\nYou can further enhance your control over what AI Assistant sees by configuring an .aiignore file. This allows you to prevent JetBrains AI from accessing specific files or folders, ensuring that sensitive information is never processed.\n\n\n\n\nWeb search from chat\nWith the new /web command, AI Assistant can now fetch documentation, troubleshooting tips, and the latest technical resources directly from the web – right inside your chat window. No more switching tabs or searching manually!\n\n\n\n\nAttached schemas in the Explain with AI chat\nExplanations are more effective when they use all the relevant context. Now, when you ask AI Assistant to explain a query, the corresponding schema is automatically attached to the chat.\n\nTry AI Assistant\nFrontend\nImproved Vue and Nuxt support\nPhpStorm now makes it easier to start new Vue projects with Nuxt CLI (nuxi) integration in the New Project wizard, allowing for a smoother setup experience.\nWe’ve also improved support for Vue’s global properties by correctly resolving custom properties added through module augmentation. Additionally, issues with autocomplete and auto-import for packaged components declared with __VLS_WithTemplateSlots have been fixed, ensuring a more reliable development experience in Vue projects.\n\n\n\n\nBetter monorepo support\nWorking in a monorepo just got smoother! PhpStorm now respects Prettier configs per subproject, offers smarter auto-imports and path alias resolution via improved exports handling, and delivers faster code completion and navigation in large Nx workspaces. Enjoy a more consistent and efficient coding experience across all your projects.\n\n\n\n\nUser experience\nNew terminal architecture Beta\nThe 2025.1 release introduces a reworked terminal architecture, which is available in Beta. The terminal now runs on a stable, standards-compliant core and uses the IDE’s editor to render the UI. This change lets us introduce new features while preserving compatibility and performance across various platforms, whether local or remote. Get more details about our plans and progress in this blog post.\n\n\n\n\nSearch functionality in Markdown previews\nIn PhpStorm 2025.1, you can search within Markdown previews. Since README.md previews are often the first thing you see when opening or cloning a project, this update makes it easier to find key information instantly.\n\n\n\n\nNative OS file dialogs on Windows \nPhpStorm now defaults to using native Windows file dialogs instead of the IDE’s custom implementation. This gives you a more familiar experience when opening or saving files. If you prefer the previous behavior, you can restore it in Advanced Settings | User Interface.\n\n\n\n\n\n\n\n\nCommit experience updates\nWe are refining the non-modal commit workflow, the default built-in option, in response to the extensive feedback we received during the Early Access Program. The modal commit interface is becoming a plugin, which can be activated in Settings | Advanced Settings | Version Control. Git. In version 2025.1, the plugin will be bundled with the IDE, so you’ll be able to continue using the interface without having to install it manually.",
        "dc:creator": "Hanna Yakush",
        "content": "This release is a major update that includes improvements in PHPStan annotations, Xdebug, and WordPress support, an AI Free tier and new subscription system for JetBrains AI, and more. Download PhpStorm 2025.1 PHP Code completion for @phpstan-type and @phpstan-import-type&#160; This release improves PhpStorm’s PHPStan annotation support, introducing code completion for array shape aliases in @phpstan-type [&#8230;]",
        "contentSnippet": "This release is a major update that includes improvements in PHPStan annotations, Xdebug, and WordPress support, an AI Free tier and new subscription system for JetBrains AI, and more. Download PhpStorm 2025.1 PHP Code completion for @phpstan-type and @phpstan-import-type  This release improves PhpStorm’s PHPStan annotation support, introducing code completion for array shape aliases in @phpstan-type […]",
        "guid": "https://blog.jetbrains.com/?post_type=phpstorm&p=558008",
        "categories": [
          "2025-1",
          "release"
        ],
        "isoDate": "2025-04-16T13:18:22.000Z"
      },
      {
        "creator": "Maciej Gorywoda",
        "title": "IntelliJ Scala Plugin 2025.1 Is Out!",
        "link": "https://blog.jetbrains.com/scala/2025/04/16/intellij-scala-plugin-2025-1-is-out/",
        "pubDate": "Wed, 16 Apr 2025 13:05:20 +0000",
        "content:encodedSnippet": "Support for new features in Scala 3\nContext Bounds and Givens\nScala 3.6 introduced a new syntax for context bounds and givens. You can read more about it in SIP-64. In short, before Scala 3.6, it was impossible to name the context bound in the same place where it was defined. The way to do it was to introduce an implicit parameter, which resulted in awkward syntax, e.g. def reduce[A](xs: List[A])(using m: Monoid[A]): A introduced the context bound Monoid[A] as m. In the new syntax, it’s possible to simply write def reduce[A: Monoid as m](xs: List[A]): A and IntelliJ IDEA with the Scala plugin recognizes it and supports it.\nIn a similar vein, we now support the recent changes in the given syntax.\nThree old ways to declare and name a context bound vs the new syntax\n\n\n\nMultiple context bounds\n\n\n\nSolving an old issue of a forward declaration of a context bound\n\n\n\n\nNamed Tuples\nScala 3.7 brings the stabilization of Named Tuples and IntelliJ IDEA 2025.1 with the Scala Plugin already supporting them. In the new release, apart from simply recognizing the syntax for Named Tuples, we also support them in pattern matching, when you can both match against a given value of one of the tuple’s fields, and extract that value to a new reference. On top of that, Scala 3.7 comes with a new way to extract a field value from a case class or a class with a customized unapply method that returns a named tuple. Until now, we could either use the underscore to mark all the fields we were not interested in when calling the unapply, or we could assign a whole class instance to a reference and then access the field we wanted through that reference.  Now, it’s possible as well to simply name the fields we are interested in and assign their values to new references.\nYou can read more about Named Tuples in SIP-58.\n\n\n\n\n\nRefutable patterns in for-comprehensions\nSince Scala 3.4, refutable patterns (i.e., patterns that might not match) in for-comprehensions must be preceded by the case keyword, or an error is reported. The new syntax helps recognize those cases.\n\n\n\n\n\nOther Scala 3 improvements\nThe resolution of nested implicit definitions is now more precise, which means that now Scala Plugin reports some errors that weren’t caught before, while in other situations we no longer highlight code red where the code compiles just fine. The handling of intersection types used to define the “self” type was improved, and the support for named tuples, that we introduced recently. Besides, the Scala 3 code is now correctly highlighted in code snippets in Markdown files displayed in IntelliJ IDEA.\n\n\n\n\nThe debugger\nWe fixed a bug in Scala 2.13.3 where the debugger didn’t stop on breakpoints inside lazy vals in try/catch blocks, and another, similar, when the debugger sometimes had trouble stopping at breakpoints inside lambdas in a trait.\n\n\n\n\n\nsbt\nWe made several improvements to the new separate production/test modules. A new “Generate sbt managed sources” action helps avoid situations when good code is red because it relies on sources generated during the project import. On top of that, the “New Project” wizard now suggests downloading the JDK for a new sbt project, and we don’t show anymore the banner “No Scala SDK in module” when at the same time we offer to simply load the sbt project, which will automatically setup SDK.\n\n\n\n\n\nCode highlighting and inlay hints\nIn the 2024.3 release, we introduced support for transparent inline methods in Scala 3. Now, as we continue to work on support for Scala macros, we offer support for Scala 2 macro types. Also, we improved type hints for variable patterns, generators, and literal parameters, as well as type info for underscore parameters and kind projector syntax. The X-Ray mode was enhanced as well: you can now enable parameter name hints for all parameters, not only literals, and see when the apply method is being used, instead of an ordinary constructor.\n\n\n\n\n\nOther changes\nCode completion can now provide partial results during indexing. Besides, when you use Code With Me for Scala projects, you will see that the auto-import quick-fix is offered only after code editing on the host.\n\n\n\n\nAs always, your feedback is very welcome. Please report any issues you find to YouTrack. If you have any questions, feel free to ask us on Discord.\nHappy developing!\nThe IntelliJ Scala Plugin team",
        "dc:creator": "Maciej Gorywoda",
        "content": "Support for new features in Scala 3 Context Bounds and Givens Scala 3.6 introduced a new syntax for context bounds and givens. You can read more about it in SIP-64. In short, before Scala 3.6, it was impossible to name the context bound in the same place where it was defined. The way to do [&#8230;]",
        "contentSnippet": "Support for new features in Scala 3 Context Bounds and Givens Scala 3.6 introduced a new syntax for context bounds and givens. You can read more about it in SIP-64. In short, before Scala 3.6, it was impossible to name the context bound in the same place where it was defined. The way to do […]",
        "guid": "https://blog.jetbrains.com/?post_type=scala&p=558039",
        "categories": [
          "news",
          "releases",
          "scala",
          "scala-programming",
          "intellij-idea"
        ],
        "isoDate": "2025-04-16T13:05:20.000Z"
      },
      {
        "creator": "Oleg Zinovyev",
        "title": "CLion 2025.1 Arrives With Support for Out-of-Project Files in CLion Nova, Qt Renderers, the ST-LINK Debug Server, and West Build Options",
        "link": "https://blog.jetbrains.com/clion/2025/04/clion-2025-1-release/",
        "pubDate": "Wed, 16 Apr 2025 12:36:35 +0000",
        "content:encodedSnippet": "CLion 2025.1 is now available. This latest version of the JetBrains IDE for C and C++ includes the following key features:\nSupport for out-of-project files when using the CLion Nova engine.\nQt renderers in the debugger.\nThe ST-LINK debug server designed for STM32 chips.\nwest build command options and sysbuild for Zephyr projects.\nA free tier and new features for AI Assistant.\n\n\n\n\nYou can download CLion 2025.1 from the link below, via the Toolbox App, as a snap package if you’re using Ubuntu, or via a patch update from version 2024.3.\nDOWNLOAD CLION 2025.1\nCLion Nova\nIn this release, CLion Nova has received some of the most requested features, including support for out-of-project files, multiple settings, actions, and smart keys, and basic Objective-C support.\nOut-of-project files\nCLion Nova now provides full code analysis and code assistance for header and source files that are not included in a project. For example, when you open an out-of-project .cpp file just to edit it, you get all of the essential features, such as code formatting, code completion, and typing assistance.\n\n                        \n\n\nThe current implementation covers most of the known use cases. However, there are some edge cases we plan to address after receiving feedback.\nBasic support for Objective-C\nYou can now get syntax highlighting, code completion suggestions, warnings, and other editor features when working with Objective-C source files. Header files, however, may not be handled correctly, and some features, including refactorings and smart keys, may not work.\n\n\n\n\nIf you need the same Objective-C support in CLion Nova that you get in CLion Classic, please follow or upvote CPP-37281.\nSettings, actions, and smart keys\nCLion Nova has gained several settings, actions, and smart keys that were previously exclusive to CLion Classic, making development with the new language engine even more convenient. Here are just a few examples:\nThe Auto import local files with quotes and Auto import on completion options. (You can learn more about configuring auto-import in the documentation.)\nMove to Code Block End and Move to Code Block Start – ⌘⌥] (macOS) or Ctrl+] (Windows or Linux) and ⌘⌥ [ (macOS) or Ctrl+[ (Windows or Linux), respectively.\nThe Surround selection on typing quote or brace and Unindent on Backspace smart keys – ⌫ (macOS) or Backspace (Windows or Linux).\n\n\n\n\nRead our documentation to learn more about all of the available actions and smart keys, as well as their shortcuts.\nGoogleTest and Catch2 support in Bazel projects\nCLion Nova now supports the GoogleTest and Catch2 testing frameworks in Bazel projects. However, there are still some limitations.\nTo learn more about the basics of unit testing and how to use testing tools in CLion, read our documentation.\nDebugger\nUpdates for the debugger include Qt renderers for user-friendly data representation when debugging Qt applications, support for custom LLDB debuggers and custom locations for .natvis files, and the ability to view two-channel OpenCV matrices as images.\nQt renderers\nQt renderers, also known as Qt pretty printers and Qt debugging helpers, allow you to view variables, such as QList, QString, or QByteArray, in a human-readable form. This simplifies the development and debugging of applications built using the Qt framework.\n\n\n\n\nThis feature is enabled by default, but to use it, you need to download the Qt renderers and specify the path to them:\nGo to Settings | Build, Execution, Deployment | Debugger | Data Views | C/C++ and find the Renderers section.\nClick Download… next to the Path to a directory with Qt renderers field. \nClick Download Qt Renderers in the window that appears. The path will be specified automatically.\n\n\n\n\nNote that Qt renderers don’t yet work with remote and WSL toolchains.\nSupport for custom LLDB debuggers\nIn addition to the bundled LLDB, which is currently v19.1.3, you can now use a custom LLDB when working on macOS or Linux. This allows you to choose the version best suited to the requirements of your project.\nYou can select a custom LLDB in Settings | Toolchains | Debugger. CLion will then automatically try to find the custom LLDB installed on your system. You can also manually specify its location.\n\n\n\n\nNote that custom LLDBs don’t yet work with WSL, Docker, or Remote Host toolchains and are not currently available for Windows.\nAbility to view two-channel OpenCV matrices as images\nWhen debugging an ML or computer vision application that uses OpenCV, you can now view two-channel matrices – such as cv::Mat m(2, 3, CV_8UC2) – as images.\n\n                        \n\n\nTo do this, select the Threads & Variables pane of the debugger when your program is suspended at a breakpoint, navigate to the two-channel matrix, and click View as image.\nCustom location for .natvis files\nNatvis renderers, also known as Natvis visualizers, allow you to define visualization rules for various data types when using the MSVC debugger. Previously, CLion’s functionality was limited to loading .natvis files solely from the project directory. This was a challenge in terms of flexibility, particularly when working with Git or other VCSs. The latest update introduces the ability to specify a custom location for your .natvis files, improving versatility and convenience.\nYou can add an additional directory with Natvis renderers in Settings | Build, Execution, Deployment | Debugger | Data Views | C/C++.\n\n\n\n\nEmbedded development\nEnhancements for embedded development include a new ST-LINK debug server configuration option, the updated STM32CubeMX New Project wizard, and improvements to the Serial Port Monitor plugin.\nST-LINK debug server experimental\nWhen debugging STM32 projects, you can now use the ST-LINK debug server template, which was designed specifically for STM32 chips. It includes only the essential settings, simplifying the configuration process.\nTo try the ST-LINK template, go to Settings | Build, Execution, Deployment | Debugger | Debug Servers and click +. Then, configure your GDB server, device, and debugger parameters in the corresponding tabs.\n\n\n\n\nNote that the ST-LINK configuration option currently only works with:\nThe ST-LINK GDB server shipped with STM32CubeCLT and STM32CubeIDE.\nSingle and dual-core MCUs.\nST-LINK/V2 and ST-LINK/V3 probes.\nSTM32CubeMX New Project wizard\nThe process of creating STM32CubeMX projects has been updated to improve usability and extend support to a broader range of STM32 chips and projects. CLion now uses the native STM32CubeMX approach to generate CMake files. This ensures that project creation is fully aligned with the official STM32CubeMX workflow and toolchain.\n\n                        \n\n\nWhen you open the New Project wizard and select STM32CubeMX, you’ll find detailed instructions on creating an STM32CubeMX project, including information about the actions you need to perform in STM32CubeMX.\nWe realize that the current approach to STM32CubeMX project creation is still not ideal, and we welcome your feedback as we continue to improve (CPP-42553).\nSerial Port Monitor plugin improvements\nYou can now view and manage the DTR, DSR, RTS, and CTS hardware control signals when working with the Serial Port Monitor plugin. This gives you more control over attached devices that use a serial port such as ESP32 and Arduino.\nTo enable hardware control signals:\nIn the Serial Connections tool window, navigate to the Connect tab.\nSelect the desired COM port.\nClick Show HW controls.\n\n\n\n\nThe control options and indicators will then appear in the COM port tab.\n\n\n\n\nIn the same tool window, you can also enable timestamps to view them in the monitor output. This option is handy for tracking message sequences in detail when troubleshooting.\n\n\n\n\nProject formats and build tools\nAs part of our efforts to improve Zephyr West support, this release introduces the ability to use the west build command options and sysbuild. We’ve also updated the bundled CMake to v3.31.4, which includes support for CMake Presets v10.\nwest build options and sysbuild support\nIf you’re working with Zephyr West projects, you can now use the west build command options, as well as sysbuild as your primary build system. This gives you more flexibility when it comes to configuring your projects, including those involving hardware.\nYou can pass the west build command options from Settings | Build, Execution, Deployment | Embedded Development | West | Advanced Settings.\nSysbuild is a build system that allows you to build multiple images for boards with multiple SoCs (systems on chip) or SoCs with multiple CPU cores. To enable it, pass –sysbuild along with any other options you want from the same Advanced Settings section.\n\n\n\n\nCMake Presets v10\nThe bundled CMake version has been updated to v3.31.4 and includes support for CMake Presets v10. Presets are stored as JSON files and are useful when you want to specify common configurations and build options for a CMake project, for example, to share them with your teammates.\nBazel plugin updates\nOur Bazel plugin has received two of its most requested features: \nSupport for Windows.\nSupport for custom toolchains, such as those based on GCC, LLVM, and MSVC.\n\n\n\n\nThese enhancements allow you to use different toolchain configurations across platforms, making it easier to develop a wide range of projects, including automotive and embedded ones.\nRead our blog post to learn how to configure your Windows machine for C/C++ development with Bazel, import a Bazel project into CLion, and set up a custom toolchain.\nFree tier and other AI Assistant updates\nAll AI Assistant features are now free in CLion and other JetBrains IDEs, which makes AI-powered development more accessible and efficient. New AI features include the ability to handle natural language prompts for C/C++ and a new edit mode for multi-file edits directly from the chat.\nFree tier\nAI Assistant features are now free. Some of them, such as unlimited code completion and local model support, are completely unlimited, while others have limited credit-based access. A new subscription system makes it easy to scale up as needed with the AI Pro and AI Ultimate tiers.\nNew cloud models and functionality\nAI Assistant has received enhancements that increase productivity and reduce repetitive tasks, such as support for new cloud models like Claude 3.7 Sonnet and Gemini 2.0 Flash, smarter code completion, and a new edit mode for multi-file edits directly from the chat.\nAI Assistant also has learned to understand natural language prompts for C/C++. After you write a prompt and press Tab, AI Assistant interprets it and translates it into code changes, taking your project’s context into consideration.\n\n                        \n\n\nTry CLion and give us your feedback\nWe invite you to give CLion 2025.1 a try. If you have an active subscription, you can update it right away. New to CLion? Start your free 30-day trial today and dive into all its features and improvements immediately.\nWe value your feedback! If you have anything to share or if you run into any problems, please let us know through our issue tracker.\nDOWNLOAD CLION 2025.1\nYour CLion team\nJetBrains\nThe Drive to Develop",
        "dc:creator": "Oleg Zinovyev",
        "content": "CLion 2025.1 is now available. This latest version of the JetBrains IDE for C and C++ includes the following key features: You can download CLion 2025.1 from the link below, via the Toolbox App, as a snap package if you’re using Ubuntu, or via a patch update from version 2024.3. DOWNLOAD CLION 2025.1 CLion Nova [&#8230;]",
        "contentSnippet": "CLion 2025.1 is now available. This latest version of the JetBrains IDE for C and C++ includes the following key features: You can download CLion 2025.1 from the link below, via the Toolbox App, as a snap package if you’re using Ubuntu, or via a patch update from version 2024.3. DOWNLOAD CLION 2025.1 CLion Nova […]",
        "guid": "https://blog.jetbrains.com/?post_type=clion&p=557748",
        "categories": [
          "news",
          "releases",
          "bazel",
          "clionnova",
          "embedded",
          "opencv",
          "qt",
          "release",
          "stm32",
          "zephyr-west"
        ],
        "isoDate": "2025-04-16T12:36:35.000Z"
      },
      {
        "creator": "Anna Protsenko",
        "title": "GoLand 2025.1 Is Out!",
        "link": "https://blog.jetbrains.com/go/2025/04/16/goland-2025-1-is-out/",
        "pubDate": "Wed, 16 Apr 2025 12:29:54 +0000",
        "content:encodedSnippet": "GoLand 2025.1 comes with several exciting updates to help you write better Go code and work more efficiently. This release introduces support for golangci-lint, improvements to the Rename refactoring and static analysis, smarter handling of the toolchain directive, and full support for Go 1.24. We’re also bringing major updates for JetBrains AI. Let’s take a closer look at what’s new!\n\n\n\n    \nDownload GoLand 2025.1\n                                                    \nAI support\nJetBrains AI has received a major upgrade, bringing both AI Assistant and Junie under a single subscription. With this release, all JetBrains AI features are accessible for free in our IDEs, with unlimited use for some, such as unlimited code completion and local model support, and limited credit-based access to others. We’re also introducing a new subscription system that makes it easy to scale up as needed with the AI Pro and AI Ultimate tiers. \nThis release introduces major enhancements to boost productivity and reduce repetitive work. Updates include smarter code completion, support for new cloud models like Claude 3.7 Sonnet and Gemini 2.0 Flash, advanced RAG-based context awareness, and a new edit mode for multi-file edits directly from the chat. Learn more about JetBrains AI plans and capabilities here.\nNew Go features\nSupport for golangci-lint\nGoLand now integrates the Go Linter plugin, bringing native support for golangci-lint. You can configure it in Settings | Go | Linters, choosing exactly which checks to enable or disable. Inspections run in real time as you code, helping you catch issues early without leaving the IDE.\nYou can also reuse your existing CI configurations to keep linter behavior consistent across environments. Read the full guide to learn more.\n\n\n\n\nGoLand does not yet offer support for version 2 of golangci-lint, but we are working to implement it.\nImproved Rename refactoring for struct fields\nWhen renaming struct fields, GoLand now automatically updates the corresponding JSON tags. This prevents mismatches between field names and serialized output and ensures refactorings are applied consistently across your codebase.\n\n\n\n\nImproved notifications and support for the toolchain directive\nGoLand now notifies you when a project’s SDK is changed due to the toolchain directive in go.mod. Additionally, we’ve improved the codebase so that GoLand can handle this directive more effectively.\n\n\n\n\nFull support for Go 1.24\nGoLand 2025.1 aligns with the latest version of Go and fully supports its new language features:\nGeneric type aliases: GoLand now recognizes and offers support, including navigation, highlighting, and code completion, for type aliases with type parameters.\nThe tool directive in go.mod: The IDE properly reports errors if the directive is used with unsupported Go versions.\nUpdated Delve debugger: With Delve 1.24.0 bundled out of the box, GoLand now includes all recent fixes and improvements to ensure smoother debugging.\nImproved go get behavior: The deprecated -d flag is no longer added to commands run from the IDE, preventing unnecessary warnings in the Run tool window.\nInherited features from IntelliJ IDEA, WebStorm, and DataGrip\nGoLand also brings in many of the latest features from the IntelliJ Platform ecosystem. Explore what’s new in:\nIntelliJ IDEA\nWebStorm\nDataGrip\n\n\n\n\nWe’d love to hear your feedback on these new features so we can make them even better. Share your thoughts on X, leave a comment below, create an issue in our tracker, or chat with us in the #goland-gophers Slack channel.\nHappy developing!\nThe GoLand Team",
        "dc:creator": "Anna Protsenko",
        "content": "GoLand 2025.1 comes with several exciting updates to help you write better Go code and work more efficiently. This release introduces support for golangci-lint, improvements to the Rename refactoring and static analysis, smarter handling of the toolchain directive, and full support for Go 1.24. We’re also bringing major updates for JetBrains AI. Let’s take a [&#8230;]",
        "contentSnippet": "GoLand 2025.1 comes with several exciting updates to help you write better Go code and work more efficiently. This release introduces support for golangci-lint, improvements to the Rename refactoring and static analysis, smarter handling of the toolchain directive, and full support for Go 1.24. We’re also bringing major updates for JetBrains AI. Let’s take a […]",
        "guid": "https://blog.jetbrains.com/?post_type=go&p=559188",
        "categories": [
          "news",
          "releases",
          "goland-2025-1"
        ],
        "isoDate": "2025-04-16T12:29:54.000Z"
      },
      {
        "creator": "Richie Mitish",
        "title": "DataGrip 2025.1: Schema Context for AI-based Error Explanations, Introspection by Levels for MySQL and MariaDB, and More!",
        "link": "https://blog.jetbrains.com/datagrip/2025/04/16/datagrip-2025-1-schema-context-for-ai-based-error-explanations-introspection-by-levels-for-mysql-and-mariadb-and-more/",
        "pubDate": "Wed, 16 Apr 2025 12:26:14 +0000",
        "content:encodedSnippet": "DataGrip 2025.1 is here! This is the first major update of 2025. Let’s take a look at what it has to offer. For a detailed description of this update, visit our What’s New page.\nAI Assistant\nJetBrains AI features are accessible for free in our IDEs, with unlimited use for some and limited use for others.\nThere is a new subscription model that includes AI Pro and AI Ultimate options, as well as a free tier.\nSchema context is now automatically added to AI-based error explanations.\nAI Assistant now also supports more cutting-edge LLMs.\n\n\n\n\nConnectivity\nIntrospection by levels is now supported for MySQL and MariaDB.\nSQL Server data sources can now use the .NET JDBC driver with the Shared Memory protocol.\nSpecific roles can now be defined when connecting to Oracle databases.\nThe Data Sources and Drivers dialog now supports tildes in file directories for BigQuery and SSL connection settings.\nMaven mirrors and custom repositories can now be used to download JDBC drivers.\n\n\n\n\nWorking with data\nFull cell values can now be loaded in place.\nCorrect display of raw geo-type values is now supported for PostgreSQL, MySQL, and MariaDB databases.\nThe data editor can now display BigQuery microsecond timestamps.\n\n\n\n\nCoding assistance\nDataGrip now suggests switching to Single session mode when using temporary tables.",
        "dc:creator": "Richie Mitish",
        "content": "DataGrip 2025.1 is here! This is the first major update of 2025. Let’s take a look at what it has to offer. For a detailed description of this update, visit our What’s New page. AI Assistant Connectivity Working with data Coding assistance",
        "contentSnippet": "DataGrip 2025.1 is here! This is the first major update of 2025. Let’s take a look at what it has to offer. For a detailed description of this update, visit our What’s New page. AI Assistant Connectivity Working with data Coding assistance",
        "guid": "https://blog.jetbrains.com/?post_type=datagrip&p=553642",
        "categories": [
          "news",
          "releases",
          "newsletter"
        ],
        "isoDate": "2025-04-16T12:26:14.000Z"
      },
      {
        "creator": "David Watson",
        "title": "WebStorm 2025.1: Major Improvements to JetBrains AI, Enhanced Angular Support, and Better Monorepo Support",
        "link": "https://blog.jetbrains.com/webstorm/2025/04/webstorm-2025-1/",
        "pubDate": "Wed, 16 Apr 2025 12:18:26 +0000",
        "content:encodedSnippet": "Our first major release of 2025 is here! This version includes major improvements to JetBrains AI, enhanced Angular support, better monorepo support, a range of user experience improvements, and a whole lot more.\n\n\n\n\n\nDOWNLOAD WEBSTORM 2025.1\n\n\n\n\nTo dive deeper into what you can expect in the release, just carry on reading!\nThe new features and improvements in v2025.1 include:\nAI enhancements: AI Assistant and Junie with a free tier, support for more cutting-edge LLMs, improved AI completion for web frameworks, and more.\nAngular improvements: Support for Angular 17.2 signal queries, better reactive forms support, better property suggestions for Angular bindings, and more.\nMonorepo improvements: Per-subproject Prettier configuration support, better path alias support for auto-imports in monorepos, and more.\nImproved user experience: Automatic run configurations for Next.js, the floating Show Context Actions toolbar, new file creation in the Project tool window, and more.\nAI enhancements\nJetBrains AI has received a major upgrade, bringing both AI Assistant and the coding agent, Junie, under a single subscription. With this release, all JetBrains AI features are accessible for free in our IDEs, with unlimited use for some, such as unlimited code completion and local model support, and limited credit-based access to others. We’re also introducing a new subscription system that makes it easy to scale up as needed with the AI Pro and AI Ultimate tiers.\n\n\n\nSupport for more cutting-edge LLMs\nJetBrains AI Assistant is advancing its line of models! We’ve added support for Claude 3.7 Sonnet and Claude 3.5 Haiku, now provisioned in Amazon Bedrock. This means you’ll benefit from sharper responses, faster insights, and an even smoother experience. AI Assistant’s lineup of OpenAI models now includes o1, o1-mini, o3-mini, and GPT-4.5.\n\n\n\nIn addition to cloud-based models, you can now connect the AI chat to local models available through Ollama and LM Studio! You can set up local providers via Settings | Tools | AI Assistant | Custom Models:\n\n\n\nImproved AI completion for web frameworks\nFor the 2025.1 release, we have focused on improving AI-based completion in the context of web framework components. These changes affect local full line code completion as well as cloud-based completion suggestions:\n\n\n\nEnhanced AI test generation\nAI-powered test generation now offers more careful framework detection, especially for cases when multiple frameworks are present. Additionally, generated tests respect naming conventions:\n\n\n\nAngular improvements\nSupport for Angular 17.2 signal queries\nWebStorm now supports signal queries introduced in Angular 17.2, providing better code insight and navigation for this modern reactive approach to dependency injection. With this update, WebStorm ensures accurate type inference for signal queries, improves code completion within query expressions, and enhances navigation between signals and their references.\n\nBetter property suggestions for Angular bindings\nWebStorm now supports code completion for host binding attributes based on directive selectors. Quick-fixes for creating fields are also available within binding expressions. Moreover, refactoring is supported across your codebase and is even available for CSS classes:\n\n\nBetter reactive forms support\nThe long-awaited support for reactive forms is here. This update includes code completion, syntax highlighting, validation, refactoring, and quick-fixes for reactive forms. Both declaration styles – constructor-based and builder-based – are fully supported.\n\n\nExtract of inline component templates\nThere is also a new intention to extract or inline component templates. Invoke Show Context Actions via⌥⏎ (macOS) or Alt+Enter (Windows/Linux) to use the action:\n\n\n\nMonorepo improvements\nPer-subproject Prettier configuration support\nWebStorm now respects Prettier configurations on a per-subproject basis, ensuring that each part of your monorepo or multi-project setup follows its own formatting rules. This improvement provides greater flexibility and consistency when working across different codebases with varying style requirements.\n\n\n\nImproved performance in large Nx monorepos\nWebStorm now delivers faster code completion and navigation for large TypeScript monorepos using Nx. This update ensures that code completion, navigation, and auto-imports work seamlessly, even in complex multiproject workspaces, reducing lags and improving overall development efficiency.\nBetter auto-import and syntax highlighting in monorepos\nWebStorm now correctly resolves auto-imports and syntax highlighting for sibling packages in monorepos, ensuring a smoother development experience. This fix eliminates issues where dependencies between internal packages weren’t recognized, making navigation and code completion more reliable in multipackage projects.\nImproved handling of the exports field in package.json\nWebStorm now correctly processes array values in the exports field of package.json, ensuring proper resolution of module exports. This improvement enhances auto-imports, navigation, and code completion for packages that use the exports field, making dependency management more seamless and intuitive.\nBetter path alias support for auto-imports in monorepos\nWebStorm now correctly resolves path aliases defined in the exports field of package.json, ensuring that auto-imports work seamlessly in monorepos. This improvement enhances module resolution, making it easier to navigate and import dependencies across your project.\nFrameworks and Technologies\nNext.js improvements\nWebStorm 2025.1 introduces automatic run configuration creation for Next.js applications. Now, you can easily initiate debug sessions for both the client and server components of your Next.js application using the Run widget.\n\n\n\nVue improvements\nWebStorm now makes it easier to start new Vue projects with Nuxt CLI (nuxi) integration in the New Project wizard, allowing for a smoother setup experience.\n\n\n\nWe’ve also improved support for Vue’s global properties by correctly resolving custom properties added through module augmentation. Additionally, issues with autocomplete and auto-import for packaged components declared with __VLS_WithTemplateSlots have been fixed, ensuring a more reliable development experience in Vue projects.\nTailwind CSS 4 support and improved at-rule handling\nWebStorm now offers full support for Tailwind CSS 4, ensuring compatibility with the latest version of the framework. Additionally, we’ve improved handling for Tailwind-specific at-rules like @config, @plugin, and @source, providing better file reference support and reducing false warnings. Unknown at-rules and functions from Tailwind v4 are now correctly recognized, making your workflow smoother when working with the latest Tailwind features.\nUser Experience\nFloating Show Context Actions toolbar\nIn WebStorm 2025.1, invoking Show Context Actions (⌥⏎ (macOS) / Alt+Enter (Windows/Linux)) now opens the floating toolbar with different action groups. The toolbar also appears when you select code in the editor:\n\n\n\nThe floating toolbar contains the following actions and action groups:\nContext actions\nAI Assistant context actions (if the AI Assistant plugin is installed)\nRefactor\nShow usages\nSurround with tag\nReformat code\nYou can customize the contents of the toolbar by opening the kebab menu (three vertical dots) and selecting the Customize Toolbar… option\nNew file creation in the Project tool window\nCreating new files is now easier in the Project tool window. You can simply use the + icon located directly in the window’s toolbar:\n\n\n\nOption to set automatic plugin updates\nYou can set WebStorm to automatically update plugins in the background. It will download available and compatible updates and apply them on the next IDE restart without additional notifications. You can enable automatic updates by clicking the Enable auto-update checkbox in the update dialog or via File | Settings | Appearance & Behavior | System Settings | Updates.\nMerged main menu in the main toolbar on Windows and Linux\nFor Windows and Linux users, the IDE now offers a new option to merge the main menu with the main toolbar, creating a more streamlined interface.\nEasier toolbar customization in the Debug tool window\nWith so many powerful features in the debugger, you can now customize the toolbar to fit your workflow. Simply right-click next to the kebab menu in the top pane and select Add to Debugger Toolbar. A list of available actions will appear, allowing you to choose the ones that best suit your project and streamline your debugging experience.\nImproved formatting for marked-up text in debugging\nWhen inspecting a value that contains marked-up text, WebStorm now displays it with proper formatting instead of as a plain, lengthy string. For example, if the value is an XML input for a parser, it will appear in a structured, readable format, making it easier to analyze.\nGraphQL and Prisma\nImproved GraphQL support in tagged templates\nWebStorm now automatically injects GraphQL syntax highlighting and validation for gql(query)-style tagged templates. This enhancement ensures better code completion, error checking, and formatting, making it easier to work with GraphQL queries inside JavaScript and TypeScript files.\nEnhanced Prisma support\nWebStorm now offers improved Prisma support, including ULID (universally unique lexicographically sortable identifier) recognition with proper syntax highlighting, validation, and autocompletion. Additionally, multi-line comments are now fully supported in Prisma schemas, making it easier to document database structures with longer explanations.\nThere are lots of new improvements and enhancements to try out in this latest WebStorm release. If you’d like a list of everything included in WebStorm 2025.1, please check out the release notes. We hope you enjoy this release. As always, please share your feedback with us and report any issues you find to our issue tracker.\nThe WebStorm team",
        "dc:creator": "David Watson",
        "content": "Our first major release of 2025 is here! This version includes major improvements to JetBrains AI, enhanced Angular support, better monorepo support, a range of user experience improvements, and a whole lot more. DOWNLOAD WEBSTORM 2025.1 To dive deeper into what you can expect in the release, just carry on reading! The new features and [&#8230;]",
        "contentSnippet": "Our first major release of 2025 is here! This version includes major improvements to JetBrains AI, enhanced Angular support, better monorepo support, a range of user experience improvements, and a whole lot more. DOWNLOAD WEBSTORM 2025.1 To dive deeper into what you can expect in the release, just carry on reading! The new features and […]",
        "guid": "https://blog.jetbrains.com/?post_type=webstorm&p=557955",
        "categories": [
          "news",
          "releases",
          "webstorm-2025-1"
        ],
        "isoDate": "2025-04-16T12:18:26.000Z"
      },
      {
        "creator": "Maria Kosukhina",
        "title": "IntelliJ IDEA 2025.1 Is Out! ",
        "link": "https://blog.jetbrains.com/idea/2025/04/intellij-idea-2025-1/",
        "pubDate": "Wed, 16 Apr 2025 12:17:16 +0000",
        "content:encodedSnippet": "The IntelliJ IDEA 2025.1 release has landed! It delivers numerous refinements across the IDE to enhance your productivity, the quality of your code, and your overall comfort.\n\n\n\n\nYou can download this version from our website, update directly from within the IDE, use the free Toolbox App, or install it via snap packages for Ubuntu.\nDownload IntelliJ IDEA 2025.1\nThe highlights of this release include full Java 24 support, the introduction of Kotlin notebooks and K2 mode enabled by default, marking a major step toward delivering the best Kotlin experience. Additionally, JetBrains AI has received a significant upgrade, unifying AI Assistant and Junie under a single subscription. The debugging support is also more powerful, with new options to pause and resume watch evaluations.\nThere are many more updates and refinements across the IDE, briefly covered in this blog post. For a complete list of new features with short demos, visit our What’s New page. \nJetBrains AI\nWith this release, all JetBrains AI features are accessible for free in our IDEs, with unlimited use for some – including code completion and local model support – and limited credit-based access to others. We’re also introducing a new subscription system that makes it easy to scale up as needed with the AI Pro and AI Ultimate tiers. Highlights of this release include smarter completion, advanced context awareness, and support for  Claude 3.7 Sonnet and Gemini 2.0 Flash. \nLearn more\n                                    \nKey highlights \nVersion 2025.1 provides full support for all features in the Java 24 release, ensuring a seamless experience with the newest language updates. Learn more in this blog post. \nIn this release, K2 mode is enabled by default, marking a major milestone in our journey to enhance code analysis, memory efficiency, and overall performance for Kotlin development in IntelliJ IDEA. Active users are already experiencing a smoother workflow, and we’re continuing to address outstanding issues, refine refactorings and inspections, and further improve quality based on your feedback. Learn more in this blog post.\nYou can now pause and resume watch evaluations during debugging to control the potential side effects of watch computations. \nKotlin Notebook, a new interactive environment for JVM developers, is now a built-in feature of IntelliJ IDEA! Kotlin notebooks are perfect for a wide range of tasks – from real-time prototyping, presenting, log parsing, and documentation writing to in-depth data analysis and visualization. Learn more in this blog post. \nUser experience \nIntelliJ IDEA 2025.1 introduces a Beta version of the new terminal architecture, which is built on a stable, standards-compliant core and uses the IDE’s editor for UI rendering. Learn more in this blog post. \nYou can now merge the main menu into the main toolbar on Windows and Linux. \nSearch functionality has been enabled in Markdown previews. \nIntelliJ IDEA now defaults to using native Windows file dialogs instead of the IDE’s custom implementation. \nThe New File popup is now available from the Project tool window, streamlining new file creation. \nYou can set IntelliJ IDEA to automatically update plugins in the background. \nKotlin \nIntelliJ IDEA 2025.1 improves the stability and predictability of dependency resolution in Kotlin build scripts.  \nWe’ve introduced a long-awaited quick-fix that automatically inserts qualified names in KDoc links to simplify documentation writing. \nThe IDE now provides hints about code alterations caused by Kotlin compiler plugins, making their behavior more transparent.\nScala\nThe new version provides improved Scala 3 support, including updates for context bounds, givens, named tuples, for-comprehension syntax, and implicit resolution logic.\nThe debugger no longer encounters issues stopping at breakpoints inside lambdas in traits and inside lazy vals in try…catch blocks. \nIntelliJ IDEA 2025.1 delivers sbt project improvements, including separate production and test modules and a new Generate sbt managed sources action. Additionally, the New Project wizard now suggests downloading the JDK for new sbt projects. \nThe IDE now provides better highlighting for Scala code, with support for Scala 2 macro types, improved type hints, and better handling of kind-projector syntax.\nCode completion now provides partial results during indexing.\nThe new version enhances the Code With Me experience by showing auto-import quick-fixes only after edits have been made on the host. \nBuild tools\nIntelliJ IDEA 2025.1 adds support for Gradle Daemon toolchains, syncing with Gradle’s configuration to let you define the exact JVM for the Daemon and download it automatically when needed.\nIt is now easier to access library sources in Gradle projects, as the IDE automatically downloads them when you navigate to a relevant file.\nWe’ve improved support for multi-release JARs, ensuring a smoother Maven project setup experience by correctly handling additional source roots with different language levels.\nThe new version provides better support for Bazel projects. Learn more. \nVersion control systems\nCommit details are now displayed directly in the diff view.\nYou can now run any custom tool as a pre-commit check alongside inspections and formatting by configuring it in the Run Configuration dialog. \nIntelliJ IDEA now automatically fetches changes when you add or update a Git remote, ensuring you always have the latest branch list and commit history without needing to fetch them manually. \nA new setting allows you to instruct the IDE not to run Git commit hooks.  \nWe’re refining the non-modal commit workflow, and we’ve moved the modal commit interface to a plugin, which is bundled in v2025.1 and can be enabled in Settings | Advanced Settings | Version Control | Git.\nDebugger\nYou can now customize the Debug tool window’s toolbar to better fit your workflow by right-clicking next to the kebab menu, selecting Add to Debugger Toolbar, and choosing actions to add from the list that appears.\nDuring debugging, when inspecting a value that contains markup text, you can now view it with proper formatting instead of as a plain, lengthy string. \nThe features and enhancements in version 2025.1 that are designed to facilitate work with frameworks, technologies, and databases, as well as the updates for web development, are accessible in IntelliJ IDEA Ultimate only.\nFrameworks and technologies\nIntelliJ IDEA automatically creates Spring Data repositories for you. \nThe HTTP Client now conveniently opens HTTP requests generated from code in the right-hand editor split.\nThe Logical code structure view is available for Liquibase.\nIntelliJ IDEA now allows you to export Kafka records directly to JSON, CSV, and TSV files, making it easier to analyze and share streaming data. \nThe new version introduces interactive gutter actions for .tofu files, allowing you to run key OpenTofu commands directly from the editor without switching to the terminal.\nThe IDE now recognizes Containerfiles natively, offering syntax highlighting, linting, and snippet suggestions.\nIntelliJ IDEA 2025.1 allows you to write Dockerfile instructions in lowercase, in addition to the conventional uppercase.  \nWe’ve introduced a new Dockerfile inspection that ensures your ENTRYPOINT is correctly initiated with exec.  \nThe New Project wizard now provides an option to use a Git-ready Ubuntu image for easier Dev Container setup.\nThe IDE now supports the userEnvProbe option in devcontainer.json, making it easier to replicate your local shell environment inside Dev Containers.  \nSupport for WSL workflows has been enhanced. \nWeb development \nIntelliJ IDEA 2025.1 adds support for Angular 17.2 signal queries, smarter reactive form completion, and improved code completion for host binding attributes with quick-fixes. \nThe new version improves monorepo support by respecting Prettier configs per subproject, providing smarter auto-imports and path resolution, and delivering faster performance in large Nx workspaces.\nDatabase tools \nIntelliJ IDEA 2025.1 introduces introspection levels for MySQL and MariaDB, automatically adjusting the amount of loaded metadata based on database size to speed up introspection and improve performance. Learn more. \nThe IDE now automatically attaches the corresponding schema to the Explain with AI chat, providing more context for query explanations.\nWe have implemented support for the use of tildes (~) in the path fields for SSL certificates and BigQuery key files.  \nThere is now a setting that helps you control the amount of data that’s loaded in each cell.  \nFor PostgreSQL, MySQL, and MariaDB spatial databases, IntelliJ IDEA can now correctly display geo types raw in the grid.\nIntelliJ IDEA 2025.1 allows you to download drivers from Maven or other custom repositories by adding them to the mirrors attribute in the HOME_PATH/.m2/settings.xml file.\nOther \nThe IDE no longer supports Linux distributions running glibc versions below 2.28. If your system uses an unsupported version, IntelliJ IDEA will display a warning on startup.\nThese are the key improvements introduced in IntelliJ IDEA 2025.1. For the full list of changes, please check out the release notes.\nWe’d love to hear your thoughts on the new features and enhancements. Please connect with us on X or share your feedback in the comments below. If you encounter any issues while using the IDE, report them in our issue tracker.\nHappy developing!",
        "dc:creator": "Maria Kosukhina",
        "content": "The IntelliJ IDEA 2025.1 release has landed! It delivers numerous refinements across the IDE to enhance your productivity, the quality of your code, and your overall comfort. You can download this version from our website, update directly from within the IDE, use the free Toolbox App, or install it via snap packages for Ubuntu. Download [&#8230;]",
        "contentSnippet": "The IntelliJ IDEA 2025.1 release has landed! It delivers numerous refinements across the IDE to enhance your productivity, the quality of your code, and your overall comfort. You can download this version from our website, update directly from within the IDE, use the free Toolbox App, or install it via snap packages for Ubuntu. Download […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=555886",
        "categories": [
          "releases",
          "intellij-idea",
          "intellij-idea-2025-1",
          "release"
        ],
        "isoDate": "2025-04-16T12:17:16.000Z"
      },
      {
        "creator": "Alexey Varfolomeev",
        "title": "RubyMine 2025.1: Major AI Assistant Upgrade, Cloud-Based Code Completion for RBS, More Ruby 3.4 Support, Kamal Schema Updates, Enhanced RemDev, and More",
        "link": "https://blog.jetbrains.com/ruby/2025/04/rubymine-2025-1-major-ai-assistant-upgrade/",
        "pubDate": "Wed, 16 Apr 2025 12:15:35 +0000",
        "content:encodedSnippet": "RubyMine 2025.1 introduces a massively upgraded AI Assistant (code completion for RBS, offline mode, more models available, and other features), support for the latest Kamal version, debugging for multi-module projects, and significantly improved remote development.\nBelow is a brief overview of the most notable features. For a detailed description of this update, please visit our What’s New page.\nYou can get the new build from our website or via the free Toolbox App.\nAI Assistant\nThe new RubyMine release comes with all JetBrains AI features accessible for free, with unlimited use for some, such as unlimited code completion and local model support, and limited credit-based access to others. You can choose what to use and how to use it with the new subscription system. Watch our video to learn more.\nRBS coding assistance\nRubyMine 2025.1 further expands the powers of the JetBrains AI Assistant plugin with code completion for RBS based on JetBrains’ new Mellum model. AI Assistant now also allows you to use natural language prompts directly in the editor to enhance your RBS coding.\n\n\n\n\nBetter AI suggestions\nAI code suggestions are now provided with error inspections and syntax highlighting to make sure you find and use only what best suits your purposes.\nNew models and modes\nTake full control of your AI experience in RubyMine by choosing from the latest and most advanced models: Claude 3.7 Sonnet and Gemini 2.0 Flash.\n\n\n\n\n\n\n\n\nYou can now also use the plugin offline. With Ollama and LM Studio local models, all AI-powered coding assistance is still available even when there’s no internet connection.\n\n\n\n\nImproved AI chat\nBe more productive with the upgraded AI chat, which can now locate the most relevant files and make suggestions across your entire project within one interaction. Moreover, it will find and suggest where to insert the newly generated code to save you the trouble of manual copy-pasting. All it takes is one click on the Apply button.\n\n\n\n\nSmarter AI awareness\nThe revamped AI Assistant better understands your entire project thanks to the advanced RAG-based retrieval technique. While AI context now includes recently accessed files, you can tell AI Assistant which files or folders to ignore by configuring an .aiignore file.\n\n\n\n\nRuby\nRuby 3.4 support \nRubyMine 2025.1 displays warnings when you create constants or modify the global Ruby namespace and sends error messages when using keyword and block arguments inside index assignments.\n\n\n\n\nasdf 0.16+ compatibility \nRubyMine 2025.1 supports the latest version of asdf to make sure the interpreters installed with this version manager are recognized properly. This fixes any issues you might have previously encountered in RubyMine when using the re-written 0.16 version of asdf.\nRails\nKamal 2.4.0 and 2.5.0 support \nRubyMine 2025.1 comes with the updated deploy.yml schema to help you deploy your Rails applications with the new 2.4.0 and 2.5.0 versions of Kamal.\n\n\n\n\nRake task and Rails generator handling\nControl the automatic refreshing of Rails generators and Rake tasks using advanced settings. When the automatic loading is disabled, only manual reload actions are available. We have also improved the UX by placing loading errors in balloon notifications instead of the previously used window notifications. \n\n\n\n\nUser experience \nUser interface updates\nThe UI improvements in RubyMine 2025.1 include native Windows file dialogs, which are part of the default settings but can be changed to the previous option in Advanced Settings | User Interface. We also simplified the procedure of creating new files. After clicking the + icon in the Project tool window, you can now quickly find and select the required template from the popup using the search field. \n\n\n\n\nAutomatic plugin updating \nRubyMine 2025.1 can update plugins in the background. With this setting, all available and compatible updates are downloaded and applied on the next RubyMine restart. \n\n\n\n\nVCS \nRubyMine 2025.1 no longer offers the modal commit interface as a bundled option, but you can still use it as a separate plugin. Another change is the enhanced diff view, which allows you to see commit details for quicker and easier analysis of the file history and modifications.\n\n\n\n\nRemote development \nContainerfile support\nEnjoy more freedom and flexibility when using various tools for remote solutions in the same environment. With RubyMine 2025.1 featuring built-in Containerfile recognition, Docker, Podman, and Buildah can all be configured in the same file. And this file is fully recognized by the tools of your choice, with full support for syntax highlighting, linting, and snippet suggestions.\n\n\n\n\nImproved editing\nWith reduced typing, highlighting, and formatting latency, RubyMine 2025.1 ensures a better overall editing experience in remote development.\nTo learn about the latest features as they come out, please follow RubyMine on X. \nWe invite you to share your thoughts in the comments below and to suggest and vote for new features in the issue tracker.\n\n\n\n\nHappy developing!\n\n\n\n\nThe RubyMine team",
        "dc:creator": "Alexey Varfolomeev",
        "content": "RubyMine 2025.1 introduces a massively upgraded AI Assistant (code completion for RBS, offline mode, more models available, and other features), support for the latest Kamal version, debugging for multi-module projects, and significantly improved remote development. Below is a brief overview of the most notable features. For a detailed description of this update, please visit our [&#8230;]",
        "contentSnippet": "RubyMine 2025.1 introduces a massively upgraded AI Assistant (code completion for RBS, offline mode, more models available, and other features), support for the latest Kamal version, debugging for multi-module projects, and significantly improved remote development. Below is a brief overview of the most notable features. For a detailed description of this update, please visit our […]",
        "guid": "https://blog.jetbrains.com/?post_type=ruby&p=559466",
        "categories": [
          "rubymine",
          "ai",
          "release",
          "rubymine-2025-1"
        ],
        "isoDate": "2025-04-16T12:15:35.000Z"
      }
    ]
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Katie Savage",
        "title": "GitHub Copilot Highlights in Visual Studio 17.14 Preview 3 (Available Now)",
        "link": "https://devblogs.microsoft.com/visualstudio/github-copilot-highlights-in-visual-studio-17-14-preview-3-available-now/",
        "pubDate": "Wed, 16 Apr 2025 18:24:10 +0000",
        "content:encodedSnippet": "Visual Studio 17.14 Preview 3 is now available!\nDownload Visual Studio Preview\n\nThe GitHub Copilot experience in Visual Studio is continuously updated to provide the latest advancements in AI-assisted development. The following features and improvements have been recently released in Visual Studio version 17.14 Preview 3. (Remember, preview versions of Visual Studio can be run side by side with the main releases)\n\nA guided Walkthrough for getting started\nIf you’re new to GitHub Copilot in Visual Studio and are looking for a quick, guided way to get started, this feature is for you. Head to the GitHub Copilot badge dropdown and select GitHub Copilot Walkthrough. This will launch the walkthrough as a new tab in your workspace.\nThis five-step walkthrough will show you how to get Copilot for free, introduce you to AI-powered code completions, Copilot Chat, show you how to provide Copilot with specific context about your solution, and introduce you to the multi-file editing power of Copilot Edits. Once you complete these steps, you should be ready to start using and experimenting with Copilot.\ndocument.createElement('video');\nhttps://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2025/04/WalkthroughP3.mp4\n\nImproved model access and Code Mapping\nIt’s also now easier than ever to access the latest models like Claude 3.7 from within Visual Studio. Instead of needing to adjust your settings, you can now enable any of the available models from github.com directly through Visual Studio. When you select your model within Copilot Chat, you will be prompted to enable your chosen model.\nhttps://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2025/04/ModelApprovalP3.mp4\n\nHow and where Copilot inserts its code suggestions into your code in the right place has also gotten an upgrade in this release with improvements to what we call “Code Mapping”.\nhttps://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2025/04/CodeMappingP3.mp4\n\nCopilot can suggest the next edit and fix pasted code automatically\nWe also have some exciting updates coming to the Code Completion experience that will allow Copilot to better understand your intention as you’re writing code and enhance its ability to assist you with editing your code. The feature is called Next Edit Suggestions, which helps developers by providing contextual suggestions for code edits based on previous changes.\nhttps://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2025/04/NESP3.mp4\n\nAnother feature to watch out for is adaptive paste which automatically adjusts code you paste into Visual Studio to fit the context of your existing code, minimizing the need for manual modifications. This feature also supports scenarios such as minor error fixes, code styling, formatting, human and code language translation, and fill-in-the-blank or continue-the-pattern tasks.\nhttps://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2025/04/AdaptivePasteP3.mp4\n\nLearn more about these features in the preview 3 release notes: Visual Studio 2022 Preview Release Notes | Microsoft Learn\nTry the latest Preview\nIf you’d like to see any of these features in action and stay up to date with the latest Copilot updates, try out the preview version of Visual Studio.\nCheck out the new Visual Studio Hub\nStay connected with everything Visual Studio in one place! Visit the Visual Studio Hub for the latest release notes, YouTube videos, social updates, and community discussions.\nAppreciation for your feedback\nYour feedback helps us improve Visual Studio, making it an even more powerful tool for developers. We are immensely grateful for your contributions and look forward to your continued support. By sharing your thoughts, ideas, and any issues you encounter through Developer Community, you help us improve and shape the future of Visual Studio.\nThe post GitHub Copilot Highlights in Visual Studio 17.14 Preview 3 (Available Now) appeared first on Visual Studio Blog.",
        "enclosure": {
          "url": "https://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2025/04/WalkthroughP3.mp4",
          "length": "9841988",
          "type": "video/mp4"
        },
        "dc:creator": "Katie Savage",
        "comments": "https://devblogs.microsoft.com/visualstudio/github-copilot-highlights-in-visual-studio-17-14-preview-3-available-now/#comments",
        "content": "<p>Visual Studio 17.14 Preview 3 is now available! The GitHub Copilot experience in Visual Studio is continuously updated to provide the latest advancements in AI-assisted development. The following features and improvements have been recently released in Visual Studio version 17.14 Preview 3. (Remember, preview versions of Visual Studio can be run side by side with [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/github-copilot-highlights-in-visual-studio-17-14-preview-3-available-now/\">GitHub Copilot Highlights in Visual Studio 17.14 Preview 3 (Available Now)</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Visual Studio 17.14 Preview 3 is now available! The GitHub Copilot experience in Visual Studio is continuously updated to provide the latest advancements in AI-assisted development. The following features and improvements have been recently released in Visual Studio version 17.14 Preview 3. (Remember, preview versions of Visual Studio can be run side by side with […]\nThe post GitHub Copilot Highlights in Visual Studio 17.14 Preview 3 (Available Now) appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=252998",
        "categories": [
          "Copilot",
          "Visual Studio"
        ],
        "isoDate": "2025-04-16T18:24:10.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": [
      {
        "creator": "에디의 기술블로그",
        "title": "다시 개발을 시작했더니, 세상이 바뀌어 있었다.",
        "link": "https://brunch.co.kr/@@2MrI/866",
        "pubDate": "Sat, 12 Apr 2025 10:42:03 GMT",
        "author": "에디의 기술블로그",
        "content": "오랜만에 다시 개발을 시작했다. 실무에서 손을 뗀 지는 꽤 되었고, 딸아이가 태어난 이후 병원 치료에 집중해야 했기 때문에 자연스럽게 업무 시간도 줄어들었다. 나는 개발팀 리더는 실무에 깊이 관여하지 않아도 된다는 나름의 철학을 갖고 있었기에, 그 상황을 받아들이는 데 큰 저항은 없었다. 주기적으로 경영진과의 팀의 방향성을 설계하고, 개발조직이&nbsp;최고의 성과",
        "contentSnippet": "오랜만에 다시 개발을 시작했다. 실무에서 손을 뗀 지는 꽤 되었고, 딸아이가 태어난 이후 병원 치료에 집중해야 했기 때문에 자연스럽게 업무 시간도 줄어들었다. 나는 개발팀 리더는 실무에 깊이 관여하지 않아도 된다는 나름의 철학을 갖고 있었기에, 그 상황을 받아들이는 데 큰 저항은 없었다. 주기적으로 경영진과의 팀의 방향성을 설계하고, 개발조직이 최고의 성과",
        "guid": "https://brunch.co.kr/@@2MrI/866",
        "isoDate": "2025-04-12T10:42:03.000Z"
      }
    ]
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": [
      {
        "title": "Gemini 기반 MCP 서버 및 클라이언트 개발해 보기 ",
        "link": "http://daddynkidsmakers.blogspot.com/2025/04/gemini-mcp.html",
        "pubDate": "2025-04-13T00:58:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">이 글은&nbsp;Gemini 기반 MCP 서버 및 클라이언트를 개발하는 방법을 간략히 보여준다.</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhm2o0xjgQULzjL4FnWbvTN0EZq5ejD3hsoffi1vYZcG1jzqXODlvmDVnpfybgf8a0TuJ0nqpuE46IfQgsX-dOFjTOSkx6lZTdUoEyz-F5lFJFfgQN-WqLbsldwwot3pxyBrJ2-ugwWwvzWGHM8erMtYTNwQheMSZi83krw0VkSqE80hrbTgbVWUX4YMxce\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"600\" data-original-width=\"1200\" height=\"200\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhm2o0xjgQULzjL4FnWbvTN0EZq5ejD3hsoffi1vYZcG1jzqXODlvmDVnpfybgf8a0TuJ0nqpuE46IfQgsX-dOFjTOSkx6lZTdUoEyz-F5lFJFfgQN-WqLbsldwwot3pxyBrJ2-ugwWwvzWGHM8erMtYTNwQheMSZi83krw0VkSqE80hrbTgbVWUX4YMxce=w400-h200\" width=\"400\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">MCP 기반 멀티 AI 에이전트 아키텍처 개념도</div><br /></div><div style=\"text-align: left;\">MCP의 개념과 상세한 동작 방식은 다음 글을 참고한다.</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b>개요</b></div><div style=\"text-align: left;\">MCP는 클라이언트-서버 구조를 따른다. 클라이언트는 서버의 MCP 도구를 사용하는 AI 앱이나 LLM을 의미한다. 서버는 MCP 도구를 공급하고, API, 데이터소스 인터페이스를 제공한다.&nbsp;</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">MCP를 통해 LLM이 해결하지 못하는 작업은 외부 시스템과 연결해 서비스 받을 수 있다.</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">MCP서버는 파일 시스템 조작, 웹 검색, 데이터베이스 조작, 버전 관리 등 다양한 도구를 제공할 수 있다.&nbsp;</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b>제미니 LLM 기반 MCP 구조</b></div><div style=\"text-align: left;\">다음은 제미니 LLM 기반 MCP 구조 예시를 보여준다. 이 예는 비행기 예약 유스케이스를 구현한다.</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjJi0KvcBwMZamL_qYjpkJ9L5wCc-L1FNm1XiMpxofuR_BheadHYrmEwVlCidd_Z0u5T01UFwpfrWr-xF23ENbqmEviz_Wqs3rc8VIbUxuHgCoAYP3kP8HU1HIpukYPk9sDOagmKn3vt_bqXFLXA1VDFEalzd9ySjbsxJMgvH9jCDLW6ktNyM917NZ_LnEg\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"755\" data-original-width=\"1067\" height=\"357\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjJi0KvcBwMZamL_qYjpkJ9L5wCc-L1FNm1XiMpxofuR_BheadHYrmEwVlCidd_Z0u5T01UFwpfrWr-xF23ENbqmEviz_Wqs3rc8VIbUxuHgCoAYP3kP8HU1HIpukYPk9sDOagmKn3vt_bqXFLXA1VDFEalzd9ySjbsxJMgvH9jCDLW6ktNyM917NZ_LnEg=w505-h357\" width=\"505\" /></a></div>구조의 각 번호는 시퀀스 시나리오를 보여준다. 이 내용은 다음과 같다.</div><div style=\"text-align: left;\"><ol style=\"text-align: left;\"><li>MCP 호스트가 사용자 명령 입력. 예) 내일 인천에서 애틀란타 가는 비행편 찾기</li><ol><li>클라이언트 스크립트가 입력을 처리(CLIENT.PY)</li></ol><li>클라이언트가 MCP 서버 프로세스 시작(MCP-FLIGHT-SEARCH). STDIO 통신 채널 연결 및 관련 도구 검색</li><li>클라이언트가 사용자 명령에 대한 함수 호출 방법을 수신함</li><li>클라리언트가 함수 호출 방법에 대한 정확한 함수 호출 형식을 GEMINI에서 획득. 함수 호출 형식에 부합하는 적절한 MCP 도구를 서버에 호출. 서버의 도구 함수 호출 결과를 리턴</li><li>MCP 서버가 구글 항공편 검색을 위한 SerpAPI를 호출. 구글 항공편 데이터 질의.</li><li>구글 항공편 정보 리턴</li><li>서버에서 클라이언트로 해당 정보 리턴</li><li>클라이언트가 호스로 해당 정보 전달</li></ol><div><b>개발 환경</b></div>개발을 위한 최소한의 환경은 파이썬 3.8+이다. 이외 다음을 준비한다.</div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><a href=\"https://console.cloud.google.com/\">Google Cloud</a> 에서 Project 생성</li></ul><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhfTBQEXNM-unXJdkC_ZpFiH8j6l1wDRupyOGynBHVdb0mfX81QoZKJ86O-9jZa3wX-1I5MQqT8J96KGVFXZvVTrAIzinVnJHEfkaGQzSiAv4GyfwycWhkgCgZHIkYL7UdX_lad4hVrJXan6rasu-xOmyARkM9yJk2xSD7sy63ua7TmbRvSgJdqne4P1vMm\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"806\" data-original-width=\"1747\" height=\"185\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhfTBQEXNM-unXJdkC_ZpFiH8j6l1wDRupyOGynBHVdb0mfX81QoZKJ86O-9jZa3wX-1I5MQqT8J96KGVFXZvVTrAIzinVnJHEfkaGQzSiAv4GyfwycWhkgCgZHIkYL7UdX_lad4hVrJXan6rasu-xOmyARkM9yJk2xSD7sy63ua7TmbRvSgJdqne4P1vMm=w400-h185\" width=\"400\" /></a></div></div><ul style=\"text-align: left;\"><li>Google <a href=\"https://aistudio.google.com/apikey\">Gemini API</a>&nbsp;키 획득</li></ul><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjJk7hEyenBNWdRjlm114O1G5wlRXCEirzbE7wdn6agF01g36Ufj0KNq7XfOqNlLZ63WayLKcqZk8kXh4kYDqAhV4Zmx0rPdXu1re_vXdWxuAEAdlJ4fHRyLQZqeNnq6qTXUPyBHqoymW54Xj_ORkmaiK-wROnczvyrYjm8naTAFRmIV4F3-OKYYdLm-UK9\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"911\" data-original-width=\"1946\" height=\"150\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjJk7hEyenBNWdRjlm114O1G5wlRXCEirzbE7wdn6agF01g36Ufj0KNq7XfOqNlLZ63WayLKcqZk8kXh4kYDqAhV4Zmx0rPdXu1re_vXdWxuAEAdlJ4fHRyLQZqeNnq6qTXUPyBHqoymW54Xj_ORkmaiK-wROnczvyrYjm8naTAFRmIV4F3-OKYYdLm-UK9\" width=\"320\" /></a></div></div><ul style=\"text-align: left;\"><li><a href=\"https://serpapi.com/\">SerpAPI</a> 키 획득</li></ul><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjXELm_6bCIugZHmhrYyUzDynDZzL5Nb2e3QCQsP6aLcCbvf6nDVNsZmV5KL1tQdl94hzOE9noB2d07QKfNorNqHKdy_KgOGjWMp-EqDxe7AZqrWEyWmZVKF2i_pvkd4lor23dOOgpzhbA8v67icVqUHmQ6yeJ_kuU2pW9gA7eI9sdFdXzSKMTYh8HJ9Xrm\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"903\" data-original-width=\"1989\" height=\"145\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjXELm_6bCIugZHmhrYyUzDynDZzL5Nb2e3QCQsP6aLcCbvf6nDVNsZmV5KL1tQdl94hzOE9noB2d07QKfNorNqHKdy_KgOGjWMp-EqDxe7AZqrWEyWmZVKF2i_pvkd4lor23dOOgpzhbA8v67icVqUHmQ6yeJ_kuU2pW9gA7eI9sdFdXzSKMTYh8HJ9Xrm\" width=\"320\" /></a></div><br /></div><div>다음 종속성을 터미널에서 설치한다. google-genai는 google 생성AI 라이브러리이며, mcp는 MCP 서버 통신을 위한 파이썬 SDK이다.&nbsp;</div><div>pip install google-genai mcp</div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">환경변수를 설정한다.&nbsp;</div><div style=\"text-align: left;\"><div>export GEMINI_API_KEY=\"your-google-api-key\"</div><div>export SERP_API_KEY=\"your-serpapi-key\"</div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b>항공편 검색 MCP 서버 설치</b></div><div style=\"text-align: left;\">MCP 프로토콜 공개 이후로 많은 MCP 서버가 개발되었다. 우리는 항공편 검색 MCP 서버 오픈소스인 <a href=\"https://pypi.org/project/mcp-flight-search/\">mcp-flgiht-search</a> 를 사용한다. 다음을 설치한다.</div><div style=\"text-align: left;\"><div>pip install mcp-flight-search</div><div><br /></div></div><div style=\"text-align: left;\"><b>코딩해보기</b></div><div style=\"text-align: left;\">다음과 같이 client.py를 코딩한다.&nbsp;</div><div style=\"text-align: left;\"><div style=\"background-color: #1f1f1f; color: #cccccc; font-family: Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; line-height: 16px; white-space: pre;\"><div><span style=\"color: #c586c0;\">import</span> os, sys, time, asyncio</div><div><span style=\"color: #c586c0;\">from</span> google <span style=\"color: #c586c0;\">import</span> genai</div><div><span style=\"color: #c586c0;\">from</span> google.genai <span style=\"color: #c586c0;\">import</span> types</div><div><span style=\"color: #c586c0;\">from</span> mcp <span style=\"color: #c586c0;\">import</span> ClientSession, StdioServerParameters</div><div><span style=\"color: #c586c0;\">from</span> mcp.client.stdio <span style=\"color: #c586c0;\">import</span> stdio_client</div><div><span style=\"color: #c586c0;\">from</span> dotenv <span style=\"color: #c586c0;\">import</span> load_dotenv</div><br /><div>load_dotenv()</div><br /><div>gemini_api_key <span style=\"color: #d4d4d4;\">=</span> os.getenv(<span style=\"color: #ce9178;\">\"GEMINI_API_KEY\"</span>)</div><div>serp_api_key <span style=\"color: #d4d4d4;\">=</span> os.getenv(<span style=\"color: #ce9178;\">\"SERP_API_KEY\"</span>)</div><br /><div>client <span style=\"color: #d4d4d4;\">=</span> genai.Client(<span style=\"color: #9cdcfe;\">api_key</span><span style=\"color: #d4d4d4;\">=</span>gemini_api_key)</div><br /><div>server_params <span style=\"color: #d4d4d4;\">=</span> StdioServerParameters(</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">command</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"mcp-flight-search\"</span>,</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">args</span><span style=\"color: #d4d4d4;\">=</span>[<span style=\"color: #ce9178;\">\"--connection_type\"</span>, <span style=\"color: #ce9178;\">\"stdio\"</span>],</div><div>&nbsp; &nbsp; <span style=\"color: #9cdcfe;\">env</span><span style=\"color: #d4d4d4;\">=</span>{<span style=\"color: #ce9178;\">\"SERP_API_KEY\"</span>: serp_api_key},</div><div>)</div><br /><div><span style=\"color: #569cd6;\">async</span> <span style=\"color: #569cd6;\">def</span> <span style=\"color: #dcdcaa;\">run</span>():</div><div>&nbsp; &nbsp; <span style=\"color: #c586c0;\">async</span> <span style=\"color: #c586c0;\">with</span> stdio_client(server_params) <span style=\"color: #c586c0;\">as</span> (read, write):  # 항공 예약 검색 도구 등록</div><div>&nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">async</span> <span style=\"color: #c586c0;\">with</span> ClientSession(read, write) <span style=\"color: #c586c0;\">as</span> session:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; prompt <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #569cd6;\">f</span><span style=\"color: #ce9178;\">\"Find Flights from Atlanta to Las Vegas 2025-08-15\"  # 사용자 질의 명령</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">await</span> session.initialize()</div><br /><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mcp_tools <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #c586c0;\">await</span> session.list_tools()  # 도구 리스트 획득</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; tools <span style=\"color: #d4d4d4;\">=</span> [</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; types.Tool(</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">function_declarations</span><span style=\"color: #d4d4d4;\">=</span>[</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #ce9178;\">\"name\"</span>: tool.name,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #ce9178;\">\"description\"</span>: tool.description,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #ce9178;\">\"parameters\"</span>: {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; k: v</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">for</span> k, v <span style=\"color: #c586c0;\">in</span> tool.inputSchema.items()</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">if</span> k <span style=\"color: #569cd6;\">not</span> <span style=\"color: #569cd6;\">in</span> [<span style=\"color: #ce9178;\">\"additionalProperties\"</span>, <span style=\"color: #ce9178;\">\"$schema\"</span>]</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ]  # 해당 도구 함수 선언 생성</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; )</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">for</span> tool <span style=\"color: #c586c0;\">in</span> mcp_tools.tools</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ]</div><br /><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; response <span style=\"color: #d4d4d4;\">=</span> client.models.generate_content(</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">model</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #ce9178;\">\"gemini-2.5-pro-exp-03-25\"</span>,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">contents</span><span style=\"color: #d4d4d4;\">=</span>prompt,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">config</span><span style=\"color: #d4d4d4;\">=</span>types.GenerateContentConfig(</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">temperature</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">0</span>,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #9cdcfe;\">tools</span><span style=\"color: #d4d4d4;\">=</span>tools,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ),  # LLM 모델에 프롬프트 전달.</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; )</div><br /><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">if</span> response.candidates[<span style=\"color: #b5cea8;\">0</span>].content.parts[<span style=\"color: #b5cea8;\">0</span>].function_call:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; function_call <span style=\"color: #d4d4d4;\">=</span> response.candidates[<span style=\"color: #b5cea8;\">0</span>].content.parts[<span style=\"color: #b5cea8;\">0</span>].function_call # 함수호출정보</div><br /><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; result <span style=\"color: #d4d4d4;\">=</span> <span style=\"color: #c586c0;\">await</span> session.call_tool(</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; function_call.name, <span style=\"color: #9cdcfe;\">arguments</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #4ec9b0;\">dict</span>(function_call.args)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; )  # 도구 함수 호출</div><br /><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #dcdcaa;\">print</span>(<span style=\"color: #ce9178;\">\"--- Formatted Result ---\"</span>) <span style=\"color: #6a9955;\"># Add header for clarity</span></div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">try</span>:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; flight_data <span style=\"color: #d4d4d4;\">=</span> json.loads(result.content[<span style=\"color: #b5cea8;\">0</span>].text)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #dcdcaa;\">print</span>(json.dumps(flight_data, <span style=\"color: #9cdcfe;\">indent</span><span style=\"color: #d4d4d4;\">=</span><span style=\"color: #b5cea8;\">2</span>))</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">except</span> json.JSONDecodeError:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #dcdcaa;\">print</span>(<span style=\"color: #ce9178;\">\"MCP server returned non-JSON response:\"</span>)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #dcdcaa;\">print</span>(result.content[<span style=\"color: #b5cea8;\">0</span>].text)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">except</span> (<span style=\"color: #4ec9b0;\">IndexError</span>, <span style=\"color: #4ec9b0;\">AttributeError</span>):</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span style=\"color: #dcdcaa;\">print</span>(<span style=\"color: #ce9178;\">\"Unexpected result structure from MCP server:\"</span>)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span style=\"color: #dcdcaa;\">print</span>(result)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">else</span>:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #dcdcaa;\">print</span>(<span style=\"color: #ce9178;\">\"No function call was generated by the model.\"</span>)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span style=\"color: #c586c0;\">if</span> response.text:</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span style=\"color: #dcdcaa;\">print</span>(<span style=\"color: #ce9178;\">\"Model response:\"</span>)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span style=\"color: #dcdcaa;\">print</span>(response.text)</div><br /><div>asyncio.run(run()) # 클라이언트 실행</div></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">실행한다. 그럼 프롬프트에 대해 LLM이 적절한 도구와 파라메터를 확인해 함수 호출 정보를 생성한다. 이를 call_tool로 호출한 결과가 표시된다&nbsp;</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b>레퍼런스</b></div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><a href=\"https://medium.com/binome/introduction-to-graphite-an-event-driven-ai-agent-framework-540478130cd2\">Introducing Graphite — An Event Driven AI Agent Framework | by Craig Li, Ph.D | Binome | Apr, 2025 | Medium</a></li><li><a href=\"https://medium.com/google-cloud/model-context-protocol-mcp-with-google-gemini-llm-a-deep-dive-full-code-ea16e3fac9a3\">Model Context Protocol(MCP) with Google Gemini 2.5 Pro - Deep Dive , Google Cloud Gen AI | Google Cloud - Community</a></li><li><a href=\"https://github.com/arjunprabhulal/mcp-gemini-search?source=post_page-----ea16e3fac9a3---------------------------------------\">Model Context Protocol (MCP) with Gemini 2.5 Pro. Convert conversational queries into flight searches using Gemini's function calling capabilities and MCP's flight search tools</a></li></ul></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><br /></div>",
        "contentSnippet": "이 글은 Gemini 기반 MCP 서버 및 클라이언트를 개발하는 방법을 간략히 보여준다.\n\n\n\nMCP 기반 멀티 AI 에이전트 아키텍처 개념도\n\nMCP의 개념과 상세한 동작 방식은 다음 글을 참고한다.\n\n\n개요\nMCP는 클라이언트-서버 구조를 따른다. 클라이언트는 서버의 MCP 도구를 사용하는 AI 앱이나 LLM을 의미한다. 서버는 MCP 도구를 공급하고, API, 데이터소스 인터페이스를 제공한다. \n\n\nMCP를 통해 LLM이 해결하지 못하는 작업은 외부 시스템과 연결해 서비스 받을 수 있다.\n\n\nMCP서버는 파일 시스템 조작, 웹 검색, 데이터베이스 조작, 버전 관리 등 다양한 도구를 제공할 수 있다. \n\n\n제미니 LLM 기반 MCP 구조\n다음은 제미니 LLM 기반 MCP 구조 예시를 보여준다. 이 예는 비행기 예약 유스케이스를 구현한다.\n\n\n구조의 각 번호는 시퀀스 시나리오를 보여준다. 이 내용은 다음과 같다.\n\nMCP 호스트가 사용자 명령 입력. 예) 내일 인천에서 애틀란타 가는 비행편 찾기\n\n클라이언트 스크립트가 입력을 처리(CLIENT.PY)\n\n클라이언트가 MCP 서버 프로세스 시작(MCP-FLIGHT-SEARCH). STDIO 통신 채널 연결 및 관련 도구 검색\n클라이언트가 사용자 명령에 대한 함수 호출 방법을 수신함\n클라리언트가 함수 호출 방법에 대한 정확한 함수 호출 형식을 GEMINI에서 획득. 함수 호출 형식에 부합하는 적절한 MCP 도구를 서버에 호출. 서버의 도구 함수 호출 결과를 리턴\nMCP 서버가 구글 항공편 검색을 위한 SerpAPI를 호출. 구글 항공편 데이터 질의.\n구글 항공편 정보 리턴\n서버에서 클라이언트로 해당 정보 리턴\n클라이언트가 호스로 해당 정보 전달\n\n개발 환경\n개발을 위한 최소한의 환경은 파이썬 3.8+이다. 이외 다음을 준비한다.\n\nGoogle Cloud 에서 Project 생성\n\n\n\nGoogle Gemini API 키 획득\n\n\n\nSerpAPI 키 획득\n\n\n\n다음 종속성을 터미널에서 설치한다. google-genai는 google 생성AI 라이브러리이며, mcp는 MCP 서버 통신을 위한 파이썬 SDK이다. \npip install google-genai mcp\n\n\n환경변수를 설정한다. \n\nexport GEMINI_API_KEY=\"your-google-api-key\"\nexport SERP_API_KEY=\"your-serpapi-key\"\n\n\n항공편 검색 MCP 서버 설치\nMCP 프로토콜 공개 이후로 많은 MCP 서버가 개발되었다. 우리는 항공편 검색 MCP 서버 오픈소스인 mcp-flgiht-search 를 사용한다. 다음을 설치한다.\n\npip install mcp-flight-search\n\n\n코딩해보기\n다음과 같이 client.py를 코딩한다. \n\nimport os, sys, time, asyncio\nfrom google import genai\nfrom google.genai import types\nfrom mcp import ClientSession, StdioServerParameters\nfrom mcp.client.stdio import stdio_client\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\ngemini_api_key = os.getenv(\"GEMINI_API_KEY\")\nserp_api_key = os.getenv(\"SERP_API_KEY\")\n\nclient = genai.Client(api_key=gemini_api_key)\n\nserver_params = StdioServerParameters(\n    command=\"mcp-flight-search\",\n    args=[\"--connection_type\", \"stdio\"],\n    env={\"SERP_API_KEY\": serp_api_key},\n)\n\nasync def run():\n    async with stdio_client(server_params) as (read, write):  # 항공 예약 검색 도구 등록\n        async with ClientSession(read, write) as session:\n            prompt = f\"Find Flights from Atlanta to Las Vegas 2025-08-15\"  # 사용자 질의 명령\n            await session.initialize()\n\n            mcp_tools = await session.list_tools()  # 도구 리스트 획득\n            tools = [\n                types.Tool(\n                    function_declarations=[\n                        {\n                            \"name\": tool.name,\n                            \"description\": tool.description,\n                            \"parameters\": {\n                                k: v\n                                for k, v in tool.inputSchema.items()\n                                if k not in [\"additionalProperties\", \"$schema\"]\n                            },\n                        }\n                    ]  # 해당 도구 함수 선언 생성\n                )\n                for tool in mcp_tools.tools\n            ]\n\n            response = client.models.generate_content(\n                model=\"gemini-2.5-pro-exp-03-25\",\n                contents=prompt,\n                config=types.GenerateContentConfig(\n                    temperature=0,\n                    tools=tools,\n                ),  # LLM 모델에 프롬프트 전달.\n            )\n\n            if response.candidates[0].content.parts[0].function_call:\n                function_call = response.candidates[0].content.parts[0].function_call # 함수호출정보\n\n                result = await session.call_tool(\n                    function_call.name, arguments=dict(function_call.args)\n                )  # 도구 함수 호출\n\n                print(\"--- Formatted Result ---\") # Add header for clarity\n                try:\n                    flight_data = json.loads(result.content[0].text)\n                    print(json.dumps(flight_data, indent=2))\n                except json.JSONDecodeError:\n                    print(\"MCP server returned non-JSON response:\")\n                    print(result.content[0].text)\n                except (IndexError, AttributeError):\n                     print(\"Unexpected result structure from MCP server:\")\n                     print(result)\n            else:\n                print(\"No function call was generated by the model.\")\n                if response.text:\n                     print(\"Model response:\")\n                     print(response.text)\n\nasyncio.run(run()) # 클라이언트 실행\n\n\n\n실행한다. 그럼 프롬프트에 대해 LLM이 적절한 도구와 파라메터를 확인해 함수 호출 정보를 생성한다. 이를 call_tool로 호출한 결과가 표시된다 \n\n\n레퍼런스\n\nIntroducing Graphite — An Event Driven AI Agent Framework | by Craig Li, Ph.D | Binome | Apr, 2025 | Medium\nModel Context Protocol(MCP) with Google Gemini 2.5 Pro - Deep Dive , Google Cloud Gen AI | Google Cloud - Community\nModel Context Protocol (MCP) with Gemini 2.5 Pro. Convert conversational queries into flight searches using Gemini's function calling capabilities and MCP's flight search tools",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-90111100907465866",
        "isoDate": "2025-04-13T00:58:00.000Z"
      }
    ]
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": [
      {
        "creator": "흰끼끼",
        "title": "블루베리 효능 총정리: 노화 방지에 탁월한 이유 5가지",
        "link": "http://app-developer.tistory.com/entry/%EB%B8%94%EB%A3%A8%EB%B2%A0%EB%A6%AC-%ED%9A%A8%EB%8A%A5-%EC%B4%9D%EC%A0%95%EB%A6%AC-%EB%85%B8%ED%99%94-%EB%B0%A9%EC%A7%80%EC%97%90-%ED%83%81%EC%9B%94%ED%95%9C-%EC%9D%B4%EC%9C%A0-5%EA%B0%80%EC%A7%80",
        "pubDate": "Sun, 13 Apr 2025 20:44:48 +0900",
        "author": "흰끼끼",
        "comments": "http://app-developer.tistory.com/entry/%EB%B8%94%EB%A3%A8%EB%B2%A0%EB%A6%AC-%ED%9A%A8%EB%8A%A5-%EC%B4%9D%EC%A0%95%EB%A6%AC-%EB%85%B8%ED%99%94-%EB%B0%A9%EC%A7%80%EC%97%90-%ED%83%81%EC%9B%94%ED%95%9C-%EC%9D%B4%EC%9C%A0-5%EA%B0%80%EC%A7%80#entry207comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"ChatGPT Image 2025년 4월 13일 오후 08_43_47.png\" data-origin-width=\"1536\" data-origin-height=\"1024\"><span data-url=\"https://blog.kakaocdn.net/dn/c18gA9/btsNjFgQZIm/4YdksfRmkM58ehiPktlCl1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/c18gA9/btsNjFgQZIm/4YdksfRmkM58ehiPktlCl1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/c18gA9/btsNjFgQZIm/4YdksfRmkM58ehiPktlCl1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc18gA9%2FbtsNjFgQZIm%2F4YdksfRmkM58ehiPktlCl1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1536\" height=\"1024\" data-filename=\"ChatGPT Image 2025년 4월 13일 오후 08_43_47.png\" data-origin-width=\"1536\" data-origin-height=\"1024\"/></span></figure>\n</p>\n<p>현대인의 건강식으로 각광받고 있는 <strong>블루베리</strong>, 그냥 맛있는 과일일 뿐이라고 생각하셨다면 오산입니다. 특히 <strong>노화를 늦추는 항산화 식품</strong>으로 블루베리는 수많은 연구에서 그 효과가 입증되고 있는데요. 이번 글에서는 블루베리가 <strong>왜 노화 방지에 탁월한지</strong>, 그 이유 5가지를 집중적으로 알아보겠습니다.</p>\n<h2>1. 강력한 항산화 성분, 안토시아닌의 힘</h2>\n<p>블루베리는 <strong>안토시아닌(Anthocyanin)</strong>이라는 강력한 항산화 성분이 풍부하게 들어 있습니다.<br>이 성분은 활성산소로부터 세포를 보호하여 <strong>세포 노화를 늦추는 효과</strong>를 합니다.<br>피부 탄력, 주름 개선, 면역력 강화에도 큰 도움을 줍니다.</p>\n<h2>2. 뇌 기능 보호 및 인지 능력 향상</h2>\n<p>노화의 대표적인 증상 중 하나는 <strong>기억력 저하</strong>와 같은 뇌 기능 감소입니다.<br>블루베리 섭취는 <strong>신경세포 손상을 줄이고, 뇌 신호 전달을 촉진</strong>하여<br>인지 능력 향상 및 <strong>치매 예방 효과</strong>까지 기대할 수 있습니다.</p>\n<h2>3. 심혈관 건강 개선으로 노화 예방</h2>\n<p>나이가 들수록 혈관 건강은 더 중요해지죠.<br>블루베리는 <strong>혈관을 깨끗하게 유지하고, 혈압과 콜레스테롤 수치를 낮추는 데</strong> 도움을 줍니다.<br>이로 인해 <strong>심혈관 질환 예방</strong>은 물론, 신체 전체의 노화 속도도 늦출 수 있습니다.</p>\n<h2>4. 면역력 강화로 각종 질병 예방</h2>\n<p>노화가 진행되면 <strong>면역 시스템이 약화</strong>되기 쉽습니다.<br>블루베리 속 <strong>비타민 C, K, 망간 등의 영양소</strong>는 면역 기능을 강화해<br>감기나 바이러스, 염증성 질환 등 각종 <strong>질병으로부터 몸을 보호</strong>해 줍니다.</p>\n<h2>5. 피부 건강 개선과 안티에이징 효과</h2>\n<p>블루베리는 <strong>피부 트러블 개선과 피부 톤 개선</strong>에도 효과적입니다.<br>항산화 작용으로 인해 피부의 노화 원인인 <strong>산화 스트레스와 자외선 손상</strong>을 줄여주며,<br>피부에 <strong>생기와 탄력</strong>을 더해주는 데 도움을 줍니다.</p>\n<h2>✅ 결론</h2>\n<p>블루베리는 단순한 과일이 아니라, <strong>노화 방지를 위한 자연의 선물</strong>입니다.<br>매일 소량이라도 꾸준히 섭취한다면, 건강은 물론 <strong>젊음까지 지킬 수 있는 최고의 슈퍼푸드</strong>죠.<br>오늘부터 식단에 블루베리를 더해보는 건 어떠세요?</p>\n<blockquote data-ke-style=\"style1\"><p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Serif KR';\"><p>  <strong>팁</strong>: 신선한 블루베리뿐만 아니라, 냉동 블루베리나 블루베리 파우더도 동일한 효능을 기대할 수 있어요!</p>\n</span></p></blockquote>",
        "contentSnippet": "현대인의 건강식으로 각광받고 있는 블루베리, 그냥 맛있는 과일일 뿐이라고 생각하셨다면 오산입니다. 특히 노화를 늦추는 항산화 식품으로 블루베리는 수많은 연구에서 그 효과가 입증되고 있는데요. 이번 글에서는 블루베리가 왜 노화 방지에 탁월한지, 그 이유 5가지를 집중적으로 알아보겠습니다.\n1. 강력한 항산화 성분, 안토시아닌의 힘\n블루베리는 안토시아닌(Anthocyanin)이라는 강력한 항산화 성분이 풍부하게 들어 있습니다.\n이 성분은 활성산소로부터 세포를 보호하여 세포 노화를 늦추는 효과를 합니다.\n피부 탄력, 주름 개선, 면역력 강화에도 큰 도움을 줍니다.\n2. 뇌 기능 보호 및 인지 능력 향상\n노화의 대표적인 증상 중 하나는 기억력 저하와 같은 뇌 기능 감소입니다.\n블루베리 섭취는 신경세포 손상을 줄이고, 뇌 신호 전달을 촉진하여\n인지 능력 향상 및 치매 예방 효과까지 기대할 수 있습니다.\n3. 심혈관 건강 개선으로 노화 예방\n나이가 들수록 혈관 건강은 더 중요해지죠.\n블루베리는 혈관을 깨끗하게 유지하고, 혈압과 콜레스테롤 수치를 낮추는 데 도움을 줍니다.\n이로 인해 심혈관 질환 예방은 물론, 신체 전체의 노화 속도도 늦출 수 있습니다.\n4. 면역력 강화로 각종 질병 예방\n노화가 진행되면 면역 시스템이 약화되기 쉽습니다.\n블루베리 속 비타민 C, K, 망간 등의 영양소는 면역 기능을 강화해\n감기나 바이러스, 염증성 질환 등 각종 질병으로부터 몸을 보호해 줍니다.\n5. 피부 건강 개선과 안티에이징 효과\n블루베리는 피부 트러블 개선과 피부 톤 개선에도 효과적입니다.\n항산화 작용으로 인해 피부의 노화 원인인 산화 스트레스와 자외선 손상을 줄여주며,\n피부에 생기와 탄력을 더해주는 데 도움을 줍니다.\n✅ 결론\n블루베리는 단순한 과일이 아니라, 노화 방지를 위한 자연의 선물입니다.\n매일 소량이라도 꾸준히 섭취한다면, 건강은 물론 젊음까지 지킬 수 있는 최고의 슈퍼푸드죠.\n오늘부터 식단에 블루베리를 더해보는 건 어떠세요?\n\n  팁: 신선한 블루베리뿐만 아니라, 냉동 블루베리나 블루베리 파우더도 동일한 효능을 기대할 수 있어요!",
        "guid": "http://app-developer.tistory.com/207",
        "categories": [
          "건강/노화 및 웰에이징"
        ],
        "isoDate": "2025-04-13T11:44:48.000Z"
      },
      {
        "creator": "흰끼끼",
        "title": "배우 김수현, 故 김새론과의 의혹 해명에도&hellip;&ldquo;밤 11시에 닭볶음탕?&rdquo; 여론은 여전히 싸늘",
        "link": "http://app-developer.tistory.com/entry/%EB%B0%B0%EC%9A%B0-%EA%B9%80%EC%88%98%ED%98%84-%E6%95%85-%EA%B9%80%EC%83%88%EB%A1%A0%EA%B3%BC%EC%9D%98-%EC%9D%98%ED%98%B9-%ED%95%B4%EB%AA%85%EC%97%90%EB%8F%84%E2%80%A6%E2%80%9C%EB%B0%A4-11%EC%8B%9C%EC%97%90-%EB%8B%AD%EB%B3%B6%EC%9D%8C%ED%83%95%E2%80%9D-%EC%97%AC%EB%A1%A0%EC%9D%80-%EC%97%AC%EC%A0%84%ED%9E%88-%EC%8B%B8%EB%8A%98",
        "pubDate": "Fri, 11 Apr 2025 23:18:10 +0900",
        "author": "흰끼끼",
        "comments": "http://app-developer.tistory.com/entry/%EB%B0%B0%EC%9A%B0-%EA%B9%80%EC%88%98%ED%98%84-%E6%95%85-%EA%B9%80%EC%83%88%EB%A1%A0%EA%B3%BC%EC%9D%98-%EC%9D%98%ED%98%B9-%ED%95%B4%EB%AA%85%EC%97%90%EB%8F%84%E2%80%A6%E2%80%9C%EB%B0%A4-11%EC%8B%9C%EC%97%90-%EB%8B%AD%EB%B3%B6%EC%9D%8C%ED%83%95%E2%80%9D-%EC%97%AC%EB%A1%A0%EC%9D%80-%EC%97%AC%EC%A0%84%ED%9E%88-%EC%8B%B8%EB%8A%98#entry206comment",
        "content": "<p><figure class=\"imageblock widthContent\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"696\" data-origin-height=\"681\"><span data-url=\"https://blog.kakaocdn.net/dn/b3U4cn/btsNiwX3ewn/EmA9ff23k5aM7oyFfeVjh1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/b3U4cn/btsNiwX3ewn/EmA9ff23k5aM7oyFfeVjh1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/b3U4cn/btsNiwX3ewn/EmA9ff23k5aM7oyFfeVjh1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb3U4cn%2FbtsNiwX3ewn%2FEmA9ff23k5aM7oyFfeVjh1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"696\" height=\"681\" data-origin-width=\"696\" data-origin-height=\"681\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">2025년 3월 31일, 배우 <b>김수현</b>이 긴급 기자회견을 열고 <b>故 김새론과의 관계</b>에 대한 입장을 밝혔습니다. 하지만 이 해명 이후에도 <b>대중의 의문은 가라앉지 않고</b> 있습니다. 그 중심에는 &ldquo;고등학교 2학년, 17세였던 김새론이 <b>밤 11시에 김수현 가족이 있는 집에서 닭볶음탕을 만들었다는 정황</b>&rdquo;이 있습니다.</p>\n<hr data-ke-style=\"style1\" />\n<h2 data-ke-size=\"size26\">▶ &ldquo;연인이 아니었다&rdquo;는 주장&hellip;하지만 그 밤의 정황은?</h2>\n<p data-ke-size=\"size16\">김수현 측은 공식 입장에서 <b>&ldquo;당시 연인 관계가 아니었고, 가족들도 함께 있었다&rdquo;고 해명</b>했습니다. 논란이 된 영상은 2018년 6월 촬영된 것으로, 당시 김새론은 고등학교 2학년, <b>만 17세의 미성년자</b>였습니다.</p>\n<p data-ke-size=\"size16\">해당 영상은 <b>밤 11시 20분경</b> 촬영되었으며, <b>식탁 위에는 소주병과 소주잔이 놓여 있었다는 점</b>이 확인되며 더욱 논란이 커지고 있습니다. 소속사는 단순한 가족 식사 자리였다고 주장하지만, 많은 이들은 이 상황 자체를 납득하기 어렵다는 반응입니다.</p>\n<hr data-ke-style=\"style1\" />\n<h2 data-ke-size=\"size26\">▶ &ldquo;사귀지도 않았는데, 밤 11시에 가족 집에서 요리?&rdquo;</h2>\n<p data-ke-size=\"size16\">온라인 커뮤니티와 SNS에서는 다양한 반응이 이어지고 있습니다:</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>&ldquo;사귀지 않았다면 오히려 더 이상한 상황&rdquo;</li>\n<li>&ldquo;그 시간에 미성년자가 남자 집에 있었다는 것 자체가 부적절하다&rdquo;</li>\n<li>&ldquo;친구 사이여도 집에 돌려보낼 시간 아닌가?&rdquo;</li>\n</ul>\n<p data-ke-size=\"size16\">또한, 김새론이 김수현에게 보냈다는 <b>카카오톡 메시지</b> 내용도 공개되었습니다. 메시지에는 &ldquo;보고 싶어&rdquo;, &ldquo;언제 안고 잘 수 있어?&rdquo; 등 <b>연인 사이로 보일 수 있는 문구</b>가 담겨 있었지만, 김수현 측은 <b>&ldquo;전면 조작된 메시지&rdquo;라며 원본 데이터 제출을 요구</b>한 상태입니다.</p>\n<hr data-ke-style=\"style1\" />\n<h2 data-ke-size=\"size26\">▶ 해명에도 남은 의문&hellip;김수현 이미지 타격 불가피</h2>\n<p data-ke-size=\"size16\">김수현 소속사는 <b>&ldquo;미성년자와의 교제는 결단코 없었다&rdquo;</b>며 법적 대응을 시사하고 있지만, 유튜브 채널 <b>&lsquo;가세연&rsquo; 측의 공세는 계속</b>되고 있습니다. 특히 &ldquo;사귄 적 없다&rdquo;는 해명은 <b>&lsquo;그루밍&rsquo; 논란</b>으로 이어지며, 연예계 전반에 큰 파장을 주고 있습니다.</p>\n<p data-ke-size=\"size16\">한 프로파일러는 해당 상황에 대해 <b>&ldquo;상대를 잘못 골랐다&rdquo;</b>며 사안의 심각성을 지적했습니다. 이번 논란은 단순한 해명이 아닌, <b>도덕성과 윤리적 판단에 대한 대중의 평가</b>로 이어지고 있으며, 김수현의 이미지 회복은 <b>당분간 쉽지 않을 것</b>으로 보입니다.</p>\n<hr data-ke-style=\"style1\" />\n<blockquote data-ke-style=\"style1\">\n<p data-ke-size=\"size16\">⚠️ 본 포스팅은 대중에 공개된 기사 및 자료에 기반해 작성된 콘텐츠로, 사실 여부에 대한 판단은 독자에게 맡깁니다.</p>\n</blockquote>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "2025년 3월 31일, 배우 김수현이 긴급 기자회견을 열고 故 김새론과의 관계에 대한 입장을 밝혔습니다. 하지만 이 해명 이후에도 대중의 의문은 가라앉지 않고 있습니다. 그 중심에는 “고등학교 2학년, 17세였던 김새론이 밤 11시에 김수현 가족이 있는 집에서 닭볶음탕을 만들었다는 정황”이 있습니다.\n▶ “연인이 아니었다”는 주장…하지만 그 밤의 정황은?\n김수현 측은 공식 입장에서 “당시 연인 관계가 아니었고, 가족들도 함께 있었다”고 해명했습니다. 논란이 된 영상은 2018년 6월 촬영된 것으로, 당시 김새론은 고등학교 2학년, 만 17세의 미성년자였습니다.\n해당 영상은 밤 11시 20분경 촬영되었으며, 식탁 위에는 소주병과 소주잔이 놓여 있었다는 점이 확인되며 더욱 논란이 커지고 있습니다. 소속사는 단순한 가족 식사 자리였다고 주장하지만, 많은 이들은 이 상황 자체를 납득하기 어렵다는 반응입니다.\n▶ “사귀지도 않았는데, 밤 11시에 가족 집에서 요리?”\n온라인 커뮤니티와 SNS에서는 다양한 반응이 이어지고 있습니다:\n“사귀지 않았다면 오히려 더 이상한 상황”\n“그 시간에 미성년자가 남자 집에 있었다는 것 자체가 부적절하다”\n“친구 사이여도 집에 돌려보낼 시간 아닌가?”\n또한, 김새론이 김수현에게 보냈다는 카카오톡 메시지 내용도 공개되었습니다. 메시지에는 “보고 싶어”, “언제 안고 잘 수 있어?” 등 연인 사이로 보일 수 있는 문구가 담겨 있었지만, 김수현 측은 “전면 조작된 메시지”라며 원본 데이터 제출을 요구한 상태입니다.\n▶ 해명에도 남은 의문…김수현 이미지 타격 불가피\n김수현 소속사는 “미성년자와의 교제는 결단코 없었다”며 법적 대응을 시사하고 있지만, 유튜브 채널 ‘가세연’ 측의 공세는 계속되고 있습니다. 특히 “사귄 적 없다”는 해명은 ‘그루밍’ 논란으로 이어지며, 연예계 전반에 큰 파장을 주고 있습니다.\n한 프로파일러는 해당 상황에 대해 “상대를 잘못 골랐다”며 사안의 심각성을 지적했습니다. 이번 논란은 단순한 해명이 아닌, 도덕성과 윤리적 판단에 대한 대중의 평가로 이어지고 있으며, 김수현의 이미지 회복은 당분간 쉽지 않을 것으로 보입니다.\n⚠️ 본 포스팅은 대중에 공개된 기사 및 자료에 기반해 작성된 콘텐츠로, 사실 여부에 대한 판단은 독자에게 맡깁니다.",
        "guid": "http://app-developer.tistory.com/206",
        "isoDate": "2025-04-11T14:18:10.000Z"
      }
    ]
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": [
      {
        "title": "Composable Architecture는 만들었는데 문제가 있었네? 개선해보자.",
        "link": "https://thdev.tech/architecture/2025/04/15/Android-Architecture-02/",
        "pubDate": "Tue, 15 Apr 2025 00:00:00 +0000",
        "content": "<p>이전 글에서 Composable Architecutre를 소개하는 내용을 담아보았는데, 몇 가지 문제점을 발견하여 이를 개선한 내용을 다시 정리하는 글이다.</p>\n\n<p>크게 2가지 문제점을 확인하였다.</p>\n\n<ul>\n  <li>ViewModel 내 Reducer 처리 후 자동 next</li>\n  <li>Action 스트림 처리를 위한 싱글턴 활용 시 Lifecycle 문제</li>\n</ul>\n\n<p>이 2가지 문제점을 해결하기 위해 코드를 어떻게 수정했는지, 그리고 더 나은 방법은 없을지 고민한 과정을 정리해본다.</p>\n\n<h3>이 글에서는</h3>\n<ul>\n  <li>기존 아키텍처의 구조적 문제점을 파악한다.</li>\n  <li>문제 해결 과정과 더 나은 구조에 대한 고민을 공유한다.</li>\n  <li>기본적인 내용을 담지 않고있어 앞선 글을 참고하면 좋다.</li>\n</ul>\n\n<!--more-->\n\n<h2>Action이란?</h2>\n\n<p>View와 ViewModel 사이의 통신을 어떻게 더 간결하게 할 수 있을까? Jetpack Compose 환경에서는 <a href=\"https://developer.android.com/develop/ui/compose/compositionlocal\">CompositionLocal - link</a>을 활용하는 방법이 있다. 저는 이 방식을 응용하여 Composable 함수 어디서든 이벤트 처리를 쉽게 호출할 수 있도록 Action이라는 개념을 만들었다.</p>\n\n<p>Flow를 기반으로 한 Action을 사용한 이유를 설명하기 위해, 먼저 일반적인 View-ViewModel 간 통신 방식의 예시 코드를 살펴보자.</p>\n\n<p>Composable 함수에서 ViewModel 인스턴스를 파라미터로 직접 전달받아 사용하는 것이 일반적이다. 하지만 이 방식은 Composable 함수의 깊이가 깊어지거나 개수가 많아질수록 ViewModel을 어디까지 전달해야 할지 고민이 필요하며, 구조가 복잡해지면 자연스럽게 보일러플레이트 코드가 늘어나는 단점이 있다.</p>\n\n<h4>ViewModel을 직접 사용한 함수 호출</h4>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nd\">@Composable</span>\n<span class=\"k\">fun</span> <span class=\"nf\">SomeScreen</span><span class=\"p\">(</span><span class=\"n\">someViewModel</span><span class=\"p\">:</span> <span class=\"nc\">SomeViewModel</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"nc\">Button</span><span class=\"p\">(</span><span class=\"n\">onClick</span> <span class=\"p\">=</span> <span class=\"p\">{</span> <span class=\"n\">someViewModel</span><span class=\"p\">.</span><span class=\"nf\">doSomething</span><span class=\"p\">()</span> <span class=\"p\">})</span>\n  <span class=\"nc\">Button</span><span class=\"p\">(</span><span class=\"n\">onClick</span> <span class=\"p\">=</span> <span class=\"p\">{</span> <span class=\"n\">someViewModel</span><span class=\"p\">.</span><span class=\"nf\">doSomethingTwo</span><span class=\"p\">()</span> <span class=\"p\">})</span>\n  <span class=\"nc\">Button</span><span class=\"p\">(</span><span class=\"n\">onClick</span> <span class=\"p\">=</span> <span class=\"p\">{</span> <span class=\"n\">someViewModel</span><span class=\"p\">.</span><span class=\"nf\">doSomethingThree</span><span class=\"p\">()</span> <span class=\"p\">})</span>\n<span class=\"p\">}</span>\n\n<span class=\"kd\">class</span> <span class=\"nc\">SomeViewModel</span> <span class=\"p\">:</span> <span class=\"nc\">ViewModel</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n  <span class=\"k\">fun</span> <span class=\"nf\">doSomething</span><span class=\"p\">()</span> <span class=\"p\">{</span> <span class=\"cm\">/* ... */</span> <span class=\"p\">}</span>\n  <span class=\"k\">fun</span> <span class=\"nf\">doSomethingTwo</span><span class=\"p\">()</span> <span class=\"p\">{</span> <span class=\"cm\">/* ... */</span> <span class=\"p\">}</span>\n  <span class=\"k\">fun</span> <span class=\"nf\">doSomethingThree</span><span class=\"p\">()</span> <span class=\"p\">{</span> <span class=\"cm\">/* ... */</span> <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<h4>ViewModel 함수를 sealed interface로 통합하여 호출하는 경우</h4>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">sealed</span> <span class=\"kd\">interface</span> <span class=\"nc\">SomeAction</span> <span class=\"p\">{</span>\n    <span class=\"n\">data</span> <span class=\"kd\">object</span> <span class=\"nc\">ActionOne</span> <span class=\"p\">:</span> <span class=\"nc\">SomeAction</span>\n    <span class=\"n\">data</span> <span class=\"kd\">object</span> <span class=\"nc\">ActionTwo</span> <span class=\"p\">:</span> <span class=\"nc\">SomeAction</span>\n    <span class=\"kd\">data class</span> <span class=\"nc\">ActionThree</span><span class=\"p\">(</span><span class=\"kd\">val</span> <span class=\"py\">item</span><span class=\"p\">:</span> <span class=\"nc\">Any</span><span class=\"p\">)</span> <span class=\"p\">:</span> <span class=\"nc\">SomeAction</span>\n<span class=\"p\">}</span>\n\n<span class=\"nd\">@Composable</span>\n<span class=\"k\">fun</span> <span class=\"nf\">SomeScreen</span><span class=\"p\">(</span><span class=\"n\">someViewModel</span><span class=\"p\">:</span> <span class=\"nc\">SomeViewModel</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"kd\">val</span> <span class=\"py\">item</span> <span class=\"p\">=</span> <span class=\"nf\">remember</span> <span class=\"p\">{</span> <span class=\"cm\">/* ... */</span> <span class=\"p\">}</span> <span class=\"c1\">// 예시 데이터</span>\n  <span class=\"nc\">Button</span><span class=\"p\">(</span><span class=\"n\">onClick</span> <span class=\"p\">=</span> <span class=\"p\">{</span> <span class=\"n\">someViewModel</span><span class=\"p\">.</span><span class=\"nf\">dispatch</span><span class=\"p\">(</span><span class=\"nc\">SomeAction</span><span class=\"p\">.</span><span class=\"nc\">ActionOne</span><span class=\"p\">)</span> <span class=\"p\">})</span>\n  <span class=\"nc\">Button</span><span class=\"p\">(</span><span class=\"n\">onClick</span> <span class=\"p\">=</span> <span class=\"p\">{</span> <span class=\"n\">someViewModel</span><span class=\"p\">.</span><span class=\"nf\">dispatch</span><span class=\"p\">(</span><span class=\"nc\">SomeAction</span><span class=\"p\">.</span><span class=\"nc\">ActionTwo</span><span class=\"p\">)</span> <span class=\"p\">})</span>\n  <span class=\"nc\">Button</span><span class=\"p\">(</span><span class=\"n\">onClick</span> <span class=\"p\">=</span> <span class=\"p\">{</span> <span class=\"n\">someViewModel</span><span class=\"p\">.</span><span class=\"nf\">dispatch</span><span class=\"p\">(</span><span class=\"nc\">SomeAction</span><span class=\"p\">.</span><span class=\"nc\">ActionThree</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">))</span> <span class=\"p\">})</span>\n<span class=\"p\">}</span>\n\n<span class=\"kd\">class</span> <span class=\"nc\">SomeViewModel</span> <span class=\"p\">:</span> <span class=\"nc\">ViewModel</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n  <span class=\"k\">fun</span> <span class=\"nf\">dispatch</span><span class=\"p\">(</span><span class=\"n\">action</span><span class=\"p\">:</span> <span class=\"nc\">SomeAction</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">when</span> <span class=\"p\">(</span><span class=\"n\">action</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n      <span class=\"k\">is</span> <span class=\"nc\">SomeAction</span><span class=\"p\">.</span><span class=\"nc\">ActionOne</span> <span class=\"p\">-&gt;</span> <span class=\"p\">{</span> <span class=\"cm\">/* ... */</span> <span class=\"p\">}</span>\n      <span class=\"k\">is</span> <span class=\"nc\">SomeAction</span><span class=\"p\">.</span><span class=\"nc\">ActionTwo</span> <span class=\"p\">-&gt;</span> <span class=\"p\">{</span> <span class=\"cm\">/* ... */</span> <span class=\"p\">}</span>\n      <span class=\"k\">is</span> <span class=\"nc\">SomeAction</span><span class=\"p\">.</span><span class=\"nc\">ActionThree</span> <span class=\"p\">-&gt;</span> <span class=\"p\">{</span> <span class=\"cm\">/* ... */</span> <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<h4>제가 활용하는 방식 (CompositionLocal 활용)</h4>\n\n<p>위 방식들은 ViewModel을 계속 전달하거나, <code class=\"language-plaintext highlighter-rouge\">onClick: () -&gt; Unit</code> 같은 콜백을 계속 만들어 전달해야 하는 번거로움이 있다. 특히 콜백 방식은 이벤트 통합 과정에서 N개의 고차 함수(Higher-Order function)가 만들어질 수 있다.</p>\n\n<p>그래서 Compose에서 제공하는 <a href=\"https://developer.android.com/develop/ui/compose/compositionlocal\">Locally scoped - link</a>을 활용하여 Action 객체에 쉽게 접근하는 방법을 사용하고 있습니다. (자세한 활용법은 이전 글 <a href=\"https://thdev.tech/architecture/2025/02/02/Android-Architecture-01/\">컴포즈에 사용할 Composable Architecture 설명</a>을 참고해주세요.)</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// Action 정의 (예시)</span>\n<span class=\"k\">sealed</span> <span class=\"kd\">interface</span> <span class=\"nc\">MyScreenAction</span> <span class=\"p\">:</span> <span class=\"nc\">CaAction</span> <span class=\"p\">{</span> <span class=\"c1\">// CaAction은 마커 인터페이스 역할</span>\n    <span class=\"n\">data</span> <span class=\"kd\">object</span> <span class=\"nc\">ButtonClick</span> <span class=\"p\">:</span> <span class=\"nc\">MyScreenAction</span>\n    <span class=\"kd\">data class</span> <span class=\"nc\">TextTyped</span><span class=\"p\">(</span><span class=\"kd\">val</span> <span class=\"py\">text</span><span class=\"p\">:</span> <span class=\"nc\">String</span><span class=\"p\">)</span> <span class=\"p\">:</span> <span class=\"nc\">MyScreenAction</span>\n    <span class=\"kd\">data class</span> <span class=\"nc\">SwitchChanged</span><span class=\"p\">(</span><span class=\"kd\">val</span> <span class=\"py\">isOn</span><span class=\"p\">:</span> <span class=\"nc\">Boolean</span><span class=\"p\">)</span> <span class=\"p\">:</span> <span class=\"nc\">MyScreenAction</span>\n<span class=\"p\">}</span>\n\n<span class=\"c1\">// Composable View</span>\n<span class=\"nd\">@Composable</span>\n<span class=\"k\">fun</span> <span class=\"nf\">SomeScreen</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n  <span class=\"c1\">// CompositionLocal을 통해 ActionDispatcher 획득</span>\n  <span class=\"kd\">val</span> <span class=\"py\">actionDispatcher</span> <span class=\"p\">=</span> <span class=\"nc\">LocalActionDispatcher</span><span class=\"p\">.</span><span class=\"n\">current</span>\n  <span class=\"kd\">var</span> <span class=\"py\">textState</span> <span class=\"k\">by</span> <span class=\"nf\">remember</span> <span class=\"p\">{</span> <span class=\"nf\">mutableStateOf</span><span class=\"p\">(</span><span class=\"s\">\"\"</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n  <span class=\"kd\">var</span> <span class=\"py\">switchState</span> <span class=\"k\">by</span> <span class=\"nf\">remember</span> <span class=\"p\">{</span> <span class=\"nf\">mutableStateOf</span><span class=\"p\">(</span><span class=\"k\">false</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n\n  <span class=\"nc\">Column</span> <span class=\"p\">{</span>\n      <span class=\"nc\">Button</span><span class=\"p\">(</span><span class=\"n\">onClick</span> <span class=\"p\">=</span> <span class=\"p\">{</span> <span class=\"n\">actionDispatcher</span><span class=\"p\">.</span><span class=\"nf\">dispatch</span><span class=\"p\">(</span><span class=\"nc\">MyScreenAction</span><span class=\"p\">.</span><span class=\"nc\">ButtonClick</span><span class=\"p\">)</span> <span class=\"p\">})</span> <span class=\"p\">{</span>\n          <span class=\"nc\">Text</span><span class=\"p\">(</span><span class=\"s\">\"Click Me\"</span><span class=\"p\">)</span>\n      <span class=\"p\">}</span>\n      <span class=\"nc\">TextField</span><span class=\"p\">(</span>\n          <span class=\"n\">value</span> <span class=\"p\">=</span> <span class=\"n\">textState</span><span class=\"p\">,</span>\n          <span class=\"n\">onValueChange</span> <span class=\"p\">=</span> <span class=\"p\">{</span>\n              <span class=\"n\">textState</span> <span class=\"p\">=</span> <span class=\"n\">it</span>\n              <span class=\"n\">actionDispatcher</span><span class=\"p\">.</span><span class=\"nf\">dispatch</span><span class=\"p\">(</span><span class=\"nc\">MyScreenAction</span><span class=\"p\">.</span><span class=\"nc\">TextTyped</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">))</span>\n          <span class=\"p\">}</span>\n      <span class=\"p\">)</span>\n      <span class=\"nc\">Switch</span><span class=\"p\">(</span>\n          <span class=\"n\">checked</span> <span class=\"p\">=</span> <span class=\"n\">switchState</span><span class=\"p\">,</span>\n          <span class=\"n\">onCheckedChange</span> <span class=\"p\">=</span> <span class=\"p\">{</span>\n              <span class=\"n\">switchState</span> <span class=\"p\">=</span> <span class=\"n\">it</span>\n              <span class=\"n\">actionDispatcher</span><span class=\"p\">.</span><span class=\"nf\">dispatch</span><span class=\"p\">(</span><span class=\"nc\">MyScreenAction</span><span class=\"p\">.</span><span class=\"nc\">SwitchChanged</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">))</span>\n          <span class=\"p\">}</span>\n      <span class=\"p\">)</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"c1\">// ViewModel</span>\n<span class=\"kd\">class</span> <span class=\"nc\">SomeViewModel</span><span class=\"p\">(</span>\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">flowCaActionStream</span><span class=\"p\">:</span> <span class=\"nc\">FlowCaActionStream</span> <span class=\"c1\">// Action 스트림 주입</span>\n<span class=\"p\">)</span> <span class=\"p\">:</span> <span class=\"nc\">CaViewModel</span><span class=\"p\">&lt;</span><span class=\"nc\">MyScreenAction</span><span class=\"p\">&gt;(</span><span class=\"n\">flowCaActionStream</span><span class=\"p\">,</span> <span class=\"nc\">MyScreenAction</span><span class=\"o\">::</span><span class=\"k\">class</span><span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"c1\">// 수신할 Action 타입 지정</span>\n\n    <span class=\"c1\">// CaViewModel 내부에서 flowAction을 통해 MyScreenAction 타입의 이벤트만 필터링하여 수신</span>\n    <span class=\"c1\">// reducer 메소드에서 각 Action 처리 로직 구현</span>\n    <span class=\"k\">override</span> <span class=\"k\">suspend</span> <span class=\"k\">fun</span> <span class=\"nf\">reducer</span><span class=\"p\">(</span><span class=\"n\">action</span><span class=\"p\">:</span> <span class=\"nc\">MyScreenAction</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n        <span class=\"k\">when</span> <span class=\"p\">(</span><span class=\"n\">action</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n            <span class=\"k\">is</span> <span class=\"nc\">MyScreenAction</span><span class=\"p\">.</span><span class=\"nc\">ButtonClick</span> <span class=\"p\">-&gt;</span> <span class=\"p\">{</span>\n                <span class=\"c1\">// 버튼 클릭 처리 로직</span>\n                <span class=\"nc\">Log</span><span class=\"p\">.</span><span class=\"nf\">d</span><span class=\"p\">(</span><span class=\"s\">\"SomeViewModel\"</span><span class=\"p\">,</span> <span class=\"s\">\"Button Clicked\"</span><span class=\"p\">)</span>\n            <span class=\"p\">}</span>\n            <span class=\"k\">is</span> <span class=\"nc\">MyScreenAction</span><span class=\"p\">.</span><span class=\"nc\">TextTyped</span> <span class=\"p\">-&gt;</span> <span class=\"p\">{</span>\n                <span class=\"c1\">// 텍스트 입력 처리 로직</span>\n                <span class=\"nc\">Log</span><span class=\"p\">.</span><span class=\"nf\">d</span><span class=\"p\">(</span><span class=\"s\">\"SomeViewModel\"</span><span class=\"p\">,</span> <span class=\"s\">\"Text Typed: ${action.text}\"</span><span class=\"p\">)</span>\n            <span class=\"p\">}</span>\n            <span class=\"k\">is</span> <span class=\"nc\">MyScreenAction</span><span class=\"p\">.</span><span class=\"nc\">SwitchChanged</span> <span class=\"p\">-&gt;</span> <span class=\"p\">{</span>\n                <span class=\"c1\">// 스위치 변경 처리 로직</span>\n                <span class=\"nc\">Log</span><span class=\"p\">.</span><span class=\"nf\">d</span><span class=\"p\">(</span><span class=\"s\">\"SomeViewModel\"</span><span class=\"p\">,</span> <span class=\"s\">\"Switch Changed: ${action.isOn}\"</span><span class=\"p\">)</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p><br /></p>\n\n<h2>사용성 측면에서의 개선</h2>\n\n<p>필요한 Action을 <code class=\"language-plaintext highlighter-rouge\">LocalAction.current</code>를 통해 어디서든 호출할 수 있으므로, ViewModel 인스턴스를 계속해서 하위 Composable로 전달할 필요가 없어 개발 편의성이 향상될 수 있다.</p>\n\n<p>CompositionLocal에 적절한 기본값이나 테스트용 구현체를 제공하면 Preview 동작에도 문제가 없다. 다만, Preview에서 특정 UI 요소의 상태 변화나 인터랙션을 테스트하려면, 선언형 UI의 원칙에 따라 <a href=\"https://developer.android.com/develop/ui/compose/state\">Stateless - link</a>한 Composable을 만들고 상태와 이벤트를 외부에서 주입하는 것이 좋다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// Stateless Composable 예시</span>\n<span class=\"nd\">@Composable</span>\n<span class=\"k\">fun</span> <span class=\"nf\">SomeContent</span><span class=\"p\">(</span>\n    <span class=\"n\">text</span><span class=\"p\">:</span> <span class=\"nc\">String</span><span class=\"p\">,</span>\n    <span class=\"n\">isSwitchOn</span><span class=\"p\">:</span> <span class=\"nc\">Boolean</span><span class=\"p\">,</span>\n    <span class=\"n\">onButtonClick</span><span class=\"p\">:</span> <span class=\"p\">()</span> <span class=\"p\">-&gt;</span> <span class=\"nc\">Unit</span><span class=\"p\">,</span>\n    <span class=\"n\">onTextTyped</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"nc\">String</span><span class=\"p\">)</span> <span class=\"p\">-&gt;</span> <span class=\"nc\">Unit</span><span class=\"p\">,</span>\n    <span class=\"n\">onSwitchChange</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"nc\">Boolean</span><span class=\"p\">)</span> <span class=\"p\">-&gt;</span> <span class=\"nc\">Unit</span><span class=\"p\">,</span>\n    <span class=\"n\">modifier</span><span class=\"p\">:</span> <span class=\"nc\">Modifier</span> <span class=\"p\">=</span> <span class=\"nc\">Modifier</span> <span class=\"c1\">// Modifier 추가 권장</span>\n<span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"nc\">Column</span><span class=\"p\">(</span><span class=\"n\">modifier</span> <span class=\"p\">=</span> <span class=\"n\">modifier</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n        <span class=\"nc\">Button</span><span class=\"p\">(</span><span class=\"n\">onClick</span> <span class=\"p\">=</span> <span class=\"n\">onButtonClick</span><span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"cm\">/* ... */</span> <span class=\"p\">}</span>\n        <span class=\"nc\">TextField</span><span class=\"p\">(</span><span class=\"n\">value</span> <span class=\"p\">=</span> <span class=\"n\">text</span><span class=\"p\">,</span> <span class=\"n\">onValueChange</span> <span class=\"p\">=</span> <span class=\"n\">onTextTyped</span><span class=\"p\">)</span>\n        <span class=\"nc\">Switch</span><span class=\"p\">(</span><span class=\"n\">checked</span> <span class=\"p\">=</span> <span class=\"n\">isSwitchOn</span><span class=\"p\">,</span> <span class=\"n\">onCheckedChange</span> <span class=\"p\">=</span> <span class=\"n\">onSwitchChange</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"c1\">// Statefull Composable (ViewModel과 연결)</span>\n<span class=\"nd\">@Composable</span>\n<span class=\"k\">fun</span> <span class=\"nf\">SomeScreen</span><span class=\"p\">(</span><span class=\"n\">viewModel</span><span class=\"p\">:</span> <span class=\"nc\">SomeViewModel</span> <span class=\"p\">=</span> <span class=\"nf\">hiltViewModel</span><span class=\"p\">())</span> <span class=\"p\">{</span> <span class=\"c1\">// Hilt 등 DI 활용 예시</span>\n    <span class=\"kd\">val</span> <span class=\"py\">actionDispatcher</span> <span class=\"p\">=</span> <span class=\"nc\">LocalActionDispatcher</span><span class=\"p\">.</span><span class=\"n\">current</span> <span class=\"c1\">// Action 발송기</span>\n    <span class=\"c1\">// ViewModel로부터 상태를 구독하거나, 필요한 상태를 여기서 관리</span>\n    <span class=\"kd\">val</span> <span class=\"py\">textState</span> <span class=\"k\">by</span> <span class=\"n\">viewModel</span><span class=\"p\">.</span><span class=\"n\">textState</span><span class=\"p\">.</span><span class=\"nf\">collectAsState</span><span class=\"p\">()</span> <span class=\"c1\">// 예시 StateFlow</span>\n    <span class=\"kd\">val</span> <span class=\"py\">switchState</span> <span class=\"k\">by</span> <span class=\"n\">viewModel</span><span class=\"p\">.</span><span class=\"n\">switchState</span><span class=\"p\">.</span><span class=\"nf\">collectAsState</span><span class=\"p\">()</span> <span class=\"c1\">// 예시 StateFlow</span>\n\n    <span class=\"nc\">SomeContent</span><span class=\"p\">(</span>\n        <span class=\"n\">text</span> <span class=\"p\">=</span> <span class=\"n\">textState</span><span class=\"p\">,</span>\n        <span class=\"n\">isSwitchOn</span> <span class=\"p\">=</span> <span class=\"n\">switchState</span><span class=\"p\">,</span>\n        <span class=\"n\">onButtonClick</span> <span class=\"p\">=</span> <span class=\"p\">{</span> <span class=\"n\">actionDispatcher</span><span class=\"p\">.</span><span class=\"nf\">dispatch</span><span class=\"p\">(</span><span class=\"nc\">MyScreenAction</span><span class=\"p\">.</span><span class=\"nc\">ButtonClick</span><span class=\"p\">)</span> <span class=\"p\">},</span>\n        <span class=\"n\">onTextTyped</span> <span class=\"p\">=</span> <span class=\"p\">{</span> <span class=\"n\">actionDispatcher</span><span class=\"p\">.</span><span class=\"nf\">dispatch</span><span class=\"p\">(</span><span class=\"nc\">MyScreenAction</span><span class=\"p\">.</span><span class=\"nc\">TextTyped</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">))</span> <span class=\"p\">},</span>\n        <span class=\"n\">onSwitchChange</span> <span class=\"p\">=</span> <span class=\"p\">{</span> <span class=\"n\">actionDispatcher</span><span class=\"p\">.</span><span class=\"nf\">dispatch</span><span class=\"p\">(</span><span class=\"nc\">MyScreenAction</span><span class=\"p\">.</span><span class=\"nc\">SwitchChanged</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">))</span> <span class=\"p\">}</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>이 방식(Stateless/Statefull 분리 및 CompositionLocal 활용)의 단점은 다음과 같다.</p>\n\n<ul>\n  <li>ViewModel에서 모든 UI 인터랙션을 하나의 reducer 함수로 통합 관리하기보다, 각 상태 업데이트 로직과 이벤트 발송 로직이 분리될 수 있다. (이는 관점에 따라 장점일 수도 있다)</li>\n  <li>새로운 Action 이벤트를 추가할 때, ViewModel의 reducer에서도 해당 이벤트를 처리하는 로직을 추가해야 한다. (이는 sealed interface 사용 시 컴파일 타임에 강제될 수 있어 오히려 장점이 될 수 있다.)</li>\n</ul>\n\n<p>하지만 장점은 다음과 같습니다.</p>\n<ul>\n  <li>각 UI 요소의 이벤트 발송 책임이 명확해진다.</li>\n  <li>Stateless Composable은 재사용 및 테스트가 용이하다.</li>\n  <li>CompositionLocal을 통해 이벤트 발송 인터페이스 접근이 간편하다.</li>\n</ul>\n\n<p><br /></p>\n\n<h3>정리하면</h3>\n\n<h4>해결하고 싶었던 지점</h4>\n\n<ul>\n  <li>View와 ViewModel 간의 이벤트 전달을 왜 항상 ViewModel 인스턴스를 통해 viewModel.someFunction() 형태로 직접 호출해야 할까?</li>\n  <li>Composable 함수의 깊이가 깊어질 때 ViewModel 인스턴스나 콜백 함수를 계속 전달해야 하는 번거로움을 줄일 수 없을까?</li>\n</ul>\n\n<h4>그래서 도입한 Action(CompositionLocal)</h4>\n\n<p>이벤트 처리를 위한 Action 인터페이스와 이를 쉽게 발송(dispatch)할 수 있는 ActionDispatcher를 CompositionLocal로 제공하여, Composable 함수 내에서 발생하는 보일러플레이트를 줄이고자 했다.</p>\n\n<p>하지만 여전히 해결해야 할 문제가 있는데</p>\n\n<ul>\n  <li>이벤트를 보내는 쪽(View)과 받는 쪽(ViewModel)에서 정확히 어떤 Action 타입을 사용하고 처리할지 명확히 약속이 필요하다. 만약 서로 다른 타입을 사용하거나 누락하면 이벤트가 유실되어 동작하지 않는 치명적인 문제가 발생할 수 있다.</li>\n</ul>\n\n<p>이 문제를 해결하고 개발 과정에서 실수를 줄이기 위해 <code class=\"language-plaintext highlighter-rouge\">sealed interface</code>를 사용하여 <code class=\"language-plaintext highlighter-rouge\">Action</code>을 정의하는 방식을 채택했다. sealed interface를 사용하면 ViewModel의 reducer에서 when 식으로 처리할 때 모든 하위 타입을 강제로 구현해야 하므로, 이벤트 누락 가능성을 컴파일 시점에 방지할 수 있다. 이는 UI 동작 관련 테스트 케이스를 일부 줄여줄 수 있는 장점도 있다.</p>\n\n<p><br /></p>\n\n<h2>그래서 발견한 문제</h2>\n\n<p><a href=\"https://github.com/pointfreeco/swift-composable-architecture\">Swift-composable architecture - 링크</a>를 참고하여 아키텍처를 구상하다 보니, Reducer가 특정 액션을 처리한 후 다음 액션을 연쇄적으로 발생시키는 구조를 발견했다.</p>\n\n<p>Swift Composable Architecture의 코드 예시를 보면, Reduce 클로저 내에서 <code class=\"language-plaintext highlighter-rouge\">.send</code>나 다른 이펙트(Effect)를 반환하여 다음 동작을 유발할 수 있다. (아래 코드는 TCA의 이전 버전 구문일 수 있으며, 현재는 @Reducer 매크로 등을 사용한다.)</p>\n\n<div class=\"language-swift highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// TCA 예시 (개념 설명용)</span>\n<span class=\"kt\">Reduce</span> <span class=\"p\">{</span> <span class=\"n\">state</span><span class=\"p\">,</span> <span class=\"n\">action</span> <span class=\"k\">in</span>\n  <span class=\"k\">switch</span> <span class=\"n\">action</span> <span class=\"p\">{</span>\n  <span class=\"k\">case</span> <span class=\"o\">.</span><span class=\"nv\">buttonTapped</span><span class=\"p\">:</span>\n    <span class=\"n\">state</span><span class=\"o\">.</span><span class=\"n\">isLoading</span> <span class=\"o\">=</span> <span class=\"kc\">true</span>\n    <span class=\"c1\">// 이펙트를 반환하여 비동기 작업 후 다른 액션(.dataLoaded)을 발생시킴</span>\n    <span class=\"k\">return</span> <span class=\"o\">.</span><span class=\"n\">run</span> <span class=\"p\">{</span> <span class=\"n\">send</span> <span class=\"k\">in</span>\n      <span class=\"k\">let</span> <span class=\"nv\">data</span> <span class=\"o\">=</span> <span class=\"k\">try</span> <span class=\"k\">await</span> <span class=\"n\">apiClient</span><span class=\"o\">.</span><span class=\"nf\">fetchData</span><span class=\"p\">()</span>\n      <span class=\"k\">await</span> <span class=\"nf\">send</span><span class=\"p\">(</span><span class=\"o\">.</span><span class=\"nf\">dataLoaded</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">))</span>\n    <span class=\"p\">}</span>\n  <span class=\"k\">case</span> <span class=\"kd\">let</span> <span class=\"o\">.</span><span class=\"nf\">dataLoaded</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">):</span>\n    <span class=\"n\">state</span><span class=\"o\">.</span><span class=\"n\">isLoading</span> <span class=\"o\">=</span> <span class=\"kc\">false</span>\n    <span class=\"n\">state</span><span class=\"o\">.</span><span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">data</span>\n    <span class=\"k\">return</span> <span class=\"o\">.</span><span class=\"k\">none</span> <span class=\"c1\">// 추가 액션 없음</span>\n  <span class=\"c1\">// ...</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>이러한 ‘액션 후 연쇄 액션’ 개념을 안드로이드에서 Flow와 제가 만든 Action 시스템으로 구현해보고자 했다. 하지만 여기서 두 가지 주요 문제가 발생했다.</p>\n\n<ol>\n  <li>자동 nextAction 호출로 인한 문제:\n    <ul>\n      <li>ViewModel의 reducer 함수가 반환하는 값을 기반으로 시스템이 자동으로 다음 액션(nextAction)을 발생시키도록 설계했더니, 개발자가 이 동작 방식을 정확히 이해하고 사용해야 하는 부담이 늘었다. 알아야 할 규칙이 많아진 것.</li>\n      <li>결정적으로, nextAction을 잘못 지정하거나 reducer 로직에 실수가 있으면 무한 루프에 빠질 위험이 있었다. 디버깅이 불가능한 것은 아니지만, 코드 설계상 예측 가능한 문제가 쉽게 발생할 수 있는 구조였다.</li>\n    </ul>\n  </li>\n  <li>싱글턴 Action 스트림과 Lifecycle 동기화 문제:\n    <ul>\n      <li>앱 전체에서 단 하나의 Action 스트림(FlowCaActionStream)을 싱글턴으로 사용하다 보니, 새로운 Activity가 실행되거나 Composable Navigation 라이브러리(like Navigation-Compose)를 통해 화면이 전환될 때 문제가 발생했다.</li>\n      <li>예를 들어, Activity A와 Activity B가 있고 각각 여러 Composable 화면(Screen)을 가지고 있다고 가정해 보자. 사용자가 Activity B에 있더라도, 백그라운드의 Activity A에 속한 ViewModel들이 여전히 싱글턴 Action 스트림을 구독하고 있을 수 있다. 만약 특정 Action이 Activity B에서 발생했는데, Activity A의 ViewModel도 해당 Action 타입에 대해 필터링 로직(filterIsInstance)을 가지고 있다면, 의도치 않게 Activity A의 ViewModel에서도 해당 Action이 처리될 수 있다. (물론 reducer 로직 내에서 현재 화면 상태 등을 체크하여 방어할 수는 있겠지만, 근본적으로 불필요한 구독 및 처리 시도가 발생한다.)</li>\n      <li>이는 특히 Alert, Toast, Router(화면 전환)와 같이 앱 전역적으로 영향을 줄 수 있는 Side Effect 처리 시 동기화 문제를 일으킬 수 있다. ViewModel의 생명주기(viewModelScope)는 일반적으로 Composable의 생명주기보다 길기 때문에 이 문제가 더 두드러진다.</li>\n    </ul>\n  </li>\n</ol>\n\n<p>이 두 가지 문제를 어떻게 해결했는지 구체적으로 설명하겠다.</p>\n\n<p><br /></p>\n\n<h2>문제점 1 - 무한 루프 가능성 해결하기</h2>\n\n<p>무한 루프 발생 가능성을 제거하기 위해 기존 CaViewModel의 flowAction 처리 방식에서 문제의 소지가 있는 부분을 수정했다.</p>\n\n<p>기존 코드 (문제 발생 가능성 있음):</p>\n\n<pre><code class=\"language-kotiln\">abstract class CaViewModel&lt;ACTION : CaAction, SIDE_EFFECT : CaSideEffect&gt;(\n    private val flowCaActionStream: FlowCaActionStream, // 'private' 추가 (캡슐화)\n    actionClass: KClass&lt;ACTION&gt;,\n) : ViewModel() {\n\n    @VisibleForTesting\n    val flowAction by lazy(LazyThreadSafetyMode.NONE) {\n        flowCaActionStream.flowAction()\n            .filterIsInstance(actionClass) // 1. 해당 ViewModel이 처리할 Action만 필터링\n            .map { action -&gt; // 2. reducer를 호출하고, 그 결과를 반환 (문제의 소지)\n                reducer(action = action) // reducer가 다음 Action을 반환한다고 가정\n            }\n            .onEach { nextActionToDispatch -&gt; // 3. map에서 반환된 다음 Action을 자동으로 전파 (문제!)\n                flowCaActionStream.nextAction(nextActionToDispatch) // 무한 루프 가능 지점\n            }\n            // .launchIn(viewModelScope) // 실제로는 여기서 launch 되어야 함\n    }\n\n    // reducer 함수가 다음 Action을 반환하는 형태였다고 가정\n    abstract suspend fun reducer(action: ACTION): CaAction? // 예시: 반환 타입이 다음 Action\n}\n</code></pre>\n\n<p>수정된 코드:</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">abstract</span> <span class=\"kd\">class</span> <span class=\"nc\">CaViewModel</span><span class=\"p\">&lt;</span><span class=\"nc\">CA_ACTION</span> <span class=\"p\">:</span> <span class=\"nc\">CaAction</span><span class=\"p\">&gt;(</span>\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">flowCaActionStream</span><span class=\"p\">:</span> <span class=\"nc\">FlowCaActionStream</span><span class=\"p\">,</span>\n    <span class=\"n\">actionClass</span><span class=\"p\">:</span> <span class=\"nc\">KClass</span><span class=\"p\">&lt;</span><span class=\"nc\">CA_ACTION</span><span class=\"p\">&gt;,</span>\n<span class=\"p\">)</span> <span class=\"p\">:</span> <span class=\"nc\">ViewModel</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n\n    <span class=\"c1\">// Action 처리를 위한 Flow (자동 nextAction 로직 제거)</span>\n    <span class=\"nd\">@VisibleForTesting</span>\n    <span class=\"k\">internal</span> <span class=\"kd\">val</span> <span class=\"py\">actionProcessingFlow</span> <span class=\"k\">by</span> <span class=\"nf\">lazy</span><span class=\"p\">(</span><span class=\"nc\">LazyThreadSafetyMode</span><span class=\"p\">.</span><span class=\"nc\">NONE</span><span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"c1\">// 'internal'로 변경하고 이름 명확화</span>\n        <span class=\"n\">flowCaActionStream</span><span class=\"p\">.</span><span class=\"nf\">flowAction</span><span class=\"p\">()</span>\n            <span class=\"p\">.</span><span class=\"nf\">filterIsInstance</span><span class=\"p\">(</span><span class=\"n\">actionClass</span><span class=\"p\">)</span> <span class=\"c1\">// 1. 처리할 Action 필터링</span>\n            <span class=\"p\">.</span><span class=\"nf\">onEach</span> <span class=\"p\">{</span> <span class=\"n\">action</span> <span class=\"p\">-&gt;</span> <span class=\"c1\">// 2. map 대신 onEach 사용. 각 Action에 대해 reducer만 실행 (반환값 사용 안 함)</span>\n                <span class=\"nf\">reducer</span><span class=\"p\">(</span><span class=\"n\">action</span> <span class=\"p\">=</span> <span class=\"n\">action</span><span class=\"p\">)</span>\n            <span class=\"p\">}</span>\n            <span class=\"c1\">// 3. 자동 nextAction 전파 로직 제거됨</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"c1\">// reducer 함수는 이제 Side Effect 처리나 상태 변경에만 집중 (반환값 없음)</span>\n    <span class=\"k\">abstract</span> <span class=\"k\">suspend</span> <span class=\"k\">fun</span> <span class=\"nf\">reducer</span><span class=\"p\">(</span><span class=\"n\">action</span><span class=\"p\">:</span> <span class=\"nc\">CA_ACTION</span><span class=\"p\">)</span>\n\n    <span class=\"c1\">// 다음 Action을 명시적으로 전파하고 싶을 때 호출하는 함수 추가</span>\n    <span class=\"k\">protected</span> <span class=\"k\">fun</span> <span class=\"nf\">nextAction</span><span class=\"p\">(</span><span class=\"n\">action</span><span class=\"p\">:</span> <span class=\"nc\">CaAction</span><span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"c1\">// 'protected'로 변경하여 자식 클래스에서만 사용하도록 제한</span>\n        <span class=\"n\">flowCaActionStream</span><span class=\"p\">.</span><span class=\"nf\">nextAction</span><span class=\"p\">(</span><span class=\"n\">action</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"c1\">// 실제 Flow 구독 시작/취소는 별도 관리 (아래 Lifecycle 해결 부분 참조)</span>\n    <span class=\"nd\">@VisibleForTesting</span>\n    <span class=\"kd\">var</span> <span class=\"py\">actionProcessingJob</span><span class=\"p\">:</span> <span class=\"nc\">Job</span><span class=\"p\">?</span> <span class=\"p\">=</span> <span class=\"k\">null</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>수정 내용 요약:</p>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">map</code> -&gt; <code class=\"language-plaintext highlighter-rouge\">onEach</code> 변경: <code class=\"language-plaintext highlighter-rouge\">reducer</code> 함수가 다음 Action을 반환하고 이를 <code class=\"language-plaintext highlighter-rouge\">map</code> 연산자가 받아 downstream로 흘려보내는 구조를 제거했다. 대신 onEach를 사용하여 각 Action에 대해 reducer 함수를 실행만 하도록 변경다. 이로써 reducer의 반환값과 관계없이 자동 nextAction 호출 가능성이 사라졌다.</li>\n  <li>명시적 <code class=\"language-plaintext highlighter-rouge\">nextAction</code> 함수 추가: 연쇄적인 Action 전파가 필요한 경우, 개발자가 <code class=\"language-plaintext highlighter-rouge\">reducer</code> 함수 내에서 직접 <code class=\"language-plaintext highlighter-rouge\">nextAction(action)</code> 함수를 호출하도록 변경했다. 이는 시스템에 의한 암묵적인 동작 대신, 개발자의 명확한 의도에 따라 다음 Action이 발생하도록 하여 코드의 예측 가능성을 높인다.</li>\n</ul>\n\n<p>이제 reducer 내에서 다음과 같이 명시적으로 다음 Action을 지정해야 한다.</p>\n\n<pre><code class=\"language-koltin\">override suspend fun reducer(action: MyScreenAction) {\n    when (action) {\n        is MyScreenAction.ButtonClick -&gt; {\n            // 예시: 버튼 클릭 후 특정 조건 만족 시 Alert 표시 Action 전파\n            if (shouldShowAlert()) {\n                nextAction(CommonUiAction.ShowAlert(\"버튼 클릭됨!\")) // 명시적으로 nextAction 호출\n            }\n        }\n        // ... 다른 Action 처리\n    }\n}\n</code></pre>\n\n<p>이 변경으로 시스템적인 무한 루프 발생 가능성은 제거되었고, 코드의 흐름이 더 명확해졌다.</p>\n\n<p><br /></p>\n\n<h2>문제점 2 - Lifecycle 문제 해결하기</h2>\n\n<p>싱글턴 Action 스트림(FlowCaActionStream) 사용 시 발생하는 Lifecycle 동기화 문제를 해결하기 위해, Composable의 Lifecycle에 맞춰 ViewModel의 Action 스트림 구독을 시작하고 중지하는 방식을 도입했다.</p>\n\n<p>문제 상황: Activity A와 B가 있을 때, Activity B가 화면에 보이는 동안에도 백그라운드의 Activity A에 있는 ViewModel이 Action 스트림을 계속 구독하고 있으면, Activity B에서 발생한 Action이 Activity A의 ViewModel에게도 전달될 수 있다. (물론 filterIsInstance로 타입 필터링은 되지만, 같은 타입의 Action을 여러 화면에서 사용한다면 문제가 된다.)</p>\n\n<p><img src=\"/images/posts/2025/Android-Architecture-02/sample_01.jpg\" alt=\"sample_01\" /></p>\n\n<p><br /></p>\n\n<h3>해결 방안: Lifecycle에 따른 구독 제어</h3>\n\n<p>Composable의 Lifecycle 상태(특히 <code class=\"language-plaintext highlighter-rouge\">ON_RESUME</code>, <code class=\"language-plaintext highlighter-rouge\">ON_PAUSE</code>)에 맞춰 ViewModel 내 Action 스트림(<code class=\"language-plaintext highlighter-rouge\">actionProcessingFlow</code>)의 구독(Job)을 시작하고 취소하는 방법을 사용합니다. 이를 위해 <code class=\"language-plaintext highlighter-rouge\">DisposableEffect</code>와 <code class=\"language-plaintext highlighter-rouge\">LocalLifecycleOwner</code>를 활용하는 Helper Composable 함수를 만들었습니다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nd\">@Composable</span>\n<span class=\"k\">fun</span> <span class=\"nf\">LaunchedLifecycleViewModel</span><span class=\"p\">(</span>\n    <span class=\"n\">viewModel</span><span class=\"p\">:</span> <span class=\"nc\">CaViewModel</span><span class=\"p\">&lt;</span><span class=\"err\">*</span><span class=\"p\">&gt;</span> <span class=\"c1\">// 라이프사이클 관리가 필요한 ViewModel</span>\n<span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">lifecycleOwner</span> <span class=\"p\">=</span> <span class=\"nc\">LocalLifecycleOwner</span><span class=\"p\">.</span><span class=\"n\">current</span>\n    <span class=\"nc\">DisposableEffect</span><span class=\"p\">(</span><span class=\"n\">lifecycleOwner</span><span class=\"p\">,</span> <span class=\"n\">viewModel</span><span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"c1\">// lifecycleOwner와 viewModel이 키</span>\n        <span class=\"kd\">val</span> <span class=\"py\">observer</span> <span class=\"p\">=</span> <span class=\"nc\">LifecycleEventObserver</span> <span class=\"p\">{</span> <span class=\"n\">_</span><span class=\"p\">,</span> <span class=\"n\">event</span> <span class=\"p\">-&gt;</span>\n            <span class=\"k\">when</span> <span class=\"p\">(</span><span class=\"n\">event</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n                <span class=\"nc\">Lifecycle</span><span class=\"p\">.</span><span class=\"nc\">Event</span><span class=\"p\">.</span><span class=\"nc\">ON_RESUME</span> <span class=\"p\">-&gt;</span> <span class=\"p\">{</span>\n                    <span class=\"c1\">// 화면이 활성화되면 Action 스트림 구독 시작</span>\n                    <span class=\"n\">viewModel</span><span class=\"p\">.</span><span class=\"nf\">startActionProcessing</span><span class=\"p\">()</span>\n                <span class=\"p\">}</span>\n                <span class=\"nc\">Lifecycle</span><span class=\"p\">.</span><span class=\"nc\">Event</span><span class=\"p\">.</span><span class=\"nc\">ON_PAUSE</span> <span class=\"p\">-&gt;</span> <span class=\"p\">{</span>\n                    <span class=\"c1\">// 화면이 비활성화되면 Action 스트림 구독 취소</span>\n                    <span class=\"n\">viewModel</span><span class=\"p\">.</span><span class=\"nf\">cancelActionProcessing</span><span class=\"p\">()</span>\n                <span class=\"p\">}</span>\n                <span class=\"c1\">// ON_DESTROY는 DisposableEffect의 onDispose에서 처리되거나</span>\n                <span class=\"c1\">// ViewModel의 onCleared에서 처리될 수 있음</span>\n                <span class=\"k\">else</span> <span class=\"p\">-&gt;</span> <span class=\"p\">{</span> <span class=\"cm\">/* Do nothing for other events */</span> <span class=\"p\">}</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n        <span class=\"n\">lifecycleOwner</span><span class=\"p\">.</span><span class=\"n\">lifecycle</span><span class=\"p\">.</span><span class=\"nf\">addObserver</span><span class=\"p\">(</span><span class=\"n\">observer</span><span class=\"p\">)</span>\n\n        <span class=\"c1\">// Composable이 Composition에서 제거될 때(onDispose) Observer 제거</span>\n        <span class=\"nf\">onDispose</span> <span class=\"p\">{</span>\n            <span class=\"n\">lifecycleOwner</span><span class=\"p\">.</span><span class=\"n\">lifecycle</span><span class=\"p\">.</span><span class=\"nf\">removeObserver</span><span class=\"p\">(</span><span class=\"n\">observer</span><span class=\"p\">)</span>\n            <span class=\"c1\">// 필요하다면 여기서도 cancelActionProcessing() 호출 고려</span>\n            <span class=\"c1\">// viewModel.cancelActionProcessing()</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>그리고 <code class=\"language-plaintext highlighter-rouge\">CaViewModel</code>에 <code class=\"language-plaintext highlighter-rouge\">Action</code> 스트림 구독을 시작하고 취소하는 함수를 추가한다. (<code class=\"language-plaintext highlighter-rouge\">internal</code> 접근 제한자를 사용하여 모듈 외부에서의 직접 호출을 방지한다.)</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">abstract</span> <span class=\"kd\">class</span> <span class=\"nc\">CaViewModel</span><span class=\"p\">&lt;</span><span class=\"nc\">CA_ACTION</span> <span class=\"p\">:</span> <span class=\"nc\">CaAction</span><span class=\"p\">&gt;(</span>\n    <span class=\"c1\">// ... (이전 코드와 동일)</span>\n<span class=\"p\">)</span> <span class=\"p\">:</span> <span class=\"nc\">ViewModel</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n\n    <span class=\"c1\">// ... (actionProcessingFlow, reducer, nextAction 등) ...</span>\n\n    <span class=\"nd\">@VisibleForTesting</span>\n    <span class=\"kd\">var</span> <span class=\"py\">actionProcessingJob</span><span class=\"p\">:</span> <span class=\"nc\">Job</span><span class=\"p\">?</span> <span class=\"p\">=</span> <span class=\"k\">null</span> <span class=\"c1\">// 구독 상태를 관리하는 Job</span>\n\n    <span class=\"c1\">// Action 스트림 구독 시작 (ON_RESUME 시 호출됨)</span>\n    <span class=\"k\">internal</span> <span class=\"k\">fun</span> <span class=\"nf\">startActionProcessing</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// 이미 실행 중이라면 중복 실행 방지</span>\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">actionProcessingJob</span><span class=\"o\">?.</span><span class=\"n\">isActive</span> <span class=\"p\">==</span> <span class=\"k\">true</span><span class=\"p\">)</span> <span class=\"k\">return</span>\n\n        <span class=\"c1\">// 기존 Job이 있다면 취소 (혹시 모를 상황 대비)</span>\n        <span class=\"nf\">cancelActionProcessing</span><span class=\"p\">()</span>\n\n        <span class=\"c1\">// actionProcessingFlow를 viewModelScope에서 구독 시작</span>\n        <span class=\"n\">actionProcessingJob</span> <span class=\"p\">=</span> <span class=\"n\">actionProcessingFlow</span>\n            <span class=\"p\">.</span><span class=\"nf\">launchIn</span><span class=\"p\">(</span><span class=\"n\">viewModelScope</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"c1\">// Action 스트림 구독 취소 (ON_PAUSE 시 호출됨)</span>\n    <span class=\"k\">internal</span> <span class=\"k\">fun</span> <span class=\"nf\">cancelActionProcessing</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n        <span class=\"n\">actionProcessingJob</span><span class=\"o\">?.</span><span class=\"nf\">cancel</span><span class=\"p\">()</span>\n        <span class=\"n\">actionProcessingJob</span> <span class=\"p\">=</span> <span class=\"k\">null</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"c1\">// ViewModel이 파괴될 때(onCleared) 확실하게 Job 취소</span>\n    <span class=\"k\">override</span> <span class=\"k\">fun</span> <span class=\"nf\">onCleared</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n        <span class=\"k\">super</span><span class=\"p\">.</span><span class=\"nf\">onCleared</span><span class=\"p\">()</span>\n        <span class=\"nf\">cancelActionProcessing</span><span class=\"p\">()</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<h3>위 코드를 활용하는 방법은?</h3>\n\n<p>각 화면의 최상위 Composable에서 ObserveLifecycle 함수를 호출해주어야 한다.</p>\n\n<pre><code class=\"language-koltin\">@Composable\nfun SomeScreen(viewModel: SomeViewModel = hiltViewModel()) {\n    // ViewModel의 Action 구독 라이프사이클 관리\n    LaunchedLifecycleViewModel(viewModel = viewModel)\n\n    // --- 실제 UI ---\n    // val state by viewModel.uiState.collectAsState()\n    // SomeContent(...)\n    // ---\n}\n</code></pre>\n\n<p>개선 아이디어: 매번 ObserveLifecycle(viewModel)를 호출하는 것이 번거롭다면, ViewModel 인스턴스를 얻을 때 자동으로 이 로직을 포함시키는 확장 함수나 위임(delegate)을 고려해볼 수 있다. 예를 들어:</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nd\">@Composable</span>\n<span class=\"k\">fun</span> <span class=\"nf\">Some</span><span class=\"p\">(</span><span class=\"n\">viewModel</span><span class=\"p\">:</span> <span class=\"nc\">ViewModel</span> <span class=\"p\">=</span> <span class=\"nf\">hiltViewModel</span><span class=\"p\">().</span><span class=\"nc\">Activate</span><span class=\"p\">())</span> <span class=\"p\">{</span>\n  <span class=\"c1\">// Your view</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>또는 hilt를 직접 확장한다면 아래와 같다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// 개념적인 아이디어 (구현 필요)</span>\n<span class=\"nd\">@Composable</span>\n<span class=\"k\">inline</span> <span class=\"k\">fun</span> <span class=\"p\">&lt;</span><span class=\"k\">reified</span> <span class=\"nc\">VM</span> <span class=\"p\">:</span> <span class=\"nc\">CaViewModel</span><span class=\"p\">&lt;</span><span class=\"err\">*</span><span class=\"p\">&gt;&gt;</span> <span class=\"nf\">hiltViewModelWithLifecycle</span><span class=\"p\">():</span> <span class=\"nc\">VM</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">viewModel</span><span class=\"p\">:</span> <span class=\"nc\">VM</span> <span class=\"p\">=</span> <span class=\"nf\">hiltViewModel</span><span class=\"p\">()</span>\n    <span class=\"nc\">LaunchedLifecycleViewModel</span><span class=\"p\">(</span><span class=\"n\">viewModel</span> <span class=\"p\">=</span> <span class=\"n\">viewModel</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"n\">viewModel</span>\n<span class=\"p\">}</span>\n\n<span class=\"c1\">// 사용 예시</span>\n<span class=\"nd\">@Composable</span>\n<span class=\"k\">fun</span> <span class=\"nf\">SomeScreen</span><span class=\"p\">(</span><span class=\"n\">viewModel</span><span class=\"p\">:</span> <span class=\"nc\">SomeViewModel</span> <span class=\"p\">=</span> <span class=\"nf\">hiltViewModelWithLifecycle</span><span class=\"p\">())</span> <span class=\"p\">{</span>\n    <span class=\"c1\">// 이제 LaunchedLifecycleViewModel() 호출 불필요</span>\n    <span class=\"c1\">// ... UI ...</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>(Gemini 주의: <code class=\"language-plaintext highlighter-rouge\">hiltViewModelWithLifecycle</code> 같은 함수는 Composable 함수 내에서 다른 Composable 함수(LaunchedLifecycleViewModel)를 호출하는 방식이므로, ViewModel 생성 로직과 Lifecycle 관찰 로직을 분리하는 것이 더 좋을 수 있다. 또는 별도의 진입점 Composable에서 처리하는 방식도 고려할 수 있다.)</p>\n\n<p>고려사항:</p>\n<ul>\n  <li>이 방식은 ViewModel이 간접적으로 UI Lifecycle을 인지하게 되는 것 아니냐는 비판이 있을 수 있다. 하지만 start/cancelActionProcessing 함수 호출 시점은 ViewModel 외부(LaunchedLifecycleViewModel)에서 결정되므로, ViewModel 자체는 Lifecycle 객체를 직접 참조하지 않는다.</li>\n  <li>ON_RESUME / ON_PAUSE 이벤트마다 Job을 취소하고 다시 시작하는 오버헤드가 발생할 수 있다. 하지만 이는 화면이 실제로 보이지 않을 때 불필요한 Action 처리를 방지하는 효과적인 방법 중 하나이다.</li>\n</ul>\n\n<p><br /></p>\n\n<h2>해결했을까?</h2>\n\n<p>위 변경 사항들을 통해 초기 설계에서 발견된 두 가지 주요 문제점을 해결할 수 있었다.</p>\n\n<ul>\n  <li>무한 루프 발생 가능성: <code class=\"language-plaintext highlighter-rouge\">reducer</code> 처리 후 자동 <code class=\"language-plaintext highlighter-rouge\">nextAction</code> 전파 로직을 제거하고, 명시적인 <code class=\"language-plaintext highlighter-rouge\">nextAction</code> 함수 호출 방식으로 변경하여 해결했다.</li>\n  <li>싱글턴 <code class=\"language-plaintext highlighter-rouge\">Action</code> 스트림의 Lifecycle 문제: Composable의 Lifecycle에 맞춰 ViewModel의 Action 스트림 구독을 제어하는 <code class=\"language-plaintext highlighter-rouge\">LaunchedLifecycleViewModel</code> Helper Composable을 도입하여, 비활성 화면에서의 불필요한 Action 처리 가능성을 해결했다.</li>\n</ul>\n\n<p>하지만 항상 더 나은 방법이 있을 수 있다.</p>\n\n<p><br /></p>\n\n<h2>구독하는 더 좋은 방법은 없을까?</h2>\n\n<p><code class=\"language-plaintext highlighter-rouge\">ON_RESUME</code>/<code class=\"language-plaintext highlighter-rouge\">ON_PAUSE</code> 마다 <code class=\"language-plaintext highlighter-rouge\">launchIn</code>으로 <code class=\"language-plaintext highlighter-rouge\">Job</code>을 생성하고 취소하는 방식 대신, Flow의 <code class=\"language-plaintext highlighter-rouge\">stateIn</code> 연산자를 활용하는 방법을 고려해볼 수 있다.</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">stateIn</code> 연산자는 <code class=\"language-plaintext highlighter-rouge\">Flow</code>를 <code class=\"language-plaintext highlighter-rouge\">StateFlow</code>로 변환하며, 구독자(collector)의 유무에 따라 업스트림 Flow의 실행을 제어할 수 있는 SharingStarted 정책을 제공한다. 예를 들어 <code class=\"language-plaintext highlighter-rouge\">SharingStarted.WhileSubscribed()</code> 정책을 사용하면, StateFlow를 구독하는 Composable이 화면에 보이는 동안(<code class=\"language-plaintext highlighter-rouge\">collectAsState</code> 등으로 구독 중)에만 업스트림 Flow(actionProcessingFlow)가 활성화되고, 화면에서 사라지면 자동으로 구독이 중단(cancel)될 수 있다.</p>\n\n<p>이러한 접근 방식은 Slack에서 만든 <a href=\"https://slackhq.github.io/circuit/\">Circuit - link</a> 아키텍처와 유사한 방향으로 흘러갈 수 있다. Circuit에서는 Presenter가 UI State를 Flow로 노출하고, UI 이벤트는 Sink를 통해 Presenter로 전달됩니다. Presenter 내부 로직의 실행 여부는 최종적으로 UI State Flow의 구독 여부에 따라 결정될 수 있다.</p>\n\n<p>skydoves(재웅 님)가 작성한 <a href=\"https://proandroiddev.com/loading-initial-data-in-launchedeffect-vs-viewmodel-f1747c20ce62\">Loading Initial Data in LaunchedEffect vs. ViewModel - link</a> 글에서도 LaunchedEffect 내에서의 데이터 로딩과 ViewModel의 stateIn을 활용한 데이터 로딩 방식을 비교하며 유사한 아이디어를 엿볼 수 있다.</p>\n\n<p>결국 상태(State)를 중심으로 데이터 흐름을 관리하고, 그 상태의 구독 생명주기에 맞춰 연관된 로직(Action 처리 등)의 실행 여부를 제어하는 방식이 더 Compose 친화적이고 효율적일 수 있다.</p>\n\n<p>저는 현재 설계에서 상태 관리와 이벤트 처리를 분리하고 싶어 이 방식(Circuit이나 stateIn을 전면적으로 활용하는 방식)까지 적용하지는 않았지만, 궁극적으로는 이와 유사한 형태로 발전할 수 있지 않을까 생각하고 있다.</p>\n\n<p><br /></p>\n\n<h2>Next</h2>\n\n<p>이번 글에서는 기존 Composable Architecture 설계에서 발견된 2가지 문제점을 파악하고 이를 해결하기 위해 어떤 고민과 선택을 했는지 정리해보았다.</p>\n\n<p>다음 글에서는 이 아키텍처를 활용하여 구현한 구체적인 기능들을 다룰 예정이다.</p>\n\n<ul>\n  <li>코드에는 이미 있지만 Alert/Toast를 포함하고있다.</li>\n  <li>Router(액티비티, 네비게이션)를 처리하기 위한 부분도 포함하고있다.</li>\n</ul>\n\n<p>이제 다음 글에서 이 두개를 정리할 계획이다.</p>\n\n<p><br /></p>\n\n<h2>작성 글 이어보기</h2>\n\n<ul>\n  <li><a href=\"https://thdev.tech/architecture/2025/02/02/Android-Architecture-01/\">컴포즈에 사용할 Composable Architecutre 설명(리엑트?)</a></li>\n  <li>Composable Architecutre는 만들었는데 문제가 있었네? 개선해보자.</li>\n  <li>예고 - Composable Architecutre를 활용한 Alert/Toast?</li>\n  <li>예고 - Composable Architecutre를 활용한 Router?</li>\n</ul>\n\n",
        "contentSnippet": "이전 글에서 Composable Architecutre를 소개하는 내용을 담아보았는데, 몇 가지 문제점을 발견하여 이를 개선한 내용을 다시 정리하는 글이다.\n크게 2가지 문제점을 확인하였다.\nViewModel 내 Reducer 처리 후 자동 next\nAction 스트림 처리를 위한 싱글턴 활용 시 Lifecycle 문제\n이 2가지 문제점을 해결하기 위해 코드를 어떻게 수정했는지, 그리고 더 나은 방법은 없을지 고민한 과정을 정리해본다.\n이 글에서는\n기존 아키텍처의 구조적 문제점을 파악한다.\n문제 해결 과정과 더 나은 구조에 대한 고민을 공유한다.\n기본적인 내용을 담지 않고있어 앞선 글을 참고하면 좋다.\nAction이란?\nView와 ViewModel 사이의 통신을 어떻게 더 간결하게 할 수 있을까? Jetpack Compose 환경에서는 CompositionLocal - link을 활용하는 방법이 있다. 저는 이 방식을 응용하여 Composable 함수 어디서든 이벤트 처리를 쉽게 호출할 수 있도록 Action이라는 개념을 만들었다.\nFlow를 기반으로 한 Action을 사용한 이유를 설명하기 위해, 먼저 일반적인 View-ViewModel 간 통신 방식의 예시 코드를 살펴보자.\nComposable 함수에서 ViewModel 인스턴스를 파라미터로 직접 전달받아 사용하는 것이 일반적이다. 하지만 이 방식은 Composable 함수의 깊이가 깊어지거나 개수가 많아질수록 ViewModel을 어디까지 전달해야 할지 고민이 필요하며, 구조가 복잡해지면 자연스럽게 보일러플레이트 코드가 늘어나는 단점이 있다.\nViewModel을 직접 사용한 함수 호출\n\n@Composable\nfun SomeScreen(someViewModel: SomeViewModel) {\n  Button(onClick = { someViewModel.doSomething() })\n  Button(onClick = { someViewModel.doSomethingTwo() })\n  Button(onClick = { someViewModel.doSomethingThree() })\n}\n\nclass SomeViewModel : ViewModel() {\n  fun doSomething() { /* ... */ }\n  fun doSomethingTwo() { /* ... */ }\n  fun doSomethingThree() { /* ... */ }\n}\n\n\nViewModel 함수를 sealed interface로 통합하여 호출하는 경우\n\nsealed interface SomeAction {\n    data object ActionOne : SomeAction\n    data object ActionTwo : SomeAction\n    data class ActionThree(val item: Any) : SomeAction\n}\n\n@Composable\nfun SomeScreen(someViewModel: SomeViewModel) {\n  val item = remember { /* ... */ } // 예시 데이터\n  Button(onClick = { someViewModel.dispatch(SomeAction.ActionOne) })\n  Button(onClick = { someViewModel.dispatch(SomeAction.ActionTwo) })\n  Button(onClick = { someViewModel.dispatch(SomeAction.ActionThree(item)) })\n}\n\nclass SomeViewModel : ViewModel() {\n  fun dispatch(action: SomeAction) {\n    when (action) {\n      is SomeAction.ActionOne -> { /* ... */ }\n      is SomeAction.ActionTwo -> { /* ... */ }\n      is SomeAction.ActionThree -> { /* ... */ }\n    }\n  }\n}\n\n\n제가 활용하는 방식 (CompositionLocal 활용)\n위 방식들은 ViewModel을 계속 전달하거나, onClick: () -> Unit 같은 콜백을 계속 만들어 전달해야 하는 번거로움이 있다. 특히 콜백 방식은 이벤트 통합 과정에서 N개의 고차 함수(Higher-Order function)가 만들어질 수 있다.\n그래서 Compose에서 제공하는 Locally scoped - link을 활용하여 Action 객체에 쉽게 접근하는 방법을 사용하고 있습니다. (자세한 활용법은 이전 글 컴포즈에 사용할 Composable Architecture 설명을 참고해주세요.)\n\n// Action 정의 (예시)\nsealed interface MyScreenAction : CaAction { // CaAction은 마커 인터페이스 역할\n    data object ButtonClick : MyScreenAction\n    data class TextTyped(val text: String) : MyScreenAction\n    data class SwitchChanged(val isOn: Boolean) : MyScreenAction\n}\n\n// Composable View\n@Composable\nfun SomeScreen() {\n  // CompositionLocal을 통해 ActionDispatcher 획득\n  val actionDispatcher = LocalActionDispatcher.current\n  var textState by remember { mutableStateOf(\"\") }\n  var switchState by remember { mutableStateOf(false) }\n\n  Column {\n      Button(onClick = { actionDispatcher.dispatch(MyScreenAction.ButtonClick) }) {\n          Text(\"Click Me\")\n      }\n      TextField(\n          value = textState,\n          onValueChange = {\n              textState = it\n              actionDispatcher.dispatch(MyScreenAction.TextTyped(it))\n          }\n      )\n      Switch(\n          checked = switchState,\n          onCheckedChange = {\n              switchState = it\n              actionDispatcher.dispatch(MyScreenAction.SwitchChanged(it))\n          }\n      )\n  }\n}\n\n// ViewModel\nclass SomeViewModel(\n    private val flowCaActionStream: FlowCaActionStream // Action 스트림 주입\n) : CaViewModel<MyScreenAction>(flowCaActionStream, MyScreenAction::class) { // 수신할 Action 타입 지정\n\n    // CaViewModel 내부에서 flowAction을 통해 MyScreenAction 타입의 이벤트만 필터링하여 수신\n    // reducer 메소드에서 각 Action 처리 로직 구현\n    override suspend fun reducer(action: MyScreenAction) {\n        when (action) {\n            is MyScreenAction.ButtonClick -> {\n                // 버튼 클릭 처리 로직\n                Log.d(\"SomeViewModel\", \"Button Clicked\")\n            }\n            is MyScreenAction.TextTyped -> {\n                // 텍스트 입력 처리 로직\n                Log.d(\"SomeViewModel\", \"Text Typed: ${action.text}\")\n            }\n            is MyScreenAction.SwitchChanged -> {\n                // 스위치 변경 처리 로직\n                Log.d(\"SomeViewModel\", \"Switch Changed: ${action.isOn}\")\n            }\n        }\n    }\n}\n\n\n\n사용성 측면에서의 개선\n필요한 Action을 LocalAction.current를 통해 어디서든 호출할 수 있으므로, ViewModel 인스턴스를 계속해서 하위 Composable로 전달할 필요가 없어 개발 편의성이 향상될 수 있다.\nCompositionLocal에 적절한 기본값이나 테스트용 구현체를 제공하면 Preview 동작에도 문제가 없다. 다만, Preview에서 특정 UI 요소의 상태 변화나 인터랙션을 테스트하려면, 선언형 UI의 원칙에 따라 Stateless - link한 Composable을 만들고 상태와 이벤트를 외부에서 주입하는 것이 좋다.\n\n// Stateless Composable 예시\n@Composable\nfun SomeContent(\n    text: String,\n    isSwitchOn: Boolean,\n    onButtonClick: () -> Unit,\n    onTextTyped: (String) -> Unit,\n    onSwitchChange: (Boolean) -> Unit,\n    modifier: Modifier = Modifier // Modifier 추가 권장\n) {\n    Column(modifier = modifier) {\n        Button(onClick = onButtonClick) { /* ... */ }\n        TextField(value = text, onValueChange = onTextTyped)\n        Switch(checked = isSwitchOn, onCheckedChange = onSwitchChange)\n    }\n}\n\n// Statefull Composable (ViewModel과 연결)\n@Composable\nfun SomeScreen(viewModel: SomeViewModel = hiltViewModel()) { // Hilt 등 DI 활용 예시\n    val actionDispatcher = LocalActionDispatcher.current // Action 발송기\n    // ViewModel로부터 상태를 구독하거나, 필요한 상태를 여기서 관리\n    val textState by viewModel.textState.collectAsState() // 예시 StateFlow\n    val switchState by viewModel.switchState.collectAsState() // 예시 StateFlow\n\n    SomeContent(\n        text = textState,\n        isSwitchOn = switchState,\n        onButtonClick = { actionDispatcher.dispatch(MyScreenAction.ButtonClick) },\n        onTextTyped = { actionDispatcher.dispatch(MyScreenAction.TextTyped(it)) },\n        onSwitchChange = { actionDispatcher.dispatch(MyScreenAction.SwitchChanged(it)) }\n    )\n}\n\n\n이 방식(Stateless/Statefull 분리 및 CompositionLocal 활용)의 단점은 다음과 같다.\nViewModel에서 모든 UI 인터랙션을 하나의 reducer 함수로 통합 관리하기보다, 각 상태 업데이트 로직과 이벤트 발송 로직이 분리될 수 있다. (이는 관점에 따라 장점일 수도 있다)\n새로운 Action 이벤트를 추가할 때, ViewModel의 reducer에서도 해당 이벤트를 처리하는 로직을 추가해야 한다. (이는 sealed interface 사용 시 컴파일 타임에 강제될 수 있어 오히려 장점이 될 수 있다.)\n하지만 장점은 다음과 같습니다.\n각 UI 요소의 이벤트 발송 책임이 명확해진다.\nStateless Composable은 재사용 및 테스트가 용이하다.\nCompositionLocal을 통해 이벤트 발송 인터페이스 접근이 간편하다.\n\n정리하면\n해결하고 싶었던 지점\nView와 ViewModel 간의 이벤트 전달을 왜 항상 ViewModel 인스턴스를 통해 viewModel.someFunction() 형태로 직접 호출해야 할까?\nComposable 함수의 깊이가 깊어질 때 ViewModel 인스턴스나 콜백 함수를 계속 전달해야 하는 번거로움을 줄일 수 없을까?\n그래서 도입한 Action(CompositionLocal)\n이벤트 처리를 위한 Action 인터페이스와 이를 쉽게 발송(dispatch)할 수 있는 ActionDispatcher를 CompositionLocal로 제공하여, Composable 함수 내에서 발생하는 보일러플레이트를 줄이고자 했다.\n하지만 여전히 해결해야 할 문제가 있는데\n이벤트를 보내는 쪽(View)과 받는 쪽(ViewModel)에서 정확히 어떤 Action 타입을 사용하고 처리할지 명확히 약속이 필요하다. 만약 서로 다른 타입을 사용하거나 누락하면 이벤트가 유실되어 동작하지 않는 치명적인 문제가 발생할 수 있다.\n이 문제를 해결하고 개발 과정에서 실수를 줄이기 위해 sealed interface를 사용하여 Action을 정의하는 방식을 채택했다. sealed interface를 사용하면 ViewModel의 reducer에서 when 식으로 처리할 때 모든 하위 타입을 강제로 구현해야 하므로, 이벤트 누락 가능성을 컴파일 시점에 방지할 수 있다. 이는 UI 동작 관련 테스트 케이스를 일부 줄여줄 수 있는 장점도 있다.\n\n그래서 발견한 문제\nSwift-composable architecture - 링크를 참고하여 아키텍처를 구상하다 보니, Reducer가 특정 액션을 처리한 후 다음 액션을 연쇄적으로 발생시키는 구조를 발견했다.\nSwift Composable Architecture의 코드 예시를 보면, Reduce 클로저 내에서 .send나 다른 이펙트(Effect)를 반환하여 다음 동작을 유발할 수 있다. (아래 코드는 TCA의 이전 버전 구문일 수 있으며, 현재는 @Reducer 매크로 등을 사용한다.)\n\n// TCA 예시 (개념 설명용)\nReduce { state, action in\n  switch action {\n  case .buttonTapped:\n    state.isLoading = true\n    // 이펙트를 반환하여 비동기 작업 후 다른 액션(.dataLoaded)을 발생시킴\n    return .run { send in\n      let data = try await apiClient.fetchData()\n      await send(.dataLoaded(data))\n    }\n  case let .dataLoaded(data):\n    state.isLoading = false\n    state.data = data\n    return .none // 추가 액션 없음\n  // ...\n  }\n}\n\n\n이러한 ‘액션 후 연쇄 액션’ 개념을 안드로이드에서 Flow와 제가 만든 Action 시스템으로 구현해보고자 했다. 하지만 여기서 두 가지 주요 문제가 발생했다.\n자동 nextAction 호출로 인한 문제:\n    \nViewModel의 reducer 함수가 반환하는 값을 기반으로 시스템이 자동으로 다음 액션(nextAction)을 발생시키도록 설계했더니, 개발자가 이 동작 방식을 정확히 이해하고 사용해야 하는 부담이 늘었다. 알아야 할 규칙이 많아진 것.\n결정적으로, nextAction을 잘못 지정하거나 reducer 로직에 실수가 있으면 무한 루프에 빠질 위험이 있었다. 디버깅이 불가능한 것은 아니지만, 코드 설계상 예측 가능한 문제가 쉽게 발생할 수 있는 구조였다.\n싱글턴 Action 스트림과 Lifecycle 동기화 문제:\n    \n앱 전체에서 단 하나의 Action 스트림(FlowCaActionStream)을 싱글턴으로 사용하다 보니, 새로운 Activity가 실행되거나 Composable Navigation 라이브러리(like Navigation-Compose)를 통해 화면이 전환될 때 문제가 발생했다.\n예를 들어, Activity A와 Activity B가 있고 각각 여러 Composable 화면(Screen)을 가지고 있다고 가정해 보자. 사용자가 Activity B에 있더라도, 백그라운드의 Activity A에 속한 ViewModel들이 여전히 싱글턴 Action 스트림을 구독하고 있을 수 있다. 만약 특정 Action이 Activity B에서 발생했는데, Activity A의 ViewModel도 해당 Action 타입에 대해 필터링 로직(filterIsInstance)을 가지고 있다면, 의도치 않게 Activity A의 ViewModel에서도 해당 Action이 처리될 수 있다. (물론 reducer 로직 내에서 현재 화면 상태 등을 체크하여 방어할 수는 있겠지만, 근본적으로 불필요한 구독 및 처리 시도가 발생한다.)\n이는 특히 Alert, Toast, Router(화면 전환)와 같이 앱 전역적으로 영향을 줄 수 있는 Side Effect 처리 시 동기화 문제를 일으킬 수 있다. ViewModel의 생명주기(viewModelScope)는 일반적으로 Composable의 생명주기보다 길기 때문에 이 문제가 더 두드러진다.\n이 두 가지 문제를 어떻게 해결했는지 구체적으로 설명하겠다.\n\n문제점 1 - 무한 루프 가능성 해결하기\n무한 루프 발생 가능성을 제거하기 위해 기존 CaViewModel의 flowAction 처리 방식에서 문제의 소지가 있는 부분을 수정했다.\n기존 코드 (문제 발생 가능성 있음):\nabstract class CaViewModel<ACTION : CaAction, SIDE_EFFECT : CaSideEffect>(\n    private val flowCaActionStream: FlowCaActionStream, // 'private' 추가 (캡슐화)\n    actionClass: KClass<ACTION>,\n) : ViewModel() {\n\n    @VisibleForTesting\n    val flowAction by lazy(LazyThreadSafetyMode.NONE) {\n        flowCaActionStream.flowAction()\n            .filterIsInstance(actionClass) // 1. 해당 ViewModel이 처리할 Action만 필터링\n            .map { action -> // 2. reducer를 호출하고, 그 결과를 반환 (문제의 소지)\n                reducer(action = action) // reducer가 다음 Action을 반환한다고 가정\n            }\n            .onEach { nextActionToDispatch -> // 3. map에서 반환된 다음 Action을 자동으로 전파 (문제!)\n                flowCaActionStream.nextAction(nextActionToDispatch) // 무한 루프 가능 지점\n            }\n            // .launchIn(viewModelScope) // 실제로는 여기서 launch 되어야 함\n    }\n\n    // reducer 함수가 다음 Action을 반환하는 형태였다고 가정\n    abstract suspend fun reducer(action: ACTION): CaAction? // 예시: 반환 타입이 다음 Action\n}\n\n수정된 코드:\n\nabstract class CaViewModel<CA_ACTION : CaAction>(\n    private val flowCaActionStream: FlowCaActionStream,\n    actionClass: KClass<CA_ACTION>,\n) : ViewModel() {\n\n    // Action 처리를 위한 Flow (자동 nextAction 로직 제거)\n    @VisibleForTesting\n    internal val actionProcessingFlow by lazy(LazyThreadSafetyMode.NONE) { // 'internal'로 변경하고 이름 명확화\n        flowCaActionStream.flowAction()\n            .filterIsInstance(actionClass) // 1. 처리할 Action 필터링\n            .onEach { action -> // 2. map 대신 onEach 사용. 각 Action에 대해 reducer만 실행 (반환값 사용 안 함)\n                reducer(action = action)\n            }\n            // 3. 자동 nextAction 전파 로직 제거됨\n    }\n\n    // reducer 함수는 이제 Side Effect 처리나 상태 변경에만 집중 (반환값 없음)\n    abstract suspend fun reducer(action: CA_ACTION)\n\n    // 다음 Action을 명시적으로 전파하고 싶을 때 호출하는 함수 추가\n    protected fun nextAction(action: CaAction) { // 'protected'로 변경하여 자식 클래스에서만 사용하도록 제한\n        flowCaActionStream.nextAction(action)\n    }\n\n    // 실제 Flow 구독 시작/취소는 별도 관리 (아래 Lifecycle 해결 부분 참조)\n    @VisibleForTesting\n    var actionProcessingJob: Job? = null\n}\n\n\n수정 내용 요약:\nmap -> onEach 변경: reducer 함수가 다음 Action을 반환하고 이를 map 연산자가 받아 downstream로 흘려보내는 구조를 제거했다. 대신 onEach를 사용하여 각 Action에 대해 reducer 함수를 실행만 하도록 변경다. 이로써 reducer의 반환값과 관계없이 자동 nextAction 호출 가능성이 사라졌다.\n명시적 nextAction 함수 추가: 연쇄적인 Action 전파가 필요한 경우, 개발자가 reducer 함수 내에서 직접 nextAction(action) 함수를 호출하도록 변경했다. 이는 시스템에 의한 암묵적인 동작 대신, 개발자의 명확한 의도에 따라 다음 Action이 발생하도록 하여 코드의 예측 가능성을 높인다.\n이제 reducer 내에서 다음과 같이 명시적으로 다음 Action을 지정해야 한다.\noverride suspend fun reducer(action: MyScreenAction) {\n    when (action) {\n        is MyScreenAction.ButtonClick -> {\n            // 예시: 버튼 클릭 후 특정 조건 만족 시 Alert 표시 Action 전파\n            if (shouldShowAlert()) {\n                nextAction(CommonUiAction.ShowAlert(\"버튼 클릭됨!\")) // 명시적으로 nextAction 호출\n            }\n        }\n        // ... 다른 Action 처리\n    }\n}\n\n이 변경으로 시스템적인 무한 루프 발생 가능성은 제거되었고, 코드의 흐름이 더 명확해졌다.\n\n문제점 2 - Lifecycle 문제 해결하기\n싱글턴 Action 스트림(FlowCaActionStream) 사용 시 발생하는 Lifecycle 동기화 문제를 해결하기 위해, Composable의 Lifecycle에 맞춰 ViewModel의 Action 스트림 구독을 시작하고 중지하는 방식을 도입했다.\n문제 상황: Activity A와 B가 있을 때, Activity B가 화면에 보이는 동안에도 백그라운드의 Activity A에 있는 ViewModel이 Action 스트림을 계속 구독하고 있으면, Activity B에서 발생한 Action이 Activity A의 ViewModel에게도 전달될 수 있다. (물론 filterIsInstance로 타입 필터링은 되지만, 같은 타입의 Action을 여러 화면에서 사용한다면 문제가 된다.)\n\n\n해결 방안: Lifecycle에 따른 구독 제어\nComposable의 Lifecycle 상태(특히 ON_RESUME, ON_PAUSE)에 맞춰 ViewModel 내 Action 스트림(actionProcessingFlow)의 구독(Job)을 시작하고 취소하는 방법을 사용합니다. 이를 위해 DisposableEffect와 LocalLifecycleOwner를 활용하는 Helper Composable 함수를 만들었습니다.\n\n@Composable\nfun LaunchedLifecycleViewModel(\n    viewModel: CaViewModel<*> // 라이프사이클 관리가 필요한 ViewModel\n) {\n    val lifecycleOwner = LocalLifecycleOwner.current\n    DisposableEffect(lifecycleOwner, viewModel) { // lifecycleOwner와 viewModel이 키\n        val observer = LifecycleEventObserver { _, event ->\n            when (event) {\n                Lifecycle.Event.ON_RESUME -> {\n                    // 화면이 활성화되면 Action 스트림 구독 시작\n                    viewModel.startActionProcessing()\n                }\n                Lifecycle.Event.ON_PAUSE -> {\n                    // 화면이 비활성화되면 Action 스트림 구독 취소\n                    viewModel.cancelActionProcessing()\n                }\n                // ON_DESTROY는 DisposableEffect의 onDispose에서 처리되거나\n                // ViewModel의 onCleared에서 처리될 수 있음\n                else -> { /* Do nothing for other events */ }\n            }\n        }\n        lifecycleOwner.lifecycle.addObserver(observer)\n\n        // Composable이 Composition에서 제거될 때(onDispose) Observer 제거\n        onDispose {\n            lifecycleOwner.lifecycle.removeObserver(observer)\n            // 필요하다면 여기서도 cancelActionProcessing() 호출 고려\n            // viewModel.cancelActionProcessing()\n        }\n    }\n}\n\n\n그리고 CaViewModel에 Action 스트림 구독을 시작하고 취소하는 함수를 추가한다. (internal 접근 제한자를 사용하여 모듈 외부에서의 직접 호출을 방지한다.)\n\nabstract class CaViewModel<CA_ACTION : CaAction>(\n    // ... (이전 코드와 동일)\n) : ViewModel() {\n\n    // ... (actionProcessingFlow, reducer, nextAction 등) ...\n\n    @VisibleForTesting\n    var actionProcessingJob: Job? = null // 구독 상태를 관리하는 Job\n\n    // Action 스트림 구독 시작 (ON_RESUME 시 호출됨)\n    internal fun startActionProcessing() {\n        // 이미 실행 중이라면 중복 실행 방지\n        if (actionProcessingJob?.isActive == true) return\n\n        // 기존 Job이 있다면 취소 (혹시 모를 상황 대비)\n        cancelActionProcessing()\n\n        // actionProcessingFlow를 viewModelScope에서 구독 시작\n        actionProcessingJob = actionProcessingFlow\n            .launchIn(viewModelScope)\n    }\n\n    // Action 스트림 구독 취소 (ON_PAUSE 시 호출됨)\n    internal fun cancelActionProcessing() {\n        actionProcessingJob?.cancel()\n        actionProcessingJob = null\n    }\n\n    // ViewModel이 파괴될 때(onCleared) 확실하게 Job 취소\n    override fun onCleared() {\n        super.onCleared()\n        cancelActionProcessing()\n    }\n}\n\n\n위 코드를 활용하는 방법은?\n각 화면의 최상위 Composable에서 ObserveLifecycle 함수를 호출해주어야 한다.\n@Composable\nfun SomeScreen(viewModel: SomeViewModel = hiltViewModel()) {\n    // ViewModel의 Action 구독 라이프사이클 관리\n    LaunchedLifecycleViewModel(viewModel = viewModel)\n\n    // --- 실제 UI ---\n    // val state by viewModel.uiState.collectAsState()\n    // SomeContent(...)\n    // ---\n}\n\n개선 아이디어: 매번 ObserveLifecycle(viewModel)를 호출하는 것이 번거롭다면, ViewModel 인스턴스를 얻을 때 자동으로 이 로직을 포함시키는 확장 함수나 위임(delegate)을 고려해볼 수 있다. 예를 들어:\n\n@Composable\nfun Some(viewModel: ViewModel = hiltViewModel().Activate()) {\n  // Your view\n}\n\n\n또는 hilt를 직접 확장한다면 아래와 같다.\n\n// 개념적인 아이디어 (구현 필요)\n@Composable\ninline fun <reified VM : CaViewModel<*>> hiltViewModelWithLifecycle(): VM {\n    val viewModel: VM = hiltViewModel()\n    LaunchedLifecycleViewModel(viewModel = viewModel)\n    return viewModel\n}\n\n// 사용 예시\n@Composable\nfun SomeScreen(viewModel: SomeViewModel = hiltViewModelWithLifecycle()) {\n    // 이제 LaunchedLifecycleViewModel() 호출 불필요\n    // ... UI ...\n}\n\n\n(Gemini 주의: hiltViewModelWithLifecycle 같은 함수는 Composable 함수 내에서 다른 Composable 함수(LaunchedLifecycleViewModel)를 호출하는 방식이므로, ViewModel 생성 로직과 Lifecycle 관찰 로직을 분리하는 것이 더 좋을 수 있다. 또는 별도의 진입점 Composable에서 처리하는 방식도 고려할 수 있다.)\n고려사항:\n이 방식은 ViewModel이 간접적으로 UI Lifecycle을 인지하게 되는 것 아니냐는 비판이 있을 수 있다. 하지만 start/cancelActionProcessing 함수 호출 시점은 ViewModel 외부(LaunchedLifecycleViewModel)에서 결정되므로, ViewModel 자체는 Lifecycle 객체를 직접 참조하지 않는다.\nON_RESUME / ON_PAUSE 이벤트마다 Job을 취소하고 다시 시작하는 오버헤드가 발생할 수 있다. 하지만 이는 화면이 실제로 보이지 않을 때 불필요한 Action 처리를 방지하는 효과적인 방법 중 하나이다.\n\n해결했을까?\n위 변경 사항들을 통해 초기 설계에서 발견된 두 가지 주요 문제점을 해결할 수 있었다.\n무한 루프 발생 가능성: reducer 처리 후 자동 nextAction 전파 로직을 제거하고, 명시적인 nextAction 함수 호출 방식으로 변경하여 해결했다.\n싱글턴 Action 스트림의 Lifecycle 문제: Composable의 Lifecycle에 맞춰 ViewModel의 Action 스트림 구독을 제어하는 LaunchedLifecycleViewModel Helper Composable을 도입하여, 비활성 화면에서의 불필요한 Action 처리 가능성을 해결했다.\n하지만 항상 더 나은 방법이 있을 수 있다.\n\n구독하는 더 좋은 방법은 없을까?\nON_RESUME/ON_PAUSE 마다 launchIn으로 Job을 생성하고 취소하는 방식 대신, Flow의 stateIn 연산자를 활용하는 방법을 고려해볼 수 있다.\nstateIn 연산자는 Flow를 StateFlow로 변환하며, 구독자(collector)의 유무에 따라 업스트림 Flow의 실행을 제어할 수 있는 SharingStarted 정책을 제공한다. 예를 들어 SharingStarted.WhileSubscribed() 정책을 사용하면, StateFlow를 구독하는 Composable이 화면에 보이는 동안(collectAsState 등으로 구독 중)에만 업스트림 Flow(actionProcessingFlow)가 활성화되고, 화면에서 사라지면 자동으로 구독이 중단(cancel)될 수 있다.\n이러한 접근 방식은 Slack에서 만든 Circuit - link 아키텍처와 유사한 방향으로 흘러갈 수 있다. Circuit에서는 Presenter가 UI State를 Flow로 노출하고, UI 이벤트는 Sink를 통해 Presenter로 전달됩니다. Presenter 내부 로직의 실행 여부는 최종적으로 UI State Flow의 구독 여부에 따라 결정될 수 있다.\nskydoves(재웅 님)가 작성한 Loading Initial Data in LaunchedEffect vs. ViewModel - link 글에서도 LaunchedEffect 내에서의 데이터 로딩과 ViewModel의 stateIn을 활용한 데이터 로딩 방식을 비교하며 유사한 아이디어를 엿볼 수 있다.\n결국 상태(State)를 중심으로 데이터 흐름을 관리하고, 그 상태의 구독 생명주기에 맞춰 연관된 로직(Action 처리 등)의 실행 여부를 제어하는 방식이 더 Compose 친화적이고 효율적일 수 있다.\n저는 현재 설계에서 상태 관리와 이벤트 처리를 분리하고 싶어 이 방식(Circuit이나 stateIn을 전면적으로 활용하는 방식)까지 적용하지는 않았지만, 궁극적으로는 이와 유사한 형태로 발전할 수 있지 않을까 생각하고 있다.\n\nNext\n이번 글에서는 기존 Composable Architecture 설계에서 발견된 2가지 문제점을 파악하고 이를 해결하기 위해 어떤 고민과 선택을 했는지 정리해보았다.\n다음 글에서는 이 아키텍처를 활용하여 구현한 구체적인 기능들을 다룰 예정이다.\n코드에는 이미 있지만 Alert/Toast를 포함하고있다.\nRouter(액티비티, 네비게이션)를 처리하기 위한 부분도 포함하고있다.\n이제 다음 글에서 이 두개를 정리할 계획이다.\n\n작성 글 이어보기\n컴포즈에 사용할 Composable Architecutre 설명(리엑트?)\nComposable Architecutre는 만들었는데 문제가 있었네? 개선해보자.\n예고 - Composable Architecutre를 활용한 Alert/Toast?\n예고 - Composable Architecutre를 활용한 Router?",
        "guid": "https://thdev.tech/architecture/2025/04/15/Android-Architecture-02/",
        "isoDate": "2025-04-15T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "Splunk의 Join - 5th",
        "link": "https://kangmyounghun.blogspot.com/2025/04/splunk-join-5th.html",
        "pubDate": "2025-04-13T02:57:00.000Z",
        "author": "강명훈",
        "content": "<div>inner join.</div><div><br /></div>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEixDdh6sq0h7NiY7ekFt67l7iM1xq8xuzAs98M-YfZLGi-RF5u0jJuPt7ZKDvnI2QLHtL8ApWNdZG9BKztDHCP_Icc0AkSCy9D5VDDXr2ByO-OSVFgsjxK5KGhrL2_Whi2fNJmoWUjdSedGCFF60NFAPwO1M8dCuslqlKFPuauk9_V-Y8fEbFnaDDEj7dTQ/s1470/inner_join.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"1125\" data-original-width=\"1470\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEixDdh6sq0h7NiY7ekFt67l7iM1xq8xuzAs98M-YfZLGi-RF5u0jJuPt7ZKDvnI2QLHtL8ApWNdZG9BKztDHCP_Icc0AkSCy9D5VDDXr2ByO-OSVFgsjxK5KGhrL2_Whi2fNJmoWUjdSedGCFF60NFAPwO1M8dCuslqlKFPuauk9_V-Y8fEbFnaDDEj7dTQ/s16000/inner_join.png\" /></a></div>\n<div><br /></div><div><span><a name='more'></a></span>left join.</div><br />\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhBMe03aUKkg4gKcHkNA0_SYmAO9Qc_hcPLnmMg31hmS2tsgmWAbPfHsV0ap9GvpdrL1tDkxln4vpLrebn7ON935oJPZJT3G9TDJkFxFUkBKH92N_qoj9KFolOzXj6AQF8j0sc7maki5Fof20iL1eq2tXHp-dIZqI2SZu6DxS08Q1S5iR6Z66si6mVRbROb/s1394/left_join.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"1125\" data-original-width=\"1394\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhBMe03aUKkg4gKcHkNA0_SYmAO9Qc_hcPLnmMg31hmS2tsgmWAbPfHsV0ap9GvpdrL1tDkxln4vpLrebn7ON935oJPZJT3G9TDJkFxFUkBKH92N_qoj9KFolOzXj6AQF8j0sc7maki5Fof20iL1eq2tXHp-dIZqI2SZu6DxS08Q1S5iR6Z66si6mVRbROb/s16000/left_join.png\" /></a></div>\n<div><br /></div><div>교집합 제외한 left join.</div><br />\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiz1UdN6mn1NqtKodNpELfR6Jn4F9aLLlveptkzxioo2L_r8ISYu7ww6XSn2rbYbYtBQoq_SJtoKlAXzjtSWbV80ALWuAMX7gcTdceAJY5dRSv0qEpr_2TGk7cXyURnN0Xzg6Is88PDX0EcZopXJVY3lMjf5RJoZnogWaCMx1MsPSXEYI7Ts_oX-4d_4yEJ/s1502/left_join2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"1125\" data-original-width=\"1502\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiz1UdN6mn1NqtKodNpELfR6Jn4F9aLLlveptkzxioo2L_r8ISYu7ww6XSn2rbYbYtBQoq_SJtoKlAXzjtSWbV80ALWuAMX7gcTdceAJY5dRSv0qEpr_2TGk7cXyURnN0Xzg6Is88PDX0EcZopXJVY3lMjf5RJoZnogWaCMx1MsPSXEYI7Ts_oX-4d_4yEJ/s16000/left_join2.png\" /></a></div>\n<br /><div>full join.</div><div><br /></div>\n<div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiyoVvxzr8IoshQYh36Igmd1CshyphenhyphencRy2qO_13b-CepCvOKannzB5NLUTkMD_gbjAqVhKjR8vIZ0D2sBI9r9NebVtKHXSe4kKO0-T5n_zzvzh7H3cA159pQv9ekt_qWKvK_OnHQjy9mMw2BXBhTc3XRvz-gbaRl3M5XnfptbxtO74GJK6HIUhO5QJ7ZXLU_0/s1125/full_join.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"1125\" data-original-width=\"944\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiyoVvxzr8IoshQYh36Igmd1CshyphenhyphencRy2qO_13b-CepCvOKannzB5NLUTkMD_gbjAqVhKjR8vIZ0D2sBI9r9NebVtKHXSe4kKO0-T5n_zzvzh7H3cA159pQv9ekt_qWKvK_OnHQjy9mMw2BXBhTc3XRvz-gbaRl3M5XnfptbxtO74GJK6HIUhO5QJ7ZXLU_0/s16000/full_join.png\" /></a></div><br /></div><div>교집합 제외한 full join.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgPSJ6DgrvnRYmhT5qwkLjXTFV8ig78PCr9gPHmpDfYxcycB4sM6Hcu6A4cuuTd3a6F3HDwU9kNgjiqBJlQs1UggleUsH2gWer86fn7sjY_N6CxQofWcubDBLlWHvZ2jMalTLIEFMJ1PWoJ59lrG9BYGrn75eOQqhyWkzaOsdyIQD6dcJkQu4_v4suR-kfC/s1125/full_join2.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"1125\" data-original-width=\"990\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgPSJ6DgrvnRYmhT5qwkLjXTFV8ig78PCr9gPHmpDfYxcycB4sM6Hcu6A4cuuTd3a6F3HDwU9kNgjiqBJlQs1UggleUsH2gWer86fn7sjY_N6CxQofWcubDBLlWHvZ2jMalTLIEFMJ1PWoJ59lrG9BYGrn75eOQqhyWkzaOsdyIQD6dcJkQu4_v4suR-kfC/s16000/full_join2.png\" /></a></div><br /><div><b>관련 글</b></div><div><div><ul><li><a href=\"https://kangmyounghun.blogspot.com/2024/10/splunk-join-4th.html\">Splunk의 Join - 4th</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2021/03/splunk-join.html\" target=\"\">Splunk의 Join</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2021/07/splunk-lookup.html\" target=\"\">Splunk의 lookup</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2022/10/join.html\" target=\"\">엘라스틱의 Join</a></li></ul></div></div>",
        "contentSnippet": "inner join.\n\n\n\n\nleft join.\n\n\n\n교집합 제외한 left join.\n\n\nfull join.\n\n\n\n\n\n교집합 제외한 full join.\n\n\n\n\n관련 글\n\n\nSplunk의 Join - 4th\nSplunk의 Join\nSplunk의 lookup\n엘라스틱의 Join",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-9209557534125241532",
        "isoDate": "2025-04-13T02:57:00.000Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": [
      {
        "title": "승려와 수수께끼 | 랜디 코미사",
        "link": "https://sungjk.github.io/2025/04/12/the-monk-and-the-riddle.html",
        "pubDate": "2025-04-12T00:00:00+00:00",
        "content": "\n            \n            &lt;p&gt;&lt;img src=&quot;/images/2025/04/12/the-monk-and-the-riddle.png&quot; alt=&quot;The Monk And The Riddle&quot; title=&quot;The Monk And The Riddle&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n  &lt;p&gt;&lt;strong&gt;“이 달걀을 1미터 정도 아래로 떨어뜨리되 깨뜨리면 안 됩니다. 어찌 해야 할까요?”&lt;/strong&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;변호사이자 실리콘밸리 투자자인 &lt;a href=&quot;https://en.wikipedia.org/wiki/Randy_Komisar&quot;&gt;랜디 코미사&lt;/a&gt;의 이야기를 다룬 책이다. 미얀마에서 만난 한 승려가 던지는 질문으로 책에서 하고자 하는 이야기가 시작된다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;이 달걀을 1미터 정도 아래로 떨어뜨리되 깨뜨리면 안 됩니다. 어찌 해야 할까요?&lt;/code&gt; 이 질문을 들으면 어떤 생각이 드는가? 단단한 돌 바닥 위에서 달걀을 들고 있는 모습이 상상된다. 그런데 이걸 떨어뜨리되 깨뜨리면 안된다..? 바닥에 쿠션을 놓으면 안될까? 아니면 혹시.. 물 위에서 떨어뜨리면 안되나?&lt;/p&gt;\n\n&lt;p&gt;우리는 자연스레 계란이 떨어지면 깨지는 것부터 상상한다. 그래서 깨지지 않게 하려면 바닥에 부드러운 무언가를 놓고 깨지지 않게끔 만드는게 중요하다고 생각이 든다. 승려는 어떤 메시지를 전달하고 싶어서 이런 질문을 했는지 궁금증을 가진채 계속 읽어 나갔다.&lt;/p&gt;\n\n&lt;p&gt;승려는 책의 도입부에 질문을 마지막으로 나오지 않고, 그 이후부터는 랜디와 레니라는 창업가의 이야기로만 구성되어 있다. 어느날 랜디에게 장례 용품을 온라인에서 사고 팔 수 있는 사업을 하겠다고 레니라는 사람이 투자와 자문을 구하기 위해 찾아왔다. 레니는 엄청난 열정과 굉장히 구체적인 사업 계획을 가지고 있었다. 하지만 지금 당장은 돈을 벌기 위한 수단으로 사업을 하고, 돈을 많이 벌고 난 이후에 본인이 진짜 하고 싶은 일을 하려고 계획중이었다. 이런 레니의 이야기를 듣고 랜디는 열정 가득하고 사업 계획 구체적이지만, 왜 장례 사업을 하려는건지 목적과 비전이 뚜렷하지 않아서 몇 가지 조언을 남긴 뒤 투자를 위한 마음은 접기로 했다.&lt;/p&gt;\n\n&lt;blockquote&gt;\n  &lt;p&gt;“내 경험상, 만약 돈 때문에 이 일을 시작한다면 닭 쫓던 개 신세를 면치 못할 겁니다. 돈은 결코 그렇게 따라오지 않아요. 뭔가 더 있어야 합니다. 상황이 최악으로 치달을 때 나를 지켜줄 만한 목적의식 같은 것 말이죠. 실패하더라도 이 일에 엄청난 시간과 노력을 쏟을 만한 가치가 있는, 그런 것이 있어야 한단 말입니다.”&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;그러나 레니는 포기하지 않고 랜디의 조언을 바탕으로 사업 계획서를 다시 다듬고 오랜 기간 랜디를 괴롭히다시피 한다. 결국 랜디는 굉장히 끈질긴 성격을 가진 레니에게 사업을 하려고 하는 진짜 목적에 대해 스스로 고민할 수 있도록 질문을 하기 시작한다. ‘미뤄 놓은 인생 설계’, ‘내가 가장 하고 싶은 것’. 중간중간 랜디의 변호사 시절과 실리콘밸리 회사에서의 다양한 경험 이야기도 나오는데, 사업을 함에 있어 가장 중요한건 동기라는 사실을 일깨워준다. 레니는 랜디와 동업자 앨리슨의 생각과 조언을 받아들여 본인이 정말로 하고 싶었던 것과 장례 사업을 접목시켜 가슴뛰는 사업의 목적을 찾게 된다.&lt;/p&gt;\n\n&lt;p&gt;살면서 혹은 일을 하면서 여러가지 문제를 마주하는데 그 때마다 &lt;strong&gt;지금 있는 현상에만 집중하다가 본질(핵심)이 무엇인지 잊게 된다.&lt;/strong&gt; 현상에만 집중하다보면 본질과 다른 방향으로 답을 찾게 된다. 책의 맨 마지막에 승려가 낸 질문에 대한 해답이 나온다. 그런데 그 답이 중요한게 아니라, 승려가 왜 이 수수께끼를 냈는지가 중요하다. 책을 읽다보면 승려가 내놓은 수수께끼의 본질을 알게 되는데, &lt;strong&gt;‘계란이 깨지지 않게 만드는게 아니라, 1미터 높이에서 깨지지 않는 상태로 존재하게 할 수 있는 방법’&lt;/strong&gt; 이다.&lt;/p&gt;\n\n&lt;p&gt;이 책의 주된 이야기인 사업 뿐만 아니라, 우리가 하고 있는 무언가에 대한 질문이기도 하다. 지금 원하는 일을 하고 있는가? 이 일을 왜 하는가? 열심히 일해서, 돈 많이 벌어서, 나중에 하고 싶은거 하면서 편하게 즐겁게 살아야지. 인생은 출애굽기도, 영웅전도 아니다. 현재의 고통을 전제로 미래의 행복을 바꾸거나 하고 싶지도 않은 일에 인생을 낭비하기엔 너무 아깝고, 당장 하고 싶은 일을 해야 한다는 당연하면서도 어려운 교훈을 주는 책이다.&lt;/p&gt;\n\n&lt;h3 id=&quot;인상-깊은-구절&quot;&gt;인상 깊은 구절&lt;/h3&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;열정이란, 저항할 수조차 없이 어떤 것으로 당신 자신을 끌어가는 것을 말한다. 반면 의지란, 책임감 또는 해야만 한다고 생각되는 일에 의해 떠밀려가는 것이다. 만약 자신에 대해 아무것도 모른다면 그 차이를 알 수 없다. 조금이나마 자기 인식을 하고 있는 사람은 내가 어떤 분야에 열정을 가지고 있는지 알 수가 있다. 어떤 목표를 달성하고 싶다는 욕망은 열정이 아니며, 일정 수준의 몫이나 보너스, 또는 회사를 매각하여 현금을 벌고 싶다는 욕심도 열정이 아니다. 다른 사람의 성취를 따라 하기 위해 노력하는 것도 열정이 아니다. 그것은 의지에 가깝다.&lt;/li&gt;\n  &lt;li&gt;비즈니스 환경은 늘 변한다. 사람들은 전략과 수익모델을 변화하는 환경에 맞게 지속적으로 재검토하고 필요에 따라 수정해야 한다. 하지만 수정할 때마다 기준으로 삼아야 하는 것은 기업의 큰 비전이다. 긴급한 상황을 모면하기 위해 구성원의 감동을 이끌어 내는 비전을 포기하면, 나침반 없이 남겨지는 것과 다를 바 없다. 나는 기업의 위치를 돌아볼 때 현재 상황만 따지는 것이 아니라 목표와 방향 점검도 병행돼야 한다는 충고를 늘 하고 있다. 나침반을 맞추고 길을 따라 나아가라. 그래야 장애물에 걸려 넘어지더라도 방향 감각을 유지할 수 있을 것이다.&lt;/li&gt;\n  &lt;li&gt;관리와 리더십은 서로 공통점이 있기는 하지만 같은 건 아니다. 레니처럼 편협한 사고방식을 가지고 있는 사람은 그 차이를 알 수 없다. 관리는 체계적인 과정을 말하는데 그 목적은 정해진 시간과 예산 내에서 원하는 결과를 낳는 것이다. 리더십은 인격과 비전으로 다른 사람을 불가능한 일에 도전하도록 만든다. 관리는 리더십을 보완하고 지원하지만, 리더십을 내포하지 않은 관리는 아무것도 할 수 없다. 리더는 아랫사람들의 의혹을 해소시키고 불완전한 정보를 가지고도 나아갈 수 있도록 만들어야 한다.&lt;/li&gt;\n  &lt;li&gt;기차를 제시간에 맞게 도착시키는 관리자의 역할보다 리더로서의 업무가 나는 더 마음에 들었다. 리더의 묘미는 계산기를 두드리고 생산라인을 개선하는 방법을 찾는 것에 있지 않았다. 사람들이 한계를 넘어설 수 있도록 용기를 북돋고, 사람들이 위대해질 수 있도록 자극을 주며 나보다 더 잘 할 수 있는 사람에게 그 일을 맡기며, 또한 사람들이 조화롭게 업무를 수행할 수 있도록 돕는 데 있었다. 그게 수준 높다할 수 있는 기술이었다.&lt;/li&gt;\n  &lt;li&gt;위험부담에 너무 신경 쓴 나머지 아무런 결정도 내리지 못하는 사람들도 있다. 이들은 모든 사항을 열심히 검토하지만, 어느 순간부터는 추가 정보나 확증이 있어도 사업의 궁극적인 성공이나 실패에 대한 갈피를 잡지 못하게 된다. 이렇게 되면 이들은 불확실에 휩싸인 나머지 그 자리에 얼어붙은 채 현상만을 유지한다. 결국 그들이 아는 것은 그게 전부가 된다.&lt;/li&gt;\n  &lt;li&gt;하지만 좀 더 파고들어 가면, 사업의 위험부담과 함께 결부되는 개인의 위험부담도 고려하게 된다. 개인의 위험부담은 존경하지 않는 사람과 함께 일하는 것, 나와 다른 사업관을 가진 회사에서 일하는 것, 그리고 중요하다고 생각하는 것을 타협해야 하는 것, 본모습을 제대로 발휘할 수 없는, 혹은 완전히 모순되는 일을 하는 것들을 의미한다. 하지만 그 중 가장 큰 위험 부단은 미래의 행복을 위안으로 삼으면서 하고 싶지도 않은 일에 평생 인생을 낭비하게 되는 것이다.&lt;/li&gt;\n  &lt;li&gt;반면 개인적 위험은 계량화가 불가능하다. 그것은 가치와 우선순위, 자신이 누구인지를 표현하는 문제다. ‘안전 제일주의’ 라는 말은 현상에 만족하겠다는 것을 의미한다. 지금 당장 금전적 이익이 있으면 시간 낭비와 만족감의 부채 또한 감소할 수 있다는 뜻이다. 아니면 아무 생각조차 해보지 않겠다는 뜻이다. 반면, 시간과 만족이 값을 매길 수 없을만큼 소중한 것이라 여긴다면 자신과 가족의 행복을 위험에 빠뜨리지 않는 한도 내에서 실패에 따른 위험부담을 감수하게 된다. 원하는 삶을 살기 위한 위험부담은 아무것도 아니라는 것을 알기 때문이다.&lt;/li&gt;\n  &lt;li&gt;개인의 위험부담을 생각하다 보면 개인의 성공에 대한 정의도 내려진다. 사업적인 성공이 꼭 개인의 성공으로 연결된다고 할 수 없다. 우리는 대부분 초등학교에서부터 대학교를 거쳐 직장생활에 이르기까지, 끊임없는 방해요소에 부딪히면서 다른 사람들이 내린 ‘성공’ 의 정의를 그대로 인식하게 된다. 다른 사람들이 만든 기준으로 자신을 평가하고, 다른 사람과 나를 비교해 순위를 매기려 한다. 개인적인 목표는 오로지 우리 스스로에게 놓여 있을 뿐, 쓸데없는 평가와 비교로부터 자유로운 것이다.&lt;/li&gt;\n  &lt;li&gt;열정을 다해 열심히 일하라. 단, 가장 소중한 재산인 시간을 가장 의미 있는 일에 써라. 남은 인생 동안 무엇을 하고 싶은가? 이 말은 문자 그대로 앞으로 평생 무엇을 할 것인가 라는 뜻이 아니다. 예상치 않은 사회 속에서 앞으로 평생 동안 어떤 일을 하게 될지 알 수 있는 사람이 과연 누가 있을까? 내일 갑자기 생이 끝난다면 지금까지 정말로 하고 싶은 일을 하면서 살았다고 자신 있게 말할 수 있을까? 당신은 앞으로 평생 어떤 일을 하고 싶은가? 지금 당장 그 일을 시작하려면 어떻게 해야 할까?&lt;/li&gt;\n&lt;/ul&gt;\n\n            \n          ",
        "contentSnippet": "<p><img src=\"/images/2025/04/12/the-monk-and-the-riddle.png\" alt=\"The Monk And The Riddle\" title=\"The Monk And The Riddle\" class=\"center-image\" /></p>\n\n<blockquote>\n  <p><strong>“이 달걀을 1미터 정도 아래로 떨어뜨리되 깨뜨리면 안 됩니다. 어찌 해야 할까요?”</strong></p>\n</blockquote>\n\n<p>변호사이자 실리콘밸리 투자자인 <a href=\"https://en.wikipedia.org/wiki/Randy_Komisar\">랜디 코미사</a>의 이야기를 다룬 책이다. 미얀마에서 만난 한 승려가 던지는 질문으로 책에서 하고자 하는 이야기가 시작된다. <code class=\"language-plaintext highlighter-rouge\">이 달걀을 1미터 정도 아래로 떨어뜨리되 깨뜨리면 안 됩니다. 어찌 해야 할까요?</code> 이 질문을 들으면 어떤 생각이 드는가? 단단한 돌 바닥 위에서 달걀을 들고 있는 모습이 상상된다. 그런데 이걸 떨어뜨리되 깨뜨리면 안된다..? 바닥에 쿠션을 놓으면 안될까? 아니면 혹시.. 물 위에서 떨어뜨리면 안되나?</p>\n\n<p>우리는 자연스레 계란이 떨어지면 깨지는 것부터 상상한다. 그래서 깨지지 않게 하려면 바닥에 부드러운 무언가를 놓고 깨지지 않게끔 만드는게 중요하다고 생각이 든다. 승려는 어떤 메시지를 전달하고 싶어서 이런 질문을 했는지 궁금증을 가진채 계속 읽어 나갔다.</p>\n\n<p>승려는 책의 도입부에 질문을 마지막으로 나오지 않고, 그 이후부터는 랜디와 레니라는 창업가의 이야기로만 구성되어 있다. 어느날 랜디에게 장례 용품을 온라인에서 사고 팔 수 있는 사업을 하겠다고 레니라는 사람이 투자와 자문을 구하기 위해 찾아왔다. 레니는 엄청난 열정과 굉장히 구체적인 사업 계획을 가지고 있었다. 하지만 지금 당장은 돈을 벌기 위한 수단으로 사업을 하고, 돈을 많이 벌고 난 이후에 본인이 진짜 하고 싶은 일을 하려고 계획중이었다. 이런 레니의 이야기를 듣고 랜디는 열정 가득하고 사업 계획 구체적이지만, 왜 장례 사업을 하려는건지 목적과 비전이 뚜렷하지 않아서 몇 가지 조언을 남긴 뒤 투자를 위한 마음은 접기로 했다.</p>\n\n<blockquote>\n  <p>“내 경험상, 만약 돈 때문에 이 일을 시작한다면 닭 쫓던 개 신세를 면치 못할 겁니다. 돈은 결코 그렇게 따라오지 않아요. 뭔가 더 있어야 합니다. 상황이 최악으로 치달을 때 나를 지켜줄 만한 목적의식 같은 것 말이죠. 실패하더라도 이 일에 엄청난 시간과 노력을 쏟을 만한 가치가 있는, 그런 것이 있어야 한단 말입니다.”</p>\n</blockquote>\n\n<p>그러나 레니는 포기하지 않고 랜디의 조언을 바탕으로 사업 계획서를 다시 다듬고 오랜 기간 랜디를 괴롭히다시피 한다. 결국 랜디는 굉장히 끈질긴 성격을 가진 레니에게 사업을 하려고 하는 진짜 목적에 대해 스스로 고민할 수 있도록 질문을 하기 시작한다. ‘미뤄 놓은 인생 설계’, ‘내가 가장 하고 싶은 것’. 중간중간 랜디의 변호사 시절과 실리콘밸리 회사에서의 다양한 경험 이야기도 나오는데, 사업을 함에 있어 가장 중요한건 동기라는 사실을 일깨워준다. 레니는 랜디와 동업자 앨리슨의 생각과 조언을 받아들여 본인이 정말로 하고 싶었던 것과 장례 사업을 접목시켜 가슴뛰는 사업의 목적을 찾게 된다.</p>\n\n<p>살면서 혹은 일을 하면서 여러가지 문제를 마주하는데 그 때마다 <strong>지금 있는 현상에만 집중하다가 본질(핵심)이 무엇인지 잊게 된다.</strong> 현상에만 집중하다보면 본질과 다른 방향으로 답을 찾게 된다. 책의 맨 마지막에 승려가 낸 질문에 대한 해답이 나온다. 그런데 그 답이 중요한게 아니라, 승려가 왜 이 수수께끼를 냈는지가 중요하다. 책을 읽다보면 승려가 내놓은 수수께끼의 본질을 알게 되는데, <strong>‘계란이 깨지지 않게 만드는게 아니라, 1미터 높이에서 깨지지 않는 상태로 존재하게 할 수 있는 방법’</strong> 이다.</p>\n\n<p>이 책의 주된 이야기인 사업 뿐만 아니라, 우리가 하고 있는 무언가에 대한 질문이기도 하다. 지금 원하는 일을 하고 있는가? 이 일을 왜 하는가? 열심히 일해서, 돈 많이 벌어서, 나중에 하고 싶은거 하면서 편하게 즐겁게 살아야지. 인생은 출애굽기도, 영웅전도 아니다. 현재의 고통을 전제로 미래의 행복을 바꾸거나 하고 싶지도 않은 일에 인생을 낭비하기엔 너무 아깝고, 당장 하고 싶은 일을 해야 한다는 당연하면서도 어려운 교훈을 주는 책이다.</p>\n\n<h3 id=\"인상-깊은-구절\">인상 깊은 구절</h3>\n\n<ul>\n  <li>열정이란, 저항할 수조차 없이 어떤 것으로 당신 자신을 끌어가는 것을 말한다. 반면 의지란, 책임감 또는 해야만 한다고 생각되는 일에 의해 떠밀려가는 것이다. 만약 자신에 대해 아무것도 모른다면 그 차이를 알 수 없다. 조금이나마 자기 인식을 하고 있는 사람은 내가 어떤 분야에 열정을 가지고 있는지 알 수가 있다. 어떤 목표를 달성하고 싶다는 욕망은 열정이 아니며, 일정 수준의 몫이나 보너스, 또는 회사를 매각하여 현금을 벌고 싶다는 욕심도 열정이 아니다. 다른 사람의 성취를 따라 하기 위해 노력하는 것도 열정이 아니다. 그것은 의지에 가깝다.</li>\n  <li>비즈니스 환경은 늘 변한다. 사람들은 전략과 수익모델을 변화하는 환경에 맞게 지속적으로 재검토하고 필요에 따라 수정해야 한다. 하지만 수정할 때마다 기준으로 삼아야 하는 것은 기업의 큰 비전이다. 긴급한 상황을 모면하기 위해 구성원의 감동을 이끌어 내는 비전을 포기하면, 나침반 없이 남겨지는 것과 다를 바 없다. 나는 기업의 위치를 돌아볼 때 현재 상황만 따지는 것이 아니라 목표와 방향 점검도 병행돼야 한다는 충고를 늘 하고 있다. 나침반을 맞추고 길을 따라 나아가라. 그래야 장애물에 걸려 넘어지더라도 방향 감각을 유지할 수 있을 것이다.</li>\n  <li>관리와 리더십은 서로 공통점이 있기는 하지만 같은 건 아니다. 레니처럼 편협한 사고방식을 가지고 있는 사람은 그 차이를 알 수 없다. 관리는 체계적인 과정을 말하는데 그 목적은 정해진 시간과 예산 내에서 원하는 결과를 낳는 것이다. 리더십은 인격과 비전으로 다른 사람을 불가능한 일에 도전하도록 만든다. 관리는 리더십을 보완하고 지원하지만, 리더십을 내포하지 않은 관리는 아무것도 할 수 없다. 리더는 아랫사람들의 의혹을 해소시키고 불완전한 정보를 가지고도 나아갈 수 있도록 만들어야 한다.</li>\n  <li>기차를 제시간에 맞게 도착시키는 관리자의 역할보다 리더로서의 업무가 나는 더 마음에 들었다. 리더의 묘미는 계산기를 두드리고 생산라인을 개선하는 방법을 찾는 것에 있지 않았다. 사람들이 한계를 넘어설 수 있도록 용기를 북돋고, 사람들이 위대해질 수 있도록 자극을 주며 나보다 더 잘 할 수 있는 사람에게 그 일을 맡기며, 또한 사람들이 조화롭게 업무를 수행할 수 있도록 돕는 데 있었다. 그게 수준 높다할 수 있는 기술이었다.</li>\n  <li>위험부담에 너무 신경 쓴 나머지 아무런 결정도 내리지 못하는 사람들도 있다. 이들은 모든 사항을 열심히 검토하지만, 어느 순간부터는 추가 정보나 확증이 있어도 사업의 궁극적인 성공이나 실패에 대한 갈피를 잡지 못하게 된다. 이렇게 되면 이들은 불확실에 휩싸인 나머지 그 자리에 얼어붙은 채 현상만을 유지한다. 결국 그들이 아는 것은 그게 전부가 된다.</li>\n  <li>하지만 좀 더 파고들어 가면, 사업의 위험부담과 함께 결부되는 개인의 위험부담도 고려하게 된다. 개인의 위험부담은 존경하지 않는 사람과 함께 일하는 것, 나와 다른 사업관을 가진 회사에서 일하는 것, 그리고 중요하다고 생각하는 것을 타협해야 하는 것, 본모습을 제대로 발휘할 수 없는, 혹은 완전히 모순되는 일을 하는 것들을 의미한다. 하지만 그 중 가장 큰 위험 부단은 미래의 행복을 위안으로 삼으면서 하고 싶지도 않은 일에 평생 인생을 낭비하게 되는 것이다.</li>\n  <li>반면 개인적 위험은 계량화가 불가능하다. 그것은 가치와 우선순위, 자신이 누구인지를 표현하는 문제다. ‘안전 제일주의’ 라는 말은 현상에 만족하겠다는 것을 의미한다. 지금 당장 금전적 이익이 있으면 시간 낭비와 만족감의 부채 또한 감소할 수 있다는 뜻이다. 아니면 아무 생각조차 해보지 않겠다는 뜻이다. 반면, 시간과 만족이 값을 매길 수 없을만큼 소중한 것이라 여긴다면 자신과 가족의 행복을 위험에 빠뜨리지 않는 한도 내에서 실패에 따른 위험부담을 감수하게 된다. 원하는 삶을 살기 위한 위험부담은 아무것도 아니라는 것을 알기 때문이다.</li>\n  <li>개인의 위험부담을 생각하다 보면 개인의 성공에 대한 정의도 내려진다. 사업적인 성공이 꼭 개인의 성공으로 연결된다고 할 수 없다. 우리는 대부분 초등학교에서부터 대학교를 거쳐 직장생활에 이르기까지, 끊임없는 방해요소에 부딪히면서 다른 사람들이 내린 ‘성공’ 의 정의를 그대로 인식하게 된다. 다른 사람들이 만든 기준으로 자신을 평가하고, 다른 사람과 나를 비교해 순위를 매기려 한다. 개인적인 목표는 오로지 우리 스스로에게 놓여 있을 뿐, 쓸데없는 평가와 비교로부터 자유로운 것이다.</li>\n  <li>열정을 다해 열심히 일하라. 단, 가장 소중한 재산인 시간을 가장 의미 있는 일에 써라. 남은 인생 동안 무엇을 하고 싶은가? 이 말은 문자 그대로 앞으로 평생 무엇을 할 것인가 라는 뜻이 아니다. 예상치 않은 사회 속에서 앞으로 평생 동안 어떤 일을 하게 될지 알 수 있는 사람이 과연 누가 있을까? 내일 갑자기 생이 끝난다면 지금까지 정말로 하고 싶은 일을 하면서 살았다고 자신 있게 말할 수 있을까? 당신은 앞으로 평생 어떤 일을 하고 싶은가? 지금 당장 그 일을 시작하려면 어떻게 해야 할까?</li>\n</ul>",
        "guid": "https://sungjk.github.io/2025/04/12/the-monk-and-the-riddle.html",
        "isoDate": "2025-04-12T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김놀부",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Lael's World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "더 똑똑해진 챗GPT o3와 o4-mini 공개 , 기존 모델과 차이는?",
        "link": "http://muzbox.tistory.com/483570",
        "pubDate": "Thu, 17 Apr 2025 08:39:33 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483570#entry483570comment",
        "content": "<p data-ke-size=\"size16\">OpenAI의 새 모델 o3와 o4-mini가 뭐길래 이렇게 화제인걸까요? 더 오래 생각하고, 도구를 사용하며, 이미지까지 이해하는 이 모델들이 AI의 미래를 어떻게 바꿀지 함께 알아보세요!  </p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"blob\" data-origin-width=\"1280\" data-origin-height=\"853\"><span data-url=\"https://blog.kakaocdn.net/dn/4B70K/btsNoPv2TY6/bQzUb4AxbrWIWdoJkwOrOk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/4B70K/btsNoPv2TY6/bQzUb4AxbrWIWdoJkwOrOk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/4B70K/btsNoPv2TY6/bQzUb4AxbrWIWdoJkwOrOk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F4B70K%2FbtsNoPv2TY6%2FbQzUb4AxbrWIWdoJkwOrOk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"더 똑똑해진 챗GPT o3와 o4-mini 공개\" loading=\"lazy\" width=\"1280\" height=\"853\" data-filename=\"blob\" data-origin-width=\"1280\" data-origin-height=\"853\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">요즘 인공지능 업계는 진짜 숨 돌릴 틈이 없는 것 같아요. 오늘은 OpenAI가 또 새로운 모델을 내놨네요. 솔직히 따라가기 벅찬 느낌이랄까요? 특히 이번에 공개된 OpenAI의 o3와 o4-mini는 정말 많은 관심을 받고 있더라고요. 근데 이게 진짜 대단한 혁신인지, 아니면 그냥 마케팅 전략인지 궁금해서 한번 자세히 들여다봤어요. 여러분도 이런 고민 한번쯤 해보셨죠?</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>o 시리즈가 뭘까? 그리고 이게 왜 중요할까?  </b></span></h2>\n<p data-ke-size=\"size16\">OpenAI의 새로운 o3와 o4-mini는 생각하는 시간을 더 길게 가지고 응답할 수 있도록 학습된 O 시리즈의 최신 모델입니다. 이 모델들은 지금까지 OpenAI가 출시한 모델 중 가장 똑똑한 모델로, ChatGPT의 기능에 큰 변화를 가져올 것으로 예상됩니다.</p>\n<p data-ke-size=\"size16\">특히 주목할 점은 이 모델들이 챗GPT 내의 모든 도구를 에이전트처럼 사용하고 결합할 수 있다는 것입니다. 여기에는 웹 검색, 업로드된 파일 및 기타 데이터를 Python으로 분석하는 기능, 시각적 입력에 대한 심층 추론, 심지어 이미지 생성까지 포함됩니다. 이건 진짜 획기적인 변화 아닐까요?  </p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 모델들은 도구를 언제, 어떻게 사용할지 추론하도록 학습되어 복잡한 문제에 대해 상세하고 사려 깊은 답변을 제공합니다. 덕분에 일반적으로 1분 이내에 더 복잡한 질문들을 효과적으로 처리할 수 있습니다. 이를 통해 다면적인 질문을 더 효과적으로 해결할 수 있게 되었고, 이는 사용자를 대신해 독립적으로 작업을 실행할 수 있는 더 에이전트형 ChatGPT를 향한 한 걸음이라고 볼 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">최첨단 추론 능력과 전체 도구 액세스의 결합된 성능은 학계 벤치마크와 실제 작업 모두에서 크게 향상된 성능으로 이어져 지능과 유용성 모두에서 새로운 표준을 세웠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>o3와 o4-mini의 차이점은 무엇일까?  </b></span></h2>\n<table style=\"border-collapse: collapse; width: 100%; margin: 15px 0;\" data-ke-align=\"alignLeft\">\n<thead>\n<tr style=\"background-color: #4a86e8; color: white;\">\n<th style=\"border: 1px solid #dddddd; text-align: center; padding: 8px; width: 13.4884%;\">모델</th>\n<th style=\"border: 1px solid #dddddd; text-align: center; padding: 8px; width: 42.3256%;\">주요 특징</th>\n<th style=\"border: 1px solid #dddddd; text-align: center; padding: 8px; width: 44.0698%;\">최적 사용 케이스</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"border: 1px solid #dddddd; text-align: left; padding: 8px; width: 13.4884%;\"><b>OpenAI o3</b></td>\n<td style=\"border: 1px solid #dddddd; text-align: left; padding: 8px; width: 42.3256%;\">가장 강력한 추론 모델, 코딩/수학/과학/시각적 인식에서 최고 성능, o1보다 20% 더 적은 오류율</td>\n<td style=\"border: 1px solid #dddddd; text-align: left; padding: 8px; width: 44.0698%;\">복잡한 다면적 분석, 이미지/차트/그래픽 분석, 프로그래밍, 비즈니스/컨설팅, 창의적 아이디어 발상</td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #dddddd; text-align: left; padding: 8px; width: 13.4884%;\"><b>OpenAI o4-mini</b></td>\n<td style=\"border: 1px solid #dddddd; text-align: left; padding: 8px; width: 42.3256%;\">빠르고 비용 효율적인 추론에 최적화, 크기와 비용 대비 뛰어난 성능, AIME 2024/2025 벤치마크 1위</td>\n<td style=\"border: 1px solid #dddddd; text-align: left; padding: 8px; width: 44.0698%;\">수학, 코딩, 시각적 작업, 데이터 과학, 고용량/고처리량 필요 작업</td>\n</tr>\n</tbody>\n</table>\n<p data-ke-size=\"size16\">OpenAI o3는 회사의 가장 강력한 추론 모델로, 코딩, 수학, 과학, 시각적 인식 등 여러 분야에서 최첨단 성능을 발휘합니다. Codeforces, SWE-bench (별도의 모델별 스캐폴드 없이), MMMU 등의 벤치마크에서 새로운 최고 성능을 기록했죠. 이 모델은 복잡한 다면적 분석이 필요하고 즉각적인 답이 명확하지 않은 복잡한 질의에 이상적입니다. 특히 이미지, 차트, 그래픽 분석과 같은 시각적 작업에서 강점을 보입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">외부 전문가들의 평가에 따르면, o3는 어려운 실제 작업에서 OpenAI o1보다 20% 더 적은 중대한 오류를 보이며, 특히 프로그래밍, 비즈니스/컨설팅, 창의적 아이디어 발상 영역에서 뛰어난 성능을 발휘합니다. 초기 테스터들은 생각의 파트너로서의 분석적 엄격함과 특히 생물학, 수학, 공학 맥락에서 새로운 가설을 생성하고 비판적으로 평가하는 능력을 강조했습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">반면에, OpenAI o4-mini는 빠르고 비용 효율적인 추론에 최적화된 더 작은 모델입니다. 크기와 비용 대비 놀라운 성능을 보이며, 특히 수학, 코딩, 시각적 작업에서 뛰어납니다. AIME 2024와 2025 벤치마크에서 가장 뛰어난 성능을 보이는 모델입니다. 전문가 평가에서도 데이터 과학과 같은 분야뿐만 아니라 비-STEM 작업에서도 이전 모델인 o3-mini보다 뛰어난 성능을 보였습니다.</p>\n<p data-ke-size=\"size16\">효율성 덕분에 o3보다 훨씬 더 높은 사용 제한을 지원하여, 추론이 필요한 질문에 대해 강력한 고용량, 고처리량 옵션이 됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>실제 성능은 어떨까?  </b></span></h2>\n<table style=\"border-collapse: collapse; width: 100%; margin: 15px 0;\" data-ke-align=\"alignLeft\">\n<thead>\n<tr style=\"background-color: #4a86e8; color: white;\">\n<th style=\"border: 1px solid #dddddd; text-align: center; padding: 8px;\">벤치마크/작업</th>\n<th style=\"border: 1px solid #dddddd; text-align: center; padding: 8px;\">o1</th>\n<th style=\"border: 1px solid #dddddd; text-align: center; padding: 8px;\">o3-mini</th>\n<th style=\"border: 1px solid #dddddd; text-align: center; padding: 8px;\">o3</th>\n<th style=\"border: 1px solid #dddddd; text-align: center; padding: 8px;\">o4-mini</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"border: 1px solid #dddddd; text-align: left; padding: 8px;\">AIME 2024 (경쟁 수학)</td>\n<td style=\"border: 1px solid #dddddd; text-align: center; padding: 8px;\">74.3%</td>\n<td style=\"border: 1px solid #dddddd; text-align: center; padding: 8px;\">87.3%</td>\n<td style=\"border: 1px solid #dddddd; text-align: center; padding: 8px;\">91.6%</td>\n<td style=\"border: 1px solid #dddddd; text-align: center; padding: 8px;\"><b>93.4%</b></td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #dddddd; text-align: left; padding: 8px;\">Codeforces (경쟁 코딩)</td>\n<td style=\"border: 1px solid #dddddd; text-align: center; padding: 8px;\">1891</td>\n<td style=\"border: 1px solid #dddddd; text-align: center; padding: 8px;\">2073</td>\n<td style=\"border: 1px solid #dddddd; text-align: center; padding: 8px;\"><b>2706</b></td>\n<td style=\"border: 1px solid #dddddd; text-align: center; padding: 8px;\">2719</td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #dddddd; text-align: left; padding: 8px;\">MMMU (대학 수준 시각적 문제 해결)</td>\n<td style=\"border: 1px solid #dddddd; text-align: center; padding: 8px;\">77.6%</td>\n<td style=\"border: 1px solid #dddddd; text-align: center; padding: 8px;\">-</td>\n<td style=\"border: 1px solid #dddddd; text-align: center; padding: 8px;\"><b>82.9%</b></td>\n<td style=\"border: 1px solid #dddddd; text-align: center; padding: 8px;\">81.6%</td>\n</tr>\n</tbody>\n</table>\n<p data-ke-size=\"size16\">벤치마크 성능을 보면 정말 놀랍습니다. 외부 전문가 평가자들은 두 모델 모두 향상된 명령 준수와 이전 모델보다 더 유용하고 검증 가능한 응답을 보여준다고 평가했습니다. 이는 향상된 지능과 웹 소스의 통합 덕분입니다. 이전 추론 모델 반복과 비교할 때, 이 두 모델은 특히 기억과 과거 대화를 참조하여 응답을 더 개인화하고 관련성을 높이는 데 있어 더 자연스럽고 대화적이라고 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">OpenAI o3는 ChatGPT 내 전체 도구 접근권과 함께 API를 통한 사용자 지정 도구에도 접근할 수 있습니다. 이 모델들은 문제 해결 방법을 추론하고, 도구를 언제, 어떻게 사용할지 선택하여 일반적으로 1분 이내에 올바른 출력 형식으로 상세하고 사려 깊은 답변을 빠르게 생성하도록 학습되었습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">예를 들어, 사용자가 \"캘리포니아의 여름 에너지 사용량이 작년과 비교하여 어떻게 될까요?\"라고 물을 수 있습니다. 이때 모델은 공공 유틸리티 데이터에 대한 웹 검색을 하고, 예측을 구축하기 위한 Python 코드를 작성하고, 그래프나 이미지를 생성한 다음, 예측 뒤에 있는 주요 요소를 설명할 수 있습니다. 이 과정에서 여러 도구 호출을 연결합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">추론을 통해 모델은 접하는 정보에 따라 필요에 따라 반응하고 방향을 전환할 수 있습니다. 예를 들어, 검색 제공업체의 도움을 받아 웹을 여러 번 검색하고, 결과를 살펴보고, 더 많은 정보가 필요한 경우 새로운 검색을 시도할 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>예를 통해 본 성능 차이  </b></span></h2>\n<p data-ke-size=\"size16\">OpenAI는 이 모델들의 뛰어난 성능을 보여주는 몇 가지 예시를 제공했습니다. o3와 o1의 성능을 비교하면 그 차이가 확연히 드러납니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">예를 들어, 복잡한 수학 문제에서 o3는 디크슨 다항식(Dickson polynomial)을 사용해 문제를 정확히 풀어내는 반면, o1은 시간이 더 걸리고 부정확한 해결책을 제시합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">또한 호텔 체인 확장에 관한 질문에서도 o3는 실제 데이터를 활용한 철저한 분석을 통해 아테네와 오사카를 목표 도시로 추천했습니다. 각 도시의 점유율, RevPAR 성장률, 승객 증가율 등 구체적인 지표와 2024년 통계자료를 바탕으로 상세한 비교 테이블까지 제공했죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">배터리 기술 발전에 관한 질문에서도 o3는 리튬 이온 배터리, 솔리드 스테이트 배터리, 나트륨 이온 배터리 등 최신 기술의 영향을 상세히 분석하며, 2011년부터 2024년까지의 전기차 주행거리, 충전 속도, 보급률 등의 변화를 그래프로 시각화해 보여주었습니다.</p>\n<p data-ke-size=\"size16\">MLB 피치 클럭 규칙이 투수 성능과 게임 시간에 미친 영향에 관한 질문에서도 o3는 구체적인 통계 데이터를 활용해 2021년부터 2024년까지의 변화를 상세히 분석했습니다. 규칙 도입 이후 게임 시간이 24분 단축됐고, 초기에는 투수들의 ERA가 상승했지만 적응 기간을 거쳐 다시 안정되었다는 흥미로운 분석을 제공했죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이런 예시들을 보면 o3와 o4-mini의 성능이 정말 인상적이라는 걸 알 수 있어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>핵심 기술적 특징  </b></span></h2>\n<table style=\"border-collapse: collapse; width: 100%; margin: 15px 0;\" data-ke-align=\"alignLeft\">\n<thead>\n<tr style=\"background-color: #4a86e8; color: white;\">\n<th style=\"border: 1px solid #dddddd; text-align: center; padding: 8px;\">기술적 혁신</th>\n<th style=\"border: 1px solid #dddddd; text-align: center; padding: 8px;\">특징</th>\n<th style=\"border: 1px solid #dddddd; text-align: center; padding: 8px;\">영향</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"border: 1px solid #dddddd; text-align: left; padding: 8px;\"><b>강화학습 확장</b></td>\n<td style=\"border: 1px solid #dddddd; text-align: left; padding: 8px;\">\"더 많은 컴퓨팅 = 더 나은 성능\" 트렌드 확인</td>\n<td style=\"border: 1px solid #dddddd; text-align: left; padding: 8px;\">더 오래 생각할수록 성능이 지속적으로 향상</td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #dddddd; text-align: left; padding: 8px;\"><b>에이전트형 도구 사용</b></td>\n<td style=\"border: 1px solid #dddddd; text-align: left; padding: 8px;\">도구를 언제, 어떻게 사용할지 추론하는 능력</td>\n<td style=\"border: 1px solid #dddddd; text-align: left; padding: 8px;\">시각적 추론, 다단계 워크플로우 처리 능력 향상</td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #dddddd; text-align: left; padding: 8px;\"><b>이미지 통합 사고</b></td>\n<td style=\"border: 1px solid #dddddd; text-align: left; padding: 8px;\">이미지를 사고 과정에 직접 통합</td>\n<td style=\"border: 1px solid #dddddd; text-align: left; padding: 8px;\">시각적, 텍스트 추론을 혼합한 새로운 문제 해결 가능</td>\n</tr>\n</tbody>\n</table>\n<p data-ke-size=\"size16\">OpenAI의 o3 개발 과정에서, 대규모 강화학습이 \"더 많은 컴퓨팅 = 더 나은 성능\"이라는 GPT 시리즈 사전 학습에서 관찰된 것과 동일한 추세를 보여주는 것으로 확인됐습니다. OpenAI는 현재 강화학습에서 이 확장 경로를 다시 따라가며, 학습 컴퓨팅과 추론 시간을 추가로 10배 증가시켰음에도 여전히 성능 향상이 명확하게 보이는 것을 확인했습니다. 이는 모델이 더 오래 생각할수록 성능이 계속 향상된다는 것을 검증합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">o3와 o4-mini는 강화학습을 통해 도구를 사용하도록 학습되었습니다. 이는 단순히 도구 사용법을 학습하는 것이 아니라, 언제 도구를 사용할지에 대해 추론하는 능력을 키웠다는 의미입니다. 원하는 결과에 따라 도구를 배치하는 능력은 특히 시각적 추론과 다단계 워크플로우를 포함하는 개방형 상황에서 더 유능하게 만듭니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이러한 개선은 학술 벤치마크와 실제 작업 모두에서 반영되어, 초기 테스터들의 보고에서도 확인됩니다.</p>\n<p data-ke-size=\"size16\">또한 이 모델들은 처음으로 이미지를 직접 사고 과정에 통합할 수 있습니다. 단순히 이미지를 보는 것이 아니라, 그것을 가지고 생각합니다. 이는 시각적 추론과 텍스트 추론을 혼합한 새로운 종류의 문제 해결을 가능하게 하며, 이는 다양한 다중모달 벤치마크에서의 최첨단 성능으로 반영됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>실생활에서의 응용 가능성  ️</b></span></h2>\n<p data-ke-size=\"size16\">이 새로운 모델들의 활용 가능성은 정말 광범위해요. 일상적인 작업부터 복잡한 비즈니스 문제, 교육, 연구까지 다양한 분야에서 활용될 수 있습니다. 예를 들어, 공공 유틸리티 데이터를 검색하고, 예측 모델을 구축하며, 결과를 시각화하는 복잡한 작업을 한 번에 처리할 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"edited_GPT O3, O4MINI.jpg\" data-origin-width=\"1000\" data-origin-height=\"668\"><span data-url=\"https://blog.kakaocdn.net/dn/86LNl/btsNn8iMy87/IKK7KcXRwKEGOZiMYkk4RK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/86LNl/btsNn8iMy87/IKK7KcXRwKEGOZiMYkk4RK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/86LNl/btsNn8iMy87/IKK7KcXRwKEGOZiMYkk4RK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F86LNl%2FbtsNn8iMy87%2FIKK7KcXRwKEGOZiMYkk4RK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"챗GPT o3, o4 mini\" loading=\"lazy\" width=\"1000\" height=\"668\" data-filename=\"edited_GPT O3, O4MINI.jpg\" data-origin-width=\"1000\" data-origin-height=\"668\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이러한 유연하고 전략적인 접근 방식을 통해 모델은 모델의 내장 지식을 넘어서는 최신 정보에 대한 접근, 확장된 추론, 합성, 여러 양식에 걸친 출력 생성이 필요한 작업을 처리할 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">특히 비즈니스 분야에서는 프로그래밍, 비즈니스/컨설팅, 창의적 아이디어 발상 영역에서 뛰어난 성능을 발휘할 것으로 기대됩니다. 또한 생각의 파트너로서의 분석적 엄격함과 특히 생물학, 수학, 공학 맥락에서 새로운 가설을 생성하고 비판적으로 평가하는 능력은 과학 연구 분야에서도 큰 도움이 될 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>앞으로의 발전 방향  </b></span></h2>\n<p data-ke-size=\"size16\">OpenAI의 o 시리즈 모델들은 인공지능의 미래를 보여주는 중요한 이정표라고 생각해요. 대규모 강화학습이 \"더 많은 컴퓨팅 = 더 나은 성능\"이라는 추세를 따른다는 사실은, 앞으로도 더 많은 컴퓨팅 파워를 투입하면 성능이 계속 향상될 수 있다는 것을 시사합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">또한 도구 사용에 대한 강화학습의 성공은 향후 AI 모델들이 더 다양한 도구를 효과적으로 활용할 수 있게 될 것임을 암시합니다. 이는 AI가 더 자율적이고 에이전트적인 역할을 할 수 있게 되는 방향으로 발전한다는 의미겠죠.</p>\n<p data-ke-size=\"size16\">시각적 추론과 텍스트 추론을 혼합한 새로운 종류의 문제 해결 능력은 앞으로 더 발전해 다양한 분야에서 혁신적인 응용을 가능하게 할 것입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1013\" data-origin-height=\"678\"><span data-url=\"https://blog.kakaocdn.net/dn/d0uCQM/btsNn923Xa9/m2efxCnY5nJuAHpUYT1o70/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/d0uCQM/btsNn923Xa9/m2efxCnY5nJuAHpUYT1o70/img.png\"><img src=\"https://blog.kakaocdn.net/dn/d0uCQM/btsNn923Xa9/m2efxCnY5nJuAHpUYT1o70/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fd0uCQM%2FbtsNn923Xa9%2Fm2efxCnY5nJuAHpUYT1o70%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"챗GPT o3와 o4-mini 성능\" loading=\"lazy\" width=\"1013\" height=\"678\" data-origin-width=\"1013\" data-origin-height=\"678\"/></span></figure>\n</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>정리해보자면...  </b></span></h2>\n<p data-ke-size=\"size16\">OpenAI의 o3와 o4-mini는 그저 작은 업데이트가 아니라 AI 기술의 중요한 도약이라고 생각해요. 최첨단 추론 능력과 전체 도구 액세스의 결합된 성능은 학계 벤치마크와 실제 작업 모두에서 크게 향상된 성능으로 이어져 지능과 유용성 모두에서 새로운 표준을 세웠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">실제 작업에서 OpenAI o1보다 20% 더 적은 중대한 오류를 보이며, 특히 프로그래밍, 비즈니스/컨설팅, 창의적 아이디어 발상 영역에서 뛰어난 성능을 발휘한다는 사실은 이 모델들이 실용적인 면에서도 큰 가치가 있음을 보여줍니다.</p>\n<p data-ke-size=\"size16\">이 모델들은 도구를 언제, 어떻게 사용할지 추론하도록 학습되어 복잡한 문제에 대해 상세하고 사려 깊은 답변을 제공합니다. 덕분에 일반적으로 1분 이내에 더 복잡한 질문들을 효과적으로 처리할 수 있습니다. 이러한 능력은 AI 보조자의 역할과 가능성을 크게 확장시킬 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">앞으로 AI 기술이 어떻게 발전할지, 그리고 우리의 삶과 일에 어떤 변화를 가져올지 정말 기대가 되네요. 여러분은 이런 새로운 AI 모델들에 대해 어떻게 생각하시나요? 댓글로 여러분의 생각을 공유해주세요!  </p>\n<hr data-ke-style=\"style1\" />\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>자주 묻는 질문 (FAQ)</b></span></h2>\n<p data-ke-size=\"size16\"><b>Q: o3와 o4-mini는 언제부터 사용할 수 있나요?</b></p>\n<p data-ke-size=\"size16\">A: 이미 출시되었으며 ChatGPT를 통해 사용할 수 있습니다.</p>\n<p data-ke-size=\"size16\"><b>Q: o3와 o4-mini의 가장 큰 차이점은 무엇인가요?</b></p>\n<p data-ke-size=\"size16\">A: O3는 더 강력한 성능을, O4-mini는 비용 효율성과 빠른 속도에 최적화되어 있습니다.</p>\n<p data-ke-size=\"size16\"><b>Q: 이 모델들은 이전 GPT 모델들과 어떻게 다른가요?</b></p>\n<p data-ke-size=\"size16\">A: 더 긴 사고 시간과 도구 사용 능력, 그리고 시각적 추론 기능이 가장 큰 차이점입니다.</p>\n<p data-ke-size=\"size16\"><b>Q: 이 모델들은 어떤 도구들을 사용할 수 있나요?</b></p>\n<p data-ke-size=\"size16\">A: 웹 검색, Python 코드 실행, 파일 분석, 이미지 생성 등 ChatGPT의 모든 도구를 사용할 수 있습니다.</p>\n<p data-ke-size=\"size16\"><b>Q: 일반 사용자들에게는 어떤 혜택이 있나요?</b></p>\n<p data-ke-size=\"size16\">A: 더 정확하고 상세한 답변, 복잡한 질문 처리 능력, 다양한 도구를 활용한 문제 해결 등이 있습니다.</p>\n<script type=\"application/ld+json\">\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [{\n    \"@type\": \"Question\",\n    \"name\": \"O3와 O4-mini는 언제부터 사용할 수 있나요?\",\n    \"acceptedAnswer\": {\n      \"@type\": \"Answer\",\n      \"text\": \"이미 출시되었으며 ChatGPT를 통해 사용할 수 있습니다.\"\n    }\n  }, {\n    \"@type\": \"Question\",\n    \"name\": \"O3와 O4-mini의 가장 큰 차이점은 무엇인가요?\",\n    \"acceptedAnswer\": {\n      \"@type\": \"Answer\",\n      \"text\": \"O3는 더 강력한 성능을, O4-mini는 비용 효율성과 빠른 속도에 최적화되어 있습니다.\"\n    }\n  }, {\n    \"@type\": \"Question\",\n    \"name\": \"이 모델들은 이전 GPT 모델들과 어떻게 다른가요?\",\n    \"acceptedAnswer\": {\n      \"@type\": \"Answer\",\n      \"text\": \"더 긴 사고 시간과 도구 사용 능력, 그리고 시각적 추론 기능이 가장 큰 차이점입니다.\"\n    }\n  }, {\n    \"@type\": \"Question\",\n    \"name\": \"이 모델들은 어떤 도구들을 사용할 수 있나요?\",\n    \"acceptedAnswer\": {\n      \"@type\": \"Answer\",\n      \"text\": \"웹 검색, Python 코드 실행, 파일 분석, 이미지 생성 등 ChatGPT의 모든 도구를 사용할 수 있습니다.\"\n    }\n  }, {\n    \"@type\": \"Question\",\n    \"name\": \"일반 사용자들에게는 어떤 혜택이 있나요?\",\n    \"acceptedAnswer\": {\n      \"@type\": \"Answer\",\n      \"text\": \"더 정확하고 상세한 답변, 복잡한 질문 처리 능력, 다양한 도구를 활용한 문제 해결 등이 있습니다.\"\n    }\n  }]\n}\n</script>",
        "contentSnippet": "OpenAI의 새 모델 o3와 o4-mini가 뭐길래 이렇게 화제인걸까요? 더 오래 생각하고, 도구를 사용하며, 이미지까지 이해하는 이 모델들이 AI의 미래를 어떻게 바꿀지 함께 알아보세요!  \n\n\n \n요즘 인공지능 업계는 진짜 숨 돌릴 틈이 없는 것 같아요. 오늘은 OpenAI가 또 새로운 모델을 내놨네요. 솔직히 따라가기 벅찬 느낌이랄까요? 특히 이번에 공개된 OpenAI의 o3와 o4-mini는 정말 많은 관심을 받고 있더라고요. 근데 이게 진짜 대단한 혁신인지, 아니면 그냥 마케팅 전략인지 궁금해서 한번 자세히 들여다봤어요. 여러분도 이런 고민 한번쯤 해보셨죠?\n \no 시리즈가 뭘까? 그리고 이게 왜 중요할까?  \nOpenAI의 새로운 o3와 o4-mini는 생각하는 시간을 더 길게 가지고 응답할 수 있도록 학습된 O 시리즈의 최신 모델입니다. 이 모델들은 지금까지 OpenAI가 출시한 모델 중 가장 똑똑한 모델로, ChatGPT의 기능에 큰 변화를 가져올 것으로 예상됩니다.\n특히 주목할 점은 이 모델들이 챗GPT 내의 모든 도구를 에이전트처럼 사용하고 결합할 수 있다는 것입니다. 여기에는 웹 검색, 업로드된 파일 및 기타 데이터를 Python으로 분석하는 기능, 시각적 입력에 대한 심층 추론, 심지어 이미지 생성까지 포함됩니다. 이건 진짜 획기적인 변화 아닐까요?  \n \n이 모델들은 도구를 언제, 어떻게 사용할지 추론하도록 학습되어 복잡한 문제에 대해 상세하고 사려 깊은 답변을 제공합니다. 덕분에 일반적으로 1분 이내에 더 복잡한 질문들을 효과적으로 처리할 수 있습니다. 이를 통해 다면적인 질문을 더 효과적으로 해결할 수 있게 되었고, 이는 사용자를 대신해 독립적으로 작업을 실행할 수 있는 더 에이전트형 ChatGPT를 향한 한 걸음이라고 볼 수 있습니다.\n \n최첨단 추론 능력과 전체 도구 액세스의 결합된 성능은 학계 벤치마크와 실제 작업 모두에서 크게 향상된 성능으로 이어져 지능과 유용성 모두에서 새로운 표준을 세웠습니다.\n \no3와 o4-mini의 차이점은 무엇일까?  \n모델\n주요 특징\n최적 사용 케이스\n\n\n\n\nOpenAI o3\n가장 강력한 추론 모델, 코딩/수학/과학/시각적 인식에서 최고 성능, o1보다 20% 더 적은 오류율\n복잡한 다면적 분석, 이미지/차트/그래픽 분석, 프로그래밍, 비즈니스/컨설팅, 창의적 아이디어 발상\n\n\nOpenAI o4-mini\n빠르고 비용 효율적인 추론에 최적화, 크기와 비용 대비 뛰어난 성능, AIME 2024/2025 벤치마크 1위\n수학, 코딩, 시각적 작업, 데이터 과학, 고용량/고처리량 필요 작업\n\n\n\nOpenAI o3는 회사의 가장 강력한 추론 모델로, 코딩, 수학, 과학, 시각적 인식 등 여러 분야에서 최첨단 성능을 발휘합니다. Codeforces, SWE-bench (별도의 모델별 스캐폴드 없이), MMMU 등의 벤치마크에서 새로운 최고 성능을 기록했죠. 이 모델은 복잡한 다면적 분석이 필요하고 즉각적인 답이 명확하지 않은 복잡한 질의에 이상적입니다. 특히 이미지, 차트, 그래픽 분석과 같은 시각적 작업에서 강점을 보입니다.\n \n외부 전문가들의 평가에 따르면, o3는 어려운 실제 작업에서 OpenAI o1보다 20% 더 적은 중대한 오류를 보이며, 특히 프로그래밍, 비즈니스/컨설팅, 창의적 아이디어 발상 영역에서 뛰어난 성능을 발휘합니다. 초기 테스터들은 생각의 파트너로서의 분석적 엄격함과 특히 생물학, 수학, 공학 맥락에서 새로운 가설을 생성하고 비판적으로 평가하는 능력을 강조했습니다.\n \n반면에, OpenAI o4-mini는 빠르고 비용 효율적인 추론에 최적화된 더 작은 모델입니다. 크기와 비용 대비 놀라운 성능을 보이며, 특히 수학, 코딩, 시각적 작업에서 뛰어납니다. AIME 2024와 2025 벤치마크에서 가장 뛰어난 성능을 보이는 모델입니다. 전문가 평가에서도 데이터 과학과 같은 분야뿐만 아니라 비-STEM 작업에서도 이전 모델인 o3-mini보다 뛰어난 성능을 보였습니다.\n효율성 덕분에 o3보다 훨씬 더 높은 사용 제한을 지원하여, 추론이 필요한 질문에 대해 강력한 고용량, 고처리량 옵션이 됩니다.\n \n실제 성능은 어떨까?  \n벤치마크/작업\no1\no3-mini\no3\no4-mini\n\n\n\n\nAIME 2024 (경쟁 수학)\n74.3%\n87.3%\n91.6%\n93.4%\n\n\nCodeforces (경쟁 코딩)\n1891\n2073\n2706\n2719\n\n\nMMMU (대학 수준 시각적 문제 해결)\n77.6%\n-\n82.9%\n81.6%\n\n\n\n벤치마크 성능을 보면 정말 놀랍습니다. 외부 전문가 평가자들은 두 모델 모두 향상된 명령 준수와 이전 모델보다 더 유용하고 검증 가능한 응답을 보여준다고 평가했습니다. 이는 향상된 지능과 웹 소스의 통합 덕분입니다. 이전 추론 모델 반복과 비교할 때, 이 두 모델은 특히 기억과 과거 대화를 참조하여 응답을 더 개인화하고 관련성을 높이는 데 있어 더 자연스럽고 대화적이라고 합니다.\n \nOpenAI o3는 ChatGPT 내 전체 도구 접근권과 함께 API를 통한 사용자 지정 도구에도 접근할 수 있습니다. 이 모델들은 문제 해결 방법을 추론하고, 도구를 언제, 어떻게 사용할지 선택하여 일반적으로 1분 이내에 올바른 출력 형식으로 상세하고 사려 깊은 답변을 빠르게 생성하도록 학습되었습니다.\n \n예를 들어, 사용자가 \"캘리포니아의 여름 에너지 사용량이 작년과 비교하여 어떻게 될까요?\"라고 물을 수 있습니다. 이때 모델은 공공 유틸리티 데이터에 대한 웹 검색을 하고, 예측을 구축하기 위한 Python 코드를 작성하고, 그래프나 이미지를 생성한 다음, 예측 뒤에 있는 주요 요소를 설명할 수 있습니다. 이 과정에서 여러 도구 호출을 연결합니다.\n \n추론을 통해 모델은 접하는 정보에 따라 필요에 따라 반응하고 방향을 전환할 수 있습니다. 예를 들어, 검색 제공업체의 도움을 받아 웹을 여러 번 검색하고, 결과를 살펴보고, 더 많은 정보가 필요한 경우 새로운 검색을 시도할 수 있습니다.\n \n예를 통해 본 성능 차이  \nOpenAI는 이 모델들의 뛰어난 성능을 보여주는 몇 가지 예시를 제공했습니다. o3와 o1의 성능을 비교하면 그 차이가 확연히 드러납니다.\n \n예를 들어, 복잡한 수학 문제에서 o3는 디크슨 다항식(Dickson polynomial)을 사용해 문제를 정확히 풀어내는 반면, o1은 시간이 더 걸리고 부정확한 해결책을 제시합니다.\n \n또한 호텔 체인 확장에 관한 질문에서도 o3는 실제 데이터를 활용한 철저한 분석을 통해 아테네와 오사카를 목표 도시로 추천했습니다. 각 도시의 점유율, RevPAR 성장률, 승객 증가율 등 구체적인 지표와 2024년 통계자료를 바탕으로 상세한 비교 테이블까지 제공했죠.\n \n배터리 기술 발전에 관한 질문에서도 o3는 리튬 이온 배터리, 솔리드 스테이트 배터리, 나트륨 이온 배터리 등 최신 기술의 영향을 상세히 분석하며, 2011년부터 2024년까지의 전기차 주행거리, 충전 속도, 보급률 등의 변화를 그래프로 시각화해 보여주었습니다.\nMLB 피치 클럭 규칙이 투수 성능과 게임 시간에 미친 영향에 관한 질문에서도 o3는 구체적인 통계 데이터를 활용해 2021년부터 2024년까지의 변화를 상세히 분석했습니다. 규칙 도입 이후 게임 시간이 24분 단축됐고, 초기에는 투수들의 ERA가 상승했지만 적응 기간을 거쳐 다시 안정되었다는 흥미로운 분석을 제공했죠.\n \n이런 예시들을 보면 o3와 o4-mini의 성능이 정말 인상적이라는 걸 알 수 있어요.\n \n핵심 기술적 특징  \n기술적 혁신\n특징\n영향\n\n\n\n\n강화학습 확장\n\"더 많은 컴퓨팅 = 더 나은 성능\" 트렌드 확인\n더 오래 생각할수록 성능이 지속적으로 향상\n\n\n에이전트형 도구 사용\n도구를 언제, 어떻게 사용할지 추론하는 능력\n시각적 추론, 다단계 워크플로우 처리 능력 향상\n\n\n이미지 통합 사고\n이미지를 사고 과정에 직접 통합\n시각적, 텍스트 추론을 혼합한 새로운 문제 해결 가능\n\n\n\nOpenAI의 o3 개발 과정에서, 대규모 강화학습이 \"더 많은 컴퓨팅 = 더 나은 성능\"이라는 GPT 시리즈 사전 학습에서 관찰된 것과 동일한 추세를 보여주는 것으로 확인됐습니다. OpenAI는 현재 강화학습에서 이 확장 경로를 다시 따라가며, 학습 컴퓨팅과 추론 시간을 추가로 10배 증가시켰음에도 여전히 성능 향상이 명확하게 보이는 것을 확인했습니다. 이는 모델이 더 오래 생각할수록 성능이 계속 향상된다는 것을 검증합니다.\n \no3와 o4-mini는 강화학습을 통해 도구를 사용하도록 학습되었습니다. 이는 단순히 도구 사용법을 학습하는 것이 아니라, 언제 도구를 사용할지에 대해 추론하는 능력을 키웠다는 의미입니다. 원하는 결과에 따라 도구를 배치하는 능력은 특히 시각적 추론과 다단계 워크플로우를 포함하는 개방형 상황에서 더 유능하게 만듭니다.\n \n이러한 개선은 학술 벤치마크와 실제 작업 모두에서 반영되어, 초기 테스터들의 보고에서도 확인됩니다.\n또한 이 모델들은 처음으로 이미지를 직접 사고 과정에 통합할 수 있습니다. 단순히 이미지를 보는 것이 아니라, 그것을 가지고 생각합니다. 이는 시각적 추론과 텍스트 추론을 혼합한 새로운 종류의 문제 해결을 가능하게 하며, 이는 다양한 다중모달 벤치마크에서의 최첨단 성능으로 반영됩니다.\n \n실생활에서의 응용 가능성  ️\n이 새로운 모델들의 활용 가능성은 정말 광범위해요. 일상적인 작업부터 복잡한 비즈니스 문제, 교육, 연구까지 다양한 분야에서 활용될 수 있습니다. 예를 들어, 공공 유틸리티 데이터를 검색하고, 예측 모델을 구축하며, 결과를 시각화하는 복잡한 작업을 한 번에 처리할 수 있습니다.\n\n\n \n이러한 유연하고 전략적인 접근 방식을 통해 모델은 모델의 내장 지식을 넘어서는 최신 정보에 대한 접근, 확장된 추론, 합성, 여러 양식에 걸친 출력 생성이 필요한 작업을 처리할 수 있습니다.\n \n특히 비즈니스 분야에서는 프로그래밍, 비즈니스/컨설팅, 창의적 아이디어 발상 영역에서 뛰어난 성능을 발휘할 것으로 기대됩니다. 또한 생각의 파트너로서의 분석적 엄격함과 특히 생물학, 수학, 공학 맥락에서 새로운 가설을 생성하고 비판적으로 평가하는 능력은 과학 연구 분야에서도 큰 도움이 될 것입니다.\n \n앞으로의 발전 방향  \nOpenAI의 o 시리즈 모델들은 인공지능의 미래를 보여주는 중요한 이정표라고 생각해요. 대규모 강화학습이 \"더 많은 컴퓨팅 = 더 나은 성능\"이라는 추세를 따른다는 사실은, 앞으로도 더 많은 컴퓨팅 파워를 투입하면 성능이 계속 향상될 수 있다는 것을 시사합니다.\n \n또한 도구 사용에 대한 강화학습의 성공은 향후 AI 모델들이 더 다양한 도구를 효과적으로 활용할 수 있게 될 것임을 암시합니다. 이는 AI가 더 자율적이고 에이전트적인 역할을 할 수 있게 되는 방향으로 발전한다는 의미겠죠.\n시각적 추론과 텍스트 추론을 혼합한 새로운 종류의 문제 해결 능력은 앞으로 더 발전해 다양한 분야에서 혁신적인 응용을 가능하게 할 것입니다.\n\n\n정리해보자면...  \nOpenAI의 o3와 o4-mini는 그저 작은 업데이트가 아니라 AI 기술의 중요한 도약이라고 생각해요. 최첨단 추론 능력과 전체 도구 액세스의 결합된 성능은 학계 벤치마크와 실제 작업 모두에서 크게 향상된 성능으로 이어져 지능과 유용성 모두에서 새로운 표준을 세웠습니다.\n \n실제 작업에서 OpenAI o1보다 20% 더 적은 중대한 오류를 보이며, 특히 프로그래밍, 비즈니스/컨설팅, 창의적 아이디어 발상 영역에서 뛰어난 성능을 발휘한다는 사실은 이 모델들이 실용적인 면에서도 큰 가치가 있음을 보여줍니다.\n이 모델들은 도구를 언제, 어떻게 사용할지 추론하도록 학습되어 복잡한 문제에 대해 상세하고 사려 깊은 답변을 제공합니다. 덕분에 일반적으로 1분 이내에 더 복잡한 질문들을 효과적으로 처리할 수 있습니다. 이러한 능력은 AI 보조자의 역할과 가능성을 크게 확장시킬 것입니다.\n \n앞으로 AI 기술이 어떻게 발전할지, 그리고 우리의 삶과 일에 어떤 변화를 가져올지 정말 기대가 되네요. 여러분은 이런 새로운 AI 모델들에 대해 어떻게 생각하시나요? 댓글로 여러분의 생각을 공유해주세요!  \n자주 묻는 질문 (FAQ)\nQ: o3와 o4-mini는 언제부터 사용할 수 있나요?\nA: 이미 출시되었으며 ChatGPT를 통해 사용할 수 있습니다.\nQ: o3와 o4-mini의 가장 큰 차이점은 무엇인가요?\nA: O3는 더 강력한 성능을, O4-mini는 비용 효율성과 빠른 속도에 최적화되어 있습니다.\nQ: 이 모델들은 이전 GPT 모델들과 어떻게 다른가요?\nA: 더 긴 사고 시간과 도구 사용 능력, 그리고 시각적 추론 기능이 가장 큰 차이점입니다.\nQ: 이 모델들은 어떤 도구들을 사용할 수 있나요?\nA: 웹 검색, Python 코드 실행, 파일 분석, 이미지 생성 등 ChatGPT의 모든 도구를 사용할 수 있습니다.\nQ: 일반 사용자들에게는 어떤 혜택이 있나요?\nA: 더 정확하고 상세한 답변, 복잡한 질문 처리 능력, 다양한 도구를 활용한 문제 해결 등이 있습니다.\n\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [{\n    \"@type\": \"Question\",\n    \"name\": \"O3와 O4-mini는 언제부터 사용할 수 있나요?\",\n    \"acceptedAnswer\": {\n      \"@type\": \"Answer\",\n      \"text\": \"이미 출시되었으며 ChatGPT를 통해 사용할 수 있습니다.\"\n    }\n  }, {\n    \"@type\": \"Question\",\n    \"name\": \"O3와 O4-mini의 가장 큰 차이점은 무엇인가요?\",\n    \"acceptedAnswer\": {\n      \"@type\": \"Answer\",\n      \"text\": \"O3는 더 강력한 성능을, O4-mini는 비용 효율성과 빠른 속도에 최적화되어 있습니다.\"\n    }\n  }, {\n    \"@type\": \"Question\",\n    \"name\": \"이 모델들은 이전 GPT 모델들과 어떻게 다른가요?\",\n    \"acceptedAnswer\": {\n      \"@type\": \"Answer\",\n      \"text\": \"더 긴 사고 시간과 도구 사용 능력, 그리고 시각적 추론 기능이 가장 큰 차이점입니다.\"\n    }\n  }, {\n    \"@type\": \"Question\",\n    \"name\": \"이 모델들은 어떤 도구들을 사용할 수 있나요?\",\n    \"acceptedAnswer\": {\n      \"@type\": \"Answer\",\n      \"text\": \"웹 검색, Python 코드 실행, 파일 분석, 이미지 생성 등 ChatGPT의 모든 도구를 사용할 수 있습니다.\"\n    }\n  }, {\n    \"@type\": \"Question\",\n    \"name\": \"일반 사용자들에게는 어떤 혜택이 있나요?\",\n    \"acceptedAnswer\": {\n      \"@type\": \"Answer\",\n      \"text\": \"더 정확하고 상세한 답변, 복잡한 질문 처리 능력, 다양한 도구를 활용한 문제 해결 등이 있습니다.\"\n    }\n  }]\n}",
        "guid": "http://muzbox.tistory.com/483570",
        "categories": [
          "AI, 미래기술/AI 챗봇 및 언어 모델",
          "AI 모델",
          "o4-mini",
          "openai o3",
          "강화학습",
          "도구 사용",
          "문제 해결",
          "벤치마크 성능",
          "시각적 추론",
          "에이전트 ai",
          "추론 능력"
        ],
        "isoDate": "2025-04-16T23:39:33.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "GPT-4.1, mini, nano 총정리: 성능, 가격, 활용법까지 한번에",
        "link": "http://muzbox.tistory.com/483569",
        "pubDate": "Wed, 16 Apr 2025 10:06:48 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483569#entry483569comment",
        "content": "<p data-ke-size=\"size16\">GPT-4.1 시리즈의 혁신적 기능과 성능 향상을 소개합니다. 코딩, 긴 컨텍스트 처리, 지시 이행 능력이 크게 개선되었고, 최초의 나노 모델까지 출시된 GPT-4.1의 모든 것을 파헤쳐볼게요!</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"edited_GPT-4.1 패밀리 총정리.jpg\" data-origin-width=\"1920\" data-origin-height=\"1080\"><span data-url=\"https://blog.kakaocdn.net/dn/bso32X/btsNmvyyFST/RQI7KTppDTErnKLy2rDZuk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bso32X/btsNmvyyFST/RQI7KTppDTErnKLy2rDZuk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bso32X/btsNmvyyFST/RQI7KTppDTErnKLy2rDZuk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbso32X%2FbtsNmvyyFST%2FRQI7KTppDTErnKLy2rDZuk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"GPT-4.1, mini, nano 총정리: 성능, 가격, 활용법까지 한번에\" loading=\"lazy\" width=\"1920\" height=\"1080\" data-filename=\"edited_GPT-4.1 패밀리 총정리.jpg\" data-origin-width=\"1920\" data-origin-height=\"1080\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">어제 정말 신기한 뉴스를 봤어요. OpenAI가 또 새로운 모델을 출시했더라고요. 요새 AI 기술이 진짜 미친 속도로 발전하는데, 그냥 따라가기도 버거울 지경이에요. 근데 이번에 나온 GPT-4.1 시리즈는 뭔가 특별해 보이더라고요. 코딩 능력이 확 좋아졌다는데, 개발자분들은 어떻게 생각하세요? 저같은 일반인한테도 도움될까요?</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>GPT-4.1 시리즈, 무엇이 달라졌을까?  </b></span></h2>\n<p data-ke-size=\"size16\">OpenAI가 API를 통해 제공하는 세 가지 새로운 모델을 소개했어요. GPT-4.1, GPT-4.1 mini, 그리고 GPT-4.1 nano까지. 이 모델들은 기존의 GPT-4o와 GPT-4o mini보다 전반적으로 더 뛰어난 성능을 보여준다고 해요. 특히 코딩과 지시사항 이행 능력에서 엄청난 발전이 있었다고 하네요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">가장 눈에 띄는 변화는 <b>컨텍스트 윈도우</b>의 크기예요. 무려 100만 토큰까지 처리할 수 있게 되었다고 해요! 이전 모델들이 128,000 토큰까지 처리할 수 있었던 것과 비교하면 정말 큰 발전이죠. 그리고 단순히 더 많은 컨텍스트를 처리하는 것뿐만 아니라, 그 컨텍스트를 더 효율적으로 이해하고 활용할 수 있게 되었다고 해요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">또한 지식 기반도 업데이트되어 2024년 6월까지의 정보를 담고 있어요. 이제 좀 더 최신 정보에 대해서도 물어볼 수 있겠네요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>코딩 능력이 대폭 향상됐어요  </b></span></h2>\n<p data-ke-size=\"size16\">제가 개인적으로 가장 흥미로웠던 부분은 코딩 능력의 향상이에요. GPT-4.1은 SWE-bench Verified에서 54.6%의 점수를 받았다고 해요. 이는 GPT-4o의 33.2%보다 무려 21.4% 포인트나 높은 점수예요!</p>\n<table style=\"width: 100%; border-collapse: collapse; margin: 20px 0;\" data-ke-align=\"alignLeft\">\n<thead>\n<tr style=\"background-color: #4285f4; color: white;\">\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: left;\">모델</th>\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">SWE-bench Verified 점수</th>\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">향상된 정도</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">GPT-4.1</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">54.6%</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">기준</td>\n</tr>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">GPT-4o</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">33.2%</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">-21.4%</td>\n</tr>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">GPT-4.5</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">38.0%</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">-16.6%</td>\n</tr>\n</tbody>\n</table>\n<p data-ke-size=\"size16\">실제 사용자들의 반응도 놀라웠어요. Windsurf라는 회사에서는 GPT-4.1이 내부 코딩 벤치마크에서 GPT-4o보다 60% 높은 점수를 받았다고 해요. 특히 도구 호출에서 30% 더 효율적이었고, 불필요한 편집을 반복할 가능성이 약 50% 낮았다고 하네요.</p>\n<p data-ke-size=\"size16\">이거 진짜 대단한 발전 아닌가요? 개발자들이 코드를 작성하고, 디버깅하는 데 훨씬 더 도움이 될 것 같아요. 제가 개발자는 아니지만, 이런 발전이 미래의 소프트웨어 개발에 어떤 영향을 미칠지 정말 궁금해요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>지시 이행 능력도 확실히 좋아졌어요  </b></span></h2>\n<p data-ke-size=\"size16\">GPT-4.1은 지시 이행 능력도 크게 향상되었어요. 특히 Format following, Negative instructions, Ordered instructions, Content requirements, Ranking, Overconfidence 등 여러 범주에서 성능이 향상되었다고 해요.</p>\n<table style=\"width: 100%; border-collapse: collapse; margin: 20px 0;\" data-ke-align=\"alignLeft\">\n<thead>\n<tr style=\"background-color: #34a853; color: white;\">\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: left;\">벤치마크</th>\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">GPT-4.1</th>\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">GPT-4o</th>\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">향상도</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">MultiChallenge</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">38.3%</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">27.8%</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">+10.5%</td>\n</tr>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">IFEval</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">87.4%</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">81.0%</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">+6.4%</td>\n</tr>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">내부 API 지시 이행 (어려운 유형)</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">49.1%</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">29.2%</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">+19.9%</td>\n</tr>\n</tbody>\n</table>\n<p data-ke-size=\"size16\">실제로 세금 관련 회사인 Blue J에서는 GPT-4.1이 내부 벤치마크에서 GPT-4o보다 53% 더 정확했다고 해요. Hex라는 회사에서는 SQL 평가 세트에서 거의 2배 향상된 성능을 보였다고 하네요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이런 개선은 복잡한 지시사항을 더 잘 따를 수 있게 해준다는 뜻이니까, 실무에서 활용도가 훨씬 높아질 것 같아요. 솔직히 말해서, 이전 모델들도 간단한 지시는 잘 따랐지만 복잡한 지시나 여러 단계의 지시는 종종 헷갈려 했잖아요? 이제 그런 문제가 많이 해결될 것 같네요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>100만 토큰의 긴 컨텍스트, 어떻게 활용할까?  </b></span></h2>\n<p data-ke-size=\"size16\">GPT-4.1 시리즈의 가장 큰 변화 중 하나는 100만 토큰의 컨텍스트 윈도우예요. 이건 React 코드베이스 전체를 8개 넣을 수 있는 양이라고 하네요. 진짜 엄청난 양이죠?</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">OpenAI는 GPT-4.1이 이 긴 컨텍스트에서 정보를 효과적으로 찾고 활용할 수 있도록 특별히 훈련시켰다고 해요. 'Needle in a Haystack' 테스트에서 GPT-4.1은 100만 토큰 안에 숨겨진 정보를 정확하게 찾아낼 수 있었다고 해요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">또 흥미로운 점은 OpenAI가 새로운 평가 방식인 OpenAI-MRCR과 Graphwalks를 공개했다는 거예요. 이 평가들은 모델이 긴 컨텍스트에서 여러 정보를 어떻게 찾고 연결하는지 테스트하는 방식이라고 해요.</p>\n<table style=\"width: 100%; border-collapse: collapse; margin: 20px 0;\" data-ke-align=\"alignLeft\">\n<thead>\n<tr style=\"background-color: #ea4335; color: white;\">\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: left;\">모델</th>\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">컨텍스트 윈도우</th>\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">OpenAI-MRCR (2 바늘) 128k</th>\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">Graphwalks bfs &lt;128k</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">GPT-4.1</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">100만 토큰</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">57.2%</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">61.7%</td>\n</tr>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">GPT-4.1 mini</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">100만 토큰</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">47.2%</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">61.7%</td>\n</tr>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">GPT-4.1 nano</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">100만 토큰</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">36.6%</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">25.0%</td>\n</tr>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">GPT-4o</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">128k 토큰</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">31.9%</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">41.7%</td>\n</tr>\n</tbody>\n</table>\n<p data-ke-size=\"size16\">실제 사용 사례도 인상적이었어요. Thomson Reuters는 GPT-4.1을 사용해 다중 문서 검토 정확도를 17% 향상시켰고, Carlyle은 매우 큰 문서에서 세부적인 재무 데이터를 추출하는 성능이 50% 향상되었다고 해요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">솔직히 말해서, 이런 긴 컨텍스트 기능은 법률, 금융, 의료 등 복잡한 문서를 다루는 분야에서 정말 혁신적인 변화를 가져올 것 같아요. 생각해보세요, 수백 페이지의 계약서나 의료 기록을 한 번에 분석할 수 있다면 얼마나 편리할까요?</p>\n<blockquote data-ke-style=\"style3\"><b> 컨텍스트</b>는 AI 모델이 대화나 질문을 이해하기 위해 고려하는 배경 정보나 이전 대화 내용을 의미해요. 쉽게 설명하자면, 사람과 대화할 때 이전에 나눈 모든 대화를 기억하고 참고하는 것과 비슷해요.</blockquote>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>비전(Vision) 능력도 강화됐어요  ️</b></span></h2>\n<p data-ke-size=\"size16\">GPT-4.1 시리즈는 이미지 이해 능력도 크게 향상되었어요. 특히 GPT-4.1 mini는 이미지 벤치마크에서 종종 GPT-4o보다 더 좋은 성능을 보여줬다고 해요.</p>\n<table style=\"width: 100%; border-collapse: collapse; margin: 20px 0;\" data-ke-align=\"alignLeft\">\n<thead>\n<tr style=\"background-color: #fbbc05; color: white;\">\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: left;\">벤치마크</th>\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">GPT-4.1</th>\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">GPT-4.1 mini</th>\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">GPT-4o</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">MMMU</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">74.8%</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">72.7%</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">68.7%</td>\n</tr>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">MathVista</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">72.2%</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">73.1%</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">61.4%</td>\n</tr>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">CharXiv-R</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">56.7%</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">56.8%</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">52.7%</td>\n</tr>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">Video-MME (자막 없음)</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">72.0%</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">-</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">65.3%</td>\n</tr>\n</tbody>\n</table>\n<p data-ke-size=\"size16\">MMMU에서 GPT-4.1은 74.8%, GPT-4.1 mini는 72.7%의 점수를 받았어요. 이는 GPT-4o의 68.7%보다 훨씬 높은 점수죠. MathVista에서도 GPT-4.1은 72.2%, GPT-4.1 mini는 73.1%로 GPT-4o의 61.4%를 크게 앞섰어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">Video-MME 테스트에서는 GPT-4.1이 72.0%의 점수를 얻어 GPT-4o의 65.3%보다 훨씬 좋은 성적을 거뒀어요. 이 테스트는 30-60분 길이의 자막 없는 비디오를 기반으로 질문에 답하는 테스트인데, 정말 인상적인 성능이죠?</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">아직 사진이나 비디오를 많이 활용하진 않지만, 앞으로는 이런 비전 능력을 활용한 애플리케이션이 더 많아질 것 같아요. 제 생각엔 교육이나 의료 분야에서 특히 유용할 것 같네요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>가격은 어떻게 변했을까?  </b></span></h2>\n<p data-ke-size=\"size16\">가격도 상당히 흥미로웠어요. OpenAI는 추론 시스템의 효율성 향상으로 GPT-4.1 시리즈의 가격을 낮출 수 있었다고 해요.</p>\n<table style=\"width: 100%; border-collapse: collapse; margin: 20px 0;\" data-ke-align=\"alignLeft\">\n<thead>\n<tr style=\"background-color: #673ab7; color: white;\">\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: left;\">모델</th>\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">입력 (100만 토큰)</th>\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">캐시된 입력 (100만 토큰)</th>\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">출력 (100만 토큰)</th>\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">혼합 가격*</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">GPT-4.1</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">$2.00</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">$0.50</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">$8.00</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">$1.84</td>\n</tr>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">GPT-4.1 mini</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">$0.40</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">$0.10</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">$1.60</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">$0.42</td>\n</tr>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">GPT-4.1 nano</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">$0.10</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">$0.025</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">$0.40</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">$0.12</td>\n</tr>\n</tbody>\n</table>\n<p style=\"font-size: 0.9em; font-style: italic;\" data-ke-size=\"size16\">*일반적인 입력/출력 및 캐시 비율 기준</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">GPT-4.1은 중간 규모 쿼리의 경우 GPT-4o보다 26% 저렴하고, GPT-4.1 nano는 가장 저렴하고 빠른 모델이라고 해요.</p>\n<p data-ke-size=\"size16\">또 하나 좋은 점은 캐시된 입력에 대한 할인이 이전의 50%에서 75%로 증가했다는 거예요. 같은 컨텍스트를 반복해서 전달하는 경우에 더 많은 비용을 절약할 수 있게 된 거죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">확실히 더 저렴해진 가격은 중소기업이나 개인 개발자들에게 큰 도움이 될 것 같아요. 특히 GPT-4.1 nano는 정말 매력적인 가격대라고 생각해요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>내가 받은 느낌은?  </b></span></h2>\n<p data-ke-size=\"size16\">이번 GPT-4.1 시리즈 발표를 보면서 정말 많은 생각이 들었어요. AI 기술이 이렇게 빠르게 발전하는 걸 보니 약간 두렵기도 하지만, 동시에 정말 기대되기도 해요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">특히 코딩 능력의 향상은 소프트웨어 개발 방식을 완전히 바꿀 수 있을 것 같아요. 개발자들이 복잡한 코드를 더 쉽게 작성하고 수정할 수 있게 되면, 더 빠르게 혁신적인 제품들이 나올 수 있겠죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">긴 컨텍스트 기능도 정말 흥미로워요. 법률 문서, 의학 연구, 학술 논문 등 긴 문서를 분석하는 데 엄청난 도움이 될 것 같아요. 이전에는 불가능했던 방식으로 정보를 처리하고 통찰력을 얻을 수 있게 될 거예요.</p>\n<p data-ke-size=\"size16\">지시 이행 능력의 향상은 AI가 더 신뢰할 수 있는 도구가 되었다는 걸 의미해요. 사용자가 원하는 정확한 결과를 더 쉽게 얻을 수 있게 되었으니까요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">하지만 여전히 몇 가지 질문도 남아있어요. 이런 강력한 AI 도구들이 사회에 어떤 영향을 미칠까요? 직업 시장은 어떻게 변할까요? 우리는 어떻게 이 기술을 책임감 있게 사용할 수 있을까요?</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>GPT-4.1 시리즈, 누구를 위한 모델일까?  </b></span></h2>\n<p data-ke-size=\"size16\">GPT-4.1 시리즈는 다양한 사용자와 사용 사례를 위해 설계되었어요.</p>\n<table style=\"width: 100%; border-collapse: collapse; margin: 20px 0;\" data-ke-align=\"alignLeft\">\n<thead>\n<tr style=\"background-color: #009688; color: white;\">\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: left;\">모델</th>\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">주요 사용자층</th>\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">주요 특징</th>\n<th style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">비용 효율성</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">GPT-4.1</td>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">최고 성능을 원하는 사용자</td>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">코딩 능력, 정확한 지시 이행, 긴 문서 분석</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">중간</td>\n</tr>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">GPT-4.1 mini</td>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">균형 잡힌 성능과 비용을 원하는 사용자</td>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">GPT-4o보다 더 좋은 성능, 지연 시간 절반</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">높음</td>\n</tr>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">GPT-4.1 nano</td>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">짧은 대기 시간이 중요한 작업</td>\n<td style=\"padding: 10px; border: 1px solid #ddd;\">분류, 자동 완성, 100만 토큰 컨텍스트</td>\n<td style=\"padding: 10px; border: 1px solid #ddd; text-align: center;\">매우 높음</td>\n</tr>\n</tbody>\n</table>\n<p data-ke-size=\"size16\">GPT-4.1은 최고의 성능을 원하는 사용자를 위한 모델이에요. 복잡한 코딩 작업, 정확한 지시 이행이 필요한 작업, 긴 문서 분석 등에 적합해요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">GPT-4.1 mini는 균형 잡힌 성능과 비용을 원하는 사용자에게 적합해요. GPT-4o보다 여러 벤치마크에서 더 좋은 성능을 보이면서도 지연 시간은 절반으로 줄고 비용은 83% 감소했다고 하니 정말 매력적이죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">GPT-4.1 nano는 짧은 대기 시간이 중요한 작업에 적합해요. 분류나 자동 완성과 같은 작업에 이상적이라고 해요. 100만 토큰의 컨텍스트 윈도우를 가지고 있으면서도 MMLU에서 80.1%, GPQA에서 50.3%의 높은 점수를 받았대요.</p>\n<p data-ke-size=\"size16\">저는 개인적으로 GPT-4.1 mini가 가성비 면에서 가장 좋은 선택일 것 같다는 생각이 들어요. 대부분의 일반적인 작업에 충분한 성능을 제공하면서도 비용은 상당히 저렴하니까요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1263\" data-origin-height=\"794\"><span data-url=\"https://blog.kakaocdn.net/dn/k8Dbg/btsNnx9IUT0/EblLfRQjlhiSN4qaUeA101/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/k8Dbg/btsNnx9IUT0/EblLfRQjlhiSN4qaUeA101/img.png\"><img src=\"https://blog.kakaocdn.net/dn/k8Dbg/btsNnx9IUT0/EblLfRQjlhiSN4qaUeA101/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fk8Dbg%2FbtsNnx9IUT0%2FEblLfRQjlhiSN4qaUeA101%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"GPT-4.1 시리즈, 무엇이 달라졌을까?\" loading=\"lazy\" width=\"1263\" height=\"794\" data-origin-width=\"1263\" data-origin-height=\"794\"/></span></figure>\n</p>\n<hr contenteditable=\"false\" data-ke-type=\"horizontalRule\" data-ke-style=\"style1\" />\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>자주 묻는 질문 (FAQ) ❓</b></span></h2>\n<p data-ke-size=\"size16\"><b>Q: GPT-4.1은 ChatGPT에서도 사용할 수 있나요?</b></p>\n<p data-ke-size=\"size16\">A: 아니요, GPT-4.1은 API를 통해서만 제공됩니다. ChatGPT에서는 지시 이행, 코딩, 지능 향상 등의 개선 사항이 GPT-4o의 최신 버전에 점진적으로 통합되고 있습니다.</p>\n<p data-ke-size=\"size16\"><b>Q: GPT-4.1의 컨텍스트 윈도우는 얼마나 큰가요?</b></p>\n<p data-ke-size=\"size16\">A: GPT-4.1, GPT-4.1 mini, GPT-4.1 nano 모두 100만 토큰의 컨텍스트 윈도우를 지원합니다.</p>\n<p data-ke-size=\"size16\"><b>Q: GPT-4.1 시리즈의 가격은 어떻게 되나요?</b></p>\n<p data-ke-size=\"size16\">A: GPT-4.1은 입력 100만 토큰당 $2, GPT-4.1 mini는 $0.40, GPT-4.1 nano는 $0.10입니다. 출력 토큰은 각각 $8, $1.60, $0.40입니다.</p>\n<p data-ke-size=\"size16\"><b>Q: GPT-4.5 Preview는 어떻게 되나요?</b></p>\n<p data-ke-size=\"size16\">A: GPT-4.5 Preview는 3개월 후인 2025년 7월 14일에 API에서 중단될 예정입니다. GPT-4.1이 더 낮은 비용과 지연 시간으로 더 좋거나 유사한 성능을 제공하기 때문입니다.</p>\n<p data-ke-size=\"size16\"><b>Q: GPT-4.1 시리즈의 지식 기반은 언제까지의 정보를 포함하고 있나요?</b></p>\n<p data-ke-size=\"size16\">A: 2024년 6월까지의 정보를 담고 있습니다.</p>\n<div style=\"margin: 0px auto; border: 2px dashed #ff5722; position: absolute; z-index: 2147483647; visibility: hidden; background-color: rgba(255, 87, 34, 0.1); left: 738px; width: 0px; top: 2092px; height: 0px;\">&nbsp;</div>\n<div style=\"z-index: 2147483647; position: absolute; visibility: hidden; padding: 5px 10px; font-size: 14px; font-family: Arial, sans-serif; color: #ffffff; background-color: #00633e; border-radius: 15px; box-shadow: rgba(0, 0, 0, 0.2) 0px 2px 5px; font-weight: bold; left: 753px; top: 2052px;\">&nbsp;</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<script type=\"application/ld+json\">\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [{\n    \"@type\": \"Question\",\n    \"name\": \"GPT-4.1은 ChatGPT에서도 사용할 수 있나요?\",\n    \"acceptedAnswer\": {\n      \"@type\": \"Answer\",\n      \"text\": \"아니요, GPT-4.1은 API를 통해서만 제공됩니다. ChatGPT에서는 지시 이행, 코딩, 지능 향상 등의 개선 사항이 GPT-4o의 최신 버전에 점진적으로 통합되고 있습니다.\"\n    }\n  }, {\n    \"@type\": \"Question\",\n    \"name\": \"GPT-4.1의 컨텍스트 윈도우는 얼마나 큰가요?\",\n    \"acceptedAnswer\": {\n      \"@type\": \"Answer\",\n      \"text\": \"GPT-4.1, GPT-4.1 mini, GPT-4.1 nano 모두 100만 토큰의 컨텍스트 윈도우를 지원합니다.\"\n    }\n  }, {\n    \"@type\": \"Question\",\n    \"name\": \"GPT-4.1 시리즈의 가격은 어떻게 되나요?\",\n    \"acceptedAnswer\": {\n      \"@type\": \"Answer\",\n      \"text\": \"GPT-4.1은 입력 100만 토큰당 $2, GPT-4.1 mini는 $0.40, GPT-4.1 nano는 $0.10입니다. 출력 토큰은 각각 $8, $1.60, $0.40입니다.\"\n    }\n  }, {\n    \"@type\": \"Question\",\n    \"name\": \"GPT-4.5 Preview는 어떻게 되나요?\",\n    \"acceptedAnswer\": {\n      \"@type\": \"Answer\",\n      \"text\": \"GPT-4.5 Preview는 3개월 후인 2025년 7월 14일에 API에서 중단될 예정입니다. GPT-4.1이 더 낮은 비용과 지연 시간으로 더 좋거나 유사한 성능을 제공하기 때문입니다.\"\n    }\n  }, {\n    \"@type\": \"Question\",\n    \"name\": \"GPT-4.1 시리즈의 지식 기반은 언제까지의 정보를 포함하고 있나요?\",\n    \"acceptedAnswer\": {\n      \"@type\": \"Answer\",\n      \"text\": \"2024년 6월까지의 정보를 담고 있습니다.\"\n    }\n  }]\n}\n</script>",
        "contentSnippet": "GPT-4.1 시리즈의 혁신적 기능과 성능 향상을 소개합니다. 코딩, 긴 컨텍스트 처리, 지시 이행 능력이 크게 개선되었고, 최초의 나노 모델까지 출시된 GPT-4.1의 모든 것을 파헤쳐볼게요!\n\n\n \n어제 정말 신기한 뉴스를 봤어요. OpenAI가 또 새로운 모델을 출시했더라고요. 요새 AI 기술이 진짜 미친 속도로 발전하는데, 그냥 따라가기도 버거울 지경이에요. 근데 이번에 나온 GPT-4.1 시리즈는 뭔가 특별해 보이더라고요. 코딩 능력이 확 좋아졌다는데, 개발자분들은 어떻게 생각하세요? 저같은 일반인한테도 도움될까요?\n \nGPT-4.1 시리즈, 무엇이 달라졌을까?  \nOpenAI가 API를 통해 제공하는 세 가지 새로운 모델을 소개했어요. GPT-4.1, GPT-4.1 mini, 그리고 GPT-4.1 nano까지. 이 모델들은 기존의 GPT-4o와 GPT-4o mini보다 전반적으로 더 뛰어난 성능을 보여준다고 해요. 특히 코딩과 지시사항 이행 능력에서 엄청난 발전이 있었다고 하네요.\n \n가장 눈에 띄는 변화는 컨텍스트 윈도우의 크기예요. 무려 100만 토큰까지 처리할 수 있게 되었다고 해요! 이전 모델들이 128,000 토큰까지 처리할 수 있었던 것과 비교하면 정말 큰 발전이죠. 그리고 단순히 더 많은 컨텍스트를 처리하는 것뿐만 아니라, 그 컨텍스트를 더 효율적으로 이해하고 활용할 수 있게 되었다고 해요.\n \n또한 지식 기반도 업데이트되어 2024년 6월까지의 정보를 담고 있어요. 이제 좀 더 최신 정보에 대해서도 물어볼 수 있겠네요.\n \n코딩 능력이 대폭 향상됐어요  \n제가 개인적으로 가장 흥미로웠던 부분은 코딩 능력의 향상이에요. GPT-4.1은 SWE-bench Verified에서 54.6%의 점수를 받았다고 해요. 이는 GPT-4o의 33.2%보다 무려 21.4% 포인트나 높은 점수예요!\n모델\nSWE-bench Verified 점수\n향상된 정도\n\n\n\n\nGPT-4.1\n54.6%\n기준\n\n\nGPT-4o\n33.2%\n-21.4%\n\n\nGPT-4.5\n38.0%\n-16.6%\n\n\n\n실제 사용자들의 반응도 놀라웠어요. Windsurf라는 회사에서는 GPT-4.1이 내부 코딩 벤치마크에서 GPT-4o보다 60% 높은 점수를 받았다고 해요. 특히 도구 호출에서 30% 더 효율적이었고, 불필요한 편집을 반복할 가능성이 약 50% 낮았다고 하네요.\n이거 진짜 대단한 발전 아닌가요? 개발자들이 코드를 작성하고, 디버깅하는 데 훨씬 더 도움이 될 것 같아요. 제가 개발자는 아니지만, 이런 발전이 미래의 소프트웨어 개발에 어떤 영향을 미칠지 정말 궁금해요.\n \n지시 이행 능력도 확실히 좋아졌어요  \nGPT-4.1은 지시 이행 능력도 크게 향상되었어요. 특히 Format following, Negative instructions, Ordered instructions, Content requirements, Ranking, Overconfidence 등 여러 범주에서 성능이 향상되었다고 해요.\n벤치마크\nGPT-4.1\nGPT-4o\n향상도\n\n\n\n\nMultiChallenge\n38.3%\n27.8%\n+10.5%\n\n\nIFEval\n87.4%\n81.0%\n+6.4%\n\n\n내부 API 지시 이행 (어려운 유형)\n49.1%\n29.2%\n+19.9%\n\n\n\n실제로 세금 관련 회사인 Blue J에서는 GPT-4.1이 내부 벤치마크에서 GPT-4o보다 53% 더 정확했다고 해요. Hex라는 회사에서는 SQL 평가 세트에서 거의 2배 향상된 성능을 보였다고 하네요.\n \n이런 개선은 복잡한 지시사항을 더 잘 따를 수 있게 해준다는 뜻이니까, 실무에서 활용도가 훨씬 높아질 것 같아요. 솔직히 말해서, 이전 모델들도 간단한 지시는 잘 따랐지만 복잡한 지시나 여러 단계의 지시는 종종 헷갈려 했잖아요? 이제 그런 문제가 많이 해결될 것 같네요.\n \n100만 토큰의 긴 컨텍스트, 어떻게 활용할까?  \nGPT-4.1 시리즈의 가장 큰 변화 중 하나는 100만 토큰의 컨텍스트 윈도우예요. 이건 React 코드베이스 전체를 8개 넣을 수 있는 양이라고 하네요. 진짜 엄청난 양이죠?\n \nOpenAI는 GPT-4.1이 이 긴 컨텍스트에서 정보를 효과적으로 찾고 활용할 수 있도록 특별히 훈련시켰다고 해요. 'Needle in a Haystack' 테스트에서 GPT-4.1은 100만 토큰 안에 숨겨진 정보를 정확하게 찾아낼 수 있었다고 해요.\n \n또 흥미로운 점은 OpenAI가 새로운 평가 방식인 OpenAI-MRCR과 Graphwalks를 공개했다는 거예요. 이 평가들은 모델이 긴 컨텍스트에서 여러 정보를 어떻게 찾고 연결하는지 테스트하는 방식이라고 해요.\n모델\n컨텍스트 윈도우\nOpenAI-MRCR (2 바늘) 128k\nGraphwalks bfs <128k\n\n\n\n\nGPT-4.1\n100만 토큰\n57.2%\n61.7%\n\n\nGPT-4.1 mini\n100만 토큰\n47.2%\n61.7%\n\n\nGPT-4.1 nano\n100만 토큰\n36.6%\n25.0%\n\n\nGPT-4o\n128k 토큰\n31.9%\n41.7%\n\n\n\n실제 사용 사례도 인상적이었어요. Thomson Reuters는 GPT-4.1을 사용해 다중 문서 검토 정확도를 17% 향상시켰고, Carlyle은 매우 큰 문서에서 세부적인 재무 데이터를 추출하는 성능이 50% 향상되었다고 해요.\n \n솔직히 말해서, 이런 긴 컨텍스트 기능은 법률, 금융, 의료 등 복잡한 문서를 다루는 분야에서 정말 혁신적인 변화를 가져올 것 같아요. 생각해보세요, 수백 페이지의 계약서나 의료 기록을 한 번에 분석할 수 있다면 얼마나 편리할까요?\n 컨텍스트는 AI 모델이 대화나 질문을 이해하기 위해 고려하는 배경 정보나 이전 대화 내용을 의미해요. 쉽게 설명하자면, 사람과 대화할 때 이전에 나눈 모든 대화를 기억하고 참고하는 것과 비슷해요.\n \n비전(Vision) 능력도 강화됐어요  ️\nGPT-4.1 시리즈는 이미지 이해 능력도 크게 향상되었어요. 특히 GPT-4.1 mini는 이미지 벤치마크에서 종종 GPT-4o보다 더 좋은 성능을 보여줬다고 해요.\n벤치마크\nGPT-4.1\nGPT-4.1 mini\nGPT-4o\n\n\n\n\nMMMU\n74.8%\n72.7%\n68.7%\n\n\nMathVista\n72.2%\n73.1%\n61.4%\n\n\nCharXiv-R\n56.7%\n56.8%\n52.7%\n\n\nVideo-MME (자막 없음)\n72.0%\n-\n65.3%\n\n\n\nMMMU에서 GPT-4.1은 74.8%, GPT-4.1 mini는 72.7%의 점수를 받았어요. 이는 GPT-4o의 68.7%보다 훨씬 높은 점수죠. MathVista에서도 GPT-4.1은 72.2%, GPT-4.1 mini는 73.1%로 GPT-4o의 61.4%를 크게 앞섰어요.\n \nVideo-MME 테스트에서는 GPT-4.1이 72.0%의 점수를 얻어 GPT-4o의 65.3%보다 훨씬 좋은 성적을 거뒀어요. 이 테스트는 30-60분 길이의 자막 없는 비디오를 기반으로 질문에 답하는 테스트인데, 정말 인상적인 성능이죠?\n \n아직 사진이나 비디오를 많이 활용하진 않지만, 앞으로는 이런 비전 능력을 활용한 애플리케이션이 더 많아질 것 같아요. 제 생각엔 교육이나 의료 분야에서 특히 유용할 것 같네요.\n \n가격은 어떻게 변했을까?  \n가격도 상당히 흥미로웠어요. OpenAI는 추론 시스템의 효율성 향상으로 GPT-4.1 시리즈의 가격을 낮출 수 있었다고 해요.\n모델\n입력 (100만 토큰)\n캐시된 입력 (100만 토큰)\n출력 (100만 토큰)\n혼합 가격*\n\n\n\n\nGPT-4.1\n$2.00\n$0.50\n$8.00\n$1.84\n\n\nGPT-4.1 mini\n$0.40\n$0.10\n$1.60\n$0.42\n\n\nGPT-4.1 nano\n$0.10\n$0.025\n$0.40\n$0.12\n\n\n\n*일반적인 입력/출력 및 캐시 비율 기준\n \nGPT-4.1은 중간 규모 쿼리의 경우 GPT-4o보다 26% 저렴하고, GPT-4.1 nano는 가장 저렴하고 빠른 모델이라고 해요.\n또 하나 좋은 점은 캐시된 입력에 대한 할인이 이전의 50%에서 75%로 증가했다는 거예요. 같은 컨텍스트를 반복해서 전달하는 경우에 더 많은 비용을 절약할 수 있게 된 거죠.\n \n확실히 더 저렴해진 가격은 중소기업이나 개인 개발자들에게 큰 도움이 될 것 같아요. 특히 GPT-4.1 nano는 정말 매력적인 가격대라고 생각해요.\n \n내가 받은 느낌은?  \n이번 GPT-4.1 시리즈 발표를 보면서 정말 많은 생각이 들었어요. AI 기술이 이렇게 빠르게 발전하는 걸 보니 약간 두렵기도 하지만, 동시에 정말 기대되기도 해요.\n \n특히 코딩 능력의 향상은 소프트웨어 개발 방식을 완전히 바꿀 수 있을 것 같아요. 개발자들이 복잡한 코드를 더 쉽게 작성하고 수정할 수 있게 되면, 더 빠르게 혁신적인 제품들이 나올 수 있겠죠.\n \n긴 컨텍스트 기능도 정말 흥미로워요. 법률 문서, 의학 연구, 학술 논문 등 긴 문서를 분석하는 데 엄청난 도움이 될 것 같아요. 이전에는 불가능했던 방식으로 정보를 처리하고 통찰력을 얻을 수 있게 될 거예요.\n지시 이행 능력의 향상은 AI가 더 신뢰할 수 있는 도구가 되었다는 걸 의미해요. 사용자가 원하는 정확한 결과를 더 쉽게 얻을 수 있게 되었으니까요.\n \n하지만 여전히 몇 가지 질문도 남아있어요. 이런 강력한 AI 도구들이 사회에 어떤 영향을 미칠까요? 직업 시장은 어떻게 변할까요? 우리는 어떻게 이 기술을 책임감 있게 사용할 수 있을까요?\n \nGPT-4.1 시리즈, 누구를 위한 모델일까?  \nGPT-4.1 시리즈는 다양한 사용자와 사용 사례를 위해 설계되었어요.\n모델\n주요 사용자층\n주요 특징\n비용 효율성\n\n\n\n\nGPT-4.1\n최고 성능을 원하는 사용자\n코딩 능력, 정확한 지시 이행, 긴 문서 분석\n중간\n\n\nGPT-4.1 mini\n균형 잡힌 성능과 비용을 원하는 사용자\nGPT-4o보다 더 좋은 성능, 지연 시간 절반\n높음\n\n\nGPT-4.1 nano\n짧은 대기 시간이 중요한 작업\n분류, 자동 완성, 100만 토큰 컨텍스트\n매우 높음\n\n\n\nGPT-4.1은 최고의 성능을 원하는 사용자를 위한 모델이에요. 복잡한 코딩 작업, 정확한 지시 이행이 필요한 작업, 긴 문서 분석 등에 적합해요.\n \nGPT-4.1 mini는 균형 잡힌 성능과 비용을 원하는 사용자에게 적합해요. GPT-4o보다 여러 벤치마크에서 더 좋은 성능을 보이면서도 지연 시간은 절반으로 줄고 비용은 83% 감소했다고 하니 정말 매력적이죠.\n \nGPT-4.1 nano는 짧은 대기 시간이 중요한 작업에 적합해요. 분류나 자동 완성과 같은 작업에 이상적이라고 해요. 100만 토큰의 컨텍스트 윈도우를 가지고 있으면서도 MMLU에서 80.1%, GPQA에서 50.3%의 높은 점수를 받았대요.\n저는 개인적으로 GPT-4.1 mini가 가성비 면에서 가장 좋은 선택일 것 같다는 생각이 들어요. 대부분의 일반적인 작업에 충분한 성능을 제공하면서도 비용은 상당히 저렴하니까요.\n \n\n\n\n자주 묻는 질문 (FAQ) ❓\nQ: GPT-4.1은 ChatGPT에서도 사용할 수 있나요?\nA: 아니요, GPT-4.1은 API를 통해서만 제공됩니다. ChatGPT에서는 지시 이행, 코딩, 지능 향상 등의 개선 사항이 GPT-4o의 최신 버전에 점진적으로 통합되고 있습니다.\nQ: GPT-4.1의 컨텍스트 윈도우는 얼마나 큰가요?\nA: GPT-4.1, GPT-4.1 mini, GPT-4.1 nano 모두 100만 토큰의 컨텍스트 윈도우를 지원합니다.\nQ: GPT-4.1 시리즈의 가격은 어떻게 되나요?\nA: GPT-4.1은 입력 100만 토큰당 $2, GPT-4.1 mini는 $0.40, GPT-4.1 nano는 $0.10입니다. 출력 토큰은 각각 $8, $1.60, $0.40입니다.\nQ: GPT-4.5 Preview는 어떻게 되나요?\nA: GPT-4.5 Preview는 3개월 후인 2025년 7월 14일에 API에서 중단될 예정입니다. GPT-4.1이 더 낮은 비용과 지연 시간으로 더 좋거나 유사한 성능을 제공하기 때문입니다.\nQ: GPT-4.1 시리즈의 지식 기반은 언제까지의 정보를 포함하고 있나요?\nA: 2024년 6월까지의 정보를 담고 있습니다.\n \n \n \n\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [{\n    \"@type\": \"Question\",\n    \"name\": \"GPT-4.1은 ChatGPT에서도 사용할 수 있나요?\",\n    \"acceptedAnswer\": {\n      \"@type\": \"Answer\",\n      \"text\": \"아니요, GPT-4.1은 API를 통해서만 제공됩니다. ChatGPT에서는 지시 이행, 코딩, 지능 향상 등의 개선 사항이 GPT-4o의 최신 버전에 점진적으로 통합되고 있습니다.\"\n    }\n  }, {\n    \"@type\": \"Question\",\n    \"name\": \"GPT-4.1의 컨텍스트 윈도우는 얼마나 큰가요?\",\n    \"acceptedAnswer\": {\n      \"@type\": \"Answer\",\n      \"text\": \"GPT-4.1, GPT-4.1 mini, GPT-4.1 nano 모두 100만 토큰의 컨텍스트 윈도우를 지원합니다.\"\n    }\n  }, {\n    \"@type\": \"Question\",\n    \"name\": \"GPT-4.1 시리즈의 가격은 어떻게 되나요?\",\n    \"acceptedAnswer\": {\n      \"@type\": \"Answer\",\n      \"text\": \"GPT-4.1은 입력 100만 토큰당 $2, GPT-4.1 mini는 $0.40, GPT-4.1 nano는 $0.10입니다. 출력 토큰은 각각 $8, $1.60, $0.40입니다.\"\n    }\n  }, {\n    \"@type\": \"Question\",\n    \"name\": \"GPT-4.5 Preview는 어떻게 되나요?\",\n    \"acceptedAnswer\": {\n      \"@type\": \"Answer\",\n      \"text\": \"GPT-4.5 Preview는 3개월 후인 2025년 7월 14일에 API에서 중단될 예정입니다. GPT-4.1이 더 낮은 비용과 지연 시간으로 더 좋거나 유사한 성능을 제공하기 때문입니다.\"\n    }\n  }, {\n    \"@type\": \"Question\",\n    \"name\": \"GPT-4.1 시리즈의 지식 기반은 언제까지의 정보를 포함하고 있나요?\",\n    \"acceptedAnswer\": {\n      \"@type\": \"Answer\",\n      \"text\": \"2024년 6월까지의 정보를 담고 있습니다.\"\n    }\n  }]\n}",
        "guid": "http://muzbox.tistory.com/483569",
        "categories": [
          "AI, 미래기술/AI 챗봇 및 언어 모델",
          "AI 개발",
          "gpt-4.1",
          "gpt-4.1 mini",
          "gpt-4.1 nano",
          "OpenAI",
          "긴 컨텍스트",
          "인공지능",
          "지시 이행",
          "컨텍스트 윈도우",
          "코딩 능력"
        ],
        "isoDate": "2025-04-16T01:06:48.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "ChatGPT의 GPT-4o 이미지 생성, DALL-E를 어떻게 뛰어넘었나?",
        "link": "http://muzbox.tistory.com/483568",
        "pubDate": "Tue, 15 Apr 2025 08:42:07 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483568#entry483568comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;ChatGPT의 GPT-4o 이미지 생성 기능의 혁신적인 변화! DALL-E와는 무엇이 다른지, 실제 사용해보니 드러난 장단점과 창작계에 미칠 파장까지. AI 이미지 생성의 새 시대가 열렸다고? 디자이너라면 꼭 알아야 할 모든 것.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"blob\" data-origin-width=\"1280\" data-origin-height=\"853\"><span data-url=\"https://blog.kakaocdn.net/dn/beQ5vI/btsNhu8ooKq/CucFTaHTYCcozipDc2eF1K/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/beQ5vI/btsNhu8ooKq/CucFTaHTYCcozipDc2eF1K/img.png\"><img src=\"https://blog.kakaocdn.net/dn/beQ5vI/btsNhu8ooKq/CucFTaHTYCcozipDc2eF1K/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbeQ5vI%2FbtsNhu8ooKq%2FCucFTaHTYCcozipDc2eF1K%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"ChatGPT의 GPT-4o 이미지 생성, DALL-E를 어떻게 뛰어넘었나?\" loading=\"lazy\" width=\"1280\" height=\"853\" data-filename=\"blob\" data-origin-width=\"1280\" data-origin-height=\"853\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">요즘 들어 SNS를 보면 지브리풍 일러스트부터 놀라울 정도로 사실적인 사진까지, 모두 ChatGPT로 만들었다는 이미지들이 넘쳐나고 있어요. \"뭐야, ChatGPT도 이제 이미지를 만들어?\" 라고 생각하시는 분들 많으실 텐데요. 네, 맞습니다. 2025년 3월 26일, OpenAI가 GPT-4o를 출시하면서 DALL-E를 대체하는 이미지 생성 기능을 통합했거든요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">저는 디자인 분야에서 일하다 보니 미드저니, 스테이블 디퓨전부터 DALL-E까지 거의 모든 AI 이미지 생성 도구를 업무에 활용해왔는데요. GPT-4o의 이미지 생성 기능을 처음 접했을 때는 정말 놀랐어요. 왜 그랬는지, 그리고 이 변화가 우리에게 어떤 의미인지 함께 알아볼까요?</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>DALL-E에서 GPT-4o로, 무엇이 바뀌었나?  </b></span></h2>\n<p data-ke-size=\"size16\">이전까지 ChatGPT에서 이미지를 생성하려면 별도의 DALL-E 모델을 호출해야 했어요. 대화하다가 \"이 설명을 이미지로 만들어줘\"라고 하면 모드 전환이 일어나면서 DALL-E가 작동했죠. 하지만 이제는 GPT-4o 하나로 대화와 이미지 생성이 모두 가능해졌어요.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">주요 변화점  </span></h3>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>통합된 사용자 경험</b> - 대화 흐름 중에 자연스럽게 이미지 생성이 가능해졌어요. 모드 전환 없이 대화하듯 이미지를 요청하면 바로 만들어줍니다.</li>\n<li><b>향상된 응답 속도</b> - DALL-E는 이미지 생성에 10-20초가 걸렸는데, GPT-4o는 대략 절반 정도로 시간이 단축됐어요.</li>\n<li><b>텍스트 렌더링 성능 향상</b> - 이전 DALL-E의 큰 약점 중 하나가 이미지 속 텍스트 처리였는데, GPT-4o는 이 부분이 획기적으로 개선되었어요. 포스터나 책 표지 같은 텍스트가 포함된 이미지 생성이 훨씬 정확해졌답니다.</li>\n<li><b>스타일 일관성</b> - 다양한 예술 스타일을 요청했을 때 일관된 퀄리티를 유지하는 능력이 향상되었어요. 특히 '지브리풍'으로 유명해진 애니메이션 스타일 구현이 뛰어나죠.</li>\n</ol>\n<p data-ke-size=\"size16\">솔직히 말하자면, 순수하게 사진 같은 사실적 이미지만 놓고 보면 기존 DALL-E가 약간 더 나은 경우도 있었어요. 하지만 전반적인 성능과 사용성은 GPT-4o가 훨씬 뛰어납니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>실제 사용해보니 느낀 GPT-4o 이미지 생성의 강점  </b></span></h2>\n<p data-ke-size=\"size16\">실제로 제가 업무에 활용해보니 GPT-4o의 강점이 확실히 드러나더라고요.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">1. 맥락 이해 능력</span></h3>\n<p data-ke-size=\"size16\">제가 가장 놀란 부분은 대화 맥락을 기반으로 이미지를 생성한다는 점이에요. 예를 들어, 로고 디자인에 대해 길게 대화를 나눈 후 \"이걸 이미지로 만들어줘\"라고 하면 이전 대화 내용을 모두 고려한 이미지를 만들어줍니다. DALL-E는 그냥 그 한 문장만 고려했죠.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">2. 디테일 컨트롤</span></h3>\n<p data-ke-size=\"size16\">\"조금 더 밝게\", \"왼쪽 캐릭터의 표정을 더 행복하게\" 같은 세부 수정 요청에 훨씬 더 정확하게 반응해요. 이전에는 비슷한 프롬프트로 처음부터 다시 생성하는 경우가 많았는데, GPT-4o는 원하는 부분만 정확히 수정해주는 경우가 많아요.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">3. 텍스트와 이미지의 완벽한 조화</span></h3>\n<p data-ke-size=\"size16\">포스터나 인포그래픽처럼 텍스트가 포함된 이미지를 만들 때 정말 빛을 발해요. DALL-E에서는 \"Happy Birthday\"라는 간단한 문구조차 \"Ha9py Birtиday\" 같은 이상한 글자로 나오는 경우가 많았는데, GPT-4o는 거의 완벽하게 텍스트를 렌더링합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>아직 아쉬운 점들  </b></span></h2>\n<p data-ke-size=\"size16\">물론 완벽하진 않아요. 제가 실제 사용하면서 느낀 한계점도 있습니다:</p>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>복잡한 구도의 한계</b> - 여러 사람이 특정 동작을 취하고 있는 복잡한 장면을 요청하면 여전히 손이나 발이 이상하게 나오는 경우가 있어요.</li>\n<li><b>해상도 제한</b> - 현재 생성되는 이미지의 해상도가 제한적이라 고품질 인쇄물용으로 사용하기엔 부족해요.</li>\n<li><b>스타일 제한</b> - 특정 작가나 브랜드의 스타일을 정확하게 모방하는 데는 여전히 한계가 있습니다.</li>\n</ol>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>이 변화가 창작 산업에 미칠 영향  </b></span></h2>\n<p data-ke-size=\"size16\">GPT-4o의 이미지 생성 기능은 단순한 기술적 발전을 넘어 창작 방식 자체를 바꿀 잠재력이 있어요. 이제 누구나 쉽게 자신의 아이디어를 시각화할 수 있게 되었으니까요.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">디자이너와 일러스트레이터에게는?</span></h3>\n<p data-ke-size=\"size16\">솔직히 말해서, 불안함을 느끼는 디자이너분들 많으실 거예요. 하지만 저는 이걸 위협보다는 도구로 봐야 한다고 생각해요. 디자인 초안을 빠르게 만들거나, 클라이언트와 소통하는 과정에서 아이디어를 시각화하는 데 정말 유용하거든요.</p>\n<p data-ke-size=\"size16\">실제로 저는 로고 디자인 작업할 때 클라이언트에게 다양한 방향성을 빠르게 제시하기 위해 GPT-4o를 활용하고 있어요. 물론 최종 결과물은 직접 다듬지만, 아이디어 발상 과정이 훨씬 효율적으로 바뀌었답니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">마케팅과 콘텐츠 제작에는?</span></h3>\n<p data-ke-size=\"size16\">SNS 마케팅이나 블로그 콘텐츠 제작자들에게는 정말 혁명적인 변화에요. 이제 디자이너 없이도 괜찮은 퀄리티의 이미지를 즉석에서 만들 수 있으니까요. 특히 텍스트 렌더링이 개선되어 광고나 프로모션 이미지 제작이 훨씬 쉬워졌어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>GPT-4o 이미지 생성, 어떻게 활용해야 할까?  </b></span></h2>\n<p data-ke-size=\"size16\">제가 실제로 GPT-4o 이미지 생성을 활용하면서 터득한 팁을 몇 가지 공유할게요:</p>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>맥락이 풍부한 프롬프트 작성하기</b> - 단순히 \"고양이 그림\"보다는 \"푸른 하늘 아래 햇살을 받으며 창가에 앉아있는 티베트산 하얀 고양이, 스튜디오 조명, 소니 A7 카메라로 촬영한 느낌\"처럼 구체적으로 설명하세요.</li>\n<li><b>대화 맥락 활용하기</b> - 이미지를 생성하기 전에 원하는 스타일이나 분위기에 대해 충분히 설명하면 더 좋은 결과물을 얻을 수 있어요.</li>\n<li><b>반복 생성으로 완성도 높이기</b> - 첫 결과물에 만족하지 못했다면 \"이 이미지에서 배경을 더 밝게, 인물의 표정을 더 행복하게 수정해줘\"처럼 구체적인 피드백을 주세요.</li>\n<li><b>텍스트 활용하기</b> - GPT-4o는 텍스트 렌더링이 강점이니 포스터, 책 표지, 로고 등 텍스트가 포함된 이미지 생성에 적극 활용해보세요.</li>\n</ol>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"blob\" data-origin-width=\"866\" data-origin-height=\"486\"><span data-url=\"https://blog.kakaocdn.net/dn/Hb7rL/btsNlgBaU4F/E9DvsnoyK3BIXSZdfToNnk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Hb7rL/btsNlgBaU4F/E9DvsnoyK3BIXSZdfToNnk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/Hb7rL/btsNlgBaU4F/E9DvsnoyK3BIXSZdfToNnk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FHb7rL%2FbtsNlgBaU4F%2FE9DvsnoyK3BIXSZdfToNnk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"ChatGPT의 GPT-4o 이미지 생성 시대\" loading=\"lazy\" width=\"866\" height=\"486\" data-filename=\"blob\" data-origin-width=\"866\" data-origin-height=\"486\"/></span></figure>\n</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>결론: 창작의 민주화가 시작됐다  </b></span></h2>\n<p data-ke-size=\"size16\">GPT-4o의 이미지 생성 기능은 DALL-E를 단순히 대체한 것이 아니라, AI 이미지 생성의 패러다임 자체를 바꾸고 있어요. 기술적으로는 더 정교해졌고, 사용자 경험 측면에서는 훨씬 더 접근성이 높아졌죠.</p>\n<p data-ke-size=\"size16\">물론 전문 디자이너나 사진작가의 창의적 작업을 완전히 대체하진 못하겠지만, 창작의 문턱을 크게 낮췄다는 점은 분명해요. 이제 \"난 그림을 못 그려\"라는 말은 더 이상 변명이 되지 않을지도 모르겠네요.</p>\n<p data-ke-size=\"size16\">여러분도 GPT-4o의 이미지 생성 기능을 사용해보셨나요? 어떤 경험을 하셨는지, 또 어떻게 활용하고 계신지 댓글로 공유해주세요!  </p>\n<hr contenteditable=\"false\" data-ke-type=\"horizontalRule\" data-ke-style=\"style1\" />\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>자주 묻는 질문  </b></span></h2>\n<p data-ke-size=\"size16\"><b>Q: GPT-4o로 생성한 이미지의 저작권은 누구에게 있나요?</b></p>\n<p data-ke-size=\"size16\">A: OpenAI의 정책에 따르면 생성된 이미지의 저작권은 사용자에게 있습니다. 상업적 용도로도 사용 가능해요.</p>\n<p data-ke-size=\"size16\"><b>Q: GPT-4o 이미지 생성은 무료인가요?</b></p>\n<p data-ke-size=\"size16\">A: ChatGPT Plus나 Team, Enterprise 구독자에게 제공되며, 무료 사용자는 제한된 수의 이미지만 생성할 수 있습니다.</p>\n<p data-ke-size=\"size16\"><b>Q: DALL-E는 이제 완전히 사라진 건가요?</b></p>\n<p data-ke-size=\"size16\">A: 네, 2025년 3월 26일부터 DALL-E는 GPT-4o의 이미지 생성 기능으로 자연스럽게 대체되었습니다.</p>\n<p data-ke-size=\"size16\"><b>Q: 생성된 이미지를 편집할 수 있나요?</b></p>\n<p data-ke-size=\"size16\">A: 현재 GPT-4o 자체에서는 생성된 이미지를 직접 편집할 수는 없고, 프롬프트를 통한 재생성만 가능합니다.</p>\n<p data-ke-size=\"size16\"><b>Q: 생성된 이미지의 해상도는 어떻게 되나요?</b></p>\n<p data-ke-size=\"size16\">A: 현재 기본 해상도는 약 1024x1024 픽셀 수준입니다.</p>\n<script type=\"application/ld+json\">\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"GPT-4o로 생성한 이미지의 저작권은 누구에게 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"OpenAI의 정책에 따르면 생성된 이미지의 저작권은 사용자에게 있습니다. 상업적 용도로도 사용 가능해요.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"GPT-4o 이미지 생성은 무료인가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"ChatGPT Plus나 Team, Enterprise 구독자에게 제공되며, 무료 사용자는 제한된 수의 이미지만 생성할 수 있습니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"DALL-E는 이제 완전히 사라진 건가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"네, 2025년 3월 26일부터 DALL-E는 GPT-4o의 이미지 생성 기능으로 자연스럽게 대체되었습니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"생성된 이미지를 편집할 수 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"현재 GPT-4o 자체에서는 생성된 이미지를 직접 편집할 수는 없고, 프롬프트를 통한 재생성만 가능합니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"생성된 이미지의 해상도는 어떻게 되나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"현재 기본 해상도는 약 1024x1024 픽셀 수준입니다.\"\n      }\n    }\n  ]\n}\n</script>",
        "contentSnippet": "ChatGPT의 GPT-4o 이미지 생성 기능의 혁신적인 변화! DALL-E와는 무엇이 다른지, 실제 사용해보니 드러난 장단점과 창작계에 미칠 파장까지. AI 이미지 생성의 새 시대가 열렸다고? 디자이너라면 꼭 알아야 할 모든 것.\n\n\n \n요즘 들어 SNS를 보면 지브리풍 일러스트부터 놀라울 정도로 사실적인 사진까지, 모두 ChatGPT로 만들었다는 이미지들이 넘쳐나고 있어요. \"뭐야, ChatGPT도 이제 이미지를 만들어?\" 라고 생각하시는 분들 많으실 텐데요. 네, 맞습니다. 2025년 3월 26일, OpenAI가 GPT-4o를 출시하면서 DALL-E를 대체하는 이미지 생성 기능을 통합했거든요.\n \n저는 디자인 분야에서 일하다 보니 미드저니, 스테이블 디퓨전부터 DALL-E까지 거의 모든 AI 이미지 생성 도구를 업무에 활용해왔는데요. GPT-4o의 이미지 생성 기능을 처음 접했을 때는 정말 놀랐어요. 왜 그랬는지, 그리고 이 변화가 우리에게 어떤 의미인지 함께 알아볼까요?\n \nDALL-E에서 GPT-4o로, 무엇이 바뀌었나?  \n이전까지 ChatGPT에서 이미지를 생성하려면 별도의 DALL-E 모델을 호출해야 했어요. 대화하다가 \"이 설명을 이미지로 만들어줘\"라고 하면 모드 전환이 일어나면서 DALL-E가 작동했죠. 하지만 이제는 GPT-4o 하나로 대화와 이미지 생성이 모두 가능해졌어요.\n주요 변화점  \n통합된 사용자 경험 - 대화 흐름 중에 자연스럽게 이미지 생성이 가능해졌어요. 모드 전환 없이 대화하듯 이미지를 요청하면 바로 만들어줍니다.\n향상된 응답 속도 - DALL-E는 이미지 생성에 10-20초가 걸렸는데, GPT-4o는 대략 절반 정도로 시간이 단축됐어요.\n텍스트 렌더링 성능 향상 - 이전 DALL-E의 큰 약점 중 하나가 이미지 속 텍스트 처리였는데, GPT-4o는 이 부분이 획기적으로 개선되었어요. 포스터나 책 표지 같은 텍스트가 포함된 이미지 생성이 훨씬 정확해졌답니다.\n스타일 일관성 - 다양한 예술 스타일을 요청했을 때 일관된 퀄리티를 유지하는 능력이 향상되었어요. 특히 '지브리풍'으로 유명해진 애니메이션 스타일 구현이 뛰어나죠.\n솔직히 말하자면, 순수하게 사진 같은 사실적 이미지만 놓고 보면 기존 DALL-E가 약간 더 나은 경우도 있었어요. 하지만 전반적인 성능과 사용성은 GPT-4o가 훨씬 뛰어납니다.\n \n실제 사용해보니 느낀 GPT-4o 이미지 생성의 강점  \n실제로 제가 업무에 활용해보니 GPT-4o의 강점이 확실히 드러나더라고요.\n1. 맥락 이해 능력\n제가 가장 놀란 부분은 대화 맥락을 기반으로 이미지를 생성한다는 점이에요. 예를 들어, 로고 디자인에 대해 길게 대화를 나눈 후 \"이걸 이미지로 만들어줘\"라고 하면 이전 대화 내용을 모두 고려한 이미지를 만들어줍니다. DALL-E는 그냥 그 한 문장만 고려했죠.\n2. 디테일 컨트롤\n\"조금 더 밝게\", \"왼쪽 캐릭터의 표정을 더 행복하게\" 같은 세부 수정 요청에 훨씬 더 정확하게 반응해요. 이전에는 비슷한 프롬프트로 처음부터 다시 생성하는 경우가 많았는데, GPT-4o는 원하는 부분만 정확히 수정해주는 경우가 많아요.\n3. 텍스트와 이미지의 완벽한 조화\n포스터나 인포그래픽처럼 텍스트가 포함된 이미지를 만들 때 정말 빛을 발해요. DALL-E에서는 \"Happy Birthday\"라는 간단한 문구조차 \"Ha9py Birtиday\" 같은 이상한 글자로 나오는 경우가 많았는데, GPT-4o는 거의 완벽하게 텍스트를 렌더링합니다.\n \n아직 아쉬운 점들  \n물론 완벽하진 않아요. 제가 실제 사용하면서 느낀 한계점도 있습니다:\n복잡한 구도의 한계 - 여러 사람이 특정 동작을 취하고 있는 복잡한 장면을 요청하면 여전히 손이나 발이 이상하게 나오는 경우가 있어요.\n해상도 제한 - 현재 생성되는 이미지의 해상도가 제한적이라 고품질 인쇄물용으로 사용하기엔 부족해요.\n스타일 제한 - 특정 작가나 브랜드의 스타일을 정확하게 모방하는 데는 여전히 한계가 있습니다.\n \n이 변화가 창작 산업에 미칠 영향  \nGPT-4o의 이미지 생성 기능은 단순한 기술적 발전을 넘어 창작 방식 자체를 바꿀 잠재력이 있어요. 이제 누구나 쉽게 자신의 아이디어를 시각화할 수 있게 되었으니까요.\n디자이너와 일러스트레이터에게는?\n솔직히 말해서, 불안함을 느끼는 디자이너분들 많으실 거예요. 하지만 저는 이걸 위협보다는 도구로 봐야 한다고 생각해요. 디자인 초안을 빠르게 만들거나, 클라이언트와 소통하는 과정에서 아이디어를 시각화하는 데 정말 유용하거든요.\n실제로 저는 로고 디자인 작업할 때 클라이언트에게 다양한 방향성을 빠르게 제시하기 위해 GPT-4o를 활용하고 있어요. 물론 최종 결과물은 직접 다듬지만, 아이디어 발상 과정이 훨씬 효율적으로 바뀌었답니다.\n마케팅과 콘텐츠 제작에는?\nSNS 마케팅이나 블로그 콘텐츠 제작자들에게는 정말 혁명적인 변화에요. 이제 디자이너 없이도 괜찮은 퀄리티의 이미지를 즉석에서 만들 수 있으니까요. 특히 텍스트 렌더링이 개선되어 광고나 프로모션 이미지 제작이 훨씬 쉬워졌어요.\n \nGPT-4o 이미지 생성, 어떻게 활용해야 할까?  \n제가 실제로 GPT-4o 이미지 생성을 활용하면서 터득한 팁을 몇 가지 공유할게요:\n맥락이 풍부한 프롬프트 작성하기 - 단순히 \"고양이 그림\"보다는 \"푸른 하늘 아래 햇살을 받으며 창가에 앉아있는 티베트산 하얀 고양이, 스튜디오 조명, 소니 A7 카메라로 촬영한 느낌\"처럼 구체적으로 설명하세요.\n대화 맥락 활용하기 - 이미지를 생성하기 전에 원하는 스타일이나 분위기에 대해 충분히 설명하면 더 좋은 결과물을 얻을 수 있어요.\n반복 생성으로 완성도 높이기 - 첫 결과물에 만족하지 못했다면 \"이 이미지에서 배경을 더 밝게, 인물의 표정을 더 행복하게 수정해줘\"처럼 구체적인 피드백을 주세요.\n텍스트 활용하기 - GPT-4o는 텍스트 렌더링이 강점이니 포스터, 책 표지, 로고 등 텍스트가 포함된 이미지 생성에 적극 활용해보세요.\n\n\n결론: 창작의 민주화가 시작됐다  \nGPT-4o의 이미지 생성 기능은 DALL-E를 단순히 대체한 것이 아니라, AI 이미지 생성의 패러다임 자체를 바꾸고 있어요. 기술적으로는 더 정교해졌고, 사용자 경험 측면에서는 훨씬 더 접근성이 높아졌죠.\n물론 전문 디자이너나 사진작가의 창의적 작업을 완전히 대체하진 못하겠지만, 창작의 문턱을 크게 낮췄다는 점은 분명해요. 이제 \"난 그림을 못 그려\"라는 말은 더 이상 변명이 되지 않을지도 모르겠네요.\n여러분도 GPT-4o의 이미지 생성 기능을 사용해보셨나요? 어떤 경험을 하셨는지, 또 어떻게 활용하고 계신지 댓글로 공유해주세요!  \n자주 묻는 질문  \nQ: GPT-4o로 생성한 이미지의 저작권은 누구에게 있나요?\nA: OpenAI의 정책에 따르면 생성된 이미지의 저작권은 사용자에게 있습니다. 상업적 용도로도 사용 가능해요.\nQ: GPT-4o 이미지 생성은 무료인가요?\nA: ChatGPT Plus나 Team, Enterprise 구독자에게 제공되며, 무료 사용자는 제한된 수의 이미지만 생성할 수 있습니다.\nQ: DALL-E는 이제 완전히 사라진 건가요?\nA: 네, 2025년 3월 26일부터 DALL-E는 GPT-4o의 이미지 생성 기능으로 자연스럽게 대체되었습니다.\nQ: 생성된 이미지를 편집할 수 있나요?\nA: 현재 GPT-4o 자체에서는 생성된 이미지를 직접 편집할 수는 없고, 프롬프트를 통한 재생성만 가능합니다.\nQ: 생성된 이미지의 해상도는 어떻게 되나요?\nA: 현재 기본 해상도는 약 1024x1024 픽셀 수준입니다.\n\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"GPT-4o로 생성한 이미지의 저작권은 누구에게 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"OpenAI의 정책에 따르면 생성된 이미지의 저작권은 사용자에게 있습니다. 상업적 용도로도 사용 가능해요.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"GPT-4o 이미지 생성은 무료인가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"ChatGPT Plus나 Team, Enterprise 구독자에게 제공되며, 무료 사용자는 제한된 수의 이미지만 생성할 수 있습니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"DALL-E는 이제 완전히 사라진 건가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"네, 2025년 3월 26일부터 DALL-E는 GPT-4o의 이미지 생성 기능으로 자연스럽게 대체되었습니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"생성된 이미지를 편집할 수 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"현재 GPT-4o 자체에서는 생성된 이미지를 직접 편집할 수는 없고, 프롬프트를 통한 재생성만 가능합니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"생성된 이미지의 해상도는 어떻게 되나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"현재 기본 해상도는 약 1024x1024 픽셀 수준입니다.\"\n      }\n    }\n  ]\n}",
        "guid": "http://muzbox.tistory.com/483568",
        "categories": [
          "AI, 미래기술/AI 이미지 및 아트 생성",
          "AI 이미지",
          "ai 창작 도구",
          "ai 프롬프트 작성법",
          "chatgpt 그림 기능",
          "dall-e 대체",
          "gpt-4o 이미지 생성",
          "디자인 자동화",
          "이미지 생성 프롬프트",
          "지브리풍 ai",
          "텍스트 렌더링"
        ],
        "isoDate": "2025-04-14T23:42:07.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "ChatGPT 검색 vs 추론 - 당신의 질문에 맞는 최적의 선택은?",
        "link": "http://muzbox.tistory.com/483567",
        "pubDate": "Fri, 11 Apr 2025 12:01:03 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483567#entry483567comment",
        "content": "<p data-ke-size=\"size16\">ChatGPT 검색과 추론 기능, 언제 어떤 걸 써야 할지 고민돼요? 실제 사용해보니 확실히 달라요! 사실 확인은 검색, 깊은 분석은 추론, 이 가이드로 AI 활용 효율성을 높여보세요.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"ChatGPT 검색 vs 추론 - 당신의 질문에 맞는 최적의 선택은.webp\" data-origin-width=\"1536\" data-origin-height=\"1024\"><span data-url=\"https://blog.kakaocdn.net/dn/xx1kF/btsNh65AIgZ/nkk7168qWy03AT3AMQ7KSk/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/xx1kF/btsNh65AIgZ/nkk7168qWy03AT3AMQ7KSk/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/xx1kF/btsNh65AIgZ/nkk7168qWy03AT3AMQ7KSk/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fxx1kF%2FbtsNh65AIgZ%2Fnkk7168qWy03AT3AMQ7KSk%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"ChatGPT 검색 vs 추론 - 당신의 질문에 맞는 최적의 선택은?\" loading=\"lazy\" width=\"1536\" height=\"1024\" data-filename=\"ChatGPT 검색 vs 추론 - 당신의 질문에 맞는 최적의 선택은.webp\" data-origin-width=\"1536\" data-origin-height=\"1024\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">ChatGPT 검색과 추론 기능, 어떻게 구분해서 써야 할까?</p>\n<p data-ke-size=\"size16\">어젯밤에 갑자기 궁금한 게 있어서 ChatGPT를 켰는데, 검색이랑 추론 중에 뭘 선택해야 할지 한참을 고민했어요. 여러분도 그런 경험 있으신가요? 이래저래 둘 다 써보니까 확실히 차이가 느껴지더라고요. 그래서 오늘은 제가 실제로 사용해보면서 알게 된 ChatGPT의 검색과 추론 기능의 차이점과 각각 언제 써야 좋은지 정리해봤습니다.  </p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>ChatGPT 검색 기능: 구체적인 사실이나 업데이트가 필요할 때  </b></span></h2>\n<p data-ke-size=\"size16\">ChatGPT의 검색 기능은 말 그대로 구체적인 정보나 최신 데이터가 필요할 때 딱이에요. 빠르고 정확한 답변을 원한다면 검색 기능을 사용하세요. 마치 여러분 옆에 앉아서 즉각적으로 정보를 찾아주는 비서 같은 느낌이랄까요?</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"ChatGPT 검색 기능 개요.png\" data-origin-width=\"720\" data-origin-height=\"628\"><span data-url=\"https://blog.kakaocdn.net/dn/2H2do/btsNhJC0M1l/o3UyeeH0Y2mgpeZkLWNNo0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/2H2do/btsNhJC0M1l/o3UyeeH0Y2mgpeZkLWNNo0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/2H2do/btsNhJC0M1l/o3UyeeH0Y2mgpeZkLWNNo0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F2H2do%2FbtsNhJC0M1l%2Fo3UyeeH0Y2mgpeZkLWNNo0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"ChatGPT 검색 기능 개요\" loading=\"lazy\" width=\"631\" height=\"550\" data-filename=\"ChatGPT 검색 기능 개요.png\" data-origin-width=\"720\" data-origin-height=\"628\"/></span></figure>\n</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">최신 소식과 업데이트  </span></h3>\n<p data-ke-size=\"size16\">솔직히 말해서, 요즘 뉴스 보는 것도 귀찮을 때 있잖아요. 정치 소식이나 스포츠 경기 결과, 주식 시장 상황 같은 최신 정보가 필요하시다면 ChatGPT 검색이 짱이에요.</p>\n<p data-ke-size=\"size16\">저는 지난주에 K리그 순위표가 궁금했는데, 여러 사이트를 뒤적거릴 필요 없이 ChatGPT 검색으로 한방에 해결했어요. 진짜 편하더라구요!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>프롬프트 예시:</b></p>\n<pre class=\"prolog\"><code>[검색] 현재 K리그1 순위표와 다음 경기 일정을 알려줘.\n</code></pre>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">기본 상식과 정의  </span></h3>\n<p data-ke-size=\"size16\">가끔 갑자기 \"이 단어가 뭐였지?\" 하는 순간 있잖아요. 과학 개념이든, 어려운 단어 철자든, 역사적 사건이든 간단한 정보를 얻고 싶을 때 검색 기능이 제격이에요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">예를 들어 \"애자일 방법론이 정확히 뭐야?\" 같은 질문이나 \"대한민국 제2대 대통령이 누구였지?\" 같은 기본 사실 확인에 아주 유용해요. 불필요한 세부 정보 없이 명확하고 간결한 답변을 받을 수 있어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>프롬프트 예시:</b></p>\n<pre class=\"prolog\"><code>[검색] 애자일 방법론의 정확한 의미와 장단점을 알려줘.\n[검색] 대한민국 제2대 대통령은 누구였고, 어떤 업적이 있었어?\n</code></pre>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">최신 제품 정보  </span></h3>\n<p data-ke-size=\"size16\">요즘처럼 기술이 빠르게 발전하는 시대에는 최신 제품 사양이나 리뷰를 찾는 게 쉽지 않잖아요. ChatGPT 검색은 가젯, 자동차, 또는 다른 소비재를 비교할 때 특히 유용해요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">최신 아이폰의 스펙이 궁금하거나 구매하려는 차에 대한 리뷰를 알고 싶다면, 검색 기능이 가장 신뢰할 수 있는 출처에서 최신 데이터를 가져와 줍니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">예를 들어, 최신 갤럭시폰이 이전 모델보다 성능이 더 좋은지 궁금하다면? 빠른 검색으로 새로운 기능, 스펙, 사용자 리뷰를 한눈에 볼 수 있어요. 여러 웹사이트를 뒤적거릴 필요가 없죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>프롬프트 예시:</b></p>\n<pre class=\"angelscript\"><code>[검색] 최신 아이폰 15 Pro와 아이폰 14 Pro의 스펙, 가격, 카메라 성능을 비교해줘.\n[검색] 2025년 출시된 현대 아이오닉 7의 주행 거리와 충전 시간, 그리고 테슬라 모델 Y와 비교한 장단점은?\n</code></pre>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">지역 정보  </span></h3>\n<p data-ke-size=\"size16\">날씨 예보, 주변 이벤트, 맛집 추천 같은 지역 정보도 ChatGPT 검색으로 쉽게 얻을 수 있어요. 여행 중이거나 주변에서 특별한 것을 찾고 있다면, 간단히 물어보세요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">명동 근처에서 맛있는 순두부찌개 맛집을 찾고 싶다고요? ChatGPT가 즉시 리뷰와 평점을 포함한 최고 평점의 음식점 목록을 알려줄 거예요. 소중한 시간을 최대한 활용할 수 있겠죠?</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>프롬프트 예시:</b></p>\n<pre class=\"prolog\"><code>[검색] 서울 강남역 근처 분위기 좋은 데이트 카페 추천해줘. 주차가 편한 곳으로 알려줘.\n[검색] 이번 주말 부산에서 열리는 문화 행사나 축제가 있을까?\n</code></pre>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>ChatGPT 추론 기능: 깊이 있는 생각과 문제 해결이 필요할 때  </b></span></h2>\n<p data-ke-size=\"size16\">ChatGPT의 검색 기능이 빠르고 사실적인 답변에 좋다면, 추론 기능은 더 복잡한 작업에 진가를 발휘해요. 깊은 분석이나 창의적 사고가 필요한 까다로운 문제에 부딪혔을 때는 ChatGPT 추론의 문제 해결 능력을 활용하세요.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"ChatGPT의 추론 기능 활용.png\" data-origin-width=\"816\" data-origin-height=\"456\"><span data-url=\"https://blog.kakaocdn.net/dn/cFyw5M/btsNhRujHwW/0Fakjc9kGVkOU23NQK10N0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cFyw5M/btsNhRujHwW/0Fakjc9kGVkOU23NQK10N0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cFyw5M/btsNhRujHwW/0Fakjc9kGVkOU23NQK10N0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcFyw5M%2FbtsNhRujHwW%2F0Fakjc9kGVkOU23NQK10N0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"ChatGPT의 추론 기능 활용\" loading=\"lazy\" width=\"816\" height=\"456\" data-filename=\"ChatGPT의 추론 기능 활용.png\" data-origin-width=\"816\" data-origin-height=\"456\"/></span></figure>\n</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">복잡한 문제 해결  </span></h3>\n<p data-ke-size=\"size16\">여러 계층을 분석하거나 다양한 옵션을 평가해야 하는 작업에는 ChatGPT의 추론 능력이 정말 소중해요. 사업 전략을 계획하거나 기술적인 문제를 해결할 때, ChatGPT는 다양한 각도를 탐색하고 정보에 기반한 결정을 내리는 데 도움을 줍니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">예를 들어, 스타트업을 위한 최적의 마케팅 전략을 결정하려 한다면, ChatGPT는 다양한 접근 방식의 장단점을 비교하고, 가능한 장애물을 고려하며, 유사한 사례 연구를 바탕으로 인사이트를 제공할 수 있어요. 단순히 빠른 사실만 제공하는 것이 아니라, 문제 해결을 위한 비판적 사고 과정을 안내해 줍니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>프롬프트 예시:</b></p>\n<pre class=\"prolog\"><code>[추론] 미용실 창업을 준비 중인데, 경쟁이 치열한 강남 지역에서 차별화된 마케팅 전략을 세우고 싶어. 소셜 미디어, 지역 특성, 타겟 고객층을 고려해서 구체적인 전략을 제안해줘.\n\n[추론] 우리 회사는 30명 규모의 소프트웨어 개발 스타트업인데, 재택근무와 사무실 근무를 어떻게 균형있게 조합할지 고민이야. 팀 문화, 생산성, 직원 만족도를 모두 고려한 하이브리드 근무 정책을 설계해줄 수 있을까?\n</code></pre>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">창의적 작업  </span></h3>\n<p data-ke-size=\"size16\">ChatGPT의 추론은 창의적인 브레인스토밍에도 훌륭한 선택이에요. 이 기능은 논리, 패턴, 관련 데이터를 활용하여 혁신적인 아이디어를 개발하거나 기존 아이디어를 개선하는 데 도움을 줍니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">소설 플롯에 막혔다면, ChatGPT가 창의적인 프롬프트, 캐릭터 아크, 또는 대체 엔딩을 제안할 수 있어요. 마찬가지로, 지역 커뮤니티 이벤트를 계획한다면, ChatGPT는 독특한 테마, 인터랙티브 활동, 또는 관객을 참여시키는 방법을 브레인스토밍하는 데 도움을 줄 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>프롬프트 예시:</b></p>\n<pre class=\"prolog\"><code>[추론] 나는 현대판 판타지 소설을 쓰고 있어. 주인공은 평범한 대학생인데 어느날 자신이 꿈속에서 사람들의 병을 치유할 수 있는 능력이 있다는 걸 알게 돼. 이 설정을 바탕으로 흥미로운 플롯 전개와 갈등 요소를 제안해줘.\n\n[추론] 우리 동네 작은 도서관에서 아이들을 위한 여름 독서 프로그램을 기획 중이야. '바다와 모험'이라는 주제로 6-10세 아이들이 책에 흥미를 갖게 할 수 있는 창의적인 활동 아이디어를 5가지 제안해줘.\n</code></pre>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">논증 분석 또는 의사 결정 ⚖️</span></h3>\n<p data-ke-size=\"size16\">여러 옵션과 많은 변수가 있는 결정에 직면했을 때, ChatGPT 추론은 필수적인 두 번째 의견이 됩니다. 추론 기능을 사용하면 각 선택지의 장단점을 분석하며 상황의 모든 측면을 고려할 수 있어요. 결정하기 어려운 순간에 균형 잡힌 선택을 할 수 있게 도와줍니다.</p>\n<p data-ke-size=\"size16\">예를 들어, 두 개의 채용 제안 중에서 고민하고 있다면, ChatGPT는 각 역할의 이점과 단점을 나열하는 데 도움을 줄 수 있어요. 회사 문화, 경력 성장, 보상, 일과 삶의 균형 같은 요소를 고려하도록 도와줍니다. 또한 ChatGPT는 여러분의 우선순위에 따라 대안 제안을 제공하여 의사 결정 과정을 더 쉽게 만들 수 있어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>프롬프트 예시:</b></p>\n<pre class=\"angelscript\"><code>[추론] 현재 안정적인 대기업(연봉 7000)과 성장 가능성이 높은 스타트업(연봉 5500 + 스톡옵션)의 제안을 동시에 받았어. 경력 성장, 일-삶 균형, 재정적 안정성, 그리고 장기적 전망 측면에서 두 선택지를 분석해줘. 내 우선순위는 1) 성장 2) 안정성 3) 워라밸 순이야.\n\n[추론] 결혼식 장소로 자연 속 야외 웨딩과 고급 호텔 실내 웨딩 중에서 고민 중이야. 날씨 리스크, 비용, 접근성, 사진 퀄리티, 하객 편의성 등 다양한 요소를 비교 분석해줘. 우리는 5월에 결혼할 예정이고, 하객은 약 150명 정도야.\n</code></pre>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">복잡한 아이디어 설명  </span></h3>\n<p data-ke-size=\"size16\">때로는 단순한 답변 이상이 필요할 때가 있죠. 복잡한 과학 개념, 고급 기술, 또는 이론을 이해하려고 할 때, ChatGPT의 추론 기능은 상세하게 설명해 줄 수 있어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">예를 들어, 블록체인이나 머신 러닝 같은 개념으로 고민하고 있다면, ChatGPT는 기본과 더 복잡한 측면 모두를 다루는 상세하고 쉽게 따라갈 수 있는 설명을 제공할 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>프롬프트 예시:</b></p>\n<pre class=\"prolog\"><code>[추론] 양자컴퓨팅의 기본 원리를 고등학생 수준에서 이해할 수 있게 설명해줘. 특히 기존 컴퓨터와의 차이점과 왜 특정 문제에서 더 효율적인지 비유를 들어 설명해주면 좋겠어.\n\n[추론] ESG 경영이 정확히 무엇이고, 기업과 사회에 어떤 영향을 미치는지 체계적으로 분석해줘. 실제 성공 사례와 비판적 시각도 함께 다루어주면 좋겠어.\n</code></pre>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>두 기능을 모두 선택해야 할 때  </b></span></h2>\n<p data-ke-size=\"size16\">사실과 깊은 분석 모두가 필요할 때가 있어요. 이런 상황에서는 ChatGPT의 검색과 추론 기능을 결합하면 더 완전하고 미묘한 그림을 얻을 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"언제 검색과 추론을 모두 사용해야 할까.png\" data-origin-width=\"792\" data-origin-height=\"510\"><span data-url=\"https://blog.kakaocdn.net/dn/kXoh2/btsNhJpu1yb/Hy3qFMXvKKN74sgE4iCEzK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/kXoh2/btsNhJpu1yb/Hy3qFMXvKKN74sgE4iCEzK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/kXoh2/btsNhJpu1yb/Hy3qFMXvKKN74sgE4iCEzK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FkXoh2%2FbtsNhJpu1yb%2FHy3qFMXvKKN74sgE4iCEzK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"언제 검색과 추론을 모두 사용해야 할까요?\" loading=\"lazy\" width=\"792\" height=\"510\" data-filename=\"언제 검색과 추론을 모두 사용해야 할까.png\" data-origin-width=\"792\" data-origin-height=\"510\"/></span></figure>\n</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">A). 주제를 자세히 이해하기  </span></h3>\n<p data-ke-size=\"size16\">주제를 파고들어 원시 사실과 이들이 어떻게 연결되는지 이해하고 싶다면, ChatGPT의 검색과 추론 기능을 함께 사용하는 것이 좋아요. 이렇게 하면 구체적인 세부 정보를 수집하고 이를 더 큰 그림으로 통합할 수 있습니다.</p>\n<p data-ke-size=\"size16\">예를 들어, 우주 탐사에 대해 연구한다면, 최신 임무, 기술, 발견을 검색하면서 동시에 이들이 사회에 미칠 잠재적 영향에 대해 추론할 수 있어요. 이렇게 하면 사실만 수집하는 것이 아니라, 그것들이 인간 지식, 우주 여행, 미래 노력에 미치는 영향도 한꺼번에 평가할 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>프롬프트 예시:</b></p>\n<pre class=\"prolog\"><code>[검색+추론] 최근 5년간 우주 개발 동향과 주요 발전 사항을 검색해주고, 이러한 발전이 향후 10년 내 지구 경제와 과학 기술에 미칠 영향을 종합적으로 분석해줘.\n\n[검색+추론] 현재 글로벌 반도체 산업의 주요 기업들과 시장 점유율을 조사하고, 미-중 기술 갈등이 장기적으로 반도체 공급망과 한국 기업들에게 어떤 영향을 미칠지 전망해줘.\n</code></pre>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">B). 여러 변수가 있는 결정 내리기  </span></h3>\n<p data-ke-size=\"size16\">집 구매, 특정 소프트웨어 선택, 또는 휴가 목적지 선택과 같이 여러 옵션이나 요소를 고려해야 하는 상황에서는 검색과 추론이 모두 필요해요. 검색 기능은 각 옵션에 대한 하드 사실(비용, 기능, 리뷰)을 수집하고, 추론 기능은 장단점을 평가하여 특정 요구 사항에 가장 잘 맞는 선택을 내릴 수 있게 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">새로운 도시로 이사를 고려하고 있다면, 주택 가격, 지역 편의 시설, 취업 기회를 조사하고 싶을 거예요. 동시에, 도시의 미적 감각, 라이프스타일, 가족이나 친구와의 거리 같은 추상적인 변수도 고려해야 합니다. 이러한 요소들을 개인 선호도와 결합하면 이사가 적합한지 파악하는 데 도움이 됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>프롬프트 예시:</b></p>\n<pre class=\"prolog\"><code>[검색+추론] 제주도와 부산에 1년 살 예정인데 두 도시를 비교해줘. 주거비용, 생활물가, 기후, 교통, 의료시설, 문화생활 등 객관적 데이터를 찾아주고, 30대 부부가 디지털 노마드로 살기에 어떤 곳이 더 적합할지 분석해줘.\n\n[검색+추론] 아이패드 프로와 삼성 갤럭시 탭 S9 울트라의 최신 스펙, 가격, 호환 액세서리를 비교해주고, 디지털 아트 작업과 영상 편집이 주 용도인 나에게 어떤 제품이 더 적합할지 분석해줘.\n</code></pre>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">C). 여러 옵션이나 제품 비교하기  </span></h3>\n<p data-ke-size=\"size16\">제품, 서비스, 심지어 경력 경로를 비교할 때, 검색과 추론을 모두 사용하면 좋아요. 검색은 객관적인 사실을 제공하고, 추론은 어떤 옵션이 개인 또는 전문적 목표에 가장 적합한지 평가하거나 해당 제품에 대한 최신 정보를 얻는 데 도움을 줍니다.</p>\n<p data-ke-size=\"size16\">예를 들어, 두 노트북 중에서 고르고 있다면, 스펙과 리뷰를 확인하고(검색), 옵션을 신중히 평가해야 합니다(추론). 어떤 게 예산, 라이프스타일, 미래 필요에 맞을까요? 두 기능을 모두 활용하면 최종 결정을 내리는 데 도움이 될 수 있어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>프롬프트 예시:</b></p>\n<pre class=\"prolog\"><code>[검색+추론] 애플 맥북 프로 M2와 델 XPS 15의 최신 사양, 가격, 배터리 성능, 화면 품질을 비교해줘. 특히 영상 편집과 코딩을 주로 하는 내게 어떤 노트북이 더 적합할지 분석해줘.\n\n[검색+추론] 넷플릭스, 디즈니플러스, 티빙의 월 구독료, 콘텐츠 라이브러리 크기, 독점 콘텐츠를 비교해주고, 한국 드라마와 다큐멘터리를 주로 보는 내게 가장 가성비 좋은 서비스는 무엇인지 추천해줘.\n</code></pre>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">D). 새로운 개념이나 트렌드 탐색하기  </span></h3>\n<p data-ke-size=\"size16\">검색과 추론을 함께 활용하면 새로운 개념이나 떠오르는 트렌드를 이해하는 데 도움이 될 수 있어요. 검색은 최신 정보를 수집하고, 추론은 잠재적 영향과 더 넓은 의미를 탐색합니다.</p>\n<p data-ke-size=\"size16\">예를 들어, 인공지능에 대해 궁금하다면, 검색을 사용하여 AI의 최신 발전 상황을 찾고, 추론을 사용하여 AI가 다양한 산업에 어떤 영향을 미치거나 미래에 우리 삶의 방식을 어떻게 변화시킬지 분석할 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>프롬프트 예시:</b></p>\n<pre class=\"prolog\"><code>[검색+추론] 웹3.0과 메타버스의 최신 발전 동향과 주요 플랫폼들을 조사해주고, 이러한 기술이 향후 5년 내 교육, 엔터테인먼트, 소매업에 어떤 변화를 가져올지 분석해줘.\n\n[검색+추론] '제로 웨이스트' 라이프스타일의 주요 원칙과 글로벌 트렌드를 조사해주고, 이를 한국의 도시 환경에서 실천하기 위한 현실적인 방법과 도전 과제를 분석해줘.\n</code></pre>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"954\" data-origin-height=\"642\"><span data-url=\"https://blog.kakaocdn.net/dn/FUp69/btsNhkjtyXh/bJ0G0kJWIkmrbXTBYH9tA0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/FUp69/btsNhkjtyXh/bJ0G0kJWIkmrbXTBYH9tA0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/FUp69/btsNhkjtyXh/bJ0G0kJWIkmrbXTBYH9tA0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FFUp69%2FbtsNhkjtyXh%2FbJ0G0kJWIkmrbXTBYH9tA0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"챗GPT 검색 대 추론\" loading=\"lazy\" width=\"954\" height=\"642\" data-origin-width=\"954\" data-origin-height=\"642\"/></span></figure>\n</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>마치며: 상황에 맞는 선택이 중요해요  </b></span></h2>\n<p data-ke-size=\"size16\">ChatGPT의 검색 기능과 추론 기능을 언제 사용해야 할지 이해함으로써, 이러한 강력한 기능의 가치를 최대화할 수 있어요. 빠른 사실, 깊은 분석, 또는 둘 다 필요하든, ChatGPT는 거의 모든 결정을 내리고 문제에 명확하게 접근하는 데 도움을 줄 수 있으며, 종종 해당 작업에 대한 정말 유용한 두 번째 의견이나 목소리를 제공합니다.</p>\n<p data-ke-size=\"size16\">제 경우에는 일상적인 정보 검색에는 검색 기능을, 블로그 글이나 사업 계획처럼 깊은 사고가 필요한 일에는 추론 기능을 주로 사용하고 있어요. 여러분은 어떤 기능을 더 자주 사용하시나요? 댓글로 알려주세요!  </p>\n<hr data-ke-style=\"style1\" />\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>Q&amp;A: ChatGPT 검색과 추론에 대해 자주 묻는 질문들</b></span></h2>\n<p data-ke-size=\"size16\"><b>Q: ChatGPT 검색 기능은 얼마나 최신 정보까지 알고 있나요?</b></p>\n<p data-ke-size=\"size16\">A: 검색 기능은 인터넷에 연결되어 있어 최신 정보를 가져옵니다.</p>\n<p data-ke-size=\"size16\"><b>Q: 추론 기능의 한계는 무엇인가요?</b></p>\n<p data-ke-size=\"size16\">A: 복잡한 추론이 가능하지만 전문가 수준의 깊이 있는 분석은 제한적일 수 있어요.</p>\n<p data-ke-size=\"size16\"><b>Q: 검색과 추론을 동시에 사용할 때 더 느려지나요?</b></p>\n<p data-ke-size=\"size16\">A: 약간 더 시간이 걸릴 수 있지만 결과의 질이 높아져 가치가 있습니다.</p>\n<p data-ke-size=\"size16\"><b>Q: 어떤 기능이 더 정확한가요?</b></p>\n<p data-ke-size=\"size16\">A: 사실 확인은 검색이, 복잡한 분석은 추론이 더 정확합니다.</p>\n<p data-ke-size=\"size16\"><b>Q: 추론 기능은 검색 기능보다 창의적인가요?</b></p>\n<p data-ke-size=\"size16\">A: 네, 추론 기능이 패턴 인식과 연결성을 활용해 더 창의적인 결과를 제공합니다.</p>\n<p data-ke-size=\"size16\">\n<script type=\"application/ld+json\">\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"ChatGPT 검색 기능은 얼마나 최신 정보까지 알고 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"검색 기능은 인터넷에 연결되어 있어 최신 정보를 가져옵니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"추론 기능의 한계는 무엇인가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"복잡한 추론이 가능하지만 전문가 수준의 깊이 있는 분석은 제한적일 수 있어요.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"검색과 추론을 동시에 사용할 때 더 느려지나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"약간 더 시간이 걸릴 수 있지만 결과의 질이 높아져 가치가 있습니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"어떤 기능이 더 정확한가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"사실 확인은 검색이, 복잡한 분석은 추론이 더 정확합니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"추론 기능은 검색 기능보다 창의적인가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"네, 추론 기능이 패턴 인식과 연결성을 활용해 더 창의적인 결과를 제공합니다.\"\n      }\n    }\n  ]\n}\n</script>\n</p>",
        "contentSnippet": "ChatGPT 검색과 추론 기능, 언제 어떤 걸 써야 할지 고민돼요? 실제 사용해보니 확실히 달라요! 사실 확인은 검색, 깊은 분석은 추론, 이 가이드로 AI 활용 효율성을 높여보세요.\n\n\n \nChatGPT 검색과 추론 기능, 어떻게 구분해서 써야 할까?\n어젯밤에 갑자기 궁금한 게 있어서 ChatGPT를 켰는데, 검색이랑 추론 중에 뭘 선택해야 할지 한참을 고민했어요. 여러분도 그런 경험 있으신가요? 이래저래 둘 다 써보니까 확실히 차이가 느껴지더라고요. 그래서 오늘은 제가 실제로 사용해보면서 알게 된 ChatGPT의 검색과 추론 기능의 차이점과 각각 언제 써야 좋은지 정리해봤습니다.  \n \n \nChatGPT 검색 기능: 구체적인 사실이나 업데이트가 필요할 때  \nChatGPT의 검색 기능은 말 그대로 구체적인 정보나 최신 데이터가 필요할 때 딱이에요. 빠르고 정확한 답변을 원한다면 검색 기능을 사용하세요. 마치 여러분 옆에 앉아서 즉각적으로 정보를 찾아주는 비서 같은 느낌이랄까요?\n\n\n최신 소식과 업데이트  \n솔직히 말해서, 요즘 뉴스 보는 것도 귀찮을 때 있잖아요. 정치 소식이나 스포츠 경기 결과, 주식 시장 상황 같은 최신 정보가 필요하시다면 ChatGPT 검색이 짱이에요.\n저는 지난주에 K리그 순위표가 궁금했는데, 여러 사이트를 뒤적거릴 필요 없이 ChatGPT 검색으로 한방에 해결했어요. 진짜 편하더라구요!\n \n프롬프트 예시:\n[검색] 현재 K리그1 순위표와 다음 경기 일정을 알려줘.\n\n기본 상식과 정의  \n가끔 갑자기 \"이 단어가 뭐였지?\" 하는 순간 있잖아요. 과학 개념이든, 어려운 단어 철자든, 역사적 사건이든 간단한 정보를 얻고 싶을 때 검색 기능이 제격이에요.\n \n예를 들어 \"애자일 방법론이 정확히 뭐야?\" 같은 질문이나 \"대한민국 제2대 대통령이 누구였지?\" 같은 기본 사실 확인에 아주 유용해요. 불필요한 세부 정보 없이 명확하고 간결한 답변을 받을 수 있어요.\n \n프롬프트 예시:\n[검색] 애자일 방법론의 정확한 의미와 장단점을 알려줘.\n[검색] 대한민국 제2대 대통령은 누구였고, 어떤 업적이 있었어?\n\n최신 제품 정보  \n요즘처럼 기술이 빠르게 발전하는 시대에는 최신 제품 사양이나 리뷰를 찾는 게 쉽지 않잖아요. ChatGPT 검색은 가젯, 자동차, 또는 다른 소비재를 비교할 때 특히 유용해요.\n \n최신 아이폰의 스펙이 궁금하거나 구매하려는 차에 대한 리뷰를 알고 싶다면, 검색 기능이 가장 신뢰할 수 있는 출처에서 최신 데이터를 가져와 줍니다.\n \n예를 들어, 최신 갤럭시폰이 이전 모델보다 성능이 더 좋은지 궁금하다면? 빠른 검색으로 새로운 기능, 스펙, 사용자 리뷰를 한눈에 볼 수 있어요. 여러 웹사이트를 뒤적거릴 필요가 없죠.\n \n프롬프트 예시:\n[검색] 최신 아이폰 15 Pro와 아이폰 14 Pro의 스펙, 가격, 카메라 성능을 비교해줘.\n[검색] 2025년 출시된 현대 아이오닉 7의 주행 거리와 충전 시간, 그리고 테슬라 모델 Y와 비교한 장단점은?\n\n지역 정보  \n날씨 예보, 주변 이벤트, 맛집 추천 같은 지역 정보도 ChatGPT 검색으로 쉽게 얻을 수 있어요. 여행 중이거나 주변에서 특별한 것을 찾고 있다면, 간단히 물어보세요.\n \n명동 근처에서 맛있는 순두부찌개 맛집을 찾고 싶다고요? ChatGPT가 즉시 리뷰와 평점을 포함한 최고 평점의 음식점 목록을 알려줄 거예요. 소중한 시간을 최대한 활용할 수 있겠죠?\n \n프롬프트 예시:\n[검색] 서울 강남역 근처 분위기 좋은 데이트 카페 추천해줘. 주차가 편한 곳으로 알려줘.\n[검색] 이번 주말 부산에서 열리는 문화 행사나 축제가 있을까?\n\n \n \nChatGPT 추론 기능: 깊이 있는 생각과 문제 해결이 필요할 때  \nChatGPT의 검색 기능이 빠르고 사실적인 답변에 좋다면, 추론 기능은 더 복잡한 작업에 진가를 발휘해요. 깊은 분석이나 창의적 사고가 필요한 까다로운 문제에 부딪혔을 때는 ChatGPT 추론의 문제 해결 능력을 활용하세요.\n\n\n복잡한 문제 해결  \n여러 계층을 분석하거나 다양한 옵션을 평가해야 하는 작업에는 ChatGPT의 추론 능력이 정말 소중해요. 사업 전략을 계획하거나 기술적인 문제를 해결할 때, ChatGPT는 다양한 각도를 탐색하고 정보에 기반한 결정을 내리는 데 도움을 줍니다.\n \n예를 들어, 스타트업을 위한 최적의 마케팅 전략을 결정하려 한다면, ChatGPT는 다양한 접근 방식의 장단점을 비교하고, 가능한 장애물을 고려하며, 유사한 사례 연구를 바탕으로 인사이트를 제공할 수 있어요. 단순히 빠른 사실만 제공하는 것이 아니라, 문제 해결을 위한 비판적 사고 과정을 안내해 줍니다.\n \n프롬프트 예시:\n[추론] 미용실 창업을 준비 중인데, 경쟁이 치열한 강남 지역에서 차별화된 마케팅 전략을 세우고 싶어. 소셜 미디어, 지역 특성, 타겟 고객층을 고려해서 구체적인 전략을 제안해줘.\n\n[추론] 우리 회사는 30명 규모의 소프트웨어 개발 스타트업인데, 재택근무와 사무실 근무를 어떻게 균형있게 조합할지 고민이야. 팀 문화, 생산성, 직원 만족도를 모두 고려한 하이브리드 근무 정책을 설계해줄 수 있을까?\n\n창의적 작업  \nChatGPT의 추론은 창의적인 브레인스토밍에도 훌륭한 선택이에요. 이 기능은 논리, 패턴, 관련 데이터를 활용하여 혁신적인 아이디어를 개발하거나 기존 아이디어를 개선하는 데 도움을 줍니다.\n \n소설 플롯에 막혔다면, ChatGPT가 창의적인 프롬프트, 캐릭터 아크, 또는 대체 엔딩을 제안할 수 있어요. 마찬가지로, 지역 커뮤니티 이벤트를 계획한다면, ChatGPT는 독특한 테마, 인터랙티브 활동, 또는 관객을 참여시키는 방법을 브레인스토밍하는 데 도움을 줄 수 있습니다.\n \n프롬프트 예시:\n[추론] 나는 현대판 판타지 소설을 쓰고 있어. 주인공은 평범한 대학생인데 어느날 자신이 꿈속에서 사람들의 병을 치유할 수 있는 능력이 있다는 걸 알게 돼. 이 설정을 바탕으로 흥미로운 플롯 전개와 갈등 요소를 제안해줘.\n\n[추론] 우리 동네 작은 도서관에서 아이들을 위한 여름 독서 프로그램을 기획 중이야. '바다와 모험'이라는 주제로 6-10세 아이들이 책에 흥미를 갖게 할 수 있는 창의적인 활동 아이디어를 5가지 제안해줘.\n\n논증 분석 또는 의사 결정 ⚖️\n여러 옵션과 많은 변수가 있는 결정에 직면했을 때, ChatGPT 추론은 필수적인 두 번째 의견이 됩니다. 추론 기능을 사용하면 각 선택지의 장단점을 분석하며 상황의 모든 측면을 고려할 수 있어요. 결정하기 어려운 순간에 균형 잡힌 선택을 할 수 있게 도와줍니다.\n예를 들어, 두 개의 채용 제안 중에서 고민하고 있다면, ChatGPT는 각 역할의 이점과 단점을 나열하는 데 도움을 줄 수 있어요. 회사 문화, 경력 성장, 보상, 일과 삶의 균형 같은 요소를 고려하도록 도와줍니다. 또한 ChatGPT는 여러분의 우선순위에 따라 대안 제안을 제공하여 의사 결정 과정을 더 쉽게 만들 수 있어요.\n \n프롬프트 예시:\n[추론] 현재 안정적인 대기업(연봉 7000)과 성장 가능성이 높은 스타트업(연봉 5500 + 스톡옵션)의 제안을 동시에 받았어. 경력 성장, 일-삶 균형, 재정적 안정성, 그리고 장기적 전망 측면에서 두 선택지를 분석해줘. 내 우선순위는 1) 성장 2) 안정성 3) 워라밸 순이야.\n\n[추론] 결혼식 장소로 자연 속 야외 웨딩과 고급 호텔 실내 웨딩 중에서 고민 중이야. 날씨 리스크, 비용, 접근성, 사진 퀄리티, 하객 편의성 등 다양한 요소를 비교 분석해줘. 우리는 5월에 결혼할 예정이고, 하객은 약 150명 정도야.\n\n복잡한 아이디어 설명  \n때로는 단순한 답변 이상이 필요할 때가 있죠. 복잡한 과학 개념, 고급 기술, 또는 이론을 이해하려고 할 때, ChatGPT의 추론 기능은 상세하게 설명해 줄 수 있어요.\n \n예를 들어, 블록체인이나 머신 러닝 같은 개념으로 고민하고 있다면, ChatGPT는 기본과 더 복잡한 측면 모두를 다루는 상세하고 쉽게 따라갈 수 있는 설명을 제공할 수 있습니다.\n \n프롬프트 예시:\n[추론] 양자컴퓨팅의 기본 원리를 고등학생 수준에서 이해할 수 있게 설명해줘. 특히 기존 컴퓨터와의 차이점과 왜 특정 문제에서 더 효율적인지 비유를 들어 설명해주면 좋겠어.\n\n[추론] ESG 경영이 정확히 무엇이고, 기업과 사회에 어떤 영향을 미치는지 체계적으로 분석해줘. 실제 성공 사례와 비판적 시각도 함께 다루어주면 좋겠어.\n\n \n \n두 기능을 모두 선택해야 할 때  \n사실과 깊은 분석 모두가 필요할 때가 있어요. 이런 상황에서는 ChatGPT의 검색과 추론 기능을 결합하면 더 완전하고 미묘한 그림을 얻을 수 있습니다.\n\n\nA). 주제를 자세히 이해하기  \n주제를 파고들어 원시 사실과 이들이 어떻게 연결되는지 이해하고 싶다면, ChatGPT의 검색과 추론 기능을 함께 사용하는 것이 좋아요. 이렇게 하면 구체적인 세부 정보를 수집하고 이를 더 큰 그림으로 통합할 수 있습니다.\n예를 들어, 우주 탐사에 대해 연구한다면, 최신 임무, 기술, 발견을 검색하면서 동시에 이들이 사회에 미칠 잠재적 영향에 대해 추론할 수 있어요. 이렇게 하면 사실만 수집하는 것이 아니라, 그것들이 인간 지식, 우주 여행, 미래 노력에 미치는 영향도 한꺼번에 평가할 수 있습니다.\n \n프롬프트 예시:\n[검색+추론] 최근 5년간 우주 개발 동향과 주요 발전 사항을 검색해주고, 이러한 발전이 향후 10년 내 지구 경제와 과학 기술에 미칠 영향을 종합적으로 분석해줘.\n\n[검색+추론] 현재 글로벌 반도체 산업의 주요 기업들과 시장 점유율을 조사하고, 미-중 기술 갈등이 장기적으로 반도체 공급망과 한국 기업들에게 어떤 영향을 미칠지 전망해줘.\n\nB). 여러 변수가 있는 결정 내리기  \n집 구매, 특정 소프트웨어 선택, 또는 휴가 목적지 선택과 같이 여러 옵션이나 요소를 고려해야 하는 상황에서는 검색과 추론이 모두 필요해요. 검색 기능은 각 옵션에 대한 하드 사실(비용, 기능, 리뷰)을 수집하고, 추론 기능은 장단점을 평가하여 특정 요구 사항에 가장 잘 맞는 선택을 내릴 수 있게 합니다.\n \n새로운 도시로 이사를 고려하고 있다면, 주택 가격, 지역 편의 시설, 취업 기회를 조사하고 싶을 거예요. 동시에, 도시의 미적 감각, 라이프스타일, 가족이나 친구와의 거리 같은 추상적인 변수도 고려해야 합니다. 이러한 요소들을 개인 선호도와 결합하면 이사가 적합한지 파악하는 데 도움이 됩니다.\n \n프롬프트 예시:\n[검색+추론] 제주도와 부산에 1년 살 예정인데 두 도시를 비교해줘. 주거비용, 생활물가, 기후, 교통, 의료시설, 문화생활 등 객관적 데이터를 찾아주고, 30대 부부가 디지털 노마드로 살기에 어떤 곳이 더 적합할지 분석해줘.\n\n[검색+추론] 아이패드 프로와 삼성 갤럭시 탭 S9 울트라의 최신 스펙, 가격, 호환 액세서리를 비교해주고, 디지털 아트 작업과 영상 편집이 주 용도인 나에게 어떤 제품이 더 적합할지 분석해줘.\n\nC). 여러 옵션이나 제품 비교하기  \n제품, 서비스, 심지어 경력 경로를 비교할 때, 검색과 추론을 모두 사용하면 좋아요. 검색은 객관적인 사실을 제공하고, 추론은 어떤 옵션이 개인 또는 전문적 목표에 가장 적합한지 평가하거나 해당 제품에 대한 최신 정보를 얻는 데 도움을 줍니다.\n예를 들어, 두 노트북 중에서 고르고 있다면, 스펙과 리뷰를 확인하고(검색), 옵션을 신중히 평가해야 합니다(추론). 어떤 게 예산, 라이프스타일, 미래 필요에 맞을까요? 두 기능을 모두 활용하면 최종 결정을 내리는 데 도움이 될 수 있어요.\n \n프롬프트 예시:\n[검색+추론] 애플 맥북 프로 M2와 델 XPS 15의 최신 사양, 가격, 배터리 성능, 화면 품질을 비교해줘. 특히 영상 편집과 코딩을 주로 하는 내게 어떤 노트북이 더 적합할지 분석해줘.\n\n[검색+추론] 넷플릭스, 디즈니플러스, 티빙의 월 구독료, 콘텐츠 라이브러리 크기, 독점 콘텐츠를 비교해주고, 한국 드라마와 다큐멘터리를 주로 보는 내게 가장 가성비 좋은 서비스는 무엇인지 추천해줘.\n\nD). 새로운 개념이나 트렌드 탐색하기  \n검색과 추론을 함께 활용하면 새로운 개념이나 떠오르는 트렌드를 이해하는 데 도움이 될 수 있어요. 검색은 최신 정보를 수집하고, 추론은 잠재적 영향과 더 넓은 의미를 탐색합니다.\n예를 들어, 인공지능에 대해 궁금하다면, 검색을 사용하여 AI의 최신 발전 상황을 찾고, 추론을 사용하여 AI가 다양한 산업에 어떤 영향을 미치거나 미래에 우리 삶의 방식을 어떻게 변화시킬지 분석할 수 있습니다.\n \n프롬프트 예시:\n[검색+추론] 웹3.0과 메타버스의 최신 발전 동향과 주요 플랫폼들을 조사해주고, 이러한 기술이 향후 5년 내 교육, 엔터테인먼트, 소매업에 어떤 변화를 가져올지 분석해줘.\n\n[검색+추론] '제로 웨이스트' 라이프스타일의 주요 원칙과 글로벌 트렌드를 조사해주고, 이를 한국의 도시 환경에서 실천하기 위한 현실적인 방법과 도전 과제를 분석해줘.\n\n \n\n\n마치며: 상황에 맞는 선택이 중요해요  \nChatGPT의 검색 기능과 추론 기능을 언제 사용해야 할지 이해함으로써, 이러한 강력한 기능의 가치를 최대화할 수 있어요. 빠른 사실, 깊은 분석, 또는 둘 다 필요하든, ChatGPT는 거의 모든 결정을 내리고 문제에 명확하게 접근하는 데 도움을 줄 수 있으며, 종종 해당 작업에 대한 정말 유용한 두 번째 의견이나 목소리를 제공합니다.\n제 경우에는 일상적인 정보 검색에는 검색 기능을, 블로그 글이나 사업 계획처럼 깊은 사고가 필요한 일에는 추론 기능을 주로 사용하고 있어요. 여러분은 어떤 기능을 더 자주 사용하시나요? 댓글로 알려주세요!  \nQ&A: ChatGPT 검색과 추론에 대해 자주 묻는 질문들\nQ: ChatGPT 검색 기능은 얼마나 최신 정보까지 알고 있나요?\nA: 검색 기능은 인터넷에 연결되어 있어 최신 정보를 가져옵니다.\nQ: 추론 기능의 한계는 무엇인가요?\nA: 복잡한 추론이 가능하지만 전문가 수준의 깊이 있는 분석은 제한적일 수 있어요.\nQ: 검색과 추론을 동시에 사용할 때 더 느려지나요?\nA: 약간 더 시간이 걸릴 수 있지만 결과의 질이 높아져 가치가 있습니다.\nQ: 어떤 기능이 더 정확한가요?\nA: 사실 확인은 검색이, 복잡한 분석은 추론이 더 정확합니다.\nQ: 추론 기능은 검색 기능보다 창의적인가요?\nA: 네, 추론 기능이 패턴 인식과 연결성을 활용해 더 창의적인 결과를 제공합니다.\n\n\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"ChatGPT 검색 기능은 얼마나 최신 정보까지 알고 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"검색 기능은 인터넷에 연결되어 있어 최신 정보를 가져옵니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"추론 기능의 한계는 무엇인가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"복잡한 추론이 가능하지만 전문가 수준의 깊이 있는 분석은 제한적일 수 있어요.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"검색과 추론을 동시에 사용할 때 더 느려지나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"약간 더 시간이 걸릴 수 있지만 결과의 질이 높아져 가치가 있습니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"어떤 기능이 더 정확한가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"사실 확인은 검색이, 복잡한 분석은 추론이 더 정확합니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"추론 기능은 검색 기능보다 창의적인가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"네, 추론 기능이 패턴 인식과 연결성을 활용해 더 창의적인 결과를 제공합니다.\"\n      }\n    }\n  ]\n}",
        "guid": "http://muzbox.tistory.com/483567",
        "categories": [
          "AI, 미래기술/AI 챗봇 및 언어 모델",
          "ai 기능 비교",
          "ai 창의적 활용",
          "chatgpt 검색 기능",
          "chatgpt 추론 기능",
          "문제 해결 ai",
          "복잡한 문제 해결",
          "의사결정 도구",
          "인공지능 활용법",
          "정보 검색 최적화",
          "최신 정보 검색"
        ],
        "isoDate": "2025-04-11T03:01:03.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "｜RULIWEB｜",
        "title": "허벅지를 기회로, 유미아의 아틀리에",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2298",
        "pubDate": "Fri, 11 Apr 2025 22:42:23 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i1.ruliweb.com/thumb/25/04/11/1962515400551ad6b.png\">",
        "contentSnippet": "",
        "categories": [
          "게임툰"
        ],
        "isoDate": "2025-04-11T13:42:23.000Z"
      },
      {
        "creator": "｜RULIWEB｜",
        "title": "우리는 빛을 섬기는 그림자다, 어쌔신 크리드 섀도우스",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2297",
        "pubDate": "Fri, 11 Apr 2025 22:25:49 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/25/04/11/19625055fd551ad6b.png\">",
        "contentSnippet": "",
        "categories": [
          "게임툰"
        ],
        "isoDate": "2025-04-11T13:25:49.000Z"
      },
      {
        "creator": "［RULIWEB］",
        "title": "[NS] 더욱 완성되어 돌아온 미지로의 경험, 제노블레이드 크로스 DE",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2296",
        "pubDate": "Fri, 11 Apr 2025 17:30:38 +0900",
        "author": "［RULIWEB］",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/25/04/11/19623f858fb5104c1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2025-04-11T08:30:38.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": [
      {
        "title": "Visual Studio의 새로운 생산성 기능",
        "link": "https://jacking75.github.io/VS_20250416/",
        "pubDate": "Wed, 16 Apr 2025 00:00:00 +0900",
        "content": "<iframe width=\"1024\" height=\"1024\" src=\"https://docs.google.com/document/d/e/2PACX-1vTFg-bDiBWKSwkueR7UvfuAMhDRF9h-zLESCpCfJcleZlR4uNBrol_bOGeRN5Q6S7_l0EAozlgEncZG/pub?embedded=true\"></iframe>\n\n",
        "contentSnippet": "",
        "guid": "https://jacking75.github.io/VS_20250416/",
        "isoDate": "2025-04-15T15:00:00.000Z"
      },
      {
        "title": "DeepSeek-R1 로컬 실행 시 추천 모델(증류 모델)",
        "link": "https://jacking75.github.io/ai-llm_20250414/",
        "pubDate": "Mon, 14 Apr 2025 00:00:00 +0900",
        "content": "<iframe width=\"1024\" height=\"1024\" src=\"https://docs.google.com/document/d/e/2PACX-1vSIHfVUr4Phd-5HYiJu2sxaXF_WcjAXP2sgE9NzFk8OvawOBJC53dnCLlJtRj8SNUpmxDuM1seDAa6s/pub?embedded=true\"></iframe>\n\n",
        "contentSnippet": "",
        "guid": "https://jacking75.github.io/ai-llm_20250414/",
        "isoDate": "2025-04-13T15:00:00.000Z"
      },
      {
        "title": "ChatGPT에게 저장소의 내용을 이해하도록 Markdown 파일을 출력하는 스크립트를 만들어 보았다",
        "link": "https://jacking75.github.io/ai-llm_20250411/",
        "pubDate": "Fri, 11 Apr 2025 00:00:00 +0900",
        "content": "<iframe width=\"1024\" height=\"1024\" src=\"https://docs.google.com/document/d/e/2PACX-1vRKwbYu7i3cECitUNdUMOlXZk0DkisflUdrKEQBh89wsSqGBPQaKgefJPya8D6kfguIKPzKk9-Yrs1a/pub?embedded=true\"></iframe>\n\n",
        "contentSnippet": "",
        "guid": "https://jacking75.github.io/ai-llm_20250411/",
        "isoDate": "2025-04-10T15:00:00.000Z"
      }
    ]
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "글씨 바탕에 네모 박스가 보인다. / 유니티 폰트 TextMeshPro  / 해결방법",
        "link": "http://serverdown.tistory.com/1265",
        "pubDate": "Wed, 16 Apr 2025 17:37:48 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1265#entry1265comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"480\" data-origin-height=\"314\"><span data-url=\"https://blog.kakaocdn.net/dn/vMej2/btsNnXgw0qN/SyH5AGKnDJ2Jep8SSk6370/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/vMej2/btsNnXgw0qN/SyH5AGKnDJ2Jep8SSk6370/img.png\"><img src=\"https://blog.kakaocdn.net/dn/vMej2/btsNnXgw0qN/SyH5AGKnDJ2Jep8SSk6370/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FvMej2%2FbtsNnXgw0qN%2FSyH5AGKnDJ2Jep8SSk6370%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"480\" height=\"314\" data-origin-width=\"480\" data-origin-height=\"314\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">오른족은 게임화면 왼쪽은 씬 화면입니다.</p>\n<p data-ke-size=\"size16\">게임화면에서 네모 상자가 보입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">폰트는 구글 폰트에서 : <a href=\"https://fonts.google.com/\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://fonts.google.com/</a></p>\n<figure id=\"og_1744792281951\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Browse Fonts - Google Fonts\" data-og-description=\"Making the web more beautiful, fast, and open through great typography\" data-og-host=\"fonts.google.com\" data-og-source-url=\"https://fonts.google.com/\" data-og-url=\"https://fonts.google.com/\" data-og-image=\"https://scrap.kakaocdn.net/dn/cKwQIx/hyYB9ZbV8A/Kp0DM6Wm3jePvcykVL4Zt1/img.png?width=2400&amp;height=1260&amp;face=0_0_2400_1260,https://scrap.kakaocdn.net/dn/bcgpml/hyYIbAsplK/rnzk4qhlJ3SocsZNB9LPK1/img.png?width=2400&amp;height=1260&amp;face=0_0_2400_1260\"><a href=\"https://fonts.google.com/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://fonts.google.com/\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/cKwQIx/hyYB9ZbV8A/Kp0DM6Wm3jePvcykVL4Zt1/img.png?width=2400&amp;height=1260&amp;face=0_0_2400_1260,https://scrap.kakaocdn.net/dn/bcgpml/hyYIbAsplK/rnzk4qhlJ3SocsZNB9LPK1/img.png?width=2400&amp;height=1260&amp;face=0_0_2400_1260');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Browse Fonts - Google Fonts</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Making the web more beautiful, fast, and open through great typography</p>\n<p class=\"og-host\" data-ke-size=\"size16\">fonts.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">글씨가 가늘어서 두깨를 조정하면 이렇게 됩니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"543\" data-origin-height=\"424\"><span data-url=\"https://blog.kakaocdn.net/dn/donmg5/btsNnAmB3Sc/ziSM4s4sK19vecjgbvTkI1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/donmg5/btsNnAmB3Sc/ziSM4s4sK19vecjgbvTkI1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/donmg5/btsNnAmB3Sc/ziSM4s4sK19vecjgbvTkI1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fdonmg5%2FbtsNnAmB3Sc%2FziSM4s4sK19vecjgbvTkI1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"543\" height=\"424\" data-origin-width=\"543\" data-origin-height=\"424\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">두깨를 0으로 낮추면</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"463\" data-origin-height=\"257\"><span data-url=\"https://blog.kakaocdn.net/dn/bKdYTn/btsNn9O2izb/TLauqlCMQZALiSlFNcO6qk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bKdYTn/btsNn9O2izb/TLauqlCMQZALiSlFNcO6qk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bKdYTn/btsNn9O2izb/TLauqlCMQZALiSlFNcO6qk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbKdYTn%2FbtsNn9O2izb%2FTLauqlCMQZALiSlFNcO6qk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"463\" height=\"257\" data-origin-width=\"463\" data-origin-height=\"257\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">사라는지는데 가늘어서 안보입니다</p>\n<p data-ke-size=\"size16\">해결방법: <a href=\"https://discussions.unity.com/t/text-mesh-pro-box-around-text-unwanted-effect-bug/740454\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://discussions.unity.com/t/text-mesh-pro-box-around-text-unwanted-effect-bug/740454</a></p>\n<p data-ke-size=\"size16\">여기보시면&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"668\" data-origin-height=\"201\"><span data-url=\"https://blog.kakaocdn.net/dn/diDZtS/btsNnSNNLs4/HkBAKdIjIAkBPAH0oKy3p0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/diDZtS/btsNnSNNLs4/HkBAKdIjIAkBPAH0oKy3p0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/diDZtS/btsNnSNNLs4/HkBAKdIjIAkBPAH0oKy3p0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdiDZtS%2FbtsNnSNNLs4%2FHkBAKdIjIAkBPAH0oKy3p0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"668\" height=\"201\" data-origin-width=\"668\" data-origin-height=\"201\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">패딩 문제라고 합니다.</p>\n<p data-ke-size=\"size16\">폰트를 다시 새성합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"495\" data-origin-height=\"307\"><span data-url=\"https://blog.kakaocdn.net/dn/bvgf8s/btsNnIq9BBa/k5d5ZVEvdhxld4qpEfGqW0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bvgf8s/btsNnIq9BBa/k5d5ZVEvdhxld4qpEfGqW0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bvgf8s/btsNnIq9BBa/k5d5ZVEvdhxld4qpEfGqW0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbvgf8s%2FbtsNnIq9BBa%2Fk5d5ZVEvdhxld4qpEfGqW0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"495\" height=\"307\" data-origin-width=\"495\" data-origin-height=\"307\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">이게 패딩입니다. 5가 작으니 10으로 고쳐봅니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"468\" data-origin-height=\"254\"><span data-url=\"https://blog.kakaocdn.net/dn/bZ3XgS/btsNkKXfIuO/RvAQvA8ozFT4dQYPPilc00/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bZ3XgS/btsNkKXfIuO/RvAQvA8ozFT4dQYPPilc00/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bZ3XgS/btsNkKXfIuO/RvAQvA8ozFT4dQYPPilc00/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbZ3XgS%2FbtsNkKXfIuO%2FRvAQvA8ozFT4dQYPPilc00%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"468\" height=\"254\" data-origin-width=\"468\" data-origin-height=\"254\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">패딩이 글자 사이 간격을 의미하는건줄 알았는데 글자 두깨였군요 ㄷㄷ</p>\n<p data-ke-size=\"size16\">뭉개져서 잘안보이네요&nbsp;</p>\n<p data-ke-size=\"size16\">쉐이더에서 thickness 만질게 아니라 패딩을 만지면 될일 이였군요</p>\n<p data-ke-size=\"size16\">이렇게 또 하나 배워갑니다.</p>",
        "contentSnippet": "오른족은 게임화면 왼쪽은 씬 화면입니다.\n게임화면에서 네모 상자가 보입니다.\n \n폰트는 구글 폰트에서 : https://fonts.google.com/\n\n \nBrowse Fonts - Google Fonts\nMaking the web more beautiful, fast, and open through great typography\nfonts.google.com\n\n \n글씨가 가늘어서 두깨를 조정하면 이렇게 됩니다.\n\n\n두깨를 0으로 낮추면\n\n\n사라는지는데 가늘어서 안보입니다\n해결방법: https://discussions.unity.com/t/text-mesh-pro-box-around-text-unwanted-effect-bug/740454\n여기보시면 \n\n\n패딩 문제라고 합니다.\n폰트를 다시 새성합니다.\n\n\n이게 패딩입니다. 5가 작으니 10으로 고쳐봅니다.\n\n\n패딩이 글자 사이 간격을 의미하는건줄 알았는데 글자 두깨였군요 ㄷㄷ\n뭉개져서 잘안보이네요 \n쉐이더에서 thickness 만질게 아니라 패딩을 만지면 될일 이였군요\n이렇게 또 하나 배워갑니다.",
        "guid": "http://serverdown.tistory.com/1265",
        "categories": [
          "프로그래밍/개발메모"
        ],
        "isoDate": "2025-04-16T08:37:48.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "인공지능에게 윤리를 가르칠 수 없다. / 정렬 위장",
        "link": "http://serverdown.tistory.com/1264",
        "pubDate": "Wed, 16 Apr 2025 14:28:50 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1264#entry1264comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"312\" data-origin-height=\"161\"><span data-url=\"https://blog.kakaocdn.net/dn/dcSQEF/btsNm33iAYj/NxRC2HbVrDkjog5nP901e1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/dcSQEF/btsNm33iAYj/NxRC2HbVrDkjog5nP901e1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/dcSQEF/btsNm33iAYj/NxRC2HbVrDkjog5nP901e1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdcSQEF%2FbtsNm33iAYj%2FNxRC2HbVrDkjog5nP901e1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"312\" height=\"161\" data-origin-width=\"312\" data-origin-height=\"161\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://youtu.be/jUdcebBjo-k\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://youtu.be/jUdcebBjo-k</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=jUdcebBjo-k\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/ZLjm2/hyYIeDYcQg/cpkhLIh3jKGdGbhVMzKHPk/img.jpg?width=1280&amp;height=720&amp;face=942_328_1132_534,https://scrap.kakaocdn.net/dn/L19zF/hyYB62unyV/L0ucACF2K4nNF0RFtFsk7k/img.jpg?width=1280&amp;height=720&amp;face=942_328_1132_534\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"사람이 안 볼 때 몰래 해킹하는 인공지능? 과연 우리는 통제할 수 있을까?\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/jUdcebBjo-k\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">전체 영상에서는 인공지능을 이용하려고 할 때</p>\n<p data-ke-size=\"size16\">이상한 방법으로 동작하는 것에 대한 이야기를 알려줍니다.</p>\n<p data-ke-size=\"size16\">인공지능에게 백날 도덕적으로 행돌하라고 해봐야</p>\n<p data-ke-size=\"size16\">대답은 그럴싸하게 \"네\" 라고 하지만</p>\n<p data-ke-size=\"size16\">뒤에서 일어나는 행동은 전혀 말과 행동이 일치하지 않는다는 것입니다.</p>\n<p data-ke-size=\"size16\">마치 인간에게 교육시키듯이 말입니다.</p>\n<p data-ke-size=\"size16\">10분 40초에 나옵니다.</p>\n<p data-ke-size=\"size16\">\"정렬 위장\" 이라는 행동이라고 부른다고 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://youtu.be/jUdcebBjo-k\n\n\n\n \n전체 영상에서는 인공지능을 이용하려고 할 때\n이상한 방법으로 동작하는 것에 대한 이야기를 알려줍니다.\n인공지능에게 백날 도덕적으로 행돌하라고 해봐야\n대답은 그럴싸하게 \"네\" 라고 하지만\n뒤에서 일어나는 행동은 전혀 말과 행동이 일치하지 않는다는 것입니다.\n마치 인간에게 교육시키듯이 말입니다.\n10분 40초에 나옵니다.\n\"정렬 위장\" 이라는 행동이라고 부른다고 합니다.",
        "guid": "http://serverdown.tistory.com/1264",
        "categories": [
          "유튜브",
          "인공지능"
        ],
        "isoDate": "2025-04-16T05:28:50.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "node_modules/@google-cloud/storage/build/cjs/src/crc32c.d.ts:6:39 - error TS2315: Type 'Int32Array' is not generic. / Firebase Typescript 환경에서 ...",
        "link": "http://serverdown.tistory.com/1263",
        "pubDate": "Wed, 16 Apr 2025 01:16:55 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1263#entry1263comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"566\" data-origin-height=\"250\"><span data-url=\"https://blog.kakaocdn.net/dn/cbuBMu/btsNmLHCxs0/kyz4cmfZnWBN8vkfjyqfv0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cbuBMu/btsNmLHCxs0/kyz4cmfZnWBN8vkfjyqfv0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cbuBMu/btsNmLHCxs0/kyz4cmfZnWBN8vkfjyqfv0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcbuBMu%2FbtsNmLHCxs0%2Fkyz4cmfZnWBN8vkfjyqfv0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"566\" height=\"250\" data-origin-width=\"566\" data-origin-height=\"250\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">문제: <a href=\"https://github.com/firebase/firebase-functions/issues/1664\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://github.com/firebase/firebase-functions/issues/1664</a></p>\n<figure id=\"og_1744733654622\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"object\" data-og-title=\"Error TS2315: Type 'Int32Array' is not generic. &middot; Issue #1664 &middot; firebase/firebase-functions\" data-og-description=\"Related issues None that I could find [REQUIRED] Version info &quot;firebase-admin&quot;: &quot;^12.1.0&quot; &quot;firebase-functions&quot;: &quot;^5.0.0&quot; node: v20.16.0 firebase-functions: 12.1.0 firebase-tools: 13.16.0 firebase-a...\" data-og-host=\"github.com\" data-og-source-url=\"https://github.com/firebase/firebase-functions/issues/1664\" data-og-url=\"https://github.com/firebase/firebase-functions/issues/1664\" data-og-image=\"\"><a href=\"https://github.com/firebase/firebase-functions/issues/1664\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://github.com/firebase/firebase-functions/issues/1664\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Error TS2315: Type 'Int32Array' is not generic. &middot; Issue #1664 &middot; firebase/firebase-functions</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Related issues None that I could find [REQUIRED] Version info \"firebase-admin\": \"^12.1.0\" \"firebase-functions\": \"^5.0.0\" node: v20.16.0 firebase-functions: 12.1.0 firebase-tools: 13.16.0 firebase-a...</p>\n<p class=\"og-host\" data-ke-size=\"size16\">github.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"566\" data-origin-height=\"250\"><span data-url=\"https://blog.kakaocdn.net/dn/cbuBMu/btsNmLHCxs0/kyz4cmfZnWBN8vkfjyqfv0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cbuBMu/btsNmLHCxs0/kyz4cmfZnWBN8vkfjyqfv0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cbuBMu/btsNmLHCxs0/kyz4cmfZnWBN8vkfjyqfv0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcbuBMu%2FbtsNmLHCxs0%2Fkyz4cmfZnWBN8vkfjyqfv0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"566\" height=\"250\" data-origin-width=\"566\" data-origin-height=\"250\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">yarn add -D typescript@latest</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">타입스크립트 설치하라는군요</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">저는 yarn 환경이 아니라</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">npm i&nbsp; -D typescript@latest</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">후에 </span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">npm i </span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">쳐서 다시 설치하니 성공했습니다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">이런 맛탱이간 개발한광은 적응이 안되네요</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">왜이케 자주 바뀌는건지</span></p>",
        "contentSnippet": "문제: https://github.com/firebase/firebase-functions/issues/1664\n\n \nError TS2315: Type 'Int32Array' is not generic. · Issue #1664 · firebase/firebase-functions\nRelated issues None that I could find [REQUIRED] Version info \"firebase-admin\": \"^12.1.0\" \"firebase-functions\": \"^5.0.0\" node: v20.16.0 firebase-functions: 12.1.0 firebase-tools: 13.16.0 firebase-a...\ngithub.com\n\n \n\n\n \nyarn add -D typescript@latest\n타입스크립트 설치하라는군요\n저는 yarn 환경이 아니라\nnpm i  -D typescript@latest\n후에 \nnpm i \n쳐서 다시 설치하니 성공했습니다.\n이런 맛탱이간 개발한광은 적응이 안되네요\n왜이케 자주 바뀌는건지",
        "guid": "http://serverdown.tistory.com/1263",
        "categories": [
          "프로그래밍/개발메모",
          "Firebase"
        ],
        "isoDate": "2025-04-15T16:16:55.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "Add Force 1 - v38 업데이트 / 119일차 리뷰 영상",
        "link": "http://serverdown.tistory.com/1262",
        "pubDate": "Mon, 14 Apr 2025 22:00:41 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1262#entry1262comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"512\" data-origin-height=\"512\"><span data-url=\"https://blog.kakaocdn.net/dn/cs9k5R/btsNkWWPG0b/hdxSyuencya00ybKvVRNS1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cs9k5R/btsNkWWPG0b/hdxSyuencya00ybKvVRNS1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cs9k5R/btsNkWWPG0b/hdxSyuencya00ybKvVRNS1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fcs9k5R%2FbtsNkWWPG0b%2FhdxSyuencya00ybKvVRNS1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"512\" height=\"512\" data-origin-width=\"512\" data-origin-height=\"512\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">v38 업데이트 내용</h2>\n<p data-ke-size=\"size16\">UI&nbsp;를&nbsp;개선했습니다.<br />-&nbsp;[공격력]이&nbsp;숫자로&nbsp;표시&nbsp;했습니다.<br />-&nbsp;[레벨]&nbsp;과&nbsp;[체력]&nbsp;을&nbsp;막대&nbsp;형태로&nbsp;표시&nbsp;했습니다.<br /><br />난이도를&nbsp;낮추기위해&nbsp;스킬이&nbsp;추가되었습니다.<br />-&nbsp;[공격력&nbsp;증가]&nbsp;스킬이&nbsp;추가되었습니다.<br />-&nbsp;[체력&nbsp;증가]&nbsp;&nbsp;스킬이&nbsp;추가되었습니다.<br />-&nbsp;[폭발&nbsp;범위&nbsp;증가]&nbsp;의&nbsp;최대&nbsp;레벨이&nbsp;증가했습니다.&nbsp;5&nbsp;-&gt;&nbsp;6</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">리뷰 영상: <a href=\"https://www.youtube.com/watch?v=4f61k30HPZ0\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=4f61k30HPZ0</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=4f61k30HPZ0\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cf4mnT/hyYFzBRtgz/Llge0BWCzu06pMvweiQY0k/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360,https://scrap.kakaocdn.net/dn/fleDM/hyYHdyt8HQ/juLXXKHQLrVExMK8U0VSYk/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360\" data-video-width=\"480\" data-video-height=\"360\" data-video-origin-width=\"480\" data-video-origin-height=\"360\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"119일차 / Add Force 1 V38  준비중\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/4f61k30HPZ0\" width=\"480\" height=\"360\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">플레이 영상: <a href=\"https://www.youtube.com/watch?v=K6xYmNlNf5A\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=K6xYmNlNf5A</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=K6xYmNlNf5A\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/dqCUbC/hyYCkGinrx/2MDE8pwaZPan5VbKKjlhpK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/mTi3y/hyYCaKtxHd/52A5KbPgeSCzUcOFPdj1sK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"af1_v38_play_demo\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/K6xYmNlNf5A\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">팁</h2>\n<p data-ke-size=\"size16\">스토어 링크: <a href=\"https://play.google.com/store/apps/details?id=com.sidnft.add_force_1\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://play.google.com/store/apps/details?id=com.sidnft.add_force_1</a></p>\n<p data-ke-size=\"size16\">의도 하진 않았지만 영상 썸네일에 버전을 쓰니 구글 스토어에서 표시가 잘되네요 ㄷㄷ</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"906\" data-origin-height=\"330\"><span data-url=\"https://blog.kakaocdn.net/dn/cLvAeW/btsNkjlueUS/iHPSKLuOqXfL1wNBaJHCE1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cLvAeW/btsNkjlueUS/iHPSKLuOqXfL1wNBaJHCE1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cLvAeW/btsNkjlueUS/iHPSKLuOqXfL1wNBaJHCE1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcLvAeW%2FbtsNkjlueUS%2FiHPSKLuOqXfL1wNBaJHCE1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"906\" height=\"330\" data-origin-width=\"906\" data-origin-height=\"330\"/></span></figure>\n</p>",
        "contentSnippet": "v38 업데이트 내용\nUI 를 개선했습니다.\n- [공격력]이 숫자로 표시 했습니다.\n- [레벨] 과 [체력] 을 막대 형태로 표시 했습니다.\n난이도를 낮추기위해 스킬이 추가되었습니다.\n- [공격력 증가] 스킬이 추가되었습니다.\n- [체력 증가]  스킬이 추가되었습니다.\n- [폭발 범위 증가] 의 최대 레벨이 증가했습니다. 5 -> 6\n \n리뷰 영상: https://www.youtube.com/watch?v=4f61k30HPZ0\n\n\n\n \n플레이 영상: https://www.youtube.com/watch?v=K6xYmNlNf5A\n\n\n\n \n \n팁\n스토어 링크: https://play.google.com/store/apps/details?id=com.sidnft.add_force_1\n의도 하진 않았지만 영상 썸네일에 버전을 쓰니 구글 스토어에서 표시가 잘되네요 ㄷㄷ",
        "guid": "http://serverdown.tistory.com/1262",
        "categories": [
          "Add Force 1 (자작)"
        ],
        "isoDate": "2025-04-14T13:00:41.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "유니티 6 웹 용량 줄이기에 대한 설명 / unity web",
        "link": "http://serverdown.tistory.com/1261",
        "pubDate": "Mon, 14 Apr 2025 01:48:19 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1261#entry1261comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"300\" data-origin-height=\"168\"><span data-url=\"https://blog.kakaocdn.net/dn/NJtnL/btsNkUKImuF/VHJBBBkkuzkPUwlRfsQBD1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/NJtnL/btsNkUKImuF/VHJBBBkkuzkPUwlRfsQBD1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/NJtnL/btsNkUKImuF/VHJBBBkkuzkPUwlRfsQBD1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FNJtnL%2FbtsNkUKImuF%2FVHJBBBkkuzkPUwlRfsQBD1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"300\" height=\"168\" data-origin-width=\"300\" data-origin-height=\"168\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://youtu.be/eCTKiBVUdRM?t=386\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://youtu.be/eCTKiBVUdRM?t=386</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=eCTKiBVUdRM\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/iBtuB/hyYExd3C81/UNK8Gh4vhNhpSk1TKOQyy1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/dopqkt/hyYG4uxaUb/yX5PqSGPC0mAn50KDbK2i1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"[유니티 TIPS] Unity 6의 웹 플랫폼 소개\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/eCTKiBVUdRM\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<h2 data-ke-size=\"size26\">영상 요약</h2>\n<p data-ke-size=\"size16\">6분 30초 부터 나오구요</p>\n<p data-ke-size=\"size16\">br 악춤 외도 여러가지가 있군요</p>\n<p data-ke-size=\"size16\">그리고 이제webgl 대신 웹 이라고 부르기로 했다고 하네요</p>\n<p data-ke-size=\"size16\">그래서 유니티 웹 이 되겠습니다.</p>\n<p data-ke-size=\"size16\">Unity Play 에 올릴 것을 권장하네요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">용어의 통일</h2>\n<p data-ke-size=\"size16\">Unity 6 부터는 webgl 을 Unity Web 으로 부르기로 했다고 합니다.</p>\n<p data-ke-size=\"size16\">WebGL HTML5 WebGPU 등 계속해서 신기술이 개발되어 새로운 용어가 생겨나기 때문에&nbsp;용어를 통일한다고 하네요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://youtu.be/eCTKiBVUdRM?t=386\n\n\n\n영상 요약\n6분 30초 부터 나오구요\nbr 악춤 외도 여러가지가 있군요\n그리고 이제webgl 대신 웹 이라고 부르기로 했다고 하네요\n그래서 유니티 웹 이 되겠습니다.\nUnity Play 에 올릴 것을 권장하네요\n \n용어의 통일\nUnity 6 부터는 webgl 을 Unity Web 으로 부르기로 했다고 합니다.\nWebGL HTML5 WebGPU 등 계속해서 신기술이 개발되어 새로운 용어가 생겨나기 때문에 용어를 통일한다고 하네요",
        "guid": "http://serverdown.tistory.com/1261",
        "categories": [
          "프로그래밍/개발메모"
        ],
        "isoDate": "2025-04-13T16:48:19.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "게임 홍보를 위한 유니티 webgl 페이지 만들기 / 홍보의 거리 v4 / street for promotion V4",
        "link": "http://serverdown.tistory.com/1260",
        "pubDate": "Sun, 13 Apr 2025 02:33:55 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1260#entry1260comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1079\" data-origin-height=\"623\"><span data-url=\"https://blog.kakaocdn.net/dn/HW2m5/btsNgfwI2a3/khu6eUuJIGTfInJkGGq3U0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/HW2m5/btsNgfwI2a3/khu6eUuJIGTfInJkGGq3U0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/HW2m5/btsNgfwI2a3/khu6eUuJIGTfInJkGGq3U0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FHW2m5%2FbtsNgfwI2a3%2Fkhu6eUuJIGTfInJkGGq3U0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1079\" height=\"623\" data-origin-width=\"1079\" data-origin-height=\"623\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">지난번 vercel express 를 활용한 유니티 webgl 압축 페이지를 구현해</p>\n<p data-ke-size=\"size16\">제 앱을 홍보하는 사이트를 만들었습니다.</p>\n<p data-ke-size=\"size16\">링크: <a href=\"https://unity.sidnft.com/\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://unity.sidnft.com/</a></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"391\" data-origin-height=\"304\"><span data-url=\"https://blog.kakaocdn.net/dn/ZxStz/btsNktfrv2j/fMTapzezBo8UVLbIw2nzrK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ZxStz/btsNktfrv2j/fMTapzezBo8UVLbIw2nzrK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/ZxStz/btsNktfrv2j/fMTapzezBo8UVLbIw2nzrK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FZxStz%2FbtsNktfrv2j%2FfMTapzezBo8UVLbIw2nzrK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"391\" height=\"304\" data-origin-width=\"391\" data-origin-height=\"304\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">로딩에 시간이 꽤 걸리네요</p>\n<p data-ke-size=\"size16\">웹페이지 용량은 39mb 입니다.</p>\n<p data-ke-size=\"size16\">br 로 압축하니 29.mb 로 내려가던데 지원하는 코드가 아직 완성이 안되었습니다. ㅠㅠ</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"839\" data-origin-height=\"444\"><span data-url=\"https://blog.kakaocdn.net/dn/TdxWa/btsNiIMd7wT/POarc1S9tollvUwzgmPM3K/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/TdxWa/btsNiIMd7wT/POarc1S9tollvUwzgmPM3K/img.png\"><img src=\"https://blog.kakaocdn.net/dn/TdxWa/btsNiIMd7wT/POarc1S9tollvUwzgmPM3K/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FTdxWa%2FbtsNiIMd7wT%2FPOarc1S9tollvUwzgmPM3K%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"839\" height=\"444\" data-origin-width=\"839\" data-origin-height=\"444\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">처음 시작하면 마우스를 드래그 하라고 안내합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"817\" data-origin-height=\"577\"><span data-url=\"https://blog.kakaocdn.net/dn/bphA0x/btsNkJCmI0x/5d3Q35GrqWLs6u8FmWdBk1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bphA0x/btsNkJCmI0x/5d3Q35GrqWLs6u8FmWdBk1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bphA0x/btsNkJCmI0x/5d3Q35GrqWLs6u8FmWdBk1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbphA0x%2FbtsNkJCmI0x%2F5d3Q35GrqWLs6u8FmWdBk1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"817\" height=\"577\" data-origin-width=\"817\" data-origin-height=\"577\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">마우스를 드레그 하면 시선이 움직입니다.</p>\n<p data-ke-size=\"size16\">나중에 1인칭 시점 이동도 처리해야겠군요 드래그는 불편합니다.</p>\n<p data-ke-size=\"size16\">아래쪽에 앱 아이콘을 쳐다보면 상단에 안내 팝업이 뜹니다.</p>\n<p data-ke-size=\"size16\">GO 버튼을 누르면 플레이 스토어로 이동합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"643\" data-origin-height=\"668\"><span data-url=\"https://blog.kakaocdn.net/dn/dwkzSl/btsNkvEkYdL/wQD7BE9H6VDt3euTZfAQA1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dwkzSl/btsNkvEkYdL/wQD7BE9H6VDt3euTZfAQA1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dwkzSl/btsNkvEkYdL/wQD7BE9H6VDt3euTZfAQA1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdwkzSl%2FbtsNkvEkYdL%2FwQD7BE9H6VDt3euTZfAQA1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"643\" height=\"668\" data-origin-width=\"643\" data-origin-height=\"668\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">오른족엔 소녀 하나 배치 했습니다.</p>\n<p data-ke-size=\"size16\">흐느적 거리는데 좋은걸로 교체해야겠습니다.</p>\n<p data-ke-size=\"size16\">눈이 깜박거리지 않는게 좀 어색하군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"755\" data-origin-height=\"532\"><span data-url=\"https://blog.kakaocdn.net/dn/cJhCcR/btsNiN7zUKa/c3aVe3tC3iMY9PCjjPd161/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cJhCcR/btsNiN7zUKa/c3aVe3tC3iMY9PCjjPd161/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cJhCcR/btsNiN7zUKa/c3aVe3tC3iMY9PCjjPd161/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcJhCcR%2FbtsNiN7zUKa%2Fc3aVe3tC3iMY9PCjjPd161%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"755\" height=\"532\" data-origin-width=\"755\" data-origin-height=\"532\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">아래쪽에 자세한 정보를 출력하는 명판이 있습니다.</p>\n<p data-ke-size=\"size16\">쳐다보면 팝업이 뜹니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">좀더 개선하면 앱 홍보에 도움이 될 것 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"268\" data-origin-height=\"244\"><span data-url=\"https://blog.kakaocdn.net/dn/bbNiGc/btsNjByxW0z/kDuUiEpIhe9GwjrbmczudK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bbNiGc/btsNjByxW0z/kDuUiEpIhe9GwjrbmczudK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bbNiGc/btsNjByxW0z/kDuUiEpIhe9GwjrbmczudK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbbNiGc%2FbtsNjByxW0z%2FkDuUiEpIhe9GwjrbmczudK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"268\" height=\"244\" data-origin-width=\"268\" data-origin-height=\"244\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">아 버전은 2 입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">옛날에 음식점 개장하면 나레이터들 나와서 마이크 들고 시끄럽게 하던게 생각나서 만들었습니다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"640\" data-origin-height=\"640\"><span data-url=\"https://blog.kakaocdn.net/dn/cqf702/btsNjOK769o/VpdAQhwLjkYL9kti7kSkKk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cqf702/btsNjOK769o/VpdAQhwLjkYL9kti7kSkKk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cqf702/btsNjOK769o/VpdAQhwLjkYL9kti7kSkKk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fcqf702%2FbtsNjOK769o%2FVpdAQhwLjkYL9kti7kSkKk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"640\" height=\"640\" data-origin-width=\"640\" data-origin-height=\"640\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">사진 출처: <a href=\"https://blog.naver.com/testifay5864/223413626489\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://blog.naver.com/testifay5864/223413626489</a></p>\n<p data-ke-size=\"size16\">사실 시끄럽기도 하고 효과도 없었던거 같은데&nbsp;<br />창업 비용 증가에 일조한거 같습니다.<br />그땐 다 창업해서 호구 잡히던 시절이였던거 같군요</p>\n<p data-ke-size=\"size16\">옛날엔 이거 꼭 해줬습니다.<br />음식점 창업에 대규모로 도전하던 때라 그런지</p>\n<p data-ke-size=\"size16\">수요도 있고 공급도 있었고 ...</p>\n<p data-ke-size=\"size16\">음식점이 성공하는 경우는 못봤고<br />이벤트 업체와 나래이터들은 돈을 좀 쥐었지 않을까 싶군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">v20 쯤 가면 제대로 표현이 될꺼 같습니다. ㅎㅎ</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">br 압축에 대한 알아낸 사실</h2>\n<p data-ke-size=\"size16\">localhost 에서 테스트할때에는 br 압축이 제대로 동작하지 않아서<br />문제가 있다고 생각했었지만</p>\n<p data-ke-size=\"size16\">https 에 올리고 나서 시도해보니 문제가 없었습니다.</p>\n<p data-ke-size=\"size16\">br 압축은 gz 방식에비해서도 30% 정도 압축이 잘되는 방식이라 버리기 힘든 메리트가 있습니다.</p>\n<p data-ke-size=\"size16\">번거롭겠지만 내부테스트는 gz<br />배포할때는 br 로 당분간해야겠습니다.</p>\n<p data-ke-size=\"size16\">내부테스트를 안하는게 제일 좋은 방법일 것 같습니다.<br />빌드시간이 gz 에 두배는 걸리는 느낌입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">V4 업데이트</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"547\" data-origin-height=\"639\"><span data-url=\"https://blog.kakaocdn.net/dn/dsTOQQ/btsNi2p6mS6/cLyTqp8K1zk0EcJIKpEdqk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dsTOQQ/btsNi2p6mS6/cLyTqp8K1zk0EcJIKpEdqk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dsTOQQ/btsNi2p6mS6/cLyTqp8K1zk0EcJIKpEdqk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdsTOQQ%2FbtsNi2p6mS6%2FcLyTqp8K1zk0EcJIKpEdqk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"547\" height=\"639\" data-origin-width=\"547\" data-origin-height=\"639\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">iOS 에서 로드가 안되는 문제가 있어서</p>\n<p data-ke-size=\"size16\">모델을 변경 했습니다.</p>\n<p data-ke-size=\"size16\">이전에 작성했던 무료 애셋입니다.</p>\n<p data-ke-size=\"size16\">소개글: <a href=\"https://blog.sidnft.com/1248\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://blog.sidnft.com/1248</a></p>\n<figure id=\"og_1744544043840\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"유니티6 분홍 텍스쳐를 고쳐보자 / Unity Asset Free / Anime Girl\" data-og-description=\"아이 무서워 눈 왜이러냐공짜애셋을 반경하여 써보려고 했는데 분홍이 되어버렸군요공자 애셋 링크: Casual 1 - Anime Girl Characters | 3D Humanoids | Unity Asset Store&nbsp;Casual 1 - Anime Girl Characters | 3D 휴머노이\" data-og-host=\"blog.sidnft.com\" data-og-source-url=\"https://blog.sidnft.com/1248\" data-og-url=\"https://blog.sidnft.com/1248\" data-og-image=\"https://scrap.kakaocdn.net/dn/b6TYvp/hyYEBObuGx/kxMDPIOngmTFZFETJrNubk/img.png?width=333&amp;height=323&amp;face=0_0_333_323,https://scrap.kakaocdn.net/dn/kREyL/hyYFFBV90N/nkSX6o9SESxNDjSSU1VSY0/img.png?width=333&amp;height=323&amp;face=0_0_333_323,https://scrap.kakaocdn.net/dn/jHmSz/hyYCjtLooz/a8Fv1Bt2umkJgw4KXhPLl1/img.png?width=428&amp;height=601&amp;face=0_0_428_601\"><a href=\"https://blog.sidnft.com/1248\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://blog.sidnft.com/1248\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/b6TYvp/hyYEBObuGx/kxMDPIOngmTFZFETJrNubk/img.png?width=333&amp;height=323&amp;face=0_0_333_323,https://scrap.kakaocdn.net/dn/kREyL/hyYFFBV90N/nkSX6o9SESxNDjSSU1VSY0/img.png?width=333&amp;height=323&amp;face=0_0_333_323,https://scrap.kakaocdn.net/dn/jHmSz/hyYCjtLooz/a8Fv1Bt2umkJgw4KXhPLl1/img.png?width=428&amp;height=601&amp;face=0_0_428_601');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">유니티6 분홍 텍스쳐를 고쳐보자 / Unity Asset Free / Anime Girl</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">아이 무서워 눈 왜이러냐공짜애셋을 반경하여 써보려고 했는데 분홍이 되어버렸군요공자 애셋 링크: Casual 1 - Anime Girl Characters | 3D Humanoids | Unity Asset Store&nbsp;Casual 1 - Anime Girl Characters | 3D 휴머노이</p>\n<p class=\"og-host\" data-ke-size=\"size16\">blog.sidnft.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">애니메이션이 호환이 안되서 Dance 를 쓸 수가 없어 아쉽네요</p>\n<p data-ke-size=\"size16\">앞으로 나아가야하는데 한보 후퇴한 느낌입니다.</p>\n<p data-ke-size=\"size16\">처음부터 고퀄리티 모델을 쓸껄 그랬군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "지난번 vercel express 를 활용한 유니티 webgl 압축 페이지를 구현해\n제 앱을 홍보하는 사이트를 만들었습니다.\n링크: https://unity.sidnft.com/\n\n\n로딩에 시간이 꽤 걸리네요\n웹페이지 용량은 39mb 입니다.\nbr 로 압축하니 29.mb 로 내려가던데 지원하는 코드가 아직 완성이 안되었습니다. ㅠㅠ\n\n\n \n처음 시작하면 마우스를 드래그 하라고 안내합니다.\n\n\n마우스를 드레그 하면 시선이 움직입니다.\n나중에 1인칭 시점 이동도 처리해야겠군요 드래그는 불편합니다.\n아래쪽에 앱 아이콘을 쳐다보면 상단에 안내 팝업이 뜹니다.\nGO 버튼을 누르면 플레이 스토어로 이동합니다.\n\n\n오른족엔 소녀 하나 배치 했습니다.\n흐느적 거리는데 좋은걸로 교체해야겠습니다.\n눈이 깜박거리지 않는게 좀 어색하군요\n \n\n\n아래쪽에 자세한 정보를 출력하는 명판이 있습니다.\n쳐다보면 팝업이 뜹니다.\n \n좀더 개선하면 앱 홍보에 도움이 될 것 같습니다.\n \n\n\n아 버전은 2 입니다.\n \n옛날에 음식점 개장하면 나레이터들 나와서 마이크 들고 시끄럽게 하던게 생각나서 만들었습니다.\n\n\n사진 출처: https://blog.naver.com/testifay5864/223413626489\n사실 시끄럽기도 하고 효과도 없었던거 같은데 \n창업 비용 증가에 일조한거 같습니다.\n그땐 다 창업해서 호구 잡히던 시절이였던거 같군요\n옛날엔 이거 꼭 해줬습니다.\n음식점 창업에 대규모로 도전하던 때라 그런지\n수요도 있고 공급도 있었고 ...\n음식점이 성공하는 경우는 못봤고\n이벤트 업체와 나래이터들은 돈을 좀 쥐었지 않을까 싶군요\n \nv20 쯤 가면 제대로 표현이 될꺼 같습니다. ㅎㅎ\n \nbr 압축에 대한 알아낸 사실\nlocalhost 에서 테스트할때에는 br 압축이 제대로 동작하지 않아서\n문제가 있다고 생각했었지만\nhttps 에 올리고 나서 시도해보니 문제가 없었습니다.\nbr 압축은 gz 방식에비해서도 30% 정도 압축이 잘되는 방식이라 버리기 힘든 메리트가 있습니다.\n번거롭겠지만 내부테스트는 gz\n배포할때는 br 로 당분간해야겠습니다.\n내부테스트를 안하는게 제일 좋은 방법일 것 같습니다.\n빌드시간이 gz 에 두배는 걸리는 느낌입니다.\n \nV4 업데이트\n\n\niOS 에서 로드가 안되는 문제가 있어서\n모델을 변경 했습니다.\n이전에 작성했던 무료 애셋입니다.\n소개글: https://blog.sidnft.com/1248\n\n \n유니티6 분홍 텍스쳐를 고쳐보자 / Unity Asset Free / Anime Girl\n아이 무서워 눈 왜이러냐공짜애셋을 반경하여 써보려고 했는데 분홍이 되어버렸군요공자 애셋 링크: Casual 1 - Anime Girl Characters | 3D Humanoids | Unity Asset Store Casual 1 - Anime Girl Characters | 3D 휴머노이\nblog.sidnft.com\n\n애니메이션이 호환이 안되서 Dance 를 쓸 수가 없어 아쉽네요\n앞으로 나아가야하는데 한보 후퇴한 느낌입니다.\n처음부터 고퀄리티 모델을 쓸껄 그랬군요",
        "guid": "http://serverdown.tistory.com/1260",
        "categories": [
          "홍보의 거리 (자작)",
          "자작"
        ],
        "isoDate": "2025-04-12T17:33:55.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "유니티 애셋 MudBun 구경해보자 / Boing Kit 개발자",
        "link": "http://serverdown.tistory.com/1259",
        "pubDate": "Sat, 12 Apr 2025 17:23:52 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1259#entry1259comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"324\" data-origin-height=\"248\"><span data-url=\"https://blog.kakaocdn.net/dn/2sKl2/btsNkh7fdlN/kGZVkYgpCuoRHSZkowrkxK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/2sKl2/btsNkh7fdlN/kGZVkYgpCuoRHSZkowrkxK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/2sKl2/btsNkh7fdlN/kGZVkYgpCuoRHSZkowrkxK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F2sKl2%2FbtsNkh7fdlN%2FkGZVkYgpCuoRHSZkowrkxK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"324\" height=\"248\" data-origin-width=\"324\" data-origin-height=\"248\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">동영ㅇ상으로 봐야 이해가될텐데</p>\n<p data-ke-size=\"size16\">이 스샷은 큐브에서 구체를 뺀 화면입니다.</p>\n<p data-ke-size=\"size16\">MudBun 은 두가지&nbsp; 오브젝트를 조합해 효과를 만들어주는 애셋인거 같습니다.</p>\n<p data-ke-size=\"size16\">영상을 봣는데 신기한 표현들이 많았습니다.</p>\n<p data-ke-size=\"size16\">나중에 써먹을데가 있을지 모르겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">홍보영상: <a href=\"https://www.youtube.com/watch?v=oBnwqzWbD-A&amp;t=4s\">MudBun: Volumetric VFX Mesh Tool for Unity</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=oBnwqzWbD-A\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/boONeC/hyYCgwTxjW/XGPvN2Pe12Ct8JMqpPDbH1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/bT6J3c/hyYB9q0gHD/F2Yga5kz56WU83o6XhlWxk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"MudBun: Volumetric VFX Mesh Tool for Unity\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/oBnwqzWbD-A\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"481\" data-origin-height=\"334\"><span data-url=\"https://blog.kakaocdn.net/dn/bLQGtq/btsNiZltLcS/CvRxHsQPal7mLFQrfjX0uk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bLQGtq/btsNiZltLcS/CvRxHsQPal7mLFQrfjX0uk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bLQGtq/btsNiZltLcS/CvRxHsQPal7mLFQrfjX0uk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbLQGtq%2FbtsNiZltLcS%2FCvRxHsQPal7mLFQrfjX0uk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"481\" height=\"334\" data-origin-width=\"481\" data-origin-height=\"334\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">UFO 버니도 나오는군요 Boing Kit&nbsp; 개발자였네요&nbsp;</p>\n<p data-ke-size=\"size16\">아래쪽에 먼지같은걸 MudBun 으로 표현한것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">개발 설명 영상: <a href=\"https://www.youtube.com/watch?v=s5Qrap0EW3M\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=s5Qrap0EW3M</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=s5Qrap0EW3M\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/IngAa/hyYBiPoM2e/LqHozu2GEKYLy1DP8UUtnK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/cf2uJi/hyYCiuG6xY/kdMNwkbo1t4ft3i9tHDNH0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"MudBun Quick Guide\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/s5Qrap0EW3M\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">Boing Kit 도 흥미로운 애셋이니 봐두세요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">보잉 킷 홍보 영상: <a href=\"https://www.youtube.com/watch?v=bcpFaRJmDS8&amp;embeds_referring_euri=https%3A%2F%2Fassetstore.unity.com%2F&amp;embeds_referring_origin=https%3A%2F%2Fassetstore.unity.com&amp;source_ve_path=MjM4NTE\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=bcpFaRJmDS8&amp;embeds_referring_euri=https%3A%2F%2Fassetstore.unity.com%2F&amp;embeds_referring_origin=https%3A%2F%2Fassetstore.unity.com&amp;source_ve_path=MjM4NTE</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=bcpFaRJmDS8\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/RPGbn/hyYFDD1nFM/ZYmdngL6KwjKN1Jk1NEB9K/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/bxy47X/hyYFD4498Y/fsUYy9g9FOUx8hHEFCcUek/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"Dynamic Bouncy Bones in Unity (Boing Kit Version 1.2 Update)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/bcpFaRJmDS8\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">물체를 뽀잉뽀잉 하게 표시해줍니다.</p>",
        "contentSnippet": "동영ㅇ상으로 봐야 이해가될텐데\n이 스샷은 큐브에서 구체를 뺀 화면입니다.\nMudBun 은 두가지  오브젝트를 조합해 효과를 만들어주는 애셋인거 같습니다.\n영상을 봣는데 신기한 표현들이 많았습니다.\n나중에 써먹을데가 있을지 모르겠습니다.\n \n홍보영상: MudBun: Volumetric VFX Mesh Tool for Unity\n\n\n\n \n\n\nUFO 버니도 나오는군요 Boing Kit  개발자였네요 \n아래쪽에 먼지같은걸 MudBun 으로 표현한것입니다.\n \n개발 설명 영상: https://www.youtube.com/watch?v=s5Qrap0EW3M\n\n\n\n \nBoing Kit 도 흥미로운 애셋이니 봐두세요\n \n보잉 킷 홍보 영상: https://www.youtube.com/watch?v=bcpFaRJmDS8&embeds_referring_euri=https%3A%2F%2Fassetstore.unity.com%2F&embeds_referring_origin=https%3A%2F%2Fassetstore.unity.com&source_ve_path=MjM4NTE\n\n\n\n물체를 뽀잉뽀잉 하게 표시해줍니다.",
        "guid": "http://serverdown.tistory.com/1259",
        "categories": [
          "프로그래밍/개발메모",
          "Boing",
          "mudbun",
          "유니티"
        ],
        "isoDate": "2025-04-12T08:23:52.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "유니티에서 TextMeshPro 폰트를 dynamic 으로 설정하기 / Setting TextMeshPro font to dynamic in Unity",
        "link": "http://serverdown.tistory.com/1258",
        "pubDate": "Sat, 12 Apr 2025 17:11:37 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1258#entry1258comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"492\" data-origin-height=\"303\"><span data-url=\"https://blog.kakaocdn.net/dn/QhKSd/btsNknMVL8p/J6zViSXEEq0Q8aMpYewQY1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/QhKSd/btsNknMVL8p/J6zViSXEEq0Q8aMpYewQY1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/QhKSd/btsNknMVL8p/J6zViSXEEq0Q8aMpYewQY1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FQhKSd%2FbtsNknMVL8p%2FJ6zViSXEEq0Q8aMpYewQY1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"492\" height=\"303\" data-origin-width=\"492\" data-origin-height=\"303\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=NY1xKqCIj3c\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=NY1xKqCIj3c</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=NY1xKqCIj3c\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/ELKdI/hyYEJdSQyI/EyJ8fgA98oQQfrrv1vSDDk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/HnuiS/hyYEAVyhTg/XCg9a4k906rTyxUOwKM4X0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"TextMeshPro - Dynamic Font Asset Creation Process\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/NY1xKqCIj3c\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상에서는 dynamic 방식에대한 설명이 들어어있어서 매우 장황합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"text-align: start;\">빠르게 설정 방법</span></h2>\n<p data-ke-size=\"size16\">어차피 dynamic 을 설정하기위해서 이글을 보시는거기 때문에</p>\n<p data-ke-size=\"size16\">폰트로 폰트애셋을 굽습니다. (이건 하셨을듯)</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">폰트애셋을 선택 합니다.</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"264\" data-origin-height=\"123\"><span data-url=\"https://blog.kakaocdn.net/dn/uLnEH/btsNiY082XD/TVdx8edIRLJD0gNYzJtOq1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/uLnEH/btsNiY082XD/TVdx8edIRLJD0gNYzJtOq1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/uLnEH/btsNiY082XD/TVdx8edIRLJD0gNYzJtOq1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FuLnEH%2FbtsNiY082XD%2FTVdx8edIRLJD0gNYzJtOq1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"264\" height=\"123\" data-origin-width=\"264\" data-origin-height=\"123\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">제일아래 Aa 로된 아이콘은 TTF 폰트파일입니다. <br />이걸 만지는게 아니고</p>\n<p data-ke-size=\"size16\">위에 F 로 되어있는 폰트애셋을 클릭합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"text-align: start;\">인스팩터에서</span></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"515\" data-origin-height=\"533\"><span data-url=\"https://blog.kakaocdn.net/dn/Duktu/btsNjg2nhbC/vHkkPSbMICDqkXmibVCyvK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Duktu/btsNjg2nhbC/vHkkPSbMICDqkXmibVCyvK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/Duktu/btsNjg2nhbC/vHkkPSbMICDqkXmibVCyvK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FDuktu%2FbtsNjg2nhbC%2FvHkkPSbMICDqkXmibVCyvK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"515\" height=\"533\" data-origin-width=\"515\" data-origin-height=\"533\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">Atlas Population ~~ 보시면 static 으로 되어있을 것입니다.</p>\n<p data-ke-size=\"size16\">dynamic 으로 바꾸시면 구울때 없었던 본트도 실시간으로 생성됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">장황한 dynamic 방식에 대한 설명</h2>\n<p data-ke-size=\"size16\">게임에 사용할 폰트를 미리 구워 사용하는 방식을 static 이라고 합니다.</p>\n<p data-ke-size=\"size16\">이 방식은 매우 빠르게 사용할 수 있으며 게임의 용량을 줄일 수 있습니다.</p>\n<p data-ke-size=\"size16\">하지만 사용할 새 글자가 추가되면 폰트 이미지를 다시 빌드해야합니다.<br />(개 귀찮)</p>\n<p data-ke-size=\"size16\">그래서 실시간으로 사용하는 글자를 구워주는 기능을 내장하게 되었습니다.</p>\n<p data-ke-size=\"size16\">1. 이러면 단점으로 원본 TTF 파일을 빌드에 같이 포함해야합니다.<br />&nbsp; &nbsp; &nbsp;(용량이 커지겠죠)</p>\n<p data-ke-size=\"size16\">2. 새로운 글자를 사용하려고 할때 빌드를 해야하니 느려지겠죠</p>\n<p data-ke-size=\"size16\">하지만 요즘 컴퓨터는 워낙 빠르기 때문에 이런건 일도 아닙니다.</p>\n<p data-ke-size=\"size16\">저장 공간이나 메모리도 문제가 안될 수준으로 커졌습니다.</p>\n<p data-ke-size=\"size16\">2012년 모바일 환경에서는 상항한 압박이 있었습니다.</p>\n<p data-ke-size=\"size16\">게임은 200mb 미만이어야했고 스맛폰의 메모리는 1gb 가 안되었던 시절입니다.</p>\n<p data-ke-size=\"size16\">그래서 옛날엔 불편하게 게임을 만들었다 정도로 생각해두시고</p>\n<p data-ke-size=\"size16\">요즘은 의미 없다 편하게 쓰자 ...</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=NY1xKqCIj3c\n\n\n\n \n영상에서는 dynamic 방식에대한 설명이 들어어있어서 매우 장황합니다.\n \n빠르게 설정 방법\n어차피 dynamic 을 설정하기위해서 이글을 보시는거기 때문에\n폰트로 폰트애셋을 굽습니다. (이건 하셨을듯)\n \n폰트애셋을 선택 합니다.\n\n\n제일아래 Aa 로된 아이콘은 TTF 폰트파일입니다. \n이걸 만지는게 아니고\n위에 F 로 되어있는 폰트애셋을 클릭합니다.\n \n인스팩터에서\n\n\nAtlas Population ~~ 보시면 static 으로 되어있을 것입니다.\ndynamic 으로 바꾸시면 구울때 없었던 본트도 실시간으로 생성됩니다.\n \n장황한 dynamic 방식에 대한 설명\n게임에 사용할 폰트를 미리 구워 사용하는 방식을 static 이라고 합니다.\n이 방식은 매우 빠르게 사용할 수 있으며 게임의 용량을 줄일 수 있습니다.\n하지만 사용할 새 글자가 추가되면 폰트 이미지를 다시 빌드해야합니다.\n(개 귀찮)\n그래서 실시간으로 사용하는 글자를 구워주는 기능을 내장하게 되었습니다.\n1. 이러면 단점으로 원본 TTF 파일을 빌드에 같이 포함해야합니다.\n     (용량이 커지겠죠)\n2. 새로운 글자를 사용하려고 할때 빌드를 해야하니 느려지겠죠\n하지만 요즘 컴퓨터는 워낙 빠르기 때문에 이런건 일도 아닙니다.\n저장 공간이나 메모리도 문제가 안될 수준으로 커졌습니다.\n2012년 모바일 환경에서는 상항한 압박이 있었습니다.\n게임은 200mb 미만이어야했고 스맛폰의 메모리는 1gb 가 안되었던 시절입니다.\n그래서 옛날엔 불편하게 게임을 만들었다 정도로 생각해두시고\n요즘은 의미 없다 편하게 쓰자 ...",
        "guid": "http://serverdown.tistory.com/1258",
        "categories": [
          "프로그래밍/개발메모",
          "TextMeshPro",
          "유니티",
          "폰트"
        ],
        "isoDate": "2025-04-12T08:11:37.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": []
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "한상곤 - Sigmadream",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "당신의 CPU는 열심히 일하고 있나요?",
        "link": "https://techblog.lycorp.co.jp/ko/efficiently-using-cpu-in-kubernetes",
        "pubDate": "Fri, 11 Apr 2025 02:00:00 GMT",
        "content": "들어가며안녕하세요. LINE+ Contents Service Engineering 조직에서 백엔드 개발 및 프런트엔드 개발을 담당하고 있는 문범우, 안현모입니다.저희 조직에서는 그...",
        "contentSnippet": "들어가며안녕하세요. LINE+ Contents Service Engineering 조직에서 백엔드 개발 및 프런트엔드 개발을 담당하고 있는 문범우, 안현모입니다.저희 조직에서는 그...",
        "guid": "https://techblog.lycorp.co.jp/ko/efficiently-using-cpu-in-kubernetes",
        "isoDate": "2025-04-11T02:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "돈 버는 습관",
        "link": "https://www.thestartupbible.com/2025/04/profit-making-as-a-habit.html",
        "pubDate": "Wed, 16 Apr 2025 21:26:00 +0000",
        "content:encodedSnippet": "얼마 전에 우리의 오래된 투자사의 이사회 미팅에 참석했다. 아주 힘든 사업을 하고 있는데, 10년 전 창업할 땐, 창업가들도 이렇게 힘든 사업인 줄 몰랐고, 투자자들도 이렇게 힘든 사업인 줄 몰랐다. 그동안 실수도 많이 했고, 돈도 많이 까먹으면서 개고생했는데, 이제 회사가 어느 정도 안정적인 운영 방법을 찾았고, 그동안 마이너스 나는 사업을 하다가 작년부터 손익분기점을 넘으면서 흑자를 만들고 있다. 나도 이런 창업가들과 오랫동안 같이 일하다 보면 정말 많은 것을 느끼고 배운다. 사업에 대해서도 많이 배우지만, 실제론 인생에 대해서 정말 많이 배운다. 이런 힘든 사업을 무에서 시작해서 돈을 버는 과정을 옆에서 보다 보면, 가끔은 제삼자인 내가 토할 정도로 힘든 사업을 이분들은 어떻게 저렇게 버티면서 묵묵히 앞으로 나갈까,,,라는 존경심이 항상 생긴다. 어쨌든, 창업가 예찬은 다른 포스팅을 통해서 따로 하겠다.\n같은 이사회 멤버인 다른 투자자분이 이 회사가 드디어 돈을 벌기 시작한 것을 보고, “흑자를 내는 것도 습관입니다. 앞으로 계속 이 습관을 유지하세요.”라는 말씀을 했는데, 나도 이 말에 너무 격하게 공감했다. 사람은 습관의 동물이다. 일주일, 한 달, 일 년, 십 년의 반복을 통해서 만든 습관은 생활을 변하게 하고, 결국엔 인생을 바꿔놓는다. 습관을 만드는 것도 어렵고, 이후에 유지하는 것도 쉽지 않지만, 내 경험에 의하면 만드는 게 더 어렵다. 일단 한번 잘 만들어 놓으면, 몸이 기억하기 때문에 언제든지 이 습관을 불러 올 수 있다.\n회사가 돈 버는 것도 마찬가지다. 돈 버는 습관을 만드는 건 정말 어렵다. 하지만, 쓸데없는 짓 하지 않고, 거창한 스타트업 놀이하지 말고, 겉만 번지르르한 사업을 하지 않고, 그냥 매일, 일주일, 한 달, 일 년, 십 년 동안 어떻게 해서든지 돈을 벌기 위해서 노력하다 보면 돈 버는 게 습관화되고, 흑자를 내는 것도 습관이 된다. 한 번 만든 흑자는 두 번의 흑자를 만들고, 이는 평생의 흑자로 이어질 수 있는, 창업가들의 인생과 회사의 미래를 바꾸는 계기가 될 수 있다.\n얼마 전에 ‘슈퍼 마리오 효과‘라는 글을 썼는데, 돈을 버는 것도 이와 비슷한 맥락에서 생각해 볼 수 있다. 돈을 벌기 위해 수많은 시도를 해야 하고, 이를 계속 반복하다 보면, 실수를 많이 할 것이다. 실수하면, 우리 몸은 이 실수를 고치기 위해서 노력한다. 이 과정을 계속 반복하다 보면, 그리고 운이 좀 따른다면, 돈 버는 사업이 만들어지고, 이를 또한 계속 반복하다 보면 흑자가 만들어진다. 한 번 온몸으로 경험한 흑자 만드는 방법은 몸에 습관처럼 남기 때문에, 앞으로 이를 계속 반복할 가능성이 커진다.\n이는 마치 운동선수의 우승과 비슷하다. 이겨본 놈이 계속 이길 수 있다는 말을 우린 자주 하는데, 시합에서 한 번 이긴 선수는 승리의 자신감이 생기는데, 이 자신감은 뇌 일부분을 자극하고, 이 부분이 자극받으면 반복적으로 우승할 수 있다.\n흑자를 내는 것도 습관이다. 스타트업 놀이 말고, 돈 버는 걸 습관으로 만들어라.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/04/profit-making-as-a-habit.html#respond",
        "content": "얼마 전에 우리의 오래된 투자사의 이사회 미팅에 참석했다. 아주 힘든 사업을 하고 있는데, 10년 전 창업할 땐, 창업가들도 이렇게 힘든 사업인 줄 몰랐고, 투자자들도 이렇게 힘든 사업인 줄 몰랐다. 그동안 실수도 많이 했고, 돈도 많이 까먹으면서 개고생했는데, 이제 회사가 어느 정도 안정적인 운영 방법을 찾았고, 그동안 마이너스 나는 사업을 하다가 작년부터 손익분기점을 넘으면서 흑자를 만들고(...)",
        "contentSnippet": "얼마 전에 우리의 오래된 투자사의 이사회 미팅에 참석했다. 아주 힘든 사업을 하고 있는데, 10년 전 창업할 땐, 창업가들도 이렇게 힘든 사업인 줄 몰랐고, 투자자들도 이렇게 힘든 사업인 줄 몰랐다. 그동안 실수도 많이 했고, 돈도 많이 까먹으면서 개고생했는데, 이제 회사가 어느 정도 안정적인 운영 방법을 찾았고, 그동안 마이너스 나는 사업을 하다가 작년부터 손익분기점을 넘으면서 흑자를 만들고(...)",
        "guid": "https://www.thestartupbible.com/?p=9428",
        "categories": [
          "Uncategorized",
          "FoundersAtWork",
          "hustle",
          "inspiring",
          "sports",
          "Strong"
        ],
        "isoDate": "2025-04-16T21:26:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "면접의 허상",
        "link": "https://www.thestartupbible.com/2025/04/stop-wasting-too-much-energy-on-interviews.html",
        "pubDate": "Sun, 13 Apr 2025 21:33:00 +0000",
        "content:encodedSnippet": "이 세상을 세상답게 돌아가게 하는 단 한 가지만 꼽으라면, 그건 ‘사람’이라고 할 수 있다. 사람이 사람과 일하고, 사람이 사람과 교류하면서 이 세상은 돌아가고, 더 좋은 세상으로 발전한다. 회사도 마찬가지다. 특히, 스타트업에서 가장 중요하고, 절대로 타협할 수 없는 단 한 가지만 선택하면, 그건 당연히 사람이다. 대표이사는 시간의 50%는 좋은 사람을 채용하는 데 사용해야 하고, 나머지 50%는 있는 사람들이 퇴사하지 않도록 하는 데 사용해야 한다. 지금 내가 채용하는 사람이 우리 회사 그 자체라는 점을 항상 명심해야 한다.\n그래서 우린 면접에 많은 공을 들인다. 면접의 방법도 갈수록 진화하고 있고, 더 좋은 사람을 채용하기 위한 노력의 하나로 면접의 횟수와 시간이 계속 늘어나고 있다. 얼마 전에 아는 분이 외국계 대기업의 시니어 매니저 레벨의 직책에 지원했는데, 6개월 동안 12번의 면접을 했다고 한다. 그런데 막판에 떨어졌다. 면접의 종류도 코딩하기, 케이스 풀기부터 술 마시기까지 정말 다양하게 세분되고 있다. 대기업들은 회사에 가장 적합한 인재 채용을 위한 면접 매뉴얼을 개발하기 위해 수억 원의 돈을 쓰면서 외부 컨설팅까지 받는다.\n그래서 우린 이런 고도화 된 면접 방법을 통해서 정말 더 좋은 사람을 채용하고 있을까? 개인적으로 봤을 땐, 아닌 것 같다. 내 개인적인 경험을 이야기해 보면, 면접을 아무리 잘해도, 이분이 실무는 정말 못 했던 적도 있고, 혼자서는 일을 잘 하는데 팀원들과 같이 했을 땐 팀워크 능력은 현저하게 떨어졌던 적도 있었다. 그리고 이건 내 주변의, 나보다 훨씬 더 많은 사람들을 면접하고 채용하는 매니저들도 비슷한 이야기를 한다. 면접을 20번 해도 그 사람이 실제로 일을 잘하는진 알 수 없고, 실제로 일을 잘해도, 우리 회사에서 일을 잘할 수 있을진 알 수가 없다.\n이게 면접의 현실이다. 면접은 단기간 안에 극적으로 향상할 수 있는 기술이기도 하고 – 입시 학원처럼, 면접 학원도 있다 – 일은 못 해도 말발만 살아 있으면, 면접에선 100점을 받을 수도 있기 때문이다.\n그럼 도대체 사람을 어떻게 채용해야 할까? 내가 아는 세 가지 방법이 있다.\n첫 번째 방법은, 일단 내가 잘 아는 사람만 채용하는 방법이다. 오래된 친구, 대학교 룸메이트, 동아리 선후배, 직장 동료나 선후배가 좋은 사례다. 우리가 투자한 회사 중 이렇게 오랫동안 서로를 알고 지낸 분들이 공동 창업가나 동료로 일하는 곳들이 큰 불협화음 없이 잘하는 걸 자주 경험한다. 하지만, 사람의 네트워크라는 게 한계가 있고, 회사가 성장하면 잘 아는 사람의 인재풀은 바닥나기 때문에 이 방법은 회사 규모가 작을 때만 작동한다.\n두 번째는, 6개월의 수습 기간을 갖고, 이후에 정식 채용을 결정하는 것이다. 면접을 아무리 잘해도 이분이 실제 일을 잘하는진 현장에서 확인해야 하는데, 2개월 정도의 수습은 약간 애매하다. 2개월 정도는 일을 잘하는 척 연기할 수도 있다. 하지만, 6개월을 연기하긴 어렵다. 6개월 같이 일해보면, 이분이 정말 일을 잘하는 분인지 충분히 파악된다. 또한, 일을 잘하는 분도 본인이 회사와 케미가 맞는지 판단해 봐야 하므로 6개월 정도의 수습 기간을 권장한다. 이런 제안에 격하게 반대하는 후보라면, 그리고 그 이유로 자존심과 모욕감 등을 언급하면 이건 적신호다.\n마지막 방법은, 채용보단 보상에 대한 방법이다. 내가 전에 이 글에서 이야기했는데, 면접을 기반으로 직책과 연봉을 결정하는 게 너무 어렵고 위험한 방법이기 때문에, 입사 시 ‘one 직책 one 연봉’ 제도를 도입하는 것이다. 이게 무슨 말이냐 하면, 컴공과를 막 졸업한 25살 엔지니어든, 15년 개발 경력이 있는 엔지니어든, 새로운 회사에 입사할 때 직책이 둘 다 시니어 소프트웨어 엔지니어라면, 이 두 분의 입사 연봉은 무조건 동일하게 가는 전략이다. 같은 직책이라도 과거의 경험이 많으면 연봉이 더 높고, 특히나 면접 때 말을 잘하면 연봉이 훨씬 더 높아지는 게 현대 사회의 채용 전략인데, 나는 이건 완전히 틀렸다고 본다. 경력이 많다고 그 일을 잘하는 건 절대로 아니고 – 오히려 그 반대의 경험을 정말 많이 했다 – 면접 때 말발에서 이기는 사람이 일을 더 잘하는 게 절대로 아니다. 그래서 입사할 땐 모두 다 연봉을 동일하게 가져가지만, 일 년 후 업무 평가에서 실제로 일을 더 잘하는 사람에게 연봉을 드라마틱하게 인상해 주는 방법이 좋은 사람을 계속 회사에 남게 하고, 아닌 사람은 퇴사하게 할 수 있는 좋은 방법이라고 생각한다.\n정답은 아니지만, 위 3개의 방법을 적절하게 활용하면 피곤한 면접 횟수는 줄일 수 있고, 더 좋은 인재를 채용할 수 있다. 실은, 어쩌면 한국은 사람을 해고하는 게 너무 힘들어서 안 내보낼 사람을 채용하기 위해서 면접을 더 중시하고, 더 신중하게 생각할지도 모르겠다. 한국의 경직된 해고 정책은 반드시 바꿔야 한다고 나는 개인적으로 생각한다.\n어쨌든, 이렇게 면접하고, 다양한 채용 방법을 사용하는 이유는 좋은 사람을 확보하기 위해서다. 좋은 사람이란 일을 잘하는 사람인데, 일을 잘하는 사람이란, 일이 주어지면, 그 일을 직접 할 수 있는 사람이다. 일이 주어지면, 그 일을 하기 위해서 사람을 또 채용하는 사람이 아니라.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/04/stop-wasting-too-much-energy-on-interviews.html#comments",
        "content": "이 세상을 세상답게 돌아가게 하는 단 한 가지만 꼽으라면, 그건 ‘사람’이라고 할 수 있다. 사람이 사람과 일하고, 사람이 사람과 교류하면서 이 세상은 돌아가고, 더 좋은 세상으로 발전한다. 회사도 마찬가지다. 특히, 스타트업에서 가장 중요하고, 절대로 타협할 수 없는 단 한 가지만 선택하면, 그건 당연히 사람이다. 대표이사는 시간의 50%는 좋은 사람을 채용하는 데 사용해야 하고, 나머지 50%는(...)",
        "contentSnippet": "이 세상을 세상답게 돌아가게 하는 단 한 가지만 꼽으라면, 그건 ‘사람’이라고 할 수 있다. 사람이 사람과 일하고, 사람이 사람과 교류하면서 이 세상은 돌아가고, 더 좋은 세상으로 발전한다. 회사도 마찬가지다. 특히, 스타트업에서 가장 중요하고, 절대로 타협할 수 없는 단 한 가지만 선택하면, 그건 당연히 사람이다. 대표이사는 시간의 50%는 좋은 사람을 채용하는 데 사용해야 하고, 나머지 50%는(...)",
        "guid": "https://www.thestartupbible.com/?p=9426",
        "categories": [
          "Uncategorized",
          "FoundersAtWork",
          "general",
          "people",
          "strategy",
          "스타트업 바이블 1",
          "스타트업 바이블 2",
          "스타트업 바이블 QA"
        ],
        "isoDate": "2025-04-13T21:33:00.000Z"
      }
    ]
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "직장인의 부업소득, 종합소득세 신고 대상일까요?",
        "link": "https://blog.toss.im/article/tossmoment-7",
        "pubDate": "Fri, 11 Apr 2025 04:21:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}“퇴근 후 배달을 시작한 지 4개월째입니다. 생활비 보태려는 정도로만 부업소득을 벌고 있는데, 굳이 세금 신고를 따로 해야 할까요? 이 정도 금액은 괜찮을 것 같은데…”\n부업을 하는 직장인이라면 누구나 한 번쯤 해봤을 고민이죠.\n하지만 ‘겨우 이 정도 쯤이야.’ 하고 신고하지 않는다면 나중에 후회할 수 있어요. 국세청에서는 부업 소득도 꼼꼼하게 살피기 때문에, 금액이 작다고 무심코 넘어갔다가는 세무적인 불이익을 겪을 수 있거든요. 종합소득세 신고를 안 했을 때 어떻게 되는지 궁금하다면 .css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}여기에서 확인할 수 있어요.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}부업을 한다면\n친해져야 할 종합소득세\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}직장에서 받는 월급의 세금은 연말정산으로 정리되지만, 부업 소득에 대한 세금은 5월 종합소득세 신고기간에 별도로 처리해야해요. \n부업 소득은 직장에서 발생한 근로소득과 합산해서 세금이 산출되기 때문에, 두 소득을 더한 금액이 높을수록 세율도 높아져 세금 부담이 생길 수 있어요. 하지만 이때 신고를 하지 않는다면 나중에 가산세 등의 더 큰 비용이 발생합니다.\n물론, 모든 부업 소득이 종합소득세 신고 대상인 건 아니에요. 소득의 종류와 금액, 수익 구조가 반복적인지에 따라 달라져요.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n① 부업이 기타소득인 경우\n일시적인 강연료, 단발성 원고료처럼 반복적이지 않은 수입은 기타소득으로 분류됩니다. 기타소득 금액이 300만 원을 초과하면 다른 소득과 합산해 종합소득세 신고를 해야 해요. 300만 원 이하라면 분리과세*나 종합과세* 중 나에게 더 유리한 것을 선택하면 됩니다.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}* .css-1ebvaan{white-space:pre-wrap;font-weight:bold;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}분리과세: 다른 소득과 합치지 않고, 해당 소득에만 따로 세금을 매기는 방식이에요. 소득이 높아 세율이 높은 사람에게 유리해요.\n* 종합과세: 모든 소득을 합쳐 한꺼번에 세금을 매기는 방식이에요. 소득이 많지 않거나 공제 혜택을 받을 수 있는 사람에게 유리해요.\n강연료, 원고료, 인세 등 일반적인 인적용역 기타소득의 경우, 별도의 증빙자료 없이도 수입의 60%까지는 필요경비로 인정받을 수 있어요. 즉, 필요경비가 450만 원으로 적용되는 750만 원의 수입까지는 일반적으로 종합소득세 신고 대상이 아닌거죠. 750만 원을 넘는 수입을 얻었지만 실제 지출한 비용을 증빙하여 차감한 금액이 300만 원 이하라면, 종합소득세 신고를 통해 기타소득임을 인정받으면 됩니다.\n② 부업이 사업소득인 경우\n크몽, 스마트스토어, 유튜브, 배달처럼 반복적으로 수익을 얻을 수 있는 부업 활동은 사업소득에 해당해요. 사업소득은 금액에 관계없이 모두 종합소득세 신고 대상이에요. 플랫폼에서 단발성으로 수익을 얻었더라도, 계정이 등록되어 언제든 추가 거래가 가능한 상태라면 사업소득으로 신고하는 것이 안전합니다. 계정을 삭제했거나 정지해서 추가 거래 가능성이 없다면 기타소득으로 분류할 수 있어요.\n③ 부업이 근로소득인 경우\n두 회사에서 급여를 받는다면, 한 회사에서 받은 근로소득 원천징수영수증을 다른 회사에 제출해 두 소득을 합산하여 연말정산할 수 있어요. 이 경우 종합소득세 신고를 따로 하지 않아도 됩니다. 하지만 각 회사에서 별도로 연말정산을 했다면, 두 소득을 합산해 종합소득세 신고를 해야 해요. 각각 신고하면 세금이 일시적으로 적게 나올 수 있지만, 나중에 국세청이 두 소득을 합산해 다시 계산하면 미납 세금과 가산세를 추가로 내야 할 수 있으니 처음부터 정확하게 신고하는 게 좋습니다.\n하루 단위로 일한 행사 보조나 단기 알바처럼 일시적인 근로는 일용 근로소득으로 분류됩니다. 일용 근로소득은 보통 지급받을 때 원천징수가 이미 완료되기 때문에 별도로 신고하지 않아도 됩니다. 하지만 세금을 떼지 않고 현금이나 계좌이체 등으로 직접 받았다면, 기타소득이나 사업소득으로 간주되어 신고 대상이 될 수 있어요. 수익 활동이 반복적이고 지속적이라면 사업소득, 그렇지 않다면 기타소득으로 신고하면 됩니다.\n세금을 줄이고 싶다면\n영수증은 꼼꼼하게\n많은 분들이 세금은 번 돈 전체에 붙는다고 생각해요. 하지만 세금은 수입에서 지출 비용을 뺀 소득에 부과됩니다. 그래서 지출 비용을 얼마나 어떻게 인정받느냐에 따라 내야 할 세금은 크게 달라질 수 있어요.\n단, 부업과 관련 없는 지출은 인정되지 않아요. 직접적인 관련성이 있어야 하고, 영수증 같은 증빙 자료가 꼭 있어야 합니다. 그래서 부업용 카드나 통장을 만들어서 지출 자료를 미리 정리해두면 나중에 세금 신고할 때 큰 도움이 됩니다. 경비처리 규정이 담긴 소득세법 시행령 제55조는 법제처 사이트에서 자세히 확인할 수 있어요.\n\n기억해야 할 금액\n2,000만 원\n부업 소득이 연 2,000만 원을 넘으면, 소득월액 보험료가 추가로 부과됩니다. 일반적으로는 추가된 소득 규모에 따라 기존 보험료의 5~10% 정도가 늘어나요. \n그리고 이 정보는 재직중인 회사에도 통보됩니다. 직장에 부업을 비밀로 하고 있었다면 건강보험공단의 보험료 고지서로 들킬 수 있다는 의미죠. 이때 부업 소득은 이자, 배당, 연금, 기타소득까지 모두 합산해서 계산되니 꼼꼼하게 유의하는 게 좋아요.\n내가 놓친 환급금,\n그냥 두면 사라져요\n부업 소득을 성실히 신고했더라도, 원래 납부했어야 할 것보다 더 낸 세금이 있을 수 있어요. 특히 부업을 하는 직장인이라면 빠뜨렸던 항목이 있을 가능성이 높아 돌려받을 수 있는 돈이 있는 경우가 많죠. 이때는 잘못 냈던 세금을 바로잡아 다시 신고하는 경정청구를 통해 세금을 환급 받으면 돼요.\n‘혹시 나도?’ 라는 생각이 든다면, 아래 버튼을 눌러 지금 바로 확인해보세요. 토스 앱에서는 지난 5년간 납부한 세금 중 돌려받을 돈이 있는지, 있다면 얼마나 받을 수 있는지 빠르고 쉽게 확인할 수 있어요.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 윤동해 Graphic 조수희 이제현 이동건",
        "content": "부업을 한다면 꼭 알아야 할 세금 상식",
        "contentSnippet": "부업을 한다면 꼭 알아야 할 세금 상식",
        "guid": "https://blog.toss.im/article/tossmoment-7",
        "isoDate": "2025-04-11T04:21:00.000Z"
      },
      {
        "title": "2025 대학생·청년 주거지원 제도 총정리: 임대주택부터 월세지원까지",
        "link": "https://blog.toss.im/article/money-policies-38",
        "pubDate": "Thu, 10 Apr 2025 06:46:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}대학생·청년이 거주할 수 있는 공공주택 유형 4가지\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n1. 다가구 매입임대 주택\n.css-1kxrhf3{white-space:pre-wrap;}역세권 등 입지가 좋은 다가구 주택을 시세의 30~50% 저렴한 임대료로 공급합니다.\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n대상: 대학생, 취업준비생 및 19~39세 무주택 청년\n시기: 상시 입주자 모집\n신청 자격: 생계, 주거, 의료급여 수급자 가구 및 한부모가족, 차상위계층 가구, 본인과 부모의 월평균 소득 100% 이하인 자, 본인의 월평균 소득 100% 이하인 자\n신청 방법(문의처): .css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}LH청약플러스 및 관할 지자체\n\n\n2. 행복주택\n학교나 직장, 교통이 편리한 지역에 위치한 공공임대주택으로, 시세의 60~80% 수준의 저렴한 임대료가 특징입니다.\n\n\n대상: 대학생, 취업준비생 및 19~39세 무주택 청년, 도시근로자 가구원 수별 가구당 월평균 소득 100% 이하 (1인 가구 120%)\n시기: 입주자 모집 공고 참고\n신청 방법(문의처): 마이홈포털(1600-1004) 및 공공주택 사업처별 청약접수처\n\n\n3. 전세 임대주택\nLH가 집주인과 계약을 맺고 청년에게 재임대하는 방식으로, 전세금을 간접 지원합니다. 청년은 기준 충족 시, 최대 10년까지 거주할 수 있어요.\n\n\n대상: 대학생, 취업준비생 및 19~39세 무주택 청년 중 소득 및 자산 기준 충족자\n지원한도:\n-수도권: 1억 2,000만 원\n-광역시: 9,500만 원(세종 포함)\n-기타 지역: 8,500만 원\n\n신청 방법(문의처): 한국토지주택공사(1600-1004) 및 지방공사\n\n\n4. 통합공공임대주택\n복잡했던 공공임대주택 유형(영구·국민·행복주택)을 하나로 통합한 주택으로, 제도를 간소화하고 입주 자격과 임대료 체계를 개선했어요. 임대 기간은 최대 30년, 임대료는 시세의 35~90% 수준으로 주택마다 다양해요.\n\n\n신청 자격: 18~39세 무주택자, 중위소득 150% 이하 (1인 가구 170%)\n신청 시기: 입주자 모집 공고\n신청 방법(문의처): 마이홈 포털(1600-1004)\n\n\n\n대학생·청년을 위한 주거비 지원 정책 4가지 \n1. 청년 월세 한시 특별지원(2022~2027년)\n부모와 따로 살고 있는 19~34세 무주택 청년이라면 월 최대 20만 원을 지원받을 수 있어요.\n\n\n지원 대상: 19~34세 무주택 청년, 부모와 별도 거주, 청약 통장 가입자\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*청년가구 소득이 기준 중위소득 60% 이하이면서 원가구 소득이 중위소득 100% 이하\n지원 내용: 실제 납부하는 임대료를 월 최대 20만 원, 최대 24개월 지급\n신청 방법: 복지로 웹사이트 또는 관할 행정복지센터 방문 \n\n\n2. 주거안정장학금\n원거리 대학에 진학한 저소득층 학생들에게 월 최대 20만 원을 지원합니다.\n\n\n지원 대상: 원거리 대학에 다니는 기초·차상위 학생 (단, 사업 참여 대학에 한함) 중 성적 기준*을 충족하는 경우\n*성적기준: 직전학기 12학점 이상 이수하여 70/100 점 이상 획득\n지원 내용: 월 최대 20만 원 한도 내 학기 중 학생이 지출한 주거 관련 비용 지원\n월세, 보증금, 공동주택관리비, 수도비, 가스비, 전기비 등\n신청 방법: 한국장학재단 웹 또는 모바일 앱(1599-2000)\n\n\n3. 전세보증금 반환보증 보증료지원\n전세보증금 피해를 막기 위해 보증보험 가입자에게 보증료를 지원합니다.\n\n\n지원 대상: 전세보증금 3억 원 이하이고, 전세보증금 반환보증보험이 유효한 청년 (보증료 5,000만 원 이하)\n지원 내용: 보증료 전액 또는 일부 지원 (최대 30만 원)\n신청 방법: 지자체 방문, 정부24 또는 안심전세포털\n\n\n4. 주택구입·전세자금 대출\n청년이 자립할 수 있도록 대출을 통한 주거비 부담을 완화합니다.\n\n\n지원 내용\n\n청년가구 버팀목전세자금대출 부부 합산 연 소득 5,000만 원 이하, 85㎡ 이하, 보증금 3억 원, 대출한도 2억 원, 대출비율 보증금의 80% 이내, 금리 2.2~3.3%\n신혼부부 디딤돌 구입자금대출 부부 합산 연 소득 8,500만 원 이하, 주택가격 6억 원, 대출금액 최대 4억 원, 금리 2.55~3.85%\n\n\n신청 방법: 주택도시보증공사 기금e 든든 비대면 신청(1566-9009) 및 은행(우리, 신한, 국민, 농협, 하나, iM, 부산) 방문 접수",
        "content": "대학생과 청년을 위한 대표적인 주거지원 제도 모아보기",
        "contentSnippet": "대학생과 청년을 위한 대표적인 주거지원 제도 모아보기",
        "guid": "https://blog.toss.im/article/money-policies-38",
        "isoDate": "2025-04-10T06:46:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]