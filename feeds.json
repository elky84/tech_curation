[
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "David Li",
        "title": "Now in Public Preview: GitHub Copilot build performance for Windows",
        "link": "https://devblogs.microsoft.com/cppblog/now-in-public-preview-github-copilot-build-performance-for-windows/",
        "pubDate": "Wed, 21 Jan 2026 18:17:56 +0000",
        "content:encodedSnippet": "Last year, we launched our new GitHub Copilot build performance capabilities in Private Preview. With help from our fantastic C++ community, we gathered insights and addressed key feedback. We’re happy to share that GitHub Copilot build performance for Windows is now in Public Preview. Today, all C++ developers can try out the new capabilities in the latest Visual Studio 2026 Insiders.\n“I’ve tried the feature for a few hours and I’m happily impressed. The agent provided accurate suggestions, implemented them, and managed to reduce my build time by about 20%.” – Alessandro Vergani, ARGO Vision\nOptimizing Build Times with GitHub Copilot\nWhen you use this new capability in Visual Studio, GitHub Copilot will use an agent to:\nInitiate a build and capture a diagnostic trace\nIdentify bottlenecks in the following areas:\n\nexpensive headers\nlong function generation times\ncostly template instantiations\nSuggest and apply optimizations\nValidate changes through rebuilds so your code stays correct\nReport measurable improvements and recommend next steps\nTo see how it works in action, please watch our demo below.\n\nLearn more: Documentation for GitHub Copilot build performance for Windows | Microsoft Learn\nUsing GitHub Copilot build performance for Windows\nThere are several ways to start the new build performance capabilities:\n1. Select the responder in Copilot Chat by typing “@BuildPerfCpp”\n\n2. Select menu entry Build > Run Build Insights > Improve build performance\n\n3. If you already have a .etl trace file open from Build Insights, click Improve on the top right corner of the report view. The view or tab you click from gives GitHub Copilot important context to focus on the relevant hot spots when the chat session begins.\n\nOnce you start a chat session from any of the entry points above, GitHub Copilot begins analyzing your build and offering suggestions to reduce build time. It will iterate on these optimizations until your build completes successfully. You’ll always have final approval on whether to apply the changes.\nUsing The Build Insights Tool\nTo start trace collection, GitHub Copilot will ask your permission to run the Build Insights tool.\n\nIf it is your first time using Build Insights, you will need to grant a one-time elevated request.\n \nLearn more: Build Insights needs additional permissions | Microsoft Learn\nTemplate Instantiation Collection\nTo collect template information, you must opt-in via Tools > Options > Build Insights > Trace Collection > Collect template instantiation.\nDefault Report Location\nBy default, your reports will be saved in %TEMP%/BuildInsights. You can customize the save location at Tools > Options > Build Insights > Trace Collection > Override default location for saved reports.\nShare your feedback\nWe’d love to hear feedback on how we can improve GitHub Copilot build performance for Windows. Please leave feedback by commenting below or report any issues with Help > Send Feedback.\nThe post Now in Public Preview: GitHub Copilot build performance for Windows appeared first on C++ Team Blog.",
        "dc:creator": "David Li",
        "comments": "https://devblogs.microsoft.com/cppblog/now-in-public-preview-github-copilot-build-performance-for-windows/#respond",
        "content": "<p>Last year, we launched our new GitHub Copilot build performance capabilities in Private Preview. With help from our fantastic C++ community, we gathered insights and addressed key feedback. We’re happy to share that GitHub Copilot build performance for Windows is now in Public Preview. Today, all C++ developers can try out the new capabilities in [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/now-in-public-preview-github-copilot-build-performance-for-windows/\">Now in Public Preview: GitHub Copilot build performance for Windows</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "Last year, we launched our new GitHub Copilot build performance capabilities in Private Preview. With help from our fantastic C++ community, we gathered insights and addressed key feedback. We’re happy to share that GitHub Copilot build performance for Windows is now in Public Preview. Today, all C++ developers can try out the new capabilities in […]\nThe post Now in Public Preview: GitHub Copilot build performance for Windows appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=36214",
        "categories": [
          "C++",
          "Build Insights",
          "build performance",
          "speed"
        ],
        "isoDate": "2026-01-21T18:17:56.000Z"
      }
    ]
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": [
      {
        "creator": "Netflix Technology Blog",
        "title": "The AI Evolution of Graph Search at Netflix",
        "link": "https://netflixtechblog.com/the-ai-evolution-of-graph-search-at-netflix-d416ec5b1151?source=rss----2615bd06b42e---4",
        "pubDate": "Mon, 26 Jan 2026 19:01:27 GMT",
        "content:encodedSnippet": "The AI Evolution of Graph Search at Netflix: From Structured Queries to Natural Language\nBy Alex Hutter and Bartosz Balukiewicz\nOur previous blog posts (part 1, part 2, part 3) detailed how Netflix’s Graph Search platform addresses the challenges of searching across federated data sets within Netflix’s enterprise ecosystem. Although highly scalable and easy to configure, it still relies on a structured query language for input. Natural language based search has been possible for some time, but the level of effort required was high. The emergence of readily-available AI, specifically Large Language Models (LLMs), has created new opportunities to integrate AI search features, with a smaller investment and improved accuracy.\nWhile Text-to-Query and Text-to-SQL are established problems, the complexity of distributed Graph Search data in the GraphQL ecosystem necessitates innovative solutions. This is the first in a three-part series where we will detail our journey: how we implemented these solutions, evaluated their performance, and ultimately evolved them into a self-managed platform.\nThe Need for Intuitive Search: Addressing Business and Product Demands\nNatural language search is the ability to use everyday language to retrieve information as opposed to complex, structured query languages like the Graph Search Filter Domain Specific Language (DSL). When users interact with 100’s of various UIs within the suite of Content and Business Products applications, a frequent task is filtering a data table like the one below:\nExample Content and Business Products application view\nIdeally, a user simply wants to satisfy a query like “I want to see all movies from the 90s about robots from the US.” Because the underlying platform operates on the Graph Search Filter DSL, the application acts as an intermediary. Users input their requirements through UI elements — toggling facets or using query builders — and the system programmatically converts these interactions into a valid DSL query to filter the data.\nThe Complexity of filtering and DSL generation\nThis process presents a few issues.\nToday, many applications have bespoke components for collecting user input — the experience varies across them and they have inconsistent support for the DSL. Users need to “learn” how to use each application to achieve their goals.\nAdditionally, some domains have hundreds of fields in an index that could be faceted or filtered by. A subject matter expert (SME) may know exactly what they want to accomplish, but be bottlenecked by the inefficient pace of filling out a large scale UI form and translating their questions in order to encode it in a representation Graph Search needs.\nMost importantly, users think and operate using natural language, not technical constructs like query builders, components, or DSLs. By requiring them to switch contexts, we introduce friction that slows them down or even prevents their progress.\nWith readily-available AI components, our users can now interact with our systems through natural language. The challenge now is to make sure our offering, searching Netflix’s complex enterprise state with natural language, is an intuitive and trustworthy experience.\nNatural language queries translated into Graph Search Filter DSL\nWe’ve made a decision to pursue generating Graph Search Filter statements from natural language to meet this need. Our intention is to augment and not replace existing applications with retrieval augmented generation (RAG), providing tooling and capabilities so that applications in our ecosystem have newly accessible means of processing and presenting their data in their distinct domain flavours. It should be noted that all the work here has direct application to building a RAG system on top of Graph Search in the future.\nUnder the Hood: Our Approach to Text-to-Query\nThe core function of the text-to-query process is converting a user’s (often ambiguous) natural language question into a structured query. We primarily achieve this through the use of an LLM.\nBefore we dive deeper, let’s quickly revisit the structure of Graph Search Filter DSL. Each Graph Search index is defined by a GraphQL query, made up of a collection of fields. Each field has a type e.g. boolean, string, and some have their permitted values governed by controlled vocabularies — a standardized and governed list of values (like an enumeration, or a foreign key). The names of those fields can be used to construct expressions using comparison (e.g. > or ==) or inclusion/exclusion operators (e.g. IN). In turn those expressions can be combined using logical operators (e.g. AND) to construct complex statements.\nGraph Search Filter DSL\nWith that understanding, we can now more rigorously define the conversion process. We need the LLM to generate a Graph Search Filter DSL statement that is syntactically, semantically, and pragmatically correct.\nSyntactic correctness is easy — does it parse? To be syntactically correct, the generated statement must be well formed i.e. follow the grammar of the Graph Search Filter DSL.\nSemantic correctness adds some additional complexity as it requires more knowledge of the index itself. To be semantically correct:\n\nit must respect the field types i.e. only use comparisons that make sense given the underlying type;\nit must only use fields that are actually present in the index, i.e. does not hallucinate;\nwhen the values of a field are constrained to a controlled vocabulary, any comparison must only use values from that controlled vocabulary.\n\nPragmatic correctness is much more difficult. It asks the question: does the generated filter actually capture the intent of the user’s query?\nThe following sections will detail how we pre-process the user’s question to create appropriate context for the instructions that we will provide to the LLM — both of which are fundamental to LLM interaction — as well as post-processing we perform on the generated statement to validate it, and help users understand and trust the results they receive.\nAt a high level that process looks like this:\nGraph Search FIlter DSL generation process\nContext Engineering\nPreparation for the filter generation task is predominantly engineering the appropriate context. The LLM will need access to the fields of an index and their metadata in order to construct semantically correct filters. As the indices are defined by GraphQL queries, we can use the type information from the GraphQL schema to derive much of the required information. For some fields, there is additional information we can provide beyond what’s available in the schema as well, in particular permissible values that pull from controlled vocabularies.\nEach field in the index is associated with metadata as seen below, and that metadata is provided as part of the context.\nGraph Search index representation\nThe field is derived from the document path as characterized by the GraphQL query.\nThe description is the comment from the GraphQL schema for the field.\nThe type is derived from the GraphQL schema for the field e.g. Boolean, String, enum. We also support an additional controlled vocabulary type we will discuss more of shortly.\nThe valid values are derived from enum values for the enum type or from a controlled vocabulary as we will now discuss.\n\nA controlled vocabulary is a specific field type that consists of a finite set of allowed values, which are defined by a SMEs or domain owners. Index fields can be associated with a particular controlled vocabulary, e.g. countries with members such as Spain and Thailand, and any usage of that field within a generated statement must refer to values from that vocabulary.\nNaively providing all the metadata as context to the LLM worked for simple cases but did not scale. Some indices have hundreds of fields and some controlled vocabularies have thousands of valid values. Providing all of those, especially the controlled vocabulary values and their accompanying metadata, expands the context; this proportionally increases latency and decreases the correctness of generated filter statements. Not providing the values wasn’t an option as we needed to ground the LLMs generated statements- without them, the LLM would frequently hallucinate values that did not exist.\nCurating the context to an appropriate subset was a problem we addressed using the well known RAG pattern.\nField RAG\nAs mentioned previously, some indices have hundreds of fields, however, most user’s questions typically refer only to a handful of them. If there was no cost in including them all, we would, but as mentioned prior, there is a cost in terms of the latency of query generation as well as the correctness of the generated query (e.g. needle-in-the-hackstack problem) and non-deterministic results.\nTo determine which subset of fields to include in the context, we “match” them against the intent of the user’s question.\n\nEmbeddings are created for index fields and their metadata (name, description, type) and are indexed in a vector store\nAt filter generation time, the user’s question is chunked with an overlapping strategy. For each chunk, we perform a vector search to identify the top K most relevant values and the fields to which they belong.\nDeduplication: The top K fields from each chunk are both consolidated and deduplicated before being provided as context to the system instructions.\nField RAG process (chunking, merge, deduplicate)\nControlled Vocabularies RAG\nIndex fields of the controlled vocabulary type are associated with a particular controlled vocabulary, again, countries are one example. Given a user’s question, we can infer whether or not it refers to values of a particular controlled vocabulary. In turn, by knowing which controlled vocabulary values are present, we can identify additional, related index fields that should be included in the context that may not have been identified by the field RAG step.\nEach controlled vocabulary value has:\n\na unique identifier within its type;\na human readable display name;\na description of the value;\nalso-known-as values or AKA display names, e.g. “romcom” for “Romantic Comedy”.\n\nTo determine which subset of values to include in the context for controlled vocabulary fields (and also possibly infer additional fields), we “match” them against the user’s question.\n\nEmbeddings are created for controlled vocabulary values and their metadata, and these are indexed in a vector store. The controlled vocabularies are available via GraphQL and are regularly fetched and reindexed so this system stays up to date with any changes in the domain.\nAt filter generation time, the user’s question is chunked. For each chunk, we perform a vector search to identify the top K most relevant values (but only for the controlled vocabularies that are associated with fields in the index)\nThe top K values from each chunk are deduplicated by their controlled vocabulary type. The associated field definition is then injected into the context along with the matched values.\nControlled Vocabularies RAG\nCombining both approaches, the RAG of fields and controlled vocabularies, we end up with the solution that each input question resolves in available and matched fields and values:\nField and CV RAG\nThe quality of results generated by the RAG tool can be significantly enhanced by tuning its various parameters, or “levers.” These include strategies for reranking, chunking, and the selection of different embedding generation models. The careful and systematic evaluation of these factors will be the focus of the subsequent parts of this series.\nThe Instructions\nOnce the context is constructed, it is provided to the LLM with a set of instructions and the user’s question. The instructions can be summarised as follows: “Given a natural language question, generate a syntactically, semantically, and pragmatically correct filter statement given the availability of the following index fields and their metadata.”\n\nIn order to generate a syntactically correct filter statement, the instructions include the syntax rules of the DSL.\nIn order to generate a semantically correct filter statement, the instructions tell the LLM to ground the generated statement in the provided context.\nIn order to generate a pragmatically correct filter statement, so far we focus on better context engineering to ensure that only the most relevant fields and values are provided. We haven’t identified any instructions that make the LLM just “do better” at this aspect of the task.\nGraph Search Filter DSL generation\nAfter the filter statement is generated by the LLM, we deterministically validate it prior to returning the values to the user.\nValidation\nSyntactic Correctness\nSyntactic correctness ensures the LLM output is a parsable filter statement. We utilize an Abstract Syntax Tree (AST) parser built for our custom DSL. If the generated string fails to parse into a valid AST, we know immediately that the query is malformed and there is a fundamental issue with the generation.\nThe other approach to solve this problem could be using the structured outputs modes provided by some LLMs. However, our initial evaluation yielded mixed results, as the custom DSL is not natively supported and requires further work.\nSemantic Correctness\nDespite careful context engineering using the RAG pattern, the LLM sometimes hallucinates both fields and available values in the generated filter statement. The most straightforward way of preventing this phenomenon is validating the generated filters against available index metadata. This approach does not impact the overall latency of the system, as we are already working with an AST of the filter statement, and the metadata is freely available from the context engineering stage.\nDSL verification & hallucinations\nIf a hallucination is detected it can be returned as an error to a user, indicating the need to refine the query, or can be provided back to the LLM in the form of a feedback loop for self correction.\nThis increases the filter generation time, so should be used cautiously with a limited number of retries.\nBuilding Confidence\nYou probably noticed we are not validating the generated filter for pragmatic correctness. That task is the hardest challenge: The filter parses (syntactic) and uses real fields (semantic), but is it what the user meant? When a user searches for “Dark”, do they mean the specific German sci-fi series Dark, or are they browsing for the mood category “dark TV shows”?\nThe gap between what a user intended and the generated filter statement is often caused by ambiguity. Ambiguity stems from the compression of natural language. A user says “German time-travel mystery with the missing boy and the cave” but the index contains discrete metadata fields like releaseYear, genreTags, and synopsisKeywords.\nHow do we ensure users aren’t inadvertently led to wrong answers or to answers for questions they didn’t ask?\nShowing Our Work\nOne way we are handling ambiguity is by showing our work. We visualise the generated filters in the UI in a user-friendly way allowing them to very clearly see if the answer we’re returning is what they were looking for so they can trust the results..\nWe cannot show a raw DSL string (e.g., origin.country == ‘Germany’ AND genre.tags CONTAINS ‘Time Travel’ AND synopsisKeywords LIKE ‘*cave*’) to a non-technical user. Instead, we reflect its underlying AST into UI components.\nAfter the LLM generates a filter statement, we parse it into an AST, and then map that AST to the existing “Chips” and “Facets” in our UI (see below). If the LLM generates a filter for origin.country == ‘Germany’, the user sees the “Country” dropdown pre-selected to “Germany.” This gives users immediate visual feedback and the ability to easily fine-tune the query using standard UI controls when the results need improvement or further experimentation.\nGenerated filters visualisation\nExplicit Entity Selection\nAnother strategy we’ve developed to remove ambiguity happens at query time. We give users the ability to constrain their input to refer to known entities using “@mentions”. Similar to Slack, typing @ lets them search for entities directly from our specialized UI Graph Search component, giving them easy access to multiple controlled vocabularies (plus other identifying metadata like launch year) to feel confident they’re choosing the entity they intend.\nIf a user types, “When was @dark produced”, we explicitly know they are referring to the Series controlled vocabulary, allowing us to bypass the RAG inference step and hard-code that context, significantly increasing pragmatic correctness (and building user trust in the process).\nExample @mentions usage in the UI\nEnd-to-end architecture\nAs mentioned previously, the solution architecture is divided into pre-processing, filter statement generation, and then post-processing stages. The pre-processing handles context building and involves a RAG pattern for similarity search, while the post-processing validation stage checks the correctness of the LLM-generated filter statements and provides visibility into the results for end users. This design strategically balances LLM involvement with more deterministic strategies.\nEnd-to-end architecture\nThe end-to-end process is as follows:\n\nA user’s natural language question (with optional `@mentions` statements) are provided as input, along with the Graph Search index context\nThe context is scoped by using the RAG pattern on both fields and possible values\nThe pre-processed context and the question are fed into the LLM with an instruction asking for a syntactically and semantically correct filter statement\nThe generated filer statement DSL is verified and checked for hallucinations\nThe final response contains the related AST in order to build “Chips” and “Facets”\n\nSummary\nBy combining our existing Graph Search infrastructure with the power and flexibility of LLMs, we’ve bridged the gap between complex filter statements and user intent. We moved from requiring users to speak our language (DSL) to our systems understanding theirs.\nThe initial challenge for our users was successfully addressed. However, our next steps involve transforming this system into a comprehensive and expandable platform, rigorously evaluating its performance in a live production environment, and expanding its capabilities to support GraphQL-first user interfaces. These topics, and others, will be the focus of the subsequent installments in this series. Be sure to follow along!\nYou may have noticed that we have a lot more to do on this project, including named entity recognition and extraction, intent detection so we can route questions to the appropriate indices, and query rewriting among others. If this kind of work interests you, reach out! We’re hiring in our Warsaw office, check for open roles here.\nCredits\nSpecial thanks to Alejandro Quesada, Yevgeniya Li, Dmytro Kyrii, Razvan-Gabriel Gatea, Orif Milod, Michal Krol, Jeff Balis, Charles Zhao, Shilpa Motukuri, Shervine Amidi, Alex Borysov, Mike Azar, Bernardo Gomez Palacio, Haoyun He, Eduardo Ramirez, Cynthia Xie.\n\nThe AI Evolution of Graph Search at Netflix was originally published in Netflix TechBlog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Netflix Technology Blog",
        "guid": "https://medium.com/p/d416ec5b1151",
        "categories": [
          "search-engines",
          "graphql",
          "software-engineering",
          "ai",
          "llm"
        ],
        "isoDate": "2026-01-26T19:01:27.000Z"
      }
    ]
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Dmitrii Korovin",
        "title": "The Jenkins Migration Planning Kit",
        "link": "https://blog.jetbrains.com/teamcity/2026/01/jenkins-migration-planning-kit/",
        "pubDate": "Mon, 26 Jan 2026 18:25:53 +0000",
        "content:encodedSnippet": "This article was brought to you by Cameron Pavey, draft.dev.\nJenkins has served the development community well for over a decade, but it was designed for a different era of software development. Developers who are tired of fighting with plugin compatibility issues, slow builds, and brittle configurations are exploring alternatives.\nBut is your organization ready for the move? What is the actual work involved? And how do you communicate the benefits of a more modern CI/CD solution to leadership to get their buy-in?\nOur migration planning kit answers these questions:\nThe migration-readiness assessment scores and plots your organization’s readiness against the pain you’re experiencing with Jenkins to determine whether you are an ideal migration candidate, need to address foundational issues first, or ought to focus on other priorities.\nYou’ll see how Jenkins patterns compare to TeamCity to assess the effort required and plan for an effective migration.\nThe safe migration plan guides you through the five phases of a successful migration: discovery & assessment, pilot setup, incremental migration, optimization, and full cutover.\nYou’ll get templates and guidance on how to communicate the benefits of migration to management.\nThis guide contains a lot of information, so feel free to use the hyperlinks above to navigate to the information that’s most relevant for you right now.\nMigration-readiness checklist: Assessing your team’s preparation\nBefore considering any migration, you need an honest assessment of your current CI/CD maturity and readiness for change. The following self-evaluation will help you determine whether migration is the right next step and identify areas that need attention.\nOrganizational-readiness assessment\nStart by evaluating how your organization manages Jenkins infrastructure and pipeline development.\nDo you manage Jenkins centrally, or is it distributed across teams? Centralized management typically indicates better standardization and makes migration coordination easier. Distributed management may require more planning but often means teams have stronger pipeline ownership.\nDo you have standardized pipeline practices across your organization? If you have consistent patterns, shared libraries, and documented standards, you are typically better positioned for migration because you’ve already solved many of the organizational challenges. If your pipelines vary dramatically between projects, consider standardizing approaches before migrating.\nAre your builds reliable, or do you regularly experience flaky failures? This question reveals both technical debt and team practices. Reliable builds point to good testing practices and stable infrastructure, while frequent flakiness could be due to underlying issues that migration alone won’t solve.\nTechnical-inventory questions\nUnderstanding your current Jenkins footprint is essential for planning.\nHow many Jenkinsfiles do you maintain across all repositories? This gives you a scope estimate for the migration effort. Count both declarative pipelines and freestyle jobs that would need conversion.\nWhich Jenkins plugins are actively used in your pipelines? Create a comprehensive list including build tools, deployment integrations, notification systems, and reporting plugins. Research TeamCity equivalents for critical plugins, and identify any that might require custom development or workflow changes.\nDo you have custom integrations, scripts, or Jenkins extensions? Custom code represents the highest migration risk because it cannot be automatically translated to TeamCity: Each integration must be completely rebuilt using different APIs, often without clear documentation of the original business requirements or dependencies. Document any custom plugins, shared libraries, or external integrations that directly interact with Jenkins APIs.\nCI/CD pain point analysis\nConsider and identify the specific problems migration should solve for your team.\nAre your builds slow, or do you experience frequent bottlenecks? Common issues include slow build agents, inefficient artifact management, poor parallelization, and resource contention during peak hours. Having a clear goal is important as it will inform decisions throughout the migration process.\nDo you face debugging challenges regularly? Consider how much time your team spends investigating pipeline failures, tracking down build-environment issues, or understanding why tests behave differently in CI versus local environments.\nDo you have scalability issues that limit your current setup? Look for signs like build queues during busy periods, difficulty adding new projects, or infrastructure costs that grow faster than your team size.\nDo you want more control over your pipeline logic and infrastructure? If you are frequently working around Jenkins limitations or investing significant time in custom solutions, you would likely benefit greatly from TeamCity’s more flexible architecture.\nDo you need better visibility into flaky or slow tests? If your team struggles to identify unreliable tests or understand performance bottlenecks, TeamCity’s built-in test intelligence can provide immediate value.\nAre you spending more time maintaining CI infrastructure than building products? This is often the clearest signal that your current platform has become a productivity drain rather than an enabler.\nInterpreting your migration assessment\nLet’s now determine your readiness for migration.\nYou can find a printable version of this readiness checklist in the supporting files.\nFirst, calculate two separate scores:\nReadiness score:\nGive yourself 1 point for each “Yes”:\nCentralized Jenkins management\nStandardized pipeline practices across teams\nReliable builds with minimal flaky failures\nClear inventory of Jenkinsfiles and plugins\nDocumented custom integrations and dependencies\nPain score:\nGive yourself 1 point for each “Yes”:\nSlow builds or frequent bottlenecks\nRegular debugging challenges consuming team time\nScalability issues limiting growth\nNeed for more pipeline control and flexibility\nPoor visibility into test performance and failures\nMore time spent maintaining than building\nMigration recommendation\n\n\n\n\nLow readiness (0–3 points) + high pain (4–6 points): Address foundational issues first, but consider that TeamCity’s better tooling can help with cleanup. Start with organizational improvements and a small pilot.\nLow readiness (0–3 points) + low pain (0–3 points): Migration is not a priority. Focus on other improvements to your development process first.\nWhy choose TeamCity?\nKnowing when it’s time to migrate is only part of the puzzle. You also need to have a solid platform to migrate to. TeamCity addresses the core problems that drive teams away from Jenkins while providing capabilities that simply don’t exist in older CI/CD platforms. Consider the following, to list just a few:\nKotlin DSL for maintainable pipeline logic\nTeamCity’s Kotlin DSL provides type safety, IDE support, and compile-time validation. You can create reusable templates, refactor configurations with confidence, and catch errors before committing changes. Complex pipeline logic becomes maintainable code rather than fragile scripts that break unexpectedly.\nBuilt-in test intelligence\nFlaky test detection, automatic failure assignment, and a comprehensive test history are native platform features. TeamCity identifies which tests fail inconsistently, tracks patterns across builds, and assigns investigations based on recent changes. You’re not parsing logs or building custom solutions to understand test failures; the platform tells you what’s wrong and who should fix it.\nEnterprise orchestration without enterprise complexity\nBuild chains, artifact dependencies, and parallel execution work without extensive configuration or specialized expertise. Visual pipeline editors make complex workflows immediately comprehensible to new team members. You gain sophisticated orchestration capabilities without the operational overhead typically associated with enterprise platforms.\nHow do Jenkins pipelines compare to TeamCity?\nUnderstanding how your existing Jenkins patterns translate to TeamCity will help you determine what kinds of workflows you need to create as part of planning for an effective migration.\nPipelines vs. Build Chains\nTeamCity offers two complementary approaches for defining build workflows: Build Chains and Pipelines. Build Chains is an established method for modeling dependencies and complex workflows, while Pipelines, a new feature as of version 2025.07, provides a modern pipeline experience. While Pipelines is a newer feature that does not yet support as many use cases as the more battle-hardened Build Chains, it offers a more familiar and intuitive interface for teams migrating from Jenkins.\nThe specifics of the CI/CD processes you’re looking to implement will determine which option is best for you.\nOpt for Build Chains if:\nYou need mature, production-ready orchestration with advanced features like artifact dependencies, custom triggers, and snapshot isolation.\nYour workflows involve large monorepos or multiproject builds where many components must be built, tested, and deployed in a coordinated fashion.\nStability and long-term support matter more than having the latest pipeline syntax.\nOpt for Pipelines if:\nYou want a modern, YAML-based pipeline-as-code approach that feels closer to Jenkins, GitHub Actions, or GitLab CI.\nYour workflows are relatively straightforward (build → test → deploy) and don’t require deep artifact or snapshot dependency modeling.\nYou value developer-friendly ergonomics and repo-first configuration over enterprise-grade complexity.\nSample patterns\nBoth Build Chains and Pipelines support Kotlin DSL for configuration (Kotlin DSL support is coming to Pipelines after 2025.11), which offers significant advantages over traditional Jenkinsfile syntax.\nThe following side-by-side examples compare common Jenkins pipeline patterns with TeamCity’s Kotlin DSL, showing syntax differences and TeamCity’s enhanced native capabilities.\nDeclarative pipeline definition\nJenkins’s declarative pipelines use a YAML-like syntax within Groovy that can become verbose and error-prone:\n// Jenkinsfile\n\npipeline {\n\n    agent any\n\n    stages {\n\n        stage('Build') {\n\n            steps {\n\n                sh 'echo \"Building application...\"'\n\n                sh './gradlew build'\n\n            }\n\n        }\n\n        stage('Test') {\n\n            steps {\n\n                sh './gradlew test'\n\n            }\n\n        }\n\n        stage('Deploy') {\n\n            steps {\n\n                sh './deploy.sh'\n\n            }\n\n        }\n\n    }\n\n}\nTeamCity’s Kotlin DSL provides type safety and better IDE support:\n// .teamcity/settings.kts\n\nimport jetbrains.buildServer.configs.kotlin.*\n\nimport jetbrains.buildServer.configs.kotlin.buildSteps.script\n\nimport jetbrains.buildServer.configs.kotlin.triggers.vcs\n\nobject Build : BuildType({\n\n    name = \"Build and Deploy\"\n\n    vcs {\n\n        root(DslContext.settingsRoot)\n\n    }\n\n    steps {\n\n        script {\n\n            name = \"Build\"\n\n            scriptContent = \"\"\"\n\n                echo \"Building application...\"\n\n                ./gradlew build\n\n            \"\"\".trimIndent()\n\n        }\n\n        script {\n\n            name = \"Test\"\n\n            scriptContent = \"./gradlew test\"\n\n        }\n\n        script {\n\n            name = \"Deploy\"\n\n            scriptContent = \"./deploy.sh\"\n\n        }\n\n    }\n\n    triggers {\n\n        vcs {\n\n            branchFilter = \"+:*\"\n\n        }\n\n    }\n\n})\nTriggering builds on VCS commits\nJenkins requires either polling or webhook configuration with plugins:\npipeline {\n\n    triggers {\n\n        pollSCM('H/5 * * * *')  // Poll every 5 minutes\n\n        // OR\n\n        githubPush()  // Requires GitHub plugin\n\n    }\n\n    stages {\n\n        stage('Build on Commit') {\n\n            when {\n\n                anyOf {\n\n                    branch 'main'\n\n                    branch 'develop'\n\n                    changeRequest()\n\n                }\n\n            }\n\n            steps {\n\n                sh './build.sh'\n\n            }\n\n        }\n\n    }\n\n}\nTeamCity provides native VCS integration with sophisticated branch filtering:\nobject BuildOnCommit : BuildType({\n\n    name = \"Build on VCS Commit\"\n\n    vcs {\n\n        root(DslContext.settingsRoot)\n\n        branchFilter = \"\"\"\n\n            +:refs/heads/main\n\n            +:refs/heads/develop\n\n            +:refs/heads/feature/*\n\n        \"\"\".trimIndent()\n\n    }\n\n    triggers {\n\n        vcs {\n\n            branchFilter = \"+:*\"\n\n            enableQueueOptimization = false\n\n        }\n\n    }\n\n    steps {\n\n        script {\n\n            name = \"Build Application\"\n\n            scriptContent = \"./build.sh\"\n\n        }\n\n    }\n\n})\nEnvironment variables and configuration\nJenkins handles environment variables through pipeline syntax:\npipeline {\n\n    environment {\n\n        DATABASE_URL = 'jdbc:postgresql://localhost:5432/mydb'\n\n        API_KEY = credentials('api-key')\n\n    }\n\n    stages {\n\n        stage('Deploy') {\n\n            environment {\n\n                DEPLOY_ENV = 'staging'\n\n            }\n\n            steps {\n\n                sh 'echo \"Deploying to ${DEPLOY_ENV}\"'\n\n            }\n\n        }\n\n    }\n\n}\nTeamCity provides more flexible parameter management with type safety:\nobject Deploy : BuildType({\n\n    name = \"Deploy Application\"\n\n    params {\n\n        text(\"database.url\", \"jdbc:postgresql://localhost:5432/mydb\")\n\n        password(\"api.key\", \"credentialsJSON:api-key\")\n\n        select(\"deploy.environment\", \"staging\", options = listOf(\"staging\", \"production\"))\n\n    }\n\n    steps {\n\n        script {\n\n            scriptContent = \"\"\"\n\n                echo \"Deploying to %deploy.environment%\"\n\n                ./deploy.sh --env %deploy.environment%\n\n            \"\"\".trimIndent()\n\n        }\n\n    }\n\n})\nTest reporting integration\nJenkins requires plugins for comprehensive test reporting:\npipeline {\n\n    stages {\n\n        stage('Test') {\n\n            steps {\n\n                sh './gradlew test'\n\n            }\n\n            post {\n\n                always {\n\n                    publishTestResults([\n\n                        testResultsFiles: 'build/test-results/test/*.xml',\n\n                        allowEmptyResults: false\n\n                    ])\n\n                    publishHTML([\n\n                        allowMissing: false,\n\n                        alwaysLinkToLastBuild: true,\n\n                        keepAll: true,\n\n                        reportDir: 'build/reports/tests/test',\n\n                        reportFiles: 'index.html',\n\n                        reportName: 'Test Report'\n\n                    ])\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\nTeamCity provides built-in test intelligence with automatic failure assignment:\nobject TestWithReporting : BuildType({\n\n    name = \"Test with Reporting\"\n\n    steps {\n\n        script {\n\n            name = \"Run Tests\"\n\n            scriptContent = \"./gradlew test\"\n\n        }\n\n    }\n\n    features {\n\n        xmlReport {\n\n            reportType = XmlReport.XmlReportType.JUNIT\n\n            rules = \"build/test-results/test/*.xml\"\n\n        }\n\n        htmlReport {\n\n            reportDir = \"build/reports/tests/test\"\n\n            startPage = \"index.html\"\n\n            reportName = \"Test Results\"\n\n        }\n\n        investigationsAutoAssigner {\n\n            users = \"teamlead\"\n\n            assignOnSecondFailure = true\n\n            assignOnNewFailure = true\n\n        }\n\n    }\n\n    failureConditions {\n\n        executionTimeoutMin = 30\n\n        testFailure = false  // Don't fail build on test failures, just report\n\n    }\n\n})\nConditional stages and matrix builds\nJenkins’s conditional logic can become complex and hard to maintain:\npipeline {\n\n    stages {\n\n        stage('Deploy to Production') {\n\n            when {\n\n                branch 'main'\n\n                environment name: 'DEPLOY_PROD', value: 'true'\n\n            }\n\n            steps {\n\n                sh './deploy-prod.sh'\n\n            }\n\n        }\n\n    }\n\n    strategy {\n\n        matrix {\n\n            axes {\n\n                axis {\n\n                    name 'JAVA_VERSION'\n\n                    values '11', '17', '21'\n\n                }\n\n                axis {\n\n                    name 'OS'\n\n                    values 'ubuntu-latest', 'windows-latest'\n\n                }\n\n            }\n\n        }\n\n        stages {\n\n            stage('Test Matrix') {\n\n                steps {\n\n                    sh './test-java-${JAVA_VERSION}.sh'\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\nTeamCity’s approach is more explicit and maintainable, with better reusability:\nobject ProductionDeploy : BuildType({\n\n    name = \"Production Deploy\"\n\n    steps {\n\n        script {\n\n            name = \"Deploy to Production\"\n\n            scriptContent = \"./deploy-prod.sh\"\n\n            conditions {\n\n                equals(\"teamcity.build.branch\", \"main\")\n\n                equals(\"deploy.environment\", \"production\")\n\n            }\n\n        }\n\n    }\n\n})\n\n// Matrix builds as separate build configurations with reusable functions\n\nfun createTestBuild(javaVersion: String, os: String): BuildType {\n\n    return BuildType({\n\n        name = \"Test Java $javaVersion on $os\"\n\n        params {\n\n            text(\"java.version\", javaVersion)\n\n            text(\"agent.os\", os)\n\n        }\n\n        steps {\n\n            script {\n\n                scriptContent = \"./test-java-%java.version%.sh\"\n\n            }\n\n        }\n\n        requirements {\n\n            equals(\"system.os\", os)\n\n        }\n\n    })\n\n}\n\n// Create matrix builds programmatically\n\nval testBuilds = listOf(\n\n    createTestBuild(\"11\", \"Linux\"),\n\n    createTestBuild(\"17\", \"Linux\"),\n\n    createTestBuild(\"21\", \"Linux\"),\n\n    createTestBuild(\"11\", \"Windows\"),\n\n    createTestBuild(\"17\", \"Windows\"),\n\n    createTestBuild(\"21\", \"Windows\")\n\n)\nArtifact management\nJenkins’s artifact handling requires careful configuration and lacks sophisticated dependency management:\npipeline {\n\n    stages {\n\n        stage('Build') {\n\n            steps {\n\n                sh './gradlew build'\n\n            }\n\n            post {\n\n                success {\n\n                    archiveArtifacts([\n\n                        artifacts: 'build/libs/*.jar,build/distributions/*.zip',\n\n                        allowEmptyArchive: false,\n\n                        fingerprint: true\n\n                    ])\n\n                }\n\n            }\n\n        }\n\n        stage('Deploy') {\n\n            steps {\n\n                // Copy artifacts from upstream build\n\n                copyArtifacts([\n\n                    projectName: 'upstream-job',\n\n                    selector: lastSuccessful(),\n\n                    target: 'artifacts/'\n\n                ])\n\n                sh 'deploy.sh artifacts/*.jar'\n\n            }\n\n        }\n\n    }\n\n}\nTeamCity provides sophisticated artifact management, with dependency tracking and automatic cleanup:\nobject BuildWithArtifacts : BuildType({\n\n    name = \"Build and Archive\"\n\n    steps {\n\n        script {\n\n            name = \"Build Application\"\n\n            scriptContent = \"./gradlew build\"\n\n        }\n\n    }\n\n    artifactRules = \"\"\"\n\n        build/libs/*.jar => libs/\n\n        build/distributions/*.zip => distributions/\n\n        build/reports/** => reports/\n\n    \"\"\".trimIndent()\n\n    cleanup {\n\n        keepRule {\n\n            id = \"keep_successful_builds\"\n\n            keepAtLeast = days(30)\n\n            applyToBuilds {\n\n                inBranches {\n\n                    branchFilter = \"+:refs/heads/main\"\n\n                }\n\n                withStatus = BuildStatus.SUCCESSFUL\n\n            }\n\n            preserveArtifacts = PreserveArtifacts.ALL\n\n        }\n\n    }\n\n})\n\nobject DeployWithArtifacts : BuildType({\n\n    name = \"Deploy Application\"\n\n    dependencies {\n\n        artifacts(BuildWithArtifacts) {\n\n            buildRule = lastSuccessful()\n\n            artifactRules = \"\"\"\n\n                libs/*.jar => app/\n\n                distributions/*.zip => packages/\n\n            \"\"\".trimIndent()\n\n        }\n\n    }\n\n    steps {\n\n        script {\n\n            name = \"Deploy\"\n\n            scriptContent = \"\"\"\n\n                echo \"Deploying artifacts...\"\n\n                ./deploy.sh app/*.jar\n\n            \"\"\".trimIndent()\n\n        }\n\n    }\n\n})\nBenefits of Kotlin DSL\nThe advantages of TeamCity’s Kotlin DSL approach become clear when you’re managing complex pipelines:\nType safety and IDE support: Your IDE can provide autocompletion, refactoring tools, and compile-time error checking for pipeline configurations. This eliminates the trial-and-error cycles common with Jenkinsfile development.\nReusability and modularity: You can create reusable functions, templates, and shared configuration objects. This reduces duplication and makes it easier to maintain consistent patterns across multiple projects.\nVersion-control integration: Kotlin DSL configurations are easier to review in pull requests, track changes over time, and understand the impact of modifications. The type system makes it clearer what each change affects.\nWhat does a safe migration plan look like?\nSuccessfully migrating from Jenkins to a more modern system requires a structured, phased approach that minimizes risk while incrementally proving value as you go.\nYou’ll get the most value out of your migration if you don’t treat it as a direct-translation exercise but as an opportunity to modernize and improve your CI/CD workflows.\nPhase 1: Discovery and assessment\nGoal: Understand your current Jenkins environment and identify the biggest challenges you want to overcome through migration.\nKey question: What are the most significant problems we want to solve by migrating, and how will you measure success?\nThe discovery phase involves conducting a comprehensive audit of your Jenkins instances and documenting all active jobs, pipelines, and their dependencies. Create an inventory that includes Jenkinsfiles, freestyle jobs, shared libraries, custom plugins, and external integrations. Pay special attention to identifying critical pipelines that cannot afford downtime and any custom functionality that might require special handling.\nThis audit should go beyond simple documentation. Ask what business goal each Jenkins pipeline was originally designed to accomplish. Many complex Jenkins configurations exist as workarounds for platform limitations rather than optimal solutions. Similarly, some pipelines may have evolved organically, accumulating complexity that can be eliminated in a fresh implementation.\nDuring this phase, engage with development teams to understand their pain points with the current system. Document specific examples of maintenance overhead, debugging challenges, and workflow inefficiencies. This information will guide your migration priorities and help you measure the success of your TeamCity implementation.\nPhase 2: Pilot setup\nGoal: Set up a low-risk TeamCity environment, and demonstrate core capabilities with a representative workload.\nKey question: Can you prove measurable value at a small scale before committing to a broader migration?\nChoose a pilot project that represents typical patterns in your organization but won’t impact critical business operations if problems occur. This might be an internal tool, a staging-environment pipeline, or a new feature-branch workflow. The goal is to validate TeamCity’s capabilities with real work while building team confidence.\nResist the temptation to simply recreate your Jenkins pipeline as is in TeamCity. Treat the pilot as an opportunity to implement best practices from the start. Use TeamCity’s visual build chains to clarify pipeline dependencies, leverage Kotlin DSL for maintainable configuration, and take advantage of built-in features like test parallelization and flaky test detection.\nSet up side-by-side comparisons where possible. Run the same builds in both Jenkins and TeamCity to compare performance, reliability, and developer experience. Document specific improvements, such as reduced build times, clearer failure diagnostics, or easier configuration management.\nCollect detailed feedback from the development team using the pilot system. Focus on daily workflow impact. Is it easier to understand build failures? Are configuration changes simpler to make? Does the system provide better visibility into test results?\nPhase 3: Incremental migration\nGoal: Migrate remaining pipelines based on complexity and business criticality while maintaining Jenkins as a fallback option.\nKey question: How can you migrate safely without disrupting team productivity or deployment capabilities?\nDevelop a migration priority matrix based on pipeline complexity, business criticality, and team readiness. Start with simpler, less critical pipelines to build expertise and confidence. Save the most complex or business-critical systems for later when your team has developed migration best practices.\nFor each pipeline migration, follow a consistent modernization approach. Review the original Jenkins implementation to understand its intended purpose. Then, design a TeamCity solution that accomplishes the same goals using native platform capabilities. This often results in simpler, more maintainable configurations.\nMaintain Jenkins pipelines in parallel during this phase so you can do quick rollbacks if issues arise. Use feature flags or branch-based routing to gradually shift traffic to TeamCity while keeping Jenkins as a safety net. This parallel operation also allows you to validate that TeamCity implementations produce identical results.\nUse Kotlin DSL consistently for new TeamCity configurations. This investment in type-safe, maintainable pipeline definitions pays dividends as your migration scales and more teams adopt the platform.\nPhase 4: Optimization\nGoal: Take full advantage of TeamCity’s advanced features to achieve benefits beyond basic pipeline migration.\nKey question: How can you unlock capabilities that weren’t possible with Jenkins to improve development velocity and quality?\nThis phase focuses on using TeamCity’s built-in intelligence and optimization features. Enable flaky test detection to automatically identify unreliable tests that waste developer time. Configure test parallelization to reduce build times and provide faster feedback on changes.\nImplement visual build chains to make complex workflows easier to understand and maintain. Use TeamCity’s dependency management to optimize resource utilization and reduce unnecessary work. Take advantage of TeamCity’s superior observability features. Set up dashboards that provide clear visibility into build performance, test results, and system health. Configure meaningful notifications that help developers focus on actionable issues rather than noise.\nConsider implementing TeamCity’s integration features with development tools like IDEs, issue trackers, and deployment platforms. These integrations can significantly improve developer workflow efficiency when working with TeamCity builds.\nPhase 5: Full cutover\nGoal: Complete the migration by retiring Jenkins and ensuring all teams are successfully operating on TeamCity.\nKey question: Are you confident enough in your TeamCity implementation to retire Jenkins and scale this success to other teams?\nEstablish comprehensive monitoring for your TeamCity environment before retiring Jenkins. This includes system performance metrics, build success rates, and developer satisfaction indicators. You want to catch any issues quickly and have data to demonstrate migration success.\nOnce you’re ready, create a formal Jenkins retirement plan that includes data archival, access revocation, and infrastructure decommissioning. Ensure you maintain access to historical build data and artifacts as needed for compliance or debugging purposes.\nDocument migration outcomes and lessons learned. Consider creating case studies that demonstrate measurable improvements in build performance, developer productivity, and system maintainability. This documentation will be valuable for expanding TeamCity adoption to other teams and for ongoing system optimization.\nIt may also be worth establishing an internal guild focused on CI/CD best practices with TeamCity. This group can help new teams adopt the platform effectively and continue evolving your implementation based on emerging needs.\nExplaining the migration to management\nTechnical migrations often fail not because of technology issues but because of inadequate stakeholder communication and buy-in. Leadership needs to understand both the business case for migration and the risk-mitigation strategies that make it a safe investment.\nKey benefits for leadership\nPresent migration benefits in terms of business impact rather than technical features.\nLower CI/CD maintenance overhead translates to engineering time that can be redirected from infrastructure firefighting to product development. Quantify this where possible: If senior engineers currently spend 10 percent of their time managing Jenkins, that represents a significant opportunity cost.\nFaster builds and deployment cycles directly impact time to market and customer responsiveness. Demonstrate how TeamCity’s optimizations can reduce feedback loops and enable more frequent releases. This is particularly compelling for organizations pursuing competitive advantages through rapid innovation.\nBetter test insights and quality visibility reduce production incidents and customer-impacting defects. TeamCity’s flaky test detection and failure-analysis capabilities help teams identify quality issues before they reach customers, reducing support burden and protecting brand reputation.\nRisk-mitigation talking points\nAddress leadership concerns about migration risk directly and specifically.\nTeamCity supports parallel CI environments, which means you can validate the new system thoroughly without disrupting current operations. This isn’t a risky “big bang” migration that puts business continuity at stake.\nNo full cutover is required until teams are ready, which allows for controlled, incremental adoption. Teams can migrate when they have capacity and confidence rather than being forced into arbitrary timelines that create unnecessary stress and risk.\nThe phased rollout approach means early phases can be reversed easily if issues arise, while later phases build on proven success. This creates multiple decision points where leadership can evaluate progress and adjust strategy based on actual results rather than theoretical projections.\nBusiness-case template\nBelow is a template you can adapt for your organization’s specific situation and leadership communication style. You can find an editable copy of this template in the supporting files.\nProposal: TeamCity Migration to Reduce CI/CD Maintenance and Improve Development Velocity\nExecutive summary\nOur engineering team is requesting approval to migrate from Jenkins to TeamCity for our CI/CD infrastructure. This migration will reduce maintenance overhead currently consuming [X hours per week] of senior engineering time, improve build performance by an estimated [Y percent], and provide better visibility into code-quality issues before they reach production.\nCurrent challenges\nOur [your team name] team currently experiences [current pain point] with our Jenkins infrastructure. For example, [pipeline example] requires [specific maintenance burden or performance issue]. These issues are consuming approximately [time estimate] of engineering capacity that could be better spent on [strategic initiatives].\nProposed solution\nTeamCity offers a modern CI/CD platform with built-in capabilities that address our current pain points:\nReduced maintenance: The Kotlin DSL configuration eliminates plugin-compatibility issues and provides IDE support for pipeline development.\nImproved performance: Built-in test parallelization and intelligent caching can reduce build times by [estimated percentage].\nBetter quality insights: Automatic flaky test detection and comprehensive failure analysis help teams identify issues faster.\nRisk mitigation\nThis migration uses a proven, low-risk approach:\nParallel operation: TeamCity will run alongside Jenkins during transition, allowing immediate rollback if issues arise.\nIncremental adoption: We’ll migrate one pipeline at a time, starting with noncritical systems to validate the approach.\nPilot validation: Initial implementation will focus on [specific low-risk project] to prove value before broader adoption.\nSuccess metrics\nWe will measure migration success through these metrics:\nEngineering efficiency: Reduction in CI/CD maintenance time from [current] to [target].\nBuild performance: Average build-time improvement of [estimated percentage].\nQuality indicators: Faster identification of test issues and deployment problems.\nTimeline and investment\nPhase 1 (discovery): [timeframe] – current system audit and TeamCity environment setup.\nPhase 2 (pilot): [timeframe] – single project migration and validation.\nPhase 3 (rollout): [timeframe] – incremental migration based on pilot results.\nRecommendation\nWe recommend proceeding with Phase 1 (discovery) and a pilot implementation. This low-risk initial investment of [resource estimate] will provide concrete data about TeamCity’s benefits for our specific use cases and inform decisions about broader adoption.\nNext steps\nWith your approval, we will:\nConduct a comprehensive Jenkins environment audit.\nSet up a TeamCity evaluation environment.\nExecute pilot migration with [specific project].\nReport our results and recommendations for Phase 3.\nPlease let me know if you have questions about this proposal or would like additional details about any aspect of the migration plan.\nConclusion: Making migration a strategic success\nJenkins isn’t an inherently bad tool: It served the industry well during the early days of continuous integration and enabled countless teams to adopt automated build and deployment practices. However, like many tools from that era, Jenkins was designed for constraints and expectations that were different from what modern software development teams face today.\nIf your team is spending more time maintaining CI/CD infrastructure than building products, experiencing frequent pipeline-reliability issues, or lacking visibility into build and test performance, migration to a modern platform like TeamCity represents a strategic investment in developer productivity and system reliability.\nThe key to successful migration is approaching it as a systematic, risk-managed process rather than a disruptive technology replacement. With the right planning framework, you can migrate safely while improving your development workflows and team efficiency.\nStart with the migration-readiness checklist to perform an honest assessment of your current situation and organizational readiness. This self-evaluation will help you determine whether migration makes sense for your team and identify areas that need attention regardless of platform choice.\nExperiment with Kotlin DSL samples to understand how TeamCity’s approach differs from Jenkins and what benefits it offers for your specific use cases. The type safety and IDE support alone often convince teams that the learning investment is worthwhile.\nExecute a focused pilot project to validate TeamCity’s benefits in your environment with real workloads and development patterns. This proof-of-concept approach allows you to make data-driven decisions about broader adoption while building team confidence and expertise.\nTeamCity is a modern, scalable CI/CD platform that supports powerful pipeline authoring via Kotlin DSL, built-in test intelligence, and visual pipeline chains. Whether you’re a team of five or five hundred developers, TeamCity helps you ship software with confidence through better tooling, clearer visibility, and reduced maintenance overhead.\nThe migration frameworks and templates in this guide provide the structure you need to execute a successful transition. However, every organization’s situation is unique, so keep in mind that you’ll likely adapt these approaches based on your specific constraints and requirements.\nReady to explore how TeamCity can improve your development workflow? Visit the TeamCity website to learn more about our platform capabilities, or contact our team to discuss your specific migration requirements and get expert guidance for your transition planning.",
        "dc:creator": "Dmitrii Korovin",
        "content": "This article was brought to you by Cameron Pavey, draft.dev. Jenkins has served the development community well for over a decade, but it was designed for a different era of software development. Developers who are tired of fighting with plugin compatibility issues, slow builds, and brittle configurations are exploring alternatives. But is your organization ready [&#8230;]",
        "contentSnippet": "This article was brought to you by Cameron Pavey, draft.dev. Jenkins has served the development community well for over a decade, but it was designed for a different era of software development. Developers who are tired of fighting with plugin compatibility issues, slow builds, and brittle configurations are exploring alternatives. But is your organization ready […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=677066",
        "categories": [
          "best-practices",
          "teamcity-2",
          "devopspains",
          "jenkins"
        ],
        "isoDate": "2026-01-26T18:25:53.000Z"
      },
      {
        "creator": "Fatimazahra El Akkary",
        "title": "Building AI Agents in Kotlin – Part 5: Teaching Agents to Forget",
        "link": "https://blog.jetbrains.com/ai/2026/01/building-ai-agents-in-kotlin-part-5-teaching-agents-to-forget/",
        "pubDate": "Mon, 26 Jan 2026 16:09:12 +0000",
        "content:encodedSnippet": "Previously in this series:\nBuilding AI Agents in Kotlin – Part 1: A Minimal Coding Agent\nBuilding AI Agents in Kotlin – Part 2: A Deeper Dive Into Tools\nBuilding AI Agents in Kotlin – Part 3: Under Observation\nBuilding AI Agents in Kotlin – Part 4: Delegation and Sub-Agent\nAgents eventually run out of context. When they do, they crash, and you lose everything mid-task.\nWe’ve been running GPT-5 Codex since Part 1. It scores 0.58 on SWE-bench Verified. We tried Claude Sonnet 4.5 next, which scored 0.6 and ran faster on most tasks. But complex problems hit Claude’s 200K context window faster. \nYou’ll probably find yourself switching models too, for better performance, lower cost, or to run locally. Sometimes that means smaller context windows, especially for local models limited by expensive memory. But even the biggest context windows fail on complex and long tasks. You can’t just keep buying more context.\nThe problem is that agents hold onto everything: every file, every command output, every search result, every user message. Eventually, there’s no room left.\nThat’s where compression comes in. But not the lazy kind that just drops old messages when you run out of space. Think about handing off a task to another developer. You don’t give them a transcript of everything you did. You tell them the goal, what files you changed, what worked, and what didn’t. That’s smart compression: Keep the context needed to continue; drop the verbose history.\nLet’s figure out how to implement this in Koog. First, we need to understand what strategy = singleRunStrategy() has been doing since Part 1. This is where you see how strategies control your agent’s loop and how you can modify them to create your own flow. We’ll examine singleRunStrategy(), and then build a version that compresses automatically. \nWhat that strategy line does\nIn the previous parts, you built a coding agent. You gave it tools, along with this line:\nstrategy = singleRunStrategy()\nHere, a strategy is the code that runs your agent loop. All strategies share the same core elements: call the LLM, execute tools, send results back, repeat. But they differ in when they stop and what they do between iterations.\nsingleRunStrategy() is the simplest possible version. It keeps iterating as long as the LLM returns tool calls. In other words: call the LLM → return tool call? → execute → call again → return text? → done.\n\n\n\n\nIt works fine for simple tasks. But on complex problems, the history keeps growing. Every command output, every file read, every search result stays in context. Eventually you hit the limit and crash mid-task.\nWhat we need instead is a strategy that runs the same loop but also checks the history size and compresses it when it grows too large.\nAdding compression\nWe’re swapping this:\nstrategy = singleRunStrategy()\nFor this:\nstrategy = singleRunStrategyWithHistoryCompression()\nThe loop is the same, but there’s now a checkpoint between Execute Tool and Send Tool Result. After each tool execution, the strategy asks:\nCheck: Is the history greater than the threshold?\nIf yes? Compress it: Extract the important facts. Drop the rest.\nIf no? Continue as usual.\n\n\n\n\nThat checkpoint is what lets your agent complete long-running tasks within tighter token budgets to avoid the error “context window exceeded”.\nBut you have to configure it. The strategy can’t guess when the history is too big or what facts matter for your task. You have to tell it two things: when to compress, and what to keep.\nWhen to compress \nFirst, you set thresholds – how many messages or characters you allow before compression kicks in:\nval CODE_AGENT_HISTORY_TOO_BIG = { prompt ->\n   prompt.messages.size > 200 || prompt.messages.sumOf { it.content.length } > 200_000}\nWhy these numbers? We experimented with different thresholds after seeing where errors appeared.\n\n\n\n\nThis agent hit 220K tokens and crashed. Claude’s limit is 200K tokens. We needed to compress before reaching that point.\nWe set compression at 200 messages or 200,000 characters, whichever comes first. Note that the code measures characters, not tokens. They’re different, but this threshold keeps us under the token limit – high enough to avoid over-compression, low enough to prevent hitting the limit.\nThese numbers aren’t fixed. If your agent hits the limit earlier, lower the threshold. Still completing tasks past these thresholds? Raise them. The choice depends on your use case: file sizes, message length, how verbose your tool outputs are, task complexity. Experiment and find what works.\nWhat to keep\nYou’ve set when compression triggers. Now choose what to keep.\nThere are two options: Either trust the LLM to decide what’s important, or tell it exactly what to extract.\nOption 1: Trust the LLM to summarize\nThe LLM decides what’s important using WholeHistory:\ncompressionStrategy = WholeHistory\nWhen compression triggers, Koog asks the LLM to create a TL;DR summary of the entire conversation history.\nBefore compression:\nAll messages up to the threshold: system prompt, user messages, assistant responses, tool calls, tool results.\nAfter compression:\nSystem prompt (preserved).\nFirst user message (preserved, so the agent remembers the original goal). \nOne TL;DR summary message (written by the LLM).\nThe tradeoff: This approach is simple and fast, but you’re trusting the LLM to decide what matters. Sometimes it keeps exactly the right details. Sometimes it drops something critical.\nOption 2: Tell the LLM exactly what to extract\nInstead of telling the model to summarize everything, you specify exactly what facts to extract using RetrieveFactsFromHistory:\ncompressionStrategy = RetrieveFactsFromHistory(\n   Concept(...),\n   Concept(...),\n   ...\n)\nHow it works:\nYou define Concept objects: specific questions about your task that the agent must remember. When compression triggers, Koog makes one LLM call per concept, sending the full conversation history each time and asking just that single question.\n\n\n\n\nWhy separate calls? LLMs get worse at answering when you ask multiple questions at once. We saw this in testing: Bundle eight concepts into one prompt, and some answers come back vague or incomplete. Ask them one at a time, and each response is more reliable.\nDefining a concept\nEach Concept instance has three parts:\nkeyword: a label for logs \ndescription: the actual question or instruction the LLM should answer \nfactType: the expected format of the answer\n\nMULTIPLE for lists\nSINGLE for single value\nConcept(\n    keyword = \"project-structure\",\n    description = \"What is the project structure?\",\n    factType = FactType.MULTIPLE\n)\nChoosing the right concepts\nFor our coding agent, the key question is: What information, if lost, would force the agent to start over? \nHere’s what happens when compression drops critical information:\nThe agent opens the same file twice as though it’s never seen it before.\nIt rewrites tests that already exist.\nIt drifts away from the task you originally gave it.\nEach failure shows what must survive compression:\nRe-exploring files → You need a project-structure concept.\nRedoing finished work → You need an important-achievements concept.\nLosing direction → You need an agent-goal concept.\nOur coding agent concepts\nWhen we tested on SWE-bench-Verified, we ended up with eight concepts. Here are three of them:\nval CODE_AGENT_COMPRESSION_STRATEGY = RetrieveFactsFromHistory(\n    Concept(\n        \"project-structure\",\n        \"What is the structure of this project?\",\n        FactType.MULTIPLE\n    ),\n    Concept(\n        \"important-achievements\",\n        \"What has been achieved during the execution of this current agent?\",\n        FactType.MULTIPLE\n    ),\n    Concept(\n        \"agent-goal\",\n        \"What is the primary goal or task the agent is trying to accomplish in this session?\",\n        FactType.SINGLE\n    ),\n    ...\nYour agent may need different concepts. The goal isn’t to copy the list; it’s to identify what state your agent needs to continue working and define concepts that preserve that information.\nYou can check out the full implementation of the eight concepts on GitHub. \nWhich model to use \nJust like with sub-agents (Part 4), you can use different models for different parts of the process. The retrievalModel parameters lets you specify which LLM handles the history compression. This parameter is optional – if not specified, compression uses your agent’s main model.\nretrievalModel = OpenAIModels.Chat.GPT4_1Mini\nHere’s the complete configuration for the coding-agent strategy:\nstrategy = singleRunStrategyWithHistoryCompression(\n   config = HistoryCompressionConfig(\n       isHistoryTooBig = CODE_AGENT_HISTORY_TOO_BIG,\n       compressionStrategy = CODE_AGENT_COMPRESSION_STRATEGY,\n       retrievalModel = OpenAIModels.Chat.GPT4_1Mini\n   )\n)\nThree parameters: when to compress (isHistoryTooBig), what to keep (compressionStrategy), and which model does the work (retrievalModel).\nConclusion\nAt this point, your agent can run longer tasks without hitting context limits. The compression problem is solved. Instead of crashing when it runs out of space, the agent compresses its history, keeping decisions and outcomes while dropping verbose outputs, and continues working within whatever token budget you have.\nIn this series, we started with a basic coding agent in Part 1. Since then, we’ve added tools, observability, sub-agents, and history compression. These five pieces give you what you need to build working AI agents in Kotlin that can operate within the constraints of real models.\nIf you want to keep building and practicing these patterns, planning and reasoning are interesting areas to explore: how agents decide what to do across multiple turns and how they break down complex problems. We didn’t cover those here, but they’re good practice once you’ve got these pieces working. \nThe full code’s on GitHub. If you run into any issues, leave a comment. We’re happy to help 😊",
        "dc:creator": "Fatimazahra El Akkary",
        "content": "Previously in this series: Agents eventually run out of context. When they do, they crash, and you lose everything mid-task. We&#8217;ve been running GPT-5 Codex since Part 1. It scores 0.58 on SWE-bench Verified. We tried Claude Sonnet 4.5 next, which scored 0.6 and ran faster on most tasks. But complex problems hit Claude&#8217;s 200K [&#8230;]",
        "contentSnippet": "Previously in this series: Agents eventually run out of context. When they do, they crash, and you lose everything mid-task. We’ve been running GPT-5 Codex since Part 1. It scores 0.58 on SWE-bench Verified. We tried Claude Sonnet 4.5 next, which scored 0.6 and ran faster on most tasks. But complex problems hit Claude’s 200K […]",
        "guid": "https://blog.jetbrains.com/?post_type=ai&p=676707",
        "categories": [
          "kotlin",
          "tutorials",
          "ai",
          "ai-agents"
        ],
        "isoDate": "2026-01-26T16:09:12.000Z"
      },
      {
        "creator": "Sasha Korepanov",
        "title": "How We Made Variable Inspections 87 Times Faster for Unreal Engine in Rider",
        "link": "https://blog.jetbrains.com/dotnet/2026/01/26/how-we-made-variable-inspections-87-times-faster-for-unreal-engine-in-rider/",
        "pubDate": "Mon, 26 Jan 2026 13:08:53 +0000",
        "content:encodedSnippet": "If you’ve ever expanded a complex Unreal Engine variable in Rider’s debugger and had time to contemplate your life choices, this post is for you.\nWe’ve rewritten our expression evaluator, and the results are dramatic: Variable inspection is up to 87 times faster on warm runs and 16 times faster on cold ones. The debugger memory usage has dropped to just over a third of what it was. And there’s even a bonus benefit, but more on that at the end.\nThese improvements are already available for you to test in Rider 2026.1 EAP 1. But how did we get here? Buckle up – things are about to get very technical, but the payoff will be worth it.\nTest it in Rider 2026.1 EAP 1\n                                                    \nThe Natvis of it all\nVariable visualization is one of the most important features of any debugger. Without it, debuggers show just raw class fields – no array elements, no map contents, just raw pointers to memory, trees, and hash tables. There are many ways to tell debuggers how to display types nicely: pretty printers, data formatters, Natvis, and others.\nIf you use the MSVC C++ toolchain to build your programs, there’s a 99% chance you’re using Natvis. Natvis allows you to describe how to visualize your types. You can specify which items to show and describe that a type should be visualized as an array. Or, if you have a hash table, you can write complex expressions with temporary local variables, invisible to the debugged program, for extracting elements. Natvis also supports intrinsics – user-defined functions that prevent code duplication and make expressions more structured.\nTo understand what Natvis does, let’s look at a simple example with std::string using the standard stl.natvis:\n\n\n\n\nAs you can see, the debugger must evaluate at least 6 expressions when you expand a simple string object.\nThe LLDB challenge\nRider supports Natvis, and uses it when you debug native C++ applications on Windows. But here’s the tricky part: Rider uses LLDB as its native C++ debugger, and LLDB doesn’t support Natvis natively. Instead, LLDB supports data formatters, which allow writing arbitrary Python code.\nWe thought we had it all figured out when we developed a special data formatter that implements Natvis support under Rider’s hood. The formatter parses Natvis files – matching types, creating items, generating summary strings, and building child hierarchies… Except we ran into some problems. \nWe had to use LLDB’s expression evaluator to evaluate Natvis expressions. This evaluator uses Clang under the hood, which is powerful but brings significant issues:\nMaintenance pains: Clang parsers are notoriously difficult to maintain. Sometimes, valid Natvis expressions simply wouldn’t compile, and debugging these failures was extremely challenging.\nPerformance problems: It’s slow – very slow.\nLimited intrinsic support: There’s no simple way to register and call intrinsics.\nMemory pollution: Declaring temporary variables for expressions injects those variables into the debugged process.\n\n\n\n\nTo work around these issues, we accumulated hacks everywhere. We had hacks in Clang, tried inlining intrinsics, and used top-level function declarations (an LLDB feature) for intrinsics that couldn’t be inlined. To improve performance, we cached Clang parsing results. But all these workarounds were unreliable and unstable.\nIf you use Rider for Unreal Engine, you’ve probably noticed that after updating the Unreal Engine version, TMap or TArray visualization sometimes stops working. This happens because Unreal.natvis becomes more complex with every update, and LLDB’s expression evaluator can’t handle the new expressions properly. Additionally, using LLDB’s expression evaluator within LLDB data formatters is fundamentally problematic.\nBuilding our own solution\nTo eliminate these issues, we decided to rethink how we work with Natvis entirely. Our first step: develop an alternative expression evaluator for Natvis without Clang. We knew about lldb-eval – another custom expression evaluator for LLDB that’s fast and powerful – but we wanted complete control, so we implemented our own evaluator from scratch.\nYes, we threw out an entire time-tested system and rewrote everything. Before you question our sanity, let us show you why it was worth it.\nThe results\nWe didn’t create artificial synthetic projects for testing. Instead, we used a standard Lyra game demo and created a script that recursively dumps variable children, emulating the scenario where you expand variables to see their contents. The script processes 6,000 values with two measurement scenarios: cold debugger (the very first evaluation, like a fresh debug session) and warm debugger (with all caches warmed up).\n\nColdWarmDebugger RAM usage\nStandard LLDB evaluator115 seconds7 seconds9 GB\nOur new evaluator7 seconds0.08 seconds3.5 GB\n\n\n\n\n\nThat’s 16 times faster on cold starts and 87 times faster on warm runs! Plus, it takes just over a third of the memory as before. The difference is immediately noticeable during debugging. On massive Unreal Engine projects, the improvement is even more dramatic.\nThe bonus benefit we promised you\nOur new expression evaluator delivered two additional benefits we did not foresee.\n🎉 Core dumps finally work properly . The standard LLDB evaluator performs poorly with core dumps – almost every expression from Unreal.natvis fails, resulting in terrible visualization. With our new evaluator, Natvis works completely and reliably. The difference is striking:\nWhat Rider 2025.3 with the standard LLDB expression evaluator looks like in comparison to Rider 2026.1 EAP 1 with the alternative LLDB expression evaluator.\n\n\n\nPerformance is better across the board. Since this is a general expression evaluator, we also use it for:\nNormal expression evaluation (Add to Watches actions)\nConditional breakpoints\nWhile the performance boost here isn’t as dramatic and depends on the specific expression, even simple expressions make conditional breakpoints at least 20% faster. For complex expressions, the difference can be even larger!\nWhat do you think?\nThese improvements are already available for you to test in the Early Access Program builds for Rider 2026.1. Give one of the EAP builds a try (they’re free!) and let us know how much faster your debugging sessions become. \nTest it in Rider 2026.1 EAP 1\n                                                    \nIf you enjoyed this story, perhaps you’d also like a to know how we made LLDB’s stepping time 50 times faster in Rider.  Cheers!",
        "dc:creator": "Sasha Korepanov",
        "content": "If you&#8217;ve ever expanded a complex Unreal Engine variable in Rider&#8217;s debugger and had time to contemplate your life choices, this post is for you. We&#8217;ve rewritten our expression evaluator, and the results are dramatic: Variable inspection is up to 87 times faster on warm runs and 16 times faster on cold ones. The debugger [&#8230;]",
        "contentSnippet": "If you’ve ever expanded a complex Unreal Engine variable in Rider’s debugger and had time to contemplate your life choices, this post is for you. We’ve rewritten our expression evaluator, and the results are dramatic: Variable inspection is up to 87 times faster on warm runs and 16 times faster on cold ones. The debugger […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=676804",
        "categories": [
          "net-tools",
          "rider",
          "eap",
          "game-debugging",
          "game-development",
          "lldb",
          "unreal-engine"
        ],
        "isoDate": "2026-01-26T13:08:53.000Z"
      },
      {
        "creator": "Daria Voronina",
        "title": "Meet the First Speakers Heading to KotlinConf 2026",
        "link": "https://blog.jetbrains.com/kotlin/2026/01/meet-the-first-speakers-heading-to-kotlinconf-2026/",
        "pubDate": "Mon, 26 Jan 2026 09:58:20 +0000",
        "content:encodedSnippet": "With each KotlinConf, developers from around the world come together to learn from leading experts, explore the latest industry insights, and engage with the Kotlin community. KotlinConf’25 alone welcomed attendees from over 50 countries.\nKotlinConf’26 is just a few months away, and we’re excited to introduce the first round of speakers who will be joining us on stage.\nThey’re the brilliant minds shaping the future of the language and the wider ecosystem – and this is just the beginning. KotlinConf’26 will be packed with inspiring talks, in-depth workshops, and plenty of opportunities to learn, share ideas, and connect with fellow Kotlin enthusiasts.\n\n\n\n\nWant to meet the people defining what’s next for Kotlin and the industry around it? Secure your ticket and get ready for an unforgettable conference experience.\nSave your spot at KotlinConf’26\n         \nMore speakers and the full schedule are coming soon – stay tuned!",
        "dc:creator": "Daria Voronina",
        "content": "With each KotlinConf, developers from around the world come together to learn from leading experts, explore the latest industry insights, and engage with the Kotlin community. KotlinConf’25 alone welcomed attendees from over 50 countries. KotlinConf’26 is just a few months away, and we’re excited to introduce the first round of speakers who will be joining [&#8230;]",
        "contentSnippet": "With each KotlinConf, developers from around the world come together to learn from leading experts, explore the latest industry insights, and engage with the Kotlin community. KotlinConf’25 alone welcomed attendees from over 50 countries. KotlinConf’26 is just a few months away, and we’re excited to introduce the first round of speakers who will be joining […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=676361",
        "categories": [
          "news",
          "kotlinconf"
        ],
        "isoDate": "2026-01-26T09:58:20.000Z"
      },
      {
        "creator": "Anna Rovinskaia",
        "title": "New Livestream – From Detection to Remediation: Wiz in Your JetBrains IDE",
        "link": "https://blog.jetbrains.com/idea/2026/01/new-livestream-engineers-talk-about-spring-boot-4-life-and-other-stuff/",
        "pubDate": "Mon, 26 Jan 2026 09:39:43 +0000",
        "content:encodedSnippet": "Join our upcoming IntelliJ IDEA livestream with Daniel Velikanski from Wiz to see how cloud security insights can be brought directly into your JetBrains IDE, helping you detect and address real risks as you code. \nDate: February 5, 2026\nTime: 3:00–4:00 pm UTC\nREGISTER FOR THE LIVESTREAM\n\n\n\n\nSession abstract\nDevelopers move fast in the cloud, and security tools need to move just as fast to keep from slowing them down. Built through a collaboration between JetBrains and Wiz, the Wiz plugin for JetBrains IDEs brings Wiz’s cloud security context directly into the tools you use every day. You can now identify and address real application security risks as you code. Misconfigurations, vulnerabilities, exposed secrets, and sensitive data are surfaced directly in the IDE, making security a natural part of your workflow. This marks another step in Wiz’s mission to secure everything you build and run in the cloud, from the first line of code to deployment.\nIn this talk, we will bring those capabilities to life, showing how the plugin works in action and how it allows you to write code more securely.\nYour speaker and host\nSpeaker\nDaniel Velikanski\nDaniel Velikanski is a Product Manager at Wiz, leading initiatives on Wiz Code and WizOS with a focus on application security posture management, developer security, and container security. With close to ten years of software engineering experience, including several at Wiz before transitioning to product management, Daniel combines deep technical expertise with a strong understanding of developer workflows.\nLinkedIn\nHost\nEvgeny Borisov\nEvgeny has been working with Java since 2001, building and leading complex enterprise systems, consulting engineering teams, and training thousands of developers worldwide. Over the years, he has grown from a hands-on engineer to an architect, educator, and community speaker. Today, Evgeny leads the Java Developer Advocacy team at JetBrains, focusing on enhancing developer productivity in IntelliJ IDEA and delivering deep technical insights into the Spring ecosystem. He continues to share his experience through conference talks and workshops across the globe.\nLinkedIn\nX\nAsking questions\nDaniel will try to answer all of your questions from the chat during the session. If we run out of time, we’ll publish answers to any remaining questions in a follow-up blog post.\nHappy developing!",
        "dc:creator": "Anna Rovinskaia",
        "content": "Join our upcoming IntelliJ IDEA livestream with Daniel Velikanski from Wiz to see how cloud security insights can be brought directly into your JetBrains IDE, helping you detect and address real risks as you code. Date: February 5, 2026 Time: 3:00–4:00 pm UTC REGISTER FOR THE LIVESTREAM Session abstract Developers move fast in the cloud, [&#8230;]",
        "contentSnippet": "Join our upcoming IntelliJ IDEA livestream with Daniel Velikanski from Wiz to see how cloud security insights can be brought directly into your JetBrains IDE, helping you detect and address real risks as you code. Date: February 5, 2026 Time: 3:00–4:00 pm UTC REGISTER FOR THE LIVESTREAM Session abstract Developers move fast in the cloud, […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=676269",
        "categories": [
          "livestreams",
          "intellij-idea",
          "intellijidealivestream",
          "livestream",
          "webinars"
        ],
        "isoDate": "2026-01-26T09:39:43.000Z"
      },
      {
        "creator": "Andrey Belyaev",
        "title": "Spring Boot Debugging – Now Remote",
        "link": "https://blog.jetbrains.com/idea/2026/01/spring-boot-debugging-now-remote/",
        "pubDate": "Fri, 23 Jan 2026 16:17:13 +0000",
        "content:encodedSnippet": "We released Spring Debugger in May 2025 to bring more clarity to the “magic” behind Spring Boot – helping you see what’s really happening inside your running application. By the end of 2025, the plugin had reached more than 300,000 unique downloads and became a trusted tool within the developer community.\nWe’ve received a lot of valuable feedback, including feature requests, bug reports, and improvement ideas. Surprisingly, this was the most common question:\n“Can I debug remote applications?”\nIn this version, we’re happy to say that yes, you can.\nRemote debug with Spring Debugger\nWhen we started developing Spring Debugger, one of our cornerstone principles was:\n“We do not want to use any debug agents.”\nAdding agents to local code often makes setup harder, increases maintenance overhead, and can interfere with the debugging process. We decided to keep this approach for remote debugging as well.\nThe main challenge in remote debugging was gathering bean information after attaching to the app.\nIn the local setup, that’s simple – we set a non-suspending breakpoint in the method that finalizes Spring context initialization and then read all beans from the context. Remotely, however, the application is already running, and the context is fully initialized when we attach.\nContainer threading model and debugging\nOur current solution is to suspend one of the servlet-container threads and read the Spring context from that thread. This approach is where our decision to avoid using debug agents is truly tested.\nThe behavior of Spring Debugger depends on which embedded servlet container your Spring Boot app is using, as each container handles network I/O and worker threads differently.\nWith Apache Tomcat, the connector maintains a pool of worker threads as soon as the server starts. Because these threads are available and ready before any HTTP request arrives, the Spring Debugger can hook into one of them immediately after startup and fetch the Spring application context.\nBy contrast, with Eclipse Jetty or Undertow, the thread model is more layered. For example, Jetty uses separate producer (I/O) threads and worker (task) threads submitted to an Executor. \nUndertow uses I/O (event‐loop) threads for non‐blocking network handling and dispatches to worker threads for actual request processing. \nBecause a fully available worker thread with access to the Spring context can only appear once a request is processed, the debugger cannot load context information until the first incoming connection.\nIn short, when running on Tomcat, Spring Debugger can present the context immediately. When running on Jetty/Undertow, there is a slight delay in context loading before the first HTTP request. This is not a bug – it is a design trade-off linked to our agent-free inspection approach.\nYou can still debug remote Spring applications with nearly all Spring Debugger features – the main difference is when the context becomes available for inspection.\nHow to configure remote debugging\nThe process is the same as standard JVM remote debugging – run your application with an open debug port and connect using the Remote JVM Debug configuration.\nFor example, in a Docker Compose setup on a remote server:\nhttp-server:\n depends_on:\n   - postgresql\n image: 'jb/http-server:latest'\n environment:\n   - SPRING_DATASOURCE_URL=jdbc:postgresql://postgresql:5432/db\n   - SPRING_DATASOURCE_USERNAME=user\n   - SPRING_DATASOURCE_PASSWORD=secret\n   - JAVA_TOOL_OPTIONS=-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=*:5005\n ports:\n   - '8080:8080'\n   - '5005:5005'\n\n\n\n\nThe key line is:\nJAVA_TOOL_OPTIONS=-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=*:5005\n\n\n\n\nThis is a well-known option for enabling remote debugging. It opens port 5005 for debugger connections and exposes it from the container.\nTo start debugging, create a Remote JVM Debug configuration in IntelliJ IDEA and make sure to specify the correct module classpath.\n\n\n\n\nThat’s it – you can now debug the remote application, inspect property values, evaluate bean expressions, and analyze transactions right inside your IDE.\nLimitations\nRemote debugging differs slightly from local debugging, but there are a few limitations:\nOnly embedded containers (Tomcat, Jetty, Undertow) are currently supported.\nYou need to specify the module classpath in your run configuration.\nDatabase connections are shown, but the database structure view is not available.\nThe last point might be disappointing, but direct access to a remote database is often not technically possible – it may be inside a Docker network, a separate environment, or behind a firewall. We’re working on finding a solution, but this will take some time.\nConclusion\nThe new version of Spring Debugger takes another step toward application troubleshooting by adding remote attach support. Even if you’ve never tried remote debugging before, you’ll find the process almost identical to local debugging – just open a port and connect from IntelliJ IDEA.\nNo agents, no actuators, just a standard remote port and a regular debug session.\nSimply hit Debug and dive into your running application – inspect beans, properties, transactions, and use extended expression evaluation capabilities.\nWe’re exploring optional agent-based extensions for environments where deeper introspection is worth the trade-off, and we’d love to hear your feedback.\nHappy coding!",
        "dc:creator": "Andrey Belyaev",
        "content": "We released Spring Debugger in May 2025 to bring more clarity to the “magic” behind Spring Boot – helping you see what’s really happening inside your running application. By the end of 2025, the plugin had reached more than 300,000 unique downloads and became a trusted tool within the developer community. We’ve received a lot [&#8230;]",
        "contentSnippet": "We released Spring Debugger in May 2025 to bring more clarity to the “magic” behind Spring Boot – helping you see what’s really happening inside your running application. By the end of 2025, the plugin had reached more than 300,000 unique downloads and became a trusted tool within the developer community. We’ve received a lot […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=675548",
        "categories": [
          "news",
          "remote-debug",
          "remote-development",
          "spring-debugger"
        ],
        "isoDate": "2026-01-23T16:17:13.000Z"
      },
      {
        "creator": "Simon Vergauwen",
        "title": "Ktor 3.4.0 Is Now Available!",
        "link": "https://blog.jetbrains.com/kotlin/2026/01/ktor-3-4-0-is-now-available/",
        "pubDate": "Fri, 23 Jan 2026 14:05:30 +0000",
        "content:encodedSnippet": "Ktor 3.4.0 improves stability and addresses outstanding issues. Highlights include OpenAPI generation, Ztsd support for the compression plugin, duplex streaming for OkHttp, Structured concurrency integrations for the HTTP request lifecycle, and much more. For a detailed list of all the changes, check out the What’s new page.\nStability and performance\nWith its focus on stability and fixes for some long-standing issues, this release ensures Ktor is ready for another year of amazing development! \nBecause stability and performance remain among our top priorities heading into the new year, we want to invite all of you again to join the Ktor Early Access Program and help us test new versions and features. Start building your next project at start.ktor.io. Your suggestions and contributions are always welcome!\nGet Started With Ktor 3.4.0\n         \nOpenAPI generation from code\nIn 3.4.0, we completed the story for OpenAPI document generation by introducing a new API for dynamically documenting endpoints that works in tandem with a new compiler plugin. Now, instead of building your Swagger frontend from a static file, the model is built at runtime from details embedded in the routing tree.\nTo generate your documentation, you can enable it through the Ktor Gradle plugin, then it will automatically provide details in your code via the new describe API:\n/**\n * Our existing plugins work with the information found in the routes.\n */\nswaggerUI(\"/docs\") {\n    // Customize the result with general details\n    info = OpenApiInfo(\"KChat API\", \"1.0.0\")\n}\n\n/**\n * Get a list of messages.\n * \n * Query parameters: \n *  - search [String] a search query\n */\nget(\"/messages\") {\n    val query = call.parameters[\"search\"]?.parseQueryOrNull()\n    call.respond(messageTable.listMessages(query))\n}.describe {\n    // This code is generated from the code above\n    summary = \"Get a list of messages\"\n    parameters {\n        query(\"q\") {\n            description = \"a search query\"\n        }\n    }\n    responses {\n        HttpStatusCode.OK {\n            schema = jsonSchema<Message>()\n        }\n    }\n}\nDuplex streaming for OkHttp\nThe OkHttp client engine now supports duplex streaming, enabling clients to send request body data and receive response data simultaneously, in contrast to regular HTTP calls, where the request body must be fully sent before the response begins.\nDuplex streaming is available for HTTP/2 connections and can be enabled using the new duplexStreamingEnabled property in OkHttpConfig:\nval client = HttpClient(OkHttp) {\n    engine {\n        duplexStreamingEnabled = true\n        config {\n            protocols(listOf(Protocol.H2_PRIOR_KNOWLEDGE))\n        }\n    }\n}\nZstd compression support\nThe Compression plugin now supports Ztsd via the new ktor-server-compression-zstd module. Zstd is a fast compression algorithm that offers high compression ratios, low compression times, and a configurable compression level.  To set this level, call the zstd function from inside the compression block:\ninstall(Compression) {\n   zstd {\n       compressionLevel = 3\n       ...\n   }\n}\nHttpRequestLifecycle\nThe new HttpRequestLifecycle plugin allows you to cancel in-flight HTTP requests when the client disconnects, which is useful when you need to cancel a long-running or resource-intensive in-flight request. Simply install the HttpRequestLifecycle plugin and set cancelCallOnClose = true:\ninstall(HttpRequestLifecycle) {\n    cancelCallOnClose = true\n}\n\nrouting {\n    get(\"/long-process\") {\n        try {\n            while (isActive) {\n                delay(10_000)\n                logger.info(\"Very important work.\")\n            }\n            call.respond(\"Completed\")\n        } catch (e: CancellationException) {\n            logger.info(\"Cleaning up resources.\")\n        }\n    }\n}\nWhen the client disconnects, the coroutine handling the request is canceled, along with any launch or async coroutines started by it, and structured concurrency cleans all resources. This is currently only supported for the Netty and CIO engines.\n🚀 Thank you!\nWe want to thank everyone in the community for your support and feedback, as well as for reporting issues.\nStart building your next project at start.ktor.io. Your suggestions and contributions are always welcome! 🔗 Get Started With Ktor | 📢 Join the Community on Reddit and Slack",
        "dc:creator": "Simon Vergauwen",
        "content": "Ktor 3.4.0 improves stability and addresses outstanding issues. Highlights include OpenAPI generation, Ztsd support for the compression plugin, duplex streaming for OkHttp, Structured concurrency integrations for the HTTP request lifecycle, and much more. For a detailed list of all the changes, check out the What’s new page. Stability and performance With its focus on stability [&#8230;]",
        "contentSnippet": "Ktor 3.4.0 improves stability and addresses outstanding issues. Highlights include OpenAPI generation, Ztsd support for the compression plugin, duplex streaming for OkHttp, Structured concurrency integrations for the HTTP request lifecycle, and much more. For a detailed list of all the changes, check out the What’s new page. Stability and performance With its focus on stability […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=676081",
        "categories": [
          "ktor",
          "news",
          "releases",
          "backend",
          "kotlin",
          "release",
          "server-side"
        ],
        "isoDate": "2026-01-23T14:05:30.000Z"
      },
      {
        "creator": "Simon Vergauwen",
        "title": "Exposed 1.0 Is Now Available",
        "link": "https://blog.jetbrains.com/kotlin/2026/01/exposed-1-0-is-now-available/",
        "pubDate": "Fri, 23 Jan 2026 13:07:20 +0000",
        "content:encodedSnippet": "This is the first major release of Exposed – a huge milestone for both the project and the Exposed team! This release brings many new exciting features, the most requested being R2DBC support, as well as performance enhancements and bug fixes. Exposed 1.0 also introduces a stable API that guarantees no breaking changes until the next major release.\nGet started\nCan’t wait to start building your next project with Exposed 1.0? Check out the examples with Ktor or Spring and join the #exposed channel on Kotlin Slack if you have any questions or feedback.\nGet Started With Exposed\n         \nIf you are already using Exposed, check out the Migration Guide on how to migrate from version 0.61.0 to 1.0.\nWhat’s new\nR2DBC\nHighly requested by the community, R2DBC support has made it into Exposed. This brings support for reactive drivers to the Exposed SQL DSL approach.\nval database = R2dbcDatabase.connect(\n    url = \"r2dbc:postgresql://db:5432/mydatabase\",\n        databaseConfig = R2dbcDatabaseConfig {\n        defaultMaxAttempts = 1\n        defaultR2dbcIsolationLevel = IsolationLevel.READ_COMMITTED\n\n        connectionFactoryOptions {\n            option(ConnectionFactoryOptions.USER, dbUser)\n        }\n    }\n)\nSpring Support\nSpring is heavily used in Kotlin and with Exposed. For 1.0, we will continue to support Spring Boot 3 alongside Spring Boot 4. Exposed brings many quality of life improvements when using Spring with Exposed, such as GraalVM native image support and better transaction management.\n@Component\n@Transactional\nclass UserService {\n    // Use Exposed dsl without `transaction { }`\n    fun findUserById(id: UserId): User? =\n        UserTable.selectAll().where { UserTable.id eq id.value }\n            .firstOrNull()?.let { row ->\n                User(\n                    id = UserId(row[UserTable.id].value),\n                    name = row[UserTable.name],\n                    age = row[UserTable.age],\n                )\n            }\n}\nExposed 1.0: Stable, scalable, and looking forward | Chantal Loncle\nChantal Loncle gave an overview of Exposed 1.0, how we got here, and what the future might bring at KotlinConf 2025. (embed video in blog)\n\n\n\n\n\n\nThank you!\nWe want to thank everyone for their support, contributions, and feedback as we prepared for this release!\nWe’d especially like to thank all of our contributors whose pull requests were included in this release:\nAvi18971911, Attacktive, Marceli Grabowski, Michael Edwards, Tim Koopman, Mikhael Sokolov, Juan Luis Caro, Nick Telford, Ilya, Kuyho Chung, tronto20, mole828, Jiwoo Kim, Seonghyeon, Cho, Zachary Sistrunk, devch37\nYour suggestions and issue reports are always welcome!\nGet Started with Exposed | Join the Community on Slack",
        "dc:creator": "Simon Vergauwen",
        "content": "This is the first major release of Exposed – a huge milestone for both the project and the Exposed team! This release brings many new exciting features, the most requested being R2DBC support, as well as performance enhancements and bug fixes. Exposed 1.0 also introduces a stable API that guarantees no breaking changes until the [&#8230;]",
        "contentSnippet": "This is the first major release of Exposed – a huge milestone for both the project and the Exposed team! This release brings many new exciting features, the most requested being R2DBC support, as well as performance enhancements and bug fixes. Exposed 1.0 also introduces a stable API that guarantees no breaking changes until the […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=676201",
        "categories": [
          "exposed",
          "news",
          "releases",
          "backend",
          "kotlin",
          "release",
          "server-side"
        ],
        "isoDate": "2026-01-23T13:07:20.000Z"
      },
      {
        "creator": "Anna Maltseva",
        "title": "Codex Is Now Integrated Into JetBrains IDEs",
        "link": "https://blog.jetbrains.com/ai/2026/01/codex-in-jetbrains-ides/",
        "pubDate": "Thu, 22 Jan 2026 18:14:41 +0000",
        "content:encodedSnippet": "OpenAI Codex is now natively integrated into the JetBrains AI chat, giving you another powerful option for tackling real development tasks right inside your IDE. \nYou can use Codex with a JetBrains AI subscription, your ChatGPT account, or an OpenAI API key – all within the same AI сhat interface.\nSee Codex in action in a JetBrains IDE, as Dominik Kundel from OpenAI and Gleb Melnikov from JetBrains walk you through real development tasks:\n\n\n\n\n\n\nGet started with Codex in your IDE\nCodex is available directly in the AI chat of your JetBrains IDE (starting from v2025.3). Make sure you have the latest version of the AI Assistant plugin. You will find Codex in the agent picker menu and can start using it right away.\n\n\n\n\nIf you’re new to the AI chat, open the JetBrains AI widget in the top-right corner of your IDE, click Let’s Go, and follow the instructions to install the AI Assistant plugin. You can find a detailed step-by-step guide in the documentation.\n\n\n\n\nFlexible authentication options\nThere are several different ways you can authenticate Codex inside your JetBrains IDE, which means you can choose the setup that best fits your preferences:\nJetBrains AI\nUse Codex directly as part of your JetBrains AI subscription.\nChatGPT\nSign in using an existing ChatGPT account.\nBring Your Own Key (BYOK)\nConnect to Codex using your own OpenAI API key.\n\n\n\n\nFree access for a limited time\nThe Codex agent is available for free for a limited time when accessed via JetBrains AI, including the free trial or free tier version. The promotion starts on January 22 and will remain available until your allocated promotional credits have been used up. We reserve the right to cancel the free promotion at any time.\n\n\n\n\nThis free offer does not apply when using a ChatGPT account or an OpenAI API key. Other JetBrains AI features continue to consume AI Credits as usual.\nWhen the free period ends, OpenAI’s Codex agent will continue to be available to you, but any use of it after this point will consume AI Credits. You can track your usage of AI Credits via the JetBrains AI widget. \nWorking with Codex in JetBrains IDEs\nIn JetBrains IDEs, you can make Codex your active agent via the AI chat. With Codex, you can delegate real coding tasks from within your IDE and let the agent reason, act, and iterate alongside you. Codex supports various interaction modes, so you can decide how much autonomy to give it – from simple question-response permissions to the ability to access your network and run commands autonomously. You can also switch between supported OpenAI models and their reasoning budget directly in the AI chat, making it easy to balance reasoning depth, speed, and cost depending on the task at hand.\n\n\n\n\nLooking ahead\nBy partnering with leading AI providers like OpenAI and integrating their technologies directly into JetBrains IDEs, we’re ensuring these tools work where developers already are, in a way that respects their preferences.\nWe’d love to hear how you’re using Codex and what you’d like to see next. Are there other agents or capabilities you’d like us to bring into JetBrains IDEs? Let us know and help shape what comes next for JetBrains AI.",
        "dc:creator": "Anna Maltseva",
        "content": "OpenAI Codex is now natively integrated into the JetBrains AI chat, giving you another powerful option for tackling real development tasks right inside your IDE.&#160; You can use Codex with a JetBrains AI subscription, your ChatGPT account, or an OpenAI API key – all within the same AI сhat interface. See Codex in action in [&#8230;]",
        "contentSnippet": "OpenAI Codex is now natively integrated into the JetBrains AI chat, giving you another powerful option for tackling real development tasks right inside your IDE.  You can use Codex with a JetBrains AI subscription, your ChatGPT account, or an OpenAI API key – all within the same AI сhat interface. See Codex in action in […]",
        "guid": "https://blog.jetbrains.com/?post_type=ai&p=673181",
        "categories": [
          "news",
          "ai-in-ides",
          "codex"
        ],
        "isoDate": "2026-01-22T18:14:41.000Z"
      },
      {
        "creator": "Maria Kosukhina",
        "title": "IntelliJ IDEA 2025.3.2 Is Out!",
        "link": "https://blog.jetbrains.com/idea/2026/01/intellij-idea-2025-3-2/",
        "pubDate": "Thu, 22 Jan 2026 14:42:51 +0000",
        "content:encodedSnippet": "We’ve just released another update for v2025.3. \nYou can update to this version from inside the IDE, using the Toolbox App, or by using snaps if you are a Ubuntu user. You can also download it from our website.\nThis version brings the following valuable refinements:  \nThe Terminal tool window no longer flickers when you use CLI tools with synchronized output, such as Claude Code. [IJPL-204106], [IJPL-212577]\nSeveral issues related to credential storage and settings synchronization in remote development have been resolved: [IJPL-229203], [IJPL-227079], [IJPL-225754], [IJPL-170100], [IJPL-229877], [IJPL-229439], [IJPL-229417], [IJPL-227079]\nRun configuration handling in the Services tool window has received multiple improvements: [IJPL-220985], [IJPL-218977] [IJPL-223486], [IJPL-220985], [IJPL-227260], [IJPL-229476], [IJPL-229272], [IJPL-220900]\n\n\n\n\nTo see the full list of issues addressed in this version, please refer to the release notes. \nIf you encounter any bugs, please report them using our issue tracker. \nHappy developing!",
        "dc:creator": "Maria Kosukhina",
        "content": "We’ve just released another update for v2025.3.&#160; You can update to this version from inside the IDE, using the&#160;Toolbox App, or by using snaps if you are a Ubuntu user. You can also download it from our&#160;website. This version brings the following valuable refinements:&#160;&#160; To see the full list of issues addressed in this version, [&#8230;]",
        "contentSnippet": "We’ve just released another update for v2025.3.  You can update to this version from inside the IDE, using the Toolbox App, or by using snaps if you are a Ubuntu user. You can also download it from our website. This version brings the following valuable refinements:   To see the full list of issues addressed in this version, […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=675585",
        "categories": [
          "releases",
          "bug-fix-update",
          "intellij-idea"
        ],
        "isoDate": "2026-01-22T14:42:51.000Z"
      },
      {
        "creator": "Sasha Ivanova",
        "title": "ReSharper 2026.1 Early Access Program Has Begun",
        "link": "https://blog.jetbrains.com/dotnet/2026/01/22/resharper-2026-1-early-access-program/",
        "pubDate": "Thu, 22 Jan 2026 13:42:08 +0000",
        "content:encodedSnippet": "The ReSharper 2026.1 Early Access Program is now open, and the first EAP build brings a mix of C# productivity improvements, new inspections, performance work, and expanded C++ language support.\nAs always, EAP builds are an opportunity to try upcoming features early and help us refine them before the final release. Here’s what’s new in ReSharper 2026.1 EAP 1.\nDownload ReSharper 2026.1\n                                                    \nNote: .NET runtime for ReSharper 2026.1 in Out-of-Process (OOP) mode has been updated to .NET 10.\n\r\n\n        \nС# updates\nSmarter code generation and completion\nThe Generate | Partial Members action now supports generating partial member definitions, making it easier to work with partial types spread across multiple files.\nCode completion has also been improved for logging scenarios. After applying the\n[LoggerMessage(\"your message here\")] attribute, ReSharper can now generate the corresponding method definition directly from completion, streamlining structured logging workflows. [RSRP-495191]\nCleaner extension method declarations\nA new Consolidate extension members context action helps reduce fragmentation in extension code. When multiple compatible extension declarations and classic extension methods are present, ReSharper can now merge them into a single extension block. This keeps extension-heavy codebases easier to read and navigate, especially as they grow.\nTo see the new context action in action, try this example:\npublic static class ListExtensions\n{\n    public static List<T> GetSortedList<T>(this List<T> list)\n    {\n        list.Sort();\n        return list;\n    }\n    extension<T>(List<T> list)\n    {\n        public T? GetMaxElement() => list.Max();\n        public T? GetMinElement() => list.Min();\n    }\n    extension<T>(List<T> list)\n    {\n        public T GetFirstElement() => list.First();\n        public T GetLastElement() => list.Last();\n    }\n}\nPlace the caret inside one of the extension<T>(List<T> list) blocks and invoke Consolidate extension members to see ReSharper merge the compatible declarations into a single, cleaner extension definition.\nAnd here’s what you would get as a result:\npublic static class ListExtensions\n{\n    extension<T>(List<T> list)\n    {\n        public List<T> GetSortedCollection()\n        {\n            list.Sort();\n            return list;\n        }\n        public T? GetMaxElement() => list.Max();\n        public T? GetMinElement() => list.Min();\n        public T GetFirstElement() => list.First();\n        public T GetLastElement() => list.Last();\n    }\n}\nNew inspections \nTwo new inspections focus on correctness and runtime safety:\nImmutableArray initialization: ReSharper now detects cases where ImmutableArray<T> is used with collection initializers, leading to a runtime exception, and offers a quick-fix to use ImmutableArray.Create instead. [RSRP-502408]\nShort-lived HttpClient usage: A new inspection highlights patterns where HttpClient instances are repeatedly created and disposed. ReSharper warns about the risk of socket exhaustion and guides you toward safer alternatives, such as reusing instances or using IHttpClientFactory. \nPerformance\nWe’ve optimized several performance-critical code paths to significantly reduce costly clr!JIT_IsInstanceOfInterface runtime checks, resulting in faster code analysis and lower overhead.\nReSharper C++\nLanguage support\nThis preview build introduces:\nInitial support for C++23 floating-point types: bfloat16_t, float16_t, and float128_t.\nSupport for the C23 _Countof operator.\nGCC nested functions are now recognized correctly.\nEditor and navigation\nEAP 1 improves gutter marks with colorized tooltips for better readability [RSCPP-37086], and marks for base classes, making inheritance hierarchies easier to navigate [RSCPP-37085].\nProject model\nThe Library Directories project property is now respected when resolving #import directives [RSCPP-37070].\nReSharper now offers improved handling of WinUI 3 projects. [RSCPP-37089]\nInspections\nThe Symbol is never used inspection now applies to members of class definitions in .cpp files.\nDynamic Program Analysis (DPA) to be sunset\nDynamic Program Analysis (DPA) in ReSharper is evolving. Starting with ReSharper 2026.1, DPA will be sunset as a standalone feature. Its analytical capabilities are being consolidated into a reimagined, more comprehensive performance monitoring experience within ReSharper, modeled after the one we’ve implemented in Rider. \nFor the complete list of feature updates and resolved issues, please refer to our issue tracker. \nGive it a try\nReSharper 2026.1 EAP 1 is available now. You can install it alongside your stable version and start exploring the new features today.\nAs always, we’d love to hear your feedback. If you run into issues or have suggestions, please report them via our issue tracker so we can address them early in the release cycle.\nHappy coding—and thank you for helping shape ReSharper 2026.1!\nDownload ReSharper 2026.1",
        "dc:creator": "Sasha Ivanova",
        "content": "The ReSharper 2026.1 Early Access Program is now open, and the first EAP build brings a mix of C# productivity improvements, new inspections, performance work, and expanded C++ language support. As always, EAP builds are an opportunity to try upcoming features early and help us refine them before the final release. Here’s what’s new in [&#8230;]",
        "contentSnippet": "The ReSharper 2026.1 Early Access Program is now open, and the first EAP build brings a mix of C# productivity improvements, new inspections, performance work, and expanded C++ language support. As always, EAP builds are an opportunity to try upcoming features early and help us refine them before the final release. Here’s what’s new in […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=675128",
        "categories": [
          "net-tools",
          "eap",
          "releases",
          "resharpercplusplus",
          "resharper",
          "c",
          "c23",
          "dpa"
        ],
        "isoDate": "2026-01-22T13:42:08.000Z"
      },
      {
        "creator": "Sasha Ivanova",
        "title": "Rider 2026.1 Early Access Program Is Now Open!",
        "link": "https://blog.jetbrains.com/dotnet/2026/01/22/rider-2026-1-early-access-program-start/",
        "pubDate": "Thu, 22 Jan 2026 13:41:54 +0000",
        "content:encodedSnippet": "The Early Access Program (EAP) for Rider 2026.1 has just begun, and the first preview build for the upcoming major release is already out. \nThere are several ways for you to get your hands on the first preview build:\nDownload and install it from our website.\nGet it via the Toolbox App.\nInstall this snap package from the SnapCraft store if you’re using a compatible Linux distribution.\nDownload Rider 2026.1 EAP 1\n                                                    \nA reminder of what the EAP is all about\nThe Early Access Program is a long-standing tradition that gives our users early access to the new features we’re preparing. By participating, you get a first look at what’s coming and a chance to help shape the final release through your feedback.\nEAP builds are free to use, though they may be less stable than the final release versions. You can learn more about the EAP and why you might want to participate here.\nAnd now on to Rider 2026.1 EAP 1 release highlights.\nC# language support\nFor the latest updates to C# support, please check out the ReSharper 2026.1 EAP 1 blog post for ReSharper. \nAzure DevOps integration: Cloning repositories from Rider\nIf your team uses Azure DevOps, you can now clone repositories directly from Rider using the new bundled Azure DevOps plugin for JetBrains Rider.\nTo get started, go to File | Open | Get from Version Control from the main menu. From the Clone Repository dialog, select Azure DevOps from the list of version control providers. Rider authenticates using a personal access token (PAT), which you generate in Azure DevOps and then use to sign in from within the IDE. Once authenticated, Rider shows a list of repositories available to you, so you can select and clone them without leaving the IDE.\n\n\n\n\nAt this stage, the plugin focuses on the most common and reliable workflow: repository cloning via PAT-based authentication. This approach matches how authentication works for other organization-based Git providers in Rider and avoids frequent reauthentication or token refresh issues.\nThis is just the beginning of Azure DevOps support in Rider. We plan to expand the integration over time with additional baseline workflows. If you’re looking for more advanced Azure DevOps functionality today, the community-driven azd plugin is a great complement to the functionality already available in Rider.\nNuGet PowerShell commands support in the Package Manager Console\nRider now offers a Package Manager Console (PMC) in preview, bringing NuGet’s PowerShell-based workflow into the IDE.\nThe new console supports standard NuGet PowerShell commands, as well as commands provided by NuGet packages themselves. Entity Framework Core PowerShell commands such as Add-Migration, Update-Database, and Scaffold-DbContext are fully supported, enabling familiar EF Core workflows without leaving Rider. Broader command coverage will continue to expand based on user feedback.\nYou can access the PMC in two places:\nAs a dedicated tab in the NuGet tool window\n\n\n\n\n\nAs a predefined session in the Terminal tool window\n\n\n\n\n\nBoth options let you run the same commands, but differ slightly in how context is handled. In the NuGet tool window, you can select the package source and default project using UI controls. In the terminal-based console, this context is shown as part of the PowerShell prompt and can be changed using PowerShell commands.\nThis preview is about finding the right balance between flexibility and convenience for our users. Your feedback will help us decide which experience to refine and carry forward into the final release. Please share your feedback in the comments under this ticket or in the comment section below this post.\n.NET mixed-mode debugging on Windows\nRider 2026.1 introduces mixed-mode debugging, which lets you debug both managed (.NET and .NET Framework) and native (C/C++) code in a single debugging session.\nThis is particularly useful for applications that cross managed-native boundaries, such as .NET code calling into native libraries or game engines and tools built from a mix of managed and native components.\n\n\n\n\nYou can start a mixed-mode debugging session in two ways:\nOpen your run configuration and enable the Use mixed mode debug checkbox. When you start debugging, Rider will attach both the .NET and native debuggers automatically.\nOpen Run | Attach to Process, select a running process, and choose Attach with .NET and Native Debuggers. This attaches both debuggers to the same process, allowing you to step across managed and native code without having to restart the application.\nPlease note that .NET mixed-mode debugging is currently available only on Windows. Please leave your feedback on this ticket.\nThe ability to inspect .NET assembly output\nRider now offers a .NET Disassembler via a custom plugin that lets you inspect the native disassembly generated for your C# code directly in the IDE.\nYou can view the native disassembly generated from your C# code, along with output from the JIT, ReadyToRun, and NativeAOT compilers in the ASM Viewer tool window, which is available through the new plugin. This makes the feature particularly useful when working on performance-sensitive code, low-level optimizations, SIMD-heavy paths, or when validating how code changes affect the final machine instructions.\n\n\n\n\nThe .NET Disassembler is designed for use during development. You can open it directly from your C# code and inspect the generated assembly side by side with the source. Rider also supports:\nConfigurable compiler options such as tiered compilation and PGO.\nSnapshots and diff views to compare assembly output before and after code changes.\nSyntax highlighting for x86/x64 and ARM64 assembly.\nThe introduction of this plugin is our answer to long-standing requests from developers who need visibility beyond IL and want to understand what actually runs on the CPU, without repeatedly rebuilding projects or switching to external tools.\nEnhanced integration with the Godot Editor\nThis release introduces a Godot Editor addon that enhances the way Rider works with Godot Engine projects.\nWhen you enable the JetBrains Rider External Editor addon in the Godot Editor, it automatically detects your installed Rider versions and configures Godot to work with Rider as the external IDE. It also applies a set of recommended editor settings to optimize your workflow – helping with project opening, file navigation, and debugging.\nCombined with Rider’s Godot Support plugin (now bundled with the IDE), this enables:\nAutomatic Godot project discovery in Rider.\nGeneration of run/debug configurations for Godot scenes.\nCode insight and navigation for both GDScript and C#.\nIntegrated debugging with scene variables and node context.\n\n\n\n\n\nInspect the sources of the addon to see how GDExtension can be developed in JetBrains Rider at any OS.\nSearch for “JetBrains Rider Integration” on the AssetLib inside GodotEditor to get started.\nImproved Natvis expression evaluation\nC++ debugging in Rider now uses a new standalone parser and evaluator for Natvis expressions.  Thanks to the new evaluator, variable inspection is up to 87 times faster on warm runs and 16 times faster on cold ones. The debugger memory usage has dropped to just over a third of what it was. And that’s not even all of the benefits! Click here to learn more. \nC++ naming rules improvements\nRider now offers a more flexible C++ naming rules configuration. The updated settings page lets you edit naming rules [RIDER-121211], apply predefined naming styles [RIDER-132026], and define abbreviations [RIDER-52334], making it easier to align code style with your team’s conventions.\nFor the full list of changes included in this build, please see our issue tracker.\nWe encourage you to download the EAP build, give these new features a try, and share your feedback. The Early Access Program is a collaborative effort, and your input plays a vital role in making Rider the best it can be.\nDownload Rider 2026.1 EAP 1\n                                                    \nThank you for being part of our EAP community, and we look forward to hearing what you think!",
        "dc:creator": "Sasha Ivanova",
        "content": "The Early Access Program (EAP) for Rider 2026.1 has just begun, and the first preview build for the upcoming major release is already out.&#160; There are several ways for you to get your hands on the first preview build: A reminder of what the EAP is all about The Early Access Program is a long-standing [&#8230;]",
        "contentSnippet": "The Early Access Program (EAP) for Rider 2026.1 has just begun, and the first preview build for the upcoming major release is already out.  There are several ways for you to get your hands on the first preview build: A reminder of what the EAP is all about The Early Access Program is a long-standing […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=675034",
        "categories": [
          "net-tools",
          "eap",
          "releases",
          "rider",
          "azure",
          "azure-devops",
          "godot",
          "mixed-mode-debugging",
          "natvis",
          "nuget",
          "nuget-pmc",
          "package-management"
        ],
        "isoDate": "2026-01-22T13:41:54.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": []
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": [
      {
        "creator": "sunyzero",
        "title": "LargeSystemCache 설정에 대한 오해 (윈11, 윈10 최적화)",
        "link": "https://sunyzero.tistory.com/324",
        "pubDate": "Fri, 23 Jan 2026 19:52:55 +0900",
        "author": "sunyzero",
        "comments": "https://sunyzero.tistory.com/324#entry324comment",
        "content": "<p data-ke-size=\"size16\">윈도11 최적화 팁 중에 <span style=\"background-color: #f6e199;\">LargeSystemCache</span>와 <span style=\"background-color: #9feec3;\">DisablePagingExecutive</span>가 있는데, 이건 옛날에나 쓰던 방식이고, SSD를 사용하는 최근 2010년 이후의 시스템에는 오히려 문제가 되기 때문에 쓰면 안되는 설정이다. 하지만 여러 곳에서 잘못된 정보가 유통되기에 이 글을 쓰게 되었다. 실제로 주변인이 이걸 설정해서 PC와 랩탑이 이상 작동하는 문제가 있었고, 고쳐준 다음에 쓴 글이다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">1. 역사적 배경 (알아둬도 큰 쓸모는 없지만...)</h2>\n<p data-ke-size=\"size16\"><span style=\"color: #333333; text-align: start;\">LargeSystemCache와<span>&nbsp;</span></span>DisablePagingExecutive 설정은 과거 HDD라고 불리는 하드 디스크를 장착한 십수년전 시스템에서 사용되던 설정으로서, 커널이라고 불리는 시스템 코어 부분이 사용하는 메모리 영역을 큰 값으로 확보해서 시스템 영역을 메모리에 상주시키는 효과가 있었다. 그렇다면 왜 시스템 영역을 메모리에 상주되는 기능이 있는지 살펴봐야 한다. 이를 위해 우린 스왑 영역에 대해서 조금 알아둬야만한다.</p>\n<p data-ke-size=\"size16\">우선 램은 프로그램이 실행되기 위에서 디스크에 있는 정보를 읽어서 올려두는 주 메모리 공간(main memory)이다. 모든 프로그램은 램을 사용한다는 사실부터 기억해두자.</p>\n<p data-ke-size=\"size16\">2000년대 중반만 하더라도 인터넷 열풍으로 PC 시장이 빠르게 성장했는데, 그에 비해 메모리(RAM) 용량은 발전이 더뎌서 1GB정도 밖에 안되는 경우가 많았다. 2026년 기준으로 보면 PC의 램 최소사양이 8~16GB이고, 게임을 하는 사람은 보통 32GB를 쓰는 것에 비하면 1GB는 엄청 작은 값이었다. 따라서 Windows에서는 여러 프로그램을 원활하게 실행하기 위해 최대한 램을 아껴써야만 했다. 이를 위해 스왑 영역을 사용하는 기법이 도입되었는데, 이는 OS(운영체제)론을 배운 학생이라면 다 알것이다. 혹시나 모르는 사람을 위해 설명하자면, 운영체제가 메모리 부족을 해결하기 위해 디스크의 특정 영역에 메모리 공간의 일부를 이동(copy and remove)시켰다가 나중에 필요할때 다시 메모리로 가져오는 기법이다. 이렇게 하면 RAM이 1GB여도 2GB인 것처럼 뻥튀기를 할 수 있었다.&nbsp;운영체제론에서는 이때 사용되는 디스크 공간을 스왑공간(swap space)이라고 부르는데, 윈도에서는 페이지 파일(pagefile) 이라고 다르게 부르며 실제 위치는 C:\\pagefile.sys 에 만들어지는 경우가 많다.[1]</p>\n<p data-ke-size=\"size16\">참고로 메모리의 영역을 pagefile로 이동시키는 과정을 <span style=\"background-color: #f6e199;\">스왑 아웃(swap out)</span>이라고 부르고, 반대로 pagefile에서 RAM으로 이동하는 과정을 <span style=\"background-color: #f6e199;\">스왑 인(swap in)</span>이라고 부른다. 아래 그림을 보면 이해가 쉬울 것이다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Windows11_ram_hdd_swap.png\" data-origin-width=\"1051\" data-origin-height=\"807\"><span data-url=\"https://blog.kakaocdn.net/dn/26DOu/dJMcaajMma1/Af7ipBkFXPYypOv9gEXfAk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/26DOu/dJMcaajMma1/Af7ipBkFXPYypOv9gEXfAk/img.png\" data-alt=\"Windows, Swap Out, Swap In (Gemini 생성)\"><img src=\"https://blog.kakaocdn.net/dn/26DOu/dJMcaajMma1/Af7ipBkFXPYypOv9gEXfAk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F26DOu%2FdJMcaajMma1%2FAf7ipBkFXPYypOv9gEXfAk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1051\" height=\"807\" data-filename=\"Windows11_ram_hdd_swap.png\" data-origin-width=\"1051\" data-origin-height=\"807\"/></span><figcaption>Windows, Swap Out, Swap In (Gemini 생성)</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">그런데 스왑 아웃이나 스왑 인에는 심각한 문제가 있다. 그건 바로 딜레이가 발생한다는 점이다. 어떤 프로그램을 수행하려고 하는데, 필요한 램 공간이 500MB정도 부족하다고 가정하자. 그럼 운영체제는 최소 500MB 이상의 메모리를 확보하기 위해 메모리 일부분을 디스크로 복사하는 과정, 즉 swap out이 발생한다. 문제는 500MB이상의 데이터를 디스크로 복사하는 과정에서 심각한 딜레이가 발생한다는 점이다(당시 하드 디스크의 속도는 대체로 초당 50~100MB수준 이었다). 따라서 500MB이상의 메모리를 swap out하려면 최소 6~10초 정도는 딜레이가 생길 것이다. 그런데 프로그램 실행시 이 정도 딜레이가 발생하면 악영향을 줄 것이다. 그렇다면 딜레이를 줄이기 위해 어떤 방법이 있을까? 그건 바로 미리미리 복사하던지, 아니면 메모리를 비워서 빈 메모리 공간을 만들어두는 것이다.</p>\n<p data-ke-size=\"size16\">그런데 이렇게 미리 공간을 확보하는 것이 효과가 좋은 원인을 생각해보면 HDD(하드 디스크)의 복사 속도가 매우 느렸기 때문에 발생하는 딜레이였다. 그리고 공간을 확보하기 위해 디스크를 자주 쓰거나 읽게되면 디스크로부터 데이터를 주로 많이 읽어들이는 데이터베이스나 서버들은 악영향이 생긴다. 그래서 메모리를 미리 확보하는 기법은 반대로 커널의 응답속도가 떨어뜨리는 문제가 생긴다. 그래서 주변 장치를 많이 사용하거나 혹은 커널이 대용량 데이터를 처리하는 경우에 반대로 커널(시스템) 영역이 디스크로 swap out되지 않도록 하는 기능이 필요해진 것이었다. 이를 돕는 기능이 바로 LargeSystemCache, DisablePagingExecutive 라 부르는 것이었다. 두가지 기능에 대해서는 아래에 표로 정리해두었다.</p>\n<table style=\"border-collapse: collapse; width: 100%;\" border=\"1\" data-ke-align=\"alignLeft\">\n<tbody>\n<tr>\n<td style=\"width: 23.0233%;\"><span style=\"background-color: #f6e199;\"> LargeSystemCache </span></td>\n<td style=\"width: 76.9767%;\">대용량 캐시를 사용하도록 하여, 커널이 파일을 읽거나 메모리 영역을 사용 할 때 캐싱을 최대한 하도록 하는 기법이다. 즉 빈 공간을 남기지 말고 최대한 파일을 위한 캐시로 쓰게 한다. 윈도 서버에서 데이터베이스나 네트워크 서비스를 사용할 때 반응 속도를 올리는데 도움이 되던 설정이다. 게임이나 문서 작업을 하는 일반인들에게는 필요가 없는 설정이다.[2]</td>\n</tr>\n<tr>\n<td style=\"width: 23.0233%;\"><span style=\"color: #333333; text-align: start; background-color: #f6e199;\"> DisablePagingExecutive&nbsp; </span></td>\n<td style=\"width: 76.9767%;\">커널이 사용하는 영역의 메모리나 디바이스 메모리를 swap out을 하지 않고 메인 메모리에 유지하도록 하는 것이다. 위와 마찬가지로 윈도 시스템의 반응 속도를 올려주는 장점이 있었다. 혹은 디바이스 장치를 개발하는 경우에 주로 사용한다. [3]</td>\n</tr>\n</tbody>\n</table>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이들은 위에 정리한대로 메인 메모리(RAM)를 소모해서 윈도 시스템 자체의 서비스와 장치들의 반응 속도를 올리는게 핵심 목적이므로 주소 Windows Server에서 사용되는 기능이었다. 물론 개인용 PC에서 사용하던 Windows 7 (2009년)이나 Windows 8 (2012년)에는 4GB이상의 메모리를 가지고 있고, HDD 디스크를 사용하던 경우에는 이 설정이 효과가 있는 경우가 많았었다. 문제는 2010년대 중반에는 SSD가 대거 보급되었고, 8GB이상의 대용량 메모리를 가진 시스템이 늘어나면서 해당 설정이 무의미해졌다는 점이다. <span style=\"color: #ee2323;\">지금 대부분의 시스템들은 보통 16GB이상의 메모리를 가지고 있고, 고성능의 SSD를 가지고 있기에 전혀 쓸 이유가 없는 기능이다</span>.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Tiger_smoking_season.png\" data-origin-width=\"1415\" data-origin-height=\"1287\"><span data-url=\"https://blog.kakaocdn.net/dn/bdRLi2/dJMcacomG2g/1gI7JgTcUZzFRqmd8oEEfK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bdRLi2/dJMcacomG2g/1gI7JgTcUZzFRqmd8oEEfK/img.png\" data-alt=\"호랑이 담배 피우던 시절에 쓰는 PC설정 (Gemini 생성)\"><img src=\"https://blog.kakaocdn.net/dn/bdRLi2/dJMcacomG2g/1gI7JgTcUZzFRqmd8oEEfK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbdRLi2%2FdJMcacomG2g%2F1gI7JgTcUZzFRqmd8oEEfK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1415\" height=\"1287\" data-filename=\"Tiger_smoking_season.png\" data-origin-width=\"1415\" data-origin-height=\"1287\"/></span><figcaption>호랑이 담배 피우던 시절에 쓰는 PC설정 (Gemini 생성)</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">그럼에도 불구하고 이 설정을 하면 빨라진다는 호랑이 담배피던 시절 괴담이 늘어나고 있는데, Win10이나 Win11에서&nbsp; LargeSystemCache나 DisablePagingExecutive 를 설정해봐야 효과도 없고, 도리어 시스템을 불안정하게 만드는 경우도 많다. 특히 랩탑(노트북)은 이 설정을 켜면 절전모드에서 깨어날때 문제가 생기거나 몇몇 블루투스나 와이파이 장치들이 문제를 일으키기도 한다. PC 데스크탑에서는 랩탑보다는 안정적이지만 간혹 USB 장치나 PCIe 장치가 문제를 일으킬 수도 있다. 따라서 현재는 쓰면 안되는 기능이다. 그러면 이 기능을 어떻게 켜고 끄는지 살펴보자.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">2. LargeSystemCache, DisablePagingExecutive<span style=\"color: #333333; text-align: start;\"><span>&nbsp;</span></span> 끄기</h2>\n<p data-ke-size=\"size16\">혹시라도 이 설정을 켠 사람들은 아래 방법으로 끄면 된다. 먼저 regedit를 실행해서 레지스트리 편집을 시행한다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Windows11_LargeSystemCache_DisablePagingExecutive.png\" data-origin-width=\"1366\" data-origin-height=\"627\"><span data-url=\"https://blog.kakaocdn.net/dn/bZWgt5/dJMcagjZYXx/w2pq8MvntRmIKTGpVVwBM0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bZWgt5/dJMcagjZYXx/w2pq8MvntRmIKTGpVVwBM0/img.png\" data-alt=\"LargeSystemCache와 DisablePagingExecutive 설정\"><img src=\"https://blog.kakaocdn.net/dn/bZWgt5/dJMcagjZYXx/w2pq8MvntRmIKTGpVVwBM0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbZWgt5%2FdJMcagjZYXx%2Fw2pq8MvntRmIKTGpVVwBM0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1366\" height=\"627\" data-filename=\"Windows11_LargeSystemCache_DisablePagingExecutive.png\" data-origin-width=\"1366\" data-origin-height=\"627\"/></span><figcaption>LargeSystemCache와 DisablePagingExecutive 설정</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">여기서 HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Session Manager\\Memory Management 설정으로 이동하면 <span style=\"color: #333333; text-align: start;\"><span style=\"background-color: #f6e199;\">LargeSystemCache</span>나<span>&nbsp;</span></span><span style=\"color: #333333; text-align: start;\"><span style=\"background-color: #9feec3;\">DisablePagingExecutive</span><span> 설정이 보일 것이다. 이 값들은 on하는 것이 <span style=\"background-color: #f6e199;\">1</span>이고, off하는 것이 <span style=\"background-color: #ffc1c8;\">0</span>이다. 당연히 default값은 off인 0이다. 이 2가지 설정 값이 1이라면 0으로 수정하면 된다.</span></span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">혹시 이 값을 설정한 뒤에 페이징 파일(pagefile)을 0바이트로 설정했다면 원상복구하는 것을 추천한다. 원복을 위해서는 다음과 같이 sysdm.cpl 프로그램에 설정하는 것이 편하다. 먼저 Win + R 키를 누르면 나타나는 좌측 하단 입력창에 <span style=\"background-color: #9feec3;\">sysdm.cpl</span> 을 타이핑해서 실행한다. 그리고 \"<span style=\"background-color: #f6e199;\">고급</span>\" 탭에 \"<span style=\"background-color: #c0d1e7;\">성능</span>\" 설정을 눌러서 \"<span style=\"background-color: #c1bef9;\">성능 옵션</span>\" 창을 띄운다. 여기서 다시 \"<span style=\"background-color: #f6e199;\">고급</span>\" 탭으로 이동해서 \"<span style=\"background-color: #f6e199;\">가상 메모리</span>\"의 변경 버튼을 누르면 아래 그림처럼 가상 메모리 설정을 볼 수 있다. 가상메모리 설정을 \"<b><span style=\"color: #ee2323;\">시스템이 관리하는 크기</span></b>\"로 설정하면 원상복구가 된다. 간혹 가상메모리 크기를 고정값으로 \"<b><span style=\"color: #ee2323;\">사용자 지정 크기</span></b>\" 로 16GB로 해두는게 좋다는 글도 있는데, 다 십수년전 옛날 설정 이야기다. 2026년 기준으로 보면 쓸데없는 설정이다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Windows11_LargeSystemCache_DisablePagingExecutive_PagingFile.png\" data-origin-width=\"677\" data-origin-height=\"977\"><span data-url=\"https://blog.kakaocdn.net/dn/bMicnY/dJMcacaQV6d/TWkDLxE48q4quBKY6opES0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bMicnY/dJMcacaQV6d/TWkDLxE48q4quBKY6opES0/img.png\" data-alt=\"sysdm.cpl의 성능옵션, 가상 메모리 설정\"><img src=\"https://blog.kakaocdn.net/dn/bMicnY/dJMcacaQV6d/TWkDLxE48q4quBKY6opES0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbMicnY%2FdJMcacaQV6d%2FTWkDLxE48q4quBKY6opES0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"677\" height=\"977\" data-filename=\"Windows11_LargeSystemCache_DisablePagingExecutive_PagingFile.png\" data-origin-width=\"677\" data-origin-height=\"977\"/></span><figcaption>sysdm.cpl의 성능옵션, 가상 메모리 설정</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">윈도10이나 윈도11은 옛날처럼 최적화 하는 기법이 대부분 작동하지 않는다. 오히려 요새 최적화 기법은 발열이 심각한 몇몇 랩탑의 CPU나 올인원 PC들의 CPU 성능을 80% 정도로 낮추는 기능이 유용하고, 알림을 꺼서 최적화 하는 정도만 제대로 쓸모가 있다. 그 외에는 그냥 디폴트 값을 쓰는게 좋다. 괜히 만져서 더 느려지거나 문제가 생길 수 있으니 주의하도록 하자.</p>\n<p data-ke-size=\"size16\">그러나 굳이 꼭 쓰고 싶다면 위에 레지스트리를 고쳐서 LargeSystemCache 정도만 쓰는 것을 추천한다. 간혹 엄청난 문서 파일들을 작업하거나 동영상 같은 것을 편집하는 경우에는 아주 조금 유용할 수는 있을 듯 하다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">레퍼런스</h2>\n<p data-ke-size=\"size16\">[1] 페이징 파일 소개, Microsoft Learn, <a href=\"https://learn.microsoft.com/ko-kr/troubleshoot/windows-client/performance/introduction-to-the-page-file?source=recommendations\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://learn.microsoft.com/ko-kr/troubleshoot/windows-client/performance/introduction-to-the-page-file?source=recommendations</a></p>\n<p data-ke-size=\"size16\">[2] LargeSystemCache에 대한 설명, <a href=\"https://learn.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2003/cc784562(v=ws.10)\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://learn.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2003/cc784562(v=ws.10)</a></p>\n<p data-ke-size=\"size16\">[3] DisablePagingExecutive 에 대한 설명, <a href=\"https://learn.microsoft.com/en-us/windows-hardware/test/wpt/wpr-command-line-options\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://learn.microsoft.com/en-us/windows-hardware/test/wpt/wpr-command-line-options</a></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">히스토리</h2>\n<p data-ke-size=\"size16\">2026.01.23 문서를 처음으로 작성</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "윈도11 최적화 팁 중에 LargeSystemCache와 DisablePagingExecutive가 있는데, 이건 옛날에나 쓰던 방식이고, SSD를 사용하는 최근 2010년 이후의 시스템에는 오히려 문제가 되기 때문에 쓰면 안되는 설정이다. 하지만 여러 곳에서 잘못된 정보가 유통되기에 이 글을 쓰게 되었다. 실제로 주변인이 이걸 설정해서 PC와 랩탑이 이상 작동하는 문제가 있었고, 고쳐준 다음에 쓴 글이다.\n \n1. 역사적 배경 (알아둬도 큰 쓸모는 없지만...)\nLargeSystemCache와 DisablePagingExecutive 설정은 과거 HDD라고 불리는 하드 디스크를 장착한 십수년전 시스템에서 사용되던 설정으로서, 커널이라고 불리는 시스템 코어 부분이 사용하는 메모리 영역을 큰 값으로 확보해서 시스템 영역을 메모리에 상주시키는 효과가 있었다. 그렇다면 왜 시스템 영역을 메모리에 상주되는 기능이 있는지 살펴봐야 한다. 이를 위해 우린 스왑 영역에 대해서 조금 알아둬야만한다.\n우선 램은 프로그램이 실행되기 위에서 디스크에 있는 정보를 읽어서 올려두는 주 메모리 공간(main memory)이다. 모든 프로그램은 램을 사용한다는 사실부터 기억해두자.\n2000년대 중반만 하더라도 인터넷 열풍으로 PC 시장이 빠르게 성장했는데, 그에 비해 메모리(RAM) 용량은 발전이 더뎌서 1GB정도 밖에 안되는 경우가 많았다. 2026년 기준으로 보면 PC의 램 최소사양이 8~16GB이고, 게임을 하는 사람은 보통 32GB를 쓰는 것에 비하면 1GB는 엄청 작은 값이었다. 따라서 Windows에서는 여러 프로그램을 원활하게 실행하기 위해 최대한 램을 아껴써야만 했다. 이를 위해 스왑 영역을 사용하는 기법이 도입되었는데, 이는 OS(운영체제)론을 배운 학생이라면 다 알것이다. 혹시나 모르는 사람을 위해 설명하자면, 운영체제가 메모리 부족을 해결하기 위해 디스크의 특정 영역에 메모리 공간의 일부를 이동(copy and remove)시켰다가 나중에 필요할때 다시 메모리로 가져오는 기법이다. 이렇게 하면 RAM이 1GB여도 2GB인 것처럼 뻥튀기를 할 수 있었다. 운영체제론에서는 이때 사용되는 디스크 공간을 스왑공간(swap space)이라고 부르는데, 윈도에서는 페이지 파일(pagefile) 이라고 다르게 부르며 실제 위치는 C:\\pagefile.sys 에 만들어지는 경우가 많다.[1]\n참고로 메모리의 영역을 pagefile로 이동시키는 과정을 스왑 아웃(swap out)이라고 부르고, 반대로 pagefile에서 RAM으로 이동하는 과정을 스왑 인(swap in)이라고 부른다. 아래 그림을 보면 이해가 쉬울 것이다.\nWindows, Swap Out, Swap In (Gemini 생성)\n\n\n그런데 스왑 아웃이나 스왑 인에는 심각한 문제가 있다. 그건 바로 딜레이가 발생한다는 점이다. 어떤 프로그램을 수행하려고 하는데, 필요한 램 공간이 500MB정도 부족하다고 가정하자. 그럼 운영체제는 최소 500MB 이상의 메모리를 확보하기 위해 메모리 일부분을 디스크로 복사하는 과정, 즉 swap out이 발생한다. 문제는 500MB이상의 데이터를 디스크로 복사하는 과정에서 심각한 딜레이가 발생한다는 점이다(당시 하드 디스크의 속도는 대체로 초당 50~100MB수준 이었다). 따라서 500MB이상의 메모리를 swap out하려면 최소 6~10초 정도는 딜레이가 생길 것이다. 그런데 프로그램 실행시 이 정도 딜레이가 발생하면 악영향을 줄 것이다. 그렇다면 딜레이를 줄이기 위해 어떤 방법이 있을까? 그건 바로 미리미리 복사하던지, 아니면 메모리를 비워서 빈 메모리 공간을 만들어두는 것이다.\n그런데 이렇게 미리 공간을 확보하는 것이 효과가 좋은 원인을 생각해보면 HDD(하드 디스크)의 복사 속도가 매우 느렸기 때문에 발생하는 딜레이였다. 그리고 공간을 확보하기 위해 디스크를 자주 쓰거나 읽게되면 디스크로부터 데이터를 주로 많이 읽어들이는 데이터베이스나 서버들은 악영향이 생긴다. 그래서 메모리를 미리 확보하는 기법은 반대로 커널의 응답속도가 떨어뜨리는 문제가 생긴다. 그래서 주변 장치를 많이 사용하거나 혹은 커널이 대용량 데이터를 처리하는 경우에 반대로 커널(시스템) 영역이 디스크로 swap out되지 않도록 하는 기능이 필요해진 것이었다. 이를 돕는 기능이 바로 LargeSystemCache, DisablePagingExecutive 라 부르는 것이었다. 두가지 기능에 대해서는 아래에 표로 정리해두었다.\n LargeSystemCache \n대용량 캐시를 사용하도록 하여, 커널이 파일을 읽거나 메모리 영역을 사용 할 때 캐싱을 최대한 하도록 하는 기법이다. 즉 빈 공간을 남기지 말고 최대한 파일을 위한 캐시로 쓰게 한다. 윈도 서버에서 데이터베이스나 네트워크 서비스를 사용할 때 반응 속도를 올리는데 도움이 되던 설정이다. 게임이나 문서 작업을 하는 일반인들에게는 필요가 없는 설정이다.[2]\n\n\n DisablePagingExecutive  \n커널이 사용하는 영역의 메모리나 디바이스 메모리를 swap out을 하지 않고 메인 메모리에 유지하도록 하는 것이다. 위와 마찬가지로 윈도 시스템의 반응 속도를 올려주는 장점이 있었다. 혹은 디바이스 장치를 개발하는 경우에 주로 사용한다. [3]\n\n\n\n \n이들은 위에 정리한대로 메인 메모리(RAM)를 소모해서 윈도 시스템 자체의 서비스와 장치들의 반응 속도를 올리는게 핵심 목적이므로 주소 Windows Server에서 사용되는 기능이었다. 물론 개인용 PC에서 사용하던 Windows 7 (2009년)이나 Windows 8 (2012년)에는 4GB이상의 메모리를 가지고 있고, HDD 디스크를 사용하던 경우에는 이 설정이 효과가 있는 경우가 많았었다. 문제는 2010년대 중반에는 SSD가 대거 보급되었고, 8GB이상의 대용량 메모리를 가진 시스템이 늘어나면서 해당 설정이 무의미해졌다는 점이다. 지금 대부분의 시스템들은 보통 16GB이상의 메모리를 가지고 있고, 고성능의 SSD를 가지고 있기에 전혀 쓸 이유가 없는 기능이다.\n호랑이 담배 피우던 시절에 쓰는 PC설정 (Gemini 생성)\n\n\n그럼에도 불구하고 이 설정을 하면 빨라진다는 호랑이 담배피던 시절 괴담이 늘어나고 있는데, Win10이나 Win11에서  LargeSystemCache나 DisablePagingExecutive 를 설정해봐야 효과도 없고, 도리어 시스템을 불안정하게 만드는 경우도 많다. 특히 랩탑(노트북)은 이 설정을 켜면 절전모드에서 깨어날때 문제가 생기거나 몇몇 블루투스나 와이파이 장치들이 문제를 일으키기도 한다. PC 데스크탑에서는 랩탑보다는 안정적이지만 간혹 USB 장치나 PCIe 장치가 문제를 일으킬 수도 있다. 따라서 현재는 쓰면 안되는 기능이다. 그러면 이 기능을 어떻게 켜고 끄는지 살펴보자.\n \n2. LargeSystemCache, DisablePagingExecutive  끄기\n혹시라도 이 설정을 켠 사람들은 아래 방법으로 끄면 된다. 먼저 regedit를 실행해서 레지스트리 편집을 시행한다.\nLargeSystemCache와 DisablePagingExecutive 설정\n\n\n여기서 HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Session Manager\\Memory Management 설정으로 이동하면 LargeSystemCache나 DisablePagingExecutive 설정이 보일 것이다. 이 값들은 on하는 것이 1이고, off하는 것이 0이다. 당연히 default값은 off인 0이다. 이 2가지 설정 값이 1이라면 0으로 수정하면 된다.\n \n혹시 이 값을 설정한 뒤에 페이징 파일(pagefile)을 0바이트로 설정했다면 원상복구하는 것을 추천한다. 원복을 위해서는 다음과 같이 sysdm.cpl 프로그램에 설정하는 것이 편하다. 먼저 Win + R 키를 누르면 나타나는 좌측 하단 입력창에 sysdm.cpl 을 타이핑해서 실행한다. 그리고 \"고급\" 탭에 \"성능\" 설정을 눌러서 \"성능 옵션\" 창을 띄운다. 여기서 다시 \"고급\" 탭으로 이동해서 \"가상 메모리\"의 변경 버튼을 누르면 아래 그림처럼 가상 메모리 설정을 볼 수 있다. 가상메모리 설정을 \"시스템이 관리하는 크기\"로 설정하면 원상복구가 된다. 간혹 가상메모리 크기를 고정값으로 \"사용자 지정 크기\" 로 16GB로 해두는게 좋다는 글도 있는데, 다 십수년전 옛날 설정 이야기다. 2026년 기준으로 보면 쓸데없는 설정이다.\nsysdm.cpl의 성능옵션, 가상 메모리 설정\n\n\n윈도10이나 윈도11은 옛날처럼 최적화 하는 기법이 대부분 작동하지 않는다. 오히려 요새 최적화 기법은 발열이 심각한 몇몇 랩탑의 CPU나 올인원 PC들의 CPU 성능을 80% 정도로 낮추는 기능이 유용하고, 알림을 꺼서 최적화 하는 정도만 제대로 쓸모가 있다. 그 외에는 그냥 디폴트 값을 쓰는게 좋다. 괜히 만져서 더 느려지거나 문제가 생길 수 있으니 주의하도록 하자.\n그러나 굳이 꼭 쓰고 싶다면 위에 레지스트리를 고쳐서 LargeSystemCache 정도만 쓰는 것을 추천한다. 간혹 엄청난 문서 파일들을 작업하거나 동영상 같은 것을 편집하는 경우에는 아주 조금 유용할 수는 있을 듯 하다.\n \n레퍼런스\n[1] 페이징 파일 소개, Microsoft Learn, https://learn.microsoft.com/ko-kr/troubleshoot/windows-client/performance/introduction-to-the-page-file?source=recommendations\n[2] LargeSystemCache에 대한 설명, https://learn.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2003/cc784562(v=ws.10)\n[3] DisablePagingExecutive 에 대한 설명, https://learn.microsoft.com/en-us/windows-hardware/test/wpt/wpr-command-line-options\n \n \n히스토리\n2026.01.23 문서를 처음으로 작성",
        "guid": "https://sunyzero.tistory.com/324",
        "categories": [
          "컴퓨터 관련/윈도 패밀리",
          "DisablePagingExecutive",
          "LargeSystemCache",
          "regedit",
          "sysdm.cpl",
          "Windows",
          "windows11",
          "운영체제",
          "윈도 페이징 파일 설정",
          "최적화"
        ],
        "isoDate": "2026-01-23T10:52:55.000Z"
      }
    ]
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "데이터 노가다 실수담 - 15th",
        "link": "https://kangmyounghun.blogspot.com/2026/01/15th.html",
        "pubDate": "2026-01-22T12:55:00.003Z",
        "author": "강명훈",
        "content": "<div>IIS 웹로그는 모든 필드를 '공백'으로 구분하기 때문에 원활한 필드 분류를 위해 필드값에 포함된 공백을 + 기호로 대체한다.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgxrl9Sc79-VPrYDDq6Gj6riU0rDPdtnoxbO2QHL_3aVV8J76roVOyoaKm1iF8m6WkDA0WpAx6GO0BY30VsXy3RWVg-4O5UWiHwCTgfaYB7MrpgrOYl4AD_8wZ6lgzHHiyUVRpFdlvRP1sdFqqG_0vbUXHNiXArYiBa0dX8t22ec0G0nVOrWIEv1Q7nYEyw/s1024/iis_agent.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"538\" data-original-width=\"1024\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgxrl9Sc79-VPrYDDq6Gj6riU0rDPdtnoxbO2QHL_3aVV8J76roVOyoaKm1iF8m6WkDA0WpAx6GO0BY30VsXy3RWVg-4O5UWiHwCTgfaYB7MrpgrOYl4AD_8wZ6lgzHHiyUVRpFdlvRP1sdFqqG_0vbUXHNiXArYiBa0dX8t22ec0G0nVOrWIEv1Q7nYEyw/s16000/iis_agent.png\" /></a></div><br /><span><a name='more'></a></span><div>가독성을 높이기 위해 +를 공백으로 치환하는 계산 필드 정책 추가.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgs7wZ5vvKFzFzaLqFp2ChjwiVhZwua6Hlk51jx7NIW3TXPD0gyJ17mGSJnNtLt-H0eWjXSC7PddSOShUNuN4gFFpSukBwQy9kek_7ZrRejGirxqucbSwdHQx3Pm1anSTL5_qztNaYcQms-Ftp50K2D97vhbEbH3qBaagEbjP_DNzPSCMlaPgpRagE6a7B5/s1280/calulated_field.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"648\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgs7wZ5vvKFzFzaLqFp2ChjwiVhZwua6Hlk51jx7NIW3TXPD0gyJ17mGSJnNtLt-H0eWjXSC7PddSOShUNuN4gFFpSukBwQy9kek_7ZrRejGirxqucbSwdHQx3Pm1anSTL5_qztNaYcQms-Ftp50K2D97vhbEbH3qBaagEbjP_DNzPSCMlaPgpRagE6a7B5/s16000/calulated_field.png\" /></a></div><br /><div>+가 공백으로 바뀐 agent 필드 상태를 축소해서 agent2 필드에 저장하는 정책도 추가.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhDa6II9cJGVjRB8lchTY_2yuqtQhH25x6fZu8jrUWpI0-jkWlZoAjvREISwnCQ4gK6ClrMgBaNH5Lys4HzJn4hfwHaYgRygsKyx_Gf4034SInon-6BvYN3MboqIKM-GD8e-YEdLPsnpxQncbtFrWf7NslP7RTWVA51nkW6pckf_EluaHpqmkqedanR3DTP/s1280/calulated_field2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"648\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhDa6II9cJGVjRB8lchTY_2yuqtQhH25x6fZu8jrUWpI0-jkWlZoAjvREISwnCQ4gK6ClrMgBaNH5Lys4HzJn4hfwHaYgRygsKyx_Gf4034SInon-6BvYN3MboqIKM-GD8e-YEdLPsnpxQncbtFrWf7NslP7RTWVA51nkW6pckf_EluaHpqmkqedanR3DTP/s16000/calulated_field2.png\" /></a></div><br /><div>그런데 + 기호가 사라지지 않는다.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiWg3DvesRsEtdGyvsIE9tlUxXOaxyU5sLnOgzM6iiIgrEfGTs6vruWya3Z5a1mofGBbhi4ZkLVKXUGgm0PH09sPDwcJIriE2uJvXpcIV1OqzW76Oe_M4TVjhfMuQjUPnl1Hgv15qF5hR5lXy2v3ghlZ6cwpuyb2ia4Ut5gXsMknN_i5WcmvdTkBEi8eE0T/s1024/iis_agent2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"538\" data-original-width=\"1024\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiWg3DvesRsEtdGyvsIE9tlUxXOaxyU5sLnOgzM6iiIgrEfGTs6vruWya3Z5a1mofGBbhi4ZkLVKXUGgm0PH09sPDwcJIriE2uJvXpcIV1OqzW76Oe_M4TVjhfMuQjUPnl1Hgv15qF5hR5lXy2v3ghlZ6cwpuyb2ia4Ut5gXsMknN_i5WcmvdTkBEi8eE0T/s16000/iis_agent2.png\" /></a></div><div><br /></div><div>검색창에서는 잘 되는데?</div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhMNeBmYzh-e-VgoJth9E4E6WsWxKfP9clB8HWoQCHmGcJcJtDW9ahb7IZVD-apAQ3rL4-q9Norv5Ci57XqPXNwJ3EYocB4YXzfmLnWZX-mIbafQDSrXlMJvdUGDT4bbUUKxXBxnfMdcRPkpNpCXIotFqX7jjouuU7P6xV_NRyAiU61RpjKQEitzThxqeip/s1024/iis_agent3.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"538\" data-original-width=\"1024\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhMNeBmYzh-e-VgoJth9E4E6WsWxKfP9clB8HWoQCHmGcJcJtDW9ahb7IZVD-apAQ3rL4-q9Norv5Ci57XqPXNwJ3EYocB4YXzfmLnWZX-mIbafQDSrXlMJvdUGDT4bbUUKxXBxnfMdcRPkpNpCXIotFqX7jjouuU7P6xV_NRyAiU61RpjKQEitzThxqeip/s16000/iis_agent3.png\" /></a></div><br /><div>문득 계산 필드 정책은 순서대로 실행되지 않는다는 사실이 생각났다. 계산 필드는 모든 정책을 동시에 실행하기 때문에 agent2 필드를 만드는 시점에, +가 공백으로 바뀐 agent 필드는 존재하지 않는다는 얘기. 열심히 설명해놓고 설명대로 안 했네<span style=\"font-size: x-small;\">(..)</span></div><div><br /></div><div><div><b>관련 글</b></div><div><ul><li><a href=\"https://kangmyounghun.blogspot.com/2025/10/14th.html\">데이터 노가다 실수담 - 14th</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2019/01/blog-post_90.html\" target=\"\">데이터 노가다 실수담</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2023/06/blog-post.html\">평균의 함정</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2020/09/blog-post_27.html\" target=\"\">데이터 분석이 쉬워지는 비법</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2021/12/blog-post.html\" target=\"\">데이터 분석에 필요한 자질은 뭘까?</a></li></ul></div></div>",
        "contentSnippet": "IIS 웹로그는 모든 필드를 '공백'으로 구분하기 때문에 원활한 필드 분류를 위해 필드값에 포함된 공백을 + 기호로 대체한다.\n\n\n\n\n가독성을 높이기 위해 +를 공백으로 치환하는 계산 필드 정책 추가.\n\n\n\n\n+가 공백으로 바뀐 agent 필드 상태를 축소해서 agent2 필드에 저장하는 정책도 추가.\n\n\n\n\n그런데 + 기호가 사라지지 않는다.\n\n\n\n\n\n검색창에서는 잘 되는데?\n\n\n\n문득 계산 필드 정책은 순서대로 실행되지 않는다는 사실이 생각났다. 계산 필드는 모든 정책을 동시에 실행하기 때문에 agent2 필드를 만드는 시점에, +가 공백으로 바뀐 agent 필드는 존재하지 않는다는 얘기. 열심히 설명해놓고 설명대로 안 했네(..)\n\n\n관련 글\n\n데이터 노가다 실수담 - 14th\n데이터 노가다 실수담\n평균의 함정\n데이터 분석이 쉬워지는 비법\n데이터 분석에 필요한 자질은 뭘까?",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-8539436614040563107",
        "isoDate": "2026-01-22T12:55:00.003Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": [
      {
        "creator": "고명환",
        "title": "R&amp;D 합격은 성과지표(KPI)에서 갈린다. - 창업(스타트업)",
        "link": "https://brunch.co.kr/@@LOc/327",
        "pubDate": "Fri, 23 Jan 2026 03:32:32 GMT",
        "author": "고명환",
        "content": "1. 왜 R&amp;D 지원사업은 '성과지표'에서 합격이 갈릴까  처음 R&amp;D를 신청하는 스타트업 대표님들이 가장 많이 놓치는 지점은 한 가지입니다. 정부 R&amp;D는 '좋은 기술' 자체보다 예산 투입의 결과를 '증명 가능한 형태'로 설계했는지를 봅니다.  평가위원 입장에서 사업계획서는 결국 아래 질문에 대한 답입니다.  이 과제는 무엇을 만들고(산출물) 어떤 기준으<img src= \"https://img1.kakaocdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.kakaocdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2F_FRck0zdinWyIxb2nnpeUYPVaj0.jpg\" width=\"500\" />",
        "contentSnippet": "1. 왜 R&D 지원사업은 '성과지표'에서 합격이 갈릴까  처음 R&D를 신청하는 스타트업 대표님들이 가장 많이 놓치는 지점은 한 가지입니다. 정부 R&D는 '좋은 기술' 자체보다 예산 투입의 결과를 '증명 가능한 형태'로 설계했는지를 봅니다.  평가위원 입장에서 사업계획서는 결국 아래 질문에 대한 답입니다.  이 과제는 무엇을 만들고(산출물) 어떤 기준으",
        "guid": "https://brunch.co.kr/@@LOc/327",
        "isoDate": "2026-01-23T03:32:32.000Z"
      },
      {
        "creator": "고명환",
        "title": "2026년 중소벤처기업부 소상공인 지원사업 변화 총정리 - 창업(소상공인)",
        "link": "https://brunch.co.kr/@@LOc/326",
        "pubDate": "Wed, 21 Jan 2026 14:43:56 GMT",
        "author": "고명환",
        "content": "1. 왜 2026년 소상공인 정책이 중요한가  2026년은 소상공인 정책의 패러다임이 근본적으로 전환되는 해입니다.  중소벤처기업부는 더 이상 단순한 생계 유지 목적의 지원이 아닌, 성장 가능성이 있는 '기업가형 소상공인' 육성을 정책의 중심에 두었습니다. 이를 반영해 2026년 소상공인 지원사업은 총 7개 분야, 26개 사업, 약 1조 3,410억 원 &nbsp;<img src= \"https://img1.kakaocdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.kakaocdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2F5W3W4_3Cy9zKzHIIJMvXz1EfDbs.jpg\" width=\"500\" />",
        "contentSnippet": "1. 왜 2026년 소상공인 정책이 중요한가  2026년은 소상공인 정책의 패러다임이 근본적으로 전환되는 해입니다.  중소벤처기업부는 더 이상 단순한 생계 유지 목적의 지원이 아닌, 성장 가능성이 있는 '기업가형 소상공인' 육성을 정책의 중심에 두었습니다. 이를 반영해 2026년 소상공인 지원사업은 총 7개 분야, 26개 사업, 약 1조 3,410억 원",
        "guid": "https://brunch.co.kr/@@LOc/326",
        "isoDate": "2026-01-21T14:43:56.000Z"
      }
    ]
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "모공, 잡티, 솜털까지 표현! PURE GLOW 앱으로 AI 인물 피부 표현의 리얼리티를 극대화하는 법",
        "link": "https://muzbox.tistory.com/483704",
        "pubDate": "Sat, 24 Jan 2026 22:04:43 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "https://muzbox.tistory.com/483704#entry483704comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #3c4043;\">\n<div style=\"background-color: #e8f4fd; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">혹시 AI로 만든 인물 이미지가 너무 부자연스러워서 실망한 적 있으신가요? 오늘은 플라스틱 같은 피부, 인형 같은 눈동자 등 이른바 &lsquo;AI 티&rsquo; 나는 이미지를 피하고, 모공, 잡티, 솜털까지 섬세하게 표현하는 극사실적인 AI 인물 사진을 만드는 방법을 알려드립니다. 혁신적인 PURE GLOW 앱을 통해 조명, 카메라, 피부 질감, 움직임의 4가지 핵심 원칙을 적용하여 실제 사진처럼 보이는 이미지를 만드는 비법을 최신 정보로 공개합니다.</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/bkHtuJ/dJMcacBUIUt/uClZWIpkmmBoNEL7Tlw9L1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bkHtuJ/dJMcacBUIUt/uClZWIpkmmBoNEL7Tlw9L1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bkHtuJ/dJMcacBUIUt/uClZWIpkmmBoNEL7Tlw9L1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbkHtuJ%2FdJMcacBUIUt%2FuClZWIpkmmBoNEL7Tlw9L1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"다양한 인종과 연령대의 사람들이 자연스러운 표정으로 카메라를 응시하는 극사실적인 인물 사진. 모공, 미세한 잡티, 솜털까지 섬세하게 표현된 피부 질감이 돋보이며, 부드러운 자연광이 따뜻한 분위기를 연출한다.\" loading=\"lazy\" width=\"500\" height=\"500\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✨ AI 인물 이미지, 왜 '진짜' 같지 않을까?</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">AI 기술이 급속도로 발전하면서 이미지 생성 능력도 놀라워졌죠. 그런데 인물 사진만큼은 여전히 어딘가 어색하고 부자연스럽다는 느낌을 지울 수 없습니다. 분명히 &ldquo;사실적인 인물 사진을 생성해줘&rdquo;라고 요청했는데, 결과물은 플라스틱 같은 피부나 인형 같은 눈동자를 가진 이미지일 때가 많아요. 이를 우리는 흔히 <b>&ldquo;AI 티&rdquo;</b>가 난다고 표현하곤 합니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이런 이미지를 SNS 피드나 블로그 포스팅 섬네일에 사용하면 어떤 일이 벌어질까요? 유저들은 한눈에 &ldquo;아, 이건 그냥 대충 만든 이미지네&rdquo;라는 인상을 받게 되고, 이는 곧 서비스나 콘텐츠에 대한 신뢰도 하락으로 이어지기 쉽습니다. 저도 이런 경험이 참 많았어요. 완벽한 것 같으면서도 어딘가 부족한, 이른바 <b>&lsquo;불쾌한 골짜기(Uncanny Valley)&rsquo;</b> 현상이 바로 그 원인입니다.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  제미나이와 함께 찾아낸 극사실 이미지의 비밀</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">그렇다면 어떻게 해야 AI 티 없이 실제 사진처럼 보이는 극사실적인 인물 이미지를 만들 수 있을까요? 저는 이 질문을 제미나이(Gemini)에게 던져서 핵심 인사이트를 얻었습니다. 그리고 그 인사이트를 바탕으로 'PURE GLOW'라는 AI 인물 이미지 생성 앱을 직접 만들어봤어요. 제미나이의 답변은 정말 체계적이고 구체적이었습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">제미나이는 AI 이미지가 부자연스러운 주된 이유로 너무 <b>매끈한 피부, 완벽한 대칭, 과한 색감</b> 등을 꼽았으며, 이를 해결하기 위한 네 가지 핵심 원칙을 제시했습니다. 바로 <b>구체적인 시간대의 빛 지정, 실제 렌즈 스펙 활용, 피부의 불완전함 구현, 살아있는 움직임 담기</b>입니다. 또한, 앱 개발 시 필요한 조명 설정, 카메라 설정, 피부 질감 옵션, 포즈 라이브러리, 필름 스톡 같은 기능들도 상세하게 제안했죠. 이제 이 인사이트들을 바탕으로 AI 이미지의 10가지 흔한 실수와 고급 테크닉을 자세히 살펴보겠습니다.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  AI 티를 내는 10가지 흔한 실수와 개선 방안</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">먼저, 왜 AI 이미지가 이상해 보이는지부터 정확히 아는 것이 중요합니다. 제미나이가 알려준 10가지 결정적인 실수를 파악하고 피하면, 여러분의 AI 이미지 퀄리티가 확연히 달라질 거예요. 제가 직접 이미지를 생성하며 겪었던 문제점들이기도 합니다.</p>\n<ol style=\"list-style-type: decimal; margin-left: 20px; margin-bottom: 20px; color: #3c4043;\" data-ke-list-type=\"decimal\">\n<li style=\"margin-bottom: 10px;\"><b>너무 매끈한 피부:</b> AI는 기본적으로 완벽한 피부를 만들려 하지만, 실제 사람은 모공, 미세한 잡티, 솜털이 있어야 자연스럽습니다. <b>피부의 불완전함을 표현하는 디테일이 핵심이에요.</b></li>\n<li style=\"margin-bottom: 10px;\"><b>완벽한 좌우 대칭:</b> 사람의 얼굴은 완벽하게 대칭적이지 않습니다. 한쪽 눈썹이 살짝 높거나 입꼬리가 약간 다른 등 미묘한 비대칭이 오히려 자연스러움을 더하죠.</li>\n<li style=\"margin-bottom: 10px;\"><b>비현실적인 눈동자:</b> 너무 크거나 과하게 반짝이는 눈동자는 인형처럼 보입니다. 실제 눈은 주변 환경의 빛을 자연스럽게 반사하는 그 느낌이 중요해요.</li>\n<li style=\"margin-bottom: 10px;\"><b>배경이나 간판의 깨진 글자:</b> AI가 생성한 텍스트는 종종 이상하게 깨져 나옵니다. 배경에 간판이나 로고가 있다면, 아예 텍스트를 제외하는 것이 좋습니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>머리카락이 한 덩어리로 뭉쳐있음:</b> 플라스틱 가발처럼 보이는 머리카락은 부자연스럽습니다. '바람에 자연스럽게 흩날리는 머리카락'처럼 디테일을 추가해야 합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>배경이 너무 비현실적:</b> 지나치게 깔끔하거나 과도하게 흐려진 배경은 오히려 어색해요. 실제 사진처럼 자연스러운 디테일과 보케(아웃포커싱)가 필요합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>HDR처럼 색감이 과도함:</b> 너무 선명하고 강렬한 색감은 게임 그래픽처럼 보일 수 있습니다. 좀 더 미묘하고 자연스러운 색감이 실제 사진에 가깝습니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>디테일이 지나치게 선명함:</b> 모든 부분이 똑같이 선명하면 부자연스럽습니다. 실제 사진은 초점 맞은 부분만 선명하고 나머지는 살짝 흐릿하게 표현됩니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>포즈가 너무 과도함:</b> 억지스러운 모델 화보 같은 포즈보다는 자연스러운 일상적 순간을 포착한 느낌이 훨씬 리얼합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>조명이 너무 완벽함:</b> 스튜디오 조명처럼 그림자가 전혀 없고 모든 것이 균일하게 밝으면 인공적으로 보입니다. 실제 환경은 빛과 그림자의 자연스러운 대비가 있어야 합니다.</li>\n</ol>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 10가지 실수만 제대로 피해도 AI 이미지의 '티'는 정말 확연히 줄어들 것입니다. 저도 이 점들을 유의하면서 PURE GLOW 앱을 개발하고 사용하고 있습니다. 물론 처음부터 완벽하게 구현하기는 어렵지만, 꾸준히 시도하면 분명 좋은 결과를 얻을 수 있을 거예요.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/czpGkn/dJMcabbVpgz/GvGmjnmWDLtDTR7lOtPw6k/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/czpGkn/dJMcabbVpgz/GvGmjnmWDLtDTR7lOtPw6k/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/czpGkn/dJMcabbVpgz/GvGmjnmWDLtDTR7lOtPw6k/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FczpGkn%2FdJMcabbVpgz%2FGvGmjnmWDLtDTR7lOtPw6k%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"과도하게 매끄럽고 인형 같은 피부, 부자연스러운 눈동자를 가진 AI 생성 여성 인물 사진. 전반적으로 부자연스럽고 인공적인 느낌을 준다.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  극사실 표현을 위한 고급 테크닉: PURE GLOW의 핵심 원리</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">앞서 언급된 실수들을 피하는 것을 넘어, 한 차원 높은 리얼리티를 구현하기 위한 제미나이의 고급 조언들이 있었습니다. PURE GLOW 앱은 이러한 기법들을 옵션으로 제공하여 사용자가 쉽게 적용할 수 있도록 했습니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; padding-left: 10px; border-left: 3px solid #1a73e8;\" data-ke-size=\"size23\"><b>1. 필름 룩: 디지털 느낌을 없애고 아날로그 감성 더하기</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">디지털 이미지는 때로 너무 선명하고 색감이 강렬해서 인공적으로 보입니다. 반면 실제 필름 카메라로 찍은 사진은 색이 좀 더 부드럽고 미묘하며, 특유의 감성을 담고 있죠. PURE GLOW는 대표적인 필름 스톡을 모방한 필터를 제공하여 이러한 아날로그적인 느낌을 연출할 수 있습니다.</p>\n<ul style=\"list-style-type: disc; margin-left: 20px; margin-bottom: 20px; color: #3c4043;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 8px;\"><b>코닥 포트라 400:</b> 따뜻하고 부드러운 색감으로, 특히 피부 톤을 아름답게 표현하는 데 탁월합니다.</li>\n<li style=\"margin-bottom: 8px;\"><b>후지 400H:</b> 살짝 차갑고 청량한 느낌으로, 현대적인 감성을 더할 때 유용합니다.</li>\n<li style=\"margin-bottom: 8px;\"><b>코닥 골드 200:</b> 따뜻하고 빈티지한 느낌을 선사하여 아련한 분위기를 연출할 수 있습니다.</li>\n</ul>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">또한, 필름 사진 특유의 미세한 입자감, 즉 <b>그레인(Grain)</b> 효과는 오히려 이미지에 자연스럽고 따뜻한 감성을 불어넣어줍니다. PURE GLOW에서는 이러한 디테일한 옵션까지 조절할 수 있습니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; padding-left: 10px; border-left: 3px solid #1a73e8;\" data-ke-size=\"size23\"><b>2. 혼합광: 실제 환경의 빛을 재현하라</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">실제 실내 환경을 생각해보면, 단 하나의 광원만 있는 경우는 거의 없습니다. 창문으로 들어오는 차가운 자연광, 천장의 따뜻한 램프 조명 등 여러 광원이 섞여있는 것이 현실이죠. PURE GLOW의 <b>'아침 창가광'</b> 같은 조명 설정은 이처럼 복합적인 혼합광 효과를 재현하여 이미지에 극도의 사실감을 부여합니다.</p>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>팁:</b> 자연스러운 혼합광은 인물의 입체감을 살리고 그림자를 부드럽게 만들어, AI 이미지가 가진 평면적인 느낌을 효과적으로 줄여줍니다.</div>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; padding-left: 10px; border-left: 3px solid #1a73e8;\" data-ke-size=\"size23\"><b>3. 재질감: 고급스러움과 현실감의 결정적 요소</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">의상 설명을 할 때 단순히 &ldquo;예쁜 원피스&rdquo;라고 하는 대신, <b>&ldquo;실크 소재의 은은하게 빛나는 원피스&rdquo;</b>처럼 재질을 구체적으로 지정하는 것이 중요합니다. 재질마다 빛을 받았을 때 반사되는 방식이 다르기 때문이에요. 실크는 은은한 광택을, 린넨은 거친 반사를, 캐시미어는 부드러운 빛 흡수를 보여주죠. PURE GLOW 앱에서는 이러한 재질감 옵션을 세밀하게 조절하여 의상과 배경의 현실감을 높일 수 있습니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/bi9GKZ/dJMcadtZtAs/2NGKBlMbb8YNNj8h8q41I1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bi9GKZ/dJMcadtZtAs/2NGKBlMbb8YNNj8h8q41I1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bi9GKZ/dJMcadtZtAs/2NGKBlMbb8YNNj8h8q41I1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbi9GKZ%2FdJMcadtZtAs%2F2NGKBlMbb8YNNj8h8q41I1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"주름, 기미, 솜털이 자연스럽게 드러나는 노인의 사실적인 인물 사진. 나이 든 피부의 질감과 따뜻한 자연광이 실제와 같은 느낌을 강조한다.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  PURE GLOW 앱으로 만드는 '진짜' 같은 AI 인물 이미지</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">제가 제미나이의 인사이트를 바탕으로 개발한 PURE GLOW 앱은 위에 언급된 모든 원칙과 고급 테크닉들을 손쉽게 적용할 수 있도록 설계되었습니다. 2026년 현재, 이 앱은 나노 바나나 프로(Nano Banana Pro) API를 활용하여 구체적인 설정값만 입력하면 누구든지 클릭 몇 번으로 극사실적인 AI 인물 이미지를 만들 수 있도록 돕습니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1670\" data-origin-height=\"989\"><span data-url=\"https://blog.kakaocdn.net/dn/bgIKSk/dJMcab33Lbi/3jkzYaqiDwMYAJBvwCuBV1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bgIKSk/dJMcab33Lbi/3jkzYaqiDwMYAJBvwCuBV1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bgIKSk/dJMcab33Lbi/3jkzYaqiDwMYAJBvwCuBV1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbgIKSk%2FdJMcab33Lbi%2F3jkzYaqiDwMYAJBvwCuBV1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"'PURE GLOW' 앱의 사용자 인터페이스 화면으로, 조명, 카메라, 피부 질감 등 다양한 설정 옵션과 함께 자연스러운 AI 인물 사진 미리보기가 보인다.\" loading=\"lazy\" width=\"1670\" height=\"989\" data-origin-width=\"1670\" data-origin-height=\"989\"/></span></figure>\n\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; padding-left: 10px; border-left: 3px solid #1a73e8;\" data-ke-size=\"size23\"><b>PURE GLOW의 기본 기능</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">PURE GLOW의 기본 설정은 다음과 같이 구성되어 있습니다:</p>\n<table style=\"width: 100%; border-collapse: collapse; margin-bottom: 20px; text-align: left; color: #3c4043;\" data-ke-align=\"alignLeft\">\n<thead>\n<tr style=\"background-color: #e8eaed;\">\n<th style=\"border: 1px solid #dadce0; padding: 10px; font-weight: bold; color: #3c4043;\">카테고리</th>\n<th style=\"border: 1px solid #dadce0; padding: 10px; font-weight: bold; color: #3c4043;\">주요 설정 옵션</th>\n</tr>\n</thead>\n<tbody>\n<tr style=\"background-color: white;\">\n<td style=\"border: 1px solid #dadce0; padding: 10px; color: #3c4043;\">외형 설정</td>\n<td style=\"border: 1px solid #dadce0; padding: 10px; color: #3c4043;\">성별, 국적, 나이, 헤어스타일</td>\n</tr>\n<tr style=\"background-color: #f1f3f4;\">\n<td style=\"border: 1px solid #dadce0; padding: 10px; color: #3c4043;\">인물 디테일</td>\n<td style=\"border: 1px solid #dadce0; padding: 10px; color: #3c4043;\">표정, 포즈, 의상, 장소</td>\n</tr>\n<tr style=\"background-color: white;\">\n<td style=\"border: 1px solid #dadce0; padding: 10px; color: #3c4043;\">사실감 강화</td>\n<td style=\"border: 1px solid #dadce0; padding: 10px; color: #3c4043;\">조명 및 카메라 설정, 피부 질감 (모공, 잡티, 솜털)</td>\n</tr>\n<tr style=\"background-color: #f1f3f4;\">\n<td style=\"border: 1px solid #dadce0; padding: 10px; color: #3c4043;\">필터 및 기타</td>\n<td style=\"border: 1px solid #dadce0; padding: 10px; color: #3c4043;\">필름 필터(코닥 포트라 400 등), 랜덤 생성 기능</td>\n</tr>\n</tbody>\n</table>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">예를 들어, 20대 한국 여성에 오버사이즈 화이트 셔츠, 도서관 장소, 은은한 미소와 벽에 기대는 포즈, 아침 창가광 조명, 폰 카메라 후면 장비, 코닥 포트라 400 필름 필터, 그리고 <b>초정밀 모공, 사실적 잡티, 솜털까지 적용한 피부 질감</b>을 선택하면, 실제로 촬영한 것과 같은 높은 퀄리티의 이미지를 얻을 수 있습니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; padding-left: 10px; border-left: 3px solid #1a73e8;\" data-ke-size=\"size23\"><b>PURE GLOW Pro: AI 인플루언서 기능으로 확장된 활용성</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">PURE GLOW 프로 버전은 단순한 이미지 생성을 넘어, 가상 인플루언서의 하루 일과나 특정 이벤트를 AI가 자동으로 생성하고 여기에 광고까지 포함할 수 있는 획기적인 기능을 제공합니다. 이 기능은 특히 소셜 미디어 콘텐츠 제작자나 마케터에게 유용할 것입니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">인물 설정을 마친 후 '랜덤 일과'를 클릭하면 시간대별로 다양한 이벤트 목록이 생성되며, 이를 기반으로 레퍼런스 이미지를 등록하거나 바로 이미지를 생성하여 가상 인플루언서의 특별한 하루를 연출할 수 있습니다. 또한, 사용자가 직접 'AI 플래닝 입력 창'에 간단한 하루 일정을 입력하면, AI가 이를 바탕으로 맞춤형 이벤트 목록을 생성해주기도 합니다.</p>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>주목:</b> 광고 모드에서는 특정 광고 유형을 선택하고 상품 사진과 제품명을 입력하면, 선택한 이벤트와 상품이 자연스럽게 적용된 이미지를 생성할 수 있습니다. 이는 제품 홍보 콘텐츠 제작에 혁신적인 변화를 가져올 거예요.</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">생성된 이미지와 함께 인스타그램에 바로 올릴 수 있는 적절한 캡션과 해시태그까지 자동으로 제공되니, 콘텐츠 제작 과정이 훨씬 간편해집니다. 만약 캡션이 마음에 들지 않는다면 '다시 생성' 버튼을 클릭하여 새로운 캡션을 받아볼 수도 있습니다. 제가 직접 해보니 정말 편리하고 아이디어를 얻기에도 좋았습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">&nbsp;</p>\n<figure id=\"og_1769260181702\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"PureGlow: AI Influencer Studio\" data-og-description=\"\" data-og-host=\"pure-glow-basic.vercel.app\" data-og-source-url=\"https://pure-glow-basic.vercel.app/\" data-og-url=\"https://pure-glow-basic.vercel.app/\" data-og-image=\"\"><a href=\"https://pure-glow-basic.vercel.app/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://pure-glow-basic.vercel.app/\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">PureGlow: AI Influencer Studio</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">&nbsp;</p>\n<p class=\"og-host\" data-ke-size=\"size16\">pure-glow-basic.vercel.app</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  핵심 요약: PURE GLOW가 선사하는 AI 이미지의 새 지평</b></h2>\n<div style=\"background-color: #f8f9fa; border: 1px solid #dadce0; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); padding: 25px; margin-bottom: 30px;\">\n<div style=\"font-size: 26px; color: #1a73e8; font-weight: bold; margin-bottom: 15px; padding-bottom: 10px; border-bottom: 2px solid #1a73e8;\">  핵심 요약</div>\n<ul style=\"list-style: none; padding: 0; margin-bottom: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"font-size: 17px; margin-bottom: 10px;\"><b>1. 'AI 티' 제거:</b> PURE GLOW는 매끈한 피부, 완벽 대칭 등 AI 이미지의 흔한 실수를 보완하여 실제 사진 같은 리얼리티를 구현합니다.</li>\n<li style=\"font-size: 17px; margin-bottom: 10px;\"><b>2. 4가지 핵심 원칙:</b> 조명, 카메라, 피부 질감, 움직임의 디테일한 설정으로 극사실적인 인물 표현을 가능하게 합니다.</li>\n<li style=\"font-size: 17px; margin-bottom: 10px;\"><b>3. 고급 테크닉 적용:</b> 필름 룩, 혼합광, 재질감 표현 등 전문적인 사진 기법을 앱 내에서 쉽게 사용할 수 있습니다.</li>\n<li style=\"font-size: 17px; margin-bottom: 10px;\"><b>4. AI 인플루언서 기능:</b> 프로 버전은 가상 인플루언서의 하루를 생성하고 광고 콘텐츠까지 제작할 수 있어 콘텐츠 마케팅에 최적화되어 있습니다.</li>\n</ul>\n<div style=\"font-size: 14px; color: #5f6368; border-top: 1px dashed #dadce0; padding-top: 15px;\">이러한 기능들을 통해 PURE GLOW는 단순한 이미지 생성을 넘어, 새로운 형태의 디지털 콘텐츠를 창조하는 강력한 도구가 될 것입니다.</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<div style=\"margin-bottom: 15px;\">\n<p style=\"margin-bottom: 5px; font-weight: bold; color: #3c4043;\" data-ke-size=\"size16\">Q1: PURE GLOW 앱은 어떤 AI 엔진을 사용하나요?</p>\n<p style=\"margin-bottom: 20px; color: #3c4043;\" data-ke-size=\"size16\">A1: PURE GLOW 앱은 나노 바나나 프로(Nano Banana Pro) API를 활용하여 이미지를 생성합니다. 이를 통해 사용자들은 고품질의 사실적인 이미지를 얻을 수 있습니다.</p>\n</div>\n<div style=\"margin-bottom: 15px;\">\n<p style=\"margin-bottom: 5px; font-weight: bold; color: #3c4043;\" data-ke-size=\"size16\">Q2: PURE GLOW로 만든 이미지는 상업적으로 이용해도 되나요?</p>\n<p style=\"margin-bottom: 20px; color: #3c4043;\" data-ke-size=\"size16\">A2: 네, 상업적 이용이 가능하지만, AI 인플루언서 기능으로 생성된 이미지는 <b>가상의 인물</b>이라는 점을 명확히 고지해야 합니다. SNS 업로드 시 '#AI생성이미지', '#가상인물'과 같은 해시태그를 반드시 포함해 주세요.</p>\n</div>\n<div style=\"margin-bottom: 15px;\">\n<p style=\"margin-bottom: 5px; font-weight: bold; color: #3c4043;\" data-ke-size=\"size16\">Q3: PURE GLOW 베이직 버전과 프로 버전의 차이점은 무엇인가요?</p>\n<p style=\"margin-bottom: 20px; color: #3c4043;\" data-ke-size=\"size16\">A3: 베이직 버전은 사실적인 인물 이미지 생성의 기본 기능을 제공하며, 프로 버전은 여기에 AI 인플루언서 기능(하루 일과 및 광고 콘텐츠 자동 생성)이 추가되어 더욱 폭넓은 활용이 가능합니다.</p>\n</div>\n<div style=\"margin-bottom: 15px;\">\n<p style=\"margin-bottom: 5px; font-weight: bold; color: #3c4043;\" data-ke-size=\"size16\">Q4: 이미지 생성 시 텍스트나 로고가 깨져서 나오는 문제가 발생합니다.</p>\n<p style=\"margin-bottom: 20px; color: #3c4043;\" data-ke-size=\"size16\">A4: AI 이미지 생성 시 텍스트는 아직 완벽하지 않은 경우가 많습니다. 배경에 간판이나 포스터가 포함될 경우, 프롬프트에 '텍스트, 간판, 로고 제외'와 같은 지시어를 추가하여 텍스트 깨짐 현상을 방지하는 것이 좋습니다.</p>\n</div>\n<script type=\"application/ld+json\">\n  {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n      {\n        \"@type\": \"Question\",\n        \"name\": \"PURE GLOW 앱은 어떤 AI 엔진을 사용하나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"PURE GLOW 앱은 나노 바나나 프로(Nano Banana Pro) API를 활용하여 이미지를 생성합니다. 이를 통해 사용자들은 고품질의 사실적인 이미지를 얻을 수 있습니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"PURE GLOW로 만든 이미지는 상업적으로 이용해도 되나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"네, 상업적 이용이 가능하지만, AI 인플루언서 기능으로 생성된 이미지는 가상의 인물이라는 점을 명확히 고지해야 합니다. SNS 업로드 시 '#AI생성이미지', '#가상인물'과 같은 해시태그를 반드시 포함해 주세요.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"PURE GLOW 베이직 버전과 프로 버전의 차이점은 무엇인가요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"베이직 버전은 사실적인 인물 이미지 생성의 기본 기능을 제공하며, 프로 버전은 여기에 AI 인플루언서 기능(하루 일과 및 광고 콘텐츠 자동 생성)이 추가되어 더욱 폭넓은 활용이 가능합니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"이미지 생성 시 텍스트나 로고가 깨져서 나오는 문제가 발생합니다.\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"AI 이미지 생성 시 텍스트는 아직 완벽하지 않은 경우가 많습니다. 배경에 간판이나 포스터가 포함될 경우, 프롬프트에 '텍스트, 간판, 로고 제외'와 같은 지시어를 추가하여 텍스트 깨짐 현상을 방지하는 것이 좋습니다.\"\n        }\n      }\n    ]\n  }\n  </script>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>마무리하며: AI 이미지의 새로운 기준을 제시하다</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">지금까지 PURE GLOW 앱을 활용하여 모공, 잡티, 솜털까지 표현하는 극사실적인 AI 인물 이미지를 만드는 방법을 자세히 살펴보았습니다. AI 기술이 아직 완벽하지 않더라도, 우리가 디테일한 부분에 신경 쓰고 실제 사진의 특성을 이해한다면 충분히 '진짜보다 더 진짜 같은' 결과물을 만들 수 있다는 것을 알게 되셨으리라 생각합니다. 2026년에 들어서면서 AI 이미지 생성 기술은 더욱 빠르게 발전하고 있으며, PURE GLOW와 같은 도구들은 이러한 발전을 한층 더 가속화할 것이라고 믿어요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>중요한 주의사항을 다시 한번 강조합니다:</b> AI 인플루언서 기능으로 생성된 이미지는 <b>가상의 인물</b>입니다. SNS에 올리거나 포트폴리오에 사용할 때는 반드시 <b>\"#AI생성이미지\", \"#가상인물\"</b>과 같은 해시태그를 달아 실제 사람인 것처럼 오인하게 하거나 악의적으로 사용해서는 절대 안 됩니다. 이는 윤리적인 AI 사용에 있어 매우 중요한 부분이에요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">PURE GLOW는 베이직 버전과 AI 인플루언서 기능까지 포함된 프로 버전으로 나뉘니, 여러분의 프로젝트나 필요에 맞는 버전을 선택하여 활용해보시길 바랍니다. 이 글이 여러분의 AI 이미지 생성 작업에 큰 도움이 되었기를 진심으로 바랍니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=4u1MrSxVYZ0\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/PtDCd/dJMb9dHimQ7/hz7yVlea1XkdpJGnUCuXh1/img.jpg?width=1280&amp;height=720&amp;face=106_208_1144_576,https://scrap.kakaocdn.net/dn/blEsrm/dJMb81GRuAd/ciKYhQ8iV3U3903v5MtIy0/img.jpg?width=1280&amp;height=720&amp;face=106_208_1144_576\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"이게 진짜 AI라고?&quot; 플라스틱 피부 탈출! 극사실 인물 사진 만드는 비법 (ft. 제미나이)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/4u1MrSxVYZ0\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n</div>",
        "contentSnippet": "혹시 AI로 만든 인물 이미지가 너무 부자연스러워서 실망한 적 있으신가요? 오늘은 플라스틱 같은 피부, 인형 같은 눈동자 등 이른바 ‘AI 티’ 나는 이미지를 피하고, 모공, 잡티, 솜털까지 섬세하게 표현하는 극사실적인 AI 인물 사진을 만드는 방법을 알려드립니다. 혁신적인 PURE GLOW 앱을 통해 조명, 카메라, 피부 질감, 움직임의 4가지 핵심 원칙을 적용하여 실제 사진처럼 보이는 이미지를 만드는 비법을 최신 정보로 공개합니다.\n\n\n✨ AI 인물 이미지, 왜 '진짜' 같지 않을까?\nAI 기술이 급속도로 발전하면서 이미지 생성 능력도 놀라워졌죠. 그런데 인물 사진만큼은 여전히 어딘가 어색하고 부자연스럽다는 느낌을 지울 수 없습니다. 분명히 “사실적인 인물 사진을 생성해줘”라고 요청했는데, 결과물은 플라스틱 같은 피부나 인형 같은 눈동자를 가진 이미지일 때가 많아요. 이를 우리는 흔히 “AI 티”가 난다고 표현하곤 합니다.\n이런 이미지를 SNS 피드나 블로그 포스팅 섬네일에 사용하면 어떤 일이 벌어질까요? 유저들은 한눈에 “아, 이건 그냥 대충 만든 이미지네”라는 인상을 받게 되고, 이는 곧 서비스나 콘텐츠에 대한 신뢰도 하락으로 이어지기 쉽습니다. 저도 이런 경험이 참 많았어요. 완벽한 것 같으면서도 어딘가 부족한, 이른바 ‘불쾌한 골짜기(Uncanny Valley)’ 현상이 바로 그 원인입니다.\n  제미나이와 함께 찾아낸 극사실 이미지의 비밀\n그렇다면 어떻게 해야 AI 티 없이 실제 사진처럼 보이는 극사실적인 인물 이미지를 만들 수 있을까요? 저는 이 질문을 제미나이(Gemini)에게 던져서 핵심 인사이트를 얻었습니다. 그리고 그 인사이트를 바탕으로 'PURE GLOW'라는 AI 인물 이미지 생성 앱을 직접 만들어봤어요. 제미나이의 답변은 정말 체계적이고 구체적이었습니다.\n제미나이는 AI 이미지가 부자연스러운 주된 이유로 너무 매끈한 피부, 완벽한 대칭, 과한 색감 등을 꼽았으며, 이를 해결하기 위한 네 가지 핵심 원칙을 제시했습니다. 바로 구체적인 시간대의 빛 지정, 실제 렌즈 스펙 활용, 피부의 불완전함 구현, 살아있는 움직임 담기입니다. 또한, 앱 개발 시 필요한 조명 설정, 카메라 설정, 피부 질감 옵션, 포즈 라이브러리, 필름 스톡 같은 기능들도 상세하게 제안했죠. 이제 이 인사이트들을 바탕으로 AI 이미지의 10가지 흔한 실수와 고급 테크닉을 자세히 살펴보겠습니다.\n  AI 티를 내는 10가지 흔한 실수와 개선 방안\n먼저, 왜 AI 이미지가 이상해 보이는지부터 정확히 아는 것이 중요합니다. 제미나이가 알려준 10가지 결정적인 실수를 파악하고 피하면, 여러분의 AI 이미지 퀄리티가 확연히 달라질 거예요. 제가 직접 이미지를 생성하며 겪었던 문제점들이기도 합니다.\n너무 매끈한 피부: AI는 기본적으로 완벽한 피부를 만들려 하지만, 실제 사람은 모공, 미세한 잡티, 솜털이 있어야 자연스럽습니다. 피부의 불완전함을 표현하는 디테일이 핵심이에요.\n완벽한 좌우 대칭: 사람의 얼굴은 완벽하게 대칭적이지 않습니다. 한쪽 눈썹이 살짝 높거나 입꼬리가 약간 다른 등 미묘한 비대칭이 오히려 자연스러움을 더하죠.\n비현실적인 눈동자: 너무 크거나 과하게 반짝이는 눈동자는 인형처럼 보입니다. 실제 눈은 주변 환경의 빛을 자연스럽게 반사하는 그 느낌이 중요해요.\n배경이나 간판의 깨진 글자: AI가 생성한 텍스트는 종종 이상하게 깨져 나옵니다. 배경에 간판이나 로고가 있다면, 아예 텍스트를 제외하는 것이 좋습니다.\n머리카락이 한 덩어리로 뭉쳐있음: 플라스틱 가발처럼 보이는 머리카락은 부자연스럽습니다. '바람에 자연스럽게 흩날리는 머리카락'처럼 디테일을 추가해야 합니다.\n배경이 너무 비현실적: 지나치게 깔끔하거나 과도하게 흐려진 배경은 오히려 어색해요. 실제 사진처럼 자연스러운 디테일과 보케(아웃포커싱)가 필요합니다.\nHDR처럼 색감이 과도함: 너무 선명하고 강렬한 색감은 게임 그래픽처럼 보일 수 있습니다. 좀 더 미묘하고 자연스러운 색감이 실제 사진에 가깝습니다.\n디테일이 지나치게 선명함: 모든 부분이 똑같이 선명하면 부자연스럽습니다. 실제 사진은 초점 맞은 부분만 선명하고 나머지는 살짝 흐릿하게 표현됩니다.\n포즈가 너무 과도함: 억지스러운 모델 화보 같은 포즈보다는 자연스러운 일상적 순간을 포착한 느낌이 훨씬 리얼합니다.\n조명이 너무 완벽함: 스튜디오 조명처럼 그림자가 전혀 없고 모든 것이 균일하게 밝으면 인공적으로 보입니다. 실제 환경은 빛과 그림자의 자연스러운 대비가 있어야 합니다.\n이 10가지 실수만 제대로 피해도 AI 이미지의 '티'는 정말 확연히 줄어들 것입니다. 저도 이 점들을 유의하면서 PURE GLOW 앱을 개발하고 사용하고 있습니다. 물론 처음부터 완벽하게 구현하기는 어렵지만, 꾸준히 시도하면 분명 좋은 결과를 얻을 수 있을 거예요.\n\n\n  극사실 표현을 위한 고급 테크닉: PURE GLOW의 핵심 원리\n앞서 언급된 실수들을 피하는 것을 넘어, 한 차원 높은 리얼리티를 구현하기 위한 제미나이의 고급 조언들이 있었습니다. PURE GLOW 앱은 이러한 기법들을 옵션으로 제공하여 사용자가 쉽게 적용할 수 있도록 했습니다.\n1. 필름 룩: 디지털 느낌을 없애고 아날로그 감성 더하기\n디지털 이미지는 때로 너무 선명하고 색감이 강렬해서 인공적으로 보입니다. 반면 실제 필름 카메라로 찍은 사진은 색이 좀 더 부드럽고 미묘하며, 특유의 감성을 담고 있죠. PURE GLOW는 대표적인 필름 스톡을 모방한 필터를 제공하여 이러한 아날로그적인 느낌을 연출할 수 있습니다.\n코닥 포트라 400: 따뜻하고 부드러운 색감으로, 특히 피부 톤을 아름답게 표현하는 데 탁월합니다.\n후지 400H: 살짝 차갑고 청량한 느낌으로, 현대적인 감성을 더할 때 유용합니다.\n코닥 골드 200: 따뜻하고 빈티지한 느낌을 선사하여 아련한 분위기를 연출할 수 있습니다.\n또한, 필름 사진 특유의 미세한 입자감, 즉 그레인(Grain) 효과는 오히려 이미지에 자연스럽고 따뜻한 감성을 불어넣어줍니다. PURE GLOW에서는 이러한 디테일한 옵션까지 조절할 수 있습니다.\n2. 혼합광: 실제 환경의 빛을 재현하라\n실제 실내 환경을 생각해보면, 단 하나의 광원만 있는 경우는 거의 없습니다. 창문으로 들어오는 차가운 자연광, 천장의 따뜻한 램프 조명 등 여러 광원이 섞여있는 것이 현실이죠. PURE GLOW의 '아침 창가광' 같은 조명 설정은 이처럼 복합적인 혼합광 효과를 재현하여 이미지에 극도의 사실감을 부여합니다.\n  팁: 자연스러운 혼합광은 인물의 입체감을 살리고 그림자를 부드럽게 만들어, AI 이미지가 가진 평면적인 느낌을 효과적으로 줄여줍니다.\n3. 재질감: 고급스러움과 현실감의 결정적 요소\n의상 설명을 할 때 단순히 “예쁜 원피스”라고 하는 대신, “실크 소재의 은은하게 빛나는 원피스”처럼 재질을 구체적으로 지정하는 것이 중요합니다. 재질마다 빛을 받았을 때 반사되는 방식이 다르기 때문이에요. 실크는 은은한 광택을, 린넨은 거친 반사를, 캐시미어는 부드러운 빛 흡수를 보여주죠. PURE GLOW 앱에서는 이러한 재질감 옵션을 세밀하게 조절하여 의상과 배경의 현실감을 높일 수 있습니다.\n\n\n  PURE GLOW 앱으로 만드는 '진짜' 같은 AI 인물 이미지\n제가 제미나이의 인사이트를 바탕으로 개발한 PURE GLOW 앱은 위에 언급된 모든 원칙과 고급 테크닉들을 손쉽게 적용할 수 있도록 설계되었습니다. 2026년 현재, 이 앱은 나노 바나나 프로(Nano Banana Pro) API를 활용하여 구체적인 설정값만 입력하면 누구든지 클릭 몇 번으로 극사실적인 AI 인물 이미지를 만들 수 있도록 돕습니다.\n\n\nPURE GLOW의 기본 기능\nPURE GLOW의 기본 설정은 다음과 같이 구성되어 있습니다:\n카테고리\n주요 설정 옵션\n\n\n\n\n외형 설정\n성별, 국적, 나이, 헤어스타일\n\n\n인물 디테일\n표정, 포즈, 의상, 장소\n\n\n사실감 강화\n조명 및 카메라 설정, 피부 질감 (모공, 잡티, 솜털)\n\n\n필터 및 기타\n필름 필터(코닥 포트라 400 등), 랜덤 생성 기능\n\n\n\n예를 들어, 20대 한국 여성에 오버사이즈 화이트 셔츠, 도서관 장소, 은은한 미소와 벽에 기대는 포즈, 아침 창가광 조명, 폰 카메라 후면 장비, 코닥 포트라 400 필름 필터, 그리고 초정밀 모공, 사실적 잡티, 솜털까지 적용한 피부 질감을 선택하면, 실제로 촬영한 것과 같은 높은 퀄리티의 이미지를 얻을 수 있습니다.\nPURE GLOW Pro: AI 인플루언서 기능으로 확장된 활용성\nPURE GLOW 프로 버전은 단순한 이미지 생성을 넘어, 가상 인플루언서의 하루 일과나 특정 이벤트를 AI가 자동으로 생성하고 여기에 광고까지 포함할 수 있는 획기적인 기능을 제공합니다. 이 기능은 특히 소셜 미디어 콘텐츠 제작자나 마케터에게 유용할 것입니다.\n인물 설정을 마친 후 '랜덤 일과'를 클릭하면 시간대별로 다양한 이벤트 목록이 생성되며, 이를 기반으로 레퍼런스 이미지를 등록하거나 바로 이미지를 생성하여 가상 인플루언서의 특별한 하루를 연출할 수 있습니다. 또한, 사용자가 직접 'AI 플래닝 입력 창'에 간단한 하루 일정을 입력하면, AI가 이를 바탕으로 맞춤형 이벤트 목록을 생성해주기도 합니다.\n  주목: 광고 모드에서는 특정 광고 유형을 선택하고 상품 사진과 제품명을 입력하면, 선택한 이벤트와 상품이 자연스럽게 적용된 이미지를 생성할 수 있습니다. 이는 제품 홍보 콘텐츠 제작에 혁신적인 변화를 가져올 거예요.\n생성된 이미지와 함께 인스타그램에 바로 올릴 수 있는 적절한 캡션과 해시태그까지 자동으로 제공되니, 콘텐츠 제작 과정이 훨씬 간편해집니다. 만약 캡션이 마음에 들지 않는다면 '다시 생성' 버튼을 클릭하여 새로운 캡션을 받아볼 수도 있습니다. 제가 직접 해보니 정말 편리하고 아이디어를 얻기에도 좋았습니다.\n \n\n \nPureGlow: AI Influencer Studio\n \npure-glow-basic.vercel.app\n\n \n  핵심 요약: PURE GLOW가 선사하는 AI 이미지의 새 지평\n  핵심 요약\n1. 'AI 티' 제거: PURE GLOW는 매끈한 피부, 완벽 대칭 등 AI 이미지의 흔한 실수를 보완하여 실제 사진 같은 리얼리티를 구현합니다.\n2. 4가지 핵심 원칙: 조명, 카메라, 피부 질감, 움직임의 디테일한 설정으로 극사실적인 인물 표현을 가능하게 합니다.\n3. 고급 테크닉 적용: 필름 룩, 혼합광, 재질감 표현 등 전문적인 사진 기법을 앱 내에서 쉽게 사용할 수 있습니다.\n4. AI 인플루언서 기능: 프로 버전은 가상 인플루언서의 하루를 생성하고 광고 콘텐츠까지 제작할 수 있어 콘텐츠 마케팅에 최적화되어 있습니다.\n이러한 기능들을 통해 PURE GLOW는 단순한 이미지 생성을 넘어, 새로운 형태의 디지털 콘텐츠를 창조하는 강력한 도구가 될 것입니다.\n❓ 자주 묻는 질문 (FAQ)\nQ1: PURE GLOW 앱은 어떤 AI 엔진을 사용하나요?\nA1: PURE GLOW 앱은 나노 바나나 프로(Nano Banana Pro) API를 활용하여 이미지를 생성합니다. 이를 통해 사용자들은 고품질의 사실적인 이미지를 얻을 수 있습니다.\nQ2: PURE GLOW로 만든 이미지는 상업적으로 이용해도 되나요?\nA2: 네, 상업적 이용이 가능하지만, AI 인플루언서 기능으로 생성된 이미지는 가상의 인물이라는 점을 명확히 고지해야 합니다. SNS 업로드 시 '#AI생성이미지', '#가상인물'과 같은 해시태그를 반드시 포함해 주세요.\nQ3: PURE GLOW 베이직 버전과 프로 버전의 차이점은 무엇인가요?\nA3: 베이직 버전은 사실적인 인물 이미지 생성의 기본 기능을 제공하며, 프로 버전은 여기에 AI 인플루언서 기능(하루 일과 및 광고 콘텐츠 자동 생성)이 추가되어 더욱 폭넓은 활용이 가능합니다.\nQ4: 이미지 생성 시 텍스트나 로고가 깨져서 나오는 문제가 발생합니다.\nA4: AI 이미지 생성 시 텍스트는 아직 완벽하지 않은 경우가 많습니다. 배경에 간판이나 포스터가 포함될 경우, 프롬프트에 '텍스트, 간판, 로고 제외'와 같은 지시어를 추가하여 텍스트 깨짐 현상을 방지하는 것이 좋습니다.\n마무리하며: AI 이미지의 새로운 기준을 제시하다\n지금까지 PURE GLOW 앱을 활용하여 모공, 잡티, 솜털까지 표현하는 극사실적인 AI 인물 이미지를 만드는 방법을 자세히 살펴보았습니다. AI 기술이 아직 완벽하지 않더라도, 우리가 디테일한 부분에 신경 쓰고 실제 사진의 특성을 이해한다면 충분히 '진짜보다 더 진짜 같은' 결과물을 만들 수 있다는 것을 알게 되셨으리라 생각합니다. 2026년에 들어서면서 AI 이미지 생성 기술은 더욱 빠르게 발전하고 있으며, PURE GLOW와 같은 도구들은 이러한 발전을 한층 더 가속화할 것이라고 믿어요.\n중요한 주의사항을 다시 한번 강조합니다: AI 인플루언서 기능으로 생성된 이미지는 가상의 인물입니다. SNS에 올리거나 포트폴리오에 사용할 때는 반드시 \"#AI생성이미지\", \"#가상인물\"과 같은 해시태그를 달아 실제 사람인 것처럼 오인하게 하거나 악의적으로 사용해서는 절대 안 됩니다. 이는 윤리적인 AI 사용에 있어 매우 중요한 부분이에요.\nPURE GLOW는 베이직 버전과 AI 인플루언서 기능까지 포함된 프로 버전으로 나뉘니, 여러분의 프로젝트나 필요에 맞는 버전을 선택하여 활용해보시길 바랍니다. 이 글이 여러분의 AI 이미지 생성 작업에 큰 도움이 되었기를 진심으로 바랍니다.",
        "guid": "https://muzbox.tistory.com/483704",
        "categories": [
          "AI, 미래기술/AI 챗봇 및 지침 무료 배포",
          "AI 인물 사진",
          "ai 인플루언서",
          "AI 피부 표현",
          "DALL-E 프롬프트",
          "PURE GLOW 앱",
          "극사실 이미지",
          "모공 잡티 솜털",
          "바이브코딩",
          "불쾌한 골짜기",
          "제미나이 ai"
        ],
        "isoDate": "2026-01-24T13:04:43.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "이더넷 케이블 내부와 외부 색상 코드, 당신이 몰랐던 진짜 의미는?",
        "link": "https://muzbox.tistory.com/483703",
        "pubDate": "Thu, 22 Jan 2026 10:50:31 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "https://muzbox.tistory.com/483703#entry483703comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #3c4043;\">\n<div style=\"background-color: #e8f4fd; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">이더넷 케이블, 겉모습은 다 같아 보이지만 사실은 색상별로 숨겨진 의미가 있다는 사실, 알고 계셨나요? 흔히 성능이나 속도를 나타낸다고 오해하기 쉽지만, 이 색상 코드에는 우리가 미처 몰랐던 진짜 활용법과 네트워크 관리의 비밀이 숨어있습니다. 오늘은 이더넷 케이블의 외부 재킷 색상부터 내부 전선의 복잡한 색상 코드까지, 그 흥미로운 세계를 함께 탐험해볼까 합니다. 과연 색상들이 어떤 역할을 하는지, 또 어떤 점에 주의해야 하는지 최신 정보를 바탕으로 자세히 알아볼게요!</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/q9yaQ/dJMcahXwh0Y/II8LKF2VBknAWIFkITXMS1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/q9yaQ/dJMcahXwh0Y/II8LKF2VBknAWIFkITXMS1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/q9yaQ/dJMcahXwh0Y/II8LKF2VBknAWIFkITXMS1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fq9yaQ%2FdJMcahXwh0Y%2FII8LKF2VBknAWIFkITXMS1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"다양한 색상의 이더넷 케이블과 내부 전선 색상 코드가 보이는 RJ45 커넥터, 네트워크 구성의 복잡성과 효율성을 나타내는 이미지.\" loading=\"lazy\" width=\"500\" height=\"500\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>이더넷 케이블 외부 색상, 그 진짜 의미는?  </b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">음, 우리가 흔히 보는 이더넷 케이블들, 그냥 다 똑같이 생겼다고 생각하셨을 거예요. 파란색, 노란색, 빨간색, 초록색, 회색 심지어 분홍색까지 다양하게 있긴 하지만, 사실 그냥 예쁘라고 만든 건 아니거든요. 많은 분들이 USB 포트 색깔처럼 속도나 성능을 나타내는 게 아닐까 오해하시곤 하는데, <b>그건 정말 아니에요.</b> 이 케이블 색상들은 단순히 시각적인 요소도 아니고, 성능과도 전혀 무관하답니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">그렇다면 왜 이렇게 다양한 색깔이 존재할까요? 바로 <b>\"조직화\"와 \"명확성\"</b> 때문입니다. 상상해보세요. 복잡한 데이터 센터나 사무실에서 수백 가닥의 케이블이 얽혀있는 모습을요. 그때 특정 색깔의 케이블이 어떤 용도로 쓰이는지 한눈에 파악할 수 있다면 얼마나 편리할까요?</p>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>잠깐!</b> 여기서 말하는 색상 코드는 케이블 외부 재킷의 색깔을 의미합니다. 케이블 내부에 꼬여있는 전선들의 색상 코드는 연결성과 신호 전송에 매우 중요한 역할을 하는데, 이건 나중에 따로 자세히 이야기해 드릴게요. 착각하시면 안 돼요!</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">대규모 네트워크 환경에서는 말할 것도 없고요, 집에서도 유용해요. 여러분의 라우터, 스위치, 모뎀 연결에 각기 다른 색상의 케이블을 사용하면, 갑자기 네트워크가 안 될 때 문제의 원인을 훨씬 쉽게 찾아낼 수 있답니다. 정말 작은 차이 같지만, 실제로 써보면 엄청난 편리함을 가져다주죠.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 외에도 제조사들은 케이블 카테고리(예: Cat 5, Cat 6, Cat 7)를 구분하거나, 케이블 길이, 심지어는 설치 연도(예: 2025년 설치는 파란색, 2026년 설치는 노란색)를 나타내는 데 색상을 활용하기도 합니다. 결국, 케이블 색상은 작업과 유지보수를 더 빠르고 덜 헷갈리게 만드는 데 큰 도움을 준다고 볼 수 있어요. 성능에 영향을 주진 않지만, 네트워크 관리의 효율성에는 지대한 영향을 끼치는 거죠.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>주요 색상별 용도, 과연 정해진 규칙이 있을까?  </b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">자, 그렇다면 각 색상들이 정확히 어떤 의미를 가지고 있을까요? 음&hellip; 사실은 <b>정해진 \"만국 공통\" 표준은 없어요.</b> 이 점이 좀 중요합니다. 케이블 색상의 의미는 특정 조직, 공급업체 또는 설치자가 어떻게 사용하기로 결정했는지에 따라 전적으로 달라질 수 있어요. 하지만 제가 겪어본 바로는, 몇 가지 흔한 패턴은 분명히 존재합니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px;\"><b>  파란색:</b> 대부분 표준 네트워크 연결에 사용돼요. 데스크톱 컴퓨터, 노트북 독, 사무실 프린터 등을 네트워크 스위치나 라우터에 연결할 때 말이죠. 가장 보편적이죠!</li>\n<li style=\"margin-bottom: 10px;\"><b>  노란색:</b> PoE(Power over Ethernet) 장치에 자주 사용됩니다. IP 보안 카메라, VoIP 전화, 무선 액세스 포인트처럼 케이블 자체에서 전력을 공급받는 장치들이요.</li>\n<li style=\"margin-bottom: 10px;\"><b>⬛ 검은색 또는 회색:</b> 사무실이나 가정에서 일상적인 연결에 많이 쓰입니다. 라우터를 모뎀에 연결하거나, 게임 콘솔을 네트워크 스위치에 연결하는 경우처럼요. 저도 집에서 주로 회색 케이블을 쓰고 있어요.</li>\n<li style=\"margin-bottom: 10px;\"><b>  빨간색:</b> 이건 정말 중요한 연결에만 사용되는 경우가 많습니다. 서버, 방화벽, 비상 백업 시스템처럼 절대로 연결이 끊기면 안 되는 곳에요. 때로는 제한되거나 보안이 강화된 네트워크 구간을 나타내기도 해요.</li>\n<li style=\"margin-bottom: 10px;\"><b>  녹색:</b> 크로스오버 연결(두 개의 유사한 장치를 직접 연결할 때, 예: 스위치-스위치 또는 컴퓨터-컴퓨터)이나 스마트 온도 조절기, 빌딩 제어 시스템 같은 환경 시스템에 사용되기도 합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>  주황색 또는   보라색:</b> 비교적 드물지만, 테스트 환경, 외부 연결, 게스트나 계약자를 위한 VLAN 세그먼트와 같은 특별한 네트워크 기능에 사용될 수 있어요.</li>\n</ul>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/zRH0b/dJMcafZFCOz/bkGoodPmczp6zoyijKPuj1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/zRH0b/dJMcafZFCOz/bkGoodPmczp6zoyijKPuj1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/zRH0b/dJMcafZFCOz/bkGoodPmczp6zoyijKPuj1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FzRH0b%2FdJMcafZFCOz%2FbkGoodPmczp6zoyijKPuj1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"여러 색상의 이더넷 케이블이 깔끔하게 정리된 서버 랙, 효율적인 네트워크 관리를 시각적으로 보여주는 이미지.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<div style=\"background-color: #fce8e6; border-left: 4px solid #d93025; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">⚠️ <b>경고!</b> 다시 한번 강조하지만, 위에 설명된 색상별 의미는 보편적인 표준이 아닙니다. 색상이 어떤 용도를 암시할 수는 있지만, 중요한 장비를 연결하거나 제거하기 전에는 <b>반드시 해당 케이블의 문서나 네트워크 관리자에게 확인</b>하는 것이 가장 안전합니다. 실수가 발생하면 큰 문제를 초래할 수 있으니까요.</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>케이블 성능? 색상 대신 '카테고리'에 주목하세요!  </b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">가장 중요한 포인트 중 하나인데요, 케이블 재킷의 색상은 해당 케이블의 <b>실제 성능과는 전혀 무관하다는 것</b>입니다. 이더넷 케이블은 <b>'카테고리'</b>로 분류되며, 각 카테고리는 특정 속도와 대역폭을 위해 설계되었어요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">예를 들어볼까요?</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px;\"><b>Cat 5e</b>는 최대 1Gbps의 속도를 지원하고요,</li>\n<li style=\"margin-bottom: 10px;\"><b>Cat 6a</b>는 더 긴 거리에서 최대 10Gbps까지 처리할 수 있습니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>Cat 8</b>은 대역폭의 헤비급 선수라고 할 수 있는데, 데이터 센터용으로 제작되어 짧은 거리에서는 최대 40Gbps까지 도달할 수 있어요. 정말 엄청난 속도죠!</li>\n</ul>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">그러니까, 화려한 분홍색 Cat 6 케이블이 칙칙한 회색 Cat 5e 케이블보다 훨씬 뛰어난 성능을 발휘할 수 있다는 이야기예요. 중요한 것은 케이블 옆면에 인쇄된 <b><b>'카테고리 등급'</b></b>이지, 겉으로 보이는 색상이 아니라는 점을 꼭 기억해주세요. 이 카테고리는 단순히 속도뿐만 아니라, 전기적 간섭으로부터 케이블을 얼마나 잘 보호하는지, 그리고 안정적이고 신뢰할 수 있는 연결을 얼마나 잘 유지하는지까지 정의한답니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 때문에 오래된 Cat 5 케이블을 Cat 6 또는 Cat 6a로 업그레이드하면 현대 네트워크 환경에서 확연한 성능 차이를 느낄 수 있어요. 제 경험상, 특히 고화질 스트리밍이나 대용량 파일 전송이 잦다면 체감 효과가 상당합니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/L6Ub0/dJMcafFn5v9/swUouL0Jd9yZxMI9XcxHm0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/L6Ub0/dJMcafFn5v9/swUouL0Jd9yZxMI9XcxHm0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/L6Ub0/dJMcafFn5v9/swUouL0Jd9yZxMI9XcxHm0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FL6Ub0%2FdJMcafFn5v9%2FswUouL0Jd9yZxMI9XcxHm0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"Cat 5e, Cat 6, Cat 8 등 다양한 이더넷 케이블의 카테고리 등급이 명확히 표시된 모습, 성능 분류의 중요성 강조.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>내부 전선 색상 코드는 왜 중요할까?  </b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">외부 재킷 색깔 이야기는 이제 충분히 한 것 같고, 그럼 이제 <b>케이블 '내부' 전선들의 색상 코드</b>로 넘어가 볼까요? 사실 여기가 진짜 중요합니다. 외부 색상이 그저 \"편의\"를 위한 것이었다면, 내부 전선의 색상 코드는 이더넷 케이블이 제대로 작동하기 위한 \"필수\" 요소예요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 내부 전선 색상 코드는 크게 두 가지 국제 표준으로 나뉘어요: <b>T568A</b>와 <b>T568B</b>입니다. 이 두 가지 표준은 8개의 내부 전선(4쌍의 꼬임선)을 RJ45 커넥터의 핀에 어떤 순서로 연결할지를 정의합니다. 이 순서가 틀어지면 네트워크 연결이 아예 안 되거나, 불안정해지죠.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">대부분의 상업용 및 주거용 건물에서는 T568B 표준을 사용하는 경우가 많지만, 오래된 건물이나 특정 환경에서는 T568A를 쓰기도 합니다. 중요한 건, 양쪽 끝 커넥터의 배열이 같아야 스트레이트(Straight-through) 케이블이 되고, 한쪽은 T568A, 다른 한쪽은 T568B로 배열해야 크로스오버(Crossover) 케이블이 된다는 점이에요. 크로스오버 케이블은 스위치 없이 두 대의 컴퓨터를 직접 연결하는 등 특정 상황에서만 사용됩니다.</p>\n<table style=\"width: 100%; border-collapse: collapse; margin: 25px 0; font-size: 15px; text-align: left; color: #3c4043;\" data-ke-align=\"alignLeft\">\n<thead style=\"background-color: #e8eaed;\">\n<tr>\n<th style=\"padding: 12px 15px; border: 1px solid #dadce0; color: #3c4043;\">핀 번호</th>\n<th style=\"padding: 12px 15px; border: 1px solid #dadce0; color: #3c4043;\">T568A 색상</th>\n<th style=\"padding: 12px 15px; border: 1px solid #dadce0; color: #3c4043;\">T568B 색상</th>\n</tr>\n</thead>\n<tbody>\n<tr style=\"background-color: #f8f9fa;\">\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">1</td>\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">흰-녹</td>\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">흰-주</td>\n</tr>\n<tr style=\"background-color: #f1f3f4;\">\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">2</td>\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">녹</td>\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">주</td>\n</tr>\n<tr style=\"background-color: #f8f9fa;\">\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">3</td>\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">흰-주</td>\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">흰-녹</td>\n</tr>\n<tr style=\"background-color: #f1f3f4;\">\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">4</td>\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">파</td>\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">파</td>\n</tr>\n<tr style=\"background-color: #f8f9fa;\">\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">5</td>\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">흰-파</td>\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">흰-파</td>\n</tr>\n<tr style=\"background-color: #f1f3f4;\">\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">6</td>\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">주</td>\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">녹</td>\n</tr>\n<tr style=\"background-color: #f8f9fa;\">\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">7</td>\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">흰-갈</td>\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">흰-갈</td>\n</tr>\n<tr style=\"background-color: #f1f3f4;\">\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">8</td>\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">갈</td>\n<td style=\"padding: 10px 15px; border: 1px solid #dadce0; color: #3c4043;\">갈</td>\n</tr>\n</tbody>\n</table>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">아, 그리고 잊지 말아야 할 게 하나 더 있어요. 내부 전선은 모두 꼬여있다는 사실입니다. 이렇게 꼬여있는 형태는 외부 간섭으로부터 신호 손실을 최소화하고 안정적인 통신을 가능하게 해요. 그래서 \"꼬임쌍선(Twisted Pair)\" 케이블이라고 불리는 거고요. 혹시 직접 이더넷 케이블을 만드실 기회가 있다면, 이 내부 색상 코드를 <b>정말 정말</b> 신중하게 맞춰야 합니다. 잘못 연결하면 정말 곤란해지거든요!</p>\n<div style=\"background-color: #f8f9fa; border: 1px solid #dadce0; border-radius: 8px; padding: 25px; margin: 30px 0; box-shadow: 0 4px 12px rgba(0,0,0,0.1);\">\n<div style=\"font-size: 26px; color: #1a73e8; font-weight: bold; margin-bottom: 15px; padding-bottom: 10px; border-bottom: 2px solid #1a73e8;\">  핵심 요약</div>\n<ul style=\"list-style: none; padding: 0; margin: 0;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 15px; font-size: 17px;\"><b>✅ 외부 색상은 성능과 무관:</b> 이더넷 케이블의 외부 재킷 색상은 속도나 성능이 아닌, 주로 '조직화'와 '식별'을 위한 도구입니다.</li>\n<li style=\"margin-bottom: 15px; font-size: 17px;\"><b>✅ 정해진 표준은 없음:</b> 외부 색상에 대한 보편적인 국제 표준은 없으며, 사용자의 재량이나 특정 조직의 규칙에 따라 의미가 달라질 수 있습니다.</li>\n<li style=\"margin-bottom: 15px; font-size: 17px;\"><b>✅ 성능은 '카테고리'가 결정:</b> 케이블의 실제 성능(속도, 대역폭, 안정성)은 Cat 5e, Cat 6, Cat 8과 같은 '카테고리 등급'에 의해 결정됩니다. 구매 시 반드시 이를 확인해야 해요.</li>\n<li style=\"margin-bottom: 0; font-size: 17px;\"><b>✅ 내부 색상 코드는 필수:</b> 케이블 내부의 꼬임쌍선 색상 코드(T568A/B)는 RJ45 커넥터 연결에 필수적이며, 네트워크 연결 안정성에 직접적인 영향을 미칩니다.</li>\n</ul>\n<div style=\"margin-top: 25px; padding-top: 15px; border-top: 1px solid #dadce0; font-size: 14px; color: #5f6368;\">이더넷 케이블 선택과 사용에 있어 색상이 주는 시각적 정보는 분명 도움이 되지만, 그 본질적인 역할과 성능 기준을 정확히 이해하는 것이 중요합니다.</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q1: 이더넷 케이블 색깔이 다르면 속도도 다른가요?</b><br />A1: 아니요, 이더넷 케이블의 외부 색상은 데이터 전송 속도나 성능과는 전혀 무관합니다. 색상은 주로 네트워크 관리의 편의를 위해 케이블의 용도를 구분하는 데 사용됩니다. 실제 속도와 성능은 'Cat(카테고리)' 등급(예: Cat 5e, Cat 6, Cat 8)에 따라 결정됩니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q2: T568A와 T568B는 무엇이며, 왜 중요한가요?</b><br />A2: T568A와 T568B는 이더넷 케이블 내부 꼬임쌍선의 RJ45 커넥터 연결 배열을 정의하는 두 가지 국제 표준입니다. 이 표준에 따라 정확하게 연결해야 데이터 신호가 올바르게 전송되고 안정적인 네트워크 연결이 가능합니다. 이 배열이 잘못되면 통신이 불가능해지거나 불안정해질 수 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q3: 집에서 이더넷 케이블을 고를 때 어떤 점을 봐야 하나요?</b><br />A3: 집에서 사용할 케이블을 고를 때는 외부 색상보다는 케이블의 '카테고리' 등급을 확인하는 것이 가장 중요합니다. 연결하려는 장비와 인터넷 속도에 맞춰 적절한 카테고리(예: 기가비트 인터넷에는 Cat 5e 이상, 더 높은 성능을 원하면 Cat 6 이상)를 선택하는 것이 좋습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q4: 오래된 Cat 5 케이블을 Cat 6로 바꾸면 효과가 있을까요?</b><br />A4: 네, 상당한 효과를 볼 수 있습니다. Cat 5는 최대 100Mbps를 지원하는 반면, Cat 6는 최대 1Gbps(Cat 6a는 10Gbps)를 지원하기 때문에, 기가비트 이상의 인터넷 환경을 사용하고 계시다면 Cat 6 이상의 케이블로 교체 시 네트워크 속도와 안정성 면에서 개선을 체감하실 수 있을 거예요.</p>\n</div>\n<script type=\"application/ld+json\">\n    {\n      \"@context\": \"https://schema.org\",\n      \"@type\": \"FAQPage\",\n      \"mainEntity\": [\n        {\n          \"@type\": \"Question\",\n          \"name\": \"이더넷 케이블 색깔이 다르면 속도도 다른가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"아니요, 이더넷 케이블의 외부 색상은 데이터 전송 속도나 성능과는 전혀 무관합니다. 색상은 주로 네트워크 관리의 편의를 위해 케이블의 용도를 구분하는 데 사용됩니다. 실제 속도와 성능은 'Cat(카테고리)' 등급(예: Cat 5e, Cat 6, Cat 8)에 따라 결정됩니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"T568A와 T568B는 무엇이며, 왜 중요한가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"T568A와 T568B는 이더넷 케이블 내부 꼬임쌍선의 RJ45 커넥터 연결 배열을 정의하는 두 가지 국제 표준입니다. 이 표준에 따라 정확하게 연결해야 데이터 신호가 올바르게 전송되고 안정적인 네트워크 연결이 가능합니다. 이 배열이 잘못되면 통신이 불가능해지거나 불안정해질 수 있습니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"집에서 이더넷 케이블을 고를 때 어떤 점을 봐야 하나요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"집에서 사용할 케이블을 고를 때는 외부 색상보다는 케이블의 '카테고리' 등급을 확인하는 것이 가장 중요합니다. 연결하려는 장비와 인터넷 속도에 맞춰 적절한 카테고리(예: 기가비트 인터넷에는 Cat 5e 이상, 더 높은 성능을 원하면 Cat 6 이상)를 선택하는 것이 좋습니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"오래된 Cat 5 케이블을 Cat 6로 바꾸면 효과가 있을까요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"네, 상당한 효과를 볼 수 있습니다. Cat 5는 최대 100Mbps를 지원하는 반면, Cat 6는 최대 1Gbps(Cat 6a는 10Gbps)를 지원하기 때문에, 기가비트 이상의 인터넷 환경을 사용하고 계시다면 Cat 6 이상의 케이블로 교체 시 네트워크 속도와 안정성 면에서 개선을 체감하실 수 있을 거예요.\"\n          }\n        }\n      ]\n    }\n    </script>",
        "contentSnippet": "이더넷 케이블, 겉모습은 다 같아 보이지만 사실은 색상별로 숨겨진 의미가 있다는 사실, 알고 계셨나요? 흔히 성능이나 속도를 나타낸다고 오해하기 쉽지만, 이 색상 코드에는 우리가 미처 몰랐던 진짜 활용법과 네트워크 관리의 비밀이 숨어있습니다. 오늘은 이더넷 케이블의 외부 재킷 색상부터 내부 전선의 복잡한 색상 코드까지, 그 흥미로운 세계를 함께 탐험해볼까 합니다. 과연 색상들이 어떤 역할을 하는지, 또 어떤 점에 주의해야 하는지 최신 정보를 바탕으로 자세히 알아볼게요!\n\n\n이더넷 케이블 외부 색상, 그 진짜 의미는?  \n음, 우리가 흔히 보는 이더넷 케이블들, 그냥 다 똑같이 생겼다고 생각하셨을 거예요. 파란색, 노란색, 빨간색, 초록색, 회색 심지어 분홍색까지 다양하게 있긴 하지만, 사실 그냥 예쁘라고 만든 건 아니거든요. 많은 분들이 USB 포트 색깔처럼 속도나 성능을 나타내는 게 아닐까 오해하시곤 하는데, 그건 정말 아니에요. 이 케이블 색상들은 단순히 시각적인 요소도 아니고, 성능과도 전혀 무관하답니다.\n그렇다면 왜 이렇게 다양한 색깔이 존재할까요? 바로 \"조직화\"와 \"명확성\" 때문입니다. 상상해보세요. 복잡한 데이터 센터나 사무실에서 수백 가닥의 케이블이 얽혀있는 모습을요. 그때 특정 색깔의 케이블이 어떤 용도로 쓰이는지 한눈에 파악할 수 있다면 얼마나 편리할까요?\n  잠깐! 여기서 말하는 색상 코드는 케이블 외부 재킷의 색깔을 의미합니다. 케이블 내부에 꼬여있는 전선들의 색상 코드는 연결성과 신호 전송에 매우 중요한 역할을 하는데, 이건 나중에 따로 자세히 이야기해 드릴게요. 착각하시면 안 돼요!\n대규모 네트워크 환경에서는 말할 것도 없고요, 집에서도 유용해요. 여러분의 라우터, 스위치, 모뎀 연결에 각기 다른 색상의 케이블을 사용하면, 갑자기 네트워크가 안 될 때 문제의 원인을 훨씬 쉽게 찾아낼 수 있답니다. 정말 작은 차이 같지만, 실제로 써보면 엄청난 편리함을 가져다주죠.\n이 외에도 제조사들은 케이블 카테고리(예: Cat 5, Cat 6, Cat 7)를 구분하거나, 케이블 길이, 심지어는 설치 연도(예: 2025년 설치는 파란색, 2026년 설치는 노란색)를 나타내는 데 색상을 활용하기도 합니다. 결국, 케이블 색상은 작업과 유지보수를 더 빠르고 덜 헷갈리게 만드는 데 큰 도움을 준다고 볼 수 있어요. 성능에 영향을 주진 않지만, 네트워크 관리의 효율성에는 지대한 영향을 끼치는 거죠.\n주요 색상별 용도, 과연 정해진 규칙이 있을까?  \n자, 그렇다면 각 색상들이 정확히 어떤 의미를 가지고 있을까요? 음… 사실은 정해진 \"만국 공통\" 표준은 없어요. 이 점이 좀 중요합니다. 케이블 색상의 의미는 특정 조직, 공급업체 또는 설치자가 어떻게 사용하기로 결정했는지에 따라 전적으로 달라질 수 있어요. 하지만 제가 겪어본 바로는, 몇 가지 흔한 패턴은 분명히 존재합니다.\n  파란색: 대부분 표준 네트워크 연결에 사용돼요. 데스크톱 컴퓨터, 노트북 독, 사무실 프린터 등을 네트워크 스위치나 라우터에 연결할 때 말이죠. 가장 보편적이죠!\n  노란색: PoE(Power over Ethernet) 장치에 자주 사용됩니다. IP 보안 카메라, VoIP 전화, 무선 액세스 포인트처럼 케이블 자체에서 전력을 공급받는 장치들이요.\n⬛ 검은색 또는 회색: 사무실이나 가정에서 일상적인 연결에 많이 쓰입니다. 라우터를 모뎀에 연결하거나, 게임 콘솔을 네트워크 스위치에 연결하는 경우처럼요. 저도 집에서 주로 회색 케이블을 쓰고 있어요.\n  빨간색: 이건 정말 중요한 연결에만 사용되는 경우가 많습니다. 서버, 방화벽, 비상 백업 시스템처럼 절대로 연결이 끊기면 안 되는 곳에요. 때로는 제한되거나 보안이 강화된 네트워크 구간을 나타내기도 해요.\n  녹색: 크로스오버 연결(두 개의 유사한 장치를 직접 연결할 때, 예: 스위치-스위치 또는 컴퓨터-컴퓨터)이나 스마트 온도 조절기, 빌딩 제어 시스템 같은 환경 시스템에 사용되기도 합니다.\n  주황색 또는   보라색: 비교적 드물지만, 테스트 환경, 외부 연결, 게스트나 계약자를 위한 VLAN 세그먼트와 같은 특별한 네트워크 기능에 사용될 수 있어요.\n\n\n⚠️ 경고! 다시 한번 강조하지만, 위에 설명된 색상별 의미는 보편적인 표준이 아닙니다. 색상이 어떤 용도를 암시할 수는 있지만, 중요한 장비를 연결하거나 제거하기 전에는 반드시 해당 케이블의 문서나 네트워크 관리자에게 확인하는 것이 가장 안전합니다. 실수가 발생하면 큰 문제를 초래할 수 있으니까요.\n케이블 성능? 색상 대신 '카테고리'에 주목하세요!  \n가장 중요한 포인트 중 하나인데요, 케이블 재킷의 색상은 해당 케이블의 실제 성능과는 전혀 무관하다는 것입니다. 이더넷 케이블은 '카테고리'로 분류되며, 각 카테고리는 특정 속도와 대역폭을 위해 설계되었어요.\n예를 들어볼까요?\nCat 5e는 최대 1Gbps의 속도를 지원하고요,\nCat 6a는 더 긴 거리에서 최대 10Gbps까지 처리할 수 있습니다.\nCat 8은 대역폭의 헤비급 선수라고 할 수 있는데, 데이터 센터용으로 제작되어 짧은 거리에서는 최대 40Gbps까지 도달할 수 있어요. 정말 엄청난 속도죠!\n그러니까, 화려한 분홍색 Cat 6 케이블이 칙칙한 회색 Cat 5e 케이블보다 훨씬 뛰어난 성능을 발휘할 수 있다는 이야기예요. 중요한 것은 케이블 옆면에 인쇄된 '카테고리 등급'이지, 겉으로 보이는 색상이 아니라는 점을 꼭 기억해주세요. 이 카테고리는 단순히 속도뿐만 아니라, 전기적 간섭으로부터 케이블을 얼마나 잘 보호하는지, 그리고 안정적이고 신뢰할 수 있는 연결을 얼마나 잘 유지하는지까지 정의한답니다.\n이 때문에 오래된 Cat 5 케이블을 Cat 6 또는 Cat 6a로 업그레이드하면 현대 네트워크 환경에서 확연한 성능 차이를 느낄 수 있어요. 제 경험상, 특히 고화질 스트리밍이나 대용량 파일 전송이 잦다면 체감 효과가 상당합니다.\n\n\n내부 전선 색상 코드는 왜 중요할까?  \n외부 재킷 색깔 이야기는 이제 충분히 한 것 같고, 그럼 이제 케이블 '내부' 전선들의 색상 코드로 넘어가 볼까요? 사실 여기가 진짜 중요합니다. 외부 색상이 그저 \"편의\"를 위한 것이었다면, 내부 전선의 색상 코드는 이더넷 케이블이 제대로 작동하기 위한 \"필수\" 요소예요.\n이 내부 전선 색상 코드는 크게 두 가지 국제 표준으로 나뉘어요: T568A와 T568B입니다. 이 두 가지 표준은 8개의 내부 전선(4쌍의 꼬임선)을 RJ45 커넥터의 핀에 어떤 순서로 연결할지를 정의합니다. 이 순서가 틀어지면 네트워크 연결이 아예 안 되거나, 불안정해지죠.\n대부분의 상업용 및 주거용 건물에서는 T568B 표준을 사용하는 경우가 많지만, 오래된 건물이나 특정 환경에서는 T568A를 쓰기도 합니다. 중요한 건, 양쪽 끝 커넥터의 배열이 같아야 스트레이트(Straight-through) 케이블이 되고, 한쪽은 T568A, 다른 한쪽은 T568B로 배열해야 크로스오버(Crossover) 케이블이 된다는 점이에요. 크로스오버 케이블은 스위치 없이 두 대의 컴퓨터를 직접 연결하는 등 특정 상황에서만 사용됩니다.\n핀 번호\nT568A 색상\nT568B 색상\n\n\n\n\n1\n흰-녹\n흰-주\n\n\n2\n녹\n주\n\n\n3\n흰-주\n흰-녹\n\n\n4\n파\n파\n\n\n5\n흰-파\n흰-파\n\n\n6\n주\n녹\n\n\n7\n흰-갈\n흰-갈\n\n\n8\n갈\n갈\n\n\n\n아, 그리고 잊지 말아야 할 게 하나 더 있어요. 내부 전선은 모두 꼬여있다는 사실입니다. 이렇게 꼬여있는 형태는 외부 간섭으로부터 신호 손실을 최소화하고 안정적인 통신을 가능하게 해요. 그래서 \"꼬임쌍선(Twisted Pair)\" 케이블이라고 불리는 거고요. 혹시 직접 이더넷 케이블을 만드실 기회가 있다면, 이 내부 색상 코드를 정말 정말 신중하게 맞춰야 합니다. 잘못 연결하면 정말 곤란해지거든요!\n  핵심 요약\n✅ 외부 색상은 성능과 무관: 이더넷 케이블의 외부 재킷 색상은 속도나 성능이 아닌, 주로 '조직화'와 '식별'을 위한 도구입니다.\n✅ 정해진 표준은 없음: 외부 색상에 대한 보편적인 국제 표준은 없으며, 사용자의 재량이나 특정 조직의 규칙에 따라 의미가 달라질 수 있습니다.\n✅ 성능은 '카테고리'가 결정: 케이블의 실제 성능(속도, 대역폭, 안정성)은 Cat 5e, Cat 6, Cat 8과 같은 '카테고리 등급'에 의해 결정됩니다. 구매 시 반드시 이를 확인해야 해요.\n✅ 내부 색상 코드는 필수: 케이블 내부의 꼬임쌍선 색상 코드(T568A/B)는 RJ45 커넥터 연결에 필수적이며, 네트워크 연결 안정성에 직접적인 영향을 미칩니다.\n이더넷 케이블 선택과 사용에 있어 색상이 주는 시각적 정보는 분명 도움이 되지만, 그 본질적인 역할과 성능 기준을 정확히 이해하는 것이 중요합니다.\n❓ 자주 묻는 질문 (FAQ)\nQ1: 이더넷 케이블 색깔이 다르면 속도도 다른가요?\nA1: 아니요, 이더넷 케이블의 외부 색상은 데이터 전송 속도나 성능과는 전혀 무관합니다. 색상은 주로 네트워크 관리의 편의를 위해 케이블의 용도를 구분하는 데 사용됩니다. 실제 속도와 성능은 'Cat(카테고리)' 등급(예: Cat 5e, Cat 6, Cat 8)에 따라 결정됩니다.\nQ2: T568A와 T568B는 무엇이며, 왜 중요한가요?\nA2: T568A와 T568B는 이더넷 케이블 내부 꼬임쌍선의 RJ45 커넥터 연결 배열을 정의하는 두 가지 국제 표준입니다. 이 표준에 따라 정확하게 연결해야 데이터 신호가 올바르게 전송되고 안정적인 네트워크 연결이 가능합니다. 이 배열이 잘못되면 통신이 불가능해지거나 불안정해질 수 있습니다.\nQ3: 집에서 이더넷 케이블을 고를 때 어떤 점을 봐야 하나요?\nA3: 집에서 사용할 케이블을 고를 때는 외부 색상보다는 케이블의 '카테고리' 등급을 확인하는 것이 가장 중요합니다. 연결하려는 장비와 인터넷 속도에 맞춰 적절한 카테고리(예: 기가비트 인터넷에는 Cat 5e 이상, 더 높은 성능을 원하면 Cat 6 이상)를 선택하는 것이 좋습니다.\nQ4: 오래된 Cat 5 케이블을 Cat 6로 바꾸면 효과가 있을까요?\nA4: 네, 상당한 효과를 볼 수 있습니다. Cat 5는 최대 100Mbps를 지원하는 반면, Cat 6는 최대 1Gbps(Cat 6a는 10Gbps)를 지원하기 때문에, 기가비트 이상의 인터넷 환경을 사용하고 계시다면 Cat 6 이상의 케이블로 교체 시 네트워크 속도와 안정성 면에서 개선을 체감하실 수 있을 거예요.\n\n\n    {\n      \"@context\": \"https://schema.org\",\n      \"@type\": \"FAQPage\",\n      \"mainEntity\": [\n        {\n          \"@type\": \"Question\",\n          \"name\": \"이더넷 케이블 색깔이 다르면 속도도 다른가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"아니요, 이더넷 케이블의 외부 색상은 데이터 전송 속도나 성능과는 전혀 무관합니다. 색상은 주로 네트워크 관리의 편의를 위해 케이블의 용도를 구분하는 데 사용됩니다. 실제 속도와 성능은 'Cat(카테고리)' 등급(예: Cat 5e, Cat 6, Cat 8)에 따라 결정됩니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"T568A와 T568B는 무엇이며, 왜 중요한가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"T568A와 T568B는 이더넷 케이블 내부 꼬임쌍선의 RJ45 커넥터 연결 배열을 정의하는 두 가지 국제 표준입니다. 이 표준에 따라 정확하게 연결해야 데이터 신호가 올바르게 전송되고 안정적인 네트워크 연결이 가능합니다. 이 배열이 잘못되면 통신이 불가능해지거나 불안정해질 수 있습니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"집에서 이더넷 케이블을 고를 때 어떤 점을 봐야 하나요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"집에서 사용할 케이블을 고를 때는 외부 색상보다는 케이블의 '카테고리' 등급을 확인하는 것이 가장 중요합니다. 연결하려는 장비와 인터넷 속도에 맞춰 적절한 카테고리(예: 기가비트 인터넷에는 Cat 5e 이상, 더 높은 성능을 원하면 Cat 6 이상)를 선택하는 것이 좋습니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"오래된 Cat 5 케이블을 Cat 6로 바꾸면 효과가 있을까요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"네, 상당한 효과를 볼 수 있습니다. Cat 5는 최대 100Mbps를 지원하는 반면, Cat 6는 최대 1Gbps(Cat 6a는 10Gbps)를 지원하기 때문에, 기가비트 이상의 인터넷 환경을 사용하고 계시다면 Cat 6 이상의 케이블로 교체 시 네트워크 속도와 안정성 면에서 개선을 체감하실 수 있을 거예요.\"\n          }\n        }\n      ]\n    }",
        "guid": "https://muzbox.tistory.com/483703",
        "categories": [
          "윈도우 사용팁/하드웨어",
          "Cat 5e",
          "Cat 6",
          "Cat 8",
          "PoE 케이블",
          "RJ45",
          "T568A",
          "T568B",
          "네트워크 케이블",
          "랜선 속도",
          "이더넷 케이블 색상"
        ],
        "isoDate": "2026-01-22T01:50:31.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "AI는 거창한 기술이 아니다? 우리가 미처 몰랐던 생활 속 인공지능의 진짜 얼굴",
        "link": "https://muzbox.tistory.com/483702",
        "pubDate": "Wed, 21 Jan 2026 12:22:39 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "https://muzbox.tistory.com/483702#entry483702comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #424242;\">\n<div style=\"background-color: #fbe9e7; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">우리가 모르는 사이에 우리 삶 깊숙이 파고든 인공지능. 챗GPT 같은 거창한 기술만 AI라고 생각하셨나요? 사실은 스마트폰, 스트리밍 서비스, 심지어 우리 집 가전제품까지, 인공지능은 매일매일 우리 곁에서 삶을 더 편리하고 윤택하게 만들고 있답니다. 2026년, 인공지능의 진짜 얼굴을 만나볼까요?</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">요즘 인공지능(AI)이라는 단어를 빼놓고 이야기하기는 정말 어려운 것 같아요. 거리를 걷다 보면 AI 관련 광고가 눈에 띄고, 스마트폰을 켜면 AI 기반 앱이 가득하죠. 하지만 많은 분들이 AI를 아직도 영화 속 로봇이나 복잡한 미래 기술로만 생각하시는 경향이 있는 것 같아요. 솔직히 저도 그랬거든요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">그런데 말이죠, 곰곰이 생각해보면 AI는 이미 우리 일상에 너무나 자연스럽게 스며들어 있습니다. 우리는 의식하지 못하는 사이에 AI의 도움을 받으며 살아가고 있어요. 마치 공기처럼 말이죠. 오늘은 2026년 현재, 우리가 미처 몰랐던 생활 속 인공지능의 진짜 모습을 파헤쳐보고, AI가 어떻게 우리의 삶을 더 쉽고 즐겁게 만드는지 이야기해보려 합니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/bES4Q5/dJMcafyBH2d/rFkW69ueFoJvNrk2oB1751/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bES4Q5/dJMcafyBH2d/rFkW69ueFoJvNrk2oB1751/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bES4Q5/dJMcafyBH2d/rFkW69ueFoJvNrk2oB1751/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbES4Q5%2FdJMcafyBH2d%2FrFkW69ueFoJvNrk2oB1751%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"스마트 스피커와 태블릿, 스트리밍 TV 등 다양한 기기 속에서 일상생활에 자연스럽게 녹아든 인공지능의 모습\" loading=\"lazy\" width=\"500\" height=\"500\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #e57373, #c62828); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  우리 곁에 너무나 당연한 존재, 스마트 비서</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">아침에 눈을 뜨자마자 날씨를 묻고, 커피 머신을 켜달라고 말하고, 좋아하는 음악을 틀어달라고 요청하는 경험, 혹시 있으신가요? 바로 스마트 스피커나 스마트폰의 <b>음성 비서</b>를 통해 이루어지는 일이죠. 구글 어시스턴트, 애플 시리, 삼성 빅스비, 아마존 알렉사 등은 이제 우리에게 너무나 익숙한 이름이 되었습니다. 사실 이들이 바로 인공지능의 대표적인 예시라는 것을 아셨나요?</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 스마트 비서들은 단순히 명령을 수행하는 것을 넘어, 우리의 음성을 인식하고, 질문의 의도를 파악하며, 방대한 데이터를 기반으로 적절한 답변이나 서비스를 제공합니다. 예를 들어, &ldquo;오늘 저녁 메뉴 추천해 줘&rdquo;라고 물으면, 우리의 과거 검색 기록이나 즐겨찾는 레시피를 분석해서 개인화된 추천을 해주는 식이죠. 저는 아침마다 알렉사에게 오늘의 뉴스를 요약해달라고 요청하는데, 출근 준비를 하면서 세상 소식을 한 번에 들을 수 있어서 정말 편리해요. 이건 단순한 기술이 아니라, 제 패턴을 학습하고 저에게 맞춰주는 AI의 능력 덕분이라고 생각합니다.</p>\n<div style=\"background-color: #fbe9e7; border-left: 4px solid #ff8a65; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>2014년 아마존 에코 출시</b> 이후, 스마트 스피커는 놀라운 속도로 우리 일상에 자리 잡았습니다. 이제는 거의 모든 스마트홈 기기와 연동되어 집 안의 허브 역할을 톡톡히 하고 있죠.</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/Ur4W9/dJMcafSVqkn/aix60de4KQMj8p14GcTxe0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/Ur4W9/dJMcafSVqkn/aix60de4KQMj8p14GcTxe0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/Ur4W9/dJMcafSVqkn/aix60de4KQMj8p14GcTxe0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FUr4W9%2FdJMcafSVqkn%2Faix60de4KQMj8p14GcTxe0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"주방에서 스마트 스피커에게 아침 날씨를 묻고 있는 편안한 모습의 사람\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #e57373, #c62828); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✍️ 궁금증 해결사부터 창작 도구까지, LLM의 변신</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">최근 몇 년간 가장 뜨거웠던 AI 분야를 꼽으라면 단연 <b>대규모 언어 모델(LLM) 기반의 챗봇</b>일 거예요. 챗GPT, 구글 제미니, 마이크로소프트 코파일럿 등 다양한 서비스들이 쏟아져 나오면서 정보 탐색 방식 자체를 바꿔버렸죠.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">옛날에는 어떤 정보가 궁금하면 백과사전을 뒤지거나 도서관에 가서 책을 찾아봐야 했죠. 인터넷 시대가 열리면서 검색 엔진으로 빠르게 정보를 찾을 수 있게 되었지만, 여전히 수많은 검색 결과 중에서 필요한 정보를 선별하는 건 우리의 몫이었어요. 하지만 지금은 어떤가요? 챗봇에게 질문 하나만 던지면, 인터넷의 방대한 정보를 순식간에 요약하고 정리해서 우리에게 필요한 답을 딱! 제시해줍니다. 심지어 복잡한 질문에 대한 여러 가지 관점이나 대안까지도 보여주니, 정말 놀랍지 않나요?</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">저는 최근에 인테리어를 고민하면서 챗봇의 도움을 많이 받았어요. 거실에 어떤 색깔의 소파가 어울릴지, 혹은 특정 공간에 어떤 식물을 놓으면 좋을지 막연하게 생각만 하고 있었거든요. 챗봇에게 &ldquo;우리 집 거실 사진을 보여주며 이 공간에 어울리는 현대적인 소파 디자인을 추천해줘&rdquo;라고 입력했더니, 몇 초 만에 여러 가지 시안을 이미지로 생성해주더라고요. 또, &ldquo;이런 스타일의 소파를 파는 믿을 수 있는 국내 가구 업체 3곳을 추천해줘&rdquo;라고 요청하니, 관련 정보를 요약해서 보여주기도 했습니다. 덕분에 시행착오를 줄이고 시간과 비용을 절약할 수 있었죠. 이런 경험을 해보면 AI가 더 이상 거창한 기술이 아니라, 삶의 질을 높여주는 똑똑한 비서라는 것을 절감하게 됩니다.</p>\n<div style=\"background-color: #fff3e0; border-left: 4px solid #ffa726; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">⚠️ 챗봇의 답변은 항상 100% 정확한 것은 아닐 수 있습니다. 중요한 정보를 얻을 때는 <b>교차 검증</b>하는 습관을 들이는 것이 좋습니다.</div>\n<h3 style=\"font-size: 19px; color: #c62828; margin: 25px 0 10px; padding-left: 10px; border-left: 3px solid #e57373;\" data-ke-size=\"size23\"><b>LLM이 바꿔놓은 정보 탐색의 패러다임</b></h3>\n<table style=\"width: 100%; border-collapse: collapse; margin-bottom: 20px; color: #424242;\" data-ke-align=\"alignLeft\">\n<thead>\n<tr style=\"background-color: #eeeeee;\">\n<th style=\"border: 1px solid #e0e0e0; padding: 10px; text-align: left; color: #424242;\">항목</th>\n<th style=\"border: 1px solid #e0e0e0; padding: 10px; text-align: left; color: #424242;\">전통적 방식 (인터넷 이전)</th>\n<th style=\"border: 1px solid #e0e0e0; padding: 10px; text-align: left; color: #424242;\">검색 엔진 (인터넷 초기)</th>\n<th style=\"border: 1px solid #e0e0e0; padding: 10px; text-align: left; color: #424242;\">AI 챗봇 (2026년 현재)</th>\n</tr>\n</thead>\n<tbody>\n<tr style=\"background-color: #fafafa;\">\n<td style=\"border: 1px solid #e0e0e0; padding: 10px; color: #424242;\">정보 획득 방식</td>\n<td style=\"border: 1px solid #e0e0e0; padding: 10px; color: #424242;\">백과사전, 책, 전문가 질문</td>\n<td style=\"border: 1px solid #e0e0e0; padding: 10px; color: #424242;\">키워드 검색, 웹사이트 방문</td>\n<td style=\"border: 1px solid #e0e0e0; padding: 10px; color: #424242;\">자연어 질문, 종합 요약 및 생성</td>\n</tr>\n<tr style=\"background-color: #f5f5f5;\">\n<td style=\"border: 1px solid #e0e0e0; padding: 10px; color: #424242;\">정보 선별 시간</td>\n<td style=\"border: 1px solid #e0e0e0; padding: 10px; color: #424242;\">오래 걸림 (수동 작업)</td>\n<td style=\"border: 1px solid #e0e0e0; padding: 10px; color: #424242;\">비교적 빠르나 사용자 노력 필요</td>\n<td style=\"border: 1px solid #e0e0e0; padding: 10px; color: #424242;\">매우 빠름 (AI 자동 선별)</td>\n</tr>\n<tr style=\"background-color: #fafafa;\">\n<td style=\"border: 1px solid #e0e0e0; padding: 10px; color: #424242;\">개인화 수준</td>\n<td style=\"border: 1px solid #e0e0e0; padding: 10px; color: #424242;\">낮음</td>\n<td style=\"border: 1px solid #e0e0e0; padding: 10px; color: #424242;\">중간 (검색 기록 기반)</td>\n<td style=\"border: 1px solid #e0e0e0; padding: 10px; color: #424242;\">높음 (대화형 맞춤 정보)</td>\n</tr>\n</tbody>\n</table>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/bALKbe/dJMcaia2dRC/xYlZ1JmGUjyko8D8g6Mirk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bALKbe/dJMcaia2dRC/xYlZ1JmGUjyko8D8g6Mirk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bALKbe/dJMcaia2dRC/xYlZ1JmGUjyko8D8g6Mirk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbALKbe%2FdJMcaia2dRC%2FxYlZ1JmGUjyko8D8g6Mirk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"태블릿으로 챗봇에게 거실 인테리어 시안을 요청하며 집중하고 있는 사람\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #e57373, #c62828); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  넷플릭스만 봐도 알 수 있는 AI의 섬세한 취향 저격</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">하루를 마무리하며 편안하게 소파에 앉아 넷플릭스나 유튜브를 시청하는 것만큼 행복한 순간이 있을까요? 그런데 이 스트리밍 서비스들이 끊임없이 우리에게 &ldquo;OO님이 좋아할 만한 콘텐츠&rdquo;를 추천해주는 이유가 무엇인지 생각해보셨나요? 네, 맞아요. 여기에도 <b>인공지능</b>이 숨어있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">스트리밍 서비스의 AI는 우리가 어떤 장르의 영화를 즐겨 보는지, 어떤 배우나 감독에게 관심이 많은지, 시청하는 시간대는 언제인지 등 수많은 데이터를 분석해요. 그리고 이러한 패턴을 기반으로 우리가 좋아할 만한 콘텐츠를 예측하고 추천 리스트를 만들어줍니다. 처음 서비스를 시작할 때 취향을 묻는 질문부터, 우리가 콘텐츠를 시청하는 모든 순간이 AI 학습 데이터가 되는 셈이죠.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">솔직히 예전에는 TV 채널을 이리저리 돌리거나 비디오 가게에서 한참을 서성이다가 아무거나 빌려오는 경우가 많았잖아요. 그러다 재미없는 영화를 보면 시간 낭비라는 생각이 들기도 했고요. 하지만 이제는 AI 덕분에 그런 고민을 할 필요가 없어요. AI가 저의 취향에 딱 맞는 콘텐츠만 쏙쏙 골라주니, 시간을 절약할 수 있을 뿐만 아니라 매번 만족스러운 시청 경험을 할 수 있게 되는 거죠. 서비스 제공자 입장에서는 사용자가 플랫폼에 더 오래 머물고, 재결제할 확률이 높아지니 서로 윈-윈이 되는 효과라고 볼 수 있습니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/CnYcW/dJMcabiGp2a/vjWYxfn6oufZJwJjI8YCNK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/CnYcW/dJMcabiGp2a/vjWYxfn6oufZJwJjI8YCNK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/CnYcW/dJMcabiGp2a/vjWYxfn6oufZJwJjI8YCNK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FCnYcW%2FdJMcabiGp2a%2FvjWYxfn6oufZJwJjI8YCNK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"편안한 거실에서 스트리밍 서비스의 맞춤형 영화 추천을 보며 휴식하는 사람\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #e57373, #c62828); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  AI, 생각보다 훨씬 더 우리의 삶에 스며들었네요</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">스마트 비서, 챗봇, 스트리밍 추천 외에도 AI는 정말 다양한 방식으로 우리의 삶을 풍요롭게 하고 있습니다. 스마트폰 카메라의 얼굴 인식 기능, 은행 앱의 이상 금융 거래 감지, 온라인 쇼핑몰의 맞춤형 상품 추천, 심지어는 차량 내비게이션의 실시간 교통 분석까지, 우리가 인지하지 못하는 사이에도 AI는 조용히, 그러나 강력하게 작동하고 있어요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">물론, AI 기술의 발전이 항상 장밋빛 미래만을 의미하는 것은 아닙니다. 개인 정보 보호나 데이터 오남용, 딥페이크와 같은 윤리적인 문제들은 우리가 계속해서 논의하고 해결해나가야 할 숙제임은 분명해요. 하지만 이러한 우려에도 불구하고, AI가 우리 삶을 더 편리하고 효율적으로 만드는 긍정적인 측면이 훨씬 더 많다는 것을 부정하기는 어렵습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">솔직히 처음에는 저도 AI가 너무 어렵고, '거대한 기술'이라고만 생각했어요. 하지만 이렇게 매일매일 사용하는 기술들을 되짚어보니, AI는 우리의 삶을 '더 쉽게' 만들어주는 '친근한 도구'라는 사실을 깨달았습니다. 미래의 AI는 또 어떤 모습으로 우리를 놀라게 할지, 정말 기대되지 않나요?</p>\n<div style=\"background-color: #fafafa; border: 1px solid #e0e0e0; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); padding: 25px; margin: 40px 0;\">\n<div style=\"font-size: 26px; color: #e57373; font-weight: bold; margin-bottom: 15px; padding-bottom: 10px; border-bottom: 2px solid #e57373;\">  핵심 요약</div>\n<p style=\"font-size: 17px; margin-bottom: 10px; color: #424242;\" data-ke-size=\"size16\"><b>✅ AI는 스마트 비서처럼 이미 우리 일상에 깊이 스며들어 있습니다.</b></p>\n<p style=\"font-size: 17px; margin-bottom: 10px; color: #424242;\" data-ke-size=\"size16\"><b>✅ 챗봇은 정보 탐색을 넘어 창의적인 아이디어와 시각적 자료까지 제공합니다.</b></p>\n<p style=\"font-size: 17px; margin-bottom: 10px; color: #424242;\" data-ke-size=\"size16\"><b>✅ 스트리밍 서비스 추천은 AI가 우리의 취향을 섬세하게 분석한 결과입니다.</b></p>\n<p style=\"font-size: 17px; margin-bottom: 10px; color: #424242;\" data-ke-size=\"size16\"><b>✅ AI는 우리 삶을 더 편리하고 효율적으로 만드는 '친근한 도구'입니다.</b></p>\n<div style=\"font-size: 14px; color: #757375; margin-top: 20px; padding-top: 15px; border-top: 1px dashed #e0e0e0;\">AI는 우리의 생각보다 훨씬 가까이에 있습니다. 조금만 관심을 가지면 AI의 놀라운 잠재력을 더욱 효과적으로 활용할 수 있을 거예요.</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #e57373, #c62828); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<div style=\"margin-bottom: 15px; color: #424242;\">\n<p style=\"margin-bottom: 5px;\" data-ke-size=\"size16\"><b>Q1: 제가 매일 사용하는 것 중에 AI가 적용된 예시가 또 있을까요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A1: 네, 아주 많습니다! 스마트폰의 얼굴 인식 잠금 해제, 지도 앱의 최적 경로 안내, 온라인 쇼핑몰의 개인 맞춤 광고, 은행 앱의 사기 거래 탐지, 심지어는 이메일 스팸 필터링까지 모두 AI 기술이 적용된 예시입니다. 이처럼 AI는 우리 삶의 거의 모든 디지털 접점에서 활동하고 있어요.</p>\n</div>\n<div style=\"margin-bottom: 15px; color: #424242;\">\n<p style=\"margin-bottom: 5px;\" data-ke-size=\"size16\"><b>Q2: AI가 이렇게 일상에 스며들면 혹시 개인 정보는 안전한가요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A2: 개인 정보 보호는 AI 시대의 중요한 과제 중 하나입니다. 대부분의 AI 서비스 제공 기업들은 암호화, 익명화 등의 기술로 데이터를 보호하고 있지만, 사용자 스스로도 불필요한 정보 제공을 줄이고, 서비스 약관을 꼼꼼히 확인하는 습관을 들이는 것이 중요합니다. 정부와 기업들도 AI 윤리 및 개인 정보 보호를 위한 법규와 가이드라인을 강화하고 있습니다.</p>\n</div>\n<div style=\"margin-bottom: 15px; color: #424242;\">\n<p style=\"margin-bottom: 5px;\" data-ke-size=\"size16\"><b>Q3: 미래에는 AI가 어디까지 발전할 것이라고 예상하나요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A3: 2026년 현재를 기준으로 볼 때, AI는 더욱 개인화되고 맞춤화된 서비스로 발전할 것으로 예상됩니다. 예를 들어, 개인의 건강 데이터를 분석하여 맞춤형 식단이나 운동 프로그램을 제안하고, 교육 분야에서는 개개인의 학습 속도에 맞는 맞춤형 학습 콘텐츠를 제공하는 등 더욱 밀접하게 우리 삶의 질을 향상시키는 방향으로 진화할 것입니다. 또한, 자율주행, 로봇 공학 등 다양한 산업 분야에서 혁신을 가속화할 것으로 보입니다.</p>\n</div>\n</div>\n<script type=\"application/ld+json\">\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"제가 매일 사용하는 것 중에 AI가 적용된 예시가 또 있을까요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"네, 아주 많습니다! 스마트폰의 얼굴 인식 잠금 해제, 지도 앱의 최적 경로 안내, 온라인 쇼핑몰의 개인 맞춤 광고, 은행 앱의 사기 거래 탐지, 심지어는 이메일 스팸 필터링까지 모두 AI 기술이 적용된 예시입니다. 이처럼 AI는 우리 삶의 거의 모든 디지털 접점에서 활동하고 있어요.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"AI가 이렇게 일상에 스며들면 혹시 개인 정보는 안전한가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"개인 정보 보호는 AI 시대의 중요한 과제 중 하나입니다. 대부분의 AI 서비스 제공 기업들은 암호화, 익명화 등의 기술로 데이터를 보호하고 있지만, 사용자 스스로도 불필요한 정보 제공을 줄이고, 서비스 약관을 꼼꼼히 확인하는 습관을 들이는 것이 중요합니다. 정부와 기업들도 AI 윤리 및 개인 정보 보호를 위한 법규와 가이드라인을 강화하고 있습니다.\"\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"미래에는 AI가 어디까지 발전할 것이라고 예상하나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"2026년 현재를 기준으로 볼 때, AI는 더욱 개인화되고 맞춤화된 서비스로 발전할 것으로 예상됩니다. 예를 들어, 개인의 건강 데이터를 분석하여 맞춤형 식단이나 운동 프로그램을 제안하고, 교육 분야에서는 개개인의 학습 속도에 맞는 맞춤형 학습 콘텐츠를 제공하는 등 더욱 밀접하게 우리 삶의 질을 향상시키는 방향으로 진화할 것입니다. 또한, 자율주행, 로봇 공학 등 다양한 산업 분야에서 혁신을 가속화할 것으로 보입니다.\"\n      }\n    }\n  ]\n}\n</script>",
        "contentSnippet": "우리가 모르는 사이에 우리 삶 깊숙이 파고든 인공지능. 챗GPT 같은 거창한 기술만 AI라고 생각하셨나요? 사실은 스마트폰, 스트리밍 서비스, 심지어 우리 집 가전제품까지, 인공지능은 매일매일 우리 곁에서 삶을 더 편리하고 윤택하게 만들고 있답니다. 2026년, 인공지능의 진짜 얼굴을 만나볼까요?\n요즘 인공지능(AI)이라는 단어를 빼놓고 이야기하기는 정말 어려운 것 같아요. 거리를 걷다 보면 AI 관련 광고가 눈에 띄고, 스마트폰을 켜면 AI 기반 앱이 가득하죠. 하지만 많은 분들이 AI를 아직도 영화 속 로봇이나 복잡한 미래 기술로만 생각하시는 경향이 있는 것 같아요. 솔직히 저도 그랬거든요.\n그런데 말이죠, 곰곰이 생각해보면 AI는 이미 우리 일상에 너무나 자연스럽게 스며들어 있습니다. 우리는 의식하지 못하는 사이에 AI의 도움을 받으며 살아가고 있어요. 마치 공기처럼 말이죠. 오늘은 2026년 현재, 우리가 미처 몰랐던 생활 속 인공지능의 진짜 모습을 파헤쳐보고, AI가 어떻게 우리의 삶을 더 쉽고 즐겁게 만드는지 이야기해보려 합니다.\n\n\n  우리 곁에 너무나 당연한 존재, 스마트 비서\n아침에 눈을 뜨자마자 날씨를 묻고, 커피 머신을 켜달라고 말하고, 좋아하는 음악을 틀어달라고 요청하는 경험, 혹시 있으신가요? 바로 스마트 스피커나 스마트폰의 음성 비서를 통해 이루어지는 일이죠. 구글 어시스턴트, 애플 시리, 삼성 빅스비, 아마존 알렉사 등은 이제 우리에게 너무나 익숙한 이름이 되었습니다. 사실 이들이 바로 인공지능의 대표적인 예시라는 것을 아셨나요?\n이 스마트 비서들은 단순히 명령을 수행하는 것을 넘어, 우리의 음성을 인식하고, 질문의 의도를 파악하며, 방대한 데이터를 기반으로 적절한 답변이나 서비스를 제공합니다. 예를 들어, “오늘 저녁 메뉴 추천해 줘”라고 물으면, 우리의 과거 검색 기록이나 즐겨찾는 레시피를 분석해서 개인화된 추천을 해주는 식이죠. 저는 아침마다 알렉사에게 오늘의 뉴스를 요약해달라고 요청하는데, 출근 준비를 하면서 세상 소식을 한 번에 들을 수 있어서 정말 편리해요. 이건 단순한 기술이 아니라, 제 패턴을 학습하고 저에게 맞춰주는 AI의 능력 덕분이라고 생각합니다.\n  2014년 아마존 에코 출시 이후, 스마트 스피커는 놀라운 속도로 우리 일상에 자리 잡았습니다. 이제는 거의 모든 스마트홈 기기와 연동되어 집 안의 허브 역할을 톡톡히 하고 있죠.\n\n\n✍️ 궁금증 해결사부터 창작 도구까지, LLM의 변신\n최근 몇 년간 가장 뜨거웠던 AI 분야를 꼽으라면 단연 대규모 언어 모델(LLM) 기반의 챗봇일 거예요. 챗GPT, 구글 제미니, 마이크로소프트 코파일럿 등 다양한 서비스들이 쏟아져 나오면서 정보 탐색 방식 자체를 바꿔버렸죠.\n옛날에는 어떤 정보가 궁금하면 백과사전을 뒤지거나 도서관에 가서 책을 찾아봐야 했죠. 인터넷 시대가 열리면서 검색 엔진으로 빠르게 정보를 찾을 수 있게 되었지만, 여전히 수많은 검색 결과 중에서 필요한 정보를 선별하는 건 우리의 몫이었어요. 하지만 지금은 어떤가요? 챗봇에게 질문 하나만 던지면, 인터넷의 방대한 정보를 순식간에 요약하고 정리해서 우리에게 필요한 답을 딱! 제시해줍니다. 심지어 복잡한 질문에 대한 여러 가지 관점이나 대안까지도 보여주니, 정말 놀랍지 않나요?\n저는 최근에 인테리어를 고민하면서 챗봇의 도움을 많이 받았어요. 거실에 어떤 색깔의 소파가 어울릴지, 혹은 특정 공간에 어떤 식물을 놓으면 좋을지 막연하게 생각만 하고 있었거든요. 챗봇에게 “우리 집 거실 사진을 보여주며 이 공간에 어울리는 현대적인 소파 디자인을 추천해줘”라고 입력했더니, 몇 초 만에 여러 가지 시안을 이미지로 생성해주더라고요. 또, “이런 스타일의 소파를 파는 믿을 수 있는 국내 가구 업체 3곳을 추천해줘”라고 요청하니, 관련 정보를 요약해서 보여주기도 했습니다. 덕분에 시행착오를 줄이고 시간과 비용을 절약할 수 있었죠. 이런 경험을 해보면 AI가 더 이상 거창한 기술이 아니라, 삶의 질을 높여주는 똑똑한 비서라는 것을 절감하게 됩니다.\n⚠️ 챗봇의 답변은 항상 100% 정확한 것은 아닐 수 있습니다. 중요한 정보를 얻을 때는 교차 검증하는 습관을 들이는 것이 좋습니다.\nLLM이 바꿔놓은 정보 탐색의 패러다임\n항목\n전통적 방식 (인터넷 이전)\n검색 엔진 (인터넷 초기)\nAI 챗봇 (2026년 현재)\n\n\n\n\n정보 획득 방식\n백과사전, 책, 전문가 질문\n키워드 검색, 웹사이트 방문\n자연어 질문, 종합 요약 및 생성\n\n\n정보 선별 시간\n오래 걸림 (수동 작업)\n비교적 빠르나 사용자 노력 필요\n매우 빠름 (AI 자동 선별)\n\n\n개인화 수준\n낮음\n중간 (검색 기록 기반)\n높음 (대화형 맞춤 정보)\n\n\n\n\n\n  넷플릭스만 봐도 알 수 있는 AI의 섬세한 취향 저격\n하루를 마무리하며 편안하게 소파에 앉아 넷플릭스나 유튜브를 시청하는 것만큼 행복한 순간이 있을까요? 그런데 이 스트리밍 서비스들이 끊임없이 우리에게 “OO님이 좋아할 만한 콘텐츠”를 추천해주는 이유가 무엇인지 생각해보셨나요? 네, 맞아요. 여기에도 인공지능이 숨어있습니다.\n스트리밍 서비스의 AI는 우리가 어떤 장르의 영화를 즐겨 보는지, 어떤 배우나 감독에게 관심이 많은지, 시청하는 시간대는 언제인지 등 수많은 데이터를 분석해요. 그리고 이러한 패턴을 기반으로 우리가 좋아할 만한 콘텐츠를 예측하고 추천 리스트를 만들어줍니다. 처음 서비스를 시작할 때 취향을 묻는 질문부터, 우리가 콘텐츠를 시청하는 모든 순간이 AI 학습 데이터가 되는 셈이죠.\n솔직히 예전에는 TV 채널을 이리저리 돌리거나 비디오 가게에서 한참을 서성이다가 아무거나 빌려오는 경우가 많았잖아요. 그러다 재미없는 영화를 보면 시간 낭비라는 생각이 들기도 했고요. 하지만 이제는 AI 덕분에 그런 고민을 할 필요가 없어요. AI가 저의 취향에 딱 맞는 콘텐츠만 쏙쏙 골라주니, 시간을 절약할 수 있을 뿐만 아니라 매번 만족스러운 시청 경험을 할 수 있게 되는 거죠. 서비스 제공자 입장에서는 사용자가 플랫폼에 더 오래 머물고, 재결제할 확률이 높아지니 서로 윈-윈이 되는 효과라고 볼 수 있습니다.\n\n\n  AI, 생각보다 훨씬 더 우리의 삶에 스며들었네요\n스마트 비서, 챗봇, 스트리밍 추천 외에도 AI는 정말 다양한 방식으로 우리의 삶을 풍요롭게 하고 있습니다. 스마트폰 카메라의 얼굴 인식 기능, 은행 앱의 이상 금융 거래 감지, 온라인 쇼핑몰의 맞춤형 상품 추천, 심지어는 차량 내비게이션의 실시간 교통 분석까지, 우리가 인지하지 못하는 사이에도 AI는 조용히, 그러나 강력하게 작동하고 있어요.\n물론, AI 기술의 발전이 항상 장밋빛 미래만을 의미하는 것은 아닙니다. 개인 정보 보호나 데이터 오남용, 딥페이크와 같은 윤리적인 문제들은 우리가 계속해서 논의하고 해결해나가야 할 숙제임은 분명해요. 하지만 이러한 우려에도 불구하고, AI가 우리 삶을 더 편리하고 효율적으로 만드는 긍정적인 측면이 훨씬 더 많다는 것을 부정하기는 어렵습니다.\n솔직히 처음에는 저도 AI가 너무 어렵고, '거대한 기술'이라고만 생각했어요. 하지만 이렇게 매일매일 사용하는 기술들을 되짚어보니, AI는 우리의 삶을 '더 쉽게' 만들어주는 '친근한 도구'라는 사실을 깨달았습니다. 미래의 AI는 또 어떤 모습으로 우리를 놀라게 할지, 정말 기대되지 않나요?\n  핵심 요약\n✅ AI는 스마트 비서처럼 이미 우리 일상에 깊이 스며들어 있습니다.\n✅ 챗봇은 정보 탐색을 넘어 창의적인 아이디어와 시각적 자료까지 제공합니다.\n✅ 스트리밍 서비스 추천은 AI가 우리의 취향을 섬세하게 분석한 결과입니다.\n✅ AI는 우리 삶을 더 편리하고 효율적으로 만드는 '친근한 도구'입니다.\nAI는 우리의 생각보다 훨씬 가까이에 있습니다. 조금만 관심을 가지면 AI의 놀라운 잠재력을 더욱 효과적으로 활용할 수 있을 거예요.\n❓ 자주 묻는 질문 (FAQ)\nQ1: 제가 매일 사용하는 것 중에 AI가 적용된 예시가 또 있을까요?\nA1: 네, 아주 많습니다! 스마트폰의 얼굴 인식 잠금 해제, 지도 앱의 최적 경로 안내, 온라인 쇼핑몰의 개인 맞춤 광고, 은행 앱의 사기 거래 탐지, 심지어는 이메일 스팸 필터링까지 모두 AI 기술이 적용된 예시입니다. 이처럼 AI는 우리 삶의 거의 모든 디지털 접점에서 활동하고 있어요.\nQ2: AI가 이렇게 일상에 스며들면 혹시 개인 정보는 안전한가요?\nA2: 개인 정보 보호는 AI 시대의 중요한 과제 중 하나입니다. 대부분의 AI 서비스 제공 기업들은 암호화, 익명화 등의 기술로 데이터를 보호하고 있지만, 사용자 스스로도 불필요한 정보 제공을 줄이고, 서비스 약관을 꼼꼼히 확인하는 습관을 들이는 것이 중요합니다. 정부와 기업들도 AI 윤리 및 개인 정보 보호를 위한 법규와 가이드라인을 강화하고 있습니다.\nQ3: 미래에는 AI가 어디까지 발전할 것이라고 예상하나요?\nA3: 2026년 현재를 기준으로 볼 때, AI는 더욱 개인화되고 맞춤화된 서비스로 발전할 것으로 예상됩니다. 예를 들어, 개인의 건강 데이터를 분석하여 맞춤형 식단이나 운동 프로그램을 제안하고, 교육 분야에서는 개개인의 학습 속도에 맞는 맞춤형 학습 콘텐츠를 제공하는 등 더욱 밀접하게 우리 삶의 질을 향상시키는 방향으로 진화할 것입니다. 또한, 자율주행, 로봇 공학 등 다양한 산업 분야에서 혁신을 가속화할 것으로 보입니다.\n\n\n\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"제가 매일 사용하는 것 중에 AI가 적용된 예시가 또 있을까요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"네, 아주 많습니다! 스마트폰의 얼굴 인식 잠금 해제, 지도 앱의 최적 경로 안내, 온라인 쇼핑몰의 개인 맞춤 광고, 은행 앱의 사기 거래 탐지, 심지어는 이메일 스팸 필터링까지 모두 AI 기술이 적용된 예시입니다. 이처럼 AI는 우리 삶의 거의 모든 디지털 접점에서 활동하고 있어요.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"AI가 이렇게 일상에 스며들면 혹시 개인 정보는 안전한가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"개인 정보 보호는 AI 시대의 중요한 과제 중 하나입니다. 대부분의 AI 서비스 제공 기업들은 암호화, 익명화 등의 기술로 데이터를 보호하고 있지만, 사용자 스스로도 불필요한 정보 제공을 줄이고, 서비스 약관을 꼼꼼히 확인하는 습관을 들이는 것이 중요합니다. 정부와 기업들도 AI 윤리 및 개인 정보 보호를 위한 법규와 가이드라인을 강화하고 있습니다.\"\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"미래에는 AI가 어디까지 발전할 것이라고 예상하나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"2026년 현재를 기준으로 볼 때, AI는 더욱 개인화되고 맞춤화된 서비스로 발전할 것으로 예상됩니다. 예를 들어, 개인의 건강 데이터를 분석하여 맞춤형 식단이나 운동 프로그램을 제안하고, 교육 분야에서는 개개인의 학습 속도에 맞는 맞춤형 학습 콘텐츠를 제공하는 등 더욱 밀접하게 우리 삶의 질을 향상시키는 방향으로 진화할 것입니다. 또한, 자율주행, 로봇 공학 등 다양한 산업 분야에서 혁신을 가속화할 것으로 보입니다.\"\n      }\n    }\n  ]\n}",
        "guid": "https://muzbox.tistory.com/483702",
        "categories": [
          "AI, 미래기술/AI 인사이트",
          "AI 기술 활용",
          "AI 윤리",
          "LLM",
          "개인화 ai",
          "생활 속 ai",
          "스마트 비서",
          "스트리밍 추천",
          "인공지능",
          "일상의 편리함",
          "챗봇"
        ],
        "isoDate": "2026-01-21T03:22:39.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "(RULIWEB`Д')/",
        "title": "[MULTI] 순수 재미로 의혹 돌파할까, 레이드 슈터 ‘하이가드’",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2413",
        "pubDate": "Tue, 27 Jan 2026 03:00:00 +0900",
        "author": "(RULIWEB`Д')/",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/26/01/27/19bfb2451344c329e.jpg\">",
        "contentSnippet": "",
        "categories": [
          "프리뷰"
        ],
        "isoDate": "2026-01-26T18:00:00.000Z"
      },
      {
        "creator": "［RULIWEB］",
        "title": "[MULTI] 낡음과 익숙함 속에서 폭발적 각별함이 터지다, 드래곤소드",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2412",
        "pubDate": "Mon, 26 Jan 2026 17:34:55 +0900",
        "author": "［RULIWEB］",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/26/01/26/19bf96ff0455104c1.webp\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2026-01-26T08:34:55.000Z"
      },
      {
        "creator": "｜RULIWEB｜",
        "title": "악역영애 4컷 만화 - 36화, 달리기 시합인데스와",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2411",
        "pubDate": "Wed, 21 Jan 2026 20:19:05 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/26/01/21/19be047091a51ad6b.webp\">",
        "contentSnippet": "",
        "categories": [
          "웹툰"
        ],
        "isoDate": "2026-01-21T11:19:05.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "406일차 - NFT 는 안되고 WEB3 로 방향 선회",
        "link": "https://serverdown.tistory.com/1564",
        "pubDate": "Mon, 26 Jan 2026 12:59:54 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1564#entry1564comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"296\" data-origin-height=\"274\"><span data-url=\"https://blog.kakaocdn.net/dn/k8u9A/dJMcafk6Hdk/qgwBWmsKsOtWrZUFeKMKN0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/k8u9A/dJMcafk6Hdk/qgwBWmsKsOtWrZUFeKMKN0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/k8u9A/dJMcafk6Hdk/qgwBWmsKsOtWrZUFeKMKN0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fk8u9A%2FdJMcafk6Hdk%2FqgwBWmsKsOtWrZUFeKMKN0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"296\" height=\"274\" data-origin-width=\"296\" data-origin-height=\"274\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://youtu.be/VAqWSlALXGM\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://youtu.be/VAqWSlALXGM</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=VAqWSlALXGM\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/ilzSY/dJMb81fM2nD/PvapoWF7DSWT4F2gBzYZPK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/2rJEi/dJMb9aKzv7m/sE8HCES8aZjs7mMfUmK051/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/hwNFz/dJMb895X1np/Dlt9fkk7I07uuRKQaWyWOK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"406일차 - NFT 안된다 WEB3 로 간다.\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/VAqWSlALXGM\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">슬픈 일이지만 NFT 는 24년에 정부 가이드라인이 있었나봅니다.</p>\n<p data-ke-size=\"size16\">그래서 수익창출이 힘들다고 하네요</p>\n<p data-ke-size=\"size16\">기능 구현 위주로 가야하고 한국쪽에 서비스하면 안됡 것 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">유이티 웹빌드라도 결과물을 확실히 챙겨야겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://youtu.be/VAqWSlALXGM\n\n\n\n \n \n슬픈 일이지만 NFT 는 24년에 정부 가이드라인이 있었나봅니다.\n그래서 수익창출이 힘들다고 하네요\n기능 구현 위주로 가야하고 한국쪽에 서비스하면 안됡 것 같습니다.\n \n유이티 웹빌드라도 결과물을 확실히 챙겨야겠습니다.",
        "guid": "https://serverdown.tistory.com/1564",
        "categories": [
          "프로그래밍/개발메모",
          "aptos",
          "nft",
          "web3",
          "앱토스",
          "유니티"
        ],
        "isoDate": "2026-01-26T03:59:54.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "유니티 광고 레벨플레이 아이언소스 / LevelPlay / IronSource",
        "link": "https://serverdown.tistory.com/1563",
        "pubDate": "Sat, 24 Jan 2026 14:34:30 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1563#entry1563comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"939\" data-origin-height=\"633\"><span data-url=\"https://blog.kakaocdn.net/dn/c4xnA7/dJMcaaqyq2g/dkhv8K8nKJkfK4PZfeGbpk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/c4xnA7/dJMcaaqyq2g/dkhv8K8nKJkfK4PZfeGbpk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/c4xnA7/dJMcaaqyq2g/dkhv8K8nKJkfK4PZfeGbpk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc4xnA7%2FdJMcaaqyq2g%2Fdkhv8K8nKJkfK4PZfeGbpk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"939\" height=\"633\" data-origin-width=\"939\" data-origin-height=\"633\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">애드몹 광고가 부족해서 표시 못하는 상황을 겪다보니</p>\n<p data-ke-size=\"size16\">찾은 방법이 매디에이션 입니다.</p>\n<p data-ke-size=\"size16\">애드몹 자체 광고만으로 부족하기 때문에</p>\n<p data-ke-size=\"size16\">더 많은 입찰 업체를 연결해서 남는 광고를 경매로 넘기는 방식입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">미디에이션을 하려면 입찰자들의 광고 모듈을 붙여줘야합니다.</p>\n<p data-ke-size=\"size16\">각 회사마다 방식이 있기 때문에 붙이기 어려운데요</p>\n<p data-ke-size=\"size16\">유니티에서는 레벨플레이를 지원합니다.</p>\n<p data-ke-size=\"size16\">그런데 버튼만 누르면 끝이군요&nbsp;</p>\n<p data-ke-size=\"size16\">아주 편합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">뒤에 더 많은 작업이 잇을꺼 같긴한데</p>\n<p data-ke-size=\"size16\">일단 문서를 보고 더 진행해야겠습니다.</p>\n<p data-ke-size=\"size16\">개발 문서: <a href=\"https://developers.is.com/ironsource-mobile/unity/unity-plugin/\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://developers.is.com/ironsource-mobile/unity/unity-plugin/</a></p>\n<figure id=\"og_1769233088923\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Unity Package Integration - IronSource Knowledge Center\" data-og-description=\"Unity Package Integration ⚡ Before you start Unity LevelPlay mediation supports Unity version 2021.3+, and Android operating systems version 4.4 (API level 19)+. iOS version support is defined per network. ironSource Ads and LevelPlay mediation support i\" data-og-host=\"developers.is.com\" data-og-source-url=\"https://developers.is.com/ironsource-mobile/unity/unity-plugin/\" data-og-url=\"https://developers.is.com/ironsource-mobile/unity/unity-plugin/\" data-og-image=\"https://scrap.kakaocdn.net/dn/ctyKIA/dJMb83Sc562/CubWm5029KQ5MSUDHVNIKK/img.jpg?width=500&amp;height=160&amp;face=0_0_500_160,https://scrap.kakaocdn.net/dn/sUtw5/dJMb84p21nv/KzyaMIHe5SzKVzy56OsAK0/img.png?width=774&amp;height=793&amp;face=0_0_774_793\"><a href=\"https://developers.is.com/ironsource-mobile/unity/unity-plugin/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://developers.is.com/ironsource-mobile/unity/unity-plugin/\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/ctyKIA/dJMb83Sc562/CubWm5029KQ5MSUDHVNIKK/img.jpg?width=500&amp;height=160&amp;face=0_0_500_160,https://scrap.kakaocdn.net/dn/sUtw5/dJMb84p21nv/KzyaMIHe5SzKVzy56OsAK0/img.png?width=774&amp;height=793&amp;face=0_0_774_793');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Unity Package Integration - IronSource Knowledge Center</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Unity Package Integration ⚡ Before you start Unity LevelPlay mediation supports Unity version 2021.3+, and Android operating systems version 4.4 (API level 19)+. iOS version support is defined per network. ironSource Ads and LevelPlay mediation support i</p>\n<p class=\"og-host\" data-ke-size=\"size16\">developers.is.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">개발 순서</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"730\" data-origin-height=\"323\"><span data-url=\"https://blog.kakaocdn.net/dn/c1knk7/dJMcafMa7oY/uvwDzjuQIf3sdVfo4Tv5H0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/c1knk7/dJMcafMa7oY/uvwDzjuQIf3sdVfo4Tv5H0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/c1knk7/dJMcafMa7oY/uvwDzjuQIf3sdVfo4Tv5H0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc1knk7%2FdJMcafMa7oY%2FuvwDzjuQIf3sdVfo4Tv5H0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"730\" height=\"323\" data-origin-width=\"730\" data-origin-height=\"323\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">어린이를 대상으로 하나요 ?</p>\n<p data-ke-size=\"size16\">저는 아니요 골랐습니다.</p>\n<p data-ke-size=\"size16\">어린이 게임 만드실분은 예 눌러아겠죠</p>\n<p data-ke-size=\"size16\">다음</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"725\" data-origin-height=\"443\"><span data-url=\"https://blog.kakaocdn.net/dn/cRT7dC/dJMcaaKQ8sM/UDggUev3RaAGonJPpjyZ2k/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cRT7dC/dJMcaaKQ8sM/UDggUev3RaAGonJPpjyZ2k/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cRT7dC/dJMcaaKQ8sM/UDggUev3RaAGonJPpjyZ2k/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcRT7dC%2FdJMcaaKQ8sM%2FUDggUev3RaAGonJPpjyZ2k%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"725\" height=\"443\" data-origin-width=\"725\" data-origin-height=\"443\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">레벨플레이 대시보드 안내하네요</p>\n<p data-ke-size=\"size16\">유니티 로그인을 거쳐</p>\n<p data-ke-size=\"size16\">아이언소스 쪽으로 로그인 되네요</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"753\" data-origin-height=\"454\"><span data-url=\"https://blog.kakaocdn.net/dn/J5SBv/dJMcagdexSZ/qwDXKKCb9hlSFUbogGCuWK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/J5SBv/dJMcagdexSZ/qwDXKKCb9hlSFUbogGCuWK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/J5SBv/dJMcagdexSZ/qwDXKKCb9hlSFUbogGCuWK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FJ5SBv%2FdJMcagdexSZ%2FqwDXKKCb9hlSFUbogGCuWK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"753\" height=\"454\" data-origin-width=\"753\" data-origin-height=\"454\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">아이언소스 회원가입하나봅니다.</p>\n<p data-ke-size=\"size16\">다음</p>\n<p data-ke-size=\"size16\">이름이랑 도시 넣는데 스샷 안찍었습니다.</p>\n<p data-ke-size=\"size16\">다</p>\n<p data-ke-size=\"size16\">앱이 출시되었는지 묻는군요 알아서 입력하시구요</p>\n<p data-ke-size=\"size16\">저는 새 앱에 적용할 꺼라 아니오 눌렀습니다.</p>\n<p data-ke-size=\"size16\">아래로 가면</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"522\" data-origin-height=\"243\"><span data-url=\"https://blog.kakaocdn.net/dn/s9eTl/dJMcai28CVd/1wDQSqkcTzsBBGHCkI2hR1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/s9eTl/dJMcai28CVd/1wDQSqkcTzsBBGHCkI2hR1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/s9eTl/dJMcai28CVd/1wDQSqkcTzsBBGHCkI2hR1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fs9eTl%2FdJMcai28CVd%2F1wDQSqkcTzsBBGHCkI2hR1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"522\" height=\"243\" data-origin-width=\"522\" data-origin-height=\"243\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">COPPA* 는 정보 보호법이라고 하네요</p>\n<p data-ke-size=\"size16\">따를 것이기 때문에 Directed 디렉티드 고릅니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"776\" data-origin-height=\"64\"><span data-url=\"https://blog.kakaocdn.net/dn/bWIj8S/dJMcaaqysoA/P9nFUSGDcDX8tRbYY0jQn1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bWIj8S/dJMcaaqysoA/P9nFUSGDcDX8tRbYY0jQn1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bWIj8S/dJMcaaqysoA/P9nFUSGDcDX8tRbYY0jQn1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbWIj8S%2FdJMcaaqysoA%2FP9nFUSGDcDX8tRbYY0jQn1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"776\" height=\"64\" data-origin-width=\"776\" data-origin-height=\"64\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">플레이 가능한 광고를 사용하겠느냐인데</p>\n<p data-ke-size=\"size16\">저는 플레이가능한 광고 싫습니다.</p>\n<p data-ke-size=\"size16\">체크를 하면 거부하겠다는 뜻 같군요&nbsp;</p>\n<p data-ke-size=\"size16\">저는 체크 했습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"816\" data-origin-height=\"424\"><span data-url=\"https://blog.kakaocdn.net/dn/zpWVQ/dJMcabJMSkG/JIaRqx3H1fagGT0KlzMdc1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/zpWVQ/dJMcabJMSkG/JIaRqx3H1fagGT0KlzMdc1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/zpWVQ/dJMcabJMSkG/JIaRqx3H1fagGT0KlzMdc1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FzpWVQ%2FdJMcabJMSkG%2FJIaRqx3H1fagGT0KlzMdc1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"816\" height=\"424\" data-origin-width=\"816\" data-origin-height=\"424\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">이 뒤론 메뉴가 너무 많쿤요 Admob 같은 화면이 나왔습니다.</p>\n<p data-ke-size=\"size16\">메뉴는 더 확인해봐야겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">투자 관점</h2>\n<p data-ke-size=\"size16\">이부분에서 유명한 회사가 앱러빈 입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"808\" data-origin-height=\"512\"><span data-url=\"https://blog.kakaocdn.net/dn/qUQCf/dJMcadgulBx/00bKyKlVsAY7Wp9jD6urH1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/qUQCf/dJMcadgulBx/00bKyKlVsAY7Wp9jD6urH1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/qUQCf/dJMcadgulBx/00bKyKlVsAY7Wp9jD6urH1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FqUQCf%2FdJMcadgulBx%2F00bKyKlVsAY7Wp9jD6urH1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"808\" height=\"512\" data-origin-width=\"808\" data-origin-height=\"512\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">5년치 차트인데요 엄청난 주가 향상이 있었죠</p>\n<p data-ke-size=\"size16\">게임은 유니티로 만드는데 광고는 앱러빈이 먹고 있었습니다.</p>\n<p data-ke-size=\"size16\">이번에 유니티가 이걸 하겠다고 만든게 레벨플레이 구요</p>\n<p data-ke-size=\"size16\">모듈 붙이기가 아주 쉬워졌으니 효과가 있을 것 같습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"828\" data-origin-height=\"701\"><span data-url=\"https://blog.kakaocdn.net/dn/dqCLxu/dJMcaiWn88u/cLnG1wxQTuItn9Y7gok0rK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dqCLxu/dJMcaiWn88u/cLnG1wxQTuItn9Y7gok0rK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dqCLxu/dJMcaiWn88u/cLnG1wxQTuItn9Y7gok0rK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdqCLxu%2FdJMcaiWn88u%2FcLnG1wxQTuItn9Y7gok0rK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"828\" height=\"701\" data-origin-width=\"828\" data-origin-height=\"701\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">이제 시작 아닌가 싶군요</p>\n<p data-ke-size=\"size16\">저는 왕창 사야겠습니다. 가즈아~</p>\n<p data-ke-size=\"size16\">붙이는법 쓸려고 문서 썼는데</p>\n<p data-ke-size=\"size16\">투자로 갔군요 ㅎㅎ</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "애드몹 광고가 부족해서 표시 못하는 상황을 겪다보니\n찾은 방법이 매디에이션 입니다.\n애드몹 자체 광고만으로 부족하기 때문에\n더 많은 입찰 업체를 연결해서 남는 광고를 경매로 넘기는 방식입니다.\n \n미디에이션을 하려면 입찰자들의 광고 모듈을 붙여줘야합니다.\n각 회사마다 방식이 있기 때문에 붙이기 어려운데요\n유니티에서는 레벨플레이를 지원합니다.\n그런데 버튼만 누르면 끝이군요 \n아주 편합니다.\n \n뒤에 더 많은 작업이 잇을꺼 같긴한데\n일단 문서를 보고 더 진행해야겠습니다.\n개발 문서: https://developers.is.com/ironsource-mobile/unity/unity-plugin/\n\n \nUnity Package Integration - IronSource Knowledge Center\nUnity Package Integration ⚡ Before you start Unity LevelPlay mediation supports Unity version 2021.3+, and Android operating systems version 4.4 (API level 19)+. iOS version support is defined per network. ironSource Ads and LevelPlay mediation support i\ndevelopers.is.com\n\n \n \n개발 순서\n\n\n어린이를 대상으로 하나요 ?\n저는 아니요 골랐습니다.\n어린이 게임 만드실분은 예 눌러아겠죠\n다음\n\n\n레벨플레이 대시보드 안내하네요\n유니티 로그인을 거쳐\n아이언소스 쪽으로 로그인 되네요\n\n\n아이언소스 회원가입하나봅니다.\n다음\n이름이랑 도시 넣는데 스샷 안찍었습니다.\n다\n앱이 출시되었는지 묻는군요 알아서 입력하시구요\n저는 새 앱에 적용할 꺼라 아니오 눌렀습니다.\n아래로 가면\n\n\nCOPPA* 는 정보 보호법이라고 하네요\n따를 것이기 때문에 Directed 디렉티드 고릅니다.\n\n\n플레이 가능한 광고를 사용하겠느냐인데\n저는 플레이가능한 광고 싫습니다.\n체크를 하면 거부하겠다는 뜻 같군요 \n저는 체크 했습니다.\n\n\n이 뒤론 메뉴가 너무 많쿤요 Admob 같은 화면이 나왔습니다.\n메뉴는 더 확인해봐야겠습니다.\n \n \n \n \n \n \n투자 관점\n이부분에서 유명한 회사가 앱러빈 입니다.\n\n\n5년치 차트인데요 엄청난 주가 향상이 있었죠\n게임은 유니티로 만드는데 광고는 앱러빈이 먹고 있었습니다.\n이번에 유니티가 이걸 하겠다고 만든게 레벨플레이 구요\n모듈 붙이기가 아주 쉬워졌으니 효과가 있을 것 같습니다.\n\n\n이제 시작 아닌가 싶군요\n저는 왕창 사야겠습니다. 가즈아~\n붙이는법 쓸려고 문서 썼는데\n투자로 갔군요 ㅎㅎ",
        "guid": "https://serverdown.tistory.com/1563",
        "categories": [
          "프로그래밍/개발메모",
          "LevelPlay",
          "unity",
          "레벨플레이",
          "아이언소스",
          "유니티"
        ],
        "isoDate": "2026-01-24T05:34:30.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "Strip Engine Code 를 끄라고 한다. / Admob 문제로 추측",
        "link": "https://serverdown.tistory.com/1562",
        "pubDate": "Fri, 23 Jan 2026 00:32:04 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1562#entry1562comment",
        "content": "<h2 data-ke-size=\"size26\">문제가 로그에 찍혀서 남겨둔다.</h2>\n<p data-ke-size=\"size16\">AssetBundle 을 읽으려고 하는데 실패를 한다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1102\" data-origin-height=\"401\"><span data-url=\"https://blog.kakaocdn.net/dn/bsmDBt/dJMcagK4NiD/7GNkscJs4AxWumqs8D4A11/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bsmDBt/dJMcagK4NiD/7GNkscJs4AxWumqs8D4A11/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bsmDBt/dJMcagK4NiD/7GNkscJs4AxWumqs8D4A11/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbsmDBt%2FdJMcagK4NiD%2F7GNkscJs4AxWumqs8D4A11%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1102\" height=\"401\" data-origin-width=\"1102\" data-origin-height=\"401\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">Strap Engine Code 글 끄라고 한다.</p>\n<p data-ke-size=\"size16\">Admob 때문에 발생한다고 한다.</p>\n<p data-ke-size=\"size16\">영상을 읽는 건데 Admob 도 영상을 읽어야해서 그런가 보다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"708\" data-origin-height=\"698\"><span data-url=\"https://blog.kakaocdn.net/dn/p6Q0Q/dJMcadndonB/dBVOjMdevsXUsVNUarxAi0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/p6Q0Q/dJMcadndonB/dBVOjMdevsXUsVNUarxAi0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/p6Q0Q/dJMcadndonB/dBVOjMdevsXUsVNUarxAi0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fp6Q0Q%2FdJMcadndonB%2FdBVOjMdevsXUsVNUarxAi0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"708\" height=\"698\" data-origin-width=\"708\" data-origin-height=\"698\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">Project Setting 에 Other Option 인가에 있다.</p>\n<p data-ke-size=\"size16\">스샷을 보고 대충 위치를 찾아보도록 켜져있길레 껏다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\">로그</h3>\n<p data-ke-size=\"size16\">01-23&nbsp;00:22:07.860&nbsp;11829&nbsp;30918&nbsp;I&nbsp;Unity&nbsp;&nbsp;&nbsp;:&nbsp;UnityEngine.DebugLogHandler:Internal_Log(LogType,&nbsp;LogOption,&nbsp;String,&nbsp;Object) <br />01-23&nbsp;00:22:07.860&nbsp;11829&nbsp;30918&nbsp;I&nbsp;Unity&nbsp;&nbsp;&nbsp;:&nbsp;&lt;LoadAssetAfter&gt;d__51:MoveNext() <br />01-23&nbsp;00:22:07.860&nbsp;11829&nbsp;30918&nbsp;I&nbsp;Unity&nbsp;&nbsp;&nbsp;:&nbsp;UnityEngine.SetupCoroutine:InvokeMoveNext(IEnumerator,&nbsp;IntPtr) <br />01-23&nbsp;00:22:07.860&nbsp;11829&nbsp;30918&nbsp;I&nbsp;Unity&nbsp;&nbsp;&nbsp;: <br />01-23&nbsp;00:22:07.861&nbsp;11829&nbsp;30918&nbsp;E&nbsp;Unity&nbsp;&nbsp;&nbsp;:&nbsp;Could&nbsp;not&nbsp;produce&nbsp;class&nbsp;with&nbsp;ID&nbsp;329. <br />01-23&nbsp;00:22:07.861&nbsp;11829&nbsp;30918&nbsp;E&nbsp;Unity&nbsp;&nbsp;&nbsp;:&nbsp;This&nbsp;could&nbsp;be&nbsp;caused&nbsp;by&nbsp;a&nbsp;class&nbsp;being&nbsp;stripped&nbsp;from&nbsp;the&nbsp;build&nbsp;even&nbsp;though&nbsp;it&nbsp;is&nbsp;needed.&nbsp;Try&nbsp;disabling&nbsp;'Strip&nbsp;Engine&nbsp;Code'&nbsp;in&nbsp;Player&nbsp;Settings. <br />01-23&nbsp;00:22:07.861&nbsp;11829&nbsp;30918&nbsp;E&nbsp;Unity&nbsp;&nbsp;&nbsp;:&nbsp;UnityEngine.AssetBundle:LoadAssetWithSubAssets_Internal(String,&nbsp;Type) <br />01-23&nbsp;00:22:07.861&nbsp;11829&nbsp;30918&nbsp;E&nbsp;Unity&nbsp;&nbsp;&nbsp;:&nbsp;Helper:LoadVidePlayerFromObject(AssetBundle,&nbsp;Action`1) <br />01-23&nbsp;00:22:07.861&nbsp;11829&nbsp;30918&nbsp;E&nbsp;Unity&nbsp;&nbsp;&nbsp;:&nbsp;&lt;LoadAssetAfter&gt;d__51:MoveNext() <br />01-23&nbsp;00:22:07.861&nbsp;11829&nbsp;30918&nbsp;E&nbsp;Unity&nbsp;&nbsp;&nbsp;:&nbsp;UnityEngine.SetupCoroutine:InvokeMoveNext(IEnumerator,&nbsp;IntPtr) <br />01-23&nbsp;00:22:07.861&nbsp;11829&nbsp;30918&nbsp;E&nbsp;Unity&nbsp;&nbsp;&nbsp;:</p>",
        "contentSnippet": "문제가 로그에 찍혀서 남겨둔다.\nAssetBundle 을 읽으려고 하는데 실패를 한다.\n\n\nStrap Engine Code 글 끄라고 한다.\nAdmob 때문에 발생한다고 한다.\n영상을 읽는 건데 Admob 도 영상을 읽어야해서 그런가 보다.\n\n\nProject Setting 에 Other Option 인가에 있다.\n스샷을 보고 대충 위치를 찾아보도록 켜져있길레 껏다.\n \n \n \n로그\n01-23 00:22:07.860 11829 30918 I Unity   : UnityEngine.DebugLogHandler:Internal_Log(LogType, LogOption, String, Object) \n01-23 00:22:07.860 11829 30918 I Unity   : <LoadAssetAfter>d__51:MoveNext() \n01-23 00:22:07.860 11829 30918 I Unity   : UnityEngine.SetupCoroutine:InvokeMoveNext(IEnumerator, IntPtr) \n01-23 00:22:07.860 11829 30918 I Unity   : \n01-23 00:22:07.861 11829 30918 E Unity   : Could not produce class with ID 329. \n01-23 00:22:07.861 11829 30918 E Unity   : This could be caused by a class being stripped from the build even though it is needed. Try disabling 'Strip Engine Code' in Player Settings. \n01-23 00:22:07.861 11829 30918 E Unity   : UnityEngine.AssetBundle:LoadAssetWithSubAssets_Internal(String, Type) \n01-23 00:22:07.861 11829 30918 E Unity   : Helper:LoadVidePlayerFromObject(AssetBundle, Action`1) \n01-23 00:22:07.861 11829 30918 E Unity   : <LoadAssetAfter>d__51:MoveNext() \n01-23 00:22:07.861 11829 30918 E Unity   : UnityEngine.SetupCoroutine:InvokeMoveNext(IEnumerator, IntPtr) \n01-23 00:22:07.861 11829 30918 E Unity   :",
        "guid": "https://serverdown.tistory.com/1562",
        "categories": [
          "프로그래밍/개발메모"
        ],
        "isoDate": "2026-01-22T15:32:04.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": [
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "AI로 레거시 환경 개선하기",
        "link": "https://jojoldu.tistory.com/859",
        "pubDate": "Mon, 26 Jan 2026 10:22:35 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "https://jojoldu.tistory.com/859#entry859comment",
        "content": "<p data-ke-size=\"size16\">요즘의 개발자 채용은 채용하는 팀과 채용하지 않는 팀으로 완전히 나뉘어 있다.</p>\n<p data-ke-size=\"size16\">비즈니스 속도가 안정권에 들어섰고, 레거시가 충분히 해소된 팀은 개발자 채용을 거의 하지 않는다.<br />누군가 퇴사를 해도 그 자리를 채우지 않는다.</p>\n<p data-ke-size=\"size16\">반면, 여전히 비즈니스 속도를 내는 팀은 공격적으로 개발자를 채용하고 있다.<br />이런 속도를 유지하는 팀은 기술 부채와 레거시를 계속해서 쌓이는 것으로만 보며, 해결해야 할 대상으로 보지 않는다.</p>\n<p data-ke-size=\"size16\">지금의 인원으로 속도가 점점 떨어진다면, 더 많은 개발자를 채용함으로써 계속해서 그 속도를 유지한다.<br />속도를 최우선으로 하면서 쌓이는 부채보다 비즈니스 성장이 떨어지는 것이 더 무서운 일이기 때문이다.</p>\n<p data-ke-size=\"size16\">개발자를 공격적으로 채용하고 있으니 그만큼 개발문화와 개발 환경이 좋을 것이라 예상했으나 첫 온보딩때 그 예상은 산산히 부서진다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>해당 프로젝트의 히스토리를 아는 개발자는 모두 퇴사한 상태라 알려줄 사람이 없다.</li>\n<li>개발/정책 문서가 없어서 흩어진 슬랙 메시지, 극 초기의 컨셉만 담은 노션의 몇 안되는 페이지들, 주석이 없는 애플리케이션 코드, comment가 없는 테이블 스키마 등을 보면서 분석해야 한다.</li>\n<li>시스템 구조를 알 수 있는 방법이 없어 지금 호출하고 있는 API에 신규 속성을 추가하려면 누구와 이야기해야 할지, 어느 프로젝트를 봐야 할지도 알 수 없다.</li>\n<li>테스트 코드가 없어 지금의 이 코드를 수정하면 무슨 일이 벌어질지 알 수 없다. 테스트 코드를 넣자니 인풋/아웃풋이 무엇이어야 하는지조차 알 수가 없다.</li>\n<li>히스토리와 기능이 전혀 분석이 되지 않는 상태에서 PO/PM은 새로운 기능에 대해 요구사항 분석과 언제까지 가능한지 일정을 알려달라 한다.</li>\n<li>기술 리더는 기술 부채를 해결하는 것 보다 제품지표/비즈니스 성과에 대해서 더 중요하다고 이야기한다. 레거시를 해결할 시간 따위 여기선 별도로 할당 받을 수 없는 상황이다.</li>\n</ul>\n<p data-ke-size=\"size16\">이렇게 레거시가 가득한 환경에선 도저히 일할 수 없을 것 같다는 생각이 매일 출근마다 머릿속을 가득 채운다.</p>\n<p data-ke-size=\"size16\">하지만, 지금의 개발자를 채용하는 대부분의 회사는 이렇게 레거시가 가득할 확률이 높다.<br />그렇지 않으면 이미 많은 개발자가 있음에도 더 많은 개발자를 채용할 이유가 요즘에 찾기가 어렵기 때문이다.</p>\n<p data-ke-size=\"size16\">\"레거시 코드 활용 전략\", \"리팩토링 데이터베이스\" 등 점진적으로 레거시를 해소할 여러 노하우가 담긴 책들이 많다.<br />하지만, 이 책을 지금 읽어보고 현재의 내 상황에 하나하나 대입하기엔 시간이 너무 부족하다.</p>\n<p data-ke-size=\"size16\">수습 기간의 카운트다운은 이미 시작되었다.<br />조직에서는 새로 합류한 나에 대한 평가를 계속해서 하고 있는 상황에서, \"레거시가 심해서 도저히 일할 수가 없어요\"라고만 말할 수도 없다.<br />그렇게 얘기했다가는 이 사람들이 나와 함께 할 필요가 없어지니.</p>\n<p data-ke-size=\"size16\">막막한 이 상황을 도대체 어디서부터 풀어나가야 할까?</p>\n<hr data-ke-style=\"style1\" />\n<p data-ke-size=\"size16\">다행히 이제는 개발자에겐 AI라는 막강한 도구가 있다.<br />개발자를 적극적으로 채용하는 회사로 합류하는 모든 개발자들에겐 레거시 환경과 기술 부채 환경은 기본값으로 봐야한다.<br />그리고 그런 막막한 상황에서 우린 AI의 도움을 어떻게 받을 것인지를 고민해야 한다.</p>\n<p data-ke-size=\"size16\">기존 코드를 분석해서 기능 명세서를 만드는 것도,<br />로그를 분석해서 테스트 코드를 만드는 것도,<br />암호 같던 PO/PM의 기획서를 분석하는 것도,<br />예전이라면 며칠씩 걸릴 것 같던 레거시 분석 + 기존 기능 수정이 이제는 단 몇시간만에 해결될 수 있는 상황이다.</p>\n<p data-ke-size=\"size16\">근데 레거시에 어떻게 AI의 도움을 받을 것인지도 공부해야 할 대상이 아닌가?</p>\n<hr data-ke-style=\"style1\" />\n<p data-ke-size=\"size16\">이번에 재민님의 레거시와 AI 활용편 강의가 출시되었다.<br />재민님은 17년차 개발자로, 토스페이먼츠 기술이사(Director of Engineering), 우아한형제들 서버 개발자 등을 거치며 레거시가 가득한 수많은 상황을 경험하고 해결해온 시니어이다.</p>\n<p data-ke-size=\"size16\">그리고 이젠 어떻게 하면 AI의 도움을 받으며 레거시 해결과 비즈니스 속도감을 유지하는지에 대해 노하우를 나누어 주신다.</p>\n<p data-ke-size=\"size16\">딱 9시간이면 \"막막한 레거시 환경에서 어떻게 적응하고 성과를 낼 것인가\" 에 대해 재민님의 노하우를 배워볼 수 있다.</p>\n<p data-ke-size=\"size16\">새 회사에, 새 팀에 합류해야 할 개발자분들이나,<br />현재 기술 부채가 있는 환경에서 일하고 있는 개발자분들이라면 이번 재민님의 강의를 적극 추천한다.</p>\n<p data-ke-size=\"size16\"><a href=\"https://inf.run/ZzaQn\">https://inf.run/ZzaQn</a></p>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">현재 <b>얼리버드로 30% 할인 중</b>이니 할인 기회를 놓치지 않으시길 추천드린다.</p>\n</blockquote>",
        "contentSnippet": "요즘의 개발자 채용은 채용하는 팀과 채용하지 않는 팀으로 완전히 나뉘어 있다.\n비즈니스 속도가 안정권에 들어섰고, 레거시가 충분히 해소된 팀은 개발자 채용을 거의 하지 않는다.\n누군가 퇴사를 해도 그 자리를 채우지 않는다.\n반면, 여전히 비즈니스 속도를 내는 팀은 공격적으로 개발자를 채용하고 있다.\n이런 속도를 유지하는 팀은 기술 부채와 레거시를 계속해서 쌓이는 것으로만 보며, 해결해야 할 대상으로 보지 않는다.\n지금의 인원으로 속도가 점점 떨어진다면, 더 많은 개발자를 채용함으로써 계속해서 그 속도를 유지한다.\n속도를 최우선으로 하면서 쌓이는 부채보다 비즈니스 성장이 떨어지는 것이 더 무서운 일이기 때문이다.\n개발자를 공격적으로 채용하고 있으니 그만큼 개발문화와 개발 환경이 좋을 것이라 예상했으나 첫 온보딩때 그 예상은 산산히 부서진다.\n해당 프로젝트의 히스토리를 아는 개발자는 모두 퇴사한 상태라 알려줄 사람이 없다.\n개발/정책 문서가 없어서 흩어진 슬랙 메시지, 극 초기의 컨셉만 담은 노션의 몇 안되는 페이지들, 주석이 없는 애플리케이션 코드, comment가 없는 테이블 스키마 등을 보면서 분석해야 한다.\n시스템 구조를 알 수 있는 방법이 없어 지금 호출하고 있는 API에 신규 속성을 추가하려면 누구와 이야기해야 할지, 어느 프로젝트를 봐야 할지도 알 수 없다.\n테스트 코드가 없어 지금의 이 코드를 수정하면 무슨 일이 벌어질지 알 수 없다. 테스트 코드를 넣자니 인풋/아웃풋이 무엇이어야 하는지조차 알 수가 없다.\n히스토리와 기능이 전혀 분석이 되지 않는 상태에서 PO/PM은 새로운 기능에 대해 요구사항 분석과 언제까지 가능한지 일정을 알려달라 한다.\n기술 리더는 기술 부채를 해결하는 것 보다 제품지표/비즈니스 성과에 대해서 더 중요하다고 이야기한다. 레거시를 해결할 시간 따위 여기선 별도로 할당 받을 수 없는 상황이다.\n이렇게 레거시가 가득한 환경에선 도저히 일할 수 없을 것 같다는 생각이 매일 출근마다 머릿속을 가득 채운다.\n하지만, 지금의 개발자를 채용하는 대부분의 회사는 이렇게 레거시가 가득할 확률이 높다.\n그렇지 않으면 이미 많은 개발자가 있음에도 더 많은 개발자를 채용할 이유가 요즘에 찾기가 어렵기 때문이다.\n\"레거시 코드 활용 전략\", \"리팩토링 데이터베이스\" 등 점진적으로 레거시를 해소할 여러 노하우가 담긴 책들이 많다.\n하지만, 이 책을 지금 읽어보고 현재의 내 상황에 하나하나 대입하기엔 시간이 너무 부족하다.\n수습 기간의 카운트다운은 이미 시작되었다.\n조직에서는 새로 합류한 나에 대한 평가를 계속해서 하고 있는 상황에서, \"레거시가 심해서 도저히 일할 수가 없어요\"라고만 말할 수도 없다.\n그렇게 얘기했다가는 이 사람들이 나와 함께 할 필요가 없어지니.\n막막한 이 상황을 도대체 어디서부터 풀어나가야 할까?\n다행히 이제는 개발자에겐 AI라는 막강한 도구가 있다.\n개발자를 적극적으로 채용하는 회사로 합류하는 모든 개발자들에겐 레거시 환경과 기술 부채 환경은 기본값으로 봐야한다.\n그리고 그런 막막한 상황에서 우린 AI의 도움을 어떻게 받을 것인지를 고민해야 한다.\n기존 코드를 분석해서 기능 명세서를 만드는 것도,\n로그를 분석해서 테스트 코드를 만드는 것도,\n암호 같던 PO/PM의 기획서를 분석하는 것도,\n예전이라면 며칠씩 걸릴 것 같던 레거시 분석 + 기존 기능 수정이 이제는 단 몇시간만에 해결될 수 있는 상황이다.\n근데 레거시에 어떻게 AI의 도움을 받을 것인지도 공부해야 할 대상이 아닌가?\n이번에 재민님의 레거시와 AI 활용편 강의가 출시되었다.\n재민님은 17년차 개발자로, 토스페이먼츠 기술이사(Director of Engineering), 우아한형제들 서버 개발자 등을 거치며 레거시가 가득한 수많은 상황을 경험하고 해결해온 시니어이다.\n그리고 이젠 어떻게 하면 AI의 도움을 받으며 레거시 해결과 비즈니스 속도감을 유지하는지에 대해 노하우를 나누어 주신다.\n딱 9시간이면 \"막막한 레거시 환경에서 어떻게 적응하고 성과를 낼 것인가\" 에 대해 재민님의 노하우를 배워볼 수 있다.\n새 회사에, 새 팀에 합류해야 할 개발자분들이나,\n현재 기술 부채가 있는 환경에서 일하고 있는 개발자분들이라면 이번 재민님의 강의를 적극 추천한다.\nhttps://inf.run/ZzaQn\n현재 얼리버드로 30% 할인 중이니 할인 기회를 놓치지 않으시길 추천드린다.",
        "guid": "https://jojoldu.tistory.com/859",
        "categories": [
          "생각정리",
          "기술 부채",
          "김재민",
          "레거시",
          "레거시코드 활용 전략",
          "리팩토링 데이터베이스",
          "토스"
        ],
        "isoDate": "2026-01-26T01:22:35.000Z"
      },
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "기다리기",
        "link": "https://jojoldu.tistory.com/858",
        "pubDate": "Sat, 24 Jan 2026 22:20:49 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "https://jojoldu.tistory.com/858#entry858comment",
        "content": "<p data-ke-size=\"size16\">샤워를 할 때 수온 조절이 바로 되지 않을 때가 있다.<br />온수 쪽으로 손잡이를 돌렸는데 따뜻한 물이 나오지 않으면, 조급해져서 곧바로 반대쪽으로 돌리게 된다.<br />그렇게 이리저리 돌리다 보면 정작 어느 방향이 온수인지 알 수 없게 된다.<br />한쪽으로 돌려놓고 조금만 기다리면 될 일인데.</p>\n<p data-ke-size=\"size16\">식사할 때도 비슷한 일이 벌어진다.<br />밥을 먹는 중에는 배부름이 잘 느껴지지 않는다.<br />그러다 잠깐 자리에서 일어나 물을 가져오거나, 다른 일을 하다가 돌아오면 갑자기 배가 부른 것을 느끼게 된다.<br />식사와 포만감 사이에는 시간 지연이 있기 때문이다.<br />이 지연을 모르면 이미 충분히 먹었는데도 계속 먹게 되고, 결국 과식하게 된다.</p>\n<p data-ke-size=\"size16\">우리는 일상에서 이런 '지연'을 자주 경험한다.<br />그리고 대부분의 경우, 그것이 지연이라는 것도 알고 있다.</p>\n<hr data-ke-style=\"style1\" />\n<p data-ke-size=\"size16\">그런데 조직에서는 이 지연을 쉽게 잊는다.</p>\n<p data-ke-size=\"size16\">팀에 리소스가 부족해서 사람을 채용했다고 하자.<br />하지만 그 사람이 지금 당장 팀의 부족함을 채워주진 못한다.<br />조직에 적응하고, 업무 맥락을 익히고, 실제로 역량을 발휘하기까지는 최소 3~6개월의 시간이 필요하다.</p>\n<p data-ke-size=\"size16\">그 사이에도 팀은 여전히 리소스가 부족하다고 느낀다.<br />마치 샤워할 때 온수 손잡이를 돌렸는데 따뜻한 물이 나오지 않는 것처럼.<br />그래서 더 채용한다.<br />또 채용한다.</p>\n<p data-ke-size=\"size16\">그러다 어느 순간, <b>채용한 사람들이 모두 적응을 마치고 본격적으로 역량을 발휘하기 시작</b>한다.<br />그때서야 \"왜 이렇게 사람이 많지?\"라는 생각이 든다.<br />밥 먹을 때는 배부르지 않았는데, 일어나서 돌아오니 배가 터질 것 같은 것처럼.</p>\n<p data-ke-size=\"size16\">새로운 기능을 출시했는데 첫 1~2주간 반응이 좋지 않다고 하자.<br />실패한 걸까?<br />아직 알 수 없다.</p>\n<p data-ke-size=\"size16\"><b>고객이 새로운 기능을 인지하고, 학습하고, 습관처럼 사용하기까지는 생각보다 긴 시간이 필요하다.</b><br />샤워 손잡이를 돌리고 따뜻한 물이 나올 때까지 기다려야 하는 것처럼.</p>\n<p data-ke-size=\"size16\">반대로 출시 직후 반응이 폭발적이었다고 해서 그것이 진짜 성공인지도 모른다.<br />초기의 호기심에 의한 사용인지, 이전에 쌓아둔 기능들이 이제서야 효과를 내기 시작한 것인지, 정말 고객의 문제를 해결해주는 제품인지는 <b>시간이 지나고 사용량이 유지되는지를 봐야만</b> 알 수 있다.</p>\n<p data-ke-size=\"size16\">관계도 마찬가지다.</p>\n<p data-ke-size=\"size16\"><b>동료에게 무례한 말을 했을 때, 그 여파가 바로 나타나지는 않는다.</b><br />한두 번의 실수는 괜찮아 보인다.<br />상대방도 웃어넘기고, 분위기도 별로 나빠지지 않는다.</p>\n<p data-ke-size=\"size16\">하지만 그것이 쌓이면 어느 순간 관계가 무너진다.<br />밥 먹을 때는 배부르지 않았는데, 일어서니 배가 터질 것 같은 것처럼.<br /><b>그때는 이미 늦다</b>.</p>\n<hr data-ke-style=\"style1\" />\n<p data-ke-size=\"size16\"><b>행동과 결과 사이에는 항상 어느 정도의 지연이 있다</b>.</p>\n<p data-ke-size=\"size16\">지금 느끼는 불안이나 조급함을 해소하려고 같은 행동을 계속 반복하면, 나중에 그 행동들이 한꺼번에 쏟아져 새로운 문제가 된다.</p>\n<p data-ke-size=\"size16\">샤워할 때는 손잡이를 돌려놓고 잠시 기다릴 줄 안다.<br />식사할 때는 천천히 먹으면 과식을 피할 수 있다는 것도 안다.</p>\n<p data-ke-size=\"size16\">조직에서도 그렇게 해보자.<br />채용을 했다면, 그 사람이 자리 잡을 시간을 주자.<br />기능을 출시했다면, 고객이 적응할 시간을 주자.<br />관계에서 실수를 했다면, 지금 당장 괜찮아 보여도 되돌아보자.</p>\n<p data-ke-size=\"size16\">행동을 했다면, 조금은 기다려보자.</p>",
        "contentSnippet": "샤워를 할 때 수온 조절이 바로 되지 않을 때가 있다.\n온수 쪽으로 손잡이를 돌렸는데 따뜻한 물이 나오지 않으면, 조급해져서 곧바로 반대쪽으로 돌리게 된다.\n그렇게 이리저리 돌리다 보면 정작 어느 방향이 온수인지 알 수 없게 된다.\n한쪽으로 돌려놓고 조금만 기다리면 될 일인데.\n식사할 때도 비슷한 일이 벌어진다.\n밥을 먹는 중에는 배부름이 잘 느껴지지 않는다.\n그러다 잠깐 자리에서 일어나 물을 가져오거나, 다른 일을 하다가 돌아오면 갑자기 배가 부른 것을 느끼게 된다.\n식사와 포만감 사이에는 시간 지연이 있기 때문이다.\n이 지연을 모르면 이미 충분히 먹었는데도 계속 먹게 되고, 결국 과식하게 된다.\n우리는 일상에서 이런 '지연'을 자주 경험한다.\n그리고 대부분의 경우, 그것이 지연이라는 것도 알고 있다.\n그런데 조직에서는 이 지연을 쉽게 잊는다.\n팀에 리소스가 부족해서 사람을 채용했다고 하자.\n하지만 그 사람이 지금 당장 팀의 부족함을 채워주진 못한다.\n조직에 적응하고, 업무 맥락을 익히고, 실제로 역량을 발휘하기까지는 최소 3~6개월의 시간이 필요하다.\n그 사이에도 팀은 여전히 리소스가 부족하다고 느낀다.\n마치 샤워할 때 온수 손잡이를 돌렸는데 따뜻한 물이 나오지 않는 것처럼.\n그래서 더 채용한다.\n또 채용한다.\n그러다 어느 순간, 채용한 사람들이 모두 적응을 마치고 본격적으로 역량을 발휘하기 시작한다.\n그때서야 \"왜 이렇게 사람이 많지?\"라는 생각이 든다.\n밥 먹을 때는 배부르지 않았는데, 일어나서 돌아오니 배가 터질 것 같은 것처럼.\n새로운 기능을 출시했는데 첫 1~2주간 반응이 좋지 않다고 하자.\n실패한 걸까?\n아직 알 수 없다.\n고객이 새로운 기능을 인지하고, 학습하고, 습관처럼 사용하기까지는 생각보다 긴 시간이 필요하다.\n샤워 손잡이를 돌리고 따뜻한 물이 나올 때까지 기다려야 하는 것처럼.\n반대로 출시 직후 반응이 폭발적이었다고 해서 그것이 진짜 성공인지도 모른다.\n초기의 호기심에 의한 사용인지, 이전에 쌓아둔 기능들이 이제서야 효과를 내기 시작한 것인지, 정말 고객의 문제를 해결해주는 제품인지는 시간이 지나고 사용량이 유지되는지를 봐야만 알 수 있다.\n관계도 마찬가지다.\n동료에게 무례한 말을 했을 때, 그 여파가 바로 나타나지는 않는다.\n한두 번의 실수는 괜찮아 보인다.\n상대방도 웃어넘기고, 분위기도 별로 나빠지지 않는다.\n하지만 그것이 쌓이면 어느 순간 관계가 무너진다.\n밥 먹을 때는 배부르지 않았는데, 일어서니 배가 터질 것 같은 것처럼.\n그때는 이미 늦다.\n행동과 결과 사이에는 항상 어느 정도의 지연이 있다.\n지금 느끼는 불안이나 조급함을 해소하려고 같은 행동을 계속 반복하면, 나중에 그 행동들이 한꺼번에 쏟아져 새로운 문제가 된다.\n샤워할 때는 손잡이를 돌려놓고 잠시 기다릴 줄 안다.\n식사할 때는 천천히 먹으면 과식을 피할 수 있다는 것도 안다.\n조직에서도 그렇게 해보자.\n채용을 했다면, 그 사람이 자리 잡을 시간을 주자.\n기능을 출시했다면, 고객이 적응할 시간을 주자.\n관계에서 실수를 했다면, 지금 당장 괜찮아 보여도 되돌아보자.\n행동을 했다면, 조금은 기다려보자.",
        "guid": "https://jojoldu.tistory.com/858",
        "categories": [
          "생각정리",
          "리더십",
          "스타트업",
          "조직 생활",
          "채용",
          "학습하는 조직"
        ],
        "isoDate": "2026-01-24T13:20:49.000Z"
      }
    ]
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": [
      {
        "creator": "dlehddus84",
        "title": "아르낙 빅박스 모험의 궤의 검은 석판 도색",
        "link": "https://blog.naver.com/dlehddus84/224160512478?fromRss=true&trackingCode=rss",
        "pubDate": "Mon, 26 Jan 2026 19:14:30 +0900",
        "author": "dlehddus84",
        "content": "기존 아르낙의 석판을 도색했는데 원래는 아이보리 색인데 석판 느낌 낸다고 회색으로 도색했는데 이번에 검은색 석판이 나왔다... 드라이브러싱을 회색으로 해버리면 서로 컴포가 비슷한 색으로 수렴하기에 이번 검은석판은 글자 부분에만 붉은 색을 넣어주는식으로 마무리 해주었다. 프라이밍도 건너뛰고 음각이 있는 부분에 색을 칠해줄거라 마감제도 하지 않았다. ak사의 Deep Red로 글자부분을 2회 칠해주었다. 어짜피 벗어난 부분은 다 지워줄것이기에 삐져나오는것에 신경쓰지 말고 잘 칠해주었다. 그리고 삐저나온 부분을 지워주었다. 화장솜에 아크릴 물감을 녹일 수 있는 용액으로 지우면 된다. 나는 이소프로필알코올을 대량사놓은것....... <img src=\"https://blogthumb.pstatic.net/MjAyNjAxMjZfMTc0/MDAxNzY5NDIyMDkzNjQz.q4V3ZPeEAcRpHo0H5OOi0H7MyaOpeuzQ_XE7pKzCni0g.VLH1VJKXgthz5_6pwaWggITptuFfUhix8N-GfyoEPuUg.JPEG/KakaoTalk_20260126_190220817.jpg?type=s3\" />",
        "contentSnippet": "기존 아르낙의 석판을 도색했는데 원래는 아이보리 색인데 석판 느낌 낸다고 회색으로 도색했는데 이번에 검은색 석판이 나왔다... 드라이브러싱을 회색으로 해버리면 서로 컴포가 비슷한 색으로 수렴하기에 이번 검은석판은 글자 부분에만 붉은 색을 넣어주는식으로 마무리 해주었다. 프라이밍도 건너뛰고 음각이 있는 부분에 색을 칠해줄거라 마감제도 하지 않았다. ak사의 Deep Red로 글자부분을 2회 칠해주었다. 어짜피 벗어난 부분은 다 지워줄것이기에 삐져나오는것에 신경쓰지 말고 잘 칠해주었다. 그리고 삐저나온 부분을 지워주었다. 화장솜에 아크릴 물감을 녹일 수 있는 용액으로 지우면 된다. 나는 이소프로필알코올을 대량사놓은것.......",
        "guid": "https://blog.naver.com/dlehddus84/224160512478",
        "categories": [
          "도색과 제작"
        ],
        "isoDate": "2026-01-26T10:14:30.000Z"
      },
      {
        "creator": "dlehddus84",
        "title": "군제 프로콘 보이 직구",
        "link": "https://blog.naver.com/dlehddus84/224158032060?fromRss=true&trackingCode=rss",
        "pubDate": "Sat, 24 Jan 2026 12:11:50 +0900",
        "author": "dlehddus84",
        "content": "10년 전부터 입문용으로 써오던 에어브러쉬가 아직도 잘 되는데 스팩을 좀 높이고 싶어서 가성비 제품으로 일마존에서 직구했다. 국내 가격이랑 차이가 많이 나서 직구를 하면 가격을 많이 저렴하게 살 수 있다. 일단 네이버에 군제 프로콘 보이를 검색했을때 나오는 가격이다. 내가 구매할것은 3호로 범용적으로 쓰기 좋은 모델이다. 정확히는 3호 WA 플래티넘 Ver.2 더블액션 모델을 구입할 예정인데 네이버 쇼핑에서는 15만원 후반대에 가격이 형성되어 있다. 엔화도 그리 비싸지 않아서 일마존에서 해당 제품을 찾아봤다. 세부 모델명인 PS289로 검색해도 나온다. 배송비를 제외하면 11520엔으로 원화로는 10만7천원 정도 나오는데 많이 저렴....... <img src=\"https://blogthumb.pstatic.net/MjAyNjAxMjRfNjgg/MDAxNzY5MjIzMDQ3MzE2.wMSxwpy1IYwgFvjKLn4I2pEH2YEx-XM7Ifuu0ahn1ZAg.Kh7XJshlfCbZ0fbEE0MYNIC6POJWC7cWpsQMdnczZ3Ug.JPEG/%C8%AD%B8%E9_%C4%B8%C3%B3_2026-01-24_114703.jpg?type=s3\" />",
        "contentSnippet": "10년 전부터 입문용으로 써오던 에어브러쉬가 아직도 잘 되는데 스팩을 좀 높이고 싶어서 가성비 제품으로 일마존에서 직구했다. 국내 가격이랑 차이가 많이 나서 직구를 하면 가격을 많이 저렴하게 살 수 있다. 일단 네이버에 군제 프로콘 보이를 검색했을때 나오는 가격이다. 내가 구매할것은 3호로 범용적으로 쓰기 좋은 모델이다. 정확히는 3호 WA 플래티넘 Ver.2 더블액션 모델을 구입할 예정인데 네이버 쇼핑에서는 15만원 후반대에 가격이 형성되어 있다. 엔화도 그리 비싸지 않아서 일마존에서 해당 제품을 찾아봤다. 세부 모델명인 PS289로 검색해도 나온다. 배송비를 제외하면 11520엔으로 원화로는 10만7천원 정도 나오는데 많이 저렴.......",
        "guid": "https://blog.naver.com/dlehddus84/224158032060",
        "categories": [
          "도색과 제작"
        ],
        "isoDate": "2026-01-24T03:11:50.000Z"
      }
    ]
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "코드 품질 개선 기법 30편: (투명한) 운명의 붉은 실",
        "link": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-30",
        "pubDate": "Fri, 23 Jan 2026 08:00:00 GMT",
        "content": "이 글은 2024년 6월 20일에 일본어로 먼저 발행된 기사를 번역한 글입니다.LY Corporation은 높은 개발 생산성을 유지하기 위해 코드 품질 및 개발 문화 개선에 힘쓰고...",
        "contentSnippet": "이 글은 2024년 6월 20일에 일본어로 먼저 발행된 기사를 번역한 글입니다.LY Corporation은 높은 개발 생산성을 유지하기 위해 코드 품질 및 개발 문화 개선에 힘쓰고...",
        "guid": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-30",
        "isoDate": "2026-01-23T08:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": [
      {
        "title": "뱅크샐러드의 첫 웰컴키트 제작기",
        "link": "https://blog.banksalad.com/pnc/banksalad-welcome-kit/",
        "pubDate": "Fri, 23 Jan 2026 00:00:00 GMT",
        "content": "뱅크샐러드에 웰컴키트가 없었다고? 뱅크샐러드에는 한동안 웰컴키트가 없었습니다. 의외라고 느끼는 분들도 계실지 모르겠어요. 웰컴키트 프로젝트를 진행한 두 디자이너 모두 202…",
        "contentSnippet": "뱅크샐러드에 웰컴키트가 없었다고? 뱅크샐러드에는 한동안 웰컴키트가 없었습니다. 의외라고 느끼는 분들도 계실지 모르겠어요. 웰컴키트 프로젝트를 진행한 두 디자이너 모두 202…",
        "guid": "https://blog.banksalad.com/pnc/banksalad-welcome-kit/",
        "isoDate": "2026-01-23T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "기세",
        "link": "https://www.thestartupbible.com/2026/01/confidence-and-swag.html",
        "pubDate": "Sun, 25 Jan 2026 21:28:00 +0000",
        "content:encodedSnippet": "창업가나 투자자라면 ‘피칭’이라는 말이 너무나 익숙할 것이다. 창업가라면 투자받기 위해서 VC들을 대상으로 셀 수 없을 정도로 사업에 관해서 설명하는 피칭을 했을 것이다. 우리도 작년에 수백 개의 피칭을 듣고 봤다. 그런데 우리 같은 VC도 투자하기 위해서는 남의 투자를 받아야 해서 우리도 펀드레이징을 하고, 꽤 많은 피칭을 한다. 우리는 작년 9월에 새로운 펀드를 만들었는데, 나중에 통계를 내보니까 이 펀드를 만들기 위해서 180명이 넘는 투자자를(=LP) 대상으로 피칭했다. 어떤 분들은 그냥 줌으로 한 번 온라인 미팅만 했지만, 어떤 해외 투자자는 10번 이상 대면 미팅한 경우도 있었다.\n물론, 이들이 스트롱에게 모두 다 돈을 준 건 아니다. 이 중 일부만 우리에게 출자했고, 대부분의 미팅을 전쟁에 임하는 태도로 열심히, 에너지 넘치게, 그리고 기세 넘치게 진행했기 때문에, 특히나 우리에게 자금을 출자한 분들과의 미팅은 아직도 머릿속에 생생하게 기억한다. 이 중 기억에 남는 미팅이 하나 있는데, 당시의 상황을 간략하게 설명하면, 펀드를 마무리해야 하는 데드라인이 몇 주 안 남았었고, 이 투자자의 돈은 꼭 받아야만 하는 상황이었다. 그런데 실은, 이미 이 투자자에게 과거에 두 번 피칭했다 두 번 모두 거절당했기 때문에, 세 번째 시도는(=삼수) 마지막 기회였다. 절박함에 대해서 우리는 자주 이야기하는데, 당시 내 심정은 절박함 그 자체였고, 정말로 비장한 각오로 줌 피칭 미팅을 시작했다.\n피칭하기 바로 전날 밤으로 상황을 리와인드 해보자. 실은 발표해야 하는 내용은 내가 14년 동안 직접 해왔던 거라서 아주 익숙했지만, 그래도 나는 전날 밤에 10번 연달아서 리허설을 했다. 약 20분 정도의 발표이니 거의 세 시간을 같은 내용을 미친 사람처럼 달달 다시 연습했던 것이다. 줌으로 파워포인트 발표를 해본 분들은 잘 아시겠지만, 화면 공유할 때 파워포인트의 포인터/펜 기능이 가끔 충돌을 일으킬 때가 있고, 강조해야 할 부분을 빨간펜으로 체크하면서 발표하다 보면 그다음 슬라이드로 넘어가지 않는 알려진 문제점도 있다. 나는 발표의 흐름을 끊을 수 있는 이런 문제점들을 사전에 모두 방지하기 위해서, 그 전날 10번 리허설을 상대편에는 아무도 없지만, 실제로 줌을 켜고 라이브로 연습했다. 그리고 연습하면서 파워포인트의 포인터 -> 펜 -> 줌의 화면 공유 상에서의 페이지 넘기기, 이 전환이 매끄럽게 될 수 있게 충분히 연습했다.\n다시 실제 피칭하는 순간으로 패스트포워드 해보자. 전날 연습을 충분히 했기 때문에 나는 자신감이 넘쳤고, 이번에도 돈을 못 받는 건 고려 대상이 아니라는 벼랑 끝에 선 각오로 엄청나게 기세 있게 발표했다. 온라인이고 작은 노트북 화면에서 발표하는 거지만, 반대편에 보이는 약 10명의 청중의 눈을 하나씩 맞추려고 노력했고, 엄청난 기세를 이들에게 100% 전달하겠다는 각오로 거의 샤우팅 하듯이 피칭했다. 그리고 이분들에게 우리는 돈을 받았다는 해피엔딩으로 이 피칭 이야기는 끝난다.\n나중에, 이 LP들에게 들었다. 화면으로만 나를 보고 들었지만, 정말로 스트롱이 돈을 꼭 받아야겠다는 독기를 품었다는 각오가 강하게 느껴졌고, 정말 그 엄청난 기세가 줌 화면을 통해서도 생생하게 온몸으로 전달됐다고.\n“인생은 기세다.”라는 말을 우리는 자주 한다. 밑바닥에서 시작해서 성공한 연예인들이 이 말을 하는 것을 나는 자주 들었다. 그런데 나도 좀 살아보고, 일도 좀 해보고, 투자도 좀 해보니 정말로 이 기세가 중요하다는 걸 느끼고 있다. 창업도 기세, 펀드레이징도 기세, 글로벌 진출도 기세, 심지어 우리 같은 VC가 하는 벤처 투자도 기세다. 이 모든 게 안 될 이유가 백만 가지가 있는, 했다 하면 실패할 게 거의 뻔한 일들이다. 그 와중에 되게 만들어야 하고, 되게 할 이유를 찾아야 하는데, 이건 자신감과 기세가 없으면 매우 힘든 일이다. 우리 주변에 불가능을 가능케 하는 사람들을 보면, 가끔 나는 이들이 짐승 같다고 생각한다. 그만큼 본인들이 목표하는 걸 무조건 해야겠다는 의지와 이를 막는 사람들은 모두 다 짐승같이 씹어 먹어버리겠다는 기세가 보이기 때문이다.\n기세는 실제로 그 일을 하는 사람에게 발동을 걸고, 누가 봐도 안 될 일을 계속 시도하게 만드는 희망과 에너지의 원동력이다. 하지만, 기세는 그 일을 하는 사람의 힘든 여정을 같이 하는 주변 사람들에게도 전류와 같이 흐르면서 안 될 일을 되게 만드는 방향으로 기운을 흐르게 만들 수도 있다고 생각한다. 내가 피칭할 때 내 기세가 분명히 발표를 듣는 분들에게도 전달됐고, 이들의 결정에 긍정적인 영향을 미쳤다고 나는 믿는다.\n그럼, 이 기세는 어디서 나오는 건가? 내 경험에 의하면 기세는 누구나 다 후천적으로 습득할 수 있는 기술이자 자산이다. 기세는 자신감에서 나온다. 그럼, 자신감은 어디서 나오나? 결국엔 수년, 수십 년 동안 반복하는 좋은 습관과 연습에서 나온다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2026/01/confidence-and-swag.html#respond",
        "content": "창업가나 투자자라면 ‘피칭’이라는 말이 너무나 익숙할 것이다. 창업가라면 투자받기 위해서 VC들을 대상으로 셀 수 없을 정도로 사업에 관해서 설명하는 피칭을 했을 것이다. 우리도 작년에 수백 개의 피칭을 듣고 봤다. 그런데 우리 같은 VC도 투자하기 위해서는 남의 투자를 받아야 해서 우리도 펀드레이징을 하고, 꽤 많은 피칭을 한다. 우리는 작년 9월에 새로운 펀드를 만들었는데, 나중에 통계를 내보니까(...)",
        "contentSnippet": "창업가나 투자자라면 ‘피칭’이라는 말이 너무나 익숙할 것이다. 창업가라면 투자받기 위해서 VC들을 대상으로 셀 수 없을 정도로 사업에 관해서 설명하는 피칭을 했을 것이다. 우리도 작년에 수백 개의 피칭을 듣고 봤다. 그런데 우리 같은 VC도 투자하기 위해서는 남의 투자를 받아야 해서 우리도 펀드레이징을 하고, 꽤 많은 피칭을 한다. 우리는 작년 9월에 새로운 펀드를 만들었는데, 나중에 통계를 내보니까(...)",
        "guid": "https://www.thestartupbible.com/?p=9672",
        "categories": [
          "Uncategorized",
          "compounding",
          "failure",
          "FoundersAtWork",
          "fundraising",
          "hustle",
          "inspiring",
          "Strong",
          "vc"
        ],
        "isoDate": "2026-01-25T21:28:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "철면피",
        "link": "https://www.thestartupbible.com/2026/01/you-always-need-to-be-thick-skinned-and-shameless.html",
        "pubDate": "Wed, 21 Jan 2026 21:34:00 +0000",
        "content:encodedSnippet": "본인이 얼굴이 두꺼운 철면피이거나, 또는 주변에 이렇게 얼굴이 두꺼운 철면피 친구와 지인이 항상 몇 명씩 누구나 있을 것이다. 철면피는 말 그대로 얼굴이 두꺼워서 남의 비판을 신경 쓰지 않는 뻔뻔한 사람을 뜻하는데, ‘얼굴에 철판을 깔았다’라는 말도 우리는 자주 사용한다. 이 말은 어떻게, 언제 쓰이냐에 따라 긍정적인 의미를 가질 수도 있고, 부정적인 의미를 가질 수도 있는데, 오늘은 아주 긍정적인 의미에서의 철면피에 대해서 이야기해 보려고 한다.\n얼마 전에 미국의 슈퍼 어디에서나 볼 수 있는 저당 간식 스키니딥드(SkinnyDipped)의 창업 이야기를 팟캐스트로 들었다. 초코 코팅 아몬드인데, 주로 다크초콜릿을 사용하고 코팅을 아주 얇게 해서 다른 간식보다 당과 열량이 낮은 제품인데, 모든 창업 이야기가 웬만한 TV 드라마보다 드라마틱하듯이, 이 회사의 이야기도 너무 재미있었다. 이 회사의 창업 초기에는 내가 다른 스타트업의 창업 초기에서도 항상 발견하는 공통점이 있었는데, 바로 창업가들의 철면피와 뻔뻔스러움이다. 엄마와 딸이 창업한 회사인데 제품을 오프라인 유통업체에 입점시키기 위해서 초반에는 두 분이 별의별 짓을 다 했다. 일단 Whole Foods 입점을 위해 간식 담당자를 만나기 위해서 매일 매장에서 하염없이 기다린 이야기도 있고(우리가 투자한 회사의 대표도 실제로 이렇게 한 적이 있는데, 이건 요새도 잘 먹히는 방법이다.), 더 재미있었던 에피소드는 회사의 본사가 있던 시애틀의 구글 건물에 몰래 들어가서, 구내식당에서 어슬렁거리면서 쉐프를 찾았고, 스키니딥드 제품을 구글 직원들에게 간식으로 제공해야 한다고 설득한 이야기다.\n이런 두꺼운 낯짝으로 고객사, 투자사, 협력사에 쳐들어가는 건 내가 아는 매우 많은 창업가가 창업 초기에 했던할 수밖에 없었던 공통된 필수 코스인데, 실제로 사업을 하다 보면 누구나 다 이렇게 해야 하는 시점이 있다. 그리고 정말 성공하고 싶다면 모든 창업가들이 이렇게 철면피를 깔고, 일반인들은 쪽팔려서 절대로 하지 못하는, 그런 일들을 해야 한다.\n나도 오래전에 영업하면서 철면피 영업을 했었고, 뮤직쉐이크를 하면서도 여러 번 이런 경험이 있고, 스트롱을 처음 시작할 때도 그냥 여기저기 쳐들어가서 달성하고자 하는 일을 시도해 본 적이 있다. 모든 쳐들어감이 성공하진 못했고, 어떤 경우에는 철면피가 찢어지기도 했지만, 어쨌든 나는 정말 간절했고, 그 간절함이 당시에 이런 두꺼운 낯짝을 형성해 준 것 같다.\n나도 이런 경험을 직접 해봤기 때문에 우리 투자사 대표님들에게도 가끔 이렇게 해야 한다고 하는데, 많은 분들이 “저는 그런 거 원래 못해요” , “뭐, 그렇게까지 해야 하나요?”라는 말을 한다. 나는 “네, 그렇게까지 해야 합니다.”라고 하지만, 실제로 철면피를 깔고 행동할 수 있는 분들은 그렇게 많지 않다.\n그런데 이분들이 잘 모르는 사실이 하나 있다. 위에서 말한 스키니딥드 창업가나 과거의 나 같은 사람도 태어날 때부터 쪽팔림을 모르고, 남의 시선을 신경 쓰지 않고, 철면피였던 건 아니다. 이들도 당연히 안 만나주려고 하는 사람들의 사무실에 불쑥 쳐들어가거나, 누가 건물의 출입구를 열어주기를 하염없이 추위에서 기다리거나, 안 사겠다고 하는 잠재 고객사 대표의 새벽 출근길 자가용의 문을 기사님 대신 매일 열어주고 인사하는 짓을 너무너무 즐겁고 기쁘게 하진 않을 것이다. 이들에게도 아주 창피하고, 자존심 상하고, 하기 싫은 일이지만, 해야 하니까 하는 것이다.\n모든 창업가에겐 어느 정도의 철면피가 꼭 필요하다고 나는 생각한다. 이들이 회사를 처음 창업하고, 회사가 어느 정도 궤도에 올라가기 전까지는 대부분 투자자들이 만나고 싶지 않거나 관심 없는 사람이고, 협력업체들이 협업하고 싶지 않거나 관심 없는 사람이고, 좋은 잠재 임직원분들이 만나고 싶지 않거나 관심 없는 사람인데, 나를 만나기 싫거나 나에게 관심이 없는 사람과 만나서 이야기할 수 있는 유일한 방법은 그냥 얼굴에 철판 깔고 쳐들어가는 것이다. 아주 힘들고, 아주 쪽팔리고, 아주 자존심 상하고, 굳이 이렇게까지 해야 하나 생각이 드는, 그런 행동이지만, 사업을 하기 위해서는 필요한 일이다. 왜냐하면, 이렇게 무리수를 둬서 일단 만나면 그 이후에 안 될 일도 되는 것을 나는 직접 경험해봤고, 여러 번 옆에서 목격했기 때문이다.\n다시 한번 강조한다. 그 누구도 철면피를 갖고 태어나진 않았다. 꼭 필요하고, 꼭 해야 하니까 낯짝을 두껍게 만든 것이다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2026/01/you-always-need-to-be-thick-skinned-and-shameless.html#comments",
        "content": "본인이 얼굴이 두꺼운 철면피이거나, 또는 주변에 이렇게 얼굴이 두꺼운 철면피 친구와 지인이 항상 몇 명씩 누구나 있을 것이다. 철면피는 말 그대로 얼굴이 두꺼워서 남의 비판을 신경 쓰지 않는 뻔뻔한 사람을 뜻하는데, ‘얼굴에 철판을 깔았다’라는 말도 우리는 자주 사용한다. 이 말은 어떻게, 언제 쓰이냐에 따라 긍정적인 의미를 가질 수도 있고, 부정적인 의미를 가질 수도 있는데, 오늘은(...)",
        "contentSnippet": "본인이 얼굴이 두꺼운 철면피이거나, 또는 주변에 이렇게 얼굴이 두꺼운 철면피 친구와 지인이 항상 몇 명씩 누구나 있을 것이다. 철면피는 말 그대로 얼굴이 두꺼워서 남의 비판을 신경 쓰지 않는 뻔뻔한 사람을 뜻하는데, ‘얼굴에 철판을 깔았다’라는 말도 우리는 자주 사용한다. 이 말은 어떻게, 언제 쓰이냐에 따라 긍정적인 의미를 가질 수도 있고, 부정적인 의미를 가질 수도 있는데, 오늘은(...)",
        "guid": "https://www.thestartupbible.com/?p=9670",
        "categories": [
          "Uncategorized",
          "consumer",
          "FoundersAtWork",
          "hustle"
        ],
        "isoDate": "2026-01-21T21:34:00.000Z"
      }
    ]
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "이자는 언제 기회가 되고, 언제 위기가 될까?",
        "link": "https://toss.im/tossfeed/article/behindthemoney-15",
        "pubDate": "Tue, 20 Jan 2026 09:20:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}압박: 빌린 것보다 더 많이 갚던 시대\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1kxrhf3{white-space:pre-wrap;}“그런 난리판에도 부자들만은 흉년 덕을 톡톡히 보았거든.”\n“흉년 덕이라뇨?”\n“땅값이 워낙 싸졌으니 그렇지. 당장 굶어 죽는 판에 논밭이 쓸 데 있는가! 그저 지낼 만한 댁에 가서 흰죽 한두 그릇 얻어먹고는 두서너 마지기씩 척척 바쳤거든. 실은 네 칠촌댁 재산도 거의 그때 걸태질해 들인 것이지만 말야. 우리도 논마지기 종이 갖다 바쳤지...”\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}-김정한, 《사하촌》 중, 1936\n김정한의 소설 《사하촌》을 보면 일제강점기 소작제도의 현실이 얼마나 고단했는지가 잘 묘사된다. 풍년이면 쌀값이 싸져서 돈을 못벌고, 흉년이면 내다 팔 쌀이 없어서 돈을 못벌었다. 조선 후기 민중들의 삶은 팍팍하기 그지없었다. 그래도 삶은 계속되어야 하고 자식들은 먹여살려야 하지 않겠는가. 오늘날 우리가 대출 이자에 시달리듯 그때의 민중들은 동네 양반지주들에게 땅과 쌀을 빌렸다. 그런데 이게 문제였다. 당시 ‘장리’라고 불렸던 이자가 너무 컸기 때문이다. \n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}‘1년에 5할’, 보릿고개 시절 쌀을 빌리면 50%를 더하여 갚는 방식인데 ‘십오지사채’라고도 불렸다. 자기 땅을 가지고 있으면 20%의 세금을 내지만 땅을 빌리면 이자를 두 배 이상을 내야 했다. 비율제였기 때문에 쌀 100석을 생산하면 50석, 150석을 생산하면 75석을 내야하는 식이었다. 식량이 부족한 봄철, 이른바 춘궁기에 쌀을 빌리면 또다시 50%의 이자가 붙었다. 그 결과 추수 때가 되면 생산량의 60~80%를 이자로 내야 하는 경우도 적지 않았다. 임술농민봉기(1862), 동학농민운동(1894) 등 구한말 농민들의 저항이 계속된 이유도 결국은 무자비한 이자 때문이었다.\n소작 문제는 일제강점기 들어 더욱 악화되었다. 제국주의 본국에서 식민지 백성들의 고통에 무슨 관심이 있겠는가. 순사들은 모른 척으로 일관했고 총독부는 지주 편이었기 때문에 농민은 소작권마저 보장받지 못했다. 소설 《사하촌》에서는 갑자기 소작권을 빼앗겨서 어려움을 겪게 되는 농민 이야기부터 위에 나온 것처럼 빚을 감당하지 못하다 자신의 땅마저 빼앗기는 온갖 비극적인 이야기가 담겨있다.\n이자는 시대마다 다른 이름으로 불려 왔지만, 그 역사는 오래됐다. ‘돈놀이’나 ‘사채’ 같은 표현이 말해주듯, 돈을 빌려주고 이자를 받는 행위에 대한 경계와 불신은 고대부터 존재해왔다. 돈이나 땅을 빌려주어 이익을 얻는 사람들이 생겨났고, 이자를 감당하며 생계를 이어가는 방식 역시 시대와 지역을 가리지 않고 반복됐다.\n하지만 근대 산업혁명을 거치며 이자의 의미는 달라지기 시작한다. 금융 제도가 정비되고 경제를 운영하는 방식에 대한 이해가 깊어지면서, 이자는 개인 간 거래를 넘어 보다 조직적이고 전문적인 경제 활동의 일부로 자리 잡게 된다. 이 변화의 흐름 속에서, 이자를 다루는 방식으로 시대를 앞서간 ‘지아니니’라는 사람이 있었다.\n기회: 뱅크 오브 아메리카와 백설공주\n아마데오 지아니니(1870~1949)는 이탈리아 이민자 가정에서 태어났다. 미국 남북전쟁 이후 산업화와 국가 재건이 본격화되면서, 많은 이탈리아 이민자들이 미국에 자리를 잡았고 지아니니의 가족도 그중 하나였다. 당시 많은 이민자들이 그렇듯 지아니니 역시 13살의 어린 나이에 일을 시작했고 우연한 기회에 임대사업을 접한 후 장인의 부동산 사업을 도우며 돈의 흐름을 익혀갔다.\n31살이 되던 해 장인이 세상을 떠나자 지아니니는 샌프란시스코에 ‘뱅크 오브 이탈리아(Bank of Italy)’라는 작은 회사를 차렸다. 금융에 대한 이해가 부족하고 신용도가 낮아 기존 은행에서는 담보를 통한 대출이 불가능한 이들을 상대로 한 회사였다. 일종의 틈새시장을 노린 셈이지만, 대출 규모가 낮고 연체 위험 또한 높기 때문에 큰 수익을 보기 어려운 구조이기도 했다.\n2년간 어렵게 회사를 꾸려오던 1906년 4월 18일, 샌프란시스코를 강타한 대지진이 모든 것을 뒤흔들었다. 지아니니는 곧장 은행으로 달려가 200만 달러 규모의 금과 현금, 유가증권 등을 간신히 챙겨 나온다. 이날 지진은 규모 8.3으로, 약 3,000명의 사망자와 도시 인구의 절반을 넘는 23만 명의 이재민을 남긴 미국 역사상 최악의 지진 재해였다. 지진의 여파로 화재가 잇따르면서 지역의 군소 은행들은 무너졌고, 일부 은행은 금고가 녹아내릴 정도였다. 수많은 사람들의 재산이 하루아침에 공중으로 사라졌다.\n하지만 빠른 대응으로 자신과 고객의 자산을 지켜낸 지아니니에게 재난은 기회가 되었다. 그는 샌프란시스코 북쪽 해변 근처 부두에 자리를 잡고 나무 판자와 배럴을 책상 삼아, 삶의 터전을 잃은 사람들을 직접 만났다. 대지진과 화재로 모든 것을 잃은 이탈리아 이민자들에게 기존 은행들은 뻣뻣하게 굴었다. 담보가 없다는 이유로 대출을 거절했기 때문이다.\n하지만 지아니니의 선택은 달랐다. 그는 이민자들의 이야기를 직접 듣고, 사업 계획이 분명하다면 구매 물품을 담보 삼아 대출을 실행했다. 소문은 빠르게 퍼졌고, 작은 술집을 개조해 쓰던 은행은 곧 샌프란시스코 리틀 이탤리의 상징인 콜럼버스타워로 자리를 옮기게 된다. 소상공인의 사정을 이해하고 그에 맞는 금융을 설계한 지아니니의 방식이 힘을 발휘한 순간이었다.\n당시만 하더라도 금융은 미국 동부, 특히 뉴욕의 금융기관들이 꽉 잡고 있었고, 이들은 미국 서부를 변방으로 여겼다. 급변하던 샌프란시스코와 캘리포니아의 경제를 제대로 이해하지 못한 것도 사실이었다. 당시 미국 서부는 뜨거웠다. 일명 골드러시. 수많은 사람들이 몰려 들었고 항구와 철도같은 대단위 사업은 물론이고 이민자를 중심으로 과일, 와인, 통조림 등 농업과 식품산업이 커나가고 있었다. 지진에도 불구하고 재건 붐이 일며 서부는 빠르게 변화하고 있었다.\n20세기 초 호황기와 전쟁기를 거치며 그는 적극적인 대출을 이어갔고, 주법 은행과 국법 은행으로 나뉘어 있던 미국의 금융 시스템을 유연하게 활용해 사업을 빠르게 확장했다. 기존의 사업을 키우고 새로운 은행을 인수합병하는 가운데 그의 은행은 1928년 ‘뱅크 오브 아메리카(Bank of America)’로 이름이 바뀌었으며 이후 미국을 대표하는 금융기관으로 자리 잡는다.\n가난한 이탈리아 이민자를 상대하던 꼬마은행 사업가에서 미국을 대표하는 은행으로 성장하기까지. 지아니니는 합병과 인수를 거듭하며 기업이나 정치권과 교묘히 결탁하는 등 미국 금융계를 시끌벅적하게 만든 인물이기도 하다. 하지만 그의 뚝심과 소외된 영역에 과감히 투자하는 방식은 통했다.\n그는 월트 디즈니 스튜디오의 대출을 주관하기도 했다. 당시만 해도 ‘동화로 만든 만화영화를 누가 보겠느냐’는 인식이 투자자들 사이에서 지배적이었다. 하지만 지아니니는 제작 중이던 영화의 일부를 직접 확인한 뒤, 영화 필름 자체를 담보로 자금을 내주었다. 당시 디즈니는 제작비가 200만 달러 이상 초과되어 난항을 겪고 있었는데, 지아니니의 투자로 탄생한 작품이 바로 《백설공주와 일곱난쟁이》다. \n이후 찰리 채플린을 비롯해 20세기 폭스, 컬럼비아 영화사 등 여러 창작자와 기업이 지아니니의 금융 지원을 받으며 성장했다. 20세기 미국 대중문화사에서 그의 안목있는 투자 방식은 문화 산업의 위상을 바꾸어놓았다고 해도 과언이 아니다.\n질서: 세계의 시선을 한 몸에 받는 FED의 정책\n조선 후기와 일제강점기 조선 농민을 괴롭혔던 소작료, 그리고 산업혁명기 이탈리아 이민자들과 새로운 사업에 도움을 주었던 지아니니의 대출 사업. 두 사례에서 알 수 있듯 '이자'는 매우 이중적인 성격을 지니고 있다. 과도한 이자는 삶을 위협하지만, 이자 수익을 전제로 한 과감한 투자가 없으면 산업은 앞으로 나아가기 어렵다. 생계와 성장, 개인의 삶과 국가 경제. 이자는 이 두 세계가 만나는 지점에서 가장 현실적인 문제이기도 하다.\n아마 이 지점에서 자신의 역할을 가장 분명하게 수행한 인물이 매리너 애클스(Marriner Stoddard Eccles, 1890~1977)일 것이다. 사업가 출신이었던 그는 민주당 정부에서 연방준비제도(이하 연준)*의 위상을 이전과는 다른 차원으로 끌어올린 인물로 평가받는다.\n*미국의 통화금융정책을 수행하는 중앙은행제도, 보통 약자인 FED(Federal Reserve System)로 불린다.\n애클스가 프랭클린 루스벨트 대통령 시절 정부에 합류했을 당시만 해도, 연준은 여전히 19세기의 원칙을 그대로 따르고 있었다. 이른바 ‘진성어음주의’라 불리던 원칙에 따라, 경제활동에 적정한 상업어음을 할인해주는 것이 중앙은행의 역할이라고 여겼기 때문이다. 경제에 직접 개입하기보다는, 실물경제를 조용히 뒷받침하는 역할에 가까웠다.\n하지만 애클스가 살았던 시대는 그야말로 격변의 시기였다. 1929년 대공황으로 대량 실업이 발생했고, 설상가상으로 제2차 세계대전에, 6.25전쟁까지 벌어졌다. 국가도 개인도, 급변하는 정세에 위협받던 시기였다. 애클스가 보기에 적정한 통화정책과 규제정책의 실천은 단순히 나라 경제를 일으키는 것을 넘어 국민들의 삶을 돌보는 중요한 수단이었다. 경기가 침체될 때는 숨통을 틔워주고, 반대로 과열될 때는 속도를 늦춰야 한다는 것이 그의 생각이었다. 시장의 성장을 무작정 뒷받침하기보다, 물가 안정과 지속적인 성장을 함께 관리하는 기준이 필요하다고 보았다.\n애클스는 루스벨트 대통령을 설득했고, 연방준비제도법 개정 등 굵직한 제도 개혁을 이끌어냈다. 무엇보다 그는 연준의 독립과 자율성을 위한 제도적인 방안을 마련하는 데 동분서주했다. 재무부 장관과 차관의 연준 참여를 제한하고, 연준 이사의 교체 주기도 정권 교체에 영향을 받지 않는 방식으로 조정했으며, 대통령의 임기 동안 연준 위원 임명에 제한을 두었다. 즉, 로비스트들에 크게 영향을 받는 정권의 이해 관계를 벗어나 거시적인 경제정책을 추진하기 위한 제도적 기반을 만들었다. 소위 ‘금리 정책’을 통해 국민 경제의 안정을 기하는 방식, 대출 이자의 적정성을 도모하면서 기업과 가계에 도움이 되는 전통이 애클스에 의해 본격화된 것이다.\n침식: 나라를 담보로 한 대출\n조선 말 국가의 재정 상태는 엉망이었다. ‘나라에는 한 달 쓸 비축도 없다’라는 말이 나올 지경이었다. 서양 열강과 청나라, 일본의 간섭을 막으려면 국가 주도의 적극적인 근대화 정책이 필요했다. 하지만 철도를 놓고 전신을 연결하는 대단위 산업을 위해서는 막대한 양의 자금이 필요했고, 조선은 결정적으로 자금이 부족했다.\n이 와중에 1882년 임오군란을 진압하기 위해 청나라 군대가 조선에 파견됐고, 이때 중국의 정치인 이홍장은 자신의 심복인 원세개(위안스카이)를 함께 보낸다. 원세개의 목표는 명확했다. 막대한 자금을 대출해주고 조선을 청나라에 예속시킬 것. 정치력을 극대화하여 일본의 간섭을 뿌리치고 조선을 식민지로 만들 것. 이러한 원칙하에 원세개는 적극적인 차관 정책을 추진하였다.\n1882년 8월 조선은 청나라로부터 50만 냥의 돈을 연이자 8리(0.8%), 거치 7년 상환 조건으로 빌렸다. 개화 정책을 추진하기 위해 빌려온 대규모 차관이었다. 1885년 6월에는 ‘의주전선 조약’을 체결했는데 전신 시설을 위해 5년 거치 20년 기한으로 10만 냥의 차관을 또 빌렸다. 이 조약은 파격적이었다. 이자를 받지 않았기 때문이다. 대신 매년 5,000냥씩 무이자 상환을 하되 상환이 어려울 경우 전선부설권 및 관리권을 청나라가 갖는 것을 조건으로 했다. 1889년이 되면 조선이 청나라에게 빌린 돈이 130만 냥에 달했다.\n당시 조선은 갑신정변 때 피해를 이유로 배상금을 요구했던 일본의 5만 냥을 갚지 못해 세창양행* 같은 해외 기업으로부터 돈을 빌리고 있었다. 하지만 원세개는 끊임없는 내정간섭을 통해 청나라 이외의 나라에서부터 차관을 들여오는 것을 막았고, 그만큼 조선의 시장과 산업을 지배하였다. 물론 이 시도는 1894년 청일전쟁에서 청나라가 일본에 의해 완전히 패배하면서 끝나게 된다. 하지만 이후 일본은 같은 방식으로 조선을 집어삼키는 데 성공한다.\n*1884년 독일 마이어 상사(Meyer 商社)의 제물포 지점으로 설립된 무역상사. 근대화 정책을 명분으로 독일산 기계와 기술자 도입을 담당하며 각종 이권을 확보한 창구 역할을 했다.\n이 사례는 19-20세기 제국주의 국가들이 약소국을 지배해온 전형적인 방식이기도 하다. 자금에 의존하게 한 후, 빚은 점차 통제와 간섭으로 이어졌다. 돈을 빌려 감당할 수 없는 이자의 늪에 빠지는 것은 개인의 생계를 넘어, 때로는 국가의 존망까지 좌우하는 문제로 확장된다.\n사실 대출이자 몇 퍼센트가 올랐냐, 떨어졌냐를 두고 희비가 엇갈리는 것이 평범한 우리의 일상이다. 하지만 금리라는 숫자 뒤에는 언제나 더 큰 이야기가 놓여있다. 앞서 살펴본 네 가지 역사적 사례처럼 정부의 정책, 경기의 흐름, 그리고 국제사회의 변화 같은 구조적인 배경이 있다는 사실을 기억해야 한다. 지아니니와 애클스가 좋은 선례를 만들었던 것처럼, 이자와 금리는 책임 있게 다뤄질 때 기회와 질서가 된다.\n당연한 이야기지만, 좋은 정책을 통해 안정적으로 금리가 관리될 때 사람들은 삶을 잘 꾸리고 미래를 계획해 나갈 수 있다. 그리고 좋은 정책의 출발점에는 ‘세상이 어떻게 흘러가고 변화하는가’를 냉정하게 바라보는 국민들의 시선이 있다. 정부는 언제나 국민의 눈치를 보기 때문이다. 따라서 우리의 시선은 보다 이성적이면서도 공공적인 방향을 가리킬 필요가 있다.",
        "content": "이자가 만들어낸 네 가지 역사적 장면",
        "contentSnippet": "이자가 만들어낸 네 가지 역사적 장면",
        "guid": "https://toss.im/tossfeed/article/behindthemoney-15",
        "isoDate": "2026-01-20T09:20:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]