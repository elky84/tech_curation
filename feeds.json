[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Augustin Popa",
        "title": "What’s New in vcpkg (November 2024)",
        "link": "https://devblogs.microsoft.com/cppblog/whats-new-in-vcpkg-november-2024/",
        "pubDate": "Sat, 23 Nov 2024 19:40:27 +0000",
        "content:encodedSnippet": "This blog post summarizes changes to the vcpkg package manager as part of the 2024.11.16 registry release, 2024-11-12 tool release, as well as changes to vcpkg documentation throughout November. This release includes a command line option to force vcpkg to use classic mode even if a manifest file is found along with bug fixes.\nSome stats for this period:\nThere are now 2,508 total ports available in the vcpkg curated registry. A port is a versioned recipe for building a package from source, such as a C or C++ library.\n20 new ports were added to the curated registry.\n185 updates were made to existing ports. As always, we validate each change to a port by building all other ports that depend on or are depended by the library that is being updated for our 13 main triplets.\n88 contributors made commits (not counting the vcpkg maintainers).\nThe main vcpkg repo has over 6,400 forks and 23,300 stars on GitHub.\nvcpkg changelog (2024.11.16 release)\nThe following changes were made in November:\nAdded a command line option called –classic, which instructs vcpkg to skip looking for a manifest and run in classic mode, even if a manifest file exists in the directory hierarchy. Useful for multi-project codebases where some submodules may want run vcpkg in classic mode, while others do not (PR: Microsoft/vcpkg-tool#1535).\nFixed a bug where vcpkg was claiming that certain builds were failing due to the x-block-origin option (PR: Microsoft/vcpkg-tool#1513).\nOther minor bug fixes.\nDocumentation changes\nAdded documentation for new –classic command line option (PR: Microsoft/vcpkg-docs#423).\nUpdated overlay port documentation to clarify how overlay ports in subdirectories are handled by vcpkg (PR: Microsoft/vcpkg-docs#422).\nOther minor fixes (thanks @bansan85, @dg0yt, and @woopelderly!).\nIf you have any suggestions for our documentation, please submit an issue in our GitHub repo or see the box at the bottom of a particular article.\n\nTotal ports available for tested triplets\ntriplet\nports available\n\n\nx64-windows\n2,389\n\n\nx86-windows\n2,261\n\n\nx64-windows-static\n2,259\n\n\nx64-windows-static-md\n2,305\n\n\narm64-windows\n1,978\n\n\nx64-uwp\n1,319\n\n\narm64-uwp\n1,287\n\n\nx64-linux\n2,362\n\n\nx64-osx\n2,234\n\n\narm64-osx\n2,152\n\n\narm-neon-android\n1,646\n\n\nx64-android\n1,722\n\n\narm64-android\n1,695\n\n\n\nWhile vcpkg supports a much larger variety of target platforms and architectures (as community triplets), the list above is validated exhaustively to ensure updated ports don’t break other ports in the catalog.\nThank you to our contributors\nvcpkg couldn’t be where it is today without contributions from our open-source community. Thank you for your continued support! The following people contributed to the vcpkg, vcpkg-tool, or vcpkg-docs repos in this release (listed alphabetically by GitHub username):\n17steen\nADKaster\nAenBleidd\nagl-alexglopez\nalagoutte\nalbertony\nalfredh\naluaces\naminya\nandre-nguyen\nankurvdev\nAnyOldName3\nautoantwort\nazure-sdk\nbansan85\nblavallee\nbraindigitalis\nbuck-yeh\nbw-hro\nc8ef\ncenit\nDanAlbert\ndaniele77\nDeishelon\ndg0yt\ndonny-dont\neao197\neclipse0922\nelsid\nerikyuzwa\ng-maxime\ngavinltomra\nHisuianZoroark69\nHoneybunch\nhuangqinjin\nlrineau\nJacobBarthelmeh\nJanWilczek\njgillis\njiayuehua\njll63\nJoergAtGithub\njohnwason\njreichel-nvidia\nmbeutel\nmetsma\nmichaelmigliore\nmikaellindemann\nmiyanyan\nmyd7349\nn-taka\nnetheril96\nNeumann-A\nnickdademo\nnirvn\nnlogozzo\noleg-derevenetz\nOsyotr\npedrolcl\nPoldraunic\nrinechran\nrinrab\nrogerqcify\nrtzoeller\nscotthart\nSHIINASAMA\nSidneyCogdill\nsimolis3\nskypjack\nsssooonnnggg\nstemann\nSunBlack\nswebb2066\nszhorvat\ntalregev\nteo-tsirpanis\nTerentyev\ntheblackunknown\nThomas1664\ntomwillow\nTradias\ntraversaro\nwalbourn\nwaywardmonkeys\nwinsoft666\nwolfgitpr\nwoopelderly\nxiaozhuai\nLearn more\nYou can find the main release notes on GitHub. Recent updates to the vcpkg tool can be viewed on the vcpkg-tool Releases page. To contribute to vcpkg documentation, visit the vcpkg-docs repo. If you’re new to vcpkg or curious about how a package manager can make your life easier as a C/C++ developer, check out the vcpkg website – vcpkg.io.\nIf you would like to contribute to vcpkg and its library catalog, or want to give us feedback on anything, check out our GitHub repo. Please report bugs or request updates to ports in our issue tracker or join more general discussion in our discussion forum.\nThe post What’s New in vcpkg (November 2024) appeared first on C++ Team Blog.",
        "dc:creator": "Augustin Popa",
        "comments": "https://devblogs.microsoft.com/cppblog/whats-new-in-vcpkg-november-2024/#respond",
        "content": "<p>This blog post summarizes changes to the vcpkg package manager as part of the 2024.11.16 registry release, 2024-11-12 tool release, as well as changes to vcpkg documentation throughout November. This release includes a command line option to force vcpkg to use classic mode even if a manifest file is found along with bug fixes. Some [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/whats-new-in-vcpkg-november-2024/\">What’s New in vcpkg (November 2024)</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "This blog post summarizes changes to the vcpkg package manager as part of the 2024.11.16 registry release, 2024-11-12 tool release, as well as changes to vcpkg documentation throughout November. This release includes a command line option to force vcpkg to use classic mode even if a manifest file is found along with bug fixes. Some […]\nThe post What’s New in vcpkg (November 2024) appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34955",
        "categories": [
          "C++",
          "Vcpkg",
          "vcpkg;CPP"
        ],
        "isoDate": "2024-11-23T19:40:27.000Z"
      }
    ]
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Sequence learning: A paradigm shift for personalized ads recommendations",
        "link": "https://engineering.fb.com/2024/11/19/data-infrastructure/sequence-learning-personalized-ads-recommendations/",
        "pubDate": "Tue, 19 Nov 2024 17:00:43 +0000",
        "content:encodedSnippet": "AI plays a fundamental role in creating valuable connections between people and advertisers within Meta’s family of apps. Meta’s ad recommendation engine, powered by deep learning recommendation models (DLRMs), has been instrumental in delivering personalized ads to people. Key to this success was incorporating thousands of human-engineered signals or features in the DLRM-based recommendation system.\nDespite training on vast amounts of data, there are limitations to current DLRM-based ads recommendations with manual feature engineering due to the inability of DLRMs to leverage sequential information from people’s experience data. To better capture the experiential behavior, the ads recommendation models have undergone foundational transformations along two dimensions:\n\n\nEvent-based learning: learning representations directly from a person’s engagement and conversion events rather than traditional human-engineered features.\nLearning from sequences: developing new sequence learning architectures to replace traditional DLRM neural network architectures.\nBy incorporating these advancements from the fields of natural language understanding and computer vision, Meta’s next-generation ads recommendation engine addresses the limitations of traditional DLRMs, resulting in more relevant ads for people, higher value for advertisers, and better infrastructure efficiency.\nThese innovations have enabled our ads system to develop a deeper understanding of people’s behavior before and after converting on an ad, enabling us to infer the next set of relevant ads. Since launch, the new ads recommendation system has improved ads prediction accuracy – leading to higher value for advertisers and 2-4% more conversions on select segments.\nThe limits of DLRMs for ads recommendations\nMeta’s DLRMs for personalized ads rely on a wide array of signals to understand people’s purchase intent and preferences. DLRMs have revolutionized learning from sparse features, which capture a person’s interactions on entities like Facebook pages, which have massive cardinalities often in the billions. The success of DLRMs is founded on their ability to learn generalizable, high dimensional representations, i.e., embeddings from sparse features. \nTo leverage tens of thousands of such features, various strategies are employed to combine features, transform intermediate representations, and compose the final outputs. Further, sparse features are built by aggregating attributes across a person’s actions over various time windows with different data sources and aggregation schemes. \nSome examples of legacy sparse features thus engineered would be:\n\n\nAds that a person clicked in the last N days → [Ad-id1, Ad-id2, Ad-id3, …, Ad-idN]\nFacebook pages a person visited in the past M days with a score of how many visits on each page  → [(Page-id1, 45), (Page-id2, 30), (Page-id3, 8), …]\n\n\nHuman-engineered sparse features, as described above, have been a cornerstone for personalized recommendations with DLRMs for several years. But this approach has limitations:\n\n\nLoss of sequential information: Sequence information, i.e., the order of a person’s events, can provide valuable insights for better ads recommendations relevant to a person’s behavior. Sparse feature aggregations lose the sequential information in a person’s journeys.\nLoss of granular information: Fine-grained information like collocation of attributes in the same event is lost as features are aggregated across events.\nReliance on human intuition: Human intuition is unlikely to recognize non-intuitive, complex interactions and patterns from vast quantities of data.\nRedundant feature space: Multiple variants of features get created with different aggregation schemes. Though providing incremental value, overlapping aggregations increase compute and storage costs and make feature management cumbersome.\nPeople’s interests evolve over time with continuously evolving and dynamic intents. Such complexities are hard to model with handcrafted features. Modeling these inter-dynamics helps achieve a deeper understanding of a person’s behavior over time for better ad recommendations. \nA paradigm shift with learning from sequences for recommendation systems\nMeta’s new system for ads recommendations uses sequence learning at its core. This necessitated a complete redesign of the ads recommendations system across data storage, feature input formats, and model architecture. The redesign required building a new people-centric infrastructure, training and serving optimization for state-of-the-art sequence learning architectures, and model/system codesign for efficient scaling.\nEvent-based features\nEvent-based features (EBFs) are the building blocks for the new sequence learning models. EBFs – an upgrade to traditional features – standardizes heterogeneous inputs to sequence learning models along three dimensions:\nEvent streams: the data stream for an EBF, e.g. the sequence of recent ads people engaged with or the sequence of pages people liked.\nSequence length defines how many recent events are incorporated from each stream and is determined by the importance of each stream.\nEvent Information: captures semantic and contextual information about each event in the stream such as the ad category a person engaged with and the timestamp of the event.\nEach EBF is a single coherent object that captures all key information about an event. EBFs allow us to incorporate rich information and scale inputs systematically. EBF sequences replace legacy sparse features as the main inputs to the recommendation models. When combined with event models described below, EBFs have ushered in a departure from human-engineered feature aggregations.\n\nSequence modeling with EBFs\nAn event model synthesizes event embeddings from event attributes. It learns embeddings for each attribute and uses linear compression to summarize them into a single event attributed-based embedding. Events are timestamp encoded to capture their recency and temporal order. The event model combines timestamp encoding with the synthesized event attribute-based embedding to produce the final event-level representation – thus translating an EBF sequence into an event embedding sequence.\nThis is akin to how language models use embeddings to represent words. The difference is that EBFs have a vocabulary that is many orders of magnitude larger than a natural language because they come from heterogeneous event streams and encompass millions of entities.\nThe event embeddings from the event model are then fed into the sequence model at the center of the next-generation ads recommendation system. The event sequence model is a person level event summarization model that consumes sequential event embeddings. It utilizes state-of-the-art attention mechanisms to synthesize the event embeddings to a predefined number of  embeddings that are keyed by the ad to be ranked. With techniques like multi-headed attention pooling, the complexity of the self-attention module is reduced from O(N*N) to O(M*N) . M is a tunable parameter and N is the maximum event sequence length.\nThe following figure illustrates the differences between DLRMs with a human-engineered features paradigm (left) and the sequence modeling paradigm with EBFs (right) from a person’s event flow perspective.\n\nScaling the new sequence learning paradigm\nFollowing the redesign to shift from sparse feature learning to event-based sequence learning, the next focus was scaling across two domains — scaling the sequence learning architecture and scaling event sequences to be longer and richer.\nScaling sequence learning architectures\nA custom transformer architecture that incorporates complex feature encoding schemes to fully model sequential information was developed to enable faster exploration and adoption of state-of-the-art techniques for recommendation systems. The main challenge with this architectural approach is achieving the performance and efficiency requirements for production. A request to Meta’s ads recommendation system has to rank thousands of ads in a few hundred milliseconds.\nTo scale representation learning for higher fidelity, the existing sum pooling approach was replaced with a new architecture that learned feature interactions from unpooled embeddings. Whereas the prior system based on aggregated features was highly optimized for fixed length embeddings that are pooled by simple methods like averaging, sequence learning introduces new challenges because different people have different event lengths. Longer variable length event sequences, represented by jagged embedding tensors and unpooled embeddings, result in larger compute and communication costs with higher variance.\n\nThis challenge of growing costs is addressed by adopting hardware codesign innovations for supporting jagged tensors, namely:\n\n\nNative PyTorch capabilities to support Jagged tensors.\nKernel-level optimization for processing Jagged tensors on GPUs.\nA Jagged Flash Attention module to support Flash Attention on Jagged tensors.\n\n\nScaling with longer, richer sequences\nMeta’s next-generation recommendation system’s ability to learn directly from event sequences to better understand people’s preferences is further enhanced with longer sequences and richer event attributes.\nSequence scaling entailed:\n\n\nScaling with longer sequences: Increasing sequence lengths gives deeper insights and context about a person’s interests. Techniques like multi-precision quantization and value-based sampling techniques are used to efficiently scale sequence length.\nScaling with richer semantics: EBFs enable us to capture richer semantic signals about each event e.g. through multimodal content embeddings. Customized vector quantization techniques are used to efficiently encode the embedding attributes of each event. This yields a more informative representation of the final event embedding.\nThe impact and future of sequence learning\nThe event sequence learning paradigm has been widely adopted across Meta’s ads systems, resulting in gains in ad relevance and performance, more efficient infrastructure, and accelerated research velocity. Coupled with our focus on advanced transformer architectures, event sequence learning has reshaped Meta’s approach to ads recommendation systems. \nGoing forward, the focus will be on further scaling event sequences by 100X, developing more efficient sequence modeling architectures like linear attention and state space models, key-value (KV) cache optimization, and multimodal enrichment of event sequences.\nAcknowledgements\nWe would like to thank Neeraj Bhatia, Zhirong Chen, Parshva Doshi, Jonathan Herbach, Yuxi Hu, Abha Jain, Kun Jiang, Santanu Kolay, Boyang Li,  Hong Li, Paolo Massimi, Sandeep Pandey, Dinesh Ramasamy, Ketan Singh, Doris Wang, Rengan Xu, Junjie Yang, and the entire event sequence learning team involved in the development and productionization of the next-generation sequencing learning-based ads recommendation system.\nThe post Sequence learning: A paradigm shift for personalized ads recommendations appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>AI plays a fundamental role in creating valuable connections between people and advertisers within Meta’s family of apps. Meta’s ad recommendation engine, powered by deep learning recommendation models (DLRMs), has been instrumental in delivering personalized ads to people. Key to this success was incorporating thousands of human-engineered signals or features in the DLRM-based recommendation system. [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/11/19/data-infrastructure/sequence-learning-personalized-ads-recommendations/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/11/19/data-infrastructure/sequence-learning-personalized-ads-recommendations/\">Sequence learning: A paradigm shift for personalized ads recommendations</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "AI plays a fundamental role in creating valuable connections between people and advertisers within Meta’s family of apps. Meta’s ad recommendation engine, powered by deep learning recommendation models (DLRMs), has been instrumental in delivering personalized ads to people. Key to this success was incorporating thousands of human-engineered signals or features in the DLRM-based recommendation system. [...]\nRead More...\nThe post Sequence learning: A paradigm shift for personalized ads recommendations appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21954",
        "categories": [
          "Data Infrastructure",
          "ML Applications",
          "Production Engineering"
        ],
        "isoDate": "2024-11-19T17:00:43.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "eBay News Team",
        "title": "Introducing eBay Evo: The Evolution of eBay’s Brand and Design System",
        "link": "https://innovation.ebayinc.com/tech/features/ebay-evo-the-evolution-of-ebays-brand-and-design-system/",
        "pubDate": "Mon, 18 Nov 2024 00:00:00 -0800",
        "dc:creator": "eBay News Team",
        "content": "<div style=\"margin-bottom: 10px;\"><img src=\"https://static.ebayinc.com/static/assets/Uploads/Blog/Posts/_resampled/FitWzIwMCwxMTNd/Overview-Still.jpg?fs=aa44968bd70eed27\" width=\"200\" height=\"113\" alt=\"Introducing eBay Evo: The Evolution of eBay’s Brand and Design System\" /></div><div>Developed in-house, Evo enhances the customer experience through a modern and simplified approach.</div>",
        "contentSnippet": "Developed in-house, Evo enhances the customer experience through a modern and simplified approach.",
        "guid": "https://innovation.ebayinc.com/tech/features/ebay-evo-the-evolution-of-ebays-brand-and-design-system/",
        "categories": [
          "article"
        ],
        "isoDate": "2024-11-18T08:00:00.000Z"
      }
    ]
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Irina Mariasova",
        "title": "JetBrains AI Assistant Integrates Google Gemini and Local LLMs",
        "link": "https://blog.jetbrains.com/ai/2024/11/jetbrains-ai-assistant-integrates-google-gemini-and-local-llms/",
        "pubDate": "Fri, 22 Nov 2024 14:55:23 +0000",
        "content:encodedSnippet": "We’ve now added Gemini 1.5 Pro and Gemini 1.5 Flash to the lineup of LLMs used by JetBrains AI Assistant. These LLMs join forces with OpenAI models and local models. \nWhat’s special about Google models?\nGemini 1.5 Pro and 1.5 Flash on Google Cloud’s Vertex AI will deliver advanced reasoning and impressive performance, unlocking several new use cases. Gemini Flash 1.5 will specifically help when cost efficiency at high volume and low latency is paramount.  \nHow to try Google models\nStarting from the 2024.3 version of JetBrains AI Assistant, you can pick your preferred LLM right in the AI chat. This expanded selection allows you to customize the AI chat’s responses to your specific workflow, offering a more adaptable and personalized experience. \n\n\n\n\nLocal model support via Ollama\nIn addition to cloud-based models, you can now connect the AI chat to local models available through Ollama. This is particularly useful if you need more control over your AI models, and it offers enhanced privacy, flexibility, and the ability to run models on local hardware.\nTo add an Ollama model to the chat, enable Ollama support in AI Assistant’s settings and configure the connection to your Ollama instance. \n\n\n\n\nExplore these new models, and let us know what you think! 🌟",
        "dc:creator": "Irina Mariasova",
        "content": "We’ve now added Gemini 1.5 Pro and Gemini 1.5 Flash to the lineup of LLMs used by JetBrains AI Assistant. These LLMs join forces with OpenAI models and local models. What’s special about Google models? Gemini 1.5 Pro and 1.5 Flash on Google Cloud’s Vertex AI will deliver advanced reasoning and impressive performance, unlocking several [&#8230;]",
        "contentSnippet": "We’ve now added Gemini 1.5 Pro and Gemini 1.5 Flash to the lineup of LLMs used by JetBrains AI Assistant. These LLMs join forces with OpenAI models and local models. What’s special about Google models? Gemini 1.5 Pro and 1.5 Flash on Google Cloud’s Vertex AI will deliver advanced reasoning and impressive performance, unlocking several […]",
        "guid": "https://blog.jetbrains.com/?post_type=ai&p=529591",
        "categories": [
          "news",
          "gemini",
          "google",
          "jetbrains-ai",
          "mellum"
        ],
        "isoDate": "2024-11-22T14:55:23.000Z"
      },
      {
        "creator": "Oleg Zinovyev",
        "title": "CLion Nova Improvements, Debug Servers, OpenCV Image Viewer, and Zephyr West Debugging in CLion 2024.3",
        "link": "https://blog.jetbrains.com/clion/2024/11/2024-3-available/",
        "pubDate": "Wed, 20 Nov 2024 11:40:48 +0000",
        "content:encodedSnippet": "CLion 2024.3 is now available. This latest version of the JetBrains IDE for C and C++ includes the following key features and updates:\nConsiderable improvements to the new language engine, CLion Nova.\nNew Debug Servers configuration option.\nOpenCV image viewer.\nAbility to attach the debugger to an unstarted process.\nDebugging support for Zephyr West.\n\n\n\n\nYou can download CLion 2024.3 from the link below, via the Toolbox App, as a snap package if you’re using Ubuntu, or via a patch update from version 2024.2.\nDOWNLOAD CLION 2024.3\nCLion Nova\nIn this release, our new language engine, CLion Nova, has received many important enhancements, including various language-specific and UI updates and several memory usage optimizations. We’ve also provided improved language support for modern C++ features.\nFurthermore, to simplify the transition from CLion Classic to CLion Nova, we’ve added a toggle switch to both the Welcome screen and the Configuration menu.\n\n\n\n\nCall for feedback on CLion Nova\nThe performance of CLion Nova now exceeds that of CLion Classic by an even greater margin. It’s smoother and more responsive, even on larger projects with hundreds of thousands of lines of code. That’s why we’ve added even more convenient ways for you to switch to CLion Nova. \nHowever, we realize that some CLion Classic users are not ready to make the switch. Before we make CLion Nova the default engine for everyone, we would like to understand why some users prefer CLion Classic over CLion Nova. We would therefore appreciate it if you could share your feedback with us via Help | Submit Feedback… in the main IDE menu. We’ll review it carefully and try to resolve any critical issues that might prevent you from getting the most out of CLion Nova.\nMemory usage improvements\nVarious improvements have vastly reduced CLion Nova’s memory usage and improved overall IDE performance. This is especially noticeable in large projects like Chromium ones.\n\n\n\n\nFor example, when we compared the memory usage of a Chromium project in CLion Nova 2024.2 with the same project in 2024.3, we saw that the IDE frontend used 51% less memory in the new version, and the IDE backend used 15% less. In short, this means the IDE has become more responsive and quicker to launch.\nCall hierarchy\nThe function call hierarchy is now available when using CLion Nova in the Hierarchy tool window. It displays caller and callee hierarchies, visually representing how your functions interact and highlighting recursive calls with the corresponding icon.\n\n                        \n\n\nTo see the call hierarchy of a function, select it in the editor, and then click Navigate | Call Hierarchy from the main menu or use the shortcut ⌃⌥H (macOS) or Ctrl+Alt+H (Windows/Linux).\nPredefined code styles from other projects\nOne of the most requested features we’ve added to this release is predefined code styles from other projects such as LLVM, GNU, Qt, and Google. This allows you to follow popular style guides for code structure rules, naming conventions, and other C++ areas where consistency is crucial. You can select your preferred style via Settings | Editor | Code Style | C/C++ | Set from….\n\n\n\n\nQuick Definition support\nThe Quick Definition popup reveals where and how function, class, method, and other project symbols are defined. To call it, place the caret at a symbol in the editor and press ⌥Space (macOS) or Ctrl+Shift+| (Windows/Linux). You can also access it from the main menu via View | Quick Definition.\n\n                        \n\n\nEmbedded development\nIn this release, we have continued to expand CLion’s functionality to meet the diverse needs of embedded developers. Major updates for embedded development include debug servers, the ability to edit peripheral register values, and support for debugging West projects.\nDebug servers experimental\nWe’ve introduced a new Debug Servers configuration option to simplify the setup of debugging for embedded and remote development. Located in Settings | Debugger, this dedicated section allows you to configure a debug server for the specific debug probe and use it to run or debug the build target.\nTo enable the configuration option, go to Settings | Advanced Settings | Debugger. You can select Edit Debug Servers from the main toolbar switcher or go to Settings | Debugger and open the Debug Servers dialog to configure a debug server.\n\n                        \n\n\nPlease be aware that this is an experimental feature, and it doesn’t work with PlatformIO yet. There is, however, a workaround. We encourage you to give it a try and share your feedback with us. Additionally, we are more than willing to arrange a brief call to understand your specific use cases and challenges better.\nDebugging support for Zephyr West\nNow, you can natively debug Zephyr projects that use the West meta-tool directly in CLion. When you import your Zephyr West project, a West run/debug configuration is automatically created in the Run/Debug Configurations switcher. You can also create a new run/debug configuration by selecting Run | Edit Configurations… from the main menu, clicking +, and selecting a West template:\n\n\n\n\nOnce configured, the new West run/debug configuration will be available in the Run/Debug Configurations switcher, and you can use it to run a debug session.\nEditable peripheral register values\nWhen debugging board peripherals like timers, communication interfaces, or GPIO ports, you can now instantly observe the results of your modifications by editing peripheral registers directly in the Peripherals pane.\n\n\n\n\nYou can test different configurations and device states on the go without recompiling your code or reloading your application or board.\nSupport for MISRA C++:2023 with CLion Nova\nThe MISRA guidelines are indispensable in the development of safety-critical systems. In this release, CLion’s static analysis toolset gets a significant portion of MISRA C++:2023 checks specifically targeted at C++17.\n\n\n\n\nDebugger\nCLion’s debugger has received several updates, the most important of which are an OpenCV image viewer, the ability to attach the debugger to an unstarted process, a formatted view for strings with structured data, and new bundled GDB (15.2) and LLDB (19.1.3) debuggers.\nOpenCV image viewer\nIf you’re developing an ML application that uses the OpenCV library, you can now view a two-dimensional OpenCV array as an image while debugging the application. The image opens in a separate dialog with multiple editing options.\n\n                        \n\n\nThe OpenCV image viewer simplifies image processing inspection during application debugging. It’s also more convenient than alternative methods like saving an image to the hard drive or writing extra code to display it in a popup window.\nAbility to attach the debugger to an unstarted process\nAttaching the debugger to an unstarted local process is helpful when one part of your project is written in C++ and runs in CLion, while another is written in another language and runs in an external environment.\nTo try the feature:\nSet a breakpoint in your code.\nSelect Run | Attach to an Unstarted Process… from the main menu.\nIn the Command line field, add a pattern to find the process using wildcard characters: *process_name*.\nSelect the options you need.\nSelect a debugger to attach.\nThe debugger will start watching the process.\n\n\n\n                                                \n                        \n\n\nOnce the external process starts, the debugger will attach to it. From there, the debugging session will continue as normal, with the program running and halting at the breakpoints you have set.\nFormatted view for strings with JSON, XML, or HTML data\nWhen debugging strings containing JSON, XML, or HTML data, or newline characters, you can view them formatted according to their code style directly in the debugger. This means you no longer need to copy unformatted values into a third-party tool for examination. \nWhen debugging, click View next to a variable to see the structured or raw data in a separate window.\n\n\n\n\nOther enhancements\nThis release also includes a number of user experience improvements, such as renewed cloud completion, a new project status widget, and an updated UI for the new terminal. We’ve also updated the CMake bundle to 3.30.5.\nRenewed cloud completion powered by AI Assistant \nThe enhanced JetBrains AI Assistant plugin, featuring our internally trained LLM for C++, has significantly improved the speed and intelligence of CLion’s cloud code completion. AI Assistant now provides more usage scenarios, better suffix matching, and more correct code fragment completions.\nOne of the most significant enhancements is multiline code completion, which brings syntax highlighting and the ability to incrementally accept code suggestions. \n\n                        \n\n\nMultiline code completion operates alongside standard code completion and Full Line Code Completion (the latter uses the local LLM and doesn’t require sending data to the cloud). It allows you to review and accept suggestions incrementally. Additionally, you can accept suggestions word by word using the shortcut ⌥→ on macOS or Ctrl+→ on Windows. \nProject status widget\nCLion’s project status notifications inform you of potential problems with your project configuration and offer ways to resolve them. In the previous CLion version, 2024.2, these notifications were displayed as yellow banners in the editor until the problem was resolved. They were irrelevant for some users – for example, those who just wanted to open a .cpp file from a third-party project to read the code. Having a notification banner hanging in the editor all the time is unnecessary in such cases.\nFor this release, we’ve moved project status notifications from the top of the editor to a new widget in the status bar.\n\n\n\n\nNow, the notification that your file doesn’t belong to any project won’t appear until you hover over the ⚠️ icon. When you click on the icon, the widget will offer to fix the problem. This makes notifications less distracting while still keeping the information accessible to those who want it.\nUpdated UI for the new terminal\nThe new terminal’s interface has been redesigned to be more compact by reducing padding. This change maximizes screen space, making it easier to view and work with commands while keeping everything readable and clear. \n\n\n\n\nHighlighted occurrences of selected text\nBy default, CLion now highlights every instance of the text you select in any file type, not just .c and .cpp files. This change makes it much simpler to track where your selected text appears throughout the file. \n\n\n\n\nTry CLion and give us your feedback\nWe invite you to give CLion 2024.3 a try. If you have an active subscription, you can update it right away. New to CLion? Start your free 30-day trial today and dive into all its features and improvements immediately.\nWe value your feedback! If you have anything to share or if you run into any problems, please let us know through our issue tracker.\nDOWNLOAD CLION 2024.3\nYour CLion team\nJetBrains\nThe Drive to Develop",
        "dc:creator": "Oleg Zinovyev",
        "content": "CLion 2024.3 is now available. This latest version of the JetBrains IDE for C and C++ includes the following key features and updates: You can download CLion 2024.3 from the link below, via the Toolbox App, as a snap package if you’re using Ubuntu, or via a patch update from version 2024.2. DOWNLOAD CLION 2024.3 [&#8230;]",
        "contentSnippet": "CLion 2024.3 is now available. This latest version of the JetBrains IDE for C and C++ includes the following key features and updates: You can download CLion 2024.3 from the link below, via the Toolbox App, as a snap package if you’re using Ubuntu, or via a patch update from version 2024.2. DOWNLOAD CLION 2024.3 […]",
        "guid": "https://blog.jetbrains.com/?post_type=clion&p=527231",
        "categories": [
          "news",
          "releases",
          "ai-assistant",
          "clionnova",
          "debugger",
          "embedded",
          "misra",
          "opencv",
          "zephyr-west"
        ],
        "isoDate": "2024-11-20T11:40:48.000Z"
      },
      {
        "creator": "Mukul Mantosh",
        "title": "Deploying Go Apps with Kubernetes",
        "link": "https://blog.jetbrains.com/go/2024/11/20/deploying-go-apps-with-kubernetes/",
        "pubDate": "Wed, 20 Nov 2024 11:24:31 +0000",
        "content:encodedSnippet": "We live in a world where things change at a rapid pace, and the latest and greatest quickly becomes outdated. The same goes for deploying applications to servers. You used to have to physically travel to a data center to deploy your changes. Later on, we moved to VMs. Then containers came along and changed the game again.\nContainers have been widely adopted by most industries, and one of the most popular containerization tools is Docker. However, as complexity grew, people started looking for orchestration tools that were effective at scale, performed load balancing, self-healed, and more. There were many contenders in the competition, like Apache Mesos, HashiCorp Nomad, and Docker Swarm, but Kubernetes has thrived for a long time due to its robust ecosystem, extensive community support, scalability, and ability to manage complex, distributed applications across multiple environments.\n\n\n\n\nSource: drgarcia1986.medium.com\nKubernetes is an open-source container orchestration platform that automates the deployment, scaling, and management of containerized applications. Originally developed by Google, it is now maintained by the CNCF.\nKubernetes is one of the largest open-source projects to date. With over a decade of development, its maturity is undeniable, boasting more than 88,000 contributors. Check out the 10 Years of Kubernetes blog post for more insights.\nIn this tutorial, we are going to create a Go application and prepare it to run inside a Kubernetes cluster. \nLet’s get started!\nCreating a Go application in GoLand\nIn this tutorial, we’ll start by creating a basic Go application which performs CRUD operations. We’ll then containerize the application and deploy it to the local Kubernetes cluster using Docker Desktop.\nYou can access the source code used in this tutorial here.\nTo create your project, launch GoLand and click New Project. \nProvide necessary information such as the project name, GOROOT, and environment variables.\nEven if you don’t have the Go SDK installed on your system, GoLand will assist you in downloading the correct SDK.\n\n\n\n\nThen click Create.\nInstalling packages\nGorilla Mux\nOnce the project has been created, install Gorilla. The Gorilla Mux package is among the most widely used routers. It offers functionalities for route matching, serving static files, supporting middleware and websockets, managing CORS requests, and testing handlers.\nInstalling it from GoLand is simple and straightforward. Just import the package name, and the IDE will prompt you to install it.\n\n\n\n\nAlternatively, you can use the default method by accessing the Terminal and executing the following command:\ngo get -u github.com/gorilla/mux\n\n\n\n\nGORM\nGORM is an Object Relational Mapping (ORM) library for Go. It simplifies database interactions by making it easier for developers to work with database records and perform CRUD (Create, Read, Update, Delete) operations.\n*NOTE: We will be using the Postgres driver.\nTo install, run the following command in the Terminal:\ngo get -u gorm.io/gorm\ngo get -u gorm.io/driver/postgres\nAlternatively, you can also directly mention the package in the go.mod file and GoLand will take care of the installation.\n\n\n\n\n\n\n\n\nNOTE: When you see // indirect next to a dependency in the require block of your go.mod file, it indicates that your project does not import this package directly in its code, but some other package that your project imports does. \nBuilding core business functions\nNow, we have installed the core packages required to build the application. It’s time to start writing the core business logic. \nDatabase\nLet’s begin with the database.\nCreate a database.go file under project root. \n\n\n\n\nLet’s break it down step-by-step. \nIn this section we are managing a database client using the GORM library for Postgres.\nDBClient: This is an interface with two method signatures:\nReady(): This function returns a boolean value based on whether the database is ready or not. \nRunMigration(): This function performs database migrations. \n\n\n\n\n\nClient: This is a concrete type Client that implements the DBClient interface. It contains a single db *gorm.DB field which points to a gorm.DB instance.\n\n\n\n\n\nNext, in the Ready method we perform a RAW SQL query to check database readiness. It will return a boolean response (true or false). \n\n\n\n\n\nUnder RunMigration, we first check whether the database is ready. If successful, we proceed to invoke the AutoMigrate method provided by GORM to apply migrations to the database schema. As noted in the comment, we need to register the model to run the migration. We haven’t created a model yet, but don’t worry – we’ll get to that shortly. \n\n\n\n\n\nThe NewDBClient function constructs a database connection from environment variables, creating a Client that can be used to interact with the database.\n\n\n\n\nThe database section is done. Now let’s create our user model. \nUser model\nCreate a model.go file under the project root. \n\n\n\n\n\n\n\n\nHere you can see the User struct with fields ID, Name, Email, and Age, each annotated with JSON tags for serialization and GORM tags for database constraints, including primary key, uniqueness, and non-null constraints.\nThese tags specify database constraints and behaviors using GORM:\ngorm:\"primaryKey\": The ID field is the primary key.\ngorm:\"not null\": The Name and Email fields cannot be NULL in the database.\ngorm:\"unique\": The Email must be unique across the database table.\nNow we need to pass the User model to the AutoMigrate function which we discussed earlier. \n\n\n\n\nServer\nWe have implemented the database and the user model, so now it’s time to construct the mux server. \nCreate the server.go and routes.go files under the project root.\n\n\n\n\nWe’ll just leave this routes.go file empty for now, and we’ll cover what to do with it in the next section when we start defining HTTP handlers.\n\n\n\n\nLet’s break down the ‘server.go’ file step-by-step.\n\n\n\n\nThe Server interface declares two methods: \n– Start() error: Starts the server and returns any errors that pop up. \n– routes(): Defines the server routes.\n\n\n\n\nThe MuxServer struct implements the Server interface. \nIt contains: \n– gorilla *mux.Router: An instance of Gorilla Mux Router. \n– Client: An embedded field pointing to a database client. \n\n\n\n\nNewServer is a constructor function that creates and initializes a MuxServer instance. \n It accepts a Client which refers to a database client. \n A new MuxServer is created with: \n– A new router from mux.NewRouter(). \n– The provided db client. \n– The server.routes()method is called to set up the routes. \n\n\n\n\nThe Start method takes care of starting up the HTTP server and listening on port 8080. \n\n\n\n\nWe haven’t defined any HTTP handlers yet, which is why the routes function is currently empty. \nLet’s take care of that now.\n\n\n\n\nHTTP handlers\nCreate a new file called controller.go under the project root. \n\n\n\n\nOnce you’ve created the file, go ahead and open model.go and add the following struct:\n\n\n\n\nThe UserParam struct serves as a data transfer object (DTO) specifically for input handling, often seen in web APIs or web forms. \nSeparation of Concerns:\nThe User struct represents the data structure of a user entity in the system, which corresponds directly to the database schema. The UserParam struct is used for handling input validation and data transfer, particularly from HTTP requests.\nSecurity:\nYou’ll have better control over your data by separating fields into two categories: (1) information received from requests (like user input), and (2) information stored in the database. This gives you control over what data is exposed, enhances security by filtering out sensitive info, and ensures you only transfer necessary data between layers. \nLet’s go ahead and start implementing the HTTP handlers. \nHead back into the controller.go file.\n\n\n\n\nLet’s break it down step-by-step. We are going to implement the basic CRUD (Create, Read, Update, and Delete) operations on the User model. \nAdd User\nTo create a new user and add it to the database.\n\n\n\n\nList Users\nTo list all users from the database.\n\n\n\n\nUpdate User\nTo update an existing user’s details.\n\n\n\n\nDelete User\nTo delete an existing user.\n\n\n\n\nNow, it’s time to update the routes. \n\n\n\n\nIn this function, we’ll set up various kinds of routes (GET, POST, PUT and DELETE) to handle requests.\n\n\n\n\nRunning the application\nWe’re almost done! It’s time to define the entry point of the application where we can initialize the database, run migrations, and start the server.\nCreate a new file called main.go under the project root.\n\n\n\n\nAs you can see from the code below, we are initializing the database client, running database migration, and starting up the server. \n\n\n\n\nNow, it’s time to start the server. Before that, make sure you are running a local instance of Postgres. I will use Docker to spin up a postgres container.\nRun the following command in the Terminal:\ndocker run --name goland-k8s-demo -p 5432:5432 -e POSTGRES_PASSWORD=********** -d postgres\n\n\n\n\nOnce the container is up and running, go ahead and modify the Run Configuration. \n\n\n\n\nAdd these variables to the Environment field, as shown in the image below:\nDB_HOST\nDB_USERNAME\nDB_PASSWORD\nDB_NAME\nDB_PORT\n\n\n\n\n\n\n\n\nOnce done, apply the changes.\nClick the play icon to start the application. \n\n\n\n\n\n\n\n\nOnce the application is running, navigate to http-client | apis.http.\nYou can play around with the REST APIs directly from the IDE itself. \n\n\n\n\nDiving into K8s\nNow that we have developed the entire application,  it’s time to deploy the application inside the Kubernetes cluster. \nThe process starts with creating the Dockerfile.\nDockerfile\nA Dockerfile is a text document that contains a set of instructions for building a Docker image. It defines how the image should be constructed, including the base image to use, the files to include, and any commands to run during the build process.\nCreate a new file under project root and name it “Dockerfile”.\nSimply follow the steps I’ve outlined to build the Docker image. I’ll walk you through it step by step.\n\n\n\n\n\n\n\n\nFROM golang:1.23-alpine AS builder\nStarts with golang:1.23-alpine as the base image and labels the stage as builder.\nWORKDIR /app\nSet the working directory to /app.\nCOPY . .\nCopies the entire current directory (.) into the /app directory.\nRUN CGO_ENABLED=0 GOOS=linux go build -o go_k8s\nRuns the Go build command to compile the application. \nCGO_ENABLED=0 disables CGO (CGO enables the creation of Go packages that call C code).\n GOOS=linux sets the target OS to Linux. \nThe output binary is named go_k8s.\n\n\n\n\nFROM gcr.io/distroless/base\nUses a minimal distroless base image for the final container, focusing on security by excluding unnecessary components. To learn more about distroless images, check this out. \nWORKDIR /app\nSets the working directory to /app in the final stage.\nCOPY --from=builder /app/go_k8s .\nCopies the go_k8s binary from the /app directory of the builder stage into the /app directory of the final image.\nCMD [\"./go_k8s\"]\nSets the command to run when the container starts, which is the go_k8s binary.\nThe final image is kept as small and secure as possible, containing only the Go application binary without any unnecessary build tools or dependencies.\nGo ahead and build the Docker image. \nClick Run ‘Dockerfile’.\nNote: Before running, make sure the Docker daemon is running in the background. For this tutorial we are going to be using Docker Desktop.\n\n\n\n\nOnce the image is successfully built, push the image to the Docker registry.\nRight-click the image tag and select Edit Configuration.\n\n\n\n\nProvide the image tag and apply the changes.\nNote:\nBefore pushing, make sure to change the image tag based on the Docker repository which you have created in DockerHub.\nThe image tag should follow the format <hub-user>/<repo-name>[:<tag>]. Follow the steps to create repositories.\nIn this example, the tag mukulmantosh/go_k8s:1.0 is for demonstration only and may change based on your account type. Here, mukulmantosh represents the user, while go_k8s is the repository name and 1.0 is the specified tag.\n\n\n\n\n\n\n\n\n\nMake sure to re-run the build process. \n\n\n\n\nYou can see that the image tag has been applied. \n\n\n\n\nIt’s time to push the image. \nRight-click on the image tag, then select Push Image.\n\n\n\n\nClick Add and provide your Docker registry information.\n\n\n\n\n\n\n\n\nOnce successfully authenticated, click OK to push the image.\n\n\n\n\nOnce the image is successfully pushed, you can observe the changes in DockerHub. \n\n\n\n\nWell, the image is built and pushed. Now it’s time to work on the second part – writing the Kubernetes YAML files. \nWriting K8s manifests\nThis part of the tutorial covers how to deploy applications to local Kubernetes clusters.\nIn this tutorial, we have utilized Docker Desktop, though you can also opt for Minikube or Kind.\nIf you’ve chosen Docker Desktop as your preferred platform for running Kubernetes, be sure to enable Kubernetes in the settings by clicking the Enable Kubernetes checkbox.\n\n\n\n\nOnce Kubernetes is up and running, it’s time to create a namespace.\nWhat is a namespace?\nIn Kubernetes, a namespace is a logical partitioning of the cluster that allows you to divide resources and organize them into groups. Namespaces enable multiple teams or projects to share the same cluster while maintaining isolation and avoiding naming conflicts.\n\n\n\n\nSource: belowthemalt.com\nBegin by creating a directory called k8s in the root of your project.\nNext, create a new file and name it ns.yaml.\nNOTE: A Kubernetes manifest is typically written in YAML or JSON format and outlines various parameters for the resource, including its type, metadata, and specifications.\n\n\n\n\nThis YAML file would create a namespace named go-k8s-demo in your Kubernetes cluster.\nLet’s break it down.\napiVersion: v1: This specifies the API version of the Kubernetes resource. In this case, v1 indicates that the resource is using version 1 of the Kubernetes API.\nkind: Namespace: This indicates the type of Kubernetes resource being defined. It can be Deployment, Service, etc.\nmetadata: This section holds metadata about the Kubernetes resource. Metadata usually includes details like the name, labels, and annotations.\nIf you type the following command in the Terminal, it will show you lists of the API resources available in the Kubernetes cluster. \nkubectl api-resources\n\n\n\n\nOkay – you’ve created the YAML file. Now it’s time to execute it. \nThere are two ways you can create a namespace:\nIf you prefer using the Terminal, you can run this command:\nkubectl create ns go-k8s-demo\nOr, you can apply a file by running this command:\ncd k8s\nkubectl apply -f ns.yaml\nBoth methods will create the same namespace.\nCreating a namespace with GoLand\nYou also have the option of doing this in GoLand. Yes, you read that right, you can play with your Kubernetes clusters directly from the GoLand IDE. \nAs a side note, if you’re using GoLand 2024.2 or later, the Kubernetes plugin is already bundled with the IDE, so you don’t need to install it separately.\nOpen the Service tool window  by going to View | Tool Windows | Services.\n\n\n\n\nRight-click on Kubernetes | Add Clusters | From Default Directory.\n\n\n\n\nSelect docker-desktop and click Add Clusters.\n\n\n\n\nYou will see docker-desktop as your newly added cluster. Click the play icon to connect to it.\n\n\n\n\n\n\n\n\nReturn to the YAML file and hover over the top right corner of the screen and click Apply to Cluster to set your cluster to docker-desktop.\nOnce done, apply the changes.\n\n\n\n\nThe namespace is successfully created. \n\n\n\n\nWe will now switch to the newly created namespace to easily view the applications running within it.\n\n\n\n\n\n\n\n\nYou might be asking, “This works with a local cluster, but what about connecting to an external one?” Good news! You can do that as well.\n\n\n\n\nYou can also modify the paths for the kubectl and helm executables. Additionally, you have the option to customize Kubernetes configuration files at either the global or project level.\n\n\n\n\n\n\n\n\nDatabase and K8s\nThe namespace has been created. Now let’s start working on the database.\nPersistentVolume\nWe are going to create a persistent volume. A PersistentVolume (PV) in Kubernetes provides storage for your application’s pods. Think of it as a storage space that exists independently of any specific application.\nUnlike regular storage that disappears when an application stops, a PersistentVolume retains the data, making it suitable for applications that need to save files or databases.\nCreate a new folder called db in the project root, and then add a new file named pv.yaml inside it.\n\n\n\n\nThis YAML configuration defines a PersistentVolume named postgres-pv with 1 GB of storage. It is associated with the postgres application and can be accessed as read-write by one node at a time. The volume is stored locally on the host at the path /data/db.\nPersistentVolumeClaim\nCreate a new file called pvc.yaml under db.\nA PersistentVolumeClaim (PVC) in Kubernetes is a request for storage by a user or application. It allows you to specify how much storage you need and what characteristics it should have, such as access modes (like read/write).\n\n\n\n\nIn this YAML configuration we are creating a PVC in the go-k8s-demo namespace requesting 1 GiB of storage with a ReadWriteOnce access mode using the manual storage class.\nConfigMap\nCreate a new file cm.yaml under db.\nA ConfigMap in Kubernetes is a resource used to store configuration data in a key-value format. It allows you to separate configuration from application code, making it easier to manage and modify settings without needing to rebuild your application.\n\n\n\n\nDeployment\nA Deployment in Kubernetes is a resource used to manage and orchestrate the deployment of applications. It allows you to define how many instances of your application (called Pods) you want to run, and it ensures that they are running as expected.\nCreate a new file deploy.yaml under db.\n\n\n\n\nThis YAML file defines a deployment of a single PostgreSQL container running version 17.0, which exposes port 5432 and runs only one instance. It loads environment variables from a ConfigMap and uses a PersistentVolume to store data. \nService\nA Service in Kubernetes is an abstraction that defines a logical set of pods and a way to access them. It provides a stable endpoint for your applications, making it easier to communicate with groups of pods.\n\n\n\n\nSource: kubernetes.io\nCreate a new file svc.yaml under db.\n\n\n\n\nIn this YAML file we have defined a Kubernetes Service named postgres-service. The Service exposes port 5432 and routes traffic to the pods labeled with app: postgres-db, so it will allow other applications within the cluster to connect to the database.\nLaunching DB\nWe now have all of the configuration files needed to start the database. Let’s execute them.\nThere are two methods to do this.\nFirst, open the Terminal, navigate to the db directory, and run the following command:\ncd db\nkubectl apply -f .\nTo see the current status of your pods, you can run the following command:\nkubectl get pods -n go-k8s-demo\n\n\n\n\nThe second option is quite easy with GoLand. You don’t need to remember the commands – just the follow along with the video below:\n\n\n\n\nApplication and K8s\nNow that the database is up and running, it’s time to prepare our backend application.\nBegin by creating an app folder inside the k8s directory.\nConfigMap\nCreate a new file called cm.yaml under app.\nEnter the required database credentials.\nNOTE:\nGrab the credentials from db/cm.yaml that you defined earlier when creating the database pod.\npostgres-service under DB_HOST refers to the db/svc.yaml service we created earlier.\n\n\n\n\n\n\n\n\n\n\n\n\nDeployment\nNow let’s move on to the deployment. \nCreate a new file called deploy.yaml under app. \n\n\n\n\n\n\n\n\nIn this YAML file we define a Kubernetes deployment that runs a single replica of a pod, which contains a single container using the mukulmantosh/go_k8s:1.0 image. The container exposes port 8080 and gets its environment variables from a ConfigMap named app-cm.\nService\nNow let’s wrap up the last file. \nCreate a file called svc.yaml under app.\n\n\n\n\nTo summarize, we set up a service named app-service that allows external traffic to reach your application running in the cluster through port 30004. Requests received here are forwarded to port 8080 on the application pods.\nTesting\nNow let’s deploy our application and start testing it out. \nThe process is going to be exactly the same as what we did for the database.\nNavigate to the app directory and run the following command:\ncd app\nkubectl apply -f .\nAlternatively, you can do this in GoLand, which is quite easy and straightforward. \n\n\n\n\nYou can also check the status of your application by running the following command:\nkubectl get pods -n go-k8s-demo\n\n\n\n\nLet’s test out the application by sending an HTTP request.\n\n\n\n\n\n\n\n\nThe application works!\nThis was just a brief demonstration of how to use Kubernetes with Go, but there are many more possibilities to explore.\nReferences\nIf you already have a strong grasp of Kubernetes and want to learn how to deploy in a live cluster, take a look at my tutorial on deploying Go apps in Google Kubernetes Engine.",
        "dc:creator": "Mukul Mantosh",
        "content": "We live in a world where things change at a rapid pace, and the latest and greatest quickly becomes outdated. The same goes for deploying applications to servers. You used to have to physically travel to a data center to deploy your changes. Later on, we moved to VMs. Then containers came along and changed [&#8230;]",
        "contentSnippet": "We live in a world where things change at a rapid pace, and the latest and greatest quickly becomes outdated. The same goes for deploying applications to servers. You used to have to physically travel to a data center to deploy your changes. Later on, we moved to VMs. Then containers came along and changed […]",
        "guid": "https://blog.jetbrains.com/?post_type=go&p=528858",
        "categories": [
          "tutorials",
          "go",
          "goland",
          "kubernetes"
        ],
        "isoDate": "2024-11-20T11:24:31.000Z"
      },
      {
        "creator": "Anton Yalyshev",
        "title": "State of Kotlin Scripting 2024",
        "link": "https://blog.jetbrains.com/kotlin/2024/11/state-of-kotlin-scripting-2024/",
        "pubDate": "Tue, 19 Nov 2024 16:07:29 +0000",
        "content:encodedSnippet": "Update: we made some updates to the original post to accurately reflect the state of Custom Scripting and to avoid misinterpretations.\nTL;DR: Kotlin scripting remains an essential part of the Kotlin infrastructure. We continue to support it in the experimental state, and we are concluding certain experiments and reducing the number of scripting-related technologies that we provide and actively develop.\nKotlin scripting is the technology that enables executing Kotlin code as scripts without prior compilation or packaging into executables. In addition, several extension mechanisms exist to facilitate the usage of Kotlin for specific applications, such as configuring build tools. On top of that, REPL functionality, which is closely related to scripting, is available for Kotlin in various forms (including, for example, Kotlin Notebook).\nAll these technologies can be found in Kotlin and other JetBrains projects. Some of them are well known, others are barely used, but all require a noticeable amount of attention from the team.\nThe evolution of scripting in Kotlin\nScripting was introduced into Kotlin long ago as an experiment to investigate new ways of using the language. Since then, the development has been driven by the demand of external and internal adopters, as well as some experiments born inside our team. Over time, we accumulated a lot of functionality related to scripting in our codebase, and the effort required to support it grew quite significantly. Therefore, at some point, we started to review the functionality we have, how it is used inside and outside of JetBrains, and how we can distill it into a reasonable minimal subset that we are willing to support and develop without breaking too many existing use cases.\nThis blog post attempts to summarize our findings, explain our decisions, and outline the future directions in this area. We hope it will clarify the future of scripting in Kotlin and give the community a solid basis for making technical decisions. \nWhile we already have a firm roadmap for the immediate future, we welcome and appreciate your feedback and ideas for further improvements. We are especially interested in hearing about any particular use cases for scripting that you may have. We encourage you to use comments here or create YouTrack issues describing your scenarios and how the announced changes may affect them. Your insights are invaluable to us and will play a crucial role in shaping our future plans for the language’s development.\nContribute Your Feedback and Ideas\nBasic scripting\nWe conducted some research into scripting usage in the past and concluded that besides a few main adoptions, like Gradle build scripts, there is a relatively small number of known uses for scripting and REPL. This might be attributable to various factors, but the result is nonetheless clear: The functionality is not as popular as we had anticipated.\nSome technological problems could (and will) be addressed, but there are some inherent issues with attempting to position Kotlin as a scripting language. \nIn particular, Kotlin is not an interpreted language, and it cannot achieve the user experience typical for dedicated scripting languages. To achieve the current script-like behavior, we compile the code under the hood. The compilation process is quite intensive because the Kotlin compiler was not designed for such scenarios. \nThat is why we made the following decision:\nAlthough we will continue to provide generalized support for scripting in Kotlin, which includes compilation and evaluation of basic `.kts` files, as well as custom scripting (more about this below), we are not prepared to recommend Kotlin scripting as a generally applicable scripting solution, for example, as a replacement for Bash or Python.\nOn the other hand, we believe there are many new usage scenarios where, despite the known limitations, the use of Kotlin scripting could be beneficial. There are also several other potential use cases that we would like to explore further.\nCustom script types\nThe most powerful scripting solutions require extension mechanisms that allow for the customization of script compilation and evaluation. One of the most prominent examples is Gradle Kotlin DSL, where the Custom Scripting API is used to bring Kotlin language with traditional Gradle DSL to build scripts. This brings us to the second decision:\nWe will continue to support the Custom Scripting API (an unofficial name for a set of APIs for customizing script compilation and evaluation, as well as APIs for embedding script hosts into third-party applications). Therefore:\nWe are concentrating our efforts on improving the user experience with a few known use cases, in particular Gradle Kotlin DSL and select others.\nOutside these use cases, the API remains in the experimental state. Hence, things like documentation and IDE support for generic custom script support may continue to lag behind.\nMain.kts\nIn addition to the basic and custom scripting, we would like to continue supporting `.main.kts` scripts. The `.main.kts` scripts were initially developed to demonstrate the utility of the Custom Scripting API. However, with its support of dependencies and other features, it was adopted by many users as a default Kotlin scripting solution. Therefore, the next decision is:\nWe will continue to develop the `.main.kts` script type, which is already helpful for simple automation tasks. We have plans to extend its functionality and streamline IDE support. Such scripts continue to be supported out of the box in the Kotlin compiler and the Kotlin plugin for IntelliJ IDEA.\nKotlin REPL\nThe default REPL implementation has been a part of the Kotlin compiler (`kotlinc`) and Kotlin plugin for IntelliJ IDEA since the first release. Still, the functionality is limited, and improving it was never a priority for the team. Therefore, the user experience is not on par with the general Kotlin user experience in IntelliJ IDEA. We made several attempts to spin off alternative REPL implementations (e.g. the Kotlin Interactive Shell), but unfortunately, these never gained enough traction.\nMeanwhile, we are improving the Kotlin Notebook plugin for IntelliJ IDEA, which offers a smooth, extensive, and interactive experience working in Kotlin. With Kotlin Notebook, you can develop and experiment with Kotlin code, receive immediate outputs, and visualize data. We believe that it is an excellent replacement for all our current REPL solutions. \nBesides that, IntelliJ IDEA provides Kotlin Scratch files, where you can quickly prototype your code. Therefore:\nWe plan to sunset the default REPL implementations in the Kotlin compiler and the IntelliJ IDEA plugin.\nCLI REPL (via `kotlinc`) will continue to function at least until the release of Kotlin 2.3, but its operation will be limited to compatibility mode, i.e. with the `-language-version 1.9` option set (and may require an opt-in flag starting from release 2.2). \nThe default Kotlin REPL in the IntelliJ IDEA plugin will be removed in one of the next IntelliJ IDEA releases. \nWe will continue to promote the Kotlin Notebook plugin and IDE Scratch files as solutions for interactive Kotlin development.\nThis decision places some uncertainty on the external REPL implementations, like the Kotlin Interactive Shell. Although we plan to keep some REPL-related functionality in the compiler and Custom Scripting API (not least because solutions like Kotlin Notebook rely on them), with a final switch to the K2 compiler, a significant portion of this functionality will be changed or dropped, so it may require substantial effort to rewrite such implementations to the changed APIs. \nOther technologies based on Kotlin scripting\nBesides these main areas, there are a few other related technologies and APIs for scripting that we are currently supporting. We believe the cases explicitly mentioned above cover a majority of possible user needs. Therefore, we plan to drop most other scripting-related components and libraries from the compiler and IntelliJ IDEA. In particular:\nJSR-223 support – considering that the original JSR is in the withdrawn state, we do not believe supporting the de-facto obsolete API makes sense. The existing implementation will continue to function at least until the release of Kotlin 2.3 in the language version 1.9 compatibility mode (but we may consider renaming the artifact to raise awareness of the planned changes), and it will be dropped after that.\n`KotlinScriptMojo` – a Maven plugin that supports script execution during the Maven build. We did not find evidence of enough usages to keep maintaining it, so we plan to drop it in one of the next Kotlin releases.\n`kotlin-scripting-ide-services` – a library for implementing code completion functionality, mainly for REPL implementations. It is currently used in projects like Kotlin Interactive. It is heavily based on the infrastructure of the pre-K2 compiler and cannot be easily ported to the K2 version. Therefore, it will most likely stop working around the release of Kotlin 2.3 and will be removed from the codebase. We may consider reimplementing similar functionality on top of K2 in the future, but for now, this is not something we are actively pursuing.\nMoving forward\nWe hope the focused approach will allow us to move forward and provide a better experience with widely used scripting technologies. At the same time, it will free some resources for exciting language features and applications. We encourage you to share your use cases for scripting and appreciate your feedback on these changes and how they may affect your work.\nShare Your Feedback and Use Cases\nWhat else to read\nKotlin Notebook – documentation\nKotlin DSL Is Now the Default for New Gradle Builds",
        "dc:creator": "Anton Yalyshev",
        "content": "Update: we made some updates to the original post to accurately reflect the state of Custom Scripting and to avoid misinterpretations. TL;DR: Kotlin scripting remains an essential part of the Kotlin infrastructure. We continue to support it in the experimental state, and we are concluding certain experiments and reducing the number of scripting-related technologies that [&#8230;]",
        "contentSnippet": "Update: we made some updates to the original post to accurately reflect the state of Custom Scripting and to avoid misinterpretations. TL;DR: Kotlin scripting remains an essential part of the Kotlin infrastructure. We continue to support it in the experimental state, and we are concluding certain experiments and reducing the number of scripting-related technologies that […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=527650",
        "categories": [
          "ecosystem",
          "news",
          "kotlin-scripting"
        ],
        "isoDate": "2024-11-19T16:07:29.000Z"
      },
      {
        "creator": "Helen Scott",
        "title": "Code Faster with JetBrains AI in PyCharm",
        "link": "https://blog.jetbrains.com/pycharm/2024/11/code-faster-with-jetbrains-ai-in-pycharm/",
        "pubDate": "Tue, 19 Nov 2024 15:25:51 +0000",
        "content:encodedSnippet": "PyCharm 2024.3 comes with many improvements to JetBrains AI to help you code faster. I’m going to walk you through some of these updates in this blog post. \n\n\n\n\n\n\nNatural language inline AI prompt\nYou can now use JetBrains AI by typing straight into your editor in natural language without opening the AI Assistant tool window. If you use either IntelliJ IDEA or PyCharm, you might already be familiar with natural language AI prompts, but let me walk you through the process. \nIf you’re typing in the gutter you can start typing your request straight into the editor, and then press Tab. Here’s an example of one such request:\nwrite a script to capture a date input from a user and print it out prefixed by a message stating that their birthday is on that date.\nYou can then iterate on the initial input by clicking on the purple block in the gutter or by pressing ⌘\\ or Ctrl+\\ and pressing Enter:\nadd error handling so that when a birthday is in the future, we dont accept it\n\n\n\n\nYou can use  ⌘\\ or Ctrl+\\ to keep iterating until you’re happy with the result. For example, we can use the prompt:\nprint out the day of the week as well as their birthday date\nAnd then: \nchange the format of day_of_week to short\n\n\n\n\nThis feature is available for Python, JavaScript, TypeScript, JSON, and YAML files.\nLet’s look at some more examples. We can get JetBrains AI Assistant to help us generate new code with a prompt like this:\nWrite code that lists the latest polls, shows poll details, handles voting, updates votes, and displays poll results, ensuring only published polls are accessible.\n\n\n\n\nOr add some error handling to our code:\nAdd edge case handling to this code\n\n\n\n\nRemember, context is everything. Where you start your natural language prompt is important, as PyCharm uses the placement of your caret to figure out the context. You don’t need to prefix your query with a ? or $ if you start typing in the gutter because the context is the file, but if your caret is indented, you’ll need to start your query with the ? or $ character so PyCharm knows you’re crafting a natural language query.\nIn this example, we want to refactor existing code, so we need to prefix our query with the ? character:\n?create a dedicated function for printing the schedule and remove the code from here\n\n\n\n\n\n          \n        Try JetBrains AI for free\n    \n\n\n\n\nRunning code in the Python console\nWe know that JetBrains AI can generate code for you, but now you can run that code in the Python console without leaving the AI Assistant tool window by clicking the green run arrow.\nFor example, let’s say you have the following prompt:\nCreate a python script that asks for a birthday date in standard format yyy-MM-dd then converts it and prints it back out in a written format such as 22nd January 1991 \nYou can now click the green run arrow on the top-right of the code snippet to run it in your Python console:\n\n\n\n\nEven more features\nIn addition to the new functionality for natural language and code completion for PyCharm highlighted above, there are several other improvements to JetBrains AI. \nFaster code completion\nWe have introduced a new model for faster cloud-based completion with AI Assistant which is showing very promising results.\n\n\n\n\nFaster documentation\nIf documentation isn’t your thing, you can now hand off writing your Python docstrings to JetBrains AI. If you type either single or double quotes to enter a docstring and then press Return, you’ll see a prompt that says Generate with AI Assistant. Click that prompt and let JetBrains AI generate the documentation for you:\n\n\n\n\nHelp at your fingertips\nWe all need a little help now and again, and we can get JetBrains AI to help us here too. We’ve added a /docs prompt to the JetBrains AI tool window. This prompt will query the PyCharm documentation to save you from switching out of the context you’re working in!\n\n\n\n\nAbility to choose your LLM\nFor AI Chat, you can now select a different LLM from the drop-down menu in the chat window itself. There are lots of options for you to choose from:\n\n\n\n\nMore context in Jupyter notebooks\nWe’ve also improved how JetBrains AI works for data scientists. JetBrains AI now recognizes DataFrames and variables in your notebook. You can prefix your DataFrame or variable with # so that JetBrains AI considers it as part of the context. \n\n\n\n\nSummary\nJetBrains AI is available inside PyCharm, right where you need it. This release brings many improvements, from writing in natural language inside the editor and running AI-generated Python snippets in the console to generating documentation. \nRemember, if you’re in the gutter, you can start typing in natural language and then press Tab to get AI Assistant to generate the code. If you’re inside a method or function, you need to prefix your natural language query with either ? or $. You can then iterate on the generated code as many times as you like as you build out your new functionality and explore further.\n      \n        Try JetBrains AI for free",
        "dc:creator": "Helen Scott",
        "content": "PyCharm 2024.3 comes with many improvements to JetBrains AI to help you code faster. I’m going to walk you through some of these updates in this blog post.&#160; Natural language inline AI prompt You can now use JetBrains AI by typing straight into your editor in natural language without opening the AI Assistant tool window. [&#8230;]",
        "contentSnippet": "PyCharm 2024.3 comes with many improvements to JetBrains AI to help you code faster. I’m going to walk you through some of these updates in this blog post.  Natural language inline AI prompt You can now use JetBrains AI by typing straight into your editor in natural language without opening the AI Assistant tool window. […]",
        "guid": "https://blog.jetbrains.com/?post_type=pycharm&p=527669",
        "categories": [
          "ai-assistant",
          "productivity"
        ],
        "isoDate": "2024-11-19T15:25:51.000Z"
      },
      {
        "creator": "Aleksandra Zdrojowa",
        "title": "New Module Layout for sbt Projects",
        "link": "https://blog.jetbrains.com/scala/2024/11/19/new-module-layout-for-sbt/",
        "pubDate": "Tue, 19 Nov 2024 15:00:19 +0000",
        "content:encodedSnippet": "Try out the enhanced sbt integration with IntelliJ Scala Plugin 2024.3\nWe’re introducing a new mode that better represents the structure of sbt projects in IntelliJ IDEA by organizing main and test sources into separate modules. The improved layout resolves several issues with compilation and highlighting. It also allows using different compiler options for main and test sources.\nWe strongly encourage you to try out this new functionality and share your feedback! Enable it via Settings | Build, Execution, Deployment | Build Tools | sbt and select Create separate modules for production and test sources.\nTechnical background\nEach build tool has its own model to represent the project – this includes concepts of modules, dependencies, and much more.When the project is imported to IntelliJ IDEA, it is essential to translate this model into the IDE’s internal model, which may not perfectly align with the build tool’s structure.\nImproperly mapping a given build tool’s model to IntelliJ IDEA’s model can lead to issues, such as code compiling when it shouldn’t (or vice versa) and incorrect highlighting.\nA significant challenge when mapping the sbt model was the limited distinction between main and test sources. When managing dependencies between two modules, all sources from the dependent module were added to the parent module, making it impossible to include only the main sources. Another issue was configuring separate compiler options for main and test sources.\nTo address these issues, a new approach has been developed for mapping the sbt model to IntelliJ IDEA – creating separate modules for main and test sources.\n\n\n\n\nHow it works\nFor each project declared in the sbt build, two additional modules are created: main and test. They contain the main and test sources, respectively.\n\n\n\n\n\nWhen the project is reloaded in the new mode, each run configuration that references a module should switch to the corresponding main or test module. This happens automatically when the new mode is activated. In very rare cases, it may not be possible to change the modules in the run configurations automatically. If this happens, a notification will appear, giving you the option to update the run configurations manually. If you miss the notification, you can still update the run configurations by explicitly using the Update Run Configurations to the new module naming scheme action.\n\n\n\n\n\nKey improvements\nThese examples illustrate the most noticeable changes. However, enabling the new mode also allows for many other improvements, such as more accurate handling of transitive dependencies, support for compile->test dependencies, and better management of -internal configurations.\n\n\n\n\nDifferent compiler options for Compile and Test scopes\nsbt allows you to declare different compiler options in various configuration scopes. The new project model in IntelliJ IDEA now leverages this capability by recognizing compiler options declared in the Test scope, allowing you to configure different options for Compile and Test scopes in the IDE.\nFor example, if you configure scalacOptions in an sbt project like this:\nTest / scalacOptions += \"-Ywarn-value-discard\"\nthen warnings about discarded values will only be displayed in the test sources.\n\nIf you configure the options in the Compile scope like this:\nCompile / scalacOptions += \"-Ywarn-value-discard\"\nthen warnings can be displayed both in the main and test sources.\n\n\n\n\n\nCompile scope project dependencies\nKeeping main and test sources in separate modules allows for a more accurate representation of dependencies. This is particularly significant for classpath dependencies, which are always per-configuration in sbt.\nLet’s consider a very common dependency example:\ncore.dependsOn(foo)\nwhich is always resolved to \ncore.dependsOn(foo %”compile->compile”)\nWhen separate modules for main and sources are created, this dependency resolves so that both core.main and core.test modules contain only the core.foo.main dependency. None of the core modules has foo.test in its dependencies, which is a proper sbt representation.\n\n\nIt’s worth mentioning that in the old implementation, the core module included the entire foo module. This meant that core test sources had access to foo test sources.\n\n\n\n\nHow to enable this feature\nAs this feature is currently in Beta, it is not enabled by default. Enable it via Settings | Build, Execution, Deployment | Build Tools | sbt and select Create separate modules for production and test sources.\n\n\n\n\n\nFeedback\nWe need your feedback! If you encounter any bugs in this feature, please report them to our YouTrack. If you have any questions, feel free to ask them on in our Discord.\nHappy developing!\nThe IntelliJ Scala Plugin team",
        "dc:creator": "Aleksandra Zdrojowa",
        "content": "Try out the enhanced sbt integration with IntelliJ Scala Plugin 2024.3 We’re introducing a new mode that better represents the structure of sbt projects in IntelliJ IDEA by organizing main and test sources into separate modules. The improved layout resolves several issues with compilation and highlighting. It also allows using different compiler options for main [&#8230;]",
        "contentSnippet": "Try out the enhanced sbt integration with IntelliJ Scala Plugin 2024.3 We’re introducing a new mode that better represents the structure of sbt projects in IntelliJ IDEA by organizing main and test sources into separate modules. The improved layout resolves several issues with compilation and highlighting. It also allows using different compiler options for main […]",
        "guid": "https://blog.jetbrains.com/?post_type=scala&p=527952",
        "categories": [
          "intellij",
          "sbt",
          "scala"
        ],
        "isoDate": "2024-11-19T15:00:19.000Z"
      },
      {
        "creator": "Vaclav Pech",
        "title": "The MPS 2024.3 Early Access Program Is Open",
        "link": "https://blog.jetbrains.com/mps/2024/11/the-mps-2024-1-eap-has-started-2-2/",
        "pubDate": "Tue, 19 Nov 2024 13:07:36 +0000",
        "content:encodedSnippet": "The first EAP build of MPS 2024.3 is now ready for you to download and try!\nDOWNLOAD MPS 2024.3 EAP\nThe new version includes numerous fixes and improvements. Here are the two major ones that deserve special attention:\nIcon handling\nIcons and images that use a path relative to the module are no longer copied during generation next to the places of their individual usage. Instead, they are copied to the distribution module once as image files and are available for use at this single location. This has two immediate benefits: avoiding the duplication of image files to save disk space and the ability to access the images both from the distribution and from the source module.\nConstant icons\nIn addition to the existing TextIcon and FileIcon concepts, a new ConstantFieldIcon concept has become available. It allows an icon to be specified by reference to a concrete static field declaration holding an instance of javax.swing.Icon.\nTextGen binary outcome\nInspired by the need for the improved handling of icon files, there is now a new mechanism to produce binary output during the TextGen process instead of text. The new API consists of a write operation that directly manipulates data as instances of byte[].\nNumerous bug fixes\nYou can find a full list of the issues we’ve fixed here.\nThis is only the first EAP release. We will keep adding more features and bigfixes to MPS 2024.3, so stay tuned!\nYour JetBrains MPS team",
        "dc:creator": "Vaclav Pech",
        "content": "The first EAP build of MPS 2024.3 is now ready for you to download and try! DOWNLOAD MPS 2024.3 EAP The new version includes numerous fixes and improvements. Here are the two major ones that deserve special attention: Icon handling Icons and images that use a path relative to the module are no longer copied [&#8230;]",
        "contentSnippet": "The first EAP build of MPS 2024.3 is now ready for you to download and try! DOWNLOAD MPS 2024.3 EAP The new version includes numerous fixes and improvements. Here are the two major ones that deserve special attention: Icon handling Icons and images that use a path relative to the module are no longer copied […]",
        "guid": "https://blog.jetbrains.com/?post_type=mps&p=528203",
        "categories": [
          "releases",
          "eap",
          "release"
        ],
        "isoDate": "2024-11-19T13:07:36.000Z"
      },
      {
        "creator": "Siva Katamreddy",
        "title": "From Code to Clarity With the Redesigned Structure Tool Window",
        "link": "https://blog.jetbrains.com/idea/2024/11/from-code-to-clarity-with-the-redesigned-structure-tool-window/",
        "pubDate": "Tue, 19 Nov 2024 13:06:12 +0000",
        "content:encodedSnippet": "Developers usually spend more time reading existing code than writing new code. To understand the existing codebase of an application, developers spend a good amount of time looking at how various frameworks and libraries are configured and how different components interact with each other.\nWhile developing JetBrains AI Assistant, we enriched prompts with context extracted from file links and dependencies. This context proved valuable for both AI and human understanding.\nIn this article, you will learn:\nHow our R&D on AI Assistant led to redesigning the Structure tool window.\nHow to use the new Structure tool window’s Logical view to explore and understand your existing codebase.\nHow you can perform various context-relevant actions from the Structure tool window itself.\nBackground\nAI assistants can produce disappointing results when asked to generate or explain code. This is because they can lack the rich context that developers are aware of. A project is not just code. It’s a complex interplay of components, both explicit like method calls, and implicit, defined by the framework being used. Understanding these intricate connections is crucial for accurate AI assistance.\nTo get the best results from AI Assistant, we need to describe all this context to it. This same context would be invaluable for developers. In IntelliJ IDEA, the main code navigation tool is the Project tool window. It provides a code-level view of the project, including folders, packages, and files. Though familiar, the Project tool window doesn’t show links between code components. Developers have to figure those out themselves by looking for class usages for explicit links and reading the framework documentation for implicit ones.\nUnsurprisingly, IntelliJ IDEA knows a lot about project internals. While implementing support for a language or framework in the IDE, we, as developers, have to understand how a technology works under the hood. For example, if you open a file from the project implemented with the Spring Boot framework, you’ll see components like bean indicators, injection points, and web API endpoints.\nWe recently introduced an internal API to implement domain context providers – code that can collect extended information about a project structure, used tech stack, etc. The first step was to provide better context for AI Assistant. We conducted R&D by seamlessly enriching prompts with the information from domain providers – this showed good results!\nThe second step involved using this information to show the code structure from the framework perspective. In IntelliJ IDEA, the Structure tool window presents the structure of a selected file. We decided to enhance this window and add a Logical view, which illustrates the file structure from the framework point of view. This means that you can now see how a selected piece of code, such as a file or class, is connected to other parts of the application. This context is sometimes more valuable than the code itself because it helps you understand how an application works.\nStructure tool window redesign\nLet’s explore a Spring Boot application to learn how the new Structure tool window provides better insights into your application by providing a logical structure of the components, indicating how they all work together.\nThe entry point of any Spring Boot application is the main application class annotated with @SpringBootApplication. The class code’s physical structure is simple:\n@SpringBootApplication\npublic class BlogApplication {\n\n\tpublic static void main(String[] args) {\n\t\tSpringApplication.run(BlogApplication.class, args);\n\t}\n}\n\nThe magic of Spring Boot is hidden in bean configurations – classes that instantiate required services based on various conditions and put them into the Spring context. Now, we can see it!\n\nDomain context providers know which configurations are scanned and which beans are instantiated by bean configuration – it’s all revealed in the structure.\nNow, let’s take a look at how the Structure tool window shows the logical view of a Spring Boot REST controller.\n\nThe Structure tool window displays the autowired Spring beans in the Autowires node and the API endpoints defined in the controller class. When you click on any API endpoint, you will be taken to that method in the editor. You can also click on the API gutter icon to invoke that API endpoint in the HTTP Client.\nThe Spring Framework provides event publishing and consuming capabilities using ApplicationEventPublisher. If the selected Spring bean publishes events using ApplicationEventPublisher, you can see these details under the Publishers node.\n\nSimilarly, if the Spring bean implements event listeners using @EventListener, the listeners’ details are shown under the Listeners node.\n\nLet’s take another example: JPA entities.\nThe Structure tool window also provides a Logical view of JPA entities by providing a lot of context, such as the column mappings, relationship with other entities, Spring Data JPA repositories associated with the entity, and related DTOs and projections:\n\nIf you select the Entity node, you can see the DDL gutter icon which you can use to generate an SQL script to create the table.\nSimilarly, IntelliJ IDEA provides a Logical view for other Spring components like MVC controllers, services, repositories, and configuration classes.\n\nConclusion\nAn application’s complex structure consists of various parts, including code, dependencies, build processes, and deployment scripts. A solid grasp of the connections between these components is crucial for a comprehensive understanding of the application’s architecture and functionality. \nBy introducing domain context providers, we can explain the code structure from another point of view, revealing hidden framework-specific connections between various components. This can be useful for AI Assistant, so its answers could be improved, as well as for developers to help them understand the code better.\nThe redesigned Structure tool window’s Logical view allows you to see the application structure and navigate through linked components. The context-specific actions associated with the selected component make it easy to perform various tasks right from the Structure tool window itself.\nCurrently, the IDE supports Jakarta EE and Spring, and we plan to expand this support to other technologies like frameworks, build tools, and Docker configuration files.\nYou can find the official documentation for Logical structure here .\nThe redesigned Structure tool window is available in IntelliJ IDEA Ultimate 2024.3, and the context-relevant actions support will be available from version 2024.3.1. You can install the latest version of the IDE from the JetBrains Toolbox App, or you can download and install it from our website.\nDownload IntelliJ IDEA",
        "dc:creator": "Siva Katamreddy",
        "content": "Developers usually spend more time reading existing code than writing new code. To understand the existing codebase of an application, developers spend a good amount of time looking at how various frameworks and libraries are configured and how different components interact with each other. While developing JetBrains AI Assistant, we enriched prompts with context extracted [&#8230;]",
        "contentSnippet": "Developers usually spend more time reading existing code than writing new code. To understand the existing codebase of an application, developers spend a good amount of time looking at how various frameworks and libraries are configured and how different components interact with each other. While developing JetBrains AI Assistant, we enriched prompts with context extracted […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=524902",
        "categories": [
          "idea",
          "java",
          "jetbrains-ai",
          "ai-assistant",
          "spring-boot"
        ],
        "isoDate": "2024-11-19T13:06:12.000Z"
      },
      {
        "creator": "Elena Kerpeleva",
        "title": "Busy Plugin Developers Newsletter – Q3 2024",
        "link": "https://blog.jetbrains.com/platform/2024/11/busy-plugin-developers-newsletter-q3-2024/",
        "pubDate": "Mon, 18 Nov 2024 20:39:43 +0000",
        "content:encodedSnippet": "⭐️ Community highlights\nJetBrains Plugin Developer Conf 2024: Kicking off our first event\nOn November 7, we hosted the first-ever JetBrains Plugin Developer Conf, a virtual event dedicated entirely to plugin development for JetBrains products.\n\n\n\n\nThe conference brought together JetBrains experts and plugin developers to explore a wide range of topics, including developing and launching plugins on JetBrains Marketplace, plugin localization, handling user feedback, plugin testing, building collaborative plugins, and more. Attendees also got a glimpse into our future plans for Marketplace and the latest tooling updates.\nMissed the event? You can watch the recording here.\n⭐️ Marketplace updates\nSpecial offers are now displayed on the Pricing Tab\nPaid plugin authors can now display discounts on the Pricing Tab, with the previous price crossed out. To set up a special offer, reach out to the JetBrains Marketplace Support team. Learn more in our documentation. \n\n\n\n\n\n\n\n\nSales report update\nWe’ve made some improvements to our sales report. You can now filter reports by month, and the table includes detailed information about purchased licenses. Additionally, the full report can be downloaded as a .csv file. \n\n\n\n\nMore new UI Icons for your plugins\nWe’ve added over 1,000 new UI icons to the IntelliJ Platform Icons library. These icons are tailored to the new UI and come with Apache 2.0 licensing. You can also use our Figma library to design your own custom icons. Get all the details in this blog post. \nMigrating your IntelliJ IDEA Kotlin plugin to K2 Mode\nIf your plugin code depends on the Kotlin K1 plugin API, this news is for you. Starting from IntelliJ 2024.2.1, you need to migrate to the Kotlin K2 mode. Otherwise, your plugin might not work properly when K2 mode is enabled. Learn more about how to migrate in this blog post.\n⭐️ Plugin development tooling updates\nIntelliJ Platform Plugin Template 2.0.2\nThe IntelliJ Platform Plugin Template is a repository that streamlines the initial stages of plugin development for IntelliJ-based IDEs. The latest update upgrades the Gradle Wrapper to 8.10.2, sets the platformVersion to 2023.3.8, and updates key dependencies. Check out the release notes for more details. \nIntelliJ Plugin Verifier 1.379\nPlugin Verifier Version 1.379 adds the ability to ignore restrictions on the internal com.intellij.languageBundle extension point, improved handling for malformed annotation descriptors with obfuscation, and support for composite action names with namespaces in TeamCity Actions. This update also removes duplicate vendor checks for JetBrains plugins, unifies plugin problem classification, and fixes an issue with empty dotnet plugin names. Check out the changelog for more details.\nIntelliJ Platform Gradle Plugin 2.0 is out\nVersion 2.0 of the IntelliJ Platform Gradle Plugin is now available. This updated plugin for the Gradle build system simplifies the configuration of environments for building, testing, verifying, and publishing plugins for IntelliJ-based IDEs.  Find all of the details here. \n⭐️ Useful resources\nThreading Model and Background Processes\nThe revamped Threading Model page provides updated guidance on managing concurrency in the IntelliJ Platform, detailing UI thread restrictions, background tasks, and thread safety to help developers build responsive, stable plugins. \nThe new Background Processes page complements this with best practices for handling asynchronous tasks, using progress indicators, and creating cancelable tasks for enhanced user experience and performance.\nWorkspace Model\nThe Workspace Model article introduces plugin developers to the Workspace Model in the IntelliJ Platform, highlighting its architecture, data handling capabilities, and interaction with the Project Model. It explains how to use the Workspace Model to efficiently store, manage, and access project-related data.",
        "dc:creator": "Elena Kerpeleva",
        "content": "⭐️ Community highlights JetBrains Plugin Developer Conf 2024: Kicking off our first event On November 7, we hosted the first-ever JetBrains Plugin Developer Conf, a virtual event dedicated entirely to plugin development for JetBrains products. The conference brought together JetBrains experts and plugin developers to explore a wide range of topics, including developing and launching [&#8230;]",
        "contentSnippet": "⭐️ Community highlights JetBrains Plugin Developer Conf 2024: Kicking off our first event On November 7, we hosted the first-ever JetBrains Plugin Developer Conf, a virtual event dedicated entirely to plugin development for JetBrains products. The conference brought together JetBrains experts and plugin developers to explore a wide range of topics, including developing and launching […]",
        "guid": "https://blog.jetbrains.com/?post_type=platform&p=527916",
        "categories": [
          "marketplace",
          "news",
          "busy-plugin-developers"
        ],
        "isoDate": "2024-11-18T20:39:43.000Z"
      },
      {
        "creator": "Alexandra Charikova",
        "title": "Let’s meet at Slush 2024 in Helsinki!",
        "link": "https://blog.jetbrains.com/blog/2024/11/18/let-s-meet-at-slush-2024-in-helsinki/",
        "pubDate": "Mon, 18 Nov 2024 18:26:29 +0000",
        "content:encodedSnippet": "Meet with our JetBrains for Startups team at Slush 2024 in Helsinki on November 20–21!\nThis November, our JetBrains team is returning for the third year in a row to the most founder-focused event on Earth. Join us at booth 7A2 to discuss how our tools can accelerate your startup’s growth, win exclusive swag, or simply drop by to say hello!\nOur team will be there to talk about AI, scaling startups, and the future of development. In addition, we’ll be showcasing our latest AI-powered tools, including IDEs, AI Assistant, and YouTrack. You can also catch a glimpse of the new tools, special partner offers, and exclusive resources that have been added to our JetBrains Startup Program. Whether you are building your first MVP, scaling up, or refining your product, our tools can support you in the process.\nYou can also learn more about our Partner Program for incubators, accelerators, and investors – a unique opportunity to bring JetBrains tools to your portfolio companies. To meet with us, book a slot via the Slush Platform, reach out at startups@jetbrains.com, or simply stop by our booth.\nDon’t miss our special activities, including a Wheel of Fortune with special prizes to be won!\n\n\n\n\nWhere to find us:\nHall: 7 | Booth: 7A2, near the Builder Stage and Mentoring Area\nVenue: Messukeskus Helsinki\n\n\n\n\nLearn more about our programs for startups:\nJetBrains Startup Program\nJetBrains Partner Program for incubators, accelerators and investors\nWe look forward to connecting with you at Slush 2024 and exploring how JetBrains can help bring your ideas to life. See you there!",
        "dc:creator": "Alexandra Charikova",
        "content": "Meet with our JetBrains for Startups team at Slush 2024 in Helsinki on November 20–21! This November, our JetBrains team is returning for the third year in a row to the most founder-focused event on Earth. Join us at booth 7A2 to discuss how our tools can accelerate your startup’s growth, win exclusive swag, or [&#8230;]",
        "contentSnippet": "Meet with our JetBrains for Startups team at Slush 2024 in Helsinki on November 20–21! This November, our JetBrains team is returning for the third year in a row to the most founder-focused event on Earth. Join us at booth 7A2 to discuss how our tools can accelerate your startup’s growth, win exclusive swag, or […]",
        "guid": "https://blog.jetbrains.com/?post_type=blog&p=528503",
        "categories": [
          "events",
          "startup-offer",
          "startups"
        ],
        "isoDate": "2024-11-18T18:26:29.000Z"
      },
      {
        "creator": "Teodor Irkhin",
        "title": "Kotlin K2 Mode Becomes Stable",
        "link": "https://blog.jetbrains.com/idea/2024/11/k2-mode-becomes-stable/",
        "pubDate": "Mon, 18 Nov 2024 14:16:21 +0000",
        "content:encodedSnippet": "In IntelliJ IDEA 2024.3, K2 mode is out of Beta and is now Stable and ready for general use. K2 mode significantly improves Kotlin code analysis stability, memory consumption efficiency, and the IDE’s overall performance, and it supports Kotlin 2.1 language features.\nBackground\nK2 mode in IntelliJ IDEA was developed to address limitations in the previous version of the Kotlin plugin, including various performance and stability issues. It aims to enhance the efficiency of the Kotlin plugin for IntelliJ IDEA by improving code analysis stability and performance while reducing UI freezes. Additionally, K2 mode enables support for new language features that will be introduced in Kotlin 2.1 and later versions.\nCompatibility\nIntelliJ IDEA’s K2 mode doesn’t depend on the Kotlin compiler version specified in the project’s build settings. K2 mode represents an almost complete rewrite of Kotlin support within the IDE. The name “K2” reflects that the Kotlin plugin includes an internal version of the K2 Kotlin compiler, which it uses for code analysis, while K1 mode uses the K1 compiler. The version of the Kotlin compiler bundled in IntelliJ IDEA is entirely independent of the version specified in the project’s build file, though it may affect the range of supported Kotlin versions in projects.\nHow to enable K2 mode\nTo enable K2 mode, go to Preferences/Settings | Languages & Frameworks | Kotlin and select the Enable K2 mode checkbox.\n\n\n\n\nResults\nAdoption\nSince the 2024.2 release, K2 mode (Beta) has shown adoption rates of 15% – and this number is growing weekly. K2 mode was enabled by default starting with 2024.3 EAP 1, and 86% of developers who tried it are still using it.\nPerformance\nWith the new architecture, K2 mode has vast potential for future enhancements, and we already have improvements in Kotlin code analysis, completion, and navigation speed. \nThere are benchmarks that we use to measure the performance of the most popular IntelliJ IDEA features. These benchmarks work on real codebases, including open-source and internal projects. Here are some of the projects we measured the performance on:\nIntelliJ IDEA: the IntelliJ IDEA Ultimate’s source code (closed source)\nkotlinx.coroutines https://github.com/Kotlin/kotlinx.coroutines \nKtor: https://github.com/ktorio/ktor\n\n\n\n\nBelow are the results. Lower is better.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnsupported functionality \nSome third-party IntelliJ IDEA plugins that depend on the Kotlin plugin may be currently unavailable because of recent changes to the Kotlin plugin API. We’re actively working on supporting plugin authors to make their plugins compatible with K2 mode as quickly as possible. For more information, please refer to our detailed migration guide.\nSome functionality like Kotlin scratch file support, as well as some minor inspections, intention actions, and quick-fixes are still in progress and will be supported in the next version.\nPlans for the future\nBy the 2025.1 version, we plan to make K2 mode the default option.\nWith the new architecture, we’ve broken the ceiling of previous limitations, and we now have many new ways to improve the future performance of the Kotlin plugin. We’ll continue to make it more performant, memory-efficient, and stable to make your experience smoother. While K2 mode is a powerful tool, it’s important to note that it won’t address all challenges immediately, but it does provide a great foundation from which we can make further improvements! \nThe future of Kotlin awaits!",
        "dc:creator": "Teodor Irkhin",
        "content": "In IntelliJ IDEA 2024.3, K2 mode is out of Beta and is now Stable and ready for general use. K2 mode significantly improves Kotlin code analysis stability, memory consumption efficiency, and the IDE’s overall performance, and it supports Kotlin 2.1 language features. Background K2 mode in IntelliJ IDEA was developed to address limitations in the [&#8230;]",
        "contentSnippet": "In IntelliJ IDEA 2024.3, K2 mode is out of Beta and is now Stable and ready for general use. K2 mode significantly improves Kotlin code analysis stability, memory consumption efficiency, and the IDE’s overall performance, and it supports Kotlin 2.1 language features. Background K2 mode in IntelliJ IDEA was developed to address limitations in the […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=527536",
        "categories": [
          "idea",
          "kotlin",
          "news",
          "intelij-idea",
          "k2"
        ],
        "isoDate": "2024-11-18T14:16:21.000Z"
      },
      {
        "creator": "Kerry Beetge",
        "title": "Qodana Case Studies: How Moovit Prevents Production Incidents With Code Analysis by Qodana",
        "link": "https://blog.jetbrains.com/qodana/2024/11/qodana-case-studies-moovit/",
        "pubDate": "Mon, 18 Nov 2024 13:03:28 +0000",
        "content:encodedSnippet": "Moovit – a popular commuter app serving 1.5 billion users in over 3,500 cities – has become a critical part of people’s daily transit since its inception in 2012. \nAs with any large-scale application, the Moovit team has to maintain a clean and sustainable codebase to limit outages and ensure a smooth and effective service for its widespread user base. This also had to be achieved within a team that included users of Java, Spring, Jenkins, and IntelliJ IDEA. \nTechnically, this requires:\nNull pointer detection and finding other flaws that can cause outages.\nReducing production issues in the development stage.\nEnforcing critical code rules, team-wide.\nEnhancing developer productivity and adopting best practices.\n\n\n\n\nPaving the road to production readiness with Qodana\nAfter careful deliberation, Moovit selected Qodana. They were impressed by its strong integration capabilities, competitive pricing, and high level of customization – a combination of features they couldn’t find with another provider. Once these important boxes were checked, the Moovit team used Qodana to:\nHelp run quick scans for early issue detection.\nCreate custom rules and configurations suited to their use case. \nImprove scalability and cost-effectiveness throughout the development process. \nThe result?\n“In the long term, it has stabilized our production system and allowed developers to avoid fixing issues too late in the pipeline. We’re seeing the shift of the paradigm, where development teams follow the policies and save a few sleepless nights with Qodana.”\n\n            \nAmit Weinblum\n                                                                Infrastructure Team Leader at Moovit\n                                    \nView the official case study below for more information on the project and how Moovit benefited from prioritizing code quality with Qodana and IntelliJ IDEA. You can also view other Qodana case studies for more information on how your team can benefit from Qodana. \nView Case Study",
        "dc:creator": "Kerry Beetge",
        "content": "Moovit – a popular commuter app serving 1.5 billion users in over 3,500 cities – has become a critical part of people’s daily transit since its inception in 2012.&#160; As with any large-scale application, the Moovit team has to maintain a clean and sustainable codebase to limit outages and ensure a smooth and effective service [&#8230;]",
        "contentSnippet": "Moovit – a popular commuter app serving 1.5 billion users in over 3,500 cities – has become a critical part of people’s daily transit since its inception in 2012.  As with any large-scale application, the Moovit team has to maintain a clean and sustainable codebase to limit outages and ensure a smooth and effective service […]",
        "guid": "https://blog.jetbrains.com/?post_type=qodana&p=527652",
        "categories": [
          "case-study-qodana",
          "idea",
          "qodana",
          "casestudy",
          "intellijidea"
        ],
        "isoDate": "2024-11-18T13:03:28.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": [
      {
        "creator": "Kidai Kwon",
        "title": "Building a User Signals Platform at Airbnb",
        "link": "https://medium.com/airbnb-engineering/building-a-user-signals-platform-at-airbnb-b236078ec82b?source=rss----53c7c27702d5---4",
        "pubDate": "Wed, 20 Nov 2024 19:27:27 GMT",
        "content:encodedSnippet": "How Airbnb built a stream processing platform to power user personalization.\nBy: Kidai Kwon, Pavan Tambay, Xinrui Hua, Soumyadip (Soumo) Banerjee, Phanindra (Phani) Ganti\n\nOverview\nUnderstanding user actions is critical for delivering a more personalized product experience. In this blog, we will explore how Airbnb developed a large-scale, near real-time stream processing platform for capturing and understanding user actions, which enables multiple teams to easily leverage real-time user activities. Additionally, we will discuss the challenges encountered and valuable insights gained from operating a large-scale stream processing platform.\nBackground\nAirbnb connects millions of guests with unique homes and experiences worldwide. To help guests make the best travel decisions, providing personalized experiences throughout the booking process is essential. Guests may move through various stages — browsing destinations, planning trips, wishlisting, comparing listings, and finally booking. At each stage, Airbnb can enhance the guest experience through tailored interactions, both within the app and through notifications.\nThis personalization can range from understanding recent user activities, like searches and viewed homes, to segmenting users based on their trip intent and stage. A robust infrastructure is essential for processing extensive user engagement data and delivering insights in near real-time. Additionally, it’s important to platformize the infrastructure so that other teams can contribute to deriving user insights, especially since many engineering teams are not familiar with stream processing.\nAirbnb’s User Signals Platform (USP) is designed to leverage user engagement data to provide personalized product experiences with many goals:\n\nAbility to store both real-time and historic data about users’ engagement across the site.\nAbility to query data for both online use cases and offline data analyses.\nAbility to support online serving use cases with real-time data, with an end-to-end streaming latency of less than 1 second.\nAbility to support asynchronous computations to derive user understanding data, such as user segments and session engagement.\nAbility to allow various teams to easily define pipelines to capture user activities.\n\nUSP System Architecture\nUSP consists of a data pipeline layer and an online serving layer. The data pipeline layer is based on the Lambda architecture with an online streaming component that processes Kafka events near real-time and an offline component for data correction and backfill. The online serving layer performs read time operations by querying the Key Value (KV) store, written at the data pipeline layer. At a high-level, the below diagram demonstrates the lifecycle of user events produced by Airbnb applications that are transformed via Flink, stored in the KV store, then served via the service layer:\nFigure 1. USP System Architecture Overview\nKey design choices that were made:\n\nWe chose Flink streaming over Spark streaming because we previously experienced event delays with Spark due to the difference between micro-batch streaming (Spark streaming), which processes data streams as a series of small batch jobs, and event-based streaming (Flink), which processes event by event.\nWe decided to store transformed data in an append-only manner in the KV store with the event processing timestamp as a version. This greatly reduces complexity because with at-least once processing, it guarantees idempotency even if the same events are processed multiple times via stream processing or batch processing.\nWe used a config based developer workflow to generate job templates and allow developers to define transforms, which are shared between Flink and batch jobs in order to make the USP developer friendly, especially to other teams that are not familiar with Flink operations.\n\nUSP Capabilities\nUSP supports several types of user event processing based on the above streaming architecture. The diagram below is a detailed view of various user event processing flows within USP. Source Kafka events from user activities are first transformed into User Signals, which are written to the KV store for querying purposes and also emitted as Kafka events. These transform Kafka events are consumed by user understanding jobs (such as User Segments, Session Engagements) to trigger asynchronous computations. The USP service layer handles online query requests by querying the KV store and performing any other query time operations.\nFigure 2. USP Capabilities Flow\nUser Signals\nUser signals correspond to a list of recent user activities that are queryable by signal type, start time, and end time. Searches, home views, and bookings are example signal types. When creating a new User Signal, the developer defines a config that specifies the source Kafka event and the transform class. Below is an example User Signal definition with a config and a user-defined transform class.\n- name: example_signal\n  type: simple\n  signal_class: com.airbnb.usp.api.ExampleSignal\n  event_sources:\n  - kafka_topic: example_source_event\n    transform: com.airbnb.usp.transforms.ExampleSignalTransform\npublic class ExampleSignalTransform extends AbstractSignalTransform {\n  @Override\n  public boolean isValidEvent(ExampleSourceEvent event) {\n  }\n  @Override\n  public ExampleSignal transform(ExampleSourceEvent event) {\n  }\n}\nDevelopers can also specify a join signal, which allows joining multiple source Kafka events with a specified join key near real-time via stateful streaming with RocksDB as a state store.\n- name: example_join_signal\n  type: left_join\n  signal_class: com.airbnb.usp.api.ExampleJoinSignal\n  transform: com.airbnb.usp.transforms.ExampleJoinSignalTransform\n  left_event_source:\n    kafka_topic: example_left_source_event\n    join_key_field: example_join_key\n  right_event_source:\n    kafka_topic: example_right_source_event\n    join_key_field: example_join_key\nOnce the config and the transform class are defined for a signal, developers run a script to auto-generate Flink configurations, backfill batch files, and alert files like below:\n$ python3 setup_signal.py --signal example_signal\nGenerates:\n# Flink configuration related\n[1] ../flink/signals/flink-jobs.yaml\n[2] ../flink/signals/example_signal-streaming.conf\n# Backfill related files\n[3] ../batch/example_signal-batch.py\n# Alerts related files\n[4] ../alerts/example_signal-events_written_anomaly.yaml\n[5] ../alerts/example_signal-overall_latency_high.yaml\n[6] ../alerts/example_signal-overall_success_rate_low.yaml\nUser Segments\nUser Segments provide the ability to define user cohorts near real-time with different triggering criteria for compute and various start and expiration conditions. The user-defined transform exposes several abstract methods which developers can simply implement the business logic without having to worry about streaming components.\nFor example, the active trip planner is a User Segment that assigns guests into the segment as soon as the guest performs a search and removes the guests from the segment after 14 days of inactivity or once the guest makes a booking. Below are abstract methods that the developer will implement to create the active trip planner User Segment:\n\ninSegment: Given the triggered User Signals, check if the given user is in the segment.\ngetStartTimestamp: Define the start time when the given user will be in the segment. For example, when the user starts a search on Airbnb, the start time will be set to the search timestamp and the user will be immediately placed in this user segment.\ngetExpirationTimestamp: Define the end time when the given user will be out of the segment. For example, when the user performs a search, the user will be in the segment for the next 14 days until the next triggering User Signal arrives, then the expiration time will be updated accordingly.\n\npublic class ExampleSegmentTransform extends AbstractSegmentTransform {\n  @Override\n  protected boolean inSegment(List<Signal> inputSignals) {\n  }\n  @Override\n  public Instant getStartTimestamp(List<Signal> inputSignals) {\n  }\n  @Override\n  public Instant getExpirationTimestamp(List<Signal> inputSignals) {\n  }\n}\nSession Engagements\nThe session engagement Flink job enables developers to group and analyze a series of short-term user actions, known as session engagements, to gain insights into holistic user behavior within a specific timeframe. For example, understanding the photos of homes the guest viewed in the current session would be useful to derive the guest preference for the upcoming trip.\nAs transform Kafka events from User Signals get ingested, the job splits the stream into keyed streams by user id as a key to allow the computation to be performed in parallel.\nThe job employs various windowing techniques, such as sliding windows and session windows, to trigger computations based on aggregated user actions within these windows. Sliding windows continuously advance by a specified time interval, while session windows dynamically adjust based on user activity patterns. For example, as a user browses multiple listings on the Airbnb app, a sliding window of size 10 minutes that slides every 5 minutes is used to analyze the user’s short term engagement to generate the user’s short term trip preference.\nThe asynchronous compute pattern empowers developers to execute resource intensive operations, such as running ML models or making service calls, without disrupting the real-time processing pipeline. This approach ensures that computed user understanding data is efficiently stored and readily available for rapid querying from the KV store.\nFigure 3. Session Engagements Flow\nFlink Operations\nUSP is a stream processing platform built for developers. Below are some of the learnings from operating hundreds of Flink jobs.\nMetrics\nWe use various latency metrics to measure the performance of streaming jobs.\n\nEvent Latency: From when the user events are generated from applications to when the transformed events are written to the KV store.\nIngestion Latency: From when the user events arrive at the Kafka cluster to when the transformed events are written to the KV store.\nJob Latency: From when the Flink job starts processing source Kafka events to when the transformed events are written to the KV store.\nTransform Latency: From when the Flink job starts processing source Kafka events to when the Flink job finishes the transformation.\nFigure 4. Flink Job Metrics\nEvent Latency is the end-to-end latency measuring when the generated user action becomes queryable. This metric can be difficult to control because if the Flink job relies on client side events, the events themselves may not be readily ingestible due to the slow network on the client device or the batching of the logs on the client device for performance. With these reasons, it’s also preferable to rely on server side events over client side events for the source user events, only if the comparables are available.\nIngestion Latency is the main metric we monitor. This also covers various issues that can happen in different stages such as overloaded Kafka topics and latency issues when writing to the KV store (from client pool issues, rate limits, service instability).\nImproving Flink Job stability with standby Task Managers\nFlink is a distributed system that runs on a single Job Manager that orchestrates tasks in different Task Managers that act as actual workers. When a Flink job is ingesting a Kafka topic, different partitions of the Kafka topic are assigned to different Task Managers. If one Task Manager fails, incoming Kafka events from the partitions assigned to that task manager will be blocked until a new replacement task manager is created. Unlike the online service horizontal scaling where pods can be simply replaced with traffic rebalancing, Flink assigns fixed partitions of input Kafka topics to Task Managers without auto reassignment. This creates large backlogs of events from those Kafka partitions from the failed Task Manager, while other Task Managers are still processing events from other partitions.\nIn order to reduce this downtime, we provision extra hot-standby pods. In the diagram below, on the left side, the job is running at a stable state with four Task Managers with one Task Manager (Task Manager 5) as a hot-standby. On the right side, in case of the Task Manager 4 failure, the standby Task Manager 5 immediately starts processing tasks for the terminated pod, instead of waiting for the new pod to spin up. Eventually another standby pod will be created. In this way, we can achieve better stability with a small cost of having standby pods.\nFigure 5. Flink Job Manager And Task Manager Setup\nConclusion\nOver the last several years, USP has played a crucial role as a platform empowering numerous teams to achieve product personalization. Currently, USP processes over 1 million events per second across 100+ Flink jobs and the USP service serves 70k queries per second. For future work, we are looking into different types of asynchronous compute patterns via Flink to improve performance.\nAcknowledgments\nUSP is a collaborative effort between Airbnb’s Search Infrastructure and Stream Infrastructure, particularly Derrick Chie, Ran Zhang, Yi Li. Big thanks to our former teammates who contributed to this work: Emily Hsia, Youssef Francis, Swaroop Jagadish, Brandon Bevans, Zhi Feng, Wei Sun, Alex Tian, Wei Hou.\n\nBuilding a User Signals Platform at Airbnb was originally published in The Airbnb Tech Blog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Kidai Kwon",
        "guid": "https://medium.com/p/b236078ec82b",
        "categories": [
          "personalization",
          "technology",
          "machine-learning",
          "engineering",
          "ai"
        ],
        "isoDate": "2024-11-20T19:27:27.000Z"
      }
    ]
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Amy Nguyen",
        "title": "Top 5 GitHub Copilot Features in Visual Studio from Microsoft Ignite 2024",
        "link": "https://devblogs.microsoft.com/visualstudio/top-5-github-copilot-features-in-visual-studio-from-microsoft-ignite-2024/",
        "pubDate": "Fri, 22 Nov 2024 13:00:25 +0000",
        "content:encodedSnippet": "At this year’s Microsoft Ignite, it was truly exciting to see Scott, Dalia, and Jessie demo some of the most innovative features of GitHub Copilot that are transforming the developer experience in Visual Studio. From the breakout session, we highlighted five standout features that are pushing productivity to the next level. Whether you’re working on complex edits or crafting custom workflows, these tools showcase how AI can elevate your coding game in ways you never thought possible.\nWatch the Ignite Session Here\n\n*Note: It will take 24-48 hours after the session for the recording to be uploaded.\n1. Copilot Edits: Collaborative Iterations\n\nIt was amazing to see Copilot Edits in action. This new editing surface is designed for seamless multi-file changes, making large-scale updates across your project feel effortless. Imagine needing to redesign your UI or implement logic that spans multiple files—Copilot handles it by generating a change plan tailored to your goals, without the usual headache of tracking dependencies manually.\nWhat makes this feature transformative is how Copilot analyzes your codebase, identifies the necessary edits through multiple files, and iterates on those changes while maintaining the context from your conversation history. And the best part? Visual Studio’s inline code previews let you review, modify, or accept suggestions directly in the IDE, making complex updates feel more like a smooth collaboration than a solo effort. This iterative approach ensures that Copilot evolves alongside your intentions, keeping you in control while streamlining your updates.\n2. Vision: Code Smarter with Contextual Understanding\n\nThis feature blew us away with its ability to process images and screenshots, allowing GitHub Copilot to instantly grasp your intentions, without the hassle of going back and forth, tediously describing UI changes.\nFor instance, when updating a UI, you can simply paste screenshots of the current and desired states into Copilot. It analyzes the differences, determines the necessary changes, and suggests edits tailored to your goals. Vision bridges the gap between visual inputs and actionable suggestions, empowering developers to handle visually-oriented tasks with ease. It truly makes Copilot feel like a collaborative partner in your workflow.\n3. Icebreakers: A Launchpad for Productivity\n\nWe all know that getting started can sometimes feel like the hardest part, but Icebreakers make it so much easier. These curated starter prompts, like “Refactor my code” or “Add a new feature,” inspire action and guide your initial steps when facing common coding challenges. Seeing Scott demo how Icebreakers now support more complex, multi-step workflows was incredible. They seamlessly integrate with Copilot Edits, enabling actionable plans for even the most intricate tasks.\nWhether you’re navigating an unfamiliar codebase or tackling a large project, Icebreakers reduce cognitive load, giving you a clear starting point and boosting productivity right from the get-go. It was exciting to see how this feature now helps developers take control of complex tasks and move forward with confidence.\n4. Function Calling: Bridging Gaps in Logic\n\nFunction Calling, which enhances GitHub Copilot’s ability to provide precise recommendations by automatically determining the relevant context and tools based on your natural language prompts. Copilot seamlessly integrates the necessary context, saving you time and effort.\nFunction Calling streamlines the process by dynamically accessing open files and project structure, eliminating the need to manually specify paths. This makes debugging and integration faster and more efficient. Watching them demo this feature was a highlight, as they showed how quickly developers can go from idea to implementation with Copilot’s context-aware functionality!\n5. Custom Instructions: Your Copilot, Your Way\n\nCustom Instructions allow Copilot to adapt to your unique team workflow. No two teams are alike, and seeing Jessie demonstrate how you can fine-tune Copilot’s behavior to align with your team’s coding conventions and communication style was truly amazing!\nWith Custom Instructions, you can add team-specific practices to your Copilot instructions file, ensuring consistency across your codebase. This feature is a game-changer for teams who want to make their workflow more efficient while ensuring alignment with best practices.\nYour New Development Sidekick\nThe advancements showcased at Ignite reaffirm GitHub Copilot’s role as a transformative tool for developers. From simplifying multi-file edits to embracing team-specific workflows, these features show how AI can be both powerful and adaptable.\nTry these features in Visual Studio today and see how GitHub Copilot can help you code smarter, faster, and with more confidence.\nWhich feature are you most excited to try? Let us know in the comments below!\nDownload Visual Studio 2022\n\nThe post Top 5 GitHub Copilot Features in Visual Studio from Microsoft Ignite 2024 appeared first on Visual Studio Blog.",
        "dc:creator": "Amy Nguyen",
        "content": "<p>At this year’s Microsoft Ignite, it was truly exciting to see Scott, Dalia, and Jessie demo some of the most innovative features of GitHub Copilot that are transforming the developer experience in Visual Studio. From the breakout session, we highlighted five standout features that are pushing productivity to the next level. Whether you&#8217;re working on [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/top-5-github-copilot-features-in-visual-studio-from-microsoft-ignite-2024/\">Top 5 GitHub Copilot Features in Visual Studio from Microsoft Ignite 2024</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "At this year’s Microsoft Ignite, it was truly exciting to see Scott, Dalia, and Jessie demo some of the most innovative features of GitHub Copilot that are transforming the developer experience in Visual Studio. From the breakout session, we highlighted five standout features that are pushing productivity to the next level. Whether you’re working on […]\nThe post Top 5 GitHub Copilot Features in Visual Studio from Microsoft Ignite 2024 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251478",
        "categories": [
          "Copilot",
          "GitHub Copilot",
          "Productivity",
          "Visual Studio",
          "Ignite"
        ],
        "isoDate": "2024-11-22T13:00:25.000Z"
      },
      {
        "creator": "Mads Kristensen",
        "title": "Making you more productive with Visual Studio v17.12",
        "link": "https://devblogs.microsoft.com/visualstudio/making-you-more-productive-with-visual-studio-v17-12/",
        "pubDate": "Thu, 21 Nov 2024 13:00:47 +0000",
        "content:encodedSnippet": "The 12th update to Visual Studio 2022 is packed with lots of exciting new features that users have been asking for! Here are some of the awesome highlights from this release that are some of my personal favorites. For all the details, be sure to check out our release notes.\nCopy from the Error List\nYou see an error in the Error List that you don’t know how to fix. So, you select it and hit Ctrl+C to copy the description for a web search. After you’ve pasted it into the search engine, you realize it copied all column headers and row values instead of just the description. Now you must delete everything except the error description before you can perform the web search. This is cumbersome, but now we have a fix!\n\nWhen you copy an error from the Error List using Ctrl+C, only the description is copied to the clipboard. This makes it easier to search for the error online or share it with others.\nYou can still copy the entire row by right-clicking the error and selecting Copy Row from the context menu or hitting Ctrl+Shift+C.\nIf what you wanted to do with the error description was to do a web search, then just hit Ctrl+F1 to search for information about the error online.\nGo to line anywhere in code search\nSometimes you know that there’s an issue on a certain line in your code and you want to get to it quickly. Maybe you were told about an error being thrown on line 43 of some file, or you want to get to the bottom of a specific file.\nCode search now supports quick navigation to a specific line in your code.\nOpen Code Search and go to a line in the current document by using colon + line number. For example, :39 will navigate to line 39 in the active file.\n\nYou can also go to a line in a different document by using file name + colon + line number. For example, Order:43 will navigate to line 43 in Order.cs. If you don’t specify the exact file name, then the search will try to find the best match.\n\nDock the code search window\nIf you need Code or Feature Search to stay out of your way, you now have more control over the behavior of the search window.\nYou can now dock the search window and perform tool window actions with it, like Solution Explorer and others.\n\nAfter opening Code Search or Feature Search, click on the box icon at the top right to convert it into a tool window. You may choose to dock it elsewhere, pop it out, auto-hide, etc. You can revert to the dismissible window by closing the tool window and reopening search.\n\nWe’ve also simplified and cleaned up the previewing experience in search. There is now one button, indicated with an eye icon, to toggle the preview on and off.\n\nThe position of the preview panel will also adjust based on the dimensions of the search window.\n\nRefresh the Find results\nWe heard from a lot of users that it’s frustrating having to reopen the Find window and go through the motions of redoing a search to get updated results. Maybe you just refactored some code and want to confirm everything has been changed as expected, or you pulled some recent changes and need your recent Find operation to reflect those updates.\nAfter completing Find in Files, you will now have the option to Refresh the Find results in the window. You’ll get your updated results without having to redo the search.\n\nWe’ve also redesigned the former Repeat Find option to distinguish it from Refresh. It is now represented as Modify Find with a pencil icon. This button will still reopen Find in Files with the same search criteria you used for that results window.\n\nCopy files between instances\nWe are excited to introduce a highly requested feature in Visual Studio! You can now seamlessly copy and paste code files and folders between different Visual Studio instances using the Solution Explorer. Simply select the desired file or folder, use Ctrl+C or Ctrl+X, switch to another Visual Studio instance, and use Ctrl+V to include those files or folders in your new solution. All changes will be accurately reflected in the file system.\nIn addition to copying and pasting, you can also drag the files and folders from one instance of Visual Studio to another.\n\nPreviously, this functionality was available only for a few project types, but we have now expanded it to include all the major project types in Visual Studio.\nMulti-project launch configuration\nThe Multi-Project Launch Configuration feature allows you to set up and save profiles for launching specific projects within a multi-project solution in predefined states for debugging.\n\nThis simplifies the process of working with complex solutions, improves debugging efficiency, and enables easy sharing of configurations among team members.\nThank you!\nWe deeply appreciate your valuable feedback and feature requests, which have been instrumental in shaping these updates. Your insights have a profound impact on our development process, and we are committed to continually enhancing your experience with Visual Studio. We encourage you to keep sharing your thoughts and suggestions, as they are vital in helping us make Visual Studio the best it can be. Thank you for your continued support and collaboration.\nHappy Coding!\nThe post Making you more productive with Visual Studio v17.12 appeared first on Visual Studio Blog.",
        "dc:creator": "Mads Kristensen",
        "content": "<p>The 12th update to Visual Studio 2022 is packed with lots of exciting new features that users have been asking for! Here are some of the awesome highlights from this release that are some of my personal favorites. For all the details, be sure to check out our release notes. Copy from the Error List [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/making-you-more-productive-with-visual-studio-v17-12/\">Making you more productive with Visual Studio v17.12</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "The 12th update to Visual Studio 2022 is packed with lots of exciting new features that users have been asking for! Here are some of the awesome highlights from this release that are some of my personal favorites. For all the details, be sure to check out our release notes. Copy from the Error List […]\nThe post Making you more productive with Visual Studio v17.12 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251450",
        "categories": [
          "Accessibility",
          "Productivity",
          "Visual Studio",
          "Search"
        ],
        "isoDate": "2024-11-21T13:00:47.000Z"
      },
      {
        "creator": "Mads Kristensen",
        "title": "Copy files across instances of Visual Studio",
        "link": "https://devblogs.microsoft.com/visualstudio/copy-files-across-instances-of-visual-studio/",
        "pubDate": "Wed, 20 Nov 2024 13:00:30 +0000",
        "content:encodedSnippet": "Transferring code files between different instances of Visual Studio has often been a tedious task. To simplify this process, Visual Studio 2022 now includes a feature that allows you to easily copy and paste code files and folders between instances using the Solution Explorer. This enhancement aims to streamline workflow and save time.\n\nUntil now, moving code files and folders between different Visual Studio instances has been a hassle. Developers often had to manually relocate files, risking errors and inefficiencies in their workflow. With the new copy and paste functionality, this problem is now a thing of the past. Visual Studio 2022 makes it easier to manage your code files, regardless of the project type.\nHow the Feature Works\nThe process is straightforward:\nSelect the desired file or folder: Navigate to the Solution Explorer and choose the code file or folder you wish to transfer.\nUse Ctrl+C or Ctrl+X: Copy or cut the selected file or folder.\nSwitch to another Visual Studio instance: Open the instance where you want to paste the file or folder.\nUse Ctrl+V: Paste the file or folder. All changes will be accurately reflected in the file system.\nAdditionally, you can also drag and drop files and folders between instances, providing even more flexibility in how you manage your projects.\nExpanded Functionality\nPreviously, this feature was limited to a few specific project types. However, in response to your feedback, we’ve expanded this functionality to include all major project types in Visual Studio. Whether you are working on a web application, a desktop application, or a complex multi-project solution, you can now benefit from this streamlined capability.\nContinuous Improvement\nWe are committed to making Visual Studio the best development environment available. Your feedback is invaluable to us, and it directly influences the improvements we make. This new feature is a testament to our dedication to listening to our users and enhancing their development experience.\nThank you for your continued support and feedback. Together, we are making Visual Studio better every day.\nThe post Copy files across instances of Visual Studio appeared first on Visual Studio Blog.",
        "dc:creator": "Mads Kristensen",
        "content": "<p>Transferring code files between different instances of Visual Studio has often been a tedious task. To simplify this process, Visual Studio 2022 now includes a feature that allows you to easily copy and paste code files and folders between instances using the Solution Explorer. This enhancement aims to streamline workflow and save time. Until now, [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/copy-files-across-instances-of-visual-studio/\">Copy files across instances of Visual Studio</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Transferring code files between different instances of Visual Studio has often been a tedious task. To simplify this process, Visual Studio 2022 now includes a feature that allows you to easily copy and paste code files and folders between instances using the Solution Explorer. This enhancement aims to streamline workflow and save time. Until now, […]\nThe post Copy files across instances of Visual Studio appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251424",
        "categories": [
          "Productivity",
          "Visual Studio"
        ],
        "isoDate": "2024-11-20T13:00:30.000Z"
      },
      {
        "creator": "Tina Schrepfer (LI)",
        "title": "VisualStudio.Extensibility 17.12: CodeLens support is here!",
        "link": "https://devblogs.microsoft.com/visualstudio/visualstudio-extensibility-17-12-codelens-support-is-here/",
        "pubDate": "Tue, 19 Nov 2024 15:28:38 +0000",
        "content:encodedSnippet": "We continue to invest in the VisualStudio.Extensibility SDK to allow users like you to create extensions that run faster and smoother than ever before! VisualStudio.Extensibility helps you build extensions that run outside the main Visual Studio IDE process for improved performance and reliability, and can be installed without the need to restart Visual Studio. Additional benefits include a sleek and intuitive .NET 8-based API and comprehensive, well-maintained documentation to help you develop amazing extensions faster than ever before.\nThis 17.12 release builds on our previous releases and brings support for CodeLens in the editor. We’ve also addressed feedback from early users and revamped the output window API to make it easier to use.\nGet Started with VisualStudio.Extensibility\n\nFor the latest up-to-date docs and installation instructions, visit https://aka.ms/VisualStudio.Extensibility. We encourage you to report bugs and suggest features via the issue tracker on our GitHub repo, where you can also find extension samples to help you get started.\nWhat’s new for VisualStudio.Extensibility?\nOur 17.12 release of VisualStudio.Extensibility includes the following features:\nCustomized CodeLens experience in the Visual Studio editor by adding your own CodeLens provider (currently released as experimental API)\nRevamped output window API for better discoverability and ease of use\nAdditional diagnostics information for debugging VisualStudio.Extensibility extensions\nAs with previous releases, we continuously update our documentation to reflect the latest features in version 17.12. We have also prepared a comprehensive guide that outlines the three different extensibility models for Visual Studio. This guide explains why VisualStudio.Extensibility is the ideal choice for those new to writing extensions.\nProvide your own CodeLens experience\nCodeLens is an experience in the Visual Studio editor that allows developers like you to stay focused on your work and get contextual information about your code without ever leaving the editor. Using CodeLens, you can quickly find all references of code or see the pass rate of unit tests. With the release of 17.12, extenders can now create a custom CodeLens on supported languages provided by Visual Studio! CodeLens support in VisualStudio.Extensibility goes beyond what the Visual Studio SDK (VSSDK) offers in that it not only allows for custom UI to be displayed for your CodeLens; it also offers a way for users to interact with your custom CodeLens through invokable CodeLens.\nCheck out this sample to learn how you can create a custom interactive word counter CodeLens using this new API. The sample extension allows you to define what to search for and count its occurrences in a C# method block, all from the context of CodeLens!\n\nTo get started on creating your own CodeLens provider, please review our documentation here. CodeLens support is currently released as an experimental API. We welcome questions and suggestions on the API as we work to stabilize it. Note that we currently only allow CodeLenses to be added to existing languages supported by Visual Studio. Stay tuned for when we enable CodeLens support for arbitrary files.\nAccess the output window with ease\nDuring 17.12, we revamped the APIs for writing to Visual Studio’s output window. The original APIs were one of the first APIs we migrated from VSSDK to VisualStudio.Extensibility and had started to show their age. In the time we’ve been working on the new model, we’ve iterated on the principles of API design and refined them. Looking back at the original output window APIs, we realized that they did not meet our standards for simplicity and ease of use. In the revamp, we abstracted away concepts like resource IDs and channels to provide a simpler interface, and we gave users multiple ways to write to the output window, including writing using string, TextWriter, or PipeWriter. Check out the updated docs and sample to see how you can utilize the new and improved APIs!\nGiven that these original APIs were marked as preview, we changed them in accordance with our preview API guidance. For more information about breaking changes, refer to the Breaking Changes article.\nDebug your extensions more easily\nWith this release, we’ve also updated the diagnostics explorer to better assist you in debugging VisualStudio.Extensibility extensions. We separated the diagnostics pages into 2 groups – extension centric and platform centric. This separation makes it simpler to find information specific to your extension versus information that’s about the underlying Visual Studio platform to get more contextual data.\n\n\nOur documentation goes into detail on what each of these pages provide. You can download the latest version of the diagnostics explorer from the Marketplace here.\nWe want to hear from you!\nSince embarking on this journey to provide a new extensibility model for Visual Studio, our goal has always been to keep our ecosystem partners engaged. Besides regular blog posts like this one to update our customers of the latest additions to VisualStudio.Extensibility, we also have extensive and up-to-date documentation on how to use the APIs, as well as media content that gives a quick overview of VisualStudio.Extensibility. We also have 2 different channels for customers to interact with us to either report issues or suggest new features:\nGitHub: Our GitHub page is the primary destination for extenders to ask questions or report issues with respect to creating extensions for Visual Studio. While we try our best to answer questions, we can’t always get to them in real time. Our goal is to eventually have the GitHub page be something that the community can help answer each other’s questions. That can only happen if more extenders adopt VisualStudio.Extensibility to build their extensions.\nDeveloper Community: We primarily use Developer Community to track feature requests. Occasionally, we’ll get issues created in our GitHub page that are related to a feature not yet implemented in VisualStudio.Extensibility. Our practice is to then turn that issue into a suggestion ticket and use that ticket to track upvotes and post updates. In our most recent releases, we closed 2 of these suggestion tickets with the implementation of settings last release, and the support for code lens this release. We encourage you to review the current list of feature requests for VisualStudio.Extensibility and upvote any most relevant to your scenarios.\nKeep those questions and suggestions coming! There are many things we take into consideration when planning our roadmap, but rest assured that customer feedback is something that’s always top of mind for us.\nStay connected with the Visual Studio team by following us on YouTube, Twitter, LinkedIn, Twitch and on Microsoft Learn.\nThe post VisualStudio.Extensibility 17.12: CodeLens support is here! appeared first on Visual Studio Blog.",
        "dc:creator": "Tina Schrepfer (LI)",
        "content": "<p>We continue to invest in the VisualStudio.Extensibility SDK to allow users like you to create extensions that run faster and smoother than ever before! VisualStudio.Extensibility helps you build extensions that run outside the main Visual Studio IDE process for improved performance and reliability, and can be installed without the need to restart Visual Studio. Additional [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/visualstudio-extensibility-17-12-codelens-support-is-here/\">VisualStudio.Extensibility 17.12: CodeLens support is here!</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "We continue to invest in the VisualStudio.Extensibility SDK to allow users like you to create extensions that run faster and smoother than ever before! VisualStudio.Extensibility helps you build extensions that run outside the main Visual Studio IDE process for improved performance and reliability, and can be installed without the need to restart Visual Studio. Additional […]\nThe post VisualStudio.Extensibility 17.12: CodeLens support is here! appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251397",
        "categories": [
          "Extensibility",
          "Visual Studio",
          "CodeLens",
          "Extensions",
          "Visual Studio 2022"
        ],
        "isoDate": "2024-11-19T15:28:38.000Z"
      },
      {
        "creator": "Jessie Houghton",
        "title": "Git tooling updates in Visual Studio 17.12",
        "link": "https://devblogs.microsoft.com/visualstudio/git-tooling-updates-in-visual-studio-17-12/",
        "pubDate": "Mon, 18 Nov 2024 15:37:56 +0000",
        "content:encodedSnippet": "We are thrilled to announce the latest updates to Git tooling in Visual Studio, designed to enhance your development experience and streamline your workflow. These new features are in direct response to user feedback, ensuring that you have the tools you need to be more productive and efficient. For the full list, check out the release notes.\nPull request drafts and templates\nYou can now create pull request drafts and start your descriptions with GitHub templates in Visual Studio. These were the two top requests for the create a pull request experience.\nDraft PRs\nUse the drop-down menu on the Create button to Create as Draft.\n\nPR Templates\nYour default PR template will be used when creating a new PR for both GitHub and Azure DevOps. Learn more about how to add a PR template to your repository in the GitHub documentation and Azure DevOps documentation.\nCreate internal GitHub repos\nVisual Studio now supports internal repos for your GitHub organizations. We also included guidance for each type of repository to give you more clarity on the visibility of the new project depending on which account you’re using.\n\nCopy Git link\nWhenever you share a few lines of code with a colleague, it can often be useful for them to get extra context from your repository. However, if they’re working on something else it can take too long and disrupt their work to checkout your branch.\nNow, you can highlight the code you want to share in your editor, open the context menu with a right click, and under the Git submenu get a shareable link to your code in GitHub or Azure DevOps. This makes it simple and easy to collaborate, and it smooths the flow between the IDE and your remote repos on the web.\n\nYou can also get shareable links directly from commit history. This allows for code not currently checked out or code that exists in previous iterations to be referenced just as effortlessly.\n\nCustomize AI Git commit message\nNow you can add additional instructions to the prompt for generating your Git commit message with GitHub Copilot. This allows you to customize the commit message to better fit your workflow and team’s standards. You can specify the number of lines to generate, the length of the lines, and even provide a sample commit style. Edit the message in the Tools > Options > Copilot > Source Control > Commit message additional instructions: prompt field.\n\nGit multi-repo support\nYou can now create pull requests and link work items in multi-repo scenarios. For both GitHub and Azure DevOps, we support your integrations when you use the repository picker to focus on a particular repository in your multi-repo scenarios.\n\nKeep sharing your feedback!\nWe are continuously striving to improve and adapt to your needs, and your feedback is invaluable in this process. Thank you for your continued feedback and support. Your insights help us shape the tools and features that make your development experience more efficient and enjoyable.\nThe post Git tooling updates in Visual Studio 17.12 appeared first on Visual Studio Blog.",
        "dc:creator": "Jessie Houghton",
        "content": "<p>We are thrilled to announce the latest updates to Git tooling in Visual Studio, designed to enhance your development experience and streamline your workflow. These new features are in direct response to user feedback, ensuring that you have the tools you need to be more productive and efficient. For the full list, check out the [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/git-tooling-updates-in-visual-studio-17-12/\">Git tooling updates in Visual Studio 17.12</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "We are thrilled to announce the latest updates to Git tooling in Visual Studio, designed to enhance your development experience and streamline your workflow. These new features are in direct response to user feedback, ensuring that you have the tools you need to be more productive and efficient. For the full list, check out the […]\nThe post Git tooling updates in Visual Studio 17.12 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251381",
        "categories": [
          "Git",
          "Team and Development",
          "Visual Studio",
          "Git Integration",
          "Multi-repo"
        ],
        "isoDate": "2024-11-18T15:37:56.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": [
      {
        "creator": "sunyzero",
        "title": "AMD 내장 그래픽 튜닝 (7840HS) - 아드레날린 메모리 옵티마이저",
        "link": "http://sunyzero.tistory.com/305",
        "pubDate": "Sat, 23 Nov 2024 10:08:26 +0900",
        "author": "sunyzero",
        "comments": "http://sunyzero.tistory.com/305#entry305comment",
        "content": "<p data-ke-size=\"size16\">AMD CPU중에는 내장 그래픽을 가진 경우가 많은데, 대표적으로 5600G나 7834HS, 7840HS 같은 CPU가 있다. 이들은 전용 그래픽 메모리가 없기 때문에 메인 메모리인 RAM를 대신 사용한다. 비디오 메모리는 많으면 좋지만 그렇다고 메인 메모리의 대부분을 비디오 메모리로 사용하면 시스템이 굴러가지 못한다. 따라서 AMD 내장 그래픽 시스템은 메인 메모리의 일부를 비디오 전용 메모리로 예약해두고 사용하고, 만일 비디오 메모리가 부족하면 그때그때 메인 메모리를 조금씩 차용해서 쓰도록 되어있다. 하지만 비디오 메모리가 부족할 때 메인 메모리의 파편화나 각종 이유 때문에 즉시 차용되지 못하면 프로그램에서 팅기거나 작동하던 멈출 수 있다. </p>\n<p data-ke-size=\"size16\">이를 해결하기 위해 AMD는 그래픽 드라이버 프로그램 아드레날린(adrenalin)에서 <span style=\"background-color: #9feec3;\">메모리 옵티마이저</span>라는 기능을 제공하는데, 여기서는 \"<span style=\"background-color: #ffc9af;\">생산성</span>\"과 \"<span style=\"background-color: #f6e199;\">게임</span>\"의 2가지 옵션을 제공한다.</p>\n<p data-ke-size=\"size16\">메모리 옵티마이저의 \"<span style=\"background-color: #ffc9af;\">생산성</span>\" 옵션은 일반적인 사무 프로그램을 사용하는 사용자를 대상으로 해서 비디오 메모리를 작은 사이즈로 예약한다. 따라서 메인 메모리를 덜 사용한다. 그 대신 비디오 메모리를 많이 사용하는 게임이라든지 영상 관련 프로그램은 제대로 작동하지 않는다. 심지어 작동하다가 멈추거나 죽을 수도 있다.</p>\n<p data-ke-size=\"size16\">메모리 옵티마이저의 \"<span style=\"background-color: #f6e199;\">게임</span>\" 옵션은 반대로 게임이나 영상 프로그램을 사용하는 경우에 대비해서 비디오 메모리를 좀 더 큰 사이즈로 예약한다. 따라서 메인 메모리를 더 많이 사용하므로, 사용가능한 메인 메모리가 줄어든다.(보통 1~2GiB 정도 줄어든다.) 그 대신에 비디오 메모리를 많이 사용하는 게임에서도 끊김이 덜하고 팅기지도 않는다. <span style=\"background-color: #9feec3;\">그런데 일반 사용자라고 하더라도 메모리가 최소 16~32GB를 많이 사용할텐데, 이런 경우에는 게임 옵션으로 두는게 그래픽이 부드러워지고 더 좋았다. 굳이 게임을 하는 경우가 아니라고 해도 \"게임\" 옵션으로 맞춰두고 사용하는 것이 좋다고 생각된다</span>.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">1. 메모리 옵티마이저</h2>\n<p data-ke-size=\"size16\">먼저 아드레날린이 설치되어있어야 한다. AMD 사이트에서 프로세서와 그래픽 드라이버를 받아서 설치하면 된다. 설치 후 아드레날린을 찾아서 실행한다. 그리고 실행 후 \"성능\"을 선택하고 튜닝쪽으로 가면 다음 그림처럼 메모리 옵티마이저를 볼 수 있다. 아래는 기본값인 \"<span style=\"background-color: #ffc9af;\">생산성</span>\"으로 선택된 것을 보여주고 있다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"7840hs 780M memory optimizer productive - amd adrenalin.png\" data-origin-width=\"1297\" data-origin-height=\"635\"><span data-url=\"https://blog.kakaocdn.net/dn/FaTzL/btsKS9SIaAy/h5noyeUf9M7gjGom2Vj6x0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/FaTzL/btsKS9SIaAy/h5noyeUf9M7gjGom2Vj6x0/img.png\" data-alt=\"아드레날린(adrenalin) - 메모리 옵티마이저(Memory optimizer) - 생산성(Productive)\"><img src=\"https://blog.kakaocdn.net/dn/FaTzL/btsKS9SIaAy/h5noyeUf9M7gjGom2Vj6x0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FFaTzL%2FbtsKS9SIaAy%2Fh5noyeUf9M7gjGom2Vj6x0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"7840hs 780M memory optimizer productive - amd adrenalin.png\" data-origin-width=\"1297\" data-origin-height=\"635\"/></span><figcaption>아드레날린(adrenalin) - 메모리 옵티마이저(Memory optimizer) - 생산성(Productive)</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">메모리 옵티마이저가 생산성으로 선택되어있는 경우에 제어판의 디스플레이 상태를 보면 아래 그림과 같다. (참고로 해당 시스템은 총 메모리가 32GB이다) 그림에 보면 전용 비디오 메모리는 <span style=\"background-color: #ffc9af;\">448MB</span>임을 볼 수 있다. 즉 미리 잡혀있는 전용 비디오 메모리가 겨우 0.5기가 바이트도 안되는 것이다. 공유 메모리가 16GB지만 이 부분을 다 쓸 수 있다는 것은 아니고, 쓸 가능성이 있다고 봐야한다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"7840hs 780M memory optimizer productive - vram 448MB.png\" data-origin-width=\"796\" data-origin-height=\"1007\"><span data-url=\"https://blog.kakaocdn.net/dn/ZEKQQ/btsKUHm6NTq/GCilcVbMYXfJzxsf6XVmN1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ZEKQQ/btsKUHm6NTq/GCilcVbMYXfJzxsf6XVmN1/img.png\" data-alt=\"제어판 - 그래픽스 속성 - 메모리 옵티마이저 - 생산성 옵션 선택\"><img src=\"https://blog.kakaocdn.net/dn/ZEKQQ/btsKUHm6NTq/GCilcVbMYXfJzxsf6XVmN1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FZEKQQ%2FbtsKUHm6NTq%2FGCilcVbMYXfJzxsf6XVmN1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"7840hs 780M memory optimizer productive - vram 448MB.png\" data-origin-width=\"796\" data-origin-height=\"1007\"/></span><figcaption>제어판 - 그래픽스 속성 - 메모리 옵티마이저 - 생산성 옵션 선택</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">비디오 메모리는 Ctrl + Shift + ESC를 눌러 작업 관리자에서 살펴봐도 메모리 상태를 볼 수 있다. 아래를 보면 전용 메모리 448메가중에 아무것도 안해도 273메가를 사용하고 있음을 볼 수 있다. 벌써 절반 이상이 소진된 것이다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"7840hs 780M memory optimizer productive - 작업관리자 GPU.png\" data-origin-width=\"1212\" data-origin-height=\"1105\"><span data-url=\"https://blog.kakaocdn.net/dn/9O5x3/btsKS3L1fsf/k18geptJfkVAveqE221jF0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/9O5x3/btsKS3L1fsf/k18geptJfkVAveqE221jF0/img.png\" data-alt=\"작업관리자 - GPU - 메모리 옵티마이저 생산성 옵션 선택\"><img src=\"https://blog.kakaocdn.net/dn/9O5x3/btsKS3L1fsf/k18geptJfkVAveqE221jF0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F9O5x3%2FbtsKS3L1fsf%2Fk18geptJfkVAveqE221jF0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"7840hs 780M memory optimizer productive - 작업관리자 GPU.png\" data-origin-width=\"1212\" data-origin-height=\"1105\"/></span><figcaption>작업관리자 - GPU - 메모리 옵티마이저 생산성 옵션 선택</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000; text-align: start;\" data-ke-size=\"size26\">2. 메모리 옵티마이저 : \"게임\" 변경</h2>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\">메모리 옵티마이저를 \"게임\"으로 변경해보자. 변경하면 꼭&nbsp;<span style=\"background-color: #ffc9af;\">재부팅을 해야 적용된다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"7840hs 780M memory optimizer game - amd adrenalin.jpg\" data-origin-width=\"1296\" data-origin-height=\"505\"><span data-url=\"https://blog.kakaocdn.net/dn/8CUD9/btsKVs34uFf/vDB0kQG8Pi6O9j9MwzPWjk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/8CUD9/btsKVs34uFf/vDB0kQG8Pi6O9j9MwzPWjk/img.jpg\" data-alt=\"아드레날린(adrenalin) - 메모리 옵티마이저(Memory optimizer) - 게임(Game)\"><img src=\"https://blog.kakaocdn.net/dn/8CUD9/btsKVs34uFf/vDB0kQG8Pi6O9j9MwzPWjk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F8CUD9%2FbtsKVs34uFf%2FvDB0kQG8Pi6O9j9MwzPWjk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"7840hs 780M memory optimizer game - amd adrenalin.jpg\" data-origin-width=\"1296\" data-origin-height=\"505\"/></span><figcaption>아드레날린(adrenalin) - 메모리 옵티마이저(Memory optimizer) - 게임(Game)</figcaption>\n</figure>\n</p>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\">메모리 옵티마이저를 게임으로 변경하고 제어판 디스플레이 상태를 보면 아래 그림과 같다. (참고로 해당 시스템은 총 메모리가 32기가이다) 그림에 보면 이제 전용 비디오 메모리는 4096MB, 즉 4GB 임을 볼 수 있다. 이렇게 해두면 대부분의 게임이나 영상 프로그램도 잘 돌아가고, 팅김이 없어진다. (16GB메모리인 경우에는 아마도 더 적게 잡힐 가능성이 있다)</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"7840hs 780M memory optimizer game - vram 4096MB.jpg\" data-origin-width=\"1207\" data-origin-height=\"792\"><span data-url=\"https://blog.kakaocdn.net/dn/b6KTJr/btsKUlYSAGp/Husihae9nCgggj9vERL0fK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/b6KTJr/btsKUlYSAGp/Husihae9nCgggj9vERL0fK/img.jpg\" data-alt=\"제어판 - 그래픽스 속성 - 메모리 옵티마이저 - 게임 옵션 선택\"><img src=\"https://blog.kakaocdn.net/dn/b6KTJr/btsKUlYSAGp/Husihae9nCgggj9vERL0fK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb6KTJr%2FbtsKUlYSAGp%2FHusihae9nCgggj9vERL0fK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"7840hs 780M memory optimizer game - vram 4096MB.jpg\" data-origin-width=\"1207\" data-origin-height=\"792\"/></span><figcaption>제어판 - 그래픽스 속성 - 메모리 옵티마이저 - 게임 옵션 선택</figcaption>\n</figure>\n</p>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\">비디오 메모리는 Ctrl + Shift + ESC를 눌러 작업 관리자에서 살펴봐도 메모리 상태를 볼 수 있다. 아래 그림을 보면 전용 메모리 4.0GB중에 아무것도 안해도 0.3GB를 사용하고 있음을 볼 수 있다. 그리고 이제 떳떳하게 말할 수 있어졌다. 아직도 신에게는 3.7GB의 메모리가 남아있습니다라고... </p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"7840hs 780M memory optimizer game - 작업관리자 GPU.png\" data-origin-width=\"1186\" data-origin-height=\"1081\"><span data-url=\"https://blog.kakaocdn.net/dn/bOYxQC/btsKSSDCOfM/YptZ2H3QLX4DL4RaLuyUR1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bOYxQC/btsKSSDCOfM/YptZ2H3QLX4DL4RaLuyUR1/img.png\" data-alt=\"작업관리자 - GPU - 메모리 옵티마이저 게임 옵션 선택\"><img src=\"https://blog.kakaocdn.net/dn/bOYxQC/btsKSSDCOfM/YptZ2H3QLX4DL4RaLuyUR1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbOYxQC%2FbtsKSSDCOfM%2FYptZ2H3QLX4DL4RaLuyUR1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"7840hs 780M memory optimizer game - 작업관리자 GPU.png\" data-origin-width=\"1186\" data-origin-height=\"1081\"/></span><figcaption>작업관리자 - GPU - 메모리 옵티마이저 게임 옵션 선택</figcaption>\n</figure>\n</p>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #333333; text-align: start;\" data-ke-size=\"size26\">3. 결론</h2>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\"><span>AMD 내장 그래픽을 사용한다면 아드레날린의 메모리 옵티마이저를 \"게임\"으로 변경하는 것이 좋다. 끝.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">2024.11.23 초안</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "AMD CPU중에는 내장 그래픽을 가진 경우가 많은데, 대표적으로 5600G나 7834HS, 7840HS 같은 CPU가 있다. 이들은 전용 그래픽 메모리가 없기 때문에 메인 메모리인 RAM를 대신 사용한다. 비디오 메모리는 많으면 좋지만 그렇다고 메인 메모리의 대부분을 비디오 메모리로 사용하면 시스템이 굴러가지 못한다. 따라서 AMD 내장 그래픽 시스템은 메인 메모리의 일부를 비디오 전용 메모리로 예약해두고 사용하고, 만일 비디오 메모리가 부족하면 그때그때 메인 메모리를 조금씩 차용해서 쓰도록 되어있다. 하지만 비디오 메모리가 부족할 때 메인 메모리의 파편화나 각종 이유 때문에 즉시 차용되지 못하면 프로그램에서 팅기거나 작동하던 멈출 수 있다. \n이를 해결하기 위해 AMD는 그래픽 드라이버 프로그램 아드레날린(adrenalin)에서 메모리 옵티마이저라는 기능을 제공하는데, 여기서는 \"생산성\"과 \"게임\"의 2가지 옵션을 제공한다.\n메모리 옵티마이저의 \"생산성\" 옵션은 일반적인 사무 프로그램을 사용하는 사용자를 대상으로 해서 비디오 메모리를 작은 사이즈로 예약한다. 따라서 메인 메모리를 덜 사용한다. 그 대신 비디오 메모리를 많이 사용하는 게임이라든지 영상 관련 프로그램은 제대로 작동하지 않는다. 심지어 작동하다가 멈추거나 죽을 수도 있다.\n메모리 옵티마이저의 \"게임\" 옵션은 반대로 게임이나 영상 프로그램을 사용하는 경우에 대비해서 비디오 메모리를 좀 더 큰 사이즈로 예약한다. 따라서 메인 메모리를 더 많이 사용하므로, 사용가능한 메인 메모리가 줄어든다.(보통 1~2GiB 정도 줄어든다.) 그 대신에 비디오 메모리를 많이 사용하는 게임에서도 끊김이 덜하고 팅기지도 않는다. 그런데 일반 사용자라고 하더라도 메모리가 최소 16~32GB를 많이 사용할텐데, 이런 경우에는 게임 옵션으로 두는게 그래픽이 부드러워지고 더 좋았다. 굳이 게임을 하는 경우가 아니라고 해도 \"게임\" 옵션으로 맞춰두고 사용하는 것이 좋다고 생각된다.\n \n \n1. 메모리 옵티마이저\n먼저 아드레날린이 설치되어있어야 한다. AMD 사이트에서 프로세서와 그래픽 드라이버를 받아서 설치하면 된다. 설치 후 아드레날린을 찾아서 실행한다. 그리고 실행 후 \"성능\"을 선택하고 튜닝쪽으로 가면 다음 그림처럼 메모리 옵티마이저를 볼 수 있다. 아래는 기본값인 \"생산성\"으로 선택된 것을 보여주고 있다.\n아드레날린(adrenalin) - 메모리 옵티마이저(Memory optimizer) - 생산성(Productive)\n\n\n메모리 옵티마이저가 생산성으로 선택되어있는 경우에 제어판의 디스플레이 상태를 보면 아래 그림과 같다. (참고로 해당 시스템은 총 메모리가 32GB이다) 그림에 보면 전용 비디오 메모리는 448MB임을 볼 수 있다. 즉 미리 잡혀있는 전용 비디오 메모리가 겨우 0.5기가 바이트도 안되는 것이다. 공유 메모리가 16GB지만 이 부분을 다 쓸 수 있다는 것은 아니고, 쓸 가능성이 있다고 봐야한다.\n제어판 - 그래픽스 속성 - 메모리 옵티마이저 - 생산성 옵션 선택\n\n\n \n비디오 메모리는 Ctrl + Shift + ESC를 눌러 작업 관리자에서 살펴봐도 메모리 상태를 볼 수 있다. 아래를 보면 전용 메모리 448메가중에 아무것도 안해도 273메가를 사용하고 있음을 볼 수 있다. 벌써 절반 이상이 소진된 것이다.\n작업관리자 - GPU - 메모리 옵티마이저 생산성 옵션 선택\n\n\n \n2. 메모리 옵티마이저 : \"게임\" 변경\n메모리 옵티마이저를 \"게임\"으로 변경해보자. 변경하면 꼭 재부팅을 해야 적용된다.\n아드레날린(adrenalin) - 메모리 옵티마이저(Memory optimizer) - 게임(Game)\n\n\n메모리 옵티마이저를 게임으로 변경하고 제어판 디스플레이 상태를 보면 아래 그림과 같다. (참고로 해당 시스템은 총 메모리가 32기가이다) 그림에 보면 이제 전용 비디오 메모리는 4096MB, 즉 4GB 임을 볼 수 있다. 이렇게 해두면 대부분의 게임이나 영상 프로그램도 잘 돌아가고, 팅김이 없어진다. (16GB메모리인 경우에는 아마도 더 적게 잡힐 가능성이 있다)\n제어판 - 그래픽스 속성 - 메모리 옵티마이저 - 게임 옵션 선택\n\n\n비디오 메모리는 Ctrl + Shift + ESC를 눌러 작업 관리자에서 살펴봐도 메모리 상태를 볼 수 있다. 아래 그림을 보면 전용 메모리 4.0GB중에 아무것도 안해도 0.3GB를 사용하고 있음을 볼 수 있다. 그리고 이제 떳떳하게 말할 수 있어졌다. 아직도 신에게는 3.7GB의 메모리가 남아있습니다라고... \n작업관리자 - GPU - 메모리 옵티마이저 게임 옵션 선택\n\n\n \n3. 결론\nAMD 내장 그래픽을 사용한다면 아드레날린의 메모리 옵티마이저를 \"게임\"으로 변경하는 것이 좋다. 끝.\n \n2024.11.23 초안",
        "guid": "http://sunyzero.tistory.com/305",
        "categories": [
          "컴퓨터 관련/윈도 패밀리",
          "7840hs",
          "amd 그래픽 게임용",
          "amd 내장 그래픽 최적화",
          "firebat mn56",
          "아드레날린 메모리 옵티마이저"
        ],
        "isoDate": "2024-11-23T01:08:26.000Z"
      }
    ]
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": [
      {
        "title": "간단한 LLM 기반 멀티 에이전트 시스템 만들어보기",
        "link": "http://daddynkidsmakers.blogspot.com/2024/11/llm.html",
        "pubDate": "2024-11-23T11:54:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">이 글은&nbsp;간단한 LLM 기반 멀티 에이전트 시스템 만드는 방법을 나눔한다.<br /></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEineMk2AGeAfb1q767pz7fv8W3zgLMz1fe5-cU6d0SivZJzxuVeTBSUXVJ1-psyaKfas-aiNRIWl1CHzHAy875fRqIV0qxzXC1xDXCYvixefxKzDZ4NF_DEGCXAXHcHQ-FSL4M93jKeWKSyaP6XJnQv3kDSB1i_TuM-iY7wC9xEEFuNqijYBVW9FPfC1T63\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"1294\" data-original-width=\"2000\" height=\"378\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEineMk2AGeAfb1q767pz7fv8W3zgLMz1fe5-cU6d0SivZJzxuVeTBSUXVJ1-psyaKfas-aiNRIWl1CHzHAy875fRqIV0qxzXC1xDXCYvixefxKzDZ4NF_DEGCXAXHcHQ-FSL4M93jKeWKSyaP6XJnQv3kDSB1i_TuM-iY7wC9xEEFuNqijYBVW9FPfC1T63=w585-h378\" width=\"585\" /></a></div><br /></div><div style=\"text-align: left;\">레퍼런스</div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><a href=\"https://langchain-ai.github.io/langgraph/tutorials/multi_agent/agent_supervisor/\">Multi-agent supervisor</a></li><li><a href=\"https://blog.langchain.dev/agent-protocol-interoperability-for-llm-agents/\">Agent Protocol: Interoperability for LLM agents</a></li><li><a href=\"https://shaikhmubin.medium.com/multi-agent-hedge-fund-simulation-with-langchain-and-langgraph-64060aabe711\">Multi-Agent Hedge Fund Simulation with LangChain and LangGraph | by Mubin Shaikh | Nov, 2024 | Medium</a></li><li><a href=\"https://arxiv.org/html/2411.08899v1\">FinVision: A Multi-Agent Framework for Stock Market Prediction</a></li></ul></div>",
        "contentSnippet": "이 글은 간단한 LLM 기반 멀티 에이전트 시스템 만드는 방법을 나눔한다.\n\n\n\n\n\n레퍼런스\n\nMulti-agent supervisor\nAgent Protocol: Interoperability for LLM agents\nMulti-Agent Hedge Fund Simulation with LangChain and LangGraph | by Mubin Shaikh | Nov, 2024 | Medium\nFinVision: A Multi-Agent Framework for Stock Market Prediction",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-3273090753094149136",
        "isoDate": "2024-11-23T11:54:00.000Z"
      }
    ]
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권영재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": [
      {
        "title": "Hikari와 비교하며 알아보는 Redis Lettuce 커넥션 풀의 특징",
        "link": "https://cheese10yun.github.io/redis-lettuce-connection/",
        "pubDate": "2024-11-17T07:13:12.000Z",
        "content": "<p>Redis는 싱글 스레드로 동작하는 인메모리 데이터베이스로, 모든 요청을 순차적으로 처리합니다. 이러한 특성 때문에 많은 개발자들은 Redis 클라이언트인 Lettuce에서 제공하는 <strong>커넥션 풀의 필요성과 이점</strong>에 대해 의문을 가질 수 있습니다. 특히, &quot;<strong>Redis는 싱글 스레드로 동작하기 때문에 여러 개의 커넥션을 사용해도 동시성을 처리할 수 없을 텐데, 이런 커넥션 풀이 무슨 의미가 있을까?</strong>&quot;라는 생각을 할 수 있습니다.</p><p>Redis 클라이언트에서 커넥션 풀을 사용하는 이유는 서버의 동작 방식과 클라이언트 애플리케이션에서의 요구사항이 다르기 때문입니다. Redis는 서버 레벨에서 요청을 순차적으로 처리하지만, 클라이언트 애플리케이션은 <strong>동시성과 성능을 최적화하기 위해 비동기 및 넌블로킹 I/O를 지원하는 Lettuce</strong>와 같은 클라이언트를 통해 여러 요청을 효과적으로 관리합니다. Lettuce는 이러한 특성을 활용해 적은 수의 커넥션으로도 높은 효율을 발휘할 수 있도록 설계되었습니다.</p><p>이번 글에서는 Hikari Connection Pool과 비교하며 Lettuce 커넥션 풀이 애플리케이션 성능에 미치는 영향을 실제 사례를 통해 구체적으로 살펴보겠습니다.</p><h2><span id=\"jdbc-hikari-connection-pool의-동작-방식\">JDBC Hikari Connection Pool의 동작 방식</span></h2><p>Redis Lettuce 커넥션 풀의 역할을 이해하기 위해, 먼저 전통적인 데이터베이스 커넥션 풀의 대표적인 예인 <strong>JDBC Hikari Connection Pool</strong>을 살펴보겠습니다.</p><p><img src=\"https://raw.githubusercontent.com/cheese10yun/blog-sample/refs/heads/master/redis/docs/lettuce-000.png\" alt=\"\"></p><p>전통적인 Hikari Connection Pool에서는 애플리케이션이 주문 정보를 조회하기 위해 커넥션 풀에서 하나의 커넥션을 가져옵니다. 아래 그림에서 볼 수 있듯이, <strong>idleConnections</strong>가 10개라면, 그 중 하나의 커넥션을 가져와 <strong>activeConnections</strong>로 전환하게 됩니다. 이 경우 <strong>idleConnections</strong>는 9개로 줄고, <strong>activeConnections</strong>는 1개가 됩니다. 전체 <strong>totalConnections</strong>는 변하지 않고 유지됩니다.</p><p><img src=\"https://raw.githubusercontent.com/cheese10yun/blog-sample/refs/heads/master/redis/docs/connection-pool-001.png\" alt=\"Hikari Connection Pool - Idle to Active\"></p><p>만약 요청이 많이 들어와 응답이 지연되고 있는 경우를 생각해 봅시다. 아래 그림처럼 <strong>maximum-pool-size</strong>가 10개인 상황에서, 모든 10개의 커넥션이 <strong>activeConnections</strong>로 전환되어 사용 중이라면, 추가적인 요청은 <strong>threadsAwaitingConnection</strong>으로 들어가 대기하게 됩니다. 즉, 사용 가능한 커넥션이 없기 때문에 요청 스레드는 커넥션이 반환될 때까지 기다려야 합니다.</p><p><img src=\"https://raw.githubusercontent.com/cheese10yun/blog-sample/refs/heads/master/redis/docs/connection-pool-002.png\" alt=\"Hikari Connection Pool - Threads Awaiting Connection\"></p><p>이와 같이 전통적인 커넥션 풀의 개념에서는, <strong>요청 스레드마다 활성화된 커넥션을 사용</strong>하며, 해당 스레드가 작업을 끝내기 전까지는 <strong>커넥션을 점유</strong>하게 됩니다. 이는 데이터베이스의 동시 연결 수와 처리 능력을 효과적으로 관리할 수 있는 방법이지만, 커넥션이 사용 중일 때 대기하는 요청들이 발생할 수 있다는 단점이 있습니다.</p><p>이제 이러한 전통적인 커넥션 풀과 비교하여, <strong>Redis Lettuce Connection Pool</strong>이 어떻게 다른 방식으로 동작하는지에 대해 알아보겠습니다.</p><h2><span id=\"redis-lettuce-connection-pool의-동작-방식\">Redis Lettuce Connection Pool의 동작 방식</span></h2><p>Redis Lettuce Connection Pool의 동작 방식을 이해하기 위해, <strong>Redis 조회와 MySQL 조회가 함께 사용되는 시나리오</strong>를 살펴보겠습니다.</p><p><img src=\"https://raw.githubusercontent.com/cheese10yun/blog-sample/refs/heads/master/redis/docs/lettuce-001.png\" alt=\"\"></p><p>위의 시나리오에서 애플리케이션은 먼저 Redis에서 쿠폰 정보를 조회한 후, MySQL에서 주문 정보를 조회합니다. Redis 쿠폰 조회는 10ms 만에 응답이 오지만, 이후 이어지는 MySQL 조회는 2,500ms가 걸립니다. 이 상황에서 Redis Lettuce 커넥션 풀이 어떻게 동작하는지를 이해하는 것이 중요합니다.</p><p>Redis에 쿠폰 조회 요청을 보내면, 10ms 내에 쿠폰 정보가 응답됩니다. 여기서 Lettuce 커넥션 풀이 1개만 있다고 가정해 보겠습니다. 만약 이 상황이 전통적인 커넥션 풀 구조였다면, MySQL 데이터 조회(2,500ms)가 완료되기 전까지 하나뿐인 Redis 커넥션이 블록되어 Redis에 대한 추가적인 요청을 처리할 수 없었을 것입니다. 이는 Redis 서버가 이미 응답을 완료했음에도 불구하고, 애플리케이션 측에서 더 이상 Redis에 대한 요청을 처리할 수 없게 된다는 문제를 야기합니다.</p><p>그러나 Redis Lettuce의 경우 비동기적으로 동작할 수 있습니다. Redis 서버에서 응답을 내린 후 해당 커넥션이 즉시 반환된다면, MySQL 조회가 진행 중이더라도 Redis에 대한 새로운 요청을 처리할 수 있게 됩니다. 이는 Redis 서버가 싱글 스레드로 동작하더라도 Lettuce 클라이언트 측에서는 추가적인 요청을 계속해서 보낼 수 있는 가능성을 열어줍니다. 그렇다면 실제로 Redis Lettuce가 이러한 방식으로 동작하는지, 아니면 다른 방식으로 동작하는지 <strong>코드를 통해 더 자세히 살펴보겠습니다</strong>.</p><h2><span id=\"redis-lettuce와-hikari-동작-비교를-위한-코드\">Redis Lettuce와 Hikari 동작 비교를 위한 코드</span></h2><figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@RestController</span></span><br><span class=\"line\"><span class=\"meta\">@RequestMapping</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MemberController</span></span>(</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">val</span> redisConnectionPoolSample: RedisConnectionPoolSample,</span><br><span class=\"line\">) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@GetMapping(<span class=\"meta-string\">\"/api/redis\"</span>)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">fun</span> <span class=\"title\">getRedis</span><span class=\"params\">(<span class=\"meta\">@RequestParam(<span class=\"meta-string\">\"id\"</span>)</span> id: <span class=\"type\">String</span>)</span></span> = redisConnectionPoolSample.getRedis(id)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@GetMapping(<span class=\"meta-string\">\"/api/mysql\"</span>)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">fun</span> <span class=\"title\">getMySql</span><span class=\"params\">(<span class=\"meta\">@RequestParam(<span class=\"meta-string\">\"id\"</span>)</span> id: <span class=\"type\">Long</span>)</span></span> = redisConnectionPoolSample.getMySql(id)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@GetMapping(<span class=\"meta-string\">\"/api/composite\"</span>)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">fun</span> <span class=\"title\">getRedis2</span><span class=\"params\">(<span class=\"meta\">@RequestParam(<span class=\"meta-string\">\"id\"</span>)</span> id: <span class=\"type\">String</span>)</span></span> = redisConnectionPoolSample.getComposite(id)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@Service</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">RedisConnectionPoolSample</span></span>(</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">val</span> couponRepository: CouponRepository,</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">val</span> orderRepository: OrderRepository</span><br><span class=\"line\"></span><br><span class=\"line\">) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">fun</span> <span class=\"title\">getRedis</span><span class=\"params\">(id: <span class=\"type\">String</span>)</span></span>: Coupon? &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> couponRepository.findByIdOrNull(id)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">fun</span> <span class=\"title\">getMySql</span><span class=\"params\">(id: <span class=\"type\">Long</span>)</span></span>: Order? &#123;</span><br><span class=\"line\">        printHikariConnection()</span><br><span class=\"line\">        <span class=\"keyword\">return</span> orderRepository.findByIdOrNull(id)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">fun</span> <span class=\"title\">getComposite</span><span class=\"params\">(id: <span class=\"type\">String</span>)</span></span>: Pair&lt;Coupon?, Order?&gt; &#123;</span><br><span class=\"line\">        <span class=\"keyword\">val</span> coupon = couponRepository.findByIdOrNull(id)</span><br><span class=\"line\">        <span class=\"keyword\">val</span> order = orderRepository.findByIdOrNull(id.toLong())</span><br><span class=\"line\">        Thread.sleep(<span class=\"number\">2500</span>) <span class=\"comment\">// 2.5초 대기</span></span><br><span class=\"line\">        printHikariConnection()</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Pair(coupon, order)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"function\"><span class=\"keyword\">fun</span> <span class=\"title\">printHikariConnection</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">val</span> targetDataSource = dataSource.unwrap(HikariDataSource::<span class=\"class\"><span class=\"keyword\">class</span>.<span class=\"title\">java</span>)</span></span><br><span class=\"line\">        <span class=\"keyword\">val</span> hikariDataSource = targetDataSource <span class=\"keyword\">as</span> HikariDataSource</span><br><span class=\"line\">        <span class=\"keyword\">val</span> hikariPoolMXBean = hikariDataSource.hikariPoolMXBean</span><br><span class=\"line\">        <span class=\"keyword\">val</span> hikariConfigMXBean = hikariDataSource.hikariConfigMXBean</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">val</span> log = buildString &#123;</span><br><span class=\"line\">            append(<span class=\"string\">\"totalConnections: <span class=\"subst\">$&#123;hikariPoolMXBean.totalConnections&#125;</span>, \"</span>)</span><br><span class=\"line\">            append(<span class=\"string\">\"activeConnections: <span class=\"subst\">$&#123;hikariPoolMXBean.activeConnections&#125;</span>, \"</span>)</span><br><span class=\"line\">            append(<span class=\"string\">\"idleConnections: <span class=\"subst\">$&#123;hikariPoolMXBean.idleConnections&#125;</span>, \"</span>)</span><br><span class=\"line\">            append(<span class=\"string\">\"threadsAwaitingConnection: <span class=\"subst\">$&#123;hikariPoolMXBean.threadsAwaitingConnection&#125;</span>\"</span>)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        println(log)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><p>위의 코드에서 <code>/api/redis</code>는 단순히 Redis에서 쿠폰 정보를 조회하는 API입니다. <code>/api/mysql</code>은 MySQL에서 주문 정보를 조회하는 API이며, <code>/api/composite</code>는 Redis 조회 후 MySQL 조회를 수행하고 2.5초 동안 대기한 후 응답을 반환하는 API입니다.</p><p>특히 <code>/api/composite</code>는 Redis에서 쿠폰을 조회한 후 MySQL 조회를 수행하며, 이때 <code>Thread.sleep(2500)</code>으로 인해 2.5초 동안 대기하게 됩니다. 이 상황에서 Lettuce의 커넥션 풀이 어떻게 동작하는지 살펴볼 수 있습니다.</p><h2><span id=\"시나리오별-hikari와-lettuce의-차이점\">시나리오별 Hikari와 Lettuce의 차이점</span></h2><p>이 섹션에서는 Hikari와 Lettuce의 동작 방식을 서로 비교하면서 각 시나리오에서 어떤 차이점이 발생하는지에 대해 구체적으로 살펴보겠습니다. 이를 통해 각 커넥션 풀이 어떤 차이점을 갖고 있는지 명확히 이해할 수 있습니다.</p><h3><span id=\"시나리오-getcomposite-호출-이후-getmysql-호출\">시나리오: getComposite 호출 이후 getMySql 호출</span></h3><p>Hikari 설정은 <code>maximum-pool-size=1</code>, <code>minimum-idle=1</code>로 구성되어 있으며, <code>getComposite</code> 호출 시 사용 가능한 단 하나의 커넥션을 사용하여 작업이 진행됩니다. 이번 테스트의 목적은 <strong><code>/api/composite</code> 호출 이후 <code>getMySql</code> 호출의 응답 속도를 확인</strong>하는 것입니다. 만약 Hikari Connection Pool이 블로킹 방식으로 동작한다면 <code>getComposite</code> 호출 중 MySQL 조회 요청으로 점유된 커넥션이 반환되지 않아 <code>getMySql</code> 요청은 대기 상태에 놓이고 응답 시간이 지연될 것입니다. 반대로 MySQL 조회 요청이 빠르게 완료되거나, 추가적인 idle 커넥션이 있다면 <code>getMySql</code> 요청은 지연 없이 처리될 수 있습니다.</p><p>이 상태에서 <code>getMySql</code> 호출을 시도하면, 사용 가능한 <strong>idle 커넥션</strong>이 없기 때문에 <code>getComposite</code> 호출이 끝난 후 반환된 커넥션을 사용해야 합니다. 이로 인해 <strong>threadsAwaitingConnection</strong> 상태에서 대기하게 되고, 지연이 발생합니다. 이후 <strong>threadsAwaitingConnection</strong>에서 대기하던 요청이 <strong>activeConnections</strong>로 전환되면, <code>getMySql</code> 호출에서 해당 커넥션을 사용할 수 있게 됩니다.</p><h4><span id=\"테스트-결과\">테스트 결과</span></h4><ol><li><p><code>/api/mysql</code> 단독 호출 시:</p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Connection totalConnections: 1, activeConnections: 1, idleConnections: 0, threadsAwaitingConnection: 0</span><br><span class=\"line\"># HTTP 응답 Response code: 200; Time: 24ms (24 ms); Content length: 64 bytes (64 B)</span><br></pre></td></tr></table></figure></li><li><p><code>/api/composite</code> 호출 이후 바로 <code>/api/mysql</code>를 호출한 경우:</p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Connection totalConnections: 1, activeConnections: 1, idleConnections: 0, threadsAwaitingConnection: 1</span><br><span class=\"line\"># HTTP 응답 Response code: 200; Time: 1112ms (1 s 112 ms); Content length: 64 bytes (64 B)</span><br></pre></td></tr></table></figure></li></ol><p>테스트 결과, <code>/api/composite</code> 호출 이후 <code>getMySql</code> 요청은 대기 상태에 놓이며, MySQL 조회 작업이 완료되어 커넥션이 반환된 이후에 처리되는 것을 확인할 수 있었습니다. 이는 Hikari Connection Pool이 동기적이며, 사용 중인 커넥션이 반환될 때까지 대기 상태에 놓이는 블로킹 방식으로 동작하기 때문입니다.</p><h4><span id=\"동작-흐름\">동작 흐름</span></h4><p><img src=\"https://raw.githubusercontent.com/cheese10yun/blog-sample/refs/heads/master/redis/docs/lettuce-002.png\" alt=\"\"></p><p>Hikari Connection Pool의 동작 방식은 아래와 같습니다.</p><ol><li><strong><code>getComposite</code> 호출</strong>: <code>Service</code>는 MySQL A 조회를 요청하고, 사용 가능한 idle 커넥션을 가져옵니다. 이 요청은 2,500ms가 소요되며, 해당 커넥션은 점유된 상태로 유지됩니다.</li><li><strong><code>getMySql</code> 호출</strong>: <code>Controller</code>는 <code>Service</code>로 <code>getMySql</code> 호출을 보냅니다. 그러나 MySQL A 조회 요청이 아직 진행 중이므로 사용 가능한 커넥션이 없습니다. 이에 따라 요청은 <strong>threadsAwaitingConnection</strong> 상태로 대기하게 됩니다.</li><li><strong>MySQL A 응답 반환</strong>: MySQL A 조회 요청이 완료되면서 커넥션이 반환됩니다. 반환된 커넥션은 대기 중이던 <code>getMySql</code>의 MySQL B 조회 요청에서 다시 사용됩니다.</li><li><strong>MySQL B 조회 요청 및 응답</strong>: 반환된 커넥션을 사용해 MySQL B 조회 요청이 처리됩니다. B 조회는 지연 없이 완료되며, 응답이 반환됩니다.</li><li><strong>최종 응답 반환</strong>: <code>getComposite</code>와 <code>getMySql</code> 요청이 순차적으로 완료되며, 최종적으로 각각의 결과가 <code>Controller</code>로 반환됩니다.</li></ol><h4><span id=\"블로킹-방식의-한계\">블로킹 방식의 한계</span></h4><p>이 시나리오에서 Hikari Connection Pool의 블로킹 특성으로 인해 다음과 같은 한계가 발생합니다. MySQL A 조회 요청이 완료되기 전까지 커넥션이 반환되지 않아 <code>getMySql</code> 호출이 대기 상태에 놓이고, 동시 요청 수가 증가하면 <strong>threadsAwaitingConnection</strong> 상태가 늘어나면서 대기 시간이 길어질 가능성이 있습니다. 반면, Redis Lettuce 커넥션 풀은 이러한 상황에서 다르게 동작할 수 있습니다. Lettuce가 스레드를 블록시키는 방식으로 작동한다면 비슷한 지연 문제가 발생하지만, 논블로킹 방식이라면 MySQL의 지연과 관계없이 추가적인 Redis 요청에 빠르게 응답할 수 있습니다.</p><h3><span id=\"시나리오-getcomposite-호출-이후-getredis-호출\">시나리오: getComposite 호출 이후 getRedis 호출</span></h3><p>Lettuce 설정은 <code>max-active=1</code>, <code>max-idle=1</code>, <code>min-idle=1</code>로 구성되어 있으며, <code>getComposite</code> 호출 시 사용 가능한 단 하나의 커넥션을 사용하여 작업이 진행됩니다. 이번 테스트의 목적은 <strong><code>/api/composite</code> 호출 이후 <code>getRedis</code> 호출의 응답 속도를 확인</strong>하는 것입니다. 만약 Lettuce가 블록되는 방식으로 동작한다면 <code>getComposite</code> 호출 중 Redis 조회 요청으로 점유된 커넥션이 MySQL 작업이 끝날 때까지 반환되지 않아 <code>getRedis</code> 요청은 대기 상태에 놓이고 응답 시간이 지연될 것입니다. 반대로 Lettuce가 비동기적이며 블로킹되지 않는 방식으로 동작한다면 <code>getComposite</code> 호출 중에도 커넥션이 Redis 요청 응답 후 즉시 반환되므로, <code>getRedis</code> 요청이 지연 없이 처리될 것입니다.</p><h4><span id=\"테스트-결과\">테스트 결과</span></h4><ol><li><p><code>/api/composite</code> 호출 이후 바로 <code>/api/redis</code>를 호출한 경우:</p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Response code: 200; Time: 8ms (8 ms); Content length: 56 bytes (56 B)</span><br></pre></td></tr></table></figure></li><li><p><code>/api/redis</code> 단독 호출 시:</p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Response code: 200; Time: 6ms (6 ms); Content length: 56 bytes (56 B)</span><br></pre></td></tr></table></figure></li></ol><p>테스트 결과, <code>/api/composite</code> 호출 중에도 <code>/api/redis</code> 요청은 지연 없이 빠르게 응답하는 것을 확인할 수 있었습니다. 이는 Lettuce가 비동기적으로 동작하며, 스레드를 블록하지 않음을 시사합니다.</p><h4><span id=\"동작-흐름\">동작 흐름</span></h4><p><img src=\"https://raw.githubusercontent.com/cheese10yun/blog-sample/refs/heads/master/redis/docs/lettuce-003.png\" alt=\"\"></p><ol><li><strong><code>getComposite</code> 호출</strong>: <code>Controller</code>가 <code>getComposite</code> 요청을 보냅니다. <code>Service</code>는 먼저 Redis 조회를 수행하며, 이 작업은 10ms 만에 완료되고 커넥션은 즉시 반환됩니다. 이후 MySQL 조회를 시작하며, MySQL 조회 작업은 2,500ms가 소요됩니다.</li><li><strong><code>getRedis</code> 호출</strong>: MySQL 조회가 진행 중인 상태에서 <code>Controller</code>가 <code>getRedis</code> 요청을 보냅니다. Redis는 MySQL 작업과는 독립적으로 동작하므로, Redis 조회 요청은 지연 없이 처리됩니다. 반환된 Redis 커넥션이 즉시 재사용되어 <code>getRedis</code> 요청이 빠르게 완료됩니다.</li><li><strong><code>getComposite</code> 응답 반환</strong>: MySQL 작업이 완료되면 <code>getComposite</code> 응답이 반환됩니다.</li><li><strong><code>getRedis</code> 응답 반환</strong>: hRedis 조회 요청이 완료된 후 응답이 반환됩니다. Redis 작업이 MySQL 작업의 지연과 상관없이 즉시 처리되었기 때문에 빠른 응답 시간을 유지합니다.</li></ol><h4><span id=\"논블로킹의-장점\">논블로킹의 장점</span></h4><p>테스트 결과를 통해 Lettuce가 비동기적이고 논블로킹 방식으로 동작한다는 것을 확인할 수 있었습니다. Redis 조회는 10ms 만에 응답을 완료하고 커넥션을 즉시 반환하므로, MySQL 작업이 진행 중이라도 Redis 커넥션이 점유된 상태로 남아있지 않습니다. 결과적으로, 추가적인 Redis 요청(<code>getRedis</code>)은 MySQL의 작업 지연과 관계없이 빠르게 처리됩니다.</p><p>이는 MySQL의 Hikari Connection Pool이 스레드를 블록하여 대기 시간을 유발하는 방식과 대비됩니다. Hikari에서는 커넥션이 반환될 때까지 다른 요청이 대기 상태에 놓이지만, Lettuce는 커넥션 반환이 즉시 이루어져 이러한 지연 없이 요청을 처리할 수 있습니다.</p><p>Redis의 비동기 I/O와 Lettuce의 설계가 결합되어 높은 동시성 환경에서도 안정적인 성능을 유지할 수 있음을 보여주는 사례라 할 수 있습니다. 이러한 특성은 Redis와 같이 빠른 응답성을 요구하는 환경에서 Lettuce가 얼마나 효율적인지를 잘 보여줍니다.</p><h3><span id=\"hikari와-lettuce의-차이점-정리\">Hikari와 Lettuce의 차이점 정리</span></h3><ol><li><strong>동작 방식의 차이</strong>:<ul><li>Hikari Connection Pool은 <strong>전통적인 동기식 동작</strong>을 기반으로 하며, 스레드 블로킹이 발생합니다. MySQL 같은 관계형 데이터베이스와 함께 사용하는 경우, 데이터 조회 시 커넥션이 점유된 상태로 유지되므로 다른 요청들은 사용 가능한 커넥션이 없어 대기하게 됩니다.</li><li>Redis Lettuce Connection Pool은 <strong>비동기 및 넌블로킹 I/O</strong>를 지원하여, Redis 서버에서 응답을 받은 후에도 바로 커넥션을 반환할 수 있습니다. 이를 통해 <strong>커넥션 점유 시간이 짧아져</strong> Redis에 대한 다른 요청들도 빠르게 처리될 수 있습니다.</li></ul></li><li><strong>커넥션 풀의 활용도</strong>:<ul><li>Hikari Connection Pool은 <strong>threadsAwaitingConnection</strong>을 관리하며, 커넥션 풀이 모두 사용 중일 경우 새 요청들은 대기하게 됩니다. 따라서 <strong>커넥션 풀 크기 설정</strong>이 성능에 큰 영향을 미칩니다.</li><li>Redis Lettuce Connection Pool은 커넥션을 빠르게 반환하기 때문에, <strong>커넥션 풀 크기를 크게 설정하지 않아도 효율적으로 동작</strong>할 수 있습니다. Redis의 비동기 처리 덕분에 서버의 응답이 빠르다면, 적은 수의 커넥션으로도 많은 요청을 처리할 수 있습니다.</li></ul></li><li><strong>특정 상황에서의 블로킹 차이</strong>:<ul><li>Hikari Connection Pool은 요청이 지연되면, 다른 커넥션이 점유되지 않는 한 <strong>대기 스레드</strong>가 계속 늘어날 수 있습니다. 이는 높은 동시성에서 성능 저하를 야기할 수 있습니다.</li><li>Redis Lettuce는 비동기적이며, Redis 서버로부터 응답을 받은 후에는 <strong>커넥션을 빠르게 반환</strong>하므로, <strong>서버 응답 시간</strong>이 Lettuce의 성능에 직접적인 영향을 미칩니다. 즉, Redis 명령어가 복잡하고 시간이 오래 걸리면(예: <code>keys *</code> 사용), 그 시간 동안 다른 요청들이 블록될 수 있습니다.</li></ul></li><li><strong>블로킹/넌블로킹의 영향</strong>:<ul><li>Hikari의 경우 <strong>스레드 블로킹</strong>이 빈번히 발생하는 반면, Lettuce는 넌블로킹으로 <strong>추가적인 스레드 리소스를 사용하지 않고도</strong> 더 많은 요청을 처리할 수 있는 장점이 있습니다.</li><li>이는 특히 <strong>IO 작업이 많은 환경</strong>에서 Lettuce가 더 효율적으로 동작하도록 만듭니다. 반면, Hikari는 <strong>동기적 처리</strong>로 인해 CPU 자원을 더 많이 사용하게 되며, 이는 고비용의 대기 시간이 발생할 가능성을 증가시킵니다.</li></ul></li></ol><h2><span id=\"lettuce-connection-pool-설정과-의미\">Lettuce Connection Pool 설정과 의미</span></h2><h3><span id=\"lettuce-connection-pool-properties\">Lettuce Connection Pool Properties</span></h3><p>Spring Data Redis에서는 <code>application.yml</code> 파일을 통해 Lettuce Connection Pool의 설정을 손쉽게 구성할 수 있습니다. 아래는 주요 프로퍼티와 그 설명입니다:</p><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">spring:</span></span><br><span class=\"line\"><span class=\"attr\">    redis:</span></span><br><span class=\"line\"><span class=\"attr\">        lettuce:</span></span><br><span class=\"line\"><span class=\"attr\">            pool:</span></span><br><span class=\"line\"><span class=\"attr\">                max-active:</span> <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"attr\">                max-idle:</span> <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"attr\">                min-idle:</span> <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"attr\">                enabled:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"attr\">                max-wait:</span> <span class=\"number\">1000</span><span class=\"string\">ms</span></span><br><span class=\"line\"><span class=\"attr\">                time-between-eviction-runs:</span> <span class=\"number\">1000</span><span class=\"string\">ms</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>설정 항목</th><th>설명</th><th>기본 값</th></tr></thead><tbody><tr><td><code>max-active</code></td><td>Connection Pool에서 사용할 수 있는 최대 커넥션 수로, 동시 연결 수를 제한합니다.</td><td>8</td></tr><tr><td><code>max-idle</code></td><td>Connection Pool에서 유지할 수 있는 최대 유휴 커넥션 수입니다. 이 값을 초과하는 유휴 커넥션은 폐기됩니다.</td><td>8</td></tr><tr><td><code>min-idle</code></td><td>Connection Pool에서 유지할 최소 유휴 커넥션 수입니다. 유휴 커넥션이 부족하면 새 커넥션을 생성합니다.</td><td>0</td></tr><tr><td><code>enabled</code></td><td>Lettuce Connection Pool 사용 여부를 설정합니다. <code>true</code>로 설정 시 Pool이 활성화됩니다.</td><td><code>false</code></td></tr><tr><td><code>max-wait</code></td><td>커넥션이 사용 중일 때 새로운 요청이 대기할 수 있는 최대 시간입니다. 설정된 시간이 초과되면 예외가 발생합니다.</td><td>-1 (무제한 대기)</td></tr><tr><td><code>time-between-eviction-runs</code></td><td>유휴 커넥션 검사 및 제거 작업의 주기를 설정합니다. (단위: 밀리초)</td><td>-1 (검사하지 않음)</td></tr></tbody></table><p>이러한 설정은 Lettuce Connection Pool의 동작을 세부적으로 제어하며, 애플리케이션의 요구 사항에 맞게 성능과 리소스 사용량을 조정할 수 있습니다. 특히, <code>max-active</code>, <code>min-idle</code>, <code>max-wait</code>와 같은 설정은 TPS가 높은 환경이나 트래픽 변동이 큰 상황에서 애플리케이션의 안정성을 보장하는 데 중요한 역할을 합니다.</p><h3><span id=\"lettuce-connection-pool의-개수가-갖는-의미\">Lettuce Connection Pool의 개수가 갖는 의미</span></h3><p>Redis Lettuce Connection은 비동기 방식으로 동작하며, 요청을 처리한 후 커넥션을 즉시 반환하는 구조를 가지고 있습니다. 이는 적은 수의 커넥션으로도 높은 효율을 발휘할 수 있다는 점에서 큰 장점입니다. 하지만, Hikari와 같은 전통적인 동기 커넥션 풀처럼 미리 커넥션을 확보하여 동시성을 처리하는 방식은 아니기 때문에, &quot;Lettuce Connection Pool의 개수가 많다고 해서 이점이 있을까?&quot;라는 의문을 가질 수 있습니다.</p><p>사실, Lettuce Connection Pool의 개수는 TPS가 높아지고 Redis 서버의 응답이 느려질 때 중요한 의미를 가집니다. 다음은 Lettuce Connection Pool의 개수가 많을 때 가지는 이점을 설명합니다.</p><ol><li><p><strong>Redis 응답 지연 시 동시 요청 처리 가능</strong>:<br>Redis 서버가 응답을 지연하는 경우, 요청이 커넥션을 점유하는 시간이 길어집니다. 이때 Connection Pool의 크기가 작다면 모든 커넥션이 점유된 상태에서 새로운 요청이 대기 상태로 전환될 가능성이 높습니다. 하지만 Connection Pool 크기가 충분히 크다면, 지연된 요청과 별개로 다른 요청을 처리할 여유를 확보할 수 있습니다. 이는 TPS가 몰리는 상황에서도 전체 시스템의 성능 저하를 방지합니다.</p></li><li><p><strong>Burst 트래픽에서의 안정성 확보</strong>:<br>트래픽이 순간적으로 폭증하는 경우, Pool 크기가 충분히 크면 새로운 요청을 대기시키지 않고 처리할 수 있습니다. 이는 특히 Redis 응답 시간이 일관되지 않은 상황에서 더욱 중요한데, Pool 크기가 충분하지 않으면 요청 처리 시간이 예측 불가능하게 증가할 수 있습니다.</p></li><li><p><strong>멀티 인스턴스 활용 가능성</strong>:<br>Redis는 싱글 스레드로 동작하지만, 애플리케이션 인스턴스가 여러 개일 경우 각 인스턴스에서 동시에 Redis에 접근합니다. Pool 크기가 충분히 크다면, 여러 인스턴스가 Redis와 병렬로 통신하면서도 효율적으로 커넥션을 재사용할 수 있습니다.</p></li><li><p><strong>비동기 요청 처리 속도 향상</strong>:<br>Lettuce는 비동기적으로 여러 요청을 처리할 수 있지만, Pool 크기가 제한적이라면 커넥션 재사용의 병목이 발생할 수 있습니다. Pool 크기를 늘리면 이러한 병목을 완화하고, Redis 서버의 응답 속도에 따라 더 많은 요청을 처리할 수 있습니다.</p></li><li><p><strong>장시간 실행되는 명령어의 영향 완화</strong>:<br>일부 Redis 명령어(예: <code>zrange</code>, <code>keys</code>)는 실행 시간이 길어질 수 있습니다. Pool 크기가 작다면 이런 명령이 다른 요청 처리에 직접적인 영향을 미치지만, 충분한 Pool 크기는 이런 상황에서도 다른 요청을 지연 없이 처리할 수 있도록 합니다.</p></li></ol><p>Lettuce Connection Pool의 개수는 TPS와 Redis 서버의 응답 지연이 증가하는 상황에서 중요한 역할을 합니다. 비록 Lettuce가 비동기적이고 효율적인 구조를 가졌더라도, Pool 크기를 적절히 설정하지 않으면 요청 대기가 발생할 수 있습니다.</p><p>따라서 Lettuce Connection Pool의 개수는 단순히 많은 요청을 처리하기 위한 것이 아니라, Redis 서버 응답 시간의 변동성, Burst 트래픽, 그리고 장시간 실행되는 명령어 처리와 같은 다양한 상황에 대비하기 위한 안정성을 제공한다고 볼 수 있습니다. Connection Pool 크기를 TPS와 트래픽 패턴에 맞게 조정하는 것이 Lettuce의 효율성을 극대화하는 핵심 전략입니다.</p><h2><span id=\"결론\">결론</span></h2><p>논블로킹 방식이 항상 절대적으로 좋은 것은 아닙니다. Redis Lettuce와 Hikari Connection Pool은 서로 다른 특성과 장점을 가지고 있으며, 각 환경에 따라 적절히 선택해야 합니다.</p><p>Lettuce의 경우, Redis 서버로부터 응답을 받으면 커넥션을 즉시 반환하고 다음 요청을 처리할 준비를 합니다. 이는 커넥션 점유 시간이 짧아져 더 작은 풀 크기로 효율적인 요청 처리가 가능하다는 큰 장점이 있습니다. 하지만 Redis 서버 자체가 응답을 지연한다면, 다른 요청이 대기 상태에 놓이게 되어 성능 저하로 이어질 수 있습니다. 이러한 상황에서는 Lettuce의 비동기적 특성이 한계를 보일 수 있습니다.</p><p>반면, Hikari Connection Pool은 유휴 커넥션이 있는 경우 한 요청이 오래 걸리더라도 다른 커넥션을 사용하여 추가적인 요청을 처리할 수 있습니다. 이는 Redis와 같은 싱글 스레드 구조가 아닌, 다중 커넥션을 사용하는 데이터베이스 환경에 잘 맞는 전략입니다. 그러나 Hikari는 요청 중 커넥션이 블록되는 방식으로 동작하기 때문에, 풀 크기가 제한적이거나 동시 요청이 많아지면 대기 시간이 길어질 가능성이 있습니다.</p><p>이러한 차이는 Redis가 싱글 스레드로 모든 요청을 처리하도록 설계된 서버라는 점에서 기인합니다. Lettuce는 Redis 서버의 메커니즘과 잘 맞는 전략을 선택하여 구현되었으며, 비동기와 논블로킹을 통해 Redis의 성능 특성을 최대한 활용합니다. 이는 Hikari Connection Pool과는 다른 접근 방식으로, Redis 서버와의 높은 호환성을 유지하며 효율적인 자원 관리를 가능하게 합니다.</p><p>소프트웨어 개발에서는 항상 트레이드오프가 존재합니다. 특정 기술이 모든 상황에서 우월하다고 말할 수는 없습니다. Lettuce와 Hikari의 차이는 각기 다른 환경에 적합한 도구를 제공하며, 사용자는 자신의 애플리케이션 요구사항에 따라 적합한 전략을 선택해야 합니다. 결국, 어떤 도구가 &quot;좋다&quot;라고 단정짓기보다는, 각 기술의 장단점을 이해하고 상황에 맞게 활용하는 것이 중요합니다.</p>",
        "contentSnippet": "Redis는 싱글 스레드로 동작하는 인메모리 데이터베이스로, 모든 요청을 순차적으로 처리합니다. 이러한 특성 때문에 많은 개발자들은 Redis 클라이언트인 Lettuce에서 제공하는 커넥션 풀의 필요성과 이점에 대해 의문을 가질 수 있습니다. 특히, \"Redis는 싱글 스레드로 동작하기 때문에 여러 개의 커넥션을 사용해도 동시성을 처리할 수 없을 텐데, 이런 커넥션 풀이 무슨 의미가 있을까?\"라는 생각을 할 수 있습니다.\nRedis 클라이언트에서 커넥션 풀을 사용하는 이유는 서버의 동작 방식과 클라이언트 애플리케이션에서의 요구사항이 다르기 때문입니다. Redis는 서버 레벨에서 요청을 순차적으로 처리하지만, 클라이언트 애플리케이션은 동시성과 성능을 최적화하기 위해 비동기 및 넌블로킹 I/O를 지원하는 Lettuce와 같은 클라이언트를 통해 여러 요청을 효과적으로 관리합니다. Lettuce는 이러한 특성을 활용해 적은 수의 커넥션으로도 높은 효율을 발휘할 수 있도록 설계되었습니다.\n이번 글에서는 Hikari Connection Pool과 비교하며 Lettuce 커넥션 풀이 애플리케이션 성능에 미치는 영향을 실제 사례를 통해 구체적으로 살펴보겠습니다.\nJDBC Hikari Connection Pool의 동작 방식\nRedis Lettuce 커넥션 풀의 역할을 이해하기 위해, 먼저 전통적인 데이터베이스 커넥션 풀의 대표적인 예인 JDBC Hikari Connection Pool을 살펴보겠습니다.\n\n전통적인 Hikari Connection Pool에서는 애플리케이션이 주문 정보를 조회하기 위해 커넥션 풀에서 하나의 커넥션을 가져옵니다. 아래 그림에서 볼 수 있듯이, idleConnections가 10개라면, 그 중 하나의 커넥션을 가져와 activeConnections로 전환하게 됩니다. 이 경우 idleConnections는 9개로 줄고, activeConnections는 1개가 됩니다. 전체 totalConnections는 변하지 않고 유지됩니다.\n\n만약 요청이 많이 들어와 응답이 지연되고 있는 경우를 생각해 봅시다. 아래 그림처럼 maximum-pool-size가 10개인 상황에서, 모든 10개의 커넥션이 activeConnections로 전환되어 사용 중이라면, 추가적인 요청은 threadsAwaitingConnection으로 들어가 대기하게 됩니다. 즉, 사용 가능한 커넥션이 없기 때문에 요청 스레드는 커넥션이 반환될 때까지 기다려야 합니다.\n\n이와 같이 전통적인 커넥션 풀의 개념에서는, 요청 스레드마다 활성화된 커넥션을 사용하며, 해당 스레드가 작업을 끝내기 전까지는 커넥션을 점유하게 됩니다. 이는 데이터베이스의 동시 연결 수와 처리 능력을 효과적으로 관리할 수 있는 방법이지만, 커넥션이 사용 중일 때 대기하는 요청들이 발생할 수 있다는 단점이 있습니다.\n이제 이러한 전통적인 커넥션 풀과 비교하여, Redis Lettuce Connection Pool이 어떻게 다른 방식으로 동작하는지에 대해 알아보겠습니다.\nRedis Lettuce Connection Pool의 동작 방식\nRedis Lettuce Connection Pool의 동작 방식을 이해하기 위해, Redis 조회와 MySQL 조회가 함께 사용되는 시나리오를 살펴보겠습니다.\n\n위의 시나리오에서 애플리케이션은 먼저 Redis에서 쿠폰 정보를 조회한 후, MySQL에서 주문 정보를 조회합니다. Redis 쿠폰 조회는 10ms 만에 응답이 오지만, 이후 이어지는 MySQL 조회는 2,500ms가 걸립니다. 이 상황에서 Redis Lettuce 커넥션 풀이 어떻게 동작하는지를 이해하는 것이 중요합니다.\nRedis에 쿠폰 조회 요청을 보내면, 10ms 내에 쿠폰 정보가 응답됩니다. 여기서 Lettuce 커넥션 풀이 1개만 있다고 가정해 보겠습니다. 만약 이 상황이 전통적인 커넥션 풀 구조였다면, MySQL 데이터 조회(2,500ms)가 완료되기 전까지 하나뿐인 Redis 커넥션이 블록되어 Redis에 대한 추가적인 요청을 처리할 수 없었을 것입니다. 이는 Redis 서버가 이미 응답을 완료했음에도 불구하고, 애플리케이션 측에서 더 이상 Redis에 대한 요청을 처리할 수 없게 된다는 문제를 야기합니다.\n그러나 Redis Lettuce의 경우 비동기적으로 동작할 수 있습니다. Redis 서버에서 응답을 내린 후 해당 커넥션이 즉시 반환된다면, MySQL 조회가 진행 중이더라도 Redis에 대한 새로운 요청을 처리할 수 있게 됩니다. 이는 Redis 서버가 싱글 스레드로 동작하더라도 Lettuce 클라이언트 측에서는 추가적인 요청을 계속해서 보낼 수 있는 가능성을 열어줍니다. 그렇다면 실제로 Redis Lettuce가 이러한 방식으로 동작하는지, 아니면 다른 방식으로 동작하는지 코드를 통해 더 자세히 살펴보겠습니다.\nRedis Lettuce와 Hikari 동작 비교를 위한 코드\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n\n@RestController\n@RequestMapping\nclass MemberController(\n    private val redisConnectionPoolSample: RedisConnectionPoolSample,\n) {\n\n    @GetMapping(\"/api/redis\")\n    fun getRedis(@RequestParam(\"id\") id: String) = redisConnectionPoolSample.getRedis(id)\n\n    @GetMapping(\"/api/mysql\")\n    fun getMySql(@RequestParam(\"id\") id: Long) = redisConnectionPoolSample.getMySql(id)\n\n    @GetMapping(\"/api/composite\")\n    fun getRedis2(@RequestParam(\"id\") id: String) = redisConnectionPoolSample.getComposite(id)\n}\n\n@Service\nclass RedisConnectionPoolSample(\n    private val couponRepository: CouponRepository,\n    private val orderRepository: OrderRepository\n\n) {\n\n    fun getRedis(id: String): Coupon? {\n        return couponRepository.findByIdOrNull(id)\n    }\n\n\n    fun getMySql(id: Long): Order? {\n        printHikariConnection()\n        return orderRepository.findByIdOrNull(id)\n    }\n\n    fun getComposite(id: String): Pair<Coupon?, Order?> {\n        val coupon = couponRepository.findByIdOrNull(id)\n        val order = orderRepository.findByIdOrNull(id.toLong())\n        Thread.sleep(2500) // 2.5초 대기\n        printHikariConnection()\n        return Pair(coupon, order)\n    }\n\n    private fun printHikariConnection() {\n        val targetDataSource = dataSource.unwrap(HikariDataSource::class.java)\n        val hikariDataSource = targetDataSource as HikariDataSource\n        val hikariPoolMXBean = hikariDataSource.hikariPoolMXBean\n        val hikariConfigMXBean = hikariDataSource.hikariConfigMXBean\n\n        val log = buildString {\n            append(\"totalConnections: ${hikariPoolMXBean.totalConnections}, \")\n            append(\"activeConnections: ${hikariPoolMXBean.activeConnections}, \")\n            append(\"idleConnections: ${hikariPoolMXBean.idleConnections}, \")\n            append(\"threadsAwaitingConnection: ${hikariPoolMXBean.threadsAwaitingConnection}\")\n        }\n        println(log)\n    }\n}\n\n\n위의 코드에서 /api/redis는 단순히 Redis에서 쿠폰 정보를 조회하는 API입니다. /api/mysql은 MySQL에서 주문 정보를 조회하는 API이며, /api/composite는 Redis 조회 후 MySQL 조회를 수행하고 2.5초 동안 대기한 후 응답을 반환하는 API입니다.\n특히 /api/composite는 Redis에서 쿠폰을 조회한 후 MySQL 조회를 수행하며, 이때 Thread.sleep(2500)으로 인해 2.5초 동안 대기하게 됩니다. 이 상황에서 Lettuce의 커넥션 풀이 어떻게 동작하는지 살펴볼 수 있습니다.\n시나리오별 Hikari와 Lettuce의 차이점\n이 섹션에서는 Hikari와 Lettuce의 동작 방식을 서로 비교하면서 각 시나리오에서 어떤 차이점이 발생하는지에 대해 구체적으로 살펴보겠습니다. 이를 통해 각 커넥션 풀이 어떤 차이점을 갖고 있는지 명확히 이해할 수 있습니다.\n시나리오: getComposite 호출 이후 getMySql 호출\nHikari 설정은 maximum-pool-size=1, minimum-idle=1로 구성되어 있으며, getComposite 호출 시 사용 가능한 단 하나의 커넥션을 사용하여 작업이 진행됩니다. 이번 테스트의 목적은 /api/composite 호출 이후 getMySql 호출의 응답 속도를 확인하는 것입니다. 만약 Hikari Connection Pool이 블로킹 방식으로 동작한다면 getComposite 호출 중 MySQL 조회 요청으로 점유된 커넥션이 반환되지 않아 getMySql 요청은 대기 상태에 놓이고 응답 시간이 지연될 것입니다. 반대로 MySQL 조회 요청이 빠르게 완료되거나, 추가적인 idle 커넥션이 있다면 getMySql 요청은 지연 없이 처리될 수 있습니다.\n이 상태에서 getMySql 호출을 시도하면, 사용 가능한 idle 커넥션이 없기 때문에 getComposite 호출이 끝난 후 반환된 커넥션을 사용해야 합니다. 이로 인해 threadsAwaitingConnection 상태에서 대기하게 되고, 지연이 발생합니다. 이후 threadsAwaitingConnection에서 대기하던 요청이 activeConnections로 전환되면, getMySql 호출에서 해당 커넥션을 사용할 수 있게 됩니다.\n테스트 결과\n\n/api/mysql 단독 호출 시:\n\n\n1\n2\n\n# Connection totalConnections: 1, activeConnections: 1, idleConnections: 0, threadsAwaitingConnection: 0\n# HTTP 응답 Response code: 200; Time: 24ms (24 ms); Content length: 64 bytes (64 B)\n\n\n\n/api/composite 호출 이후 바로 /api/mysql를 호출한 경우:\n\n\n1\n2\n\n# Connection totalConnections: 1, activeConnections: 1, idleConnections: 0, threadsAwaitingConnection: 1\n# HTTP 응답 Response code: 200; Time: 1112ms (1 s 112 ms); Content length: 64 bytes (64 B)\n\n\n\n테스트 결과, /api/composite 호출 이후 getMySql 요청은 대기 상태에 놓이며, MySQL 조회 작업이 완료되어 커넥션이 반환된 이후에 처리되는 것을 확인할 수 있었습니다. 이는 Hikari Connection Pool이 동기적이며, 사용 중인 커넥션이 반환될 때까지 대기 상태에 놓이는 블로킹 방식으로 동작하기 때문입니다.\n동작 흐름\n\nHikari Connection Pool의 동작 방식은 아래와 같습니다.\n\ngetComposite 호출: Service는 MySQL A 조회를 요청하고, 사용 가능한 idle 커넥션을 가져옵니다. 이 요청은 2,500ms가 소요되며, 해당 커넥션은 점유된 상태로 유지됩니다.\ngetMySql 호출: Controller는 Service로 getMySql 호출을 보냅니다. 그러나 MySQL A 조회 요청이 아직 진행 중이므로 사용 가능한 커넥션이 없습니다. 이에 따라 요청은 threadsAwaitingConnection 상태로 대기하게 됩니다.\nMySQL A 응답 반환: MySQL A 조회 요청이 완료되면서 커넥션이 반환됩니다. 반환된 커넥션은 대기 중이던 getMySql의 MySQL B 조회 요청에서 다시 사용됩니다.\nMySQL B 조회 요청 및 응답: 반환된 커넥션을 사용해 MySQL B 조회 요청이 처리됩니다. B 조회는 지연 없이 완료되며, 응답이 반환됩니다.\n최종 응답 반환: getComposite와 getMySql 요청이 순차적으로 완료되며, 최종적으로 각각의 결과가 Controller로 반환됩니다.\n\n블로킹 방식의 한계\n이 시나리오에서 Hikari Connection Pool의 블로킹 특성으로 인해 다음과 같은 한계가 발생합니다. MySQL A 조회 요청이 완료되기 전까지 커넥션이 반환되지 않아 getMySql 호출이 대기 상태에 놓이고, 동시 요청 수가 증가하면 threadsAwaitingConnection 상태가 늘어나면서 대기 시간이 길어질 가능성이 있습니다. 반면, Redis Lettuce 커넥션 풀은 이러한 상황에서 다르게 동작할 수 있습니다. Lettuce가 스레드를 블록시키는 방식으로 작동한다면 비슷한 지연 문제가 발생하지만, 논블로킹 방식이라면 MySQL의 지연과 관계없이 추가적인 Redis 요청에 빠르게 응답할 수 있습니다.\n시나리오: getComposite 호출 이후 getRedis 호출\nLettuce 설정은 max-active=1, max-idle=1, min-idle=1로 구성되어 있으며, getComposite 호출 시 사용 가능한 단 하나의 커넥션을 사용하여 작업이 진행됩니다. 이번 테스트의 목적은 /api/composite 호출 이후 getRedis 호출의 응답 속도를 확인하는 것입니다. 만약 Lettuce가 블록되는 방식으로 동작한다면 getComposite 호출 중 Redis 조회 요청으로 점유된 커넥션이 MySQL 작업이 끝날 때까지 반환되지 않아 getRedis 요청은 대기 상태에 놓이고 응답 시간이 지연될 것입니다. 반대로 Lettuce가 비동기적이며 블로킹되지 않는 방식으로 동작한다면 getComposite 호출 중에도 커넥션이 Redis 요청 응답 후 즉시 반환되므로, getRedis 요청이 지연 없이 처리될 것입니다.\n테스트 결과\n\n/api/composite 호출 이후 바로 /api/redis를 호출한 경우:\n\n\n1\n\nResponse code: 200; Time: 8ms (8 ms); Content length: 56 bytes (56 B)\n\n\n\n/api/redis 단독 호출 시:\n\n\n1\n\nResponse code: 200; Time: 6ms (6 ms); Content length: 56 bytes (56 B)\n\n\n\n테스트 결과, /api/composite 호출 중에도 /api/redis 요청은 지연 없이 빠르게 응답하는 것을 확인할 수 있었습니다. 이는 Lettuce가 비동기적으로 동작하며, 스레드를 블록하지 않음을 시사합니다.\n동작 흐름\n\n\ngetComposite 호출: Controller가 getComposite 요청을 보냅니다. Service는 먼저 Redis 조회를 수행하며, 이 작업은 10ms 만에 완료되고 커넥션은 즉시 반환됩니다. 이후 MySQL 조회를 시작하며, MySQL 조회 작업은 2,500ms가 소요됩니다.\ngetRedis 호출: MySQL 조회가 진행 중인 상태에서 Controller가 getRedis 요청을 보냅니다. Redis는 MySQL 작업과는 독립적으로 동작하므로, Redis 조회 요청은 지연 없이 처리됩니다. 반환된 Redis 커넥션이 즉시 재사용되어 getRedis 요청이 빠르게 완료됩니다.\ngetComposite 응답 반환: MySQL 작업이 완료되면 getComposite 응답이 반환됩니다.\ngetRedis 응답 반환: hRedis 조회 요청이 완료된 후 응답이 반환됩니다. Redis 작업이 MySQL 작업의 지연과 상관없이 즉시 처리되었기 때문에 빠른 응답 시간을 유지합니다.\n\n논블로킹의 장점\n테스트 결과를 통해 Lettuce가 비동기적이고 논블로킹 방식으로 동작한다는 것을 확인할 수 있었습니다. Redis 조회는 10ms 만에 응답을 완료하고 커넥션을 즉시 반환하므로, MySQL 작업이 진행 중이라도 Redis 커넥션이 점유된 상태로 남아있지 않습니다. 결과적으로, 추가적인 Redis 요청(getRedis)은 MySQL의 작업 지연과 관계없이 빠르게 처리됩니다.\n이는 MySQL의 Hikari Connection Pool이 스레드를 블록하여 대기 시간을 유발하는 방식과 대비됩니다. Hikari에서는 커넥션이 반환될 때까지 다른 요청이 대기 상태에 놓이지만, Lettuce는 커넥션 반환이 즉시 이루어져 이러한 지연 없이 요청을 처리할 수 있습니다.\nRedis의 비동기 I/O와 Lettuce의 설계가 결합되어 높은 동시성 환경에서도 안정적인 성능을 유지할 수 있음을 보여주는 사례라 할 수 있습니다. 이러한 특성은 Redis와 같이 빠른 응답성을 요구하는 환경에서 Lettuce가 얼마나 효율적인지를 잘 보여줍니다.\nHikari와 Lettuce의 차이점 정리\n\n동작 방식의 차이:\nHikari Connection Pool은 전통적인 동기식 동작을 기반으로 하며, 스레드 블로킹이 발생합니다. MySQL 같은 관계형 데이터베이스와 함께 사용하는 경우, 데이터 조회 시 커넥션이 점유된 상태로 유지되므로 다른 요청들은 사용 가능한 커넥션이 없어 대기하게 됩니다.\nRedis Lettuce Connection Pool은 비동기 및 넌블로킹 I/O를 지원하여, Redis 서버에서 응답을 받은 후에도 바로 커넥션을 반환할 수 있습니다. 이를 통해 커넥션 점유 시간이 짧아져 Redis에 대한 다른 요청들도 빠르게 처리될 수 있습니다.\n\n커넥션 풀의 활용도:\nHikari Connection Pool은 threadsAwaitingConnection을 관리하며, 커넥션 풀이 모두 사용 중일 경우 새 요청들은 대기하게 됩니다. 따라서 커넥션 풀 크기 설정이 성능에 큰 영향을 미칩니다.\nRedis Lettuce Connection Pool은 커넥션을 빠르게 반환하기 때문에, 커넥션 풀 크기를 크게 설정하지 않아도 효율적으로 동작할 수 있습니다. Redis의 비동기 처리 덕분에 서버의 응답이 빠르다면, 적은 수의 커넥션으로도 많은 요청을 처리할 수 있습니다.\n\n특정 상황에서의 블로킹 차이:\nHikari Connection Pool은 요청이 지연되면, 다른 커넥션이 점유되지 않는 한 대기 스레드가 계속 늘어날 수 있습니다. 이는 높은 동시성에서 성능 저하를 야기할 수 있습니다.\nRedis Lettuce는 비동기적이며, Redis 서버로부터 응답을 받은 후에는 커넥션을 빠르게 반환하므로, 서버 응답 시간이 Lettuce의 성능에 직접적인 영향을 미칩니다. 즉, Redis 명령어가 복잡하고 시간이 오래 걸리면(예: keys * 사용), 그 시간 동안 다른 요청들이 블록될 수 있습니다.\n\n블로킹/넌블로킹의 영향:\nHikari의 경우 스레드 블로킹이 빈번히 발생하는 반면, Lettuce는 넌블로킹으로 추가적인 스레드 리소스를 사용하지 않고도 더 많은 요청을 처리할 수 있는 장점이 있습니다.\n이는 특히 IO 작업이 많은 환경에서 Lettuce가 더 효율적으로 동작하도록 만듭니다. 반면, Hikari는 동기적 처리로 인해 CPU 자원을 더 많이 사용하게 되며, 이는 고비용의 대기 시간이 발생할 가능성을 증가시킵니다.\n\n\nLettuce Connection Pool 설정과 의미\nLettuce Connection Pool Properties\nSpring Data Redis에서는 application.yml 파일을 통해 Lettuce Connection Pool의 설정을 손쉽게 구성할 수 있습니다. 아래는 주요 프로퍼티와 그 설명입니다:\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\nspring:\n    redis:\n        lettuce:\n            pool:\n                max-active: 1\n                max-idle: 1\n                min-idle: 1\n                enabled: true\n                max-wait: 1000ms\n                time-between-eviction-runs: 1000ms\n\n\n\n설정 항목설명기본 값\n\nmax-activeConnection Pool에서 사용할 수 있는 최대 커넥션 수로, 동시 연결 수를 제한합니다.8\nmax-idleConnection Pool에서 유지할 수 있는 최대 유휴 커넥션 수입니다. 이 값을 초과하는 유휴 커넥션은 폐기됩니다.8\nmin-idleConnection Pool에서 유지할 최소 유휴 커넥션 수입니다. 유휴 커넥션이 부족하면 새 커넥션을 생성합니다.0\nenabledLettuce Connection Pool 사용 여부를 설정합니다. true로 설정 시 Pool이 활성화됩니다.false\nmax-wait커넥션이 사용 중일 때 새로운 요청이 대기할 수 있는 최대 시간입니다. 설정된 시간이 초과되면 예외가 발생합니다.-1 (무제한 대기)\ntime-between-eviction-runs유휴 커넥션 검사 및 제거 작업의 주기를 설정합니다. (단위: 밀리초)-1 (검사하지 않음)\n\n이러한 설정은 Lettuce Connection Pool의 동작을 세부적으로 제어하며, 애플리케이션의 요구 사항에 맞게 성능과 리소스 사용량을 조정할 수 있습니다. 특히, max-active, min-idle, max-wait와 같은 설정은 TPS가 높은 환경이나 트래픽 변동이 큰 상황에서 애플리케이션의 안정성을 보장하는 데 중요한 역할을 합니다.\nLettuce Connection Pool의 개수가 갖는 의미\nRedis Lettuce Connection은 비동기 방식으로 동작하며, 요청을 처리한 후 커넥션을 즉시 반환하는 구조를 가지고 있습니다. 이는 적은 수의 커넥션으로도 높은 효율을 발휘할 수 있다는 점에서 큰 장점입니다. 하지만, Hikari와 같은 전통적인 동기 커넥션 풀처럼 미리 커넥션을 확보하여 동시성을 처리하는 방식은 아니기 때문에, \"Lettuce Connection Pool의 개수가 많다고 해서 이점이 있을까?\"라는 의문을 가질 수 있습니다.\n사실, Lettuce Connection Pool의 개수는 TPS가 높아지고 Redis 서버의 응답이 느려질 때 중요한 의미를 가집니다. 다음은 Lettuce Connection Pool의 개수가 많을 때 가지는 이점을 설명합니다.\n\nRedis 응답 지연 시 동시 요청 처리 가능:\nRedis 서버가 응답을 지연하는 경우, 요청이 커넥션을 점유하는 시간이 길어집니다. 이때 Connection Pool의 크기가 작다면 모든 커넥션이 점유된 상태에서 새로운 요청이 대기 상태로 전환될 가능성이 높습니다. 하지만 Connection Pool 크기가 충분히 크다면, 지연된 요청과 별개로 다른 요청을 처리할 여유를 확보할 수 있습니다. 이는 TPS가 몰리는 상황에서도 전체 시스템의 성능 저하를 방지합니다.\n\nBurst 트래픽에서의 안정성 확보:\n트래픽이 순간적으로 폭증하는 경우, Pool 크기가 충분히 크면 새로운 요청을 대기시키지 않고 처리할 수 있습니다. 이는 특히 Redis 응답 시간이 일관되지 않은 상황에서 더욱 중요한데, Pool 크기가 충분하지 않으면 요청 처리 시간이 예측 불가능하게 증가할 수 있습니다.\n\n멀티 인스턴스 활용 가능성:\nRedis는 싱글 스레드로 동작하지만, 애플리케이션 인스턴스가 여러 개일 경우 각 인스턴스에서 동시에 Redis에 접근합니다. Pool 크기가 충분히 크다면, 여러 인스턴스가 Redis와 병렬로 통신하면서도 효율적으로 커넥션을 재사용할 수 있습니다.\n\n비동기 요청 처리 속도 향상:\nLettuce는 비동기적으로 여러 요청을 처리할 수 있지만, Pool 크기가 제한적이라면 커넥션 재사용의 병목이 발생할 수 있습니다. Pool 크기를 늘리면 이러한 병목을 완화하고, Redis 서버의 응답 속도에 따라 더 많은 요청을 처리할 수 있습니다.\n\n장시간 실행되는 명령어의 영향 완화:\n일부 Redis 명령어(예: zrange, keys)는 실행 시간이 길어질 수 있습니다. Pool 크기가 작다면 이런 명령이 다른 요청 처리에 직접적인 영향을 미치지만, 충분한 Pool 크기는 이런 상황에서도 다른 요청을 지연 없이 처리할 수 있도록 합니다.\n\nLettuce Connection Pool의 개수는 TPS와 Redis 서버의 응답 지연이 증가하는 상황에서 중요한 역할을 합니다. 비록 Lettuce가 비동기적이고 효율적인 구조를 가졌더라도, Pool 크기를 적절히 설정하지 않으면 요청 대기가 발생할 수 있습니다.\n따라서 Lettuce Connection Pool의 개수는 단순히 많은 요청을 처리하기 위한 것이 아니라, Redis 서버 응답 시간의 변동성, Burst 트래픽, 그리고 장시간 실행되는 명령어 처리와 같은 다양한 상황에 대비하기 위한 안정성을 제공한다고 볼 수 있습니다. Connection Pool 크기를 TPS와 트래픽 패턴에 맞게 조정하는 것이 Lettuce의 효율성을 극대화하는 핵심 전략입니다.\n결론\n논블로킹 방식이 항상 절대적으로 좋은 것은 아닙니다. Redis Lettuce와 Hikari Connection Pool은 서로 다른 특성과 장점을 가지고 있으며, 각 환경에 따라 적절히 선택해야 합니다.\nLettuce의 경우, Redis 서버로부터 응답을 받으면 커넥션을 즉시 반환하고 다음 요청을 처리할 준비를 합니다. 이는 커넥션 점유 시간이 짧아져 더 작은 풀 크기로 효율적인 요청 처리가 가능하다는 큰 장점이 있습니다. 하지만 Redis 서버 자체가 응답을 지연한다면, 다른 요청이 대기 상태에 놓이게 되어 성능 저하로 이어질 수 있습니다. 이러한 상황에서는 Lettuce의 비동기적 특성이 한계를 보일 수 있습니다.\n반면, Hikari Connection Pool은 유휴 커넥션이 있는 경우 한 요청이 오래 걸리더라도 다른 커넥션을 사용하여 추가적인 요청을 처리할 수 있습니다. 이는 Redis와 같은 싱글 스레드 구조가 아닌, 다중 커넥션을 사용하는 데이터베이스 환경에 잘 맞는 전략입니다. 그러나 Hikari는 요청 중 커넥션이 블록되는 방식으로 동작하기 때문에, 풀 크기가 제한적이거나 동시 요청이 많아지면 대기 시간이 길어질 가능성이 있습니다.\n이러한 차이는 Redis가 싱글 스레드로 모든 요청을 처리하도록 설계된 서버라는 점에서 기인합니다. Lettuce는 Redis 서버의 메커니즘과 잘 맞는 전략을 선택하여 구현되었으며, 비동기와 논블로킹을 통해 Redis의 성능 특성을 최대한 활용합니다. 이는 Hikari Connection Pool과는 다른 접근 방식으로, Redis 서버와의 높은 호환성을 유지하며 효율적인 자원 관리를 가능하게 합니다.\n소프트웨어 개발에서는 항상 트레이드오프가 존재합니다. 특정 기술이 모든 상황에서 우월하다고 말할 수는 없습니다. Lettuce와 Hikari의 차이는 각기 다른 환경에 적합한 도구를 제공하며, 사용자는 자신의 애플리케이션 요구사항에 따라 적합한 전략을 선택해야 합니다. 결국, 어떤 도구가 \"좋다\"라고 단정짓기보다는, 각 기술의 장단점을 이해하고 상황에 맞게 활용하는 것이 중요합니다.",
        "summary": "\n    \n      \n      \n        <p>Redis는 싱글 스레드로 동작하는 인메모리 데이터베이스로, 모든 요청을 순차적으로 처리합니다. 이러한 특성 때문에 많은 개발자들은 Redis 클라이언트인 Lettuce에서 제공하는 <strong>커넥션 풀의 필요성과 이점</strong>에 대해\n      \n    \n    ",
        "id": "https://cheese10yun.github.io/redis-lettuce-connection/",
        "isoDate": "2024-11-17T07:13:12.000Z"
      }
    ]
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김상훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": [
      {
        "title": "나의 세번쨰 컴퓨터",
        "link": "https://elky84.github.io/2024/11/24/my_third_computer/",
        "pubDate": "Sun, 24 Nov 2024 00:00:00 +0000",
        "content": "<p>MMX166은 금새 느려졌다.</p>\n\n<p>게임은 계속 발전했고, 두루넷 개통으로 드디어 상시 인터넷을 쓸 수 있게 됐지만 내 컴퓨터는 너무 느렸다.</p>\n\n<p>2000년 드디어 세번째 컴퓨터를 맞추게 되었는데 셀러론 III 700MHz 에 <a href=\"https://ko.wikipedia.org/wiki/S3_%EC%84%B8%EB%B9%84%EC%A7%80\">S3 세비지 - 위키백과, 우리 모두의 백과사전</a> 중에서 Savage 4였는데, AMD Radeon의 분전과  사실상 독점인 nVidia이 대표적 그래픽 카드인 지금과 달리 당시만해도 다양한 회사의 그래픽 카드가 존재했는데, 마이너한 그래픽 카드보니 호환성 이슈로 많은 3D 게임에서 깨짐 현상의 슬픔을 함께한 컴퓨터였다. 당시 조립 PC 업체에서 예산에 맞춰 적당한 컴퓨터를 구매했는데, 이 때의 충격으로 하드웨어 공부를 시작한 계기가 되기도 했다.</p>\n\n<p>특히 당시 나는 리니지를 아주 열심히 했었는데, 로딩도 길고 종종 멈추다보니 의문사가 많아졌고 이를 바탕으로 누나들을 설득해 리니지 아이템을 판 돈이 컴퓨터 구입 자금이 되었다.</p>\n\n<blockquote>\n  <p>대학 신입생 때도 방학 때 다른 알바가 아닌 짧은 방학 기간에 짬짬이 리니지 아이템 판 돈으로 용돈과 학비 일부를 충당했었다.\n어지간한 알바보다 수익이 좋아서 알바 대신 하게 된 것인데, 지금의 리니지와 다르게 당시의 리니지는 돈을 벌 수 있는 게임이었다.</p>\n</blockquote>\n\n<p>수익은 좋았지만 리니지를 하면서 오는 현타가 었다보니 이 컴퓨터를 가지고 다른 것들을 많이 했는데, 에뮬레이터 사이트를 만들거나, 개발 관련 홈페이지, 게임 팬 페이지를 만들곤 했다.</p>\n\n<p>완성도가 만족스러운 퀄리티는 아니였지만 프로그래밍을 배운 목적이 그러했듯 여러 공모전 제출 용도로 게임을 만든 시기기도 하다.</p>\n\n<hr />\n\n<p>2000년대 초는 에뮬레이터가 급격히 발전한 시기기도 했다.</p>\n\n<p>물론 90년대 후반부터 에뮬레이터가 대중화 되긴 했지만, 2000년대 초반은 플레이스테이션 에뮬레이터 Bleem 등의 논란, CPS를 지원했던 Callus, CPS2 복호화를 통한 finalburn, MAME의 발전, 닌텐도 64 (UltraHLE부터 시작되어 Project 64 등), 네오지오 등이 그리 오래 되지 않은 현세대기거나 아주 비싼 롬팩을 사야하거나, 기판 세팅을 해야 되는 어려움을 겪던 게임기를 손쉽게 즐길 수 있게 됐던 시기기도 하다.</p>\n\n<p>이를 통해 구경만 했던 닌텐도 64의 슈퍼 마리오 64를 플레이하게 됐는데, 3차원이 제대로 느껴지는 충격을 가져다 준 첫 게임이었다랄까?</p>\n\n<p>또한 2D에서도 엄청난 수준의 레벨 디자인을 보여줬던 마리오가, 제한된 스테이지 구성을 지루하지 않게 만들어주는 별 모으기 기반의 반복 플레이가 지루하지 않게 너무나도 잘 만들어서, 아주 오랜 시간 즐기게 됐다.</p>\n\n<p>그리고 그 이후 패미컴이나 슈퍼 패미컴, MAME 에뮬레이터 게임을 다수 즐겼다.</p>\n\n<p>아이러니 하게도 이 시기에 게임도 많이 했음에도, 프로그래밍 경험도 많이 늘게 됐는데, 주로 재밌게 즐긴 게임의 클론 게임을 만들어 보는 방식으로 실습을 이어나가는 것이 유의미하게 작용했었다.</p>\n\n<p>고전 게임이지만 퀄리티는 상당했던 게임이 많다보니, 클론 게임이라지만 그 게임의 모든 요소를 따라한다기 보다는 몇가지 로직을 구현한다거나, 프로토타이핑 수준에 가까웠고, 어떠한 시스템을 이렇게 구현했을까 하는 자의적 해석이 곁들여진 역설계에 가깝긴 했지만, 이 경험이 이후 게임 개발자로서의 삶에 긍정적인 영향을 주었다.</p>\n\n<hr />\n\n<p>당시 재밌게 즐긴 PC 게임들도 참 많다. 모두 언급하긴 어렵지만</p>\n\n<h2 id=\"문명-3\">문명 3</h2>\n\n<p><a href=\"https://www.youtube.com/watch?v=3KVSCwQASbM\">[옛날PC] 문명3 컴플리트 (Sid Meier’s Civilization 3 Complete)</a></p>\n<ul>\n  <li>당시에 용산을 자주 갔는데, 틴 케이스에 들어있던 버전을 샀었다</li>\n  <li>문명 1, 2를 안해보고 3로 입문했는데….</li>\n</ul>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/3KVSCwQASbM?wmode=opaque\" frameborder=\"0\" allowfullscreen=\"\"></iframe>\n\n<h2 id=\"악튜러스\">악튜러스</h2>\n\n<p><a href=\"https://www.youtube.com/watch?v=ngMxhN6pWfg&amp;list=PLzRx55cOIP4sC8tqMf946_OsloGDo-_WP\">[악튜러스_타임어택] 악튜러스 스피드런 2시간4분 (사용가능한 모든 버그 활용)</a></p>\n<ul>\n  <li>여러 역사에 의해 소프트맥스보다는 손노리파였다보니까 구입하게 됐다</li>\n  <li>초판, 재판 둘다 구매 했었는데 2D 스프라이트 + 3D 배경이라는 조합이 실제 체감으로도 나쁘지 않아서 지금도 종종 고전 게임 플레이 하는 분들이 자주 선택하는 게임</li>\n</ul>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ngMxhN6pWfg?wmode=opaque\" frameborder=\"0\" allowfullscreen=\"\"></iframe>\n\n<h2 id=\"히어로즈-오브-마이트-앤-매직-3\">히어로즈 오브 마이트 앤 매직 3</h2>\n\n<p><a href=\"https://www.youtube.com/watch?v=FW3ULCBOV2w\">우리의 주말을 삭제했던 악마의 게임 - 히어로즈 오브 마이트 앤 매직 3</a></p>\n<ul>\n  <li>1편부터 조금씩 했고, 2편도 친구 집에서 꽤 길게 했으나 3편이야 말로 그 정수 같은 게임이었다.</li>\n  <li>쉐도우 오브 데스는 지금도 팬들 사이에서 화자 될만한 명작인데 나 역시 쉐도우 오브 데스와 같은 재미는 이 시리즈에서 다시 못만날줄은 몰랐다.</li>\n</ul>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/FW3ULCBOV2w?wmode=opaque\" frameborder=\"0\" allowfullscreen=\"\"></iframe>\n\n<h2 id=\"챔피언-쉽-매니저-2002-k리그\">챔피언 쉽 매니저 2002 K리그</h2>\n\n<p><a href=\"https://www.youtube.com/watch?v=R6fnjdEDmXk\">Championship Manager 01/02 - Youth Team Premier League! - 1</a></p>\n<ul>\n  <li>영상은 CM01/02인데, 나는 정발됐던 CM2002 K리그 버전으로 입문했다.</li>\n  <li>월드컵의 영향을 받아 즐기게 됐었는데, 이외에도 피파 03, 피파 월드컵 2002도 즐기면서 축구를 좋아하게 됐기 이후의 CM버전이나 FM도 열심히 즐기게 됐다.</li>\n</ul>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/R6fnjdEDmXk?wmode=opaque\" frameborder=\"0\" allowfullscreen=\"\"></iframe>\n\n<h2 id=\"워크래프트-3\">워크래프트 3</h2>\n\n<p><a href=\"https://www.youtube.com/watch?v=MKgREM7JO8w\">[War3]야인시대특별판 완전공략</a></p>\n<ul>\n  <li>재밌긴했는데 게임 템포가 길고, 운영이 너무 중요한 게임 스타일이 어려움을 느끼게 됐었다.</li>\n  <li>야인시대 드라마가 워낙 인기일 때라 야인시대, DOTA, 타워 디펜스 등의 MOD도 많이 즐겼다</li>\n</ul>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/MKgREM7JO8w?wmode=opaque\" frameborder=\"0\" allowfullscreen=\"\"></iframe>\n\n<h2 id=\"디아블로-2\">디아블로 2</h2>\n\n<p><a href=\"https://www.youtube.com/watch?v=0nCWJW1s5Jw\">디아블로2클래식 궁금하시죠? 이렇습니다 【디아블로2클래식 Diablo2classic】 - YouTube</a></p>\n<ul>\n  <li>디아블로 2의 국템 시절부터 짬짬이 즐겼는데, 하도 서버 이슈도 많고 복사 이슈도 많고 해서 카우방 돌면서 노는 재미로 했었다.</li>\n</ul>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/0nCWJW1s5Jw?wmode=opaque\" frameborder=\"0\" allowfullscreen=\"\"></iframe>\n\n<h2 id=\"퀘이크-3-아레나\">퀘이크 3 아레나</h2>\n\n<p><a href=\"https://www.youtube.com/watch?v=Jse88q0k_28\">퀘이크 3 : 아레나 - 퀘이크 1 리마스터 기념으로 오래간만에 돌려봤습니다.</a></p>\n<ul>\n  <li>사실 98년도부터 PC방에서 많이 즐겼던 게임인데, 당시 컴퓨터로는 잘 안돌아갔다보니 새로 산 컴퓨터에서 종종 즐겼다.</li>\n  <li>퀘이크3는 워낙 넷플 방식도 다양하게 즐길 수 있다보니까, 하이퍼 슈팅 게임 답게 가볍게 즐기기 좋았다.</li>\n</ul>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Jse88q0k_28?wmode=opaque\" frameborder=\"0\" allowfullscreen=\"\"></iframe>\n\n<hr />\n\n<p>에뮬레이터 이야기를 조금 더 하자면, 2001년 즈음 당시의 화두는 CPS2 에뮬레이터였다.</p>\n\n<p>CPS2가 뭐냐면, 캡콤의 아케이드 시스템으로써 오락실용 기판이라고 봐도 무방하겠다.</p>\n\n<p>이름이 2인 만큼 CPS1도 존재했는데, CPS1은 Callus와 같은 에뮬레이터를 통해 이미 널리 퍼진 상태였으나, CPS2의 경우 강력한 암호화/복호화 체계로 에뮬레이션 되지 않고 있었다.</p>\n\n<p>자살 배터리로 유명한 이 방식은, 게임 데이터를 복호화 하기 위한 키를 배터리에 심어두었고, 배터리가 방전되면 게임 실행이 불가능해져 캡콤에 보내 복원 받아야만 하는 구조였다.</p>\n\n<table>\n  <tbody>\n    <tr>\n      <td>[How Capcom’s clever CPS2 Arcade Game Copy Protection stopped bootleg games</td>\n      <td>MVG](https://www.youtube.com/watch?v=vCtXZM8iG-o)</td>\n    </tr>\n  </tbody>\n</table>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/vCtXZM8iG-o?wmode=opaque\" frameborder=\"0\" allowfullscreen=\"\"></iframe>\n\n<p><a href=\"https://arcadehacker.blogspot.com/2017/03/a-journey-into-capcoms-cps2-silicon.html\">Arcade Hacker: A Journey Into Capcom’s CPS2 Silicon - Part 1</a></p>\n\n<p>이로 인해 당시 컴퓨터 사양으로 충분히 에뮬레이션 가능했고, 대중화 되었던 CPS2, 네오지오 등과 달리 복호화가 불가능해 쓸모 없는 롬 파일만 돌아다닐 뿐이었는데, 보안 취약점으로 암호화 되지 않은 롬 덤프에 성공하게 되고, CPS1가 유사한 점이 많은 CPS2 에뮬레이터는 금새 완성도가 높아져, FInalBurn, Kawaks 등의 에뮬레이터를 통해 플레이 가능해지게 됐었다.</p>\n\n<p>당시만 해도 PS1이 현역 기기였는데, 이를 에뮬레이터 관련 소송과 단속이 시작되면서, 자연스레 에뮬레이터 사이트들은 음지로 사라지거나, 고전 게임이라는 카테고리로 묶어서 현세대기가 아닌 게임 위주로 공유되는 분위기로 바뀌기 시작했다.</p>\n\n<hr />\n\n<p>에뮬레이터 이야기를 많이 했는데, 당시 내가 워낙 마이너한 그래픽 카드를 썼다보니, 패키지 게임에 비해서 에뮬레이터에서의 호환성은 극악이었다.</p>\n\n<p>이때를 계기로 그래픽 카드, CPU, 램 등 하드웨어에 익숙해지고 공부하게 되는 계기가 되었는데 이 부분이 추후 개발자로 일하면서도 도움이 되었으니 아이러니 한 일이 아닐 수 없다.</p>\n\n<p>종종 겜덕, 컴덕이 프로그래머로 전직하게 되는데 나도 그런 케이스라고도 볼 수 있을 거 같다.</p>\n",
        "contentSnippet": "MMX166은 금새 느려졌다.\n게임은 계속 발전했고, 두루넷 개통으로 드디어 상시 인터넷을 쓸 수 있게 됐지만 내 컴퓨터는 너무 느렸다.\n2000년 드디어 세번째 컴퓨터를 맞추게 되었는데 셀러론 III 700MHz 에 S3 세비지 - 위키백과, 우리 모두의 백과사전 중에서 Savage 4였는데, AMD Radeon의 분전과  사실상 독점인 nVidia이 대표적 그래픽 카드인 지금과 달리 당시만해도 다양한 회사의 그래픽 카드가 존재했는데, 마이너한 그래픽 카드보니 호환성 이슈로 많은 3D 게임에서 깨짐 현상의 슬픔을 함께한 컴퓨터였다. 당시 조립 PC 업체에서 예산에 맞춰 적당한 컴퓨터를 구매했는데, 이 때의 충격으로 하드웨어 공부를 시작한 계기가 되기도 했다.\n특히 당시 나는 리니지를 아주 열심히 했었는데, 로딩도 길고 종종 멈추다보니 의문사가 많아졌고 이를 바탕으로 누나들을 설득해 리니지 아이템을 판 돈이 컴퓨터 구입 자금이 되었다.\n대학 신입생 때도 방학 때 다른 알바가 아닌 짧은 방학 기간에 짬짬이 리니지 아이템 판 돈으로 용돈과 학비 일부를 충당했었다.\n어지간한 알바보다 수익이 좋아서 알바 대신 하게 된 것인데, 지금의 리니지와 다르게 당시의 리니지는 돈을 벌 수 있는 게임이었다.\n수익은 좋았지만 리니지를 하면서 오는 현타가 었다보니 이 컴퓨터를 가지고 다른 것들을 많이 했는데, 에뮬레이터 사이트를 만들거나, 개발 관련 홈페이지, 게임 팬 페이지를 만들곤 했다.\n완성도가 만족스러운 퀄리티는 아니였지만 프로그래밍을 배운 목적이 그러했듯 여러 공모전 제출 용도로 게임을 만든 시기기도 하다.\n2000년대 초는 에뮬레이터가 급격히 발전한 시기기도 했다.\n물론 90년대 후반부터 에뮬레이터가 대중화 되긴 했지만, 2000년대 초반은 플레이스테이션 에뮬레이터 Bleem 등의 논란, CPS를 지원했던 Callus, CPS2 복호화를 통한 finalburn, MAME의 발전, 닌텐도 64 (UltraHLE부터 시작되어 Project 64 등), 네오지오 등이 그리 오래 되지 않은 현세대기거나 아주 비싼 롬팩을 사야하거나, 기판 세팅을 해야 되는 어려움을 겪던 게임기를 손쉽게 즐길 수 있게 됐던 시기기도 하다.\n이를 통해 구경만 했던 닌텐도 64의 슈퍼 마리오 64를 플레이하게 됐는데, 3차원이 제대로 느껴지는 충격을 가져다 준 첫 게임이었다랄까?\n또한 2D에서도 엄청난 수준의 레벨 디자인을 보여줬던 마리오가, 제한된 스테이지 구성을 지루하지 않게 만들어주는 별 모으기 기반의 반복 플레이가 지루하지 않게 너무나도 잘 만들어서, 아주 오랜 시간 즐기게 됐다.\n그리고 그 이후 패미컴이나 슈퍼 패미컴, MAME 에뮬레이터 게임을 다수 즐겼다.\n아이러니 하게도 이 시기에 게임도 많이 했음에도, 프로그래밍 경험도 많이 늘게 됐는데, 주로 재밌게 즐긴 게임의 클론 게임을 만들어 보는 방식으로 실습을 이어나가는 것이 유의미하게 작용했었다.\n고전 게임이지만 퀄리티는 상당했던 게임이 많다보니, 클론 게임이라지만 그 게임의 모든 요소를 따라한다기 보다는 몇가지 로직을 구현한다거나, 프로토타이핑 수준에 가까웠고, 어떠한 시스템을 이렇게 구현했을까 하는 자의적 해석이 곁들여진 역설계에 가깝긴 했지만, 이 경험이 이후 게임 개발자로서의 삶에 긍정적인 영향을 주었다.\n당시 재밌게 즐긴 PC 게임들도 참 많다. 모두 언급하긴 어렵지만\n문명 3\n[옛날PC] 문명3 컴플리트 (Sid Meier’s Civilization 3 Complete)\n당시에 용산을 자주 갔는데, 틴 케이스에 들어있던 버전을 샀었다\n문명 1, 2를 안해보고 3로 입문했는데….\n\n\n악튜러스\n[악튜러스_타임어택] 악튜러스 스피드런 2시간4분 (사용가능한 모든 버그 활용)\n여러 역사에 의해 소프트맥스보다는 손노리파였다보니까 구입하게 됐다\n초판, 재판 둘다 구매 했었는데 2D 스프라이트 + 3D 배경이라는 조합이 실제 체감으로도 나쁘지 않아서 지금도 종종 고전 게임 플레이 하는 분들이 자주 선택하는 게임\n\n\n히어로즈 오브 마이트 앤 매직 3\n우리의 주말을 삭제했던 악마의 게임 - 히어로즈 오브 마이트 앤 매직 3\n1편부터 조금씩 했고, 2편도 친구 집에서 꽤 길게 했으나 3편이야 말로 그 정수 같은 게임이었다.\n쉐도우 오브 데스는 지금도 팬들 사이에서 화자 될만한 명작인데 나 역시 쉐도우 오브 데스와 같은 재미는 이 시리즈에서 다시 못만날줄은 몰랐다.\n\n\n챔피언 쉽 매니저 2002 K리그\nChampionship Manager 01/02 - Youth Team Premier League! - 1\n영상은 CM01/02인데, 나는 정발됐던 CM2002 K리그 버전으로 입문했다.\n월드컵의 영향을 받아 즐기게 됐었는데, 이외에도 피파 03, 피파 월드컵 2002도 즐기면서 축구를 좋아하게 됐기 이후의 CM버전이나 FM도 열심히 즐기게 됐다.\n\n\n워크래프트 3\n[War3]야인시대특별판 완전공략\n재밌긴했는데 게임 템포가 길고, 운영이 너무 중요한 게임 스타일이 어려움을 느끼게 됐었다.\n야인시대 드라마가 워낙 인기일 때라 야인시대, DOTA, 타워 디펜스 등의 MOD도 많이 즐겼다\n\n\n디아블로 2\n디아블로2클래식 궁금하시죠? 이렇습니다 【디아블로2클래식 Diablo2classic】 - YouTube\n디아블로 2의 국템 시절부터 짬짬이 즐겼는데, 하도 서버 이슈도 많고 복사 이슈도 많고 해서 카우방 돌면서 노는 재미로 했었다.\n\n\n퀘이크 3 아레나\n퀘이크 3 : 아레나 - 퀘이크 1 리마스터 기념으로 오래간만에 돌려봤습니다.\n사실 98년도부터 PC방에서 많이 즐겼던 게임인데, 당시 컴퓨터로는 잘 안돌아갔다보니 새로 산 컴퓨터에서 종종 즐겼다.\n퀘이크3는 워낙 넷플 방식도 다양하게 즐길 수 있다보니까, 하이퍼 슈팅 게임 답게 가볍게 즐기기 좋았다.\n\n\n\n\n에뮬레이터 이야기를 조금 더 하자면, 2001년 즈음 당시의 화두는 CPS2 에뮬레이터였다.\nCPS2가 뭐냐면, 캡콤의 아케이드 시스템으로써 오락실용 기판이라고 봐도 무방하겠다.\n이름이 2인 만큼 CPS1도 존재했는데, CPS1은 Callus와 같은 에뮬레이터를 통해 이미 널리 퍼진 상태였으나, CPS2의 경우 강력한 암호화/복호화 체계로 에뮬레이션 되지 않고 있었다.\n자살 배터리로 유명한 이 방식은, 게임 데이터를 복호화 하기 위한 키를 배터리에 심어두었고, 배터리가 방전되면 게임 실행이 불가능해져 캡콤에 보내 복원 받아야만 하는 구조였다.\n[How Capcom’s clever CPS2 Arcade Game Copy Protection stopped bootleg games\n      MVG](https://www.youtube.com/watch?v=vCtXZM8iG-o)\n    \n\n\nArcade Hacker: A Journey Into Capcom’s CPS2 Silicon - Part 1\n이로 인해 당시 컴퓨터 사양으로 충분히 에뮬레이션 가능했고, 대중화 되었던 CPS2, 네오지오 등과 달리 복호화가 불가능해 쓸모 없는 롬 파일만 돌아다닐 뿐이었는데, 보안 취약점으로 암호화 되지 않은 롬 덤프에 성공하게 되고, CPS1가 유사한 점이 많은 CPS2 에뮬레이터는 금새 완성도가 높아져, FInalBurn, Kawaks 등의 에뮬레이터를 통해 플레이 가능해지게 됐었다.\n당시만 해도 PS1이 현역 기기였는데, 이를 에뮬레이터 관련 소송과 단속이 시작되면서, 자연스레 에뮬레이터 사이트들은 음지로 사라지거나, 고전 게임이라는 카테고리로 묶어서 현세대기가 아닌 게임 위주로 공유되는 분위기로 바뀌기 시작했다.\n에뮬레이터 이야기를 많이 했는데, 당시 내가 워낙 마이너한 그래픽 카드를 썼다보니, 패키지 게임에 비해서 에뮬레이터에서의 호환성은 극악이었다.\n이때를 계기로 그래픽 카드, CPU, 램 등 하드웨어에 익숙해지고 공부하게 되는 계기가 되었는데 이 부분이 추후 개발자로 일하면서도 도움이 되었으니 아이러니 한 일이 아닐 수 없다.\n종종 겜덕, 컴덕이 프로그래머로 전직하게 되는데 나도 그런 케이스라고도 볼 수 있을 거 같다.",
        "guid": "https://elky84.github.io/2024/11/24/my_third_computer/",
        "categories": [
          "1997년",
          "추억"
        ],
        "isoDate": "2024-11-24T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": [
      {
        "title": "Kotlin Coroutines Flow의 Cold/Hot flow(Stream)의 데이터 흐름(Data flow) 이해해 보기",
        "link": "https://thdev.tech/dataflow/2024/11/23/Flow-Data-flow/",
        "pubDate": "Sat, 23 Nov 2024 00:00:00 +0000",
        "content": "<p>이전 글에서 <a href=\"https://thdev.tech/dataflow/2024/11/09/Data-flow/\">데이터 흐름(Data flow)을 이해해 보는 데 있어 필요한 것은? 짝퉁 개발자처럼 논하기</a>란 주제로 글을 작성했다.</p>\n\n<p>이번 글에서는 이 글에 나온 내용 중 Coroutines Flow에 대한 데이터 흐름을 이해하기 위한 글을 작성해 보았다.</p>\n\n<h3>이 글에서는</h3>\n<ul>\n  <li>Coroutines Flow</li>\n  <li>지속적인 흐름</li>\n  <li>Cold/Hot stream</li>\n  <li>ReactiveX에서 제공하는 subject에 대해서 이해하기</li>\n</ul>\n\n<!--more-->\n\n<h2>Coroutines Flow</h2>\n\n<p><a href=\"https://kotlinlang.org/docs/flow.html\">Asynchronous Flow - link</a>는 공식 문서에 나온 설명을 그대로 가져왔다.</p>\n\n<blockquote>\n  <p>A suspending function asynchronously returns a single value, but how can we return multiple asynchronously computed values? This is where Kotlin Flows come in.</p>\n</blockquote>\n\n<p>supend 함수는 비동기적인 값을 불러올 순 있지만 지속적인 값의 흐름을 가지지는 않는다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">suspend</span> <span class=\"k\">fun</span> <span class=\"nf\">featchData</span><span class=\"p\">()</span> <span class=\"p\">=</span> <span class=\"cm\">/* 생략 */</span>\n\n<span class=\"k\">fun</span> <span class=\"nf\">main</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"nf\">featchData</span><span class=\"p\">())</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>이런 흐름은 사실 누구나 이해하기 쉽다. main 함수에서 featchData()를 호출하면 응답이 딱 1번 온다는 것이다.</p>\n\n<p>그럼 이를 2회로 반복하면? main 함수에 한 줄 더 추가하거나, (0..1).forEach {}처럼 자동화할 수 있다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">suspend</span> <span class=\"k\">fun</span> <span class=\"nf\">featchData</span><span class=\"p\">()</span> <span class=\"p\">=</span> <span class=\"cm\">/* 생략 */</span>\n\n<span class=\"k\">fun</span> <span class=\"nf\">main</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"nf\">featchData</span><span class=\"p\">())</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"nf\">featchData</span><span class=\"p\">())</span> <span class=\"c1\">// 1회 더 추가</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p><br /></p>\n\n<h2>지속적인 흐름</h2>\n\n<p>flow를 통한 지속적인 흐름을 만든다는 것은 아래와 같다.</p>\n\n<ul>\n  <li>함수를 호출한다.</li>\n  <li>Flow<T>로 생성한 객체를 리턴 받는다.</T></li>\n  <li>구독(collect) 한다.\n    <ul>\n      <li>collect()을 하기 전에도 새로운 데이터 흐름이 있다.</li>\n      <li>collect()을 해야만 새로운 데이터 흐름이 시작한다.</li>\n    </ul>\n  </li>\n</ul>\n\n<p>flow를 활용하는 방식에서의 지속적인 흐름은 이와 같다.</p>\n\n<p>이를 아무나 이해할 수 있는 내용이 뭐가 있을까?</p>\n\n<ul>\n  <li>collect() 하기 전에도 새로운 데이터 흐름이 있다.\n    <ul>\n      <li>물은 흐른다.</li>\n      <li>스트리밍 서비스를 월 결제한다.</li>\n    </ul>\n  </li>\n  <li>collect() 해야 만 새로운 데이터 흐름이 시작된다.\n    <ul>\n      <li>커피를 주문한다.</li>\n      <li>음식을 주문한다.</li>\n    </ul>\n  </li>\n</ul>\n\n<p>위의 예들이 맞을 수도 있고, 엄밀히 따지면 적합한 예가 아닐 수 있지만 대략 구분해 보면 이와 같을 수 있다.</p>\n\n<p>결국 이미 있는 걸 필요할 때만 받아쓴다로 표현할 수 있는 것을 HotFlow(HotStream)으로 칭하고, 새로운 줌의 발생으로 만들기 시작한다는 ColdFlow(ColdStream)으로 칭한다.</p>\n\n<p><br /></p>\n\n<h2>ColdFlow</h2>\n\n<p>ColdFlow인 flow {}에 대한 코드가 아래와 같다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kd\">val</span> <span class=\"py\">flow</span> <span class=\"p\">=</span> <span class=\"nf\">flow</span> <span class=\"p\">{</span>\n    <span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"o\">..</span><span class=\"mi\">6</span><span class=\"p\">).</span><span class=\"nf\">forEach</span> <span class=\"p\">{</span>\n        <span class=\"nf\">emit</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">)</span>\n        <span class=\"nf\">delay</span><span class=\"p\">(</span><span class=\"mi\">1_000L</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"c1\">// collect 1</span>\n<span class=\"n\">flow</span>\n    <span class=\"p\">.</span><span class=\"nf\">onEach</span> <span class=\"p\">{</span> <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">launchIn</span><span class=\"p\">(</span><span class=\"n\">viewModelScope</span><span class=\"p\">)</span>\n\n<span class=\"nf\">delay</span><span class=\"p\">(</span><span class=\"mi\">2_000L</span><span class=\"p\">)</span> <span class=\"c1\">// 2초 후 구독</span>\n\n<span class=\"c1\">// collect 2</span>\n<span class=\"n\">flow</span>\n    <span class=\"p\">.</span><span class=\"nf\">onEach</span> <span class=\"p\">{</span> <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">launchIn</span><span class=\"p\">(</span><span class=\"n\">viewModelScope</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>이에 대한 출력 결과는 아래와 같다.</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">1(new), 2, 1(new), 3, 2, 4, 3, 5, 4, 6, 5, 6</code></p>\n\n<p>각각을 보면 1-6까지 정상 출력함을 알 수 있다.</p>\n\n<p>이를 그림으로 표현하면 아래와 같다.</p>\n\n<p><img src=\"/images/posts/2024/Flow-Data-flow/sample_01.png\" alt=\"sample_01\" /></p>\n\n<p>flow에서의 데이터 흐름은 결국 collect 전에는 아무런 시작을 하지 않음을 알 수 있다.</p>\n\n<p><br /></p>\n\n<h2>ReactiveX의 HotStream</h2>\n\n<p>HotFlow는 collect 과는 상관없이 물이 흘러가듯 언제나 흘러가고 있다.</p>\n\n<p>구독 시점을 기준으로 이전의 데이터 흐름부터 시작할지 항상 새로운 흐름만 받을지가 다를 뿐이다.</p>\n\n<p>ReactiveX에는 이런 형태의 함수가 총 4가지 있는데 아래와 같다.</p>\n\n<h3>AsyncSubject</h3>\n\n<p>구독한 시점의 마지막 값을 방출하고, 새로운 구독이 발생해도 역시 마지막 값을 방출한다.(항상 최신의 마지막만 제공한다)</p>\n\n<p><img src=\"/images/posts/2024/Flow-Data-flow/sample_02.png\" alt=\"sample_02\" /></p>\n\n<h3>BehaviorSubject</h3>\n\n<p>구독한 시점의 최근 데이터 1개와 이후 데이터 흐름을 받을 수 있다.</p>\n\n<p><img src=\"/images/posts/2024/Flow-Data-flow/sample_03.png\" alt=\"sample_03\" /></p>\n\n<h3>PublishSubject</h3>\n\n<p>구독한 시점 이후의 최신 데이터를 순차 흐름을 받을 수 있다.</p>\n\n<p><img src=\"/images/posts/2024/Flow-Data-flow/sample_04.png\" alt=\"sample_04\" /></p>\n\n<h3>ReplaySubject</h3>\n\n<p>구독 시점 앞서 발생한 모든 값을 다시 받을 수 있다.</p>\n\n<p><img src=\"/images/posts/2024/Flow-Data-flow/sample_05.png\" alt=\"sample_05\" /></p>\n\n<p><a href=\"https://reactivex.io/documentation/subject.html\">ReactiveX - Subject - link</a></p>\n\n<p>ReactiveX에는 4가지의 Subject가 HotStream에 해당하는데 방식도 다양하다. Flow에서는 크게 2가지를 제공한다.</p>\n\n<ul>\n  <li>StateFlow : 구독한 시점의 최근 데이터 1개와 이후 데이터 흐름을 받을 수 있다.</li>\n  <li>SharedFlow : SharedFlow의 옵션을 통해 구독 시점을 다양하게 관리할 수 있으며, 동일한 값 역시 방출이 가능하다.</li>\n</ul>\n\n<p>StateFlow는 상태를 관리하기 위한 최적의 상태를 제공해 주기 위해 추가되었는데 ReactiveX에서 PublishSubject와 동일함을 알 수 있다.</p>\n\n<p>엄밀히 따지면 RectiveX Subject와는 다른 부분이 존재하지만 이해도를 높이기 위해 그림을 포함하였다.</p>\n\n<p><br /></p>\n\n<h2>Flow의 HotFlow(HotStream)</h2>\n\n<p>Flow에는 HotStream으로 2개를 제공 있다.</p>\n\n<h3>StateFlow</h3>\n\n<p>StateFlow는 equals, hashCode가 같은 경우 방출하지 않으며, 구독 시점 최근 마지막 데이터 1개와 이후 흐름을 받을 수 있다.</p>\n\n<p>1개의 StateFlow와 2개의 <code class=\"language-plaintext highlighter-rouge\">collect()</code>하는 코드를 아래와 같이 구현하였다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kd\">val</span> <span class=\"py\">stateFlow</span> <span class=\"p\">=</span> <span class=\"nc\">MutableStateFlow</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n\n<span class=\"c1\">// collect 1</span>\n<span class=\"n\">stateFlow</span>\n    <span class=\"p\">.</span><span class=\"nf\">onEach</span> <span class=\"p\">{</span> <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">launchIn</span><span class=\"p\">(</span><span class=\"n\">viewModelScope</span><span class=\"p\">)</span>\n\n<span class=\"nf\">delay</span><span class=\"p\">(</span><span class=\"mi\">500</span><span class=\"p\">)</span>\n\n<span class=\"n\">stateFlow</span><span class=\"p\">.</span><span class=\"n\">value</span> <span class=\"p\">=</span> <span class=\"mi\">0</span>\n\n<span class=\"nf\">delay</span><span class=\"p\">(</span><span class=\"mi\">1_000L</span><span class=\"p\">)</span>\n\n<span class=\"c1\">// collect 2</span>\n<span class=\"n\">stateFlow</span>\n    <span class=\"p\">.</span><span class=\"nf\">onEach</span> <span class=\"p\">{</span> <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">launchIn</span><span class=\"p\">(</span><span class=\"n\">viewModelScope</span><span class=\"p\">)</span>\n\n<span class=\"nf\">delay</span><span class=\"p\">(</span><span class=\"mi\">500</span><span class=\"p\">)</span>\n<span class=\"n\">stateFlow</span><span class=\"p\">.</span><span class=\"n\">value</span> <span class=\"p\">=</span> <span class=\"mi\">1</span>\n<span class=\"nf\">delay</span><span class=\"p\">(</span><span class=\"mi\">500</span><span class=\"p\">)</span>\n<span class=\"n\">stateFlow</span><span class=\"p\">.</span><span class=\"n\">value</span> <span class=\"p\">=</span> <span class=\"mi\">2</span>\n</code></pre></div></div>\n\n<p>이 코드의 실행 결과는 아래와 같다.</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">0(first) 0(reaply) 1(new) 1(new) 2(new) 2(new)</code></p>\n\n<p>이에 대한 도식화 결과가 다음과 같다.</p>\n\n<p><img src=\"/images/posts/2024/Flow-Data-flow/sample_06.png\" alt=\"sample_06\" /></p>\n\n<p><br /></p>\n\n<h4>StateFlow를 좀 더 알아보면</h4>\n\n<p>StateFlow는 내부에서 <code class=\"language-plaintext highlighter-rouge\">private val _state = atomic(initialState) // T | NULL</code>을 활용하여 처리하고 있다. atomic은 멀티 스레드 환경에서 하나의 변수에 대한 동시 접근 시 데이터의 일관성을 보장하기 위한 메커니즘이 적용되어 있다.</p>\n\n<p>Android 개발에서 가장 많이 활용하고 있는 StateFlow는 atomic 적용되어 있기 때문에 Thread safe를 보장한다.</p>\n\n<blockquote>\n  <p>다른 이야기지만 일부 아키텍처 패턴 글에 해당 패턴을 사용하면 Thread safe라는 표현을 쓰는 경우가 있다. StateFlow를 기본 사용하는 경우는 어떤 아키텍처 패턴을 쓰던 StateFlow가 thread safe를 제공하는 것이지 해당 패턴에서 thread safe를 지켜주었다는 표현은 잘못된 표현이다.</p>\n</blockquote>\n\n<p>그리고 값을 update 하는 경우는 2가지 기법을 활용할 수 있다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kd\">val</span> <span class=\"py\">stateFlow</span> <span class=\"p\">=</span> <span class=\"nc\">MutableStateFlow</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n\n<span class=\"c1\">// update 사용하는 케이스</span>\n<span class=\"n\">stateFlow</span><span class=\"p\">.</span><span class=\"nf\">update</span> <span class=\"p\">{</span> <span class=\"n\">newValue</span> <span class=\"p\">}</span>\n\n<span class=\"c1\">// setValue</span>\n<span class=\"n\">stateFlow</span><span class=\"p\">.</span><span class=\"n\">value</span> <span class=\"p\">=</span> <span class=\"n\">newValue</span>\n</code></pre></div></div>\n\n<p>각각에 대한 내부 코드를 조금 살펴보면</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// update 함수</span>\n<span class=\"k\">public</span> <span class=\"k\">inline</span> <span class=\"k\">fun</span> <span class=\"p\">&lt;</span><span class=\"nc\">T</span><span class=\"p\">&gt;</span> <span class=\"nf\">MutableStateFlow</span><span class=\"p\">&lt;</span><span class=\"nc\">T</span><span class=\"p\">&gt;.</span><span class=\"nf\">update</span><span class=\"p\">(</span><span class=\"n\">function</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"nc\">T</span><span class=\"p\">)</span> <span class=\"p\">-&gt;</span> <span class=\"nc\">T</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">while</span> <span class=\"p\">(</span><span class=\"k\">true</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n        <span class=\"kd\">val</span> <span class=\"py\">prevValue</span> <span class=\"p\">=</span> <span class=\"n\">value</span>\n        <span class=\"kd\">val</span> <span class=\"py\">nextValue</span> <span class=\"p\">=</span> <span class=\"nf\">function</span><span class=\"p\">(</span><span class=\"n\">prevValue</span><span class=\"p\">)</span>\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nf\">compareAndSet</span><span class=\"p\">(</span><span class=\"n\">prevValue</span><span class=\"p\">,</span> <span class=\"n\">nextValue</span><span class=\"p\">))</span> <span class=\"p\">{</span>\n            <span class=\"k\">return</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"c1\">// property setValue</span>\n<span class=\"k\">public</span> <span class=\"k\">override</span> <span class=\"kd\">var</span> <span class=\"py\">value</span><span class=\"p\">:</span> <span class=\"nc\">T</span>\n    <span class=\"k\">get</span><span class=\"p\">()</span> <span class=\"p\">=</span> <span class=\"nc\">NULL</span><span class=\"p\">.</span><span class=\"nf\">unbox</span><span class=\"p\">(</span><span class=\"n\">_state</span><span class=\"p\">.</span><span class=\"n\">value</span><span class=\"p\">)</span>\n    <span class=\"k\">set</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"nf\">updateState</span><span class=\"p\">(</span><span class=\"k\">null</span><span class=\"p\">,</span> <span class=\"n\">value</span> <span class=\"o\">?:</span> <span class=\"nc\">NULL</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p><code class=\"language-plaintext highlighter-rouge\">update</code> 함수는 compareAndSet을 호출하고 있고, setValue는 updateState()를 호출하고 있지만 사실 둘 다 <code class=\"language-plaintext highlighter-rouge\">updateState</code> 함수를 호출하고 있다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">override</span> <span class=\"k\">fun</span> <span class=\"nf\">compareAndSet</span><span class=\"p\">(</span><span class=\"n\">expect</span><span class=\"p\">:</span> <span class=\"nc\">T</span><span class=\"p\">,</span> <span class=\"n\">update</span><span class=\"p\">:</span> <span class=\"nc\">T</span><span class=\"p\">):</span> <span class=\"nc\">Boolean</span> <span class=\"p\">=</span>\n    <span class=\"nf\">updateState</span><span class=\"p\">(</span><span class=\"n\">expect</span> <span class=\"o\">?:</span> <span class=\"nc\">NULL</span><span class=\"p\">,</span> <span class=\"n\">update</span> <span class=\"o\">?:</span> <span class=\"nc\">NULL</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>update를 쓰나 property <code class=\"language-plaintext highlighter-rouge\">.value</code>를 바로 바꾸나 둘 다 thread safe 하게 값을 변경한다는 점이다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"nf\">updateState</span><span class=\"p\">(</span><span class=\"n\">expectedState</span><span class=\"p\">:</span> <span class=\"nc\">Any</span><span class=\"p\">?,</span> <span class=\"n\">newState</span><span class=\"p\">:</span> <span class=\"nc\">Any</span><span class=\"p\">):</span> <span class=\"nc\">Boolean</span> <span class=\"p\">{</span>\n    <span class=\"c1\">// 생략</span>\n    <span class=\"nf\">synchronized</span><span class=\"p\">(</span><span class=\"k\">this</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// 생략</span>\n    <span class=\"p\">}</span>\n    \n    <span class=\"k\">while</span> <span class=\"p\">(</span><span class=\"k\">true</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// 생략</span>\n        <span class=\"nf\">synchronized</span><span class=\"p\">(</span><span class=\"k\">this</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n            <span class=\"c1\">// 생략</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p><br /></p>\n\n<h3>SharedFlow</h3>\n\n<p>이번엔 SharedFlow이다. SharedFlow는 특이하게도 3가지 기본 옵션을 제공하고 있어서 다양한 방식의 사용이 가능하다.</p>\n\n<p><a href=\"https://kotlinlang.org/api/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines.flow/-shared-flow/\">kotlin coroutines SharedFlow - link</a></p>\n\n<ul>\n  <li>extraBufferCapacity : 기본 설정은 0, 버퍼는 1개를 기본 제공하는데, 여기에 N 개의 추가 버퍼를 적용할 수 있다.</li>\n  <li>replay : 기본 설정은 0, 새로운 구독 시점에 마지막 N 개의 아이템을 replay 한다.</li>\n  <li>onBufferOverflow : 기본값은 SUSPEND이고, DROP_OLDEST 목록 중 이전 값을 제거하거나, DROP_LATEST 목록 중 어느 값이 버려지는지 중요하지 않은 경우</li>\n</ul>\n\n<p>drop_latest은 해석이 애매해서 원문을 그대로 적어둔다.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>This option can be used in rare advanced scenarios where all elements that are expected to enter the buffer are equal, so it is not important which of them get thrown away.\n</code></pre></div></div>\n\n<p>SharedFlow로는 다음의 시나리오가 모두 가능하다.</p>\n\n<ul>\n  <li>구독 시점 이후 최신 데이터 만 받을 수 있다.(ReactiveX PublishSubject)</li>\n</ul>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// suspend로 활용하고, emit 만 활용하는 경우</span>\n<span class=\"kd\">val</span> <span class=\"py\">mutableSharedFlow</span><span class=\"p\">&lt;</span><span class=\"nc\">Int</span><span class=\"p\">&gt;()</span>\n</code></pre></div></div>\n\n<ul>\n  <li>구독 시점 최근 데이터 1개 또는 N 개를 replay 받고, 이후 흐름을 받을 수 있다.(ReactiveX BehaviorSubject, ReplaySubject)</li>\n</ul>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// suspend로 활용하고, emit 만 활용하는 경우</span>\n<span class=\"kd\">val</span> <span class=\"py\">mutableSharedFlow</span><span class=\"p\">&lt;</span><span class=\"nc\">Int</span><span class=\"p\">&gt;(</span>\n    <span class=\"n\">extraBufferCapacity</span> <span class=\"p\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"n\">replay</span> <span class=\"p\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"c1\">// or N</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\">// DROP_OLDEST tryEmit으로 emit하는 경우</span>\n<span class=\"kd\">val</span> <span class=\"py\">mutableSharedFlow</span><span class=\"p\">&lt;</span><span class=\"nc\">Int</span><span class=\"p\">&gt;(</span>\n    <span class=\"n\">extraBufferCapacity</span> <span class=\"p\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"n\">replay</span> <span class=\"p\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"c1\">// or N</span>\n    <span class=\"n\">onBufferOverflow</span> <span class=\"p\">=</span> <span class=\"nc\">BufferOverflow</span><span class=\"p\">.</span><span class=\"nc\">DROP_OLDEST</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n</code></pre></div></div>\n\n<ul>\n  <li>구독 시점 최근 데이터 중 가장 마지막의 데이터부터 받는다.(ReactiveX AsyncSubject)</li>\n</ul>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// DROP_OLDEST tryEmit으로 emit하는 경우</span>\n<span class=\"kd\">val</span> <span class=\"py\">mutableSharedFlow</span><span class=\"p\">&lt;</span><span class=\"nc\">Int</span><span class=\"p\">&gt;(</span>\n    <span class=\"n\">extraBufferCapacity</span> <span class=\"p\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"n\">onBufferOverflow</span> <span class=\"p\">=</span> <span class=\"nc\">BufferOverflow</span><span class=\"p\">.</span><span class=\"nc\">DROP_OLDEST</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>앞에서 언급한 ReactiveX의 4가지 모두를 자유롭게 사용할 수 있기에 옵션만 잘 활용해도 동일한 결과를 얻을 수 있다.</p>\n\n<h4>샘플 코드라서 비밀은 있다(문제가 있다)</h4>\n\n<p>위 코드에는 하나의 비밀이 숨겨져있는데, emit/tryEmit을 선택하여 사용해야 하며, 이에 따라 결과가 달라진다는 점이다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kd\">val</span> <span class=\"py\">sharedFlow</span> <span class=\"p\">=</span> <span class=\"nc\">MutableSharedFlow</span><span class=\"p\">&lt;</span><span class=\"nc\">Int</span><span class=\"p\">&gt;(</span>\n    <span class=\"n\">extraBufferCapacity</span> <span class=\"p\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"n\">replay</span> <span class=\"p\">=</span> <span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"n\">onBufferOverflow</span> <span class=\"p\">=</span> <span class=\"nc\">BufferOverflow</span><span class=\"p\">.</span><span class=\"nc\">DROP_OLDEST</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">sharedFlow</span><span class=\"p\">.</span><span class=\"nf\">tryEmit</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"n\">sharedFlow</span><span class=\"p\">.</span><span class=\"nf\">tryEmit</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"n\">sharedFlow</span>\n    <span class=\"p\">.</span><span class=\"nf\">onEach</span> <span class=\"p\">{</span> <span class=\"n\">i</span> <span class=\"p\">-&gt;</span>\n        <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"index $i\"</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">launchIn</span><span class=\"p\">(</span><span class=\"k\">this</span><span class=\"p\">)</span>\n\n<span class=\"n\">sharedFlow</span><span class=\"p\">.</span><span class=\"nf\">tryEmit</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"n\">sharedFlow</span><span class=\"p\">.</span><span class=\"nf\">tryEmit</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>이 코드에 대한 기대 결과는 <code class=\"language-plaintext highlighter-rouge\">1(replay), 2(replay), 3(new), 4(new)</code>라고 생각할 수 있지만 실제 결과는 <code class=\"language-plaintext highlighter-rouge\">3(replay), 4(replay)</code>란 결과가 나온다.</p>\n\n<p>이는 laucnIn(collect)으로 stream 구독을 시작하였지만 구독에 대한 시간이 필요하며, emit/tryEmit을 연속으로 처리했기 때문에 마지막 emit 값 3, 4 replay로 값이 전달되어 출력됨을 디버그를 통해 확인할 수 있다.</p>\n\n<p>추가로 emit 함수에는 아래와 같이 tryEmit과 emitSuspend를 사용하고 있지만 디버그 해보면 대부분 tryEmit에서 완료되어 fast-path 처리하고 끝난다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">override</span> <span class=\"k\">suspend</span> <span class=\"k\">fun</span> <span class=\"nf\">emit</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">:</span> <span class=\"nc\">T</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nf\">tryEmit</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">))</span> <span class=\"k\">return</span> <span class=\"c1\">// fast-path</span>\n    <span class=\"nf\">emitSuspend</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>이런 코드를 작성하지는 않겠지만 replay만 동작하고 끝날 수 있기에 샘플 코드에서는 다음과 같이 수정하였다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kd\">val</span> <span class=\"py\">sharedFlow</span> <span class=\"p\">=</span> <span class=\"nc\">MutableSharedFlow</span><span class=\"p\">&lt;</span><span class=\"nc\">Int</span><span class=\"p\">&gt;(</span>\n    <span class=\"n\">extraBufferCapacity</span> <span class=\"p\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"n\">replay</span> <span class=\"p\">=</span> <span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"n\">onBufferOverflow</span> <span class=\"p\">=</span> <span class=\"nc\">BufferOverflow</span><span class=\"p\">.</span><span class=\"nc\">DROP_OLDEST</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">sharedFlow</span><span class=\"p\">.</span><span class=\"nf\">tryEmit</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"n\">sharedFlow</span><span class=\"p\">.</span><span class=\"nf\">tryEmit</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"n\">sharedFlow</span>\n    <span class=\"p\">.</span><span class=\"nf\">onEach</span> <span class=\"p\">{</span> <span class=\"n\">i</span> <span class=\"p\">-&gt;</span>\n        <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"index $i\"</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">launchIn</span><span class=\"p\">(</span><span class=\"k\">this</span><span class=\"p\">)</span>\n\n<span class=\"nf\">delay</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"c1\">// 대기시간을 줘야 한다.</span>\n<span class=\"n\">sharedFlow</span><span class=\"p\">.</span><span class=\"nf\">tryEmit</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"n\">sharedFlow</span><span class=\"p\">.</span><span class=\"nf\">tryEmit</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>이와 같이 대기시간을 1ms 정도 주면 결과가 <code class=\"language-plaintext highlighter-rouge\">3, 4</code>에서 <code class=\"language-plaintext highlighter-rouge\">1(replay), 2(replay), 3(new), 4(new)</code>를 순서대로 동작시켜준다.</p>\n\n<p>emit으로 변경한다 해도 동일한 결과가 나오는데, emit을 연속으로 하였기 때문에 구독 이전의 값들이 사실상 의미가 없다는 점이다.</p>\n\n<p><br /></p>\n\n<h2>시나리오 1</h2>\n\n<p>StateFlow와 SharedFlow에 대해서 설명하였는데 그래서 어떻게 쓰는 것이 좋을까? 이 둘을 같이 사용하는 것이 가능할까?</p>\n\n<p>GitHub 사용자 검색 api를 활용한 예이다.</p>\n\n<p><a href=\"https://github.com/taehwandev/GithubUserSearch\">GitHub GithubUserSearch - link</a></p>\n\n<p>이 코드가 실시간 갱신을 사용하기 위한 시나리오를 가지고 ColdFlow와 HotFlow를 연속적으로 사용하기 위한 코드에 대한 설명이다.</p>\n\n<p>이미 과거에 작성했던 글과 연속적으로 같은 설명이라서 이 글에서는 생략하고 넘어가겠다.</p>\n\n<p><a href=\"https://thdev.tech/android/2023/10/15/Android-GitHubSample-01/\">Android에서 flow를 통한 실시간 데이터 갱신에 대한 정리 - link</a></p>\n\n<p><br /></p>\n\n<h2>시나리오 2</h2>\n\n<p>사용자가 동의하기 버튼과 확인 버튼을 누르기 전에는 데이터를 불러올 수 없으며, check에 대한 상태는 실시간 갱신되어야 하며, 버튼은 사용자가 누르기 전에는 액션 할 수 없다.</p>\n\n<p>suspend로 작성하면 버튼을 누르면 suspend 함수를 호출해 주면 끝이다.</p>\n\n<p>이를 지속적인 흐름으로 가져가고 싶다면 일단 시나리오를 구분해야 한다.</p>\n\n<ul>\n  <li>사용자의 동의 버튼 누르는 행동은 언제나 일어난다.\n    <ul>\n      <li>StateFlow를 활용해 true/false를 관리한다.</li>\n    </ul>\n  </li>\n  <li>사용자가 확인 버튼을 누를 수 있는 경우는 동의한 경우에만 실행하도록 대기한다.\n    <ul>\n      <li>SharedFlow와 앞선 StateFlow를 동시에 true 인지 체크가 필요하다.</li>\n    </ul>\n  </li>\n</ul>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// 동의 버튼에 대한 처리</span>\n<span class=\"kd\">val</span> <span class=\"py\">agree</span> <span class=\"p\">=</span> <span class=\"nc\">MutableStateFlow</span><span class=\"p\">(</span><span class=\"k\">false</span><span class=\"p\">)</span>\n\n<span class=\"c1\">// 사용자 버튼 클릭을 처리하기 위함</span>\n<span class=\"kd\">val</span> <span class=\"py\">ok</span> <span class=\"p\">=</span> <span class=\"nc\">MutableSharedFlow</span><span class=\"p\">&lt;</span><span class=\"nc\">Boolean</span><span class=\"p\">&gt;(</span>\n    <span class=\"n\">extraBufferCapacity</span> <span class=\"p\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"n\">onBufferOverflow</span> <span class=\"p\">=</span> <span class=\"nc\">BufferOverflow</span><span class=\"p\">.</span><span class=\"nc\">DROP_OLDEST</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>코드의 순서가 어디가 먼저일까? agree 되었을 경우 button이 눌러짐을 대기해야 할까? button은 눌러질 수 있지만 agree를 체크하고 나서 실행해야 할까?</p>\n\n<p>이런 시나리오라면 코드는 달라질 수 있지만 전자에 대한 시나리오 코드를 적어보겠다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">agree</span> <span class=\"c1\">// 1</span>\n    <span class=\"p\">.</span><span class=\"nf\">onEach</span> <span class=\"p\">{</span> <span class=\"n\">isAgree</span> <span class=\"p\">-&gt;</span>\n        <span class=\"n\">_uiState</span><span class=\"p\">.</span><span class=\"nf\">update</span> <span class=\"p\">{</span>\n            <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"nf\">copy</span><span class=\"p\">(</span>\n                <span class=\"n\">isAgree</span> <span class=\"p\">=</span> <span class=\"n\">isAgree</span><span class=\"p\">,</span>\n            <span class=\"p\">)</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">filter</span> <span class=\"p\">{</span> <span class=\"n\">it</span> <span class=\"p\">}</span> <span class=\"c1\">// 2</span>\n    <span class=\"p\">.</span><span class=\"nf\">flatMapLatest</span> <span class=\"p\">{</span> <span class=\"n\">agree</span> <span class=\"p\">-&gt;</span> <span class=\"c1\">// 3</span>\n        <span class=\"n\">ok</span> <span class=\"c1\">// ok event는 true 말곤 올게 없어서 필터하지 않음</span>\n            <span class=\"p\">.</span><span class=\"nf\">map</span> <span class=\"p\">{</span> <span class=\"n\">agree</span> <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">map</span> <span class=\"p\">{</span>\n        <span class=\"n\">repository</span><span class=\"p\">.</span><span class=\"nf\">updateAgree</span><span class=\"p\">()</span> <span class=\"c1\">// 4</span>\n    <span class=\"p\">}</span>\n    <span class=\"p\">.</span><span class=\"nf\">retryWhen</span> <span class=\"p\">{</span> <span class=\"n\">_</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"p\">-&gt;</span> <span class=\"k\">true</span> <span class=\"p\">}</span> <span class=\"c1\">// 5</span>\n    <span class=\"p\">.</span><span class=\"nf\">flowOn</span><span class=\"p\">(</span><span class=\"nc\">Disatpcher</span><span class=\"p\">.</span><span class=\"nc\">IO</span><span class=\"p\">)</span>\n    <span class=\"p\">.</span><span class=\"nf\">launchIn</span><span class=\"p\">(</span><span class=\"n\">viewModelScope</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<ol>\n  <li>사용자 동의는 true/false로 언제나 일어난다.</li>\n  <li>만약 agree true 이면 filter를 통과한다.</li>\n  <li>flatMapLatest는 2번 true 이면 통과되어 ok에 대한 이벤트를 받을 수 있다.</li>\n  <li>3번의 이벤트가 발생하지 않는 이상 이 코드는 동작하지 않는다.</li>\n</ol>\n\n<p>만약 network fail이 발생하고, 재시도 가능한 상태를 둔다고 하더라도 이 코드는 3번에서 사용자의 액션을 받기 전에는 동작하지 않는다. 그렇기에 그만큼 간단한 코드로 예외 처리할 수 있다.</p>\n\n<ol>\n  <li>4번의 네트워크 실패 케이스가 발생하면 5번 <code class=\"language-plaintext highlighter-rouge\">retryWhen</code>으로 이동한다.</li>\n  <li>재시도에 대한 사용자에게 알릴 수 있다. 5번에서 true 값을 사용했기에 1번부터 다시 시작한다.</li>\n  <li>이전의 값이 true이기 때문에 true를 다시 방출한다.</li>\n  <li>true이기에 filter 통과한다.</li>\n  <li>사용자의 새로운 액션을 대기한다.</li>\n</ol>\n\n<p><code class=\"language-plaintext highlighter-rouge\">retryWhen</code>이 동작하더라도 3번의 아무런 액션이 없기 때문이 이 코드는 멈춘다. 예외 처리에 대한 자세한 내용은 이전에 작성한 글을 참고하시길</p>\n\n<p><a href=\"https://thdev.tech/kotlin/2023/04/13/Kotlin-Flow-Retry/\">Kotlin flow의 예외 처리(catch), 재시도(retry, retryWhen) 살펴보기 - link</a></p>\n\n<p><br /></p>\n\n<h2>마무리</h2>\n\n<p>StateFlow와 SharedFlow에 대한 데이터 흐름을 알아보고, 2가지 시나리오를 기반으로 간단한 코드를 적어보았다.</p>\n\n",
        "contentSnippet": "이전 글에서 데이터 흐름(Data flow)을 이해해 보는 데 있어 필요한 것은? 짝퉁 개발자처럼 논하기란 주제로 글을 작성했다.\n이번 글에서는 이 글에 나온 내용 중 Coroutines Flow에 대한 데이터 흐름을 이해하기 위한 글을 작성해 보았다.\n이 글에서는\nCoroutines Flow\n지속적인 흐름\nCold/Hot stream\nReactiveX에서 제공하는 subject에 대해서 이해하기\nCoroutines Flow\nAsynchronous Flow - link는 공식 문서에 나온 설명을 그대로 가져왔다.\nA suspending function asynchronously returns a single value, but how can we return multiple asynchronously computed values? This is where Kotlin Flows come in.\nsupend 함수는 비동기적인 값을 불러올 순 있지만 지속적인 값의 흐름을 가지지는 않는다.\n\nsuspend fun featchData() = /* 생략 */\n\nfun main() {\n    println(featchData())\n}\n\n\n이런 흐름은 사실 누구나 이해하기 쉽다. main 함수에서 featchData()를 호출하면 응답이 딱 1번 온다는 것이다.\n그럼 이를 2회로 반복하면? main 함수에 한 줄 더 추가하거나, (0..1).forEach {}처럼 자동화할 수 있다.\n\nsuspend fun featchData() = /* 생략 */\n\nfun main() {\n    println(featchData())\n    println(featchData()) // 1회 더 추가\n}\n\n\n\n지속적인 흐름\nflow를 통한 지속적인 흐름을 만든다는 것은 아래와 같다.\n함수를 호출한다.\nFlow로 생성한 객체를 리턴 받는다.\n구독(collect) 한다.\n    \ncollect()을 하기 전에도 새로운 데이터 흐름이 있다.\ncollect()을 해야만 새로운 데이터 흐름이 시작한다.\nflow를 활용하는 방식에서의 지속적인 흐름은 이와 같다.\n이를 아무나 이해할 수 있는 내용이 뭐가 있을까?\ncollect() 하기 전에도 새로운 데이터 흐름이 있다.\n    \n물은 흐른다.\n스트리밍 서비스를 월 결제한다.\ncollect() 해야 만 새로운 데이터 흐름이 시작된다.\n    \n커피를 주문한다.\n음식을 주문한다.\n위의 예들이 맞을 수도 있고, 엄밀히 따지면 적합한 예가 아닐 수 있지만 대략 구분해 보면 이와 같을 수 있다.\n결국 이미 있는 걸 필요할 때만 받아쓴다로 표현할 수 있는 것을 HotFlow(HotStream)으로 칭하고, 새로운 줌의 발생으로 만들기 시작한다는 ColdFlow(ColdStream)으로 칭한다.\n\nColdFlow\nColdFlow인 flow {}에 대한 코드가 아래와 같다.\n\nval flow = flow {\n    (1..6).forEach {\n        emit(it)\n        delay(1_000L)\n    }\n}\n\n// collect 1\nflow\n    .onEach { println(it) }\n    .launchIn(viewModelScope)\n\ndelay(2_000L) // 2초 후 구독\n\n// collect 2\nflow\n    .onEach { println(it) }\n    .launchIn(viewModelScope)\n\n\n이에 대한 출력 결과는 아래와 같다.\n1(new), 2, 1(new), 3, 2, 4, 3, 5, 4, 6, 5, 6\n각각을 보면 1-6까지 정상 출력함을 알 수 있다.\n이를 그림으로 표현하면 아래와 같다.\n\nflow에서의 데이터 흐름은 결국 collect 전에는 아무런 시작을 하지 않음을 알 수 있다.\n\nReactiveX의 HotStream\nHotFlow는 collect 과는 상관없이 물이 흘러가듯 언제나 흘러가고 있다.\n구독 시점을 기준으로 이전의 데이터 흐름부터 시작할지 항상 새로운 흐름만 받을지가 다를 뿐이다.\nReactiveX에는 이런 형태의 함수가 총 4가지 있는데 아래와 같다.\nAsyncSubject\n구독한 시점의 마지막 값을 방출하고, 새로운 구독이 발생해도 역시 마지막 값을 방출한다.(항상 최신의 마지막만 제공한다)\n\nBehaviorSubject\n구독한 시점의 최근 데이터 1개와 이후 데이터 흐름을 받을 수 있다.\n\nPublishSubject\n구독한 시점 이후의 최신 데이터를 순차 흐름을 받을 수 있다.\n\nReplaySubject\n구독 시점 앞서 발생한 모든 값을 다시 받을 수 있다.\n\nReactiveX - Subject - link\nReactiveX에는 4가지의 Subject가 HotStream에 해당하는데 방식도 다양하다. Flow에서는 크게 2가지를 제공한다.\nStateFlow : 구독한 시점의 최근 데이터 1개와 이후 데이터 흐름을 받을 수 있다.\nSharedFlow : SharedFlow의 옵션을 통해 구독 시점을 다양하게 관리할 수 있으며, 동일한 값 역시 방출이 가능하다.\nStateFlow는 상태를 관리하기 위한 최적의 상태를 제공해 주기 위해 추가되었는데 ReactiveX에서 PublishSubject와 동일함을 알 수 있다.\n엄밀히 따지면 RectiveX Subject와는 다른 부분이 존재하지만 이해도를 높이기 위해 그림을 포함하였다.\n\nFlow의 HotFlow(HotStream)\nFlow에는 HotStream으로 2개를 제공 있다.\nStateFlow\nStateFlow는 equals, hashCode가 같은 경우 방출하지 않으며, 구독 시점 최근 마지막 데이터 1개와 이후 흐름을 받을 수 있다.\n1개의 StateFlow와 2개의 collect()하는 코드를 아래와 같이 구현하였다.\n\nval stateFlow = MutableStateFlow(0)\n\n// collect 1\nstateFlow\n    .onEach { println(it) }\n    .launchIn(viewModelScope)\n\ndelay(500)\n\nstateFlow.value = 0\n\ndelay(1_000L)\n\n// collect 2\nstateFlow\n    .onEach { println(it) }\n    .launchIn(viewModelScope)\n\ndelay(500)\nstateFlow.value = 1\ndelay(500)\nstateFlow.value = 2\n\n\n이 코드의 실행 결과는 아래와 같다.\n0(first) 0(reaply) 1(new) 1(new) 2(new) 2(new)\n이에 대한 도식화 결과가 다음과 같다.\n\n\nStateFlow를 좀 더 알아보면\nStateFlow는 내부에서 private val _state = atomic(initialState) // T | NULL을 활용하여 처리하고 있다. atomic은 멀티 스레드 환경에서 하나의 변수에 대한 동시 접근 시 데이터의 일관성을 보장하기 위한 메커니즘이 적용되어 있다.\nAndroid 개발에서 가장 많이 활용하고 있는 StateFlow는 atomic 적용되어 있기 때문에 Thread safe를 보장한다.\n다른 이야기지만 일부 아키텍처 패턴 글에 해당 패턴을 사용하면 Thread safe라는 표현을 쓰는 경우가 있다. StateFlow를 기본 사용하는 경우는 어떤 아키텍처 패턴을 쓰던 StateFlow가 thread safe를 제공하는 것이지 해당 패턴에서 thread safe를 지켜주었다는 표현은 잘못된 표현이다.\n그리고 값을 update 하는 경우는 2가지 기법을 활용할 수 있다.\n\nval stateFlow = MutableStateFlow(0)\n\n// update 사용하는 케이스\nstateFlow.update { newValue }\n\n// setValue\nstateFlow.value = newValue\n\n\n각각에 대한 내부 코드를 조금 살펴보면\n\n// update 함수\npublic inline fun <T> MutableStateFlow<T>.update(function: (T) -> T) {\n    while (true) {\n        val prevValue = value\n        val nextValue = function(prevValue)\n        if (compareAndSet(prevValue, nextValue)) {\n            return\n        }\n    }\n}\n\n// property setValue\npublic override var value: T\n    get() = NULL.unbox(_state.value)\n    set(value) { updateState(null, value ?: NULL) }\n\n\nupdate 함수는 compareAndSet을 호출하고 있고, setValue는 updateState()를 호출하고 있지만 사실 둘 다 updateState 함수를 호출하고 있다.\n\noverride fun compareAndSet(expect: T, update: T): Boolean =\n    updateState(expect ?: NULL, update ?: NULL)\n\n\nupdate를 쓰나 property .value를 바로 바꾸나 둘 다 thread safe 하게 값을 변경한다는 점이다.\n\nprivate fun updateState(expectedState: Any?, newState: Any): Boolean {\n    // 생략\n    synchronized(this) {\n        // 생략\n    }\n    \n    while (true) {\n        // 생략\n        synchronized(this) {\n            // 생략\n        }\n    }\n}\n\n\n\nSharedFlow\n이번엔 SharedFlow이다. SharedFlow는 특이하게도 3가지 기본 옵션을 제공하고 있어서 다양한 방식의 사용이 가능하다.\nkotlin coroutines SharedFlow - link\nextraBufferCapacity : 기본 설정은 0, 버퍼는 1개를 기본 제공하는데, 여기에 N 개의 추가 버퍼를 적용할 수 있다.\nreplay : 기본 설정은 0, 새로운 구독 시점에 마지막 N 개의 아이템을 replay 한다.\nonBufferOverflow : 기본값은 SUSPEND이고, DROP_OLDEST 목록 중 이전 값을 제거하거나, DROP_LATEST 목록 중 어느 값이 버려지는지 중요하지 않은 경우\ndrop_latest은 해석이 애매해서 원문을 그대로 적어둔다.\n\nThis option can be used in rare advanced scenarios where all elements that are expected to enter the buffer are equal, so it is not important which of them get thrown away.\n\n\nSharedFlow로는 다음의 시나리오가 모두 가능하다.\n구독 시점 이후 최신 데이터 만 받을 수 있다.(ReactiveX PublishSubject)\n\n// suspend로 활용하고, emit 만 활용하는 경우\nval mutableSharedFlow<Int>()\n\n\n구독 시점 최근 데이터 1개 또는 N 개를 replay 받고, 이후 흐름을 받을 수 있다.(ReactiveX BehaviorSubject, ReplaySubject)\n\n// suspend로 활용하고, emit 만 활용하는 경우\nval mutableSharedFlow<Int>(\n    extraBufferCapacity = 1,\n    replay = 1, // or N\n)\n\n// DROP_OLDEST tryEmit으로 emit하는 경우\nval mutableSharedFlow<Int>(\n    extraBufferCapacity = 1,\n    replay = 1, // or N\n    onBufferOverflow = BufferOverflow.DROP_OLDEST,\n)\n\n\n구독 시점 최근 데이터 중 가장 마지막의 데이터부터 받는다.(ReactiveX AsyncSubject)\n\n// DROP_OLDEST tryEmit으로 emit하는 경우\nval mutableSharedFlow<Int>(\n    extraBufferCapacity = 1,\n    onBufferOverflow = BufferOverflow.DROP_OLDEST,\n)\n\n\n앞에서 언급한 ReactiveX의 4가지 모두를 자유롭게 사용할 수 있기에 옵션만 잘 활용해도 동일한 결과를 얻을 수 있다.\n샘플 코드라서 비밀은 있다(문제가 있다)\n위 코드에는 하나의 비밀이 숨겨져있는데, emit/tryEmit을 선택하여 사용해야 하며, 이에 따라 결과가 달라진다는 점이다.\n\nval sharedFlow = MutableSharedFlow<Int>(\n    extraBufferCapacity = 1,\n    replay = 2,\n    onBufferOverflow = BufferOverflow.DROP_OLDEST,\n)\n\nsharedFlow.tryEmit(0)\nsharedFlow.tryEmit(1)\n\nsharedFlow\n    .onEach { i ->\n        println(\"index $i\")\n    }\n    .launchIn(this)\n\nsharedFlow.tryEmit(3)\nsharedFlow.tryEmit(4)\n\n\n이 코드에 대한 기대 결과는 1(replay), 2(replay), 3(new), 4(new)라고 생각할 수 있지만 실제 결과는 3(replay), 4(replay)란 결과가 나온다.\n이는 laucnIn(collect)으로 stream 구독을 시작하였지만 구독에 대한 시간이 필요하며, emit/tryEmit을 연속으로 처리했기 때문에 마지막 emit 값 3, 4 replay로 값이 전달되어 출력됨을 디버그를 통해 확인할 수 있다.\n추가로 emit 함수에는 아래와 같이 tryEmit과 emitSuspend를 사용하고 있지만 디버그 해보면 대부분 tryEmit에서 완료되어 fast-path 처리하고 끝난다.\n\noverride suspend fun emit(value: T) {\n    if (tryEmit(value)) return // fast-path\n    emitSuspend(value)\n}\n\n\n이런 코드를 작성하지는 않겠지만 replay만 동작하고 끝날 수 있기에 샘플 코드에서는 다음과 같이 수정하였다.\n\nval sharedFlow = MutableSharedFlow<Int>(\n    extraBufferCapacity = 1,\n    replay = 2,\n    onBufferOverflow = BufferOverflow.DROP_OLDEST,\n)\n\nsharedFlow.tryEmit(0)\nsharedFlow.tryEmit(1)\n\nsharedFlow\n    .onEach { i ->\n        println(\"index $i\")\n    }\n    .launchIn(this)\n\ndelay(1) // 대기시간을 줘야 한다.\nsharedFlow.tryEmit(3)\nsharedFlow.tryEmit(4)\n\n\n이와 같이 대기시간을 1ms 정도 주면 결과가 3, 4에서 1(replay), 2(replay), 3(new), 4(new)를 순서대로 동작시켜준다.\nemit으로 변경한다 해도 동일한 결과가 나오는데, emit을 연속으로 하였기 때문에 구독 이전의 값들이 사실상 의미가 없다는 점이다.\n\n시나리오 1\nStateFlow와 SharedFlow에 대해서 설명하였는데 그래서 어떻게 쓰는 것이 좋을까? 이 둘을 같이 사용하는 것이 가능할까?\nGitHub 사용자 검색 api를 활용한 예이다.\nGitHub GithubUserSearch - link\n이 코드가 실시간 갱신을 사용하기 위한 시나리오를 가지고 ColdFlow와 HotFlow를 연속적으로 사용하기 위한 코드에 대한 설명이다.\n이미 과거에 작성했던 글과 연속적으로 같은 설명이라서 이 글에서는 생략하고 넘어가겠다.\nAndroid에서 flow를 통한 실시간 데이터 갱신에 대한 정리 - link\n\n시나리오 2\n사용자가 동의하기 버튼과 확인 버튼을 누르기 전에는 데이터를 불러올 수 없으며, check에 대한 상태는 실시간 갱신되어야 하며, 버튼은 사용자가 누르기 전에는 액션 할 수 없다.\nsuspend로 작성하면 버튼을 누르면 suspend 함수를 호출해 주면 끝이다.\n이를 지속적인 흐름으로 가져가고 싶다면 일단 시나리오를 구분해야 한다.\n사용자의 동의 버튼 누르는 행동은 언제나 일어난다.\n    \nStateFlow를 활용해 true/false를 관리한다.\n사용자가 확인 버튼을 누를 수 있는 경우는 동의한 경우에만 실행하도록 대기한다.\n    \nSharedFlow와 앞선 StateFlow를 동시에 true 인지 체크가 필요하다.\n\n// 동의 버튼에 대한 처리\nval agree = MutableStateFlow(false)\n\n// 사용자 버튼 클릭을 처리하기 위함\nval ok = MutableSharedFlow<Boolean>(\n    extraBufferCapacity = 1,\n    onBufferOverflow = BufferOverflow.DROP_OLDEST,\n)\n\n\n코드의 순서가 어디가 먼저일까? agree 되었을 경우 button이 눌러짐을 대기해야 할까? button은 눌러질 수 있지만 agree를 체크하고 나서 실행해야 할까?\n이런 시나리오라면 코드는 달라질 수 있지만 전자에 대한 시나리오 코드를 적어보겠다.\n\nagree // 1\n    .onEach { isAgree ->\n        _uiState.update {\n            it.copy(\n                isAgree = isAgree,\n            )\n        }\n    }\n    .filter { it } // 2\n    .flatMapLatest { agree -> // 3\n        ok // ok event는 true 말곤 올게 없어서 필터하지 않음\n            .map { agree }\n    }\n    .map {\n        repository.updateAgree() // 4\n    }\n    .retryWhen { _, _ -> true } // 5\n    .flowOn(Disatpcher.IO)\n    .launchIn(viewModelScope)\n\n\n사용자 동의는 true/false로 언제나 일어난다.\n만약 agree true 이면 filter를 통과한다.\nflatMapLatest는 2번 true 이면 통과되어 ok에 대한 이벤트를 받을 수 있다.\n3번의 이벤트가 발생하지 않는 이상 이 코드는 동작하지 않는다.\n만약 network fail이 발생하고, 재시도 가능한 상태를 둔다고 하더라도 이 코드는 3번에서 사용자의 액션을 받기 전에는 동작하지 않는다. 그렇기에 그만큼 간단한 코드로 예외 처리할 수 있다.\n4번의 네트워크 실패 케이스가 발생하면 5번 retryWhen으로 이동한다.\n재시도에 대한 사용자에게 알릴 수 있다. 5번에서 true 값을 사용했기에 1번부터 다시 시작한다.\n이전의 값이 true이기 때문에 true를 다시 방출한다.\ntrue이기에 filter 통과한다.\n사용자의 새로운 액션을 대기한다.\nretryWhen이 동작하더라도 3번의 아무런 액션이 없기 때문이 이 코드는 멈춘다. 예외 처리에 대한 자세한 내용은 이전에 작성한 글을 참고하시길\nKotlin flow의 예외 처리(catch), 재시도(retry, retryWhen) 살펴보기 - link\n\n마무리\nStateFlow와 SharedFlow에 대한 데이터 흐름을 알아보고, 2가지 시나리오를 기반으로 간단한 코드를 적어보았다.",
        "guid": "https://thdev.tech/dataflow/2024/11/23/Flow-Data-flow/",
        "isoDate": "2024-11-23T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕홍",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": [
      {
        "creator": "bahamoth",
        "title": "호랑이는 죽어서 가죽을 남기고, 프로그램은 죽어서 덤프를 남긴다.",
        "link": "https://01010011.blog/2024/11/20/%ed%98%b8%eb%9e%91%ec%9d%b4%eb%8a%94-%ec%a3%bd%ec%96%b4%ec%84%9c-%ea%b0%80%ec%a3%bd%ec%9d%84-%eb%82%a8%ea%b8%b0%ea%b3%a0-%ed%94%84%eb%a1%9c%ea%b7%b8%eb%9e%a8%ec%9d%80-%ec%a3%bd%ec%96%b4%ec%84%9c/",
        "pubDate": "Wed, 20 Nov 2024 12:59:33 +0000",
        "content:encodedSnippet": "서론\n아무리 소프트웨어를 잘 만들었더라도 구동중인 프로그램이 사용자 환경에서 비정상 종료되는 문제는 필연적이다.\n속된 말로 ‘프로그램이 죽는’ 현상이 이러한 비정상 종료에 해당하는데, 개발자 입장에서는 왜 이러한 ‘죽음’이 발생하는지 파악이 어렵다. 왜냐하면 개발자의 PC에서는 프로그램이 죽지 않기 때문이다.(It works on my machine)\n너무도 다양한 사용자 환경은 기상천외한 문제를 일으킨다.(바닐라 아이스크림 알러지가 있는 자동차)\n이러한 안타까운 죽음의 원인을 부검하기 위해, 개발자는 프로그램이 실행되었던 주변환경에 대한 다양한 정보를 수집한다. 허나 아무리 다양한 주변 정보를 수집한다 하더라도 직접적인 사인은 시체를 확인해야만 하듯, 프로그램이 비정상 종료된 원인은 크래시가 발생한 시점에 메모리에 적재된 스냅샷을 확인해야만 한다.\n그렇다. 호랑이는 죽어서 가죽을 남기고 한우는 죽어서 T본 스테이크를 남기듯, 프로그램은 죽어서 메모리 덤프를 남긴다. 이 글에서는 메모리 덤프가 무엇인지 알아보고, 다양한 사용자 환경에서 덤프를 수집하고 처리하기 위해 어떤 과정들이 이뤄지는지를 알아보겠다.\n프로그램의 생애주기(정상종료 vs 비정상종료)​\n프로그램의 비정상 종료가 무엇인지 설명하려면 정상적으로 실행되어 종료되는 상황이 어떤 흐름으로 진행되는지 알아둘 필요가 있다.\n먼저 소스코드가 실행가능한 프로그램으로 변환되는 과정을 개략적으로 살펴보자. 컴파일러는 소스코드를 역할에 따라 다양한 중간형태(=Object File)로 변환한다.\n다음은 Linux의 Object File 형식이다. 다른 플랫폼의 경우 명칭이 좀 다를 수 있으나 개념은 크게 다르지 않다.\n\n\n\n\n출처: https://cs4157.github.io/www/2024-1/lect/15-elf-intro.html\ntext section: 컴파일 타겟 머신에서 실행 가능한 기계어 코드\ndata section: 초기화된 전역변수/static 변수\nbss section: 초기화되지 않은 전역변수의 메타정보\n그밖에: 읽기 전용(rodata)나 심볼테이블(symtab) relocation 정보(rel.text/rel.data) 등등\n이 중간형태의 Object file들이 실행가능한 형태의 Executable file로 결합이 되어야 비로소 최종적인 프로그램의 형태가 된다.\nJava나 Python, Typescript 같은 Managed 환경은 동작방식도 다르고, 이 글의 메인 주제인 Crash Dump를 (웬만하면)남기지 않기 때문에 여기서는 다루지 않는다.\n프로그램이 실행되기 위해서는 Object file들을 결합 후 메모리에 적재하여야 한다. 이 과정에서 링커는 여러 오브젝트 파일을 하나의 실행 파일로 결합하고, 로더는 이 실행 파일을 메모리에 적재한다. 이 실행파일 형식은 플랫폼에 따라 다르다.\nWindows: PE(Portable Executable)\nLinux: ELF(Executable and Linkable Format)\nmacOS: Mach-O(Mach Object)\n프로그램이 메모리에 적재되었을 때 text / data / bss 같은 영역의 크기는 고정적이다. 한편, 프로그램이 동작함에 따라 동적으로 크기가 늘었다 줄었다 하는 영역이 있는데, TLS(Thread Local Storage)에서 자라나는 콜스택이나 힙이 그러한 예이다. 콜스택은 함수 호출 시 스택 프레임을 추가하고, 함수 종료 시 제거하는 구조다. 힙은 프로그램 실행 중 메모리를 할당하고 해제하는 영역이다.\n프로그램의 특정 기능을 사용하기 위해 버튼을 누르거나, 화면을 터치하는 등의 행위를 하면 그 기능을 수행하기 위해 구성된 함수들이 차례대로 호출된다. 때로는 크기가 얼마나 될지 모르는 데이터를 읽고 쓰는 작업이 필요하기도 하다. 이 과정에서 콜스택과 힙이 자라나게 된다.\n정상적인 사용자 시나리오에서는 프로그램이 모든 작업을 마치고 종료될 때, 콜스택과 힙에 할당된 모든 메모리가 정리되고, 모든 리소스는 OS에 반환된다. 이로써 프로그램은 정상 종료 상태에 진입하게 된다.\nAlt + X 나 Ctrl + C 로 프로세스를 중단시키는 것도 정상 종료의 범주에 들어야 할까? 관점에 따라 다르겠지만 일단 필자가 글을 통해 다루려는건 회복 불가능한 상태에 진입한 프로그램이다. Alt + X 나 Ctrl + C로 프로그램을 종료한다는건 사용자의 의도에 의해 프로그램이 종료되는 것이므로 이 글에서는 정상 종료로 간주한다.\n하지만 프로그램이 예기치 못한 상황에 직면하면 비정상 종료가 발생할 수 있다. 이는 마치 사람이 가서는 안 되는 곳 – 군사분계선 바깥 지역이나 은행 금고 등 -에 발을 들이거나, 다른 사람들에게 치명적인 피해를 입히는 행위를 했을 때 정부가 이를 제재하고 감옥으로 보내는 것과 비슷하다. 마찬가지로 OS도 시스템의 안정성을 위해 계약되지 않은 행위를 하는 프로그램을 강제로 종료시킨다. 시스템 메모리의 보호된 영역 또는 잘못된 주소를 참조하거나, 리소스를 과도하게 점유하는 경우 운영체제는 해당 프로그램을 강제로 종료하는데, 이것이 우리가 흔히 말하는 크래시이다.\n예외처리​\n이러한 갑작스러운 비정상 종료를 제어하기 위해 프로그래밍 언어와 운영체제는 예외처리 수단을 제공한다. 이 글에서는 OS 수준의 예외처리에 대해서만 다룬다.\nWindows: SEH(Structured Exception Handling)\nLinux: Signal\nmacOS: Mach Exception & Signal(Mach Exception의 우선순위가 더 높음)\n비교 표: 플랫폼별 관리 예외/신호\n\n문제 유형Windows (SEH)Linux (Signals)macOS (Mach + Signals)\n\n잘못된 메모리 접근STATUS_ACCESS_VIOLATIONSIGSEGV, SIGBUSSIGSEGV, SIGBUS, EXC_BAD_ACCESS\n스택 오버플로우STATUS_STACK_OVERFLOWSIGSEGV (간접적으로 발생)SIGSEGV (간접적으로 발생)\n잘못된 명령어STATUS_ILLEGAL_INSTRUCTIONSIGILLSIGILL, EXC_BAD_INSTRUCTION\n0으로 나누기 등STATUS_FLOAT_DIVIDE_BY_ZEROSIGFPESIGFPE, EXC_ARITHMETIC\n리소스 초과STATUS_INSUFFICIENT_RESOURCESSIGXCPU, SIGXFSZSIGXCPU, SIGXFSZ\n\n\n\n\n\nOS 별로 서로 다른 덤프 포맷​\n크래시가 발생하면 운영체제는 메모리 스냅샷을 기록하여 디버깅과 원인 분석에 활용한다. 그러나 각 운영체제는 크래시 시점의 메모리 상태를 저장하는 방식과 포맷이 서로 다르다. 각 OS는 고유의 덤프 포맷을 사용하여 크래시 상황을 분석하는 데 필요한 정보를 제공한다.\n1. Windows\nMinidump: Windows 운영체제는 Minidump 포맷을 사용하여 크래시 정보를 저장한다. Minidump는 크래시 원인을 분석하는 데 필요한 최소한의 정보를 포함하며, 파일 크기가 작아 전송과 분석이 용이하다. 보통은 힙을 포함하지 않으며, 옵션으로 힙 영역을 포함시키더라도 전체 내용을 포함하지 않기 때문에 파일 크기가 상대적으로 작다.\nFull Dump: 전체 메모리 덤프를 포함하여 크래시 시점의 모든 메모리 상태를 기록한다. 힙, 전역변수, 확장 레지스터, 기타 리소스 등의 모든 내용을 포함하여 파일 크기가 크고 분석이 복잡할 수 있다.\n2. Linux\nCore Dump: Linux 운영체제는 Core Dump 포맷을 사용하여 크래시 정보를 저장한다. Core Dump는 프로세스의 메모리 이미지와 레지스터 상태를 포함하며, 디버깅에 유용한 정보를 제공한다. 그러나 파일 크기가 크고 다루기 어려운 경우가 많다.\n3. macOS\nApple Crash Report: macOS는 Apple Crash Report 포맷을 사용하여 크래시 정보를 저장한다. 이 포맷은 크래시 시점의 스택 트레이스, 메모리 내용, 레지스터 상태 등을 포함하며, 분석을 위해 Xcode와 같은 도구와 함께 사용된다.\n4. Android\nTombstone: Android 운영체제는 Tombstone 포맷을 사용하여 크래시 정보를 저장한다. Tombstone은 크래시 시점의 스택 트레이스, 메모리 내용, 레지스터 상태 등을 포함하며, adb와 같은 도구를 사용하여 분석할 수 있다.\n이렇듯 각 운영체제의 덤프 포맷은 크래시 원인 분석에 필요한 정보를 제공하지만, 그 구조가 다르기 때문에 크로스 플랫폼 환경에서 어플리케이션을 배포하는 개발자는 파편화된 덤프 포맷을 일일이 관리해야 한다. 이는 고통스러운 작업이기에 덤프를 다루는 일관된 방법이 필요해지는 이유가 된다.\nMinidump Format 과 Chromium Breakpad Project​\n지금까지 우리가 알아본 것을 요약하면,\n프로그램은 정상적으로 실행되다가 예기치 못한 상황에 직면하면 비정상 종료한다.\n운영체제는 비정상 종료 시점의 메모리 스냅샷을 저장하여 디버깅과 원인 분석에 활용한다.\n각 운영체제는 프로그램의 메모리 적재 방식이 서로 다르며, 크래시 덤프 포맷도 다르다.\n또한 각 운영체제마다 예외를 처리하는 방식도 다르다.\n브라우저나 JVM, .NET 처럼 크로스 플랫폼 환경에서도 동일한 방식의 동작을 보장하는 레이어를 지닌 어플리케이션은 위와 같은 크래시 덤프의 수집 및 분석 시 파편화 문제가 크게 체감되지 않을 수 있다. 허나 여러 플랫폼 타겟을 지원하는 네이티브 어플리케이션의 경우, 이러한 크래시 파편화는 개발자가 문제를 찾기 어렵게 한다.\n2008년 9월, 구글은 Chromium이라는 오픈소스 웹브라우저 프로젝트를 발표하였는데, 이 프로젝트의 주요 목표 중 하나는 모든 플랫폼에서 일관된 사용자 경험을 제공하는데 있었다. 필연적으로 여러 플랫폼에서 발생하는 크래시 정보를 효과적으로 수집하고 분석하기 위한 수단이 필요했는데, 이를 위한 Chromium의 해결책이 바로 Breakpad Project이다.\nMicrosoft의 Minidump 포맷은 Breakpad에서 크로스플랫폼 환경에서 일관된 크래시 덤프 수집을 위해 채택한 형식이다. Breakpad Processor 디자인 문서에 따르면 왜 Minidump 포맷을 선택하였는지에 대한 이유가 자세히 기술되어 있다.\n경량화된 포맷: Minidump는 크래시 원인을 분석하는 데 필요한 최소한의 정보만을 포함하며, 파일 크기가 작아 전송과 분석이 용이하다.\n확장성: 다양한 CPU 아키텍처 및 운영체제를 지원하도록 설계되었으며, 다른 포맷들과는 다르게 확장이 용이하다.\n검증된 도구: Minidump 포맷은 Windows 운영체제에서 수 년간 검증된 포맷이기 때문에 안정성이 높으며, MS의 디버깅 도구들을 활용할 수 있다.\n눈치빠른 사람들은 여기서 아직 해결되지 못한 파편화 문제를 알아챌 것이다. 바로 Debugging Symbol인데, Minidump를 쓰더라도 플랫폼 별로 서로 다른 Symbol 포맷은 여전히 문제가 된다.\n이에 대한 Breakpad의 해법은 각 플랫폼의 Symbol을 Breakpad 만의 Human-Readable한 고유의 Symbol Format으로 변환하는 것이다.\n아래 그림은 Breakpad 프로젝트가 어떻게 동작하는지에 대한 개략적인 flow를 보여준다.\n\n\n\n\nBreakpad의 한계와 이를 개선하는 프로젝트들(Crashpad, Rust-Minidump)\n\n\n\n\nBreakpad Client를 사용해보면 가끔씩 제대로 된 덤프가 수집되지 않는 경우가 있다. Breakpad Client가 덤프를 생성할 충분한 시간을 확보하지 못하거나, 덤프 생성 중에 프로세스가 비정상 종료되는 경우가 그 예이다. 앞서 그림을 보면 Breakpad Client는 사용자의 어플리케이션 프로세스 내부에서 동작하도록 설계되어 있는데, 어플리케이션이 종료되는 상황에서는 Breakpad Client가 덤프를 생성할 충분한 시간을 확보하지 못할 수도 있다.\nCrashpad는 이러한 한계를 극복하기 위한 개선 프로젝트로, 별도의 Crash 수집 및 전송을 담당하는 Handler Process를 구성하여 이 문제를 해결하였다.\n\n\n\n\n한편, Chromium의 Breakpad가 쌓아놓은 유산을 토대로 RIIR(Re-write It in Rust)한 Rust-Minidump 프로젝트도 주목할 만 하다. 2017년 luser라는 개발자가 Rust User Forum에 처음으로 소개한 이 프로젝트는 Rust 언어로 작성하였다는 것 만으로도 다양한 장점(메모리 안정성, 속도, 사용 편의성)을 갖고 있을 뿐 아니라 Rust Crate의 확장성을 활용하여 사용자가 원하는 기능을 쉽게 추가할 수도 있다. 덤프 분석 결과물을 JSON 형태로 출력해주는 편의 기능이나 cli 도구도 제공하므로 덤프 분석을 원하는 개발자들은 다양한 용도로 활용이 가능할 것이다.\n결론​\n지금까지 크로스플랫폼 환경에서 발생하는 다양한 덤프를 수집하기 위해 알아야 하는 배경지식과, 파편화 문제를 해결해주는 Breakpad 프로젝트를 위시한 Crashpad, Rust-Minidump 등에 대해 알아보았다. 대개는 Sentry나 Google Crashlytics 등의 Managed Service를 사용하느라 직접 어플리케이션 덤프를 수집하고 분석할 일이 많지 않겠지만 어느 정도 규모가 있는 서비스를 운영, 직접 덤프를 수집하여야만 하는 개발자에게 이 글이 도움이 되길 바란다.",
        "dc:creator": "bahamoth",
        "comments": "https://01010011.blog/2024/11/20/%ed%98%b8%eb%9e%91%ec%9d%b4%eb%8a%94-%ec%a3%bd%ec%96%b4%ec%84%9c-%ea%b0%80%ec%a3%bd%ec%9d%84-%eb%82%a8%ea%b8%b0%ea%b3%a0-%ed%94%84%eb%a1%9c%ea%b7%b8%eb%9e%a8%ec%9d%80-%ec%a3%bd%ec%96%b4%ec%84%9c/#respond",
        "content": "서론 아무리 소프트웨어를 잘 만들었더라도 구동중인 프로그램이 사용자 환경에서 비정상 종료되는 문제는 필연적이다. 속된 말로 &#8216;프로그램이 죽는&#8217; 현상이 이러한 비정상 종료에 해당하는데, 개발자 입장에서는 왜 이러한 &#8216;죽음&#8217;이 발생하는지 파악이 어렵다. 왜냐하면 개발자의 PC에서는 프로그램이 죽지 않기 때문이다.(It works on my machine)너무도 다양한 사용자 환경은 기상천외한 문제를 일으킨다.(바닐라 아이스크림 알러지가 있는 자동차) 이러한 안타까운 죽음의 원인을 [&#8230;]",
        "contentSnippet": "서론 아무리 소프트웨어를 잘 만들었더라도 구동중인 프로그램이 사용자 환경에서 비정상 종료되는 문제는 필연적이다. 속된 말로 ‘프로그램이 죽는’ 현상이 이러한 비정상 종료에 해당하는데, 개발자 입장에서는 왜 이러한 ‘죽음’이 발생하는지 파악이 어렵다. 왜냐하면 개발자의 PC에서는 프로그램이 죽지 않기 때문이다.(It works on my machine)너무도 다양한 사용자 환경은 기상천외한 문제를 일으킨다.(바닐라 아이스크림 알러지가 있는 자동차) 이러한 안타까운 죽음의 원인을 […]",
        "guid": "https://01010011.blog/?p=2209",
        "categories": [
          "programming"
        ],
        "isoDate": "2024-11-20T12:59:33.000Z"
      }
    ]
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김놀부",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "이어폰 잭, 스마트폰에서 사라지는 이유",
        "link": "http://muzbox.tistory.com/483501",
        "pubDate": "Wed, 20 Nov 2024 11:15:22 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483501#entry483501comment",
        "content": "<p data-ke-size=\"size16\">아이폰부터 안드로이드까지 스마트폰에서 이어폰 잭이 사라지는 이유와 그에 따른 변화, 대안 기술 및 여전히 이어폰 잭을 탑재하는 기기의 트렌드를 살펴봅니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"500\" data-origin-height=\"333\"><span data-url=\"https://blog.kakaocdn.net/dn/cXrZxI/btsKPT8PUJM/OGoJSdoiqwtPnHIaWZloqK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cXrZxI/btsKPT8PUJM/OGoJSdoiqwtPnHIaWZloqK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cXrZxI/btsKPT8PUJM/OGoJSdoiqwtPnHIaWZloqK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcXrZxI%2FbtsKPT8PUJM%2FOGoJSdoiqwtPnHIaWZloqK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"이어폰 잭, 스마트폰에서 사라지는 이유\" data-origin-width=\"500\" data-origin-height=\"333\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;스마트폰은 현대인의 일상에서 빼놓을 수 없는 존재가 되었습니다. 이와 함께 이어폰은 음악 감상, 영상 시청, 게임 플레이 등 다양한 활동에서 중요한 도구로 자리 잡았습니다. 과거에는 이어폰 잭이 스마트폰에 필수적으로 포함되었지만, 최근에는 이어폰 잭이 사라지고 무선 이어폰이 그 자리를 대체하고 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이러한 변화는 단순히 기술 발전 때문만이 아니라, 스마트폰 제조사들의 설계와 제품 전략에 따른 결과입니다. 이어폰 잭이 사라진 이유와 이러한 변화가 소비자와 기술 산업에 미친 영향을 살펴보는 것은 흥미로운 주제입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이번 포스팅에서는 이어폰 잭의 퇴장 배경, 이어폰 잭이 여전히 필요한 이유, 그리고 앞으로의 기술 전망을 깊이 있게 살펴보겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>이어폰 잭의 퇴장 이유</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #f89009;\"><i><b>1. 스마트폰 디자인과 기능의 진화</b></i></span></h3>\n<p data-ke-size=\"size16\">&nbsp;이어폰 잭이 사라진 가장 큰 이유 중 하나는 <b>스마트폰 설계의 혁신</b>입니다. 스마트폰 내부 공간은 매우 한정적이며, 이어폰 잭은 크기와 구조상 많은 공간을 차지합니다. 이를 제거함으로써 스마트폰 제조사들은 더 얇고 가벼운 디자인을 실현하고, 확보된 공간을 활용해 더 큰 배터리나 향상된 카메라 센서를 추가할 수 있게 되었습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;예를 들어, 2016년 애플은 <b>아이폰 7</b>에서 이어폰 잭을 제거하며 이 공간을 방수 및 방진 기능 강화에 활용했습니다. 또한 이 모델을 통해 블루투스 연결 무선 이어폰인 <b>에어팟</b>을 발표하며 무선 기술 도입을 대중화했습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"500\" data-origin-height=\"375\"><span data-url=\"https://blog.kakaocdn.net/dn/cDnq21/btsKOb4chKb/2auVt0lR8mD9fXoJmAY57K/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cDnq21/btsKOb4chKb/2auVt0lR8mD9fXoJmAY57K/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cDnq21/btsKOb4chKb/2auVt0lR8mD9fXoJmAY57K/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcDnq21%2FbtsKOb4chKb%2F2auVt0lR8mD9fXoJmAY57K%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"500\" data-origin-height=\"375\"/></span></figure>\n</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #f89009;\"><i><b>2. 무선 기술의 발전</b></i></span></h3>\n<p data-ke-size=\"size16\">이어폰 잭의 퇴장은 무선 기술의 급격한 발전과 맞물려 있습니다. 블루투스 5.0 기술은 연결 안정성과 음질을 크게 개선했으며, 이를 통해 소비자들은 유선 이어폰에 비해 더욱 편리한 무선 이어폰을 선택하게 되었습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">또한 무선 이어폰의 보급이 확대되면서 가격도 다양해졌습니다. 초기에는 고가의 제품만 있었지만, 현재는 저렴한 무선 이어폰도 쉽게 구입할 수 있어 소비자의 선택지가 넓어졌습니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #f89009;\"><b>3. 새로운 수익 모델 창출</b></span></h3>\n<p data-ke-size=\"size16\">제조사 입장에서는 이어폰 잭 제거가 새로운 수익 창출 기회로 작용하기도 합니다. 애플이 에어팟을 통해 시장에서 성공을 거둔 것처럼, 제조사들은 자사 브랜드의 무선 이어폰을 소비자에게 판매하며 추가적인 매출을 올릴 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>여전히 이어폰 잭을 사용하는 스마트폰</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #f89009;\"><i><b>1. 실용성과 가성비를 중시하는 저가형 스마트폰</b></i></span></h3>\n<p data-ke-size=\"size16\">&nbsp;이어폰 잭이 사라지고 있는 와중에도, 일부 제조사들은 저가형 스마트폰에 이어폰 잭을 유지하고 있습니다. 이 스마트폰은 주로 <b>고령층 사용자</b>나 <b>경제적 여유가 부족한 계층</b>을 겨냥합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이러한 사용자층은 무선 이어폰의 사용법을 익히는 데 어려움을 느끼거나, 고가의 무선 이어폰을 구입하기 부담스러워합니다. 예를 들어, 일본의 <b>arrows We2</b>와 같은 스마트폰은 이어폰 잭을 유지함으로써 이들의 필요를 충족합니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #f89009;\"><i><b>2. 고음질을 중시하는 오디오 전문 스마트폰</b></i></span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1149\" data-origin-height=\"616\"><span data-url=\"https://blog.kakaocdn.net/dn/dphqQ9/btsKN5QIKb7/9Iz2Ka4rm1KveW5Ch41xR1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dphqQ9/btsKN5QIKb7/9Iz2Ka4rm1KveW5Ch41xR1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dphqQ9/btsKN5QIKb7/9Iz2Ka4rm1KveW5Ch41xR1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdphqQ9%2FbtsKN5QIKb7%2F9Iz2Ka4rm1KveW5Ch41xR1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"700\" height=\"375\" data-origin-width=\"1149\" data-origin-height=\"616\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;음질에 민감한 사용자들 사이에서는 여전히 유선 이어폰이 선호됩니다. 특히, 소니의 <b>Xperia 1 II</b>와 같은 스마트폰은 이어폰 잭을 유지하며 고품질 오디오 경험을 제공합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">소니는 자사의 강력한 오디오 기술을 활용해 <b>하이파이 음원</b>이나 <b>하이레졸루션 오디오</b>를 즐기고자 하는 사용자들에게 특별한 경험을 제공합니다. 이는 오디오 애호가들이 여전히 유선 이어폰을 선호하는 이유와 맞닿아 있습니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #f89009;\"><i><b>3. 게임 성능을 강조하는 게이밍 스마트폰</b></i></span></h3>\n<p data-ke-size=\"size16\">게이밍 스마트폰은 이어폰 잭을 필수적으로 포함하는 경우가 많습니다. 무선 연결은 지연 문제가 발생하기 쉬운데, 이는 <b>리듬 게임</b>이나 <b>슈팅 게임</b>과 같은 정확한 타이밍이 중요한 게임에서 치명적일 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>ASUS ROG Phone</b> 시리즈는 이러한 이유로 유선 이어폰 연결을 지원하며, 게이머들에게 최고의 성능을 제공합니다. 이는 게이밍 환경에서 유선 이어폰의 중요성을 잘 보여주는 사례입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>앞으로의 기술 전망</b></span></h2>\n<p data-ke-size=\"size16\">이어폰 잭의 퇴장은 기술과 소비자 트렌드의 변화에 따른 자연스러운 흐름으로 보입니다. 그러나 특정 사용자층의 요구는 여전히 존재하며, 이어폰 잭을 완전히 제거하는 것은 쉽지 않아 보입니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #f89009;\"><i><b>1. 혼합형 스마트폰의 등장</b></i></span></h3>\n<p data-ke-size=\"size16\">앞으로는 이어폰 잭과 무선 기술을 혼합하여 제공하는 스마트폰이 증가할 가능성이 있습니다. 이는 소비자에게 선택의 자유를 제공하고, 특정 니즈를 충족하기 위한 전략이 될 것입니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #f89009;\"><i><b>2. 블루투스 기술의 추가 발전</b></i></span></h3>\n<p data-ke-size=\"size16\">무선 연결의 지연 문제와 음질 저하를 극복하기 위해 블루투스 기술은 계속 발전하고 있습니다. 특히, <b>aptX Adaptive</b>나 <b>LDAC</b>와 같은 고급 코덱은 무선 환경에서도 뛰어난 음질을 제공하며, 유선의 필요성을 점점 줄여 나갈 것입니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #f89009;\"><i><b>3. 사용자 맞춤형 경험</b></i></span></h3>\n<p data-ke-size=\"size16\">스마트폰 제조사들은 이어폰 잭과 무선 기술의 공존을 넘어, 소비자 개개인의 라이프스타일에 맞춘 제품을 선보일 가능성이 큽니다. 이는 맞춤형 기능과 액세서리를 통해 이루어질 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>마치며</b></span></h2>\n<p data-ke-size=\"size16\">&nbsp;스마트폰에서 이어폰 잭이 사라지는 현상은 단순한 기술적 변화라기보다, 산업의 흐름과 소비자 니즈의 복합적인 결과입니다. 이어폰 잭의 제거는 스마트폰 설계와 성능에 긍정적인 영향을 미쳤고, 무선 기술의 대중화를 가속화했습니다. 하지만 여전히 이어폰 잭을 필요로 하는 소비자가 존재하며, 특정 사용자층과 제품 카테고리에서는 이어폰 잭이 유지되고 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1062\" data-origin-height=\"750\"><span data-url=\"https://blog.kakaocdn.net/dn/bne3VS/btsKPNOlMRK/Jl50GmJUyaRDjy1QlfbusK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bne3VS/btsKPNOlMRK/Jl50GmJUyaRDjy1QlfbusK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bne3VS/btsKPNOlMRK/Jl50GmJUyaRDjy1QlfbusK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbne3VS%2FbtsKPNOlMRK%2FJl50GmJUyaRDjy1QlfbusK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"스마트폰 오디오잭\" width=\"700\" height=\"494\" data-origin-width=\"1062\" data-origin-height=\"750\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;이어폰 잭의 퇴장과 무선 기술의 부상은 단순히 기술적 편의성을 넘어, 우리의 라이프스타일에 직접적인 변화를 가져왔습니다. 무선 이어폰은 더 자유롭고 간편한 사용을 제공하지만, 유선 이어폰만이 줄 수 있는 고음질과 안정성은 무시할 수 없는 장점으로 남아 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;앞으로의 기술 발전이 이러한 장점을 모두 아우를 수 있을지, 그리고 스마트폰 제조사들이 어떤 전략을 펼칠지 기대됩니다. 여러분도 스마트폰을 선택할 때, 자신의 사용 패턴과 라이프스타일에 맞는 기능을 꼼꼼히 따져 보세요. 기술은 우리 삶을 편리하게 해주는 도구일 뿐, 궁극적인 결정권은 항상 여러분에게 있다는 점을 잊지 마시길 바랍니다.  </p>",
        "contentSnippet": "아이폰부터 안드로이드까지 스마트폰에서 이어폰 잭이 사라지는 이유와 그에 따른 변화, 대안 기술 및 여전히 이어폰 잭을 탑재하는 기기의 트렌드를 살펴봅니다.\n\n\n \n 스마트폰은 현대인의 일상에서 빼놓을 수 없는 존재가 되었습니다. 이와 함께 이어폰은 음악 감상, 영상 시청, 게임 플레이 등 다양한 활동에서 중요한 도구로 자리 잡았습니다. 과거에는 이어폰 잭이 스마트폰에 필수적으로 포함되었지만, 최근에는 이어폰 잭이 사라지고 무선 이어폰이 그 자리를 대체하고 있습니다.\n \n이러한 변화는 단순히 기술 발전 때문만이 아니라, 스마트폰 제조사들의 설계와 제품 전략에 따른 결과입니다. 이어폰 잭이 사라진 이유와 이러한 변화가 소비자와 기술 산업에 미친 영향을 살펴보는 것은 흥미로운 주제입니다.\n \n이번 포스팅에서는 이어폰 잭의 퇴장 배경, 이어폰 잭이 여전히 필요한 이유, 그리고 앞으로의 기술 전망을 깊이 있게 살펴보겠습니다.\n \n \n이어폰 잭의 퇴장 이유\n1. 스마트폰 디자인과 기능의 진화\n 이어폰 잭이 사라진 가장 큰 이유 중 하나는 스마트폰 설계의 혁신입니다. 스마트폰 내부 공간은 매우 한정적이며, 이어폰 잭은 크기와 구조상 많은 공간을 차지합니다. 이를 제거함으로써 스마트폰 제조사들은 더 얇고 가벼운 디자인을 실현하고, 확보된 공간을 활용해 더 큰 배터리나 향상된 카메라 센서를 추가할 수 있게 되었습니다.\n \n 예를 들어, 2016년 애플은 아이폰 7에서 이어폰 잭을 제거하며 이 공간을 방수 및 방진 기능 강화에 활용했습니다. 또한 이 모델을 통해 블루투스 연결 무선 이어폰인 에어팟을 발표하며 무선 기술 도입을 대중화했습니다.\n\n\n2. 무선 기술의 발전\n이어폰 잭의 퇴장은 무선 기술의 급격한 발전과 맞물려 있습니다. 블루투스 5.0 기술은 연결 안정성과 음질을 크게 개선했으며, 이를 통해 소비자들은 유선 이어폰에 비해 더욱 편리한 무선 이어폰을 선택하게 되었습니다.\n \n또한 무선 이어폰의 보급이 확대되면서 가격도 다양해졌습니다. 초기에는 고가의 제품만 있었지만, 현재는 저렴한 무선 이어폰도 쉽게 구입할 수 있어 소비자의 선택지가 넓어졌습니다.\n3. 새로운 수익 모델 창출\n제조사 입장에서는 이어폰 잭 제거가 새로운 수익 창출 기회로 작용하기도 합니다. 애플이 에어팟을 통해 시장에서 성공을 거둔 것처럼, 제조사들은 자사 브랜드의 무선 이어폰을 소비자에게 판매하며 추가적인 매출을 올릴 수 있습니다.\n \n \n여전히 이어폰 잭을 사용하는 스마트폰\n1. 실용성과 가성비를 중시하는 저가형 스마트폰\n 이어폰 잭이 사라지고 있는 와중에도, 일부 제조사들은 저가형 스마트폰에 이어폰 잭을 유지하고 있습니다. 이 스마트폰은 주로 고령층 사용자나 경제적 여유가 부족한 계층을 겨냥합니다.\n \n이러한 사용자층은 무선 이어폰의 사용법을 익히는 데 어려움을 느끼거나, 고가의 무선 이어폰을 구입하기 부담스러워합니다. 예를 들어, 일본의 arrows We2와 같은 스마트폰은 이어폰 잭을 유지함으로써 이들의 필요를 충족합니다.\n2. 고음질을 중시하는 오디오 전문 스마트폰\n\n\n \n 음질에 민감한 사용자들 사이에서는 여전히 유선 이어폰이 선호됩니다. 특히, 소니의 Xperia 1 II와 같은 스마트폰은 이어폰 잭을 유지하며 고품질 오디오 경험을 제공합니다.\n \n소니는 자사의 강력한 오디오 기술을 활용해 하이파이 음원이나 하이레졸루션 오디오를 즐기고자 하는 사용자들에게 특별한 경험을 제공합니다. 이는 오디오 애호가들이 여전히 유선 이어폰을 선호하는 이유와 맞닿아 있습니다.\n3. 게임 성능을 강조하는 게이밍 스마트폰\n게이밍 스마트폰은 이어폰 잭을 필수적으로 포함하는 경우가 많습니다. 무선 연결은 지연 문제가 발생하기 쉬운데, 이는 리듬 게임이나 슈팅 게임과 같은 정확한 타이밍이 중요한 게임에서 치명적일 수 있습니다.\n \nASUS ROG Phone 시리즈는 이러한 이유로 유선 이어폰 연결을 지원하며, 게이머들에게 최고의 성능을 제공합니다. 이는 게이밍 환경에서 유선 이어폰의 중요성을 잘 보여주는 사례입니다.\n \n \n앞으로의 기술 전망\n이어폰 잭의 퇴장은 기술과 소비자 트렌드의 변화에 따른 자연스러운 흐름으로 보입니다. 그러나 특정 사용자층의 요구는 여전히 존재하며, 이어폰 잭을 완전히 제거하는 것은 쉽지 않아 보입니다.\n1. 혼합형 스마트폰의 등장\n앞으로는 이어폰 잭과 무선 기술을 혼합하여 제공하는 스마트폰이 증가할 가능성이 있습니다. 이는 소비자에게 선택의 자유를 제공하고, 특정 니즈를 충족하기 위한 전략이 될 것입니다.\n2. 블루투스 기술의 추가 발전\n무선 연결의 지연 문제와 음질 저하를 극복하기 위해 블루투스 기술은 계속 발전하고 있습니다. 특히, aptX Adaptive나 LDAC와 같은 고급 코덱은 무선 환경에서도 뛰어난 음질을 제공하며, 유선의 필요성을 점점 줄여 나갈 것입니다.\n3. 사용자 맞춤형 경험\n스마트폰 제조사들은 이어폰 잭과 무선 기술의 공존을 넘어, 소비자 개개인의 라이프스타일에 맞춘 제품을 선보일 가능성이 큽니다. 이는 맞춤형 기능과 액세서리를 통해 이루어질 것입니다.\n \n \n마치며\n 스마트폰에서 이어폰 잭이 사라지는 현상은 단순한 기술적 변화라기보다, 산업의 흐름과 소비자 니즈의 복합적인 결과입니다. 이어폰 잭의 제거는 스마트폰 설계와 성능에 긍정적인 영향을 미쳤고, 무선 기술의 대중화를 가속화했습니다. 하지만 여전히 이어폰 잭을 필요로 하는 소비자가 존재하며, 특정 사용자층과 제품 카테고리에서는 이어폰 잭이 유지되고 있습니다.\n\n\n \n 이어폰 잭의 퇴장과 무선 기술의 부상은 단순히 기술적 편의성을 넘어, 우리의 라이프스타일에 직접적인 변화를 가져왔습니다. 무선 이어폰은 더 자유롭고 간편한 사용을 제공하지만, 유선 이어폰만이 줄 수 있는 고음질과 안정성은 무시할 수 없는 장점으로 남아 있습니다.\n \n 앞으로의 기술 발전이 이러한 장점을 모두 아우를 수 있을지, 그리고 스마트폰 제조사들이 어떤 전략을 펼칠지 기대됩니다. 여러분도 스마트폰을 선택할 때, 자신의 사용 패턴과 라이프스타일에 맞는 기능을 꼼꼼히 따져 보세요. 기술은 우리 삶을 편리하게 해주는 도구일 뿐, 궁극적인 결정권은 항상 여러분에게 있다는 점을 잊지 마시길 바랍니다.",
        "guid": "http://muzbox.tistory.com/483501",
        "categories": [
          "ANDROID &amp; 모바일/안드로이드 꿀팁",
          "게이밍기기",
          "무선기술",
          "무선이어폰",
          "블루투스5",
          "블루투스이어폰",
          "스마트폰",
          "오디오마니아",
          "오디오잭",
          "이어폰잭"
        ],
        "isoDate": "2024-11-20T02:15:22.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "윈도우용 추천 프리웨어 (2024.11.18) SSD 진단, 시스템 안정성 테스트, 초고속 복사 프로그램, 파일명 변경, 폴더명 변경, 슬라이드쇼 만들기)",
        "link": "http://muzbox.tistory.com/483500",
        "pubDate": "Mon, 18 Nov 2024 08:46:52 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483500#entry483500comment",
        "content": "<p style=\"text-align: left;\" data-ke-size=\"size18\"><span style=\"background-color: #ffffff; color: #0d0d0d; text-align: start;\">&nbsp;네이버 소프트웨어와 같은 프로그램 소개 사이트가 종료된 후, 윈도우 운영체제를 사용하는 이용자들을 위해 공개 프리웨어 및 오픈소스 프로그램을 소개합니다. 유용한 무료 소프트웨어를 찾고자 하는 사용자들에게 정기적으로 알찬 정보를 제공합니다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"추천프리웨어241118.png\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/TI4no/btsKLpBnbWe/rZm04JDeKJgZ4JcQkFDpkk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/TI4no/btsKLpBnbWe/rZm04JDeKJgZ4JcQkFDpkk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/TI4no/btsKLpBnbWe/rZm04JDeKJgZ4JcQkFDpkk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FTI4no%2FbtsKLpBnbWe%2FrZm04JDeKJgZ4JcQkFDpkk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"추천프리웨어241118.png\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\"><span style=\"color: #333333; text-align: left;\">&nbsp;윈도우용 응용프로그램 (Application)은 수없이 많은 종류가 많은 개발자들에 의해 하루에도 수백,수천개가 새로 출시되고 그보다 더 많은 수의 프로그램들이 업데이트 됩니다. 이들 응용프로그램 (Application)은 비율을 지불해야하는<span>&nbsp;</span></span><b><span style=\"color: #009a87;\">상용프로그램</span></b><span style=\"color: #333333; text-align: left;\">과 정품 구매를 확대하기 위해 공급하는 일종의 샘플 개념의<span>&nbsp;</span></span><span style=\"color: #ee2323;\"><b>쉐어웨어</b></span><span style=\"color: #333333; text-align: left;\">, 무료로 사용할 수 있는<span>&nbsp;</span></span><b><span style=\"color: #ef6f53;\">프리웨어</span></b>등으로 크게 3가지로 나뉘게 되는데요.</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\"><br />&nbsp;물론 프리웨어에도 개인만 사용할 있다던가, 기업이나 관공서에서도 사용이 가능하다던가, 소스까지 같이 공개하여 맘대로 수정과 배포가 가능한 완전 무료등의 추가 분류가 필요합니다. 하지만, 개발자가 공개하는 무료배포의 의미가 정확하지 않는 프로그램도 많고, 저작권의 정의도 각양각색이라 본 블로그에서 소개하는 프리웨어도<span>&nbsp;</span><span style=\"color: #006dd7;\"><b>최대한 확인이 가능한 범위에서 개인 또는 기업에서 사용가능한지를 구분하여 소개</b></span>하고 있습니다.</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\">&nbsp;</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\">&nbsp;</p>\n<p style=\"text-align: center;\" data-ke-size=\"size18\">'어떤오후의 프리웨어 이야기'에서 추천하는<br /><span style=\"color: #409d00;\">&nbsp;<b>2024년 11월 18일자 공개자료실 윈도우용 추천 프리웨어</b></span>입니다.</p>\n<p id=\"no_1\" data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000;\" data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>1. ADATA&nbsp;SSD&nbsp;Toolbox&nbsp;(ADATA&nbsp;SSD&nbsp;진단/최적화/정보확인)<br /></b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp; 사용자가&nbsp;SSD&nbsp;디스크&nbsp;정보를&nbsp;확인하고&nbsp;설정을&nbsp;쉽게&nbsp;변경할&nbsp;수&nbsp;있도록&nbsp;다양한&nbsp;기능을&nbsp;제공하는&nbsp;프로그램입니다.&nbsp;이&nbsp;도구는&nbsp;SSD의&nbsp;속도&nbsp;향상과&nbsp;내구성&nbsp;유지를&nbsp;지원하며,&nbsp;다음과&nbsp;같은&nbsp;주요&nbsp;기능을&nbsp;포함합니다. <br /><br />1.&nbsp;드라이브&nbsp;정보&nbsp;확인:&nbsp;드라이브의&nbsp;용량,&nbsp;사용&nbsp;공간,&nbsp;온도,&nbsp;상태,&nbsp;수명&nbsp;등을&nbsp;상세히&nbsp;조회할&nbsp;수&nbsp;있습니다. <br />2.&nbsp;진단&nbsp;기능:&nbsp;빠른&nbsp;진단을&nbsp;통해&nbsp;선택된&nbsp;드라이브의&nbsp;사용&nbsp;가능한&nbsp;공간을&nbsp;간단히&nbsp;테스트하고,&nbsp;정밀&nbsp;진단을&nbsp;통해&nbsp;사용된&nbsp;모든&nbsp;공간에&nbsp;대한&nbsp;읽기&nbsp;테스트를&nbsp;수행합니다. <br />3.&nbsp;유틸리티&nbsp;제공:&nbsp;보안&nbsp;삭제(Security&nbsp;Erase),&nbsp;펌웨어&nbsp;업데이트,&nbsp;SSD&nbsp;Toolbox&nbsp;업그레이드,&nbsp;로그&nbsp;내보내기&nbsp;등의&nbsp;기능을&nbsp;제공합니다. <br />4.&nbsp;시스템&nbsp;최적화:&nbsp;TRIM&nbsp;서비스와&nbsp;간단한&nbsp;설정을&nbsp;통해&nbsp;SSD와&nbsp;운영&nbsp;체제를&nbsp;최적화합니다. <br />5.&nbsp;시스템&nbsp;정보&nbsp;표시:&nbsp;현재&nbsp;시스템의&nbsp;하드웨어&nbsp;정보를&nbsp;제공합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"ADATA SSD Toolbox.png\" data-origin-width=\"1161\" data-origin-height=\"699\"><span data-url=\"https://blog.kakaocdn.net/dn/bACOI8/btsKMYJgvRQ/8S8ZkeZhmKLe657aqD1uB0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bACOI8/btsKMYJgvRQ/8S8ZkeZhmKLe657aqD1uB0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bACOI8/btsKMYJgvRQ/8S8ZkeZhmKLe657aqD1uB0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbACOI8%2FbtsKMYJgvRQ%2F8S8ZkeZhmKLe657aqD1uB0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"ADATA SSD Toolbox.png\" data-origin-width=\"1161\" data-origin-height=\"699\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶ 프리웨어 - 개인</p>\n<p data-ke-size=\"size18\">▶ Windows 10/11</p>\n<p data-ke-size=\"size18\">▶무료 다운로드◀</p>\n<figure id=\"og_1731886982402\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"다운로드 | ADATA (Korea)\" data-og-description=\"\" data-og-host=\"www.adata.com\" data-og-source-url=\"https://www.adata.com/kr/support/downloads/\" data-og-url=\"https://www.adata.com/kr/support/downloads/\" data-og-image=\"\"><a href=\"https://www.adata.com/kr/support/downloads/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.adata.com/kr/support/downloads/\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">다운로드 | ADATA (Korea)</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">&nbsp;</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.adata.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"no_2\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000;\" data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>2. OCCT&nbsp;(시스템&nbsp;안정성&nbsp;테스트)</b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp; 개인&nbsp;사용자에게&nbsp;무료로&nbsp;제공되는&nbsp;강력한&nbsp;PC&nbsp;모니터링&nbsp;및&nbsp;안정성&nbsp;점검&nbsp;도구입니다.&nbsp;프로그램을&nbsp;실행하면&nbsp;PC와&nbsp;GPU&nbsp;관련&nbsp;시스템&nbsp;정보를&nbsp;즉시&nbsp;확인할&nbsp;수&nbsp;있으며,&nbsp;시스템&nbsp;온도,&nbsp;CPU&nbsp;전압,&nbsp;RAM&nbsp;사용량&nbsp;등의&nbsp;변화를&nbsp;시간에&nbsp;따라&nbsp;그래프로&nbsp;표시합니다. <br /><br />이&nbsp;도구는&nbsp;단순한&nbsp;모니터링에&nbsp;그치지&nbsp;않고,&nbsp;CPU,&nbsp;GPU,&nbsp;전원&nbsp;공급&nbsp;장치를&nbsp;테스트하여&nbsp;시스템의&nbsp;온도와&nbsp;전압&nbsp;변화&nbsp;등을&nbsp;자세히&nbsp;분석할&nbsp;수&nbsp;있습니다.&nbsp;특히,&nbsp;시스템을&nbsp;오버클럭한&nbsp;후에는&nbsp;PC의&nbsp;안정성을&nbsp;확인하는&nbsp;데&nbsp;유용합니다. <br /><br />다만,&nbsp;이처럼&nbsp;컴퓨터를&nbsp;스트레스&nbsp;테스트하면&nbsp;과열로&nbsp;인해&nbsp;손상이&nbsp;발생할&nbsp;수도&nbsp;있습니다.&nbsp;그러나&nbsp;테스트&nbsp;중에&nbsp;발생하는&nbsp;변화를&nbsp;주의&nbsp;깊게&nbsp;관찰하면&nbsp;문제를&nbsp;방지할&nbsp;수&nbsp;있으며,&nbsp;OCCT는&nbsp;특정&nbsp;값이&nbsp;과도하게&nbsp;높아지면&nbsp;자동으로&nbsp;테스트를&nbsp;중단하도록&nbsp;설정할&nbsp;수도&nbsp;있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"occt.png\" data-origin-width=\"768\" data-origin-height=\"545\"><span data-url=\"https://blog.kakaocdn.net/dn/dbcW6S/btsKNeLRD1W/iV5Ca9l3k5NxDh8ZUM8oxK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dbcW6S/btsKNeLRD1W/iV5Ca9l3k5NxDh8ZUM8oxK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dbcW6S/btsKNeLRD1W/iV5Ca9l3k5NxDh8ZUM8oxK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdbcW6S%2FbtsKNeLRD1W%2FiV5Ca9l3k5NxDh8ZUM8oxK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"occt.png\" data-origin-width=\"768\" data-origin-height=\"545\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인</p>\n<p data-ke-size=\"size18\">▶Windows 10/11</p>\n<p data-ke-size=\"size18\">▶무료 다운로드</p>\n<figure id=\"og_1731887000912\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"OCBASE/OCCT : Free, all-in-one stability, stress test, benchmark and monitoring tool for your PC\" data-og-description=\"What's in the box OCCT will analyze every major components of your systems with complete portability. Its modern and ergonomic interface provides a smooth and efficient user experience. In close collaboration with manufacturers, OCCT remains at the forefro\" data-og-host=\"www.ocbase.com\" data-og-source-url=\"https://www.ocbase.com/\" data-og-url=\"https://www.ocbase.com/\" data-og-image=\"https://scrap.kakaocdn.net/dn/bpLDq6/hyXzU8v9Sa/Q6Q7pG8YFksS3yGilEK5Lk/img.jpg?width=1920&amp;height=1280&amp;face=0_0_1920_1280,https://scrap.kakaocdn.net/dn/b1LlzJ/hyXzQZmFcK/JlCkp6GraPDe9bXDqs8lT0/img.jpg?width=1624&amp;height=1080&amp;face=0_0_1624_1080,https://scrap.kakaocdn.net/dn/dtTMQr/hyXzINL8rn/DHswKbZ4pC17PNiURlpa4K/img.png?width=1287&amp;height=757&amp;face=0_0_1287_757\"><a href=\"https://www.ocbase.com/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.ocbase.com/\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/bpLDq6/hyXzU8v9Sa/Q6Q7pG8YFksS3yGilEK5Lk/img.jpg?width=1920&amp;height=1280&amp;face=0_0_1920_1280,https://scrap.kakaocdn.net/dn/b1LlzJ/hyXzQZmFcK/JlCkp6GraPDe9bXDqs8lT0/img.jpg?width=1624&amp;height=1080&amp;face=0_0_1624_1080,https://scrap.kakaocdn.net/dn/dtTMQr/hyXzINL8rn/DHswKbZ4pC17PNiURlpa4K/img.png?width=1287&amp;height=757&amp;face=0_0_1287_757');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">OCBASE/OCCT : Free, all-in-one stability, stress test, benchmark and monitoring tool for your PC</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">What's in the box OCCT will analyze every major components of your systems with complete portability. Its modern and ergonomic interface provides a smooth and efficient user experience. In close collaboration with manufacturers, OCCT remains at the forefro</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.ocbase.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"no_3\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000;\" data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>3. Ultracopier&nbsp;(빠르고&nbsp;안정적인&nbsp;초고속&nbsp;복사&nbsp;프로그램) <br /></b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp;Windows 운영체제에서 파일 복사, 이동, 전송 작업을 더욱 빠르고 안전하게 수행하기 위한 고급 소프트웨어입니다. 내장된 파일 복사 대화 상자를 대체하여, 사용자에게 다양한 설정 옵션과 도구를 제공하여 파일 관리 과정을 향상시킵니다. 특히 대용량 파일을 다루거나 중요한 프로젝트 파일을 안전하게 관리해야 하는 전문 사용자에게 유용합니다. <br /><br />이&nbsp;소프트웨어는&nbsp;일시&nbsp;정지&nbsp;및&nbsp;재개&nbsp;기능,&nbsp;동적&nbsp;속도&nbsp;제한,&nbsp;오류&nbsp;감지&nbsp;후&nbsp;전송&nbsp;재개,&nbsp;파일&nbsp;충돌&nbsp;관리&nbsp;등&nbsp;다양한&nbsp;고급&nbsp;기능을&nbsp;지원합니다.&nbsp;사용자는&nbsp;전송&nbsp;규칙을&nbsp;설정하거나&nbsp;여러&nbsp;복사&nbsp;작업을&nbsp;대기열에&nbsp;추가해&nbsp;시스템&nbsp;리소스를&nbsp;효율적으로&nbsp;관리할&nbsp;수&nbsp;있습니다.&nbsp;또한,&nbsp;플러그인&nbsp;지원을&nbsp;통해&nbsp;기능을&nbsp;확장할&nbsp;수&nbsp;있고,&nbsp;포터블&nbsp;버전을&nbsp;제공하여&nbsp;설치&nbsp;없이&nbsp;외부&nbsp;장치에서도&nbsp;사용할&nbsp;수&nbsp;있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Ultracopier.png\" data-origin-width=\"1157\" data-origin-height=\"605\"><span data-url=\"https://blog.kakaocdn.net/dn/PHk2n/btsKL2TqqrF/KDpRRF4wrIdHCWrYzVyJlk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/PHk2n/btsKL2TqqrF/KDpRRF4wrIdHCWrYzVyJlk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/PHk2n/btsKL2TqqrF/KDpRRF4wrIdHCWrYzVyJlk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FPHk2n%2FbtsKL2TqqrF%2FKDpRRF4wrIdHCWrYzVyJlk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Ultracopier.png\" data-origin-width=\"1157\" data-origin-height=\"605\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶ 프리웨어 - 개인</p>\n<p data-ke-size=\"size18\">▶Windows 10/11&nbsp;</p>\n<p data-ke-size=\"size18\">▶무료 다운로드 ◀</p>\n<figure id=\"og_1731887032451\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"Ultracopier, best tools for copying files\" data-og-description=\"Ultracopier your file copy software Ultracopier acts as a replacement for files copy dialogs. Help you into daily file management as professional or advanced user Trusty software used by millions around the world Control you data Save time by reduce mistak\" data-og-host=\"ultracopier.herman-brule.com\" data-og-source-url=\"https://ultracopier.herman-brule.com/\" data-og-url=\"https://ultracopier.herman-brule.com/\" data-og-image=\"https://scrap.kakaocdn.net/dn/d8VeuE/hyXzINL8S7/qABxqaqwlLSMR5sd4uYDjK/img.png?width=1&amp;height=1&amp;face=0_0_1_1,https://scrap.kakaocdn.net/dn/bG81jW/hyXzImH8bK/0hYh1Qk3rGsxtexBllzfsk/img.png?width=1&amp;height=1&amp;face=0_0_1_1,https://scrap.kakaocdn.net/dn/bJuunh/hyXzKx25X5/1TPRsyZaQ1CCgszT514PV1/img.png?width=856&amp;height=659&amp;face=0_0_856_659\"><a href=\"https://ultracopier.herman-brule.com/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://ultracopier.herman-brule.com/\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/d8VeuE/hyXzINL8S7/qABxqaqwlLSMR5sd4uYDjK/img.png?width=1&amp;height=1&amp;face=0_0_1_1,https://scrap.kakaocdn.net/dn/bG81jW/hyXzImH8bK/0hYh1Qk3rGsxtexBllzfsk/img.png?width=1&amp;height=1&amp;face=0_0_1_1,https://scrap.kakaocdn.net/dn/bJuunh/hyXzKx25X5/1TPRsyZaQ1CCgszT514PV1/img.png?width=856&amp;height=659&amp;face=0_0_856_659');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Ultracopier, best tools for copying files</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Ultracopier your file copy software Ultracopier acts as a replacement for files copy dialogs. Help you into daily file management as professional or advanced user Trusty software used by millions around the world Control you data Save time by reduce mistak</p>\n<p class=\"og-host\" data-ke-size=\"size16\">ultracopier.herman-brule.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"no_4\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000;\" data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>4. Advanced&nbsp;Renamer&nbsp;(강력한&nbsp;파일,폴더&nbsp;이름&nbsp;변경)<br /></b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp;여러 파일과 폴더를 한 번에 이름을 변경할 수 있는 무료 프로그램으로, 다양한 방식으로 파일 이름을 조작할 수 있도록 14가지의 리네이밍 방법을 제공합니다. 이 도구를 사용하면 파일의 이름, 속성, 타임스탬프를 한꺼번에 변경할 수 있으며, 파일 정보를 바탕으로 파일을 새로운 위치로 복사하거나 이동할 수도 있습니다. 복잡한 일괄 작업을 설정한 후에는 변경 결과를 미리 확인할 수 있고, 잘못된 경우 언제든지 전체 작업을 되돌릴 수 있습니다. <br /><br />특히&nbsp;이미지&nbsp;파일&nbsp;관리에&nbsp;유용하여,&nbsp;썸네일&nbsp;모드로&nbsp;파일&nbsp;목록을&nbsp;시각적으로&nbsp;확인하면서&nbsp;사진을&nbsp;손쉽게&nbsp;정리할&nbsp;수&nbsp;있습니다.&nbsp;GPS&nbsp;데이터가&nbsp;포함된&nbsp;사진의&nbsp;경우,&nbsp;파일명에&nbsp;촬영된&nbsp;도시와&nbsp;국가&nbsp;이름을&nbsp;자동으로&nbsp;추가할&nbsp;수&nbsp;있습니다.&nbsp;또한,&nbsp;음악&nbsp;파일의&nbsp;경우&nbsp;내장된&nbsp;ID3&nbsp;기능을&nbsp;통해&nbsp;복잡한&nbsp;파일명을&nbsp;깔끔하게&nbsp;정리할&nbsp;수&nbsp;있고,&nbsp;비디오&nbsp;파일에는&nbsp;코덱&nbsp;정보나&nbsp;해상도를&nbsp;파일명에&nbsp;추가할&nbsp;수&nbsp;있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Advanced Renamer.jpg\" data-origin-width=\"1728\" data-origin-height=\"1077\"><span data-url=\"https://blog.kakaocdn.net/dn/dsC5pV/btsKK3yNalp/jinBOdiKg7nkYBuRcwgF8k/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/dsC5pV/btsKK3yNalp/jinBOdiKg7nkYBuRcwgF8k/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/dsC5pV/btsKK3yNalp/jinBOdiKg7nkYBuRcwgF8k/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdsC5pV%2FbtsKK3yNalp%2FjinBOdiKg7nkYBuRcwgF8k%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Advanced Renamer.jpg\" data-origin-width=\"1728\" data-origin-height=\"1077\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인</p>\n<p data-ke-size=\"size18\">▶Windows 10/11</p>\n<p data-ke-size=\"size18\">▶무료 다운로드 ◀</p>\n<figure id=\"og_1731887054448\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Advanced Renamer - Batch file renaming for Windows and macOS\" data-og-description=\"Image file formats .jpg, .jpeg, .jif, .jfif, .jfi, .jps, .mpo, .png, .apng, .gif, .bmp, .tiff, .tif, .dng, .cr2, .3fr, .arw, .srf, .sr2, .pef, .dcr, .kdc, .erf, .nrw, .nef, .orf, .rw2, .webp, .heic, .cr3, .heif, .hif, .avci, .ico, .cur, .psd, .xcf, .svg Vi\" data-og-host=\"www.advancedrenamer.com\" data-og-source-url=\"https://www.advancedrenamer.com/\" data-og-url=\"https://www.advancedrenamer.com/\" data-og-image=\"https://scrap.kakaocdn.net/dn/TYitK/hyXzOHeHYm/xS5KHKWhQbTJ82gmtHcpkk/img.png?width=1726&amp;height=1075&amp;face=0_0_1726_1075\"><a href=\"https://www.advancedrenamer.com/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.advancedrenamer.com/\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/TYitK/hyXzOHeHYm/xS5KHKWhQbTJ82gmtHcpkk/img.png?width=1726&amp;height=1075&amp;face=0_0_1726_1075');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Advanced Renamer - Batch file renaming for Windows and macOS</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Image file formats .jpg, .jpeg, .jif, .jfif, .jfi, .jps, .mpo, .png, .apng, .gif, .bmp, .tiff, .tif, .dng, .cr2, .3fr, .arw, .srf, .sr2, .pef, .dcr, .kdc, .erf, .nrw, .nef, .orf, .rw2, .webp, .heic, .cr3, .heif, .hif, .avci, .ico, .cur, .psd, .xcf, .svg Vi</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.advancedrenamer.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"no_5\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000;\" data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>5. Icecream Slideshow Maker (슬라이드쇼 만들기)</b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp; 사진과&nbsp;음악을&nbsp;사용해&nbsp;고품질&nbsp;슬라이드쇼를&nbsp;손쉽게&nbsp;제작할&nbsp;수&nbsp;있는&nbsp;강력한&nbsp;프로그램입니다.&nbsp;사용자는&nbsp;직관적인&nbsp;인터페이스와&nbsp;간단한&nbsp;조작으로&nbsp;슬라이드쇼를&nbsp;구성할&nbsp;수&nbsp;있으며,&nbsp;JPG,&nbsp;PNG,&nbsp;TIFF&nbsp;등&nbsp;다양한&nbsp;이미지&nbsp;형식과&nbsp;MP3,&nbsp;WAV&nbsp;등&nbsp;오디오&nbsp;파일을&nbsp;지원합니다.&nbsp;각&nbsp;사진의&nbsp;표시&nbsp;시간과&nbsp;전환&nbsp;효과를&nbsp;조정할&nbsp;수&nbsp;있으며,&nbsp;26가지&nbsp;전환&nbsp;효과를&nbsp;선택할&nbsp;수&nbsp;있습니다. <br /><br />이&nbsp;프로그램은&nbsp;내장된&nbsp;미디어&nbsp;플레이어를&nbsp;통해&nbsp;슬라이드쇼를&nbsp;미리보기할&nbsp;수&nbsp;있으며,&nbsp;효과를&nbsp;적용하기&nbsp;전에&nbsp;확인할&nbsp;수&nbsp;있습니다.&nbsp;또한,&nbsp;YouTube&nbsp;업로드&nbsp;버튼을&nbsp;제공하여&nbsp;슬라이드쇼를&nbsp;즉시&nbsp;YouTube&nbsp;채널에&nbsp;게시할&nbsp;수&nbsp;있습니다.&nbsp;이러한&nbsp;기능&nbsp;덕분에&nbsp;초보자와&nbsp;고급&nbsp;사용자&nbsp;모두&nbsp;손쉽게&nbsp;활용할&nbsp;수&nbsp;있는&nbsp;유용한&nbsp;도구입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Icecream Slideshow Maker.png\" data-origin-width=\"908\" data-origin-height=\"511\"><span data-url=\"https://blog.kakaocdn.net/dn/QGl9u/btsKMJldtil/HnSuT1V8WedKuvcUxSfJU1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/QGl9u/btsKMJldtil/HnSuT1V8WedKuvcUxSfJU1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/QGl9u/btsKMJldtil/HnSuT1V8WedKuvcUxSfJU1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FQGl9u%2FbtsKMJldtil%2FHnSuT1V8WedKuvcUxSfJU1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Icecream Slideshow Maker.png\" data-origin-width=\"908\" data-origin-height=\"511\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인</p>\n<p data-ke-size=\"size18\">▶Windows 10/11</p>\n<p data-ke-size=\"size18\">▶무료 다운로드 ◀</p>\n<figure id=\"og_1731887088855\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Free Slideshow Maker for Windows - Icecream Apps\" data-og-description=\"Make a beautiful photo slideshow with music with our Slideshow Maker. Free version for Windows. Create slideshows for weddings, birthdays, travel, etc.\" data-og-host=\"icecreamapps.com\" data-og-source-url=\"https://icecreamapps.com/Slideshow-Maker/\" data-og-url=\"https://icecreamapps.com/Slideshow-Maker/\" data-og-image=\"https://scrap.kakaocdn.net/dn/ezUbfJ/hyXzV0EzoL/aPJ8QsrOcaChKCbrub6NAk/img.png?width=1024&amp;height=512&amp;face=0_0_1024_512\"><a href=\"https://icecreamapps.com/Slideshow-Maker/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://icecreamapps.com/Slideshow-Maker/\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/ezUbfJ/hyXzV0EzoL/aPJ8QsrOcaChKCbrub6NAk/img.png?width=1024&amp;height=512&amp;face=0_0_1024_512');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Free Slideshow Maker for Windows - Icecream Apps</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Make a beautiful photo slideshow with music with our Slideshow Maker. Free version for Windows. Create slideshows for weddings, birthdays, travel, etc.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">icecreamapps.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "네이버 소프트웨어와 같은 프로그램 소개 사이트가 종료된 후, 윈도우 운영체제를 사용하는 이용자들을 위해 공개 프리웨어 및 오픈소스 프로그램을 소개합니다. 유용한 무료 소프트웨어를 찾고자 하는 사용자들에게 정기적으로 알찬 정보를 제공합니다.\n\n\n 윈도우용 응용프로그램 (Application)은 수없이 많은 종류가 많은 개발자들에 의해 하루에도 수백,수천개가 새로 출시되고 그보다 더 많은 수의 프로그램들이 업데이트 됩니다. 이들 응용프로그램 (Application)은 비율을 지불해야하는 상용프로그램과 정품 구매를 확대하기 위해 공급하는 일종의 샘플 개념의 쉐어웨어, 무료로 사용할 수 있는 프리웨어등으로 크게 3가지로 나뉘게 되는데요.\n 물론 프리웨어에도 개인만 사용할 있다던가, 기업이나 관공서에서도 사용이 가능하다던가, 소스까지 같이 공개하여 맘대로 수정과 배포가 가능한 완전 무료등의 추가 분류가 필요합니다. 하지만, 개발자가 공개하는 무료배포의 의미가 정확하지 않는 프로그램도 많고, 저작권의 정의도 각양각색이라 본 블로그에서 소개하는 프리웨어도 최대한 확인이 가능한 범위에서 개인 또는 기업에서 사용가능한지를 구분하여 소개하고 있습니다.\n \n \n'어떤오후의 프리웨어 이야기'에서 추천하는\n 2024년 11월 18일자 공개자료실 윈도우용 추천 프리웨어입니다.\n \n \n1. ADATA SSD Toolbox (ADATA SSD 진단/최적화/정보확인)\n\n  사용자가 SSD 디스크 정보를 확인하고 설정을 쉽게 변경할 수 있도록 다양한 기능을 제공하는 프로그램입니다. 이 도구는 SSD의 속도 향상과 내구성 유지를 지원하며, 다음과 같은 주요 기능을 포함합니다. \n1. 드라이브 정보 확인: 드라이브의 용량, 사용 공간, 온도, 상태, 수명 등을 상세히 조회할 수 있습니다. \n2. 진단 기능: 빠른 진단을 통해 선택된 드라이브의 사용 가능한 공간을 간단히 테스트하고, 정밀 진단을 통해 사용된 모든 공간에 대한 읽기 테스트를 수행합니다. \n3. 유틸리티 제공: 보안 삭제(Security Erase), 펌웨어 업데이트, SSD Toolbox 업그레이드, 로그 내보내기 등의 기능을 제공합니다. \n4. 시스템 최적화: TRIM 서비스와 간단한 설정을 통해 SSD와 운영 체제를 최적화합니다. \n5. 시스템 정보 표시: 현재 시스템의 하드웨어 정보를 제공합니다.\n\n\n▶ 프리웨어 - 개인\n▶ Windows 10/11\n▶무료 다운로드◀\n\n \n다운로드 | ADATA (Korea)\n \nwww.adata.com\n\n \n \n \n \n \n2. OCCT (시스템 안정성 테스트)\n  개인 사용자에게 무료로 제공되는 강력한 PC 모니터링 및 안정성 점검 도구입니다. 프로그램을 실행하면 PC와 GPU 관련 시스템 정보를 즉시 확인할 수 있으며, 시스템 온도, CPU 전압, RAM 사용량 등의 변화를 시간에 따라 그래프로 표시합니다. \n이 도구는 단순한 모니터링에 그치지 않고, CPU, GPU, 전원 공급 장치를 테스트하여 시스템의 온도와 전압 변화 등을 자세히 분석할 수 있습니다. 특히, 시스템을 오버클럭한 후에는 PC의 안정성을 확인하는 데 유용합니다. \n다만, 이처럼 컴퓨터를 스트레스 테스트하면 과열로 인해 손상이 발생할 수도 있습니다. 그러나 테스트 중에 발생하는 변화를 주의 깊게 관찰하면 문제를 방지할 수 있으며, OCCT는 특정 값이 과도하게 높아지면 자동으로 테스트를 중단하도록 설정할 수도 있습니다.\n\n\n▶프리웨어 - 개인\n▶Windows 10/11\n▶무료 다운로드\n\n \nOCBASE/OCCT : Free, all-in-one stability, stress test, benchmark and monitoring tool for your PC\nWhat's in the box OCCT will analyze every major components of your systems with complete portability. Its modern and ergonomic interface provides a smooth and efficient user experience. In close collaboration with manufacturers, OCCT remains at the forefro\nwww.ocbase.com\n\n \n \n \n \n \n3. Ultracopier (빠르고 안정적인 초고속 복사 프로그램) \n\n Windows 운영체제에서 파일 복사, 이동, 전송 작업을 더욱 빠르고 안전하게 수행하기 위한 고급 소프트웨어입니다. 내장된 파일 복사 대화 상자를 대체하여, 사용자에게 다양한 설정 옵션과 도구를 제공하여 파일 관리 과정을 향상시킵니다. 특히 대용량 파일을 다루거나 중요한 프로젝트 파일을 안전하게 관리해야 하는 전문 사용자에게 유용합니다. \n이 소프트웨어는 일시 정지 및 재개 기능, 동적 속도 제한, 오류 감지 후 전송 재개, 파일 충돌 관리 등 다양한 고급 기능을 지원합니다. 사용자는 전송 규칙을 설정하거나 여러 복사 작업을 대기열에 추가해 시스템 리소스를 효율적으로 관리할 수 있습니다. 또한, 플러그인 지원을 통해 기능을 확장할 수 있고, 포터블 버전을 제공하여 설치 없이 외부 장치에서도 사용할 수 있습니다.\n\n\n▶ 프리웨어 - 개인\n▶Windows 10/11 \n▶무료 다운로드 ◀\n\n \nUltracopier, best tools for copying files\nUltracopier your file copy software Ultracopier acts as a replacement for files copy dialogs. Help you into daily file management as professional or advanced user Trusty software used by millions around the world Control you data Save time by reduce mistak\nultracopier.herman-brule.com\n\n \n \n \n \n \n4. Advanced Renamer (강력한 파일,폴더 이름 변경)\n\n 여러 파일과 폴더를 한 번에 이름을 변경할 수 있는 무료 프로그램으로, 다양한 방식으로 파일 이름을 조작할 수 있도록 14가지의 리네이밍 방법을 제공합니다. 이 도구를 사용하면 파일의 이름, 속성, 타임스탬프를 한꺼번에 변경할 수 있으며, 파일 정보를 바탕으로 파일을 새로운 위치로 복사하거나 이동할 수도 있습니다. 복잡한 일괄 작업을 설정한 후에는 변경 결과를 미리 확인할 수 있고, 잘못된 경우 언제든지 전체 작업을 되돌릴 수 있습니다. \n특히 이미지 파일 관리에 유용하여, 썸네일 모드로 파일 목록을 시각적으로 확인하면서 사진을 손쉽게 정리할 수 있습니다. GPS 데이터가 포함된 사진의 경우, 파일명에 촬영된 도시와 국가 이름을 자동으로 추가할 수 있습니다. 또한, 음악 파일의 경우 내장된 ID3 기능을 통해 복잡한 파일명을 깔끔하게 정리할 수 있고, 비디오 파일에는 코덱 정보나 해상도를 파일명에 추가할 수 있습니다.\n\n\n▶프리웨어 - 개인\n▶Windows 10/11\n▶무료 다운로드 ◀\n\n \nAdvanced Renamer - Batch file renaming for Windows and macOS\nImage file formats .jpg, .jpeg, .jif, .jfif, .jfi, .jps, .mpo, .png, .apng, .gif, .bmp, .tiff, .tif, .dng, .cr2, .3fr, .arw, .srf, .sr2, .pef, .dcr, .kdc, .erf, .nrw, .nef, .orf, .rw2, .webp, .heic, .cr3, .heif, .hif, .avci, .ico, .cur, .psd, .xcf, .svg Vi\nwww.advancedrenamer.com\n\n \n \n \n \n \n5. Icecream Slideshow Maker (슬라이드쇼 만들기)\n  사진과 음악을 사용해 고품질 슬라이드쇼를 손쉽게 제작할 수 있는 강력한 프로그램입니다. 사용자는 직관적인 인터페이스와 간단한 조작으로 슬라이드쇼를 구성할 수 있으며, JPG, PNG, TIFF 등 다양한 이미지 형식과 MP3, WAV 등 오디오 파일을 지원합니다. 각 사진의 표시 시간과 전환 효과를 조정할 수 있으며, 26가지 전환 효과를 선택할 수 있습니다. \n이 프로그램은 내장된 미디어 플레이어를 통해 슬라이드쇼를 미리보기할 수 있으며, 효과를 적용하기 전에 확인할 수 있습니다. 또한, YouTube 업로드 버튼을 제공하여 슬라이드쇼를 즉시 YouTube 채널에 게시할 수 있습니다. 이러한 기능 덕분에 초보자와 고급 사용자 모두 손쉽게 활용할 수 있는 유용한 도구입니다.\n\n\n▶프리웨어 - 개인\n▶Windows 10/11\n▶무료 다운로드 ◀\n\n \nFree Slideshow Maker for Windows - Icecream Apps\nMake a beautiful photo slideshow with music with our Slideshow Maker. Free version for Windows. Create slideshows for weddings, birthdays, travel, etc.\nicecreamapps.com",
        "guid": "http://muzbox.tistory.com/483500",
        "categories": [
          "NEWS/프리웨어 뉴스",
          "sd 진단",
          "공개자료실",
          "무료프로그램",
          "슬라이드쇼 만들기",
          "시스템 안정성 테스트",
          "초고속 복사 프로그램",
          "추천프로그램",
          "파일명 변경",
          "폴더명 변경",
          "프리웨어"
        ],
        "isoDate": "2024-11-17T23:46:52.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "｜RULIWEB｜",
        "title": "[게임툰] 폰으로 즐기는 포케카 배틀! 포켓몬 카드 게임 Pocket",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2268",
        "pubDate": "Fri, 22 Nov 2024 20:25:52 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/24/11/22/193539d2e4651ad6b.jpg\">",
        "contentSnippet": "",
        "categories": [
          "게임툰"
        ],
        "isoDate": "2024-11-22T11:25:52.000Z"
      },
      {
        "creator": "샤말란의눈",
        "title": "[MULTI] 지스타 2024, 취재·컨퍼런스 등 관련 기사 종합",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2267",
        "pubDate": "Mon, 18 Nov 2024 00:01:48 +0900",
        "author": "샤말란의눈",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i1.ruliweb.com/thumb/24/10/25/192c1c605f513b2a1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "특집"
        ],
        "isoDate": "2024-11-17T15:01:48.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "기업살인과 댓글부대 / PD수첩 / 선동 하는 방법",
        "link": "http://serverdown.tistory.com/998",
        "pubDate": "Sat, 23 Nov 2024 04:13:44 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/998#entry998comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=BgBLY1B2irk\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=BgBLY1B2irk</a></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=BgBLY1B2irk\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/BzzzQ/hyXzPmZmBG/SyT5pWuvD7ft2zMl8MP5K0/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360,https://scrap.kakaocdn.net/dn/chrXsZ/hyXDgJYaEH/pFoxxcAjKX8WQrAdP4MQ11/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360\" data-video-width=\"480\" data-video-height=\"360\" data-video-origin-width=\"480\" data-video-origin-height=\"360\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"[PD수첩] 기업살인과 댓글부대 - 2024년 4월 2일 밤 9시\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/BgBLY1B2irk\" width=\"480\" height=\"360\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">경쟁 기업이 여러가지를 조작했군요.</p>\n<p data-ke-size=\"size16\">여기서 알 수 있는 사실은</p>\n<p data-ke-size=\"size16\">댓글을 1년 조작하는데는 2,500만원 정도들고</p>\n<p data-ke-size=\"size16\">맘카페를 조작하면 경쟁자를 제거할 수 있군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">예전 회사에서 신사업으로 키드 레스토랑 카페를 하려고 했는데</p>\n<p data-ke-size=\"size16\">1년쯤 하니까 이상한 일이 마구 생기더군요.</p>\n<p data-ke-size=\"size16\">아이가 레스토랑에서 다쳤다던지 (그날도 아니고 아니고 다음날 와서)<br />먹고 배탈 나싸던지&nbsp; (혼자만)</p>\n<p data-ke-size=\"size16\">탕시엔 cctv 같은게 없었는데 지금 생각해보면 정말 이상한 현상이였는데<br />몇년 지나보니 경쟁사에서 공격한거 같다는 소문이 있었습니다.</p>\n<p data-ke-size=\"size16\">아무튼 신사업은 1년 더하고 접었던걸로 기억납니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상 마지막엔 법으로 어쩌구 하는데</p>\n<p data-ke-size=\"size16\">매번드는 생각이 법이 없어서 이런일이 난게 아닙니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">제 시간 내에 처리되지 않아서 일이 커지는걸 막을 수 없었던 것입니다.</p>\n<p data-ke-size=\"size16\">믿었던 인증 기관은 공작에 당해 인증을 취소하질 않나.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">PD 수첩은 매번 법을 어쩌구 하는데</p>\n<p data-ke-size=\"size16\">제 경험상 이말은 \"안될껄?\" 이라는 듯 입니다.<br />단지 마지막에 훈훈하게 끝내고 싶었던 것이겠죠..</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"676\" data-origin-height=\"199\"><span data-url=\"https://blog.kakaocdn.net/dn/dzftVL/btsKVyXten4/bHAXzqv0bebWqI3PkqHrxK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dzftVL/btsKVyXten4/bHAXzqv0bebWqI3PkqHrxK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dzftVL/btsKVyXten4/bHAXzqv0bebWqI3PkqHrxK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdzftVL%2FbtsKVyXten4%2FbHAXzqv0bebWqI3PkqHrxK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"676\" data-origin-height=\"199\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">올해 제가 당했던 인버스 사건입니다.</p>\n<p data-ke-size=\"size16\">금투세가 주식시장을 약화시기고 있는 가운데 굳이 \"우린 세금 겆을 것이다., 떨어질꺼 같으면 인버스 사라\" 라고 한 사건입니다.&nbsp;</p>\n<p data-ke-size=\"size16\">모든것은 본인들이 이기기위해 무엇이든 한다는 것입니다. <br />그것이 나라 팔아먹는 일이라도 이기는 것이 중요하기 때문입니다. <br />그것이 국회의원이라도 다르지 않았던거 같습니다.</p>\n<p data-ke-size=\"size16\">결국 단기적으로는 저 시점으로 해서 인버스를 사는게 맞았습니다.<br />코인과 미국 주식을 사는게 맞았던 것이죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">목적이 분명한 사람의 행동은 놀랍도록 강력합니다.</p>\n<p data-ke-size=\"size16\">그게 좋은일이 아니더라도 ...</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=BgBLY1B2irk\n \n\n\n\n경쟁 기업이 여러가지를 조작했군요.\n여기서 알 수 있는 사실은\n댓글을 1년 조작하는데는 2,500만원 정도들고\n맘카페를 조작하면 경쟁자를 제거할 수 있군요\n \n예전 회사에서 신사업으로 키드 레스토랑 카페를 하려고 했는데\n1년쯤 하니까 이상한 일이 마구 생기더군요.\n아이가 레스토랑에서 다쳤다던지 (그날도 아니고 아니고 다음날 와서)\n먹고 배탈 나싸던지  (혼자만)\n탕시엔 cctv 같은게 없었는데 지금 생각해보면 정말 이상한 현상이였는데\n몇년 지나보니 경쟁사에서 공격한거 같다는 소문이 있었습니다.\n아무튼 신사업은 1년 더하고 접었던걸로 기억납니다.\n \n영상 마지막엔 법으로 어쩌구 하는데\n매번드는 생각이 법이 없어서 이런일이 난게 아닙니다.\n \n제 시간 내에 처리되지 않아서 일이 커지는걸 막을 수 없었던 것입니다.\n믿었던 인증 기관은 공작에 당해 인증을 취소하질 않나.\n \nPD 수첩은 매번 법을 어쩌구 하는데\n제 경험상 이말은 \"안될껄?\" 이라는 듯 입니다.\n단지 마지막에 훈훈하게 끝내고 싶었던 것이겠죠..\n \n\n\n올해 제가 당했던 인버스 사건입니다.\n금투세가 주식시장을 약화시기고 있는 가운데 굳이 \"우린 세금 겆을 것이다., 떨어질꺼 같으면 인버스 사라\" 라고 한 사건입니다. \n모든것은 본인들이 이기기위해 무엇이든 한다는 것입니다. \n그것이 나라 팔아먹는 일이라도 이기는 것이 중요하기 때문입니다. \n그것이 국회의원이라도 다르지 않았던거 같습니다.\n결국 단기적으로는 저 시점으로 해서 인버스를 사는게 맞았습니다.\n코인과 미국 주식을 사는게 맞았던 것이죠.\n \n목적이 분명한 사람의 행동은 놀랍도록 강력합니다.\n그게 좋은일이 아니더라도 ...",
        "guid": "http://serverdown.tistory.com/998",
        "categories": [
          "유튜브",
          "선동",
          "오블완",
          "조작",
          "티스토리챌린지"
        ],
        "isoDate": "2024-11-22T19:13:44.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "삼국지 납득이 된다 / 신해석 삼국지 / 일본 / 영화",
        "link": "http://serverdown.tistory.com/997",
        "pubDate": "Fri, 22 Nov 2024 18:19:50 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/997#entry997comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=go62t6k_SyU&amp;t=59s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=go62t6k_SyU&amp;t=59s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=go62t6k_SyU\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bLDJvf/hyXzIagh4x/Avyun9KZbq5wi1leAi6JN1/img.jpg?width=1280&amp;height=720&amp;face=238_254_730_590,https://scrap.kakaocdn.net/dn/cmBYUd/hyXDhoxMZJ/vzy2jivI4hcQxjlFlkIXk0/img.jpg?width=1280&amp;height=720&amp;face=238_254_730_590\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"약빨고 B급으로 만든 코미디 인 줄 알았는데 ㅋㅋㅋ 의외로 말이 되는 느낌의 니뽄 삼국지\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/go62t6k_SyU\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">넷플리스에 있다구</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=go62t6k_SyU&t=59s\n\n\n\n넷플리스에 있다구",
        "guid": "http://serverdown.tistory.com/997",
        "categories": [
          "유튜브",
          "일드"
        ],
        "isoDate": "2024-11-22T09:19:50.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "맛탱이가 간 두개의 코인을 사서 묵혀두자 / LUNC / FTT",
        "link": "http://serverdown.tistory.com/996",
        "pubDate": "Fri, 22 Nov 2024 13:55:02 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/996#entry996comment",
        "content": "<p data-ke-size=\"size16\">주요 메이저 종목은 비트코인, 리플, 도지코인 입니다.</p>\n<p data-ke-size=\"size16\">수익이 나셨다면 맛탱이가 간 코인들을 조금 사모아요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=3Yg7AQ_QYfs\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=3Yg7AQ_QYfs</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=3Yg7AQ_QYfs\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cDjrdD/hyXDdfj3VH/LmoFdKBz6DUgxuaBIJryU1/img.jpg?width=480&amp;height=360&amp;face=385_210_430_259,https://scrap.kakaocdn.net/dn/bK0ELk/hyXDgb2BVT/QSlpj8R0eyyUtVjzH1IZmK/img.jpg?width=480&amp;height=360&amp;face=385_210_430_259\" data-video-width=\"480\" data-video-height=\"360\" data-video-origin-width=\"480\" data-video-origin-height=\"360\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"권도형은 도대체 왜 몬테네그로에서 나오지 못하고 있는가\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/3Yg7AQ_QYfs\" width=\"480\" height=\"360\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">영상은 업비트 재상장인데 이런 맛탱이간 뉴스가 압니다.</p>\n<p data-ke-size=\"size16\">이분은 예전부터 루나 클래식을 부르짓었습니다.</p>\n<p data-ke-size=\"size16\">제가 찾아온 코인은 LUNC / FTT 입니다.</p>\n<p data-ke-size=\"size16\">LUNC 는 2년전에 망한 루나사태의 그 코인의 다음버전입니다. 원본은 완전 망해서 없어졌습니다.</p>\n<p data-ke-size=\"size16\">그리고 FTT 는 FTX 사태로 망한 그 거래소의 지분을 상징하는 코인입니다.</p>\n<p data-ke-size=\"size16\">이 두개는 망한 채권 같은것입니다.</p>\n<p data-ke-size=\"size16\">그만큼 가격이 떨어져있구요</p>\n<p data-ke-size=\"size16\">이게 왜 오르냐 한다면</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">LUNC <span style=\"text-align: start;\"><span>&nbsp;</span>/ 바이낸스에 있습니다.</span></h2>\n<p data-ke-size=\"size16\">영상에 보시면 루나는 망했기 때문에 회사 지분을 모두 소각해야한다는 법원의 판단이 나올 수 있습니다.</p>\n<p data-ke-size=\"size16\">소각되면 수량이 줄어들게 되겠죠</p>\n<p data-ke-size=\"size16\">법원의 판단으로 가는 계획이구요.</p>\n<p data-ke-size=\"size16\">권도형은 현재 감오에 있구요.</p>\n<p data-ke-size=\"size16\">비트코인이 오름으로서 그가 숨겨놓은 자산도 올랐을 가능성이 있습니다.</p>\n<p data-ke-size=\"size16\">당시 루나는 거의 가치를 상실했기 때문에 본인 자금으로 매꾸면 피해복구가 가능할 수도 있습니다.</p>\n<p data-ke-size=\"size16\">이부분은 거의 10년 쯤 소요될 것같군요.</p>\n<p data-ke-size=\"size16\">그러면 더 자산이 올라와 있어서 피해복구가 쉬워질것입니다.</p>\n<p data-ke-size=\"size16\">시간과의 싸음이라는 뜻입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">FTT / 바이낸스에 있습니다.</p>\n<p data-ke-size=\"size16\">뽀글이도 감옥에 가긴했는데</p>\n<p data-ke-size=\"size16\">FTX 를 다시 살릴 가능성이 있습니다.&nbsp;</p>\n<p data-ke-size=\"size16\">뽀글이는 권도형과 다르게 실제로 떡상할 회사들을 투자했습니다. 대표적으로 스페이스X 죠</p>\n<p data-ke-size=\"size16\">그래서 그의 실제 자산이 올라버려서 피해 복구가 가능할 것으로 판단됩니다.</p>\n<p data-ke-size=\"size16\">그러다보면 FTX 도 다시 살아날 수 있겠죠</p>\n<p data-ke-size=\"size16\">현재 FTX 는 거의 98% 폭락했습니다.</p>\n<p data-ke-size=\"size16\">이것도 사서 그냥 묵혀 두면 살아나지 않는가 하는 마음으로 살짝 투자해볼 필요가 있겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">그리고 베이비도지코인</h2>\n<p data-ke-size=\"size16\">80% 를 소각할까 고민중에 있습니다.</p>\n<p data-ke-size=\"size16\">시바이누의 상승도 엄청난양의 소각 뉴스 이후에 일어났습니다.</p>\n<p data-ke-size=\"size16\">소각이 결정된다면 엄청나게 오를 가능성이 있습니다.</p>\n<p data-ke-size=\"size16\">소간 할까 한지 1년쯤 지난거 같군요.</p>\n<p data-ke-size=\"size16\">언젠간 하겠죠</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">투가 권고 사항</h2>\n<p data-ke-size=\"size16\">소개해드린 투자 상품은 극도로 위험하며 부실한 자산입니다.</p>\n<p data-ke-size=\"size16\">전자산의 1% 이하로만 투자하는게 원칙입니다.</p>\n<p data-ke-size=\"size16\">그리고 시간을 녹이세요 1~10년이 걸릴 수 있습니다.</p>\n<p data-ke-size=\"size16\">이런 자산은 욕심부리시면 안되니 절대로 많은 비중을 들고계시면 안되고 특히 떨어진다고 물타셔도 안됩니다.</p>\n<p data-ke-size=\"size16\">얼마나 떨어질지 예상이 불가능 합니다.</p>\n<p data-ke-size=\"size16\">시간을 녹이세요!</p>",
        "contentSnippet": "주요 메이저 종목은 비트코인, 리플, 도지코인 입니다.\n수익이 나셨다면 맛탱이가 간 코인들을 조금 사모아요\n \n영상: https://www.youtube.com/watch?v=3Yg7AQ_QYfs\n\n\n\n영상은 업비트 재상장인데 이런 맛탱이간 뉴스가 압니다.\n이분은 예전부터 루나 클래식을 부르짓었습니다.\n제가 찾아온 코인은 LUNC / FTT 입니다.\nLUNC 는 2년전에 망한 루나사태의 그 코인의 다음버전입니다. 원본은 완전 망해서 없어졌습니다.\n그리고 FTT 는 FTX 사태로 망한 그 거래소의 지분을 상징하는 코인입니다.\n이 두개는 망한 채권 같은것입니다.\n그만큼 가격이 떨어져있구요\n이게 왜 오르냐 한다면\n \nLUNC  / 바이낸스에 있습니다.\n영상에 보시면 루나는 망했기 때문에 회사 지분을 모두 소각해야한다는 법원의 판단이 나올 수 있습니다.\n소각되면 수량이 줄어들게 되겠죠\n법원의 판단으로 가는 계획이구요.\n권도형은 현재 감오에 있구요.\n비트코인이 오름으로서 그가 숨겨놓은 자산도 올랐을 가능성이 있습니다.\n당시 루나는 거의 가치를 상실했기 때문에 본인 자금으로 매꾸면 피해복구가 가능할 수도 있습니다.\n이부분은 거의 10년 쯤 소요될 것같군요.\n그러면 더 자산이 올라와 있어서 피해복구가 쉬워질것입니다.\n시간과의 싸음이라는 뜻입니다.\n \nFTT / 바이낸스에 있습니다.\n뽀글이도 감옥에 가긴했는데\nFTX 를 다시 살릴 가능성이 있습니다. \n뽀글이는 권도형과 다르게 실제로 떡상할 회사들을 투자했습니다. 대표적으로 스페이스X 죠\n그래서 그의 실제 자산이 올라버려서 피해 복구가 가능할 것으로 판단됩니다.\n그러다보면 FTX 도 다시 살아날 수 있겠죠\n현재 FTX 는 거의 98% 폭락했습니다.\n이것도 사서 그냥 묵혀 두면 살아나지 않는가 하는 마음으로 살짝 투자해볼 필요가 있겠습니다.\n \n그리고 베이비도지코인\n80% 를 소각할까 고민중에 있습니다.\n시바이누의 상승도 엄청난양의 소각 뉴스 이후에 일어났습니다.\n소각이 결정된다면 엄청나게 오를 가능성이 있습니다.\n소간 할까 한지 1년쯤 지난거 같군요.\n언젠간 하겠죠\n \n투가 권고 사항\n소개해드린 투자 상품은 극도로 위험하며 부실한 자산입니다.\n전자산의 1% 이하로만 투자하는게 원칙입니다.\n그리고 시간을 녹이세요 1~10년이 걸릴 수 있습니다.\n이런 자산은 욕심부리시면 안되니 절대로 많은 비중을 들고계시면 안되고 특히 떨어진다고 물타셔도 안됩니다.\n얼마나 떨어질지 예상이 불가능 합니다.\n시간을 녹이세요!",
        "guid": "http://serverdown.tistory.com/996",
        "categories": [
          "투자",
          "babydoge",
          "FTT",
          "lunc",
          "코인",
          "투자"
        ],
        "isoDate": "2024-11-22T04:55:02.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "자율주행 시대가 오면 자동차회사들의 미래는 ... / 깁학주 교수",
        "link": "http://serverdown.tistory.com/995",
        "pubDate": "Fri, 22 Nov 2024 00:23:19 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/995#entry995comment",
        "content": "<p data-ke-size=\"size16\">전체 내용은 내년에 좋을만한 주식을 추천해주시네요<br />2024-11-22 이니 날짜 참고해주시구요. 이상한 시기에 보시고 투자하시면 큰일납니다.</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">자율주행 및 차사고가 안나는 사회 이야기는 너무 먼 이야기니까 투자에 반영하진 마시구요</span></p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://youtu.be/mhm5GkKR8pY?t=2228\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://youtu.be/mhm5GkKR8pY?t=2228</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=mhm5GkKR8pY\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cHZMYh/hyXzJmCzNx/jkdjlPHW7XnTbiozgGkbkK/img.jpg?width=1280&amp;height=720&amp;face=166_396_1152_568,https://scrap.kakaocdn.net/dn/bvlxpi/hyXzVHk5tE/w63m7mPZOUWIKM400Gg720/img.jpg?width=1280&amp;height=720&amp;face=166_396_1152_568\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\" [19시 생방송] 돌고 도는 순환매 장세...변동성은 더 극대화 (김학주, 곽상준, 김민수, 유영화) |\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/mhm5GkKR8pY\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">37분에 나옵니다.</p>\n<p data-ke-size=\"size16\">자율주행이 가능해지면 이런 문제들이 생깁니다.</p>\n<p data-ke-size=\"size16\">1. 차를 가질 필요가 있는가?<br />부르면 올테고<br />주차안해도 되고</p>\n<p data-ke-size=\"size16\">2. 사고가 안나게 되면<br />안전성이 약화되면서 아무나 차를 만들 수 있게됨<br /><br /></p>\n<p data-ke-size=\"size16\">먼 미래 였지만 트럼프 - 일론 머스크가 엮이게 되면서 자율주행 택시가 잘 될것 같습니다.</p>\n<p data-ke-size=\"size16\">한 결국 시간이 지나서 자동차 사고가 0 이되어버린다면&nbsp;</p>\n<p data-ke-size=\"size16\">차를 종이로 만들어도 팔 수 있는 시대가 되지 않겠냐 하는 망상을 해볼 수도 있습니다.</p>\n<p data-ke-size=\"size16\">그때가 올꺼라고 확신하는 분이셨습니다.</p>\n<p data-ke-size=\"size16\">지금은 신차 팔아야죠</p>\n<p data-ke-size=\"size16\">나중엔 UAM 이나 도시 설계를 해야할 수도 있겠군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "전체 내용은 내년에 좋을만한 주식을 추천해주시네요\n2024-11-22 이니 날짜 참고해주시구요. 이상한 시기에 보시고 투자하시면 큰일납니다.\n자율주행 및 차사고가 안나는 사회 이야기는 너무 먼 이야기니까 투자에 반영하진 마시구요\n영상: https://youtu.be/mhm5GkKR8pY?t=2228\n\n\n\n37분에 나옵니다.\n자율주행이 가능해지면 이런 문제들이 생깁니다.\n1. 차를 가질 필요가 있는가?\n부르면 올테고\n주차안해도 되고\n2. 사고가 안나게 되면\n안전성이 약화되면서 아무나 차를 만들 수 있게됨\n\n먼 미래 였지만 트럼프 - 일론 머스크가 엮이게 되면서 자율주행 택시가 잘 될것 같습니다.\n한 결국 시간이 지나서 자동차 사고가 0 이되어버린다면 \n차를 종이로 만들어도 팔 수 있는 시대가 되지 않겠냐 하는 망상을 해볼 수도 있습니다.\n그때가 올꺼라고 확신하는 분이셨습니다.\n지금은 신차 팔아야죠\n나중엔 UAM 이나 도시 설계를 해야할 수도 있겠군요",
        "guid": "http://serverdown.tistory.com/995",
        "categories": [
          "유튜브",
          "오블완",
          "자동차",
          "자율주행",
          "티스토리챌린지"
        ],
        "isoDate": "2024-11-21T15:23:19.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "RG556 / 스트리트 파이터 3 실행해보기",
        "link": "http://serverdown.tistory.com/994",
        "pubDate": "Thu, 21 Nov 2024 22:14:55 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/994#entry994comment",
        "content": "<p data-ke-size=\"size16\">처음에 사서 제대로 실행이 안되길래 포기했다 거의 3달만아에 다시 도전하였습니다.</p>\n<p data-ke-size=\"size16\">잘못된 설명으로 고생한거였더군요</p>\n<p data-ke-size=\"size16\">FB Neo CPS3 라는게 있는데 이게 아니였습니다.</p>\n<p data-ke-size=\"size16\">레딧 질문: <a href=\"https://www.reddit.com/r/PlaystationClassic/comments/f3r73l/help_running_street_fighter_3_new_generation_on/?rdt=52304\">Help running Street Fighter 3 New Generation on RetroArch (FB 2012 core) : r/PlaystationClassic</a></p>\n<figure id=\"og_1732194561100\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"From the PlaystationClassic community on Reddit\" data-og-description=\"Explore this post and more from the PlaystationClassic community\" data-og-host=\"www.reddit.com\" data-og-source-url=\"https://www.reddit.com/r/PlaystationClassic/comments/f3r73l/help_running_street_fighter_3_new_generation_on/?rdt=52304\" data-og-url=\"https://www.reddit.com/r/PlaystationClassic/comments/f3r73l/help_running_street_fighter_3_new_generation_on/?rdt=52304\" data-og-image=\"https://scrap.kakaocdn.net/dn/3CCyy/hyXDmJX4Ky/mC8RNdA1dxi16xFxmbCVOk/img.jpg?width=1120&amp;height=584&amp;face=0_0_1120_584,https://scrap.kakaocdn.net/dn/xrnBS/hyXDkrUBKs/r5kf6umB5GhrEMik9aefg0/img.jpg?width=1120&amp;height=584&amp;face=0_0_1120_584\"><a href=\"https://www.reddit.com/r/PlaystationClassic/comments/f3r73l/help_running_street_fighter_3_new_generation_on/?rdt=52304\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.reddit.com/r/PlaystationClassic/comments/f3r73l/help_running_street_fighter_3_new_generation_on/?rdt=52304\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/3CCyy/hyXDmJX4Ky/mC8RNdA1dxi16xFxmbCVOk/img.jpg?width=1120&amp;height=584&amp;face=0_0_1120_584,https://scrap.kakaocdn.net/dn/xrnBS/hyXDkrUBKs/r5kf6umB5GhrEMik9aefg0/img.jpg?width=1120&amp;height=584&amp;face=0_0_1120_584');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">From the PlaystationClassic community on Reddit</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Explore this post and more from the PlaystationClassic community</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.reddit.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">여기에선 FB Neo 를 고르라는데<br />밑에 누구는 FBA NEO 라고 하고 정신없습니다.</p>\n<p data-ke-size=\"size16\">정답은 Final Burn NEO 였습니다. ㅎㅎ</p>\n<p data-ke-size=\"size16\">롬은 여기에 있군요: <a href=\"https://wowroms.com/en/roms/mame/street-fighter-iii-new-generation-asia-clone/106260.html\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://wowroms.com/en/roms/mame/street-fighter-iii-new-generation-asia-clone/106260.html</a></p>\n<p data-ke-size=\"size16\">이 사이트에 많은 롬을 제공해줍니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">1. RetroArch 를 실행합니다.</p>\n<p data-ke-size=\"size16\">2. 코어를&nbsp; FinalBurn NEO 으로 선택합니다.</p>\n<p data-ke-size=\"size16\">3. 다운로드한 스파3 파일을 선택합니다.</p>\n<p data-ke-size=\"size16\">4. 압축파일을 선택 <br />(첫번째 선택지가 압축파일 내부를 보겠냐는 거 같군요)</p>\n<p data-ke-size=\"size16\">게임 실행됩니당 굿굿</p>\n<p data-ke-size=\"size16\">버튼도 설정해야되서<br />나중에 스샷 넣어서 좀더 제대로 써야겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "처음에 사서 제대로 실행이 안되길래 포기했다 거의 3달만아에 다시 도전하였습니다.\n잘못된 설명으로 고생한거였더군요\nFB Neo CPS3 라는게 있는데 이게 아니였습니다.\n레딧 질문: Help running Street Fighter 3 New Generation on RetroArch (FB 2012 core) : r/PlaystationClassic\n\n \nFrom the PlaystationClassic community on Reddit\nExplore this post and more from the PlaystationClassic community\nwww.reddit.com\n\n여기에선 FB Neo 를 고르라는데\n밑에 누구는 FBA NEO 라고 하고 정신없습니다.\n정답은 Final Burn NEO 였습니다. ㅎㅎ\n롬은 여기에 있군요: https://wowroms.com/en/roms/mame/street-fighter-iii-new-generation-asia-clone/106260.html\n이 사이트에 많은 롬을 제공해줍니다.\n \n1. RetroArch 를 실행합니다.\n2. 코어를  FinalBurn NEO 으로 선택합니다.\n3. 다운로드한 스파3 파일을 선택합니다.\n4. 압축파일을 선택 \n(첫번째 선택지가 압축파일 내부를 보겠냐는 거 같군요)\n게임 실행됩니당 굿굿\n버튼도 설정해야되서\n나중에 스샷 넣어서 좀더 제대로 써야겠습니다.",
        "guid": "http://serverdown.tistory.com/994",
        "categories": [
          "게임",
          "rg556",
          "게임"
        ],
        "isoDate": "2024-11-21T13:14:55.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "비트코인으로 미국 정부 부채를 해결하는 시나리오 / BTC / USDT",
        "link": "http://serverdown.tistory.com/993",
        "pubDate": "Thu, 21 Nov 2024 16:32:01 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/993#entry993comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=yn2al5DxFb0\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=yn2al5DxFb0</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=yn2al5DxFb0\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/LmoKx/hyXDit2Acd/NSAv52wk0jDTscR1xRyxN1/img.jpg?width=1280&amp;height=720&amp;face=146_54_1142_380,https://scrap.kakaocdn.net/dn/txWrg/hyXzNCuEla/JktiCpeQygYIjsN3zADbLk/img.jpg?width=1280&amp;height=720&amp;face=146_54_1142_380\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"트럼프의 전략자산 핵심은...비트코인 결국 '여기'까지 올라간다 (오태민) | 인포맥스라이브 202411\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/yn2al5DxFb0\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">미국 국채 수요 때문입니다.</p>\n<p data-ke-size=\"size16\">여기서 핵심은 정부부채를 줄이는게 아닙니다. \"해결하겠다\" 입니다.</p>\n<p data-ke-size=\"size16\">미국이 미국 국채를 금리 인상없이 발행할 수 만 있다면 정부부채는 게속 늘어도 괜찮습니다.</p>\n<p data-ke-size=\"size16\">그런데 비트코인인가?</p>\n<p data-ke-size=\"size16\">그것은 바로 USDT 때문입니다.</p>\n<h2 data-ke-size=\"size26\">USDT 와 미국 국채의 관계</h2>\n<p data-ke-size=\"size16\">대부분의 코인은 USDT 로 거래합니다. 코인 시장이 커진다면 USDT 총발행량은 증가하게 되겠죠</p>\n<p data-ke-size=\"size16\">USDT 운영 원칙은 발행량 만큼 달러를 보유하는 것입니다.</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">USDT 재단도 달러만 가지고 있으면 이자 수익이 없어서 투자를 합니다.</span></p>\n<p data-ke-size=\"size16\">대부분을 국채에 투자하기 했습니다.&nbsp;한때 중국 / 홍콩 부동산도 투자하고 있었는데 미국 정부로 부터 혼난적이 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">즉 코인 시장이 커지면 미국 국채의 수료를 창출하게 되는 것이죠</p>\n<p data-ke-size=\"size16\">심지어 이건 가상 자산이라 얼마든지 가격이 올라도 문제가 없고 다른 코인도 역시 커져도 상관없습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">중국</h2>\n<p data-ke-size=\"size16\">중국인들은 정부를 믿지 않았습니다.</p>\n<p data-ke-size=\"size16\">수천년 동안 그래왔었죠.&nbsp;</p>\n<p data-ke-size=\"size16\">좀 살만해지면 재산을 겆어가거나 전쟁으로 목슴을 갈아넣거나 했습니다.</p>\n<p data-ke-size=\"size16\">현재도 그런 상황인 것은 동일하구요.</p>\n<p data-ke-size=\"size16\">그래서 비트코인가격이 오르면 중국인들은 어떻게든 자국의 위안화로 비트코인을 사려고 할 것입니다.</p>\n<p data-ke-size=\"size16\">결국 중국 정부의 부는 해외로 유출 되고</p>\n<p data-ke-size=\"size16\">비트코인이 커지면 다시 미국의 국채 수요 증가로 이어집니다.</p>\n<h2 data-ke-size=\"size26\">결론</h2>\n<p data-ke-size=\"size16\">미국은 백년전엔 금을 달러와 엮었고<br />50년전엔 석유를 달러와 엮었습니다.<br />지금은 비트코인을 달러와 엮었습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=yn2al5DxFb0\n\n\n\n \n미국 국채 수요 때문입니다.\n여기서 핵심은 정부부채를 줄이는게 아닙니다. \"해결하겠다\" 입니다.\n미국이 미국 국채를 금리 인상없이 발행할 수 만 있다면 정부부채는 게속 늘어도 괜찮습니다.\n그런데 비트코인인가?\n그것은 바로 USDT 때문입니다.\nUSDT 와 미국 국채의 관계\n대부분의 코인은 USDT 로 거래합니다. 코인 시장이 커진다면 USDT 총발행량은 증가하게 되겠죠\nUSDT 운영 원칙은 발행량 만큼 달러를 보유하는 것입니다.\nUSDT 재단도 달러만 가지고 있으면 이자 수익이 없어서 투자를 합니다.\n대부분을 국채에 투자하기 했습니다. 한때 중국 / 홍콩 부동산도 투자하고 있었는데 미국 정부로 부터 혼난적이 있습니다.\n \n즉 코인 시장이 커지면 미국 국채의 수료를 창출하게 되는 것이죠\n심지어 이건 가상 자산이라 얼마든지 가격이 올라도 문제가 없고 다른 코인도 역시 커져도 상관없습니다.\n \n중국\n중국인들은 정부를 믿지 않았습니다.\n수천년 동안 그래왔었죠. \n좀 살만해지면 재산을 겆어가거나 전쟁으로 목슴을 갈아넣거나 했습니다.\n현재도 그런 상황인 것은 동일하구요.\n그래서 비트코인가격이 오르면 중국인들은 어떻게든 자국의 위안화로 비트코인을 사려고 할 것입니다.\n결국 중국 정부의 부는 해외로 유출 되고\n비트코인이 커지면 다시 미국의 국채 수요 증가로 이어집니다.\n결론\n미국은 백년전엔 금을 달러와 엮었고\n50년전엔 석유를 달러와 엮었습니다.\n지금은 비트코인을 달러와 엮었습니다.",
        "guid": "http://serverdown.tistory.com/993",
        "categories": [
          "코인",
          "비트코인"
        ],
        "isoDate": "2024-11-21T07:32:01.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "2024 유니티 에셋 스토어 블랙프라이데이 세일 정리 / Unity Asset Store",
        "link": "http://serverdown.tistory.com/992",
        "pubDate": "Thu, 21 Nov 2024 15:35:50 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/992#entry992comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=cVDpe_3uY0k\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=cVDpe_3uY0k</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=cVDpe_3uY0k\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bx1BZV/hyXzSw068I/b2iCay5O0Y4GbygCneNmrk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/c3FEIs/hyXDh9JmrS/kk8H5dXE7ZjmjESlm5AffK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"에셋스토어 블랙프라이데이 추천 에셋\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/cVDpe_3uY0k\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">꼭 할인하는걸 안사도 어떤에셋이 좋은지 보기위해서라도 이 영상을 확인하는 것이 좋습니다.</p>\n<p data-ke-size=\"size16\">치트를 방지하는 에셋도 있고</p>\n<p data-ke-size=\"size16\">스팀 출시를 위한 에셋도 있군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=cVDpe_3uY0k\n\n\n\n꼭 할인하는걸 안사도 어떤에셋이 좋은지 보기위해서라도 이 영상을 확인하는 것이 좋습니다.\n치트를 방지하는 에셋도 있고\n스팀 출시를 위한 에셋도 있군요",
        "guid": "http://serverdown.tistory.com/992",
        "categories": [
          "프로그래밍/개발메모",
          "게임개발",
          "오블완",
          "유니티",
          "티스토리챌린지"
        ],
        "isoDate": "2024-11-21T06:35:50.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "iShares Core S&amp;P Small-Cap / IJR / 스몰캡 / 사팔 하기 좋은 ETF",
        "link": "http://serverdown.tistory.com/991",
        "pubDate": "Wed, 20 Nov 2024 20:36:07 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/991#entry991comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"124\" data-origin-height=\"96\"><span data-url=\"https://blog.kakaocdn.net/dn/MMapW/btsKRnPwWiZ/rCXPS8ohf1Y8ZJKLvCjRU1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/MMapW/btsKRnPwWiZ/rCXPS8ohf1Y8ZJKLvCjRU1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/MMapW/btsKRnPwWiZ/rCXPS8ohf1Y8ZJKLvCjRU1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FMMapW%2FbtsKRnPwWiZ%2FrCXPS8ohf1Y8ZJKLvCjRU1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"124\" data-origin-height=\"96\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">IJR 은 요즘 핫한 스몰캡 입니다.</p>\n<p data-ke-size=\"size16\">이 ETF 역사상 고점을 꾸준히 넘어주었습니다.</p>\n<p data-ke-size=\"size16\">사팔 사팔 만 잘하면 꽤 많이 발라 먹을 수 있는 ETF 가 아닌가 주장해봅니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"824\" data-origin-height=\"274\"><span data-url=\"https://blog.kakaocdn.net/dn/cIYdji/btsKRiHr0NW/WFSk3ytXk8rOq7vmpmbk1k/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cIYdji/btsKRiHr0NW/WFSk3ytXk8rOq7vmpmbk1k/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cIYdji/btsKRiHr0NW/WFSk3ytXk8rOq7vmpmbk1k/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcIYdji%2FbtsKRiHr0NW%2FWFSk3ytXk8rOq7vmpmbk1k%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"824\" data-origin-height=\"274\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">이게 1년치 차트</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"832\" data-origin-height=\"272\"><span data-url=\"https://blog.kakaocdn.net/dn/blkgqS/btsKPHPxj4g/9RhxcErz5RfcotZK8l0Qvk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/blkgqS/btsKPHPxj4g/9RhxcErz5RfcotZK8l0Qvk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/blkgqS/btsKPHPxj4g/9RhxcErz5RfcotZK8l0Qvk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FblkgqS%2FbtsKPHPxj4g%2F9RhxcErz5RfcotZK8l0Qvk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"832\" data-origin-height=\"272\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">요거는 5년치 차트</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"838\" data-origin-height=\"268\"><span data-url=\"https://blog.kakaocdn.net/dn/cTCm6O/btsKQeTBr5o/JGRCz188sWqKI7gZDkziYk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cTCm6O/btsKQeTBr5o/JGRCz188sWqKI7gZDkziYk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cTCm6O/btsKQeTBr5o/JGRCz188sWqKI7gZDkziYk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcTCm6O%2FbtsKQeTBr5o%2FJGRCz188sWqKI7gZDkziYk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"838\" data-origin-height=\"268\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">요거는 25년간 차트 입니다.</p>\n<p data-ke-size=\"size16\">17 -&gt; 120 으로 7배 올랐습니다.</p>\n<p data-ke-size=\"size16\">25년으로 나우면 0.2 군요 (복리 는 아닙니다. 단순계산)</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">MOAT&nbsp; (독점 기업 ETF)</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"827\" data-origin-height=\"267\"><span data-url=\"https://blog.kakaocdn.net/dn/bVCAuu/btsKRxEwXGY/ATRGL4TjddveJU9U9xjG9K/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bVCAuu/btsKRxEwXGY/ATRGL4TjddveJU9U9xjG9K/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bVCAuu/btsKRxEwXGY/ATRGL4TjddveJU9U9xjG9K/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbVCAuu%2FbtsKRxEwXGY%2FATRGL4TjddveJU9U9xjG9K%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"827\" data-origin-height=\"267\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">MOAT 가 12년 동안 4배 정도 올랐습니다. 차라리 이게 나을꺼 같아요</p>\n<p data-ke-size=\"size16\">20 -&gt; 94 로 4.7배 입니다.</p>\n<p data-ke-size=\"size16\">12년으로나누면 0.39 입니다.</p>\n<p data-ke-size=\"size16\">IJR 은 0.2<br />MOAT 는 0.39</p>\n<p data-ke-size=\"size16\">MOAT 가 더 좋습니다. 스몰캡이 핫할거라길레 가져왔는데 과거기록은 별로군요 빠지면사서 올라오면 팔기에 좋은 종목같습니다. MOAT 는 그럴 기회가 상당히 적습니다.</p>",
        "contentSnippet": "IJR 은 요즘 핫한 스몰캡 입니다.\n이 ETF 역사상 고점을 꾸준히 넘어주었습니다.\n사팔 사팔 만 잘하면 꽤 많이 발라 먹을 수 있는 ETF 가 아닌가 주장해봅니다.\n \n\n\n이게 1년치 차트\n \n\n\n요거는 5년치 차트\n \n \n\n\n요거는 25년간 차트 입니다.\n17 -> 120 으로 7배 올랐습니다.\n25년으로 나우면 0.2 군요 (복리 는 아닙니다. 단순계산)\n \nMOAT  (독점 기업 ETF)\n\n\nMOAT 가 12년 동안 4배 정도 올랐습니다. 차라리 이게 나을꺼 같아요\n20 -> 94 로 4.7배 입니다.\n12년으로나누면 0.39 입니다.\nIJR 은 0.2\nMOAT 는 0.39\nMOAT 가 더 좋습니다. 스몰캡이 핫할거라길레 가져왔는데 과거기록은 별로군요 빠지면사서 올라오면 팔기에 좋은 종목같습니다. MOAT 는 그럴 기회가 상당히 적습니다.",
        "guid": "http://serverdown.tistory.com/991",
        "categories": [
          "투자"
        ],
        "isoDate": "2024-11-20T11:36:07.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "2024년 11월 현재 루나 클래식 미는 분 발견 / Luna classic / LUNC",
        "link": "http://serverdown.tistory.com/990",
        "pubDate": "Wed, 20 Nov 2024 14:03:23 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/990#entry990comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"296\" data-origin-height=\"170\"><span data-url=\"https://blog.kakaocdn.net/dn/dXLf3f/btsKPIGXMyH/ZoZ4NgaIzPOIkq2HSvDBr1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/dXLf3f/btsKPIGXMyH/ZoZ4NgaIzPOIkq2HSvDBr1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/dXLf3f/btsKPIGXMyH/ZoZ4NgaIzPOIkq2HSvDBr1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdXLf3f%2FbtsKPIGXMyH%2FZoZ4NgaIzPOIkq2HSvDBr1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"296\" data-origin-height=\"170\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=XDrqQofpseY\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=XDrqQofpseY</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=XDrqQofpseY\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/i66cn/hyXzRLt9Jk/HElD2FbnG3DMDO0XXqYeoK/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360,https://scrap.kakaocdn.net/dn/bdDbuv/hyXzUamXh7/ALj2BH4bjG3ptYiLW0kO0k/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360\" data-video-width=\"480\" data-video-height=\"360\" data-video-origin-width=\"480\" data-video-origin-height=\"360\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"2만원으로 10억만들기\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/XDrqQofpseY\" width=\"480\" height=\"360\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">베이비 도지를 투자하는 입장에서 어이 없는 코인을 조금 사두는게 나쁘진 않겠다는 생각이듭니다.</p>\n<p data-ke-size=\"size16\">루나 클래식을 미는 분이 있군요</p>\n<p data-ke-size=\"size16\">피넛이라는 코인이 17만배 올랐다는 뉴스를 가지고 오셨는데</p>\n<p data-ke-size=\"size16\">바이낸스 상장 전후로는 20배 정도 올라갔군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">투자 방법</h2>\n<p data-ke-size=\"size16\">아무 코인을 다 조금씩 사는 방법을 사용하네요</p>\n<p data-ke-size=\"size16\">그리곤 얼마든지 기다리다보면 어이없이 올라간 코인들이 생기는거 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">루나 클래식 LUNC / USTC</h2>\n<p data-ke-size=\"size16\">루나 클래식은 바이넨스에 있었군요.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"869\" data-origin-height=\"840\"><span data-url=\"https://blog.kakaocdn.net/dn/b5UJNU/btsKQ85Clq8/I4KKGtutBwh92JPV3Lisrk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/b5UJNU/btsKQ85Clq8/I4KKGtutBwh92JPV3Lisrk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/b5UJNU/btsKQ85Clq8/I4KKGtutBwh92JPV3Lisrk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb5UJNU%2FbtsKQ85Clq8%2FI4KKGtutBwh92JPV3Lisrk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"869\" data-origin-height=\"840\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">저도 LUNC / USTC&nbsp; 둘다 10달러씩 사봤습니다.</p>\n<p data-ke-size=\"size16\">현재 가격은 어의없는 가격 수준이구요.</p>\n<p data-ke-size=\"size16\">권도영 소송을 해결하는 방법은 숨겨놓은 비트코인을 가져와 소각 시키는 방법이 있습니다.</p>\n<p data-ke-size=\"size16\">전체를 구제해주진 못해도 일부라도 된다면 가격은 급등할 것입니다.</p>\n<p data-ke-size=\"size16\">마운틴곡스 사태처럼 한 10년 쯤 기다리면 더 적은 비트코인으로 살릴 가능성이 있긴합니다.</p>\n<p data-ke-size=\"size16\">감옥에 그만큼 가있어야겠지만 ...</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=XDrqQofpseY\n\n\n\n베이비 도지를 투자하는 입장에서 어이 없는 코인을 조금 사두는게 나쁘진 않겠다는 생각이듭니다.\n루나 클래식을 미는 분이 있군요\n피넛이라는 코인이 17만배 올랐다는 뉴스를 가지고 오셨는데\n바이낸스 상장 전후로는 20배 정도 올라갔군요\n \n투자 방법\n아무 코인을 다 조금씩 사는 방법을 사용하네요\n그리곤 얼마든지 기다리다보면 어이없이 올라간 코인들이 생기는거 같습니다.\n \n루나 클래식 LUNC / USTC\n루나 클래식은 바이넨스에 있었군요.\n\n\n저도 LUNC / USTC  둘다 10달러씩 사봤습니다.\n현재 가격은 어의없는 가격 수준이구요.\n권도영 소송을 해결하는 방법은 숨겨놓은 비트코인을 가져와 소각 시키는 방법이 있습니다.\n전체를 구제해주진 못해도 일부라도 된다면 가격은 급등할 것입니다.\n마운틴곡스 사태처럼 한 10년 쯤 기다리면 더 적은 비트코인으로 살릴 가능성이 있긴합니다.\n감옥에 그만큼 가있어야겠지만 ...",
        "guid": "http://serverdown.tistory.com/990",
        "categories": [
          "투자",
          "코인"
        ],
        "isoDate": "2024-11-20T05:03:23.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "2039년 외계인이 지구를 침공... 하긴했다.  / The Road Not Taken / SF소설",
        "link": "http://serverdown.tistory.com/989",
        "pubDate": "Wed, 20 Nov 2024 12:24:21 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/989#entry989comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"300\" data-origin-height=\"168\"><span data-url=\"https://blog.kakaocdn.net/dn/wbVB5/btsKObQNrJn/RTKVvRV4UhOkhfK3B7n51k/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/wbVB5/btsKObQNrJn/RTKVvRV4UhOkhfK3B7n51k/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/wbVB5/btsKObQNrJn/RTKVvRV4UhOkhfK3B7n51k/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FwbVB5%2FbtsKObQNrJn%2FRTKVvRV4UhOkhfK3B7n51k%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"300\" data-origin-height=\"168\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=wplfZoSGDTA\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=wplfZoSGDTA</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=wplfZoSGDTA\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/XNs0n/hyXzT3z2X9/WaoIHQMLocxKXQPRkhwjv0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/Putns/hyXzJUdKgs/aNLwVByKSSmqcLJ8rrYtZK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"해외 SF마니아들 사이에서 끊임없이 회자되는 명작, 고도로 발전한 미래 지구를 침공한 \" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/wplfZoSGDTA\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<h2 data-ke-size=\"size26\"><span style=\"text-align: start;\">제목: 가지 않은 길 / <span style=\"text-align: left;\">The Road Not Taken</span> <br /></span></h2>\n<p data-ke-size=\"size16\">하이퍼 드라이브로로 광속을 돌파하고 반중력 비행기로 지구에 내려오는데 ...</p>\n<p data-ke-size=\"size16\">그들의 전투력이 ...</p>\n<p data-ke-size=\"size16\">인류는 이상하게 진화했다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">파일</h2>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">PDF 링크 :<span>&nbsp;</span></span><a style=\"background-color: #000000; color: #000000; text-align: start;\" href=\"https://www.eyeofmidas.com/scifi/Turtledove_RoadNotTaken.pdf\">Turtledove_RoadNotTaken.pdf</a></p>\n<p data-ke-size=\"size16\">공개되 있네용 ㄷㄷ</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=wplfZoSGDTA\n\n\n\n제목: 가지 않은 길 / The Road Not Taken \n\n하이퍼 드라이브로로 광속을 돌파하고 반중력 비행기로 지구에 내려오는데 ...\n그들의 전투력이 ...\n인류는 이상하게 진화했다.\n \n파일\nPDF 링크 : Turtledove_RoadNotTaken.pdf\n공개되 있네용 ㄷㄷ",
        "guid": "http://serverdown.tistory.com/989",
        "categories": [
          "유튜브",
          "소설"
        ],
        "isoDate": "2024-11-20T03:24:21.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": [
      {
        "creator": "ZeroCho",
        "title": "제일 처음 커밋 앞에 커밋 추가하기",
        "link": "https://www.zerocho.com/category/Git/post/673cc471d44b1e6d6a984f49",
        "pubDate": "Tue, 19 Nov 2024 17:01:37 GMT",
        "dc:creator": "ZeroCho",
        "content": "이 게시글은 첫 커밋 앞에 다른 커밋을 추가하는 방법을 다룹니다.\n기존 커밋 히스토리가 A - B - C - D라면(A가 제일 오래된 첫 커밋) Z - A - B - C - D처럼 제일 앞에 Z를 끼워넣는 것이죠.\n왜 이런 짓을 하는 걸까요? 다양한 이유가 있겠으나 저는 중간 커밋 수정하기 를 할 때 첫 커밋은 수정이 안 되는 것을 발견했습니다. 그래서 첫 커밋 앞에 빈 커밋(Z) 하나를 추가한 뒤에 두 번째 커밋이 된 A를 수정하는 것이죠. 다른 이유를 찾으셨다면 댓글로 남겨주세요!\n방법은 다음과 같습니다.\ngit checkout --orphan tempgit rm -rf .git commit --allow-empty -m 'Z'git rebase --onto temp --root maingit branch -d temp \nZ(첫 커밋 메시지)나 main(현재 브랜치 이름) 부분은 여러분의 상황에 맞게 바꾸시면 됩니다. 다른 것들은 그대로 입력하세요.\n간단한 원리를 설명하자면 다음과 같습니다. 처음에 기존 브랜치와 완벽하게 분리된 빈 브랜치(orphan branch) temp를 생성하고, 현재 파일을 전부 지웁니다(git rm -rf .)\n현재 아무 파일/폴더가 없는데 --allow-empty 옵션을 사용해서 새로운 커밋 Z를 하나 만듭니다. 그러고나서 temp 브랜치 커밋 위에 main 브랜치의 커밋을 쌓는 겁니다. 그래서 Z 위에 A - B - C - D 가 올라갈 수 있게 됩니다. 이후에 temp 브랜치를 지우고 main 브랜치로 돌아가는 것입니다.\n",
        "contentSnippet": "이 게시글은 첫 커밋 앞에 다른 커밋을 추가하는 방법을 다룹니다.\n기존 커밋 히스토리가 A - B - C - D라면(A가 제일 오래된 첫 커밋) Z - A - B - C - D처럼 제일 앞에 Z를 끼워넣는 것이죠.\n왜 이런 짓을 하는 걸까요? 다양한 이유가 있겠으나 저는 중간 커밋 수정하기 를 할 때 첫 커밋은 수정이 안 되는 것을 발견했습니다. 그래서 첫 커밋 앞에 빈 커밋(Z) 하나를 추가한 뒤에 두 번째 커밋이 된 A를 수정하는 것이죠. 다른 이유를 찾으셨다면 댓글로 남겨주세요!\n방법은 다음과 같습니다.\ngit checkout --orphan tempgit rm -rf .git commit --allow-empty -m 'Z'git rebase --onto temp --root maingit branch -d temp \nZ(첫 커밋 메시지)나 main(현재 브랜치 이름) 부분은 여러분의 상황에 맞게 바꾸시면 됩니다. 다른 것들은 그대로 입력하세요.\n간단한 원리를 설명하자면 다음과 같습니다. 처음에 기존 브랜치와 완벽하게 분리된 빈 브랜치(orphan branch) temp를 생성하고, 현재 파일을 전부 지웁니다(git rm -rf .)\n현재 아무 파일/폴더가 없는데 --allow-empty 옵션을 사용해서 새로운 커밋 Z를 하나 만듭니다. 그러고나서 temp 브랜치 커밋 위에 main 브랜치의 커밋을 쌓는 겁니다. 그래서 Z 위에 A - B - C - D 가 올라갈 수 있게 됩니다. 이후에 temp 브랜치를 지우고 main 브랜치로 돌아가는 것입니다.",
        "guid": "https://www.zerocho.com/category/Git/post/673cc471d44b1e6d6a984f49",
        "categories": [
          "Git"
        ],
        "isoDate": "2024-11-19T17:01:37.000Z"
      }
    ]
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": []
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "한상곤 - Sigmadream",
    "category": "개인",
    "posts": [
      {
        "creator": "Sangkon Han",
        "title": "Ubuntu 24.10 Release &  20 Years Party ASP.NET 배포하기",
        "link": "https://www.sangkon.com/asp-deploy-ubuntu-24-10-release-20-years-party/",
        "pubDate": "Sun, 17 Nov 2024 05:06:00 GMT",
        "content:encodedSnippet": "ASP.NET 배포\nASP.NET 프로젝트를 우분투 24.10에서 배포하는 방법을 소개하였습니다. Azure 클라우드에서 해당 과정을 진행하였습니다. 시간이 허락한다면 YouTube에 해당 영상을 올려두도록 하겠습니다.\n\n2024.10.27_24.10 ASP.NET 배포하기\nUbuntu 24.10 Release & 20 Years Party ASP.NET 배포하기 우분투한국커뮤니티 / 마이크로소프트 MVP 한상곤\nGoogle Docs",
        "dc:creator": "Sangkon Han",
        "content": "<h2 id=\"aspnet-%EB%B0%B0%ED%8F%AC\">ASP.NET &#xBC30;&#xD3EC;</h2>\n<p>ASP.NET &#xD504;&#xB85C;&#xC81D;&#xD2B8;&#xB97C; &#xC6B0;&#xBD84;&#xD22C; 24.10&#xC5D0;&#xC11C; &#xBC30;&#xD3EC;&#xD558;&#xB294; &#xBC29;&#xBC95;&#xC744; &#xC18C;&#xAC1C;&#xD558;&#xC600;&#xC2B5;&#xB2C8;&#xB2E4;. Azure &#xD074;&#xB77C;&#xC6B0;&#xB4DC;&#xC5D0;&#xC11C; &#xD574;&#xB2F9; &#xACFC;&#xC815;&#xC744; &#xC9C4;&#xD589;&#xD558;&#xC600;&#xC2B5;&#xB2C8;</p>",
        "contentSnippet": "ASP.NET 배포\nASP.NET 프로젝트를 우분투 24.10에서 배포하는 방법을 소개하였습니다. Azure 클라우드에서 해당 과정을 진행하였습니",
        "guid": "673c1c56bf78853c742b071d",
        "categories": [
          "Etc..."
        ],
        "isoDate": "2024-11-17T05:06:00.000Z"
      }
    ]
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "Poetry를 이용한 멀티 프로젝트 Python 애플리케이션 개발 방법",
        "link": "https://techblog.lycorp.co.jp/ko/python-multi-project-application-with-poetry",
        "pubDate": "Tue, 19 Nov 2024 02:00:00 GMT",
        "content": "들어가며\n안녕하세요. LINE GAME Platform Dev2 팀의 이현섭, 이형중입니다. LINE GAME Platform에서는 게임 개발에 필요한 다양한 플랫폼 서비스를 개발...",
        "contentSnippet": "들어가며\n안녕하세요. LINE GAME Platform Dev2 팀의 이현섭, 이형중입니다. LINE GAME Platform에서는 게임 개발에 필요한 다양한 플랫폼 서비스를 개발...",
        "guid": "https://techblog.lycorp.co.jp/ko/python-multi-project-application-with-poetry",
        "isoDate": "2024-11-19T02:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": [
      {
        "title": "뱅크샐러드에서 테스트 데이터를 생성하는 방법 (feat. LLM)",
        "link": "https://blog.banksalad.com/tech/how-banksalad-testdata/",
        "pubDate": "Mon, 18 Nov 2024 00:00:00 GMT",
        "content": "안녕하세요. 뱅크샐러드 QA팀 Tech Lead Manager…",
        "contentSnippet": "안녕하세요. 뱅크샐러드 QA팀 Tech Lead Manager…",
        "guid": "https://blog.banksalad.com/tech/how-banksalad-testdata/",
        "isoDate": "2024-11-18T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": [
      {
        "title": "스포카의 백엔드팀에서 코딩 컨벤션을 관리하는 방법",
        "link": "https://spoqa.github.io/2024/11/18/coding-convention-story.html",
        "pubDate": "2024-11-18T00:00:00.000Z",
        "author": "남경호",
        "content": "<p>안녕하세요, 스포카 백엔드팀 프로그래머 남경호입니다.</p>\n\n<p>개발자라면 누구나 한 번쯤 더 나은 코드를 작성하고, 팀의 생산성과 유지보수성을 높이기 위해 고민해 보셨을 겁니다. 중복된 코드를 줄이고, 가독성을 높이며, 테스트 코드를 꼼꼼히 작성하거나, 알맞은 변수명을 고심하는 과정은 모두 그런 노력의 일환이죠. 하지만 이런 개선 작업이 효과적으로 이루어지려면, 팀 전체가 공통된 코딩 기준을 공유하고 지키는 것이 무엇보다 중요합니다.</p>\n\n<p>일관된 코딩 컨벤션은 단순한 규칙 이상의 역할을 합니다. 특히 여러 명의 개발자로 이루어진 팀에서는 코드의 가독성과 유지보수성을 높이고, 불필요한 논쟁을 줄이며, 협업의 효율성을 극대화하는 강력한 도구가 됩니다. 하지만 이러한 컨벤션을 설정하고, 이를 꾸준히 유지하는 과정은 절대 간단하지 않습니다. 문서로 정리한 규칙이 팀 내에서 제대로 적용되지 않거나, 시간이 지나며 점차 구식이 되는 문제를 겪어보신 분들도 많을 겁니다.</p>\n\n<p>우리 스포카 백엔드팀 역시 비슷한 과정을 겪었습니다. 코딩 컨벤션을 관리하기 위해 문서, 코드 리뷰, 그리고 자동화 도구를 활용하며, 더 나아가 Konsist라는 새로운 도구까지 도입하게 된 여정을 통해 다양한 시행착오를 경험했죠. 이 글에서는 단순한 도구 사용법을 넘어, 우리가 직면했던 문제들과 이를 어떻게 극복했는지에 대해 이야기해 보려 합니다.</p>\n\n<p>코딩 컨벤션 관리라는 쉽지 않은 도전이 어떻게 우리 팀의 개발 문화를 변화시켰는지, 그리고 여러분의 팀에도 어떤 인사이트를 줄 수 있을지 함께 살펴보시죠.</p>\n\n<h1 id=\"코딩-컨벤션-관리의-시작-문서-작성\">코딩 컨벤션 관리의 시작: 문서 작성</h1>\n\n<p>모든 시작은 단순합니다. 우리 팀 역시 처음에는 README.md 파일을 통해 코딩 컨벤션을 관리하기 시작했습니다. 사내 문서 관리 도구인 Confluence를 사용하지 않은 이유는 간단했는데요. 코딩 컨벤션은 코드와 가장 밀접하게 연관되어 있기 때문에, 코드와 가장 가까운 곳에서 관리할 필요가 있다고 판단했기 때문입니다.</p>\n\n<p>README.md에는 서버 실행을 위한 준비 작업, IDEA 환경 설정, GIT 브랜치 전략, 그리고 코딩 컨벤션 등 백엔드 개발자가 우리 팀에서 알아야 할 모든 내용이 기재되어 있었습니다. 초기에는, 이 접근법이 꽤 효과적이었습니다. 새로운 팀원이 들어오더라도 문서를 참고해 작업 환경을 설정하거나 코드를 작성할 때 기준을 따를 수 있었으니까요.</p>\n\n<p>아래는 저희가 README.md에 작성했던 문서의 일부분입니다.</p>\n\n<h4 id=\"일관된-eofend-of-file-설정을-위한-가이드\">일관된 EOF(End of File) 설정을 위한 가이드</h4>\n\n<div class=\"language-markdown highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"gu\">#### EOF 설정</span>\n\n파일의 마지막 라인에 자동으로 개행이 되도록 하기 위한 설정입니다.\n<span class=\"p\">\n1.</span> <span class=\"sb\">`Editor`</span> -&gt; <span class=\"sb\">`General`</span>로 이동합니다.\n<span class=\"p\">2.</span> <span class=\"sb\">`On Save`</span> 색션에서 <span class=\"sb\">`Ensure every saved file ends with a line break`</span>를 체크합니다.\n</code></pre></div></div>\n\n<h4 id=\"ktlint-플러그인-설정-가이드\">Ktlint 플러그인 설정 가이드</h4>\n\n<div class=\"language-markdown highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"gu\">## Ktlint Settings</span>\n\n<span class=\"gu\">### ktlint pre-commit 설정</span>\n\n아래 명령어를 실행하여 pre-commit hook을 등록합니다.\n\n\"\"\"\n./gradlew addKtlintCheckGitPreCommitHook\n\"\"\"<span class=\"sb\">\n\n\n</span><span class=\"gu\">### Formatting</span>\n\n만약 lint 위반 오류가 발생하는 경우 아래 명령어를 실행하여 자동으로 포메팅을 수행합니다.\n\n\"\"\"\n./gradlew ktlintFormat\n\"\"\"\n</code></pre></div></div>\n\n<p>이처럼 문서는 개발자가 코드 작성 시 참고할 수 있는 명확한 기준을 제시해 주었고, 코드 리뷰 과정에서도 사소한 논쟁을 줄이는 데 기여했습니다. 하지만 시간이 지나면서 문제점이 하나둘씩 드러나기 시작했습니다.</p>\n\n<h3 id=\"문서-관리의-한계\">문서 관리의 한계</h3>\n\n<p>코딩 컨벤션은 한 번 정하고 끝나는 작업이 아닙니다. 시간이 흐르고 조직의 요구사항이나 기술 스택이 변화함에 따라 컨벤션도 업데이트되어야 합니다. 하지만 문서로 관리할 경우, 이를 지속적으로 유지하는 책임자가 없다면 문서가 점차 구식이 되는 문제가 발생합니다.</p>\n\n<p>예를 들어, 문서에 설명된 규칙이 실제 코드와 일치하지 않을 때, 팀원들 사이에서 혼란이 발생하곤 했습니다. 이에 따라 코딩 컨벤션의 신뢰성이 떨어지고, “문서에 적혀 있는 내용은 무시해도 되는 것”이라는 인식이 퍼지기도 했죠.</p>\n\n<p>이러한 한계를 극복하기 위해 우리 팀은 문서만으로 코딩 컨벤션을 관리하는 데서 벗어나기 시작했습니다. 코딩 컨벤션을 더 효과적으로 지키기 위해 Lint와 같은 자동화된 도구, 그리고 코드 리뷰와 같은 방식을 도입했고, 이는 더 나은 방향으로의 첫걸음이 되었습니다.</p>\n\n<h1 id=\"자동화의-첫걸음-ktlint의-도입\">자동화의 첫걸음: ktlint의 도입</h1>\n\n<p>문서로 코딩 컨벤션을 관리하는 데 한계를 느낀 우리 팀은 Lint라는 자동화 도구를 도입했습니다. Lint는 코드의 오류, 버그, 스타일 문제를 찾아주는 정적 코드 분석 도구로, 간단한 설정만으로도 코드 스타일을 일관성 있게 유지할 수 있게 해줍니다. 특히, Kotlin 언어에서는 ktlint가 대표적인 Lint 도구로 자리 잡고 있습니다.</p>\n\n<h3 id=\"lint-도구의-효과\">Lint 도구의 효과</h3>\n<p>Lint 도구를 활용하면서 코드 스타일 문제를 해결하는 과정이 크게 간소화되었습니다. 이전에는 코드 리뷰 과정에서 개행, Trailing commas, 공백 처리 같은 사소한 스타일 문제로 많은 시간을 할애해야 했습니다. 하지만 Lint를 도입한 이후, 이런 문제들은 더 이상 개발자들이 신경 써야 할 부분이 아니게 되었죠. CI/CD 파이프라인에 통합하면, 코드가 규칙을 위반할 경우 자동으로 알려주기 때문에 문제를 사전에 방지할 수 있었습니다.</p>\n\n<h4 id=\"gradle에서-ktlint-설정하기\">Gradle에서 ktlint 설정하기</h4>\n\n<p>Gradle에서 ktlint를 설정하는 방법은 간단합니다. 먼저, Gradle 빌드 스크립트에 ktlint 플러그인을 추가합니다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nf\">plugins</span> <span class=\"p\">{</span>\n    <span class=\"nf\">id</span><span class=\"p\">(</span><span class=\"s\">\"org.jlleitschuh.gradle.ktlint\"</span><span class=\"p\">)</span> <span class=\"n\">version</span> <span class=\"s\">\"{version}\"</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>그 후, 특정 파일이나 디렉터리를 제외하고 싶은 경우, 다음과 같이 필터를 설정할 수 있습니다. 아래 예시는 다른 프레임워크에서 자동으로 생성된 코드들은 Lint의 검증 대상에서 제외하도록 하는 설정을 나타냅니다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nf\">ktlint</span> <span class=\"p\">{</span>\n    <span class=\"nf\">filter</span> <span class=\"p\">{</span>\n        <span class=\"nf\">exclude</span><span class=\"p\">(</span><span class=\"s\">\"**/generated/**\"</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>마지막으로, 테스트 실행 전 lint 검사를 자동으로 수행하도록 구성할 수 있습니다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">tasks</span><span class=\"p\">.</span><span class=\"n\">withType</span><span class=\"p\">&lt;</span><span class=\"nc\">Test</span><span class=\"p\">&gt;</span> <span class=\"p\">{</span>\n    <span class=\"nf\">dependsOn</span><span class=\"p\">(</span><span class=\"n\">tasks</span><span class=\"p\">.</span><span class=\"n\">withType</span><span class=\"p\">&lt;</span><span class=\"nc\">KtLintCheckTask</span><span class=\"p\">&gt;())</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>만약 ktlint에서 제공해 주는 Hook 기능을 사용한다면 Git에서 Commit 시 매번 스타일 오류를 수작업으로 수정하지 않아도, 코드를 저장하거나 테스트를 실행하는 과정에서 자동으로 스타일이 교정되거나 문제를 알려주도록 만들 수 있었습니다.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code># Git Commit 전 ktlint check를 통해 스타일 위반 사항이 있는지 확인\n./graldew addKtlintCheckGitPreCommitHook\n\n# Git Commit 전 kotlin format을 통해 스타일을 자동으로 보정\n./graldew addKtlintFormatGitPreCommitHook\n</code></pre></div></div>\n\n<h3 id=\"lint-도구의-한계\">Lint 도구의 한계</h3>\n\n<p>Lint는 코드 스타일을 유지하고 간단한 문제를 잡아내는 데 매우 유용하지만, 모든 문제를 해결해 주는 도구는 아닙니다. 개행이나 공백 처리 같은 기본적인 규칙을 강제할 수는 있지만, 코드의 중복 문제나 보안상의 허점, 복잡한 구조적 컨벤션은 감지하지 못합니다.</p>\n\n<p>Lint 도구를 사용하면서 우리는 “자동화로 해결할 수 있는 범위는 어디까지일까?”라는 고민을 하게 되었고, 이 고민은 더 정교한 도구와 방법을 찾는 과정으로 이어졌으며, 그 여정은 곧 SonarQube와 Konsist 같은 도구의 도입으로 확장되었습니다.</p>\n\n<h1 id=\"코드-리뷰-사람의-눈은-여전히-중요하다\">코드 리뷰: 사람의 눈은 여전히 중요하다</h1>\n\n<p>자동화 도구를 더 이야기하기 전에, Lint와 같은 자동화 도구를 도입했음에도, 코드 리뷰는 여전히 코딩 컨벤션을 지키고 코드 품질을 높이는 데 필수적인 과정으로 남아 있습니다. 자동화 도구가 사소한 스타일 문제를 처리해 준다면, 코드 리뷰는 도메인 요구사항을 잘 충족하였는지, 자동화된 도구 잡아내기 힘든 컨벤션 위반을 발견해 주는 등의 더 깊이 있는 검토를 통해 팀의 코드 베이스를 개선하는 데 집중할 수 있습니다.</p>\n\n<p>아래 이미지는 Lint로는 잡아내기 힘든 컨벤션 위반을 코드리뷰를 통해 개선할 수 있었던 사례입니다. 우리 팀은 테스팅 라이브러리로 Kotest를 사용 중이며 테스트 코드 작성 시 아래와 같은 컨벤션을 지키도록 약속되어 있습니다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// 테스트 코드 컨벤션</span>\n\n<span class=\"kd\">class</span> <span class=\"nc\">SalesOrderFacadeTest</span> <span class=\"p\">:</span> <span class=\"nc\">UnitTestBase</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"c1\">// ... 생략</span>\n    \n    <span class=\"nf\">init</span> <span class=\"p\">{</span>\n        <span class=\"nf\">context</span><span class=\"p\">(</span><span class=\"s\">\"getSalesOrderById\"</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n            <span class=\"nf\">test</span><span class=\"p\">(</span><span class=\"s\">\"아이디로 매출 전표를 조회한다\"</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n                <span class=\"c1\">// ... 생략</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n        \n        <span class=\"c1\">// ... 생략</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p><img src=\"/images/coding-convention-story/code-review.png\" alt=\"code-review\" /></p>\n\n<h3 id=\"코드-리뷰의-한계\">코드 리뷰의 한계</h3>\n\n<p>코드 리뷰는 수많은 회사에서 도입하고 있는 코드 품질을 높일 수 있는 수단임에도 불구하고 아래와 같이 몇 가지 한계가 있습니다.</p>\n\n<p>첫 번째로, 사람이 직접 코드를 검토하기 때문에 시간이 많이 소요된다는 점입니다. 특히, 개행, 공백, Trailing commas 같은 사소한 스타일 문제를 반복적으로 지적해야 한다면, 리뷰어와 작성자 모두에게 소모적인 작업이 될 수 있습니다. 이러한 한계는 앞서 소개한 Lint를 통해 해결할 수 있습니다.</p>\n\n<p>두 번째로, 리뷰 품질이 리뷰어에 따라 다를 수 있다는 문제도 있습니다. 어떤 리뷰어는 코드 설계나 성능 최적화에 집중할 수 있지만, 다른 리뷰어는 스타일 문제에 더 많은 시간을 할애할 수 있습니다. 이에 따라 팀 내에서 일관성이 떨어질 가능성이 있습니다.</p>\n\n<p>마지막으로, 코드 리뷰 과정에서 부정적인 피드백이 적절히 전달되지 않으면 팀원 간의 긴장감이 생길 수 있습니다. 이는 팀워크에 부정적인 영향을 미칠 수 있고, 오히려 협업의 효율성을 저해하는 결과를 초래할 수 있습니다.</p>\n\n<p>이러한 한계를 극복하기 위해 자동화 도구를 활용해 사소한 문제를 미리 해결하거나, 팀의 리뷰 가이드라인을 문서화하여 일관성을 유지하는 등의 보완책이 필요합니다. 코드 리뷰는 팀의 코드 품질과 협업 문화를 개선하는 중요한 과정인 만큼, 이러한 한계를 인지하고 효과적으로 관리하는 것이 중요합니다.</p>\n\n<p>“자동화된 도구가 더 많은 것을 해결해 줄 순 없을까?”라는 고민은 여기서 더욱 깊어졌습니다.</p>\n\n<h1 id=\"sonarqube의-도입-더-넓은-관점에서의-코드-품질-관리\">SonarQube의 도입: 더 넓은 관점에서의 코드 품질 관리</h1>\n\n<p>Lint와 코드 리뷰를 통해 팀의 코딩 컨벤션을 어느 정도 유지할 수 있었지만, 여전히 놓치고 있는 문제들이 있었습니다. 스타일 문제나 사소한 규칙 위반은 Lint로 충분히 해결할 수 있었지만, 코드의 중복, 복잡성, 보안 취약점, 그리고 더 넓은 관점에서의 코드 품질 관리는 다른 도구가 필요했습니다. 이에 우리 팀은 SonarQube를 도입하게 되었습니다.</p>\n\n<h3 id=\"sonarqube의-기능과-장점\">SonarQube의 기능과 장점</h3>\n\n<p>SonarQube는 코드 품질을 유지하고 개선하는 데 있어 매우 강력한 도구입니다. 가장 큰 장점은 코드의 다양한 품질 요소를 종합적으로 분석할 수 있다는 점입니다. 예를 들어, 코드에서 중복된 부분을 찾아내거나 복잡도가 높은 영역을 감지하며, 테스트 커버리지를 평가하고 버그나 보안 취약점을 자동으로 탐지할 수 있습니다. 이를 통해 개발자는 단순한 스타일 문제를 넘어서, 코드의 구조적 결함이나 유지보수성을 저해할 수 있는 장기적인 문제들을 사전에 파악할 수 있습니다.</p>\n\n<p>아래 사례는 Kotlin의 Data Class에서 Array 프로퍼티를 사용하는 경우 equals, hashCode, toString을 재정의해 주지 않아 발생한 SonarQube의 이슈 목록을 보여줍니다.</p>\n\n<p><img src=\"/images/coding-convention-story/sonarqube-issues.png\" alt=\"sonarqube-issues\" /></p>\n\n<p>또한, SonarQube는 오픈소스로 제공되기 때문에 로컬 환경이나 사내 서버에 설치해서 사용할 수 있습니다. 이 외에도 클라우드 기반으로도 운영이 가능하여 팀의 필요에 맞는 다양한 방식으로 유연하게 활용할 수 있습니다. 기본 제공되는 검사 규칙뿐만 아니라, 프로젝트의 특성에 따라 다양한 플러그인과 설정을 통해 맞춤형 규칙을 추가할 수도 있어 확장성도 뛰어납니다.</p>\n\n<h3 id=\"운영-과정에서-마주한-도전-과제\">운영 과정에서 마주한 도전 과제</h3>\n\n<p>SonarQube의 강력함에도 불구하고, 실제 운영 과정에서는 몇 가지 불편한 점들이 존재했습니다.</p>\n\n<p>첫 번째로는 서버 관리와 관련된 문제입니다. SonarQube를 사용하려면 자체 서버를 설치하고 운영해야 하는데, 이 과정에서 추가적인 설정과 유지보수가 필요했습니다. 특히, 코드 분석 과정에서 소스코드를 서버에 업로드하고 검증하는 데 시간이 소요되었는데, 이는 Pull Request 단계에서 실시간 검증을 수행하기에는 부담으로 작용했습니다.</p>\n\n<p>두 번째 도전 과제는 사전 검증과 사후 검증 간의 균형을 맞추는 일이었습니다. 초기에는 코드 변경 사항이 병합되기 전에 Pull Request 단계에서 SonarQube를 통해 코드를 검증하려 했습니다. 그러나 검증 과정이 느리고 시간이 오래 걸리는 탓에, 개발 속도를 저하하는 문제가 있었습니다. 이에 따라 우리는 코드가 병합된 후에 Code Smell이나 품질 문제를 감지하는 방식으로 운영 방식을 조정했습니다. 이 방식은 코드 품질 문제를 감지하는 데 유연함을 제공했지만, 문제를 사전에 완전히 방지할 수는 없다는 한계도 있었습니다.</p>\n\n<p>SonarQube는 단순히 스타일을 검사하는 도구에서 벗어나, 팀이 더 넓은 관점에서 코드 품질을 관리할 수 있도록 도와주는 강력한 도구입니다. 비록 작업코드가 병합되기 전에 품질관리를 하기 어렵다는 불편함은 있지만 사후 검증을 통해서도 Lint와 코드 리뷰가 해결하지 못했던 복잡한 문제를 감지하고, 코드베이스의 장기적인 건강 상태를 유지하는 데 중요한 역할을 하고 있다는 점은 코드 컨벤션 관리를 통해 우리 팀이 더 나은 코드 품질을 유지하기 위한 노력에 잘 부합한다고 할 수 있습니다.</p>\n\n<p>다만, SonarQube를 도입한 이후에도 우리는 더 세부적인 규칙 검증과 구조적인 코딩 컨벤션 관리를 필요로 했고, 이 과정은 결국 Konsist와 같은 도구를 찾게 되는 계기가 되었습니다.</p>\n\n<h1 id=\"konsist-코딩-컨벤션-관리의-새로운-도약\">Konsist: 코딩 컨벤션 관리의 새로운 도약</h1>\n\n<p>앞서 소개한 도구들(문서, Lint, SonarQube, 코드 리뷰)은 코딩 컨벤션을 유지하고 코드 품질을 관리하는 데 큰 도움이 되었지만, 여전히 해결되지 않는 문제들이 있었습니다. 예를 들어, 프로젝트의 구조적 규칙을 정의하거나, 클래스 네이밍 규칙, 의존성 방향과 같은 팀 고유의 복잡한 코딩 컨벤션을 자동으로 검증하는 것은 기존 도구로는 쉽지 않았습니다. 바로 이 지점에서 Konsist라는 새로운 도구가 빛을 발했습니다.</p>\n\n<h3 id=\"konsist란-무엇인가\">Konsist란 무엇인가?</h3>\n\n<p>Konsist는 Kotlin 언어를 위해 설계된 정적 코드 분석 도구로, 기존의 Lint나 SonarQube가 다루기 어려운 구조적 규칙과 세세한 컨벤션을 검증할 수 있도록 설계되었습니다. Konsist의 가장 큰 특징은 API를 활용한 단위 테스트를 통해, 팀에서 정의한 코딩 규칙을 명확히 표현하고 자동화된 방식으로 검증할 수 있다는 점입니다.</p>\n\n<p>예를 들어, “Domain 레이어는 Application 레이어를 의존하지 않는다”와 같은 복잡한 구조적 규칙을 코드로 표현하고, 이를 테스트를 통해 검증할 수 있습니다. 이 도구는 기존 도구들의 한계를 보완하며, 코딩 컨벤션 관리의 새로운 가능성을 열어주었습니다.</p>\n\n<h3 id=\"konsist의-주요-특징\">Konsist의 주요 특징</h3>\n\n<h4 id=\"간단한-설정\">간단한 설정</h4>\n\n<p>Konsist는 Gradle이나 Maven에 의존성을 추가하고, JUnit이나 Kotest와 같은 테스트 프레임워크와 연동하면 바로 사용할 수 있습니다. 복잡한 설정 과정 없이 빠르게 적용할 수 있기 때문에 새로운 도구를 도입할 때 진입 장벽이 낮습니다. 우리 팀도 Konsist를 처음 접한 날 바로 프로젝트에 적용 테스트를 진행할 수 있을 만큼 사용이 간단했습니다.</p>\n\n<h4 id=\"구조적-규칙-검증\">구조적 규칙 검증</h4>\n\n<p>Konsist는 기존 도구들이 다루기 어려운 프로젝트의 구조적 규칙을 검증할 수 있는 강력한 기능을 제공합니다. 예를 들어, 특정 레이어가 다른 레이어를 의존하지 않도록 규칙을 정의하거나, 클래스와 속성의 네이밍 규칙을 설정하고 이를 자동으로 검증할 수 있습니다. 이러한 기능은 프로젝트 구조와 일관성을 유지하는 데 큰 도움이 됩니다.</p>\n\n<h4 id=\"효율성-향상\">효율성 향상</h4>\n\n<p>Konsist를 활용하면 코드 리뷰 과정에서 반복적으로 지적해야 했던 많은 규칙 위반을 자동화할 수 있습니다. 이는 코드 리뷰의 품질을 높이는 동시에, 리뷰어가 더 중요한 논의나 설계 검토에 집중할 수 있도록 해줍니다. 덕분에 팀의 생산성과 효율성이 크게 향상되었습니다.</p>\n\n<h4 id=\"단순하면서도-강력한-구조\">단순하면서도 강력한 구조</h4>\n\n<p>Konsist는 복잡한 학습 없이 바로 사용할 수 있는 단순한 구조로 되어 있습니다. 개발자는 검증해야 할 코딩 규칙을 정의하는 데만 집중하면 되며, 불필요한 설정이나 복잡한 사용법으로 인해 시간을 낭비하지 않아도 됩니다. 이는 도구를 처음 접하는 개발자들에게도 사용이 용이하다는 점에서 큰 장점으로 작용합니다.</p>\n\n<h3 id=\"konsist-활용-사례\">Konsist 활용 사례</h3>\n\n<p>이 글의 목적은 Konsist를 자세히 소개하는 데 있지 않습니다. Konsist를 시작하는 방법이나 설치 가이드는 <a href=\"https://docs.konsist.lemonappdev.com/\" target=\"\\_blank\">공식 홈페이지</a> 에서 확인하실 수 있습니다. 대신, 이 글에서는 우리 팀이 Konsist를 활용하고 있는 몇 가지 사례를 통해, 이 도구를 어떻게 효과적으로 사용할 수 있을지 감을 잡을 수 있도록 도와드리고자 합니다.</p>\n\n<h4 id=\"구조-컨벤션\">구조 컨벤션</h4>\n\n<p>우리 팀은 명확하고 이해하기 쉬우며 유지보수성을 높일 수 있도록 아래처럼 단순한 프로젝트 구조를 사용하고 있습니다.</p>\n\n<p><img src=\"/images/coding-convention-story/architecture.png\" alt=\"architecture\" /></p>\n\n<p>Domain 레이어는 데이터 및 비즈니스 로직과 같은 도메인 로직을 처리하는 코드들이 위치하며,\nApplication 레이어는 표현 계층, Facade, 그리고 외부 리소스와의 연동을 담당하는 기반 코드들이 포함되어 있습니다.</p>\n\n<p>의존성 방향에 대한 규칙도 명확히 정의했습니다. Application 레이어는 Domain 레이어를 의존할 수 있지만, 반대로 Domain 레이어는 Application 레이어를 의존하지 않도록 컨벤션을 정했습니다.</p>\n\n<p>이러한 규칙을 코드로 표현하면 아래와 같습니다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nf\">test</span><span class=\"p\">(</span><span class=\"s\">\"application 레이어는 domain 레이어를 의존한다.\"</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"nc\">Konsist</span>\n        <span class=\"p\">.</span><span class=\"nf\">scopeFromProduction</span><span class=\"p\">()</span>\n        <span class=\"p\">.</span><span class=\"nf\">assertArchitecture</span> <span class=\"p\">{</span>\n            <span class=\"kd\">val</span> <span class=\"py\">application</span> <span class=\"p\">=</span> <span class=\"nc\">Layer</span><span class=\"p\">(</span><span class=\"s\">\"Application\"</span><span class=\"p\">,</span> <span class=\"s\">\"com.spoqa.cart.application..\"</span><span class=\"p\">)</span>\n            <span class=\"kd\">val</span> <span class=\"py\">domain</span> <span class=\"p\">=</span> <span class=\"nc\">Layer</span><span class=\"p\">(</span><span class=\"s\">\"Domain\"</span><span class=\"p\">,</span> <span class=\"s\">\"com.spoqa.cart.domain..\"</span><span class=\"p\">)</span>\n\n            <span class=\"n\">application</span><span class=\"p\">.</span><span class=\"nf\">dependsOn</span><span class=\"p\">(</span><span class=\"n\">domain</span><span class=\"p\">)</span>\n            <span class=\"n\">domain</span><span class=\"p\">.</span><span class=\"nf\">dependsOnNothing</span><span class=\"p\">()</span>\n        <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>여담으로, 처음 구조 테스트를 실행했을 때 나름 코드 리뷰에서 꼼꼼하게 의존성 위반 여부를 점검했다고 생각했지만, 예상외로 다수의 의존성 위반 코드가 발견되었습니다. 이를 통해 코드 리뷰가 사람이 수행하는 작업인 만큼, 놓치는 부분이 생길 수밖에 없다는 점을 다시 한번 실감했습니다. 동시에, Konsist가 이런 문제를 효과적으로 해결할 수 있다는 점도 확실히 체감할 수 있었습니다.</p>\n\n<p><img src=\"/images/coding-convention-story/architectural-test-result.png\" alt=\"architectural-test-result\" /></p>\n\n<h4 id=\"class-컨벤션\">Class 컨벤션</h4>\n\n<p>또한 우리 팀에서는 Entity 클래스나 테스트 클래스들은 여러 이유로 인해 특정 클래스를 필수적으로 상속받도록 강제하고 있습니다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nd\">@Entity</span>\n<span class=\"kd\">class</span> <span class=\"nc\">Bill</span><span class=\"p\">(</span>\n    <span class=\"n\">orderableVendor</span><span class=\"p\">:</span> <span class=\"nc\">OrderableVendor</span><span class=\"p\">,</span>\n    <span class=\"n\">store</span><span class=\"p\">:</span> <span class=\"nc\">Store</span><span class=\"p\">,</span>\n    <span class=\"n\">amount</span><span class=\"p\">:</span> <span class=\"nc\">BigDecimal</span><span class=\"p\">,</span>\n    <span class=\"n\">type</span><span class=\"p\">:</span> <span class=\"nc\">BillType</span><span class=\"p\">,</span>\n    <span class=\"n\">attachements</span><span class=\"p\">:</span> <span class=\"nc\">List</span><span class=\"p\">&lt;</span><span class=\"nc\">String</span><span class=\"p\">&gt;,</span>\n<span class=\"p\">)</span> <span class=\"p\">:</span> <span class=\"nc\">BaseEntity</span><span class=\"p\">()</span>\n\n<span class=\"nd\">@Entity</span>\n<span class=\"kd\">class</span> <span class=\"nc\">Role</span><span class=\"p\">(</span>\n    <span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nc\">String</span><span class=\"p\">,</span>\n    <span class=\"n\">permissions</span><span class=\"p\">:</span> <span class=\"nc\">Array</span><span class=\"p\">&lt;</span><span class=\"nc\">String</span><span class=\"p\">&gt;,</span>\n<span class=\"p\">)</span> <span class=\"p\">:</span> <span class=\"nc\">BaseEntity</span><span class=\"p\">()</span>\n\n<span class=\"c1\">// ... 생략</span>\n\n<span class=\"kd\">class</span> <span class=\"nc\">OrderSheetFacadeTest</span> <span class=\"p\">:</span> <span class=\"nc\">UnitTestBase</span><span class=\"p\">()</span>\n\n<span class=\"kd\">class</span> <span class=\"nc\">AdminMutationTest</span> <span class=\"p\">:</span> <span class=\"nc\">FunctionalTestBase</span><span class=\"p\">()</span>\n\n<span class=\"kd\">class</span> <span class=\"nc\">CartRepositoryTest</span><span class=\"p\">(</span>\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">cartRepository</span><span class=\"p\">:</span> <span class=\"nc\">CartRepository</span><span class=\"p\">,</span>\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">testEntityManager</span><span class=\"p\">:</span> <span class=\"nc\">TestEntityManager</span><span class=\"p\">,</span>\n<span class=\"p\">)</span> <span class=\"p\">:</span> <span class=\"nc\">RepositoryTestBase</span><span class=\"p\">()</span>\n\n<span class=\"c1\">// ... 생략</span>\n</code></pre></div></div>\n\n<p>위와 같은 컨벤션을 테스트하는 코드는 아래와 같습니다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nf\">test</span><span class=\"p\">(</span><span class=\"s\">\"Entity 클래스는 BaseEntity 클래스를 필수로 상속한다\"</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"nc\">Konsist</span><span class=\"p\">.</span><span class=\"nf\">scopeFromProduction</span><span class=\"p\">()</span>\n        <span class=\"p\">.</span><span class=\"nf\">classes</span><span class=\"p\">()</span>\n        <span class=\"p\">.</span><span class=\"nf\">filter</span> <span class=\"p\">{</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"nf\">hasAnnotationOf</span><span class=\"p\">(</span><span class=\"nc\">Entity</span><span class=\"o\">::</span><span class=\"k\">class</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n        <span class=\"p\">.</span><span class=\"nf\">assertTrue</span><span class=\"p\">(</span><span class=\"n\">testName</span> <span class=\"p\">=</span> <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"n\">testCase</span><span class=\"p\">.</span><span class=\"n\">name</span><span class=\"p\">.</span><span class=\"n\">testName</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n            <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"nf\">hasParentClassOf</span><span class=\"p\">(</span><span class=\"nc\">BaseEntity</span><span class=\"o\">::</span><span class=\"k\">class</span><span class=\"p\">)</span>\n        <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"nf\">test</span><span class=\"p\">(</span><span class=\"s\">\"test 클래스는 Base 클래스 중 하나를 필수로 상속한다\"</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"nc\">Konsist</span><span class=\"p\">.</span><span class=\"nf\">scopeFromTest</span><span class=\"p\">()</span>\n        <span class=\"p\">.</span><span class=\"nf\">classes</span><span class=\"p\">()</span>\n        <span class=\"p\">.</span><span class=\"nf\">filter</span> <span class=\"p\">{</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">name</span><span class=\"p\">.</span><span class=\"nf\">endsWith</span><span class=\"p\">(</span><span class=\"s\">\"Test\"</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n        <span class=\"p\">.</span><span class=\"nf\">assertTrue</span><span class=\"p\">(</span><span class=\"n\">testName</span> <span class=\"p\">=</span> <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"n\">testCase</span><span class=\"p\">.</span><span class=\"n\">name</span><span class=\"p\">.</span><span class=\"n\">testName</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n            <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"nf\">hasParentClassOf</span><span class=\"p\">(</span><span class=\"nc\">FunctionalTestBase</span><span class=\"o\">::</span><span class=\"k\">class</span><span class=\"p\">)</span> <span class=\"p\">||</span>\n                <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"nf\">hasParentClassOf</span><span class=\"p\">(</span><span class=\"nc\">UnitTestBase</span><span class=\"o\">::</span><span class=\"k\">class</span><span class=\"p\">)</span> <span class=\"p\">||</span>\n                <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"nf\">hasParentClassOf</span><span class=\"p\">(</span><span class=\"nc\">RepositoryTestBase</span><span class=\"o\">::</span><span class=\"k\">class</span><span class=\"p\">)</span> <span class=\"p\">||</span>\n                <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"nf\">hasParentClassOf</span><span class=\"p\">(</span><span class=\"nc\">IndexRepositoryTestBase</span><span class=\"o\">::</span><span class=\"k\">class</span><span class=\"p\">)</span>\n        <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<h4 id=\"entity-property-컨벤션\">Entity Property 컨벤션</h4>\n\n<p>Kotlin으로 JPA를 사용하다 보면 종종 실수하기 쉬운 부분이 있습니다. 바로 JPA의 <code class=\"language-plaintext highlighter-rouge\">@Column</code> 어노테이션에서 <code class=\"language-plaintext highlighter-rouge\">nullable</code> 속성과 Entity 프로퍼티의 타입을 다르게 정의하는 경우입니다. 우리 팀은 이러한 실수를 방지하기 위해 아래와 같이 Declarations Test를 정의해 두었습니다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nf\">test</span><span class=\"p\">(</span><span class=\"s\">\"Entity 클래스의 Column 프로퍼티가 non-nullable 타입이라면 '@Column(nullable=false)'가 선언되어야 한다\"</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"nc\">Konsist</span><span class=\"p\">.</span><span class=\"nf\">scopeFromProject</span><span class=\"p\">()</span>\n        <span class=\"p\">.</span><span class=\"nf\">classes</span><span class=\"p\">()</span>\n        <span class=\"p\">.</span><span class=\"nf\">withAllAnnotationsOf</span><span class=\"p\">(</span><span class=\"nc\">Entity</span><span class=\"o\">::</span><span class=\"k\">class</span><span class=\"p\">)</span>\n        <span class=\"p\">.</span><span class=\"nf\">properties</span><span class=\"p\">()</span>\n        <span class=\"p\">.</span><span class=\"nf\">withAllAnnotationsOf</span><span class=\"p\">(</span><span class=\"nc\">Column</span><span class=\"o\">::</span><span class=\"k\">class</span><span class=\"p\">)</span>\n        <span class=\"p\">.</span><span class=\"nf\">filter</span> <span class=\"p\">{</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">type</span><span class=\"o\">?.</span><span class=\"n\">isNullable</span> <span class=\"p\">==</span> <span class=\"k\">false</span> <span class=\"p\">}</span>\n        <span class=\"p\">.</span><span class=\"nf\">assertTrue</span> <span class=\"p\">{</span>\n            <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"nf\">hasAnnotation</span> <span class=\"p\">{</span> <span class=\"k\">annotation</span> <span class=\"p\">-&gt;</span>\n                <span class=\"k\">annotation</span><span class=\"p\">.</span><span class=\"nf\">hasArgument</span> <span class=\"p\">{</span> <span class=\"n\">arg</span> <span class=\"p\">-&gt;</span>\n                    <span class=\"n\">arg</span><span class=\"p\">.</span><span class=\"n\">name</span> <span class=\"p\">==</span> <span class=\"s\">\"nullable\"</span> <span class=\"p\">&amp;&amp;</span> <span class=\"n\">arg</span><span class=\"p\">.</span><span class=\"n\">value</span> <span class=\"p\">==</span> <span class=\"s\">\"false\"</span>\n                <span class=\"p\">}</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>이와 같이 테스트 코드를 작성하면 아래와 같이 어노테이션과 컬럼의 타입이 불일치하게 작성하는 경우를 효율적으로 방지할 수 있습니다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nd\">@Entity</span>\n<span class=\"kd\">class</span> <span class=\"nc\">Admin</span><span class=\"p\">(</span>\n    <span class=\"n\">email</span><span class=\"p\">:</span> <span class=\"nc\">String</span><span class=\"p\">,</span>\n    <span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nc\">String</span><span class=\"p\">,</span>\n    <span class=\"n\">role</span><span class=\"p\">:</span> <span class=\"nc\">Role</span><span class=\"p\">?,</span>\n<span class=\"p\">)</span> <span class=\"p\">:</span> <span class=\"nc\">BaseEntity</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"nd\">@Column</span>\n    <span class=\"kd\">val</span> <span class=\"py\">email</span><span class=\"p\">:</span> <span class=\"nc\">String</span> <span class=\"p\">=</span> <span class=\"n\">email</span>\n    \n    <span class=\"c1\">// ... 생략</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p><img src=\"/images/coding-convention-story/property-test-result.png\" alt=\"property-test-result\" /></p>\n\n<h1 id=\"마무리하며\">마무리하며</h1>\n\n<p>Konsist와 같은 도구는 팀이 코딩 컨벤션을 잘 지키도록 돕는 강력한 도구지만, 모든 문제를 해결할 수 있는 만능 솔루션은 아닙니다. 지나치게 세부적인 규칙은 생산성을 떨어뜨릴 수 있으며, 도구가 잡아내지 못하는 부분은 결국 사람이 검토해야 합니다.</p>\n\n<p>저희 백엔드팀은 Konsist, ktlint, SonarQube와 같은 도구를 적절히 조합하고, 코드 리뷰를 통해 이를 보완하면서 코딩 컨벤션을 지속적으로 발전시키고 있습니다. 이러한 과정은 단순히 코딩 규칙을 준수하는 것을 넘어, 팀의 협업 문화를 개선하고 더 나은 코드를 만드는 데 기여하고 있습니다.</p>\n\n<p>여러분의 팀은 코딩 컨벤션을 어떻게 관리하고 계신가요? 기회가 된다면 각자의 경험과 노하우를 공유하며 서로 배울 수 있는 시간이 있기를 기대합니다.</p>\n\n<p>긴 글 읽어주셔서 감사합니다.</p>\n",
        "contentSnippet": "안녕하세요, 스포카 백엔드팀 프로그래머 남경호입니다.\n개발자라면 누구나 한 번쯤 더 나은 코드를 작성하고, 팀의 생산성과 유지보수성을 높이기 위해 고민해 보셨을 겁니다. 중복된 코드를 줄이고, 가독성을 높이며, 테스트 코드를 꼼꼼히 작성하거나, 알맞은 변수명을 고심하는 과정은 모두 그런 노력의 일환이죠. 하지만 이런 개선 작업이 효과적으로 이루어지려면, 팀 전체가 공통된 코딩 기준을 공유하고 지키는 것이 무엇보다 중요합니다.\n일관된 코딩 컨벤션은 단순한 규칙 이상의 역할을 합니다. 특히 여러 명의 개발자로 이루어진 팀에서는 코드의 가독성과 유지보수성을 높이고, 불필요한 논쟁을 줄이며, 협업의 효율성을 극대화하는 강력한 도구가 됩니다. 하지만 이러한 컨벤션을 설정하고, 이를 꾸준히 유지하는 과정은 절대 간단하지 않습니다. 문서로 정리한 규칙이 팀 내에서 제대로 적용되지 않거나, 시간이 지나며 점차 구식이 되는 문제를 겪어보신 분들도 많을 겁니다.\n우리 스포카 백엔드팀 역시 비슷한 과정을 겪었습니다. 코딩 컨벤션을 관리하기 위해 문서, 코드 리뷰, 그리고 자동화 도구를 활용하며, 더 나아가 Konsist라는 새로운 도구까지 도입하게 된 여정을 통해 다양한 시행착오를 경험했죠. 이 글에서는 단순한 도구 사용법을 넘어, 우리가 직면했던 문제들과 이를 어떻게 극복했는지에 대해 이야기해 보려 합니다.\n코딩 컨벤션 관리라는 쉽지 않은 도전이 어떻게 우리 팀의 개발 문화를 변화시켰는지, 그리고 여러분의 팀에도 어떤 인사이트를 줄 수 있을지 함께 살펴보시죠.\n코딩 컨벤션 관리의 시작: 문서 작성\n모든 시작은 단순합니다. 우리 팀 역시 처음에는 README.md 파일을 통해 코딩 컨벤션을 관리하기 시작했습니다. 사내 문서 관리 도구인 Confluence를 사용하지 않은 이유는 간단했는데요. 코딩 컨벤션은 코드와 가장 밀접하게 연관되어 있기 때문에, 코드와 가장 가까운 곳에서 관리할 필요가 있다고 판단했기 때문입니다.\nREADME.md에는 서버 실행을 위한 준비 작업, IDEA 환경 설정, GIT 브랜치 전략, 그리고 코딩 컨벤션 등 백엔드 개발자가 우리 팀에서 알아야 할 모든 내용이 기재되어 있었습니다. 초기에는, 이 접근법이 꽤 효과적이었습니다. 새로운 팀원이 들어오더라도 문서를 참고해 작업 환경을 설정하거나 코드를 작성할 때 기준을 따를 수 있었으니까요.\n아래는 저희가 README.md에 작성했던 문서의 일부분입니다.\n일관된 EOF(End of File) 설정을 위한 가이드\n\n#### EOF 설정\n\n파일의 마지막 라인에 자동으로 개행이 되도록 하기 위한 설정입니다.\n\n1. `Editor` -> `General`로 이동합니다.\n2. `On Save` 색션에서 `Ensure every saved file ends with a line break`를 체크합니다.\n\n\nKtlint 플러그인 설정 가이드\n\n## Ktlint Settings\n\n### ktlint pre-commit 설정\n\n아래 명령어를 실행하여 pre-commit hook을 등록합니다.\n\n\"\"\"\n./gradlew addKtlintCheckGitPreCommitHook\n\"\"\"\n\n\n### Formatting\n\n만약 lint 위반 오류가 발생하는 경우 아래 명령어를 실행하여 자동으로 포메팅을 수행합니다.\n\n\"\"\"\n./gradlew ktlintFormat\n\"\"\"\n\n\n이처럼 문서는 개발자가 코드 작성 시 참고할 수 있는 명확한 기준을 제시해 주었고, 코드 리뷰 과정에서도 사소한 논쟁을 줄이는 데 기여했습니다. 하지만 시간이 지나면서 문제점이 하나둘씩 드러나기 시작했습니다.\n문서 관리의 한계\n코딩 컨벤션은 한 번 정하고 끝나는 작업이 아닙니다. 시간이 흐르고 조직의 요구사항이나 기술 스택이 변화함에 따라 컨벤션도 업데이트되어야 합니다. 하지만 문서로 관리할 경우, 이를 지속적으로 유지하는 책임자가 없다면 문서가 점차 구식이 되는 문제가 발생합니다.\n예를 들어, 문서에 설명된 규칙이 실제 코드와 일치하지 않을 때, 팀원들 사이에서 혼란이 발생하곤 했습니다. 이에 따라 코딩 컨벤션의 신뢰성이 떨어지고, “문서에 적혀 있는 내용은 무시해도 되는 것”이라는 인식이 퍼지기도 했죠.\n이러한 한계를 극복하기 위해 우리 팀은 문서만으로 코딩 컨벤션을 관리하는 데서 벗어나기 시작했습니다. 코딩 컨벤션을 더 효과적으로 지키기 위해 Lint와 같은 자동화된 도구, 그리고 코드 리뷰와 같은 방식을 도입했고, 이는 더 나은 방향으로의 첫걸음이 되었습니다.\n자동화의 첫걸음: ktlint의 도입\n문서로 코딩 컨벤션을 관리하는 데 한계를 느낀 우리 팀은 Lint라는 자동화 도구를 도입했습니다. Lint는 코드의 오류, 버그, 스타일 문제를 찾아주는 정적 코드 분석 도구로, 간단한 설정만으로도 코드 스타일을 일관성 있게 유지할 수 있게 해줍니다. 특히, Kotlin 언어에서는 ktlint가 대표적인 Lint 도구로 자리 잡고 있습니다.\nLint 도구의 효과\nLint 도구를 활용하면서 코드 스타일 문제를 해결하는 과정이 크게 간소화되었습니다. 이전에는 코드 리뷰 과정에서 개행, Trailing commas, 공백 처리 같은 사소한 스타일 문제로 많은 시간을 할애해야 했습니다. 하지만 Lint를 도입한 이후, 이런 문제들은 더 이상 개발자들이 신경 써야 할 부분이 아니게 되었죠. CI/CD 파이프라인에 통합하면, 코드가 규칙을 위반할 경우 자동으로 알려주기 때문에 문제를 사전에 방지할 수 있었습니다.\nGradle에서 ktlint 설정하기\nGradle에서 ktlint를 설정하는 방법은 간단합니다. 먼저, Gradle 빌드 스크립트에 ktlint 플러그인을 추가합니다.\n\nplugins {\n    id(\"org.jlleitschuh.gradle.ktlint\") version \"{version}\"\n}\n\n\n그 후, 특정 파일이나 디렉터리를 제외하고 싶은 경우, 다음과 같이 필터를 설정할 수 있습니다. 아래 예시는 다른 프레임워크에서 자동으로 생성된 코드들은 Lint의 검증 대상에서 제외하도록 하는 설정을 나타냅니다.\n\nktlint {\n    filter {\n        exclude(\"**/generated/**\")\n    }\n}\n\n\n마지막으로, 테스트 실행 전 lint 검사를 자동으로 수행하도록 구성할 수 있습니다.\n\ntasks.withType<Test> {\n    dependsOn(tasks.withType<KtLintCheckTask>())\n}\n\n\n만약 ktlint에서 제공해 주는 Hook 기능을 사용한다면 Git에서 Commit 시 매번 스타일 오류를 수작업으로 수정하지 않아도, 코드를 저장하거나 테스트를 실행하는 과정에서 자동으로 스타일이 교정되거나 문제를 알려주도록 만들 수 있었습니다.\n\n# Git Commit 전 ktlint check를 통해 스타일 위반 사항이 있는지 확인\n./graldew addKtlintCheckGitPreCommitHook\n\n# Git Commit 전 kotlin format을 통해 스타일을 자동으로 보정\n./graldew addKtlintFormatGitPreCommitHook\n\n\nLint 도구의 한계\nLint는 코드 스타일을 유지하고 간단한 문제를 잡아내는 데 매우 유용하지만, 모든 문제를 해결해 주는 도구는 아닙니다. 개행이나 공백 처리 같은 기본적인 규칙을 강제할 수는 있지만, 코드의 중복 문제나 보안상의 허점, 복잡한 구조적 컨벤션은 감지하지 못합니다.\nLint 도구를 사용하면서 우리는 “자동화로 해결할 수 있는 범위는 어디까지일까?”라는 고민을 하게 되었고, 이 고민은 더 정교한 도구와 방법을 찾는 과정으로 이어졌으며, 그 여정은 곧 SonarQube와 Konsist 같은 도구의 도입으로 확장되었습니다.\n코드 리뷰: 사람의 눈은 여전히 중요하다\n자동화 도구를 더 이야기하기 전에, Lint와 같은 자동화 도구를 도입했음에도, 코드 리뷰는 여전히 코딩 컨벤션을 지키고 코드 품질을 높이는 데 필수적인 과정으로 남아 있습니다. 자동화 도구가 사소한 스타일 문제를 처리해 준다면, 코드 리뷰는 도메인 요구사항을 잘 충족하였는지, 자동화된 도구 잡아내기 힘든 컨벤션 위반을 발견해 주는 등의 더 깊이 있는 검토를 통해 팀의 코드 베이스를 개선하는 데 집중할 수 있습니다.\n아래 이미지는 Lint로는 잡아내기 힘든 컨벤션 위반을 코드리뷰를 통해 개선할 수 있었던 사례입니다. 우리 팀은 테스팅 라이브러리로 Kotest를 사용 중이며 테스트 코드 작성 시 아래와 같은 컨벤션을 지키도록 약속되어 있습니다.\n\n// 테스트 코드 컨벤션\n\nclass SalesOrderFacadeTest : UnitTestBase() {\n    // ... 생략\n    \n    init {\n        context(\"getSalesOrderById\") {\n            test(\"아이디로 매출 전표를 조회한다\") {\n                // ... 생략\n            }\n        }\n        \n        // ... 생략\n    }\n}\n\n\n\n코드 리뷰의 한계\n코드 리뷰는 수많은 회사에서 도입하고 있는 코드 품질을 높일 수 있는 수단임에도 불구하고 아래와 같이 몇 가지 한계가 있습니다.\n첫 번째로, 사람이 직접 코드를 검토하기 때문에 시간이 많이 소요된다는 점입니다. 특히, 개행, 공백, Trailing commas 같은 사소한 스타일 문제를 반복적으로 지적해야 한다면, 리뷰어와 작성자 모두에게 소모적인 작업이 될 수 있습니다. 이러한 한계는 앞서 소개한 Lint를 통해 해결할 수 있습니다.\n두 번째로, 리뷰 품질이 리뷰어에 따라 다를 수 있다는 문제도 있습니다. 어떤 리뷰어는 코드 설계나 성능 최적화에 집중할 수 있지만, 다른 리뷰어는 스타일 문제에 더 많은 시간을 할애할 수 있습니다. 이에 따라 팀 내에서 일관성이 떨어질 가능성이 있습니다.\n마지막으로, 코드 리뷰 과정에서 부정적인 피드백이 적절히 전달되지 않으면 팀원 간의 긴장감이 생길 수 있습니다. 이는 팀워크에 부정적인 영향을 미칠 수 있고, 오히려 협업의 효율성을 저해하는 결과를 초래할 수 있습니다.\n이러한 한계를 극복하기 위해 자동화 도구를 활용해 사소한 문제를 미리 해결하거나, 팀의 리뷰 가이드라인을 문서화하여 일관성을 유지하는 등의 보완책이 필요합니다. 코드 리뷰는 팀의 코드 품질과 협업 문화를 개선하는 중요한 과정인 만큼, 이러한 한계를 인지하고 효과적으로 관리하는 것이 중요합니다.\n“자동화된 도구가 더 많은 것을 해결해 줄 순 없을까?”라는 고민은 여기서 더욱 깊어졌습니다.\nSonarQube의 도입: 더 넓은 관점에서의 코드 품질 관리\nLint와 코드 리뷰를 통해 팀의 코딩 컨벤션을 어느 정도 유지할 수 있었지만, 여전히 놓치고 있는 문제들이 있었습니다. 스타일 문제나 사소한 규칙 위반은 Lint로 충분히 해결할 수 있었지만, 코드의 중복, 복잡성, 보안 취약점, 그리고 더 넓은 관점에서의 코드 품질 관리는 다른 도구가 필요했습니다. 이에 우리 팀은 SonarQube를 도입하게 되었습니다.\nSonarQube의 기능과 장점\nSonarQube는 코드 품질을 유지하고 개선하는 데 있어 매우 강력한 도구입니다. 가장 큰 장점은 코드의 다양한 품질 요소를 종합적으로 분석할 수 있다는 점입니다. 예를 들어, 코드에서 중복된 부분을 찾아내거나 복잡도가 높은 영역을 감지하며, 테스트 커버리지를 평가하고 버그나 보안 취약점을 자동으로 탐지할 수 있습니다. 이를 통해 개발자는 단순한 스타일 문제를 넘어서, 코드의 구조적 결함이나 유지보수성을 저해할 수 있는 장기적인 문제들을 사전에 파악할 수 있습니다.\n아래 사례는 Kotlin의 Data Class에서 Array 프로퍼티를 사용하는 경우 equals, hashCode, toString을 재정의해 주지 않아 발생한 SonarQube의 이슈 목록을 보여줍니다.\n\n또한, SonarQube는 오픈소스로 제공되기 때문에 로컬 환경이나 사내 서버에 설치해서 사용할 수 있습니다. 이 외에도 클라우드 기반으로도 운영이 가능하여 팀의 필요에 맞는 다양한 방식으로 유연하게 활용할 수 있습니다. 기본 제공되는 검사 규칙뿐만 아니라, 프로젝트의 특성에 따라 다양한 플러그인과 설정을 통해 맞춤형 규칙을 추가할 수도 있어 확장성도 뛰어납니다.\n운영 과정에서 마주한 도전 과제\nSonarQube의 강력함에도 불구하고, 실제 운영 과정에서는 몇 가지 불편한 점들이 존재했습니다.\n첫 번째로는 서버 관리와 관련된 문제입니다. SonarQube를 사용하려면 자체 서버를 설치하고 운영해야 하는데, 이 과정에서 추가적인 설정과 유지보수가 필요했습니다. 특히, 코드 분석 과정에서 소스코드를 서버에 업로드하고 검증하는 데 시간이 소요되었는데, 이는 Pull Request 단계에서 실시간 검증을 수행하기에는 부담으로 작용했습니다.\n두 번째 도전 과제는 사전 검증과 사후 검증 간의 균형을 맞추는 일이었습니다. 초기에는 코드 변경 사항이 병합되기 전에 Pull Request 단계에서 SonarQube를 통해 코드를 검증하려 했습니다. 그러나 검증 과정이 느리고 시간이 오래 걸리는 탓에, 개발 속도를 저하하는 문제가 있었습니다. 이에 따라 우리는 코드가 병합된 후에 Code Smell이나 품질 문제를 감지하는 방식으로 운영 방식을 조정했습니다. 이 방식은 코드 품질 문제를 감지하는 데 유연함을 제공했지만, 문제를 사전에 완전히 방지할 수는 없다는 한계도 있었습니다.\nSonarQube는 단순히 스타일을 검사하는 도구에서 벗어나, 팀이 더 넓은 관점에서 코드 품질을 관리할 수 있도록 도와주는 강력한 도구입니다. 비록 작업코드가 병합되기 전에 품질관리를 하기 어렵다는 불편함은 있지만 사후 검증을 통해서도 Lint와 코드 리뷰가 해결하지 못했던 복잡한 문제를 감지하고, 코드베이스의 장기적인 건강 상태를 유지하는 데 중요한 역할을 하고 있다는 점은 코드 컨벤션 관리를 통해 우리 팀이 더 나은 코드 품질을 유지하기 위한 노력에 잘 부합한다고 할 수 있습니다.\n다만, SonarQube를 도입한 이후에도 우리는 더 세부적인 규칙 검증과 구조적인 코딩 컨벤션 관리를 필요로 했고, 이 과정은 결국 Konsist와 같은 도구를 찾게 되는 계기가 되었습니다.\nKonsist: 코딩 컨벤션 관리의 새로운 도약\n앞서 소개한 도구들(문서, Lint, SonarQube, 코드 리뷰)은 코딩 컨벤션을 유지하고 코드 품질을 관리하는 데 큰 도움이 되었지만, 여전히 해결되지 않는 문제들이 있었습니다. 예를 들어, 프로젝트의 구조적 규칙을 정의하거나, 클래스 네이밍 규칙, 의존성 방향과 같은 팀 고유의 복잡한 코딩 컨벤션을 자동으로 검증하는 것은 기존 도구로는 쉽지 않았습니다. 바로 이 지점에서 Konsist라는 새로운 도구가 빛을 발했습니다.\nKonsist란 무엇인가?\nKonsist는 Kotlin 언어를 위해 설계된 정적 코드 분석 도구로, 기존의 Lint나 SonarQube가 다루기 어려운 구조적 규칙과 세세한 컨벤션을 검증할 수 있도록 설계되었습니다. Konsist의 가장 큰 특징은 API를 활용한 단위 테스트를 통해, 팀에서 정의한 코딩 규칙을 명확히 표현하고 자동화된 방식으로 검증할 수 있다는 점입니다.\n예를 들어, “Domain 레이어는 Application 레이어를 의존하지 않는다”와 같은 복잡한 구조적 규칙을 코드로 표현하고, 이를 테스트를 통해 검증할 수 있습니다. 이 도구는 기존 도구들의 한계를 보완하며, 코딩 컨벤션 관리의 새로운 가능성을 열어주었습니다.\nKonsist의 주요 특징\n간단한 설정\nKonsist는 Gradle이나 Maven에 의존성을 추가하고, JUnit이나 Kotest와 같은 테스트 프레임워크와 연동하면 바로 사용할 수 있습니다. 복잡한 설정 과정 없이 빠르게 적용할 수 있기 때문에 새로운 도구를 도입할 때 진입 장벽이 낮습니다. 우리 팀도 Konsist를 처음 접한 날 바로 프로젝트에 적용 테스트를 진행할 수 있을 만큼 사용이 간단했습니다.\n구조적 규칙 검증\nKonsist는 기존 도구들이 다루기 어려운 프로젝트의 구조적 규칙을 검증할 수 있는 강력한 기능을 제공합니다. 예를 들어, 특정 레이어가 다른 레이어를 의존하지 않도록 규칙을 정의하거나, 클래스와 속성의 네이밍 규칙을 설정하고 이를 자동으로 검증할 수 있습니다. 이러한 기능은 프로젝트 구조와 일관성을 유지하는 데 큰 도움이 됩니다.\n효율성 향상\nKonsist를 활용하면 코드 리뷰 과정에서 반복적으로 지적해야 했던 많은 규칙 위반을 자동화할 수 있습니다. 이는 코드 리뷰의 품질을 높이는 동시에, 리뷰어가 더 중요한 논의나 설계 검토에 집중할 수 있도록 해줍니다. 덕분에 팀의 생산성과 효율성이 크게 향상되었습니다.\n단순하면서도 강력한 구조\nKonsist는 복잡한 학습 없이 바로 사용할 수 있는 단순한 구조로 되어 있습니다. 개발자는 검증해야 할 코딩 규칙을 정의하는 데만 집중하면 되며, 불필요한 설정이나 복잡한 사용법으로 인해 시간을 낭비하지 않아도 됩니다. 이는 도구를 처음 접하는 개발자들에게도 사용이 용이하다는 점에서 큰 장점으로 작용합니다.\nKonsist 활용 사례\n이 글의 목적은 Konsist를 자세히 소개하는 데 있지 않습니다. Konsist를 시작하는 방법이나 설치 가이드는 공식 홈페이지 에서 확인하실 수 있습니다. 대신, 이 글에서는 우리 팀이 Konsist를 활용하고 있는 몇 가지 사례를 통해, 이 도구를 어떻게 효과적으로 사용할 수 있을지 감을 잡을 수 있도록 도와드리고자 합니다.\n구조 컨벤션\n우리 팀은 명확하고 이해하기 쉬우며 유지보수성을 높일 수 있도록 아래처럼 단순한 프로젝트 구조를 사용하고 있습니다.\n\nDomain 레이어는 데이터 및 비즈니스 로직과 같은 도메인 로직을 처리하는 코드들이 위치하며,\nApplication 레이어는 표현 계층, Facade, 그리고 외부 리소스와의 연동을 담당하는 기반 코드들이 포함되어 있습니다.\n의존성 방향에 대한 규칙도 명확히 정의했습니다. Application 레이어는 Domain 레이어를 의존할 수 있지만, 반대로 Domain 레이어는 Application 레이어를 의존하지 않도록 컨벤션을 정했습니다.\n이러한 규칙을 코드로 표현하면 아래와 같습니다.\n\ntest(\"application 레이어는 domain 레이어를 의존한다.\") {\n    Konsist\n        .scopeFromProduction()\n        .assertArchitecture {\n            val application = Layer(\"Application\", \"com.spoqa.cart.application..\")\n            val domain = Layer(\"Domain\", \"com.spoqa.cart.domain..\")\n\n            application.dependsOn(domain)\n            domain.dependsOnNothing()\n        }\n}\n\n\n여담으로, 처음 구조 테스트를 실행했을 때 나름 코드 리뷰에서 꼼꼼하게 의존성 위반 여부를 점검했다고 생각했지만, 예상외로 다수의 의존성 위반 코드가 발견되었습니다. 이를 통해 코드 리뷰가 사람이 수행하는 작업인 만큼, 놓치는 부분이 생길 수밖에 없다는 점을 다시 한번 실감했습니다. 동시에, Konsist가 이런 문제를 효과적으로 해결할 수 있다는 점도 확실히 체감할 수 있었습니다.\n\nClass 컨벤션\n또한 우리 팀에서는 Entity 클래스나 테스트 클래스들은 여러 이유로 인해 특정 클래스를 필수적으로 상속받도록 강제하고 있습니다.\n\n@Entity\nclass Bill(\n    orderableVendor: OrderableVendor,\n    store: Store,\n    amount: BigDecimal,\n    type: BillType,\n    attachements: List<String>,\n) : BaseEntity()\n\n@Entity\nclass Role(\n    name: String,\n    permissions: Array<String>,\n) : BaseEntity()\n\n// ... 생략\n\nclass OrderSheetFacadeTest : UnitTestBase()\n\nclass AdminMutationTest : FunctionalTestBase()\n\nclass CartRepositoryTest(\n    private val cartRepository: CartRepository,\n    private val testEntityManager: TestEntityManager,\n) : RepositoryTestBase()\n\n// ... 생략\n\n\n위와 같은 컨벤션을 테스트하는 코드는 아래와 같습니다.\n\ntest(\"Entity 클래스는 BaseEntity 클래스를 필수로 상속한다\") {\n    Konsist.scopeFromProduction()\n        .classes()\n        .filter { it.hasAnnotationOf(Entity::class) }\n        .assertTrue(testName = this.testCase.name.testName) {\n            it.hasParentClassOf(BaseEntity::class)\n        }\n}\n\ntest(\"test 클래스는 Base 클래스 중 하나를 필수로 상속한다\") {\n    Konsist.scopeFromTest()\n        .classes()\n        .filter { it.name.endsWith(\"Test\") }\n        .assertTrue(testName = this.testCase.name.testName) {\n            it.hasParentClassOf(FunctionalTestBase::class) ||\n                it.hasParentClassOf(UnitTestBase::class) ||\n                it.hasParentClassOf(RepositoryTestBase::class) ||\n                it.hasParentClassOf(IndexRepositoryTestBase::class)\n        }\n}\n\n\nEntity Property 컨벤션\nKotlin으로 JPA를 사용하다 보면 종종 실수하기 쉬운 부분이 있습니다. 바로 JPA의 @Column 어노테이션에서 nullable 속성과 Entity 프로퍼티의 타입을 다르게 정의하는 경우입니다. 우리 팀은 이러한 실수를 방지하기 위해 아래와 같이 Declarations Test를 정의해 두었습니다.\n\ntest(\"Entity 클래스의 Column 프로퍼티가 non-nullable 타입이라면 '@Column(nullable=false)'가 선언되어야 한다\") {\n    Konsist.scopeFromProject()\n        .classes()\n        .withAllAnnotationsOf(Entity::class)\n        .properties()\n        .withAllAnnotationsOf(Column::class)\n        .filter { it.type?.isNullable == false }\n        .assertTrue {\n            it.hasAnnotation { annotation ->\n                annotation.hasArgument { arg ->\n                    arg.name == \"nullable\" && arg.value == \"false\"\n                }\n            }\n        }\n}\n\n\n이와 같이 테스트 코드를 작성하면 아래와 같이 어노테이션과 컬럼의 타입이 불일치하게 작성하는 경우를 효율적으로 방지할 수 있습니다.\n\n@Entity\nclass Admin(\n    email: String,\n    name: String,\n    role: Role?,\n) : BaseEntity() {\n    @Column\n    val email: String = email\n    \n    // ... 생략\n}\n\n\n\n마무리하며\nKonsist와 같은 도구는 팀이 코딩 컨벤션을 잘 지키도록 돕는 강력한 도구지만, 모든 문제를 해결할 수 있는 만능 솔루션은 아닙니다. 지나치게 세부적인 규칙은 생산성을 떨어뜨릴 수 있으며, 도구가 잡아내지 못하는 부분은 결국 사람이 검토해야 합니다.\n저희 백엔드팀은 Konsist, ktlint, SonarQube와 같은 도구를 적절히 조합하고, 코드 리뷰를 통해 이를 보완하면서 코딩 컨벤션을 지속적으로 발전시키고 있습니다. 이러한 과정은 단순히 코딩 규칙을 준수하는 것을 넘어, 팀의 협업 문화를 개선하고 더 나은 코드를 만드는 데 기여하고 있습니다.\n여러분의 팀은 코딩 컨벤션을 어떻게 관리하고 계신가요? 기회가 된다면 각자의 경험과 노하우를 공유하며 서로 배울 수 있는 시간이 있기를 기대합니다.\n긴 글 읽어주셔서 감사합니다.",
        "id": "https://spoqa.github.io/2024/11/18/coding-convention-story.html",
        "isoDate": "2024-11-18T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "한국 제품",
        "link": "https://www.thestartupbible.com/2024/11/rise-of-the-korean-products-and-brands.html",
        "pubDate": "Wed, 20 Nov 2024 21:36:00 +0000",
        "content:encodedSnippet": "우리가 투자를 시작한 게 2012년인데, 이때부터 ‘한류’라는 말이 있었고, 한국인과 한국 제품이 드디어 한국을 벗어나서 세계 시장으로 나갈 수 있는 발판이 마련됐다고 이야기했었다. “Taking Korea global”이라는 말을 지난 10년 동안 너도나도 했지만, 솔직히 지금까진 말만큼 멋지게 실현되진 않았다. “지금까진.”\n작년, 그리고 올해 내내 미국, 유럽, 동남아, 일본을 여러 번 다니면서 내가 확실히 느낀 건, 이제 정말로 한국이 세계 시장으로 아주 자신 있게 나갈 수 있는 시점이 됐다는 점이다. 전에 ‘제2의 한류’라는 말을 내가 했는데, 이제 한국은 전 세계의 문화에 영향을 주는 global cultural force가 됐다. 인류 역사상 전 세계의 문화에 영향을 주는 cultural force가 된 국가는 아주 오랜 시간 동안 강대국의 지위를 유지했고, 그 기간 더 발전해서 더 강대국이 된 사례가 매우 많다. 나는 한국이 이런 기운과 기회를 잘 활용해서 비록 땅덩어리는 작고 인구도 작지만, 엄청나게 잘 살고, 다른 나라의 존경을 받는 초강대국이 되길 바란다.\n한국이 global cultural force가 되면서 한국의 창업가들에겐 좋은 기회가 생기고 있고, 이들을 지원하는 우리 같은 VC에게도 큰 기회가 생기고 있다. 최근에 미국을 2주 정도 돌아다녔는데, 어디 가나 한국 브랜드와 제품이 인기가 많다는 걸 직접 실감할 수 있었다. 심지어 작은 시골 도시에 가도 한국 음악, 드라마, 화장품, 음식, 그리고 자동차에 대한 인기와 관심이 너무 많았는데, 이게 참 놀라웠다. “한국이 어떻게 이렇게 인기 있는 나라가 됐을까?”라는 질문을 스스로에게 여러 번 할 정도였다. 한강 작가의 노벨 문학상 수상도 참 신기한 게, 전 세계 8,000만 명만 하는 비주류 언어인 한국어로 평생 책을 쓴 작가가 노벨 문학상을 받았다는 건, 한국과 한국어가 대단한 global cultural force라고밖에 설명할 수 없다.\n왜 이렇게 한국은 하드웨어, 소프트웨어, 콘텐츠, 브랜드를 이렇게 잘 만들까? 나는 이게 한국의 DNA에 깊게 박혀 있는 경쟁과 생존본능 때문이라고 생각한다. 한국은 아주 작은 나라다. 이 작은 나라에서 5,000만 명이 다닥다닥 붙어 살면서 남들보다 더 성공하기 위해 정말 빡세게 경쟁한다. 가끔 이 과한 경쟁의식이 부정적인 결과를 만들지만, 어쨌든 한국은 전 세계에서 가장 열심히 일하고, 가장 치열하게 살고, 가장 남보다 더 잘하기 위해서 수단과 방법을 가리지 않고 사는 사람들이 많은 국가이다. 좋든 싫든, 이건 우리의 타고난 기질이자 환경이다.\n이렇게 경쟁이 치열한 곳에서 만들어졌고, 이 치열한 시장에서 팔리고 있고, 여기서 살아남을 수 있다면 기본적으로 좋은 제품이다. 그래서 한국에서 잘 되는 제품이 미국과 같은 해외 시장으로 진출하면, 기본적으로 잘 될 가능성이 높다. 엄청 까다롭고, 엄청 치열하고, 엄청나게 경쟁하고, 동시에 엄청나게 잘 사는 소비자들이 많은 한국 시장에서 팔린다면, 제품 자체는 이미 입증된 것이다. 소비자들은 지갑으로 투표하는데, 지갑으로 투표하기 위한 기본 조건은 품질이기 때문이다.\n그러면, 왜 모든 한국의 제품이 미국 시장에서 대박 나지 않나? 왜 일부만 잘 되고, 대부분 실패하는가?\n어떤 제품과 회사는 한국에서 증명되기도 전에 너무 일찍 해외 진출을 시도하는데, 제품도 준비가 덜 됐고, 이 덜 준비된 제품을 마케팅하고 판매할 사람들도 준비가 덜 된 경우가 많다. 이런 회사는 미국 시장에서 백전백패한다.\n하지만, 이미 한국에서 품질이 증명된 제품도 미국 시장에서 실패하는 경우가 너무 많다. 여기서 우리가 말하는 globalization의 어려움이 작용하는 것이다. 제품은 좋지만, 이걸 다른 시장의 다른 소비자들에게 홍보하고 판매하기 위해서는 미세 조정을 많이 해야 하는데, 미국 시장을 잘 모르는 분들은 이 미세 조정을 어떻게 해야 하는지 감을 잘 못 잡는다. 이 미세조정에 수백억 원 또는 수천억 원을 투자하고, 결국엔 미국 시장에서 철수한 한국 회사들도 너무 많은 걸 보면, 이게 참 어려운 일인 것 같다.\n하지만, 내가 이번에 미국 시장에서 봤던 가능성은, 위에서 말했듯이 Korea라는 나라의 이미지 자체가 너무 좋아지고, 동시에 global cultural force가 되고 있기 때문에, 한국 제품과 브랜드가 미국 시장에서 거쳐야 하는 미세조정의 폭이 점점 더 좁아지고 있다는 점이다. 심지어 어떤 제품은 포장지에 한글이 그대로 적혔는데도 불티나게 팔리고 있었다.\n지난 20년 동안 말만 많고 결과는 별로였던 “Taking Korea global”. 이제 정말 그 타이밍이 온 것 같다. 제2의 한류를 타고 더 많은 한국 회사와 제품이 해외 시장을 – 특히 북미 시장 – 쓰나미같이 강타해서 글로벌 무대를 찢어버리는 이 움직임에 스트롱도 큰 기여를 할 수 있길 바란다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/11/rise-of-the-korean-products-and-brands.html#respond",
        "content": "우리가 투자를 시작한 게 2012년인데, 이때부터 ‘한류’라는 말이 있었고, 한국인과 한국 제품이 드디어 한국을 벗어나서 세계 시장으로 나갈 수 있는 발판이 마련됐다고 이야기했었다. “Taking Korea global”이라는 말을 지난 10년 동안 너도나도 했지만, 솔직히 지금까진 말만큼 멋지게 실현되진 않았다. “지금까진.” 작년, 그리고 올해 내내 미국, 유럽, 동남아, 일본을 여러 번 다니면서 내가 확실히 느낀 건, 이제(...)",
        "contentSnippet": "우리가 투자를 시작한 게 2012년인데, 이때부터 ‘한류’라는 말이 있었고, 한국인과 한국 제품이 드디어 한국을 벗어나서 세계 시장으로 나갈 수 있는 발판이 마련됐다고 이야기했었다. “Taking Korea global”이라는 말을 지난 10년 동안 너도나도 했지만, 솔직히 지금까진 말만큼 멋지게 실현되진 않았다. “지금까진.” 작년, 그리고 올해 내내 미국, 유럽, 동남아, 일본을 여러 번 다니면서 내가 확실히 느낀 건, 이제(...)",
        "guid": "https://www.thestartupbible.com/?p=9275",
        "categories": [
          "Uncategorized",
          "FoundersAtWork",
          "global",
          "korea",
          "Strong"
        ],
        "isoDate": "2024-11-20T21:36:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "월급쟁이 VC",
        "link": "https://www.thestartupbible.com/2024/11/the-shameful-and-the-shameless-vcs.html",
        "pubDate": "Sun, 17 Nov 2024 21:31:00 +0000",
        "content:encodedSnippet": "얼마 전에 내가 이런 페이스북 포스팅을 했다.\n\n\n\n\n사실의 100%를 내가 모르면, 이렇게 내 입장을 명확하게 밝히는 경우가 별로 없는데, 이 내용은 꼭 공유하고 싶었고, 나는 이 창업가를 지지한다는 점을 밝히고 싶었다. 많은 분들이 이 포스팅에 대한 의견을 공개적으로 또는 사적으로 공유해줬고, 당연히 여러 가지 내용과 의견이 있었다. 이 사태를 어반베이스의 입장에서 보는 분들에겐 신한캐피탈은 악마이지만, 또 그 반대로 신한캐피탈의 입장에서 이 사건을 보는 분들에겐 어반베이스가 멍청한 것이고, 신한캐피탈은 그냥 계약서에 충실한 대기업이라고 하는 분들도 있다.\n위의 두 가지 관점의 차이에 대해서 나는 뭐라 하지 않겠다. 이 세상은 자기 잘난 맛에 사는 거고, 보는 관점에 따라서 악마가 천사가 되고, 천사가 악마가 되는 걸 우린 너무 많이 봤다. 그런데 이 다양하고 컬러풀 한 의견 중 내가 내 생각을 다시 한번 공유하고 싶은 내용이 있다. 투자 담당자는 아무 잘못이 없고 그냥 회사에서 시키는 대로 했을 뿐이라서 회사가 이상한 거지 그 담당자를 욕하면 안 된다는 의견이다. “전 그냥 월급쟁이예요. 회사에서 시키는 대로 할 뿐입니다.”라는 말을 우린 너무 많이 듣고, 실은 너무 많이 하는데, 난 이 말을 남발하는 사람들이 정말 싫다. 내 주변에 이런 사람들이 별로 없지만, 무슨 이야기만 하면 매번 이 월급쟁이 변명을 하는 내가 아는 몇 안 되는 분들은 이 사회를 좀먹는 사람들이다. 참고로, 여기서 내가 강조하는 부분은, 본인의 의지나 힘으로 그 어떠한 노력도 해보지 않고, 매번 이 월급쟁이 변명을 하는 사람들이다. 회사에서 내 의지로 최선을 다해봐도 내 직책과 지위 때문에 일이 안 되는 경우에 이런 말을 하는 사람들을 욕하는 건 아니다.\n물론, 난 어반베이스 대표의 주장만을 기반으로 이 상황을 내 시각으로 해석하기 때문에 전체 그림의 일부를 놓치고 있을지도 모른다. 하지만, 또 내가 반박할 수 있는 건, 나도 이와 비슷한 일을 직접 경험해봤기 때문에 이게 어떤 상황인지 꽤 명확하게 이해하고 있다는 점이다. 우리 투자사의 대표이사를 집요하게 괴롭히고, 인격적으로 모욕하고, 정신적으로 힘들게 하는, 같은 배를 탔다고 생각했던 – 하지만, 이건 내 착각이었다 – 공동 투자사의 담당자와 통화하면서, 이분이 회사 또는 본인이 주장하는 일련의 상식에 어긋나는 일들에 대해서 회사 내부에서는 그 어떤 액션도 취하지 않고, 그 어떤 노력도 하지 않고 그냥 “전 회사에서 시키는 대로 하는 월급쟁이입니다.”라는 말을 했을 때 정말 정이 떨어졌다. 본인이 귀찮고, 틀렸다는 걸 잘 알면서도 이걸 조금이라도 고치려는 그 어떠한 노력도 하지 않을 때, 한 배를 같이 탄 창업가의 인생이 망가지고, 개인 파산으로 인해 신용불량자가 되고, 가족이 파탄 나고, 최악의 경우 한 생명이 사라지는 최악의 결과가 발생할 수도 있다는 걸 알면서도 이런 무책임한 생각과 말을 하는 건 정말 아니라고 생각한다.\n어쩌면 이 사람은 VC로서는 성공했을지도 모른다. 우리 같은 투자자들이 좋아하는 계약서대로 했으니까. 하지만 인간으로서는 완전 실패다. 계약서의 문구 하나하나가 당연히 중요하고, 우린 회사 대 회사가 계약으로 묶여 있고, 큰돈이 왔다 갔다 하는 아주 serious 한 일을 하고 있지만, 결국 이 거래의 본질엔 사람이 있다. 한 명의 인격체가 다른 인격체를 믿고, 존중하고, 지지하는 그런 업을 하고 있는데, 인간이기를 포기하고 단순히 계약과 돈을 쫓는 매정한 VC이길 선택한다면, 나는 그 사람을 미워하고 욕할 수밖에 없다.\n마지막으로, 회사는 그 회사의 직원들로 구성되어 있다. 이런 직원이 몇 년 후에 임원이 되고, 그 임원이 회사의 대표가 되는데, 담당자를 욕하지 말고 회사를 욕하라는 의견은 좀 그렇다. 이런 담당자들로 구성된 회사, 그리고 이런 행위를 허용하고, 오히려 부추기는 구성원들 그 자체가 회사라서 나는 더욱더 이런 사람들이 싫어진다. 내가 이런 투자자들과 같이 집합적으로, 그냥 싸잡아서 같은 VC로 분류된다는 게 창피하고 싫어지는 순간이다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/11/the-shameful-and-the-shameless-vcs.html#comments",
        "content": "얼마 전에 내가 이런 페이스북 포스팅을 했다. 사실의 100%를 내가 모르면, 이렇게 내 입장을 명확하게 밝히는 경우가 별로 없는데, 이 내용은 꼭 공유하고 싶었고, 나는 이 창업가를 지지한다는 점을 밝히고 싶었다. 많은 분들이 이 포스팅에 대한 의견을 공개적으로 또는 사적으로 공유해줬고, 당연히 여러 가지 내용과 의견이 있었다. 이 사태를 어반베이스의 입장에서 보는 분들에겐 신한캐피탈은 악마이지만,(...)",
        "contentSnippet": "얼마 전에 내가 이런 페이스북 포스팅을 했다. 사실의 100%를 내가 모르면, 이렇게 내 입장을 명확하게 밝히는 경우가 별로 없는데, 이 내용은 꼭 공유하고 싶었고, 나는 이 창업가를 지지한다는 점을 밝히고 싶었다. 많은 분들이 이 포스팅에 대한 의견을 공개적으로 또는 사적으로 공유해줬고, 당연히 여러 가지 내용과 의견이 있었다. 이 사태를 어반베이스의 입장에서 보는 분들에겐 신한캐피탈은 악마이지만,(...)",
        "guid": "https://www.thestartupbible.com/?p=9279",
        "categories": [
          "Uncategorized",
          "failure",
          "FoundersAtWork",
          "korea",
          "vc"
        ],
        "isoDate": "2024-11-17T21:31:00.000Z"
      }
    ]
  },
  {
    "name": "Build a Great Product",
    "category": "개인",
    "posts": []
  },
  {
    "name": "지금 써보러 갑니다",
    "category": "개인",
    "posts": []
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": [
      {
        "title": "Redlock 알고리즘 알아보기",
        "link": "https://hudi.blog/redlock-algorithm/",
        "pubDate": "Sat, 23 Nov 2024 00:00:00 GMT",
        "content:encodedSnippet": "블로그에 글을 오랜만에 쓴다. 요즘 공부한 대부분의 내용은 개인 옵시디언에 작성하고 있어서, 블로그 같이 공개적인 공간에 글을 발행할 일이 없었는데, 의식적으로 블로그에도 글을 써보려 해야겠다.\n최근에 Redlock 알고리즘에 대해서 가볍게 공부했는데, 이 내용을 정리해본다.\n\n분산 락이 보장해야하는 속성\n레디스 공식 문서에서는 아래와 같이 분산락이 보장해야하는 3가지 속성에 대해 제시한다.\n상호 배제 (Mutual Exclusion) : 특정 시점에 하나의 클라이언트만 락을 획득할 수 있어야 함\n교착 상태 없음 (Deadlock Free) : 먼저 락을 획득한 클라이언트가 장애(다운, 네트워크 단절 등)가 발생하더라도 락을 획득할 수 있어야 함\n내결함성 (Fault Tolerance) : Redis 노드의 과반수가 동작중이라면 클라이언트는 락을 획득/해제가 가능해야함\nRedlock 알고리즘은 어떻게 위 3가지 요건을 만족했는지 알아보자.\n\nRedlock 등장 배경\nRedlock 알고리즘이 어떤 문제를 해결하기 위해 등장했는지, Redlock 등장 이전의 분산락 구현 방식과 그 문제점을 알아보자.\n\n1. 단일 Redis 인스턴스의 문제\n\n    \n      \n    \n  \n  \n    \n    출처 : https://www.baeldung.com/cs/distributed-systems-prevent-single-point-failure\n  \nRedis 를 사용해서 락을 구현하는 가장 간단한 방법은 단일 Redis 인스턴스를 구성하는 방법이다. 락을 획득하고자 하는 클라이언트는 단일 Redis 인스턴스에서 키를 생성하고 TTL을 설정한다. 이 상태에서 다른 클라이언트가 락을 획득하려하면, 이미 해당 키가 설정되어 있으므로 실패한다. 이후 임계 영역 (Critical Section) 에서 작업을 마친 클라이언트는, 자신이 Redis 에 설정했던 키를 제거하여 락을 해제한다.\nRedis는 기본적으로 싱글 쓰레드로 동작 하기 때문에, 분산 환경에서의 경합을 크게 고려하지 않고도 간단하게 분산락을 구현할 수 있다.\n하지만, 문제는 단일 Redis 인스턴스는 단일 장애점(Single Point of Failure) 이라는 점이다. Redis 인스턴스에서 장애가 발생해 죽어버리면, 어떤 클라이언트도 임계 영역에서 작업을 수행할 수 없게 된다. 곤란한 일이다.\n\n2. Master-Slave 복제 아키텍처의 문제\n단일 Redis 인스턴스는 앞서 알아보았듯, 단일 장애점으로 인한 가용성 문제가 존재한다. 그렇다면, Master-Slave 복제 아키텍처를 사용하여 가용성을 높이는 방법을 사용하면 어떨까? 좋은 아이디어 같아 보인다. 적용해보자.\nMaster-Slave 로 Redis 를 구성했는데, 어느날 Master 노드에 장애가 발생했다. 다행히 Failover 메커니즘에 의해 Slave 가 Master 로 승격되면서, 장애는 빠르게 회복되었다. 그런데, 이상한 현상이 발생하였다. 장애가 발생한 당시, 2개의 클라이언트가 동시에 리소스에 접근하여 동시성 이슈가 발생한 것이었다. 왜 이런일이 발생했을까?\n\n    \n      \n    \n  \n  \n    \n    출처 : https://medium.com/@anil.goyal0057/distributed-locking-mechanism-using-redis-26c17d9f3d5f\n  \n이 문제는 Redis 의 복제 방식으로 인해 발생한다. Redis 는 비동기 복제 방식을 사용한다. 아래와 같은 시나리오를 생각해보자.\nClient A가 마스터에서 락을 획득함\nMaster에서 키에 대한 쓰기가 발생했지만, Slave로 복제되기 전에 마스터 노드가 다운됨\nSlave 노드가 새로운 Master로 승격됨\nClient B가 새로운 마스터로부터 락을 획득함\n이와 같은 상황을 복제 지연으로 인한 쓰기 유실 (Write Loss) 이라고 부른다. 이런 쓰기 유실이 발생한다면, 서로 다른 두 클라이언트가 동시에 임계 영역에 진입해 상호 배제 원칙이 위배될 수 있다.\nRedis 의 WAIT 명령을 사용하면 해결할 수 있을 것 같지만, WAIT 을 사용하다고 하더라도 동기 복제를 완전히 보장하지 않는다. WAIT 은 쓰기 명령이 Replica 로 도달하여 ACK 응답을 받은 시점 까지만 보장하며, 실제로 Replica 에 정상적으로 데이터가 쓰여지는 것 까지 보장하지 않는다. 또한 WAIT 에 timeout 을 설정하면, 일정 시간동안 ACK 응답을 받지 못했을 때, ACK 응답을 기다리는 것을 포기하고 다음 명령을 실행한다.\n즉, WAIT 을 사용하더라도 여전히 쓰기 유실이 발생할 가능성은 존재한다.\n\nRedlock 의 등장\n앞서 알아본 것 처럼, 단일 인스턴스를 사용하던 Master-Slave 복제 아키텍처 방식을 사용하던 Redis 는 높은 수준의 신뢰성을 제공하지 않는다. Redlock 을 사용하면, SPOF로 인한 가용성 문제와 복제 지연으로 인한 쓰기 유실 문제를 해결하면서, 안전하게 락을 제공할 수 있다.\n\n    \n      \n    \n  \n  \n    \n    출처 : https://careers.saigontechnology.com/blog-detail/implement-distributed-lock-for-a-microservices-software-system\n  \nRedlock 의 핵심 아이디어는 정족수(Quorum)이다. 정족수란, 회의나 투표가 유효하게 진행되기 위해 필요한 최소한의 참석 인원을 말한다. Redlock 에서도 이 의미는 동일하게 사용된다.\nRedlock 을 사용하기 위해서는 다수(일반적으로 5개)의 독립적인 (Standalone) Redis 인스턴스가 필요하다. 클라이언트는 이 Redis 노드 모두에게 순차적으로 락을 요청한다. 그리고 정족수(N/2 + 1) 이상의 노드들로부터 락을 획득했다면, 클라이언트는 자신이 락을 획득했다고 간주하고 임계 영역에 진입해 작업을 수행한다.\n일정 수 이상의 노드들로부터 락을 획득하면, 리소스의 락을 획득한 것으로 인정되므로, 일부 노드가 다운된 상태여도 문제 없다. 따라서 가용성 문제와 쓰기 유실 문제를 모두 해결할 수 있다.\nRedlock 을 위해 구성된 Redis 노드들은 같은 클러스터에 참여하거나, 복제를 하는 등 서로 연관되어 있어서는 안되며, 완전히 독립되어야 한다.\n이제 Redlock 알고리즘에 대해서 더 자세히 알아보자.\n\nRedlock 알고리즘\n\n1. 현재 시각을 ms 단위로 가져옴\n이 시간은 락 획득에 걸린 시간을 계산하기 위해 사용된다.\n\n2. 클라이언트는 모든 N개의 마스터 노드로부터 순차적으로 락 획득을 시도\n이떄, 클라이언트는 해당 키에 랜덤한 값을 저장한다. 아래에서 자세히 설명하겠지만, 이 랜덤 값은 락을 획득한 클라이언트만이 해당 락을 해제할 수 있도록 보장한다.\n특정 Redis 노드에 락이 이미 걸려있다면, 즉시 다음 노드로 넘어간다. 이런 상황이 발생했다면, 해당 클라이언트는 다른 클라이언트와 락 획득 경쟁이 발생한 상황일 것이다.\n\n3. 락 설정시 타임아웃을 적용\n클라이언트는 각 Redis 인스턴스에 락을 설정할 때, 한 노드를 너무 오래기다리지 않도록 타임아웃을 설정한다. 예를 들어, TTL이 10초 정도라면, 타임아웃은 5~50ms 정도로 작게 설정한다. 이렇게 하면, Redis 노드가 설령 다운된 상황이라도 오래 기다리지 않고 바로 다음 노드로 넘어갈 수 있다.\n\n4. 락 획득 성공 여부 판단\n클라이언트는 모든 Redis 노드로부터 락 설정 시도를 마치고, 과반수(N/2 + 1) 이상의 인스턴스에서 락을 획득 했는지 확인한다. 과반수 이상의 Redis 노드로부터 락을 설정하는데 성공했다면, 클라이언트는 자신이 락 획득에 성공했다고 판단한다.\n\n5. 락 유효 시간 계산\n클라이언트는 락 유효 시간(Lock Validity Time)을 계산한다. 락 유효 시간은 이름 그대로 락이 유효한 시간을 나타내며, 클라이언트는 락 유효 시간 만큼 임계영역에서 작업을 할 수 있다. 락 유효 시간은 아래와 같이 계산한다.\nLockValidityTime=TTL−(T2−T1)Lock Validity Time = TTL - (T2 - T1)LockValidityTime=TTL−(T2−T1)\n각 변수의 의미는 아래와 같다.\nTTL : Redis 키에 설정된 TTL. 이는 락의 초기 유효 시간을 나타낸다.\nT1 : 최초 노드에서 Key가 SET 된 최악의 시각 (첫번째 노드에 통신하기 전에 얻어온 시각)\nT2 : 마지막 노드에서 Key가 SET 된 최악의 시각 (마지막 노드로부터 응답을 받은 시각)\n(T2−T1)(T2 - T1)(T2−T1) 은 클라이언트가 락을 획득하는 데 소요된 총 시간으로, 이 시간이 길어질수록 실제로 락을 보유할 수 있는 시간이 줄어든다.\n\n6. 락 획득 실패 시 처리\n만약 클라이언트가 락 획득에 실패한 경우, 모든 Redis 인스턴스에서 락을 해제한다.\n\nRedlock 의 실제 구현\n레디스 공식 문서에서는 Redlock 구현 방식을 아래와 같이 제시한다.\n\n1. Redis 명령으로 락 획득\n클라이언트는 아래와 같은 SET 명령을 수행하여 락을 획득한다.\nSET resource_name my_random_value NX PX 30000\n\n\nNX : 키가 존재하지 않을 때만 값을 설정한다.\nPX : 키의 TTL을 밀리세컨드 단위로 설정한다.\n\n2. Lua Script 를 사용하여 락 해제\n락 해제 작업을 Atomic 하게 수행하기 위해, 클라이언트는 아래와 같은 Lua Script 를 실행하여 락을 해제한다.\nif redis.call(\"get\", KEYS[1]) == ARGV[1] then\n\treturn redis.call(\"del\", KEYS[1])\nelse\n\treturn 0\nend\n\n\nKEYS[1] : 해제하려는 락의 Key 를 지정. 여기서는 resource_name 에 해당하는 값을 전달한다.\nARGV[1] : Lua Script 에서 사용할 인자의 값. 여기서는 my_random_value 에 해당하는 값을 전달한다.\n\nmy_random_value 가 무엇인가?\n여기에서 my_random_value 라는 랜덤한 값이 등장한다. 이 값은 락을 획득한 클라이언트만이 락을 해제할 수 있도록 보장하는데 사용된다.\n만약 레디스 키에 대한 DEL 명령을 누구나 실행할 수 있다면, 락을 획득하지 않은 클라이언트가 임의로 락을 해제하고 자신이 락을 획득할 수 있게 되고, 이는 상호 배제의 위반이다.\n이를 방지 하기 위해서, 락을 설정할 때 클라이언트가 랜덤 값을 생성하고, 락 Key의 Value 로 사용한다. 그리고 락을 해제할 때, 자신이 생성한 랜덤 값을 제시해서, 일치하는 경우에만 락을 해제한다 (Lua Script 의 로직). 이는 클라이언트가 락의 소유권을 증명하는 일종의 비밀번호라고 할 수 있다.\n\nRedlock 주의점\n\nClock Drift 문제\nRedlock 알고리즘에서 Redis 노드들 그리고 클라이언트 간에 동기화된 시계 (Synchronized Clock)가 존재하지 않는다. 그리고 Redlock 알고리즘은 참여자간의 로컬 시간이 거의 동일한 속도로 갱신된다는 가정에 의존한다.\n하지만 현실에서는 로컬 시계가 정확한 속도로 동작하지 않는 Clock Drift 현상으로, 시스템 내부 시계가 실제 시간과 불일치하는 현상이 발생할 수 있다. 이런 현상은 하드웨어 문제, 운영체제 스케줄링 문제 등 다양한 원인으로 인해 발생할 수 있다.\n\nClock Drift 발생 시나리오\nClock Drift 현상이 발생하면, 한 Redis 노드에서는 락이 유효하다고 판단하는 반면, 다른 노드에서는 해당 락이 이미 만료되었다고 판단할 수 있다. 예를 들자면, 아래와 같은 시나리오이다.\n5개의 레디스 노드가 존재하고, 3개의 노드에서 락을 획득하면, 락이 유효한 상황\n클라이언트 1은 A, B, C 노드에서 락을 획득했으나, 네트워크 에러로 D와 E 노드에서 실패\n노드 C의 시계가 클럭 드리프트로 인해, 시간이 미래로 점프했고, 조기에 TTL이 만료됨\n이 시점에 클라이언트 2가 C, D, E 에서 락을 획득함\n\nMIN_VALIDITY\n따라서, 클라이언트는 락 유효 시간에서 클럭 드리프트를 보정한 값인 MIN_VALIDITY 를 계산하고, 자신이 획득한 락의 안정성을 판단해야한다.\nMIN_VALIDITY 는 아래와 같이 계산한다.\nMIN_VALIDITY=TTL−(T2−T1)−CLOCK_DRIFTMIN\\_VALIDITY = TTL - (T2 - T1) - CLOCK\\_DRIFTMIN_VALIDITY=TTL−(T2−T1)−CLOCK_DRIFT\n클라이언트는 이와 같이 MIN_VALIDITY 를 계산하고, 아래와 같이 락 안정성에 대해 판단한다.\nMIN_VALIDITY 가 음수거나 너무 짧다면 : 락이 불안정하다고 판단하고, 사용을 중단하거나 락을 해제한다.\nMIN_VALIDITY 가 충분히 크다면 : 락이 안정적이라고 판단하고 작업을 진행한다.\n\nCLOCK_DRIFT 계산\n그렇다면, CLOCK_DRIFT 는 어떻게 계산할까? 일반적으로 CLOCK_DRIFT_FACTOR 라는 값을 활용하여 CLOCK_DRIFT 값을 계산한다. 산식은 아래와 같다.\nCLOCK_DRIFT=TTL∗CLOCK_DRIFT_FACTOR+δCLOCK\\_DRIFT = TTL * CLOCK\\_DRIFT\\_FACTOR + δCLOCK_DRIFT=TTL∗CLOCK_DRIFT_FACTOR+δ\n일반적으로 CLOCK_DRIFT_FACTOR 의 값은 1%로 설정하는데, 이는 네트워크 시간 프로토콜(NTP)을 통한 시계 동기화의 정확도에 기반한다고 한다.\nNTP의 정확도에 대한 연구에 따르면, NTP를 통해 동기화된 시스템 간의 시계 오차는 일반적으로 수 밀리초에서 수십 밀리초 수준으로, 전체 시간의 약 0.01%에서 0.1%에 해당한다고 한다. 따라서, 보수적인 접근으로 1%를 CLOCK_DRIFT_FACTOR 로 설정하여 시계 드리프트를 고려하는 것이 일반적이다.\n\nSplit-brain Condition\n클라이언트가 락을 획득하는데 실패한 경우, 재시도 정책에 따라 락 획득을 재시도할 수 있다. 그런데 만약 재시도 하려는 클라이언트가 많다면, 동시에 재시도 요청이 쇄도하는 Retry Storm 이 발생할 것이다. 이렇게 리소스에 대해 경쟁하면, 계속해서 충돌이 발생하고, 그 어떤 클라이언트도 과반수 이상의 인스턴스에서 락을 획득할 수 없다. 이런 상황을 Split-brain 상태라고 부른다.\n이를 해결하기 위해서, 레디스 공식 문서는 아래의 3가지 방법을 제시한다.\n랜덤 딜레이 : 클라이언트들이 동일한 시간에 동시에 시도하지 않도록, 재시도 간격을 무작위로 적용하여 타이밍을 분산시킨다.\n멀티 플렉싱 : 클라이언트는 모든 Redis 인스턴스에 병렬로 동시에 락 요청을 보낸다. 락 요청 속도가 빨라지면, 여러 클라이언트가 동시에 요청하는 Time Window 가 줄어들어, Split-brain 가능성이 감소한다.\n빠른 락 해제 : 클라이언트가 과반수 락 획득에 실패했다면, 즉시 부분적으로 획득한 락을 해제해야한다. 다른 클라이언트가 락을 요청할 때 키 만료를 기다리지 않도록 해, 락 충돌 가능성을 줄이고 가용성을 높인다.\n\n애플리케이션 중단 및 네트워크 지연으로 인한 문제\n만약 락을 획득한 클라이언트가 Full GC로 인한 Stop-the-world 가 발생하는 등 긴 지연에 걸리거나, 네트워크 지연이 발생한 경우, 지연이 해소되는 동안 TTL이 먼저 만료되는 상황이 발생할 수 있다. 이 경우 기존 클라이언트의 지연이 해소되기 전에, 다른 클라이언트가 락을 획득하고 임계 영역에 진입할 수 있다.\n이런 상황에서 지연된 애플리케이션이 다시 복구되었을 때, 자신의 락이 만료됨을 인지 못한다면, 그대로 임계 영역에서 다시 작업을 이어나갈 수 있고, 이는 상호 배제의 위반이다.",
        "content": "블로그에 글을 오랜만에 쓴다. 요즘 공부한 대부분의 내용은 개인 옵시디언에 작성하고 있어서, 블로그 같이 공개적인 공간에 글을 발행할 일이 없었는데, 의식적으로 블로그에도 글을 써보려 해야겠다. 최근에 Redlock…",
        "contentSnippet": "블로그에 글을 오랜만에 쓴다. 요즘 공부한 대부분의 내용은 개인 옵시디언에 작성하고 있어서, 블로그 같이 공개적인 공간에 글을 발행할 일이 없었는데, 의식적으로 블로그에도 글을 써보려 해야겠다. 최근에 Redlock…",
        "guid": "https://hudi.blog/redlock-algorithm/",
        "isoDate": "2024-11-23T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "소득공제 40% 혜택에 카드사용실적 반영까지 : 충전식 카드형 온누리상품권",
        "link": "https://blog.toss.im/article/money-policies-30",
        "pubDate": "Fri, 22 Nov 2024 03:58:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}온누리상품권을 더 쉽고 편하게 사용하는 방법을 소개합니다. 온누리상품권은 5천원, 1만원, 3만 원권 단위로 구매해 사용할 수 있는 소상공인시장 진흥공단에서 발행하는 지류상품권이에요. 액면가의 10% 할인된 금액으로 구매할 수 있고, 전통시장이나 다양한 상점에서 사용할 수 있어요.\n이런 온누리상품권을 종이 상품권이 없어도 언제 어디서든 사용할 수 있는 방법이 있는데요. 온누리상품권 모바일 앱에 내 카드를 등록 후 금액을 충전하고, 평소처럼 카드를 사용하면 돼요. 카드로 결제해도 온누리 상품권 할인혜택은 그대로 누릴 수 있어요.\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}지류 상품권과 마찬가지로 10% 할인가로 금액을 충전할 수 있어요. 10만 원을 충전하고 싶으면 9만 원만 결제하면 돼요. 전통시장 소득공제 혜택(최대 40%)과 온라인상품권 충전금액은 카드 사용실적에도 반영돼요. 평소 현금보다 카드 사용이 많은 소비자라면 더 유리하겠죠?\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n가입방법\n.css-hokoge{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;counter-reset:numberedList;}.css-hokoge ul,.css-hokoge ol{margin:16px 0 0;}.css-hokoge>li{counter-increment:numberedList;margin-bottom:16px;padding-left:24px;}.css-hokoge>li:last-of-type{margin-bottom:0;}.css-hokoge>li>span{position:relative;}.css-hokoge>li>span>:first-child::before{content:counter(numberedList) '.';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n온누리상품권 앱 다운로드 후 본인 명의의 신용카드나 체크카드*등록  \n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*신한, 현대, 삼성, 농협, 하나, 비씨, 국민, 롯데\n충전할 계좌를 선택하고 원하는 금액 입력\n\n충전 가능한 최대 금액은 월 200만 원이에요. 다만 충전액을 초과해 결제할 경우엔 전액이 일반카드로 결제되니 이 점 유의하세요. \n만약 온누리상품권을 자주 사용한다면 이런 경우에 대비해 ‘자동충전’ 기능을 활용하면 좋아요. 원하는 금액과 날짜를 설정해놓으면 잔액을 일정 금액 이상으로 늘 유지할 수 있어요. 매번 사용액을 신경쓰며 충전할 필요 없이 편리하게 사용이 가능해요.\n온누리상품권을 사용할 수 있는 가맹점도 앱에서 확인할 수 있어요. 앱에서 ‘가맹점 찾기’ 탭을 누르면 내 주변의 온누리상품권 사용처를 알 수 있고 ‘지도로 보기’를 누르면 위치까지 한눈에 파악할 수 있어요. 지역별·시장별 매장까지 검색할 수 있어요.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}Edit 이지영 Graphic 조수희 이제현",
        "content": "온누리상품권을 가장 쉽게  쓰는 방법을 소개해요.",
        "contentSnippet": "온누리상품권을 가장 쉽게  쓰는 방법을 소개해요.",
        "guid": "https://blog.toss.im/article/money-policies-30",
        "isoDate": "2024-11-22T03:58:00.000Z"
      },
      {
        "title": "연말정산 세액공제, 올해 마지막 절세 기회를 놓치지 마세요",
        "link": "https://blog.toss.im/article/economic-terms-37-year-end-tax-adjustment",
        "pubDate": "Thu, 21 Nov 2024 02:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-8atqhb{width:100%;}.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}이 글에서 알 수 있는 것들\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1kxrhf3{white-space:pre-wrap;}연말정산으로 세금을 환급받을 수 있는 실전 꿀팁\n소득공제와 세액공제 대체 어떻게 다른지?\n퇴직연금 실물이전 서비스 활용법\n\n.css-1c1qox8{font-size:30px;letter-spacing:0em;line-height:1.55;font-weight:bold;color:var(--adaptiveGrey900);margin:40px 0 4px;}\n.css-p4abj2{display:contents;line-height:1.55;}🔖 이번 주 경제 용어\n연말정산 세액공제\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n이번 주 경제 용어는 노후에 잘 살기 위해 필요한 정보예요.\n\n.css-1pgssrp{max-width:100%;border-radius:16px;}\n연말정산에서 산출된 세금에서 일정 금액을 직접 차감하는 방식이에요.\n\n\n어느새 2024년도 한 달밖에 남지 않았습니다. 올해가 다 가기 전에 해야 할 일이 무엇이 남았을까요? 만나야 할 사람도 떠오르고, 쓰지 못했던 휴가도 떠오릅니다. 재테크도 제대로 못 한 것 같아 아쉬운 마음도 들고요. 하지만 아직 희망이 하나 남아있어요. 바로 ‘연말정산’입니다. 올해는 연말정산을 조금 더 일찍 준비해 보시죠.\n연말정산은 근로소득자가 1년간 납부한 세금과 실제 납부해야 하는 세금을 비교하여 조정하는 절차입니다. 같은 연봉을 받더라도, 연말정산을 어떻게 준비하느냐에 따라 돌려받을 수 있는 세금의 차이가 크게 날 수 있는 거죠.\n올해 연말정산은 내년 1월 국세청의 '연말정산 간소화 서비스'가 오픈되면 시작되지만, 세금을 좀더 환급받고 싶다면 소득공제와 세액공제 항목을 12월 31일 전까지 미리 챙겨두는 것이 좋습니다.\n소득공제와 세액공제는 그렇게 어려운 개념이 아닙니다. 쉽게 말해 소득공제는 연 소득에서 일정 금액을 빼서 세금을 줄이는 것이고, 세액공제는 이미 계산된 세금에서 일정 금액을 빼주는 것입니다.\n고연봉자분들은 과세표준 구간이 높기 때문에 소득공제를 잘 활용해서 세율을 낮추는 것이 유리하고, 일반 연봉자분들은 세액공제를 통해 내야 할 세금을 줄이는 것이 더 효과적일 수 있습니다.\n\n소득공제 대상: 인적공제, 특별소득공제, 개인연금저축(2001년 이전 가입자만 가능), 주택마련저축, 신용카드 사용금액, 주택청약종합저축 등\n세액공제 대상: 교육비, 의료비, 보장성 보험료, 연금저축, 개인형 퇴직연금 등\n\n그런데 지금 소득공제를 받겠다고 가족 구성원을 늘릴 수도 없고, 세액공제를 받겠다고 교육비나 의료비를 마구 쓸 수도 없습니다. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}그렇다면 가장 현실적인 절세 방법은 무엇일까요? 바로 ‘연금’을 활용하여 세액공제를 받는 겁니다.\n대표적으로 연금저축과 퇴직연금 관련 금융상품을 활용하는 건데요. 개인연금으로 세액공제를 받을 수 있는 납입 한도는 최대 900만 원입니다. 연금저축펀드는 600만 원까지, 개인형퇴직연금(IRP)을 포함하면 900만 원까지 납입할 수 있으며, 이를 모두 채우면 최소 118만 8천 원에서 최대 148만 5천 원까지 환급받을 수 있습니다.\n\n.css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}🔗 함께 읽으면 좋은 아티클: 연금저축 vs IRP 내게 맞는 노후대비 연금 상품은?\n\n\n.css-2yhypk{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);font-style:italic;-webkit-text-decoration:underline!important;text-decoration:underline!important;}“은행이자보단 더 줘야할 것 아냐”...갈아타기 시작된 퇴직연금, 운용 잘하는 곳 어디?\n(매일경제 2024.10.31)\n퇴직연금 상품을 중도해지 없이 다른 금융사로 손쉽게 이전할 수 있는 현물(실물)이전 제도가 오늘부터 시행된다. 400조원 규모의 퇴직연금 시장을 둘러싼 금융사간 경쟁이 치열해질 전망이다.\n31일 금융권에 따르면 이날부터 퇴직연금 현물이전 제도가 본격 시행된다. 앞서 고용노동부·금융감독원·한국예탁결제원 등이 지난해 2월 태스크포스팀을 구성해 관련제도 마련에 나선지 1년8개월 만이다.\n퇴직연금 현물 이전 제도는 말 그대로 현재 퇴직연금 계좌에서 굴리는 상품을 해지하지 않고, 현 상태로 다른 금융사 계좌로 옮길 수 있게 하는 것이다. 퇴직연금 가입자가 수익률이 더 높은 금융사로 쉽게 이동할 수 있도록 선택권을 보장하기 위한 조치다. (중략)\n\n\n연말정산을 잘 활용하면 꽤 큰 금액을 환급받을 수 있습니다. 매년 찾아오는 절세 기회를 미리 준비하는 것이 중요해요.\n특히 이번에 도입된 ‘퇴직연금 실물이전 서비스’를 통해 기존 퇴직연금 상품을 다른 금융사로 쉽게 옮길 수 있게 되면서, 이왕 드는 퇴직연금을 더 나은 수익률을 제공하는 금융사로 이전하기가 한층 쉬워졌습니다. 만약 퇴직연금이 오랫동안 방치되어 있었다면 이번 기회를 활용해 다양한 금융사의 수익률과 수수료를 비교해 보고, 더 좋은 조건을 제공하는 곳으로 옮겨보세요. 단순히 금융사를 바꾸는 것만으로도 노후 자금을 크게 늘릴 수 있는 기회가 될 것입니다.\n기존에도 퇴직연금을 다른 금융사로 옮길 수 있었지만, 기존 상품을 매도하고 다시 매수해야 하는 번거로움과 손실 위험 때문에 많은 분들이 망설이셨습니다. 그러나 이제 퇴직연금 실물이전 서비스를 통해 이에 대한 부담이 크게 줄어들었습니다. 퇴직연금을 더 높은 수익률을 제공하는 금융사로 옮기는 것이 훨씬 간편해졌고, 이는 금융사 간 경쟁을 촉진시켜 우리 같은 고객들에게 더욱 유리한 환경을 만들어줄 것입니다.\n그렇다면 실물이전 서비스를 어떻게 활용해야 할까요? 우선적으로 할 일은 현재 내 퇴직연금 계좌를 확인하는 것입니다. 내 퇴직연금이 어디에 있는지, 어떤 상품에 투자되고 있는지를 파악하고, 현재 수익률이 어느 정도인지 확인해야 합니다. 만약 지금 운용 중인 상품이 수익률이 좋지 않거나, 다른 금융사에 비해 상대적으로 높은 수수료를 부과하고 있다면 이전을 고려하시는 게 좋겠습니다.\n\n💡 퇴직연금 실물이전 서비스 이용하려면?\n\n이전할 금융기관 선택 및 계좌 개설 → 실물이전 가능 상품 확인 → 기존 금융기관에 실물이전 신청 → 이전 절차 진행 및 완료\n퇴직연금 실물이전은 동일한 유형의 퇴직연금 제도(DB↔DB, DC↔DC, IRP↔IRP) 간에만 가능해요.\n이전하려는 금융기관에서 동일한 상품을 취급하지 않는 경우, 실물이전이 불가능할 수 있어요.\n\n\n\n.css-1lvcgm8{padding:22px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;border-radius:20px;}\n.css-13ko30i{width:375px;}토스에서 퇴직연금 손쉽게 옮기기\n\n연금저축펀드: 개인이 노후를 대비해 가입할 수 있는 연금 상품으로, 세액 공제를 받을 수 있어요. 100%까지 위험 투자 상품 운용이 가능하며, 납입한 금액에 대해 일정 금액의 세금을 공제받을 수 있습니다.\nDC형 퇴직연금: 확정기여형 퇴직연금 제도로, 회사가 근로자에게 일정 금액을 퇴직연금으로 납입하면, 그 금액을 근로자가 직접 운용하여 수익을 얻는 방식이에요. 근로자가 운용 결과에 따라 연금의 수익이 달라질 수 있습니다.\nIRP(개인형퇴직연금): 근로자가 퇴직 후의 노후 생활을 대비하기 위해 운용하는 퇴직연금 계좌. 70%까지 위험 상품에 투자할 수 있고 세액공제 혜택도 받을 수 있어서, 연금저축과 더불어 노후 자금을 마련하는 데에 유리해요.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 금혜원 Graphic 조수희 이동건",
        "content": "세금 환급을 위한 마지막 한 달, 놓치지 말아야 할 준비사항 총정리",
        "contentSnippet": "세금 환급을 위한 마지막 한 달, 놓치지 말아야 할 준비사항 총정리",
        "guid": "https://blog.toss.im/article/economic-terms-37-year-end-tax-adjustment",
        "isoDate": "2024-11-21T02:00:00.000Z"
      },
      {
        "title": "토스인컴, ‘숨은 환급액 찾기’ 서비스 이용 고객 대상 토스포인트 지급 이벤트",
        "link": "https://blog.toss.im/article/tossincome-event",
        "pubDate": "Thu, 21 Nov 2024 01:30:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}비바리퍼블리카(이하 토스)의 자회사 토스인컴(대표 박일용)이 셀프 세금관리 서비스인 ‘숨은 환급액 찾기’ 를 이용하는 고객을 대상으로 토스포인트 지급 이벤트를 연다고 21일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n숨은 환급액 찾기 서비스를 통해 예상 환급액을 확인한 뒤 두 개의 카드 중 당첨 카드를 고르면 예상 환급액 만큼 토스포인트를 받을 수 있는 이벤트다. 신고까지 마쳐야 토스포인트를 지급하며 신고를 취소한 경우 지급된 토스포인트는 회수된다.\n이벤트는 다음 달 17일 까지 한 달간 진행한다. 단, 예산 소진 시 이벤트가 조기 종료될 수 있다. 당첨 카드를 뽑지 못하거나 예상 환급액이 없는 고객은 랜덤 포인트를 받을 수 있다.\n토스인컴의 숨은 환급액 찾기 서비스를 이용하기 위해서는 토스 앱 > 전체 탭 > ‘세금・납부・민원’ 카테고리 > ‘내 환급액 확인하기’로 들어가거나 토스 앱 상단 돋보기 아이콘을 눌러 ‘숨은 환급액 찾기’ 또는 ‘세이브잇’을 검색하면 된다.\n한편 토스인컴은 토스가 지난 5월 세이브잇 운영사 택사스소프트를 인수하면서 출범했다. 숨은 환급액 찾기 서비스는 기한 후 신고 뿐 아니라 경정청구를 지원하고 중소기업 취업자 소득세 감면 등 다양한 항목의 셀프 신고를 지원하는 것이 특징이다.\n토스인컴 관계자는 “세금관리는 매일 써야 할 서비스는 아니지만, 금융 생활에서 반드시 마주치게 되는 영역”이라며 “토스인컴은 개인이 스스로 해결하기 어려운 세무 영역의 불편을 해소하고 누구나 쉽고 정확하게 세금 정산을 할 수 있는 세상을 만들어 가겠다”고 말했다.",
        "content": " 예상 환급액 조회하고 당첨 카드 고르면 예상 환급액 만큼 토스포인트 지급",
        "contentSnippet": "예상 환급액 조회하고 당첨 카드 고르면 예상 환급액 만큼 토스포인트 지급",
        "guid": "https://blog.toss.im/article/tossincome-event",
        "isoDate": "2024-11-21T01:30:00.000Z"
      },
      {
        "title": "토스 유튜브 채널 '머니그라피', 팝업 이벤트 개최",
        "link": "https://blog.toss.im/article/moneygraphy-popup",
        "pubDate": "Wed, 20 Nov 2024 01:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}오프라인에서 경험하는 머니그라피… 12월 6일부터 8일까지 성수동에서 열려\nB주류경제학 등 상시 전시와 7개의 라이브 토크쇼로 구성\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n모바일 금융 서비스 '토스'를 운영하는 비바리퍼블리카(이하 토스)가 자사 유튜브 채널 '머니그라피’의 팝업 이벤트를 12월 6일(금)부터 8일(일)까지 개최한다고 20일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n머니그라피는 2021년 9월 첫 영상을 시작으로 취향과 경제를 잇는 콘텐츠를 선보이고 있다. 소비문화 이면의 경제 이야기를 다루는 ‘B주류경제학’, 음악 산업에 관해 이야기하는 ‘머니 코드’, 한국의 소비문화와 트렌드를 탐구하는 ‘K’s스터디’ 등 다양한 시리즈가 사랑을 받으며 개설 3년여 만에 구독자가 36만 명을 넘어섰다.\n이번 팝업 이벤트는 12월 6일부터 8일까지 사흘간 성수동 세원정밀 창고에서 열린다. 공간은 차고(개러지, Garage) 콘셉트로 꾸미고 B주류경제학, 머니 코드, K’s스터디 등 크게 세 개의 파트로 구성했다. B주류경제학 스튜디오를 그대로 구현해 놓은 포토존부터 미공개 클립을 확인할 수 있는 비디오 렌털숍, 제작 현장을 간접 체험할 수 있는 편집실, 머니 코드 레코드숍, K's스터디 문방구 등 머니그라피를 다양한 방법으로 체험할 수 있다. 이에 더해 포토카드, 포스터, 티셔츠, 양말, 모자 등 브랜딩 굿즈도 판매해 팬심을 공략한다.\n예약 후 참여할 수 있는 7개의 라이브 토크쇼도 마련했다. 팝업 공간의 한 쪽에 라이브 스테이지를 설치, 사흘간 다양한 테마의 토크쇼를 운영한다. 첫째 날인 6일에는 K’s스터디를 테마로 진행자인 존박과 레오가 출연하는 세션이 열린다. B주류경제학을 테마로 하는 둘째 날에는 프로그램에 출연 중인 이재용 회계사와 토스 김창선 PD가 총 네 개의 토크쇼를 진행한다. 마지막 날인 8일에는 머니 코드를 테마로 진행자인 룩삼과 우키팝이 출연한다. 오후 6시 30분부터는 피날레로 넉살X까데호, 힙노시스테라피의 미니 콘서트도 연다.\n머니그라피 채널 연출을 총괄하는 토스 백순도 PD는 “머니그라피는 온라인 공간에서 시청자들과 활발하게 소통해오며 커온 채널이기에 오프라인에서 직접 만날 수 있는 기회를 마련하고 싶었다”라며 “다양한 프로그램과 즐길 거리를 준비한 만큼, 머니그라피를 사랑해 주시는 많은 분들이 방문해 주시기를 바란다”라고 전했다.\n미니 콘서트를 제외한 라이브 토크쇼는 11월 22일(금) 오후 6시에 머니그라피 유튜브 채널에서 선착순으로 참가 신청이 가능하다. 1인당 세션별로 1회만 신청이 가능하며, 각 세션별로 선착순 모집한다. 미니 콘서트는 현장에서 접수를 받는다. 팝업 이벤트와 관련된 자세한 사항은 머니그라피 유튜브 채널 내 커뮤니티 탭 혹은 토스 공식 인스타그램에서 확인할 수 있다.",
        "content": "12월 6일부터 8일까지 성수동에서 운영",
        "contentSnippet": "12월 6일부터 8일까지 성수동에서 운영",
        "guid": "https://blog.toss.im/article/moneygraphy-popup",
        "isoDate": "2024-11-20T01:00:00.000Z"
      },
      {
        "title": "우리나라는 노벨문학상을 또 받을 수 있을까?",
        "link": "https://blog.toss.im/article/monthly-tosspick-2024-10",
        "pubDate": "Tue, 19 Nov 2024 00:58:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}따뜻한 축하의 마음들이 거대한 파도처럼\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1kxrhf3{white-space:pre-wrap;}10월 10일 저녁, 평소엔 쥐 죽은 듯 조용한 카톡이 갑자기 시끌벅적해졌습니다. 한강 작가의 노벨문학상 수상 소식이 전해지자 초등학교 동창, 대학 동기, 회사 동료들 채팅방까지 ‘대박’과 ‘감동’이 쏟아졌어요. 예고 없이 찾아온 대한민국의 첫 노벨문학상 소식에 ‘따뜻한 축하의 마음들이 거대한 파도처럼’* 퍼져나갔죠.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*한강 작가는 수상 직후 서면으로 “하루 동안 거대한 파도처럼 따뜻한 축하의 마음들이 전해져 온 것도 저를 놀라게 했다. 마음 깊이 감사드린다.”는 짧은 소감을 밝혔습니다.\n한강 작가의 노벨문학상 수상은 모두의 예상을 뛰어넘는 일이었습니다. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}스웨덴 한림원이 2012년부터 남녀를 번갈아 수상자로 선정했기 때문에 올해는 여성 작가가 유력하다고 봤지만, 후보로 주목받던 중국의 찬쉐를 제치고 한강이 선택된 것은 놀라움 그 자체였죠. 뉴욕타임스도 “한강의 수상은 서프라이즈”라며 출판가 역시 예상치 못했던 결과라고 전했습니다.\n온라인 반응 역시 기쁨과 환희로 넘쳤습니다. ‘오늘부터 ‘문송합니다’ 금지’, ‘국문과 졸업하면 무엇을 하냐고? 노벨문학상을 받는 거다!’ 같은 유쾌한 반응들이 넘쳤고, 노벨문학상 수상작을 원서로 읽을 수 있다는 뿌듯함도 더해졌죠.\n6일 만에 달성한 대형 출판사의 1년 매출\n노벨문학상 수상 이후 지금까지 출판 시장은 모처럼 활기를 되찾았습니다. 온라인 서점은 접속자가 몰려 마비되고, 오프라인 서점에서는 ‘오픈런’까지 이어졌죠. 인쇄소는 행복한 비명을 지르며 밤새 기계를 돌렸지만, 폭발적인 수요를 따라가지 못해 중고 앱에서는 한강 작가의 단행본이 14만 원까지 올라오기도 하고요.\n수상 단 6일 만에 한강 작가의 책은 100만 부가 판매되었습니다. 이 시기 예상 매출액이 유명 출판사의 한 해 매출 전체와 비슷하다고 하니, 한국 출판 시장에 그야말로 ‘기적’이 찾아온 셈입니다. 뿐만 아니라, 한강 작가의 도서를 제외한 국내 도서 판매량도 전년 대비 7% 증가하며 출판 업계에 활기를 불어넣었습니다.\n하지만 이런 경사 속에서도 동네 서점들은 큰 어려움을 겪어야 했는데요. 도·소매를 함께하는 대형 서점이 사실상 출판 유통을 독점해 한강 작가의 책을 찍어내고 판매하는 사이, 동네 책방들은 책을 구하지 못해 손님들을 되돌려 보내야 했거든요.\n논란이 계속되자 교보문고는 한강 작가의 책을 10월 22일부터 31일까지 한시적으로 판매하지 않고, 해당 기간 입고된 책은 모두 동네 서점에 공급하기로 결정했습니다. 노벨문학상은 한국의 ‘도서 유통 구조’까지 다시 한 번 돌아보게 했죠.\n매월 하나의 키워드를 선정해 경제적 시선으로 질문을 던져보는 <월간 토스픽>. 이번 달은 한강 작가의 《소년이 온다》를 편집한 김선영 편집자와 함께합니다. 한강 작가님과 함께 울어버린 비하인드부터 책 한 권을 팔면 출판사는 얼마를 남기는지, 출판업계의 수익 구조와 다음 노벨문학상 후보로 주목하면 좋을 작가들까지 살펴봅니다.\n\n\n우리나라는 노벨문학상을 또 받을 수 있을까?\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n🎙️ Interviewee 김선영\n\n한국문학 편집자로 활동하며 다수의 시집과 소설책을 만들었다. 책임편집을 맡은 주요 작품으로는 《소년이 온다》 《피프티 피플》 《달까지 가자》 《연년세세》 《철도원 삼대》 등이 있다. 현재는 출판사 .css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}핀드에서 '오래 간직할 책, 오래 기억될 이야기'를 모토로 책을 만들며 책 읽는 즐거움을 더하는 방법을 궁리하고 있다. 쓴 책으로 《아무튼, 스윙》이 있다.\n\n우리가 좋은 문학 작품을 \n만나기까지 벌어지는 일\n노벨문학상 발표 직후에 《소년이 온다》 담당 편집자임을 밝히며 축하 게시물을 올리셨지요. 기분이 어떠셨나요?\n막히는 강변북로 위에서 지루하게 운전을 하고 있었는데, 정신이 번쩍 들었습니다. 한강 작가님의 대표작을 함께 만든 편집자로서 이미 큰 자부심을 갖고 있었고, ‘언젠가 한국에서도 노벨문학상을 받는 날이 온다면 한강 작가님이 받을 것 같다’고 생각했지만 올해일 거라고는 생각지 못했어요. 덕분에 《소년이 온다》의 편집자로서 덩달아 저도 많은 축하를 받았습니다. 그날 이후 \"한국문학, 만세!\"를 여러 번 외쳤어요.\n편집자가 책의 시작부터 끝까지 모든 과정을 책임진다는 점은 어느 분야나 비슷하겠지만, 특히 문학 편집자는 소설이 출간되기까지 어떤 역할을 하게 되는지 궁금합니다.\n문학 작품은 작가의 세계를 인정한 상태에서 출간 결정을 하는 것이라서 먼저 아이템을 제안하는 경우보다는 ‘작가가 쓰고자 하는 이야기’에서 출발하는 때가 많아요. 대신 편집자는 작품의 전체 흐름을 보고 피드백하며 수정을 같이 해나가게 됩니다. 한 인물이 갑자기 개연성 없는 행동을 한다든지, 결말에 와서 이야기를 끌어온 힘이 떨어졌다든지 하면 원고의 첫 번째 독자로서 작가와 대화도 많이 나눠요.\n작가나 작품마다 해야 하는 역할도 달라져서 초교(첫 교정)를 시작할 때는 늘 떨려요. 처음 담당하는 작가의 작품이면 전작들을 읽어보면서 문체나 톤을 공부하고 그에 맞는 편집을 합니다. 특정 장면에서 조금 더 정확하게 표현할 수 있는 단어를 함께 찾기도 하고, 소설집의 경우에는 몇년간 쌓아온 단편들의 순서를 잡고, 작품들을 아우를 수 있는 제목도 붙이죠. 그러다 때로는 어떤 단편의 소재나 세계관을 살려 장편으로 써보실 것을 제안하기도 해요. 《채식주의자》가 이전작인 단편 〈내 여자의 열매〉에서 상상력을 극대화해 탄생하게 된 작품인 것처럼요.\n《소년이 온다》의 작업 과정은 어땠나요?\n《소년이 온다》는 창비의 문학블로그 ‘창문’에서 2013년에 먼저 공개했어요. 무려 매일 연재였죠. 문예지가 새롭게 독자를 만나는 방법이 한창 블로그나 웹진일 때가 있었거든요. 정세랑 작가의 《피프티 피플》, 천운영 작가의 《생강》 등도 모두 창문에서의 연재로 선보인 작품이에요. 신문에 연재하는 것처럼 월요일부터 금요일까지 매일 올려야 하다 보니까 힘든 마감도 많았는데 한강 작가님은 미리 원고를 꽤 보내주셔서 제가 여유롭게 편집하고 임의로 분량을 나눠서 올릴 수 있었어요.\n뵌 적은 없지만 왠지 인터뷰만 봐도 원고가 준비되어 있지 않으면 연재 시작을 안 하실 것 같아요.\n맞아요. 큰 틀이 잡혀 있었고, 아무리 늦어도 몇 주 전에는 원고가 들어왔어요. 그렇게 2014년 1월까지 연재하며 초고를 마련하고 몇달 시간을 가지면서 수정한 뒤 2014년 5월에 출간했어요. 그 기간 동안 편집부 의견도 드려서 뒷부분 수정도 좀 있었고요.\n《소년이 온다》 작업 후에 기억에 남는 일이 있으신가요?\n《소년이 온다》는 제게도 각별한 작품이었는지, 10년이 지났는데도 책을 만들고 작가님과 소통하던 많은 장면들이 오래 남아 있어요. 책이 출간되고 나서 작가가 직접 낭독하는 오디오북을 제작하기 위해 스튜디오에서 만났는데, 1장을 녹음하다가 한강 작가님과 스태프 모두가 눈물이 터지는 바람에 녹음을 멈춘 적이 있었어요. 한참을 쉬다가 결국 한 권 낭독은 불가능하다는 걸 알고 녹음을 중단했습니다. 작품 속 인물의 목소리를 한강 작가님의 음성으로 들으니 더 애틋했어요. 이런 호흡과 감정으로 쓰셨구나를 느낀 순간 다 같이 울어버렸습니다.\n노벨문학상이 발표되고 한강 작가님의 작품을 출간한 출판사들까지도 화제에 올랐죠. 창비, 문학동네, 문학과지성사, 모두 우리나라를 대표하는 문학 출판사들이더라고요. 한국 문학계는 대형 출판사만 유명한 작가의 작품을 낼 수 있는 환경인가요?\n그렇지는 않아요. 만약 한 출판사의 문예지로 등단을 했다면 7~10편 정도의 단편 소설이 쌓였을 때 보통은 등단한 출판사에서 첫 소설집을 내요. 그러고 나면 다른 출판사들에게도 기회가 생깁니다. 그 작가의 초기작을 보고 너무 좋았다면 가능성을 보고 작품이 아직 다 모이지 않았지만 미리 출간 제안을 해서 두 번째 소설집 계약을 해두는 거예요.\n문예지가 있는 곳, 혹은 작품을 아직 못 봤어도 투자할 수 있는 여력이 되는 곳은 대부분 규모가 큰 출판사이다 보니까 좋은 작가의 작품을 가져가게 될 가능성이 큰 것은 맞죠. 그런데 요즘은 작은 출판사가 신선한 기획을 많이들 하고 있어서 알려진 소설가들이 규모가 작은 곳에서 소설집이나 에세이를 내는 경우도 늘고 있어요. 레제에서 출간한 김연수 작가의 《너무나 많은 여름이》처럼 늘 호흡 맞추던 편집자가 독립해서 함께한 케이스도 있고, 프란츠에서 출간한 김애란, 김연수, 윤성희, 은희경, 편혜영 작가의 《음악소설집》은 안정적인 기획을 보여주는 소규모 출판사의 재밌는 시도라 응원하는 마음이에요.\n만약 1인 출판사를 한다면 저도 좋은 문학 작품을 낼 수 있나요?\n다른 곳보다 빠르게 제안할 수 있도록 작품을 알아보는 눈, 이전 작업에서 쌓은 신뢰관계, 충분히 투자할 수 있는 돈. 셋 중 하나가 있으면 가능하지요. 다만 셋 중 셋이 다 있더라도 고려해야 할 것은 소설이 시간이 많이 필요한 작업이라는 점이에요. 좋은 작가들은 앞으로 쓸 작품이 서너 편씩 이미 계약되어 있어요. 그럼 저는 다섯 번째에 줄을 서는 거죠.\n최근 실제로 이런 대화를 한 적이 있어요. 친한 작가에게 “우리도 같이 작업하자”고 했더니 “너무 좋은데 계약이 많이 쌓여 있다”고 하더라고요. 지금부터 장편 소설 다섯 편이 나오려면 최소 10년은 걸리잖아요? 그래서 저도 얘기했어요. “10년 금방이더라. 그럼 우리는 10년 뒤에 작업하는 걸로 하자.”\n농담처럼 얘기했지만 사실 농담이 아니라는 걸 서로 너무 잘 알고 있어요. 작가에 대한 믿음으로 10년 뒤를 계약하는 게 엄청난 것처럼 보이지만 살아남는다면 무엇이든 가능하니까요. 작가는 글 쓰기를 멈추지 않고, 출판사는 잘 살아남기를 멈추지 않아서 언젠가는 만나는 것, 이게 지금 저에게는 가장 큰 숙제예요. \n작가, 출판사, 서점은 \n책 한 권 팔면 얼마를 벌까\n‘살아남기’에 대해 말씀하시니 출판시장 이야기를 안 할 수 없는데요, 한강 작가님의 작품들이 일주일 만에 100만 부 판매를 돌파했다는 게 알려졌을 때, 온라인 커뮤니티에 “이 100만 부의 예상 매출액이 유명 출판사의 한 해 매출 전체와 비슷하다”는 글이 떠돌았어요. 댓글에서는 “그 출판사 좋아하는데 그거밖에 안 되냐”는 반응들이 있었고요.\n‘업계에서 손에 꼽히게 인지도 높은 브랜드의 매출이 그 정도?’라고 생각하실 테니 이해가 되는 반응이에요. 아마 그 매출에서 출판사가 실제로 남길 수 있는 비율을 알면 더 놀라실 텐데요… 10%도 안 되는 경우가 허다합니다.\n\n\n〈.css-114ityv{white-space:pre-wrap;cursor:pointer;-webkit-text-decoration:underline!important;text-decoration:underline!important;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}B주류경제학 - 출판 편〉에서 살펴본 주요 출판사들의 손익계산서를 들여다보면, 매출액에서 인건비 등 각종 비용을 제하고 남는 영업이익률이 1~18%였으며 평균적으로 10% 안쪽이라는 것을 확인할 수 있어요. 이것도 대형 출판사로 꼽히는 곳들의 손익임을 고려하면, 영상의 제목 ‘재무쟁이는 이해를 포기한 산업’이 이해되고 맙니다. (출처=머니그라피)\n책 한 권이 팔리면 얼마 남게 되는지 더 자세히 알려주실 수 있을까요?\n보통 책이 나오면 40% 정도가 도소매 서점 수수료로 나가고 출판사에 60%가 남아요. 그 안에서 20~25% 정도가 제작비와 유통·물류비로 나가고, 저자 인세 10%를 드립니다. 그럼 다시 남은 20~25%를 출판사 매출(마진)로 볼 수 있고, 출판사는 그 안에서 다시 책 마케팅비, 디자인비, 인건비 등을 써요. 그러다 보면 영업이 잘된 출판사는 10% 이상, 안 된 출판사는 10% 미만이 남게 됩니다.\n요즘 중쇄 찍기가 힘들다고들 하잖아요? 그런데 저처럼 소규모 출판사는 한 권당 제작원가가 더 비싸기 때문에 1쇄만 다 팔아서는 영업이익 남기기가 힘들어요. 그럼에도 좋은 책을 만들어서 2쇄부터 조금씩 수익을 남겨야 하는 거죠. 제 인건비도 그때부터 발생한다고 봐야 해요.\n\n\n정가가 15,000원인 책 한 권을 팔았을 때 출판사는 1,500원도 못 남기는 경우도 많겠네요.\n그렇죠. 저는 출판사 입장에서 말씀드렸지만 비율이 가장 큰 서점 마진도 영업이익률이 높기는 힘들어요. 우선 30~45% 안에 독자분들께 해드리는 가격 할인 10%, 마일리지 등 간접적으로 해주는 할인 5%가 들어가 있어요. 그게 도서정가제*에서 정한 할인의 상한선이고요. 그럼 서점에게도 15~30%가 남죠? 그 안에서 당일 배송도 해드려야 하고, 인건비 등 비용을 쓰고 수익을 남겨야 합니다.\n*도서정가제: 책값 인하 경쟁이 과열되는 것을 방지하고 문화상품을 보호하기 위해 정해진 비율 이상으로 책을 할인 할 수 없게 한 제도.\n\n이런 구조이기 때문에 아무리 유명한 작가라도 인세가 10%인 것이겠죠? 인센티브, 혹은 전자책·장르물 등의 높은 인세는 예외로 두고요.\n저자 인세가 10%로 동일하다는 것은 출판계에 자리 잡은 합리적이고 공평한 시스템이라고 생각해요. 다만 ‘몇년 동안 한 작품을 써냈을 때 받을 수 있는 보상으로 적당한가?’를 작가 입장에서 계산해보면 너무 적은 것도 사실이죠. 15,000원짜리 책을 냈을 때 한 권이 팔리면 1,500원을 받아요. 신입사원 초봉 3천만 원만큼 벌려면 2만 권이 팔려야 합니다. 그런데 2만 부 팔리는 책은 너무 적고, 초판 1쇄 2천 부를 겨우 다 팔았다면 3백만 원을 벌어요. 그 책을 3년간 썼다면 연봉 1백만 원이죠. 웬만해서는 전업작가를 하기 힘든 게 현실이고요.\n책값이 너무 저렴하다 보니 ‘적은 마진’이라는 짐을 출판사, 서점, 작가가 나눠 지고 있는 것 같아요.\n일반적인 단행본의 평균 가격이 15,000원 미만에서 이제는 1만 원 후반대~2만 원대*로 올랐고, 서점의 무료 배송 기준도 10,000원에서 15,000원으로 올랐지만 여전히 다른 비용 상승에 비하면 책값은 너무 싸요. 예를 들어 종잇값과 인쇄비 등 제작비는 정말 많이 올랐거든요.\n*2023년 발행 도서의 평균 가격은 1만 8,633원으로 전년 대비 4.3% 올랐다.(출처=대한출판문화협회의 '2023년 기준 한국 출판생산 통계')\n책을 즐겨 읽는 사람들이 줄어들어서 출판시장 자체가 작아지고 있는 것이 가장 근본적인 문제이겠지만, 매출을 낼 수 있는 단가(책값)가 비용에 비해 낮다는 것도 고질적인 문제예요. 동시에 책은 학습·교양 등의 목적으로 사치재보다는 필수재로 여겨지는 성격을 가지고 있어요. 그러므로 가격 저항이 센 편이라서 갑자기 올리기는 어렵고 민감한 부분이기도 합니다.\n한강 작가님 또한 작은 서점을 운영 중이었다는 게 알려져서 화제였지요. 한편 대형서점과 동네서점의 책 공급 관련 갈등도 불거졌고요. ‘제2의 한강’이 나오려면 출판 생태계가 건강하게 돌아가고, 다양성이 지켜져서 좋은 작가, 좋은 작품 풀이 넓어져야 할 텐데, 그러기 위해 어떤 것들이 필요하다고 생각하시는지요?\n두 가지를 꼽을 수 있어요. 첫 번째는 소비적인 가격 경쟁을 막고 다양한 시도가 가능한 환경을 만들기 위해서 도서정가제가 잘 지켜지는 것, 두 번째는 세상에 너무나 다양한 책이 있으니 취향에 맞거나 필요한 책을 발견해서 읽어보고 그 좋은 경험을 잊지 못하는 독자들이 늘어나는 것이에요.\n노벨문학상 수상작을 원서로 읽는 기쁨이 우리에게 찾아왔어요. 출판계로서는 듬뿍 관심을 받는 드문 기회였는데, 이번 기회에 ‘책 읽는 것 너무 좋다’를 경험하는 독자들이 많이 생길 수 있을까요?\n많은 분들이 한강 작가의 책을 샀지만 마냥 쉬운 작품들은 아니라서 갑자기 한 권을 다 읽어내기 어려울 수 있어요. 《채식주의자》가 힘들었다면 잠시 내려놓고 다른 책을 읽어보면 돼요. 저는 사적인 애정까지 조금 담아서 《소년이 온다》를 추천하고 싶고, 한강 작가님은 수상 후 인터뷰에서 \"모든 작가는 자신의 가장 최근 작품을 좋아한다. 따라서 나의 가장 최근 작품인 《작별하지 않는다》가 시작이 될 수 있기를 바란다\"고 하셨어요. 이제 곧 겨울이 오니까 《흰》도 계절의 분위기와 잘 어울릴 거예요.\n그러다 한강 작가님이 최근에 읽었다고 밝힌 조해진 작가의 《빛과 멜로디》, 김애란 작가의 《이중 하나는 거짓말》로 넘어가 보셔도 좋고, 뭐가 재밌을지 잘 모르겠다면 동네서점에 찾아가보셔도 좋아요. 그럼 또 다른 취향이 묻어나는 추천을 받을 수 있거든요.\n같이 읽는 경험을 해보는 것도 권하고 싶어요. 같은 책을 읽은 다른 사람의 언어로 해석하는 걸 듣고, 여러 세계가 겹쳐지면서 내 세계가 풍부해지는 경험이 되게 좋아요. 관심 있는 작가가 있으면 북토크도 가보고, 어느 날은 가방에 책도 챙겨서 나와보고요. 읽다 말아도 괜찮으니 책 읽기를 포기하지 않으셨으면 하는 마음이에요.\n올해 노벨문학상은 ‘아시아 여성 작가’ 차례라며 중국 작가 찬쉐가 가장 유력한 후보로 꼽혔었지요. 또 다른 후보로는 노르웨이의 욘 포세, 호주의 제럴드 머네인, 캐나다 시인 앤 카슨 등이 있었던 한편 한국 작가는 상위권에 없었다는 것도 이야깃거리였어요. 해외에서 K-문학 열풍은 이제 진짜 시작이 아닐까 싶은데, 어떤 작가들이 다음 노벨문학상 후보로 거론되나요?\n한강 작가의 수상을 계기로 더 많은 한국 문학 작품이 번역되면 앞으로 더 많은 기회가 오겠죠. 김혜순 시인, 황석영 작가는 늘 수상 가능성이 있는 분들이고, 개인적으로는 《단 한 사람》을 쓴 최진영 작가, 《여름과 루비》를 쓴 박연준 작가, 《자두》를 쓴 이주혜 작가를 눈여겨 봐주셨으면 해요.\n대표님도 눈여겨 보고 있는 작가들의 작품을 출간할 계획인가요?\n네, 자유롭게 작업하려고 소규모 출판을 시작했으니 재밌는 시도 많이 해봐야죠. 오래된 작품을 복원하는 것, 지금 좋은 작품 세계를 보여주는 작가들과 함께 작업하는 것, 그리고 글이 좋지만 한번도 책을 내보지 않은 분들 발굴해서 ‘첫 책’을 탄생시키는 것, 세 가지 일을 계속하려고 합니다.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nInterview・Edit 주소은, 이지영 Graphic 조수희, 이제현",
        "content": "월간 토스픽 10. 노벨문학상과 K-문학",
        "contentSnippet": "월간 토스픽 10. 노벨문학상과 K-문학",
        "guid": "https://blog.toss.im/article/monthly-tosspick-2024-10",
        "isoDate": "2024-11-19T00:58:00.000Z"
      },
      {
        "title": "부자는 반드시 사회에 환원해야 할까?",
        "link": "https://blog.toss.im/article/everyday-economics-20-noblesse-oblige",
        "pubDate": "Mon, 18 Nov 2024 01:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}이 글에서 알 수 있는 것들\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1kxrhf3{white-space:pre-wrap;}연말에 자주 들리는 부자들의 기부 소식, 세금 회피가 목적이라 봐야 할까?\n부자들에게 사회적 환원을 강제하는 것, 이중 과세라 봐야 할까?\n부자가 된 개인, 기업이 사회에 기여하는 방법엔 어떤 것들이 있을까?\n\n\n.css-94on8q{white-space:pre-wrap;color:#c770e4;font-weight:bold;}에디터 G (이하 G): 교수님, ‘전 세계에서 가장 부자인 사람’이라는 말을 들으면, 누가 가장 먼저 떠오르시나요?\n.css-12p6bv8{white-space:pre-wrap;color:#15c47e;font-weight:bold;}교수 K (이하 K): 실제 부자 순위는 매년 달라지지만, 세계 최고의 부자라고 하면 역시나 ‘빌 게이츠’의 이름이 가장 먼저 생각나지 않을까 싶습니다.\n다들 잘 알고 있는 것처럼, 빌 게이츠는 마이크로소프트를 창업해 막대한 부를 쌓았는데요. 2024년 기준으로 그의 재산은 약 1,056억 달러로, 원화로는 무려 145조 원에 이른답니다.\nG: 정말 어마어마한 부를 창출해낸 부자네요. 세계 최고의 부자들로 이름이 알려진 사람들 중에서도 빌 게이츠가 특별한 이유가 있을까요? 교수님은 어떻게 생각하세요?\nK: 여러가지 이유가 있겠지만, 빌 게이츠가 특별하게 거론되는 이유는 다양한 기부 활동을 해왔기 때문인 것 같습니다. 빌 게이츠와 전 부인인 멀린다 게이츠는 빌 & 멀린다 게이츠 재단(Bill & Melinda Gates Foundation)을 설립하여, 전 세계의 질병 퇴치, 빈곤 문제 해결, 교육 기회 확대 등을 위해 수백억 달러를 기부해 왔어요. \n워런 버핏도 빌 게이츠와 손을 잡고 ‘더 기빙 플레지(the giving pledge)’ 캠페인을 통해 자신의 재산을 사회에 환원하기로 약속했으며, 이후에 많은 부자들이 동참하게 됩니다.\nG: 많은 부를 쌓은 사람들이 자신들의 재산을 자발적으로 사회에 환원하는 것은 멋진 일인 것 같아요. 사회에 긍정적인 영향을 가져다 주니까요.\nK: 맞아요. 하지만 한편으로는 부유층의 기부를 바라보는 부정적인 시각도 일부 존재합니다. 예를 들면, 부유층의 자선 활동이 세금 감면 등 경제적 혜택을 가져다 주기 때문에 이뤄진다는 거예요. 기부가 공익보다는 부유층의 개인적 선호와 영향력 확대에 사용될 가능성이 있다는 점에서, ‘진정한 의미의 사회적 환원인지’를 묻는 것이죠.\nG: 아하, 기부나 자선 사업의 근본적인 이유에 의문을 제기하는 입장이겠군요. 실제로 연예인이나 공인이 기부를 했다는 기사가 뜨면 “세금 회피가 목적이겠네”는 댓글이 종종 보이더라고요.\nK: 에디터 님은 어떻게 생각하세요? 많은 부를 축적한 개인이나 기업이 반드시 사회에 환원해야 할까요? 이 질문에 대해 찬성과 반대의 두 입장으로 나누어서 한번 살펴보도록 할게요.\n\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n1. 찬성 입장: \n부유한 개인이나 기업은 반드시 사회에 환원해야 한다.\nK: 가장 먼저 생각해 볼 수 있는 것은 .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}‘공공재의 이용에 따른 사회적 책임’입니다. 현재의 경제 체제 하에서는 어떤 개인이나 기업도 온전히 자신의 힘만으로 부를 쌓았다고 주장할 수 없습니다. 어떤 식으로든 우리 사회가 무상으로 제공하는 공공 인프라를 이용해서 부를 축적했기 때문에, 자신의 재산 일부를 환원함으로써 사회적 책임을 다할 의무가 있다는 것이죠.\nG: 그렇겠네요. 개인이든 기업이든 사회를 함께 살아가는 구성원들이 힘을 합쳐 만든 인프라의 덕을 보는 것이니까요.\nK: 이 논리의 핵심은 바로 공공재입니다. 경제학에서는 재화를 경합성(rivalry)과 배제성(excludability)이라는 두 가지 기준을 사용해 분류하곤 하는데요. 여기서 ‘경합성’은 특정 재화에 대한 나의 소비가 다른 소비자의 사용에 영향을 미치는지를 의미하고요. ‘배제성’은 특정 개인이나 집단이 그 재화를 사용하지 못하도록 배제할 수 있는지를 의미합니다.\n이 두 가지 기준을 이용하면, 아래 그림과 같이 재화를 네 가지 유형으로 나눌 수 있어요.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\nG: 들어본 것도 있고 처음 접하는 것도 있네요. 각 재화에 대해 좀더 자세히 설명해주실 수 있을까요?\nK: 그럼요. 먼저, 사유재(private goods)는 개인이 소유하고 사용하는 상품, 서비스를 말해요. 내가 돈을 주고 사면 다른 사람은 못 쓰는 물건이라 생각하면 됩니다. 우리가 시장에서 일반적으로 사고 파는 상품들이 대부분 여기에 속해요.\n사유재는 개인이 완전히 소유하고 관리할 수 있는 재화라서, 한 사람이 사용하면 다른 사람의 사용이 제한되는 등 경합성이 강한 편입니다. 그리고 가격을 지불해야만 소비할 수 있기 때문에 배제성도 강해요.\n두번째로 공공재(public goods)는 사유재와 완전히 반대예요. 누구나 자유롭게 이용할 수 있는 상품, 서비스죠. 아무나 이용할 수 있고, 그 누가 사용하더라도 다른 사람에게 큰 영향을 미치지 않습니다. 우리가 길에서 흔히 볼 수 있는 가로등, 누구나 들어갈 수 있는 공원, 정부가 국민을 위해 제공하는 국방 등이 공공재에 해당하죠.\n공공재는 누군가 소비하더라도 다른 사람이 동일한 재화를 소비하는 데에 제한이 없습니다. 경합성이 약해요. 또한 대가를 지불하지 않은 사람도 자유롭게 사용할 수 있기 때문에 배제성 또한 약합니다. 시장에서는 공급이 이루어지지 않기 때문에 주로 정부가 제공하게 돼요.\nG: 사유재, 공공재는 일상에서 늘 사용하고 있는 재화네요. 이해가 쉬워졌어요. 클럽재, 공유자원은 어떤건가요?\nK: 그 둘도 설명을 들어보시면 익숙한 개념일 거예요. 클럽재(club goods)는 제한된 일부 사람들만 이용할 수 있는 상품이나 서비스를 말해요. 클럽에 속한 ‘회원’들만 이용할 수 있는 시설이나 서비스 같은 건데요. 티빙이나 넷플릭스 같은 유료 OTT 서비스, 헬스클럽이나 골프장 등이 여기에 속합니다.\n클럽재는 경합성이 약하기 때문에, 특정 시점에 모든 사람들이 꽉 채워 사용하지 않는 이상 회원들이 다같이 이용할 수 있습니다. 즉, 여러 사람이 동시에 이용해도 서비스나 재화의 질이 크게 저하되지 않아요. 그러나 일정 비용을 내야만 사용할 수 있기 때문에 이용 권한이 제한되어 있어요. 누구나 사용할 수는 없다는 측면에서 배제성은 강합니다. 공공재와 사유재의 중간쯤 되는 재화라 보시면 돼요.\n마지막으로 공유자원(common resources)은 모두가 이용할 수 있지만, 사용할수록 줄어드는 재화를 말해요. 누구나 자유롭게 이용할 수 있지만, 덮어놓고 사용하면 부족해질 수 있는 자원이에요. 어업 자원(물고기)나 공공 목초지나 숲, 바다, 강물 등이 여기에 속합니다.\n공유자원은 경합성이 강하기 때문에, 한 사람이 소비하면 양이 줄어들어요. 다른 사람의 소비에 영향을 미치는 것이죠. 그리고 배제성은 약해서 누구나 자유롭게 돈을 내지 않고도 사용할 수 있습니다. 이런 재화는 ‘공유지의 비극(tragedy of commons)’이라 불리는 과잉 소비 문제가 발생할 수 있기 때문에, 이를 관리하기 위해 정부 개입이나 규제가 필요할 때가 많아요.\nG: 우리 사회를 이루고 있는 재화를 크게 네 가지로 나눠볼 수 있겠군요. 이번 아티클에서는 특히 ‘공공재’를 주목할 필요가 있을 것 같아요.\nK: 맞습니다. 부자들이 부를 축적하는 과정에서 무상으로 사용할 수 있는 것이 바로 공공재이기 때문인데요. 공공재의 주요 예시로는 교통 인프라, 법과 치안 시스템, 공교육 제도 등이 있습니다. 이러한 공공재는 개인이나 기업이 별도의 비용을 부담할 필요가 없기 때문에, 경제적 성공을 이루는 중요한 기반이 될 수 있습니다.\n실제로 많은 기업이 부를 축적하는 과정에서 이러한 공공재를 활용했습니다. 예를 들어, 대형 전자상거래 기업은 물류의 신속성과 효율성을 극대화하기 위해 도로와 공항 등의 교통 인프라를 필수적으로 사용합니다.\n이러한 인프라는 정부가 유지하고 관리하는데요. 기업은 이 공공재를 통해 물류 비용을 절감하고 빠른 배송 서비스를 제공할 수 있습니다. 이러한 교통망이 없었다면 물류 비용은 크게 증가했을테고, 소비자와의 접근성이 떨어지니 경쟁력 또한 낮아졌을 것입니다.\nG: 그렇겠네요. 이미 정부가 깔아둔 도로나 교통 인프라 덕분에 기업의 물류 시스템이 작동할 수 있는 것이니까요.\nK: 또한 많은 기업들이 법적 시스템을 통해 지적 재산권을 보호받고 있습니다. 막대한 비용을 쏟아 부은 연구 개발의 성과를 특허로 보호받음으로써, 경쟁력 있는 기술을 유지할 수 있는 것이죠. 기업의 혁신과 기술 보호에 꼭 필요한 안정적인 법과 치안 시스템은 세금으로 운영되는 대표적인 공공재입니다.\n공교육 제도 또한 넓게 보면 기업들이 이용할 수 있는 공공재라 할 수 있습니다. 기업이 지속적으로 성장하고 기술 혁신을 이루어내기 위해서는 우수한 인적 자원이 필수적인데요. 한 명의 우수한 인적 자원을 양성하기 위해서는 초등학교부터 대학교까지 오랜 시간이 소요됩니다. 이 과정에서 공적 재원이 투입된 공교육 제도가 중요한 역할을 하고 있죠.\nG: 공공재 관점에서 보면, 부자가 된 개인이나 기업은 무상으로 제공된 교통 인프라, 법과 치안 시스템, 교육 제도 등을 활용하여 부를 축적해 왔다고 할 수 있겠군요.\nK: 이러한 공공재는 단순히 개인의 성공을 위해 존재하는 것이 아닙니다. 사회 전체를 위해 제공되는 자원이죠. 따라서 부유층이 자신의 부를 사회에 환원함으로써, 자신들이 얻은 이익을 다시 사회에 투자하는 것은 공공재 활용에 상응하는 사회적 책임으로 볼 수 있는 것입니다.\n한편, ‘경제적 안정성과 소득 불평등 관점’에서 부의 환원에 대해 생각해 볼 수도 있습니다. 소득 불평등이 심화되면 경제 성장이 둔화될 수 있습니다.\n이 때 부유한 개인이나 기업이 자신들의 부를 사회에 환원하면, 단기적으로는 자산이 줄어들 수 있지만 장기적으로는 소득의 재분배를 통해 중산층의 소비 능력을 강화시킴으로써 경제적 불안정성을 줄이고 경제 성장에도 기여할 수 있습니다.\n결국 부의 사회적 환원을 통해 경제 전체의 파이를 키우게 되면, 나중에는 부자들에게 긍정적인 부메랑이 되어 돌아온다는 입장인 것이죠.\n\n2. 반대 입장: \n부유한 개인이나 기업이 사회에 환원할 필요는 없다.\nG:.css-1mgq6qf{white-space:pre-wrap;color:#c770e4;} 찬성 입장에 대해 충분히 이해가 됐어요. 반대 입장은 어떤 관점에서 살펴보면 될까요?\nK: 부유한 개인이나 기업에게 사회적 환원을 강제하는 것은 자유 시장 경제 원칙을 훼손할 수 있다는 관점입니다.\n자본주의 시스템에서는 개인과 기업이 자신의 노력과 창의성을 통해 부를 축적하는 것이 장려됩니다. 강제적 환원은 경제적인 동기 부여를 약화시키고, 기업가 정신(entrepreneurship)을 저해할 수 있다는 것이죠.\n또한 예전에 ‘.css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}왜 세금은 소득에 따라 달라질까?’ 아티클에서 살펴본 것처럼, 부자들은 이미 상당한 수준의 소득세와 법인세 등을 납부하고 있습니다. 그리고 이들이 납부한 세금은 공공재 투자를 비롯하여 다양한 방식으로 사회에 기여하고 있죠.\nG: 아하, 이러한 상황에서 이들에게 사회적 환원을 강제하는 것은 일종의 이중 과세가 될 수 있다는 것이겠네요.\nK: 그렇습니다. 그리고 이러한 시각에서는 부의 사회적 환원이 도덕적·윤리적 의무로 간주될 수는 있지만, 법적·경제적 의무로 강제되어서는 안된다고 말합니다. 누구나 자신의 자산을 어떻게 사용할지에 대한 선택권을 갖고 있을 뿐만 아니라, 자신에게 맞는 방법으로 사회에 기여하는 것이 더 효율적이기 때문이죠.\n예를 들면, 스티브 잡스는 다른 세계적인 부자들과 비교했을 때 공개적인 방식을 통한 자선 활동에는 크게 관여하지 않은 것으로 알려져 있습니다. 그러나 그는 애플을 통해 혁신적인 제품을 개발하고 사람들에게 많은 영감을 주었으며, 경제 성장에 기여하기도 했습니다. 스티브 잡스의 사례는 굳이 개인적인 기부가 아니더라도 기업 활동을 통해 얼마든지 사회에 더 큰 기여를 할 수 있음을 보여줍니다.\n지금까지 많은 부를 축적한 사람이나 기업이 사회에 반드시 환원을 해야하는지에 대한 찬성과 반대의 논리를 살펴봤는데요.\n정리해보면 찬성 입장은 (1) 부유층의 사회적 책임과 (2) 불평등 완화 등을 강조하며 환원의 필요성을 주장합니다. 반면, 반대 입장은 (1) 자유 시장 원칙과 이중 과세, (2) 자발적 기부의 중요성 등의 이유로 사회적 환원을 강요하는 것에 반대합니다.\n결론적으로, 부의 사회적 환원 문제는 단순히 \"해야 한다\" 혹은 \"하지 말아야 한다\"로 나뉠 수 없는 까다로운 경제적·윤리적 논쟁이라고 할 수 있겠습니다. 여러분의 생각은 어떤가요?\n.css-13d8cj1{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;margin:24px 0 8px;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:var(--adaptiveGrey700);}\n.css-1dzrkjz{width:16px;margin-right:8px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}\n.svg-icon-wrapper{position:relative;display:inline-block;width:24px;height:24px;}.svg-icon-wrapper >.svg-icon:empty+.svg-icon-fallback{visibility:visible;z-index:inherit;}.svg-icon{color:var(--adaptiveGrey900);display:inline-block;width:24px;height:24px;display:block;width:100%;height:100%;}.svg-icon svg,.svg-icon img{display:block;width:100%;height:100%;}.svg-icon--hide{display:none;}.svg-icon-fallback{position:absolute;left:0;right:0;top:0;z-index:z-index(hidden);visibility:hidden;display:block;width:100%;height:100%;}.svg-icon-fallback--show{visibility:visible;z-index:inherit;}\n참고자료\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 금혜원 Graphic 조수희 이제현",
        "content": "찬성과 반대 입장에서 각각 어떤 논리를 펼치는지 살펴볼게요.",
        "contentSnippet": "찬성과 반대 입장에서 각각 어떤 논리를 펼치는지 살펴볼게요.",
        "guid": "https://blog.toss.im/article/everyday-economics-20-noblesse-oblige",
        "isoDate": "2024-11-18T01:00:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]