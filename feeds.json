[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Augustin Popa",
        "title": "What’s New in vcpkg (January 2025)",
        "link": "https://devblogs.microsoft.com/cppblog/whats-new-in-vcpkg-january-2025/",
        "pubDate": "Thu, 23 Jan 2025 18:44:37 +0000",
        "content:encodedSnippet": "This blog post summarizes changes to the vcpkg package manager as part of the 2025.01.13 registry release, 2025-01-11 tool release, as well as changes to vcpkg documentation throughout January. This release includes minor improvements and bug fixes.\nSome stats for this period:\nThere are now 2,524 total ports available in the vcpkg curated registry. A port is a versioned recipe for building a package from source, such as a C or C++ library.\n12 new ports were added to the curated registry.\n177 updates were made to existing ports. As always, we validate each change to a port by building all other ports that depend on or are depended by the library that is being updated for our 13 main triplets.\n63 community contributors made commits.\nThe main vcpkg repo has over 6,600 forks and 23,800 stars on GitHub.\nvcpkg changelog (2025.01.13 release)\nThe following notable changes were made in January:\nMoved vcpkgTools.xml data into a JSON file, removed the XML parsing code, added architecture field to tool metadata, and removed the requirement of force system binaries on arm64 Linux platforms (PR: Microsoft/vcpkg-tool#1553).\nAdded some checks to prevent vcpkg from sometimes using an incompatible version of CMake, resulting in an error for the user (PR: Microsoft/vcpkg-tool#1562, thanks @autoantwort!).\nOther minor bug fixes.\nDocumentation changes\nThere are no changes to vcpkg documentation this month.\nIf you have any suggestions for our documentation, please submit an issue in our GitHub repo or see the box at the bottom of a particular article.\n\nTotal ports available for tested triplets\ntriplet\nports available\n\n\nx64-windows\n2,422\n\n\nx86-windows\n2,315\n\n\nx64-windows-static\n2,294\n\n\nx64-windows-static-md\n2,344\n\n\narm64-windows\n2,029\n\n\narm64-windows-static-md\n2,010\n\n\nx64-uwp\n1,346\n\n\narm64-uwp\n1,312\n\n\nx64-linux\n2,399\n\n\nx64-osx\n2,273\n\n\narm64-osx\n2,191\n\n\narm-neon-android\n1,690\n\n\nx64-android\n1,764\n\n\narm64-android\n1,732\n\n\n\nWhile vcpkg supports a much larger variety of target platforms and architectures (as community triplets), the list above is validated exhaustively to ensure updated ports don’t break other ports in the catalog.\nThank you to our contributors\nvcpkg couldn’t be where it is today without contributions from our open-source community. Thank you for your continued support! The following people contributed to the vcpkg, vcpkg-tool, or vcpkg-docs repos in this release (listed alphabetically by GitHub username):\nAenBleidd\nalagoutte\nan-tao\nautoantwort\nboris-bc\nbshoshany\nbuck-yeh\nc8ef\ncffk\nchiphogg\ndanielaparker\ndavidepianca98\ndeniskovalchuk\nDeveloperPaul123\ndg0yt\ndonny-dont\ndrdanz\neyalroz\nflarive\nGabeRundlett\ngastineau\ngfeyer\nhosseinmoein\nilya-lavrenov\nJackBoosY\nJacobBarthelmeh\njcelerier\njeremy-rifkin\nJoergAtGithub\njreichel-nvidia\nlesomnus\nliuzicheng1987\nluadebug\nluncliff\nm-kuhn\nmarcodiiga\nMehdiChinoune\nmichael-doubez\nmiyanyan\nmsclock\nmyd7349\nNeumann-A\nnickdademo\nnlogozzo\noleg-derevenetz\nPavelKisliak\nrioki\nRobbertProost\nRT2Code\nrtzoeller\nrustyconover\nsalman-javed-nz\nscotthart\nSunBlack\ntalregev\ntartanpaint\nTradias\nwalbourn\nweypro\nwikiwang1991\nxb284524239\nxiaozhuai\nyurybura\nLearn more\nYou can find the main release notes on GitHub. Recent updates to the vcpkg tool can be viewed on the vcpkg-tool Releases page. To contribute to vcpkg documentation, visit the vcpkg-docs repo. If you’re new to vcpkg or curious about how a package manager can make your life easier as a C/C++ developer, check out the vcpkg website – vcpkg.io.\nIf you would like to contribute to vcpkg and its library catalog, or want to give us feedback on anything, check out our GitHub repo. Please report bugs or request updates to ports in our issue tracker or join more general discussion in our discussion forum.\n \nThe post What’s New in vcpkg (January 2025) appeared first on C++ Team Blog.",
        "dc:creator": "Augustin Popa",
        "comments": "https://devblogs.microsoft.com/cppblog/whats-new-in-vcpkg-january-2025/#respond",
        "content": "<p>This blog post summarizes changes to the vcpkg package manager as part of the 2025.01.13 registry release, 2025-01-11 tool release, as well as changes to vcpkg documentation throughout January. This release includes minor improvements and bug fixes. Some stats for this period: There are now 2,524 total ports available in the vcpkg curated registry. A [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/whats-new-in-vcpkg-january-2025/\">What’s New in vcpkg (January 2025)</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "This blog post summarizes changes to the vcpkg package manager as part of the 2025.01.13 registry release, 2025-01-11 tool release, as well as changes to vcpkg documentation throughout January. This release includes minor improvements and bug fixes. Some stats for this period: There are now 2,524 total ports available in the vcpkg curated registry. A […]\nThe post What’s New in vcpkg (January 2025) appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=35041",
        "categories": [
          "C++",
          "Vcpkg",
          "vcpkg"
        ],
        "isoDate": "2025-01-23T18:44:37.000Z"
      }
    ]
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Bringing Jetpack Compose to Instagram for Android",
        "link": "https://engineering.fb.com/2025/01/24/android/bringing-jetpack-compose-to-instagram-for-android/",
        "pubDate": "Fri, 24 Jan 2025 17:30:53 +0000",
        "content:encodedSnippet": "Introducing a new Android UI framework like Jetpack Compose into an existing app is more complicated than importing some AARS and coding away. What if your app has specific performance goals to meet? What about existing design components, integrations with navigation, and logging frameworks?\nOn this episode of the Meta Tech Podcast Pascal Hartig is joined by Summer, a software engineer whose team handles large-scale migrations for Instagram. Summer walks through the various thoughtful and intricate phases that Instagram goes through to ensure that developers have the best possible experience when working on our codebases. She also discusses balancing all of this with Meta’s infrastructure teams, who have to maintain multiple implementations at once.\nLearn how Meta approaches the rollout of a new framework and more!\nDownload or listen to the podcast episode below:\n\nSpotify\nApple Podcasts\nPocket Casts\nOvercast\nThe Meta Tech Podcast is a podcast, brought to you by Meta, where we highlight the work Meta’s engineers are doing at every level – from low-level frameworks to end-user features.\nSend us feedback on Instagram, Threads, or X.\nAnd if you’re interested in learning more about career opportunities at Meta visit the Meta Careers page.\nThe post Bringing Jetpack Compose to Instagram for Android appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Introducing a new Android UI framework like Jetpack Compose into an existing app is more complicated than importing some AARS and coding away. What if your app has specific performance goals to meet? What about existing design components, integrations with navigation, and logging frameworks? On this episode of the Meta Tech Podcast Pascal Hartig is [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/01/24/android/bringing-jetpack-compose-to-instagram-for-android/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/01/24/android/bringing-jetpack-compose-to-instagram-for-android/\">Bringing Jetpack Compose to Instagram for Android</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Introducing a new Android UI framework like Jetpack Compose into an existing app is more complicated than importing some AARS and coding away. What if your app has specific performance goals to meet? What about existing design components, integrations with navigation, and logging frameworks? On this episode of the Meta Tech Podcast Pascal Hartig is [...]\nRead More...\nThe post Bringing Jetpack Compose to Instagram for Android appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=22155",
        "categories": [
          "Android",
          "Culture",
          "DevInfra",
          "Instagram",
          "Meta Tech Podcast"
        ],
        "isoDate": "2025-01-24T17:30:53.000Z"
      },
      {
        "creator": "",
        "title": "How Meta discovers data flows via lineage at scale",
        "link": "https://engineering.fb.com/2025/01/22/security/how-meta-discovers-data-flows-via-lineage-at-scale/",
        "pubDate": "Thu, 23 Jan 2025 05:00:45 +0000",
        "content:encodedSnippet": "Data lineage is an instrumental part of Meta’s Privacy Aware Infrastructure (PAI) initiative, a suite of technologies that efficiently protect user privacy. It is a critical and powerful tool for scalable discovery of relevant data and data flows, which supports privacy controls across Meta’s systems. This allows us to verify that our users’ everyday interactions are protected across our family of apps, such as their religious views in the Facebook Dating app, the example we’ll walk through in this post.\nIn order to build high-quality data lineage, we developed different techniques to collect data flow signals across different technology stacks: static code analysis for different languages, runtime instrumentation, and input and output data matching, etc. We then built an intuitive UX into our tooling that enables developers to effectively consume all of this lineage data in a systematic way, saving significant engineering time for building privacy controls. \nAs we expanded PAI across Meta, we gained valuable insights about the data lineage space. Our understanding of the privacy space evolved, revealing the need for early focus on data lineage, tooling, a cohesive ecosystem of libraries, and more. These initiatives have assisted in accelerating the development of data lineage and implementing purpose limitation controls more quickly and efficiently.\nAt Meta, we believe that privacy enables product innovation. This belief has led us to developing Privacy Aware Infrastructure (PAI), which offers efficient and reliable first-class privacy constructs embedded in Meta infrastructure to address different privacy requirements, such as purpose limitation, which restricts the purposes for which data can be processed and used. \nIn this blog, we will delve into an early stage in PAI implementation: data lineage. Data lineage refers to the process of tracing the journey of data as it moves through various systems, illustrating how data transitions from one data asset, such as a database table (the source asset), to another (the sink asset). We’ll also walk through how we track the lineage of users’ “religion” information in our Facebook Dating app.\nMillions of data assets are vital for supporting our product ecosystem, ensuring the functionality our users anticipate, maintaining high product quality, and safeguarding user safety and integrity. Data lineage enables us to efficiently navigate these assets and protect user data. It enhances the traceability of data flows within systems, ultimately empowering developers to swiftly implement privacy controls and create innovative products.\nNote that data lineage is dependent on having already completed important and complex preliminary steps to inventory, schematize, and annotate data assets into a unified asset catalog. This took Meta multiple years to complete across our millions of disparate data assets, and we’ll cover each of these more deeply in future blog posts:\nInventorying involves collecting various code and data assets (e.g., web endpoints, data tables, AI models) used across Meta.\nSchematization expresses data assets in structural detail (e.g., indicating that a data asset has a field called “religion”).\nAnnotation labels data to describe its content (e.g., specifying that the identity column contains religion data).\nUnderstanding data lineage at Meta\nTo establish robust privacy controls, an essential part of our PAI initiative is to understand how data flows across different systems. Data lineage is part of this discovery step in the PAI workflow, as shown in the following diagram:\n\nData lineage is a key precursor to implementing Policy Zones, our information flow control technology, because it answers the question, “Where does my data come from and where does it go?” – helping inform the right places to apply privacy controls. In conjunction with Policy Zones, data lineage provides the following key benefits to thousands of developers at Meta: \nScalable data flow discovery: Data lineage answers the question above by providing an end-to-end, scalable graph of relevant data flows. We can leverage the lineage graphs to visualize and explain the flow of relevant data from the point where it is collected to all the places where it is processed.\nEfficient rollout of privacy controls: By leveraging data lineage to track data flows, we can easily pinpoint the optimal integration points for privacy controls like Policy Zones within the codebase, streamlining the rollout process. Thus we have developed a powerful flow discovery tool as part of our PAI tool suite, Policy Zone Manager (PZM), based on data lineage. PZM enables developers to rapidly identify multiple downstream assets from a set of sources simultaneously, thereby accelerating the rollout process of privacy controls.\nContinuous compliance verification: Once the privacy requirement has been fully implemented, data lineage plays a vital role in monitoring and validating data flows continuously, in addition to the enforcement mechanisms such as Policy Zones.\nTraditionally, data lineage has been collected via code inspection using manually authored data flow diagrams and spreadsheets. However, this approach does not scale in large and dynamic environments, such as Meta, with billions of lines of continuously evolving code. To tackle this challenge, we’ve developed a robust and scalable lineage solution that uses static code analysis signals as well as runtime signals.\nWalkthrough: Implementing data lineage for religion data\nWe’ll share how we have automated lineage tracking to identify religion data flows through our core systems, eventually creating an end-to-end, precise view of downstream religion assets being protected, via the following two key stages:\nCollecting data flow signals: a process to capture data flow signals from many processing activities across different systems, not only for religion, but for all other types of data, to create an end-to-end lineage graph. \nIdentifying relevant data flows: a process to identify the specific subset of data flows (“subgraph”) within the lineage graph that pertains to religion. \nThese stages propagate through various systems including function-based systems that load, process, and propagate data through stacks of function calls in different programming languages (e.g., Hack, C++, Python, etc.) such as web systems and backend services, and batch-processing systems that process data rows in batch (mainly via SQL) such as data warehouse and AI systems. \nFor simplicity, we will demonstrate these for the web, the data warehouse, and AI, per the diagram below.\n\nCollecting data flow signals for the web system\nWhen setting up a profile on the Facebook Dating app, people can populate their religious views. This information is then utilized to identify relevant matches with other people who have specified matched values in their dating preferences. On Dating, religious views are subject to purpose limitation requirements, for example, they will not be used to personalize experiences on other Facebook Products. \n\nWe start with someone entering their religion information on their dating media profile using their mobile device, which is then transmitted to a web endpoint. The web endpoint subsequently logs the data into a logging table and stores it in a database, as depicted in the following code snippet:\n\nNow let’s see how we collect lineage signals. To do this, we need to employ both static and runtime analysis tools to effectively discover data flows, particularly focusing on where religion is logged and stored. By combining static and runtime analysis, we enhance our ability to accurately track and manage data flows.\nStatic analysis tools simulate code execution to map out data flows within our systems. They also emit quality signals to indicate the confidence of whether a data flow signal is a true positive. However, these tools are limited by their lack of access to runtime data, which can lead to false positives from unexecuted code.\nTo address this limitation, we utilize Privacy Probes, a key component of our PAI lineage technologies. Privacy Probes automate data flow discovery by collecting runtime signals. These signals are gathered in real time during the execution of requests, allowing us to trace the flow of data into loggers, databases, and other services. \nWe have instrumented Meta’s core data frameworks and libraries at both the data origin points (sources) and their eventual outputs (sinks), such as logging framework, which allows for comprehensive data flow tracking. This approach is exemplified in the following code snippet:\n\nDuring runtime execution, Privacy Probes does the following:\nCapturing payloads: It captures source and sink payloads in memory on a sampled basis, along with supplementary metadata such as event timestamps, asset identifiers, and stack traces as evidence for the data flow. \nComparing payloads: It then compares the source and sink payloads within a request to identify data matches, which helps in understanding how data flows through the system. \nCategorizing results: It categorizes results into two sets. The match-set includes pairs of source and sink assets where data matches exactly or one is contained by another, therefore providing high confidence evidence of data flow between the assets. The full-set includes all source and sink pairs within a request no matter whether the sink is tainted by the source. Full-set is a superset of match-set with some noise but still important to send to human reviewers since it may contain transformed data flows. \nThe above procedure is depicted in the diagram below:\n\nLet’s look at the following examples where various religions are received in an endpoint and various values (copied or transformed) being logged in three different loggers:\nInput Value (source)\nOutput Value (sink)\nData Operation\nMatch Result\nFlow Confidence\n\n\n“Atheist”\n“Atheist”\nData Copy\nEXACT_MATCH\nHIGH\n\n\n“Buddhist”\n{metadata: {religion: Buddhist}}\nSubstring\nCONTAINS\nHIGH\n\n\n{religions:\n[“Catholic”, “Christian”]}\n{count : 2}\nTransformed\nNO_MATCH\nLOW\n\n\n\n\n\nThese signals together are used to construct a lineage graph to understand the flow of data through our web system as shown in the following diagram:\n\nCollecting data flow signals for the data warehouse system\nWith the user’s religion logged in our web system, it can propagate to the data warehouse for offline processing. To gather data flow signals, we employ a combination of both runtime instrumentation and static code analysis in a different way from the web system. The involved SQL queries are logged for data processing activities by the Presto and Spark compute engines (among others). Static analysis is then performed for the logged SQL queries and job configs in order to extract data flow signals.\nLet’s examine a simple SQL query example that processes data for the data warehouse as the following:\n\nWe’ve developed a SQL analyzer to extract data flow signals between the input table, “safety_log_tbl” and the output table, “safety_training_tbl” as shown in the following diagram. In practice, we also collect more granular-level lineage such as at column-level (e.g., “user_id” -> “target_user_id”, “religion” -> “target_religion”).\nThere are instances where data is not fully processed by SQL queries, resulting in logs that contain data flow signals for either reads or writes, but not both. To ensure we have complete lineage data, we leverage contextual information (such as execution environments; job or trace IDs) collected at runtime to connect these reads and writes together. \nThe following diagram illustrates how the lineage graph has expanded:\n\nCollecting data flow signals for the AI system\nFor our AI systems, we collect lineage signals by tracking relationships between various assets, such as input datasets, features, models, workflows, and inferences. A common approach is to extract data flows from job configurations used for different AI activities such as model training.\n\nFor instance, in order to improve the relevance of dating matches, we use an AI model to recommend potential matches based on shared religious views from users. Let’s take a look at the following training config example for this model that uses religion data:\n\nBy parsing this config obtained from the model training service, we can track the data flow from the input dataset (with asset ID asset://hive.table/dating_training_tbl) and feature (with asset ID asset://ai.feature/DATING_USER_RELIGION_SCORE) to the model (with asset ID asset://ai.model/dating_ranking_model).\nOur AI systems are also instrumented so that asset relationships and data flow signals are captured at various points at runtime, including data-loading layers (e.g., DPP) and libraries (e.g., PyTorch), workflow engines (e.g., FBLearner Flow), training frameworks, inference systems (as backend services), etc. Lineage collection for backend services utilizes the approach for function-based systems described above. By matching the source and sink assets for different data flow signals, we are able to capture a holistic lineage graph at the desired granularities:\n\nIdentifying relevant data flows from a lineage graph\nNow that we have the lineage graph at our disposal, how can we effectively distill a subset of data flows pertinent to a specific privacy requirement for religion data? To address this question, we have developed an iterative analysis tool that enables developers to pinpoint precise data flows and systematically filter out irrelevant ones. The tool kicks off a repetitive discovery process aided by the lineage graph and privacy controls from Policy Zones, to narrow down the most relevant flows. This refined data allows developers to make a final determination about the flows they would like to use, producing an optimal path for traversing the lineage graph. The following are the major steps involved, captured holistically in the diagram, below:\nDiscover data flows: identify data flows from source assets and stop at downstream assets with low-confidence flows (yellow nodes). \nExclude and include candidates: Developers or automated heuristics exclude candidates (red nodes) that don’t have religion data or include remaining ones (green nodes). By excluding the red nodes early on, it helps to exclude all of their downstream in a cascaded manner, and thus saves developer efforts significantly. As an additional safeguard, developers also implement privacy controls via Policy Zones, so all relevant data flows can be captured.\nRepeat discovery cycle: use the green nodes as new sources and repeat the cycle until no more green nodes are confirmed. \n\nWith the collection and data flow identification steps complete, developers are able to successfully locate granular data flows that contain religion across Meta’s complex systems, allowing them to move forward in the PAI workflow to apply necessary privacy controls to safeguard the data. This once-intimidating task has been completed efficiently. \nOur data lineage technology has provided developers with an unprecedented ability to quickly understand and protect religion and similar sensitive data flows. It enables Meta to scalably and efficiently implement privacy controls via PAI to protect our users’ privacy and deliver products safely.\nLearnings and challenges\nAs we’ve worked to develop and implement lineage as a core PAI technology, we’ve gained valuable insights and overcome significant challenges, yielding some important lessons:\nFocus on lineage early and reap the rewards: As we developed privacy technologies like Policy Zones, it became clear that gaining a deep understanding of data flows across various systems is essential for scaling the implementation of privacy controls. By investing in lineage, we not only accelerated the adoption of Policy Zones but also uncovered new opportunities for applying the technology. Lineage can also be extended to other use cases such as security and integrity.\nBuild lineage consumption tools to gain engineering efficiency: We initially focused on building a lineage solution but didn’t give sufficient attention to consumption tools for developers. As a result, owners had to use raw lineage signals to discover relevant data flows, which was overwhelmingly complex. We addressed this issue by developing the iterative tooling to guide engineers in discovering relevant data flows, significantly reducing engineering efforts by orders of magnitude.\nIntegrate lineage with systems to scale the coverage: Collecting lineage from diverse Meta systems was a significant challenge. Initially, we tried to ask every system to collect lineage signals to ingest into the centralized lineage service, but the progress was slow. We overcame this by developing reliable, computationally efficient, and widely applicable PAI libraries with built-in lineage collection logic in various programming languages (Hack, C++, Python, etc.). This enabled much smoother integration with a broad range of Meta’s systems.\nMeasurement improves our outcomes: By incorporating the measurement of coverage, we’ve been able to evolve our data lineage so that we stay ahead of the ever-changing landscape of data and code at Meta. By enhancing our signals and adapting to new technologies, we can maintain a strong focus on privacy outcomes and drive ongoing improvements in lineage coverage across our tech stacks.\nThe future of data lineage\nData lineage is a vital component of Meta’s PAI initiative, providing a comprehensive view of how data flows across different systems. While we’ve made significant progress in establishing a strong foundation, our journey is ongoing. We’re committed to:\nExpanding coverage: continuously enhance the coverage of our data lineage capabilities to ensure a comprehensive understanding of data flows.\nImproving consumption experience: streamline the consumption experience to make it easier for developers and stakeholders to access and utilize data lineage information.\nExploring new frontiers: investigate new applications and use cases for data lineage, driving innovation and collaboration across the industry.\nBy advancing data lineage, we aim to foster a culture of privacy awareness and drive progress in the broader fields of study. Together, we can create a more transparent and accountable data ecosystem.\nAcknowledgements\nThe authors would like to acknowledge the contributions of many current and former Meta employees who have played a crucial role in developing data lineage technologies over the years. In particular, we would like to extend special thanks to (in alphabetical order) Amit Jain, Aygun Aydin, Ben Zhang, Brian Romanko, Brian Spanton, Daniel Ramagem, David Molnar, Dzmitry Charnahalau, Gayathri Aiyer, George Stasa, Guoqiang Jerry Chen, Graham Bleaney, Haiyang Han, Howard Cheng, Ian Carmichael, Ibrahim Mohamed, Jerry Pan, Jiang Wu, Jonathan Bergeron, Joanna Jiang, Jun Fang, Kiran Badam, Komal Mangtani, Kyle Huang, Maharshi Jha, Manuel Fahndrich, Marc Celani, Lei Zhang, Mark Vismonte, Perry Stoll, Pritesh Shah, Qi Zhou, Rajesh Nishtala, Rituraj Kirti, Seth Silverman, Shelton Jiang, Sushaant Mujoo, Vlad Fedorov, Yi Huang, Xinbo Gao, and Zhaohui Zhang. We would also like to express our gratitude to all reviewers of this post, including (in alphabetical order) Aleksandar Ilic, Avtar Brar, Benjamin Renard, Bogdan Shubravyi, Brianna O’Steen, Chris Wiltz, Daniel Chamberlain, Hannes Roth, Imogen Barnes, Jason Hendrickson, Koosh Orandi, Rituraj Kirti, and Xenia Habekoss. We would like to especially thank Jonathan Bergeron for overseeing the effort and providing all of the guidance and valuable feedback, Supriya Anand for leading the editorial effort to shape the blog content, and Katherine Bates for pulling all required support together to make this blog post happen.\nThe post How Meta discovers data flows via lineage at scale appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Data lineage is an instrumental part of Meta’s Privacy Aware Infrastructure (PAI) initiative, a suite of technologies that efficiently protect user privacy. It is a critical and powerful tool for scalable discovery of relevant data and data flows, which supports privacy controls across Meta’s systems. This allows us to verify that our users’ everyday interactions [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/01/22/security/how-meta-discovers-data-flows-via-lineage-at-scale/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/01/22/security/how-meta-discovers-data-flows-via-lineage-at-scale/\">How Meta discovers data flows via lineage at scale</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Data lineage is an instrumental part of Meta’s Privacy Aware Infrastructure (PAI) initiative, a suite of technologies that efficiently protect user privacy. It is a critical and powerful tool for scalable discovery of relevant data and data flows, which supports privacy controls across Meta’s systems. This allows us to verify that our users’ everyday interactions [...]\nRead More...\nThe post How Meta discovers data flows via lineage at scale appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=22168",
        "categories": [
          "Security"
        ],
        "isoDate": "2025-01-23T05:00:45.000Z"
      },
      {
        "creator": "",
        "title": "Strobelight: A profiling service built on open source technology",
        "link": "https://engineering.fb.com/2025/01/21/production-engineering/strobelight-a-profiling-service-built-on-open-source-technology/",
        "pubDate": "Tue, 21 Jan 2025 17:00:54 +0000",
        "content:encodedSnippet": "We’re sharing details about Strobelight, Meta’s profiling orchestrator.\nStrobelight combines several technologies, many open source, into a single service that helps engineers at Meta improve efficiency and utilization across our fleet.\nUsing Strobelight, we’ve seen significant efficiency wins, including one that has resulted in an estimated 15,000 servers’ worth of annual capacity savings.\nStrobelight, Meta’s profiling orchestrator, is not really one technology. It’s several (many open source) combined to make something that unlocks truly amazing efficiency wins. Strobelight is also not a single profiler but an orchestrator of many different profilers (even ad-hoc ones) that runs on all production hosts at Meta, collecting detailed information about CPU usage, memory allocations, and other performance metrics from running processes. Engineers and developers can use this information to identify performance and resource bottlenecks, optimize their code, and improve utilization.\nWhen you combine talented engineers with rich performance data you can get efficiency wins by both creating tooling to identify issues before they reach production and finding opportunities in already running code. Let’s say an engineer makes a code change that introduces an unintended copy of some large object on a service’s critical path. Meta’s existing tools can identify the issue and query Strobelight data to estimate the impact on compute cost. Then Meta’s code review tool can notify the engineer that they’re about to waste, say, 20,000 servers.\nOf course, static analysis tools can pick up on these sorts of issues, but they are unaware of global compute cost and oftentimes these inefficiencies aren’t a problem until they’re gradually serving millions of requests per minute. The frog can boil slowly.\nWhy do we use profilers?\nProfilers operate by sampling data to perform statistical analysis. For example, a profiler takes a sample every N events (or milliseconds in the case of time profilers) to understand where that event occurs or what is happening at the moment of that event. With a CPU-cycles event, for example, the profile will be CPU time spent in functions or function call stacks executing on the CPU. This can give an engineer a high-level understanding of the code execution of a service or binary.\nChoosing your own adventure with Strobelight\nThere are other daemons at Meta that collect observability metrics, but Strobelight’s wheelhouse is software profiling. It connects resource usage to source code (what developers understand best). Strobelight’s profilers are often, but not exclusively, built using eBPF, which is a Linux kernel technology. eBPF allows the safe injection of custom code into the kernel, which enables very low overhead collection of different types of data and unlocks so many possibilities in the observability space that it’s hard to imagine how Strobelight would work without it.\nAs of the time of writing this, Strobelight has 42 different profilers, including:\nMemory profilers powered by jemalloc.\nFunction call count profilers.\nEvent-based profilers for both native and non-native languages (e.g., Python, Java, and Erlang).\nAI/GPU profilers.\nProfilers that track off-CPU time.\nProfilers that track service request latency.\nEngineers can utilize any one of these to collect data from servers on demand via Strobelight’s command line tool or web UI.\nThe Strobelight web UI.\nUsers also have the ability to set up continuous or “triggered” profiling for any of these profilers by updating a configuration file in Meta’s Configerator, allowing them to target their entire service or, for example, only hosts that run in certain regions. Users can specify how often these profilers should run, the run duration, the symbolization strategy, the process they want to target, and a lot more.\nHere is an example of a simple configuration for one of these profilers:\nadd_continuous_override_for_offcpu_data(\r\n    \"my_awesome_team\", // the team that owns this service\r\n    Type.SERVICE_ID,\r\n    \"my_awesome_service\",\r\n    30_000, // desired samples per hour\r\n)\r\n\nWhy does Strobelight have so many profilers? Because there are so many different things happening in these systems powered by so many different technologies.\nThis is also why Strobelight provides ad-hoc profilers. Since the kind of data that can be gathered from a binary is so varied, engineers often need something that Strobelight doesn’t provide out of the box. Adding a new profiler from scratch to Strobelight involves several code changes and could take several weeks to get reviewed and rolled out.\nHowever, engineers can write a single bpftrace script (a simple language/tool that allows you to easily write eBPF programs) and tell Strobelight to run it like it would any other profiler. An engineer that really cares about the latency of a particular C++ function, for example, could write up a little bpftrace script, commit it, and have Strobelight run it on any number of hosts throughout Meta’s fleet – all within a matter of hours, if needed.\nIf all of this sounds powerfully dangerous, that’s because it is. However, Strobelight has several safeguards in place to prevent users from causing performance degradation for the targeted workloads and retention issues for the databases Strobelight writes to. Strobelight also has enough awareness to ensure that different profilers don’t conflict with each other. For example, if a profiler is tracking CPU cycles, Strobelight ensures another profiler can’t use another PMU counter at the same time (as there are other services that also use them).\nStrobelight also has concurrency rules and a profiler queuing system. Of course, service owners still have the flexibility to really hammer their machines if they want to extract a lot of data to debug.\nDefault data for everyone\nSince its inception, one of Strobelight’s core principles has been to provide automatic, regularly-collected profiling data for all of Meta’s services. It’s like a flight recorder – something that doesn’t have to be thought about until it’s needed. What’s worse than waking up to an alert that a service is unhealthy and there is no data as to why?\nFor that reason, Strobelight has a handful of curated profilers that are configured to run automatically on every Meta host. They’re not running all the time; that would be “bad” and not really “profiling.” Instead, they have custom run intervals and sampling rates specific to the workloads running on the host. This provides just the right amount of data without impacting the profiled services or overburdening the systems that store Strobelight data.\nHere is an example:\nA service, named Soft Server, runs on 1,000 hosts and let’s say we want profiler A to gather 40,000 CPU-cycles samples per hour for this service (remember the config above). Strobelight, knowing how many hosts Soft Server runs on, but not how CPU intensive it is, will start with a conservative run probability, which is a sampling mechanism to prevent bias (e.g., profiling these hosts at noon every day would hide traffic patterns).\nThe next day Strobelight will look at how many samples it was able to gather for this service and then automatically tune the run probability (with some very simple math) to try to hit 40,000 samples per hour. We call this dynamic sampling and Strobelight does this readjustment every day for every service at Meta.\nAnd if there is more than one service running on the host (excluding daemons like systemd or Strobelight) then Strobelight will default to using the configuration that will yield more samples for both.\nHang on, hang on. If the run probability or sampling rate is different depending on the host for a service, then how can the data be aggregated or compared across the hosts? And how can profiling data for multiple services be compared?\nSince Strobelight is aware of all these different knobs for profile tuning, it adjusts the “weight” of a profile sample when it’s logged. A sample’s weight is used to normalize the data and prevent bias when analyzing or viewing this data in aggregate. So even if Strobelight is profiling Soft Server less often on one host than on another, the samples can be accurately compared and grouped. This also works for comparing two different services since Strobelight is used both by service owners looking at their specific service as well as efficiency experts who look for “horizontal” wins across the fleet in shared libraries.\nHow Strobelight saves capacity\nThere are two default continuous profilers that should be called out because of how much they end up saving in capacity.\nThe last branch record (LBR) profiler \nThe LBR profiler, true to its name, is used to sample last branch records (a hardware feature that started on Intel). The data from this profiler doesn’t get visualized but instead is fed into Meta’s feedback directed optimization (FDO) pipeline. This data is used to create FDO profiles that are consumed at compile time (CSSPGO) and post-compile time (BOLT) to speed up binaries through the added knowledge of runtime behavior. Meta’s top 200 largest services all have FDO profiles from the LBR data gathered continuously across the fleet. Some of these services see up to 20% reduction in CPU cycles, which equates to a 10-20% reduction in the number of servers needed to run these services at Meta.\nThe event profiler\nThe second profiler is Strobelight’s event profiler. This is Strobelight’s version of the Linux perf tool. Its primary job is to collect user and kernel stack traces from multiple performance (perf) events e.g., CPU-cycles, L3 cache misses, instructions, etc. Not only is this data looked at by individual engineers to understand what the hottest functions and call paths are, but this data is also fed into monitoring and testing tools to identify regressions; ideally before they hit production.\nDid someone say Meta…data?\nLooking at function call stacks with flame graphs is great, nothing against it. But a service owner looking at call stacks from their service, which imports many libraries and utilizes Meta’s software frameworks, will see a lot of “foreign” functions. Also, what about finding just the stacks for p99 latency requests? Or how about all the places where a service is making an unintended string copy?\nStack schemas\nStrobelight has multiple mechanisms for enhancing the data it produces according to the needs of its users. One such mechanism is called Stack Schemas (inspired by Microsoft’s stack tags), which is a small DSL that operates on call stacks and can be used to add tags (strings) to entire call stacks or individual frames/functions. These tags can then be utilized in our visualization tool. Stack Schemas can also remove functions users don’t care about with regex matching. Any number of schemas can be applied on a per-service or even per-profile basis to customize the data.\nThere are even folks who create dashboards from this metadata to help other engineers identify expensive copying, use of inefficient or inappropriate C++ containers, overuse of smart pointers, and much more. Static analysis tools that can do this have been around for a long time, but they can’t pinpoint the really painful or computationally expensive instances of these issues across a large fleet of machines.\nStrobemeta\nStrobemeta is another mechanism, which utilizes thread local storage, to attach bits of dynamic metadata at runtime to call stacks that we gather in the event profiler (and others). This is one of the biggest advantages of building profilers using eBPF: complex and customized actions taken at sample time. Collected Strobemeta is used to attribute call stacks to specific service endpoints, or request latency metrics, or request identifiers. Again, this allows engineers and tools to do more complex filtering to focus the vast amounts of data that Strobelight profilers produce.\nSymbolization\nNow is a good time to talk about symbolization: taking the virtual address of an instruction, converting it into an actual symbol (function) name, and, depending on the symbolization strategy, also getting the function’s source file, line number, and type information.\nMost of the time getting the whole enchilada means using a binary’s DWARF debug info. But this can be many megabytes (or even gigabytes) in size because DWARF debug data contains much more than the symbol information.\nThis data needs to be downloaded then parsed. But attempting this while profiling, or even afterwards on the same host where the profile is gathered, is far too computationally expensive. Even with optimal caching strategies it can cause memory issues for the host’s workloads.\nStrobelight gets around this problem via a symbolization service that utilizes several open source technologies including DWARF, ELF, gsym, and blazesym. At the end of a profile Strobelight sends stacks of binary addresses to a service that sends back symbolized stacks with file, line, type info, and even inline information.\nIt can do this because it has already done all the heavy lifting of downloading and parsing the DWARF data for each of Meta’s binaries (specifically, production binaries) and stores what it needs in a database. Then it can serve multiple symbolization requests coming from different instances of Strobelight running throughout the fleet.\nTo add to that enchilada (hungry yet?), Strobelight also delays symbolization until after profiling and stores raw data to disk to prevent memory thrash on the host. This has the added benefit of not letting the consumer impact the producer – meaning if Strobelight’s user space code can’t handle the speed at which the eBPF kernel code is producing samples (because it’s spending time symbolizing or doing some other processing) it results in dropped samples.\nAll of this is made possible with the inclusion of frame pointers in all of Meta’s user space binaries, otherwise we couldn’t walk the stack to get all these addresses (or we’d have to do some other complicated/expensive thing which wouldn’t be as efficient). \nA simplified Strobelight service graph.\nShow me the data (and make it nice)!\nThe primary tool Strobelight customers use is Scuba – a query language (like SQL), database, and UI. The Scuba UI has a large suite of visualizations for the queries people construct (e.g., flame graphs, pie charts, time series graphs, distributions, etc).\nStrobelight, for the most part, produces Scuba data and, generally, it’s a happy marriage. If someone runs an on-demand profile, it’s just a few seconds before they can visualize this data in the Scuba UI (and send people links to it). Even tools like Perfetto expose the ability to query the underlying data because they know it’s impossible to try to come up with enough dropdowns and buttons that can express everything you want to do in a query language – though the Scuba UI comes close.\nAn example flamegraph/icicle of function call stacks of the CPU cycles event for the mononoke service for one hour.\nThe other tool is a trace visualization tool used at Meta named Tracery. We use this tool when we want to combine correlated but different streams of profile data on one screen. This data is also a natural fit for viewing on a timeline. Tracery allows users to make custom visualizations and curated workspaces to share with other engineers to pinpoint the important parts of that data. It’s also powered by a client-side columnar database (written in JavaScript!), which makes it very fast when it comes to zooming and filtering. Strobelight’s Crochet profiler combines service request spans, CPU-cycles stacks, and off-CPU data to give users a detailed snapshot of their service.\nAn example trace in Tracery.\nThe Biggest Ampersand\nStrobelight has helped engineers at Meta realize countless efficiency and latency wins, ranging from increases in the number of requests served, to large reductions in heap allocations, to regressions caught in pre-prod analysis tools.\nBut one of the most significant wins is one we call, “The Biggest Ampersand.”\nA seasoned performance engineer was looking through Strobelight data and discovered that by filtering on a particular std::vector function call (using the symbolized file and line number) he could identify computationally expensive array copies that happen unintentionally with the ‘auto’ keyword in C++.\nThe engineer turned a few knobs, adjusted his Scuba query, and happened to notice one of these copies in a particularly hot call path in one of Meta’s largest ads services. He then cracked open his code editor to investigate whether this particular vector copy was intentional… it wasn’t.\nIt was a simple mistake that any engineer working in C++ has made a hundred times.\nSo, the engineer typed an “&” after the auto keyword to indicate we want a reference instead of a copy. It was a one-character commit, which, after it was shipped to production, equated to an estimated 15,000 servers in capacity savings per year!\nGo back and re-read that sentence. One ampersand! \nAn open ending\nThis only scratches the surface of everything Strobelight can do. The Strobelight team works closely with Meta’s performance engineers on new features that can better analyze code to help pinpoint where things are slow, computationally expensive, and why.\nWe’re currently working on open-sourcing Strobelight’s profilers and libraries, which will no doubt make them more robust and useful. Most of the technologies Strobelight uses are already public or open source, so please use and contribute to them!\nAcknowledgements\nSpecial thanks to Wenlei He, Andrii Nakryiko, Giuseppe Ottaviano, Mark Santaniello, Nathan Slingerland, Anita Zhang, and the Profilers Team at Meta. \nThe post Strobelight: A profiling service built on open source technology appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>We’re sharing details about Strobelight, Meta’s profiling orchestrator. Strobelight combines several technologies, many open source, into a single service that helps engineers at Meta improve efficiency and utilization across our fleet. Using Strobelight, we’ve seen significant efficiency wins, including one that has resulted in an estimated 15,000 servers’ worth of annual capacity savings. Strobelight, Meta’s [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/01/21/production-engineering/strobelight-a-profiling-service-built-on-open-source-technology/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/01/21/production-engineering/strobelight-a-profiling-service-built-on-open-source-technology/\">Strobelight: A profiling service built on open source technology</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "We’re sharing details about Strobelight, Meta’s profiling orchestrator. Strobelight combines several technologies, many open source, into a single service that helps engineers at Meta improve efficiency and utilization across our fleet. Using Strobelight, we’ve seen significant efficiency wins, including one that has resulted in an estimated 15,000 servers’ worth of annual capacity savings. Strobelight, Meta’s [...]\nRead More...\nThe post Strobelight: A profiling service built on open source technology appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=22157",
        "categories": [
          "Open Source",
          "Production Engineering"
        ],
        "isoDate": "2025-01-21T17:00:54.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "eBay News Team",
        "title": "Announcing a New Collaboration Between eBay and OpenAI",
        "link": "https://innovation.ebayinc.com/tech/features/ebay-openai-operator-assistant/",
        "pubDate": "Thu, 23 Jan 2025 00:00:00 -0800",
        "dc:creator": "eBay News Team",
        "content": "<div style=\"margin-bottom: 10px;\"><img src=\"https://static.ebayinc.com/static/assets/Uploads/Blog/Posts/_resampled/FitWzIwMCwxMTNd/ebay-hq-inc-13.jpg?fs=be5a541c54d3a565\" width=\"200\" height=\"113\" alt=\"Announcing a New Collaboration Between eBay and OpenAI\" /></div><div>We're leveraging the latest advances in AI to redefine the future of ecommerce for enthusiasts.</div>",
        "contentSnippet": "We're leveraging the latest advances in AI to redefine the future of ecommerce for enthusiasts.",
        "guid": "https://innovation.ebayinc.com/tech/features/ebay-openai-operator-assistant/",
        "categories": [
          "article"
        ],
        "isoDate": "2025-01-23T08:00:00.000Z"
      }
    ]
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Regina Muradova",
        "title": "JetBrains Academy: Top Courses and Projects of 2024",
        "link": "https://blog.jetbrains.com/education/2025/01/24/jetbrains-academy-top-courses-and-projects-of-2024/",
        "pubDate": "Fri, 24 Jan 2025 08:42:41 +0000",
        "content:encodedSnippet": "This International Day of Education, we’re celebrating that in 2024 over 340,000 new coders joined JetBrains Academy, making our community almost 1.5 million members strong. \nTo mark this impressive milestone, we’re looking back at the most popular JetBrains Academy offerings of 2024 – including JetBrains IDE courses (designed exclusively for IDEs) and Hyperskill projects (available both in-browser and in-IDE). \nLet’s dive in!\nPython\nPython was a favorite topic among JetBrains Academy learners in 2024, and it’s no wonder why! The language is beginner-friendly and widely used in everything from web development to data science. \nIntroduction to Python (In-IDE course)\nOne of JetBrains Academy’s most loved offerings, this course is designed for absolute beginners wanting to learn Python from scratch. With easy-to-follow lessons, you’ll build a solid foundation in coding, understand core concepts, and gain the confidence to explore more advanced Python projects.\n\n\n\n\n100 Days of Code – The Complete Python Pro Bootcamp (In-IDE course) \nThis course by Angela Yu offers a practical way to learn Python by building 100 projects in 100 days. From web apps to automation tools, you’ll gain hands-on experience and develop the skills needed to code professionally.\nHyperskill projects \nFor those looking to build their developer portfolio with real-world projects from Hyperskill, these were the top picks in 2024, each of which was designed to make learning interactive and fun:\nMy First Project with Python – For mastering the basics. \nSimple Chat Bot – For sharpening logical thinking skills.\nZookeeper – For practicing data management.\nFor more advanced learners, the Password Hacker with Python project was a favorite, helping learners practice the skills needed for technical interviews at top tech companies.\nJava\nHyperskill projects \nJava projects in 2024 were all about having fun, overcoming challenges, and building practical skills to kickstart a developer career. Beginners started with My First Project with Java, Simple Chat Bot with Java, and Simple Tic-Tac-Toe. \nTo get a taste of Java, advanced learners programmed a virtual barista with Coffee Machine Simulator with Java.\n\n\n\n\nData Science\nHyperskill projects \nData science continues to be a top choice for our learners, blending analytical thinking with hands-on coding. Explore why our learners love this topic by trying out these projects: Nobel Laureates and House Classification.\nKotlin\nAtomicKotlin (In-IDE-course)\nDesigned for both beginners and experienced programmers, this course contains exercises that accompany the Atomic Kotlin book. You can read an “atom” of information in the book and lock in your understanding of the material by completing the exercises in the course.\n\n\n\n\nKotlin Koans (In-IDE-course)\nThis is an interactive course that helps you practice and understand Kotlin’s syntax, idioms, and core features. If you prefer hands-on problem-solving over lectures, this one’s for you.\nHyperskill projects \nTo update your developer portfolio and to have some fun learning Kotlin, try these popular projects:\nBuild a virtual animal caretaker in Zookeeper. \nCreate your own interactive game with Simple Tic-Tac-Toe. \n\n\n\n\nFrontend\nHyperskill project \nThe Color Guess Game was a hit among frontend enthusiasts. This project is a good opportunity to enhance the skills needed to create an engaging web interface while practicing DOM manipulations, managing user interactions, and controlling game flow with loops and conditions.\n\n\n\n\nRust\nLearn Rust (In-IDE-course)\nLast but not least, this Rust course was at the top of our list. Its hands-on exercises help beginners learn quickly to read and write Rust programs.\nAll in-IDE courses are free of charge, and, as a student, you can get a free license for any JetBrains IDE! \nInterested in learning more? Check out our full course catalog. With over 90 hands-on courses, JetBrains Academy helps you improve your CV, build a standout portfolio, and ace IT interviews. \nHappy learning!\nThe JetBrains Academy team",
        "dc:creator": "Regina Muradova",
        "content": "This International Day of Education, we’re celebrating that in 2024 over 340,000 new coders joined JetBrains Academy, making our community almost 1.5 million members strong.  To mark this impressive milestone, we’re looking back at the most popular JetBrains Academy offerings of 2024 – including JetBrains IDE courses (designed exclusively for IDEs) and Hyperskill projects (available [&#8230;]",
        "contentSnippet": "This International Day of Education, we’re celebrating that in 2024 over 340,000 new coders joined JetBrains Academy, making our community almost 1.5 million members strong.  To mark this impressive milestone, we’re looking back at the most popular JetBrains Academy offerings of 2024 – including JetBrains IDE courses (designed exclusively for IDEs) and Hyperskill projects (available […]",
        "guid": "https://blog.jetbrains.com/?post_type=education&p=540494",
        "categories": [
          "data-science",
          "jetbrains-academy",
          "project-based-learning",
          "python",
          "frontend",
          "online-learning"
        ],
        "isoDate": "2025-01-24T08:42:41.000Z"
      },
      {
        "creator": "Olga Bedrina",
        "title": "TeamCity Is Now Available on AWS Marketplace",
        "link": "https://blog.jetbrains.com/teamcity/2025/01/teamcity-is-now-available-on-aws-marketplace/",
        "pubDate": "Thu, 23 Jan 2025 22:29:02 +0000",
        "content:encodedSnippet": "TeamCity is officially listed on AWS Marketplace! This milestone makes it even easier for teams to integrate the power of TeamCity into their CI/CD pipelines while leveraging the scalability and flexibility of Amazon Web Services (AWS).\n\n\n\n\nTeamCity interface\nWhether you’re already an AWS user or exploring AWS for your next project, TeamCity on AWS Marketplace simplifies access to one of the most robust CI/CD platforms in the industry.\nAdvantages for DevOps teams\nThe TeamCity listing on AWS Marketplace brings several key benefits that streamline and enhance CI/CD workflows. Here’s how it’s helpful.\nSimplified procurement\nTeamCity seamlessly integrates with your existing AWS subscription, streamlining billing and management into a unified process. With funds already allocated or billing pre-configured in your AWS account, procurement becomes faster and simpler – no need to navigate lengthy approval processes, request additional quotas, or handle complex purchase orders.\nFaster deployment\nPre-configured solutions optimized for the AWS environment let you get up and running with TeamCity in just a few clicks.\nEffortless scalability \nLeverage AWS’s cloud capabilities to effortlessly scale your CI/CD infrastructure, ensuring it keeps pace with the demands of your growing projects.\nWhy choose TeamCity for AWS?\nTeamCity is a robust and flexible CI/CD platform that seamlessly integrates with AWS’s scalable and reliable infrastructure. It equips teams with powerful tools to:\nAccelerate development – Run parallel builds and tests to receive faster feedback and iterate quickly.\nStreamline workflows – Optimize complex pipelines with intelligent configuration assistance and automation.\nStrengthen security – Leverage built-in features such as access management and audit logging to safeguard your CI/CD processes.\nGain valuable insights – Access detailed build and test reports to make informed decisions and improve software quality.\nBy combining TeamCity’s capabilities with AWS, you can build, test, and deploy with greater efficiency and confidence. Learn more about the TeamCity and AWS integration on our website.",
        "dc:creator": "Olga Bedrina",
        "content": "TeamCity is officially listed on AWS Marketplace! This milestone makes it even easier for teams to integrate the power of TeamCity into their CI/CD pipelines while leveraging the scalability and flexibility of Amazon Web Services (AWS). TeamCity interface Whether you&#8217;re already an AWS user or exploring AWS for your next project, TeamCity on AWS Marketplace [&#8230;]",
        "contentSnippet": "TeamCity is officially listed on AWS Marketplace! This milestone makes it even easier for teams to integrate the power of TeamCity into their CI/CD pipelines while leveraging the scalability and flexibility of Amazon Web Services (AWS). TeamCity interface Whether you’re already an AWS user or exploring AWS for your next project, TeamCity on AWS Marketplace […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=540679",
        "categories": [
          "news"
        ],
        "isoDate": "2025-01-23T22:29:02.000Z"
      },
      {
        "creator": "Andrew Zakonov",
        "title": "Meet Junie, Your Coding Agent by JetBrains",
        "link": "https://blog.jetbrains.com/junie/2025/01/meet-junie-your-coding-agent-by-jetbrains/",
        "pubDate": "Thu, 23 Jan 2025 13:19:59 +0000",
        "content:encodedSnippet": "At JetBrains, we aim to enable and scale the next generation of technologies to make software development a more productive and enjoyable experience. To empower and support developers, we build a variety of products for professional development, including powerful AI tools and features that have already enhanced productivity and opened new horizons for creativity. But can we go beyond that and boost productivity even further – improve code quality, unlock future innovations, help execute complex tasks, and change the way you work with code? \nYes, we can! \nWith the launch of Junie, JetBrains AI coding agent, we are redefining how we code by leveraging its agentic power for co-creation right in your IDE. With Junie, you can fully delegate routine tasks to your very own personal coding agent or collaborate with it to execute more complex ones together. Thanks to the power of JetBrains IDEs, coupled with reliable LLMs, Junie already solves tasks that would otherwise require hours of work.\n\n\n\n\n\n\nAccording to SWEBench Verified, a curated benchmark of 500 developer tasks, Junie can solve 53.6% of tasks on a single run. Such a success rate is promising – this shows the potential to also adapt Junie to the reality of today’s software development, including large amounts of tasks of different complexity. Junie will unlock the power of coding agents for millions of developers and companies around the world.\n\n\n\n\n\nRedefining the developer experience with Junie \nDelivering Junie into your familiar IDEs\nOur goal is to ensure that partnering with Junie does not disrupt your coding experience, but empowers you to create and do more. Getting started with Junie is as simple as installing it into your IDE. You can then begin with delegating simple tasks as you get used to working with the coding agent, so you don’t need to make changes to your workflow.\nAnd when you are comfortable with working with Junie, you can have it handle more complex tasks, integrate it into your team workflow and start redefining tasks, to boost productivity, unleash your ingenuity and creativity, and get the most from your coding experience powered by agentic AI.\n\n\n\n\n\n\nStay in control of your code\nDevelopers must be able to quickly review proposed changes, maintain project context, and guide critical decisions. With Junie, you stay in control, even when delegating tasks and you are always able to review code changes and how the agent executes commands. \nDelivering improved code quality\nAI-generated code can be just as flawed as developer-written code. Ultimately, Junie will not just speed up development – it is poised to raise the bar for code quality. By combining the power of JetBrains IDEs with LLMs, Junie can generate code, run inspections, write tests and verify they have passed. \nMaking Junie a trusted teammate\nJunie is designed to understand the context of any given project, so it can adapt to your coding style. Junie can also follow specific coding guidelines, additionally enhancing its ability to align with the way you code. This results in better code quality and control on how Junie performs tasks, ensuring reliability, making Junie a trusted collaborator on your team.\nLet’s build a new way of coding, together\nAt JetBrains, we build products together with users, listening to the feedback to drive innovation in software development. This approach helps us create products empowering millions of developers to make anything happen – with code. \nWe’ve now opened the Early Access Program waitlist. We invite you to try Junie and share your thoughts, feedback, and ideas.\nJunie is currently available in the following JetBrains IDEs: IntelliJ IDEA Ultimate, PyCharm Professional. WebStorm is coming next. OS X and Linux platforms are supported. \nJoin the waitlist to try it in JetBrains IDEs",
        "dc:creator": "Andrew Zakonov",
        "content": "At JetBrains, we aim to enable and scale the next generation of technologies to make software development a more productive and enjoyable experience. To empower and support developers, we build a variety of products for professional development, including powerful AI tools and features that have already enhanced productivity and opened new horizons for creativity. But [&#8230;]",
        "contentSnippet": "At JetBrains, we aim to enable and scale the next generation of technologies to make software development a more productive and enjoyable experience. To empower and support developers, we build a variety of products for professional development, including powerful AI tools and features that have already enhanced productivity and opened new horizons for creativity. But […]",
        "guid": "https://blog.jetbrains.com/?post_type=junie&p=540083",
        "categories": [
          "news"
        ],
        "isoDate": "2025-01-23T13:19:59.000Z"
      },
      {
        "creator": "Sasha Ivanova",
        "title": "The ReSharper and Rider 2024.3.4 Bug-Fix Updates Are Now Available",
        "link": "https://blog.jetbrains.com/dotnet/2025/01/23/resharper-and-rider-2024-3-4/",
        "pubDate": "Thu, 23 Jan 2025 11:14:08 +0000",
        "content:encodedSnippet": "The new bug fixes for the 2024.3 release are available to download. \nReSharper 2024.3.4\nWe’ve fixed local privilege escalation in the ETW Host Service (CVE-2025-23385).\nWe’ve fixed an issue where the foreach statement would fail to compile when iterating over a ref struct in an async method, even though the code compiled successfully using dotnet build.\nWe’ve resolved a code analysis bug where implicit type arguments involving cast operators caused incorrect errors, even though the code compiled successfully. [RSRP-499411]\nWe’ve resolved a bug in the testing platform where navigation to the test source did not work correctly for tests created with TUnit. [RSRP-498832]\nWe’ve fixed an issue in the testing platform where test gutter marks were not displayed near tests, particularly for classes or methods with parameters. [RSRP-498834]\nFor the full list of changes included in this build, please refer to our issue tracker.\nDownload ReSharper 2024.3.4\n                                                    \nRider 2024.3.4 \nWe’ve fixed local privilege escalation in the ETW Host Service. (CVE-2025-23385)\nWe’ve fixed a problem where the Azure DevOps credential provider was broken on Windows, causing authentication issues when accessing private NuGet feeds. [RIDER-121245]\nWe’ve resolved an issue where source generators failed to work on Unix-based systems when .NET SDK is installed with a package manager. [RIDER-121116]\n\n\n\n\nWe’ve also fixed several issues affecting .NET MAUI development:\nRun/debug configurations for MAUI apps are now correctly displayed. [RIDER-120425]\nDebugging support for MAUI projects on the Windows platform has been restored. [RIDER-119363, RIDER-121970]\n\n\n\n\nFor the full list of changes included in this build, please refer to our issue tracker.\nDownload Rider 2024.3.4",
        "dc:creator": "Sasha Ivanova",
        "content": "The new bug fixes for the 2024.3 release are available to download.&#160; ReSharper 2024.3.4 For the full list of changes included in this build, please refer to our issue tracker. Rider 2024.3.4 We’ve also fixed several issues affecting .NET MAUI development: For the full list of changes included in this build, please refer to our [&#8230;]",
        "contentSnippet": "The new bug fixes for the 2024.3 release are available to download.  ReSharper 2024.3.4 For the full list of changes included in this build, please refer to our issue tracker. Rider 2024.3.4 We’ve also fixed several issues affecting .NET MAUI development: For the full list of changes included in this build, please refer to our […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=540383",
        "categories": [
          "net-tools",
          "releases",
          "bug-fix",
          "resharper",
          "rider"
        ],
        "isoDate": "2025-01-23T11:14:08.000Z"
      },
      {
        "creator": "Maria Kosukhina",
        "title": "IntelliJ IDEA 2025.1 EAP 2: Containerfile Support and Updates for Dockerfiles",
        "link": "https://blog.jetbrains.com/idea/2025/01/intellij-idea-2025-1-eap-2/",
        "pubDate": "Wed, 22 Jan 2025 18:39:56 +0000",
        "content:encodedSnippet": "IntelliJ IDEA 2025.1 EAP 2 is out!\nWith a focus on improving workflows for environments like Docker containers and other remote solutions, this build introduces updates that simplify setup and enhance productivity in these scenarios.\nYou can now download this version from our website, update directly from within the IDE, use the free Toolbox App, or install it via snap packages for Ubuntu. \nDownload IntelliJ IDEA 2025.1 EAP 2\nTry the new updates delivered with the second EAP build for yourself! \nRemote development environments \nContainerfile support \nContainer ecosystems have been evolving beyond Docker-centric workflows, with tools like Podman and Buildah favoring Containerfile as a neutral alternative. However, IDE support, which is typically tied to Dockerfile, often lagged behind. That created friction, forcing developers to either rename Containerfile to Dockerfile, lose Podman-specific best practices, or just plow through with basic text editing. \nNow, JetBrains IDEs come with built-in Containerfile recognition. This might seem like a relatively minor enhancement, but it really contributes to a smooth developer experience for anyone juggling Docker, Podman, and Buildah in the same environment.\nIt is no longer necessary to keep separate versions of your build files just so your IDE doesn’t treat them as plain text. And for new hires or open-source contributors using Podman straight from the get-go, it provides enhanced clarity.\nSyntax highlighting, linting, and snippet suggestions are fully supported, reducing errors, speeding up debugging, and improving clarity – especially for new hires or contributors using Podman. Now, it doesn’t matter if you switch engines or if half the team uses Docker while the other half uses Podman – everyone can work with the same file, recognized by the same tools.\n\n\n\n\nSupport for lowercase instructions in Dockerfiles \nIntelliJ IDEA 2025.1 EAP 2 brings enhanced Dockerfile support, allowing you to write directives in lowercase in addition to the conventional uppercase. Previously, the IDE recognized commands like FROM, RUN, and COPY primarily as Dockerfile instructions. Now, you’re also free to use the lowercase from, run, and copy, too.\nAlthough Docker itself is case-insensitive with regard to instructions, uppercase has historically been used to improve readability and to distinguish instructions from arguments. However, alternative casing styles might be preferred to accommodate specific commands, plugins, corporate standards, or personal preferences. With this update, you can adhere to your preferred conventions without risking missing highlights or encountering misleading warnings from the IDE.\n\n\n\n\nNew inspection for reliable ENTRYPOINT initialization with exec\nWe’ve introduced a new Dockerfile inspection that ensures your ENTRYPOINT is correctly initiated with exec. Using exec allows signals sent via docker stop to reach the main process directly, preventing lingering or improperly terminated processes. If you omit exec, your application may run as a child process and fail to receive signals like SIGTERM, making shutdown unreliable. This inspection highlights incorrect ENTRYPOINT usage and guides you toward best practices, helping you maintain cleaner Dockerfiles and more robust container lifecycles.\n\n\n\n\nThese are the key updates for this week. For the complete list of changes, refer to the release notes.\nWe’d love for you to explore the new features and share your feedback. Let us know your thoughts and ideas in the comments below, or get in touch with us on X. If you encounter any issues, please report them through our issue tracker.\nHappy developing!",
        "dc:creator": "Maria Kosukhina",
        "content": "IntelliJ IDEA 2025.1 EAP 2 is out! With a focus on improving workflows for environments like Docker containers and other remote solutions, this build introduces updates that simplify setup and enhance productivity in these scenarios. You can now download this version from our website, update directly from within the IDE, use the free Toolbox App, [&#8230;]",
        "contentSnippet": "IntelliJ IDEA 2025.1 EAP 2 is out! With a focus on improving workflows for environments like Docker containers and other remote solutions, this build introduces updates that simplify setup and enhance productivity in these scenarios. You can now download this version from our website, update directly from within the IDE, use the free Toolbox App, […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=540054",
        "categories": [
          "eap",
          "2025-1-eap",
          "intellij-idea-2025-1",
          "intellij-idea-2025-1-eap"
        ],
        "isoDate": "2025-01-22T18:39:56.000Z"
      },
      {
        "creator": "Ksenia Shneyveys",
        "title": "Results of Google Summer of Code 2024 With the Kotlin Foundation",
        "link": "https://blog.jetbrains.com/kotlin/2025/01/google-summer-of-code-2024-with-kotlin-results/",
        "pubDate": "Wed, 22 Jan 2025 13:04:45 +0000",
        "content:encodedSnippet": "2024 marked another exciting year with respect to the Kotlin Foundation’s participation in Google Summer of Code (GSoC). GSoC is a global online program that introduces new contributors to open-source development. This year, contributors worked to expand the Kotlin ecosystem under the guidance of mentors from Google, Gradle, Microsoft, and JetBrains.\nJoin our Slack channel to learn about the next GSoC and other opportunities to contribute.\nJoin GSoC Slack\nWe’re thrilled to share the results of GSoC 2024, with four projects successfully making it into production:\nStorytale – a Compose Multiplatform component gallery generator\nThis project introduces a much-needed gallery generator for Compose Multiplatform, designed to help developers showcase and test composable functions across platforms. To achieve this, contributor WhiteScent developed a Gradle plugin and runtime library that define and generate a centralized, multiplatform gallery app (for web, desktop, iOS, and Android), offering parameter adjustments and interactions in an isolated visual interface.\nA big thanks to WhiteScent, a computer science student and Android enthusiast, and Artem Kobzar, a software engineer working on Kotlin/Wasm at JetBrains, for their great work!\nRead the full blog post.\nShare ideas and contributions to this project: Storytale on GitHub.\nIncremental compilation for the Kotlin/Wasm compiler\nThis project enhanced the Kotlin-to-Wasm compiler with incremental compilation capabilities, reducing build times by allowing it to recompile only modified files. The contributor, Osama Ahmad, optimized and reused components from the Kotlin/JS backend while improving documentation and refactoring the codebase.\nThanks to Osama Ahmad and the mentor from JetBrains, Igor Yakovlev, for their great input!\nRead the full blog post.\nExplore Kotlin/Wasm.\nAndroid support in the Gradle Build Server\nThis project brought Android project support to the Gradle Build Server. Despite starting with limited Gradle API knowledge, contributor Tanish Ranjan successfully implemented features like composite build support, Java Home handling, and Android project discovery. These enhancements have been integrated into production, enriching Gradle for Kotlin/Android development.\nWe thank Tanish Ranjan and the team of mentors, Oleg Nenashev, Donát Csikós, Bálint Hegyi, Sheng Chen, and Reinhold, for their valuable contributions to the Kotlin and Gradle ecosystems.\nRead the full blog post.\nCheck out the project page.\nSupport for Android targets in kotlinx-benchmark\nThis project enhanced the kotlinx-benchmark library, an open-source tool for benchmarking Kotlin code across platforms such as JVM, JS, wasmJs, and native, by adding support for Android benchmarking through integration with androidx.benchmark. To achieve this, the developers detected Android targets, generated template projects, integrated benchmark annotations, validated tests, and captured results.\nThank you to Qizhao Chen and the mentor team, Abduqodiri Qurbonzoda, Dustin Lam, and Rahul Ravikumar, for your great input.\nRead the full blog post.\nCheck out the kotlinx-benchmark library.\nWe are immensely grateful to our contributors, the mentors, and the Kotlin Foundation for making GSoC 2024 a success!\nJoin our Slack channel to stay tuned for more updates and other opportunities to contribute:\nJoin GSoC Slack\nLet’s continue to expand Kotlin’s reach and usability across platforms. Thank you!",
        "dc:creator": "Ksenia Shneyveys",
        "content": "2024 marked another exciting year with respect to the Kotlin Foundation’s participation in Google Summer of Code (GSoC). GSoC is a global online program that introduces new contributors to open-source development. This year, contributors worked to expand the Kotlin ecosystem under the guidance of mentors from Google, Gradle, Microsoft, and JetBrains. Join our Slack channel [&#8230;]",
        "contentSnippet": "2024 marked another exciting year with respect to the Kotlin Foundation’s participation in Google Summer of Code (GSoC). GSoC is a global online program that introduces new contributors to open-source development. This year, contributors worked to expand the Kotlin ecosystem under the guidance of mentors from Google, Gradle, Microsoft, and JetBrains. Join our Slack channel […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=538394",
        "categories": [
          "news",
          "education",
          "gsoc",
          "internship"
        ],
        "isoDate": "2025-01-22T13:04:45.000Z"
      },
      {
        "creator": "Cheuk Ting Ho",
        "title": "Anomaly Detection in Time Series",
        "link": "https://blog.jetbrains.com/pycharm/2025/01/anomaly-detection-in-time-series/",
        "pubDate": "Wed, 22 Jan 2025 12:14:32 +0000",
        "content:encodedSnippet": "How do you identify unusual patterns in data that might reveal critical issues or hidden opportunities? Anomaly detection helps identify data that deviates significantly from the norm. Time series data, which consists of data collected over time, often includes trends and seasonal patterns. Anomalies in time series data occur when these patterns are disrupted, making anomaly detection a valuable tool in industries like sales, finance, manufacturing, and healthcare.\nAs time series data has unique characteristics like seasonality and trends, specialized methods are required to detect anomalies effectively. In this blog post, we’ll explore some popular methods for anomaly detection in time series, including STL decomposition and LSTM prediction, with detailed code examples to help you get started.\nTime series anomaly detection in businesses\nTime series data is essential to many businesses and services. Many businesses record data over time with timestamps, allowing changes to be analyzed and data to be compared over time. Time series are useful when comparing a certain quantity over a certain period, as, for example, in a year-over-year comparison where the data exhibits characteristics of seasonalities.\nSales monitoring\nOne of the most common examples of time series data with seasonalities is sales data. As a lot of sales are affected by annual holidays and the time of the year, it is hard to draw conclusions about sales data without considering the seasonalities. Because of that, a common method for analyzing and finding anomalies in sales data is STL decomposition, which we will cover in detail later in this blog post.\nFinance\nFinancial data, such as transactions and stock prices, are typical examples of time series data. In the finance industry, analyzing and detecting anomalies in this data is a common practice. For example, time series prediction models can be used in automatic trading. We’ll use a time series prediction to identify anomalies in stock data later in this blog post.\nManufacturing\nAnother use case of time series anomaly detection is monitoring defects in production lines. Machines are often monitors, making time series data available. Being able to notify management of potential failures is essential, and anomaly detection plays a key role.\nMedicine and healthcare\nIn medicine and healthcare, human vitals are monitored and anomalies can be detected. This is important enough in medical research, but it’s critical in diagnostics. If a patient at a hospital has anomalies in their vitals and is not treated immediately, the results can be fatal.\nWhy is it important to use special methods for time series anomaly detection?\nTime series data is special in the sense that it sometimes cannot be treated like other types of data. For example, when we apply a train test split to time series data, the sequentially related nature of the data means we cannot shuffle it. This is also true when applying time series data to a deep learning model. A recurrent neural network (RNN) is commonly used to take the sequential relationship into account, and training data is input as time windows, which preserve the sequence of events within.\nTime series data is also special because it often has seasonality and trends that we cannot ignore. This seasonality can manifest in a 24-hour cycle, a 7-day cycle, or a 12-month cycle, just to name a few common possibilities. Anomalies can only be determined after the seasonality and trends have been considered, as you will see in our example below. \nMethods used for anomaly detection in time series\nBecause time series data is special, there are specific methods for detecting anomalies in it. Depending on the type of data, some of the methods and algorithms we mentioned in the previous blog post about anomaly detection can be used on time series data. However, with those methods, the anomaly detection may not be as robust as using ones specifically designed for time series data. In some cases, a combination of detection methods can be used to reconfirm the detection result and avoid false positives or negatives.\nSTL decomposition\nOne of the most popular ways to use time series data that has seasonality is STL decomposition – seasonal trend decomposition using LOESS (locally estimated scatterplot smoothing). In this method, a time series is decomposed using an estimate of seasonality (with the period provided or determined using an algorithm), a trend (estimated), and the residual (the noise in the data). A Python library that provides STL decomposition tools is the statsmodels library.\n\n\n\n\nAn anomaly is detected when the residual is beyond a certain threshold. \nUsing STL decomposition on beehive data\nIn an earlier blog post, we explored anomaly detection in beehives using the OneClassSVM and IsolationForest methods. \nIn this tutorial, we’ll analyze beehive data as a time series using the STL class provided by the statsmodels library. To get started, set up your environment using this file: requirements.txt. \n1. Install the library\nSince we have only been using the model provided by Scikit-learn, we will need to install statsmodels from PyPI. This is easy to do in PyCharm. \nStart with PyCharm Pro for free\n                                                    \nGo to the Python Package window (choose the icon at the bottom of the left-hand side of the IDE) and type in statsmodels in the search box.\n\n\n\n\nYou can see all of the information about the package on the right-hand side. To install it, simply click Install package.\n2. Create a Jupyter notebook\nTo investigate the dataset further, let’s create a Jupyter notebook to take advantage of the tools that PyCharm’s Jupyter notebook environment provides.\n\n\n\n\nWe will import pandas and load the .csv file.\nimport pandas as pd\n\ndf = pd.read_csv('../data/Hive17.csv', sep=\";\")\ndf = df.dropna()\ndf\n\n\n\n\n3. Inspect the data as graphs\nNow, we can inspect the data as graphs. Here, we would like to see the temperature of hive 17 over time. Click on Chart view in the dataframe inspector and then choose T17 as the y-axis in the series settings.\n\n\n\n\nWhen expressed as a time series, the temperature has a lot of ups and downs. This indicates periodic behavior, likely due to the day-night cycle, so it is safe to assume there is a 24-hour period for the temperature. \nNext, there is a trend of temperature dropping over time. If you inspect the DateTime column, you can see that the dates range from August to November. Since the Kaggle page of the dataset indicates that the data was collected in Turkey, the transition from summer to fall explains our observation that the temperature is dropping over time.\n4. Time series decomposition\nTo understand the time series and detect anomalies, we will perform STL decomposition, importing the STL class from statsmodels and fitting it with our temperature data.\nfrom statsmodels.tsa.seasonal import STL\n\nstl = STL(df[\"T17\"], period=24, robust=True) \nresult = stl.fit()\nWe will have to provide a period for the decomposition to work. As we mentioned before, it is safe to assume a 24-hour cycle.\nAccording to the documentation, STL decomposes a time series into three components: trend, seasonal, and residual. To get a clearer look at the decomposed result, we can use the built-in plot method:\nresult.plot()\n\n\n\n\nYou can see the Trend and Season plots seem to align with our assumptions above. However, we are interested in the residual plot at the bottom, which is the original series without the trend and seasonal changes. Any extremely high or low value in the residual indicates an anomaly.\n5. Anomaly threshold\nNext, we would like to determine what values of the residual we’ll consider abnormal. To do that, we can look at the residual’s histogram.\nresult.resid.plot.hist()\n\n\n\n\nThis can be considered a normal distribution around 0, with a long tail above 5 and below -5, so we’ll set the threshold to 5.\nTo show the anomalies on the original time series, we can color all of them red in the graph like this:\nimport matplotlib.pyplot as plt\n\nthreshold = 5\nanomalies_filter = result.resid.apply(lambda x: True if abs(x) > threshold else False)\nanomalies = df[\"T17\"][anomalies_filter]\n\nplt.figure(figsize=(14, 8))\nplt.scatter(x=anomalies.index, y=anomalies, color=\"red\", label=\"anomalies\")\nplt.plot(df.index, df['T17'], color='blue')\nplt.title('Temperatures in Hive 17')\nplt.xlabel('Hours')\nplt.ylabel('Temperature')\nplt.legend()\nplt.show()\n\n\n\n\nWithout STL decomposition, it is very hard to identify these anomalies in a time series consisting of periods and trends.\nLSTM prediction\nAnother way to detect anomalies in time series data is to do a time series prediction on the series using deep learning methods to estimate the outcome of data points. If an estimate is very different from the actual data point, then it could be a sign of anomalous data.\nOne of the popular deep learning algorithms to perform the prediction of sequential data is the Long short-term memory (LSTM) model, which is a type of recurrent neural network (RNN). The LSTM model has input, forget, and output gates, which are number matrices. This ensures important information is passed on in the next iteration of the data.\n\n\n\n\nSince time series data is sequential data, meaning the order of data points is in sequential order and should not be shuffled, the LSTM model is an effective deep learning model to predict the outcome at a certain time. This prediction can be compared to the actual data and a threshold can be set to determine if the actual data is an anomaly.\nUsing LSTM prediction on stock prices\nNow let’s start a new Jupyter project to detect any anomalies in Apple’s stock price over the past 5 years. The stock price dataset shows the most up-to-date data. If you want to follow along with the blog post, you can download the dataset we are using.\n1. Start a Jupyter project\nWhen starting a new project, you can choose to create a Jupyter one, which is optimized for data science. In the New Project window, you can create a Git repository and determine which conda installation to use for managing your environment.\n\n\n\n\nAfter starting the project, you will see an example notebook. Go ahead and start a new Jupyter notebook for this exercise.\n\n\n\n\nAfter that, let’s set up requirements.txt. We will need pandas, matplotlib, and PyTorch, which is named torch on PyPI. Since PyTorch is not included in the conda environment, PyCharm will tell us that we are missing the package. To install the package, click on the lightbulb and select Install all missing packages.\n\n\n\n\n2. Loading and inspecting the data\nNext, let’s put our dataset apple_stock_5y.csv in the data folder and load it as a pandas DataFrame to inspect it.\nimport pandas as pd\n \ndf = pd.read_csv('data/apple_stock_5y.csv')\ndf\nWith the interactive table, we can easily see if any data is missing.\n\n\n\n\nThere is no missing data, but we have one issue – we would like to use the Close/Last price but it is not a numeric data type. Let’s do a conversion and inspect our data again:\ndf[\"Close/Last\"] = df[\"Close/Last\"].apply(lambda x: float(x[1:]))\ndf\nNow, we can inspect the price with the interactive table. Click on the plot icon on the left and a plot will be created. By default, it uses Date as the x-axis and Volume as the y-axis. Since we would like to inspect the Close/Last price, go to the settings by clicking the gear icon on the right and choose Close/Last as the y-axis.\n\n\n\n\n3. Preparing the training data for LSTM\nNext, we have to prepare the training data to be used in the LSTM model. We need to prepare a sequence of vectors (feature X), each representing a time window, to predict the next price. The next price will form another sequence (target y). Here we can choose how big this time window is with the lookback variable. The following code creates sequences X and y which will then be converted to PyTorch tensors:\nimport torch\n\nlookback = 5\ntimeseries = df[[\"Close/Last\"]].values.astype('float32')\n\nX, y = [], []\nfor i in range(len(timeseries)-lookback):\n    feature = timeseries[i:i+lookback]\n    target = timeseries[i+1:i+lookback+1]\n    X.append(feature)\n    y.append(target)\n    \nX = torch.tensor(X)\ny = torch.tensor(y)\n\nprint(X.shape, y.shape)\nGenerally speaking, the bigger the window, the bigger our model will be, since the input vector is bigger. However, with a bigger window, the sequence of inputs will be shorter, so determining this lookback window is a balancing act. We will start with 5, but feel free to try different values to see the differences.\n4. Build and train the model\nWe can build the model by creating a class using the nn module in PyTorch before we train it. The nn module provides building blocks, such as different neural network layers. In this exercise, we will build a simple LSTM layer followed by a linear layer:\nimport torch.nn as nn\n\nclass StockModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.lstm = nn.LSTM(input_size=1, hidden_size=50, num_layers=1, batch_first=True)\n        self.linear = nn.Linear(50, 1)\n    def forward(self, x):\n        x, _ = self.lstm(x)\n        x = self.linear(x)\n        return x\nNext, we will train our model. Before training it, we will need to create an optimizer, a loss function used to calculate the loss between the predicted and actual y values, and a data loader to feed in our training data:\nimport numpy as np\nimport torch.optim as optim\nimport torch.utils.data as data\n\nmodel = StockModel()\noptimizer = optim.Adam(model.parameters())\nloss_fn = nn.MSELoss()\nloader = data.DataLoader(data.TensorDataset(X, y), shuffle=True, batch_size=8)\nThe data loader can shuffle the input, as we have already created the time windows. This preserves the sequential relationship in each window.\nTraining is done using a for loop which loops over each epoch. For every 100 epochs, we will print out the loss and observe while the model converges:\nn_epochs = 1000\nfor epoch in range(n_epochs):\n    model.train()\n    for X_batch, y_batch in loader:\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    if epoch % 100 != 0:\n        continue\n    model.eval()\n    with torch.no_grad():\n        y_pred = model(X)\n        rmse = np.sqrt(loss_fn(y_pred, y))\n    print(f\"Epoch {epoch}: RMSE {rmse:.4f}\")\nWe start at 1000 epochs, but the model converges quite quickly. Feel free to try other numbers of epochs for training to achieve the best result.\n\n\n\n\nIn PyCharm, a cell that requires some time to execute will provide a notification about how much time remains and a shortcut to the cell. This is very handy when training machine learning models, especially deep learning models, in Jupyter notebooks.\n5. Plot the prediction and find the errors\nNext, we will create the prediction and plot it together with the actual time series. Note that we will have to create a 2D np series to match with the actual time series. The actual time series will be in blue while the predicted time series will be in red.\nimport matplotlib.pyplot as plt\n\nwith torch.no_grad():\n    pred_series = np.ones_like(timeseries) * np.nan\n    pred_series[lookback:] = model(X)[:, -1, :]\n\nplt.plot(timeseries, c='b')\nplt.plot(pred_series, c='r')\nplt.show()\n\n\n\n\nIf you observe carefully, you will see that the prediction and the actual values do not align perfectly. However, most of the predictions do a good job.\nTo inspect the errors closely, we can create an error series and use the interactive table to observe them. We are using the absolute error this time.\nerror = abs(timeseries-pred_series)\nerror\nUse the settings to create a histogram with the value of the absolute error as the x-axis and the count of the value as the y-axis.\n\n\n\n\n6. Decide on the anomaly threshold and visualize\nMost of the points will have an absolute error of less than 6, so we can set that as the anomaly threshold. Similar to what we did for the beehive anomalies, we can plot the anomalous data points in the graph.\nthreshold = 6\nerror_series = pd.Series(error.flatten())\nprice_series = pd.Series(timeseries.flatten())\n\nanomalies_filter = error_series.apply(lambda x: True if x > threshold else False)\nanomalies = price_series[anomalies_filter]\n\nplt.figure(figsize=(14, 8))\nplt.scatter(x=anomalies.index, y=anomalies, color=\"red\", label=\"anomalies\")\nplt.plot(df.index, timeseries, color='blue')\nplt.title('Closing price')\nplt.xlabel('Days')\nplt.ylabel('Price')\nplt.legend()\nplt.show()\n\n\n\n\nSummary\nTime series data is a common form of data used in many applications including business and scientific research. Due to the sequential nature of time series data, special methods and algorithms are used to help determine anomalies in it. In this blog post, we demonstrated how to identify anomalies using STL decomposition to eliminate seasonalities and trends. We have also demonstrated how to use deep learning and the LSTM model to compare the predicted estimate and the actual data in order to determine anomalies.\nDetect anomalies using PyCharm\nWith the Jupyter project in PyCharm Professional, you can organize your anomaly detection project with a lot of data files and notebooks easily. Graphs output can be generated to inspect anomalies and plots are very accessible in PyCharm. Other features, such as auto-complete suggestions, make navigating all the Scikit-learn models and Matplotlib plot settings a blast.\nPower up your data science projects by using PyCharm, and check out the data science features offered to streamline your data science workflow.\nStart with PyCharm Pro for free",
        "dc:creator": "Cheuk Ting Ho",
        "content": "How do you identify unusual patterns in data that might reveal critical issues or hidden opportunities? Anomaly detection helps identify data that deviates significantly from the norm. Time series data, which consists of data collected over time, often includes trends and seasonal patterns. Anomalies in time series data occur when these patterns are disrupted, making [&#8230;]",
        "contentSnippet": "How do you identify unusual patterns in data that might reveal critical issues or hidden opportunities? Anomaly detection helps identify data that deviates significantly from the norm. Time series data, which consists of data collected over time, often includes trends and seasonal patterns. Anomalies in time series data occur when these patterns are disrupted, making […]",
        "guid": "https://blog.jetbrains.com/?post_type=pycharm&p=539241",
        "categories": [
          "data-science",
          "how-tos",
          "anomaly-detection"
        ],
        "isoDate": "2025-01-22T12:14:32.000Z"
      },
      {
        "creator": "Elena Kerpeleva",
        "title": "Introducing  Perpetual Licenses on JetBrains Marketplace",
        "link": "https://blog.jetbrains.com/platform/2025/01/introducing-perpetual-licenses-on-jetbrains-marketplace/",
        "pubDate": "Tue, 21 Jan 2025 18:11:47 +0000",
        "content:encodedSnippet": "JetBrains Marketplace provides various licensing models for paid plugins to suit different user preferences. Now, we are introducing a new option that may change how your users purchase your plugins – perpetual licensing.\nLicensing options on JetBrains Marketplace\nThe current licensing schemes available on JetBrains Marketplace include:\nAnnual/monthly subscription without a fallback license: Users can access your plugin only with an active subscription. This model is ideal for ensuring continuous revenue as users need to maintain their subscriptions to keep using the plugin.\nAnnual/monthly subscription with a fallback license: Users receive lifetime access to a specific version of your plugin. Updates and new features are only available with an active subscription. This model strikes a balance between providing long-term value to users and encouraging them to renew their subscriptions.\nThe licensing type (with or without fallback) and billing period (annual/monthly) can be selected under the Sales tab, in the Sales Info section of the plugin page.\nIn addition to the options described above, we are now introducing a perpetual license option. This new license type allows users to make a one-time payment for lifetime access to your plugin, including all future updates. It can be an appealing choice for users who prefer a single upfront payment rather than recurring charges.\n\n\n\n\nHow to implement perpetual licenses\nNow that you can opt for perpetual licensing for your new plugin, the perpetual license will be available as an option when you publish a new plugin on JetBrains Marketplace. \nNote that a plugin can currently have only one paid license option: either recurring or perpetual.\nChoosing the best licensing model for your plugin\nThe introduction of the perpetual license gives you more flexibility in how you monetize your plugin. However, it’s essential to consider the implications carefully.\nRevenue stability: While a one-time payment model may attract more users initially, it can lead to less predictable revenue in the long run compared to a subscription model.\nUser satisfaction: Perpetual licenses can increase customer satisfaction, as users appreciate the simplicity and long-term value of a single payment.\nIf you have any questions or need guidance on transitioning to the perpetual license model, feel free to reach out to the Marketplace Support team at marketplace@jetbrains.com.",
        "dc:creator": "Elena Kerpeleva",
        "content": "JetBrains Marketplace provides various licensing models for paid plugins to suit different user preferences. Now, we are introducing a new option that may change how your users purchase your plugins – perpetual licensing. Licensing options on JetBrains Marketplace The current licensing schemes available on JetBrains Marketplace include: The licensing type (with or without fallback) and [&#8230;]",
        "contentSnippet": "JetBrains Marketplace provides various licensing models for paid plugins to suit different user preferences. Now, we are introducing a new option that may change how your users purchase your plugins – perpetual licensing. Licensing options on JetBrains Marketplace The current licensing schemes available on JetBrains Marketplace include: The licensing type (with or without fallback) and […]",
        "guid": "https://blog.jetbrains.com/?post_type=platform&p=538720",
        "categories": [
          "marketplace",
          "plugin-development"
        ],
        "isoDate": "2025-01-21T18:11:47.000Z"
      },
      {
        "creator": "Vaclav Pech",
        "title": "MPS 2024.3 Is Out!",
        "link": "https://blog.jetbrains.com/mps/2025/01/mps-2024-3-is-out/",
        "pubDate": "Tue, 21 Jan 2025 17:01:08 +0000",
        "content:encodedSnippet": "In this release, you’ll find improvements to the UI, reworked internals for various components, and a binary-enabled textgen. MPS 2024.3 also brings enhanced support for icons, an applicability condition for quick-fixes, and numerous platform updates.\nDOWNLOAD MPS 2024.3\nWhat’s new\nLet’s check out the new features we’ve prepared for you in this release.\nTop-level folder for transient and checkpoint models\nThe ProjectView tool now provides three top-level folders to keep the structure of the project better organized:\nProject Name\nModules Pool\nCheckpoints and Transient Models\nThe Checkpoints and Transient Models folder is always displayed below the Modules Pool, and is empty unless any transient or checkpoint models are available. These models are displayed under this folder, and not at the top level as they used to be.\nCheckpoints and Transient Models folder allows the ProjectView to remember the expanded and collapsed subtrees of the project structure across MPS restarts.\n\nEnable preview tag option\nThe following options to enable/disable the Preview Tab provided by the IntelliJ Platform are now respected by MPS and guarantee the same behavior of the editor as in other JetBrains tools:\nSettings | Editor | General | Editor Tabs | Opening Policy | Enable preview tab\nLogical View | Behavior | Enable Preview Tab\n\nApplicability condition for a quick-fix\nA new section named applicable has been added to Quick-Fix definitions to let you control the applicability of a quick-fix. The default value <always> guarantees unrestricted applicability.\n\nIcon handling\nIcons and images that use a path relative to the module are no longer copied during generation next to the places of their individual usage. Instead, they are copied to the distribution module once as image files and are available for use at this single location. This has two immediate benefits: avoiding the duplication of image files to save disk space and the ability to access the images both from the distribution and from the source module.\nConstant icons\nIn addition to the existing TextIcon and FileIcon concepts, a new ConstantFieldIcon concept is now available. It allows an icon to be specified by reference to a concrete static field declaration holding an instance of javax.swing.Icon.\n\nTextGen binary outcome\nInspired by the need for better handling of icon files, we’ve added a new mechanism to produce binary output during the TextGen process, instead of text. The new API consists of a write operation that directly manipulates data as instances of byte[].\nTool windows migrated away from ProjectComponent\nAll tool windows, such as Inspector, HierarchyView, and Usages, have been reworked to no longer follow the long-deprecated mechanism of the IntelliJ Platform’s project components (ProjectComponent). The changes to the API have been minimal, but for some tool windows, there is a change in how they are obtained from code:\nThe Project.getComponent() method no longer returns any of the tool windows.\nTools that are implemented as an MPS tool concept can be obtained using com.intellij.openapi.project.Project.tool<ToolConcept>.\nTools that are frequently used from Java provide a static getInstance() method:\n\nUsagesViewTool.getInstance()\nInspectorTool.getInstance()\nThe Inspector tool is traditionally also available from EditorContext.inspectorTool().\nIntelliJ Platform components and services\nIn addition to tool windows, most of the MPS core functionality has been reworked not to use IntelliJ IDEA’s ApplicationComponent and ProjectComponent.\nMPS used to rely heavily on the IntelliJ Platform facilities to compose the complete application. Now, most of the legacy components have been refactored to use contemporary MPS or IntelliJ IDEA APIs (like IntelliJ IDEA’s application/project services and extension points, MPS’ CoreComponents and extensions, etc.). There are still a few components left, which the MPS team plans to get rid of completely in the next release.\nMost users probably won’t notice any difference, with the exception of reduced startup times.\nPlease consult the Migration Guide if your code fails to locate any of the platform components because it uses an obsolete retrieval mechanism.\nSwitched to the new UI\nMPS now uses the new UI. The old version of the UI can be enabled by installing the Classic UI plugin.\nMore new features…\nCheck out the What’s New page to learn all about the new features.\nYou can find a full list of fixed issues here.\nYour JetBrains MPS team",
        "dc:creator": "Vaclav Pech",
        "content": "In this release, you’ll find improvements to the UI, reworked internals for various components, and a binary-enabled textgen. MPS 2024.3 also brings enhanced support for icons, an applicability condition for quick-fixes, and numerous platform updates. DOWNLOAD MPS 2024.3 What’s new Let’s check out the new features we’ve prepared for you in this release. Top-level folder [&#8230;]",
        "contentSnippet": "In this release, you’ll find improvements to the UI, reworked internals for various components, and a binary-enabled textgen. MPS 2024.3 also brings enhanced support for icons, an applicability condition for quick-fixes, and numerous platform updates. DOWNLOAD MPS 2024.3 What’s new Let’s check out the new features we’ve prepared for you in this release. Top-level folder […]",
        "guid": "https://blog.jetbrains.com/?post_type=mps&p=533562",
        "categories": [
          "releases",
          "release"
        ],
        "isoDate": "2025-01-21T17:01:08.000Z"
      },
      {
        "creator": "Irina Mariasova",
        "title": "Maximize Code Security in JetBrains IDEs and Qodana With Mend.io",
        "link": "https://blog.jetbrains.com/idea/2025/01/maximize-code-security-in-jetbrains-ides-and-qodana-with-mend-io/",
        "pubDate": "Tue, 21 Jan 2025 09:35:46 +0000",
        "content:encodedSnippet": "JetBrains has partnered with Mend.io, a trusted name in application security. This collaboration will help us continue providing the tools you need to develop secure applications with ease and confidence in our IDEs and Qodana. For the best user experience, make sure to use the latest stable version 2024.3.2. \nWhy Mend?\nTrusted by industry giants like Google and Comcast, Mend.io offers a reliable application security platform. It helps organizations build mature AppSec programs, shifting from reactive vulnerability management to proactive risk mitigation. With Mend’s expertise, our users gain access to a robust solution that simplifies security and boosts code quality.\nWhat’s new?\nOur Package Checker plugin has long been a reliable tool for identifying vulnerabilities in third-party dependencies and suggesting safe updates. By switching to Mend.io as our software composition analysis (SCA) provider, we’re ensuring that these capabilities remain effective and up to date.\nMalicious package detection\nThanks to this partnership, you can now identify malicious packages – those specifically designed to harm systems. Mend strongly advises removing such packages immediately to protect your code and systems.\nPowered by Mend.io, the Malicious Dependency inspection helps you:\nDetect harmful npm and PyPI packages.\n\n\n\n\n\nPrevent commits with malicious dependencies, protecting your repositories.\n\n\n\n\nMalicious package detection is also available in Qodana.\n\n\n\n\nVulnerability detection \nThe popular Vulnerable Path functionality, which helps pinpoint the exact source of a vulnerability, will return with the upcoming 2025.1 version of JetBrains IDEs, giving you added precision when managing your code dependencies. \nBasic functionality remains \nThe bundled Package Checker plugin will continue to provide a reliable way to keep your code secure with the help of the following basic features:\nDependency scanning. Helps identify vulnerabilities and threats in third-party dependencies.\nSafe updates. Suggests secure versions of dependencies, allowing you to fix vulnerabilities easily.\nSmooth IDE integration. Highlights issues directly in the editor and provides details in the Problems | Vulnerable Dependencies tab or via Analyze | Vulnerable Dependencies.\n\n\n\n\nLooking ahead\nThis update brings incremental, yet valuable, improvements to the security features in JetBrains IDEs and Qodana. We’re committed to enhancing these capabilities further and providing you with the tools needed to build secure applications.\nBe sure to update your tools and try the new features once they are available!",
        "dc:creator": "Irina Mariasova",
        "content": "JetBrains has partnered with Mend.io, a trusted name in application security. This collaboration will help us continue providing the tools you need to develop secure applications with ease and confidence in our IDEs and Qodana. For the best user experience, make sure to use the latest stable version 2024.3.2. Why Mend? Trusted by industry giants [&#8230;]",
        "contentSnippet": "JetBrains has partnered with Mend.io, a trusted name in application security. This collaboration will help us continue providing the tools you need to develop secure applications with ease and confidence in our IDEs and Qodana. For the best user experience, make sure to use the latest stable version 2024.3.2. Why Mend? Trusted by industry giants […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=538928",
        "categories": [
          "news",
          "intellij-idea",
          "news-company",
          "package-checker",
          "security"
        ],
        "isoDate": "2025-01-21T09:35:46.000Z"
      },
      {
        "creator": "Olga Bedrina",
        "title": "TeamCity 2024.12.1 Bug Fix Is Now Available",
        "link": "https://blog.jetbrains.com/teamcity/2025/01/teamcity-2024-12-1-bug-fix/",
        "pubDate": "Mon, 20 Jan 2025 12:39:45 +0000",
        "content:encodedSnippet": "We’re excited to announce the release of TeamCity On-Premises 2024.12.1, a bug fix update that resolves over 80 issues reported by users. This version includes crucial fixes across multiple areas, ensuring enhanced performance, stability, and security for your CI/CD pipelines.\nSome highlights of this release include:\nResolved truncated build tags, addressing an issue that impacted tag visibility.\nEnhanced VCS checkout, ensuring revision computation considers all VCS root variations.\nFixed possible agent hang-ups during artifact publishing.\nSupport for MySQL 8.4 by adding allowPublicKeyRetrieval to the database connection URL (TW-91529).\nFixed SSH agent build feature issues on Windows (TW-85769).\nWe recommend upgrading to apply the latest improvements and security fixes to your TeamCity server.\nWhy update?\nStaying up to date with minor releases ensures your TeamCity instance benefits from:\nPerformance improvements.\nBetter compatibility with integrations.\nFaster, more stable builds.\nEnhanced security for your workflows.\nCompatibility\nTeamCity 2024.12.1 shares the same data format as all 2024.12.x releases. You can upgrade or downgrade within this series without the need for backup and restoration.\nHow to upgrade\nUse the automatic update feature in your current TeamCity version.\nDownload the latest version directly from the JetBrains website.\nPull the updated TeamCity Docker image.\nNeed help?\nThank you for reporting issues and providing feedback! If you have questions or run into any problems, please let us know via the TeamCity Forum or Issue Tracker.\nHappy building!",
        "dc:creator": "Olga Bedrina",
        "content": "We’re excited to announce the release of TeamCity On-Premises 2024.12.1, a bug fix update that resolves over 80 issues reported by users. This version includes crucial fixes across multiple areas, ensuring enhanced performance, stability, and security for your CI/CD pipelines. Some highlights of this release include: We recommend upgrading to apply the latest improvements and [&#8230;]",
        "contentSnippet": "We’re excited to announce the release of TeamCity On-Premises 2024.12.1, a bug fix update that resolves over 80 issues reported by users. This version includes crucial fixes across multiple areas, ensuring enhanced performance, stability, and security for your CI/CD pipelines. Some highlights of this release include: We recommend upgrading to apply the latest improvements and […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=539197",
        "categories": [
          "bug-fix"
        ],
        "isoDate": "2025-01-20T12:39:45.000Z"
      },
      {
        "creator": "Kerry Beetge",
        "title": "Fixing Unreal Engine Project Issues With Qodana",
        "link": "https://blog.jetbrains.com/qodana/2025/01/unreal-engine-project-qodana/",
        "pubDate": "Mon, 20 Jan 2025 11:00:47 +0000",
        "content:encodedSnippet": "If you saw our blog post about using Qodana in Unity and .NET projects, you know that we’ve been striving to explore Qodana’s potential for game development. What’s our next stop on this mission? Seeing our code quality platform in action with Unreal Engine, one of the most popular engines for different types of projects – from virtual reality prototypes to triple-A games. \nIn this post, we’ll demonstrate how we used our static analysis tool Qodana on Lyra Starter Game, a widely known sample project from Epic Games. We chose this project for its large codebase, which provides a wider range of potential issues to identify, analyze, and fix. \nThe analysis and the resolution of issues were carried out by a junior developer. Our goal was to check how someone still building their game development knowledge can use Qodana to improve code and product quality. \nTable of Contents\n\nRunning Qodana from the IDE\nSetting up the CI/CD pipeline\nFixing problems\nQodana’s Unreal Engine analysis summarized\nSwitch to Qodana for code analysis and get 25% off\n\nRunning Qodana from the IDE\nWe started by running Qodana from an IDE (Rider) to see the initial results and set up filtering. As Qodana is integrated with the most popular JetBrains IDEs, it can be easily launched directly from the Tools menu. For a better team experience, we also recommend using the JetBrains CI/CD solution, TeamCity. After setting up we will switch that on as well to set up a seamless process and quality gate.\n Running Qodana in the IDE\n\n\n\nYou can run Qodana in your IDE without a token, but we wanted our results to be accessible from Qodana Cloud, a cloud-based tool for Qodana reports. To upload a report to the cloud, you need a license token, which you can get from the Qodana Cloud project. We will also use the token to integrate our analysis into the CI/CD pipeline.\nThe qodana.yaml file is created automatically and shown in the popup below. \nThe qodana.yaml popup\n\n\n\nYou can modify this file directly in the popup window if you need to, and you can run inspections with the qodana.starter profile to check if there are any critical errors. Once you run it, the file will be saved in the project root. We wanted to use a custom profile, so we modified this file to reference the custom profile.yaml.\nIn the qodana.yaml file, we left a link to the profile. QDNET is a linter based on the Rider distribution and designed to work with Unreal Engine projects.\nversion: \"1.0\"\n\n#Specify IDE code to run analysis without container (Applied in CI/CD pipeline)\nide: QDNET\n\n#Specify inspection profile for code analysis\nprofile:\n  path: profile.yaml\nqodana.yaml\nIn the profile.yaml file, we changed the profile to the more extensive qodana.recommended and identified scope to be excluded from the analysis. We wanted to analyze only the project codebase, without Unreal Engine or plugin sources.\nbaseProfile: \"qodana.recommended\"\nname: \"UnrealEngine\"\n\ninspections:\n  - group: ALL\n    ignore:\n      - \"scope#!file:Source/LyraGame//*\"\nprofile.yaml\nThese changes provided a relatively comprehensive analysis report.\n\n We then linked our project to Qodana Cloud. \n Linking the project to Qodana Cloud\n\n\n\nThis will allow us to access future reports withinin the IDE and view problems locally.\nThe report in the IDE\n\n\n\nSetting up the CI/CD pipeline\nWe already had a CI/CD pipeline in TeamCity, which we used to build the project every time we pushed changes to the main branch. There are several ways to complete the build. One such method is with the Unreal Engine plugin for TeamCity which can be downloaded from JetBrains Marketplace. You don’t have to run the build before running Qodana, but it is convenient to put it in the same pipeline. This allows TeamCity to mark the build as Failed if Qodana finds any issues.\nTo run the Qodana analysis, we added a PowerShell step that loaded and ran our Qodana CLI tool. We opted for the latest AMD64-compatible version and assets for our agents. If you are working with a different operating system and architecture, you will have to choose the assets designed for them. \nBefore implementing this in any project, you should discuss the security implications with the people responsible for this in your organization. Downloading a third-party binary without checking its integrity and checksum can be risky. You may need to save a fixed version of the binary yourself or verify the checksum of the downloaded distribution. \nInvoke-WebRequest -Uri \"https://github.com/JetBrains/qodana-cli/releases/download/%VERSION%/qodana_windows_x86_64.exe\" -OutFile \"qodana_windows_x86_64.exe\" \n\n./qodana_windows_x86_64.exe scan --ide QDNET\nPowerShell build step\nThe linter requires a Qodana token, a value from the project page on Qodana Cloud. To pass the token through the pipeline, we added the QODANA_TOKEN environment variable with the Password value type to ensure the token remains secure.\nThen, in the same way, we added the desired version of Qodana CLI as a configuration parameter.\n\n\n\n\nFixing problems\nFor this Unreal Engine project, we were particularly interested in issues specific to projects created with the game engine. We used filters on Qodana Сloud to show only these problems.\nUnreal Engine problems\n\n\n\nQodana’s sunburst diagram provides a convenient visualization of the detected issues, as well as an easy way to navigate to them. In our case, we could see there were seven types of problems, some of which could be resolved using context actions:\nBlueprintCallable function can be made const\nBlueprintCallable function can be made static\nUse of a class that has not been declared previously\nTo quickly navigate to these issues in the IDE, we can click on the Open file in Rider button.\nPlease note: to get this functionality to work you have to install JetBrains Toolbox on your computer. \nExample of a problem in Qodana Cloud\n\n\n\nAfter opening the file in the IDE, we resolved this problem using the relevant quick-fix with a context action.\nExample of a problem in the IDE\n\n\n\nYou can also navigate by opening a report locally in the IDE and going through the list of problems grouped there by type, fixing them one by one. As you fix problems in the IDE, the number of issues detected will decrease.\n\n\n\n\nWe decided not to fix problems like BlueprintCallable function is never used in Blueprint or C++ code, as the Lyra project is considered learning material, and it’s actively maintained. The project contains methods that are not currently being used but may be in the future. \nAdditionally, we decided not to fix inconsistent Unreal Engine naming problems because the project uses a different naming convention, where upper case is used for all abbreviations.\nExample of a naming problem in the IDE\n\n\n\nTo deactivate these inspections, we added their inspection IDs to profile.yaml and set the enabled property to false, ensuring these types of problems will no longer be shown in reports. The problem ID can be found in the qodana.sarif.json file.\nNext, we moved to C++ problems. We decided to only fix the problems that were categorized as higher than moderate severity, as most low-level issues could be fixed with quick-fixes. We excluded the non-critical issues by changing the profile.yaml file.\nbaseProfile: \"qodana.recommended\"\nname: \"UnrealEngine\"\n\ninspections:\n - group: ALL\n   ignore:\n     - \"scope#!file:Source/LyraGame//*\"\n - group: \"severity:TYPO\"\n   enabled: false\n - inspection: \"CppUE4CodingStandardNamingViolationWarning\"\n   enabled: false\n - inspection: \"CppUEBlueprintCallableFunctionUnused\"\n   enabled: false\nprofile.yaml\nThis produced a report with less than a thousand problems. To experiment with different filtering strategies, we used separate branches for each YAML file. This allowed us to divide the problems into groups based on type, tackling each type in a separate branch with different settings and then merging the branches.\nLow-severity C++ problems excluded\n\n\n\nEven without the low-level results, we saw many types of problems that were not in the Unreal Engine category. \nIn total, our team fixed 822 of 937 problems from the categories we examined next.\nAs you can see below, the most common problems fell into the Common Practices and Code Improvements category and included issues like variables that could be made const or static. We resolved most of them with quick-fixes. We left problems like Function is not implemented, as they could be fixed in future development. We decided not to fix some of the problems, as the changes required to mitigate them would make the project uncompilable and in need of further refactoring.\nProblems classified as Common Practices and Code Improvements\n\n\n\nAs a result, we were left with only 26 problems in the Common Practices and Code Improvements category, which we could deal with later. \nRemaining problems classified as Common Practices and Code Improvements\n\n\n\nUp next were potential code quality issues. From this category, we fixed problems where we needed to remove unused declarators or directives. We then moved to redundancies in code, most of which were resolved easily with a quick-fix. We did not address any problems where developers left comments with their plans or TODOs because we assumed that these problems would be fixed with future changes.\nExample of a TODO\n\n\n\nLast but not least, the Syntax Style category contained only two types of problems, both of which concerned the use of virtual and override specifiers when overriding functions. We fixed all of them by adding the missing specifiers.\nSyntax Style problems\n\n\n\nWe were left with 123 unresolved problems, either due to ongoing development or the lack of a feasible solution. We moved these issues to the baseline. To apply the baseline, we downloaded the baseline file and stored it in the repository.\nSelecting problems\n\n\n\nDownloading the baseline file\n\n\n\nThen, by adding the –baseline parameter and path to the file, we adjusted the pipeline to include the baseline in future analyses.\nInvoke-WebRequest -Uri \"https://github.com/JetBrains/qodana-cli/releases/download/%VERSION%/qodana_windows_x86_64.exe\" -OutFile \"qodana_windows_x86_64.exe\" \n./qodana_windows_x86_64.exe scan --ide QDNET --baseline qodana.sarif.json\nPowerShell build step\nAnd finally, we had a flawless report.\n\n\n\n\nIf our team decided to continue working on this project, we could fix new problems as they appeared or we could focus on eliminating problems from the baseline, depending on our priorities.\nWe set up a quality gate to enforce the standards we had achieved with these efforts, and we added a several failureConditions section to qodana.yaml to configure additional quality gates for the total number of problems, as well as the numbers of critical and high-severity issues. Going forward, if any of these limits are exceeded, the build will fail.\nfailureConditions:\n  severityThresholds:\n    any: 10 # Total problems\n    critical: 0 # Critical and other severities\n    high: 5\n\n\n\n\nAdded qodana.yaml configuration\nWe also adjusted the execution of qodana-cli to consider exit code, failing the build if the result fails the quality gates. By failing builds that don’t meet our quality criteria, we can identify and address issues immediately.\nInvoke-WebRequest -Uri \"https://github.com/JetBrains/qodana-cli/releases/download/%VERSION%/qodana_windows_x86_64.exe\" -OutFile \"qodana_windows_x86_64.exe\" \n./qodana_windows_x86_64.exe scan --ide QDNET \n\n# Capture the exit code of the command\n$exitCode = $LASTEXITCODE\n\n# Print the exit code\nWrite-Output \"Exit code: $exitCode\"\n\n# Exit the script with the same exit code\nexit $exitCode\nPowerShell build step\nA failed build in TeamCity\n\n\n\nQodana’s Unreal Engine analysis summarized\nWe successfully analyzed the Lyra project, got a detailed report, and fixed more than 800 problems. While conducting professional reviews will likely require a deeper understanding of Unreal Engine, Qodana’s analysis still helped a single junior developer clean up the code and make it more concise. \nFor large-scale projects like Lyra, Qodana can effectively highlight and prioritize critical code issues that may be overlooked in manual reviews.\nSince Lyra is a private repo, we can’t share the outcome, but we hope we’ve shown you how this process could work for your team and what kind of results it can deliver.\nIf you’d like more information, visit our website, view Qodana’s features, or try it in your next game development project. \nSwitch to Qodana for code analysis and get 25% off\nQodana gets better with every release and provides a cost-effective way for teams to build confidence in code quality. \nWith this in mind, we’re offering you 25% off your first year of Qodana if you switch from a comparable commercial solution. Click on the button below to speak to our team. \nSwitch To Qodana\nThank you to Software Developer Ekaterina Trukhan for her contribution to this analysis.",
        "dc:creator": "Kerry Beetge",
        "content": "If you saw our blog post about using Qodana in Unity and .NET projects, you know that we’ve been striving to explore Qodana’s potential for game development. What’s our next stop on this mission? Seeing our code quality platform in action with Unreal Engine, one of the most popular engines for different types of projects [&#8230;]",
        "contentSnippet": "If you saw our blog post about using Qodana in Unity and .NET projects, you know that we’ve been striving to explore Qodana’s potential for game development. What’s our next stop on this mission? Seeing our code quality platform in action with Unreal Engine, one of the most popular engines for different types of projects […]",
        "guid": "https://blog.jetbrains.com/?post_type=qodana&p=537855",
        "categories": [
          "tutorials",
          "game-development",
          "qodana",
          "teamcity",
          "unreal-engine"
        ],
        "isoDate": "2025-01-20T11:00:47.000Z"
      }
    ]
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Rhea Patel",
        "title": "Announcing a free GitHub Copilot for Visual Studio",
        "link": "https://devblogs.microsoft.com/visualstudio/announcing-a-free-github-copilot-for-visual-studio/",
        "pubDate": "Thu, 23 Jan 2025 17:37:46 +0000",
        "content:encodedSnippet": "We’re excited to announce an all new free plan for GitHub Copilot, available for everyone today in Visual Studio. All you need is a GitHub account. No trial. No subscription. No credit card.\nEnable GitHub Copilot Free\n With GitHub Copilot Free, you’ll receive:\n2,000 code completions per month\n50 chat messages per month\nAccess to the latest AI models with Anthropic Claude 3.5 Sonnet and Open AI’s GPT-4o.\n\nGitHub Copilot’s Features in Visual Studio\nGitHub Copilot transforms your Visual Studio experience with powerful features designed to save you time and supercharge your productivity:\nCopilot Edits: Multi-File Editing\nCopilot Edits helps you quickly make changes to multiple files with just one prompt. Edits combines the conversational flow of chat and an inline review experience to help you write code faster and better.\nPreview with clarity: Know exactly what’s being modified with a summary of the affected files and the proposed changes.\nReview with flow: View code diffs inline, directly in your editor. Use the TAB key to accept or the Alt+Del key to reject individual changes or apply/dismiss all at once.\nIterate with confidence: Use checkpoints to revisit earlier iterations of a code file or try an alternative approach anytime for novel ideas.\n\nChat with @workspace and @vs\nCopilot Chat is deeply integrated into your workflow. It understands your entire solution and your Visual Studio environment. Just use commands like @workspace or @vs to get context-specific responses. will intuitively take in your related files and knowledge about the traits your solution to always give you the most relevant responses.\n\nNever write a commit message again \nCopilot will automatically review staged changes and suggest a commit message for you. You can even customize the prompt to make the generated message sound like you or follow your team’s conventions.\n\nUse Copilot to fix your errors \nResolve code errors effortlessly with GitHub Copilot’s file awareness. Now integrated into the lightbulb and error list, Copilot offers fixes and explanations for C# and C++ issues.\n\nSet your breakpoints automatically\nUse Copilot to help you quickly find where to apply breakpoints without manually crafting complex expressions, speed up the debugging process and make it easier to pinpoint and resolve issues in your code.\n\nGitHub Copilot is Everywhere in Visual Studio\nDiscover the amazing features GitHub Copilot brings to Visual Studio! From boosting productivity to simplifying your coding journey, there’s so much to explore. Check out this video for a deeper dive into all the features and tips to get started.\nEnable GitHub Copilot Free\n\nWant to stay in the loop on the newest and most exciting updates for Visual Studio? Follow us on Twitter and LinkedIn, and keep an eye on our blogs for the latest announcements!\nThe post Announcing a free GitHub Copilot for Visual Studio appeared first on Visual Studio Blog.",
        "dc:creator": "Rhea Patel",
        "content": "<p>We&#8217;re excited to announce an all new free plan for GitHub Copilot, available for everyone today in Visual Studio. All you need is a GitHub account. No trial. No subscription. No credit card. With GitHub Copilot Free, you’ll receive: 2,000 code completions per month 50 chat messages per month Access to the latest AI models with [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/announcing-a-free-github-copilot-for-visual-studio/\">Announcing a free GitHub Copilot for Visual Studio</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "We’re excited to announce an all new free plan for GitHub Copilot, available for everyone today in Visual Studio. All you need is a GitHub account. No trial. No subscription. No credit card. With GitHub Copilot Free, you’ll receive: 2,000 code completions per month 50 chat messages per month Access to the latest AI models with […]\nThe post Announcing a free GitHub Copilot for Visual Studio appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=252073",
        "categories": [
          "Copilot",
          "GitHub Copilot",
          "Visual Studio",
          "#Githubcopilot",
          "CopilotFree"
        ],
        "isoDate": "2025-01-23T17:37:46.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "\n                            Dmitry Kopytkov,Deepak Gupta\n            \t\t\t",
        "title": "Evolving our infrastructure through the messaging system model in Dropbox",
        "link": "https://dropbox.tech/infrastructure/infrastructure-messaging-system-model-async-platform-evolution",
        "pubDate": "Tue, 21 Jan 2025 09:00:00 -0800",
        "content:encodedSnippet": "The asynchronous platform at Dropbox integrates a suite of services that enable tasks and workflows to function independently without having to wait on one another. This is pretty important to our work as developers: It empowers any service within Dropbox to initiate and schedule tasks, seamlessly supporting over 400 product use cases—including Dropbox Dash and our other AI innovations—and efficiently routing more than 30 million tasks every minute. It also handles change data capture (CDC) use cases, where changes in our underlying storage system, including the FileSystem, are relayed to various product lambdas and processes. In short, it helps us ensure impactful and efficient business operations.\nThis implementation was essential to our growth from where we were a couple of years ago. Back then, the asynchronous platform struggled with scalability and reliability, frequently falling short of the demands of our expanding product portfolio. For product engineers, the platform posed additional hurdles due to limited developer productivity tools, making it cumbersome to build and iterate on asynchronous workflows. Today’s transformation into a robust and scalable system marks a dramatic shift from those early challenges—it enables innovation at a desired pace.\nIn this blog, we’ll introduce an open messaging system model (MSM), which played a key role in evolving our platform. It helped us build a unified event-driven system capable of orchestrating a wide range of asynchronous tasks and meeting future needs, especially as we focus on AI. Inspired by the Open Systems Interconnection (OSI) model, the MSM divides our platform into five logical layers. This standardization simplifies layers such as frontend interfaces, lambda functions, event schedulers, and event routers, allowing them to work across various use cases with different delivery guarantees and data sources, including those related to CDC.\nLet’s get into it.\nChallenges and limitations in our asynchronous infrastructure\nBeginning in 2021, our infrastructure comprised multiple asynchronous systems, each tailored to specific product or process requirements. These systems facilitated diverse functions—such as streaming events for Dropbox file uploads and edits—as well as supporting domains like security, abuse prevention, machine learning, and search indexing. Additionally, Dropbox integrated CDC functionality, enabling any modification within the underlying storage systems to generate an event, subsequently activating the async infrastructure. Despite occasional functional overlaps, these systems were developed, operated, and maintained separately, leading to inconsistencies in development speed, reliability, and operational ease.\nKey issues and limitations with these systems were as follows:\nDeveloper efficiency\nThe complexity of the current systems required product engineers to undertake a steep learning curve and assume responsibility for operational tasks such as capacity planning, release processes, and support, leading to reduced development speed and productivity.\nReliability\nThese systems had varied service-level objectives (SLOs) for availability, latency, processing, and recovery, which resulted in inconsistent and unreliable performance. Additionally, systems were not multi-homed, and this created significant reliability risk for multiple business use cases in the event of data center failure.\nOperability\nThe variety of systems led to higher operational costs due to their complexity, requiring additional development effort for maintenance and support. The asynchronous components in our technology stack relied on a mix of external queuing solutions, such as Kafka, Redis, and Amazon SQS, creating an infrastructure that was challenging to manage and operate.\nSystem scalability\nAt the beginning of 2021, our system was processing over 30 billion requests daily to dispatch jobs to lambda functions. (Lambda is a serverless cloud service that runs your code automatically in response to events, without requiring you to manage any servers.) However, meeting the defined SLOs became increasingly challenging. Certain critical components, such as the delayed event scheduler, had already maxed out their throughput capacity. Consequently, we had to implement rigorous screening protocols for each new use case before onboarding in order to ensure it adhered to the system's capacity limitations and wouldn't jeopardize its performance.\nLambda infrastructure\nThe lambda-based architecture utilized on the consumer side was complex and diverged from the Dropbox service-oriented architecture (SOA) guidelines and established best practices. Consequently, diagnosing and investigating issues on the consumption side became highly challenging, as it didn't integrate seamlessly with the Dropbox infrastructure and recommended methodologies. This lack of alignment resulted in several adverse effects, notably:\nRelease consistency: The release procedures across these systems lacked uniformity and robust safety measures, introducing deployment and update risks.\nCompute efficiency: The compute clusters supporting these systems operated below peak efficiency, resulting in suboptimal resource utilization.\nNo autoscaling: The absence of autoscaling for lambda infrastructure, stemming from its deviation from the Dropbox SOA guidelines, resulted in poor integration with our autoscaling infrastructure. As a result, there was a reliance on customer or platform-owner intervention to manually augment capacity when the base capacity proved inadequate to manage the workload.\nExtensibility\nExtensibility posed a significant challenge for these systems, characterized by a deficiency in flexibility and scalability to adapt to emerging product demands. The current solutions were ill-equipped to seamlessly integrate new workflows, and any attempts to expand them would introduce unnecessary complexities in implementation. With the introduction of Cypress, our new filesystem architecture, the existing system faced limitations in expanding our CDC pipeline to distribute Cypress events to multiple subscribers within Dropbox.\nIn all, these challenges underscored the need for a more unified and consistent approach to our asynchronous infrastructure, emphasizing the importance of addressing developer velocity, reliability, operability, efficiency, and extensibility to better support the company's evolving product landscape.\nRethinking our approach\nThe existing async systems already supported over 400 business use cases. The large number of existing use cases meant we didn’t have the flexibility to construct an entirely new system from scratch, as the migration would have been very time consuming. Instead, we decided to adopt a phased approach, with incremental steps to rebuild existing systems that mitigate risks associated with migrating existing production flows to a new infrastructure. Returning to the drawing board, we outlined three primary goals for the new platform, envisioning a gradual and incremental build-up of capabilities:\nDevelopment velocity\nSimplify the asynchronous interface to streamline platform adoption for product engineers. This allows them to focus on creating innovative product features rather than investing time in understanding the complex asynchronous landscape and determining the most suitable system for their use case.\nDecrease the operational burden on product engineers by implementing release practices that identify code regressions during deployment and automatically initiate rollbacks if a new release breaches predefined thresholds.\nEnable automatic compute scaling when a lambda function encounters a backlog of events to process, ensuring that the current base capacity is augmented if deemed insufficient.\nRobust and extensible async foundation\nUnify common elements and patterns across existing async systems within Dropbox and simplify the interface.\nSupport new use cases with minimal modifications and avoid the need to build entire new systems by providing extensible components and flexible APIs.\nCost and operational efficiency\nStreamline the foundational infrastructure by phasing out redundant systems (where applicable) and cut down on operational costs.\nTransition lambda infrastructure to the Dropbox SOA stack to increase compute efficiency and enable functionalities such as autoscaling, multihoming, and improved out-of-the-box monitoring capabilities.\nThe overarching key performance indicator (KPI) that we aimed to improve over time was the \"time to launch\" for product engineers to deploy a new use case into production. As platform owners, our primary KPI of interest was the \"oncall time\" expended on a weekly basis.\n The five layers of the messaging system model\nThe initial step in the refinement of the async system involved deconstructing it into its fundamental layers. We undertook this process to achieve the aforementioned objectives. Subsequently, a systematic approach was devised, beginning with the dissection of the async system into its core elements, followed by the formulation of a bottom-up strategy for its progressive enhancement.\nFrom a macroscopic standpoint, the asynchronous system can be mapped to an MSM consisting of three primary layers, analogous to the seven layers of the OSI model in network transmission frameworks. These three primary layers are:\nCustomer layer: This component, also known as the “frontend layer,” encompasses the various pathways through which users interact and interface with the async system. It encapsulates the mechanisms by which users communicate with and integrate into the async environment.\nOrchestration layer: This layer is intrinsic to the async system and encompasses the entirety of the tasks required for the scheduling and transmission of async operations to the compute layer (also known as the “execution layer”). It serves as the intermediary stage between the customer layer and the compute layer, and it’s responsible for ensuring that various components and services interact seamlessly to fulfill complex workflows and business logic requirements.\nCompute layer: This layer is the execution hub of the async system, where the actual processing and execution of async tasks take place. It is responsible for the seamless execution of asynchronous operations, thereby ensuring the efficient functioning of the system as a whole.\n -->\n\n        \n         \n        \n    \n\n            \nA 10,000-foot view of the async system\n\n\nThe three layers mentioned above can then be further broken down into five, more specific layers—frontend, scheduler, flow control, delivery, and execution—with each new layer serving an important role within the above three buckets. (Some overlap occurs between the customer and orchestration layers). These five layers of the MSM are illustrated in the diagram below.\n -->\n\n        \n         \n        \n    \n\n            \nAn illustration of the five components of the Messaging System Model (MSM)\n\n\nNow, let's take a closer look at each of these five layers.\nFrontend\nIn the architecture of an asynchronous system, the frontend layer assumes the critical role of serving as the primary interface for user interaction with the system. It represents the user-facing aspect of the asynchronous environment, orchestrating seamless communication and integration with the system's core functionalities. Users are categorized into two distinct groups: first, there are the regular product engineers who utilize programmatic methods to invoke a publish remote procedure call (RPC) and enqueue events, destined to be consumed by one or more subscribers. The second category encompasses systems such as databases or event sources, which necessitate the enqueuing of changes to diverse objects, entities, or files, thereby propelling both internal and external business workflows forward.\nA pivotal responsibility of the frontend layer is the management of the schema registry and the rigorous validation of every event schema traversing the system. This stringent schema validation process ensures that published events conform to the predefined contract established with subscribers. Additionally, the frontend layer is tasked with the intricate conversion of disparate message formats, including JSON, Proto, and Avro, among others, into a standardized message format—typically protocol buffers—compatible with the internal asynchronous implementation.\nFurthermore, the frontend component is entrusted with guaranteeing the durability of all events published to the asynchronous system, thereby safeguarding the integrity and reliability of the system's data flow. \nScheduler\nThe scheduler is the core engine within an async system and plays a crucial role in coordinating and dispatching disparate events for various consumers that subscribe to these events. This layer plays various roles. For example, for a CDC use case, this will call external data source APIs to get relevant range for the payloads that will be delivered to the subscribers. For a use case where events need delayed execution, the scheduler would store these events separately so they can be trigger at desired timestamp with a process keeping tabs on these events and publishing them to subscribers at those desired scheduled timestamps. \nScheduler also has the responsibility to maintain the order of execution of the events and ensures task delivery to subscribers based on this order.\nFlow control\nFlow control plays a pivotal role in the orchestration layer, managing the distribution of tasks to subscribers based on several factors, such as subscriber availability, task priority, and potential throttling events. For instance, in a CDC scenario, the orchestration layer dynamically adjusts the rate of queries dispatched to subscribers. This adaptation occurs when the orchestration layer detects that a subscriber is unable to handle the job throughput effectively or when the source, backing CDC, signals the scheduler client to reduce the pace.\nState management, another function of this layer, encompasses the maintenance of data structures responsible for tracking ongoing events and their respective statuses (such as pending, running, or complete). Additionally, it incorporates mechanisms to retry tasks in case of transient failures, ensuring robustness and reliability in task execution.\nDelivery\nThe execution layer of the messaging system model can be broken down into two main parts. The first is the delivery layer, which is the process of directing the event to the right place or service. The second, the event execution, we’ll get to in a bit.\nRouting is the final layer in an asynchronous system, responsible for directing the message out of the system and into the domain where a designated process or lambda function will handle the event. This process or lambda function may be hosted within the same virtual private cloud (VPC) as the messaging infrastructure or may be a part of public clouds like AWS, Azure, etc. In a push-based model, the routing layer is one of the most critical components, similar to the “last mile delivery” in an e-commerce delivery system.\nRouting enables many critical functions, including:\nMessage filtering based on subscriber preferences\nDelivery retries for transient failures\nContinuously monitoring the health of a subscriber’s event execution hosts, and then routing events only to those that are healthy\nDispatching event execution status to the orchestration layer for state machine management\nEvent delivery concurrency management\nExecution\nThe event execution is the second layer of the primary compute bucket. It’s when the actual task happens, and it’s usually done by a lambda function (i.e., serverless code), or a remote process—potentially even another system or service—that handles the event. In short, the compute layer involves first routing the event and then actually processing it.\nLambda infrastructure refers to the underlying framework responsible for executing events. When an event is triggered, a process is initiated within this infrastructure, which subsequently returns either a success or retriable failure status post-execution. If no status is returned, or if an error occurs, the default assumption is a retriable failure. In this interaction, the router acts as the client, operating under a push model.\nIdeally, the executing process operates across multiple cloud environments to enhance reliability. The router has the capability to push events to various clouds based on the locality preference configured by the lambda/process owner. For example, some users may opt to configure their processes to be active in specific clouds to ensure proximity to backend storage dependencies, thereby minimizing cross-data center latency.\nLambda infrastructure should also include autoscaling as part of its features. At Dropbox, our lambda infrastructure is backed by Atlas, which offers autoscaling capabilities. Additionally, Atlas supports release-time hooks, enabling validation and rollback of code changes if they would potentially degrade service uptime or impact any features negatively.\nConclusion\nEngaging with customers and understanding their requirements and pain points is vital when evolving or reconstructing a major platform component. This approach was instrumental in shaping the blueprint for MSM. By applying first principles, we deconstructed the problem into its smallest components and envisioned a system that delivers the flexibility and extensibility required for the platform. This solid foundation enabled us to rebuild from the ground up with clarity and purpose, ensuring the platform meets current demands while remaining adaptable to future challenges.\nThis blog has only scratched the surface of the asynchronous platform we’ve built over the past few years, and we’re constantly looking for new ways to improve our infrastructure. We’re excited to, in the future, dive deeper into other critical design decisions that help us build a more efficient and useful Dropbox!\n \n~ ~ ~\n \nIf building innovative products, experiences, and infrastructure excites you, come build the future with us! Visit dropbox.com/jobs to see our open roles, and follow @LifeInsideDropbox on Instagram and Facebook to see what it's like to create a more enlightened way of working.",
        "dc:creator": "\n                            Dmitry Kopytkov,Deepak Gupta\n            \t\t\t",
        "content": "null",
        "contentSnippet": "null",
        "guid": "https://dropbox.tech/infrastructure/infrastructure-messaging-system-model-async-platform-evolution",
        "categories": [
          "models",
          "Developer",
          "AI",
          "Lambda",
          "Dash",
          "Infrastructure"
        ],
        "isoDate": "2025-01-21T17:00:00.000Z"
      }
    ]
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": [
      {
        "creator": "sunyzero",
        "title": "gnome-tweaks로 리눅스 데스크탑 환경의 미세 조정",
        "link": "http://sunyzero.tistory.com/311",
        "pubDate": "Sun, 19 Jan 2025 23:48:43 +0900",
        "author": "sunyzero",
        "comments": "http://sunyzero.tistory.com/311#entry311comment",
        "content": "<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">리눅스 GNOME 데스크탑 환경을 사용하다보면 뭔가 약간 불편함이 있을 수 있는데, 이를 미세하게 조정해주면 편리해진다. 이를 위해 사용되는 프로그램이 gnome-tweaks 이다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">1. 설치</span></h2>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">dnf install gnome-tweaks 로 간단하게 설치할 수 있다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">2. 실행 및 설정</span></h2>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">애플리케이션 목록에서 실행해도되고, 터미널에서 gnome-tweaks로 실행해도 된다. 사용하는 유저로 로그인한 상태에서 실행하면 된다. root로 실행하지는 말자.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1032\" data-origin-height=\"630\"><span data-url=\"https://blog.kakaocdn.net/dn/M3UKs/btsLRhig95a/tNmcAciyh63SfNH13kykA0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/M3UKs/btsLRhig95a/tNmcAciyh63SfNH13kykA0/img.png\" data-alt=\"gnome-tweaks - Windows\"><img src=\"https://blog.kakaocdn.net/dn/M3UKs/btsLRhig95a/tNmcAciyh63SfNH13kykA0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FM3UKs%2FbtsLRhig95a%2FtNmcAciyh63SfNH13kykA0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1032\" height=\"630\" data-origin-width=\"1032\" data-origin-height=\"630\"/></span><figcaption>gnome-tweaks - Windows</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">Windows에서 설정할 수 있는 주요 기능은 다음과 같다. 특히 \"두번째 누름 동작에 크기 조절\"은 매우 유용한 기능이다.</span></p>\n<div>\n<table style=\"border-collapse: collapse; width: 100%;\" border=\"1\" data-ke-align=\"alignLeft\">\n<tbody>\n<tr>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">두번 누름</span></span></td>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">Minimize를 설정해두면 편리하게 사용할 수 있다. <br />(창 타이틀 부분을 두번 클리하면 즉시 최소화 해준다)</span></span></td>\n</tr>\n<tr>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">제목 표시줄 단추=최대화/최소화</span></span></td>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">최대화, 최소화 기능을 켜면 창 우측 or 좌측 상단에 최소/최대화 기능이 생긴다.</span></span></td>\n</tr>\n<tr>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">모달 대화 상자 붙여두기</span></span></td>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">모달 대화 상자와 상위 창이 같이 이동하면 직관적이고 잘못 입력하거나 오해할 가능성이 적어진다.</span></span></td>\n</tr>\n<tr>\n<td><span style=\"background-color: #f6e199; font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">두번째 누름 동작에 크기 조절</span></span></td>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">Super키를 누른 상태에서 휠 버튼으로 크기 조절하던 것을 마우스 오른 버튼으로 대체하여 편리해진다. 이 기능은 적극적으로 추천한다.</span></span><br /><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">(두번째 누름 동작 = Mouse 2번째 버튼 클릭 동작)</span></span></td>\n</tr>\n</tbody>\n</table>\n<span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><b><br /></b> </span></div>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">Keyboard에서는&nbsp;Capslock&nbsp;동작에&nbsp;대해서&nbsp;커스터마이징을&nbsp;하는&nbsp;편이다.&nbsp;Linux에서는&nbsp;보통&nbsp;&lt;Ctrl-C&gt;나&nbsp;&lt;Ctrl-Z&gt;,&nbsp;&lt;Ctrl-W&gt;를&nbsp;많이&nbsp;사용한다.&nbsp;각각&nbsp;취소,&nbsp;SIGTSTP&nbsp;시그널&nbsp;전달,&nbsp;GUI&nbsp;프로그램의&nbsp;탭&nbsp;닫기&nbsp;기능으로&nbsp;사용된다.&nbsp;이&nbsp;기능을&nbsp;누를때&nbsp;Capslock키를&nbsp;&lt;Ctrl&gt;로&nbsp;대체하면&nbsp;편리해진다.&nbsp;대신에&nbsp;Capslock&nbsp;기능은&nbsp;양쪽&nbsp;Shift를&nbsp;동시에&nbsp;눌러서&nbsp;토글하는&nbsp;방식으로&nbsp;변경한다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"528\" data-origin-height=\"566\"><span data-url=\"https://blog.kakaocdn.net/dn/Cfmkw/btsLSxYObiO/7CMBqnOXGC6RpJb0N2tZDK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Cfmkw/btsLSxYObiO/7CMBqnOXGC6RpJb0N2tZDK/img.png\" data-alt=\"gnome-tweaks - keyboard - caps lock\"><img src=\"https://blog.kakaocdn.net/dn/Cfmkw/btsLSxYObiO/7CMBqnOXGC6RpJb0N2tZDK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FCfmkw%2FbtsLSxYObiO%2F7CMBqnOXGC6RpJb0N2tZDK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"528\" height=\"566\" data-origin-width=\"528\" data-origin-height=\"566\"/></span><figcaption>gnome-tweaks - keyboard - caps lock</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">앞서 언급한대로 caps lock을 control키로 사용하는 경우에는 양쪽 shift로 caps lock을 대신하면 된다. 이 설정은 호환성 옵션 부분에 있다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"528\" data-origin-height=\"566\"><span data-url=\"https://blog.kakaocdn.net/dn/cOxQq0/btsLScU6XY8/MvmmPeaSLsUdf6SDi6t941/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cOxQq0/btsLScU6XY8/MvmmPeaSLsUdf6SDi6t941/img.png\" data-alt=\"gnome-tweaks - keyboard - compatibility\"><img src=\"https://blog.kakaocdn.net/dn/cOxQq0/btsLScU6XY8/MvmmPeaSLsUdf6SDi6t941/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcOxQq0%2FbtsLScU6XY8%2FMvmmPeaSLsUdf6SDi6t941%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"528\" height=\"566\" data-origin-width=\"528\" data-origin-height=\"566\"/></span><figcaption>gnome-tweaks - keyboard - compatibility</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">이외에 기본 Font나 appearance에서 이것저것 수정이 가능하므로 한번씩 살펴보면 좋을 듯 하다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">히스토리</span></h2>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">2025-01-19 작성</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "리눅스 GNOME 데스크탑 환경을 사용하다보면 뭔가 약간 불편함이 있을 수 있는데, 이를 미세하게 조정해주면 편리해진다. 이를 위해 사용되는 프로그램이 gnome-tweaks 이다.\n \n1. 설치\ndnf install gnome-tweaks 로 간단하게 설치할 수 있다.\n \n2. 실행 및 설정\n애플리케이션 목록에서 실행해도되고, 터미널에서 gnome-tweaks로 실행해도 된다. 사용하는 유저로 로그인한 상태에서 실행하면 된다. root로 실행하지는 말자.\ngnome-tweaks - Windows\n\n\nWindows에서 설정할 수 있는 주요 기능은 다음과 같다. 특히 \"두번째 누름 동작에 크기 조절\"은 매우 유용한 기능이다.\n두번 누름\nMinimize를 설정해두면 편리하게 사용할 수 있다. \n(창 타이틀 부분을 두번 클리하면 즉시 최소화 해준다)\n\n\n제목 표시줄 단추=최대화/최소화\n최대화, 최소화 기능을 켜면 창 우측 or 좌측 상단에 최소/최대화 기능이 생긴다.\n\n\n모달 대화 상자 붙여두기\n모달 대화 상자와 상위 창이 같이 이동하면 직관적이고 잘못 입력하거나 오해할 가능성이 적어진다.\n\n\n두번째 누름 동작에 크기 조절\nSuper키를 누른 상태에서 휠 버튼으로 크기 조절하던 것을 마우스 오른 버튼으로 대체하여 편리해진다. 이 기능은 적극적으로 추천한다.\n(두번째 누름 동작 = Mouse 2번째 버튼 클릭 동작)\n\n\n\n\n \nKeyboard에서는 Capslock 동작에 대해서 커스터마이징을 하는 편이다. Linux에서는 보통 <Ctrl-C>나 <Ctrl-Z>, <Ctrl-W>를 많이 사용한다. 각각 취소, SIGTSTP 시그널 전달, GUI 프로그램의 탭 닫기 기능으로 사용된다. 이 기능을 누를때 Capslock키를 <Ctrl>로 대체하면 편리해진다. 대신에 Capslock 기능은 양쪽 Shift를 동시에 눌러서 토글하는 방식으로 변경한다.\ngnome-tweaks - keyboard - caps lock\n\n\n앞서 언급한대로 caps lock을 control키로 사용하는 경우에는 양쪽 shift로 caps lock을 대신하면 된다. 이 설정은 호환성 옵션 부분에 있다.\ngnome-tweaks - keyboard - compatibility\n\n\n \n이외에 기본 Font나 appearance에서 이것저것 수정이 가능하므로 한번씩 살펴보면 좋을 듯 하다.\n \n히스토리\n2025-01-19 작성",
        "guid": "http://sunyzero.tistory.com/311",
        "categories": [
          "컴퓨터 관련/리눅스 데스크탑",
          "gnome",
          "gnome-tweaks",
          "linux",
          "그놈 데스크탑",
          "리눅스",
          "캡스락"
        ],
        "isoDate": "2025-01-19T14:48:43.000Z"
      }
    ]
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": [
      {
        "title": "CAD 모델 생성AI 및 LLM 기술 조사",
        "link": "http://daddynkidsmakers.blogspot.com/2025/01/cad-ai-llm.html",
        "pubDate": "2025-01-23T02:23:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">이 글은&nbsp;CAD 모델 생성AI 및 LLM 기술을 조사한다.</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgKnHeldVqMfPXAIE-ybSWV70HZMpQXx0k1YrSx9sMCnQkBXO0Knp0jLIYny7CBoqPmszkV57YV0vzeoOcKsWcPy260bSLDCaAbib_8lDVUj2fJ01R8GzEg67qVTXUFoCJvLIvK0jfH8urMvUfOKw1SOWLoZhuQS9Wx3oC67cmbYuB4-RNdzCLD-5y7AR9S\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"258\" data-original-width=\"803\" height=\"158\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgKnHeldVqMfPXAIE-ybSWV70HZMpQXx0k1YrSx9sMCnQkBXO0Knp0jLIYny7CBoqPmszkV57YV0vzeoOcKsWcPy260bSLDCaAbib_8lDVUj2fJ01R8GzEg67qVTXUFoCJvLIvK0jfH8urMvUfOKw1SOWLoZhuQS9Wx3oC67cmbYuB4-RNdzCLD-5y7AR9S=w489-h158\" width=\"489\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">SolidGen (Autodesk)</div><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div></div><div style=\"text-align: left;\">조사를 위해 다음 키워드로 구글링, GITHUB, 논문 검색을 수행한다.&nbsp;</div><div style=\"text-align: center;\">'CAD', 'Scketch', 'LLM', 'Generative AI', 'Transformers', 'github', 'huggingface'</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">다음은 검색된 기술 결과를 보여준다.&nbsp;</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEggmbsKltLYfN3hqkB4djXVj8dG8x-XXPz2YlBeFCRZMWApn0GeSOQXbSp0U9uF5_e8-ucw2V4lp2Dlz8AxToA2H7IAvAH8riaDFegyWu_u7iivypO8tEvGQjTAhEaq2uYRzv0P7bnauOwt2S2o3SkJ4-R6QtNrGjMLhn2XmDd2f8UX5XZxvTs_2az3pBdZ\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"348\" data-original-width=\"750\" height=\"148\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEggmbsKltLYfN3hqkB4djXVj8dG8x-XXPz2YlBeFCRZMWApn0GeSOQXbSp0U9uF5_e8-ucw2V4lp2Dlz8AxToA2H7IAvAH8riaDFegyWu_u7iivypO8tEvGQjTAhEaq2uYRzv0P7bnauOwt2S2o3SkJ4-R6QtNrGjMLhn2XmDd2f8UX5XZxvTs_2az3pBdZ\" width=\"320\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://archive.nyu.edu/handle/2451/43778\">ABC: A Big CAD Model Dataset For Geometric Deep Learning : Faculty Digital Archive : NYU Libraries</a></div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjnmIXAHRwKLEzTDXpj0CIlcKsYn3ZrpTnF2cRyo8BnIyxTnt0So15dE-9ZOJ2_3EF3lVjKf5dLvhbJGzpiFpxWv8eOWOj1qYLbA4Asnc31qNw3UVeAbPHppf3Xc7GGtC0NO6judmLTOx_-CUYubXpteNc7CsjccD_VX1zUnc702FNS2z4Ddw82brrXa8Cn\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"293\" data-original-width=\"687\" height=\"136\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjnmIXAHRwKLEzTDXpj0CIlcKsYn3ZrpTnF2cRyo8BnIyxTnt0So15dE-9ZOJ2_3EF3lVjKf5dLvhbJGzpiFpxWv8eOWOj1qYLbA4Asnc31qNw3UVeAbPHppf3Xc7GGtC0NO6judmLTOx_-CUYubXpteNc7CsjccD_VX1zUnc702FNS2z4Ddw82brrXa8Cn\" width=\"320\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://arxiv.org/pdf/2401.15563\">BrepGen: A B-rep Generative Diffusion Model with Structured Latent Geometry</a></div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhjk8V05v5esg9kP7TM03W-ShmXbadh_102dgYd4xsIq7i6vJ3k-jnuOovlgE3sBPkHYHzPYCMpRHCCv6z2v11P-L1YYayXm4BSwuxoMUV8MXu5wWMmp7T6uny6f3H-UaFYP9hhyqg5w7S5kTqUYIp3msmUoJhwYToqIP4yzUsdFfiH1bWsEJA4J7iyhzN5\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"353\" data-original-width=\"591\" height=\"191\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhjk8V05v5esg9kP7TM03W-ShmXbadh_102dgYd4xsIq7i6vJ3k-jnuOovlgE3sBPkHYHzPYCMpRHCCv6z2v11P-L1YYayXm4BSwuxoMUV8MXu5wWMmp7T6uny6f3H-UaFYP9hhyqg5w7S5kTqUYIp3msmUoJhwYToqIP4yzUsdFfiH1bWsEJA4J7iyhzN5\" width=\"320\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">Text2CAD: Text to 3D CAD Generation via Technical Drawings</div><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEiiTgNHZ92LIe-w1Qw4QNOvw8yiyMJp_pREnO8KeqYSkk3bwKmq17iWPYbnc2w2LpyBTvxu10tRrc41ofFJc60AddYNdtkqtP23EWidh_2B-Fny6KVFnQP0MK_MFYzBROQnrvIRRx96mzxICmJZ_dbD8yanqevyYgr-1qAhgAD1xyf60KXovQ4NNGk4qhxq\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"688\" data-original-width=\"552\" height=\"367\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEiiTgNHZ92LIe-w1Qw4QNOvw8yiyMJp_pREnO8KeqYSkk3bwKmq17iWPYbnc2w2LpyBTvxu10tRrc41ofFJc60AddYNdtkqtP23EWidh_2B-Fny6KVFnQP0MK_MFYzBROQnrvIRRx96mzxICmJZ_dbD8yanqevyYgr-1qAhgAD1xyf60KXovQ4NNGk4qhxq=w295-h367\" width=\"295\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://arxiv.org/pdf/2411.15279\">Don’t Mesh with Me: Generating Constructive Solid Geometry Instead of  Meshes by Fine-Tuning a Code-Generation LLM</a></div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjqA0ffRUffnsZ2nM0-WEH8OdA7asD1yke043xOO5JLX6ExVDf4sTfgkFNe8vgMkObozNZdNI-TDINNYlUKYNlkKQHlQnrsh-xCbG5gnEyf7Wl2if3jiwI_u38cw2Gy04owXk11uQaZHRQGvpLkEw35bgoAipBYBE2UrKGTSLEv42DTxgUHnOQJvkiA3kVt\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"703\" data-original-width=\"1367\" height=\"236\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjqA0ffRUffnsZ2nM0-WEH8OdA7asD1yke043xOO5JLX6ExVDf4sTfgkFNe8vgMkObozNZdNI-TDINNYlUKYNlkKQHlQnrsh-xCbG5gnEyf7Wl2if3jiwI_u38cw2Gy04owXk11uQaZHRQGvpLkEw35bgoAipBYBE2UrKGTSLEv42DTxgUHnOQJvkiA3kVt=w458-h236\" width=\"458\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://arxiv.org/pdf/2412.19663\">CAD-GPT: Synthesising CAD Construction Sequence with Spatial  Reasoning-Enhanced Multimodal LLMs</a></div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhtYING8rrI1UNpUM04MOfFPv7WUEELby0PmLOjhgsjoYmaQDscdmxoLo0Fn-M62J86XgZCv4bWsV586XmQATEL0v1qWtSkLkfajivVoVf1Il_au-_nRFCTolvCvVaUVS7zcXS78dm5icHeKVmNFLri5Avsrle9jKcI7KcQyfKo5pvo-lU66qsmB5oTQuLj\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"481\" data-original-width=\"822\" height=\"187\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhtYING8rrI1UNpUM04MOfFPv7WUEELby0PmLOjhgsjoYmaQDscdmxoLo0Fn-M62J86XgZCv4bWsV586XmQATEL0v1qWtSkLkfajivVoVf1Il_au-_nRFCTolvCvVaUVS7zcXS78dm5icHeKVmNFLri5Avsrle9jKcI7KcQyfKo5pvo-lU66qsmB5oTQuLj\" width=\"320\" /></a></div><div style=\"text-align: center;\"><a href=\"https://github.com/lingxiaoli94/SPFN\">SPFN: Source code for \"Supervised Fitting of Geometric Primitives to 3D Point Clouds\" [CVPR 2019].</a></div><div><br /></div><div style=\"text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEg5xHVPg_p-rzjEGSECiBSlvUVaOXh5kvjG2zADCwYEo-1htB42_tMNKM2RDr_mdQRwgn_Dz2900tKp8m06XKCxoEiKj4VwzjIrqOaXy_jySPziMnkNCsKbwf-snUlYhzmjQb07JOyRP6svlQ4TUSFvrP2wOM2FVdJzQQNSF8nMRJgFs0ddQnZ0DBuIpo1h\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"672\" data-original-width=\"1364\" height=\"158\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEg5xHVPg_p-rzjEGSECiBSlvUVaOXh5kvjG2zADCwYEo-1htB42_tMNKM2RDr_mdQRwgn_Dz2900tKp8m06XKCxoEiKj4VwzjIrqOaXy_jySPziMnkNCsKbwf-snUlYhzmjQb07JOyRP6svlQ4TUSFvrP2wOM2FVdJzQQNSF8nMRJgFs0ddQnZ0DBuIpo1h\" width=\"320\" /></a></div></div><div style=\"text-align: center;\"><a href=\"https://github.com/Hippogriff/parsenet-codebase\">Hippogriff/parsenet-codebase: Code base of ParSeNet: ECCV 2020</a></div><div style=\"text-align: center;\"><br /></div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhx56SODF9J8m4M4uJXqmOvNNA3qWaLLjezDfVC6DafvmQWkAxNcetQBvrZ1HMipyduxPN2AHSpMj52ntxoGqdHYZwXigRfRX4L-6qvi221Vksv1LKeStAUIK98X1mjX-0QHSQqGhnVAc2kOf8abBsUhOmPQfdJZb6qol91IKBnx6Vld1DDc3B-HZjE-xsk\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"275\" data-original-width=\"776\" height=\"162\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhx56SODF9J8m4M4uJXqmOvNNA3qWaLLjezDfVC6DafvmQWkAxNcetQBvrZ1HMipyduxPN2AHSpMj52ntxoGqdHYZwXigRfRX4L-6qvi221Vksv1LKeStAUIK98X1mjX-0QHSQqGhnVAc2kOf8abBsUhOmPQfdJZb6qol91IKBnx6Vld1DDc3B-HZjE-xsk=w458-h162\" width=\"458\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEil_pEHkyh1_5vInEmcJGumUzKjGk45wkRVytKcUuuG8btiuKEwiGuObav4k_76rl0ntdrk5j9AB8hUTJMTvxJtCg_EEzSE0tsBFIZXiZeDgnmIj9a-75quP0oqTQvER_7rCFR1U_mF9vO5Z3Lwh6Hp9WsjA9_eb_5TCCQ9qvTC7zWdTdvNghXzAHFPXz7I\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"1818\" data-original-width=\"2260\" height=\"240\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEil_pEHkyh1_5vInEmcJGumUzKjGk45wkRVytKcUuuG8btiuKEwiGuObav4k_76rl0ntdrk5j9AB8hUTJMTvxJtCg_EEzSE0tsBFIZXiZeDgnmIj9a-75quP0oqTQvER_7rCFR1U_mF9vO5Z3Lwh6Hp9WsjA9_eb_5TCCQ9qvTC7zWdTdvNghXzAHFPXz7I\" width=\"298\" /></a></div></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgN2_a_6efxkVvk9LBrw0dOgRoWJff250BJJBer2AHE6nTzJGpMwXR4MDP8c7BiJyb0wBTudntAegl9ZGzuwkD36XhaDzrKJ3g8ah7dgRX3UqtlOYFGH4UAntWlhGP1ml-IWC75zXsdm50d5oWQmfWF1Fcbszt_d1CHeQW89TnHPzZ9ByuCFYko0JlogJ5P\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"720\" data-original-width=\"2000\" height=\"176\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgN2_a_6efxkVvk9LBrw0dOgRoWJff250BJJBer2AHE6nTzJGpMwXR4MDP8c7BiJyb0wBTudntAegl9ZGzuwkD36XhaDzrKJ3g8ah7dgRX3UqtlOYFGH4UAntWlhGP1ml-IWC75zXsdm50d5oWQmfWF1Fcbszt_d1CHeQW89TnHPzZ9ByuCFYko0JlogJ5P=w490-h176\" width=\"490\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"></div></div></div><div style=\"text-align: center;\"><a href=\"https://manycore-research.github.io/CAD2Program/\">From 2D CAD Drawings to 3D Parametric Models: A Vision-Language Approach</a></div><div style=\"text-align: center;\"><br /></div><div style=\"text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEiuCkg6lb7GVHPL7XZZhR8VCD5uLXEDa_h1LnCpGUwGdV_MIdzb1p61FfbNQzquusLtCRN1hlQ8vxOyF7OZbBrON5encS9lzu41ad-c6VmYpRGEHv8ugp_XXeKLydsw7cXiwAhxPo-FQjsENzw3yS3RphQUPg65MxJiqIJoM6XBdd8H5u9ansgP0IWb6vSj\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"539\" data-original-width=\"1280\" height=\"207\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEiuCkg6lb7GVHPL7XZZhR8VCD5uLXEDa_h1LnCpGUwGdV_MIdzb1p61FfbNQzquusLtCRN1hlQ8vxOyF7OZbBrON5encS9lzu41ad-c6VmYpRGEHv8ugp_XXeKLydsw7cXiwAhxPo-FQjsENzw3yS3RphQUPg65MxJiqIJoM6XBdd8H5u9ansgP0IWb6vSj=w491-h207\" width=\"491\" /></a></div><a href=\"https://damassets.autodesk.net/content/dam/autodesk/www/pdfs/sketch-a-shape.pdf\">Sketch-A-Shape: Zero-Shot Sketch-to-3D Shape Generation</a></div><div style=\"text-align: center;\"><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEiNE95hV3UkHsJzFhS9vCArZKczORTidZi-YuGxtq5t3u0GuJqqxGyJIbNL5j_s5QzjJE6tOsUHO-IYUpK_hRCoBPkQ_LwY8UKXjg1rXxKd7kULel3rIeU1vgy_zNrQuTKIIQ-NwexdLdjKqvmdsGNL9b_SM6juukez1UeE3GTBc71pPyrftxR99pR38XTO\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"523\" data-original-width=\"662\" height=\"240\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEiNE95hV3UkHsJzFhS9vCArZKczORTidZi-YuGxtq5t3u0GuJqqxGyJIbNL5j_s5QzjJE6tOsUHO-IYUpK_hRCoBPkQ_LwY8UKXjg1rXxKd7kULel3rIeU1vgy_zNrQuTKIIQ-NwexdLdjKqvmdsGNL9b_SM6juukez1UeE3GTBc71pPyrftxR99pR38XTO\" width=\"304\" /></a></div><a href=\"https://www.research.autodesk.com/app/uploads/2024/05/hg-cad.pdf\">HG-CAD: Hierarchical Graph Learning for Material Prediction and Recommendation in Computer-Aided Design</a><br /><br /></div><div style=\"text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjl0fL9AlSfmL_cOrLANpqTQkPCmB_73o4vssLfaleX0cp5jNRqF3XZgWXjTtoEalQpdUbPsnMIFBvuG-n8MgKFJYOGnt8k_f3NwJiOIW6wKVWKq3OiU443bZhezYS4RALCy7ANgZlpXBKSSJeoyyjfqgleEhrtjCvmma5eT-aDicqvRvb3lYyRKDaITGsE\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"906\" data-original-width=\"992\" height=\"240\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjl0fL9AlSfmL_cOrLANpqTQkPCmB_73o4vssLfaleX0cp5jNRqF3XZgWXjTtoEalQpdUbPsnMIFBvuG-n8MgKFJYOGnt8k_f3NwJiOIW6wKVWKq3OiU443bZhezYS4RALCy7ANgZlpXBKSSJeoyyjfqgleEhrtjCvmma5eT-aDicqvRvb3lYyRKDaITGsE\" width=\"263\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgBDL7ghXXrFbVgeMtLJWLFn6JLVnH-tn_JijNqhV3WdacJJReXBouLBdG-s3kQ5bOCJek3P-ypF9hbW2dw1Qi-YYm6uwm-fqlLJZcx9XRPrHRzuDPLmNiYQH1UnYh22iq2m31oSkZab9_9Ba5pMFTddEOVyo-NMP-DL7eGmAkdDnQzmI_E395X41drPAWx\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"348\" data-original-width=\"1636\" height=\"110\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgBDL7ghXXrFbVgeMtLJWLFn6JLVnH-tn_JijNqhV3WdacJJReXBouLBdG-s3kQ5bOCJek3P-ypF9hbW2dw1Qi-YYm6uwm-fqlLJZcx9XRPrHRzuDPLmNiYQH1UnYh22iq2m31oSkZab9_9Ba5pMFTddEOVyo-NMP-DL7eGmAkdDnQzmI_E395X41drPAWx=w516-h110\" width=\"516\" /></a></div></div><div style=\"text-align: center;\"><a href=\"https://huggingface.co/spaces/filapro/cad-recode\">Cad Recode - a Hugging Face Space by filapro</a>&nbsp;(<a href=\"https://free3d.com/3d-model/wooden-house-752597.html\" style=\"text-align: left;\">Wooden House Free 3D Model - .fbx .obj .stl - Free3D</a>)</div><div style=\"text-align: center;\"><br /></div><div style=\"text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEiYSRp-M0iOgJlAgOZq35_-Eatl3OA4UUozbtss4tMbpd8wSw6u1U0z6AyX73d3tWVEXRnTUEMPIhBc4JwPgGwy3B4QUHgtQhlJR3gXfFLiqR1r5waf7uH7jMrHSJuc_VfqaY3xVntpIX5jCw_99XvvJ_tOa1-EvT6QZ62C-iEhD2z_iyczhLN-AnOvqVgU\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"661\" data-original-width=\"1600\" height=\"132\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEiYSRp-M0iOgJlAgOZq35_-Eatl3OA4UUozbtss4tMbpd8wSw6u1U0z6AyX73d3tWVEXRnTUEMPIhBc4JwPgGwy3B4QUHgtQhlJR3gXfFLiqR1r5waf7uH7jMrHSJuc_VfqaY3xVntpIX5jCw_99XvvJ_tOa1-EvT6QZ62C-iEhD2z_iyczhLN-AnOvqVgU\" width=\"320\" /></a></div></div><div style=\"text-align: center;\"><a href=\"https://github.com/CadQuery/cadquery\">CadQuery/cadquery: A python parametric CAD scripting framework based on OCCT</a></div><div style=\"text-align: center;\"><br /></div><div style=\"text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjp_8EAYMCu5bDgjIEevmb82rhVt3x1XtjrN42ZF-dr8cT90JAsszRyP1bdd_qRdL8a5YUgeg-yjmwrD7PBSfLnMWmfsUM7OkFxaYVEQh8Gqu4ljPtZPsWJdzDwa4AO7m_sJzREb9s_qPy1bIJHt4KfPPHswQjIwd_9C7I21Ef5EwF5b6qwu1Fsqx34zAWy\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"769\" data-original-width=\"1013\" height=\"240\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjp_8EAYMCu5bDgjIEevmb82rhVt3x1XtjrN42ZF-dr8cT90JAsszRyP1bdd_qRdL8a5YUgeg-yjmwrD7PBSfLnMWmfsUM7OkFxaYVEQh8Gqu4ljPtZPsWJdzDwa4AO7m_sJzREb9s_qPy1bIJHt4KfPPHswQjIwd_9C7I21Ef5EwF5b6qwu1Fsqx34zAWy\" width=\"316\" /></a></div></div><div style=\"text-align: center;\"><a href=\"https://github.com/huggingface/diffusers\">huggingface/diffusers: 🤗 Diffusers: State-of-the-art diffusion models for image, video, and audio generation in PyTorch and FLAX.</a></div><div style=\"text-align: center;\"><br /></div><div style=\"text-align: left;\"><b>레퍼런스</b></div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><a href=\"https://www.research.autodesk.com/app/uploads/2024/05/cadllm_neurips2023_workshop-1.pdf\">CAD-LLM:Large Language Model for CAD  Generation</a></li><li><a href=\"https://www.research.autodesk.com/app/uploads/2024/05/hg-cad.pdf\">HG-CAD: Hierarchical Graph Learning for Material Prediction and Recommendation in Computer-Aided Design</a></li><li><a href=\"https://www.research.autodesk.com/app/uploads/2024/02/SolidGen_Paper.pdf\"> SolidGen: An Autoregressive Model for Direct B-rep</a></li><li><a href=\"https://github.com/krrish94/chamferdist\">Pytorch package to compute Chamfer distance between point sets (pointclouds).</a></li><li><a href=\"https://damassets.autodesk.net/content/dam/autodesk/www/pdfs/sketch-a-shape.pdf\">Sketch-A-Shape: Zero-Shot Sketch-to-3D Shape Generation</a></li><li><a href=\"https://github.com/bertjiazheng/Awesome-CAD\">A list of awesome Computer-Aided Design (CAD) papers</a></li><li><a href=\"https://github.com/samxuxiang/BrepGen\">BrepGen: [SIGGRAPH 2024] Official PyTorch Implementation of \"BrepGen: A B-rep Generative Diffusion Model with Structured Latent Geometry\"</a></li><li><a href=\"https://archive.nyu.edu/handle/2451/43778\">ABC: A Big CAD Model Dataset For Geometric Deep Learning : Faculty Digital Archive : NYU Libraries</a></li><li><a href=\"https://github.com/AutodeskAILab/occwl\">AutodeskAILab/occwl: Lightweight Pythonic wrapper around pythonocc</a></li><li><a href=\"https://dev.opencascade.org/doc/overview/html/index.html\">Open CASCADE Technology: Introduction</a></li><li><a href=\"https://arxiv.org/pdf/2411.06206\">Text2CAD: Text to 3D CAD Generation via Technical Drawings</a></li><li><a href=\"https://arxiv.org/abs/2203.13944\">SolidGen: An Autoregressive Model for Direct B-rep Synthesis</a></li><li><a href=\"https://arxiv.org/abs/2412.19663\">CAD-GPT: Synthesising CAD Construction Sequence with Spatial Reasoning-Enhanced Multimodal LLMs</a></li><li><a href=\"https://github.com/lingxiaoli94/SPFN\">SPFN: Source code for \"Supervised Fitting of Geometric Primitives to 3D Point Clouds\" [CVPR 2019]</a></li><li><a href=\"https://github.com/Hippogriff/parsenet-codebase\">parsenet-codebase: Code base of ParSeNet: ECCV 2020.</a></li><li><a href=\"https://github.com/guohaoxiang/ComplexGen\">ComplexGen: Code for SIGGRAPH 2022 paper: ComplexGen: CAD Reconstruction by B-Rep Chain Complex Generation</a></li><li><a href=\"https://manycore-research.github.io/CAD2Program/\">From 2D CAD Drawings to 3D Parametric Models: A Vision-Language Approach</a></li><li><a href=\"https://github.com/bertjiazheng/Awesome-CAD\">Awesome-CAD: 😎 A list of awesome Computer-Aided Design (CAD) papers</a></li><li><a href=\"https://github.com/MarkMoHR/Awesome-Sketch-Based-Applications\">Awesome-Sketch-Based-Applications: :books: A collection of sketch based application papers</a></li></ul></div>",
        "contentSnippet": "이 글은 CAD 모델 생성AI 및 LLM 기술을 조사한다.\n\n\nSolidGen (Autodesk)\n\n\n조사를 위해 다음 키워드로 구글링, GITHUB, 논문 검색을 수행한다. \n'CAD', 'Scketch', 'LLM', 'Generative AI', 'Transformers', 'github', 'huggingface'\n\n\n다음은 검색된 기술 결과를 보여준다. \n\n\n\nABC: A Big CAD Model Dataset For Geometric Deep Learning : Faculty Digital Archive : NYU Libraries\n\n\nBrepGen: A B-rep Generative Diffusion Model with Structured Latent Geometry\n\n\nText2CAD: Text to 3D CAD Generation via Technical Drawings\n\n\n\nDon’t Mesh with Me: Generating Constructive Solid Geometry Instead of  Meshes by Fine-Tuning a Code-Generation LLM\n\n\nCAD-GPT: Synthesising CAD Construction Sequence with Spatial  Reasoning-Enhanced Multimodal LLMs\n\n\nSPFN: Source code for \"Supervised Fitting of Geometric Primitives to 3D Point Clouds\" [CVPR 2019].\n\n\n\n\nHippogriff/parsenet-codebase: Code base of ParSeNet: ECCV 2020\n\n\n\n\n\n\n\n\n\nFrom 2D CAD Drawings to 3D Parametric Models: A Vision-Language Approach\n\n\n\nSketch-A-Shape: Zero-Shot Sketch-to-3D Shape Generation\n\n\nHG-CAD: Hierarchical Graph Learning for Material Prediction and Recommendation in Computer-Aided Design\n\n\n\n\n\nCad Recode - a Hugging Face Space by filapro (Wooden House Free 3D Model - .fbx .obj .stl - Free3D)\n\n\n\n\nCadQuery/cadquery: A python parametric CAD scripting framework based on OCCT\n\n\n\n\nhuggingface/diffusers: 🤗 Diffusers: State-of-the-art diffusion models for image, video, and audio generation in PyTorch and FLAX.\n\n\n레퍼런스\n\nCAD-LLM:Large Language Model for CAD  Generation\nHG-CAD: Hierarchical Graph Learning for Material Prediction and Recommendation in Computer-Aided Design\n SolidGen: An Autoregressive Model for Direct B-rep\nPytorch package to compute Chamfer distance between point sets (pointclouds).\nSketch-A-Shape: Zero-Shot Sketch-to-3D Shape Generation\nA list of awesome Computer-Aided Design (CAD) papers\nBrepGen: [SIGGRAPH 2024] Official PyTorch Implementation of \"BrepGen: A B-rep Generative Diffusion Model with Structured Latent Geometry\"\nABC: A Big CAD Model Dataset For Geometric Deep Learning : Faculty Digital Archive : NYU Libraries\nAutodeskAILab/occwl: Lightweight Pythonic wrapper around pythonocc\nOpen CASCADE Technology: Introduction\nText2CAD: Text to 3D CAD Generation via Technical Drawings\nSolidGen: An Autoregressive Model for Direct B-rep Synthesis\nCAD-GPT: Synthesising CAD Construction Sequence with Spatial Reasoning-Enhanced Multimodal LLMs\nSPFN: Source code for \"Supervised Fitting of Geometric Primitives to 3D Point Clouds\" [CVPR 2019]\nparsenet-codebase: Code base of ParSeNet: ECCV 2020.\nComplexGen: Code for SIGGRAPH 2022 paper: ComplexGen: CAD Reconstruction by B-Rep Chain Complex Generation\nFrom 2D CAD Drawings to 3D Parametric Models: A Vision-Language Approach\nAwesome-CAD: 😎 A list of awesome Computer-Aided Design (CAD) papers\nAwesome-Sketch-Based-Applications: :books: A collection of sketch based application papers",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-3452899801746435343",
        "isoDate": "2025-01-23T02:23:00.000Z"
      }
    ]
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권영재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김상훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "나라를 위해서 일한다는 거짓말",
        "link": "https://kangmyounghun.blogspot.com/2025/01/blog-post.html",
        "pubDate": "2025-01-22T09:05:00.002Z",
        "author": "강명훈",
        "content": "<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiLcVGNrRzaIo4NnO-rAgjNsnQMGP6qfCjqIMoW0Wx8Qulf2HazOngJA3-tzIB5J4QDtWO9PQ42kbbPeRXTd2eptfSHPD-ma4cJGUxPtGgXltA1zFC5SFhRwsf1sH4EzNYoWjSK-Gbspf_haOLYTnM-lxHNdyQD-TM82ZHMXGFy11uXozQ0fgEJG_kewuNB/s1200/XL.jpg\" style=\"clear: left; float: left; margin-bottom: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"1200\" data-original-width=\"809\" height=\"320\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiLcVGNrRzaIo4NnO-rAgjNsnQMGP6qfCjqIMoW0Wx8Qulf2HazOngJA3-tzIB5J4QDtWO9PQ42kbbPeRXTd2eptfSHPD-ma4cJGUxPtGgXltA1zFC5SFhRwsf1sH4EzNYoWjSK-Gbspf_haOLYTnM-lxHNdyQD-TM82ZHMXGFy11uXozQ0fgEJG_kewuNB/s320/XL.jpg\" width=\"216\" /></a></div>\n<div>노한동 문체부 전 서기관이 10년 공직 경험을 바탕으로 쓴 자전 에세이.</div>\n<div><br /></div>\n<div>전도유망한 30대 서기관이 공직을 그만두고 책을 쓴 이유는 무엇일까? 저자는 그 이유를 '헛짓거리', '가짜 노동', '쓸데없는 일' 세 단어로 고백한다.</div>\n<div><blockquote style=\"text-align: center;\"><i>공직사회의 일이란 그저 관습에 따르거나 기관장을 빛내기 위한 거대한 비효율의 반복</i> <span style=\"font-size: x-small;\">(83페이지)</span></blockquote></div>\n<div><blockquote style=\"text-align: center;\"><i>진짜 필요한 일이 아닌 헛짓거리에 자신의 인생을 갈아 넣으며 느끼는 공무원들의 자괴감</i> <span style=\"font-size: x-small;\">(188페이지)</span></blockquote></div>\n<div><blockquote style=\"text-align: center;\"><i>공직사회는 일을 못한다. 관료가 게을러서도, 철밥통이어서도 아니다. 그저 쓸데없는 일이 너무 많아서다</i> <span style=\"font-size: x-small;\">(274페이지)</span></blockquote></div>\n<div><br /></div>\n<div>누가 그랬다. 노동 없는 삶은 부패하지만 영혼 없는 노동은 삶을 질식시킨다고.&nbsp;</div>\n<div><br /></div><span><a name='more'></a></span>\n<div><b><span style=\"font-size: x-large;\">짧디 짧은 1년 반의 공직 시절이 떠올랐다&nbsp;</span></b></div>\n<div><br /></div>\n<div>모 부처 소속기관에서 4년 반을 일했다. 3년은 민간인으로, 1년 반은 공무원으로. 보안장비 룰 정확도 개선을 목표로 3년을 노력했지만 쉽지 않았다. 공무원은 과거 어떤 사업자도 언급하지 않던 업무의 필요성을 이해하지 못했고, 그런 업무를 시도하는 나도 이해하지 못했다.</div><div><br /></div><div><span></span></div><div>그래서 그만 두고 책을 썼다. 이후 해당 기관의 5급 계약직 채용 공고를 보게 됐을 때 살짝 설렜다. 민간인 신분으로 일할 당시 접했던 실무 최고 책임자가 사무관이었기 때문에 채용되면 소신을 가지고 주도적으로 일할 수 있겠다는 생각이 들었던 것.</div><div><br /></div><div>물론 현실은 달랐다. 잠시 룰 정확도에&nbsp;관심을 주던 기관장은 이내 성과 어필에 더 유리한 빅데이터로 관심을 돌렸다. 솔직히 입장 바뀌면 나라도 그랬지 싶다. 당시 그만큼 핫한 아이템은 없었으니까.</div><div><blockquote style=\"text-align: center;\"><i><a href=\"https://kangmyounghun.blogspot.com/2018/07/blog-post_17.html\" target=\"_blank\">사람들은 포르쉐를 부러워하지, 운전 실력을 부러워하지 않는다. 자본주의 세상에서 비싼 포르쉐는 성공의 상징이기 때문. 비슷한 연유로 빅데이터나 인공지능같은 최신&nbsp;미국 기술은 정보보안, 나아가 IT 분야의 포르쉐가 된다.</a></i></blockquote></div>\n  <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh-3f3B1_Qr88QWfol8Nvy7yRYsvs7DE9w25mqPu7b-aT93AYtYbX5MX_57wXCW_IDAefjZiDrNNVcusIhpjtRPEKp9qWlcE5-3RxELLYi8vezOdDRIO1k1EhTUmdurTLs8tcIpyszbU9N3UOaPpro9Wjge431smxLwAPiEXIsoq7Z1m49aWxZqYGcPuBl5/s1280/before.png\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"487\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh-3f3B1_Qr88QWfol8Nvy7yRYsvs7DE9w25mqPu7b-aT93AYtYbX5MX_57wXCW_IDAefjZiDrNNVcusIhpjtRPEKp9qWlcE5-3RxELLYi8vezOdDRIO1k1EhTUmdurTLs8tcIpyszbU9N3UOaPpro9Wjge431smxLwAPiEXIsoq7Z1m49aWxZqYGcPuBl5/s16000/before.png\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><b>보안 수준 향상이 최우선 과제였던 빅데이터</b></td></tr></tbody></table><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhPPaWBDWwdp1nudsv8l7h-ljprehmBQvIuGXAiKlnYpTG2xXhU8L42mlt5D6ab74OI4kwEav4HEmxFqLWW7FmimYd_SnFBqo5YI9xuTvgM3pF94d3OwJ8DUJktygWXvMX08yOyW520e6fJiw0MtO5RJ1Jc7zmHSjGmbRws8WlGcVFH0UGtCkSNbhCQb0ox/s1280/after.png\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"485\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhPPaWBDWwdp1nudsv8l7h-ljprehmBQvIuGXAiKlnYpTG2xXhU8L42mlt5D6ab74OI4kwEav4HEmxFqLWW7FmimYd_SnFBqo5YI9xuTvgM3pF94d3OwJ8DUJktygWXvMX08yOyW520e6fJiw0MtO5RJ1Jc7zmHSjGmbRws8WlGcVFH0UGtCkSNbhCQb0ox/s16000/after.png\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><b>4년 간의 빅데이터 운영 결과</b></td></tr></tbody></table><div><br /></div><div>그래도 첫 1년 정도는 나름 보람있었다. 룰 정확도 개선 업무를 사무관 권한으로&nbsp;진행할 수 있었고, 기존 대비 분석 업무 범위 50% 확대라는 결과를 얻었기 때문. 아쉬운 점은 해당 업무가 메인이 아니었다는 것. 메인으로 진행했으면 더 나은 결과를 얻을 수도 있었다는 얘기.</div><div><br /></div><div><b><span style=\"font-size: x-large;\">진짜 메인은?</span></b></div><div><br /></div><div>원금 보장도 쉽지 않은 보험 시장은 사고, 질병 등의 공포를 먹고 성장한다. 보안 시장도 비슷. 그래서 업계와 공생 관계인 보안 업계지는 끊임없이 보안 위협 기사를 쏟아낸다. 기관장은 그런 업계지를 탐독했고, 관련 기사가 나올 때마다 내게 대책 마련을 지시했다.</div><div><br /></div><div>물론 그런 기사들이 도움이 될 때도 있다. 하지만 대부분은 일회성으로 끝나는, 정보보호체계를 큰 틀의 방향성 없이 그때그때 외부 정보에 휘둘리게 만드는, 공만 쫓아 우르르 몰려다니는 동네 축구 수준으로 전락시키는 이벤트성 업무일 뿐이었다.</div><div><br /></div><div>하지만 중요한 건 기관장의 성취감이 충족됐다는 것. 숱하게 실시되는 비상근무와 훈련 역시 기관장과 본부가 원하는, 불철주야 경계에 만전을 기하고 있다는 그림을 보여주기 위함이 최우선이었다.</div><div><blockquote style=\"text-align: center;\"><i><a href=\"https://kangmyounghun.blogspot.com/2020/06/blog-post.html\" target=\"_blank\">내가 제일 많이 기획했던 업무는 '비상근무'였다. 연말이니까 비상근무, 명절이니까 비상근무, 선거철이니까 비상근무. 그 다음은 훈련</a></i></blockquote></div><div><br /></div><div>장비 구축부터 운영까지 3년을 구른 현장에 대한 애착과 이루고 싶은 목표가 있었기에 기회 있을 때마다 룰 정확도 개선에 대한 소신을 기관장에게 피력하며 효율적인 업무를 꾀했지만 '나는 옳고, 너는 따라야한다'는 기조는 바뀌지 않았다.&nbsp;</div><div><br /></div><div>왜 룰 개선보다 상사 안심시키는 업무에 더 많은 시간을 할애해야 할까? 민간의 전문성을 활용하겠다며 뽑아놓고 왜 자신들이 인정한 전문가의 말을 듣지 않는 것일까? 회의감이 점점 커지는 와중에 세 번째 서기관을 모시게 됐다.</div><div><br /></div><div>국가직은 지방직 대비 상대적으로 민원 스트레스가 덜하지만 24시간 보안 이벤트에 대응해야 하는 정보보호 부서는 예외. 24시간 내내 민원이 쏟아지는 상황과 비슷하다고 보면 된다.</div><div></div><div style=\"text-align: center;\"><blockquote><i><a href=\"https://kangmyounghun.blogspot.com/2015/02/cxo.html\" target=\"_blank\">보안 업무는 운영성이 많아서 '잡일성 ' 업무가 많다. 눈에 잘 띄지 않더라도 꼭 필요한 일을 했다면 그것을 업무 성과로 인정해야 한다</a></i>&nbsp;-<span style=\"font-size: x-small;\">&nbsp;CxO가 알아야할 정보보안</span></blockquote></div><div><br /></div><div>한마디로 티는 안 나고 몸만 축나는 업무가 많다. 민간이든 공공이든 그런 부서로의 발령은 누구도 반기지 않는다. 당연히 발령받은 서기관들은 최선을 다해 보직 변경을 시도했다.&nbsp;1년 반 동안 세 명의 서기관을 모시게 된 이유.&nbsp;<span style=\"font-size: x-small;\">(도망 못가게 요샌 서기관도 민간 경력자로 채우는 듯)</span></div><div><br /></div><div>그런데 세 번째 서기관은 이전 상사들과 좀 달랐다. 모든 업무를 '새마을 운동'하듯 더 많이, 더 오래, 더 열심히 하려는 노력파였고, 그렇게 하면 다 통한다고 생각했다.</div><div><div><blockquote style=\"text-align: center;\"><i><a href=\"https://kangmyounghun.blogspot.com/2024/02/blog-post.html\" target=\"_blank\">업무를 이해하지 못하는 행정 계층이 자기가 아는 정도만 가지고, 그리고 일반적인 감시, 계량의 수단만 가지고 부처를 운영</a></i><i>&nbsp;-</i><span style=\"font-size: x-small;\">&nbsp;</span><span style=\"font-size: x-small;\">가짜 노동</span></blockquote></div><div><span style=\"font-size: x-small;\"><br /></span></div><div>시작은 새해 업무 보고였다. 불필요한 업무를 줄이려는 나는 업무 가짓수를 하나라도 더 늘리려는 서기관과 충돌했고, 이후 그의 눈엣가시가 됐다. 처음엔 나를 업무에서 배제시키려고 했다. 하지만 기관장이 나를 계속 호출하는 바람에 실패.&nbsp;</div></div><div><br /></div><div>몇달 후 아이핀 부정 발급 사건이 터졌다. 팀원들과 함께 며칠 간 사무실에 남아 분석 보고서를 작성했고, 책임 소재 규명으로부터 안전함을 확인한 기관장은 취약점 점검을 강화하라는 지시를 내리며 그렇게 마무리되나 싶었다.</div><div><br /></div><div>그런데 서기관은 타팀 소관인 취약점 점검 업무를 내게 지시하려 했다. 소관 업무가 다름을 지적하니 업무분장을 바꾸겠다로 응수하는 모습이 일을 뺏지 못하면 아예 일에 파묻히게 해주겠다 단단히 결심한 모양새였다.&nbsp;</div><div><br /></div><div>그리고 여세를 몰아 전직원의 주말 출근 지시. 사고 핑계를 댔지만 결국 나 하나 잡겠다는 의도가 너무 뻔한 상황에서, 나 때문에 피해보는 직원들에게 미안했다. 그래서 사직서를 제출했고, 1년 반의 공직 생활은 그렇게 끝이 났다.</div><div><br /></div><div>이런 공직사회 속에서 10년 동안 공무원<span style=\"font-size: x-small;\">(公務員)</span>&nbsp;본연의 역할에 충실하기 위해 노력한 저자의 고뇌가 얼마나 컸을지 쉽게 짐작이 가지 않는다. 어떻게 하면 저자의 바람대로 공직사회에 대한 혁신이 이루어질 수 있을까?</div><div><br /></div><div><b><span style=\"font-size: x-large;\">가짜 노동</span></b></div><div><br /></div><div>내가 경험한 공직사회는 상사의 업적을 위해 5급 이하 전 공무원이 헌신하는 문화가 지배하는 세상이었다. 모두가 리더만을 바라보는 세상에서 리더의 올바른 목표 설정은 필수. 그릇된 목표를 위해 실행되는 어떤 업무도 그릇되고 쓸데없는 일, 가짜 노동으로 전락할 수 있기 때문이다.</div><div><br /></div><div>돈을 벌어야 하는 민간은 돈 안 되는 쓸데없는 일, 가짜 노동을 스스로 쳐내는 경향이 있다. 세금을 써야 하는 공공은 쓴만큼 티가 나야 해서 효율보다 명분과 홍보에 매달리기 쉽다. 비효율에 대한 자정 작용이 힘든 이유. 이런 상황에서 전문성까지 없다면?</div><div><br /></div><div>기관장이 빅데이터를 선택한 이유는 실/국장, 장차관에게 관련 전문성이 없어서, '유명한 미국 기술'이라는 명분만으로 인정받을 가능성이 높아서였고, 노력파 서기관이 업무 가짓수를 하나라도 더 늘리려던 이유는 분야 특성을 모르는 채, 과거 업무 방식을 답습해서였다.&nbsp;&nbsp;</div><div><div><blockquote style=\"text-align: center;\"><i>1980년대에 미군은 군사계획 절차를 수정하고</i>&nbsp;<span style=\"font-size: x-small;\">(바람직한 최종 상태를 의미하는)</span>&nbsp;<i>'지휘관의 의도 '라는 신개념을 도입</i><i>했다...&nbsp;</i><i>지휘관의 의도는 직속 상사로부터 상세한 지시가 없다 하더라도 모든 계급의 병사들이 행동을 취할 수 있도록 해준다. 최종 목적지를 알고 있다면 어떤 수단을 취하든 거기 닿기만 하면 될 일</i><span style=\"text-align: left;\">&nbsp;-&nbsp;<span style=\"font-size: x-small;\">스틱</span></span></blockquote><div><span style=\"font-size: x-small;\"><br /></span></div><span style=\"font-size: x-small;\"></span></div><div>결국 리더의 의도가 올바를 때 의미 있는 업무 결과로 이어질 가능성이 높아지고, 조직 구성원이 진짜 쓸모 있음의 가치를 발견할 때 가짜 노동은 사라진다. 올바른 의도를 가지기 위해 필요한 것이 전문성. 알아야 옳다 그르다를 판단하지. 그래서 저자의 제안은 매우 적절하다.</div></div><div><div><blockquote style=\"text-align: center;\"><i>일반직 공무원도 원하는 경우 한 분야에서 장기간 계속 근무하는 것을 허용하는 것</i> <span style=\"font-size: x-small;\">(240페이지)</span></blockquote></div><div><br /></div></div><div>한 분야에 머무르며 전문성을 갖춘 관료가 늘어나고, 이들이 올바른 의도를 가진 리더로 성장한다면 국민의 인정을 받는 공직사회, 나라를 위해서 일한다 말할 수 있는 공직사회 실현이 현실로 다가오는 날이 분명 올 것이다.</div><div><br /></div><div>문제를 해결하고 싶다면 먼저 문제를 인정해야 한다. 그래서 자정 작용의 첫걸음을 알리는 이 책의 의미는 대단히 크다. 10년을 몸 담은 조직에 대한 애정 어린 고언을 결심한 저자의 용기에 박수를 보낸다.</div>",
        "contentSnippet": "노한동 문체부 전 서기관이 10년 공직 경험을 바탕으로 쓴 자전 에세이.\n\n전도유망한 30대 서기관이 공직을 그만두고 책을 쓴 이유는 무엇일까? 저자는 그 이유를 '헛짓거리', '가짜 노동', '쓸데없는 일' 세 단어로 고백한다.\n공직사회의 일이란 그저 관습에 따르거나 기관장을 빛내기 위한 거대한 비효율의 반복 (83페이지)\n\n\n진짜 필요한 일이 아닌 헛짓거리에 자신의 인생을 갈아 넣으며 느끼는 공무원들의 자괴감 (188페이지)\n\n\n공직사회는 일을 못한다. 관료가 게을러서도, 철밥통이어서도 아니다. 그저 쓸데없는 일이 너무 많아서다 (274페이지)\n\n\n\n누가 그랬다. 노동 없는 삶은 부패하지만 영혼 없는 노동은 삶을 질식시킨다고. \n\n\n짧디 짧은 1년 반의 공직 시절이 떠올랐다 \n\n모 부처 소속기관에서 4년 반을 일했다. 3년은 민간인으로, 1년 반은 공무원으로. 보안장비 룰 정확도 개선을 목표로 3년을 노력했지만 쉽지 않았다. 공무원은 과거 어떤 사업자도 언급하지 않던 업무의 필요성을 이해하지 못했고, 그런 업무를 시도하는 나도 이해하지 못했다.\n\n\n\n그래서 그만 두고 책을 썼다. 이후 해당 기관의 5급 계약직 채용 공고를 보게 됐을 때 살짝 설렜다. 민간인 신분으로 일할 당시 접했던 실무 최고 책임자가 사무관이었기 때문에 채용되면 소신을 가지고 주도적으로 일할 수 있겠다는 생각이 들었던 것.\n\n\n물론 현실은 달랐다. 잠시 룰 정확도에 관심을 주던 기관장은 이내 성과 어필에 더 유리한 빅데이터로 관심을 돌렸다. 솔직히 입장 바뀌면 나라도 그랬지 싶다. 당시 그만큼 핫한 아이템은 없었으니까.\n\n사람들은 포르쉐를 부러워하지, 운전 실력을 부러워하지 않는다. 자본주의 세상에서 비싼 포르쉐는 성공의 상징이기 때문. 비슷한 연유로 빅데이터나 인공지능같은 최신 미국 기술은 정보보안, 나아가 IT 분야의 포르쉐가 된다.\n\n  \n\n\n보안 수준 향상이 최우선 과제였던 빅데이터\n\n\n\n4년 간의 빅데이터 운영 결과\n\n\n\n그래도 첫 1년 정도는 나름 보람있었다. 룰 정확도 개선 업무를 사무관 권한으로 진행할 수 있었고, 기존 대비 분석 업무 범위 50% 확대라는 결과를 얻었기 때문. 아쉬운 점은 해당 업무가 메인이 아니었다는 것. 메인으로 진행했으면 더 나은 결과를 얻을 수도 있었다는 얘기.\n\n\n진짜 메인은?\n\n\n원금 보장도 쉽지 않은 보험 시장은 사고, 질병 등의 공포를 먹고 성장한다. 보안 시장도 비슷. 그래서 업계와 공생 관계인 보안 업계지는 끊임없이 보안 위협 기사를 쏟아낸다. 기관장은 그런 업계지를 탐독했고, 관련 기사가 나올 때마다 내게 대책 마련을 지시했다.\n\n\n물론 그런 기사들이 도움이 될 때도 있다. 하지만 대부분은 일회성으로 끝나는, 정보보호체계를 큰 틀의 방향성 없이 그때그때 외부 정보에 휘둘리게 만드는, 공만 쫓아 우르르 몰려다니는 동네 축구 수준으로 전락시키는 이벤트성 업무일 뿐이었다.\n\n\n하지만 중요한 건 기관장의 성취감이 충족됐다는 것. 숱하게 실시되는 비상근무와 훈련 역시 기관장과 본부가 원하는, 불철주야 경계에 만전을 기하고 있다는 그림을 보여주기 위함이 최우선이었다.\n\n내가 제일 많이 기획했던 업무는 '비상근무'였다. 연말이니까 비상근무, 명절이니까 비상근무, 선거철이니까 비상근무. 그 다음은 훈련\n\n\n장비 구축부터 운영까지 3년을 구른 현장에 대한 애착과 이루고 싶은 목표가 있었기에 기회 있을 때마다 룰 정확도 개선에 대한 소신을 기관장에게 피력하며 효율적인 업무를 꾀했지만 '나는 옳고, 너는 따라야한다'는 기조는 바뀌지 않았다. \n\n\n왜 룰 개선보다 상사 안심시키는 업무에 더 많은 시간을 할애해야 할까? 민간의 전문성을 활용하겠다며 뽑아놓고 왜 자신들이 인정한 전문가의 말을 듣지 않는 것일까? 회의감이 점점 커지는 와중에 세 번째 서기관을 모시게 됐다.\n\n\n국가직은 지방직 대비 상대적으로 민원 스트레스가 덜하지만 24시간 보안 이벤트에 대응해야 하는 정보보호 부서는 예외. 24시간 내내 민원이 쏟아지는 상황과 비슷하다고 보면 된다.\n\n\n보안 업무는 운영성이 많아서 '잡일성 ' 업무가 많다. 눈에 잘 띄지 않더라도 꼭 필요한 일을 했다면 그것을 업무 성과로 인정해야 한다 - CxO가 알아야할 정보보안\n\n\n한마디로 티는 안 나고 몸만 축나는 업무가 많다. 민간이든 공공이든 그런 부서로의 발령은 누구도 반기지 않는다. 당연히 발령받은 서기관들은 최선을 다해 보직 변경을 시도했다. 1년 반 동안 세 명의 서기관을 모시게 된 이유. (도망 못가게 요샌 서기관도 민간 경력자로 채우는 듯)\n\n\n그런데 세 번째 서기관은 이전 상사들과 좀 달랐다. 모든 업무를 '새마을 운동'하듯 더 많이, 더 오래, 더 열심히 하려는 노력파였고, 그렇게 하면 다 통한다고 생각했다.\n\n업무를 이해하지 못하는 행정 계층이 자기가 아는 정도만 가지고, 그리고 일반적인 감시, 계량의 수단만 가지고 부처를 운영 - 가짜 노동\n\n\n\n시작은 새해 업무 보고였다. 불필요한 업무를 줄이려는 나는 업무 가짓수를 하나라도 더 늘리려는 서기관과 충돌했고, 이후 그의 눈엣가시가 됐다. 처음엔 나를 업무에서 배제시키려고 했다. 하지만 기관장이 나를 계속 호출하는 바람에 실패. \n\n\n몇달 후 아이핀 부정 발급 사건이 터졌다. 팀원들과 함께 며칠 간 사무실에 남아 분석 보고서를 작성했고, 책임 소재 규명으로부터 안전함을 확인한 기관장은 취약점 점검을 강화하라는 지시를 내리며 그렇게 마무리되나 싶었다.\n\n\n그런데 서기관은 타팀 소관인 취약점 점검 업무를 내게 지시하려 했다. 소관 업무가 다름을 지적하니 업무분장을 바꾸겠다로 응수하는 모습이 일을 뺏지 못하면 아예 일에 파묻히게 해주겠다 단단히 결심한 모양새였다. \n\n\n그리고 여세를 몰아 전직원의 주말 출근 지시. 사고 핑계를 댔지만 결국 나 하나 잡겠다는 의도가 너무 뻔한 상황에서, 나 때문에 피해보는 직원들에게 미안했다. 그래서 사직서를 제출했고, 1년 반의 공직 생활은 그렇게 끝이 났다.\n\n\n이런 공직사회 속에서 10년 동안 공무원(公務員) 본연의 역할에 충실하기 위해 노력한 저자의 고뇌가 얼마나 컸을지 쉽게 짐작이 가지 않는다. 어떻게 하면 저자의 바람대로 공직사회에 대한 혁신이 이루어질 수 있을까?\n\n\n가짜 노동\n\n\n내가 경험한 공직사회는 상사의 업적을 위해 5급 이하 전 공무원이 헌신하는 문화가 지배하는 세상이었다. 모두가 리더만을 바라보는 세상에서 리더의 올바른 목표 설정은 필수. 그릇된 목표를 위해 실행되는 어떤 업무도 그릇되고 쓸데없는 일, 가짜 노동으로 전락할 수 있기 때문이다.\n\n\n돈을 벌어야 하는 민간은 돈 안 되는 쓸데없는 일, 가짜 노동을 스스로 쳐내는 경향이 있다. 세금을 써야 하는 공공은 쓴만큼 티가 나야 해서 효율보다 명분과 홍보에 매달리기 쉽다. 비효율에 대한 자정 작용이 힘든 이유. 이런 상황에서 전문성까지 없다면?\n\n\n기관장이 빅데이터를 선택한 이유는 실/국장, 장차관에게 관련 전문성이 없어서, '유명한 미국 기술'이라는 명분만으로 인정받을 가능성이 높아서였고, 노력파 서기관이 업무 가짓수를 하나라도 더 늘리려던 이유는 분야 특성을 모르는 채, 과거 업무 방식을 답습해서였다.  \n\n1980년대에 미군은 군사계획 절차를 수정하고 (바람직한 최종 상태를 의미하는) '지휘관의 의도 '라는 신개념을 도입했다... 지휘관의 의도는 직속 상사로부터 상세한 지시가 없다 하더라도 모든 계급의 병사들이 행동을 취할 수 있도록 해준다. 최종 목적지를 알고 있다면 어떤 수단을 취하든 거기 닿기만 하면 될 일 - 스틱\n\n\n\n결국 리더의 의도가 올바를 때 의미 있는 업무 결과로 이어질 가능성이 높아지고, 조직 구성원이 진짜 쓸모 있음의 가치를 발견할 때 가짜 노동은 사라진다. 올바른 의도를 가지기 위해 필요한 것이 전문성. 알아야 옳다 그르다를 판단하지. 그래서 저자의 제안은 매우 적절하다.\n\n\n일반직 공무원도 원하는 경우 한 분야에서 장기간 계속 근무하는 것을 허용하는 것 (240페이지)\n\n\n\n한 분야에 머무르며 전문성을 갖춘 관료가 늘어나고, 이들이 올바른 의도를 가진 리더로 성장한다면 국민의 인정을 받는 공직사회, 나라를 위해서 일한다 말할 수 있는 공직사회 실현이 현실로 다가오는 날이 분명 올 것이다.\n\n\n문제를 해결하고 싶다면 먼저 문제를 인정해야 한다. 그래서 자정 작용의 첫걸음을 알리는 이 책의 의미는 대단히 크다. 10년을 몸 담은 조직에 대한 애정 어린 고언을 결심한 저자의 용기에 박수를 보낸다.",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-97983325123962663",
        "isoDate": "2025-01-22T09:05:00.002Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕홍",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": [
      {
        "creator": "고명환",
        "title": "희망리턴패키지 사업계획서 작성 방법 및 사례 2 - 소상공인",
        "link": "https://brunch.co.kr/@@LOc/261",
        "pubDate": "Fri, 24 Jan 2025 01:46:57 GMT",
        "author": "고명환",
        "content": "희망리턴패키지 사업은 소상공인의 재창업 및 경영개선을 위한 사업으로 소상공인과 관련된 정부지원사업 중 가장 많은 사업화 자금이 지원됩니다. 소상공인 분들이 평소에 사업계획서를 작성할 일이 없어서 신청에 애로사항이 있기 때문에 이를 조금이나마 도움을 드리고자 사례를 들여서 작성 방법을 설명드리겠습니다. 2번째 목차를 설명하는 포스팅으로 이 전에 포스팅을 먼저<img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FZYLUskkbBOUvz7rmTRqb7mn4e_Y.jpg\" width=\"500\" />",
        "contentSnippet": "희망리턴패키지 사업은 소상공인의 재창업 및 경영개선을 위한 사업으로 소상공인과 관련된 정부지원사업 중 가장 많은 사업화 자금이 지원됩니다. 소상공인 분들이 평소에 사업계획서를 작성할 일이 없어서 신청에 애로사항이 있기 때문에 이를 조금이나마 도움을 드리고자 사례를 들여서 작성 방법을 설명드리겠습니다. 2번째 목차를 설명하는 포스팅으로 이 전에 포스팅을 먼저",
        "guid": "https://brunch.co.kr/@@LOc/261",
        "isoDate": "2025-01-24T01:46:57.000Z"
      },
      {
        "creator": "고명환",
        "title": "희망리턴패키지 사업계획서 작성 방법 및 사례 1 - 소상공인",
        "link": "https://brunch.co.kr/@@LOc/260",
        "pubDate": "Tue, 21 Jan 2025 04:41:12 GMT",
        "author": "고명환",
        "content": "희망리턴패키지 사업은 소상공인의 재창업 및 경영개선을 위한 사업으로 소상공인과 관련된 정부지원사업 중 가장 많은 사업화 자금이 지원됩니다. 소상공인 분들이 평소에 사업계획서를 작성할 일이 없어서 신청에 애로사항이 있기 때문에 이를 조금이나마 도움을 드리고자 사례를 들여서 작성 방법을 설명드리겠습니다.   https://www.sbiz.or.kr/sup/ma<img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FhLzDtxsW_25jtWNdD20tnwJ8AOA.jpg\" width=\"500\" />",
        "contentSnippet": "희망리턴패키지 사업은 소상공인의 재창업 및 경영개선을 위한 사업으로 소상공인과 관련된 정부지원사업 중 가장 많은 사업화 자금이 지원됩니다. 소상공인 분들이 평소에 사업계획서를 작성할 일이 없어서 신청에 애로사항이 있기 때문에 이를 조금이나마 도움을 드리고자 사례를 들여서 작성 방법을 설명드리겠습니다.   https://www.sbiz.or.kr/sup/ma",
        "guid": "https://brunch.co.kr/@@LOc/260",
        "isoDate": "2025-01-21T04:41:12.000Z"
      },
      {
        "creator": "고명환",
        "title": "스타트업의 R&amp;D 과제 수행 시 자주하는 실수 5가지 - 스타트업",
        "link": "https://brunch.co.kr/@@LOc/259",
        "pubDate": "Mon, 20 Jan 2025 01:48:48 GMT",
        "author": "고명환",
        "content": "스타트업이 R&amp;D 지원사업에 처음 도전할 때, 많은 시행착오를 겪는 경우가 많습니다. 특히, 예비창업패키지, 청년창업사관학교와 같은 사업과 혼돈해 R&amp;D 지원사업을 진행하는 경우가 많은 데 성격이 매우 다른 사업인만큼 과제를 성공적으로 수행하기 위해서는 주요 실수를 미리 파악하고 방지하는 것이 중요합니다.   1. 목표 설정의 불명확성  1) 실수  많은 <img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FI-s08aVvuHE4UdXIoQRfZftRAIc.jpg\" width=\"500\" />",
        "contentSnippet": "스타트업이 R&D 지원사업에 처음 도전할 때, 많은 시행착오를 겪는 경우가 많습니다. 특히, 예비창업패키지, 청년창업사관학교와 같은 사업과 혼돈해 R&D 지원사업을 진행하는 경우가 많은 데 성격이 매우 다른 사업인만큼 과제를 성공적으로 수행하기 위해서는 주요 실수를 미리 파악하고 방지하는 것이 중요합니다.   1. 목표 설정의 불명확성  1) 실수  많은",
        "guid": "https://brunch.co.kr/@@LOc/259",
        "isoDate": "2025-01-20T01:48:48.000Z"
      }
    ]
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김놀부",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "구글 검색 노출 감소, AI 콘텐츠 홍수 속에서 살아남는 법",
        "link": "https://muzbox.tistory.com/483529",
        "pubDate": "Wed, 22 Jan 2025 14:50:49 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "https://muzbox.tistory.com/483529#entry483529comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;구글 검색에서 블로그가 예전처럼 잘 안 보이나요? AI 콘텐츠 홍수 속에서도 끈질기게 살아남을 수 있는 SEO 최적화 전략과 E-E-A-T 강화 방법을 소개합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"내가-쓴글이-노출이-안되는-이유.webp\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/ctqrKG/btsLVfxEAmm/R7OSKlbBvnmZKtxmTfgk9k/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/ctqrKG/btsLVfxEAmm/R7OSKlbBvnmZKtxmTfgk9k/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/ctqrKG/btsLVfxEAmm/R7OSKlbBvnmZKtxmTfgk9k/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FctqrKG%2FbtsLVfxEAmm%2FR7OSKlbBvnmZKtxmTfgk9k%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"구글 검색 노출 감소, AI 콘텐츠 홍수 속에서 살아남는 법\" loading=\"lazy\" width=\"700\" height=\"382\" data-filename=\"내가-쓴글이-노출이-안되는-이유.webp\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;요즘 블로그 글을 올려도 예전처럼 구글에서 잘 보이지 않는다고 느끼신 적 있나요? 저도 같은 고민을 했어요. 아무리 공들여서 글을 써도 검색 상위에 노출되기는커녕 방문자 수도 줄어드는 것 같더라고요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이유는 간단해요. AI 기술 덕분에 콘텐츠가 넘쳐나고, 구글도 검색 품질을 유지하려고 알고리즘을 계속 바꾸고 있거든요. 예전처럼 단순히 키워드만 잘 넣어서 해결할 수 있는 시대는 끝났고, 이제는 **E-E-A-T(경험, 전문성, 권위성, 신뢰성)**이 필수적인 요소가 됐어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">그럼 어떻게 해야 블로그가 살아남을 수 있을까요? 제가 직접 시행착오를 겪으며 찾은 해결책을 공유해볼게요!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>  구글 검색 노출이 어려워진 이유</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">1.   구글 알고리즘 업데이트의 영향</span></h3>\n<p data-ke-size=\"size16\">구글은 검색 결과의 신뢰도를 높이기 위해 알고리즘을 계속 개선하고 있어요. 특히 요즘은 다음 요소들이 중요해졌어요.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>E-E-A-T 요소 강화:</b><br />구글은 사용자가 믿을 수 있는 정보를 원한다는 걸 잘 알고 있어요. 그래서 건강, 금융 같은 중요한 분야(YMYL)에서는 전문가가 작성한 신뢰성 있는 콘텐츠를 우선적으로 보여주고 있어요.</li>\n<li><b>사용자 경험(UX)의 중요성:</b><br />페이지 로딩이 느리거나 모바일에서 불편하면 방문자가 바로 나가버리죠. 구글은 이런 사이트를 좋아하지 않아요. 속도와 가독성이 중요한 이유예요.</li>\n<li><b>콘텐츠 품질 평가:</b><br />단순한 정보 나열로는 부족해요. 구체적인 사례와 심층 분석이 담긴 콘텐츠가 더 높은 평가를 받아요.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">2.   색인(Indexing) 문제</span></h3>\n<p data-ke-size=\"size16\">구글에 내 글이 제대로 색인되지 않으면 아무리 좋은 글도 검색 결과에 나오지 않아요. 다음을 체크해 보세요.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>robots.txt 설정 확인:</b> 혹시 크롤러가 내 사이트를 막고 있지는 않은지?</li>\n<li><b>사이트맵 제출:</b> Google Search Console에서 사이트맵을 등록했는지 확인해보세요.</li>\n<li><b>색인 요청:</b> 특정 페이지가 검색에 안 잡힌다면 직접 요청을 해보는 것도 방법이에요.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">3.   AI 콘텐츠 필터링 기술 강화</span></h3>\n<p data-ke-size=\"size16\">요즘 AI로 생성된 콘텐츠가 넘쳐나면서, 구글도 이를 감지하기 위해 노력하고 있어요. 자동 생성된 콘텐츠라도 품질이 낮다면 순위가 내려갈 수밖에 없죠.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">4.   경쟁 심화</span></h3>\n<p data-ke-size=\"size16\">예전에는 특정 키워드를 잡고 꾸준히 글을 쓰면 상위권이 가능했는데, 이제는 누구나 AI를 활용해서 콘텐츠를 쉽게 만들 수 있는 시대가 됐어요. 그렇다 보니 더 창의적이고 차별화된 콘텐츠가 필요해요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>  AI 시대, 효과적인 콘텐츠 제작 전략</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">1.   E-E-A-T 요소 강화하기</span></h3>\n<p data-ke-size=\"size16\">블로그에 신뢰도를 높이려면 이렇게 해보세요.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>실제 경험담 공유:</b> 사용해본 제품의 리얼 리뷰를 담으면 신뢰도가 높아져요.</li>\n<li><b>전문가 의견 추가:</b> 해당 분야의 전문가 인터뷰나 공신력 있는 자료를 인용해 보세요.</li>\n<li><b>독창적인 시각 제공:</b> 다른 블로그에서 볼 수 없는 나만의 인사이트를 더해보세요.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">2. ✍️ 효과적인 프롬프트 작성</span></h3>\n<p data-ke-size=\"size16\">AI를 사용할 때 프롬프트(명령어)를 잘 주는 게 중요해요. 예를 들면:</p>\n<p data-ke-size=\"size16\">\"2024년 블로그 SEO 트렌드를 심층 분석해줘. 구글 알고리즘 변화와 사용자 경험, E-E-A-T 적용 방안 중심으로 작성해줘.\"</p>\n<p data-ke-size=\"size16\">이렇게 구체적으로 요청할수록 더 좋은 결과가 나오더라고요.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">3.   AI 콘텐츠 검토 및 보완</span></h3>\n<p data-ke-size=\"size16\">AI가 글을 쓴다고 해서 그대로 올리면 안 돼요. 꼭 다음을 확인하세요.</p>\n<script async src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8195497734535830\"\n     crossorigin=\"anonymous\"></script>\n<ins class=\"adsbygoogle\"\n     style=\"display:block; text-align:center;\"\n     data-ad-layout=\"in-article\"\n     data-ad-format=\"fluid\"\n     data-ad-client=\"ca-pub-8195497734535830\"\n     data-ad-slot=\"1494233468\"></ins>\n<script>\n     (adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<center><figure id=\"og_1737524035750\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"AI 가 만든 글에 사람의 향기를, 무료 GTPS - 인간냄새\" data-og-description=\"사람 냄새 나는 AI 글쓰기, 어떻게 가능할까요? 제가 만든 챗봇, GPTS가 바로 그 답입니다! 자연스럽고 공감 가는 글을 만드는 비법을 지금 확인해 보세요.&nbsp;여러분, AI가 만든 글을 읽을 때 느낌이 \" data-og-host=\"muzbox.tistory.com\" data-og-source-url=\"https://muzbox.tistory.com/483526\" data-og-url=\"https://muzbox.tistory.com/483526\" data-og-image=\"https://scrap.kakaocdn.net/dn/ch7lZR/hyX4t3WxrT/2kfrHwISV5bzj9Eyr5m75k/img.jpg?width=800&amp;height=457&amp;face=0_0_800_457,https://scrap.kakaocdn.net/dn/ofjlW/hyX4yqILJG/kLYR2M1KVJRWtGGCktAyJ1/img.jpg?width=800&amp;height=457&amp;face=0_0_800_457,https://scrap.kakaocdn.net/dn/m2maj/hyX4sD0s07/rT9MjfHkyBZSP6AGZpmgbk/img.png?width=1163&amp;height=794&amp;face=0_0_1163_794\"><a href=\"https://muzbox.tistory.com/483526\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://muzbox.tistory.com/483526\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/ch7lZR/hyX4t3WxrT/2kfrHwISV5bzj9Eyr5m75k/img.jpg?width=800&amp;height=457&amp;face=0_0_800_457,https://scrap.kakaocdn.net/dn/ofjlW/hyX4yqILJG/kLYR2M1KVJRWtGGCktAyJ1/img.jpg?width=800&amp;height=457&amp;face=0_0_800_457,https://scrap.kakaocdn.net/dn/m2maj/hyX4sD0s07/rT9MjfHkyBZSP6AGZpmgbk/img.png?width=1163&amp;height=794&amp;face=0_0_1163_794');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">AI 가 만든 글에 사람의 향기를, 무료 GTPS - 인간냄새</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">사람 냄새 나는 AI 글쓰기, 어떻게 가능할까요? 제가 만든 챗봇, GPTS가 바로 그 답입니다! 자연스럽고 공감 가는 글을 만드는 비법을 지금 확인해 보세요.&nbsp;여러분, AI가 만든 글을 읽을 때 느낌이</p>\n<p class=\"og-host\" data-ke-size=\"size16\">muzbox.tistory.com</p>\n</div>\n</a></figure></center>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>문장이 자연스러운지:</b> AI가 어색한 표현을 쓸 때가 많아요.</li>\n<li><b>사실 확인:</b> 가짜 정보가 있을 수 있으니 꼭 체크하세요.</li>\n<li><b>개인적인 의견 추가:</b> 나만의 생각을 담아야 차별화가 돼요.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">4.   사용자 경험 최적화</span></h3>\n<p data-ke-size=\"size16\">방문자가 오래 머물게 하려면 어떻게 해야 할까요?</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>모바일에서도 보기 좋게 디자인하기</li>\n<li>로딩 속도 빠르게 하기</li>\n<li>관련 글을 연결해 체류 시간 늘리기</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>  구글의 AI 콘텐츠 감지 기술</b></span></h2>\n<p data-ke-size=\"size16\">구글은 AI로 작성된 콘텐츠를 찾아내기 위해 다양한 기술을 사용해요.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"구글알고리즘.webp\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/vxjdL/btsLVmcuVzv/p1o49KDZAv90rZVVvUY5a0/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/vxjdL/btsLVmcuVzv/p1o49KDZAv90rZVVvUY5a0/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/vxjdL/btsLVmcuVzv/p1o49KDZAv90rZVVvUY5a0/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FvxjdL%2FbtsLVmcuVzv%2Fp1o49KDZAv90rZVVvUY5a0%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"구글의 AI 콘텐츠 감지 기술\" loading=\"lazy\" width=\"700\" height=\"382\" data-filename=\"구글알고리즘.webp\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n</p>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>자연어 처리(NLP):</b> AI가 만든 글의 특정 패턴을 감지해요.</li>\n<li><b>중복 콘텐츠 판별:</b> 비슷한 글이 많으면 순위가 떨어질 수 있어요.</li>\n<li><b>사용자 행동 분석:</b> 방문자가 머무는 시간, 클릭률 등을 분석해요.</li>\n</ol>\n<p data-ke-size=\"size16\">결국 중요한 건 &lsquo;AI스럽지 않게&rsquo; 자연스럽고 가치 있는 정보를 제공하는 거예요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 id=\"e-e-a-t-\" style=\"color: #000000; text-align: start;\" data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>[참고] E-E-A-T 란?</b></span></h2>\n<p style=\"color: #000000; text-align: start;\" data-ke-size=\"size16\"><b>E-E-A-T</b>는 구글이 웹사이트의 콘텐츠 품질을 평가할 때 사용하는 중요한 기준이에요. 원래는<span>&nbsp;</span><b>E-A-T(Expertise, Authoritativeness, Trustworthiness: 전문성, 권위성, 신뢰성)</b>로 시작됐지만, 2022년 &lsquo;경험(Experience)&rsquo;이 추가되면서<span>&nbsp;</span><b>E-E-A-T</b>로 발전했어요.</p>\n<h2 id=\"e-e-a-t-\" style=\"color: #000000; text-align: start;\" data-ke-size=\"size26\"><span style=\"color: #ee2323;\">E-E-A-T의 구성 요소</span></h2>\n<ol style=\"list-style-type: decimal; color: #000000; text-align: start;\" data-ke-list-type=\"decimal\">\n<li><b>Experience (경험)</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>직접적인 경험이 있는 사람이 작성한 콘텐츠를 구글은 더 신뢰해요.</li>\n<li>예를 들어, 여행 리뷰는 직접 여행을 다녀온 사람이 쓴 글이 더 신뢰할 만하죠.</li>\n<li>실제 경험에서 나온 정보는 독자들에게도 더 유용해요.</li>\n</ul>\n</li>\n<li><b>Expertise (전문성)</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>콘텐츠를 작성한 사람이 해당 주제에 대해 얼마나 전문적인 지식을 가지고 있는지를 평가해요.</li>\n<li>예를 들어, 건강 관련 글이라면 의사나 전문가가 작성한 것이 높은 평가를 받겠죠.</li>\n</ul>\n</li>\n<li><b>Authoritativeness (권위성)</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>콘텐츠가 해당 분야에서 얼마나 권위 있는 정보를 제공하는지, 그리고 그 사이트 자체의 신뢰도를 평가해요.</li>\n<li>웹사이트의 도메인 평판, 외부에서 받는 인용이나 링크 등이 중요해요.</li>\n</ul>\n</li>\n<li><b>Trustworthiness (신뢰성)</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>콘텐츠의 정확성과 신뢰성을 평가하는 요소예요.</li>\n<li>사이트의 보안(SSL 사용 여부), 정확한 출처 제공, 투명한 운영 방침 등이 포함돼요.<br /><br /></li>\n</ul>\n</li>\n</ol>\n<h2 id=\"e-e-a-t-\" style=\"color: #000000; text-align: start;\" data-ke-size=\"size26\"><span style=\"color: #ee2323;\">E-E-A-T가 중요한 이유</span></h2>\n<p style=\"color: #000000; text-align: start;\" data-ke-size=\"size16\">구글은 특히<span>&nbsp;</span><b>YMYL(Your Money or Your Life)</b>, 즉 건강, 재정, 법률 등<span>&nbsp;</span><b>사람들의 삶에 직접적인 영향을 미치는 분야</b>에서 E-E-A-T 기준을 더 엄격하게 적용해요. 이런 분야에서는 부정확한 정보가 사람들에게 심각한 영향을 미칠 수 있기 때문이죠.<br /><br /></p>\n<script async src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8195497734535830\"\n     crossorigin=\"anonymous\"></script>\n<ins class=\"adsbygoogle\"\n     style=\"display:block; text-align:center;\"\n     data-ad-layout=\"in-article\"\n     data-ad-format=\"fluid\"\n     data-ad-client=\"ca-pub-8195497734535830\"\n     data-ad-slot=\"1494233468\"></ins>\n<script>\n     (adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<center><figure id=\"og_1737524075059\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"챗GPT 블로그 제목 생성 무료 GPTS, 이슈성 키워드를 롱런시키는 전략\" data-og-description=\"이슈성 키워드를 오랫동안 유지할 수 있는 블로그 제목을 만드는 방법과 SEO 최적화 전략을 해결한 무료 GPTS를 공개합니다. 연말정산이나 폭설 같은 키워드를 활용해서 꾸준한 트래픽을 유지하\" data-og-host=\"muzbox.tistory.com\" data-og-source-url=\"https://muzbox.tistory.com/483528\" data-og-url=\"https://muzbox.tistory.com/483528\" data-og-image=\"https://scrap.kakaocdn.net/dn/cRZnM0/hyX4pAwFkX/SHjC5tVLvJCBWjiUi5RiHk/img.png?width=800&amp;height=456&amp;face=0_0_800_456,https://scrap.kakaocdn.net/dn/bEKYOu/hyX4qsFN9K/QpJG3QYEyhj6eXBgcKEkkK/img.png?width=800&amp;height=456&amp;face=0_0_800_456,https://scrap.kakaocdn.net/dn/cysKC7/hyX4yKYFBv/MK3C9UpRmMO8hnWakQWIZ0/img.png?width=900&amp;height=514&amp;face=0_0_900_514\"><a href=\"https://muzbox.tistory.com/483528\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://muzbox.tistory.com/483528\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/cRZnM0/hyX4pAwFkX/SHjC5tVLvJCBWjiUi5RiHk/img.png?width=800&amp;height=456&amp;face=0_0_800_456,https://scrap.kakaocdn.net/dn/bEKYOu/hyX4qsFN9K/QpJG3QYEyhj6eXBgcKEkkK/img.png?width=800&amp;height=456&amp;face=0_0_800_456,https://scrap.kakaocdn.net/dn/cysKC7/hyX4yKYFBv/MK3C9UpRmMO8hnWakQWIZ0/img.png?width=900&amp;height=514&amp;face=0_0_900_514');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">챗GPT 블로그 제목 생성 무료 GPTS, 이슈성 키워드를 롱런시키는 전략</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">이슈성 키워드를 오랫동안 유지할 수 있는 블로그 제목을 만드는 방법과 SEO 최적화 전략을 해결한 무료 GPTS를 공개합니다. 연말정산이나 폭설 같은 키워드를 활용해서 꾸준한 트래픽을 유지하</p>\n<p class=\"og-host\" data-ke-size=\"size16\">muzbox.tistory.com</p>\n</div>\n</a></figure></center>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 id=\"e-e-a-t-\" style=\"color: #000000; text-align: start;\" data-ke-size=\"size26\"><span style=\"color: #ee2323;\">E-E-A-T를 강화하는 방법</span></h2>\n<ol style=\"list-style-type: decimal; color: #000000; text-align: start;\" data-ke-list-type=\"decimal\">\n<li><b>개인적인 경험을 적극 반영하기</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>내가 직접 사용해 본 제품 후기, 경험을 녹여서 차별화된 콘텐츠를 만들기.</li>\n<li>단순한 정보 제공이 아니라 실제 체험을 담은 글을 작성해 신뢰성을 높이기.</li>\n</ul>\n</li>\n<li><b>전문성을 강조하기</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>해당 분야의 전문가 인터뷰 추가.</li>\n<li>정확한 출처를 밝히고 신뢰할 만한 자료를 활용하기.</li>\n</ul>\n</li>\n<li><b>권위 있는 외부 사이트와의 연계</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>신뢰할 수 있는 웹사이트(공식 기관, 전문가 블로그 등)에서 내 콘텐츠를 인용하게 만들기.</li>\n<li>구글에서 내 블로그가 전문성을 인정받을 수 있도록 관련 기관과 협력하기.</li>\n</ul>\n</li>\n<li><b>사이트 신뢰도 높이기</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>HTTPS 보안 적용.</li>\n<li>저작권 정보, 문의 페이지 등 신뢰도를 높일 수 있는 요소 추가.</li>\n<li>독자 피드백을 반영하고 신속한 대응 제공.</li>\n</ul>\n</li>\n</ol>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"구글-상위-노출에-성공한-블로거.webp\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/dfd1Xv/btsLVhhV8Wp/bY2S69EElEGckhG3M58uDK/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/dfd1Xv/btsLVhhV8Wp/bY2S69EElEGckhG3M58uDK/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/dfd1Xv/btsLVhhV8Wp/bY2S69EElEGckhG3M58uDK/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fdfd1Xv%2FbtsLVhhV8Wp%2FbY2S69EElEGckhG3M58uDK%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"구글 검색 노출이 어려워진 이유\" loading=\"lazy\" width=\"700\" height=\"382\" data-filename=\"구글-상위-노출에-성공한-블로거.webp\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>✍️ 마치며</b></span></h2>\n<p data-ke-size=\"size16\">AI 시대에도 살아남는 블로그를 만들려면 단순히 AI를 활용하는 것만으로는 부족해요. 사람의 개성과 경험을 담고, 신뢰할 수 있는 정보를 제공해야 해요.</p>\n<p data-ke-size=\"size16\">검색 알고리즘이 바뀌어도 좋은 콘텐츠는 언제나 사랑받는다는 점, 잊지 마세요!  </p>\n<hr data-ke-style=\"style1\" />\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>❓ Q&amp;A</b></span></h2>\n<p data-ke-size=\"size16\"><b>Q1. 구글은 AI로 생성된 콘텐츠를 감지할 수 있나요?</b><br />A. 네, 구글은 고급 AI 분석 기술을 사용해 AI 콘텐츠를 감지하려고 해요. 하지만 고품질 콘텐츠라면 상위 노출이 가능해요.<br /><br /></p>\n<p data-ke-size=\"size16\"><b>Q2. 블로그 SEO에서 가장 중요한 요소는 무엇인가요?</b><br />A. E-E-A-T 강화와 사용자 경험 최적화가 가장 중요해요. 키워드만으로는 부족하죠.<br /><br /></p>\n<p data-ke-size=\"size16\"><b>Q3. AI 콘텐츠를 효과적으로 활용하려면?</b><br />A. AI가 초안을 작성하도록 하고, 직접 수정하고 경험을 추가하는 것이 가장 효과적인 방법이에요.</p>\n<textarea style=\"display:none\">\n<script type=\"application/ld+json\">\n{\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n        {\n            \"@type\": \"Question\",\n            \"name\": \"구글은 AI로 생성된 콘텐츠를 감지할 수 있나요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"네, 구글은 고급 AI 분석 기술을 사용해 AI 콘텐츠를 감지하려고 해요. 하지만 고품질 콘텐츠라면 상위 노출이 가능해요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"블로그 SEO에서 가장 중요한 요소는 무엇인가요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"E-E-A-T 강화와 사용자 경험 최적화가 가장 중요해요. 키워드만으로는 부족하죠.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"AI 콘텐츠를 효과적으로 활용하려면?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"AI가 초안을 작성하도록 하고, 직접 수정하고 경험을 추가하는 것이 가장 효과적인 방법이에요.\"\n            }\n        }\n    ]\n}\n</script>\n</textarea>",
        "contentSnippet": "구글 검색에서 블로그가 예전처럼 잘 안 보이나요? AI 콘텐츠 홍수 속에서도 끈질기게 살아남을 수 있는 SEO 최적화 전략과 E-E-A-T 강화 방법을 소개합니다.\n\n\n \n 요즘 블로그 글을 올려도 예전처럼 구글에서 잘 보이지 않는다고 느끼신 적 있나요? 저도 같은 고민을 했어요. 아무리 공들여서 글을 써도 검색 상위에 노출되기는커녕 방문자 수도 줄어드는 것 같더라고요.\n \n이유는 간단해요. AI 기술 덕분에 콘텐츠가 넘쳐나고, 구글도 검색 품질을 유지하려고 알고리즘을 계속 바꾸고 있거든요. 예전처럼 단순히 키워드만 잘 넣어서 해결할 수 있는 시대는 끝났고, 이제는 **E-E-A-T(경험, 전문성, 권위성, 신뢰성)**이 필수적인 요소가 됐어요.\n \n그럼 어떻게 해야 블로그가 살아남을 수 있을까요? 제가 직접 시행착오를 겪으며 찾은 해결책을 공유해볼게요!\n \n \n  구글 검색 노출이 어려워진 이유\n1.   구글 알고리즘 업데이트의 영향\n구글은 검색 결과의 신뢰도를 높이기 위해 알고리즘을 계속 개선하고 있어요. 특히 요즘은 다음 요소들이 중요해졌어요.\nE-E-A-T 요소 강화:\n구글은 사용자가 믿을 수 있는 정보를 원한다는 걸 잘 알고 있어요. 그래서 건강, 금융 같은 중요한 분야(YMYL)에서는 전문가가 작성한 신뢰성 있는 콘텐츠를 우선적으로 보여주고 있어요.\n사용자 경험(UX)의 중요성:\n페이지 로딩이 느리거나 모바일에서 불편하면 방문자가 바로 나가버리죠. 구글은 이런 사이트를 좋아하지 않아요. 속도와 가독성이 중요한 이유예요.\n콘텐츠 품질 평가:\n단순한 정보 나열로는 부족해요. 구체적인 사례와 심층 분석이 담긴 콘텐츠가 더 높은 평가를 받아요.\n2.   색인(Indexing) 문제\n구글에 내 글이 제대로 색인되지 않으면 아무리 좋은 글도 검색 결과에 나오지 않아요. 다음을 체크해 보세요.\nrobots.txt 설정 확인: 혹시 크롤러가 내 사이트를 막고 있지는 않은지?\n사이트맵 제출: Google Search Console에서 사이트맵을 등록했는지 확인해보세요.\n색인 요청: 특정 페이지가 검색에 안 잡힌다면 직접 요청을 해보는 것도 방법이에요.\n3.   AI 콘텐츠 필터링 기술 강화\n요즘 AI로 생성된 콘텐츠가 넘쳐나면서, 구글도 이를 감지하기 위해 노력하고 있어요. 자동 생성된 콘텐츠라도 품질이 낮다면 순위가 내려갈 수밖에 없죠.\n4.   경쟁 심화\n예전에는 특정 키워드를 잡고 꾸준히 글을 쓰면 상위권이 가능했는데, 이제는 누구나 AI를 활용해서 콘텐츠를 쉽게 만들 수 있는 시대가 됐어요. 그렇다 보니 더 창의적이고 차별화된 콘텐츠가 필요해요.\n \n \n  AI 시대, 효과적인 콘텐츠 제작 전략\n1.   E-E-A-T 요소 강화하기\n블로그에 신뢰도를 높이려면 이렇게 해보세요.\n실제 경험담 공유: 사용해본 제품의 리얼 리뷰를 담으면 신뢰도가 높아져요.\n전문가 의견 추가: 해당 분야의 전문가 인터뷰나 공신력 있는 자료를 인용해 보세요.\n독창적인 시각 제공: 다른 블로그에서 볼 수 없는 나만의 인사이트를 더해보세요.\n2. ✍️ 효과적인 프롬프트 작성\nAI를 사용할 때 프롬프트(명령어)를 잘 주는 게 중요해요. 예를 들면:\n\"2024년 블로그 SEO 트렌드를 심층 분석해줘. 구글 알고리즘 변화와 사용자 경험, E-E-A-T 적용 방안 중심으로 작성해줘.\"\n이렇게 구체적으로 요청할수록 더 좋은 결과가 나오더라고요.\n3.   AI 콘텐츠 검토 및 보완\nAI가 글을 쓴다고 해서 그대로 올리면 안 돼요. 꼭 다음을 확인하세요.\n\n\n\n     (adsbygoogle = window.adsbygoogle || []).push({});\n\n\n \nAI 가 만든 글에 사람의 향기를, 무료 GTPS - 인간냄새\n사람 냄새 나는 AI 글쓰기, 어떻게 가능할까요? 제가 만든 챗봇, GPTS가 바로 그 답입니다! 자연스럽고 공감 가는 글을 만드는 비법을 지금 확인해 보세요. 여러분, AI가 만든 글을 읽을 때 느낌이\nmuzbox.tistory.com\n\n\n문장이 자연스러운지: AI가 어색한 표현을 쓸 때가 많아요.\n사실 확인: 가짜 정보가 있을 수 있으니 꼭 체크하세요.\n개인적인 의견 추가: 나만의 생각을 담아야 차별화가 돼요.\n4.   사용자 경험 최적화\n방문자가 오래 머물게 하려면 어떻게 해야 할까요?\n모바일에서도 보기 좋게 디자인하기\n로딩 속도 빠르게 하기\n관련 글을 연결해 체류 시간 늘리기\n \n  구글의 AI 콘텐츠 감지 기술\n구글은 AI로 작성된 콘텐츠를 찾아내기 위해 다양한 기술을 사용해요.\n\n\n\n자연어 처리(NLP): AI가 만든 글의 특정 패턴을 감지해요.\n중복 콘텐츠 판별: 비슷한 글이 많으면 순위가 떨어질 수 있어요.\n사용자 행동 분석: 방문자가 머무는 시간, 클릭률 등을 분석해요.\n결국 중요한 건 ‘AI스럽지 않게’ 자연스럽고 가치 있는 정보를 제공하는 거예요.\n \n \n[참고] E-E-A-T 란?\nE-E-A-T는 구글이 웹사이트의 콘텐츠 품질을 평가할 때 사용하는 중요한 기준이에요. 원래는 E-A-T(Expertise, Authoritativeness, Trustworthiness: 전문성, 권위성, 신뢰성)로 시작됐지만, 2022년 ‘경험(Experience)’이 추가되면서 E-E-A-T로 발전했어요.\nE-E-A-T의 구성 요소\nExperience (경험)\n\n직접적인 경험이 있는 사람이 작성한 콘텐츠를 구글은 더 신뢰해요.\n예를 들어, 여행 리뷰는 직접 여행을 다녀온 사람이 쓴 글이 더 신뢰할 만하죠.\n실제 경험에서 나온 정보는 독자들에게도 더 유용해요.\nExpertise (전문성)\n\n콘텐츠를 작성한 사람이 해당 주제에 대해 얼마나 전문적인 지식을 가지고 있는지를 평가해요.\n예를 들어, 건강 관련 글이라면 의사나 전문가가 작성한 것이 높은 평가를 받겠죠.\nAuthoritativeness (권위성)\n\n콘텐츠가 해당 분야에서 얼마나 권위 있는 정보를 제공하는지, 그리고 그 사이트 자체의 신뢰도를 평가해요.\n웹사이트의 도메인 평판, 외부에서 받는 인용이나 링크 등이 중요해요.\nTrustworthiness (신뢰성)\n\n콘텐츠의 정확성과 신뢰성을 평가하는 요소예요.\n사이트의 보안(SSL 사용 여부), 정확한 출처 제공, 투명한 운영 방침 등이 포함돼요.\n\nE-E-A-T가 중요한 이유\n구글은 특히 YMYL(Your Money or Your Life), 즉 건강, 재정, 법률 등 사람들의 삶에 직접적인 영향을 미치는 분야에서 E-E-A-T 기준을 더 엄격하게 적용해요. 이런 분야에서는 부정확한 정보가 사람들에게 심각한 영향을 미칠 수 있기 때문이죠.\n\n\n\n\n     (adsbygoogle = window.adsbygoogle || []).push({});\n\n\n \n챗GPT 블로그 제목 생성 무료 GPTS, 이슈성 키워드를 롱런시키는 전략\n이슈성 키워드를 오랫동안 유지할 수 있는 블로그 제목을 만드는 방법과 SEO 최적화 전략을 해결한 무료 GPTS를 공개합니다. 연말정산이나 폭설 같은 키워드를 활용해서 꾸준한 트래픽을 유지하\nmuzbox.tistory.com\n\n \nE-E-A-T를 강화하는 방법\n개인적인 경험을 적극 반영하기\n\n내가 직접 사용해 본 제품 후기, 경험을 녹여서 차별화된 콘텐츠를 만들기.\n단순한 정보 제공이 아니라 실제 체험을 담은 글을 작성해 신뢰성을 높이기.\n전문성을 강조하기\n\n해당 분야의 전문가 인터뷰 추가.\n정확한 출처를 밝히고 신뢰할 만한 자료를 활용하기.\n권위 있는 외부 사이트와의 연계\n\n신뢰할 수 있는 웹사이트(공식 기관, 전문가 블로그 등)에서 내 콘텐츠를 인용하게 만들기.\n구글에서 내 블로그가 전문성을 인정받을 수 있도록 관련 기관과 협력하기.\n사이트 신뢰도 높이기\n\nHTTPS 보안 적용.\n저작권 정보, 문의 페이지 등 신뢰도를 높일 수 있는 요소 추가.\n독자 피드백을 반영하고 신속한 대응 제공.\n\n\n \n✍️ 마치며\nAI 시대에도 살아남는 블로그를 만들려면 단순히 AI를 활용하는 것만으로는 부족해요. 사람의 개성과 경험을 담고, 신뢰할 수 있는 정보를 제공해야 해요.\n검색 알고리즘이 바뀌어도 좋은 콘텐츠는 언제나 사랑받는다는 점, 잊지 마세요!  \n❓ Q&A\nQ1. 구글은 AI로 생성된 콘텐츠를 감지할 수 있나요?\nA. 네, 구글은 고급 AI 분석 기술을 사용해 AI 콘텐츠를 감지하려고 해요. 하지만 고품질 콘텐츠라면 상위 노출이 가능해요.\n\nQ2. 블로그 SEO에서 가장 중요한 요소는 무엇인가요?\nA. E-E-A-T 강화와 사용자 경험 최적화가 가장 중요해요. 키워드만으로는 부족하죠.\n\nQ3. AI 콘텐츠를 효과적으로 활용하려면?\nA. AI가 초안을 작성하도록 하고, 직접 수정하고 경험을 추가하는 것이 가장 효과적인 방법이에요.\n\n\n{\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n        {\n            \"@type\": \"Question\",\n            \"name\": \"구글은 AI로 생성된 콘텐츠를 감지할 수 있나요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"네, 구글은 고급 AI 분석 기술을 사용해 AI 콘텐츠를 감지하려고 해요. 하지만 고품질 콘텐츠라면 상위 노출이 가능해요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"블로그 SEO에서 가장 중요한 요소는 무엇인가요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"E-E-A-T 강화와 사용자 경험 최적화가 가장 중요해요. 키워드만으로는 부족하죠.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"AI 콘텐츠를 효과적으로 활용하려면?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"AI가 초안을 작성하도록 하고, 직접 수정하고 경험을 추가하는 것이 가장 효과적인 방법이에요.\"\n            }\n        }\n    ]\n}",
        "guid": "https://muzbox.tistory.com/483529",
        "categories": [
          "Google 이야기/애드센스 노하우",
          "AI 콘텐츠",
          "e-e-a-t",
          "SEO 최적화",
          "구글 검색 노출",
          "구글 알고리즘",
          "구글색인",
          "구글콘솔",
          "블로그 글쓰기",
          "색인 생성",
          "프롬프트 기법"
        ],
        "isoDate": "2025-01-22T05:50:49.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "챗GPT 블로그 제목 생성 무료 GPTS, 이슈성 키워드를 롱런시키는 전략",
        "link": "https://muzbox.tistory.com/483528",
        "pubDate": "Mon, 20 Jan 2025 09:25:33 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "https://muzbox.tistory.com/483528#entry483528comment",
        "content": "<p data-ke-size=\"size16\">이슈성 키워드를 오랫동안 유지할 수 있는 블로그 제목을 만드는 방법과 SEO 최적화 전략을 해결한 무료 GPTS를 공개합니다. 연말정산이나 폭설 같은 키워드를 활용해서 꾸준한 트래픽을 유지하는 방법, 같이 알아봐요!</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"블로그 제목 생성.png\" data-origin-width=\"900\" data-origin-height=\"514\"><span data-url=\"https://blog.kakaocdn.net/dn/cGt6gX/btsLSO0ecsE/du7A79MqpndE6lhOKAvki1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cGt6gX/btsLSO0ecsE/du7A79MqpndE6lhOKAvki1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cGt6gX/btsLSO0ecsE/du7A79MqpndE6lhOKAvki1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcGt6gX%2FbtsLSO0ecsE%2Fdu7A79MqpndE6lhOKAvki1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"챗GPT 블로그 제목 생성 무료 GPTS, 이슈성 키워드를 롱런시키는 전략\" loading=\"lazy\" width=\"700\" height=\"400\" data-filename=\"블로그 제목 생성.png\" data-origin-width=\"900\" data-origin-height=\"514\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;블로그를 운영하다 보면 특정 키워드가 갑자기 인기를 끌다가 얼마 지나지 않아 관심이 뚝 떨어지는 경우가 많죠. 저도 블로그에서 \"연말정산\"이나 \"폭설\" 같은 키워드를 써보면서 이런 경험을 했는데요. 처음엔 방문자가 몰렸다가 시즌이 끝나면 트래픽이 확 줄더라고요. 그렇다고 포기할 수는 없잖아요? 어떻게 하면 이런 키워드를 오랫동안 관심받게 만들 수 있을지, 오늘 같이 고민해볼게요!&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이러한 과정을 통해 챗GPT를 이용하여 바로 적절한 제목을 만들어 주는 GPTS 를 무료로 공개합니다.!!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>  이슈성 키워드를 꾸준히 유지하는 방법</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">  \"관심과 감정이 연결된 대상\" 찾기</span></h3>\n<p data-ke-size=\"size16\">사람들은 자기와 관련된 내용에 훨씬 더 오래 관심을 가져요. 그냥 \"폭설 대비 방법\"보다는 \"우리 가족을 위한 폭설 대비 체크리스트\"처럼 개인적인 느낌을 담으면 효과가 좋아요.</p>\n<h4 data-ke-size=\"size20\"><b>  실행 방안</b></h4>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>개인적인 관점 추가하기:</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>단순 키워드 ❌ &rarr; 감성적인 연결 ✔️</li>\n<li>예: \"폭설\" ❌ &rarr; \"우리 집 자동차를 위한 폭설 대비 완벽 가이드\" ✔️</li>\n<li>예: \"연말정산\" ❌ &rarr; \"2024 직장인을 위한 연말정산 절세 꿀팁\" ✔️</li>\n</ul>\n</li>\n<li><b>사회적 관심 반영하기:</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>트렌드와 연관된 주제로 풀어보기</li>\n<li>예: \"폭설 대비 정책 변화, 우리 생활에 미치는 영향\"</li>\n</ul>\n</li>\n<li><b>검색 의도를 고려한 키워드 조합:</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>왜 필요할까? &rarr; 폭설의 원인 분석</li>\n<li>누구에게 도움될까? &rarr; 직장인, 자영업자 등</li>\n</ul>\n</li>\n</ol>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">  검색 패턴을 활용한 키워드 전략</span></h3>\n<p data-ke-size=\"size16\">검색을 해보면 사람들이 두 가지 방식으로 키워드를 찾더라고요. 바로 <b>즉각적인 검색</b>과 <b>장기적인 검색</b>이에요.</p>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>즉각적인 검색:</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>\"2024 연말정산 마감일 언제까지?\"</li>\n<li>\"서울 폭설 현재 상황 실시간 보기\"</li>\n</ul>\n</li>\n<li><b>장기적인 검색:</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>\"연말정산 공제 항목 완벽 정리\"</li>\n<li>\"겨울철 차량 관리법, 폭설 대비 팁\"</li>\n</ul>\n</li>\n</ol>\n<h4 data-ke-size=\"size20\"><b>  키워드 전략 적용</b></h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>즉각적인 검색:</b> 마감일, 실시간, 빠른 해결</li>\n<li><b>장기적인 검색:</b> 팁, 가이드, 준비법</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">  키워드를 지속 가능하게 만드는 법</span></h3>\n<h4 data-ke-size=\"size20\">1) 트렌드 활용하기</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>연말정산: \"2025 연말정산 준비, 미리 챙겨야 할 것들\"</li>\n<li>폭설: \"기후 변화로 폭설이 많아진다, 우리가 대비할 방법은?\"</li>\n</ul>\n<h4 data-ke-size=\"size20\">2) 깊이 있는 정보 제공</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>연말정산: \"초보 직장인을 위한 연말정산 공제 완벽 정리\"</li>\n<li>폭설: \"지역별 폭설 대처법, 이렇게 하면 안전해요\"</li>\n</ul>\n<h4 data-ke-size=\"size20\">3) 키워드 확장</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>연말정산 &rarr; \"소득공제, 세액공제 뭐가 다를까?\"</li>\n<li>폭설 &rarr; \"겨울철 자동차 관리, 이것만은 꼭!\"</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>  [연말정산] 및 [폭설] 키워드 적용 예시</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">즉각적인 호기심 유발</span></h3>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>\"2024 연말정산, 이번에 놓치면 안 되는 절세 포인트!\"</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>핵심 키워드: 연말정산 팁, 절세 전략</li>\n<li>SEO 전략: '놓치면 안 되는', '필수 항목' 키워드 활용</li>\n</ul>\n</li>\n<li><b>\"올 겨울 폭설 대비, 필수 체크리스트 대공개!\"</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>핵심 키워드: 폭설 대비, 차량 준비</li>\n<li>SEO 전략: '필수', '체크리스트', '준비법' 키워드 강조</li>\n</ul>\n</li>\n</ol>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">구체적인 문제 해결</span></h3>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>\"연말정산 소득공제와 세액공제, 뭐가 다를까?\"</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>핵심 키워드: 소득공제, 세액공제</li>\n<li>SEO 전략: '차이점', '비교', '절세 방법' 강조</li>\n</ul>\n</li>\n<li><b>\"폭설 대비 차량 점검, 이것만 기억하세요!\"</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>핵심 키워드: 겨울철 차량 관리, 폭설 대비</li>\n<li>SEO 전략: '필수 확인', '고장 예방' 키워드 삽입</li>\n</ul>\n</li>\n</ol>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>마무리하며</b></span></h2>\n<p data-ke-size=\"size16\">이슈성 키워드를 꾸준히 유지하려면, <b>검색 패턴을 이해하고, 개인적인 스토리와 사회적 이슈를 적절히 섞는 게 중요해요.</b> 이렇게 하면 독자들이 꾸준히 관심을 가질 수 있답니다.</p>\n<p data-ke-size=\"size16\">이제 여러분도 연말정산이나 폭설 같은 키워드로 꾸준한 검색 유입을 만들어 보세요!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000; text-align: start;\" data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b> </b></span><span style=\"color: #009a87;\"><b><span>&nbsp;</span>GPTS 무료배포</b></span></h2>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\">&nbsp;약간의 지식과 시간만 투자하면 누구나 직접 제작하고 활용할 수 있는 유용한 GPTs가 이미 많이 존재합니다. 그러나 여전히 AI 기술에 대한 낯선 접근을 두려워하거나 IT 초보자, 또는 시간적 여유가 없거나 수익화에 대한 절실함 때문에 올바른 정보를 얻지 못하는 사람들이 많습니다. 이러한 심리를 악용해 과도한 가격으로 유료 강의를 판매하며 불필요한 부담을 주는 사례들이 늘어나고 있습니다.<span>&nbsp;</span><span style=\"color: #ee2323;\"><b>이에 본 블로그에서는 모든 사람이 AI의 혜택을 공정하고 자유롭게 누릴 수 있도록 GPTs를 무료로 배포하며, 불합리한 강의 판매 행위를 단호히 배척하고자 합니다.</b></span></p>\n<script async src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8195497734535830\"\n     crossorigin=\"anonymous\"></script>\n<ins class=\"adsbygoogle\"\n     style=\"display:block; text-align:center;\"\n     data-ad-layout=\"in-article\"\n     data-ad-format=\"fluid\"\n     data-ad-client=\"ca-pub-8195497734535830\"\n     data-ad-slot=\"7411138078\"></ins>\n<script>\n     (adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<figure id=\"og_1737332149856\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"ChatGPT - 챗GPT 블로그 제목 생성기\" data-og-description=\"사용자가 [키워드]를 입력하면 키워드를 지속적으로 유지하기 위한 블로그 제목을 제안합니다.\" data-og-host=\"chatgpt.com\" data-og-source-url=\"https://chatgpt.com/g/g-678d84eed64c819190a55fb6178767fc-caesgpt-beulrogeu-jemog-saengseonggi\" data-og-url=\"https://chatgpt.com/g/g-678d84eed64c819190a55fb6178767fc-caesgpt-beulrogeu-jemog-saengseonggi\" data-og-image=\"\"><a href=\"https://chatgpt.com/g/g-678d84eed64c819190a55fb6178767fc-caesgpt-beulrogeu-jemog-saengseonggi\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://chatgpt.com/g/g-678d84eed64c819190a55fb6178767fc-caesgpt-beulrogeu-jemog-saengseonggi\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">ChatGPT - 챗GPT 블로그 제목 생성기</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">사용자가 [키워드]를 입력하면 키워드를 지속적으로 유지하기 위한 블로그 제목을 제안합니다.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">chatgpt.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\">&nbsp;</p>\n<hr data-ke-style=\"style1\" />\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>❓ 자주 묻는 질문(Q&amp;A)</b></span></h2>\n<p data-ke-size=\"size16\"><b>1. 연말정산 키워드를 롱런하려면 어떻게 해야 하나요?</b> <br />절세&nbsp;관련&nbsp;정보나&nbsp;연중&nbsp;세테크&nbsp;팁을&nbsp;제공하세요.<br /><br /><b>2. 폭설 키워드는 시즌 외에 어떻게 유지할 수 있을까요?</b> <br />사계절&nbsp;차량&nbsp;관리법을&nbsp;포함해&nbsp;지속적인&nbsp;관심을&nbsp;유도하세요.<br /><br /><b>3. 블로그 제목을 효과적으로 작성하려면?</b> <br />키워드를&nbsp;제목&nbsp;앞쪽에&nbsp;배치하고,&nbsp;'꿀팁',&nbsp;'필수&nbsp;체크리스트'&nbsp;같은&nbsp;단어를&nbsp;활용하세요.<br /><br /><b>4. SEO 최적화를 위해 어떤 전략이 필요할까요?</b> <br />검색&nbsp;의도를&nbsp;파악하고,&nbsp;관련&nbsp;키워드를&nbsp;자연스럽게&nbsp;삽입하는&nbsp;것이&nbsp;중요합니다.<br /><br /><b>5. 이슈성 키워드 외에도 블로그 트래픽을 유지할 방법이 있을까요?</b> <br />꾸준한 콘텐츠 업데이트와 관련 주제 확장을 통해 지속적인 관심을 유도하세요.</p>\n<p><textarea style=\"display: none;\">&lt;script type=\"application/ld+json\"&gt;\n{\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n        {\n            \"@type\": \"Question\",\n            \"name\": \"연말정산 키워드를 롱런하려면 어떻게 해야 하나요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"절세 관련 정보나 연중 세테크 팁을 제공하세요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"폭설 키워드는 시즌 외에 어떻게 유지할 수 있을까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"사계절 차량 관리법을 포함해 지속적인 관심을 유도하세요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"블로그 제목을 효과적으로 작성하려면?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"키워드를 제목 앞쪽에 배치하고, '꿀팁', '필수 체크리스트' 같은 단어를 활용하세요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"SEO 최적화를 위해 어떤 전략이 필요할까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"검색 의도를 파악하고, 관련 키워드를 자연스럽게 삽입하는 것이 중요합니다.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"이슈성 키워드 외에도 블로그 트래픽을 유지할 방법이 있을까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"꾸준한 콘텐츠 업데이트와 관련 주제 확장을 통해 지속적인 관심을 유도하세요.\"\n            }\n        }\n    ]\n}\n&lt;/script&gt;\n</textarea></p>",
        "contentSnippet": "이슈성 키워드를 오랫동안 유지할 수 있는 블로그 제목을 만드는 방법과 SEO 최적화 전략을 해결한 무료 GPTS를 공개합니다. 연말정산이나 폭설 같은 키워드를 활용해서 꾸준한 트래픽을 유지하는 방법, 같이 알아봐요!\n\n\n \n 블로그를 운영하다 보면 특정 키워드가 갑자기 인기를 끌다가 얼마 지나지 않아 관심이 뚝 떨어지는 경우가 많죠. 저도 블로그에서 \"연말정산\"이나 \"폭설\" 같은 키워드를 써보면서 이런 경험을 했는데요. 처음엔 방문자가 몰렸다가 시즌이 끝나면 트래픽이 확 줄더라고요. 그렇다고 포기할 수는 없잖아요? 어떻게 하면 이런 키워드를 오랫동안 관심받게 만들 수 있을지, 오늘 같이 고민해볼게요! \n \n이러한 과정을 통해 챗GPT를 이용하여 바로 적절한 제목을 만들어 주는 GPTS 를 무료로 공개합니다.!!\n \n  이슈성 키워드를 꾸준히 유지하는 방법\n  \"관심과 감정이 연결된 대상\" 찾기\n사람들은 자기와 관련된 내용에 훨씬 더 오래 관심을 가져요. 그냥 \"폭설 대비 방법\"보다는 \"우리 가족을 위한 폭설 대비 체크리스트\"처럼 개인적인 느낌을 담으면 효과가 좋아요.\n  실행 방안\n개인적인 관점 추가하기:\n\n단순 키워드 ❌ → 감성적인 연결 ✔️\n예: \"폭설\" ❌ → \"우리 집 자동차를 위한 폭설 대비 완벽 가이드\" ✔️\n예: \"연말정산\" ❌ → \"2024 직장인을 위한 연말정산 절세 꿀팁\" ✔️\n사회적 관심 반영하기:\n\n트렌드와 연관된 주제로 풀어보기\n예: \"폭설 대비 정책 변화, 우리 생활에 미치는 영향\"\n검색 의도를 고려한 키워드 조합:\n\n왜 필요할까? → 폭설의 원인 분석\n누구에게 도움될까? → 직장인, 자영업자 등\n  검색 패턴을 활용한 키워드 전략\n검색을 해보면 사람들이 두 가지 방식으로 키워드를 찾더라고요. 바로 즉각적인 검색과 장기적인 검색이에요.\n즉각적인 검색:\n\n\"2024 연말정산 마감일 언제까지?\"\n\"서울 폭설 현재 상황 실시간 보기\"\n장기적인 검색:\n\n\"연말정산 공제 항목 완벽 정리\"\n\"겨울철 차량 관리법, 폭설 대비 팁\"\n  키워드 전략 적용\n즉각적인 검색: 마감일, 실시간, 빠른 해결\n장기적인 검색: 팁, 가이드, 준비법\n  키워드를 지속 가능하게 만드는 법\n1) 트렌드 활용하기\n연말정산: \"2025 연말정산 준비, 미리 챙겨야 할 것들\"\n폭설: \"기후 변화로 폭설이 많아진다, 우리가 대비할 방법은?\"\n2) 깊이 있는 정보 제공\n연말정산: \"초보 직장인을 위한 연말정산 공제 완벽 정리\"\n폭설: \"지역별 폭설 대처법, 이렇게 하면 안전해요\"\n3) 키워드 확장\n연말정산 → \"소득공제, 세액공제 뭐가 다를까?\"\n폭설 → \"겨울철 자동차 관리, 이것만은 꼭!\"\n \n  [연말정산] 및 [폭설] 키워드 적용 예시\n즉각적인 호기심 유발\n\"2024 연말정산, 이번에 놓치면 안 되는 절세 포인트!\"\n\n핵심 키워드: 연말정산 팁, 절세 전략\nSEO 전략: '놓치면 안 되는', '필수 항목' 키워드 활용\n\"올 겨울 폭설 대비, 필수 체크리스트 대공개!\"\n\n핵심 키워드: 폭설 대비, 차량 준비\nSEO 전략: '필수', '체크리스트', '준비법' 키워드 강조\n구체적인 문제 해결\n\"연말정산 소득공제와 세액공제, 뭐가 다를까?\"\n\n핵심 키워드: 소득공제, 세액공제\nSEO 전략: '차이점', '비교', '절세 방법' 강조\n\"폭설 대비 차량 점검, 이것만 기억하세요!\"\n\n핵심 키워드: 겨울철 차량 관리, 폭설 대비\nSEO 전략: '필수 확인', '고장 예방' 키워드 삽입\n \n마무리하며\n이슈성 키워드를 꾸준히 유지하려면, 검색 패턴을 이해하고, 개인적인 스토리와 사회적 이슈를 적절히 섞는 게 중요해요. 이렇게 하면 독자들이 꾸준히 관심을 가질 수 있답니다.\n이제 여러분도 연말정산이나 폭설 같은 키워드로 꾸준한 검색 유입을 만들어 보세요!\n \n \n  GPTS 무료배포\n 약간의 지식과 시간만 투자하면 누구나 직접 제작하고 활용할 수 있는 유용한 GPTs가 이미 많이 존재합니다. 그러나 여전히 AI 기술에 대한 낯선 접근을 두려워하거나 IT 초보자, 또는 시간적 여유가 없거나 수익화에 대한 절실함 때문에 올바른 정보를 얻지 못하는 사람들이 많습니다. 이러한 심리를 악용해 과도한 가격으로 유료 강의를 판매하며 불필요한 부담을 주는 사례들이 늘어나고 있습니다. 이에 본 블로그에서는 모든 사람이 AI의 혜택을 공정하고 자유롭게 누릴 수 있도록 GPTs를 무료로 배포하며, 불합리한 강의 판매 행위를 단호히 배척하고자 합니다.\n\n\n\n     (adsbygoogle = window.adsbygoogle || []).push({});\n\n\n \nChatGPT - 챗GPT 블로그 제목 생성기\n사용자가 [키워드]를 입력하면 키워드를 지속적으로 유지하기 위한 블로그 제목을 제안합니다.\nchatgpt.com\n\n \n \n❓ 자주 묻는 질문(Q&A)\n1. 연말정산 키워드를 롱런하려면 어떻게 해야 하나요? \n절세 관련 정보나 연중 세테크 팁을 제공하세요.\n2. 폭설 키워드는 시즌 외에 어떻게 유지할 수 있을까요? \n사계절 차량 관리법을 포함해 지속적인 관심을 유도하세요.\n3. 블로그 제목을 효과적으로 작성하려면? \n키워드를 제목 앞쪽에 배치하고, '꿀팁', '필수 체크리스트' 같은 단어를 활용하세요.\n4. SEO 최적화를 위해 어떤 전략이 필요할까요? \n검색 의도를 파악하고, 관련 키워드를 자연스럽게 삽입하는 것이 중요합니다.\n5. 이슈성 키워드 외에도 블로그 트래픽을 유지할 방법이 있을까요? \n꾸준한 콘텐츠 업데이트와 관련 주제 확장을 통해 지속적인 관심을 유도하세요.\n<script type=\"application/ld+json\">\n{\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n        {\n            \"@type\": \"Question\",\n            \"name\": \"연말정산 키워드를 롱런하려면 어떻게 해야 하나요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"절세 관련 정보나 연중 세테크 팁을 제공하세요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"폭설 키워드는 시즌 외에 어떻게 유지할 수 있을까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"사계절 차량 관리법을 포함해 지속적인 관심을 유도하세요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"블로그 제목을 효과적으로 작성하려면?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"키워드를 제목 앞쪽에 배치하고, '꿀팁', '필수 체크리스트' 같은 단어를 활용하세요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"SEO 최적화를 위해 어떤 전략이 필요할까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"검색 의도를 파악하고, 관련 키워드를 자연스럽게 삽입하는 것이 중요합니다.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"이슈성 키워드 외에도 블로그 트래픽을 유지할 방법이 있을까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"꾸준한 콘텐츠 업데이트와 관련 주제 확장을 통해 지속적인 관심을 유도하세요.\"\n            }\n        }\n    ]\n}\n</script>",
        "guid": "https://muzbox.tistory.com/483528",
        "categories": [
          "AI, 미래기술/MY GPT 공개",
          "SEO 최적화",
          "롱런 키워드 전략",
          "무료 gpts",
          "무료챗봇",
          "블로그 제목 생성기",
          "블로그 콘텐츠 기획",
          "이슈성 키워드",
          "지속 가능한 트래픽",
          "챗GPT",
          "키워드 지속 유지법"
        ],
        "isoDate": "2025-01-20T00:25:33.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": []
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": [
      {
        "title": "golang - Go의 병행 처리를 깨끗하고 안전하게 쓸 수 있는 sourcegraph/conc",
        "link": "https://jacking75.github.io/go_20250125/",
        "pubDate": "Sat, 25 Jan 2025 00:00:00 +0900",
        "content": "<iframe width=\"1024\" height=\"1024\" src=\"https://docs.google.com/document/d/e/2PACX-1vRRJ0Aa_FFBuUxHhw5VK1FwXR9vN6lArY0ziGBSgGnjaOTesMYzdYTqbBa7Lu434ZiYRzAiAftwae5C/pub?embedded=true\"></iframe>\n\n",
        "contentSnippet": "",
        "guid": "https://jacking75.github.io/go_20250125/",
        "isoDate": "2025-01-24T15:00:00.000Z"
      }
    ]
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": [
      {
        "title": "AI 도구를 써도 돈 벌기는 힘들다",
        "link": "https://jeho.page/essay/2025/01/22/making-a-difference.html",
        "pubDate": "2025-01-22T14:41:00.000Z",
        "author": "김재호",
        "content": "<p>Cursor로 코딩하니까 예전보다 분명 빨라졌는데 그래도 여전히 앱 하나 완성하기가 힘듭니다.<br />\n예전에는 이 힘든 노가다를 대체 어떻게 했는지 모르겠습니다.<br />\n그래서 그 많은 사람들이 매일 야근을 했던 걸까요?</p>\n\n<p>앱 개발이 쉬워진 건 분명하지만 돈 벌기까지 쉬워진 건 아닙니다. 돈 벌기는 항상 어려웠습니다.<br />\n오래전에 홈페이지만 만들면 몇백만 원 준다던 시절이 있었습니다. 그때도 돈 벌기는 어려웠을 겁니다.<br />\n그 시절에 컴퓨터를 가지고 있고 HTML 을 다룰 줄 안다는 것 자체가 특별한 일이었기에.<br />\n코딩을 하는 사람들이 많아지자 눈높이가 높아져 ajax를 이용한 복잡한 웹페이지를 만들어달라는 요구로 변해갔습니다.</p>\n\n<p>서비스를 잘 만들기만 하면 돈을 벌 수 있는 것은 아닙니다. <strong>경쟁자보다 더 잘 만들어야</strong> 돈을 벌 수 있습니다.<br />\n돈을 벌어주다 주는 것은 결국 <strong>차이</strong>인 것입니다. 기술의 차이, 사용자 경험의 차이. 마케팅의 차이. 서비스의 차이.<br />\nAI가 며칠 만에 만들어준 앱으로 돈 벌기는 어려울 겁니다. 차이를 만들어 낼 수 없으니까.</p>\n\n<p>예전에는 <a href=\"/essay/2021/09/05/코딩은-어렵다.html\">그 힘든 노가다</a>를 하던 것 자체가 해자였습니다.<br />\n앱을 만든다는 것이 너무 고통스러웠기 때문에.<br />\n그 고통을 견뎌낼 수 있는 사람이 적었기 때문에.<br />\n이제 앱을 완성하는 것 자체는 많이 쉬워졌습니다. 차이를 만들어 내려면 모든 면에서 예전보다 더 잘해야 합니다.</p>\n\n<p>3년쯤 지나면 이 시장이 어떻게 변해있을까요? 짐작도 가지 않습니다.<br />\n내가 언제까지 이 시장에서 살아남을 수 있을까? 이제 정말 끝물인 건 아닐까? 약간 초조한 마음도 듭니다.<br />\n지금이 마지막이라고 생각하고 하나라도 더 만들어봐야겠다는 생각입니다.<br />\n오늘 오랜만에 10시간 코딩을 했습니다. 다행인 것은 <a href=\"/essay/2024/12/23/writing-code.html\">AI로 코딩하면서도 꽤나 즐거웠다는 겁니다.</a></p>\n\n<p><br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2024/07/26/good-day.html\">코딩 많이 한 날</a></li>\n  <li><a href=\"/essay/2021/09/05/코딩은-어렵다.html\">코딩은 어렵다</a></li>\n</ul>",
        "contentSnippet": "Cursor로 코딩하니까 예전보다 분명 빨라졌는데 그래도 여전히 앱 하나 완성하기가 힘듭니다.\n앱 개발이 쉬워진 건 분명하지만 돈 벌기까지 쉬워진 건 아닙니다. 돈 벌기는 항상 어려웠습니다.\n서비스를 잘 만들기만 하면 돈을 벌 수 있는 것은 아닙니다. 경쟁자보다 더 잘 만들어야 돈을 벌 수 있습니다.\n차이인 것입니다. 기술의 차이, 사용자 경험의 차이. 마케팅의 차이. 서비스의 차이.\n예전에는 그 힘든 노가다를 하던 것 자체가 해자였습니다.\n3년쯤 지나면 이 시장이 어떻게 변해있을까요? 짐작도 가지 않습니다.\nAI로 코딩하면서도 꽤나 즐거웠다는 겁니다.\n\n함께 읽으면 좋은 글:\n코딩 많이 한 날\n코딩은 어렵다",
        "summary": "Cursor로 코딩하니까 예전보다 분명 빨라졌는데 그래도 여전히 앱 하나 완성하기가 힘듭니다. 예전에는 이 힘든 노가다를 대체 어떻게 했는지 모르겠습니다. 그래서 그 많은 사람들이 매일 야근을 했던 걸까요?",
        "id": "https://jeho.page/essay/2025/01/22/making-a-difference",
        "isoDate": "2025-01-22T14:41:00.000Z"
      },
      {
        "title": "인터넷을 처음 하던 날",
        "link": "https://jeho.page/essay/2025/01/21/internet-day1.html",
        "pubDate": "2025-01-21T09:55:00.000Z",
        "author": "김재호",
        "content": "<p>인터넷을 처음 접한 건 2000년 1월 1일이었습니다.<br />\n저 스스로도 놀라운 날짜입니다. 2000년 1월 1일이라니. 이런 우연이 다 있나..?<br />\n1990년대 내내 컴퓨터 앞에서 살았고, 1996년부터는 PC 통신도 많이 했습니다만, <strong>인터넷</strong>이라고 불리는 것은 한 번도 써보질 않았던 것입니다.</p>\n\n<p>1999년 말에는 2000년이 되면 밀레니엄 버그 때문에 난리가 날 거라고 떠들썩 했는데 막상 2000년 1월 1일이 되자 별다른 일은 일어나지 않았습니다.\n이 일이 어쩌면 영향이 있었던 건가? 처음으로 인터넷 익스플로러를 켜서 여기저기 사이트를 돌아다녔던 것 같습니다.</p>\n\n<p>와레즈라는 사이트를 그때 처음 알았습니다. 아니, 이런 세계가 있었단 말이야?<br />\nFIFA 2000을 다운로드하면서 잠이 들었었는데 50MB 쯤 되는 파일을 밤새도록 받았습니다.<br />\n(밤 10시부터 아침 9시까진가 통신 정액제가 있었던 것 같네요)</p>\n\n<p>다음 날 눈을 뜨자마자 반쯤 의심하며 실행해 봤는데 프로그램이 열리고 <a href=\"https://www.youtube.com/watch?v=ecrph82o6FU\">노래가 흘러나올 때</a> 두근거리고 기쁘던 감정을 아직 기억합니다.</p>\n\n<h1 id=\"인터넷과--pc--통신의-차이\">인터넷과  PC  통신의 차이</h1>\n<p>사실 저는 아직도 PC 통신과 인터넷의 차이를 잘 구분하지 못합니다만, 궁금해진 김에 챗지피티를 통해서 알아봤습니다.</p>\n\n<p>PC 통신은 TCP/IP로 연결했던 것이 아니라 시리얼 통신으로 연결했던 것 같습니다.<br />\n즉, 시리얼 포트에 모뎀을 꼽고 ‘01410’ 이란 번호로 전화 걸기 명령을 보내서 전화 연결을 하고, 서버에서는 역시 전화선을 통해 텍스트로 메뉴 구성을 알려줍니다.</p>\n\n<p>그 시절 PC 통신을 하기 위한 프로그램이었던 <code class=\"language-plaintext highlighter-rouge\">이야기</code>나 <code class=\"language-plaintext highlighter-rouge\">새롬데이터맨</code>은 다음처럼 짰을 것 같습니다.</p>\n\n<div class=\"language-c++ highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">HANDLE</span> <span class=\"n\">hCom</span> <span class=\"o\">=</span> <span class=\"n\">CreateFile</span><span class=\"p\">(</span>\n    <span class=\"s\">L\"COM1\"</span><span class=\"p\">,</span> <span class=\"c1\">// 모뎀이 꼽혀 있는 시리얼 포트</span>\n    <span class=\"n\">GENERIC_READ</span> <span class=\"o\">|</span> <span class=\"n\">GENERIC_WRITE</span><span class=\"p\">,</span>\n    <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"nb\">NULL</span><span class=\"p\">,</span>\n    <span class=\"n\">OPEN_EXISTING</span><span class=\"p\">,</span>\n    <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"nb\">NULL</span>\n<span class=\"p\">);</span>\n\n<span class=\"c1\">// 모뎀으로 전화 걸기 명령 전송 (하이텔의 전화번호 01410)</span>\n<span class=\"n\">WriteFile</span><span class=\"p\">(</span><span class=\"n\">hCom</span><span class=\"p\">,</span> <span class=\"s\">\"ATD01410</span><span class=\"se\">\\r\\n</span><span class=\"s\">\"</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">DWORD</span><span class=\"p\">)</span><span class=\"n\">strlen</span><span class=\"p\">(</span><span class=\"n\">atCmd</span><span class=\"p\">),</span> <span class=\"o\">&amp;</span><span class=\"n\">bytesWritten</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">);</span>\n\n<span class=\"c1\">// 서버로부터 ASCII 코드로 하이텔 대문을 받아와서 뿌려줌</span>\n\n<span class=\"c1\">// 메뉴 구성 보여주기</span>\n<span class=\"c1\">// (1) 게시판, (2) 자료실, (3) 채팅방</span>\n</code></pre></div></div>\n\n<p><code class=\"language-plaintext highlighter-rouge\">1</code>, <code class=\"language-plaintext highlighter-rouge\">2</code> 같은 메뉴의 번호를 별다른 프로토콜도 없이 raw string 에 가깝게 서버와 주고받았던 것 같네요.<br />\n채팅방 내에서 이상한 문자열을 입력해서 채팅방을 강제로 파괴하던 사람들이 있었는데, 이제야 어떻게 했는지 알 것 같습니다.</p>\n\n<p>지금 보면 참 조잡하지만, 이때 코딩하던 개발자들은 정말 신기하고 재밌었을 것 같습니다.<br />\n아마 새로운 세상을 창조해낸 기분 아니었을까?<br />\nPC 통신이 처음 시작되던 시절에 그런 기쁨을 함께 느껴보지 못했다는 게 아쉽습니다.</p>\n\n<p><img src=\"/assets/img/kitel.jpg\" alt=\"PC통신의 역사\" /><br />\n<em>넥슨컴퓨터 박물관, 2022년</em></p>\n\n<p><br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2022/11/05/old-memories-of-computers.html\">허큘리스 카드와 사운드 블라스터 그리고 PC통신</a></li>\n  <li><a href=\"https://brunch.co.kr/@buildingking/107\">넥슨 컴퓨터 박물관에 가는 날</a></li>\n</ul>",
        "contentSnippet": "인터넷을 처음 접한 건 2000년 1월 1일이었습니다.\n인터넷이라고 불리는 것은 한 번도 써보질 않았던 것입니다.\n1999년 말에는 2000년이 되면 밀레니엄 버그 때문에 난리가 날 거라고 떠들썩 했는데 막상 2000년 1월 1일이 되자 별다른 일은 일어나지 않았습니다.\n이 일이 어쩌면 영향이 있었던 건가? 처음으로 인터넷 익스플로러를 켜서 여기저기 사이트를 돌아다녔던 것 같습니다.\n와레즈라는 사이트를 그때 처음 알았습니다. 아니, 이런 세계가 있었단 말이야?\n다음 날 눈을 뜨자마자 반쯤 의심하며 실행해 봤는데 프로그램이 열리고 노래가 흘러나올 때 두근거리고 기쁘던 감정을 아직 기억합니다.\n인터넷과  PC  통신의 차이\n사실 저는 아직도 PC 통신과 인터넷의 차이를 잘 구분하지 못합니다만, 궁금해진 김에 챗지피티를 통해서 알아봤습니다.\nPC 통신은 TCP/IP로 연결했던 것이 아니라 시리얼 통신으로 연결했던 것 같습니다.\n그 시절 PC 통신을 하기 위한 프로그램이었던 이야기나 새롬데이터맨은 다음처럼 짰을 것 같습니다.\n\nHANDLE hCom = CreateFile(\n    L\"COM1\", // 모뎀이 꼽혀 있는 시리얼 포트\n    GENERIC_READ | GENERIC_WRITE,\n    0,\n    NULL,\n    OPEN_EXISTING,\n    0,\n    NULL\n);\n\n// 모뎀으로 전화 걸기 명령 전송 (하이텔의 전화번호 01410)\nWriteFile(hCom, \"ATD01410\\r\\n\", (DWORD)strlen(atCmd), &bytesWritten, NULL);\n\n// 서버로부터 ASCII 코드로 하이텔 대문을 받아와서 뿌려줌\n\n// 메뉴 구성 보여주기\n// (1) 게시판, (2) 자료실, (3) 채팅방\n\n\n1, 2 같은 메뉴의 번호를 별다른 프로토콜도 없이 raw string 에 가깝게 서버와 주고받았던 것 같네요.\n지금 보면 참 조잡하지만, 이때 코딩하던 개발자들은 정말 신기하고 재밌었을 것 같습니다.\n\n넥슨컴퓨터 박물관, 2022년\n\n함께 읽으면 좋은 글:\n허큘리스 카드와 사운드 블라스터 그리고 PC통신\n넥슨 컴퓨터 박물관에 가는 날",
        "summary": "인터넷을 처음 접한 건 2000년 1월 1일이었습니다. 저 스스로도 놀라운 날짜입니다. 2000년 1월 1일이라니. 이런 우연이 다 있나..? 1990년대 내내 컴퓨터 앞에서 살았고, 1996년부터는 PC 통신도 많이 했습니다만, 인터넷이라고 불리는 것은 한 번도 써보질 않았던 것입니다.",
        "id": "https://jeho.page/essay/2025/01/21/internet-day1",
        "isoDate": "2025-01-21T09:55:00.000Z"
      },
      {
        "title": "팀장님의 칭찬",
        "link": "https://jeho.page/essay/2025/01/20/praise-from-roy.html",
        "pubDate": "2025-01-20T08:54:00.000Z",
        "author": "김재호",
        "content": "<p>오랜만에 예전 팀 사람들과 점심을 함께했습니다.<br />\n거의 10년 가까이 못 본 친구들도 있었고, 우리 모두에게 존경받던 팀장님도 함께했습니다.</p>\n\n<p>다들 존경하고 우러러보던 팀장님의 그 시절 한 마디는 힘이 셌습니다.<br />\n팀장님이 뭔가 질문을 하면 다들 뜨끔할 정도로.</p>\n\n<p>중요한 뭔가를 놓치고 있거나, 흐리멍텅하게 일하고 있을 때.<br />\n긴장이 풀려있을 때면 어김없이 팀장님의 질문이 날아왔습니다.</p>\n\n<p>“벤자민, 이런 이런 부분도 고려하고 있는거니?”</p>\n\n<p>말이 질문이지, 사실은 정신 똑바로 차리고 일하라는 가르침이었습니다.</p>\n\n<p>다들 사고를 많이 쳐서 혼나기 일쑤였습니다만, 가끔 팀장이 칭찬을 해주실 때도 있었습니다.<br />\n누군가 칭찬을 받으면 팀원 모두가 부러워했습니다. 우와 팀장님한테 칭찬을 다 들었네.</p>\n\n<p>오늘 점심을 먹으면서 팀장님에게 칭찬을 들었습니다.<br />\n블로그 잘 읽고 있는데, 생각이 탄탄해서 좋다고.<br />\n팀장님도 미처 생각해보지 못한 이야기들이 있다고.<br />\n10년 전에 알던 저와는 많이 달라졌다고.</p>\n\n<p>우와, 이거 최고의 칭찬인 걸.<br />\n팀장님께 생각이 탄탄하단 소리를 듣다니.<br />\n같이 있던 동료들이 부러운 눈으로 쳐다봤습니다. 마치 10년 전 우리들처럼.</p>\n\n<p>저도 입이 찢어졌습니다.<br />\n회사 그만두고 혼자 지내면서 성장이 멈췄다고 생각했는데 그렇지 않았구나.<br />\n어쩌면 혼자 지내면서 더 많이 성장하게 된 건 아닐까?</p>\n\n<p>아무리 생각해도 기분이 좋아서 헤어지고 나서도 종일 헤벌쭉 해있는 걸 보니 저는 아직도 어린애입니다.(웃음)</p>\n\n<p><br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2021/09/10/왜-막내들은-항상-바깥쪽-자리에-앉아야-하나요.html\">왜 막내들은 항상 바깥쪽 자리에 앉아야 하나요?</a></li>\n  <li><a href=\"/essay/2021/11/02/윗사람과-아랫사람.html\">윗사람과 아랫사람</a></li>\n</ul>",
        "contentSnippet": "오랜만에 예전 팀 사람들과 점심을 함께했습니다.\n다들 존경하고 우러러보던 팀장님의 그 시절 한 마디는 힘이 셌습니다.\n중요한 뭔가를 놓치고 있거나, 흐리멍텅하게 일하고 있을 때.\n“벤자민, 이런 이런 부분도 고려하고 있는거니?”\n말이 질문이지, 사실은 정신 똑바로 차리고 일하라는 가르침이었습니다.\n다들 사고를 많이 쳐서 혼나기 일쑤였습니다만, 가끔 팀장이 칭찬을 해주실 때도 있었습니다.\n오늘 점심을 먹으면서 팀장님에게 칭찬을 들었습니다.\n우와, 이거 최고의 칭찬인 걸.\n저도 입이 찢어졌습니다.\n아무리 생각해도 기분이 좋아서 헤어지고 나서도 종일 헤벌쭉 해있는 걸 보니 저는 아직도 어린애입니다.(웃음)\n\n함께 읽으면 좋은 글:\n왜 막내들은 항상 바깥쪽 자리에 앉아야 하나요?\n윗사람과 아랫사람",
        "summary": "오랜만에 예전 팀 사람들과 점심을 함께했습니다. 거의 10년 가까이 못 본 친구들도 있었고, 우리 모두에게 존경받던 팀장님도 함께했습니다.",
        "id": "https://jeho.page/essay/2025/01/20/praise-from-roy",
        "isoDate": "2025-01-20T08:54:00.000Z"
      }
    ]
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "마윈이 기분 좋았던 시절의 이야기 / 특공 물 음식 하지만 공기는 ...",
        "link": "http://serverdown.tistory.com/1121",
        "pubDate": "Sat, 25 Jan 2025 19:48:53 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1121#entry1121comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://youtu.be/eemg-ZEKyrM?t=1392\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://youtu.be/eemg-ZEKyrM?t=1392</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=eemg-ZEKyrM\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bT5MsM/hyX7UGeJqc/FBc1quUA2J32wuiq3IU8v1/img.jpg?width=1280&amp;height=720&amp;face=108_116_206_224,https://scrap.kakaocdn.net/dn/c5pPvr/hyX4xeQI8V/tqDekVgK9Yf2Q6GGgv4eq1/img.jpg?width=1280&amp;height=720&amp;face=108_116_206_224\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"중국발 미세먼지 무엇을 상상하든 상상 그 이상입니다...!\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/eemg-ZEKyrM\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">23분에 나옵니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">특별한 상위 계급들은 건강에 관련된 물건은 특별이 공급 (특공) 받습니다.</p>\n<p data-ke-size=\"size16\">일반인들은 오염된 음식과 물을 먹고 살고 있지요</p>\n<p data-ke-size=\"size16\">하지만&nbsp;오늘은 기분이 매우 좋습니다.</p>\n<p data-ke-size=\"size16\">공기는 특공 할 수 없습니다.</p>",
        "contentSnippet": "영상: https://youtu.be/eemg-ZEKyrM?t=1392\n\n\n\n23분에 나옵니다.\n \n특별한 상위 계급들은 건강에 관련된 물건은 특별이 공급 (특공) 받습니다.\n일반인들은 오염된 음식과 물을 먹고 살고 있지요\n하지만 오늘은 기분이 매우 좋습니다.\n공기는 특공 할 수 없습니다.",
        "guid": "http://serverdown.tistory.com/1121",
        "categories": [
          "유튜브",
          "특공"
        ],
        "isoDate": "2025-01-25T10:48:53.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "재판의 결과가 이상하게 나오는 이유 / 솜방망이",
        "link": "http://serverdown.tistory.com/1120",
        "pubDate": "Sat, 25 Jan 2025 01:20:04 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1120#entry1120comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/shorts/EyO5PSV8Wow\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/shorts/EyO5PSV8Wow</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/shorts/EyO5PSV8Wow\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/f3ydT/hyX4oa4H38/Epxp8v1AAN3lSKIYVvhfE0/img.jpg?width=405&amp;height=720&amp;face=142_237_272_379,https://scrap.kakaocdn.net/dn/cunsIg/hyX7SVRIZb/evqbthtcjago2nwzf86Ej0/img.jpg?width=405&amp;height=720&amp;face=142_237_272_379\" data-video-width=\"405\" data-video-height=\"720\" data-video-origin-width=\"405\" data-video-origin-height=\"720\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"한국 판결이 이상한 이유\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/EyO5PSV8Wow\" width=\"405\" height=\"720\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">특수한 선례를 남겨야</p>\n<p data-ke-size=\"size16\">은퇴후 로펌에 들어가서 그 판례를 이용해 빠저나가는 결과를 만들 수 있다고 합니다.</p>\n<p data-ke-size=\"size16\">즉 돈이 되기 때문입니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/shorts/EyO5PSV8Wow\n\n\n\n특수한 선례를 남겨야\n은퇴후 로펌에 들어가서 그 판례를 이용해 빠저나가는 결과를 만들 수 있다고 합니다.\n즉 돈이 되기 때문입니다.",
        "guid": "http://serverdown.tistory.com/1120",
        "categories": [
          "유튜브"
        ],
        "isoDate": "2025-01-24T16:20:04.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "2차전지 바닥이다",
        "link": "http://serverdown.tistory.com/1119",
        "pubDate": "Thu, 23 Jan 2025 19:16:29 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1119#entry1119comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=QroRBwk7cYw&amp;t=3s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=QroRBwk7cYw&amp;t=3s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=QroRBwk7cYw\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/6geJs/hyX4q7CuXW/5BMFhLa3kkd88QC1pAvYKK/img.jpg?width=1280&amp;height=720&amp;face=858_160_994_308,https://scrap.kakaocdn.net/dn/JTZXM/hyX4r6xDS5/P7fqQbwFhAEekZSKO8uocK/img.jpg?width=1280&amp;height=720&amp;face=858_160_994_308\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"2차전지 '트럼프 쇼크' 진실은? / 윤석천 경제평론가 [대담한 대담] | Market Now 2 (20250123)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/QroRBwk7cYw\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">트럼프가 여러가지로저질렀는데</p>\n<p data-ke-size=\"size16\">그런다고 팔면 안됩니다.&nbsp;</p>\n<p data-ke-size=\"size16\">트럼프 취임과 동시에 전기자동차 보조금 패지로<br />모든 악재가 나왔습니다.</p>\n<p data-ke-size=\"size16\">이제 무슨 악재가 있겠습니까?</p>\n<p data-ke-size=\"size16\">트럼프가 베터리는 중국게 싸니까 그거 쓰세요 라고 하겠습니까?<br />(실제로 그런 방향으로 간다고 해도 말은 안할 것입니다.)</p>\n<p data-ke-size=\"size16\">호재를 봅시다.</p>\n<p data-ke-size=\"size16\">1. 정부 반도체 / 2차전지 직접투자 50조원</p>\n<p data-ke-size=\"size16\">아예 직접 투자해버린다는군요.<br />못올라도 바닥은 이걸로 지켜질 것입니다.</p>\n<p data-ke-size=\"size16\">2. AI 테마</p>\n<p data-ke-size=\"size16\">드론 자율주행 로봇 모든 산업은 더 좋은 베터리를 사용해야합니다.<br />전기차 보다도 훨씬 안전한 베터리를 써야하는 환경이기 때문입니다.</p>\n<p data-ke-size=\"size16\">3. BYD 한국 상륙</p>\n<p data-ke-size=\"size16\">이젠 경쟁을 해야합니다.<br />이것은 악재가 아니고 호재입니다.</p>\n<p data-ke-size=\"size16\">이전에는 경쟁할 필요가 없었습니다. 국가도 전기차 보급의 의지도 없었구요.<br />이제 보조금을 잘못 쓰면 중국차를 파는데 도와주는 꼴이기 때문에 방법이 없습니다.</p>\n<p data-ke-size=\"size16\">BYD 는 렌터카쪽을 치고 장악을 시작할 것입니다.</p>\n<p data-ke-size=\"size16\">매국노가 아닌이상 한국 업계에 유리하도록 보조금을 차별해야합니다.<br />착한 선비 정신이 나올때가 아닙니다.</p>\n<p data-ke-size=\"size16\">이젠 정말 정부에서 움직임이 절실한 상황입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=QroRBwk7cYw&t=3s\n\n\n\n트럼프가 여러가지로저질렀는데\n그런다고 팔면 안됩니다. \n트럼프 취임과 동시에 전기자동차 보조금 패지로\n모든 악재가 나왔습니다.\n이제 무슨 악재가 있겠습니까?\n트럼프가 베터리는 중국게 싸니까 그거 쓰세요 라고 하겠습니까?\n(실제로 그런 방향으로 간다고 해도 말은 안할 것입니다.)\n호재를 봅시다.\n1. 정부 반도체 / 2차전지 직접투자 50조원\n아예 직접 투자해버린다는군요.\n못올라도 바닥은 이걸로 지켜질 것입니다.\n2. AI 테마\n드론 자율주행 로봇 모든 산업은 더 좋은 베터리를 사용해야합니다.\n전기차 보다도 훨씬 안전한 베터리를 써야하는 환경이기 때문입니다.\n3. BYD 한국 상륙\n이젠 경쟁을 해야합니다.\n이것은 악재가 아니고 호재입니다.\n이전에는 경쟁할 필요가 없었습니다. 국가도 전기차 보급의 의지도 없었구요.\n이제 보조금을 잘못 쓰면 중국차를 파는데 도와주는 꼴이기 때문에 방법이 없습니다.\nBYD 는 렌터카쪽을 치고 장악을 시작할 것입니다.\n매국노가 아닌이상 한국 업계에 유리하도록 보조금을 차별해야합니다.\n착한 선비 정신이 나올때가 아닙니다.\n이젠 정말 정부에서 움직임이 절실한 상황입니다.",
        "guid": "http://serverdown.tistory.com/1119",
        "categories": [
          "투자",
          "2차전지"
        ],
        "isoDate": "2025-01-23T10:16:29.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "시위대안에 중국 프락치 있다.",
        "link": "http://serverdown.tistory.com/1118",
        "pubDate": "Thu, 23 Jan 2025 01:24:44 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1118#entry1118comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=cMwL2ncb3Us\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=cMwL2ncb3Us</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=cMwL2ncb3Us\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bfMVFc/hyX4wsXg5O/IHXrsCBh3kANyJuRJap2l0/img.jpg?width=1280&amp;height=720&amp;face=570_174_730_348,https://scrap.kakaocdn.net/dn/BtT4D/hyX4p1FlE1/wrno57NcurGezkZGXXbS81/img.jpg?width=1280&amp;height=720&amp;face=570_174_730_348\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"[단독] 서부지법 폭동 당시 분열을 주도하던 중국인...? 서부지법 폭력사태의 소름돋는 진실\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/cMwL2ncb3Us\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">억양도 중국 억양이고</p>\n<p data-ke-size=\"size16\">하지말라는데 잘보이는데 굳이 올라가서 위험한 짓하고</p>\n<p data-ke-size=\"size16\">의도된 움직임으로 보입니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=cMwL2ncb3Us\n\n\n\n억양도 중국 억양이고\n하지말라는데 잘보이는데 굳이 올라가서 위험한 짓하고\n의도된 움직임으로 보입니다.",
        "guid": "http://serverdown.tistory.com/1118",
        "categories": [
          "유튜브",
          "간첩"
        ],
        "isoDate": "2025-01-22T16:24:44.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "MBC 에 간첩 편집자가 있다.",
        "link": "http://serverdown.tistory.com/1117",
        "pubDate": "Thu, 23 Jan 2025 01:09:51 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1117#entry1117comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=tUIuuwL9cnk\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=tUIuuwL9cnk</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=tUIuuwL9cnk\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/xsDch/hyX4vU9l83/xYtyqYkOd62k2zMGdAm3Dk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/2kcXJ/hyX4zJOFiB/Tb67J8nBwr1Kf9GVQagq50/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"방송사고 뭔데?\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/tUIuuwL9cnk\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">뭔가 이상한게 자꾸 뜨는데 ...</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">간첩 관련된 자막이 나온적이 있다거나</p>\n<p data-ke-size=\"size16\">뭔가 자꾸 편집과정에서 뭔가가 들어가고 있다는 주장</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">시대를 관통하는 방송</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">파란 노랑 초록은 부정선거 관련 내용입니다.</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=zUE9t4CRGO4\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=zUE9t4CRGO4</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=zUE9t4CRGO4\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/HlXjG/hyX4uPt2hW/IdPhMUce8vZk21sUpQ6Vik/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/b34GMn/hyX4wNkDcR/OZODf6wk2IG3jbWk7kWxsk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"이건 100% 부정선거야!!\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/zUE9t4CRGO4\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">7분 20초에 나옵니다.</p>\n<p data-ke-size=\"size16\">프린터 특성에 맞지 않는 투표용지가 발견되었다는 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=tUIuuwL9cnk\n\n\n\n뭔가 이상한게 자꾸 뜨는데 ...\n \n간첩 관련된 자막이 나온적이 있다거나\n뭔가 자꾸 편집과정에서 뭔가가 들어가고 있다는 주장\n \n시대를 관통하는 방송\n \n파란 노랑 초록은 부정선거 관련 내용입니다.\n영상: https://www.youtube.com/watch?v=zUE9t4CRGO4\n\n\n\n7분 20초에 나옵니다.\n프린터 특성에 맞지 않는 투표용지가 발견되었다는 것입니다.",
        "guid": "http://serverdown.tistory.com/1117",
        "categories": [
          "유튜브",
          "방송사고"
        ],
        "isoDate": "2025-01-22T16:09:51.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "AI 에이전트에 대한 사업 내용에 대해 알아보자",
        "link": "http://serverdown.tistory.com/1116",
        "pubDate": "Wed, 22 Jan 2025 22:14:14 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1116#entry1116comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=rFPRStDYGIQ\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=rFPRStDYGIQ</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=rFPRStDYGIQ\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bNKzZm/hyX4mRrBZw/BeCgylyoTXIl0zcp3XvIjK/img.jpg?width=1280&amp;height=720&amp;face=986_90_1186_308,https://scrap.kakaocdn.net/dn/oSEQv/hyX4ws0uBE/w9Nu0sRZ8doliyNAmWbxB1/img.jpg?width=1280&amp;height=720&amp;face=986_90_1186_308\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"&quot;30배 넘는 시장 열린다&quot; 이 주식, 제2의 테슬라, 엔비디아 된다｜강정수 박사 3부\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/rFPRStDYGIQ\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">이제 실생활에 사용할 수 있을 정도로 AI 가 발전하였습니다.</p>\n<p data-ke-size=\"size16\">6분부터 사례가 나옵니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">마이크로소프트</h2>\n<p data-ke-size=\"size16\">이메일 분류 해서 담당에게 전달하는 프로그램을 AI 가 만들었다고 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">애플</h2>\n<p data-ke-size=\"size16\">말로 표예약 취소 같은걸 하려고 한다 (아직안했군요)</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">클라나 - <span style=\"text-align: start;\">유럽</span></h2>\n<p data-ke-size=\"size16\">고객응대의 80%를 AI 로 대처함, 2천명 해고</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">메타</h2>\n<p data-ke-size=\"size16\">광고가 클릭이 잘되도록 AI 적용</p>\n<p data-ke-size=\"size16\">광고를 하는 고객들에게 제품설명을 넣으면 아예 광고 페이지도 만들어내는 기능을 제공</p>\n<p data-ke-size=\"size16\">광고도 만들어주고</p>\n<p data-ke-size=\"size16\">관리페이지도 만들어주고</p>\n<p data-ke-size=\"size16\">회계업무도 대신 처리</p>\n<p data-ke-size=\"size16\">좋게보나봅니다. 설명이 길군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">아마존</h2>\n<p data-ke-size=\"size16\">전용 프로세서 개발</p>\n<p data-ke-size=\"size16\">AI 서비스 개발</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">테슬라</h2>\n<p data-ke-size=\"size16\">본인들 회사에 쓸 로봇 대량 생산</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">아무튼 이제 실생활에 적용될 시점입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">삼성전자</h2>\n<p data-ke-size=\"size16\">젠승황 말을 잘 생각해보면 HBM3 는 실패했다고 봐야한다고 합니다.</p>\n<p data-ke-size=\"size16\">올해는 글렀습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">&nbsp;</h2>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=rFPRStDYGIQ\n\n\n\n이제 실생활에 사용할 수 있을 정도로 AI 가 발전하였습니다.\n6분부터 사례가 나옵니다.\n \n마이크로소프트\n이메일 분류 해서 담당에게 전달하는 프로그램을 AI 가 만들었다고 합니다.\n \n애플\n말로 표예약 취소 같은걸 하려고 한다 (아직안했군요)\n \n클라나 - 유럽\n고객응대의 80%를 AI 로 대처함, 2천명 해고\n \n메타\n광고가 클릭이 잘되도록 AI 적용\n광고를 하는 고객들에게 제품설명을 넣으면 아예 광고 페이지도 만들어내는 기능을 제공\n광고도 만들어주고\n관리페이지도 만들어주고\n회계업무도 대신 처리\n좋게보나봅니다. 설명이 길군요\n \n아마존\n전용 프로세서 개발\nAI 서비스 개발\n \n테슬라\n본인들 회사에 쓸 로봇 대량 생산\n \n아무튼 이제 실생활에 적용될 시점입니다.\n \n삼성전자\n젠승황 말을 잘 생각해보면 HBM3 는 실패했다고 봐야한다고 합니다.\n올해는 글렀습니다.",
        "guid": "http://serverdown.tistory.com/1116",
        "categories": [
          "투자",
          "Ai",
          "인공지능"
        ],
        "isoDate": "2025-01-22T13:14:14.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "코인 하락장이 오면 이렇게 됩니다.",
        "link": "http://serverdown.tistory.com/1115",
        "pubDate": "Mon, 20 Jan 2025 21:29:24 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1115#entry1115comment",
        "content": "<p data-ke-size=\"size16\">저는 2025년 3월까지만 코인할 생각인데요</p>\n<p data-ke-size=\"size16\">결국 어느날 하락장이 올것입니다.</p>\n<p data-ke-size=\"size16\">그때가 되면 어떻게 되는지 알아두는 것은 매우 중요한 일입니다.</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/shorts/jmRU026r7YQ\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/shorts/jmRU026r7YQ</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/shorts/jmRU026r7YQ\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/b1e8UQ/hyX4tvI6m0/1EqwWe1aK2bsuMtNik8Kgk/img.jpg?width=405&amp;height=720&amp;face=38_115_310_391,https://scrap.kakaocdn.net/dn/3eMts/hyX4kMjOcQ/lIKmKjtqSNPGDDZMSPhGG1/img.jpg?width=405&amp;height=720&amp;face=38_115_310_391\" data-video-width=\"405\" data-video-height=\"720\" data-video-origin-width=\"405\" data-video-origin-height=\"720\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"불장에 졸업못한 사람 특  #shorts #비트코인\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/jmRU026r7YQ\" width=\"405\" height=\"720\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "저는 2025년 3월까지만 코인할 생각인데요\n결국 어느날 하락장이 올것입니다.\n그때가 되면 어떻게 되는지 알아두는 것은 매우 중요한 일입니다.\n영상: https://www.youtube.com/shorts/jmRU026r7YQ",
        "guid": "http://serverdown.tistory.com/1115",
        "categories": [
          "코인",
          "코인"
        ],
        "isoDate": "2025-01-20T12:29:24.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "일본의 초밥 자판기 / 곱창 자판기 (망함)",
        "link": "http://serverdown.tistory.com/1114",
        "pubDate": "Sun, 19 Jan 2025 23:37:28 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1114#entry1114comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=RZkb9Aptv9g\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=RZkb9Aptv9g</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=RZkb9Aptv9g\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cmGaGY/hyX4unEISc/ILuJpmQEBWHyi9TDDPzIy0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/0KWYl/hyX0lTqUYj/zQdMzxbGUkm0UZsgwkKqr0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"일본 동네 초밥 자판기에서 초밥을 사보았다\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/RZkb9Aptv9g\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">어떻게 파나 싶어서 봤는데</p>\n<p data-ke-size=\"size16\">냉동이라고 합니다.</p>\n<p data-ke-size=\"size16\">뜨거운물을 밑에 채워두고 30분 기다리면 먹을만하게 녹는다고 합니다.</p>\n<p data-ke-size=\"size16\">유통기한은 6개월 정도</p>\n<p data-ke-size=\"size16\">가격은 13,000 엔</p>\n<p data-ke-size=\"size16\">기술 좋네요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">곱창 자판기: <a href=\"https://www.youtube.com/watch?v=-nQA1meAVc8\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=-nQA1meAVc8</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=-nQA1meAVc8\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/fO2fa/hyX4xq9rlC/76fBFwCeLz3qtgA6AsK0c0/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360,https://scrap.kakaocdn.net/dn/REN6a/hyX0uCRjRs/BwVHKSEpEbU1353ZWsCp40/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360\" data-video-width=\"480\" data-video-height=\"360\" data-video-origin-width=\"480\" data-video-origin-height=\"360\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"일본 동네에 있는 곱창 자판기 이용해보기 [+혼술 먹방]\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/-nQA1meAVc8\" width=\"480\" height=\"360\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">는 망했다고 합니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=RZkb9Aptv9g\n\n\n\n어떻게 파나 싶어서 봤는데\n냉동이라고 합니다.\n뜨거운물을 밑에 채워두고 30분 기다리면 먹을만하게 녹는다고 합니다.\n유통기한은 6개월 정도\n가격은 13,000 엔\n기술 좋네요\n \n곱창 자판기: https://www.youtube.com/watch?v=-nQA1meAVc8\n\n\n\n는 망했다고 합니다.",
        "guid": "http://serverdown.tistory.com/1114",
        "categories": [
          "유튜브",
          "여행",
          "일본"
        ],
        "isoDate": "2025-01-19T14:37:28.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "깡통 7번 차고 배운점 / 투자 실패 스토리",
        "link": "http://serverdown.tistory.com/1113",
        "pubDate": "Sun, 19 Jan 2025 23:25:08 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1113#entry1113comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=w4tmHlvSidA\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=w4tmHlvSidA</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=w4tmHlvSidA\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bbkumQ/hyX4Ag7cDD/vIrmoPWQoFBjc2sSVTmBmk/img.jpg?width=1280&amp;height=720&amp;face=410_134_992_500,https://scrap.kakaocdn.net/dn/qnCHg/hyX4mQGrYw/OqQtSEbryKdZQenChGwv3K/img.jpg?width=1280&amp;height=720&amp;face=410_134_992_500\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"깡통 7번 차고 죽을 만큼 힘들었어요! &quot;실패에서 배운 성공 투자 기법&quot; / 무조건 피해야 할 1가지 (\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/w4tmHlvSidA\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">들어볼만합니다.</p>\n<p data-ke-size=\"size16\">하다보면 잘 될때가 있습니다.</p>\n<p data-ke-size=\"size16\">꼭 그럴때 욕심을 잘 조절해야합니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=w4tmHlvSidA\n\n\n\n들어볼만합니다.\n하다보면 잘 될때가 있습니다.\n꼭 그럴때 욕심을 잘 조절해야합니다.",
        "guid": "http://serverdown.tistory.com/1113",
        "categories": [
          "투자",
          "주식",
          "투자"
        ],
        "isoDate": "2025-01-19T14:25:08.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": []
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "한상곤 - Sigmadream",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "사용성을 지키면서 광고 매출 극대화하기, 가능할까요?",
        "link": "https://techblog.lycorp.co.jp/ko/maximizing-ad-revenue-while-preserving-usability",
        "pubDate": "Fri, 24 Jan 2025 02:00:00 GMT",
        "content": "안녕하세요. LINE Plus ABC Studio 기획자 한영주입니다. 저는 일본 최대 규모의 배달 서비스인 데마에칸(Demaecan, 出前館) 앱을 기획하고 있습니다.\n한국의 배...",
        "contentSnippet": "안녕하세요. LINE Plus ABC Studio 기획자 한영주입니다. 저는 일본 최대 규모의 배달 서비스인 데마에칸(Demaecan, 出前館) 앱을 기획하고 있습니다.\n한국의 배...",
        "guid": "https://techblog.lycorp.co.jp/ko/maximizing-ad-revenue-while-preserving-usability",
        "isoDate": "2025-01-24T02:00:00.000Z"
      },
      {
        "title": "코드 품질 개선 기법 4편: 문을 없애고 테스트하기",
        "link": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-4",
        "pubDate": "Wed, 22 Jan 2025 02:00:00 GMT",
        "content": "안녕하세요. 커뮤니케이션 앱 LINE의 모바일 클라이언트를 개발하고 있는 Ishikawa입니다.\n저희 회사는 높은 개발 생산성을 유지하기 위해 코드 품질 및 개발 문화 개선에 힘쓰...",
        "contentSnippet": "안녕하세요. 커뮤니케이션 앱 LINE의 모바일 클라이언트를 개발하고 있는 Ishikawa입니다.\n저희 회사는 높은 개발 생산성을 유지하기 위해 코드 품질 및 개발 문화 개선에 힘쓰...",
        "guid": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-4",
        "isoDate": "2025-01-22T02:00:00.000Z"
      },
      {
        "title": "3단계로 완성하는 유연한 디자인 시스템",
        "link": "https://techblog.lycorp.co.jp/ko/a-flexible-design-system-using-3-tier-tokens",
        "pubDate": "Mon, 20 Jan 2025 03:00:00 GMT",
        "content": "안녕하세요. LINE Plus ABC Studio에서 일본 음식 배달 서비스 Demaecan(出前館, 이하 데마에칸)의 디자인을 담당하고 있고, 사용자의 다양한 목소리를 담을 수 ...",
        "contentSnippet": "안녕하세요. LINE Plus ABC Studio에서 일본 음식 배달 서비스 Demaecan(出前館, 이하 데마에칸)의 디자인을 담당하고 있고, 사용자의 다양한 목소리를 담을 수 ...",
        "guid": "https://techblog.lycorp.co.jp/ko/a-flexible-design-system-using-3-tier-tokens",
        "isoDate": "2025-01-20T03:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "세상의 모든 큰 것은 아주 작은 것에서 시작된다",
        "link": "https://www.thestartupbible.com/2025/01/big-things-come-from-small-beginnings.html",
        "pubDate": "Wed, 22 Jan 2025 21:29:00 +0000",
        "content:encodedSnippet": "한인이 창업했고, 창업 5년 만에 한화로 거의 1조 원에 인수된 화장품 회사 Hero Cosmetics(Hero)의 팟캐스트를 얼마 전에 흥미롭게 들었다. 창업가들의 이야기는 그 결말이 해피엔딩이든 새드엔딩이든 항상 배울 점들이 많아서 재미있고, 한국에 사는 분들에겐 너무나 익숙한 여드름 패치 하나로 시작해서 1조 원짜리 회사를 만들어서 Church and Dwight에 매각한 이야기도 웬만한 케이드라마보다 더 흥미로웠다.\n이 팟캐스트를 며칠에 걸쳐 아침에 운동하면서 계속 들었는데, 그 기간 우리 투자사 대표와 미팅하면서, 이분이 하는 사업은 화장품 분야와는 완전히 다르지만, Hero가 고민하고 거쳐 온 과정에 대해서 같이 이야기하고, 나름대로 고민의 공통점들을 찾고 해답도 같이 찾는 이야기를 꽤 많이 했다.\nHero는 Mighty Patch라는 여드름 패치 제품 하나로 시작했고, 한국에서 만든 이 제품을 온, 오프라인 상점에서 팔기 시작했는데, 얼마 안 지나서 이 카테고리에서는 거의 1등 제품이 됐다. 1등 제품이긴 했지만, 없던 시장을 만들었기 때문에 일단 시장 자체가 작았고, 투자도 받고 사람도 더 고용하기 위해서 회사는 계속 성장을 해야 했다. 여기서 Hero의 창업가들은 더 큰 성장을 하기 위해서 여드름 패치보다 훨씬 큰 시장인 일반 화장품 분야로 확장하는 고민을 했다. 어차피 큰 카테고리로 보면 모두 다 화장품과 뷰티 분야였고, 다른 화장품도 한국의 공장에서 제조하기 때문에 제조사 소싱도 용이했다. 그리고 어느 시점에는 일반 화장품/뷰티 쪽으로 확장하는 게 너무 자연스러운 성장 공식이라서 여드름 패치 판매 시작 1년 후에 이런 고민을 했다.\n하지만, 이들이 내린 결론은, 일단 여드름 패치 분야에만 당분간 집중하는 것이었다. 여드름 패치 분야에서 더 많은, 더 좋은 제품을 더 싸게 판매해서 아예 다른 경쟁사들이 넘보지도 못할 정도로 압도적인 1등이 되고, 미국에서 말하는 소위 category dominator가 된 후에 다른 화장품 분야로 확장하기로 했다. 그리고 그 이후에 같은 여드름 패치를 다양한 색상, 다양한 용도, 그리고 다양한 크기로 만들어서 SKU를 다각화했고, 판매 채널 또한 온, 오프라인 모든 곳으로 확장했다. 이렇게 한 결과, 여드름 패치로만 연 매출 수백억 원대를 달성할 수 있었고, 이 정도의 매출을 하니 이 분야에서는 압도적인 1등이 됐고, 이 category dominator 해자(垓字)를 구축한 후에 다른 화장품 분야로 조금은 더 수월하고 편하게 진출했다.\n위에서 이야기했던 우리 투자사 대표도 이와 비슷한 고민을 하고 있었고, 아마도 꽤 많은 창업가들이 이런 고민을 하는 걸로 알고 있다. 아주 힘들게 한 분야를 열심히 팠고, 꽤 오랜 시간 동안 기반을 닦아 놓으니, 이 분야에서 돈을 내는 고객도 생기고, 아주 빠르진 않지만, 고객에게 서서히 입소문이 나면서 어느 순간 이 분야에서 꽤 알아주는 제품을 만드는 회사가 된 경우를 우린 자주 본다. 그런데 지금 내가 집중하고 있는 시장보다 훨씬 더 큰 수천억 원 ~ 수조 원짜리 시장에서 훨씬 더 빠르게 성장하고 싶어서, 완전히 다른 시장, 또는 같은 시장에서 다른 카테고리를 계속 기웃거리는 창업가들이 꽤 많다.\n이분들에게 내가 주로 하는 조언은 항상 비슷하다. Hero의 전략으로 가라고 한다. 즉, 내가 시작한 분야가 아무리 작아도, 고객이 존재하고, 우리가 의미 있는 제품을 만들어서 알만한 사람들은 이미 아는 브랜드를 만들고 있다면, 일단 이 시장을 완전히 장악해서 category leader를 넘어선 category dominator가 되라고 조언한다. 그 이후에 다른 곳으로 확장하라고 한다.\n예를 들며, 내가 지금까지 아주 오랜 시간 동안 기반을 잘 닦아 놓은 시장의 전체 크기가 100억 원이라면, 일단 이 시장에서 최소 30억 원의 매출을 해서 시장의 30%를 장악하라는 뜻이다. 한 시장의 30%를 장악하면 그 시장의 확실한 category dominator가 될 수 있기 때문이다. 꽤 재미있는 건, 이런 고민을 하는 대표들이 대부분 그 100억 원짜리 시장은 항상 너무 작다고 하면서도, 막상 본인들은 이 작은 시장에서 매출 1억 원도 못 하고 있다는 점이다.\n그래서 나는 항상 이들에게 일단 우리가 만들어 놓은 시장에서 작은 것부터 야금야금 먹자고 한다. 시장에서 압도적인 1등이 된 후에 다른 시장으로 진출하는 게 여러모로 봤을 때 훨씬 더 우리에게 유리하기 때문에, Hero와 같이 현재 시장에서, 현재 제품을 조금 더 다각화할 수 있는 전략을 고민해 보라는 조언을 한다. 전에도 한 번 내가 포스팅 한 적이 있는데, 일단 따기 쉬운 과일을 먼저 따먹는 전략이다.\n이런 조언을 열심히 해도, 두 마리의 토끼를 쫓거나, 아니면 우리 토끼보다 더 큰 다른 토끼를 쫓는 창업가들이 더 많다. 누가 맞고 틀렸다는 문제는 아니라서, 더 큰 카테고리로 지금 당장 진출하고 싶은 분들은 그렇게 하면 된다. 하지만, 이렇게 했을 때 조심해야 할 점은, 두 마리 토끼를 쫓다가 둘 다 놓칠 수도 있고, 더 큰 토끼를 쫓아서 힘들게 잡았는데 막상 보면 엉덩이면 커서 뒤에서만 봤을 때 큰 토끼일 가능성도 있고, 실은 내가 지금 잡고 있는 토끼가 나중에 엄청나게 커질 수 있는데 다른 토끼를 쫓다가 내 토끼를 다른 회사에 빼앗길 수도 있다는 것이다.\n왜 이런 무모한 전략을 계속 고집하는지 물어보면, 대부분의 창업가들은 더 짧은 기간에 더 빠르게 성장하고 싶다고 한다. 이분들에게 내가 한결같이 다시 해주는 조언은 세상의 모든 건 시간이 걸린다는 것이다. 100만 원 매출이 1,000만 원이 되고, 1,000만 원이 1억이 되고, 이런 느린 사이클을 타면서 언젠간 1조 원 매출이 된다. 한 번에 1,000억씩 할 수 있는 방법은 없다. 혹시 있다면 나한테 DM 부탁한다. 그땐 내가 VC를 그만둬야 할 것 같다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/01/big-things-come-from-small-beginnings.html#comments",
        "content": "한인이 창업했고, 창업 5년 만에 한화로 거의 1조 원에 인수된 화장품 회사 Hero Cosmetics(Hero)의 팟캐스트를 얼마 전에 흥미롭게 들었다. 창업가들의 이야기는 그 결말이 해피엔딩이든 새드엔딩이든 항상 배울 점들이 많아서 재미있고, 한국에 사는 분들에겐 너무나 익숙한 여드름 패치 하나로 시작해서 1조 원짜리 회사를 만들어서 Church and Dwight에 매각한 이야기도 웬만한 케이드라마보다 더 흥미로웠다. 이 팟캐스트를 며칠에(...)",
        "contentSnippet": "한인이 창업했고, 창업 5년 만에 한화로 거의 1조 원에 인수된 화장품 회사 Hero Cosmetics(Hero)의 팟캐스트를 얼마 전에 흥미롭게 들었다. 창업가들의 이야기는 그 결말이 해피엔딩이든 새드엔딩이든 항상 배울 점들이 많아서 재미있고, 한국에 사는 분들에겐 너무나 익숙한 여드름 패치 하나로 시작해서 1조 원짜리 회사를 만들어서 Church and Dwight에 매각한 이야기도 웬만한 케이드라마보다 더 흥미로웠다. 이 팟캐스트를 며칠에(...)",
        "guid": "https://www.thestartupbible.com/?p=9359",
        "categories": [
          "Uncategorized",
          "B2B",
          "consumer",
          "FoundersAtWork",
          "korea",
          "strategy",
          "Strong",
          "스타트업 바이블 QA"
        ],
        "isoDate": "2025-01-22T21:29:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "희망의 실종",
        "link": "https://www.thestartupbible.com/2025/01/will-there-be-hope-in-2025.html",
        "pubDate": "Sun, 19 Jan 2025 21:34:00 +0000",
        "content:encodedSnippet": "2022년 하반기에 많은 분들이 나에게 앞으로 경기는 어떻게 될 것이고, 언제쯤, 이 불경기가 회복될지 물어봤다. 물론, 나는 경제학자도 아니고 미래학자도 아니라서 잘 모른다고 했지만, 속으론 2024년 상반기면 괜찮아질 것으로 생각했다. 그래서 계속 개인적인 생각을 물어보면, 그냥 2024년 상반기엔 좋아지지 않겠나,,,라고 이야기했다. 그런데 2023년 상반기가 되자, 여러 가지 분위기와 정성적인 지표는 – 예, 해외 투자자들과의 이야기와 느낌 – 2024년 경기도 매우 안 좋은 방향으로 향하고 있는 게 너무나 명확했다. 그래서 내가 했던 말을 번복하고, 2025년이 돼야 시장의 상황이 더 좋아질 것 같다고 했다.\n작년 사사분기에, 이런 내 생각에 한 번의 전환이 더 있었고, 내 말을 한 번 더 번복했다. 2025년은 어쩌면 우리가 스타트업을 하면서 경험할 수 있는 최악의 경기가 될지도 모르겠다. 특히나 한국은 그동안 국제적인 이미지가 너무 좋았고, 전반적인 분위기가 나쁘지 않았는데, 말도 안 되는 정치적인 사건으로 인해서 국가의 이미지가 실추되면서 그 누구도 상상하지 못했던 엄청난 경제적인 손실이 발생하고 있다.\n그동안 내가 외국인들에게 항상 자랑스럽게 주장했던 게 두 가지가 있었다.\n하나는, 한국은 그나마 다른 아시아 국가 중 정치적으로 안정된 국가라는 점이었고, 둘째는, 한국은 그나마 다른 아시아 국가보다 USD에 대한 환율이 강한 국가라는 점이었다.\n모두 잘 아시다시피, 내가 완전히 양치기 소년이 됐다. 어쨌든, 이 좋지 않은 세계 경제 상황에서 정치적, 경제적으로 일시적으로 최악의 상황에 놓인 한국은 힘든 한 해를 보낼 것이고, 한국에서 사업을 하는 스타트업, 그리고 우리 같은 투자자 모두 아주 힘든 한 해를 경험할 것이다.\n2025년에는 사라지는 회사들이 정말 많을 것이다. 우리 투자사들도 너무 다 힘들고, 이미 폐업 준비하는 대표들이 내 주변에도 너무 많아지고 있다. 가장 먼저 문 닫을 회사들은 원래 2024년도에 폐업을 해야 했는데, 2025년은 더 좋아질 것이라는 희망을 갖고, 오로지 이 희망 하나로 작년 한 해를 버틴 회사들이다. 이들의 희망과는 달리 2025년도 크게 좋아지지 않을 것이기 때문에, 매출은 작고, 돈은 없고, 직원들은 하나둘씩 해고되거나 나갈 회사들은 문을 닫아야 할 것이다. 이들에게 더 이상 희망으로 버틸 수 있는 체력과 돈은 없다.\n펀딩 시리즈 스펙트럼의 다른 극에 있는 유니콘 회사들도 많이 망하거나, 아니면 유니콘 왕관을 스스로 내려놔야 할 것이다. 돈도 못 벌고, 마이너스만 만들고 있는 유니콘들이 꽤 많은데, 이들이 작년 한 해 유니콘 밸류에이션을 유지할 수 있었던 이유는 두 가지다. 하나는 이들도 2025년은 시장이 더 좋아져서 다시 한번 유니콘 밸류에 투자를 받을 수 있을 것이라는 희망으로 힘든 2024년을 버텼을 것이다. 또 다른 이유는 이 회사에 마지막으로 투자한 VC들이 어떻게든 기업 가치를 유지해서 본인들 투자에 손실이 발생하지 않기 위해서 이 회사들을 하드캐리 했는데, 더 이상 이걸 할 순 없을 것이다. 실은, 이 VC들도 2025년에 대한 희망을 품고 힘든 2024년을 보냈는데, 더 이상 이런 희망으로 버틸 순 없을 것이다.\n2025년에는 스타트업만 돈이 없는 게 아니라, 이들에게 투자하는 VC들도 돈이 없어서 활발한 투자를 보긴 힘들 것이다. VC들도 누군가에게 돈을 받아서 투자해야 하는데, 이들에게 돈을 주는 LP들이 매우 보수적인 자세를 취하고 있어서, 펀드를 만드는 게 우리 같은 투자자들에겐 큰 도전이자 과제다. 돈이 나올 수 있는 구멍이 여러 면에서 막혀 있는 게 VC나 스타트업의 2025년도 현실이다.\n단도직입적으로 말하자면, 근대 벤처업계 역사상 최악의 한 해가 될 것이다. 인생 최고 공포의 롤러코스터 라이드가 될 것이니까, 안전띠 꽉 조이고, 허리띠는 더 꽉 조여야 할 것이다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/01/will-there-be-hope-in-2025.html#comments",
        "content": "2022년 하반기에 많은 분들이 나에게 앞으로 경기는 어떻게 될 것이고, 언제쯤, 이 불경기가 회복될지 물어봤다. 물론, 나는 경제학자도 아니고 미래학자도 아니라서 잘 모른다고 했지만, 속으론 2024년 상반기면 괜찮아질 것으로 생각했다. 그래서 계속 개인적인 생각을 물어보면, 그냥 2024년 상반기엔 좋아지지 않겠나,,,라고 이야기했다. 그런데 2023년 상반기가 되자, 여러 가지 분위기와 정성적인 지표는 – 예, 해외 투자자들과의 이야기와(...)",
        "contentSnippet": "2022년 하반기에 많은 분들이 나에게 앞으로 경기는 어떻게 될 것이고, 언제쯤, 이 불경기가 회복될지 물어봤다. 물론, 나는 경제학자도 아니고 미래학자도 아니라서 잘 모른다고 했지만, 속으론 2024년 상반기면 괜찮아질 것으로 생각했다. 그래서 계속 개인적인 생각을 물어보면, 그냥 2024년 상반기엔 좋아지지 않겠나,,,라고 이야기했다. 그런데 2023년 상반기가 되자, 여러 가지 분위기와 정성적인 지표는 – 예, 해외 투자자들과의 이야기와(...)",
        "guid": "https://www.thestartupbible.com/?p=9352",
        "categories": [
          "Uncategorized",
          "failure",
          "FoundersAtWork",
          "fundraising",
          "korea",
          "unicorn",
          "vc"
        ],
        "isoDate": "2025-01-19T21:34:00.000Z"
      }
    ]
  },
  {
    "name": "Build a Great Product",
    "category": "개인",
    "posts": []
  },
  {
    "name": "지금 써보러 갑니다",
    "category": "개인",
    "posts": []
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "토스, 2024년 ‘혜택’ 결산",
        "link": "https://blog.toss.im/article/2024benefit",
        "pubDate": "Fri, 24 Jan 2025 01:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}토스 고객 누구나 평생 무료 송금 혜택...지난해 약 9억 8000만 건 이루어져\n만보기, 함께 토스 켜고 포인트 받기 등 사용자에게 일상 속 소소한 혜택 제공\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n모바일 금융 서비스 ‘토스’를 운영하는 비바리퍼블리카(이하 ‘토스’)가 2024년 한 해 동안 사용자들에게 제공한 주요 혜택 데이터를 공개했다. 토스 '혜택'은 무료 송금과 같이 비용을 절감해 주는 서비스와 '만보기'처럼 리워드를 제공하는 서비스로 나뉜다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n2024년 한 해 동안 토스 이용자들의 송금 횟수는 약 9억 8000만 회를 기록했다. 송금 수수료를 500원으로 계산하면, 1인당 연평균 약 4만 원의 송금 수수료를 아낀 셈이다. 토스는 2015년 간편송금 서비스를 시작했다. 2021년부터 업계에서 선도적으로 모든 고객에게 평생 무료 송금을 제공하고 있다.\n토스 앱 하단 ‘혜택’ 메뉴를 통해 현금성 포인트를 적립할 수 있는 서비스는 1월 말 현재 35가지에 이른다. 매일 새로운 혜택이 추가되고, 바로 참여할 수 있는 이벤트도 확인할 수 있다. 대표적인 서비스로는 ▲만보기 ▲함께 토스 켜고 포인트 받기 ▲고양이 키우고 간식 받기 등이 있다.\n‘만보기’는 토스 가입자의 40%가 넘는 약 1150만 명이 사용하고 있다. 만보기 이용자는 주당 평균 2회 이상 만보기를 사용하고, 하루 평균 약 5000보를 걸은 것으로 나타났다. 이용자들은 평균 약 2900원을 적립했다. 토스 만보기는 1만 보 이내에서 정해진 걸음 수에 따라 포인트와 복권을 제공한다.\n‘함께 토스 켜고 포인트 받기’는 2023년 처음 선보인 서비스로 이른바 ‘토스 성지’라는 유행어를 낳은 토스의 인기 혜택 서비스다. 오프라인에서 이용자 주변에 토스 앱을 켠 또 다른 이용자가 있을 때 포인트를 받는 방식이다. 지난해 ‘함께 토스 켜고 포인트 받기’를 통해 가장 많은 포인트를 적립한 이용자는 약 7만 원을 적립한 것으로 나타났다. 1인당 평균 약 3400원의 포인트를 적립했다.\n‘고양이 키우고 간식 받기’는 토스페이 결제 시 가상의 고양이를 키울 수 있는 서비스다. 결제 시 고양이를 키울 수 있는 아이템을 받고, 이를 e쿠폰으로 교환하는 식이다. 작년 한 해 동안 ‘고양이 키우고 간식 받기’에서 e쿠폰을 가장 많이 받은 이용자는 120장의 쿠폰을 수령했다. 이용자 1인당 평균은 약 2700원으로 햄버거 하나와 교환할 수 있는 e쿠폰을 받았다.\n이 밖에 ‘오늘의 행운복권’, ‘이번 주 미션’ 등도 토스 사용자가 즐겨 찾는 혜택 서비스로 나타났다. 이 혜택 서비스를 통해 가장 많은 포인트를 적립한 사용자는 1년 동안 약 99만 원을 모았다. 매일 2700원 이상의 혜택을 적립한 셈이다.\n토스 관계자는 \"토스는 이용자들에게 금융 서비스부터 일상 속 이벤트 등 다양한 영역에서 체감할 수 있는 혜택을 제공해 오고 있다\"며 \"앞으로도 사용자 친화적인 서비스로 편리하고 유익한 앱 사용 경험을 줄 수 있도록 노력하겠다\"고 말했다.",
        "content": "인당 송금 수수료 4만 원 절약",
        "contentSnippet": "인당 송금 수수료 4만 원 절약",
        "guid": "https://blog.toss.im/article/2024benefit",
        "isoDate": "2025-01-24T01:00:00.000Z"
      },
      {
        "title": "2025년부터 달라지는 정책: 금융·경제·복지 제도 25가지",
        "link": "https://blog.toss.im/article/new-policies-2025",
        "pubDate": "Thu, 23 Jan 2025 02:04:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}2025년을 맞아 금융·경제·복지 분야의 많은 정책들이 새롭게 시행돼요. 이 중에서 특히 눈에 띄는 정책 25가지를 골라서 정리했어요. 최저시급 인상부터 스트레스 DSR 3단계까지. 우리 일상에 큰 영향을 주는 정책의 변화를 하나씩 살펴볼까요?\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}많은 분들이 받을 수 있는 혜택\n1. 최저시급이 1만 원을 돌파했어요\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}2025년 최저임금이 지난해 시간당 9,860원에서 10,030원으로 1.7% 인상됐어요. 주 40시간 일했을 때 받는 월급은 209만 6,270원으로, 작년보다 35,530원 올랐어요. 최저시급이 1만 원을 넘은 건 제도 도입 이후 37년 만의 일이에요.\n2. 실업급여도 함께 올랐어요\n실업급여 하한액이 하루 8시간 일하는 근로자의 일급을 기준으로 64,192원으로 인상돼요. 한 달로 계산하면 192만 5,760원 받을 수 있어요.\n3. 모바일 주민등록증을 간편하게 발급받을 수 있어요\n3월부터 17세 이상 국민이라면 누구나 모바일 주민등록증을 무료로 발급받을 수 있어요. 실물 주민등록증과 동일하게 사용할 수 있고, 행정복지센터(주민센터)에 방문하거나 정부24에서 온라인으로 신청하면 돼요.\n4. 문화비 소득공제가 헬스장과 수영장에도 적용돼요\n7월부터 도서 구입, 공연 관람 등에 적용되던 문화비 소득공제가 헬스장과 수영장 이용에도 확대돼요. 연 소득 7천만 원 이하인 근로소득자는 시설 이용료의 30%를 300만 원 한도 내에서 소득공제 받을 수 있어요. ‘체육시설법’에 따라 신고된 헬스장과 수영장 중 문화비 소득공제 제도 참여에 신청한 업체에만 적용돼요.\n5. 예금보호 한도가 상향돼요\n예금보호 한도가 5천만 원에서 1억 원으로 올라요. 내 돈을 맡긴 은행이 파산하더라도 최대 1억 원까지 안전하게 돌려받을 수 있어요. 1월 중에 예금자보호법 개정안이 공포된다면, 금융위원회의 결정에 따라 올해 안으로 예금보호 한도가 상향될 예정이에요.\n6. 국민내일배움카드 훈련비 지원이 늘어요\n내일배움카드 계좌 한도 300만 원을 모두 소진했을 때 100만 원을 추가로 지원받을 수 있었는데, 2025년부터는 200만 원을 추가로 지원받아 더 많은 훈련 기회를 보장받을 수 있어요.\n출산·양육 지원 확대\n7. 육아휴직 급여가 인상돼요\n육아휴직수당 상한액이 월 150만 원에서 250만 원으로 올랐어요. 부모 동반 휴직 시 받는 첫 달 급여 상한액도 250만 원, 한부모 근로자의 첫 3개월 급여도 300만 원으로  50만 원씩 올랐어요. 휴직 중 75% 복직 후 25%를 지원하던 기존의 사후지급 방식은 폐지되어, 육아휴직 기간 동안 육아휴직 급여를 100% 받을 수 있어요.\n8. 육아 휴직 기간이 늘어나요\n2월 23일부터 육아휴직 기간이 기존 최대 1년에서 1년 6개월로 확대돼요. 배우자의 출산휴가도 10일에서 20일로 늘어나며, 사용 기준도 출산일 이후 90일에서 120일 이내로 변경돼요.\n9. 2자녀 가구도 자동차 취득세가 감면돼요\n다자녀 가구의 자동차 취득세 감면 기준이 3자녀 이상에서 2자녀 가구로 확대됐어요. 이에 따라 2자녀 가구도 자동차 취득세 50%를 감면받을 수 있게 되었어요.\n10. 근로장려금을 받을 수 있는 맞벌이 가구가 많아져요\n맞벌이 가구 근로장려금 소득상한금액이 기존 3,800만 원에서 4,400만 원으로 확대됐어요. 단독가구 소득상한금액인 연 2,200만 원의 두 배 수준에 맞춘 것으로, 일하는 저소득 결혼가구에 대한 지원을 강화하기 위한 조치예요.\n11. 혼인신고를 하면 세액공제 혜택을 받을 수 있어요\n혼인신고 시 부부 1인당 50만 원씩 세액이 공제돼요. 초혼∙재혼 관계없이 생애 1회 한정으로, 지난해 1월1일 이후 혼인신고 분부터 소급적용이 가능하고, 결혼세액공제 제도의 기한은 2026년 12월 31일까지예요.\n12. 기업의 출산지원금이 전액 비과세로 변경돼요\n기업이 근로자에게 지급하는 출산지원금이 전액 비과세로 바뀌어요. 출산 후 2년 이내에 지급한 경우에만 해당돼요.\n13. 자녀·손자녀 세액공제 금액이 확대돼요\n양육비 부담 완화를 위해 1월 1일부터 발생하는 소득부터 자녀·손자녀(8~20세)에 대한 자녀세액공제 금액이 확대돼요. 공제금액은 첫째 25만 원, 둘째 30만 원, 셋째 이후 인당 40만 원으로 작년보다 10만 원씩 늘어났어요.\n14. 아이돌봄 서비스 지원이 확대돼요\n아이돌봄 서비스 대상을 기준 중위소득 150% 이하 가구에서 200% 이하 가구로 확대했어요. 또, 돌봄수당은 지난해 1만 1,630원에서 4.7% 오른 1만 2,180원으로 책정됐어요. 36개월 이하 영아를 돌볼 때는 시간당 1,500원의 추가 수당까지 신규 지급해요.\n15. 늘봄학교 대상 지원 확대돼요\n학교와 지역사회의 다양한 교육자원을 연계해 정규수업 외 교육 프로그램을 제공하는 늘봄학교가 지난해까지는 초등학교 1학년을 우선 대상으로 운영됐지만, 2025년 1학기부터는 그 대상이 초등학교 2학년까지 확대돼요.\n미래를 위한 새로운 기회\n16. 고교학점제가 전면 시행돼요\n학생이 스스로 진로와 적성에 맞춰 과목을 선택하고 이수할 수 있는 고교학점제가 올해부터 전면 도입돼요. 모든 고등학생이 진로에 맞춰 과목을 선택하고 학점을 이수할 수 있어요. 3년간 192학점을 취득하면 졸업할 수 있어요.\n17. 청년도약계좌 정부기여금이 확대돼요\n청년도약계좌 정부기여금이 월 최대 2만 4,000원에서 3만 3,000원으로 늘어나면서 5년간 198만 원까지 지원 받을 수 있어요. 이 계좌를 3년 이상 유지하다가 중도에 해지하면, 비과세 혜택과 정부 기여금의 60%를 받을 수 있어요. 이전에는 중도해지 시 비과세 혜택이 적용되지 않고, 가입 기간 동안 받은 정부 기여금을 전액 반환해야 했어요.\n18. 무주택 청년을 위한 주택대출상품이 새로 나와요\n청년들의 내 집 마련을 돕기 위해 금리 2%대에 분양가의 80%까지 대출해주는 ‘청년주택드림대출’이 올해 상반기 시행돼요. 청년주택드림청약에 가입한 뒤 1년 이상 돈을 납입한 20~39세 무주택자 청년 중 연 소득이 7천만 원(부부는 1억 원) 이하인 사람이 6억 원 이하(전용 85㎡ 이하) 주택을 분양받을 때 이 대출을 이용할 수 있어요.\n19. 군인 월급이 올랐어요\n올해에도 병 봉급이 인상되면서 군 장병들이 받는 월급은 계급에 따라 이병이 64만 원에서 75만 원, 일병은 80만 원에서 90만 원, 상병은 100만 원에서 120만 원, 병장은 125만 원에서 150만 원으로 올랐어요.\n20. 장병내일준비적금 정부지원금도 커졌어요\n전역 시 목돈 마련을 지원해주는 장병내일준비적금 지원금도 월 최대 40만 원에서 55만 원으로 늘어났어요.\n내 집 마련을 위한 정책 변화\n21. 대출금 중도 상환 수수료가 낮아졌어요\n주택담보대출 중도상환수수료가 절반으로 줄어들어요. 2025년 1월 중순부터 신규 대출 상품에만 적용돼요. 현재 시중 은행의 주택담보대출 수수료는 약 1.2~1.4%, 신용대출은 0.6~0.8% 수준인데 앞으로 각각 0.6~0.7%, 0.4% 수준으로 낮아질 전망이에요.\n22. 주택청약종합저축 소득공제 혜택이 커져요\n연 소득 7천만 원 이하 무주택 근로자라면 납입액의 40%를 300만 원 한도 내에서 공제받을 수 있어요. 세대주 외에 배우자도 추가로 소득공제 받을 수 있어요.\n23. 신생아 특례 대출 요건이 완화돼요\n올해 1월 1일 이후 아이를 출산한 가구에 한해 신생아 특례  대출 소득 요건이 기존 부부 합산 1억 3천만 원에서 2억 5천만 원으로 완화돼요. 특례 대출 기간에 아이를 더 낳으면 우대금리가 추가로 0.4% 적용돼요. 이 제도는 2027년까지 3년간 시행돼요.\n24. 비아파트 구입자를 청약시 무주택으로 인정해주는 범위가 확대돼요\n빌라와 같은 비아파트 구입자가 아파트 청약에서 불이익을 받지 않도록 청약시 무주택으로 인정하는 비아파트의 범위가 공시가격 1억 원(수도권 1.6억 원) 이하, 전용면적 60㎡ 이하 주택에서 3억 원 이하(수도권 5억 원), 85㎡ 이하 주택으로 확대됐어요.\n25. 스트레스 DSR 3단계가 시행돼요\n2025년 7월부터 스트레스 *DSR 3단계가 시행돼요. 스트레스 DSR은 대출 심사 시 금리 상승 가능성을 반영해 가산금리를 부과하는 제도로, 가계 빚을 줄이기 위해 도입됐어요. 금융위원회는 시장 충격을 최소화하기 위해 작년 2월부터 이를 단계적으로 시행해왔죠. 스트레스 3단계가 적용되면 같은 소득이라도 이전 단계보다 대출 이자율이 높아지고 대출 한도도 줄어들어요. 올해 대출을 고려하고 있다면 미리 알아보는 게 좋아요.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*DSR이란 내 연봉 대비 빌릴 수 있는 돈의 비율을 뜻해요. 주택담보대출뿐 아니라 학자금대출, 마이너스대출, 자동차할부, 카드론 등 내가 받은 모든 대출의 원리금을 합한 금액이 내 연봉의 일정 비율을 넘을 수 없어요.\n2025년에도 다양한 정책 변화가 우리의 일상에 큰 영향을 줄 거예요. 나에게 해당하는 혜택은 놓치지 않길 바랍니다.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 윤동해 Graphic 이제현",
        "content": "내 일상에 도움이 되는 혜택을 함께 살펴봐요",
        "contentSnippet": "내 일상에 도움이 되는 혜택을 함께 살펴봐요",
        "guid": "https://blog.toss.im/article/new-policies-2025",
        "isoDate": "2025-01-23T02:04:00.000Z"
      },
      {
        "title": "토스, 안심보상제로 지난해 총 5300건, 20억 원 피해 구제해",
        "link": "https://blog.toss.im/article/customerprotection",
        "pubDate": "Thu, 23 Jan 2025 00:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}토스 고객 보호 서비스 안심보상제 2024년 결산 통해 총 보상액과 사례 공개\n2024년 1년 동안 5381건의 고객 피해 접수…선제적 보상 시행\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n모바일 금융 서비스 ‘토스’를 운영하는 비바리퍼블리카(이하 ‘토스’)가 2024년 한 해 동안 안심보상제로 5381명에게 총 20억 원을 보상했다고 23일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n안심보상제는 금융사고 발생 시 토스의 잘못이 없더라도 선제적으로 피해 금액을 보상하는 고객 보호 서비스 제도이다. 업계에서 처음 도입된 이 서비스는 크게 중고거래 사기와 금융사고 두 가지로 나뉜다. 중고거래 사기는 온라인 중고거래 플랫폼에서 진행된 실물 거래 피해를 대상으로 한다. 금융사고는 제3자의 명의도용 및 보이스 피싱 등 토스를 거쳐 일어난 금전 피해를 포함한다. 두 경우 모두 토스가 피해 금액을 먼저 보상한다.\n지난해 동안 5381건의 고객 피해 사례가 접수됐으며, 하루 평균 약 15명이 보상을 받았다. 전체 보상 금액은 약 20억 원으로, 이용자 1인당 평균 약 38만 원의 지원을 받은 셈이다. 지급된 보상액의 88%는 중고거래 사기에, 12%는 금융사고에 해당했다.\n실제로 A씨는 지난 3월 경찰을 사칭한 전화를 받고, 범죄 수사를 이유로 송금과 결제를 유도당해 총 174만 2500원을 송금하는 피해를 입었다. 이후 토스 고객센터에 피해 신고를 문의했고, 안내에 따라 필요 서류를 제출한 뒤 안심보상제를 통해 피해액 전액을 보상받았다. 또한, B씨는 지난 11월 중고거래 플랫폼에서 낚싯대를 구매하려고 송금했으나, 이후 판매자와의 연락이 끊겨 48만 원 상당의 피해가 발생했다. B씨 역시 토스 안심보상제로 전액을 보상받았다.\n안심보상제는 토스 회원이라면 누구나 신청할 수 있으며, 중고거래는 최초 1회에 한해 최대 50만 원, 금융사고는 최대 5000만 원까지 보상한다. 안심보상제 신청 시, 본인 확인과 담당 부서의 요청에 따라 필요한 서류를 제출하면 대상자 여부 확인 및 접수가 가능하다.\n토스 관계자는 “2024년 한 해 동안 토스 이용자들에게 안전한 금융 생활을 지원할 수 있도록 노력했다”며 “앞으로도 토스는 실질적인 도움을 제공하고, 사용자 보호와 편의를 최우선으로 할 계획”이라고 밝혔다.",
        "content": "선제적으로 고객의 피해 금액을 보상하는 안심보상제 2024년 결산",
        "contentSnippet": "선제적으로 고객의 피해 금액을 보상하는 안심보상제 2024년 결산",
        "guid": "https://blog.toss.im/article/customerprotection",
        "isoDate": "2025-01-23T00:00:00.000Z"
      },
      {
        "title": "노후 준비에 관한 고민, 전문가 Q&A로 해결하기",
        "link": "https://blog.toss.im/article/retirement-plans-08",
        "pubDate": "Wed, 22 Jan 2025 13:23:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}2017년, 한국에 해외 자산운용사의 TDF 상품이 처음 도입되던 시기, 영주 닐슨 교수는 연금과 노후 대비에 새로운 시각을 갖게 되었어요. 당시 국내 한 자산운용사에서 자문 활동을 하며 나와 가족들의 은퇴 준비를 넘어 한국 사람들의 연금과 노후 대비에 대한 고민이 깊어졌다고 해요.\n미국 월가에서 15년 이상 알고리즘 트레이딩 전문가로 활약했던 그는 현재 ‘한국퇴직연금데이터’를 설립하고, 퇴직연금 관리 및 노후 준비를 돕는 서비스 ‘.css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}글라이드’를 운영하고 있어요. “개인의 노후 준비를 돕는 일이 커리어에서 가장 보람 있는 일”이라고 말하죠.\n이번 인터뷰에서는 그가 쌓아온 전문성과 경험을 바탕으로, 체계적이고 현실적인 노후 준비 방법을 들어봅니다.\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}1. 2024년 초 <노후 준비 액션플랜> 시리즈를 시작할 때, 독자들에게 어떤 점을 가장 강조하고 싶으셨나요?\n이제 ‘퇴직연금’이나 ‘개인연금’이라는 단어는 미디어뿐만 아니라 버스 광고판이나 고층 빌딩의 외벽에서도 쉽게 볼 수 있을 정도로 금융사들의 적극적인 마케팅 덕에 대중에게 익숙한 용어가 되었어요. 많은 사람들이 금융사나 미디어를 통해 퇴직연금 운용과 관리에 대한 정보를 접하고 있습니다.\n하지만 특정 상품에 초점이 맞춰진 단편적인 정보만 접하면 노후 대비에 대해 체계적으로 이해하고 접근하기 어려워요. 그래서 1화 ‘은퇴 후의 삶, 준비를 시작했나요?’부터 퇴직연금을 처음 접하는 사람이 차근차근 학습할 수 있도록 체계적인 순서를 제시하는 데 초점을 맞췄습니다. 큰 그림을 그려보고 연금 상품들을 활용해 노후를 준비할 수 있는 나만의 시스템을 구축하게 하기 위해서요.\n2. 은퇴 준비까지 가는 여정에서 유의해야 할 것이 있을까요?\n처음 한국에 왔을 때 인상 깊었던 점 중 하나는 젊은 층이 공무원을 선호한다는 것이었어요. 최근에는 그런 분위기가 많이 바뀌기는 했지만, 선호했던 이유는 직업의 안정성과 은퇴 후 평생 지급되는 연금 때문이었죠. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}하지만 공무원 연금은 일하는 동안 한 달도 빠짐없이 납부한다는 점을 기억해야 해요. 연금의 핵심은 연속성인데, 퇴직연금에서는 이런 연속성이 잘 지켜지지 않는 경우가 많습니다.\n한국인의 노후 준비에서 두드러지는 특징이기도 한데요, 투자에 지나치게 신경을 쓰면서도 장기적인 계획이 부족하다는 점이 아쉬워요. 많은 사람들이 30년 이상 꾸준히 모으고 투자하는 개념보다는 단기 수익률에 집중하고, 은퇴 자금을 자녀 교육 등 다른 용도로 써버리는 사례를 많이 목격했습니다.\n또 다른 유의점은 투자 방식의 극단성이에요. 일부는 너무 공격적으로 투자해 불필요한 리스크를 감수하고, 또 일부는 지나치게 보수적으로 원금보장형 상품에만 투자해 퇴직연금 계좌가 인플레이션을 따라가지 못하는 상황을 초래합니다. 이 같은 습관은 연금의 본래 목적을 훼손하고 장기적인 노후 준비를 어렵게 만들어요.\n\n✱3~10번 질문은 토스앱 내 ‘오늘의 팁’을 통해 남겨주신 고민 중 가장 많이 중복되는 8가지에 영주 닐슨 교수가 답했습니다.\n\n3. 노후대비를 국민연금으로만 해도 될까요?\n2023년 1월 기준, 국민연금의 월평균 수급액은 61만 7,603원에 불과합니다. 이는 최소 노후생활비로 추정되는 124만 원의 절반에도 미치지 않는 금액이에요. 국민연금만으로 안정적인 노후를 준비하기엔 부족하다는 사실이 명확하죠.\n국민연금의 소득대체율 목표는 40%이에요. 이를 기준으로 생각하면, 한 달 생활비가 300만 원인 경우 국민연금이 약 120만 원을 충당해줄 거라고 예상할 수 있고요. 하지만 이마저도 충분하지 않은 금액이기에, 국민연금을 보완할 수 있는 퇴직연금, 개인연금 관리에 더욱 신경 써야 합니다.\n4. 만약 교수님께서 지금 사회초년생이라면, 어떤 상품에 가입하실 건가요?\n제가 이제 막 커리어를 시작하는 20대라면, 그리고 회사에서 퇴직연금을 제공하고 DC형과 DB형 중 선택할 수 있다면 DC형을 선택해 직접 이런저런 운용 지시를 해보면서 경험을 쌓을 거예요. 그리고 세제 혜택을 최대한 활용할 겸 IRP나 연금저축을 통해 조금씩이라도 장기적인 계획을 세우고 연금 자산을 쌓아가려고 할 거예요.\n사실 저는 20대였을 때 비슷한 선택을 했어요. 공부를 마치고 첫 직장을 잡자마자 미국의 DC형 퇴직연금인 401k를 시작했거든요. 이후 방금 말씀드린 방법을 그대로 실천했어요. 결과가 궁금하시죠? 지금까지 꾸준히 준비한 덕분에 안정적인 은퇴를 향해 나아가고 있어요.\n만약 회사에서 DC형을 선택할 수 없다면 IRP 계좌를 개설해 직접 투자해보는 게 좋아요. 공무원이든 프리랜서든 소득이 있다면 누구나 IRP에 가입할 수 있답니다. 소액이라도 매달 꾸준히 납입하면서 IRP를 통해 직접 투자 포트폴리오를 만들어가는 과정은 사회초년생일 때부터 시작하면 좋아요. 30년 이상 일하면서 자산을 관리하고 투자하는 경험은 누구에게나 꼭 필요한 일입니다.\n5. 월급 대비 연금으로 투자하는 비율은 얼마 정도가 좋을까요?\n보통 전문가들은 월급의 10~20%를 노후 자금으로 저축하거나 투자하라고 조언해요. 사실 직장인의 경우 이미 소득의 4.5%는 국민연금으로, 또 일부는 퇴직연금으로 자동납부 되고 있어요. 너무 부담되지 않도록 월급의 10% 내외를 추가로 IRP 계좌 등에 납부해보는 것을 추천드려요. 월급이 200만 원이라면 매달 20만 원을 IRP에 넣는 거죠. 물론 쉬운 일은 아니지만 연말정산에서 세액공제도 받을 수 있기 때문에 놓칠 수 없는 혜택이기도 합니다.\n연금은 중도 해지하지 않는 게 중요하니까 처음에는 감당할 수 있는 금액을 넣다가 은퇴 시점이 가까워지는 연령대가 되면 비중을 점점 높여야 해요. 젊을 때는 복리의 효과를 활용할 시간이 충분하지만, 은퇴 직전에는 이를 기대하기 어렵죠. 은퇴가 가까워질수록 투자할 수 있는 시간이 줄어들기 때문에 더 많은 자금을 투입해야 목표 자산을 달성할 수 있어요.\n6. 개인사업자에게 노후 준비 방법을 추천하신다면요?\n한국의 퇴직연금 제도는 개인사업자에게도 IRP 가입을 허용하고 있어요. 고용주 없이 프리랜서로 일하더라도 연금제도의 혜택을 누릴 수 있습니다. 거기에 더해 소상공인이라면 IRP 외에도 노란우산 공제를 활용할 수 있는데, 이것은 개인사업자가 퇴직금을 마련할 수 있도록 돕는 공제 제도예요.\n노란우산은 연간 최대 600만 원까지 소득공제가 가능하고, 월 5만 원부터 100만 원까지 납부할 수 있어요. 납부 방식은 월납 또는 분기납으로 선택할 수 있습니다. 다만, IRP와 달리 투자형 상품이 아닌 예금 형태로 운용되고, 2024년 기준 약 3.3%의 수익률을 제공해요. 이러한 특성 덕분에 퇴직금 마련뿐만 아니라 목돈을 모으기 위한 용도로도 적합하죠. 노란우산은 투자 개념이 강한 IRP와는 성격이 다르기 때문에, 두 제도를 병행하면 각각의 장점을 활용하면서 세제 혜택과 노후 자금 준비를 동시에 얻을 수 있습니다.\n7. 30년 뒤 노후 생활비는 얼마가 필요할까요?\n노후 생활비를 간단히 계산하려면, 은퇴 후 생활비 감소를 고려해 현재 생활비의 약 70%를 기준으로 잡아보세요. 정확한 계산법은 아니지만 대략적으로 필요한 금액의 감을 잡는 데는 유용합니다.\n2023년 1월 국민연금공단 보고서에 따르면 부부 기준 적정 생활비는 월평균 277만 원이라고 해요. 또, 통계청의 2023년 가계금융복지조사에 따르면 은퇴한 가구주와 배우자(2인 가구)의 월평균 적정생활비는 324만 원, 최소생활비는 231만 원이라고 합니다. 이렇게 277만 원, 324만 원, 현재 내 생활비의 70%라는 세 가지 기준을 참고하면 은퇴 후 나에게 필요한 돈을 가늠해볼 수 있죠.\n이때 잊지 말아야 할 것은 물가상승률인데요, 물가상승률을 매년 3%로 가정한다면 이를 적용해 2050년에 필요한 생활비를 계산해봐야 합니다. 이를 통해 현재의 금액뿐 아니라 미래의 경제 상황까지 고려한 현실적인 노후 자금 목표를 세울 수 있어요..\n8. 국민연금, 퇴직연금, 개인연금이라는 3단계 연금 가입 외에, 노후 대비를 위해 추가로 할 수 있는 게 있을까요?\n3단계를 모두 챙기고 있다면 이미 너무 잘하고 계신 거예요. 보통 개인연금 상품 중 수수료가 너무 비싼 것들도 있어서 배제하시는 경우도 있는데, 오랫동안 보유하면 수수료도 많이 상쇄된다는 점을 기억하시면 좋겠어요. 이렇게 3단계를 잘 쌓고 있는 분이라면, 이제 딱 두 가지가 남았을 거예요. 요즘 자격증을 많이 따시는 것처럼 은퇴 이후에도 추가 소득을 위해 일할 수 있는 전문성을 갖추는 것, 그리고 가장 중요한 건강입니다.\n9. 퇴직연금을 직접 운용하는데도 디폴트옵션을 설정해야 하나요?\n디폴트옵션은 내가 퇴직연금을 직접 운용하고 있더라도 반드시 설정해야 하는 항목입니다. 100% 투자상품으로 적립금을 운용하고 있다 하더라도 디폴트옵션을 설정하지 않으면 안 되니, 잊지 말고 선택하세요.\n현재 퇴직연금 적립금 약 400조 원 중 90% 가까이가 원리금보장형 상품에 투자되고 있습니다. 많은 사람들이 퇴직연금을 적극적으로 투자하는 데 어려움을 느끼기 때문인데요. 자신이 이런 경우에 해당한다면 퇴직연금사업자가 제공하는 디폴트옵션 상품 중 초저위험이 아닌 옵션을 선택해보길 권합니다.\n디폴트옵션은 초저위험, 저위험, 중위험, 고위험으로 분류돼요. 초저위험은 원리금보장형 상품으로만 구성되지만, 고위험 옵션으로 갈수록 TDF와 같은 실적배당형 상품의 비중이 높아져 수익성이 커질 가능성이 있습니다. 직접 투자상품을 선택하기 어렵다면, 잘 설계된 디폴트옵션 상품 중에서 적합한 것을 골라보세요. 디폴트옵션은 내가 가입한 퇴직연금사업자가 제공하는 상품만 선택할 수 있습니다. 예를 들어, A증권사의 퇴직연금 계좌에 가입했다면 A증권사가 제공하는 디폴트옵션 상품만 고를 수 있어요. 일부 사업자는 최대 10개의 디폴트옵션을 제공하기도 합니다.\n만약 은퇴까지 아직 시간이 많이 남아 있다면, 고위험군 옵션을 선택해 연금에 적립한 금액만큼은 공격적인 투자를 고려해보세요. 처음에 잘 몰라 초저위험으로 설정했더라도, 지금 내가 은퇴까지 얼마나 남았는지 등을 고려해 다시 선택할 수 있으니 그대로 두지 말고 조정하시길 바랍니다.\n10. 연금을 많이 받으면 다시 세금으로 토해내야 한다는 말이 사실인가요?\n세금은 언제나 복잡하고 어려운 주제예요. 공적연금과 사적연금의 세율 차이, 연금 수령 나이, 연금 수령 총액, 연금 외 소득 유무 등에 따라 세액이 달라집니다. 연금소득도 소득이므로, 소득이 많을수록 소득세도 많이 내야 하는 것은 맞습니다. 국세청을 참고한 뒤 나의 경우를 전문가와 상담하는 것이 가장 정확할 테니, 오늘은 절세를 위해 알아둬야 할 몇 가지를 말씀드릴게요.\n연금 소득의 종류에 따른 과세 방식\n앞서 말씀드린 연금 3단계는 공적연금(국민연금)과 사적연금(퇴직연금, 개인연금)으로 나뉘고, 과세 방식이 달라요. 공적연금은 종합소득세 신고 대상입니다. 연간 1,200만 원까지는 비과세되지만, 초과분은 과세돼요. 사적연금은 분리과세(연금소득세) 또는 종합소득세로 과세됩니다. 일반적으로 연간 1,500만 원까지는 낮은 세율(5.5%)이 적용되고요.\n절세를 위해 알아둬야 할 것들\n1. 1년에 받는 연금소득이 총 얼마냐에 따라 최대 900만 원까지 연금소득공제를 받을 수 있습니다. 이를 활용하면 과세 표준을 낮춰서 세금 부담을 줄일 수 있어요.\n연금소득 350만 원 이하: 전액 공제\n350만 원 초과~700만 원 이하: 350만 원 + 초과분의 40%\n700만 원 초과: 500만 원 + 초과분의 5%\n2. 사적연금 소득이 연 1,500만 원 이하일 때는 세율이 낮으므로 연금 수령액을 조정해 이 구간을 활용하세요. 연 1,500만 원이 넘는 경우 분리과세와 종합소득세 신고 중 세금이 낮은 쪽을 따져 선택해야 합니다. \n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}✱2024년 1월 1일부터 연금저축·퇴직연금 등 연금 소득에 대한 종합소득과세 기준이 1,200만 원에서 1,500만 원으로 상향되었어요.\n분리과세: 연간 1,500만 원까지 낮은 세율(5.5%~15%)로 과세됩니다.\n종합소득세 신고: 다른 소득(공적연금, 부동산 임대소득 등)과 합산해 신고합니다. 연금소득 외에 다른 소득이 많다면 분리과세가 유리할 수 있어요.\n3. 사적연금 세율은 70세 이전 5%, 70~79세 4%, 80세 이상 3%이기는 하지만, 여러 연금 상품을 가입한 경우 동시에 받으면 소득이 높아져 세율이 올라갈 수 있으니, 수령 시점을 조율해 세금을 최적화해야 해요.\n4. 부부가 각각 연금 상품을 보유하고 있다면, 연금을 분산 수령해서 종합소득 기준 금액을 낮춰 세율을 줄일 수 있어요.\n5. 연금 관련 세법은 매년 변화할 수 있으니 최신 정보를 확인하고 필요 시 세무 전문가의 상담을 받는 것이 중요합니다.\n\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n이 외에도 아래와 같은 질문을 많은 분들이 남겨주셨어요. <노후 준비 액션플랜>에 이전 화에서 소개했으니 아래 내용을 참고해주세요. \n\n.css-1odxvuk{white-space:pre-wrap;font-style:italic;}“노후 준비 자금은 어떻게 마련하나요?”\n”퇴직연금이 없는데 어디서부터 시작할지 모르겠어요.”\n👉 1화. 은퇴 후의 삶, 준비를 시작했나요?\n👉 3화. IRP(개인형 퇴직연금)도 똑똑한 가입 방법이 있다\n“노후엔 10억정도 필요하다던데 맞나요?”\n”1인당 노후 생활비는 얼마가 필요한가요?”\n👉 2화. 은퇴 계획의 큰 그림을 그려보는 법\n“TDF에 대한 정보를 어디서 얻나요?”\n👉 5화. TDF, 우리 모두의 은퇴 준비 필수품\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 주소은, 김현미(아이랩) Graphic 조수희",
        "content": "독자들이 가장 많이 한 질문에 영주 닐슨 교수가 직접 답했어요",
        "contentSnippet": "독자들이 가장 많이 한 질문에 영주 닐슨 교수가 직접 답했어요",
        "guid": "https://blog.toss.im/article/retirement-plans-08",
        "isoDate": "2025-01-22T13:23:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]