[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Michael Price",
        "title": "Microsoft C++ Team at CppCon 2025",
        "link": "https://devblogs.microsoft.com/cppblog/microsoft-at-cppcon-2025/",
        "pubDate": "Thu, 11 Sep 2025 22:41:21 +0000",
        "content:encodedSnippet": "It’s that time of year again! We are excited to see you all at CppCon this year, where we’ll once again be delivering a variety of presentations, from the latest advancements in debugging technology to extensibility frameworks for AI agents. See the end of this post for a listing of all of the sessions involving Microsoft staff. And yes, there’ll be plenty of information on the freshly announced Visual Studio 2026.\nWe’ll also have a booth through the first four days of the conference. Come on by and let us know what matters to you or ask any burning questions you may have regarding C++ at Microsoft. We will be well stocked with our most popular swag, so come on by and have a chat with us. There may even be appearances by speakers in case you didn’t get a chance to ask that all important question after their session.\nOur annual survey is now open and will be available all week throughout the conference. It’s super lightweight, and upon completion, CppCon attendees will be entered into a raffle for one of four great prizes. You do have to be onsite for the daily drawing to win (see official rules here), but even if you aren’t going to be at the conference, you can still complete the survey to let us know what you think of our C++ products. New this year on the survey is an option to select a dedicated time to talk with Microsoft staff about the topics you care about. So, if you don’t want to lose your voice in a crowded expo hall you can find that right time that fits into your busy schedule.\nTry out Visual Studio 2026 Insiders – Get Started Here\nVisual Studio 2026 and MSVC Build Tools v14.50 Preview are already available on the Insiders Channel (which replaces the previous Visual Studio 2022 Preview channel), with a Stable Channel going live later in 2025. We want to hear from you at CppCon about your experiences with Visual Studio 2026 Insiders, so give it a spin and come chat with us about your experiences.\nTalks from Microsoft employees (and friends)\nMonday 15th​\nBuilding Secure C++ Applications: A Practical End-to-End Approach, by Chandranath Bhattacharyya & Bharat Kumar\nTuesday​ 16th​\nWhat’s New for Visual Studio Code: CMake Improvements and GitHub Copilot Agents, by Alexandra Kemper\nWhat’s New in Visual Studio for C++ Developers in 2025, by David Li and Augustin Popa\nBack to Basics: Code Review, by Chandranath Bhattacharyya and Kathleen Baker\n​Wednesday 17th\nConnecting C++ Tools to AI Agents Using the Model Context Protocol (MCP), by Ben McMorran\nLLMs in the Trenches: Boosting System Programming with AI, by Ion Todirel\nWelcome to v1.0 of the meta::[[verse]]!, by Inbal Levi\n C++ Performance Tips: Cutting Down on Unnecessary Objects, by Prithvi Okade and Kathleen Baker\n Thursday 18th​​\nMSVC C++ Dynamic Debugging: How We Enabled Full Debuggability of Optimized Code, by Eric Brumer\nIt’s Dangerous to Go Alone: A Game Developer Tutorial, by Michael Price\nFriday 19th​​\nReflection-based JSON in C++ at Gigabytes per Second, by Daniel Lemire and Francisco Geiman Thiesen\nDuck-Tape Chronicles: Rust/C++ Interop, by Victor Ciura\nThe post Microsoft C++ Team at CppCon 2025 appeared first on C++ Team Blog.",
        "dc:creator": "Michael Price",
        "comments": "https://devblogs.microsoft.com/cppblog/microsoft-at-cppcon-2025/#respond",
        "content": "<p>&#160; It&#8217;s that time of year again! We are excited to see you all at CppCon this year, where we&#8217;ll once again be delivering a variety of presentations, from the latest advancements in debugging technology to extensibility frameworks for AI agents. See the end of this post for a listing of all of the sessions [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/microsoft-at-cppcon-2025/\">Microsoft C++ Team at CppCon 2025</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "It’s that time of year again! We are excited to see you all at CppCon this year, where we’ll once again be delivering a variety of presentations, from the latest advancements in debugging technology to extensibility frameworks for AI agents. See the end of this post for a listing of all of the sessions […]\nThe post Microsoft C++ Team at CppCon 2025 appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=35717",
        "categories": [
          "Announcement",
          "C++",
          "Survey"
        ],
        "isoDate": "2025-09-11T22:41:21.000Z"
      },
      {
        "creator": "Cameron DaCamara",
        "title": "C++ Language Updates in MSVC Build Tools v14.50",
        "link": "https://devblogs.microsoft.com/cppblog/c-language-updates-in-msvc-build-tools-v14-50/",
        "pubDate": "Wed, 10 Sep 2025 13:51:18 +0000",
        "content:encodedSnippet": "C++ Language Updates in MSVC Build Tools v14.50\nIt has been some time since we have provided an update on MSVC progress, and this one comes with the latest major update to our IDE: Visual Studio 2026 version 18.0. This version of Visual Studio ships with the MSVC Build Tools version 14.50, which includes version 19.50 of the MSVC compiler. You can try out the improvements by downloading the Insiders release. Also, if you want to track updates in the Standard Library, check out the STL Changelog, which is regularly updated. Let’s jump right into the updates!\nC++23 Features\nAs C++ standards progress in MSVC, you can follow along using the cppreference compiler support table and help us identify what we should be working on next!\nP0849R8 (auto(x): decay-copy in the language)\n// Prior to P0849R8:\r\nvoid pop_front_alike(auto& x) {\r\n    using T = std::decay_t<decltype(x.front())>;\r\n    std::erase(x, T(x.front()));\r\n}\r\n\r\n// After P0849R8:\r\nvoid pop_front_alike(auto& x) {\r\n    std::erase(x, auto(x.front()));\r\n}\r\n\nP2437R1 Implement C++23 #warning\n// Valid prior to C++23.\r\n#error bad configuration...\r\n// Valid after C++23.\r\n#warning configuration deprecated...\r\n\nCWG Issue 2586 (Explicit object parameter for assignment and comparison)\nstruct S {\r\n  S& operator=(this S&, const S&) = default; // Valid after CWG2586.\r\n  auto operator<=>(this const S&, const S&) = default; // Valid after CWG2586.\r\n};\r\n\nP2280R4, allowing references to unknown values during constant evaluation\ntemplate <typename T, size_t N>\r\nconstexpr size_t array_size(T (&)[N]) {\r\n    return N;\r\n}\r\n\r\nvoid check(int const (&param)[3]) {\r\n    constexpr auto s2 = array_size(param); // Previously ill-formed, now accepted as a constant expression after P2280R4.\r\n}\r\n\nSmaller Conformance Updates\nCWG2635 – Constrained structured bindings.\nCWG2465 (Coroutine parameters passed to a promise constructor)\nP2360R0 which extends the definition of an init-statement to allow an alias-declaration\nCWG2496 – ref-qualifiers and virtual overriding.\nCWG2506: Structured bindings and array cv-qualifiers.\nCWG2507 (default arguments for operator[]).\nCWG2585: No change required to behavior.\nP2290R3 C++23 Hex/oct delimited escape sequence support in string literals.\nCWG2521 which deprecates ‘operator string-literal identifier’.\nCWG2528 which relaxes conversion rules for the spaceship operator.\nP2797R0: Proposed resolution for CWG2692 Static and explicit object member functions with the same parameter-type-lists.\nP2266R3 Simpler implicit move.\nImplement a warning to notify of the enum type change caused by /Zc:enumTypes.\nCompiler Improvements in v14.50\nC++/CLI\nFix ICE on use of ‘auto’ in member declarations in C++/CLI managed types\n\nstatic constexpr causes C++/CLI compiler crash\nCompiler crashes: A managed type cannot have any friend functions/classes/interfaces\nFix crash in compiler in C++/CLI code using ref-types on stack\n\ncl.exe terminates with error code -529706956\nVisual Studio 17.12 introduced multiple errors while building managed C++ code in an MFC application\nDiagnostics\nFix an incorrect diagnostic about implicit enum type conversions in C even when the code explicitly converts the expression\n\n“warning C5287: operands are different enum types” even with an explicit cast\nconstexpr\nFixes several errors involving virtual function calls at compile-time.\n\nMSVC erroneously claims the return value of a virtual constexpr function-call operator is not a constant expression\nC++20 constexpr virtual polymorphism is broken in MSVC but works in ClangCL and intellisense\nVirtual constexpr function did not evaluate to a constant\nUnable to use virtual function in constexpr expression\nconstexpr should reject overflow from addition and left shifting of constants\n\nSigned overflow in core constant expression should not be allowed in all cases\nFix scenarios where constructors should be made implicitly constexpr\n\nMultiple constexpr bugs (including regresions)\nFixes scenario when initializing a constexpr variable with a consteval call\n\nMultiple constexpr bugs (including regresions)\nFix an issue with constexpr static data members and the CRTP.\n\nCRTP in MSVC 19.24 not seeing variable\nStatic constexpr member of CRTP base class not seen\nFixes a bug related to evaluating destructors of constant objects too early; objects appeared at runtime to be in their destroyed state.\n\nMSVC 14.37-40 forces my global std::string to be constinit; constinit strings don’t survive intact\nFix an issue with constexpr lambda captures and guaranteed copy elision with a compiler generated call to memset.\n\nLambda in a function template requests capturing a constexpr variable which is not odr-used\nAllow consteval constructor calls as argument of direct-initialization.\n\nMSVC Fails to compile list and direct initialization in C++20 when member constructor is consteval\nFixed an issue where calling certain consteval functions in an if consteval would sometimes produce a compiler error.\n\nThe consteval function is not an immediate function under if consteval\nAllow constexpr references to be initialized with derived class rvalue.\n\nDowncasting constexpr instance with static_cast not valid in constant expression\nwrong code bug in constexpr evaluation\nC++ Modules\nFix bug with importing friend declaration where the class-head-name was in a particular qualified-id form, encountered in nlohmann/json library.\n\nnlohmann/json does not compile as C++20 module\nFix compiler crash when using-declarations are used from a specialization inside a module.\n\nInternal compiler error when using “using” declaration with template base class in module fragments\nFix an issue that std::expected can’t be specialized in some cases when imported from a module.\n\nC1907 modules, constexpr and std::expected\nFixed an issue where functions using types from a named module would sometimes not execute properly or cause linker failures.\n\nCompiler uses non-exported class definition from wrong module (C++20)\nFix issue when importing a constexpr function with static local variables\n\nICE when calling imported function that returns local static container data\nFixed an issue where the compiler would sometimes not respect a #pragma warning(disable:...) when the pragma appeared in a module or header unit.\n\n#pragma warning(disable) not working in nested headers used with header units\nFixed various issues preventing Unreal Engine 5 from building with header units.\n\nUnreal does not build with header units enabled\nC++ modules compiler error: Base class undefined\nC++20 modules + boost::asio still being weird\nC++20 modules: specialzations in the global module fragment are discarded even if they are decl-rechable\nConformance\nAdd support for ‘[[maybe_unused]]’ on labels and fix an issue where warning C4102 (unreferenced label) was being emitted when the only reference was from a discarded branch of an if-constexpr statement.\n\n“unreferenced label” when ref hidden by “if constexpr”\nDiagnose ill-formed friend explicit specializations that were incorrectly accepted in C++20 or later.\n\nDefining explicit function template specialization in friend declaration is wrongly permitted\nFix an issue with the compiler allowing specifiers (other than type-specifiers) as part of a type-id\n\n[accepts invalid] cl will accept constexpr template arguments\nAdd a switch, ‘/Zc:enumEncoding’, to correctly encode the use of an enumeration as a non-type template parameter.\n\nOverload resolution fails for enum non-type template parameters\nFix an issue in which the compiler did not issue a diagnostic if a user did not prepend a dependent template-id with the ‘template’ keyword.\n\nNo diagnostic for missing .template in dependent names\nFix an issue with the compiler allowing specifiers (other than type-specifiers) as part of a type-id\n\n[accepts invalid] cl will accept constexpr template arguments\nReliability\nFix an ICE when explicitly instantiating a class template which has friend functions.\n\nInternal compiler error (ICE) on explicit class instantiation new to VS 2022 17.14\nFix an ICE involving explicit variable template instantiations when PCH files are used.\n\nC++ explicit variable template instantiation causes internal compiler error when using precompiled header\nFix a compiler crash involving deep nesting of aggregates, non-aggregates, and initializer lists\n\nInternal Compiler Error Found in MSVC 14.44.35207\nFix an issue with nested generic lambdas and an issue with using ‘template’ in a qualified-id\n\nVS 17.14 Preview 3.0: ICE: error C1001: Internal compiler error.\n17.14 Preview 3 Internal compiler error\nFixes internal compiler error when elaborating a struct with the same name as overloaded member functions\n\nTemplate Internal Compiler Error\nFixed a logic error that caused an exponential growth in memory usage during type deduction if a class type had a lot of base classes\n\nVS 2022 C++ compiler uses nearly 200x as much memory as VS 2019 compiler\nFix an issue with the IL we generate for a temporary that it bound to a non-static data member of reference type.\n\nCL.exe crashes with Access Violation on specific code involving references\nFix a compiler ICE when the nested lambda inside a generic lambda references a qualified name.\n\nVS 17.14 ICE with a very particular function template\nFixed an ICE after error when the compiler saw an if constexpr with empty condition.\n\nInternal compiler error parsing invalid if constexpr\nFix a compiler crash associated with initializing a bit field.\n\nInternal compiler error in VS2022 17.10+\nFix an issue with the compiler complaining about an ill-formed pure-specifier within a function template\n\nErroneous reporting of C5288 with class defined in function template in MSVC 14.44.35207\nFix a compiler ICE when the nested lambda inside a generic lambda references a captured variable.\n\nICE with nested std::visit + lambda captures\nFix crash when comma missing between designated initializers\n\nInternal compiler error with designated initializer in lambda\nFixes a compiler crash with initialization of aggregates involving commas and initializer lists.\n\nInternal Compiler Error Found in MSVC 14.44.35207\nFix an issue with lambdas and non-type template parameters whose type is a pointer-to-member.\n\nInternal Compiler Error (ICE) on function returning closure object\nCorrect bad code generation for certain templated conversion operators\n\nWrong code generation in use of templated conversion operator with explicit object parameter\nFix an internal compiler error during initialization of nested aggregates with initializer lists\n\nInternal Compiler Error Found in MSVC 14.44.35207\nICE when trying to access not captured pointer in lambda\nfatal error C1001: Internal compiler error.\nCorrectness\nFix an issue with exception handling and unions; and an issue with the handling of an rvalue reference in the context of a lambda.\n\nInternal compiler error when compiling C++17 code using union and std::array\nWhen using a lambda as a template argument for a callback, the reference is not correctly bound.\nFix an issue when explicit instantiation sometimes picks the wrong overload which has a requires clause.\n\nOverload resolution for constrained function templates confused by explicit instantiation\nCorrect some semantic issues with noexcept specifiers and compile errors for some noexcept specifiers on member functions.\n\nnoexcept for some reason work with type\nnoexcept doesn’t wants to work with operator type cast\n[C++] Post-increment operator cannot refer to this pointer in noexcept specifier\nFix an issue with phase-1 name binding in a non-static data member initializer\n\nWrong context for class field initializer\nFix an incorrect value category for expressions involving indirections and arrays.\n\ncl Preview fails to properly determine assignment of a prvalue\nFix a syntax error when parsing certain template-ids in alias declarations inside some templates.\n\nSource code parsing error in boost.parser in 17.14 Preview\nFix an issue with partial ordering and template parameter objects\n\nTemplate Specialization is not selected when passing out-of-line Lambda NTTP\nFix a bad error C2355 on ‘this’ in a local class declaration.\n\nC2355 is wrongly triggered when local class is defined in a static member function\nFix an issue with the re-declaration of constexpr variables and an issue with parsing a bit-field width within a partial specialization of a class template.\n\nA C1001 error occurs in VS17.14\nCode does not compile with MSVC\nFix an issue causing __declspec(no_sanitize_address) to be ignored on lambdas and forward-declared functions.\n\nAddress Sanitizer declspecs/attributes do not behave consistently across compilers\nFix incorrect point of instantiation when an inline static data member has a class template specialization type.\n\nstatic inline atomic and another atomic generate warning C4744 in Release configuration\nFix an issue when a static operator() was also an abbreviated function template.\n\nCall to static operator() is elided\nFix an issue with no_unique_address and class types with common subobjects.\n\n[[[msvc::no_unique_address]] incorrectly optimizes mixed structs with leading nested empty struct](https://developercommunity.visualstudio.com/t/msvc::no_unique_address-fails-to-opt/10892814)\nFix an issue with template template parameters and default template arguments\n\nVS2022 VC++ default template parameter derivation error causes the result to be inconsistent with expectations\nFix incorrect resolution of a name referring to the enclosing class template.\n\nMSVC Fails to compile friend function template whose template constraint (C++20) contains the enclosing class template\nFix an issue causing error C2106 on certain member-access expressions that should be lvalues.\n\nAfter updating VS2022 to 17.14 C++ compiler is giving me an error about lvalue and ending up with ICE (open source code)\nFixed an issue where decltype would sometimes return the wrong type when used with ternary expressions.\n\nconditional operator gives wrong result type if both operands are static_cast to prvalue pointer type\nFix 1) an issue with C++23 multi-dimensional array indexing; 2) an issue with allowing ‘[[maybe_unused]]’ on a label; and 3) an issue with the compiler being too eager to instantiate a specialization of a function template.\n\nMultidimensional operator[] with /Wall reports bogus warning C4548\nDiscarded statement instantiated in a generic lambda\nFix an issue with C4100 (unreferenced parameter) and abbreviated function template; and an issue with a missing warning for using a comma operator in subscript expression\n\nBogus C4100 “unreferenced formal parameter” warning with if constexpr in static member function template of a class template\nFix spurious unreferenced variable warning for OpenMP private loop variable.\n\nIncorrect C4101 OpenMP compiler warning in 17.8.0\nFix issues with ‘std::bit_cast’, integral non-type template parameters and instantiation of variable templates.\n\n__builtin_bit_cast Internal compiler error\nIssue in specific conditions with modulo operator in variadic template with “/permissive-” after version 19.32.\nFix spurious warning C4193 when compiling some preprocessed files\n\nIncorrect C4193 with /std:c++20\nFix a missing error when aggregate initialization is incorrectly used during class template argument deduction.\n\nDeduction of class template arguments picks up wrong constructor\nFix determination of value category for certain kinds of expressions involving a sub-expression that is a conditional expression.\n\nClass member’s array’s element is not an l-value in a ternary expression\nFix an issue with an elaborated class-specifier in a template argument list\n\n[Unreal Engine] Template compile error regression with msvc 14.42\nFix an issue with operator binding and an issue with binding local class types.\n\n[Unreal Engine] Template compile error with msvc 14.44\nFix a couple of issue related to using enum declarations.\n\nusing enum c++ 20 doesnt supported as well\nMSVC does not compile a function type with multiple parentheses\nDefining class method outside the class, with concept\nVariable Declaration Allowed Inside Switch Case Without Scoping Operator\nNo warning C4706 for assignment to std::unqiue_ptr used as a condition\nVS 17.14. “if constexpr (requires ” doesn’t work correctly\nIncorrect overload resolution for static operator()\nLvalue-to-rvalue conversion rules for std::nullptr_t are violated\nError message depends on unused parameter pack\nIn-class initialization of pointer-to-member + virtual function make MSVC to compile incorrectly\nMSVC Compiler Bug: requires Constraint Fails to Remove Non-Matching Template Candidates, Leading to Compilation Error\nRegression: c++ compilation failure in code generated by Qt’s meta object compiler\nRejects valid pack expansion in base specifier in lambda body\nCorrectness (C compiler)\nIn C23, don’t decay functions to function pointers when used as an argument to typeof\n\ntypeof not working with function types\nClosing\nAs always, we welcome your feedback. Feel free to send any comments through e-mail at visualcpp@microsoft.com, through Twitter @visualc, or through BlueSky @msftcpp.bsky.social. Also, feel free to follow Cameron DaCamara on Twitter @starfreakclone.\nIf you encounter other problems with MSVC in Visual Studio 2026 please let us know via the Report a Problem option, either from the installer or the Visual Studio IDE itself. For suggestions or bug reports, let us know through Developer Community.\n \nThe post C++ Language Updates in MSVC Build Tools v14.50 appeared first on C++ Team Blog.",
        "dc:creator": "Cameron DaCamara",
        "comments": "https://devblogs.microsoft.com/cppblog/c-language-updates-in-msvc-build-tools-v14-50/#comments",
        "content": "<p>C++ Language Updates in MSVC Build Tools v14.50 It has been some time since we have provided an update on MSVC progress, and this one comes with the latest major update to our IDE: Visual Studio 2026 version 18.0. This version of Visual Studio ships with the MSVC Build Tools version 14.50, which includes version [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/c-language-updates-in-msvc-build-tools-v14-50/\">C++ Language Updates in MSVC Build Tools v14.50</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "C++ Language Updates in MSVC Build Tools v14.50 It has been some time since we have provided an update on MSVC progress, and this one comes with the latest major update to our IDE: Visual Studio 2026 version 18.0. This version of Visual Studio ships with the MSVC Build Tools version 14.50, which includes version […]\nThe post C++ Language Updates in MSVC Build Tools v14.50 appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=35720",
        "categories": [
          "Announcement",
          "C++",
          "Featured",
          "C++ language",
          "compiler",
          "MSVC",
          "VC++"
        ],
        "isoDate": "2025-09-10T13:51:18.000Z"
      }
    ]
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Read Meta’s 2025 Sustainability Report",
        "link": "https://sustainability.atmeta.com/2025-sustainability-report/",
        "pubDate": "Fri, 12 Sep 2025 16:36:33 +0000",
        "content:encodedSnippet": "The post Read Meta’s 2025 Sustainability Report appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p> [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://sustainability.atmeta.com/2025-sustainability-report/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://sustainability.atmeta.com/2025-sustainability-report/\">Read Meta&#8217;s 2025 Sustainability Report</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "[...]\nRead More...\nThe post Read Meta’s 2025 Sustainability Report appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=22907",
        "categories": [
          "Uncategorized"
        ],
        "isoDate": "2025-09-12T16:36:33.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Maksim Sobolevskiy",
        "title": "A Farewell to Consoles",
        "link": "https://blog.jetbrains.com/datagrip/2025/09/16/a-farewell-to-consoles/",
        "pubDate": "Tue, 16 Sep 2025 16:46:20 +0000",
        "content:encodedSnippet": "Starting from the 2025.3 release, DataGrip and other JetBrains IDEs with database support will stop using the term query console. From now on, we’ll use query file – because consoles were essentially files all along, and it’s time the UI reflected that. We’ve made the workflow simpler, more discoverable, and more consistent.\nA bit of history 🏛️\nWhy did we have consoles in the first place? Here’s the short story.\nBack when JetBrains first added database functionality to IntelliJ IDEA, Java developers mostly worked with databases from the terminal. The quickest way to bring that workflow into the IDE was to give people a temporary area for writing SQL – and that temporary SQL file was called a console.\nFor many years, the IDE provided just one default console per project, and that seemed fine, but users asked for more. They wanted multiple consoles, the ability to pick the database or schema, and better control over context via the UI.\nProblems 😬\nConsoles were essentially script files, similar to what other database tools provide, but with a few quirks:\nNot part of the project. Consoles lived outside the project structure, even though users worked in a project in DataGrip.\nHard to find. They were stored in an obscure folder (next to scratch files), causing people to create consoles and then not know where to look for them. Because DataGrip autosaves these consoles, nothing was lost – but that made discovery more difficult. Users wouldn’t get a “save” prompt, so they’d create consoles and later be surprised they couldn’t find them or change their context without extra steps.\nDifficult context switching. You couldn’t change the dialect, data source, or schema for a console file via the UI. If you wanted it to behave like a local file, you had to manually save or transfer it.\nConfusing name. The term query console didn’t communicate what the feature actually was, and we kept getting feedback that newcomers didn’t understand it.\nIn short, consoles were useful in spirit but awkward in practice. Something had to change.\nThe change 🧚🏻‍♀️\nWe agonized, deliberated, and then did the obvious: merged consoles and files.\nPractically, query editing is now file-based, so query scripts are visible in your project, easy to locate, and flexible to manage.\nHow it works now:\nTo write a query to the database, create a query file from the context menu of the data source or any of its objects, like you did before with query consoles. This new file will be named Query_[$DATA_SOURCE$].sql.  The name pattern can be customized in Settings.\n\n\n\n\n\n\n\n\n\n\nBy default, query files are saved in the queries folder, which is located in the project folder. The project folder (and the queries folder) is visible in the Files tool window. You can change the storage path in Settings, and any custom folder you select will also appear in the Files tool window.\n\n\n\n\nFiles with an attached database context now show a data-source-like icon instead of the generic database icon used before. This should make query files easier to spot. We’d especially love to hear your feedback about this visual update.\n\n\n\n\n\n\n\n\n\n\nAll prior console limitations are gone! You can now re-attach query files, change their dialect and data source, and treat them like ordinary project files.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Jump to Query Console button on the database explorer toolbar has been renamed to Jump to Query File and given a new icon. It now lists all query files associated with the current data source.\n\n\n\n\n\n\n\n\n\n\n\n\nWhen you upgrade DataGrip, a migration dialog will help you transfer all of your consoles to files and guide you through the new workflow.\n\n\n\n\n\n\n\n\n\n\nThe old Database Consoles folder under the Scratches and Consoles will remain for one more release cycle, after which we’ll remove it completely.\n\n\n\n\n\n\n\n\n\nFAQ ❓\nWill my existing consoles be lost? \n\nNo. We’re carefully converting them to *.sql files and keeping them in the old location, but only for one release cycle.\nCan I keep the old behavior?\n\nTechnically, you can, but only for one more release cycle and only for old projects. You will keep seeing a migration dialog after each IDE restart, however. For new projects, only the new logic will work.\nWhat happens to the consoles of global data sources?\nIn the migration dialog, you will be able to define a separate folder for migrating consoles of such data sources. This folder will be saved in the settings and will serve as the default location for query files created for global data sources. To access these files from the IDE, you will need to attach the folder to each specific project.\nWill the same thing happen in other JetBrains IDEs?\n\nYes, but for now it’s only released in DataGrip EAP. The only difference is that in other JetBrains IDEs with database functionality, query files are migrated by default to a folder inside the .idea subfolder within the project. This folder is usually listed in .gitignore.\nWhat’s next ⏭️\nLater in this 2025.3 release cycle, we’ll add a Query Files node to the database explorer. Clicking it will show all files associated with the current data source, further improving discoverability.\nWe’re rolling out this change in the first EAP build to gather feedback from our community. Please try it out and tell us what’s missing.\n\n\n\n\nLet us know what you think in any of these ways:\nComment in the corresponding YouTrack ticket\nComplete the feedback form: https://www.jetbrains.com/feedback/datagrip/\nEmail us at datagrip@jetbrains.com\nTag @DataGrip on X or follow https://x.com/datagrip\nWe look forward to hearing your feedback!\nThe DataGrip team",
        "dc:creator": "Maksim Sobolevskiy",
        "content": "Starting from the 2025.3 release, DataGrip and other JetBrains IDEs with database support will stop using the term query console. From now on, we’ll use query file – because consoles were essentially files all along, and it’s time the UI reflected that. We&#8217;ve made the workflow simpler, more discoverable, and more consistent. A bit of [&#8230;]",
        "contentSnippet": "Starting from the 2025.3 release, DataGrip and other JetBrains IDEs with database support will stop using the term query console. From now on, we’ll use query file – because consoles were essentially files all along, and it’s time the UI reflected that. We’ve made the workflow simpler, more discoverable, and more consistent. A bit of […]",
        "guid": "https://blog.jetbrains.com/?post_type=datagrip&p=598617",
        "isoDate": "2025-09-16T16:46:20.000Z"
      },
      {
        "creator": "Ilya Petrov",
        "title": "FAQ: New AI Quotas",
        "link": "https://blog.jetbrains.com/ai/2025/09/faq-new-ai-quota/",
        "pubDate": "Tue, 16 Sep 2025 15:01:26 +0000",
        "content:encodedSnippet": "We hear you. And you’re right – the new quotas are a reduction from what you experienced. When we launched, we had little usage data for agentic experiences and no top‑up feature existed, so we set quotas much higher than the real cost of AI usage (tokens from providers) as a temporary measure. That felt great, but it loses money at scale and puts the product at risk. We set expectations incorrectly. That’s on us.\nCheck more details about the new quotas in the original blog post.\nYour Most Frequent Questions\n“It’s not transparency; it’s paying more for less.”\nFirst, cost. There’s no scam here. We’re aligning usage to real, public provider prices per token. Whether you run through us or directly with providers, it will be similar. Discounts vary, and yes, some companies still burn VC money to attract users (also that’s changing). We’re a real business; we can’t play that game. This is the real price of AI. Our job now is to make sure the value you get from our product far exceeds what you spend.\nSecond, transparency. We’ll roll out UX updates with statistics in a few weeks, and more usage details and controls after that. Being transparent about a bad situation is better than having unclear or uncontrolled terms. Our previous quotas were a temporary measure, and so they were not transparent. With the new approach, the rules of the game are clear. This is a sustainable foundation that will help us look further into the future and design new products and services around it. \n\n\n\n\n“I can’t estimate how many credits I need for specific tasks.”\nAI usage isn’t a flat fee because it depends on the type of model you use and the amount of text (tokens) flowing in and out. That means the same question can cost differently depending on how it’s phrased, how much context is added, or how long the conversation goes. In agentic workflows, where the AI may iterate and correct itself, usage can naturally be higher.\nThat said, you don’t have to fly blind. We aim to give you the tools to get the best grasp on AI usage and make sure you stay in control:\nClear pricing per credit: We align with public provider costs, so you always know the unit price.\nTransparent usage stats: We’re rolling out UX updates that let you see exactly where credits go. It will roll out in waves, with the first wave in the next few weeks.\nBest-practice guides: We will share ways to phrase prompts and structure workflows so you get quality results faster (and spend less).\nSafeguards: Subscription quotas and alerts help prevent unexpected overuse, and you can always top up to continue your work.\nThink of credits like fuel for your AI workflows: you may not know the exact mileage before the trip, but you’ll always see your fuel gauge and can plan accordingly.\n“My quota runs out in half a day. Is it a bug?”\nNo – the quota got smaller for both AI Pro and AI Ultimate. In our data, about 80% of users (plan and usage dependent) won’t hit the new limits. The downside is that the most active AI users are the most affected.\nAgain, we’re not targeting you and we’re not slicing by some percentile; we’re aligning with costs so we don’t burn money indefinitely, while still giving away more (e.g. AI Ultimate includes roughly 15% more value than you pay each month, and annual plans can go up to about 40% more than your pay). \nThere’s another reason quotas can vanish fast: agentic workflows. Agents collect context and iterate through a plan; that means multiple, long requests that eat tokens. Junie, our coding agent, is built for quality on real‑world dev tasks. Speed and cost are part of the product. Early on, we took this risk on us. That was fine for kick‑off – but it’s not how this works long‑term.\nJunie is designed for complex tasks and provides high quality output. Code generation, verification and tests together take more AI credits – but it also helps Junie achieve the better result for your job. We don’t want to sacrifice quality over speed: we benchmark the models and choose the best for your tasks, we always prioritize Junie’s ability to compare the solutions and offer you the most suitable one. We train Junie to verify the steps it is taking – not just to generate code faster, but to create solutions that you can use and maintain. All this helps Junie perform like agents in more expensive plans (up to $200/month), but we aim to keep the cost of usage reasonable and constantly work on optimization.\nSmart ways to think about your AI quota\nTrack your usage (detailed stats are coming soon; for now, watch your in‑app meter).\nConsider the best tool for the task – whether it’s an AI agent (complex workflows, iterations, validation, etc.) or an AI assistant (more straightforward Q&A and one-step solutions). \nBe intentional with the way you prompt and the model choice (e.g., GPT‑5 is often cheaper than Claude 4 with comparable results – try switching if it works for you).\nStart over instead of a follow-up if you feel that the agent is lost. Based on the way LLMs work, multiple follow-ups (e.g., more than seven) usually drift away and take more credits (the longer the chat, the more context is passed with every request) but may not get you closer to the result you have in mind.\nFavor smaller/cheaper models for drafts (check the hints in AI Chat), then upgrade for final runs.\n“I just paid for an annual AI subscription based on the old patterns. Why no refund?”\nWe do have a refund policy, and some of you have already received refunds that extended your non‑AI subscriptions. Given this, we understand the frustration. Even if the refund window has passed, we’ve prepared a set of special alternatives for annual AI Pro and AI Ultimate users; you can select the one that works best for you. Keep in mind that we can’t grant refunds for All Products Pack and dotUltimate beyond regular policies, because AI Pro was included there at no extra charge.\nThat said, we still think annual subscriptions are a good deal. Example: AI Ultimate (annual) gives you 420 AI Credits for $300 — roughly 40% more credits than your payment at public rates.\n***\nAI is a great tool, and it’s changing how we build software. But it’s not magic — especially not free, unlimited magic. As professionals, we should understand how it works, how much it costs, and how to use it better. In the real world, speed and cost matter as much as quality. We believe that’s where the industry is heading. So let’s face it and start mastering these together.\nThank you to everyone who’s supported us – and for all the honest feedback. We’re building a sustainable business. Our future is tied to the value we create for you, so we’ll keep delivering exactly that step by step.",
        "dc:creator": "Ilya Petrov",
        "content": "We hear you. And you’re right – the new quotas are a reduction from what you experienced. When we launched, we had little usage data for agentic experiences and no top‑up feature existed, so we set quotas much higher than the real cost of AI usage (tokens from providers) as a temporary measure. That felt [&#8230;]",
        "contentSnippet": "We hear you. And you’re right – the new quotas are a reduction from what you experienced. When we launched, we had little usage data for agentic experiences and no top‑up feature existed, so we set quotas much higher than the real cost of AI usage (tokens from providers) as a temporary measure. That felt […]",
        "guid": "https://blog.jetbrains.com/?post_type=ai&p=608490",
        "categories": [
          "news",
          "ai-assistant",
          "ai-in-ides",
          "junie"
        ],
        "isoDate": "2025-09-16T15:01:26.000Z"
      },
      {
        "creator": "Maria Kosukhina",
        "title": "IntelliJ IDEA 2025.3 Early Access Program Is Open!",
        "link": "https://blog.jetbrains.com/idea/2025/09/intellij-idea-2025-3-eap/",
        "pubDate": "Tue, 16 Sep 2025 11:46:24 +0000",
        "content:encodedSnippet": "We’re kicking off the next development cycle and inviting you to join it.\nThe Early Access Program (EAP) for IntelliJ IDEA 2025.3 is now open, offering an early look at the new features and improvements we’re working on. By evaluating new features and sharing constructive feedback, you help us provide you with powerful, reliable tooling for professional development.\n\n\n\n\nAs always, EAP builds are free to use and can be installed side by side with your stable IDE version. You can get EAP builds from the Toolbox App, download them from the website, or use snaps for Ubuntu.\nDownload IntelliJ IDEA 2025.3 EAP\nPlease note that EAP builds are not fully tested and might be unstable, as the version is still a work in progress. Please keep this in mind when using them.\nIn this post, we’d like to share a glimpse of what’s in our planning dashboards for the upcoming release. The list below is neither final nor exhaustive, but it’s meant to show the direction we’re heading.\nSingle distribution \nIn 2025.3, IntelliJ IDEA will move to unified distribution, and several important changes related will appear during the EAP cycle. These include more features becoming available without subscription, such as wizards, basic highlighting for JavaScript, SQL, JPQL, template engines markup, and support database schema exploration. A detailed list of features going free will be published closer to the release.\nAlso there will be no IntelliJ IDEA Community Edition EAP builds available in the Toolbox App or from the IntelliJ Platform Gradle plugin. Please use the EAP builds of IntelliJ IDEA Ultimate instead. More information about Gradle builds will be published later on platform.jetbrains.com.\nTechnology updates \nWe’re continuing our effort to support the latest technologies you may use in your projects. This release brings full support for Java 25, Spring Boot 4, JUnit 6, all expected to be released within the next few months.\nSpring \nIn addition to supporting new features introduced for Spring 7, we’re working on significantly improving Spring Data JDBC support and extending the capabilities of the Spring Debugger introduced in v2025.2.\nKotlin\nKotlin support in the IDE continues to improve, with enhancements to code completion and overall quality in K2 mode. In addition to support for Spring 7, the Kotlin Routing DSL is getting better IDE assistance, along with various quality-of-life improvements for Spring development.\nFor Kotlin Notebook, we’re also improving stability and adding more improvements, like support for database integration – one of the most common scenarios in server-side development.\nKubernetes support\nStarting with 2025.3, we’re improving the experience of working with Kubernetes YAML files. We’re aiming to enable inlay quick actions in the editor for faster port forwarding, resource status updates, current context selection, and easier access to secrets.\nUser experience\nIn v2025.3, IntelliJ IDEA is getting a visual upgrade – the new Islands theme. Based on the feedback we’ve collected and our experiments in the previous release cycle, we’re now looking into making it the new default. We are going to share more details about the new theme soon.\nMeanwhile, you can try the Islands theme in this EAP build by enabling it in Settings | Appearance & Behavior | Appearance | Theme.\nAnother notable change we’re working on is the new Welcome screen that takes you straight into the IDE, with no extra dialog windows or additional clicks.\nWe’re also working on improving how the IDE communicates with you while project indexes are still being built. This includes a clearer overview of background tasks and more transparent, predictable progress indicators so you can stay focused on your code with fewer distractions.\nRemote development\nFollowing the improvements introduced in the previous release to refine the remote development experience, we’re continuing in the same direction. In v2025.3, we plan to enable smoother typing for more languages including CSS, JavaScript, TypeScript, and shell scripts. Additionally, the launch experience is being revamped to accelerate startup and make it more seamless.\nTerminal\nIn v2025.3, we’re bringing AI support to the terminal, starting with inline completion as the first step.\nStability\nA large portion of our team’s workload is dedicated to maintaining the quality and stability of the IDE. We’ll communicate those improvements in a dedicated What’s Fixed post, like we did for the previous release.\nFor the full list of fixes and improvements already included in the first 2025.3 EAP build, please refer to the release notes.\nShare your feedback\nTake part in the Early Access Program by trying out the EAP builds and sharing your feedback with us. You can get in touch with us on X, BlueSky or LinkedIn, or leave a comment below. If you come across a bug or something that doesn’t work as expected, please report it via our issue tracker.\nHappy developing!",
        "dc:creator": "Maria Kosukhina",
        "content": "We&#8217;re kicking off the next development cycle and inviting you to join it. The Early Access Program (EAP) for IntelliJ IDEA 2025.3 is now open, offering an early look at the new features and improvements we’re working on. By evaluating new features and sharing constructive feedback, you help us provide you with powerful, reliable tooling [&#8230;]",
        "contentSnippet": "We’re kicking off the next development cycle and inviting you to join it. The Early Access Program (EAP) for IntelliJ IDEA 2025.3 is now open, offering an early look at the new features and improvements we’re working on. By evaluating new features and sharing constructive feedback, you help us provide you with powerful, reliable tooling […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=599251",
        "categories": [
          "eap",
          "2025-3-eap",
          "intellij-idea",
          "intellij-idea-2025-3"
        ],
        "isoDate": "2025-09-16T11:46:24.000Z"
      },
      {
        "creator": "Marit van Dijk",
        "title": "Java 25 LTS and IntelliJ IDEA",
        "link": "https://blog.jetbrains.com/idea/2025/09/java-25-lts-and-intellij-idea/",
        "pubDate": "Tue, 16 Sep 2025 11:15:34 +0000",
        "content:encodedSnippet": "The Java release cadence means we get a new Java version every six months. Java 25 was released on September 16, 2025. At JetBrains, we are committed to supporting new technologies in IntelliJ IDEA and adding useful enhancements for both stable and preview features. In this blog post, we will give you an overview of some changes to the Java language and how they are supported in IntelliJ IDEA. This post is limited to stable features only. Preview features will be covered separately in dedicated blog posts on relevant topics.\nJava 25 includes several changes to the language that make Java easier to use. Features like compact source files and instance main methods, as well as module import declarations, make it easier to get started with Java, both for students and when creating small projects like prototypes or hobby projects. Flexible constructor bodies allow more flexibility in constructors, giving you the option to calculate or validate data before calling the constructor of the super class. Scoped values are a new model for thread-local variables, adapted to virtual threads. They will be more useful with structured concurrency, which is currently still in preview.\nApart from changes to the language itself, there are improvements to both performance and performance insights. Compact object headers reduce memory footprint and improve cache efficiency. Ahead-of-time method profiling lets the JVM warm up more quickly by using execution data from prior runs, improving startup performance. Improvements to garbage collection (GC) like generational Shenandoah, plus better class-loading and linking optimizations, contribute to noticeably smoother server-style workloads.\nAs Java 25 is an LTS (long-term support) release, many people will be migrating to this version from Java 21, 17, 11, or even earlier. If you are coming to Java 25 from Java 21, have a look at the section describing the most relevant changes since Java 21.\nBefore diving into the new features, let’s set up IntelliJ IDEA to use Java 25.\nUsing Java 25 in IntelliJ IDEA (setup)\nTo use Java 25, you will need to download the JDK. You can do so from inside IntelliJ IDEA or by using tools like SDKMAN! To download a JDK from IntelliJ IDEA, open the Project Structure, go to the tab Project Settings | Project, open the drop-down menu in the SDK field, and select Download JDK. \nDownloading JDK from inside IntelliJ IDEA\n\n\n\nIn the Download JDK popup that opens, set Version to 25, and in the Vendor field, select the vendor you want to use. \nYou can also download Early Access (EA) versions of the JDK from inside IntelliJ IDEA, for example, when the next release becomes available or if you’d like to try Valhalla (which is based on Java 23). IntelliJ IDEA will warn you that these are not intended for production use. \nDownloading an Early Access version\n\n\n\nNext, you need to configure IntelliJ IDEA to use the right language level. To use Java 25 stable features, which is recommended for production code, set Language level to 25 – Compact source files, module imports.\nSetting Language level to 25\n\n\n\nIf you want to try out preview features, set Language level to 25 (Preview) – Primitive Types in Patterns, etc.\nSetting Language level to 25 (Preview)\n\n\n\nNew stable features in Java 25\nLet’s take a look at some of the features Java 25 introduces and how IntelliJ IDEA can help you use them.\nCompact Source Files and Instance Main Methods (JEP 512)\nJava has been working on the so-called “on-ramp”, making the language easier to use. Compact source files and instance main methods are part of that effort. It is now possible for beginners to start writing code without needing to learn about language concepts that they won’t need until they start writing larger programs. For experienced programmers, this feature can help them quickly prototype ideas without needing a lot of boilerplate code. Code can be evolved and expanded as skills and applications grow. \nTo quickly see the difference, let’s look at a classic example: `HelloWorld`. We have probably all written a HelloWorld example when we first started, possibly in a language other than Java or English. The classic `HelloWorld.java` looks like this:\npublic class HelloWorld {\n   public static void main(String[] args) {\n       System.out.println(\"Hello, World!\");\n   }\n}\nTo write this code, you had to declare a class and a lengthy main method, including concepts like `public` and `static` that are not relevant to beginners. Let’s compare this to the `HelloWorld` example using new features from compact source files and instance main methods. \nWhen creating a new Java class via New | Java Class, in the New Java Class popup, select the Compact source file option. Note that this compact source file is created in the root directory of your project, even if you create it from another package. IntelliJ IDEA automatically adds an instance main method – `void main()` – to the file. Next, you can add a method to print “Hello, World!”. You can now use `IO.println()` as a convenience method without needing to understand what `System.out` means and without even needing to add a static import. If you do want to add a static import for `java.lang.IO`, IntelliJ IDEA offers a quick-fix to do so.\nCreating `HelloWorld.java`\n\n\n\nNote that different variations of the main method are now possible, as described here.\nIntelliJ IDEA has some new live templates to add a main method to an implicit class, either with or without arguments: `main`, `maina`, `psvm`, and `psvma`. Using the `psvm` or `main` live templates inside a compact source file will add the new main method, while they will continue to add the classic main method inside a class, as you can see in the preview.\nLive templates for the main method in a compact source file\n\n\n\nLive templates for the main method in a compact source file\n\n\n\nOur new version of `HelloWorld` now looks like this:\nvoid main() {\n   IO.println(\"Hello, World!\");\n}\nCompare this code to the original example. It is much shorter, contains less boilerplate, and is limited to only the things we need: a main method and a call to print a line with the provided “Hello, World!” `String`.\nAs beginners often need to interact with the console, a convenient `readln()` method was also added. This is an overloaded method which can take a `String` argument that is printed to the console before reading the input. Let’s expand our previous example to read a name from the console. To help you use these new convenience methods, IntelliJ IDEA introduces two new live templates: `iop` for `println()` and `ior` for `readln()`.\nExpanding the example to use the convenience method readln()\n\n\n\nNote that these changes to the language are also taken into account when creating new projects. When you create a new Java project, set Build system to IntelliJ, and select Add sample code, a compact source file with a `void main()` method will be added. \nCreating a new project with the IntelliJ build system\n\n\n\nPrototyping and teaching\nWhile extremely useful for students and teachers, this feature does not just benefit beginners. It also allows experienced developers to quickly try out ideas or create a prototype. \nWhen you create a new Java project with Maven or Gradle as the selected build system, the generated source code will include a regular class, but with `IO.println()` instead of `System.out.println()`. If you are using Maven or Gradle, you’re likely working on something bigger, with actual classes instead of compact source files. Another reason to use classes is that a compact source file needs to be in the default package, and frameworks generally don’t support this. \nCreating a new project with Maven\n\n\n\nTo quickly create a prototype, you can create a Java compact file from the `src/main/java` directory in the Project tool window. IntelliJ IDEA will provide a default name for the file, so your thought process is not disrupted when you want to quickly try something out.\nCreating a Java compact file\n\n\n\nWhen prototyping, learning, or teaching, you can gradually expand your code to include features you might need when writing code that is part of a larger project, or when introducing new concepts to your students. You can convert an implicit class to a regular class using the Convert an implicitly declared class of a compact source file into a regular class quick-fix.\nConverting an implicitly declared class of a compact source file into a regular class\n\n\n\nShould you prefer to use an implicit class at any point, the reverse is also possible. Similarly, there are quick-fixes to convert `IO.println()` to `System.out.println()`, and vice versa. These are probably not things you would do as part of your daily work. But you might use features like this for coding challenges, like Advent of Code, or other fun side projects.\nThe new `void main()` method does not need `String[] args`. However, should you decide to use the `args` in your code, IntelliJ IDEA will help you by adding them to the method, as you can see below. If you like this kind of completion, please let us know in the comments what you are currently missing. \nCompletion to add `args` to the main method\n\n\n\nWith this feature, we finally have a separation in Java between prototypes and other small projects, and enterprise applications. IntelliJ IDEA supports both small and large applications. \nWe have already covered this feature in a previous Java 24 and IntelliJ IDEA post, when it was still in preview. Please have a look at that post to learn about additional support for this feature in IntelliJ IDEA. For a more in-depth explanation of this specific feature, see Mala Gupta’s previous post Java 24: ‘HelloWorld’ and ‘main()’ meet minimalistic. There are examples of practical use cases on when and how to use it to create small programs and prototypes in Java 24: Build Games, Prototypes, Utilities, and More – With Less Boilerplate. Note that (among other things) the following was changed in Java 25: Compact source files were previously called simple source files, and you now need to use the qualified name `IO.println()` or use an import statement.\nModule Import Declarations (JEP 511)\nModule import declarations simplify the importing of frequently used classes (`java.base`) or modular libraries, without having to keep adding individual import statements to keep the compiler happy (even though IntelliJ IDEA can do this for you 😉). This feature makes things easier. You can write code without needing to worry about imports, which is useful when learning or prototyping.\nAlternatively, if you have a class that imports multiple classes from a module, you can replace them with a module import statement. When you perform the Optimize imports action, the individual imports for classes imported by the module will be removed.\nAs your codebase grows, you might prefer to add import statements with specific imports, which you can do using the Replace with single class imports quick-fix.\nOptimizing imports\n\n\n\nIf you would like to remove unused module imports when performing Optimize imports, you can configure this in the settings. Open Settings | Editor | Code Style | Java and go to the Imports tab. Then, select the Delete unused module imports option.\nConfiguring the IDE to delete unused module imports\n\n\n\nTo see which packages are exported by a module, click on the module name in the editor or use the relevant shortcut for Go to Declaration or Usages, as shown here. \nYou might wonder what the difference is between module imports and wildcard imports. Wildcard imports in Java allow you to replace the import for multiple classes from the same package with one line, containing an `*`. Module imports allow you to import classes from different packages. One downside of this is the risk of potential namespace clashes. But don’t worry, IntelliJ IDEA can help you identify and fix these, as described here. \nShould you replace your current import statements with module imports? Probably not. In enterprise code, most developers prefer to have single imports. Note that IntelliJ IDEA allows you to configure the number of imports to add before replacing them with a wildcard. By default, this number is set to five. To change it, open Settings, go to Editor | Code Style | Java, and open the Imports tab. Then, set Class count to use import with ‘*’ to the desired number. Since most coding standards prefer single imports over wildcard imports, we assume the same will be true for module imports. For this reason, we are not planning to have an inspection to automatically replace existing imports with `import module java.base;`. \nHowever, even if you’re not using this feature explicitly, you will use it implicitly when using compact source files (described above). This feature was previously described in Java 24 and IntelliJ IDEA. For more background information, see Module Import Declarations: No More Import Hell by Mala Gupta.\nFlexible Constructor Bodies (JEP 513)\nWith flexible constructor bodies, previously known as “statements before super()”, you are now allowed to write statements in the constructor of a derived class before calling the constructor of the super class. This is useful if you want to validate or compute data in your constructor before passing it to `super()`, or when a superclass calls a method from its constructor that you want to override in the subclass and access a field from the subclass inside this method. \nPreviously, the call to `super()` had to be the first call in the constructor. IntelliJ IDEA would give you a warning if you tried to add statements before `super()`.\nWarning about a statement before `super()`\n\n\n\nA workaround for this restriction is to call static methods inline, as arguments passed to `super()`. While this is still possible, you now have the flexibility to call these methods before calling `super()` with the results.\nThere are some limitations on which types of statements you can execute before the call to `super()`. The statements cannot access the object under construction, which means you cannot access instance members of a class before the execution of `super()` completes or call methods of the derived class.\nThis new functionality should be used responsibly. Just because you can put arbitrary code before `super()` doesn’t mean you should move every possible validation or I/O operation into constructors. Constructors are best kept lightweight, deterministic, and free of heavy side effects. Expensive operations, retries, or external resource access are better handled in factories, builders, or initialization methods.\nIn short, this feature lets you model object invariants more naturally through inheritance, but it doesn’t change the golden rule – constructors should remain focused and predictable.\nWhile this feature might not be that exciting by itself, it is a necessary step to make value classes and objects (currently in preview), as well as upcoming null-restricted value class types (currently in draft), possible. Both of these features are part of Project Valhalla. We will discuss this topic later in a separate blog post.\nFor a more detailed explanation of this feature and examples of how to use it, have a look at the following video featuring Dr. Venkat Subramaniam:\n\n\n\n\n\n\nThis feature was previously described in Java 24 and IntelliJ IDEA. For additional details and examples, see Mala Gupta’s previous blog post Constructor Makeover in Java 22. Note that this post was written when this feature was still in preview. The only significant change since then is that a constructor body is now allowed to initialize fields in the same class before invoking a constructor. \nScoped Values (JEP 506)\nScoped values are a new model for thread-local variables adapted to virtual threads. They make it possible to share immutable data within a thread and with child threads in a convenient, safe, and scalable way.\nIn some cases, you want to share data between components of your application or between your application and a framework, such as information about a logged-in user and their permissions. While it is possible to use thread-local variables (variables of type `ThreadLocal`), there are several downsides to doing so, which might cause potential issues.\n`ThreadLocal` variables are mutable, which makes it hard to keep track of their current value and to reason about the code. The value of a `ThreadLocal` variable is retained for the lifetime of a thread, unless explicitly removed by calling the `remove()` method. Developers may forget to do so, which means data might be stored in memory longer than needed, leading to potential performance problems, as well as security issues because data might be visible to unrelated code running on the same thread. `ThreadLocal` variables can be inherited by a child thread, but each child thread will need to create a copy of the variable, which can add to the memory footprint.\nVirtual threads, added in Java 21, allow us to create many more threads than platform threads. If they each retain a copy of a thread-local variable, this will impact the memory usage. On the other hand, virtual threads may not live as long as platform threads, which minimizes the potential for memory leaks. \nTo use a `ScopedValue`, you need to first declare it. It makes sense to declare it as final. Next, you need to bind the `ScopedValue` to some data and pass a `Runnable` or `ScopedValue.CallableOp`, which may be realized as a lambda. This is done in the `ScopedValue.where()` method. The operation – and any code called from it – will be able to get the `ScopedValue`, but once it is done running, this data will be cleaned up. Scoped values have a clearly defined scope, which makes the code easier to reason about. If you try to use a `ScopedValue` that is not bound, a `NoSuchElementException` is thrown, as you can see in the following example.\nUsing `ScopedValue`\n\n\n\nWhile you cannot set a `ScopedValue`, you can rebind it. In the example below, the variable is bound to the value `24` inside the main method. The `update()` method is called from here, where the value is bound to `25` (24 + 1). When printed, it will print the current value, `25`.\npublic class RebindExample {\n   ScopedValue<Integer> JAVA_VERSION = ScopedValue.newInstance();\n   void main() {\n       ScopedValue.where(JAVA_VERSION, 24).run(this::update);\n   }\n\n   private void update() {\n       ScopedValue.where(JAVA_VERSION, JAVA_VERSION.get() + 1).run(() -> {\n           IO.println(\"Hello, Java \" + JAVA_VERSION.get()); // prints 25\n       });\n   }\n}\nScoped values are even more useful with structured concurrency, currently in its fifth preview.\nStructured concurrency will make it possible for data to be automatically inherited by any threads that a thread forks. The child threads’ scope will be contained in the parent thread’s scope. With scoped values, it is no longer necessary to make copies of the data, meaning they scale very well with many (virtual) threads. This topic deserves its own blog post, where we can dive deeper into new use cases, migration paths, and performance comparisons between different approaches. \nAs we have seen, scoped values solve several problems associated with `ThreadLocal`.They reduce memory overhead, improve predictability, and make reasoning about concurrent code much easier. Does this mean you should immediately rewrite all your code to use `ScopedValue`? Not necessarily. Frameworks like Spring and others still rely heavily on `ThreadLocal`, and migrating all existing components to Java 25 isn’t something that will happen overnight. Also, the intention behind scoped values was never to deprecate or replace `ThreadLocal` outright, but to offer a cleaner, safer alternative. However, you might consider using scoped values for new code or modules, especially where you are already facing typical `ThreadLocal` issues: leaks, context propagation, and cleanup.\nPerformance and profiler improvements\nLanguage features are just half of the story. Java 25 also brings significant runtime improvements. Let’s take a brief look at the changes:\nAhead-of-Time Method Profiling (JEP 515) speeds up warm-up by using method execution profile data from a prior run. The JVM can use that data immediately at startup so that hot methods are already known, reducing the delay before reaching peak performance. \nJFR Cooperative Sampling (JEP 518) and JFR Method Timing & Tracing (JEP 520) improve observability: Cooperative sampling lets threads report profiling data at safe points to reduce overhead and increase accuracy, and method timing and tracing give more precise, detailed call durations and call stack information. \nCompact Object Headers (JEP 519) shrink the object header on 64-bit JVMs from its larger experimental form to a compact 64-bit layout. This reduces memory overhead (especially with many small objects) and improves garbage collection (GC) and cache behavior. \nGenerational Shenandoah (JEP 521) adds generational GC support to the Shenandoah garbage collector so that young-generation objects can be collected more efficiently, reducing pause times and improving throughput for workloads with many short-lived objects.\nMoving from Java 21 to Java 25\nIf you are upgrading to Java 25 from Java 21, here is an overview of some of the stable features you might not be familiar with yet.\nStream Gatherers (JEP 485)\nStream Gatherers were added in Java 24. They improve the Stream API, added in Java 8. Stream gatherers allow you to add your own custom intermediate operations to a stream.\nFor an explanation of this feature and how you can use it, watch the following livestream with José Paumard:\n\n\n\n\n\n\nIf you’d like more background information on this feature, you might be interested in the following video we created when this feature was still in preview:\n\n\n\n\n\n\nFinally, we highly recommend this video from JavaOne by Viktor Klang, the creator of the feature:\n\n\n\n\n\n\nMarkdown Documentation Comments (JEP 467)\nMarkdown documentation comments were added in Java 23. As the name suggests, it is now possible to use Markdown in your JavaDoc. Back when Java was first created, HTML seemed like a logical choice for JavaDoc, but these days you might prefer Markdown. \nIntelliJ IDEA supports the adoption of this feature by offering a quick-fix to convert JavaDoc to Markdown. If you have JavaDoc that you would like to convert, press Alt+Enter when the cursor is on your JavaDoc and select the Convert to Markdown documentation comment option.\nConverting a documentation comment to Markdown\n\n\n\nDoes this mean you should convert your existing JavaDoc to Markdown? Not necessarily. You might just consider writing your documentation in Markdown from now on. However, should you want to convert it, IntelliJ IDEA can help you.\nFor more information on this feature, have a look at Markdown in Java Docs? Shut Up and Take My Comments! by Mala Gupta.\nIf you’re interested in more background on this feature, check out the video that was created when it was still in preview:\n\n\n\n\n\n\nUnnamed Variables & Patterns (JEP 456)\nUnnamed variables and patterns make it possible to use unnamed variables and unnamed patterns when variable declarations or nested patterns are required but the actual variables or patterns are not used. Denoting unnamed variables and patterns with an `_` clearly conveys that they are not used elsewhere in the code. IntelliJ IDEA will detect when an unused local variable could be replaced with an underscore `_` and offer a quick-fix to do so. \nRenaming a variable to ‘_’\n\n\n\nFor more details on this feature, see Drop the Baggage: Use ‘_’ for Unnamed Local Variables and Patterns in Java 22 by Mala Gupta.\nVirtual Threads (JEP 444) and Synchronize Virtual Threads without Pinning (JEP 491)\nAdded in Java 21, virtual threads are lightweight threads. Unlike platform threads, which are limited by the number of cores in your machine, you can create a potentially unlimited number of virtual threads. Virtual threads improve the scalability of your applications. They do need platform threads to perform their work, but can release them when they are waiting for blocking code. Tooling like jcmd and IntelliJ IDEA can collect thread dumps with virtual threads included.\nSynchronizing virtual threads without pinning (added in Java 24) improves the scalability of Java code that uses `synchronized` code. Virtual threads that block in `synchronized` blocks now release their underlying platform threads so they can be used by other virtual threads. This last improvement comes for free when you upgrade from Java 21 to Java 24 or higher. To see this in action, watch the demo we did in the What’s New in IntelliJ IDEA 2025.2 livestream.\n\n\n\n\n\n\nRuntime and security improvements\nJava 24 introduced some changes related to post-quantum cryptography readiness. The Java platform is preparing for the future of secure computing: \nQuantum-Resistant Module-Lattice-Based Key Encapsulation Mechanism (JEP 496) and Quantum-Resistant Module-Lattice-Based Digital Signature Algorithm (JEP 497), introduced in Java 24, are NIST-standardized post-quantum algorithms (lattice-based) aimed at replacing or augmenting classic public-key operations like RSA and ECDSA. Java also receives a performance boost. Garbage collection, memory footprint, and startup times all see measurable improvements:\nRegion Pinning for G1 (JEP 423) allows the G1 garbage collector to continue collecting parts of the heap even when some regions are in JNI critical sections. Instead of stalling GC during such critical regions, only “pinned” regions are excluded, reducing latency in mixed JNI/native workloads. \nThe Foreign Function & Memory API (JEP 454), added in Java 22, offers better performance and safety over the old JNI for foreign memory and calling native code. Bulk operations are more efficient, with less overhead in cross-boundary calls. \nZGC: Generational Mode by Default (JEP 474). The Z Garbage Collector, which is typically low-pause, uses generational mode by default starting with Java 23. Separation between young and old objects improves GC efficiency for applications that create many short-lived objects.\nAdditionally, there are further enhancements to core libraries, previews, and performance ergonomics – for example, improvements to default GC settings, memory management, etc. \nUpgrading from Java 21 to 25\nYou can find a video series that covers the Road to Java 25 on the official Java YouTube channel. We recommend watching How to Upgrade to Java 25 by Nikolai Parlog. The Oracle DevRel team also has a Java 25 livestream on September 16, 2025.\nConclusion\nAs you have seen, several additions to the language make Java easier to use, both for students and teachers, as well as experienced programmers. In fact, these features completely change the experience of using Java, by no longer requiring boilerplate code like the `public static void main(String[] args)` method, allowing statements before `super()`, offering the possibility to add custom intermediary operations in streams using gatherers, allowing underscores as variable names for unused variables, and and providing scoped values as a convenient, safe, and scalable alternative to `ThreadLocal`. With all of these changes, Java is moving forward fast. IntelliJ IDEA aims to move just as quickly by supporting these new features with relevant inspections and quick-fixes, as well as new live templates, and integrating them into existing features like the debugger. Other than improvements in the language, there are also runtime improvements that you get for free when upgrading your JDK.\nWe think Java 25 is the best Java release (so far!) and we recommend you switch to it as soon as you can. Even if you’re not using the Java language features, you will still benefit from using the new JDK. Java 25 offers a new baseline for the language, and the runtime is the fastest it has ever been.\nIf you are on Java 21, we have provided an overview of what you might have missed in terms of language features. And if you’re on an even older version of Java, now would be the time to start the process to upgrade, not just because of the benefits to you but also because the ecosystem is moving forward. Java 17 is the current baseline for Spring and Spring Boot as of Spring 6 or Spring Boot 3. The upcoming Maven 4 will require JDK 17 to run. But don’t worry, you can still compile projects with older Java versions! The upcoming JUnit 6 is also targeting JDK 17. If you are still on Java 8 (or older), now is the time to start upgrading!\nIntelliJ IDEA will continue to support the latest Java features with Java 26. If you would like to try them out, you can download the EA versions from inside IntelliJ IDEA as soon as they become available. And, as always, please let us know if you have any feedback.",
        "dc:creator": "Marit van Dijk",
        "content": "The Java release cadence means we get a new Java version every six months. Java 25 was released on September 16, 2025. At JetBrains, we are committed to supporting new technologies in IntelliJ IDEA and adding useful enhancements for both stable and preview features. In this blog post, we will give you an overview of [&#8230;]",
        "contentSnippet": "The Java release cadence means we get a new Java version every six months. Java 25 was released on September 16, 2025. At JetBrains, we are committed to supporting new technologies in IntelliJ IDEA and adding useful enhancements for both stable and preview features. In this blog post, we will give you an overview of […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=604053",
        "categories": [
          "java",
          "news",
          "tutorials",
          "update",
          "intellij-idea",
          "java-25-2",
          "java-release",
          "java-support",
          "jdk-25",
          "release"
        ],
        "isoDate": "2025-09-16T11:15:34.000Z"
      },
      {
        "creator": "Alexander Karaev",
        "title": "Introducing the Constexpr Debugger",
        "link": "https://blog.jetbrains.com/clion/2025/09/introducing-constexpr-debugger/",
        "pubDate": "Mon, 15 Sep 2025 07:33:06 +0000",
        "content:encodedSnippet": "“Not a constant expression.” You’ve seen the diagnostics and the note trail, but never the actual state. Until now.\nModern C++ pushes more logic into constexpr/consteval: parsers, tables, DSLs, hashing – real code with real branches. When code fails at compile time, you can either try to guess the reason from the compiler’s notes or de‑constexpr it and hope the runtime reproduction matches what the compiler actually did.\nThe new Constexpr Debugger available in the first CLion 2025.3 EAP build allows you to stay in the compiler’s world and see what really happens – by stepping through evaluation, inspecting values, and confirming which if constexpr branch fired. Using it helps you understand exactly what the compiler is doing and fix issues faster.\n\n\n\n\nWith reflection coming in C++26 (P2996R13), compile‑time code will increase even more. Although none of the compilers support reflection yet, the Constexpr Debugger in CLion provides a foundation that will allow for debugging this metacode in the future.\nDOWNLOAD CLION 2025.3 EAP\nFeatures\nHere is what you currently can do with the Constexpr Debugger:\nStart step-by-step debugging from the gutter by clicking the Debug button next to static_assert(...) or a constexpr declarator to check how it was evaluated or why it failed.\nUse the same actions as in the regular debugger: Step Into, Step Over, Step Out, and Restart. Additionally, you can use Step Backward, the compile-time reverse stepping feature.\nSee what the compiler sees: the call stack, locals, last returns, and template arguments of the current instantiation. \nHover over a variable to see its values, use Evaluate Expression, or navigate to the source code from the call stack.\nInspect the entire context when constant evaluation fails to determine when and why it occurred.\nHow to use the Constexpr Debugger\nBasic case\nTo provide you with an overview of the basic actions that you can perform when debugging constexpr, we’ll use this compile-time Fibonacci cache implementation:\n#include <array>\n\ntemplate<std::size_t N>\nstruct FibCache {\n    std::array<int, N + 1> memo{};\n\n    constexpr FibCache() {\n        memo[0] = 0; memo[1] = 1;\n        for (std::size_t i = 2; i <= N; ++i)\n            memo[i] = memo[i - 1] + memo[i - 2];\n    }\n\n    constexpr int operator()(int n) const { return memo[n]; }\n};\n\nconstexpr int get_fibonacci(int n) {\n    FibCache<8> cache;\n    auto result = cache(n);\n    return result;\n}\n\nconstexpr int k = get_fibonacci(6);          // gutter: step through operator()\nstatic_assert(get_fibonacci(6) == 8, \"ok\");  // gutter available here too\nThe following are some basic operations you can perform when debugging:\nFind the green Debug icon next to the constexpr declarator or static_assert (either will do) and click it to run a Constexpr Debugger session.\n\n\n\n\n\nUse the regular debugger actions, or try Step Backward to time‑travel one step back in your compile‑time evaluation.\n\n\n\n                                                \n                        \n\n\n\nInspect the state:\n\nWatch how the this->memo array fills during construction by hovering over it in the editor (see the screenshot below).\nNavigate to the Variables pane to see this, locals (like i), and recent returns.\nHover over any variable to see its value.\nNavigate to the Call Stack to see frames mapped to source.\n\n\n\n\n\nCheck the result in the Variables pane after the constructor has precomputed all the Fibonacci numbers:\n\n\n\n\nEdge case: non-constexpr call prevents evaluation\nConsider the case when we have a function (fail) that is not constexpr – it’s deliberately called to indicate invalid input. This means that the original expression (parse_int(“hello”)) cannot be evaluated at compile time.\n#include <string_view>\n\nvoid fail(); // note: non-constexpr\n\nconsteval int parse_digit(char c) {\n    if (c < '0' || c > '9') {\n        fail();\n    }\n\n    return c - '0';\n}\n\nconsteval int parse_int(std::string_view s) {\n    int result = 0;\n    for (std::size_t i = 0; i < s.size(); i++) {\n        result = result * 10 + parse_digit(s[i]);\n    }\n\n    return result;\n}\n\nconstexpr auto digit = parse_int(\"12345\");\nconstexpr auto bad_digit = parse_int(\"hello\"); // start from the gutter\nStepping here lets you see c == 'x', the taken branch, the value of argument c, and the exact point at which the evaluation fails:\n\n                        \n\n\nCurrent limitations\nBreakpoints and Run to Cursor / Force Run to Cursor are not supported in constexpr evaluation.\nC++20 modules aren’t yet supported: constexpr debugging does not navigate to entities located in imported modules.\nStepping may not work properly with some language constructs or compound statements.\nSome constructs aren’t yet supported by our constexpr evaluator. We track these unsupported cases in YouTrack.\nWe don’t have a definite timeline for when these missing bits of support might be added, but we’re working on them, so stay tuned!\nShare your feedback\nYour feedback is essential for improving this feature and making it more robust. We encourage you to try the Constexpr Debugger and share your thoughts and suggestions by submitting a ticket to our issue tracker or commenting below.\nDOWNLOAD CLION 2025.3 EAP",
        "dc:creator": "Alexander Karaev",
        "content": "“Not a constant expression.” You’ve seen the diagnostics and the note trail, but never the actual state. Until now. Modern C++ pushes more logic into constexpr/consteval: parsers, tables, DSLs, hashing – real code with real branches. When code fails at compile time, you can either try to guess the reason from the compiler’s notes or [&#8230;]",
        "contentSnippet": "“Not a constant expression.” You’ve seen the diagnostics and the note trail, but never the actual state. Until now. Modern C++ pushes more logic into constexpr/consteval: parsers, tables, DSLs, hashing – real code with real branches. When code fails at compile time, you can either try to guess the reason from the compiler’s notes or […]",
        "guid": "https://blog.jetbrains.com/?post_type=clion&p=597658",
        "categories": [
          "eap",
          "news",
          "compiler",
          "constexpr",
          "debugger"
        ],
        "isoDate": "2025-09-15T07:33:06.000Z"
      },
      {
        "creator": "Anna Ruban",
        "title": "GameDev Day 2025 Is Back in October!",
        "link": "https://blog.jetbrains.com/dotnet/2025/09/15/gamedev-day-2025-is-back-in-october/",
        "pubDate": "Sun, 14 Sep 2025 23:00:00 +0000",
        "content:encodedSnippet": "Game development is more than just code – it’s about creativity, storytelling, and community. That’s why we’re bringing back JetBrains GameDev Day on October 21, 2025, to celebrate all aspects of game creation with developers worldwide.\nRegister Now\n                                                    \nThis free, one-day online event is shaped entirely by the community. Think of it as a developer’s cheat code: one full day packed with sessions covering the tools and workflows that power modern game development.\nOur speakers are professionals who are passionate about their craft, and they’ll share insights that you can immediately put into practice – from improving developer workflows to designing for inclusivity, from building scalable systems to rethinking game architecture.\n\n\n\n\nAgenda highlights\nHere’s just a preview of what you can expect:\nBeyond OOP: A Journey From Cache Misses to MASS Hits – Konrad Słoń, Senior Gameplay Programmer at Fool’s Theory\nBuilding a Cross-Platform In-Game Store With Godot – Johannes Ebner, Gaming Solution Architect at Structed.me\nIntroduction to Netcode for Entities – Johnny Thompson, Developer and Content Creator at Turbo Makes Games \nMobile Accessibility: Building Accessible Mobile Games – Gian Wild, CEO at AccessibilityOz\nOptimizing for the Web: Lessons From Browser-Based Games – Dom Harris, Web Games Advocate at CrazyGames\n…and many more talks from leading voices in the industry.\nWhat’s new this year: local watch parties\nThis year, we’re also launching local watch parties. These meetups let you co-watch the stream with fellow developers in your city, creating opportunities to connect face-to-face while being part of a global event.\nHow to join\nThe event will be streamed live on YouTube, and all sessions will be available on demand afterward, so you won’t miss a thing. Whether you attend just a few talks or the entire event, you’ll come away with new tools, insights, and inspiration.\nSave your spot today and be part of the global gamedev community: \nJoin Us\n                                                    \nDon’t miss your chance to join thousands of game developers on October 21, 2025. The game is about to begin!\nThis event is supported by DevGAMM and WN Events.\n\n\nDevGAMM is an international gamedev conference with the mission to bring people together over the love of games. Born in Ukraine in 2008, it has become one of the fastest-growing professional gaming communities in the region.\nLearn more about Madeira Games Summit (November 3–4) and DevGAMM Lisbon (November 6–7).\n\n\nEvery year, WN Events hosts dozens of events, including conferences, mixers, and CEO summits. Participants discuss business and educational topics, including game publishing, talent management, game design, programming, artificial intelligence, Web3, and more.ㅤ\nLearn more about WN C-Level Summit Dubai’25 (December 11) and WN Conference Abu Dhabi’26 (February 2026).",
        "dc:creator": "Anna Ruban",
        "content": "Game development is more than just code – it’s about creativity, storytelling, and community. That’s why we’re bringing back JetBrains GameDev Day on October 21, 2025, to celebrate all aspects of game creation with developers worldwide. This free, one-day online event is shaped entirely by the community. Think of it as a developer’s cheat code: [&#8230;]",
        "contentSnippet": "Game development is more than just code – it’s about creativity, storytelling, and community. That’s why we’re bringing back JetBrains GameDev Day on October 21, 2025, to celebrate all aspects of game creation with developers worldwide. This free, one-day online event is shaped entirely by the community. Think of it as a developer’s cheat code: […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=598577",
        "categories": [
          "net-tools",
          "events",
          "rider",
          "teamcity-2",
          "conference",
          "gamedev",
          "gamedev-day",
          "teamcity",
          "webinat"
        ],
        "isoDate": "2025-09-14T23:00:00.000Z"
      },
      {
        "creator": "Ksenia Shneyveys",
        "title": "Your Voice Belongs Here: Creating Compelling KotlinConf Proposals [Livestream]",
        "link": "https://blog.jetbrains.com/kotlin/2025/09/creating-kotlinconf-proposals/",
        "pubDate": "Fri, 12 Sep 2025 16:57:17 +0000",
        "content:encodedSnippet": "Have you given a talk before – maybe at a meetup, online event, or a smaller conference – and wondered if you’re ready for a bigger stage like KotlinConf?\nThis supportive and practical webinar is designed for people from underrepresented groups in tech who already have some speaking experience and are ready to level up. If you’re passionate about Kotlin and want to share your story, knowledge, or unique perspective with the wider community – this is for you.\nHosted by Pamela Hill and Cheuk Ting Ho, two seasoned CFP writers, experienced speakers, and friendly faces from multiple program committees (including KotlinConf!), this session will cover:\nWhat makes a CFP stand out\nHow to shape your Kotlin journey into a strong proposal\nWhat reviewers are really looking for\nJoin us on October 14\n         \nThis isn’t just a tutorial – it’s a space to connect, gain confidence, and have a little fun while preparing to share your voice with the Kotlin world.\nLet’s get your KotlinConf talk ready – because your voice belongs here.\nPamela Hill\nPamela is a Developer Advocate for Kotlin Multiplatform at JetBrains and has more than 20 years of experience writing desktop, web, and mobile apps.\n@pamelaahill\nCheuk Ting Ho\nAfter her career as a Data Scientist and Developer Advocate, Cheuk dedicated her work to the open-source community. Currently, she is working as a developer advocate for JetBrains. She co-founded Humble Data, a beginner Python workshop that takes place around the world. She has served the EuroPython Society board for two years and is now a fellow and director of the Python Software Foundation.\ncheuk.dev",
        "dc:creator": "Ksenia Shneyveys",
        "content": "Have you given a talk before – maybe at a meetup, online event, or a smaller conference – and wondered if you&#8217;re ready for a bigger stage like KotlinConf? This supportive and practical webinar is designed for people from underrepresented groups in tech who already have some speaking experience and are ready to level up. [&#8230;]",
        "contentSnippet": "Have you given a talk before – maybe at a meetup, online event, or a smaller conference – and wondered if you’re ready for a bigger stage like KotlinConf? This supportive and practical webinar is designed for people from underrepresented groups in tech who already have some speaking experience and are ready to level up. […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=599668",
        "categories": [
          "news",
          "kotlinconf"
        ],
        "isoDate": "2025-09-12T16:57:17.000Z"
      },
      {
        "creator": "Dmitrii Korovin",
        "title": "Achieve Effortless GitHub Releases With a New Plugin for TeamCity",
        "link": "https://blog.jetbrains.com/teamcity/2025/09/teamcity-github-releases-plugin/",
        "pubDate": "Fri, 12 Sep 2025 10:55:32 +0000",
        "content:encodedSnippet": "GitHub releases are fantastic for distributing your open-source projects, as they let you turn any code revision into ready-to-go assets with a detailed version history. What makes them particularly popular, though, is that they give users a proper Download button (because not everyone dreams of compiling source code).\nIn TeamCity, the traditional approach for publishing GitHub releases is to run custom scripts via the Command Line build step. While certainly viable, this approach comes with a catch: You need to write and maintain that script and handle authentication on your own. Even more frustrating, TeamCity already has a perfectly good authentication token tucked away in your VCS root – an authentication token that you cannot directly reuse.\nThe new GitHub Releases Support plugin aims to eliminate this inconvenience once and for all. No more guesswork, no more custom scripting. With just a few clicks, you can publish your builds as GitHub releases and focus on shipping features instead of wrangling scripts.\nInstall\nThis is an unbundled plugin, which means you’ll need to download it from our Marketplace and install it on your server. To do this, click the Get button in the top right corner of the plugin page, or go directly to the Admin | Plugins page of your TeamCity server and click Browse plugins repository.\nSee also: Installing Additional Plugins\nConfigure\nOnce the plugin is installed, you can add the GitHub Release step to build configurations as you would any other build step.\n\n\n\n\nHere’s a quick overview of the key settings:\n\n\n\n\n\nRelease Repository – The GitHub repository where your release will be published. TeamCity automatically lists repositories based on the VCS roots attached to the parent build configuration.\nRelease Tag – The unique tag to label your new release. Use a parameter reference (%teamcity_parameter_name%) to fetch this value from a TeamCity parameter. You can provide this value before the build starts (via the Run Custom Build dialog) or calculate it during a build.\nRelease Title and Release Notes –  Additional details that are optional, but highly recommended. Your users will appreciate a concise description and some context. You can import the content for these fields from TeamCity parameters and let GitHub append its own auto-generated notes to your custom ones.\nAsset Paths – Files you want to publish as release assets. If you’ve run the build before, you can simply browse and select files using the folder browser instead of typing paths manually.\nRelease Options – A field where you can mark the release as a draft or pre-release, or flag it as the latest release.\n\n\n\n\nThe plugin supports multiple authentication methods, seen in the Commit Status Publisher or similar TeamCity build features.\n\n\n\n\n\nUse VCS root credentials — Reuse the same authentication method your VCS root already uses.\nAccess Token — Provide a personal GitHub access token, issued on your GitHub profile settings page.\nGitHub App access token — Use an existing GitHub App token, or create a new one, directly from TeamCity. See this documentation article for more information.\nKotlin DSL\nFor those who enjoy configuration as code, here’s how the step settings look in the Kotlin DSL:\ngitHubRelease {\n    name = \"Publish release\"\n    targetVcsRootId = \"${myVcsRoot.id}\"\n    githubUrl = \"https://api.github.com\"\n    tagName = \"v%release.version.number%\" // Supports parameter references\n    releaseName = \"Release %release.version.number%\" // Optional, uses 'tagName' if omitted\n    releaseNotes = \"\"\"\n            ## Changelog:\n            %release.changelist%\n        \"\"\".trimIndent()\n\n    // Optional, specified files will be uploaded as release assets.\n    // Paths are relative to the checkout directory, files should be present when this step runs\n    assetPaths=\"\"\"\n            library/build/libs/library-1.0-SNAPSHOT.jar\n            app/build/libs/app-1.0-SNAPSHOT.jar\n        \"\"\".trimIndent()\n\n    latest = true // Optional, labels the published release as the latest one\n    authType = vcsRoot()\n}\nRun\nOnce everything is set up, hit that big blue Run button.\nWhen the build finishes, you’ll see a Release Details section on the Build Results page. From there, click the provided link to open your freshly minted GitHub release. (Cue a sigh of relief, and maybe a small celebration.)\n\n\n\n\nYour Feedback Matters!\nThe GitHub Releases Support plugin may not come bundled in TeamCity, but we hope you find it as handy as many of the bundled ones.\nHave any ideas or requests? Would you like to give our developers a virtual high-five? Drop by JetBrains Marketplace to leave a review, or get in touch through our regular feedback channels. We listen closely to user requests and always value your feedback.",
        "dc:creator": "Dmitrii Korovin",
        "content": "GitHub releases are fantastic for distributing your open-source projects, as they let you turn any code revision into ready-to-go assets with a detailed version history. What makes them particularly popular, though, is that they give users a proper Download button (because not everyone dreams of compiling source code). In TeamCity, the traditional approach for publishing [&#8230;]",
        "contentSnippet": "GitHub releases are fantastic for distributing your open-source projects, as they let you turn any code revision into ready-to-go assets with a detailed version history. What makes them particularly popular, though, is that they give users a proper Download button (because not everyone dreams of compiling source code). In TeamCity, the traditional approach for publishing […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=597563",
        "categories": [
          "news",
          "plugin-development"
        ],
        "isoDate": "2025-09-12T10:55:32.000Z"
      },
      {
        "creator": "Margarita Shadrina",
        "title": "JetBrains at the ICPC World Finals 2025 Baku",
        "link": "https://blog.jetbrains.com/blog/2025/09/11/jetbrains-at-the-icpc-world-finals-2025-baku/",
        "pubDate": "Thu, 11 Sep 2025 14:22:17 +0000",
        "content:encodedSnippet": "The ICPC World Finals 2025 in Baku was an unforgettable event, and we were honored to be part of it once again. It’s always a joy to see the brightest students from across the globe. The Finals reminds us why supporting the ICPC is such a vital mission – it’s about community, talent, and the future of technology.\n\n\n\n\nThis year, the Finals brought together the brightest students and ICPC teams from around the world, and we were glad to see that participants from the JetBrains-supported program at Neapolis University Pafos (NUP) also qualified to compete among the best. Their team, Sigma++, proudly represented their university in Baku and was awarded an Honors distinction at the World Finals.\nIn his welcome speech, Andrey Ivanov, Senior VP of People, Research, and Investments at JetBrains, highlighted what makes the ICPC so special for us:\n\n“What I enjoy most about the ICPC and all its events is the feeling of a growing family and community. Every year we meet wonderful people – last year in Astana, this year here in Baku – and I know our paths will cross again and again.”\n\nHe also expressed gratitude to everyone who made the event possible:\n\n“I want to thank all the organizers for making this event possible. The spirit of the ICPC is alive thanks to your efforts, and it’s a real joy to see such an incredible setting for the Finals here in Baku.”\n\n\n\n\n\n\n\nHis words reflected our long-standing commitment to the ICPC and the values we share with its community.\n\n\n\n\nHighlights from JetBrains at the Finals\nThe booth and chillzone areas\nThroughout the Finals week, we met with participants in two locations. At our booth, they enjoyed tackling the Kotlin Challenge, tested their predictions for the Finals outcomes, sent postcards to family and friends, and posed with Kodee. We also talked about JetBrains tools, including our new AI agent Junie, which we presented for the first time to such a large global ICPC audience.\nIn the bustling JetBrains chillzone area, participants tried the new Nav&Code Challenge (where one teammate sees the screen and the other types), snapped instant team photos, and took part in a fun quiz about JetBrains and the ICPC. They also tested their skills in our super-fun Junie challenge, where teams prompted Junie to build an app from a mockup, with twist cards adding surprises. \nThis setup worked especially well because, for the first time in years, all participants were staying in the same hotel – a unique opportunity that made it possible to create a shared space with our photo wall and activities. Right after the quiz and the Junie challenge, a participant came up to us and said:\n\n“I just wanted to thank you for being here. It’s JetBrains that creates this amazing atmosphere.”\n\n\n\n\n\n\n\n\n\n\n\n\nBoth locations became lively hubs where contestants, coaches, and volunteers connected and shared their excitement for the competition. Another familiar detail was JetBrains notebooks on every team’s desk, a tradition we’ve maintained for years at both the ICPC Finals and regional contests. These special notebooks help participants structure their thoughts on paper during the contest – much like our tools support them in writing great code.\nJetBrains Tech Trek and Kotlin Heroes\nThe highlight of our presence at the Finals was the JetBrains Tech Trek. JetBrains Developer Advocate Sebastian Aigner opened the session by introducing Junie, our smart coding agent. He then talked about JetBrains IDEs that help in competitions and real-world development, providing students and teachers with access to modern development tools and AI in classrooms worldwide. Sebastian also explored how Kotlin – one of the official ICPC languages – is used in education and industry, and can now help with building modern AI libraries using koog.ai, a new Kotlin framework for building AI agents.\nThis seamlessly led into the live stage contest, where two of the world’s top competitive programmers, Andrew ‘ecnerwala’ He and David ‘SecondThread’ Harmeyer, went head to head in a live coding race on stage. They were solving problems from the Kotlin Heroes: Episode 13 practice round, now open to all. The main contest will take place on September 12, which means you still have time to register and compete for a chance to win a T-shirt.\n\n\n\n\n\n\nLooking ahead\nIn addition to demonstrating the power of algorithms and teamwork, the Finals in Baku reinforced the sense of community that connects ICPC participants worldwide. We were inspired to see students work hard, collaborate, discover solutions under time pressure, and just have fun together.\nWe were especially proud to see the majority of participants who had joined our Pafos Programming Camp 2025 in August. Eight of the teams made it into the top 50 worldwide:\nUniversity of Novi Sad – 11th place, bronze medal 🥉\nKarlsruhe Institute of Technology – 13th place (Highest Honors)\nUniversity of Maryland – 14th place (Highest Honors), with 7 out of 9 elegant solutions written in Kotlin\nHasso Plattner Institute – 29th place (High Honors)\nUniversità di Pisa – 39th place (High Honors)\nDelft University of Technology – 40th place (Honors)\nJagiellonian University in Krakow – 42nd place (Honors)\nUniversity of Wroclaw – 43rd place (Honors)\n\n\n\n\nThe full scoreboard can be found here.\n\n\n\n\n\n\n\n\n\nIt’s fantastic to see how well the teams prepared for the Finals, and we’re glad that Pafos Camp was part of their journey.\nWe congratulate all the medalists and finalists who made it to Baku. To every participant, coach, and organizer – thank you for your energy, passion, and determination!\nHere’s to another year of the ICPC, to many more collaborations, and to the friendships and ideas that will keep growing beyond the Finals. Stay tuned for what’s next – and we’ll see you at future contests, camps, and challenges!",
        "dc:creator": "Margarita Shadrina",
        "content": "The ICPC World Finals 2025 in Baku was an unforgettable event, and we were honored to be part of it once again. It’s always a joy to see the brightest students from across the globe. The Finals reminds us why supporting the ICPC is such a vital mission – it’s about community, talent, and the [&#8230;]",
        "contentSnippet": "The ICPC World Finals 2025 in Baku was an unforgettable event, and we were honored to be part of it once again. It’s always a joy to see the brightest students from across the globe. The Finals reminds us why supporting the ICPC is such a vital mission – it’s about community, talent, and the […]",
        "guid": "https://blog.jetbrains.com/?post_type=blog&p=599290",
        "categories": [
          "competitive-programming",
          "icpc"
        ],
        "isoDate": "2025-09-11T14:22:17.000Z"
      },
      {
        "creator": "Sergei Ugdyzhekov",
        "title": "Testing AI Coding Agents With TeamCity and SWE-bench",
        "link": "https://blog.jetbrains.com/teamcity/2025/09/testing-ai-coding-agents-with-teamcity-and-swe-bench/",
        "pubDate": "Thu, 11 Sep 2025 08:35:30 +0000",
        "content:encodedSnippet": "Introduction\nAI coding agents are no longer research experiments. They are quickly becoming practical tools that can help developers solve real problems. \nBut how do you know whether an agent is good enough for serious use? How do you measure progress when its answers are not always predictable and when there may be various correct solutions to the same task?\nThis is where systematic testing comes in. At JetBrains, we needed a way to test our own coding agent, Junie, on real-world development tasks. To achieve this, we built an evaluation pipeline powered by TeamCity and SWE-bench, a popular benchmark that provides real bugs and fixes from open-source projects.\n\n\n\n\nIn this post, I will walk you through how it works, the challenges we faced, and the solutions we found.\nPrerequisites\nIn our GitHub project, you can find a repository that contains the TeamCity Kotlin DSL and describes every component you need. You can plug it into your own TeamCity and run the full pipeline, just as I’ll demonstrate in this blog post.\n👉 Check out and fork the project 👈\nWhy this matters\nTesting AI coding agents is not like testing ordinary software. With regular programs, you can rely on unit and integration tests. With agents, things are different. Their output can vary from run to run, and there are often multiple valid ways to solve the same problem. This makes traditional testing methods ineffective.\nTo use coding agents effectively, you must answer a few critical questions: Are the results correct? Are they consistent over time? What does each run cost in compute and API usage? \nAt JetBrains, Junie’s team tracks metrics such as solved-task percentage, cost per run, common failure types, and performance across versions. This data provides clear evidence of progress and ensures that development decisions are based on facts rather than impressions.\n💡Read also: How Junie Uses TeamCity to Evaluate Coding Agents\nSWE-bench: Your benchmark toolkit\nBenchmarks give us a consistent way to test agents. SWE-bench is one of the most widely used because it is based on real issues from real projects. For every task, we know:\nThe exact project and commit where the problem appeared.\nThe correct fix.\nTests that prove both the bug and the solution.\nThe evaluation method is straightforward: Provide the agent with the project and task, let it propose a fix, run the tests, and see if they pass. SWE-bench also provides Python tooling to prepare Docker images with the correct dependencies and environments, as well as scripts to evaluate solutions.\nIn our project, we used SWE-bench Lite, a smaller variant of the full benchmark. The pipeline is flexible, so you can adapt it to any benchmark you prefer.\nBuilding stable, reusable pipelines\nOne of the biggest challenges is ensuring that every run happens in a stable, identical environment. Without this, it is impossible to know whether a failure was due to the agent or some minor setup difference.\nWhy stability matters\nTo reproduce each task, we must download the code, install dependencies, and prepare the environment. Any external hiccup, like a slow package server or rate limits on Hugging Face (which hosts the datasets), can cause tasks to fail incorrectly.\nThe Hugging Face bottleneck\nIf every TeamCity agent downloads datasets directly from Hugging Face, the requests quickly hit limits. This results in HTTP 429 errors and failed runs – not because the agent was wrong, but because the dataset could not be retrieved.\nThe solution: Caching with artifacts\nTo fix this, we created a dedicated TeamCity job that downloads the dataset and tooling once, packages them into ZIP archives, and publishes them as artifacts. All other build configurations use these cached artifacts instead of contacting Hugging Face.\nThe dataset download build type uses a Python script to cache the SWE-bench Lite dataset:\n# Download the dataset with caching\ndataset = load_dataset(\n    \"princeton-nlp/SWE-bench_Lite\",\n    cache_dir=cache_dir,\n    split=\"test\"\n)\nSource: scripts/download_dataset.py\nThe build configuration packages the cache as artifacts:\nartifactRules = \"\"\"\n    dataset_cache/** => dataset_cache.zip\n    .venv => venv.zip\n\"\"\".trimIndent()\nSource: SWE_bench_Lite.kt\n\n\n\n\nThe benefits include:\nNo more rate limits.\nFaster builds with less wasted time.\nMore reliable runs.\nConsistent datasets across all tests.\nDocker image caching\nWe extended this same caching approach to Docker images. Each task gets its own image with the project source code, Python version, dependencies, and test environment. These images are cached and reused. When new tasks are added, only their images are rebuilt.\npython {\n    name = \"Build Docker image for $taskId\"\n    command = module {\n        module = \"swebench.harness.prepare_images\"\n        scriptArguments = \"--instance_ids $taskId --tag $instanceImageOrigTag\"\n    }\n}\n\ndockerCommand {\n    name = \"Save Docker Image for $taskId\"\n    commandType = other {\n        subCommand = \"save\"\n        commandArgs = \"-o $taskId.tar $instanceImageOrig\"\n    }\n}\nSource: SWE_Bench_lite_TaskEnv.kt \nThis ensures stability and lowers costs, and it has the added advantage of making results reproducible.\n\n\n\n\nCost-efficient and scalable execution\nThough possible, running hundreds of tasks at once is wasteful. Instead, we built configurations that run smaller subsets: 10 tasks, 30 tasks, or 50 tasks.\n\n\n\n\nThe project creates different-sized task sets for cost-efficient testing:\nval tenTasksSet = mutableListOf<Task>()\nval thirtyTasksSet = mutableListOf<Task>()\nval fiftyTasksSet = mutableListOf<Task>()\n\ntasks.forEachIndexed { index, task ->\n    val taskConfiguration = createTaskForGeminiBuildType(task)\n    if (index % 10 == 0 && tenTasksSet.size < 10) tenTasksSet.add(taskConfiguration)\n    if (index % 7 == 0 && thirtyTasksSet.size < 30) thirtyTasksSet.add(taskConfiguration)\n    if (index % 5 == 0 && fiftyTasksSet.size < 50) fiftyTasksSet.add(taskConfiguration)\n}\n\nbuildType(create_SWE_Bench_Lite_XxTaskSlice(tenTasksSet, agentGemini))\nbuildType(create_SWE_Bench_Lite_XxTaskSlice(thirtyTasksSet, agentGemini))\nbuildType(create_SWE_Bench_Lite_XxTaskSlice(fiftyTasksSet, agentGemini))\nSource: Google_Gemini_CLI_AI_Agent.kt \nThis setup gives us flexibility: Daily runs can use the smaller sets for quick checks, while strong-performing agents can be scaled up to larger runs. If an agent fails early, we can stop immediately and save resources.\nThe 10-task run in particular works like a build verification test. It is fast and inexpensive, yet still provides statistical insight into the agent’s health.\nInfrastructure stability and resource control\nBy caching datasets and Docker images, our pipelines no longer depend on unstable network downloads. Failures now reflect the agent’s quality, not infrastructure problems.\nTeamCity’s resource management features also help us control concurrency. Since providers may limit request rates, we can set a maximum number of parallel agent runs. This prevents overload, avoids provider errors, and keeps the evaluation system available for everyone on the team.\nThis defines a shared resource with a quota of 20 concurrent connections, which limits how many builds can simultaneously access Hugging Face services, preventing rate limit issues:\nsharedResource {\n    id = \"HuggingFaceConnections\"\n    name = \"HuggingFaceConnection\"\n    resourceType = quoted(20)\n}\nSource: settings.kt\nfeatures {\n    sharedResources {\n        readLock(\"HuggingFaceConnection\")\n    }\n}\nSource: SWE_Bench_Lite_TaskEnv.kt\nA summary of the benefits\nWith this setup, we gain:\nEconomy: We can reuse datasets and environments efficiently.\nStability: The setup leads to fewer random failures.\nReproducibility: Runs are carried out in identical environments.\nTrustworthy metrics: Results reflect agent performance rather than noise.\nFlexibility: The Kotlin DSL makes it easy to generate hundreds of configurations.\nVisibility: We gain clear insight into agent quality over time.\nPower: TeamCity proves itself useful beyond CI/CD by serving as a robust testing platform.\nOur pipeline automatically tags runs with visual indicators for quick assessment:\nresolved_instances = data.get('resolved_instances', 0)\nunresolved_instances = data.get('unresolved_instances', 0)\nerror_instances = data.get('error_instances', 0)\n\nif resolved_instances > 0:\n    print(\"##teamcity[addBuildTag '✅ Good solution']\")\nif unresolved_instances > 0:\n    print(\"##teamcity[addBuildTag '❌ Bad solution']\")\nif error_instances > 0 or empty_patch_instances > 0:\n    print(\"##teamcity[addBuildTag '  Error']\")\nSource: scripts/tag_task_execution.py\n\n\n\n\nConclusion\nWe built a reliable and efficient system for testing AI coding agents with TeamCity and SWE-bench Lite. Repeatable, cost-effective, and adaptable, the pipeline provides reliable metrics.\nTeamCity is not just for continuous integration and deployment – it is also an excellent platform for evaluating AI agents.\nYou can find all repositories and resources linked in our project. If you’d like help setting up a similar pipeline for your own agents, just leave a comment below. We’ll be happy to help.",
        "dc:creator": "Sergei Ugdyzhekov",
        "content": "Introduction AI coding agents are no longer research experiments. They are quickly becoming practical tools that can help developers solve real problems.&#160; But how do you know whether an agent is good enough for serious use? How do you measure progress when its answers are not always predictable and when there may be various correct [&#8230;]",
        "contentSnippet": "Introduction AI coding agents are no longer research experiments. They are quickly becoming practical tools that can help developers solve real problems.  But how do you know whether an agent is good enough for serious use? How do you measure progress when its answers are not always predictable and when there may be various correct […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=598547",
        "categories": [
          "ai",
          "ai-agent"
        ],
        "isoDate": "2025-09-11T08:35:30.000Z"
      },
      {
        "creator": "Dmitrii Korovin",
        "title": "TeamCity 2025.07.2 Is Available",
        "link": "https://blog.jetbrains.com/teamcity/2025/09/teamcity-2025-07-2-bug-fix/",
        "pubDate": "Wed, 10 Sep 2025 16:31:23 +0000",
        "content:encodedSnippet": "Today we are releasing our second bug-fix release for the 2025.07 major release —TeamCity On-Premises 2025.07.2. This update ships a considerable number of bug fixes, including the following:\nMultiple issues related to the recently introduced pipelines.\nBuilds that process changes from pull requests run for the default configuration branch.\nHanging builds remain stuck in a build queue, ignoring the timeout settings.\nInability to download a JDBC driver.\nApart from resolving regular bugs, all TeamCity bug-fix updates also include performance and security improvements. For that reason, we recommend that you never ignore bug-fix releases and update your On-Premises servers whenever possible. See TeamCity 2025.07.2 Release Notes for the complete list of resolved issues.\nWhy update?\nStaying up to date with minor releases ensures your TeamCity instance benefits from the following:\nPerformance improvements.\nBetter compatibility with integrations.\nFaster, more stable builds.\nEnhanced security for your workflows.\nCompatibility\nTeamCity 2025.07.2 shares the same data format as all 2025.07.x releases. You can upgrade or downgrade within this series without the need for backup and restoration.\nHow to upgrade\nUse the automatic update feature in your current TeamCity version.\nDownload the latest version directly from the JetBrains website.\nPull the updated TeamCity Docker image.\nNeed help?\nThank you for reporting issues and providing feedback! If you have questions or run into any problems, please let us know via the TeamCity Forum or Issue Tracker.\nHappy building!",
        "dc:creator": "Dmitrii Korovin",
        "content": "Today we are releasing our second bug-fix release for the 2025.07 major release —TeamCity On-Premises 2025.07.2. This update ships a considerable number of bug fixes, including the following: Apart from resolving regular bugs, all TeamCity bug-fix updates also include performance and security improvements. For that reason, we recommend that you never ignore bug-fix releases and [&#8230;]",
        "contentSnippet": "Today we are releasing our second bug-fix release for the 2025.07 major release —TeamCity On-Premises 2025.07.2. This update ships a considerable number of bug fixes, including the following: Apart from resolving regular bugs, all TeamCity bug-fix updates also include performance and security improvements. For that reason, we recommend that you never ignore bug-fix releases and […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=598278",
        "categories": [
          "bug-fix"
        ],
        "isoDate": "2025-09-10T16:31:23.000Z"
      },
      {
        "creator": "Sarah Haggarty",
        "title": "Kotlin 2.2.20 Released",
        "link": "https://blog.jetbrains.com/kotlin/2025/09/kotlin-2-2-20-released/",
        "pubDate": "Wed, 10 Sep 2025 09:54:07 +0000",
        "content:encodedSnippet": "The Kotlin 2.2.20 release is out, delivering important changes for web development. Kotlin/Wasm is now Beta, with improvements to exception handling in JavaScript interop, npm dependency management, built-in browser debugging support, and a new shared source set for js and wasmJs targets. Additionally, here are some main highlights:\nKotlin Multiplatform: Swift export available by default, stable cross-platform compilation for Kotlin libraries, and a new approach for declaring common dependencies.\nLanguage: Improved overload resolution when passing lambdas to overloads with suspend function types.\nKotlin/Native: Support for stack canaries in binaries and smaller binary size for release binaries.\nKotlin/JS: Long values compiled into JavaScript BigInt.\nFor the complete list of changes, see What’s new in Kotlin 2.2.20 or the release notes on GitHub.\nHow to install Kotlin 2.2.20\nThe Kotlin plugin is distributed as a bundled plugin in IntelliJ IDEA and Android Studio.\nTo update to the new Kotlin version, change the Kotlin version to 2.2.20 in your build scripts.\nIf you need the command-line compiler, download it from the GitHub release page.\nIf you run into any problems:\nFind help on Slack (get an invite).\nReport issues to our issue tracker, YouTrack.\n\n\n\n\n\nStay up to date with the latest Kotlin features! Subscribe to receive Kotlin updates by filling out the form at the bottom of this post. ⬇️\nSpecial thanks to our EAP champions 🥇👏\nZac Sweers\nBernd Prünster\nDayan Ruben\nRick Clephas\nSechaba\nAlexander Nozik\nBenoit Lubek\nJake Wharton\nJohannes Svensson\nŁukasz Wasylkowski\nDavid Lopez\nFlorian Schreiber\nJosh Stagg\nMohamed Rejeb\nKacper Wojciechowski\nYinlong xiaobai\nFurther reading\nWhat’s new in Kotlin 2.2.20 documentation\nWhat’s new in Kotlin 2.2.0 documentation\nKotlin EAP Champions",
        "dc:creator": "Sarah Haggarty",
        "content": "The Kotlin 2.2.20 release is out, delivering important changes for web development. Kotlin/Wasm is now Beta, with improvements to exception handling in JavaScript interop, npm dependency management, built-in browser debugging support, and a new shared source set for js and wasmJs targets. Additionally, here are some main highlights: For the complete list of changes, see [&#8230;]",
        "contentSnippet": "The Kotlin 2.2.20 release is out, delivering important changes for web development. Kotlin/Wasm is now Beta, with improvements to exception handling in JavaScript interop, npm dependency management, built-in browser debugging support, and a new shared source set for js and wasmJs targets. Additionally, here are some main highlights: For the complete list of changes, see […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=597542",
        "categories": [
          "releases"
        ],
        "isoDate": "2025-09-10T09:54:07.000Z"
      }
    ]
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Harshada Hole",
        "title": "Democratizing Performance: The Copilot Profiler Agent in Action on Real Code",
        "link": "https://devblogs.microsoft.com/visualstudio/copilot-profiler-agent-visual-studio/",
        "pubDate": "Thu, 11 Sep 2025 16:05:09 +0000",
        "content:encodedSnippet": "Watch behind the scenes of the Profiler Agent\nHead on over to the Copilot Profiler Agent to watch.\n\n\nWe’re excited to announce the Copilot Profiler Agent available in Visual Studio 2026 Insiders, it’s an AI-powered performance assistant built directly into Visual Studio. Forget staring at endless call trees or walls of mysterious numbers that leave you asking, “where do I even start?” The Copilot Profiler Agent changes that.  \nInstead of raw data, you now get an AI partner that not only points out the real bottlenecks but also explains what’s going on, suggests fixes, writes benchmarks, and even validates improvements all in a smooth, guided loop. \nIt’s like having a performance engineer sitting next to you. Without the coffee runs. And starting today, it’s ready for action in the latest version of Visual Studio, powered by GitHub Copilot. Download Visual Studio 2026 Insiders today.\n\nCopilot Profiler Agent \nMeet the Copilot Profiler Agent \nThe Profiler Agent is the first-of-its-kind AI assistant in Visual Studio, designed to work seamlessly with GitHub Copilot. \nHere’s what it can do for you:\nAnalyze CPU usage, memory allocations, and runtime behavior\nSurface the most expensive bottlenecks in your code\nGenerate new BenchmarkDotNet benchmarks (or optimize existing ones)\nSuggest actionable performance improvements you can apply instantly\nValidate fixes with before/after metrics, all in a smooth guided loop\nAnd the best part, it’s as easy as asking a question in Copilot Chat. You can:\nTag it directly: @profiler Why is my app slow?\nOr just ask in plain language in Copilot agent mode: “Why is my frame rate dropping?”\n(Just make sure the Profiler Agent is enabled in the Copilot Chat tool menu.)\nNow, let’s take a look at it in action. In the demo below, you will see I pointed the agent at an existing benchmark in SharpZipLib and asked it to optimize. From there, it handled everything: running the benchmark, guiding me through the changes, applying targeted performance fixes, and validating the results by re-running the benchmark. The result was a measurable performance improvement, all from a single prompt.\n\nReal Code. Real Impact\nWhen we set out to build the Copilot Profiler Agent, we knew one thing for sure: showing it off on a “hello world” app wasn’t going to prove anything. Real developers don’t struggle with toy code. The real test was whether it could handle messy, performance-critical, production-grade projects. \nSo we aimed high: pointing the Profiler Agent at the top 100 most widely used open-source libraries and applications the kind of code that powers frameworks, services, and apps you probably use every single day. \nThe results blew past our expectations. The Profiler Agent : \n Surfaced hidden bottlenecks you wouldn’t spot on your own \nSuggested practical, actionable fixes \n Auto-generated benchmarks to validate improvements \n Turned insights into real pull requests on real projects \nWe’ve already contributed PRs to CSVHelper, NLog, Serilog, and more all powered by the Profiler Agent’s insights. \nAnd the feedback from the community says it all: \nSaw the YouTube video and it is almost magical. Amazing how it was able to recognize that multiple expression-compiles could be merged into a single expression-compile.– NLog Maintainer \nWe’ll be publishing a detailed case studies soon, walking through exactly how the Profiler Agent tackled these projects step by step. \nThis isn’t just OSS, either. We rolled out the Profiler Agent for internal dogfooding across Microsoft teams, and the results have been equally eye-opening. \nHere’s one story from a Principal Engineer: \nI had a class that wrapped a dictionary and exposed a limited set of operations. I wanted to support foreach on the class, so I added IEnumerable<TKey, TValue>, but this caused a big jump in memory use and execution time compared to iterating directly over the inner dictionary. After several prompt iterations with the profiler agent, it nudged me toward the realization that .NET supports duck typing for foreach. I didn’t need IEnumerable at all just exposing GetEnumerator that forwards to the inner dictionary worked.  \nHonestly, I’m not sure I would have figured this out on my own. I even asked several principal-level engineers with deep .NET experience, and none of them knew about this either. When focused on allocation optimization, the profiler agent does a great job of spotting improvements. \nWhat’s Next \nThis is just the beginning. The Profiler Agent currently supports high CPU usage analysis and .NET object allocations and memory usage analysis and more coming soon. \nWe’re excited to see how you use this in your own workflows whether it’s tuning a game engine, optimizing a service, or just speeding up a slow UI. So please try it out and don’t forget to Share your results by taking this short survey.  \nStay connected with the Visual Studio team by following us on Twitter @VS_Debugger, Twitter @VisualStudio, YouTube, and LinkedIn.\nDemocratizing profiling, one performance wins at a time.   \n \n \n \nThe post Democratizing Performance: The Copilot Profiler Agent in Action on Real Code appeared first on Visual Studio Blog.",
        "dc:creator": "Harshada Hole",
        "comments": "https://devblogs.microsoft.com/visualstudio/copilot-profiler-agent-visual-studio/#comments",
        "content": "<p>We’re excited to announce the Copilot Profiler Agent available in Visual Studio 2026 Insiders, it&#8217;s an AI-powered performance assistant built directly into Visual Studio. Forget staring at endless call trees or walls of mysterious numbers that leave you asking, “where do I even start?” The Copilot Profiler Agent changes that.   Instead of raw data, you [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/copilot-profiler-agent-visual-studio/\">Democratizing Performance: The Copilot Profiler Agent in Action on Real Code</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "We’re excited to announce the Copilot Profiler Agent available in Visual Studio 2026 Insiders, it’s an AI-powered performance assistant built directly into Visual Studio. Forget staring at endless call trees or walls of mysterious numbers that leave you asking, “where do I even start?” The Copilot Profiler Agent changes that.   Instead of raw data, you […]\nThe post Democratizing Performance: The Copilot Profiler Agent in Action on Real Code appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=254306",
        "categories": [
          "Visual Studio",
          "Debugging and Diagnostics",
          "Performance Improvements",
          "Profiling",
          "Visual Studio 2026"
        ],
        "isoDate": "2025-09-11T16:05:09.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": [
      {
        "creator": "Soomin Kim",
        "title": "태재 AI 아카데미 - 금융 AI 전망 (윤송이 박사) - 금융 + AI 과정",
        "link": "https://brunch.co.kr/@@PUo/49",
        "pubDate": "Thu, 11 Sep 2025 15:33:23 GMT",
        "author": "Soomin Kim",
        "content": "태재 AI 아카데미: 금융 + AI 과정 챗GPT (3.5) 출시 후 빠르게 나왔던 엔씨 LLM 바르코와 &lt;가장 인간적인 미래&gt; 책으로 만났던, 윤송이 박사님 &ldquo;AI Transformation at Full Speed in Finance&quot; 강연  몇 가지 인사이트가 인상에 남아 잊기 전 기록  - AI 버블은 기술 거품이라기보다, 유능한 창업자 공급 부족으<img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FPUo%2Fimage%2FS2Eou11xQsrObA8sUeXJWIsVHgQ.png\" width=\"500\" />",
        "contentSnippet": "태재 AI 아카데미: 금융 + AI 과정 챗GPT (3.5) 출시 후 빠르게 나왔던 엔씨 LLM 바르코와 <가장 인간적인 미래> 책으로 만났던, 윤송이 박사님 “AI Transformation at Full Speed in Finance\" 강연  몇 가지 인사이트가 인상에 남아 잊기 전 기록  - AI 버블은 기술 거품이라기보다, 유능한 창업자 공급 부족으",
        "guid": "https://brunch.co.kr/@@PUo/49",
        "isoDate": "2025-09-11T15:33:23.000Z"
      }
    ]
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": [
      {
        "title": "노코드 도구 Dify 사용기",
        "link": "http://daddynkidsmakers.blogspot.com/2025/09/dify.html",
        "pubDate": "2025-09-16T07:16:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">이 글은&nbsp;노코드 도구 Dify 사용기이다.&nbsp;<br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgW_TD-4n57Xk8PWHweMa4J_q9CMHhlQvNwkU3HJpF3QDSdhIbfWJfFokjyM0FSIs8yvzMWiAEUWHth4wuMwQaEZVy0gAJtvXECnzFFPUFVn73LtDKmGjXCKZECSDyfxGo5-G-pqBDxagH5nofSMTFyeUBBeqJ0tLyl8iqTLb0lIEEwlHh1Vw2xXou0SLf9\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"1205\" data-original-width=\"786\" height=\"240\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgW_TD-4n57Xk8PWHweMa4J_q9CMHhlQvNwkU3HJpF3QDSdhIbfWJfFokjyM0FSIs8yvzMWiAEUWHth4wuMwQaEZVy0gAJtvXECnzFFPUFVn73LtDKmGjXCKZECSDyfxGo5-G-pqBDxagH5nofSMTFyeUBBeqJ0tLyl8iqTLb0lIEEwlHh1Vw2xXou0SLf9\" width=\"157\" /></a></div><br /></div><div style=\"text-align: left;\"><b>레퍼런스</b></div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><a href=\"https://medium.com/@tubelwj/guide-to-dify-an-open-source-platform-for-developing-large-language-model-llm-applications-e6cc2d39ecdf\">Guide to Dify, an open-source platform for developing large language model (LLM) applications | by Gen. Devin DL. | Medium</a></li><li><a href=\"https://dify-ai.medium.com/\">Dify.AI – Medium</a></li><li><a href=\"https://medium.com/@whiteking64/explore-dify-a-step-by-step-guide-to-building-a-simple-llm-powered-application-d1dd361a33ad\">Explore Dify: A Step-by-Step Guide to Building a Simple LLM-Powered Application | by Ken Maeda | Medium</a></li><li><a href=\"https://medium.com/@researchgraph/getting-started-with-dify-no-code-ai-application-development-52c98aef48f7\">Getting Started with Dify: No-Code AI Application Development | by Research Graph | Medium</a></li></ul></div><div style=\"text-align: left;\"><br /></div>",
        "contentSnippet": "이 글은 노코드 도구 Dify 사용기이다. \n\n\n레퍼런스\n\nGuide to Dify, an open-source platform for developing large language model (LLM) applications | by Gen. Devin DL. | Medium\nDify.AI – Medium\nExplore Dify: A Step-by-Step Guide to Building a Simple LLM-Powered Application | by Ken Maeda | Medium\nGetting Started with Dify: No-Code AI Application Development | by Research Graph | Medium",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-8851914980377732492",
        "isoDate": "2025-09-16T07:16:00.000Z"
      },
      {
        "title": "노코드 도구 flowise 사용기",
        "link": "http://daddynkidsmakers.blogspot.com/2025/09/flowise.html",
        "pubDate": "2025-09-15T15:20:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">AI 채팅 플로우를 만드는 데 최적화된 노코드 도구입니다. LLM, RAG, 에이전트 등 AI 관련 기능을 시각적으로 쉽게 조합할 수 있다.</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEifUNMgWDxReR5ObMD5KFzEbOXAfVAd4kbeqH1051ZUymxltJ6aI5C5TukmOsSW9tYKzDJdcmH04e2M_HhIVgqahtlSunmtu2p7M3EsZSSxq-VNMg3geIsuxrxfE9qaREiOdZht88LSqi6OPGiwvFIk_HjIcknQjPlKzFFa2GIT_ABsGT5_xsSd90VqN7dY\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"1279\" data-original-width=\"2530\" height=\"162\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEifUNMgWDxReR5ObMD5KFzEbOXAfVAd4kbeqH1051ZUymxltJ6aI5C5TukmOsSW9tYKzDJdcmH04e2M_HhIVgqahtlSunmtu2p7M3EsZSSxq-VNMg3geIsuxrxfE9qaREiOdZht88LSqi6OPGiwvFIk_HjIcknQjPlKzFFa2GIT_ABsGT5_xsSd90VqN7dY\" width=\"320\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://github.com/FlowiseAI/Flowise\">FlowiseAI/Flowise: Build AI Agents, Visually</a></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><div>AI 개발에 최적화: RAG(문서 기반 답변) 챗봇이나 AI 에이전트를 매우 쉽고 빠르게 만들 수 있다.</div><div>직관적인 UI: AI 모델과 프롬프트를 연결하는 과정이 시각적이고 간단하여 입문자가 사용하기 좋다.</div><div>빠른 프로토타이핑: AI 챗봇 아이디어를 몇 분 만에 테스트 가능한 프로토타입으로 만들 수 있다.</div><div><br /></div><div>제한적인 자동화 기능: 다른 앱(슬랙, 구글 시트 등)과 연동하여 복잡한 업무 자동화를 구현하는 기능은 약하다.</div><div>챗봇 외 기능 부족: 사용자와 상호작용하는 챗봇이나 채팅 API 외의 다른 종류의 앱을 만들기 어렵다.</div><div><br /></div><div>반면 n8n은 서로 다른 앱과 서비스들을 연결하여 반복적인 업무를 자동화하는 워크플로우를 만드는 데 강력하다. AI 모델을 자동화의 한 단계로 사용할 수는 있지만, Flowise처럼 RAG나 에이전트 같은 복잡한 AI 로직을 설계하기는 어렵다. 사용자 화면을 만드는 기능이 없어 순수하게 백엔드 자동화에만 집중한다.</div></div><div style=\"text-align: left;\"><br /><b>레퍼런스<br /><ul style=\"text-align: left;\"><li><a href=\"https://cobusgreyling.medium.com/flowise-for-langchain-b7c4023ffa71\">Flowise For 🦜🔗LangChain. Flowise is an open source Graphic User… | by Cobus Greyling | Medium</a></li></ul></b></div>",
        "contentSnippet": "AI 채팅 플로우를 만드는 데 최적화된 노코드 도구입니다. LLM, RAG, 에이전트 등 AI 관련 기능을 시각적으로 쉽게 조합할 수 있다.\n\n\n\nFlowiseAI/Flowise: Build AI Agents, Visually\n\n\n\nAI 개발에 최적화: RAG(문서 기반 답변) 챗봇이나 AI 에이전트를 매우 쉽고 빠르게 만들 수 있다.\n직관적인 UI: AI 모델과 프롬프트를 연결하는 과정이 시각적이고 간단하여 입문자가 사용하기 좋다.\n빠른 프로토타이핑: AI 챗봇 아이디어를 몇 분 만에 테스트 가능한 프로토타입으로 만들 수 있다.\n\n\n제한적인 자동화 기능: 다른 앱(슬랙, 구글 시트 등)과 연동하여 복잡한 업무 자동화를 구현하는 기능은 약하다.\n챗봇 외 기능 부족: 사용자와 상호작용하는 챗봇이나 채팅 API 외의 다른 종류의 앱을 만들기 어렵다.\n\n\n반면 n8n은 서로 다른 앱과 서비스들을 연결하여 반복적인 업무를 자동화하는 워크플로우를 만드는 데 강력하다. AI 모델을 자동화의 한 단계로 사용할 수는 있지만, Flowise처럼 RAG나 에이전트 같은 복잡한 AI 로직을 설계하기는 어렵다. 사용자 화면을 만드는 기능이 없어 순수하게 백엔드 자동화에만 집중한다.\n\n레퍼런스\n\nFlowise For 🦜🔗LangChain. Flowise is an open source Graphic User… | by Cobus Greyling | Medium",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-4051796819247668942",
        "isoDate": "2025-09-15T15:20:00.000Z"
      },
      {
        "title": "LLM 동작 메커니즘과 최신 기술 분석",
        "link": "http://daddynkidsmakers.blogspot.com/2025/09/llm.html",
        "pubDate": "2025-09-10T12:24:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">이 글은&nbsp;LLM 동작 메커니즘과 최신 기술 분석 내용을 나눔한다.<br /><br /></div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEiPVC8sOdu3XmgOij-ge9y2rJXnTXzmek6bkqfNMZ0USBzlSbjSIPaWSSoCj4zHtGBi-4vqkR6rvvxebGne9trVlYPqNw78Vij1mVD5QNb-VV8FuYxMQdPdas4xiMCixWy5-N3MUvaJNJ3klemERnwA-LpRnzjWoyx2VZelDjdm0RarZgj5rMMdySG9P9CX\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"718\" data-original-width=\"1400\" height=\"245\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEiPVC8sOdu3XmgOij-ge9y2rJXnTXzmek6bkqfNMZ0USBzlSbjSIPaWSSoCj4zHtGBi-4vqkR6rvvxebGne9trVlYPqNw78Vij1mVD5QNb-VV8FuYxMQdPdas4xiMCixWy5-N3MUvaJNJ3klemERnwA-LpRnzjWoyx2VZelDjdm0RarZgj5rMMdySG9P9CX=w478-h245\" width=\"478\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">MoE 개념</div></div><div style=\"text-align: left;\"><p>최신 대규모 언어모델의 기술적 기법들은 크게 효율성과 성능 향상을 동시에 추구하는 방향으로 발전하고 있다. 우선 혼합 전문가 구조라 불리는 MoE 기법은 수많은 전문가 모듈 중 일부만 선택적으로 활성화하여 연산 효율을 극대화하는 방식이다. 게이트 네트워크가 입력 토큰의 은닉 상태를 보고 가장 적합한 전문가를 확률적으로 선택하고 선택된 전문가만 계산에 참여하기 때문에 전체 연산량은 줄어들면서도 특정 전문가가 특정 패턴에 특화되도록 학습된다. 이 과정에서 균형을 잡기 위해 부가적인 로드 밸런싱 손실이 함께 도입된다.</p>\n<p>또한 파라미터 효율적 미세조정 기법들이 각광받고 있다. LoRA와 같은 방법은 거대한 모델의 전체 파라미터를 업데이트하지 않고 저차원 어댑터 행렬만 학습해도 충분히 성능을 낼 수 있도록 한다. 이 방식은 저장 공간과 학습 자원을 크게 줄이면서도 다양한 도메인에 빠르게 적응할 수 있다는 장점이 있다.</p>\n<p>양자화와 프루닝 역시 중요하다. 양자화는 모델 파라미터를 16비트나 8비트 같은 저정밀도로 표현하여 메모리 사용량과 연산 속도를 개선한다. 프루닝은 중요도가 낮은 가중치를 제거함으로써 모델 크기를 줄이고 효율을 높인다. 이 두 기법은 실제 배포 환경에서의 속도와 비용 문제를 해결하는 핵심적 방법으로 활용된다.</p>\n<p>메모리와 추론 속도를 개선하기 위한 기법으로는 효율적 어텐션 구조가 있다. 전통적인 어텐션은 시퀀스 길이에 따라 연산량이 제곱으로 늘어나는데 이를 완화하기 위해 플래시 어텐션과 같은 최적화 기법이 개발되었다. 이 방식은 GPU의 메모리 대역폭을 최대한 활용하면서도 연산을 줄여 긴 시퀀스 처리 능력을 크게 향상시킨다.</p>\n<p>데이터 품질과 안전성을 강화하기 위한 학습 전략도 주목된다. 인간 피드백을 통한 강화학습 기법인 RLHF는 모델이 단순히 언어를 생성하는 수준을 넘어 사용자의 의도와 선호를 반영하도록 만든다. 최근에는 직접적인 강화학습 대신 선호 데이터만으로 지도학습을 수행하는 DPO와 같은 방식이 도입되어 학습의 안정성과 단순성이 개선되고 있다.</p>\n<p>이와 함께 다중 모달 학습이 확대되고 있다. 텍스트뿐 아니라 이미지 음성 코드 등 다양한 데이터를 하나의 모델이 동시에 이해하고 생성할 수 있도록 설계하는 것이다. 이는 언어 중심에서 벗어나 실제 세계와 상호작용하는 범용 인공지능의 기반이 된다.</p>\n<p>요약하면 최신 언어모델은 전문가를 선택적으로 활용하는 MoE 구조 파라미터 효율적 학습을 위한 LoRA 양자화와 프루닝 같은 최적화 메모리 효율적 어텐션 구조 인간 피드백 기반 학습 전략 그리고 다중 모달 통합 학습이라는 축 위에서 진화하고 있는 것이다.</p></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b>레퍼런스</b></div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><a href=\"https://sausheong.com/how-to-train-a-llm-from-scratch-1c3490e8b2ce\">How to train a LLM from scratch. How to train a small LLM at home with… | by Sau Sheong | Medium</a></li><li><a href=\"https://medium.com/@bogdan.su/in-this-article-we-will-build-our-llm-which-i-called-lightlm-from-scratch-choose-the-optimal-c1e1839668db\">Developing and training a small MoE LLM from scratch | Medium</a></li><li><a href=\"https://medium.com/@mahadir.ahmad/mastering-the-intuition-behind-large-language-model-llm-by-building-gpt-2-from-scratch-6f93bc303cb9\">Building Large Language Model (LLM) from Scratch in just 160 lines of Code | by Mahadir Ahmad | Medium</a></li><li><a href=\"https://towardsdatascience.com/how-to-build-an-llm-from-scratch-8c477768f1f9/\">How to Build an LLM from Scratch | Towards Data Science</a></li><li><a href=\"https://medium.com/@raufpokemon00/building-a-large-language-model-llm-from-scratch-61fed0570ea5\">Building a Large Language Model (LLM) from Scratch | by Abdul Rauf | Medium</a></li><li><a href=\"https://medium.com/data-science/understanding-llms-from-scratch-using-middle-school-math-e602d27ec876\">LLMs from Scratch Using Middle School Math | TDS Archive</a></li><li><a href=\"https://github.com/rasbt/LLMs-from-scratch\">rasbt/LLMs-from-scratch: Implement a ChatGPT-like LLM in PyTorch from scratch, step by step</a></li></ul></div>",
        "contentSnippet": "이 글은 LLM 동작 메커니즘과 최신 기술 분석 내용을 나눔한다.\n\n\n\nMoE 개념\n\n최신 대규모 언어모델의 기술적 기법들은 크게 효율성과 성능 향상을 동시에 추구하는 방향으로 발전하고 있다. 우선 혼합 전문가 구조라 불리는 MoE 기법은 수많은 전문가 모듈 중 일부만 선택적으로 활성화하여 연산 효율을 극대화하는 방식이다. 게이트 네트워크가 입력 토큰의 은닉 상태를 보고 가장 적합한 전문가를 확률적으로 선택하고 선택된 전문가만 계산에 참여하기 때문에 전체 연산량은 줄어들면서도 특정 전문가가 특정 패턴에 특화되도록 학습된다. 이 과정에서 균형을 잡기 위해 부가적인 로드 밸런싱 손실이 함께 도입된다.\n또한 파라미터 효율적 미세조정 기법들이 각광받고 있다. LoRA와 같은 방법은 거대한 모델의 전체 파라미터를 업데이트하지 않고 저차원 어댑터 행렬만 학습해도 충분히 성능을 낼 수 있도록 한다. 이 방식은 저장 공간과 학습 자원을 크게 줄이면서도 다양한 도메인에 빠르게 적응할 수 있다는 장점이 있다.\n양자화와 프루닝 역시 중요하다. 양자화는 모델 파라미터를 16비트나 8비트 같은 저정밀도로 표현하여 메모리 사용량과 연산 속도를 개선한다. 프루닝은 중요도가 낮은 가중치를 제거함으로써 모델 크기를 줄이고 효율을 높인다. 이 두 기법은 실제 배포 환경에서의 속도와 비용 문제를 해결하는 핵심적 방법으로 활용된다.\n메모리와 추론 속도를 개선하기 위한 기법으로는 효율적 어텐션 구조가 있다. 전통적인 어텐션은 시퀀스 길이에 따라 연산량이 제곱으로 늘어나는데 이를 완화하기 위해 플래시 어텐션과 같은 최적화 기법이 개발되었다. 이 방식은 GPU의 메모리 대역폭을 최대한 활용하면서도 연산을 줄여 긴 시퀀스 처리 능력을 크게 향상시킨다.\n데이터 품질과 안전성을 강화하기 위한 학습 전략도 주목된다. 인간 피드백을 통한 강화학습 기법인 RLHF는 모델이 단순히 언어를 생성하는 수준을 넘어 사용자의 의도와 선호를 반영하도록 만든다. 최근에는 직접적인 강화학습 대신 선호 데이터만으로 지도학습을 수행하는 DPO와 같은 방식이 도입되어 학습의 안정성과 단순성이 개선되고 있다.\n이와 함께 다중 모달 학습이 확대되고 있다. 텍스트뿐 아니라 이미지 음성 코드 등 다양한 데이터를 하나의 모델이 동시에 이해하고 생성할 수 있도록 설계하는 것이다. 이는 언어 중심에서 벗어나 실제 세계와 상호작용하는 범용 인공지능의 기반이 된다.\n요약하면 최신 언어모델은 전문가를 선택적으로 활용하는 MoE 구조 파라미터 효율적 학습을 위한 LoRA 양자화와 프루닝 같은 최적화 메모리 효율적 어텐션 구조 인간 피드백 기반 학습 전략 그리고 다중 모달 통합 학습이라는 축 위에서 진화하고 있는 것이다.\n\n\n레퍼런스\n\nHow to train a LLM from scratch. How to train a small LLM at home with… | by Sau Sheong | Medium\nDeveloping and training a small MoE LLM from scratch | Medium\nBuilding Large Language Model (LLM) from Scratch in just 160 lines of Code | by Mahadir Ahmad | Medium\nHow to Build an LLM from Scratch | Towards Data Science\nBuilding a Large Language Model (LLM) from Scratch | by Abdul Rauf | Medium\nLLMs from Scratch Using Middle School Math | TDS Archive\nrasbt/LLMs-from-scratch: Implement a ChatGPT-like LLM in PyTorch from scratch, step by step",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-6819540265708257133",
        "isoDate": "2025-09-10T12:24:00.000Z"
      }
    ]
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "30년 검색의 종말? 구글 AI 모드가 예고하는 '답변 엔진' 시대의 서막",
        "link": "http://muzbox.tistory.com/483657",
        "pubDate": "Tue, 16 Sep 2025 15:35:50 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483657#entry483657comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #333333;\">\n<div style=\"background-color: #e3f2fd; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">\n<p style=\"margin-bottom: 20px; color: #333333;\" data-ke-size=\"size16\"><b>30년 검색의 종말?</b> 구글 AI 모드의 등장은 단순한 검색 기능 업그레이드를 넘어 검색 생태계와 AI 산업 전반에 근본적인 변화를 가져오고 있습니다. 2025년 한국에 정식 출시된 제미나이 2.5 기반의 이 혁신적인 도구가 어떻게 우리의 정보 탐색 방식을 바꾸고, 미래 검색의 방향을 제시하는지 자세히 알아봅니다.</p>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #0f4c81, #002f6c); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  구글 AI 모드, 도대체 무엇이 다르죠?</b></h2>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/bkiOoa/btsQAD1I8qy/RZ2xAiSBCOjIJCp4f3iCHk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bkiOoa/btsQAD1I8qy/RZ2xAiSBCOjIJCp4f3iCHk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bkiOoa/btsQAD1I8qy/RZ2xAiSBCOjIJCp4f3iCHk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbkiOoa%2FbtsQAD1I8qy%2FRZ2xAiSBCOjIJCp4f3iCHk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"구글 AI 모드 인터페이스 스크린샷: 검색창과 여러 정보 카드가 포함된 모바일 화면으로, 사용자의 복잡한 질문에 대한 종합적인 AI 답변이 시각적으로 구성된 모습.\" loading=\"lazy\" width=\"500\" height=\"500\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">음, 2025년 9월 한국에 정식 출시된 구글 AI 모드는 정말이지 기존 검색의 판도를 완전히 뒤집는다고 해도 과언이 아니에요. 단순히 몇몇 기능을 추가한 수준이 아니라, 검색 생태계와 AI 산업 전반에 걸쳐 근본적인 변화를 가져올 혁신적인 도구라고 저는 생각합니다. 제미나이 2.5 맞춤형 버전을 기반으로 하는 이 AI 모드는 사실 기존 AI Overview의 확장된 개념인데요, 가장 핵심적인 특징은 바로 '쿼리 팬-아웃(query fan-out)' 기술이 아닐까 싶어요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 기술, 정말 대단하죠. 사용자가 복잡한 질문을 던지면 AI가 이를 여러 개의 하위 주제로 똑똑하게 분해합니다. 그리고는 각 주제에 대해 동시에 검색을 수행해서 종합적이고 아주 풍부한 답변을 척척 만들어내죠. 예를 들어, 저도 해봤는데, \"7세와 4세 아이 2명과 서울에서 1시간 거리로 주말에 함께 갈 수 있는 한적한 여행지\" 같은 복잡한 요청도 한 번에 깔끔하게 처리해주더라고요. 이런 경험은 기존 검색에서는 상상하기 어려웠던 부분이죠. 솔직히 말하면, 제가 겪어본 바로는 정말 혁신적이에요!</p>\n<h3 style=\"font-size: 19px; color: #0f4c81; margin: 25px 0 10px; padding-bottom: 5px; border-bottom: 2px solid #e3f2fd;\" data-ke-size=\"size23\">멀티모달 검색 경험의 확장</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">구글 AI 모드는 텍스트만 처리하는 것이 아니라, 음성과 이미지까지 지원하는 진정한 <b>멀티모달 검색 경험</b>을 제공합니다. 마이크 버튼 하나로 음성 질문을 하거나, 구글 렌즈와 연동해서 사진 한 장만으로도 복잡한 질문을 할 수 있어요. 얼마 전 해외여행에서 써봤는데, 식당 메뉴판을 사진으로 찍고 \"채식주의자가 먹을 수 있는 메뉴 알려줘\"라고 물으니, 번역은 물론이고 조건에 맞는 추천까지 해주더라고요. 정말이지 여행의 질이 달라지는 경험이었어요!</p>\n<h3 style=\"font-size: 19px; color: #0f4c81; margin: 25px 0 10px; padding-bottom: 5px; border-bottom: 2px solid #e3f2fd;\" data-ke-size=\"size23\">딥 서치와 개인 맞춤형 기능으로 한 단계 더!</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">여기서 끝이 아닙니다. AI 모드에서는 수백 건의 검색을 동시에 진행해서 전문가 수준의 완벽한 보고서를 단 몇 분 만에 생성하는 <b>딥 서치(Deep Search)</b> 기능도 제공해요. 저처럼 리서치를 많이 하는 사람들에게는 정말이지 빛과 소금 같은 기능이죠. 그리고 사용자의 동의하에 지메일 등 다른 구글 앱과 연동하여 개인 정보를 활용한 맞춤형 답변까지 제공하는데, 이건 정말 개인 비서가 생긴 기분이에요.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/bF4qYp/btsQAHwgiB5/Lqa3FzzwYbXs8DZ3bKass0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bF4qYp/btsQAHwgiB5/Lqa3FzzwYbXs8DZ3bKass0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bF4qYp/btsQAHwgiB5/Lqa3FzzwYbXs8DZ3bKass0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbF4qYp%2FbtsQAHwgiB5%2FLqa3FzzwYbXs8DZ3bKass0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"음성, 이미지, 텍스트 등 다양한 입력 방식을 통해 복잡한 질문을 처리하는 AI 검색 엔진의 멀티모달 기능 개념도.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<div style=\"background-color: #e3f2fd; border-left: 4px solid #0f4c81; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">\n<p style=\"margin-bottom: 0; color: #333333;\" data-ke-size=\"size16\">  <b>핵심 기술 요약:</b> 구글 AI 모드는 제미나이 2.5 기반의 쿼리 팬-아웃 기술로 복잡한 질문을 세분화하여 동시에 검색합니다. 음성/이미지 인식 멀티모달 기능과 수백 건의 동시 검색을 통한 딥 서치 기능이 핵심입니다.</p>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #0f4c81, #002f6c); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>⚙️ AI 모드, 실생활에서 어떻게 활용할까요?</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">구글 AI 모드는 단순히 기술만 발전한 것이 아니라, 우리의 일상과 업무 여러 분야에서 엄청난 잠재력을 가지고 있어요. 제가 직접 써보고 느낀 점들과 함께 몇 가지 활용법을 소개해 드릴게요.</p>\n<h3 style=\"font-size: 19px; color: #0f4c81; margin: 25px 0 10px; padding-bottom: 5px; border-bottom: 2px solid #e3f2fd;\" data-ke-size=\"size23\">비즈니스 및 마케팅 분야에서 똑똑하게!</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">비즈니스 환경에서 AI 모드는 정말 유용합니다. \"B2B 스타트업을 위한 통합 마케팅 자동화 솔루션 추천해줘\"와 같은 질문을 던져보세요. AI는 이 질문을 'B2B 특화 기능', '스타트업 예산 대응', '마케팅 자동화 도구 비교', '통합 솔루션 장점' 등으로 아주 세분화하여 검색하고, 관련 정보를 깔끔하게 정리해줍니다. 마치 전문 컨설턴트가 짧은 시간 안에 핵심 보고서를 만들어주는 느낌이랄까요? 제가 전에 리서치하던 시간의 절반도 안 걸려서 놀랐어요.</p>\n<h3 style=\"font-size: 19px; color: #0f4c81; margin: 25px 0 10px; padding-bottom: 5px; border-bottom: 2px solid #e3f2fd;\" data-ke-size=\"size23\">여행 및 생활 정보 검색도 문제없죠!</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">복잡한 여행 계획 수립이나 일상생활 정보 검색에서도 AI 모드의 강점이 빛을 발합니다. \"내년 5월에 열리는 철인 3종 경기를 준비하려고 해. 훈련 시작 전에 알아야 할 점은 무엇이야?\" 같은 다층적인 질문에도 훈련 계획, 영양, 장비, 부상 예방 등 종합적인 답변을 제공해요. 저는 다음 주말 여행 계획을 AI 모드로 짜봤는데, 숙소부터 맛집, 아이들 체험 활동까지 정말 완벽하게 추천해주더라고요. 솔직히 감탄했습니다.</p>\n<h3 style=\"font-size: 19px; color: #0f4c81; margin: 25px 0 10px; padding-bottom: 5px; border-bottom: 2px solid #e3f2fd;\" data-ke-size=\"size23\">학술 연구 및 교육 분야의 혁신</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">학술 연구와 교육 분야에서도 AI 모드는 혁신적인 도구로 자리매김하고 있습니다. 이제는 이미지나 PDF 파일에 대한 질문 분석 기능이 데스크톱으로도 확장되어, 강의 슬라이드를 업로드하고 관련 질문을 하는 것이 가능해졌어요. 학생들은 복잡한 논문 내용을 빠르게 이해하고, 연구자들은 방대한 자료를 효율적으로 탐색할 수 있게 되는 거죠. 제가 학교 다닐 때 이런 기능이 있었다면 성적이 훨씬 좋았을 것 같아요. (웃음)</p>\n<h3 style=\"font-size: 19px; color: #0f4c81; margin: 25px 0 10px; padding-bottom: 5px; border-bottom: 2px solid #e3f2fd;\" data-ke-size=\"size23\">콘텐츠 생성 및 최적화에도 탁월!</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">AI 모드는 콘텐츠 마케터들에게도 강력한 도구가 됩니다. 예를 들어, \"네이버 블로그 상위노출 기사 10개의 제목을 분석하고, 이들 기사보다 상위노출이 가능한 최적의 블로그 제목을 생성해줘\"와 같은 요청을 통해 경쟁사 분석과 함께 SEO에 최적화된 제목을 손쉽게 얻을 수 있습니다. 이는 콘텐츠 기획 시간을 크게 단축시키고, 더욱 효과적인 마케팅 전략을 수립하는 데 도움을 줍니다.</p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"kakaotv\" data-video-url=\"https://tv.kakao.com/v/457997491\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cjWFMH/hyZJjdE7ir/CTLai6zH2e794eBaBaKCZ1/img.jpg?width=1118&amp;height=702&amp;face=0_0_1118_702,https://scrap.kakaocdn.net/dn/cp7JVx/hyZJwRBTJN/72W8NsnNjkFD789w7wQnck/img.jpg?width=1118&amp;height=702&amp;face=0_0_1118_702\" data-video-width=\"860\" data-video-height=\"540\" data-video-origin-width=\"860\" data-video-origin-height=\"540\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"'어떤오후의 프리웨어 이야기 (유용한 IT정보)'에서 업로드한 동영상\" data-video-play-service=\"daum_tistory\" data-original-url=\"\"><iframe src=\"https://play-tv.kakao.com/embed/player/cliplink/457997491?service=daum_tistory\" width=\"860\" height=\"540\" frameborder=\"0\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 style=\"font-size: 19px; color: #0f4c81; margin: 25px 0 10px; padding-bottom: 5px; border-bottom: 2px solid #e3f2fd;\" data-ke-size=\"size23\">시의성 있는 정보 검색 및 기사 작성까지!</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">최신 시사 이슈나 정책에 대한 정보가 필요할 때도 AI 모드를 활용할 수 있습니다. \"정부의 2025년 추석 민생 안정대책에 대한 신뢰할 수 있는 자료를 검색하고 블로그 기사를 생성해 (검색대상에 블로그를 제외해)\"와 같이 특정 조건을 지정하여 정보를 요청하면, AI가 신뢰도 높은 자료를 기반으로 관련 기사 초안을 작성해줍니다. 이를 통해 빠르고 정확하게 필요한 정보를 얻고, 생산적인 작업으로 이어갈 수 있습니다.</p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"kakaotv\" data-video-url=\"https://tv.kakao.com/v/457997511\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/iiBsi/hyZJwc0wWQ/g4G5c2K0GROoage6AGlKe1/img.jpg?width=1122&amp;height=700&amp;face=0_0_1122_700,https://scrap.kakaocdn.net/dn/cUJpOv/hyZIMhtWRf/EISrlwrYWirPbdy3sj84iK/img.jpg?width=1122&amp;height=700&amp;face=0_0_1122_700\" data-video-width=\"860\" data-video-height=\"537\" data-video-origin-width=\"860\" data-video-origin-height=\"537\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"'어떤오후의 프리웨어 이야기 (유용한 IT정보)'에서 업로드한 동영상\" data-video-play-service=\"daum_tistory\" data-original-url=\"\"><iframe src=\"https://play-tv.kakao.com/embed/player/cliplink/457997511?service=daum_tistory\" width=\"860\" height=\"537\" frameborder=\"0\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #0f4c81, #002f6c); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>⚔️ LLM 시장의 격전, 그리고 구글의 전략</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">구글 AI 모드의 등장은 단순히 검색 기능의 변화를 넘어, 전체 AI 검색 시장의 경쟁을 더욱 치열하게 만들고 있어요. ChatGPT의 SearchGPT, Perplexity AI, Bing AI 등 각자의 강점을 내세우는 경쟁자들이 이미 많이 존재하거든요. 이런 상황에서 구글이 본격적으로 AI 검색 서비스를 도입했다는 건, 시장 판도에 상당한 변화를 가져올 것이라는 의미로 해석될 수 있죠. 제 생각에는 구글이 검색 시장의 주도권을 절대 놓치지 않겠다는 강력한 의지를 보여준 것 같아요.</p>\n<div style=\"background-color: #ffebee; border-left: 4px solid #d32f2f; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">\n<p style=\"margin-bottom: 0; color: #333333;\" data-ke-size=\"size16\">⚠️ <b>주목할 점:</b> 일부 전문가들은 AI 검색이 기존 구글의 검색 점유율 33%를 빼앗아올 수 있다고 분석합니다. 라이너는 학술 검색, Perplexity는 미디어 종사자와 리서처 사이에서 인기를 얻고 있으며, ChatGPT는 LLM 이용자들의 검색 습관을 바꾸고 있어요. 구글도 마냥 안심할 수만은 없는 상황이죠.</p>\n</div>\n<h3 style=\"font-size: 19px; color: #0f4c81; margin: 25px 0 10px; padding-bottom: 5px; border-bottom: 2px solid #e3f2fd;\" data-ke-size=\"size23\">LLM 시장의 자연독점 가능성</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">최근 AI 업계에서는 \"LLM 시장이 구글처럼 자연독점이 될 수 있다\"는 전망이 조심스럽게 제기되고 있습니다. 구글의 AI 모드 도입은 이러한 자연독점 구조를 더욱 공고히 할 가능성이 크다고 저는 봐요. 구글이 보유한 강력한 검색 인프라와 방대한 데이터, 그리고 제미나이 2.5 같은 최첨단 AI 모델을 결합하면 경쟁자들이 쉽게 따라잡기 어려운 격차를 만들어낼 수 있겠죠. 아, 그런데 이건 독점이라는 측면에서는 우려가 될 수도 있겠네요.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"구글 ai 모드.jpg\" data-origin-width=\"842\" data-origin-height=\"479\"><span data-url=\"https://blog.kakaocdn.net/dn/c1OjVU/btsQCsRMOp6/iTvKcZYXzxRGN5kREpK0kK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/c1OjVU/btsQCsRMOp6/iTvKcZYXzxRGN5kREpK0kK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/c1OjVU/btsQCsRMOp6/iTvKcZYXzxRGN5kREpK0kK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc1OjVU%2FbtsQCsRMOp6%2FiTvKcZYXzxRGN5kREpK0kK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"구글 검색엔진에 추가된 AI 모드 버튼의 위치를 가리키는 이미지\" loading=\"lazy\" width=\"842\" height=\"479\" data-filename=\"구글 ai 모드.jpg\" data-origin-width=\"842\" data-origin-height=\"479\"/></span></figure>\n\n<h3 style=\"font-size: 19px; color: #0f4c81; margin: 25px 0 10px; padding-bottom: 5px; border-bottom: 2px solid #e3f2fd;\" data-ke-size=\"size23\">플랫폼별 검색 경험의 분화</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">LLM이 모든 앱에 검색 기능을 주입하면서, 이제 검색은 더 이상 Google.com에서만 시작되거나 끝나지 않게 되었습니다. Microsoft Excel에서 쿠키 레시피를 검색하거나, Meta AI를 통해 WhatsApp, Instagram, Facebook에서도 검색할 수 있게 되었으니 말이죠. 구글은 이제 ChatGPT뿐만 아니라 수천 개의 작은 AI 검색 엔진들과도 경쟁해야 하는 상황에 놓인 겁니다. 검색의 정의 자체가 확장되고 있다는 느낌이에요.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #0f4c81, #002f6c); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  검색 엔진 생태계에 미치는 혁명적 영향</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">구글 AI 모드의 도입은 정말이지 검색 생태계 전반에 혁명적인 변화를 가져오고 있다고 저는 확신합니다. 우리 모두의 검색 습관부터 웹사이트 트래픽, 그리고 SEO 전략까지, 모든 것이 바뀌고 있어요.</p>\n<h3 style=\"font-size: 19px; color: #0f4c81; margin: 25px 0 10px; padding-bottom: 5px; border-bottom: 2px solid #e3f2fd;\" data-ke-size=\"size23\">검색 행동 패턴의 근본적 변화</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">AI Overview가 출시된 이후, 사용자들은 기존 검색보다 2~3배 긴 질문을 하기 시작했어요. 이건 AI가 자연어를 정말 잘 이해할 수 있다는 신뢰가 형성되었기 때문입니다. 전체 검색의 약 20% 정도가 '롱테일 키워드'(요구 사항이 구체적인 긴 검색어)를 차지하는데, 이 비율은 계속 증가하는 추세예요. 이제 사람들은 \"CRM 추천\" 같은 짧은 키워드 대신 \"중소기업에서 사용하기 쉬운 클라우드 기반 CRM 솔루션을 추천해줘\"와 같이 더 자연스러운 문장으로 검색하게 된 거죠. 제가 생각하기에 이런 변화는 정보 탐색의 효율성을 극대화할 거예요.</p>\n<h3 style=\"font-size: 19px; color: #0f4c81; margin: 25px 0 10px; padding-bottom: 5px; border-bottom: 2px solid #e3f2fd;\" data-ke-size=\"size23\">제로 클릭 검색 확산과 웹 트래픽의 변화</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">AI Overview와 AI 모드의 도입으로 이제 <b>제로 클릭 검색</b>이 더욱 일반화되고 있습니다. 사용자들이 검색 결과에서 바로 답을 얻을 수 있으니, 웹사이트 클릭률(CTR)이 낮아지고 자연 검색 트래픽이 줄어들 가능성이 커졌어요. 최근 데이터에 따르면 전 세계 검색 트래픽이 15% 감소했다는 분석도 있는데, 이게 바로 AI 검색 기능 강화의 영향이라고 합니다. 콘텐츠 제작자들에게는 정말 중요한 변화죠.</p>\n<h3 style=\"font-size: 19px; color: #0f4c81; margin: 25px 0 10px; padding-bottom: 5px; border-bottom: 2px solid #e3f2fd;\" data-ke-size=\"size23\">SEO 전략의 패러다임 전환</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">AI 검색의 도입은 SEO 전략에 근본적인 변화를 요구하고 있습니다. 이제는 단순히 키워드 최적화를 넘어서, AI가 이해하고 종합할 수 있는 <b>'정보의 질'과 '구조'</b>가 훨씬 더 중요해졌어요. 기업들은 키워드를 통한 검색 최적화에만 매달릴 것이 아니라, AI의 분석 능력을 활용하여 소비자의 실제 요구와 행동 패턴에 맞춘 고품질 콘텐츠 제공에 집중해야 합니다. 이건 마치 새로운 게임의 규칙을 배우는 것과 같아요. 쉬운 일은 아니지만, 반드시 적응해야 합니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/lltAC/btsQCvgE1Ui/hNCKwPdbCsdKpoNvtDsrVK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/lltAC/btsQCvgE1Ui/hNCKwPdbCsdKpoNvtDsrVK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/lltAC/btsQCvgE1Ui/hNCKwPdbCsdKpoNvtDsrVK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FlltAC%2FbtsQCvgE1Ui%2FhNCKwPdbCsdKpoNvtDsrVK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"2022년부터 2026년까지 검색 시장 점유율 변화 추이를 나타내는 추세 그래프. AI 검색의 성장과 기존 검색 엔진 시장 점유율의 변화를 시각화.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h3 style=\"font-size: 19px; color: #0f4c81; margin: 25px 0 10px; padding-bottom: 5px; border-bottom: 2px solid #e3f2fd;\" data-ke-size=\"size23\">검색 결과의 투명성과 신뢰도 향상</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">구글은 AI 모드의 투명성을 높이기 위해 Search Console에 AI 모드에서의 클릭, 노출, 순위 데이터를 통합했어요. 이를 통해 게시자와 사이트 소유자들이 AI 모드가 검색 결과에 미치는 영향을 더 정확하게 파악할 수 있게 되었죠. 게다가 AI 모드는 구글의 기존 품질 및 순위 시스템을 기반으로 작동하며, 신뢰도가 낮을 경우 기존 웹 검색 결과를 그대로 보여주는 보완 장치까지 마련했습니다. AI 답변의 품질이나 유용성에 대한 신뢰도가 충분히 높지 않다면 웹 링크를 제공하여 사용자가 직접 검증할 수 있도록 지원하는 점도 아주 긍정적인 부분이라고 생각해요.</p>\n<div style=\"background-color: #f0f4f8; border: 1px solid #b0bec5; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); padding: 25px; margin: 30px 0;\">\n<div style=\"border-bottom: 1px solid #0f4c81; padding-bottom: 15px; margin-bottom: 20px;\">\n<p style=\"font-size: 26px; color: #0f4c81; margin: 0;\" data-ke-size=\"size16\">  <b>핵심 요약</b></p>\n</div>\n<ul style=\"list-style-type: none; padding: 0; margin: 0;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 15px; font-size: 17px; color: #333333;\"><b>구글 AI 모드는 제미나이 2.5 기반의 '쿼리 팬-아웃' 기술로 복잡한 질문을 세분화하여 동시 처리, 기존 검색의 한계를 뛰어넘습니다.</b></li>\n<li style=\"margin-bottom: 15px; font-size: 17px; color: #333333;\"><b>멀티모달 검색 (음성, 이미지) 및 딥 서치 기능으로 개인 맞춤형, 전문가 수준의 정보를 제공하며 활용 범위를 넓히고 있습니다.</b></li>\n<li style=\"margin-bottom: 15px; font-size: 17px; color: #333333;\"><b>AI 검색 시장의 경쟁 심화와 LLM 시장의 자연독점 가능성 속에서, 구글은 강력한 인프라로 주도권을 유지하려 합니다.</b></li>\n<li style=\"margin-bottom: 0; font-size: 17px; color: #333333;\"><b>제로 클릭 검색 확산, 웹 트래픽 변화, 그리고 '정보의 질'과 '구조' 중심의 SEO 전략 패러다임 전환이 필수적입니다.</b></li>\n</ul>\n<div style=\"margin-top: 25px; font-size: 14px; color: #77aaff; text-align: right;\">\n<p style=\"margin: 0;\" data-ke-size=\"size16\"><i>* 미래 검색 환경에 대한 적응과 활용이 중요합니다.</i></p>\n</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #0f4c81, #002f6c); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 18px; color: #0f4c81; margin: 20px 0 5px;\" data-ke-size=\"size23\">Q1: 구글 AI 모드는 기존 검색과 무엇이 다른가요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A1: 구글 AI 모드는 제미나이 2.5 기반의 '쿼리 팬-아웃' 기술을 활용하여 사용자의 복잡한 질문을 여러 하위 주제로 분해, 동시에 검색하고 종합적인 답변을 제공합니다. 이는 기존 검색 엔진이 개별 링크를 나열하는 방식과는 근본적으로 다른, 개인 맞춤형 '답변' 중심의 경험을 선사합니다.</p>\n<h3 style=\"font-size: 18px; color: #0f4c81; margin: 20px 0 5px;\" data-ke-size=\"size23\">Q2: AI 모드의 등장으로 SEO 전략은 어떻게 바뀌어야 할까요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A2: AI 모드 시대에는 단순한 키워드 최적화를 넘어, AI가 이해하고 종합할 수 있는 <b>'정보의 질'과 '구조'</b>가 가장 중요해집니다. 사용자 질문에 대한 포괄적이고 신뢰성 높은 답변을 제공하며, AI가 콘텐츠를 쉽게 분석하고 활용할 수 있도록 명확하게 구조화된 콘텐츠 제작이 필수적입니다.</p>\n<h3 style=\"font-size: 18px; color: #0f4c81; margin: 20px 0 5px;\" data-ke-size=\"size23\">Q3: AI 모드가 웹사이트 트래픽에 미치는 영향은 무엇인가요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A3: AI 모드의 도입으로 '제로 클릭 검색'이 확산될 수 있습니다. AI가 검색 결과에서 바로 종합적인 답변을 제공하기 때문에, 사용자들이 웹사이트를 직접 클릭할 필요가 줄어들어 자연 검색 트래픽이 감소할 가능성이 있습니다. 이는 콘텐츠 제작자들이 단순히 클릭 유도를 넘어 정보 가치 자체에 집중해야 함을 의미합니다.</p>\n<h3 style=\"font-size: 18px; color: #0f4c81; margin: 20px 0 5px;\" data-ke-size=\"size23\">Q4: 구글 AI 모드의 미래는 어떻게 전망되나요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A4: 구글은 AI 모드를 지속적으로 개선하고 기능을 확장할 계획입니다. 단순한 검색 도구를 넘어 캔버스 기능, 검색 라이브, 개인 맞춤형 차트 및 그래프 생성 등 종합적인 정보 분석 및 생성 플랫폼으로 발전할 것입니다. 궁극적으로는 인덱스 중심의 검색 엔진에서 사용자 의도에 응답하는 '답변 엔진'으로의 전환을 가속화할 것으로 예상됩니다.</p>\n</div>\n<script type=\"application/ld+json\">\n    {\n      \"@context\": \"https://schema.org\",\n      \"@type\": \"FAQPage\",\n      \"mainEntity\": [\n        {\n          \"@type\": \"Question\",\n          \"name\": \"구글 AI 모드는 기존 검색과 무엇이 다른가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"구글 AI 모드는 제미나이 2.5 기반의 '쿼리 팬-아웃' 기술을 활용하여 사용자의 복잡한 질문을 여러 하위 주제로 분해, 동시에 검색하고 종합적인 답변을 제공합니다. 이는 기존 검색 엔진이 개별 링크를 나열하는 방식과는 근본적으로 다른, 개인 맞춤형 '답변' 중심의 경험을 선사합니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"AI 모드의 등장으로 SEO 전략은 어떻게 바뀌어야 할까요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"AI 모드 시대에는 단순한 키워드 최적화를 넘어, AI가 이해하고 종합할 수 있는 '정보의 질'과 '구조'가 가장 중요해집니다. 사용자 질문에 대한 포괄적이고 신뢰성 높은 답변을 제공하며, AI가 콘텐츠를 쉽게 분석하고 활용할 수 있도록 명확하게 구조화된 콘텐츠 제작이 필수적입니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"AI 모드가 웹사이트 트래픽에 미치는 영향은 무엇인가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"AI 모드의 도입으로 '제로 클릭 검색'이 확산될 수 있습니다. AI가 검색 결과에서 바로 종합적인 답변을 제공하기 때문에, 사용자들이 웹사이트를 직접 클릭할 필요가 줄어들어 자연 검색 트래픽이 감소할 가능성이 있습니다. 이는 콘텐츠 제작자들이 단순히 클릭 유도를 넘어 정보 가치 자체에 집중해야 함을 의미합니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"구글 AI 모드의 미래는 어떻게 전망되나요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"구글은 AI 모드를 지속적으로 개선하고 기능을 확장할 계획입니다. 단순한 검색 도구를 넘어 캔버스 기능, 검색 라이브, 개인 맞춤형 차트 및 그래프 생성 등 종합적인 정보 분석 및 생성 플랫폼으로 발전할 것입니다. 궁극적으로는 인덱스 중심의 검색 엔진에서 사용자 의도에 응답하는 '답변 엔진'으로의 전환을 가속화할 것으로 예상됩니다.\"\n          }\n        }\n      ]\n    }\n  </script>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #0f4c81, #002f6c); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>마무리하며: 검색 생태계의 새로운 시대</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">구글 AI 모드의 등장은 단순히 기술적 진보를 넘어, 30년간 지속되어온 전통적인 검색 방식의 패러다임을 완전히 바꾸는 중요한 이정표라고 생각합니다. AI 기반의 대화형 검색으로 진화하면서 사용자들은 훨씬 더 자연스럽고 효율적인 정보 탐색 경험을 얻게 될 것이 분명해요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">물론 이러한 변화는 다른 LLM 서비스들과의 경쟁을 더욱 치열하게 만들고 있으며, 각 플랫폼이 고유한 강점을 내세워 시장에서 경쟁하는 상황을 만들어내고 있죠. 동시에 검색 엔진 시장에서는 SEO 전략의 근본적 변화, 제로 클릭 검색의 확산, 그리고 웹 트래픽 패턴의 변화 등 다양한 영향이 나타나고 있습니다. 적응하지 않으면 도태될 수밖에 없을 거예요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">앞으로 AI 검색 기술이 더욱 발전하고 확산됨에 따라, 콘텐츠 제작자들과 마케터들은 AI가 이해하고 활용할 수 있는 <b>고품질 콘텐츠 제작</b>에 더욱 집중해야 할 것입니다. 그리고 우리 사용자들은 AI가 제공하는 정보의 신뢰성을 비판적으로 검증하고, 다양한 출처를 통해 정보를 확인하는 능력을 기르는 것이 중요하다고 생각해요. 구글 AI 모드가 보여주는 검색의 미래, 이 거대한 변화에 적응하고 활용하는 능력이 바로 다가올 디지털 환경에서 성공하는 핵심 요소가 될 거라고 저는 감히 말씀드립니다. 정말 기대되지 않나요?</p>\n<div style=\"text-align: center; margin-top: 30px; font-size: 24px; color: #0f4c81;\">⁂</div>\n</div>",
        "contentSnippet": "30년 검색의 종말? 구글 AI 모드의 등장은 단순한 검색 기능 업그레이드를 넘어 검색 생태계와 AI 산업 전반에 근본적인 변화를 가져오고 있습니다. 2025년 한국에 정식 출시된 제미나이 2.5 기반의 이 혁신적인 도구가 어떻게 우리의 정보 탐색 방식을 바꾸고, 미래 검색의 방향을 제시하는지 자세히 알아봅니다.\n  구글 AI 모드, 도대체 무엇이 다르죠?\n\n\n음, 2025년 9월 한국에 정식 출시된 구글 AI 모드는 정말이지 기존 검색의 판도를 완전히 뒤집는다고 해도 과언이 아니에요. 단순히 몇몇 기능을 추가한 수준이 아니라, 검색 생태계와 AI 산업 전반에 걸쳐 근본적인 변화를 가져올 혁신적인 도구라고 저는 생각합니다. 제미나이 2.5 맞춤형 버전을 기반으로 하는 이 AI 모드는 사실 기존 AI Overview의 확장된 개념인데요, 가장 핵심적인 특징은 바로 '쿼리 팬-아웃(query fan-out)' 기술이 아닐까 싶어요.\n이 기술, 정말 대단하죠. 사용자가 복잡한 질문을 던지면 AI가 이를 여러 개의 하위 주제로 똑똑하게 분해합니다. 그리고는 각 주제에 대해 동시에 검색을 수행해서 종합적이고 아주 풍부한 답변을 척척 만들어내죠. 예를 들어, 저도 해봤는데, \"7세와 4세 아이 2명과 서울에서 1시간 거리로 주말에 함께 갈 수 있는 한적한 여행지\" 같은 복잡한 요청도 한 번에 깔끔하게 처리해주더라고요. 이런 경험은 기존 검색에서는 상상하기 어려웠던 부분이죠. 솔직히 말하면, 제가 겪어본 바로는 정말 혁신적이에요!\n멀티모달 검색 경험의 확장\n구글 AI 모드는 텍스트만 처리하는 것이 아니라, 음성과 이미지까지 지원하는 진정한 멀티모달 검색 경험을 제공합니다. 마이크 버튼 하나로 음성 질문을 하거나, 구글 렌즈와 연동해서 사진 한 장만으로도 복잡한 질문을 할 수 있어요. 얼마 전 해외여행에서 써봤는데, 식당 메뉴판을 사진으로 찍고 \"채식주의자가 먹을 수 있는 메뉴 알려줘\"라고 물으니, 번역은 물론이고 조건에 맞는 추천까지 해주더라고요. 정말이지 여행의 질이 달라지는 경험이었어요!\n딥 서치와 개인 맞춤형 기능으로 한 단계 더!\n여기서 끝이 아닙니다. AI 모드에서는 수백 건의 검색을 동시에 진행해서 전문가 수준의 완벽한 보고서를 단 몇 분 만에 생성하는 딥 서치(Deep Search) 기능도 제공해요. 저처럼 리서치를 많이 하는 사람들에게는 정말이지 빛과 소금 같은 기능이죠. 그리고 사용자의 동의하에 지메일 등 다른 구글 앱과 연동하여 개인 정보를 활용한 맞춤형 답변까지 제공하는데, 이건 정말 개인 비서가 생긴 기분이에요.\n\n\n\n  핵심 기술 요약: 구글 AI 모드는 제미나이 2.5 기반의 쿼리 팬-아웃 기술로 복잡한 질문을 세분화하여 동시에 검색합니다. 음성/이미지 인식 멀티모달 기능과 수백 건의 동시 검색을 통한 딥 서치 기능이 핵심입니다.\n⚙️ AI 모드, 실생활에서 어떻게 활용할까요?\n구글 AI 모드는 단순히 기술만 발전한 것이 아니라, 우리의 일상과 업무 여러 분야에서 엄청난 잠재력을 가지고 있어요. 제가 직접 써보고 느낀 점들과 함께 몇 가지 활용법을 소개해 드릴게요.\n비즈니스 및 마케팅 분야에서 똑똑하게!\n비즈니스 환경에서 AI 모드는 정말 유용합니다. \"B2B 스타트업을 위한 통합 마케팅 자동화 솔루션 추천해줘\"와 같은 질문을 던져보세요. AI는 이 질문을 'B2B 특화 기능', '스타트업 예산 대응', '마케팅 자동화 도구 비교', '통합 솔루션 장점' 등으로 아주 세분화하여 검색하고, 관련 정보를 깔끔하게 정리해줍니다. 마치 전문 컨설턴트가 짧은 시간 안에 핵심 보고서를 만들어주는 느낌이랄까요? 제가 전에 리서치하던 시간의 절반도 안 걸려서 놀랐어요.\n여행 및 생활 정보 검색도 문제없죠!\n복잡한 여행 계획 수립이나 일상생활 정보 검색에서도 AI 모드의 강점이 빛을 발합니다. \"내년 5월에 열리는 철인 3종 경기를 준비하려고 해. 훈련 시작 전에 알아야 할 점은 무엇이야?\" 같은 다층적인 질문에도 훈련 계획, 영양, 장비, 부상 예방 등 종합적인 답변을 제공해요. 저는 다음 주말 여행 계획을 AI 모드로 짜봤는데, 숙소부터 맛집, 아이들 체험 활동까지 정말 완벽하게 추천해주더라고요. 솔직히 감탄했습니다.\n학술 연구 및 교육 분야의 혁신\n학술 연구와 교육 분야에서도 AI 모드는 혁신적인 도구로 자리매김하고 있습니다. 이제는 이미지나 PDF 파일에 대한 질문 분석 기능이 데스크톱으로도 확장되어, 강의 슬라이드를 업로드하고 관련 질문을 하는 것이 가능해졌어요. 학생들은 복잡한 논문 내용을 빠르게 이해하고, 연구자들은 방대한 자료를 효율적으로 탐색할 수 있게 되는 거죠. 제가 학교 다닐 때 이런 기능이 있었다면 성적이 훨씬 좋았을 것 같아요. (웃음)\n콘텐츠 생성 및 최적화에도 탁월!\nAI 모드는 콘텐츠 마케터들에게도 강력한 도구가 됩니다. 예를 들어, \"네이버 블로그 상위노출 기사 10개의 제목을 분석하고, 이들 기사보다 상위노출이 가능한 최적의 블로그 제목을 생성해줘\"와 같은 요청을 통해 경쟁사 분석과 함께 SEO에 최적화된 제목을 손쉽게 얻을 수 있습니다. 이는 콘텐츠 기획 시간을 크게 단축시키고, 더욱 효과적인 마케팅 전략을 수립하는 데 도움을 줍니다.\n\n\n\n \n시의성 있는 정보 검색 및 기사 작성까지!\n최신 시사 이슈나 정책에 대한 정보가 필요할 때도 AI 모드를 활용할 수 있습니다. \"정부의 2025년 추석 민생 안정대책에 대한 신뢰할 수 있는 자료를 검색하고 블로그 기사를 생성해 (검색대상에 블로그를 제외해)\"와 같이 특정 조건을 지정하여 정보를 요청하면, AI가 신뢰도 높은 자료를 기반으로 관련 기사 초안을 작성해줍니다. 이를 통해 빠르고 정확하게 필요한 정보를 얻고, 생산적인 작업으로 이어갈 수 있습니다.\n\n\n\n \n⚔️ LLM 시장의 격전, 그리고 구글의 전략\n구글 AI 모드의 등장은 단순히 검색 기능의 변화를 넘어, 전체 AI 검색 시장의 경쟁을 더욱 치열하게 만들고 있어요. ChatGPT의 SearchGPT, Perplexity AI, Bing AI 등 각자의 강점을 내세우는 경쟁자들이 이미 많이 존재하거든요. 이런 상황에서 구글이 본격적으로 AI 검색 서비스를 도입했다는 건, 시장 판도에 상당한 변화를 가져올 것이라는 의미로 해석될 수 있죠. 제 생각에는 구글이 검색 시장의 주도권을 절대 놓치지 않겠다는 강력한 의지를 보여준 것 같아요.\n⚠️ 주목할 점: 일부 전문가들은 AI 검색이 기존 구글의 검색 점유율 33%를 빼앗아올 수 있다고 분석합니다. 라이너는 학술 검색, Perplexity는 미디어 종사자와 리서처 사이에서 인기를 얻고 있으며, ChatGPT는 LLM 이용자들의 검색 습관을 바꾸고 있어요. 구글도 마냥 안심할 수만은 없는 상황이죠.\nLLM 시장의 자연독점 가능성\n최근 AI 업계에서는 \"LLM 시장이 구글처럼 자연독점이 될 수 있다\"는 전망이 조심스럽게 제기되고 있습니다. 구글의 AI 모드 도입은 이러한 자연독점 구조를 더욱 공고히 할 가능성이 크다고 저는 봐요. 구글이 보유한 강력한 검색 인프라와 방대한 데이터, 그리고 제미나이 2.5 같은 최첨단 AI 모델을 결합하면 경쟁자들이 쉽게 따라잡기 어려운 격차를 만들어낼 수 있겠죠. 아, 그런데 이건 독점이라는 측면에서는 우려가 될 수도 있겠네요.\n\n\n플랫폼별 검색 경험의 분화\nLLM이 모든 앱에 검색 기능을 주입하면서, 이제 검색은 더 이상 Google.com에서만 시작되거나 끝나지 않게 되었습니다. Microsoft Excel에서 쿠키 레시피를 검색하거나, Meta AI를 통해 WhatsApp, Instagram, Facebook에서도 검색할 수 있게 되었으니 말이죠. 구글은 이제 ChatGPT뿐만 아니라 수천 개의 작은 AI 검색 엔진들과도 경쟁해야 하는 상황에 놓인 겁니다. 검색의 정의 자체가 확장되고 있다는 느낌이에요.\n  검색 엔진 생태계에 미치는 혁명적 영향\n구글 AI 모드의 도입은 정말이지 검색 생태계 전반에 혁명적인 변화를 가져오고 있다고 저는 확신합니다. 우리 모두의 검색 습관부터 웹사이트 트래픽, 그리고 SEO 전략까지, 모든 것이 바뀌고 있어요.\n검색 행동 패턴의 근본적 변화\nAI Overview가 출시된 이후, 사용자들은 기존 검색보다 2~3배 긴 질문을 하기 시작했어요. 이건 AI가 자연어를 정말 잘 이해할 수 있다는 신뢰가 형성되었기 때문입니다. 전체 검색의 약 20% 정도가 '롱테일 키워드'(요구 사항이 구체적인 긴 검색어)를 차지하는데, 이 비율은 계속 증가하는 추세예요. 이제 사람들은 \"CRM 추천\" 같은 짧은 키워드 대신 \"중소기업에서 사용하기 쉬운 클라우드 기반 CRM 솔루션을 추천해줘\"와 같이 더 자연스러운 문장으로 검색하게 된 거죠. 제가 생각하기에 이런 변화는 정보 탐색의 효율성을 극대화할 거예요.\n제로 클릭 검색 확산과 웹 트래픽의 변화\nAI Overview와 AI 모드의 도입으로 이제 제로 클릭 검색이 더욱 일반화되고 있습니다. 사용자들이 검색 결과에서 바로 답을 얻을 수 있으니, 웹사이트 클릭률(CTR)이 낮아지고 자연 검색 트래픽이 줄어들 가능성이 커졌어요. 최근 데이터에 따르면 전 세계 검색 트래픽이 15% 감소했다는 분석도 있는데, 이게 바로 AI 검색 기능 강화의 영향이라고 합니다. 콘텐츠 제작자들에게는 정말 중요한 변화죠.\nSEO 전략의 패러다임 전환\nAI 검색의 도입은 SEO 전략에 근본적인 변화를 요구하고 있습니다. 이제는 단순히 키워드 최적화를 넘어서, AI가 이해하고 종합할 수 있는 '정보의 질'과 '구조'가 훨씬 더 중요해졌어요. 기업들은 키워드를 통한 검색 최적화에만 매달릴 것이 아니라, AI의 분석 능력을 활용하여 소비자의 실제 요구와 행동 패턴에 맞춘 고품질 콘텐츠 제공에 집중해야 합니다. 이건 마치 새로운 게임의 규칙을 배우는 것과 같아요. 쉬운 일은 아니지만, 반드시 적응해야 합니다.\n\n\n검색 결과의 투명성과 신뢰도 향상\n구글은 AI 모드의 투명성을 높이기 위해 Search Console에 AI 모드에서의 클릭, 노출, 순위 데이터를 통합했어요. 이를 통해 게시자와 사이트 소유자들이 AI 모드가 검색 결과에 미치는 영향을 더 정확하게 파악할 수 있게 되었죠. 게다가 AI 모드는 구글의 기존 품질 및 순위 시스템을 기반으로 작동하며, 신뢰도가 낮을 경우 기존 웹 검색 결과를 그대로 보여주는 보완 장치까지 마련했습니다. AI 답변의 품질이나 유용성에 대한 신뢰도가 충분히 높지 않다면 웹 링크를 제공하여 사용자가 직접 검증할 수 있도록 지원하는 점도 아주 긍정적인 부분이라고 생각해요.\n  핵심 요약\n구글 AI 모드는 제미나이 2.5 기반의 '쿼리 팬-아웃' 기술로 복잡한 질문을 세분화하여 동시 처리, 기존 검색의 한계를 뛰어넘습니다.\n멀티모달 검색 (음성, 이미지) 및 딥 서치 기능으로 개인 맞춤형, 전문가 수준의 정보를 제공하며 활용 범위를 넓히고 있습니다.\nAI 검색 시장의 경쟁 심화와 LLM 시장의 자연독점 가능성 속에서, 구글은 강력한 인프라로 주도권을 유지하려 합니다.\n제로 클릭 검색 확산, 웹 트래픽 변화, 그리고 '정보의 질'과 '구조' 중심의 SEO 전략 패러다임 전환이 필수적입니다.\n* 미래 검색 환경에 대한 적응과 활용이 중요합니다.\n❓ 자주 묻는 질문 (FAQ)\nQ1: 구글 AI 모드는 기존 검색과 무엇이 다른가요?\nA1: 구글 AI 모드는 제미나이 2.5 기반의 '쿼리 팬-아웃' 기술을 활용하여 사용자의 복잡한 질문을 여러 하위 주제로 분해, 동시에 검색하고 종합적인 답변을 제공합니다. 이는 기존 검색 엔진이 개별 링크를 나열하는 방식과는 근본적으로 다른, 개인 맞춤형 '답변' 중심의 경험을 선사합니다.\nQ2: AI 모드의 등장으로 SEO 전략은 어떻게 바뀌어야 할까요?\nA2: AI 모드 시대에는 단순한 키워드 최적화를 넘어, AI가 이해하고 종합할 수 있는 '정보의 질'과 '구조'가 가장 중요해집니다. 사용자 질문에 대한 포괄적이고 신뢰성 높은 답변을 제공하며, AI가 콘텐츠를 쉽게 분석하고 활용할 수 있도록 명확하게 구조화된 콘텐츠 제작이 필수적입니다.\nQ3: AI 모드가 웹사이트 트래픽에 미치는 영향은 무엇인가요?\nA3: AI 모드의 도입으로 '제로 클릭 검색'이 확산될 수 있습니다. AI가 검색 결과에서 바로 종합적인 답변을 제공하기 때문에, 사용자들이 웹사이트를 직접 클릭할 필요가 줄어들어 자연 검색 트래픽이 감소할 가능성이 있습니다. 이는 콘텐츠 제작자들이 단순히 클릭 유도를 넘어 정보 가치 자체에 집중해야 함을 의미합니다.\nQ4: 구글 AI 모드의 미래는 어떻게 전망되나요?\nA4: 구글은 AI 모드를 지속적으로 개선하고 기능을 확장할 계획입니다. 단순한 검색 도구를 넘어 캔버스 기능, 검색 라이브, 개인 맞춤형 차트 및 그래프 생성 등 종합적인 정보 분석 및 생성 플랫폼으로 발전할 것입니다. 궁극적으로는 인덱스 중심의 검색 엔진에서 사용자 의도에 응답하는 '답변 엔진'으로의 전환을 가속화할 것으로 예상됩니다.\n마무리하며: 검색 생태계의 새로운 시대\n구글 AI 모드의 등장은 단순히 기술적 진보를 넘어, 30년간 지속되어온 전통적인 검색 방식의 패러다임을 완전히 바꾸는 중요한 이정표라고 생각합니다. AI 기반의 대화형 검색으로 진화하면서 사용자들은 훨씬 더 자연스럽고 효율적인 정보 탐색 경험을 얻게 될 것이 분명해요.\n물론 이러한 변화는 다른 LLM 서비스들과의 경쟁을 더욱 치열하게 만들고 있으며, 각 플랫폼이 고유한 강점을 내세워 시장에서 경쟁하는 상황을 만들어내고 있죠. 동시에 검색 엔진 시장에서는 SEO 전략의 근본적 변화, 제로 클릭 검색의 확산, 그리고 웹 트래픽 패턴의 변화 등 다양한 영향이 나타나고 있습니다. 적응하지 않으면 도태될 수밖에 없을 거예요.\n앞으로 AI 검색 기술이 더욱 발전하고 확산됨에 따라, 콘텐츠 제작자들과 마케터들은 AI가 이해하고 활용할 수 있는 고품질 콘텐츠 제작에 더욱 집중해야 할 것입니다. 그리고 우리 사용자들은 AI가 제공하는 정보의 신뢰성을 비판적으로 검증하고, 다양한 출처를 통해 정보를 확인하는 능력을 기르는 것이 중요하다고 생각해요. 구글 AI 모드가 보여주는 검색의 미래, 이 거대한 변화에 적응하고 활용하는 능력이 바로 다가올 디지털 환경에서 성공하는 핵심 요소가 될 거라고 저는 감히 말씀드립니다. 정말 기대되지 않나요?\n⁂",
        "guid": "http://muzbox.tistory.com/483657",
        "categories": [
          "AI, 미래기술/AI 인사이트",
          "ai 검색",
          "LLM 시장 경쟁",
          "seo 전략 변화",
          "검색 생태계 변화",
          "구글 AI 모드",
          "답변 엔진",
          "멀티모달 검색",
          "제로 클릭 검색",
          "제미나이 2.5",
          "쿼리 팬-아웃"
        ],
        "isoDate": "2025-09-16T06:35:50.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "나노바나나 168개 프롬프트 모음 앱 무료 공개",
        "link": "http://muzbox.tistory.com/483656",
        "pubDate": "Sun, 14 Sep 2025 12:20:32 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483656#entry483656comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #3c4043;\">\n<div style=\"background-color: #e8f4fd; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">AI 이미지 생성에 혁신을 가져올 나노바나나 168종 프롬프트 모음 앱이 무료로 공개됩니다. 복잡한 프롬프트 작성에 어려움을 겪으셨던 분들을 위해, 구글 Gemini 2.5 Flash Image 모델의 강력한 기능을 100% 활용할 수 있도록 엄선된 프롬프트들을 하나의 웹앱에 담았습니다. 이제 클릭 몇 번으로 원하는 이미지를 손쉽게 만들어 보세요!</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  나노바나나 168종 프롬프트 앱, 드디어 무료 공개!</b></h2>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/eaqrUn/btsQxCup6SB/WzS6bYsHyU17ld2jjHCQMK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/eaqrUn/btsQxCup6SB/WzS6bYsHyU17ld2jjHCQMK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/eaqrUn/btsQxCup6SB/WzS6bYsHyU17ld2jjHCQMK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FeaqrUn%2FbtsQxCup6SB%2FWzS6bYsHyU17ld2jjHCQMK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"나노바나나 168종 AI 프롬프트 모음 웹앱 인터페이스. 다양한 이미지 생성 예시와 창의적인 AI 도구를 보여주는 파란색 테마의 디지털 화면.\" loading=\"lazy\" width=\"600\" height=\"600\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">드디어 나노바나나 168종 프롬프트 앱이 무료로 공개됩니다. 이 앱은 AI 이미지 생성에 새로운 가능성을 열어줄 혁신적인 도구입니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이제 <b>'나노바나나 프롬프트 쇼케이스 (Nano Banana Prompt Showcase)'</b>을 통해 드로잉을 현실로 바꾸고, 사진 하나로 멋진 패션 무드 콜라주를 만들며, 프롬프트만으로 미니어처까지 구현하는 놀라운 경험을 무료로 직접 해보실 수 있습니다.</p>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>잠깐! '나노바나나'가 무엇인가요?</b><br />나노바나나는 구글 Gemini 2.5 Flash Image 모델의 커뮤니티 별명이에요. 이 혁신적인 AI 모델은 캐릭터 일관성 유지, 다중 이미지 합성, 정확한 텍스트 표현 같은 놀라운 기능들을 자랑합니다. 오래된 사진 복원, 이미지 속 물체 제거, 여러 이미지를 자연스럽게 합성하는 등 정말 다양한 작업이 가능해서 많은 크리에이터들이 주목하고 있죠.</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">분명 AI 이미지 생성이나 편집할 때 어떤 프롬프트를 써야 할지 막막했던 경험, 한 번쯤 있으실 거예요. 복잡한 프롬프트 작성에 시간을 허비하거나, 원하는 결과물을 얻기 위해 수없이 시도하며 좌절했던 순간들... 이제 걱정 마세요! 이 앱 하나면 여러분의 그런 고민을 시원하게 해결해 드릴 수 있을 거라고 확신합니다.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  <b>나노바나나 프롬프트 쇼케이스</b> 왜 지금 필요할까요?</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">현재 많은 분들이 나노바나나 프롬프트를 활용하기 위해 전문가들이 공유한 웹사이트를 직접 방문하고, 마음에 드는 프롬프트를 일일이 복사해서 Gemini나 AI STUDIO 같은 툴에 붙여넣어 실행하는 번거로운 과정을 거치고 계실 거예요. 이런 수작업은 시간이 많이 들 뿐만 아니라, 168개나 되는 프롬프트를 모두 효율적으로 관리하기란 여간 어려운 일이 아니죠.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">그래서 저는 이런 불편함을 완전히 해소하고 싶었습니다. <b>168개의 프롬프트를 단 하나의 웹앱에서 한눈에 보고, 클릭 몇 번으로 원하는 기법을 선택해서 바로 테스트해볼 수 있는 혁신적인 도구</b>, 바로 '나노바나나 쇼케이스 앱'을 개발하게 된 배경입니다. 이 앱을 통해 여러분의 AI 이미지 작업이 훨씬 더 빠르고, 편리하고, 즐거워질 거라 기대해요.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b> ️ <b>나노바나나 프롬프트 쇼케이스</b> , 개발 과정 엿보기</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 앱이 탄생하기까지 어떤 과정들을 거쳤는지 궁금하지 않으신가요? 제 생각엔, 이러한 개발 과정이 여러분이 직접 AI 앱을 만들 때도 좋은 참고가 될 수 있을 것 같아요. 몇 단계를 거쳐 이 편리한 앱이 완성되었는지 함께 살펴보시죠!</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; border-left: 5px solid #1a73e8; padding-left: 10px;\" data-ke-size=\"size23\"><b>1단계: 핵심 재료, 프롬프트 데이터 준비</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">모든 요리에 좋은 재료가 필요하듯, 앱 개발의 첫걸음은 바로 '핵심 재료'인 프롬프트 모음을 준비하는 것이었어요. 전 세계 전문가들이 나노바나나를 활용해 만든 결과물과 프롬프트가 공유된 깃허브(GitHub) 저장소에서 이 귀중한 데이터들을 수집했습니다. 각 케이스별로 어떤 결과물이 나오는지, 그리고 어떤 프롬프트가 사용되었는지 꼼꼼하게 확인하는 과정이 필요했죠.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">특히, 데이터를 효과적으로 사용하려면 그 구조를 미리 파악하는 게 중요합니다. 케이스 제목, 만든이 정보, 상세 설명, 그리고 핵심 프롬프트가 어떻게 구성되어 있는지 분석하는 데 시간을 들였어요. 이렇게 정리된 데이터가 앱의 뼈대가 되었습니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; border-left: 5px solid #1a73e8; padding-left: 10px;\" data-ke-size=\"size23\"><b>2단계: UI/UX 디자인, 스케치부터 시작!</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">요즘 LLM(거대 언어 모델)들은 멀티모달 기능을 기본적으로 지원하는 경우가 많잖아요? 그래서 저는 그림판으로 앱의 UI를 대략적으로 스케치해서 업로드하는 방식을 택했습니다. 인터페이스 디자인을 직접 그리는 것만으로도 LLM이 이를 기반으로 앱을 만들어 줄 수 있다는 점이 정말 놀라웠어요!</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">저는 화면을 크게 세 부분으로 나누었어요. 왼쪽에는 <b>CASE 목록</b>을, 중앙에는 이미지를 편집하는 <b>작업 목록</b>을, 그리고 오른쪽에는 <b>결과물</b>을 출력하도록 말이죠. 이렇게 작업 프로세스의 순서대로 한 화면에 구성하면 사용자가 훨씬 직관적으로 앱을 사용할 수 있습니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/uI13Q/btsQzzcqivZ/pitKKJA0GPMRkhhnNKN7qK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/uI13Q/btsQzzcqivZ/pitKKJA0GPMRkhhnNKN7qK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/uI13Q/btsQzzcqivZ/pitKKJA0GPMRkhhnNKN7qK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FuI13Q%2FbtsQzzcqivZ%2FpitKKJA0GPMRkhhnNKN7qK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"AI 앱 개발의 초기 UI/UX 디자인 스케치. 3단계 패널 구성의 웹 인터페이스 와이어프레임.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; border-left: 5px solid #1a73e8; padding-left: 10px;\" data-ke-size=\"size23\"><b>3단계: 성공적인 앱 개발을 위한 사전 고려사항</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">본격적인 앱 개발에 앞서 몇 가지 중요한 고려사항을 정리했습니다. 이 과정을 거치면 처음 시도하는 작업에서도 비교적 원하는 결과물을 얻을 확률이 높아져요.</p>\n<ul style=\"list-style-type: disc; margin-left: 20px; margin-bottom: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px;\"><b><span style=\"color: #1a73e8;\">한글 앱 지원</span></b>: 사용자 편의성을 위해 당연히 한글로 앱이 구동되어야 했습니다.</li>\n<li style=\"margin-bottom: 10px;\"><b><span style=\"color: #1a73e8;\">카테고리 분류</span></b>: 168개나 되는 CASE를 무작정 나열하면 사용성이 떨어질 테니, 카테고리별 분류가 필수였죠.</li>\n<li style=\"margin-bottom: 10px;\"><b><span style=\"color: #1a73e8;\">컨텍스트 용량 고려</span></b>: AI 코딩 시 컨텍스트 용량은 아주 중요한데요. 168개 CASE의 제목과 프롬프트가 모두 하나의 파일에 들어가면 에러가 발생하거나 수정이 어려울 수 있습니다. 이를 분할하는 전략이 필요했어요.</li>\n<li style=\"margin-bottom: 10px;\"><b><span style=\"color: #1a73e8;\">원문 프롬프트 유지</span></b>: 한글 앱이지만, AI 이미지 생성의 최적 결과물을 위해서는 프롬프트는 원문 그대로 영어로 유지해야 한다는 점을 인지했습니다.</li>\n</ul>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; border-left: 5px solid #1a73e8; padding-left: 10px;\" data-ke-size=\"size23\"><b>4단계: AI Studio 앱빌더와 함께하는 구현 과정</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이제 그림판 스케치와 정리된 데이터를 가지고 AI Studio 앱빌더로 향했습니다. 미리 그려둔 UI 이미지를 업로드하고, 프롬프트 데이터가 담긴 `README.md` 파일을 `txt` 확장자로 변경하여 함께 올렸어요. 그리고 대화창에 <b>\"2개 문서에 있는 CASE 별 프롬프트를 이용한 나노바나나를 활용한 이미지 생성 편집 한글 앱\"</b>이라고 입력하며, 앞서 메모장에 정리한 요청사항들을 상세히 덧붙여 앱 생성을 요청했습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">처음 앱이 생성되었을 때는 아쉬움이 좀 있었어요. 왼쪽 CASE 목록에 168개보다 훨씬 적은 수의 케이스만 보였거든요. 하지만 걱정 마세요! AI와의 대화는 계속됩니다. 저는 곧바로 <b>\"2개 파일에 총 168개의 CASE가 있어. 누락되는 CASE 없이 모두 적용해. CASE가 너무 많아 소스 DATA도 카테고리별로 생성해\"</b>라고 다시 요청했습니다. 잠시 후, 모든 CASE가 완벽하게 적용된 것을 확인했고, '일러스트를 피규어로' 같은 기능을 테스트해보니 동작도 제대로 하는 것을 알 수 있었습니다. 아, 정말 뿌듯하더라고요!</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✨ 사용자 경험을 극대화하는 앱 기능 업그레이드</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">앱이 기본적인 형태를 갖추었으니, 이제 사용자 경험을 한층 더 끌어올릴 시간이었어요. 몇 가지 핵심 기능을 추가하고 개선하는 과정을 거쳤습니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/1QRN3/btsQwOP0RJ5/9IH8AL9APaj0pALNrHzcD1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/1QRN3/btsQwOP0RJ5/9IH8AL9APaj0pALNrHzcD1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/1QRN3/btsQwOP0RJ5/9IH8AL9APaj0pALNrHzcD1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F1QRN3%2FbtsQwOP0RJ5%2F9IH8AL9APaj0pALNrHzcD1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"168개 AI 프롬프트 데이터를 효율적으로 분류하고 관리하는 개발 과정의 시각화.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; border-left: 5px solid #1a73e8; padding-left: 10px;\" data-ke-size=\"size23\"><b>1단계: 결과물 확대 및 다운로드 기능 추가</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">처음에는 생성된 이미지가 너무 작아서 불편하다는 생각이 들었어요. 그래서 <b>\"결과물을 클릭하면 확대하고 다운로드 버튼을 추가해\"</b>라고 요청했습니다. 놀랍게도 클릭 시 이미지가 확대되고, 한 번의 클릭으로 이미지를 저장할 수 있는 다운로드 버튼까지 완벽하게 추가되었습니다. 사소하지만 정말 편리한 기능이죠!</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; border-left: 5px solid #1a73e8; padding-left: 10px;\" data-ke-size=\"size23\"><b>2단계: 카테고리 시각화 및 넘버링으로 가독성 향상</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">168개의 프롬프트는 결코 적은 수가 아니잖아요? CASE 목록의 카테고리 명이 눈에 잘 띄지 않아 불편할 수 있겠다는 생각이 들었어요. <b>\"카테고리명을 눈에 더 잘 띄게 버튼 형태로 변경해\"</b>라는 요청과 함께, <b>\"CASE에 넘버를 추가해\"</b>라고 요청했습니다. 덕분에 이제 원하는 프롬프트를 훨씬 빠르고 쉽게 찾을 수 있게 되었습니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; border-left: 5px solid #1a73e8; padding-left: 10px;\" data-ke-size=\"size23\"><b>3단계: AI 프롬프트 제안 기능으로 창작의 날개를 달다!</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 앱의 가장 강력한 기능 중 하나가 바로 <b>'AI 프롬프트 제안'</b> 기능이라고 생각해요. 기존 프롬프트만 사용하는 것을 넘어, 사용자가 업로드하는 이미지와 추가 요청사항에 맞춰 AI가 개선된 프롬프트를 제안해주도록 요청했습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">예를 들어, CASE 6번 '캐릭터 디자인'으로 테스트해봤어요. 기본 프롬프트는 입력한 이미지를 다양한 포즈의 디자인 시트로 만들어주는 것인데, 여기에 '교복 대신 체육복'이라는 추가 입력을 하고 AI에게 프롬프트를 제안받아 실행해보니, 와! 이미지에 체육복이 제대로 적용되는 것을 확인할 수 있었습니다. 이건 정말 창작의 가능성을 무한히 넓혀주는 기능이라고 할 수 있죠!</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; border-left: 5px solid #1a73e8; padding-left: 10px;\" data-ke-size=\"size23\"><b>4단계: 최종 마무리! 패널 조절 및 웹페이지 링크</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">마지막으로, 사용자의 편의를 위해 메인 3개 패널의 폭을 자유롭게 조절할 수 있도록 했어요. 그리고 각 CASE별 실제 사용법을 자세히 볼 수 있도록 해당 웹페이지의 링크까지 추가하여 앱을 완벽하게 마무리했습니다. 이 작은 디테일들이 모여 사용자에게 큰 만족감을 줄 거라고 믿어요.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1915\" data-origin-height=\"1079\"><span data-url=\"https://blog.kakaocdn.net/dn/2dPG7/btsQxtdLcA3/2BWkPlblg1XKOzE9R3DDh0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/2dPG7/btsQxtdLcA3/2BWkPlblg1XKOzE9R3DDh0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/2dPG7/btsQxtdLcA3/2BWkPlblg1XKOzE9R3DDh0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F2dPG7%2FbtsQxtdLcA3%2F2BWkPlblg1XKOzE9R3DDh0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"완성된 나노바나나 프롬프트 쇼케이스\" loading=\"lazy\" width=\"1915\" height=\"1079\" data-origin-width=\"1915\" data-origin-height=\"1079\"/></span></figure>\n\n<div style=\"background-color: #f8f9fa; border: 1px solid #dadce0; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); padding: 25px; margin: 40px 0;\">\n<div style=\"font-size: 26px; color: #1a73e8; border-bottom: 2px solid #1a73e8; padding-bottom: 10px; margin-bottom: 20px; font-weight: bold;\">  핵심 요약</div>\n<ul style=\"list-style-type: none; padding: 0; margin: 0;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px; font-size: 17px;\">✔ <b>나노바나나 168종 프롬프트 앱 무료 공개</b>: AI 이미지 작업을 위한 필수 도구!</li>\n<li style=\"margin-bottom: 10px; font-size: 17px;\">✔ <b>Gemini 2.5 Flash Image 모델 완벽 활용</b>: 혁신적인 AI 이미지 생성 및 편집 가능.</li>\n<li style=\"margin-bottom: 10px; font-size: 17px;\">✔ <b>직관적인 웹앱 인터페이스</b>: 168개 프롬프트를 한눈에, 클릭 한 번으로 실행.</li>\n<li style=\"margin-bottom: 0px; font-size: 17px;\">✔ <b>AI 프롬프트 제안 기능</b>: 사용자의 요청과 이미지를 기반으로 최적화된 프롬프트 자동 생성.</li>\n</ul>\n<div style=\"font-size: 14px; color: #5f6368; margin-top: 20px; padding-top: 15px; border-top: 1px dashed #dadce0;\">이 앱은 AI 이미지 작업의 효율성을 극대화하고 창작의 재미를 더해줄 것입니다. 지금 바로 경험해보세요!</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<div style=\"background-color: #f8f9fa; padding: 15px; border-bottom: 1px solid #dadce0; margin-bottom: 10px; border-radius: 8px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin: 0 0 10px;\" data-ke-size=\"size23\">Q1: 나노바나나 168종 프롬프트 앱은 어떻게 사용할 수 있나요?</h3>\n<p style=\"margin-bottom: 0px; color: #3c4043;\" data-ke-size=\"size16\">A1: 앱은 웹 기반으로 제공되며, 별도의 설치 없이 인터넷 브라우저를 통해 접속할 수 있습니다. 각 섹션에 설명된 개발 과정을 통해 앱의 주요 기능과 사용법을 익히실 수 있습니다. 링크는 블로그 포스트 하단에서 확인하실 수 있습니다.</p>\n</div>\n<div style=\"background-color: #f8f9fa; padding: 15px; border-bottom: 1px solid #dadce0; margin-bottom: 10px; border-radius: 8px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin: 0 0 10px;\" data-ke-size=\"size23\">Q2: AI 프롬프트 제안 기능은 어떤 식으로 작동하나요?</h3>\n<p style=\"margin-bottom: 0px; color: #3c4043;\" data-ke-size=\"size16\">A2: 이 기능은 사용자가 업로드하는 이미지와 텍스트로 추가하는 요청사항을 분석하여, 기존 프롬프트를 더욱 개선하거나 사용자 의도에 맞는 새로운 프롬프트를 생성해줍니다. 이를 통해 더 정교하고 독창적인 결과물을 얻을 수 있습니다.</p>\n</div>\n<div style=\"background-color: #f8f9fa; padding: 15px; border-radius: 8px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin: 0 0 10px;\" data-ke-size=\"size23\">Q3: 앱이 무료로 제공되는데, 기능 제한은 없나요?</h3>\n<p style=\"margin-bottom: 0px; color: #3c4043;\" data-ke-size=\"size16\">A3: 네, 현재 공개된 나노바나나 168종 프롬프트 앱은 모든 기능을 제한 없이 무료로 제공됩니다. 이 앱을 통해 여러분이 부담 없이 AI 이미지 생성의 즐거움을 만끽하시길 바랍니다.</p>\n</div>\n<script type=\"application/ld+json\">{\"@context\": \"https://schema.org\",\"@type\": \"FAQPage\",\"mainEntity\": [{\"@type\": \"Question\",\"name\": \"나노바나나 168종 프롬프트 앱은 어떻게 사용할 수 있나요?\",\"acceptedAnswer\": {\"@type\": \"Answer\",\"text\": \"앱은 웹 기반으로 제공되며, 별도의 설치 없이 인터넷 브라우저를 통해 접속할 수 있습니다. 각 섹션에 설명된 개발 과정을 통해 앱의 주요 기능과 사용법을 익히실 수 있습니다. 링크는 블로그 포스트 하단에서 확인하실 수 있습니다.\"}},{\"@type\": \"Question\",\"name\": \"AI 프롬프트 제안 기능은 어떤 식으로 작동하나요?\",\"acceptedAnswer\": {\"@type\": \"Answer\",\"text\": \"이 기능은 사용자가 업로드하는 이미지와 텍스트로 추가하는 요청사항을 분석하여, 기존 프롬프트를 더욱 개선하거나 사용자 의도에 맞는 새로운 프롬프트를 생성해줍니다. 이를 통해 더 정교하고 독창적인 결과물을 얻을 수 있습니다.\"}},{\"@type\": \"Question\",\"name\": \"앱이 무료로 제공되는데, 기능 제한은 없나요?\",\"acceptedAnswer\": {\"type\": \"Answer\",\"text\": \"네, 현재 공개된 나노바나나 168종 프롬프트 앱은 모든 기능을 제한 없이 무료로 제공됩니다. 이 앱을 통해 여러분이 부담 없이 AI 이미지 생성의 즐거움을 만끽하시길 바랍니다.\"}}]} </script>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>마무리하며: 새로운 창작의 문을 열다!</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이렇게 해서 많은 분들의 기대를 모았던 <b>'나노바나나 168종 프롬프트 모음 앱'</b>이 드디어 완성되었습니다! 이 앱은 단순히 프롬프트를 모아놓은 것을 넘어, AI Studio 앱빌더를 활용하여 개발 과정에서 겪었던 시행착오와 해결 과정까지 담은, 저에게는 참 의미 있는 결과물이에요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">AI 이미지 생성과 편집이 이렇게 쉽고 강력해질 수 있다는 사실에 저 스스로도 다시 한번 놀라곤 합니다. 여러분의 소중한 시간과 노력을 아껴주고, 동시에 창작의 영감을 불어넣어 줄 이 앱을 <b>지금 바로 무료로 경험해보세요!</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">앱 링크는 아래에서 확인하실 수 있습니다. 많은 관심과 활용 부탁드리며, 여러분의 멋진 AI 작품들을 기대하겠습니다!</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>나노바나나 프롬프트 쇼케이스 바로가기</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><a href=\"https://ai.studio/apps/drive/1aRW7y-kpscwD7QKyVQfP8Mf6vyuNjtSm\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://ai.studio/apps/drive/1aRW7y-kpscwD7QKyVQfP8Mf6vyuNjtSm</a></p>\n<figure id=\"og_1757819842914\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"로그인 - Google 계정\" data-og-description=\"이메일 또는 휴대전화\" data-og-host=\"accounts.google.com\" data-og-source-url=\"https://ai.studio/apps/drive/1aRW7y-kpscwD7QKyVQfP8Mf6vyuNjtSm\" data-og-url=\"https://accounts.google.com/v3/signin/identifier?continue=https%3A%2F%2Faistudio.google.com%2Fapps%2Fdrive%2F1aRW7y-kpscwD7QKyVQfP8Mf6vyuNjtSm&amp;followup=https%3A%2F%2Faistudio.google.com%2Fapps%2Fdrive%2F1aRW7y-kpscwD7QKyVQfP8Mf6vyuNjtSm&amp;ifkv=AfYwgwXtBIoUMHm1GhpmqeE-UE7wH2L3P2gbPBxQkTK3C2iATDWFM47JOZsOFdN5HvnYcgjLfUT_pQ&amp;passive=1209600&amp;flowName=WebLiteSignIn&amp;flowEntry=ServiceLogin&amp;dsh=S-1794595551%3A1757819836546085\" data-og-image=\"\"><a href=\"https://ai.studio/apps/drive/1aRW7y-kpscwD7QKyVQfP8Mf6vyuNjtSm\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://ai.studio/apps/drive/1aRW7y-kpscwD7QKyVQfP8Mf6vyuNjtSm\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">로그인 - Google 계정</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">이메일 또는 휴대전화</p>\n<p class=\"og-host\" data-ke-size=\"size16\">accounts.google.com</p>\n</div>\n</a></figure>\n  <iframe src=\"https://www.youtube.com/embed/N5ViDUlBYxY\" width=\"854\" height=\"480\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n</div>",
        "contentSnippet": "AI 이미지 생성에 혁신을 가져올 나노바나나 168종 프롬프트 모음 앱이 무료로 공개됩니다. 복잡한 프롬프트 작성에 어려움을 겪으셨던 분들을 위해, 구글 Gemini 2.5 Flash Image 모델의 강력한 기능을 100% 활용할 수 있도록 엄선된 프롬프트들을 하나의 웹앱에 담았습니다. 이제 클릭 몇 번으로 원하는 이미지를 손쉽게 만들어 보세요!\n  나노바나나 168종 프롬프트 앱, 드디어 무료 공개!\n\n\n드디어 나노바나나 168종 프롬프트 앱이 무료로 공개됩니다. 이 앱은 AI 이미지 생성에 새로운 가능성을 열어줄 혁신적인 도구입니다.\n이제 '나노바나나 프롬프트 쇼케이스 (Nano Banana Prompt Showcase)'을 통해 드로잉을 현실로 바꾸고, 사진 하나로 멋진 패션 무드 콜라주를 만들며, 프롬프트만으로 미니어처까지 구현하는 놀라운 경험을 무료로 직접 해보실 수 있습니다.\n  잠깐! '나노바나나'가 무엇인가요?\n나노바나나는 구글 Gemini 2.5 Flash Image 모델의 커뮤니티 별명이에요. 이 혁신적인 AI 모델은 캐릭터 일관성 유지, 다중 이미지 합성, 정확한 텍스트 표현 같은 놀라운 기능들을 자랑합니다. 오래된 사진 복원, 이미지 속 물체 제거, 여러 이미지를 자연스럽게 합성하는 등 정말 다양한 작업이 가능해서 많은 크리에이터들이 주목하고 있죠.\n분명 AI 이미지 생성이나 편집할 때 어떤 프롬프트를 써야 할지 막막했던 경험, 한 번쯤 있으실 거예요. 복잡한 프롬프트 작성에 시간을 허비하거나, 원하는 결과물을 얻기 위해 수없이 시도하며 좌절했던 순간들... 이제 걱정 마세요! 이 앱 하나면 여러분의 그런 고민을 시원하게 해결해 드릴 수 있을 거라고 확신합니다.\n  나노바나나 프롬프트 쇼케이스 왜 지금 필요할까요?\n현재 많은 분들이 나노바나나 프롬프트를 활용하기 위해 전문가들이 공유한 웹사이트를 직접 방문하고, 마음에 드는 프롬프트를 일일이 복사해서 Gemini나 AI STUDIO 같은 툴에 붙여넣어 실행하는 번거로운 과정을 거치고 계실 거예요. 이런 수작업은 시간이 많이 들 뿐만 아니라, 168개나 되는 프롬프트를 모두 효율적으로 관리하기란 여간 어려운 일이 아니죠.\n그래서 저는 이런 불편함을 완전히 해소하고 싶었습니다. 168개의 프롬프트를 단 하나의 웹앱에서 한눈에 보고, 클릭 몇 번으로 원하는 기법을 선택해서 바로 테스트해볼 수 있는 혁신적인 도구, 바로 '나노바나나 쇼케이스 앱'을 개발하게 된 배경입니다. 이 앱을 통해 여러분의 AI 이미지 작업이 훨씬 더 빠르고, 편리하고, 즐거워질 거라 기대해요.\n ️ 나노바나나 프롬프트 쇼케이스 , 개발 과정 엿보기\n이 앱이 탄생하기까지 어떤 과정들을 거쳤는지 궁금하지 않으신가요? 제 생각엔, 이러한 개발 과정이 여러분이 직접 AI 앱을 만들 때도 좋은 참고가 될 수 있을 것 같아요. 몇 단계를 거쳐 이 편리한 앱이 완성되었는지 함께 살펴보시죠!\n1단계: 핵심 재료, 프롬프트 데이터 준비\n모든 요리에 좋은 재료가 필요하듯, 앱 개발의 첫걸음은 바로 '핵심 재료'인 프롬프트 모음을 준비하는 것이었어요. 전 세계 전문가들이 나노바나나를 활용해 만든 결과물과 프롬프트가 공유된 깃허브(GitHub) 저장소에서 이 귀중한 데이터들을 수집했습니다. 각 케이스별로 어떤 결과물이 나오는지, 그리고 어떤 프롬프트가 사용되었는지 꼼꼼하게 확인하는 과정이 필요했죠.\n특히, 데이터를 효과적으로 사용하려면 그 구조를 미리 파악하는 게 중요합니다. 케이스 제목, 만든이 정보, 상세 설명, 그리고 핵심 프롬프트가 어떻게 구성되어 있는지 분석하는 데 시간을 들였어요. 이렇게 정리된 데이터가 앱의 뼈대가 되었습니다.\n2단계: UI/UX 디자인, 스케치부터 시작!\n요즘 LLM(거대 언어 모델)들은 멀티모달 기능을 기본적으로 지원하는 경우가 많잖아요? 그래서 저는 그림판으로 앱의 UI를 대략적으로 스케치해서 업로드하는 방식을 택했습니다. 인터페이스 디자인을 직접 그리는 것만으로도 LLM이 이를 기반으로 앱을 만들어 줄 수 있다는 점이 정말 놀라웠어요!\n저는 화면을 크게 세 부분으로 나누었어요. 왼쪽에는 CASE 목록을, 중앙에는 이미지를 편집하는 작업 목록을, 그리고 오른쪽에는 결과물을 출력하도록 말이죠. 이렇게 작업 프로세스의 순서대로 한 화면에 구성하면 사용자가 훨씬 직관적으로 앱을 사용할 수 있습니다.\n\n\n3단계: 성공적인 앱 개발을 위한 사전 고려사항\n본격적인 앱 개발에 앞서 몇 가지 중요한 고려사항을 정리했습니다. 이 과정을 거치면 처음 시도하는 작업에서도 비교적 원하는 결과물을 얻을 확률이 높아져요.\n한글 앱 지원: 사용자 편의성을 위해 당연히 한글로 앱이 구동되어야 했습니다.\n카테고리 분류: 168개나 되는 CASE를 무작정 나열하면 사용성이 떨어질 테니, 카테고리별 분류가 필수였죠.\n컨텍스트 용량 고려: AI 코딩 시 컨텍스트 용량은 아주 중요한데요. 168개 CASE의 제목과 프롬프트가 모두 하나의 파일에 들어가면 에러가 발생하거나 수정이 어려울 수 있습니다. 이를 분할하는 전략이 필요했어요.\n원문 프롬프트 유지: 한글 앱이지만, AI 이미지 생성의 최적 결과물을 위해서는 프롬프트는 원문 그대로 영어로 유지해야 한다는 점을 인지했습니다.\n4단계: AI Studio 앱빌더와 함께하는 구현 과정\n이제 그림판 스케치와 정리된 데이터를 가지고 AI Studio 앱빌더로 향했습니다. 미리 그려둔 UI 이미지를 업로드하고, 프롬프트 데이터가 담긴 `README.md` 파일을 `txt` 확장자로 변경하여 함께 올렸어요. 그리고 대화창에 \"2개 문서에 있는 CASE 별 프롬프트를 이용한 나노바나나를 활용한 이미지 생성 편집 한글 앱\"이라고 입력하며, 앞서 메모장에 정리한 요청사항들을 상세히 덧붙여 앱 생성을 요청했습니다.\n처음 앱이 생성되었을 때는 아쉬움이 좀 있었어요. 왼쪽 CASE 목록에 168개보다 훨씬 적은 수의 케이스만 보였거든요. 하지만 걱정 마세요! AI와의 대화는 계속됩니다. 저는 곧바로 \"2개 파일에 총 168개의 CASE가 있어. 누락되는 CASE 없이 모두 적용해. CASE가 너무 많아 소스 DATA도 카테고리별로 생성해\"라고 다시 요청했습니다. 잠시 후, 모든 CASE가 완벽하게 적용된 것을 확인했고, '일러스트를 피규어로' 같은 기능을 테스트해보니 동작도 제대로 하는 것을 알 수 있었습니다. 아, 정말 뿌듯하더라고요!\n✨ 사용자 경험을 극대화하는 앱 기능 업그레이드\n앱이 기본적인 형태를 갖추었으니, 이제 사용자 경험을 한층 더 끌어올릴 시간이었어요. 몇 가지 핵심 기능을 추가하고 개선하는 과정을 거쳤습니다.\n\n\n1단계: 결과물 확대 및 다운로드 기능 추가\n처음에는 생성된 이미지가 너무 작아서 불편하다는 생각이 들었어요. 그래서 \"결과물을 클릭하면 확대하고 다운로드 버튼을 추가해\"라고 요청했습니다. 놀랍게도 클릭 시 이미지가 확대되고, 한 번의 클릭으로 이미지를 저장할 수 있는 다운로드 버튼까지 완벽하게 추가되었습니다. 사소하지만 정말 편리한 기능이죠!\n2단계: 카테고리 시각화 및 넘버링으로 가독성 향상\n168개의 프롬프트는 결코 적은 수가 아니잖아요? CASE 목록의 카테고리 명이 눈에 잘 띄지 않아 불편할 수 있겠다는 생각이 들었어요. \"카테고리명을 눈에 더 잘 띄게 버튼 형태로 변경해\"라는 요청과 함께, \"CASE에 넘버를 추가해\"라고 요청했습니다. 덕분에 이제 원하는 프롬프트를 훨씬 빠르고 쉽게 찾을 수 있게 되었습니다.\n3단계: AI 프롬프트 제안 기능으로 창작의 날개를 달다!\n이 앱의 가장 강력한 기능 중 하나가 바로 'AI 프롬프트 제안' 기능이라고 생각해요. 기존 프롬프트만 사용하는 것을 넘어, 사용자가 업로드하는 이미지와 추가 요청사항에 맞춰 AI가 개선된 프롬프트를 제안해주도록 요청했습니다.\n예를 들어, CASE 6번 '캐릭터 디자인'으로 테스트해봤어요. 기본 프롬프트는 입력한 이미지를 다양한 포즈의 디자인 시트로 만들어주는 것인데, 여기에 '교복 대신 체육복'이라는 추가 입력을 하고 AI에게 프롬프트를 제안받아 실행해보니, 와! 이미지에 체육복이 제대로 적용되는 것을 확인할 수 있었습니다. 이건 정말 창작의 가능성을 무한히 넓혀주는 기능이라고 할 수 있죠!\n4단계: 최종 마무리! 패널 조절 및 웹페이지 링크\n마지막으로, 사용자의 편의를 위해 메인 3개 패널의 폭을 자유롭게 조절할 수 있도록 했어요. 그리고 각 CASE별 실제 사용법을 자세히 볼 수 있도록 해당 웹페이지의 링크까지 추가하여 앱을 완벽하게 마무리했습니다. 이 작은 디테일들이 모여 사용자에게 큰 만족감을 줄 거라고 믿어요.\n\n\n\n  핵심 요약\n✔ 나노바나나 168종 프롬프트 앱 무료 공개: AI 이미지 작업을 위한 필수 도구!\n✔ Gemini 2.5 Flash Image 모델 완벽 활용: 혁신적인 AI 이미지 생성 및 편집 가능.\n✔ 직관적인 웹앱 인터페이스: 168개 프롬프트를 한눈에, 클릭 한 번으로 실행.\n✔ AI 프롬프트 제안 기능: 사용자의 요청과 이미지를 기반으로 최적화된 프롬프트 자동 생성.\n이 앱은 AI 이미지 작업의 효율성을 극대화하고 창작의 재미를 더해줄 것입니다. 지금 바로 경험해보세요!\n❓ 자주 묻는 질문 (FAQ)\nQ1: 나노바나나 168종 프롬프트 앱은 어떻게 사용할 수 있나요?\nA1: 앱은 웹 기반으로 제공되며, 별도의 설치 없이 인터넷 브라우저를 통해 접속할 수 있습니다. 각 섹션에 설명된 개발 과정을 통해 앱의 주요 기능과 사용법을 익히실 수 있습니다. 링크는 블로그 포스트 하단에서 확인하실 수 있습니다.\nQ2: AI 프롬프트 제안 기능은 어떤 식으로 작동하나요?\nA2: 이 기능은 사용자가 업로드하는 이미지와 텍스트로 추가하는 요청사항을 분석하여, 기존 프롬프트를 더욱 개선하거나 사용자 의도에 맞는 새로운 프롬프트를 생성해줍니다. 이를 통해 더 정교하고 독창적인 결과물을 얻을 수 있습니다.\nQ3: 앱이 무료로 제공되는데, 기능 제한은 없나요?\nA3: 네, 현재 공개된 나노바나나 168종 프롬프트 앱은 모든 기능을 제한 없이 무료로 제공됩니다. 이 앱을 통해 여러분이 부담 없이 AI 이미지 생성의 즐거움을 만끽하시길 바랍니다.\n{\"@context\": \"https://schema.org\",\"@type\": \"FAQPage\",\"mainEntity\": [{\"@type\": \"Question\",\"name\": \"나노바나나 168종 프롬프트 앱은 어떻게 사용할 수 있나요?\",\"acceptedAnswer\": {\"@type\": \"Answer\",\"text\": \"앱은 웹 기반으로 제공되며, 별도의 설치 없이 인터넷 브라우저를 통해 접속할 수 있습니다. 각 섹션에 설명된 개발 과정을 통해 앱의 주요 기능과 사용법을 익히실 수 있습니다. 링크는 블로그 포스트 하단에서 확인하실 수 있습니다.\"}},{\"@type\": \"Question\",\"name\": \"AI 프롬프트 제안 기능은 어떤 식으로 작동하나요?\",\"acceptedAnswer\": {\"@type\": \"Answer\",\"text\": \"이 기능은 사용자가 업로드하는 이미지와 텍스트로 추가하는 요청사항을 분석하여, 기존 프롬프트를 더욱 개선하거나 사용자 의도에 맞는 새로운 프롬프트를 생성해줍니다. 이를 통해 더 정교하고 독창적인 결과물을 얻을 수 있습니다.\"}},{\"@type\": \"Question\",\"name\": \"앱이 무료로 제공되는데, 기능 제한은 없나요?\",\"acceptedAnswer\": {\"type\": \"Answer\",\"text\": \"네, 현재 공개된 나노바나나 168종 프롬프트 앱은 모든 기능을 제한 없이 무료로 제공됩니다. 이 앱을 통해 여러분이 부담 없이 AI 이미지 생성의 즐거움을 만끽하시길 바랍니다.\"}}]} \n마무리하며: 새로운 창작의 문을 열다!\n이렇게 해서 많은 분들의 기대를 모았던 '나노바나나 168종 프롬프트 모음 앱'이 드디어 완성되었습니다! 이 앱은 단순히 프롬프트를 모아놓은 것을 넘어, AI Studio 앱빌더를 활용하여 개발 과정에서 겪었던 시행착오와 해결 과정까지 담은, 저에게는 참 의미 있는 결과물이에요.\nAI 이미지 생성과 편집이 이렇게 쉽고 강력해질 수 있다는 사실에 저 스스로도 다시 한번 놀라곤 합니다. 여러분의 소중한 시간과 노력을 아껴주고, 동시에 창작의 영감을 불어넣어 줄 이 앱을 지금 바로 무료로 경험해보세요!\n앱 링크는 아래에서 확인하실 수 있습니다. 많은 관심과 활용 부탁드리며, 여러분의 멋진 AI 작품들을 기대하겠습니다!\n나노바나나 프롬프트 쇼케이스 바로가기\nhttps://ai.studio/apps/drive/1aRW7y-kpscwD7QKyVQfP8Mf6vyuNjtSm\n\n \n로그인 - Google 계정\n이메일 또는 휴대전화\naccounts.google.com",
        "guid": "http://muzbox.tistory.com/483656",
        "categories": [
          "AI, 미래기술/AI 챗봇 및 지침 무료 배포",
          "AI 스튜디오",
          "AI 이미지 생성",
          "DALL-E 프롬프트",
          "나노바나나",
          "무료 앱",
          "웹앱 개발",
          "이미지 편집 앱",
          "인공지능 도구",
          "제미니 2.5 플래시",
          "프롬프트 모음"
        ],
        "isoDate": "2025-09-14T03:20:32.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "클라우드 비용 0원! 2025년 주목할 온디바이스 AI, 내 디바이스에 최적화된 가성비 끝판왕 모델은?",
        "link": "http://muzbox.tistory.com/483655",
        "pubDate": "Fri, 12 Sep 2025 08:23:12 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483655#entry483655comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #263238;\">\n<div style=\"background-color: #e0f7fa; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">요즘 AI 기술 발전 속도를 보면 정말 놀랍지 않나요? 특히 개인 디바이스에서 직접 AI를 실행할 수 있는 온디바이스(On-Device) AI 모델들이 빠르게 확산되고 있습니다. 클라우드 비용 걱정 없이, 개인정보는 안전하게 지키면서 AI를 내 손안에서 활용할 수 있다는 점이 가장 큰 매력인 것 같아요. 저도 처음에는 '이게 정말 가능해?' 싶었지만, 직접 써보니 그 편리함에 솔직히 감탄했습니다. 오늘은 2025년 주목해야 할 온디바이스 AI 모델들을 초보자 눈높이에 맞춰 쉽고 자세하게 비교 분석하고, 여러분에게 꼭 맞는 '가성비 끝판왕' 모델을 찾아드리려 해요.</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  온디바이스 AI, 왜 지금 주목해야 할까요?</b></h2>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/cltNsu/btsQuhRIvy4/4jWfC73uMlcOBmCl5DZpmK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cltNsu/btsQuhRIvy4/4jWfC73uMlcOBmCl5DZpmK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cltNsu/btsQuhRIvy4/4jWfC73uMlcOBmCl5DZpmK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcltNsu%2FbtsQuhRIvy4%2F4jWfC73uMlcOBmCl5DZpmK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"클라우드 없이 기기 내에서 실행되는 온디바이스 AI의 개념을 보여주는 스마트폰과 노트북. 데이터는 장치 내부에서만 처리되어 개인정보 보호 및 비용 절감 효과를 나타냅니다.\" loading=\"lazy\" width=\"500\" height=\"500\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">우리가 흔히 접하는 AI 서비스들은 대부분 인터넷을 통해 원격 서버, 즉 클라우드에서 작동해요. 그런데 <b>온디바이스 AI</b>는 말 그대로 여러분의 스마트폰, 노트북, 태블릿 같은 <b>개인 디바이스에서 직접 인공지능 모델이 실행되는 기술</b>을 의미합니다. 클라우드를 거치지 않고 내 기기에서 모든 연산이 이루어지죠. 제가 처음 이 개념을 접했을 때 가장 크게 와닿았던 부분은 바로 개인정보 보호였어요. 데이터가 외부로 나가지 않는다는 게 정말 안심이 되더라고요.</p>\n<h3 style=\"font-size: 18px; color: #00796b; margin-top: 25px; margin-bottom: 10px;\" data-ke-size=\"size23\">온디바이스 AI의 주요 장점</h3>\n<ul style=\"list-style-type: disc; padding-left: 20px; margin-bottom: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 8px;\"><b>개인정보 보호</b>: 내 데이터가 외부 서버로 전송되지 않으니 프라이버시 걱정이 덜하죠. 이건 정말 중요한 장점이라고 생각해요.</li>\n<li style=\"margin-bottom: 8px;\"><b>빠른 응답속도</b>: 네트워크 지연 없이 바로바로 결과를 얻을 수 있어서 답답함이 없습니다. 실시간으로 빠르게 반응하는 AI를 경험할 수 있어요.</li>\n<li style=\"margin-bottom: 8px;\"><b>오프라인 사용 가능</b>: 인터넷이 연결되지 않는 환경에서도 AI 기능을 활용할 수 있다는 건 생각보다 큰 장점이에요. 비행기 안이나 데이터가 부족할 때도 문제없죠.</li>\n<li style=\"margin-bottom: 8px;\"><b>비용 절약</b>: 클라우드 API 사용료가 발생하지 않으니, 장기적으로 보면 AI 사용 비용을 크게 줄일 수 있습니다. 이것이야말로 '클라우드 비용 0원'의 핵심이죠.</li>\n</ul>\n<div style=\"background-color: #e0f7fa; border-left: 4px solid #00796b; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  팁: 온디바이스 AI는 스마트폰, 태블릿, 노트북 등 여러분이 매일 쓰는 기기에서 AI를 더욱 '개인화'되고 '효율적'으로 활용할 수 있는 미래 기술이에요. 특히 개인 정보에 민감한 분들이라면 더욱 주목해야 할 포인트입니다!</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  내게 맞는 온디바이스 AI 모델 찾기: 성능 비교 분석</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">수많은 온디바이스 AI 모델 중에서 나에게 맞는 것을 고르기란 쉽지 않죠. 모델의 크기(매개변수)는 성능과 직결되지만, 동시에 필요한 하드웨어 사양과도 밀접하게 연결됩니다. 제가 여러 모델을 직접 사용해보고 분석한 결과, 크게 세 가지 등급으로 나눌 수 있었어요. 각 등급별 대표 모델들을 함께 살펴볼까요?</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1280\" data-origin-height=\"853\"><span data-url=\"https://blog.kakaocdn.net/dn/r6zYw/btsQtYrcxgK/trgHBWempbnsyW3MwfekC1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/r6zYw/btsQtYrcxgK/trgHBWempbnsyW3MwfekC1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/r6zYw/btsQtYrcxgK/trgHBWempbnsyW3MwfekC1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fr6zYw%2FbtsQtYrcxgK%2FtrgHBWempbnsyW3MwfekC1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"내게 맞는 온디바이스 AI 모델 찾기: 성능 비교 분석\" loading=\"lazy\" width=\"732\" height=\"488\" data-origin-width=\"1280\" data-origin-height=\"853\"/></span></figure>\n\n<h3 style=\"font-size: 18px; color: #00796b; margin-top: 25px; margin-bottom: 10px;\" data-ke-size=\"size23\">  고성능 등급 (7B 이상 매개변수)</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 등급의 모델들은 최고 수준의 AI 성능을 자랑하지만, 그만큼 고사양의 하드웨어를 요구합니다. 주로 전문적인 작업이나 복잡한 추론에 적합하다고 보시면 돼요. 마치 스포츠카처럼 말이죠!</p>\n<div style=\"overflow-x: auto; margin-bottom: 20px;\">\n<table style=\"width: 100%; border-collapse: collapse; text-align: left; color: #263238; border: 1px solid #b0bec5;\" data-ke-align=\"alignLeft\">\n<thead style=\"background-color: #cfd8dc;\">\n<tr style=\"background-color: #cfd8dc;\">\n<th style=\"padding: 10px; border: 1px solid #b0bec5;\">모델명</th>\n<th style=\"padding: 10px; border: 1px solid #b0bec5;\">매개변수</th>\n<th style=\"padding: 10px; border: 1px solid #b0bec5;\">주요 성능</th>\n<th style=\"padding: 10px; border: 1px solid #b0bec5;\">메모리 요구량</th>\n<th style=\"padding: 10px; border: 1px solid #b0bec5;\">특징 및 권장 대상</th>\n</tr>\n</thead>\n<tbody>\n<tr style=\"background-color: #eceff1;\">\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\"><b>GPT-OSS</b></td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">20B</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">OpenAI o3-mini급, 수학 문제 AIME 98.7%</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">40GB 이상</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">고성능 추론, 전문 사용자용</td>\n</tr>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\"><b>Llama 3.1</b></td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">8B</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">MMLU 68.0점, 범용 성능 우수</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">16GB 이상</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">균형 잡힌 성능, 상업적 이용 가능</td>\n</tr>\n<tr style=\"background-color: #eceff1;\">\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\"><b>Mistral 7B</b></td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">7B</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">MMLU 62.0점, 효율적인 추론</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">14GB 이상</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">동급 모델 중 뛰어난 가성비</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 style=\"font-size: 18px; color: #00796b; margin-top: 25px; margin-bottom: 10px;\" data-ke-size=\"size23\">  균형 등급 (3-4B 매개변수)</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 등급은 성능과 하드웨어 요구 사항 사이에서 좋은 균형을 이루는 모델들이에요. 대부분의 일상적인 AI 작업에 충분하면서도, 비교적 접근성이 좋습니다. 딱 중간 정도의 성능을 원한다면 이 모델들을 눈여겨봐야 합니다.</p>\n<div style=\"overflow-x: auto; margin-bottom: 20px;\">\n<table style=\"width: 100%; border-collapse: collapse; text-align: left; color: #263238; border: 1px solid #b0bec5;\" data-ke-align=\"alignLeft\">\n<thead style=\"background-color: #cfd8dc;\">\n<tr style=\"background-color: #cfd8dc;\">\n<th style=\"padding: 10px; border: 1px solid #b0bec5;\">모델명</th>\n<th style=\"padding: 10px; border: 1px solid #b0bec5;\">매개변수</th>\n<th style=\"padding: 10px; border: 1px solid #b0bec5;\">주요 성능</th>\n<th style=\"padding: 10px; border: 1px solid #b0bec5;\">메모리 요구량</th>\n<th style=\"padding: 10px; border: 1px solid #b0bec5;\">특징 및 권장 대상</th>\n</tr>\n</thead>\n<tbody>\n<tr style=\"background-color: #eceff1;\">\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\"><b>Gemma 3</b></td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">4B</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">MMLU 68.0점, 소형 모델 중 최고</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">8GB 이상</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">멀티모달 기능, Google 개발</td>\n</tr>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\"><b>Phi-3</b></td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">3.8B</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">MMLU 68.8점, GPT-3.5 유사</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">8GB (4비트 양자화 시 1.8GB)</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">모바일 최적화, Microsoft 개발</td>\n</tr>\n<tr style=\"background-color: #eceff1;\">\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\"><b>Qwen 2.5</b></td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">3B</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">MMLU 65.0점, 다국어 지원 탁월</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">6GB 이상</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">29개 언어 지원, Alibaba 개발</td>\n</tr>\n</tbody>\n</table>\n</div>\n<div style=\"background-color: #ffebee; border-left: 4px solid #c62828; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">⚠️ 주의: 매개변수 크기가 작다고 무조건 성능이 낮은 것은 아닙니다! Phi-3나 Gemma 3처럼 작지만 효율적인 훈련을 통해 대형 모델에 버금가는 성능을 내는 경우도 있으니, 벤치마크 점수를 꼼꼼히 확인하는 것이 중요합니다.</div>\n<h3 style=\"font-size: 18px; color: #00796b; margin-top: 25px; margin-bottom: 10px;\" data-ke-size=\"size23\">  경량 등급 (2B 이하 매개변수)</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 등급의 모델들은 낮은 사양의 기기에서도 가볍게 구동할 수 있다는 것이 가장 큰 장점이에요. 스마트폰이나 구형 노트북에서도 AI를 경험하고 싶다면 이 모델들이 아주 좋은 출발점이 될 수 있습니다.</p>\n<div style=\"overflow-x: auto; margin-bottom: 20px;\">\n<table style=\"width: 100%; border-collapse: collapse; text-align: left; color: #263238; border: 1px solid #b0bec5;\" data-ke-align=\"alignLeft\">\n<thead style=\"background-color: #cfd8dc;\">\n<tr style=\"background-color: #cfd8dc;\">\n<th style=\"padding: 10px; border: 1px solid #b0bec5;\">모델명</th>\n<th style=\"padding: 10px; border: 1px solid #b0bec5;\">매개변수</th>\n<th style=\"padding: 10px; border: 1px solid #b0bec5;\">주요 성능</th>\n<th style=\"padding: 10px; border: 1px solid #b0bec5;\">메모리 요구량</th>\n<th style=\"padding: 10px; border: 1px solid #b0bec5;\">특징 및 권장 대상</th>\n</tr>\n</thead>\n<tbody>\n<tr style=\"background-color: #eceff1;\">\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\"><b>Gemma 2</b></td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">2B</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">MMLU 42.3점, GPT-3.5 일부 벤치마크 능가</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">4GB 이상</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">작은 크기 대비 고성능, 빠른 처리 속도</td>\n</tr>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\"><b>DeepSeek-R1</b></td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">1.5B</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">수학 추론 특화</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">3GB 이상</td>\n<td style=\"padding: 10px; border: 1px solid #b0bec5; color: #263238;\">CPU만으로도 실행 가능, 강화학습 훈련</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  하드웨어별 최적 온디바이스 AI 모델 추천 가이드</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">모델의 성능만큼 중요한 것이 바로 내 디바이스와의 궁합이죠! 아무리 좋은 모델이라도 내 하드웨어에서 제대로 돌아가지 않는다면 무용지물이니까요. 여러분의 디바이스 사양에 맞춰 최적의 온디바이스 AI 모델을 추천해 드릴게요.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/bLXmZj/btsQul0HoPj/qknyl5gIuGrfkJ45kwFNk0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bLXmZj/btsQul0HoPj/qknyl5gIuGrfkJ45kwFNk0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bLXmZj/btsQul0HoPj/qknyl5gIuGrfkJ45kwFNk0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbLXmZj%2FbtsQul0HoPj%2Fqknyl5gIuGrfkJ45kwFNk0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<ul style=\"list-style-type: disc; padding-left: 20px; margin-bottom: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 8px;\"><b>고성능 게이밍 PC (RTX 4080/4090)</b><br />추천 모델: <b>GPT-OSS 20B 또는 Llama 3.1 8B</b><br />- 40GB 이상의 VRAM으로 대용량 모델도 거뜬히! 최고 수준의 AI 성능을 만끽하고 싶은 전문가에게 제격입니다.</li>\n<li style=\"margin-bottom: 8px;\"><b>중급 게이밍 PC (RTX 3070/4060Ti)</b><br />추천 모델: <b>Mistral 7B 또는 Gemma 3 4B</b><br />- 12-16GB의 VRAM을 가진 기기에서 균형 잡힌 성능을 제공합니다. 대부분의 AI 작업에 부족함 없는 성능을 보여줄 거예요.</li>\n<li style=\"margin-bottom: 8px;\"><b>보급형 PC/노트북 (RTX 3060/통합 그래픽)</b><br />추천 모델: <b>Phi-3 3.8B 또는 Qwen 2.5 3B</b><br />- 8GB 이하 메모리로도 충분히 실행 가능한 모델들입니다. 온디바이스 AI 초보자들에게 가장 접근성이 좋고, 설정도 쉬울 거예요.</li>\n<li style=\"margin-bottom: 8px;\"><b>모바일/저사양 기기 (스마트폰, 구형 태블릿)</b><br />추천 모델: <b>Gemma 2 2B 또는 DeepSeek-R1 1.5B</b><br />- CPU만으로도 실행 가능한 모델들이 많습니다. 스마트폰에서도 가볍게 AI 기능을 활용하고 싶다면 이들을 추천합니다.</li>\n</ul>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  용도별 온디바이스 AI 모델 선택 가이드</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">어떤 용도로 AI를 사용할지에 따라 최적의 모델은 달라질 수 있습니다. 마치 망치와 드라이버를 적재적소에 사용하는 것처럼요! 여러분의 주요 사용 목적에 맞춰 가장 효율적인 모델을 찾아보세요.</p>\n<ul style=\"list-style-type: disc; padding-left: 20px; margin-bottom: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 8px;\"><b>학습 및 교육 목적</b><br />추천 모델: <b>Phi-3 3.8B</b><br />- 이유: 교육 데이터로 특별히 훈련되어 수학, 과학 문제 해결 능력이 탁월합니다. 학생들이 학습 보조 도구로 활용하기에 아주 좋습니다.<br />- 설치 난이도: 쉬움</li>\n<li style=\"margin-bottom: 8px;\"><b>일반적인 대화 및 질답</b><br />추천 모델: <b>Llama 3.1 8B 또는 Gemma 3 4B</b><br />- 이유: 균형 잡힌 성능으로 다양한 주제에 자연스럽게 대응합니다. 정확도도 높아서 일상적인 대화나 궁금증 해결에 적합합니다.<br />- 설치 난이도: 보통</li>\n<li style=\"margin-bottom: 8px;\"><b>이미지 분석 및 멀티모달 작업</b><br />추천 모델: <b>LLaVA 7B 또는 Gemma 3 4B</b><br />- 이유: 텍스트뿐만 아니라 이미지를 동시에 처리하는 멀티모달 기능을 제공합니다. 이미지 설명, 시각적 질문 답변 등 시각적인 작업에 강점을 보입니다.<br />- 설치 난이도: 어려움 (LLaVA의 경우)</li>\n<li style=\"margin-bottom: 8px;\"><b>프로그래밍 및 코드 생성</b><br />추천 모델: <b>Qwen 2.5 3B 또는 Mistral 7B</b><br />- 이유: 코딩 벤치마크에서 우수한 성능을 보여줍니다. Python, JavaScript 등 다양한 프로그래밍 언어를 지원하여 개발자들에게 큰 도움이 될 거예요.<br />- 설치 난이도: 보통</li>\n<li style=\"margin-bottom: 8px;\"><b>다국어 번역 및 처리</b><br />추천 모델: <b>Qwen 2.5 3B</b><br />- 이유: 무려 29개 언어를 지원하며 다국어 처리에 최적화되어 있습니다. 한국어를 포함한 아시아 언어 처리 능력도 우수해서 해외 자료를 다루거나 번역할 때 유용합니다.<br />- 설치 난이도: 보통</li>\n</ul>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  효율성과 가성비, 초보자를 위한 최고의 선택은?</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">모델 선택에 있어 성능만큼이나 중요한 것이 바로 '효율성'과 '가성비'입니다. 특히 온디바이스 AI에서는 제한된 리소스 내에서 얼마나 똑똑하게 작동하는지가 관건이죠. 제가 간단한 지표를 만들어 효율성을 계산해 봤어요. (효율성 점수 = (처리속도 &times; MMLU 점수) &divide; 메모리 요구량)</p>\n<h3 style=\"font-size: 18px; color: #00796b; margin-top: 25px; margin-bottom: 10px;\" data-ke-size=\"size23\">최고 효율성 모델들</h3>\n<ul style=\"list-style-type: decimal; padding-left: 20px; margin-bottom: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 8px;\"><b>Phi-3 (3.8B)</b>: 효율성 점수 23.75 - 작은 크기 대비 최고의 성능을 자랑합니다. Microsoft가 괜히 모바일 최적화에 힘쓴 게 아니겠죠?</li>\n<li style=\"margin-bottom: 8px;\"><b>Gemma 3 (4B)</b>: 효율성 점수 22.5 - 멀티모달 기능을 포함하면서도 뛰어난 균형 잡힌 성능을 보여줍니다. Google의 역량이 느껴지는 부분이에요.</li>\n<li style=\"margin-bottom: 8px;\"><b>Qwen 2.5 (3B)</b>: 효율성 점수 30.83 - 특히 다국어 지원까지 고려하면 이 모델은 정말 독보적인 효율성을 보여준다고 생각해요.</li>\n</ul>\n<h3 style=\"font-size: 18px; color: #00796b; margin-top: 25px; margin-bottom: 10px;\" data-ke-size=\"size23\">가성비 분석: 초보자에게 딱!</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">제 개인적인 경험과 분석을 종합해 볼 때, 초보자 여러분에게 <b>최고의 가성비 모델은 단연 Phi-3 3.8B</b>라고 말씀드리고 싶습니다. 낮은 하드웨어 요구사항에도 불구하고 GPT-3.5와 유사한 수준의 뛰어난 성능을 보여주니, 이보다 더 좋을 순 없겠죠. 또한 Microsoft의 적극적인 지원까지 더해져 안정성도 높습니다. 만약 조금 더 욕심을 내서 멀티모달 기능을 경험하고 싶다면, <b>Gemma 3 4B</b>도 훌륭한 대안이 될 것입니다. Google이 지속적으로 업데이트하고 있으니 미래도 밝고요.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b> ️ 온디바이스 AI, 어떻게 시작할까요? (설치 및 사용 가이드)</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">'설치가 어렵진 않을까?' 하고 걱정하시는 분들이 많을 텐데요, 솔직히 예전에는 그랬습니다. 하지만 요즘은 초보자도 쉽게 따라 할 수 있는 플랫폼들이 많이 나와서 걱정할 필요가 없어요. 제가 추천하는 단계별 가이드를 따라 해보세요!</p>\n<h3 style=\"font-size: 18px; color: #00796b; margin-top: 25px; margin-bottom: 10px;\" data-ke-size=\"size23\">초보자를 위한 단계별 가이드</h3>\n<ol style=\"list-style-type: decimal; padding-left: 20px; margin-bottom: 20px;\" data-ke-list-type=\"decimal\">\n<li style=\"margin-bottom: 8px;\"><b>1단계: 하드웨어 확인</b><br />- 가장 먼저 내 PC의 GPU 메모리 (VRAM), RAM 용량, 그리고 모델을 설치할 충분한 저장공간이 있는지 확인해야 합니다. 모델당 2GB에서 40GB까지 필요할 수 있으니 넉넉한 공간을 확보해 두세요.</li>\n<li style=\"margin-bottom: 8px;\"><b>2단계: 플랫폼 선택</b><br />- <b>Ollama</b>: 가장 초보자 친화적이고, 원클릭 설치로 빠르게 시작할 수 있어요.<br />- <b>LM Studio</b>: 직관적인 GUI와 모델 마켓플레이스를 내장하고 있어서 여러 모델을 쉽게 탐색하고 실행할 수 있습니다.<br />- <b>GPT4All</b>: 크로스플랫폼을 지원하고 CPU에 최적화되어 있어서 GPU가 없는 환경에서도 AI를 경험할 수 있습니다.</li>\n<li style=\"margin-bottom: 8px;\"><b>3단계: 모델 다운로드 및 실행</b><br />- 선택한 플랫폼에서 원하는 모델을 다운로드하고 실행하면 끝! 예를 들어, Ollama를 사용한다면 다음과 같이 간단한 명령어로 실행할 수 있습니다.</li>\n</ol>\n<pre class=\"llvm\" style=\"background-color: #f0f0f0; padding: 15px; border-radius: 8px; overflow-x: auto; font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace; color: #263238; font-size: 14px;\"><code> # Ollama 사용 예시 ollama pull phi3 ollama run phi3 </code></pre>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  온디바이스 AI의 미래, 2025년은 어떤 변화가?</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">온디바이스 AI는 정말 빠르게 발전하고 있는 분야입니다. 2025년에는 또 어떤 놀라운 변화가 우리를 기다리고 있을까요? 제가 예측하는 몇 가지 주요 발전 방향을 공유해 드릴게요.</p>\n<h3 style=\"font-size: 18px; color: #00796b; margin-top: 25px; margin-bottom: 10px;\" data-ke-size=\"size23\">모델 크기 최적화 트렌드</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">최근 연구들을 보면, 더 작은 모델들이 대형 모델과 비슷하거나 심지어 더 나은 성능을 보여주는 경우가 늘고 있습니다. 예를 들어, Gemma 2 2B 모델이 GPT-3.5보다 일부 벤치마크에서 우수한 성능을 보였다는 것은 정말 놀라운 일이죠. 앞으로는 무작정 큰 모델보다는 <b>효율적인 구조와 훈련 방법을 통해 성능을 극대화한 '작지만 강한' 모델들이 주류</b>가 될 것입니다.</p>\n<h3 style=\"font-size: 18px; color: #00796b; margin-top: 25px; margin-bottom: 10px;\" data-ke-size=\"size23\">하드웨어 발전의 영향</h3>\n<ul style=\"list-style-type: disc; padding-left: 20px; margin-bottom: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 8px;\"><b>NPU(Neural Processing Unit) 통합</b>: 차세대 CPU에는 AI 전용 프로세서인 NPU가 내장될 거예요. 이는 온디바이스 AI의 처리 속도와 효율성을 획기적으로 향상시킬 것입니다.</li>\n<li style=\"margin-bottom: 8px;\"><b>메모리 효율성 개선</b>: 양자화(Quantization) 같은 기술 덕분에 AI 모델의 메모리 사용량이 75%까지 감소할 수 있습니다. 이는 더 많은 모델을 더 작은 기기에서 실행할 수 있게 해줍니다.</li>\n<li style=\"margin-bottom: 8px;\"><b>모바일 최적화 가속화</b>: 스마트폰에서도 7B 매개변수 모델을 실시간으로 실행하는 것이 머지않아 현실이 될 겁니다. 정말 기대되지 않나요?</li>\n</ul>\n<h3 style=\"font-size: 18px; color: #00796b; margin-top: 25px; margin-bottom: 10px;\" data-ke-size=\"size23\">2025년 예상 발전사항</h3>\n<ul style=\"list-style-type: disc; padding-left: 20px; margin-bottom: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 8px;\">1B 매개변수 모델이 현재의 3B 수준 성능을 달성할 것입니다.</li>\n<li style=\"margin-bottom: 8px;\">텍스트-이미지, 텍스트-오디오 등 <b>멀티모달 기능이 온디바이스 AI의 표준</b>이 될 거예요.</li>\n<li style=\"margin-bottom: 8px;\">사용자의 패턴을 학습하여 스스로 진화하는 <b>실시간 학습 및 개인화 기능</b>이 더욱 강화될 것입니다.</li>\n</ul>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/ba54Tm/btsQt1g7NPY/nFeho4qijy8zOscLAxjv11/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/ba54Tm/btsQt1g7NPY/nFeho4qijy8zOscLAxjv11/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/ba54Tm/btsQt1g7NPY/nFeho4qijy8zOscLAxjv11/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fba54Tm%2FbtsQt1g7NPY%2FnFeho4qijy8zOscLAxjv11%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"NPU 칩이 통합된 미래형 스마트폰 내부에서 효율적으로 데이터를 처리하는 온디바이스 AI를 보여주는 이미지. 2025년 AI 하드웨어 발전을 상징합니다.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<div style=\"background-color: #eceff1; border: 1px solid #b0bec5; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); padding: 25px; margin: 40px 0;\">\n<div style=\"font-size: 26px; color: #00796b; font-weight: bold; margin-bottom: 15px; border-bottom: 2px solid #00796b; padding-bottom: 10px;\">  핵심 요약</div>\n<ul style=\"list-style-type: none; padding-left: 0; margin-bottom: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px; font-size: 17px;\">&bull; <b>온디바이스 AI는 클라우드 비용 없이 개인정보를 안전하게 지키며 AI를 사용할 수 있게 합니다.</b></li>\n<li style=\"margin-bottom: 10px; font-size: 17px;\">&bull; <b>Phi-3 3.8B는 낮은 하드웨어 요구사항과 뛰어난 성능으로 초보자에게 가장 적합한 가성비 모델입니다.</b></li>\n<li style=\"margin-bottom: 10px; font-size: 17px;\">&bull; <b>Gemma 3 4B는 멀티모달 기능을 제공하며, 균형 잡힌 성능으로 중급 사용자에게 훌륭한 선택입니다.</b></li>\n<li style=\"margin-bottom: 10px; font-size: 17px;\">&bull; <b>2025년에는 더 작고 효율적인 모델, NPU 통합, 모바일 최적화가 가속화될 전망입니다.</b></li>\n</ul>\n<div style=\"font-size: 14px; color: #607d8b; border-top: 1px dashed #b0bec5; padding-top: 15px;\">사용자의 하드웨어 환경과 목적에 맞는 모델을 신중하게 선택하는 것이 중요하며, 작은 모델부터 시작하여 경험을 쌓는 것을 권장합니다.</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<div style=\"margin-bottom: 15px;\">\n<p style=\"margin-bottom: 5px;\" data-ke-size=\"size16\"><b>Q1: 온디바이스 AI는 왜 주목받고 있나요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A1: 개인정보 보호, 빠른 응답 속도, 인터넷 연결 없이 사용 가능, 그리고 클라우드 서비스 비용 절감이라는 강력한 장점들 때문입니다. 특히 2025년에는 이러한 장점들이 더욱 부각될 것으로 예상됩니다.</p>\n</div>\n<div style=\"margin-bottom: 15px;\">\n<p style=\"margin-bottom: 5px;\" data-ke-size=\"size16\"><b>Q2: 온디바이스 AI를 사용하려면 고사양 PC가 필수인가요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A2: 아니요, 꼭 그렇지는 않습니다. Phi-3 3.8B나 Gemma 2 2B 같은 경량 모델들은 8GB 이하의 메모리나 노트북 통합 그래픽으로도 충분히 실행할 수 있습니다. 심지어 CPU만으로도 가능한 모델들도 있어요. 중요한 건 자신의 하드웨어 사양에 맞는 모델을 선택하는 것입니다.</p>\n</div>\n<div style=\"margin-bottom: 15px;\">\n<p style=\"margin-bottom: 5px;\" data-ke-size=\"size16\"><b>Q3: 온디바이스 AI 모델 설치는 어려운가요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A3: 요즘은 Ollama, LM Studio, GPT4All과 같은 사용자 친화적인 플랫폼 덕분에 설치가 매우 쉬워졌어요. 몇 번의 클릭만으로 모델을 다운로드하고 실행할 수 있습니다. 초보자도 쉽게 시작할 수 있도록 가이드가 잘 되어 있어요.</p>\n</div>\n<div style=\"margin-bottom: 15px;\">\n<p style=\"margin-bottom: 5px;\" data-ke-size=\"size16\"><b>Q4: 멀티모달 기능이 있는 온디바이스 AI 모델도 있나요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A4: 네, 물론입니다! Gemma 3 4B나 LLaVA 7B 같은 모델들은 텍스트뿐만 아니라 이미지를 동시에 처리하는 멀티모달 기능을 지원합니다. 이미지 설명이나 시각적 질문 답변 등 다양한 멀티모달 작업을 온디바이스에서 경험할 수 있습니다.</p>\n</div>\n<script type=\"application/ld+json\"> { \"@context\": \"https://schema.org\", \"@type\": \"FAQPage\", \"mainEntity\": [ { \"@type\": \"Question\", \"name\": \"온디바이스 AI는 왜 주목받고 있나요?\", \"acceptedAnswer\": { \"@type\": \"Answer\", \"text\": \"개인정보 보호, 빠른 응답 속도, 인터넷 연결 없이 사용 가능, 그리고 클라우드 서비스 비용 절감이라는 강력한 장점들 때문입니다. 특히 2025년에는 이러한 장점들이 더욱 부각될 것으로 예상됩니다.\" } }, { \"@type\": \"Question\", \"name\": \"온디바이스 AI를 사용하려면 고사양 PC가 필수인가요?\", \"acceptedAnswer\": { \"@type\": \"Answer\", \"text\": \"아니요, 꼭 그렇지는 않습니다. Phi-3 3.8B나 Gemma 2 2B 같은 경량 모델들은 8GB 이하의 메모리나 노트북 통합 그래픽으로도 충분히 실행할 수 있습니다. 심지어 CPU만으로도 가능한 모델들도 있어요. 중요한 건 자신의 하드웨어 사양에 맞는 모델을 선택하는 것입니다.\" } }, { \"@type\": \"Question\", \"name\": \"온디바이스 AI 모델 설치는 어려운가요?\", \"acceptedAnswer\": { \"@type\": \"Answer\", \"text\": \"요즘은 Ollama, LM Studio, GPT4All과 같은 사용자 친화적인 플랫폼 덕분에 설치가 매우 쉬워졌어요. 몇 번의 클릭만으로 모델을 다운로드하고 실행할 수 있습니다. 초보자도 쉽게 시작할 수 있도록 가이드가 잘 되어 있어요.\" } }, { \"@type\": \"Question\", \"name\": \"멀티모달 기능이 있는 온디바이스 AI 모델도 있나요?\", \"acceptedAnswer\": { \"@type\": \"Answer\", \"text\": \"네, 물론입니다! Gemma 3 4B나 LLaVA 7B 같은 모델들은 텍스트뿐만 아니라 이미지를 동시에 처리하는 멀티모달 기능을 지원합니다. 이미지 설명이나 시각적 질문 답변 등 다양한 멀티모달 작업을 온디바이스에서 경험할 수 있습니다.\" } } ] } </script>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #00796b, #004d40); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✨ 마무리하며: 나만의 AI 비서를 만나다</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">오늘 온디바이스 AI의 세계에 대해 깊이 파고들어 봤습니다. 클라우드 비용 걱정 없이, 개인정보는 안전하게 보호하면서 AI를 활용할 수 있다는 점은 정말 매력적이죠. 저 역시 이런 기술의 발전에 큰 흥미를 느끼고 있어요. 중요한 건 자신의 <b>하드웨어 환경과 사용 목적을 명확히 설정</b>한 후, 그에 맞는 모델을 신중하게 선택하는 것이라는 점을 꼭 기억해 주셨으면 좋겠습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">큰 모델이 항상 정답은 아니며, 효율성과 실용성을 고려한 선택이 여러분에게 더 만족스러운 경험을 선사할 거예요. 지금부터라도 자신에게 맞는 온디바이스 AI 모델을 찾아보고, 그 잠재력을 최대한 활용해 보시길 강력히 추천합니다. AI 기술은 멈추지 않고 발전하고 있으니, 새로운 모델이 나올 때마다 호기심을 갖고 탐구하는 자세도 잊지 마세요! 여러분의 일상과 업무가 온디바이스 AI를 통해 더욱 스마트하고 편리해지기를 바랍니다.</p>\n</div>",
        "contentSnippet": "요즘 AI 기술 발전 속도를 보면 정말 놀랍지 않나요? 특히 개인 디바이스에서 직접 AI를 실행할 수 있는 온디바이스(On-Device) AI 모델들이 빠르게 확산되고 있습니다. 클라우드 비용 걱정 없이, 개인정보는 안전하게 지키면서 AI를 내 손안에서 활용할 수 있다는 점이 가장 큰 매력인 것 같아요. 저도 처음에는 '이게 정말 가능해?' 싶었지만, 직접 써보니 그 편리함에 솔직히 감탄했습니다. 오늘은 2025년 주목해야 할 온디바이스 AI 모델들을 초보자 눈높이에 맞춰 쉽고 자세하게 비교 분석하고, 여러분에게 꼭 맞는 '가성비 끝판왕' 모델을 찾아드리려 해요.\n  온디바이스 AI, 왜 지금 주목해야 할까요?\n\n\n우리가 흔히 접하는 AI 서비스들은 대부분 인터넷을 통해 원격 서버, 즉 클라우드에서 작동해요. 그런데 온디바이스 AI는 말 그대로 여러분의 스마트폰, 노트북, 태블릿 같은 개인 디바이스에서 직접 인공지능 모델이 실행되는 기술을 의미합니다. 클라우드를 거치지 않고 내 기기에서 모든 연산이 이루어지죠. 제가 처음 이 개념을 접했을 때 가장 크게 와닿았던 부분은 바로 개인정보 보호였어요. 데이터가 외부로 나가지 않는다는 게 정말 안심이 되더라고요.\n온디바이스 AI의 주요 장점\n개인정보 보호: 내 데이터가 외부 서버로 전송되지 않으니 프라이버시 걱정이 덜하죠. 이건 정말 중요한 장점이라고 생각해요.\n빠른 응답속도: 네트워크 지연 없이 바로바로 결과를 얻을 수 있어서 답답함이 없습니다. 실시간으로 빠르게 반응하는 AI를 경험할 수 있어요.\n오프라인 사용 가능: 인터넷이 연결되지 않는 환경에서도 AI 기능을 활용할 수 있다는 건 생각보다 큰 장점이에요. 비행기 안이나 데이터가 부족할 때도 문제없죠.\n비용 절약: 클라우드 API 사용료가 발생하지 않으니, 장기적으로 보면 AI 사용 비용을 크게 줄일 수 있습니다. 이것이야말로 '클라우드 비용 0원'의 핵심이죠.\n  팁: 온디바이스 AI는 스마트폰, 태블릿, 노트북 등 여러분이 매일 쓰는 기기에서 AI를 더욱 '개인화'되고 '효율적'으로 활용할 수 있는 미래 기술이에요. 특히 개인 정보에 민감한 분들이라면 더욱 주목해야 할 포인트입니다!\n  내게 맞는 온디바이스 AI 모델 찾기: 성능 비교 분석\n수많은 온디바이스 AI 모델 중에서 나에게 맞는 것을 고르기란 쉽지 않죠. 모델의 크기(매개변수)는 성능과 직결되지만, 동시에 필요한 하드웨어 사양과도 밀접하게 연결됩니다. 제가 여러 모델을 직접 사용해보고 분석한 결과, 크게 세 가지 등급으로 나눌 수 있었어요. 각 등급별 대표 모델들을 함께 살펴볼까요?\n\n\n  고성능 등급 (7B 이상 매개변수)\n이 등급의 모델들은 최고 수준의 AI 성능을 자랑하지만, 그만큼 고사양의 하드웨어를 요구합니다. 주로 전문적인 작업이나 복잡한 추론에 적합하다고 보시면 돼요. 마치 스포츠카처럼 말이죠!\n모델명\n매개변수\n주요 성능\n메모리 요구량\n특징 및 권장 대상\n\n\n\n\nGPT-OSS\n20B\nOpenAI o3-mini급, 수학 문제 AIME 98.7%\n40GB 이상\n고성능 추론, 전문 사용자용\n\n\nLlama 3.1\n8B\nMMLU 68.0점, 범용 성능 우수\n16GB 이상\n균형 잡힌 성능, 상업적 이용 가능\n\n\nMistral 7B\n7B\nMMLU 62.0점, 효율적인 추론\n14GB 이상\n동급 모델 중 뛰어난 가성비\n\n\n\n\n  균형 등급 (3-4B 매개변수)\n이 등급은 성능과 하드웨어 요구 사항 사이에서 좋은 균형을 이루는 모델들이에요. 대부분의 일상적인 AI 작업에 충분하면서도, 비교적 접근성이 좋습니다. 딱 중간 정도의 성능을 원한다면 이 모델들을 눈여겨봐야 합니다.\n모델명\n매개변수\n주요 성능\n메모리 요구량\n특징 및 권장 대상\n\n\n\n\nGemma 3\n4B\nMMLU 68.0점, 소형 모델 중 최고\n8GB 이상\n멀티모달 기능, Google 개발\n\n\nPhi-3\n3.8B\nMMLU 68.8점, GPT-3.5 유사\n8GB (4비트 양자화 시 1.8GB)\n모바일 최적화, Microsoft 개발\n\n\nQwen 2.5\n3B\nMMLU 65.0점, 다국어 지원 탁월\n6GB 이상\n29개 언어 지원, Alibaba 개발\n\n\n\n\n⚠️ 주의: 매개변수 크기가 작다고 무조건 성능이 낮은 것은 아닙니다! Phi-3나 Gemma 3처럼 작지만 효율적인 훈련을 통해 대형 모델에 버금가는 성능을 내는 경우도 있으니, 벤치마크 점수를 꼼꼼히 확인하는 것이 중요합니다.\n  경량 등급 (2B 이하 매개변수)\n이 등급의 모델들은 낮은 사양의 기기에서도 가볍게 구동할 수 있다는 것이 가장 큰 장점이에요. 스마트폰이나 구형 노트북에서도 AI를 경험하고 싶다면 이 모델들이 아주 좋은 출발점이 될 수 있습니다.\n모델명\n매개변수\n주요 성능\n메모리 요구량\n특징 및 권장 대상\n\n\n\n\nGemma 2\n2B\nMMLU 42.3점, GPT-3.5 일부 벤치마크 능가\n4GB 이상\n작은 크기 대비 고성능, 빠른 처리 속도\n\n\nDeepSeek-R1\n1.5B\n수학 추론 특화\n3GB 이상\nCPU만으로도 실행 가능, 강화학습 훈련\n\n\n\n\n  하드웨어별 최적 온디바이스 AI 모델 추천 가이드\n모델의 성능만큼 중요한 것이 바로 내 디바이스와의 궁합이죠! 아무리 좋은 모델이라도 내 하드웨어에서 제대로 돌아가지 않는다면 무용지물이니까요. 여러분의 디바이스 사양에 맞춰 최적의 온디바이스 AI 모델을 추천해 드릴게요.\n\n\n\n고성능 게이밍 PC (RTX 4080/4090)\n추천 모델: GPT-OSS 20B 또는 Llama 3.1 8B\n- 40GB 이상의 VRAM으로 대용량 모델도 거뜬히! 최고 수준의 AI 성능을 만끽하고 싶은 전문가에게 제격입니다.\n중급 게이밍 PC (RTX 3070/4060Ti)\n추천 모델: Mistral 7B 또는 Gemma 3 4B\n- 12-16GB의 VRAM을 가진 기기에서 균형 잡힌 성능을 제공합니다. 대부분의 AI 작업에 부족함 없는 성능을 보여줄 거예요.\n보급형 PC/노트북 (RTX 3060/통합 그래픽)\n추천 모델: Phi-3 3.8B 또는 Qwen 2.5 3B\n- 8GB 이하 메모리로도 충분히 실행 가능한 모델들입니다. 온디바이스 AI 초보자들에게 가장 접근성이 좋고, 설정도 쉬울 거예요.\n모바일/저사양 기기 (스마트폰, 구형 태블릿)\n추천 모델: Gemma 2 2B 또는 DeepSeek-R1 1.5B\n- CPU만으로도 실행 가능한 모델들이 많습니다. 스마트폰에서도 가볍게 AI 기능을 활용하고 싶다면 이들을 추천합니다.\n  용도별 온디바이스 AI 모델 선택 가이드\n어떤 용도로 AI를 사용할지에 따라 최적의 모델은 달라질 수 있습니다. 마치 망치와 드라이버를 적재적소에 사용하는 것처럼요! 여러분의 주요 사용 목적에 맞춰 가장 효율적인 모델을 찾아보세요.\n학습 및 교육 목적\n추천 모델: Phi-3 3.8B\n- 이유: 교육 데이터로 특별히 훈련되어 수학, 과학 문제 해결 능력이 탁월합니다. 학생들이 학습 보조 도구로 활용하기에 아주 좋습니다.\n- 설치 난이도: 쉬움\n일반적인 대화 및 질답\n추천 모델: Llama 3.1 8B 또는 Gemma 3 4B\n- 이유: 균형 잡힌 성능으로 다양한 주제에 자연스럽게 대응합니다. 정확도도 높아서 일상적인 대화나 궁금증 해결에 적합합니다.\n- 설치 난이도: 보통\n이미지 분석 및 멀티모달 작업\n추천 모델: LLaVA 7B 또는 Gemma 3 4B\n- 이유: 텍스트뿐만 아니라 이미지를 동시에 처리하는 멀티모달 기능을 제공합니다. 이미지 설명, 시각적 질문 답변 등 시각적인 작업에 강점을 보입니다.\n- 설치 난이도: 어려움 (LLaVA의 경우)\n프로그래밍 및 코드 생성\n추천 모델: Qwen 2.5 3B 또는 Mistral 7B\n- 이유: 코딩 벤치마크에서 우수한 성능을 보여줍니다. Python, JavaScript 등 다양한 프로그래밍 언어를 지원하여 개발자들에게 큰 도움이 될 거예요.\n- 설치 난이도: 보통\n다국어 번역 및 처리\n추천 모델: Qwen 2.5 3B\n- 이유: 무려 29개 언어를 지원하며 다국어 처리에 최적화되어 있습니다. 한국어를 포함한 아시아 언어 처리 능력도 우수해서 해외 자료를 다루거나 번역할 때 유용합니다.\n- 설치 난이도: 보통\n  효율성과 가성비, 초보자를 위한 최고의 선택은?\n모델 선택에 있어 성능만큼이나 중요한 것이 바로 '효율성'과 '가성비'입니다. 특히 온디바이스 AI에서는 제한된 리소스 내에서 얼마나 똑똑하게 작동하는지가 관건이죠. 제가 간단한 지표를 만들어 효율성을 계산해 봤어요. (효율성 점수 = (처리속도 × MMLU 점수) ÷ 메모리 요구량)\n최고 효율성 모델들\nPhi-3 (3.8B): 효율성 점수 23.75 - 작은 크기 대비 최고의 성능을 자랑합니다. Microsoft가 괜히 모바일 최적화에 힘쓴 게 아니겠죠?\nGemma 3 (4B): 효율성 점수 22.5 - 멀티모달 기능을 포함하면서도 뛰어난 균형 잡힌 성능을 보여줍니다. Google의 역량이 느껴지는 부분이에요.\nQwen 2.5 (3B): 효율성 점수 30.83 - 특히 다국어 지원까지 고려하면 이 모델은 정말 독보적인 효율성을 보여준다고 생각해요.\n가성비 분석: 초보자에게 딱!\n제 개인적인 경험과 분석을 종합해 볼 때, 초보자 여러분에게 최고의 가성비 모델은 단연 Phi-3 3.8B라고 말씀드리고 싶습니다. 낮은 하드웨어 요구사항에도 불구하고 GPT-3.5와 유사한 수준의 뛰어난 성능을 보여주니, 이보다 더 좋을 순 없겠죠. 또한 Microsoft의 적극적인 지원까지 더해져 안정성도 높습니다. 만약 조금 더 욕심을 내서 멀티모달 기능을 경험하고 싶다면, Gemma 3 4B도 훌륭한 대안이 될 것입니다. Google이 지속적으로 업데이트하고 있으니 미래도 밝고요.\n ️ 온디바이스 AI, 어떻게 시작할까요? (설치 및 사용 가이드)\n'설치가 어렵진 않을까?' 하고 걱정하시는 분들이 많을 텐데요, 솔직히 예전에는 그랬습니다. 하지만 요즘은 초보자도 쉽게 따라 할 수 있는 플랫폼들이 많이 나와서 걱정할 필요가 없어요. 제가 추천하는 단계별 가이드를 따라 해보세요!\n초보자를 위한 단계별 가이드\n1단계: 하드웨어 확인\n- 가장 먼저 내 PC의 GPU 메모리 (VRAM), RAM 용량, 그리고 모델을 설치할 충분한 저장공간이 있는지 확인해야 합니다. 모델당 2GB에서 40GB까지 필요할 수 있으니 넉넉한 공간을 확보해 두세요.\n2단계: 플랫폼 선택\n- Ollama: 가장 초보자 친화적이고, 원클릭 설치로 빠르게 시작할 수 있어요.\n- LM Studio: 직관적인 GUI와 모델 마켓플레이스를 내장하고 있어서 여러 모델을 쉽게 탐색하고 실행할 수 있습니다.\n- GPT4All: 크로스플랫폼을 지원하고 CPU에 최적화되어 있어서 GPU가 없는 환경에서도 AI를 경험할 수 있습니다.\n3단계: 모델 다운로드 및 실행\n- 선택한 플랫폼에서 원하는 모델을 다운로드하고 실행하면 끝! 예를 들어, Ollama를 사용한다면 다음과 같이 간단한 명령어로 실행할 수 있습니다.\n # Ollama 사용 예시 ollama pull phi3 ollama run phi3 \n  온디바이스 AI의 미래, 2025년은 어떤 변화가?\n온디바이스 AI는 정말 빠르게 발전하고 있는 분야입니다. 2025년에는 또 어떤 놀라운 변화가 우리를 기다리고 있을까요? 제가 예측하는 몇 가지 주요 발전 방향을 공유해 드릴게요.\n모델 크기 최적화 트렌드\n최근 연구들을 보면, 더 작은 모델들이 대형 모델과 비슷하거나 심지어 더 나은 성능을 보여주는 경우가 늘고 있습니다. 예를 들어, Gemma 2 2B 모델이 GPT-3.5보다 일부 벤치마크에서 우수한 성능을 보였다는 것은 정말 놀라운 일이죠. 앞으로는 무작정 큰 모델보다는 효율적인 구조와 훈련 방법을 통해 성능을 극대화한 '작지만 강한' 모델들이 주류가 될 것입니다.\n하드웨어 발전의 영향\nNPU(Neural Processing Unit) 통합: 차세대 CPU에는 AI 전용 프로세서인 NPU가 내장될 거예요. 이는 온디바이스 AI의 처리 속도와 효율성을 획기적으로 향상시킬 것입니다.\n메모리 효율성 개선: 양자화(Quantization) 같은 기술 덕분에 AI 모델의 메모리 사용량이 75%까지 감소할 수 있습니다. 이는 더 많은 모델을 더 작은 기기에서 실행할 수 있게 해줍니다.\n모바일 최적화 가속화: 스마트폰에서도 7B 매개변수 모델을 실시간으로 실행하는 것이 머지않아 현실이 될 겁니다. 정말 기대되지 않나요?\n2025년 예상 발전사항\n1B 매개변수 모델이 현재의 3B 수준 성능을 달성할 것입니다.\n텍스트-이미지, 텍스트-오디오 등 멀티모달 기능이 온디바이스 AI의 표준이 될 거예요.\n사용자의 패턴을 학습하여 스스로 진화하는 실시간 학습 및 개인화 기능이 더욱 강화될 것입니다.\n\n\n\n  핵심 요약\n• 온디바이스 AI는 클라우드 비용 없이 개인정보를 안전하게 지키며 AI를 사용할 수 있게 합니다.\n• Phi-3 3.8B는 낮은 하드웨어 요구사항과 뛰어난 성능으로 초보자에게 가장 적합한 가성비 모델입니다.\n• Gemma 3 4B는 멀티모달 기능을 제공하며, 균형 잡힌 성능으로 중급 사용자에게 훌륭한 선택입니다.\n• 2025년에는 더 작고 효율적인 모델, NPU 통합, 모바일 최적화가 가속화될 전망입니다.\n사용자의 하드웨어 환경과 목적에 맞는 모델을 신중하게 선택하는 것이 중요하며, 작은 모델부터 시작하여 경험을 쌓는 것을 권장합니다.\n❓ 자주 묻는 질문 (FAQ)\nQ1: 온디바이스 AI는 왜 주목받고 있나요?\nA1: 개인정보 보호, 빠른 응답 속도, 인터넷 연결 없이 사용 가능, 그리고 클라우드 서비스 비용 절감이라는 강력한 장점들 때문입니다. 특히 2025년에는 이러한 장점들이 더욱 부각될 것으로 예상됩니다.\nQ2: 온디바이스 AI를 사용하려면 고사양 PC가 필수인가요?\nA2: 아니요, 꼭 그렇지는 않습니다. Phi-3 3.8B나 Gemma 2 2B 같은 경량 모델들은 8GB 이하의 메모리나 노트북 통합 그래픽으로도 충분히 실행할 수 있습니다. 심지어 CPU만으로도 가능한 모델들도 있어요. 중요한 건 자신의 하드웨어 사양에 맞는 모델을 선택하는 것입니다.\nQ3: 온디바이스 AI 모델 설치는 어려운가요?\nA3: 요즘은 Ollama, LM Studio, GPT4All과 같은 사용자 친화적인 플랫폼 덕분에 설치가 매우 쉬워졌어요. 몇 번의 클릭만으로 모델을 다운로드하고 실행할 수 있습니다. 초보자도 쉽게 시작할 수 있도록 가이드가 잘 되어 있어요.\nQ4: 멀티모달 기능이 있는 온디바이스 AI 모델도 있나요?\nA4: 네, 물론입니다! Gemma 3 4B나 LLaVA 7B 같은 모델들은 텍스트뿐만 아니라 이미지를 동시에 처리하는 멀티모달 기능을 지원합니다. 이미지 설명이나 시각적 질문 답변 등 다양한 멀티모달 작업을 온디바이스에서 경험할 수 있습니다.\n { \"@context\": \"https://schema.org\", \"@type\": \"FAQPage\", \"mainEntity\": [ { \"@type\": \"Question\", \"name\": \"온디바이스 AI는 왜 주목받고 있나요?\", \"acceptedAnswer\": { \"@type\": \"Answer\", \"text\": \"개인정보 보호, 빠른 응답 속도, 인터넷 연결 없이 사용 가능, 그리고 클라우드 서비스 비용 절감이라는 강력한 장점들 때문입니다. 특히 2025년에는 이러한 장점들이 더욱 부각될 것으로 예상됩니다.\" } }, { \"@type\": \"Question\", \"name\": \"온디바이스 AI를 사용하려면 고사양 PC가 필수인가요?\", \"acceptedAnswer\": { \"@type\": \"Answer\", \"text\": \"아니요, 꼭 그렇지는 않습니다. Phi-3 3.8B나 Gemma 2 2B 같은 경량 모델들은 8GB 이하의 메모리나 노트북 통합 그래픽으로도 충분히 실행할 수 있습니다. 심지어 CPU만으로도 가능한 모델들도 있어요. 중요한 건 자신의 하드웨어 사양에 맞는 모델을 선택하는 것입니다.\" } }, { \"@type\": \"Question\", \"name\": \"온디바이스 AI 모델 설치는 어려운가요?\", \"acceptedAnswer\": { \"@type\": \"Answer\", \"text\": \"요즘은 Ollama, LM Studio, GPT4All과 같은 사용자 친화적인 플랫폼 덕분에 설치가 매우 쉬워졌어요. 몇 번의 클릭만으로 모델을 다운로드하고 실행할 수 있습니다. 초보자도 쉽게 시작할 수 있도록 가이드가 잘 되어 있어요.\" } }, { \"@type\": \"Question\", \"name\": \"멀티모달 기능이 있는 온디바이스 AI 모델도 있나요?\", \"acceptedAnswer\": { \"@type\": \"Answer\", \"text\": \"네, 물론입니다! Gemma 3 4B나 LLaVA 7B 같은 모델들은 텍스트뿐만 아니라 이미지를 동시에 처리하는 멀티모달 기능을 지원합니다. 이미지 설명이나 시각적 질문 답변 등 다양한 멀티모달 작업을 온디바이스에서 경험할 수 있습니다.\" } } ] } \n✨ 마무리하며: 나만의 AI 비서를 만나다\n오늘 온디바이스 AI의 세계에 대해 깊이 파고들어 봤습니다. 클라우드 비용 걱정 없이, 개인정보는 안전하게 보호하면서 AI를 활용할 수 있다는 점은 정말 매력적이죠. 저 역시 이런 기술의 발전에 큰 흥미를 느끼고 있어요. 중요한 건 자신의 하드웨어 환경과 사용 목적을 명확히 설정한 후, 그에 맞는 모델을 신중하게 선택하는 것이라는 점을 꼭 기억해 주셨으면 좋겠습니다.\n큰 모델이 항상 정답은 아니며, 효율성과 실용성을 고려한 선택이 여러분에게 더 만족스러운 경험을 선사할 거예요. 지금부터라도 자신에게 맞는 온디바이스 AI 모델을 찾아보고, 그 잠재력을 최대한 활용해 보시길 강력히 추천합니다. AI 기술은 멈추지 않고 발전하고 있으니, 새로운 모델이 나올 때마다 호기심을 갖고 탐구하는 자세도 잊지 마세요! 여러분의 일상과 업무가 온디바이스 AI를 통해 더욱 스마트하고 편리해지기를 바랍니다.",
        "guid": "http://muzbox.tistory.com/483655",
        "categories": [
          "AI, 미래기술/AI 인사이트",
          "2025 ai 트렌드",
          "ai 성능 비교",
          "Gemma 3",
          "llama 3.1",
          "Phi-3",
          "개인정보 보호 ai",
          "로컬 ai",
          "무료 AI 모델",
          "온디바이스 AI",
          "클라우드 비용 절감"
        ],
        "isoDate": "2025-09-11T23:23:12.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "포토샵은 옛말? 2025년, 나노바나나로 사진 편집 끝내기!",
        "link": "http://muzbox.tistory.com/483654",
        "pubDate": "Thu, 11 Sep 2025 10:59:40 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483654#entry483654comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #212121;\">\n<div style=\"background-color: #e8f5e9; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">사진 편집, 아직도 어렵고 복잡하게 느끼시나요? 포토샵의 높은 문턱에 좌절했던 분들이라면 주목해주세요! 2025년, 구글 Gemini의 강력한 AI 모델 '나노바나나'가 사진 편집의 판도를 바꾸고 있습니다. 초보자도 전문가처럼, 단 몇 번의 대화만으로 놀라운 결과물을 얻을 수 있는 이 혁신적인 도구에 대해 자세히 알아보겠습니다.</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  포토샵은 옛말? AI 기반 이미지 편집의 도래</b></h2>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/61OYq/btsQshqWRgm/NMdduKZK2KxeW2tVaUKPQK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/61OYq/btsQshqWRgm/NMdduKZK2KxeW2tVaUKPQK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/61OYq/btsQshqWRgm/NMdduKZK2KxeW2tVaUKPQK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F61OYq%2FbtsQshqWRgm%2FNMdduKZK2KxeW2tVaUKPQK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"복잡한 포토샵 인터페이스와 대조되는 간단한 나노바나나 AI 편집 인터페이스를 보여주는 미래지향적 이미지. 사용자가 홀로그램 화면에서 사진을 편집하는 모습\" loading=\"lazy\" width=\"500\" height=\"500\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">예전에는 멋진 사진을 만들려면 포토샵 같은 전문 프로그램을 다루는 기술이 필수적이었죠. 하지만 수십 가지의 도구와 슬라이더, 복잡한 레이어 개념까지&hellip; 숙련된 편집자가 아니라면 원하는 결과를 얻기란 여간 어려운 일이 아니었습니다. 저 역시 처음 포토샵을 배울 때 수많은 튜토리얼을 찾아보며 진땀을 뺐던 기억이 생생합니다. 바로 이런 지점에서 AI 기술이 사진 편집의 새로운 지평을 열고 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">최근 저는 제 셀피를 픽셀(Pixel)의 AI 편집 기능으로 수정해봤는데, 결과가 정말 훌륭했어요. 그러나 이제는 Gemini를 통해 편집하면 포토샵이 필요 없을 정도로 놀라운 경험을 할 수 있게 되었습니다. 특히 Gemini의 최신 모델인 <b>&lsquo;나노바나나(Nano Banana)&rsquo;</b>는 이미지 편집에 특화되어, 마치 마법처럼 사진을 변신시켜줍니다.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✂️ 포토샵, 그 익숙함 뒤의 불편함</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">포토샵은 분명 놀라운 소프트웨어입니다. 전문적인 결과물을 만들어낼 수 있는 다양한 도구들을 제공하며, 일부는 AI 기술로 구동되기도 하죠. 막히는 부분이 있다면 인터넷에 넘쳐나는 튜토리얼이 큰 도움이 됩니다. 하지만 포토샵을 제대로 활용하려면 몇 가지 넘어야 할 산이 있습니다.</p>\n<h3 style=\"font-size: 19px; color: #2e7d32; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>높은 진입 장벽: 기술과 비용</b></h3>\n<ul style=\"list-style-type: disc; margin-left: 20px; margin-bottom: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px;\"><b>기술적 난이도:</b> 포토샵은 일정 수준의 기술 숙련도를 요구합니다. 수많은 기능들을 익히는 데 상당한 시간과 노력이 필요하죠.</li>\n<li style=\"margin-bottom: 10px;\"><b>고사양 컴퓨터:</b> 프로그램을 원활하게 실행하려면 강력한 사양의 컴퓨터가 필요합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>구독료 부담:</b> 어도비(Adobe)의 구독료는 적지 않은 재정적 투자를 요구합니다. 첫 사진을 열어보기도 전에 비용 지불이 선행되어야 합니다.</li>\n</ul>\n<h3 style=\"font-size: 19px; color: #2e7d32; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>복잡한 사용법과 시간 투자</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">물론 포토샵이 제공하는 정밀한 제어 기능은 훌륭합니다. 하지만 사실 전문 사진작가나 그래픽 디자이너가 아니라면 그 모든 기능이 다 필요하지 않을 때가 많습니다. 대부분의 일반적인 사진 편집에는 포토샵이 제공하는 복잡성이 과도하게 느껴질 수 있습니다. 가파른 학습 곡선 때문에 원하는 결과물을 얻기까지 오랜 시간 시행착오를 겪어야 한다는 점도 큰 부담입니다.</p>\n<div style=\"background-color: #e8f5e9; border-left: 4px solid #2e7d32; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>팁!</b> 전문적인 작업이 아니라면, 포토샵 대신 무료로 이용할 수 있는 다양한 대체 프로그램들도 많습니다. 하지만 AI 편집 도구는 그마저도 뛰어넘는 간편함을 제공하죠.</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  나노바나나의 등장: 이미지 편집의 새로운 기준</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">Gemini의 <b>2.5 Flash 모델, 코드명 나노바나나(Nano Banana)</b>는 이미지 편집의 패러다임을 완전히 바꾸고 있습니다. 이제 수백 개의 슬라이더와 도구를 조작하는 대신, 여러분이 원하는 변경 사항을 단순히 입력하거나 말하기만 하면 Gemini가 알아서 편집을 처리해 줍니다. 정말 놀랍지 않나요?</p>\n<h3 style=\"font-size: 19px; color: #2e7d32; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>간편함의 미학: 직관적인 AI 편집</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">나노바나나를 사용하는 방법은 매우 간단합니다. 데스크톱에서 Gemini 웹사이트에 접속하거나 Gemini 앱을 열고 <b>&lsquo;이미지 생성(Create images)&rsquo; 모드</b>를 선택합니다. 그 다음, <b>&ldquo;+&rdquo; 아이콘</b>을 눌러 편집하고 싶은 이미지를 업로드하고 원하는 편집 내용을 텍스트로 입력하기만 하면 됩니다. 정말 이보다 더 쉬울 수 있을까요?</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">구독료도, 고사양 컴퓨터도 필요 없습니다. 그냥 원하는 편집을 Gemini에게 알려주기만 하면 끝입니다. 나노바나나는 특히 다음과 같은 작업에 매우 강력한 성능을 보여줍니다.</p>\n<table style=\"width: 100%; border-collapse: collapse; margin: 20px 0; border: 1px solid #a5d6a7; color: #212121;\" data-ke-align=\"alignLeft\">\n<thead style=\"background-color: #c8e6c9;\">\n<tr>\n<th style=\"padding: 10px; border: 1px solid #a5d6a7; text-align: left; color: #212121;\">기능</th>\n<th style=\"padding: 10px; border: 1px solid #a5d6a7; text-align: left; color: #212121;\">설명</th>\n</tr>\n</thead>\n<tbody>\n<tr style=\"background-color: #f1f8e9;\">\n<td style=\"padding: 10px; border: 1px solid #a5d6a7; color: #212121;\"><b>객체 제거 및 추가</b></td>\n<td style=\"padding: 10px; border: 1px solid #a5d6a7; color: #212121;\">사진 속 불필요한 요소를 지우거나 새로운 객체를 자연스럽게 추가합니다.</td>\n</tr>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #a5d6a7; color: #212121;\"><b>배경 교체</b></td>\n<td style=\"padding: 10px; border: 1px solid #a5d6a7; color: #212121;\">원하는 배경으로 사진의 분위기를 완전히 바꿀 수 있습니다.</td>\n</tr>\n<tr style=\"background-color: #f1f8e9;\">\n<td style=\"padding: 10px; border: 1px solid #a5d6a7; color: #212121;\"><b>이미지 간 스타일 전환</b></td>\n<td style=\"padding: 10px; border: 1px solid #a5d6a7; color: #212121;\">특정 이미지의 스타일을 다른 이미지에 적용하여 독특한 결과물을 만듭니다.</td>\n</tr>\n<tr>\n<td style=\"padding: 10px; border: 1px solid #a5d6a7; color: #212121;\"><b>색상 및 조명 조정</b></td>\n<td style=\"padding: 10px; border: 1px solid #a5d6a7; color: #212121;\">사진의 색감과 밝기를 최적화하여 분위기를 살립니다.</td>\n</tr>\n<tr style=\"background-color: #f1f8e9;\">\n<td style=\"padding: 10px; border: 1px solid #a5d6a7; color: #212121;\"><b>여러 사진 합성</b></td>\n<td style=\"padding: 10px; border: 1px solid #a5d6a7; color: #212121;\">두 장 이상의 사진을 자연스럽게 하나로 합쳐줍니다.</td>\n</tr>\n</tbody>\n</table>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b> ️ 대화형 편집: 창의력의 날개를 달다</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">나노바나나로 사진을 편집할 때 가장 매력적인 점은 바로 <b>&lsquo;다단계 대화형 편집&rsquo;</b>이 가능하다는 것입니다. 한 번의 프롬프트에서 모든 변경 사항을 지정할 필요 없이, 마치 친구와 대화하듯 편집을 이어나갈 수 있습니다. 예를 들어, 첫 번째 요청으로 하늘을 바꾸고, 다음 요청으로 조명을 미세하게 조절하거나 배경 요소를 추가&middot;삭제하는 식이죠.</p>\n<h3 style=\"font-size: 19px; color: #2e7d32; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>단계별 편집의 자유</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이러한 대화형 편집 방식은 여러분의 편집 경험 자체를 변화시킵니다. 더 이상 복잡한 도구와 기술 수준에 얽매이지 않고, 오롯이 자신의 <b>창의적인 아이디어</b> 구현에 집중할 수 있게 됩니다. 편집 속도가 빠르고 노력도 적게 들기 때문에, 다양한 아이디어를 주저 없이 시도해볼 수 있다는 것도 큰 장점입니다. 이제는 기술이 아니라 여러분의 창의적인 비전이 편집의 중심이 됩니다.</p>\n<h3 style=\"font-size: 19px; color: #2e7d32; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>음성 편집, 아직은 성장 중</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">만약 타이핑이 번거롭다면, 음성 모드로 전환해 Gemini에게 말로 편집을 요청할 수도 있습니다. 하지만 제 경험상 아직 음성 모드는 완벽하게 작동하지는 않았습니다. 가끔 설명 없는 오류가 반복적으로 발생하곤 했어요. 원인은 알 수 없지만, 텍스트 입력은 언제나 안정적으로 작동했으니 참고하시면 좋겠습니다.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✍️ 나노바나나 프롬프트, 이렇게 활용해 보세요!</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">나노바나나의 AI 편집 능력은 여러분의 프롬프트에 달려있습니다. 원하는 결과를 얻기 위해서는 명확하고 구체적인 설명이 중요합니다. 다음은 효과적인 프롬프트를 작성하기 위한 몇 가지 팁입니다.</p>\n<ul style=\"list-style-type: disc; margin-left: 20px; margin-bottom: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px;\"><b>구체적인 지시:</b> 단순히 &lsquo;배경을 바꿔줘&rsquo;보다는 &lsquo;배경을 울창한 열대우림으로 바꿔주고, 빛은 나뭇잎 사이로 스며드는 듯한 효과를 줘&rsquo;와 같이 구체적으로 설명해주세요.</li>\n<li style=\"margin-bottom: 10px;\"><b>명확한 목표:</b> &lsquo;사진을 더 밝게&rsquo;보다는 &lsquo;전체적으로 따뜻한 색감으로 밝기를 한 단계 올려줘&rsquo;와 같이 목표를 명확히 제시합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>단계별 접근:</b> 복잡한 편집은 한 번에 처리하기보다 여러 단계로 나누어 요청하는 것이 좋습니다. 예를 들어, 먼저 객체를 제거하고, 그 다음 배경을 교체한 후, 마지막으로 색상 보정을 하는 식입니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>예시 활용:</b> 특정 스타일이나 느낌을 원한다면, &lsquo;인상주의 화풍으로 바꿔줘&rsquo;처럼 예시를 들어 설명할 수도 있습니다.</li>\n</ul>\n<div style=\"background-color: #e8f5e9; border-left: 4px solid #2e7d32; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>팁!</b> 처음에는 간단한 편집부터 시작하여 나노바나나의 작동 방식을 익히는 것이 좋습니다. 점점 더 복잡한 요청을 시도하며 여러분만의 노하우를 쌓아가세요!</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>⏱️ 복잡한 작업도 순식간에: 시간 절약의 마법</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">포토샵에서 배경을 바꾸는 단순한 작업조차 숙련자에게도 몇 분, 초보자에게는 몇 시간이 걸릴 수 있습니다. 레이어 작업이나 마스킹을 통해 객체를 제거하거나 배경을 교체하고, 요소를 옮기는 데 많은 집중과 시간이 필요하죠. 하지만 나노바나나에서는 같은 작업을 불과 몇 초 만에 끝낼 수 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">제가 직접 경험한 일화가 있습니다. 친구가 자전거 사고를 당해서 병원에 있었고, 사고 난 자전거 사진을 보내주기를 원했어요. 손상된 자전거가 수리점으로 운반 중인 사진이었는데, 저는 나노바나나에게 사진을 산속에 주차된 것처럼 편집해 달라고 요청했습니다. 결과는 정말 놀라웠어요! 자전거와 헬멧까지 정확하게 표현했고, 심지어 그림자, 조명, 흙먼지까지 자연스럽게 반영되어 있었죠. 이 정도 편집을 포토샵에서 했다면 훨씬 오랜 시간이 걸렸을 뿐 아니라 반드시 책상 앞에 앉아 작업해야 했을 겁니다. 나노바나나는 워터마크 제거, 배경 교체, 객체 추가&middot;삭제를 거의 요청과 동시에 수행해냅니다.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✅ 일관성 유지: AI 편집의 신뢰성 확보</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">기존 AI 편집 도구의 가장 큰 문제점 중 하나는 바로 <b>&lsquo;일관성&rsquo;</b>이었습니다. 특히 인물의 얼굴이나 주요 피사체가 편집 과정에서 미묘하게 바뀌어 버리는 경우가 많았죠. 나 자신이나 지인의 사진을 편집할 때 작은 변화만 있어도 어색하게 느껴질 수 있습니다. 비슷하지만 똑같지 않은 AI 편집 결과물은 사실상 쓸모가 없었습니다.</p>\n<h3 style=\"font-size: 19px; color: #2e7d32; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>인물, 반려동물 사진 편집의 안정성</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">하지만 구글은 Gemini, 특히 나노바나나를 개발하면서 이러한 문제점을 해결하는 데 집중했습니다. 나노바나나는 사람, 가족, 친구, 반려동물의 사진을 편집할 때 원래 모습의 <b>일관성을 유지</b>할 수 있도록 설계되었습니다. 따라서 어떤 편집을 하든 인물의 모습은 그대로 유지될 가능성이 매우 큽니다. 이제 AI가 임의로 추가하는 왜곡된 결과물이 아닌, 여러분이 지정한 편집만 정확히 반영된 결과물을 기대할 수 있습니다.</p>\n<h3 style=\"font-size: 19px; color: #2e7d32; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>여러 사진 합성도 자연스럽게</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이러한 일관성 유지 기능은 특히 여러 이미지를 합성하여 한 장의 결과물을 만들 때 더욱 유용합니다. 두 장의 사진 속에 있던 사람들이 하나의 프레임에 함께 있어도 각자의 모습이 자연스럽게 유지되는 것을 확인할 수 있습니다. 이제 여러분의 소중한 추억을 AI의 도움으로 더욱 아름답게 만들 수 있습니다.</p>\n<div style=\"background-color: #f1f8e9; border: 1px solid #a5d6a7; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); padding: 25px; margin: 40px 0;\">\n<div style=\"font-size: 26px; color: #2e7d32; font-weight: bold; margin-bottom: 15px; padding-bottom: 10px; border-bottom: 2px solid #2e7d32;\">  핵심 요약</div>\n<ul style=\"list-style-type: none; padding: 0; margin: 0;\" data-ke-list-type=\"disc\">\n<li style=\"font-size: 17px; margin-bottom: 15px;\">✅ <b>간편한 접근성:</b> 포토샵과 달리 고사양 PC나 유료 구독 없이 Gemini 웹사이트나 앱에서 즉시 이용 가능합니다.</li>\n<li style=\"font-size: 17px; margin-bottom: 15px;\">✅ <b>직관적인 대화형 편집:</b> 복잡한 도구 없이 자연어 프롬프트(텍스트 또는 음성)로 원하는 편집을 명령할 수 있습니다.</li>\n<li style=\"font-size: 17px; margin-bottom: 15px;\">✅ <b>시간 절약과 효율성:</b> 배경 교체, 객체 제거 등 복잡한 작업도 수 초 만에 처리하여 작업 시간을 혁신적으로 단축합니다.</li>\n<li style=\"font-size: 17px; margin-bottom: 0;\">✅ <b>일관성 유지:</b> 인물이나 주요 피사체의 원래 모습을 정확히 보존하며, 여러 사진 합성 시에도 자연스러운 결과물을 제공합니다.</li>\n</ul>\n<div style=\"font-size: 14px; color: #aed581; margin-top: 20px; padding-top: 15px; border-top: 1px dashed #aed581;\">나노바나나는 전문가뿐만 아니라 일반 사용자에게도 사진 편집의 즐거움을 선사하는 강력한 도구입니다. 지금 바로 경험해보세요!</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b> ️ 대화형 편집: 창의력의 날개를 달다</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">1.&nbsp; 애니메이션을 실제 모델로 변경</p>\n<pre class=\"livecodeserver\" style=\"background-color: #f6f8fa; color: #1f2328; text-align: start;\"><code>Generate a photo of a girl cosplaying this illustration, with the background set at Comiket</code></pre>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"919\" data-origin-height=\"498\"><span data-url=\"https://blog.kakaocdn.net/dn/k9kki/btsQupVsMxw/UpwFOU8O9U0tzycTCuGUsK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/k9kki/btsQupVsMxw/UpwFOU8O9U0tzycTCuGUsK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/k9kki/btsQupVsMxw/UpwFOU8O9U0tzycTCuGUsK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fk9kki%2FbtsQupVsMxw%2FUpwFOU8O9U0tzycTCuGUsK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"919\" height=\"498\" data-origin-width=\"919\" data-origin-height=\"498\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><span style=\"color: #212121; text-align: start;\">2.&nbsp; 다양한 헤어스타일로 변경</span></p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1053\" data-origin-height=\"504\"><span data-url=\"https://blog.kakaocdn.net/dn/GifWq/btsQrHXWJpG/n5I38rKPEZ0Lo7gb9GZy90/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/GifWq/btsQrHXWJpG/n5I38rKPEZ0Lo7gb9GZy90/img.png\"><img src=\"https://blog.kakaocdn.net/dn/GifWq/btsQrHXWJpG/n5I38rKPEZ0Lo7gb9GZy90/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FGifWq%2FbtsQrHXWJpG%2Fn5I38rKPEZ0Lo7gb9GZy90%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1053\" height=\"504\" data-origin-width=\"1053\" data-origin-height=\"504\"/></span></figure>\n\n<pre class=\"livecodeserver\" style=\"background-color: #f6f8fa; color: #1f2328; text-align: start;\"><code>Generate avatars of this person with different hairstyles in a 3x3 grid format</code></pre>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">&nbsp;3<span style=\"color: #212121; text-align: start;\">.&nbsp; 드로잉과 사진의 합성</span></p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"123123-horz.jpg\" data-origin-width=\"1000\" data-origin-height=\"434\"><span data-url=\"https://blog.kakaocdn.net/dn/xsRpB/btsQuhDapSI/1j14eWaNsVbagvzuFoDgu1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/xsRpB/btsQuhDapSI/1j14eWaNsVbagvzuFoDgu1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/xsRpB/btsQuhDapSI/1j14eWaNsVbagvzuFoDgu1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FxsRpB%2FbtsQuhDapSI%2F1j14eWaNsVbagvzuFoDgu1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1000\" height=\"434\" data-filename=\"123123-horz.jpg\" data-origin-width=\"1000\" data-origin-height=\"434\"/></span></figure>\n\n<pre class=\"livecodeserver\" style=\"background-color: #f6f8fa; color: #1f2328; text-align: start;\"><code>Change the pose of the person in Figure 1 to that of Figure 2, and shoot in a professional studio</code></pre>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<div style=\"margin-bottom: 15px;\">\n<p style=\"font-weight: bold; color: #2e7d32; margin-bottom: 5px;\" data-ke-size=\"size16\">Q1: 나노바나나는 포토샵을 완전히 대체할 수 있나요?</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A1: 나노바나나는 일반적인 사진 편집 작업을 매우 쉽고 빠르게 처리하여 포토샵의 필요성을 크게 줄여줍니다. 하지만 그래픽 디자인이나 고도로 정밀한 수작업이 필요한 전문적인 작업에서는 여전히 포토샵이 주된 도구로 사용될 수 있습니다. 나노바나나는 포토샵의 훌륭한 대안이자 보완재 역할을 합니다.</p>\n</div>\n<div style=\"margin-bottom: 15px;\">\n<p style=\"font-weight: bold; color: #2e7d32; margin-bottom: 5px;\" data-ke-size=\"size16\">Q2: 나노바나나를 사용하려면 별도 프로그램 설치나 구독이 필요한가요?</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A2: 아니요, Gemini의 2.5 Flash 모델인 나노바나나는 Gemini 웹사이트나 앱에서 &lsquo;이미지 생성&rsquo; 모드를 통해 바로 사용할 수 있습니다. 별도의 프로그램 설치나 유료 구독 없이 무료로 주요 편집 기능을 이용할 수 있어 접근성이 매우 뛰어납니다.</p>\n</div>\n<div style=\"margin-bottom: 15px;\">\n<p style=\"font-weight: bold; color: #2e7d32; margin-bottom: 5px;\" data-ke-size=\"size16\">Q3: AI 편집 시 인물이나 배경이 부자연스러워지지는 않나요?</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A3: 나노바나나는 인물, 가족, 친구, 반려동물 등의 주요 피사체를 편집할 때 원래 모습의 일관성을 유지하도록 설계되었습니다. 배경 교체나 객체 추가 시에도 자연스러운 그림자, 조명, 질감을 반영하여 전체적인 조화를 해치지 않는 뛰어난 결과물을 제공합니다.</p>\n</div>\n<script type=\"application/ld+json\">\n    {\n      \"@context\": \"https://schema.org\",\n      \"@type\": \"FAQPage\",\n      \"mainEntity\": [\n        {\n          \"@type\": \"Question\",\n          \"name\": \"나노바나나는 포토샵을 완전히 대체할 수 있나요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"나노바나나는 일반적인 사진 편집 작업을 매우 쉽고 빠르게 처리하여 포토샵의 필요성을 크게 줄여줍니다. 하지만 그래픽 디자인이나 고도로 정밀한 수작업이 필요한 전문적인 작업에서는 여전히 포토샵이 주된 도구로 사용될 수 있습니다. 나노바나나는 포토샵의 훌륭한 대안이자 보완재 역할을 합니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"나노바나나를 사용하려면 별도 프로그램 설치나 구독이 필요한가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"아니요, Gemini의 2.5 Flash 모델인 나노바나나는 Gemini 웹사이트나 앱에서 ‘이미지 생성’ 모드를 통해 바로 사용할 수 있습니다. 별도의 프로그램 설치나 유료 구독 없이 무료로 주요 편집 기능을 이용할 수 있어 접근성이 매우 뛰어납니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"AI 편집 시 인물이나 배경이 부자연스러워지지는 않나요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"나노바나나는 인물, 가족, 친구, 반려동물 등의 주요 피사체를 편집할 때 원래 모습의 일관성을 유지하도록 설계되었습니다. 배경 교체나 객체 추가 시에도 자연스러운 그림자, 조명, 질감을 반영하여 전체적인 조화를 해치지 않는 뛰어난 결과물을 제공합니다.\"\n          }\n        }\n      ]\n    }\n  </script>\n<p style=\"margin-bottom: 20px; text-align: left; margin-top: 40px;\" data-ke-size=\"size16\">포토샵은 여전히 그래픽 디자이너와 전문 사진작가들의 강력한 도구로 남을 것입니다. 하지만 Gemini의 나노바나나는 훌륭한 대안이자 혁신적인 미래를 제시합니다. 복잡한 제어나 기술적인 도구 다루는 것에 어려움을 느끼는 분들에게, 나노바나나는 사진을 쉽고 빠르게 원하는 대로 편집할 수 있는 최고의 도구가 될 것입니다. <span style=\"letter-spacing: 0px;\">지금 바로 나노바나나로 여러분의 사진 편집 경험을 한 단계 업그레이드해보세요!</span></p>\n</div>\n<figure id=\"og_1757555949047\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"나노바나나를 가장 스마트하게 사용하는 법. 바나나 캔버스 무료 공개\" data-og-description=\"AI 이미지 생성과 편집의 새로운 지평을 연 구글의 제미나이 2.5 Flash Image, 일명 나노바나나를 가장 스마트하게 활용하는 법을 소개합니다. 특히 나노바나나의 강력한 기능을 누구나 쉽게 사용할 \" data-og-host=\"muzbox.tistory.com\" data-og-source-url=\"https://muzbox.tistory.com/483649\" data-og-url=\"https://muzbox.tistory.com/483649\" data-og-image=\"https://scrap.kakaocdn.net/dn/b1ChQ8/hyZIV5GvYU/RHofy8PKPWvBDwKEkphUS0/img.jpg?width=800&amp;height=800&amp;face=0_0_800_800,https://scrap.kakaocdn.net/dn/cce0Mx/hyZG6740qv/3AYCrdi97KCJFe4KJuAsx0/img.jpg?width=800&amp;height=800&amp;face=0_0_800_800,https://scrap.kakaocdn.net/dn/beT7rO/hyZI00cOoU/7mVLdOrTFnHoGhQejqFjU1/img.png?width=1622&amp;height=757&amp;face=0_0_1622_757\"><a href=\"https://muzbox.tistory.com/483649\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://muzbox.tistory.com/483649\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/b1ChQ8/hyZIV5GvYU/RHofy8PKPWvBDwKEkphUS0/img.jpg?width=800&amp;height=800&amp;face=0_0_800_800,https://scrap.kakaocdn.net/dn/cce0Mx/hyZG6740qv/3AYCrdi97KCJFe4KJuAsx0/img.jpg?width=800&amp;height=800&amp;face=0_0_800_800,https://scrap.kakaocdn.net/dn/beT7rO/hyZI00cOoU/7mVLdOrTFnHoGhQejqFjU1/img.png?width=1622&amp;height=757&amp;face=0_0_1622_757');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">나노바나나를 가장 스마트하게 사용하는 법. 바나나 캔버스 무료 공개</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">AI 이미지 생성과 편집의 새로운 지평을 연 구글의 제미나이 2.5 Flash Image, 일명 나노바나나를 가장 스마트하게 활용하는 법을 소개합니다. 특히 나노바나나의 강력한 기능을 누구나 쉽게 사용할</p>\n<p class=\"og-host\" data-ke-size=\"size16\">muzbox.tistory.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "사진 편집, 아직도 어렵고 복잡하게 느끼시나요? 포토샵의 높은 문턱에 좌절했던 분들이라면 주목해주세요! 2025년, 구글 Gemini의 강력한 AI 모델 '나노바나나'가 사진 편집의 판도를 바꾸고 있습니다. 초보자도 전문가처럼, 단 몇 번의 대화만으로 놀라운 결과물을 얻을 수 있는 이 혁신적인 도구에 대해 자세히 알아보겠습니다.\n  포토샵은 옛말? AI 기반 이미지 편집의 도래\n\n\n예전에는 멋진 사진을 만들려면 포토샵 같은 전문 프로그램을 다루는 기술이 필수적이었죠. 하지만 수십 가지의 도구와 슬라이더, 복잡한 레이어 개념까지… 숙련된 편집자가 아니라면 원하는 결과를 얻기란 여간 어려운 일이 아니었습니다. 저 역시 처음 포토샵을 배울 때 수많은 튜토리얼을 찾아보며 진땀을 뺐던 기억이 생생합니다. 바로 이런 지점에서 AI 기술이 사진 편집의 새로운 지평을 열고 있습니다.\n최근 저는 제 셀피를 픽셀(Pixel)의 AI 편집 기능으로 수정해봤는데, 결과가 정말 훌륭했어요. 그러나 이제는 Gemini를 통해 편집하면 포토샵이 필요 없을 정도로 놀라운 경험을 할 수 있게 되었습니다. 특히 Gemini의 최신 모델인 ‘나노바나나(Nano Banana)’는 이미지 편집에 특화되어, 마치 마법처럼 사진을 변신시켜줍니다.\n✂️ 포토샵, 그 익숙함 뒤의 불편함\n포토샵은 분명 놀라운 소프트웨어입니다. 전문적인 결과물을 만들어낼 수 있는 다양한 도구들을 제공하며, 일부는 AI 기술로 구동되기도 하죠. 막히는 부분이 있다면 인터넷에 넘쳐나는 튜토리얼이 큰 도움이 됩니다. 하지만 포토샵을 제대로 활용하려면 몇 가지 넘어야 할 산이 있습니다.\n높은 진입 장벽: 기술과 비용\n기술적 난이도: 포토샵은 일정 수준의 기술 숙련도를 요구합니다. 수많은 기능들을 익히는 데 상당한 시간과 노력이 필요하죠.\n고사양 컴퓨터: 프로그램을 원활하게 실행하려면 강력한 사양의 컴퓨터가 필요합니다.\n구독료 부담: 어도비(Adobe)의 구독료는 적지 않은 재정적 투자를 요구합니다. 첫 사진을 열어보기도 전에 비용 지불이 선행되어야 합니다.\n복잡한 사용법과 시간 투자\n물론 포토샵이 제공하는 정밀한 제어 기능은 훌륭합니다. 하지만 사실 전문 사진작가나 그래픽 디자이너가 아니라면 그 모든 기능이 다 필요하지 않을 때가 많습니다. 대부분의 일반적인 사진 편집에는 포토샵이 제공하는 복잡성이 과도하게 느껴질 수 있습니다. 가파른 학습 곡선 때문에 원하는 결과물을 얻기까지 오랜 시간 시행착오를 겪어야 한다는 점도 큰 부담입니다.\n  팁! 전문적인 작업이 아니라면, 포토샵 대신 무료로 이용할 수 있는 다양한 대체 프로그램들도 많습니다. 하지만 AI 편집 도구는 그마저도 뛰어넘는 간편함을 제공하죠.\n  나노바나나의 등장: 이미지 편집의 새로운 기준\nGemini의 2.5 Flash 모델, 코드명 나노바나나(Nano Banana)는 이미지 편집의 패러다임을 완전히 바꾸고 있습니다. 이제 수백 개의 슬라이더와 도구를 조작하는 대신, 여러분이 원하는 변경 사항을 단순히 입력하거나 말하기만 하면 Gemini가 알아서 편집을 처리해 줍니다. 정말 놀랍지 않나요?\n간편함의 미학: 직관적인 AI 편집\n나노바나나를 사용하는 방법은 매우 간단합니다. 데스크톱에서 Gemini 웹사이트에 접속하거나 Gemini 앱을 열고 ‘이미지 생성(Create images)’ 모드를 선택합니다. 그 다음, “+” 아이콘을 눌러 편집하고 싶은 이미지를 업로드하고 원하는 편집 내용을 텍스트로 입력하기만 하면 됩니다. 정말 이보다 더 쉬울 수 있을까요?\n구독료도, 고사양 컴퓨터도 필요 없습니다. 그냥 원하는 편집을 Gemini에게 알려주기만 하면 끝입니다. 나노바나나는 특히 다음과 같은 작업에 매우 강력한 성능을 보여줍니다.\n기능\n설명\n\n\n\n\n객체 제거 및 추가\n사진 속 불필요한 요소를 지우거나 새로운 객체를 자연스럽게 추가합니다.\n\n\n배경 교체\n원하는 배경으로 사진의 분위기를 완전히 바꿀 수 있습니다.\n\n\n이미지 간 스타일 전환\n특정 이미지의 스타일을 다른 이미지에 적용하여 독특한 결과물을 만듭니다.\n\n\n색상 및 조명 조정\n사진의 색감과 밝기를 최적화하여 분위기를 살립니다.\n\n\n여러 사진 합성\n두 장 이상의 사진을 자연스럽게 하나로 합쳐줍니다.\n\n\n\n ️ 대화형 편집: 창의력의 날개를 달다\n나노바나나로 사진을 편집할 때 가장 매력적인 점은 바로 ‘다단계 대화형 편집’이 가능하다는 것입니다. 한 번의 프롬프트에서 모든 변경 사항을 지정할 필요 없이, 마치 친구와 대화하듯 편집을 이어나갈 수 있습니다. 예를 들어, 첫 번째 요청으로 하늘을 바꾸고, 다음 요청으로 조명을 미세하게 조절하거나 배경 요소를 추가·삭제하는 식이죠.\n단계별 편집의 자유\n이러한 대화형 편집 방식은 여러분의 편집 경험 자체를 변화시킵니다. 더 이상 복잡한 도구와 기술 수준에 얽매이지 않고, 오롯이 자신의 창의적인 아이디어 구현에 집중할 수 있게 됩니다. 편집 속도가 빠르고 노력도 적게 들기 때문에, 다양한 아이디어를 주저 없이 시도해볼 수 있다는 것도 큰 장점입니다. 이제는 기술이 아니라 여러분의 창의적인 비전이 편집의 중심이 됩니다.\n음성 편집, 아직은 성장 중\n만약 타이핑이 번거롭다면, 음성 모드로 전환해 Gemini에게 말로 편집을 요청할 수도 있습니다. 하지만 제 경험상 아직 음성 모드는 완벽하게 작동하지는 않았습니다. 가끔 설명 없는 오류가 반복적으로 발생하곤 했어요. 원인은 알 수 없지만, 텍스트 입력은 언제나 안정적으로 작동했으니 참고하시면 좋겠습니다.\n✍️ 나노바나나 프롬프트, 이렇게 활용해 보세요!\n나노바나나의 AI 편집 능력은 여러분의 프롬프트에 달려있습니다. 원하는 결과를 얻기 위해서는 명확하고 구체적인 설명이 중요합니다. 다음은 효과적인 프롬프트를 작성하기 위한 몇 가지 팁입니다.\n구체적인 지시: 단순히 ‘배경을 바꿔줘’보다는 ‘배경을 울창한 열대우림으로 바꿔주고, 빛은 나뭇잎 사이로 스며드는 듯한 효과를 줘’와 같이 구체적으로 설명해주세요.\n명확한 목표: ‘사진을 더 밝게’보다는 ‘전체적으로 따뜻한 색감으로 밝기를 한 단계 올려줘’와 같이 목표를 명확히 제시합니다.\n단계별 접근: 복잡한 편집은 한 번에 처리하기보다 여러 단계로 나누어 요청하는 것이 좋습니다. 예를 들어, 먼저 객체를 제거하고, 그 다음 배경을 교체한 후, 마지막으로 색상 보정을 하는 식입니다.\n예시 활용: 특정 스타일이나 느낌을 원한다면, ‘인상주의 화풍으로 바꿔줘’처럼 예시를 들어 설명할 수도 있습니다.\n  팁! 처음에는 간단한 편집부터 시작하여 나노바나나의 작동 방식을 익히는 것이 좋습니다. 점점 더 복잡한 요청을 시도하며 여러분만의 노하우를 쌓아가세요!\n⏱️ 복잡한 작업도 순식간에: 시간 절약의 마법\n포토샵에서 배경을 바꾸는 단순한 작업조차 숙련자에게도 몇 분, 초보자에게는 몇 시간이 걸릴 수 있습니다. 레이어 작업이나 마스킹을 통해 객체를 제거하거나 배경을 교체하고, 요소를 옮기는 데 많은 집중과 시간이 필요하죠. 하지만 나노바나나에서는 같은 작업을 불과 몇 초 만에 끝낼 수 있습니다.\n제가 직접 경험한 일화가 있습니다. 친구가 자전거 사고를 당해서 병원에 있었고, 사고 난 자전거 사진을 보내주기를 원했어요. 손상된 자전거가 수리점으로 운반 중인 사진이었는데, 저는 나노바나나에게 사진을 산속에 주차된 것처럼 편집해 달라고 요청했습니다. 결과는 정말 놀라웠어요! 자전거와 헬멧까지 정확하게 표현했고, 심지어 그림자, 조명, 흙먼지까지 자연스럽게 반영되어 있었죠. 이 정도 편집을 포토샵에서 했다면 훨씬 오랜 시간이 걸렸을 뿐 아니라 반드시 책상 앞에 앉아 작업해야 했을 겁니다. 나노바나나는 워터마크 제거, 배경 교체, 객체 추가·삭제를 거의 요청과 동시에 수행해냅니다.\n✅ 일관성 유지: AI 편집의 신뢰성 확보\n기존 AI 편집 도구의 가장 큰 문제점 중 하나는 바로 ‘일관성’이었습니다. 특히 인물의 얼굴이나 주요 피사체가 편집 과정에서 미묘하게 바뀌어 버리는 경우가 많았죠. 나 자신이나 지인의 사진을 편집할 때 작은 변화만 있어도 어색하게 느껴질 수 있습니다. 비슷하지만 똑같지 않은 AI 편집 결과물은 사실상 쓸모가 없었습니다.\n인물, 반려동물 사진 편집의 안정성\n하지만 구글은 Gemini, 특히 나노바나나를 개발하면서 이러한 문제점을 해결하는 데 집중했습니다. 나노바나나는 사람, 가족, 친구, 반려동물의 사진을 편집할 때 원래 모습의 일관성을 유지할 수 있도록 설계되었습니다. 따라서 어떤 편집을 하든 인물의 모습은 그대로 유지될 가능성이 매우 큽니다. 이제 AI가 임의로 추가하는 왜곡된 결과물이 아닌, 여러분이 지정한 편집만 정확히 반영된 결과물을 기대할 수 있습니다.\n여러 사진 합성도 자연스럽게\n이러한 일관성 유지 기능은 특히 여러 이미지를 합성하여 한 장의 결과물을 만들 때 더욱 유용합니다. 두 장의 사진 속에 있던 사람들이 하나의 프레임에 함께 있어도 각자의 모습이 자연스럽게 유지되는 것을 확인할 수 있습니다. 이제 여러분의 소중한 추억을 AI의 도움으로 더욱 아름답게 만들 수 있습니다.\n  핵심 요약\n✅ 간편한 접근성: 포토샵과 달리 고사양 PC나 유료 구독 없이 Gemini 웹사이트나 앱에서 즉시 이용 가능합니다.\n✅ 직관적인 대화형 편집: 복잡한 도구 없이 자연어 프롬프트(텍스트 또는 음성)로 원하는 편집을 명령할 수 있습니다.\n✅ 시간 절약과 효율성: 배경 교체, 객체 제거 등 복잡한 작업도 수 초 만에 처리하여 작업 시간을 혁신적으로 단축합니다.\n✅ 일관성 유지: 인물이나 주요 피사체의 원래 모습을 정확히 보존하며, 여러 사진 합성 시에도 자연스러운 결과물을 제공합니다.\n나노바나나는 전문가뿐만 아니라 일반 사용자에게도 사진 편집의 즐거움을 선사하는 강력한 도구입니다. 지금 바로 경험해보세요!\n ️ 대화형 편집: 창의력의 날개를 달다\n1.  애니메이션을 실제 모델로 변경\nGenerate a photo of a girl cosplaying this illustration, with the background set at Comiket\n\n\n \n2.  다양한 헤어스타일로 변경\n\n\nGenerate avatars of this person with different hairstyles in a 3x3 grid format\n \n 3.  드로잉과 사진의 합성\n\n\nChange the pose of the person in Figure 1 to that of Figure 2, and shoot in a professional studio\n❓ 자주 묻는 질문 (FAQ)\nQ1: 나노바나나는 포토샵을 완전히 대체할 수 있나요?\nA1: 나노바나나는 일반적인 사진 편집 작업을 매우 쉽고 빠르게 처리하여 포토샵의 필요성을 크게 줄여줍니다. 하지만 그래픽 디자인이나 고도로 정밀한 수작업이 필요한 전문적인 작업에서는 여전히 포토샵이 주된 도구로 사용될 수 있습니다. 나노바나나는 포토샵의 훌륭한 대안이자 보완재 역할을 합니다.\nQ2: 나노바나나를 사용하려면 별도 프로그램 설치나 구독이 필요한가요?\nA2: 아니요, Gemini의 2.5 Flash 모델인 나노바나나는 Gemini 웹사이트나 앱에서 ‘이미지 생성’ 모드를 통해 바로 사용할 수 있습니다. 별도의 프로그램 설치나 유료 구독 없이 무료로 주요 편집 기능을 이용할 수 있어 접근성이 매우 뛰어납니다.\nQ3: AI 편집 시 인물이나 배경이 부자연스러워지지는 않나요?\nA3: 나노바나나는 인물, 가족, 친구, 반려동물 등의 주요 피사체를 편집할 때 원래 모습의 일관성을 유지하도록 설계되었습니다. 배경 교체나 객체 추가 시에도 자연스러운 그림자, 조명, 질감을 반영하여 전체적인 조화를 해치지 않는 뛰어난 결과물을 제공합니다.\n포토샵은 여전히 그래픽 디자이너와 전문 사진작가들의 강력한 도구로 남을 것입니다. 하지만 Gemini의 나노바나나는 훌륭한 대안이자 혁신적인 미래를 제시합니다. 복잡한 제어나 기술적인 도구 다루는 것에 어려움을 느끼는 분들에게, 나노바나나는 사진을 쉽고 빠르게 원하는 대로 편집할 수 있는 최고의 도구가 될 것입니다. 지금 바로 나노바나나로 여러분의 사진 편집 경험을 한 단계 업그레이드해보세요!\n\n \n나노바나나를 가장 스마트하게 사용하는 법. 바나나 캔버스 무료 공개\nAI 이미지 생성과 편집의 새로운 지평을 연 구글의 제미나이 2.5 Flash Image, 일명 나노바나나를 가장 스마트하게 활용하는 법을 소개합니다. 특히 나노바나나의 강력한 기능을 누구나 쉽게 사용할\nmuzbox.tistory.com",
        "guid": "http://muzbox.tistory.com/483654",
        "categories": [
          "AI, 미래기술/AI 인사이트",
          "AI 사진 합성",
          "AI 이미지 보정",
          "AI 편집 튜토리얼",
          "gemini 2.5 flash",
          "Gemini AI 편집",
          "나노바나나",
          "무료 사진 편집",
          "사진 편집 AI",
          "쉬운 사진 편집",
          "포토샵 대체"
        ],
        "isoDate": "2025-09-11T01:59:40.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "(RULIWEB`Д')/",
        "title": "[MULTI] 우리 시리즈 정상 영업합니다, 슈퍼로봇대전 Y",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2359",
        "pubDate": "Thu, 11 Sep 2025 21:26:37 +0900",
        "author": "(RULIWEB`Д')/",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/25/09/11/19938005ac84c329e.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2025-09-11T12:26:37.000Z"
      },
      {
        "creator": "「RULIWEB」",
        "title": "[MULTI] 루터슈터의 왕좌 탈환, 보더랜드 4",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2358",
        "pubDate": "Thu, 11 Sep 2025 21:05:01 +0900",
        "author": "「RULIWEB」",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/25/09/11/1993886942e4cacdc.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2025-09-11T12:05:01.000Z"
      },
      {
        "creator": "｜RULIWEB｜",
        "title": "악역영애 4컷 만화 - 18화, 지루하고현학적인과거회상인데스와",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2357",
        "pubDate": "Wed, 10 Sep 2025 21:27:26 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i1.ruliweb.com/thumb/25/09/10/1993397cfa451ad6b.jpg\">",
        "contentSnippet": "",
        "categories": [
          "웹툰"
        ],
        "isoDate": "2025-09-10T12:27:26.000Z"
      },
      {
        "creator": "［RULIWEB］",
        "title": "[MULTI] 도전과 절망 그리고 그 끝의 절정, 할로우 나이트 : 실크송",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2356",
        "pubDate": "Wed, 10 Sep 2025 16:12:50 +0900",
        "author": "［RULIWEB］",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/25/09/10/199327743e75104c1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2025-09-10T07:12:50.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "대구 대명시작 옥이국수 골목김밥 - 500원 올랐다. (23년도 보다)",
        "link": "http://serverdown.tistory.com/1392",
        "pubDate": "Tue, 16 Sep 2025 18:36:33 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1392#entry1392comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"616\" data-origin-height=\"438\"><span data-url=\"https://blog.kakaocdn.net/dn/cKVAnl/btsQAVaeevh/IDAcCkC5XtUBewYX0FAawK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cKVAnl/btsQAVaeevh/IDAcCkC5XtUBewYX0FAawK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cKVAnl/btsQAVaeevh/IDAcCkC5XtUBewYX0FAawK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcKVAnl%2FbtsQAVaeevh%2FIDAcCkC5XtUBewYX0FAawK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"616\" height=\"438\" data-origin-width=\"616\" data-origin-height=\"438\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">옥이국수의 골목김밥</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"433\" data-origin-height=\"310\"><span data-url=\"https://blog.kakaocdn.net/dn/ciJ7p9/btsQBpBOL7G/ZIdp0StTKyQ9cxMbDBbv9k/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ciJ7p9/btsQBpBOL7G/ZIdp0StTKyQ9cxMbDBbv9k/img.png\"><img src=\"https://blog.kakaocdn.net/dn/ciJ7p9/btsQBpBOL7G/ZIdp0StTKyQ9cxMbDBbv9k/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FciJ7p9%2FbtsQBpBOL7G%2FZIdp0StTKyQ9cxMbDBbv9k%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"433\" height=\"310\" data-origin-width=\"433\" data-origin-height=\"310\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">1,500 에서 올랐다. <br />국수는 5천원이다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">23년도 블로그 글: <a href=\"https://blog.naver.com/yusungkjw/223235432716\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://blog.naver.com/yusungkjw/223235432716</a></p>\n<figure id=\"og_1758015600914\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"대구 대명시장 맛집 옥이국수 그리고 골목김밥\" data-og-description=\"대구 전통시장 중 가장 큰 규모를 자랑하고 많은 사람들이 찾는 곳이 서문시장과 칠성시장, 매천시장 등을 ...\" data-og-host=\"blog.naver.com\" data-og-source-url=\"https://blog.naver.com/yusungkjw/223235432716\" data-og-url=\"https://blog.naver.com/yusungkjw/223235432716\" data-og-image=\"https://scrap.kakaocdn.net/dn/fsz7S/hyZJgWDfCG/7injoIrPZqpQTdMY8HUL1k/img.jpg?width=743&amp;height=743&amp;face=0_0_743_743\"><a href=\"https://blog.naver.com/yusungkjw/223235432716\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://blog.naver.com/yusungkjw/223235432716\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/fsz7S/hyZJgWDfCG/7injoIrPZqpQTdMY8HUL1k/img.jpg?width=743&amp;height=743&amp;face=0_0_743_743');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">대구 대명시장 맛집 옥이국수 그리고 골목김밥</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">대구 전통시장 중 가장 큰 규모를 자랑하고 많은 사람들이 찾는 곳이 서문시장과 칠성시장, 매천시장 등을 ...</p>\n<p class=\"og-host\" data-ke-size=\"size16\">blog.naver.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">별 수 없다 오르기전에 빨리 먹는 방법 밖에</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><a href=\"https://www.youtube.com/watch?v=hdwb0rsowLo\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=hdwb0rsowLo</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=hdwb0rsowLo\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/fej1Y/hyZJvd67JC/MMupT7u1BWFyEJ0ud4Vg0k/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/chsUZK/hyZJCw1yhM/LglrGG2cBMrZuoGJRz6jP1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-original-url=\"\" data-video-title=\"\"><iframe src=\"https://www.youtube.com/embed/hdwb0rsowLo\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">물가가 오르는 영향을 받아 어쩔 수 없이 올라간다.</p>\n<p data-ke-size=\"size16\">쌀때 많이 먹을껄</p>",
        "contentSnippet": "옥이국수의 골목김밥\n\n\n1,500 에서 올랐다. \n국수는 5천원이다.\n \n23년도 블로그 글: https://blog.naver.com/yusungkjw/223235432716\n\n \n대구 대명시장 맛집 옥이국수 그리고 골목김밥\n대구 전통시장 중 가장 큰 규모를 자랑하고 많은 사람들이 찾는 곳이 서문시장과 칠성시장, 매천시장 등을 ...\nblog.naver.com\n\n별 수 없다 오르기전에 빨리 먹는 방법 밖에\n \nhttps://www.youtube.com/watch?v=hdwb0rsowLo\n\n\n\n \n물가가 오르는 영향을 받아 어쩔 수 없이 올라간다.\n쌀때 많이 먹을껄",
        "guid": "http://serverdown.tistory.com/1392",
        "categories": [
          "유튜브",
          "맛집"
        ],
        "isoDate": "2025-09-16T09:36:33.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "네팔 혁명은 디스코드로 부터",
        "link": "http://serverdown.tistory.com/1391",
        "pubDate": "Sun, 14 Sep 2025 20:23:40 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1391#entry1391comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1024\" data-origin-height=\"1024\"><span data-url=\"https://blog.kakaocdn.net/dn/cmpLMH/btsQw79kEPl/1ovBUhziDQdto8ZiDsfKU0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cmpLMH/btsQw79kEPl/1ovBUhziDQdto8ZiDsfKU0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cmpLMH/btsQw79kEPl/1ovBUhziDQdto8ZiDsfKU0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcmpLMH%2FbtsQw79kEPl%2F1ovBUhziDQdto8ZiDsfKU0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1024\" height=\"1024\" data-origin-width=\"1024\" data-origin-height=\"1024\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=i8axj6qTXjk&amp;t=104s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=i8axj6qTXjk&amp;t=104s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=i8axj6qTXjk\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bVhhJ5/hyZJvrmOpx/wW6czoefcm6Meu68JdDKKk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/wZxZ1/hyZJhU140C/ukkzzJ5UNKfqZnk6mtZwnk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"네팔 시위 결말은 대성공...중국의 개입 가능성?\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/i8axj6qTXjk\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">시위 상태에서 군은 시민을 보호했고 대통령을 교체에 성공했습니다.</p>\n<p data-ke-size=\"size16\">이때 대통령 교체 투표를 디스코드로 했다는 것입니다.</p>\n<p data-ke-size=\"size16\">디스코드 대단하네요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=i8axj6qTXjk&t=104s\n\n\n\n \n시위 상태에서 군은 시민을 보호했고 대통령을 교체에 성공했습니다.\n이때 대통령 교체 투표를 디스코드로 했다는 것입니다.\n디스코드 대단하네요",
        "guid": "http://serverdown.tistory.com/1391",
        "categories": [
          "유튜브",
          "네팔",
          "디스코드",
          "중국"
        ],
        "isoDate": "2025-09-14T11:23:40.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "게임 성인물 차단 움직임이 점점 강해지고 있다.",
        "link": "http://serverdown.tistory.com/1390",
        "pubDate": "Sat, 13 Sep 2025 17:42:30 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1390#entry1390comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"300\" data-origin-height=\"168\"><span data-url=\"https://blog.kakaocdn.net/dn/GERgM/btsQwgMl3ZH/3xBAQ6gQMXT4MSAAHZbl5k/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/GERgM/btsQwgMl3ZH/3xBAQ6gQMXT4MSAAHZbl5k/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/GERgM/btsQwgMl3ZH/3xBAQ6gQMXT4MSAAHZbl5k/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FGERgM%2FbtsQwgMl3ZH%2F3xBAQ6gQMXT4MSAAHZbl5k%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"300\" height=\"168\" data-origin-width=\"300\" data-origin-height=\"168\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">좋다 나쁘다의 판단은 없습니다.</p>\n<p data-ke-size=\"size16\">문화의 움직임은 중요하기 때문에 관심을 가져야합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">작년</p>\n<p data-ke-size=\"size16\">일본 성인 만화 결제를 비자가 막았습니다.</p>\n<p data-ke-size=\"size16\">올해</p>\n<p data-ke-size=\"size16\">스팀과 이치.io 에서 성인물 관련 게임을 차단했고</p>\n<p data-ke-size=\"size16\">마스터카드도 동창했습니다.</p>\n<p data-ke-size=\"size16\">영국의 온라인 안전법 등장</p>\n<p data-ke-size=\"size16\">넥서스모드도 성인 인증후에 모드를 다운로드 할 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=0glLHO42dow\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=0glLHO42dow</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=0glLHO42dow\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cKfu2l/hyZIM2qTOn/lpTmNk1JvvXGXV2AgCOAW0/img.jpg?width=1280&amp;height=720&amp;face=468_126_936_636,https://scrap.kakaocdn.net/dn/cuwZVi/hyZJlWrdng/na65J1xyu7ri755gysdZA0/img.jpg?width=1280&amp;height=720&amp;face=468_126_936_636\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"일본 '부정적 리뷰 성향' 파장, 넥서스 모드 연령 인증 반발, 실크송 출시일 확정 외 | 게임 헤드\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/0glLHO42dow\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">5분에 나옵니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">유저들은 검열이라면서 불만을 쏟아내고 있는데</p>\n<p data-ke-size=\"size16\">성인물을 차단하는 근본적인 이유는 잘 모르겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">아무튼 카드회사에 이어 국가도 나섰다는 점을 주목해야할 것입니다.</p>",
        "contentSnippet": "좋다 나쁘다의 판단은 없습니다.\n문화의 움직임은 중요하기 때문에 관심을 가져야합니다.\n \n작년\n일본 성인 만화 결제를 비자가 막았습니다.\n올해\n스팀과 이치.io 에서 성인물 관련 게임을 차단했고\n마스터카드도 동창했습니다.\n영국의 온라인 안전법 등장\n넥서스모드도 성인 인증후에 모드를 다운로드 할 수 있습니다.\n \n \n영상: https://www.youtube.com/watch?v=0glLHO42dow\n\n\n\n5분에 나옵니다.\n \n유저들은 검열이라면서 불만을 쏟아내고 있는데\n성인물을 차단하는 근본적인 이유는 잘 모르겠습니다.\n \n아무튼 카드회사에 이어 국가도 나섰다는 점을 주목해야할 것입니다.",
        "guid": "http://serverdown.tistory.com/1390",
        "categories": [
          "투자",
          "게임",
          "성인물"
        ],
        "isoDate": "2025-09-13T08:42:30.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "걸음 보조 로봇 기사",
        "link": "http://serverdown.tistory.com/1389",
        "pubDate": "Sat, 13 Sep 2025 13:18:23 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1389#entry1389comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"425\" data-origin-height=\"328\"><span data-url=\"https://blog.kakaocdn.net/dn/ecmvzQ/btsQytwOZ0L/buBkJ4X0VSOpblOupn2301/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ecmvzQ/btsQytwOZ0L/buBkJ4X0VSOpblOupn2301/img.png\"><img src=\"https://blog.kakaocdn.net/dn/ecmvzQ/btsQytwOZ0L/buBkJ4X0VSOpblOupn2301/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FecmvzQ%2FbtsQytwOZ0L%2FbuBkJ4X0VSOpblOupn2301%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"425\" height=\"328\" data-origin-width=\"425\" data-origin-height=\"328\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=QjHcJfI7Cik\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=QjHcJfI7Cik</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=QjHcJfI7Cik\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/s1c21/hyZIOsozVG/BkOawzD7ovXJjBa7qnyUs1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/bMfSxy/hyZJkwrsGA/sI6eFQDJZKWxUm1k53UCa0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"더 가볍고 편하게&hellip;\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/QjHcJfI7Cik\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">치아 임플란트 처럼 결국 더 걸을 수 있음으로서</p>\n<p data-ke-size=\"size16\">인간의 수명은 늘어날 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">추천주</h2>\n<p data-ke-size=\"size16\">미국 - 테슬라, 엔비디아</p>\n<p data-ke-size=\"size16\">한국 - 로보티즈, 원익홀딩스</p>\n<p data-ke-size=\"size16\">중국 - Kodex&nbsp;차이나휴머노이드로봇</p>\n<p data-ke-size=\"size16\">잘모르시면 그냥 글로벌로</p>\n<p data-ke-size=\"size16\">PLUS&nbsp;글로벌휴머노이드로봇액티브</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=QjHcJfI7Cik\n\n\n\n \n치아 임플란트 처럼 결국 더 걸을 수 있음으로서\n인간의 수명은 늘어날 것입니다.\n \n추천주\n미국 - 테슬라, 엔비디아\n한국 - 로보티즈, 원익홀딩스\n중국 - Kodex 차이나휴머노이드로봇\n잘모르시면 그냥 글로벌로\nPLUS 글로벌휴머노이드로봇액티브",
        "guid": "http://serverdown.tistory.com/1389",
        "categories": [
          "투자",
          "로봇"
        ],
        "isoDate": "2025-09-13T04:18:23.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "버블의 징후를 체크해보자",
        "link": "http://serverdown.tistory.com/1388",
        "pubDate": "Fri, 12 Sep 2025 16:12:20 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1388#entry1388comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"273\" data-origin-height=\"184\"><span data-url=\"https://blog.kakaocdn.net/dn/v6aqd/btsQvS5xhm5/FKKndRCTt2ubPM8QqmhSK1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/v6aqd/btsQvS5xhm5/FKKndRCTt2ubPM8QqmhSK1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/v6aqd/btsQvS5xhm5/FKKndRCTt2ubPM8QqmhSK1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fv6aqd%2FbtsQvS5xhm5%2FFKKndRCTt2ubPM8QqmhSK1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"273\" height=\"184\" data-origin-width=\"273\" data-origin-height=\"184\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=OcuoB9xIr70&amp;t=89s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=OcuoB9xIr70&amp;t=89s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=OcuoB9xIr70\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/hC1am/hyZJrWxgso/fzoExXaIPvr2qHb5OTACzk/img.jpg?width=1280&amp;height=720&amp;face=246_48_354_166\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"주식 많이 오른 것 같아도 지금 팔면 후회한다? 버블장 초입의 신호들(2부)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/OcuoB9xIr70\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">내년은 짝수해 미대통령 2년차 입니다.</p>\n<p data-ke-size=\"size16\">주의해야할 해 입니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=OcuoB9xIr70&t=89s\n\n\n\n내년은 짝수해 미대통령 2년차 입니다.\n주의해야할 해 입니다.",
        "guid": "http://serverdown.tistory.com/1388",
        "categories": [
          "투자",
          "버블"
        ],
        "isoDate": "2025-09-12T07:12:20.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": [
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "실패를 통과하는 일",
        "link": "https://jojoldu.tistory.com/845",
        "pubDate": "Sat, 13 Sep 2025 20:49:26 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "https://jojoldu.tistory.com/845#entry845comment",
        "content": "<p data-ke-size=\"size16\">예전 최정우님이 쓰신 옐로모바일의 흥망성쇠를 담은 <a href=\"https://ebook-product.kyobobook.co.kr/dig/epd/ebook/E000002951949\">스타트업은 어떻게 유니콘이 되는가</a> 이후 오랫만에 스타트업의 대표님이 직접 쓰신 일기장 같은 책을 봤다.</p>\n<p data-ke-size=\"size16\">퍼블리는 인프런과 꽤나 닮은 부분이 많았다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>퍼블리 &amp; 커리어리 &amp; 위하이어</li>\n<li>인프런 교육 &amp; 인프런 커뮤니티 &amp; 랠릿</li>\n</ul>\n<p data-ke-size=\"size16\">꼭 퍼블리만 아니더라도 대부분의 커리어 플랫폼들은 그 방향성은 비슷하게 간다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>교육 &amp; 채용 &amp; 커뮤니티</li>\n</ul>\n<p data-ke-size=\"size16\">시작은 서로 다를 수 있으나, 큰 그림은 다들 비슷하게 보고 있다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>원티드처럼 채용으로 시작해서 커뮤니티와 교육으로 확장하는 경우도 있으며</li>\n<li>리멤버처럼 (명함) 커뮤니티로 시작해서 채용으로 확장한 경우도 있으며</li>\n<li>인프런처럼 교육으로 시작해서 커뮤니티, 채용으로 확장한 경우도 있다.</li>\n</ul>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">다만, 지금의 우리는 교육으로 글로벌 시장을 노리는 것으로 에너지를 집중하고 있다.</p>\n</blockquote>\n<p data-ke-size=\"size16\">3개 꼭지점을 모두 다 달성한 플랫폼은 국내/국외 어디에도 없다.<br />아마도 가장 근접한 건 링크드인이다.<br />커뮤니티와 채용에 있어서는 세계 최고가 되었고, 린다닷컴을 인수해서 교육쪽으로도 계속해서 시도하고 있으니 말이다.</p>\n<p data-ke-size=\"size16\">국내에서는 확실하게 이 영역을 모두 확보한 플랫폼이 없다.<br />하지만 많은 커리어 플랫폼이 이 영역들을 확보하기 위해 도전하고 있다.</p>\n<p data-ke-size=\"size16\">그러다보니 퍼블리를 비롯해 비슷한 결의 서비스들은 어떻게 시도하는지 자주 지켜봤다.<br />마침 퍼블리에는 좋아하는 콘텐츠들도 많았어서 구독제 멤버십도 가입해서 자주 사용했다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"2.png\" data-origin-width=\"1370\" data-origin-height=\"1590\"><span data-url=\"https://blog.kakaocdn.net/dn/bwVlK9/btsQxqH1WPB/PZtQdhV3MkIDApGg0HYyk1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bwVlK9/btsQxqH1WPB/PZtQdhV3MkIDApGg0HYyk1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bwVlK9/btsQxqH1WPB/PZtQdhV3MkIDApGg0HYyk1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbwVlK9%2FbtsQxqH1WPB%2FPZtQdhV3MkIDApGg0HYyk1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1370\" height=\"1590\" data-filename=\"2.png\" data-origin-width=\"1370\" data-origin-height=\"1590\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">퍼블리를 자주 이용하던 중,<br />개발자들을 위한 SNS 서비스 '커리어리'를 시작한다는 소식을 들었다.<br />'위하이어' 라는 ATS 서비스를 시작하신다는 것도 들었다.</p>\n<p data-ke-size=\"size16\">그리고 어느 순간 퍼블리에 읽고 싶은 콘텐츠가 더이상 추가되지 않았다.<br />내 취향의 콘텐츠가 없다보니 얼마되지 않는 그 구독료도 아까웠다.<br />그래서 훨씬 더 내 취향인 폴인의 구독을 시작했고, 지금까지도 연간 구독으로 계속해서 콘텐츠를 보고 있다.</p>\n<p data-ke-size=\"size16\">2023년엔 대표인 쭈와 함께 박소령 대표님, 이승국 CPO님과 함께 저녁식사를 먹으면서 스타트업에 대한 이야기를 나누기도 했다.<br />커리어리와 위하이어로 개발자와 채용에 관해서 집중하신다는 것도 알게 됐다.</p>\n<p data-ke-size=\"size16\">그래서 어떤 과정으로 퍼블리와 그 외 서비스들이 시작했는지, 비중은 어떻게 되는지, 시리즈 B 투자로 받은 135억을 어떻게 활용하셨는지 등등 많이 궁금했었다.</p>\n<p data-ke-size=\"size16\">한국 콘텐츠 스타트업에서 퍼블리가 남긴 족적은 분명히 크다.<br />그래서 퍼블리가 어떻게 10년을 보내왔는지 그 기록이 너무나 중요하다고 생각했는데, 이번에 이렇게 책으로 정리해주셔서 정말 감사했다.</p>\n<p data-ke-size=\"size16\">금, 토 이틀만에 다 읽으면서 지금 스타트업 시리즈 A, B 단계의 회사에서는 이 노트가 얼마나 귀한 기록인지 감사한 마음뿐이다.</p>\n<p data-ke-size=\"size16\">VC와의 관계와 투자는 어떻게 진행해야하는지,<br />투자 받은 자금을 어떻게 활용해야하는지,<br />레이오프는 어떻게 해야 덜 후회하고 앞으로를 위해 도움이 되는지 등등.</p>\n<p data-ke-size=\"size16\">아직 유니콘이 되지 못한 스타트업에 다니시는 분들이라면 무조건 적으로 읽어보시라고 추천하고 싶다.<br />책 제목이 \"실패를 통과하는 일\"이다.<br />인프런은 꼭 통과하지 않기로 몇번이고 다짐했다.</p>\n<h2 data-ke-size=\"size26\">책 속 문장</h2>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">매월 달성해야하는 재무 목표는 곧 매주, 매일의 목표로도 환산되기에 업무 우선순위에 대한 감각이 더 예민해지면서 긴장감을 가질 수 있었음.<br />팀과 커뮤니케이션을 할 때도 단순히 \"BEP를 달성하자\"가 아니라 \"<b>2023년 4월에 ㅇㅇ곳의 신규고객사가 ㅇㅇ원을 결제해서 매출이 00원 발생하면 BEP를 덜상할 수 있으니 집중하자</b>\" 라고 말하면, 해야 할 일이 명료해져서 좋았음.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">사업에서 돈을 벌려면 '남이 하기 싫은 일을 대신 해주고, 그 대가로 돈을 받는다'라는 고전적인 명제가 진리임을 다시 한번 절감함.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">부와 행복은 두 가지 요소로 이뤄진 등식임을 항상 기억하자.<br />두 가지란 당신이 '가진 것(현실)'과 '기대하는 것(기대치)'이다.<br />이 둘은 똑같이 중요하다.<br />따라서 가진 것을 늘리는 데에는 엄청난 노력을 쏟으면서 기대치를 관리하는 데에는 거의 신경을 쓰지 않는 것은 말이 안된다.<br />특히 <b>우리가 훨씬 더 쉽게 통제할 수 있는 것은 현실이 아닌 기대치</b>이므로 더욱 그렇다.<br />...<br />정말로 원하는 것은 기대한 것과 실제 결과의 차이를 경험하는 일이다.<br /><b>우리는 기대한 것보다 더 좋은 결과를 얻었을 때 만족과 성취감을 느낀다</b>.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">커리어 소셜미디어를 먼저 만들고 나중에 비즈니스 모델을 붙이는 것, 채용관리 소프트웨어를 먼저 만들고 나중에 신규고객에게 세일즈하는 것은 모두 <b>돈 버는 것을 뒤로 미룬 결정</b>이었다.<br />최저 가치 단계에서 어떻게 돈을 벌어야하는지, 이렇게 돈 버는 방법이 나와 잘 맞는지, 앞으로도 지치지 않고 꾸준히 할 수 있는 일인지 미리 파악하고 고칠 수 있는 기회를 날려버리고 말았던 것이다.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">나는 모든 일은 시작보다 끝이 중요하다고 생각하며, 사람과의 관계도 마찬가지라고 생각함.<br />시작에는 설렘과 충동성, 도파민이 있음.<br />반면 끝은 책임감, 희생정신, 전우애가 필요함.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\"><b>'어떤 일의 끝에 다다랐을 때 어떻게 행동하는가' 는 그 사람이 고통을 대하는 태도를 보여주는 좋은 리트머스 테스트</b>다.<br />가장 끝의 순간에 하는 행동은 그 사람에 대해 정말 많은 것을 보여준다.<br />...<br />그래서 함께 일할 사람을 채용할 때 반드시 체크해야 할 것은 '전 직장을 퇴사할 때 어떻게 행동했는가'이다.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">자신이 사지 않을 것은 팔지 않는다.<br />존경하지 않고 존중하지 않는 사람 밑에서 일하지 않는다.<br />같이 있으면 즐거운 사람들하고만 일한다.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">정기구독 사업은 7일 무료체험을 시작하면서 고객 수가 빠르게 증가했고, 12개월 장기상품 판매로 매출도 올라가기 시작했음.<br />그 와중에 연말 프로모션 준비까지 더해지며 팀 전체가 매우 바쁘고 정신없었음.<br />하지만 밤늦게까지 야근을 해도 사무실엔 항상 활력이 돌았음.<br /><b>사업 지표가 올라가고 매출이 상승하면 누가 시키지 않아도 신나서 일한다는 것을 알게 됨</b>.<br />...<br />마지막으로 2019년 4월에 만들기 시작한 '커리어리'가 있었음.<br />이 서비스는 2년이 되도록 지지부진한 상태였음.<br />이런 상황에서는 팀 내 갈등 역시 두드러지기 마련이라는 것도, 아무리 HR 차원에서 해결책을 강구해도 사업 성과가 해결되지 않는 한 백약이 무효라는 것도 배웠음.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">평시 CEO의 특성은 소위 '좋은 사람이자 좋은 리더'의 전형적 모습이다.<br />반대로 전시 CEO의 특성은 가까이하고 싶지 않은 인물 유형이고, 특히 한국 사회의 기준에서는 비판받기 쉬운 점들도 다수 포함되어 있다.<br />그렇기에 <b>전시 CEO로 일하려면 어릴때부터 학습된 '좋은 사회인'에서 벗어날 뻔뻔함이 필요</b>한데, 나는 그러지 못했다.<br />...<br />전시 CEO는 어디까지나 긴급 상황에서 일시적으로 유효하다고 생각했고, 내가 읽었던 많은 책에 나오는 것처럼 평시 CEO 모드로 일하는 것이 더 우월한 방향이라고 믿었다.<br />하지만 지금 돌아보면, 나는 그저 전시 CEO로서 '미움받을 용기'가 없었던 것이다.<br />&lt;하드씽&gt; 에서 <b>벤 호로위츠는 대부분의 경영서들이 평화로운 시기의 성공적인 기업들을 연구한 컨설턴트가 썼다는 점을 기억해야 한다고 주장</b>한다.<br />평시 CEO가 사용하는 방법들에 대해 알려주는 책이 아니라, 전시 CEO가 탁월하게 경영하는 법을 알려주는 책을 읽어야 한다는 것이다.<br />문제는 그런 책이 거의 없다는 것이라며, 나처럼 책으로 학습하는 것을 좋아하는 독자에게 날카롭게 경고한다.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">이나모리 가즈오는 전시 상황을 겪은 기업들을 살려낸 생생한 경험이 있었기에, &lt;왜 리더인가&gt; 에서 이렇게 적는다.</p>\n<p data-ke-size=\"size16\">\"나는 느슨하고 헐거운 마음가짐으로 문제의 뒤로 물러나 좋은 사람인 척하는 리더보다 가끔은 미치광이 소리를 듣더라도 무소처럼 일의 정면으로 달려들어 일을 완벽하게 장악하는 리더를 훨씬 신뢰한다.<br />우리는 일 앞에서 좀 더 난폭해져도 된다.<br />아니, 리더라면 반드시 그래야만 한다\"</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">레이 달리오가 쓴 책 &lt;원칙&gt;을 읽었음.</p>\n<p data-ke-size=\"size16\">\"<b>사람을 계획에 맞춰라</b>.<br />당신에게 필요한 사람들의 유형은 조직의 설계에 달려 있기 때문에, 조직을 구성할 때는 계획이 사람보다 선행한다.<br />조직을 설계하면서 일을 잘하기 위해 개인들에게 요구되는 특성에 대한 명확한 심상지도를 만들어라.<br />...<br /><b>사람에 맞추기 위해 업무를 계획해서는 안 된다</b>.<br />이것은 시간이 흐르면 대부분 실패로 드러난다.<br /><b>이런 일은 해고하는 것을 꺼리는 사람이 그 사람이 할 수 있는 다른 일을 찾아보려는 경향이 있을 때 흔히 발생한다</b>\"</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">\"내가 지금까지 만난 대표 중에 늦게 레이오프해서 후회한 대표는 있어도, 빨리 레이오프해서 후회한 대표는 한 명도 없었다.<br />대표가 '뭔가 잘못되었는제'라고 느끼고 있다면 그때가 결정해야 할 타이밍이다.<br />대표가 가진 직감을 믿어라.\"</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">필요한 일을 할 수 있는 사람이 지금 팀에서 누구인지 매칭하는 작업도 진행함.<br />변화에 빠르고 유연하게 적응할 수 있는 능력,<br />계속 학습하며 성장하는 마인드셋을 보인 사람과 그렇지 않은 사람에 대해서도 의견을 듣고 여러 차례 논의를 거침.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">7월 1일 19명이었던 팀이 8월 20일 무렵 11명으로 줄어 있었음.<br /><b>레이오프는 한 명이었지만, 연쇄작용으로 7명이 자진 퇴사했기 때문임</b>.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">레이오프를 거치면서, 채용에 대한 생가에 변화가 생김<br />첫 번째, 유능한 제너럴리스트를 뽑자.<br />비가와도 망하는 게 스타트업이라고, 한 치 앞을 알 수 없는 상황에서는 사업이 언제 어떻게 바뀔지 모름.<br />시장 상황에 맞게 계속 변화하고 또 변화해야만 생존할 수 있음.<br />스페셜리스트에게 맞지 않는 일을 주는 것은 개인에게도 조직에도 불행임.<br />따라서 <b>사업모델에 여전히 불확실성이 높은 상태에서는 유능한 스페셜리스트가 아니라 유능한 제너럴리스트를 뽑아야 함</b>.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">내가 생각한 스타트업의 가장 큰 특징은 '생존의 불확실성'이었음</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">실력과 태도 둘 다 좋은 사람만 채용한다는 것은 현실적으로 매우 어려운 일이었고, 또 다른 어려운 점은 실력과 태도라는 개념이 참으로 추상적이라는 사실이었음.<br />...<br />여기서 말하는 태도는 <b>조직에서 선호하는 속성이 기준</b>임.<br />...<br />나의 경우, 시간이 갈수록 점점 더 중요하게 본 세 가지 속성이 겸손함, 성실함, 책임감이었음.<br />반대로 말하자면 겸손하지 않은 사람, 성실하지 않은 사람, 책임감이 없는 사람은 '곱하기'에서 0에 해당한다고 생각했음.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">첫 번째 대규모 레이오프를 계획하면서 두 가지 선택지를 놓고 고민했음.<br />동일한 액수의 현금을 절감한다면,<br />a. 많은 인원을 레이오프하고, 기존 인력들의 보상을 유지한다.<br />b. 적은 인원을 레이오프하는 대신, 기존 인력들의 현금 보상을 절감한다.<br />나는 두 번째를 선택함.<br />커리어리가 이제 막 개발자라는 주요한 타깃 고객을 찾아낸 상황이었고, 이들이 사랑할 수 있는 제품을 만들려면 빠르게 많은 실험을 해야 하므로 제품 조직은 꼭 필요하다는 생각 떄문이었음.<br />...<br />당시 팀 규모는 60명 후반에서 70명 초반 정도였고, 레이오프 대상자는 10% 이내였음.<br />각자 받는 총보상액에 따라 현금 보상의 삭감 수준이 달랐는데 5~20% 범위였고, 나는 40%를 삭감함<br />...<br />놀랍게도 현금 보상을 줄이자는 제안에 모두가 동의했음.<br />...<br />하지만 내가 잘못 판단한 것이 있었음.<br />타운홀을 기점으로 레이오프에 대한 커뮤니케이션을 종료하고 <b>그 다음 목표를 향해 빠르게 달리자고 치열함을 독려하기보다는, 어수선하고 상처받았을 팀원들을 감정적으로 케어하는 데 조직의 에너지를 쓰게 만든 것</b>임.<br />회사의 공식적인 리소스가 게속 포스트 레이오프에 쓰이게 됨.<br /><b>미래로 나아가는 것이 아니라 과거의 상처를 핥는 데 팀의 중요한 시간을 쓰게 한 것</b>, 즉 레이오프 이후 냉정하지 못했떤 나 자신에 대한 반성이 있음.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">2023년 11월에 진행된 대규모 레이오프의 목적은 첫 번째 대규모 레이오프에서 얻은 크나큰 깨달음에서 비롯되었음.<br /><b>현금 보상 삭감이라는 선택이 얼마나 인간의 본성에 어긋나는 결정이었는가</b>에 대한 아하 모멘트가 뒤늦게 찾아왔기 때문임.<br />...<br />어렵게 채용한 팀원들을 최대한 데리고 가야 원하는 성과를 낼 수 있다는 이유 때문이었음.<br />...<br />약 반년이 지나 깨달은 것은 <b>'내가 회사를 위해 보상을 희생했다' 라는 인식으로 여러 부작용이 발생</b>했다는 것임.<br />개인으로서는 자연스러운 감정이라고 생각함.<br />나 자신도 되돌아보니, 급여에 대한 희생을 요구했다는 미안함 때문에 팀과 정확한 커뮤니케이션을 해야 할 때도 심리적 장벽으로 인해 그러지 못했음.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\"><b>레이오프를 많이 했다고 후회하는 대표는 본 적이 없다</b>.<br />할 수 있는 한 최대한 해라.<br />60~70%까지 해도 된다.<br />이렇게 해도 의외로 회사는 잘 돌아간다.<br /><b>처음 레이오프를 적게 했다가 두 번 레이오프하는 게 최악이다</b>.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">&lt;파워풀&gt; 에는 수십 명 규모의 작은 스타트업이었던 넷플릭스가 전 세계에 서비스를 제공하는 글로벌 기업으로 확장하던 시기에 겪은 내부 진통의 경험이 나온다.<br />패티 맥코드에게 초기 멤버였던 팀원이 회사가 변했다며 불만을 토로하자, <b>당신은 50명 규모의 스타트업 조직에서 가장 행복해할 사람이라며 이제는 회사와 개인의 교집합이 종료되었다는 사실</b>을 알려준다.<br />또한 커리어 상담을 하러 찾아온 직원에게는 자신이 좋아하고 잘하는 일을 계속 같은 회사에서 할 필요는 없다고 조언한다.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">이사진이나 주요 주주를 눈치 봐야 할 상사로 생각하지 말고, 문제를 상담할 수 있는 멘토로 여겨라.<br />기업가치 극대화라는 관점에서 이들은 그 어떤 이들보다 우군이다.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">2024년 &lt;이나모리 가즈오의 회계경영&gt; 이라는 책을 선물 받았다.<br />...<br />'60년간 수많은 기업을 이끌며 내가 단 한 번도 적자를 기록한 적이 없는 비결은 매출은 최대로, 경비는 최소로 라는 아주 단순한 원칙을 목숨처럼 지켰기 때문이다.<br />...<br />함부로 사람 늘리지마라. 원자재는 딱 필요한 만큼만 사라.<br />...<br />이익이 없다면 당신의 사업은 사업이 아니다.<br />이익이 없으면 그것은 회사가 아니다.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">제프 베이조스는 의사결정 전에 '<b>이 결정은 번복 가능한가, 아닌가</b>'를 먼저 따져봐야 한다고 말했다.<br />대부분은 번복 가능한 의사결정에 속하므로 원하는 결과가 아니라면 결정을 빠르게 되돌리면 그만이다.<br />하지만 주주에 관한 결정 (누구를 주주로 초대하고, 그가 몇 퍼센트의 지분을 갖는가)은 번복하기 어려운 데다 번복하려면 큰 비용을 치러야 한다.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">회사 매각 과정을 거치면서 내가 절실하게 깨달았던 것은, <b>창업자와 주주 사이에 중요한 어젠다 중 하나가 회사의 최종 목표와 주주의 엑시트 플랜</b>에 대한 대화라는 점이다.<br />VC 주주는 우리 회사에 투자한 펀드의 만기일이 있다보니 오랜 시간 기다려줄 수도 없거니와, 애초에 오랜 기간이 필요한 사업이었다면 VC 투자가 적합하지도 않다.<br />'우리의 목표는 매각인가, IPO인가? 매각이라면 언제 얼마의 가치로 어떤 곳을 잠재 인수자로 고려하여 진행해야 하는가? IPO라면 언제 얼마의 가치로 어디에 상장할 것인가?<br />다음 라운드는 언제, 얼마로 펀드레이징을 할 것인가?<br />펀드 만기와 수익률을 고려할 때 납득할 만한 계획인가?'</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">회사의 최종 목표와 주주의 엑시트 플랜에 대한 고민은 '중요하지만 급하지는 않은 일'에 해당했고, 이런 카테고리의 일이야말로 <b>시간을 따로 빼노혹 챙겨야 한다</b>는 것을 머리로는 알았지만 몸이 따라가지 못했다.<br />'중요하지만 급하지는 않은 일'이 어느새 '중요하고 급한 일'이 되는 순간부터 혼돈이 시작되는 것은 당연지사였다.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">&lt;허브 코헨의 협상의 기술 1&gt; 의 내용이 뒤늦게 떠올랐음.<br />...<br />이 책에서 그는 <b>협상에서 승리하는 열쇠는 항상 상대방이 시간, 돈, 에너지를 먼저 투자하게 만드는 것</b>이라고 강조함.<br />어떤 형태로든 투자한 게 있어야 자신이 쏟아부은 노력을 돌려받고자 하는 심리가 발동한다는 이유 때문이었음.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">2024년 9월, 드라마 &lt;쇼군&gt;이 미국 에미상 시상식에서 18관왕을 휩쓸었다는 기사를 읽은 후 뒤늦게 몰아보았다.<br />...<br />그리고 &lt;쇼군&gt;이 내게 준 가장 큰 교훈은 '<b>약자의 협상법</b>'이었다.<br />...<br />드라마 후반, 죽음이 코앞에 닥친 상황에서 도쿠가와는 오사카 세력을 상대로 협상하면서 한 가지를 반드시 지킨다.<br />바로 <b>'시간의 주도권'만큼은 본인이 절대 놓지 않는 것</b>.<br />그는 협상 자리에서 매번 \"X라는 상황이 오면, 나는 언제까지 Y를 하겠다\"라는 식으로 말한다.<br />상황 자체는 본인 힘으로 온전히 통제할 수 없지만, 그 상황에 따른 자신의 행동만큼은 먼저 타임라인을 설정하고 상대에게 통보한다.<br />이렇게 하면 상대도 그가 제시한 타임라인을 기준으로 생각하게 된다.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">내가 만약 다시 투자받을 일이 있다면, 그때는 투자한 회사 중 잘 안된 곳 대표를 소개해달라고 할 것 같다.<br />그 대표와 이야기를 하면 이 VC가 어떤 곳인지 가장 잘 알 수 있을 것 같다.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">왜 이렇게 돈 관리가 느슨했는지 돌이켜보면, '스타트업은 속도가 생명이니, 돈으로 시간을 살 수 있다면 돈을 쓰는게 맞다' 라는 분위기에 나도 별생각 없이 편승했기 때문이라고 생각한다.<br />문제는 이 명제가 언제나 그리고 모든 사업에 통용되는 건 아니라는 사실이다.<br />우리 사업은 '지금 돈과 시간 중 무엇에 더 높은 가치를 둘 것인가'에 대해 건강검진하듯 꾸준히 체크했어야 했는데, 그러지 못했다.</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">&lt;월마트, 두려움 없는 도전&gt;을 읽고 나서, 제포 베이조스는 분명 샘 월턴으로부터 영향을 받았을 것이라고 생각했다.<br />...<br />'경쟁에서 이기는 것보다 비용 관리에 더 집중하라.<br />이를 잘하면 반드시 경쟁우위를 선점할 수 있다.<br />우리는 매출액 대비 비용이 가장 낮다는 점에서 업계 내 1위를 차지했다.<br /><b>사업을 하다 보면 몇 차례 실수하기 마련이다</b>.<br /><b>그대로 전반적인 운영 효율이 높으면 실수를 해도 큰 타격을 입을 우려는 없다</b>'</p>\n</blockquote>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">'내가 약간은 손해 보는 것이 좋다' 라는 생각으로 임하자.<br />...<br />내가 약간은 손해 본다는 생각으로 타협해야만 상대방은 5대5라고 느낀다고 했다.<br />반대로 내가 5대5라고 생각하고 타협하면 상대는 오히려 손해 봤다고 생각할 거라고.</p>\n</blockquote>",
        "contentSnippet": "예전 최정우님이 쓰신 옐로모바일의 흥망성쇠를 담은 스타트업은 어떻게 유니콘이 되는가 이후 오랫만에 스타트업의 대표님이 직접 쓰신 일기장 같은 책을 봤다.\n퍼블리는 인프런과 꽤나 닮은 부분이 많았다.\n퍼블리 & 커리어리 & 위하이어\n인프런 교육 & 인프런 커뮤니티 & 랠릿\n꼭 퍼블리만 아니더라도 대부분의 커리어 플랫폼들은 그 방향성은 비슷하게 간다.\n교육 & 채용 & 커뮤니티\n시작은 서로 다를 수 있으나, 큰 그림은 다들 비슷하게 보고 있다.\n원티드처럼 채용으로 시작해서 커뮤니티와 교육으로 확장하는 경우도 있으며\n리멤버처럼 (명함) 커뮤니티로 시작해서 채용으로 확장한 경우도 있으며\n인프런처럼 교육으로 시작해서 커뮤니티, 채용으로 확장한 경우도 있다.\n다만, 지금의 우리는 교육으로 글로벌 시장을 노리는 것으로 에너지를 집중하고 있다.\n3개 꼭지점을 모두 다 달성한 플랫폼은 국내/국외 어디에도 없다.\n아마도 가장 근접한 건 링크드인이다.\n커뮤니티와 채용에 있어서는 세계 최고가 되었고, 린다닷컴을 인수해서 교육쪽으로도 계속해서 시도하고 있으니 말이다.\n국내에서는 확실하게 이 영역을 모두 확보한 플랫폼이 없다.\n하지만 많은 커리어 플랫폼이 이 영역들을 확보하기 위해 도전하고 있다.\n그러다보니 퍼블리를 비롯해 비슷한 결의 서비스들은 어떻게 시도하는지 자주 지켜봤다.\n마침 퍼블리에는 좋아하는 콘텐츠들도 많았어서 구독제 멤버십도 가입해서 자주 사용했다.\n\n\n퍼블리를 자주 이용하던 중,\n개발자들을 위한 SNS 서비스 '커리어리'를 시작한다는 소식을 들었다.\n'위하이어' 라는 ATS 서비스를 시작하신다는 것도 들었다.\n그리고 어느 순간 퍼블리에 읽고 싶은 콘텐츠가 더이상 추가되지 않았다.\n내 취향의 콘텐츠가 없다보니 얼마되지 않는 그 구독료도 아까웠다.\n그래서 훨씬 더 내 취향인 폴인의 구독을 시작했고, 지금까지도 연간 구독으로 계속해서 콘텐츠를 보고 있다.\n2023년엔 대표인 쭈와 함께 박소령 대표님, 이승국 CPO님과 함께 저녁식사를 먹으면서 스타트업에 대한 이야기를 나누기도 했다.\n커리어리와 위하이어로 개발자와 채용에 관해서 집중하신다는 것도 알게 됐다.\n그래서 어떤 과정으로 퍼블리와 그 외 서비스들이 시작했는지, 비중은 어떻게 되는지, 시리즈 B 투자로 받은 135억을 어떻게 활용하셨는지 등등 많이 궁금했었다.\n한국 콘텐츠 스타트업에서 퍼블리가 남긴 족적은 분명히 크다.\n그래서 퍼블리가 어떻게 10년을 보내왔는지 그 기록이 너무나 중요하다고 생각했는데, 이번에 이렇게 책으로 정리해주셔서 정말 감사했다.\n금, 토 이틀만에 다 읽으면서 지금 스타트업 시리즈 A, B 단계의 회사에서는 이 노트가 얼마나 귀한 기록인지 감사한 마음뿐이다.\nVC와의 관계와 투자는 어떻게 진행해야하는지,\n투자 받은 자금을 어떻게 활용해야하는지,\n레이오프는 어떻게 해야 덜 후회하고 앞으로를 위해 도움이 되는지 등등.\n아직 유니콘이 되지 못한 스타트업에 다니시는 분들이라면 무조건 적으로 읽어보시라고 추천하고 싶다.\n책 제목이 \"실패를 통과하는 일\"이다.\n인프런은 꼭 통과하지 않기로 몇번이고 다짐했다.\n책 속 문장\n매월 달성해야하는 재무 목표는 곧 매주, 매일의 목표로도 환산되기에 업무 우선순위에 대한 감각이 더 예민해지면서 긴장감을 가질 수 있었음.\n팀과 커뮤니케이션을 할 때도 단순히 \"BEP를 달성하자\"가 아니라 \"2023년 4월에 ㅇㅇ곳의 신규고객사가 ㅇㅇ원을 결제해서 매출이 00원 발생하면 BEP를 덜상할 수 있으니 집중하자\" 라고 말하면, 해야 할 일이 명료해져서 좋았음.\n사업에서 돈을 벌려면 '남이 하기 싫은 일을 대신 해주고, 그 대가로 돈을 받는다'라는 고전적인 명제가 진리임을 다시 한번 절감함.\n부와 행복은 두 가지 요소로 이뤄진 등식임을 항상 기억하자.\n두 가지란 당신이 '가진 것(현실)'과 '기대하는 것(기대치)'이다.\n이 둘은 똑같이 중요하다.\n따라서 가진 것을 늘리는 데에는 엄청난 노력을 쏟으면서 기대치를 관리하는 데에는 거의 신경을 쓰지 않는 것은 말이 안된다.\n특히 우리가 훨씬 더 쉽게 통제할 수 있는 것은 현실이 아닌 기대치이므로 더욱 그렇다.\n...\n정말로 원하는 것은 기대한 것과 실제 결과의 차이를 경험하는 일이다.\n우리는 기대한 것보다 더 좋은 결과를 얻었을 때 만족과 성취감을 느낀다.\n커리어 소셜미디어를 먼저 만들고 나중에 비즈니스 모델을 붙이는 것, 채용관리 소프트웨어를 먼저 만들고 나중에 신규고객에게 세일즈하는 것은 모두 돈 버는 것을 뒤로 미룬 결정이었다.\n최저 가치 단계에서 어떻게 돈을 벌어야하는지, 이렇게 돈 버는 방법이 나와 잘 맞는지, 앞으로도 지치지 않고 꾸준히 할 수 있는 일인지 미리 파악하고 고칠 수 있는 기회를 날려버리고 말았던 것이다.\n나는 모든 일은 시작보다 끝이 중요하다고 생각하며, 사람과의 관계도 마찬가지라고 생각함.\n시작에는 설렘과 충동성, 도파민이 있음.\n반면 끝은 책임감, 희생정신, 전우애가 필요함.\n'어떤 일의 끝에 다다랐을 때 어떻게 행동하는가' 는 그 사람이 고통을 대하는 태도를 보여주는 좋은 리트머스 테스트다.\n가장 끝의 순간에 하는 행동은 그 사람에 대해 정말 많은 것을 보여준다.\n...\n그래서 함께 일할 사람을 채용할 때 반드시 체크해야 할 것은 '전 직장을 퇴사할 때 어떻게 행동했는가'이다.\n자신이 사지 않을 것은 팔지 않는다.\n존경하지 않고 존중하지 않는 사람 밑에서 일하지 않는다.\n같이 있으면 즐거운 사람들하고만 일한다.\n정기구독 사업은 7일 무료체험을 시작하면서 고객 수가 빠르게 증가했고, 12개월 장기상품 판매로 매출도 올라가기 시작했음.\n그 와중에 연말 프로모션 준비까지 더해지며 팀 전체가 매우 바쁘고 정신없었음.\n하지만 밤늦게까지 야근을 해도 사무실엔 항상 활력이 돌았음.\n사업 지표가 올라가고 매출이 상승하면 누가 시키지 않아도 신나서 일한다는 것을 알게 됨.\n...\n마지막으로 2019년 4월에 만들기 시작한 '커리어리'가 있었음.\n이 서비스는 2년이 되도록 지지부진한 상태였음.\n이런 상황에서는 팀 내 갈등 역시 두드러지기 마련이라는 것도, 아무리 HR 차원에서 해결책을 강구해도 사업 성과가 해결되지 않는 한 백약이 무효라는 것도 배웠음.\n평시 CEO의 특성은 소위 '좋은 사람이자 좋은 리더'의 전형적 모습이다.\n반대로 전시 CEO의 특성은 가까이하고 싶지 않은 인물 유형이고, 특히 한국 사회의 기준에서는 비판받기 쉬운 점들도 다수 포함되어 있다.\n그렇기에 전시 CEO로 일하려면 어릴때부터 학습된 '좋은 사회인'에서 벗어날 뻔뻔함이 필요한데, 나는 그러지 못했다.\n...\n전시 CEO는 어디까지나 긴급 상황에서 일시적으로 유효하다고 생각했고, 내가 읽었던 많은 책에 나오는 것처럼 평시 CEO 모드로 일하는 것이 더 우월한 방향이라고 믿었다.\n하지만 지금 돌아보면, 나는 그저 전시 CEO로서 '미움받을 용기'가 없었던 것이다.\n<하드씽> 에서 벤 호로위츠는 대부분의 경영서들이 평화로운 시기의 성공적인 기업들을 연구한 컨설턴트가 썼다는 점을 기억해야 한다고 주장한다.\n평시 CEO가 사용하는 방법들에 대해 알려주는 책이 아니라, 전시 CEO가 탁월하게 경영하는 법을 알려주는 책을 읽어야 한다는 것이다.\n문제는 그런 책이 거의 없다는 것이라며, 나처럼 책으로 학습하는 것을 좋아하는 독자에게 날카롭게 경고한다.\n이나모리 가즈오는 전시 상황을 겪은 기업들을 살려낸 생생한 경험이 있었기에, <왜 리더인가> 에서 이렇게 적는다.\n\"나는 느슨하고 헐거운 마음가짐으로 문제의 뒤로 물러나 좋은 사람인 척하는 리더보다 가끔은 미치광이 소리를 듣더라도 무소처럼 일의 정면으로 달려들어 일을 완벽하게 장악하는 리더를 훨씬 신뢰한다.\n우리는 일 앞에서 좀 더 난폭해져도 된다.\n아니, 리더라면 반드시 그래야만 한다\"\n레이 달리오가 쓴 책 <원칙>을 읽었음.\n\"사람을 계획에 맞춰라.\n당신에게 필요한 사람들의 유형은 조직의 설계에 달려 있기 때문에, 조직을 구성할 때는 계획이 사람보다 선행한다.\n조직을 설계하면서 일을 잘하기 위해 개인들에게 요구되는 특성에 대한 명확한 심상지도를 만들어라.\n...\n사람에 맞추기 위해 업무를 계획해서는 안 된다.\n이것은 시간이 흐르면 대부분 실패로 드러난다.\n이런 일은 해고하는 것을 꺼리는 사람이 그 사람이 할 수 있는 다른 일을 찾아보려는 경향이 있을 때 흔히 발생한다\"\n\"내가 지금까지 만난 대표 중에 늦게 레이오프해서 후회한 대표는 있어도, 빨리 레이오프해서 후회한 대표는 한 명도 없었다.\n대표가 '뭔가 잘못되었는제'라고 느끼고 있다면 그때가 결정해야 할 타이밍이다.\n대표가 가진 직감을 믿어라.\"\n필요한 일을 할 수 있는 사람이 지금 팀에서 누구인지 매칭하는 작업도 진행함.\n변화에 빠르고 유연하게 적응할 수 있는 능력,\n계속 학습하며 성장하는 마인드셋을 보인 사람과 그렇지 않은 사람에 대해서도 의견을 듣고 여러 차례 논의를 거침.\n7월 1일 19명이었던 팀이 8월 20일 무렵 11명으로 줄어 있었음.\n레이오프는 한 명이었지만, 연쇄작용으로 7명이 자진 퇴사했기 때문임.\n레이오프를 거치면서, 채용에 대한 생가에 변화가 생김\n첫 번째, 유능한 제너럴리스트를 뽑자.\n비가와도 망하는 게 스타트업이라고, 한 치 앞을 알 수 없는 상황에서는 사업이 언제 어떻게 바뀔지 모름.\n시장 상황에 맞게 계속 변화하고 또 변화해야만 생존할 수 있음.\n스페셜리스트에게 맞지 않는 일을 주는 것은 개인에게도 조직에도 불행임.\n따라서 사업모델에 여전히 불확실성이 높은 상태에서는 유능한 스페셜리스트가 아니라 유능한 제너럴리스트를 뽑아야 함.\n내가 생각한 스타트업의 가장 큰 특징은 '생존의 불확실성'이었음\n실력과 태도 둘 다 좋은 사람만 채용한다는 것은 현실적으로 매우 어려운 일이었고, 또 다른 어려운 점은 실력과 태도라는 개념이 참으로 추상적이라는 사실이었음.\n...\n여기서 말하는 태도는 조직에서 선호하는 속성이 기준임.\n...\n나의 경우, 시간이 갈수록 점점 더 중요하게 본 세 가지 속성이 겸손함, 성실함, 책임감이었음.\n반대로 말하자면 겸손하지 않은 사람, 성실하지 않은 사람, 책임감이 없는 사람은 '곱하기'에서 0에 해당한다고 생각했음.\n첫 번째 대규모 레이오프를 계획하면서 두 가지 선택지를 놓고 고민했음.\n동일한 액수의 현금을 절감한다면,\na. 많은 인원을 레이오프하고, 기존 인력들의 보상을 유지한다.\nb. 적은 인원을 레이오프하는 대신, 기존 인력들의 현금 보상을 절감한다.\n나는 두 번째를 선택함.\n커리어리가 이제 막 개발자라는 주요한 타깃 고객을 찾아낸 상황이었고, 이들이 사랑할 수 있는 제품을 만들려면 빠르게 많은 실험을 해야 하므로 제품 조직은 꼭 필요하다는 생각 떄문이었음.\n...\n당시 팀 규모는 60명 후반에서 70명 초반 정도였고, 레이오프 대상자는 10% 이내였음.\n각자 받는 총보상액에 따라 현금 보상의 삭감 수준이 달랐는데 5~20% 범위였고, 나는 40%를 삭감함\n...\n놀랍게도 현금 보상을 줄이자는 제안에 모두가 동의했음.\n...\n하지만 내가 잘못 판단한 것이 있었음.\n타운홀을 기점으로 레이오프에 대한 커뮤니케이션을 종료하고 그 다음 목표를 향해 빠르게 달리자고 치열함을 독려하기보다는, 어수선하고 상처받았을 팀원들을 감정적으로 케어하는 데 조직의 에너지를 쓰게 만든 것임.\n회사의 공식적인 리소스가 게속 포스트 레이오프에 쓰이게 됨.\n미래로 나아가는 것이 아니라 과거의 상처를 핥는 데 팀의 중요한 시간을 쓰게 한 것, 즉 레이오프 이후 냉정하지 못했떤 나 자신에 대한 반성이 있음.\n2023년 11월에 진행된 대규모 레이오프의 목적은 첫 번째 대규모 레이오프에서 얻은 크나큰 깨달음에서 비롯되었음.\n현금 보상 삭감이라는 선택이 얼마나 인간의 본성에 어긋나는 결정이었는가에 대한 아하 모멘트가 뒤늦게 찾아왔기 때문임.\n...\n어렵게 채용한 팀원들을 최대한 데리고 가야 원하는 성과를 낼 수 있다는 이유 때문이었음.\n...\n약 반년이 지나 깨달은 것은 '내가 회사를 위해 보상을 희생했다' 라는 인식으로 여러 부작용이 발생했다는 것임.\n개인으로서는 자연스러운 감정이라고 생각함.\n나 자신도 되돌아보니, 급여에 대한 희생을 요구했다는 미안함 때문에 팀과 정확한 커뮤니케이션을 해야 할 때도 심리적 장벽으로 인해 그러지 못했음.\n레이오프를 많이 했다고 후회하는 대표는 본 적이 없다.\n할 수 있는 한 최대한 해라.\n60~70%까지 해도 된다.\n이렇게 해도 의외로 회사는 잘 돌아간다.\n처음 레이오프를 적게 했다가 두 번 레이오프하는 게 최악이다.\n<파워풀> 에는 수십 명 규모의 작은 스타트업이었던 넷플릭스가 전 세계에 서비스를 제공하는 글로벌 기업으로 확장하던 시기에 겪은 내부 진통의 경험이 나온다.\n패티 맥코드에게 초기 멤버였던 팀원이 회사가 변했다며 불만을 토로하자, 당신은 50명 규모의 스타트업 조직에서 가장 행복해할 사람이라며 이제는 회사와 개인의 교집합이 종료되었다는 사실을 알려준다.\n또한 커리어 상담을 하러 찾아온 직원에게는 자신이 좋아하고 잘하는 일을 계속 같은 회사에서 할 필요는 없다고 조언한다.\n이사진이나 주요 주주를 눈치 봐야 할 상사로 생각하지 말고, 문제를 상담할 수 있는 멘토로 여겨라.\n기업가치 극대화라는 관점에서 이들은 그 어떤 이들보다 우군이다.\n2024년 <이나모리 가즈오의 회계경영> 이라는 책을 선물 받았다.\n...\n'60년간 수많은 기업을 이끌며 내가 단 한 번도 적자를 기록한 적이 없는 비결은 매출은 최대로, 경비는 최소로 라는 아주 단순한 원칙을 목숨처럼 지켰기 때문이다.\n...\n함부로 사람 늘리지마라. 원자재는 딱 필요한 만큼만 사라.\n...\n이익이 없다면 당신의 사업은 사업이 아니다.\n이익이 없으면 그것은 회사가 아니다.\n제프 베이조스는 의사결정 전에 '이 결정은 번복 가능한가, 아닌가'를 먼저 따져봐야 한다고 말했다.\n대부분은 번복 가능한 의사결정에 속하므로 원하는 결과가 아니라면 결정을 빠르게 되돌리면 그만이다.\n하지만 주주에 관한 결정 (누구를 주주로 초대하고, 그가 몇 퍼센트의 지분을 갖는가)은 번복하기 어려운 데다 번복하려면 큰 비용을 치러야 한다.\n회사 매각 과정을 거치면서 내가 절실하게 깨달았던 것은, 창업자와 주주 사이에 중요한 어젠다 중 하나가 회사의 최종 목표와 주주의 엑시트 플랜에 대한 대화라는 점이다.\nVC 주주는 우리 회사에 투자한 펀드의 만기일이 있다보니 오랜 시간 기다려줄 수도 없거니와, 애초에 오랜 기간이 필요한 사업이었다면 VC 투자가 적합하지도 않다.\n'우리의 목표는 매각인가, IPO인가? 매각이라면 언제 얼마의 가치로 어떤 곳을 잠재 인수자로 고려하여 진행해야 하는가? IPO라면 언제 얼마의 가치로 어디에 상장할 것인가?\n다음 라운드는 언제, 얼마로 펀드레이징을 할 것인가?\n펀드 만기와 수익률을 고려할 때 납득할 만한 계획인가?'\n회사의 최종 목표와 주주의 엑시트 플랜에 대한 고민은 '중요하지만 급하지는 않은 일'에 해당했고, 이런 카테고리의 일이야말로 시간을 따로 빼노혹 챙겨야 한다는 것을 머리로는 알았지만 몸이 따라가지 못했다.\n'중요하지만 급하지는 않은 일'이 어느새 '중요하고 급한 일'이 되는 순간부터 혼돈이 시작되는 것은 당연지사였다.\n<허브 코헨의 협상의 기술 1> 의 내용이 뒤늦게 떠올랐음.\n...\n이 책에서 그는 협상에서 승리하는 열쇠는 항상 상대방이 시간, 돈, 에너지를 먼저 투자하게 만드는 것이라고 강조함.\n어떤 형태로든 투자한 게 있어야 자신이 쏟아부은 노력을 돌려받고자 하는 심리가 발동한다는 이유 때문이었음.\n2024년 9월, 드라마 <쇼군>이 미국 에미상 시상식에서 18관왕을 휩쓸었다는 기사를 읽은 후 뒤늦게 몰아보았다.\n...\n그리고 <쇼군>이 내게 준 가장 큰 교훈은 '약자의 협상법'이었다.\n...\n드라마 후반, 죽음이 코앞에 닥친 상황에서 도쿠가와는 오사카 세력을 상대로 협상하면서 한 가지를 반드시 지킨다.\n바로 '시간의 주도권'만큼은 본인이 절대 놓지 않는 것.\n그는 협상 자리에서 매번 \"X라는 상황이 오면, 나는 언제까지 Y를 하겠다\"라는 식으로 말한다.\n상황 자체는 본인 힘으로 온전히 통제할 수 없지만, 그 상황에 따른 자신의 행동만큼은 먼저 타임라인을 설정하고 상대에게 통보한다.\n이렇게 하면 상대도 그가 제시한 타임라인을 기준으로 생각하게 된다.\n내가 만약 다시 투자받을 일이 있다면, 그때는 투자한 회사 중 잘 안된 곳 대표를 소개해달라고 할 것 같다.\n그 대표와 이야기를 하면 이 VC가 어떤 곳인지 가장 잘 알 수 있을 것 같다.\n왜 이렇게 돈 관리가 느슨했는지 돌이켜보면, '스타트업은 속도가 생명이니, 돈으로 시간을 살 수 있다면 돈을 쓰는게 맞다' 라는 분위기에 나도 별생각 없이 편승했기 때문이라고 생각한다.\n문제는 이 명제가 언제나 그리고 모든 사업에 통용되는 건 아니라는 사실이다.\n우리 사업은 '지금 돈과 시간 중 무엇에 더 높은 가치를 둘 것인가'에 대해 건강검진하듯 꾸준히 체크했어야 했는데, 그러지 못했다.\n<월마트, 두려움 없는 도전>을 읽고 나서, 제포 베이조스는 분명 샘 월턴으로부터 영향을 받았을 것이라고 생각했다.\n...\n'경쟁에서 이기는 것보다 비용 관리에 더 집중하라.\n이를 잘하면 반드시 경쟁우위를 선점할 수 있다.\n우리는 매출액 대비 비용이 가장 낮다는 점에서 업계 내 1위를 차지했다.\n사업을 하다 보면 몇 차례 실수하기 마련이다.\n그대로 전반적인 운영 효율이 높으면 실수를 해도 큰 타격을 입을 우려는 없다'\n'내가 약간은 손해 보는 것이 좋다' 라는 생각으로 임하자.\n...\n내가 약간은 손해 본다는 생각으로 타협해야만 상대방은 5대5라고 느낀다고 했다.\n반대로 내가 5대5라고 생각하고 타협하면 상대는 오히려 손해 봤다고 생각할 거라고.",
        "guid": "https://jojoldu.tistory.com/845",
        "categories": [
          "도서",
          "박소령",
          "스타트업",
          "실패를 통과하는 일",
          "인프런",
          "커리어리",
          "퍼블리"
        ],
        "isoDate": "2025-09-13T11:49:26.000Z"
      }
    ]
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "코드 품질 개선 기법 20편: 이례적인 예외 과대 포장",
        "link": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-20",
        "pubDate": "Fri, 12 Sep 2025 02:00:00 GMT",
        "content": "이 글은 2024년 4월 4일에 일본어로 먼저 발행된 기사를 번역한 글입니다.LY Corporation은 높은 개발 생산성을 유지하기 위해 코드 품질 및 개발 문화 개선에 힘쓰고 ...",
        "contentSnippet": "이 글은 2024년 4월 4일에 일본어로 먼저 발행된 기사를 번역한 글입니다.LY Corporation은 높은 개발 생산성을 유지하기 위해 코드 품질 및 개발 문화 개선에 힘쓰고 ...",
        "guid": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-20",
        "isoDate": "2025-09-12T02:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": [
      {
        "title": "Kubernetes CPU Limit을 사용하면 벌어지는 일",
        "link": "https://meetup.nhncloud.com/posts/395",
        "pubDate": "Sun, 14 Sep 2025 23:39:12 GMT",
        "content": "[![NHN Cloud_meetup banner_K8s CPU limit_202509-01.png](https://image.toast.com/aaaadh/real/2025/techblog/NHN%20Cloudmeetup%20bannerK8s%20CPU%20limit20250901.png)](https://www.nhncloud.com/kr)\r\r\n\r\r\n## 들어가며\r\r\n오늘날 대부분의 서비스가 컨테이너 환경을 이용하고 있고, 컨테이너를 실행하는 환경으로는 Kubernetes가 표준으로 자리 잡고 있습니다. Kubernetes에서 컨테이너를 실행할 때는 Pod를 사용하는데요. Pod를 사용할 때 컨테이너의 리소스를 얼마나 할당할 것인가는 클러스터의 안정성과 연결되어 있기 때문에 중요한 문제 중 하나입니다. Pod의 컴퓨팅 리소스는 보통 다음과 같이 **requests**와 **limit**으로 설정할 수 있습니다.\r\r\n\r\r\n```\r\r\napiVersion: v1\r\r\nkind: Pod\r\r\nmetadata:\r\r\n  name: frontend\r\r\nspec:\r\r\n  containers:\r\r\n  - name: app\r\r\n    image: images.my-company.example/app:v4\r\r\n    resources:\r\r\n      requests:\r\r\n        memory: \"64Mi\"\r\r\n        cpu: \"250m\"\r\r\n      limits:\r\r\n        memory: \"128Mi\"\r\r\n        cpu: \"500m\"\r\r\n  - name: log-aggregator\r\r\n    image: images.my-company.example/log-aggregator:v6\r\r\n    resources:\r\r\n      requests:\r\r\n        memory: \"64Mi\"\r\r\n        cpu: \"250m\"\r\r\n      limits:\r\r\n        memory: \"128Mi\"\r\r\n        cpu: \"500m\"\r\r\n\r\r\n```\r\r\n<br>\r\r\n리소스를 설정할 때 우리는 보통 메모리를 중심으로 정하는데요, 컨테이너의 메모리 사용량이 한계값에 도달하면 Pod는 재실행됩니다.\r\r\n그렇다면, CPU 사용량의 경우에는 어떨까요? 자주 사용되진 않지만 한 번쯤 알아두면 좋은 CPU 사용량 제한에 대해 알아보았습니다.\r\r\n<br>\r\r\n## Kubernetes CPU Resource 설정\r\r\n먼저 Pod의 Resource 항목에서 설정 가능한 CPU의 Request와 Limit, 그리고 단위에 대해 알아보도록 하겠습니다.\r\r\n\r\r\n### 1. CPU Requests\r\r\nCPU requests는 컨테이너가 정상적으로 실행하기 위한 최소한의 CPU 양을 의미합니다. requests는 kube-scheduler가 Pod를 노드에 할당하는 스케줄링 작업에서 사용합니다. kube-scheduler는 Pod의 requests 값을 합산하여 할당 가능한 노드를 찾아서 Pod를 배치합니다. 노드에 Pod의 requests를 수용할 만한 여유가 있어야 할당이 되는 것이죠. 이 조건을 만족하는 노드가 없다면 Pod는 pending 상태로 스케줄링되지 않습니다.\r\r\nPod가 특정 노드에 스케줄링되었다면 요청된 CPU의 양은 보장됩니다. 이 말은 requests의 양만큼 CPU를 항상 점유한다는 뜻은 아닙니다. CPU 사용에 경합이 발생했을 때도 요청한 만큼의 CPU 시간을 할당 받는 것을 보장합니다. requests의 값이 없다면 Pod가 비효율적으로 배치될 수 있고 필요 이상의 클러스터 자원을 사용하여 불필요한 비용 지출이 발생할 수 있습니다.\r\r\n\r\r\n### 2. CPU Limits\r\r\nCPU limits는 컨테이너가 사용할 수 있는 CPU의 절대적인 최댓값을 의미하며 kubelet이 관리합니다. Pod의 컨테이너가 limits를 초과하여 CPU를 사용하려 할 때 해당 컨테이너의 CPU 사용을 인위적으로 낮추는 스로틀링(Throttling)을 통해 상한선을 강제합니다. limits는 여러 서비스가 동시에 실행되고 있는 Kubernetes 클러스터에서 하나의 컨테이너가 CPU를 과점하여 다른 컨테이너의 성능에 영향을 주거나 노드의 안정성을 해치는 CPU 기아 상태를 방지하는 데 의미가 있습니다.\r\r\n\r\r\n### 3. CPU Unit\r\r\nKubernetes에서 CPU의 단위는 절대적인 양으로 사용되며 1 Kubernetes CPU는 1vCPU 또는 물리적인 1 CPU 코어의 컴퓨팅 파워와 동일한 것으로 간주합니다.\r\r\nKubernetes에서는 코어를 밀리코어(millicore)로 더 작게 나누어 설정할 수 있습니다. 1000m은 1 CPU와 동일하며 0.5 CPU는 500m과 같습니다.\r\r\n\r\r\n### 4. QoS(quality of service, 서비스 품질) 클래스\r\r\nKubernetes는 설정한 requests와 limits에 따라서 자동으로 QoS 클래스를 할당합니다.\r\r\n• **Guaranteed (보장)**: Pod 내의 모든 컨테이너가 CPU와 메모리에 대해 requests와 limits를 모두 설정하고, 그 값이 서로 동일할 때(requests.cpu == limits.cpu) 할당됩니다. 이 Pod들은 가장 높은 우선순위를 가지며, 노드에 리소스 압박이 발생했을 때 가장 마지막에 축출(eviction)됩니다.\r\r\n• **Burstable (버스트 가능)**: Pod 내에 최소 하나 이상의 컨테이너가 CPU 또는 메모리 requests를 설정했지만, Guaranteed 클래스의 조건을 충족하지 못할 때 할당됩니다(예: requests.cpu < limits.cpu). 이 Pod들은 노드에 여유 리소스가 있을 경우, 요청한 양보다 더 많은 리소스를 \"버스트(burst)\"하여 사용할 수 있습니다.\r\r\n• **BestEffort (최선 노력)**: Pod 내의 어떤 컨테이너도 CPU나 메모리에 대한 requests나 limits를 설정하지 않았을 때 할당됩니다. 이 Pod들은 가장 낮은 우선순위를 가지며, 노드 리소스가 부족해지면 가장 먼저 축출 대상이 됩니다. \r\r\n<br>\r\r\n## 리눅스 커널의 CPU 관리 메커니즘\r\r\nKubernetes에서 설정한 requests와 limits를 리눅스 커널이 어떻게 실제로 CPU를 할당하고 제한하는지 알아보도록 하겠습니다. 여기에는 컨테이너 기술을 탄생시킨 cgroup(Control Group)과 CFS(Completely Fair Scheduler)가 사용됩니다.\r\r\n\r\r\n### 1. 리눅스 컨트롤 그룹(cgroup)\r\r\ncgroup은 프로세스들의 집합에 대해 CPU, 메모리, I/O와 같은 시스템 리소스의 사용량을 제한하고, 추적하며, 격리합니다. cgroup은 /sys/fs/cgroup/이라는 가상 파일 시스템 내에 계층적 구조로 구성됩니다. Kubernetes는 이 구조 내에 kubepods.slice라는 전용 경로를 만들어 Pod들의 리소스를 관리합니다.\r\r\nCPU 리소스 관리를 담당하는 cgroup의 특정 모듈을 ‘컨트롤러’ 또는 ‘서브시스템’이라 부르며, Kubernetes가 CPU requests와 limits를 구현하기 위해 사용하는 것이 바로 CPU 서브시스템입니다.\r\r\n\r\r\n### 2. Completely Fair Scheduler(CFS)\r\r\nCFS는 리눅스 커널의 기본 프로세스 스케줄러로, 그 이름처럼 ‘완전한 공정성’을 목표로 합니다. CFS는 마치 ‘이상적인 멀티태스킹 CPU’가 존재하는 것처럼, 실행 가능한 모든 태스크(프로세스)가 정확히 동일한 비율의 CPU 시간을 할당 받도록 노력합니다.\r\r\n실제 하드웨어는 한 번에 하나의 작업만 실행할 수 있기 때문에, CFS는 ‘가상 런타임(virtual runtime, vruntime)’이라는 개념을 사용합니다. CFS는 항상 가장 작은 vruntime 값을 가진 작업, 즉 지금까지 가장 적게 실행된 작업을 선택하여 실행함으로써 장기적인 관점에서 공정성을 보장합니다.\r\r\n\r\r\n### 3. Kubernetes와 커널의 매핑\r\r\nkubelet은 Kubernetes의 yaml 명세를 실제 커널에 적용하기 위해서 변환 작업을 수행합니다. kubelet은 resources 설정을 읽어 해당 컨테이너의 cgroup 디렉터리 내 특정 파일에 값을 덮어쓰는 방식으로 커널에 지시를 내립니다.\r\r\n\r\r\n#### **3.1. Requests와 cpu.shares: 상대적 가중치 시스템**\r\r\nPod의 resources.requests.cpu 값은 cgroup의 cpu.shares 파일 값으로 변환됩니다. 공식은 다음과 같습니다.\r\r\n```\r\r\ncpu.shares=requests.cpu (millicores)×1024/1000.\r\r\n```\r\r\n예를 들어, 1000m(1 코어) 요청은 1024 shares로, 500m 요청은 512 shares로 변환됩니다. 가장 중요한 점은 cpu.shares가 **노드에 CPU 경합이 있을 때만 의미를 가지는 상대적 가중치**라는 것입니다. 만약 CPU 자원을 두고 경쟁하는 두 컨테이너가 있고, 하나는 2048 shares, 다른 하나는 1024 shares를 가지고 있다면, 전자는 후자보다 두 배의 CPU 시간을 할당 받게 됩니다. 하지만 노드가 유휴 상태이고 CPU 경합이 없다면, 컨테이너는 자신의 shares 값과 무관하게 필요한 만큼의 CPU를 사용할 수 있습니다.\r\r\n\r\r\n#### **3.2. Limits와 cpu.cfs_period_us & cpu.cfs_quota_us: 절대적 시간 할당량 시스템**\r\r\nPod의 resources.limits.cpu 값은 CFS 대역폭 제어라는 메커니즘을 통해 강제됩니다. 이 메커니즘은 두 가지 파라미터에 의해서 결정됩니다.\r\r\n• cpu.cfs_period_us: 할당량을 정산하는 주기로 단위는 마이크로초입니다. Kubernetes는 기본값인 100000(즉 100ms)을 사용합니다. 이 한 window 내에서 할당량이 정해집니다.\r\r\n• cpu.cfs_quota_us: 위에서 정의된 period 동안 cgroup이 소비할 수 있는 총 CPU 시간을 정의합니다. 단위는 마이크로초입니다. 이 값은 resources.limitscpu로부터 계산됩니다. limits가 없을 경우 -1로 할당량 없음을 의미합니다.\r\r\n\r\r\n변환 공식은 다음과 같습니다.\r\r\n```\r\r\ncpu.cfs_quota_us=limits.cpu (cores)×cpu.cfs_period_us.\r\r\n```\r\r\n예를 들어, limits.cpu를 500m(0.5 코어)로 설정하면, cpu.cfs_quota_us=0.5×100000=50000이 됩니다. 이는 해당 컨테이너가 매 100ms 주기마다 최대 50,000 마이크로초(50ms)의 CPU 시간만 사용할 수 있음을 의미합니다.\r\r\n\r\r\n#### 요약\r\r\n| Kubernetes 설정 | Kubernetes에서의 목적 | 리눅스 cgroup 파일 | 동작 |\r\r\n| --- | --- | --- | --- |\r\r\n| resources.requests.cpu | 스케줄링 및 경합 시 최소 CPU 보장 | cpu.shares | 상대적 가중치; CPU 경합 시에만 활성화 |\r\r\n| resources.lmits.cpu | 런타임 시 최대 CPU사용량 제한 | cpu.cfs_quota_us | 절대적 시간 할당량; 항상 활성화, 스로틀링 발생 |\r\r\n<br>\r\r\n## Limits 적용으로 발생할 수 있는 현상\r\r\nCPU limits를 설정했을 때 발생하는 가장 중요하고 종종 오해 받는 현상이 바로 CPU 스로틀링입니다. 스로틀링은 단순히 성능을 약간 늦추는 것이 아니라, 애플리케이션의 지연 시간에 심각하고 예측 불가능한 영향을 미칠 수 있는 ‘정지-대기(stop-wait)’ 프로세스입니다.\r\r\n\r\r\n### 1. CPU 스로틀링과 발생 원인\r\r\nCPU 스로틀링은 컨테이너 내의 프로세스들이 현재의 cfs_period_us(보통 100ms) 동안 할당된 cfs_quota_us를 모두 소진했을 때 발생합니다. 할당량을 모두 사용한 컨테이너의 프로세스들은 커널 스케줄러에 의해 실행이 '정지'됩니다. 그리고 다음 100ms 주기가 시작되어 할당량이 다시 채워질 때까지 대기해야 합니다.\r\r\n이 현상은 특히 멀티 스레드 애플리케이션에서 증폭되어 나타납니다. 예를 들어, 한 컨테이너가 1 코어(cfs_quota_us=100000)의 limit을 가지고 있지만, 4개의 바쁜 스레드를 동시에 실행한다고 가정해 봅시다.\r\r\n이 컨테이너는 4개의 코어를 동시에 사용하여 단 25ms의 실제 시간만에 100ms의 CPU 시간 할당량을 모두 소진할 수 있습니다. 그 후, 해당 컨테이너는 남은 75ms 동안 노드에 유휴 코어가 있더라도 완전히 스로틀링되어 아무 작업도 수행할 수 없게 됩니다.\r\r\n![K8s_CPU limit_1.png](https://image.toast.com/aaaadh/real/2025/techblog/K8sCPU%20limit1.png)\r\r\n\r\r\n### 2. CPU 스로틀링으로 인한 지연 시간 증가\r\r\n![K8s_CPU limit_2.png](https://image.toast.com/aaaadh/real/2025/techblog/K8sCPU%20limit2.png)\r\r\n스로틀링은 애플리케이션 요청 처리 시간에 직접적으로 지연을 추가합니다. 예를 들어, 어떤 작업을 완료하는 데 순수하게 300ms의 CPU 시간이 필요한 애플리케이션이 100ms 주기당 50ms의 limit에 의해 제한된다고 가정해 봅시다. 이 작업은 다른 시스템 부하가 전혀 없더라도 최소 6개의 주기, 즉 600ms의 실제 시간이 걸려야 완료될 수 있습니다. 이러한 지연은 타임아웃, 연쇄적인 장애, 그리고 궁극적으로는 나쁜 사용자 경험으로 이어질 수 있습니다.\r\r\n스로틀링은 전통적인 CPU 사용률 지표로는 확인하기가 힘든 경우가 있습니다. 어떤 컨테이너가 CPU 사용률 50%(자신의 limit 값)를 보이고 있더라도, 실제로는 심각하게 스로틀링되어 매우 느린 상태일 수 있습니다. 이 경우 CPU는 전통적인 의미에서 '최대치로 사용'되는 것이 아니라, 인위적으로 억제되고 있는 상태입니다.\r\r\n\r\r\n\r\r\n### 3. '시끄러운 이웃' 오해\r\r\nlimits가 ‘시끄러운 이웃(noisy neighbor)’ 문제, 즉 하나의 애플리케이션이 리소스를 독점하여 다른 애플리케이션에 영향을 주는 것을 막아 줄 수 있을 것처럼 보입니다. 하지만 실제로는 requests에 의해 결정되는 cpu.shares가 경합 상황에서도 적절하게 리소스를 배분할 수 있는 시스템이라고 할 수 있습니다. 만약 모든 Pod에 적절한 requests가 설정되어 있다면, CFS 스케줄러는 shares 값에 비례하여 CPU 시간을 분배함으로써 특정 Pod가 다른 Pod들이 기아 상태에 빠지는 것을 방지합니다. 반면 limits는 다른 누구도 CPU를 필요로 하지 않는 상황에서조차 Pod의 사용량을 제한하는 무딘 도구에 가깝습니다.\r\r\n<br>\r\r\n## 스로틀링 테스트\r\r\n테스트를 위해 한 웹 애플리케이션을 만들었습니다. 이 애플리케이션에 1 CPU를 할당하면 작업을 완료하는 데 대략 12초 정도 걸립니다.\r\r\n이 애플리케이션에 각각 1 CPU, 0.1 CPU를 할당하여 CPU 사용량과 작업 시간을 확인하여 지금까지 확인한 현상이 발생하는지 테스트해 보았습니다.\r\r\n\r\r\n### 테스트용 Pod 준비\r\r\n아래와 같이 CPU limit만 다르게 설정하여 Pod를 생성하였습니다.\r\r\n```\r\r\napiVersion: apps/v1\r\r\nkind: Deployment\r\r\nmetadata:\r\r\n  name: cpu-test-app\r\r\n  labels:\r\r\n    app: cpu-test-app\r\r\nspec:\r\r\n  replicas: 1\r\r\n  selector:\r\r\n    matchLabels:\r\r\n      app: cpu-test-app\r\r\n  template:\r\r\n    metadata:\r\r\n      labels:\r\r\n        app: cpu-test-app\r\r\n    spec:\r\r\n      containers:\r\r\n      - name: cpu-test-app\r\r\n        image: cpu-test-app\r\r\n        ports:\r\r\n        - containerPort: 8081\r\r\n        resources:\r\r\n          requests:\r\r\n            memory: \"64Mi\"\r\r\n            cpu: \"100m\"    # 0.1 코어\r\r\n          limits:\r\r\n            memory: \"128Mi\"\r\r\n            cpu: \"100m\"    # 0.1 코어로 제한\r\r\n        livenessProbe:\r\r\n          httpGet:\r\r\n            path: /health\r\r\n            port: 8080\r\r\n          initialDelaySeconds: 10\r\r\n          periodSeconds: 30\r\r\n        readinessProbe:\r\r\n          httpGet:\r\r\n            path: /health\r\r\n            port: 8080\r\r\n          initialDelaySeconds: 5\r\r\n          periodSeconds: 10\r\r\n---\r\r\n# 1 코어 제한 버전\r\r\napiVersion: apps/v1\r\r\nkind: Deployment\r\r\nmetadata:\r\r\n  name: cpu-test-app-1core\r\r\n  labels:\r\r\n    app: cpu-test-app-1core\r\r\nspec:\r\r\n  replicas: 1\r\r\n  selector:\r\r\n    matchLabels:\r\r\n      app: cpu-test-app-1core\r\r\n  template:\r\r\n    metadata:\r\r\n      labels:\r\r\n        app: cpu-test-app-1core\r\r\n    spec:\r\r\n      containers:\r\r\n      - name: cpu-test-app\r\r\n        image: cpu-test-app\r\r\n        ports:\r\r\n        - containerPort: 8080\r\r\n        resources:\r\r\n          requests:\r\r\n            memory: \"64Mi\"\r\r\n            cpu: \"1000m\"   # 1 코어\r\r\n          limits:\r\r\n            memory: \"128Mi\"\r\r\n            cpu: \"1000m\"   # 1 코어로 제한\r\r\n        livenessProbe:\r\r\n          httpGet:\r\r\n            path: /health\r\r\n            port: 8080\r\r\n          initialDelaySeconds: 10\r\r\n          periodSeconds: 30\r\r\n        readinessProbe:\r\r\n          httpGet:\r\r\n            path: /health\r\r\n            port: 8080\r\r\n          initialDelaySeconds: 5\r\r\n          periodSeconds: 10\r\r\n```\r\r\n\r\r\n### 응답 시간 비교\r\r\n0.1 CPU를 할당한 애플리케이션에서는 122초가 소요된 반면 1 CPU가 할당된 애플리케이션에서는 11.51초만 소요된 것을 확인할 수 있었습니다.\r\r\n![K8s_CPU limit_3.png](https://image.toast.com/aaaadh/real/2025/techblog/K8sCPU%20limit3.png)\r\r\n\r\r\n### 그라파나를 통한 스로틀링 현상 확인\r\r\n* <span style=\"background-color:#DCFFE4\">초록색: 1 CPU</span>\r\r\n* <span style=\"background-color:#fff5b1\">노란색: 0.1 CPU</span>\r\r\n\r\r\nCPU 사용률에서 노란색 그래프가 CPU limits가 0.1로 설정되어 그 이상 사용하지 못하는 모습을 보여줍니다. CPU 할당 횟수에서 노란색이 Limits에 걸려서 더 많은 cpu 할당이 발생한 것을 확인할 수 있습니다. 이것은 스로틀링으로 인한 지연 시간 증가 시뮬레이션과 일치하는 결과입니다. 당연하게도 스로틀링 비율도 노란색이 더 높은 것을 알 수 있습니다.\r\r\n![K8s_CPU limit_4.png](https://image.toast.com/aaaadh/real/2025/techblog/K8sCPU%20limit4.png)\r\r\n중요한 지표는 스로틀링 비율로서 비율이 5%를 지속적으로 넘는 현상이 발생한다면 스로틀링이 빈번하게 발생하여 성능에 제약을 받아 서비스가 느려져 있을 가능성이 있으므로 조치를 취해야 합니다.\r\r\n\r\r\n#### 스로틀링 비율 지표 예시\r\r\n```\r\r\nsum by (namespace, pod) (rate(container_cpu_cfs_throttled_periods_total{container!=\"\"}[5m]))\r\r\n/\r\r\nsum by (namespace, pod) (rate(container_cpu_cfs_periods_total{container!=\"\"}[5m]))\r\r\n```\r\r\n<br>\r\r\n## 나가며\r\r\n결론은 아래와 같습니다.\r\r\n* 일반적인 경우,\r\r\n\t* request만 설정하여 자원이 더 필요할 때는 노드의 가용 자원을 사용하고 자원이 모자랄 때는 비율로 할당 받도록 하는 것이 좋은 것 같습니다. (QoS는 Burstable로 설정됨)\r\r\n\t* QoS가 Burstable로 설정되지만 CPU는 Eviction의 조건이 아니기 때문에 throttling이 발생할지언정 pod가 eviction 되지는 않습니다.\r\r\n* limit만 설정하는 경우는 피해야 합니다. limit만 설정할 경우 request가 0이 되어 자원 가용량이 없는 노드에도 스케줄링 될 수 있으며 런타임 시 예측이 어려워집니다.\r\r\n* CPU request는 Pod가 노드에 할당될 때는 절댓값으로 사용되고 할당된 뒤에는 상대적인 비율로 사용됩니다.\r\r\n\r\r\n<br>\r\r\n긴 글을 읽어 주셔서 감사합니다. \r\r\n<br>\r\r\n### 참고 문헌\r\r\n• Kubernetes, Resource Management for Pods and Containers, https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\r\r\n• KubeBlog, Understanding CPU Requests and Limits, 2023. 10. 5., https://www.kubeblog.com/basics/understanding-cpu-requests-and-limits/\r\r\n• Itiel Shwartz, Kubernetes CPU Limits: What’s the Right Way to Assign CPU Resources?, 2025. 1. 14., https://komodor.com/learn/kubernetes-cpu-limits-throttling/\r\r\n• Eliran Cohen, For the love of god, learn when to use CPU limits on Kubernetes., 2023. 3. 5., https://medium.com/@eliran89c/for-the-love-of-god-learn-when-to-use-cpu-limits-on-kubernetes-2225341e9dbd\r\r\n• Max Levin, Kubernetes CPU Throttling: What it is, and Best Practices, 2024. 6. 6., https://www.groundcover.com/blog/kubernetes-cpu-throttling\r\r\n• CODE FARM, Linux CGroups and Containers, 2024. 2. 3., https://blog.codefarm.me/2021/11/23/linux-cgroups-containers/\r\r\n• Andreas Karis Blog, Quick guide for cgroups, 2020. 9. 3., https://andreaskaris.github.io/blog/linux/cgroups/\r\r\n• Martin, Cgroups - Deep Dive into Resource Management in Kubernetes, 2023. 2. 20., https://martinheinz.dev/blog/91\r\r\n• Jianhao, Kubernetes CPU requests and limits, 2021. 11. 11., https://jaanhio.me/blog/kubernetes-cpu-requests-limits/\r\r\n• Red Hat, Resource Management Guide > CPU, https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/6/html/resource_management_guide/sec-cpu\r\r\n• Real-time Ubuntu, Linux kernel schedulers, https://documentation.ubuntu.com/real-time/latest/explanation/schedulers/\r\r\n• Rifewang, Kubernetes: CPU Configuration, Linux CFS, and Performance Issues with Programming Languages, 2024. 12. 11., https://medium.com/@rifewang/kubernetes-cpu-configuration-linux-cfs-and-performance-issues-with-programming-languages-ccef783ed22e\r\r\n• JettyCloud, Making Sense of Kubernetes CPU Requests And Limits, 2023. 3. 20., https://medium.com/@jettycloud/making-sense-of-kubernetes-cpu-requests-and-limits-390bbb5b7c92\r\r\n• Tania Duggal, PerfectScale, Kubernetes CPU Limit: Best Practices for Optimal Performance, 2024. 10. 24., https://www.perfectscale.io/blog/kubernetes-cpu-limit-best-practises\r\r\n• Shane Corbett, AWS Blogs, Using Prometheus to Avoid Disasters with Kubernetes CPU Limits, 2022. 9. 21., https://aws.amazon.com/blogs/containers/using-prometheus-to-avoid-disasters-with-kubernetes-cpu-limits/\r\r\n\r\r\n\r\r\n[![NHN Cloud_meetup banner_footer_blue_202509.png](https://image.toast.com/aaaadh/real/2025/techblog/NHN%20Cloudmeetup%20bannerfooterblue202509.png)](https://www.nhncloud.com/kr)",
        "contentSnippet": "[![NHN Cloud_meetup banner_K8s CPU limit_202509-01.png](https://image.toast.com/aaaadh/real/2025/techblog/NHN%20Cloudmeetup%20bannerK8s%20CPU%20limit20250901.png)](https://www.nhncloud.com/kr)\r\r\n\r\r\n## 들어가며\r\r\n오늘날 대부분의 서비스가 컨테이너 환경을 이용하고 있고, 컨테이너를 실행하는 환경으로는 Kubernetes가 표준으로 자리 잡고 있습니다. Kubernetes에서 컨테이너를 실행할 때는 Pod를 사용하는데요. Pod를 사용할 때 컨테이너의 리소스를 얼마나 할당할 것인가는 클러스터의 안정성과 연결되어 있기 때문에 중요한 문제 중 하나입니다. Pod의 컴퓨팅 리소스는 보통 다음과 같이 **requests**와 **limit**으로 설정할 수 있습니다.\r\r\n\r\r\n```\r\r\napiVersion: v1\r\r\nkind: Pod\r\r\nmetadata:\r\r\n  name: frontend\r\r\nspec:\r\r\n  containers:\r\r\n  - name: app\r\r\n    image: images.my-company.example/app:v4\r\r\n    resources:\r\r\n      requests:\r\r\n        memory: \"64Mi\"\r\r\n        cpu: \"250m\"\r\r\n      limits:\r\r\n        memory: \"128Mi\"\r\r\n        cpu: \"500m\"\r\r\n  - name: log-aggregator\r\r\n    image: images.my-company.example/log-aggregator:v6\r\r\n    resources:\r\r\n      requests:\r\r\n        memory: \"64Mi\"\r\r\n        cpu: \"250m\"\r\r\n      limits:\r\r\n        memory: \"128Mi\"\r\r\n        cpu: \"500m\"\r\r\n\r\r\n```\r\r\n\r\r\n리소스를 설정할 때 우리는 보통 메모리를 중심으로 정하는데요, 컨테이너의 메모리 사용량이 한계값에 도달하면 Pod는 재실행됩니다.\r\r\n그렇다면, CPU 사용량의 경우에는 어떨까요? 자주 사용되진 않지만 한 번쯤 알아두면 좋은 CPU 사용량 제한에 대해 알아보았습니다.\r\r\n\r\r\n## Kubernetes CPU Resource 설정\r\r\n먼저 Pod의 Resource 항목에서 설정 가능한 CPU의 Request와 Limit, 그리고 단위에 대해 알아보도록 하겠습니다.\r\r\n\r\r\n### 1. CPU Requests\r\r\nCPU requests는 컨테이너가 정상적으로 실행하기 위한 최소한의 CPU 양을 의미합니다. requests는 kube-scheduler가 Pod를 노드에 할당하는 스케줄링 작업에서 사용합니다. kube-scheduler는 Pod의 requests 값을 합산하여 할당 가능한 노드를 찾아서 Pod를 배치합니다. 노드에 Pod의 requests를 수용할 만한 여유가 있어야 할당이 되는 것이죠. 이 조건을 만족하는 노드가 없다면 Pod는 pending 상태로 스케줄링되지 않습니다.\r\r\nPod가 특정 노드에 스케줄링되었다면 요청된 CPU의 양은 보장됩니다. 이 말은 requests의 양만큼 CPU를 항상 점유한다는 뜻은 아닙니다. CPU 사용에 경합이 발생했을 때도 요청한 만큼의 CPU 시간을 할당 받는 것을 보장합니다. requests의 값이 없다면 Pod가 비효율적으로 배치될 수 있고 필요 이상의 클러스터 자원을 사용하여 불필요한 비용 지출이 발생할 수 있습니다.\r\r\n\r\r\n### 2. CPU Limits\r\r\nCPU limits는 컨테이너가 사용할 수 있는 CPU의 절대적인 최댓값을 의미하며 kubelet이 관리합니다. Pod의 컨테이너가 limits를 초과하여 CPU를 사용하려 할 때 해당 컨테이너의 CPU 사용을 인위적으로 낮추는 스로틀링(Throttling)을 통해 상한선을 강제합니다. limits는 여러 서비스가 동시에 실행되고 있는 Kubernetes 클러스터에서 하나의 컨테이너가 CPU를 과점하여 다른 컨테이너의 성능에 영향을 주거나 노드의 안정성을 해치는 CPU 기아 상태를 방지하는 데 의미가 있습니다.\r\r\n\r\r\n### 3. CPU Unit\r\r\nKubernetes에서 CPU의 단위는 절대적인 양으로 사용되며 1 Kubernetes CPU는 1vCPU 또는 물리적인 1 CPU 코어의 컴퓨팅 파워와 동일한 것으로 간주합니다.\r\r\nKubernetes에서는 코어를 밀리코어(millicore)로 더 작게 나누어 설정할 수 있습니다. 1000m은 1 CPU와 동일하며 0.5 CPU는 500m과 같습니다.\r\r\n\r\r\n### 4. QoS(quality of service, 서비스 품질) 클래스\r\r\nKubernetes는 설정한 requests와 limits에 따라서 자동으로 QoS 클래스를 할당합니다.\r\r\n• **Guaranteed (보장)**: Pod 내의 모든 컨테이너가 CPU와 메모리에 대해 requests와 limits를 모두 설정하고, 그 값이 서로 동일할 때(requests.cpu == limits.cpu) 할당됩니다. 이 Pod들은 가장 높은 우선순위를 가지며, 노드에 리소스 압박이 발생했을 때 가장 마지막에 축출(eviction)됩니다.\r\r\n• **Burstable (버스트 가능)**: Pod 내에 최소 하나 이상의 컨테이너가 CPU 또는 메모리 requests를 설정했지만, Guaranteed 클래스의 조건을 충족하지 못할 때 할당됩니다(예: requests.cpu < limits.cpu). 이 Pod들은 노드에 여유 리소스가 있을 경우, 요청한 양보다 더 많은 리소스를 \"버스트(burst)\"하여 사용할 수 있습니다.\r\r\n• **BestEffort (최선 노력)**: Pod 내의 어떤 컨테이너도 CPU나 메모리에 대한 requests나 limits를 설정하지 않았을 때 할당됩니다. 이 Pod들은 가장 낮은 우선순위를 가지며, 노드 리소스가 부족해지면 가장 먼저 축출 대상이 됩니다. \r\r\n\r\r\n## 리눅스 커널의 CPU 관리 메커니즘\r\r\nKubernetes에서 설정한 requests와 limits를 리눅스 커널이 어떻게 실제로 CPU를 할당하고 제한하는지 알아보도록 하겠습니다. 여기에는 컨테이너 기술을 탄생시킨 cgroup(Control Group)과 CFS(Completely Fair Scheduler)가 사용됩니다.\r\r\n\r\r\n### 1. 리눅스 컨트롤 그룹(cgroup)\r\r\ncgroup은 프로세스들의 집합에 대해 CPU, 메모리, I/O와 같은 시스템 리소스의 사용량을 제한하고, 추적하며, 격리합니다. cgroup은 /sys/fs/cgroup/이라는 가상 파일 시스템 내에 계층적 구조로 구성됩니다. Kubernetes는 이 구조 내에 kubepods.slice라는 전용 경로를 만들어 Pod들의 리소스를 관리합니다.\r\r\nCPU 리소스 관리를 담당하는 cgroup의 특정 모듈을 ‘컨트롤러’ 또는 ‘서브시스템’이라 부르며, Kubernetes가 CPU requests와 limits를 구현하기 위해 사용하는 것이 바로 CPU 서브시스템입니다.\r\r\n\r\r\n### 2. Completely Fair Scheduler(CFS)\r\r\nCFS는 리눅스 커널의 기본 프로세스 스케줄러로, 그 이름처럼 ‘완전한 공정성’을 목표로 합니다. CFS는 마치 ‘이상적인 멀티태스킹 CPU’가 존재하는 것처럼, 실행 가능한 모든 태스크(프로세스)가 정확히 동일한 비율의 CPU 시간을 할당 받도록 노력합니다.\r\r\n실제 하드웨어는 한 번에 하나의 작업만 실행할 수 있기 때문에, CFS는 ‘가상 런타임(virtual runtime, vruntime)’이라는 개념을 사용합니다. CFS는 항상 가장 작은 vruntime 값을 가진 작업, 즉 지금까지 가장 적게 실행된 작업을 선택하여 실행함으로써 장기적인 관점에서 공정성을 보장합니다.\r\r\n\r\r\n### 3. Kubernetes와 커널의 매핑\r\r\nkubelet은 Kubernetes의 yaml 명세를 실제 커널에 적용하기 위해서 변환 작업을 수행합니다. kubelet은 resources 설정을 읽어 해당 컨테이너의 cgroup 디렉터리 내 특정 파일에 값을 덮어쓰는 방식으로 커널에 지시를 내립니다.\r\r\n\r\r\n#### **3.1. Requests와 cpu.shares: 상대적 가중치 시스템**\r\r\nPod의 resources.requests.cpu 값은 cgroup의 cpu.shares 파일 값으로 변환됩니다. 공식은 다음과 같습니다.\r\r\n```\r\r\ncpu.shares=requests.cpu (millicores)×1024/1000.\r\r\n```\r\r\n예를 들어, 1000m(1 코어) 요청은 1024 shares로, 500m 요청은 512 shares로 변환됩니다. 가장 중요한 점은 cpu.shares가 **노드에 CPU 경합이 있을 때만 의미를 가지는 상대적 가중치**라는 것입니다. 만약 CPU 자원을 두고 경쟁하는 두 컨테이너가 있고, 하나는 2048 shares, 다른 하나는 1024 shares를 가지고 있다면, 전자는 후자보다 두 배의 CPU 시간을 할당 받게 됩니다. 하지만 노드가 유휴 상태이고 CPU 경합이 없다면, 컨테이너는 자신의 shares 값과 무관하게 필요한 만큼의 CPU를 사용할 수 있습니다.\r\r\n\r\r\n#### **3.2. Limits와 cpu.cfs_period_us & cpu.cfs_quota_us: 절대적 시간 할당량 시스템**\r\r\nPod의 resources.limits.cpu 값은 CFS 대역폭 제어라는 메커니즘을 통해 강제됩니다. 이 메커니즘은 두 가지 파라미터에 의해서 결정됩니다.\r\r\n• cpu.cfs_period_us: 할당량을 정산하는 주기로 단위는 마이크로초입니다. Kubernetes는 기본값인 100000(즉 100ms)을 사용합니다. 이 한 window 내에서 할당량이 정해집니다.\r\r\n• cpu.cfs_quota_us: 위에서 정의된 period 동안 cgroup이 소비할 수 있는 총 CPU 시간을 정의합니다. 단위는 마이크로초입니다. 이 값은 resources.limitscpu로부터 계산됩니다. limits가 없을 경우 -1로 할당량 없음을 의미합니다.\r\r\n\r\r\n변환 공식은 다음과 같습니다.\r\r\n```\r\r\ncpu.cfs_quota_us=limits.cpu (cores)×cpu.cfs_period_us.\r\r\n```\r\r\n예를 들어, limits.cpu를 500m(0.5 코어)로 설정하면, cpu.cfs_quota_us=0.5×100000=50000이 됩니다. 이는 해당 컨테이너가 매 100ms 주기마다 최대 50,000 마이크로초(50ms)의 CPU 시간만 사용할 수 있음을 의미합니다.\r\r\n\r\r\n#### 요약\r\r\n| Kubernetes 설정 | Kubernetes에서의 목적 | 리눅스 cgroup 파일 | 동작 |\r\r\n| --- | --- | --- | --- |\r\r\n| resources.requests.cpu | 스케줄링 및 경합 시 최소 CPU 보장 | cpu.shares | 상대적 가중치; CPU 경합 시에만 활성화 |\r\r\n| resources.lmits.cpu | 런타임 시 최대 CPU사용량 제한 | cpu.cfs_quota_us | 절대적 시간 할당량; 항상 활성화, 스로틀링 발생 |\r\r\n\r\r\n## Limits 적용으로 발생할 수 있는 현상\r\r\nCPU limits를 설정했을 때 발생하는 가장 중요하고 종종 오해 받는 현상이 바로 CPU 스로틀링입니다. 스로틀링은 단순히 성능을 약간 늦추는 것이 아니라, 애플리케이션의 지연 시간에 심각하고 예측 불가능한 영향을 미칠 수 있는 ‘정지-대기(stop-wait)’ 프로세스입니다.\r\r\n\r\r\n### 1. CPU 스로틀링과 발생 원인\r\r\nCPU 스로틀링은 컨테이너 내의 프로세스들이 현재의 cfs_period_us(보통 100ms) 동안 할당된 cfs_quota_us를 모두 소진했을 때 발생합니다. 할당량을 모두 사용한 컨테이너의 프로세스들은 커널 스케줄러에 의해 실행이 '정지'됩니다. 그리고 다음 100ms 주기가 시작되어 할당량이 다시 채워질 때까지 대기해야 합니다.\r\r\n이 현상은 특히 멀티 스레드 애플리케이션에서 증폭되어 나타납니다. 예를 들어, 한 컨테이너가 1 코어(cfs_quota_us=100000)의 limit을 가지고 있지만, 4개의 바쁜 스레드를 동시에 실행한다고 가정해 봅시다.\r\r\n이 컨테이너는 4개의 코어를 동시에 사용하여 단 25ms의 실제 시간만에 100ms의 CPU 시간 할당량을 모두 소진할 수 있습니다. 그 후, 해당 컨테이너는 남은 75ms 동안 노드에 유휴 코어가 있더라도 완전히 스로틀링되어 아무 작업도 수행할 수 없게 됩니다.\r\r\n![K8s_CPU limit_1.png](https://image.toast.com/aaaadh/real/2025/techblog/K8sCPU%20limit1.png)\r\r\n\r\r\n### 2. CPU 스로틀링으로 인한 지연 시간 증가\r\r\n![K8s_CPU limit_2.png](https://image.toast.com/aaaadh/real/2025/techblog/K8sCPU%20limit2.png)\r\r\n스로틀링은 애플리케이션 요청 처리 시간에 직접적으로 지연을 추가합니다. 예를 들어, 어떤 작업을 완료하는 데 순수하게 300ms의 CPU 시간이 필요한 애플리케이션이 100ms 주기당 50ms의 limit에 의해 제한된다고 가정해 봅시다. 이 작업은 다른 시스템 부하가 전혀 없더라도 최소 6개의 주기, 즉 600ms의 실제 시간이 걸려야 완료될 수 있습니다. 이러한 지연은 타임아웃, 연쇄적인 장애, 그리고 궁극적으로는 나쁜 사용자 경험으로 이어질 수 있습니다.\r\r\n스로틀링은 전통적인 CPU 사용률 지표로는 확인하기가 힘든 경우가 있습니다. 어떤 컨테이너가 CPU 사용률 50%(자신의 limit 값)를 보이고 있더라도, 실제로는 심각하게 스로틀링되어 매우 느린 상태일 수 있습니다. 이 경우 CPU는 전통적인 의미에서 '최대치로 사용'되는 것이 아니라, 인위적으로 억제되고 있는 상태입니다.\r\r\n\r\r\n\r\r\n### 3. '시끄러운 이웃' 오해\r\r\nlimits가 ‘시끄러운 이웃(noisy neighbor)’ 문제, 즉 하나의 애플리케이션이 리소스를 독점하여 다른 애플리케이션에 영향을 주는 것을 막아 줄 수 있을 것처럼 보입니다. 하지만 실제로는 requests에 의해 결정되는 cpu.shares가 경합 상황에서도 적절하게 리소스를 배분할 수 있는 시스템이라고 할 수 있습니다. 만약 모든 Pod에 적절한 requests가 설정되어 있다면, CFS 스케줄러는 shares 값에 비례하여 CPU 시간을 분배함으로써 특정 Pod가 다른 Pod들이 기아 상태에 빠지는 것을 방지합니다. 반면 limits는 다른 누구도 CPU를 필요로 하지 않는 상황에서조차 Pod의 사용량을 제한하는 무딘 도구에 가깝습니다.\r\r\n\r\r\n## 스로틀링 테스트\r\r\n테스트를 위해 한 웹 애플리케이션을 만들었습니다. 이 애플리케이션에 1 CPU를 할당하면 작업을 완료하는 데 대략 12초 정도 걸립니다.\r\r\n이 애플리케이션에 각각 1 CPU, 0.1 CPU를 할당하여 CPU 사용량과 작업 시간을 확인하여 지금까지 확인한 현상이 발생하는지 테스트해 보았습니다.\r\r\n\r\r\n### 테스트용 Pod 준비\r\r\n아래와 같이 CPU limit만 다르게 설정하여 Pod를 생성하였습니다.\r\r\n```\r\r\napiVersion: apps/v1\r\r\nkind: Deployment\r\r\nmetadata:\r\r\n  name: cpu-test-app\r\r\n  labels:\r\r\n    app: cpu-test-app\r\r\nspec:\r\r\n  replicas: 1\r\r\n  selector:\r\r\n    matchLabels:\r\r\n      app: cpu-test-app\r\r\n  template:\r\r\n    metadata:\r\r\n      labels:\r\r\n        app: cpu-test-app\r\r\n    spec:\r\r\n      containers:\r\r\n      - name: cpu-test-app\r\r\n        image: cpu-test-app\r\r\n        ports:\r\r\n        - containerPort: 8081\r\r\n        resources:\r\r\n          requests:\r\r\n            memory: \"64Mi\"\r\r\n            cpu: \"100m\"    # 0.1 코어\r\r\n          limits:\r\r\n            memory: \"128Mi\"\r\r\n            cpu: \"100m\"    # 0.1 코어로 제한\r\r\n        livenessProbe:\r\r\n          httpGet:\r\r\n            path: /health\r\r\n            port: 8080\r\r\n          initialDelaySeconds: 10\r\r\n          periodSeconds: 30\r\r\n        readinessProbe:\r\r\n          httpGet:\r\r\n            path: /health\r\r\n            port: 8080\r\r\n          initialDelaySeconds: 5\r\r\n          periodSeconds: 10\r\r\n---\r\r\n# 1 코어 제한 버전\r\r\napiVersion: apps/v1\r\r\nkind: Deployment\r\r\nmetadata:\r\r\n  name: cpu-test-app-1core\r\r\n  labels:\r\r\n    app: cpu-test-app-1core\r\r\nspec:\r\r\n  replicas: 1\r\r\n  selector:\r\r\n    matchLabels:\r\r\n      app: cpu-test-app-1core\r\r\n  template:\r\r\n    metadata:\r\r\n      labels:\r\r\n        app: cpu-test-app-1core\r\r\n    spec:\r\r\n      containers:\r\r\n      - name: cpu-test-app\r\r\n        image: cpu-test-app\r\r\n        ports:\r\r\n        - containerPort: 8080\r\r\n        resources:\r\r\n          requests:\r\r\n            memory: \"64Mi\"\r\r\n            cpu: \"1000m\"   # 1 코어\r\r\n          limits:\r\r\n            memory: \"128Mi\"\r\r\n            cpu: \"1000m\"   # 1 코어로 제한\r\r\n        livenessProbe:\r\r\n          httpGet:\r\r\n            path: /health\r\r\n            port: 8080\r\r\n          initialDelaySeconds: 10\r\r\n          periodSeconds: 30\r\r\n        readinessProbe:\r\r\n          httpGet:\r\r\n            path: /health\r\r\n            port: 8080\r\r\n          initialDelaySeconds: 5\r\r\n          periodSeconds: 10\r\r\n```\r\r\n\r\r\n### 응답 시간 비교\r\r\n0.1 CPU를 할당한 애플리케이션에서는 122초가 소요된 반면 1 CPU가 할당된 애플리케이션에서는 11.51초만 소요된 것을 확인할 수 있었습니다.\r\r\n![K8s_CPU limit_3.png](https://image.toast.com/aaaadh/real/2025/techblog/K8sCPU%20limit3.png)\r\r\n\r\r\n### 그라파나를 통한 스로틀링 현상 확인\r\r\n* 초록색: 1 CPU\r\r\n* 노란색: 0.1 CPU\r\r\n\r\r\nCPU 사용률에서 노란색 그래프가 CPU limits가 0.1로 설정되어 그 이상 사용하지 못하는 모습을 보여줍니다. CPU 할당 횟수에서 노란색이 Limits에 걸려서 더 많은 cpu 할당이 발생한 것을 확인할 수 있습니다. 이것은 스로틀링으로 인한 지연 시간 증가 시뮬레이션과 일치하는 결과입니다. 당연하게도 스로틀링 비율도 노란색이 더 높은 것을 알 수 있습니다.\r\r\n![K8s_CPU limit_4.png](https://image.toast.com/aaaadh/real/2025/techblog/K8sCPU%20limit4.png)\r\r\n중요한 지표는 스로틀링 비율로서 비율이 5%를 지속적으로 넘는 현상이 발생한다면 스로틀링이 빈번하게 발생하여 성능에 제약을 받아 서비스가 느려져 있을 가능성이 있으므로 조치를 취해야 합니다.\r\r\n\r\r\n#### 스로틀링 비율 지표 예시\r\r\n```\r\r\nsum by (namespace, pod) (rate(container_cpu_cfs_throttled_periods_total{container!=\"\"}[5m]))\r\r\n/\r\r\nsum by (namespace, pod) (rate(container_cpu_cfs_periods_total{container!=\"\"}[5m]))\r\r\n```\r\r\n\r\r\n## 나가며\r\r\n결론은 아래와 같습니다.\r\r\n* 일반적인 경우,\r\r\n\t* request만 설정하여 자원이 더 필요할 때는 노드의 가용 자원을 사용하고 자원이 모자랄 때는 비율로 할당 받도록 하는 것이 좋은 것 같습니다. (QoS는 Burstable로 설정됨)\r\r\n\t* QoS가 Burstable로 설정되지만 CPU는 Eviction의 조건이 아니기 때문에 throttling이 발생할지언정 pod가 eviction 되지는 않습니다.\r\r\n* limit만 설정하는 경우는 피해야 합니다. limit만 설정할 경우 request가 0이 되어 자원 가용량이 없는 노드에도 스케줄링 될 수 있으며 런타임 시 예측이 어려워집니다.\r\r\n* CPU request는 Pod가 노드에 할당될 때는 절댓값으로 사용되고 할당된 뒤에는 상대적인 비율로 사용됩니다.\r\r\n\r\r\n\r\r\n긴 글을 읽어 주셔서 감사합니다. \r\r\n\r\r\n### 참고 문헌\r\r\n• Kubernetes, Resource Management for Pods and Containers, https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\r\r\n• KubeBlog, Understanding CPU Requests and Limits, 2023. 10. 5., https://www.kubeblog.com/basics/understanding-cpu-requests-and-limits/\r\r\n• Itiel Shwartz, Kubernetes CPU Limits: What’s the Right Way to Assign CPU Resources?, 2025. 1. 14., https://komodor.com/learn/kubernetes-cpu-limits-throttling/\r\r\n• Eliran Cohen, For the love of god, learn when to use CPU limits on Kubernetes., 2023. 3. 5., https://medium.com/@eliran89c/for-the-love-of-god-learn-when-to-use-cpu-limits-on-kubernetes-2225341e9dbd\r\r\n• Max Levin, Kubernetes CPU Throttling: What it is, and Best Practices, 2024. 6. 6., https://www.groundcover.com/blog/kubernetes-cpu-throttling\r\r\n• CODE FARM, Linux CGroups and Containers, 2024. 2. 3., https://blog.codefarm.me/2021/11/23/linux-cgroups-containers/\r\r\n• Andreas Karis Blog, Quick guide for cgroups, 2020. 9. 3., https://andreaskaris.github.io/blog/linux/cgroups/\r\r\n• Martin, Cgroups - Deep Dive into Resource Management in Kubernetes, 2023. 2. 20., https://martinheinz.dev/blog/91\r\r\n• Jianhao, Kubernetes CPU requests and limits, 2021. 11. 11., https://jaanhio.me/blog/kubernetes-cpu-requests-limits/\r\r\n• Red Hat, Resource Management Guide > CPU, https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/6/html/resource_management_guide/sec-cpu\r\r\n• Real-time Ubuntu, Linux kernel schedulers, https://documentation.ubuntu.com/real-time/latest/explanation/schedulers/\r\r\n• Rifewang, Kubernetes: CPU Configuration, Linux CFS, and Performance Issues with Programming Languages, 2024. 12. 11., https://medium.com/@rifewang/kubernetes-cpu-configuration-linux-cfs-and-performance-issues-with-programming-languages-ccef783ed22e\r\r\n• JettyCloud, Making Sense of Kubernetes CPU Requests And Limits, 2023. 3. 20., https://medium.com/@jettycloud/making-sense-of-kubernetes-cpu-requests-and-limits-390bbb5b7c92\r\r\n• Tania Duggal, PerfectScale, Kubernetes CPU Limit: Best Practices for Optimal Performance, 2024. 10. 24., https://www.perfectscale.io/blog/kubernetes-cpu-limit-best-practises\r\r\n• Shane Corbett, AWS Blogs, Using Prometheus to Avoid Disasters with Kubernetes CPU Limits, 2022. 9. 21., https://aws.amazon.com/blogs/containers/using-prometheus-to-avoid-disasters-with-kubernetes-cpu-limits/\r\r\n\r\r\n\r\r\n[![NHN Cloud_meetup banner_footer_blue_202509.png](https://image.toast.com/aaaadh/real/2025/techblog/NHN%20Cloudmeetup%20bannerfooterblue202509.png)](https://www.nhncloud.com/kr)",
        "isoDate": "2025-09-14T23:39:12.000Z"
      }
    ]
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "아시아연합",
        "link": "https://www.thestartupbible.com/2025/09/asian-union.html",
        "pubDate": "Sun, 14 Sep 2025 21:27:00 +0000",
        "content:encodedSnippet": "“한국은 시장이 작다.”\n이 말은 내가 13년 넘게 한국에 투자하면서 셀 수 없을 정도로 너무나 많이 듣던 말이다. 우리 같은 VC에게 자금을 제공하는 한국과 외국 투자자들이 입에 달고 다닐 정도로 너무 많이 하는 지적이고, 심지어 창업가들도 한국 시장이 너무 작기 때문에 항상 해외 시장을 타겟 하거나 아예 본사를 해외로 옮기는 걸 고민하는 경우를 너무 자주 본다. 시장이 작다는 건 다양한 방식으로 해석할 수 있지만, 한국 시장이 작다고 말하는 분들은 대부분 한국의 5,000만 명 인구를 의미한다. 5,000만 인구로 만들 수 있는 GDP와 같은 출력은 한정되어 있기 때문에 한국 시장은 완전히 의미 없을 정도로 작진 않지만, 아무리 커져도 확실히 한계가 있다는 의미이다.\n내가 전에 이 글에서 이제 한국 창업가들이 드디어 글로벌 시장으로 나갈 능력, 배짱, 그리고 자신감이 생겼기 때문에 이제 우리의 TAM(Total Addressable Market)은 한국의 5,000만 명으로 국한되는 게 아니라 일본이나 동남아 시장도 우리의 시장이라고 볼 수 있다고 했다. 이렇게 보면 한국이라는 나라는 인구 5,000만 명의 나라지만, 한국 창업가들의 시장은 이보다 훨씬 더 크다고 할 수 있다.\n물론, 이 외에도 경제 전문가들이 말하는 한국 시장 크기의 한계를 극복하는 두 가지 방법은 북한과의 통일, 그리고 더 많은 외국인을 수입하는 것이다. 현실적으로 북한과의 통일은 단기간 내에 이룩하기 어렵고, 솔직히 요새 많은 분과 이야기해 보면 통일을 오히려 원치 않는다는 느낌을 받기도 한다. 더 많은 외국인을 – 그리고 여기서 말하는 외국인은 외국인 노동자보단, 지식근로자를 의미한다 – 한국으로 수입하기 위해서는 한국의 외국인 비자 정책을 더 쉽고 간단하게 만들어야 한다. 한국의 외국인 비자 프로그램은 생각보다 더 복잡하고 까다로워서 외국인들이 한국에 와서 일하고 사는 게 은근히 어렵다. 그리고 아직도 일부는 한국 젊은이들도 취업을 못 하는데, 외국인들이 한국에 와서 그나마 없는 일자리를 다 “뺐어” 가는 것에 대해서 상당한 불만을 표시하는 분들도 있어서 이 또한 단시간 내에 해결하기 어려운 문제 같다.\n내가 요새 생각하는 한국의 경제 규모와 시장 크기를 확장하는 다른 한 가지 방법은 조금 뜬금없지만, 우리의 가깝고도 먼 이웃 일본과 경제공동체를 만드는 것이다. 그리고 조금 더 나아가선 한국-일본-대만, 이렇게 세 나라가 EU와 같은 경제공동체 AU(Asian Union)를 만드는 것이다. 세 나라는 공통점이 많다. 모두 다 아시아 문화권이고, 모두 다 잘 사는 나라들이고, 모두 다 인구밀도도 비슷해서 이 바닥에서 말하는 ARPU가 높게 나올 수 있다. 그리고 모두 다 서로를 좋아하고 교류가 많다. 이런 말을 전에 공개적으로 했는데, 어떤 분들은 일본과 우리가 경제공동체를 만들어야 한다는 아이디어에 매우 민감하게 반응했다. 대부분 나이가 든 노인들이었는데, 나는 이분들에게 얼마나 많은 한국 젊은이가 일본을 좋아하고, 얼마나 많은 일본 젊은이가 한국을 좋아하는지 강조했다. 솔직히 잘 먹히진 않았지만, 어차피 노인들은 곧 죽을 것이고, 양국의 정치 또한 젊은이들이 할 것이라서 나는 이 아이디어가 그렇게 가능성이 없다고 생각하지 않는다.\n솔직히 대만은 중국이 있어서 좀 어렵긴 할 것 같지만, 이미 월드 클래스인 세 나라가 공동체를 만들 수 있다면, 시장 크기, 인구 크기, 경제 크기, 이 모든 면에서 정말 거대하고 대단한 규모의 시장을 만들 수 있을 것이다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/09/asian-union.html#respond",
        "content": "“한국은 시장이 작다.” 이 말은 내가 13년 넘게 한국에 투자하면서 셀 수 없을 정도로 너무나 많이 듣던 말이다. 우리 같은 VC에게 자금을 제공하는 한국과 외국 투자자들이 입에 달고 다닐 정도로 너무 많이 하는 지적이고, 심지어 창업가들도 한국 시장이 너무 작기 때문에 항상 해외 시장을 타겟 하거나 아예 본사를 해외로 옮기는 걸 고민하는 경우를 너무 자주(...)",
        "contentSnippet": "“한국은 시장이 작다.” 이 말은 내가 13년 넘게 한국에 투자하면서 셀 수 없을 정도로 너무나 많이 듣던 말이다. 우리 같은 VC에게 자금을 제공하는 한국과 외국 투자자들이 입에 달고 다닐 정도로 너무 많이 하는 지적이고, 심지어 창업가들도 한국 시장이 너무 작기 때문에 항상 해외 시장을 타겟 하거나 아예 본사를 해외로 옮기는 걸 고민하는 경우를 너무 자주(...)",
        "guid": "https://www.thestartupbible.com/?p=9560",
        "categories": [
          "Uncategorized",
          "korea"
        ],
        "isoDate": "2025-09-14T21:27:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "습관을 형성하는 기계",
        "link": "https://www.thestartupbible.com/2025/09/the-habit-forming-machine.html",
        "pubDate": "Wed, 10 Sep 2025 21:28:00 +0000",
        "content:encodedSnippet": "얼마 전에 한 팟캐스트에서 습관에 대해 연구하는 작가의 인터뷰를 들었다. 이분이 최근에 출시한 책은 습관은 무엇이고, 어떻게 하면 큰 목표를 달성하기 위한 습관을 형성할 수 있는지에 대한 내용인데, 이 책을 출간하면서 가장 많이 참고했던 게 군대이고, 가장 많이 인터뷰했던 사람들이 군인이라고 한다. 특히 작가가 했던 말 중 내 기억에 인상 깊게 남았던 말은 “군대는 습관을 인위적으로 형성하는 거대한 기계”였다. 이 말을 하면서 예로 들었던 건, 이제 갓 고등학교를 졸업하고 입대한, 정말로 아무것도 모르는 18살짜리 애도 수색하다가 폭탄이 발견되면 완전히 기계같이 행동한다는 내용이었다.\n위의 예처럼 폭탄이 발견되면 기계같이 행동하는 군인들이 있지만, 또 그렇게 하지 않는 군인도 있는데, 어쨌든 전반적으로 군대 자체가 모두의 습관을 형성하는 거대한 기계의 역할을 하므로, 입대하면 어쩔 수 없이 이런 습관들이 다른 업종 사람들보다 더 잘 형성된다는 내용이었다. 나는 이 팟캐스트를 들으면서, 군대만큼 습관을 형성해 주는 거대한 기계는 바로 스타트업이라는 생각을 했다.\n내가 아는 모든 창업가 중 사업을 오랫동안, 꾸준히 잘하는 분들은 모두 다 습관의 동물들이다. 실은 나도 스트롱벤처스를 만들었으니까 굳이 분류하자면 창업가라고 할 수 있는데, 나에게도 스트롱벤처스는 지난 13년 동안 습관을 – 좋은 습관도 있고 좋지 않은 습관도 있지만, 대부분 너무 좋은 습관 – 형성해 준 작은 기계와도 같다. 아마도 투자자로서의 습관, 그리고 실제로 사업을 운영하는 창업가로서의 습관은 조금 다르겠지만, 내가 창업가들을 관찰하면서 느끼는, 이들이 스타트업을 하기 때문에 형성된 가장 두드러진 습관은 우선순위를 파악하는 인지적 습관이다. 사업을 하다 보면 해야 할 일은 너무 많은데, 그 모든 것을 할 수 있는 시간과 돈은 턱없이 부족하다. 그리고 주위에서 잔소리와 훈계를 얼마나 많이 하는지. 이 모든 것을 무시하면서, 실제로 나에게 도움을 주는 조언과 도움이 전혀 되지 않는 잡음을 구분하고, 우리 회사에 도움이 되는 일에만 우선순위를 매기는 습관은 내가 아는 사람 중 창업가들이 가장 잘 한다.\n스타트업이 창업가들에게 기계적으로 형성시켜 주는 또 다른 습관은 행동하고, 이를 계속 반복하는 행동이다. 내가 자주 사용하는 말 중 하나가 “founders are machines of iteration”인데, 한정된 자원으로 좋은 제품을 만들다 보면, 어쩔 수 없이 이론보단 실제로 뭔가를 만들어 테스팅하고, 답이 없는 문제에 대해 오래 끙끙 고민하기보단 그냥 바로 실행하는 게 창업가들이다. 아주 훌륭한 습관이다.\n그리고 또 다른 습관은 위기에서 빠져나가서 살 수 있는 기회와 패턴을 남들보다 더 잘 볼 수 있는 것도 스타트업이 창업가들에게 단련시키는 습관 중 하나인 것 같다. 위기 앞에서 남들은 감정적으로 휩쓸리면서, 가장 덜 고통스럽게 포기하는 방법을 찾지만, 창업가들은 절대로 포기하지 않고, 이 위기를 극복할 방법을 습관적으로 찾게 되는데, 이건 스타트업이 아니었으면 아마도 형성되기 어려운 습관이지 않을까 생각한다.\n마지막으로, 아무리 좋아도 별로 좋아하지 않고, 아무리 나빠도 별로 낙담하지 않는, 일희일비하지 않는 습관이다. 내가 아는 대부분의 경험 많은 창업가들은 일희일비하지 않는다. 실은, 나도 비슷한 성향이긴 하지만, 그래도 너무 좋을 땐 기뻐하고, 너무 화가 날 땐 슬퍼하는 감정에 빠진다. 하지만, 내가 아는 정말 노련한 창업가들은 “이기면 다음 시합을 준비하고, 져도 다음 시합을 준비한다.”라는 덤덤한 마인드로 사업을 하고 인생을 사는데, 이것 또한 스타트업이라는 습관을 형성해 주는 거대한 기계가 아니면 생길 수 없는 좋은 습관인 것 같다.\n위에서 언급한 습관들은 내가 지난 13년 동안 창업가들과 가깝게 지내면서 항상 감탄하면서 동시에 나도 내 습관으로 만들기 위해서 부단하게 노력하고 있는 그런 좋은 장점들인데, 어떻게 보면 이런 습관은 내가 항상 강조하는 창업가의 바퀴벌레와 같은 특성을 기반으로 형성되기도 하는 것 같다. 원래 바퀴벌레 특성을 가진 사람들이 창업하는 건지, 아니면 창업하게 되면 스타트업이라는 기계가 바퀴벌레의 습관을 형성하는 건진 잘 모르겠지만, 아마 둘 다이지 않을까 싶다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/09/the-habit-forming-machine.html#respond",
        "content": "얼마 전에 한 팟캐스트에서 습관에 대해 연구하는 작가의 인터뷰를 들었다. 이분이 최근에 출시한 책은 습관은 무엇이고, 어떻게 하면 큰 목표를 달성하기 위한 습관을 형성할 수 있는지에 대한 내용인데, 이 책을 출간하면서 가장 많이 참고했던 게 군대이고, 가장 많이 인터뷰했던 사람들이 군인이라고 한다. 특히 작가가 했던 말 중 내 기억에 인상 깊게 남았던 말은 “군대는 습관을(...)",
        "contentSnippet": "얼마 전에 한 팟캐스트에서 습관에 대해 연구하는 작가의 인터뷰를 들었다. 이분이 최근에 출시한 책은 습관은 무엇이고, 어떻게 하면 큰 목표를 달성하기 위한 습관을 형성할 수 있는지에 대한 내용인데, 이 책을 출간하면서 가장 많이 참고했던 게 군대이고, 가장 많이 인터뷰했던 사람들이 군인이라고 한다. 특히 작가가 했던 말 중 내 기억에 인상 깊게 남았던 말은 “군대는 습관을(...)",
        "guid": "https://www.thestartupbible.com/?p=9557",
        "categories": [
          "Uncategorized",
          "FoundersAtWork",
          "inspiring",
          "people"
        ],
        "isoDate": "2025-09-10T21:28:00.000Z"
      }
    ]
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "빚 다 갚으면 연체 기록도 지워주는 ‘신용회복’, 나도 대상자일까?",
        "link": "https://toss.im/tossfeed/article/tossmoment-17",
        "pubDate": "Tue, 16 Sep 2025 09:32:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}신용회복이란 특정 기한 내 연체가 발생했지만 이후 전액 상환을 완료한 분들의 연체 기록을 삭제하는 정부 지원 제도.css-1kxrhf3{white-space:pre-wrap;}예요.\n코로나19와 고금리로 생긴 빚을 모두 갚았지만 일부 서민과 소상공인은 과거 연체 기록 때문에 여전히 대출이 거절되거나 카드 발급이 제한 등의 금융 제약을 받고 있었어요. 정부는 이를 개선하기 위해 '신용회복 지원' 제도를 도입했습니다. 재기 의지를 보인 성실상환자들이 정상적인 금융생활로 복귀할 수 있도록 돕고, 불법사금융으로 내몰리는 것을 방지하는 것이 주요 목적이에요.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}Q. 누가 신용회복 대상자인가요?\n신용사면 대상자는 2020년 1월 1일부터 2025년 8월 31일 사이에 5,000만 원 이하의 연체 금액이 발생한 개인 및 사업자예요. 이때 중요한 조건은 2025년 12월 31일까지 전액 상환을 완료해야 한다는 점입니다. 다시 말해 2025년 연말까지 상환을 완료해야 신용사면 혜택을 받을 수 있어요.\nQ. 신용회복 신청은 어떻게 하나요?\n2025년 9월 30일, 신용사면 시스템이 정식 오픈되면 조건에 해당하는 경우 별도의 신청 절차 없이  자동으로 사면이 적용돼요.\n조금 더 구체적으로 말하면 9월 30일 전까지 상환을 완료하면 시스템 오픈과 동시에 연체 기록이 사라지고요. 10월 1일부터 12월 31일 사이에 상환하는 경우에는 다음 날 연체 기록이 없어져요. 복잡한 서류 작성이나 승인 과정 없이, 빚만 다 갚으면 즉시 신용이 회복되죠.\nQ. 신용회복이 되면 어떤 점이 달라지나요?\n신용사면을 받으면 신용점수가 크게 오릅니다. 개인은 평균 39점, 개인사업자는 평균 101점까지 올라가기도 해요. 덕분에 더 나은 조건의 대출이나 카드를 신청하거나, 기존에 쓰던 카드의 한도를 상향하는 등 정상적인 금융생활로 돌아갈 수 있어요.\n다만 신용회복을 받은 후에도 새로운 연체가 발생하지 않도록 계획적인 금융관리를 지속하는 것이 중요해요.\n토스 신용회복 사전알림 신청하고 반가운 소식 놓치지 마세요!\n‘나도 신용회복 대상일지’ 궁금하다면, 토스에서 사전알림 서비스를 활용해보세요. 아래 버튼을 통해 사전알림을 신청해 두시면 9월 30일 오픈과 동시에 대상 여부를 빠르게 확인할 수 있어요.\n이미 대출 상환을 완료하신 경우에도 시스템 오픈과 동시에 신용회복 대상자인지 바로 알려드려요. 아래 버튼을 눌러 사전알림 신청하고 반가운 소식 놓치지 마세요.",
        "content": "대상자 확인부터 상환 방법까지 2025년 최신 버전을 알려드려요  ",
        "contentSnippet": "대상자 확인부터 상환 방법까지 2025년 최신 버전을 알려드려요",
        "guid": "https://toss.im/tossfeed/article/tossmoment-17",
        "isoDate": "2025-09-16T09:32:00.000Z"
      },
      {
        "title": "치열한 미·중 갈등 속에서 찾는 투자 전략",
        "link": "https://toss.im/tossfeed/article/US-Investment-Insights-2",
        "pubDate": "Mon, 15 Sep 2025 09:19:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}📃 토스증권 리서치센터 리포트\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n⟨다녀왔습니다 워싱턴 D.C. - 02. 미국엔 중국이 가득했다⟩\n.css-1kxrhf3{white-space:pre-wrap;}토스증권 리서치센터 애널리스트들은 최근 미국 정치의 심장 워싱턴 D.C.를 다녀왔습니다. 트럼프 당선 이후 정치가 글로벌 주식시장을 흔드는 지금, 현장에서 투자 아이디어를 찾기 위해서였죠.\n그곳에서 얻은 두 번째 인사이트를 한줄로 요약하면 이렇습니다. “미국은 중국 견제에 진심이다!”\n\n워싱턴 D.C에 머무는 동안 인상 깊었던 건 도시 곳곳에서 열리는 세미나와 공개 행사였습니다. 평일 낮임에도 불구하고 많은 사람들이 모여 치열하게 토론하는 모습에서 정책에 대한 높은 사회적 관심이 느껴졌습니다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}토론에서 유독 자주 등장하는 키워드는 바로 ‘중국’이었어요. 현지인들은 중국과의 구도가 경제, 외교, 안보 등 다방면에서 가장 중요한 변수라고 여기고 있었습니다. 중국 얘기를 계속 듣다 보니 궁금해졌습니다. 미국은 왜 이렇게까지 중국을 견제할까요? 이러한 집중 견제는 어떤 결과로 이어질까요?\n이번 글에서는 미국이 중국을 견제하는 이유가 무엇인지, 미·중 갈등이 지속될 경우 투자자는 어떻게 대응해야 하는지를 차근차근 말씀드릴게요.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n미국 vs 중국, 4가지 경쟁 구도\n출장에서 만난 현지 전문가들에 따르면, 미국은 관세뿐 아니라 여러 방면에서 중국을 견제하고 있었습니다. 그 말인즉슨, 중국의 부상을 억제하려면 그만큼 복합적인 전략이 필요하다는 의미입니다.\na) 체제 경쟁\n후버 연구소의 조셉 토리지안은 시진핑 주석이 부친의 숙청 경험과 문화대혁명을 반면교사 삼아 ‘중국식 현대화 모델’을 채택했다고 말합니다. 공산당 이념에 디지털 통제를 융합한 이 모델이 장기 집권을 정당화하는 데 쓰이고 있다는 거죠.\n미국이 경계하는 건 이러한 체제가 중국 외 다른 나라로 확산되는 것입니다. 실제로 중국은 우간다, 짐바브웨 같은 아프리카 기업에 AI 기반 감시 카메라나 안면인식 군중분석 시스템 등 감시 인프라를 수출했어요. 이를 두고 허드슨 연구소의 토마스 벤슨은 중국이 전 세계로 확산될 ‘기술 기반 전체주의 모델’을 선도하고 있다고 우려했습니다.\nb) 금융 자본 경쟁\n미국은 중국으로 금융자본이 유입되는 상황에 대해서도 강한 경계심을 갖고 있었습니다. 토마스 벤슨은 특히 미국과 유럽의 자본이 홍콩 증시를 통해 제재 대상인 중국 기업으로 흘러갈 수 있음을 지적했어요.\n예를 들어, 미국은 인권 문제를 이유로 신장 위구르 지역에서 생산된 제품의 수입을 금지하고 있습니다. 하지만 이들 기업도 금융시장을 통하면 미국으로부터 자금을 조달할 수 있죠. 당연히 제재 효과는 약해질 수밖에 없습니다.\nc) 기술 패권 경쟁\nAI, 반도체, 위성 등 첨단 기술은 국가 경쟁력의 핵심으로 여겨져요. 미국이 중국의 기술 발전을 경계하는 이유도 여기에 있습니다. 실제로 미국은 AI 산업의 핵심인 GPU 가 중국으로 수출되는 것에 제한을 두고 있죠.\n우려가 현실로 드러난 사례도 있었습니다. 올해 초 중국 딥시크(Deepseek)가 등장하면서 미국 주식시장에서 엔비디아 등 관련 기업의 주가가 크게 하락한 것입니다. 이후 주가는 회복되었지만, 중국의 기술 발전이 미국의 AI 및 반도체 산업에 타격을 줄 수 있다는 걸 보여준 사건이었어요.\nd) 공급망 확보 경쟁\n코로나19 당시 미국은 면봉이나 시약 같은 기본적인 의료 물품조차 중국에 의존해야 했어요. 쓰라린 경험을 통해 미국은 공급망 확보의 중요성을 새삼 깨달았죠. 이후 미국은 헬스케어 산업뿐 아니라 반도체, 에너지, 클라우드 등 핵심 산업 전반에 걸쳐 공급망 국내화를 추진하고 있습니다.\n바이든 정부가 인플레이션 감축법(IRA)*, 칩스법(Chips Act)** 등 미국 내 에너지/반도체 생산 기업에 보조금을 지급한 것도 공급망 국내화 전략의 일환이었습니다. 칩스법에는 ‘미국에서 보조금을 받는 기업은 중국 내 첨단 반도체 투자를 금지한다’는 조항이 포함되어 있죠. 인플레이션 감축법 또한 ‘중국에서 생산된 소재 및 부품을 사용할 경우 보조금 대상에서 제외한다’는 조건을 담고 있고요.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}* 미국 내에서 생산된 전기차·배터리 등 친환경 산업에 보조금을 주는 법\n** 미국 내 반도체 공장 투자와 생산에 보조금과 세제 혜택을 지원하는 법\n과거 미국이 견제했던 다른 나라들\n미국은 과거에도 특정 국가를 견제한 적이 있습니다. 바로 소련과 일본이에요.\n\na) 소련 - 냉전시대의 경쟁자\n1950년대, 공산주의 진영을 대표하던 소련은 산업화에 성공하며 세계 2위 경제대국으로 올라섰어요. 군사력도 막강했죠. 미국 입장에서는 위기감이 들 수밖에 없었습니다. 그때 미국 외교관 조지 캐넌이 대통령에게 편지 한 통을 보냅니다.\n.css-2sk6rv{font-size:19px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);white-space:pre-wrap;margin:24px 0;padding-left:20px;position:relative;}.css-2sk6rv::before{content:'';display:block;position:absolute;top:4px;left:0;width:2px;height:calc(100% - 4px * 2);padding:4px 0;background-color:var(--adaptiveGrey800);}\n소련은 공산주의 확산을 꿈꾸고 있습니다. 정치, 경제, 외교로 봉쇄해야 해요..css-7mseny>*{margin-left:0;margin-right:0;}.css-7mseny>:last-child{margin-bottom:0;}blockquote>.css-7mseny:first-child>:first-child{margin-top:0;}\n이 편지를 계기로 소련 봉쇄 전략이 구체화됐어요.\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n마셜 플랜: 유럽 경제 재건 지원으로 소련의 영향력 차단\n나토(NATO): 서유럽 국가들을 군사 동맹으로 묶어 소련 견제\n\n쉽게 말해 미국이 소련을 왕따시킨 셈이었죠. 당시 미·소 갈등은 자유주의와 공산주의의 ‘진영 싸움’이었기에 가능했어요. 결국 막대한 군비 지출에 허덕이던 소련은 붕괴했습니다.\nb) 일본 - 한때 반도체 생산량 1위\n1980년대에는 일본이 미국을 긴장하게 했습니다. 일본의 반도체, 자동차, 전자제품이 세계 시장을 휩쓸면서 미국의 핵심 산업을 위협했거든요. 당시 미국 무역적자의 40%가 일본 때문일 정도였어요.\n미국은 곧바로 대응했습니다. 엔화 가치를 올리는 ‘플라자 합의’로 일본의 수출 경쟁력을 꺾고, 반도체 협정을 맺어 일본 기업들이 만든 반도체의 가격과 시장 점유율에 관여하기 시작했죠.\n미국과의 무역에 기대 성장한 일본에는 뼈아픈 견제였습니다. 결국 일본은 버블 붕괴와 함께 ‘잃어버린 20년’을 맞이하게 됩니다.\n중국과의 싸움은\n조금 더 복잡하고 어렵다\n소련도 눌렀고 일본도 눌렀으니, 중국과의 대결에서도 미국이 간단히 승리할까요? 생각만큼 그리 간단하지 않습니다. 중국은 과거 라이벌인 소련과 일본보다 훨씬 까다로운 상대거든요.\n\n중국은 소련처럼 체제가 달라 동맹을 맺기는 어려운 상대인데, 일본처럼 무역으로 긴밀히 얽혀 있어 완전히 끊어내기도 어렵기 때문입니다. 이른바 ‘복합 경쟁자’인 셈이죠.\n게다가 중국은 과거 소련과 일본의 사례에서 교훈도 얻었어요. 소련처럼 무리한 군비 경쟁에 뛰어들지도 않고, 일본처럼 불리한 협상 테이블에 앉지도 않고 있죠. 대신 수출과 내수 시장을 함께 키우는 ‘쌍순환 전략’으로 버틸 힘을 기르겠다는 영리한 전략을 펴고 있어요.\n투자자는 어떻게 대응해야 할까요?\n1. 장기전을 염두에 두기\n미국과 중국의 갈등은 길어질 거예요. 두 나라의 복잡한 관계를 고려했을 때, 미국과 중국의 갈등이 단기간에 끝나진 않을 거거든요. 그러니 앞으로 장기전이 될 가능성이 높다는 걸 염두에 두셔야 해요.\n2. 기술 패권 경쟁에 주목하기\n기술 패권을 둘러싼 치열한 경쟁은 기술 기업에게 기회가 될 수 있어요.css-1swx3yz{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;font-weight:bold;}. 두 나라 모두 기술 패권을 유지하는 것이 얼마나 중요한 일인지 잘 알고 있기 때문에, 경쟁이 치열할수록 산업의 성장 속도도 빨라질 거예요. 인공지능, 우주, 로봇 등 기술 패권을 좌우할 분야는 이미 윤곽이 드러나고 있습니다.\n3. 잠재적 리스크 관리하기\n지속되는 갈등은 잠재적인 리스크예요. 미·중 갈등이 언제든 다시 격화될 수 있다는 점을 염두에 둘 필요가 있어요. 세계 1, 2위 국가의 충돌은 글로벌 증시에 큰 충격을 줄 수 있어요. 이는 트럼프의 임기가 끝나든, 집권 정당이 바뀌든 마찬가지입니다. 미·중 갈등을 사라지지 않을 ‘상수’로 받아들이는 것이 중요합니다.\n\n💡 다음 글 예고\n\n트럼프 2기 정부 출범과 함께 신설된 DOGE(정부효율부), 혹시 잊으셨나요?\n우리가 워싱턴에서 만난 기업 관계자들은 하나같이 DOGE(Department of Government Efficiency)의 영향력에 대해 이야기하고 있었어요. 다음 글에서는 DOGE 의 진짜 목적은 무엇이며 향후 미국 경제에는 어떤 영향을 미칠지, 기업과 언론, 정치권의 평가는 어떤지, 결국 투자자가 알아야 할 것들은 무엇일지에 대해 말씀드리겠습니다.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nWriter 한상원 애널리스트 Edit 기명균 윤동해 Graphic 윤자영",
        "content": "중국 견제에 진심인 미국과 버틸 힘을 기르는 중국",
        "contentSnippet": "중국 견제에 진심인 미국과 버틸 힘을 기르는 중국",
        "guid": "https://toss.im/tossfeed/article/US-Investment-Insights-2",
        "isoDate": "2025-09-15T09:19:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]