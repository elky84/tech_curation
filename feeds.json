[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Strobelight: A profiling service built on open source technology",
        "link": "https://engineering.fb.com/2025/01/21/production-engineering/strobelight-a-profiling-service-built-on-open-source-technology/",
        "pubDate": "Tue, 21 Jan 2025 17:00:54 +0000",
        "content:encodedSnippet": "We’re sharing details about Strobelight, Meta’s profiling orchestrator.\nStrobelight combines several technologies, many open source, into a single service that helps engineers at Meta improve efficiency and utilization across our fleet.\nUsing Strobelight, we’ve seen significant efficiency wins, including one that has resulted in an estimated 15,000 servers’ worth of annual capacity savings.\nStrobelight, Meta’s profiling orchestrator, is not really one technology. It’s several (many open source) combined to make something that unlocks truly amazing efficiency wins. Strobelight is also not a single profiler but an orchestrator of many different profilers (even ad-hoc ones) that runs on all production hosts at Meta, collecting detailed information about CPU usage, memory allocations, and other performance metrics from running processes. Engineers and developers can use this information to identify performance and resource bottlenecks, optimize their code, and improve utilization.\nWhen you combine talented engineers with rich performance data you can get efficiency wins by both creating tooling to identify issues before they reach production and finding opportunities in already running code. Let’s say an engineer makes a code change that introduces an unintended copy of some large object on a service’s critical path. Meta’s existing tools can identify the issue and query Strobelight data to estimate the impact on compute cost. Then Meta’s code review tool can notify the engineer that they’re about to waste, say, 20,000 servers.\nOf course, static analysis tools can pick up on these sorts of issues, but they are unaware of global compute cost and oftentimes these inefficiencies aren’t a problem until they’re gradually serving millions of requests per minute. The frog can boil slowly.\nWhy do we use profilers?\nProfilers operate by sampling data to perform statistical analysis. For example, a profiler takes a sample every N events (or milliseconds in the case of time profilers) to understand where that event occurs or what is happening at the moment of that event. With a CPU-cycles event, for example, the profile will be CPU time spent in functions or function call stacks executing on the CPU. This can give an engineer a high-level understanding of the code execution of a service or binary.\nChoosing your own adventure with Strobelight\nThere are other daemons at Meta that collect observability metrics, but Strobelight’s wheelhouse is software profiling. It connects resource usage to source code (what developers understand best). Strobelight’s profilers are often, but not exclusively, built using eBPF, which is a Linux kernel technology. eBPF allows the safe injection of custom code into the kernel, which enables very low overhead collection of different types of data and unlocks so many possibilities in the observability space that it’s hard to imagine how Strobelight would work without it.\nAs of the time of writing this, Strobelight has 42 different profilers, including:\nMemory profilers powered by jemalloc.\nFunction call count profilers.\nEvent-based profilers for both native and non-native languages (e.g., Python, Java, and Erlang).\nAI/GPU profilers.\nProfilers that track off-CPU time.\nProfilers that track service request latency.\nEngineers can utilize any one of these to collect data from servers on demand via Strobelight’s command line tool or web UI.\nThe Strobelight web UI.\nUsers also have the ability to set up continuous or “triggered” profiling for any of these profilers by updating a configuration file in Meta’s Configerator, allowing them to target their entire service or, for example, only hosts that run in certain regions. Users can specify how often these profilers should run, the run duration, the symbolization strategy, the process they want to target, and a lot more.\nHere is an example of a simple configuration for one of these profilers:\nadd_continuous_override_for_offcpu_data(\r\n    \"my_awesome_team\", // the team that owns this service\r\n    Type.SERVICE_ID,\r\n    \"my_awseome_service\",\r\n    30_000, // desired samples per hour\r\n)\r\n\nWhy does Strobelight have so many profilers? Because there are so many different things happening in these systems powered by so many different technologies.\nThis is also why Strobelight provides ad-hoc profilers. Since the kind of data that can be gathered from a binary is so varied, engineers often need something that Strobelight doesn’t provide out of the box. Adding a new profiler from scratch to Strobelight involves several code changes and could take several weeks to get reviewed and rolled out.\nHowever, engineers can write a single bpftrace script (a simple language/tool that allows you to easily write eBPF programs) and tell Strobelight to run it like it would any other profiler. An engineer that really cares about the latency of a particular C++ function, for example, could write up a little bpftrace script, commit it, and have Strobelight run it on any number of hosts throughout Meta’s fleet – all within a matter of hours, if needed.\nIf all of this sounds powerfully dangerous, that’s because it is. However, Strobelight has several safeguards in place to prevent users from causing performance degradation for the targeted workloads and retention issues for the databases Strobelight writes to. Strobelight also has enough awareness to ensure that different profilers don’t conflict with each other. For example, if a profiler is tracking CPU cycles, Strobelight ensures another profiler can’t use another PMU counter at the same time (as there are other services that also use them).\nStrobelight also has concurrency rules and a profiler queuing system. Of course, service owners still have the flexibility to really hammer their machines if they want to extract a lot of data to debug.\nDefault data for everyone\nSince its inception, one of Strobelight’s core principles has been to provide automatic, regularly-collected profiling data for all of Meta’s services. It’s like a flight recorder – something that doesn’t have to be thought about until it’s needed. What’s worse than waking up to an alert that a service is unhealthy and there is no data as to why?\nFor that reason, Strobelight has a handful of curated profilers that are configured to run automatically on every Meta host. They’re not running all the time; that would be “bad” and not really “profiling.” Instead, they have custom run intervals and sampling rates specific to the workloads running on the host. This provides just the right amount of data without impacting the profiled services or overburdening the systems that store Strobelight data.\nHere is an example:\nA service, named Soft Server, runs on 1,000 hosts and let’s say we want profiler A to gather 40,000 CPU-cycles samples per hour for this service (remember the config above). Strobelight, knowing how many hosts Soft Server runs on, but not how CPU intensive it is, will start with a conservative run probability, which is a sampling mechanism to prevent bias (e.g., profiling these hosts at noon every day would hide traffic patterns).\nThe next day Strobelight will look at how many samples it was able to gather for this service and then automatically tune the run probability (with some very simple math) to try to hit 40,000 samples per hour. We call this dynamic sampling and Strobelight does this readjustment every day for every service at Meta.\nAnd if there is more than one service running on the host (excluding daemons like systemd or Strobelight) then Strobelight will default to using the configuration that will yield more samples for both.\nHang on, hang on. If the run probability or sampling rate is different depending on the host for a service, then how can the data be aggregated or compared across the hosts? And how can profiling data for multiple services be compared?\nSince Strobelight is aware of all these different knobs for profile tuning, it adjusts the “weight” of a profile sample when it’s logged. A sample’s weight is used to normalize the data and prevent bias when analyzing or viewing this data in aggregate. So even if Strobelight is profiling Soft Server less often on one host than on another, the samples can be accurately compared and grouped. This also works for comparing two different services since Strobelight is used both by service owners looking at their specific service as well as efficiency experts who look for “horizontal” wins across the fleet in shared libraries.\nHow Strobelight saves capacity\nThere are two default continuous profilers that should be called out because of how much they end up saving in capacity.\nThe last branch record (LBR) profiler \nThe LBR profiler, true to its name, is used to sample last branch records (a hardware feature that started on Intel). The data from this profiler doesn’t get visualized but instead is fed into Meta’s feedback directed optimization (FDO) pipeline. This data is used to create FDO profiles that are consumed at compile time (CSSPGO) and post-compile time (BOLT) to speed up binaries through the added knowledge of runtime behavior. Meta’s top 200 largest services all have FDO profiles from the LBR data gathered continuously across the fleet. Some of these services see up to 20% reduction in CPU cycles, which equates to a 10-20% reduction in the number of servers needed to run these services at Meta.\nThe event profiler\nThe second profiler is Strobelight’s event profiler. This is Strobelight’s version of the Linux perf tool. Its primary job is to collect user and kernel stack traces from multiple performance (perf) events e.g., CPU-cycles, L3 cache misses, instructions, etc. Not only is this data looked at by individual engineers to understand what the hottest functions and call paths are, but this data is also fed into monitoring and testing tools to identify regressions; ideally before they hit production.\nDid someone say Meta…data?\nLooking at function call stacks with flame graphs is great, nothing against it. But a service owner looking at call stacks from their service, which imports many libraries and utilizes Meta’s software frameworks, will see a lot of “foreign” functions. Also, what about finding just the stacks for p99 latency requests? Or how about all the places where a service is making an unintended string copy?\nStack schemas\nStrobelight has multiple mechanisms for enhancing the data it produces according to the needs of its users. One such mechanism is called Stack Schemas (inspired by Microsoft’s stack tags), which is a small DSL that operates on call stacks and can be used to add tags (strings) to entire call stacks or individual frames/functions. These tags can then be utilized in our visualization tool. Stack Schemas can also remove functions users don’t care about with regex matching. Any number of schemas can be applied on a per-service or even per-profile basis to customize the data.\nThere are even folks who create dashboards from this metadata to help other engineers identify expensive copying, use of inefficient or inappropriate C++ containers, overuse of smart pointers, and much more. Static analysis tools that can do this have been around for a long time, but they can’t pinpoint the really painful or computationally expensive instances of these issues across a large fleet of machines.\nStrobemeta\nStrobemeta is another mechanism, which utilizes thread local storage, to attach bits of dynamic metadata at runtime to call stacks that we gather in the event profiler (and others). This is one of the biggest advantages of building profilers using eBPF: complex and customized actions taken at sample time. Collected Strobemeta is used to attribute call stacks to specific service endpoints, or request latency metrics, or request identifiers. Again, this allows engineers and tools to do more complex filtering to focus the vast amounts of data that Strobelight profilers produce.\nSymbolization\nNow is a good time to talk about symbolization: taking the virtual address of an instruction, converting it into an actual symbol (function) name, and, depending on the symbolization strategy, also getting the function’s source file, line number, and type information.\nMost of the time getting the whole enchilada means using a binary’s DWARF debug info. But this can be many megabytes (or even gigabytes) in size because DWARF debug data contains much more than the symbol information.\nThis data needs to be downloaded then parsed. But attempting this while profiling, or even afterwards on the same host where the profile is gathered, is far too computationally expensive. Even with optimal caching strategies it can cause memory issues for the host’s workloads.\nStrobelight gets around this problem via a symbolization service that utilizes several open source technologies including DWARF, ELF, gsym, and blazesym. At the end of a profile Strobelight sends stacks of binary addresses to a service that sends back symbolized stacks with file, line, type info, and even inline information.\nIt can do this because it has already done all the heavy lifting of downloading and parsing the DWARF data for each of Meta’s binaries (specifically, production binaries) and stores what it needs in a database. Then it can serve multiple symbolization requests coming from different instances of Strobelight running throughout the fleet.\nTo add to that enchilada (hungry yet?), Strobelight also delays symbolization until after profiling and stores raw data to disk to prevent memory thrash on the host. This has the added benefit of not letting the consumer impact the producer – meaning if Strobelight’s user space code can’t handle the speed at which the eBPF kernel code is producing samples (because it’s spending time symbolizing or doing some other processing) it results in dropped samples.\nAll of this is made possible with the inclusion of frame pointers in all of Meta’s user space binaries, otherwise we couldn’t walk the stack to get all these addresses (or we’d have to do some other complicated/expensive thing which wouldn’t be as efficient). \nA simplified Strobelight service graph.\nShow me the data (and make it nice)!\nThe primary tool Strobelight customers use is Scuba – a query language (like SQL), database, and UI. The Scuba UI has a large suite of visualizations for the queries people construct (e.g., flame graphs, pie charts, time series graphs, distributions, etc).\nStrobelight, for the most part, produces Scuba data and, generally, it’s a happy marriage. If someone runs an on-demand profile, it’s just a few seconds before they can visualize this data in the Scuba UI (and send people links to it). Even tools like Perfetto expose the ability to query the underlying data because they know it’s impossible to try to come up with enough dropdowns and buttons that can express everything you want to do in a query language – though the Scuba UI comes close.\nAn example flamegraph/icicle of function call stacks of the CPU cycles event for the mononoke service for one hour.\nThe other tool is a trace visualization tool used at Meta named Tracery. We use this tool when we want to combine correlated but different streams of profile data on one screen. This data is also a natural fit for viewing on a timeline. Tracery allows users to make custom visualizations and curated workspaces to share with other engineers to pinpoint the important parts of that data. It’s also powered by a client-side columnar database (written in JavaScript!), which makes it very fast when it comes to zooming and filtering. Strobelight’s Crochet profiler combines service request spans, CPU-cycles stacks, and off-CPU data to give users a detailed snapshot of their service.\nAn example trace in Tracery.\nThe Biggest Ampersand\nStrobelight has helped engineers at Meta realize countless efficiency and latency wins, ranging from increases in the number of requests served, to large reductions in heap allocations, to regressions caught in pre-prod analysis tools.\nBut one of the most significant wins is one we call, “The Biggest Ampersand.”\nA seasoned performance engineer was looking through Strobelight data and discovered that by filtering on a particular std::vector function call (using the symbolized file and line number) he could identify computationally expensive array copies that happen unintentionally with the ‘auto’ keyword in C++.\nThe engineer turned a few knobs, adjusted his Scuba query, and happened to notice one of these copies in a particularly hot call path in one of Meta’s largest ads services. He then cracked open his code editor to investigate whether this particular vector copy was intentional… it wasn’t.\nIt was a simple mistake that any engineer working in C++ has made a hundred times.\nSo, the engineer typed an “&” in front of the auto keyword to indicate we want a reference instead of a copy. It was a one-character commit, which, after it was shipped to production, equated to an estimated 15,000 servers in capacity savings per year!\nGo back and re-read that sentence. One ampersand! \nAn open ending\nThis only scratches the surface of everything Strobelight can do. The Strobelight team works closely with Meta’s performance engineers on new features that can better analyze code to help pinpoint where things are slow, computationally expensive, and why.\nWe’re currently working on open-sourcing Strobelight’s profilers and libraries, which will no doubt make them more robust and useful. Most of the technologies Strobelight uses are already public or open source, so please use and contribute to them!\nAcknowledgements\nSpecial thanks to Wenlei He, Andrii Nakryiko, Giuseppe Ottaviano, Mark Santaniello, Nathan Slingerland, Anita Zhang, and the Profilers Team at Meta. \nThe post Strobelight: A profiling service built on open source technology appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>We’re sharing details about Strobelight, Meta’s profiling orchestrator. Strobelight combines several technologies, many open source, into a single service that helps engineers at Meta improve efficiency and utilization across our fleet. Using Strobelight, we’ve seen significant efficiency wins, including one that has resulted in an estimated 15,000 servers’ worth of annual capacity savings. Strobelight, Meta’s [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/01/21/production-engineering/strobelight-a-profiling-service-built-on-open-source-technology/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/01/21/production-engineering/strobelight-a-profiling-service-built-on-open-source-technology/\">Strobelight: A profiling service built on open source technology</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "We’re sharing details about Strobelight, Meta’s profiling orchestrator. Strobelight combines several technologies, many open source, into a single service that helps engineers at Meta improve efficiency and utilization across our fleet. Using Strobelight, we’ve seen significant efficiency wins, including one that has resulted in an estimated 15,000 servers’ worth of annual capacity savings. Strobelight, Meta’s [...]\nRead More...\nThe post Strobelight: A profiling service built on open source technology appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=22157",
        "categories": [
          "Open Source",
          "Production Engineering"
        ],
        "isoDate": "2025-01-21T17:00:54.000Z"
      },
      {
        "creator": "",
        "title": "Measuring productivity impact with Diff Authoring Time",
        "link": "https://engineering.fb.com/2025/01/16/developer-tools/measuring-productivity-impact-with-diff-authoring-time/",
        "pubDate": "Thu, 16 Jan 2025 17:00:00 +0000",
        "content:encodedSnippet": "Do types actually make developers more productive? Or is it just more typing on the keyboard? To answer that question we’re revisiting Diff Authoring Time (DAT) – how Meta measures how long it takes to submit changes to a codebase.\nDAT is just one of the ways e measure developer productivity and this latest episode of the Meta Tech Podcast takes a look at two concrete use cases for DAT, including a type-safe mocking framework in Hack.\nTune in to learn how we leverage metrics to run experiments on productivity in our internal codebase at Meta.\nDownload or listen to the podcast episode below:\n\nSpotify\nApple Podcasts\nPocket Casts\nOvercast\nThe Meta Tech Podcast is a podcast, brought to you by Meta, where we highlight the work Meta’s engineers are doing at every level – from low-level frameworks to end-user features.\nSend us feedback on Instagram, Threads, or X.\nAnd if you’re interested in learning more about career opportunities at Meta visit the Meta Careers page.\nThe post Measuring productivity impact with Diff Authoring Time appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Do types actually make developers more productive? Or is it just more typing on the keyboard? To answer that question we’re revisiting Diff Authoring Time (DAT) – how Meta measures how long it takes to submit changes to a codebase. DAT is just one of the ways e measure developer productivity and this latest episode [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/01/16/developer-tools/measuring-productivity-impact-with-diff-authoring-time/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/01/16/developer-tools/measuring-productivity-impact-with-diff-authoring-time/\">Measuring productivity impact with Diff Authoring Time</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Do types actually make developers more productive? Or is it just more typing on the keyboard? To answer that question we’re revisiting Diff Authoring Time (DAT) – how Meta measures how long it takes to submit changes to a codebase. DAT is just one of the ways e measure developer productivity and this latest episode [...]\nRead More...\nThe post Measuring productivity impact with Diff Authoring Time appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=22150",
        "categories": [
          "Culture",
          "DevInfra",
          "Meta Tech Podcast"
        ],
        "isoDate": "2025-01-16T17:00:00.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Christian Herold and Shahram Khadivi",
        "title": "Scaling Large Language Models for e-Commerce: The Development of a Llama-Based Customized LLM",
        "link": "https://innovation.ebayinc.com/tech/features/scaling-large-language-models-for-e-commerce-the-development-of-a-llama-based-customized-llm-for-e-commerce/",
        "pubDate": "Fri, 17 Jan 2025 00:00:00 -0800",
        "dc:creator": "Christian Herold and Shahram Khadivi",
        "content": "<div style=\"margin-bottom: 10px;\"><img src=\"https://static.ebayinc.com/static/assets/Uploads/Blog/Posts/_resampled/FitWzIwMCwxMTZd/Llama-Graphic.jpg?fs=238f37447da3cf46\" width=\"200\" height=\"116\" alt=\"Scaling Large Language Models for e-Commerce: The Development of a Llama-Based Customized LLM\" /></div><div>Third-party LLMs like Llama 3.1 allow us to adapt powerful tools for the e-commerce domain with a mix of eBay and general data to enable our magical AI experiences. </div>",
        "contentSnippet": "Third-party LLMs like Llama 3.1 allow us to adapt powerful tools for the e-commerce domain with a mix of eBay and general data to enable our magical AI experiences.",
        "guid": "https://innovation.ebayinc.com/tech/features/scaling-large-language-models-for-e-commerce-the-development-of-a-llama-based-customized-llm-for-e-commerce/",
        "categories": [
          "article"
        ],
        "isoDate": "2025-01-17T08:00:00.000Z"
      },
      {
        "creator": "eBay News Team",
        "title": "eBay Design Team Reflects On a Transformative 2024",
        "link": "https://innovation.ebayinc.com/tech/features/ebay-design-2024/",
        "pubDate": "Thu, 16 Jan 2025 00:00:00 -0800",
        "dc:creator": "eBay News Team",
        "content": "<div style=\"margin-bottom: 10px;\"><img src=\"https://static.ebayinc.com/static/assets/Uploads/Blog/Posts/_resampled/FitWzIwMCwxMTJd/2024-Lookback-Article-Thumbnail.jpg?fs=fecdec16f242078b\" width=\"200\" height=\"112\" alt=\"eBay Design Team Reflects On a Transformative 2024\" /></div><div>Check out a roundup of eBay Design’s favorite moments from 2024.</div>",
        "contentSnippet": "Check out a roundup of eBay Design’s favorite moments from 2024.",
        "guid": "https://innovation.ebayinc.com/tech/features/ebay-design-2024/",
        "categories": [
          "article"
        ],
        "isoDate": "2025-01-16T08:00:00.000Z"
      }
    ]
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Maria Kosukhina",
        "title": "IntelliJ IDEA 2025.1 EAP 2: Containerfile Support and Updates for Dockerfiles",
        "link": "https://blog.jetbrains.com/idea/2025/01/intellij-idea-2025-1-eap-2/",
        "pubDate": "Wed, 22 Jan 2025 18:39:56 +0000",
        "content:encodedSnippet": "IntelliJ IDEA 2025.1 EAP 2 is out!\nWith a focus on improving workflows for environments like Docker containers and other remote solutions, this build introduces updates that simplify setup and enhance productivity in these scenarios.\nYou can now download this version from our website, update directly from within the IDE, use the free Toolbox App, or install it via snap packages for Ubuntu. \nDownload IntelliJ IDEA 2025.1 EAP 2\nTry the new updates delivered with the second EAP build for yourself! \nRemote development environments \nContainerfile support \nContainer ecosystems have been evolving beyond Docker-centric workflows, with tools like Podman and Buildah favoring Containerfile as a neutral alternative. However, IDE support, which is typically tied to Dockerfile, often lagged behind. That created friction, forcing developers to either rename Containerfile to Dockerfile, lose Podman-specific best practices, or just plow through with basic text editing. \nNow, JetBrains IDEs come with built-in Containerfile recognition. This might seem like a relatively minor enhancement, but it really contributes to a smooth developer experience for anyone juggling Docker, Podman, and Buildah in the same environment.\nIt is no longer necessary to keep separate versions of your build files just so your IDE doesn’t treat them as plain text. And for new hires or open-source contributors using Podman straight from the get-go, it provides enhanced clarity.\nSyntax highlighting, linting, and snippet suggestions are fully supported, reducing errors, speeding up debugging, and improving clarity – especially for new hires or contributors using Podman. Now, it doesn’t matter if you switch engines or if half the team uses Docker while the other half uses Podman – everyone can work with the same file, recognized by the same tools.\n\n\n\n\nSupport for lowercase instructions in Dockerfiles \nIntelliJ IDEA 2025.1 EAP 2 brings enhanced Dockerfile support, allowing you to write directives in lowercase in addition to the conventional uppercase. Previously, the IDE recognized commands like FROM, RUN, and COPY primarily as Dockerfile instructions. Now, you’re also free to use the lowercase from, run, and copy, too.\nAlthough Docker itself is case-insensitive with regard to instructions, uppercase has historically been used to improve readability and to distinguish instructions from arguments. However, alternative casing styles might be preferred to accommodate specific commands, plugins, corporate standards, or personal preferences. With this update, you can adhere to your preferred conventions without risking missing highlights or encountering misleading warnings from the IDE.\n\n\n\n\nNew inspection for reliable ENTRYPOINT initialization with exec\nWe’ve introduced a new Dockerfile inspection that ensures your ENTRYPOINT is correctly initiated with exec. Using exec allows signals sent via docker stop to reach the main process directly, preventing lingering or improperly terminated processes. If you omit exec, your application may run as a child process and fail to receive signals like SIGTERM, making shutdown unreliable. This inspection highlights incorrect ENTRYPOINT usage and guides you toward best practices, helping you maintain cleaner Dockerfiles and more robust container lifecycles.\n\n\n\n\nThese are the key updates for this week. For the complete list of changes, refer to the release notes.\nWe’d love for you to explore the new features and share your feedback. Let us know your thoughts and ideas in the comments below, or get in touch with us on X. If you encounter any issues, please report them through our issue tracker.\nHappy developing!",
        "dc:creator": "Maria Kosukhina",
        "content": "IntelliJ IDEA 2025.1 EAP 2 is out! With a focus on improving workflows for environments like Docker containers and other remote solutions, this build introduces updates that simplify setup and enhance productivity in these scenarios. You can now download this version from our website, update directly from within the IDE, use the free Toolbox App, [&#8230;]",
        "contentSnippet": "IntelliJ IDEA 2025.1 EAP 2 is out! With a focus on improving workflows for environments like Docker containers and other remote solutions, this build introduces updates that simplify setup and enhance productivity in these scenarios. You can now download this version from our website, update directly from within the IDE, use the free Toolbox App, […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=540054",
        "categories": [
          "eap"
        ],
        "isoDate": "2025-01-22T18:39:56.000Z"
      },
      {
        "creator": "Ksenia Shneyveys",
        "title": "Results of Google Summer of Code 2024 With the Kotlin Foundation",
        "link": "https://blog.jetbrains.com/kotlin/2025/01/google-summer-of-code-2024-with-kotlin-results/",
        "pubDate": "Wed, 22 Jan 2025 13:04:45 +0000",
        "content:encodedSnippet": "2024 marked another exciting year with respect to the Kotlin Foundation’s participation in Google Summer of Code (GSoC). GSoC is a global online program that introduces new contributors to open-source development. This year, contributors worked to expand the Kotlin ecosystem under the guidance of mentors from Google, Gradle, Microsoft, and JetBrains.\nJoin our Slack channel to learn about the next GSoC and other opportunities to contribute.\nJoin GSoC Slack\nWe’re thrilled to share the results of GSoC 2024, with four projects successfully making it into production:\nStorytale – a Compose Multiplatform component gallery generator\nThis project introduces a much-needed gallery generator for Compose Multiplatform, designed to help developers showcase and test composable functions across platforms. To achieve this, contributor WhiteScent developed a Gradle plugin and runtime library that define and generate a centralized, multiplatform gallery app (for web, desktop, iOS, and Android), offering parameter adjustments and interactions in an isolated visual interface.\nA big thanks to WhiteScent, a computer science student and Android enthusiast, and Artem Kobzar, a software engineer working on Kotlin/Wasm at JetBrains, for their great work!\nRead the full blog post.\nShare ideas and contributions to this project: Storytale on GitHub.\nIncremental compilation for the Kotlin/Wasm compiler\nThis project enhanced the Kotlin-to-Wasm compiler with incremental compilation capabilities, reducing build times by allowing it to recompile only modified files. The contributor, Osama Ahmad, optimized and reused components from the Kotlin/JS backend while improving documentation and refactoring the codebase.\nThanks to Osama Ahmad and the mentor from JetBrains, Igor Yakovlev, for their great input!\nRead the full blog post.\nExplore Kotlin/Wasm.\nAndroid support in the Gradle Build Server\nThis project brought Android project support to the Gradle Build Server. Despite starting with limited Gradle API knowledge, contributor Tanish Ranjan successfully implemented features like composite build support, Java Home handling, and Android project discovery. These enhancements have been integrated into production, enriching Gradle for Kotlin/Android development.\nWe thank Tanish Ranjan and the team of mentors, Oleg Nenashev, Donát Csikós, Bálint Hegyi, Sheng Chen, and Reinhold, for their valuable contributions to the Kotlin and Gradle ecosystems.\nRead the full blog post.\nCheck out the project page.\nSupport for Android targets in kotlinx-benchmark\nThis project enhanced the kotlinx-benchmark library, an open-source tool for benchmarking Kotlin code across platforms such as JVM, JS, wasmJs, and native, by adding support for Android benchmarking through integration with androidx.benchmark. To achieve this, the developers detected Android targets, generated template projects, integrated benchmark annotations, validated tests, and captured results.\nThank you to Qizhao Chen and the mentor team, Abduqodiri Qurbonzoda, Dustin Lam, and Rahul Ravikumar, for your great input.\nRead the full blog post.\nCheck out the kotlinx-benchmark library.\nWe are immensely grateful to our contributors, the mentors, and the Kotlin Foundation for making GSoC 2024 a success!\nJoin our Slack channel to stay tuned for more updates and other opportunities to contribute:\nJoin GSoC Slack\nLet’s continue to expand Kotlin’s reach and usability across platforms. Thank you!",
        "dc:creator": "Ksenia Shneyveys",
        "content": "2024 marked another exciting year with respect to the Kotlin Foundation’s participation in Google Summer of Code (GSoC). GSoC is a global online program that introduces new contributors to open-source development. This year, contributors worked to expand the Kotlin ecosystem under the guidance of mentors from Google, Gradle, Microsoft, and JetBrains. Join our Slack channel [&#8230;]",
        "contentSnippet": "2024 marked another exciting year with respect to the Kotlin Foundation’s participation in Google Summer of Code (GSoC). GSoC is a global online program that introduces new contributors to open-source development. This year, contributors worked to expand the Kotlin ecosystem under the guidance of mentors from Google, Gradle, Microsoft, and JetBrains. Join our Slack channel […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=538394",
        "categories": [
          "news",
          "education",
          "gsoc",
          "internship"
        ],
        "isoDate": "2025-01-22T13:04:45.000Z"
      },
      {
        "creator": "Cheuk Ting Ho",
        "title": "Anomaly Detection in Time Series",
        "link": "https://blog.jetbrains.com/pycharm/2025/01/anomaly-detection-in-time-series/",
        "pubDate": "Wed, 22 Jan 2025 12:14:32 +0000",
        "content:encodedSnippet": "How do you identify unusual patterns in data that might reveal critical issues or hidden opportunities? Anomaly detection helps identify data that deviates significantly from the norm. Time series data, which consists of data collected over time, often includes trends and seasonal patterns. Anomalies in time series data occur when these patterns are disrupted, making anomaly detection a valuable tool in industries like sales, finance, manufacturing, and healthcare.\nAs time series data has unique characteristics like seasonality and trends, specialized methods are required to detect anomalies effectively. In this blog post, we’ll explore some popular methods for anomaly detection in time series, including STL decomposition and LSTM prediction, with detailed code examples to help you get started.\nTime series anomaly detection in businesses\nTime series data is essential to many businesses and services. Many businesses record data over time with timestamps, allowing changes to be analyzed and data to be compared over time. Time series are useful when comparing a certain quantity over a certain period, as, for example, in a year-over-year comparison where the data exhibits characteristics of seasonalities.\nSales monitoring\nOne of the most common examples of time series data with seasonalities is sales data. As a lot of sales are affected by annual holidays and the time of the year, it is hard to draw conclusions about sales data without considering the seasonalities. Because of that, a common method for analyzing and finding anomalies in sales data is STL decomposition, which we will cover in detail later in this blog post.\nFinance\nFinancial data, such as transactions and stock prices, are typical examples of time series data. In the finance industry, analyzing and detecting anomalies in this data is a common practice. For example, time series prediction models can be used in automatic trading. We’ll use a time series prediction to identify anomalies in stock data later in this blog post.\nManufacturing\nAnother use case of time series anomaly detection is monitoring defects in production lines. Machines are often monitors, making time series data available. Being able to notify management of potential failures is essential, and anomaly detection plays a key role.\nMedicine and healthcare\nIn medicine and healthcare, human vitals are monitored and anomalies can be detected. This is important enough in medical research, but it’s critical in diagnostics. If a patient at a hospital has anomalies in their vitals and is not treated immediately, the results can be fatal.\nWhy is it important to use special methods for time series anomaly detection?\nTime series data is special in the sense that it sometimes cannot be treated like other types of data. For example, when we apply a train test split to time series data, the sequentially related nature of the data means we cannot shuffle it. This is also true when applying time series data to a deep learning model. A recurrent neural network (RNN) is commonly used to take the sequential relationship into account, and training data is input as time windows, which preserve the sequence of events within.\nTime series data is also special because it often has seasonality and trends that we cannot ignore. This seasonality can manifest in a 24-hour cycle, a 7-day cycle, or a 12-month cycle, just to name a few common possibilities. Anomalies can only be determined after the seasonality and trends have been considered, as you will see in our example below. \nMethods used for anomaly detection in time series\nBecause time series data is special, there are specific methods for detecting anomalies in it. Depending on the type of data, some of the methods and algorithms we mentioned in the previous blog post about anomaly detection can be used on time series data. However, with those methods, the anomaly detection may not be as robust as using ones specifically designed for time series data. In some cases, a combination of detection methods can be used to reconfirm the detection result and avoid false positives or negatives.\nSTL decomposition\nOne of the most popular ways to use time series data that has seasonality is STL decomposition – seasonal trend decomposition using LOESS (locally estimated scatterplot smoothing). In this method, a time series is decomposed using an estimate of seasonality (with the period provided or determined using an algorithm), a trend (estimated), and the residual (the noise in the data). A Python library that provides STL decomposition tools is the statsmodels library.\n\n\n\n\nAn anomaly is detected when the residual is beyond a certain threshold. \nUsing STL decomposition on beehive data\nIn an earlier blog post, we explored anomaly detection in beehives using the OneClassSVM and IsolationForest methods. \nIn this tutorial, we’ll analyze beehive data as a time series using the STL class provided by the statsmodels library. To get started, set up your environment using this file: requirements.txt. \n1. Install the library\nSince we have only been using the model provided by Scikit-learn, we will need to install statsmodels from PyPI. This is easy to do in PyCharm. \nStart with PyCharm Pro for free\n                                                    \nGo to the Python Package window (choose the icon at the bottom of the left-hand side of the IDE) and type in statsmodels in the search box.\n\n\n\n\nYou can see all of the information about the package on the right-hand side. To install it, simply click Install package.\n2. Create a Jupyter notebook\nTo investigate the dataset further, let’s create a Jupyter notebook to take advantage of the tools that PyCharm’s Jupyter notebook environment provides.\n\n\n\n\nWe will import pandas and load the .csv file.\nimport pandas as pd\n\ndf = pd.read_csv('../data/Hive17.csv', sep=\";\")\ndf = df.dropna()\ndf\n\n\n\n\n3. Inspect the data as graphs\nNow, we can inspect the data as graphs. Here, we would like to see the temperature of hive 17 over time. Click on Chart view in the dataframe inspector and then choose T17 as the y-axis in the series settings.\n\n\n\n\nWhen expressed as a time series, the temperature has a lot of ups and downs. This indicates periodic behavior, likely due to the day-night cycle, so it is safe to assume there is a 24-hour period for the temperature. \nNext, there is a trend of temperature dropping over time. If you inspect the DateTime column, you can see that the dates range from August to November. Since the Kaggle page of the dataset indicates that the data was collected in Turkey, the transition from summer to fall explains our observation that the temperature is dropping over time.\n4. Time series decomposition\nTo understand the time series and detect anomalies, we will perform STL decomposition, importing the STL class from statsmodels and fitting it with our temperature data.\nfrom statsmodels.tsa.seasonal import STL\n\nstl = STL(df[\"T17\"], period=24, robust=True) \nresult = stl.fit()\nWe will have to provide a period for the decomposition to work. As we mentioned before, it is safe to assume a 24-hour cycle.\nAccording to the documentation, STL decomposes a time series into three components: trend, seasonal, and residual. To get a clearer look at the decomposed result, we can use the built-in plot method:\nresult.plot()\n\n\n\n\nYou can see the Trend and Season plots seem to align with our assumptions above. However, we are interested in the residual plot at the bottom, which is the original series without the trend and seasonal changes. Any extremely high or low value in the residual indicates an anomaly.\n5. Anomaly threshold\nNext, we would like to determine what values of the residual we’ll consider abnormal. To do that, we can look at the residual’s histogram.\nresult.resid.plot.hist()\n\n\n\n\nThis can be considered a normal distribution around 0, with a long tail above 5 and below -5, so we’ll set the threshold to 5.\nTo show the anomalies on the original time series, we can color all of them red in the graph like this:\nimport matplotlib.pyplot as plt\n\nthreshold = 5\nanomalies_filter = result.resid.apply(lambda x: True if abs(x) > threshold else False)\nanomalies = df[\"T17\"][anomalies_filter]\n\nplt.figure(figsize=(14, 8))\nplt.scatter(x=anomalies.index, y=anomalies, color=\"red\", label=\"anomalies\")\nplt.plot(df.index, df['T17'], color='blue')\nplt.title('Temperatures in Hive 17')\nplt.xlabel('Hours')\nplt.ylabel('Temperature')\nplt.legend()\nplt.show()\n\n\n\n\nWithout STL decomposition, it is very hard to identify these anomalies in a time series consisting of periods and trends.\nLSTM prediction\nAnother way to detect anomalies in time series data is to do a time series prediction on the series using deep learning methods to estimate the outcome of data points. If an estimate is very different from the actual data point, then it could be a sign of anomalous data.\nOne of the popular deep learning algorithms to perform the prediction of sequential data is the Long short-term memory (LSTM) model, which is a type of recurrent neural network (RNN). The LSTM model has input, forget, and output gates, which are number matrices. This ensures important information is passed on in the next iteration of the data.\n\n\n\n\nSince time series data is sequential data, meaning the order of data points is in sequential order and should not be shuffled, the LSTM model is an effective deep learning model to predict the outcome at a certain time. This prediction can be compared to the actual data and a threshold can be set to determine if the actual data is an anomaly.\nUsing LSTM prediction on stock prices\nNow let’s start a new Jupyter project to detect any anomalies in Apple’s stock price over the past 5 years. The stock price dataset shows the most up-to-date data. If you want to follow along with the blog post, you can download the dataset we are using.\n1. Start a Jupyter project\nWhen starting a new project, you can choose to create a Jupyter one, which is optimized for data science. In the New Project window, you can create a Git repository and determine which conda installation to use for managing your environment.\n\n\n\n\nAfter starting the project, you will see an example notebook. Go ahead and start a new Jupyter notebook for this exercise.\n\n\n\n\nAfter that, let’s set up requirements.txt. We will need pandas, matplotlib, and PyTorch, which is named torch on PyPI. Since PyTorch is not included in the conda environment, PyCharm will tell us that we are missing the package. To install the package, click on the lightbulb and select Install all missing packages.\n\n\n\n\n2. Loading and inspecting the data\nNext, let’s put our dataset apple_stock_5y.csv in the data folder and load it as a pandas DataFrame to inspect it.\nimport pandas as pd\n \ndf = pd.read_csv('data/apple_stock_5y.csv')\ndf\nWith the interactive table, we can easily see if any data is missing.\n\n\n\n\nThere is no missing data, but we have one issue – we would like to use the Close/Last price but it is not a numeric data type. Let’s do a conversion and inspect our data again:\ndf[\"Close/Last\"] = df[\"Close/Last\"].apply(lambda x: float(x[1:]))\ndf\nNow, we can inspect the price with the interactive table. Click on the plot icon on the left and a plot will be created. By default, it uses Date as the x-axis and Volume as the y-axis. Since we would like to inspect the Close/Last price, go to the settings by clicking the gear icon on the right and choose Close/Last as the y-axis.\n\n\n\n\n3. Preparing the training data for LSTM\nNext, we have to prepare the training data to be used in the LSTM model. We need to prepare a sequence of vectors (feature X), each representing a time window, to predict the next price. The next price will form another sequence (target y). Here we can choose how big this time window is with the lookback variable. The following code creates sequences X and y which will then be converted to PyTorch tensors:\nimport torch\n\nlookback = 5\ntimeseries = df[[\"Close/Last\"]].values.astype('float32')\n\nX, y = [], []\nfor i in range(len(timeseries)-lookback):\n    feature = timeseries[i:i+lookback]\n    target = timeseries[i+1:i+lookback+1]\n    X.append(feature)\n    y.append(target)\n    \nX = torch.tensor(X)\ny = torch.tensor(y)\n\nprint(X.shape, y.shape)\nGenerally speaking, the bigger the window, the bigger our model will be, since the input vector is bigger. However, with a bigger window, the sequence of inputs will be shorter, so determining this lookback window is a balancing act. We will start with 5, but feel free to try different values to see the differences.\n4. Build and train the model\nWe can build the model by creating a class using the nn module in PyTorch before we train it. The nn module provides building blocks, such as different neural network layers. In this exercise, we will build a simple LSTM layer followed by a linear layer:\nimport torch.nn as nn\n\nclass StockModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.lstm = nn.LSTM(input_size=1, hidden_size=50, num_layers=1, batch_first=True)\n        self.linear = nn.Linear(50, 1)\n    def forward(self, x):\n        x, _ = self.lstm(x)\n        x = self.linear(x)\n        return x\nNext, we will train our model. Before training it, we will need to create an optimizer, a loss function used to calculate the loss between the predicted and actual y values, and a data loader to feed in our training data:\nimport numpy as np\nimport torch.optim as optim\nimport torch.utils.data as data\n\nmodel = StockModel()\noptimizer = optim.Adam(model.parameters())\nloss_fn = nn.MSELoss()\nloader = data.DataLoader(data.TensorDataset(X, y), shuffle=True, batch_size=8)\nThe data loader can shuffle the input, as we have already created the time windows. This preserves the sequential relationship in each window.\nTraining is done using a for loop which loops over each epoch. For every 100 epochs, we will print out the loss and observe while the model converges:\nn_epochs = 1000\nfor epoch in range(n_epochs):\n    model.train()\n    for X_batch, y_batch in loader:\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    if epoch % 100 != 0:\n        continue\n    model.eval()\n    with torch.no_grad():\n        y_pred = model(X)\n        rmse = np.sqrt(loss_fn(y_pred, y))\n    print(f\"Epoch {epoch}: RMSE {rmse:.4f}\")\nWe start at 1000 epochs, but the model converges quite quickly. Feel free to try other numbers of epochs for training to achieve the best result.\n\n\n\n\nIn PyCharm, a cell that requires some time to execute will provide a notification about how much time remains and a shortcut to the cell. This is very handy when training machine learning models, especially deep learning models, in Jupyter notebooks.\n5. Plot the prediction and find the errors\nNext, we will create the prediction and plot it together with the actual time series. Note that we will have to create a 2D np series to match with the actual time series. The actual time series will be in blue while the predicted time series will be in red.\nimport matplotlib.pyplot as plt\n\nwith torch.no_grad():\n    pred_series = np.ones_like(timeseries) * np.nan\n    pred_series[lookback:] = model(X)[:, -1, :]\n\nplt.plot(timeseries, c='b')\nplt.plot(pred_series, c='r')\nplt.show()\n\n\n\n\nIf you observe carefully, you will see that the prediction and the actual values do not align perfectly. However, most of the predictions do a good job.\nTo inspect the errors closely, we can create an error series and use the interactive table to observe them. We are using the absolute error this time.\nerror = abs(timeseries-pred_series)\nerror\nUse the settings to create a histogram with the value of the absolute error as the x-axis and the count of the value as the y-axis.\n\n\n\n\n6. Decide on the anomaly threshold and visualize\nMost of the points will have an absolute error of less than 6, so we can set that as the anomaly threshold. Similar to what we did for the beehive anomalies, we can plot the anomalous data points in the graph.\nthreshold = 6\nerror_series = pd.Series(error.flatten())\nprice_series = pd.Series(timeseries.flatten())\n\nanomalies_filter = error_series.apply(lambda x: True if x > threshold else False)\nanomalies = price_series[anomalies_filter]\n\nplt.figure(figsize=(14, 8))\nplt.scatter(x=anomalies.index, y=anomalies, color=\"red\", label=\"anomalies\")\nplt.plot(df.index, timeseries, color='blue')\nplt.title('Closing price')\nplt.xlabel('Days')\nplt.ylabel('Price')\nplt.legend()\nplt.show()\n\n\n\n\nSummary\nTime series data is a common form of data used in many applications including business and scientific research. Due to the sequential nature of time series data, special methods and algorithms are used to help determine anomalies in it. In this blog post, we demonstrated how to identify anomalies using STL decomposition to eliminate seasonalities and trends. We have also demonstrated how to use deep learning and the LSTM model to compare the predicted estimate and the actual data in order to determine anomalies.\nDetect anomalies using PyCharm\nWith the Jupyter project in PyCharm Professional, you can organize your anomaly detection project with a lot of data files and notebooks easily. Graphs output can be generated to inspect anomalies and plots are very accessible in PyCharm. Other features, such as auto-complete suggestions, make navigating all the Scikit-learn models and Matplotlib plot settings a blast.\nPower up your data science projects by using PyCharm, and check out the data science features offered to streamline your data science workflow.\nStart with PyCharm Pro for free",
        "dc:creator": "Cheuk Ting Ho",
        "content": "How do you identify unusual patterns in data that might reveal critical issues or hidden opportunities? Anomaly detection helps identify data that deviates significantly from the norm. Time series data, which consists of data collected over time, often includes trends and seasonal patterns. Anomalies in time series data occur when these patterns are disrupted, making [&#8230;]",
        "contentSnippet": "How do you identify unusual patterns in data that might reveal critical issues or hidden opportunities? Anomaly detection helps identify data that deviates significantly from the norm. Time series data, which consists of data collected over time, often includes trends and seasonal patterns. Anomalies in time series data occur when these patterns are disrupted, making […]",
        "guid": "https://blog.jetbrains.com/?post_type=pycharm&p=539241",
        "categories": [
          "data-science",
          "how-tos",
          "anomaly-detection"
        ],
        "isoDate": "2025-01-22T12:14:32.000Z"
      },
      {
        "creator": "Elena Kerpeleva",
        "title": "Introducing  Perpetual Licenses on JetBrains Marketplace",
        "link": "https://blog.jetbrains.com/platform/2025/01/introducing-perpetual-licenses-on-jetbrains-marketplace/",
        "pubDate": "Tue, 21 Jan 2025 18:11:47 +0000",
        "content:encodedSnippet": "JetBrains Marketplace provides various licensing models for paid plugins to suit different user preferences. Now, we are introducing a new option that may change how your users purchase your plugins – perpetual licensing.\nLicensing options on JetBrains Marketplace\nThe current licensing schemes available on JetBrains Marketplace include:\nAnnual/monthly subscription without a fallback license: Users can access your plugin only with an active subscription. This model is ideal for ensuring continuous revenue as users need to maintain their subscriptions to keep using the plugin.\nAnnual/monthly subscription with a fallback license: Users receive lifetime access to a specific version of your plugin. Updates and new features are only available with an active subscription. This model strikes a balance between providing long-term value to users and encouraging them to renew their subscriptions.\nThe licensing type (with or without fallback) and billing period (annual/monthly) can be selected under the Sales tab, in the Sales Info section of the plugin page.\nIn addition to the options described above, we are now introducing a perpetual license option. This new license type allows users to make a one-time payment for lifetime access to your plugin, including all future updates. It can be an appealing choice for users who prefer a single upfront payment rather than recurring charges.\n\n\n\n\nHow to implement perpetual licenses\nNow that you can opt for perpetual licensing for your new plugin, the perpetual license will be available as an option when you publish a new plugin on JetBrains Marketplace. \nAlternatively, if you prefer to switch your existing plugin to a perpetual licensing model, you can do so by contacting the JetBrains Marketplace team at marketplace@jetbrains.com. In this scenario, all current customers will automatically receive the perpetual license for free, while new customers will need to purchase it.\nNote that a plugin can currently have only one paid license option: either recurring or perpetual.\nChoosing the best licensing model for your plugin\nThe introduction of the perpetual license gives you more flexibility in how you monetize your plugin. However, it’s essential to consider the implications carefully.\nRevenue stability: While a one-time payment model may attract more users initially, it can lead to less predictable revenue in the long run compared to a subscription model.\nUser satisfaction: Perpetual licenses can increase customer satisfaction, as users appreciate the simplicity and long-term value of a single payment.\nIf you have any questions or need guidance on transitioning to the perpetual license model, feel free to reach out to the Marketplace Support team at marketplace@jetbrains.com.",
        "dc:creator": "Elena Kerpeleva",
        "content": "JetBrains Marketplace provides various licensing models for paid plugins to suit different user preferences. Now, we are introducing a new option that may change how your users purchase your plugins – perpetual licensing. Licensing options on JetBrains Marketplace The current licensing schemes available on JetBrains Marketplace include: The licensing type (with or without fallback) and [&#8230;]",
        "contentSnippet": "JetBrains Marketplace provides various licensing models for paid plugins to suit different user preferences. Now, we are introducing a new option that may change how your users purchase your plugins – perpetual licensing. Licensing options on JetBrains Marketplace The current licensing schemes available on JetBrains Marketplace include: The licensing type (with or without fallback) and […]",
        "guid": "https://blog.jetbrains.com/?post_type=platform&p=538720",
        "categories": [
          "marketplace",
          "plugin-development"
        ],
        "isoDate": "2025-01-21T18:11:47.000Z"
      },
      {
        "creator": "Vaclav Pech",
        "title": "MPS 2024.3 Is Out!",
        "link": "https://blog.jetbrains.com/mps/2025/01/mps-2024-3-is-out/",
        "pubDate": "Tue, 21 Jan 2025 17:01:08 +0000",
        "content:encodedSnippet": "In this release, you’ll find improvements to the UI, reworked internals for various components, and a binary-enabled textgen. MPS 2024.3 also brings enhanced support for icons, an applicability condition for quick-fixes, and numerous platform updates.\nDOWNLOAD MPS 2024.3\nWhat’s new\nLet’s check out the new features we’ve prepared for you in this release.\nTop-level folder for transient and checkpoint models\nThe ProjectView tool now provides three top-level folders to keep the structure of the project better organized:\nProject Name\nModules Pool\nCheckpoints and Transient Models\nThe Checkpoints and Transient Models folder is always displayed below the Modules Pool, and is empty unless any transient or checkpoint models are available. These models are displayed under this folder, and not at the top level as they used to be.\nCheckpoints and Transient Models folder allows the ProjectView to remember the expanded and collapsed subtrees of the project structure across MPS restarts.\n\nEnable preview tag option\nThe following options to enable/disable the Preview Tab provided by the IntelliJ Platform are now respected by MPS and guarantee the same behavior of the editor as in other JetBrains tools:\nSettings | Editor | General | Editor Tabs | Opening Policy | Enable preview tab\nLogical View | Behavior | Enable Preview Tab\n\nApplicability condition for a quick-fix\nA new section named applicable has been added to Quick-Fix definitions to let you control the applicability of a quick-fix. The default value <always> guarantees unrestricted applicability.\n\nIcon handling\nIcons and images that use a path relative to the module are no longer copied during generation next to the places of their individual usage. Instead, they are copied to the distribution module once as image files and are available for use at this single location. This has two immediate benefits: avoiding the duplication of image files to save disk space and the ability to access the images both from the distribution and from the source module.\nConstant icons\nIn addition to the existing TextIcon and FileIcon concepts, a new ConstantFieldIcon concept is now available. It allows an icon to be specified by reference to a concrete static field declaration holding an instance of javax.swing.Icon.\n\nTextGen binary outcome\nInspired by the need for better handling of icon files, we’ve added a new mechanism to produce binary output during the TextGen process, instead of text. The new API consists of a write operation that directly manipulates data as instances of byte[].\nTool windows migrated away from ProjectComponent\nAll tool windows, such as Inspector, HierarchyView, and Usages, have been reworked to no longer follow the long-deprecated mechanism of the IntelliJ Platform’s project components (ProjectComponent). The changes to the API have been minimal, but for some tool windows, there is a change in how they are obtained from code:\nThe Project.getComponent() method no longer returns any of the tool windows.\nTools that are implemented as an MPS tool concept can be obtained using com.intellij.openapi.project.Project.tool<ToolConcept>.\nTools that are frequently used from Java provide a static getInstance() method:\n\nUsagesViewTool.getInstance()\nInspectorTool.getInstance()\nThe Inspector tool is traditionally also available from EditorContext.inspectorTool().\nIntelliJ Platform components and services\nIn addition to tool windows, most of the MPS core functionality has been reworked not to use IntelliJ IDEA’s ApplicationComponent and ProjectComponent.\nMPS used to rely heavily on the IntelliJ Platform facilities to compose the complete application. Now, most of the legacy components have been refactored to use contemporary MPS or IntelliJ IDEA APIs (like IntelliJ IDEA’s application/project services and extension points, MPS’ CoreComponents and extensions, etc.). There are still a few components left, which the MPS team plans to get rid of completely in the next release.\nMost users probably won’t notice any difference, with the exception of reduced startup times.\nPlease consult the Migration Guide if your code fails to locate any of the platform components because it uses an obsolete retrieval mechanism.\nSwitched to the new UI\nMPS now uses the new UI. The old version of the UI can be enabled by installing the Classic UI plugin.\nMore new features…\nCheck out the What’s New page to learn all about the new features.\nYou can find a full list of fixed issues here.\nYour JetBrains MPS team",
        "dc:creator": "Vaclav Pech",
        "content": "In this release, you’ll find improvements to the UI, reworked internals for various components, and a binary-enabled textgen. MPS 2024.3 also brings enhanced support for icons, an applicability condition for quick-fixes, and numerous platform updates. DOWNLOAD MPS 2024.3 What’s new Let’s check out the new features we’ve prepared for you in this release. Top-level folder [&#8230;]",
        "contentSnippet": "In this release, you’ll find improvements to the UI, reworked internals for various components, and a binary-enabled textgen. MPS 2024.3 also brings enhanced support for icons, an applicability condition for quick-fixes, and numerous platform updates. DOWNLOAD MPS 2024.3 What’s new Let’s check out the new features we’ve prepared for you in this release. Top-level folder […]",
        "guid": "https://blog.jetbrains.com/?post_type=mps&p=533562",
        "categories": [
          "releases",
          "release"
        ],
        "isoDate": "2025-01-21T17:01:08.000Z"
      },
      {
        "creator": "Irina Mariasova",
        "title": "Maximize Code Security in JetBrains IDEs and Qodana With Mend.io",
        "link": "https://blog.jetbrains.com/idea/2025/01/maximize-code-security-in-jetbrains-ides-and-qodana-with-mend-io/",
        "pubDate": "Tue, 21 Jan 2025 09:35:46 +0000",
        "content:encodedSnippet": "JetBrains has partnered with Mend.io, a trusted name in application security. This collaboration will help us continue providing the tools you need to develop secure applications with ease and confidence in our IDEs and Qodana. For the best user experience, make sure to use the latest stable version 2024.3.2. \nWhy Mend?\nTrusted by industry giants like Google and Comcast, Mend.io offers a reliable application security platform. It helps organizations build mature AppSec programs, shifting from reactive vulnerability management to proactive risk mitigation. With Mend’s expertise, our users gain access to a robust solution that simplifies security and boosts code quality.\nWhat’s new?\nOur Package Checker plugin has long been a reliable tool for identifying vulnerabilities in third-party dependencies and suggesting safe updates. By switching to Mend.io as our software composition analysis (SCA) provider, we’re ensuring that these capabilities remain effective and up to date.\nMalicious package detection\nThanks to this partnership, you can now identify malicious packages – those specifically designed to harm systems. Mend strongly advises removing such packages immediately to protect your code and systems.\nPowered by Mend.io, the Malicious Dependency inspection helps you:\nDetect harmful npm and PyPI packages.\n\n\n\n\n\nPrevent commits with malicious dependencies, protecting your repositories.\n\n\n\n\nMalicious package detection is also available in Qodana.\n\n\n\n\nVulnerability detection \nThe popular Vulnerable Path functionality, which helps pinpoint the exact source of a vulnerability, will return with the upcoming 2025.1 version of JetBrains IDEs, giving you added precision when managing your code dependencies. \nBasic functionality remains \nThe bundled Package Checker plugin will continue to provide a reliable way to keep your code secure with the help of the following basic features:\nDependency scanning. Helps identify vulnerabilities and threats in third-party dependencies.\nSafe updates. Suggests secure versions of dependencies, allowing you to fix vulnerabilities easily.\nSmooth IDE integration. Highlights issues directly in the editor and provides details in the Problems | Vulnerable Dependencies tab or via Analyze | Vulnerable Dependencies.\n\n\n\n\nLooking ahead\nThis update brings incremental, yet valuable, improvements to the security features in JetBrains IDEs and Qodana. We’re committed to enhancing these capabilities further and providing you with the tools needed to build secure applications.\nBe sure to update your tools and try the new features once they are available!",
        "dc:creator": "Irina Mariasova",
        "content": "JetBrains has partnered with Mend.io, a trusted name in application security. This collaboration will help us continue providing the tools you need to develop secure applications with ease and confidence in our IDEs and Qodana. For the best user experience, make sure to use the latest stable version 2024.3.2. Why Mend? Trusted by industry giants [&#8230;]",
        "contentSnippet": "JetBrains has partnered with Mend.io, a trusted name in application security. This collaboration will help us continue providing the tools you need to develop secure applications with ease and confidence in our IDEs and Qodana. For the best user experience, make sure to use the latest stable version 2024.3.2. Why Mend? Trusted by industry giants […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=538928",
        "categories": [
          "news",
          "intellij-idea",
          "news-company",
          "package-checker",
          "security"
        ],
        "isoDate": "2025-01-21T09:35:46.000Z"
      },
      {
        "creator": "Olga Bedrina",
        "title": "TeamCity 2024.12.1 Bug Fix Is Now Available",
        "link": "https://blog.jetbrains.com/teamcity/2025/01/teamcity-2024-12-1-bug-fix/",
        "pubDate": "Mon, 20 Jan 2025 12:49:48 +0000",
        "content:encodedSnippet": "We’re excited to announce the release of TeamCity On-Premises 2024.12.1, a bug fix update that resolves over 80 issues reported by users. This version includes crucial fixes across multiple areas, ensuring enhanced performance, stability, and security for your CI/CD pipelines.\nSome highlights of this release include:\nResolved truncated build tags, addressing an issue that impacted tag visibility.\nEnhanced VCS checkout, ensuring revision computation considers all VCS root variations.\nFixed possible agent hang-ups during artifact publishing.\nSupport for MySQL 8.4 by adding allowPublicKeyRetrieval to the database connection URL (TW-91529).\nFixed SSH agent build feature issues on Windows (TW-85769).\nWe recommend upgrading to apply the latest improvements and security fixes to your TeamCity server.\nWhy update?\nStaying up to date with minor releases ensures your TeamCity instance benefits from:\nPerformance improvements.\nBetter compatibility with integrations.\nFaster, more stable builds.\nEnhanced security for your workflows.\nCompatibility\nTeamCity 2024.12.1 shares the same data format as all 2024.12.x releases. You can upgrade or downgrade within this series without the need for backup and restoration.\nHow to upgrade\nUse the automatic update feature in your current TeamCity version.\nDownload the latest version directly from the JetBrains website.\nPull the updated TeamCity Docker image.\nNeed help?\nThank you for reporting issues and providing feedback! If you have questions or run into any problems, please let us know via the TeamCity Forum or Issue Tracker.\nHappy building!",
        "dc:creator": "Olga Bedrina",
        "content": "We’re excited to announce the release of TeamCity On-Premises 2024.12.1, a bug fix update that resolves over 80 issues reported by users. This version includes crucial fixes across multiple areas, ensuring enhanced performance, stability, and security for your CI/CD pipelines. Some highlights of this release include: We recommend upgrading to apply the latest improvements and [&#8230;]",
        "contentSnippet": "We’re excited to announce the release of TeamCity On-Premises 2024.12.1, a bug fix update that resolves over 80 issues reported by users. This version includes crucial fixes across multiple areas, ensuring enhanced performance, stability, and security for your CI/CD pipelines. Some highlights of this release include: We recommend upgrading to apply the latest improvements and […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=539240",
        "categories": [
          "bug-fix"
        ],
        "isoDate": "2025-01-20T12:49:48.000Z"
      },
      {
        "creator": "Olga Bedrina",
        "title": "TeamCity 2024.12.1 Bug Fix Is Now Available",
        "link": "https://blog.jetbrains.com/teamcity/2025/01/teamcity-2024-12-1-bug-fix/",
        "pubDate": "Mon, 20 Jan 2025 12:39:45 +0000",
        "content:encodedSnippet": "We’re excited to announce the release of TeamCity On-Premises 2024.12.1, a bug fix update that resolves over 80 issues reported by users. This version includes crucial fixes across multiple areas, ensuring enhanced performance, stability, and security for your CI/CD pipelines.\nSome highlights of this release include:\nResolved truncated build tags, addressing an issue that impacted tag visibility.\nEnhanced VCS checkout, ensuring revision computation considers all VCS root variations.\nFixed possible agent hang-ups during artifact publishing.\nSupport for MySQL 8.4 by adding allowPublicKeyRetrieval to the database connection URL (TW-91529).\nFixed SSH agent build feature issues on Windows (TW-85769).\nWe recommend upgrading to apply the latest improvements and security fixes to your TeamCity server.\nWhy update?\nStaying up to date with minor releases ensures your TeamCity instance benefits from:\nPerformance improvements.\nBetter compatibility with integrations.\nFaster, more stable builds.\nEnhanced security for your workflows.\nCompatibility\nTeamCity 2024.12.1 shares the same data format as all 2024.12.x releases. You can upgrade or downgrade within this series without the need for backup and restoration.\nHow to upgrade\nUse the automatic update feature in your current TeamCity version.\nDownload the latest version directly from the JetBrains website.\nPull the updated TeamCity Docker image.\nNeed help?\nThank you for reporting issues and providing feedback! If you have questions or run into any problems, please let us know via the TeamCity Forum or Issue Tracker.\nHappy building!",
        "dc:creator": "Olga Bedrina",
        "content": "We’re excited to announce the release of TeamCity On-Premises 2024.12.1, a bug fix update that resolves over 80 issues reported by users. This version includes crucial fixes across multiple areas, ensuring enhanced performance, stability, and security for your CI/CD pipelines. Some highlights of this release include: We recommend upgrading to apply the latest improvements and [&#8230;]",
        "contentSnippet": "We’re excited to announce the release of TeamCity On-Premises 2024.12.1, a bug fix update that resolves over 80 issues reported by users. This version includes crucial fixes across multiple areas, ensuring enhanced performance, stability, and security for your CI/CD pipelines. Some highlights of this release include: We recommend upgrading to apply the latest improvements and […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=539197",
        "categories": [
          "bug-fix"
        ],
        "isoDate": "2025-01-20T12:39:45.000Z"
      },
      {
        "creator": "Kerry Beetge",
        "title": "Fixing Unreal Engine Project Issues With Qodana",
        "link": "https://blog.jetbrains.com/qodana/2025/01/unreal-engine-project-qodana/",
        "pubDate": "Mon, 20 Jan 2025 11:00:47 +0000",
        "content:encodedSnippet": "If you saw our blog post about using Qodana in Unity and .NET projects, you know that we’ve been striving to explore Qodana’s potential for game development. What’s our next stop on this mission? Seeing our code quality platform in action with Unreal Engine, one of the most popular engines for different types of projects – from virtual reality prototypes to triple-A games. \nIn this post, we’ll demonstrate how we used our static analysis tool Qodana on Lyra Starter Game, a widely known sample project from Epic Games. We chose this project for its large codebase, which provides a wider range of potential issues to identify, analyze, and fix. \nThe analysis and the resolution of issues were carried out by a junior developer. Our goal was to check how someone still building their game development knowledge can use Qodana to improve code and product quality. \nTable of Contents\n\nRunning Qodana from the IDE\nSetting up the CI/CD pipeline\nFixing problems\nQodana’s Unreal Engine analysis summarized\nSwitch to Qodana for code analysis and get 25% off\n\nRunning Qodana from the IDE\nWe started by running Qodana from an IDE (Rider) to see the initial results and set up filtering. As Qodana is integrated with the most popular JetBrains IDEs, it can be easily launched directly from the Tools menu. For a better team experience, we also recommend using the JetBrains CI/CD solution, TeamCity. After setting up we will switch that on as well to set up a seamless process and quality gate.\n Running Qodana in the IDE\n\n\n\nYou can run Qodana in your IDE without a token, but we wanted our results to be accessible from Qodana Cloud, a cloud-based tool for Qodana reports. To upload a report to the cloud, you need a license token, which you can get from the Qodana Cloud project. We will also use the token to integrate our analysis into the CI/CD pipeline.\nThe qodana.yaml file is created automatically and shown in the popup below. \nThe qodana.yaml popup\n\n\n\nYou can modify this file directly in the popup window if you need to, and you can run inspections with the qodana.starter profile to check if there are any critical errors. Once you run it, the file will be saved in the project root. We wanted to use a custom profile, so we modified this file to reference the custom profile.yaml.\nIn the qodana.yaml file, we left a link to the profile. QDNET is a linter based on the Rider distribution and designed to work with Unreal Engine projects.\nversion: \"1.0\"\n\n#Specify IDE code to run analysis without container (Applied in CI/CD pipeline)\nide: QDNET\n\n#Specify inspection profile for code analysis\nprofile:\n  path: profile.yaml\nqodana.yaml\nIn the profile.yaml file, we changed the profile to the more extensive qodana.recommended and identified scope to be excluded from the analysis. We wanted to analyze only the project codebase, without Unreal Engine or plugin sources.\nbaseProfile: \"qodana.recommended\"\nname: \"UnrealEngine\"\n\ninspections:\n  - group: ALL\n    ignore:\n      - \"scope#!file:Source/LyraGame//*\"\nprofile.yaml\nThese changes provided a relatively comprehensive analysis report.\n\n We then linked our project to Qodana Cloud. \n Linking the project to Qodana Cloud\n\n\n\nThis will allow us to access future reports withinin the IDE and view problems locally.\nThe report in the IDE\n\n\n\nSetting up the CI/CD pipeline\nWe already had a CI/CD pipeline in TeamCity, which we used to build the project every time we pushed changes to the main branch. There are several ways to complete the build. One such method is with the Unreal Engine plugin for TeamCity which can be downloaded from JetBrains Marketplace. You don’t have to run the build before running Qodana, but it is convenient to put it in the same pipeline. This allows TeamCity to mark the build as Failed if Qodana finds any issues.\nTo run the Qodana analysis, we added a PowerShell step that loaded and ran our Qodana CLI tool. We opted for the latest AMD64-compatible version and assets for our agents. If you are working with a different operating system and architecture, you will have to choose the assets designed for them. \nBefore implementing this in any project, you should discuss the security implications with the people responsible for this in your organization. Downloading a third-party binary without checking its integrity and checksum can be risky. You may need to save a fixed version of the binary yourself or verify the checksum of the downloaded distribution. \nInvoke-WebRequest -Uri \"https://github.com/JetBrains/qodana-cli/releases/download/%VERSION%/qodana_windows_x86_64.exe\" -OutFile \"qodana_windows_x86_64.exe\" \n\n./qodana_windows_x86_64.exe scan --ide QDNET\nPowerShell build step\nThe linter requires a Qodana token, a value from the project page on Qodana Cloud. To pass the token through the pipeline, we added the QODANA_TOKEN environment variable with the Password value type to ensure the token remains secure.\nThen, in the same way, we added the desired version of Qodana CLI as a configuration parameter.\n\n\n\n\nFixing problems\nFor this Unreal Engine project, we were particularly interested in issues specific to projects created with the game engine. We used filters on Qodana Сloud to show only these problems.\nUnreal Engine problems\n\n\n\nQodana’s sunburst diagram provides a convenient visualization of the detected issues, as well as an easy way to navigate to them. In our case, we could see there were seven types of problems, some of which could be resolved using context actions:\nBlueprintCallable function can be made const\nBlueprintCallable function can be made static\nUse of a class that has not been declared previously\nTo quickly navigate to these issues in the IDE, we can click on the Open file in Rider button.\nPlease note: to get this functionality to work you have to install JetBrains Toolbox on your computer. \nExample of a problem in Qodana Cloud\n\n\n\nAfter opening the file in the IDE, we resolved this problem using the relevant quick-fix with a context action.\nExample of a problem in the IDE\n\n\n\nYou can also navigate by opening a report locally in the IDE and going through the list of problems grouped there by type, fixing them one by one. As you fix problems in the IDE, the number of issues detected will decrease.\n\n\n\n\nWe decided not to fix problems like BlueprintCallable function is never used in Blueprint or C++ code, as the Lyra project is considered learning material, and it’s actively maintained. The project contains methods that are not currently being used but may be in the future. \nAdditionally, we decided not to fix inconsistent Unreal Engine naming problems because the project uses a different naming convention, where upper case is used for all abbreviations.\nExample of a naming problem in the IDE\n\n\n\nTo deactivate these inspections, we added their inspection IDs to profile.yaml and set the enabled property to false, ensuring these types of problems will no longer be shown in reports. The problem ID can be found in the qodana.sarif.json file.\nNext, we moved to C++ problems. We decided to only fix the problems that were categorized as higher than moderate severity, as most low-level issues could be fixed with quick-fixes. We excluded the non-critical issues by changing the profile.yaml file.\nbaseProfile: \"qodana.recommended\"\nname: \"UnrealEngine\"\n\ninspections:\n - group: ALL\n   ignore:\n     - \"scope#!file:Source/LyraGame//*\"\n - group: \"severity:TYPO\"\n   enabled: false\n - inspection: \"CppUE4CodingStandardNamingViolationWarning\"\n   enabled: false\n - inspection: \"CppUEBlueprintCallableFunctionUnused\"\n   enabled: false\nprofile.yaml\nThis produced a report with less than a thousand problems. To experiment with different filtering strategies, we used separate branches for each YAML file. This allowed us to divide the problems into groups based on type, tackling each type in a separate branch with different settings and then merging the branches.\nLow-severity C++ problems excluded\n\n\n\nEven without the low-level results, we saw many types of problems that were not in the Unreal Engine category. \nIn total, our team fixed 822 of 937 problems from the categories we examined next.\nAs you can see below, the most common problems fell into the Common Practices and Code Improvements category and included issues like variables that could be made const or static. We resolved most of them with quick-fixes. We left problems like Function is not implemented, as they could be fixed in future development. We decided not to fix some of the problems, as the changes required to mitigate them would make the project uncompilable and in need of further refactoring.\nProblems classified as Common Practices and Code Improvements\n\n\n\nAs a result, we were left with only 26 problems in the Common Practices and Code Improvements category, which we could deal with later. \nRemaining problems classified as Common Practices and Code Improvements\n\n\n\nUp next were potential code quality issues. From this category, we fixed problems where we needed to remove unused declarators or directives. We then moved to redundancies in code, most of which were resolved easily with a quick-fix. We did not address any problems where developers left comments with their plans or TODOs because we assumed that these problems would be fixed with future changes.\nExample of a TODO\n\n\n\nLast but not least, the Syntax Style category contained only two types of problems, both of which concerned the use of virtual and override specifiers when overriding functions. We fixed all of them by adding the missing specifiers.\nSyntax Style problems\n\n\n\nWe were left with 123 unresolved problems, either due to ongoing development or the lack of a feasible solution. We moved these issues to the baseline. To apply the baseline, we downloaded the baseline file and stored it in the repository.\nSelecting problems\n\n\n\nDownloading the baseline file\n\n\n\nThen, by adding the –baseline parameter and path to the file, we adjusted the pipeline to include the baseline in future analyses.\nInvoke-WebRequest -Uri \"https://github.com/JetBrains/qodana-cli/releases/download/%VERSION%/qodana_windows_x86_64.exe\" -OutFile \"qodana_windows_x86_64.exe\" \n./qodana_windows_x86_64.exe scan --ide QDNET --baseline qodana.sarif.json\nPowerShell build step\nAnd finally, we had a flawless report.\n\n\n\n\nIf our team decided to continue working on this project, we could fix new problems as they appeared or we could focus on eliminating problems from the baseline, depending on our priorities.\nWe set up a quality gate to enforce the standards we had achieved with these efforts, and we added a several failureConditions section to qodana.yaml to configure additional quality gates for the total number of problems, as well as the numbers of critical and high-severity issues. Going forward, if any of these limits are exceeded, the build will fail.\nfailureConditions:\n  severityThresholds:\n    any: 10 # Total problems\n    critical: 0 # Critical and other severities\n    high: 5\n\n\n\n\nAdded qodana.yaml configuration\nWe also adjusted the execution of qodana-cli to consider exit code, failing the build if the result fails the quality gates. By failing builds that don’t meet our quality criteria, we can identify and address issues immediately.\nInvoke-WebRequest -Uri \"https://github.com/JetBrains/qodana-cli/releases/download/%VERSION%/qodana_windows_x86_64.exe\" -OutFile \"qodana_windows_x86_64.exe\" \n./qodana_windows_x86_64.exe scan --ide QDNET \n\n# Capture the exit code of the command\n$exitCode = $LASTEXITCODE\n\n# Print the exit code\nWrite-Output \"Exit code: $exitCode\"\n\n# Exit the script with the same exit code\nexit $exitCode\nPowerShell build step\nA failed build in TeamCity\n\n\n\nQodana’s Unreal Engine analysis summarized\nWe successfully analyzed the Lyra project, got a detailed report, and fixed more than 800 problems. While conducting professional reviews will likely require a deeper understanding of Unreal Engine, Qodana’s analysis still helped a single junior developer clean up the code and make it more concise. \nFor large-scale projects like Lyra, Qodana can effectively highlight and prioritize critical code issues that may be overlooked in manual reviews.\nSince Lyra is a private repo, we can’t share the outcome, but we hope we’ve shown you how this process could work for your team and what kind of results it can deliver.\nIf you’d like more information, visit our website, view Qodana’s features, or try it in your next game development project. \nSwitch to Qodana for code analysis and get 25% off\nQodana gets better with every release and provides a cost-effective way for teams to build confidence in code quality. \nWith this in mind, we’re offering you 25% off your first year of Qodana if you switch from a comparable commercial solution. Click on the button below to speak to our team. \nSwitch To Qodana\nThank you to Software Developer Ekaterina Trukhan for her contribution to this analysis.",
        "dc:creator": "Kerry Beetge",
        "content": "If you saw our blog post about using Qodana in Unity and .NET projects, you know that we’ve been striving to explore Qodana’s potential for game development. What’s our next stop on this mission? Seeing our code quality platform in action with Unreal Engine, one of the most popular engines for different types of projects [&#8230;]",
        "contentSnippet": "If you saw our blog post about using Qodana in Unity and .NET projects, you know that we’ve been striving to explore Qodana’s potential for game development. What’s our next stop on this mission? Seeing our code quality platform in action with Unreal Engine, one of the most popular engines for different types of projects […]",
        "guid": "https://blog.jetbrains.com/?post_type=qodana&p=537855",
        "categories": [
          "tutorials",
          "game-development",
          "qodana",
          "teamcity",
          "unreal-engine"
        ],
        "isoDate": "2025-01-20T11:00:47.000Z"
      },
      {
        "creator": "Sasha Ivanova",
        "title": "The Early Access Program for ReSharper and the .NET Tools 2025.1 Is Here!",
        "link": "https://blog.jetbrains.com/dotnet/2025/01/17/resharper-2025-1-eap-1/",
        "pubDate": "Fri, 17 Jan 2025 12:46:31 +0000",
        "content:encodedSnippet": "We are excited to announce the launch of the Early Access Program (EAP) for the next major release of ReSharper and the .NET Tools! This initial EAP build is now available for download and offers a preview of the upcoming features and enhancements. Your feedback is crucial in helping us refine these updates, so we encourage you to try out the new build and share your thoughts.\nDownload ReSharper 2025.1 EAP 1\n                                                    \nIf you’re new to the Early Access Program, we encourage you to read this blog post where we outline what the program is all about and the benefits you can expect from participating in it.\nNow let’s take a look at the feature highlights of the first preview build!\ndotMemory\ndotMemory is now fully integrated with Visual Studio\nWith the 2025.1 update we’re elevating dotMemory from a standalone companion application to a fully integrated part of your Visual Studio workflow. The integration brings dotMemory’s complete feature set right into your development environment, accessible through the familiar ReSharper | Profile menu.\n\n\n\n\nHere’s how it works\nYou can now start profiling your application, capture memory snapshots, and analyze memory usage patterns without leaving Visual Studio. The dedicated dotMemory tool window gives you instant access to the collected profiling data. The profiling data is shown in the corresponding document tabs.\n\n\n\n\nThe dotMemory workspace inside Visual Studio\nA flashing memory profiling icon appears in the bottom-right corner of the Visual Studio window whenever a profiling session is running. Right-clicking this status bar icon allows you to:\nQuickly stop the current profiling session.\nOpen the dotMemory tool window if it’s not already visible.\n\n\n\n\nThis status bar menu also offers a faster way to access dotMemory than navigating through the main menu (Extensions | ReSharper | Profile | Show dotMemory Profiler), ensuring you can manage profiling sessions with ease. \n\n\n\n\nYou can also find your way to the dotMemory tool window by looking it up using the Search Everywhere action. \nGetting started\nFollow these steps to get started with dotMemory inside Visual Studio:\nInstall the ReSharper 2025.1 EAP 1 build\nGo to Extensions | ReSharper | Profile in the main menu\nChoose your target process or start a new profiling session\nConfigure your profiling parameters and start the profiling session.\nInvestigate the memory usage patterns in the dedicated Analysis tabs in the document window inside Visual Studio.  \nThe integration requires Visual Studio 2019 or later, and all your existing dotMemory workspaces will work seamlessly with the integrated version.\ndotMemory is part of the dotUltimate suite of tools, so if you already have a dotUltimate license, you can start using it right away!\nShould you encounter any issues with using the integrated version of dotMemory, please report them to this issue.\nReSharper C++\nThe 2025.1 EAP 1 build for ReSharper C++ comes with the following improvements:\nCross-platform code enhancements\nImproved support for conditionals with omitted operands. [RSCPP-35483]\nAdded support for the GNU #import directive. [RSCPP-35415]\nAdded support for _Float16, __bf16, and __float128 types. [RSCPP-35004, RSCPP-35814]\nCode editing and navigation\nIf no file with a matching name exists, the Switch header/source feature now suggests files containing symbols from the current file. [RSCPP-36341]\nThe __declspec(property) feature now parses get and put arguments and also supports Rename refactoring for them. [RSCPP-14090]\nCode analysis and formatting\nImproved handling of the Indent class member from access specifier formatter setting in typing assistance for a smoother editing experience. [RSCPP-31862]\nAn inspection has been added to detect redundant forward declarations within a single file. [RSCPP-35102]\nFor the full list of changes included in this build please see our issue tracker.\n[Download the EAP 1 build]\nWe encourage you to download the latest build and explore these new features. Your feedback is invaluable as we continue to refine and improve ReSharper for the upcoming release. Please share your thoughts and suggestions in the comments below or via our issue tracker.",
        "dc:creator": "Sasha Ivanova",
        "content": "We are excited to announce the launch of the Early Access Program (EAP) for the next major release of ReSharper and the .NET Tools! This initial EAP build is now available for download and offers a preview of the upcoming features and enhancements. Your feedback is crucial in helping us refine these updates, so we [&#8230;]",
        "contentSnippet": "We are excited to announce the launch of the Early Access Program (EAP) for the next major release of ReSharper and the .NET Tools! This initial EAP build is now available for download and offers a preview of the upcoming features and enhancements. Your feedback is crucial in helping us refine these updates, so we […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=538158",
        "categories": [
          "net-tools",
          "dotmemory",
          "resharpercplusplus",
          "resharper",
          "resharper-c"
        ],
        "isoDate": "2025-01-17T12:46:31.000Z"
      },
      {
        "creator": "Sasha Ivanova",
        "title": "The Early Access Program for Rider 2025.1 Is Now Open!",
        "link": "https://blog.jetbrains.com/dotnet/2025/01/17/rider-2025-1-eap-1/",
        "pubDate": "Fri, 17 Jan 2025 12:46:08 +0000",
        "content:encodedSnippet": "The Early Access Program for Rider 2025.1 has just begun. This is your chance to preview the new features and enhancements we’ve been working on and share your feedback to help us shape the future of JetBrains Rider. \nThere are several ways for you to get your hands on the first preview build:\nDownload and install them from our website.\nUse the Toolbox App.\nInstall this snap package from the SnapCraft store if you’re using a compatible Linux distribution.\n\n\n\n\nTo see the big picture of what’s coming, don’t miss our Rider 2025.1 Roadmap blog post. You may also want to check out this blog post, where we outline how the EAP program works and the benefits from using it.\nWithout further ado, here’s a quick overview of the first EAP build:\nRepository-wide visibility in the Solution Explorer\nYou can now navigate your entire codebase with Rider’s new Files view. This redesigned view complements the existing Solution view and displays your complete repository structure from the root, making it easier to work with full-stack projects, configuration files, and other modern development environment components.\n\n\n\n\nTo enable the Files tab by default, go to Settings/Preferences | Advanced Settings | Project View and select Enable Repository view in Explorer tool window.\nPlease note that there may be some performance issues when using the Files view with large solutions, which will be resolved in the upcoming builds.\nMore about this feature here. \nAutomatic child processes attachment for the .NET debugger\nRider now offers automatic attachment to child and grandchild processes during .NET application debugging. When enabled in the Run/Debug configurations, the IDE tracks and attaches to all .NET processes spawned within the application’s process tree.\nEnable this feature using the new Attach to child .NET processes checkbox.\nEnhanced .NET exception breakpoint configuration\nDebugging with exceptions gets smoother with Rider 2025.1! We’ve redesigned how you manage exception breakpoints, making it easier to focus on the exceptions that matter while keeping the noise at bay.\nThe new UI brings new filtering capabilities to your debugging workflow. When debugging your application, you now have precise control over which exceptions trigger breakpoints. Rider lets you filter exceptions based on both their origin (whether they come from your application code or external libraries) and how they’re handled in the code (if they’re caught by exception handlers or left unhandled). \n\n\n\n\n\nWe’ve expanded the exception popup’s capabilities to include unhandled exceptions management. While you could already mute handled exceptions from the popup window, now you can do the same for unhandled exceptions too with a single click of the Mute and Resume button.\n\n\n\n\nIf you’re migrating from a previous version of JetBrains Rider, your existing exception settings will automatically transfer to the new system, ensuring a smooth transition to the improved interface.\nSeparate color settings for C++ keywords\nWe’re ve introduced distinct color settings for built-in type keywords, control flow keywords, and control transfer keywords in C++, similar to the existing settings for C#. \n\n\n\n\n____________________________________________________________________________\nFor the full list of changes included in this build please see our issue tracker.\nWe encourage you to download the EAP build, give these new features a try, and share your feedback. The Early Access Program is a collaborative effort, and your input plays a vital role in making Rider the best it can be.\nDownload Rider 2025.1 EAP 1\n                                                    \nThank you for being part of our EAP community, and we look forward to hearing what you think!",
        "dc:creator": "Sasha Ivanova",
        "content": "The Early Access Program for Rider 2025.1 has just begun. This is your chance to preview the new features and enhancements we’ve been working on and share your feedback to help us shape the future of JetBrains Rider.  There are several ways for you to get your hands on the first preview build: To see [&#8230;]",
        "contentSnippet": "The Early Access Program for Rider 2025.1 has just begun. This is your chance to preview the new features and enhancements we’ve been working on and share your feedback to help us shape the future of JetBrains Rider.  There are several ways for you to get your hands on the first preview build: To see […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=538188",
        "categories": [
          "net-tools",
          "rider",
          "eap"
        ],
        "isoDate": "2025-01-17T12:46:08.000Z"
      },
      {
        "creator": "Sasha Ivanova",
        "title": "New Files View in Solution Explorer",
        "link": "https://blog.jetbrains.com/dotnet/2025/01/17/new-files-view-in-solution-explorer/",
        "pubDate": "Fri, 17 Jan 2025 12:45:43 +0000",
        "content:encodedSnippet": "In modern development, repositories are much more than just .NET solutions. From TypeScript end-to-end tests and Docker compose files to global.json and Playwright configs – your codebase contains numerous essential files that live outside of your C# projects.While these files are fully supported in Rider, they can be hard to find when viewing your solution structure.\nThis is why we’re introducing an enhanced Files view in the EAP 1 release for Rider 2025.1. \nDownload Rider 2025.1 EAP 1\n                                                    \nWhat’s new?\nThe reimagined Files view brings three key improvements:\nFirst, we’ve elevated the Files tab to be a true companion to the Solution view. You’ll find them side-by-side in one tool window, making it easier to switch contexts. Need to check your e2e tests in the tests folder? Looking for that CI configuration in .github? The Files view puts everything at your fingertips.\nSecond, we’ve shifted the view’s starting point to your repository root instead of the directory that contains the current solution file. This can be especially valuable for full-stack projects, where you might have:\nA backend folder with multiple .NET solutions\nA frontend directory containing your React, Angular, or Vue code\nDocker configurations and Kubernetes manifests\nDatabase migrations and scripts\nAPI documentation and Swagger files\n\n\n\n\nFinally, we’ve added intelligent folder highlighting to speed up navigation:\nDevelopment folders like src and tests stand out for quick access.\nSystem folders like .git fade into the background.\nSpecial directories like .github get distinct styling.\n\n\n\n\nHow to try it \nTo make sure the Files tab is displayed by default, go to Rider’s Settings/Preferences | Advanced Settings | Project View and check the Enable Repository view in Explorer toolwindow box.\n\n\n\n\nThen restart Rider, and you’ll see your full-stack repository in a whole new light!\nHelp us shape this feature\nThis is an early implementation, and your experience matters. We’d love to hear how the new Files view fits into your workflow. Share your thoughts in the comments below – what works, what doesn’t, and what you’d like to see next.\nDownload Rider 2025.1 EAP 1",
        "dc:creator": "Sasha Ivanova",
        "content": "In modern development, repositories are much more than just .NET solutions. From TypeScript end-to-end tests and Docker compose files to global.json and Playwright configs – your codebase contains numerous essential files that live outside of your C# projects.While these files are fully supported in Rider, they can be hard to find when viewing your solution [&#8230;]",
        "contentSnippet": "In modern development, repositories are much more than just .NET solutions. From TypeScript end-to-end tests and Docker compose files to global.json and Playwright configs – your codebase contains numerous essential files that live outside of your C# projects.While these files are fully supported in Rider, they can be hard to find when viewing your solution […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=537683",
        "categories": [
          "net-tools",
          "rider",
          "full-stack-development",
          "solution-explorer"
        ],
        "isoDate": "2025-01-17T12:45:43.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": []
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Jason Chlus",
        "title": "Our Favorite NEW Visual Studio Features of 2024",
        "link": "https://devblogs.microsoft.com/visualstudio/our-favorite-new-visual-studio-features-of-2024/",
        "pubDate": "Thu, 16 Jan 2025 17:01:56 +0000",
        "content:encodedSnippet": "Last year, the Visual Studio team delivered many new developer-focused improvements and AI integrations, many of which came directly from your feedback on Developer Community. In this post, we highlight the team’s favorite features from 2024 that boost productivity, streamline workflows, and enhance your coding experience. Let’s dive in!\nDownload Visual Studio 2022\n\n\nImage Hover Preview: See your images instantly! (Mads Kristensen 00:30)\nStruggling to visualize referenced images in your code? Visual Studio’s Image Hover Preview solves this by showing a quick preview of any image, complete with dimensions and file size, when you hover over its reference. It’s a small addition with a big impact on productivity.\n\nI love this feature!\nError Copying Improvements: Copy only what you need (Mads Kristensen 00:55)\nHistorically, copying error messages might have included detailed data that weren’t necessary to you. With this update, you can copy (Ctrl+C) just the error description, making it easier to search for solutions online.\n\nBefore:\nSeverity Code Description Project File Line Suppression State\nError (active) CS0103 The name ‘Test’ does not exist in the current context ConsoleApp1 C:\\Users\\jamont\\source\\repos\\ConsoleApp1\\ConsoleApp1\\Program.cs 7\nAfter:\nThe name ‘Test’ does not exist in the current context\nDrag/Drop across multiple instances of Visual Studio (Mads Kristensen 1:45)\nYou can now copy/paste or drag/drop files between Visual Studio instances seamlessly. This feature works across most project types and enhances workflow efficiency.\n\nRename Suggestions: Smarter names for cleaner code (Dalia Ado Sheasha 2:48)\nTired of unclear variable or method names? The Rename Suggestions feature analyzes your code to offer context-aware naming options. It’s a lifesaver when working on legacy or inherited projects.\nI hate naming things; this means I don’t have to!\nCopilot for Commits: Automated and personalized messages (Jessie Houghton 4:23)\nCommit messages just got easier. GitHub Copilot now generates customized commit messages, ensuring they align with your preferences and cover every change.\n\nMemory Layout Viewer: Optimize memory usage (Sy Brand 5:25)\nVisual Studio now lets you visualize memory layout, identify gaps, and optimize memory usage. This is particularly beneficial for projects requiring efficient memory management.\n\nAsync Debugging made easy (Andy Sterland 6:23)\nDebugging async/await code is notoriously tricky. The new Async Debugger in Visual Studio provides clearer insights into async calls, making it easier to identify issues and debug effectively.\nNew .NET MAUI templates: Start projects with ease (Rachel Kang 8:08)\nWith this update to .NET MAUI templates, you can now include sample content to jump-start your project. These templates integrate popular toolkits for a smoother development experience.\n\nEverything Copilot (Bruno Capuano 9:50)\nYou can now ask domain specific questions in Copilot Chat. Which, in combination with Copilot Edits, provides targeted code suggestions that you can add in session. If you want to change up the suggestions, you now can choose between different models in Copilot Chat.\nNew Extension Manager and Extension Hot Loading (Maia Kelner 11:11)\nInstalling extensions no longer interrupts your flow. With extension hot loading, you can install and use extensions without restarting Visual Studio.\n\nCheck out the new Bright Xaml Extension!\nUnreal Engine integration: Game development streamlined (David Li 12:55)\nGame developers rejoice! Open Unreal Engine projects directly in Visual Studio, configure targets, and leverage the new Unreal Engine toolbar for efficient workflows.\n\nCode Search (Sandy Armstrong 14:13)\nUse Ctrl + T to launch search. You can now search for specific scopes (current document, entire solution, etc)\n\nYou can dock the feature search window!\n.NET Aspire integrations (James Montemagno 15:09)\nYou can now easily orchestrate your existing .NET applications and services with a single click. Visual Studio will automatically create the .NET Aspire `AppHost` and `ServiceDefault` projects and configure everything for you! From the same context menu in Visual Studio you can easily add .NET Aspire integrations to your project by bringing up a filtered NuGet search. Check it out!\n\nWe love your feedback!\nThese innovations and improvements are a direct result of your input. The Visual Studio team thrives on feedback, and your suggestions continue to make it better. Keep sharing your thoughts and ideas on Developer Community. We’re building the future of development together!\nThe post Our Favorite NEW Visual Studio Features of 2024 appeared first on Visual Studio Blog.",
        "dc:creator": "Jason Chlus",
        "content": "<p>Last year, the Visual Studio team delivered many new developer-focused improvements and AI integrations, many of which came directly from your feedback on Developer Community. In this post, we highlight the team’s favorite features from 2024 that boost productivity, streamline workflows, and enhance your coding experience. Let’s dive in! Image Hover Preview: See your images [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/our-favorite-new-visual-studio-features-of-2024/\">Our Favorite NEW Visual Studio Features of 2024</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Last year, the Visual Studio team delivered many new developer-focused improvements and AI integrations, many of which came directly from your feedback on Developer Community. In this post, we highlight the team’s favorite features from 2024 that boost productivity, streamline workflows, and enhance your coding experience. Let’s dive in! Image Hover Preview: See your images […]\nThe post Our Favorite NEW Visual Studio Features of 2024 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=252076",
        "categories": [
          "Artificial Intelligence",
          "Data and Analytics",
          "Debug",
          "Git",
          "GitHub Copilot",
          "performance",
          "Productivity",
          "Visual Studio",
          ".NET MAUI",
          "Aspire",
          "code search",
          "Copilot",
          "Debugging",
          "Extensions",
          "Unreal Engine"
        ],
        "isoDate": "2025-01-16T17:01:56.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "\n                            Dmitry Kopytkov,Deepak Gupta\n            \t\t\t",
        "title": "Evolving our infrastructure through the messaging system model in Dropbox",
        "link": "https://dropbox.tech/infrastructure/infrastructure-messaging-system-model-async-platform-evolution",
        "pubDate": "Tue, 21 Jan 2025 09:00:00 -0800",
        "content:encodedSnippet": "The asynchronous platform at Dropbox integrates a suite of services that enable tasks and workflows to function independently without having to wait on one another. This is pretty important to our work as developers: It empowers any service within Dropbox to initiate and schedule tasks, seamlessly supporting over 400 product use cases—including Dropbox Dash and our other AI innovations—and efficiently routing more than 30 million tasks every minute. It also handles change data capture (CDC) use cases, where changes in our underlying storage system, including the FileSystem, are relayed to various product lambdas and processes. In short, it helps us ensure impactful and efficient business operations.\nThis implementation was essential to our growth from where we were a couple of years ago. Back then, the asynchronous platform struggled with scalability and reliability, frequently falling short of the demands of our expanding product portfolio. For product engineers, the platform posed additional hurdles due to limited developer productivity tools, making it cumbersome to build and iterate on asynchronous workflows. Today’s transformation into a robust and scalable system marks a dramatic shift from those early challenges—it enables innovation at a desired pace.\nIn this blog, we’ll introduce an open messaging system model (MSM), which played a key role in evolving our platform. It helped us build a unified event-driven system capable of orchestrating a wide range of asynchronous tasks and meeting future needs, especially as we focus on AI. Inspired by the Open Systems Interconnection (OSI) model, the MSM divides our platform into five logical layers. This standardization simplifies layers such as frontend interfaces, lambda functions, event schedulers, and event routers, allowing them to work across various use cases with different delivery guarantees and data sources, including those related to CDC.\nLet’s get into it.\nChallenges and limitations in our asynchronous infrastructure\nBeginning in 2021, our infrastructure comprised multiple asynchronous systems, each tailored to specific product or process requirements. These systems facilitated diverse functions—such as streaming events for Dropbox file uploads and edits—as well as supporting domains like security, abuse prevention, machine learning, and search indexing. Additionally, Dropbox integrated CDC functionality, enabling any modification within the underlying storage systems to generate an event, subsequently activating the async infrastructure. Despite occasional functional overlaps, these systems were developed, operated, and maintained separately, leading to inconsistencies in development speed, reliability, and operational ease.\nKey issues and limitations with these systems were as follows:\nDeveloper efficiency\nThe complexity of the current systems required product engineers to undertake a steep learning curve and assume responsibility for operational tasks such as capacity planning, release processes, and support, leading to reduced development speed and productivity.\nReliability\nThese systems had varied service-level objectives (SLOs) for availability, latency, processing, and recovery, which resulted in inconsistent and unreliable performance. Additionally, systems were not multi-homed, and this created significant reliability risk for multiple business use cases in the event of data center failure.\nOperability\nThe variety of systems led to higher operational costs due to their complexity, requiring additional development effort for maintenance and support. The asynchronous components in our technology stack relied on a mix of external queuing solutions, such as Kafka, Redis, and Amazon SQS, creating an infrastructure that was challenging to manage and operate.\nSystem scalability\nAt the beginning of 2021, our system was processing over 30 billion requests daily to dispatch jobs to lambda functions. (Lambda is a serverless cloud service that runs your code automatically in response to events, without requiring you to manage any servers.) However, meeting the defined SLOs became increasingly challenging. Certain critical components, such as the delayed event scheduler, had already maxed out their throughput capacity. Consequently, we had to implement rigorous screening protocols for each new use case before onboarding in order to ensure it adhered to the system's capacity limitations and wouldn't jeopardize its performance.\nLambda infrastructure\nThe lambda-based architecture utilized on the consumer side was complex and diverged from the Dropbox service-oriented architecture (SOA) guidelines and established best practices. Consequently, diagnosing and investigating issues on the consumption side became highly challenging, as it didn't integrate seamlessly with the Dropbox infrastructure and recommended methodologies. This lack of alignment resulted in several adverse effects, notably:\nRelease consistency: The release procedures across these systems lacked uniformity and robust safety measures, introducing deployment and update risks.\nCompute efficiency: The compute clusters supporting these systems operated below peak efficiency, resulting in suboptimal resource utilization.\nNo autoscaling: The absence of autoscaling for lambda infrastructure, stemming from its deviation from the Dropbox SOA guidelines, resulted in poor integration with our autoscaling infrastructure. As a result, there was a reliance on customer or platform-owner intervention to manually augment capacity when the base capacity proved inadequate to manage the workload.\nExtensibility\nExtensibility posed a significant challenge for these systems, characterized by a deficiency in flexibility and scalability to adapt to emerging product demands. The current solutions were ill-equipped to seamlessly integrate new workflows, and any attempts to expand them would introduce unnecessary complexities in implementation. With the introduction of Cypress, our new filesystem architecture, the existing system faced limitations in expanding our CDC pipeline to distribute Cypress events to multiple subscribers within Dropbox.\nIn all, these challenges underscored the need for a more unified and consistent approach to our asynchronous infrastructure, emphasizing the importance of addressing developer velocity, reliability, operability, efficiency, and extensibility to better support the company's evolving product landscape.\nRethinking our approach\nThe existing async systems already supported over 400 business use cases. The large number of existing use cases meant we didn’t have the flexibility to construct an entirely new system from scratch, as the migration would have been very time consuming. Instead, we decided to adopt a phased approach, with incremental steps to rebuild existing systems that mitigate risks associated with migrating existing production flows to a new infrastructure. Returning to the drawing board, we outlined three primary goals for the new platform, envisioning a gradual and incremental build-up of capabilities:\nDevelopment velocity\nSimplify the asynchronous interface to streamline platform adoption for product engineers. This allows them to focus on creating innovative product features rather than investing time in understanding the complex asynchronous landscape and determining the most suitable system for their use case.\nDecrease the operational burden on product engineers by implementing release practices that identify code regressions during deployment and automatically initiate rollbacks if a new release breaches predefined thresholds.\nEnable automatic compute scaling when a lambda function encounters a backlog of events to process, ensuring that the current base capacity is augmented if deemed insufficient.\nRobust and extensible async foundation\nUnify common elements and patterns across existing async systems within Dropbox and simplify the interface.\nSupport new use cases with minimal modifications and avoid the need to build entire new systems by providing extensible components and flexible APIs.\nCost and operational efficiency\nStreamline the foundational infrastructure by phasing out redundant systems (where applicable) and cut down on operational costs.\nTransition lambda infrastructure to the Dropbox SOA stack to increase compute efficiency and enable functionalities such as autoscaling, multihoming, and improved out-of-the-box monitoring capabilities.\nThe overarching key performance indicator (KPI) that we aimed to improve over time was the \"time to launch\" for product engineers to deploy a new use case into production. As platform owners, our primary KPI of interest was the \"oncall time\" expended on a weekly basis.\n The five layers of the messaging system model\nThe initial step in the refinement of the async system involved deconstructing it into its fundamental layers. We undertook this process to achieve the aforementioned objectives. Subsequently, a systematic approach was devised, beginning with the dissection of the async system into its core elements, followed by the formulation of a bottom-up strategy for its progressive enhancement.\nFrom a macroscopic standpoint, the asynchronous system can be mapped to an MSM consisting of three primary layers, analogous to the seven layers of the OSI model in network transmission frameworks. These three primary layers are:\nCustomer layer: This component, also known as the “frontend layer,” encompasses the various pathways through which users interact and interface with the async system. It encapsulates the mechanisms by which users communicate with and integrate into the async environment.\nOrchestration layer: This layer is intrinsic to the async system and encompasses the entirety of the tasks required for the scheduling and transmission of async operations to the compute layer (also known as the “execution layer”). It serves as the intermediary stage between the customer layer and the compute layer, and it’s responsible for ensuring that various components and services interact seamlessly to fulfill complex workflows and business logic requirements.\nCompute layer: This layer is the execution hub of the async system, where the actual processing and execution of async tasks take place. It is responsible for the seamless execution of asynchronous operations, thereby ensuring the efficient functioning of the system as a whole.\n -->\n\n        \n         \n        \n    \n\n            \nA 10,000-foot view of the async system\n\n\nThe three layers mentioned above can then be further broken down into five, more specific layers—frontend, scheduler, flow control, delivery, and execution—with each new layer serving an important role within the above three buckets. (Some overlap occurs between the customer and orchestration layers). These five layers of the MSM are illustrated in the diagram below.\n -->\n\n        \n         \n        \n    \n\n            \nAn illustration of the five components of the Messaging System Model (MSM)\n\n\nNow, let's take a closer look at each of these five layers.\nFrontend\nIn the architecture of an asynchronous system, the frontend layer assumes the critical role of serving as the primary interface for user interaction with the system. It represents the user-facing aspect of the asynchronous environment, orchestrating seamless communication and integration with the system's core functionalities. Users are categorized into two distinct groups: first, there are the regular product engineers who utilize programmatic methods to invoke a publish remote procedure call (RPC) and enqueue events, destined to be consumed by one or more subscribers. The second category encompasses systems such as databases or event sources, which necessitate the enqueuing of changes to diverse objects, entities, or files, thereby propelling both internal and external business workflows forward.\nA pivotal responsibility of the frontend layer is the management of the schema registry and the rigorous validation of every event schema traversing the system. This stringent schema validation process ensures that published events conform to the predefined contract established with subscribers. Additionally, the frontend layer is tasked with the intricate conversion of disparate message formats, including JSON, Proto, and Avro, among others, into a standardized message format—typically protocol buffers—compatible with the internal asynchronous implementation.\nFurthermore, the frontend component is entrusted with guaranteeing the durability of all events published to the asynchronous system, thereby safeguarding the integrity and reliability of the system's data flow. \nScheduler\nThe scheduler is the core engine within an async system and plays a crucial role in coordinating and dispatching disparate events for various consumers that subscribe to these events. This layer plays various roles. For example, for a CDC use case, this will call external data source APIs to get relevant range for the payloads that will be delivered to the subscribers. For a use case where events need delayed execution, the scheduler would store these events separately so they can be trigger at desired timestamp with a process keeping tabs on these events and publishing them to subscribers at those desired scheduled timestamps. \nScheduler also has the responsibility to maintain the order of execution of the events and ensures task delivery to subscribers based on this order.\nFlow control\nFlow control plays a pivotal role in the orchestration layer, managing the distribution of tasks to subscribers based on several factors, such as subscriber availability, task priority, and potential throttling events. For instance, in a CDC scenario, the orchestration layer dynamically adjusts the rate of queries dispatched to subscribers. This adaptation occurs when the orchestration layer detects that a subscriber is unable to handle the job throughput effectively or when the source, backing CDC, signals the scheduler client to reduce the pace.\nState management, another function of this layer, encompasses the maintenance of data structures responsible for tracking ongoing events and their respective statuses (such as pending, running, or complete). Additionally, it incorporates mechanisms to retry tasks in case of transient failures, ensuring robustness and reliability in task execution.\nDelivery\nThe execution layer of the messaging system model can be broken down into two main parts. The first is the delivery layer, which is the process of directing the event to the right place or service. The second, the event execution, we’ll get to in a bit.\nRouting is the final layer in an asynchronous system, responsible for directing the message out of the system and into the domain where a designated process or lambda function will handle the event. This process or lambda function may be hosted within the same virtual private cloud (VPC) as the messaging infrastructure or may be a part of public clouds like AWS, Azure, etc. In a push-based model, the routing layer is one of the most critical components, similar to the “last mile delivery” in an e-commerce delivery system.\nRouting enables many critical functions, including:\nMessage filtering based on subscriber preferences\nDelivery retries for transient failures\nContinuously monitoring the health of a subscriber’s event execution hosts, and then routing events only to those that are healthy\nDispatching event execution status to the orchestration layer for state machine management\nEvent delivery concurrency management\nExecution\nThe event execution is the second layer of the primary compute bucket. It’s when the actual task happens, and it’s usually done by a lambda function (i.e., serverless code), or a remote process—potentially even another system or service—that handles the event. In short, the compute layer involves first routing the event and then actually processing it.\nLambda infrastructure refers to the underlying framework responsible for executing events. When an event is triggered, a process is initiated within this infrastructure, which subsequently returns either a success or retriable failure status post-execution. If no status is returned, or if an error occurs, the default assumption is a retriable failure. In this interaction, the router acts as the client, operating under a push model.\nIdeally, the executing process operates across multiple cloud environments to enhance reliability. The router has the capability to push events to various clouds based on the locality preference configured by the lambda/process owner. For example, some users may opt to configure their processes to be active in specific clouds to ensure proximity to backend storage dependencies, thereby minimizing cross-data center latency.\nLambda infrastructure should also include autoscaling as part of its features. At Dropbox, our lambda infrastructure is backed by Atlas, which offers autoscaling capabilities. Additionally, Atlas supports release-time hooks, enabling validation and rollback of code changes if they would potentially degrade service uptime or impact any features negatively.\nConclusion\nEngaging with customers and understanding their requirements and pain points is vital when evolving or reconstructing a major platform component. This approach was instrumental in shaping the blueprint for MSM. By applying first principles, we deconstructed the problem into its smallest components and envisioned a system that delivers the flexibility and extensibility required for the platform. This solid foundation enabled us to rebuild from the ground up with clarity and purpose, ensuring the platform meets current demands while remaining adaptable to future challenges.\nThis blog has only scratched the surface of the asynchronous platform we’ve built over the past few years, and we’re constantly looking for new ways to improve our infrastructure. We’re excited to, in the future, dive deeper into other critical design decisions that help us build a more efficient and useful Dropbox!\n \n~ ~ ~\n \nIf building innovative products, experiences, and infrastructure excites you, come build the future with us! Visit dropbox.com/jobs to see our open roles, and follow @LifeInsideDropbox on Instagram and Facebook to see what it's like to create a more enlightened way of working.",
        "dc:creator": "\n                            Dmitry Kopytkov,Deepak Gupta\n            \t\t\t",
        "content": "null",
        "contentSnippet": "null",
        "guid": "https://dropbox.tech/infrastructure/infrastructure-messaging-system-model-async-platform-evolution",
        "categories": [
          "models",
          "Developer",
          "AI",
          "Lambda",
          "Dash",
          "Infrastructure"
        ],
        "isoDate": "2025-01-21T17:00:00.000Z"
      }
    ]
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": [
      {
        "creator": "sunyzero",
        "title": "gnome-tweaks로 리눅스 데스크탑 환경의 미세 조정",
        "link": "http://sunyzero.tistory.com/311",
        "pubDate": "Sun, 19 Jan 2025 23:48:43 +0900",
        "author": "sunyzero",
        "comments": "http://sunyzero.tistory.com/311#entry311comment",
        "content": "<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">리눅스 GNOME 데스크탑 환경을 사용하다보면 뭔가 약간 불편함이 있을 수 있는데, 이를 미세하게 조정해주면 편리해진다. 이를 위해 사용되는 프로그램이 gnome-tweaks 이다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">1. 설치</span></h2>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">dnf install gnome-tweaks 로 간단하게 설치할 수 있다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">2. 실행 및 설정</span></h2>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">애플리케이션 목록에서 실행해도되고, 터미널에서 gnome-tweaks로 실행해도 된다. 사용하는 유저로 로그인한 상태에서 실행하면 된다. root로 실행하지는 말자.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1032\" data-origin-height=\"630\"><span data-url=\"https://blog.kakaocdn.net/dn/M3UKs/btsLRhig95a/tNmcAciyh63SfNH13kykA0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/M3UKs/btsLRhig95a/tNmcAciyh63SfNH13kykA0/img.png\" data-alt=\"gnome-tweaks - Windows\"><img src=\"https://blog.kakaocdn.net/dn/M3UKs/btsLRhig95a/tNmcAciyh63SfNH13kykA0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FM3UKs%2FbtsLRhig95a%2FtNmcAciyh63SfNH13kykA0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1032\" height=\"630\" data-origin-width=\"1032\" data-origin-height=\"630\"/></span><figcaption>gnome-tweaks - Windows</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">Windows에서 설정할 수 있는 주요 기능은 다음과 같다. 특히 \"두번째 누름 동작에 크기 조절\"은 매우 유용한 기능이다.</span></p>\n<div>\n<table style=\"border-collapse: collapse; width: 100%;\" border=\"1\" data-ke-align=\"alignLeft\">\n<tbody>\n<tr>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">두번 누름</span></span></td>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">Minimize를 설정해두면 편리하게 사용할 수 있다. <br />(창 타이틀 부분을 두번 클리하면 즉시 최소화 해준다)</span></span></td>\n</tr>\n<tr>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">제목 표시줄 단추=최대화/최소화</span></span></td>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">최대화, 최소화 기능을 켜면 창 우측 or 좌측 상단에 최소/최대화 기능이 생긴다.</span></span></td>\n</tr>\n<tr>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">모달 대화 상자 붙여두기</span></span></td>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">모달 대화 상자와 상위 창이 같이 이동하면 직관적이고 잘못 입력하거나 오해할 가능성이 적어진다.</span></span></td>\n</tr>\n<tr>\n<td><span style=\"background-color: #f6e199; font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">두번째 누름 동작에 크기 조절</span></span></td>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">Super키를 누른 상태에서 휠 버튼으로 크기 조절하던 것을 마우스 오른 버튼으로 대체하여 편리해진다. 이 기능은 적극적으로 추천한다.</span></span><br /><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">(두번째 누름 동작 = Mouse 2번째 버튼 클릭 동작)</span></span></td>\n</tr>\n</tbody>\n</table>\n<span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><b><br /></b> </span></div>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">Keyboard에서는&nbsp;Capslock&nbsp;동작에&nbsp;대해서&nbsp;커스터마이징을&nbsp;하는&nbsp;편이다.&nbsp;Linux에서는&nbsp;보통&nbsp;&lt;Ctrl-C&gt;나&nbsp;&lt;Ctrl-Z&gt;,&nbsp;&lt;Ctrl-W&gt;를&nbsp;많이&nbsp;사용한다.&nbsp;각각&nbsp;취소,&nbsp;SIGTSTP&nbsp;시그널&nbsp;전달,&nbsp;GUI&nbsp;프로그램의&nbsp;탭&nbsp;닫기&nbsp;기능으로&nbsp;사용된다.&nbsp;이&nbsp;기능을&nbsp;누를때&nbsp;Capslock키를&nbsp;&lt;Ctrl&gt;로&nbsp;대체하면&nbsp;편리해진다.&nbsp;대신에&nbsp;Capslock&nbsp;기능은&nbsp;양쪽&nbsp;Shift를&nbsp;동시에&nbsp;눌러서&nbsp;토글하는&nbsp;방식으로&nbsp;변경한다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"528\" data-origin-height=\"566\"><span data-url=\"https://blog.kakaocdn.net/dn/Cfmkw/btsLSxYObiO/7CMBqnOXGC6RpJb0N2tZDK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Cfmkw/btsLSxYObiO/7CMBqnOXGC6RpJb0N2tZDK/img.png\" data-alt=\"gnome-tweaks - keyboard - caps lock\"><img src=\"https://blog.kakaocdn.net/dn/Cfmkw/btsLSxYObiO/7CMBqnOXGC6RpJb0N2tZDK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FCfmkw%2FbtsLSxYObiO%2F7CMBqnOXGC6RpJb0N2tZDK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"528\" height=\"566\" data-origin-width=\"528\" data-origin-height=\"566\"/></span><figcaption>gnome-tweaks - keyboard - caps lock</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">앞서 언급한대로 caps lock을 control키로 사용하는 경우에는 양쪽 shift로 caps lock을 대신하면 된다. 이 설정은 호환성 옵션 부분에 있다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"528\" data-origin-height=\"566\"><span data-url=\"https://blog.kakaocdn.net/dn/cOxQq0/btsLScU6XY8/MvmmPeaSLsUdf6SDi6t941/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cOxQq0/btsLScU6XY8/MvmmPeaSLsUdf6SDi6t941/img.png\" data-alt=\"gnome-tweaks - keyboard - compatibility\"><img src=\"https://blog.kakaocdn.net/dn/cOxQq0/btsLScU6XY8/MvmmPeaSLsUdf6SDi6t941/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcOxQq0%2FbtsLScU6XY8%2FMvmmPeaSLsUdf6SDi6t941%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"528\" height=\"566\" data-origin-width=\"528\" data-origin-height=\"566\"/></span><figcaption>gnome-tweaks - keyboard - compatibility</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">이외에 기본 Font나 appearance에서 이것저것 수정이 가능하므로 한번씩 살펴보면 좋을 듯 하다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">히스토리</span></h2>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">2025-01-19 작성</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "리눅스 GNOME 데스크탑 환경을 사용하다보면 뭔가 약간 불편함이 있을 수 있는데, 이를 미세하게 조정해주면 편리해진다. 이를 위해 사용되는 프로그램이 gnome-tweaks 이다.\n \n1. 설치\ndnf install gnome-tweaks 로 간단하게 설치할 수 있다.\n \n2. 실행 및 설정\n애플리케이션 목록에서 실행해도되고, 터미널에서 gnome-tweaks로 실행해도 된다. 사용하는 유저로 로그인한 상태에서 실행하면 된다. root로 실행하지는 말자.\ngnome-tweaks - Windows\n\n\nWindows에서 설정할 수 있는 주요 기능은 다음과 같다. 특히 \"두번째 누름 동작에 크기 조절\"은 매우 유용한 기능이다.\n두번 누름\nMinimize를 설정해두면 편리하게 사용할 수 있다. \n(창 타이틀 부분을 두번 클리하면 즉시 최소화 해준다)\n\n\n제목 표시줄 단추=최대화/최소화\n최대화, 최소화 기능을 켜면 창 우측 or 좌측 상단에 최소/최대화 기능이 생긴다.\n\n\n모달 대화 상자 붙여두기\n모달 대화 상자와 상위 창이 같이 이동하면 직관적이고 잘못 입력하거나 오해할 가능성이 적어진다.\n\n\n두번째 누름 동작에 크기 조절\nSuper키를 누른 상태에서 휠 버튼으로 크기 조절하던 것을 마우스 오른 버튼으로 대체하여 편리해진다. 이 기능은 적극적으로 추천한다.\n(두번째 누름 동작 = Mouse 2번째 버튼 클릭 동작)\n\n\n\n\n \nKeyboard에서는 Capslock 동작에 대해서 커스터마이징을 하는 편이다. Linux에서는 보통 <Ctrl-C>나 <Ctrl-Z>, <Ctrl-W>를 많이 사용한다. 각각 취소, SIGTSTP 시그널 전달, GUI 프로그램의 탭 닫기 기능으로 사용된다. 이 기능을 누를때 Capslock키를 <Ctrl>로 대체하면 편리해진다. 대신에 Capslock 기능은 양쪽 Shift를 동시에 눌러서 토글하는 방식으로 변경한다.\ngnome-tweaks - keyboard - caps lock\n\n\n앞서 언급한대로 caps lock을 control키로 사용하는 경우에는 양쪽 shift로 caps lock을 대신하면 된다. 이 설정은 호환성 옵션 부분에 있다.\ngnome-tweaks - keyboard - compatibility\n\n\n \n이외에 기본 Font나 appearance에서 이것저것 수정이 가능하므로 한번씩 살펴보면 좋을 듯 하다.\n \n히스토리\n2025-01-19 작성",
        "guid": "http://sunyzero.tistory.com/311",
        "categories": [
          "컴퓨터 관련/리눅스 데스크탑",
          "gnome",
          "gnome-tweaks",
          "linux",
          "그놈 데스크탑",
          "리눅스",
          "캡스락"
        ],
        "isoDate": "2025-01-19T14:48:43.000Z"
      }
    ]
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권영재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": [
      {
        "title": "Spring Data MongoDB에서의 Update 전략과 경험",
        "link": "https://cheese10yun.github.io/spring-data-mongo-update-guide-1/",
        "pubDate": "2025-01-18T14:24:07.000Z",
        "content": "<p>Spring Data MongoDB를 활용한 애플리케이션 개발 과정에서, 데이터를 업데이트하는 방법은 프로젝트의 설계와 성능에 큰 영향을 미칩니다. 특히, <code>mongoRepository.save</code>, <code>mongoTemplate.save</code>, 그리고 <code>mongoTemplate.updateFirst</code>와 같은 메서드들은 각각의 특성과 적합한 상황이 다릅니다. 이 글에서는 Spring Data MongoDB에서 <strong>업데이트 전략</strong>을 중심으로 개발 경험에서 얻은 인사이트를 공유하며, 각 메서드의 동작 방식과 적절한 사용 방법에 대해 논의합니다.</p><h2><span id=\"update-메서드-비교\">Update 메서드 비교</span></h2><p>Spring Data MongoDB에서 사용되는 주요 업데이트 메서드들은 아래와 같이 동작 방식과 적합한 시나리오에서 차이가 있습니다:</p><table><thead><tr><th><strong>특징</strong></th><th><strong>mongoRepository.save</strong></th><th><strong>mongoTemplate.save</strong></th><th><strong>mongoTemplate.updateFirst</strong></th></tr></thead><tbody><tr><td><strong>작업 대상</strong></td><td>단일 문서</td><td>단일 문서</td><td>단일 문서</td></tr><tr><td><strong>저장 방식</strong></td><td>변경된 필드만 업데이트</td><td>전체 문서 교체</td><td>변경된 필드만 업데이트</td></tr><tr><td><strong>문서가 없을 경우</strong></td><td>새로 삽입</td><td>새로 삽입</td><td>기본적으로 아무 작업도 수행하지 않음</td></tr><tr><td><strong>업데이트 범위</strong></td><td>필드 단위</td><td>전체 문서</td><td>필드 단위</td></tr><tr><td><strong>조건 지정</strong></td><td><code>_id</code> 기준</td><td><code>_id</code> 기준</td><td>사용자 정의 쿼리</td></tr><tr><td><strong>Spring Data 통합</strong></td><td>페이징, 정렬 등 지원</td><td>미지원</td><td>미지원</td></tr><tr><td><strong>적합한 상황</strong></td><td>간단한 CRUD 작업</td><td>전체 문서 교체 또는 삽입</td><td>조건에 맞는 단일 문서 필드 수정</td></tr></tbody></table><h3><span id=\"mongotemplatesave\">mongoTemplate.save</span></h3><p>문서 전체 교체(Replace)를 수행합니다.</p><h4><span id=\"동작-방식\">동작 방식</span></h4><ul><li><code>_id</code> 필드를 기준으로 MongoDB에서 문서를 검색.</li><li>문서가 존재하면 <strong>전체 문서를 교체</strong>합니다.</li><li>문서가 존재하지 않으면 새로 삽입합니다.</li><li>저장 객체에 없는 필드는 기존 문서에서 삭제됩니다.</li></ul><h4><span id=\"예제\">예제</span></h4><figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">val</span> user = User(id = <span class=\"string\">\"123\"</span>, name = <span class=\"string\">\"John Doe\"</span>, age = <span class=\"number\">30</span>)</span><br><span class=\"line\">mongoTemplate.save(user)</span><br></pre></td></tr></table></figure><h4><span id=\"결과\">결과</span></h4><ul><li>기존 문서: <code>{ &quot;_id&quot;: &quot;123&quot;, &quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 25, &quot;email&quot;: &quot;alice@example.com&quot; }</code></li><li>업데이트 후: <code>{ &quot;_id&quot;: &quot;123&quot;, &quot;name&quot;: &quot;John Doe&quot;, &quot;age&quot;: 30 }</code></li><li>변경 사항: <code>email</code> 필드가 삭제됨.</li></ul><h3><span id=\"mongorepositorysave\">mongoRepository.save</span></h3><p>문서의 일부 필드만 업데이트(Partial Update)를 수행합니다.</p><h4><span id=\"동작-방식\">동작 방식</span></h4><ul><li><code>_id</code> 필드를 기준으로 MongoDB에서 문서를 검색.</li><li>문서가 존재하면 <strong>변경된 필드만 업데이트</strong>하고, 나머지 필드는 유지됩니다.</li><li>문서가 존재하지 않으면 새로 삽입합니다.</li></ul><h4><span id=\"예제\">예제</span></h4><figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">val</span> user = User(id = <span class=\"string\">\"123\"</span>, name = <span class=\"string\">\"John Doe\"</span>)</span><br><span class=\"line\">userRepository.save(user)</span><br></pre></td></tr></table></figure><h4><span id=\"결과\">결과</span></h4><ul><li>기존 문서: <code>{ &quot;_id&quot;: &quot;123&quot;, &quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 25, &quot;email&quot;: &quot;alice@example.com&quot; }</code></li><li>업데이트 후: <code>{ &quot;_id&quot;: &quot;123&quot;, &quot;name&quot;: &quot;John Doe&quot;, &quot;age&quot;: 25, &quot;email&quot;: &quot;alice@example.com&quot; }</code></li><li>변경 사항: <code>name</code> 필드만 업데이트, 나머지 필드는 유지됨.</li></ul><h3><span id=\"mongotemplateupdatefirst\">mongoTemplate.updateFirst</span></h3><p>MongoDB의 <strong><code>updateFirst</code></strong> 명령어를 실행하여 <strong>단일 문서를 부분 업데이트</strong>합니다.</p><h4><span id=\"동작-방식\">동작 방식</span></h4><ul><li>조건을 지정하여 MongoDB에서 문서를 검색.</li><li>첫 번째로 매칭된 문서의 <strong>일부 필드만 업데이트</strong>합니다.</li><li>문서가 존재하지 않으면 기본적으로 아무 작업도 수행하지 않습니다(삽입하지 않음).</li><li><code>$set</code>과 같은 MongoDB 연산자를 사용하여 지정된 필드만 업데이트합니다.</li></ul><h4><span id=\"예제\">예제</span></h4><figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">val</span> query = Query(Criteria.where(<span class=\"string\">\"name\"</span>).`<span class=\"keyword\">is</span>`(<span class=\"string\">\"Alice\"</span>))</span><br><span class=\"line\"><span class=\"keyword\">val</span> update = Update().<span class=\"keyword\">set</span>(<span class=\"string\">\"age\"</span>, <span class=\"number\">30</span>)</span><br><span class=\"line\">mongoTemplate.updateFirst(query, update, User::<span class=\"class\"><span class=\"keyword\">class</span>.<span class=\"title\">java</span>)</span></span><br></pre></td></tr></table></figure><h4><span id=\"결과\">결과</span></h4><ul><li>기존 문서: <code>{ &quot;_id&quot;: &quot;123&quot;, &quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 25, &quot;email&quot;: &quot;alice@example.com&quot; }</code></li><li>업데이트 후: <code>{ &quot;_id&quot;: &quot;123&quot;, &quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 30, &quot;email&quot;: &quot;alice@example.com&quot; }</code></li><li>변경 사항: <code>age</code> 필드만 업데이트, 나머지 필드는 유지됨.</li></ul><h2><span id=\"효율적인-mongodb-업데이트-전략\">효율적인 MongoDB 업데이트 전략</span></h2><p><code>mongoTemplate.save</code>는 문서 전체를 교체하기 때문에 일반적인 경우에는 거의 사용되지 않습니다. 반면, <code>mongoRepository.save</code>는 더 직관적이며, 특히 Spring Data JPA 경험이 있는 개발자에게는 익숙하고 이해하기 쉬운 방식입니다. 그럼에도 불구하고, 저는 업데이트 작업에 <code>mongoTemplate</code>기반의 업데이트만을 사용하고 있습니다. 그 이유는 다음과 같습니다.</p><h3><span id=\"대량-처리에서의-성능-차이\">대량 처리에서의 성능 차이</span></h3><p><a href=\"https://cheese10yun.github.io/spring-data-mongodb-update-performance/\">MongoDB Update 성능 측정 및 분석</a>에서 업데이트 성능을 측정한 결과를 참고할 수 있습니다.</p><p><img src=\"https://raw.githubusercontent.com/cheese10yun/blog-sample/5fc6127a0800ca9bce5de5a6c73931b2025b0791/mongo-study/images/performance-update.png\" alt=\"\"></p><table><thead><tr><th><strong>Rows</strong></th><th><strong>saveAll</strong></th><th><strong>updateFirst</strong></th><th><strong>bulkOps (UNORDERED)</strong></th><th><strong>bulkOps (ORDERED)</strong></th></tr></thead><tbody><tr><td>100</td><td>1,052 ms</td><td>1,176 ms</td><td>46 ms</td><td>79 ms</td></tr><tr><td>200</td><td>2,304 ms</td><td>2,196 ms</td><td>103 ms</td><td>124 ms</td></tr><tr><td>500</td><td>5,658 ms</td><td>5,250 ms</td><td>309 ms</td><td>257 ms</td></tr><tr><td>1,000</td><td>11,106 ms</td><td>10,846 ms</td><td>418 ms</td><td>412 ms</td></tr><tr><td>2,000</td><td>22,592 ms</td><td>21,427 ms</td><td>1,060 ms</td><td>1,004 ms</td></tr><tr><td>5,000</td><td>54,407 ms</td><td>52,075 ms</td><td>2,663 ms</td><td>2,292 ms</td></tr><tr><td>10,000</td><td>107,651 ms</td><td>110,884 ms</td><td>4,514 ms</td><td>4,496 ms</td></tr></tbody></table><p>대량 처리를 할 경우 <code>saveAll</code> 방식은 내부적으로 반복문을 돌면서 <code>save</code>를 호출하는 방식으로 동작합니다. 이는 데이터베이스 요청을 문서별로 각각 보내기 때문에, 대량 처리 시 성능이 크게 저하됩니다. <code>saveAll</code>과 <code>updateFirst</code>는 모두 문서 단위로 데이터베이스 요청을 반복 호출하기 때문에 처리 성능이 거의 비슷하지만, 요청 수가 많아질수록 응답 시간이 급격히 증가하는 문제가 발생합니다.</p><p>반면, <code>bulkOps</code>는 여러 업데이트 작업을 한 번의 연산으로 묶어서 실행하므로 대량 처리에서 훨씬 효율적입니다. 이를 통해 처리 시간을 크게 단축할 수 있지만, <code>save</code>와 <code>saveAll</code> 방식으로는 <code>bulkOps</code>를 활용할 수 없다는 한계가 있습니다. 이러한 이유로 저는 대량 처리 작업에서 <code>updateFirst</code>와 함께 <code>bulkOps</code>를 활용하는 방식을 선호합니다.</p><p>또한, 대량 데이터를 업데이트할 때 <strong><code>where in</code> 절</strong>을 활용하면 효과적입니다. 이 경우, <code>mongoTemplate.updateMulti</code>를 사용하면 <code>bulkOps</code> 방식과 유사한 성능을 얻을 수 있습니다. <code>saveAll</code>을 사용하면 성능이 급격히 저하되므로, 대량 데이터를 업데이트할 때는 반드시 <code>mongoTemplate</code>을 사용하는 것이 좋습니다. 이러한 접근 방식은 대량 처리의 효율성과 성능 최적화를 보장하며, 대량 데이터를 다루는 애플리케이션에서 더욱 유용합니다.</p><h3><span id=\"명확한-변경-사항-추적\">명확한 변경 사항 추적</span></h3><p><code>mongoRepository.save</code>를 사용하여 데이터를 업데이트할 경우, 정확히 어떤 필드가 변경되었는지 추적하기 어렵습니다. MongoDB는 비정형 데이터베이스로, 다양한 필드와 그 필드들이 다루는 컨텍스트가 매우 다양합니다. 이런 상황에서 <code>mongoRepository.save</code>를 통해 업데이트가 이루어지면, 어떤 필드가 어떤 조건에서 업데이트되었는지 명확히 파악하기 어렵기 때문에 데이터 변경 사항을 추적하고 관리하는 데 어려움이 발생할 수 있습니다.</p><p>반면, <code>mongoTemplate</code>을 기반으로 업데이트 쿼리를 작성하면 특정 필드에 대해 명확히 정의된 업데이트를 수행할 수 있습니다. 각 업데이트가 어디에서 이루어졌는지, 어떤 필드가 변경되었는지를 코드 레벨에서 명확히 확인할 수 있어 추적이 용이합니다. 특히 프로젝트가 복잡해지거나 엄격한 변경 관리가 요구될수록, 이러한 명확성은 유지보수와 협업 측면에서 큰 장점으로 작용합니다. 이를 통해 데이터 업데이트의 불확실성을 줄이고, 코드의 가독성과 신뢰성을 높일 수 있습니다.</p><h2><span id=\"실제-사용-예시\">실제 사용 예시</span></h2><h3><span id=\"document-정의\">Document 정의</span></h3><figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Document(collection = <span class=\"meta-string\">\"members\"</span>)</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Member</span></span>(</span><br><span class=\"line\">    <span class=\"meta\">@Field(name = <span class=\"meta-string\">\"name\"</span>)</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> name: String,</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Field(name = <span class=\"meta-string\">\"address\"</span>)</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> address: Address,</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Field(name = <span class=\"meta-string\">\"member_id\"</span>)</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> memberId: String,</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Field(name = <span class=\"meta-string\">\"email\"</span>)</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> email: String,</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Field(name = <span class=\"meta-string\">\"status\"</span>)</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> status: MemberStatus</span><br><span class=\"line\">) : Auditable()</span><br></pre></td></tr></table></figure><p>위 예시와 같이 <code>Member</code> 도큐먼트가 정의되어 있다고 가정하겠습니다. 이 도큐먼트는 <code>MongoRepository</code>를 사용하여 업데이트하지 않기 때문에, 필드들이 <code>val</code>로 지정되어 있습니다. 필드를 <code>val</code>로 지정하면 도큐먼트의 특정 필드를 변경하기 위해 객체를 직접 수정한 뒤 <code>save</code>를 호출하는 방식이 불가능합니다. 이렇게 필드를 <code>val</code>로 지정하면 도큐먼트의 불변성을 보장하며, 특정 필드의 변경을 엄격히 관리할 수 있습니다.</p><h3><span id=\"repository-정의\">Repository 정의</span></h3><figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">MemberRepository</span> : <span class=\"type\">MongoRepository</span>&lt;<span class=\"type\">Member, ObjectId</span>&gt;, <span class=\"type\">MemberCustomRepository</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">MemberCustomRepository</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">fun</span> <span class=\"title\">updateName</span><span class=\"params\">(targets: <span class=\"type\">List</span>&lt;<span class=\"type\">MemberQueryForm</span>.<span class=\"type\">UpdateName</span>&gt;)</span></span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MemberCustomRepositoryImpl</span></span>(mongoTemplate: MongoTemplate) : MemberCustomRepository, MongoCustomRepositorySupport&lt;Member&gt;(Member::<span class=\"class\"><span class=\"keyword\">class</span>.<span class=\"title\">java</span>, <span class=\"type\">mongoTemplate) &#123;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">override</span> <span class=\"function\"><span class=\"keyword\">fun</span> <span class=\"title\">updateName</span><span class=\"params\">(targets: <span class=\"type\">List</span>&lt;<span class=\"type\">MemberQueryForm</span>.<span class=\"type\">UpdateName</span>&gt;)</span></span> &#123;</span><br><span class=\"line\">        bulkUpdate(</span><br><span class=\"line\">            targets.map &#123;</span><br><span class=\"line\">                Pair(</span><br><span class=\"line\">                    &#123; Query(Criteria.where(<span class=\"string\">\"id\"</span>).`<span class=\"keyword\">is</span>`(it.id)) &#125;,</span><br><span class=\"line\">                    &#123; Update().<span class=\"keyword\">set</span>(<span class=\"string\">\"name\"</span>, it.name) &#125;</span><br><span class=\"line\">                )</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        )</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><p><code>MongoCustomRepositorySupport</code>를 상속받아 <code>bulkUpdate</code> 메서드를 통해 <code>bulkOps</code>를 사용한 대량 업데이트를 수행합니다. 이를 활용하면 대량 데이터를 효율적으로 처리할 수 있으며, 단일 업데이트만 필요한 경우 <code>updateFirst</code>를 사용하여 업데이트를 수행할 수도 있습니다. 그러나 특별한 이유가 없다면 <code>MongoCustomRepositorySupport</code> 기반으로 대량 업데이트를 지원하는 <code>bulkUpdate</code>를 사용하는 것을 권장합니다.</p><p>이 방식에 대한 자세한 구현 방법은 이전 포스팅 <a href=\"https://cheese10yun.github.io/spring-data-mongodb-update-performance/\">MongoDB Update 성능 측정 및 분석 - MongoCustomRepositorySupport을 통한 bulkOps 기능 제공</a>에서 확인할 수 있습니다.</p><h3><span id=\"업데이트-쿼리에-사용할-객체-정의\">업데이트 쿼리에 사용할 객체 정의</span></h3><figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">object</span> MemberQueryForm &#123;</span><br><span class=\"line\">    <span class=\"keyword\">data</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">UpdateName</span></span>(</span><br><span class=\"line\">        <span class=\"keyword\">val</span> id: ObjectId,</span><br><span class=\"line\">        <span class=\"keyword\">val</span> name: String</span><br><span class=\"line\">    )</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><p><code>MemberQueryForm</code> 객체를 정의하여 쿼리에 필요한 필드와 데이터를 명확하게 관리합니다. 이를 통해 업데이트 작업에서 어떤 필드가 업데이트되는지 명확히 파악할 수 있습니다. 만약 <code>MemberQueryForm</code>에 정의되지 않은 필드가 있다면, 해당 필드는 현재 업데이트 대상이 아니거나 정책적으로 업데이트되지 않는 필드라고 간주할 수 있습니다.</p><h3><span id=\"테스트-코드-예시\">테스트 코드 예시</span></h3><figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@MongoTestSupport</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MemberRepositoryTest</span></span>(</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">val</span> memberRepository: MemberRepository</span><br><span class=\"line\">) : MongoStudyApplicationTests() &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Test</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">fun</span> `updateName test`<span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// given</span></span><br><span class=\"line\">        <span class=\"keyword\">val</span> members = (<span class=\"number\">1.</span><span class=\"number\">.20</span>).map &#123;</span><br><span class=\"line\">            Member(</span><br><span class=\"line\">                name = <span class=\"string\">\"name\"</span>,</span><br><span class=\"line\">                ...</span><br><span class=\"line\">            )</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">val</span> targets = mongoTemplate</span><br><span class=\"line\">            .insertAll(members).map &#123;</span><br><span class=\"line\">                MemberQueryForm.UpdateName(</span><br><span class=\"line\">                    id = it.id!!,</span><br><span class=\"line\">                    name = <span class=\"string\">\"newName\"</span></span><br><span class=\"line\">                )</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// when</span></span><br><span class=\"line\">        memberRepository.updateName(targets)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// then</span></span><br><span class=\"line\">        <span class=\"keyword\">val</span> results = mongoTemplate.findAll&lt;Member&gt;()</span><br><span class=\"line\"></span><br><span class=\"line\">        then(results).hasSize(<span class=\"number\">20</span>)</span><br><span class=\"line\">        then(results).allSatisfy &#123;</span><br><span class=\"line\">            then(it.name).isEqualTo(<span class=\"string\">\"newName\"</span>)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><p>해당 테스트 코드는 <code>MemberRepository</code>의 <code>updateName</code> 메서드를 검증합니다.</p><ol><li>먼저 <code>Member</code> 객체를 생성하고 MongoDB에 저장한 뒤, 저장된 데이터를 조회하여 <code>UpdateName</code> 객체를 생성합니다.</li><li>이후 <code>updateName</code> 메서드를 호출하여 업데이트를 수행합니다.</li><li>마지막으로 MongoDB에서 데이터를 다시 조회해, 업데이트가 성공적으로 이루어졌는지 확인합니다.</li></ol><p>이처럼 <code>MemberQueryForm</code> 객체를 사용해 업데이트 대상 필드를 명확히 정의함으로써, 변경 작업의 범위를 명확히 관리하고 추적할 수 있습니다. 테스트 코드 역시 이러한 명확성을 기반으로 업데이트 로직을 확인하도록 작성되었습니다.</p><h2><span id=\"정리\">정리</span></h2><p>제가 담당하는 도메인은 특정 필드마다 업데이트 권한이 다르게 설정되어 있어, 업데이트 필드를 보다 명확하고 엄격하게 관리해야 하는 상황입니다. 또한, 대량의 데이터를 처리해야 하며, 빠른 처리를 보장해야 하는 요구사항도 있습니다. 이러한 이유로, 위에서 설명한 방식의 업데이트 전략을 선택했습니다. 각자의 상황과 요구사항에 맞는 적절한 방법을 선택하는 것이 가장 중요합니다.</p>",
        "contentSnippet": "Spring Data MongoDB를 활용한 애플리케이션 개발 과정에서, 데이터를 업데이트하는 방법은 프로젝트의 설계와 성능에 큰 영향을 미칩니다. 특히, mongoRepository.save, mongoTemplate.save, 그리고 mongoTemplate.updateFirst와 같은 메서드들은 각각의 특성과 적합한 상황이 다릅니다. 이 글에서는 Spring Data MongoDB에서 업데이트 전략을 중심으로 개발 경험에서 얻은 인사이트를 공유하며, 각 메서드의 동작 방식과 적절한 사용 방법에 대해 논의합니다.\nUpdate 메서드 비교\nSpring Data MongoDB에서 사용되는 주요 업데이트 메서드들은 아래와 같이 동작 방식과 적합한 시나리오에서 차이가 있습니다:\n\n특징mongoRepository.savemongoTemplate.savemongoTemplate.updateFirst\n\n작업 대상단일 문서단일 문서단일 문서\n저장 방식변경된 필드만 업데이트전체 문서 교체변경된 필드만 업데이트\n문서가 없을 경우새로 삽입새로 삽입기본적으로 아무 작업도 수행하지 않음\n업데이트 범위필드 단위전체 문서필드 단위\n조건 지정_id 기준_id 기준사용자 정의 쿼리\nSpring Data 통합페이징, 정렬 등 지원미지원미지원\n적합한 상황간단한 CRUD 작업전체 문서 교체 또는 삽입조건에 맞는 단일 문서 필드 수정\n\nmongoTemplate.save\n문서 전체 교체(Replace)를 수행합니다.\n동작 방식\n\n_id 필드를 기준으로 MongoDB에서 문서를 검색.\n문서가 존재하면 전체 문서를 교체합니다.\n문서가 존재하지 않으면 새로 삽입합니다.\n저장 객체에 없는 필드는 기존 문서에서 삭제됩니다.\n\n예제\n\n\n1\n2\n\nval user = User(id = \"123\", name = \"John Doe\", age = 30)\nmongoTemplate.save(user)\n\n\n결과\n\n기존 문서: { \"_id\": \"123\", \"name\": \"Alice\", \"age\": 25, \"email\": \"alice@example.com\" }\n업데이트 후: { \"_id\": \"123\", \"name\": \"John Doe\", \"age\": 30 }\n변경 사항: email 필드가 삭제됨.\n\nmongoRepository.save\n문서의 일부 필드만 업데이트(Partial Update)를 수행합니다.\n동작 방식\n\n_id 필드를 기준으로 MongoDB에서 문서를 검색.\n문서가 존재하면 변경된 필드만 업데이트하고, 나머지 필드는 유지됩니다.\n문서가 존재하지 않으면 새로 삽입합니다.\n\n예제\n\n\n1\n2\n\nval user = User(id = \"123\", name = \"John Doe\")\nuserRepository.save(user)\n\n\n결과\n\n기존 문서: { \"_id\": \"123\", \"name\": \"Alice\", \"age\": 25, \"email\": \"alice@example.com\" }\n업데이트 후: { \"_id\": \"123\", \"name\": \"John Doe\", \"age\": 25, \"email\": \"alice@example.com\" }\n변경 사항: name 필드만 업데이트, 나머지 필드는 유지됨.\n\nmongoTemplate.updateFirst\nMongoDB의 updateFirst 명령어를 실행하여 단일 문서를 부분 업데이트합니다.\n동작 방식\n\n조건을 지정하여 MongoDB에서 문서를 검색.\n첫 번째로 매칭된 문서의 일부 필드만 업데이트합니다.\n문서가 존재하지 않으면 기본적으로 아무 작업도 수행하지 않습니다(삽입하지 않음).\n$set과 같은 MongoDB 연산자를 사용하여 지정된 필드만 업데이트합니다.\n\n예제\n\n\n1\n2\n3\n\nval query = Query(Criteria.where(\"name\").`is`(\"Alice\"))\nval update = Update().set(\"age\", 30)\nmongoTemplate.updateFirst(query, update, User::class.java)\n\n\n결과\n\n기존 문서: { \"_id\": \"123\", \"name\": \"Alice\", \"age\": 25, \"email\": \"alice@example.com\" }\n업데이트 후: { \"_id\": \"123\", \"name\": \"Alice\", \"age\": 30, \"email\": \"alice@example.com\" }\n변경 사항: age 필드만 업데이트, 나머지 필드는 유지됨.\n\n효율적인 MongoDB 업데이트 전략\nmongoTemplate.save는 문서 전체를 교체하기 때문에 일반적인 경우에는 거의 사용되지 않습니다. 반면, mongoRepository.save는 더 직관적이며, 특히 Spring Data JPA 경험이 있는 개발자에게는 익숙하고 이해하기 쉬운 방식입니다. 그럼에도 불구하고, 저는 업데이트 작업에 mongoTemplate기반의 업데이트만을 사용하고 있습니다. 그 이유는 다음과 같습니다.\n대량 처리에서의 성능 차이\nMongoDB Update 성능 측정 및 분석에서 업데이트 성능을 측정한 결과를 참고할 수 있습니다.\n\n\nRowssaveAllupdateFirstbulkOps (UNORDERED)bulkOps (ORDERED)\n\n1001,052 ms1,176 ms46 ms79 ms\n2002,304 ms2,196 ms103 ms124 ms\n5005,658 ms5,250 ms309 ms257 ms\n1,00011,106 ms10,846 ms418 ms412 ms\n2,00022,592 ms21,427 ms1,060 ms1,004 ms\n5,00054,407 ms52,075 ms2,663 ms2,292 ms\n10,000107,651 ms110,884 ms4,514 ms4,496 ms\n\n대량 처리를 할 경우 saveAll 방식은 내부적으로 반복문을 돌면서 save를 호출하는 방식으로 동작합니다. 이는 데이터베이스 요청을 문서별로 각각 보내기 때문에, 대량 처리 시 성능이 크게 저하됩니다. saveAll과 updateFirst는 모두 문서 단위로 데이터베이스 요청을 반복 호출하기 때문에 처리 성능이 거의 비슷하지만, 요청 수가 많아질수록 응답 시간이 급격히 증가하는 문제가 발생합니다.\n반면, bulkOps는 여러 업데이트 작업을 한 번의 연산으로 묶어서 실행하므로 대량 처리에서 훨씬 효율적입니다. 이를 통해 처리 시간을 크게 단축할 수 있지만, save와 saveAll 방식으로는 bulkOps를 활용할 수 없다는 한계가 있습니다. 이러한 이유로 저는 대량 처리 작업에서 updateFirst와 함께 bulkOps를 활용하는 방식을 선호합니다.\n또한, 대량 데이터를 업데이트할 때 where in 절을 활용하면 효과적입니다. 이 경우, mongoTemplate.updateMulti를 사용하면 bulkOps 방식과 유사한 성능을 얻을 수 있습니다. saveAll을 사용하면 성능이 급격히 저하되므로, 대량 데이터를 업데이트할 때는 반드시 mongoTemplate을 사용하는 것이 좋습니다. 이러한 접근 방식은 대량 처리의 효율성과 성능 최적화를 보장하며, 대량 데이터를 다루는 애플리케이션에서 더욱 유용합니다.\n명확한 변경 사항 추적\nmongoRepository.save를 사용하여 데이터를 업데이트할 경우, 정확히 어떤 필드가 변경되었는지 추적하기 어렵습니다. MongoDB는 비정형 데이터베이스로, 다양한 필드와 그 필드들이 다루는 컨텍스트가 매우 다양합니다. 이런 상황에서 mongoRepository.save를 통해 업데이트가 이루어지면, 어떤 필드가 어떤 조건에서 업데이트되었는지 명확히 파악하기 어렵기 때문에 데이터 변경 사항을 추적하고 관리하는 데 어려움이 발생할 수 있습니다.\n반면, mongoTemplate을 기반으로 업데이트 쿼리를 작성하면 특정 필드에 대해 명확히 정의된 업데이트를 수행할 수 있습니다. 각 업데이트가 어디에서 이루어졌는지, 어떤 필드가 변경되었는지를 코드 레벨에서 명확히 확인할 수 있어 추적이 용이합니다. 특히 프로젝트가 복잡해지거나 엄격한 변경 관리가 요구될수록, 이러한 명확성은 유지보수와 협업 측면에서 큰 장점으로 작용합니다. 이를 통해 데이터 업데이트의 불확실성을 줄이고, 코드의 가독성과 신뢰성을 높일 수 있습니다.\n실제 사용 예시\nDocument 정의\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n@Document(collection = \"members\")\nclass Member(\n    @Field(name = \"name\")\n    val name: String,\n\n    @Field(name = \"address\")\n    val address: Address,\n\n    @Field(name = \"member_id\")\n    val memberId: String,\n\n    @Field(name = \"email\")\n    val email: String,\n\n    @Field(name = \"status\")\n    val status: MemberStatus\n) : Auditable()\n\n\n위 예시와 같이 Member 도큐먼트가 정의되어 있다고 가정하겠습니다. 이 도큐먼트는 MongoRepository를 사용하여 업데이트하지 않기 때문에, 필드들이 val로 지정되어 있습니다. 필드를 val로 지정하면 도큐먼트의 특정 필드를 변경하기 위해 객체를 직접 수정한 뒤 save를 호출하는 방식이 불가능합니다. 이렇게 필드를 val로 지정하면 도큐먼트의 불변성을 보장하며, 특정 필드의 변경을 엄격히 관리할 수 있습니다.\nRepository 정의\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\ninterface MemberRepository : MongoRepository<Member, ObjectId>, MemberCustomRepository\n\ninterface MemberCustomRepository {\n    fun updateName(targets: List<MemberQueryForm.UpdateName>)\n}\n\nclass MemberCustomRepositoryImpl(mongoTemplate: MongoTemplate) : MemberCustomRepository, MongoCustomRepositorySupport<Member>(Member::class.java, mongoTemplate) {\n\n    override fun updateName(targets: List<MemberQueryForm.UpdateName>) {\n        bulkUpdate(\n            targets.map {\n                Pair(\n                    { Query(Criteria.where(\"id\").`is`(it.id)) },\n                    { Update().set(\"name\", it.name) }\n                )\n            }\n        )\n    }\n}\n\n\nMongoCustomRepositorySupport를 상속받아 bulkUpdate 메서드를 통해 bulkOps를 사용한 대량 업데이트를 수행합니다. 이를 활용하면 대량 데이터를 효율적으로 처리할 수 있으며, 단일 업데이트만 필요한 경우 updateFirst를 사용하여 업데이트를 수행할 수도 있습니다. 그러나 특별한 이유가 없다면 MongoCustomRepositorySupport 기반으로 대량 업데이트를 지원하는 bulkUpdate를 사용하는 것을 권장합니다.\n이 방식에 대한 자세한 구현 방법은 이전 포스팅 MongoDB Update 성능 측정 및 분석 - MongoCustomRepositorySupport을 통한 bulkOps 기능 제공에서 확인할 수 있습니다.\n업데이트 쿼리에 사용할 객체 정의\n\n\n1\n2\n3\n4\n5\n6\n\nobject MemberQueryForm {\n    data class UpdateName(\n        val id: ObjectId,\n        val name: String\n    )\n}\n\n\nMemberQueryForm 객체를 정의하여 쿼리에 필요한 필드와 데이터를 명확하게 관리합니다. 이를 통해 업데이트 작업에서 어떤 필드가 업데이트되는지 명확히 파악할 수 있습니다. 만약 MemberQueryForm에 정의되지 않은 필드가 있다면, 해당 필드는 현재 업데이트 대상이 아니거나 정책적으로 업데이트되지 않는 필드라고 간주할 수 있습니다.\n테스트 코드 예시\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n@MongoTestSupport\nclass MemberRepositoryTest(\n    private val memberRepository: MemberRepository\n) : MongoStudyApplicationTests() {\n\n    @Test\n    fun `updateName test`() {\n        // given\n        val members = (1..20).map {\n            Member(\n                name = \"name\",\n                ...\n            )\n        }\n\n        val targets = mongoTemplate\n            .insertAll(members).map {\n                MemberQueryForm.UpdateName(\n                    id = it.id!!,\n                    name = \"newName\"\n                )\n            }\n\n        // when\n        memberRepository.updateName(targets)\n\n        // then\n        val results = mongoTemplate.findAll<Member>()\n\n        then(results).hasSize(20)\n        then(results).allSatisfy {\n            then(it.name).isEqualTo(\"newName\")\n        }\n    }\n}\n\n\n해당 테스트 코드는 MemberRepository의 updateName 메서드를 검증합니다.\n\n먼저 Member 객체를 생성하고 MongoDB에 저장한 뒤, 저장된 데이터를 조회하여 UpdateName 객체를 생성합니다.\n이후 updateName 메서드를 호출하여 업데이트를 수행합니다.\n마지막으로 MongoDB에서 데이터를 다시 조회해, 업데이트가 성공적으로 이루어졌는지 확인합니다.\n\n이처럼 MemberQueryForm 객체를 사용해 업데이트 대상 필드를 명확히 정의함으로써, 변경 작업의 범위를 명확히 관리하고 추적할 수 있습니다. 테스트 코드 역시 이러한 명확성을 기반으로 업데이트 로직을 확인하도록 작성되었습니다.\n정리\n제가 담당하는 도메인은 특정 필드마다 업데이트 권한이 다르게 설정되어 있어, 업데이트 필드를 보다 명확하고 엄격하게 관리해야 하는 상황입니다. 또한, 대량의 데이터를 처리해야 하며, 빠른 처리를 보장해야 하는 요구사항도 있습니다. 이러한 이유로, 위에서 설명한 방식의 업데이트 전략을 선택했습니다. 각자의 상황과 요구사항에 맞는 적절한 방법을 선택하는 것이 가장 중요합니다.",
        "summary": "\n    \n      \n      \n        <p>Spring Data MongoDB를 활용한 애플리케이션 개발 과정에서, 데이터를 업데이트하는 방법은 프로젝트의 설계와 성능에 큰 영향을 미칩니다. 특히, <code>mongoRepository.save</code>, <code>mongoTemp\n      \n    \n    ",
        "id": "https://cheese10yun.github.io/spring-data-mongo-update-guide-1/",
        "isoDate": "2025-01-18T14:24:07.000Z"
      }
    ]
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": [
      {
        "creator": "강철 벼룩",
        "title": "ARM 템플릿을 사용한 인프라 배포 시 만날 수 있는 오류",
        "link": "http://www.dokyun.pe.kr/352",
        "pubDate": "Sun, 19 Jan 2025 00:24:40 +0900",
        "author": "강철 벼룩",
        "comments": "http://www.dokyun.pe.kr/352#entry352comment",
        "content": "<h3 data-ke-size=\"size23\">Errors&nbsp;you&nbsp;may&nbsp;encounter&nbsp;when&nbsp;deploying&nbsp;infrastructure&nbsp;with&nbsp;ARM&nbsp;templates</h3>\n<p data-ke-size=\"size18\">기존 가상 네트워크를 업데이트하는 update-vnet.json 이라는 ARM 템플릿을 작성했다.</p>\n<p data-ke-size=\"size18\">다음의 Azure Cli 스크립트를 통해 이 템플릿을 적용했다.</p>\n<pre id=\"code_1737212932841\" class=\"bash\" data-ke-language=\"bash\" data-ke-type=\"codeblock\"><code>az deployment group create --resource-group $rgName --name UpdateVNet --template-file .\\update-vnet.json</code></pre>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">이 스크립트 실행 중에 다음과 같은 오류를 만났다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"876\" data-origin-height=\"231\"><span data-url=\"https://blog.kakaocdn.net/dn/Ccycb/btsLTGNKVJ8/qAMKIg1ETkf2is9WBxss6k/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Ccycb/btsLTGNKVJ8/qAMKIg1ETkf2is9WBxss6k/img.png\"><img src=\"https://blog.kakaocdn.net/dn/Ccycb/btsLTGNKVJ8/qAMKIg1ETkf2is9WBxss6k/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FCcycb%2FbtsLTGNKVJ8%2FqAMKIg1ETkf2is9WBxss6k%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"876\" height=\"231\" data-origin-width=\"876\" data-origin-height=\"231\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">이 오류에서 사각형 박스 내의 문구가 문제를 해결하는 단서다.</p>\n<p data-ke-size=\"size18\">현재 구독과 리소스 그룹에서 진행 중인 배포는 없었으며, 진행 완료된 기존 배포는 성공 상태로 종료한 것으로 확인했다. 혹시나 해서 구독과 리소스 그룹의 배포 섹션에 나열된 모든 배포를 제거하고 다시 시도해보아도 동일한 문제가 발생했다.</p>\n<p data-ke-size=\"size18\">잠깐 생각을 하다가 떠오른 부분은 현재 배포하는 ARM 템플릿의 배포 이름의 고유성으로 인한 문제인가 싶었다. 그래서 <b><span style=\"color: #006dd7;\"><u>다음 그림의 사각형 박스를&nbsp; 기존의 평이한 배포 이름인 \"UpdateVnet\"을 고유한 이름으로 변경하고 다시 템플릿을 적용했을 때 비로소 문제가 해결 되었다.</u></span></b></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"994\" data-origin-height=\"580\"><span data-url=\"https://blog.kakaocdn.net/dn/cn7Dah/btsLSdM4Mwx/KmjeWkczrwagT3GXtrj0u1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cn7Dah/btsLSdM4Mwx/KmjeWkczrwagT3GXtrj0u1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cn7Dah/btsLSdM4Mwx/KmjeWkczrwagT3GXtrj0u1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fcn7Dah%2FbtsLSdM4Mwx%2FKmjeWkczrwagT3GXtrj0u1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"994\" height=\"580\" data-origin-width=\"994\" data-origin-height=\"580\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">이 외에도 내 구독이나 리소스 그룹에서 실제 배포중인 상태라면&nbsp; 배포 완료나 실패를 기다리거나, 진행 중인 다른 배포를 취소하고 다시 배포를 시도할 수 있다.</p>",
        "contentSnippet": "Errors you may encounter when deploying infrastructure with ARM templates\n기존 가상 네트워크를 업데이트하는 update-vnet.json 이라는 ARM 템플릿을 작성했다.\n다음의 Azure Cli 스크립트를 통해 이 템플릿을 적용했다.\naz deployment group create --resource-group $rgName --name UpdateVNet --template-file .\\update-vnet.json\n \n이 스크립트 실행 중에 다음과 같은 오류를 만났다.\n\n\n \n이 오류에서 사각형 박스 내의 문구가 문제를 해결하는 단서다.\n현재 구독과 리소스 그룹에서 진행 중인 배포는 없었으며, 진행 완료된 기존 배포는 성공 상태로 종료한 것으로 확인했다. 혹시나 해서 구독과 리소스 그룹의 배포 섹션에 나열된 모든 배포를 제거하고 다시 시도해보아도 동일한 문제가 발생했다.\n잠깐 생각을 하다가 떠오른 부분은 현재 배포하는 ARM 템플릿의 배포 이름의 고유성으로 인한 문제인가 싶었다. 그래서 다음 그림의 사각형 박스를  기존의 평이한 배포 이름인 \"UpdateVnet\"을 고유한 이름으로 변경하고 다시 템플릿을 적용했을 때 비로소 문제가 해결 되었다.\n\n\n \n이 외에도 내 구독이나 리소스 그룹에서 실제 배포중인 상태라면  배포 완료나 실패를 기다리거나, 진행 중인 다른 배포를 취소하고 다시 배포를 시도할 수 있다.",
        "guid": "http://www.dokyun.pe.kr/352",
        "categories": [
          "Azure &amp; Windows/Azure",
          "ARM",
          "azure",
          "IAC"
        ],
        "isoDate": "2025-01-18T15:24:40.000Z"
      }
    ]
  },
  {
    "name": "김상훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": [
      {
        "title": "리눅스 컴플렉스",
        "link": "https://elky84.github.io/2025/01/19/linux_complex/",
        "pubDate": "Sun, 19 Jan 2025 00:00:00 +0000",
        "content": "<h1 id=\"개요\">개요</h1>\n<p>나는 게임 클라이언트 프로그래머 지망생이었다.</p>\n\n<p>그리고 첫 취업을 한 2005년 당시에는 당연하게도 윈도우를 썼고, 윈도우용 게임을 개발해야 했으며, 클라이언트다 보니 당시 서버가 (당시엔 당연한 줄 알았지만 보기 드문)리눅스용 소켓서버였음에도 나는 윈도우만 썼다.</p>\n\n<p>그리고 그게 전혀 이상하지 않았다.</p>\n\n<p>나에게 리눅스란 먼 존재였다.</p>\n\n<p>내가 직접 게임 서버를 개발한 시기에는 리눅스 서버가 아닌 윈도우 게임 서버를 썼기에, 리눅스를 잘 써야 할 상황은 없었다.</p>\n\n<p>2014년까지의 나에게 리눅스는 먼 존재였고, 책에서 읽으면 리눅스에 대한 호기심이 생기긴 했지만, 업무에서 쓸 확률이 낮은 OS를 가볍게 쓰는 것 이외에는 하기 어려웠고, 파고들기엔 다른 중요한 것들이 너무나 많았다.</p>\n\n<h1 id=\"컴플렉스\">컴플렉스</h1>\n\n<p>나는 게임에서도 관심가는 게임이라면 찍먹이라도 해봐야 하는 성향이다.</p>\n\n<p>현실적 이슈로 못할 지언정, 성향적으로 그렇다보니 리눅스에 대해 분명히 관심이 생겼는데 이를 해소하지 못한 불편함이 마음 한켠에 존재했다.</p>\n\n<p>특히 IT 관련 서적을 읽을 때 마다, 해킹 관련 서적은 물론이고, 다양한 기술 서적의 실습에서도 제약이 따르는 기분을 지울 수가 없었다.</p>\n\n<p>또한 리눅스와 유닉스의 그 문화를 공감하지 못한다는 것이 더욱 큰 아쉬움이자 불편한 마음을 만들었다.</p>\n\n<h1 id=\"해소\">해소</h1>\n\n<p>2015년 즈음 나는 루비 온 레일즈로 리눅스 환경에서 서비스를 배포하고, 처음으로 웹 서버로 게임을 서비스하게 됐다. 물론 게임 서버로써였고, API 서버에 가까웠으며, 나의 많은 업무 시간은 유니티 클라이언트 개발도 하다보니 리눅스 이해도가 높아지진 않았따.</p>\n\n<p>2년여가 더 지낫 결국 여러가지 이유가 복합적이었지만 나는 플랫폼 개발자로 전향해보기로 했고, 마침 그 회사가 당시 트래픽이 많던 넷마블이었고, 심지어 그 부서가 Private Cloud를 개발하는 부서라서 인프라를 제공하는 과정에서 다양한 팀의 리눅스 환경 구성을 돕게 됐고, 이로 인해 나 역시 자연스레 리눅스 이해도가 극적으로 높아졌다.</p>\n\n<p>메인 데스크탑은 여전히 윈도우였지만, 적어도 리눅스 서버에서 하게 되는 수 많은 작업이 나에게 리눅스 이해도를 높여줬다.</p>\n\n<p>특히 당시만 해도 Docker가 활성화되기 전이라, daemonize와 배포 및 가동에 골치를 썩었는데 이러한 과정 역시 나에게 리눅스 이해도를 높여주게 됐다.</p>\n\n<p>이 시기 쯤해서 홈 서버를 리눅스로 바꾸기 시작했다.</p>\n\n<p>중간에 라즈베리 파이로 홈서버를 쓰기도 했으나 너무 저성능이라 결국 미니 PC로 바꾸긴 했지만, 라즈베리 파이 역시 리눅스를 깔아서 썼다.</p>\n\n<p>여러 이슈를 겪으면서 막연한 두려움은 사라지고 훨씬 더 익숙해져서 나에게 서버는 리눅스가 더 익숙해지기까지 했는데, 이 과정으로 오는 과정에 리눅스 데스크탑 강제로 써보기, 맥만 쓰기 운동 등을 통해서 익숙하지 않은 환경을 강제화 하는 것도 크게 도움이 됐다.</p>\n\n<h1 id=\"마치며\">마치며</h1>\n\n<p>리눅스는 나에게 있어 컴플렉스가 아니게 됐는데, 아마도 그렇게 된 시점이 내가 순혈 게임 개발자로 남는 길 보다, 다재다능한 제너럴 리스트가 되기로 마음 먹고, 노력하는 과정에서 극복 된 것 같다.</p>\n\n<p>이미 익숙하고, 많은 경험을 쌓은 환경을 선호하는 것은 나 역시 마찬가지 였고, 배우는 것 까지는 좋아하는 개발자가 많지만, 익숙하지 않은 환경에서 낮은 퍼포먼스가 날 때의 저항감을 이겨내는 것이 쉽지 않은데, 나는 이 과정을 전향과, 집에서의 Dev Toy와 학습, 회사에서도 가능한 상황에선 강제로 OS를 바꿔서 사용해보며 극복하고자 했었다.</p>\n\n<p>순혈 게임 서버 개발자는 평생 윈도우 게임 서버만으로 서비스 할 수도 있는데, 그러한 개발자가 어떻게 리눅스와 리눅스 서버에 익숙해졌는지 가볍게 이야기 해보고 싶었다.</p>\n",
        "contentSnippet": "개요\n나는 게임 클라이언트 프로그래머 지망생이었다.\n그리고 첫 취업을 한 2005년 당시에는 당연하게도 윈도우를 썼고, 윈도우용 게임을 개발해야 했으며, 클라이언트다 보니 당시 서버가 (당시엔 당연한 줄 알았지만 보기 드문)리눅스용 소켓서버였음에도 나는 윈도우만 썼다.\n그리고 그게 전혀 이상하지 않았다.\n나에게 리눅스란 먼 존재였다.\n내가 직접 게임 서버를 개발한 시기에는 리눅스 서버가 아닌 윈도우 게임 서버를 썼기에, 리눅스를 잘 써야 할 상황은 없었다.\n2014년까지의 나에게 리눅스는 먼 존재였고, 책에서 읽으면 리눅스에 대한 호기심이 생기긴 했지만, 업무에서 쓸 확률이 낮은 OS를 가볍게 쓰는 것 이외에는 하기 어려웠고, 파고들기엔 다른 중요한 것들이 너무나 많았다.\n컴플렉스\n나는 게임에서도 관심가는 게임이라면 찍먹이라도 해봐야 하는 성향이다.\n현실적 이슈로 못할 지언정, 성향적으로 그렇다보니 리눅스에 대해 분명히 관심이 생겼는데 이를 해소하지 못한 불편함이 마음 한켠에 존재했다.\n특히 IT 관련 서적을 읽을 때 마다, 해킹 관련 서적은 물론이고, 다양한 기술 서적의 실습에서도 제약이 따르는 기분을 지울 수가 없었다.\n또한 리눅스와 유닉스의 그 문화를 공감하지 못한다는 것이 더욱 큰 아쉬움이자 불편한 마음을 만들었다.\n해소\n2015년 즈음 나는 루비 온 레일즈로 리눅스 환경에서 서비스를 배포하고, 처음으로 웹 서버로 게임을 서비스하게 됐다. 물론 게임 서버로써였고, API 서버에 가까웠으며, 나의 많은 업무 시간은 유니티 클라이언트 개발도 하다보니 리눅스 이해도가 높아지진 않았따.\n2년여가 더 지낫 결국 여러가지 이유가 복합적이었지만 나는 플랫폼 개발자로 전향해보기로 했고, 마침 그 회사가 당시 트래픽이 많던 넷마블이었고, 심지어 그 부서가 Private Cloud를 개발하는 부서라서 인프라를 제공하는 과정에서 다양한 팀의 리눅스 환경 구성을 돕게 됐고, 이로 인해 나 역시 자연스레 리눅스 이해도가 극적으로 높아졌다.\n메인 데스크탑은 여전히 윈도우였지만, 적어도 리눅스 서버에서 하게 되는 수 많은 작업이 나에게 리눅스 이해도를 높여줬다.\n특히 당시만 해도 Docker가 활성화되기 전이라, daemonize와 배포 및 가동에 골치를 썩었는데 이러한 과정 역시 나에게 리눅스 이해도를 높여주게 됐다.\n이 시기 쯤해서 홈 서버를 리눅스로 바꾸기 시작했다.\n중간에 라즈베리 파이로 홈서버를 쓰기도 했으나 너무 저성능이라 결국 미니 PC로 바꾸긴 했지만, 라즈베리 파이 역시 리눅스를 깔아서 썼다.\n여러 이슈를 겪으면서 막연한 두려움은 사라지고 훨씬 더 익숙해져서 나에게 서버는 리눅스가 더 익숙해지기까지 했는데, 이 과정으로 오는 과정에 리눅스 데스크탑 강제로 써보기, 맥만 쓰기 운동 등을 통해서 익숙하지 않은 환경을 강제화 하는 것도 크게 도움이 됐다.\n마치며\n리눅스는 나에게 있어 컴플렉스가 아니게 됐는데, 아마도 그렇게 된 시점이 내가 순혈 게임 개발자로 남는 길 보다, 다재다능한 제너럴 리스트가 되기로 마음 먹고, 노력하는 과정에서 극복 된 것 같다.\n이미 익숙하고, 많은 경험을 쌓은 환경을 선호하는 것은 나 역시 마찬가지 였고, 배우는 것 까지는 좋아하는 개발자가 많지만, 익숙하지 않은 환경에서 낮은 퍼포먼스가 날 때의 저항감을 이겨내는 것이 쉽지 않은데, 나는 이 과정을 전향과, 집에서의 Dev Toy와 학습, 회사에서도 가능한 상황에선 강제로 OS를 바꿔서 사용해보며 극복하고자 했었다.\n순혈 게임 서버 개발자는 평생 윈도우 게임 서버만으로 서비스 할 수도 있는데, 그러한 개발자가 어떻게 리눅스와 리눅스 서버에 익숙해졌는지 가볍게 이야기 해보고 싶었다.",
        "guid": "https://elky84.github.io/2025/01/19/linux_complex/",
        "categories": [
          "Windows",
          "Linux",
          "OS",
          "OS"
        ],
        "isoDate": "2025-01-19T00:00:00.000Z"
      },
      {
        "title": "윈도우도 훌륭한 개발머신이라구",
        "link": "https://elky84.github.io/2025/01/18/good_dev_os_windows/",
        "pubDate": "Sat, 18 Jan 2025 00:00:00 +0000",
        "content": "<h1 id=\"개요\">개요</h1>\n\n<p>한국에서 많은 웹이나 앱 개발자의 많은 수가 맥을 선택하고 있다.</p>\n\n<p>나 역시 2018년 이후 맥을 병행해서 쓰고 있고, 특정한 시기에는 온리 맥도 썼던 입장에서 맥의 장점도 이해하고 공감하는 부분이 있다.</p>\n\n<p>특히 인텔 맥 때의 애매함을 이겨낸 애플 실리콘 칩 이후의 맥은 ARM 데스크탑의 시대를 열었고 그 만족도는 나 역시 체감하고 있다.</p>\n\n<p>M1 맥북 에어는 교체의 필요성을 못느낄 만큼 만족하고 있고, 특히 여행이나 집 안에서 가벼운 코딩이나, 타이핑에서 아주 잘 쓰고 있다.</p>\n\n<p>개인적으로 오래 써오던 리눅스 미니 데스크탑도 맥미니로 교체하고 싶을 정도니 말이다.</p>\n\n<p>나는 게임 개발자로써 살아온 커리어도 길고, 게이머로써의 아이덴티티도 강하다 보니 윈도우가 좋은 측면이 있다.</p>\n\n<p>하지만 개발에서 아쉬움이 있었다면 윈도우를 메인 데스크탑으로 쓸 이유가 없는 상황이다.</p>\n\n<p>이미 맥북만 써서 개발했던 기간도 5년이었고, 맥과 윈도우 (+WSL), 리눅스 데스크탑 OS (노트북으로) 사용한지도 8년이 넘었는데, 사실 어떤 OS를 써도 크게 이질감이 들지 않게 적응한 상황이기 때문이다.</p>\n\n<p>이렇게 다 사용해본 입장에서 종종 나오는 논란에 대해서 이야기해보고자 한다.</p>\n\n<h1 id=\"논란\">논란</h1>\n\n<h2 id=\"맥은-리눅스가-아니다\">맥은 리눅스가 아니다</h2>\n<p>종종 리눅스 서버 개발에 친화적이라는 이야기를 하는 사람을 자주 본다.</p>\n\n<p>맥은 Darwin 커널 기반의 별개의 OS지 리눅스가 아니다.</p>\n\n<p>리눅스 개발 환경과 유사한 점은 유닉스 라이크라고 보는 것이 맞고, 이로 인해 꽤 많은 차이가 나서 동일한 동작을 보장하지 않는다.</p>\n\n<h2 id=\"wsl2\">WSL2</h2>\n\n<p><strong>WSL(Windows Subsystem for Linux)</strong> 은 리눅스 호환률이 macOS보다 더 높은 편이다.</p>\n\n<p>이는 WSL의 구조와 설계 방식이 리눅스와 직접적인데, WSL2는 리눅스 커널을 실제로 실행한다.</p>\n\n<p>WSL1은 에뮬레이션 방식 이었지만, WSL2는 커널이다 커널.</p>\n\n<p>당연히 훨씬 더 높은 호환성을 보여준다.</p>\n<h2 id=\"리눅스-데스크탑은-어때\">리눅스 데스크탑은 어때?</h2>\n\n<p>리눅스 데스크탑을 쓰면 여러가지 지식이 늘어난다.</p>\n\n<p>각종 오류 (…) 발생 시 커맨드 라인 명령어를 써서 해결 해야 되는 상황들, 그리고 부족한 레퍼런스, 정식으로 지원되지 않은 수많은 앱 (다수의 앱이 윈도우나 맥 온리 또는 윈도우와 맥을 지원한다)이 개발자로써의 나를 강하게 성장시켜준다. (강해지고 싶다면 오라)</p>\n\n<h1 id=\"마치며\">마치며</h1>\n\n<p>조만간 리눅스 이야기를 좀 더 하게 되겠지만, 개인적으로 리눅스에 익숙해진 뒤에도 여전히 윈도우를 쓰는 이유에 게임이 무관하지 않다.</p>\n\n<p>다만 콘솔 켜듯이 충분히 윈도우도 스위칭해서 쓸 수 있음에도 개발 머신으로도 쓰는 것은, 철저히 윈도우가 개발 머신으로 훌륭하기 때문이다.</p>\n\n<p>특히 많은 사람들이 불편을 말하는 포인트 대다수가 WSL2+VS Code를 연동하면 해결되는 이슈이기도하고, 윈도우를 사용하면서 발생되는 문제도 과거에 비하면 매우 줄어들기도 했다.</p>\n\n<p>사실 개인적으로는 지금은 많이 해소 됐지만 m1 맥북 넘어오면서 아키텍쳐 변경으로 인한 호환성 이슈가 꽤 길기도 했고, 그러한 문제 이외에도 나는 리눅스 서버 개발에 더 편한 경험을 못했는데, 감안할만한 수준이라는 점은 나 역시 공감한다.</p>\n\n<p>또한 프론트엔드 개발자라면 맥 OS를 쓰면서 겪는 이슈나 문제가 없을 가능성도 높고 맥의 장점 위주로 체감할 확률이 높다는 것 역시 인정하한다.</p>\n\n<p>다만 맥을 써야만 개발이 편하다는 편견 대신 윈도우가 개발 머신으로 부족하거나 문제가 있는게 아니고 충분한 선택지이며, 리눅스 데스크탑도 쓸만하다는 이야기를 하고 싶었다.</p>\n\n",
        "contentSnippet": "개요\n한국에서 많은 웹이나 앱 개발자의 많은 수가 맥을 선택하고 있다.\n나 역시 2018년 이후 맥을 병행해서 쓰고 있고, 특정한 시기에는 온리 맥도 썼던 입장에서 맥의 장점도 이해하고 공감하는 부분이 있다.\n특히 인텔 맥 때의 애매함을 이겨낸 애플 실리콘 칩 이후의 맥은 ARM 데스크탑의 시대를 열었고 그 만족도는 나 역시 체감하고 있다.\nM1 맥북 에어는 교체의 필요성을 못느낄 만큼 만족하고 있고, 특히 여행이나 집 안에서 가벼운 코딩이나, 타이핑에서 아주 잘 쓰고 있다.\n개인적으로 오래 써오던 리눅스 미니 데스크탑도 맥미니로 교체하고 싶을 정도니 말이다.\n나는 게임 개발자로써 살아온 커리어도 길고, 게이머로써의 아이덴티티도 강하다 보니 윈도우가 좋은 측면이 있다.\n하지만 개발에서 아쉬움이 있었다면 윈도우를 메인 데스크탑으로 쓸 이유가 없는 상황이다.\n이미 맥북만 써서 개발했던 기간도 5년이었고, 맥과 윈도우 (+WSL), 리눅스 데스크탑 OS (노트북으로) 사용한지도 8년이 넘었는데, 사실 어떤 OS를 써도 크게 이질감이 들지 않게 적응한 상황이기 때문이다.\n이렇게 다 사용해본 입장에서 종종 나오는 논란에 대해서 이야기해보고자 한다.\n논란\n맥은 리눅스가 아니다\n종종 리눅스 서버 개발에 친화적이라는 이야기를 하는 사람을 자주 본다.\n맥은 Darwin 커널 기반의 별개의 OS지 리눅스가 아니다.\n리눅스 개발 환경과 유사한 점은 유닉스 라이크라고 보는 것이 맞고, 이로 인해 꽤 많은 차이가 나서 동일한 동작을 보장하지 않는다.\nWSL2\nWSL(Windows Subsystem for Linux) 은 리눅스 호환률이 macOS보다 더 높은 편이다.\n이는 WSL의 구조와 설계 방식이 리눅스와 직접적인데, WSL2는 리눅스 커널을 실제로 실행한다.\nWSL1은 에뮬레이션 방식 이었지만, WSL2는 커널이다 커널.\n당연히 훨씬 더 높은 호환성을 보여준다.\n리눅스 데스크탑은 어때?\n리눅스 데스크탑을 쓰면 여러가지 지식이 늘어난다.\n각종 오류 (…) 발생 시 커맨드 라인 명령어를 써서 해결 해야 되는 상황들, 그리고 부족한 레퍼런스, 정식으로 지원되지 않은 수많은 앱 (다수의 앱이 윈도우나 맥 온리 또는 윈도우와 맥을 지원한다)이 개발자로써의 나를 강하게 성장시켜준다. (강해지고 싶다면 오라)\n마치며\n조만간 리눅스 이야기를 좀 더 하게 되겠지만, 개인적으로 리눅스에 익숙해진 뒤에도 여전히 윈도우를 쓰는 이유에 게임이 무관하지 않다.\n다만 콘솔 켜듯이 충분히 윈도우도 스위칭해서 쓸 수 있음에도 개발 머신으로도 쓰는 것은, 철저히 윈도우가 개발 머신으로 훌륭하기 때문이다.\n특히 많은 사람들이 불편을 말하는 포인트 대다수가 WSL2+VS Code를 연동하면 해결되는 이슈이기도하고, 윈도우를 사용하면서 발생되는 문제도 과거에 비하면 매우 줄어들기도 했다.\n사실 개인적으로는 지금은 많이 해소 됐지만 m1 맥북 넘어오면서 아키텍쳐 변경으로 인한 호환성 이슈가 꽤 길기도 했고, 그러한 문제 이외에도 나는 리눅스 서버 개발에 더 편한 경험을 못했는데, 감안할만한 수준이라는 점은 나 역시 공감한다.\n또한 프론트엔드 개발자라면 맥 OS를 쓰면서 겪는 이슈나 문제가 없을 가능성도 높고 맥의 장점 위주로 체감할 확률이 높다는 것 역시 인정하한다.\n다만 맥을 써야만 개발이 편하다는 편견 대신 윈도우가 개발 머신으로 부족하거나 문제가 있는게 아니고 충분한 선택지이며, 리눅스 데스크탑도 쓸만하다는 이야기를 하고 싶었다.",
        "guid": "https://elky84.github.io/2025/01/18/good_dev_os_windows/",
        "categories": [
          "Windows",
          "Mac",
          "Linux",
          "OS",
          "OS"
        ],
        "isoDate": "2025-01-18T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "나라를 위해서 일한다는 거짓말",
        "link": "https://kangmyounghun.blogspot.com/2025/01/blog-post.html",
        "pubDate": "2025-01-22T09:05:00.001Z",
        "author": "강명훈",
        "content": "<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiLcVGNrRzaIo4NnO-rAgjNsnQMGP6qfCjqIMoW0Wx8Qulf2HazOngJA3-tzIB5J4QDtWO9PQ42kbbPeRXTd2eptfSHPD-ma4cJGUxPtGgXltA1zFC5SFhRwsf1sH4EzNYoWjSK-Gbspf_haOLYTnM-lxHNdyQD-TM82ZHMXGFy11uXozQ0fgEJG_kewuNB/s1200/XL.jpg\" style=\"clear: left; float: left; margin-bottom: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"1200\" data-original-width=\"809\" height=\"320\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiLcVGNrRzaIo4NnO-rAgjNsnQMGP6qfCjqIMoW0Wx8Qulf2HazOngJA3-tzIB5J4QDtWO9PQ42kbbPeRXTd2eptfSHPD-ma4cJGUxPtGgXltA1zFC5SFhRwsf1sH4EzNYoWjSK-Gbspf_haOLYTnM-lxHNdyQD-TM82ZHMXGFy11uXozQ0fgEJG_kewuNB/s320/XL.jpg\" width=\"216\" /></a></div>\n<div>노한동 문체부 전 서기관이 10년 공직 경험을 바탕으로 쓴 자전 에세이.</div>\n<div><br /></div>\n<div>전도유망한 30대 서기관이 공직을 그만두고 책을 쓴 이유는 무엇일까? 저자는 그 이유를 '헛짓거리', '가짜 노동', '쓸데없는 일' 세 단어로 고백한다.</div>\n<div><blockquote style=\"text-align: center;\"><i>공직사회의 일이란 그저 관습에 따르거나 기관장을 빛내기 위한 거대한 비효율의 반복</i> <span style=\"font-size: x-small;\">(83페이지)</span></blockquote></div>\n<div><blockquote style=\"text-align: center;\"><i>진짜 필요한 일이 아닌 헛짓거리에 자신의 인생을 갈아 넣으며 느끼는 공무원들의 자괴감</i> <span style=\"font-size: x-small;\">(188페이지)</span></blockquote></div>\n<div><blockquote style=\"text-align: center;\"><i>공직사회는 일을 못한다. 관료가 게을러서도, 철밥통이어서도 아니다. 그저 쓸데없는 일이 너무 많아서다</i> <span style=\"font-size: x-small;\">(274페이지)</span></blockquote></div>\n<div><br /></div>\n<div>누가 그랬다. 노동 없는 삶은 부패하지만 영혼 없는 노동은 삶을 질식시킨다고.&nbsp;</div>\n<div><br /></div><span><a name='more'></a></span>\n<div><b><span style=\"font-size: x-large;\">짧디 짧은 1년 반의 공직 시절이 떠올랐다&nbsp;</span></b></div>\n<div><br /></div>\n<div>모 부처 소속기관에서 4년 반을 일했다. 3년은 민간인으로, 1년 반은 공무원으로. 보안장비 룰 정확도 개선을 목표로 3년을 노력했지만 쉽지 않았다. 공무원은 과거 어떤 사업자도 언급하지 않던 업무의 필요성을 이해하지 못했고, 그런 업무를 시도하는 나도 이해하지 못했다.</div><div><br /></div><div><span></span></div><div>그래서 그만 두고 책을 썼다. 이후 해당 기관의 5급 계약직 채용 공고를 보게 됐을 때 살짝 설렜다. 민간인 신분으로 일할 당시 접했던 실무 최고 책임자가 사무관이었기 때문에 채용되면 소신을 가지고 주도적으로 일할 수 있겠다는 생각이 들었던 것.</div><div><br /></div><div>물론 현실은 달랐다. 잠시 룰 정확도에&nbsp;관심을 주던 기관장은 이내 성과 어필에 더 유리한 빅데이터로 관심을 돌렸다. 솔직히 입장 바뀌면 나라도 그랬지 싶다. 당시 그만큼 핫한 아이템은 없었으니까.</div><div><blockquote style=\"text-align: center;\"><i><a href=\"https://kangmyounghun.blogspot.com/2018/07/blog-post_17.html\" target=\"_blank\">사람들은 포르쉐를 부러워하지, 운전 실력을 부러워하지 않는다. 자본주의 세상에서 비싼 포르쉐는 성공의 상징이기 때문. 비슷한 연유로 빅데이터나 인공지능같은 최신&nbsp;미국 기술은 정보보안, 나아가 IT 분야의 포르쉐가 된다.</a></i></blockquote></div>\n  <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh-3f3B1_Qr88QWfol8Nvy7yRYsvs7DE9w25mqPu7b-aT93AYtYbX5MX_57wXCW_IDAefjZiDrNNVcusIhpjtRPEKp9qWlcE5-3RxELLYi8vezOdDRIO1k1EhTUmdurTLs8tcIpyszbU9N3UOaPpro9Wjge431smxLwAPiEXIsoq7Z1m49aWxZqYGcPuBl5/s1280/before.png\" imageanchor=\"1\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"487\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh-3f3B1_Qr88QWfol8Nvy7yRYsvs7DE9w25mqPu7b-aT93AYtYbX5MX_57wXCW_IDAefjZiDrNNVcusIhpjtRPEKp9qWlcE5-3RxELLYi8vezOdDRIO1k1EhTUmdurTLs8tcIpyszbU9N3UOaPpro9Wjge431smxLwAPiEXIsoq7Z1m49aWxZqYGcPuBl5/s16000/before.png\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><b>보안 수준 향상이 최우선 과제였던 빅데이터</b></td></tr></tbody></table><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhPPaWBDWwdp1nudsv8l7h-ljprehmBQvIuGXAiKlnYpTG2xXhU8L42mlt5D6ab74OI4kwEav4HEmxFqLWW7FmimYd_SnFBqo5YI9xuTvgM3pF94d3OwJ8DUJktygWXvMX08yOyW520e6fJiw0MtO5RJ1Jc7zmHSjGmbRws8WlGcVFH0UGtCkSNbhCQb0ox/s1280/after.png\" imageanchor=\"1\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"485\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhPPaWBDWwdp1nudsv8l7h-ljprehmBQvIuGXAiKlnYpTG2xXhU8L42mlt5D6ab74OI4kwEav4HEmxFqLWW7FmimYd_SnFBqo5YI9xuTvgM3pF94d3OwJ8DUJktygWXvMX08yOyW520e6fJiw0MtO5RJ1Jc7zmHSjGmbRws8WlGcVFH0UGtCkSNbhCQb0ox/s16000/after.png\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><b>4년 간의 빅데이터 운영 결과</b></td></tr></tbody></table><div><br /></div><div>그래도 첫 1년 정도는 나름 보람있었다. 룰 정확도 개선 업무를 사무관 권한으로&nbsp;진행할 수 있었고, 기존 대비 분석 업무 범위 50% 확대라는 결과를 얻었기 때문. 아쉬운 점은 해당 업무가 메인이 아니었다는 것. 메인으로 진행했으면 더 나은 결과를 얻을 수도 있었다는 얘기.</div><div><br /></div><div><b><span style=\"font-size: x-large;\">진짜 메인은?</span></b></div><div><br /></div><div>원금 보장도 쉽지 않은 보험 시장은 사고, 질병 등의 공포를 먹고 성장한다. 보안 시장도 비슷. 그래서 업계와 공생 관계인 보안 업계지는 끊임없이 보안 위협 기사를 쏟아낸다. 기관장은 그런 업계지를 탐독했고, 관련 기사가 나올 때마다 내게 대책 마련을 지시했다.</div><div><br /></div><div>물론 그런 기사들이 도움이 될 때도 있다. 하지만 대부분은 일회성으로 끝나는, 정보보호체계를 큰 틀의 방향성 없이 그때그때 외부 정보에 휘둘리게 만드는, 공만 쫓아 우르르 몰려다니는 동네 축구 수준으로 전락시키는 이벤트성 업무일 뿐이었다.</div><div><br /></div><div>하지만 중요한 건 기관장의 성취감이 충족됐다는 것. 숱하게 실시되는 비상근무와 훈련 역시 기관장과 본부가 원하는, 불철주야 경계에 만전을 기하고 있다는 그림을 보여주기 위함이 최우선이었다.</div><div><blockquote style=\"text-align: center;\"><i><a href=\"https://kangmyounghun.blogspot.com/2020/06/blog-post.html\" target=\"_blank\">내가 제일 많이 기획했던 업무는 '비상근무'였다. 연말이니까 비상근무, 명절이니까 비상근무, 선거철이니까 비상근무. 그 다음은 훈련</a></i></blockquote></div><div><br /></div><div>장비 구축부터 운영까지 3년을 구른 현장에 대한 애착과 이루고 싶은 목표가 있었기에 기회 있을 때마다 룰 정확도 개선에 대한 소신을 기관장에게 피력하며 효율적인 업무를 꾀했지만 '나는 옳고, 너는 따라야한다'는 기조는 바뀌지 않았다.&nbsp;</div><div><br /></div><div>왜 룰 개선보다 상사 안심시키는 업무에 더 많은 시간을 할애해야 할까? 민간의 전문성을 활용하겠다며 뽑아놓고 왜 자신들이 인정한 전문가의 말을 듣지 않는 것일까? 회의감이 점점 커지는 와중에 세 번째 서기관을 모시게 됐다.</div><div><br /></div><div>국가직은 지방직 대비 상대적으로 민원 스트레스가 덜하지만 24시간 보안 이벤트에 대응해야 하는 정보보호 부서는 예외. 24시간 내내 민원이 쏟아지는 상황과 비슷하다고 보면 된다.</div><div></div><div style=\"text-align: center;\"><blockquote><i><a href=\"https://kangmyounghun.blogspot.com/2015/02/cxo.html\" target=\"_blank\">보안 업무는 운영성이 많아서 '잡일성 ' 업무가 많다. 눈에 잘 띄지 않더라도 꼭 필요한 일을 했다면 그것을 업무 성과로 인정해야 한다</a></i>&nbsp;-<span style=\"font-size: x-small;\">&nbsp;CxO가 알아야할 정보보안</span></blockquote></div><div><br /></div><div>한마디로 티는 안 나고 몸만 축나는 업무가 많다. 민간이든 공공이든 그런 부서로의 발령은 누구도 반기지 않는다. 당연히 발령받은 서기관들은 최선을 다해 보직 변경을 시도했다.&nbsp;1년 반 동안 세 명의 서기관을 모시게 된 이유.&nbsp;<span style=\"font-size: x-small;\">(도망 못가게 요샌 서기관도 민간 경력자로 채우는 듯)</span></div><div><br /></div><div>그런데 세 번째 서기관은 이전 상사들과 좀 달랐다. 모든 업무를 '새마을 운동'하듯 더 많이, 더 오래, 더 열심히 하려는 노력파였고, 그렇게 하면 다 통한다고 생각했다.</div><div><div><blockquote style=\"text-align: center;\"><i><a href=\"https://kangmyounghun.blogspot.com/2024/02/blog-post.html\" target=\"_blank\">업무를 이해하지 못하는 행정 계층이 자기가 아는 정도만 가지고, 그리고 일반적인 감시, 계량의 수단만 가지고 부처를 운영</a></i><i>&nbsp;-</i><span style=\"font-size: x-small;\">&nbsp;</span><span style=\"font-size: x-small;\">가짜 노동</span></blockquote></div><div><span style=\"font-size: x-small;\"><br /></span></div><div>시작은 새해 업무 보고였다. 불필요한 업무를 줄이려는 나는 업무 가짓수를 하나라도 더 늘리려는 서기관과 충돌했고, 이후 그의 눈엣가시가 됐다. 처음엔 나를 업무에서 배제시키려고 했다. 하지만 기관장이 나를 계속 호출하는 바람에 실패.&nbsp;</div></div><div><br /></div><div>몇달 후 아이핀 부정 발급 사건이 터졌다. 팀원들과 함께 며칠 간 사무실에 남아 분석 보고서를 작성했고, 책임 소재 규명으로부터 안전함을 확인한 기관장은 취약점 점검을 강화하라는 지시를 내리며 그렇게 마무리되나 싶었다.</div><div><br /></div><div>그런데 서기관은 타팀 소관인 취약점 점검 업무를 내게 지시하려 했다. 소관 업무가 다름을 지적하니 업무분장을 바꾸겠다로 응수하는 모습이 일을 뺏지 못하면 아예 일에 파묻히게 해주겠다 단단히 결심한 모양새였다.&nbsp;</div><div><br /></div><div>그리고 여세를 몰아 전직원의 주말 출근 지시. 사고 핑계를 댔지만 결국 나 하나 잡겠다는 의도가 너무 뻔한 상황에서, 나 때문에 피해보는 직원들에게 미안했다. 그래서 사직서를 제출했고, 1년 반의 공직 생활은 그렇게 끝이 났다.</div><div><br /></div><div>이런 공직사회 속에서 10년 동안 공무원<span style=\"font-size: x-small;\">(公務員)</span>&nbsp;본연의 역할에 충실하기 위해 노력한 저자의 고뇌가 얼마나 컸을지 쉽게 짐작이 가지 않는다. 어떻게 하면 저자의 바람대로 공직사회에 대한 혁신이 이루어질 수 있을까?</div><div><br /></div><div><b><span style=\"font-size: x-large;\">가짜 노동</span></b></div><div><br /></div><div>내가 경험한 공직사회는 상사의 업적을 위해 5급 이하 전 공무원이 헌신하는 문화가 지배하는 세상이었다. 모두가 리더만을 바라보는 세상에서 리더의 올바른 목표 설정은 필수. 그릇된 목표를 위해 실행되는 어떤 업무도 그릇되고 쓸데없는 일, 가짜 노동으로 전락할 수 있기 때문이다.</div><div><br /></div><div>돈을 벌어야 하는 민간은 돈 안 되는 쓸데없는 일, 가짜 노동을 스스로 쳐내는 경향이 있다. 세금을 써야 하는 공공은 쓴만큼 티가 나야 해서 효율보다 명분과 홍보에 매달리기 쉽다. 비효율에 대한 자정 작용이 힘든 이유. 이런 상황에서 전문성까지 없다면?</div><div><br /></div><div>기관장이 빅데이터를 선택한 이유는 실/국장, 장차관에게 해당 분야 전문성이 없어서, '유명한 미국 기술'이라는 명분만으로 인정받을 가능성이 높아서였고, 노력파 서기관이 업무 가짓수를 하나라도 더 늘리려던 이유는 분야 특성을 모르는 채, 과거 업무 방식을 답습해서였다.&nbsp;&nbsp;</div><div><div><blockquote style=\"text-align: center;\"><i>1980년대에 미군은 군사계획 절차를 수정하고</i>&nbsp;<span style=\"font-size: x-small;\">(바람직한 최종 상태를 의미하는)</span>&nbsp;<i>'지휘관의 의도 '라는 신개념을 도입</i><i>했다...&nbsp;</i><i>지휘관의 의도는 직속 상사로부터 상세한 지시가 없다 하더라도 모든 계급의 병사들이 행동을 취할 수 있도록 해준다. 최종 목적지를 알고 있다면 어떤 수단을 취하든 거기 닿기만 하면 될 일</i><span style=\"text-align: left;\">&nbsp;-&nbsp;<span style=\"font-size: x-small;\">스틱</span></span></blockquote><div><span style=\"font-size: x-small;\"><br /></span></div><span style=\"font-size: x-small;\"></span></div><div>결국 리더의 의도가 올바를 때 의미 있는 업무 결과로 이어질 가능성이 높아지고, 조직 구성원이 진짜 쓸모 있음의 가치를 발견할 때 가짜 노동은 사라진다. 올바른 의도를 가지기 위해 필요한 것이 전문성. 알아야 옳다 그르다를 판단하지. 그래서 저자의 제안은 매우 적절하다.</div></div><div><div><blockquote style=\"text-align: center;\"><i>일반직 공무원도 원하는 경우 한 분야에서 장기간 계속 근무하는 것을 허용하는 것</i> <span style=\"font-size: x-small;\">(240페이지)</span></blockquote></div><div><br /></div></div><div>한 분야에 머무르며 전문성을 갖춘 관료가 늘어나고, 이들이 올바른 의도를 가진 리더로 성장한다면 국민의 인정을 받는 공직사회, 나라를 위해서 일한다 말할 수 있는 공직사회 실현이 현실로 다가오는 날이 분명 올 것이다.</div><div><br /></div><div>문제를 해결하고 싶다면 먼저 문제를 인정해야 한다. 그래서 자정 작용의 첫걸음을 알리는 이 책의 의미는 대단히 크다. 10년을 몸 담은 조직에 대한 애정 어린 고언을 결심한 저자의 용기에 박수를 보낸다.</div>",
        "contentSnippet": "노한동 문체부 전 서기관이 10년 공직 경험을 바탕으로 쓴 자전 에세이.\n\n전도유망한 30대 서기관이 공직을 그만두고 책을 쓴 이유는 무엇일까? 저자는 그 이유를 '헛짓거리', '가짜 노동', '쓸데없는 일' 세 단어로 고백한다.\n공직사회의 일이란 그저 관습에 따르거나 기관장을 빛내기 위한 거대한 비효율의 반복 (83페이지)\n\n\n진짜 필요한 일이 아닌 헛짓거리에 자신의 인생을 갈아 넣으며 느끼는 공무원들의 자괴감 (188페이지)\n\n\n공직사회는 일을 못한다. 관료가 게을러서도, 철밥통이어서도 아니다. 그저 쓸데없는 일이 너무 많아서다 (274페이지)\n\n\n\n누가 그랬다. 노동 없는 삶은 부패하지만 영혼 없는 노동은 삶을 질식시킨다고. \n\n\n짧디 짧은 1년 반의 공직 시절이 떠올랐다 \n\n모 부처 소속기관에서 4년 반을 일했다. 3년은 민간인으로, 1년 반은 공무원으로. 보안장비 룰 정확도 개선을 목표로 3년을 노력했지만 쉽지 않았다. 공무원은 과거 어떤 사업자도 언급하지 않던 업무의 필요성을 이해하지 못했고, 그런 업무를 시도하는 나도 이해하지 못했다.\n\n\n\n그래서 그만 두고 책을 썼다. 이후 해당 기관의 5급 계약직 채용 공고를 보게 됐을 때 살짝 설렜다. 민간인 신분으로 일할 당시 접했던 실무 최고 책임자가 사무관이었기 때문에 채용되면 소신을 가지고 주도적으로 일할 수 있겠다는 생각이 들었던 것.\n\n\n물론 현실은 달랐다. 잠시 룰 정확도에 관심을 주던 기관장은 이내 성과 어필에 더 유리한 빅데이터로 관심을 돌렸다. 솔직히 입장 바뀌면 나라도 그랬지 싶다. 당시 그만큼 핫한 아이템은 없었으니까.\n\n사람들은 포르쉐를 부러워하지, 운전 실력을 부러워하지 않는다. 자본주의 세상에서 비싼 포르쉐는 성공의 상징이기 때문. 비슷한 연유로 빅데이터나 인공지능같은 최신 미국 기술은 정보보안, 나아가 IT 분야의 포르쉐가 된다.\n\n  \n\n\n보안 수준 향상이 최우선 과제였던 빅데이터\n\n\n\n4년 간의 빅데이터 운영 결과\n\n\n\n그래도 첫 1년 정도는 나름 보람있었다. 룰 정확도 개선 업무를 사무관 권한으로 진행할 수 있었고, 기존 대비 분석 업무 범위 50% 확대라는 결과를 얻었기 때문. 아쉬운 점은 해당 업무가 메인이 아니었다는 것. 메인으로 진행했으면 더 나은 결과를 얻을 수도 있었다는 얘기.\n\n\n진짜 메인은?\n\n\n원금 보장도 쉽지 않은 보험 시장은 사고, 질병 등의 공포를 먹고 성장한다. 보안 시장도 비슷. 그래서 업계와 공생 관계인 보안 업계지는 끊임없이 보안 위협 기사를 쏟아낸다. 기관장은 그런 업계지를 탐독했고, 관련 기사가 나올 때마다 내게 대책 마련을 지시했다.\n\n\n물론 그런 기사들이 도움이 될 때도 있다. 하지만 대부분은 일회성으로 끝나는, 정보보호체계를 큰 틀의 방향성 없이 그때그때 외부 정보에 휘둘리게 만드는, 공만 쫓아 우르르 몰려다니는 동네 축구 수준으로 전락시키는 이벤트성 업무일 뿐이었다.\n\n\n하지만 중요한 건 기관장의 성취감이 충족됐다는 것. 숱하게 실시되는 비상근무와 훈련 역시 기관장과 본부가 원하는, 불철주야 경계에 만전을 기하고 있다는 그림을 보여주기 위함이 최우선이었다.\n\n내가 제일 많이 기획했던 업무는 '비상근무'였다. 연말이니까 비상근무, 명절이니까 비상근무, 선거철이니까 비상근무. 그 다음은 훈련\n\n\n장비 구축부터 운영까지 3년을 구른 현장에 대한 애착과 이루고 싶은 목표가 있었기에 기회 있을 때마다 룰 정확도 개선에 대한 소신을 기관장에게 피력하며 효율적인 업무를 꾀했지만 '나는 옳고, 너는 따라야한다'는 기조는 바뀌지 않았다. \n\n\n왜 룰 개선보다 상사 안심시키는 업무에 더 많은 시간을 할애해야 할까? 민간의 전문성을 활용하겠다며 뽑아놓고 왜 자신들이 인정한 전문가의 말을 듣지 않는 것일까? 회의감이 점점 커지는 와중에 세 번째 서기관을 모시게 됐다.\n\n\n국가직은 지방직 대비 상대적으로 민원 스트레스가 덜하지만 24시간 보안 이벤트에 대응해야 하는 정보보호 부서는 예외. 24시간 내내 민원이 쏟아지는 상황과 비슷하다고 보면 된다.\n\n\n보안 업무는 운영성이 많아서 '잡일성 ' 업무가 많다. 눈에 잘 띄지 않더라도 꼭 필요한 일을 했다면 그것을 업무 성과로 인정해야 한다 - CxO가 알아야할 정보보안\n\n\n한마디로 티는 안 나고 몸만 축나는 업무가 많다. 민간이든 공공이든 그런 부서로의 발령은 누구도 반기지 않는다. 당연히 발령받은 서기관들은 최선을 다해 보직 변경을 시도했다. 1년 반 동안 세 명의 서기관을 모시게 된 이유. (도망 못가게 요샌 서기관도 민간 경력자로 채우는 듯)\n\n\n그런데 세 번째 서기관은 이전 상사들과 좀 달랐다. 모든 업무를 '새마을 운동'하듯 더 많이, 더 오래, 더 열심히 하려는 노력파였고, 그렇게 하면 다 통한다고 생각했다.\n\n업무를 이해하지 못하는 행정 계층이 자기가 아는 정도만 가지고, 그리고 일반적인 감시, 계량의 수단만 가지고 부처를 운영 - 가짜 노동\n\n\n\n시작은 새해 업무 보고였다. 불필요한 업무를 줄이려는 나는 업무 가짓수를 하나라도 더 늘리려는 서기관과 충돌했고, 이후 그의 눈엣가시가 됐다. 처음엔 나를 업무에서 배제시키려고 했다. 하지만 기관장이 나를 계속 호출하는 바람에 실패. \n\n\n몇달 후 아이핀 부정 발급 사건이 터졌다. 팀원들과 함께 며칠 간 사무실에 남아 분석 보고서를 작성했고, 책임 소재 규명으로부터 안전함을 확인한 기관장은 취약점 점검을 강화하라는 지시를 내리며 그렇게 마무리되나 싶었다.\n\n\n그런데 서기관은 타팀 소관인 취약점 점검 업무를 내게 지시하려 했다. 소관 업무가 다름을 지적하니 업무분장을 바꾸겠다로 응수하는 모습이 일을 뺏지 못하면 아예 일에 파묻히게 해주겠다 단단히 결심한 모양새였다. \n\n\n그리고 여세를 몰아 전직원의 주말 출근 지시. 사고 핑계를 댔지만 결국 나 하나 잡겠다는 의도가 너무 뻔한 상황에서, 나 때문에 피해보는 직원들에게 미안했다. 그래서 사직서를 제출했고, 1년 반의 공직 생활은 그렇게 끝이 났다.\n\n\n이런 공직사회 속에서 10년 동안 공무원(公務員) 본연의 역할에 충실하기 위해 노력한 저자의 고뇌가 얼마나 컸을지 쉽게 짐작이 가지 않는다. 어떻게 하면 저자의 바람대로 공직사회에 대한 혁신이 이루어질 수 있을까?\n\n\n가짜 노동\n\n\n내가 경험한 공직사회는 상사의 업적을 위해 5급 이하 전 공무원이 헌신하는 문화가 지배하는 세상이었다. 모두가 리더만을 바라보는 세상에서 리더의 올바른 목표 설정은 필수. 그릇된 목표를 위해 실행되는 어떤 업무도 그릇되고 쓸데없는 일, 가짜 노동으로 전락할 수 있기 때문이다.\n\n\n돈을 벌어야 하는 민간은 돈 안 되는 쓸데없는 일, 가짜 노동을 스스로 쳐내는 경향이 있다. 세금을 써야 하는 공공은 쓴만큼 티가 나야 해서 효율보다 명분과 홍보에 매달리기 쉽다. 비효율에 대한 자정 작용이 힘든 이유. 이런 상황에서 전문성까지 없다면?\n\n\n기관장이 빅데이터를 선택한 이유는 실/국장, 장차관에게 해당 분야 전문성이 없어서, '유명한 미국 기술'이라는 명분만으로 인정받을 가능성이 높아서였고, 노력파 서기관이 업무 가짓수를 하나라도 더 늘리려던 이유는 분야 특성을 모르는 채, 과거 업무 방식을 답습해서였다.  \n\n1980년대에 미군은 군사계획 절차를 수정하고 (바람직한 최종 상태를 의미하는) '지휘관의 의도 '라는 신개념을 도입했다... 지휘관의 의도는 직속 상사로부터 상세한 지시가 없다 하더라도 모든 계급의 병사들이 행동을 취할 수 있도록 해준다. 최종 목적지를 알고 있다면 어떤 수단을 취하든 거기 닿기만 하면 될 일 - 스틱\n\n\n\n결국 리더의 의도가 올바를 때 의미 있는 업무 결과로 이어질 가능성이 높아지고, 조직 구성원이 진짜 쓸모 있음의 가치를 발견할 때 가짜 노동은 사라진다. 올바른 의도를 가지기 위해 필요한 것이 전문성. 알아야 옳다 그르다를 판단하지. 그래서 저자의 제안은 매우 적절하다.\n\n\n일반직 공무원도 원하는 경우 한 분야에서 장기간 계속 근무하는 것을 허용하는 것 (240페이지)\n\n\n\n한 분야에 머무르며 전문성을 갖춘 관료가 늘어나고, 이들이 올바른 의도를 가진 리더로 성장한다면 국민의 인정을 받는 공직사회, 나라를 위해서 일한다 말할 수 있는 공직사회 실현이 현실로 다가오는 날이 분명 올 것이다.\n\n\n문제를 해결하고 싶다면 먼저 문제를 인정해야 한다. 그래서 자정 작용의 첫걸음을 알리는 이 책의 의미는 대단히 크다. 10년을 몸 담은 조직에 대한 애정 어린 고언을 결심한 저자의 용기에 박수를 보낸다.",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-97983325123962663",
        "isoDate": "2025-01-22T09:05:00.001Z"
      },
      {
        "title": "Logstash 필터 ruby - 6th",
        "link": "https://kangmyounghun.blogspot.com/2025/01/logstash-ruby-6th.html",
        "pubDate": "2025-01-18T11:49:00.003Z",
        "author": "강명훈",
        "content": "<div>캡쳐그룹 순서번호는 1부터 시작한다.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhGl-5aMV8phuQR0YOOViJkCOnonbpTk6NzLnrtM_5H-P1k-9IxU-w1atWtv20yMfM1L2FjEX0kFuBFaM9R_PlFvpYDnBlV2xe24avBHbE65D_4iizpQQTPEDsVz7ewR2f_XtRi-t6J7I7sAASiWydMfrl7vpO-BsQco4oPrAHoeQxcQbyIc_W_yoUvuvaH/s2027/captures.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"988\" data-original-width=\"2027\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhGl-5aMV8phuQR0YOOViJkCOnonbpTk6NzLnrtM_5H-P1k-9IxU-w1atWtv20yMfM1L2FjEX0kFuBFaM9R_PlFvpYDnBlV2xe24avBHbE65D_4iizpQQTPEDsVz7ewR2f_XtRi-t6J7I7sAASiWydMfrl7vpO-BsQco4oPrAHoeQxcQbyIc_W_yoUvuvaH/s16000/captures.png\" /></a></div><br /><div><span><a name='more'></a></span>첫 번째 순서번호 캡쳐를 위한 ruby 필터</div>\n<div><pre><code><div>ruby {</div><div><span style=\"white-space: normal;\">&nbsp;code =&gt; \"</span></div><div><span style=\"white-space: normal;\">&nbsp; event.set('result', event.get('message').match(/(.).../).captures[1])<span style=\"white-space: pre;\">\t</span></span></div><div><span style=\"white-space: normal;\">&nbsp;\"</span></div><div><span style=\"white-space: normal;\">}</span></div></code></pre></div><div><br /></div>\n<div>캡쳐 실패.</div>\n<div><pre><code><div>[2025-01-18T20:37:14,434][INFO ][logstash.agent&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;] Pipelines running {:count=&gt;1, :running_pipelines=&gt;[:main], :non_running_pipelines=&gt;[]}</div><div>{</div><div>&nbsp; &nbsp; \"message\" =&gt; \"abcd\\r\",</div><div>&nbsp; &nbsp; &nbsp;\"result\" =&gt; nil</div><div>}</div></code></pre></div>\n<div><br /></div>\n<div>왜 안 되지? 전체 문자를 개별 캡쳐해봤다.</div>\n<div><pre><code><div>ruby {</div><div><span style=\"white-space: normal;\">&nbsp;code =&gt; \"</span></div><div><span style=\"white-space: normal;\">&nbsp; event.set('result', event.get('message').match(/(.)(.)(.)(.)/).captures[1])<span style=\"white-space: pre;\">\t</span></span></div><div><span style=\"white-space: normal;\">&nbsp;\"</span></div><div><span style=\"white-space: normal;\">}</span></div></code></pre></div>\n<div><br /></div>\n<div>두 번째 순서번호를 가져오네?</div>\n<div><pre><code><div>[2025-01-18T20:32:47,467][INFO ][logstash.agent&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;] Pipelines running {:count=&gt;1, :running_pipelines=&gt;[:main], :non_running_pipelines=&gt;[]}</div><div>{</div><div>&nbsp; &nbsp; \"message\" =&gt; \"abcd\\r\",</div><div>&nbsp; &nbsp; &nbsp;\"result\" =&gt; \"b\"</div><div>}</div></code></pre></div>\n<div><br /></div>\n<div>순서번호를 빼봤다.</div>\n<div><pre><code><div>ruby {</div><div><span style=\"white-space: normal;\">&nbsp;code =&gt; \"</span></div><div><span style=\"white-space: normal;\">&nbsp; event.set('result', event.get('message').match(/(.)(.)(.)(.)/).captures)<span style=\"white-space: pre;\">\t</span></span></div><div><span style=\"white-space: normal;\">&nbsp;\"</span></div><div><span style=\"white-space: normal;\">}</span></div></code></pre></div>\n<div><pre><code><div>[2025-01-18T20:33:35,432][INFO ][logstash.agent&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;] Pipelines running {:count=&gt;1, :running_pipelines=&gt;[:main], :non_running_pipelines=&gt;[]}</div><div>{</div><div>&nbsp; &nbsp; \"message\" =&gt; \"abcd\\r\",</div><div>&nbsp; &nbsp; &nbsp;\"result\" =&gt; [</div><div>&nbsp; &nbsp; &nbsp; &nbsp; [0] \"a\",</div><div>&nbsp; &nbsp; &nbsp; &nbsp; [1] \"b\",</div><div>&nbsp; &nbsp; &nbsp; &nbsp; [2] \"c\",</div><div>&nbsp; &nbsp; &nbsp; &nbsp; [3] \"d\"</div><div>&nbsp; &nbsp; ]</div><div>}</div></code></pre></div>\n<div><br /></div><div>순서번호가 0부터 시작<span style=\"font-size: x-small;\">(..)</span></div><div><br /></div><div><b style=\"font-family: inherit;\">관련&nbsp;글</b><br /><ul><li><a href=\"https://kangmyounghun.blogspot.com/2025/01/logstash-ruby-5th.html\">Logstash 필터 ruby - 5th</a></li><li><span style=\"font-family: inherit;\"><a href=\"http://kangmyounghun.blogspot.kr/2017/10/logstash-ruby.html\" target=\"\">Logstash 필터 ruby</a></span></li><li><span style=\"font-family: inherit;\"><a href=\"http://kangmyounghun.blogspot.com/2017/06/elasticsearch-grok.html\" target=\"_blank\">Logstash 필터 grok</a></span></li><li><span style=\"font-family: inherit;\"><a href=\"http://kangmyounghun.blogspot.com/2017/07/logstash-mutate.html\" target=\"_blank\">Logstash 필터 mutate</a></span></li><li><span style=\"font-family: inherit;\"><a href=\"http://kangmyounghun.blogspot.kr/2018/02/logstash-geoip.html\" target=\"_blank\">Logstash 필터&nbsp;geoip</a></span></li><li><span style=\"font-family: inherit;\"><a href=\"http://kangmyounghun.blogspot.kr/2018/04/logstash-dissect.html\" target=\"_blank\">Logstash 필터 dissect</a></span></li><li><a href=\"http://kangmyounghun.blogspot.com/2018/09/logstash-kv.html\" target=\"_blank\">Logstash 필터&nbsp;kv</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2019/01/logstash-date.html\" target=\"_blank\">Logstash 필터 date</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2019/02/logstash-translate.html\" target=\"_blank\">Logstash 필터 translate</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2019/08/logstash-drop.html\" target=\"_blank\">Logstash 필터 drop</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2019/11/logstash-useragent.html\" target=\"_blank\">Logstash 필터 useragent</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2020/02/logstash-elapsed.html\" target=\"_blank\">Logstash 필터 elapsed</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2020/04/logstash-fingerprint.html\" target=\"_blank\">Logstash 필터 fingerprint</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2022/12/logstash-csv.html\" target=\"_blank\">Logstash 필터 csv</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2023/11/logstash-dns.html\">Logstash 필터 dns</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2025/01/logstash-split.html\">Logstash 필터 split</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2020/02/logstash-codec-multiline.html\" target=\"_blank\">Logstash codec 플러그인 multiline</a></li></ul></div>",
        "contentSnippet": "캡쳐그룹 순서번호는 1부터 시작한다.\n\n\n\n\n첫 번째 순서번호 캡쳐를 위한 ruby 필터\n\nruby {\n code => \"\n  event.set('result', event.get('message').match(/(.).../).captures[1])\t\n \"\n}\n\n\n\n캡쳐 실패.\n\n[2025-01-18T20:37:14,434][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}\n{\n    \"message\" => \"abcd\\r\",\n     \"result\" => nil\n}\n\n\n\n\n왜 안 되지? 전체 문자를 개별 캡쳐해봤다.\n\nruby {\n code => \"\n  event.set('result', event.get('message').match(/(.)(.)(.)(.)/).captures[1])\t\n \"\n}\n\n\n\n\n두 번째 순서번호를 가져오네?\n\n[2025-01-18T20:32:47,467][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}\n{\n    \"message\" => \"abcd\\r\",\n     \"result\" => \"b\"\n}\n\n\n\n\n순서번호를 빼봤다.\n\nruby {\n code => \"\n  event.set('result', event.get('message').match(/(.)(.)(.)(.)/).captures)\t\n \"\n}\n\n\n\n\n[2025-01-18T20:33:35,432][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}\n{\n    \"message\" => \"abcd\\r\",\n     \"result\" => [\n        [0] \"a\",\n        [1] \"b\",\n        [2] \"c\",\n        [3] \"d\"\n    ]\n}\n\n\n\n\n순서번호가 0부터 시작(..)\n\n\n관련 글\n\nLogstash 필터 ruby - 5th\nLogstash 필터 ruby\nLogstash 필터 grok\nLogstash 필터 mutate\nLogstash 필터 geoip\nLogstash 필터 dissect\nLogstash 필터 kv\nLogstash 필터 date\nLogstash 필터 translate\nLogstash 필터 drop\nLogstash 필터 useragent\nLogstash 필터 elapsed\nLogstash 필터 fingerprint\nLogstash 필터 csv\nLogstash 필터 dns\nLogstash 필터 split\nLogstash codec 플러그인 multiline",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-1406692707397421592",
        "isoDate": "2025-01-18T11:49:00.003Z"
      },
      {
        "title": "Logstash 필터 ruby - 5th",
        "link": "https://kangmyounghun.blogspot.com/2025/01/logstash-ruby-5th.html",
        "pubDate": "2025-01-18T06:28:00.002Z",
        "author": "강명훈",
        "content": "<div>ruby 필터는 <span style=\"font-family: courier;\">==</span> 등의 비교 연산자를 지원하지 않는다. 다음은 include 메소드를 이용한 <span style=\"font-family: courier;\">?</span> 검사.</div>\n<div><pre><code><span style=\"font-family: courier;\"><div>ruby {</div><div><span style=\"white-space: normal;\">&nbsp;code =&gt; \"</span></div><div><span style=\"white-space: normal;\">&nbsp; if event.get('message').include?('?')</span></div><div><span style=\"white-space: normal;\">&nbsp; &nbsp;event.set('result', 'TRUE')</span></div><div><span style=\"white-space: normal;\">&nbsp; else</span></div><div><span style=\"white-space: normal;\">&nbsp; &nbsp;event.set('result', 'FALSE')</span></div><div><span style=\"white-space: normal;\">&nbsp; end<span style=\"white-space: pre;\">\t</span></span></div><div><span style=\"white-space: normal;\">&nbsp;\"</span></div><div><span style=\"white-space: normal;\">}</span></div></span></code></pre></div>\n<span><a name='more'></a></span><div><pre><code><span style=\"font-family: courier;\"><div>[2025-01-18T14:56:19,606][INFO ][logstash.agent&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;] Pipelines running {:count=&gt;1, :running_pipelines=&gt;[:main], :non_running_pipelines=&gt;[]}</div><div>{</div><div>&nbsp; &nbsp; \"message\" =&gt; \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.php?board_id=kor%5Fmedia&amp;gul_no=1106&amp;idx=17&amp;m=4&amp;upage=25&amp;tpage=&amp;PAGE=4 HTTP/1.1\\\" 200 37727\\r\",</div><div>&nbsp; &nbsp; &nbsp;\"result\" =&gt; \"TRUE\"</div><div>}</div><div>{</div><div>&nbsp; &nbsp; \"message\" =&gt; \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.html HTTP/1.1\\\" 200 37727\\r\",</div><div>&nbsp; &nbsp; &nbsp;\"result\" =&gt; \"FALSE\"</div><div>}</div></span></code></pre></div>\n<div><br /></div>\n<div>정규표현식 검사는 match 메소드로 가능.</div>\n<div><pre><code><span style=\"font-family: courier;\"><div>ruby {</div><div>&nbsp;code =&gt; \"</div><div>&nbsp; if event.get('message').match('\\?')</div><div>&nbsp; &nbsp;event.set('result', 'TRUE')</div><div>&nbsp; else</div><div>&nbsp; &nbsp;event.set('result', 'FALSE')</div><div>&nbsp; end<span style=\"white-space: pre;\">\t</span></div><div>&nbsp;\"</div><div>}</div></span></code></pre></div><div><br /></div>\n<div>그런데 code 표현식 구분기호를 <span style=\"font-family: courier;\">'</span>로 바꾸면서 충돌 방지를 위해 표현식내에 사용된 <span style=\"font-family: courier;\">'</span>를 <span style=\"font-family: courier;\">\"</span>로 바꾸니 에러 발생. 순수문자&nbsp;<span style=\"font-family: courier;\">?</span><span style=\"font-size: x-small;\">(\\?)</span>를 수량자로 인식한다.</div>\n<div><pre><code><span style=\"font-family: courier;\"><div>ruby {</div><div><span style=\"white-space: normal;\">&nbsp;code =&gt; '</span></div><div><span style=\"white-space: normal;\">&nbsp; if event.get(\"message\").match(\"\\?\")</span></div><div><span style=\"white-space: normal;\">&nbsp; &nbsp;event.set(\"result\", \"TRUE\")</span></div><div><span style=\"white-space: normal;\">&nbsp; else</span></div><div><span style=\"white-space: normal;\">&nbsp; &nbsp;event.set(\"result\", \"FALSE\")</span></div><div><span style=\"white-space: normal;\">&nbsp; end<span style=\"white-space: pre;\">\t</span></span></div><div><span style=\"white-space: normal;\">&nbsp;'</span></div><div><span style=\"white-space: normal;\">}</span></div></span></code></pre></div>\n<div><pre><code><span style=\"font-family: courier;\"><div>[2025-01-18T15:02:16,612][INFO ][logstash.agent&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;] Pipelines running {:count=&gt;1, :running_pipelines=&gt;[:main], :non_running_pipelines=&gt;[]}</div><div>[2025-01-18T15:02:16,740][ERROR][logstash.filters.ruby&nbsp; &nbsp; ][main][62b3883710cf5e6539519c02d2e859b71543aa213032326fbf070fa80051a3f3] Ruby exception occurred: target of repeat operator is not specified: /?/ {:class=&gt;\"RegexpError\", :backtrace=&gt;[\"org/jruby/RubyString.java:1754:in `match'\", \"(ruby filter code):3:in `block in register'\", \"D:/ELK/logstash-8.17.0/vendor/bundle/jruby/3.1.0/gems/logstash-filter-ruby-3.1.8/lib/logstash/filters/ruby.rb:96:in `inline_script'\", \"D:/ELK/logstash-8.17.0/vendor/bundle/jruby/3.1.0/gems/logstash-filter-ruby-3.1.8/lib/logstash/filters/ruby.rb:89:in `filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:158:in `do_filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:176:in `block in multi_filter'\", \"org/jruby/RubyArray.java:1981:in `each'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:173:in `multi_filter'\", \"org/logstash/config/ir/compiler/AbstractFilterDelegatorExt.java:133:in `multi_filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/java_pipeline.rb:308:in `block in start_workers'\"]}</div><div>[2025-01-18T15:02:16,742][ERROR][logstash.filters.ruby&nbsp; &nbsp; ][main][62b3883710cf5e6539519c02d2e859b71543aa213032326fbf070fa80051a3f3] Ruby exception occurred: target of repeat operator is not specified: /?/ {:class=&gt;\"RegexpError\", :backtrace=&gt;[\"org/jruby/RubyString.java:1754:in `match'\", \"(ruby filter code):3:in `block in register'\", \"D:/ELK/logstash-8.17.0/vendor/bundle/jruby/3.1.0/gems/logstash-filter-ruby-3.1.8/lib/logstash/filters/ruby.rb:96:in `inline_script'\", \"D:/ELK/logstash-8.17.0/vendor/bundle/jruby/3.1.0/gems/logstash-filter-ruby-3.1.8/lib/logstash/filters/ruby.rb:89:in `filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:158:in `do_filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:176:in `block in multi_filter'\", \"org/jruby/RubyArray.java:1981:in `each'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:173:in `multi_filter'\", \"org/logstash/config/ir/compiler/AbstractFilterDelegatorExt.java:133:in `multi_filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/java_pipeline.rb:308:in `block in start_workers'\"]}</div><div>{</div><div>&nbsp; &nbsp; \"message\" =&gt; \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.php?board_id=kor%5Fmedia&amp;gul_no=1106&amp;idx=17&amp;m=4&amp;upage=25&amp;tpage=&amp;PAGE=4 HTTP/1.1\\\" 200 37727\\r\",</div><div>&nbsp; &nbsp; &nbsp; &nbsp;\"tags\" =&gt; [</div><div>&nbsp; &nbsp; &nbsp; &nbsp; [0] \"_rubyexception\"</div><div>&nbsp; &nbsp; ]</div><div>}</div><div>{</div><div>&nbsp; &nbsp; \"message\" =&gt; \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.html HTTP/1.1\\\" 200 37727\\r\",</div><div>&nbsp; &nbsp; &nbsp; &nbsp;\"tags\" =&gt; [</div><div>&nbsp; &nbsp; &nbsp; &nbsp; [0] \"_rubyexception\"</div><div>&nbsp; &nbsp; ]</div><div>}</div></span></code></pre></div>\n<div><br /></div>\n<div><span style=\"font-family: courier;\">\\</span>를 하나 더 추가해줘야 예외처리가 됨. 인용부호 종류에 따라 동작 방식이 바뀌다니 신기하네<span style=\"font-size: x-small;\">(..)</span></div>\n<div><pre><code><span style=\"font-family: courier;\"><div>ruby {</div><div>&nbsp;code =&gt; '</div><div>&nbsp; if event.get(\"message\").match(\"\\\\?\")</div><div>&nbsp; &nbsp;event.set(\"result\", \"TRUE\")</div><div>&nbsp; else</div><div>&nbsp; &nbsp;event.set(\"result\", \"FALSE\")</div><div>&nbsp; end<span style=\"white-space: pre;\">\t</span></div><div>&nbsp;'</div><div>}</div></span></code></pre></div>\n<div><pre><code><span style=\"font-family: courier;\"><div>[2025-01-18T15:02:55,821][INFO ][logstash.agent&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;] Pipelines running {:count=&gt;1, :running_pipelines=&gt;[:main], :non_running_pipelines=&gt;[]}</div><div>[2025-01-18T15:02:55,823][INFO ][filewatch.observingtail&nbsp; ][main][925210a49f665e5510840791e908400bcb21ff21428156584c5f572f276da2fe] START, creating Discoverer, Watch with file and sincedb collections</div><div>{</div><div>&nbsp; &nbsp; \"message\" =&gt; \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.html HTTP/1.1\\\" 200 37727\\r\",</div><div>&nbsp; &nbsp; &nbsp;\"result\" =&gt; \"FALSE\"</div><div>}</div><div>{</div><div>&nbsp; &nbsp; \"message\" =&gt; \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.php?board_id=kor%5Fmedia&amp;gul_no=1106&amp;idx=17&amp;m=4&amp;upage=25&amp;tpage=&amp;PAGE=4 HTTP/1.1\\\" 200 37727\\r\",</div><div>&nbsp; &nbsp; &nbsp;\"result\" =&gt; \"TRUE\"</div><div>}</div></span></code></pre></div>\n<div><br /></div>\n<div>정규표현식 구분기호는 <span style=\"font-family: courier;\">/</span>만 써야겠다.</div>\n<div><pre><code><span style=\"font-family: courier;\"><div>ruby {</div><div>&nbsp;code =&gt; '</div><div>&nbsp; if event.get(\"message\").match(/\\?/)</div><div>&nbsp; &nbsp;event.set(\"result\", \"TRUE\")</div><div>&nbsp; else</div><div>&nbsp; &nbsp;event.set(\"result\", \"FALSE\")</div><div>&nbsp; end<span style=\"white-space: pre;\">\t</span></div><div>&nbsp;'</div><div>}</div></span></code></pre></div>\n<div><br /></div>\n<div><b style=\"font-family: inherit;\">관련&nbsp;글</b><br /><ul><li><a href=\"https://kangmyounghun.blogspot.com/2025/01/logstash-ruby-6th.html\">Logstash 필터 ruby - 6th</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2020/02/logstash-ruby-4th.html\" target=\"\">Logstash 필터 ruby - 4th</a></li></ul></div>",
        "contentSnippet": "ruby 필터는 == 등의 비교 연산자를 지원하지 않는다. 다음은 include 메소드를 이용한 ? 검사.\n\nruby {\n code => \"\n  if event.get('message').include?('?')\n   event.set('result', 'TRUE')\n  else\n   event.set('result', 'FALSE')\n  end\t\n \"\n}\n\n\n\n\n[2025-01-18T14:56:19,606][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}\n{\n    \"message\" => \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.php?board_id=kor%5Fmedia&gul_no=1106&idx=17&m=4&upage=25&tpage=&PAGE=4 HTTP/1.1\\\" 200 37727\\r\",\n     \"result\" => \"TRUE\"\n}\n{\n    \"message\" => \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.html HTTP/1.1\\\" 200 37727\\r\",\n     \"result\" => \"FALSE\"\n}\n\n\n\n\n정규표현식 검사는 match 메소드로 가능.\n\nruby {\n code => \"\n  if event.get('message').match('\\?')\n   event.set('result', 'TRUE')\n  else\n   event.set('result', 'FALSE')\n  end\t\n \"\n}\n\n\n\n그런데 code 표현식 구분기호를 '로 바꾸면서 충돌 방지를 위해 표현식내에 사용된 '를 \"로 바꾸니 에러 발생. 순수문자 ?(\\?)를 수량자로 인식한다.\n\nruby {\n code => '\n  if event.get(\"message\").match(\"\\?\")\n   event.set(\"result\", \"TRUE\")\n  else\n   event.set(\"result\", \"FALSE\")\n  end\t\n '\n}\n\n\n\n\n[2025-01-18T15:02:16,612][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}\n[2025-01-18T15:02:16,740][ERROR][logstash.filters.ruby    ][main][62b3883710cf5e6539519c02d2e859b71543aa213032326fbf070fa80051a3f3] Ruby exception occurred: target of repeat operator is not specified: /?/ {:class=>\"RegexpError\", :backtrace=>[\"org/jruby/RubyString.java:1754:in `match'\", \"(ruby filter code):3:in `block in register'\", \"D:/ELK/logstash-8.17.0/vendor/bundle/jruby/3.1.0/gems/logstash-filter-ruby-3.1.8/lib/logstash/filters/ruby.rb:96:in `inline_script'\", \"D:/ELK/logstash-8.17.0/vendor/bundle/jruby/3.1.0/gems/logstash-filter-ruby-3.1.8/lib/logstash/filters/ruby.rb:89:in `filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:158:in `do_filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:176:in `block in multi_filter'\", \"org/jruby/RubyArray.java:1981:in `each'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:173:in `multi_filter'\", \"org/logstash/config/ir/compiler/AbstractFilterDelegatorExt.java:133:in `multi_filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/java_pipeline.rb:308:in `block in start_workers'\"]}\n[2025-01-18T15:02:16,742][ERROR][logstash.filters.ruby    ][main][62b3883710cf5e6539519c02d2e859b71543aa213032326fbf070fa80051a3f3] Ruby exception occurred: target of repeat operator is not specified: /?/ {:class=>\"RegexpError\", :backtrace=>[\"org/jruby/RubyString.java:1754:in `match'\", \"(ruby filter code):3:in `block in register'\", \"D:/ELK/logstash-8.17.0/vendor/bundle/jruby/3.1.0/gems/logstash-filter-ruby-3.1.8/lib/logstash/filters/ruby.rb:96:in `inline_script'\", \"D:/ELK/logstash-8.17.0/vendor/bundle/jruby/3.1.0/gems/logstash-filter-ruby-3.1.8/lib/logstash/filters/ruby.rb:89:in `filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:158:in `do_filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:176:in `block in multi_filter'\", \"org/jruby/RubyArray.java:1981:in `each'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:173:in `multi_filter'\", \"org/logstash/config/ir/compiler/AbstractFilterDelegatorExt.java:133:in `multi_filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/java_pipeline.rb:308:in `block in start_workers'\"]}\n{\n    \"message\" => \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.php?board_id=kor%5Fmedia&gul_no=1106&idx=17&m=4&upage=25&tpage=&PAGE=4 HTTP/1.1\\\" 200 37727\\r\",\n       \"tags\" => [\n        [0] \"_rubyexception\"\n    ]\n}\n{\n    \"message\" => \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.html HTTP/1.1\\\" 200 37727\\r\",\n       \"tags\" => [\n        [0] \"_rubyexception\"\n    ]\n}\n\n\n\n\n\\를 하나 더 추가해줘야 예외처리가 됨. 인용부호 종류에 따라 동작 방식이 바뀌다니 신기하네(..)\n\nruby {\n code => '\n  if event.get(\"message\").match(\"\\\\?\")\n   event.set(\"result\", \"TRUE\")\n  else\n   event.set(\"result\", \"FALSE\")\n  end\t\n '\n}\n\n\n\n\n[2025-01-18T15:02:55,821][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}\n[2025-01-18T15:02:55,823][INFO ][filewatch.observingtail  ][main][925210a49f665e5510840791e908400bcb21ff21428156584c5f572f276da2fe] START, creating Discoverer, Watch with file and sincedb collections\n{\n    \"message\" => \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.html HTTP/1.1\\\" 200 37727\\r\",\n     \"result\" => \"FALSE\"\n}\n{\n    \"message\" => \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.php?board_id=kor%5Fmedia&gul_no=1106&idx=17&m=4&upage=25&tpage=&PAGE=4 HTTP/1.1\\\" 200 37727\\r\",\n     \"result\" => \"TRUE\"\n}\n\n\n\n\n정규표현식 구분기호는 /만 써야겠다.\n\nruby {\n code => '\n  if event.get(\"message\").match(/\\?/)\n   event.set(\"result\", \"TRUE\")\n  else\n   event.set(\"result\", \"FALSE\")\n  end\t\n '\n}\n\n\n\n\n관련 글\n\nLogstash 필터 ruby - 6th\nLogstash 필터 ruby - 4th",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-6643708857228007068",
        "isoDate": "2025-01-18T06:28:00.002Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕홍",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": [
      {
        "creator": "고명환",
        "title": "희망리턴패키지 사업계획서 작성 방법 및 사례 1 - 소상공인",
        "link": "https://brunch.co.kr/@@LOc/260",
        "pubDate": "Tue, 21 Jan 2025 04:41:12 GMT",
        "author": "고명환",
        "content": "희망리턴패키지 사업은 소상공인의 재창업 및 경영개선을 위한 사업으로 소상공인과 관련된 정부지원사업 중 가장 많은 사업화 자금이 지원됩니다. 소상공인 분들이 평소에 사업계획서를 작성할 일이 없어서 신청에 애로사항이 있기 때문에 이를 조금이나마 도움을 드리고자 사례를 들여서 작성 방법을 설명드리겠습니다.   https://www.sbiz.or.kr/sup/ma<img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FhLzDtxsW_25jtWNdD20tnwJ8AOA.jpg\" width=\"500\" />",
        "contentSnippet": "희망리턴패키지 사업은 소상공인의 재창업 및 경영개선을 위한 사업으로 소상공인과 관련된 정부지원사업 중 가장 많은 사업화 자금이 지원됩니다. 소상공인 분들이 평소에 사업계획서를 작성할 일이 없어서 신청에 애로사항이 있기 때문에 이를 조금이나마 도움을 드리고자 사례를 들여서 작성 방법을 설명드리겠습니다.   https://www.sbiz.or.kr/sup/ma",
        "guid": "https://brunch.co.kr/@@LOc/260",
        "isoDate": "2025-01-21T04:41:12.000Z"
      },
      {
        "creator": "고명환",
        "title": "스타트업의 R&amp;D 과제 수행 시 자주하는 실수 5가지 - 스타트업",
        "link": "https://brunch.co.kr/@@LOc/259",
        "pubDate": "Mon, 20 Jan 2025 01:48:48 GMT",
        "author": "고명환",
        "content": "스타트업이 R&amp;D 지원사업에 처음 도전할 때, 많은 시행착오를 겪는 경우가 많습니다. 특히, 예비창업패키지, 청년창업사관학교와 같은 사업과 혼돈해 R&amp;D 지원사업을 진행하는 경우가 많은 데 성격이 매우 다른 사업인만큼 과제를 성공적으로 수행하기 위해서는 주요 실수를 미리 파악하고 방지하는 것이 중요합니다.   1. 목표 설정의 불명확성  1) 실수  많은 <img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FI-s08aVvuHE4UdXIoQRfZftRAIc.jpg\" width=\"500\" />",
        "contentSnippet": "스타트업이 R&D 지원사업에 처음 도전할 때, 많은 시행착오를 겪는 경우가 많습니다. 특히, 예비창업패키지, 청년창업사관학교와 같은 사업과 혼돈해 R&D 지원사업을 진행하는 경우가 많은 데 성격이 매우 다른 사업인만큼 과제를 성공적으로 수행하기 위해서는 주요 실수를 미리 파악하고 방지하는 것이 중요합니다.   1. 목표 설정의 불명확성  1) 실수  많은",
        "guid": "https://brunch.co.kr/@@LOc/259",
        "isoDate": "2025-01-20T01:48:48.000Z"
      },
      {
        "creator": "고명환",
        "title": "R&amp;D 성능지표 선정 시 주의할 점 및 참고 웹사이트 - 스타트",
        "link": "https://brunch.co.kr/@@LOc/258",
        "pubDate": "Fri, 17 Jan 2025 02:00:06 GMT",
        "author": "고명환",
        "content": "R&amp;D 지원사업에서 '성능지표'는 과제의 성공 가능성을 평가하는 중요한 기준입니다. 성능지표를 잘 선정하면 사업계획서 평가에서 긍정적인 영향을 줄 뿐 아니라, 과제 종료 후 성과를 명확히 입증할 수 있습니다. 아래는 성능지표 선정 시 주의할 점과 참고할만한 웹사이트를 정리하였습니다   1. 성능지표 선정 시 주의할 점  가. 구체적이고 측정 가능해야 함(S<img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FqsgCb0yPb3Am8ZuXSfVlR2DoHf0.jpg\" width=\"500\" />",
        "contentSnippet": "R&D 지원사업에서 '성능지표'는 과제의 성공 가능성을 평가하는 중요한 기준입니다. 성능지표를 잘 선정하면 사업계획서 평가에서 긍정적인 영향을 줄 뿐 아니라, 과제 종료 후 성과를 명확히 입증할 수 있습니다. 아래는 성능지표 선정 시 주의할 점과 참고할만한 웹사이트를 정리하였습니다   1. 성능지표 선정 시 주의할 점  가. 구체적이고 측정 가능해야 함(S",
        "guid": "https://brunch.co.kr/@@LOc/258",
        "isoDate": "2025-01-17T02:00:06.000Z"
      }
    ]
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김놀부",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "구글 검색 노출 감소, AI 콘텐츠 홍수 속에서 살아남는 법",
        "link": "https://muzbox.tistory.com/483529",
        "pubDate": "Wed, 22 Jan 2025 14:50:49 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "https://muzbox.tistory.com/483529#entry483529comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;구글 검색에서 블로그가 예전처럼 잘 안 보이나요? AI 콘텐츠 홍수 속에서도 끈질기게 살아남을 수 있는 SEO 최적화 전략과 E-E-A-T 강화 방법을 소개합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"내가-쓴글이-노출이-안되는-이유.webp\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/ctqrKG/btsLVfxEAmm/R7OSKlbBvnmZKtxmTfgk9k/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/ctqrKG/btsLVfxEAmm/R7OSKlbBvnmZKtxmTfgk9k/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/ctqrKG/btsLVfxEAmm/R7OSKlbBvnmZKtxmTfgk9k/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FctqrKG%2FbtsLVfxEAmm%2FR7OSKlbBvnmZKtxmTfgk9k%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"구글 검색 노출 감소, AI 콘텐츠 홍수 속에서 살아남는 법\" loading=\"lazy\" width=\"700\" height=\"382\" data-filename=\"내가-쓴글이-노출이-안되는-이유.webp\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;요즘 블로그 글을 올려도 예전처럼 구글에서 잘 보이지 않는다고 느끼신 적 있나요? 저도 같은 고민을 했어요. 아무리 공들여서 글을 써도 검색 상위에 노출되기는커녕 방문자 수도 줄어드는 것 같더라고요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이유는 간단해요. AI 기술 덕분에 콘텐츠가 넘쳐나고, 구글도 검색 품질을 유지하려고 알고리즘을 계속 바꾸고 있거든요. 예전처럼 단순히 키워드만 잘 넣어서 해결할 수 있는 시대는 끝났고, 이제는 **E-E-A-T(경험, 전문성, 권위성, 신뢰성)**이 필수적인 요소가 됐어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">그럼 어떻게 해야 블로그가 살아남을 수 있을까요? 제가 직접 시행착오를 겪으며 찾은 해결책을 공유해볼게요!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>  구글 검색 노출이 어려워진 이유</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">1.   구글 알고리즘 업데이트의 영향</span></h3>\n<p data-ke-size=\"size16\">구글은 검색 결과의 신뢰도를 높이기 위해 알고리즘을 계속 개선하고 있어요. 특히 요즘은 다음 요소들이 중요해졌어요.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>E-E-A-T 요소 강화:</b><br />구글은 사용자가 믿을 수 있는 정보를 원한다는 걸 잘 알고 있어요. 그래서 건강, 금융 같은 중요한 분야(YMYL)에서는 전문가가 작성한 신뢰성 있는 콘텐츠를 우선적으로 보여주고 있어요.</li>\n<li><b>사용자 경험(UX)의 중요성:</b><br />페이지 로딩이 느리거나 모바일에서 불편하면 방문자가 바로 나가버리죠. 구글은 이런 사이트를 좋아하지 않아요. 속도와 가독성이 중요한 이유예요.</li>\n<li><b>콘텐츠 품질 평가:</b><br />단순한 정보 나열로는 부족해요. 구체적인 사례와 심층 분석이 담긴 콘텐츠가 더 높은 평가를 받아요.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">2.   색인(Indexing) 문제</span></h3>\n<p data-ke-size=\"size16\">구글에 내 글이 제대로 색인되지 않으면 아무리 좋은 글도 검색 결과에 나오지 않아요. 다음을 체크해 보세요.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>robots.txt 설정 확인:</b> 혹시 크롤러가 내 사이트를 막고 있지는 않은지?</li>\n<li><b>사이트맵 제출:</b> Google Search Console에서 사이트맵을 등록했는지 확인해보세요.</li>\n<li><b>색인 요청:</b> 특정 페이지가 검색에 안 잡힌다면 직접 요청을 해보는 것도 방법이에요.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">3.   AI 콘텐츠 필터링 기술 강화</span></h3>\n<p data-ke-size=\"size16\">요즘 AI로 생성된 콘텐츠가 넘쳐나면서, 구글도 이를 감지하기 위해 노력하고 있어요. 자동 생성된 콘텐츠라도 품질이 낮다면 순위가 내려갈 수밖에 없죠.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">4.   경쟁 심화</span></h3>\n<p data-ke-size=\"size16\">예전에는 특정 키워드를 잡고 꾸준히 글을 쓰면 상위권이 가능했는데, 이제는 누구나 AI를 활용해서 콘텐츠를 쉽게 만들 수 있는 시대가 됐어요. 그렇다 보니 더 창의적이고 차별화된 콘텐츠가 필요해요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>  AI 시대, 효과적인 콘텐츠 제작 전략</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">1.   E-E-A-T 요소 강화하기</span></h3>\n<p data-ke-size=\"size16\">블로그에 신뢰도를 높이려면 이렇게 해보세요.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>실제 경험담 공유:</b> 사용해본 제품의 리얼 리뷰를 담으면 신뢰도가 높아져요.</li>\n<li><b>전문가 의견 추가:</b> 해당 분야의 전문가 인터뷰나 공신력 있는 자료를 인용해 보세요.</li>\n<li><b>독창적인 시각 제공:</b> 다른 블로그에서 볼 수 없는 나만의 인사이트를 더해보세요.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">2. ✍️ 효과적인 프롬프트 작성</span></h3>\n<p data-ke-size=\"size16\">AI를 사용할 때 프롬프트(명령어)를 잘 주는 게 중요해요. 예를 들면:</p>\n<p data-ke-size=\"size16\">\"2024년 블로그 SEO 트렌드를 심층 분석해줘. 구글 알고리즘 변화와 사용자 경험, E-E-A-T 적용 방안 중심으로 작성해줘.\"</p>\n<p data-ke-size=\"size16\">이렇게 구체적으로 요청할수록 더 좋은 결과가 나오더라고요.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">3.   AI 콘텐츠 검토 및 보완</span></h3>\n<p data-ke-size=\"size16\">AI가 글을 쓴다고 해서 그대로 올리면 안 돼요. 꼭 다음을 확인하세요.</p>\n<script async src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8195497734535830\"\n     crossorigin=\"anonymous\"></script>\n<ins class=\"adsbygoogle\"\n     style=\"display:block; text-align:center;\"\n     data-ad-layout=\"in-article\"\n     data-ad-format=\"fluid\"\n     data-ad-client=\"ca-pub-8195497734535830\"\n     data-ad-slot=\"1494233468\"></ins>\n<script>\n     (adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<center><figure id=\"og_1737524035750\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"AI 가 만든 글에 사람의 향기를, 무료 GTPS - 인간냄새\" data-og-description=\"사람 냄새 나는 AI 글쓰기, 어떻게 가능할까요? 제가 만든 챗봇, GPTS가 바로 그 답입니다! 자연스럽고 공감 가는 글을 만드는 비법을 지금 확인해 보세요.&nbsp;여러분, AI가 만든 글을 읽을 때 느낌이 \" data-og-host=\"muzbox.tistory.com\" data-og-source-url=\"https://muzbox.tistory.com/483526\" data-og-url=\"https://muzbox.tistory.com/483526\" data-og-image=\"https://scrap.kakaocdn.net/dn/ch7lZR/hyX4t3WxrT/2kfrHwISV5bzj9Eyr5m75k/img.jpg?width=800&amp;height=457&amp;face=0_0_800_457,https://scrap.kakaocdn.net/dn/ofjlW/hyX4yqILJG/kLYR2M1KVJRWtGGCktAyJ1/img.jpg?width=800&amp;height=457&amp;face=0_0_800_457,https://scrap.kakaocdn.net/dn/m2maj/hyX4sD0s07/rT9MjfHkyBZSP6AGZpmgbk/img.png?width=1163&amp;height=794&amp;face=0_0_1163_794\"><a href=\"https://muzbox.tistory.com/483526\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://muzbox.tistory.com/483526\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/ch7lZR/hyX4t3WxrT/2kfrHwISV5bzj9Eyr5m75k/img.jpg?width=800&amp;height=457&amp;face=0_0_800_457,https://scrap.kakaocdn.net/dn/ofjlW/hyX4yqILJG/kLYR2M1KVJRWtGGCktAyJ1/img.jpg?width=800&amp;height=457&amp;face=0_0_800_457,https://scrap.kakaocdn.net/dn/m2maj/hyX4sD0s07/rT9MjfHkyBZSP6AGZpmgbk/img.png?width=1163&amp;height=794&amp;face=0_0_1163_794');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">AI 가 만든 글에 사람의 향기를, 무료 GTPS - 인간냄새</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">사람 냄새 나는 AI 글쓰기, 어떻게 가능할까요? 제가 만든 챗봇, GPTS가 바로 그 답입니다! 자연스럽고 공감 가는 글을 만드는 비법을 지금 확인해 보세요.&nbsp;여러분, AI가 만든 글을 읽을 때 느낌이</p>\n<p class=\"og-host\" data-ke-size=\"size16\">muzbox.tistory.com</p>\n</div>\n</a></figure></center>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>문장이 자연스러운지:</b> AI가 어색한 표현을 쓸 때가 많아요.</li>\n<li><b>사실 확인:</b> 가짜 정보가 있을 수 있으니 꼭 체크하세요.</li>\n<li><b>개인적인 의견 추가:</b> 나만의 생각을 담아야 차별화가 돼요.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">4.   사용자 경험 최적화</span></h3>\n<p data-ke-size=\"size16\">방문자가 오래 머물게 하려면 어떻게 해야 할까요?</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>모바일에서도 보기 좋게 디자인하기</li>\n<li>로딩 속도 빠르게 하기</li>\n<li>관련 글을 연결해 체류 시간 늘리기</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>  구글의 AI 콘텐츠 감지 기술</b></span></h2>\n<p data-ke-size=\"size16\">구글은 AI로 작성된 콘텐츠를 찾아내기 위해 다양한 기술을 사용해요.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"구글알고리즘.webp\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/vxjdL/btsLVmcuVzv/p1o49KDZAv90rZVVvUY5a0/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/vxjdL/btsLVmcuVzv/p1o49KDZAv90rZVVvUY5a0/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/vxjdL/btsLVmcuVzv/p1o49KDZAv90rZVVvUY5a0/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FvxjdL%2FbtsLVmcuVzv%2Fp1o49KDZAv90rZVVvUY5a0%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"구글의 AI 콘텐츠 감지 기술\" loading=\"lazy\" width=\"700\" height=\"382\" data-filename=\"구글알고리즘.webp\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n</p>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>자연어 처리(NLP):</b> AI가 만든 글의 특정 패턴을 감지해요.</li>\n<li><b>중복 콘텐츠 판별:</b> 비슷한 글이 많으면 순위가 떨어질 수 있어요.</li>\n<li><b>사용자 행동 분석:</b> 방문자가 머무는 시간, 클릭률 등을 분석해요.</li>\n</ol>\n<p data-ke-size=\"size16\">결국 중요한 건 &lsquo;AI스럽지 않게&rsquo; 자연스럽고 가치 있는 정보를 제공하는 거예요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 id=\"e-e-a-t-\" style=\"color: #000000; text-align: start;\" data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>[참고] E-E-A-T 란?</b></span></h2>\n<p style=\"color: #000000; text-align: start;\" data-ke-size=\"size16\"><b>E-E-A-T</b>는 구글이 웹사이트의 콘텐츠 품질을 평가할 때 사용하는 중요한 기준이에요. 원래는<span>&nbsp;</span><b>E-A-T(Expertise, Authoritativeness, Trustworthiness: 전문성, 권위성, 신뢰성)</b>로 시작됐지만, 2022년 &lsquo;경험(Experience)&rsquo;이 추가되면서<span>&nbsp;</span><b>E-E-A-T</b>로 발전했어요.</p>\n<h2 id=\"e-e-a-t-\" style=\"color: #000000; text-align: start;\" data-ke-size=\"size26\"><span style=\"color: #ee2323;\">E-E-A-T의 구성 요소</span></h2>\n<ol style=\"list-style-type: decimal; color: #000000; text-align: start;\" data-ke-list-type=\"decimal\">\n<li><b>Experience (경험)</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>직접적인 경험이 있는 사람이 작성한 콘텐츠를 구글은 더 신뢰해요.</li>\n<li>예를 들어, 여행 리뷰는 직접 여행을 다녀온 사람이 쓴 글이 더 신뢰할 만하죠.</li>\n<li>실제 경험에서 나온 정보는 독자들에게도 더 유용해요.</li>\n</ul>\n</li>\n<li><b>Expertise (전문성)</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>콘텐츠를 작성한 사람이 해당 주제에 대해 얼마나 전문적인 지식을 가지고 있는지를 평가해요.</li>\n<li>예를 들어, 건강 관련 글이라면 의사나 전문가가 작성한 것이 높은 평가를 받겠죠.</li>\n</ul>\n</li>\n<li><b>Authoritativeness (권위성)</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>콘텐츠가 해당 분야에서 얼마나 권위 있는 정보를 제공하는지, 그리고 그 사이트 자체의 신뢰도를 평가해요.</li>\n<li>웹사이트의 도메인 평판, 외부에서 받는 인용이나 링크 등이 중요해요.</li>\n</ul>\n</li>\n<li><b>Trustworthiness (신뢰성)</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>콘텐츠의 정확성과 신뢰성을 평가하는 요소예요.</li>\n<li>사이트의 보안(SSL 사용 여부), 정확한 출처 제공, 투명한 운영 방침 등이 포함돼요.<br /><br /></li>\n</ul>\n</li>\n</ol>\n<h2 id=\"e-e-a-t-\" style=\"color: #000000; text-align: start;\" data-ke-size=\"size26\"><span style=\"color: #ee2323;\">E-E-A-T가 중요한 이유</span></h2>\n<p style=\"color: #000000; text-align: start;\" data-ke-size=\"size16\">구글은 특히<span>&nbsp;</span><b>YMYL(Your Money or Your Life)</b>, 즉 건강, 재정, 법률 등<span>&nbsp;</span><b>사람들의 삶에 직접적인 영향을 미치는 분야</b>에서 E-E-A-T 기준을 더 엄격하게 적용해요. 이런 분야에서는 부정확한 정보가 사람들에게 심각한 영향을 미칠 수 있기 때문이죠.<br /><br /></p>\n<script async src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8195497734535830\"\n     crossorigin=\"anonymous\"></script>\n<ins class=\"adsbygoogle\"\n     style=\"display:block; text-align:center;\"\n     data-ad-layout=\"in-article\"\n     data-ad-format=\"fluid\"\n     data-ad-client=\"ca-pub-8195497734535830\"\n     data-ad-slot=\"1494233468\"></ins>\n<script>\n     (adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<center><figure id=\"og_1737524075059\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"챗GPT 블로그 제목 생성 무료 GPTS, 이슈성 키워드를 롱런시키는 전략\" data-og-description=\"이슈성 키워드를 오랫동안 유지할 수 있는 블로그 제목을 만드는 방법과 SEO 최적화 전략을 해결한 무료 GPTS를 공개합니다. 연말정산이나 폭설 같은 키워드를 활용해서 꾸준한 트래픽을 유지하\" data-og-host=\"muzbox.tistory.com\" data-og-source-url=\"https://muzbox.tistory.com/483528\" data-og-url=\"https://muzbox.tistory.com/483528\" data-og-image=\"https://scrap.kakaocdn.net/dn/cRZnM0/hyX4pAwFkX/SHjC5tVLvJCBWjiUi5RiHk/img.png?width=800&amp;height=456&amp;face=0_0_800_456,https://scrap.kakaocdn.net/dn/bEKYOu/hyX4qsFN9K/QpJG3QYEyhj6eXBgcKEkkK/img.png?width=800&amp;height=456&amp;face=0_0_800_456,https://scrap.kakaocdn.net/dn/cysKC7/hyX4yKYFBv/MK3C9UpRmMO8hnWakQWIZ0/img.png?width=900&amp;height=514&amp;face=0_0_900_514\"><a href=\"https://muzbox.tistory.com/483528\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://muzbox.tistory.com/483528\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/cRZnM0/hyX4pAwFkX/SHjC5tVLvJCBWjiUi5RiHk/img.png?width=800&amp;height=456&amp;face=0_0_800_456,https://scrap.kakaocdn.net/dn/bEKYOu/hyX4qsFN9K/QpJG3QYEyhj6eXBgcKEkkK/img.png?width=800&amp;height=456&amp;face=0_0_800_456,https://scrap.kakaocdn.net/dn/cysKC7/hyX4yKYFBv/MK3C9UpRmMO8hnWakQWIZ0/img.png?width=900&amp;height=514&amp;face=0_0_900_514');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">챗GPT 블로그 제목 생성 무료 GPTS, 이슈성 키워드를 롱런시키는 전략</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">이슈성 키워드를 오랫동안 유지할 수 있는 블로그 제목을 만드는 방법과 SEO 최적화 전략을 해결한 무료 GPTS를 공개합니다. 연말정산이나 폭설 같은 키워드를 활용해서 꾸준한 트래픽을 유지하</p>\n<p class=\"og-host\" data-ke-size=\"size16\">muzbox.tistory.com</p>\n</div>\n</a></figure></center>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 id=\"e-e-a-t-\" style=\"color: #000000; text-align: start;\" data-ke-size=\"size26\"><span style=\"color: #ee2323;\">E-E-A-T를 강화하는 방법</span></h2>\n<ol style=\"list-style-type: decimal; color: #000000; text-align: start;\" data-ke-list-type=\"decimal\">\n<li><b>개인적인 경험을 적극 반영하기</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>내가 직접 사용해 본 제품 후기, 경험을 녹여서 차별화된 콘텐츠를 만들기.</li>\n<li>단순한 정보 제공이 아니라 실제 체험을 담은 글을 작성해 신뢰성을 높이기.</li>\n</ul>\n</li>\n<li><b>전문성을 강조하기</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>해당 분야의 전문가 인터뷰 추가.</li>\n<li>정확한 출처를 밝히고 신뢰할 만한 자료를 활용하기.</li>\n</ul>\n</li>\n<li><b>권위 있는 외부 사이트와의 연계</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>신뢰할 수 있는 웹사이트(공식 기관, 전문가 블로그 등)에서 내 콘텐츠를 인용하게 만들기.</li>\n<li>구글에서 내 블로그가 전문성을 인정받을 수 있도록 관련 기관과 협력하기.</li>\n</ul>\n</li>\n<li><b>사이트 신뢰도 높이기</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>HTTPS 보안 적용.</li>\n<li>저작권 정보, 문의 페이지 등 신뢰도를 높일 수 있는 요소 추가.</li>\n<li>독자 피드백을 반영하고 신속한 대응 제공.</li>\n</ul>\n</li>\n</ol>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"구글-상위-노출에-성공한-블로거.webp\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/dfd1Xv/btsLVhhV8Wp/bY2S69EElEGckhG3M58uDK/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/dfd1Xv/btsLVhhV8Wp/bY2S69EElEGckhG3M58uDK/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/dfd1Xv/btsLVhhV8Wp/bY2S69EElEGckhG3M58uDK/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fdfd1Xv%2FbtsLVhhV8Wp%2FbY2S69EElEGckhG3M58uDK%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"구글 검색 노출이 어려워진 이유\" loading=\"lazy\" width=\"700\" height=\"382\" data-filename=\"구글-상위-노출에-성공한-블로거.webp\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>✍️ 마치며</b></span></h2>\n<p data-ke-size=\"size16\">AI 시대에도 살아남는 블로그를 만들려면 단순히 AI를 활용하는 것만으로는 부족해요. 사람의 개성과 경험을 담고, 신뢰할 수 있는 정보를 제공해야 해요.</p>\n<p data-ke-size=\"size16\">검색 알고리즘이 바뀌어도 좋은 콘텐츠는 언제나 사랑받는다는 점, 잊지 마세요!  </p>\n<hr data-ke-style=\"style1\" />\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>❓ Q&amp;A</b></span></h2>\n<p data-ke-size=\"size16\"><b>Q1. 구글은 AI로 생성된 콘텐츠를 감지할 수 있나요?</b><br />A. 네, 구글은 고급 AI 분석 기술을 사용해 AI 콘텐츠를 감지하려고 해요. 하지만 고품질 콘텐츠라면 상위 노출이 가능해요.<br /><br /></p>\n<p data-ke-size=\"size16\"><b>Q2. 블로그 SEO에서 가장 중요한 요소는 무엇인가요?</b><br />A. E-E-A-T 강화와 사용자 경험 최적화가 가장 중요해요. 키워드만으로는 부족하죠.<br /><br /></p>\n<p data-ke-size=\"size16\"><b>Q3. AI 콘텐츠를 효과적으로 활용하려면?</b><br />A. AI가 초안을 작성하도록 하고, 직접 수정하고 경험을 추가하는 것이 가장 효과적인 방법이에요.</p>\n<textarea style=\"display:none\">\n<script type=\"application/ld+json\">\n{\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n        {\n            \"@type\": \"Question\",\n            \"name\": \"구글은 AI로 생성된 콘텐츠를 감지할 수 있나요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"네, 구글은 고급 AI 분석 기술을 사용해 AI 콘텐츠를 감지하려고 해요. 하지만 고품질 콘텐츠라면 상위 노출이 가능해요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"블로그 SEO에서 가장 중요한 요소는 무엇인가요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"E-E-A-T 강화와 사용자 경험 최적화가 가장 중요해요. 키워드만으로는 부족하죠.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"AI 콘텐츠를 효과적으로 활용하려면?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"AI가 초안을 작성하도록 하고, 직접 수정하고 경험을 추가하는 것이 가장 효과적인 방법이에요.\"\n            }\n        }\n    ]\n}\n</script>\n</textarea>",
        "contentSnippet": "구글 검색에서 블로그가 예전처럼 잘 안 보이나요? AI 콘텐츠 홍수 속에서도 끈질기게 살아남을 수 있는 SEO 최적화 전략과 E-E-A-T 강화 방법을 소개합니다.\n\n\n \n 요즘 블로그 글을 올려도 예전처럼 구글에서 잘 보이지 않는다고 느끼신 적 있나요? 저도 같은 고민을 했어요. 아무리 공들여서 글을 써도 검색 상위에 노출되기는커녕 방문자 수도 줄어드는 것 같더라고요.\n \n이유는 간단해요. AI 기술 덕분에 콘텐츠가 넘쳐나고, 구글도 검색 품질을 유지하려고 알고리즘을 계속 바꾸고 있거든요. 예전처럼 단순히 키워드만 잘 넣어서 해결할 수 있는 시대는 끝났고, 이제는 **E-E-A-T(경험, 전문성, 권위성, 신뢰성)**이 필수적인 요소가 됐어요.\n \n그럼 어떻게 해야 블로그가 살아남을 수 있을까요? 제가 직접 시행착오를 겪으며 찾은 해결책을 공유해볼게요!\n \n \n  구글 검색 노출이 어려워진 이유\n1.   구글 알고리즘 업데이트의 영향\n구글은 검색 결과의 신뢰도를 높이기 위해 알고리즘을 계속 개선하고 있어요. 특히 요즘은 다음 요소들이 중요해졌어요.\nE-E-A-T 요소 강화:\n구글은 사용자가 믿을 수 있는 정보를 원한다는 걸 잘 알고 있어요. 그래서 건강, 금융 같은 중요한 분야(YMYL)에서는 전문가가 작성한 신뢰성 있는 콘텐츠를 우선적으로 보여주고 있어요.\n사용자 경험(UX)의 중요성:\n페이지 로딩이 느리거나 모바일에서 불편하면 방문자가 바로 나가버리죠. 구글은 이런 사이트를 좋아하지 않아요. 속도와 가독성이 중요한 이유예요.\n콘텐츠 품질 평가:\n단순한 정보 나열로는 부족해요. 구체적인 사례와 심층 분석이 담긴 콘텐츠가 더 높은 평가를 받아요.\n2.   색인(Indexing) 문제\n구글에 내 글이 제대로 색인되지 않으면 아무리 좋은 글도 검색 결과에 나오지 않아요. 다음을 체크해 보세요.\nrobots.txt 설정 확인: 혹시 크롤러가 내 사이트를 막고 있지는 않은지?\n사이트맵 제출: Google Search Console에서 사이트맵을 등록했는지 확인해보세요.\n색인 요청: 특정 페이지가 검색에 안 잡힌다면 직접 요청을 해보는 것도 방법이에요.\n3.   AI 콘텐츠 필터링 기술 강화\n요즘 AI로 생성된 콘텐츠가 넘쳐나면서, 구글도 이를 감지하기 위해 노력하고 있어요. 자동 생성된 콘텐츠라도 품질이 낮다면 순위가 내려갈 수밖에 없죠.\n4.   경쟁 심화\n예전에는 특정 키워드를 잡고 꾸준히 글을 쓰면 상위권이 가능했는데, 이제는 누구나 AI를 활용해서 콘텐츠를 쉽게 만들 수 있는 시대가 됐어요. 그렇다 보니 더 창의적이고 차별화된 콘텐츠가 필요해요.\n \n \n  AI 시대, 효과적인 콘텐츠 제작 전략\n1.   E-E-A-T 요소 강화하기\n블로그에 신뢰도를 높이려면 이렇게 해보세요.\n실제 경험담 공유: 사용해본 제품의 리얼 리뷰를 담으면 신뢰도가 높아져요.\n전문가 의견 추가: 해당 분야의 전문가 인터뷰나 공신력 있는 자료를 인용해 보세요.\n독창적인 시각 제공: 다른 블로그에서 볼 수 없는 나만의 인사이트를 더해보세요.\n2. ✍️ 효과적인 프롬프트 작성\nAI를 사용할 때 프롬프트(명령어)를 잘 주는 게 중요해요. 예를 들면:\n\"2024년 블로그 SEO 트렌드를 심층 분석해줘. 구글 알고리즘 변화와 사용자 경험, E-E-A-T 적용 방안 중심으로 작성해줘.\"\n이렇게 구체적으로 요청할수록 더 좋은 결과가 나오더라고요.\n3.   AI 콘텐츠 검토 및 보완\nAI가 글을 쓴다고 해서 그대로 올리면 안 돼요. 꼭 다음을 확인하세요.\n\n\n\n     (adsbygoogle = window.adsbygoogle || []).push({});\n\n\n \nAI 가 만든 글에 사람의 향기를, 무료 GTPS - 인간냄새\n사람 냄새 나는 AI 글쓰기, 어떻게 가능할까요? 제가 만든 챗봇, GPTS가 바로 그 답입니다! 자연스럽고 공감 가는 글을 만드는 비법을 지금 확인해 보세요. 여러분, AI가 만든 글을 읽을 때 느낌이\nmuzbox.tistory.com\n\n\n문장이 자연스러운지: AI가 어색한 표현을 쓸 때가 많아요.\n사실 확인: 가짜 정보가 있을 수 있으니 꼭 체크하세요.\n개인적인 의견 추가: 나만의 생각을 담아야 차별화가 돼요.\n4.   사용자 경험 최적화\n방문자가 오래 머물게 하려면 어떻게 해야 할까요?\n모바일에서도 보기 좋게 디자인하기\n로딩 속도 빠르게 하기\n관련 글을 연결해 체류 시간 늘리기\n \n  구글의 AI 콘텐츠 감지 기술\n구글은 AI로 작성된 콘텐츠를 찾아내기 위해 다양한 기술을 사용해요.\n\n\n\n자연어 처리(NLP): AI가 만든 글의 특정 패턴을 감지해요.\n중복 콘텐츠 판별: 비슷한 글이 많으면 순위가 떨어질 수 있어요.\n사용자 행동 분석: 방문자가 머무는 시간, 클릭률 등을 분석해요.\n결국 중요한 건 ‘AI스럽지 않게’ 자연스럽고 가치 있는 정보를 제공하는 거예요.\n \n \n[참고] E-E-A-T 란?\nE-E-A-T는 구글이 웹사이트의 콘텐츠 품질을 평가할 때 사용하는 중요한 기준이에요. 원래는 E-A-T(Expertise, Authoritativeness, Trustworthiness: 전문성, 권위성, 신뢰성)로 시작됐지만, 2022년 ‘경험(Experience)’이 추가되면서 E-E-A-T로 발전했어요.\nE-E-A-T의 구성 요소\nExperience (경험)\n\n직접적인 경험이 있는 사람이 작성한 콘텐츠를 구글은 더 신뢰해요.\n예를 들어, 여행 리뷰는 직접 여행을 다녀온 사람이 쓴 글이 더 신뢰할 만하죠.\n실제 경험에서 나온 정보는 독자들에게도 더 유용해요.\nExpertise (전문성)\n\n콘텐츠를 작성한 사람이 해당 주제에 대해 얼마나 전문적인 지식을 가지고 있는지를 평가해요.\n예를 들어, 건강 관련 글이라면 의사나 전문가가 작성한 것이 높은 평가를 받겠죠.\nAuthoritativeness (권위성)\n\n콘텐츠가 해당 분야에서 얼마나 권위 있는 정보를 제공하는지, 그리고 그 사이트 자체의 신뢰도를 평가해요.\n웹사이트의 도메인 평판, 외부에서 받는 인용이나 링크 등이 중요해요.\nTrustworthiness (신뢰성)\n\n콘텐츠의 정확성과 신뢰성을 평가하는 요소예요.\n사이트의 보안(SSL 사용 여부), 정확한 출처 제공, 투명한 운영 방침 등이 포함돼요.\n\nE-E-A-T가 중요한 이유\n구글은 특히 YMYL(Your Money or Your Life), 즉 건강, 재정, 법률 등 사람들의 삶에 직접적인 영향을 미치는 분야에서 E-E-A-T 기준을 더 엄격하게 적용해요. 이런 분야에서는 부정확한 정보가 사람들에게 심각한 영향을 미칠 수 있기 때문이죠.\n\n\n\n\n     (adsbygoogle = window.adsbygoogle || []).push({});\n\n\n \n챗GPT 블로그 제목 생성 무료 GPTS, 이슈성 키워드를 롱런시키는 전략\n이슈성 키워드를 오랫동안 유지할 수 있는 블로그 제목을 만드는 방법과 SEO 최적화 전략을 해결한 무료 GPTS를 공개합니다. 연말정산이나 폭설 같은 키워드를 활용해서 꾸준한 트래픽을 유지하\nmuzbox.tistory.com\n\n \nE-E-A-T를 강화하는 방법\n개인적인 경험을 적극 반영하기\n\n내가 직접 사용해 본 제품 후기, 경험을 녹여서 차별화된 콘텐츠를 만들기.\n단순한 정보 제공이 아니라 실제 체험을 담은 글을 작성해 신뢰성을 높이기.\n전문성을 강조하기\n\n해당 분야의 전문가 인터뷰 추가.\n정확한 출처를 밝히고 신뢰할 만한 자료를 활용하기.\n권위 있는 외부 사이트와의 연계\n\n신뢰할 수 있는 웹사이트(공식 기관, 전문가 블로그 등)에서 내 콘텐츠를 인용하게 만들기.\n구글에서 내 블로그가 전문성을 인정받을 수 있도록 관련 기관과 협력하기.\n사이트 신뢰도 높이기\n\nHTTPS 보안 적용.\n저작권 정보, 문의 페이지 등 신뢰도를 높일 수 있는 요소 추가.\n독자 피드백을 반영하고 신속한 대응 제공.\n\n\n \n✍️ 마치며\nAI 시대에도 살아남는 블로그를 만들려면 단순히 AI를 활용하는 것만으로는 부족해요. 사람의 개성과 경험을 담고, 신뢰할 수 있는 정보를 제공해야 해요.\n검색 알고리즘이 바뀌어도 좋은 콘텐츠는 언제나 사랑받는다는 점, 잊지 마세요!  \n❓ Q&A\nQ1. 구글은 AI로 생성된 콘텐츠를 감지할 수 있나요?\nA. 네, 구글은 고급 AI 분석 기술을 사용해 AI 콘텐츠를 감지하려고 해요. 하지만 고품질 콘텐츠라면 상위 노출이 가능해요.\n\nQ2. 블로그 SEO에서 가장 중요한 요소는 무엇인가요?\nA. E-E-A-T 강화와 사용자 경험 최적화가 가장 중요해요. 키워드만으로는 부족하죠.\n\nQ3. AI 콘텐츠를 효과적으로 활용하려면?\nA. AI가 초안을 작성하도록 하고, 직접 수정하고 경험을 추가하는 것이 가장 효과적인 방법이에요.\n\n\n{\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n        {\n            \"@type\": \"Question\",\n            \"name\": \"구글은 AI로 생성된 콘텐츠를 감지할 수 있나요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"네, 구글은 고급 AI 분석 기술을 사용해 AI 콘텐츠를 감지하려고 해요. 하지만 고품질 콘텐츠라면 상위 노출이 가능해요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"블로그 SEO에서 가장 중요한 요소는 무엇인가요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"E-E-A-T 강화와 사용자 경험 최적화가 가장 중요해요. 키워드만으로는 부족하죠.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"AI 콘텐츠를 효과적으로 활용하려면?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"AI가 초안을 작성하도록 하고, 직접 수정하고 경험을 추가하는 것이 가장 효과적인 방법이에요.\"\n            }\n        }\n    ]\n}",
        "guid": "https://muzbox.tistory.com/483529",
        "categories": [
          "Google 이야기/애드센스 노하우",
          "AI 콘텐츠",
          "e-e-a-t",
          "SEO 최적화",
          "구글 검색 노출",
          "구글 알고리즘",
          "구글색인",
          "구글콘솔",
          "블로그 글쓰기",
          "색인 생성",
          "프롬프트 기법"
        ],
        "isoDate": "2025-01-22T05:50:49.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "챗GPT 블로그 제목 생성 무료 GPTS, 이슈성 키워드를 롱런시키는 전략",
        "link": "https://muzbox.tistory.com/483528",
        "pubDate": "Mon, 20 Jan 2025 09:25:33 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "https://muzbox.tistory.com/483528#entry483528comment",
        "content": "<p data-ke-size=\"size16\">이슈성 키워드를 오랫동안 유지할 수 있는 블로그 제목을 만드는 방법과 SEO 최적화 전략을 해결한 무료 GPTS를 공개합니다. 연말정산이나 폭설 같은 키워드를 활용해서 꾸준한 트래픽을 유지하는 방법, 같이 알아봐요!</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"블로그 제목 생성.png\" data-origin-width=\"900\" data-origin-height=\"514\"><span data-url=\"https://blog.kakaocdn.net/dn/cGt6gX/btsLSO0ecsE/du7A79MqpndE6lhOKAvki1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cGt6gX/btsLSO0ecsE/du7A79MqpndE6lhOKAvki1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cGt6gX/btsLSO0ecsE/du7A79MqpndE6lhOKAvki1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcGt6gX%2FbtsLSO0ecsE%2Fdu7A79MqpndE6lhOKAvki1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"챗GPT 블로그 제목 생성 무료 GPTS, 이슈성 키워드를 롱런시키는 전략\" loading=\"lazy\" width=\"700\" height=\"400\" data-filename=\"블로그 제목 생성.png\" data-origin-width=\"900\" data-origin-height=\"514\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;블로그를 운영하다 보면 특정 키워드가 갑자기 인기를 끌다가 얼마 지나지 않아 관심이 뚝 떨어지는 경우가 많죠. 저도 블로그에서 \"연말정산\"이나 \"폭설\" 같은 키워드를 써보면서 이런 경험을 했는데요. 처음엔 방문자가 몰렸다가 시즌이 끝나면 트래픽이 확 줄더라고요. 그렇다고 포기할 수는 없잖아요? 어떻게 하면 이런 키워드를 오랫동안 관심받게 만들 수 있을지, 오늘 같이 고민해볼게요!&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이러한 과정을 통해 챗GPT를 이용하여 바로 적절한 제목을 만들어 주는 GPTS 를 무료로 공개합니다.!!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>  이슈성 키워드를 꾸준히 유지하는 방법</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">  \"관심과 감정이 연결된 대상\" 찾기</span></h3>\n<p data-ke-size=\"size16\">사람들은 자기와 관련된 내용에 훨씬 더 오래 관심을 가져요. 그냥 \"폭설 대비 방법\"보다는 \"우리 가족을 위한 폭설 대비 체크리스트\"처럼 개인적인 느낌을 담으면 효과가 좋아요.</p>\n<h4 data-ke-size=\"size20\"><b>  실행 방안</b></h4>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>개인적인 관점 추가하기:</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>단순 키워드 ❌ &rarr; 감성적인 연결 ✔️</li>\n<li>예: \"폭설\" ❌ &rarr; \"우리 집 자동차를 위한 폭설 대비 완벽 가이드\" ✔️</li>\n<li>예: \"연말정산\" ❌ &rarr; \"2024 직장인을 위한 연말정산 절세 꿀팁\" ✔️</li>\n</ul>\n</li>\n<li><b>사회적 관심 반영하기:</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>트렌드와 연관된 주제로 풀어보기</li>\n<li>예: \"폭설 대비 정책 변화, 우리 생활에 미치는 영향\"</li>\n</ul>\n</li>\n<li><b>검색 의도를 고려한 키워드 조합:</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>왜 필요할까? &rarr; 폭설의 원인 분석</li>\n<li>누구에게 도움될까? &rarr; 직장인, 자영업자 등</li>\n</ul>\n</li>\n</ol>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">  검색 패턴을 활용한 키워드 전략</span></h3>\n<p data-ke-size=\"size16\">검색을 해보면 사람들이 두 가지 방식으로 키워드를 찾더라고요. 바로 <b>즉각적인 검색</b>과 <b>장기적인 검색</b>이에요.</p>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>즉각적인 검색:</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>\"2024 연말정산 마감일 언제까지?\"</li>\n<li>\"서울 폭설 현재 상황 실시간 보기\"</li>\n</ul>\n</li>\n<li><b>장기적인 검색:</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>\"연말정산 공제 항목 완벽 정리\"</li>\n<li>\"겨울철 차량 관리법, 폭설 대비 팁\"</li>\n</ul>\n</li>\n</ol>\n<h4 data-ke-size=\"size20\"><b>  키워드 전략 적용</b></h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>즉각적인 검색:</b> 마감일, 실시간, 빠른 해결</li>\n<li><b>장기적인 검색:</b> 팁, 가이드, 준비법</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">  키워드를 지속 가능하게 만드는 법</span></h3>\n<h4 data-ke-size=\"size20\">1) 트렌드 활용하기</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>연말정산: \"2025 연말정산 준비, 미리 챙겨야 할 것들\"</li>\n<li>폭설: \"기후 변화로 폭설이 많아진다, 우리가 대비할 방법은?\"</li>\n</ul>\n<h4 data-ke-size=\"size20\">2) 깊이 있는 정보 제공</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>연말정산: \"초보 직장인을 위한 연말정산 공제 완벽 정리\"</li>\n<li>폭설: \"지역별 폭설 대처법, 이렇게 하면 안전해요\"</li>\n</ul>\n<h4 data-ke-size=\"size20\">3) 키워드 확장</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>연말정산 &rarr; \"소득공제, 세액공제 뭐가 다를까?\"</li>\n<li>폭설 &rarr; \"겨울철 자동차 관리, 이것만은 꼭!\"</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>  [연말정산] 및 [폭설] 키워드 적용 예시</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">즉각적인 호기심 유발</span></h3>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>\"2024 연말정산, 이번에 놓치면 안 되는 절세 포인트!\"</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>핵심 키워드: 연말정산 팁, 절세 전략</li>\n<li>SEO 전략: '놓치면 안 되는', '필수 항목' 키워드 활용</li>\n</ul>\n</li>\n<li><b>\"올 겨울 폭설 대비, 필수 체크리스트 대공개!\"</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>핵심 키워드: 폭설 대비, 차량 준비</li>\n<li>SEO 전략: '필수', '체크리스트', '준비법' 키워드 강조</li>\n</ul>\n</li>\n</ol>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">구체적인 문제 해결</span></h3>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>\"연말정산 소득공제와 세액공제, 뭐가 다를까?\"</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>핵심 키워드: 소득공제, 세액공제</li>\n<li>SEO 전략: '차이점', '비교', '절세 방법' 강조</li>\n</ul>\n</li>\n<li><b>\"폭설 대비 차량 점검, 이것만 기억하세요!\"</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>핵심 키워드: 겨울철 차량 관리, 폭설 대비</li>\n<li>SEO 전략: '필수 확인', '고장 예방' 키워드 삽입</li>\n</ul>\n</li>\n</ol>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>마무리하며</b></span></h2>\n<p data-ke-size=\"size16\">이슈성 키워드를 꾸준히 유지하려면, <b>검색 패턴을 이해하고, 개인적인 스토리와 사회적 이슈를 적절히 섞는 게 중요해요.</b> 이렇게 하면 독자들이 꾸준히 관심을 가질 수 있답니다.</p>\n<p data-ke-size=\"size16\">이제 여러분도 연말정산이나 폭설 같은 키워드로 꾸준한 검색 유입을 만들어 보세요!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000; text-align: start;\" data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b> </b></span><span style=\"color: #009a87;\"><b><span>&nbsp;</span>GPTS 무료배포</b></span></h2>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\">&nbsp;약간의 지식과 시간만 투자하면 누구나 직접 제작하고 활용할 수 있는 유용한 GPTs가 이미 많이 존재합니다. 그러나 여전히 AI 기술에 대한 낯선 접근을 두려워하거나 IT 초보자, 또는 시간적 여유가 없거나 수익화에 대한 절실함 때문에 올바른 정보를 얻지 못하는 사람들이 많습니다. 이러한 심리를 악용해 과도한 가격으로 유료 강의를 판매하며 불필요한 부담을 주는 사례들이 늘어나고 있습니다.<span>&nbsp;</span><span style=\"color: #ee2323;\"><b>이에 본 블로그에서는 모든 사람이 AI의 혜택을 공정하고 자유롭게 누릴 수 있도록 GPTs를 무료로 배포하며, 불합리한 강의 판매 행위를 단호히 배척하고자 합니다.</b></span></p>\n<script async src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8195497734535830\"\n     crossorigin=\"anonymous\"></script>\n<ins class=\"adsbygoogle\"\n     style=\"display:block; text-align:center;\"\n     data-ad-layout=\"in-article\"\n     data-ad-format=\"fluid\"\n     data-ad-client=\"ca-pub-8195497734535830\"\n     data-ad-slot=\"7411138078\"></ins>\n<script>\n     (adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<figure id=\"og_1737332149856\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"ChatGPT - 챗GPT 블로그 제목 생성기\" data-og-description=\"사용자가 [키워드]를 입력하면 키워드를 지속적으로 유지하기 위한 블로그 제목을 제안합니다.\" data-og-host=\"chatgpt.com\" data-og-source-url=\"https://chatgpt.com/g/g-678d84eed64c819190a55fb6178767fc-caesgpt-beulrogeu-jemog-saengseonggi\" data-og-url=\"https://chatgpt.com/g/g-678d84eed64c819190a55fb6178767fc-caesgpt-beulrogeu-jemog-saengseonggi\" data-og-image=\"\"><a href=\"https://chatgpt.com/g/g-678d84eed64c819190a55fb6178767fc-caesgpt-beulrogeu-jemog-saengseonggi\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://chatgpt.com/g/g-678d84eed64c819190a55fb6178767fc-caesgpt-beulrogeu-jemog-saengseonggi\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">ChatGPT - 챗GPT 블로그 제목 생성기</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">사용자가 [키워드]를 입력하면 키워드를 지속적으로 유지하기 위한 블로그 제목을 제안합니다.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">chatgpt.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\">&nbsp;</p>\n<hr data-ke-style=\"style1\" />\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>❓ 자주 묻는 질문(Q&amp;A)</b></span></h2>\n<p data-ke-size=\"size16\"><b>1. 연말정산 키워드를 롱런하려면 어떻게 해야 하나요?</b> <br />절세&nbsp;관련&nbsp;정보나&nbsp;연중&nbsp;세테크&nbsp;팁을&nbsp;제공하세요.<br /><br /><b>2. 폭설 키워드는 시즌 외에 어떻게 유지할 수 있을까요?</b> <br />사계절&nbsp;차량&nbsp;관리법을&nbsp;포함해&nbsp;지속적인&nbsp;관심을&nbsp;유도하세요.<br /><br /><b>3. 블로그 제목을 효과적으로 작성하려면?</b> <br />키워드를&nbsp;제목&nbsp;앞쪽에&nbsp;배치하고,&nbsp;'꿀팁',&nbsp;'필수&nbsp;체크리스트'&nbsp;같은&nbsp;단어를&nbsp;활용하세요.<br /><br /><b>4. SEO 최적화를 위해 어떤 전략이 필요할까요?</b> <br />검색&nbsp;의도를&nbsp;파악하고,&nbsp;관련&nbsp;키워드를&nbsp;자연스럽게&nbsp;삽입하는&nbsp;것이&nbsp;중요합니다.<br /><br /><b>5. 이슈성 키워드 외에도 블로그 트래픽을 유지할 방법이 있을까요?</b> <br />꾸준한 콘텐츠 업데이트와 관련 주제 확장을 통해 지속적인 관심을 유도하세요.</p>\n<p><textarea style=\"display: none;\">&lt;script type=\"application/ld+json\"&gt;\n{\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n        {\n            \"@type\": \"Question\",\n            \"name\": \"연말정산 키워드를 롱런하려면 어떻게 해야 하나요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"절세 관련 정보나 연중 세테크 팁을 제공하세요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"폭설 키워드는 시즌 외에 어떻게 유지할 수 있을까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"사계절 차량 관리법을 포함해 지속적인 관심을 유도하세요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"블로그 제목을 효과적으로 작성하려면?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"키워드를 제목 앞쪽에 배치하고, '꿀팁', '필수 체크리스트' 같은 단어를 활용하세요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"SEO 최적화를 위해 어떤 전략이 필요할까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"검색 의도를 파악하고, 관련 키워드를 자연스럽게 삽입하는 것이 중요합니다.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"이슈성 키워드 외에도 블로그 트래픽을 유지할 방법이 있을까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"꾸준한 콘텐츠 업데이트와 관련 주제 확장을 통해 지속적인 관심을 유도하세요.\"\n            }\n        }\n    ]\n}\n&lt;/script&gt;\n</textarea></p>",
        "contentSnippet": "이슈성 키워드를 오랫동안 유지할 수 있는 블로그 제목을 만드는 방법과 SEO 최적화 전략을 해결한 무료 GPTS를 공개합니다. 연말정산이나 폭설 같은 키워드를 활용해서 꾸준한 트래픽을 유지하는 방법, 같이 알아봐요!\n\n\n \n 블로그를 운영하다 보면 특정 키워드가 갑자기 인기를 끌다가 얼마 지나지 않아 관심이 뚝 떨어지는 경우가 많죠. 저도 블로그에서 \"연말정산\"이나 \"폭설\" 같은 키워드를 써보면서 이런 경험을 했는데요. 처음엔 방문자가 몰렸다가 시즌이 끝나면 트래픽이 확 줄더라고요. 그렇다고 포기할 수는 없잖아요? 어떻게 하면 이런 키워드를 오랫동안 관심받게 만들 수 있을지, 오늘 같이 고민해볼게요! \n \n이러한 과정을 통해 챗GPT를 이용하여 바로 적절한 제목을 만들어 주는 GPTS 를 무료로 공개합니다.!!\n \n  이슈성 키워드를 꾸준히 유지하는 방법\n  \"관심과 감정이 연결된 대상\" 찾기\n사람들은 자기와 관련된 내용에 훨씬 더 오래 관심을 가져요. 그냥 \"폭설 대비 방법\"보다는 \"우리 가족을 위한 폭설 대비 체크리스트\"처럼 개인적인 느낌을 담으면 효과가 좋아요.\n  실행 방안\n개인적인 관점 추가하기:\n\n단순 키워드 ❌ → 감성적인 연결 ✔️\n예: \"폭설\" ❌ → \"우리 집 자동차를 위한 폭설 대비 완벽 가이드\" ✔️\n예: \"연말정산\" ❌ → \"2024 직장인을 위한 연말정산 절세 꿀팁\" ✔️\n사회적 관심 반영하기:\n\n트렌드와 연관된 주제로 풀어보기\n예: \"폭설 대비 정책 변화, 우리 생활에 미치는 영향\"\n검색 의도를 고려한 키워드 조합:\n\n왜 필요할까? → 폭설의 원인 분석\n누구에게 도움될까? → 직장인, 자영업자 등\n  검색 패턴을 활용한 키워드 전략\n검색을 해보면 사람들이 두 가지 방식으로 키워드를 찾더라고요. 바로 즉각적인 검색과 장기적인 검색이에요.\n즉각적인 검색:\n\n\"2024 연말정산 마감일 언제까지?\"\n\"서울 폭설 현재 상황 실시간 보기\"\n장기적인 검색:\n\n\"연말정산 공제 항목 완벽 정리\"\n\"겨울철 차량 관리법, 폭설 대비 팁\"\n  키워드 전략 적용\n즉각적인 검색: 마감일, 실시간, 빠른 해결\n장기적인 검색: 팁, 가이드, 준비법\n  키워드를 지속 가능하게 만드는 법\n1) 트렌드 활용하기\n연말정산: \"2025 연말정산 준비, 미리 챙겨야 할 것들\"\n폭설: \"기후 변화로 폭설이 많아진다, 우리가 대비할 방법은?\"\n2) 깊이 있는 정보 제공\n연말정산: \"초보 직장인을 위한 연말정산 공제 완벽 정리\"\n폭설: \"지역별 폭설 대처법, 이렇게 하면 안전해요\"\n3) 키워드 확장\n연말정산 → \"소득공제, 세액공제 뭐가 다를까?\"\n폭설 → \"겨울철 자동차 관리, 이것만은 꼭!\"\n \n  [연말정산] 및 [폭설] 키워드 적용 예시\n즉각적인 호기심 유발\n\"2024 연말정산, 이번에 놓치면 안 되는 절세 포인트!\"\n\n핵심 키워드: 연말정산 팁, 절세 전략\nSEO 전략: '놓치면 안 되는', '필수 항목' 키워드 활용\n\"올 겨울 폭설 대비, 필수 체크리스트 대공개!\"\n\n핵심 키워드: 폭설 대비, 차량 준비\nSEO 전략: '필수', '체크리스트', '준비법' 키워드 강조\n구체적인 문제 해결\n\"연말정산 소득공제와 세액공제, 뭐가 다를까?\"\n\n핵심 키워드: 소득공제, 세액공제\nSEO 전략: '차이점', '비교', '절세 방법' 강조\n\"폭설 대비 차량 점검, 이것만 기억하세요!\"\n\n핵심 키워드: 겨울철 차량 관리, 폭설 대비\nSEO 전략: '필수 확인', '고장 예방' 키워드 삽입\n \n마무리하며\n이슈성 키워드를 꾸준히 유지하려면, 검색 패턴을 이해하고, 개인적인 스토리와 사회적 이슈를 적절히 섞는 게 중요해요. 이렇게 하면 독자들이 꾸준히 관심을 가질 수 있답니다.\n이제 여러분도 연말정산이나 폭설 같은 키워드로 꾸준한 검색 유입을 만들어 보세요!\n \n \n  GPTS 무료배포\n 약간의 지식과 시간만 투자하면 누구나 직접 제작하고 활용할 수 있는 유용한 GPTs가 이미 많이 존재합니다. 그러나 여전히 AI 기술에 대한 낯선 접근을 두려워하거나 IT 초보자, 또는 시간적 여유가 없거나 수익화에 대한 절실함 때문에 올바른 정보를 얻지 못하는 사람들이 많습니다. 이러한 심리를 악용해 과도한 가격으로 유료 강의를 판매하며 불필요한 부담을 주는 사례들이 늘어나고 있습니다. 이에 본 블로그에서는 모든 사람이 AI의 혜택을 공정하고 자유롭게 누릴 수 있도록 GPTs를 무료로 배포하며, 불합리한 강의 판매 행위를 단호히 배척하고자 합니다.\n\n\n\n     (adsbygoogle = window.adsbygoogle || []).push({});\n\n\n \nChatGPT - 챗GPT 블로그 제목 생성기\n사용자가 [키워드]를 입력하면 키워드를 지속적으로 유지하기 위한 블로그 제목을 제안합니다.\nchatgpt.com\n\n \n \n❓ 자주 묻는 질문(Q&A)\n1. 연말정산 키워드를 롱런하려면 어떻게 해야 하나요? \n절세 관련 정보나 연중 세테크 팁을 제공하세요.\n2. 폭설 키워드는 시즌 외에 어떻게 유지할 수 있을까요? \n사계절 차량 관리법을 포함해 지속적인 관심을 유도하세요.\n3. 블로그 제목을 효과적으로 작성하려면? \n키워드를 제목 앞쪽에 배치하고, '꿀팁', '필수 체크리스트' 같은 단어를 활용하세요.\n4. SEO 최적화를 위해 어떤 전략이 필요할까요? \n검색 의도를 파악하고, 관련 키워드를 자연스럽게 삽입하는 것이 중요합니다.\n5. 이슈성 키워드 외에도 블로그 트래픽을 유지할 방법이 있을까요? \n꾸준한 콘텐츠 업데이트와 관련 주제 확장을 통해 지속적인 관심을 유도하세요.\n<script type=\"application/ld+json\">\n{\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n        {\n            \"@type\": \"Question\",\n            \"name\": \"연말정산 키워드를 롱런하려면 어떻게 해야 하나요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"절세 관련 정보나 연중 세테크 팁을 제공하세요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"폭설 키워드는 시즌 외에 어떻게 유지할 수 있을까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"사계절 차량 관리법을 포함해 지속적인 관심을 유도하세요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"블로그 제목을 효과적으로 작성하려면?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"키워드를 제목 앞쪽에 배치하고, '꿀팁', '필수 체크리스트' 같은 단어를 활용하세요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"SEO 최적화를 위해 어떤 전략이 필요할까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"검색 의도를 파악하고, 관련 키워드를 자연스럽게 삽입하는 것이 중요합니다.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"이슈성 키워드 외에도 블로그 트래픽을 유지할 방법이 있을까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"꾸준한 콘텐츠 업데이트와 관련 주제 확장을 통해 지속적인 관심을 유도하세요.\"\n            }\n        }\n    ]\n}\n</script>",
        "guid": "https://muzbox.tistory.com/483528",
        "categories": [
          "AI, 미래기술/MY GPT 공개",
          "SEO 최적화",
          "롱런 키워드 전략",
          "무료 gpts",
          "무료챗봇",
          "블로그 제목 생성기",
          "블로그 콘텐츠 기획",
          "이슈성 키워드",
          "지속 가능한 트래픽",
          "챗GPT",
          "키워드 지속 유지법"
        ],
        "isoDate": "2025-01-20T00:25:33.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "AI 노트북 고민 끝!: 에이서 스위프트 16 AI",
        "link": "https://muzbox.tistory.com/483527",
        "pubDate": "Fri, 17 Jan 2025 09:54:33 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "https://muzbox.tistory.com/483527#entry483527comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;요즘 AI 기술이 빠르게 발전하면서 관련 작업에 적합한 노트북을 찾는 일이 점점 더 중요해지고 있어요.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"에이서 스위프트 16 AI 노트북 리뷰.jpg\" data-origin-width=\"775\" data-origin-height=\"460\"><span data-url=\"https://blog.kakaocdn.net/dn/bzu9UO/btsLQi1GVls/ad4Uf2qqMXKq5EYMVfb0X0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bzu9UO/btsLQi1GVls/ad4Uf2qqMXKq5EYMVfb0X0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bzu9UO/btsLQi1GVls/ad4Uf2qqMXKq5EYMVfb0X0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbzu9UO%2FbtsLQi1GVls%2Fad4Uf2qqMXKq5EYMVfb0X0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"AI 노트북 고민 끝!: 에이서 스위프트 16 AI\" loading=\"lazy\" width=\"700\" height=\"415\" data-filename=\"에이서 스위프트 16 AI 노트북 리뷰.jpg\" data-origin-width=\"775\" data-origin-height=\"460\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;저도 비슷한 고민을 하던 중에 우연히 <b>에이서 스위프트 16 AI</b>를 발견하게 되었는데요. 단순히 \"AI 기술에 적합하다\"를 넘어서, <b>성능, 디자인, 휴대성, 배터리 지속 시간</b>까지 어느 하나 빠지지 않는 제품이더라고요. 그래서 오늘은 이 노트북의 각 특징을 구체적으로 살펴보며, 여러분께 추천드리고자 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">1️⃣ <b>최신 인텔 코어 울트라 7로 AI 작업에 최적화된 퍼포먼스</b></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"773\" data-origin-height=\"614\"><span data-url=\"https://blog.kakaocdn.net/dn/bP9iqF/btsLPQEv2Xr/HmVQ0mgk7sqqFVnxURYoDK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bP9iqF/btsLPQEv2Xr/HmVQ0mgk7sqqFVnxURYoDK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bP9iqF/btsLPQEv2Xr/HmVQ0mgk7sqqFVnxURYoDK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbP9iqF%2FbtsLPQEv2Xr%2FHmVQ0mgk7sqqFVnxURYoDK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"에이서 스위프트 16 AI CPU\" loading=\"lazy\" width=\"773\" height=\"614\" data-origin-width=\"773\" data-origin-height=\"614\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>에이서 스위프트 16 AI</b>가 특별히 주목받는 이유 중 하나는 최신형 <b>인텔 코어 울트라 7 258V 프로세서</b> 덕분이에요. 이 CPU는 일반적인 프로세서 성능 개선을 넘어, <b>AI 작업에 특화된 전용 하드웨어</b>를 탑재하고 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">우선, 이 프로세서의 가장 큰 특징은 <b>NPU(신경망 처리 장치)</b>예요. 기존 CPU는 모든 작업을 동일한 프로세서 코어에서 처리했지만, 이 제품은 AI 연산을 NPU가 전담합니다. 예를 들어, 머신러닝 모델을 훈련시키거나 데이터 분석 작업을 수행할 때, NPU가 따로 일을 처리하기 때문에 작업 속도가 기존 프로세서 대비 월등히 빠르고 효율적이에요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">또한, <b>47TOPS(초당 연산 트릴리언 회수)</b>라는 AI 연산 성능은 복잡한 딥러닝 연산이나 대규모 시뮬레이션을 부드럽게 처리할 수 있는 수준입니다. 이 정도 성능은 데이터 과학자, AI 연구원, 개발자들이 주로 사용하는 고성능 워크스테이션과도 견줄 만하다고 할 수 있어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">여기에 더해, 이 CPU는 전력 효율성이 뛰어나서 배터리 소모를 줄이면서도 고성능을 유지할 수 있습니다. 예를 들어, AI 기반 앱을 장시간 실행하더라도 발열과 배터리 문제가 크게 줄어든다는 점은 정말 매력적이에요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">2️⃣ <b>Intel Arc 140V 그래픽으로 AI와 비주얼 작업을 한 번에</b></h2>\n<p data-ke-size=\"size16\">AI 작업은 그래픽 성능과도 밀접한 연관이 있죠. 특히 데이터 시각화, 영상 편집, 3D 모델링 같은 고사양 작업은 CPU와 GPU의 조화가 중요합니다. 에이서 스위프트 16 AI는 <b>Intel Arc 140V 그래픽 카드</b>를 탑재해 이 두 가지를 완벽히 충족시켜 줍니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 그래픽 카드는 머신러닝 모델의 시각화 작업이나 대규모 데이터 처리 시 병렬 연산 성능을 극대화해줍니다. 예를 들어, 딥러닝 모델의 훈련 과정을 시각적으로 확인하거나 복잡한 데이터 분석 결과를 시뮬레이션할 때, 기존 대비 훨씬 빠르고 정확하게 결과를 얻을 수 있어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">그래픽 성능이 뛰어난 덕분에, 영상 편집자나 디자이너처럼 고사양 작업이 잦은 분들에게도 큰 도움이 됩니다. <b>최대 1.5배 향상된 그래픽 처리 능력</b>은 4K 이상의 고해상도 영상 작업이나 3D 렌더링 프로젝트를 더욱 빠르게 처리할 수 있게 해줍니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">또한, 이 제품은 게이머들에게도 매력적입니다. 고사양 게임에서 요구하는 그래픽 처리량을 안정적으로 처리할 수 있어서, 업무와 오락 모두를 만족시킬 수 있는 만능형 노트북이에요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<div class=\"product-details-button-wrapper\">\n    <style>\n        .product-details-button-wrapper .button-container {\n            display: flex;\n            justify-content: center;\n            align-items: center;\n            padding: 20px 0;\n        }\n        .product-details-button-wrapper .product-details-button {\n            width: 600px;\n            height: 80px; /* 높이를 줄임 */\n            font-family: '맑은 고딕', 'Malgun Gothic', sans-serif;\n            font-weight: bold;\n            font-size: 28px; /* 글자 크기를 키움 */\n            color: white;\n            background: linear-gradient(145deg, #ff6b6b, #ee5253);\n            border: 4px solid #c0392b;\n            border-radius: 15px;\n            cursor: pointer;\n            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);\n            transition: all 0.3s ease;\n            overflow: hidden;\n            position: relative;\n            display: flex; /* 추가 */\n            justify-content: center; /* 추가 */\n            align-items: center; /* 추가 */\n        }\n        .product-details-button-wrapper .product-details-button:hover {\n            transform: scale(1.05);\n            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);\n        }\n        .product-details-button-wrapper .button-text {\n            position: relative;\n            z-index: 1;\n            animation: sparkle 1.5s infinite;\n        }\n        @keyframes sparkle {\n            0%, 100% { opacity: 1; }\n            50% { opacity: 0.7; }\n        }\n    </style>\n    <div class=\"button-container\">\n        <button class=\"product-details-button\">\n            <span class=\"button-text\">제품 상세 정보는 여기를 클릭하세요</span>\n        </button>\n    </div>\n    <script>\n        (function() {\n            var wrapper = document.currentScript.closest('.product-details-button-wrapper');\n            var button = wrapper.querySelector('.product-details-button');\n            // URL을 여기에 삽입하세요\n            var productDetailsUrl = \"https://link.coupang.com/a/cafzqG\";\n            button.addEventListener(\"click\", function() {\n                window.open(productDetailsUrl, '_self');\n            });\n        })();\n    </script>\n    <p style=\"text-align: center;\" data-ke-size=\"size14\"><span style=\"background-color: #ffffff; color: #0f0f0f; text-align: start;\">&lt;이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.&gt;</span></p>\n</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">3️⃣ <b>초경량 디자인으로 휴대성과 편리함을 모두 잡다</b></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"774\" data-origin-height=\"616\"><span data-url=\"https://blog.kakaocdn.net/dn/oznVM/btsLO8TfwWM/Q6Sk17gauKQJU2ONeW9cik/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/oznVM/btsLO8TfwWM/Q6Sk17gauKQJU2ONeW9cik/img.png\"><img src=\"https://blog.kakaocdn.net/dn/oznVM/btsLO8TfwWM/Q6Sk17gauKQJU2ONeW9cik/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FoznVM%2FbtsLO8TfwWM%2FQ6Sk17gauKQJU2ONeW9cik%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"에이서 스위프트 16 AI 디자인\" loading=\"lazy\" width=\"774\" height=\"616\" data-origin-width=\"774\" data-origin-height=\"616\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">노트북을 선택할 때 휴대성이 중요한 분들이 많으실 텐데요. 특히 매일같이 들고 다니는 직장인이나 학생들에게 <b>가벼운 무게와 슬림한 디자인</b>은 필수 조건이죠. 에이서 스위프트 16 AI는 <b>1.46kg</b>의 초경량 무게와 <b>15.95mm의 얇은 두께</b>로 휴대성을 극대화했어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">가방에 넣고 다녀도 부담스럽지 않은 무게와 디자인 덕분에, 외근이 잦은 직장인이나 이동 중 작업이 많은 프리랜서들에게 특히 유용합니다. 더불어, <b>180도 힌지</b>가 적용되어 회의 중 다른 사람과 화면을 쉽게 공유하거나, 여러 각도로 화면을 조정하며 편리하게 작업할 수 있어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">여기에 넓은 터치패드는 세밀한 작업이 필요할 때 큰 도움을 줍니다. 터치패드의 감도와 크기는 사용자의 편의성을 크게 좌우하는데, 이 제품은 그런 점에서도 아주 잘 설계되었어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">4️⃣ <b>생산성을 높이는 16인치 WQXGA+ 디스플레이</b></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"775\" data-origin-height=\"767\"><span data-url=\"https://blog.kakaocdn.net/dn/bbM2Ec/btsLQPYYSgC/4cjtK5e4D8mC0YknzNG8P1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bbM2Ec/btsLQPYYSgC/4cjtK5e4D8mC0YknzNG8P1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bbM2Ec/btsLQPYYSgC/4cjtK5e4D8mC0YknzNG8P1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbbM2Ec%2FbtsLQPYYSgC%2F4cjtK5e4D8mC0YknzNG8P1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"에이서 스위프트 16 AI 디스플레이\" loading=\"lazy\" width=\"775\" height=\"767\" data-origin-width=\"775\" data-origin-height=\"767\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">노트북 화면은 단순히 크기만 중요한 게 아니라, 해상도와 화면 비율도 생산성에 큰 영향을 미쳐요. <b>에이서 스위프트 16 AI</b>의 <b>16인치 WQXGA+ 디스플레이</b>는 그런 면에서 최고의 선택이에요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>2880x1800 해상도</b>는 텍스트, 이미지, 영상 모두를 선명하게 표현해주며, 세부적인 작업에서도 왜곡 없이 명확한 화면을 제공합니다. 특히, 해상도가 높으면 영상 편집이나 그래픽 작업에서 작은 디테일까지 확인할 수 있어 작업 효율이 크게 높아집니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">또한, <b>16:10 화면 비율</b>은 기존 16:9 비율보다 더 넓은 작업 공간을 제공해 여러 창을 띄워도 답답하지 않아요. 이 비율은 멀티태스킹 작업에 최적화되어 있어, 영상 편집자나 코딩 작업을 하는 분들에게 특히 유용합니다.</p>\n<p data-ke-size=\"size16\"><b>120Hz 주사율</b>은 화면 전환이 빠르고 부드러워 눈의 피로를 줄여줍니다. 특히, 그래픽 디자인이나 사진 보정 작업 중 미세한 화면 움직임이 필요할 때 이 기능이 크게 도움됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">5️⃣ <b>강력한 배터리로 하루 종일 충전 걱정 없이</b></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"772\" data-origin-height=\"652\"><span data-url=\"https://blog.kakaocdn.net/dn/bqu3mm/btsLP4CBYQY/7GKn2GczR3lAKqaRpkiNJ0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bqu3mm/btsLP4CBYQY/7GKn2GczR3lAKqaRpkiNJ0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bqu3mm/btsLP4CBYQY/7GKn2GczR3lAKqaRpkiNJ0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbqu3mm%2FbtsLP4CBYQY%2F7GKn2GczR3lAKqaRpkiNJ0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"에이서 스위프트 16 AI 배터리\" loading=\"lazy\" width=\"772\" height=\"652\" data-origin-width=\"772\" data-origin-height=\"652\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">긴 배터리 지속 시간은 외부에서 장시간 작업해야 하는 사용자들에게 필수 조건이죠. 에이서 스위프트 16 AI는 <b>70Wh 배터리</b>를 탑재해 하루 종일 충전 걱정 없이 사용할 수 있어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">비디오 재생 기준으로 <b>최대 20시간</b>, 일반 작업 기준으로 <b>17.5시간</b>, 웹 브라우징 기준으로 <b>13.5시간</b>까지 사용 가능합니다. 충전기를 따로 들고 다니지 않아도, 배터리가 오래 지속되니 가벼운 마음으로 이동할 수 있어요.</p>\n<p data-ke-size=\"size16\">특히, 출장이나 야외 촬영이 많은 분들에게 이 배터리 성능은 큰 장점으로 다가올 거예요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<div class=\"product-details-button-wrapper\">\n    <style>\n        .product-details-button-wrapper .button-container {\n            display: flex;\n            justify-content: center;\n            align-items: center;\n            padding: 20px 0;\n        }\n        .product-details-button-wrapper .product-details-button {\n            width: 600px;\n            height: 80px; /* 높이를 줄임 */\n            font-family: '맑은 고딕', 'Malgun Gothic', sans-serif;\n            font-weight: bold;\n            font-size: 28px; /* 글자 크기를 키움 */\n            color: white;\n            background: linear-gradient(145deg, #ff6b6b, #ee5253);\n            border: 4px solid #c0392b;\n            border-radius: 15px;\n            cursor: pointer;\n            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);\n            transition: all 0.3s ease;\n            overflow: hidden;\n            position: relative;\n            display: flex; /* 추가 */\n            justify-content: center; /* 추가 */\n            align-items: center; /* 추가 */\n        }\n        .product-details-button-wrapper .product-details-button:hover {\n            transform: scale(1.05);\n            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);\n        }\n        .product-details-button-wrapper .button-text {\n            position: relative;\n            z-index: 1;\n            animation: sparkle 1.5s infinite;\n        }\n        @keyframes sparkle {\n            0%, 100% { opacity: 1; }\n            50% { opacity: 0.7; }\n        }\n    </style>\n    <div class=\"button-container\">\n        <button class=\"product-details-button\">\n            <span class=\"button-text\">제품 상세 정보는 여기를 클릭하세요</span>\n        </button>\n    </div>\n    <script>\n        (function() {\n            var wrapper = document.currentScript.closest('.product-details-button-wrapper');\n            var button = wrapper.querySelector('.product-details-button');\n            // URL을 여기에 삽입하세요\n            var productDetailsUrl = \"https://link.coupang.com/a/cafzqG\";\n            button.addEventListener(\"click\", function() {\n                window.open(productDetailsUrl, '_self');\n            });\n        })();\n    </script>\n    <p style=\"text-align: center;\" data-ke-size=\"size14\"><span style=\"background-color: #ffffff; color: #0f0f0f; text-align: start;\">&lt;이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.&gt;</span></p>\n</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">6️⃣ <b>Windows 11과 Copilot으로 AI 활용을 극대화</b></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"757\" data-origin-height=\"703\"><span data-url=\"https://blog.kakaocdn.net/dn/bLNDWm/btsLRpMaSEW/PHaTwgUzuZmNKCmVYu0Hg1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bLNDWm/btsLRpMaSEW/PHaTwgUzuZmNKCmVYu0Hg1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bLNDWm/btsLRpMaSEW/PHaTwgUzuZmNKCmVYu0Hg1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbLNDWm%2FbtsLRpMaSEW%2FPHaTwgUzuZmNKCmVYu0Hg1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"에이서 스위프트 16 AI 코파일럿\" loading=\"lazy\" width=\"757\" height=\"703\" data-origin-width=\"757\" data-origin-height=\"703\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;AI 소프트웨어를 제대로 활용하려면 운영 체제와의 조화가 중요한데요, 에이서 스위프트 16 AI는 최신 <b>Windows 11</b>에 포함된 <b>Copilot</b> 기능을 탑재해 작업 효율을 극대화합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">Copilot은 번역, 문서 분석, PDF 요약, 웹 검색 같은 다양한 작업을 AI 기반으로 더 빠르고 정확하게 처리할 수 있게 도와줍니다. 여기에 <b>AcerSense</b>가 추가돼 시스템 최적화와 성능 관리까지 자동으로 이루어지니, 사용자 입장에서는 더 편리하죠.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"784\" data-origin-height=\"602\"><span data-url=\"https://blog.kakaocdn.net/dn/GsI8g/btsLQt9S2u4/ydyzhKseBDe6hI4HZJRMuk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/GsI8g/btsLQt9S2u4/ydyzhKseBDe6hI4HZJRMuk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/GsI8g/btsLQt9S2u4/ydyzhKseBDe6hI4HZJRMuk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FGsI8g%2FbtsLQt9S2u4%2FydyzhKseBDe6hI4HZJRMuk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"에이서 스위프트 16 AI 카메라\" loading=\"lazy\" width=\"784\" height=\"602\" data-origin-width=\"784\" data-origin-height=\"602\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;또한, <b>1440p QHD 카메라</b>와 <b>AI 기반 Windows Studio Effects</b> 기능이 더해져 화상회의나 온라인 학습에서도 탁월한 품질을 제공합니다. 배경 흐림, 자동 프레이밍, 아이컨택 같은 기능은 화상 통화 중 더 자연스럽고 편리한 경험을 선사합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">7️⃣ <b>튼튼한 내구성과 다양한 연결 옵션으로 완벽한 호환성 제공</b></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"769\" data-origin-height=\"649\"><span data-url=\"https://blog.kakaocdn.net/dn/cRyruq/btsLP7zekvo/NQyMLvkKkE6uYRZ4uCUk8k/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cRyruq/btsLP7zekvo/NQyMLvkKkE6uYRZ4uCUk8k/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cRyruq/btsLP7zekvo/NQyMLvkKkE6uYRZ4uCUk8k/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcRyruq%2FbtsLP7zekvo%2FNQyMLvkKkE6uYRZ4uCUk8k%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"에이서 스위프트 16 AI 내구성\" loading=\"lazy\" width=\"769\" height=\"649\" data-origin-width=\"769\" data-origin-height=\"649\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">노트북의 내구성은 장기적인 사용을 보장하는 중요한 요소인데요, 이 제품은 <b>MIL-STD-810G 인증</b>을 받아 다양한 환경에서도 안정적으로 사용할 수 있어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">포트 구성도 완벽합니다. <b>Thunderbolt&trade; 4</b>, <b>USB 3.2 Gen1</b>, <b>HDMI 2.1</b> 등의 포트를 지원해 다양한 외부 장치와 연결이 가능합니다. 이 정도 연결 옵션이면 업무 환경이 훨씬 더 유연해질 거예요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><b>결론: AI 노트북의 새로운 기준, 지금 바로 선택하세요!</b></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"775\" data-origin-height=\"588\"><span data-url=\"https://blog.kakaocdn.net/dn/B8nOH/btsLRFOSUhk/xtsnbs1aczMioyiKeosvO0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/B8nOH/btsLRFOSUhk/xtsnbs1aczMioyiKeosvO0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/B8nOH/btsLRFOSUhk/xtsnbs1aczMioyiKeosvO0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FB8nOH%2FbtsLRFOSUhk%2Fxtsnbs1aczMioyiKeosvO0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"에이서 스위프트 16 AI 제원\" loading=\"lazy\" width=\"775\" height=\"588\" data-origin-width=\"775\" data-origin-height=\"588\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>&nbsp;에이서 스위프트 16 AI</b>는 AI 기술을 제대로 활용하면서도, <b>성능, 디스플레이, 휴대성, 배터리</b>까지 완벽한 균형을 갖춘 제품이에요. 특히, 가격대비 뛰어난 성능 덕분에 가성비를 중시하는 사용자들에게 정말 좋은 선택이 될 거예요.<br /><br /></p>\n<p data-ke-size=\"size16\">최신 AI 기술을 활용해 생산성과 창의성을 높이고 싶으시다면, 더 이상 고민할 필요 없이 이 제품을 선택해 보세요.  ✨</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<div class=\"product-details-button-wrapper\">\n    <style>\n        .product-details-button-wrapper .button-container {\n            display: flex;\n            justify-content: center;\n            align-items: center;\n            padding: 20px 0;\n        }\n        .product-details-button-wrapper .product-details-button {\n            width: 600px;\n            height: 80px; /* 높이를 줄임 */\n            font-family: '맑은 고딕', 'Malgun Gothic', sans-serif;\n            font-weight: bold;\n            font-size: 28px; /* 글자 크기를 키움 */\n            color: white;\n            background: linear-gradient(145deg, #ff6b6b, #ee5253);\n            border: 4px solid #c0392b;\n            border-radius: 15px;\n            cursor: pointer;\n            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);\n            transition: all 0.3s ease;\n            overflow: hidden;\n            position: relative;\n            display: flex; /* 추가 */\n            justify-content: center; /* 추가 */\n            align-items: center; /* 추가 */\n        }\n        .product-details-button-wrapper .product-details-button:hover {\n            transform: scale(1.05);\n            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);\n        }\n        .product-details-button-wrapper .button-text {\n            position: relative;\n            z-index: 1;\n            animation: sparkle 1.5s infinite;\n        }\n        @keyframes sparkle {\n            0%, 100% { opacity: 1; }\n            50% { opacity: 0.7; }\n        }\n    </style>\n    <div class=\"button-container\">\n        <button class=\"product-details-button\">\n            <span class=\"button-text\">제품 상세 정보는 여기를 클릭하세요</span>\n        </button>\n    </div>\n    <script>\n        (function() {\n            var wrapper = document.currentScript.closest('.product-details-button-wrapper');\n            var button = wrapper.querySelector('.product-details-button');\n            // URL을 여기에 삽입하세요\n            var productDetailsUrl = \"https://link.coupang.com/a/cafzqG\";\n            button.addEventListener(\"click\", function() {\n                window.open(productDetailsUrl, '_self');\n            });\n        })();\n    </script>\n    <p style=\"text-align: center;\" data-ke-size=\"size14\"><span style=\"background-color: #ffffff; color: #0f0f0f; text-align: start;\">&lt;이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.&gt;</span></p>\n</div>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"kakaotv\" data-video-url=\"https://tv.kakao.com/v/452396312\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cEcAWC/hyX4nobXQb/BDmOOzuWlZXNdDr55YWw61/img.jpg?width=776&amp;height=442&amp;face=156_72_358_292,https://scrap.kakaocdn.net/dn/bj53RV/hyX0v9fYkz/yPQayThp8U0KkfXVUR2CG1/img.jpg?width=776&amp;height=442&amp;face=156_72_358_292\" data-video-width=\"776\" data-video-height=\"442\" data-video-origin-width=\"776\" data-video-origin-height=\"442\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"'어떤오후의 프리웨..'에서 업로드한 동영상\" data-video-play-service=\"daum_tistory\" data-original-url=\"\"><iframe src=\"https://play-tv.kakao.com/embed/player/cliplink/452396312?service=daum_tistory\" width=\"776\" height=\"442\" frameborder=\"0\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "요즘 AI 기술이 빠르게 발전하면서 관련 작업에 적합한 노트북을 찾는 일이 점점 더 중요해지고 있어요.\n\n\n \n 저도 비슷한 고민을 하던 중에 우연히 에이서 스위프트 16 AI를 발견하게 되었는데요. 단순히 \"AI 기술에 적합하다\"를 넘어서, 성능, 디자인, 휴대성, 배터리 지속 시간까지 어느 하나 빠지지 않는 제품이더라고요. 그래서 오늘은 이 노트북의 각 특징을 구체적으로 살펴보며, 여러분께 추천드리고자 합니다.\n \n \n1️⃣ 최신 인텔 코어 울트라 7로 AI 작업에 최적화된 퍼포먼스\n\n\n \n에이서 스위프트 16 AI가 특별히 주목받는 이유 중 하나는 최신형 인텔 코어 울트라 7 258V 프로세서 덕분이에요. 이 CPU는 일반적인 프로세서 성능 개선을 넘어, AI 작업에 특화된 전용 하드웨어를 탑재하고 있습니다.\n \n우선, 이 프로세서의 가장 큰 특징은 NPU(신경망 처리 장치)예요. 기존 CPU는 모든 작업을 동일한 프로세서 코어에서 처리했지만, 이 제품은 AI 연산을 NPU가 전담합니다. 예를 들어, 머신러닝 모델을 훈련시키거나 데이터 분석 작업을 수행할 때, NPU가 따로 일을 처리하기 때문에 작업 속도가 기존 프로세서 대비 월등히 빠르고 효율적이에요.\n \n또한, 47TOPS(초당 연산 트릴리언 회수)라는 AI 연산 성능은 복잡한 딥러닝 연산이나 대규모 시뮬레이션을 부드럽게 처리할 수 있는 수준입니다. 이 정도 성능은 데이터 과학자, AI 연구원, 개발자들이 주로 사용하는 고성능 워크스테이션과도 견줄 만하다고 할 수 있어요.\n \n여기에 더해, 이 CPU는 전력 효율성이 뛰어나서 배터리 소모를 줄이면서도 고성능을 유지할 수 있습니다. 예를 들어, AI 기반 앱을 장시간 실행하더라도 발열과 배터리 문제가 크게 줄어든다는 점은 정말 매력적이에요.\n \n \n2️⃣ Intel Arc 140V 그래픽으로 AI와 비주얼 작업을 한 번에\nAI 작업은 그래픽 성능과도 밀접한 연관이 있죠. 특히 데이터 시각화, 영상 편집, 3D 모델링 같은 고사양 작업은 CPU와 GPU의 조화가 중요합니다. 에이서 스위프트 16 AI는 Intel Arc 140V 그래픽 카드를 탑재해 이 두 가지를 완벽히 충족시켜 줍니다.\n \n이 그래픽 카드는 머신러닝 모델의 시각화 작업이나 대규모 데이터 처리 시 병렬 연산 성능을 극대화해줍니다. 예를 들어, 딥러닝 모델의 훈련 과정을 시각적으로 확인하거나 복잡한 데이터 분석 결과를 시뮬레이션할 때, 기존 대비 훨씬 빠르고 정확하게 결과를 얻을 수 있어요.\n \n그래픽 성능이 뛰어난 덕분에, 영상 편집자나 디자이너처럼 고사양 작업이 잦은 분들에게도 큰 도움이 됩니다. 최대 1.5배 향상된 그래픽 처리 능력은 4K 이상의 고해상도 영상 작업이나 3D 렌더링 프로젝트를 더욱 빠르게 처리할 수 있게 해줍니다.\n \n또한, 이 제품은 게이머들에게도 매력적입니다. 고사양 게임에서 요구하는 그래픽 처리량을 안정적으로 처리할 수 있어서, 업무와 오락 모두를 만족시킬 수 있는 만능형 노트북이에요.\n \n제품 상세 정보는 여기를 클릭하세요\n        \n    \n<이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.>\n \n3️⃣ 초경량 디자인으로 휴대성과 편리함을 모두 잡다\n\n\n노트북을 선택할 때 휴대성이 중요한 분들이 많으실 텐데요. 특히 매일같이 들고 다니는 직장인이나 학생들에게 가벼운 무게와 슬림한 디자인은 필수 조건이죠. 에이서 스위프트 16 AI는 1.46kg의 초경량 무게와 15.95mm의 얇은 두께로 휴대성을 극대화했어요.\n \n가방에 넣고 다녀도 부담스럽지 않은 무게와 디자인 덕분에, 외근이 잦은 직장인이나 이동 중 작업이 많은 프리랜서들에게 특히 유용합니다. 더불어, 180도 힌지가 적용되어 회의 중 다른 사람과 화면을 쉽게 공유하거나, 여러 각도로 화면을 조정하며 편리하게 작업할 수 있어요.\n \n여기에 넓은 터치패드는 세밀한 작업이 필요할 때 큰 도움을 줍니다. 터치패드의 감도와 크기는 사용자의 편의성을 크게 좌우하는데, 이 제품은 그런 점에서도 아주 잘 설계되었어요.\n \n \n4️⃣ 생산성을 높이는 16인치 WQXGA+ 디스플레이\n\n\n \n노트북 화면은 단순히 크기만 중요한 게 아니라, 해상도와 화면 비율도 생산성에 큰 영향을 미쳐요. 에이서 스위프트 16 AI의 16인치 WQXGA+ 디스플레이는 그런 면에서 최고의 선택이에요.\n \n2880x1800 해상도는 텍스트, 이미지, 영상 모두를 선명하게 표현해주며, 세부적인 작업에서도 왜곡 없이 명확한 화면을 제공합니다. 특히, 해상도가 높으면 영상 편집이나 그래픽 작업에서 작은 디테일까지 확인할 수 있어 작업 효율이 크게 높아집니다.\n \n또한, 16:10 화면 비율은 기존 16:9 비율보다 더 넓은 작업 공간을 제공해 여러 창을 띄워도 답답하지 않아요. 이 비율은 멀티태스킹 작업에 최적화되어 있어, 영상 편집자나 코딩 작업을 하는 분들에게 특히 유용합니다.\n120Hz 주사율은 화면 전환이 빠르고 부드러워 눈의 피로를 줄여줍니다. 특히, 그래픽 디자인이나 사진 보정 작업 중 미세한 화면 움직임이 필요할 때 이 기능이 크게 도움됩니다.\n \n \n5️⃣ 강력한 배터리로 하루 종일 충전 걱정 없이\n\n\n \n긴 배터리 지속 시간은 외부에서 장시간 작업해야 하는 사용자들에게 필수 조건이죠. 에이서 스위프트 16 AI는 70Wh 배터리를 탑재해 하루 종일 충전 걱정 없이 사용할 수 있어요.\n \n비디오 재생 기준으로 최대 20시간, 일반 작업 기준으로 17.5시간, 웹 브라우징 기준으로 13.5시간까지 사용 가능합니다. 충전기를 따로 들고 다니지 않아도, 배터리가 오래 지속되니 가벼운 마음으로 이동할 수 있어요.\n특히, 출장이나 야외 촬영이 많은 분들에게 이 배터리 성능은 큰 장점으로 다가올 거예요.\n \n제품 상세 정보는 여기를 클릭하세요\n        \n    \n<이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.>\n \n6️⃣ Windows 11과 Copilot으로 AI 활용을 극대화\n\n\n \n AI 소프트웨어를 제대로 활용하려면 운영 체제와의 조화가 중요한데요, 에이서 스위프트 16 AI는 최신 Windows 11에 포함된 Copilot 기능을 탑재해 작업 효율을 극대화합니다.\n \nCopilot은 번역, 문서 분석, PDF 요약, 웹 검색 같은 다양한 작업을 AI 기반으로 더 빠르고 정확하게 처리할 수 있게 도와줍니다. 여기에 AcerSense가 추가돼 시스템 최적화와 성능 관리까지 자동으로 이루어지니, 사용자 입장에서는 더 편리하죠.\n\n\n \n 또한, 1440p QHD 카메라와 AI 기반 Windows Studio Effects 기능이 더해져 화상회의나 온라인 학습에서도 탁월한 품질을 제공합니다. 배경 흐림, 자동 프레이밍, 아이컨택 같은 기능은 화상 통화 중 더 자연스럽고 편리한 경험을 선사합니다.\n \n \n7️⃣ 튼튼한 내구성과 다양한 연결 옵션으로 완벽한 호환성 제공\n\n\n노트북의 내구성은 장기적인 사용을 보장하는 중요한 요소인데요, 이 제품은 MIL-STD-810G 인증을 받아 다양한 환경에서도 안정적으로 사용할 수 있어요.\n \n포트 구성도 완벽합니다. Thunderbolt™ 4, USB 3.2 Gen1, HDMI 2.1 등의 포트를 지원해 다양한 외부 장치와 연결이 가능합니다. 이 정도 연결 옵션이면 업무 환경이 훨씬 더 유연해질 거예요.\n \n \n결론: AI 노트북의 새로운 기준, 지금 바로 선택하세요!\n\n\n \n 에이서 스위프트 16 AI는 AI 기술을 제대로 활용하면서도, 성능, 디스플레이, 휴대성, 배터리까지 완벽한 균형을 갖춘 제품이에요. 특히, 가격대비 뛰어난 성능 덕분에 가성비를 중시하는 사용자들에게 정말 좋은 선택이 될 거예요.\n\n최신 AI 기술을 활용해 생산성과 창의성을 높이고 싶으시다면, 더 이상 고민할 필요 없이 이 제품을 선택해 보세요.  ✨\n \n제품 상세 정보는 여기를 클릭하세요\n        \n    \n<이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.>",
        "guid": "https://muzbox.tistory.com/483527",
        "categories": [
          "신제품 리뷰/컴퓨터",
          "ai노트북추천",
          "가성비노트북",
          "노트북추천",
          "에이서 스위프트 16 ai",
          "에이서노트북",
          "인공지능 노트북"
        ],
        "isoDate": "2025-01-17T00:54:33.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "［RULIWEB］",
        "title": "[MULTI] 시리즈의 미래를 밝힐 긍정적 변화, 진 · 삼국무쌍 ORIGINS",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2280",
        "pubDate": "Thu, 16 Jan 2025 15:24:47 +0900",
        "author": "［RULIWEB］",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/25/01/16/1946dc8b4c75104c1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2025-01-16T06:24:47.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": [
      {
        "title": "AI 도구를 써도 돈 벌기는 힘들다",
        "link": "https://jeho.page/essay/2025/01/22/making-a-difference.html",
        "pubDate": "2025-01-22T14:41:00.000Z",
        "author": "김재호",
        "content": "<p>Cursor로 코딩하니까 예전보다 분명 빨라졌는데 그래도 여전히 앱 하나 완성하기가 힘듭니다.<br />\n예전에는 이 힘든 노가다를 대체 어떻게 했는지 모르겠습니다.<br />\n그래서 그 많은 사람들이 매일 야근을 했던 걸까요?</p>\n\n<p>앱 개발이 쉬워진 건 분명하지만 돈 벌기까지 쉬워진 건 아닙니다. 돈 벌기는 항상 어려웠습니다.<br />\n오래전에 홈페이지만 만들면 몇백만 원 준다던 시절이 있었다지만, 그때도 돈 벌기는 어려웠을 겁니다. 그 시절에 컴퓨터를 가지고 있고 HTML 을 다룰 줄 안다는 것 자체가 특별한 일이었기에. 코딩을 하는 사람들이 많아지자 눈높이가 높아져 ajax를 이용한 복잡한 웹페이지를 만들어달라는 요구로 변해갔습니다.</p>\n\n<p>서비스를 잘 만들기만 하면 돈을 벌 수 있는 것은 아닙니다. <strong>경쟁자보다 더 잘 만들어야</strong> 돈을 벌 수 있습니다.<br />\n돈을 벌어주다 주는 것은 결국 <strong>차이</strong>인 것입니다. 기술의 차이, 사용자 경험의 차이. 마케팅의 차이.<br />\nAI가 며칠 만에 만들어준 앱으로 돈 벌기는 어려울 겁니다. 차이를 만들어 낼 수 없으니까.</p>\n\n<p>예전에는 <a href=\"/essay/2021/09/05/코딩은-어렵다.html\">그 힘든 노가다</a>를 하던 것 자체가 해자였습니다.<br />\n앱을 만든다는 것이 너무 고통스러웠기 때문에.<br />\n그 고통을 견뎌낼 수 있는 사람이 적었기 때문에.<br />\n이제 앱을 완성하는 것 자체는 많이 쉬워진 것 같습니다. 하지만 차이를 만들어 내려면 모든 면에서 예전보다 더 잘해야 합니다.</p>\n\n<p>3년쯤 지나면 이 시장이 어떻게 변해있을까요? 짐작도 가지 않습니다.<br />\n내가 언제까지 이 시장에서 살아남을 수 있을까? 이제 정말 끝물인 건 아닐까? 약간 초조한 마음도 듭니다.<br />\n지금이 마지막이라고 생각하고 하나라도 더 만들어봐야겠다는 생각입니다.<br />\n오늘 오랜만에 10시간 코딩을 했습니다. 다행인 것은 <a href=\"/essay/2024/12/23/writing-code.html\">AI로 코딩하면서도 꽤나 즐거웠다는 겁니다.</a></p>\n\n<p><br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2024/07/26/good-day.html\">코딩 많이 한 날</a></li>\n  <li><a href=\"/essay/2021/09/05/코딩은-어렵다.html\">코딩은 어렵다</a></li>\n</ul>",
        "contentSnippet": "Cursor로 코딩하니까 예전보다 분명 빨라졌는데 그래도 여전히 앱 하나 완성하기가 힘듭니다.\n앱 개발이 쉬워진 건 분명하지만 돈 벌기까지 쉬워진 건 아닙니다. 돈 벌기는 항상 어려웠습니다.\n서비스를 잘 만들기만 하면 돈을 벌 수 있는 것은 아닙니다. 경쟁자보다 더 잘 만들어야 돈을 벌 수 있습니다.\n차이인 것입니다. 기술의 차이, 사용자 경험의 차이. 마케팅의 차이.\n예전에는 그 힘든 노가다를 하던 것 자체가 해자였습니다.\n3년쯤 지나면 이 시장이 어떻게 변해있을까요? 짐작도 가지 않습니다.\nAI로 코딩하면서도 꽤나 즐거웠다는 겁니다.\n\n함께 읽으면 좋은 글:\n코딩 많이 한 날\n코딩은 어렵다",
        "summary": "Cursor로 코딩하니까 예전보다 분명 빨라졌는데 그래도 여전히 앱 하나 완성하기가 힘듭니다. 예전에는 이 힘든 노가다를 대체 어떻게 했는지 모르겠습니다. 그래서 그 많은 사람들이 매일 야근을 했던 걸까요?",
        "id": "https://jeho.page/essay/2025/01/22/making-a-difference",
        "isoDate": "2025-01-22T14:41:00.000Z"
      },
      {
        "title": "인터넷을 처음 하던 날",
        "link": "https://jeho.page/essay/2025/01/21/internet-day1.html",
        "pubDate": "2025-01-21T09:55:00.000Z",
        "author": "김재호",
        "content": "<p>인터넷을 처음 접한 건 2000년 1월 1일이었습니다.<br />\n저 스스로도 놀라운 날짜입니다. 2000년 1월 1일이라니. 이런 우연이 다 있나..?<br />\n1990년대 내내 컴퓨터 앞에서 살았고, 1996년부터는 PC 통신도 많이 했습니다만, <strong>인터넷</strong>이라고 불리는 것은 한 번도 써보질 않았던 것입니다.</p>\n\n<p>1999년 말에는 2000년이 되면 밀레니엄 버그 때문에 난리가 날 거라고 떠들썩 했는데 막상 2000년 1월 1일이 되자 별다른 일은 일어나지 않았습니다.\n이 일이 어쩌면 영향이 있었던 건가? 처음으로 인터넷 익스플로러를 켜서 여기저기 사이트를 돌아다녔던 것 같습니다.</p>\n\n<p>와레즈라는 사이트를 그때 처음 알았습니다. 아니, 이런 세계가 있었단 말이야?<br />\nFIFA 2000을 다운로드하면서 잠이 들었었는데 50MB 쯤 되는 파일을 밤새도록 받았습니다.<br />\n(밤 10시부터 아침 9시까진가 통신 정액제가 있었던 것 같네요)</p>\n\n<p>다음 날 눈을 뜨자마자 반쯤 의심하며 실행해 봤는데 프로그램이 열리고 <a href=\"https://www.youtube.com/watch?v=ecrph82o6FU\">노래가 흘러나올 때</a> 두근거리고 기쁘던 감정을 아직 기억합니다.</p>\n\n<h1 id=\"인터넷과--pc--통신의-차이\">인터넷과  PC  통신의 차이</h1>\n<p>사실 저는 아직도 PC 통신과 인터넷의 차이를 잘 구분하지 못합니다만, 궁금해진 김에 챗지피티를 통해서 알아봤습니다.</p>\n\n<p>PC 통신은 TCP/IP로 연결했던 것이 아니라 시리얼 통신으로 연결했던 것 같습니다.<br />\n즉, 시리얼 포트에 모뎀을 꼽고 ‘01410’ 이란 번호로 전화 걸기 명령을 보내서 전화 연결을 하고, 서버에서는 역시 전화선을 통해 텍스트로 메뉴 구성을 알려줍니다.</p>\n\n<p>그 시절 PC 통신을 하기 위한 프로그램이었던 <code class=\"language-plaintext highlighter-rouge\">이야기</code>나 <code class=\"language-plaintext highlighter-rouge\">새롬데이터맨</code>은 다음처럼 짰을 것 같습니다.</p>\n\n<div class=\"language-c++ highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">HANDLE</span> <span class=\"n\">hCom</span> <span class=\"o\">=</span> <span class=\"n\">CreateFile</span><span class=\"p\">(</span>\n    <span class=\"s\">L\"COM1\"</span><span class=\"p\">,</span> <span class=\"c1\">// 모뎀이 꼽혀 있는 시리얼 포트</span>\n    <span class=\"n\">GENERIC_READ</span> <span class=\"o\">|</span> <span class=\"n\">GENERIC_WRITE</span><span class=\"p\">,</span>\n    <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"nb\">NULL</span><span class=\"p\">,</span>\n    <span class=\"n\">OPEN_EXISTING</span><span class=\"p\">,</span>\n    <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"nb\">NULL</span>\n<span class=\"p\">);</span>\n\n<span class=\"c1\">// 모뎀으로 전화 걸기 명령 전송 (하이텔의 전화번호 01410)</span>\n<span class=\"n\">WriteFile</span><span class=\"p\">(</span><span class=\"n\">hCom</span><span class=\"p\">,</span> <span class=\"s\">\"ATD01410</span><span class=\"se\">\\r\\n</span><span class=\"s\">\"</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">DWORD</span><span class=\"p\">)</span><span class=\"n\">strlen</span><span class=\"p\">(</span><span class=\"n\">atCmd</span><span class=\"p\">),</span> <span class=\"o\">&amp;</span><span class=\"n\">bytesWritten</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">);</span>\n\n<span class=\"c1\">// 서버로부터 ASCII 코드로 하이텔 대문을 받아와서 뿌려줌</span>\n\n<span class=\"c1\">// 메뉴 구성 보여주기</span>\n<span class=\"c1\">// (1) 게시판, (2) 자료실, (3) 채팅방</span>\n</code></pre></div></div>\n\n<p><code class=\"language-plaintext highlighter-rouge\">1</code>, <code class=\"language-plaintext highlighter-rouge\">2</code> 같은 메뉴의 번호를 별다른 프로토콜도 없이 raw string 에 가깝게 서버와 주고받았던 것 같네요.<br />\n채팅방 내에서 이상한 문자열을 입력해서 채팅방을 강제로 파괴하던 사람들이 있었는데, 이제야 어떻게 했는지 알 것 같습니다.</p>\n\n<p>지금 보면 참 조잡하지만, 이때 코딩하던 개발자들은 정말 신기하고 재밌었을 것 같습니다.<br />\n아마 새로운 세상을 창조해낸 기분 아니었을까?<br />\nPC 통신이 처음 시작되던 시절에 그런 기쁨을 함께 느껴보지 못했다는 게 아쉽습니다.</p>\n\n<p><img src=\"/assets/img/kitel.jpg\" alt=\"PC통신의 역사\" /><br />\n<em>넥슨컴퓨터 박물관, 2022년</em></p>\n\n<p><br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2022/11/05/old-memories-of-computers.html\">허큘리스 카드와 사운드 블라스터 그리고 PC통신</a></li>\n  <li><a href=\"https://brunch.co.kr/@buildingking/107\">넥슨 컴퓨터 박물관에 가는 날</a></li>\n</ul>",
        "contentSnippet": "인터넷을 처음 접한 건 2000년 1월 1일이었습니다.\n인터넷이라고 불리는 것은 한 번도 써보질 않았던 것입니다.\n1999년 말에는 2000년이 되면 밀레니엄 버그 때문에 난리가 날 거라고 떠들썩 했는데 막상 2000년 1월 1일이 되자 별다른 일은 일어나지 않았습니다.\n이 일이 어쩌면 영향이 있었던 건가? 처음으로 인터넷 익스플로러를 켜서 여기저기 사이트를 돌아다녔던 것 같습니다.\n와레즈라는 사이트를 그때 처음 알았습니다. 아니, 이런 세계가 있었단 말이야?\n다음 날 눈을 뜨자마자 반쯤 의심하며 실행해 봤는데 프로그램이 열리고 노래가 흘러나올 때 두근거리고 기쁘던 감정을 아직 기억합니다.\n인터넷과  PC  통신의 차이\n사실 저는 아직도 PC 통신과 인터넷의 차이를 잘 구분하지 못합니다만, 궁금해진 김에 챗지피티를 통해서 알아봤습니다.\nPC 통신은 TCP/IP로 연결했던 것이 아니라 시리얼 통신으로 연결했던 것 같습니다.\n그 시절 PC 통신을 하기 위한 프로그램이었던 이야기나 새롬데이터맨은 다음처럼 짰을 것 같습니다.\n\nHANDLE hCom = CreateFile(\n    L\"COM1\", // 모뎀이 꼽혀 있는 시리얼 포트\n    GENERIC_READ | GENERIC_WRITE,\n    0,\n    NULL,\n    OPEN_EXISTING,\n    0,\n    NULL\n);\n\n// 모뎀으로 전화 걸기 명령 전송 (하이텔의 전화번호 01410)\nWriteFile(hCom, \"ATD01410\\r\\n\", (DWORD)strlen(atCmd), &bytesWritten, NULL);\n\n// 서버로부터 ASCII 코드로 하이텔 대문을 받아와서 뿌려줌\n\n// 메뉴 구성 보여주기\n// (1) 게시판, (2) 자료실, (3) 채팅방\n\n\n1, 2 같은 메뉴의 번호를 별다른 프로토콜도 없이 raw string 에 가깝게 서버와 주고받았던 것 같네요.\n지금 보면 참 조잡하지만, 이때 코딩하던 개발자들은 정말 신기하고 재밌었을 것 같습니다.\n\n넥슨컴퓨터 박물관, 2022년\n\n함께 읽으면 좋은 글:\n허큘리스 카드와 사운드 블라스터 그리고 PC통신\n넥슨 컴퓨터 박물관에 가는 날",
        "summary": "인터넷을 처음 접한 건 2000년 1월 1일이었습니다. 저 스스로도 놀라운 날짜입니다. 2000년 1월 1일이라니. 이런 우연이 다 있나..? 1990년대 내내 컴퓨터 앞에서 살았고, 1996년부터는 PC 통신도 많이 했습니다만, 인터넷이라고 불리는 것은 한 번도 써보질 않았던 것입니다.",
        "id": "https://jeho.page/essay/2025/01/21/internet-day1",
        "isoDate": "2025-01-21T09:55:00.000Z"
      },
      {
        "title": "팀장님의 칭찬",
        "link": "https://jeho.page/essay/2025/01/20/praise-from-roy.html",
        "pubDate": "2025-01-20T08:54:00.000Z",
        "author": "김재호",
        "content": "<p>오랜만에 예전 팀 사람들과 점심을 함께했습니다.<br />\n거의 10년 가까이 못 본 친구들도 있었고, 우리 모두에게 존경받던 팀장님도 함께했습니다.</p>\n\n<p>다들 존경하고 우러러보던 팀장님의 그 시절 한 마디는 힘이 셌습니다.<br />\n팀장님이 뭔가 질문을 하면 다들 뜨끔할 정도로.</p>\n\n<p>중요한 뭔가를 놓치고 있거나, 흐리멍텅하게 일하고 있을 때.<br />\n긴장이 풀려있을 때면 어김없이 팀장님의 질문이 날아왔습니다.</p>\n\n<p>“벤자민, 이런 이런 부분도 고려하고 있는거니?”</p>\n\n<p>말이 질문이지, 사실은 정신 똑바로 차리고 일하라는 가르침이었습니다.</p>\n\n<p>다들 사고를 많이 쳐서 혼나기 일쑤였습니다만, 가끔 팀장이 칭찬을 해주실 때도 있었습니다.<br />\n누군가 칭찬을 받으면 팀원 모두가 부러워했습니다. 우와 팀장님한테 칭찬을 다 들었네.</p>\n\n<p>오늘 점심을 먹으면서 팀장님에게 칭찬을 들었습니다.<br />\n블로그 잘 읽고 있는데, 생각이 탄탄해서 좋다고.<br />\n팀장님도 미처 생각해보지 못한 이야기들이 있다고.<br />\n10년 전에 알던 저와는 많이 달라졌다고.</p>\n\n<p>우와, 이거 최고의 칭찬인 걸.<br />\n팀장님께 생각이 탄탄하단 소리를 듣다니.<br />\n같이 있던 동료들이 부러운 눈으로 쳐다봤습니다. 마치 10년 전 우리들처럼.</p>\n\n<p>저도 입이 찢어졌습니다.<br />\n회사 그만두고 혼자 지내면서 성장이 멈췄다고 생각했는데 그렇지 않았구나.<br />\n어쩌면 혼자 지내면서 더 많이 성장하게 된 건 아닐까?</p>\n\n<p>아무리 생각해도 기분이 좋아서 헤어지고 나서도 종일 헤벌쭉 해있는 걸 보니 저는 아직도 어린애입니다.(웃음)</p>\n\n<p><br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2021/09/10/왜-막내들은-항상-바깥쪽-자리에-앉아야-하나요.html\">왜 막내들은 항상 바깥쪽 자리에 앉아야 하나요?</a></li>\n  <li><a href=\"/essay/2021/11/02/윗사람과-아랫사람.html\">윗사람과 아랫사람</a></li>\n</ul>",
        "contentSnippet": "오랜만에 예전 팀 사람들과 점심을 함께했습니다.\n다들 존경하고 우러러보던 팀장님의 그 시절 한 마디는 힘이 셌습니다.\n중요한 뭔가를 놓치고 있거나, 흐리멍텅하게 일하고 있을 때.\n“벤자민, 이런 이런 부분도 고려하고 있는거니?”\n말이 질문이지, 사실은 정신 똑바로 차리고 일하라는 가르침이었습니다.\n다들 사고를 많이 쳐서 혼나기 일쑤였습니다만, 가끔 팀장이 칭찬을 해주실 때도 있었습니다.\n오늘 점심을 먹으면서 팀장님에게 칭찬을 들었습니다.\n우와, 이거 최고의 칭찬인 걸.\n저도 입이 찢어졌습니다.\n아무리 생각해도 기분이 좋아서 헤어지고 나서도 종일 헤벌쭉 해있는 걸 보니 저는 아직도 어린애입니다.(웃음)\n\n함께 읽으면 좋은 글:\n왜 막내들은 항상 바깥쪽 자리에 앉아야 하나요?\n윗사람과 아랫사람",
        "summary": "오랜만에 예전 팀 사람들과 점심을 함께했습니다. 거의 10년 가까이 못 본 친구들도 있었고, 우리 모두에게 존경받던 팀장님도 함께했습니다.",
        "id": "https://jeho.page/essay/2025/01/20/praise-from-roy",
        "isoDate": "2025-01-20T08:54:00.000Z"
      },
      {
        "title": "홈택스 칭찬",
        "link": "https://jeho.page/essay/2025/01/16/cheer-up-hometax.html",
        "pubDate": "2025-01-16T04:25:00.000Z",
        "author": "김재호",
        "content": "<p>부가세 신고를 하면서 홈택스에 구글의 인앱 결제 매출이 집계되기 시작했다는 걸 알았습니다.<br />\n구글에서 국세청으로 드디어 매출을 건네주기 시작한 것 같습니다.</p>\n\n<p>그동안은 매출을 건네주지 않고 있었냐? 그렇습니다.<br />\n구글이나 애플이 우리나라에 세금을 제대로 안 내고 있다는 말은 워낙 많았으니까요.</p>\n\n<p>구글이나 애플뿐만이 아니라 앱 개발자들도 매출을 누락시켜 신고하거나, 신고조차 하지 않는 사람들이 있었을 걸로 추측합니다.<br />\n어차피 국세청에서 모를 테니까. 이제 그런 탈세는 하지 못하게 되었습니다. 잘된 일입니다.<br />\n(굳이 강조하자면 <a href=\"https://withcoffee.app/\">커피한잔</a>은 돈을 거의 못 벌 때조차 항상 정직하게 매출을 신고했습니다.)</p>\n\n<p>저는 구글과 애플의 오랜 주주이고 이들이 세상 사람들의 돈을 다 긁어 모으는 것이 좋으면서도… <br />\n우리나라에 세금을 제대로 안 내는 부분은 영 못 마땅한 이중적인 입장에 있었습니다.<br />\n이제 드디어 구글이 세금을 제대로 내려는 의지를 보여줬으니 기쁘게 생각합니다. 애플도 얼른 매출 데이터를 보내주면 좋겠습니다.</p>\n\n<p>국세청에 대한 칭찬도 하고 싶습니다. 홈택스는 볼 때마다 편리한 기능이 추가되고 감탄하게 됩니다.<br />\n정부 사이트들 중 이렇게 서비스에 열심인 곳이 또 있을까?<br />\n돈 걷어야 해서 더 열심히 하는 것이겠지만 (ㅋㅋ) 그래도 괜찮습니다.<br />\n(거지같이 만들어 놓고 돈 걷는다 생각하면 얼마나 열받겠습니까?)</p>\n\n<p>홈택스는 <a href=\"https://www.sejungilbo.com/news/articleView.html?idxno=44309\">세무사들의 반발</a>때문에 혁신하기가 쉽지 않은 서비스이기도 합니다.<br />\n너무 잘 만들어버리면 영세한 세무사무실들은 문을 닫아야 할 테니.<br />\n그럼에도 불구하고 혁신의 의지가 느껴지는 유일한 정부 사이트 아닌가 생각합니다. 응원하고 있습니다.</p>\n\n<p>반면에 정부 사이트들 중 가장 한숨이 나오는 사이트는 법원 사이트입니다. 인터넷 등기소, 전자 소송.<br />\n2025년에도 https 조차되어있지 않고 밤늦은 시간이 되면 문을 닫는(?) 믿기 힘든 사이트.</p>\n\n<p>하지만 이런 법원 사이트도 며칠 후 개편될 예정입니다.<br />\n이제 정말 막바지 작업을 하고 있는 것 같습니다.</p>\n\n<p><img src=\"/assets/img/scourt.png\" alt=\"법원 사이트 개편\" /></p>\n\n<p>공지사항을 읽어보니 약간 걱정이 들기도 합니다.\n세상 어떤 사이트가 개편을 위한 작업 중단을 6일씩이나 하는 걸까? 아마 책임자는 큰 개편이니 충분히 시간을 확보하고 싶었을 것 같습니다.<br />\n하지만 사용자들 생각은 너무 뒷전인거 아닌가…?</p>\n\n<p>카톡, 당근, 쿠팡 같은 서비스가 5분이라도 멈췄을 때 서비스를 복구하기 위해 얼마나 애쓰는지 상상해 보면…<br />\n정부 관리자의 사용자를 배려하는 마음은 달라도 너무 다른 것 같습니다.<br />\n이런 감독하에 만들어진 사이트가 얼마나 좋아졌을지 염려가 되는 것도 사실입니다.</p>\n\n<p>제 염려가 무색할 만큼 좋은 사이트가 출시되길 기대합니다.</p>\n\n<p><br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2024/10/21/government-sponsored.html\">정부의 창업 지원 (비대면 바우처)</a></li>\n  <li><a href=\"/essay/2024/10/18/business-registration.html\">개인 사업자와 법인 사업자</a></li>\n</ul>",
        "contentSnippet": "부가세 신고를 하면서 홈택스에 구글의 인앱 결제 매출이 집계되기 시작했다는 걸 알았습니다.\n그동안은 매출을 건네주지 않고 있었냐? 그렇습니다.\n구글이나 애플뿐만이 아니라 앱 개발자들도 매출을 누락시켜 신고하거나, 신고조차 하지 않는 사람들이 있었을 걸로 추측합니다.\n커피한잔은 돈을 거의 못 벌 때조차 항상 정직하게 매출을 신고했습니다.)\n저는 구글과 애플의 오랜 주주이고 이들이 세상 사람들의 돈을 다 긁어 모으는 것이 좋으면서도… \n국세청에 대한 칭찬도 하고 싶습니다. 홈택스는 볼 때마다 편리한 기능이 추가되고 감탄하게 됩니다.\n홈택스는 세무사들의 반발때문에 혁신하기가 쉽지 않은 서비스이기도 합니다.\n반면에 정부 사이트들 중 가장 한숨이 나오는 사이트는 법원 사이트입니다. 인터넷 등기소, 전자 소송.\n하지만 이런 법원 사이트도 며칠 후 개편될 예정입니다.\n\n공지사항을 읽어보니 약간 걱정이 들기도 합니다.\n세상 어떤 사이트가 개편을 위한 작업 중단을 6일씩이나 하는 걸까? 아마 책임자는 큰 개편이니 충분히 시간을 확보하고 싶었을 것 같습니다.\n카톡, 당근, 쿠팡 같은 서비스가 5분이라도 멈췄을 때 서비스를 복구하기 위해 얼마나 애쓰는지 상상해 보면…\n제 염려가 무색할 만큼 좋은 사이트가 출시되길 기대합니다.\n\n함께 읽으면 좋은 글:\n정부의 창업 지원 (비대면 바우처)\n개인 사업자와 법인 사업자",
        "summary": "부가세 신고를 하면서 홈택스에 구글의 인앱 결제 매출이 집계되기 시작했다는 걸 알았습니다. 구글에서 국세청으로 드디어 매출을 건네주기 시작한 것 같습니다.",
        "id": "https://jeho.page/essay/2025/01/16/cheer-up-hometax",
        "isoDate": "2025-01-16T04:25:00.000Z"
      }
    ]
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "시위대안에 중국 프락치 있다.",
        "link": "http://serverdown.tistory.com/1118",
        "pubDate": "Thu, 23 Jan 2025 01:24:44 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1118#entry1118comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=cMwL2ncb3Us\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=cMwL2ncb3Us</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=cMwL2ncb3Us\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bfMVFc/hyX4wsXg5O/IHXrsCBh3kANyJuRJap2l0/img.jpg?width=1280&amp;height=720&amp;face=570_174_730_348,https://scrap.kakaocdn.net/dn/BtT4D/hyX4p1FlE1/wrno57NcurGezkZGXXbS81/img.jpg?width=1280&amp;height=720&amp;face=570_174_730_348\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"[단독] 서부지법 폭동 당시 분열을 주도하던 중국인...? 서부지법 폭력사태의 소름돋는 진실\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/cMwL2ncb3Us\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">억양도 중국 억양이고</p>\n<p data-ke-size=\"size16\">하지말라는데 잘보이는데 굳이 올라가서 위험한 짓하고</p>\n<p data-ke-size=\"size16\">의도된 움직임으로 보입니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=cMwL2ncb3Us\n\n\n\n억양도 중국 억양이고\n하지말라는데 잘보이는데 굳이 올라가서 위험한 짓하고\n의도된 움직임으로 보입니다.",
        "guid": "http://serverdown.tistory.com/1118",
        "categories": [
          "유튜브",
          "간첩"
        ],
        "isoDate": "2025-01-22T16:24:44.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "MBC 에 간첩 편집자가 있다.",
        "link": "http://serverdown.tistory.com/1117",
        "pubDate": "Thu, 23 Jan 2025 01:09:51 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1117#entry1117comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=tUIuuwL9cnk\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=tUIuuwL9cnk</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=tUIuuwL9cnk\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/xsDch/hyX4vU9l83/xYtyqYkOd62k2zMGdAm3Dk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/2kcXJ/hyX4zJOFiB/Tb67J8nBwr1Kf9GVQagq50/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"방송사고 뭔데?\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/tUIuuwL9cnk\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">뭔가 이상한게 자꾸 뜨는데 ...</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">간첩 관련된 자막이 나온적이 있다거나</p>\n<p data-ke-size=\"size16\">뭔가 자꾸 편집과정에서 뭔가가 들어가고 있다는 주장</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">시대를 관통하는 방송</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">파란 노랑 초록은 부정선거 관련 내용입니다.</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=zUE9t4CRGO4\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=zUE9t4CRGO4</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=zUE9t4CRGO4\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/HlXjG/hyX4uPt2hW/IdPhMUce8vZk21sUpQ6Vik/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/b34GMn/hyX4wNkDcR/OZODf6wk2IG3jbWk7kWxsk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"이건 100% 부정선거야!!\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/zUE9t4CRGO4\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">7분 20초에 나옵니다.</p>\n<p data-ke-size=\"size16\">프린터 특성에 맞지 않는 투표용지가 발견되었다는 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=tUIuuwL9cnk\n\n\n\n뭔가 이상한게 자꾸 뜨는데 ...\n \n간첩 관련된 자막이 나온적이 있다거나\n뭔가 자꾸 편집과정에서 뭔가가 들어가고 있다는 주장\n \n시대를 관통하는 방송\n \n파란 노랑 초록은 부정선거 관련 내용입니다.\n영상: https://www.youtube.com/watch?v=zUE9t4CRGO4\n\n\n\n7분 20초에 나옵니다.\n프린터 특성에 맞지 않는 투표용지가 발견되었다는 것입니다.",
        "guid": "http://serverdown.tistory.com/1117",
        "categories": [
          "유튜브",
          "방송사고"
        ],
        "isoDate": "2025-01-22T16:09:51.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "AI 에이전트에 대한 사업 내용에 대해 알아보자",
        "link": "http://serverdown.tistory.com/1116",
        "pubDate": "Wed, 22 Jan 2025 22:14:14 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1116#entry1116comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=rFPRStDYGIQ\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=rFPRStDYGIQ</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=rFPRStDYGIQ\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bNKzZm/hyX4mRrBZw/BeCgylyoTXIl0zcp3XvIjK/img.jpg?width=1280&amp;height=720&amp;face=986_90_1186_308,https://scrap.kakaocdn.net/dn/oSEQv/hyX4ws0uBE/w9Nu0sRZ8doliyNAmWbxB1/img.jpg?width=1280&amp;height=720&amp;face=986_90_1186_308\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"&quot;30배 넘는 시장 열린다&quot; 이 주식, 제2의 테슬라, 엔비디아 된다｜강정수 박사 3부\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/rFPRStDYGIQ\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">이제 실생활에 사용할 수 있을 정도로 AI 가 발전하였습니다.</p>\n<p data-ke-size=\"size16\">6분부터 사례가 나옵니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">마이크로소프트</h2>\n<p data-ke-size=\"size16\">이메일 분류 해서 담당에게 전달하는 프로그램을 AI 가 만들었다고 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">애플</h2>\n<p data-ke-size=\"size16\">말로 표예약 취소 같은걸 하려고 한다 (아직안했군요)</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">클라나 - <span style=\"text-align: start;\">유럽</span></h2>\n<p data-ke-size=\"size16\">고객응대의 80%를 AI 로 대처함, 2천명 해고</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">메타</h2>\n<p data-ke-size=\"size16\">광고가 클릭이 잘되도록 AI 적용</p>\n<p data-ke-size=\"size16\">광고를 하는 고객들에게 제품설명을 넣으면 아예 광고 페이지도 만들어내는 기능을 제공</p>\n<p data-ke-size=\"size16\">광고도 만들어주고</p>\n<p data-ke-size=\"size16\">관리페이지도 만들어주고</p>\n<p data-ke-size=\"size16\">회계업무도 대신 처리</p>\n<p data-ke-size=\"size16\">좋게보나봅니다. 설명이 길군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">아마존</h2>\n<p data-ke-size=\"size16\">전용 프로세서 개발</p>\n<p data-ke-size=\"size16\">AI 서비스 개발</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">테슬라</h2>\n<p data-ke-size=\"size16\">본인들 회사에 쓸 로봇 대량 생산</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">아무튼 이제 실생활에 적용될 시점입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">삼성전자</h2>\n<p data-ke-size=\"size16\">젠승황 말을 잘 생각해보면 HBM3 는 실패했다고 봐야한다고 합니다.</p>\n<p data-ke-size=\"size16\">올해는 글렀습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">&nbsp;</h2>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=rFPRStDYGIQ\n\n\n\n이제 실생활에 사용할 수 있을 정도로 AI 가 발전하였습니다.\n6분부터 사례가 나옵니다.\n \n마이크로소프트\n이메일 분류 해서 담당에게 전달하는 프로그램을 AI 가 만들었다고 합니다.\n \n애플\n말로 표예약 취소 같은걸 하려고 한다 (아직안했군요)\n \n클라나 - 유럽\n고객응대의 80%를 AI 로 대처함, 2천명 해고\n \n메타\n광고가 클릭이 잘되도록 AI 적용\n광고를 하는 고객들에게 제품설명을 넣으면 아예 광고 페이지도 만들어내는 기능을 제공\n광고도 만들어주고\n관리페이지도 만들어주고\n회계업무도 대신 처리\n좋게보나봅니다. 설명이 길군요\n \n아마존\n전용 프로세서 개발\nAI 서비스 개발\n \n테슬라\n본인들 회사에 쓸 로봇 대량 생산\n \n아무튼 이제 실생활에 적용될 시점입니다.\n \n삼성전자\n젠승황 말을 잘 생각해보면 HBM3 는 실패했다고 봐야한다고 합니다.\n올해는 글렀습니다.",
        "guid": "http://serverdown.tistory.com/1116",
        "categories": [
          "투자",
          "Ai",
          "인공지능"
        ],
        "isoDate": "2025-01-22T13:14:14.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "코인 하락장이 오면 이렇게 됩니다.",
        "link": "http://serverdown.tistory.com/1115",
        "pubDate": "Mon, 20 Jan 2025 21:29:24 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1115#entry1115comment",
        "content": "<p data-ke-size=\"size16\">저는 2025년 3월까지만 코인할 생각인데요</p>\n<p data-ke-size=\"size16\">결국 어느날 하락장이 올것입니다.</p>\n<p data-ke-size=\"size16\">그때가 되면 어떻게 되는지 알아두는 것은 매우 중요한 일입니다.</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/shorts/jmRU026r7YQ\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/shorts/jmRU026r7YQ</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/shorts/jmRU026r7YQ\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/b1e8UQ/hyX4tvI6m0/1EqwWe1aK2bsuMtNik8Kgk/img.jpg?width=405&amp;height=720&amp;face=38_115_310_391,https://scrap.kakaocdn.net/dn/3eMts/hyX4kMjOcQ/lIKmKjtqSNPGDDZMSPhGG1/img.jpg?width=405&amp;height=720&amp;face=38_115_310_391\" data-video-width=\"405\" data-video-height=\"720\" data-video-origin-width=\"405\" data-video-origin-height=\"720\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"불장에 졸업못한 사람 특  #shorts #비트코인\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/jmRU026r7YQ\" width=\"405\" height=\"720\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "저는 2025년 3월까지만 코인할 생각인데요\n결국 어느날 하락장이 올것입니다.\n그때가 되면 어떻게 되는지 알아두는 것은 매우 중요한 일입니다.\n영상: https://www.youtube.com/shorts/jmRU026r7YQ",
        "guid": "http://serverdown.tistory.com/1115",
        "categories": [
          "코인",
          "코인"
        ],
        "isoDate": "2025-01-20T12:29:24.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "일본의 초밥 자판기 / 곱창 자판기 (망함)",
        "link": "http://serverdown.tistory.com/1114",
        "pubDate": "Sun, 19 Jan 2025 23:37:28 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1114#entry1114comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=RZkb9Aptv9g\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=RZkb9Aptv9g</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=RZkb9Aptv9g\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cmGaGY/hyX4unEISc/ILuJpmQEBWHyi9TDDPzIy0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/0KWYl/hyX0lTqUYj/zQdMzxbGUkm0UZsgwkKqr0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"일본 동네 초밥 자판기에서 초밥을 사보았다\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/RZkb9Aptv9g\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">어떻게 파나 싶어서 봤는데</p>\n<p data-ke-size=\"size16\">냉동이라고 합니다.</p>\n<p data-ke-size=\"size16\">뜨거운물을 밑에 채워두고 30분 기다리면 먹을만하게 녹는다고 합니다.</p>\n<p data-ke-size=\"size16\">유통기한은 6개월 정도</p>\n<p data-ke-size=\"size16\">가격은 13,000 엔</p>\n<p data-ke-size=\"size16\">기술 좋네요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">곱창 자판기: <a href=\"https://www.youtube.com/watch?v=-nQA1meAVc8\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=-nQA1meAVc8</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=-nQA1meAVc8\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/fO2fa/hyX4xq9rlC/76fBFwCeLz3qtgA6AsK0c0/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360,https://scrap.kakaocdn.net/dn/REN6a/hyX0uCRjRs/BwVHKSEpEbU1353ZWsCp40/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360\" data-video-width=\"480\" data-video-height=\"360\" data-video-origin-width=\"480\" data-video-origin-height=\"360\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"일본 동네에 있는 곱창 자판기 이용해보기 [+혼술 먹방]\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/-nQA1meAVc8\" width=\"480\" height=\"360\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">는 망했다고 합니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=RZkb9Aptv9g\n\n\n\n어떻게 파나 싶어서 봤는데\n냉동이라고 합니다.\n뜨거운물을 밑에 채워두고 30분 기다리면 먹을만하게 녹는다고 합니다.\n유통기한은 6개월 정도\n가격은 13,000 엔\n기술 좋네요\n \n곱창 자판기: https://www.youtube.com/watch?v=-nQA1meAVc8\n\n\n\n는 망했다고 합니다.",
        "guid": "http://serverdown.tistory.com/1114",
        "categories": [
          "유튜브",
          "여행",
          "일본"
        ],
        "isoDate": "2025-01-19T14:37:28.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "깡통 7번 차고 배운점 / 투자 실패 스토리",
        "link": "http://serverdown.tistory.com/1113",
        "pubDate": "Sun, 19 Jan 2025 23:25:08 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1113#entry1113comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=w4tmHlvSidA\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=w4tmHlvSidA</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=w4tmHlvSidA\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bbkumQ/hyX4Ag7cDD/vIrmoPWQoFBjc2sSVTmBmk/img.jpg?width=1280&amp;height=720&amp;face=410_134_992_500,https://scrap.kakaocdn.net/dn/qnCHg/hyX4mQGrYw/OqQtSEbryKdZQenChGwv3K/img.jpg?width=1280&amp;height=720&amp;face=410_134_992_500\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"깡통 7번 차고 죽을 만큼 힘들었어요! &quot;실패에서 배운 성공 투자 기법&quot; / 무조건 피해야 할 1가지 (\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/w4tmHlvSidA\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">들어볼만합니다.</p>\n<p data-ke-size=\"size16\">하다보면 잘 될때가 있습니다.</p>\n<p data-ke-size=\"size16\">꼭 그럴때 욕심을 잘 조절해야합니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=w4tmHlvSidA\n\n\n\n들어볼만합니다.\n하다보면 잘 될때가 있습니다.\n꼭 그럴때 욕심을 잘 조절해야합니다.",
        "guid": "http://serverdown.tistory.com/1113",
        "categories": [
          "투자",
          "주식",
          "투자"
        ],
        "isoDate": "2025-01-19T14:25:08.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "미국 강의 - 자유가 무엇인지 설명하기위해 &quot;바이든 멍청이&quot; 를 시켜봅니다.",
        "link": "http://serverdown.tistory.com/1112",
        "pubDate": "Fri, 17 Jan 2025 15:45:37 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1112#entry1112comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=1OfJGkltN_M\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=1OfJGkltN_M</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=1OfJGkltN_M\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/b8p1fr/hyX4otUrDw/YOqcBapLDK3LD74AKQRkn0/img.jpg?width=1280&amp;height=720&amp;face=128_254_654_424,https://scrap.kakaocdn.net/dn/dO6FbY/hyX0rFLG0a/N2wKJEkNajt90CLyUoGl01/img.jpg?width=1280&amp;height=720&amp;face=128_254_654_424\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"하버드 교수의 일침에 중국 찬양하던 중국 유학생이 1초만에 입 다문 이유\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/1OfJGkltN_M\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">사우디 와 중국 항생에게 이야기를 시키면서</p>\n<p data-ke-size=\"size16\">미국 학생에게 \"바이든 멍청이\" (현직 대통령) 이라고 말해보라고 시킵니다.<br />미국 항생은 당연히 말했지요.</p>\n<p data-ke-size=\"size16\">자유라는게 무엇인지 아주 간단하게 보여주는 강의 였습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">자율라는건 이미 누리고 있다면 알 방법이 없습니다.</p>\n<p data-ke-size=\"size16\">공기 같은 것이죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=1OfJGkltN_M\n\n\n\n사우디 와 중국 항생에게 이야기를 시키면서\n미국 학생에게 \"바이든 멍청이\" (현직 대통령) 이라고 말해보라고 시킵니다.\n미국 항생은 당연히 말했지요.\n자유라는게 무엇인지 아주 간단하게 보여주는 강의 였습니다.\n \n자율라는건 이미 누리고 있다면 알 방법이 없습니다.\n공기 같은 것이죠.",
        "guid": "http://serverdown.tistory.com/1112",
        "categories": [
          "유튜브",
          "미국"
        ],
        "isoDate": "2025-01-17T06:45:37.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "2차전지 중국의 폐베터리는 재홀용할 방법이 없다.",
        "link": "http://serverdown.tistory.com/1111",
        "pubDate": "Fri, 17 Jan 2025 15:31:21 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1111#entry1111comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://youtu.be/1YlJg3y_8wQ?t=274\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://youtu.be/1YlJg3y_8wQ?t=274</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=1YlJg3y_8wQ\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/y5ycB/hyX4spxakF/OPlt3RiXfVLf024vLFbUS0/img.jpg?width=1280&amp;height=720&amp;face=882_264_1104_506,https://scrap.kakaocdn.net/dn/c9XFXF/hyX4rEaSar/nSOhj36XXAIzu8I7UikEO0/img.jpg?width=1280&amp;height=720&amp;face=882_264_1104_506\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"【중국인사이트】 2025년, 중국 경제의 추락? 숨겨진 진실 공개! (진태산 보도)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/1YlJg3y_8wQ\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">4분 30초에 나옵니다.</p>\n<p data-ke-size=\"size16\">유럽에 많이 수출했지만 베터리를 교체하기위해 베터리를 중국에 다시 보낼텐데</p>\n<p data-ke-size=\"size16\">이 폐베터리는 환경에 문제 없이 폐기나 재활용할 방법이 중국에는 없습니다.</p>\n<p data-ke-size=\"size16\">왜냐하면 당연히 그런걸 고려안하고 만든 가격이 지금 가격이기 때문입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이런 베터리는 싸다고 많이 사용해봐야 환경문제를 일으키게 됩니다.</p>\n<p data-ke-size=\"size16\">비싼비용으로 재활용 하느니 땅에 뭍어버리는게 낫을 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">그렇습니다. 중국의 베터리 가격은 뒷일을 생각하지 않은 그냥 원가 인것입니다.</p>\n<p data-ke-size=\"size16\">물론 유럽은 이 베터리를 자국에서 어떻게 하지 않고 중국으로 보내버릴 것입니다.</p>",
        "contentSnippet": "영상: https://youtu.be/1YlJg3y_8wQ?t=274\n\n\n\n4분 30초에 나옵니다.\n유럽에 많이 수출했지만 베터리를 교체하기위해 베터리를 중국에 다시 보낼텐데\n이 폐베터리는 환경에 문제 없이 폐기나 재활용할 방법이 중국에는 없습니다.\n왜냐하면 당연히 그런걸 고려안하고 만든 가격이 지금 가격이기 때문입니다.\n \n이런 베터리는 싸다고 많이 사용해봐야 환경문제를 일으키게 됩니다.\n비싼비용으로 재활용 하느니 땅에 뭍어버리는게 낫을 것입니다.\n \n그렇습니다. 중국의 베터리 가격은 뒷일을 생각하지 않은 그냥 원가 인것입니다.\n물론 유럽은 이 베터리를 자국에서 어떻게 하지 않고 중국으로 보내버릴 것입니다.",
        "guid": "http://serverdown.tistory.com/1111",
        "categories": [
          "투자",
          "2차전지",
          "중국",
          "폐베터리"
        ],
        "isoDate": "2025-01-17T06:31:21.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": []
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "한상곤 - Sigmadream",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "코드 품질 개선 기법 4편: 문을 없애고 테스트하기",
        "link": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-4",
        "pubDate": "Wed, 22 Jan 2025 02:00:00 GMT",
        "content": "안녕하세요. 커뮤니케이션 앱 LINE의 모바일 클라이언트를 개발하고 있는 Ishikawa입니다.\n저희 회사는 높은 개발 생산성을 유지하기 위해 코드 품질 및 개발 문화 개선에 힘쓰...",
        "contentSnippet": "안녕하세요. 커뮤니케이션 앱 LINE의 모바일 클라이언트를 개발하고 있는 Ishikawa입니다.\n저희 회사는 높은 개발 생산성을 유지하기 위해 코드 품질 및 개발 문화 개선에 힘쓰...",
        "guid": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-4",
        "isoDate": "2025-01-22T02:00:00.000Z"
      },
      {
        "title": "3단계로 완성하는 유연한 디자인 시스템",
        "link": "https://techblog.lycorp.co.jp/ko/a-flexible-design-system-using-3-tier-tokens",
        "pubDate": "Mon, 20 Jan 2025 03:00:00 GMT",
        "content": "안녕하세요. LINE Plus ABC Studio에서 일본 음식 배달 서비스 Demaecan(出前館, 이하 데마에칸)의 디자인을 담당하고 있고, 사용자의 다양한 목소리를 담을 수 ...",
        "contentSnippet": "안녕하세요. LINE Plus ABC Studio에서 일본 음식 배달 서비스 Demaecan(出前館, 이하 데마에칸)의 디자인을 담당하고 있고, 사용자의 다양한 목소리를 담을 수 ...",
        "guid": "https://techblog.lycorp.co.jp/ko/a-flexible-design-system-using-3-tier-tokens",
        "isoDate": "2025-01-20T03:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "세상의 모든 큰 것은 아주 작은 것에서 시작된다",
        "link": "https://www.thestartupbible.com/2025/01/big-things-come-from-small-beginnings.html",
        "pubDate": "Wed, 22 Jan 2025 21:29:00 +0000",
        "content:encodedSnippet": "한인이 창업했고, 창업 5년 만에 한화로 거의 1조 원에 인수된 화장품 회사 Hero Cosmetics(Hero)의 팟캐스트를 얼마 전에 흥미롭게 들었다. 창업가들의 이야기는 그 결말이 해피엔딩이든 새드엔딩이든 항상 배울 점들이 많아서 재미있고, 한국에 사는 분들에겐 너무나 익숙한 여드름 패치 하나로 시작해서 1조 원짜리 회사를 만들어서 Church and Dwight에 매각한 이야기도 웬만한 케이드라마보다 더 흥미로웠다.\n이 팟캐스트를 며칠에 걸쳐 아침에 운동하면서 계속 들었는데, 그 기간 우리 투자사 대표와 미팅하면서, 이분이 하는 사업은 화장품 분야와는 완전히 다르지만, Hero가 고민하고 거쳐 온 과정에 대해서 같이 이야기하고, 나름대로 고민의 공통점들을 찾고 해답도 같이 찾는 이야기를 꽤 많이 했다.\nHero는 Mighty Patch라는 여드름 패치 제품 하나로 시작했고, 한국에서 만든 이 제품을 온, 오프라인 상점에서 팔기 시작했는데, 얼마 안 지나서 이 카테고리에서는 거의 1등 제품이 됐다. 1등 제품이긴 했지만, 없던 시장을 만들었기 때문에 일단 시장 자체가 작았고, 투자도 받고 사람도 더 고용하기 위해서 회사는 계속 성장을 해야 했다. 여기서 Hero의 창업가들은 더 큰 성장을 하기 위해서 여드름 패치보다 훨씬 큰 시장인 일반 화장품 분야로 확장하는 고민을 했다. 어차피 큰 카테고리로 보면 모두 다 화장품과 뷰티 분야였고, 다른 화장품도 한국의 공장에서 제조하기 때문에 제조사 소싱도 용이했다. 그리고 어느 시점에는 일반 화장품/뷰티 쪽으로 확장하는 게 너무 자연스러운 성장 공식이라서 여드름 패치 판매 시작 1년 후에 이런 고민을 했다.\n하지만, 이들이 내린 결론은, 일단 여드름 패치 분야에만 당분간 집중하는 것이었다. 여드름 패치 분야에서 더 많은, 더 좋은 제품을 더 싸게 판매해서 아예 다른 경쟁사들이 넘보지도 못할 정도로 압도적인 1등이 되고, 미국에서 말하는 소위 category dominator가 된 후에 다른 화장품 분야로 확장하기로 했다. 그리고 그 이후에 같은 여드름 패치를 다양한 색상, 다양한 용도, 그리고 다양한 크기로 만들어서 SKU를 다각화했고, 판매 채널 또한 온, 오프라인 모든 곳으로 확장했다. 이렇게 한 결과, 여드름 패치로만 연 매출 수백억 원대를 달성할 수 있었고, 이 정도의 매출을 하니 이 분야에서는 압도적인 1등이 됐고, 이 category dominator 해자(垓字)를 구축한 후에 다른 화장품 분야로 조금은 더 수월하고 편하게 진출했다.\n위에서 이야기했던 우리 투자사 대표도 이와 비슷한 고민을 하고 있었고, 아마도 꽤 많은 창업가들이 이런 고민을 하는 걸로 알고 있다. 아주 힘들게 한 분야를 열심히 팠고, 꽤 오랜 시간 동안 기반을 닦아 놓으니, 이 분야에서 돈을 내는 고객도 생기고, 아주 빠르진 않지만, 고객에게 서서히 입소문이 나면서 어느 순간 이 분야에서 꽤 알아주는 제품을 만드는 회사가 된 경우를 우린 자주 본다. 그런데 지금 내가 집중하고 있는 시장보다 훨씬 더 큰 수천억 원 ~ 수조 원짜리 시장에서 훨씬 더 빠르게 성장하고 싶어서, 완전히 다른 시장, 또는 같은 시장에서 다른 카테고리를 계속 기웃거리는 창업가들이 꽤 많다.\n이분들에게 내가 주로 하는 조언은 항상 비슷하다. Hero의 전략으로 가라고 한다. 즉, 내가 시작한 분야가 아무리 작아도, 고객이 존재하고, 우리가 의미 있는 제품을 만들어서 알만한 사람들은 이미 아는 브랜드를 만들고 있다면, 일단 이 시장을 완전히 장악해서 category leader를 넘어선 category dominator가 되라고 조언한다. 그 이후에 다른 곳으로 확장하라고 한다.\n예를 들며, 내가 지금까지 아주 오랜 시간 동안 기반을 잘 닦아 놓은 시장의 전체 크기가 100억 원이라면, 일단 이 시장에서 최소 30억 원의 매출을 해서 시장의 30%를 장악하라는 뜻이다. 한 시장의 30%를 장악하면 그 시장의 확실한 category dominator가 될 수 있기 때문이다. 꽤 재미있는 건, 이런 고민을 하는 대표들이 대부분 그 100억 원짜리 시장은 항상 너무 작다고 하면서도, 막상 본인들은 이 작은 시장에서 매출 1억 원도 못 하고 있다는 점이다.\n그래서 나는 항상 이들에게 일단 우리가 만들어 놓은 시장에서 작은 것부터 야금야금 먹자고 한다. 시장에서 압도적인 1등이 된 후에 다른 시장으로 진출하는 게 여러모로 봤을 때 훨씬 더 우리에게 유리하기 때문에, Hero와 같이 현재 시장에서, 현재 제품을 조금 더 다각화할 수 있는 전략을 고민해 보라는 조언을 한다. 전에도 한 번 내가 포스팅 한 적이 있는데, 일단 따기 쉬운 과일을 먼저 따먹는 전략이다.\n이런 조언을 열심히 해도, 두 마리의 토끼를 쫓거나, 아니면 우리 토끼보다 더 큰 다른 토끼를 쫓는 창업가들이 더 많다. 누가 맞고 틀렸다는 문제는 아니라서, 더 큰 카테고리로 지금 당장 진출하고 싶은 분들은 그렇게 하면 된다. 하지만, 이렇게 했을 때 조심해야 할 점은, 두 마리 토끼를 쫓다가 둘 다 놓칠 수도 있고, 더 큰 토끼를 쫓아서 힘들게 잡았는데 막상 보면 엉덩이면 커서 뒤에서만 봤을 때 큰 토끼일 가능성도 있고, 실은 내가 지금 잡고 있는 토끼가 나중에 엄청나게 커질 수 있는데 다른 토끼를 쫓다가 내 토끼를 다른 회사에 빼앗길 수도 있다는 것이다.\n왜 이런 무모한 전략을 계속 고집하는지 물어보면, 대부분의 창업가들은 더 짧은 기간에 더 빠르게 성장하고 싶다고 한다. 이분들에게 내가 한결같이 다시 해주는 조언은 세상의 모든 건 시간이 걸린다는 것이다. 100만 원 매출이 1,000만 원이 되고, 1,000만 원이 1억이 되고, 이런 느린 사이클을 타면서 언젠간 1조 원 매출이 된다. 한 번에 1,000억씩 할 수 있는 방법은 없다. 혹시 있다면 나한테 DM 부탁한다. 그땐 내가 VC를 그만둬야 할 것 같다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/01/big-things-come-from-small-beginnings.html#respond",
        "content": "한인이 창업했고, 창업 5년 만에 한화로 거의 1조 원에 인수된 화장품 회사 Hero Cosmetics(Hero)의 팟캐스트를 얼마 전에 흥미롭게 들었다. 창업가들의 이야기는 그 결말이 해피엔딩이든 새드엔딩이든 항상 배울 점들이 많아서 재미있고, 한국에 사는 분들에겐 너무나 익숙한 여드름 패치 하나로 시작해서 1조 원짜리 회사를 만들어서 Church and Dwight에 매각한 이야기도 웬만한 케이드라마보다 더 흥미로웠다. 이 팟캐스트를 며칠에(...)",
        "contentSnippet": "한인이 창업했고, 창업 5년 만에 한화로 거의 1조 원에 인수된 화장품 회사 Hero Cosmetics(Hero)의 팟캐스트를 얼마 전에 흥미롭게 들었다. 창업가들의 이야기는 그 결말이 해피엔딩이든 새드엔딩이든 항상 배울 점들이 많아서 재미있고, 한국에 사는 분들에겐 너무나 익숙한 여드름 패치 하나로 시작해서 1조 원짜리 회사를 만들어서 Church and Dwight에 매각한 이야기도 웬만한 케이드라마보다 더 흥미로웠다. 이 팟캐스트를 며칠에(...)",
        "guid": "https://www.thestartupbible.com/?p=9359",
        "categories": [
          "Uncategorized",
          "B2B",
          "consumer",
          "FoundersAtWork",
          "korea",
          "strategy",
          "Strong",
          "스타트업 바이블 QA"
        ],
        "isoDate": "2025-01-22T21:29:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "희망의 실종",
        "link": "https://www.thestartupbible.com/2025/01/will-there-be-hope-in-2025.html",
        "pubDate": "Sun, 19 Jan 2025 21:34:00 +0000",
        "content:encodedSnippet": "2022년 하반기에 많은 분들이 나에게 앞으로 경기는 어떻게 될 것이고, 언제쯤, 이 불경기가 회복될지 물어봤다. 물론, 나는 경제학자도 아니고 미래학자도 아니라서 잘 모른다고 했지만, 속으론 2024년 상반기면 괜찮아질 것으로 생각했다. 그래서 계속 개인적인 생각을 물어보면, 그냥 2024년 상반기엔 좋아지지 않겠나,,,라고 이야기했다. 그런데 2023년 상반기가 되자, 여러 가지 분위기와 정성적인 지표는 – 예, 해외 투자자들과의 이야기와 느낌 – 2024년 경기도 매우 안 좋은 방향으로 향하고 있는 게 너무나 명확했다. 그래서 내가 했던 말을 번복하고, 2025년이 돼야 시장의 상황이 더 좋아질 것 같다고 했다.\n작년 사사분기에, 이런 내 생각에 한 번의 전환이 더 있었고, 내 말을 한 번 더 번복했다. 2025년은 어쩌면 우리가 스타트업을 하면서 경험할 수 있는 최악의 경기가 될지도 모르겠다. 특히나 한국은 그동안 국제적인 이미지가 너무 좋았고, 전반적인 분위기가 나쁘지 않았는데, 말도 안 되는 정치적인 사건으로 인해서 국가의 이미지가 실추되면서 그 누구도 상상하지 못했던 엄청난 경제적인 손실이 발생하고 있다.\n그동안 내가 외국인들에게 항상 자랑스럽게 주장했던 게 두 가지가 있었다.\n하나는, 한국은 그나마 다른 아시아 국가 중 정치적으로 안정된 국가라는 점이었고, 둘째는, 한국은 그나마 다른 아시아 국가보다 USD에 대한 환율이 강한 국가라는 점이었다.\n모두 잘 아시다시피, 내가 완전히 양치기 소년이 됐다. 어쨌든, 이 좋지 않은 세계 경제 상황에서 정치적, 경제적으로 일시적으로 최악의 상황에 놓인 한국은 힘든 한 해를 보낼 것이고, 한국에서 사업을 하는 스타트업, 그리고 우리 같은 투자자 모두 아주 힘든 한 해를 경험할 것이다.\n2025년에는 사라지는 회사들이 정말 많을 것이다. 우리 투자사들도 너무 다 힘들고, 이미 폐업 준비하는 대표들이 내 주변에도 너무 많아지고 있다. 가장 먼저 문 닫을 회사들은 원래 2024년도에 폐업을 해야 했는데, 2025년은 더 좋아질 것이라는 희망을 갖고, 오로지 이 희망 하나로 작년 한 해를 버틴 회사들이다. 이들의 희망과는 달리 2025년도 크게 좋아지지 않을 것이기 때문에, 매출은 작고, 돈은 없고, 직원들은 하나둘씩 해고되거나 나갈 회사들은 문을 닫아야 할 것이다. 이들에게 더 이상 희망으로 버틸 수 있는 체력과 돈은 없다.\n펀딩 시리즈 스펙트럼의 다른 극에 있는 유니콘 회사들도 많이 망하거나, 아니면 유니콘 왕관을 스스로 내려놔야 할 것이다. 돈도 못 벌고, 마이너스만 만들고 있는 유니콘들이 꽤 많은데, 이들이 작년 한 해 유니콘 밸류에이션을 유지할 수 있었던 이유는 두 가지다. 하나는 이들도 2025년은 시장이 더 좋아져서 다시 한번 유니콘 밸류에 투자를 받을 수 있을 것이라는 희망으로 힘든 2024년을 버텼을 것이다. 또 다른 이유는 이 회사에 마지막으로 투자한 VC들이 어떻게든 기업 가치를 유지해서 본인들 투자에 손실이 발생하지 않기 위해서 이 회사들을 하드캐리 했는데, 더 이상 이걸 할 순 없을 것이다. 실은, 이 VC들도 2025년에 대한 희망을 품고 힘든 2024년을 보냈는데, 더 이상 이런 희망으로 버틸 순 없을 것이다.\n2025년에는 스타트업만 돈이 없는 게 아니라, 이들에게 투자하는 VC들도 돈이 없어서 활발한 투자를 보긴 힘들 것이다. VC들도 누군가에게 돈을 받아서 투자해야 하는데, 이들에게 돈을 주는 LP들이 매우 보수적인 자세를 취하고 있어서, 펀드를 만드는 게 우리 같은 투자자들에겐 큰 도전이자 과제다. 돈이 나올 수 있는 구멍이 여러 면에서 막혀 있는 게 VC나 스타트업의 2025년도 현실이다.\n단도직입적으로 말하자면, 근대 벤처업계 역사상 최악의 한 해가 될 것이다. 인생 최고 공포의 롤러코스터 라이드가 될 것이니까, 안전띠 꽉 조이고, 허리띠는 더 꽉 조여야 할 것이다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/01/will-there-be-hope-in-2025.html#comments",
        "content": "2022년 하반기에 많은 분들이 나에게 앞으로 경기는 어떻게 될 것이고, 언제쯤, 이 불경기가 회복될지 물어봤다. 물론, 나는 경제학자도 아니고 미래학자도 아니라서 잘 모른다고 했지만, 속으론 2024년 상반기면 괜찮아질 것으로 생각했다. 그래서 계속 개인적인 생각을 물어보면, 그냥 2024년 상반기엔 좋아지지 않겠나,,,라고 이야기했다. 그런데 2023년 상반기가 되자, 여러 가지 분위기와 정성적인 지표는 – 예, 해외 투자자들과의 이야기와(...)",
        "contentSnippet": "2022년 하반기에 많은 분들이 나에게 앞으로 경기는 어떻게 될 것이고, 언제쯤, 이 불경기가 회복될지 물어봤다. 물론, 나는 경제학자도 아니고 미래학자도 아니라서 잘 모른다고 했지만, 속으론 2024년 상반기면 괜찮아질 것으로 생각했다. 그래서 계속 개인적인 생각을 물어보면, 그냥 2024년 상반기엔 좋아지지 않겠나,,,라고 이야기했다. 그런데 2023년 상반기가 되자, 여러 가지 분위기와 정성적인 지표는 – 예, 해외 투자자들과의 이야기와(...)",
        "guid": "https://www.thestartupbible.com/?p=9352",
        "categories": [
          "Uncategorized",
          "failure",
          "FoundersAtWork",
          "fundraising",
          "korea",
          "unicorn",
          "vc"
        ],
        "isoDate": "2025-01-19T21:34:00.000Z"
      }
    ]
  },
  {
    "name": "Build a Great Product",
    "category": "개인",
    "posts": []
  },
  {
    "name": "지금 써보러 갑니다",
    "category": "개인",
    "posts": []
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "노후 준비에 관한 고민, 전문가 Q&A로 해결하기",
        "link": "https://blog.toss.im/article/retirement-plans-08",
        "pubDate": "Wed, 22 Jan 2025 13:23:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}2017년, 한국에 해외 자산운용사의 TDF 상품이 처음 도입되던 시기, 영주 닐슨 교수는 연금과 노후 대비에 새로운 시각을 갖게 되었어요. 당시 국내 한 자산운용사에서 자문 활동을 하며 나와 가족들의 은퇴 준비를 넘어 한국 사람들의 연금과 노후 대비에 대한 고민이 깊어졌다고 해요.\n미국 월가에서 15년 이상 알고리즘 트레이딩 전문가로 활약했던 그는 현재 ‘한국퇴직연금데이터’를 설립하고, 퇴직연금 관리 및 노후 준비를 돕는 서비스 ‘.css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}글라이드’를 운영하고 있어요. “개인의 노후 준비를 돕는 일이 커리어에서 가장 보람 있는 일”이라고 말하죠.\n이번 인터뷰에서는 그가 쌓아온 전문성과 경험을 바탕으로, 체계적이고 현실적인 노후 준비 방법을 들어봅니다.\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}1. 2024년 초 <노후 준비 액션플랜> 시리즈를 시작할 때, 독자들에게 어떤 점을 가장 강조하고 싶으셨나요?\n이제 ‘퇴직연금’이나 ‘개인연금’이라는 단어는 미디어뿐만 아니라 버스 광고판이나 고층 빌딩의 외벽에서도 쉽게 볼 수 있을 정도로 금융사들의 적극적인 마케팅 덕에 대중에게 익숙한 용어가 되었어요. 많은 사람들이 금융사나 미디어를 통해 퇴직연금 운용과 관리에 대한 정보를 접하고 있습니다.\n하지만 특정 상품에 초점이 맞춰진 단편적인 정보만 접하면 노후 대비에 대해 체계적으로 이해하고 접근하기 어려워요. 그래서 1화 ‘은퇴 후의 삶, 준비를 시작했나요?’부터 퇴직연금을 처음 접하는 사람이 차근차근 학습할 수 있도록 체계적인 순서를 제시하는 데 초점을 맞췄습니다. 큰 그림을 그려보고 연금 상품들을 활용해 노후를 준비할 수 있는 나만의 시스템을 구축하게 하기 위해서요.\n2. 은퇴 준비까지 가는 여정에서 유의해야 할 것이 있을까요?\n처음 한국에 왔을 때 인상 깊었던 점 중 하나는 젊은 층이 공무원을 선호한다는 것이었어요. 최근에는 그런 분위기가 많이 바뀌기는 했지만, 선호했던 이유는 직업의 안정성과 은퇴 후 평생 지급되는 연금 때문이었죠. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}하지만 공무원 연금은 일하는 동안 한 달도 빠짐없이 납부한다는 점을 기억해야 해요. 연금의 핵심은 연속성인데, 퇴직연금에서는 이런 연속성이 잘 지켜지지 않는 경우가 많습니다.\n한국인의 노후 준비에서 두드러지는 특징이기도 한데요, 투자에 지나치게 신경을 쓰면서도 장기적인 계획이 부족하다는 점이 아쉬워요. 많은 사람들이 30년 이상 꾸준히 모으고 투자하는 개념보다는 단기 수익률에 집중하고, 은퇴 자금을 자녀 교육 등 다른 용도로 써버리는 사례를 많이 목격했습니다.\n또 다른 유의점은 투자 방식의 극단성이에요. 일부는 너무 공격적으로 투자해 불필요한 리스크를 감수하고, 또 일부는 지나치게 보수적으로 원금보장형 상품에만 투자해 퇴직연금 계좌가 인플레이션을 따라가지 못하는 상황을 초래합니다. 이 같은 습관은 연금의 본래 목적을 훼손하고 장기적인 노후 준비를 어렵게 만들어요.\n\n✱3~10번 질문은 토스앱 내 ‘오늘의 팁’을 통해 남겨주신 고민 중 가장 많이 중복되는 8가지에 영주 닐슨 교수가 답했습니다.\n\n3. 노후대비를 국민연금으로만 해도 될까요?\n2023년 1월 기준, 국민연금의 월평균 수급액은 61만 7,603원에 불과합니다. 이는 최소 노후생활비로 추정되는 124만 원의 절반에도 미치지 않는 금액이에요. 국민연금만으로 안정적인 노후를 준비하기엔 부족하다는 사실이 명확하죠.\n국민연금의 소득대체율 목표는 40%이에요. 이를 기준으로 생각하면, 한 달 생활비가 300만 원인 경우 국민연금이 약 120만 원을 충당해줄 거라고 예상할 수 있고요. 하지만 이마저도 충분하지 않은 금액이기에, 국민연금을 보완할 수 있는 퇴직연금, 개인연금 관리에 더욱 신경 써야 합니다.\n4. 만약 교수님께서 지금 사회초년생이라면, 어떤 상품에 가입하실 건가요?\n제가 이제 막 커리어를 시작하는 20대라면, 그리고 회사에서 퇴직연금을 제공하고 DC형과 DB형 중 선택할 수 있다면 DC형을 선택해 직접 이런저런 운용 지시를 해보면서 경험을 쌓을 거예요. 그리고 세제 혜택을 최대한 활용할 겸 IRP나 연금저축을 통해 조금씩이라도 장기적인 계획을 세우고 연금 자산을 쌓아가려고 할 거예요.\n사실 저는 20대였을 때 비슷한 선택을 했어요. 공부를 마치고 첫 직장을 잡자마자 미국의 DC형 퇴직연금인 401k를 시작했거든요. 이후 방금 말씀드린 방법을 그대로 실천했어요. 결과가 궁금하시죠? 지금까지 꾸준히 준비한 덕분에 안정적인 은퇴를 향해 나아가고 있어요.\n만약 회사에서 DC형을 선택할 수 없다면 IRP 계좌를 개설해 직접 투자해보는 게 좋아요. 공무원이든 프리랜서든 소득이 있다면 누구나 IRP에 가입할 수 있답니다. 소액이라도 매달 꾸준히 납입하면서 IRP를 통해 직접 투자 포트폴리오를 만들어가는 과정은 사회초년생일 때부터 시작하면 좋아요. 30년 이상 일하면서 자산을 관리하고 투자하는 경험은 누구에게나 꼭 필요한 일입니다.\n5. 월급 대비 연금으로 투자하는 비율은 얼마 정도가 좋을까요?\n보통 전문가들은 월급의 10~20%를 노후 자금으로 저축하거나 투자하라고 조언해요. 사실 직장인의 경우 이미 소득의 4.5%는 국민연금으로, 또 일부는 퇴직연금으로 자동납부 되고 있어요. 너무 부담되지 않도록 월급의 10% 내외를 추가로 IRP 계좌 등에 납부해보는 것을 추천드려요. 월급이 200만 원이라면 매달 20만 원을 IRP에 넣는 거죠. 물론 쉬운 일은 아니지만 연말정산에서 세액공제도 받을 수 있기 때문에 놓칠 수 없는 혜택이기도 합니다.\n연금은 중도 해지하지 않는 게 중요하니까 처음에는 감당할 수 있는 금액을 넣다가 은퇴 시점이 가까워지는 연령대가 되면 비중을 점점 높여야 해요. 젊을 때는 복리의 효과를 활용할 시간이 충분하지만, 은퇴 직전에는 이를 기대하기 어렵죠. 은퇴가 가까워질수록 투자할 수 있는 시간이 줄어들기 때문에 더 많은 자금을 투입해야 목표 자산을 달성할 수 있어요.\n6. 개인사업자에게 노후 준비 방법을 추천하신다면요?\n한국의 퇴직연금 제도는 개인사업자에게도 IRP 가입을 허용하고 있어요. 고용주 없이 프리랜서로 일하더라도 연금제도의 혜택을 누릴 수 있습니다. 거기에 더해 소상공인이라면 IRP 외에도 노란우산 공제를 활용할 수 있는데, 이것은 개인사업자가 퇴직금을 마련할 수 있도록 돕는 공제 제도예요.\n노란우산은 연간 최대 600만 원까지 소득공제가 가능하고, 월 5만 원부터 100만 원까지 납부할 수 있어요. 납부 방식은 월납 또는 분기납으로 선택할 수 있습니다. 다만, IRP와 달리 투자형 상품이 아닌 예금 형태로 운용되고, 2024년 기준 약 3.3%의 수익률을 제공해요. 이러한 특성 덕분에 퇴직금 마련뿐만 아니라 목돈을 모으기 위한 용도로도 적합하죠. 노란우산은 투자 개념이 강한 IRP와는 성격이 다르기 때문에, 두 제도를 병행하면 각각의 장점을 활용하면서 세제 혜택과 노후 자금 준비를 동시에 얻을 수 있습니다.\n7. 30년 뒤 노후 생활비는 얼마가 필요할까요?\n노후 생활비를 간단히 계산하려면, 은퇴 후 생활비 감소를 고려해 현재 생활비의 약 70%를 기준으로 잡아보세요. 정확한 계산법은 아니지만 대략적으로 필요한 금액의 감을 잡는 데는 유용합니다.\n2023년 1월 국민연금공단 보고서에 따르면 부부 기준 적정 생활비는 월평균 277만 원이라고 해요. 또, 통계청의 2023년 가계금융복지조사에 따르면 은퇴한 가구주와 배우자(2인 가구)의 월평균 적정생활비는 324만 원, 최소생활비는 231만 원이라고 합니다. 이렇게 277만 원, 324만 원, 현재 내 생활비의 70%라는 세 가지 기준을 참고하면 은퇴 후 나에게 필요한 돈을 가늠해볼 수 있죠.\n이때 잊지 말아야 할 것은 물가상승률인데요, 물가상승률을 매년 3%로 가정한다면 이를 적용해 2050년에 필요한 생활비를 계산해봐야 합니다. 이를 통해 현재의 금액뿐 아니라 미래의 경제 상황까지 고려한 현실적인 노후 자금 목표를 세울 수 있어요..\n8. 국민연금, 퇴직연금, 개인연금이라는 3단계 연금 가입 외에, 노후 대비를 위해 추가로 할 수 있는 게 있을까요?\n3단계를 모두 챙기고 있다면 이미 너무 잘하고 계신 거예요. 보통 개인연금 상품 중 수수료가 너무 비싼 것들도 있어서 배제하시는 경우도 있는데, 오랫동안 보유하면 수수료도 많이 상쇄된다는 점을 기억하시면 좋겠어요. 이렇게 3단계를 잘 쌓고 있는 분이라면, 이제 딱 두 가지가 남았을 거예요. 요즘 자격증을 많이 따시는 것처럼 은퇴 이후에도 추가 소득을 위해 일할 수 있는 전문성을 갖추는 것, 그리고 가장 중요한 건강입니다.\n9. 퇴직연금을 직접 운용하는데도 디폴트옵션을 설정해야 하나요?\n디폴트옵션은 내가 퇴직연금을 직접 운용하고 있더라도 반드시 설정해야 하는 항목입니다. 100% 투자상품으로 적립금을 운용하고 있다 하더라도 디폴트옵션을 설정하지 않으면 안 되니, 잊지 말고 선택하세요.\n현재 퇴직연금 적립금 약 400조 원 중 90% 가까이가 원리금보장형 상품에 투자되고 있습니다. 많은 사람들이 퇴직연금을 적극적으로 투자하는 데 어려움을 느끼기 때문인데요. 자신이 이런 경우에 해당한다면 퇴직연금사업자가 제공하는 디폴트옵션 상품 중 초저위험이 아닌 옵션을 선택해보길 권합니다.\n디폴트옵션은 초저위험, 저위험, 중위험, 고위험으로 분류돼요. 초저위험은 원리금보장형 상품으로만 구성되지만, 고위험 옵션으로 갈수록 TDF와 같은 실적배당형 상품의 비중이 높아져 수익성이 커질 가능성이 있습니다. 직접 투자상품을 선택하기 어렵다면, 잘 설계된 디폴트옵션 상품 중에서 적합한 것을 골라보세요. 디폴트옵션은 내가 가입한 퇴직연금사업자가 제공하는 상품만 선택할 수 있습니다. 예를 들어, A증권사의 퇴직연금 계좌에 가입했다면 A증권사가 제공하는 디폴트옵션 상품만 고를 수 있어요. 일부 사업자는 최대 10개의 디폴트옵션을 제공하기도 합니다.\n만약 은퇴까지 아직 시간이 많이 남아 있다면, 고위험군 옵션을 선택해 연금에 적립한 금액만큼은 공격적인 투자를 고려해보세요. 처음에 잘 몰라 초저위험으로 설정했더라도, 지금 내가 은퇴까지 얼마나 남았는지 등을 고려해 다시 선택할 수 있으니 그대로 두지 말고 조정하시길 바랍니다.\n10. 연금을 많이 받으면 다시 세금으로 토해내야 한다는 말이 사실인가요?\n세금은 언제나 복잡하고 어려운 주제예요. 공적연금과 사적연금의 세율 차이, 연금 수령 나이, 연금 수령 총액, 연금 외 소득 유무 등에 따라 세액이 달라집니다. 연금소득도 소득이므로, 소득이 많을수록 소득세도 많이 내야 하는 것은 맞습니다. 국세청을 참고한 뒤 나의 경우를 전문가와 상담하는 것이 가장 정확할 테니, 오늘은 절세를 위해 알아둬야 할 몇 가지를 말씀드릴게요.\n연금 소득의 종류에 따른 과세 방식\n앞서 말씀드린 연금 3단계는 공적연금(국민연금)과 사적연금(퇴직연금, 개인연금)으로 나뉘고, 과세 방식이 달라요. 공적연금은 종합소득세 신고 대상입니다. 연간 1,200만 원까지는 비과세되지만, 초과분은 과세돼요. 사적연금은 분리과세(연금소득세) 또는 종합소득세로 과세됩니다. 일반적으로 연간 1,500만 원까지는 낮은 세율(5.5%)이 적용되고요.\n절세를 위해 알아둬야 할 것들\n1. 1년에 받는 연금소득이 총 얼마냐에 따라 최대 900만 원까지 연금소득공제를 받을 수 있습니다. 이를 활용하면 과세 표준을 낮춰서 세금 부담을 줄일 수 있어요.\n연금소득 350만 원 이하: 전액 공제\n350만 원 초과~700만 원 이하: 350만 원 + 초과분의 40%\n700만 원 초과: 500만 원 + 초과분의 5%\n2. 사적연금 소득이 연 1,500만 원 이하일 때는 세율이 낮으므로 연금 수령액을 조정해 이 구간을 활용하세요. 연 1,500만 원이 넘는 경우 분리과세와 종합소득세 신고 중 세금이 낮은 쪽을 따져 선택해야 합니다. \n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}✱2024년 1월 1일부터 연금저축·퇴직연금 등 연금 소득에 대한 종합소득과세 기준이 1,200만 원에서 1,500만 원으로 상향되었어요.\n분리과세: 연간 1,500만 원까지 낮은 세율(5.5%~15%)로 과세됩니다.\n종합소득세 신고: 다른 소득(공적연금, 부동산 임대소득 등)과 합산해 신고합니다. 연금소득 외에 다른 소득이 많다면 분리과세가 유리할 수 있어요.\n3. 사적연금 세율은 70세 이전 5%, 70~79세 4%, 80세 이상 3%이기는 하지만, 여러 연금 상품을 가입한 경우 동시에 받으면 소득이 높아져 세율이 올라갈 수 있으니, 수령 시점을 조율해 세금을 최적화해야 해요.\n4. 부부가 각각 연금 상품을 보유하고 있다면, 연금을 분산 수령해서 종합소득 기준 금액을 낮춰 세율을 줄일 수 있어요.\n5. 연금 관련 세법은 매년 변화할 수 있으니 최신 정보를 확인하고 필요 시 세무 전문가의 상담을 받는 것이 중요합니다.\n\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n이 외에도 아래와 같은 질문을 많은 분들이 남겨주셨어요. <노후 준비 액션플랜>에 이전 화에서 소개했으니 아래 내용을 참고해주세요. \n\n.css-1odxvuk{white-space:pre-wrap;font-style:italic;}“노후 준비 자금은 어떻게 마련하나요?”\n”퇴직연금이 없는데 어디서부터 시작할지 모르겠어요.”\n👉 1화. 은퇴 후의 삶, 준비를 시작했나요?\n👉 3화. IRP(개인형 퇴직연금)도 똑똑한 가입 방법이 있다\n“노후엔 10억정도 필요하다던데 맞나요?”\n”1인당 노후 생활비는 얼마가 필요한가요?”\n👉 2화. 은퇴 계획의 큰 그림을 그려보는 법\n“TDF에 대한 정보를 어디서 얻나요?”\n👉 5화. TDF, 우리 모두의 은퇴 준비 필수품\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 주소은, 김현미(아이랩) Graphic 조수희",
        "content": "독자들이 가장 많이 한 질문에 영주 닐슨 교수가 직접 답했어요",
        "contentSnippet": "독자들이 가장 많이 한 질문에 영주 닐슨 교수가 직접 답했어요",
        "guid": "https://blog.toss.im/article/retirement-plans-08",
        "isoDate": "2025-01-22T13:23:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]