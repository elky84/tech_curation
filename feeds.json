[
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Adapting the Facebook Reels RecSys AI Model Based on User Feedback",
        "link": "https://engineering.fb.com/2026/01/14/ml-applications/adapting-the-facebook-reels-recsys-ai-model-based-on-user-feedback/",
        "pubDate": "Wed, 14 Jan 2026 20:51:33 +0000",
        "content:encodedSnippet": "We’ve improved personalized video recommendations on Facebook Reels by moving beyond metrics such as likes and watch time and directly leveraging user feedback. \nOur new User True Interest Survey (UTIS) model, now helps surface more niche, high-quality content and boosts engagement, retention, and satisfaction.\nWe’re doubling down on personalization, tackling challenges like sparse user data and bias, and exploring advanced AI to make recommendations even smarter and more diverse.\nOur paper, “Improve the Personalization of Large-Scale Ranking Systems by Integrating User Survey Feedback” shares full details on this work. \nDelivering personalized video recommendations is a common challenge for user satisfaction and long-term engagement on large-scale social platforms. At Facebook Reels, we’ve been working to close this gap by focusing on “interest matching” – ensuring that the content people see truly aligns with their unique preferences. By combining large-scale user surveys with recent advances in machine learning, we are now able to better understand and model what people genuinely care about, which has led to significant improvements in both recommendation quality and overall user satisfaction.\nWhy True Interest Matters\nTraditional recommendation systems often rely on engagement signals – such as likes, shares, and watch time – or heuristics to infer user interests. However, these signals can be noisy and may not fully capture the nuances of what people actually care about or want to see. Models trained only on these signals tend to recommend content that has high short-term user value measured by watch time and engagement but doesn’t capture true interests that are important for long-term utility of the product. To bridge this gap, we needed a more direct way to measure user perception of content relevance. Our research shows that effective interest matching goes beyond simple topic alignment; it also encompasses factors like audio, production style, mood, and motivation. By accurately capturing these dimensions, we can deliver recommendations that feel more relevant and personalized, encouraging people to return to the app more frequently.\nRecommendation systems are typically optimized based on user interactions on the product, such as watch time, likes, shares, etc. However, by incorporating user perception feedback – like interest match and novelty – we can significantly improve relevance, quality, and the overall ecosystem.\n\nHow We Measured User Perception\nTo validate our approach, we launched large-scale, randomized surveys within the video feed, asking users, “How well does this video match your interests?” These surveys were deployed across Facebook Reels and other video surfaces, enabling us to collect thousands of in-context responses from users every day. The results revealed that previous interest heuristics only achieved a 48.3% precision in identifying true interests, highlighting the need for a more robust measurement framework. \nBy weighting responses to correct for sampling and nonresponse bias, we built a comprehensive dataset that accurately reflects real user preferences – moving beyond implicit engagement signals to leverage direct, real-time user feedback.\n\nFramework: User True Interest Survey (UTIS) Model\nDaily, a certain proportion of users viewing sessions on the platform are randomly chosen to display a single-question survey asking, “To what extent does this video match your interests?” on a 1-5 scale. The survey aims to gather real-time feedback from users about the content they have just viewed.\nThe main candidate ranking model used by the platform is a large multi-task, multi-label model. We trained a lightweight UTIS alignment model layer on the collected user survey responses using existing predictions of the main model as input features. The survey responses used to train our model were binarized for easy modelling and denoises variance in responses. In addition, new features were engineered to capture user behavior, content attributes, and interest signals with the object function to optimize predicting users’ interest-matching extent.\nThe UTIS model outputs the probability that a user is satisfied with a video, and is designed to be interpretable, allowing us to understand the factors contributing to users’ interest matching experience.\nUser perception feedback collected using surveys are extremely sparse but such feedback can be generalized in large scale recommendation systems using our novel model “Perception Layer” architecture that uses existing event predictions as additional features.\nIntegrating the UTIS Model in the Main Ranking System\nWe have experimented with and deployed several use cases of the UTIS model in our ranking funnel, all of which showed successful tier 0 user retention metric improvements:\nLate Stage Ranking (LSR): UTIS is deployed in parallel to the LSR model, providing an additional input feature into the final value formula. This allows fine-tuning of the final ranking stage to incorporate true interests while balancing other concerns.\nEarly Stage Ranking (Retrieval): UTIS is used to reconstruct users’ true interest profiles by aggregating survey data to predict affinity for any given user-video pair, allowing us to re-rank the user interest profile and source more candidates relevant to users’ true interests. Also, large sequences based on user-to-item retrieval models are aligned using knowledge distillation based objectives trained on UTIS predictions from LSR as labels. \nThe UTIS model score is now one of the inputs to our ranking system. Videos predicted to be of high interest receive a modest boost, while those with low predicted interest are demoted. This approach has led to: \nIncreased delivery of high-quality, niche content. \nA reduction in low-quality, generic popularity based recommendations.\nImprovements in like, share, and follow rates.\nImproved user engagement and retention metrics.\nSince launching this approach, we’ve observed robust offline and online performance\nOffline Performance: The UTIS model delivered an improvement in accuracy and reliability over the heuristic rule baseline. Accuracy increased from 59.5% to 71.5%, precision improved from 48.3% to 63.2%, and recall increased from 45.4% to 66.1%. These gains demonstrate the model’s ability to help in accurately identifying users’ interest preferences.\nOnline Performance: Large-scale A/B testing with over 10 million users confirmed these improvements in real-world settings. The UTIS model consistently outperformed the baseline, driving higher user engagement and retention. Notably, we saw a +5.4% increase in high survey ratings, a -6.84% reduction in low survey ratings, a +5.2% boost in total user engagement, and a -0.34% decrease in integrity violations. These results highlight the model’s effectiveness in improving user experience and matching users with relevant interests.\nFuture Work for Interest Recommendations\nBy integrating survey-based measurement with machine learning, we are creating a more engaging and personalized experience – delivering content on Facebook Reels that feels truly tailored to each user and encourages repeat visits. While survey-driven modeling has already improved our recommendations, there remain important opportunities for improvement, such as better serving users with sparse engagement histories, reducing bias in survey sampling and delivery, further personalizing recommendations for diverse user cohorts and improving the diversity of recommendations. To address these challenges and continue advancing relevance and quality, we are also exploring advanced modeling techniques, including large language models and more granular user representations.\nRead the Paper\nImprove the Personalization of Large-Scale Ranking Systems by Integrating User Survey Feedback\n    background-color: #0064E0;      /* Meta Blue */\n    color: #ffffff !important;      /* Force white text */\n    padding: 10px 20px;             /* Button size */\n    border: none;                   /* No border */\n    border-radius: 5px;             /* Rounded corners */\n    cursor: pointer;                /* Pointer cursor on hover */\n    text-decoration: none;          /* Remove underline */\n    display: inline-block;          /* Button-like display */\n    font-weight: bold;              /* Optional: bold text */\n    transition: color 0.3s ease, background-color 0.3s ease; /* Smooth transitions */\n  }\n  .meta-btn:hover {\n    color: #808080 !important;      /* Grey text on hover */\n  }\n\nThe post Adapting the Facebook Reels RecSys AI Model Based on User Feedback appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>We’ve improved personalized video recommendations on Facebook Reels by moving beyond metrics such as likes and watch time and directly leveraging user feedback.  Our new User True Interest Survey (UTIS) model, now helps surface more niche, high-quality content and boosts engagement, retention, and satisfaction. We’re doubling down on personalization, tackling challenges like sparse user data [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2026/01/14/ml-applications/adapting-the-facebook-reels-recsys-ai-model-based-on-user-feedback/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2026/01/14/ml-applications/adapting-the-facebook-reels-recsys-ai-model-based-on-user-feedback/\">Adapting the Facebook Reels RecSys AI Model Based on User Feedback</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "We’ve improved personalized video recommendations on Facebook Reels by moving beyond metrics such as likes and watch time and directly leveraging user feedback.  Our new User True Interest Survey (UTIS) model, now helps surface more niche, high-quality content and boosts engagement, retention, and satisfaction. We’re doubling down on personalization, tackling challenges like sparse user data [...]\nRead More...\nThe post Adapting the Facebook Reels RecSys AI Model Based on User Feedback appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=23389",
        "categories": [
          "ML Applications",
          "Video Engineering"
        ],
        "isoDate": "2026-01-14T20:51:33.000Z"
      },
      {
        "creator": "",
        "title": "CSS at Scale With StyleX",
        "link": "https://engineering.fb.com/2026/01/12/web/css-at-scale-with-stylex/",
        "pubDate": "Mon, 12 Jan 2026 18:34:59 +0000",
        "content:encodedSnippet": "Build a large enough website with a large enough codebase, and you’ll eventually find that CSS presents challenges at scale. It’s no different at Meta, which is why we open-sourced StyleX, a solution for CSS at scale. StyleX combines the ergonomics of CSS-in-JS with the performance of static CSS. It allows atomic styling of components while deduplicating definitions to reduce bundle size and exposes a simple API for developers.\nStyleX has become the standard at companies like Figma and Snowflake. Here at Meta, it’s the standard styling system across Facebook, Instagram, WhatsApp, Messenger, and Threads.\nOn this episode of the Meta Tech Podcast, meet Melissa, a software engineer at Meta and one of StyleX’s maintainers.  Pascal Hartig talks to her about all things StyleX—its origins, how open source has been a force multiplier for the project, and what it’s like interacting with large companies across the industry as they’ve adopted StyleX.\n\nDownload or listen to the episode below:\n\nYou can also find the episode wherever you get your podcasts, including:\nSpotify\nApple Podcasts\nPocket Casts\nThe Meta Tech Podcast is a podcast, brought to you by Meta, where we highlight the work Meta’s engineers are doing at every level – from low-level frameworks to end-user features.\nSend us feedback on Instagram, Threads, or X.\nAnd if you’re interested in learning more about career opportunities at Meta visit the Meta Careers page.\nThe post CSS at Scale With StyleX appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Build a large enough website with a large enough codebase, and you’ll eventually find that CSS presents challenges at scale. It’s no different at Meta, which is why we open-sourced StyleX, a solution for CSS at scale. StyleX combines the ergonomics of CSS-in-JS with the performance of static CSS. It allows atomic styling of components [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2026/01/12/web/css-at-scale-with-stylex/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2026/01/12/web/css-at-scale-with-stylex/\">CSS at Scale With StyleX</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Build a large enough website with a large enough codebase, and you’ll eventually find that CSS presents challenges at scale. It’s no different at Meta, which is why we open-sourced StyleX, a solution for CSS at scale. StyleX combines the ergonomics of CSS-in-JS with the performance of static CSS. It allows atomic styling of components [...]\nRead More...\nThe post CSS at Scale With StyleX appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=23515",
        "categories": [
          "Culture",
          "Open Source",
          "Web",
          "Meta Tech Podcast"
        ],
        "isoDate": "2026-01-12T18:34:59.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "eBay News Team",
        "title": "AI Trends to Watch In 2026",
        "link": "https://innovation.ebayinc.com/stories/ai-trends-to-watch-in-2026/",
        "pubDate": "Fri, 16 Jan 2026 00:00:00 -0800",
        "dc:creator": "eBay News Team",
        "content": "<div style=\"margin-bottom: 10px;\"><img src=\"https://static.ebayinc.com/static/assets/Uploads/Blog/Posts/_resampled/FitWzIwMCwxMTNd/Illo-3-Dev-Productivity.jpg?fs=7254c2f19a5c4b96\" width=\"200\" height=\"113\" alt=\"AI Trends to Watch In 2026\" /></div><div>We asked leaders across eBay for the most transformative tech trends to watch in the year ahead. Here’s what they had to say.</div>",
        "contentSnippet": "We asked leaders across eBay for the most transformative tech trends to watch in the year ahead. Here’s what they had to say.",
        "guid": "https://innovation.ebayinc.com/stories/ai-trends-to-watch-in-2026/",
        "categories": [
          "article"
        ],
        "isoDate": "2026-01-16T08:00:00.000Z"
      }
    ]
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Márton Braun",
        "title": "Update your Kotlin projects for Android Gradle Plugin 9.0",
        "link": "https://blog.jetbrains.com/kotlin/2026/01/update-your-projects-for-agp9/",
        "pubDate": "Fri, 16 Jan 2026 10:30:56 +0000",
        "content:encodedSnippet": "Android Gradle plugin 9.0 is now available, and it includes two major changes that will affect existing Kotlin projects:\nAndroid apps need to start using AGP 9.0’s built-in Kotlin support.\nKotlin Multiplatform projects targeting Android need to migrate to the new Android KMP library plugin.\nThis post provides some details about these changes and points you to the resources that you’ll need to update your existing projects.\nYou’ll also need to update tools and plugins that depend on AGP to their latest versions with support for AGP 9.0. If you use Android Studio, you’ll need to use Otter 3 Feature Drop or later.\nNote: Support for AGP 9.0 is coming soon to IntelliJ IDEA, expected to arrive in Q1 2026.\nFor information about Gradle plugin compatibility, you can refer to this community-maintained page.\nWe are working on adopting AGP 9.0 in our documentation, samples, and wizards. This means that they will all use AGP 9.0 by default and already include these changes in their respective configurations.\nUse built-in Kotlin\nPreviously, Android projects had to apply the Kotlin Android plugin (org.jetbrains.kotlin.android) to add support for Kotlin source files. With AGP 9.0, Kotlin support is built in and enabled by default, so you no longer need to apply the Kotlin Android plugin separately for Android apps.\nThe main migration step here is to remove usages of the Kotlin Android plugin from your projects. However, if your project uses kapt for annotation processing or sets custom kotlinOptions, you’ll need to update those configurations as well.\nRead the migration guide in the Android documentation for step-by-step instructions.\nWith AGP 9.0, you can still opt out of these changes temporarily by adding android.builtInKotlin=false and android.newDsl=false to your gradle.properties. However, this will no longer work in AGP 10.0, which is expected sometime in 2026.\nUse the new Android KMP library plugin\nIn previous versions, the Android Gradle plugin provided two different plugins you could apply to a module:\nThe Android library plugin (com.android.library).\nThe Android application plugin (com.android.application).\nEither of them could be used in combination with the KMP plugin (org.jetbrains.kotlin.multiplatform) to set up a multiplatform module.\nAGP 9.0 introduces a new, simplified Android KMP library plugin (com.android.kotlin.multiplatform.library), built specifically for multiplatform projects. The previously used Android library and Android application plugins are no longer compatible with the KMP plugin in the same module, which means you’ll need to migrate any multiplatform modules to the new plugin. This migration will be different for library and application modules; you can learn more about both scenarios below.\nWith AGP 9.0, you can still opt out of these changes temporarily by adding android.enableLegacyVariantApi=true to your gradle.properties. However, this will no longer work in AGP 10.0, which is expected sometime in 2026.\nMigrating a library module\nIf you have a module that uses the Android library plugin and the Kotlin Multiplatform plugin together, you’ll have to replace the Android library plugin with the Android KMP library plugin. This means you’ll have to update the build configuration of your existing module, but generally no changes are required to your project structure or source code.\nThe new Android KMP library plugin has default settings that are designed for Kotlin Multiplatform and optimized for build speed and stability. Some previous configuration options have been removed or moved to new APIs.\nRead the migration guide to learn about the differences and get step-by-step instructions on how to migrate a library module to the new plugin.\nMigrate a library module\n                                                    \nMigrating an application module\nMany projects apply both the Android application plugin and the Kotlin Multiplatform plugin in the same module. A module like this contains shared multiplatform code as well as an Android application with all of its related build configuration. This was the recommended structure in the past, and if you created your project using the KMP wizard, your project probably has a single composeApp module that’s set up like this.\nThe starting setup\nModules like this also have to be migrated to use the new Android KMP library plugin in the module that contains shared code, which requires multiple steps.\nFirst, you’ll have to create a new module for the entry point of your app and apply the Android application plugin there. This new module can be relatively small and simple, containing the build configuration to package an Android app and its entry point, such as Activity and Application classes (all represented by MainActivity in the illustrations here).\nWhen using AGP 9.0, this new module doesn’t need to apply a Kotlin plugin, as it can use the built-in Kotlin support (as detailed above).\nThen, this new application module should depend on the existing multiplatform module to have access to its contents. The multiplatform module can now become an Android library, which means you should migrate it to the new Android KMP library plugin.\nThe migrated project\nTo migrate an Android application module to AGP 9.0, follow the detailed steps in the migration guide.\nMigrate an application module\n                                                    \nConclusion\nWe recommend making these configuration changes in your existing projects as soon as possible to ensure smooth upgrades to the latest versions of AGP in the future.\nIn addition to the links above, you can read the full release notes for AGP 9.0 to learn more about what’s new.\nIf you encounter any issues with AGP 9.0 itself, create a new issue in the Android Studio component of the Google issue tracker.\nFor problems related to the Kotlin Multiplatform IDE plugin, create an issue in the KMT tracker.\nTo provide feedback on Kotlin documentation, create an issue on YouTrack or report it in the #multiplatform channel on the Kotlinlang Slack.",
        "dc:creator": "Márton Braun",
        "content": "Android Gradle plugin 9.0 is now available, and it includes two major changes that will affect existing Kotlin projects: This post provides some details about these changes and points you to the resources that you’ll need to update your existing projects. You’ll also need to update tools and plugins that depend on AGP to their [&#8230;]",
        "contentSnippet": "Android Gradle plugin 9.0 is now available, and it includes two major changes that will affect existing Kotlin projects: This post provides some details about these changes and points you to the resources that you’ll need to update your existing projects. You’ll also need to update tools and plugins that depend on AGP to their […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=673033",
        "isoDate": "2026-01-16T10:30:56.000Z"
      },
      {
        "creator": "Aleksandra Krupskaya",
        "title": "TransformConf: a New Conference on AI in Software Development",
        "link": "https://blog.jetbrains.com/blog/2026/01/15/transformconf-a-new-conference-on-ai-in-software-development/",
        "pubDate": "Thu, 15 Jan 2026 12:43:46 +0000",
        "content:encodedSnippet": "TransformConf, a new event focused on how AI is transforming software development, is coming in 2026!\nSave the date: September 15–16, London, UK. Early bird tickets are already available!\nGet early bird tickets\n                                                    \nAI is revolutionizing software development – that much barely needs saying. AI is already a daily tool for 85% of developers, and 68% expect AI proficiency to become a non-negotiable part of job descriptions within the next few years (according to the State of Developer Ecosystem Report 2025).\nAt JetBrains, we leverage it every day. AI is changing how we write, review, and ship code. We build AI-powered products like AI Assistant and Junie, train models like Mellum, and create frameworks like Koog so others can build their own AI agents.\nWhile everyone’s talking about AI, the conversations vary wildly, from doomsday scenarios to starry-eyed optimism, and everything in between. TransformConf is our attempt to create space for practical discussions. We want you to bring home more than cool merch – we want you to leave with insights you can immediately apply to your work.\nSince 2017, we’ve organized KotlinConf, the biggest yearly Kotlin event and a true celebration of the community. We know how impactful offline events can be. Our hope is that TransformConf becomes the place to discuss AI in software development in a way that impacts both today and tomorrow, a community where you feel at home, and a source of development and inspiration.\nKey details\nThe first TransformConf will take place September 15–16, 2026, at Tobacco Dock in London, UK.\nWho is it for?\nAnyone who is building AI, using AI tools, integrating AI into their products, platforms, and workflows, or preparing to do so. Developers are always at the heart of everything we do, so expect an engineering focus, but we also want to see ML researchers and engineers, DevOps specialists, technical leaders, architects, developer experience and productivity engineers, and anyone on product teams working with AI in production.\nWhat to expect?\nTwo days in London, packed with educational talks, peer discussions, booth meetings, professional reflection, and some fun activities. We’re planning 45-minute and 15-minute talks across three parallel tracks. The program will cover these practical and forward-looking topics:\nBuilding, deploying, and maintaining AI systems end to end\nAligning AI development across disciplines\nAdvanced modeling and training techniques\nDeveloper education and techniques in an AI-driven landscape\nLong-term changes to programming, teams, and the software industry\nSeparating myths from reality, addressing ethics, compliance, and long-term impact\nRethinking developer productivity and human-AI collaboration\nHow do I stay in touch?\nIf TransformConf is something you’re interested in, subscribe to our newsletter for updates on speakers, the program, tickets, and more. \nWhat about speaking and partnership opportunities?\nThe call for speakers is open! Check out the details and apply here. If you’re interested in partnership opportunities, contact us here.\nGet early bird tickets\n                                                    \nSee you in September in London!\nThe JetBrains team",
        "dc:creator": "Aleksandra Krupskaya",
        "content": "TransformConf, a new event focused on how AI is transforming software development, is coming in 2026! Save the date: September 15–16, London, UK. Early bird tickets are already available! AI is revolutionizing software development – that much barely needs saying. AI is already a daily tool for 85% of developers, and 68% expect AI proficiency [&#8230;]",
        "contentSnippet": "TransformConf, a new event focused on how AI is transforming software development, is coming in 2026! Save the date: September 15–16, London, UK. Early bird tickets are already available! AI is revolutionizing software development – that much barely needs saying. AI is already a daily tool for 85% of developers, and 68% expect AI proficiency […]",
        "guid": "https://blog.jetbrains.com/?post_type=blog&p=673222",
        "categories": [
          "events",
          "transformconf"
        ],
        "isoDate": "2026-01-15T12:43:46.000Z"
      },
      {
        "creator": "Maciej Gorywoda",
        "title": "Scala 3.8 Support in the Scala Plugin",
        "link": "https://blog.jetbrains.com/scala/2026/01/15/scala-38-support-in-the-scala-plugin/",
        "pubDate": "Thu, 15 Jan 2026 12:08:14 +0000",
        "content:encodedSnippet": "Hello everyone,\nAs I write these words, the Scala compiler team is wrapping up the Scala 3.8 release. It’s the last major release before a feature freeze. The next one, 3.9, will be the new Long-Term Support version. The compiler team decided that most of the work between 3.8 and 3.9 will go into stabilization, while new features and other improvements will be released with Scala 3.8. By providing support for the new Scala 3.8 features now, we’re able to give you the opportunity to enjoy and test them immediately. This will give both our team and the compiler team the opportunity to collect more and better feedback from you.\n\n\n\n\nThe into modifier\nThere’s a new modifier in Scala syntax, into, that can be used in two ways: as a wrapper over a type or as a soft keyword in front of classes, traits, opaque type aliases, and enum types. By wrapping a type with into[T] – for example, a type of a function parameter – we indicate that any type implicitly convertible to the declared type inside the into wrapper is accepted without requiring the implicitConversions import. The Scala plugin understands this mechanism, correctly infers types, and highlights cases where the conversion isn’t possible. In the future, using an implicit conversion without the implicitConversions import will be treated as an error.\n\n\n\n\nNotice that into is used as a type wrapper for elems, but at the same time we can still use elems.iterator as if elems was of the underlying type IterableOnce[A].\nAlternatively, if the type is in your codebase, you can also add the into modifier to indicate that implicit conversions into that type should always be allowed.\n\n\n\n\nPlease note that the warning displayed in the video appears only if Compiler-Based Highlighting is enabled.\nYou can read more about the into modifier in the Scala 3 documentation.\n\n\n\n\nScala 3.8 requires JDK 17+\nIn the new Scala release, the minimum required JDK version has been updated to 17. The latest version of the Scala plugin supports this requirement in two ways:\nIn the New Project Wizard: If you select Scala 3.8+ or newer, but choose a JDK version older than 17, a warning popup that reads “JDK >= 17 is required with Scala 3.8” will appear.\n\n\n\n\n\n\n\n\n\n\nIn existing projects: If your Scala project or any of its modules requires Scala 3.8+ but is being compiled on a JDK version lower than 17, IntelliJ IDEA will display a special warning.\n\n\n\n\n\n“Better fors”\n“Better fors” might sound a bit awkward for a feature name, but it introduces a significant and long-anticipated syntax relaxation for Scala’s for-comprehensions. Previously, a for-comprehension had to start with a generator, such as number <- List(1, 2, 3). If you wanted to use an alias, like list = List(1, 2, 3), you had to place it after a generator or define it before the entire for-comprehension and save the result as a value. Now, Scala 3.8 and the Scala plugin support having just the alias before a generator and transforming it into a value automatically. \n\n\n\n\n\nBasic support for capture checking\nThe Scala standard library is now compiled and published using Scala 3. You can see it in the Project view of a Scala 3.8 project. Simply scroll down and unfold the following path: External Libraries | sbt:org.scala-lang.scala-library-3.8.0:jar | scala-lang.scala-library-3.8.0:jar. There, you can find and open standard library source files, for example IterableOnce.\n\n\n\n\n\n\n\n\nAs you can see in the screenshots, the code in the Scala 3.8 version of this class already uses one of the new features: capture checking. Currently, the Scala plugin only supports basic syntax for capture checking, and even this support is experimental. Our goal was to enable you to navigate the Scala standard library code without encountering error highlighting, view type information for captures, and jump to their declarations.\n\n\n\n\nThe runtimeChecked method\nThe runtimeChecked method is an extension method defined in scala.Predef that can be called on any expression. When an expression ends with .runtimeChecked, it is exempt from certain static checks in the compiler, such as pattern match exhaustivity. The Scala plugin supports this feature out of the box. For example, if you write a pattern match that misses some cases – as in the screenshot below that defines all days of the week, but then uses only five of them in a match case – the Scala plugin displays a warning that the pattern matching is not exhaustive. If you decorate the value used for pattern matching with .runtimeChecked, the warning will not be displayed.\n\n\n\n\n\nLooking ahead\nThe features highlighted in this article are where the Scala plugin’s support is most visible to users. However, there are numerous other changes we’ve made in preparation for the Scala 3.8 release. In the near future, we will continue to improve our Scala 3 support, including some of the new Scala 3.8 features. Expect more updates in the form of blog posts, release notes, and videos.\nThe features highlighted in this article are where the Scala plugin’s support is most visible to users. However, there are numerous other changes we’ve made in preparation for the Scala 3.8 release. In the near future, we will continue to improve our Scala 3 support, including some of the new Scala 3.8 features. Expect more updates in the form of blog posts, release notes, and videos.\n\n\n\n\n\nAs always, your feedback is invaluable. Please report any issues you encounter in YouTrack,, and feel free to share your questions, thoughts and suggestions on Discord.\nWe’re always happy to help.\nHappy developing!\nThe Scala team at JetBrains",
        "dc:creator": "Maciej Gorywoda",
        "content": "Hello everyone, As I write these words, the Scala compiler team is wrapping up the Scala 3.8 release. It&#8217;s the last major release before a feature freeze. The next one, 3.9, will be the new Long-Term Support version. The compiler team decided that most of the work between 3.8 and 3.9 will go into stabilization, [&#8230;]",
        "contentSnippet": "Hello everyone, As I write these words, the Scala compiler team is wrapping up the Scala 3.8 release. It’s the last major release before a feature freeze. The next one, 3.9, will be the new Long-Term Support version. The compiler team decided that most of the work between 3.8 and 3.9 will go into stabilization, […]",
        "guid": "https://blog.jetbrains.com/?post_type=scala&p=672397",
        "categories": [
          "news",
          "releases",
          "scala",
          "scala-programming",
          "intellij-idea"
        ],
        "isoDate": "2026-01-15T12:08:14.000Z"
      },
      {
        "creator": "Kerry Beetge",
        "title": "Introducing Global Project Configuration: One Place to Manage All Your Qodana Rules",
        "link": "https://blog.jetbrains.com/qodana/2026/01/introducing-global-project-configuration-one-place-to-manage-all-your-qodana-rules/",
        "pubDate": "Wed, 14 Jan 2026 09:06:12 +0000",
        "content:encodedSnippet": "Global Project Configuration is a new feature that helps Qodana users manage linter settings across an entire organization or team – all from one location. Until now, maintaining consistent code quality rules meant updating configuration profiles in every individual repository. \nWhether you were approving new licenses, adjusting rule severity, or defining custom patterns for hardcoded passwords, changes had to be repeated manually across multiple projects. However, as organizations scale, this approach becomes slow, error-prone, and difficult to audit.\nGlobal Project Configuration solves this. It provides a streamlined, reusable, organization-wide mechanism for defining and enforcing code quality standards – without limiting the flexibility individual projects may need.\nBook Demo\nWhy Global Project Configuration matters\nWith this new capability, you can:\nEstablish organization-wide standards once, and apply them everywhere.\nEnforce best practices without sacrificing project-specific adjustments.\nApply and update rules at scale, instantly affecting any linked projects.\nReduce duplication and manual overhead, especially for large repositories or distributed teams.\nImprove consistency across teams, languages, and tech stacks.\nThis makes Qodana easier to manage, more adaptable to real-world work, and much more scalable.\nHow it works\nGlobal Project Configuration is powered by a dedicated repository in which your organization stores the configuration files to be used during Qodana analysis. You can structure this repository in a way that suits your workflow, organizing configurations logically and referencing others to encourage reuse.\n\n\n\n\n\nConfiguring for teams: A practical example\nLet’s look at how different teams might take advantage of this feature.\nImagine your organization creates a global Base configuration containing universal coding standards shared across all teams. From there:\nTeam A, which uses Lombok in Java development, inherits from Base and adds stricter Lombok-related rules. They apply this configuration only to their own projects.\nTeam B, maintaining a legacy project, inherits from Base but disables most checks except for security rules. This allows them to focus on critical issues without being overwhelmed by unrelated warnings.\nEach team tailors the standards to their needs – while still aligning with the organization’s overall quality strategy.\nApplying configurations to projects\nOnce a project is linked to a configuration:\nQodana automatically applies it on the next run.\nAny changes pushed to the configuration repository are picked up and applied seamlessly.\nYou can view all configurations and their associated projects in the Qodana Cloud UI, making management transparent and intuitive.\nEverything is centralized, traceable, and easy to maintain.\nGet started with Qodana’s Global Project Configuration\n\nVisit Qodana Cloud → Settings → Global Configurations in the product, or view our documentation for a full guide on creating the configuration repository, syncing it with Qodana Cloud, and linking configurations to specific projects.\nView Setup",
        "dc:creator": "Kerry Beetge",
        "content": "Global Project Configuration is a new feature that helps Qodana users manage linter settings across an entire organization or team &#8211; all from one location. Until now, maintaining consistent code quality rules meant updating configuration profiles in every individual repository.&#160; Whether you were approving new licenses, adjusting rule severity, or defining custom patterns for hardcoded [&#8230;]",
        "contentSnippet": "Global Project Configuration is a new feature that helps Qodana users manage linter settings across an entire organization or team – all from one location. Until now, maintaining consistent code quality rules meant updating configuration profiles in every individual repository.  Whether you were approving new licenses, adjusting rule severity, or defining custom patterns for hardcoded […]",
        "guid": "https://blog.jetbrains.com/?post_type=qodana&p=674592",
        "isoDate": "2026-01-14T09:06:12.000Z"
      },
      {
        "creator": "Sofia Kulikova",
        "title": "Insights Into China’s Developer Landscape: Key Trends From the JetBrains Developer Ecosystem Survey 2025",
        "link": "https://blog.jetbrains.com/research/2026/01/insights-into-china-s-developer-landscape-key-trends/",
        "pubDate": "Tue, 13 Jan 2026 16:11:09 +0000",
        "content:encodedSnippet": "Every year, thousands of developers take part in the JetBrains Developer Ecosystem Survey, helping us map the evolving landscape of software development worldwide. Published in eight languages with data from 20 geographical regions, the survey includes China – a fast-evolving market that shares many global characteristics while retaining distinct traits of its own. \nFor example, Java remains the most widely used language in many Chinese industries – a pattern that differs from global trends and reflects the country’s vast mobile and enterprise sectors. At the same time, rising adoption of Go and TypeScript points to a growing focus on scalability, developer experience, and modern web architectures.\nThanks to the contributions of our survey participants, we’re able to offer a closer look at the Chinese developer ecosystem, including insights not featured in our published infographics. We hope these findings are valuable not only to developers working in China, but also to those less familiar with the market who may find it fascinating to compare local practices with global trends.\nSoftware development trends in China: It’s all in the details\nBroadly, the coding landscape in China looks similar to that of many other regions: STEM graduates with backgrounds in computer science, trained in widely adopted languages and tools, applying their skills in various industries. But to understand what truly shapes this market, it’s vital to look beneath the surface – and that’s where the differences emerge.\n 1.  The prevalence of Java for coding\nWhile Java remains a popular development language worldwide, it is far more common among Chinese developers than in most other regions.\n\n\n\n\nGlobally, an average of 27.76% of professional developers use Java as their primary development language, with Java, JavaScript, and Python forming a relatively balanced “big three”. In China, however, Java stands out clearly: it’s the first choice of 58.17% of Chinese developers.\n\n\n\n    \n“The dominance of Java in the Chinese market is fundamentally driven by the explosive growth of its internet industry and the resulting established technology stacks. China’s massive wave of e-commerce, fintech, and social media startups standardized on Java in their early stages. They built their core, high-throughput, distributed systems on proven Java frameworks like Spring and Apache Dubbo. This created a massive ecosystem and a self-reinforcing cycle: Companies use Java because the talent pool is large, and developers learn Java because that’s where the jobs are.\n\r\nThere’s also the Android factor. Before Kotlin became the preferred language, the massive adoption of Android smartphones in China cemented Java’s position for years as the primary language for mobile app development, further expanding its developer base.”\n\n            \nJoseph Du\n                                                                Customer Success Engineer\n                                    \n2. Widespread mini-app adoption vs. limited cloud service development in China\nIn Developer Ecosystem 2025, Chinese developers show a significantly higher tendency to develop mini-apps compared to the global developer community: 30.27% of professional developers in China are involved in mini-app development. The two most popular solutions are uni-app (35.06%) and Weixin native (34.21%), though 22.39% of developers report dissatisfaction with the current tooling ecosystem.\nMini-apps (小程序) are deeply integrated into daily life in China. A single mobile app can host a wide range of services, from messaging and taxi booking to food delivery and business registration. These lightweight applications run inside larger platforms and typically rely on platform-specific frameworks, such as WeChat Mini Programs and uni-app, combining JavaScript, custom markup languages, and CSS-like styles.\nThis year, the WebStorm team introduced a highly requested WeChat Mini Program plugin for working with Weixin native, with support from user research. This plugin adds native support for WXML, WXSS, and WXS syntax, allowing developers to work directly in WebStorm without switching between the WeChat IDE and their primary editor. It also reduces time spent checking component documentation. More details about the WeChat Mini Program plugin are available in this blog post.\n\n\n\n\n3.  Publicly traded companies outweigh privately owned ones\nOur third theme looks at where developers work and the types of organizations they are part of. The chart displays a diverse mix of company types, highlighting how the distribution in China differs from the global picture.\n\n\n\n\n\nPrivately owned companies: Chinese respondents are more likely to work for startups (24%) and large publicly traded companies (24%), compared to the global averages of 16% and 16%, respectively. The more striking difference, however, lies in ownership structure – only 22% of Chinese developers work for private companies, compared to 32% worldwide.\nMultinational corporations: Just 10% of developers in China are employed by multinationals, far below the global average of 19%.\nB2B vs. B2C: Business orientation also differs. In China, 39% of developers work in B2B and 28% in B2C, compared to 58% in B2B and 35% in B2C globally. This suggests a stronger consumer-facing focus in the Chinese market, where developers more often contribute to end-user products and services.\n\n\n\n\n4.  A perspective on low-code / no-code\nChinese developers show a stronger tendency to actively engage with low-code/no-code platforms compared to the global average.\n\n\n\n\nChinese developers are more likely to both build applications using these tools (17% vs. 10% globally) and to develop systems that support other users (14% vs. 4%). Business process automation (BPA) remains the top use case worldwide and in China.\nThe big gap appears in building websites and applications: 30% of Chinese respondents use low-code/no-code for building websites and applications, compared to just 17% globally.\n\n\n\n\nGlobally, low-code/no-code is still viewed primarily as a tool for business processes and rapid prototyping. In China, however, it has become part of a broader productivity-driven culture, with developers not only using these tools themselves but also enabling others to build and automate through them.\n5. Chinese LLM landscape: Foreign LLMs remain the top choice\nChinese developers show a distinct pattern in their use of AI tools. GitHub Copilot is significantly less popular in China than worldwide (26% vs. 38%), while Cursor has gained remarkable traction and is used by 23% of Chinese developers compared to 11% globally.\nGlobal leaders like ChatGPT and Claude are also far less represented in China. Instead, local alternatives, such as DeepSeek and TONGYI Lingma, play a major role, reflecting a strong preference for domestic or self-hosted solutions.\nNote: The list of LLMs in the survey was limited, with no open field. As a result, the findings reflect only the tools included in the questionnaire rather than the full market landscape.\n\n\n\n\nClosing thoughts\nThe insights in this post go beyond what you’ll find in our public infographics, which do not include comparison filters. We’re glad to share these deeper perspectives into the Chinese developer ecosystem, and we’re especially grateful to everyone who took part in our survey – your contributions make it possible for us to capture and understand these unique trends.\nIf you’d like to take part in future studies and help us learn more about how developers work around the world, we invite you to join the JetBrains Tech Insights Lab. \nTo stay updated on new findings, stories, and behind-the-scenes perspectives, subscribe to the JetBrains Research Blog.",
        "dc:creator": "Sofia Kulikova",
        "content": "Every year, thousands of developers take part in the JetBrains Developer Ecosystem Survey, helping us map the evolving landscape of software development worldwide. Published in eight languages with data from 20 geographical regions, the survey includes China –&#160;a fast-evolving market that shares many global characteristics while retaining distinct traits of its own.&#160; For example, Java [&#8230;]",
        "contentSnippet": "Every year, thousands of developers take part in the JetBrains Developer Ecosystem Survey, helping us map the evolving landscape of software development worldwide. Published in eight languages with data from 20 geographical regions, the survey includes China – a fast-evolving market that shares many global characteristics while retaining distinct traits of its own.  For example, Java […]",
        "guid": "https://blog.jetbrains.com/?post_type=research&p=672795",
        "categories": [
          "articles-2",
          "deveco",
          "industry-trends",
          "china",
          "jetbrains-research"
        ],
        "isoDate": "2026-01-13T16:11:09.000Z"
      },
      {
        "creator": "Elvira Mustafina",
        "title": "Compose Multiplatform 1.10.0: Unified @Preview, Navigation 3, and Stable Compose Hot Reload",
        "link": "https://blog.jetbrains.com/kotlin/2026/01/compose-multiplatform-1-10-0/",
        "pubDate": "Tue, 13 Jan 2026 14:48:34 +0000",
        "content:encodedSnippet": "Compose Multiplatform 1.10.0 has been released! We’re continually developing our multiplatform APIs and expanding support for Jetpack libraries commonly used on Android.\nHere are the highlights of this release:\nOne common @Preview annotation to rule them all\nNavigation 3 is available on non-Android targets\nStable and bundled Compose Hot Reload\n\n\n\n\nGet Started with Compose Multiplatform\nFor a complete overview of the changes, check out What’s new in Compose Multiplatform 1.10.0 or the release notes on GitHub.\nCommon @Preview annotation\nPreviously, we had three separate @Preview annotations across different packages, which made it challenging to figure out the correct combination of annotation, platform, and IDE.\nWith this release, we’ve unified previews under a single @Preview annotation that works in your commonMain source set:\n\n\n\n\nAll other annotations have been deprecated. But fear not – IDE quick-fix suggestions will help you easily update your dependencies to androidx.compose.ui.tooling.preview.Preview.\nNavigation 3\nWe’ve introduced support for Navigation 3, a new library for managing navigation. With Navigation 3, you can manipulate your navigation stack directly, making tasks like adding or removing destinations more straightforward.\nTo help you get started, we’ve compiled a set of Navigation 3 recipes with examples of common usage patterns for Compose Multiplatform.\n\n\n\n\nCompose Hot Reload\nCompose Hot Reload is designed to speed up UI iteration by letting you instantly see changes without restarting the application:\n\n                        \n\n\nThe Compose Hot Reload plugin is now stable – check out this deep-dive blog post to learn more about how it works. It’s now bundled with the Compose Multiplatform Gradle plugin and enabled by default, so no additional configuration is required.\nTry Compose Hot Reload\nThese are just the highlights – this release includes numerous updates across platforms, including the introduction of more transparent dependency management for Compose Multiplatform libraries with direct library references.\nMake sure to check out the full version in our documentation. If you encounter any issues, please report them on our issue tracker.",
        "dc:creator": "Elvira Mustafina",
        "content": "Compose Multiplatform 1.10.0 has been released! We’re continually developing our multiplatform APIs and expanding support for Jetpack libraries commonly used on Android. Here are the highlights of this release: Get Started with Compose Multiplatform For a complete overview of the changes, check out What’s new in Compose Multiplatform 1.10.0 or the release notes on GitHub. [&#8230;]",
        "contentSnippet": "Compose Multiplatform 1.10.0 has been released! We’re continually developing our multiplatform APIs and expanding support for Jetpack libraries commonly used on Android. Here are the highlights of this release: Get Started with Compose Multiplatform For a complete overview of the changes, check out What’s new in Compose Multiplatform 1.10.0 or the release notes on GitHub. […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=674389",
        "categories": [
          "multiplatform",
          "compose-hot-reload",
          "compose-multiplatform"
        ],
        "isoDate": "2026-01-13T14:48:34.000Z"
      },
      {
        "creator": "Sebastian Sellmair",
        "title": "The Journey to Compose Hot Reload 1.0.0",
        "link": "https://blog.jetbrains.com/kotlin/2026/01/the-journey-to-compose-hot-reload-1-0-0/",
        "pubDate": "Tue, 13 Jan 2026 14:47:58 +0000",
        "content:encodedSnippet": "Compose Hot Reload has just been promoted to stable with our 1.0.0 release. We worked hard to build a technology that is easy to use and well-integrated into existing tools while also requiring zero configuration from users. The tool is bundled with Compose Multiplatform, starting from version 1.10 (see our dedicated release blog post). While we’re happy to have built tooling that doesn’t really require users to think about its technical implementation, we’re also immensely proud of the engineering behind the project. This blog post highlights some of the technical aspects we find most interesting and provides a high-level overview of how Compose Hot Reload works under the hood.\n\n\n\n\nWhat we’ve built so far\nCompose Multiplatform is a declarative framework for sharing UIs across multiple platforms. Typically, if you’d like to launch a Compose application during development, you need to invoke the corresponding Gradle build tasks or otherwise launch it directly from within the IDE. This is also the case with Compose Hot Reload. Launching your application can be done by invoking the ./gradlew :myApp:hotRunJvm task or clicking Run with Compose Hot Reload in IntelliJ IDEA (assuming that the Kotlin Multiplatform plugin has already been installed).\nOnce the app launches in hot-reload mode, we see a floating toolbar right next to the application window. Changing code within IntelliJ IDEA and clicking Save (Cmd+S/Ctrl+S) will recompile the relevant code, perform a hot reload, and update the UI accordingly while preserving all parts of the state that are still considered valid.\nNote: Screen recordings were made using the latest Compose Hot Reload version, 1.1, which differs visually from the 1.0 release but is conceptually equivalent.\n\n\n\n\nBeyond simply changing the image resources, Compose Hot Reload lets you make almost arbitrary changes to your code, including but not limited to adding and removing functions, classes, and parameters – in short, all the kinds of changes you typically make during regular development.\nThe floating toolbar next to your application offers additional features, such as the ability to view logs, manually trigger a reload, and reset the UI state, as well as status indications and more. One of the most critical aspects of any hot-reload user experience, however, is communicating whether something went wrong. As the developer, you should always be acutely aware when reloading fails, causing your current code changes not to be reflected in the application. This could happen, for example, if you try to reload but the code cannot compile and requires your attention. In such cases, Compose Hot Reload will prominently display the error right in the target application’s window.\n\n\n\n\nLet’s decompose Compose Hot Reload\nLooking at the example above, let’s break Compose Hot Reload into its separate components and try to understand their individual purposes. In this section, we will recreate the process of building the core of Compose Hot Reload from the ground up, before proceeding to an explanation of the more technical details in the following sections.\nFirst things first, the main requirement for Compose Hot Reload is the ability to update the application while it is running dynamically. To achieve this, we need to answer two questions: How do we reload code that is already running dynamically, and when should we do it? Without first answering these questions, the technology will not work. \nThe how part can be achieved in multiple ways in the JVM world: using custom classloaders, JVM hot swapping, and via various other methods. But what really makes Compose Hot Reload work so well is the JetBrains Runtime and its DCEVM implementation, which we’ll cover in detail later.\nWith the how being taken care of by DCEVM, we need to decide on the when. In other words, we need a way to run the application with DCEVM, detect when the user makes changes, recompile the code, and trigger the reload. That’s right, we need an integration with the application’s build system – a plugin that will provide us access to applications’ build and launch configurations.\nIt would seem that these components should provide everything we need, right? We can integrate with the application’s build system and trigger code reloads when the user changes their code! Unfortunately, it’s not that simple. You see, dynamically changing the code will not re-render the application’s UI. Even worse, changes to the code can now lead to errors when interacting with the UI. For example, what will happen if a user interacts with a button that no longer exists in the code? Therefore, we also need a way to interact with the Compose framework and re-render the UI when necessary. Luckily, the Compose Runtime provides APIs to invalidate states and re-render UIs, so we just need to correctly invoke them after the code is reloaded.\nGood news: these three components are sufficient to provide the core functionality of Compose Hot Reload! But to truly elevate the user experience, we need to provide quick visual feedback on the current state of the hot reload. That’s why Compose Hot Reload also offers:\nIn-app notifications about the state of any hot reloads.\nA custom toolbar next to the application window, which allows us to track the status and control the state of a given hot reload.\nIntegration with an IDE that allows you to easily run the application with Compose Hot Reload and monitor its state.\nNow that you have the rough outline of Compose Hot Reload, let’s dive deeper into its technical implementation. There is a lot to discover!\nReloading code dynamically: DCEVM and the JetBrains Runtime \nAs previously mentioned, Compose Hot Reload relies heavily on the JetBrains Runtime to run the user code. Not only is the JetBrains Runtime specialized in building UI applications, it is also, to date, the only JVM to implement the DCEVM proposal published in 2011 by Thomas Würthinger, Christian Wimmer, and Lukas Stadler. This proposal enhances virtual machines’ ability to reload code. Where a regular JVM is limited to just reloading function bodies, DCEVM proposes “unrestricted and safe dynamic code evolution for Java”, which lifts the restrictions and supports almost arbitrary code changes. Here’s an example demonstrating how the JetBrains Runtime can perform more complex reloads:\n\n\n\n\nThe given program creates an instance of the class Foo and prints it every second in an endless loop.\nWhen reloading, the class was modified, and a second property y was added. This begs the question: How can the program and the current state be reloaded in this way? Once the developer edits the code and compiles it, Compose Hot Reload sends the updated .class files to the currently running application, requesting that it reload. The request will be handled over several subsequent steps. \nThe first step can be called “verification”: The JetBrains Runtime will check whether the new .class files are valid and can generally be reloaded. If the code passes all checks, it can proceed to the second stage, “loading”. Then, the JetBrains Runtime will load all classes into what we call a “side universe”. This will represent the application code (all loaded classes) after the reload.\n\n\n\n\nAt this point, the side universe can be thought of as a second instance of your application, containing all updated application code, but without any state or threads executing. The above example shows the changed Foo.class marked in green, indicating that it points to an updated version of the class.\nThe current state of the application is then required to migrate objects to this side universe: We call this a “state transfer”. This state transfer is implemented as a special garbage collection (GC) pass. GC has a few properties that are useful for implementing the state transfer. Not only is it possible to “stop the world” (wait for all application threads to reach safe points), but GC is also allowed to allocate new memory and move objects to new locations!\nTo demonstrate this for the previous example, we can look at the instance created by val foo = Foo(1). The actual instance might look something like this in your memory:\n\n\n\n\nThis is where the object currently resides at a known memory location. The memory representation of our object starts with a 16-byte header containing metadata about our object, for example, a pointer or a compressed pointer to our runtime representation of the class (called Klass). Right after the header, we can find the actual fields stored in the object. In our case, we see the value 1 associated with the property x. Memory before or after our object is unknown and could contain basically anything. When a reload changes a class’s layout by adding or removing properties, it becomes clear that the object needs to be adjusted.\nThis is where the nature of GC works well for migrating the object. GC can allocate a new block of memory to account for the object’s new size, and then start migrating the object by copying its previous values. In the chosen example, we added one more int field, requiring us to allocate 32 additional bits of memory. Since the x field was unchanged, we can just copy the previous value to its new location. However, a decision has to be made on how to treat the newly introduced field y. Re-running the constructor is not feasible, so DCEVM uses the JVM defaults: null, 0, and false.\n\n\n\n\nNote that the new object has a different header that points to the new Klass object, representing the reloaded code.\nOnce all objects are migrated, all pointers to them will be updated to point to the migrated objects. In our example above, the instance Foo has moved to a new memory location and now carries a y property. \nBefore we can resume the application, the runtime needs to consider that previous optimizations and just-in-time compilations to machine code might be invalid. For this reason, the code is then “de-optimized”. Once the application resumes, the JIT compiler is free to kick in again, optimizing our code and returning the application to the previous level of performance.\nJava agents FTW\nDCEVM is an amazing technology that allows you to dynamically reload and redefine code while it is executing. However, to make it actually work, we need a way to call its APIs from the user application. \nLuckily, the JVM has a way to implement that – it’s called a Java agent. A Java agent is a Java library that can be attached to any Java program and execute code before the target program starts.\nTo create a Java agent, we need to declare a class with a premain method. This method, as the name suggests, will be executed before the target application’s main, i.e. during JVM startup. The method takes a String argument and an instance of java.lang.instrument.Instrumentation as its parameters.\nfun premain(args: String, instrumentation: Instrumentation)\njava.lang.instrument.Instrumentation is a part of the Java Instrumentation API, which allows agents to observe, modify, and redefine classes at runtime. When you are using the JetBrains Runtime, java.lang.instrument.Instrumentation provides you with access to DCEVM via its redefineClasses method implementation.\nSo, in the case of Compose Hot Reload, the Java agent’s function is relatively straightforward: We attach it to the target application and launch a background task/thread in the premain. This background task will invoke instrumentation.redefineClasses with new classes whenever it receives information about changes to the application’s code. \nFinally, we just need to package our agent as a standalone JAR and give the agent information required by the JVM in the manifest file:\nPremain-Class: org.jetbrains.compose.reload.agent.ComposeHotReloadAgent\nCan-Redefine-Classes: true  // declare that we intend to redefine classes\nIn practice, we use the Compose Hot Reload agent for much more than just redefining classes via DCEVM. We will cover its other functions in the following sections.\nYou may have noticed that we boldly skipped one of the most important parts of any hot reload by simply claiming that the agent “receives information about changes in the code”. It is, indeed, not so simple. However, to get the whole picture, we first have to dive into another complex subsystem of Compose Hot Reload – its integration with build systems.\nBuilding a zero-configuration tool\nThe combination of the JetBrains Runtime’s ability to reload code and an agent that can listen for reload requests form the core functionality of Compose Hot Reload. Integrating these components into a zero-configuration product requires careful integration into build tools. The following describes how the Gradle plugin is implemented, but hot reload is also available in Amper. The user-facing workflows can be separated into two typical kinds of builds: In the first, the user compiles the application and intends to launch it in hot-reload mode. In the second kind of build, there will be multiple reloads. These consist of incrementally compiling the code, and then sending the reload request to the agent after a given change. Reload requests typically contain all .class files that have been either changed, added, or modified. While reloading can be triggered manually, it is typically managed either by Compose Hot Reload itself or by the IDE, which watches source files for changes. \nThis leads to two questions: \nHow can the set of changed files be resolved efficiently when reloading?\nHow can other tools reliably issue reloads?\n\n\n\n\nThe flow of launching the application already gives a lot of insights into how the overall system works, and it is relatively straightforward: \nThe entire project is compiled, as usual, and produces the corresponding .class files. Typically, applications can launch directly afterwards by launching the JVM with all necessary arguments (classpath, properties, JVM arguments, user arguments, etc.). A hot reload run will then perform two additional steps before actually launching.\nAfter the compilation finishes, a snapshot of the classpath is taken. It’s worth mentioning that Compose Hot Reload differentiates the classpath into a hot and cold part. Dependencies resolved from remote repositories are considered cold because they won’t change during a hot reload session. Code compiled by the current build, however, is considered hot. The snapshot is therefore only taken of the hot part of the classpath and contains all known .class files, each with a checksum of its contents.\nThe second task performed by hot reload is to produce special hot-reload arguments for the run. For convenience and to support restarting the application, these arguments will be stored in an .argfile. The most important arguments being:\n-XX:+AllowEnhancedClassRedefinition, which enables the JetBrains Runtime’s DCEVM capabilities.\n-javaagent:/.../hot-reload-agent-1.1.0.jar, which adds our agent to the application.\n-Dcompose.reload.buildSystem=Gradle, which tells Compose Hot Reload to use the Gradle recompiler backend.\n-Dgradle.build.root=/.../myProject, which tells Compose Hot Reload where the current Gradle project is located.\n-Dgradle.build.project=:app, which indicates which Gradle project was launched for hot reload.\n-Dgradle.build.task=hotReloadJvmMain, which tells Compose Hot Reload which Gradle task can be executed to issue a reload.\n-Dcompose.reload.devToolsClasspath=..., which provides the floating toolbar application classpath.\n-Dcompose.reload.devToolsEnabled=true, which enables the floating toolbar application.\nGiven that the application now has all the information necessary to start reloads by invoking the provided Gradle task at the provided location, Compose Hot Reload will start a supervisor process called devTools. This is the same process that will then provide the floating toolbar window. This process will either start a continuous Gradle build for reloading or wait for external events (such as you clicking Reload, or the IDE sending a signal to reload). \nSuch signals can be sent through the orchestration protocol, which we’ll talk about in more detail later. For now, it is just essential to know that the application will host a TCP server that allows components, such as Gradle, Amper, or the IDE, to communicate with each other.\nRequests to reload the application will trigger the corresponding reload task. Such a Gradle invocation will be marked as isHotReloadBuild and will get the application server port forwarded as orchestration.port.\nOnce the project is compiled incrementally, the snapshot will be rebuilt incrementally as well. Comparing the previous snapshot to the new one is quick and produces a map of .class files that are either added, removed, or modified. \nThe last task is to connect to the application using the provided port and send a request to reload those files. The agent will handle this request and reload the code using the JetBrains Runtime.\n\n\n\n\nSince all relevant tasks can be created automatically by inferring them from the Kotlin Gradle Plugin model, the tool can be used effectively without any further configuration. Launching from the CLI only requires calling the corresponding hotRunJvm task. IntelliJ IDEA can import hot reload tasks during the Gradle sync process and create corresponding run gutters.\nBut what about the UI?\nAs we mentioned before, being able to reload the code does not guarantee that Compose Hot Reload will magically start working. Modern applications are far too complex for that to happen. Therefore, after reloading the code, we need to propagate those updates throughout the application, re-rendering the UI, resetting the state, cleaning the references to the old code, etc. \nNow, to do that correctly, we first need to understand how Compose code actually works. Let’s take a look at how our App function from the previous examples is represented.\n@Composable\nfun App() {\n   var clicks by remember { mutableStateOf(0) }\n   MaterialTheme {\n       Column(\n           horizontalAlignment = Alignment.CenterHorizontally,\n       ) {\n           Button(onClick = { clicks++ }) {\n               Text(\"Clicks: $clicks\")\n           }\n\n\n           Icon(\n               imageResource(Res.drawable.Kodee_Assets_Digital_Kodee_greeting),\n               contentDescription = \"Kodee!!!\",\n               modifier = Modifier,\n               tint = Color.Unspecified\n           )\n       }\n   }\n}\nCompose splits the code into sections called groups and assigns each group a unique integer key. As an approximation, you can think that each scope (e.g. each {} pair in the code) corresponds to a separate group. The groups are organized in a tree-like structure that corresponds to their relations in the source code. In this image, green nodes correspond to Compose groups created by the App function, blue nodes represent other Composable functions called in the App function, and white nodes represent state information. \nWhen the Compose Runtime detects that some parts of the UI need to be re-rendered, it marks the groups corresponding to those components as invalid. It then re-executes all the code corresponding to those groups, creating an updated version of the tree. Subsequently, this means that the state created by any invalidated groups will be reset. For example, if we invalidate the group with the key -419397569, the mutable state with the counter will not be reset, while all the other code will be re-executed.\n\n\n\n\nNow that we have a high-level understanding of the Compose representation, how do we actually implement hot reload? Well, the intuitive option would be to reuse the Compose Runtime’s existing functionality: If the code changes, we invalidate all groups corresponding to that code. This will allow us to:\nRe-render only the necessary parts of the UI.\nPreserve the state whenever possible.\nClean up all references to the old code.\nTo do that, we need to understand:\nWhat code has been changed?\nWhich Compose groups need to be invalidated because of that change?\nAnd here, the Compose Hot Reload agent comes into play one more time.\nBytecode analysis\nWhen compiling the application, the Compose plugin changes the intermediate representation (IR) of the Composable functions and inserts additional instructions for the Compose Runtime. For example, the bytecode of the App function will start with the following instruction: $composer.startRestartGroup(1359525739).\nHere, startRestartGroup is a special instruction of the Compose Runtime that marks the start of a new group, and its argument is the key for this group. Correspondingly, the end of this group will be marked by a call to endRestartGroup. This means that all the information that we’re interested in is actually contained in the bytecode; we just need to extract it.\nLuckily, the Java agent allows us to hook into the target application and inspect all the classes while they are loading. We use the ASM library to analyze classes, and for each method, we build our own representation of the Compose tree. By locating the startGroup and endGroup calls, we can determine the bounds (and keys) of Compose groups, and their locations in the code define the parent-child relations between them. Conditional branches inside a function can be parsed by tracking jump instructions and their target labels.\n\n\n\n\nFor each Compose group, we determine its key, its relations with other groups, its dependencies on different methods, and its hash. The group’s hash value attempts to capture its semantics; for simplicity, we can think of it as a hash of all the bytecode instructions in this group. It allows us to quickly determine whether the group’s code has changed semantically during reloads.\nTracking changes\nNow that we know how to extract information from the bytecode, we need to think about how to apply it. As we mentioned, a Java agent allows us to analyze every class before it has been loaded. This will enable us to analyze classes not only during initial loading, but also during reloads. Thus, during reload, we can keep track of both the old and new versions of each class and monitor changes.\n\n\n\n\nWhen the class is reloaded, we can compare both its old and new runtime information and invalidate groups using the following rules.\nIf the code hash of a Compose group is changed, invalidate it.\nIf the code hash of a non-Compose function is changed, invalidate all Compose groups that are (transitively) dependent on it. Since we keep track of the entire runtime, we can efficiently compute all method dependencies.\nAfter that, the only thing left to do is to save the new version of the runtime as the current one.\nThe compiler doesn’t like your hot reload stuff\nEven though the core idea of the code invalidation and UI re-rendering approach is not particularly complicated, the path to Compose Hot Reload’s success was blocked by many obstacles and hurdles we had to overcome. Many of them stemmed from the fact that the Kotlin compiler and Compose plugin weren’t built with DCEVM and hot swapping in mind. Therefore, bytecode produced by those tools often behaved unexpectedly during hot reload. In this section, we will highlight some of the technical difficulties we encountered during the development of Compose Hot Reload and how we solved them.\nAll your lambdas belong to us\nBoth Kotlin and Compose encourage heavy use of lambda functions. However, lambda functions were a significant source of inconsistency in the bytecode produced by the Kotlin compiler, mainly due to their names. Users do not provide names for lambda functions; therefore, the compiler generates them itself, using predefined rules to determine each lambda’s name. Unfortunately, those rules are not designed with hot reload in mind.\nThere are two ways a lambda function can be compiled to the bytecode: anonymous classes and indy lambdas. The first way suggests that a lambda is compiled as a class that implements one of Kotlin’s FunctionN interfaces, and the lambda’s body is placed inside the invoke method of this class.\nThe indy way suggests that a lambda is compiled as a function inside the original class, which is then converted into an object in the runtime via the JVM’s invokedynamic instruction and the LambdaMetafactory.\nfun bar() =\n   foo { println(it) }\n\n\nfun foo(a: (Int) -> Unit) {\n   listOf(1, 2, 3).forEach(a)\n}\nClass-based lambda:\nfinal class org/example/project/MainKt$bar$1 extends kotlin/jvm/internal/Lambda implements kotlin/jvm/functions/Function1 {\n   // access flags 0x0\n   <init>()V\n           L0\n   ALOAD 0\n   ICONST_1\n   INVOKESPECIAL kotlin/jvm/internal/Lambda.<init> (I)V\n   RETURN\n\n\n   // access flags 0x11\n   public final invoke(I)V\n   GETSTATIC java/lang/System.out : Ljava/io/PrintStream;\n   ILOAD 1\n   INVOKEVIRTUAL java/io/PrintStream.println (I)V\n   RETURN\n}\nIndy lambda:\npublic final static bar()V\nINVOKEDYNAMIC invoke()Lkotlin/jvm/functions/Function1; [\n// handle kind 0x6 : INVOKESTATIC\njava/lang/invoke/LambdaMetafactory.metafactory(Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite;\n// arguments:\n(Ljava/lang/Object;)Ljava/lang/Object;,\n// handle kind 0x6 : INVOKESTATIC\norg/example/project/MainKt.bar$lambda$0(I)Lkotlin/Unit;,\n(Ljava/lang/Integer;)Lkotlin/Unit;\n]\nINVOKESTATIC org/example/project/MainKt.foo (Lkotlin/jvm/functions/Function1;)V\nRETURN\n\n\nprivate final static bar$lambda$0(I)Lkotlin/Unit;\nGETSTATIC java/lang/System.out : Ljava/io/PrintStream;\nILOAD 0\nINVOKEVIRTUAL java/io/PrintStream.println (I)V\nGETSTATIC kotlin/Unit.INSTANCE : Lkotlin/Unit;\nARETURN\nComposableSingleton classes\nCompose attempts to emit every composable lambda function as a singleton, meaning there is only one instance of that lambda function in existence. Therefore, it compiles all the composable lambdas as classes with a ComposableSingleton prefix in their names. Before Kotlin 2.1.20, the Compose compiler traversed nested functions using depth-first search and assigned each lambda class a unique name just using a counter. \nThe problem, however, arises when we introduce changes to the original code:\n\n\n\n\nAs you can see, just by adding a single new call to Surface, we caused two significant changes:\nEach lambda class changed, because adding a new lambda at the bottom of the tree caused all the lambda classes in the file to be renamed.\nThe class named ComposableSingleton$AppKt$lambda-0 changed its interface from Function3 to Function2, which causes an error in the JetBrains Runtime during reload, as before version 21.0.8, the JetBrains Runtime did not support changes to class interfaces.\nObviously, these kinds of dramatic bytecode changes are not good when hot reloading. Therefore, we changed how the Compose compiler generates names for composable singleton lambdas. Starting from version 2.1.20, the Compose compiler uses group keys as a stable, unique name for composable lambdas:\n\n\n\n\nThis change ensures that changes to composable lambdas do not cause errors or excessive invalidations in Compose Hot Reload.\nIndy lambdas\nWe encountered similar problems with the names generated for indy lambdas by the Kotlin compiler: Adding a nested lambda anywhere in the code renames all other lambdas.\n\n\n\n\nThis issue leads to the same problems as we observed with ComposableSingletons. However, this issue was reinforced by the fact that it affects all lambdas in the code, and Kotlin switched to indy lambdas by default in 2.0.0.\nTo solve this problem, we have changed the Kotlin compiler. As of Kotlin 2.2.20, indices for indy lambda names are unique for each scope they appear in. This guarantees that:\nRandom changes at the beginning of the file will not affect lambda names at the end of the file.\nAdding nested lambdas will not affect all the other lambdas declared in the class.\n\n\n\n\nFunctionKeyMeta annotations\nThe whole functionality of Compose Hot Reload relies on the fact that we can extract information about Compose from the bytecode. However, consider this example:\n@Composable\nfun App() {\n   Button(onClick = { }) {\n       Text(\"Click me!!!\")\n   }\n}\nThe lambda, passed to a Button call, only creates a single text field and does not create any new Compose groups. The (decompiled) bytecode of this lambda function looks like this:\nfinal class ComposableSingletons$AppKt$lambda$-794152384$1 implements Function3<RowScope, Composer, Integer, Unit> {\n\n\n   @FunctionKeyMeta(\n       key = -794152384,\n       startOffset = 568,\n       endOffset = 603\n   )\n   @Composable\n   public final void invoke(RowScope $this$Button, Composer $composer, int $changed) {\n       Intrinsics.checkNotNullParameter($this$Button, \"$this$Button\");\n       ComposerKt.sourceInformation($composer, \"C17@578L19:App.kt\");\n       if ($composer.shouldExecute(($changed & 17) != 16, $changed & 1)) {\n       if (ComposerKt.isTraceInProgress()) {\n           ComposerKt.traceEventStart(-794152384, $changed, -1, \"ComposableSingletons$AppKt.lambda$-794152384.<anonymous> (App.kt:17)\");\n       }\n\n\n       TextKt.Text--4IGK_g(\"Click me!!!\", (Modifier)null, 0L, 0L, (FontStyle)null, (FontWeight)null, (FontFamily)null, 0L, (TextDecoration)null, (TextAlign)null, 0L, 0, false, 0, 0, (Function1)null, (TextStyle)null, $composer, 6, 0, 131070);\n       if (ComposerKt.isTraceInProgress()) {\n           ComposerKt.traceEventEnd();\n       }\n   } else {\n       $composer.skipToGroupEnd();\n   }\n   }\n}\nAs you may notice, the source code of the invoke function does not contain any calls to startGroup or endGroup methods, and we can’t reliably extract the group information from it. The only way to access it is to read the FunctionKeyMeta annotation. This is a special annotation emitted by the Compose compiler that is intended to be used by tooling. \nHowever, before version 2.1.20, there was no way to generate FunctionKeyMeta annotations on composable functions, and there was no way to infer the group key from the bytecode of the compiled composable lambdas. We introduced this option in Kotlin 2.1.20 (which is why it is the required version of Kotlin if you want to use Compose Hot Reload) and enabled it by default in Kotlin 2.2.0.\nLifting the limits of the JetBrains Runtime\nWith the compiler tamed to emit bytecode that can be reloaded, another set of potential issues needs to be solved. One such issue surfaced very early in our testing. What should happen to the state that was statically initialized? The state in question here is not a UI state, stored by Compose, but static values, such as top-level properties. Take a look at the following test, which failed in early versions of Compose Hot Reload.\n\n\n\n\nThe test first defines an enum with the cases A, B, and C, then compiles and reloads the enum definition so that it also contains the case D. This failure is due to the EnumCases.entries being stored statically on the enum class. Once this collection is initialized, reloading this code will not magically cause its state to change to include the new case. Similarly, any other top-level property or static value would not change.\nThis is analogous to managing the state within the Compose framework, which means the same problems need to be solved. \nWe still need a way to reinitialize static values, and we need to know when to do so. This time around, we can answer the question of when to do so much more easily: Our bytecode analysis engine is perfectly capable of finding which functions and properties are considered dirty. However, reinitializing static fields is not as straightforward as calling a function. First, many static fields are also declared as final; re-assigning values cannot be done by calling a given function again, as it would require reflection. Second, the code that initializes statics lives inside a function called clinit. This function cannot be simply invoked, as it’s supposed to be invoked during class loading by the JVM itself. The problem requires transforming the code of .class files that will subsequently be reloaded. The transformation removes all final modifiers from static fields and copies the body of the clinit function to a new, synthetic $chr$clinit function (where chr is short for Compose Hot Reload). When reloading, the clinit method of several classes can be marked as dirty. We enqueue those classes for reinitialization and call them in topological order, according to their dependencies.\n\n\n\n\nWhen this project started, one of the stated limitations of the JetBrains Runtime was that reloads were rejected if either the superclass or any of a class’s interfaces changed while the class had active instances. Since some Kotlin lambdas still compile to abstract classes that implement Function1, Function2, and other interfaces, the limitation prevented some valid user code from reloading. We were able to produce lambda class names that were unique in Compose and much more tame outside of Compose, but users could occasionally encounter this limitation. We’re happy to announce that the team working on the JetBrains Runtime, especially Vladimir Dvorak, has lifted the restriction on changing interfaces and is now working on changing superclasses as well.\nThe orchestration protocol\nWe have previously seen that different processes need to communicate with each other. There are two concepts we can deduce from the required communication:\nEvents: Single-shot pieces of data (something that happened to which other parts of the system can react).\nStates: Current statuses of different Compose Hot Reload components that are continuously updated and available across the entire orchestration. For example, the ReloadState can either be Ok, Reloading, or Failed. This is not just a single event, but a universal state that each component can interact with. You can see that this ReloadState will be displayed in the application, the floating toolbar, and the IDE. \nTypically, such communication patterns can be modelled using higher-level abstractions, such as HTTP, and many would think that Ktor, or kotlinx.rpc might be fitting technologies. We, however, believe that technologies like Compose Hot Reload need to prioritize compatibility over our own developer experience. Using external libraries inside our devtools application is not a problem, but the communication with the user application requires code to run inside the user’s application, and polluting the user’s classpath might lead to frustrating compatibility issues. Shading such libraries can work, but most of those libraries would require kotlinx.coroutines. While kotlinx.coroutines can be shaded, it is designed to be a system-level library, and we would like to keep it this way.\nTherefore, we opted to implement all of the server/client code without any external dependencies. To model async code accurately, we even implemented a tiny coroutines runtime that allows launching tasks, switching threads, offering a Queue option (analogous to a Channel in kotlinx.coroutines), and more. \nThe key aspect of this protocol is that it is both forward- and backwards-compatible. This bi-directional compatibility is verified by running tests in a special way, but we’ll go into more detail on that later.\nDefining a state within a single process is hard enough to get right, but defining it across multiple processes raises the question of how to implement it safely. State updates in Compose Hot Reload are defined atomically and are done through an atomic update function. This means that racing threads, even racing processes, will be able to conveniently update a given state while using a pattern that is widely adopted by application developers:\n\n\n\n\nThe provided update function ensures atomic updates to the state. Like an AtomicReference or a MutableSharedFlow, this update function might be called multiple times if proposed updates are rejected. To enable such atomic updates across numerous processes, the OrchestrationServer acts as the source of truth: Any participant trying to update the state will send binary Update requests to the server. These requests will contain the binary (serialized) form of the expected state and the binary form of the updated state. \nThe server processes all requests in a single Queue. If the expected binary matches, the update gets accepted, and the updated state binary is distributed to all clients. If many threads or processes are racing to update a given state value, the expected binary representation might have changed so that it no longer matches the update request. Such updates will be rejected; the client will receive the new underlying state value, call the update function again, and send a new update request.\n\n\n\n\nFast visual feedback\nWe’ve now covered the internal workings of Compose Hot Reload. But as interesting as all that is, in our opinion, fast visual feedback is the most important part of the hot reload experience. So, how can we provide this feedback, and more importantly, share it across different processes? Well, the key to doing this is the states that are shared between all processes via the orchestration protocol. The hot-reload-devtooling-api module introduces them:\nWindowsState. By hooking into the user application process and intercepting all the ComposeWindow.setContent invocations, we can keep track of all the windows created by the user application. Each window is assigned a unique windowId, and we keep information about the current position of all windows.\npublic class WindowsState(\n   public val windows: Map<WindowId, WindowState>\n) : OrchestrationState {\n   public class WindowState(\n       public val x: Int,\n       public val y: Int,\n       public val width: Int,\n       public val height: Int,\n       public val isAlwaysOnTop: Boolean\n   )\n}\nReloadState. ReloadState keeps track of the current reload status. Basically, it tracks all orchestration messages and updates the state based on reload, recompile, or build status messages exchanged between the processes. \npublic sealed class ReloadState : OrchestrationState {\n   public abstract val time: Instant\n\n\n   public class Ok(\n       override val time: Instant,\n   ) : ReloadState()\n\n\n   public class Reloading(\n       override val time: Instant,\n       public val reloadRequestId: OrchestrationMessageId?\n   ) : ReloadState() {\n\n\n   public class Failed(\n       override val time: Instant,\n       public val reason: String,\n   ) : ReloadState()\n}\nReloadCountState. In addition to the reload state, it is also nice to keep track of the history of reload attempts. Working on the UI of your application and seeing that you have iterated on it over 30 times already is a very inspiring feeling!\npublic class ReloadCountState(\n   \t    public val successfulReloads: Int = 0,\n   \t    public val failedReloads: Int = 0\n) : OrchestrationState\nAs we mentioned before, all these states are shared between the processes. So if you feel like it, you can actually create your own UI tooling for Compose Hot Reload! \nIn-app effects\nThe Compose Hot Reload agent hooks to the user application process and intercepts Compose calls that initialize the window: ComposeWindow.setContent and ComposeDialog.setContent. To be more precise, we don’t just intercept these calls; we actually replace them with our own implementation that wraps the user content into a special DevelopmentEntryPoint function.\n@Composable\npublic fun DevelopmentEntryPoint(\n   window: Window,\n   child: @Composable () -> Unit\n) {\n   startWindowManager(window)\n   val currentHotReloadState by hotReloadState.collectAsState()\n\n\n   CompositionLocalProvider(hotReloadStateLocal provides currentHotReloadState) {\n       key(currentHotReloadState.key) {\n           when {\n               reloadEffectsEnabled -> ReloadEffects(child)\n               else -> child()\n           }\n       }\n   }\n}\nThis is a very high-level implementation of the DevelopmentEntryPoint. As you can see, it provides us with three key features:\nWe start a window manager that updates the WindowState of the current window.\nWe wrap the user app’s contents in a separate scope guarded by a special hot-reload state. If we ever want to reset the user application’s UI state, we can do so by resetting the hot-reload state.\nWe wrap the user content into the ReloadEffects function, which renders all in-app effects based on the shared states.\nFloating toolbar\nThe floating toolbar, or the Compose Hot Reload Dev tools window, is a separate process that starts together with the user application and connects to the orchestration. Then, it just tracks the WindowsState, and launches a new toolbar for each window of the user application. The toolbar just tracks the target window’s state and updates its position accordingly.\nThe toolbar also contains action buttons that control the user application: Reload UI, Reset UI, and Shutdown. These actions are implemented via the orchestration protocol as well: Clicking a button just triggers a corresponding orchestration message to be sent to all connected processes. Each process then knows how to handle received commands.\n\n\n\n\nIDE integration\nIDE support for Compose Hot Reload is implemented in the Kotlin Multiplatform plugin. When you open a Kotlin Multiplatform project in your IDE, the KMP plugin checks whether the Compose Hot Reload plugin is applied to the project. If it is, the KMP plugin also checks the versions for compatibility (IDEs support Compose Hot Reload versions from 1.0.0-beta07 onward). Via IDE integration with the build systems, the KMP plugin can extract all the information needed to run the app in hot-reload mode. And when you click on the Run button in the gutter next to main, the KMP plugin automatically generates a new run configuration with hot reload enabled.\n\n\n\n\nEverything else works very similarly to the Dev tools window. The KMP plugin connects to the orchestration server of the running application and displays information about the app’s current state: logs, reload status, errors, etc.\nTesting\nThis project required the team to think about many components across the entire Kotlin and JetBrains technology stack, and we have spent a lot of time debugging, experimenting, and writing production code. We would like to claim that most of our time was spent on our project infrastructure. However, we estimate that roughly 30% of all our commits were purely for introducing test infrastructure, highlighting how complicated testing a system that reloads code can be.\nHot-reload unit tests\nTests running assertions within the JVM that reload code are called hot-reload unit tests. An example of such a test case was shown earlier in this blog post.\n\n\n\n\nThe tests here can define code of interest right next to the actual test function. But the real magic happens when calling the compileAndReload method. \nThis method allows us to compile the provided source code within the current process and reload it. Once this compileAndReload method finishes, we can safely assume the new code is available and begin to write assertions. The example above shows a test that defines an enum with three cases. After reloading the enum with one case added, we can safely assert that the .entries property contains the newly added case. This test suite implements a custom test executor for Gradle, which launches each test case in a fresh JetBrains Runtime with hot reload enabled and provides a Kotlin compiler for the compileAndReload function. We used such tests in cases where reloading either crashed or had some issues, as mentioned previously (reinitializing statics).\nHotReloadTestFixture: Orchestration-based tests\nSince this project integrates into many other systems, having a heavier, end-to-end test fixture at our disposal seems natural. Similar to how Gradle plugins would write Gradle integration tests using Gradle-specific fixtures, we have implemented a HotReloadTestFixture that launches actual applications with Gradle in hot-reload mode and communicates with Gradle and the application using the previously mentioned orchestration protocol. Such tests were implemented to cover the integration with the JDWP commands for reloading and testing generic Gradle tasks, but they were also very useful for building screenshot tests:\n\n\n\n\nJust as unit tests do, orchestration-based tests have a convenient way to replace code, thanks to the HotReloadTestFixture; however, this test fixture actually changes source code on disk and thus relies on the entire Gradle/Compose Hot Reload machinery to pick the change up correctly, issue the reload request, and perform other relevant actions, right up until Compose actually updates the UI. After that, the test then takes a screenshot. We have many tests that ensure, through screenshots, that the code change was handled properly, i.e. that only the corresponding state was reset and the UI picked up the changes.\nTesting the backwards and forwards compatibility of the orchestration protocol\nAs we mentioned before, compatibility is one of the key properties of the orchestration protocol. For example, the IDE might have a different client version bundled compared to the server version hosted by the application. \nSuch compatibility tests typically define a communication flow between a server and a client. Let’s say the client connects, the server sends a message Foo, and the client responds with Bar. Now, to test the compatibility, this flow will be separated into two parts: \nThe first part is called main, which contains one side of the communication (e.g. the server’s) and runs with the currently compiled version of the code. The second part is called Isolate, and this code will be running in a separate process, launched with the previous JARs of the protocol.\n\n\n\n\nThe Isolate class can be defined right next to the test function, making it easy to write compatibility test cases where both ends of the communication are close together. Still, only one will be launched in isolation, running the test against many different, previously released versions of Compose Hot Reload.\nContinuing the journey\nCompose Hot Reload is a very complex technical project, and we are proud of the engineering work behind it. We tried to highlight what we consider the most interesting aspects of Compose Hot Reload in this blog post. But if you are interested in learning more about the project, check out our GitHub repository. And don’t hesitate to create new issues or discussions if you have any questions or ideas.\nCompose Hot Reload version 1.0.0 is bundled automatically with the latest Compose Multiplatform 1.10 release. But we are continuing to work on improving both the IDE experience and the underlying technology. So check out our latest releases and share your feedback!",
        "dc:creator": "Sebastian Sellmair",
        "content": "Compose Hot Reload has just been promoted to stable with our 1.0.0 release. We worked hard to build a technology that is easy to use and well-integrated into existing tools while also requiring zero configuration from users. The tool is bundled with Compose Multiplatform, starting from version 1.10 (see our dedicated release blog post). While [&#8230;]",
        "contentSnippet": "Compose Hot Reload has just been promoted to stable with our 1.0.0 release. We worked hard to build a technology that is easy to use and well-integrated into existing tools while also requiring zero configuration from users. The tool is bundled with Compose Multiplatform, starting from version 1.10 (see our dedicated release blog post). While […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=673207",
        "categories": [
          "multiplatform",
          "compose-hot-reload",
          "compose-multiplatform"
        ],
        "isoDate": "2026-01-13T14:47:58.000Z"
      },
      {
        "creator": "Oleg Zinovyev",
        "title": "What’s Next for CLion: The 2026.1 Roadmap",
        "link": "https://blog.jetbrains.com/clion/2026/01/2026-1-roadmap/",
        "pubDate": "Tue, 13 Jan 2026 09:21:09 +0000",
        "content:encodedSnippet": "We’re now working on our next major release, which we plan to deliver in March. In our latest stable version (v2025.3), we introduced many features and enhancements, so for the next release, we’ve decided to focus on maintenance and bug fixes rather than introducing new functionality. With that in mind, we’ve prioritized the following areas for v2026.1:\nLanguage support\nBuild tools and project formats\nFeatures for embedded development\nDebugging\n\n\n\n\nRead on to learn more about our planned updates.\nOur team is committed to creating an IDE that makes development smooth and productive. However, the following is only a preliminary roadmap. We can’t guarantee that all of the issues and features listed below will be addressed and implemented in CLion 2026.1. Unexpected circumstances could require us to modify our plans or implementation timelines for some items.\nLanguage support\nFor CLion’s language support, we plan to concentrate on improving the coding experience, refining compile-time debugging capabilities, and updating testing framework integration.\nLanguage and editor features\nThe CLion Nova language engine powers all of the recent performance and accuracy improvements in CLion. In v2025.3, this engine has become the default for all users, replacing the legacy CLion Classic engine.\nWhile we’re not aiming for complete feature parity between CLion Nova and CLion Classic, we remain committed to implementing the most popular features from the legacy engine. Here’s what we’re adding in this release:\nSupport for Clang blocks (CPP-37839): This non-standard extension provides a lambda-like syntax for creating closures in C and C++. It’s useful for writing concise, type-safe, and context-aware callbacks or asynchronous code.\nSupport for GCC nested functions (RSCPP-35876): This GCC extension lets you define a function inside another function, with the inner function accessible only within the outer function’s scope. This is particularly valuable in embedded systems, where it can help users optimize code and better manage limited resources.\nCode folding improvements: CLion automatically recognizes certain code structures and allows you to fold them. In v2026.1, we plan to support additional code structure types and regions that you can fold to help you better organize your code.\nGo to Usages and Go to Declaration popup improvements (CPP-45132, CPP-46560): We want to address several UX issues with this popup, such as displaying unnecessary information and unintuitive grouping of a function’s declaration and usages.\nConstexpr Debugger improvements\nIn v2025.3, we introduced the Constexpr Debugger, a tool that enables compile-time debugging of constexpr and consteval code, which is hard or impossible to debug at runtime. We’ll continue to refine the Constexpr Debugger and fix bugs in the next release.\nUpdates to unit testing frameworks\nCLion supports multiple unit test frameworks, such as GoogleTest, Catch2, Boost.Test, and doctest. In v2026.1, we plan to revise our support for these frameworks and update it where necessary – for example, by adding support for the latest framework features or removing obsolete ones.\nWe also plan to make unit test integration independent of the CMake project format. This will allow other project formats, like Meson (CPP-35147) or the JSON compilation database, to utilize the comprehensive test functionality that is currently available only for CMake projects.\nBuild tools and project formats\nHere, we’ll focus on enhancing Bazel support with new tools, optimizing the CLion update process, and expanding code insight capabilities for complex embedded projects.\nBazel support improvements\nLast year, we took over the development of the Bazel for CLion plugin from Google and have since continued to improve its stability and user experience. For the upcoming release, we plan to add support for several new Bazel features and tools, including:\nStarlark REPL: Bazel includes an official read-eval-print loop (REPL) for the Starlark language, allowing you to explore its semantics. We plan to bundle the REPL and offer a dedicated, interactive shell session directly within the IDE, facilitating easy experimentation with Starlark.\nExeclog parser: Bazel’s build execution logs, for example, generated by using \nthe --execution_log_compact_file flag, are a valuable resource for advanced build analysis and debugging performance issues. We’ll integrate the Bazel execution log parser, which will let you easily parse these logs and diff two log files simultaneously.\nConfiguration transitions: Transitions are a powerful Bazel feature that allows you to compile C and C++ projects for multiple architectures simultaneously. Currently, our plugin only supports the default configuration. If your project uses configuration transitions, the plugin ignores them, and it’s not possible to see code insight for different configurations. We plan to add full support for transitions so you can get accurate code insight for all configurations in your project.\nPerformance improvements: We continually work to enhance the plugin’s performance and will make related updates in v2026.1. One example is the header cache, which is used for headers generated during the build process or those from virtual include paths. This cache stores headers in a format optimized for CLion, improving overall performance.\n\n\n\n\nAdditionally, our plugin is already compatible with Bazel 9.\nFor more details on recent Bazel updates and announcements, check out our BazelCon 2025 recap.\nAccelerating CLion updates on Windows\nSome Windows users have reported that CLion updates take too long. To address this, we plan to remove unnecessary components and optimize packaging in the installer. This will reduce the installer size and speed up the updates for Windows and other supported operating systems.\nConfiguration profiles for West projects\nWe plan to add the ability to create configuration profiles for West projects, similar to CMake profiles (CPP-42799). This will streamline working with multiple build configurations that use different build parameters or target different boards, making it easy to switch between configurations on the fly.\nCode insight features for external projects\nProjects in popular embedded frameworks, such as West, STM32, and ESP-IDF, are often divided into multiple parts. Some of these parts may be external projects with respect to the primary project. These external projects are listed in the CMake ExternalProject_Add() section. For example, in a dual-core setup, one application acts as the primary application (a primary project), while the other one runs on the coprocessor and is responsible only for communication (an external project). Similarly, when using Arm® TrustZone® technology or a bootloader, one application may have elevated privileges, while the other retains regular privileges. An external project may also contain system dependencies used only for building.\nThese external projects would benefit from having the same code insight features as the primary project, such as error detection, warnings, search for usages, and refactoring. Currently, this is only possible if you load an external project as a separate project model, which can be unnecessary or cumbersome in many cases.\nWe want to generate a compile_commands.json file from an external project’s CMake configuration. This will enable you to load the external project as part of the primary CMake project and access code insight features, making it more convenient to work with complex, multi-part projects.\nUnbundling Cygwin\nWe plan to remove the pre-defined Cygwin setup from our list of default CLion toolchains and release it as a separate plugin. This plugin will be available to download from JetBrains Marketplace. There are two main reasons behind this decision:\nThe very low number of users.\nThe uncertainty of the Cygwin project’s future, especially since WSL can replace Cygwin in most cases.\n\n\n\n\nIf you use Cygwin in CLion and have concerns about this change, please comment below or contact our Support team. We’ll do our best to help you find a suitable solution.\nEmbedded development\nMost improvements in embedded development support will be related to live watches and debug servers.\nUpdates to live watches\nIn the latest release, live watches received several UX improvements, including the ability to export data in CSV format and view peripheral register values. For the upcoming release, we’ll continue refining the feature and fixing reported issues. To learn more about live watches, see our documentation.\nOpenOCD debug server\nWe’ve developed dedicated debug servers for different projects, such as STM32CubeMX and ESP-IDF, but not yet for OpenOCD. Although OpenOCD users can still use a generic debug server, this isn’t optimal. In the next release, we plan to add a dedicated debug server for OpenOCD, making it even more convenient to create and manage debug configurations for different targets.\nDebugger\nIn the last release, we introduced support for the Debug Adapter Protocol (DAP). This feature allows you to work with third-party debuggers that use DAP, expanding your options beyond LLDB and GDB.\nImproving the DAP integration will be our main priority in the debugger updates. We plan to address reported issues and add the ability to communicate with DAP servers via a TCP port (CPP-46675).\nConclusion\nThe Early Access Program is just around the corner and will give you the chance to try all of the new features planned for the next major release for free. In the meantime, upgrade to CLion 2025.3 if you haven’t already done so, and let us know what you think!\nDOWNLOAD CLION 2025.3",
        "dc:creator": "Oleg Zinovyev",
        "content": "We’re now working on our next major release, which we plan to deliver in March. In our latest stable version (v2025.3), we introduced many features and enhancements, so for the next release, we’ve decided to focus on maintenance and bug fixes rather than introducing new functionality. With that in mind, we’ve prioritized the following areas [&#8230;]",
        "contentSnippet": "We’re now working on our next major release, which we plan to deliver in March. In our latest stable version (v2025.3), we introduced many features and enhancements, so for the next release, we’ve decided to focus on maintenance and bug fixes rather than introducing new functionality. With that in mind, we’ve prioritized the following areas […]",
        "guid": "https://blog.jetbrains.com/?post_type=clion&p=670428",
        "categories": [
          "news",
          "roadmap",
          "bazel",
          "clionnova",
          "constexpr",
          "dap",
          "gcc",
          "live-watches"
        ],
        "isoDate": "2026-01-13T09:21:09.000Z"
      },
      {
        "creator": "Bruno Lannoo",
        "title": "Building AI Agents in Kotlin – Part 4: Delegation and Sub-Agents",
        "link": "https://blog.jetbrains.com/ai/2026/01/building-ai-agents-in-kotlin-part-4-delegation-and-sub-agents/",
        "pubDate": "Tue, 13 Jan 2026 08:27:09 +0000",
        "content:encodedSnippet": "Previously in this series:\nBuilding AI Agents in Kotlin – Part 1: A Minimal Coding Agent\nBuilding AI Agents in Kotlin – Part 2: A Deeper Dive Into Tools\nBuilding AI Agents in Kotlin – Part 3: Under Observation\nIn the previous installment, we saw how to set up tracing, which brings us to two new questions: What should we experiment with based on the information this tool provides? And what parts of our agent could we improve using its observations?\nThe first idea we had was to experiment with sub-agents, or more specifically, a find sub-agent. This will give us a chance to have a look at how Koog makes it easier to implement common patterns like sub-agents. Our hypothesis is that a find sub-agent might reduce overall cost while maintaining, or even improving, performance.\nWhy would we think that? Well, the main driver of cost is context growth. Each LLM request contains the full context from start to finish, which means each subsequent request is more expensive (at least in terms of input tokens) than the previous one. If we could limit context growth, especially early in the agent’s run, we might significantly reduce cost. An unnecessarily large context could also distract the agent from its core task. Therefore, by narrowing the context, we might even see a performance improvement, though that’s harder to predict.\nThe find functionality is particularly suited for removal from the long-term context. When searching for something, you typically open many files that don’t contain your target. Remembering those dead ends isn’t useful. Remembering what you actually found is. You could think of this as a natural way of compressing the agent’s history (we’ll look at actual compression in a later article).\nThis task is also a good candidate for a sub-agent because it’s relatively simple. That simplicity means we could also make use of the sub-agent’s ability to use a different LLM model. In this case, a faster and cheaper one. This offers flexibility that regular compression doesn’t.\nOf course, we could have built a traditional procedural tool to do this. In fact, we did build one called RegexSearchTool, but for the purposes of this experiment, we put it inside the find agent rather than directly in the main agent. This approach provides us with flexibility in terms of model choice while also incorporating an extra layer of intelligence.\nThe find agent\nTo be able to have a sub-agent pattern, we first need a second agent. We’ve already covered agent creation in depth in Part 1 of the series, so we won’t spend much time on this now. However, a few details are still worth noting.\nFirst, a minor point: We’re using GPT4.1 Mini for this sub-agent because its task is much simpler and doesn’t require a model as capable as the one used by the main agent.\nSecond, it’s useful to look at which tools this agent can access. Like the main agent, it has access to the ListDirectoryTool and ReadFileTool, but not the EditFileTool or ExecuteShellCommandTool. We’ve also given it access to the new procedural search tool we mentioned above, RegexSearchTool, which allows us to search a comprehensive range of files inside a folder and its subfolders using a regex pattern.\nToolRegistry {\n    tool(ListDirectoryTool(JVMFileSystemProvider.ReadOnly))\n    tool(ReadFileTool(JVMFileSystemProvider.ReadOnly))\n    tool(RegexSearchTool(JVMFileSystemProvider.ReadOnly))\n}\nFor more detailed information, check out the full implementation here.\nBuilding a find sub-agent\n\n\n\n\nFirst things first – what is a sub-agent? A sub-agent is really quite simple; it is an agent that is being controlled by another agent. In this specific case, we are working with the agent-as-a-tool sub-agent pattern, where the sub-agent is running inside a tool that is provided to the main agent.\nCreating a sub-agent turns out to be straightforward. We know a tool is essentially a function paired with descriptors that the agent can read to understand when and how to call it. We could simply define a tool whose .execute() function calls our sub-agent. But Koog provides tools to remove even this boilerplate:\nfun createFindAgentTool(): Tool<*, *> {\n    return AIAgentService\n        .fromAgent(findAgent as GraphAIAgent<String, String>)\n        .createAgentTool<String, String>(\n            agentName = \"__find_in_codebase_agent__\",\n            agentDescription = \"\"\"\n                <when to call your agent>\n            \"\"\".trimIndent(),\n            inputDescription = \"\"\"\n                <how to call your agent>\n            \"\"\".trimIndent()\n        )\n}\nYou could think of this as roughly equivalent to:\npublic class FindAgentTool(): Tool<FindAgentTool.Args, FindAgentTool.Result>() {\n   override val name: String = \"__find_in_codebase_agent__\"\n   override val description: String = \"\"\"\n      <when to call your agent>\n   \"\"\"\n   @Serializable\n   public data class Args(\n      @property: LLMDescription(\n         \"\"\"\n            <how to call your agent>\n         \"\"\"\n      )\n      val input: String\n   )\n   @Serializable\n   public data class Result(\n\tval output: String\n   )\n   override suspend fun execute(args: Args): Result = when {\n      output = findAgent.run(args.input)\n      Result(output)\n   }\n}\nIn either case, the only things we need to do are: \nCreate our sub-agent.\nGive it an agentName.\nSpecify when to call the agent through the agentDescription prompt.\nSpecify how to call the agent through the inputDescription prompt.\nThe prompts are, perhaps, the trickiest part. There’s plenty of room for fine-tuning. But there’s some indication that newer LLMs need less precisely tuned prompts, so perfectly fine-tuned prompts may not be worth our time. We’re still exploring this topic ourselves, and it will take more experimentation to really come to a strong conclusion.\nOne thing we did notice is that, if we’re not careful with the prompts, the main agent sometimes confuses the find agent with a simple Ctrl+F / ⌘F function, sending only the tokens it wants to search for. That’s clearly suboptimal. With so little context, the find agent can’t reason about what it should actually be looking for. To address this, we include instructions requiring the main agent to specify why it’s looking for something. That way, the find agent can fully leverage its intelligence to find the actual thing the main agent is looking for.\n\"\"\"\nThis tool is powered by an intelligent micro agent that analyzes and understands code context to find specific elements in your codebase.\nUnlike simple text search (Ctrl+F / ⌘F), it intelligently interprets your query to locate classes, functions, variables, or files that best match your intent.\nIt requires a detailed query describing what to search for, why you need this information, and an absolute path defining the search scope.\n...\n\"\"\"\n\nQuery WITH highlighting (not Ctrl+F /⌘F)Query WITHOUT highlighting (not Ctrl+F /⌘F)\n\nSearch for changes in get_search_results regarding unnecessary joins to see if there are comment or logic on unnecessary joins.get_search_results\nSearch for environment variable usage with SKLEARN_ALLOW or similar in repository to find potential bypass of check_build.SKLEARN_ALLOW\n\n\n\n\n\nWe also noticed that the main agent sometimes still chooses to call the shell tool with a grep command instead of the find agent, which undermines the entire purpose of having a dedicated sub-agent. To avoid this pattern, we added this section to the main system prompt in order to push it harder:\n\"\"\"\n...\nYou also have an intelligent find micro agent at your disposal,\nwhich can help you find code components and other constructs more\ncheaply than you can yourself. Lean on it for any and all\nsearch operations. Do not use shell execution for find tasks.\n...\n\"\"\"\nWe also took some lessons from years of IDE development. When you search in your IDE, you don’t just get file paths and line numbers. You get snippets of the code around each match. This helps you quickly determine whether that’s actually what you were looking for without opening every file.\nWe wanted to create a similar experience for the main agent, which is why we prompt the find sub-agent to include snippets in its results:\n\"\"\"\n...\nPrioritize accuracy and relevance in your search results.\n* For each result, provide a clear and concise explanation of why it was selected.\n* The explanation should state the specific criteria that led to its selection.\n* If the match is partial or inferred, clearly state the limitations and potential inaccuracies.\n* Include only relevant snippets in the results.\n...\nThis way, the main agent gets the same rich context we get as engineers, without needing to read through entire files just to verify it found the right thing.\nThis is the “natural compression” we mentioned in the opening. The find agent opens many files, follows dead ends, and explores the codebase. But the main agent only sees the results: relevant file paths, snippets, and explanations. All that exploration stays in the find agent’s context and disappears after it returns. Only the stuff that really mattered is then added to the main agent’s context.\nThe trade-offs\nUsing a sub-agent has its benefits, but it also has downsides. This is certainly the kind of change that warrants experimentation to show whether it delivers the benefits we’re hoping for without too many sacrifices.\nThe first trade-off is cost and time. While shortening the context in the main thread helps bring down the cost and time there, we now also have to pay and wait for a number of LLM calls in the sub-agent. The hope is that the total cost and time spent are less, but that depends on how the main agent uses the sub-agent. If it ends up doing a large number of small queries, that benefit might not materialize. We will look at the costs when we run the benchmarks again in a later section, and we will just assume that cost and time are correlated.\nWe did notice this happening in some of our runs, so we added a segment to the tool’s agentDescription that explains the issue to the main agent and tries to limit the frequency of such high volumes of small queries:\n\"\"\"\n...\nWhile this agent is much more cost efficient at executing searches than using shell commands, it does lose context in between searches. So give preference to clustering similar searches in one call rather than doing multiple calls to this tool.\n...\n\"\"\"\n\n\n\n\nA second trade-off is that this approach treats context retention in a far more black-and-white way than humans do. We may not pull everything that happened in the past into active memory, but we do keep vague impressions of what happened and can retrieve additional context when needed. There are ways to model this kind of behavior, but they are far beyond the scope of the current iteration of our agent and are more related to the deep and complex subject of agentic memory.\nAnother challenge is that it creates more complexity in tracing. In Langfuse, we no longer only have to look at the trace of just one agent. Indeed, we might even need to look at the behavior from multiple perspectives – both the full view and each agent separately.\nThink wider: The engineering team analogy\nThis technique of using sub-agents isn’t limited to simple cases like the find agent. You could, for example, replicate the separation of concerns in team structures by assigning analysis, implementation, testing, and planning to different sub-agents. \nIt’s still an open question whether an agent with all these capabilities does better or worse than a system where such capabilities are divided among sub-agents, but it’s not hard to imagine potential benefits. Think of Conway’s law: “Organizations design systems that mirror their communication structure.” One interpretation is that these communication structures evolved to discover efficient patterns worth keeping. The reverse Conway maneuver even suggests this is desirable.\nCould the same be true for role distribution? Maybe the division of tasks across different specializations in software teams also evolved to discover efficient ways of working. Maybe LLMs could benefit from that, too.\nYet this is not guaranteed. The efficiencies might stem largely from spreading the human learning processes, and this might not apply to LLMs. But in the book Clean Code, we read about wearing different hats: a writer hat (creator), a reader hat (maintainer), and a tester hat (tester). The idea is to focus on one role without being distracted by the perspectives of the others. This suggests task division goes deeper than just learning efficiency, meaning it might indeed be relevant to LLMs.\n\n\n\n\nAll of this is to say that you can take sub-agents a lot further, but whether this is a beneficial approach is still unproven. It’s still an art form for now, not a hard science.\nBenchmark results: Testing the hypothesis\nWe’re happy to report that our version without the find sub-agent shows a cost of about $814, or $1.63 per instance, while our version with this sub-agent shows a cost of about $733, or $1.47 per instance. That’s a 10% cost saving, which is definitely worth noting.\nOne interesting observation is how strongly the results depend on the choice of LLM for the sub-agent. In a smaller experiment, we tried keeping our sub-agent connected to GPT-5 Codex, and that dramatically increased the cost to $3.30 per example, averaged over 50 examples.\n\nExperimentSuccess rateCost per instance\nPart 03 (Langfuse)56% (278/500)$1.63 ($814/500)\nPart 04 (sub-agent GPT4.1 mini)58% (290/500)$1.47 ($733/500) \nPart 04 (sub-agent GPT-5 Codex)58% (29/50)$3.30 ($165/50)\n\n\n\n\n\nHowever, it is interesting to note that we hypothesized two ways to reduce cost. The first was shrinking the context size through the natural compression achieved by task handoffs, and the second was offloading work to a cheaper model. The data suggests that just splitting off a sub-agent (and keeping the GPT-5 Codex model) actually increases the cost significantly, so our first method doesn’t seem to work, while our second (cheaper models) is the one that seems to do the trick – though this may not be rigorous proof.\nAs for performance improvements, we see a small uptick from 56% to 58%. This could be within the tolerance of statistical variance, but it’s encouraging that performance at least stayed consistent while we reduced costs.\nConclusion\nWe’ve seen that creating sub-agents is both simple and potentially powerful. Koog provides convenient tooling to streamline the process even further, leaving only the prompts for the agent-as-a-tool for you to define.\nThis technique clearly delivers worthwhile cost savings. We achieved nearly a 10% reduction – a clear, measurable improvement. The performance impact is less clear, but it does look like it might be some gains there, too.\nAt the same time, these kinds of evaluations are expensive. Even with reduced costs, this benchmark still totaled $730. That’s why, in the next part, we will take a closer look at another strategy for lowering costs: a more general approach to compression. In it, we’ll answer the question, “How do you prevent your context from growing indefinitely, and your costs growing with it?”",
        "dc:creator": "Bruno Lannoo",
        "content": "Previously in this series: In the previous installment, we saw how to set up tracing, which brings us to two new questions: What should we experiment with based on the information this tool provides? And what parts of our agent could we improve using its observations? The first idea we had was to experiment with [&#8230;]",
        "contentSnippet": "Previously in this series: In the previous installment, we saw how to set up tracing, which brings us to two new questions: What should we experiment with based on the information this tool provides? And what parts of our agent could we improve using its observations? The first idea we had was to experiment with […]",
        "guid": "https://blog.jetbrains.com/?post_type=ai&p=672689",
        "categories": [
          "kotlin",
          "tutorials",
          "ai",
          "ai-agents"
        ],
        "isoDate": "2026-01-13T08:27:09.000Z"
      },
      {
        "creator": "Ksenia Shneyveys",
        "title": "Advent of Code 2025 in Kotlin: Puzzles, Prizes, and Community",
        "link": "https://blog.jetbrains.com/kotlin/2026/01/advent-of-code-2025-in-kotlin/",
        "pubDate": "Mon, 12 Jan 2026 19:33:14 +0000",
        "content:encodedSnippet": "Thank you to everyone who participated in Advent of Code 2025 in Kotlin! Once again, it was a joy to see so many of you sharing solutions, cheering each other on in Slack, and keeping the holiday coding spirit alive.\nThis year, we kicked things off with five days of livestreams on December 1–5, with Sebastian Aigner and fantastic guests solving puzzles live, discussing strategies, and showing off idiomatic Kotlin approaches.\nIf you missed the streams or want to revisit a clever trick, you can still catch up with the recordings:\n\n\n\n\n\n\nCommunity\nThe Advent of Code puzzles remain available all year round, and so does the community energy. The #advent-of-code channel in the Kotlinlang Slack was once again full of:\nCreative Kotlin snippets\nNon-spoiler hints\nLots of encouragement\nWhether you took part in discussions every day or just lurked and learned, thank you for making the channel such a friendly, collaborative space.\nJoin the AoC channel in Slack\nWinners\nAs in previous years, we invited you to solve Advent of Code puzzles in Kotlin, join our Kotlin leaderboards, and share your solutions on GitHub with the aoc-2025-in-kotlin topic for a chance to win special Kotlin prizes.\nThis year, we’re celebrating nine winners across three categories: Fastest to Solve, Random, and Community.\nFastest to Solve\nThese three contestants topped the combined Kotlin leaderboards, consistently solving the puzzles at impressive speed:\nKroppeb\nAndrejStratmann\n770grappenmaker\n\n\n\n\n\nCongratulations on those lightning-fast stars and Kotlin-powered solutions!\nRandom winners\nTo give everyone a chance regardless of speed, we also randomly selected three prize winners from all the participants:\nlbcp\nFelixDombek\nbjdupuis\n\n\n\n\nIf you see your name here, keep an eye on your inbox. We’ll be in touch about your prize soon.\nCommunity winners\nFinally, Advent of Code in Kotlin wouldn’t be the same without the people who answer questions, share insights and alternative solutions, help newcomers get started, and keep the #advent-of-code channel buzzing throughout December.\nThis year, we’d like to give a special shout-out to these three community stars:\njakubgwozdz\nbj0\nephemient\n\n\n\n\n\nThank you for your team spirit in the Kotlin community!\nKeep learning and solving\nAdvent of Code might be over for this year, but the puzzles and the learning opportunities remain. If you’d like to keep sharpening your skills and prepare for future events, here are some resources:\nAdvent of Code 2025 in Kotlin YouTube playlist.\nSolutions to Advent of Code puzzles from previous years in idiomatic Kotlin.\nA tutorial on how to explore and solve programming puzzles using Kotlin Notebooks.\n\n\n\n\nWe want to say a huge thank-you, as always, to Eric Wastl and the Advent of Code team for creating such a beloved set of puzzles year after year.\nLet’s keep exploring Kotlin, solving algorithmic challenges, and supporting each other. We hope to see you for the next Advent of Code in Kotlin! 🎄",
        "dc:creator": "Ksenia Shneyveys",
        "content": "Thank you to everyone who participated in Advent of Code 2025 in Kotlin! Once again, it was a joy to see so many of you sharing solutions, cheering each other on in Slack, and keeping the holiday coding spirit alive. This year, we kicked things off with five days of livestreams on December 1–5, with [&#8230;]",
        "contentSnippet": "Thank you to everyone who participated in Advent of Code 2025 in Kotlin! Once again, it was a joy to see so many of you sharing solutions, cheering each other on in Slack, and keeping the holiday coding spirit alive. This year, we kicked things off with five days of livestreams on December 1–5, with […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=673883",
        "categories": [
          "education",
          "news",
          "advent-of-code",
          "aoc",
          "prizes"
        ],
        "isoDate": "2026-01-12T19:33:14.000Z"
      },
      {
        "creator": "Dmitrii Korovin",
        "title": "How to Troubleshoot Builds With TeamCity Dashboards",
        "link": "https://blog.jetbrains.com/teamcity/2026/01/how-to-troubleshoot-teamcity-builds-using-dashboards/",
        "pubDate": "Mon, 12 Jan 2026 17:16:46 +0000",
        "content:encodedSnippet": "This article was brought to you by Damaso Sanoja, draft.dev.\nIf you’re spending your mornings debugging Jenkins pipeline failures, waiting for builds that should take minutes but stretch into hours, or scrambling to identify which plugin update broke your deployment process, you’re not alone. These daily troubleshooting battles with legacy CI/CD systems drain engineering time that could be spent building features and delivering value.\nTeamCity’s built-in health signals help you address these everyday struggles head-on by surfacing the root causes of your pipeline problems before they escalate. Instead of hunting through logs to understand why builds fail, you get clear visibility into success rates, build duration trends, and bottleneck identification. When issues arise, comprehensive test reporting and failure analysis help you pinpoint what broke and why, turning hours of detective work into minutes of targeted fixes.\nIn this article, you’ll learn how TeamCity’s monitoring and diagnostic capabilities give you the insights needed to maintain stable and fast pipelines and spend more time on what matters most – shipping quality software.\nEnsuring stability and quality in every release\nConsistently shipping stable, high-quality code is non-negotiable; unstable releases undermine customer trust, inflate support costs, and create compounding technical debt. But how do you know your pipeline is stable and which levers improve quality?\nTeamCity’s Statistics Charts offer precise answers that translate complexity into clarity.\nMonitor success rates for continuous stability\nSuccess rate is an important metric of any CI/CD: It tracks the percentage of passing builds over time, spotlighting trends and sudden changes.\nHigh success rates indicate predictable pipelines and effective feedback loops, while dips signal fragility, demanding immediate attention.\n\n\n\n\nVisualize test failures to diagnose quality risks\nFailure rates provide additional insight: While the success rate gives you a pass/fail snapshot, overlaying failed test counts helps pinpoint when and how systemic issues emerge, revealing what releases are more problematic.\nIn the same Statistics tab, toggle Show failed in the Test Count graph to make test failures visible.\n\n\n\n\nAccess high-level failure data in seconds\nRapidly spotting patterns, like back-to-back failures, allows for proactive fixes before technical debt accumulates.\nUse the Overview tab for a high-level summary of all builds for a project, listed with their statuses, durations, changes, and failure indicators.\n\n\n\n\nInvestigate failures with one click\nClick into any build for detailed information regarding the status of every step, their duration, code-inspection results, changes in the code, and more:\n\n\n\n\nFollow the evidence: Click the Tests tab to get the full breakdown of which tests failed, whether they’re new or recurring, and contextual details that guide targeted fixes:\n\n\n\n\nFrom the Tests tab, you can drill deeper into individual test behavior by accessing the test history page. Click the three-dot menu to the right of any test name to open this view, which reveals patterns in test failures, such as how frequently the test fails, which build agents experience issues, when failures began, and trends over time. This historical perspective helps you distinguish between flaky tests and genuine regressions, making it easier to prioritize fixes based on impact and recurrence.\n\n\n\n\nTo complete the feedback loop, the Build Log offers a searchable, chronological trace of every step for uncovering underlying errors and misconfigurations behind failed tests.\n\n\n\n\nFrom failures to code quality: Tracking what matters\nAfter tracing a failure, comprehensive quality assurance means going beyond green builds to deep code insights. TeamCity’s Statistics tab offers dedicated charts for Code Inspections and Code Coverage to track technical debt and ensure essential logic is tested. You can also extend TeamCity’s dashboard by adding custom tabs with your own reports to the build results interface, enabling you to incorporate specialized metrics and third-party analysis tools directly into your workflow.\n\n\n\n\nClicking any point in the Code Coverage chart brings you to that build’s Coverage tab. Depending on your configured tool (in this example, coverage.py), you’ll find granular coverage reports here. These insights clarify which parts of your codebase are thoroughly tested versus those at risk of silent failure.\n\n\n\n\nUnderstanding where failures occur and which code remains untested raises quality, shortens feedback loops, and reduces risk for every subsequent release.\nAccelerating delivery: Measuring and improving release velocity\nOnce stability and quality are established, the next challenge for any engineering team is maximizing how quickly new value reaches users.\nTeamCity’s analytic charts and dashboards surface velocity as a multidimensional flow to help you drive meaningful gains in delivery speed without sacrificing rigor. You can enhance these analytics by reporting custom statistic values using TeamCity service messages directly from your build steps, allowing you to track metrics like code coverage percentages, inspection results, and other team-specific indicators alongside TeamCity’s built-in measurements.\nMonitoring release cadence for continuous value delivery\nEvery successful production release puts features, fixes, and security improvements directly into the hands of customers. That’s why tracking how often your CI/CD pipeline ships code is a critical health signal for agility and operational efficiency.\nFrequent deployments mean smaller, safer changes and less risk per release.\nTeamCity charts like Time Spent in Queue and Build Times help you identify when and how production deployments occur to quickly spot accelerations or slowdowns in delivery cadence.\n\n\n\n\nShortening cycle time for a faster feedback loop\nSpeed isn’t just about shipping more often; it’s also about reducing the interval between code commit and user impact. This end-to-end cycle time is an important health signal that defines your delivery pipeline’s efficiency and how quickly improvements make it to production.\nTeamCity’s flexibility allows for custom charts that highlight patterns in end-to-end delivery duration. For instance, you can build an Average Deployment Time graph using the Starting Build on Agent and Finishing Build on Server metrics:\n\n\n\n\nImproving failure response time to minimize impact\nThe speed at which your team responds to and recovers from production failures is a pivotal indicator of both resilience and operational maturity. TeamCity’s Time to Fix Tests and detailed build duration analytics show you how quickly errors surface and get resolved so you can quantify the impact of failures and how effectively you recover.\n\n\n\n\nMonitoring build duration for sustainable velocity\nVelocity also depends on how little time is wasted in each cycle. Analyzing Build Times and Build Duration by Stage reveals how efficiently your pipeline processes changes to help you maintain momentum and ensure timely deployments.\n\n\n\n\nDiagnosing bottlenecks: Pinpointing and resolving pipeline inefficiencies\nWhile fast delivery accelerates value, a truly effective pipeline depends on quickly surfacing and eliminating waste before slowdowns become systemic. Efficiently diagnosing bottlenecks prevents frustration, boosts developer productivity, and ensures that each iteration is an opportunity for improvement, not an exercise in firefighting.\nTeamCity’s analytics transform this process from guesswork into surgical, data-driven action.\nSpotting build spikes with actionable trends\nAnalyzing build duration trends is one of the most effective ways to identify pipeline inefficiencies. A sudden spike on the Build Times chart instantly highlights a potential issue, whether due to environmental issues, unusually long tests, or integration problems.\nFor example, you can use the Build Duration by Stage custom chart to pinpoint where in the pipeline bottlenecks occur as soon as unusual patterns emerge.\n\n\n\n\nInvestigating test duration: Finding the crawl in your pipeline\nLong build times can often be traced back to problematic tests. You can use the Tests tab in any build to check on the status, name, and duration of every test.\n\n\n\n\nIf the test duration is abnormally high, you can click on it for a historical trend chart that lets you identify when the test began slowing down and in what context.\n\n\n\n\nSimply click on any test to mute it or assign ownership for further investigation, ensuring accountability and rapid feedback.\n\n\n\n\nDetecting and managing flaky tests automatically\nFlaky tests (those that fail unpredictably) can silently degrade confidence in your pipeline and are notoriously difficult to spot through duration analysis alone.\nTeamCity proactively flags flaky tests and surfaces them in the dedicated Flaky Tests tab at the project level. Here, you see the test name, failure count, flip rate, and insights into the causes for flakiness that you can act on.\n\n\n\n\nFlaky tests are also prominently flagged in the Overview code inspection section for any failed build. Click into the test entry for a detailed stack trace, or open the error in the Build Log for a deeper dive.\n\n\n\n\nUsing test reports for root-cause analysis\nAlong with flaky test management, TeamCity’s Tests tab flags these problematic tests and offers a Test History report on clicking. These reports let you compare failure patterns across builds by listing status, duration, build number, changes, agent, and precise timestamps side by side. Additionally, an intuitive history chart enables quick trend analysis.\n\n\n\n\nConclusion\nMoving beyond the daily cycle of troubleshooting builds requires more than patch fixes and workarounds. TeamCity provides the diagnostic clarity you need with built-in health signals that reveal build duration trends, success rate patterns, and failure root causes – without having to dive through endless plugin configurations or log files.\nInstead of spending hours investigating why builds randomly fail or trying to identify which plugin update broke your deployment chain, TeamCity’s comprehensive monitoring gives you immediate visibility into pipeline bottlenecks and stability issues. The integrated test reporting eliminates guesswork so you can pinpoint problems quickly and maintain consistent delivery performance.",
        "dc:creator": "Dmitrii Korovin",
        "content": "This article was brought to you by Damaso Sanoja, draft.dev. If you&#8217;re spending your mornings debugging Jenkins pipeline failures, waiting for builds that should take minutes but stretch into hours, or scrambling to identify which plugin update broke your deployment process, you&#8217;re not alone. These daily troubleshooting battles with legacy CI/CD systems drain engineering time [&#8230;]",
        "contentSnippet": "This article was brought to you by Damaso Sanoja, draft.dev. If you’re spending your mornings debugging Jenkins pipeline failures, waiting for builds that should take minutes but stretch into hours, or scrambling to identify which plugin update broke your deployment process, you’re not alone. These daily troubleshooting battles with legacy CI/CD systems drain engineering time […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=673380",
        "categories": [
          "best-practices",
          "teamcity-2",
          "devopspains",
          "docker"
        ],
        "isoDate": "2026-01-12T17:16:46.000Z"
      },
      {
        "creator": "Dominika Stankiewicz",
        "title": "Dancing Backwards With Go",
        "link": "https://blog.jetbrains.com/go/2026/01/12/dancing-backwards-with-go/",
        "pubDate": "Mon, 12 Jan 2026 12:07:51 +0000",
        "content:encodedSnippet": "This is a guest post from John Arundel, a Go writer and teacher who runs a free email course for Go learners. His book The Power of Go: Tests is a love letter to test-driven development in Go.\n“Fred Astaire? Sure, he was great, but don’t forget Ginger Rogers did everything he did… backwards, and in high heels.”\n\n            \nBob Thaves\n                                                        \nHave you ever tried programming backwards? If not, you’re in for a treat! You won’t even need to wear high heels.\n(If you want to, though, go for it—you’ll look fabulous!)\nThe function that never was\nSuppose we want to write a Go function that checks whether a given slice is sorted (that is, its elements are in order).\nFor example, if the input is {1, 2, 3}, the answer should be true, because the slice is sorted. On the other hand, if the input is {3, 1, 2}, we should get false, because the slice is not sorted.\nMost people would probably start writing some function IsSorted. That’s fine for Fred Astaire. Just for fun, though, shall we try tackling this problem backwards, like Ginger Rogers?\nWe’ll start by imagining that we already have the IsSorted function, and we’ll try to write a test for it. Once we have the test, we’ll go on to write the function.Let’s fire up GoLand and select File / New / Project… / sorted.\n\n\n\n\nNext, we’ll use New / Go File to create a source file, and name it sorted_test.go.\nWe’ll start by declaring:\npackage sorted_test\nAll Go tests have the same signature, so the test snippet saves us writing it. We’ll type test, and press Tab to complete:\nfunc TestName(t *testing.T) {\n\n}\nWe’re invited to replace Name with a description of the behavior to test. How about:\nfunc TestIsSorted_IsTrueForSortedSlice(t *testing.T) {\n\n}\nSounds believable, so let’s fill in the rest:\nfunc TestIsSorted_IsTrueForSortedSlice(t *testing.T) {\n    t.Parallel()\n    input := []int{1, 2, 3}\n    if !sorted.IsSorted(input) {\n        t.Errorf(\"got false for %v\", input)\n    }\n}\nIf the result of calling IsSorted on this input is false, the test fails. Straightforward!\nThe fastest route to failure\nWe know IsSorted doesn’t exist yet, but before we implement it, we need to know if this test will actually detect bugs in IsSorted. That’s what tests are for, after all.\nLet’s write as little code as we possibly can to get this test compiling and failing. The first problem GoLand tells us about is “Unresolved reference sorted”. Fair enough!\nWe need to create the sorted package, so let’s set up another new file: New / Go File / sorted.go.\nNow we have a quick-fix action available in the test: import sorted. Great!\n\n\n\n\nWe still have an unresolved reference IsSorted, but now we can use the quick fix Create Function IsSorted. Here’s the result:\nfunc IsSorted(input []int) bool {\n\n}\nGood start, but now GoLand says “Missing the return statement at end of function.” Here’s the quick fix: Add return statement.\n\n\n\n\nNow we have:\nfunc IsSorted(input []int) bool {\n    return\n}\nAlmost there, but now we have the error “not enough arguments to return.” Quick fix again: Add missing return values.\nfunc IsSorted(input []int) bool {\n    return false\n}\n“But this won’t work!” I hear you wail. “It always returns false no matter what the input!”\nYour wailing is on point, dear reader, but remember, we want a non-working implementation, and now we have one. This is the perfect time to check if our test will actually detect a bug in IsSorted—for instance, that it always returns false!\nLet’s click the green triangle next to the test name to run the test. We assume it will fail, but you never know—that’s why we check:\nsorted_test.go:12: got false for [1 2 3]\n--- FAIL: TestIsSorted_IsTrueForSortedSlice (0.00s)\n\n\n\n\nSuccess! (I said this was backwards.)\n\n\n\n\nCranking up the difficulty\nWe could trivially change IsSorted to return true instead of false to make this pass, but that doesn’t really get us anywhere. IsSorted needs to be able to distinguish between sorted and unsorted slices, not just return a fixed value.\nWe want two tests, for two different behaviours: that IsSorted is true for sorted inputs, and that it’s false for unsorted ones.\nfunc TestIsSorted_IsTrueForSortedSlice(t *testing.T) {\n    t.Parallel()\n    input := []int{1, 2, 3}\n    if !sorted.IsSorted(input) {\n        t.Errorf(\"got false for %v\", input)\n    }\n}\n\nfunc TestIsSorted_IsFalseForUnsortedSlice(t *testing.T) {\n    t.Parallel()\n    input := []int{1, 3, 2}\n    if sorted.IsSorted(input) {\n        t.Errorf(\"got true for %v\", input)\n    }\n}\nA fixed-value implementation could pass one test or the other, but not both. Let’s prove it, using the Ctrl-Shift-R shortcut to run all tests in this file:\n\n\n\n\nHow little work do you think we can do to get both tests passing?\nBaby’s first steps\nIf any elements are not in order, then at some point we’ll encounter a number that’s smaller than the previous one. The simplest, dumbest way I can think of to detect that is:\nfunc IsSorted(input []int) bool {\n    prev := 0\n    for _, v := range input {\n        if v < prev {\n            return false\n        }\n    }\n    return true\n}\nIt seems reasonable, but I could stare at this code all day and not be sure whether it’s correct or not. Let’s check:\n=== FAIL:  TestIsSorted_IsFalseForUnsortedSlice\n    sorted_test.go:20: got true for [1 3 2]\n\n\n\n\nOops. I forgot to update prev with each new number (not enough coffee today). Let’s add a prev = v to the loop:\nfunc IsSorted(input []int) bool {\n    prev := 0\n    for _, v := range input {\n        if v < prev {\n            return false\n        }\n        prev = v\n    }\n    return true\n}\nThis passes both tests now, but is it really correct? Again, we could have a staring contest with this code looking for bugs, and we might find some, or we might not.\n\n\n\n\nThe backwards programmer’s approach, though, is to stare at the tests instead. Can we think of some more test cases that might trip up a buggy implementation of IsSorted?\nWhat about a slice that contains repeated numbers, for example?\nfunc TestIsSorted_IsTrueForSortedSliceWithRepeat(t *testing.T) {\n    t.Parallel()\n    input := []int{1, 2, 2}\n    if !sorted.IsSorted(input) {\n        t.Errorf(\"got false for %v\", input)\n    }\n}\nThis passes, which is encouraging. But I notice that the test logic is the same for all our “sorted” tests, so let’s combine them into a single table test.\n\n\n\n\nCases on the table\nGoLand can write this table test for us, if we right-click on the IsSorted function and select Generate / Test for function:\nfunc TestIsSorted(t *testing.T) {\n    type args struct {\n        input []int\n    }\n    tests := []struct {\n        name string\n        args args\n        want bool\n    }{\n        // TODO: Add test cases.\n    }\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            if got := sorted.IsSorted(tt.args.input); got != tt.want {\n                t.Errorf(\"IsSorted() = %v, want %v\", got, tt.want)\n            }\n        })\n    }\n}\nNot bad, but this generated code is just a suggestion: we don’t have to follow it slavishly. Let’s make a few small tweaks:\nWe’ll run the test in parallel\nWe’ll organise the test cases as a map, keyed by name\nWe don’t need to specify want every time, because it’s always true in this test\nSo:\nfunc TestIsSorted_IsTrueForSortedSlicesWith(t *testing.T) {\n    t.Parallel()\n    inputs := map[string][]int{\n        \"all elements different\": {1, 2, 3},\n        \"repeated elements\":      {1, 2, 2},\n    }\n    for name, input := range inputs {\n        t.Run(name, func(t *testing.T) {\n            if !sorted.IsSorted(input) {\n                t.Errorf(\"got false for %v\", input)\n            }\n        })\n    }\n}\nUsing t.Run turns each case into a named subtest, and all our subtests can share the same function body, which simplifies things.\n\n\n\n\nThis replaces the two old IsTrue tests, so now let’s add another table test for IsFalse:\nfunc TestIsSorted_IsFalseForUnsortedSlicesWith(t *testing.T) {\n    t.Parallel()\n    inputs := map[string][]int{\n        \"all elements different\": {1, 3, 2},\n        \"repeated elements\":      {3, 2, 2},\n    }\n    for name, input := range inputs {\n        t.Run(name, func(t *testing.T) {\n            if sorted.IsSorted(input) {\n                t.Errorf(\"got true for %v\", input)\n            }\n        })\n    }\n}\nLooking good. Time for a well-earned break, I think. Would you care for some tea and cake?\nDon’t be so negative!\nWhile I was nibbling at a moist, fudgy chocolate brownie just now, I thought: prev starts at zero, but what if the first element is negative? Then we’d wrongly return false for a sorted slice, because v < prev. Yikes!\nYour conventional programmer—Fred Astaire, if you like—would jump straight into fixing IsSorted. But we’re backwards programmers, so we’ll use the Ginger Rogers technique: first write a failing test, then make it pass.\nfunc TestIsSorted_IsTrueForSortedSlicesWith(t *testing.T) {\n    t.Parallel()\n    inputs := map[string][]int{\n        \"all elements different\": {1, 2, 3},\n        \"repeated elements\":      {1, 2, 2},\n        \"negative first element\": {-1, 2, 3},\n    }\n    ...\nThis fails as expected:\n\n\n\n\nNow we can fix it. Let’s initialize prev to the first element of input and then loop over the remaining elements:\nfunc IsSorted(input []int) bool {\n    prev := input[0]\n    for _, v := range input[1:] {\n        if v < prev {\n            return false\n        }\n        prev = v\n    }\n    return true\n}\nAnd:\n\n\n\n\nOh glory be, oh happy day! We can ship the package to production and go out for our team pizza night (extra pepperoni on mine, please).\nLater that same week…\nWell, everything was fine for a few days, but then a bug report came in from a customer: IsSorted panicked when they called it with an empty slice (oh dear).\nWell, we can fix this—backwards! Let’s add the customer’s “no elements” test case to our table:\nfunc TestIsSorted_IsTrueForSortedSlicesWith(t *testing.T) {\n    t.Parallel()\n    inputs := map[string][]int{\n        \"all elements different\": {1, 2, 3},\n        \"repeated elements\":      {1, 2, 2},\n        \"negative first element\": {-1, 2, 3},\n        \"no elements\":            {},\n    }\n    ...\nThis should reproduce the bug report:\n\n\n\n\nNext, we’ll locate the panic using the stack trace:\nsorted.IsSorted(...)\n    /yumyum/cake/yesplease/sorted/sorted.go:4\nThis is a link, so clicking the filename teleports us straight to the offending line:\nprev := input[0]\nAn empty slice has no elements, hence the panic. But it is sorted, so we can simply return true straight away in this case:\nif len(input) == 0 {\n    return true\n}\n\n\n\n\nAnd while we’re here, let’s handle a one-element slice the same way. New test case:\nfunc TestIsSorted_IsTrueForSortedSlicesWith(t *testing.T) {\n    t.Parallel()\n    inputs := map[string][]int{\n        \"all elements different\": {1, 2, 3},\n        \"repeated elements\":      {1, 2, 2},\n        \"negative first element\": {-1, 2, 3},\n        \"no elements\":            {},\n        \"one element\":            {1},\n    }\n    ...\nA small tweak to the function:\nif len(input) < 2 {\n    return true\n}\nTests are passing, and customers are happy. Another win for backwards programming!\n\n\n\n\nCutting out the calories\nA little while later, a new member of the team, Alyssa, is looking at our current version of IsSorted:\nfunc IsSorted(input []int) bool {\n    if len(input) < 2 {\n        return true\n    }\n    prev := input[0]\n    for _, v := range input[1:] {\n        if v < prev {\n            return false\n        }\n        prev = v\n    }\n    return true\n}\n“You know,” she says, “there’s a function for this in the standard library. I think we could replace all this code with just…”\nreturn slices.IsSorted(input)\nHuge if true! Well, we know exactly how to find out: run the tests.\nJust for fun, let’s use the gotestdox tool, which both runs the tests and prints their names as English sentences. “Tests as docs”, if you like.\ngo run github.com/bitfield/gotestdox/cmd/gotestdox@latest\n\n\n\n\nWonderful! This is exactly the kind of radical refactoring idea we hoped you’d bring to the team, Alyssa P. Hacker. And backwards programming helped make it safe: by writing our tests first, we made sure that any new code is always covered by tests.\nThe way forward?\nSo that’s backwards programming. Once you’ve tried it, it doesn’t really seem so backwards after all, does it?\nNext time you have a feature to add or a bug to fix, then, why not try doing the backwards quickstep yourself? It’s as easy as “red, green, refactor”:\nAdd a failing test (“red”)\nMake it pass (“green”)\nTidy up, optimise, and check that all tests still pass (“refactor”)\nJust remember to always look where you’re going, and try not to trip over your own feet. Shall we dance?",
        "dc:creator": "Dominika Stankiewicz",
        "content": "This is a guest post from John Arundel, a Go writer and teacher who runs a free email course for Go learners. His book The Power of Go: Tests is a love letter to test-driven development in Go. Have you ever tried programming backwards? If not, you’re in for a treat! You won’t even need [&#8230;]",
        "contentSnippet": "This is a guest post from John Arundel, a Go writer and teacher who runs a free email course for Go learners. His book The Power of Go: Tests is a love letter to test-driven development in Go. Have you ever tried programming backwards? If not, you’re in for a treat! You won’t even need […]",
        "guid": "https://blog.jetbrains.com/?post_type=go&p=672799",
        "categories": [
          "goland",
          "go",
          "golang"
        ],
        "isoDate": "2026-01-12T12:07:51.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": [
      {
        "creator": "Gerum Haile",
        "title": "Pay As a Local",
        "link": "https://medium.com/airbnb-engineering/pay-as-a-local-bef469b72f32?source=rss----53c7c27702d5---4",
        "pubDate": "Mon, 12 Jan 2026 18:02:56 GMT",
        "content:encodedSnippet": "How Airbnb rolled out 20+ locally relevant payment methods worldwide in just 14 months\nBy: Gerum Haile, Bo Shi, Yujia Liu, Yanwei Bai, Bo Yuan, Rory MacQueen, Yixia Mao\n\nAcross the more than 220 global markets that Airbnb operates in, cards are the primary way that guests pay for stays, experiences, and services. However, to help make our platform accessible to more people, reduce friction at checkout, and drive more adoption, we introduced trusted, locally preferred payment methods — called local payment methods or LPMs. By offering and supporting these payment methods, Airbnb enables guests everywhere to choose what works best for them.\nIn this blog post, we’ll discuss the implementation details behind our Pay as a Local initiative, which allowed us to launch 20+ local payment methods across multiple markets in just over one year.\nLPMs: What they are, why they matter, and our discovery and selection process\nLocal payment methods go beyond traditional cards and include:\n\nCountry or region-specific digital wallets (such as M-Pesa or MTN, MoMo)\nOnline bank transfers (such as Online Banking Czech, Online Banking Slovakia)\nReal-time or instant bank payments (such as PIX, UPI)\nLocal payment schemes (such as EFTPOS, Cartes Bancaires)\n\nBy embracing LPMs, Airbnb helps make travel more inclusive and seamless for people around the world. LPMs help the platform to:\n\nBoost conversion and bookings by offering guests familiar, trusted payment options.\nUnlock new markets where credit card usage is low or non-existent.\nBuild accessibility for guests without credit cards or traditional banking access.\n\nThrough our research on local payment methods (LPMs), we identified over 300 unique payment options worldwide. For the initial phase of the LPM initiative, we used a structured qualification framework to select which local payment methods we would support. We evaluated the top 75 travel markets and selected the top one to two payment methods per market — excluding those without a clear travel use case — and arrived at a shortlist of just over 20 LPMs best suited for integration into our payment platform.\nBackground on Airbnb’s payment platform\nAirbnb’s payments platform is designed to decouple payment logic from the core business (i.e., stays, experiences, and services), allowing for greater flexibility and scalability. The platform efficiently coordinates both guest pay-ins and host payouts by working with regulated payment service providers and financial partners.\nBeyond payment processing, the system also supports robust payment trust and compliance functions.\nModernization\nAs part of a multi-year replatforming initiative for our payments architecture called Payments LTA (long-term architecture), we shifted from a monolithic system to a capability-oriented services system structured by domains, using a domain-driven decomposition approach. This modernization approach reduced our time to market, increased reusability and extensibility, and empowered greater team autonomy.\nThe core payment domain delivers essential capabilities for pay-in, payout, and payment intermediation. It consists of multiple subdomains, including Pay-in, Payout, Transaction Fulfillment, Processing, Wallet & instruments, Ledger, Incentives & Stored Value, Issuing, and Settlement & Reconciliation.\nReplatforming as an enabler for local payment method expansion\nThe processing subdomain enables integration with third-party payment service providers (PSPs) and supports API and file-based vendor integration, as well as switching and routing capabilities. As part of our replatforming initiative, we adopted a connector and plugin-based architecture for onboarding new third-party payment service providers. This strategy has significantly reduced the time required to integrate new PSPs in different markets.\nDuring this replatforming effort, we also introduced Multi-Step Transactions (MST): a processor-agnostic framework that supports payment flows completed across multiple stages. MST defines a PSP-agnostic transaction language to describe the intermediate steps required in a payment, such as submitting supplemental data or handling dynamic interactions. These steps, called Actions, can include:\n\nRedirects\nStrong customer authentication (SCA) frictions (challenges, fingerprinting)\nPayment method — specific flows\n\nWhen a PSP indicates that an additional user action is required, its vendor plugin normalizes the request into an ActionPayload and returns it with a transaction intent status of ACTION_REQUIRED. This architecture ensures consistent handling of complex, multi-step payment experiences across diverse PSPs and markets.\n\nLPM integration architecture\nWhile our modernized payment platform laid the foundation for enabling LPMs, these payment methods come with a unique set of challenges. Many local methods require users to complete transactions in third-party wallet apps. This introduces complexity in app switching, session hand-off, and synchronization between Airbnb and external digital wallets.\nEach local payment vendor also exposes different APIs and behaviors across charge, refund, and settlement flows, making integration and standardization difficult.\nTechnical approach\nWe analyzed the end-to-end behavior of our 20+ LPMs, and identified three foundational payment flows that capture the full spectrum of user and system interactions. By distilling LPM behaviors into these standardized payment flow archetypes, we established a unified framework for integration:\n\nRedirect flow: Guests are redirected to a third-party site or app to complete the payment, then return to Airbnb to finalize their booking (e.g., Naver Pay, GoPay, FPX).\nAsync flow: Guests complete payment externally after receiving a prompt (such as a QR code or push notification), and Airbnb receives payment confirmation asynchronously via webhooks (e.g., Pix, MB Way, Blik).\nDirect flow: Guests enter their payment credentials directly within Airbnb’s interface, allowing real-time processing similar to traditional card payments (e.g., Carte Bancaires, Apple Pay).\n\nThis standardized approach has enabled significant reusability across integrations and substantially reduced the engineering effort required to support new payment methods.\nAsynchronous payment orchestration\nSince many guests complete payments through external providers, we redesigned our payment orchestration — building on top of MST — to support payment flows that require user actions outside Airbnb (redirect flows and async flows).\nFor redirect flows, where guests complete the payment on a third-party app or website:\n\nAirbnb’s payments platform sends a charge request to the local payment vendor, whose response includes a redirectUrl.\nOur platform redirects the user to the external app or website to complete the payment.\nOnce the payment is successfully completed, the user is redirected back to Airbnb with a result token. Airbnb’s payments platform then uses this token to securely confirm and finalize the payment with the local processor.\n\nFor async flows (which typically involve scanning a QR code):\n\nAirbnb’s payments platform sends a charge request to the local payment vendor, whose response includes a qrCodeData.\nThe checkout page displays the QR code for the user to scan and complete the payment in their wallet app.\nAfter the payment succeeds, the vendor sends a webhook notification to Airbnb’s payments platform, which updates the payment status to success and confirms the user’s order.\n\nNaver Pay: Redirect To Naver Pay Website\nNaver Pay is one of the fastest-growing digital payment methods in South Korea. As of early 2025, it has reached over 30.6 million active users, representing approximately 60% of the South Korean population. Enabling Naver Pay in the South Korean market not only helps deliver a more seamless and familiar payment experience for local guests, but also expands Airbnb’s reach to new users who prefer using Naver Pay as their primary payment method.\n\nPix: Scan A QR Code\nPix is an instant payment system developed by the Central Bank of Brazil, enabling 24/7 real-time money transfers through methods such as QR codes or Pix keys. Its adoption has been extraordinary — by late 2024, more than 76% of Brazil’s population was using Pix, making it the country’s most popular payment method, surpassing cash, credit, and debit cards. In 2024 alone, Pix processed over BRL 26.4 trillion (approximately USD 4.6 trillion) in transaction volume, underscoring its pivotal role in Brazil’s digital payment ecosystem.\n\nConfig-driven payment method integration\nAirbnb embraced a config-driven approach, powered by a central YAML-based Payment Method Config that acts as a single source of truth for flows, eligibility, input fields, refund rules, and more. Instead of scattering payment method logic across the frontend, backend, and various services, we consolidate all relevant details in this config. Both core payment services and frontend experiences dynamically reference this single source of truth, ensuring consistency for eligibility checks, UI rendering, and business rules. This unified approach dramatically reduces duplication, manual updates, and errors across the stack, making integration and maintenance faster and more reliable.\nThese configs also drive automated code generation for backend services using code generation tools, producing Java classes, DTOs, enums, schema, and integration scaffolding. As a result, integrating or updating a payment method is largely declarative — just a config change. This streamlines launches from months to weeks and makes ongoing maintenance far simpler.\n\nPayment widget\nOur payment widget — the payment method UI embedded into the checkout page — includes the list of available payment methods and handles the user’s inputs. Local payment methods often require specialized input forms (such as CPF for Pix) and have unique country/currency eligibility.\nRather than hardcoding forms and rules into the client, we centralize both form-field specification and eligibility checks in the backend. Servers send configuration payloads to clients defining exactly which fields to collect, which validation rules to apply, and which payment options to render. This empowers the frontend to dynamically adapt UI and validation for each payment method, accelerating launches and keeping user experiences fresh without frequent client releases.\nFor example, Pix in Brazil requires the guest’s first name, last name, and CPF (tax ID), which we collect and transmit as required to complete the payment.\n\nBelow is a diagram illustrating how dynamic payment method configurations are delivered from the backend to the frontend, enabling tailored checkout presentations for each payment method.\n\nBuilding confidence through better testability\nTesting local payment methods can be difficult, because developers often don’t have access to local wallets. Yet with such a broad range of payment methods and complex flows, comprehensive testing is essential to prevent regressions and ensure seamless functionality.\nTo address this, we enhanced Airbnb’s in-house Payment Service Provider (PSP) Emulator, enabling realistic simulation of PSP interactions for both redirect and asynchronous payment methods. The Emulator allows developers to test end-to-end payment scenarios without relying on unstable (or nonexistent) PSP sandboxes. For redirect payments, the Emulator provides a simple UI mirroring PSP acquirer pages, allowing testers to explicitly approve or decline transactions for precise scenario control. For async methods, it returns QR code details and automatically schedules webhook emission tasks upon receiving a /payments request — delivering a complete, reliable testing environment across diverse LPMs.\n\nScaling observability for local payment methods\nMaintaining high reliability and availability is critical for Airbnb’s global payment system. As we expand to support many new local payment methods, we face increasing complexity: greater dependencies on external PSPs and wide variations in payment behaviors. For example, a real-time card payment and a redirect flow like Naver Pay follow completely different technical paths. That diversity makes observability difficult — a single “payment success rate” may represent card health well, but say little about an asynchronous LPM. Without proper visibility, regressions can go unnoticed until they affect real users. As dozens of new LPMs go live, observability has become the foundation of reliability.\nTo address this, we built a centralized monitoring framework that unifies metrics across all layers, from client to PSP. When launching a new LPM, onboarding now requires a single config change; add the method name, and metrics begin streaming automatically:\n\nClient metrics — user-level flow health from clients\nPayment backend metrics — API-level metrics for payment flows\nPSP metrics — API-level visibility between Airbnb and the PSP\nWebhook metrics — async completion status for redirect methods or refunds\n\nWe have also standardized the alerting rules across our platform’s Client, Backend, PSP, and Webhook layers using composite alerts and anomaly detection. Each alert follows a consistent pattern (failure count, rate, time window), e.g., “Naver Pay resume failures > 5 and failure rate > 20% in 30 minutes.” This design minimizes false positives during low-traffic periods.\nThis framework scales effectively, providing end-to-end visibility from user click to PSP confirmation. It enables engineers to trace issues in minutes rather than hours, whether those issues were caused by internal changes or external outages. By turning observability into a shared, automated layer, we were able to strengthen the backbone of payment reliability while accelerating the rollout of new LPMs worldwide.\nImpact\nThe Pay as a Local initiative delivered significant business and technical impact:\n\nMeaningful booking uplift: We observed meaningful uplift in bookings and new users in markets where we launched local payment methods\nFaster integrations: Reduced integration time significantly through reusable flows and config-driven automation.\nStronger reliability: Improved observability for early outage detection, standardized testing to prevent regressions, and streamlined vendor escalation and on-call processes for global resilience.\n\nConclusion\nSupporting local payment methods helps Airbnb to stay competitive and relevant in the global travel industry. These payment options help improve checkout conversion, drive adoption, and unlock new growth opportunities.\nThis post outlined how the Airbnb payment platform has evolved to support local payment methods at scale — through asynchronous payment orchestration, config-driven onboarding, centralized observability, and robust testability. Together, these capabilities enable faster integrations, lower maintenance overhead, and offer a more seamless, localized checkout experience for guests worldwide.\nAs Airbnb continues to expand globally, our payments platform will keep evolving with the same principles of extensibility, reliability, and scalability, ensuring that guests everywhere can pay confidently, using the methods they know and trust.\nAcknowledgments\nWe had many people at Airbnb contributing to this big rearchitecture, but countless thanks to Mini Atwal, Ashish Singla, Musaab At-Taras,Linmin Yang, Yong Rhyu, Yohannes Tsegay, Livar Cunha, Praveena Subrahmanyam, Steve Ickes, Vijaykumar Borkar, Vibhu Ramani, Aashna Jain, Abhishek Ghosh, Abhishek Patel, Adithya Tammavarapu, Akai Hsieh, Akash Budhia, Amar Parkash, Amee Mewada, Ankita Balakrushan Tate, Bharath Kumar Chandramouli, Bo Shi, Bo Yuan. Callum Li. Carlos Townsend Pico, Chanakya Daparthy, Charles Tang, Cibi Pari, Cindy Jaimez, Cindy Shi, Dan Yo, Daniela Nobre, Danielle Zegelstein, David Cordoba, David Drinan, Dawei Wang, Dechuan Xu, Denise Francisco, Denny Liang, Dimi Matcovschi, Divya Verma, Feifeng Yang, Gabriel Siqueira, Sunny Wallia, Prashant Jamlakar, Daniel Kriske, Giovanni Iniguez, Haojie Zhang, Haokun Chen, Haoti Zhong, Harriet Russell, Harshit Gupta, Henrique Moreira Indio do Brasil, Ishan Ishan, Jenny Shen, Jerroid Marks, Jiafang Jiang, Joey Yin, Jon Chew, Karen Kuo, Katie Turley, Letian Zhang, Maneesh Lall, Manish Singhal, Maria Daneri, Mark Jang, Mengfei Ren, Michelle Desiderio, Mohit Dhawan, Nam Kim, Nerea Ruiz Alvarez, Nikita Kapoor, Oliver Zhang, Omer Faruk Gul, Pallavi Sharma, Prateek Sri, Rae Huang, Rohit Krishnan Dandayudham, Rory MacQueen, Ruize Liu, Sam Bitter, Sam Tang, Saran Singh. Sardana Sai Anil, Serdar Yildirim, Shwetha Saibanna, Silvia Crespo Sanchez, Simon Xia, Stella Dong, Stella Su, Stephanie Leung, Steve Cao, Sumit Ranjan, Tay Rauch, Thanigaivelan Manickavelu, Tiffany Selby, Toland Hon, Trish Burgess,Vishal Garg, Vivian Lue, Vyom Rastogi, William Betz, Xi Wen, Xing Xing, Xuanxuan Wu, Yangguang Li, Yanwei Bai, Yeung Song, Yixia Mao, Yujia Liu. Yun Cho, Zhenhui Zhu, Ziyun Ye\n****************\nAll product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.\n\nPay As a Local was originally published in The Airbnb Tech Blog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Gerum Haile",
        "guid": "https://medium.com/p/bef469b72f32",
        "categories": [
          "payments",
          "tech",
          "technology",
          "engineering"
        ],
        "isoDate": "2026-01-12T18:02:56.000Z"
      }
    ]
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Jessie Houghton",
        "title": "Copilot Memories",
        "link": "https://devblogs.microsoft.com/visualstudio/copilot-memories/",
        "pubDate": "Thu, 15 Jan 2026 13:00:33 +0000",
        "content:encodedSnippet": "Are you wasting time reviewing code for nits on code standards, project preferences, or important contribution guidelines? We know the pain. It’s all too easy for best practices and those tiny but critical team details to slip through the cracks, resulting in inconsistencies, confusion, and wasted time. But now, there’s a smarter way to ensure everyone’s always on the same page! \nHow Copilot memories make teamwork effortless \nIntroducing Copilot memories, a new feature that empowers every developer and team to capture, remember, and share their coding preferences and important project guidelines, automatically! \nIntelligent detection just for you and your team \nCopilot memories continuously learns how you and your team likes to work. It intelligently detects unique preferences within your projects as you prompt. No more manual reminders or digging through old messages. Copilot keeps track of what matters most, so you don’t have to. \nConfirmation nudges you can trust \nWorried about Copilot making changes without you knowing? Don’t be! Whenever Copilot is ready to save a new memory or update an existing one, you’ll receive a clear confirmation nudge. You’re always in control. Simply review, accept, or adjust as needed before preferences are updated. \nSmart categorization, right where you need it \nCopilot memories doesn’t just remember information. It also helps you organize it exactly where you expect to find it. Each memory gives you the option to save preferences in your personal user preference file %USERPROFILE%/copilot-instructions.md or in the version-controlled repo-level instructions in the /.github/copilot-instructions.md. Copilot intelligently merges the results into your existing files or creates new ones.\nBenefits for every developer and team \nWith Copilot memories, your projects automatically become more consistent and easier to onboard to. New team members can instantly see “how we do things here,” and seasoned pros save time by letting Copilot handle the details. It’s project-aware and makes documentation part of your natural workflow. \nCheck out the new Visual Studio Hub  \nStay connected with everything Visual Studio in one place! Visit the Visual Studio Hub for the latest release notes, YouTube videos, social updates, and community discussions.  \nAppreciation for your feedback  \nYour feedback helps us improve Visual Studio, making it an even more powerful tool for developers. We are immensely grateful for your contributions and look forward to your continued support. By sharing your thoughts, ideas, and any issues you encounter through Developer Community, you help us improve and shape the future of Visual Studio. \nThe post Copilot Memories appeared first on Visual Studio Blog.",
        "dc:creator": "Jessie Houghton",
        "comments": "https://devblogs.microsoft.com/visualstudio/copilot-memories/#comments",
        "content": "<p>Are you wasting time reviewing code for nits on code standards, project preferences, or important contribution guidelines? We know the pain. It’s all too easy for best practices and those tiny but critical team details to slip through the cracks, resulting in inconsistencies, confusion, and wasted time. But now, there’s a smarter way to ensure everyone’s always on the same [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/copilot-memories/\">Copilot Memories</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Are you wasting time reviewing code for nits on code standards, project preferences, or important contribution guidelines? We know the pain. It’s all too easy for best practices and those tiny but critical team details to slip through the cracks, resulting in inconsistencies, confusion, and wasted time. But now, there’s a smarter way to ensure everyone’s always on the same […]\nThe post Copilot Memories appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=255205",
        "categories": [
          "Visual Studio"
        ],
        "isoDate": "2026-01-15T13:00:33.000Z"
      }
    ]
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": [
      {
        "title": "QueryDSL을 이용한 Batch Insert 성능 개선",
        "link": "https://cheese10yun.github.io/querydsl-batch-insert/",
        "pubDate": "Sat, 17 Jan 2026 15:54:48 GMT",
        "content:encodedSnippet": "JPA를 사용하다 보면 대량의 데이터를 삽입해야 하는 상황에서 saveAll의 성능 한계에 부딪히게 됩니다. 이번 포스팅에서는 JPA saveAll의 성능 이슈를 살펴보고, QueryDSL의 SQLQueryFactory를 활용한 Batch Insert로 성능을 획기적으로 개선하는 방법을 소개합니다.\n개요#\n대량의 데이터를 데이터베이스에 저장해야 할 때, 일반적으로 JPA의 saveAll 메서드를 사용합니다. 하지만 데이터의 양이 늘어날수록 saveAll의 처리 속도는 급격히 느려질 수 있습니다. 특히 ID 생성 전략이 IDENTITY인 경우, JPA는 Batch Insert를 지원하지 않아 단건으로 Insert 쿼리가 실행되는 문제가 있습니다.\n이전 포스팅(Spring Batch에서 Exposed를 이용한 Batch Insert)에서 Exposed를 활용한 성능 개선 방법을 소개한 적이 있습니다. 하지만 오직 Batch Insert만을 위해 JPA 환경에 Exposed라는 새로운 ORM을 도입하고 혼합해서 사용하는 것은 설정의 복잡함이나 학습 곡선 측면에서 비효율적일 수 있습니다.\n만약 이미 프로젝트에서 JPA와 QueryDSL을 사용하고 있다면, 추가적인 ORM 도입 없이 QueryDSL-SQL 모듈을 활용하여 Type-Safe하게 Batch Insert를 구현할 수 있습니다. 이번 포스팅에서는 그 방법을 소개합니다.\nJPA saveAll의 성능 이슈#\nJPA(Hibernate)는 엔티티의 ID 생성 전략이 @GeneratedValue(strategy = GenerationType.IDENTITY)로 설정되어 있을 때, JDBC 레벨의 Batch Insert를 비활성화합니다. 이는 영속성 컨텍스트가 엔티티를 관리하기 위해 Insert 즉시 ID 값을 알아야 하기 때문입니다. 결과적으로 1,000개의 데이터를 저장하면 1,000번의 Insert 쿼리가 데이터베이스로 전송되어 성능 저하의 주원인이 됩니다.\n일반적인 JPA의 saveAll 사용 코드는 다음과 같습니다.\n\n\n1\n2\n3\n4\n\n@Transactional\nfun saveAllWriters(writers: List<Writer>) {\n    writerRepository.saveAll(writers)\n}\n\n\n위 코드는 사용하기 매우 편리하지만, 대량의 데이터를 처리할 때는 각 엔티티마다 개별적인 Insert 쿼리가 발생하여 네트워크 오버헤드와 데이터베이스 처리 비용이 증가하게 됩니다.\nQueryDSL Batch Insert 구현#\nQueryDSL-SQL 모듈을 사용하면 JPA 엔티티가 아닌 JDBC 레벨에서 직접 SQL을 구성하여 실행할 수 있습니다. 이를 통해 addBatch 기능을 활용한 Bulk Insert를 구현할 수 있습니다.\n의존성 설정#\nQueryDSL-SQL을 사용하기 위해 build.gradle.kts에 아래 의존성을 추가합니다.\n\n\n1\n2\n3\n4\n5\n6\n7\n\ndependencies {\n    // QueryDSL JPA (기본 사용)\n    implementation(\"com.querydsl:querydsl-jpa:5.1.0:jakarta\")\n\n    // QueryDSL SQL (Batch Insert를 위해 필요)\n    implementation(\"com.querydsl:querydsl-sql:5.1.0\")\n}\n\n\nQueryDSL-SQL 소개:\nQueryDSL-SQL은 JPA 엔티티 모델이 아닌 데이터베이스 스키마를 기반으로 쿼리를 작성할 수 있게 해주는 모듈입니다. JPA가 제공하지 않는 세밀한 SQL 제어(예: Batch Insert, 특정 벤더 전용 구문 등)가 필요할 때 유용하게 사용할 수 있습니다. SQLQueryFactory를 통해 JDBC 레벨의 기능을 Type-Safe하게 사용할 수 있도록 도와줍니다.\n구현 코드 예시#\nSQLQueryFactory를 사용하여 Batch Insert를 구현하는 방법은 다음과 같습니다.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n\n@Service\nclass BatchInsertService(\n    private val dataSource: DataSource\n) {\n    @Transactional\n    fun executeBulkInsertWithSql(members: List<Member>): Long {\n        // 1. 테이블 및 컬럼 메타데이터 정의\n        val memberTable = RelationalPathBase(Member::class.java, \"member\", null, \"member\")\n        val username = Expressions.stringPath(memberTable, \"username\")\n        val age = Expressions.numberPath(Int::class.java, memberTable, \"age\")\n        val status = Expressions.stringPath(memberTable, \"status\")\n        val teamId = Expressions.numberPath(Long::class.java, memberTable, \"team_id\")\n\n        // 2. SQLQueryFactory 생성 (MySQL 템플릿 사용)\n        val sqlQueryFactory = SQLQueryFactory(Configuration(MySQLTemplates()), dataSource)\n\n        val insert = sqlQueryFactory.insert(memberTable)\n\n        // 3. 데이터를 Batch에 추가\n        for (member in members) {\n            insert.set(username, member.username)\n            insert.set(age, member.age)\n            insert.set(status, member.status.name)\n            insert.set(teamId, member.team.id)\n            insert.addBatch() // 메모리에 쿼리 적재\n        }\n\n        // 4. 일괄 실행\n        return insert.execute()\n    }\n}\n\n\n코드 설명\n\nRelationalPathBase: SQL 쿼리 작성을 위해 대상 테이블의 메타데이터를 정의합니다.\naddBatch(): 루프를 돌며 데이터를 즉시 Insert 하지 않고, JDBC의 Batch 기능을 활용하기 위해 메모리에 쿼리 파라미터들을 쌓아둡니다.\nexecute(): 쌓여있는 Batch 쿼리를 데이터베이스로 한 번에 전송하여 실행합니다.\n\nMySQL 최적화 옵션: rewriteBatchedStatements#\nMySQL을 사용하는 경우, JDBC 연결 URL에 rewriteBatchedStatements=true 옵션을 반드시 추가해야 합니다.\n\n\n1\n\njdbc:mysql://localhost:3306/mydb?rewriteBatchedStatements=true\n\n\n이 옵션이 필요한 이유:\n기본적으로 MySQL JDBC 드라이버는 addBatch()로 들어온 쿼리들을 개별적인 Insert 구문으로 전송합니다. 하지만 이 옵션을 활성화하면 드라이버 레벨에서 여러 개의 Insert 구문을 하나의 INSERT INTO ... VALUES (...), (...), (...) 형태의 Multi-Value Insert 구문으로 재작성(Rewrite)하여 전송합니다. 이를 통해 네트워크 패킷 수를 획기적으로 줄이고 데이터베이스의 파싱 비용을 절감하여 성능을 극대화할 수 있습니다.\n성능 비교#\n성능 측정 코드#\n정확한 성능 측정을 위해 saveAll과 QueryDSL addBatch의 실행 시간을 각각 측정했습니다.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n\n    @Test\nfun `saveAll test`() {\n    val rowsList = listOf(100, 200, 500, 1_000, 2_000, 5_000, 10_000)\n    val iterations = 5\n\n    rowsList.forEach { rows ->\n        var totalTimeMillis = 0.0\n        for (i in 1..iterations) {\n            val uniqueWriters = (1..rows).map {\n                Writer(name = \"name-$i-$it\", email = \"email-$i-$it\")\n            }\n\n            val stopWatch = StopWatch()\n            stopWatch.start()\n            writerRepository.saveAll(uniqueWriters)\n            stopWatch.stop()\n\n            if (i > 1) { // 첫 회차 제외\n                totalTimeMillis += stopWatch.totalTimeMillis\n            }\n        }\n        val averageTimeMillis = totalTimeMillis / (iterations - 1)\n        println(\"$rows 건 saveAll 평균 실행 시간: ${averageTimeMillis} ms\")\n    }\n}\n\n@Test\nfun `executeBulkInsertWritersWithSql test`() {\n    val rowsList = listOf(100, 200, 500, 1_000, 2_000, 5_000, 10_000)\n    val iterations = 5\n\n    rowsList.forEach { rows ->\n        var totalTimeMillis = 0.0\n        for (i in 1..iterations) {\n            val uniqueWriters = (1..rows).map {\n                Writer(name = \"name-$i-$it\", email = \"email-$i-$it\")\n            }\n\n            val stopWatch = StopWatch()\n            stopWatch.start()\n            batchInsertService.executeBulkInsertWritersWithSql(uniqueWriters)\n            stopWatch.stop()\n\n            if (i > 1) { // 첫 회차 제외\n                totalTimeMillis += stopWatch.totalTimeMillis\n            }\n        }\n        val averageTimeMillis = totalTimeMillis / (iterations - 1)\n        println(\"$rows 건 QueryDSL Batch Insert 평균 실행 시간: ${averageTimeMillis} ms\")\n    }\n}\n\n\n측정 방식 설명\n\n반복 측정: 각 데이터 구간(100건 ~ 10,000건)마다 총 5회 반복하여 측정했습니다.\nWarm-up 고려: 테스트 실행 시 첫 번째 회차는 결과에서 제외했습니다. 이는 데이터베이스 커넥션 풀(Connection Pool)에서 커넥션을 처음 생성하는 초기 비용 등 초기화 작업에 소요되는 시간이 포함되어 결과가 왜곡되는 것을 방지하기 위함입니다.\n평균값 산출: 첫 회차를 제외한 나머지 4회의 실행 시간을 합산하여 평균값을 산출함으로써 보다 신뢰성 있는 성능 데이터를 얻었습니다.\n\n성능 측정 결과#\n\nJPA saveAll과 QueryDSL addBatch를 사용했을 때의 성능 차이를 비교한 결과입니다. 데이터 개수가 늘어날수록 성능 차이가 확연하게 벌어지는 것을 확인할 수 있습니다.\n\nrowssaveAll (ms)add batch (ms)성능 개선율\n\n1001041288.50%\n200174.51690.80%\n500370.2527.592.60%\n1,0006955691.90%\n2,0001,5746895.70%\n5,0003,77814096.30%\n10,0007,50526596.50%\n\n\nsaveAll: JPA Repository의 saveAll 메서드 사용\nadd batch: QueryDSL SQLQueryFactory의 addBatch 사용\n\n10,000건 기준으로 약 96.5%의 성능 개선 효과가 있었습니다. saveAll이 약 7.5초 걸리는 작업을 Batch Insert로는 0.26초 만에 처리할 수 있습니다.\n결론#\n대량의 데이터를 처리해야 하는 배치성 작업이나 초기 데이터 적재 시에는 JPA의 saveAll보다는 JDBC Batch Insert를 사용하는 것이 필수적입니다.\n특히, 오직 Batch Insert 성능 개선만을 위해 Exposed와 같은 새로운 ORM을 도입하는 것은 프로젝트의 복잡도를 높일 수 있습니다. 이미 JPA와 QueryDSL을 사용 중인 환경이라면, QueryDSL-SQL을 활용하는 것이 추가적인 학습 곡선이나 설정의 번거로움 없이 Type-Safe하게 성능을 극대화할 수 있는 가장 효율적인 대안입니다.\n프로젝트에서 대량 Insert가 필요한 구간이 있다면, 별도의 라이브러리 추가 없이 QueryDSL-SQL을 통해 성능과 생산성을 동시에 챙겨보시기를 권장합니다.",
        "comments": "https://cheese10yun.github.io/querydsl-batch-insert/#disqus_thread",
        "content": "JPA 환경에서 QueryDSL-SQL을 활용해 대량 데이터 삽입 성능을 획기적으로 개선하는 방법을 소개합니다.",
        "contentSnippet": "JPA 환경에서 QueryDSL-SQL을 활용해 대량 데이터 삽입 성능을 획기적으로 개선하는 방법을 소개합니다.",
        "guid": "https://cheese10yun.github.io/querydsl-batch-insert/",
        "categories": [
          {
            "_": "JPA",
            "$": {
              "domain": "https://cheese10yun.github.io/tags/JPA/"
            }
          },
          {
            "_": "ORM",
            "$": {
              "domain": "https://cheese10yun.github.io/tags/ORM/"
            }
          },
          {
            "_": "Performance",
            "$": {
              "domain": "https://cheese10yun.github.io/tags/Performance/"
            }
          },
          {
            "_": "Querydsl",
            "$": {
              "domain": "https://cheese10yun.github.io/tags/Querydsl/"
            }
          }
        ],
        "isoDate": "2026-01-17T15:54:48.000Z"
      }
    ]
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": [
      {
        "creator": "고명환",
        "title": "대표가 알아야하는 2026년 바뀐 기업 정책 총정리 - 창업(스타트업)",
        "link": "https://brunch.co.kr/@@LOc/325",
        "pubDate": "Fri, 16 Jan 2026 07:27:58 GMT",
        "author": "고명환",
        "content": "2026년은 기업 입장에서 한 문장으로 요약하면 이렇습니다.  &quot;규제 준법 이용은 올라가고, 대신 지원금, 정책자금 기회도 커지는 해&quot;  특히 스타트업, 중소기업은 인력과 시간 여력이 제한적이라, 정책 변화가 생기면 '뉴스로만 소비' 하면 손해가 나고 운영 시스템(세무/노무/수출/AI)로 반영해야 실제로 비용을 막고 기회를 잡을 수 있습니다.  오늘 글에서<img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FmMCv0P4u8lE1gLx2HKj6IrZvDBw.png\" width=\"500\" />",
        "contentSnippet": "2026년은 기업 입장에서 한 문장으로 요약하면 이렇습니다.  \"규제 준법 이용은 올라가고, 대신 지원금, 정책자금 기회도 커지는 해\"  특히 스타트업, 중소기업은 인력과 시간 여력이 제한적이라, 정책 변화가 생기면 '뉴스로만 소비' 하면 손해가 나고 운영 시스템(세무/노무/수출/AI)로 반영해야 실제로 비용을 막고 기회를 잡을 수 있습니다.  오늘 글에서",
        "guid": "https://brunch.co.kr/@@LOc/325",
        "isoDate": "2026-01-16T07:27:58.000Z"
      },
      {
        "creator": "고명환",
        "title": "도메인 AI란? 2026년 정부 R&amp;D 지원 확대 흐름 - 창업(스타트업)",
        "link": "https://brunch.co.kr/@@LOc/324",
        "pubDate": "Thu, 15 Jan 2026 04:33:26 GMT",
        "author": "고명환",
        "content": "1. 도메인(Domain AI)란 무엇인가   도메인 AI는 '모든 걸 조금씩 아는 범용 AI'가 아니라, 특정 산업/업무 영역(제조, 의료, 금융, 법무, 물류, 건설, 공동 등)의 데이터, 용어, 규정, 업무 흐름을 깊게 학습/연결해 '현장에서 바로 성과(정확도, 시간절감, 리스크 감소)'를 내는 특화 AI를 말합니다. 예를 들어, 제조 현장의 설비 데<img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FlXHMOAqJ0I1uqeYMPFJviGrpUZA.png\" width=\"500\" />",
        "contentSnippet": "1. 도메인(Domain AI)란 무엇인가   도메인 AI는 '모든 걸 조금씩 아는 범용 AI'가 아니라, 특정 산업/업무 영역(제조, 의료, 금융, 법무, 물류, 건설, 공동 등)의 데이터, 용어, 규정, 업무 흐름을 깊게 학습/연결해 '현장에서 바로 성과(정확도, 시간절감, 리스크 감소)'를 내는 특화 AI를 말합니다. 예를 들어, 제조 현장의 설비 데",
        "guid": "https://brunch.co.kr/@@LOc/324",
        "isoDate": "2026-01-15T04:33:26.000Z"
      },
      {
        "creator": "고명환",
        "title": "초기 스타트업 중진공 정책자금, 브로커 없이 받는 법 - 창업(스타트업)",
        "link": "https://brunch.co.kr/@@LOc/323",
        "pubDate": "Wed, 14 Jan 2026 06:06:04 GMT",
        "author": "고명환",
        "content": "1. 2026 정책자금 브로커 피해 예방법   정책자금은 원칙적으로 중진공 온라인(디지털지점)에서 기업이 직접 신청할 수 있습니다. 그런데도 매년 '정책자금 확정' '심사역 연결' 등을 내세운 브로커 피해가 반복됩니다. 이번 글에서는 브로커를 10초 만에 판별하는 방법과 사장님이 직접 신청으로 안정하게 승인 가능성을 올리는 방법을 체크리스트로 정리합니다. <img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FnxxNbFl2gHmtVEBJeTdijMdBLpo.jpg\" width=\"500\" />",
        "contentSnippet": "1. 2026 정책자금 브로커 피해 예방법   정책자금은 원칙적으로 중진공 온라인(디지털지점)에서 기업이 직접 신청할 수 있습니다. 그런데도 매년 '정책자금 확정' '심사역 연결' 등을 내세운 브로커 피해가 반복됩니다. 이번 글에서는 브로커를 10초 만에 판별하는 방법과 사장님이 직접 신청으로 안정하게 승인 가능성을 올리는 방법을 체크리스트로 정리합니다.",
        "guid": "https://brunch.co.kr/@@LOc/323",
        "isoDate": "2026-01-14T06:06:04.000Z"
      }
    ]
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "텍스트,영상,이미지 넘어 '오디오'까지! 2026년, AI 콘텐츠 정복 로드맵 (무료 도구 편)",
        "link": "https://muzbox.tistory.com/483701",
        "pubDate": "Sun, 18 Jan 2026 16:52:49 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "https://muzbox.tistory.com/483701#entry483701comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #3c4043;\">\n<div style=\"background-color: #e8f4fd; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">텍스트, 영상, 이미지까지 정복했다면, 이제 '오디오' 차례입니다! 비싼 유료 서비스에 지치셨나요? 2026년 최신 AI 무료 오디오 도구 3종으로 회의록 작성, 음악 마스터링, 음성 합성을 여러분의 PC에서 비용 걱정 없이 해결하세요.</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/cgTwSw/dJMcajgDZFG/heEBbeWQHHPYzbTKgT7Aa0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cgTwSw/dJMcajgDZFG/heEBbeWQHHPYzbTKgT7Aa0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cgTwSw/dJMcajgDZFG/heEBbeWQHHPYzbTKgT7Aa0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcgTwSw%2FdJMcajgDZFG%2FheEBbeWQHHPYzbTKgT7Aa0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"AI 기술로 음성 분석, 음악 마스터링, 음성 합성을 무료로 할 수 있는 미래형 오디오 콘텐츠 제작 도구들을 나타내는 이미지.\" loading=\"lazy\" width=\"500\" height=\"500\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  AI 콘텐츠 정복, 오디오가 마지막 퍼즐!</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">여러분, 2026년 현재 우리는 이미 AI로 텍스트, 영상, 이미지 콘텐츠 영역을 사실상 정복했습니다. 그런데 유독 오디오 앞에서만 막막함을 느꼈던 분들 많으시죠? 비싼 TTS 비용, 복잡한 마스터링, 수동 회의록 작성의 번거로움&hellip; 이제 그 모든 걱정을 내려놓으세요! 오늘은 돈 한 푼 들이지 않고 여러분의 PC에서 이 모든 오디오 작업을 해결할 수 있는 <b>유료급 AI 무료 도구 3가지</b>를 소개해 드릴 겁니다. 제가 직접 써보니, 정말 놀라움의 연속이었어요. 음성 분석부터 음악 마스터링, 고품질 음성 합성까지, 이 강력한 도구들과 함께 오디오 콘텐츠 제작의 신세계를 경험해 보세요!</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  AI 오디오 랩: 음성&amp;음악, 심층 분석 웹 앱</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">첫 번째 도구는 <b>AI 오디오 랩</b>입니다. 회의 녹음이나 음악 파일을 분석해야 할 때, 내용을 정리하거나 구조를 파악하는 일이 정말 고역이죠? AI 오디오 랩은 이런 작업을 자동으로 처리해주는 <b>웹 기반 도구</b>입니다. 구글의 제미나이 AI와 브라우저의 웹 오디오 API를 결합해, 오디오의 텍스트 내용과 기술적인 신호 데이터를 동시에 분석해줍니다. 별도 설치 없이 브라우저에서 바로 사용 가능해서 정말 편리해요.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1454\" data-origin-height=\"859\"><span data-url=\"https://blog.kakaocdn.net/dn/ONCzi/dJMcabCW2Vq/atSzPtIYrenIB2kCKgm8w1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ONCzi/dJMcabCW2Vq/atSzPtIYrenIB2kCKgm8w1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/ONCzi/dJMcabCW2Vq/atSzPtIYrenIB2kCKgm8w1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FONCzi%2FdJMcabCW2Vq%2FatSzPtIYrenIB2kCKgm8w1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1454\" height=\"859\" data-origin-width=\"1454\" data-origin-height=\"859\"/></span></figure>\n\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>회의록 자동 작성! 음성 인텔리전스 기능</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">음성 파일을 업로드하고 '분석 시작' 버튼을 누르면, 놀라운 음성 인텔리전스 리포트가 생성됩니다. 화자 수, 언어, 재생 시간은 기본이고, 전체 대화의 <b>핵심 요약</b>, <b>화자별 발언 분석</b>, <b>참여율 차트</b>까지 제공됩니다. 특히 화자별로 정리된 대화 기록은 시간까지 표시되어 필요한 부분을 찾기 용이해요. 이제 클릭 한 번으로 완벽한 비즈니스 문서를 마크다운이나 PDF로 다운로드해 공유할 수 있으니, 회의록 작성 시간은 확 줄어들 겁니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>음악의 모든 것을 파헤치다! 뮤직 딥 다이브 기능</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">음악 분석 기능도 강력합니다. 음악 파일을 업로드하면 장르, 키(Key), BPM은 물론 <b>오디오 품질 분석</b>, <b>스템 분석</b>(보컬, 베이스, 드럼 등 파트별 특징) 결과까지 상세히 보여줍니다. 심지어 <b>Suno AI 프롬프트가 자동 생성</b>되어 비슷한 음악을 만들 수도 있어요. '신호처리' 탭에서는 오디오 파형의 시간 시리즈, MFCC, 크로마 차트 등을 통해 소리의 물리적 실체를 데이터로 확인할 수 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">&nbsp;</p>\n<figure id=\"og_1768722038140\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"GPT PARK's AI Audio Lab\" data-og-description=\"\" data-og-host=\"gpt-park-ai-audio-lab.vercel.app\" data-og-source-url=\"https://gpt-park-ai-audio-lab.vercel.app/\" data-og-url=\"https://gpt-park-ai-audio-lab.vercel.app/\" data-og-image=\"\"><a href=\"https://gpt-park-ai-audio-lab.vercel.app/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://gpt-park-ai-audio-lab.vercel.app/\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">GPT PARK's AI Audio Lab</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">&nbsp;</p>\n<p class=\"og-host\" data-ke-size=\"size16\">gpt-park-ai-audio-lab.vercel.app</p>\n</div>\n</a></figure>\n<figure class=\"fileblock\" data-ke-align=\"alignCenter\"><a href=\"https://blog.kakaocdn.net/dn/qIW4n/dJMcabiFaYj/Td537lDEHuWZZkRqLosT81/AI%20AUDIO%20LAB%20%EC%A0%9C%EC%9E%91%20%ED%94%84%EB%A1%AC%ED%94%84%ED%8A%B8.txt?attach=1&amp;knm=tfile.txt\" class=\"\">\n    <div class=\"image\"></div>\n    <div class=\"desc\"><div class=\"filename\"><span class=\"name\">AI AUDIO LAB 제작 프롬프트.txt</span></div>\n<div class=\"size\">0.00MB</div>\n</div>\n  </a></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b> ️ Mastering Studio: 내 PC에서 전문가급 마스터링</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">두 번째 도구는 <b>Mastering Studio</b>입니다. 음악 마스터링, 비싼 비용과 복잡함 때문에 망설이셨죠? 이 앱은 구글 Gemini AI와 브라우저 오디오 처리 기술로 <b>여러분의 컴퓨터에서 직접 마스터링</b>을 해줍니다. 파일을 서버로 전송할 필요 없어 보안 걱정도 없고요. 역시 설치가 필요 없는 웹 앱이라 아주 편리해요.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1751\" data-origin-height=\"917\"><span data-url=\"https://blog.kakaocdn.net/dn/n94iM/dJMcabbSRJW/j92vkG77sr34HSO2jb9dtk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/n94iM/dJMcabbSRJW/j92vkG77sr34HSO2jb9dtk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/n94iM/dJMcabbSRJW/j92vkG77sr34HSO2jb9dtk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fn94iM%2FdJMcabbSRJW%2Fj92vkG77sr34HSO2jb9dtk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1751\" height=\"917\" data-origin-width=\"1751\" data-origin-height=\"917\"/></span></figure>\n\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px;\" data-ke-size=\"size23\"><b>AI가 만들어주는 맞춤형 마스터링</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">오디오 파일을 업로드하면 마스터링을 시작할 수 있습니다. <b>12가지 사운드 프로필 프리셋</b> 중에서 선택하거나, <b>AI 로직 생성기</b>를 활용해 보세요. 텍스트로 원하는 사운드를 설명하면 AI가 그에 맞춰 마스터링해줍니다! 원본과 마스터링된 파형을 비교해 볼 수도 있어요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">마스터링 후에는 <b>정밀 마스터링 랙</b>에서 이퀄라이저, 아날로그 새츄레이션, 컴프레서 등 전문가급 도구로 세밀하게 조정할 수 있습니다. 무료 베이직 버전에는 일부 프로필과 AI 로직 생성 기능에 제한이 있지만, 이 정도 퀄리티의 마스터링을 무료로 쓸 수 있다는 건 정말 놀랍습니다.</p>\n<div style=\"background-color: #fce8e6; border-left: 4px solid #d93025; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">⚠️ <b>참고:</b> Mastering Studio의 AI 로직 생성 및 12개 사운드 프로필 전체 이용은 프로 버전(유튜브 멤버십 전용)에서만 가능합니다.</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">&nbsp;</p>\n<figure id=\"og_1768722340017\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"GPT PARK's Mastering Studio\" data-og-description=\"\" data-og-host=\"gpt-park-mastering-studio-basic.vercel.app\" data-og-source-url=\"https://gpt-park-mastering-studio-basic.vercel.app/\" data-og-url=\"https://gpt-park-mastering-studio-basic.vercel.app/\" data-og-image=\"\"><a href=\"https://gpt-park-mastering-studio-basic.vercel.app/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://gpt-park-mastering-studio-basic.vercel.app/\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">GPT PARK's Mastering Studio</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">&nbsp;</p>\n<p class=\"og-host\" data-ke-size=\"size16\">gpt-park-mastering-studio-basic.vercel.app</p>\n</div>\n</a></figure>\n<figure class=\"fileblock\" data-ke-align=\"alignCenter\"><a href=\"https://blog.kakaocdn.net/dn/lZ80h/dJMcadnblIB/dgY7rEowy6h7VjUQoo4aOK/Mastering%20Studio%20%EC%A0%9C%EC%9E%91%20%ED%94%84%EB%A1%AC%ED%94%84%ED%8A%B8.txt?attach=1&amp;knm=tfile.txt\" class=\"\">\n    <div class=\"image\"></div>\n    <div class=\"desc\"><div class=\"filename\"><span class=\"name\">Mastering Studio 제작 프롬프트.txt</span></div>\n<div class=\"size\">0.00MB</div>\n</div>\n  </a></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b> ️ Supertonic2 TTS: 무제한 무료 음성 합성의 혁명</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">마지막은 <b>Supertonic2 TTS</b>입니다. 고품질 TTS 서비스의 API 비용이 부담스러우셨죠? Supertonic2 TTS는 깃허브에 오픈소스로 공개된 초고속 온디바이스 TTS 소스를 기반으로 제작된, <b>완전 무료 로컬 음성 합성 프로그램</b>입니다. API 호출 없이 여러분의 PC에서 직접 음성을 생성하기 때문에, 몇 번을 사용하든 비용은 0원! 심지어 MIT 라이선스 기반이라 상업적 이용까지 가능합니다. 다운로드 후 바로 실행되는 EXE 파일이라 설치 걱정도 없고요.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1141\" data-origin-height=\"682\"><span data-url=\"https://blog.kakaocdn.net/dn/b60Nqw/dJMcabCW2Rn/YtybHX4VolGZ6oLutnce50/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/b60Nqw/dJMcabCW2Rn/YtybHX4VolGZ6oLutnce50/img.png\"><img src=\"https://blog.kakaocdn.net/dn/b60Nqw/dJMcabCW2Rn/YtybHX4VolGZ6oLutnce50/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb60Nqw%2FdJMcabCW2Rn%2FYtybHX4VolGZ6oLutnce50%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1141\" height=\"682\" data-origin-width=\"1141\" data-origin-height=\"682\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">깔끔한 다크 테마 인터페이스에서 언어, 목소리, 속도, 품질(5단계)을 조절한 뒤, 텍스트를 입력하고 'Generate Speech' 버튼만 누르면 음성 생성이 완료됩니다. 원하는 음성을 WAV 파일로 저장할 수 있습니다. 혹시 처음 실행 시 오류가 발생해도, 함께 제공되는 배치파일(fix_dll_error.bat)로 쉽게 해결 가능하니 염려 마세요! 이 도구 하나면 여러분의 콘텐츠에 무제한으로 고품질 음성을 더할 수 있습니다.</p>\n<figure id=\"og_1768722414949\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"Supertonic2TTS.zip\" data-og-description=\"\" data-og-host=\"drive.google.com\" data-og-source-url=\"https://drive.google.com/file/d/1sAa-lJlM2uEshIfv0Ojje8KCAUeg_BYh/view?usp=sharing\" data-og-url=\"https://drive.google.com/file/d/1sAa-lJlM2uEshIfv0Ojje8KCAUeg_BYh/view?usp=sharing&amp;usp=embed_facebook\" data-og-image=\"\"><a href=\"https://drive.google.com/file/d/1sAa-lJlM2uEshIfv0Ojje8KCAUeg_BYh/view?usp=sharing\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://drive.google.com/file/d/1sAa-lJlM2uEshIfv0Ojje8KCAUeg_BYh/view?usp=sharing\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Supertonic2TTS.zip</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">&nbsp;</p>\n<p class=\"og-host\" data-ke-size=\"size16\">drive.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<div style=\"background-color: #f8f9fa; border: 1px solid #dadce0; border-radius: 8px; padding: 25px; margin: 40px 0; box-shadow: 0 4px 12px rgba(0,0,0,0.1);\">\n<div style=\"font-size: 26px; color: #1a73e8; font-weight: bold; margin-bottom: 15px; padding-bottom: 10px; border-bottom: 1px solid #1a73e8;\">  <b>핵심 요약</b></div>\n<ul style=\"list-style: none; padding: 0; margin: 0;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 15px; font-size: 17px;\"><b>1. AI 오디오 랩:</b> 음성 및 음악 파일 심층 분석으로 회의록, 음악 프로듀싱 혁신 (웹 기반, 무료).</li>\n<li style=\"margin-bottom: 15px; font-size: 17px;\"><b>2. Mastering Studio:</b> 내 PC에서 전문가급 마스터링! AI 로직 생성기로 사운드 구현 (무료 베이직 제한).</li>\n<li style=\"margin-bottom: 0; font-size: 17px;\"><b>3. Supertonic2 TTS:</b> API 비용 0원! 무제한 고품질 음성 합성, 상업적 이용 가능 (로컬 프로그램).</li>\n</ul>\n<div style=\"margin-top: 25px; padding-top: 15px; border-top: 1px solid #eee; font-size: 14px; color: #5f6368;\">2026년, AI 오디오 로드맵과 함께 더욱 풍부한 콘텐츠를 만들어가세요!</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q1: 소개된 AI 오디오 도구들은 정말 무료인가요?</b><br />A1: 네, AI 오디오 랩, Mastering Studio (베이직 버전), Supertonic2 TTS는 모두 무료입니다. Mastering Studio의 AI 마스터링 기능 등 일부 고급 기능은 유튜브 멤버십 프로 버전에서만 제공됩니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q2: 프로그램 설치는 어떻게 하나요?</b><br />A2: AI 오디오 랩과 Mastering Studio는 웹 기반이라 설치가 필요 없으며, Supertonic2 TTS는 EXE 파일이라 다운로드 후 바로 실행 가능합니다. 초기 오류 시 제공되는 배치 파일로 쉽게 해결됩니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q3: Supertonic2 TTS 음성을 상업적으로 이용할 수 있나요?</b><br />A3: 네, MIT 라이선스 기반으로 제작되어 유튜브, 교육, 상업 프로젝트 등 모든 콘텐츠에 자유롭게 활용 가능합니다.</p>\n<script type=\"application/ld+json\">\n    {\n      \"@context\": \"https://schema.org\",\n      \"@type\": \"FAQPage\",\n      \"mainEntity\": [\n        {\n          \"@type\": \"Question\",\n          \"name\": \"소개된 AI 오디오 도구들은 정말 무료인가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"네, AI 오디오 랩, Mastering Studio (베이직 버전), Supertonic2 TTS는 모두 무료입니다. Mastering Studio의 AI 마스터링 기능 등 일부 고급 기능은 유튜브 멤버십 프로 버전에서만 제공됩니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"프로그램 설치는 어떻게 하나요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"AI 오디오 랩과 Mastering Studio는 웹 기반이라 설치가 필요 없으며, Supertonic2 TTS는 EXE 파일이라 다운로드 후 바로 실행 가능합니다. 초기 오류 시 제공되는 배치 파일로 쉽게 해결됩니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"Supertonic2 TTS 음성을 상업적으로 이용할 수 있나요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"네, MIT 라이선스 기반으로 제작되어 유튜브, 교육, 상업 프로젝트 등 모든 콘텐츠에 자유롭게 활용 가능합니다.\"\n          }\n        }\n      ]\n    }\n    </script>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">&nbsp;</p>\n</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=SqtccsojSeM\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/Er4gd/dJMb87NP1Dd/jNahgsT6NVH3xpcO4LsfN1/img.jpg?width=1280&amp;height=720&amp;face=858_328_1002_484\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"유료 결제 취소하세요. 월 10만 원 아껴주는 역대급 무료 AI 오디오 도구 3종\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/SqtccsojSeM\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "텍스트, 영상, 이미지까지 정복했다면, 이제 '오디오' 차례입니다! 비싼 유료 서비스에 지치셨나요? 2026년 최신 AI 무료 오디오 도구 3종으로 회의록 작성, 음악 마스터링, 음성 합성을 여러분의 PC에서 비용 걱정 없이 해결하세요.\n\n\n  AI 콘텐츠 정복, 오디오가 마지막 퍼즐!\n여러분, 2026년 현재 우리는 이미 AI로 텍스트, 영상, 이미지 콘텐츠 영역을 사실상 정복했습니다. 그런데 유독 오디오 앞에서만 막막함을 느꼈던 분들 많으시죠? 비싼 TTS 비용, 복잡한 마스터링, 수동 회의록 작성의 번거로움… 이제 그 모든 걱정을 내려놓으세요! 오늘은 돈 한 푼 들이지 않고 여러분의 PC에서 이 모든 오디오 작업을 해결할 수 있는 유료급 AI 무료 도구 3가지를 소개해 드릴 겁니다. 제가 직접 써보니, 정말 놀라움의 연속이었어요. 음성 분석부터 음악 마스터링, 고품질 음성 합성까지, 이 강력한 도구들과 함께 오디오 콘텐츠 제작의 신세계를 경험해 보세요!\n  AI 오디오 랩: 음성&음악, 심층 분석 웹 앱\n첫 번째 도구는 AI 오디오 랩입니다. 회의 녹음이나 음악 파일을 분석해야 할 때, 내용을 정리하거나 구조를 파악하는 일이 정말 고역이죠? AI 오디오 랩은 이런 작업을 자동으로 처리해주는 웹 기반 도구입니다. 구글의 제미나이 AI와 브라우저의 웹 오디오 API를 결합해, 오디오의 텍스트 내용과 기술적인 신호 데이터를 동시에 분석해줍니다. 별도 설치 없이 브라우저에서 바로 사용 가능해서 정말 편리해요.\n\n\n회의록 자동 작성! 음성 인텔리전스 기능\n음성 파일을 업로드하고 '분석 시작' 버튼을 누르면, 놀라운 음성 인텔리전스 리포트가 생성됩니다. 화자 수, 언어, 재생 시간은 기본이고, 전체 대화의 핵심 요약, 화자별 발언 분석, 참여율 차트까지 제공됩니다. 특히 화자별로 정리된 대화 기록은 시간까지 표시되어 필요한 부분을 찾기 용이해요. 이제 클릭 한 번으로 완벽한 비즈니스 문서를 마크다운이나 PDF로 다운로드해 공유할 수 있으니, 회의록 작성 시간은 확 줄어들 겁니다.\n음악의 모든 것을 파헤치다! 뮤직 딥 다이브 기능\n음악 분석 기능도 강력합니다. 음악 파일을 업로드하면 장르, 키(Key), BPM은 물론 오디오 품질 분석, 스템 분석(보컬, 베이스, 드럼 등 파트별 특징) 결과까지 상세히 보여줍니다. 심지어 Suno AI 프롬프트가 자동 생성되어 비슷한 음악을 만들 수도 있어요. '신호처리' 탭에서는 오디오 파형의 시간 시리즈, MFCC, 크로마 차트 등을 통해 소리의 물리적 실체를 데이터로 확인할 수 있습니다.\n \n \n\n \nGPT PARK's AI Audio Lab\n \ngpt-park-ai-audio-lab.vercel.app\n\n\n    \n\n    \nAI AUDIO LAB 제작 프롬프트.txt\n0.00MB\n\n\n \n ️ Mastering Studio: 내 PC에서 전문가급 마스터링\n두 번째 도구는 Mastering Studio입니다. 음악 마스터링, 비싼 비용과 복잡함 때문에 망설이셨죠? 이 앱은 구글 Gemini AI와 브라우저 오디오 처리 기술로 여러분의 컴퓨터에서 직접 마스터링을 해줍니다. 파일을 서버로 전송할 필요 없어 보안 걱정도 없고요. 역시 설치가 필요 없는 웹 앱이라 아주 편리해요.\n\n\nAI가 만들어주는 맞춤형 마스터링\n오디오 파일을 업로드하면 마스터링을 시작할 수 있습니다. 12가지 사운드 프로필 프리셋 중에서 선택하거나, AI 로직 생성기를 활용해 보세요. 텍스트로 원하는 사운드를 설명하면 AI가 그에 맞춰 마스터링해줍니다! 원본과 마스터링된 파형을 비교해 볼 수도 있어요.\n \n마스터링 후에는 정밀 마스터링 랙에서 이퀄라이저, 아날로그 새츄레이션, 컴프레서 등 전문가급 도구로 세밀하게 조정할 수 있습니다. 무료 베이직 버전에는 일부 프로필과 AI 로직 생성 기능에 제한이 있지만, 이 정도 퀄리티의 마스터링을 무료로 쓸 수 있다는 건 정말 놀랍습니다.\n⚠️ 참고: Mastering Studio의 AI 로직 생성 및 12개 사운드 프로필 전체 이용은 프로 버전(유튜브 멤버십 전용)에서만 가능합니다.\n \n\n \nGPT PARK's Mastering Studio\n \ngpt-park-mastering-studio-basic.vercel.app\n\n\n    \n\n    \nMastering Studio 제작 프롬프트.txt\n0.00MB\n\n\n ️ Supertonic2 TTS: 무제한 무료 음성 합성의 혁명\n마지막은 Supertonic2 TTS입니다. 고품질 TTS 서비스의 API 비용이 부담스러우셨죠? Supertonic2 TTS는 깃허브에 오픈소스로 공개된 초고속 온디바이스 TTS 소스를 기반으로 제작된, 완전 무료 로컬 음성 합성 프로그램입니다. API 호출 없이 여러분의 PC에서 직접 음성을 생성하기 때문에, 몇 번을 사용하든 비용은 0원! 심지어 MIT 라이선스 기반이라 상업적 이용까지 가능합니다. 다운로드 후 바로 실행되는 EXE 파일이라 설치 걱정도 없고요.\n\n\n \n깔끔한 다크 테마 인터페이스에서 언어, 목소리, 속도, 품질(5단계)을 조절한 뒤, 텍스트를 입력하고 'Generate Speech' 버튼만 누르면 음성 생성이 완료됩니다. 원하는 음성을 WAV 파일로 저장할 수 있습니다. 혹시 처음 실행 시 오류가 발생해도, 함께 제공되는 배치파일(fix_dll_error.bat)로 쉽게 해결 가능하니 염려 마세요! 이 도구 하나면 여러분의 콘텐츠에 무제한으로 고품질 음성을 더할 수 있습니다.\n\n \nSupertonic2TTS.zip\n \ndrive.google.com\n\n \n  핵심 요약\n1. AI 오디오 랩: 음성 및 음악 파일 심층 분석으로 회의록, 음악 프로듀싱 혁신 (웹 기반, 무료).\n2. Mastering Studio: 내 PC에서 전문가급 마스터링! AI 로직 생성기로 사운드 구현 (무료 베이직 제한).\n3. Supertonic2 TTS: API 비용 0원! 무제한 고품질 음성 합성, 상업적 이용 가능 (로컬 프로그램).\n2026년, AI 오디오 로드맵과 함께 더욱 풍부한 콘텐츠를 만들어가세요!\n❓ 자주 묻는 질문 (FAQ)\nQ1: 소개된 AI 오디오 도구들은 정말 무료인가요?\nA1: 네, AI 오디오 랩, Mastering Studio (베이직 버전), Supertonic2 TTS는 모두 무료입니다. Mastering Studio의 AI 마스터링 기능 등 일부 고급 기능은 유튜브 멤버십 프로 버전에서만 제공됩니다.\nQ2: 프로그램 설치는 어떻게 하나요?\nA2: AI 오디오 랩과 Mastering Studio는 웹 기반이라 설치가 필요 없으며, Supertonic2 TTS는 EXE 파일이라 다운로드 후 바로 실행 가능합니다. 초기 오류 시 제공되는 배치 파일로 쉽게 해결됩니다.\nQ3: Supertonic2 TTS 음성을 상업적으로 이용할 수 있나요?\nA3: 네, MIT 라이선스 기반으로 제작되어 유튜브, 교육, 상업 프로젝트 등 모든 콘텐츠에 자유롭게 활용 가능합니다.",
        "guid": "https://muzbox.tistory.com/483701",
        "categories": [
          "AI, 미래기술/AI 챗봇 및 지침 무료 배포",
          "2026 AI 콘텐츠 로드맵",
          "AI 오디오",
          "AI 오디오 랩",
          "ai 음성 합성",
          "AI 음악 마스터링",
          "ai 회의록",
          "Mastering Studio",
          "Supertonic2 TTS",
          "무료 AI 도구",
          "온디바이스 tts"
        ],
        "isoDate": "2026-01-18T07:52:49.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "'생각의 수준'을 높이는 8가지 브레인스토밍 프롬프트",
        "link": "https://muzbox.tistory.com/483700",
        "pubDate": "Fri, 16 Jan 2026 08:34:44 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "https://muzbox.tistory.com/483700#entry483700comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #212121;\">\n<div style=\"background-color: #e8f5e9; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">\n<p style=\"margin-bottom: 0;\" data-ke-size=\"size16\">여러분은 브레인스토밍을 할 때 막막함을 느끼시나요? 방대한 아이디어가 필요한데 어디서부터 시작해야 할지 모르겠다고요? 2026년, 이제 ChatGPT는 단순한 정보 제공자를 넘어 여러분의 <b>'생각의 수준'을 한 차원 높여줄 유능한 브레인스토밍 파트너</b>가 될 수 있습니다. 오늘은 제가 직접 사용하며 효과를 본, 창의적인 사고를 돕는 8가지 ChatGPT 프롬프트를 공개합니다. 평범한 아이디어를 벗어나 실용적이고 깊이 있는 통찰력을 얻고 싶은 분들을 위해 준비했어요.</p>\n</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/5dW8u/dJMcac9DEe0/4sKie3rjLmr5A4JovC3jj1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/5dW8u/dJMcac9DEe0/4sKie3rjLmr5A4JovC3jj1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/5dW8u/dJMcac9DEe0/4sKie3rjLmr5A4JovC3jj1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F5dW8u%2FdJMcac9DEe0%2F4sKie3rjLmr5A4JovC3jj1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"노트북 화면 속 ChatGPT와 함께 아이디어를 발상하고 정리하는 모습. 현대적인 작업 공간에서 자연 친화적인 초록색과 따뜻한 빛이 어우러져 창의적인 분위기를 연출합니다.\" loading=\"lazy\" width=\"500\" height=\"500\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">솔직히 말하면, 우리는 ChatGPT를 너무 쉽게 생각하는 경향이 있는 것 같아요. 그냥 질문을 던지면 답을 뱉어내는 <b>'아이디어 자판기'</b>처럼 말이죠. 하지만 제가 직접 겪어보니, 제대로 활용하면 정말 놀라운 <b>'브레인스토밍 파트너'</b>가 될 수 있다는 걸 깨달았습니다. 우리가 머리를 쥐어짜며 생각의 흐름을 만들 때, ChatGPT는 그 아이디어의 <b>볼륨과 구조를 잡아주는 역할</b>을 톡톡히 해내죠. 제가 오랫동안 마케팅과 웹 개발 분야에서 일하며 숱하게 브레인스토밍을 해왔는데, 최근 챗GPT와 함께하면서 아이디어의 명확성과 범위가 확연히 넓어지는 것을 경험하고 있습니다. 수많은 선배들의 지혜와 레딧 같은 커뮤니티에서 얻은 영감을 바탕으로, 퍼져 있던 생각들을 <b>실행 가능한 아이디어</b>로 다듬는 데 최적화된 프롬프트 8가지를 소개할게요. 저의 뉴스레터를 장기적으로 흥미롭게 유지하는 방법이라는 주제로 같이 고민해보면 더 와닿으실 거예요.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>1. 맥락을 이해시키는 것부터 시작하세요: 일반적인 아이디어를 피하는 첫걸음</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">아무리 인공지능이라도 우리 마음을 꿰뚫어 볼 수는 없잖아요? 그래서 저는 항상 브레인스토밍 세션을 시작하기 전에 ChatGPT에게 <b>명확한 지침</b>을 줍니다. 마치 유능한 팀원에게 프로젝트 브리핑을 하듯이요. 이 <b>'핵심 프롬프트'</b>는 전체 대화의 틀을 잡고, 챗GPT가 뻔하거나 피상적인 아이디어를 내놓는 걸 미리 방지해 주는 역할을 해요. 복잡한 콘텐츠 기획이나 개인적인 목표 설정 같은 작업에 특히 유용하더라고요. 처음부터 이렇게 세부적으로 조율해두면 나중에 불필요한 노력을 훨씬 줄일 수 있습니다. 핵심은 <b>맥락, 명확성, 그리고 의도</b>라는 점, 잊지 마세요!</p>\n<div style=\"background-color: #e8f5e9; border-left: 4px solid #2e7d32; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">\n<p style=\"margin-bottom: 5px; color: #212121;\" data-ke-size=\"size16\">  <b>프롬프트 활용 팁:</b></p>\n<ul style=\"list-style-type: disc; margin-left: 20px; padding-left: 0; color: #212121;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>Goal(목표)</b>: 최종적으로 무엇을 얻고 싶은지 명확히 하세요.</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>Context(맥락)</b>: 대상, 제약 조건, 시간, 자원 등 배경 정보를 상세히 설명하세요.</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>Process(과정)</b>: 어떤 방식으로 진행할지 (예: 질문 개수, 프레임워크 제안 등) 구체적으로 알려주세요.</li>\n</ul>\n</div>\n<div style=\"background-color: #f1f8e9; border: 1px solid #a5d6a7; padding: 15px; margin: 20px 0; border-radius: 8px; overflow-x: auto;\">\n<pre class=\"prolog\" style=\"margin: 0; padding: 0; white-space: pre-wrap; word-wrap: break-word;\"><code>당신은 저의 구조화된 브레인스토밍 파트너입니다.\n목표: [주제/문제/결과물 설명]에 대해 브레인스토밍하는 것을 도와주세요.\n맥락: [대상, 제약 조건, 기한, 자원].\n과정: 최대 5개의 명확화 질문을 하나씩 해주세요.\n사용할 수 있는 3-5가지의 다른 브레인스토밍 프레임워크를 제안해주세요 (예: SCAMPER, 마인드맵, 가정, 제약, 첫 번째 원칙).\n제가 하나를 선택하면, 간결하고 번호가 매겨진 목록으로 브레인스토밍을 안내해주세요. 이때 구체성과 실용성을 목표로 합니다.\n궁극적으로, 최고의 아이디어를 3-5가지 테마로 분류하고 구체적인 다음 단계를 제안해주세요.\n간결한 글머리 기호를 사용하고 일반적인 조언은 피해주세요.\n        </code></pre>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>2. 다양한 아이디어로 물꼬를 트세요: 양으로 승부하는 발산적 사고</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">아이디어가 막힐 때 가장 빠르고 확실한 방법은 <b>일단 많은 아이디어를 쏟아내는 것</b>이라고 생각해요. 심지어 좀 터무니없는 아이디어라도 괜찮아요! 초기 단계에서는 아이디어의 질보다는 <b>속도와 범위</b>가 훨씬 중요합니다. 이 프롬프트는 ChatGPT와 우리 뇌의 시동을 거는 역할을 해요. 나중에 걸러내고 우선순위를 정하는 건 그때 가서 해도 늦지 않습니다.</p>\n<div style=\"background-color: #e8f5e9; border-left: 4px solid #2e7d32; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">\n<p style=\"margin-bottom: 5px; color: #212121;\" data-ke-size=\"size16\">  <b>뉴스레터 아이디어 적용 예시:</b></p>\n<ul style=\"list-style-type: disc; margin-left: 20px; padding-left: 0; color: #212121;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px; color: #212121;\">뉴스레터의 메인 콘텐츠를 짧은 숏폼 비디오로 전환 (요즘 대세죠!)</li>\n<li style=\"margin-bottom: 5px; color: #212121;\">구독자들이 직접 참여하는 '익명 고민 상담소' 코너 운영</li>\n<li style=\"margin-bottom: 5px; color: #212121;\">매주 다른 분야의 전문가를 초대해 인터뷰 시리즈 진행</li>\n</ul>\n</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">프롬프트의 마지막 단계가 정말 중요해요. <b>'가장 유망한 아이디어 5가지 표시'</b>가 없다면, 그냥 방치되는 목록으로 끝나버릴 수도 있거든요. 번호가 매겨진 목록은 나중에 특정 아이디어를 참조할 때도 편리하고요. 개인적인 경험으로는, 종종 <b>목록의 뒷부분에 숨어있는 기발한 아이디어</b>들이 많았습니다. ChatGPT와 마인드맵 도구를 함께 사용하면 아이디어 간의 연관성을 찾는 데 큰 도움이 될 거예요.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/cx30E5/dJMcacaMVhh/WZnipYK02qn5cczWiglkPK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cx30E5/dJMcacaMVhh/WZnipYK02qn5cczWiglkPK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cx30E5/dJMcacaMVhh/WZnipYK02qn5cczWiglkPK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fcx30E5%2FdJMcacaMVhh%2FWZnipYK02qn5cczWiglkPK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"카오스에서 질서로 변하는 발산적 사고의 흐름을 보여주는 이미지. 어지러운 아이디어들이 챗GPT의 도움으로 점차 구조화되는 모습을 초록색 계열로 표현했습니다.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<div style=\"background-color: #f1f8e9; border: 1px solid #a5d6a7; padding: 15px; margin: 20px 0; border-radius: 8px; overflow-x: auto;\">\n<pre class=\"prolog\" style=\"margin: 0; padding: 0; white-space: pre-wrap; word-wrap: break-word;\"><code>[주제]에 대해 발산적 브레인스토밍을 해봅시다.\n제약 조건: [예산/시간/산업/대상/기타].\n1단계: 명확한 것부터 파격적인 것까지 20가지의 빠르고 대략적인 아이디어를 번호가 매겨진 목록으로 생성해주세요.\n2단계: 각 아이디어에 대해 왜 효과적일 수 있는지에 대한 짧은 문구를 추가해주세요.\n3단계: 영향력 대비 노력 측면에서 가장 유망해 보이는 5가지 아이디어를 표시해주세요.\n        </code></pre>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>3. 역 브레인스토밍으로 숨겨진 문제점 찾기: 실패를 통해 성공 배우기</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">생각해보니, 성공하는 방법만 고민할 필요는 없더라고요. <b>역 브레인스토밍(Reverse Brainstorming)</b>은 문제를 뒤집어서 '어떻게 하면 실패할 수 있을까?'를 묻는 기법입니다. 마치 일이 터지기 전에 미리 사후 검토(Pre-mortem)를 하는 것과 비슷하죠. 저는 이 프롬프트를 통해 어떤 아이디어가 <b>'괜찮긴 한데 뭔가 부족하다'</b>고 느껴질 때 그 이유를 파악하는 데 활용합니다.</p>\n<div style=\"background-color: #fffde7; border-left: 4px solid #fbc02d; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">\n<p style=\"margin-bottom: 5px; color: #212121;\" data-ke-size=\"size16\">⚠️ <b>뉴스레터 아이디어 적용 예시 (역발상):</b></p>\n<ul style=\"list-style-type: disc; margin-left: 20px; padding-left: 0; color: #212121;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>문제:</b> 뉴스레터 이탈률을 높이는 방법은?</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>해결책:</b> 과도한 광고 삽입 (뒤집으면: 광고를 최소화하고 콘텐츠 집중)</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>해결책:</b> 매주 비슷한 내용만 반복 (뒤집으면: 다양한 형식과 주제로 신선함 유지)</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>해결책:</b> 발행 주기를 불규칙하게 (뒤집으면: 일관된 발행 주기 유지)</li>\n</ul>\n</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 프롬프트는 약한 아이디어와 흔한 실수를 빠르게 파악하게 해줘요. 만약 아이디어가 너무 일반적이라 실패한다면, <b>더 틈새시장을 노리는 것</b>이 해결책이 될 수 있고, 너무 복잡해서 실패한다면 <b>간단하게 만드는 것</b>이 답이 될 수 있죠. 정말 유용한 전략입니다!</p>\n<div style=\"background-color: #f1f8e9; border: 1px solid #a5d6a7; padding: 15px; margin: 20px 0; border-radius: 8px; overflow-x: auto;\">\n<pre class=\"prolog\" style=\"margin: 0; padding: 0; white-space: pre-wrap; word-wrap: break-word;\"><code>[주제]에 대해 역 브레인스토밍을 사용하세요.\n이 문제를 악화시킬 수 있는 15가지 방법을 나열하세요.\n각각의 \"악화\" 아이디어를 건설적인 아이디어 또는 보호 장치로 전환하세요.\n전환된 목록을 구체적이고 테스트 가능한 행동 또는 개념으로 제시하세요.\n        </code></pre>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>4. 무작위 단어로 상상력 점프하기: 기발한 연결고리 만들기</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">모든 아이디어가 비슷하게 들리기 시작할 때, 저는 가끔 <b>'무작위성'</b>의 도움을 받아요. 예전에는 사전을 펼치거나 신문을 보면서 뜬금없는 단어에서 영감을 얻기도 했죠. 이 프롬프트는 전혀 관련 없어 보이는 입력값들을 한데 모아 <b>새로운 연결고리</b>를 찾도록 강제합니다. 아, 그런데 이거 뇌세포에 정말 무리가 갈 때도 있어요... 그래서 챗GPT가 이렇게 도움이 될 줄은 몰랐네요!</p>\n<div style=\"background-color: #e8f5e9; border-left: 4px solid #2e7d32; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">\n<p style=\"margin-bottom: 5px; color: #212121;\" data-ke-size=\"size16\">  <b>뉴스레터 아이디어 적용 예시 (무작위 단어: '나무'):</b></p>\n<ul style=\"list-style-type: disc; margin-left: 20px; padding-left: 0; color: #212121;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>은유:</b> 나무의 나이테처럼 구독자들의 성장 과정을 담는 콘텐츠 시리즈 기획</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>제약:</b> '나무'라는 단어의 의미를 벗어나지 않게 친환경, 지속 가능성 테마의 콘텐츠만 다루기</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>관점:</b> 뉴스레터를 '지식의 숲'으로 비유하여 구독자들이 각자 나무를 심고 가꾸는 커뮤니티 조성</li>\n</ul>\n</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">사실 무작위 단어 그 자체는 중요하지 않아요. 중요한 건 그 단어들을 <b>은유, 제약, 또는 평소에는 고려하지 않았을 관점</b>으로 번역하는 과정에서 가치가 생긴다는 점입니다. 정말 신기하죠?!</p>\n<div style=\"background-color: #f1f8e9; border: 1px solid #a5d6a7; padding: 15px; margin: 20px 0; border-radius: 8px; overflow-x: auto;\">\n<pre class=\"angelscript\" style=\"margin: 0; padding: 0; white-space: pre-wrap; word-wrap: break-word;\"><code>[주제]에 대한 창의적이고 명확하지 않은 아이디어를 원합니다.\n1단계: 무작위의 관련 없는 트리거 단어 5개를 생성하세요.\n2단계: 각 단어에 대해 아이디어를 영감을 주거나 수정할 수 있는 세 가지 방법을 보여주세요.\n3단계: 도출된 가장 흥미로운 방향 5가지를 요약하세요.\n        </code></pre>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>5. SCAMPER 프레임워크로 체계적인 사고 확장하기</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">에드워드 드 보노(Edward de Bono)가 측면 사고(Lateral Thinking)를 대중화시켰죠. <b>SCAMPER</b>는 측면 사고를 위한 고전적인 창의성 프레임워크인데, AI와 함께 사용하면 정말 눈부시게 빠릅니다! 이 프레임워크는 <b>특정 아이디어를 다양한 각도에서 질문하고 변형</b>하며 새로운 가능성을 탐색하도록 돕습니다.</p>\n<table style=\"width: 100%; border-collapse: collapse; margin: 20px 0; font-size: 15px; border: 1px solid #a5d6a7;\" data-ke-align=\"alignLeft\">\n<thead style=\"background-color: #c8e6c9;\">\n<tr>\n<th style=\"border: 1px solid #a5d6a7; padding: 10px; text-align: left; color: #212121;\">요소</th>\n<th style=\"border: 1px solid #a5d6a7; padding: 10px; text-align: left; color: #212121;\">의미</th>\n<th style=\"border: 1px solid #a5d6a7; padding: 10px; text-align: left; color: #212121;\">뉴스레터 아이디어 예시</th>\n</tr>\n</thead>\n<tbody>\n<tr style=\"background-color: #f1f8e9;\">\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\"><b>S</b>ubstitute</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">대체하기</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">텍스트 콘텐츠를 짧은 오디오 클립으로 대체</td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\"><b>C</b>ombine</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">결합하기</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">주간 칼럼과 독자 Q&amp;A 코너를 결합하여 '전문가에게 묻다' 시리즈</td>\n</tr>\n<tr style=\"background-color: #f1f8e9;\">\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\"><b>A</b>dapt</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">적응하기</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">타 산업의 성공적인 콘텐츠 전략을 뉴스레터에 적용</td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\"><b>M</b>odify</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">수정/확대/축소</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">메인 칼럼의 길이를 확 줄이고 대신 인포그래픽으로 시각화</td>\n</tr>\n<tr style=\"background-color: #f1f8e9;\">\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\"><b>P</b>ut to other uses</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">다른 용도로 활용</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">뉴스레터 콘텐츠를 활용해 소셜 미디어 카드뉴스 제작</td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\"><b>E</b>liminate</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">제거하기</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">모든 광고 제거, 오직 순수 콘텐츠에만 집중</td>\n</tr>\n<tr style=\"background-color: #f1f8e9;\">\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\"><b>R</b>everse</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">뒤집기/재배열</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">결론을 먼저 보여주고 그 이유를 설명하는 콘텐츠 구성</td>\n</tr>\n</tbody>\n</table>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/QKpLU/dJMcafehv24/3JCcjKKTFj298eGcWp1H7k/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/QKpLU/dJMcafehv24/3JCcjKKTFj298eGcWp1H7k/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/QKpLU/dJMcafehv24/3JCcjKKTFj298eGcWp1H7k/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FQKpLU%2FdJMcafehv24%2F3JCcjKKTFj298eGcWp1H7k%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"SCAMPER 프레임워크를 시각적으로 보여주는 인포그래픽. 각 요소(대체, 결합, 적용, 수정, 다른 용도, 제거, 재배열)가 아이콘과 함께 중앙 아이디어를 둘러싸고 있어 체계적인 사고 과정을 나타냅니다.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 프롬프트는 <b>이미 어느 정도 구체화된 아이디어</b>에 적용할 때 빛을 발합니다. 그래서 저는 브레인스토밍 과정의 후반부에 이 프롬프트를 사용하는 편이에요. 특정 기능을 제거하거나 두 가지 요소를 결합하는 것 같은 <b>작은 변화가 아이디어의 명확성이나 유용성을 극적으로 향상</b>시키는 것을 자주 경험할 수 있을 겁니다.</p>\n<div style=\"background-color: #f1f8e9; border: 1px solid #a5d6a7; padding: 15px; margin: 20px 0; border-radius: 8px; overflow-x: auto;\">\n<pre class=\"prolog\" style=\"margin: 0; padding: 0; white-space: pre-wrap; word-wrap: break-word;\"><code>SCAMPER 프레임워크를 사용하여 [제품/프로젝트/주제]에 대해 브레인스토밍하세요.\n각 요소(Substitute, Combine, Adapt, Modify, Put to other uses, Eliminate, Reverse)에 대해:\n일반적인 조언이 아닌 3-5가지 구체적인 아이디어를 생성하세요.\n각 아이디어를 한 문장으로 유지하세요.\n모든 SCAMPER 단계에서 가장 좋은 아이디어 5가지의 짧은 목록으로 마무리하세요.\n        </code></pre>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>6. SWOT 분석으로 아이디어를 현실에 대입하기: 전략적 점검</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">아이디어가 아무리 좋아 보여도 현실성이 없으면 무용지물이잖아요? <b>SWOT 분석</b> 스타일의 프롬프트는 브레인스토밍을 <b>현실 세계로 끌어와</b> 앞으로 발생할 수 있는 <b>상충 관계(Trade-offs)</b>를 미리 보여줍니다. 저는 종종 이 프롬프트를 통해 '보기에는 좋은 아이디어'가 실질적으로 어떤 문제점을 안고 있는지 파악하고 싶을 때 사용하곤 해요.</p>\n<div style=\"background-color: #e8f5e9; border-left: 4px solid #2e7d32; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">\n<p style=\"margin-bottom: 5px; color: #212121;\" data-ke-size=\"size16\">  <b>뉴스레터 아이디어 적용 예시 (SWOT):</b></p>\n<ul style=\"list-style-type: disc; margin-left: 20px; padding-left: 0; color: #212121;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>강점 활용:</b> '전문가 인터뷰' 강점을 살려 해당 분야 최고 권위자를 초빙하는 특별 시리즈 기획</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>약점 보완:</b> '콘텐츠 제작 시간 부족' 약점을 해결하기 위해 구독자 참여형 콘텐츠 비중 확대</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>기회 포착:</b> '트렌드 변화' 기회를 활용해 AI 기술 트렌드를 빠르게 분석하는 섹션 신설</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>위협 방어:</b> '경쟁사 증가' 위협에 대비해 뉴스레터만의 독점적인 커뮤니티 기능 강화</li>\n</ul>\n</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 분석을 통해 얻은 통찰력은 아이디어의 질을 높이고 실행력을 개선하는 데 결정적인 역할을 합니다. 시각적인 다이어그램 도구를 함께 사용하면 아이디어를 한눈에 파악하는 데 더욱 효과적일 거예요. 솔직히 말해서, 이 과정 없이는 뭔가 중요한 걸 놓치고 있는 느낌이 들 때가 많아요.</p>\n<div style=\"background-color: #f1f8e9; border: 1px solid #a5d6a7; padding: 15px; margin: 20px 0; border-radius: 8px; overflow-x: auto;\">\n<pre class=\"angelscript\" style=\"margin: 0; padding: 0; white-space: pre-wrap; word-wrap: break-word;\"><code>[아이디어 또는 프로젝트]에 대해 SWOT 방식의 브레인스토밍 세션을 실행하세요.\n5-7가지 강점, 5-7가지 약점, 5-7가지 기회, 5-7가지 위협을 나열하세요.\n이것들로부터 다음을 나열하세요:\n강점을 두 배로 활용하는 아이디어 3가지\n약점을 고치거나 우회하는 아이디어 3가지\n기회를 포착하는 아이디어 3가지\n위협에 대비하는 아이디어 3가지\n모든 것을 간결한 글머리 기호로 제시하세요.\n        </code></pre>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>7. 역할극으로 다양한 관점 얻기: 미처 몰랐던 니즈 발굴</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">우리는 모두 자기만의 시각에 갇히기 쉬워요. <b>역할극 브레인스토밍(Rolestorming)</b>은 다른 사람의 입장이 되어 생각해보는 기법인데, 제품이나 프로세스의 <b>페인 포인트(Pain Point)</b>를 찾는 데 정말 탁월한 효과를 발휘합니다. 내가 미처 생각하지 못했던 필요나 개선점들을 발견하게 해주거든요.</p>\n<div style=\"background-color: #e8f5e9; border-left: 4px solid #2e7d32; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">\n<p style=\"margin-bottom: 5px; color: #212121;\" data-ke-size=\"size16\">  <b>뉴스레터 아이디어 적용 예시 (페르소나):</b></p>\n<ul style=\"list-style-type: disc; margin-left: 20px; padding-left: 0; color: #212121;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>초보 사용자:</b> '용어가 너무 어려워요. 초보자를 위한 쉬운 설명이나 용어 사전이 필요해요.'</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>파워 사용자:</b> '심화 자료나 다른 전문가와의 네트워킹 기회가 있으면 좋겠어요.'</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>경쟁사:</b> '이 뉴스레터는 특정 주제에 대한 심층 분석이 부족하고, 인터랙티브 요소가 약해.'</li>\n</ul>\n</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">작가로서, 저는 이 프롬프트 덕분에 다양한 독자층의 니즈를 파악하고 콘텐츠를 미세 조정하는 데 큰 도움을 받았습니다. 여러 페르소나에서 공통적으로 발견되는 인사이트는 콘텐츠를 더 넓은 독자층에 맞게 다듬는 데 정말 핵심적이라고 할 수 있죠. 아마 여러분도 이 과정을 통해 예상치 못한 보물을 발견하실 거예요.</p>\n<div style=\"background-color: #f1f8e9; border: 1px solid #a5d6a7; padding: 15px; margin: 20px 0; border-radius: 8px; overflow-x: auto;\">\n<pre class=\"prolog\" style=\"margin: 0; padding: 0; white-space: pre-wrap; word-wrap: break-word;\"><code>[주제]에 대해 \"역할 브레인스토밍\"을 할 것입니다.\n다음 관점에서 생각하세요:\n&ndash; 초보자\n&ndash; 파워 사용자\n&ndash; 주요 이해관계자\n&ndash; 경쟁사\n각 페르소나에 대해 그들이 주장할 5가지 아이디어, 요청 또는 개선 사항을 나열하세요.\n그리고 최고의 아이디어를 하나의 우선순위 목록으로 통합하세요.\n        </code></pre>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>8. 아이디어를 실행 가능한 로드맵으로 전환하기: 실질적인 계획</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">브레인스토밍이 아무리 멋진 아이디어를 쏟아냈어도, 그것들이 그냥 문서 속에서 잠들어버린다면 아무 소용이 없겠죠? 이 프롬프트는 <b>아이디어를 실제 행동으로 옮길 수 있는 구체적인 로드맵으로 전환</b>시켜 줍니다. 단순히 직감에만 의존하는 것이 아니라, <b>영향력(Impact)과 노력(Effort)</b>을 기준으로 아이디어를 평가하게 함으로써 가장 효과적인 계획을 세울 수 있도록 도와줘요. 제가 겪어본 바로는, 최상의 아이디어는 직감과 어느 정도의 객관적인 증거 사이의 균형에서 나온다고 생각합니다.</p>\n<div style=\"background-color: #e8f5e9; border-left: 4px solid #2e7d32; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">\n<p style=\"margin-bottom: 5px; color: #212121;\" data-ke-size=\"size16\">  <b>아이디어 분류 기준:</b></p>\n<ul style=\"list-style-type: disc; margin-left: 20px; padding-left: 0; color: #212121;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>Quick wins (빠른 성과):</b> 적은 노력으로 큰 영향력을 낼 수 있는 아이디어</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>Long bets (장기 투자):</b> 큰 노력이 필요하지만 장기적으로 엄청난 영향력을 가져올 아이디어</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>Experiments (실험):</b> 시도해 볼 만하지만 불확실성이 있는 아이디어</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>Cancel (취소):</b> 영향력은 낮고 노력은 많이 드는 비효율적인 아이디어</li>\n</ul>\n</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/U88XA/dJMcahiRBOO/A7K7LwyPI2AQU9xP7s79vK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/U88XA/dJMcahiRBOO/A7K7LwyPI2AQU9xP7s79vK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/U88XA/dJMcahiRBOO/A7K7LwyPI2AQU9xP7s79vK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FU88XA%2FdJMcahiRBOO%2FA7K7LwyPI2AQU9xP7s79vK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"이블 위에 펼쳐진 전략적 로드맵 이미지. '빠른 성과', '장기 투자', '실험', '취소' 섹션으로 명확히 구분되어 있으며, 손이 로드맵을 가리키며 실행 가능한 계획을 나타냅니다.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">제대로 된 브레인스토밍의 마지막은 항상 <b>실행 가능한 계획</b>이어야 한다고 생각해요. 챗GPT와 함께라면 이런 과정도 훨씬 체계적이고 효율적으로 진행할 수 있습니다. 예를 들어, 뉴스레터 관련 아이디어 3가지에 대해 2주간의 실행 계획을 세우는 거죠. 정말 생산적이지 않나요?</p>\n<div style=\"background-color: #f1f8e9; border: 1px solid #a5d6a7; padding: 15px; margin: 20px 0; border-radius: 8px; overflow-x: auto;\">\n<pre class=\"angelscript\" style=\"margin: 0; padding: 0; white-space: pre-wrap; word-wrap: break-word;\"><code>제가 제공하는 아이디어 목록을 실용적인 실행 로드맵으로 전환하세요.\n각 아이디어를 영향력(1-5)과 노력(1-5) 기준으로 평가하고 간략한 설명을 덧붙이세요.\n이를 빠른 성과(Quick wins), 장기 투자(Long bets), 실험(Experiments), 취소(Cancel)로 분류하세요.\n최고의 아이디어 3개를 테스트하기 위한 구체적인 작업이 포함된 2주 실행 계획을 제안하세요.\n        </code></pre>\n</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">생산적인 브레인스토밍은 단순히 더 좋은 아이디어를 내는 것을 넘어, <b>우리 자신의 맹점(Blind Spots)을 이해하는 과정</b>이기도 합니다. 모든 프롬프트를 다 사용할 필요는 없어요 (물론 다 사용하면 좋긴 합니다!). 초기 설정 프롬프트로 시작한 뒤, 발산적 프롬프트 하나와 SWOT 분석 같은 '아이디어 검증용' 프롬프트를 조합해보세요. 아마 생각지도 못했던 <b>명확성의 비약적인 상승</b>을 경험하게 될 겁니다. 2026년, ChatGPT와 함께 여러분의 생각의 지평을 더욱 넓혀나가시길 바랍니다!</p>\n<div style=\"background-color: #f1f8e9; border: 1px solid #a5d6a7; border-radius: 8px; padding: 25px; margin: 40px 0; box-shadow: 0 4px 12px rgba(0,0,0,0.1);\">\n<div style=\"border-bottom: 1px solid #2e7d32; padding-bottom: 15px; margin-bottom: 20px;\">\n<p style=\"font-size: 26px; color: #2e7d32; font-weight: bold; margin: 0;\" data-ke-size=\"size16\">  핵심 요약</p>\n</div>\n<p style=\"font-size: 17px; margin-bottom: 10px;\" data-ke-size=\"size16\"><b>1. 명확한 컨텍스트 설정:</b> ChatGPT에게 구체적인 목표와 제약 조건을 미리 알려 일반적인 답변을 방지하세요.</p>\n<p style=\"font-size: 17px; margin-bottom: 10px;\" data-ke-size=\"size16\"><b>2. 다양한 사고 확장:</b> 발산적 사고, 역 브레인스토밍, 무작위 단어, SCAMPER를 활용해 사고의 폭을 넓히세요.</p>\n<p style=\"font-size: 17px; margin-bottom: 10px;\" data-ke-size=\"size16\"><b>3. 아이디어 현실 점검:</b> SWOT 분석과 역할극을 통해 아이디어의 강점, 약점, 기회, 위협을 파악하고 다양한 관점을 통합하세요.</p>\n<p style=\"font-size: 17px; margin-bottom: 0px;\" data-ke-size=\"size16\"><b>4. 실행 가능한 로드맵:</b> 아이디어를 영향력과 노력 기준으로 평가하고, 단기 성과, 장기 투자, 실험, 취소 항목으로 분류하여 구체적인 실행 계획을 세우세요.</p>\n<div style=\"margin-top: 20px; padding-top: 15px; border-top: 1px dashed #aed581;\">\n<p style=\"font-size: 14px; color: #aed581; margin: 0;\" data-ke-size=\"size16\">  이 프롬프트들을 활용하면 여러분의 브레인스토밍이 훨씬 더 깊고 실용적으로 변할 거예요!</p>\n</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<div style=\"margin-bottom: 15px;\">\n<p style=\"font-size: 18px; color: #2e7d32; margin-bottom: 5px;\" data-ke-size=\"size16\"><b>Q1: ChatGPT 브레인스토밍 프롬프트를 사용할 때 가장 중요한 점은 무엇인가요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">가장 중요한 건 <b>명확한 컨텍스트와 목표를 설정</b>하는 거예요. ChatGPT를 단순한 아이디어 자동판매기가 아닌, 구조화된 브레인스토밍 파트너로 생각하고 구체적인 지침을 제공할수록 훨씬 더 유용하고 깊이 있는 결과를 얻을 수 있답니다. 마치 유능한 팀원에게 정확한 프로젝트 브리핑을 하는 것과 비슷하다고 보면 돼요!</p>\n</div>\n<div style=\"margin-bottom: 15px;\">\n<p style=\"font-size: 18px; color: #2e7d32; margin-bottom: 5px;\" data-ke-size=\"size16\"><b>Q2: 여러 프롬프트를 어떻게 조합해서 사용하는 것이 좋을까요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">저는 보통 <b>초기 설정 프롬프트(#1)로 시작</b>해서, 발산적 사고를 위한 프롬프트(#2)로 아이디어의 양을 늘려요. 그 다음, 역 브레인스토밍(#3)이나 SWOT 분석(#6) 같은 <b>'검증용' 프롬프트</b>로 아이디어를 점검하죠. 이렇게 하면 초기 아이디어의 맹점을 파악하고 보완할 수 있어서 정말 도움이 된답니다. 상황에 따라 SCAMPER(#5)나 역할극(#7)을 추가해서 더 깊이 있는 아이디어를 발굴하기도 해요.</p>\n</div>\n<div style=\"margin-bottom: 15px;\">\n<p style=\"font-size: 18px; color: #2e7d32; margin-bottom: 5px;\" data-ke-size=\"size16\"><b>Q3: ChatGPT가 생성한 아이디어가 너무 일반적일 때는 어떻게 해야 할까요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">음, 이런 경우도 자주 있죠! 그럴 때는 먼저 <b>컨텍스트를 더 구체적으로 설명</b>하는 게 좋아요. 예를 들어, \"이 아이디어를 20대 여성 직장인을 위한 뉴스레터에 적용한다면?\" 같이 대상 독자나 특정 상황을 더 명확히 제시하는 거죠. 그리고 역 브레인스토밍(#3)을 통해 '어떻게 하면 이 아이디어를 망칠 수 있을까?'를 고민해보면, 의외로 신선한 해결책이 나올 때가 많아요.</p>\n</div>\n<div style=\"margin-bottom: 0;\">\n<p style=\"font-size: 18px; color: #2e7d32; margin-bottom: 5px;\" data-ke-size=\"size16\"><b>Q4: 이 프롬프트들을 어디에 활용하면 가장 효과적일까요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">개인적으로는 <b>콘텐츠 기획, 마케팅 전략 수립, 제품 개발 아이디어 도출, 개인적인 목표 설정</b> 등 다양한 분야에서 활용도가 높았어요. 특히 혼자서 막막할 때나 팀원들과 새로운 시각이 필요할 때 ChatGPT를 유능한 동료 삼아 이 프롬프트들을 적용해보면, 생각지도 못한 인사이트를 얻을 수 있을 거예요.</p>\n</div>\n<script type=\"application/ld+json\">\n        {\n          \"@context\": \"https://schema.org\",\n          \"@type\": \"FAQPage\",\n          \"mainEntity\": [\n            {\n              \"@type\": \"Question\",\n              \"name\": \"ChatGPT 브레인스토밍 프롬프트를 사용할 때 가장 중요한 점은 무엇인가요?\",\n              \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"가장 중요한 건 명확한 컨텍스트와 목표를 설정하는 거예요. ChatGPT를 단순한 아이디어 자동판매기가 아닌, 구조화된 브레인스토밍 파트너로 생각하고 구체적인 지침을 제공할수록 훨씬 더 유용하고 깊이 있는 결과를 얻을 수 있답니다. 마치 유능한 팀원에게 정확한 프로젝트 브리핑을 하는 것과 비슷하다고 보면 돼요!\"\n              }\n            },\n            {\n              \"@type\": \"Question\",\n              \"name\": \"여러 프롬프트를 어떻게 조합해서 사용하는 것이 좋을까요?\",\n              \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"저는 보통 초기 설정 프롬프트(#1)로 시작해서, 발산적 사고를 위한 프롬프트(#2)로 아이디어의 양을 늘려요. 그 다음, 역 브레인스토밍(#3)이나 SWOT 분석(#6) 같은 '검증용' 프롬프트로 아이디어를 점검하죠. 이렇게 하면 초기 아이디어의 맹점을 파악하고 보완할 수 있어서 정말 도움이 된답니다. 상황에 따라 SCAMPER(#5)나 역할극(#7)을 추가해서 더 깊이 있는 아이디어를 발굴하기도 해요.\"\n              }\n            },\n            {\n              \"@type\": \"Question\",\n              \"name\": \"ChatGPT가 생성한 아이디어가 너무 일반적일 때는 어떻게 해야 할까요?\",\n              \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"음, 이런 경우도 자주 있죠! 그럴 때는 먼저 컨텍스트를 더 구체적으로 설명하는 게 좋아요. 예를 들어, '이 아이디어를 20대 여성 직장인을 위한 뉴스레터에 적용한다면?' 같이 대상 독자나 특정 상황을 더 명확히 제시하는 거죠. 그리고 역 브레인스토밍(#3)을 통해 '어떻게 하면 이 아이디어를 망칠 수 있을까?'를 고민해보면, 의외로 신선한 해결책이 나올 때가 많아요.\"\n              }\n            },\n            {\n              \"@type\": \"Question\",\n              \"name\": \"이 프롬프트들을 어디에 활용하면 가장 효과적일까요?\",\n              \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"개인적으로는 콘텐츠 기획, 마케팅 전략 수립, 제품 개발 아이디어 도출, 개인적인 목표 설정 등 다양한 분야에서 활용도가 높았어요. 특히 혼자서 막막할 때나 팀원들과 새로운 시각이 필요할 때 ChatGPT를 유능한 동료 삼아 이 프롬프트들을 적용해보면, 생각지도 못한 인사이트를 얻을 수 있을 거예요.\"\n              }\n            }\n          ]\n        }\n    </script>\n</div>",
        "contentSnippet": "여러분은 브레인스토밍을 할 때 막막함을 느끼시나요? 방대한 아이디어가 필요한데 어디서부터 시작해야 할지 모르겠다고요? 2026년, 이제 ChatGPT는 단순한 정보 제공자를 넘어 여러분의 '생각의 수준'을 한 차원 높여줄 유능한 브레인스토밍 파트너가 될 수 있습니다. 오늘은 제가 직접 사용하며 효과를 본, 창의적인 사고를 돕는 8가지 ChatGPT 프롬프트를 공개합니다. 평범한 아이디어를 벗어나 실용적이고 깊이 있는 통찰력을 얻고 싶은 분들을 위해 준비했어요.\n\n\n솔직히 말하면, 우리는 ChatGPT를 너무 쉽게 생각하는 경향이 있는 것 같아요. 그냥 질문을 던지면 답을 뱉어내는 '아이디어 자판기'처럼 말이죠. 하지만 제가 직접 겪어보니, 제대로 활용하면 정말 놀라운 '브레인스토밍 파트너'가 될 수 있다는 걸 깨달았습니다. 우리가 머리를 쥐어짜며 생각의 흐름을 만들 때, ChatGPT는 그 아이디어의 볼륨과 구조를 잡아주는 역할을 톡톡히 해내죠. 제가 오랫동안 마케팅과 웹 개발 분야에서 일하며 숱하게 브레인스토밍을 해왔는데, 최근 챗GPT와 함께하면서 아이디어의 명확성과 범위가 확연히 넓어지는 것을 경험하고 있습니다. 수많은 선배들의 지혜와 레딧 같은 커뮤니티에서 얻은 영감을 바탕으로, 퍼져 있던 생각들을 실행 가능한 아이디어로 다듬는 데 최적화된 프롬프트 8가지를 소개할게요. 저의 뉴스레터를 장기적으로 흥미롭게 유지하는 방법이라는 주제로 같이 고민해보면 더 와닿으실 거예요.\n1. 맥락을 이해시키는 것부터 시작하세요: 일반적인 아이디어를 피하는 첫걸음\n아무리 인공지능이라도 우리 마음을 꿰뚫어 볼 수는 없잖아요? 그래서 저는 항상 브레인스토밍 세션을 시작하기 전에 ChatGPT에게 명확한 지침을 줍니다. 마치 유능한 팀원에게 프로젝트 브리핑을 하듯이요. 이 '핵심 프롬프트'는 전체 대화의 틀을 잡고, 챗GPT가 뻔하거나 피상적인 아이디어를 내놓는 걸 미리 방지해 주는 역할을 해요. 복잡한 콘텐츠 기획이나 개인적인 목표 설정 같은 작업에 특히 유용하더라고요. 처음부터 이렇게 세부적으로 조율해두면 나중에 불필요한 노력을 훨씬 줄일 수 있습니다. 핵심은 맥락, 명확성, 그리고 의도라는 점, 잊지 마세요!\n  프롬프트 활용 팁:\nGoal(목표): 최종적으로 무엇을 얻고 싶은지 명확히 하세요.\nContext(맥락): 대상, 제약 조건, 시간, 자원 등 배경 정보를 상세히 설명하세요.\nProcess(과정): 어떤 방식으로 진행할지 (예: 질문 개수, 프레임워크 제안 등) 구체적으로 알려주세요.\n당신은 저의 구조화된 브레인스토밍 파트너입니다.\n목표: [주제/문제/결과물 설명]에 대해 브레인스토밍하는 것을 도와주세요.\n맥락: [대상, 제약 조건, 기한, 자원].\n과정: 최대 5개의 명확화 질문을 하나씩 해주세요.\n사용할 수 있는 3-5가지의 다른 브레인스토밍 프레임워크를 제안해주세요 (예: SCAMPER, 마인드맵, 가정, 제약, 첫 번째 원칙).\n제가 하나를 선택하면, 간결하고 번호가 매겨진 목록으로 브레인스토밍을 안내해주세요. 이때 구체성과 실용성을 목표로 합니다.\n궁극적으로, 최고의 아이디어를 3-5가지 테마로 분류하고 구체적인 다음 단계를 제안해주세요.\n간결한 글머리 기호를 사용하고 일반적인 조언은 피해주세요.\n        \n2. 다양한 아이디어로 물꼬를 트세요: 양으로 승부하는 발산적 사고\n아이디어가 막힐 때 가장 빠르고 확실한 방법은 일단 많은 아이디어를 쏟아내는 것이라고 생각해요. 심지어 좀 터무니없는 아이디어라도 괜찮아요! 초기 단계에서는 아이디어의 질보다는 속도와 범위가 훨씬 중요합니다. 이 프롬프트는 ChatGPT와 우리 뇌의 시동을 거는 역할을 해요. 나중에 걸러내고 우선순위를 정하는 건 그때 가서 해도 늦지 않습니다.\n  뉴스레터 아이디어 적용 예시:\n뉴스레터의 메인 콘텐츠를 짧은 숏폼 비디오로 전환 (요즘 대세죠!)\n구독자들이 직접 참여하는 '익명 고민 상담소' 코너 운영\n매주 다른 분야의 전문가를 초대해 인터뷰 시리즈 진행\n프롬프트의 마지막 단계가 정말 중요해요. '가장 유망한 아이디어 5가지 표시'가 없다면, 그냥 방치되는 목록으로 끝나버릴 수도 있거든요. 번호가 매겨진 목록은 나중에 특정 아이디어를 참조할 때도 편리하고요. 개인적인 경험으로는, 종종 목록의 뒷부분에 숨어있는 기발한 아이디어들이 많았습니다. ChatGPT와 마인드맵 도구를 함께 사용하면 아이디어 간의 연관성을 찾는 데 큰 도움이 될 거예요.\n\n\n\n[주제]에 대해 발산적 브레인스토밍을 해봅시다.\n제약 조건: [예산/시간/산업/대상/기타].\n1단계: 명확한 것부터 파격적인 것까지 20가지의 빠르고 대략적인 아이디어를 번호가 매겨진 목록으로 생성해주세요.\n2단계: 각 아이디어에 대해 왜 효과적일 수 있는지에 대한 짧은 문구를 추가해주세요.\n3단계: 영향력 대비 노력 측면에서 가장 유망해 보이는 5가지 아이디어를 표시해주세요.\n        \n3. 역 브레인스토밍으로 숨겨진 문제점 찾기: 실패를 통해 성공 배우기\n생각해보니, 성공하는 방법만 고민할 필요는 없더라고요. 역 브레인스토밍(Reverse Brainstorming)은 문제를 뒤집어서 '어떻게 하면 실패할 수 있을까?'를 묻는 기법입니다. 마치 일이 터지기 전에 미리 사후 검토(Pre-mortem)를 하는 것과 비슷하죠. 저는 이 프롬프트를 통해 어떤 아이디어가 '괜찮긴 한데 뭔가 부족하다'고 느껴질 때 그 이유를 파악하는 데 활용합니다.\n⚠️ 뉴스레터 아이디어 적용 예시 (역발상):\n문제: 뉴스레터 이탈률을 높이는 방법은?\n해결책: 과도한 광고 삽입 (뒤집으면: 광고를 최소화하고 콘텐츠 집중)\n해결책: 매주 비슷한 내용만 반복 (뒤집으면: 다양한 형식과 주제로 신선함 유지)\n해결책: 발행 주기를 불규칙하게 (뒤집으면: 일관된 발행 주기 유지)\n이 프롬프트는 약한 아이디어와 흔한 실수를 빠르게 파악하게 해줘요. 만약 아이디어가 너무 일반적이라 실패한다면, 더 틈새시장을 노리는 것이 해결책이 될 수 있고, 너무 복잡해서 실패한다면 간단하게 만드는 것이 답이 될 수 있죠. 정말 유용한 전략입니다!\n[주제]에 대해 역 브레인스토밍을 사용하세요.\n이 문제를 악화시킬 수 있는 15가지 방법을 나열하세요.\n각각의 \"악화\" 아이디어를 건설적인 아이디어 또는 보호 장치로 전환하세요.\n전환된 목록을 구체적이고 테스트 가능한 행동 또는 개념으로 제시하세요.\n        \n4. 무작위 단어로 상상력 점프하기: 기발한 연결고리 만들기\n모든 아이디어가 비슷하게 들리기 시작할 때, 저는 가끔 '무작위성'의 도움을 받아요. 예전에는 사전을 펼치거나 신문을 보면서 뜬금없는 단어에서 영감을 얻기도 했죠. 이 프롬프트는 전혀 관련 없어 보이는 입력값들을 한데 모아 새로운 연결고리를 찾도록 강제합니다. 아, 그런데 이거 뇌세포에 정말 무리가 갈 때도 있어요... 그래서 챗GPT가 이렇게 도움이 될 줄은 몰랐네요!\n  뉴스레터 아이디어 적용 예시 (무작위 단어: '나무'):\n은유: 나무의 나이테처럼 구독자들의 성장 과정을 담는 콘텐츠 시리즈 기획\n제약: '나무'라는 단어의 의미를 벗어나지 않게 친환경, 지속 가능성 테마의 콘텐츠만 다루기\n관점: 뉴스레터를 '지식의 숲'으로 비유하여 구독자들이 각자 나무를 심고 가꾸는 커뮤니티 조성\n사실 무작위 단어 그 자체는 중요하지 않아요. 중요한 건 그 단어들을 은유, 제약, 또는 평소에는 고려하지 않았을 관점으로 번역하는 과정에서 가치가 생긴다는 점입니다. 정말 신기하죠?!\n[주제]에 대한 창의적이고 명확하지 않은 아이디어를 원합니다.\n1단계: 무작위의 관련 없는 트리거 단어 5개를 생성하세요.\n2단계: 각 단어에 대해 아이디어를 영감을 주거나 수정할 수 있는 세 가지 방법을 보여주세요.\n3단계: 도출된 가장 흥미로운 방향 5가지를 요약하세요.\n        \n5. SCAMPER 프레임워크로 체계적인 사고 확장하기\n에드워드 드 보노(Edward de Bono)가 측면 사고(Lateral Thinking)를 대중화시켰죠. SCAMPER는 측면 사고를 위한 고전적인 창의성 프레임워크인데, AI와 함께 사용하면 정말 눈부시게 빠릅니다! 이 프레임워크는 특정 아이디어를 다양한 각도에서 질문하고 변형하며 새로운 가능성을 탐색하도록 돕습니다.\n요소\n의미\n뉴스레터 아이디어 예시\n\n\n\n\nSubstitute\n대체하기\n텍스트 콘텐츠를 짧은 오디오 클립으로 대체\n\n\nCombine\n결합하기\n주간 칼럼과 독자 Q&A 코너를 결합하여 '전문가에게 묻다' 시리즈\n\n\nAdapt\n적응하기\n타 산업의 성공적인 콘텐츠 전략을 뉴스레터에 적용\n\n\nModify\n수정/확대/축소\n메인 칼럼의 길이를 확 줄이고 대신 인포그래픽으로 시각화\n\n\nPut to other uses\n다른 용도로 활용\n뉴스레터 콘텐츠를 활용해 소셜 미디어 카드뉴스 제작\n\n\nEliminate\n제거하기\n모든 광고 제거, 오직 순수 콘텐츠에만 집중\n\n\nReverse\n뒤집기/재배열\n결론을 먼저 보여주고 그 이유를 설명하는 콘텐츠 구성\n\n\n\n\n\n이 프롬프트는 이미 어느 정도 구체화된 아이디어에 적용할 때 빛을 발합니다. 그래서 저는 브레인스토밍 과정의 후반부에 이 프롬프트를 사용하는 편이에요. 특정 기능을 제거하거나 두 가지 요소를 결합하는 것 같은 작은 변화가 아이디어의 명확성이나 유용성을 극적으로 향상시키는 것을 자주 경험할 수 있을 겁니다.\nSCAMPER 프레임워크를 사용하여 [제품/프로젝트/주제]에 대해 브레인스토밍하세요.\n각 요소(Substitute, Combine, Adapt, Modify, Put to other uses, Eliminate, Reverse)에 대해:\n일반적인 조언이 아닌 3-5가지 구체적인 아이디어를 생성하세요.\n각 아이디어를 한 문장으로 유지하세요.\n모든 SCAMPER 단계에서 가장 좋은 아이디어 5가지의 짧은 목록으로 마무리하세요.\n        \n6. SWOT 분석으로 아이디어를 현실에 대입하기: 전략적 점검\n아이디어가 아무리 좋아 보여도 현실성이 없으면 무용지물이잖아요? SWOT 분석 스타일의 프롬프트는 브레인스토밍을 현실 세계로 끌어와 앞으로 발생할 수 있는 상충 관계(Trade-offs)를 미리 보여줍니다. 저는 종종 이 프롬프트를 통해 '보기에는 좋은 아이디어'가 실질적으로 어떤 문제점을 안고 있는지 파악하고 싶을 때 사용하곤 해요.\n  뉴스레터 아이디어 적용 예시 (SWOT):\n강점 활용: '전문가 인터뷰' 강점을 살려 해당 분야 최고 권위자를 초빙하는 특별 시리즈 기획\n약점 보완: '콘텐츠 제작 시간 부족' 약점을 해결하기 위해 구독자 참여형 콘텐츠 비중 확대\n기회 포착: '트렌드 변화' 기회를 활용해 AI 기술 트렌드를 빠르게 분석하는 섹션 신설\n위협 방어: '경쟁사 증가' 위협에 대비해 뉴스레터만의 독점적인 커뮤니티 기능 강화\n이 분석을 통해 얻은 통찰력은 아이디어의 질을 높이고 실행력을 개선하는 데 결정적인 역할을 합니다. 시각적인 다이어그램 도구를 함께 사용하면 아이디어를 한눈에 파악하는 데 더욱 효과적일 거예요. 솔직히 말해서, 이 과정 없이는 뭔가 중요한 걸 놓치고 있는 느낌이 들 때가 많아요.\n[아이디어 또는 프로젝트]에 대해 SWOT 방식의 브레인스토밍 세션을 실행하세요.\n5-7가지 강점, 5-7가지 약점, 5-7가지 기회, 5-7가지 위협을 나열하세요.\n이것들로부터 다음을 나열하세요:\n강점을 두 배로 활용하는 아이디어 3가지\n약점을 고치거나 우회하는 아이디어 3가지\n기회를 포착하는 아이디어 3가지\n위협에 대비하는 아이디어 3가지\n모든 것을 간결한 글머리 기호로 제시하세요.\n        \n7. 역할극으로 다양한 관점 얻기: 미처 몰랐던 니즈 발굴\n우리는 모두 자기만의 시각에 갇히기 쉬워요. 역할극 브레인스토밍(Rolestorming)은 다른 사람의 입장이 되어 생각해보는 기법인데, 제품이나 프로세스의 페인 포인트(Pain Point)를 찾는 데 정말 탁월한 효과를 발휘합니다. 내가 미처 생각하지 못했던 필요나 개선점들을 발견하게 해주거든요.\n  뉴스레터 아이디어 적용 예시 (페르소나):\n초보 사용자: '용어가 너무 어려워요. 초보자를 위한 쉬운 설명이나 용어 사전이 필요해요.'\n파워 사용자: '심화 자료나 다른 전문가와의 네트워킹 기회가 있으면 좋겠어요.'\n경쟁사: '이 뉴스레터는 특정 주제에 대한 심층 분석이 부족하고, 인터랙티브 요소가 약해.'\n작가로서, 저는 이 프롬프트 덕분에 다양한 독자층의 니즈를 파악하고 콘텐츠를 미세 조정하는 데 큰 도움을 받았습니다. 여러 페르소나에서 공통적으로 발견되는 인사이트는 콘텐츠를 더 넓은 독자층에 맞게 다듬는 데 정말 핵심적이라고 할 수 있죠. 아마 여러분도 이 과정을 통해 예상치 못한 보물을 발견하실 거예요.\n[주제]에 대해 \"역할 브레인스토밍\"을 할 것입니다.\n다음 관점에서 생각하세요:\n– 초보자\n– 파워 사용자\n– 주요 이해관계자\n– 경쟁사\n각 페르소나에 대해 그들이 주장할 5가지 아이디어, 요청 또는 개선 사항을 나열하세요.\n그리고 최고의 아이디어를 하나의 우선순위 목록으로 통합하세요.\n        \n8. 아이디어를 실행 가능한 로드맵으로 전환하기: 실질적인 계획\n브레인스토밍이 아무리 멋진 아이디어를 쏟아냈어도, 그것들이 그냥 문서 속에서 잠들어버린다면 아무 소용이 없겠죠? 이 프롬프트는 아이디어를 실제 행동으로 옮길 수 있는 구체적인 로드맵으로 전환시켜 줍니다. 단순히 직감에만 의존하는 것이 아니라, 영향력(Impact)과 노력(Effort)을 기준으로 아이디어를 평가하게 함으로써 가장 효과적인 계획을 세울 수 있도록 도와줘요. 제가 겪어본 바로는, 최상의 아이디어는 직감과 어느 정도의 객관적인 증거 사이의 균형에서 나온다고 생각합니다.\n  아이디어 분류 기준:\nQuick wins (빠른 성과): 적은 노력으로 큰 영향력을 낼 수 있는 아이디어\nLong bets (장기 투자): 큰 노력이 필요하지만 장기적으로 엄청난 영향력을 가져올 아이디어\nExperiments (실험): 시도해 볼 만하지만 불확실성이 있는 아이디어\nCancel (취소): 영향력은 낮고 노력은 많이 드는 비효율적인 아이디어\n\n\n제대로 된 브레인스토밍의 마지막은 항상 실행 가능한 계획이어야 한다고 생각해요. 챗GPT와 함께라면 이런 과정도 훨씬 체계적이고 효율적으로 진행할 수 있습니다. 예를 들어, 뉴스레터 관련 아이디어 3가지에 대해 2주간의 실행 계획을 세우는 거죠. 정말 생산적이지 않나요?\n제가 제공하는 아이디어 목록을 실용적인 실행 로드맵으로 전환하세요.\n각 아이디어를 영향력(1-5)과 노력(1-5) 기준으로 평가하고 간략한 설명을 덧붙이세요.\n이를 빠른 성과(Quick wins), 장기 투자(Long bets), 실험(Experiments), 취소(Cancel)로 분류하세요.\n최고의 아이디어 3개를 테스트하기 위한 구체적인 작업이 포함된 2주 실행 계획을 제안하세요.\n        \n생산적인 브레인스토밍은 단순히 더 좋은 아이디어를 내는 것을 넘어, 우리 자신의 맹점(Blind Spots)을 이해하는 과정이기도 합니다. 모든 프롬프트를 다 사용할 필요는 없어요 (물론 다 사용하면 좋긴 합니다!). 초기 설정 프롬프트로 시작한 뒤, 발산적 프롬프트 하나와 SWOT 분석 같은 '아이디어 검증용' 프롬프트를 조합해보세요. 아마 생각지도 못했던 명확성의 비약적인 상승을 경험하게 될 겁니다. 2026년, ChatGPT와 함께 여러분의 생각의 지평을 더욱 넓혀나가시길 바랍니다!\n  핵심 요약\n1. 명확한 컨텍스트 설정: ChatGPT에게 구체적인 목표와 제약 조건을 미리 알려 일반적인 답변을 방지하세요.\n2. 다양한 사고 확장: 발산적 사고, 역 브레인스토밍, 무작위 단어, SCAMPER를 활용해 사고의 폭을 넓히세요.\n3. 아이디어 현실 점검: SWOT 분석과 역할극을 통해 아이디어의 강점, 약점, 기회, 위협을 파악하고 다양한 관점을 통합하세요.\n4. 실행 가능한 로드맵: 아이디어를 영향력과 노력 기준으로 평가하고, 단기 성과, 장기 투자, 실험, 취소 항목으로 분류하여 구체적인 실행 계획을 세우세요.\n  이 프롬프트들을 활용하면 여러분의 브레인스토밍이 훨씬 더 깊고 실용적으로 변할 거예요!\n❓ 자주 묻는 질문 (FAQ)\nQ1: ChatGPT 브레인스토밍 프롬프트를 사용할 때 가장 중요한 점은 무엇인가요?\n가장 중요한 건 명확한 컨텍스트와 목표를 설정하는 거예요. ChatGPT를 단순한 아이디어 자동판매기가 아닌, 구조화된 브레인스토밍 파트너로 생각하고 구체적인 지침을 제공할수록 훨씬 더 유용하고 깊이 있는 결과를 얻을 수 있답니다. 마치 유능한 팀원에게 정확한 프로젝트 브리핑을 하는 것과 비슷하다고 보면 돼요!\nQ2: 여러 프롬프트를 어떻게 조합해서 사용하는 것이 좋을까요?\n저는 보통 초기 설정 프롬프트(#1)로 시작해서, 발산적 사고를 위한 프롬프트(#2)로 아이디어의 양을 늘려요. 그 다음, 역 브레인스토밍(#3)이나 SWOT 분석(#6) 같은 '검증용' 프롬프트로 아이디어를 점검하죠. 이렇게 하면 초기 아이디어의 맹점을 파악하고 보완할 수 있어서 정말 도움이 된답니다. 상황에 따라 SCAMPER(#5)나 역할극(#7)을 추가해서 더 깊이 있는 아이디어를 발굴하기도 해요.\nQ3: ChatGPT가 생성한 아이디어가 너무 일반적일 때는 어떻게 해야 할까요?\n음, 이런 경우도 자주 있죠! 그럴 때는 먼저 컨텍스트를 더 구체적으로 설명하는 게 좋아요. 예를 들어, \"이 아이디어를 20대 여성 직장인을 위한 뉴스레터에 적용한다면?\" 같이 대상 독자나 특정 상황을 더 명확히 제시하는 거죠. 그리고 역 브레인스토밍(#3)을 통해 '어떻게 하면 이 아이디어를 망칠 수 있을까?'를 고민해보면, 의외로 신선한 해결책이 나올 때가 많아요.\nQ4: 이 프롬프트들을 어디에 활용하면 가장 효과적일까요?\n개인적으로는 콘텐츠 기획, 마케팅 전략 수립, 제품 개발 아이디어 도출, 개인적인 목표 설정 등 다양한 분야에서 활용도가 높았어요. 특히 혼자서 막막할 때나 팀원들과 새로운 시각이 필요할 때 ChatGPT를 유능한 동료 삼아 이 프롬프트들을 적용해보면, 생각지도 못한 인사이트를 얻을 수 있을 거예요.\n\n\n        {\n          \"@context\": \"https://schema.org\",\n          \"@type\": \"FAQPage\",\n          \"mainEntity\": [\n            {\n              \"@type\": \"Question\",\n              \"name\": \"ChatGPT 브레인스토밍 프롬프트를 사용할 때 가장 중요한 점은 무엇인가요?\",\n              \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"가장 중요한 건 명확한 컨텍스트와 목표를 설정하는 거예요. ChatGPT를 단순한 아이디어 자동판매기가 아닌, 구조화된 브레인스토밍 파트너로 생각하고 구체적인 지침을 제공할수록 훨씬 더 유용하고 깊이 있는 결과를 얻을 수 있답니다. 마치 유능한 팀원에게 정확한 프로젝트 브리핑을 하는 것과 비슷하다고 보면 돼요!\"\n              }\n            },\n            {\n              \"@type\": \"Question\",\n              \"name\": \"여러 프롬프트를 어떻게 조합해서 사용하는 것이 좋을까요?\",\n              \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"저는 보통 초기 설정 프롬프트(#1)로 시작해서, 발산적 사고를 위한 프롬프트(#2)로 아이디어의 양을 늘려요. 그 다음, 역 브레인스토밍(#3)이나 SWOT 분석(#6) 같은 '검증용' 프롬프트로 아이디어를 점검하죠. 이렇게 하면 초기 아이디어의 맹점을 파악하고 보완할 수 있어서 정말 도움이 된답니다. 상황에 따라 SCAMPER(#5)나 역할극(#7)을 추가해서 더 깊이 있는 아이디어를 발굴하기도 해요.\"\n              }\n            },\n            {\n              \"@type\": \"Question\",\n              \"name\": \"ChatGPT가 생성한 아이디어가 너무 일반적일 때는 어떻게 해야 할까요?\",\n              \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"음, 이런 경우도 자주 있죠! 그럴 때는 먼저 컨텍스트를 더 구체적으로 설명하는 게 좋아요. 예를 들어, '이 아이디어를 20대 여성 직장인을 위한 뉴스레터에 적용한다면?' 같이 대상 독자나 특정 상황을 더 명확히 제시하는 거죠. 그리고 역 브레인스토밍(#3)을 통해 '어떻게 하면 이 아이디어를 망칠 수 있을까?'를 고민해보면, 의외로 신선한 해결책이 나올 때가 많아요.\"\n              }\n            },\n            {\n              \"@type\": \"Question\",\n              \"name\": \"이 프롬프트들을 어디에 활용하면 가장 효과적일까요?\",\n              \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"개인적으로는 콘텐츠 기획, 마케팅 전략 수립, 제품 개발 아이디어 도출, 개인적인 목표 설정 등 다양한 분야에서 활용도가 높았어요. 특히 혼자서 막막할 때나 팀원들과 새로운 시각이 필요할 때 ChatGPT를 유능한 동료 삼아 이 프롬프트들을 적용해보면, 생각지도 못한 인사이트를 얻을 수 있을 거예요.\"\n              }\n            }\n          ]\n        }",
        "guid": "https://muzbox.tistory.com/483700",
        "categories": [
          "AI, 미래기술/프롬프트 다이어리",
          "AI 아이디어",
          "ChatGPT 브레인스토밍",
          "SCAMPER 프레임워크",
          "SWOT 분석",
          "뉴스레터 기획",
          "디지털 마케팅 전략",
          "문제 해결 기법",
          "생산성 향상 프롬프트",
          "역 브레인스토밍",
          "창의적 사고"
        ],
        "isoDate": "2026-01-15T23:34:44.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "2026년 전문가들이 극찬한 AI 3대장 심층 분석 (ChatGPT Plus, Adobe Firefly, Notion AI)",
        "link": "https://muzbox.tistory.com/483699",
        "pubDate": "Wed, 14 Jan 2026 10:26:50 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "https://muzbox.tistory.com/483699#entry483699comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #3c4043;\">\n<div style=\"background-color: #e8f4fd; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">매일 새로운 AI 도구가 쏟아져 나오는 2026년, 어떤 도구가 정말 우리의 시간과 돈을 투자할 가치가 있을까요? 수많은 AI 서비스 중에서 제가 직접 경험하고 전문가들이 극찬하는 단 세 가지 AI 도구, ChatGPT Plus, Adobe Firefly, 그리고 Notion AI를 심층 분석합니다. 이 글을 통해 여러분의 업무 생산성과 창의력을 한 차원 높여줄 현명한 AI 선택 가이드를 얻어가시길 바랍니다.</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/duPw4D/dJMcaiaZnWp/b4nortkleHifKECoWKQJgk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/duPw4D/dJMcaiaZnWp/b4nortkleHifKECoWKQJgk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/duPw4D/dJMcaiaZnWp/b4nortkleHifKECoWKQJgk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FduPw4D%2FdJMcaiaZnWp%2Fb4nortkleHifKECoWKQJgk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"2026년 미래형 사무실에서 ChatGPT Plus, Adobe Firefly, Notion AI 세 가지 AI 도구를 활용하여 생산성을 높이는 전문가들의 모습.\" loading=\"lazy\" width=\"500\" height=\"500\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>AI 홍수 시대, 진짜배기를 찾아서  </b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">사랑하든 싫어하든, 인공지능은 2026년 현재 우리의 삶 곳곳에 스며들어 있습니다. 매일같이 창의력, 생산성, 글쓰기 능력을 향상시키고 삶을 더 쉽게 만들어주겠다고 약속하는 새로운 AI 도구들이 쏟아져 나오고 있죠. 하지만 AI 시장이 팽창하면서 혼란도 함께 가중되고 있습니다. 너무나도 유혹적인 선택지, 수많은 구독 서비스, 인상적인 기능 목록 속에서 필요한지조차 불분명한 AI 도구에 쉽게 지갑을 열게 되는 경우가 많습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">하지만 모든 AI 도구가 똑같지는 않습니다. 어떤 도구들은 터무니없이 비싸거나 그저 겉만 번지르르한 기능으로 가득한 반면, 소수의 도구들은 실제로 비용을 정당화할 만큼 뛰어난 성능을 발휘합니다. 저는 지난 몇 년간 생산성, 이미지 생성 등 다양한 분야의 여러 AI 도구들을 직접 시험하고 사용해봤어요. 솔직히 말해서 대부분의 AI 도구는 돈 낭비라고 생각했습니다. 그럼에도 불구하고, 실제로 돈을 지불할 가치가 있다고 확신하는 세 가지 도구를 발견했습니다. 이제 그 세 가지 AI 3대장을 심층적으로 파헤쳐 볼 시간입니다.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>1. ChatGPT Plus: 대화형 AI의 기준을 높이다  </b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">혹시 AI 챗봇을 사용해보고는 기대 이하였다고 실망한 적 있으신가요? 아마 여러분만 그런 것은 아닐 거예요. 무료 버전의 챗봇들은 보통 느린 속도, 기본 모델, 사용량 제한, 그리고 한정된 기능을 제공하기 마련이죠. 저 역시 몇 주 동안 ChatGPT 무료 버전을 사용했습니다. 주로 아이디어를 브레인스토밍하고, 복잡한 정보를 요약하고, 일정을 계획하거나, 새로운 쇼핑 리서치 기능을 시도하는 데 사용했죠.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">몇 주간 사용한 후, 저는 ChatGPT Plus로 업그레이드를 결정했습니다. 이미 많은 친구들이 사용하며 만족하고 있었거든요. 그리고 Plus 버전으로 전환했을 때, 단순히 업그레이드를 넘어선 <b>완전히 새로운 경험</b>이라는 것을 깨달았습니다. 정말 <b>게임 체인저</b>였어요.</p>\n<h3 data-ke-size=\"size23\"><b>ChatGPT Plus, 왜 전문가들의 선택일까요?</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">월 20달러라는 합리적인 비용으로, 여러분은 <b>더 나은 추론 능력을 가진 최첨단 ChatGPT 5 모델</b>에 접근할 수 있게 됩니다. 이 모델은 복잡한 프롬프트를 훨씬 더 잘 처리하고, 맥락을 정확하게 이해하며, <b>더 스마트하고 신뢰할 수 있는 답변</b>을 제공합니다. 게다가 피크 시간대에 대기할 필요 없이 우선적인 접근 권한을 얻어 더 빠른 응답을 받을 수 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">무엇보다 ChatGPT Plus는 <b>더 나은 설명, 뛰어난 지원, 그리고 창의적인 답변</b>을 제공하는 데 탁월합니다. 비즈니스 아이디어를 브레인스토밍하고 싶을 때, 코드를 디버깅해야 할 때, 답변에 창의성을 더하고 싶을 때, 또는 일상적인 작업을 자동화하고 싶을 때, ChatGPT Plus의 고급 모델은 비교할 수 없는 신뢰할 수 있는 결과를 제공할 것입니다.</p>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  팁: ChatGPT Plus를 사용하면 복잡한 데이터 분석, 장문의 보고서 요약, 심지어 특정 주제에 대한 심도 있는 연구까지 훨씬 빠르고 정확하게 수행할 수 있습니다. 여러분의 디지털 비서가 한 단계 더 진화하는 경험을 할 수 있을 거예요.</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/JCTWC/dJMcadAHa12/cRPIEgIeZB7AgL6hpry2OK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/JCTWC/dJMcadAHa12/cRPIEgIeZB7AgL6hpry2OK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/JCTWC/dJMcadAHa12/cRPIEgIeZB7AgL6hpry2OK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FJCTWC%2FdJMcadAHa12%2FcRPIEgIeZB7AgL6hpry2OK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>2. Adobe Firefly: 창의력을 현실로, 상업적 활용까지  </b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">만약 여러분이 소셜 미디어 게시물, 일러스트레이션, 제품 이미지 또는 디자인 프로토타입과 같은 시각적 콘텐츠를 생성하는 사람이라면, 이미 인기 있는 생성형 이미지 도구들을 사용해봤을 가능성이 높습니다. 이들 중 많은 도구가 무료로 제공되지만, 소수의 도구만이 <b>놀라운 수준의 창의적 제어력</b>을 선사합니다. 저는 Google의 Nano Banana, Midjourney, Canva, 그리고 Adobe Firefly를 사용해봤고, 각기 독특한 강점과 단점을 가지고 있었죠.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">그중에서도 저에게 특히 인상 깊었던 AI 이미지 생성 도구는 바로 <b>Adobe Firefly</b>였습니다. Firefly는 아름다운 Pinterest 스타일의 이미지를 자유롭게 만들 수 있게 해줄 뿐만 아니라, <b>전문가 수준의 에셋</b>을 제공하고 <b>상업적으로 안전하게 사용할 수 있는 결과물</b>을 생성해줍니다. Firefly는 가장 유능한 텍스트-이미지 생성기 중 하나로, 텍스트 프롬프트만으로 <b>텍스트 효과까지 적용</b>할 수 있습니다.</p>\n<h3 data-ke-size=\"size23\"><b>Firefly의 핵심 기능과 통합의 힘</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">저는 온라인 비즈니스와 소셜 미디어를 위한 몇몇 이미지를 생성해 보았는데, 결과물이 정말 마음에 들었습니다. Firefly는 여러분의 창의적인 갈증을 해소해줄 수많은 스타일을 제공합니다. Firefly의 가장 큰 장점 중 하나는 <b>Adobe Creative Cloud와의 완벽한 통합</b>입니다. 덕분에 Generative Fill(생성형 채우기), Generative Recolor(생성형 재색상), Generative Expand(생성형 확장)와 같은 뛰어난 기능들을 Photoshop, Premiere Pro, Illustrator 등 핵심 앱 내에서 바로 사용할 수 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">무료 버전은 제한된 크레딧, 워터마크가 있는 결과물, 기본적인 기능만 제공하며 Adobe 앱과의 통합은 불가능합니다. 저는 무료 버전을 사용해보고 그 결과물에 너무 감탄한 나머지, 결국 프로 버전으로 업그레이드했습니다. 프로 버전은 추가 크레딧, 프리미엄 기능, Adobe 앱 통합, 그리고 ChatGPT 및 Gemini와 같은 파트너 AI 모델에 대한 접근을 가능하게 합니다.</p>\n<div style=\"background-color: #fce8e6; border-left: 4px solid #d93025; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">⚠️ 주의: 생성형 AI 이미지의 저작권 문제나 상업적 이용 가능 여부는 플랫폼마다 다릅니다. Adobe Firefly는 상업적 사용에 안전하다고 명시하고 있으나, 다른 도구를 사용할 때는 반드시 라이선스 규정을 확인해야 합니다.</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">만약 여러분이 디지털 아티스트, 소셜 미디어 관리자 또는 소규모 사업자라면, Firefly의 유료 버전은 충분히 그만한 가치를 할 것입니다. 특히 기존 어도비 사용자라면 워크플로우를 혁신할 수 있는 최고의 도구가 될 거예요.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/cyYeS0/dJMcabCVs9H/DeS6MtBtBdaDZRT573gyBk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cyYeS0/dJMcabCVs9H/DeS6MtBtBdaDZRT573gyBk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cyYeS0/dJMcabCVs9H/DeS6MtBtBdaDZRT573gyBk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcyYeS0%2FdJMcabCVs9H%2FDeS6MtBtBdaDZRT573gyBk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"Adobe Firefly의 강력한 생성형 이미지 기능을 활용해 독창적인 비주얼 콘텐츠를 만드는 디지털 아티스트.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>3. Notion AI: 스마트한 작업 공간의 완성  </b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">Notion은 이미 강력한 디지털 워크스페이스로서 우리의 정리 정돈을 돕는 유능한 도구입니다. 여기에 Notion AI가 더해지면 여러분의 생산성은 완전히 새로운 수준으로 도약합니다. 텍스트를 생성하는 데 도움이 되는 많은 도구들이 있지만, Notion AI는 <b>기존 Notion 워크스페이스에 통합</b>되어 있어 훨씬 더 유용하고 손쉽게 사용할 수 있다는 장점이 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">Notion AI는 글쓰기 도우미, AI 챗봇, 그리고 스마트 검색 엔진 역할을 한 곳에서 모두 수행합니다. 블로그 게시물 초안을 작성하거나, 아이디어를 브레인스토밍하고, 페이지를 다른 언어로 번역하는 등 훨씬 더 많은 작업을 할 수 있죠. 또한, 여러분의 워크스페이스 또는 Slack, Google Drive와 같은 연결된 앱에서 특정 질문을 할 수도 있습니다. 예를 들어, &ldquo;내 최종 선정 피치는 무엇이었지?&rdquo;라고 물으면, Notion AI가 최근 Slack 대화를 스캔하여 관련 결과를 가져다줄 것입니다.</p>\n<h3 data-ke-size=\"size23\"><b>Notion AI로 달라지는 워크플로우</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">Notion AI는 문서 디자인 개선을 제안하거나 PDF를 분석하여 핵심 요점을 추출해주는 데도 도움을 줄 수 있습니다. 저는 몇 년 동안 Notion을 사용해왔고, 무료 버전도 상당히 관대하다고 생각했습니다. 하지만 유료 버전은 협업 도구, 무제한 파일 업로드, 우선 지원, 비공개 팀 공간 등 유용한 추가 혜택을 제공합니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">특히 유료 버전에서 제공되는 Notion AI는 이 워크스페이스를 단순한 아이디어 기록 공간이 아니라, <b>모든 업무의 파트너</b>로 탈바꿈시켰습니다. 만약 여러분이 프리랜서, 크리에이터, 또는 작업을 정리하고 자주 협업해야 하는 사람이라면, Notion의 유료 구독에 투자하는 것은 매우 합리적인 선택이 될 것입니다.</p>\n<table style=\"width: 100%; border-collapse: collapse; margin: 25px 0; color: #3c4043;\" data-ke-align=\"alignLeft\">\n<thead>\n<tr style=\"background-color: #e8eaed;\">\n<th style=\"border: 1px solid #dadce0; padding: 12px; text-align: left; color: #3c4043;\">주요 AI 기능</th>\n<th style=\"border: 1px solid #dadce0; padding: 12px; text-align: left; color: #3c4043;\">활용 예시 및 이점</th>\n</tr>\n</thead>\n<tbody>\n<tr style=\"background-color: #f1f3f4;\">\n<td style=\"border: 1px solid #dadce0; padding: 12px; color: #3c4043;\">텍스트 생성 및 편집</td>\n<td style=\"border: 1px solid #dadce0; padding: 12px; color: #3c4043;\">블로그 초안, 아이디어 브레인스토밍, 보고서 요약, 문법 교정 등을 Notion 내에서 바로 처리</td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #dadce0; padding: 12px; color: #3c4043;\">워크스페이스 질문/검색</td>\n<td style=\"border: 1px solid #dadce0; padding: 12px; color: #3c4043;\">Slack, Google Drive 등 연동된 앱의 정보까지 통합 검색하여 필요한 정보를 빠르게 찾음</td>\n</tr>\n<tr style=\"background-color: #f1f3f4;\">\n<td style=\"border: 1px solid #dadce0; padding: 12px; color: #3c4043;\">PDF 분석 및 요약</td>\n<td style=\"border: 1px solid #dadce0; padding: 12px; color: #3c4043;\">긴 PDF 문서의 핵심 내용을 파악하고 질문에 대한 답변을 얻어 시간 절약</td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #dadce0; padding: 12px; color: #3c4043;\">디자인 및 레이아웃 개선</td>\n<td style=\"border: 1px solid #dadce0; padding: 12px; color: #3c4043;\">Notion 페이지의 가독성 및 시각적 매력을 높이는 AI 기반 제안 받기</td>\n</tr>\n</tbody>\n</table>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>AI 도구, 언제 유료 버전을 선택해야 할까요?  </b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">피드에 뜨는 모든 AI 도구에 비용을 지불하고 싶은 유혹을 느끼는 것은 당연합니다. 하지만 신중한 접근 방식은 불필요한 디지털 혼란과 지출을 피하는 데 도움이 될 수 있습니다. 만약 여러분이 <b>전문가이거나 AI를 계획, 글쓰기, 코딩, 또는 창의적인 워크플로우에 깊이 통합하려는 사람</b>이라면, AI 도구에 비용을 지불하는 것이 합리적입니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">유료 버전은 다음과 같은 이점을 제공합니다:</p>\n<ul style=\"list-style-type: disc; padding-left: 20px; margin-bottom: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px;\"><b>더욱 고급스러운 기능</b>: 무료 버전에는 없는 전문가용 기능을 활용할 수 있습니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>강화된 보안 및 신뢰성</b>: 민감한 데이터를 다루거나 중요한 프로젝트에 사용할 때 더욱 안심할 수 있습니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>고품질 결과물</b>: 더 유능한 AI 모델에 접근하여 훨씬 정교하고 만족스러운 결과물을 얻을 수 있습니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>우선 지원 및 통합 혜택</b>: 문제 발생 시 빠른 지원을 받거나 다른 서비스와의 연동성을 높일 수 있습니다.</li>\n</ul>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">결론적으로, AI를 집약적으로 사용하고 고품질 결과를 얻기 위해 더 유능한 AI 모델에 접근하고 싶다면 유료 버전은 충분히 그 가치를 합니다. 반면에 AI를 가끔씩만 사용하고 작업을 자동화하는 데 AI에 의존하지 않는 캐주얼 사용자라면, 무료 버전을 고수하는 것도 좋은 생각입니다. 무료 버전만으로도 여러분의 요구 사항과 기대치의 80%는 충족될 수 있습니다. 무료 버전은 가벼운 사용이나 실험에는 훌륭하지만, 깊이와 신뢰성이 부족할 수 있습니다. 이 점을 크게 신경 쓰지 않는다면 무료 버전을 계속 사용하는 것이 현명할 수 있습니다.</p>\n<!-- 핵심 요약 카드 -->\n<div style=\"background-color: #f8f9fa; border: 1px solid #dadce0; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); padding: 25px; margin: 30px 0;\">\n<div style=\"font-size: 26px; color: #1a73e8; font-weight: bold; margin-bottom: 15px; padding-bottom: 10px; border-bottom: 2px solid #1a73e8;\">  핵심 요약</div>\n<div style=\"font-size: 17px; line-height: 1.8; color: #3c4043;\">\n<p style=\"margin-bottom: 10px;\" data-ke-size=\"size16\">1. <b>ChatGPT Plus</b>는 더욱 <b>정교한 추론 능력</b>과 <b>빠른 응답 속도</b>로 전문적인 작업에 필수적입니다.</p>\n<p style=\"margin-bottom: 10px;\" data-ke-size=\"size16\">2. <b>Adobe Firefly</b>는 <b>상업적으로 안전한 고품질 이미지</b>를 생성하며, Adobe Creative Cloud와의 <b>최고의 통합성</b>을 자랑합니다.</p>\n<p style=\"margin-bottom: 10px;\" data-ke-size=\"size16\">3. <b>Notion AI</b>는 기존 Notion 워크스페이스에 <b>AI 기능을 완벽하게 통합</b>하여 생산성을 극대화하는 올인원 비서입니다.</p>\n<p style=\"margin-bottom: 0;\" data-ke-size=\"size16\">4. AI 유료 버전은 <b>집약적인 사용</b>과 <b>고품질 결과</b>가 필요한 전문가에게, 무료 버전은 <b>가벼운 실험 및 캐주얼 사용자</b>에게 적합합니다.</p>\n</div>\n<div style=\"font-size: 14px; color: #5f6368; margin-top: 25px; padding-top: 15px; border-top: 1px solid #dadce0;\">* 이 정보는 2026년 1월 14일 기준으로 작성되었습니다.</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q1: 2026년 현재, 어떤 AI 도구가 가장 전문가에게 추천되나요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A1: 2026년 현재, 전문가들 사이에서 가장 각광받고 있는 AI 도구는 ChatGPT Plus, Adobe Firefly, Notion AI입니다. 이들은 각자의 분야에서 독보적인 기능과 효율성을 제공하여 작업의 질과 생산성을 크게 향상시킬 수 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q2: ChatGPT Plus는 무료 버전과 비교하여 어떤 점이 크게 다른가요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A2: ChatGPT Plus는 최신 모델인 ChatGPT 5 접근, 피크 시간대 대기열 없음, 더 빠른 응답 속도, 복잡한 프롬프트 처리 능력 향상, 그리고 훨씬 더 정교하고 창의적인 답변을 제공합니다. 이는 비즈니스 아이디어 구상, 코드 디버깅, 콘텐츠 생성 등 전문적인 작업에 필수적인 요소입니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q3: Adobe Firefly를 사용해야 하는 주된 이유는 무엇인가요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A3: Adobe Firefly는 상업적으로 안전하게 사용할 수 있는 고품질 이미지를 생성하며, 텍스트 효과 적용 등 강력한 텍스트-이미지 변환 기능을 제공합니다. 특히 Adobe Creative Cloud 제품군과의 완벽한 통합으로 기존 디자인 워크플로우를 더욱 효율적으로 만듭니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q4: Notion AI가 다른 생산성 AI 도구와 차별화되는 점은 무엇인가요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A4: Notion AI는 기존 Notion 워크스페이스에 깊이 통합되어 있어, 별도의 도구를 오갈 필요 없이 바로 작업을 수행할 수 있습니다. 글쓰기, 아이디어 구상, 번역은 물론, 연결된 앱(Slack, Google Drive 등)의 정보를 바탕으로 스마트 검색과 요약 기능을 제공하여 통합적인 생산성 향상을 돕습니다.</p>\n<script type=\"application/ld+json\">\n    {\n      \"@context\": \"https://schema.org\",\n      \"@type\": \"FAQPage\",\n      \"mainEntity\": [\n        {\n          \"@type\": \"Question\",\n          \"name\": \"2026년 현재, 어떤 AI 도구가 가장 전문가에게 추천되나요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"2026년 현재, 전문가들 사이에서 가장 각광받고 있는 AI 도구는 ChatGPT Plus, Adobe Firefly, Notion AI입니다. 이들은 각자의 분야에서 독보적인 기능과 효율성을 제공하여 작업의 질과 생산성을 크게 향상시킬 수 있습니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"ChatGPT Plus는 무료 버전과 비교하여 어떤 점이 크게 다른가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"ChatGPT Plus는 최신 모델인 ChatGPT 5 접근, 피크 시간대 대기열 없음, 더 빠른 응답 속도, 복잡한 프롬프트 처리 능력 향상, 그리고 훨씬 더 정교하고 창의적인 답변을 제공합니다. 이는 비즈니스 아이디어 구상, 코드 디버깅, 콘텐츠 생성 등 전문적인 작업에 필수적인 요소입니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"Adobe Firefly를 사용해야 하는 주된 이유는 무엇인가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"Adobe Firefly는 상업적으로 안전하게 사용할 수 있는 고품질 이미지를 생성하며, 텍스트 효과 적용 등 강력한 텍스트-이미지 변환 기능을 제공합니다. 특히 Adobe Creative Cloud 제품군과의 완벽한 통합으로 기존 디자인 워크플로우를 더욱 효율적으로 만듭니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"Notion AI가 다른 생산성 AI 도구와 차별화되는 점은 무엇인가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"Notion AI는 기존 Notion 워크스페이스에 깊이 통합되어 있어, 별도의 도구를 오갈 필요 없이 바로 작업을 수행할 수 있습니다. 글쓰기, 아이디어 구상, 번역은 물론, 연결된 앱(Slack, Google Drive 등)의 정보를 바탕으로 스마트 검색과 요약 기능을 제공하여 통합적인 생산성 향상을 돕습니다.\"\n          }\n        }\n      ]\n    }\n    </script>\n<p style=\"margin-bottom: 20px; font-size: 15px; text-align: center; color: #5f6368; margin-top: 30px;\" data-ke-size=\"size16\">AI 기술은 계속해서 발전하고 있습니다. 오늘 소개된 AI 3대장이 여러분의 2026년을 더욱 빛나게 하기를 바랍니다. <br />궁금한 점이나 의견이 있다면 언제든지 댓글로 남겨주세요!</p>\n</div>",
        "contentSnippet": "매일 새로운 AI 도구가 쏟아져 나오는 2026년, 어떤 도구가 정말 우리의 시간과 돈을 투자할 가치가 있을까요? 수많은 AI 서비스 중에서 제가 직접 경험하고 전문가들이 극찬하는 단 세 가지 AI 도구, ChatGPT Plus, Adobe Firefly, 그리고 Notion AI를 심층 분석합니다. 이 글을 통해 여러분의 업무 생산성과 창의력을 한 차원 높여줄 현명한 AI 선택 가이드를 얻어가시길 바랍니다.\n\n\nAI 홍수 시대, 진짜배기를 찾아서  \n사랑하든 싫어하든, 인공지능은 2026년 현재 우리의 삶 곳곳에 스며들어 있습니다. 매일같이 창의력, 생산성, 글쓰기 능력을 향상시키고 삶을 더 쉽게 만들어주겠다고 약속하는 새로운 AI 도구들이 쏟아져 나오고 있죠. 하지만 AI 시장이 팽창하면서 혼란도 함께 가중되고 있습니다. 너무나도 유혹적인 선택지, 수많은 구독 서비스, 인상적인 기능 목록 속에서 필요한지조차 불분명한 AI 도구에 쉽게 지갑을 열게 되는 경우가 많습니다.\n하지만 모든 AI 도구가 똑같지는 않습니다. 어떤 도구들은 터무니없이 비싸거나 그저 겉만 번지르르한 기능으로 가득한 반면, 소수의 도구들은 실제로 비용을 정당화할 만큼 뛰어난 성능을 발휘합니다. 저는 지난 몇 년간 생산성, 이미지 생성 등 다양한 분야의 여러 AI 도구들을 직접 시험하고 사용해봤어요. 솔직히 말해서 대부분의 AI 도구는 돈 낭비라고 생각했습니다. 그럼에도 불구하고, 실제로 돈을 지불할 가치가 있다고 확신하는 세 가지 도구를 발견했습니다. 이제 그 세 가지 AI 3대장을 심층적으로 파헤쳐 볼 시간입니다.\n1. ChatGPT Plus: 대화형 AI의 기준을 높이다  \n혹시 AI 챗봇을 사용해보고는 기대 이하였다고 실망한 적 있으신가요? 아마 여러분만 그런 것은 아닐 거예요. 무료 버전의 챗봇들은 보통 느린 속도, 기본 모델, 사용량 제한, 그리고 한정된 기능을 제공하기 마련이죠. 저 역시 몇 주 동안 ChatGPT 무료 버전을 사용했습니다. 주로 아이디어를 브레인스토밍하고, 복잡한 정보를 요약하고, 일정을 계획하거나, 새로운 쇼핑 리서치 기능을 시도하는 데 사용했죠.\n몇 주간 사용한 후, 저는 ChatGPT Plus로 업그레이드를 결정했습니다. 이미 많은 친구들이 사용하며 만족하고 있었거든요. 그리고 Plus 버전으로 전환했을 때, 단순히 업그레이드를 넘어선 완전히 새로운 경험이라는 것을 깨달았습니다. 정말 게임 체인저였어요.\nChatGPT Plus, 왜 전문가들의 선택일까요?\n월 20달러라는 합리적인 비용으로, 여러분은 더 나은 추론 능력을 가진 최첨단 ChatGPT 5 모델에 접근할 수 있게 됩니다. 이 모델은 복잡한 프롬프트를 훨씬 더 잘 처리하고, 맥락을 정확하게 이해하며, 더 스마트하고 신뢰할 수 있는 답변을 제공합니다. 게다가 피크 시간대에 대기할 필요 없이 우선적인 접근 권한을 얻어 더 빠른 응답을 받을 수 있습니다.\n무엇보다 ChatGPT Plus는 더 나은 설명, 뛰어난 지원, 그리고 창의적인 답변을 제공하는 데 탁월합니다. 비즈니스 아이디어를 브레인스토밍하고 싶을 때, 코드를 디버깅해야 할 때, 답변에 창의성을 더하고 싶을 때, 또는 일상적인 작업을 자동화하고 싶을 때, ChatGPT Plus의 고급 모델은 비교할 수 없는 신뢰할 수 있는 결과를 제공할 것입니다.\n  팁: ChatGPT Plus를 사용하면 복잡한 데이터 분석, 장문의 보고서 요약, 심지어 특정 주제에 대한 심도 있는 연구까지 훨씬 빠르고 정확하게 수행할 수 있습니다. 여러분의 디지털 비서가 한 단계 더 진화하는 경험을 할 수 있을 거예요.\n\n\n2. Adobe Firefly: 창의력을 현실로, 상업적 활용까지  \n만약 여러분이 소셜 미디어 게시물, 일러스트레이션, 제품 이미지 또는 디자인 프로토타입과 같은 시각적 콘텐츠를 생성하는 사람이라면, 이미 인기 있는 생성형 이미지 도구들을 사용해봤을 가능성이 높습니다. 이들 중 많은 도구가 무료로 제공되지만, 소수의 도구만이 놀라운 수준의 창의적 제어력을 선사합니다. 저는 Google의 Nano Banana, Midjourney, Canva, 그리고 Adobe Firefly를 사용해봤고, 각기 독특한 강점과 단점을 가지고 있었죠.\n그중에서도 저에게 특히 인상 깊었던 AI 이미지 생성 도구는 바로 Adobe Firefly였습니다. Firefly는 아름다운 Pinterest 스타일의 이미지를 자유롭게 만들 수 있게 해줄 뿐만 아니라, 전문가 수준의 에셋을 제공하고 상업적으로 안전하게 사용할 수 있는 결과물을 생성해줍니다. Firefly는 가장 유능한 텍스트-이미지 생성기 중 하나로, 텍스트 프롬프트만으로 텍스트 효과까지 적용할 수 있습니다.\nFirefly의 핵심 기능과 통합의 힘\n저는 온라인 비즈니스와 소셜 미디어를 위한 몇몇 이미지를 생성해 보았는데, 결과물이 정말 마음에 들었습니다. Firefly는 여러분의 창의적인 갈증을 해소해줄 수많은 스타일을 제공합니다. Firefly의 가장 큰 장점 중 하나는 Adobe Creative Cloud와의 완벽한 통합입니다. 덕분에 Generative Fill(생성형 채우기), Generative Recolor(생성형 재색상), Generative Expand(생성형 확장)와 같은 뛰어난 기능들을 Photoshop, Premiere Pro, Illustrator 등 핵심 앱 내에서 바로 사용할 수 있습니다.\n무료 버전은 제한된 크레딧, 워터마크가 있는 결과물, 기본적인 기능만 제공하며 Adobe 앱과의 통합은 불가능합니다. 저는 무료 버전을 사용해보고 그 결과물에 너무 감탄한 나머지, 결국 프로 버전으로 업그레이드했습니다. 프로 버전은 추가 크레딧, 프리미엄 기능, Adobe 앱 통합, 그리고 ChatGPT 및 Gemini와 같은 파트너 AI 모델에 대한 접근을 가능하게 합니다.\n⚠️ 주의: 생성형 AI 이미지의 저작권 문제나 상업적 이용 가능 여부는 플랫폼마다 다릅니다. Adobe Firefly는 상업적 사용에 안전하다고 명시하고 있으나, 다른 도구를 사용할 때는 반드시 라이선스 규정을 확인해야 합니다.\n만약 여러분이 디지털 아티스트, 소셜 미디어 관리자 또는 소규모 사업자라면, Firefly의 유료 버전은 충분히 그만한 가치를 할 것입니다. 특히 기존 어도비 사용자라면 워크플로우를 혁신할 수 있는 최고의 도구가 될 거예요.\n\n\n3. Notion AI: 스마트한 작업 공간의 완성  \nNotion은 이미 강력한 디지털 워크스페이스로서 우리의 정리 정돈을 돕는 유능한 도구입니다. 여기에 Notion AI가 더해지면 여러분의 생산성은 완전히 새로운 수준으로 도약합니다. 텍스트를 생성하는 데 도움이 되는 많은 도구들이 있지만, Notion AI는 기존 Notion 워크스페이스에 통합되어 있어 훨씬 더 유용하고 손쉽게 사용할 수 있다는 장점이 있습니다.\nNotion AI는 글쓰기 도우미, AI 챗봇, 그리고 스마트 검색 엔진 역할을 한 곳에서 모두 수행합니다. 블로그 게시물 초안을 작성하거나, 아이디어를 브레인스토밍하고, 페이지를 다른 언어로 번역하는 등 훨씬 더 많은 작업을 할 수 있죠. 또한, 여러분의 워크스페이스 또는 Slack, Google Drive와 같은 연결된 앱에서 특정 질문을 할 수도 있습니다. 예를 들어, “내 최종 선정 피치는 무엇이었지?”라고 물으면, Notion AI가 최근 Slack 대화를 스캔하여 관련 결과를 가져다줄 것입니다.\nNotion AI로 달라지는 워크플로우\nNotion AI는 문서 디자인 개선을 제안하거나 PDF를 분석하여 핵심 요점을 추출해주는 데도 도움을 줄 수 있습니다. 저는 몇 년 동안 Notion을 사용해왔고, 무료 버전도 상당히 관대하다고 생각했습니다. 하지만 유료 버전은 협업 도구, 무제한 파일 업로드, 우선 지원, 비공개 팀 공간 등 유용한 추가 혜택을 제공합니다.\n특히 유료 버전에서 제공되는 Notion AI는 이 워크스페이스를 단순한 아이디어 기록 공간이 아니라, 모든 업무의 파트너로 탈바꿈시켰습니다. 만약 여러분이 프리랜서, 크리에이터, 또는 작업을 정리하고 자주 협업해야 하는 사람이라면, Notion의 유료 구독에 투자하는 것은 매우 합리적인 선택이 될 것입니다.\n주요 AI 기능\n활용 예시 및 이점\n\n\n\n\n텍스트 생성 및 편집\n블로그 초안, 아이디어 브레인스토밍, 보고서 요약, 문법 교정 등을 Notion 내에서 바로 처리\n\n\n워크스페이스 질문/검색\nSlack, Google Drive 등 연동된 앱의 정보까지 통합 검색하여 필요한 정보를 빠르게 찾음\n\n\nPDF 분석 및 요약\n긴 PDF 문서의 핵심 내용을 파악하고 질문에 대한 답변을 얻어 시간 절약\n\n\n디자인 및 레이아웃 개선\nNotion 페이지의 가독성 및 시각적 매력을 높이는 AI 기반 제안 받기\n\n\n\nAI 도구, 언제 유료 버전을 선택해야 할까요?  \n피드에 뜨는 모든 AI 도구에 비용을 지불하고 싶은 유혹을 느끼는 것은 당연합니다. 하지만 신중한 접근 방식은 불필요한 디지털 혼란과 지출을 피하는 데 도움이 될 수 있습니다. 만약 여러분이 전문가이거나 AI를 계획, 글쓰기, 코딩, 또는 창의적인 워크플로우에 깊이 통합하려는 사람이라면, AI 도구에 비용을 지불하는 것이 합리적입니다.\n유료 버전은 다음과 같은 이점을 제공합니다:\n더욱 고급스러운 기능: 무료 버전에는 없는 전문가용 기능을 활용할 수 있습니다.\n강화된 보안 및 신뢰성: 민감한 데이터를 다루거나 중요한 프로젝트에 사용할 때 더욱 안심할 수 있습니다.\n고품질 결과물: 더 유능한 AI 모델에 접근하여 훨씬 정교하고 만족스러운 결과물을 얻을 수 있습니다.\n우선 지원 및 통합 혜택: 문제 발생 시 빠른 지원을 받거나 다른 서비스와의 연동성을 높일 수 있습니다.\n결론적으로, AI를 집약적으로 사용하고 고품질 결과를 얻기 위해 더 유능한 AI 모델에 접근하고 싶다면 유료 버전은 충분히 그 가치를 합니다. 반면에 AI를 가끔씩만 사용하고 작업을 자동화하는 데 AI에 의존하지 않는 캐주얼 사용자라면, 무료 버전을 고수하는 것도 좋은 생각입니다. 무료 버전만으로도 여러분의 요구 사항과 기대치의 80%는 충족될 수 있습니다. 무료 버전은 가벼운 사용이나 실험에는 훌륭하지만, 깊이와 신뢰성이 부족할 수 있습니다. 이 점을 크게 신경 쓰지 않는다면 무료 버전을 계속 사용하는 것이 현명할 수 있습니다.\n  핵심 요약\n1. ChatGPT Plus는 더욱 정교한 추론 능력과 빠른 응답 속도로 전문적인 작업에 필수적입니다.\n2. Adobe Firefly는 상업적으로 안전한 고품질 이미지를 생성하며, Adobe Creative Cloud와의 최고의 통합성을 자랑합니다.\n3. Notion AI는 기존 Notion 워크스페이스에 AI 기능을 완벽하게 통합하여 생산성을 극대화하는 올인원 비서입니다.\n4. AI 유료 버전은 집약적인 사용과 고품질 결과가 필요한 전문가에게, 무료 버전은 가벼운 실험 및 캐주얼 사용자에게 적합합니다.\n* 이 정보는 2026년 1월 14일 기준으로 작성되었습니다.\n❓ 자주 묻는 질문 (FAQ)\nQ1: 2026년 현재, 어떤 AI 도구가 가장 전문가에게 추천되나요?\nA1: 2026년 현재, 전문가들 사이에서 가장 각광받고 있는 AI 도구는 ChatGPT Plus, Adobe Firefly, Notion AI입니다. 이들은 각자의 분야에서 독보적인 기능과 효율성을 제공하여 작업의 질과 생산성을 크게 향상시킬 수 있습니다.\nQ2: ChatGPT Plus는 무료 버전과 비교하여 어떤 점이 크게 다른가요?\nA2: ChatGPT Plus는 최신 모델인 ChatGPT 5 접근, 피크 시간대 대기열 없음, 더 빠른 응답 속도, 복잡한 프롬프트 처리 능력 향상, 그리고 훨씬 더 정교하고 창의적인 답변을 제공합니다. 이는 비즈니스 아이디어 구상, 코드 디버깅, 콘텐츠 생성 등 전문적인 작업에 필수적인 요소입니다.\nQ3: Adobe Firefly를 사용해야 하는 주된 이유는 무엇인가요?\nA3: Adobe Firefly는 상업적으로 안전하게 사용할 수 있는 고품질 이미지를 생성하며, 텍스트 효과 적용 등 강력한 텍스트-이미지 변환 기능을 제공합니다. 특히 Adobe Creative Cloud 제품군과의 완벽한 통합으로 기존 디자인 워크플로우를 더욱 효율적으로 만듭니다.\nQ4: Notion AI가 다른 생산성 AI 도구와 차별화되는 점은 무엇인가요?\nA4: Notion AI는 기존 Notion 워크스페이스에 깊이 통합되어 있어, 별도의 도구를 오갈 필요 없이 바로 작업을 수행할 수 있습니다. 글쓰기, 아이디어 구상, 번역은 물론, 연결된 앱(Slack, Google Drive 등)의 정보를 바탕으로 스마트 검색과 요약 기능을 제공하여 통합적인 생산성 향상을 돕습니다.\nAI 기술은 계속해서 발전하고 있습니다. 오늘 소개된 AI 3대장이 여러분의 2026년을 더욱 빛나게 하기를 바랍니다. \n궁금한 점이나 의견이 있다면 언제든지 댓글로 남겨주세요!",
        "guid": "https://muzbox.tistory.com/483699",
        "categories": [
          "AI, 미래기술/AI 인사이트",
          "2026년 AI 도구",
          "Adobe Firefly 활용",
          "AI 유료 버전 장점",
          "AI 이미지 생성",
          "ai 챗봇 비교",
          "ai 협업 도구",
          "chatgpt plus 기능",
          "Notion AI 생산성",
          "생성형 ai 추천",
          "전문가 AI 추천"
        ],
        "isoDate": "2026-01-14T01:26:50.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "｜RULIWEB｜",
        "title": "보드 위의 새옹지마, 더 게임 오브 라이프 for NS",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2410",
        "pubDate": "Thu, 15 Jan 2026 17:44:43 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/26/01/15/19bc0cda9f251ad6b.webp\">",
        "contentSnippet": "",
        "categories": [
          "게임툰"
        ],
        "isoDate": "2026-01-15T08:44:43.000Z"
      },
      {
        "creator": "｜RULIWEB｜",
        "title": "악역영애 4컷 만화 - 35화, 영애 없는 영애 학교 근황 데스와",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2409",
        "pubDate": "Wed, 14 Jan 2026 21:25:36 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/26/01/14/19bbc775ac351ad6b.webp\">",
        "contentSnippet": "",
        "categories": [
          "웹툰"
        ],
        "isoDate": "2026-01-14T12:25:36.000Z"
      },
      {
        "creator": "샤말란의눈",
        "title": "[MULTI] 나의 히어로 아카데미아 올즈 저스티스, 진일보한 연출과 게임 모드",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2408",
        "pubDate": "Tue, 13 Jan 2026 00:01:33 +0900",
        "author": "샤말란의눈",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/26/01/10/19ba39cb90213b2a1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "프리뷰"
        ],
        "isoDate": "2026-01-12T15:01:33.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "SID-ROOM v3 - 앱토스 NFT 게임 개발 - 점프 트리거 구현",
        "link": "https://serverdown.tistory.com/1560",
        "pubDate": "Mon, 19 Jan 2026 00:15:39 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1560#entry1560comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"sr_3_jump.gif\" data-origin-width=\"524\" data-origin-height=\"306\"><span data-url=\"https://blog.kakaocdn.net/dn/cYdYkq/dJMcabQt5lc/sBOGKxpZta6Oh1eIrmKwZK/img.gif\" data-phocus=\"https://blog.kakaocdn.net/dn/cYdYkq/dJMcabQt5lc/sBOGKxpZta6Oh1eIrmKwZK/img.gif\"><img src=\"https://blog.kakaocdn.net/dn/cYdYkq/dJMcabQt5lc/sBOGKxpZta6Oh1eIrmKwZK/img.gif\" srcset=\"https://blog.kakaocdn.net/dn/cYdYkq/dJMcabQt5lc/sBOGKxpZta6Oh1eIrmKwZK/img.gif\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"524\" height=\"306\" data-filename=\"sr_3_jump.gif\" data-origin-width=\"524\" data-origin-height=\"306\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">점프를 좀 날림으로 구현했군요</p>\n<p data-ke-size=\"size16\">하강할때 움직임이 이상합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">올라가기</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"sr_3_jump_up.gif\" data-origin-width=\"524\" data-origin-height=\"306\"><span data-url=\"https://blog.kakaocdn.net/dn/bLzLBv/dJMcaaD2Ulr/ek181K3QCzLxWPpmR0NgJk/img.gif\" data-phocus=\"https://blog.kakaocdn.net/dn/bLzLBv/dJMcaaD2Ulr/ek181K3QCzLxWPpmR0NgJk/img.gif\"><img src=\"https://blog.kakaocdn.net/dn/bLzLBv/dJMcaaD2Ulr/ek181K3QCzLxWPpmR0NgJk/img.gif\" srcset=\"https://blog.kakaocdn.net/dn/bLzLBv/dJMcaaD2Ulr/ek181K3QCzLxWPpmR0NgJk/img.gif\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"524\" height=\"306\" data-filename=\"sr_3_jump_up.gif\" data-origin-width=\"524\" data-origin-height=\"306\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">의도하지 않았지만 상자에 올라갈 수 있군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">낙하 처리</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"sr_3_reset.gif\" data-origin-width=\"524\" data-origin-height=\"306\"><span data-url=\"https://blog.kakaocdn.net/dn/8LK0R/dJMcabiFhyo/IDSDGq9kp6j46sYegMIhRK/img.gif\" data-phocus=\"https://blog.kakaocdn.net/dn/8LK0R/dJMcabiFhyo/IDSDGq9kp6j46sYegMIhRK/img.gif\"><img src=\"https://blog.kakaocdn.net/dn/8LK0R/dJMcabiFhyo/IDSDGq9kp6j46sYegMIhRK/img.gif\" srcset=\"https://blog.kakaocdn.net/dn/8LK0R/dJMcabiFhyo/IDSDGq9kp6j46sYegMIhRK/img.gif\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"524\" height=\"306\" data-filename=\"sr_3_reset.gif\" data-origin-width=\"524\" data-origin-height=\"306\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">게임 화면 밖으로 나가면 추락합니다.</p>\n<p data-ke-size=\"size16\">아래로 많이 내려가면 처음 위치로 리셋됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">트리거</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"sr_3_trigger.gif\" data-origin-width=\"524\" data-origin-height=\"306\"><span data-url=\"https://blog.kakaocdn.net/dn/CbQ7z/dJMcabXgggV/ZbofFk6RpCbW6UYkgKPUyK/img.gif\" data-phocus=\"https://blog.kakaocdn.net/dn/CbQ7z/dJMcabXgggV/ZbofFk6RpCbW6UYkgKPUyK/img.gif\"><img src=\"https://blog.kakaocdn.net/dn/CbQ7z/dJMcabXgggV/ZbofFk6RpCbW6UYkgKPUyK/img.gif\" srcset=\"https://blog.kakaocdn.net/dn/CbQ7z/dJMcabXgggV/ZbofFk6RpCbW6UYkgKPUyK/img.gif\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"524\" height=\"306\" data-filename=\"sr_3_trigger.gif\" data-origin-width=\"524\" data-origin-height=\"306\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">상호작용 구현을 하기위해 트리거를 만들었습니다.</p>\n<p data-ke-size=\"size16\">특정 위치로 가면 로그인창을 띄울 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">영상</h2>\n<p data-ke-size=\"size16\">전체영상: <a href=\"https://www.youtube.com/watch?v=VLuN_j0NuCE\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=VLuN_j0NuCE</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=VLuN_j0NuCE\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/WSSxN/dJMb9kl6AGd/rbncrYnjen9k4SSSNw1Na1/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360,https://scrap.kakaocdn.net/dn/ceovMH/dJMb9g44SNP/DOwHbekjBGhyruXxaoKMK0/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360,https://scrap.kakaocdn.net/dn/zyKIJ/dJMb9dHhLT1/sF6Dqe8qlwKD5IFzQeDgl0/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360\" data-video-width=\"480\" data-video-height=\"360\" data-video-origin-width=\"480\" data-video-origin-height=\"360\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"SID-ROOM v3 playdemo\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/VLuN_j0NuCE\" width=\"480\" height=\"360\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">로그인 절차</h2>\n<p data-ke-size=\"size16\">1. 로그인 창이 뜨면 로그인 버튼을 누른다.</p>\n<p data-ke-size=\"size16\">2. 지갑 연동 페이지가 열리면 지갑을 연동한다.</p>\n<p data-ke-size=\"size16\">3. 게임화면으로 돌아오면 숫자 값이 보일 것입니다. 6~8자리로 생각합니다.</p>\n<p data-ke-size=\"size16\">4. 게임케릭과 내 지갑 소유자 확인을 위해 게임 내에 표시된 숫자를 입력합니다.<br />&nbsp; &nbsp; 매번 연동하기 귀찮을 수 있으니 연동을 유지할 수 있는 기능이 필요하겠군요</p>\n<p data-ke-size=\"size16\">5. NFT 가 있다면 정보가 게임 내에 표시 됩니다.</p>\n<p data-ke-size=\"size16\">6. 거래중이 아닌 NFT 에는 무언가를 담거나 꺼낼 수 있습니다.</p>\n<p data-ke-size=\"size16\">이정도 구현하면 기능연동은 끝날 것 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 style=\"background-color: #000000; color: #000000; text-align: start;\" data-ke-size=\"size23\">링크들</h3>\n<p style=\"background-color: #000000; color: #000000; text-align: start;\" data-ke-size=\"size16\">웹페이지  <span style=\"background-color: #000000; color: #000000;\">&nbsp;</span><a style=\"background-color: #000000; color: #000000;\" href=\"https://nextjs-nft-kappa.vercel.app/\">Create Next App</a></p>\n<p style=\"background-color: #000000; color: #000000; text-align: start;\" data-ke-size=\"size16\">유튜브  <span style=\"background-color: #000000; color: #000000;\">&nbsp;</span><a style=\"background-color: #000000; color: #000000;\" href=\"https://www.youtube.com/@%EC%9D%B4%EB%A0%87%EA%B2%8C%EB%90%9C%EC%9D%B4%EC%83%81%EB%A9%94%ED%83%80%EB%B2%84%EC%8A%A4\">메타버스준비하자 - YouTube</a></p>\n<p style=\"background-color: #000000; color: #000000; text-align: start;\" data-ke-size=\"size16\">블로그  <span style=\"background-color: #000000; color: #000000;\">&nbsp;</span><a style=\"background-color: #000000; color: #000000;\" href=\"https://blog.sidnft.com/tag/SID-ROOM\">'SID-ROOM' 태그의 글 목록 :: 퇴근후서버다운 SIDNFT</a></p>\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "점프를 좀 날림으로 구현했군요\n하강할때 움직임이 이상합니다.\n \n올라가기\n\n\n의도하지 않았지만 상자에 올라갈 수 있군요\n \n낙하 처리\n\n\n게임 화면 밖으로 나가면 추락합니다.\n아래로 많이 내려가면 처음 위치로 리셋됩니다.\n \n트리거\n\n\n상호작용 구현을 하기위해 트리거를 만들었습니다.\n특정 위치로 가면 로그인창을 띄울 수 있습니다.\n \n영상\n전체영상: https://www.youtube.com/watch?v=VLuN_j0NuCE\n\n\n\n \n \n \n로그인 절차\n1. 로그인 창이 뜨면 로그인 버튼을 누른다.\n2. 지갑 연동 페이지가 열리면 지갑을 연동한다.\n3. 게임화면으로 돌아오면 숫자 값이 보일 것입니다. 6~8자리로 생각합니다.\n4. 게임케릭과 내 지갑 소유자 확인을 위해 게임 내에 표시된 숫자를 입력합니다.\n    매번 연동하기 귀찮을 수 있으니 연동을 유지할 수 있는 기능이 필요하겠군요\n5. NFT 가 있다면 정보가 게임 내에 표시 됩니다.\n6. 거래중이 아닌 NFT 에는 무언가를 담거나 꺼낼 수 있습니다.\n이정도 구현하면 기능연동은 끝날 것 같습니다.\n \n \n링크들\n웹페이지   Create Next App\n유튜브   메타버스준비하자 - YouTube\n블로그   'SID-ROOM' 태그의 글 목록 :: 퇴근후서버다운 SIDNFT",
        "guid": "https://serverdown.tistory.com/1560",
        "categories": [
          "프로그래밍/자작",
          "aptos",
          "SID-ROOM",
          "unity",
          "앱토스",
          "유니티"
        ],
        "isoDate": "2026-01-18T15:15:39.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "BEVY 0.17 / RUST 게임엔진 소식",
        "link": "https://serverdown.tistory.com/1559",
        "pubDate": "Sat, 17 Jan 2026 13:20:23 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1559#entry1559comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"821\" data-origin-height=\"491\"><span data-url=\"https://blog.kakaocdn.net/dn/c0nPdf/dJMcagjWWEV/YJgR2w4bKYBYaMe1Csw0nk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/c0nPdf/dJMcagjWWEV/YJgR2w4bKYBYaMe1Csw0nk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/c0nPdf/dJMcagjWWEV/YJgR2w4bKYBYaMe1Csw0nk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc0nPdf%2FdJMcagjWWEV%2FYJgR2w4bKYBYaMe1Csw0nk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"821\" height=\"491\" data-origin-width=\"821\" data-origin-height=\"491\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">RUST 로 제작되서</p>\n<p data-ke-size=\"size16\">멀티코어에 특화 되어있는거 같습니다.</p>\n<p data-ke-size=\"size16\">꾸준히 업데이트 되고 있군요</p>\n<p data-ke-size=\"size16\">지켜봐야할꺼 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=7VuSzV_Gcsw\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=7VuSzV_Gcsw</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=7VuSzV_Gcsw\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/3MO1h/dJMb9fry49z/Dk8jO4dK8rKaDzQigypGEK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/bfGfxi/dJMb9lL5e1E/iJzPHJW44KyPfo0fWMR5p0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"Bevy 0.17 -- Rust Powered Game Engine -- Now with Raytracing!\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/7VuSzV_Gcsw\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "RUST 로 제작되서\n멀티코어에 특화 되어있는거 같습니다.\n꾸준히 업데이트 되고 있군요\n지켜봐야할꺼 같습니다.\n \n영상: https://www.youtube.com/watch?v=7VuSzV_Gcsw",
        "guid": "https://serverdown.tistory.com/1559",
        "categories": [
          "프로그래밍/개발메모",
          "bevy",
          "rust"
        ],
        "isoDate": "2026-01-17T04:20:23.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "SID-ROOM v2 - 앱토스 NFT 게임 개발",
        "link": "https://serverdown.tistory.com/1558",
        "pubDate": "Fri, 16 Jan 2026 23:15:24 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1558#entry1558comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"buildgame_2.gif\" data-origin-width=\"544\" data-origin-height=\"266\"><span data-url=\"https://blog.kakaocdn.net/dn/cXIJvf/dJMcaa46YBN/YzkqiCENKTytkK0KjNmOw1/img.gif\" data-phocus=\"https://blog.kakaocdn.net/dn/cXIJvf/dJMcaa46YBN/YzkqiCENKTytkK0KjNmOw1/img.gif\"><img src=\"https://blog.kakaocdn.net/dn/cXIJvf/dJMcaa46YBN/YzkqiCENKTytkK0KjNmOw1/img.gif\" srcset=\"https://blog.kakaocdn.net/dn/cXIJvf/dJMcaa46YBN/YzkqiCENKTytkK0KjNmOw1/img.gif\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"544\" height=\"266\" data-filename=\"buildgame_2.gif\" data-origin-width=\"544\" data-origin-height=\"266\"/></span></figure>\n</p>\n<p style=\"text-align: left;\" data-ke-size=\"size16\">업데이트 내용</p>\n<p style=\"text-align: left;\" data-ke-size=\"size16\">- Z 축이동<br />- 상자 추가<br />- 바닥 추가</p>\n<p style=\"text-align: left;\" data-ke-size=\"size16\"><span style=\"text-align: left;\">2시간 정도 작업했습니다.</span></p>\n<p style=\"text-align: left;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: left;\" data-ke-size=\"size16\"><span style=\"text-align: left;\">레딕에 글도 올렸습니다.</span></p>\n<p style=\"text-align: left;\" data-ke-size=\"size16\"><span style=\"text-align: left;\">레딧 <span style=\"text-align: start;\"> </span> &nbsp; <a href=\"https://www.reddit.com/r/KoreanGameDev/comments/1qf47f6/nft_%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94_%EA%B2%8C%EC%9E%84_%EB%A7%8C%EB%93%A4%EA%B8%B0_%EC%8B%9C%EC%9E%91%ED%96%88%EC%8A%B5%EB%8B%88%EB%8B%A4/\">NFT 사용하는 게임 만들기 시작했습니다. : r/KoreanGameDev</a> </span></p>\n<figure id=\"og_1768643813341\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Reddit의 KoreanGameDev 커뮤니티\" data-og-description=\"KoreanGameDev 커뮤니티에서 이 게시물을 비롯한 다양한 콘텐츠를 살펴보세요\" data-og-host=\"www.reddit.com\" data-og-source-url=\"https://www.reddit.com/r/KoreanGameDev/comments/1qf47f6/nft_%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94_%EA%B2%8C%EC%9E%84_%EB%A7%8C%EB%93%A4%EA%B8%B0_%EC%8B%9C%EC%9E%91%ED%96%88%EC%8A%B5%EB%8B%88%EB%8B%A4/\" data-og-url=\"https://www.reddit.com/r/KoreanGameDev/comments/1qf47f6/nft_사용하는_게임_만들기_시작했습니다/?seeker-session=true\" data-og-image=\"https://scrap.kakaocdn.net/dn/cgATfz/dJMb88eUeLB/82H96JqFFoKg3ySirQ8YTK/img.jpg?width=1120&amp;height=584&amp;face=0_0_1120_584,https://scrap.kakaocdn.net/dn/bAmtN0/dJMb895XeSK/1KqHeJeMg5pKM2BIVxRxe1/img.jpg?width=1120&amp;height=584&amp;face=0_0_1120_584\"><a href=\"https://www.reddit.com/r/KoreanGameDev/comments/1qf47f6/nft_%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94_%EA%B2%8C%EC%9E%84_%EB%A7%8C%EB%93%A4%EA%B8%B0_%EC%8B%9C%EC%9E%91%ED%96%88%EC%8A%B5%EB%8B%88%EB%8B%A4/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.reddit.com/r/KoreanGameDev/comments/1qf47f6/nft_%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94_%EA%B2%8C%EC%9E%84_%EB%A7%8C%EB%93%A4%EA%B8%B0_%EC%8B%9C%EC%9E%91%ED%96%88%EC%8A%B5%EB%8B%88%EB%8B%A4/\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/cgATfz/dJMb88eUeLB/82H96JqFFoKg3ySirQ8YTK/img.jpg?width=1120&amp;height=584&amp;face=0_0_1120_584,https://scrap.kakaocdn.net/dn/bAmtN0/dJMb895XeSK/1KqHeJeMg5pKM2BIVxRxe1/img.jpg?width=1120&amp;height=584&amp;face=0_0_1120_584');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Reddit의 KoreanGameDev 커뮤니티</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">KoreanGameDev 커뮤니티에서 이 게시물을 비롯한 다양한 콘텐츠를 살펴보세요</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.reddit.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: left;\" data-ke-size=\"size16\">&nbsp;</p>\n<h3 style=\"background-color: #000000; color: #000000; text-align: start;\" data-ke-size=\"size23\">링크들</h3>\n<p style=\"background-color: #000000; color: #000000; text-align: start;\" data-ke-size=\"size16\">웹페이지  <span>&nbsp;</span><a style=\"background-color: #000000; color: #000000;\" href=\"https://nextjs-nft-kappa.vercel.app/\">Create Next App</a></p>\n<p style=\"background-color: #000000; color: #000000; text-align: start;\" data-ke-size=\"size16\">유튜브  <span>&nbsp;</span><a style=\"background-color: #000000; color: #000000;\" href=\"https://www.youtube.com/@%EC%9D%B4%EB%A0%87%EA%B2%8C%EB%90%9C%EC%9D%B4%EC%83%81%EB%A9%94%ED%83%80%EB%B2%84%EC%8A%A4\">메타버스준비하자 - YouTube</a></p>\n<p style=\"background-color: #000000; color: #000000; text-align: start;\" data-ke-size=\"size16\">블로그  <span>&nbsp;</span><a style=\"background-color: #000000; color: #000000;\" href=\"https://blog.sidnft.com/tag/SID-ROOM\">'SID-ROOM' 태그의 글 목록 :: 퇴근후서버다운 SIDNFT</a></p>\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "업데이트 내용\n- Z 축이동\n- 상자 추가\n- 바닥 추가\n2시간 정도 작업했습니다.\n \n레딕에 글도 올렸습니다.\n레딧     NFT 사용하는 게임 만들기 시작했습니다. : r/KoreanGameDev \n\n \nReddit의 KoreanGameDev 커뮤니티\nKoreanGameDev 커뮤니티에서 이 게시물을 비롯한 다양한 콘텐츠를 살펴보세요\nwww.reddit.com\n\n \n \n링크들\n웹페이지   Create Next App\n유튜브   메타버스준비하자 - YouTube\n블로그   'SID-ROOM' 태그의 글 목록 :: 퇴근후서버다운 SIDNFT",
        "guid": "https://serverdown.tistory.com/1558",
        "categories": [
          "프로그래밍/자작",
          "SID-ROOM"
        ],
        "isoDate": "2026-01-16T14:15:24.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "SID-ROOM v1 - 앱토스 NFT 게임 개발 시작했습니다.",
        "link": "https://serverdown.tistory.com/1557",
        "pubDate": "Thu, 15 Jan 2026 22:33:05 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1557#entry1557comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"464\" data-origin-height=\"196\"><span data-url=\"https://blog.kakaocdn.net/dn/ykf46/dJMcadOelQc/jymJlhbt7D9UwdYNMXI8N1/img.gif\" data-phocus=\"https://blog.kakaocdn.net/dn/ykf46/dJMcadOelQc/jymJlhbt7D9UwdYNMXI8N1/img.gif\"><img src=\"https://blog.kakaocdn.net/dn/ykf46/dJMcadOelQc/jymJlhbt7D9UwdYNMXI8N1/img.gif\" srcset=\"https://blog.kakaocdn.net/dn/ykf46/dJMcadOelQc/jymJlhbt7D9UwdYNMXI8N1/img.gif\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"464\" height=\"196\" data-origin-width=\"464\" data-origin-height=\"196\"/></span></figure>\n</p>\n<h2 data-ke-size=\"size26\">시작</h2>\n<p data-ke-size=\"size16\">NFT 으로 게임을 적용시킬 예정입니다.</p>\n<p data-ke-size=\"size16\">spum 언제 써보나 하다 이제 붙여 봤습니다.</p>\n<p data-ke-size=\"size16\">케릭터 이동을 구현했습니다.</p>\n<p data-ke-size=\"size16\">앞으로 꾸준히 연재하겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">계획</h2>\n<p data-ke-size=\"size16\"><a href=\"https://www.youtube.com/watch?v=0atlSxgwOtc\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=0atlSxgwOtc</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=0atlSxgwOtc\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/hCwgz/dJMb8PGpEem/EQZPigtP8FeMcHH3PQaTr0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/cR5doU/dJMb8RjVppt/EyAmnI602o50gdgPeTudk0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/bl4vQV/dJMb86nQ1uz/aPaltP3Ro0KHaF0PN5ccJ1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"393일차 #2 - 다시 NFT / APTOS (앱토스)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/0atlSxgwOtc\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">제 앱토스 NFT 시작 영상입니다.</p>\n<p data-ke-size=\"size16\">한번 봐주시구요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">개발 순서</h2>\n<p data-ke-size=\"size16\">1. 드래곤퀘스트 (영상 끝부분 참조) 비슷한 카메라 시점으로 블록 쌓기를 구현합니다.</p>\n<p data-ke-size=\"size16\">2. NFT 를 사용해 로그인하고 내 정보를 저장합니다.</p>\n<p data-ke-size=\"size16\">3. NFT 에 케릭터 아이템 땅 같은걸 저장합니다.</p>\n<p data-ke-size=\"size16\">4. NFT 를 판매해 실제 아이템 거래를 구현합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">랜딩페이지</h2>\n<p data-ke-size=\"size16\"><a href=\"https://room.sidnft.com/\">SID-ROOM | Aptos NFT</a></p>\n<p data-ke-size=\"size16\">아직은 볼품없지만 ...</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"440\" data-origin-height=\"482\"><span data-url=\"https://blog.kakaocdn.net/dn/LLn99/dJMcacaM351/ywocz4VTETYJfK0sa0iWs0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/LLn99/dJMcacaM351/ywocz4VTETYJfK0sa0iWs0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/LLn99/dJMcacaM351/ywocz4VTETYJfK0sa0iWs0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FLLn99%2FdJMcacaM351%2Fywocz4VTETYJfK0sa0iWs0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"440\" height=\"482\" data-origin-width=\"440\" data-origin-height=\"482\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">좀 엉상하긴한데 시작이니까요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\">링크들</h3>\n<p data-ke-size=\"size16\">웹페이지   <a href=\"https://nextjs-nft-kappa.vercel.app/\">Create Next App</a></p>\n<p data-ke-size=\"size16\">유튜브   <a href=\"https://www.youtube.com/@%EC%9D%B4%EB%A0%87%EA%B2%8C%EB%90%9C%EC%9D%B4%EC%83%81%EB%A9%94%ED%83%80%EB%B2%84%EC%8A%A4\">메타버스준비하자 - YouTube</a></p>\n<p data-ke-size=\"size16\">블로그   <a href=\"https://blog.sidnft.com/tag/SID-ROOM\">'SID-ROOM' 태그의 글 목록 :: 퇴근후서버다운 SIDNFT</a></p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "시작\nNFT 으로 게임을 적용시킬 예정입니다.\nspum 언제 써보나 하다 이제 붙여 봤습니다.\n케릭터 이동을 구현했습니다.\n앞으로 꾸준히 연재하겠습니다.\n \n \n계획\nhttps://www.youtube.com/watch?v=0atlSxgwOtc\n\n\n\n \n제 앱토스 NFT 시작 영상입니다.\n한번 봐주시구요\n \n개발 순서\n1. 드래곤퀘스트 (영상 끝부분 참조) 비슷한 카메라 시점으로 블록 쌓기를 구현합니다.\n2. NFT 를 사용해 로그인하고 내 정보를 저장합니다.\n3. NFT 에 케릭터 아이템 땅 같은걸 저장합니다.\n4. NFT 를 판매해 실제 아이템 거래를 구현합니다.\n \n랜딩페이지\nSID-ROOM | Aptos NFT\n아직은 볼품없지만 ...\n\n\n좀 엉상하긴한데 시작이니까요\n \n링크들\n웹페이지   Create Next App\n유튜브   메타버스준비하자 - YouTube\n블로그   'SID-ROOM' 태그의 글 목록 :: 퇴근후서버다운 SIDNFT",
        "guid": "https://serverdown.tistory.com/1557",
        "categories": [
          "프로그래밍/자작",
          "SID-ROOM"
        ],
        "isoDate": "2026-01-15T13:33:05.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": [
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "좋은 태도, 나쁜 태도",
        "link": "https://jojoldu.tistory.com/857",
        "pubDate": "Mon, 19 Jan 2026 08:58:42 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "https://jojoldu.tistory.com/857#entry857comment",
        "content": "<p data-ke-size=\"size16\">최근 기회가 되어서 개발자의 커리어에 관한 발표를 했다.<br />발표 주제는 \"탐욕 알고리즘처럼 너무 각 단계별로 최적화된 선택을 하느라 전체 최적화를 놓치는 우를 범하지 말라\" 였다.<br />(이에 관해서도 따로 글로 쓸 예정이다.)</p>\n<p data-ke-size=\"size16\">그 발표에서 \"좋은 경험과 나쁜 경험은 없으며, 좋은 태도와 나쁜 태도만 있는 것 같다\" 라는 이야기를 드렸다.</p>\n<p data-ke-size=\"size16\">발표가 끝나고 QnA 때 \"그럼 좋은 태도와 나쁜 태도를 가르는 기준이 어떻게 되나요?\" 라는 질문을 받았다.</p>\n<p data-ke-size=\"size16\">미리 생각해둔 질문은 아니였어서 곰곰히 생각해보고 나서 다음과 같이 답변 드렸다.</p>\n<p data-ke-size=\"size16\">\"<b>지금 주어진 이 일이 커리어에 도움이 되냐/안되냐를 끊임없이 판단하는 건 좋은 태도가 아닌 것 같다</b>.<br />커리어에 도움이 안되는 일이면 잘하기 위해 노력하지 않게 된다.<br />그러면 결국 그 일은 도움이 안되는 경험으로 마무리 된다.</p>\n<p data-ke-size=\"size16\">반면, 그 일이 커리어에 도움이 될지 안될지 상관없이 이 일을 잘하기 위해 노력하는 것만 생각한다면 그게 어떤 경험이든 이후에 도움이 되는 경우가 많다.</p>\n<p data-ke-size=\"size16\">좋아하는 일을 선택할 수 없는 상황이라면 주어진 일 그 자체를 좋아하는 것이 좋은 태도인 것 같다.<br />그리고 그 일을 좋아하려면, 그 일을 잘해야하는데, 잘하기 위한 노력 과정들이 결국은 좋은 경험으로 갈무리 되는 것 같다.\"</p>\n<p data-ke-size=\"size16\">여러 채널을 통해 개발자분들의 고민을 듣다보면 \"미래에 내가 가고 싶은 회사, 하고 싶은 직무를 정해두고\" 현재의 경험을 설계하는데 거기서 불일치하는 경우가 생기면 불행하다고 느끼는 경우를 많이 봤다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>합격한 회사가 풀스택을 원하는데 저는 백엔드 개발자가 되고 싶어서 백엔드만 전문적으로 할 수 있는 회사에 계속 지원해보려고요.</li>\n<li>네이버 백엔드 개발자로 취업하고 싶은데 현재는 SI 회사여서 프론트엔드, 인프라 등 여러가지를 다 하고 있어서 고민이다.</li>\n<li>빅테크 개발자로 이직할 계획인데, 현재는 스타트업이라 MSA, k8s 같은 경험을 못해보고 있다. 회사에선 저런 환경으로의 개선 일정을 전혀 주지 않아서 고민이다.</li>\n<li>실시간 유저 트래픽을 받아보고 싶은데, 회사에선 계속 내부 어드민 개선 일감만 주어서 고민이다.</li>\n</ul>\n<p data-ke-size=\"size16\">내가 생각한대로 최적화된 선택만 할 수 있는 환경은 잘 없다.</p>\n<p data-ke-size=\"size16\">주변의 좋은 시니어 개발자분들을 보면 생각보다 생각한대로의 커리어 패스를 순차적으로 밟아오신 분들은 많지 않았다.</p>\n<p data-ke-size=\"size16\">그렇지만 어느 일정 궤도에 오르신 선배들을 보면 대부분 \"<b>본인은 운이 좋아서 좋은 경험들을 많이 했고, 덕분에 좋은 기회를 얻을 수 있었다</b>\" 라고 이야기 하신다.</p>\n<p data-ke-size=\"size16\">대부분은 우연한 기회로 새로운 일을 맡게 되고 , 그 일 자체를 잘하기 위해 노력하던 과정에서 새로운 경험을 얻게 되고, 그 새로운 경험으로 새로운 기회를 얻게되는 그런 과정들을 많이들 겪으셨다.</p>\n<p data-ke-size=\"size16\"><b>시간이 지나고보니 그게 좋은 경험인 것을 알 수 있는 것이지, 시작하는 단계에서 판단할 수 있는 것이 아니다</b>.</p>\n<p data-ke-size=\"size16\">어떤 경험을 선택하기 전에 이게 나한테 좋은지 아닌지를 너무 길게 판단할 필요는 없는 것 같다.</p>\n<p data-ke-size=\"size16\">어떤 경험이든 그걸 잘 하기 위한 생각만 바꾸어도 그건 전부 다 나에게 도움이 되는 경험이 되는 것 같다.</p>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">그런 면에서 <a href=\"https://product.kyobobook.co.kr/detail/S000000582065\">늦깎이 천재들의 비밀</a> 도 추천한다.</p>\n</blockquote>",
        "contentSnippet": "최근 기회가 되어서 개발자의 커리어에 관한 발표를 했다.\n발표 주제는 \"탐욕 알고리즘처럼 너무 각 단계별로 최적화된 선택을 하느라 전체 최적화를 놓치는 우를 범하지 말라\" 였다.\n(이에 관해서도 따로 글로 쓸 예정이다.)\n그 발표에서 \"좋은 경험과 나쁜 경험은 없으며, 좋은 태도와 나쁜 태도만 있는 것 같다\" 라는 이야기를 드렸다.\n발표가 끝나고 QnA 때 \"그럼 좋은 태도와 나쁜 태도를 가르는 기준이 어떻게 되나요?\" 라는 질문을 받았다.\n미리 생각해둔 질문은 아니였어서 곰곰히 생각해보고 나서 다음과 같이 답변 드렸다.\n\"지금 주어진 이 일이 커리어에 도움이 되냐/안되냐를 끊임없이 판단하는 건 좋은 태도가 아닌 것 같다.\n커리어에 도움이 안되는 일이면 잘하기 위해 노력하지 않게 된다.\n그러면 결국 그 일은 도움이 안되는 경험으로 마무리 된다.\n반면, 그 일이 커리어에 도움이 될지 안될지 상관없이 이 일을 잘하기 위해 노력하는 것만 생각한다면 그게 어떤 경험이든 이후에 도움이 되는 경우가 많다.\n좋아하는 일을 선택할 수 없는 상황이라면 주어진 일 그 자체를 좋아하는 것이 좋은 태도인 것 같다.\n그리고 그 일을 좋아하려면, 그 일을 잘해야하는데, 잘하기 위한 노력 과정들이 결국은 좋은 경험으로 갈무리 되는 것 같다.\"\n여러 채널을 통해 개발자분들의 고민을 듣다보면 \"미래에 내가 가고 싶은 회사, 하고 싶은 직무를 정해두고\" 현재의 경험을 설계하는데 거기서 불일치하는 경우가 생기면 불행하다고 느끼는 경우를 많이 봤다.\n합격한 회사가 풀스택을 원하는데 저는 백엔드 개발자가 되고 싶어서 백엔드만 전문적으로 할 수 있는 회사에 계속 지원해보려고요.\n네이버 백엔드 개발자로 취업하고 싶은데 현재는 SI 회사여서 프론트엔드, 인프라 등 여러가지를 다 하고 있어서 고민이다.\n빅테크 개발자로 이직할 계획인데, 현재는 스타트업이라 MSA, k8s 같은 경험을 못해보고 있다. 회사에선 저런 환경으로의 개선 일정을 전혀 주지 않아서 고민이다.\n실시간 유저 트래픽을 받아보고 싶은데, 회사에선 계속 내부 어드민 개선 일감만 주어서 고민이다.\n내가 생각한대로 최적화된 선택만 할 수 있는 환경은 잘 없다.\n주변의 좋은 시니어 개발자분들을 보면 생각보다 생각한대로의 커리어 패스를 순차적으로 밟아오신 분들은 많지 않았다.\n그렇지만 어느 일정 궤도에 오르신 선배들을 보면 대부분 \"본인은 운이 좋아서 좋은 경험들을 많이 했고, 덕분에 좋은 기회를 얻을 수 있었다\" 라고 이야기 하신다.\n대부분은 우연한 기회로 새로운 일을 맡게 되고 , 그 일 자체를 잘하기 위해 노력하던 과정에서 새로운 경험을 얻게 되고, 그 새로운 경험으로 새로운 기회를 얻게되는 그런 과정들을 많이들 겪으셨다.\n시간이 지나고보니 그게 좋은 경험인 것을 알 수 있는 것이지, 시작하는 단계에서 판단할 수 있는 것이 아니다.\n어떤 경험을 선택하기 전에 이게 나한테 좋은지 아닌지를 너무 길게 판단할 필요는 없는 것 같다.\n어떤 경험이든 그걸 잘 하기 위한 생각만 바꾸어도 그건 전부 다 나에게 도움이 되는 경험이 되는 것 같다.\n그런 면에서 늦깎이 천재들의 비밀 도 추천한다.",
        "guid": "https://jojoldu.tistory.com/857",
        "categories": [
          "생각정리",
          "개발자",
          "늦깎이 천재들의 비밀",
          "루프클럽",
          "좋은 태도",
          "커리어",
          "커리어 패스"
        ],
        "isoDate": "2026-01-18T23:58:42.000Z"
      }
    ]
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "코드 품질 개선 기법 29편: 고르디우스 변수",
        "link": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-29",
        "pubDate": "Thu, 15 Jan 2026 17:30:00 GMT",
        "content": "이 글은 2024년 6월 13일에 일본어로 먼저 발행된 기사를 번역한 글입니다.LY Corporation은 높은 개발 생산성을 유지하기 위해 코드 품질 및 개발 문화 개선에 힘쓰고...",
        "contentSnippet": "이 글은 2024년 6월 13일에 일본어로 먼저 발행된 기사를 번역한 글입니다.LY Corporation은 높은 개발 생산성을 유지하기 위해 코드 품질 및 개발 문화 개선에 힘쓰고...",
        "guid": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-29",
        "isoDate": "2026-01-15T17:30:00.000Z"
      },
      {
        "title": "엔터프라이즈 LLM 서비스 구축기 1: 컨텍스트 엔지니어링",
        "link": "https://techblog.lycorp.co.jp/ko/building-an-llm-service-for-enterprise-1-context-engineering",
        "pubDate": "Wed, 14 Jan 2026 02:00:00 GMT",
        "content": "들어가며안녕하세요. Cloud AI Platform 팀에서 AI 어시스턴트의 PM 및 기술 리딩을 맡고 있는 한우형입니다. 클라우드 환경에 AI를 도입해 운영 생산성을 높이는 일을...",
        "contentSnippet": "들어가며안녕하세요. Cloud AI Platform 팀에서 AI 어시스턴트의 PM 및 기술 리딩을 맡고 있는 한우형입니다. 클라우드 환경에 AI를 도입해 운영 생산성을 높이는 일을...",
        "guid": "https://techblog.lycorp.co.jp/ko/building-an-llm-service-for-enterprise-1-context-engineering",
        "isoDate": "2026-01-14T02:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": [
      {
        "title": "React랑 Lottie로 게임을 만든다고요?",
        "link": "https://blog.banksalad.com/tech/banksalad-react-lottie/",
        "pubDate": "Thu, 15 Jan 2026 00:00:00 GMT",
        "content": "안녕하세요, 뱅크샐러드 프론트엔드 엔지니어 김덕현입니다. 웹뷰 환경에서 게임 엔진 없이 React와 DOM, 그리고 Lottie…",
        "contentSnippet": "안녕하세요, 뱅크샐러드 프론트엔드 엔지니어 김덕현입니다. 웹뷰 환경에서 게임 엔진 없이 React와 DOM, 그리고 Lottie…",
        "guid": "https://blog.banksalad.com/tech/banksalad-react-lottie/",
        "isoDate": "2026-01-15T00:00:00.000Z"
      },
      {
        "title": "2025 re:Invent 여정",
        "link": "https://blog.banksalad.com/tech/aws-reinvent-2025/",
        "pubDate": "Tue, 13 Jan 2026 00:00:00 GMT",
        "content": "2025 re:Invent 여정 AWS re:Invent…",
        "contentSnippet": "2025 re:Invent 여정 AWS re:Invent…",
        "guid": "https://blog.banksalad.com/tech/aws-reinvent-2025/",
        "isoDate": "2026-01-13T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "학생 창업가를 위한 몇 가지 조언",
        "link": "https://www.thestartupbible.com/2026/01/some-words-of-advice-for-student-founders.html",
        "pubDate": "Sun, 18 Jan 2026 21:27:00 +0000",
        "content:encodedSnippet": "나는 개인적으로 학생 창업가를 좋아하고, 이들이 창업하는 걸 적극적으로 추천하고 응원한다. 우리가 학생 창업가에게만 전문적으로 투자하거나 이들에게만 투자하는 펀드가 있는 건 아니지만, 스트롱은 지금까지 꾸준히 대학생 창업팀에 투자하고 있고 이들이 하는 몇 개의 이벤트를 후원하고 있다. 그리고 우린 모두 다 바빠서 외부 강연이나 발표는 거의 안, 못 하고 있는데, 학생들 대상의 강연이나 발표, 또는 해커톤 심사는 웬만하면 시간을 만들어서 참석하고 있다. 창업가들의 나이는 점점 더 낮아지고 있는데, 우리가 지향하는 첫 번째 기관투자자가 되기 위해서는 이제는 학생들에게 투자해야 하기 때문이다. 결국 이 학생들은 스트롱의 미래의 고객이기 때문에 우리가 학생들 대상으로 하는 모든 활동은 잠재 고객에 대한 영업/마케팅 활동이라고 봐도 무방하다. 이들이 지금 또는 나중에 창업할 때, 가장 먼저 생각나는 VC가 스트롱벤처스가 되는 게 우리의 목표다.\n내가 스트롱을 시작한 2012년만 해도 학생들은 창업을 거의 하지 않았다. 창업이 뭔지도 몰랐고, 어떻게 하는지도 몰랐고, 이들에게 투자해 주는 VC도 없었다. 창업은 취업하지 못하면 어쩔 수 없이 선택해야 하는 마지막 옵션이었기 때문에 내가 당시에 만났던 학생 창업가들은 준비도 안 됐고, 실력도 없었다. 실은, 아직도 대부분의 학부생이나 대학원생들은 취업을 선호하긴 하지만, 요샌 창업을 1순위로 생각하는 학생들이 점점 더 많아지고 있다는 게 내 개인적인 생각이다.\n요새도 우린 더 많은 학생 창업가를 만나기 위한 방법에 대해서 고민하고 있는데, 혹시 이 글을 읽는 학생분들 중 좋은 방법이 있다면 언제든지 제안해 주시면 좋겠다.\n이미 창업했거나, 창업을 생각하는 학생들에게 내가 몇 가지 해주고 싶은 조언이 있다. 꼭 이렇게 하라는 건 아니지만, 창업하기 전에 충분히 생각해 봐야 하는 주제들이고, 몇 개는 나중에 회사가 켜졌을 때 이 회사를 완전히 망가뜨릴 수 있는 중요한 내용이라고 생각한다.\n일단 가장 첫 번째 조언은, 사업은 학교 과제가 아니라는 것이다. 내가 만나는 많은 학생 창업가는 실은 학생 창업가가 아니라 그냥 창업 과제를 하는 학생이다. 이들은 사업할 준비가 전혀 되지 않았고, 그냥 학업 외 재미있는 일을 하고 싶고, 멀리서 다른 창업가를 보니까 본인들도 할 수 있을 것 같다는 생각으로 법인설립하고 대표이사 명함 만들고, 코파운더 명함 만들면서 여기저기 기웃거리는 수준의 활동을 하고 있다. 어떤 분은 소위 말하는 스타트업 대표이사 놀이에 빠져있고, 졸업하고 대기업에 취직하는 게 목적인데, 이력서에 “ABC 창업 경험” 한 줄 달기 위해서 창업을 하는 경우도 있었다. 이렇게 하다 보니, 당연히 사업을 풀타임으로 안 한다. 학업을 하면서 사업을 병행하는데, 이렇게 대충대충, 건성건성 해서 제대로 된 사업을 만들 수 있다면, 우리가 14년 동안 투자한 290개의 회사는 모두 다 유니콘이 돼야 했다.\n그래서 내가 학생 창업가에게 가장 먼저 드리고 싶은 조언은, 정말로 제대로 사업을 하려면 일단 그 마음가짐부터 제대로 가지고, 이를 실제로 행동에 옮기려면 학업을 휴학하거나, 아니면 자퇴하라는 것이다. 이렇게 하지 않고서는 절대로 제대로 사업을 할 수가 없다. 너무 이진법적인 생각 같지만, 창업은 all in or nothing이다.\n두 번째 조언은, 교수님의 말을 맹신하지 말라는 것이다. 그리고 되도록 창업하는 회사의 주주명부에서 교수님은 빼거나, 아니면 이들의 지분을 2% 이하로 낮추라는 조언을 드리고 싶다. 내가 만나는 대부분의 학생 창업 스타트업은, 그리고 특히 지도교수가 있는 대학원생이 창업한 스타트업의 창업팀에는 지도교수가 들어가 있다. 그리고 대부분의 경우 이들은 30% 이상의 지분을 보유하고 있다. 이게 왜 틀렸는지는 내가 전에 이 글에서 대략 설명했는데, 다시 한번 간략하게 요약하자면, 스타트업의 코파운더는 1년 365일 하루 24시간 이 사업 생각만 해야 하고, 이 사업에 그 무엇보다 높은 우선순위를 둬야 한다. 교수들은 이게 구조적으로 안 된다. 왜냐하면 학교가 이들의 직장이라서 항상 학교가 이들의 우선순위이기 때문이다. 나는 회사가 잘 되면 가장 고생하고 기여를 많이 한 사람들이 가장 많은 돈을 벌어야 한다고 생각하는데 지분이 이걸 결정한다. 회사가 안 되면 역시 지분이 가장 많은 분들이 모든 책임과 비난을 받아야 한다. 하지만, 이 회사에 all in 하지 않고, 시간이 날 때마다 와서 파트타임으로 조언과 훈수를 하는 교수들이 지분을 이렇게 많이 보유하는 건 확실히 불공평하다고 생각한다. 어떤 교수들은 학교에서 가르치고, 본인이 창업한 회사가 있고, 지도하는 학생들이 창업한 3~4개 회사의 높은 지분을 보유한 C 레벨 임원으로 활동하고 있는데, 이런 구조로 회사가 나중에 투자받고, 좋은 사람을 채용하고, 잘 되는 건 쉽지 않다.\n그래서 되도록 교수는 창업팀에서 빼라. 꼭 이들의 조언이나 도움이 필요하다면 스톡옵션을 0.5% 이하로 주고 고문으로 모시는 걸 권장한다. 전에 어떤 학생 대표에게 이런 이야기를 하니까 굉장히 곤란해하면서 나에게 다음과 같은 말을 했다. 본인도 졸업해야 하는데, 지도교수님이 승인하지 않으면 졸업을 못 하므로 이런 껄끄러운 대화를 하는 게 너무 힘들다고. 그래서 내가 위에서 말한 대로 진짜로 사업을 하려면 그냥 학업을 중단하는 게 이런 졸업의 고민으로부터 자유로워질 수 있는 가장 좋은 방법이다. 아니면, 교수님과 이 힘든 대화를 해서 쇼부를 봐야 한다. 사업하면 이보다 훨씬 더 어려운 대화를 많이 해야 하고 훨씬 더 힘든 결정을 많이 해야 하는데, 여기서부터 막힌다면 사업 못 한다.\n마지막 조언은, 스타트업은 돈을 버는 사업을 만드는 곳이지, 그 누구도 따라 할 수 없는 기술을 개발하는 조직이 아니라는 점이다. 본인이 현재 개발하고 연구하는 분야가 세계 최고 수준이라면 이건 정말 대단하고 축하할만하다. 하지만, 그렇다고 이게 세계 최고의 사업이 된다는 보장은 없다. 아니, 그렇게 되는 경우는 거의 없다. 그럼, 노벨상 받은 모든 이론과 기술이 유니콘 사업이 돼야 한다. 기술은 그냥 단지 기술일 뿐이다. 이 기술을 기반으로 비즈니스 모델을 만들고, 더 나아가서는 돈을 버는 사업으로 진화시키는 건 완전히 다른 일이다. 연구보다 사업이 더 어렵다는 말이 아니다. 그냥 완전히 다르다는 말이다.\n우리 같은 VC는 기술에 투자하지 않는다. 그 기술로 만드는 돈을 버는 사업에 투자한다. 이걸 명확하게 이해해야 한다. \n나는 젊고, 똑똑하고, 에너지 넘치는 학생 창업가를 정말 좋아한다. 이들이 맘먹고 사고 치면 유니콘이 아니라 데카콘 몇 마리 만들 수 있다고 믿는다. 나는 더 많은 학생이 창업해야 한다고 생각한다. 특히, 위에서 말한 내용에 대해서 충분히 고민해 본 학생 창업가들이라면 언제든지 스트롱에 연락해 주시길.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2026/01/some-words-of-advice-for-student-founders.html#respond",
        "content": "나는 개인적으로 학생 창업가를 좋아하고, 이들이 창업하는 걸 적극적으로 추천하고 응원한다. 우리가 학생 창업가에게만 전문적으로 투자하거나 이들에게만 투자하는 펀드가 있는 건 아니지만, 스트롱은 지금까지 꾸준히 대학생 창업팀에 투자하고 있고 이들이 하는 몇 개의 이벤트를 후원하고 있다. 그리고 우린 모두 다 바빠서 외부 강연이나 발표는 거의 안, 못 하고 있는데, 학생들 대상의 강연이나 발표, 또는 해커톤(...)",
        "contentSnippet": "나는 개인적으로 학생 창업가를 좋아하고, 이들이 창업하는 걸 적극적으로 추천하고 응원한다. 우리가 학생 창업가에게만 전문적으로 투자하거나 이들에게만 투자하는 펀드가 있는 건 아니지만, 스트롱은 지금까지 꾸준히 대학생 창업팀에 투자하고 있고 이들이 하는 몇 개의 이벤트를 후원하고 있다. 그리고 우린 모두 다 바빠서 외부 강연이나 발표는 거의 안, 못 하고 있는데, 학생들 대상의 강연이나 발표, 또는 해커톤(...)",
        "guid": "https://www.thestartupbible.com/?p=9666",
        "categories": [
          "Uncategorized",
          "education",
          "FoundersAtWork",
          "Strong",
          "students",
          "vc"
        ],
        "isoDate": "2026-01-18T21:27:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "두 번 실수하지 말자",
        "link": "https://www.thestartupbible.com/2026/01/never-miss-twice.html",
        "pubDate": "Wed, 14 Jan 2026 21:34:00 +0000",
        "content:encodedSnippet": "바로 전 글에서 골프 이야기를 잠깐 했는데, 같은 내용으로 이 포스팅을 시작해 본다. 실제로 골프를 쳤던 방콕 골프장에서 1번 홀이 어려운 파 5였고, 여기서 나는 4개 오버해서 9개를 친 적이 있다.(골프 용어로는 쿼드러플인데, 절대로 해서는 안 되는 점수다). 그리고 그다음 2번 홀은 파3인데, 여기서 3개 오버하면서 6개를 쳐서 소위 말하는 양파를 했고, 3번 홀은 파4인데 6개를 쳐서 더블보기를 했다. 이렇게 치고 나니 18홀 중 3개를 쳤는데 점수는 이미 9+가 됐다. 그리고 이후 4번 홀부터 내 마인드는 어차피 이번 라운딩은 망했으니까 그냥 대충 막 쳐야겠다였고, 정말로 막 쳐서 최악의 점수가 나왔다. 그리고 막 치는 4시간 내내 이번 게임은 망했으니까, 다음에 제대로 쳐야지 생각했다.\n그런데 나중에 숙소로 돌아와서 생각해 보니, 정말 후회가 많이 됐고, 그날 내 행동에 대해 짜증이 많이 났다. 첫 3개 홀을 못 쳤으면, 그 다음엔 잘 치기 위해서 더 집중해야 했는데, 나는 그냥 이생망(=이번 생은 망했다)의 마인드로 고칠 수 있는 실수를 안 고치고 계속 실수했고, 이렇게 해서 조금만 경기가 안 풀리면 그냥 막 치는 게 습관화됐을 가능성이 매우 크다. 최악의 행동이었다.\n요새 내가 듣는 몇 팟캐스트의 단골이 ‘Atomic Habits’의 저자 제임스 클리어인데, 이 책에서 정확하게 이런 행동을 절대로 하지 말라고 하면서 “한 번 실수는 사고지만, 두 번 실수는 새로운 습관의 시작이 될 수 있다.”라는 말을 한다. 무슨 말이냐 하면, 내가 초반에 골프를 못 친건 사고지만, 이후에 포기하고 마음먹고 그냥 계속 실수한 건 나쁜 습관의 시작이 된다는 말이다.\n새해 결심을 아침에 운동을 열심히 하기로 했다면, 그리고 이게 작심삼일이 되는 나쁜 습관으로 바뀌는 걸 원치 않는다면, 매일 몸을 움직여야 한다. 아침 일찍 미팅이 있어서 하루 빠지고, 그다음 날은 늦게 일어나서 또 빠지면, 그냥 이번 주는 운동 안 하고 다음 주부터 열심히 해야지라는 생각을 많은 분들이 하는데, 이렇게 되면 일 년 내내 절대로 운동하지 않는다. 아침 일찍 미팅이 있어서 운동을 안 한 건 실수다. 그리고 늦게 일어나서 못 한 것도 실수다. 하지만, 그다음 날 곧바로 이 실수를 바로잡고 운동을 해야 한다. 안 그러면 운동하지 않는 행동이 습관화되기 때문이다.\n새해 결심이 다이어트라서 식단 관리를 잘하다가 화요일 저녁에 피자 한 판을 다 먹는 칼로리 폭탄 실수를 했다면, 그다음 날은 다시 제대로 식단 관리를 하면 된다. 하지만, 많은 사람들이 이렇게 먹으면 기분이 상하고 어차피 식단 망했기 때문에 이번 주는 그냥 막 먹고 다음 주부터 다시 식단 관리하자라는 생각으로 일주일 내내 막 먹는다. 이렇게 두 번, 세 번 실수하면 막 먹는 게 습관이 돼서 다이어트는 물 건너간다. 누구도 완벽할 순 없고, 누구나 다 실수할 수 있는데, 중요한 건 그 시점에 바로 고치는 것이다. 이생망 기분으로 두 번 실수하면, 정말로 이생망된다.\n운동을 빠지면, 다시 하면 된다. 잘하다가 또 빠지면, 그 이후에 또다시 하며 된다. 다이어트하는데 칼로리 폭탄을 먹었다면, 그다음 끼니는 건강하게 먹으면 된다. 건강하게 먹다가 어느 날 혼자서 치킨 한 마리랑 맥주를 먹었다면, 그다음 끼니부터 또 식단 관리하면 된다.\n제임스 클리어의 두 번 실수하지 않는 프레임은 다음과 같다. 하루를 4쿼터로 나누고, 이 중 4쿼터를 모두 완벽하게 살면 좋겠지만, 그렇게 하기는 너무 힘드니까 4쿼터 중 한 쿼터만 실수하는 걸 목표로 삼으라고 한다. 한 쿼터만 실수하고, 나머지 세 쿼터는 실수하지 않는 걸 목표로 하면 나름 좋은 습관을 만드는 인생을 살 수 있다고 한다.\n한 번 실수했을 때 너무 자책하거나 실망하지 말고, 곧바로 다시 시도하는 게 연속적으로 실패하는 습관의 형성을 방지할 수 있다. “이생망”이라는 말은 우리가 절대로 생각해서도 안 되고, 입에 담아서도 안 되는 말이다. 다음 생은 없으니까.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2026/01/never-miss-twice.html#comments",
        "content": "바로 전 글에서 골프 이야기를 잠깐 했는데, 같은 내용으로 이 포스팅을 시작해 본다. 실제로 골프를 쳤던 방콕 골프장에서 1번 홀이 어려운 파 5였고, 여기서 나는 4개 오버해서 9개를 친 적이 있다.(골프 용어로는 쿼드러플인데, 절대로 해서는 안 되는 점수다). 그리고 그다음 2번 홀은 파3인데, 여기서 3개 오버하면서 6개를 쳐서 소위 말하는 양파를 했고, 3번 홀은 파4인데(...)",
        "contentSnippet": "바로 전 글에서 골프 이야기를 잠깐 했는데, 같은 내용으로 이 포스팅을 시작해 본다. 실제로 골프를 쳤던 방콕 골프장에서 1번 홀이 어려운 파 5였고, 여기서 나는 4개 오버해서 9개를 친 적이 있다.(골프 용어로는 쿼드러플인데, 절대로 해서는 안 되는 점수다). 그리고 그다음 2번 홀은 파3인데, 여기서 3개 오버하면서 6개를 쳐서 소위 말하는 양파를 했고, 3번 홀은 파4인데(...)",
        "guid": "https://www.thestartupbible.com/?p=9663",
        "categories": [
          "Uncategorized",
          "consistency",
          "failure",
          "FoundersAtWork",
          "habit",
          "inspiring"
        ],
        "isoDate": "2026-01-14T21:34:00.000Z"
      }
    ]
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "2026년부터 이렇게 달라집니다: 새로운 금융·복지·노동 정책 26가지",
        "link": "https://toss.im/tossfeed/article/new-policies-2026",
        "pubDate": "Wed, 14 Jan 2026 06:22:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}2026년에도 정부 부처의 다양한 정책이 나왔어요. 최저임금 인상부터 대중교통비 지원까지, 우리 일상에 직접 영향을 주는 변화들이에요. 여러 정책 중에서 꼭 챙겨볼 만한 26가지를 선정해 정리했어요.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}누구에게나 해당되는\n일상 속 변화\n1. 최저임금 10,320원\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}2026년 최저임금은 시간당 10,320원으로 2025년(10,030원)보다 2.9% 올랐어요. 주 40시간 근무 기준으로 계산하면, 주휴수당을 포함해 월 215만 6,880원을 받을 수 있어요.\n2. 실업급여 상승\n실업급여 하루 최대 지급액이 6만 6,000원에서 6만 8,100원으로 올랐어요. 한 달로 계산하면 약 6만 3,000원을 더 받게 돼요.\n3. 많이 탈수록 돌려받는 대중교통비\n대중교통을 자주 이용하는 사람을 위한 새로운 환급 제도가 시작돼요. 새로 도입되는 ‘모두의 카드’는 이용 횟수에 제한이 있었던 K-패스와 달리 일정 금액 이상 사용한 대중교통비를 돌려주는 방식이에요. 기존에 K-패스를 사용하고 있었다면 별도로 신청하지 않아도 대중교통 이용 금액에 따라 가장 많은 환급 혜택이 자동으로 적용돼요.\n4. 따로 계산하는 배당소득세\n고배당 상장법인*에서 받은 배당소득을 종합소득 과세 대상에서 제외해 분리과세하는 배당소득 분리과세도 시작돼요. 그동안은 연 2,000만 원을 초과하는 금융소득이 다른 종합소득과 합산되어 누진세율이 적용되었지만, 이제는 배당 규모에 따라 차등 세율이 적용돼 세금 부담이 줄어들 수 있어요.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*국내에 상장된 기업 중 현금배당액이 전년 대비 감소하지 않았으면서 배당성향 40% 이상이거나 배당성향이 25% 이상 및 전년 대비 10% 이상 배당이 증가한 상장법인. 투자회사, 공모·사모펀드, SPC, 부동산 리츠, 배당 ETF 상품 등은 해당하지 않아요.\n5. 자동으로 신청되는 금리인하요구권\n그동안은 대출 이후 소득이 늘거나 신용점수가 올라도, 금리인하요구권에 대해 잘 몰라서 지나치는 경우가 많았어요. 상반기부터는 토스처럼 마이데이터 서비스*를 활용하는 핀테크 앱에서 신용 상태와 소득 변화를 자동으로 확인해 금리인하요구권을 신청해줘요.\n* 여러 금융기관에 흩어진 금융소비자의 정보를 한곳에 모아 관리하는 서비스\n6. 전기·전자제품 회수·재활용 의무 모든 제품으로 확대\n가정에서 사용하는 모든 전기·전자제품이 생산자 책임 재활용(EPR)* 제도 대상으로 확대돼요. 작년까지는 세탁기, 냉장고, TV, 컴퓨터 등 중·대형 기기 50종만 해당됐는데, 이제 건조기, 전기자전거, 보조배터리, 블루투스 이어폰, 휴대용 선풍기까지 모든 전기·전자제품을 폐기물 스티커 없이 무상으로 수거해요.\n* Extended Producer Responsibility: 제품 생산자에게 제품 및 포장재의 폐기물 수거 및 재활용 의무를 부여하는 제도\n7. 농어촌 여행하면 50% 돌려받는 여행비\n인구감소지역으로 여행을 가면 여행 경비의 50%를 지역화폐로 돌려받을 수 있어요. 개인은 최대 10만 원, 단체는 최대 20만 원까지 지원받을 수 있어요. 여행지역에 사전 신청해 혜택 대상자로 선정되면, 여행을 마친 뒤 환급받는 방식이에요. 인구감소지역 84곳 중 공모로 선정된 20곳을 대상으로 상반기에 시행될 예정이에요.\n8. 고향사랑기부금 세액공제 확대\n10만 원 초과 20만 원 이하 고향사랑기부금에 대한 세액공제율이 15%에서 40%로 올라요. 주소지 외 지역에 20만 원을 기부하면 10만 원은 전액 공제되고, 나머지 10만 원은 지방소득세 포함 44%가 공제돼 총 14만 4,000원의 세액공제를 받을 수 있어요. 여기에 기부금액의 30% 한도로 답례품도 받을 수 있어서, 20만 원으로 20만 4,000원의 혜택을 볼 수 있죠.\n일을 한다면\n알아야 하는 정책\n9. 국민연금 보험료율·소득대체율 인상\n국민연금 보험료율이 9%에서 9.5%로 인상됐어요. 직장인은 늘어난 보험료를 회사와 절반씩 나눠 부담하고, 지역가입자나 자영업자는 전액을 본인이 부담해요. 월 300만 원 소득 기준으로 직장인은 약 7,500원, 지역가입자는 약 15,000원을 더 내야 해요.\n부담만 늘어나는 것은 아니에요. 보험료율과 함께 소득대체율*도 41.5%에서 43%로 올랐어요. 이 비율이 높아지면 연금 가입자가 노후에 받는 연금액도 커져요. 매달 내는 돈이 조금씩 늘지만, 그만큼 노후의 소득 안전망도 커지는 거죠.\n* 가입자의 생애 평균 소득에서 연금액이 차지하는 비율\n10. 3년 만에 인상된 건강보험료율\n건강보험료율도 7.09%에서 7.19%로 올랐어요. 월 300만 원 소득 기준으로 직장가입자는 약 1,500원이 올라 10만 7,850원, 지역가입자는 약 3,000원이 올라 21만 5,700원을 건강보험료로 내게 돼요.\n11. 중소기업 직장인을 위한 든든한 한 끼\n인구감소지역에서 근무하는 중소기업 직장인들은 아침이나 점심 중 한 끼를 지원받아요. 아침밥 지원은 1월부터 시행되며, 백반이나 김밥처럼 쌀로 만든 식사를 1,000원에 먹을 수 있어요. 하반기부터 시행되는 점심밥 지원은 근로지 내 식당에서 결제한 점심 식사값의 20%를 월 4만 원 한도로 할인 받는 정책이에요.\n12. 일손부족일자리 동행인센티브 신설\n직업훈련이나 일 경험 프로그램을 수료한 50세 이상 중장년층이 제조업, 운수업, 창고업 등 인력이 부족한 업종에 취업하면 인센티브를 받을 수 있어요. 근로자가 6개월, 12개월 근속할 경우 정부에게 각각 180만 원씩, 총 360만 원을 지급 받아요.\n아이 키우는 부모라면\n꼭 챙겨야 할 정보\n13. 육아기 10시 출근제 시작\n육아기 자녀를 둔 근로자가 돌봄 시간을 확보할 수 있도록 ‘육아기 10시 출근제’ 지원 사업이 새로 생겼어요. 만 12세 이하 자녀를 둔 근로자에게 임금 감소 없이 근로시간 단축을 허용한 중소·중견 사업주에게 정부가 근로자 1인당 월 30만 원을 지원하는 제도예요. 회사가 이 제도를 운영하는지 확인해보세요. 단, 육아기 근로시간 단축 제도와는 중복 지원되지 않아요.\n14. 늘어난 육아기 근로시간 단축 급여\n자녀 양육을 위해 근로시간을 줄인 근로자에게 지급되는 육아기 근로시간 단축 급여 상한액이 올랐어요. 주당 근무 시간을 10시간까지 줄이면 월 최대 250만 원, 10시간 이상 줄이면 최대 160만 원까지 지원돼요.\n15. 출산전후휴가 급여 상한액 증가\n출산전후휴가 급여 상한액이 월 210만 원에서 220만 원으로 올랐어요. 출산전후휴가는 총 90일이에요. 이 가운데 앞 60일은 회사가 급여를 지급하고, 남은 30일은 고용보험에서 지급해요. 근로자가 속한 회사가 우선지원대상기업*이라면 앞 60일 급여의 일부를 정부가 회사에 지원해줘요. 이때 정부가 회사에 지원하는 최대 금액이 월 220만 원으로 올랐어요. 남은 30일은 고용보험에서 지급되며, 이 기간에도 월 최대 220만 원까지 받을 수 있어요.\n* 상시 근로자 수가 제조업의 경우 500인 이하, 건설업ㆍ광업ㆍ운수업ㆍ창고업ㆍ통신업의 경우 300인 이하, 기타 산업의 경우 100인 이하인 중소기업\n16. 자녀 기준으로 넓어진 보육수당 비과세 한도\n만 6세 이하 자녀의 보육과 관련해서 지급받는 비과세 한도가 근로자 1인당 월 20만 원에서 자녀 1인당 월 20만 원으로 확대돼요. 자녀가 2명이면 40만 원, 3명이면 60만 원까지 비과세 혜택을 받을 수 있어요.\n17. 자녀수에 따라 커지는 신용카드 소득공제 혜택\n자녀 수에 따른 신용카드 소득공제 기본한도가 확대됐어요. 작년에는 연간 총급여 7,000만 원 이하인 경우 자녀 수와 무관하게 300만 원이었는데, 올해부터는 자녀 1명이면 350만 원, 자녀 2명 이상이면 400만 원으로 늘어나요. 총급여 7,000만 원 초과자는 무자녀일 때 250만 원, 자녀 1명일 때 275만 원, 자녀 2명 이상일 때 300만 원까지 공제받을 수 있어요.\n18. 초등 저학년 예체능 학원비 세제지원\n교육비 세액공제 대상에 만 9세 미만 자녀의 예체능 학원비도 포함됐어요. 이제 피아노, 태권도, 미술 등의 학원비도 연말정산 때 15% 세액공제받을 수 있어요.\n19. 육아휴직자 주담대 원금상환유예\n육아휴직 기간에는 주택담보대출 원금을 갚지 않고 이자만 내면 돼요. 본인이나 배우자가 육아휴직 중이라면 1월 31일부터 신청할 수 있어요. 집값이 9억 원 이하인 1주택자가 대출받은 지 1년 이상 된 경우 신청 가능해요. 육아휴직이 길어지면 최대 3년까지 연장할 수 있어요.\n20. 장난감도 이제 분리배출 대상\n생산자 책임 재활용(EPR) 제도 대상에 완구류도 추가됐어요. 그동안 레고를 비롯한 플라스틱 완구류는 재활용 의무대상에서 빠져 종량제봉투에 담아 버려야 했지만, 이제는 일반 플라스틱과 동일하게 분리배출할 수 있어요. 버려진 완구류는 회수 후 플레이크 형태로 만들어져 건설자재로 다시 쓰여요. 단, 배터리가 들어간 전기·전자제품 완구는 폭발 위험이 있어 소형가전 전용 수거함이나 지자체 전자제품 회수체계로 배출해야 해요.\n청년들을 위한\n새로운 기회\n21. 청년미래적금 신설\n6월에 청년미래적금이 출시돼요. 기존 청년도약계좌를 대신하는 상품으로, 가입 기간을 5년에서 3년으로 줄여 부담을 낮췄어요. 매달 저축하면 은행 이자와 별도로 정부가 저축액의 일정 비율을 지원금으로 적립해주고, 이자 소득은 전액 비과세예요. 이를 연 이자율로 환산하면 일반형은 최대 12%, 우대형은 16.9% 수준이죠. 우대형 가입자가 월 50만 원씩 3년 동안 저축하면, 정부 기여금을 더해 최대 2,200만 원의 목돈을 모을 수 있어요. 만 19~34세 청년 중 개인소득 6,000만 원 이하, 기준 중위소득 200% 이하라면 가입할 수 있어요.\n22. 청년일자리도약장려금 비수도권 우대지원\n비수도권 중소기업에서 2년간 근무하면 장려금을 받을 수 있어요. 근무 지역에 따라 일반 지역은 480만 원, 우대지원지역은 600만 원, 특별지원지역은 최대 720만 원까지 지원돼요.\n23. 대학생·대학원생 학자금대출\n취업 후 상환 학자금대출은 학부생과 대학원생이 재학 중 상환 부담 없이 학업에 전념하고 취업 후 상환하는 제도예요. 원래는 가구소득에 따라 신청할 수 있었지만, 올해부터 등록금 대출에 한해 소득이나 재산과 관계없이 누구나 신청할 수 있게 되었어요.\n24. 계속 이어지는 청년월세지원\n2025년까지만 운영 예정이었던 청년월세지원사업이 이제 상시 사업으로 바뀌어요. 만 19~34세 청년 중 기준 중위소득 60% 이하이면서 원가구* 소득이 기준 중위소득 100% 이하라면 24개월간 월 최대 20만 원의 월세를 지원받을 수 있어요.\n* 청년 가구와 부모를 포함한 가구\n25. 혜택이 넓어진 청년문화예술패스\n청년들에게 공연·전시 관람비 15만원을 지원하던 문화예술패스의 혜택이 더 커졌어요. 지원 대상은 만 19세에서 만 19~20세로 확대됐고, 비수도권에 거주하는 청년은 지원금이 20만 원으로 늘어났어요.\n26. 예비군 훈련비 상승\n2박 3일 동원훈련에 참가하는 1~4년 차 예비군 훈련비가 8만 2,000원에서 9만 5,000원으로, 4일간 출퇴근 방식 동원훈련 참가자 훈련비는 4만 원에서 5만 원으로 올라요. 5, 6년 차 예비군이 기본훈련과 작계훈련에 참가할 경우에는 별도 훈련비 2만 원을 지급해요.\n* 이 콘텐츠는 기획재정부에서 발간한 .css-114ityv{white-space:pre-wrap;cursor:pointer;-webkit-text-decoration:underline!important;text-decoration:underline!important;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}<2026년부터 이렇게 달라집니다>를 참고해서 작성되었습니다.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 윤동해 Graphic 윤자영",
        "content": "나를 위한 정책, 놓치지 말고 챙겨봐요",
        "contentSnippet": "나를 위한 정책, 놓치지 말고 챙겨봐요",
        "guid": "https://toss.im/tossfeed/article/new-policies-2026",
        "isoDate": "2026-01-14T06:22:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]