[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": [
      {
        "creator": "리승환",
        "title": "8년간 흑자 기록하며 ‘법인 영업용 차량’을 독점하다: 카택스 안재희 대표 인터뷰",
        "link": "https://ppss.kr/archives/268053",
        "pubDate": "Wed, 04 Dec 2024 04:22:18 +0000",
        "content:encodedSnippet": "광고 한번 없이 매일 3천 명 가입하며 시장 독식\n이승환: 자기소개를 부탁드립니다.\n안재희: 안녕하세요, 카택스 대표 안재희입니다. 카택스는 ‘업무용 차량 운행일지’ 앱으로, 기업들의 차량 관리 고민을 덜어드리고 있습니다.\n서비스 초기 모델로도 활동했던 안재희 카택스 대표 (출처: 매일신문)\n이승환: ‘업무용 차량 운행일지’가 뭐죠?\n안재희: 법인 차량이 어디서 어떻게 쓰였는지를 꼼꼼히 기록하는 문서에요. 이전에는 비싼 수입차를 법인 명의로 등록하고 개인적으로 사용하면서도, 모든 비용을 회사 경비로 처리하는 관행이 많았는데요. 이런 ‘꼼수 절세’를 막기 위해, 정부에서 연간 1500만 원 이상의 차량 비용을 경비로 인정받으려면 운행일지를 작성하도록 의무화한 겁니다.\n이승환: 운행일지를 하나하나 다 써요? 몇 월 몇 일 몇 시 어디 출발, 몇 월 몇 일 몇 시 어디 도착…\n안재희: 네. 맞습니다. 2016년 ‘업무용 승용차 세법 개정’으로 발표됐는데요. 업무용 차량 돌리는 사람들은 그야말로 멘붕이었죠. 그래서 GPS 기반의 ‘위치 추적기’를 부착했는데, 직원들 입장에서는 기분 나쁘거든요. 일이란 게 하다 보면 좀 쉬기도 하고 하는데, 내 움직이는 경로가 다 공개되니까요. 회사 입장에서도 그 비싼 기계를 통신사 3년 약정까지 받아가며 써야 했고요.\n검색하면 이런 거 많이 나온다\n이승환: 카택스는 그걸 앱으로 해결한 건가요?\n안재희: 예, 원래 저희는 다양한 앱을 만들던 SI 회사였어요. 세법 개정 뉴스를 보자마자 바로 앱을 만들었어요. 되게 심플했습니다. 차량 출발 전 앱 켜고 내릴 때 앱 끄면, GPS로 이동 경로를 알려주는 방식이었어요. 그런데 그게 광고비를 한 푼도 안 썼는데 순수 바이럴로 하루에 막 3천명씩 인스톨하고 그러는 거예요.\n이승환: 엄청난데요;;;\n안재희: 카택스가 국세청에서 요구하는 운행일지 양식을 그대로 뽑아줬거든요. 예로 그냥 운동용 GPS 트래킹 앱을 깐다. 그러면 내가 어디부터 어디까지 달렸다는 나오지만, 국세청 운행일지 양식으로는 나오지 않아요. 근데 카택스는 차량번호, 업무 목적, 주행거리, 운전자 등 국세청 양식에 딱 맞으니 총무부 입장에서는 너무 편한 거죠. 대부분 사람들은 이 양식이 뭔지도 모를 때였으니까요.\n이런 빡빡한 일지를 앱 사용으로 바로 뽑아준다\n \n고객의 요청을 맞춰가며 돈도 벌고 사용 기업을 10만까지 늘리다\n이승환: 사용자는 얼마나 되나요?\n안재희: 사용 기업 수는 약 10만 정도고요. 이 중 지속적으로 쓰고 있는 기업은 약 3만 정도예요. 등록된 차량은 누적 15만 대 정도입니다. 1대만 쓰는 기업도 있지만 4천 대 쓰는 기업도 있고 다양해요. 올해 매출액은 10억 정도 될 것 같고요. 큰 매출액은 아니지만 매해 우상향하고 있고, 또 한 번도 적자 보지 않고 매해 흑자를 내고 있습니다.\n매해 흑자를 기록하며 성장 중이다\n이승환: 매해 흑자라니 대단하네요. 매출은 어떻게 낸 거죠?\n안재희: 처음에는 운행 일지를 통해 돈을 벌 생각은 없었어요. 10년 전 앱 시장 분위기가, 일단 사용자만 늘려두면 할 수 있는 게 많다 생각했어요. 자동차 시장이 정말 크잖아요. 보험, 구매, 정비… 기업 고객사가 늘어나면 그 뒤에 붙일 거는 많다는 생각이었죠. 그런데 대기업 통신사에서 연락이 왔어요. 혹시 관리자 페이지를 만들어줄 수 있겠냐고.\n이승환: 시작부터 클라이언트가 통신사라니 대단하군요;;;\n안재희: 네. 저희도 좀 놀랐죠. 대기업 통신사에서 카택스 잘 쓰고 있는데, 지금 앱으로는 차량 하나하나를 따로 관리해야 해서 좀 번거롭다. 관리자 페이지가 있으면 회사 전체 차량을 관리를 할 수 있으니까, 그 기능을 개발해 주면 안 되겠냐… 그렇게 통신사를 위해 기능 개발을 하면서 돈을 벌었더니, 그 기능 때문에 또 고객이 생겨요. 그 고객이 돈 줄 테니 또 다른 기능 개발을 해달라고 해요. 이렇게 반복되며 기능도 개선되고 매출도 늘었어요.\n매출이 꾸준히 늘어나는 카택스 (출처: 피치덱)\n이승환: 엄청난 플라이휠이네요. 근데 통신사에서도 GPS 추적 서비스 내놓았다 하지 않았어요? 거기서 카택스를 쓰다니 신기하네요.\n안재희: 사실 저희라고 하드웨어 도입을 고민하지 않은 건 아니에요. 영업사원이 앱을 깜빡하고 안 켜도 자동으로 기록되니 편리하고, 추가 매출도 기대할 수 있고요. 근데 법인차도 아니고 자기 차에 위치추적기를 달고 싶어 할 사람이 얼마나 될까요? 입장 바꿔서 생각해 보면 화날 만하죠. 회사 입장에서도 머리 아프죠. 반발도 심한데, 초기비용, 설치, 유지보수, 위약금까지…\n이승환: 그래서 앱에 집중했는데 그게 승리의 원인이 됐다.\n안재희: 네. 앱을 통해 ‘장치 없는 간편함’을 표방했죠. 결과적으로는 하드웨어를 안 해서 살아남은 것 같아요. GPS 장치를 만든 대기업들도 비슷한 이야기를 하시더라고요. 돌아보면 현실적인 상황에 맞춘 선택과 집중이었던 것 같아요.\n클릭 한두 번이면 끝나는 간편한 앱 카택스\n \n도입하자마자 큰 비용을 절감하게 해주는 카택스\n이승환: 대기업은 어떤 이유 때문에 카택스를 필요로 한 거죠.\n안재희: 작은 회사야 차를 별로 안 사용하니까 수기로도 어떻게 처리되겠지요. 그런데 영업 많이 하거나 물류 관리해야 하는 회사는 차량이 수십 대 수백 대잖아요? 이걸 총무과 직원 1명이 다 관리할 수 있게 된 거죠. 누가 어느 차를 타서 어디서 어디까지 갔고, 그 동선은 어떻고 시간은 얼마 걸렸고… 이런 데이터를 다 파악할 수 있게 됐어요.\n수많은 차량을 한 번에 관리할 수 있다\n이승환: 회사 입장에서 그게 그렇게까지 중요한가요?\n안재희: 매우 중요합니다. 일단 비용이 줄지요. 운행 기록을 정확히 기록해서 정부에 제출하면 비용 처리가 되거든요. 또 대기업은 유류비 정산에만 4~5팀이 개입해요. 잡다한 서류 도장 찍고 하는, 반복적이거나 불필요한 업무가 많거든요. 그러다 문제가 생기면 정산 담당자가 책임지는 일이 많았는데, 이게 카택스를 쓰니까 다 사라지는 거죠. 그리고 애초에 카택스 같은 시스템의 도움이 없으면, 제대로 하려고 해도 할 수 있는 업무가 아닙니다.\n이승환: 그건 또 무슨 말이죠?\n안재희: 총무팀 입장에서는 이게 주 업무가 아니에요. 인사라거나 세무라거나 이런 거에 비하면 사이드 업무예요. 근데 정산해야 하는 인원이 몇백 명 몇천 명이다… 일일이 운행 기록을 확인할 수가 없죠. 그러다 보니 슈킹이 좀 생깁니다. 어지간한 건 적당히 넘어가겠지만 심한 경우도 많아요. 예로 한 영업사원은 본인은 전철로 돌아다니고, 가족이 쓴 내역을 회사 돈으로 처리한 거예요. 그러니까 주말에 사용하는데도 유류비가 계속 들어오는 거죠.\n그런 문제 없도록 카택스는 깔끔하게 계산해 준다\n이승환: ……\n안재희: 회사들이 보면 참 별의별 일이 다 있는 게, 영업사원이 관리자보다 직급이 높은 경우가 있거든요. 부장님이 영업사원이고, 대리가 정산하는 담당자란 말이에요. 근데 부장님이 한 달에 유류비를 200만 원씩 받아 가요. 아무리 봐도 이건 ‘부장님이 택시 알바를 하나?’ 싶은 수준인데, 상사한테 대리가 따질 수도 없어요. 자기 상사니까요. 이럴 땐 정말 디지털의 공정함이 절실합니다.\n☞ 카택스 홈페이지 바로가기\n \n근로자의 유류비를 높여주고 카택스 케어로 자기부담금 보험까지\n이승환: 근데 반대로 말하면, 직원들 반대로 도입이 쉽지 않을 것 같은데요.\n안재희: 네. 반발이 심하죠. 과거에 모 회사 노조에서 카텍스 도입하는 걸 반대하겠다고 나오시더라고요. 그러면 저희는 이렇게 설득합니다. 우리 카택스를 쓰면 오히려 유류비를 기존보다 더 많이 정산해 드린다… 이게 가능한 게, 카택스를 쓰면 회사 관리 비용이 엄청 줄어들고, 비용 처리도 완벽하게 되니까요. 유류비 좀 더 쳐줘도 한참 남아요. 기사님들 입장에서도 정직하게만 하면 오히려 과거보다 비용을 더 많이 받을 수 있으니까요.\n총무팀이라면 흔하게 봤을 일 (출처: 카택스)\n이승환: 그러면 근로자들도 바로 수긍하나요?\n안재희: 그렇지는 않습니다. 이게 좀 감정적인 거예요. 꼭 나오는 이야기가 개인정보 침해 아니냐, 이런 건데 이미 내부적으로 법무 검토를 마쳤습니다. 저희 최대 고객사인 S기업이나 엔터사, 방산업체 등에서도 도입할 때 대형 로펌 써가면서 법적 검토를 해주시더라고요. 운행 기록 데이터는 개인정보가 아니라 회사의 자산이기 때문에, 저희도 더욱 안전하게 보호되도록 특히 신경 쓰고 있어요. 카택스에는 출도착지 좌표 블라인드 기능이나 사용자별 권한 설정으로 정보 접근을 제한적으로 할 수 있는 기능도 제공하고 있고요.\n이승환: 그러면 근로자들의 반발을 이겨내기 위해 어떻게 하시나요?\n안재희: 최근 저희가 각 분야 보험 전문가를 주축으로 ‘카택스 케어’라는 최초의 영업용 차량 케어 상품을 내놓았어요. 보통 자기 차량에 대한 자동차 보험은 다 들잖아요? 사고 나면 일부 자기 부담금을 내고요. 근데 내 차 타고 회사 일하다가 사고가 났다. 그러면 회사 일 때문에 사고가 난 건데, 내가 자기부담금을 내야 해요. 직원 입장에서 얼마나 억울합니까. 카택스 케어는 이를 법인에서 지급할 수 있도록 보상 지원하는 서비스예요.\n국내 최초로 법인에서 자기부담금을 지급하는 보험 ‘카택스 케어’\n이승환: 오오. 좋네요…\n안재희: 네. 근데 또 문제가 법인차는 아무래도 개인 차량보다는 좀 함부로 운전하게 마련이에요. 그래서 사고 나는 경우도 좀 많아요. 그러면 근로자도 회사도 손해거든요. 그래서 저희는 이걸 UBI 보험(운전습관연계보험)으로 연결했어요. 카택스에는 급가속, 급회전, 급정지, 이런 것도 다 잡혀요. 티맵, 카카오내비 등을 통해 개인 보험 할인해 주는 것들은 있는데, 운전자 특정이 안 되는 법인차는 해당이 안 되더라고요. 이걸 DB 손해보험과 함께 인슈어테크 상품으로 출시 준비 중이에요.\n \n법인, 기업용 업무 차량의 데이터를 모아 애프터마켓으로 진출\n이승환: 정말 다양한 걸 하고 있네요. 앞으로는 어떤 쪽으로 확장하실 계획인가요?\n안재희: 굳이 운행 기록이 아니라도, 저희가 법인 차량 전체의 데이터를 가지고 있다는 자체가 크죠. 이 차가 이제 렌트 만기다. 예를 들어 GV80을 타고 있던 대표님인데 차 바꿀 때가 됐단 말이에요. 그러면 저희가 두세 달 전에 신품 프로모션 한번 해드릴게요. 여기서 운행 기록이 도움이 되지요. 장거리 운행이 많고 탑승 인원이 적으니까 이런 차 어떨까요, 이런 식의 맞춤형 제안으로.\n차량 데이터를 가지고 있기에 자연히 다른 시장으로 연결 가능하다\n이승환: 오…\n안재희: 정비 시장 진출도 모색 중이에요. 사실 회사에서도 차량 관리하는 게 엄청 부담이에요. 개인이 아니라 회사다 보니, 정비 비용을 아꼈다 해서 누가 알아주는 것도 아니고요. 반대로 정비 제대로 안 해서 사고가 나면 또 덤탱이를 써야 하고…\n이승환: 잘될 것 같은데요?\n안재희: 네. 이미 모 대기업에서도 협업 제안을 받은 적이 있어요. 우리가 법인 차량 데이터를 가지고 있으니까, 차량 주기에 맞게 자기들 정비소로 보내는 그런 모델이었지요. 또 직접 대형 정비소로 가지 않아도 되는 출장 정비 스타트업과도 이야기 중입니다. 요즘은 굳이 정비소 안 가도 OBD소켓이란 걸로 통신하면, 이 차량이 몇 km를 달렸고 이런 정보가 다 스캔이 돼요. 또 타이어 마모도나 브레이크 패드 등, 정비사분들이 육안으로 확인할 수 있고요. 저희는 이 데이터를 카택스 차량 정비 페이지랑 연결해서 ‘타이어 갈아주세요’ 같은 알림을 미리 보내고 정비 내역을 관리해 주는 거죠.\nOBD를 통해 차량의 온갖 정보를 가져올 수 있다\n이승환: 이렇게 데이터를 계속 모을수록 연계할 수 있는 게 많아지는 거군요.\n안재희: 맞습니다. 모든 운행 기록을 기록하고, 여기에 법인과 차량의 데이터를 엮으면 별의별 게 다 되지요. 중고차 매매 시 차량 평가도 가능하고, 자연히 거래로도 이어질 수 있어요. 중고차 매매, 렌터카, 신차 시장까지도 자연히 이어져요. 이런 애프터 마켓을 보고 인수 제안도 많이 들어왔어요.\n이승환: 그 귀한 엑싯 기회를 왜 안 잡은 겁니까!\n안재희: 저희의 미래는 단순히 운행 일지에서 끝나는 게 아니라 연계 시장, 즉 애프터마켓에 있었고 인수를 생각하던 담당자분들도 그 부분을 좋게 봐주셨어요. 그런데 당시 저희는 운행일지, 유류비 정산, 차량 관제 같은 기능으로만 사업하고 있었고, 애프터마켓은 아직 증명하지 못했는데 이 상태로 기회를 잡는 게 성급해 보였죠. 저희가 앞으로 증명해 나가야 할 게 많은 거 같아요.\n이미 급성장 중이고 남은 건 다른 시장 진출이다\n \n자동차 관련 모든 경험을 카택스로 해결할 때까지\n이승환: 그러고 보니 투자는 좀 받으셨나요?\n안재희: 8년간 카택스 한길을 걸으며 한 번도 투자를 받지 않았다가, 올해 4월에 중진공에서 투자를 받았어요. 투자라는 게 ‘신뢰성’을 확보한 것이기도 하잖아요. 아무래도 중진공은 정부 공인, 인증, 이런 느낌이 있으니까 더 의미 있었죠. 중진공이 저희 비즈니스를 잘 이해해 주고, 비전도 지지해 주신 덕분에 목표했던 프리A 단계에서 100억 이상의 밸류를 인정받았다는 점에서 한 단계 더 도약할 수 있게 됐습니다.\n\n이승환: 8년 동안 존버라니, 그것만으로도 대단하네요.\n안재희: SW만 할 때는 큰돈이 들지 않지만, 예로 법인차량 렌트를 한다고 하면 당장 차량 가득한 땅부터 필요하잖아요. 언젠가는 큰 자본이 필요할 때가 올 거라고 생각했었고, 그게 지금이라고 생각해요. 실은 저희가 중간에 해외 진출, 중고차 시장 진출, 등등 도전을 해봤어요. 그런데 메인 서비스가 딱 자리 잡지 않으면 뭘 붙여도 의미 없더라고요. 지금이야말로 운행일지 기반 서비스 안정화가 끝났고 이제 그다음 확장을 위해 나가야 할 때인 거죠.\n이승환: 본사가 대구라서 좋은 점이나 어려운 점은 없나요?\n안재희: 물가가 저렴한 건 좋은데, 지방은 아무래도 인재를 찾기가 어렵죠. 가끔 서울살이에 지쳐 고향으로 돌아오시는 능력자분들을 놓치지 않으려고 눈에 불을 켤 정도예요. 반대로 신입을 키워야 하는 일이 많고요. 혹시라도 대구에서 SW를 만들고 싶은 분은 언제든 환영합니다.\n이승환: 지방에서 한다고 무시당하거나 하지는 않나요?\n안재희: 음… 그런 면이 있다면 있는데, 나중에 지방 기업인 줄 몰랐을 정도로 서비스가 좋았다는 말을 종종 들어요. 실제 저희도 욕 안 먹으려고 되게 조심스럽게 회사를 운영해 오기도 했고요. 괜히 지방 기업이라 무시당하고 욕먹지 않으려면 꼼꼼하게 잘하자. 고급 음식은 아니라도 맛있고 따뜻한 음식을 내는 식당처럼.\n쟁쟁한 기업들이 카택스를 사용하고 있다\n이승환: 감사합니다. 마지막으로 한마디 부탁드립니다.\n안재희: 저희의 궁극적인 목표는 차량과 관련된 모든 과정을 편하고 쉽게, 카택스로 다 해결할 수 있게 만드는 거예요. 차량 교체부터 구매, 보험 처리, 정기점검, 유류비 정산 등 운전자나 관리자가 해야되는 온갖 골치 아픈 일을 카택스가 대신하는 경험을 제공하고 싶어요.\n저는 넓고 좋은 사무실에서 많은 사람들과 빨리 가는 것도 좋겠지만, 같은 비전을 공유하는 유능한 팀원들이랑 제대로 된 방향으로 가는 게 훨씬 중요하다 생각해요. 카택스는 지금까지 천천히, 하지만 꾸준히 잘 성장해왔다고 생각해요. 이제 방향은 잡혔으니까, 앞으로는 이 길을 흔들림 없이 쭉 직진할 겁니다.\n☞ 카택스 홈페이지 바로가기",
        "enclosure": {
          "type": "image/jpeg",
          "length": "0",
          "url": "https://ppss.kr/wp-content/uploads/2024/12/0.jpg"
        },
        "dc:creator": "리승환",
        "content": "광고 한번 없이 매일 3천 명 가입하며 시장 독식 이승환: 자기소개를 부탁드립니다. 안재희: 안녕하세요, 카택스 대표 안재희입니다. 카택스는 ‘업무용 차량 운행일지’ 앱으로, 기업들의 차량 관리 고민을 덜어드리고 있습니다. 이승환: ‘업무용 차량 운행일지’가 뭐죠? 안재희: 법인 차량이 어디서 어떻게 쓰였는지를 꼼꼼히 기록하는 문서에요. 이전에는 비싼 수입차를 법인 명의로 등록하고 개인적으로 사용하면서도, 모든 비용을 회사 경비로 처리하는 [&#8230;]",
        "contentSnippet": "광고 한번 없이 매일 3천 명 가입하며 시장 독식 이승환: 자기소개를 부탁드립니다. 안재희: 안녕하세요, 카택스 대표 안재희입니다. 카택스는 ‘업무용 차량 운행일지’ 앱으로, 기업들의 차량 관리 고민을 덜어드리고 있습니다. 이승환: ‘업무용 차량 운행일지’가 뭐죠? 안재희: 법인 차량이 어디서 어떻게 쓰였는지를 꼼꼼히 기록하는 문서에요. 이전에는 비싼 수입차를 법인 명의로 등록하고 개인적으로 사용하면서도, 모든 비용을 회사 경비로 처리하는 […]",
        "guid": "https://ppss.kr/?p=268053",
        "categories": [
          "IT",
          "스타트업",
          "인터뷰",
          "sponsored"
        ],
        "isoDate": "2024-12-04T04:22:18.000Z"
      }
    ]
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Cameron DaCamara",
        "title": "MSVC Compiler Language Updates in Visual Studio 2022 version 17.12",
        "link": "https://devblogs.microsoft.com/cppblog/msvc-compiler-language-updates-in-visual-studio-2022-version-17-12/",
        "pubDate": "Fri, 06 Dec 2024 17:32:53 +0000",
        "content:encodedSnippet": "Introduction\nIn alignment with the Visual Studio 2022 version 17.12 release, and based upon feedback received from the community, the MSVC compiler team would like to provide greater visibility into the C++ language-level fixes for customer-reported issues that made it into the release. This is similar to how the standard library team publishes regular changelogs (see VS 2022 17.12 for reference). The focus for Visual Studio 2022 version 17.12 is primarily to address bugs reported through Developer Community.\nC++23 Features:\nWhile our overall focus has been on fixing bugs reported via Developer Community, we implemented a C++23 feature to address one ticket.\nP2128R6 Multidimensional subscript operator. This paper enables code such as:\nstruct Array {\r\n    int arr[2][2];\r\n    int operator[](int x, int y) const {\r\n        return arr[x][y];\r\n    }\r\n};\r\nint main() {\r\n    Array arr = { {\r\n        { 1, 2 },\r\n        { 3, 4 }\r\n    } };\r\n    return arr[1, 1]; // Returns 4.\r\n}\nThis resolved the following Developer Community ticket. std::mdspan not working with [] operator – Developer Community\nOver the next few MSVC toolset update releases, the compiler team is dramatically shifting towards improving C++23 conformance.\nDeveloper Community Feedback:\nFirst of all, thank you all for taking the time to report issues on MSVC compiler on Developer Community portal. We take your reports with utmost importance and seriousness. We know that we don’t respond to all issues in timely manner and as a result some bug reports stay there for multiple releases without resolution. We will do better here and will strive to maximize our developer capacity as much as possible. We really appreciate your patience and understanding while we work through these issues.\nFixes\nC++ copy elision not performed when using ternary operator in return statement\nAccess to invalid memory when using an explicitly created initializer list in a for loop with /permissive-\n“C4388 – signed/unsigned mismatch” not triggering for sizeof\nError message “predefined C++ types (compiler internal), continuing without source annotations””\nRegression in MSVC++ 16.8: C++ multiple inheritance incorrectly allows operator() of private base classes to be accessible\nstd::invoke with a constexpr function is falsely noexcept with /permissive\nerror C7608: atomic constraint should be a constant expression\nconstant evaluation with do not works with msvc 19 latest\nUsing std::format in a module requires including format header in .cpp files using that module\n[[msvc::no_unique_address]] nonconformant class layout for nested non-unique-address empty classes\nPartial specialization of std::formatter in module is not found in other module.\nstd::mdspan not working with [] operator\nexplicit template instantiation wrongly checks private base class accessibility\nInternal compiler error with C++ Modules and Coroutine\nMSVC’s __declspec(empty_bases) and [[msvc::no_unique_address]] don’t work together\nCompiler hang when when code below is compiled with /std:c++20\nICE in stdexec metaprogramming\nFalse branch of if constexpr is evaluated in alias template, in lambda\nMSVC incorrectly considers a trivial but noexcept(false) destructor to be non-throwing\nMSVC incorrectly considers reference to a cv-/ref-qualified function type to be valid in a requires-expression\nC++ modules: Internal compiler error when using std::stacktrace\nClass derived from std::expected can’t be constructed with bool value type\nICE with template code and friend\nInternal compiler error caused by unparenthesized “sizeof” within requires-expression\nMSVC wrong recursive alias error\nBogus C4716 when explicitly instantiating auto member function with /Gv\n[regression] Bogus static_assert failure in VS 2022 17.11 Preview 1.0\nCode compiles in GCC and Clang, but fails in MSVC\nICE on invalid requires clause\nC++ requires requires parsing error?\nFatal error C1001 with simple code only with VS2022 17.10\ninternal compilator error\nC++ compiler regression constexpr constructors\nC++ compiler bug in 17.10.1: std::enable_if_t SFINAE fails to resolve template function\nC++ 20 header unit problem\n__builtin_bit_cast Internal compiler error\nA capture in lambda expression of constant bit-fields by reference with initializer is totally broken\nInternal compiler error related to “requires”\nVS 2022 17.11.0 Preview 2: intellisense or compiler bug: type is not a class template\nError C7576 produces ‘Unhandled Exception’ error in cl.exe when building 32-bit x86 code\nReject valid auto with braced initializer in new-expression\n__is_nothrow_assignable Builtin Produces Incorrect Value\ntab-complete.c(4023): fatal error C1001: Internal compiler error. (compiler file ‘msc1.cpp’, line 1611)\nNo warning about deprecated enum usage\nICE with STD Module usage (compiler file ‘msc1.cpp’, line 1587)\nFriendship to a function through a template class is giving an internal error.\nRegression: constexpr capture required in nested lambda with inferred argument\nExpansion of a nested template pack inside a template lambda\nInternal compiler error when initializing std::function member via default argument depending on parameter pack\nimplicitly generated special member functions do not properly inherit noexcept specification from base classes\nstd::is_constructible_v incorrectly evaluates to false with aggregate class and a member containing an array\nfatal error C1001: Internal compiler error.\nC26493 false positive initializing a base class\nApparently False C++ C2385 error\nMismatched pack expansion in requires expression is incorrectly treated as expansion of empty pack \nC26493 false positive initializing a base class\nInternal compiler error for C++20 designated initializers in non-type template parameter\nVisualStudio v17.10.3 won’t compile my C code\ninitializing capture clause does not work with access into this\nUnary + on a function is incorrectly considered not to be a constant expression\nReject valid constexpr variable in lambda in requires-expression\nBug? (erroneous error C3865: ‘__thiscall’: can only be used on native member functions)\nInstantianizing a concept with a nested type of a struct template instantiated with a variadic function causes errors: C2923 and C2065.\nICE with operator& inside virtual destructor\nC26493 false positive initializing a base class\nFalse compilation error when unpacking a template parameter pack into a template with more than one parameter\nInternal Compiler Error VS17.10 Regression\nRegression in 19.40 when using co_await in a lambda capture\nInternal compiler error in trees.c, line 12009\nThe discarded std::basic_format_string causes C1001: Internal compiler error.\n17.11 Preview 3 and later: seemingly bogus static_assert failure\nMSVC 17.11 regression: “RWTH OpenMesh” ICE in msc1.cpp, line 1611\nC++ Syntax Error after upgrading to Visual Studio 17.11.0\nVisual Studio C++ version 17.11.0 cannot perform constexpr evaluation in certain contexts\n‘this’ keyword is not evaluated appropriately in some context evaluations\nVS2022 17.11.0 GA Internal Compiler Error building C++ code\nIncorrect if constexpr usage in lambad causes ICE\nC++ requires expression name shadowing in const-evaluated context \nC++ failed to compile, this caputures in lambda as __this, and incorrect return type detection\nVS 17.11.1: Compiler fails to match definition to declaration when /permissive- is specified\nInternal compiler error C1001 with latest version of VS2022\n17.11 fails to compile templated code under C++20\nUnresolved token for TypeForwardedToAttribute in C++/CLI\nClosing\nAs always, we welcome your feedback. Feel free to send any comments through e-mail at visualcpp@microsoft.com or through Twitter @visualc. Also, feel free to follow Cameron DaCamara on Twitter @starfreakclone.\nIf you encounter other problems with MSVC in VS 2022 please let us know via the Report a Problem option, either from the installer or the Visual Studio IDE itself. For suggestions or bug reports, let us know through Developer Community.\nThe post MSVC Compiler Language Updates in Visual Studio 2022 version 17.12 appeared first on C++ Team Blog.",
        "dc:creator": "Cameron DaCamara",
        "comments": "https://devblogs.microsoft.com/cppblog/msvc-compiler-language-updates-in-visual-studio-2022-version-17-12/#respond",
        "content": "<p>Introduction In alignment with the Visual Studio 2022 version 17.12 release, and based upon feedback received from the community, the MSVC compiler team would like to provide greater visibility into the C++ language-level fixes for customer-reported issues that made it into the release. This is similar to how the standard library team publishes regular changelogs [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/msvc-compiler-language-updates-in-visual-studio-2022-version-17-12/\">MSVC Compiler Language Updates in Visual Studio 2022 version 17.12</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "Introduction In alignment with the Visual Studio 2022 version 17.12 release, and based upon feedback received from the community, the MSVC compiler team would like to provide greater visibility into the C++ language-level fixes for customer-reported issues that made it into the release. This is similar to how the standard library team publishes regular changelogs […]\nThe post MSVC Compiler Language Updates in Visual Studio 2022 version 17.12 appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34976",
        "categories": [
          "Announcement",
          "C++",
          "Frontend",
          "C++ language",
          "compiler",
          "VC++"
        ],
        "isoDate": "2024-12-06T17:32:53.000Z"
      }
    ]
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Powering AI innovation by acccelerating the next wave of nuclear",
        "link": "https://sustainability.atmeta.com/blog/2024/12/03/accelerating-the-next-wave-of-nuclear-to-power-ai-innovation/",
        "pubDate": "Tue, 03 Dec 2024 20:27:12 +0000",
        "content:encodedSnippet": "The post Powering AI innovation by acccelerating the next wave of nuclear appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p> [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://sustainability.atmeta.com/blog/2024/12/03/accelerating-the-next-wave-of-nuclear-to-power-ai-innovation/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://sustainability.atmeta.com/blog/2024/12/03/accelerating-the-next-wave-of-nuclear-to-power-ai-innovation/\">Powering AI innovation by acccelerating the next wave of nuclear</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "[...]\nRead More...\nThe post Powering AI innovation by acccelerating the next wave of nuclear appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=22022",
        "categories": [
          "Data Center Engineering"
        ],
        "isoDate": "2024-12-03T20:27:12.000Z"
      },
      {
        "creator": "",
        "title": "Meta Andromeda: Supercharging Advantage+ automation with the next-gen personalized ads retrieval engine",
        "link": "https://engineering.fb.com/2024/12/02/production-engineering/meta-andromeda-advantage-automation-next-gen-personalized-ads-retrieval-engine/",
        "pubDate": "Mon, 02 Dec 2024 17:00:56 +0000",
        "content:encodedSnippet": "Andromeda is Meta’s proprietary machine learning (ML) system design for retrieval in ad recommendation focused on delivering a step-function improvement in value to our advertisers and people. \nThis system pushes the boundary of cutting edge AI for retrieval with NVIDIA Grace Hopper Superchip and Meta Training and Inference Accelerator (MTIA) hardware through innovations in ML model architecture, feature representation, learning algorithm, indexing, and inference paradigm.\nWe’re sharing how Andromeda establishes an efficient scaling law for retrieval by harnessing the power of state-of-the-art deep neural networks, benefitting from the co-design of ML, system, and hardware (NVIDIA and MTIA chips) that improves performance and return on investment.\nAI plays an important role in Meta’s advertising system by leveraging the power of machine learning (ML) to predict which ads a person will find most interesting. This helps people learn about a business or product they are interested in while helping an advertiser meet their objectives such as increasing brand awareness, acquiring new customers, and driving sales.\nRetrieval is the first step in our multi-stage ads recommendation system. This stage is tasked with selecting ads from tens of millions of ad candidates into a few thousand relevant ad candidates. In the following stage, larger and more sophisticated ranking models predict people and advertiser value to determine the final set of ads to be shown to the person. \nChallenges and opportunities in this new era of advertiser automation with generative AI\nThe retrieval stage is challenging primarily because of scalability constraints in two axes: volume of ad candidates and tight latency constraints.\nVolume of ad candidates: Retrieval processes three orders of magnitude more ads than subsequent stages. Features like predictive targeting, which dramatically improve advertiser outcomes, are computationally expensive. The continued positive momentum of Meta’s Advantage+ suite further increases the number of eligible ads through automation of audience creation, optimal budget allocation, dynamic placement across Meta surfaces, and creative generation. Finally, with the adoption of powerful new tools based on generative AI for creating and optimizing ad creative content, the number of ads creatives in Meta’s recommendation systems is expected to grow significantly.\nTight latency constraints: Selecting ads rapidly is essential for delivering timely and relevant ads, as any delay can disrupt the viewers experience by not providing the most current content. As advertising becomes increasingly dynamic, frequent updates to both delivery and each person’s interests demand increased model complexity in near real-time.\nProcessing such a vast number of ads in so little time is capacity intensive, which requires substantial optimization and innovation to scale up model complexity for better personalization while maintaining a high return on investment (ROI) on the required infrastructure investments. \nUnlocking advertiser value through industry-leading ML innovation\nMeta Andromeda is a personalized ads retrieval engine that leverages the NVIDIA Grace Hopper Superchip, to enable cutting edge ML innovation in the Ads retrieval stage to drive efficiency and advertiser performance. Key AI advancements include: \nDeep neural networks custom-designed for the NVIDIA Grace Hopper Superchip to deliver superior performance\nAndromeda improves performance of Meta ads system by delivering more personalized ads to viewers and maximizing return on ad spend for advertisers. Meta’s Ads team has created a deep neural network with increased compute complexity and massive parallelism on the NVIDIA Grace Hopper Superchip to better learn higher-order interactions from people and ads data. Its deployment across Instagram and Facebook applications has achieved +6% recall improvement to the retrieval system, delivering +8% ads quality improvement on selected segments.\nHierarchical indexing to support exponential ad creatives growth from Advantage+ creative \nAdvantage+ automates budget allocation, audience targeting, and bid adjustments – streamlining campaign management and boosting performance through more ads in the system for different audiences. \nFor example, when advertisers who did not previously use Advantage+ creative turned on its AI-driven targeting features, they experienced a 22% increase in ROAS from our ads. We estimate that businesses using image generation are seeing a +7% increase in conversions. Even at this early stage, more than a million advertisers used our generative AI (GenAI) tools to create more than 15 million ads in a month. Andromeda is designed to maximize ads performance by utilizing the exponential growth in volume of eligible ads available to the retrieval stage. It introduces an efficient hierarchical index to scale up to a large volume of ads creatives, empowering the adoption of GenAI technologies by advertisers.\nAI development efficiency\nAndromeda reduces system complexity by minimizing components and rule-based logic, allowing for end-to-end performance optimization. This streamlined system enhances pace of adoption for future AI innovation in the retrieval space.\nMeta’s new personalized ads retrieval paradigm\nBefore Andromeda, Meta’s retrieval systems were only able to apply limited personalization, relying on a process with isolated model stages and numerous rule-based heuristics to manage the vast number of ads. This approach hindered end-to-end optimization and efficient global resource allocation to maximize performance. Handling such a massive volume of ads per request was complex, memory bandwidth-intensive, and difficult to scale, resulting in low hardware-level parallelism in conventional retrieval models. This often led to suboptimal performance and slower adoption of AI innovations.\n\nAndromeda represents a significant technological leap in retrieval – addressing the above challenges with key ML and system innovations.\nA state-of-the-art deep neural network for retrieval\nAndromeda is able to efficiently scale retrieval models by designing a highly customized deep neural network with sublinear inference cost, enabling a meaningful increase of model capacity (10,000x) for enhanced personalization. Complex latent relationships between people’s interests, products, and services offered through ads are captured through advanced interaction features and new algorithms, further enhancing recommendation relevance and accuracy.\nThe design is optimized for AI hardware, minimizing memory bandwidth bottlenecks and enabling highly parallel, computation-intensive retrieval models with high performance. GPU preprocessing is used for feature extraction, and all precomputed ad embeddings and features are stored in the local memory of the Grace Hopper Superchip. This approach addresses the traditional scaling constraints of limited CPU-to-GPU interconnect bandwidth, heavy memory IO overhead, and low GPU utilization and enables efficient handling of a larger set of diverse feature inputs.\nHierarchical indexing for efficiency and scalable retrieval\nAndromeda organizes ads into a hierarchical index with multiple layers, reducing the number of inference steps by focusing only on most relevant nodes. The hierarchical index and retrieval models are jointly trained, which aligns the index representations with neural networks; this improves both precision and recall compared to commonly used two-tower neural networks or approximate nearest neighbor search. \nThe hierarchical structured neural network provides sub-linear inference costs, enabling retrieval models to scale up to much higher capacity, allowing efficient handling of a larger volume of ads with high retrieval accuracy while achieving higher performance.\nModel elasticity\nAndromeda enhances overall system ROI by enabling agile and efficient resource allocation. A segment-aware design leverages higher complexity models to serve high value ads segments to maximize ROI. It automatically adjusts model complexity and inference steps in real-time based on available resources, thereby allowing a more scalable retrieval system. Together with a hierarchical structured neural network, model elasticity further boosts model inference efficiency by 10x.\nAn optimized retrieval model\nAndromeda significantly enhances the retrieval model’s instruction and thread-level parallelism through innovations in model architecture, features, learning algorithms, and the inference paradigm. This model is built with low-latency, high-throughput, and memory-IO aware GPU operators, utilizing deep kernel fusion and advanced software pipelining techniques. This minimizes kernel dispatching overhead, avoids bottlenecks on repeated HBM-SRAM memory IO, and reduces dependency on low arithmetic intensity modules. \nUnlike conventional retrieval models that rely on expert-engineered features, Andromeda leverages the NVIDIA Hopper GPU’s massive parallel computing capabilities to dynamically reconstruct latent user-ad interaction signals on-the-fly, achieving over 100x improvement in both feature extraction latency and throughput of previous CPU based components. In addition, the chip’s high-bandwidth CPU-GPU interconnection supercharges ads retrieval inference to process an enormous number of ads per request, enabling a faster and more efficient delivery of relevant and personalized Ads. The effort has enhanced end-to-end model inference queries per second (QPS) by over 3x.\nAdvancing the state of art in ads retrieval\nAndromeda significantly enhances Meta’s ads system by enabling the integration of AI that optimizes and improves personalization capabilities at the retrieval stage and improves return on ad spend. A hierarchical indexing solution leveraging deep neural networks co-designed with the NVIDIA Grace Hopper Superchip helps address the scalability challenges presented by the exponential growth of creatives while delivering the best experience given the strict latency and capacity ROI budgets. Andromeda capitalizes the fast industry adoption of Advantage+ automation and GenAI to deliver value for our advertisers, people who use our suite of products, and Meta.\nLooking forward, the Andromeda model architecture is expected to transition to support an autoregressive loss function, leading to a more efficient and faster inferencing solution that delivers a more diverse set of ad candidates. Increased ad diversity can improve people’s experience with ads and drive better advertiser outcomes. \nIntegrating Andromeda with MTIA and future generations of commercially-available GPUs will continue to push the boundaries of scaling retrieval – further improving advertiser performance and achieving what we estimate will be another 1,000x increase in model complexity. \nAcknowledgements\nWe would like to thank Habiya Beg, Zain Brohi, Wenlin Chen. Chunli Fu, Golnaz Ghasemiesfeh, Xingfeng He, Akshay Hegde, Liquan Huang, Liuhan Huang, Kamran Izadi, Santosh Janardhan, Karthik Jayaraman, Changkyu Kim, Santanu Kolay, Ilia Lewis, Wenqian Li, Xiaotian Li, Rocky Liu, Paolo Massimi, Kexin Nie, Sandeep Pandey, Uladzimir Pashkevich, Varna Puvvada, Hang Qu, Melanie Roe, Yan Shi, Matt Steiner, Alisha Swinteck, Bangsheng Tang, Jim Tao, Sunay Vaishnav, Arunprasad Venkatraman, Vidhoon Viswanathan, Sasha Vorontsov, Minghui Wanghan, Fangzhou Xu, Nathan Yan, Tak Yan, Yang Yang, Qing Zhang, Fangyu Zou, and everyone who contributed to the success of Meta Andromeda.\nThe post Meta Andromeda: Supercharging Advantage+ automation with the next-gen personalized ads retrieval engine appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Andromeda is Meta’s proprietary machine learning (ML) system design for retrieval in ad recommendation focused on delivering a step-function improvement in value to our advertisers and people.  This system pushes the boundary of cutting edge AI for retrieval with NVIDIA Grace Hopper Superchip and Meta Training and Inference Accelerator (MTIA) hardware through innovations in ML [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/12/02/production-engineering/meta-andromeda-advantage-automation-next-gen-personalized-ads-retrieval-engine/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/12/02/production-engineering/meta-andromeda-advantage-automation-next-gen-personalized-ads-retrieval-engine/\">Meta Andromeda: Supercharging Advantage+ automation with the next-gen personalized ads retrieval engine</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Andromeda is Meta’s proprietary machine learning (ML) system design for retrieval in ad recommendation focused on delivering a step-function improvement in value to our advertisers and people.  This system pushes the boundary of cutting edge AI for retrieval with NVIDIA Grace Hopper Superchip and Meta Training and Inference Accelerator (MTIA) hardware through innovations in ML [...]\nRead More...\nThe post Meta Andromeda: Supercharging Advantage+ automation with the next-gen personalized ads retrieval engine appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21998",
        "categories": [
          "ML Applications",
          "Production Engineering"
        ],
        "isoDate": "2024-12-02T17:00:56.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Alena Gupaisova",
        "title": "Livestream alert: Ace the CSAI Math Entrance Test",
        "link": "https://blog.jetbrains.com/education/2024/12/06/livestream-alert-ace-the-csai-math-entrance-test/",
        "pubDate": "Fri, 06 Dec 2024 11:13:55 +0000",
        "content:encodedSnippet": "Want to study computer science in Europe? Join the Computer Science and AI bachelor’s program at Neapolis University Pafos – with exclusive JetBrains scholarships up for grabs!\nRegister now\n                                                    \n\n\n\n\nOn December 18, 2024, at 5:00 pm UTC, we’re hosting a special preparation session to help you ace the entrance test for this BSc. You’ll get tips from Andrei Smolensky, Assistant Professor at Neapolis University Pafos. With a PhD in Algebra, he has been teaching for 10 years at universities and high schools. His current research is about interfaces between algebra and machine learning.",
        "dc:creator": "Alena Gupaisova",
        "content": "Want to study computer science in Europe? Join the Computer Science and AI bachelor&#8217;s program at Neapolis University Pafos – with exclusive JetBrains scholarships up for grabs! On December 18, 2024, at 5:00 pm UTC, we&#8217;re hosting a special preparation session to help you ace the entrance test for this BSc. You&#8217;ll get tips from [&#8230;]",
        "contentSnippet": "Want to study computer science in Europe? Join the Computer Science and AI bachelor’s program at Neapolis University Pafos – with exclusive JetBrains scholarships up for grabs! On December 18, 2024, at 5:00 pm UTC, we’re hosting a special preparation session to help you ace the entrance test for this BSc. You’ll get tips from […]",
        "guid": "https://blog.jetbrains.com/?post_type=education&p=533489",
        "categories": [
          "csai",
          "offline-programs"
        ],
        "isoDate": "2024-12-06T11:13:55.000Z"
      },
      {
        "creator": "Dmitry Pogrebnoy",
        "title": "Mastering Ruby Debugging: From puts to Professional Tools",
        "link": "https://blog.jetbrains.com/ruby/2024/12/mastering_ruby_debugging/",
        "pubDate": "Fri, 06 Dec 2024 08:55:18 +0000",
        "content:encodedSnippet": "Hello, Ruby developers!\nDebugging is an essential skill in software development, and in this post, we’ll be looking at how to investigate the behavior of Ruby code. As the RubyMine team, we’ve accumulated considerable expertise in creating tools for Ruby developers, and we’re excited to share our experience and knowledge with you.\nRecently, at the EuRuKo 2024 conference, our team member Dmitry Pogrebnoy presented the Demystifying Debuggers talk. This blog post is the first in a series based on that presentation, aiming to provide you with valuable insights into debugging Ruby applications.\nEvery Ruby programmer inevitably encounters situations where their code doesn’t behave as expected. In these moments, we all wish we had an efficient way to pinpoint the problem and fix it quickly. That’s where debugging tools come into play.\nIn this post, we’ll explore various tools and approaches available to Ruby developers for investigating bugs. We’ll cover several classes of tools, each with its own strengths and weaknesses. Understanding the specifics of each tool will help you choose the most effective one for your particular debugging scenario.\nTo make our discussion more concrete, we’ll start with a real-world example of a bug we encountered in one of our internal Ruby projects. This case study will illustrate the importance of proper debugging techniques and set the stage for our exploration of debugging tools.\nWhether you’re a seasoned Ruby developer or just starting out, this guide will help you sharpen your debugging skills and tackle bugs more efficiently. Let’s get started!\nA real bug case from the RubyMine team\nIn the RubyMine team, our development efforts extend beyond the IDE itself. We’ve created several proprietary gems that enhance the IDE’s functionality. To share some insights, we’ll explore a real-world bug we encountered in one of these gems about a year ago. We’ve isolated and simplified the code sample to focus on the core issue.\nConsider the following Ruby code:\ndef process(thing)\n if defined? thing.to_s || defined? thing.inspect\n   puts \"Element is Printable\"\n else\n   puts \"Element is Not Printable\"\n end\nend\n\nprocess(5)               # -> Element is Printable\nprocess(BasicObject.new) # -> Element is Printable\nAt first glance, this process method seems straightforward. It aims to check whether the given argument has either a to_s or an inspect method. If either method exists, process should print “Element is Printable”; otherwise, it prints “Element is Not Printable”.\nAt the bottom, you can see two calls of this method with their outputs. The first call process(5) produces the message “Element is Printable”. This is correct. But the second call process(BasicObject.new) looks suspicious. It takes BasicObject as an argument, but prints “Element is Printable”. This is incorrect because the BasicObject instance does not respond to either of the methods we are looking for. So apparently this code contains a bug.\nLet’s take a moment to examine the process method. Can you spot the bug?\nSpoiler – click to expand!\nThe bug lies in the if condition:\n defined? thing.to_s || defined? thing.inspect\nDue to Ruby’s operator precedence, the interpreter actually evaluates this as:\ndefined?(thing.to_s || defined?(thing.inspect))\nThis expression always returns “expression”, regardless of whether thing responds to to_s or inspect. As a result, the condition is always true, and our method incorrectly classifies every object as printable.\nThe fix is simple but illustrative of how small syntax errors can lead to significant logical flaws. We need to explicitly structure our conditions using parentheses:\ndef process(thing)\n if defined?(thing.to_s) || defined?(thing.inspect)\n   puts \"Element is Printable\"\n else\n   puts \"Element is Not Printable\"\n end\nend\n\nprocess(5)               # -> Element is Printable\nprocess(BasicObject.new) # -> Element is Not Printable\nWith this correction, our method now accurately distinguishes between objects that implement to_s or inspect and those that don’t.\n\n\n\n\nBy sharing this real-world example, we hope to demonstrate that debugging is a crucial skill for all developers, regardless of experience level. It’s not just about fixing errors; it’s about understanding the intricacies of the language and writing more reliable code.\nIn more complex, production-level applications, such issues can be far more challenging to identify and resolve. This underscores the importance of robust debugging tools and techniques, which we’ll explore in the following sections.\nChoosing the right tool\nWhen it comes to debugging Ruby code, developers have several tools and approaches at their disposal. Let’s explore these options, starting with the basics and then moving on to more advanced techniques.\nputs statements\nThe most basic debugging technique, requiring no setup or additional gems, is using puts statements. This method involves inserting print statements directly into your code to output variable values or execution flow information. While simple, it can be surprisingly effective for quick investigations.\nLet’s apply this technique to our earlier example:\ndef process(thing)\n puts \"defined? thing.to_s: #{defined? thing.to_s}\"\n puts \"defined? thing.inspect: #{defined? thing.inspect}\"\n puts \"defined? thing.to_s || defined? thing.inspect: #{\n   defined? thing.to_s || defined? thing.inspect\n }\"\n if defined? thing.to_s || defined? thing.inspect\n   puts \"Element is Printable\"\n else\n   puts \"Element is Not Printable\"\n end\nend\n\nprocess(5)\nprocess(BasicObject.new)\nThis yields the following output:\ndefined? thing.to_s: method\ndefined? thing.inspect: method\ndefined? thing.to_s || defined? thing.inspect: expression\nElement is Printable\ndefined? thing.to_s: \ndefined? thing.inspect: \ndefined? thing.to_s || defined? thing.inspect: expression\nElement is Printable\nThe inconsistent output from these two methods calls with different arguments hints at where the problem might lie. We can see that, for BasicObject.new, both thing.to_s and thing.inspect are undefined, yet the condition still evaluates to true.\nWhile basic puts statements are useful, several gems can make them more informative:\n1. puts_debuggerer gem enhances puts output with the file name, line number, and content of this line.\nFor example:\nrequire 'puts_debuggerer'\npd \"defined? thing.to_s: #{defined? thing.to_s}\"\nOutput:\n[PD] example_puts_debuggerer.rb:5 in Object.process\n   > pd \"defined? thing.to_s: #{defined? thing.to_s}\"\n  => \"Debug print 1: method\"\n2. awesome_print and similar gems provide more structured and readable output, especially useful for complex objects.\nGenerally puts statements are useful and might effectively help you with simple cases or when other tools don’t work for some reason. However, puts statements are really basic. They require modifying your source code every time you need to adjust an existing message or add a new one. They are usually not convenient to use because you need to restart the program whenever you modify what you are printing. \nPros and cons of debugging using puts\nPros:\nSimple and quick to implement.\nWorks in any Ruby environment.\nNo additional tools or setup are required.\n \n\n\n\nCons:\nRequires modifying source code.\nCan clutter the code if overused.\nForces you to restart the program if you want to change what you print.\nLimited information compared to more advanced tools.\n \n\n\n\nWhile puts statements are invaluable for quick checks, they become less efficient for complex scenarios or when frequent changes are needed. In such cases, more advanced tools like interactive consoles or full-fledged debuggers offer greater flexibility and power.\nInteractive consoles\nInteractive consoles represent the next level in bug investigation tools for Ruby developers. The two primary options are IRB and Pry, both offering powerful introspection capabilities.\nTo utilize interactive consoles for debugging, you typically need to insert binding.irb or binding.pry calls into your source code. When the binding command is executed, an interactive console launches, providing access to the current context and the ability to execute arbitrary expressions in this context.\nLet’s use IRB in our earlier example:\ndef process(thing)\n binding.irb\n if defined? thing.to_s || defined? thing.inspect\n   puts \"Element is Printable\"\n else\n   puts \"Element is Not Printable\"\n end\nend\n\nprocess(5) # -> Element is Printable\nprocess(BasicObject.new) # -> Element is Printable\nWhen the code hits the binding.irb line, we’ll enter an interactive session:\nFrom: 5_example_define_irb.rb @ line 2 :\n\n    1: def process(thing)\n => 2:   binding.irb\n    3:   if defined? thing.to_s || defined? thing.inspect\n    4:     puts \"Element is Printable\"\n    5:   else\n    6:     puts \"Element is Not Printable\"\n    7:   end\n\nirb(main):001> defined? thing.to_s\n=> nil\nirb(main):002> defined? thing.inspect\n=> nil\nirb(main):003> defined? thing.to_s || defined? thing.inspect\n=> \"expression\"\nirb(main):004> exit\nElement is Printable\nThis interaction allows us to examine the behavior of the condition’s individual parts, helping to pinpoint the issue.\nPros and cons of debugging using interactive consoles\nPros:\nMore complex and flexible than puts statements.\nPartially allows for on-the-fly investigation.\nNo need to predetermine all debugging output.\n \n\n\n\nCons:\nStill requires source code modification.\nRequires you to set predefined introspection points that cannot be changed at runtime.\nForces you to restart the program if you want to change introspection points.\n \n\n\n\nWhile interactive consoles offer more power than simple puts statements, they still have limitations. For complex debugging scenarios or when fine-grained control over execution is needed, full-featured debuggers provide even more capabilities.\nDebuggers\nDebuggers represent the pinnacle of tools available for investigating bugs in Ruby code. They offer capabilities far beyond simple puts statements and interactive consoles, providing full control over program execution. This powerful feature set allows developers to:\nPause execution at a specified point using breakpoints.\nInspect and modify variables in real time.\nExamine the call stack at every breakpoint.\nStep through code line by line.\nEvaluate expressions in the current context.\n \n\n\n\nLet’s explore the three main debuggers for Ruby:\n1. byebug gem\nDefault debugger for Ruby 2.5.X, Ruby 2.6.X, Rails 5, and Rails 6.\nComes with all the essential features you’d expect from a debugger like breakpoints, stepping, context, and stack introspection.\nFor Rails applications, it requires modification of the application source code. You usually need to place a special call in your code to start the debugger at a certain place.\nHas noticeable performance overheads that make it less usable for complicated applications.\n\n\n\n\n2. debug gem\nSupports only Ruby versions starting from 2.7.\nHas no performance overheads on supported Ruby versions.\nFor Rails applications, debug, similar to byebug, requires modification of the application source code.\nBundled with Ruby starting from version 3.1.\n\n\n\n\n3. RubyMine debugger\nSupports Ruby versions 2.3 and later – so almost all possible versions of Ruby your application could use.\nHas no performance overheads on any of the supported versions of Ruby.\nNo need to modify the code to use the debugger.\nProvides a user-friendly UI out of the box that streamlines debugging.\n\n\n\n\nDespite its extensive feature set, debuggers might be difficult to use in some specific configurations. While debuggers are powerful, they’re most effective when combined with other debugging techniques. The choice of debugger often depends on your specific project and configuration requirements, Ruby version, and personal preferences.\nConclusion\nDebugging in Ruby is both an art and a science, presenting challenges that can be overcome with the right tools. As we’ve explored in this post, Ruby developers have a rich toolkit at their disposal, ranging from simple puts statements to sophisticated debuggers.\nEach debugging approach we’ve discussed has its strengths:\nputs statements offer quick, straightforward insights, ideal for simple issues or when other tools are unavailable.\nInteractive consoles like IRB and Pry provide a more dynamic environment, allowing for deep context introspection and complex expression evaluation.\nFull-fledged debuggers, such as the byebug and debug gems, as well as the RubyMine debugger, offer comprehensive control over program execution, enabling developers to dissect even the most intricate bugs.\n \n\n\n\nThe journey from encountering an unexpected bug to pinpointing its exact cause often requires a combination of these tools, along with methodical investigation and sometimes a bit of creative problem-solving. By understanding the strengths and limitations of each debugging tool, you can select the most appropriate approach for each unique situation.\nAs the RubyMine team, we’re particularly interested in how our debugging tools serve the Ruby community. We encourage you to explore the RubyMine debugger and share your experiences in the comments below or create an issue in the issue tracker. Your fellow developers will surely appreciate your insight.\nLooking ahead, our next post will delve deeper into the inner workings of debuggers. We’ll explore their internal mechanisms and even tackle an exciting challenge: creating a basic debugger from scratch. This exploration will enhance your understanding of debugging tools and provide deeper insights into Ruby’s internals.\nMeanwhile, take advantage of the advanced debugger in RubyMine. Download the latest RubyMine version from our website or via the free Toolbox App.\nRemember, effective debugging is more than just finding and fixing errors – it’s about understanding your code at a fundamental level. Each debugging session is an opportunity to learn, improve, and write more robust Ruby code.\n\n\n\n\nStay curious, keep exploring, and happy debugging!\nThe RubyMine team",
        "dc:creator": "Dmitry Pogrebnoy",
        "content": "Hello, Ruby developers! Debugging is an essential skill in software development, and in this post, we&#8217;ll be looking at how to investigate the behavior of Ruby code. As the RubyMine team, we&#8217;ve accumulated considerable expertise in creating tools for Ruby developers, and we&#8217;re excited to share our experience and knowledge with you. Recently, at the [&#8230;]",
        "contentSnippet": "Hello, Ruby developers! Debugging is an essential skill in software development, and in this post, we’ll be looking at how to investigate the behavior of Ruby code. As the RubyMine team, we’ve accumulated considerable expertise in creating tools for Ruby developers, and we’re excited to share our experience and knowledge with you. Recently, at the […]",
        "guid": "https://blog.jetbrains.com/?post_type=ruby&p=533180",
        "categories": [
          "rubymine"
        ],
        "isoDate": "2024-12-06T08:55:18.000Z"
      },
      {
        "creator": "Ekaterina Petrova",
        "title": "Code, Learn, Repeat: Get Ready for KotlinConf 2025",
        "link": "https://blog.jetbrains.com/kotlin/2024/12/code-learn-repeat-get-ready-for-kotlinconf-2025/",
        "pubDate": "Thu, 05 Dec 2024 16:39:15 +0000",
        "content:encodedSnippet": "KotlinConf has always been about more than just code – it’s where ideas spark, skills develop, and the Kotlin community comes together to share knowledge, connect, and celebrate. \nWhile we’re still crafting the 2025 program (stay tuned for the big reveal in February), here are the recordings of last year’s top talks to give you a taste of what to expect at the upcoming event:\n\n\n\n\n\n🎤 Why We Can’t Have Nice Things in Kotlin by Vsevolod Tolstopyatov. A delightful dive into the unexpected challenges of creating Kotlin libraries. Ever wondered how nineteenth-century insect collections impact APIs? Find out in this witty, thought-provoking session.\n🔍 Debugging the Future: Coroutine Debugger Tools by Nikita Naza. Master coroutine debugging with deep insights and powerful tools.\n☁️ Have Your Serverless Kotlin Functions and Eat Them Too by Andrew O’Hara. Learn to minimize initialization time, streamline dependencies, and eliminate reflection, so you can build fast, efficient API services in Kotlin – no compromises needed!\n🧠 Free the World From Wasteful Scheduling With Timefold AI by Geoffrey De Smet. Learn how to tackle complex planning problems like scheduling and routing efficiently using Timefold, an Apache-licensed AI solver for Kotlin. Live coding guaranteed!\n🎨 Tap it! Shake it! Fling it! Sheep it! by Nicole Terc. Combining gesture animations with Compose Multiplatform, this presentation is fun, interactive, and packed with tips for Android and iOS.\n🚀 Evolving Compose Multiplatform on iOS and Beyond by Sebastian Aigner. A sneak peek into the future of Compose Multiplatform with new features like common previews, lifecycle, and navigation.\n🌟 The Best Programmer I Know by Daniel Terhorst-North. A heartfelt exploration of what truly makes a great programmer, this one is inspiring and relatable.\nThis year, expect an equally dynamic mix of technical deep dives, practical sessions, and soft skill talks tailored for every Kotlin enthusiast across backend, mobile, web, and desktop. But KotlinConf isn’t just about the talks! The event also provides the opportunity to network with thousands of professional developers, build new connections through various activities, flex your coding skills in fun challenges, and recharge your passion for development during unforgettable social events, including an epic after-party!\n\n\n\n\nDon’t miss out on the energy and inspiration that is KotlinConf.  Let’s learn, build, and celebrate together. 🎟️ Secure your spot today!",
        "dc:creator": "Ekaterina Petrova",
        "content": "KotlinConf has always been about more than just code – it’s where ideas spark, skills develop, and the Kotlin community comes together to share knowledge, connect, and celebrate.&#160; While we’re still crafting the 2025 program (stay tuned for the big reveal in February), here are the recordings of last year’s top talks to give you [&#8230;]",
        "contentSnippet": "KotlinConf has always been about more than just code – it’s where ideas spark, skills develop, and the Kotlin community comes together to share knowledge, connect, and celebrate.  While we’re still crafting the 2025 program (stay tuned for the big reveal in February), here are the recordings of last year’s top talks to give you […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=533389",
        "categories": [
          "kotlin-news",
          "news"
        ],
        "isoDate": "2024-12-05T16:39:15.000Z"
      },
      {
        "creator": "Maria Sharobaeva",
        "title": "JetBrains Academy – November Digest",
        "link": "https://blog.jetbrains.com/education/2024/12/05/jetbrains-academy-november-digest-2/",
        "pubDate": "Thu, 05 Dec 2024 16:18:22 +0000",
        "content:encodedSnippet": "As the year draws to a close, the JetBrains Academy team has some exciting updates for you! In this newsletter, you’ll discover new courses, plugins to enhance your learning, tech career tips, and updates for computer science educators.\nMaster AI With Courses\nNEW AI course\nTry the new Master AI: Build Game Players Using AlphaZero course. This course gives you the tools and resources to build AI from scratch, emulating DeepMind’s AlphaZero. Work hands-on with GPU-powered cloud environments to create AI game players and design your own web interface. \nTry now\n                                                    \nDevOps Engineer with AI\nGain a comprehensive understanding of DevOps principles, CI/CD, configuration management, and the integration of AI technologies in DevOps processes. Learn up-to-date practical skills needed for a DevOps engineer role.\nStart learning\n                                                    \nNew in November\nSee what new content has been added to JetBrains Academy in November, including new Kotlin projects, AI tools, and more.\nExplore now\n                                                    \nPlugins for Effective Learning\nIDE Features Trainer \nDiscover essential IDE shortcuts and features with the IDE Features Trainer plugin! Learn interactively right inside your IDE – no manuals or video tutorials needed.\nDownload now\n                                                    \nWrite flawlessly with Grazie\nSpot and correct grammar, spelling, and style issues instantly with the Grazie plugin. Get quick-fixes and explanations for your text – whether in comments, commits, messages, or code.\nInstall now\n                                                    \nCareer in Tech\nFive soft skills to include in your resume\nIn an increasingly AI-driven world, soft skills are invaluable! Discover the top five skills to develop for a successful career in tech.\nRead now\n                                                    \nJetBrains Academy for Course Creators\nTeaching IT simplified\nAre you an independent course creator or a university professor? We’ve gathered all the useful resources for project-based course creation in one place.\nLearn more",
        "dc:creator": "Maria Sharobaeva",
        "content": "As the year draws to a close, the JetBrains Academy team has some exciting updates for you! In this newsletter, you’ll discover new courses, plugins to enhance your learning, tech career tips, and updates for computer science educators.",
        "contentSnippet": "As the year draws to a close, the JetBrains Academy team has some exciting updates for you! In this newsletter, you’ll discover new courses, plugins to enhance your learning, tech career tips, and updates for computer science educators.",
        "guid": "https://blog.jetbrains.com/?post_type=education&p=533229",
        "categories": [
          "digest",
          "jetbrains-academy",
          "newsletter"
        ],
        "isoDate": "2024-12-05T16:18:22.000Z"
      },
      {
        "creator": "Maciej Gorywoda",
        "title": "IntelliJ Scala Plugin 2024.3.20 Is Out!",
        "link": "https://blog.jetbrains.com/scala/2024/12/05/intellij-scala-plugin-2024-3-is-out-2/",
        "pubDate": "Thu, 05 Dec 2024 16:10:39 +0000",
        "content:encodedSnippet": "We’ve just published a maintenance update to IntelliJ Scala Plugin 2024.3. This minor release includes several bug fixes and improvements to existing features introduced in the main release.\nLambda breakpoints in the debugger\nWe’ve made improvements to how lambda expressions are handled in the debugger. Previously, setting a breakpoint on a line with a lambda (e.g. in a method parameter list) would cause the entire line to be highlighted. Starting with this release, only the lambda body is highlighted, reflecting the actual point where the breakpoint is attached.\n\n\n\n\nNamed tuples completion\nNamed tuples are a new experimental feature introduced in Scala 3.5 that will become a standard feature in Scala 3.7. You can read more about our support for named tuples in the release notes for the 2024.3 release of the IntelliJ Scala Plugin.\nIn this minor release, we’ve added another enhancement to make working with named tuples even more efficient. Suppose you have a named tuple already defined in your code, for example:\ntype X = (a: Int, b: String)\nIf you declare a value of this type, then IntelliJ IDEA will now suggest a completion that lists all the tuple’s fields’ names:\nval blub: X = (a = ???, b = ???)\n\n\n\n\n\nFixes to Optimize imports\nWe fixed a bug that was causing the Optimize imports action to identify the imported derived extension method as unused and remove it. This fix ensures that your code stays functional while optimizing imports.\n\n\n\n\nThe AI-powered Rename refactoring no longer suggests existing names\nIf you’ve used AI Assistant, you’re likely familiar with its ability to assist in solving one of the most challenging problems in programming: giving meaningful names to your classes, methods, and fields. Until recently, though, when you wanted to rename a field, AI would occasionally suggest names that were already in use in your code, leading to potential conflicts. Since the current release, this is not going to happen anymore.\n\n\n\n\nAs always, your feedback is very welcome. Please report any issues you find to YouTrack. If you have any questions, feel free to ask us on Discord.\nHappy developing!\nThe IntelliJ Scala Plugin team",
        "dc:creator": "Maciej Gorywoda",
        "content": "We’ve just published a maintenance update to IntelliJ Scala Plugin 2024.3. This minor release includes several bug fixes and improvements to existing features introduced in the main release. Lambda breakpoints in the debugger We’ve made improvements to how lambda expressions are handled in the debugger. Previously, setting a breakpoint on a line with a lambda [&#8230;]",
        "contentSnippet": "We’ve just published a maintenance update to IntelliJ Scala Plugin 2024.3. This minor release includes several bug fixes and improvements to existing features introduced in the main release. Lambda breakpoints in the debugger We’ve made improvements to how lambda expressions are handled in the debugger. Previously, setting a breakpoint on a line with a lambda […]",
        "guid": "https://blog.jetbrains.com/?post_type=scala&p=530145",
        "categories": [
          "news",
          "releases",
          "scala",
          "scala-programming",
          "intellij-idea"
        ],
        "isoDate": "2024-12-05T16:10:39.000Z"
      },
      {
        "creator": "Irina Mariasova",
        "title": "Java Annotated Monthly – December 2024",
        "link": "https://blog.jetbrains.com/idea/2024/12/java-annotated-monthly-december-2024/",
        "pubDate": "Thu, 05 Dec 2024 15:57:47 +0000",
        "content:encodedSnippet": "As 2024 wraps up, this December edition of Java Annotated Monthly brings you the latest on JEPs targeted for Java 24, helpful tutorials on Java, Kotlin, and AI, and more. This time, we’ve included thought-provoking non-tech articles perfect for year-end reflection. Plus, we’re thrilled to welcome Josh Long as our featured author, who will be sharing the latest Spring updates. \nGrab a cup of something warm and enjoy a mix of learning, inspiration, and fresh perspectives to close out the year!\nFeatured Content \nJosh Long \n\nJosh Long became the first Spring Developer Advocate in 2010, and he has served in that role ever since. Josh is a Java Champion and the author of 7 books (including Reactive Spring) and numerous best-selling video training materials (including Building Microservices with Spring Boot Livelessons with Spring Boot co-founder Phil Webb). He is also an open-source contributor (Spring Boot, Spring Integration, Axon, Spring Cloud, Activiti, Vaadin, etc), a Youtuber (Coffee + Software with Josh Long as well as a Spring Tips series), and a podcaster (A Bootiful Podcast).\n\nHi, Spring fans! I want to start off with something profoundly simple: thank you! Last week, we Americans celebrated Thanksgiving, a holiday that is (when it’s at its best) about being thankful. I am thankful for you all. You know what else I am thankful for? That the Spring Boot team got Spring Boot out the door a week earlier this year, so I can enjoy my turkey in peace! Yes, Spring Boot is officially out, and it’s jam-packed… stuffed like a Thanksgiving turkey!\nI was told these Java Annotated Monthly installments need to be pithy, concise. (Do they know me?) But I wanted to talk about all the goodness in Spring Boot 3.4. I am not sure how I am meant to keep the discussion of six months of amazing new software to the lengths required for this installment. Then it dawned on me! Links are short. Read this; it’s my much longer-form thoughts on just some of the amazing new features when you’re using Spring Boot 3.4!\nStill here? Just want the TL;DR? Did I hear you say “listacle”? Fine! Here are my top thirty-four (34 for Spring Boot 3.4) favorite features shipping with Spring Boot 3.4, grouped by the technologies to which they belong. We’ll start at the top of the abstraction stacks, those technologies that build upon Spring Boot first:\nSpring Modulith has…\nSupport for nested application modules and external application module contributions.\nNew deleting and archiving event publication completion modes.\nBy-ID event publication completion significantly improves performance.\nEvent externalization into Spring’s MessageChannel abstraction to, for example, trigger Spring Integration flows.\nSpring AI has…\nA ton of work done around function calling, both in Java and Kotlin.\nAnd the first cut of support for the ideas taking shape in the AI community around “advanced and modular RAG”. \nThen move on to Spring Boot itself:\nSpring Boot has…\nAn updated auto-configuration experience for underlying HttpRequestFactory implementations that are plugged into either the RestClient or RestTemplate.\nNewly added support for structured logging, with built-in support for Elastic Common Schema (ecs), Graylog Extended Log Format (gelf), and Logstash (logstash).\nAn updated auto-configuration for ActiveMQ Classic support for an embedded broker.\nThe paketobuildpacks/builder-jammy-java-tiny set for use by default. This builder supports ARM and x64 platforms out of the box. Yes, you read that right: you can build Docker images with your GraalVM native images on Apple Silicon, and it’ll work! \nImproved Spring Boot Actuator endpoints that show more information about SSL bundles and scheduled tasks.\nAnd then the things upon which Spring Boot depends:\nSpring Framework has…\nSupport for the concept of @Fallback beans, essentially the mirror image of @Primary beans.\nFragment rendering! This one is for you HTMX and Turbo enjoyers! You can now render multiple views in one request or create a stream of rendered views.\nEasier reflection of non-Spring-managed beans with @Reflective and the new @ReflectiveScan annotation.\nSpring Data has…\nA new Repository fragments SPI that lets any arbitrary .jar on the classpath contribute extensions to the Spring Data repository.\nMuch-reduced query parsing overhead in Spring Data JPA.\nExpiration for @TimeSeries in Spring Data MongoDB.\nKeyspace qualification for tables and user-defined types in Spring Data for Apache Cassandra.\nJedis Lua scripting support in transaction and pipeline operations in Spring Data Redis.\nSpring Batch has…\nGone from one to three – count ’em: three! – JobRepository implementations.\nNew support for data classes – Kotlin data class or Java record instances – when using a JDBC-based ItemReader<T>.\nConcurrent steps with BlockingQueueItemReader<T> and BlockingQueueItemWriter<T>; this is the EZ button for staged event-driven architectures (SEDA)!\nA CompositeItemReader<T> that can sequentially drain data from more than one delegated ItemReader<T>.\nSpring Integration has…\nBig improvements to remote file system inbound adapters.\nA convenient Consumer<SshClient> to allow for further customization of the internal SshClient.\nScripting support for Python that now builds on the GraalVM Truffle Polyglot project.\nA new BaseMessageBuilder that has been extracted from the MessageBuilder to simplify building your custom builder implementation, where most of the logic should be identical to that of MessageBuilder.\nEasier configuration for the control bus pattern, along with a new control bus HTTP controller.\nSpring Security has…\nIntroduced support for WebAuthN/Passkeys! Yes, that’s right, you can have people logging into your application with their laptop’s fingerprint reader, their Yubikey, their phone’s face scanner, and more, in no time!\n“Magic links” – insta-login a person with a link!\nOIDC back-channel support that now accepts logout tokens of type logout+jwt.\nThe Spring RestClient that can now be configured with OAuth2ClientHttpRequestInterceptor to make protected resource requests.\nA token exchange that now supports refresh tokens.\nA token exchange that now supports refresh tokens. Technically, the Spring Authorization Server isn’t part of Spring Security, but I’ll mention it here for simplicity. It includes many new features, including a markedly more consistent and concise DSL configuration. Getting a whole OAuth IDP up and running with one line of Java code in a typical Spring Security application and a few configuration lines in your properties or YAML file is SO NICE.\nAs always, if you want to try things out, you just need to go and choose File | New Project | and choosing Spring Boot from among the project types in the fantastic IntelliJ IDEA IDE. If you’d like to learn more, maybe check out the Spring Guides, Spring Academy, or my YouTube channel!\nThank you.\nJava News\nJava News Roundup 1, 2, 3, 4 – Don’t miss any Java news from the past month. \nHere is the list of JEPs targeting JDK 24:\n490: ZGC: Remove the Non-Generational Mode\n478: Key Derivation Function API (Preview)\n493: Linking Run-Time Images without JMODs\n488: Primitive Types in Patterns, instanceof, and switch (Second Preview)\n486: Permanently Disable the Security Manager\n487: Scoped Values (Fourth Preview)\n491: Synchronize Virtual Threads without Pinning\n450: Compact Object Headers (Experimental)\n494: Module Import Declarations (Second Preview)\n497: Quantum-Resistant Module-Lattice-Based Digital Signature Algorithm\n496: Quantum-Resistant Module-Lattice-Based Key Encapsulation Mechanism\n498: Warn upon Use of Memory-Access Methods in sun.misc.Unsafe\nJava Tutorials and Tips\nExploring New Features in JDK 23: Module Design Pattern with JEP-476 – In this article, Miro Wengner focuses on the innovative module design pattern and explains how this update enhances modularity and scalability in Java development.\nWhy Java 8 is a Ticking Time Bomb Hiding Within Your Organization – Frank Delporte discusses the risks associated with continuing to use Java 8, including security vulnerabilities, performance limitations, and reduced developer productivity, advocating for upgrading to newer Java versions to mitigate these issues.\nDiscovering the perfect Java Supply Chain Attack vector and how it got fixed – This article walks you through the fascinating process of uncovering a critical vulnerability in the Java ecosystem and teaches you about the measures taken to resolve it. It highlights the importance of securing supply chains and shares insights to help developers safeguard their projects.\nMigrating from the Javax to Jakarta Namespace in Spring Boot App – In this article, Mónika Lombos provides a practical guide to migrating Spring Boot applications from the javax namespace to the jakarta namespace. She explains the steps, challenges, and considerations involved in making this transition smooth and efficient.\nLeverage LLMs in Java with LangChain4j and Quarkus – Holly Cummins and Georgios Andrianakis explore how combining LangChain4j and Quarkus can simplify building applications powered by LLMs. \nPattern Matching in Java – Past, Present, Future – Aggelos Biboudis talks about the evolution of switch and instanceof in Java, from their classic roles in data introspection to their modern transformation into powerful tools for pattern matching.\nPostcards from the Peak of Complexity – In this talk, Brian Goetz shares insights, lessons, and behind-the-scenes stories from the development of Java’s major features, such as generics, lambdas, and virtual threads.\nMark–Scavenge: Waiting for Trash to Take Itself Out – This blog post summarizes the new Mark-Scavenge garbage collection algorithm, which tackles the inefficiencies of using reachability as a proxy for liveness in moving GCs, leading to reduced unnecessary data movement. The work is part of a research collaboration between Oracle and Uppsala University, with the full paper available on the ACM website.\nJava-Based No-Code and Low-Code Application Bootstrapping Tools Review – What exactly are no-code or low-code platforms? This article will help you understand them, while also explaining how to avoid common mistakes and pitfalls. \nJava Language Futures – Fall 2024 Edition – Gavin Bierman explores the future of Java, summarizing recent changes while providing insights into upcoming directions and features currently in development. It’s an excellent overview for those keen to see what’s next for the language.\nWhat collection mapping should I use? – Gavin King explains how to map collections and @ManyToMany associations in Jakarta Persistence, providing tips on choosing the right collection types and annotations for better code.\nSome Common Java Gotchas – Peter Lawrey explores frequent pitfalls developers encounter when working with Java, offering insights and practical advice for navigating these challenges effectively. \nTen Java Myths and Misconceptions – Another interesting piece by Peter Lawrey where he demystifies common misunderstandings about Java.\nOptimizing Java Applications on Kubernetes: Beyond the Basics – In this talk from the InfoQ Dev Summit Boston conference, Bruno Borges discusses strategies for enhancing Java application performance on Kubernetes, focusing on leveraging JVM ergonomics, and managing garbage collection processes.\nBuild and Run TornadoVM with IntelliJ IDEA – TornadoVM is an open-source Java technology designed to help developers optimize their codebases for hardware acceleration. This blog post provides a detailed guide on building TornadoVM with IntelliJ IDEA and running TornadoVM unit tests or other Java programs.\nHashcode and Equals Debugging, Performance – Shai Almog examines the inefficiencies in Java’s hashCode() and equals() methods and offers insights for avoiding such pitfalls.\nKotlin Corner\nKotlin K2 Mode Becomes Stable – Learn more about IntelliJ IDEA’s Kotlin K2 mode, which is now out of Beta and ready for general use starting from version 2024.3. K2 mode significantly improves Kotlin code analysis stability, memory consumption efficiency, and the IDE’s overall performance – and it supports Kotlin 2.1 language features, too.\nThe best dispatcher for a backend framework – Marcin Moskała examines various Kotlin coroutine dispatchers to identify the most suitable one for backend request handlers, providing insights into their performance and appropriate use cases.\nKotlin Tips and Tricks You May Not Know: #3 — Built-in Assertions – This is a light yet insightful read that shows you how to write cleaner, safer Kotlin code with powerful built-in tools you might not be using yet!\nKotest + Spring + Testcontainers – Ronny Bräunlich demonstrates how to easily integrate Kotest, Spring, and Testcontainers for a smoother Java testing setup.\nAnonymous Functions Aren’t Lambdas – In his video, Dave Leeds introduces Kotlin’s anonymous functions, those rare gems that combine the best of named functions and lambdas, and shows you how to spot and use them effectively in your code.\nFun with Function Types in Kotlin – In another video, Dave takes you on a tour of Kotlin’s function types, from regular and extension functions to bound and property references.\nUnderstanding Gradle – Duncan McGregor takes a deep dive into Gradle builds, exploring task dependencies, build artifacts, and optimization tricks like skipping unchanged tests. \nAdvanced Kotlin Coroutine Cheat sheet (for Android Engineer) – This practical guide by Gaëlle Minisini untangles the complexities of Kotlin coroutines, offering Android developers handy tips and best practices to level up their async programming skills.\nState of Kotlin Scripting 2024 – Find out more the evolution of scripting in Kotlin, along with tips to supercharge your scripting workflows.\nLanguages, Frameworks, Libraries, and Technologies\nThis Week in Spring 1, 2, 3, 4 – Check out all the important Spring news.\nSpring Boot: Java Template Engine (JTE) – Learn more about the Java Template Engine (JTE) – a new addition to the Spring Initializer ecosystem.\nThe Latest in the World of Web Engineering (Featuring AI) – In this talk from Qcon London, Tejas Kumar overviews web engineering in relation to AI, intelligent answer engines, an update on CSS, HTML, JavaScript, and personal health and productivity.\nFront End Debugging Part 1: Not just Console Log – Shai Almog highlights advanced debugging techniques, such as the use of the debugger keyword, triggering debugging from the console, and setting DOM and XHR breakpoints.\nPodcast: Generally AI – Season 2 – Episode 6: the Godfathers of Programming and AI – The hosts discuss Geoffrey Hinton, the “Godfather of AI”, who developed key algorithms like backpropagation, helped with neural visualization using t-SNE, and sparked renewed interest in neural networks with the success of AlexNet. Less than a month after this podcast was recorded, Geoffrey Hinton won the Nobel Prize for Physics for his research into neural networks.\nThe best way to determine the optimal connection pool size – Vlad Mihalcea provides a practical guide to determining the ideal connection pool size for database applications, balancing performance and resource efficiency.\nRedacting sensitive information when using Generative AI models – Guillaume Laforge delves into strategies for protecting sensitive data when using AI. \nConferences and Events\nGet ready for the last events of this year:\nFrom Code to Clarity With the Redesigned Structure Tool Window – Online, December 12\nUtrecht JUG December Meetup – Utrecht, Netherlands, December 12\nTest Driving Code with the Help of AI with Dr. Venkat Subramaniam – Atlanta, USA, December 17\nGraalVM and GraalPy Meet IntelliJ IDEA – Online, December 19\nCulture and Community\nName things unambiguously – In this article, Peter Hilton explores the challenges of ambiguous naming in software development and how it can lead to misunderstandings and bugs. Are your names crystal clear, or do they cause chaos in your code?\nThe Philosophical Implications of Technology: A Conversation with Anders Indset – In this podcast, Shane Hastie, Lead Editor for Culture & Methods, chats with Anders Indset, a Norwegian philosopher exploring the impact of technology on humanity.\nThe Efficiency Paradox and How to Save Yourself and the World – Holly Cummins talks about the ups and downs of trying to be efficient. This piece can be a good point to start a discussion about this topic. \nHow we almost missed a plane in Kazakhstan, but OpenJDK could have saved us… – Ever thought Java could help with travel drama? Read this article to find out if it’s possible. \nWhat Developers Can Do to Continue to Program as They Age – Ben Linders summarizes insights that Kate Gregory shared at NDC Tech Town, including practical tips for adapting work environments and maintaining the personal well-being of older workers. \nPodcast: Trends in Engineering Leadership: Observability, Agile Backlash, and Building Autonomous Teams – Learn more about the trends in software engineering, including the pushback against “Agile” practices, the rise of observability, people-focused metrics, ways to align teams while keeping their independence, and more. \nDay 13 of BlueSky; thoughts so far – Are you giving BlueSky a chance?\nFoojay Podcast #61: As a developer, how do we keep our body and mind healthy? – This podcast episode explores how developers can maintain physical and mental well-being, featuring insights from industry professionals on topics like AI’s impact, the challenges of remote work, and preventing burnout.\n5 Lessons I learned the hard way from 10+ years as a software engineer – What lessons have you learned?\nBeing a Responsible Developer in the Age of AI Hype – If you are curious about how developers can cut through the AI hype responsibly, check out this article. \nAnd Finally…\nIntelliJ IDEA 2024.3 Is Out! – IntelliJ IDEA 2024.3, the final major release of the year, is packed with new features and enhancements to elevate your development experience. Highlights include a visual representation of your code’s logical structure in the Structure tool window, improved debugging for Kubernetes applications, and cluster-wide Kubernetes log access.\nFaster Time-to-Code in IntelliJ IDEA – In this post, you can read about the key steps we’ve taken to enhance performance in the latest versions of IntelliJ IDEA. These improvements focus on reducing time-to-code through phased indexing and making the IDE more responsive, ensuring a faster and smoother experience from the moment you start up.\nTop Java Blogs for Experienced Programmers – Check out our curated selections of the best expert blogs on Java. \nIn Memory of Stiver – Sad news for the Java community: Stiver, the original author of the Fernflower Java decompiler, has passed away.\nHow to Use Flyway for Database Migrations in Spring Boot Applications – In this article, you’ll discover why Flyway is a must-have for database migrations, how it works, ways to integrate it with Spring Boot, and how IntelliJ IDEA Ultimate simplifies migration script generation.\nFrom Code to Clarity With the Redesigned Structure Tool Window – This article shows how AI-inspired updates to the Structure tool window make exploring code and performing actions easier with the new Logical view.\nAdvanced Code Analysis in IntelliJ IDEA – Level up your code analysis with Marit van Dijk. Learn how to find specific patterns in your code and create custom inspections in IntelliJ IDEA.\nDeclarative Gradle in IntelliJ IDEA – Find out what Declarative Gradle is and how to try it. \nLivestreams\nThe JUnit Crew Presents What’s New – In this session, the JUnit team introduces the new features of the recent 5.11 release, along with highlights from the previous 5.9 and 5.10 releases.\nThat’s it for today! We’re collecting ideas for the next Java Annotated Monthly – send your suggestions via email or X by December 20. Don’t forget to check out our archive of past JAM issues for any articles you may have missed!",
        "dc:creator": "Irina Mariasova",
        "content": "As 2024 wraps up, this December edition of Java Annotated Monthly brings you the latest on JEPs targeted for Java 24, helpful tutorials on Java, Kotlin, and AI, and more. This time, we’ve included thought-provoking non-tech articles perfect for year-end reflection. Plus, we’re thrilled to welcome Josh Long as our featured author, who will be [&#8230;]",
        "contentSnippet": "As 2024 wraps up, this December edition of Java Annotated Monthly brings you the latest on JEPs targeted for Java 24, helpful tutorials on Java, Kotlin, and AI, and more. This time, we’ve included thought-provoking non-tech articles perfect for year-end reflection. Plus, we’re thrilled to welcome Josh Long as our featured author, who will be […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=533184",
        "categories": [
          "news",
          "java",
          "java-annotated",
          "java-annotated-monthly",
          "kotlin"
        ],
        "isoDate": "2024-12-05T15:57:47.000Z"
      },
      {
        "creator": "Olga Bedrina",
        "title": "TeamCity 2024.12: UI Updates, Experimental Kubernetes Executor Mode, Conditional Dependencies in Build Chains, and More",
        "link": "https://blog.jetbrains.com/teamcity/2024/12/teamcity-202412/",
        "pubDate": "Thu, 05 Dec 2024 12:52:46 +0000",
        "content:encodedSnippet": "TeamCity 2024.12 introduces a redesigned UI, conditional build chains, simplified OAuth token management, and enhanced AWS and Perforce integrations. \nNew features also include support for custom Kotlin DSL libraries, centralized refreshable token management, and single-action build chain approvals, among others.\nConditional dependencies in build chains\nIn TeamCity, you can break down complex build processes into distinct stages, each executed on different build agents. These interconnected stages form what we call a build chain. A build chain is configured by creating multiple build configurations, each representing a stage, and linking them with snapshot dependencies.\nUntil now, every part of a build chain was expected to run or be reused from a previous run.\nWith TeamCity 2024.12, we’re introducing conditional dependency execution, which lets you selectively skip certain stages when a build chain is queued.\n\n\n\n\nFor example, imagine you’re running a large test suite where each build configuration represents a specific set of tests, like frontend tests, backend tests, and performance tests. \nWith conditional dependencies, you can configure your build chain to run specific builds depending on files in the VCS commit. There is no need to run your backend or performance tests if only CSS files were changed, but you still need the final deployment package at the end of your build chain.\nPreviously, TeamCity allowed skipping particular steps of a single build configuration. Now, whole builds can be skipped, and they won’t occupy a build agent at all.\nThis update enables you to create more efficient, targeted build chains by omitting specific configurations as needed.\nRead more about how to configure the functionality in our release notes.\n[Experimental] Kubernetes executor mode\nTeamCity already offers a native integration with Kubernetes, but with 2024.12, we’re extending this functionality. Now, TeamCity can directly use Kubernetes as a scheduling and orchestrating system for your builds, thanks to the experimental Kubernetes executor mode.\nNow, you can specify the task you want to run and which image you want to run it on, and Kubernetes will do everything else.\n\n\n\n\nKey benefits of the integration include:\nNative Kubernetes integration: Developers and QA teams can configure their builds without diving into infrastructure details like servers or cloud providers. Meanwhile, infrastructure teams can focus on preparing familiar Kubernetes setups. TeamCity builds are executed on native K8s pods, with each step running inside its own container. This allows you to use separate Docker images for each individual build step, among other advantages. \n\n\n\n\nFaster task execution: Builds start much more quickly compared to virtual servers, enabling developers to get feedback from automated tests sooner.\n\n\n\n\nEfficient resource utilization: Kubernetes allows multiple builds to run on a single server, compactly placing workloads and maximizing resource use. With less idle time, resources are utilized more effectively. This functionality is now available in TeamCity out of the box.\nRead more about the experimental Kubernetes executor mode in our docs.\nUI updates: Breadcrumbs and redesigned navigation\nWith TeamCity 2024.12, we started updating TeamCity’s product design. The main menu now resides on the left-hand side of the screen, offering a more intuitive structure that keeps key actions and views within reach.\n\n\n\n\nBreadcrumbs at the top make it simple to track your location within complex builds or pipelines so you can quickly move between projects and configurations.\n\n\n\n\nThis update enhances accessibility and brings a cleaner, more organized workspace that feels natural whether you’re working on a single project or managing multiple builds.\nSimplified VCS OAuth token management\nIn TeamCity 2024.12, we’ve implemented the Project Administration tab for managing short-lived VCS OAuth tokens. This initial rollout provides essential tools to streamline token handling in the admin UI.\nOur goal is to make OAuth-like tokens more accessible, enabling project administrators to view, configure, and create custom tokens with ease.\n\n\n\n\n\n\nKey capabilities include:\nToken search and display: Easily search for and view tokens available to specific TeamCity projects.\nToken deletion: Remove outdated or unused tokens with a single click.\nToken details: Inspect and copy token IDs for streamlined integration, especially for Kotlin DSL usage.\nToken naming: Assign descriptive names to tokens for easier identification and organization.\nToken scope: TeamCity displays a list of projects where the token can be used.\n\n\n\n\nOAuth authentication flow: Trigger OAuth flows directly to generate and securely store new tokens.\nThis update also extends token functionality in VCS roots, build features, and project settings, making token management more accessible across the TeamCity interface.\nApprove an entire build chain\nIn complex release workflows, a build chain might consist of many individual dependencies, which often require approval from a release manager.\nPreviously, triggering the composite configuration resulted in all dependent configurations needing separate approvals.\nIn 2024.12, we’re introducing the ability to approve an entire build chain in a single action. Release managers can now approve a composite build and its downstream dependencies without needing to authorize each individual configuration. This makes the release process more efficient.\n\n\n\n\nPull request filters\nTeamCity 2024.12 supports pull request filters in branch filters using the +|-pr: syntax. This lets you create detailed filters to track pull requests based on factors like author, user role, target and source branches, and more.\nCurrently, this new syntax is available only for triggers. To set it up, click the magic wand icon next to the Branch Filter field in the trigger settings to open an expression editor.\n\n\n\n\nPerforce integration enhancements\nWith the latest update, when a Perforce VCS root is set to check sources by label (using the Label/Changelist to Sync setting), TeamCity now records the corresponding revision number in a new vcsRoot.{externalId}.changelist parameter.\nThis enhancement improves usability by providing clear and immediate identification of the synced revision, streamlining traceability and management.\nCustom Kotlin DSL libraries\nTeamCity allows you to configure pipelines programmatically using the Kotlin DSL. Starting with version 2024.12, you can upload custom Kotlin libraries as a .jar file to your TeamCity server that will be available to use in your Kotlin DSL projects as a Maven dependency.\nThis simplifies the sharing and reuse of Kotlin DSL code between different projects.\n\n\n\n\nTo learn more about adding custom Kotlin DSL libraries to your TeamCity server, refer to our documentation.\nAWS integration enhancements\nAmazon EC2 cloud profiles will now use TeamCity AWS connections for authentication, moving away from access keys or the default credential provider chain. This update consolidates authentication settings into one connection, which can be used across multiple features (such as cloud profiles, S3 artifact storage, and AWS credentials).\nNew EC2 cloud profiles will support these new connections as well as legacy authentication methods, such as keys and default chain providers. Existing connections have received a reworked UI and will continue supporting legacy authentication methods, as well.\nLearn more about this and other new features in our documentation.\nPerformance updates\nIn this release, we’ve revamped how build lists and project trees are loaded. Along with frontend optimizations, these changes bring major improvements to performance, especially for users with large TeamCity installations and complex project setups.\n\n\n\n\nFor example, some pages now load up to three times faster, based on the 75th percentile data.\nIf you have any questions, feel free to reach out to us in the comments below or via the support form. We’ll be happy to help!",
        "dc:creator": "Olga Bedrina",
        "content": "TeamCity 2024.12 introduces a redesigned UI, conditional build chains, simplified OAuth token management, and enhanced AWS and Perforce integrations.&#160; New features also include support for custom Kotlin DSL libraries, centralized refreshable token management, and single-action build chain approvals, among others. Conditional dependencies in build chains In TeamCity, you can break down complex build processes into [&#8230;]",
        "contentSnippet": "TeamCity 2024.12 introduces a redesigned UI, conditional build chains, simplified OAuth token management, and enhanced AWS and Perforce integrations.  New features also include support for custom Kotlin DSL libraries, centralized refreshable token management, and single-action build chain approvals, among others. Conditional dependencies in build chains In TeamCity, you can break down complex build processes into […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=531718",
        "categories": [
          "news",
          "releases",
          "teamcity-2",
          "release"
        ],
        "isoDate": "2024-12-05T12:52:46.000Z"
      },
      {
        "creator": "Jodie Burchell",
        "title": "How to Do Sentiment Analysis With Large Language Models",
        "link": "https://blog.jetbrains.com/pycharm/2024/12/how-to-do-sentiment-analysis-with-large-language-models/",
        "pubDate": "Thu, 05 Dec 2024 10:49:14 +0000",
        "content:encodedSnippet": "Sentiment analysis is a powerful tool for understanding emotions in text. While there are many ways to approach sentiment analysis, including more traditional lexicon-based and machine learning approaches, today we’ll be focusing on one of the most cutting-edge ways of working with text – large language models (LLMs). We’ll explain how you can use these powerful models to predict the sentiment expressed in a text.\nAs a practical tutorial, this post will introduce you to the types of LLMs most suited for sentiment analysis tasks and then show you how to choose the right model for your specific task.\nWe’ll cover using models that other people have fine-tuned for sentiment analysis and how to fine-tune one yourself. We’ll also look at some of the powerful tools and resources available that can help you work with these models easily, while demystifying what can feel like an overly complex and overwhelming topic.\nTo get the most out of this blog post, we’d recommend you have some experience training machine learning or deep learning models and be confident using Python. That said, you don’t necessarily need to have a background in large language models to enjoy it.\nLet’s get started!\nWhat are large language models?\nLarge language models are some of the latest and most powerful tools for solving natural language problems. In brief, they are generalist language models that can complete a range of natural language tasks, from named entity recognition to question answering. LLMs are based on the transformer architecture, a type of neural network that uses a mechanism called attention to represent complex and nuanced relationships between words in a piece of text. This design allows LLMs to accurately represent the information being conveyed in a piece of text.\nThe full transformer model architecture consists of two blocks. Encoder blocks are designed to receive text inputs and build a representation of them, creating a feature set based on the text corpus over which the model is trained. Decoder blocks take the features generated by the encoder and other inputs and attempt to generate a sequence based on these.\nTransformer models can be divided up based on whether they contain encoder blocks, decoder blocks, or both.\nEncoder-only models tend to be good at tasks requiring a detailed understanding of the input to do downstream tasks, like text classification and named entity recognition.\nDecoder-only models are best for tasks such as text generation.\nEncoder-decoder, or sequence-to-sequence models are mainly used for tasks that require the model to evaluate an input and generate a different output, such as translation. In fact, translation was the original task that transformer models were designed for!\nThis Hugging Face table (also featured below), which I took from their course on natural language processing, gives an overview of what each model tends to be strongest at.\nAfter finishing this blog post and discovering what other natural language tasks you can perform with the Transformers library, I recommend the course if you’d like to learn more about LLMs. It strikes an excellent balance between accessibility and technical depth.\n\nModel typeExamplesTasks\nEncoder-onlyALBERT, BERT, DistilBERT, ELECTRA, RoBERTaSentence classification, named entity recognition, extractive question answering\nDecoder-onlyCTRL, GPT, GPT-2, Transformer XLText generation\nEncoder-decoderBART, T5, Marian, mBARTSummarization, translation, generative question answering\n\n\n\n\n\nSentiment analysis is usually treated as a text or sentence classification problem with LLMs, meaning that encoder-only models such as RoBERTa, BERT, and ELECTRA are most often used for this task. However, there are some exceptions. For example, the top scoring model for aspect-based sentiment analysis, InstructABSA, is based on a fine-tuned version of T5, an encoder-decoder model.\nUsing large language models for sentiment analysis\nWith all of the background out of the way, we can now get started with using LLMs to do sentiment analysis.\nInstall PyCharm to get started with sentiment analysis\nWe’ll use PyCharm Professional for this demo, but you can follow along with any other IDE that supports Python development.\nPyCharm Professional is a powerful Python IDE for data science. It supports advanced Python code completion, inspections and debugging, rich databases, Jupyter, Git, Conda, and more right out of the box. You can try out great features such as our DataFrame Column Statistics and Chart View, as well as Hugging Face integrations, which make working with LLMs much simpler and faster.\nIf you’d like to follow along with this tutorial, you can activate your free three-month subscription to PyCharm using this special promo code: PCSA. Click on the link below, and enter the code. You’ll then receive an activation code through your email.\nActivate your free three-month subscription\n                                                    \nImport the required libraries\nThere are two parts to this tutorial: using an LLM that someone else has fine-tuned for sentiment analysis, and fine-tuning a model ourselves.\nIn order to run both parts of this tutorial, we need to import the following packages:\nTransformers: As described, this will allow us to use fine-tuned LLMs for sentiment analysis and fine-tune our own models.\nPyTorch, Tensorflow, or Flax: Transformers acts as a high-level interface for deep learning frameworks, reusing their functionality for building, training, and running neural networks. In order to actually work with LLMs using the Transformers package, you will need to install your choice of PyTorch, Tensorflow, or Flax. PyTorch supports the largest number of models of the three frameworks, so that’s the one we’ll use in this tutorial.\nDatasets: This is another package from Hugging Face that allows you to easily work with the datasets hosted on Hugging Face Hub. We’ll need this package to get a dataset to fine-tune an LLM for sentiment analysis.\nIn order to fine-tune our own model, we also need to import these additional packages:\nNumPy: NumPy allows us to work with arrays. We’ll need this to do some post-processing on the predictions generated by our LLM.\nscikit-learn: This package contains a huge range of functionality for machine learning. We’ll use it to evaluate the performance of our model.\nEvaluate: This is another package from Hugging Face. Evaluate adds a convenient interface for measuring the performance of models. It will give us an alternative way of measuring our model’s performance.\nAccelerate: This final package from Hugging Face, Accelerate, takes care of distributed model training.\nWe can easily find and install these in PyCharm. Make sure you’re using a Python 3.7 or higher interpreter. For this demo, we’ll be using Python 3.11.7.\n\n\n\n\nPick the right model\nThe next step is picking the right model. Before we get into that, we need to cover some terminology.\nLLMs are made up of two components: an architecture and a checkpoint. The architecture is like the blueprint of the model, and describes what will be contained in each layer and each operation that takes place within the model.\nThe checkpoint refers to the weights that will be used within each layer. Each of the pretrained models will use an architecture like T5 or GPT, and obtain the specific weights (the model checkpoint) by training the model over a huge corpus of text data.\nFine-tuning will adjust the weights in the checkpoint by retraining the last layer(s) on a dataset specialized in a certain task or domain. To make predictions (called inference), an architecture will load in the checkpoint and use this to process text inputs, and together this is called a model.\nIf you’ve ever looked at the models available on Hugging Face, you might have been overwhelmed by the sheer number of them (even when we narrow them down to encoder-only models).\nSo, how do you know which one to use for sentiment analysis?\nOne useful place to start is the sentiment analysis page on Papers With Code. This page includes a very helpful overview of this task and a Benchmarks table that includes the top-performing models for each sentiment analysis benchmarking dataset. From this page, we can see that some of the commonly appearing models are those based on BERT and RoBERTa architectures.\nWhile we may not be able to access these exact model checkpoints on Hugging Face (as not all of them will be uploaded there), it can give us a guide for what sorts of models might perform well at this task. Papers With Code also has similar pages for a range of other natural language tasks: If you search for the task in the upper left-hand corner of the site, you can navigate to these.\nNow that we know what kinds of architectures are likely to do well for this problem, we can start searching for a specific model.\nPyCharm has an built-in integration with Hugging Face that allows us to search for models directly. Simply right-click anywhere in your Jupyter notebook or Python script, and select Insert HF model. You’ll be presented with the following window:\n\n\n\n\nYou can see that we can find Hugging Face models either by the task type (which we can select from the menu on the left-hand side), by keyword search in the search box at the top of the window, or by a combination of both. Models are ranked by the number of likes by default, but we can also select models based on downloads or when the model was created or last modified.\n\n\n\n\nWhen you use a model for a task, the checkpoint is downloaded and cached, making it faster the next time you need to use that model. You can see all of the models you’ve downloaded in the Hugging Face tool window.\n\n\n\n\nOnce we’ve downloaded the model, we can also look at its model card again by hovering over the model name in our Jupyter notebook or Python script. We can do the same thing with dataset cards.\nUse a fine-tuned LLM for sentiment analysis\nLet’s move on to how we can use a model that someone else has already fine-tuned for sentiment analysis.\nAs mentioned, sentiment analysis is usually treated as a text classification problem for LLMs.  This means that in our Hugging Face model selection window, we’ll select Text Classification, which can be found under Natural Language Processing on the left-hand side. To narrow the results down to sentiment analysis models, we’ll type “sentiment” in the search box in the upper left-hand corner.\n\n\n\n\nWe can see various fine-tuned models, and as expected from what we saw on the Papers With Code Benchmarks table, most of them use RoBERTa or BERT architectures. Let’s try out the top ranked model, Twitter-roBERTa-base for Sentiment Analysis.\n\n\n\n\nYou can see that after we select Use Model in the Hugging Face model selection window, code is automatically generated at the caret in our Jupyter notebook or Python script to allow us to start working with this model.\nfrom transformers import pipeline\npipe = pipeline(\"text-classification\",\n model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\nBefore we can do inference with this model, we’ll need to modify this code.\nThe first thing we can check is whether we have a GPU available, which will make the model run faster. We’ll check for two types: NVIDIA GPUs, which support CUDA, and Apple GPUs, which support MPS.\nimport torch\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nprint(f\"MPS available: {torch.backends.mps.is_available()}\")\nMy computer supports MPS, so we can add a device argument to the pipeline and add \"mps\". If your computer supports CUDA, you can instead add the argument device=0.\nfrom transformers import pipeline\n\npipe = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n                device=\"mps\")\nFinally, we can get the fine-tuned LLM to run inference over our example text.\nresult = pipe(\"I love PyCharm! It's my favorite Python IDE.\")\nresult\n[{'label': 'positive', 'score': 0.9914802312850952}]\nYou can see that this model predicts that the text will be positive, with 99% probability.\nFine-tune your own LLM for sentiment analysis\nThe other way we can use LLMs for sentiment analysis is to fine-tune our own model.\nYou might wonder why you’d bother doing this, given the huge number of fine-tuned models that already exist on Hugging Face Hub. The main reason you might want to fine-tune a model is so that you can tailor it to your specific use case.\nMost models are fine-tuned on public datasets, especially social media posts and movie reviews, and you might need your model to be more sensitive to your specific domain or use case.\nModel fine-tuning can be quite a complex topic, so in this demonstration, I’ll explain how to do it at a more general level. However, if you want to understand this in more detail, you can read more about it in Hugging Face’s excellent NLP course, which I recommended earlier. In their tutorial, they explain in detail how to process data for fine-tuning models and two different approaches to fine-tuning: with the trainer API and without it.\nTo demonstrate how to fine-tune a model, we’ll use the SST-2 dataset, which is composed of single lines pulled from movie reviews that have been annotated as either negative or positive.\nAs mentioned earlier, BERT models consistently show up as top performers on the Papers With Code benchmarks, so we’ll fine-tune a BERT checkpoint.\nWe can again search for these models in PyCharm’s Hugging Face model selection window.\n\n\n\n\nWe can see that the most popular BERT model is bert-base-uncased. This is perfect for our use case, as this was also trained on lowercase text, so it will match the casing of our dataset.\nWe could have used the popular bert-large-uncased, but the base model has only 110 million parameters compared to BERT large, which has 340 million, so the base model is a bit friendlier for fine-tuning on a local machine.\nIf you still want to use a smaller model, you could also try this with a DistilBERT model, which has far fewer parameters but still preserves most of the performance of the original BERT models.\nLet’s start by reading in our dataset. We can do so using the load_dataset() function from the Datasets package. SST-2 is part of the GLUE dataset, which is designed to see how well a model can complete a range of natural language tasks.\nfrom datasets import load_dataset\n\nsst_2_raw = load_dataset(\"glue\", \"sst2\")\nsst_2_raw\nDatasetDict({\n    train: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 67349\n    })\n    validation: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 872\n    })\n    test: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 1821\n    })\n})\nThis dataset has already been split into the train, validation, and test sets. We have around 67,349 training examples – quite a modest number for fine-tuning such a large model.\nHere’s an example from this dataset.\nsst_2_raw[\"train\"][1]\n{'sentence': 'contains no wit , only labored gags ', 'label': 0, 'idx': 1}\nWe can see what the labels mean by calling the features attribute on the training set.\nsst_2_raw[\"train\"].features\n{'sentence': Value(dtype='string', id=None),\n 'label': ClassLabel(names=['negative', 'positive'], id=None),\n 'idx': Value(dtype='int32', id=None)}\n0 indicates a negative sentiment, and 1 indicates a positive one.\nLet’s look at the number in each class:\nprint(f'Number of negative examples: {sst_2_raw[\"train\"][\"label\"].count(0)}')\nprint(f'Number of positive examples: {sst_2_raw[\"train\"][\"label\"].count(1)}')\nNumber of negative examples: 29780\nNumber of positive examples: 37569\nThe classes in our training data are a tad unbalanced, but they aren’t excessively skewed.\nWe now need to tokenize our data, transforming the raw text into a form that our model can use. To do this, we need to use the same tokenizer that was used to train the bert-large-uncased model in the first place. The AutoTokenizer class will take care of all of the under-the-hood details for us.\nfrom transformers import AutoTokenizer\n\ncheckpoint = \"google-bert/bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nOnce we’ve loaded in the correct tokenizer, we can apply this to the training data.\ntokenised_sentences = tokenizer(sst_2_raw[\"train\"][\"sentence\"])\nFinally, we need to add a function to pad our tokenized sentences. This will make sure all of the inputs in a training batch are the same length – text inputs are rarely the same length and models require a consistent number of features for each input.\nfrom transformers import DataCollatorWithPadding\n\ndef tokenize_function(example):\n    return tokenizer(example[\"sentence\"])\n\ntokenized_datasets = sst_2_raw.map(tokenize_function, batched=True)\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\nNow that we’ve prepared our dataset, we need to determine how well the model is fitting to the data as it trains. To do this, we need to decide which metrics to use to evaluate the model’s prediction performance.\nAs we’re dealing with a binary classification problem, we have a few choices of metrics, the most popular of which are accuracy, precision, recall, and the F1 score. In the “Evaluate the model” section, we’ll discuss the pros and cons of using each of these measures.\nWe have two ways of creating an evaluation function for our model. The first is using the Evaluate package. This package allows us to use the specific evaluator for the SST-2 dataset, meaning we’ll evaluate the model fine-tuning using the specific metrics for this task. In the case of SST-2, the metric used is accuracy.\nimport evaluate\nimport numpy as np\n\ndef compute_metrics(eval_preds):\n    metric = evaluate.load(\"glue\", \"sst2\")\n    logits, labels = eval_preds\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)\nHowever, if we want to customize the metrics used, we can also create our own evaluation function. \nIn this case, I’ve imported the accuracy, precision, recall, and F1 score metrics from scikit-learn. I’ve then created a function which takes in the predicted labels versus actual labels for each sentence and calculates the four required metrics. We’ll use this function, as it gives us a wider variety of metrics we can check our model performance against.\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nimport numpy as np\n\ndef compute_metrics(eval_preds):\n    logits, labels = eval_preds\n    predictions = np.argmax(logits, axis=-1)\n    return {\n        'accuracy': accuracy_score(labels, predictions),\n        'f1': f1_score(labels, predictions, average='macro'),\n        'precision': precision_score(labels, predictions, average='macro'),\n        'recall': recall_score(labels, predictions, average='macro')\n    }\nNow that we’ve done all of the setup, we’re ready to train the model. The first thing we need to do is define some parameters that will control the training process using the TrainingArguments class. We’ve only specified a few parameters here, but this class has an enormous number of possible arguments allowing you to calibrate your model training to a high degree of specificity.\nfrom transformers import TrainingArguments\n\ntraining_args = TrainingArguments(output_dir=\"sst2-bert-fine-tuning\",\n                                  eval_strategy=\"epoch\",\n                                  num_train_epochs=3)\nIn our case, we’ve used the following arguments:\noutput_dir: The output directory where we want our model predictions and checkpoints saved.\neval_strategy=\"epoch\": This ensures that the evaluation is performed at the end of each training epoch. Other possible values are “steps” (meaning that evaluation is done at regular step intervals) and “no” (meaning that evaluation is not done during training).\nnum_train_epochs=3: This sets the number of training epochs (or the number of times the training loop will repeat over all of the data). In this case, it’s set to train on the data three times.\nThe next step is to load in our pre-trained BERT model.\nfrom transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nLet’s break this down step-by-step:\nThe AutoModelForSequenceClassification class does two things. First, it automatically identifies the appropriate model architecture from the Hugging Face model hub given the provided checkpoint string. In our case, this would be the BERT architecture. Second, it converts this model into one we can use for classification. It does this by discarding the weights in the model’s final layer(s) so that we can retrain these using our sentiment analysis dataset.\nThe from_pretrained() method loads in our selected checkpoint, which in this case is bert-base-uncased.\nThe argument num_labels=2 indicates that we have two classes to predict in our model: positive and negative.\nWe get a message telling us that some model weights were not initialized when we ran this code. This message is exactly the one we want – it tells us that the AutoModelForSequenceClassification class reset the final model weights in preparation for our fine-tuning.\nThe last step is to set up our Trainer object. This stage takes in the model, the training arguments, the train and validation datasets, our tokenizer and padding function, and our evaluation function. It uses all of these to train the weights for the head (or final layers) of the BERT model, evaluating the performance of the model after each epoch on the validation set.\nfrom transformers import Trainer\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)\nWe can now kick off the training. The Trainer class gives us a nice timer that tells us both the elapsed time and how much longer the training is estimated to take. We can also see the metrics after each epoch, as we requested when creating the TrainingArguments.\ntrainer.train()\n\n\n\n\nEvaluate the model\nClassification metrics\nBefore we have a look at how our model performed, let’s first discuss the evaluation metrics we used in more detail:\nAccuracy: As mentioned, this is the default evaluation metric for the SST-2 dataset. Accuracy is the simplest metric for evaluating classification models, being the ratio of correct predictions to all predictions. Accuracy is a good choice when the target classes are well balanced, meaning each class has an approximately equal number of instances.\nPrecision: Precision calculates the percentage of the correctly predicted positive observations to the total predicted positives. It is important when the cost of a false positive is high. For example, in spam detection, you would rather miss a spam email (false negative) than have non-spam emails land in your spam folder (false positive).\nRecall (also known as sensitivity): Recall calculates the percentage of the correctly predicted positive observations to all observations in the actual class. It is of interest when the cost of false negatives is high, meaning classifying a positive class incorrectly as negative. For example, in disease diagnosis, you would rather have false alarms (false positives) than miss someone who is actually ill (false negatives).\nF1-score: The F1-score is the harmonic mean of precision and recall. It tries to find the balance between both measures. It is a more reliable metric than accuracy when dealing with imbalanced classes.\nIn our case, we had slightly imbalanced classes, so it’s a good idea to check both accuracy and the F1 score. If they differ, the F1 score is likely to be more trustworthy. However, if they are roughly the same, it is nice to be able to use accuracy, as it is easily interpretable.\nKnowing whether your model is better at predicting one class versus the other is also useful. Depending on your application, capturing all customers who are unhappy with your service may be more important, even if you sometimes get false negatives. In this case, a model with high recall would be a priority over high precision.\nModel predictions\nNow that we’ve trained our model, we need to evaluate it. Normally, we would use the test set to get a final, unbiased evaluation, but the SST-2 test set does not have labels, so we cannot use it for evaluation. In this case, we’ll use the validation set accuracy scores for our final evaluation. We can do this using the following code:\ntrainer.evaluate(eval_dataset=tokenized_datasets[\"validation\"])\n{'eval_loss': 0.4223457872867584,\n 'eval_accuracy': 0.9071100917431193,\n 'eval_f1': 0.9070209502998072,\n 'eval_precision': 0.9074841225920363,\n 'eval_recall': 0.9068472678285763,\n 'eval_runtime': 3.9341,\n 'eval_samples_per_second': 221.649,\n 'eval_steps_per_second': 27.706,\n 'epoch': 3.0}\nWe see that the model has a 90% accuracy on the test set, comparable to other BERT models trained on SST-2. If we wanted to improve our model performance, we could investigate a few things:\nCheck whether the model is overfitting: While small by LLM standards, the BERT model we used for fine-tuning is still very large, and our training set was quite modest. In such cases, overfitting is quite common. To check this, we should compare our validation set metrics with our training set metrics. If the training set metrics are much higher than the validation set metrics, then we have overfit the model. You can adjust a range of parameters during model training to help mitigate this.\nTrain on more epochs: In this example, we only trained the model for three epochs. If the model is not overfitting, continuing to train it for longer may improve its performance.\nCheck where the model has misclassified: We could dig into where the model is classifying correctly and incorrectly to see if we could spot a pattern. This may allow us to spot any issues with ambiguous cases or mislabelled data. Perhaps the fact this is a binary classification problem with no label for “neutral” sentiment means there is a subset of sentences that the model cannot properly classify.\nTo finish our section on evaluating this model, let’s see how it goes with our test sentence. We’ll pass our fine-tuned model and tokenizer to a TextClassificationPipeline, then pass our sentence to this pipeline:\nfrom transformers import TextClassificationPipeline\n\npipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True)\n\npredictions = pipeline(\"I love PyCharm! It's my favourite Python IDE.\")\n\nprint(predictions)\n[[{'label': 'LABEL_0', 'score': 0.0006891043740324676}, {'label': 'LABEL_1', 'score': 0.9993108510971069}]]\nOur model assigns LABEL_0 (negative) a probability of 0.0007 and LABEL_1 (positive) a probability of 0.999, indicating it predicts that the sentence has a positive sentiment with 99% certainty. This result is similar to the one we got from the fine-tuned RoBERTa model we used earlier in the post.\nSentiment analysis benchmarks\nInstead of evaluating the model on only the dataset it was trained on, we could also assess it on other datasets.\nAs you can see from the Papers With Code benchmarking table, you can use a wide variety of labeled datasets to assess the performance of your sentiment classifiers. These datasets include the SST-5 fine-grained classification, IMDB dataset, Yelp binary and fine-grained classification, Amazon review polarity, TweetEval, and the SemEval Aspect-based sentiment analysis dataset.\nWhen evaluating your model, the main thing is to ensure that the datasets represent your problem domain.\nMost of the benchmarking datasets contain either reviews or social media texts, so if your problem is in either of these domains, you may find an existing benchmark that mirrors your business domain closely enough. However, suppose you are applying sentiment analysis to a more specialized problem. In that case, it may be necessary to create your own benchmarks to ensure your model can generalize to your problem domain properly.\nSince there are multiple ways of measuring sentiment, it’s also necessary to make sure that any benchmarks you use to assess your model have the same target as the dataset you trained your model on.\nFor example, it wouldn’t be a fair measure of a model’s performance to fine-tune it on the SST-2 with a binary target, and then test it on the SST-5. As the model has never seen the very positive, very negative, and neutral categories, it will not be able to accurately predict texts with these labels and hence will perform poorly.\nWrapping up\nIn this blog post, we saw how LLMs can be a powerful way of classifying the sentiment expressed in a piece of text and took a hands-on approach to fine-tuning an LLM for this purpose.\nWe saw how understanding which types of models are most suited for sentiment analysis, as well as how being able to see the top performing models on different benchmarks with resources like Papers With Code can help you narrow down your options for which models to use.\nWe also learned how Hugging Face’s powerful tooling for using these models and their integration into PyCharm makes using LLMs for sentiment analysis approachable for anyone with a background in machine learning.\nIf you’d like to continue learning about large language models, check out our guest blog post by Dido Grigorov, who explains how to build a chatbot using the LangChain package.\nGet started with sentiment analysis with PyCharm today\nIf you’re ready to get started on your own sentiment analysis project, you can activate your free three-month subscription of PyCharm. Click on the link below, and enter this promo code: PCSA. You’ll then receive an activation code through your email.\nActivate your free three-month subscription",
        "dc:creator": "Jodie Burchell",
        "content": "Sentiment analysis is a powerful tool for understanding emotions in text. While there are many ways to approach sentiment analysis, including more traditional lexicon-based and machine learning approaches, today we’ll be focusing on one of the most cutting-edge ways of working with text – large language models (LLMs). We’ll explain how you can use these [&#8230;]",
        "contentSnippet": "Sentiment analysis is a powerful tool for understanding emotions in text. While there are many ways to approach sentiment analysis, including more traditional lexicon-based and machine learning approaches, today we’ll be focusing on one of the most cutting-edge ways of working with text – large language models (LLMs). We’ll explain how you can use these […]",
        "guid": "https://blog.jetbrains.com/?post_type=pycharm&p=530781",
        "categories": [
          "data-science",
          "how-tos",
          "ai",
          "llms",
          "machine-learning",
          "python"
        ],
        "isoDate": "2024-12-05T10:49:14.000Z"
      },
      {
        "creator": "Ivan Tiutiundzhi",
        "title": "GreenJinn Took the Strain Off Their Core Tech Team and Achieved a 200% ROI With Datalore",
        "link": "https://blog.jetbrains.com/datalore/2024/12/04/greenjinn-achieved-a-200-roi-with-datalore/",
        "pubDate": "Wed, 04 Dec 2024 10:48:03 +0000",
        "content:encodedSnippet": "Trapped in the insights loop\nAs GreenJinn scaled, its tech and engineering team became overwhelmed with data extraction requests from non-technical teams, including operations, insights, sales, and marketing. These teams relied on the tech department for all their data needs, creating a bottleneck that slowed down operations and disrupted product development.\n\n\n\n    \n“If you’d asked me a few months ago, I would have said we were absolutely stuck. We were in a constant struggle to satisfy insights requests. The tech team was tied up with low-value tasks, like extracting data and making endless revisions, which prevented us from focusing on high-priority product development.”\n\n            \nDaniel Sonny Agliardi\n                                                                Tech Lead at GreenJinn\n                                    \n\n\n\n\nThe insights loop was a repetitive cycle. The operations and insights team would submit data requests, but often, the initial requests were incomplete, leading to multiple follow-ups and delays. This inefficiency meant that the tech team was spending up to 11 hours per week on data extraction tasks, rather than focusing on core development work.\n“We identified our reliance on the tech team for data extraction as the root cause of inefficiencies. The constant need for follow-ups and clarifications made it impossible for us to deliver insights in a timely manner.”\n\n            \nMarco Patrini\n                                                                Operations & Insights Lead at GreenJinn\n                                    \nGreenJinn’s small tech team struggled with technical debt and outdated dashboards, adding further strain on the system. This led to delays, miscommunication, and ultimately slowed decision-making across the company.\nEmpowering Non-Technical Teams With Datalore\nGreenJinn realized they lacked the right tools to allow their non-technical teams to manage data independently, which led to a heavy reliance on the tech team. To address this, they implemented Datalore, a collaborative data science platform that empowered their operations and insights teams to handle data extraction and analysis themselves, reducing the burden on the tech team\n“Datalore gave us the flexibility to handle extraction and analysis without relying on the tech team for every request.”\n\n            \nMarco Patrini\n                                                                Operations & Insights Lead at GreenJinn\n                                    \nWith collaborative SQL and Python notebooks and automated scheduling for reports, Datalore significantly streamlined GreenJinn’s data workflows, enabling more efficient and seamless data management across teams. The platform’s user-friendly interface empowered non-technical staff to access, extract, and analyze data independently, while integrating seamlessly with tools like Google Looker.\nUse case 1: B2B client reporting\nGreenJinn’s client reporting process was previously manual and time-consuming, taking up to two days per report. The operations team relied on the tech team to extract, clean, and set up data for client reports.\nWith Datalore, the operations team automated the entire process, from data extraction to report generation. Using SQL queries and Python code, they were able to pull data into Datalore, analyze it, and generate ready-to-use reports in under half a day. The platform’s flexibility allowed the team to maintain the same report formats while scaling the output by 70% to meet increased client demand without additional resources.\n\n\n\n    \n“We cut delivery times drastically, scaling our reports without any disruptions.”\n\n            \nDaniel Sonny Agliardi\n                                                                Tech Lead at GreenJinn\n                                    \nUse case 2: internal KPIs reporting\nGreenJinn’s internal KPI reporting process was similarly fragmented, with data spread across various spreadsheets and requiring significant manual effort. Datalore allowed the team to consolidate data extraction, analysis, and visualization into a single platform.\nUsing shared SQL and Python notebooks, multiple team members collaborated in real time on KPI analytics. The Report Buildersimplified turning Jupyter notebooks into clean reports, while Metric cells highlighted key KPIs. With interactive visualizations, the team could easily track performance metrics and adjust strategies. Thanks to this real-time data access, GreenJinn improved their KPI achievement by 35%, enabling faster responses to ongoing feedback.\n\n\n\n    \n“We turned our KPI reporting into a streamlined process, which helped us respond faster to internal feedback.”\n\n            \nMarco Patrini\n                                                                Operations & Insights Lead at GreenJinn\n                                    \nResults: 200%+ ROI, efficiency, and scalability\nBy implementing Datalore, GreenJinn achieved a 200%+ return on investment (ROI), thanks to the time saved and enhanced efficiency across internal and client-facing processes.\nThe key results include:\n60% faster insights delivery, reducing report turnaround from 1.5–2 days to under half a day.\n70% increase in client report output, allowing for more reports with the same resources.\n35% improvement in internal KPI achievement, driven by real-time data access and streamlined reporting.\nOne full day per week freed up for the tech team, enabling them to focus on core product development instead of repetitive data tasks.\n“Datalore delivered an impressive 200%+ ROI by freeing up our resources and streamlining both internal and client workflows. The time savings alone have been invaluable.”\n\n            \nDaniel Sonny Agliardi\n                                                                Tech Lead at GreenJinn\n                                    \n“Datalore has transformed how we approach data, empowering our teams and improving efficiency across the board.”\n\n            \nMarco Patrini\n                                                                Operations & Insights Lead at GreenJinn\n                                    \nThe adoption of Datalore has allowed GreenJinn to scale operations, optimize decision-making, and free up valuable resources, leading to substantial business performance improvements and a significant ROI.",
        "dc:creator": "Ivan Tiutiundzhi",
        "content": "Trapped in the insights loop As GreenJinn scaled, its&#160;tech and engineering team&#160;became overwhelmed with data extraction requests from non-technical teams, including operations, insights, sales, and marketing. These teams relied on the tech department for all their data needs, creating a bottleneck that slowed down operations and disrupted product development. The&#160;insights loop&#160;was a repetitive cycle. The [&#8230;]",
        "contentSnippet": "Trapped in the insights loop As GreenJinn scaled, its tech and engineering team became overwhelmed with data extraction requests from non-technical teams, including operations, insights, sales, and marketing. These teams relied on the tech department for all their data needs, creating a bottleneck that slowed down operations and disrupted product development. The insights loop was a repetitive cycle. The […]",
        "guid": "https://blog.jetbrains.com/?post_type=datalore&p=532954",
        "categories": [
          "case-study"
        ],
        "isoDate": "2024-12-04T10:48:03.000Z"
      },
      {
        "creator": "Oleg Zinovyev",
        "title": "Refactoring in C++: Top Techniques and Best Practices",
        "link": "https://blog.jetbrains.com/clion/2024/12/refactoring-in-cpp/",
        "pubDate": "Mon, 02 Dec 2024 13:19:06 +0000",
        "content:encodedSnippet": "Whether you’re a seasoned C++ developer or just starting out, refactoring is a key way you can make your code cleaner, more efficient, and easier to maintain. In this article, we’ll review common refactoring techniques in C++ and explore their benefits, from improving code readability to reducing technical debt. We’ll also look at the main challenges you’ll need to overcome and best practices to follow in order to ensure that you get the most out of refactoring. So, grab a cup of your favorite beverage, make yourself comfortable, and let’s see how you can make your code sparkle!\nWhat is refactoring?\nRefactoring in software development involves reorganizing existing source code to improve it without creating new functionality. It includes various techniques such as renaming variables and methods, deleting unused parameters, extracting functions, and more. Which technique to use in a given situation depends on what you’re trying to achieve, whether fixing performance issues, reducing technical debt, or resolving a combination of several problems.\nRefactoring offers the following main benefits:\nMore readable code: When you simplify tricky parts of code, use clear names for variables and functions, and organize everything logically, your code becomes easier to read.\nEnhanced performance: When you optimize algorithms, enhance data structures, and cut out extra computations, you get faster and more efficient code that uses fewer resources.\nEasier maintenance: When you split large functions and methods into smaller, more manageable ones and remove any redundant code, you make your codebase easier to maintain.\nReduced technical debt: When you clean up code smells, such as duplication and overly complicated logic, you make it easier to avoid problems down the line.\n\n\n\n\nRefactoring can be done manually or automatically. Manual refactoring is when, for example, you search for a specific piece of code in an IDE or a simple code editor and then rewrite that code. This works fine if your codebase is small, or if you need to fix a local problem in a specific block of code. However, most modern production-grade codebases contain hundreds of thousands of lines of code and are difficult to refactor manually.\nAuto-refactoring, on the other hand, is a feature provided by advanced IDEs such as CLion. It allows you to refactor a codebase of any size quickly and on a large scale. Such IDEs free you from manual work, which is invaluable in large real-world projects.\nSpecifics of C++ refactoring\nRefactoring code in C++ is challenging because there are roughly ten different ways to do one thing. The language has complex grammar, elaborate scoping rules, and a wealth of language constructs and features, making it hard to parse correctly. This means that the IDE you use for refactoring must understand all of these language peculiarities and corner cases well enough to be genuinely helpful and ensure it doesn’t introduce new bugs during refactoring.\nEven experienced C++ developers can forget some nuances of the language. A good IDE needs to know C++ inside and out to ensure developers don’t miss something when refactoring their code. This makes auto-refactoring an indispensable IDE feature for every C++ developer.\nCommon refactoring techniques in C++\nCommon C++ refactoring techniques include renaming variables and functions, simplifying conditional statements, extracting functions, and removing code duplication. Below is an overview of several refactoring examples performed in CLion with the CLion Nova engine enabled. To try these techniques as you read, download CLion using the link below.\nDOWNLOAD CLION\nRenaming variables and functions\nChanging the names of variables and functions is a basic refactoring technique that improves code clarity and maintainability. You can apply this refactoring locally, such as in one function, or throughout your project, which can include multiple .cpp and .h files.\nHere are the main advantages of renaming:\nImproved readability: Clear and descriptive names help you and other developers understand the purpose of variables and functions. For example, renaming a data variable to user_data gives more information about the purpose of the variable.\nOngoing accuracy: As code changes, timely renaming aligns names with their actual functionality, making the codebase more intuitive and easier to understand. So, if a function has calculated a user’s payment and now calculates a user’s fee, it’s better to reflect that in the function name.\nCompliance with naming conventions: Different teams and companies use different naming conventions, such as snake_case or camelCase. Renaming variables and functions to conform to these conventions improves consistency throughout the codebase.\n\n\n\n\nAs for renaming in an IDE, the major benefit of this technique is that an IDE updates a symbol – method, function, class, field, etc. – not just text.\nYou can also use a simple code editor to rename variables or functions by search and replace, but it will break code that uses the same names for different symbols in different scopes. This doesn’t happen in an IDE.\nIn the example below, we rename a macro from FMT_RTR to FMT_RETRY in order to improve code readability. Notice how the IDE handles this renaming throughout the project: It changes the name in all the scopes and files the macro is used in.\n\n                        \n\n\nFigure 1: Renaming a macro to improve readability\nExtracting functions\nExtracting a function entails isolating a block of code that performs a specific task – for example, within a function – and creating another function from it. The main reasons for extracting functions are to:\nReduce complexity: By breaking large functions into smaller ones, you improve code readability and make it easier to understand program logic.\nFacilitate testing: When you split your code functionality into separate functions, you can create unit tests for each and improve test coverage. \nSimplify maintenance: Encapsulating functionality into individual functions makes it easier to update code. If you need to modify a particular behavior in your code, you change only the relevant function, leaving the rest of the code untouched.\n\n\n\n\nHere is an example of transforming a block of code that performs various math calculations into a separate function, calculate_basic_operations:\n\n                        \n\n\nFigure 2: Extracting a code block into a separate function\nIn CLion Nova, this refactoring feature is called Extract Method, but functionally speaking, it has the same effect as extracting a function.\nSimplifying conditional statements\nTo make conditional statements simpler, we typically refactor if-else and switch statements. Key benefits of such an approach include:\nImproved logic: Sometimes, changing a sequence of if-else statements makes the logic clearer to new developers unfamiliar with a codebase.\nReduced redundancy: If multiple conditional statements give the same result, it’s better to combine them into a single statement. This helps eliminate duplication and reduce code size.\nEnhanced performance: Eliminating calculations on unnecessary statements speeds up code execution. This technique is particularly useful for performance-critical projects.\n\n\n\n\nHere is how to change the order of if-else statements in CLion using the Invert “if” statement action:\n\n                        \n\n\nFigure 3: Simplifying an if-else statement\nOptimizing loops\nWhen you optimize loops, you usually cut down the number of iterations and simplify internal dependencies. The benefits of this technique are: \nEnhanced performance: Loops, especially nested ones, are common performance sinks. To mitigate this effect, you can reduce loop iterations, simplify conditions, and avoid unnecessary computation.\nImproved readability: Breaking down complex loops into smaller, well-named functions clarifies intent and simplifies management for future developers.\nReduced code duplication: When you extract common functionality into separate methods or functions, you eliminate code repetition, improve maintainability, and reduce the potential for errors. \n\n\n\n\nIn the example below, a for loop is optimized by changing an index-based loop to a more readable range-based loop, removing a redundant else statement, and converting a local variable to a constant:\n\n                        \n\n\nFigure 4: Optimizing a for loop\nRemoving code duplication\nIt takes more work to read and understand the logic of a codebase that is full of duplications. Such a codebase is also harder to maintain and more error-prone.  When you remove code duplication, you are primarily improving the maintainability and readability of the code.\nDevelopers remove code duplication using a variety of approaches, including by:\nIntroducing variables: When you see similar expressions are repeated, for example function calls, you can replace them with a new variable. This will eliminate redundancy and improve code readability. In the case of function calls, it also reduces the number of repetitive calculations. \nUsing inheritance: If similar functionality occurs in different classes, you can turn them into subclasses that share the same behavior with the superclass. These subclasses then inherit the attributes and methods of the superclass. \nExtracting methods: Similar to function extraction, this method isolates duplicate code blocks in a separate method for improved clarity and reusability.\n\n\n\n\nHere is an example of eliminating the repetitive use of the same function by introducing a variable:\n\n                        \n\n\nFigure 5: Introducing a variable\nRefactoring challenges\nWhile refactoring is helpful, it can also be challenging. There are two cases where it is typically required: with complex, difficult-to-understand code and when working in unreliable IDEs.\nComplex code\nWhen working on large, poorly documented projects with thousands of lines of code, it’s hard to refactor them without getting confused. Manual refactoring can be torture: Imagine a developer who has to delete a function parameter used in more than a hundred places in different files. In this case, IDE auto-refactorings are essential.\nUnreliable IDEs\nAn unreliable IDE that performs auto-refactoring incorrectly can introduce new bugs into the code. This puts the burden of refactoring on the developer because these additional bugs have to be caught somehow.\nBut what makes a reliable IDE? A good definition would be one that is capable of parsing every project file without missing anything. A reliable IDE should know all of the features and particularities of C++, so the developer using it doesn’t need to worry about forgetting some of them.\nFor example, if you’re using a “safe delete” feature to delete a function parameter, a reliable IDE will check all project files to ensure nothing is broken after the deletion. If the procedure is unsafe, the IDE will warn you of all the places in your code where the parameter is used and the possible consequences. Here is an example of a warning that CLion provides:\n\n\n\n\nFigure 6: Using the Safe Delete feature in CLion\nIf an IDE can’t parse all parameter usages and allows unsafe deletion, the consequences can be unpredictable. In the best case, a compiler will catch the error. In the worst case, the program will compile but then behave erratically or crash at runtime.\nBest practices for C++ refactoring\nBecause C++ code refactoring is generally challenging, following best practices makes it easier to improve code quality while avoiding unexpected results and bugs. These practices include refactoring in small steps, using a version control system, automating testing, and more.\nRefactoring in small steps \nWhen you make small, incremental changes, it’s easier to debug and track their impact. If a bug appears after refactoring, you can quickly find the problem.\nMinor changes are also easier for teams to review than significant ones. This incremental approach takes less time and fewer resources, so a team can allocate its efforts more effectively while still improving the code.\nUsing a version control system\nThe benefits of using a version control system (VCS) like Git for refactoring are the same as for collaborative development. These include tracking changes, reviewing code, isolating changes, and facilitating testing. VCS clarifies the decisions made and what areas of the code were affected. It helps team members and future developers better understand the rationale behind refactorings.\nIn CLion, you can also use Local History, which tracks all of the changes you make to a project independently of a VCS.\nAutomated testing\nAutomated tests, especially unit tests, verify that code blocks behave as expected after refactoring. Ideally, you should have unit tests for all major code blocks before you refactor. It’s especially important when refactoring large, complex projects, where a small change can affect multiple files and hundreds of lines of code.\nPrioritizing code readability\nImproving code readability is one of the main reasons for refactoring, as it directly impacts code quality and maintainability. Readable code with clear logic and functionality is easier for developers to understand. This is critical when working in teams or when reviewing code later. Therefore, prioritizing code readability during refactoring is essential for developing maintainable and high-quality software.\nWhen and why to refactor your C++ code\nC++ refactoring can help you improve the quality of your code in a variety of situations, from boosting readability to better managing technical debt.\nUnreadable code\nIf you’re spending too much time trying to understand what code does and feel it would be better to rewrite it, you’re dealing with poor code readability. The exact reasons may be one or a combination of the following:\nMeaningless function and variable names\nComplex conditional logic\nRedundant code\nInconsistent formatting\n\n\n\n\nAll of these and other signs that prevent you from understanding code’s logic indicate that it needs to be refactored to make it more readable.\nNon-extensible code\nPoor or non-extensible code is challenging to adapt to new requirements, technologies, and other future changes. There are several indicators of such code. \nFor example, one of the most common problems is tightly coupled components, such as classes, where one class is heavily dependent on another. It’s difficult to add new functionality without untangling all of the dependencies between these classes.\nHard-coded functionality in source code is another common sign of non-extensible code. Examples include various fixed data, such as credentials, timeout values, and out-of-context numeric values (magic numbers) used instead of variables and constants. Code with hard-coded values is difficult to customize, and it’s also easy to add bugs when modifying it.\nPoor testability\nIt’s hard to write tests for code that has excessively long methods and classes, complex conditional logic, tight coupling, and a lack of modularity. This makes it difficult to test a certain functionality and cover the entire codebase with the necessary tests. In the end, it increases the chance that bugs will be missed.\nCode duplication\nThere is a rule of thumb in programming: If you see three pieces of the same code or something repeated three times, you should refactor the code. This also ties in with the DRY (don’t repeat yourself) principle, which helps eliminate redundancy and improve your code quality.\nPerformance issues\nEven though C++ is famed for its excellent performance, it’s still possible to run into performance-related issues. Common reasons for this include the following:\nExcessive memory allocation and deallocation, which can cause slowdowns, especially if there are a lot of complicated loops.\nPassing unnecessary objects by value instead of reference, which can lead to expensive value copying. This becomes critical when working with large objects.\nThe use of inappropriate data structures – for example, linking lists for random access instead of vectors – which can result in significant overheads. \n\n\n\n\nWe generally improve our code performance by doing more low-level optimizations, such as improving CPU and memory consumption. Occasionally, however, the structure of our code prevents us from optimizing it – in these cases, it’s a good idea to refactor our codebase first. Sometimes, we optimize it first and then refactor it to clean it up afterwards.\nTechnical debt\nTechnical debt accumulates gradually through patches, bug fixes, or poor C++ design patterns. It leads to code smells, adds redundancies, reduces performance, and causes other problems. \nYou can’t avoid technical debt, but by regularly refactoring your code, you can mitigate it and ensure that your codebase is more maintainable.\nConclusion\nRegular refactoring of C++ code comes with plenty of perks that boost your code quality and make it easier to maintain. The key gains are improved code readability, maintainability, and performance. If you think your code needs refactoring, try the techniques discussed in this article.\nTo learn more about the C++ refactoring features available with the new CLion Nova language engine, read our documentation. Check out our blog post about the CLion 2024.3 release to explore all the new IDE features and improvements. And feel free to ask questions and give feedback in the comments section below!\nDOWNLOAD CLION",
        "dc:creator": "Oleg Zinovyev",
        "content": "Whether you’re a seasoned C++ developer or just starting out, refactoring is a key way you can make your code cleaner, more efficient, and easier to maintain. In this article, we’ll review common refactoring techniques in C++ and explore their benefits, from improving code readability to reducing technical debt. We’ll also look at the main [&#8230;]",
        "contentSnippet": "Whether you’re a seasoned C++ developer or just starting out, refactoring is a key way you can make your code cleaner, more efficient, and easier to maintain. In this article, we’ll review common refactoring techniques in C++ and explore their benefits, from improving code readability to reducing technical debt. We’ll also look at the main […]",
        "guid": "https://blog.jetbrains.com/?post_type=clion&p=532538",
        "categories": [
          "tips-tricks",
          "clionnova",
          "ide-code-refactoring",
          "refactoring"
        ],
        "isoDate": "2024-12-02T13:19:06.000Z"
      },
      {
        "creator": "Olga Bedrina",
        "title": "Lowering Prices for TeamCity Pipelines | TeamCity Pipelines Pulse, Issue #10",
        "link": "https://blog.jetbrains.com/teamcity/2024/12/lowering-prices-for-teamcity-pipelines/",
        "pubDate": "Mon, 02 Dec 2024 12:30:50 +0000",
        "content:encodedSnippet": "Great news – we’re cutting the cost of TeamCity Pipelines! Now, the prices start from USD 15/month. Check out all the pricing options on our website.\nWhy the change? Because we’re committed to making modern, reliable CI/CD solutions affordable for teams of all sizes. Building and shipping great software shouldn’t break the bank.\nNew UI\nWith this release, we’ve given TeamCity Pipelines a fresh look! The main menu has moved to the left-hand side of the interface, making it easier to navigate and keeping all the important stuff right at your fingertips.\n\n\n\n\nBug fixes and improvements\nWe’ve also fixed some bugs to make your TeamCity Pipelines experience smoother. Here’s what’s new:\nThere’s no longer an issue with pipelines appearing empty when clicking the Edit button.\nSmooth parameters are working as intended for custom JDK paths or Dockerfile paths. You can now define these fields using parameters seamlessly – no more manual adjustments needed!\nThe Maven runner now allows you to specify a custom path for Maven installation in pipeline jobs.\nThat’s it! If you have any questions or comments, feel free to leave them in the comments section below. We’re always happy to hear your feedback.",
        "dc:creator": "Olga Bedrina",
        "content": "Great news – we’re cutting the cost of TeamCity Pipelines! Now, the prices start from USD 15/month. Check out all the pricing options on our website. Why the change? Because we’re committed to making modern, reliable CI/CD solutions affordable for teams of all sizes. Building and shipping great software shouldn’t break the bank. New UI [&#8230;]",
        "contentSnippet": "Great news – we’re cutting the cost of TeamCity Pipelines! Now, the prices start from USD 15/month. Check out all the pricing options on our website. Why the change? Because we’re committed to making modern, reliable CI/CD solutions affordable for teams of all sizes. Building and shipping great software shouldn’t break the bank. New UI […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=532537",
        "categories": [
          "news",
          "releases",
          "release",
          "teamcity-pipelines-pulse"
        ],
        "isoDate": "2024-12-02T12:30:50.000Z"
      },
      {
        "creator": "Cheuk Ting Ho",
        "title": "The State of Data Science 2024: 6 Key Data Science Trends",
        "link": "https://blog.jetbrains.com/pycharm/2024/12/the-state-of-data-science/",
        "pubDate": "Mon, 02 Dec 2024 10:43:37 +0000",
        "content:encodedSnippet": "Generative AI and LLMs have been hot topics this year, but are they affecting trends in data science and machine learning? What new trends in data science are worth following? Every year, JetBrains collaborates with the Python Software Foundation to carry out the Python Developer Survey, which can offer some useful insight into these questions.\nThe results from the latest iteration of the survey, collected between November 2023 and February 2024, included a new Data Science section. This allowed us to get a more complete picture of data science trends over the past year and highlighted how important Python remains in this domain. \n\n\n\n\nWhile 48% of Python developers are involved in data exploration and processing, the percentage of respondents using Python for data analysis dropped from 51% in 2022 to 44% in 2023. The percentage of respondents using Python for machine learning dropped from 36% in 2022 to 34% in 2023. At the same time, 27% of respondents use Python for data engineering, and 8% use it for MLOps – two new categories that were added to the survey in 2023. \n\n\n\n\nLet’s take a closer look at the trends in the survey results to put these numbers into context and get a better sense of what they mean. Read on to learn about the latest developments in the fields of data science and machine learning to prepare yourself for 2025.\nData processing: pandas remains the top choice, but Polars is gaining ground\nData processing is an essential part of data science. pandas, a project that is 15 years old, is still at the top of the list of the most commonly used data processing tools. It is used by 77% of respondents who do data exploration and processing. As a mature project, its API is stable, and many working examples can be found on the internet. It’s no surprise that pandas is still the obvious choice. As a NumFOCUS sponsored project, pandas has proven to the community that it is sustainable and its governance model has gained user trust. It is a great choice for beginners who may still be learning the ropes of data processing, as it’s a stable project that does not undergo rapid changes.\nOn the other hand, Polars, which pitches itself as DataFrames for the new era, has been in the spotlight quite a bit both last year and this year, thanks to the advantages it provides in terms of speed and parallel processing. In 2023, a company led by the creator of Polars, Ritchie Vink, was formed to support the development of the project. This ensures Polars will be able to maintain its rapid pace of development. In July of 2024, version 1.0 of Polars was released. Later, Polars expanded its compatibility with other popular data science tools like Hugging Face and NVIDIA RAPIDS. It also provides a lightweight plotting backend, just like pandas.\nSo, for working professionals in data science, there is an advantage to switching to Polars. As the project matures, it can become a load-bearing tool in your data science workflow and can be used to process more data faster. In the 2023 survey, 10% of respondents said that they are using Polars as their data processing tool. It is not hard to imagine this figure being higher in this year’s survey.\n\n\n\n\nWhether you are a working professional or just starting to process your first dataset, it is important to have an efficient tool at hand that can make your work more enjoyable. With PyCharm, you can inspect your data as interactive tables, which you can scroll, sort, filter, convert to plots, or use to generate heat maps. Moreover, you can get analytics for each column and use AI assistance to explain DataFrames or create visualizations. Apart from pandas and Polars, PyCharm provides this functionality for Hugging Face datasets, NumPy, PyTorch, and TensorFlow.\nTry PyCharm for free\n                                                    \nAn interactive table in PyCharm 2024.2.2 Pro provides tools for inspecting pandas and Polars DataFrames\n\n\n\nThe popularity of Polars has led to the creation of a new project called Narwhals. Independent from pandas and Polars, Narwhals aims to unite the APIs of both tools (and many others). Since it is a very young project (started in February 2024), it hasn’t yet shown up on our list of the most popular data processing tools, but we suspect it may get there in the next few years.\nAlso worth mentioning are Spark (16%) and Dask (7%), which are useful for processing large quantities of data thanks to their parallel processes. These tools require a bit more engineering capability to set up. However, as the amount of data that projects depend on increasingly exceeds what a traditional Python program can handle, these tools will become more important and we may see these figures go up.\nData visualization: Will HoloViz Panel surpass Plotly Dash and Streamlit within the next year?\nData scientists have to be able to create reports and explain their findings to businesses. Various interactive visualization dashboard tools have been developed for working with Python. According to the survey results, the most popular of them is Plotly Dash.\n\n\n\n\nPlotly is most known in the data science community for the ggplot2 library, which is a highly popular visualization library for users of the R language. Ever since Python became popular for data science, Plotly has also provided a Python library, which gives you a similar experience to ggplot2 in Python. In recent years, Dash, a Python framework for building reactive web apps developed by Plotly, has become an obvious choice for those who are used to Plotly and need to build an interactive dashboard. However, Dash’s API requires some basic understanding of the elements used in HTML when designing the layout of an app. For users who have little to no frontend experience, this could be a hurdle they need to overcome before making effective use of Dash.\nSecond place for “best visualization dashboard” goes to Streamlit, which has now joined forces with Snowflake. It doesn’t have as long of a history as Plotly, but it has been gaining a lot of momentum over the past few years because it’s easy to use and comes packaged with a command line tool. Although Streamlit is not as customizable as Plotly, building the layout of the dashboard is quite straightforward, and it supports multipage apps, making it possible to build more complex applications.\nHowever, in the 2024 results these numbers may change a little. There are up-and-coming tools that could catch up to – or even surpass – these apps in popularity. One of them is HoloViz Panel. As one of the libraries in the HoloViz ecosystem, it is sponsored by NumFocus and is gaining traction among the PyData community. Panel lets users generate reports in the HTML format and also works very well with Jupyter Notebook. It offers templates to help new users get started, as well as a great deal of customization options for expert users who want to fine-tune their dashboards.\nML models: scikit-learn is still prominent, while PyTorch is the most popular for deep learning\nBecause generative AI and LLMs have been such hot topics in recent years, you might expect deep learning frameworks and libraries to have completely taken over. However, this isn’t entirely true. There is still a lot of insight that can be extracted from data using traditional statistics-based methods offered by scikit-learn, a well-known machine learning library mostly maintained by researchers. Sponsored by NumFocus since 2020, it remains the most important library in machine learning and data science. SciPy, another Python library that provides support for scientific calculations, is also one of the most used libraries in data science.\n\n\n\n\nHaving said that, we cannot ignore the impact of deep learning and the increase in popularity of deep learning frameworks. PyTorch, a machine learning library created by Meta, is now under the governance of the Linux Foundation. In light of this change, we can expect PyTorch to continue being a load-bearing library in the open-source ecosystem and to maintain its level of active community involvement. As the most used deep learning framework, it is loved by Python users – especially those who are familiar with numpy, since “tensors”, the basic data structures in PyTorch, are very similar to numpy arrays. \nYou can inspect Pytorch tensors in PyCharm 2024.2.2 Pro just like you inspect Numpy arrays\n\n\n\nUnlike TensorFlow, which uses a static computational graph, PyTorch uses a dynamic one – and this makes profiling in Python a blast. To top it all off, PyTorch also provides a profiling API, making it a good choice for research and experimentation. However, if your deep learning project needs to be scalable in deployment and needs to support multiple programming languages, TensorFlow may be a better choice, as it is compatible with many languages, including C++, JavaScript, Python, C#, Ruby, and Swift. Keras is a tool that makes TensorFlow more accessible and is also popular for deep learning frameworks.\nAnother framework we cannot ignore for deep learning is Hugging Face Transformers. Hugging Face is a hub that provides many state-of-the-art pre-trained deep learning models that are popular in the data science and machine learning community, which you can download and train further yourself. Transformers is a library maintained by Hugging Face and the community for state-of-the-art machine learning with PyTorch, TensorFlow, and JAX. We can expect Hugging Face Transformers will gain more users in 2024 due to the popularity of LLMs. \nWith PyCharm you can identify and manage Hugging Face models in a dedicated tool window. PyCharm can also help you to choose the right model for your use case from the large variety of Hugging Face models directly in the IDE. \nOne new library that is worth paying attention to in 2024 is Scikit-LLM, which allows you to tap into Open AI models like ChatGPT and integrate them with scikit-learn. This is very handy when text analysis is needed, and you can perform analysis using models from scikit-learn with the power of modern LLM models.\nMLOps: The future of data science projects\nOne aspect of data science projects that is essential but frequently overlooked is MLOps (machine learning operations). In the workflow of a data science project, data scientists need to manage data, retrain the model, and have version control for all the data and models used. Sometimes, when a machine learning application is deployed in production, performance and usage also need to be observed and monitored.\nIn recent years, MLOps tools designed for data science projects have emerged. One of the issues that has been bothering data scientists and data engineers is versioning the data, which is crucial when your pipeline constantly has data flowing in. \n\n\n\n\nData scientists and engineers also need to track their experiments. Since the machine learning model will be retrained with new data and hyperparameters will be fine-tuned, it’s important to keep track of model training and experiment results. Right now, the most popular tool is TensorBoard. However, this may be changing soon. TensorBoard.dev has been deprecated, which means users are now forced to deploy their own TensorBoard installations locally or share results using the TensorBoard integration with Google Colab. As a result, we may see a drop in the usage of TensorBoard and an uptick in that of other tools like MLflow and PyTorch.\n\n\n\n\nAnother MLOps step that is necessary for ensuring that data projects run smoothly is shipping the development environment for production. The use of Docker containers, a common development practice among software engineers, seems to have been adopted by the data science community. This ensures that the development environment and the production environment remain consistent, which is important for data science projects involving machine learning models that need to be deployed as applications. We can see that Docker is a popular tool among Python users who need to deploy services to the cloud.\n\n\n\n\nThis year, Docker containers is slightly ahead of Anaconda in the “Python installation and upgrade” category.\n2023 survey results\n\n\n\n2022 survey results\n\n\n\nBig data: How much is enough?\nOne common misconception is that we will need more data to train better, more complex models in order to improve prediction. However, this is not the case. Since models can be overfitted, more is not always better in machine learning. Different tools and approaches will be required depending on the use case, the model, and how much data is being handled at the same time.\n\n\n\n\nThe challenge of handling a huge amount of data in Python is that most Python libraries rely on the data being stored in the memory. We could just deploy cloud computing resources with huge amounts of memory, but even this approach has its limitations and would sometimes be slow and costly.\nWhen handling huge amounts of data that are hard to fit in memory, a common solution is to use distributed computing resources. Computation tasks and data are distributed over a cluster to be performed and handled in parallel. This approach makes data science and machine learning operations scalable, and the most popular engine for this is Apache Spark. Spark can be used with PySpark, the Python API library for it.\n\n\n\n\nAs of Spark 2.0, anyone using Spark RDD API is encouraged to switch to Spark SQL, which provides better performance. Spark SQL also makes it easier for data scientists to handle data because it enables SQL queries to be executed. We can expect PySpark to remain the most popular choice in 2024.\nAnother popular tool for managing data in clusters is Databricks. If you are using Databricks to work with your data in clusters, now you can benefit from the powerful integration of Databricks and PyCharm. You can write code for your pipelines and jobs in PyCharm, then deploy, test, and run it in real time on your Databricks cluster without any additional configuration.\nCommunities: Events shifting focus toward data science\nMany newcomers to Python are using it for data science, and thus more Python libraries have been catering to data science use cases. In that same vein, Python events like PyCon and EuroPython are beginning to include more tracks, talks, and workshops that focus on data science, while events that are specific to data science, like PyData and SciPy, remain popular, as well.\nFinal thoughts\nData science and machine learning are becoming increasingly active, and together with the popularity of AI and LLMs, more and more new open source tools have become available for use in data science. The landscape of data science continues to change rapidly, and we are excited to see what becomes most popular in the 2024 survey results.\nEnhance your data science experience with PyCharm\nModern data science demands skills for a wide range of tasks, including data processing and visualization, coding, model deployment, and managing large datasets. As an integrated development environment (IDE), PyCharm helps you efficiently build this skill set. It provides intelligent coding assistance, top-tier debugging, version control, integrated database management, and seamless Docker integration. For data science, PyCharm supports Jupyter notebooks, as well as key scientific and machine learning libraries, and it integrates with tools like the Hugging Face models library, Anaconda, and Databricks.\nStart using PyCharm for your data science projects today and enjoy its latest improvements, including features for inspecting pandas and Polars DataFrames, and for the layer by layer inspection of PyTorch tensors, which is handy when exploring data and building deep learning models.\nTry PyCharm for free",
        "dc:creator": "Cheuk Ting Ho",
        "content": "Generative AI and LLMs have been hot topics this year, but are they affecting trends in data science and machine learning? What new trends in data science are worth following? Every year, JetBrains collaborates with the Python Software Foundation to carry out the Python Developer Survey, which can offer some useful insight into these questions. [&#8230;]",
        "contentSnippet": "Generative AI and LLMs have been hot topics this year, but are they affecting trends in data science and machine learning? What new trends in data science are worth following? Every year, JetBrains collaborates with the Python Software Foundation to carry out the Python Developer Survey, which can offer some useful insight into these questions. […]",
        "guid": "https://blog.jetbrains.com/?post_type=pycharm&p=531370",
        "categories": [
          "data-science",
          "survey",
          "trends"
        ],
        "isoDate": "2024-12-02T10:43:37.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": [
      {
        "creator": "Lauren Mackevich",
        "title": "My Journey To Airbnb | Vijaya Kaza",
        "link": "https://medium.com/airbnb-engineering/my-journey-to-airbnb-vijaya-kaza-8f06543b38d5?source=rss----53c7c27702d5---4",
        "pubDate": "Thu, 05 Dec 2024 18:36:44 GMT",
        "content:encodedSnippet": "Vijaya Kaza is the Chief Security Officer and Head of Engineering for Trust and Safety at Airbnb. She leads teams responsible for developing the technology (Platforms, tools and AI models), to safeguard the Airbnb community, as well as for securing Airbnb’s infrastructure and information assets. She is also the executive co-sponsor of Airbnb Tech’s Diversity Council.\nHere’s Vijaya’s story of how she got to Airbnb, in her own words.\nStraight shot to science and engineering\nI grew up in a modest, multi-generational family in India with 30 to 40 family members under one roof on any given day. As the oldest child in that house, I was expected to excel academically and set an example for the other children to follow.\nIn our culture back then, being “good at school” was synonymous with shining in science and math. As luck would have it, I had a strong affinity for those subjects and enjoyed studying and diving deep into them. I followed a natural path that combined math and science, studying engineering in college, and got a bachelor’s and two master’s in electrical engineering. This foundation paved the way for my future work in technology.\nStumbling into cybersecurity\nAfter college, I landed my first job as a Software Engineer at Cisco. However, my entry into the security field was accidental. I simply followed a manager I liked who was moving into a new security business unit, fell in love with Security and never looked back after that! There was no grand plan or calculated career strategy.\nAfter 17 years at Cisco leading product development for a $1B security product portfolio, I headed to FireEye, another well-known name in the Cybersecurity space. There I had the responsibility for helping the company transition from on-prem to a cloud/SaaS business model, and growing the revenue of their cloud security portfolio. That role gave me the experience of working on different areas of security, as well as leading both Product Management and Engineering in a General Manager capacity.\nNext, I led Product Development at Lookout, a startup in San Francisco focused on mobile security. At the time, it was a consumer security company pivoting to building for enterprise customers. I didn’t know it then, but that glimpse of consumer security was a great primer for my eventual role at Airbnb.\nCybersecurity is an ever-changing domain with constant innovation and I’ve thoroughly enjoyed working and learning in such a dynamic space. Each major technological transformation — from cloud to mobile to AI — brings novel security challenges to solve for businesses and end users.\n\nAn unexpected opportunity at Airbnb\nWhen I was initially approached for the Chief Security Officer (CSO) role at Airbnb, I was taken aback. I had always worked in the field doing engineering and product development work, so I wasn’t sure about this role. But after meeting Ari Balogh, Airbnb’s Chief Technology Officer (CTO) for an informal coffee chat, we really hit it off and I was thoroughly impressed by his vision to transform the engineering and technology organization within the company. Ari shared his philosophy of focusing on the craft of engineering and that really resonated with me. The prospect of molding Airbnb’s engineering culture was very enticing.\nTurns out Airbnb was also looking for someone to lead engineering for its Trust and Safety organization. Given my background with a blend of engineering and security domain expertise, I ended up taking on both of these roles. This unique opportunity allowed me to go back to my roots leading engineering teams while taking advantage of my security experience in the capacity of a CSO.\nWhen I joined the company in 2019, I was struck by Airbnb’s dedication and effort to deliver a positive user experience. Our attention and design focus that go into helping guests and hosts have a seamless experience is unlike anything I’ve experienced before.\nWhy Airbnb?\nI joined Airbnb because of the opportunity to have an outsized impact — Airbnb’s almost 6,000 employees serve millions of people worldwide. Our mission-driven approach, powered by our founders’ unmatched passion and commitment to doing good through initiatives like Airbnb.org really resonated with me. I’ve been continuously impressed by the caliber of talented, caring people here who are united by Airbnb’s vision. It’s rare to find a company that so effectively combines technical excellence with social consciousness.\nTwo teams, one mission\nWhile both the Trust and Safety and Security teams share the common mission of safeguarding users and the platform, the actual techniques, threats, and focus areas are completely different. Trust is at the core of our business and we’re deeply focused on providing our guests and hosts peace of mind as they live, work, travel and host on Airbnb. We build technology to help lower safety and privacy risks for our community.\nFor example, our innovative reservation screening technology aims to help reduce the risk of disruptive parties on Airbnb globally by taking steps to identify higher-risk reservations and potentially prevent these bookings from being made.\nOn the cybersecurity front, we focus on securing Airbnb’s assets, our data, our employees, and our infrastructure. We implement robust security controls and threat detection capabilities to safeguard Airbnb’s internal resources.\nEmbracing the improv mindset\nOutside of work, I’ve pursued some hobbies that have surprisingly imparted invaluable leadership lessons. A few years ago, I decided to try improv comedy, something that’s entirely outside my wheelhouse. I had never done anything close to theater or acting in my entire life. What started as a fun experiment quickly became a passion project and I progressed through the levels and eventually performed live in front of an audience with friends and family in attendance.\nIt may seem unrelated at first, but the very nature of improv is profoundly relevant for leadership. You’re constantly put on the spot and need to think on your feet, responding to new questions and scenarios in the moment. Improv trains this vital skill of processing information in real time and formulating a coherent, compelling reaction.\nKeep a steady head\nOver any career, including mine, there are inevitable professional setbacks, disappointments, and annoyances along the way. The key is to not make much of these short-term hurdles; it’s how you respond that matters most. The less you agonize over the bumps in the road, the better. Maintain your focus, keep one foot in front of the other, and persist forward undeterred. I learned these lessons early, having taken on leadership roles from a young age as the eldest child in a large household. My advice is to keep a steady head, maintain perspective, and plow forward with conviction.\nWe’re currently expanding the Airbnb team and hiring for several roles. Check out our open positions here.\n\nMy Journey To Airbnb | Vijaya Kaza was originally published in The Airbnb Tech Blog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Lauren Mackevich",
        "guid": "https://medium.com/p/8f06543b38d5",
        "categories": [
          "engineering",
          "people",
          "technology",
          "leadership",
          "cybersecurity"
        ],
        "isoDate": "2024-12-05T18:36:44.000Z"
      }
    ]
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Rhea Patel",
        "title": "Introducing Code Referencing for GitHub Copilot Chat in Visual Studio",
        "link": "https://devblogs.microsoft.com/visualstudio/introducing-code-referencing-for-github-copilot-chat-in-visual-studio/",
        "pubDate": "Thu, 05 Dec 2024 16:00:15 +0000",
        "content:encodedSnippet": "Are you tired of the uncertainty that comes with using code suggestions from AI tools? We’ve got exciting news for you! Visual Studio 2022 now includes code referencing in GitHub Copilot, ensuring greater transparency and control for developers.\nWe are thrilled to announce that code referencing is now available in GitHub Copilot Chat within Visual Studio. This new feature introduces a filter that detects when code suggestions match public code on GitHub, providing you with valuable context to make more informed decisions about the code you incorporate into your projects.\nMake Informed Decisions with Code Suggestions\nIn the rare instances where GitHub Copilot suggests code that matches public repositories on GitHub, this feature displays a list of those repositories along with their licenses directly in the editor. This transparency empowers you to:\nLearn from existing implementations: Gain insights from how others have tackled similar problems.\nConsider dependencies: Decide whether to use an existing library instead of writing new code.\nAcknowledge similar work: Give or receive credit for comparable code within the community.\nHow It Works\nWhen GitHub Copilot suggests code that matches public code, it now lets you know of this match. You can view the matching code, its source file, and any associated licensing information directly within Visual Studio. This allows you to make more informed decisions about whether to use the suggested code.\nIf a match is found, a notification appears in the editor showing:\nThe matching code snippet\nRepositories where the code appears\nThe licenses governing each repository\nYou have the option to block suggestions containing matching code or allow them with full awareness of their context.\nIn Copilot Chat it will show like this\n\nInstead of this:\n\nTry It Out Today\nWe believe this new code referencing feature enhances your development experience by adding an extra layer of transparency and choice. Try it out in Visual Studio 17.12 Preview 3 and above, and let us know your feedback. Your insights help us improve and tailor our tools to better meet your needs.\nConfiguration Note\nPlease note that this feature may need to be configured by your administrator. To ensure its enabled for you, check your settings:\nCopilot – Suggestions matching public code (duplication detection filter): Allowed\nGitHub Copilot can provide you with details about matching code when you accept such suggestions. Learn more.\nEnabling or Disabling Suggestions Matching Public Code\nNote: If you are a member of an organization on GitHub Enterprise Cloud and have been assigned a GitHub Copilot seat through your organization, you may not be able to configure suggestions matching public code in your personal account settings. Your settings will be inherited from your organization or enterprise.\nYour personal settings for GitHub Copilot include an option to either allow or block code suggestions that match publicly available code:\nBlock suggestions matching public code: GitHub Copilot checks code suggestions with their surrounding code against public code on GitHub. If there’s a match or near match, the suggestion is not shown.\nAllow suggestions matching public code: When Copilot suggests matching code, you can view details of the matches and navigate to the relevant repositories on GitHub.\nTo adjust your settings:\nIn the upper-right corner of any page on GitHub, click your profile photo, then click Your Copilot.\nNext to Suggestions matching public code, use the dropdown menu to select Allow or Block.\nFor more information, see Managing Copilot policies as an individual subscriber.\nDevelopers often face the challenge of not knowing the origins of code suggestions offered by AI tools. This can lead to concerns about licensing and the appropriateness of using certain code snippets. With the new code referencing feature in GitHub Copilot, those worries are outdated.\nFostering knowledge sharing\nBy integrating code referencing into GitHub Copilot, we are fostering a culture of knowledge sharing and transparency. This feature not only empowers individual developers but also supports larger teams in navigating the complexities of public code with ease.\nThe post Introducing Code Referencing for GitHub Copilot Chat in Visual Studio appeared first on Visual Studio Blog.",
        "dc:creator": "Rhea Patel",
        "content": "<p>Are you tired of the uncertainty that comes with using code suggestions from AI tools? We&#8217;ve got exciting news for you! Visual Studio 2022 now includes code referencing in GitHub Copilot, ensuring greater transparency and control for developers. We are thrilled to announce that code referencing is now available in GitHub Copilot Chat within Visual [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/introducing-code-referencing-for-github-copilot-chat-in-visual-studio/\">Introducing Code Referencing for GitHub Copilot Chat in Visual Studio</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Are you tired of the uncertainty that comes with using code suggestions from AI tools? We’ve got exciting news for you! Visual Studio 2022 now includes code referencing in GitHub Copilot, ensuring greater transparency and control for developers. We are thrilled to announce that code referencing is now available in GitHub Copilot Chat within Visual […]\nThe post Introducing Code Referencing for GitHub Copilot Chat in Visual Studio appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251641",
        "categories": [
          "GitHub Copilot",
          "Visual Studio"
        ],
        "isoDate": "2024-12-05T16:00:15.000Z"
      },
      {
        "creator": "Harshada Hole",
        "title": "How Inline Return Values Simplify Debugging in Visual Studio 2022",
        "link": "https://devblogs.microsoft.com/visualstudio/how-inline-return-values-simplify-debugging-in-visual-studio-2022/",
        "pubDate": "Wed, 04 Dec 2024 16:00:35 +0000",
        "content:encodedSnippet": "Have you ever found yourself creating temporary variables just to inspect return values from functions? It’s a small task that can quickly become tedious, breaking your rhythm and cluttering up your code. Visual Studio 2022 introduces a smarter way to handle this with “Inline Return Values,” allowing you to stay focused on coding without the extra steps.\n\n\nThis new feature allows you to view return values directly in your code, right where you need them. With Copilot integration, you can go a step further by analyzing the return values in real time. It simplifies understanding and verifying your code’s behavior, cutting out unnecessary steps. Whether you’re working with native or managed code, this feature is designed to enhance your workflow, providing a seamless, intuitive debugging experience tailored to your needs.\nHow It Works\nPreviously you might have used the return values shown in the Autos / Locals windows. These values would appear after the function has exited and returned to the caller. Inline return values show this information before the function exits and directly in the editor. And with Copilot integration, you can now receive explanations and solutions without ever leaving your code.\nWhen you hit a breakpoint or step through your code, Visual Studio 2022 automatically displays “the value which will be returned inline, right next to the closing brace of the method. This provides immediate, clear feedback, making it easy to spot issues and verify that your functions are returning the expected results. \nTo explore the return values further, simply hover over the inline display and click “Ask Copilot” icon on the datatip. A new Copilot chat window will open, and the debugger will gather relevant context and pass it to Copilot for analysis. Copilot will not only explain why you’re seeing those values, but also provide insights into potential issues. If necessary, it can even suggest code fixes to ensure the correct return values, streamlining your debugging process.\nYou will experience similar Copilot-assisted variable analysis capabilities for Locals, Autos, Watch windows, and DataTips as well , learn more here : AI-Powered Insights: Streamlining Variable Analysis with GitHub Copilot in Visual Studio – Visual Studio Blog\nTell us what you think!\nWe hope the inline return values feature enhances your debugging experience! As we continue to develop seamless inline data inspection, your feedback is invaluable. Consider completing our quick survey to help us improve this feature.\nIf you have comments or questions about this or any other Visual Studio features, please use the Report a Problem tool. Stay connected with the Visual Studio team by following us on Twitter @VS_Debugger, Twitter @VisualStudio, YouTube, and LinkedIn.\nThe post How Inline Return Values Simplify Debugging in Visual Studio 2022 appeared first on Visual Studio Blog.",
        "dc:creator": "Harshada Hole",
        "content": "<p>Have you ever found yourself creating temporary variables just to inspect return values from functions? It’s a small task that can quickly become tedious, breaking your rhythm and cluttering up your code. Visual Studio 2022 introduces a smarter way to handle this with &#8220;Inline Return Values,&#8221; allowing you to stay focused on coding without the [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/how-inline-return-values-simplify-debugging-in-visual-studio-2022/\">How Inline Return Values Simplify Debugging in Visual Studio 2022</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Have you ever found yourself creating temporary variables just to inspect return values from functions? It’s a small task that can quickly become tedious, breaking your rhythm and cluttering up your code. Visual Studio 2022 introduces a smarter way to handle this with “Inline Return Values,” allowing you to stay focused on coding without the […]\nThe post How Inline Return Values Simplify Debugging in Visual Studio 2022 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251636",
        "categories": [
          "Debug",
          "GitHub Copilot",
          "Visual Studio",
          "Debugging and Diagnostics",
          "Developer Productivity"
        ],
        "isoDate": "2024-12-04T16:00:35.000Z"
      },
      {
        "creator": "Jullyana Ramos",
        "title": "Introducing the Copy Git Permalink Feature in Visual Studio 17.12",
        "link": "https://devblogs.microsoft.com/visualstudio/introducing-the-copy-git-permalink-feature-in-visual-studio-17-12/",
        "pubDate": "Tue, 03 Dec 2024 14:05:05 +0000",
        "content:encodedSnippet": "We are excited to announce the release of the Copy Git Permalink feature in Visual Studio 17.12. This new functionality streamlines the process of sharing code references, enhancing collaboration and ensuring that critical context is preserved.\n\nEffortless Code Sharing\nIf you’ve found yourself needing to share code snippets with colleagues, you know the challenges of preserving context. With the new Copy Git Permalink feature, you can now generate a permalink directly from Visual Studio to the remote repository. Simply select the desired code, right-click, and choose the “Copy Permalink” option under the Git submenu. Then, your colleague can open the link you shared to get to that line of code on the web, providing them with the surrounding code without disrupting their local environment.\nThis feature supports both Azure DevOps repositories and GitHub (requires sign-in). If you’d like the ability to extend the support for your own favorite Git hosting provider, please upvote this Visual Studio Extensibility suggestion ticket.\nBest Practices for Accuracy\nTo ensure that your permalink reflects the latest code, remember to commit and push your changes before generating the link. Visual Studio will automatically find the most recent commit on the web if your changes haven’t been pushed recently.\nTo include line and column numbers in your permalink, make sure the text of interest is selected.\nHistorical Code Reference\nThe Copy Git Permalink option is also available within the embedded commit details view in the Git Repository window. This allows you to reference specific code from previous commits without switching branches.\n\nFrom Marketplace to Product\nThis started as a hackathon project of a Visual Studio engineer, Etienne Baudoux, which turned into the popular Copy Git Link extension. The productivity gains experienced by internal Microsoft adopters and the votes received in a related suggestion ticket made it clear that an in-box alternative to this extension would be appreciated.\nConclusion\nWe encourage you to explore the new Copy Git Permalink feature and share your feedback with us. We are committed to enhancing your development experience and look forward to hear your thoughts.\nThe post Introducing the Copy Git Permalink Feature in Visual Studio 17.12 appeared first on Visual Studio Blog.",
        "dc:creator": "Jullyana Ramos",
        "content": "<p>We are excited to announce the release of the Copy Git Permalink feature in Visual Studio 17.12. This new functionality streamlines the process of sharing code references, enhancing collaboration and ensuring that critical context is preserved. Effortless Code Sharing If you’ve found yourself needing to share code snippets with colleagues, you know the challenges of [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/introducing-the-copy-git-permalink-feature-in-visual-studio-17-12/\">Introducing the Copy Git Permalink Feature in Visual Studio 17.12</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "We are excited to announce the release of the Copy Git Permalink feature in Visual Studio 17.12. This new functionality streamlines the process of sharing code references, enhancing collaboration and ensuring that critical context is preserved. Effortless Code Sharing If you’ve found yourself needing to share code snippets with colleagues, you know the challenges of […]\nThe post Introducing the Copy Git Permalink Feature in Visual Studio 17.12 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251631",
        "categories": [
          "Git",
          "Visual Studio"
        ],
        "isoDate": "2024-12-03T14:05:05.000Z"
      },
      {
        "creator": "Harshada Hole",
        "title": "AI-Powered Insights: Streamlining Variable Analysis with GitHub Copilot in Visual Studio",
        "link": "https://devblogs.microsoft.com/visualstudio/ai-powered-insights-streamlining-variable-analysis-with-github-copilot-in-visual-studio/",
        "pubDate": "Mon, 02 Dec 2024 14:44:07 +0000",
        "content:encodedSnippet": "Tired of spending countless hours troubleshooting errors and unexpected values in your code? Visual Studio 2022 introduces GitHub Copilot Variable Analysis. This powerful tool makes inspecting and analyzing variables from Locals, Autos, watch windows and DataTips effortless, helping you solve issues faster and cutting down on time and frustration.\nEnhanced Debugging Experience\nDebugging can often resemble searching for a needle in a haystack, especially in complex codebases. But GitHub Copilot Variable Analysis can make the debugging experience much easier and smoother. Simply hover over any variable in the Locals, Autos, Watch, or DataTips windows to reveal the Copilot icon. Clicking this icon launches an interactive chat within Visual Studio, delivering detailed, AI-driven insights about the variable’s values and how they affect your code’s execution.\n\n\nThis feature is also accessible via the right-click context menu for added convenience.\nHow It Works\nWhen you click the Copilot icon next to a variable, GitHub Copilot analyzes its value and delivers comprehensive insights. The debugger supplies necessary references, allowing Copilot to evaluate the code and offer relevant insights for understanding variable behavior or specific values.\nWhen relevant, Copilot also offers code solutions. To incorporate a suggested solution, simply click the preview button in the chat, which will insert the code directly into the editor. If the code aligns with your requirements, you can accept it and continue debugging.\n\nThe Benefits of Real-Time Analysis\nVariable Analysis is a standout feature of GitHub Copilot, enabling real-time evaluation of variables. When unexpected values arise, you can quickly access detailed information, significantly improving your troubleshooting speed. This seamless integration within the IDE reduces the need for internet searches or context switching, allowing you to concentrate on resolving issues.\nFurthermore, GitHub Copilot empowers you to make informed decisions rapidly. Whether addressing errors or understanding variable behavior, you receive instant feedback without disrupting your workflow.\nThank you for your feedback\nWe believe that the continuous feedback from our users is what makes Visual Studio better with every release. We appreciate your input and are committed to incorporating your suggestions to improve your development experience. Thank you for helping us make Visual Studio the best IDE for developers worldwide.\nThe post AI-Powered Insights: Streamlining Variable Analysis with GitHub Copilot in Visual Studio appeared first on Visual Studio Blog.",
        "dc:creator": "Harshada Hole",
        "content": "<p>Tired of spending countless hours troubleshooting errors and unexpected values in your code? Visual Studio 2022 introduces GitHub Copilot Variable Analysis. This powerful tool makes inspecting and analyzing variables from Locals, Autos, watch windows and DataTips effortless, helping you solve issues faster and cutting down on time and frustration. Enhanced Debugging Experience Debugging can often [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/ai-powered-insights-streamlining-variable-analysis-with-github-copilot-in-visual-studio/\">AI-Powered Insights: Streamlining Variable Analysis with GitHub Copilot in Visual Studio</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Tired of spending countless hours troubleshooting errors and unexpected values in your code? Visual Studio 2022 introduces GitHub Copilot Variable Analysis. This powerful tool makes inspecting and analyzing variables from Locals, Autos, watch windows and DataTips effortless, helping you solve issues faster and cutting down on time and frustration. Enhanced Debugging Experience Debugging can often […]\nThe post AI-Powered Insights: Streamlining Variable Analysis with GitHub Copilot in Visual Studio appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251626",
        "categories": [
          "Debug",
          "GitHub Copilot",
          "Visual Studio",
          "Debugging and Diagnostics",
          "Developer Productivity"
        ],
        "isoDate": "2024-12-02T14:44:07.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": [
      {
        "title": "벡터데이터베이스 기반 간단한 PDF, Web 기반 검색 전문 에이전트 만들기",
        "link": "http://daddynkidsmakers.blogspot.com/2024/12/pdf-web.html",
        "pubDate": "2024-12-07T08:52:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">이 글은&nbsp;벡터데이터베이스 기반 간단한 PDF, Web 기반 검색 전문 에이전트 만드는 방법을 정리한 것이다. 이 글은 LangChain을 사용한다. lanchain은 급속히 버전과 함수가 개선되고 있어 API가 자주 변경되는 경향이 있다(Deprecated error). 이런 이유로, 현지 시점에서 관련 에이전트를 만드는 주요 코드를 남긴다.&nbsp;</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhrwUKukG1vNC6VO5Q7CBYRv328pGfWlLPqQ2kZTn3MGUb2Hi3Tt6AMuMTWCgihnRMd8pmaOnyMsgohtgmx7EuFbvuemhA0BeTT1Ar7qt7qzWPGAOYnvVCcH6RE_DzK1GmLL7RYtOdP0-EivlnuP1ZTebqg3sZb1XpwVzSDXAHZD_2nvaXl-RsusQlprmOJ\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"610\" data-original-width=\"1035\" height=\"236\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhrwUKukG1vNC6VO5Q7CBYRv328pGfWlLPqQ2kZTn3MGUb2Hi3Tt6AMuMTWCgihnRMd8pmaOnyMsgohtgmx7EuFbvuemhA0BeTT1Ar7qt7qzWPGAOYnvVCcH6RE_DzK1GmLL7RYtOdP0-EivlnuP1ZTebqg3sZb1XpwVzSDXAHZD_2nvaXl-RsusQlprmOJ=w400-h236\" width=\"400\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">에이전트 예시(<a href=\"https://discuss.streamlit.io/t/langchain-tutorial-5-build-an-ask-the-data-app/47672\" style=\"text-align: left;\">Build Ask Data app - Streamlit</a>)</div><div class=\"separator\" style=\"clear: both; text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEj3araWZEqoYX8kek2SYNSQyY6ufSjqaM_FZf2Im-u-1O-j7ODINEVDK_5TXEo-qzEgsXZaGAh5oKNTLuAnueT16_YA-RLgh4a2i_ik19iX3_tCncRNk8oUdTudCkRuwGJHKa8owOoIIDkKqzXQE0JbE6jOX-b1DtAS3rtDlNnHZ0G-4_muNzx860Mlop9s\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"305\" data-original-width=\"812\" height=\"192\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEj3araWZEqoYX8kek2SYNSQyY6ufSjqaM_FZf2Im-u-1O-j7ODINEVDK_5TXEo-qzEgsXZaGAh5oKNTLuAnueT16_YA-RLgh4a2i_ik19iX3_tCncRNk8oUdTudCkRuwGJHKa8owOoIIDkKqzXQE0JbE6jOX-b1DtAS3rtDlNnHZ0G-4_muNzx860Mlop9s=w512-h192\" width=\"512\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">에이전트 예시(<a href=\"https://github.com/langchain-ai/langchain/blob/master/cookbook/local_rag_agents_intel_cpu.ipynb\">Local_RAG_Agents_Intel_cpu</a>)</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">LangChain 설명 및 사용법은 앞의 블로그 내용(검색)을 참고한다. 다음 같은 순서로 LLM이 사용된다는 것만 이해하고 있으면 코드 사용에 큰 어려움은 없을 것이다.&nbsp;</div><div style=\"text-align: left;\"><br /></div></div></div><blockquote style=\"border: none; margin: 0 0 0 40px; padding: 0px;\"><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><div style=\"text-align: left;\"><b><span style=\"color: #0b5394;\">사용자 입력 &gt; 컨텐츠 검색 입력 &gt; 에이전트 도구에서 데이터 입력 &gt; 과거 메모리 내용 입력 &gt; 프롬프트 생성 &gt; LLM 전달 &gt; 추론 내용 출력</span></b></div></div></div></blockquote><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><div style=\"text-align: left;\"><br /></div></div></div><div style=\"text-align: left;\"><b><span style=\"font-size: medium;\">설치</span>&nbsp;</b></div><div style=\"text-align: left;\">파이썬, 아나콘다가 준비되어 있다는 가정에서, 라이브러리 설치는 다음과 같다.&nbsp;</div><div style=\"text-align: left;\">pip install --upgrade openai langchain-openai langchain langchain-experimental</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">이 글은 <a href=\"https://platform.openai.com/api-keys\">OpenAI API Key</a>, <a href=\"https://app.tavily.com/home\">Tavily API Key</a>를 신청해 가지고 있다고 가정한다. 실행 시 로그나 성능을 확인하고자 한다면, <a href=\"https://smith.langchain.com/o/2c462eb1-5b83-41c8-96c5-e008809d5655/settings\">Langsmith</a>에 가입한다. 각 API는 해당 웹사이트에서 가입하여 얻을 수 있다. 각 사이트에서 생성한 API키는 .env 파일을 생성해 다음과 같이 입력해 놓는다.</div><div style=\"text-align: left;\"><div>OPENAI_API_KEY=&lt;OpenAI API Key&gt;</div><div>LANGCHAIN_TRACING_V2=false</div><div>LANGCHAIN_ENDPOINT=https://api.smith.langchain.com</div><div>LANGCHAIN_API_KEY=&lt;Langsmith API Key&gt;</div><div>LANGCHAIN_PROJECT=AGENT TUTORIAL</div><div><br /></div></div><div style=\"text-align: left;\"><b><span style=\"font-size: medium;\">코딩</span></b></div><div style=\"text-align: left;\">다음과 같이 코딩한다. 우선 필요한 라이브러리를 임포트한다.</div><div style=\"text-align: left;\"><div>import os, getpass</div><div>from openai import OpenAI&nbsp;&nbsp;</div><div>from dotenv import load_dotenv</div><div>from langchain_community.tools.tavily_search import TavilySearchResults</div><div>from langchain.text_splitter import RecursiveCharacterTextSplitter</div><div>from langchain_community.vectorstores import FAISS</div><div>from langchain_openai import OpenAIEmbeddings</div><div>from langchain.agents import create_openai_functions_agent</div><div>from langchain_community.document_loaders import PyPDFLoader</div><div>from langchain.tools.retriever import create_retriever_tool</div><div>from langchain.agents import AgentExecutor</div><div>from langchain_openai import ChatOpenAI</div><div>from langchain import hub</div><div><br /></div><div>os.environ[\"TAVILY_API_KEY\"] = \"input your key\"</div><div>os.environ[\"LANGCHAIN_PROJECT\"] = \"AGENT TUTORIAL\"</div><div>load_dotenv()</div><div>client = OpenAI(api_key=\"input your key\")</div><div><br /></div><div># Travily의 웹 검색 객체 획득</div><div>web_search = TavilySearchResults(k=5)&nbsp;</div><div><br /></div><div># PDF 데이터를 벡터DB에 청크로 저장하고, 문서 검색 객체를 획득</div><div>loader = PyPDFLoader(\"./202212_LiDAR.pdf\")&nbsp; # 적절한 PDF 입력</div><div>text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)</div><div>split_docs = loader.load_and_split(text_splitter)</div><div><br /></div><div>embeddings = OpenAIEmbeddings(api_key=os.environ[\"OPENAI_API_KEY\"])</div><div>vector = FAISS.from_documents(split_docs, embeddings)</div><div>vectordb_retriever = vector.as_retriever()</div><div>output = vectordb_retriever.get_relevant_documents(</div><div>&nbsp; &nbsp; \"PCL(Point Cloud Library) 라이브러리에 대해 설명해줘\"</div><div>)[0]</div><div>print(output)&nbsp; # PCL 검색 예시</div><div><br /></div><div>pdf_retriever_tool = create_retriever_tool(</div><div>&nbsp; &nbsp; vectordb_retriever,</div><div>&nbsp; &nbsp; name=\"pdf_search\",</div><div>&nbsp; &nbsp; description=\"2023년 12월 PCL(Point Cloud Library) 정보를 PDF 문서에서 검색합니다. '2023년 12월 라이다 포인트 클라우드 처리 기술' 과 관련된 질문은 이 도구를 사용해야 합니다!\",</div><div>) # 문서 검색 객체</div><div><br /></div><div># 에이전트 도구들 설정</div><div>tools = [web_search, pdf_retriever_tool]</div><div><br /></div><div># LLM 객체 설정</div><div>llm = ChatOpenAI(model=\"gpt-4-turbo-preview\", temperature=0)</div><div><br /></div><div># 프롬프트 설정</div><div>prompt = hub.pull(\"hwchase17/openai-functions-agent\")</div><div>print(prompt.messages)</div><div><br /></div><div># LLM 함수 호출 에이전트 설정</div><div>agent = create_openai_functions_agent(llm, tools, prompt)</div><div>agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)</div><div><br /></div><div># 전문가 에이전트 질문 수행</div><div>response = agent_executor.invoke(</div><div>&nbsp; &nbsp; {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; \"input\": \"2010년부터 PCL 라이브러리 기술에 대한 대한 내용을 PDF 문서에서 알려줘\"</div><div>&nbsp; &nbsp; }</div><div>)</div><div>print(f'답변: {response[\"output\"]}')</div><div><br /></div><div>우선 PDF에서 검색하라고 에이전트에게 명령했으므로, tools에 등록된 pdf vector database를 검색하는 tool을 실행한다. 다음은 이 결과의 예이다.&nbsp;</div><div><br /></div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjfh8xL3CrGSX76ETNH_1VgxAGsRKJdyTu410kmC6iEh_AcjDWab_V6_2svh3x1QPI6Uf-smIWu6o4vt0S_E-tIfSk80OsFbKa3I_HyQxPXYqisqp1dqtuDV7KygSNR-5LnjhPX15mTk7Bv6sC0P91mqs2dy7KXKpIYDk-jHKhcMEwb5Ed50sFqsTbQfWPm\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"92\" data-original-width=\"737\" height=\"64\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjfh8xL3CrGSX76ETNH_1VgxAGsRKJdyTu410kmC6iEh_AcjDWab_V6_2svh3x1QPI6Uf-smIWu6o4vt0S_E-tIfSk80OsFbKa3I_HyQxPXYqisqp1dqtuDV7KygSNR-5LnjhPX15mTk7Bv6sC0P91mqs2dy7KXKpIYDk-jHKhcMEwb5Ed50sFqsTbQfWPm=w510-h64\" width=\"510\" /></a></div><br /></div><div><div>&gt; Finished chain.</div><div>답변: PCL(Point Cloud Library)은 BSD 라이선스로 개발되어 상업 및 연구 목적에 서 무료로 사용할 수 있습니다. 이 라이브러리는 크로스 플랫폼 개발을 지원하여 리눅스, 맥, 윈도우, 안드로이드 등 다양한 운영 체제에서 사용할 수 있습니다. PCL은 잘 모듈화되어 있어 배포가 용이하며, ROS(Robot Operating System), PDAL 등 유명한 오픈소스 프로젝트에서 직접 사용됩니다....</div><div><br /></div></div><div>이제, web 검색 도구를 실행해 관련 내용을 추론하고, 기존 추론된 내용은 메모리를 이용해 같이 이용해 보도록 한다. 다음 코드를 입력해 본다.&nbsp;</div><div><div>from langchain_community.chat_message_histories import ChatMessageHistory</div><div>from langchain_core.runnables.history import RunnableWithMessageHistory</div><div>message_history = ChatMessageHistory()&nbsp; # 메모리 사용</div><div><br /></div><div>agent_with_chat_history = RunnableWithMessageHistory(</div><div>&nbsp; &nbsp; agent_executor,</div><div>&nbsp; &nbsp; lambda session_id: message_history,</div><div>&nbsp; &nbsp; input_messages_key=\"input\",</div><div>&nbsp; &nbsp; history_messages_key=\"chat_history\",</div><div>)</div><div><br /></div><div>response = agent_with_chat_history.invoke(</div><div>&nbsp; &nbsp; {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; \"input\": \"2024년부터 PCL에 대한 새로운 내용을 인터넷 웹 문서에서 알려줘\"</div><div>&nbsp; &nbsp; },</div><div>&nbsp; &nbsp; config={\"configurable\": {\"session_id\": \"MyTestSessionID\"}},</div><div>)</div><div>print(f\"답변: {response['output']}\")</div></div><div><br /></div><div>이 코드를 실행하면, 다음과 같이 travily web search 도구를 이용해, 인터넷에서 해당 질문에 대한 검색을 수행하여, 결과를 LLM이 추론한다.</div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjBB0K3vh5xYWx_Rq31M3Sqcn6PvD-Hb110Iu4AdZ5OIJFzbqWic3aClBkgND4YBewU5qgwgqOA-Lb4IdX2KyiOQ5RKLasIM6H15PiYz6UfQfGMP6_ZwHy_V52HMGeDn4DdB6FZH50C611QDm8dUq8XVGrwn7-0YERhw2VF8NyCNkfS_W_wK_DLRovTUzo7\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"79\" data-original-width=\"969\" height=\"52\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjBB0K3vh5xYWx_Rq31M3Sqcn6PvD-Hb110Iu4AdZ5OIJFzbqWic3aClBkgND4YBewU5qgwgqOA-Lb4IdX2KyiOQ5RKLasIM6H15PiYz6UfQfGMP6_ZwHy_V52HMGeDn4DdB6FZH50C611QDm8dUq8XVGrwn7-0YERhw2VF8NyCNkfS_W_wK_DLRovTUzo7=w640-h52\" width=\"640\" /></a></div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjVH5rigrRq3B4qrJbCS1cphFcAIE90bxduufimleE2ATc7ZEP-DThCX-m0zHLKyCOxg5Lvx9HM-2CxWqyQyTV6FUZxJab6NXN80iQYnDhAyscYuBc0JyEsoNjnv14rYWoALKZF4gzjYBA55b7Zelju-LhOqJ6q42zd2thennSwZbEIORkHklezDafMhaIO\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"195\" data-original-width=\"1041\" height=\"120\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjVH5rigrRq3B4qrJbCS1cphFcAIE90bxduufimleE2ATc7ZEP-DThCX-m0zHLKyCOxg5Lvx9HM-2CxWqyQyTV6FUZxJab6NXN80iQYnDhAyscYuBc0JyEsoNjnv14rYWoALKZF4gzjYBA55b7Zelju-LhOqJ6q42zd2thennSwZbEIORkHklezDafMhaIO=w640-h120\" width=\"640\" /></a></div><br />추론 결과는 다음과 같다.<br /><div>&gt; Finished chain.</div><div>답변: 2024년에 대한 Point Cloud Library (PCL)의 새로운 업데이트와 관련된 정보는 다음과 같습니다:</div><div><br /></div><div>- **GitHub Pull Requests**: 2024년에는 PCL 개발에 몇 가지 주목할 만한 기여가 있었습니다. 예를 들어, 2024년 2월 10일에 larshg에 의해 열린 [#5958 (https://github.com/PointCloudLibrary/pcl/pulls)는 기능을 두 개의 라이브러리로 분할하&nbsp;</div><div>는 작업에 대한 초안입니다. 또한, 2024년 1월 15일에 larshg에 의해 열린 [#5932 (https://github.com/PointCloudLibrary/pcl/pulls)는 관련된 또 다른 기여입니다.</div><div><br /></div><div>- **공식 문서 및 웹사이트**: PCL은 대규모 오픈 프로젝트로, 포인트 클라우드 처리를 위한 다양한 최신 알고리즘을 포함하고 있습니다. 이러한 알고리즘에는 노이즈 데이터에서 이상치를 필터링하는 것과 같은 작업을 위한 필터링, 특징 추정, 표면 재구성, 등록, 모델 피팅 및 세분화가 포함됩니다. [공식 문서](http://pointclouds.org/documentation/index.html)와 [공식 웹사이트](https://pointclouds.org/)에서는 PCL에 대한 자세한 정보와 리소스를 제공합니다.</div></div><div><br /></div><div><b><span style=\"font-size: medium;\">결론</span></b></div><div>langchain의 tool 에이전트 기능을 이용하면, 파일 벡터 검색, 웹 검색, 계산, 추론, 텍스트 및 차트 생성 등과 같은 기능을 쉽게 개발할 수 있다.</div><div><br /></div><div>참고로, langchain과 연동되는 langsmith 사이트를 방문하면, 다음과 같이 얼마나 토큰을 사용했는 지 확인할 수 있다.&nbsp;</div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjjSPvbyNb_4loyz1j3qZ_VGEGjNlH1bGjyXFB2Ld2fvJnQ2qCJN0o5mmY9bVSCfBB4O_AU9TordeYg7U-Euj4hwSVlC22gNeY4qWF5eX_Dkz8NpsOxTXy67LQjh1Iv-YOvyyobvNphCy2mIs05SWexz0R_873k13_jLyVhAHdu4PBiMCZeBdqtIWAspDBP\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"1237\" data-original-width=\"2517\" height=\"314\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjjSPvbyNb_4loyz1j3qZ_VGEGjNlH1bGjyXFB2Ld2fvJnQ2qCJN0o5mmY9bVSCfBB4O_AU9TordeYg7U-Euj4hwSVlC22gNeY4qWF5eX_Dkz8NpsOxTXy67LQjh1Iv-YOvyyobvNphCy2mIs05SWexz0R_873k13_jLyVhAHdu4PBiMCZeBdqtIWAspDBP=w640-h314\" width=\"640\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">LangSmith 로그 결과</div><br /></div><div><b><span style=\"font-size: medium;\">레퍼런스</span></b></div><div><ul style=\"text-align: left;\"><li><a href=\"https://smith.langchain.com/onboarding?organizationId=2c462eb1-5b83-41c8-96c5-e008809d5655&amp;step=1\">LangSmith</a></li><li><a href=\"https://github.com/langchain-ai/langchain\">langchain-ai/langchain: 🦜🔗 Build context-aware reasoning applications</a></li><li><a href=\"https://github.com/langchain-ai/langchain/blob/master/cookbook/generative_agents_interactive_simulacra_of_human_behavior.ipynb\">langchain/cookbook/generative_agents_interactive_simulacra_of_human_behavior.ipynb at master · langchain-ai/langchain</a></li><li><a href=\"https://github.com/langchain-ai/langchain/blob/master/cookbook/llm_symbolic_math.ipynb\">langchain/cookbook/llm_symbolic_math.ipynb at master · langchain-ai/langchai</a></li><li><a href=\"https://github.com/teddylee777/langchain-kr\">teddylee777/langchain-kr: LangChain Document, Cookbook</a>, <a href=\"https://teddylee777.github.io/categories/#langchain\">tutorial</a></li><li><a href=\"https://discuss.streamlit.io/t/langchain-tutorial-5-build-an-ask-the-data-app/47672\">LangChain tutorial #5: Build an Ask the Data app - Show the Community! - Streamlit</a></li></ul><div><b><span style=\"font-size: medium;\">부록</span></b></div><div><b>LCEL 문법</b></div></div><div>사용자 정의 체인을 위한 LCEL은 기본으로 Runnable 에서 파생되어 처리된다. 이는 다음 표준적인 인터페이스를 지원한다.</div><div><ul style=\"text-align: left;\"><li>stream: 응답 청크를 스트리밍</li><li>invoke: 입력에 대한 체인을 실행 호출</li><li>batch: 입력 목록에 대해 체인들을 실행 호출</li><li>astream: 비동기적으로 응답 청크를 스트리밍</li><li>ainvoke: invoke의 비동기 버전</li></ul><div><div>LCEL는 유닉스 파이프라인처럼 입력 | 처리 | 실행 | 출력 형태로 유연한 LLM 오케스트레이션을 지원한다.<br /></div><div>from langchain_openai import ChatOpenAI</div><div>from langchain_core.prompts import PromptTemplate</div><div>from langchain_core.output_parsers import StrOutputParser</div><div><br /></div><div>model = ChatOpenAI()</div><div>prompt = PromptTemplate.from_template(\"Explain about {topic} as one paragraph.\")</div><div>chain = prompt | model | StrOutputParser()</div></div><div><br /></div><div><div>다음 코드를 이용해 체인 그래프의 구조를 확인할 수 있다.</div><div>chain.get_graph().nodes</div><div>chain.get_graph().edges</div><div>chain.get_graph().print_ascii()</div><div><br /></div></div><div>각 체인은 이터레이션(iteration)을 이용해 각 단계를 개별 관찰, 실행, 제어할 수 있도록 한다.</div><div><br /></div><div><b>Runnable</b></div><div>runnable을 사용하면, 프롬프트 실행 중 동적으로 입력 단계에 참여할 수 있다. 이는 프롬프트에 데이터를 전달할 수 있다.</div></div><div><div><div>from langchain_core.prompts import PromptTemplate</div><div>from langchain_openai import ChatOpenAI</div></div><div>from langchain_core.runnables import RunnablePassthrough # RunnablePassthrough().invoke({\"num\": 10})</div><div>from langchain_core.runnables import RunnableLambda, RunnablePassthrough</div></div><div><div><br /></div><div>prompt = PromptTemplate.from_template(</div><div>&nbsp; &nbsp; \"List top {n} famous people which have birthday {today}.\"</div><div>)</div><div>llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")</div><div><br /></div><div>chain = (</div><div>&nbsp; &nbsp; {\"today\": RunnableLambda(get_today), \"n\": RunnablePassthrough()}</div><div>&nbsp; &nbsp; | prompt</div><div>&nbsp; &nbsp; | llm</div><div>&nbsp; &nbsp; | StrOutputParser()</div><div>)</div></div><div><div>print(chain.invoke({'n': 3}))</div></div><div><br /></div><div>사용자 정의 람다를 지원하는 RunnableLambda, 입력에 따른 동적 라우팅 RunnableBranch, 병렬 처리 RunnableParall, 이전 내용 기억을 하는&nbsp;RunnableWithMessageHistory 등이 있다.&nbsp;</div><div><br /></div><div>@chain을 사용하면, 알아서 RunnableLambda로 주어진 함수를 래핑한다.</div><div><div>@chain</div><div>def custom_chain(text):</div><div>&nbsp; &nbsp; chain1 = prompt1 | ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser()</div><div>&nbsp; &nbsp; output1 = chain1.invoke({\"topic\": text})</div><div>&nbsp; &nbsp; chain2 = prompt2 | ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser()</div><div>&nbsp; &nbsp; return chain2.invoke({\"sentence\": output1})</div></div><div><br /></div><div><b>PydanticOutputParser</b></div><div>LLM 출력을 기계처리 가능한 구조화된 형태로 변환하는 파서이다. 다음은 그 예이다.&nbsp;</div><div><div>class EmailSummary(BaseModel):</div><div>&nbsp; &nbsp; person: str = Field(description=\"person who send email\")</div><div>&nbsp; &nbsp; email: str = Field(description=\"email address of sender\")</div><div>&nbsp; &nbsp; subject: str = Field(description=\"email title\")</div><div>&nbsp; &nbsp; summary: str = Field(description=\"email's summerized text\")</div><div>&nbsp; &nbsp; date: str = Field(description=\"meeting date and time in email\")</div><div><br /></div><div>parser = PydanticOutputParser(pydantic_object=EmailSummary)</div></div><div><div>print(parser.get_format_instructions())</div></div><div><br /></div><div>이와 유사한, StructuredOutputParser, JsonOutputParser, PandasDataFrameOutputParser 등이 있다.</div><div><br /></div><div><b>OutputFixingParser</b></div><div>출력 파싱 시 발생하는 오류를 자동으로 수정한다.&nbsp;</div><div><br /></div><div><b>LLM 모델 종류</b></div><div>lanchain이 지원하는 주요 LLM 모델은 openai, anthropic claude, cohere aya, facebook llama, microsoft phi, google gemini (ChatGoogleGenerativeAI), GPT4All 등이 있다. 이 중 몇몇 모델은 멀티모달을 지원한다.</div><div><div>gemini = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\")</div><div><br /></div><div>system_prompt = (</div><div>&nbsp; &nbsp; \"You're writer. From given image, write short novel.\"</div><div>)</div><div><br /></div><div>user_prompt = \"Write short novel from the follow image.\"</div><div><br /></div><div>multimodal_gemini = MultiModal(</div><div>&nbsp; &nbsp; llm, system_prompt=system_prompt, user_prompt=user_prompt</div><div>)</div></div><div><div>IMAGE_URL = \"house.jpg\"</div><div>answer = multimodal_gemini.stream(IMAGE_URL)</div><div><br /></div></div><div><b>Caching</b></div><div>이미 얻은 답변을 캐쉬처리 하여, LLM API 호출을 줄여주고, 실행 속도를 높여준다. InMemoryCache, SQLiteCache 등이 있다.</div><div><br /></div><div><b>체인 직렬화</b></div><div>앞서 정의한 LLM 체인을 직렬화(langchain_core.load)하면, 개별로 파일 저장해, 필요 시 동적으로 로딩하여 사용할 수 있다.&nbsp;</div><div><br /></div><div><b>LLM 모델 로컬 실행</b></div><div>LLM 모델을 로컬 PC에서도 실행할 수 있다. 이 경우, 허깅페이스, Ollama를 이용한다.&nbsp;</div><div><div>llm = HuggingFacePipeline.from_model_id(</div><div>&nbsp; &nbsp; model_id=\"beomi/llama-2-ko-7b\",&nbsp;&nbsp;</div><div>&nbsp; &nbsp; task=\"text-generation\",&nbsp;&nbsp;</div><div>&nbsp; &nbsp; pipeline_kwargs={\"max_new_tokens\": 512},</div><div>)</div></div><div><br /></div><div>llm = ChatOllama(model=\"EEVE-Korean-10.8B:latest\")</div><div><br /></div><div><b>문서 로더</b></div><div>LangChain은 매우 다양한 문서 종류를 지원한다. PDF, CSV, Excel, Word, Web, JSON, Arxiv 등을 지원한다.</div><div><br /></div><div><b>문서 청크 분할 및 요약</b></div><div>문서를 LLM에 입력 가능하도록 청크로 분할하는 CharacterTextSplitter(/n 기준 분할), 재귀적 문서 분할, 토큰 제한 분할, 의미론적 분할, 코드 분할, HTML 분할, JSON 분할(RecursiveJsonSplitter) 등이 있다.&nbsp;</div><div><br /></div><div>문서를 요약하는 방법은 전체 문서 요약하는 Stuff, 분할 요약하는 Map reduce, 분할 요약 후 정리하는 Map refine 및 chain of density, clustering map refine 방법 등이 있다.&nbsp;</div><div><br /></div><div><b>임베딩 모델</b></div><div>문서의 청크를 검색 가능한 벡터 형태의 임베딩 벡터로 변환하는 모델을 말한다. 보통, OpenAIEmbedding,&nbsp;CacheBackedEmbeddings,&nbsp;HuggingFace Embeddings,&nbsp;OllamaEmbeddings,&nbsp;GPT4All 등이 사용된다.&nbsp;</div><div><br /></div><div><b>벡터 데이터베이스와 검색기</b></div><div>보통, Chroma, Vectordatabase, FAISS, Pinecone 등이 사용된다. 여기서 원하는 임베딩 벡터를 검색해 문서를 리턴하는 방법은 vectorstore 기반 similarity search, MMR,&nbsp;ContextualCompressionRetriever(압축 검색),&nbsp;ContextualCompressionRetriever(컨테텍스트 압축),&nbsp;LongContextReorder(긴 문맥 기록),&nbsp;ParentDocumentRetriever(계층적 문서 검색),&nbsp;MultiQueryRetriever(다중 질의 후 검색),&nbsp;SelfQueryRetriever 등이 있다.</div><div><br /></div><div>이와 더불어, 재순위(Reranker)를 이용해, 원하는 답을 검색할 때까지 우선순위를 조정할 수 있다.&nbsp;Cross Encoder Reranker,&nbsp;Cohere reranker,&nbsp;Jina Reranker,&nbsp;FlashRank reranker 등이 있다.</div><div><br /></div><div><b>메모리</b></div><div>채팅과 같이 앞의 입출력에 대한 맥락을 기억해야 할 때 사용한다.&nbsp;RunnableWithMessageHistory 등이 있다.</div><div><br /></div><div><b>Fallback 오류 방지</b></div><div>만약 체인 실행 중 여러 이유로 에러가 발생할 경우, 다시 재 시도하는 방법이 폴백이다.&nbsp;with_fallbacks 함수를 사용한다.</div><div><br /></div><div><b>도구와 에이전트</b></div><div>앞서 언급한 <a href=\"https://python.langchain.com/docs/integrations/tools/\">도구</a>나 사전 정의된 에이전트를 이용하면, 멀티 에이전트를 만들 수 있다. 도구들 중에서는 파일관리 도구, 이미지 생성 도구, 보고서 작성 도구 등이 있다.</div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjZ_kFy931EbwyGHZOyHJw26BnnMbrb61d0m5gZFEL1UHSXyeoTobCqZ92zwoaEyjLKcdB05Ivsuyk3sZFsI0vvab6VDcG8r6nI5A6O4C9ia8liTbQCKq_IUNNn0x95JINdMDpNLg4eZIyji4EndJFJpsl5occ4L38BXywezFbPZ-SA91ND0ACgW6M0ouvo\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"1234\" data-original-width=\"1230\" height=\"400\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjZ_kFy931EbwyGHZOyHJw26BnnMbrb61d0m5gZFEL1UHSXyeoTobCqZ92zwoaEyjLKcdB05Ivsuyk3sZFsI0vvab6VDcG8r6nI5A6O4C9ia8liTbQCKq_IUNNn0x95JINdMDpNLg4eZIyji4EndJFJpsl5occ4L38BXywezFbPZ-SA91ND0ACgW6M0ouvo=w398-h400\" width=\"398\" /></a></div></div><div class=\"separator\" style=\"clear: both; text-align: center;\">랭체인 무료 제공 도구 예</div><div><br /></div><div>예를 들어, <a href=\"https://api.python.langchain.com/en/latest/community/index.html\">agent_toolkits</a>에는 langchain 커뮤니티 생태계에서 업로드한 다양한 에이전트가 있다. 이 중에 엑셀 분석 에이전트, SQL agent인 create_sql_agent 등은 많이 사용된다.</div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhe5uArl7u2fmAH2Ty60o4X6STnLZZvoA0lbQbZjFao327E3QjWXZHfPhvJ_gNj3FUEYNhlsK_Lz8ce7Kew8sNFWuzpfbPUSfBVnvjLL60KzT_tF24uovrfoz2wwEw7SquapDlsMx9fE-AEuzTYGbyX3TkbG85PLP85Z0bBHpsa2Vcr3WuufOJz8I6npAsr\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"677\" data-original-width=\"1216\" height=\"223\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhe5uArl7u2fmAH2Ty60o4X6STnLZZvoA0lbQbZjFao327E3QjWXZHfPhvJ_gNj3FUEYNhlsK_Lz8ce7Kew8sNFWuzpfbPUSfBVnvjLL60KzT_tF24uovrfoz2wwEw7SquapDlsMx9fE-AEuzTYGbyX3TkbG85PLP85Z0bBHpsa2Vcr3WuufOJz8I6npAsr=w400-h223\" width=\"400\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">랭체인 커뮤니티 제공 에이전트 예</div><div><br /></div>이런 에이전트는 BaseToolkit, BaseTool, RunnableSerializable를 기본 클래스로 파생되어 개발할 수 있다. 이 클래스의 아키텍처는 컴포짓(Composite) 디자인 패턴으로 다음과 같다.<br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjwPbbdE8F4FWAMPcXBPIvWR-C44KwjKupaDMCAc8jo4fAEBCN3HEHKHgslOMCHIMQTmXoCuhJfRbyP5DyDRXMoeEAMPPsiWx2OJOKJr9rIJ4d2x7J-LXKZVWltyvLXPs5yKtBHsHbg2_x29QnCrEYa0giMn0rynQvFGJtgkmHdWJU7cwrXKyw5BDhEtYH9\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"513\" data-original-width=\"482\" height=\"359\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjwPbbdE8F4FWAMPcXBPIvWR-C44KwjKupaDMCAc8jo4fAEBCN3HEHKHgslOMCHIMQTmXoCuhJfRbyP5DyDRXMoeEAMPPsiWx2OJOKJr9rIJ4d2x7J-LXKZVWltyvLXPs5yKtBHsHbg2_x29QnCrEYa0giMn0rynQvFGJtgkmHdWJU7cwrXKyw5BDhEtYH9=w337-h359\" width=\"337\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: left;\">도구를 정의할 때 앞의 @chain 처럼 @tool 데코레이터를 사용할 수도 있다. <a href=\"https://wikidocs.net/262585\">description</a>은 어떤 도구를 LLM이 선택할 지를 체인에서 결정하는 힌트로 동작한다. 예는 다음과 같다.</div><div class=\"separator\" style=\"clear: both; text-align: left;\"><div class=\"separator\" style=\"clear: both;\">import re</div><div class=\"separator\" style=\"clear: both;\">import requests</div><div class=\"separator\" style=\"clear: both;\">from bs4 import BeautifulSoup</div><div class=\"separator\" style=\"clear: both;\">from langchain.agents import tool</div><div class=\"separator\" style=\"clear: both;\"><br /></div><div class=\"separator\" style=\"clear: both;\">@tool</div><div class=\"separator\" style=\"clear: both;\">def get_word_length(word: str) -&gt; int:</div><div class=\"separator\" style=\"clear: both;\">&nbsp; &nbsp; \"\"\"Returns the length of a word.\"\"\"</div><div class=\"separator\" style=\"clear: both;\">&nbsp; &nbsp; return len(word)</div><div class=\"separator\" style=\"clear: both;\"><br /></div><div class=\"separator\" style=\"clear: both;\">@tool</div><div class=\"separator\" style=\"clear: both;\">def add_function(a: float, b: float) -&gt; float:</div><div class=\"separator\" style=\"clear: both;\">&nbsp; &nbsp; \"\"\"Adds two numbers together.\"\"\"</div><div class=\"separator\" style=\"clear: both;\">&nbsp; &nbsp; return a + b</div><div class=\"separator\" style=\"clear: both;\"><br /></div><div class=\"separator\" style=\"clear: both;\">@tool</div><div class=\"separator\" style=\"clear: both;\">def naver_news_crawl(news_url: str) -&gt; str:</div><div class=\"separator\" style=\"clear: both;\">&nbsp; &nbsp; \"\"\"Crawls a naver.com news article and returns the body content.\"\"\"</div><div class=\"separator\" style=\"clear: both;\">&nbsp; &nbsp; response = requests.get(news_url)</div><div class=\"separator\" style=\"clear: both;\">&nbsp; &nbsp; if response.status_code == 200:</div><div class=\"separator\" style=\"clear: both;\">&nbsp; &nbsp; &nbsp; &nbsp; soup = BeautifulSoup(response.text, \"html.parser\")</div><div class=\"separator\" style=\"clear: both;\">&nbsp; &nbsp; &nbsp; &nbsp; title = soup.find(\"h2\", id=\"title_area\").get_text()</div><div class=\"separator\" style=\"clear: both;\">&nbsp; &nbsp; &nbsp; &nbsp; content = soup.find(\"div\", id=\"contents\").get_text()</div><div class=\"separator\" style=\"clear: both;\">&nbsp; &nbsp; &nbsp; &nbsp; cleaned_title = re.sub(r\"\\n{2,}\", \"\\n\", title)</div><div class=\"separator\" style=\"clear: both;\">&nbsp; &nbsp; &nbsp; &nbsp; cleaned_content = re.sub(r\"\\n{2,}\", \"\\n\", content)</div><div class=\"separator\" style=\"clear: both;\">&nbsp; &nbsp; else:</div><div class=\"separator\" style=\"clear: both;\">&nbsp; &nbsp; &nbsp; &nbsp; print(f\"HTTP fail code: {response.status_code}\")</div><div class=\"separator\" style=\"clear: both;\">&nbsp; &nbsp; return f\"{cleaned_title}\\n{cleaned_content}\"</div><div class=\"separator\" style=\"clear: both;\"><br /></div><div class=\"separator\" style=\"clear: both;\">tools = [get_word_length, add_function, naver_news_crawl]</div><div><br /></div></div><div class=\"separator\" style=\"clear: both; text-align: left;\"><div class=\"separator\" style=\"clear: both;\">from langchain_openai import ChatOpenAI</div><div class=\"separator\" style=\"clear: both;\">llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)</div><div class=\"separator\" style=\"clear: both;\">llm_with_tools = llm.bind_tools(tools)</div></div><div class=\"separator\" style=\"clear: both; text-align: left;\"><br /></div><b>LLM 평가</b></div><div>생성 결과에 대한 평가 방법은 자동 계산이 가능한 BLEU, ROUGE, METEOR, SemScore, 수동 평가, 작업 기반 평가, LLM 기반 평가 등이 있다. 평가용 라이브러리는 RAGAS, LangSmith, W&amp;B 등이 있다.<br /><br /></div><div>평가를 위해, 테스트 데이터셋을&nbsp;from ragas.testset.generator import TestsetGenerator 를 통해 자동 생성할 수 있다. 다만, 토큰 비용이 과대해 질 수 있는 문제가 발생할 수 있다. 이 경우, 오픈소스 LLM 모델을 사용할 수 있다.</div></div>",
        "contentSnippet": "이 글은 벡터데이터베이스 기반 간단한 PDF, Web 기반 검색 전문 에이전트 만드는 방법을 정리한 것이다. 이 글은 LangChain을 사용한다. lanchain은 급속히 버전과 함수가 개선되고 있어 API가 자주 변경되는 경향이 있다(Deprecated error). 이런 이유로, 현지 시점에서 관련 에이전트를 만드는 주요 코드를 남긴다. \n\n\n에이전트 예시(Build Ask Data app - Streamlit)\n\n\n에이전트 예시(Local_RAG_Agents_Intel_cpu)\n\n\nLangChain 설명 및 사용법은 앞의 블로그 내용(검색)을 참고한다. 다음 같은 순서로 LLM이 사용된다는 것만 이해하고 있으면 코드 사용에 큰 어려움은 없을 것이다. \n\n\n\n\n사용자 입력 > 컨텐츠 검색 입력 > 에이전트 도구에서 데이터 입력 > 과거 메모리 내용 입력 > 프롬프트 생성 > LLM 전달 > 추론 내용 출력\n\n\n\n\n\n설치 \n파이썬, 아나콘다가 준비되어 있다는 가정에서, 라이브러리 설치는 다음과 같다. \npip install --upgrade openai langchain-openai langchain langchain-experimental\n\n\n이 글은 OpenAI API Key, Tavily API Key를 신청해 가지고 있다고 가정한다. 실행 시 로그나 성능을 확인하고자 한다면, Langsmith에 가입한다. 각 API는 해당 웹사이트에서 가입하여 얻을 수 있다. 각 사이트에서 생성한 API키는 .env 파일을 생성해 다음과 같이 입력해 놓는다.\n\nOPENAI_API_KEY=<OpenAI API Key>\nLANGCHAIN_TRACING_V2=false\nLANGCHAIN_ENDPOINT=https://api.smith.langchain.com\nLANGCHAIN_API_KEY=<Langsmith API Key>\nLANGCHAIN_PROJECT=AGENT TUTORIAL\n\n\n코딩\n다음과 같이 코딩한다. 우선 필요한 라이브러리를 임포트한다.\n\nimport os, getpass\nfrom openai import OpenAI  \nfrom dotenv import load_dotenv\nfrom langchain_community.tools.tavily_search import TavilySearchResults\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain.agents import create_openai_functions_agent\nfrom langchain_community.document_loaders import PyPDFLoader\nfrom langchain.tools.retriever import create_retriever_tool\nfrom langchain.agents import AgentExecutor\nfrom langchain_openai import ChatOpenAI\nfrom langchain import hub\n\n\nos.environ[\"TAVILY_API_KEY\"] = \"input your key\"\nos.environ[\"LANGCHAIN_PROJECT\"] = \"AGENT TUTORIAL\"\nload_dotenv()\nclient = OpenAI(api_key=\"input your key\")\n\n\n# Travily의 웹 검색 객체 획득\nweb_search = TavilySearchResults(k=5) \n\n\n# PDF 데이터를 벡터DB에 청크로 저장하고, 문서 검색 객체를 획득\nloader = PyPDFLoader(\"./202212_LiDAR.pdf\")  # 적절한 PDF 입력\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\nsplit_docs = loader.load_and_split(text_splitter)\n\n\nembeddings = OpenAIEmbeddings(api_key=os.environ[\"OPENAI_API_KEY\"])\nvector = FAISS.from_documents(split_docs, embeddings)\nvectordb_retriever = vector.as_retriever()\noutput = vectordb_retriever.get_relevant_documents(\n    \"PCL(Point Cloud Library) 라이브러리에 대해 설명해줘\"\n)[0]\nprint(output)  # PCL 검색 예시\n\n\npdf_retriever_tool = create_retriever_tool(\n    vectordb_retriever,\n    name=\"pdf_search\",\n    description=\"2023년 12월 PCL(Point Cloud Library) 정보를 PDF 문서에서 검색합니다. '2023년 12월 라이다 포인트 클라우드 처리 기술' 과 관련된 질문은 이 도구를 사용해야 합니다!\",\n) # 문서 검색 객체\n\n\n# 에이전트 도구들 설정\ntools = [web_search, pdf_retriever_tool]\n\n\n# LLM 객체 설정\nllm = ChatOpenAI(model=\"gpt-4-turbo-preview\", temperature=0)\n\n\n# 프롬프트 설정\nprompt = hub.pull(\"hwchase17/openai-functions-agent\")\nprint(prompt.messages)\n\n\n# LLM 함수 호출 에이전트 설정\nagent = create_openai_functions_agent(llm, tools, prompt)\nagent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n\n\n# 전문가 에이전트 질문 수행\nresponse = agent_executor.invoke(\n    {\n        \"input\": \"2010년부터 PCL 라이브러리 기술에 대한 대한 내용을 PDF 문서에서 알려줘\"\n    }\n)\nprint(f'답변: {response[\"output\"]}')\n\n\n우선 PDF에서 검색하라고 에이전트에게 명령했으므로, tools에 등록된 pdf vector database를 검색하는 tool을 실행한다. 다음은 이 결과의 예이다. \n\n\n\n\n\n> Finished chain.\n답변: PCL(Point Cloud Library)은 BSD 라이선스로 개발되어 상업 및 연구 목적에 서 무료로 사용할 수 있습니다. 이 라이브러리는 크로스 플랫폼 개발을 지원하여 리눅스, 맥, 윈도우, 안드로이드 등 다양한 운영 체제에서 사용할 수 있습니다. PCL은 잘 모듈화되어 있어 배포가 용이하며, ROS(Robot Operating System), PDAL 등 유명한 오픈소스 프로젝트에서 직접 사용됩니다....\n\n\n이제, web 검색 도구를 실행해 관련 내용을 추론하고, 기존 추론된 내용은 메모리를 이용해 같이 이용해 보도록 한다. 다음 코드를 입력해 본다. \n\nfrom langchain_community.chat_message_histories import ChatMessageHistory\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\nmessage_history = ChatMessageHistory()  # 메모리 사용\n\n\nagent_with_chat_history = RunnableWithMessageHistory(\n    agent_executor,\n    lambda session_id: message_history,\n    input_messages_key=\"input\",\n    history_messages_key=\"chat_history\",\n)\n\n\nresponse = agent_with_chat_history.invoke(\n    {\n        \"input\": \"2024년부터 PCL에 대한 새로운 내용을 인터넷 웹 문서에서 알려줘\"\n    },\n    config={\"configurable\": {\"session_id\": \"MyTestSessionID\"}},\n)\nprint(f\"답변: {response['output']}\")\n\n\n이 코드를 실행하면, 다음과 같이 travily web search 도구를 이용해, 인터넷에서 해당 질문에 대한 검색을 수행하여, 결과를 LLM이 추론한다.\n\n\n\n\n추론 결과는 다음과 같다.\n> Finished chain.\n답변: 2024년에 대한 Point Cloud Library (PCL)의 새로운 업데이트와 관련된 정보는 다음과 같습니다:\n\n\n- **GitHub Pull Requests**: 2024년에는 PCL 개발에 몇 가지 주목할 만한 기여가 있었습니다. 예를 들어, 2024년 2월 10일에 larshg에 의해 열린 [#5958 (https://github.com/PointCloudLibrary/pcl/pulls)는 기능을 두 개의 라이브러리로 분할하 \n는 작업에 대한 초안입니다. 또한, 2024년 1월 15일에 larshg에 의해 열린 [#5932 (https://github.com/PointCloudLibrary/pcl/pulls)는 관련된 또 다른 기여입니다.\n\n\n- **공식 문서 및 웹사이트**: PCL은 대규모 오픈 프로젝트로, 포인트 클라우드 처리를 위한 다양한 최신 알고리즘을 포함하고 있습니다. 이러한 알고리즘에는 노이즈 데이터에서 이상치를 필터링하는 것과 같은 작업을 위한 필터링, 특징 추정, 표면 재구성, 등록, 모델 피팅 및 세분화가 포함됩니다. [공식 문서](http://pointclouds.org/documentation/index.html)와 [공식 웹사이트](https://pointclouds.org/)에서는 PCL에 대한 자세한 정보와 리소스를 제공합니다.\n\n\n결론\nlangchain의 tool 에이전트 기능을 이용하면, 파일 벡터 검색, 웹 검색, 계산, 추론, 텍스트 및 차트 생성 등과 같은 기능을 쉽게 개발할 수 있다.\n\n\n참고로, langchain과 연동되는 langsmith 사이트를 방문하면, 다음과 같이 얼마나 토큰을 사용했는 지 확인할 수 있다. \n\n\nLangSmith 로그 결과\n\n레퍼런스\n\nLangSmith\nlangchain-ai/langchain: 🦜🔗 Build context-aware reasoning applications\nlangchain/cookbook/generative_agents_interactive_simulacra_of_human_behavior.ipynb at master · langchain-ai/langchain\nlangchain/cookbook/llm_symbolic_math.ipynb at master · langchain-ai/langchai\nteddylee777/langchain-kr: LangChain Document, Cookbook, tutorial\nLangChain tutorial #5: Build an Ask the Data app - Show the Community! - Streamlit\n\n부록\nLCEL 문법\n\n사용자 정의 체인을 위한 LCEL은 기본으로 Runnable 에서 파생되어 처리된다. 이는 다음 표준적인 인터페이스를 지원한다.\n\nstream: 응답 청크를 스트리밍\ninvoke: 입력에 대한 체인을 실행 호출\nbatch: 입력 목록에 대해 체인들을 실행 호출\nastream: 비동기적으로 응답 청크를 스트리밍\nainvoke: invoke의 비동기 버전\n\nLCEL는 유닉스 파이프라인처럼 입력 | 처리 | 실행 | 출력 형태로 유연한 LLM 오케스트레이션을 지원한다.\n\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\n\n\nmodel = ChatOpenAI()\nprompt = PromptTemplate.from_template(\"Explain about {topic} as one paragraph.\")\nchain = prompt | model | StrOutputParser()\n\n\n\n다음 코드를 이용해 체인 그래프의 구조를 확인할 수 있다.\nchain.get_graph().nodes\nchain.get_graph().edges\nchain.get_graph().print_ascii()\n\n\n각 체인은 이터레이션(iteration)을 이용해 각 단계를 개별 관찰, 실행, 제어할 수 있도록 한다.\n\n\nRunnable\nrunnable을 사용하면, 프롬프트 실행 중 동적으로 입력 단계에 참여할 수 있다. 이는 프롬프트에 데이터를 전달할 수 있다.\n\n\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_openai import ChatOpenAI\n\nfrom langchain_core.runnables import RunnablePassthrough # RunnablePassthrough().invoke({\"num\": 10})\nfrom langchain_core.runnables import RunnableLambda, RunnablePassthrough\n\n\n\nprompt = PromptTemplate.from_template(\n    \"List top {n} famous people which have birthday {today}.\"\n)\nllm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n\n\nchain = (\n    {\"today\": RunnableLambda(get_today), \"n\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n\nprint(chain.invoke({'n': 3}))\n\n\n사용자 정의 람다를 지원하는 RunnableLambda, 입력에 따른 동적 라우팅 RunnableBranch, 병렬 처리 RunnableParall, 이전 내용 기억을 하는 RunnableWithMessageHistory 등이 있다. \n\n\n@chain을 사용하면, 알아서 RunnableLambda로 주어진 함수를 래핑한다.\n\n@chain\ndef custom_chain(text):\n    chain1 = prompt1 | ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser()\n    output1 = chain1.invoke({\"topic\": text})\n    chain2 = prompt2 | ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser()\n    return chain2.invoke({\"sentence\": output1})\n\n\nPydanticOutputParser\nLLM 출력을 기계처리 가능한 구조화된 형태로 변환하는 파서이다. 다음은 그 예이다. \n\nclass EmailSummary(BaseModel):\n    person: str = Field(description=\"person who send email\")\n    email: str = Field(description=\"email address of sender\")\n    subject: str = Field(description=\"email title\")\n    summary: str = Field(description=\"email's summerized text\")\n    date: str = Field(description=\"meeting date and time in email\")\n\n\nparser = PydanticOutputParser(pydantic_object=EmailSummary)\n\nprint(parser.get_format_instructions())\n\n\n이와 유사한, StructuredOutputParser, JsonOutputParser, PandasDataFrameOutputParser 등이 있다.\n\n\nOutputFixingParser\n출력 파싱 시 발생하는 오류를 자동으로 수정한다. \n\n\nLLM 모델 종류\nlanchain이 지원하는 주요 LLM 모델은 openai, anthropic claude, cohere aya, facebook llama, microsoft phi, google gemini (ChatGoogleGenerativeAI), GPT4All 등이 있다. 이 중 몇몇 모델은 멀티모달을 지원한다.\n\ngemini = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\")\n\n\nsystem_prompt = (\n    \"You're writer. From given image, write short novel.\"\n)\n\n\nuser_prompt = \"Write short novel from the follow image.\"\n\n\nmultimodal_gemini = MultiModal(\n    llm, system_prompt=system_prompt, user_prompt=user_prompt\n)\n\nIMAGE_URL = \"house.jpg\"\nanswer = multimodal_gemini.stream(IMAGE_URL)\n\n\nCaching\n이미 얻은 답변을 캐쉬처리 하여, LLM API 호출을 줄여주고, 실행 속도를 높여준다. InMemoryCache, SQLiteCache 등이 있다.\n\n\n체인 직렬화\n앞서 정의한 LLM 체인을 직렬화(langchain_core.load)하면, 개별로 파일 저장해, 필요 시 동적으로 로딩하여 사용할 수 있다. \n\n\nLLM 모델 로컬 실행\nLLM 모델을 로컬 PC에서도 실행할 수 있다. 이 경우, 허깅페이스, Ollama를 이용한다. \n\nllm = HuggingFacePipeline.from_model_id(\n    model_id=\"beomi/llama-2-ko-7b\",  \n    task=\"text-generation\",  \n    pipeline_kwargs={\"max_new_tokens\": 512},\n)\n\n\nllm = ChatOllama(model=\"EEVE-Korean-10.8B:latest\")\n\n\n문서 로더\nLangChain은 매우 다양한 문서 종류를 지원한다. PDF, CSV, Excel, Word, Web, JSON, Arxiv 등을 지원한다.\n\n\n문서 청크 분할 및 요약\n문서를 LLM에 입력 가능하도록 청크로 분할하는 CharacterTextSplitter(/n 기준 분할), 재귀적 문서 분할, 토큰 제한 분할, 의미론적 분할, 코드 분할, HTML 분할, JSON 분할(RecursiveJsonSplitter) 등이 있다. \n\n\n문서를 요약하는 방법은 전체 문서 요약하는 Stuff, 분할 요약하는 Map reduce, 분할 요약 후 정리하는 Map refine 및 chain of density, clustering map refine 방법 등이 있다. \n\n\n임베딩 모델\n문서의 청크를 검색 가능한 벡터 형태의 임베딩 벡터로 변환하는 모델을 말한다. 보통, OpenAIEmbedding, CacheBackedEmbeddings, HuggingFace Embeddings, OllamaEmbeddings, GPT4All 등이 사용된다. \n\n\n벡터 데이터베이스와 검색기\n보통, Chroma, Vectordatabase, FAISS, Pinecone 등이 사용된다. 여기서 원하는 임베딩 벡터를 검색해 문서를 리턴하는 방법은 vectorstore 기반 similarity search, MMR, ContextualCompressionRetriever(압축 검색), ContextualCompressionRetriever(컨테텍스트 압축), LongContextReorder(긴 문맥 기록), ParentDocumentRetriever(계층적 문서 검색), MultiQueryRetriever(다중 질의 후 검색), SelfQueryRetriever 등이 있다.\n\n\n이와 더불어, 재순위(Reranker)를 이용해, 원하는 답을 검색할 때까지 우선순위를 조정할 수 있다. Cross Encoder Reranker, Cohere reranker, Jina Reranker, FlashRank reranker 등이 있다.\n\n\n메모리\n채팅과 같이 앞의 입출력에 대한 맥락을 기억해야 할 때 사용한다. RunnableWithMessageHistory 등이 있다.\n\n\nFallback 오류 방지\n만약 체인 실행 중 여러 이유로 에러가 발생할 경우, 다시 재 시도하는 방법이 폴백이다. with_fallbacks 함수를 사용한다.\n\n\n도구와 에이전트\n앞서 언급한 도구나 사전 정의된 에이전트를 이용하면, 멀티 에이전트를 만들 수 있다. 도구들 중에서는 파일관리 도구, 이미지 생성 도구, 보고서 작성 도구 등이 있다.\n\n\n\n랭체인 무료 제공 도구 예\n\n\n예를 들어, agent_toolkits에는 langchain 커뮤니티 생태계에서 업로드한 다양한 에이전트가 있다. 이 중에 엑셀 분석 에이전트, SQL agent인 create_sql_agent 등은 많이 사용된다.\n\n\n랭체인 커뮤니티 제공 에이전트 예\n\n이런 에이전트는 BaseToolkit, BaseTool, RunnableSerializable를 기본 클래스로 파생되어 개발할 수 있다. 이 클래스의 아키텍처는 컴포짓(Composite) 디자인 패턴으로 다음과 같다.\n\n도구를 정의할 때 앞의 @chain 처럼 @tool 데코레이터를 사용할 수도 있다. description은 어떤 도구를 LLM이 선택할 지를 체인에서 결정하는 힌트로 동작한다. 예는 다음과 같다.\n\nimport re\nimport requests\nfrom bs4 import BeautifulSoup\nfrom langchain.agents import tool\n\n\n@tool\ndef get_word_length(word: str) -> int:\n    \"\"\"Returns the length of a word.\"\"\"\n    return len(word)\n\n\n@tool\ndef add_function(a: float, b: float) -> float:\n    \"\"\"Adds two numbers together.\"\"\"\n    return a + b\n\n\n@tool\ndef naver_news_crawl(news_url: str) -> str:\n    \"\"\"Crawls a naver.com news article and returns the body content.\"\"\"\n    response = requests.get(news_url)\n    if response.status_code == 200:\n        soup = BeautifulSoup(response.text, \"html.parser\")\n        title = soup.find(\"h2\", id=\"title_area\").get_text()\n        content = soup.find(\"div\", id=\"contents\").get_text()\n        cleaned_title = re.sub(r\"\\n{2,}\", \"\\n\", title)\n        cleaned_content = re.sub(r\"\\n{2,}\", \"\\n\", content)\n    else:\n        print(f\"HTTP fail code: {response.status_code}\")\n    return f\"{cleaned_title}\\n{cleaned_content}\"\n\n\ntools = [get_word_length, add_function, naver_news_crawl]\n\n\n\nfrom langchain_openai import ChatOpenAI\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\nllm_with_tools = llm.bind_tools(tools)\n\n\nLLM 평가\n생성 결과에 대한 평가 방법은 자동 계산이 가능한 BLEU, ROUGE, METEOR, SemScore, 수동 평가, 작업 기반 평가, LLM 기반 평가 등이 있다. 평가용 라이브러리는 RAGAS, LangSmith, W&B 등이 있다.\n\n평가를 위해, 테스트 데이터셋을 from ragas.testset.generator import TestsetGenerator 를 통해 자동 생성할 수 있다. 다만, 토큰 비용이 과대해 질 수 있는 문제가 발생할 수 있다. 이 경우, 오픈소스 LLM 모델을 사용할 수 있다.",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-5269609793318259495",
        "isoDate": "2024-12-07T08:52:00.000Z"
      }
    ]
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권영재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김상훈",
    "category": "개인",
    "posts": [
      {
        "creator": "김상훈",
        "title": "Weekly IC #2",
        "link": "https://interpiler.com/2024/12/02/weekly-ic-2/",
        "pubDate": "Mon, 02 Dec 2024 06:30:36 +0000",
        "content:encodedSnippet": "PC방 대신 게임호텔\n중국 젊은이들은 게임을 할 때 PC방 대신 호텔에서 모인다. 온라인 게임의 특성상 친구들과 모여서 함께 게임을 하는 게 즐거우니 중국 젊은이들도 과거에는 PC방을 찾았는데, 코로나19 때 집합금지 명령으로 PC방 문화가 사라졌다고.\n하지만 중국에는 “위에서 정책을 만들면 아래에선 대책을 만든다(上有政策 下有對策)”는 말이 있다. PC방 대신 찾은 곳이 호텔. 소수의 친구들이 호텔방에서 자는 것까지는 당국도 막지 못했다. 그러자 이젠 호텔들이 아예 나서서 이런 젊은이들을 위한 시설을 만들기 시작했다. 최신 컴퓨터와 키보드, 마우스는 물론이고 아예 우주선 분위기가 나도록 객실을 꾸며서 SF 속에 들어온 기분이 나게 했다.\n중국의 게임호텔 https://www.bloomberg.com/news/articles/2024-11-22/china-gamers-playing-league-of-legends-pubg-drive-demand-for-esports-hotels\n\n\n\n에너지 드링크와 컵라면이 한쪽에 구비되어 있고, 배달음식 주문도 가능해서, 한 번 팀이 입장하면 주말 2박3일 정도를 보내는 건 일도 아니라고. 기사에는 토요일에 입실했다가 연장에 연장을 거듭해 8일을 묵은 투숙객 이야기도 나온다. 예전에는 서양 게임 기자들이 한국의 PC방 문화를 취재하겠다며 한국을 찾기도 했는데, 이젠 다들 중국으로 향하는 듯.\n\n\n\n\n보이스피싱 사기꾼을 속여먹자!\n가끔 주위의 연로하신 부모님이나 노인 분들이 보이스피싱 사기꾼들의 손쉬운 먹잇감이 되는 걸 보고 답답할 때가 있다. 세계 어디를 가도 마찬가지인 모양인데, 그래서 영국의 통신사 O2가 재미있는 일을 벌였다. AI를 이용해 데이지 해리스라는 이름의 가짜 할머니를 만든 것. 데이지 할머니는 고양이 한마리를 키우고, 뜨개질을 좋아하신다. 인터넷과 컴퓨터는 잘 몰라서 설명을 길게 해줘야 알아듣는다는 설정.\n데이지 할머니와 고양이 플러피. https://www.nytimes.com/2024/11/25/technology/ai-granny-phone-scam.html\nO2는 데이지 할머니가 보이스피싱 사기꾼들과 최대한 오래 통화를 하면서 이들의 시간을 빼앗기를 기대하고 있다. 사기꾼들이 할머니를 속여보려고 오래 시간을 끌수록, 그만큼 선량한 사람들의 피해가 줄어들 테니까. 실제로 세 명으로 구성된 사기꾼 집단이 데이지 할머니에게 “일단 주소창에 www를 치시고요!”라는 간단한 작업을 성공시킬 때까지 3시간이 걸릴 정도였다.\n데이지 할머니의 캐릭터는 가상으로 창조된 것이지만, 목소리 모델만큼은 개발팀원 중 한 명의 실제 할머니에게 부탁해 함께 차를 마시며 나눈 대화 속 목소리를 사용해 합성했다고 한다. 진짜 할머니처럼 얘기하려면 진짜 할머니가 얘기해야지, 전문 성우들로는 진정성을 느끼기 힘들다고 생각한 듯. O2가 실제로 얼마나 많은 보이스피싱을 예방했는지는 알 수 없지만, 적어도 마케팅 하나 만큼은 제대로 했다.\n\n\n\n\n쿠팡이 제일 싼 이유\n올해 최악, 어쩌면 최근 10년 내 최악의 이커머스 악재가 될 티메프 사태가 벌어진 뒤 오픈마켓 판매자들의 삶도 많이 달라졌다. 가장 직접적인 변화가 쿠팡과 네이버로의 쏠림일 텐데, 대금을 떼일 수 있다는 불안이 판매자들을 쿠팡과 네이버로 내몰았다.\nhttps://stibee.com/api/v1.0/emails/share/x1aUfv1plACixQdnaoOnD_eRpsWmgBM\n\n\n\n문제는 쿠팡의 가격 정책. 이 회사는 최저가 정책을 고수하는데, 경쟁 이커머스보다 쿠팡 판매가격이 같거나 낮지 않으면 입점 퇴출도 불사할 정도로 공격적인 것으로 유명하다. 소비자 입장에서야 쿠팡에서 물건을 사면 적어도 다른 곳보다 비쌀 일은 없다는 편한 일이지만, 판매자 입장에선 피를 말린다. 매출 대부분이 쿠팡에서 나오는데 퇴출되면 큰일이기 때문. 문제는 11번가나 옥션 같은 곳에 10% 정도 비싼 가격을 매겨뒀는데, 이런 플랫폼들이 자체 비용으로 15%할인을 일괄적으로 때릴 때다. 역시 11번가나 옥션 소비자 입장에선 싸니까 좋지만, 판매자들은 자기가 가격을 높여뒀는데도 갑자기 쿠팡에서 제품이 내려가면 황당해진다. 해명하고 복구될 때까지의 시간이 며칠 걸리는데 마침 그 때가 대목이라면 손실은 더 불어난다.\n그래서 쿠팡을 주력 채널로 삼는 많은 판매자들이 다른 플랫폼 가격은 아예 쿠팡보다 두배씩 비싸게 책정한다는 얘기다. 이래야 제아무리 경쟁 채널이 가격 할인을 한다 해도 쿠팡의 최저가 조건을 지킬 수 있기 때문에. 이런 식의 영업 활동은 결국 대형 플랫폼으로 더욱 쏠리는 현상으로 이어질 테고, 그만큼 판매자들의 플랫폼 의존도도 높아질 수밖에 없다. 고객에게 좋은 건 모두에게 좋은 것이라는 아마존식 사업 방식에 바이든 정부 시절의 미국 연방거래위원회가 “No more”라고 경고했던 이유도 이런 탓.\n\n\n\n\n메타가 지구를 한바퀴 휘감는다\n지구 한바퀴의 둘레는 약 4만km. 메타(페이스북, 인스타그램의 모회사)가 이 정도 길이의 해저케이블을 바다 밑에 직접 설치할 계획이다. 우리가 평소에는 공기처럼 잘 느끼지 못하는 일이지만, 지금 이 순간에도 국가 사이를 오가는 수많은 데이터의 99%는 해저케이블을 통해 이동한다. 스타링크 같은 위성인터넷이 세계를 우주에서 연결한다고 해봐야 그 기여는 아주 미미한 수준.\n해저케이블은 1850년 영국과 프랑스 사이의 도버 해협을 연결하는 전선이 그 첫 시작이었는데, 당시에는 지금처럼 영상과 다양한 정보를 실어보내는 능력은 없었고, 전보를 보내기 위한 몇 글자를 전송하는 게 고작이었다. 이후 200년도 지나지 않아서 우리는 지구 반대편의 지인들과 실시간 영상 회의를 하고, 스포츠 중계를 전송하며, 인공지능에게 일을 시킨다. 이게 겨우 2~5cm 굵기의 얇은 광섬유 전선에 위태롭게 의존하는 일.\n세계 해저케이블 지도 https://www.submarinecablemap.com\n\n\n\n하지만 얇은 전선이라 해도 태평양과 대서양을 가로지르려면 쉽지 않은 일이라 지금까지는 세계 대형 통신사들이 컨소시엄을 만들어 전선과 선박, 잠수함을 구입해 함께 해저케이블을 설치했다. 여기에 처음 변화를 준 건 구글이었는데, 처음엔 통신사 컨소시엄에 자기들도 끼워달라 하더니 최근 10년 사이엔 구글의 자본만으로 직접 설치하는 해저케이블을 급격히 늘렸다. 통신사들이 어지간한 빅테크들에게는 망사용료를 내라며 으름장을 놓으면서도 구글에겐 별 소리 못하는 게 구글은 자체 통신망을 갖고 있어서 통신사의 협박을 별로 심각하게 듣지 않기 때문이다.\n메타도 이걸 유심히 지켜보다가 직접 케이블을 깔겠다고 나선 것. 아래 그림처럼 세계를 W로 휘감는 케이블이 될텐데, 미국 동부 해안에서 시작해 남아공을 거쳐 인도를 지나 호주를 통과한 다음 미국 서부로 오는 경로다. 이 경로의 장점은 분쟁이 잦은 지역을 다 피한다는 것. 위에 있는 기존 해저케이블 지도를 보면 대부분의 경로가 북반구에 집중돼 있다. 미국과 유럽, 미국과 동아시아, 유럽과 아시아 등 인구밀집 지역에 비용효율을 위해 최단거리로 설치했기 때문이다.\nhttps://techcrunch.com/2024/11/29/meta-plans-to-build-a-10b-subsea-cable-spanning-the-world-sources-say/\n\n\n\n하지만 최근 발트해 해저케이블이 끊어졌는데 배후에 러시아가 있다는 얘기가 나오고, 중동에서는 후티 반군의 테러로 해저케이블에 문제가 빈번히 발생하고 있으며, 싱가포르를 지나는 말라카 해협은 세계 최대의 해적 활동지로 악명이 높다. 즉, 대부분의 케이블이 지나는 바다에서 케이블이 끊어질 확률도 가장 높다. 메타의 케이블은 의도한 것처럼 이런 지역들을 모두 피한다.\n너무 나간 상상일 수도 있겠지만, 이런 관측들이 나온다. 첫째, 분쟁이 심해져서 케이블 단선이 빈번해지면 이젠 메타가 통신사에게 망사용료를 내는 대신 우회 트래픽 경로가 당장 필요한 통신사들이 메타에게 망사용료를 내게 될 수 있다.(이미 구글은 일부 이런 우월적 지위를 확보했다.) 둘째, 이 경로는 미국과 인도를 잇는 최단거리 통신망이다. 즉, 데이터센터와 기술 인재, 안정적 정치상황 등을 갖춘 인도의 테크 시장을 미국의 메타와 물리적으로 연결하는 케이블이 될 수 있다. 여기에 들어가는 돈이 100억 달러, 한화로 14조 원 규모다. 23년 LG유플러의 매출(이익 아님) 전체가 약 14조 원 정도 된다. 영업이익 기준으로 따지면 통신3사가 3년 동안 버는 이익을 전부 투자해도 100억 달러가 못 된다. 어마어마한 규모다.",
        "dc:creator": "김상훈",
        "comments": "https://interpiler.com/2024/12/02/weekly-ic-2/#respond",
        "content": "PC방 대신 게임호텔 중국 젊은이들은 게임을 할 때 PC방 대신 호텔에서 모인다. 온라인 게임의 특성상 친구들과 모여서 함께 게임을 하는 게 즐거우니 중국 젊은이들도 과거에는 PC방을 찾았는데, 코로나19 때 집합금지 명령으로 PC방 문화가 사라졌다고. 하지만 중국에는 &#8220;위에서 정책을 만들면 아래에선 대책을 만든다(上有政策 下有對策)&#8221;는 말이 있다. PC방 대신 찾은 곳이 호텔. 소수의 친구들이 호텔방에서 자는 것까지는 &#8230; <a href=\"https://interpiler.com/2024/12/02/weekly-ic-2/\" class=\"more-link\">계속 읽기 <span class=\"screen-reader-text\">Weekly IC #2</span> <span class=\"meta-nav\">\t</span></a>",
        "contentSnippet": "PC방 대신 게임호텔 중국 젊은이들은 게임을 할 때 PC방 대신 호텔에서 모인다. 온라인 게임의 특성상 친구들과 모여서 함께 게임을 하는 게 즐거우니 중국 젊은이들도 과거에는 PC방을 찾았는데, 코로나19 때 집합금지 명령으로 PC방 문화가 사라졌다고. 하지만 중국에는 “위에서 정책을 만들면 아래에선 대책을 만든다(上有政策 下有對策)”는 말이 있다. PC방 대신 찾은 곳이 호텔. 소수의 친구들이 호텔방에서 자는 것까지는 … 계속 읽기 Weekly IC #2",
        "guid": "http://interpiler.com/?p=1586",
        "categories": [
          "That's IT"
        ],
        "isoDate": "2024-12-02T06:30:36.000Z"
      }
    ]
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": [
      {
        "title": "🤔 2025년도에도 개발자들은 코루틴 예외 처리 때문에 밤샘각? 😨 이 글 보면 완전 정복 가능(2025학년도 안드로이드 탐구영역 문제풀이)",
        "link": "https://thdev.tech/coroutines/2024/12/08/Kotlin-Coroutines-effect-exception/",
        "pubDate": "Sun, 08 Dec 2024 00:00:00 +0000",
        "content": "<p>이 글은 2025 안드로이드 탐구 영역에 나온 문제 중 일부를 해석하는 글의 형태로 작성합니다. 문제 전체를 담지 않고, 중요한 해설을 작성합니다.</p>\n\n<h4>안드로이드 탐구 영역 후기 글</h4>\n<ul>\n  <li><a href=\"https://android-exam25.gdg.kr/\">2025학년도 안드로이드 탐구영역 - link</a></li>\n  <li><a href=\"https://medium.com/@lucas.kang/2025%ED%95%99%EB%85%84%EB%8F%84-%EC%95%88%EB%93%9C%EB%A1%9C%EC%9D%B4%EB%93%9C-%ED%83%90%EA%B5%AC%EC%98%81%EC%97%AD%EC%9D%84-%EC%A4%80%EB%B9%84%ED%95%98%EB%A9%B0-feabccc2b0cc\">2025학년도 안드로이드 탐구영역을 준비하며(경완님 작성) - link</a></li>\n</ul>\n\n<h3>어떤 문제일까?</h3>\n\n<p>코루틴 Exception 발생 시 예외 범위를 물어보는 질문에 대한 해석을 담는 글이다.</p>\n\n<p>대략 적어보면</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>- 최상위 Job A는 viewModelScope.launch로 생성되고 내부에서 B, C를 생성한다.\n- B에서는 coroutineScope 내에서 D, E를 생성한다.\n- C에서는 withContext(Dispatchers.IO) 내에서 F를 생성한다.\n\n모든 Job이 Finish 되었다고 가정\n</code></pre></div></div>\n\n<p>A-F까지 모두 Job이 리턴된다는 사실과 모든 Job이 동작 완료되었을 때를 가정한다.</p>\n\n<p>이 부분에 대한 글은 이미 과거에도 작성했어서 링크를 추가해두겠다.</p>\n\n<ul>\n  <li><a href=\"https://thdev.tech/kotlin/2019/04/08/Init-Coroutines-Job/\">Kotlin Coroutines의 Job 동작을 알아보자</a></li>\n  <li><a href=\"https://thdev.tech/kotlin/2019/04/30/Coroutines-Job-Exception/\">Kotlin Coroutines Exception 영향도 알아보기</a></li>\n</ul>\n\n<p>이 두 개의 글을 이해한다면 사실 해석할 필요도 없지만, 새로운 마음으로 글을 적어본다.</p>\n\n<h3>이 글에서는</h3>\n<ul>\n  <li>2025 안드로이드 탐구 영역에 나온 문제 일부를 정리한다.</li>\n  <li>Job에 대한 이해가 필요하다.</li>\n</ul>\n\n<!--more-->\n\n<h2>문제의 해석</h2>\n\n<p>모든 실행에서 Job을 가지려면 <code class=\"language-plaintext highlighter-rouge\">launch {}</code>를 통해 새로운 작업을 실행해야 한다는 점이다.</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">async</code>는 DeffDeferred T를 리턴하기에 적절하지 않은 실행에 해당하기에 코드로 작성하면 아래와 같다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// A의 실행</span>\n<span class=\"n\">viewModelScope</span><span class=\"p\">.</span><span class=\"nf\">launch</span> <span class=\"p\">{</span>\n    <span class=\"c1\">// B의 실행</span>\n    <span class=\"nf\">launch</span> <span class=\"p\">{</span>\n        <span class=\"nf\">coroutineScope</span> <span class=\"p\">{</span>\n            <span class=\"c1\">// D의 실행</span>\n            <span class=\"nf\">launch</span> <span class=\"p\">{</span> <span class=\"p\">}</span>\n            <span class=\"c1\">// E의 실행</span>\n            <span class=\"nf\">launch</span> <span class=\"p\">{</span> <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n    <span class=\"c1\">// C의 실행</span>\n    <span class=\"nf\">launch</span> <span class=\"p\">{</span>\n        <span class=\"nf\">withContext</span><span class=\"p\">(</span><span class=\"nc\">Dispatchers</span><span class=\"p\">.</span><span class=\"nc\">IO</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n            <span class=\"c1\">// F의 실행</span>\n            <span class=\"nf\">launch</span> <span class=\"p\">{</span> <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>이 문제를 해석할 때 주의할 점이 하나 있다.</p>\n\n<p>Coroutine builder로 실행하는 경우 부모의 CoroutineContext는 하위(자식) 모두 상속받는 것이 아니라는 점이다. 코드를 추적하면 fold를 통해 합산한다.</p>\n\n<p>단, Job은 상속받지 않는데 다음과 같은 이유로 제미나이의 설명이다.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>만약 Job이 상속된다면, 부모 코루틴의 Job이 취소될 때 자식 코루틴도 함께 취소됩니다. 이는 각 코루틴의 생명주기를 개별적으로 관리하기 어렵게 만듭니다. 각 코루틴이 독립적인 Job을 가지도록 함으로써, 코루틴의 취소와 생명주기 관리를 더욱 유연하게 제어할 수 있습니다.\n</code></pre></div></div>\n\n<p>결국 필요한 것만 합산하고 치환할 수 있으며, Job은 예외로 상속받지 않는다.</p>\n\n<p><br /></p>\n\n<h2>함정도 찾아보자.</h2>\n\n<p>이 문제에는 2가지 함정이 있다. 바로 <code class=\"language-plaintext highlighter-rouge\">coroutineScope</code>과 <code class=\"language-plaintext highlighter-rouge\">withContext(Dispatchers.IO)</code>이다.</p>\n\n<p>이 코드에서는 사실 아무런 의미가 없다. 어차피 <code class=\"language-plaintext highlighter-rouge\">launch {}</code>를 통해 코드를 실행하기 때문에 <code class=\"language-plaintext highlighter-rouge\">blocking</code>을 만드는 <code class=\"language-plaintext highlighter-rouge\">coroutineScope</code>과 <code class=\"language-plaintext highlighter-rouge\">withContext(Dispatchers.IO)</code> 코드의 사용은 의미가 없고 함정을 만들기 위한 코드 설명이라는 점이다.</p>\n\n<ul>\n  <li><a href=\"https://kotlinlang.org/api/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/coroutine-scope.html\">coroutineScope - link</a></li>\n  <li><a href=\"https://kotlinlang.org/api/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/with-context.html\">withContext - link</a></li>\n</ul>\n\n<p><br /></p>\n\n<h2>Job?</h2>\n\n<p>Job에는 크게 2개 있다.</p>\n\n<p>그냥 <a href=\"https://kotlinlang.org/api/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/-job/\">Job - link</a>과 <a href=\"https://kotlinlang.org/api/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/-supervisor-job.html\">SupervisorJob - link</a>을 가진다.</p>\n\n<p>이 둘은 딱 하나의 차이가 있는데, 하위 Job에서 발생하는 Exception 케이스로 인해 부모가 영향을 받는가 아닌가이다.</p>\n\n<p>이전 글에서도 작성했지만 <a href=\"https://thdev.tech/kotlin/2019/04/30/Coroutines-Job-Exception/\">Kotlin Coroutines Exception 영향도 알아보기</a>를 줄이기 위해서는 SupervisorJob을 활용하는 것이 적합하다.</p>\n\n<p>다행히 android viewModelScope은 <code class=\"language-plaintext highlighter-rouge\">SupervisorJob</code>을 기본으로 활용하고 있다.</p>\n\n<p>Job은 라이프 사이클도 가지고 있는데 아래의 그림과 같다.</p>\n\n<p><img src=\"/images/posts/2024/Kotlin-Coroutines-Effect/sample_01.png\" alt=\"sample_01\" /></p>\n\n<p>이 부분을 꼭 기억할 이유는 없지만 <code class=\"language-plaintext highlighter-rouge\">cancel/fail</code> 처리 시 <code class=\"language-plaintext highlighter-rouge\">Cancelled</code> 상태로 변경된다는 점이 중요한 부분이다.</p>\n\n<p>이걸 알지 않더라도 코루틴에서는 exception 발생 시 <code class=\"language-plaintext highlighter-rouge\">runCatch</code>만 잘 걸어도 문제가 없으며, 오류가 발생하더라도 재시도 가능하다는 점이 중요한 포인트 아닐까 싶다.</p>\n\n<p><br /></p>\n\n<h2>문제의 해석은 끝났다.</h2>\n\n<p>위에서 적은 내용만 알면 사실문제 해석은 완료되었다.</p>\n\n<p>문제에서 도출한 내용의 코드는 아래와 같은데,</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// A의 실행</span>\n<span class=\"n\">viewModelScope</span><span class=\"p\">.</span><span class=\"nf\">launch</span> <span class=\"p\">{</span>\n    <span class=\"c1\">// B의 실행</span>\n    <span class=\"nf\">launch</span> <span class=\"p\">{</span>\n        <span class=\"nf\">coroutineScope</span> <span class=\"p\">{</span>\n            <span class=\"c1\">// D의 실행</span>\n            <span class=\"nf\">launch</span> <span class=\"p\">{</span> <span class=\"p\">}</span>\n            <span class=\"c1\">// E의 실행</span>\n            <span class=\"nf\">launch</span> <span class=\"p\">{</span> <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n    <span class=\"c1\">// C의 실행</span>\n    <span class=\"nf\">launch</span> <span class=\"p\">{</span>\n        <span class=\"nf\">withContext</span><span class=\"p\">(</span><span class=\"nc\">Dispatchers</span><span class=\"p\">.</span><span class=\"nc\">IO</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n            <span class=\"c1\">// F의 실행</span>\n            <span class=\"nf\">launch</span> <span class=\"p\">{</span> <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>여기에서 어떠한 위치에서 오류가 발생하더라도 서로 영향을 미치지 않아야 한다.</p>\n\n<p>그러니 총 6개의 작업 중 하나의 <code class=\"language-plaintext highlighter-rouge\">fail</code>이 난다면 5개의 작업만이 성공한 것이며, 그중 1개가 <code class=\"language-plaintext highlighter-rouge\">fail</code>이 기에 실패한 케이스는 1개이라는 점이다.</p>\n\n<p>F에서 exception이 발생하였다고 하더라도 C에는 영향을 미치지 않으며, A 역시 동작에 문제가 없다는 점이다.</p>\n\n<p><br /></p>\n\n<h2>그래도 궁금하잖아</h2>\n\n<p>그럼 위 코드에서 일부의 작업을 Job()로 다시 변경하면 영향은 어떻게 달라질까?</p>\n\n<p>앞서 적었던 코드에 B의 작업에 <code class=\"language-plaintext highlighter-rouge\">Job()</code>으로 치환하면 어떤 일이 벌어질까?</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// A의 실행</span>\n<span class=\"nc\">CoroutinesScope</span><span class=\"p\">(</span><span class=\"nc\">SupervisorJob</span><span class=\"p\">()).</span><span class=\"nf\">launch</span> <span class=\"p\">{</span>\n    <span class=\"c1\">// B의 실행</span>\n    <span class=\"nf\">launch</span><span class=\"p\">(</span><span class=\"nc\">Job</span><span class=\"p\">())</span> <span class=\"p\">{</span> <span class=\"c1\">// Job으로 변경</span>\n        <span class=\"c1\">// D의 실행</span>\n        <span class=\"nf\">launch</span> <span class=\"p\">{</span> <span class=\"k\">throw</span> <span class=\"nc\">Exception</span><span class=\"p\">(</span><span class=\"s\">\"exception\"</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n        <span class=\"c1\">// E의 실행</span>\n        <span class=\"nf\">launch</span> <span class=\"p\">{</span> <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n    <span class=\"c1\">// C의 실행</span>\n    <span class=\"nf\">launch</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// F의 실행</span>\n        <span class=\"nf\">launch</span> <span class=\"p\">{</span> <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>정답은 간단하다.</p>\n\n<ul>\n  <li>A는 영향받지 않는다.</li>\n  <li>B는 D/E의 작업 실패에 대한 영향을 받는다.</li>\n  <li>C는 B 또는 F의 작업에 영향받지 않는다.</li>\n</ul>\n\n<p>이런 이유는 제미나이에서 설명한 Job의 예외 설명에서 충분히 잘 나온다.</p>\n\n<p><br /></p>\n\n<h2>간단한 원리</h2>\n\n<p>내부를 알아야 이 원리를 알 수 있는 건 아니다. 테스트해보고도 알 수 있긴 하다. 내부 코드 다 까보고 <code class=\"language-plaintext highlighter-rouge\">SupervisorJob</code>을 알아야 하는 걸까? 거기에 가면 무슨 코드에 따라서 동작할까?</p>\n\n<p>사실 더 깊이 갈 것도 없이 명확하게 아래와 같이 <code class=\"language-plaintext highlighter-rouge\">childCancelled</code>란 코드를 바로 볼 수 있다.</p>\n\n<p>Job과 딱 하나 다르다는 이야기다. 이를 활용하는 부분을 찾으려면 더 깊이 들어가 봐야겠지만 기본은 아래와 같다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">private</span> <span class=\"kd\">class</span> <span class=\"nc\">SupervisorJobImpl</span><span class=\"p\">(</span><span class=\"n\">parent</span><span class=\"p\">:</span> <span class=\"nc\">Job</span><span class=\"p\">?)</span> <span class=\"p\">:</span> <span class=\"nc\">JobImpl</span><span class=\"p\">(</span><span class=\"n\">parent</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">override</span> <span class=\"k\">fun</span> <span class=\"nf\">childCancelled</span><span class=\"p\">(</span><span class=\"n\">cause</span><span class=\"p\">:</span> <span class=\"nc\">Throwable</span><span class=\"p\">):</span> <span class=\"nc\">Boolean</span> <span class=\"p\">=</span> <span class=\"k\">false</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>D 작업에서 오류가 발생하였다면 D의 상위인 B Job에 통지가 간다. 이때 <code class=\"language-plaintext highlighter-rouge\">childCancelled</code>의 정보를 무시할 것인지 결정하는 옵션에 따라 무시하거나, 예외 처리를 발생시키게 된다.</p>\n\n<p>무시하면 통지 만 받는 것이며, 무시하지 않는다면 코드상 오류를 발생시키고, 상위로 또 전달한다.</p>\n\n<p>Job을 상속받지 않는 것이지, 기본 cancelled 정보 전달 여부는 따른다는 것이다.</p>\n\n<p>지금 현재의 Job과 Parent Job을 모두 가지고 소통한다는 점을 알 수 있다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">_parentHandle</span> <span class=\"p\">=</span> <span class=\"n\">atomic</span><span class=\"p\">&lt;</span><span class=\"nc\">ChildHandle</span><span class=\"p\">?&gt;(</span><span class=\"k\">null</span><span class=\"p\">)</span>\n<span class=\"k\">internal</span> <span class=\"kd\">var</span> <span class=\"py\">parentHandle</span><span class=\"p\">:</span> <span class=\"nc\">ChildHandle</span><span class=\"p\">?</span>\n    <span class=\"k\">get</span><span class=\"p\">()</span> <span class=\"p\">=</span> <span class=\"n\">_parentHandle</span><span class=\"p\">.</span><span class=\"n\">value</span>\n    <span class=\"k\">set</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"n\">_parentHandle</span><span class=\"p\">.</span><span class=\"n\">value</span> <span class=\"p\">=</span> <span class=\"n\">value</span> <span class=\"p\">}</span>\n\n<span class=\"k\">override</span> <span class=\"kd\">val</span> <span class=\"py\">parent</span><span class=\"p\">:</span> <span class=\"nc\">Job</span><span class=\"p\">?</span>\n    <span class=\"k\">get</span><span class=\"p\">()</span> <span class=\"p\">=</span> <span class=\"n\">parentHandle</span><span class=\"o\">?.</span><span class=\"n\">parent</span>\n</code></pre></div></div>\n\n<p><br /></p>\n\n<h2>마무리</h2>\n\n<p>간단하게 2025 안드로이드 탐구영역의 Exception 전파에 대해 정리하였다.</p>\n\n<p>이 문제를 알 수 있는 것은</p>\n<ul>\n  <li>Job은 <code class=\"language-plaintext highlighter-rouge\">cancel/fail</code> 발생 시 현재 상태를 <code class=\"language-plaintext highlighter-rouge\">Cancelled</code> 처리한다.</li>\n  <li>Job은 하위 context에 전달되지 않지만 Parent.job은 하위 Job에서도 별도로 관리한다.</li>\n  <li>SupervisorJob과 Job을 중간에 혼용해서 사용하는 경우에는 Job 부분은 모두 종료 처리한다.</li>\n  <li>launch로 실행할 경우 return 결과는 Job이 된다.</li>\n</ul>\n\n<p>Job과 SupervisorJob의 중요성을 이해할 수 있는 간단한 문제입니다.</p>\n\n",
        "contentSnippet": "이 글은 2025 안드로이드 탐구 영역에 나온 문제 중 일부를 해석하는 글의 형태로 작성합니다. 문제 전체를 담지 않고, 중요한 해설을 작성합니다.\n안드로이드 탐구 영역 후기 글\n2025학년도 안드로이드 탐구영역 - link\n2025학년도 안드로이드 탐구영역을 준비하며(경완님 작성) - link\n어떤 문제일까?\n코루틴 Exception 발생 시 예외 범위를 물어보는 질문에 대한 해석을 담는 글이다.\n대략 적어보면\n\n- 최상위 Job A는 viewModelScope.launch로 생성되고 내부에서 B, C를 생성한다.\n- B에서는 coroutineScope 내에서 D, E를 생성한다.\n- C에서는 withContext(Dispatchers.IO) 내에서 F를 생성한다.\n\n모든 Job이 Finish 되었다고 가정\n\n\nA-F까지 모두 Job이 리턴된다는 사실과 모든 Job이 동작 완료되었을 때를 가정한다.\n이 부분에 대한 글은 이미 과거에도 작성했어서 링크를 추가해두겠다.\nKotlin Coroutines의 Job 동작을 알아보자\nKotlin Coroutines Exception 영향도 알아보기\n이 두 개의 글을 이해한다면 사실 해석할 필요도 없지만, 새로운 마음으로 글을 적어본다.\n이 글에서는\n2025 안드로이드 탐구 영역에 나온 문제 일부를 정리한다.\nJob에 대한 이해가 필요하다.\n문제의 해석\n모든 실행에서 Job을 가지려면 launch {}를 통해 새로운 작업을 실행해야 한다는 점이다.\nasync는 DeffDeferred T를 리턴하기에 적절하지 않은 실행에 해당하기에 코드로 작성하면 아래와 같다.\n\n// A의 실행\nviewModelScope.launch {\n    // B의 실행\n    launch {\n        coroutineScope {\n            // D의 실행\n            launch { }\n            // E의 실행\n            launch { }\n        }\n    }\n    // C의 실행\n    launch {\n        withContext(Dispatchers.IO) {\n            // F의 실행\n            launch { }\n        }\n    }\n}\n\n\n이 문제를 해석할 때 주의할 점이 하나 있다.\nCoroutine builder로 실행하는 경우 부모의 CoroutineContext는 하위(자식) 모두 상속받는 것이 아니라는 점이다. 코드를 추적하면 fold를 통해 합산한다.\n단, Job은 상속받지 않는데 다음과 같은 이유로 제미나이의 설명이다.\n\n만약 Job이 상속된다면, 부모 코루틴의 Job이 취소될 때 자식 코루틴도 함께 취소됩니다. 이는 각 코루틴의 생명주기를 개별적으로 관리하기 어렵게 만듭니다. 각 코루틴이 독립적인 Job을 가지도록 함으로써, 코루틴의 취소와 생명주기 관리를 더욱 유연하게 제어할 수 있습니다.\n\n\n결국 필요한 것만 합산하고 치환할 수 있으며, Job은 예외로 상속받지 않는다.\n\n함정도 찾아보자.\n이 문제에는 2가지 함정이 있다. 바로 coroutineScope과 withContext(Dispatchers.IO)이다.\n이 코드에서는 사실 아무런 의미가 없다. 어차피 launch {}를 통해 코드를 실행하기 때문에 blocking을 만드는 coroutineScope과 withContext(Dispatchers.IO) 코드의 사용은 의미가 없고 함정을 만들기 위한 코드 설명이라는 점이다.\ncoroutineScope - link\nwithContext - link\n\nJob?\nJob에는 크게 2개 있다.\n그냥 Job - link과 SupervisorJob - link을 가진다.\n이 둘은 딱 하나의 차이가 있는데, 하위 Job에서 발생하는 Exception 케이스로 인해 부모가 영향을 받는가 아닌가이다.\n이전 글에서도 작성했지만 Kotlin Coroutines Exception 영향도 알아보기를 줄이기 위해서는 SupervisorJob을 활용하는 것이 적합하다.\n다행히 android viewModelScope은 SupervisorJob을 기본으로 활용하고 있다.\nJob은 라이프 사이클도 가지고 있는데 아래의 그림과 같다.\n\n이 부분을 꼭 기억할 이유는 없지만 cancel/fail 처리 시 Cancelled 상태로 변경된다는 점이 중요한 부분이다.\n이걸 알지 않더라도 코루틴에서는 exception 발생 시 runCatch만 잘 걸어도 문제가 없으며, 오류가 발생하더라도 재시도 가능하다는 점이 중요한 포인트 아닐까 싶다.\n\n문제의 해석은 끝났다.\n위에서 적은 내용만 알면 사실문제 해석은 완료되었다.\n문제에서 도출한 내용의 코드는 아래와 같은데,\n\n// A의 실행\nviewModelScope.launch {\n    // B의 실행\n    launch {\n        coroutineScope {\n            // D의 실행\n            launch { }\n            // E의 실행\n            launch { }\n        }\n    }\n    // C의 실행\n    launch {\n        withContext(Dispatchers.IO) {\n            // F의 실행\n            launch { }\n        }\n    }\n}\n\n\n여기에서 어떠한 위치에서 오류가 발생하더라도 서로 영향을 미치지 않아야 한다.\n그러니 총 6개의 작업 중 하나의 fail이 난다면 5개의 작업만이 성공한 것이며, 그중 1개가 fail이 기에 실패한 케이스는 1개이라는 점이다.\nF에서 exception이 발생하였다고 하더라도 C에는 영향을 미치지 않으며, A 역시 동작에 문제가 없다는 점이다.\n\n그래도 궁금하잖아\n그럼 위 코드에서 일부의 작업을 Job()로 다시 변경하면 영향은 어떻게 달라질까?\n앞서 적었던 코드에 B의 작업에 Job()으로 치환하면 어떤 일이 벌어질까?\n\n// A의 실행\nCoroutinesScope(SupervisorJob()).launch {\n    // B의 실행\n    launch(Job()) { // Job으로 변경\n        // D의 실행\n        launch { throw Exception(\"exception\") }\n        // E의 실행\n        launch { }\n    }\n    // C의 실행\n    launch {\n        // F의 실행\n        launch { }\n    }\n}\n\n\n정답은 간단하다.\nA는 영향받지 않는다.\nB는 D/E의 작업 실패에 대한 영향을 받는다.\nC는 B 또는 F의 작업에 영향받지 않는다.\n이런 이유는 제미나이에서 설명한 Job의 예외 설명에서 충분히 잘 나온다.\n\n간단한 원리\n내부를 알아야 이 원리를 알 수 있는 건 아니다. 테스트해보고도 알 수 있긴 하다. 내부 코드 다 까보고 SupervisorJob을 알아야 하는 걸까? 거기에 가면 무슨 코드에 따라서 동작할까?\n사실 더 깊이 갈 것도 없이 명확하게 아래와 같이 childCancelled란 코드를 바로 볼 수 있다.\nJob과 딱 하나 다르다는 이야기다. 이를 활용하는 부분을 찾으려면 더 깊이 들어가 봐야겠지만 기본은 아래와 같다.\n\nprivate class SupervisorJobImpl(parent: Job?) : JobImpl(parent) {\n    override fun childCancelled(cause: Throwable): Boolean = false\n}\n\n\nD 작업에서 오류가 발생하였다면 D의 상위인 B Job에 통지가 간다. 이때 childCancelled의 정보를 무시할 것인지 결정하는 옵션에 따라 무시하거나, 예외 처리를 발생시키게 된다.\n무시하면 통지 만 받는 것이며, 무시하지 않는다면 코드상 오류를 발생시키고, 상위로 또 전달한다.\nJob을 상속받지 않는 것이지, 기본 cancelled 정보 전달 여부는 따른다는 것이다.\n지금 현재의 Job과 Parent Job을 모두 가지고 소통한다는 점을 알 수 있다.\n\nprivate val _parentHandle = atomic<ChildHandle?>(null)\ninternal var parentHandle: ChildHandle?\n    get() = _parentHandle.value\n    set(value) { _parentHandle.value = value }\n\noverride val parent: Job?\n    get() = parentHandle?.parent\n\n\n\n마무리\n간단하게 2025 안드로이드 탐구영역의 Exception 전파에 대해 정리하였다.\n이 문제를 알 수 있는 것은\nJob은 cancel/fail 발생 시 현재 상태를 Cancelled 처리한다.\nJob은 하위 context에 전달되지 않지만 Parent.job은 하위 Job에서도 별도로 관리한다.\nSupervisorJob과 Job을 중간에 혼용해서 사용하는 경우에는 Job 부분은 모두 종료 처리한다.\nlaunch로 실행할 경우 return 결과는 Job이 된다.\nJob과 SupervisorJob의 중요성을 이해할 수 있는 간단한 문제입니다.",
        "guid": "https://thdev.tech/coroutines/2024/12/08/Kotlin-Coroutines-effect-exception/",
        "isoDate": "2024-12-08T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕홍",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": [
      {
        "creator": "고명환",
        "title": "강의안 | 2025 창업에 필요한 소비트렌드 정보 - 창업",
        "link": "https://brunch.co.kr/@@LOc/239",
        "pubDate": "Thu, 05 Dec 2024 13:15:27 GMT",
        "author": "고명환",
        "content": "1. 2025 창업에 필요한 소비트렌드 정보 - Sample ​ ​ 2. 2025 창업에 필요한 소비트렌드 정보 - 전체 강의안 ​ https://docs.google.com/presentation/d/e/2PACX-1vSJodpPKdxtRVvIsbc9fUyMXiESlia_D0_Rzxs0fR18uMk7n9qGKLE56f_lReQitg/pub?start=fa<img src= \"https://img1.daumcdn.net/thumb/R1280x0.fjpg/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2Fy4SkwBUN5BewBNG6mW2aq0qOBQ0.JPG\" width=\"500\" />",
        "contentSnippet": "1. 2025 창업에 필요한 소비트렌드 정보 - Sample ​ ​ 2. 2025 창업에 필요한 소비트렌드 정보 - 전체 강의안 ​ https://docs.google.com/presentation/d/e/2PACX-1vSJodpPKdxtRVvIsbc9fUyMXiESlia_D0_Rzxs0fR18uMk7n9qGKLE56f_lReQitg/pub?start=fa",
        "guid": "https://brunch.co.kr/@@LOc/239",
        "isoDate": "2024-12-05T13:15:27.000Z"
      }
    ]
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김놀부",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "안드로이드 추천 앱, 추천 어플 (24.12.09) 맛집예약, 식당예약, 공연애매, 티켓 예매, 교통사고 합의금 계산, 수능 기출문제, 피아노 연습, 악보읽기",
        "link": "http://muzbox.tistory.com/483509",
        "pubDate": "Mon, 9 Dec 2024 08:49:49 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483509#entry483509comment",
        "content": "<p data-ke-size=\"size16\">구글 플레이 스토어의 수많은 앱 중, 유용하고 안전한 앱을 엄선해 매주 소개합니다. 신뢰할 수 있는 앱 리뷰를 확인하세요.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"241209 추천앱.png\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/Kdn7J/btsLaxeSoe1/aXRcEKHgksjpM5LjG6vSO0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Kdn7J/btsLaxeSoe1/aXRcEKHgksjpM5LjG6vSO0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/Kdn7J/btsLaxeSoe1/aXRcEKHgksjpM5LjG6vSO0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FKdn7J%2FbtsLaxeSoe1%2FaXRcEKHgksjpM5LjG6vSO0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"241209 추천앱.png\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;안드로이드 앱스토어인 구글 플레이 스토어에는 하루에도 엄청난 수의 앱과 게임이 신규로 등록됩니다. 이 모든앱들을 사용자가 확인하고 양질의 앱을 선택하는 것이 사실상 불가능 하다는 얘기죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">또한, 최근들어 강화되었다 하지만 여전히 구글 플레이스토어에는 유해한 앱들이 사라지지 않고 이들 앱으로 피해를 보는 사용자도 많습니다.본 블로그에서는 일주일에 한번정도 운영자가 직접 유용하고 편리한 앱을 엄선하여 소개합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: center;\" data-ke-size=\"size16\"><span style=\"color: #ee2323;\"><b>'어떤오후의 프리웨어 이야기'에서 추천하는 2024년 12월 9일자 '안드로이드 추천 앱'입니다.</b></span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000;\" data-ke-size=\"size26\"><b>1. 캐치테이블<br /></b></h2>\n<p data-ke-size=\"size16\">&nbsp;21년 구글 '올해를 빛낸 앱'과 2022년 앱스토어 '오늘의 앱'에 선정된 인기 맛집 예약 및 웨이팅 앱으로, 300만 이상의 사용자가 선택한 서비스입니다. 10,000여 개의 파인다이닝, 핫플 맛집을 포함해 예약과 웨이팅 서비스를 제공하며, 지역, 편의시설, 방문 목적, 프로그램명 등을 기반으로 한 편리한 검색 기능을 갖추고 있습니다. 사용자는 전화 없이도 앱에서 24시간 온라인 예약이 가능하며, 인기 맛집에 긴 웨이팅 없이 입장할 수 있도록 돕습니다. 또한, 할인 티켓을 통해 스시야와 스테이크 같은 다양한 메뉴를 저렴하게 즐길 수 있습니다. <br /><br />&nbsp; 다양한 필터와 실시간 리뷰를 통해 맞춤형 맛집 정보를 제공합니다. 사용자는 방문 목적, 인원, 가격대, 음식 종류, 테이블 타입 등을 선택해 자신에게 딱 맞는 맛집을 찾을 수 있으며, 150만 개 이상의 실제 방문 리뷰를 통해 취향에 맞는 식당을 쉽게 발견할 수 있습니다. 또한, 베스트 메뉴, 가격, 발렛, 콜키지와 같은 세부 정보를 한눈에 확인할 수 있어 편리한 선택이 가능합니다. 예약 실패 시 빈자리 알림을 설정하거나, 웨이팅 미루기 기능으로 입장 순서를 조정하는 등 실용적인 기능도 제공됩니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"캐치테이블.jpg\" data-origin-width=\"760\" data-origin-height=\"1346\"><span data-url=\"https://blog.kakaocdn.net/dn/exhcm8/btsLbR4fJBW/ujnOmsLt0ylL9p61C4CchK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/exhcm8/btsLbR4fJBW/ujnOmsLt0ylL9p61C4CchK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/exhcm8/btsLbR4fJBW/ujnOmsLt0ylL9p61C4CchK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fexhcm8%2FbtsLbR4fJBW%2FujnOmsLt0ylL9p61C4CchK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"캐치테이블.jpg\" data-origin-width=\"760\" data-origin-height=\"1346\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<figure id=\"og_1733701669750\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"캐치테이블 - Google Play 앱\" data-og-description=\"인기 맛집, 핫플 예약부터 웨이팅까지 한번에!\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=co.kr.catchtable.android.catchtable_app\" data-og-url=\"https://play.google.com/store/apps/details?id=co.kr.catchtable.android.catchtable_app&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/FGGTu/hyXKqZ9NP2/iWuRzCdX6vR4GFK5Uk2zG0/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/t1f9V/hyXGNvWru7/LxQbV95DzOqe5hqM6LtOe0/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/cjVIjW/hyXKzpgVmL/bDikYbNpBSoa4mQYPQ9Py0/img.png?width=240&amp;height=240&amp;face=0_0_240_240\"><a href=\"https://play.google.com/store/apps/details?id=co.kr.catchtable.android.catchtable_app\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=co.kr.catchtable.android.catchtable_app\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/FGGTu/hyXKqZ9NP2/iWuRzCdX6vR4GFK5Uk2zG0/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/t1f9V/hyXGNvWru7/LxQbV95DzOqe5hqM6LtOe0/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/cjVIjW/hyXKzpgVmL/bDikYbNpBSoa4mQYPQ9Py0/img.png?width=240&amp;height=240&amp;face=0_0_240_240');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">캐치테이블 - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">인기 맛집, 핫플 예약부터 웨이팅까지 한번에!</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000;\" data-ke-size=\"size26\"><b>2. 타임티켓&nbsp;-&nbsp;마감임박&nbsp;공연/전시&nbsp;할인 <br /><br /></b></h2>\n<p data-ke-size=\"size16\">&nbsp;공연, 전시, 체험, 액티비티, 원데이클래스 등을 합리적인 가격에 제공하는 티켓 예매 플랫폼으로, 알뜰한 문화생활을 원하는 사용자들에게 최적의 선택입니다. 대학로 연극부터 리미티드런 뮤지컬, 다양한 체험 프로그램까지 폭넓은 티켓을 지원하며, 당일 할인 혜택과 타임세일을 통해 최대 90%까지 할인된 가격으로 티켓을 구매할 수 있습니다. 예매수수료가 없고, 간편한 현장 발권 시스템을 통해 사용자 편의를 극대화했습니다. 또한, 실시간 랭킹과 후기 시스템을 통해 사용자들은 인기 있는 공연과 전시를 한눈에 파악하고, 선택의 고민을 줄일 수 있습니다. <br /><br />&nbsp;타임티켓의 주요 특징 중 하나는 마감 임박 티켓을 추가 할인하는 '타임커머스'와 다양한 지역에서 제공되는 티켓 옵션입니다. 대학로, 강남, 홍대 등 서울 지역뿐만 아니라 경기도, 부산, 대구, 제주 등 전국적으로 다양한 문화상품과 액티비티를 만나볼 수 있습니다. 특히, 해설사와 함께하는 투어, 계절별 레저 활동, 커플 데이트를 위한 프로그램 등이 준비되어 있어 사용자의 다양한 취향을 만족시킵니다. 또한, 무료 초대 이벤트를 통해 공연 및 전시 티켓을 무료로 받을 기회도 제공하며, 영화보다 저렴한 가격에 고품질의 문화생활을 즐길 수 있도록 돕습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"타임티켓.jpg\" data-origin-width=\"760\" data-origin-height=\"1346\"><span data-url=\"https://blog.kakaocdn.net/dn/cBKy1S/btsLcKpNf74/DLFIZuK5i2J9fBVrGH3Am1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cBKy1S/btsLcKpNf74/DLFIZuK5i2J9fBVrGH3Am1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cBKy1S/btsLcKpNf74/DLFIZuK5i2J9fBVrGH3Am1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcBKy1S%2FbtsLcKpNf74%2FDLFIZuK5i2J9fBVrGH3Am1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"타임티켓.jpg\" data-origin-width=\"760\" data-origin-height=\"1346\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<figure id=\"og_1733701697078\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"타임티켓 - 마감임박 공연/전시 할인 - Google Play 앱\" data-og-description=\"대학로연극부터 뮤지컬/콘서트/전시회/체험/투어/레저/액티비티/원데이클래스까지! 마감임박 오늘할인과 최저가 타임세일로 즐기는 합리적인 문화생활!\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.app.timeticket\" data-og-url=\"https://play.google.com/store/apps/details?id=com.app.timeticket&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/bFLd12/hyXKqZ9NRA/Ss5pr4gHS81q26f8jeOMl1/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/dmuhGC/hyXKvAnERU/RCie1eJeW1OglvirZx2X2k/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/j9iBG/hyXKyYbrQY/2A00ks4iMRAo9kb67OKVa1/img.png?width=240&amp;height=240&amp;face=0_0_240_240\"><a href=\"https://play.google.com/store/apps/details?id=com.app.timeticket\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.app.timeticket\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/bFLd12/hyXKqZ9NRA/Ss5pr4gHS81q26f8jeOMl1/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/dmuhGC/hyXKvAnERU/RCie1eJeW1OglvirZx2X2k/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/j9iBG/hyXKyYbrQY/2A00ks4iMRAo9kb67OKVa1/img.png?width=240&amp;height=240&amp;face=0_0_240_240');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">타임티켓 - 마감임박 공연/전시 할인 - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">대학로연극부터 뮤지컬/콘서트/전시회/체험/투어/레저/액티비티/원데이클래스까지! 마감임박 오늘할인과 최저가 타임세일로 즐기는 합리적인 문화생활!</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000;\" data-ke-size=\"size26\"><b>3. 사고링크&nbsp;-&nbsp;교통사고&nbsp;합의금&nbsp;계산(상담,&nbsp;치료,&nbsp;수리) <br /></b></h2>\n<p data-ke-size=\"size16\">&nbsp;교통사고 및 일반사고 피해자들에게 보상 전문가의 무료 상담과 손해사정 서비스를 제공하는 플랫폼으로, 고객이 적절한 보상을 받을 수 있도록 돕습니다. 특히 교통사고의 경우, 사고링크는 25만 건 이상의 데이터를 활용한 빅데이터 알고리즘을 통해 예상 합의금을 산출하며, 보험사가 제시한 금액과 비교해 적절성을 검증할 수 있는 기능을 제공합니다. 단순한 사고라도 고객 입장에서 세심하게 상담하며, 심각한 피해가 발생한 경우에는 전문가의 직접 상담을 권장합니다. <br /><br />&nbsp;사고링크는 교통사고 피해자의 편의를 위한 다양한 서비스를 제공합니다. 차량 수리, 렌트, 병원 치료 등 사고 이후 필요한 모든 과정을 고객의 입장에서 지원하며, 상대 보험사의 이익이 아닌 피해자의 권리를 우선으로 합니다. 고객은 프라이빗 입원실, 한방 병원 등 최적의 치료 환경을 안내받을 수 있고, 전문 현장 기사의 도움을 받아 차량 수리와 대차 과정을 신뢰할 수 있습니다. 또한, 고객이 보험사와 직접 대면하지 않고도 정확한 보상금을 받을 수 있도록 상담과 지원을 제공합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"사고링크.jpg\" data-origin-width=\"760\" data-origin-height=\"1346\"><span data-url=\"https://blog.kakaocdn.net/dn/U4na8/btsLbNgoDO8/zPNQB29XjEXZ2iNJrVrPGk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/U4na8/btsLbNgoDO8/zPNQB29XjEXZ2iNJrVrPGk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/U4na8/btsLbNgoDO8/zPNQB29XjEXZ2iNJrVrPGk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FU4na8%2FbtsLbNgoDO8%2FzPNQB29XjEXZ2iNJrVrPGk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"사고링크.jpg\" data-origin-width=\"760\" data-origin-height=\"1346\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<figure id=\"og_1733701717329\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"사고링크 - 교통사고 합의금 계산(상담, 치료, 수리) - Google Play 앱\" data-og-description=\"교통사고, 일상사고, 질병 등 사고를 당한 사람들이 제대로 보상을 받을 수 있도록 손해사정사, 병원 수리&middot;렌트 업체를 통해 도와드립니다.\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.sagolinkapp\" data-og-url=\"https://play.google.com/store/apps/details?id=com.sagolinkapp&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/cVOgTG/hyXKpAcaag/9vstRZmbLKAEzpmtiz2Tw0/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/cam5sZ/hyXKziuLqp/kB0lE0us7pmKLOuBOSAcfK/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/u0qpQ/hyXGOIn4Y0/9vKE8SDmktpETS2VVwTad1/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360\"><a href=\"https://play.google.com/store/apps/details?id=com.sagolinkapp\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.sagolinkapp\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/cVOgTG/hyXKpAcaag/9vstRZmbLKAEzpmtiz2Tw0/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/cam5sZ/hyXKziuLqp/kB0lE0us7pmKLOuBOSAcfK/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/u0qpQ/hyXGOIn4Y0/9vKE8SDmktpETS2VVwTad1/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">사고링크 - 교통사고 합의금 계산(상담, 치료, 수리) - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">교통사고, 일상사고, 질병 등 사고를 당한 사람들이 제대로 보상을 받을 수 있도록 손해사정사, 병원 수리&middot;렌트 업체를 통해 도와드립니다.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000;\" data-ke-size=\"size26\"><b>4. 오르조&nbsp;-&nbsp;수능,&nbsp;기출,&nbsp;내신,&nbsp;PDF,&nbsp;문제집<br /></b></h2>\n<p data-ke-size=\"size16\">&nbsp;태블릿을 활용하여 수능 준비를 하는 학생들을 위해 개발된 학습 앱으로, 기출문제 풀이에 필요한 다양한 기능을 제공합니다. 앱 내에서 원터치로 각종 기출문제와 모의고사에 응시할 수 있으며, PDF 다운로드나 불러오기 없이 간편하게 이용 가능합니다. 또한, 다른 학생들의 풀이를 확인할 수 있어 어려운 문제를 더욱 쉽게 이해할 수 있습니다.&nbsp;<br /><br />자동&nbsp;채점&nbsp;및&nbsp;분석&nbsp;기능을&nbsp;통해&nbsp;학습&nbsp;효율을&nbsp;높일&nbsp;수&nbsp;있습니다.&nbsp;문제&nbsp;풀이&nbsp;후&nbsp;1초&nbsp;만에&nbsp;자동으로&nbsp;채점되어&nbsp;점수를&nbsp;확인할&nbsp;수&nbsp;있으며,&nbsp;자신이&nbsp;선택한&nbsp;답안과&nbsp;정답,&nbsp;문제별&nbsp;풀이&nbsp;시간&nbsp;등을&nbsp;상세히&nbsp;볼&nbsp;수&nbsp;있습니다.&nbsp;이를&nbsp;통해&nbsp;자신의&nbsp;약점을&nbsp;파악하고,&nbsp;효율적인&nbsp;학습&nbsp;계획을&nbsp;세울&nbsp;수&nbsp;있습니다.&nbsp; <br /><br />오르조는 다양한 문제집과 복습노트 기능을 통해 체계적인 학습을 지원합니다. 앱 내에서 다양한 문제집을 편리하게 공부할 수 있으며, 오직 오르조에서만 제공되는 콘텐츠도 활용할 수 있습니다. 또한, 원하는 문제를 복습노트에 모아 효율적으로 복습할 수 있어 오답 노트 작성에 소요되는 시간을 절약할 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"오르조.jpg\" data-origin-width=\"760\" data-origin-height=\"1346\"><span data-url=\"https://blog.kakaocdn.net/dn/chT7EJ/btsLbwMJISt/mrpUc1B0Xdz39DDNz6cqdk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/chT7EJ/btsLbwMJISt/mrpUc1B0Xdz39DDNz6cqdk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/chT7EJ/btsLbwMJISt/mrpUc1B0Xdz39DDNz6cqdk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FchT7EJ%2FbtsLbwMJISt%2FmrpUc1B0Xdz39DDNz6cqdk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"오르조.jpg\" data-origin-width=\"760\" data-origin-height=\"1346\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<figure id=\"og_1733701744807\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"오르조 - 수능, 기출, 내신, PDF, 문제집 - Google Play 앱\" data-og-description=\"8년치 기출문제, 모의고사, 다양한 문제집을 공부해보세요. 1초만에 자동채점 기능으로 채점하고 0.1초만에 오답노트까지 만들어보세요!\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=kr.slingcorp.orzocsat\" data-og-url=\"https://play.google.com/store/apps/details?id=kr.slingcorp.orzocsat&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/mwHpd/hyXGNCGwoF/dAVgDqdHs9PR6Hfj3cTVv0/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/967wv/hyXKyYbrRz/OwE6VQPqZqbmDkWKnMFteK/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/bODu3d/hyXGOO95fJ/cMssARQHr4LLB2G4QaOh51/img.png?width=240&amp;height=240&amp;face=0_0_240_240\"><a href=\"https://play.google.com/store/apps/details?id=kr.slingcorp.orzocsat\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=kr.slingcorp.orzocsat\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/mwHpd/hyXGNCGwoF/dAVgDqdHs9PR6Hfj3cTVv0/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/967wv/hyXKyYbrRz/OwE6VQPqZqbmDkWKnMFteK/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/bODu3d/hyXGOO95fJ/cMssARQHr4LLB2G4QaOh51/img.png?width=240&amp;height=240&amp;face=0_0_240_240');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">오르조 - 수능, 기출, 내신, PDF, 문제집 - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">8년치 기출문제, 모의고사, 다양한 문제집을 공부해보세요. 1초만에 자동채점 기능으로 채점하고 0.1초만에 오답노트까지 만들어보세요!</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000;\" data-ke-size=\"size26\"><b>5. 피아노키위즈</b></h2>\n<p data-ke-size=\"size16\">&nbsp;당신의 악보와 한계를 새로운 방식으로 넘어서도록 도와줍니다. 사람이 직접 악보를 넘기는 것처럼 자연스럽게 처리해주며, 약간의 차이가 있더라도 사용자에게 부드럽고 편리한 경험을 제공합니다. 어쿠스틱 피아노와 디지털 피아노 모두를 지원하며, 소리를 기반으로 작동하기 때문에 다양한 환경에서 활용할 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;또한, 누구나 자신의 악보를 업로드하면 피아노키위즈의 연주 분석 기능을 통해 더욱 깊이 있는 연주 데이터를 확인할 수 있습니다. 심지어 악보를 읽지 못하는 사람들도 쉽게 사용할 수 있도록 설계되어 있어, 음악을 배우고 연주하는 과정에서 누구나 접근 가능하도록 돕습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"피아노키위즈.jpg\" data-origin-width=\"760\" data-origin-height=\"1346\"><span data-url=\"https://blog.kakaocdn.net/dn/sVQ9q/btsLa9RNXVW/7YEmd4SkzW2pYemJbcoGjk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/sVQ9q/btsLa9RNXVW/7YEmd4SkzW2pYemJbcoGjk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/sVQ9q/btsLa9RNXVW/7YEmd4SkzW2pYemJbcoGjk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FsVQ9q%2FbtsLa9RNXVW%2F7YEmd4SkzW2pYemJbcoGjk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"피아노키위즈.jpg\" data-origin-width=\"760\" data-origin-height=\"1346\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<figure id=\"og_1733701770837\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"피아노키위즈 - Google Play 앱\" data-og-description=\"소리인식 자동 넘김 악보 앱 피아노키위즈\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.clebrain.pianokiwis\" data-og-url=\"https://play.google.com/store/apps/details?id=com.clebrain.pianokiwis&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/t00Cs/hyXGOVTX9i/dpD9zlgAqQNkMhF7zbZJK0/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/bZhnCK/hyXKrrcbOG/emspQX1E2nYLUBzBilB6Gk/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/bgOprm/hyXKjfFNdY/bKGVbbpGvmHMdFvf0gjKiK/img.png?width=240&amp;height=240&amp;face=0_0_240_240\"><a href=\"https://play.google.com/store/apps/details?id=com.clebrain.pianokiwis\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.clebrain.pianokiwis\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/t00Cs/hyXGOVTX9i/dpD9zlgAqQNkMhF7zbZJK0/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/bZhnCK/hyXKrrcbOG/emspQX1E2nYLUBzBilB6Gk/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/bgOprm/hyXKjfFNdY/bKGVbbpGvmHMdFvf0gjKiK/img.png?width=240&amp;height=240&amp;face=0_0_240_240');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">피아노키위즈 - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">소리인식 자동 넘김 악보 앱 피아노키위즈</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "구글 플레이 스토어의 수많은 앱 중, 유용하고 안전한 앱을 엄선해 매주 소개합니다. 신뢰할 수 있는 앱 리뷰를 확인하세요.\n\n\n \n 안드로이드 앱스토어인 구글 플레이 스토어에는 하루에도 엄청난 수의 앱과 게임이 신규로 등록됩니다. 이 모든앱들을 사용자가 확인하고 양질의 앱을 선택하는 것이 사실상 불가능 하다는 얘기죠.\n \n또한, 최근들어 강화되었다 하지만 여전히 구글 플레이스토어에는 유해한 앱들이 사라지지 않고 이들 앱으로 피해를 보는 사용자도 많습니다.본 블로그에서는 일주일에 한번정도 운영자가 직접 유용하고 편리한 앱을 엄선하여 소개합니다.\n \n'어떤오후의 프리웨어 이야기'에서 추천하는 2024년 12월 9일자 '안드로이드 추천 앱'입니다.\n \n1. 캐치테이블\n\n 21년 구글 '올해를 빛낸 앱'과 2022년 앱스토어 '오늘의 앱'에 선정된 인기 맛집 예약 및 웨이팅 앱으로, 300만 이상의 사용자가 선택한 서비스입니다. 10,000여 개의 파인다이닝, 핫플 맛집을 포함해 예약과 웨이팅 서비스를 제공하며, 지역, 편의시설, 방문 목적, 프로그램명 등을 기반으로 한 편리한 검색 기능을 갖추고 있습니다. 사용자는 전화 없이도 앱에서 24시간 온라인 예약이 가능하며, 인기 맛집에 긴 웨이팅 없이 입장할 수 있도록 돕습니다. 또한, 할인 티켓을 통해 스시야와 스테이크 같은 다양한 메뉴를 저렴하게 즐길 수 있습니다. \n  다양한 필터와 실시간 리뷰를 통해 맞춤형 맛집 정보를 제공합니다. 사용자는 방문 목적, 인원, 가격대, 음식 종류, 테이블 타입 등을 선택해 자신에게 딱 맞는 맛집을 찾을 수 있으며, 150만 개 이상의 실제 방문 리뷰를 통해 취향에 맞는 식당을 쉽게 발견할 수 있습니다. 또한, 베스트 메뉴, 가격, 발렛, 콜키지와 같은 세부 정보를 한눈에 확인할 수 있어 편리한 선택이 가능합니다. 예약 실패 시 빈자리 알림을 설정하거나, 웨이팅 미루기 기능으로 입장 순서를 조정하는 등 실용적인 기능도 제공됩니다.\n\n\n \n\n \n캐치테이블 - Google Play 앱\n인기 맛집, 핫플 예약부터 웨이팅까지 한번에!\nplay.google.com\n\n \n \n \n \n2. 타임티켓 - 마감임박 공연/전시 할인 \n\n 공연, 전시, 체험, 액티비티, 원데이클래스 등을 합리적인 가격에 제공하는 티켓 예매 플랫폼으로, 알뜰한 문화생활을 원하는 사용자들에게 최적의 선택입니다. 대학로 연극부터 리미티드런 뮤지컬, 다양한 체험 프로그램까지 폭넓은 티켓을 지원하며, 당일 할인 혜택과 타임세일을 통해 최대 90%까지 할인된 가격으로 티켓을 구매할 수 있습니다. 예매수수료가 없고, 간편한 현장 발권 시스템을 통해 사용자 편의를 극대화했습니다. 또한, 실시간 랭킹과 후기 시스템을 통해 사용자들은 인기 있는 공연과 전시를 한눈에 파악하고, 선택의 고민을 줄일 수 있습니다. \n 타임티켓의 주요 특징 중 하나는 마감 임박 티켓을 추가 할인하는 '타임커머스'와 다양한 지역에서 제공되는 티켓 옵션입니다. 대학로, 강남, 홍대 등 서울 지역뿐만 아니라 경기도, 부산, 대구, 제주 등 전국적으로 다양한 문화상품과 액티비티를 만나볼 수 있습니다. 특히, 해설사와 함께하는 투어, 계절별 레저 활동, 커플 데이트를 위한 프로그램 등이 준비되어 있어 사용자의 다양한 취향을 만족시킵니다. 또한, 무료 초대 이벤트를 통해 공연 및 전시 티켓을 무료로 받을 기회도 제공하며, 영화보다 저렴한 가격에 고품질의 문화생활을 즐길 수 있도록 돕습니다.\n\n\n \n\n \n타임티켓 - 마감임박 공연/전시 할인 - Google Play 앱\n대학로연극부터 뮤지컬/콘서트/전시회/체험/투어/레저/액티비티/원데이클래스까지! 마감임박 오늘할인과 최저가 타임세일로 즐기는 합리적인 문화생활!\nplay.google.com\n\n \n \n \n \n \n \n3. 사고링크 - 교통사고 합의금 계산(상담, 치료, 수리) \n\n 교통사고 및 일반사고 피해자들에게 보상 전문가의 무료 상담과 손해사정 서비스를 제공하는 플랫폼으로, 고객이 적절한 보상을 받을 수 있도록 돕습니다. 특히 교통사고의 경우, 사고링크는 25만 건 이상의 데이터를 활용한 빅데이터 알고리즘을 통해 예상 합의금을 산출하며, 보험사가 제시한 금액과 비교해 적절성을 검증할 수 있는 기능을 제공합니다. 단순한 사고라도 고객 입장에서 세심하게 상담하며, 심각한 피해가 발생한 경우에는 전문가의 직접 상담을 권장합니다. \n 사고링크는 교통사고 피해자의 편의를 위한 다양한 서비스를 제공합니다. 차량 수리, 렌트, 병원 치료 등 사고 이후 필요한 모든 과정을 고객의 입장에서 지원하며, 상대 보험사의 이익이 아닌 피해자의 권리를 우선으로 합니다. 고객은 프라이빗 입원실, 한방 병원 등 최적의 치료 환경을 안내받을 수 있고, 전문 현장 기사의 도움을 받아 차량 수리와 대차 과정을 신뢰할 수 있습니다. 또한, 고객이 보험사와 직접 대면하지 않고도 정확한 보상금을 받을 수 있도록 상담과 지원을 제공합니다.\n\n\n \n\n \n사고링크 - 교통사고 합의금 계산(상담, 치료, 수리) - Google Play 앱\n교통사고, 일상사고, 질병 등 사고를 당한 사람들이 제대로 보상을 받을 수 있도록 손해사정사, 병원 수리·렌트 업체를 통해 도와드립니다.\nplay.google.com\n\n \n \n \n \n \n \n4. 오르조 - 수능, 기출, 내신, PDF, 문제집\n\n 태블릿을 활용하여 수능 준비를 하는 학생들을 위해 개발된 학습 앱으로, 기출문제 풀이에 필요한 다양한 기능을 제공합니다. 앱 내에서 원터치로 각종 기출문제와 모의고사에 응시할 수 있으며, PDF 다운로드나 불러오기 없이 간편하게 이용 가능합니다. 또한, 다른 학생들의 풀이를 확인할 수 있어 어려운 문제를 더욱 쉽게 이해할 수 있습니다. \n자동 채점 및 분석 기능을 통해 학습 효율을 높일 수 있습니다. 문제 풀이 후 1초 만에 자동으로 채점되어 점수를 확인할 수 있으며, 자신이 선택한 답안과 정답, 문제별 풀이 시간 등을 상세히 볼 수 있습니다. 이를 통해 자신의 약점을 파악하고, 효율적인 학습 계획을 세울 수 있습니다.  \n오르조는 다양한 문제집과 복습노트 기능을 통해 체계적인 학습을 지원합니다. 앱 내에서 다양한 문제집을 편리하게 공부할 수 있으며, 오직 오르조에서만 제공되는 콘텐츠도 활용할 수 있습니다. 또한, 원하는 문제를 복습노트에 모아 효율적으로 복습할 수 있어 오답 노트 작성에 소요되는 시간을 절약할 수 있습니다.\n\n\n \n\n \n오르조 - 수능, 기출, 내신, PDF, 문제집 - Google Play 앱\n8년치 기출문제, 모의고사, 다양한 문제집을 공부해보세요. 1초만에 자동채점 기능으로 채점하고 0.1초만에 오답노트까지 만들어보세요!\nplay.google.com\n\n \n \n \n \n \n \n5. 피아노키위즈\n 당신의 악보와 한계를 새로운 방식으로 넘어서도록 도와줍니다. 사람이 직접 악보를 넘기는 것처럼 자연스럽게 처리해주며, 약간의 차이가 있더라도 사용자에게 부드럽고 편리한 경험을 제공합니다. 어쿠스틱 피아노와 디지털 피아노 모두를 지원하며, 소리를 기반으로 작동하기 때문에 다양한 환경에서 활용할 수 있습니다.\n \n 또한, 누구나 자신의 악보를 업로드하면 피아노키위즈의 연주 분석 기능을 통해 더욱 깊이 있는 연주 데이터를 확인할 수 있습니다. 심지어 악보를 읽지 못하는 사람들도 쉽게 사용할 수 있도록 설계되어 있어, 음악을 배우고 연주하는 과정에서 누구나 접근 가능하도록 돕습니다.\n\n\n \n\n \n피아노키위즈 - Google Play 앱\n소리인식 자동 넘김 악보 앱 피아노키위즈\nplay.google.com",
        "guid": "http://muzbox.tistory.com/483509",
        "categories": [
          "ANDROID &amp; 모바일/추천 무료 앱",
          "공연애매",
          "교통사고 합의금 계산",
          "맛집예약",
          "수능 기출문제",
          "식당예약",
          "악보읽기",
          "안드로이드 추천앱",
          "추천앱",
          "티켓 예매",
          "피아노 연습"
        ],
        "isoDate": "2024-12-08T23:49:49.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "챗GPT 와 퍼플렉시티의 차이, 어느 챗봇이 나을까?",
        "link": "http://muzbox.tistory.com/483508",
        "pubDate": "Wed, 4 Dec 2024 08:43:07 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483508#entry483508comment",
        "content": "<p data-ke-size=\"size18\">&nbsp;ChatGPT Plus와 Perplexity AI를 심층 비교하여 두 챗봇의 기술, 기능, 가격 및 사용 사례를 알아보세요. 최적의 AI 도구를 선택하는 데 필요한 모든 정보를 제공합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"ChatGPT VS Perplexity AI.jpg\" data-origin-width=\"1920\" data-origin-height=\"1080\"><span data-url=\"https://blog.kakaocdn.net/dn/rOSJ8/btsK6r5tWbg/vedRvnkpJGRKzw6KOCGiX0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/rOSJ8/btsK6r5tWbg/vedRvnkpJGRKzw6KOCGiX0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/rOSJ8/btsK6r5tWbg/vedRvnkpJGRKzw6KOCGiX0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FrOSJ8%2FbtsK6r5tWbg%2FvedRvnkpJGRKzw6KOCGiX0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"챗GPT 와 퍼플렉시티의 차이\" data-filename=\"ChatGPT VS Perplexity AI.jpg\" data-origin-width=\"1920\" data-origin-height=\"1080\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;요즘 AI 챗봇은 단순한 기술 그 이상입니다. 검색 엔진을 대체하거나 복잡한 문제를 해결하는 데 필수적인 도구로 자리 잡았죠. ChatGPT Plus와 Perplexity AI는 각각 다른 방향성을 가진 두 AI 도구입니다. 한쪽은 다목적 활용과 창의적 작업을 지원하는 반면, 다른 한쪽은 정보 탐색과 실시간 데이터 제공에 초점을 맞춥니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">ChatGPT Plus는 OpenAI의 기술력으로 대화형 AI의 한계를 넘어섰습니다. 창의적 프로젝트부터 고급 데이터 분석까지 가능한 만능 AI 도구로 자리 잡았죠. 반면, Perplexity AI는 실시간 웹 검색과 정보 출처의 명확성을 강점으로 하는 도구로, 정확성과 신뢰성이 요구되는 작업에서 돋보입니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">이번 포스팅에서는 두 챗봇의 주요 기술, 기능, 가격, 그리고 사용자 경험을 자세히 분석합니다. 이 정보를 통해 여러분이 필요로 하는 도구를 정확히 선택할 수 있기를 바랍니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>기능 비교</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><i>ChatGPT Plus의 기술적 강점</i></span></h3>\n<p data-ke-size=\"size18\">ChatGPT Plus는 OpenAI의 가장 발전된 기술을 기반으로 만들어졌습니다. 특히 GPT-4o 모델을 사용하는 유료 플랜은 다음과 같은 특징을 자랑합니다:</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>GPT-4o 모델</b>: 기존 모델보다 더 세밀하고 자연스러운 대화를 제공합니다. 예를 들어, 복잡한 문맥에서도 높은 정확도를 보여줍니다.</li>\n<li><b>DALL-E와 고급 음성 모드</b>: 텍스트 기반 작업뿐만 아니라 이미지 생성과 음성을 활용한 상호작용도 가능합니다.</li>\n<li><b>다중 언어 지원</b>: 전 세계 다양한 언어로 작업할 수 있어 글로벌 사용자들에게 매력적입니다.</li>\n<li><b>확장 가능한 플랫폼</b>: iOS, Android, Windows, macOS 등 다양한 환경에서 사용할 수 있습니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><i>Perplexity AI의 독창적 기술</i></span></h3>\n<p data-ke-size=\"size18\">Perplexity AI는 실시간 검색과 데이터 분석을 위한 최신 기술을 활용합니다. 이 도구는 특히 다음과 같은 기능에서 두각을 나타냅니다:</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>GPT-4 Omni 및 Claude 3.5 Sonnet</b>: 최신 언어 모델을 통해 깊이 있는 응답과 신뢰성 높은 정보를 제공합니다.</li>\n<li><b>실시간 검색</b>: 단순히 미리 학습된 데이터를 활용하는 것이 아니라, 사용자가 질문하는 순간 데이터를 검색하여 최신 정보를 제공합니다.</li>\n<li><b>파일 분석 기능</b>: PDF와 같은 파일을 업로드하여 문서를 분석할 수 있어 연구자와 전문가들에게 유용합니다.</li>\n<li><b>오픈 소스 접근성</b>: 사용자들이 커뮤니티 기반으로 도구를 개선할 수 있는 환경을 제공합니다.</li>\n</ul>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"기술비교.png\" data-origin-width=\"971\" data-origin-height=\"317\"><span data-url=\"https://blog.kakaocdn.net/dn/btLDAS/btsK67McupY/MNCHQvCoUE5stBUK0cMhy1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/btLDAS/btsK67McupY/MNCHQvCoUE5stBUK0cMhy1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/btLDAS/btsK67McupY/MNCHQvCoUE5stBUK0cMhy1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbtLDAS%2FbtsK67McupY%2FMNCHQvCoUE5stBUK0cMhy1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"기술비교.png\" data-origin-width=\"971\" data-origin-height=\"317\"/></span></figure>\n</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>기능 차이</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><i>ChatGPT Plus: 다목적 AI의 모든 것</i></span></h3>\n<p data-ke-size=\"size18\">ChatGPT Plus는 단순한 AI 챗봇을 넘어선, 생산성과 창의적 작업을 위한 완벽한 도구입니다. 다음은 주요 기능들입니다:</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>커스텀 GPT 생성</b>: 사용자가 직접 AI의 성격과 기능을 정의하여 업무에 특화된 AI를 만들 수 있습니다. 예를 들어, 고객 응대를 위한 GPT나 데이터 분석 전용 GPT를 설정할 수 있습니다.</li>\n<li><b>웹 검색 통합</b>: 최신 웹 데이터를 실시간으로 분석하고, 이를 기반으로 한 고급 응답을 제공합니다.</li>\n<li><b>창의적 작업 지원</b>: 텍스트 요약, 글쓰기, 데이터 시각화, 그리고 이미지 생성과 같은 다양한 창작 활동에 사용 가능합니다.</li>\n<li><b>AI 도구와의 통합</b>: DALL-E와 같은 이미지 생성 도구 및 음성 상호작용 기능을 통해 더 풍부한 작업 경험을 제공합니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><i>Perplexity AI: 신뢰할 수 있는 정보 검색</i></span></h3>\n<p data-ke-size=\"size18\">Perplexity AI는 검색과 데이터 분석에 초점을 맞춘 도구로, 다음과 같은 기능을 제공합니다:</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>출처 명시</b>: 모든 답변에 출처를 포함하여 사용자가 신뢰할 수 있는 데이터를 제공합니다. 예를 들어, 학술 연구나 뉴스 데이터를 정확히 인용합니다.</li>\n<li><b>관련 검색어 제안</b>: 사용자가 한 질문을 기반으로 추가적인 정보를 쉽게 탐색할 수 있도록 돕습니다.</li>\n<li><b>파일 분석 기능</b>: 업로드한 파일을 바탕으로 세부적인 데이터 분석 결과를 제공합니다. 연구 논문이나 비즈니스 보고서에서 유용하게 사용될 수 있습니다.</li>\n<li><b>음성 명령 지원</b>: 음성을 통해 질문하고 데이터를 받을 수 있어, 핸즈프리 환경에서도 효과적으로 작동합니다.</li>\n</ul>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"기능분석.png\" data-origin-width=\"521\" data-origin-height=\"325\"><span data-url=\"https://blog.kakaocdn.net/dn/H65lj/btsK4X5P1K3/ooiKKdXk3OFzCpIQOVk0a1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/H65lj/btsK4X5P1K3/ooiKKdXk3OFzCpIQOVk0a1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/H65lj/btsK4X5P1K3/ooiKKdXk3OFzCpIQOVk0a1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FH65lj%2FbtsK4X5P1K3%2FooiKKdXk3OFzCpIQOVk0a1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"기능분석.png\" data-origin-width=\"521\" data-origin-height=\"325\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>가격 비교</b></span></h2>\n<p data-ke-size=\"size18\">ChatGPT Plus와 Perplexity AI 모두 월 $20의 유료 플랜을 제공하지만, 제공되는 기능과 타겟 사용자에 따라 가치가 다릅니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><i>ChatGPT Plus의 비용 대비 가치</i></span></h3>\n<p data-ke-size=\"size18\">ChatGPT Plus의 유료 플랜은 고급 대화형 AI를 원하는 사용자들에게 적합합니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>주요 혜택</b>: GPT-4o 모델, 이미지 생성, 음성 기능 등.</li>\n<li><b>활용 사례</b>: 글쓰기, 데이터 분석, 고객 서비스 등.</li>\n<li><b>타겟 사용자</b>: 창의적 작업과 다목적 AI 기능을 원하는 사용자.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><i>Perplexity Pro의 비용 대비 가치</i></span></h3>\n<p data-ke-size=\"size18\">Perplexity Pro는 검색 및 데이터 분석에 중점을 둔 사용자들에게 더 적합합니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>주요 혜택</b>: 300회 검색, 파일 분석, $5의 API 크레딧.</li>\n<li><b>활용 사례</b>: 연구, 실시간 데이터 검색, 파일 기반 분석.</li>\n<li><b>타겟 사용자</b>: 연구자, 개발자, 정보 검색에 특화된 사용자.</li>\n</ul>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1792\" data-origin-height=\"1024\"><span data-url=\"https://blog.kakaocdn.net/dn/F16Z8/btsK5EYKj4c/dLxvJXBTSGAfcjfpnTClxK/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/F16Z8/btsK5EYKj4c/dLxvJXBTSGAfcjfpnTClxK/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/F16Z8/btsK5EYKj4c/dLxvJXBTSGAfcjfpnTClxK/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FF16Z8%2FbtsK5EYKj4c%2FdLxvJXBTSGAfcjfpnTClxK%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"ChatGPT VS Perplexity\" width=\"700\" height=\"400\" data-origin-width=\"1792\" data-origin-height=\"1024\"/></span></figure>\n</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>사용자 경험</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><i>ChatGPT Plus의 사용자 경험</i></span></h3>\n<p data-ke-size=\"size18\">ChatGPT Plus는 다음과 같은 사용자 경험을 제공합니다:</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>다목적 인터페이스</b>: 간단하면서도 직관적인 디자인으로 누구나 쉽게 사용할 수 있습니다.</li>\n<li><b>응답 속도</b>: 빠른 처리 속도로 복잡한 질문에도 적시에 답변 가능합니다.</li>\n<li><b>사용자 맞춤형 기능</b>: 개인화된 GPT를 만들거나, 작업 요구 사항에 따라 도구를 조정할 수 있습니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><i>Perplexity AI의 사용자 경험</i></span></h3>\n<p data-ke-size=\"size18\">Perplexity AI는 정보 검색에 최적화된 사용자 경험을 제공합니다:</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>출처 신뢰성</b>: 사용자는 답변의 출처를 직접 확인할 수 있어, 정보의 신뢰도를 높입니다.</li>\n<li><b>탐색 기능</b>: 질문 하나를 시작으로 여러 주제를 깊이 탐구할 수 있는 관련 검색어 제안 기능이 돋보입니다.</li>\n<li><b>안정성</b>: 실시간 검색 엔진으로 최신 정보를 정확히 제공합니다.</li>\n</ul>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"815\" data-origin-height=\"354\"><span data-url=\"https://blog.kakaocdn.net/dn/bJmxCe/btsK6yQ30tN/s5nFX393EAN1uejX1mKuc0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bJmxCe/btsK6yQ30tN/s5nFX393EAN1uejX1mKuc0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bJmxCe/btsK6yQ30tN/s5nFX393EAN1uejX1mKuc0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbJmxCe%2FbtsK6yQ30tN%2Fs5nFX393EAN1uejX1mKuc0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"챗GPT 와 퍼플렉시티의 차이\" data-origin-width=\"815\" data-origin-height=\"354\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>마치며</b></span></h2>\n<p data-ke-size=\"size18\">ChatGPT Plus와 Perplexity AI는 각각 다른 강점을 가지고 있는 AI 챗봇입니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>ChatGPT Plus</b>는 다목적 AI 기능을 제공하며 창의적 작업과 생산성 향상을 지원합니다.</li>\n<li><b>Perplexity AI</b>는 신뢰성 높은 실시간 정보 검색과 데이터 분석에 초점을 맞춘 도구입니다.</li>\n</ul>\n<p data-ke-size=\"size18\">두 도구 모두 무료 버전을 제공하니, 직접 체험해보고 필요에 따라 적합한 유료 플랜을 선택해 보세요.  </p>\n<hr data-ke-style=\"style1\" />\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>Q&amp;A</b></span></h2>\n<p data-ke-size=\"size18\"><b>1. ChatGPT Plus는 누구에게 적합한가요?</b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>글쓰기, 창의적 프로젝트, 데이터 분석을 하는 사용자에게 적합합니다.</li>\n</ul>\n<p data-ke-size=\"size18\"><b>2. Perplexity AI는 어떤 환경에서 유용한가요?</b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>실시간 정보 검색과 신뢰성 높은 데이터를 필요로 하는 연구자나 개발자에게 적합합니다.</li>\n</ul>\n<p data-ke-size=\"size18\"><b>3. 두 도구 중 무엇이 더 빠르게 응답하나요?</b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>Perplexity AI는 실시간 웹 검색으로 빠르게 정보를 제공합니다. 하지만 ChatGPT Plus도 최근 업데이트로 속도가 향상되었습니다.</li>\n</ul>",
        "contentSnippet": "ChatGPT Plus와 Perplexity AI를 심층 비교하여 두 챗봇의 기술, 기능, 가격 및 사용 사례를 알아보세요. 최적의 AI 도구를 선택하는 데 필요한 모든 정보를 제공합니다.\n\n\n \n 요즘 AI 챗봇은 단순한 기술 그 이상입니다. 검색 엔진을 대체하거나 복잡한 문제를 해결하는 데 필수적인 도구로 자리 잡았죠. ChatGPT Plus와 Perplexity AI는 각각 다른 방향성을 가진 두 AI 도구입니다. 한쪽은 다목적 활용과 창의적 작업을 지원하는 반면, 다른 한쪽은 정보 탐색과 실시간 데이터 제공에 초점을 맞춥니다.\n \nChatGPT Plus는 OpenAI의 기술력으로 대화형 AI의 한계를 넘어섰습니다. 창의적 프로젝트부터 고급 데이터 분석까지 가능한 만능 AI 도구로 자리 잡았죠. 반면, Perplexity AI는 실시간 웹 검색과 정보 출처의 명확성을 강점으로 하는 도구로, 정확성과 신뢰성이 요구되는 작업에서 돋보입니다.\n \n이번 포스팅에서는 두 챗봇의 주요 기술, 기능, 가격, 그리고 사용자 경험을 자세히 분석합니다. 이 정보를 통해 여러분이 필요로 하는 도구를 정확히 선택할 수 있기를 바랍니다.\n \n기능 비교\nChatGPT Plus의 기술적 강점\nChatGPT Plus는 OpenAI의 가장 발전된 기술을 기반으로 만들어졌습니다. 특히 GPT-4o 모델을 사용하는 유료 플랜은 다음과 같은 특징을 자랑합니다:\nGPT-4o 모델: 기존 모델보다 더 세밀하고 자연스러운 대화를 제공합니다. 예를 들어, 복잡한 문맥에서도 높은 정확도를 보여줍니다.\nDALL-E와 고급 음성 모드: 텍스트 기반 작업뿐만 아니라 이미지 생성과 음성을 활용한 상호작용도 가능합니다.\n다중 언어 지원: 전 세계 다양한 언어로 작업할 수 있어 글로벌 사용자들에게 매력적입니다.\n확장 가능한 플랫폼: iOS, Android, Windows, macOS 등 다양한 환경에서 사용할 수 있습니다.\nPerplexity AI의 독창적 기술\nPerplexity AI는 실시간 검색과 데이터 분석을 위한 최신 기술을 활용합니다. 이 도구는 특히 다음과 같은 기능에서 두각을 나타냅니다:\nGPT-4 Omni 및 Claude 3.5 Sonnet: 최신 언어 모델을 통해 깊이 있는 응답과 신뢰성 높은 정보를 제공합니다.\n실시간 검색: 단순히 미리 학습된 데이터를 활용하는 것이 아니라, 사용자가 질문하는 순간 데이터를 검색하여 최신 정보를 제공합니다.\n파일 분석 기능: PDF와 같은 파일을 업로드하여 문서를 분석할 수 있어 연구자와 전문가들에게 유용합니다.\n오픈 소스 접근성: 사용자들이 커뮤니티 기반으로 도구를 개선할 수 있는 환경을 제공합니다.\n\n\n기능 차이\nChatGPT Plus: 다목적 AI의 모든 것\nChatGPT Plus는 단순한 AI 챗봇을 넘어선, 생산성과 창의적 작업을 위한 완벽한 도구입니다. 다음은 주요 기능들입니다:\n커스텀 GPT 생성: 사용자가 직접 AI의 성격과 기능을 정의하여 업무에 특화된 AI를 만들 수 있습니다. 예를 들어, 고객 응대를 위한 GPT나 데이터 분석 전용 GPT를 설정할 수 있습니다.\n웹 검색 통합: 최신 웹 데이터를 실시간으로 분석하고, 이를 기반으로 한 고급 응답을 제공합니다.\n창의적 작업 지원: 텍스트 요약, 글쓰기, 데이터 시각화, 그리고 이미지 생성과 같은 다양한 창작 활동에 사용 가능합니다.\nAI 도구와의 통합: DALL-E와 같은 이미지 생성 도구 및 음성 상호작용 기능을 통해 더 풍부한 작업 경험을 제공합니다.\nPerplexity AI: 신뢰할 수 있는 정보 검색\nPerplexity AI는 검색과 데이터 분석에 초점을 맞춘 도구로, 다음과 같은 기능을 제공합니다:\n출처 명시: 모든 답변에 출처를 포함하여 사용자가 신뢰할 수 있는 데이터를 제공합니다. 예를 들어, 학술 연구나 뉴스 데이터를 정확히 인용합니다.\n관련 검색어 제안: 사용자가 한 질문을 기반으로 추가적인 정보를 쉽게 탐색할 수 있도록 돕습니다.\n파일 분석 기능: 업로드한 파일을 바탕으로 세부적인 데이터 분석 결과를 제공합니다. 연구 논문이나 비즈니스 보고서에서 유용하게 사용될 수 있습니다.\n음성 명령 지원: 음성을 통해 질문하고 데이터를 받을 수 있어, 핸즈프리 환경에서도 효과적으로 작동합니다.\n\n\n \n \n가격 비교\nChatGPT Plus와 Perplexity AI 모두 월 $20의 유료 플랜을 제공하지만, 제공되는 기능과 타겟 사용자에 따라 가치가 다릅니다.\nChatGPT Plus의 비용 대비 가치\nChatGPT Plus의 유료 플랜은 고급 대화형 AI를 원하는 사용자들에게 적합합니다.\n주요 혜택: GPT-4o 모델, 이미지 생성, 음성 기능 등.\n활용 사례: 글쓰기, 데이터 분석, 고객 서비스 등.\n타겟 사용자: 창의적 작업과 다목적 AI 기능을 원하는 사용자.\nPerplexity Pro의 비용 대비 가치\nPerplexity Pro는 검색 및 데이터 분석에 중점을 둔 사용자들에게 더 적합합니다.\n주요 혜택: 300회 검색, 파일 분석, $5의 API 크레딧.\n활용 사례: 연구, 실시간 데이터 검색, 파일 기반 분석.\n타겟 사용자: 연구자, 개발자, 정보 검색에 특화된 사용자.\n\n\n사용자 경험\nChatGPT Plus의 사용자 경험\nChatGPT Plus는 다음과 같은 사용자 경험을 제공합니다:\n다목적 인터페이스: 간단하면서도 직관적인 디자인으로 누구나 쉽게 사용할 수 있습니다.\n응답 속도: 빠른 처리 속도로 복잡한 질문에도 적시에 답변 가능합니다.\n사용자 맞춤형 기능: 개인화된 GPT를 만들거나, 작업 요구 사항에 따라 도구를 조정할 수 있습니다.\nPerplexity AI의 사용자 경험\nPerplexity AI는 정보 검색에 최적화된 사용자 경험을 제공합니다:\n출처 신뢰성: 사용자는 답변의 출처를 직접 확인할 수 있어, 정보의 신뢰도를 높입니다.\n탐색 기능: 질문 하나를 시작으로 여러 주제를 깊이 탐구할 수 있는 관련 검색어 제안 기능이 돋보입니다.\n안정성: 실시간 검색 엔진으로 최신 정보를 정확히 제공합니다.\n\n\n \n \n마치며\nChatGPT Plus와 Perplexity AI는 각각 다른 강점을 가지고 있는 AI 챗봇입니다.\nChatGPT Plus는 다목적 AI 기능을 제공하며 창의적 작업과 생산성 향상을 지원합니다.\nPerplexity AI는 신뢰성 높은 실시간 정보 검색과 데이터 분석에 초점을 맞춘 도구입니다.\n두 도구 모두 무료 버전을 제공하니, 직접 체험해보고 필요에 따라 적합한 유료 플랜을 선택해 보세요.  \nQ&A\n1. ChatGPT Plus는 누구에게 적합한가요?\n글쓰기, 창의적 프로젝트, 데이터 분석을 하는 사용자에게 적합합니다.\n2. Perplexity AI는 어떤 환경에서 유용한가요?\n실시간 정보 검색과 신뢰성 높은 데이터를 필요로 하는 연구자나 개발자에게 적합합니다.\n3. 두 도구 중 무엇이 더 빠르게 응답하나요?\nPerplexity AI는 실시간 웹 검색으로 빠르게 정보를 제공합니다. 하지만 ChatGPT Plus도 최근 업데이트로 속도가 향상되었습니다.",
        "guid": "http://muzbox.tistory.com/483508",
        "categories": [
          "AI, 미래기술/채팅",
          "ai 도구 비교",
          "Ai 활용",
          "ChatGPT Plus",
          "gpt 모델",
          "perplexity ai",
          "생산성",
          "챗GPT",
          "퍼플랙시티",
          "퍼플렉시티"
        ],
        "isoDate": "2024-12-03T23:43:07.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "Franzis HDR Projects 9 Pro 무료 인증 방법",
        "link": "http://muzbox.tistory.com/483507",
        "pubDate": "Tue, 3 Dec 2024 15:37:13 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483507#entry483507comment",
        "content": "<p data-ke-size=\"size18\">&nbsp;Franzis HDR Projects 9 Pro는 HDR 사진 편집을 위한 전문 소프트웨어로, 무료 라이센스를 통해 강력한 RAW 처리, 다양한 프리셋, 배치 처리 기능을 체험해보세요.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"HDR PROJECT 9.jpg\" data-origin-width=\"1538\" data-origin-height=\"896\"><span data-url=\"https://blog.kakaocdn.net/dn/R04rq/btsK5cgXc6A/KNznRDa3BrFb6VvTHcKSZ1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/R04rq/btsK5cgXc6A/KNznRDa3BrFb6VvTHcKSZ1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/R04rq/btsK5cgXc6A/KNznRDa3BrFb6VvTHcKSZ1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FR04rq%2FbtsK5cgXc6A%2FKNznRDa3BrFb6VvTHcKSZ1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"Franzis HDR Projects 9 Pro 무료 인증 방법\" data-filename=\"HDR PROJECT 9.jpg\" data-origin-width=\"1538\" data-origin-height=\"896\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;HDR(High-Dynamic-Range) 사진은 디지털 사진의 새로운 가능성을 열어주는 기술적 혁신입니다. Franzis HDR Projects 9 Pro는 이러한 HDR 사진 제작 및 편집을 위한 전문적인 소프트웨어로, 초보자부터 전문가까지 누구나 활용할 수 있는 기능을 제공합니다. 이 소프트웨어는 RAW 이미지 처리, 다양한 프리셋, 배치 처리 모드 등 폭넓은 기능을 포함하고 있으며, 특히 Adobe Photoshop과 Lightroom 같은 유명한 이미지 편집 툴과도 호환됩니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">Franzis HDR Projects 9 Pro의 강력한 기능과 무료 라이센스를 얻는 방법을 자세히 소개합니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>Franzis HDR Projects 9 Pro: 주요 기능</b></span></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"HDR PROJECT 9A.jpg\" data-origin-width=\"1538\" data-origin-height=\"896\"><span data-url=\"https://blog.kakaocdn.net/dn/JUVNu/btsK5tW3OT4/vRGgXQLr4MORJmlrGDN1kK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/JUVNu/btsK5tW3OT4/vRGgXQLr4MORJmlrGDN1kK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/JUVNu/btsK5tW3OT4/vRGgXQLr4MORJmlrGDN1kK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FJUVNu%2FbtsK5tW3OT4%2FvRGgXQLr4MORJmlrGDN1kK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"HDR PROJECT 9A.jpg\" data-origin-width=\"1538\" data-origin-height=\"896\"/></span></figure>\n</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>1. 전문적인 RAW 이미지 처리</b></span></h3>\n<p data-ke-size=\"size18\">HDR Projects 9 Pro는 전문 RAW 컨버터의 모든 기능을 갖춘 강력한 RAW 이미지 처리 모듈을 제공합니다. 이 모듈은 다음과 같은 고급 편집 기능을 지원합니다:</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>밝기, 대비, 채도, 색조 등 세부적인 이미지 조정.</li>\n<li>RAW 파일에서 노출, 화이트 밸런스, 디테일을 정확하게 제어.</li>\n<li>사용자가 원하는 대로 왜곡을 보정하여 완벽한 이미지를 생성.</li>\n</ul>\n<p data-ke-size=\"size18\">RAW 이미지는 사진의 원본 데이터를 보존하여 최대한의 품질을 유지하기 때문에, 전문가들은 대부분 이 형식을 선호합니다. 이 소프트웨어는 RAW 파일의 잠재력을 최대한 끌어낼 수 있도록 설계되었습니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>2. 다양한 프리셋과 효과</b></span></h3>\n<p data-ke-size=\"size18\">Franzis HDR Projects 9 Pro는 188가지의 프리셋과 다양한 HDR 알고리즘을 제공하여 사용자가 빠르고 쉽게 원하는 결과물을 얻을 수 있습니다. 예를 들어:</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>클래식 HDR</b>: 일반적인 HDR 사진의 선명함과 생동감을 강조.</li>\n<li><b>드라마틱 효과</b>: 강렬하고 독특한 스타일 구현.</li>\n<li><b>흑백 사진</b>: 깊이 있는 흑백 톤으로 변환.</li>\n<li><b>사용자 정의 프리셋</b>: 개인적인 스타일을 반영한 설정 저장.</li>\n</ul>\n<p data-ke-size=\"size18\">이 프리셋은 초보자에게 특히 유용하며, 버튼 몇 번만으로 전문적인 결과를 얻을 수 있도록 도와줍니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>3. 배치 처리와 자동화</b></span></h3>\n<p data-ke-size=\"size18\">많은 사진을 한꺼번에 처리해야 하는 경우, 배치 처리 기능이 큰 도움을 줄 수 있습니다. Franzis HDR Projects 9 Pro의 배치 처리 모드는 다음과 같은 이점을 제공합니다:</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>폴더 전체를 불러와 자동으로 HDR 이미지 생성.</li>\n<li>자동 브라케팅 감지 기능을 통해 다양한 노출값을 가진 사진을 합성.</li>\n<li>작업 중 중단된 경우에도 진행 상태를 저장하여 언제든 복구 가능.</li>\n</ul>\n<p data-ke-size=\"size18\">이 기능은 특히 많은 양의 사진을 관리하는 전문가에게 시간과 노력을 절약해주는 핵심 도구입니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>4. Adobe Photoshop 및 Lightroom 플러그인 지원</b></span></h3>\n<p data-ke-size=\"size18\">Franzis HDR Projects 9 Pro는 독립적인 소프트웨어로 사용할 수도 있지만, Adobe Photoshop 및 Lightroom과의 플러그인 형태로도 사용할 수 있어 더 큰 유연성을 제공합니다. 이 플러그인을 통해:</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>Photoshop에서 직접 HDR Projects의 고급 기능을 활용.</li>\n<li>Lightroom에서 사진을 가져와 추가적으로 편집 가능.</li>\n</ul>\n<p data-ke-size=\"size18\">이러한 호환성은 기존의 워크플로를 방해하지 않으면서 HDR 편집 도구를 추가로 사용할 수 있는 기회를 제공합니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>Franzis HDR Projects 9 Pro 무료 라이센스 등록 방법</b></span></h2>\n<p data-ke-size=\"size18\">지금 Franzis HDR Projects 9 Pro를 무료로 이용할 수 있는 특별한 기회가 제공되고 있습니다. 다음 단계를 따라 무료 라이센스를 등록하고 소프트웨어를 다운로드하세요.</p>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>등록 페이지 방문</b><br /><a href=\"https://reg.franzis.de/reg/HPW-22338000/999999999/0/502/1.3/3/de\">여기</a>를 클릭하여 Franzis의 등록 페이지로 이동하세요.</li>\n<li><b>이메일 주소 입력 및 약관 동의</b><br />이메일 주소를 입력하고 약관 동의 체크박스를 클릭한 후, 캡차 인증을 완료합니다.</li>\n<li><b>이메일 확인</b><br />Franzis에서 보내온 이메일을 열고 확인 링크를 클릭하여 등록을 완료합니다.</li>\n<li><b>소프트웨어 다운로드 및 설치</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><a href=\"https://transfer.franzis.de/download/kronen/HDR-projects-9_winde.zip\">소프트웨어 다운로드</a> 링크를 클릭하여 파일을 저장합니다.</li>\n<li>설치 파일을 실행하고 제공된 시리얼 번호로 소프트웨어를 활성화합니다.</li>\n</ul>\n</li>\n</ol>\n<p data-ke-size=\"size18\">이 간단한 과정을 완료하면 Franzis HDR Projects 9 Pro의 모든 기능을 무료로 이용할 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Franzis_HDR_Projects_9.gif\" data-origin-width=\"899\" data-origin-height=\"655\"><span data-url=\"https://blog.kakaocdn.net/dn/rJyZs/btsK6lRyVjY/HfFGfaCRIZvnBzBAxtCtY0/img.gif\" data-phocus=\"https://blog.kakaocdn.net/dn/rJyZs/btsK6lRyVjY/HfFGfaCRIZvnBzBAxtCtY0/img.gif\"><img src=\"https://blog.kakaocdn.net/dn/rJyZs/btsK6lRyVjY/HfFGfaCRIZvnBzBAxtCtY0/img.gif\" srcset=\"https://blog.kakaocdn.net/dn/rJyZs/btsK6lRyVjY/HfFGfaCRIZvnBzBAxtCtY0/img.gif\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Franzis_HDR_Projects_9.gif\" data-origin-width=\"899\" data-origin-height=\"655\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>Franzis HDR Projects 9 Pro: 활용 사례와 혜택</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>1. 초보자에게 완벽한 입문 도구</b></span></h3>\n<p data-ke-size=\"size18\">사진 편집에 익숙하지 않은 사용자도 간단한 인터페이스와 자동화 기능 덕분에 멋진 HDR 사진을 손쉽게 만들 수 있습니다. 프리셋을 활용하여 몇 번의 클릭만으로도 놀라운 결과를 얻을 수 있습니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>2. 전문가를 위한 고급 옵션</b></span></h3>\n<p data-ke-size=\"size18\">사진 작가와 편집 전문가들은 세부적인 RAW 편집, 배치 처리, 그리고 Photoshop 및 Lightroom 플러그인 지원을 통해 작업 효율성을 높이고 창의력을 극대화할 수 있습니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>3. 시간 절약과 생산성 향상</b></span></h3>\n<p data-ke-size=\"size18\">배치 처리 및 진행 상태 저장 기능은 특히 시간 관리를 중요시하는 사용자들에게 큰 장점으로 작용합니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>마치며</b></span></h2>\n<p data-ke-size=\"size18\">Franzis HDR Projects 9 Pro는 HDR 사진 편집의 새로운 표준을 제시하는 소프트웨어로, 초보자와 전문가 모두에게 유용한 도구입니다. 지금 바로 무료 라이센스를 등록하여 이 강력한 소프트웨어를 체험해보세요. 생동감 넘치는 HDR 사진의 세계로 여러분을 초대합니다.</p>",
        "contentSnippet": "Franzis HDR Projects 9 Pro는 HDR 사진 편집을 위한 전문 소프트웨어로, 무료 라이센스를 통해 강력한 RAW 처리, 다양한 프리셋, 배치 처리 기능을 체험해보세요.\n\n\n \n HDR(High-Dynamic-Range) 사진은 디지털 사진의 새로운 가능성을 열어주는 기술적 혁신입니다. Franzis HDR Projects 9 Pro는 이러한 HDR 사진 제작 및 편집을 위한 전문적인 소프트웨어로, 초보자부터 전문가까지 누구나 활용할 수 있는 기능을 제공합니다. 이 소프트웨어는 RAW 이미지 처리, 다양한 프리셋, 배치 처리 모드 등 폭넓은 기능을 포함하고 있으며, 특히 Adobe Photoshop과 Lightroom 같은 유명한 이미지 편집 툴과도 호환됩니다.\n \nFranzis HDR Projects 9 Pro의 강력한 기능과 무료 라이센스를 얻는 방법을 자세히 소개합니다.\n \nFranzis HDR Projects 9 Pro: 주요 기능\n\n\n1. 전문적인 RAW 이미지 처리\nHDR Projects 9 Pro는 전문 RAW 컨버터의 모든 기능을 갖춘 강력한 RAW 이미지 처리 모듈을 제공합니다. 이 모듈은 다음과 같은 고급 편집 기능을 지원합니다:\n밝기, 대비, 채도, 색조 등 세부적인 이미지 조정.\nRAW 파일에서 노출, 화이트 밸런스, 디테일을 정확하게 제어.\n사용자가 원하는 대로 왜곡을 보정하여 완벽한 이미지를 생성.\nRAW 이미지는 사진의 원본 데이터를 보존하여 최대한의 품질을 유지하기 때문에, 전문가들은 대부분 이 형식을 선호합니다. 이 소프트웨어는 RAW 파일의 잠재력을 최대한 끌어낼 수 있도록 설계되었습니다.\n2. 다양한 프리셋과 효과\nFranzis HDR Projects 9 Pro는 188가지의 프리셋과 다양한 HDR 알고리즘을 제공하여 사용자가 빠르고 쉽게 원하는 결과물을 얻을 수 있습니다. 예를 들어:\n클래식 HDR: 일반적인 HDR 사진의 선명함과 생동감을 강조.\n드라마틱 효과: 강렬하고 독특한 스타일 구현.\n흑백 사진: 깊이 있는 흑백 톤으로 변환.\n사용자 정의 프리셋: 개인적인 스타일을 반영한 설정 저장.\n이 프리셋은 초보자에게 특히 유용하며, 버튼 몇 번만으로 전문적인 결과를 얻을 수 있도록 도와줍니다.\n3. 배치 처리와 자동화\n많은 사진을 한꺼번에 처리해야 하는 경우, 배치 처리 기능이 큰 도움을 줄 수 있습니다. Franzis HDR Projects 9 Pro의 배치 처리 모드는 다음과 같은 이점을 제공합니다:\n폴더 전체를 불러와 자동으로 HDR 이미지 생성.\n자동 브라케팅 감지 기능을 통해 다양한 노출값을 가진 사진을 합성.\n작업 중 중단된 경우에도 진행 상태를 저장하여 언제든 복구 가능.\n이 기능은 특히 많은 양의 사진을 관리하는 전문가에게 시간과 노력을 절약해주는 핵심 도구입니다.\n4. Adobe Photoshop 및 Lightroom 플러그인 지원\nFranzis HDR Projects 9 Pro는 독립적인 소프트웨어로 사용할 수도 있지만, Adobe Photoshop 및 Lightroom과의 플러그인 형태로도 사용할 수 있어 더 큰 유연성을 제공합니다. 이 플러그인을 통해:\nPhotoshop에서 직접 HDR Projects의 고급 기능을 활용.\nLightroom에서 사진을 가져와 추가적으로 편집 가능.\n이러한 호환성은 기존의 워크플로를 방해하지 않으면서 HDR 편집 도구를 추가로 사용할 수 있는 기회를 제공합니다.\n \n \nFranzis HDR Projects 9 Pro 무료 라이센스 등록 방법\n지금 Franzis HDR Projects 9 Pro를 무료로 이용할 수 있는 특별한 기회가 제공되고 있습니다. 다음 단계를 따라 무료 라이센스를 등록하고 소프트웨어를 다운로드하세요.\n등록 페이지 방문\n여기를 클릭하여 Franzis의 등록 페이지로 이동하세요.\n이메일 주소 입력 및 약관 동의\n이메일 주소를 입력하고 약관 동의 체크박스를 클릭한 후, 캡차 인증을 완료합니다.\n이메일 확인\nFranzis에서 보내온 이메일을 열고 확인 링크를 클릭하여 등록을 완료합니다.\n소프트웨어 다운로드 및 설치\n\n소프트웨어 다운로드 링크를 클릭하여 파일을 저장합니다.\n설치 파일을 실행하고 제공된 시리얼 번호로 소프트웨어를 활성화합니다.\n이 간단한 과정을 완료하면 Franzis HDR Projects 9 Pro의 모든 기능을 무료로 이용할 수 있습니다.\n\n\n \n \nFranzis HDR Projects 9 Pro: 활용 사례와 혜택\n1. 초보자에게 완벽한 입문 도구\n사진 편집에 익숙하지 않은 사용자도 간단한 인터페이스와 자동화 기능 덕분에 멋진 HDR 사진을 손쉽게 만들 수 있습니다. 프리셋을 활용하여 몇 번의 클릭만으로도 놀라운 결과를 얻을 수 있습니다.\n2. 전문가를 위한 고급 옵션\n사진 작가와 편집 전문가들은 세부적인 RAW 편집, 배치 처리, 그리고 Photoshop 및 Lightroom 플러그인 지원을 통해 작업 효율성을 높이고 창의력을 극대화할 수 있습니다.\n3. 시간 절약과 생산성 향상\n배치 처리 및 진행 상태 저장 기능은 특히 시간 관리를 중요시하는 사용자들에게 큰 장점으로 작용합니다.\n \n \n마치며\nFranzis HDR Projects 9 Pro는 HDR 사진 편집의 새로운 표준을 제시하는 소프트웨어로, 초보자와 전문가 모두에게 유용한 도구입니다. 지금 바로 무료 라이센스를 등록하여 이 강력한 소프트웨어를 체험해보세요. 생동감 넘치는 HDR 사진의 세계로 여러분을 초대합니다.",
        "guid": "http://muzbox.tistory.com/483507",
        "categories": [
          "NEWS/프리웨어 뉴스",
          "hdr projects 9",
          "HDR 사진",
          "라이센스키 활성화",
          "무료 소프트웨어",
          "사진 편집",
          "사진 편집 툴",
          "정품인증"
        ],
        "isoDate": "2024-12-03T06:37:13.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "윈도우용 추천 프리웨어 (2024.12.2)  화면인쇄, 매크로, 디스크 모니터링, 이미지 최적화, 텍스트 에디터",
        "link": "http://muzbox.tistory.com/483506",
        "pubDate": "Mon, 2 Dec 2024 10:09:33 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483506#entry483506comment",
        "content": "<p style=\"text-align: left;\" data-ke-size=\"size18\"><span style=\"background-color: #ffffff; color: #0d0d0d; text-align: start;\">&nbsp;네이버 소프트웨어와 같은 프로그램 소개 사이트가 종료된 후, 윈도우 운영체제를 사용하는 이용자들을 위해 공개 프리웨어 및 오픈소스 프로그램을 소개합니다. 유용한 무료 소프트웨어를 찾고자 하는 사용자들에게 정기적으로 알찬 정보를 제공합니다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"추천프리웨어 241202.png\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/qsQib/btsK18NfbZh/pk2dtGBpej43xondRaNzQK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/qsQib/btsK18NfbZh/pk2dtGBpej43xondRaNzQK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/qsQib/btsK18NfbZh/pk2dtGBpej43xondRaNzQK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FqsQib%2FbtsK18NfbZh%2Fpk2dtGBpej43xondRaNzQK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"윈도우용 추천 프리웨어\" data-filename=\"추천프리웨어 241202.png\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\">&nbsp;</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\"><span style=\"color: #333333; text-align: left;\">&nbsp;윈도우용 응용프로그램 (Application)은 수없이 많은 종류가 많은 개발자들에 의해 하루에도 수백,수천개가 새로 출시되고 그보다 더 많은 수의 프로그램들이 업데이트 됩니다. 이들 응용프로그램 (Application)은 비율을 지불해야하는<span>&nbsp;</span></span><b><span style=\"color: #009a87;\">상용프로그램</span></b><span style=\"color: #333333; text-align: left;\">과 정품 구매를 확대하기 위해 공급하는 일종의 샘플 개념의<span>&nbsp;</span></span><span style=\"color: #ee2323;\"><b>쉐어웨어</b></span><span style=\"color: #333333; text-align: left;\">, 무료로 사용할 수 있는<span>&nbsp;</span></span><b><span style=\"color: #ef6f53;\">프리웨어</span></b>등으로 크게 3가지로 나뉘게 되는데요.</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\"><br />&nbsp;물론 프리웨어에도 개인만 사용할 있다던가, 기업이나 관공서에서도 사용이 가능하다던가, 소스까지 같이 공개하여 맘대로 수정과 배포가 가능한 완전 무료등의 추가 분류가 필요합니다. 하지만, 개발자가 공개하는 무료배포의 의미가 정확하지 않는 프로그램도 많고, 저작권의 정의도 각양각색이라 본 블로그에서 소개하는 프리웨어도<span>&nbsp;</span><span style=\"color: #006dd7;\"><b>최대한 확인이 가능한 범위에서 개인 또는 기업에서 사용가능한지를 구분하여 소개</b></span>하고 있습니다.</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\">&nbsp;</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\">&nbsp;</p>\n<p style=\"text-align: center;\" data-ke-size=\"size18\">'어떤오후의 프리웨어 이야기'에서 추천하는<br /><span style=\"color: #409d00;\">&nbsp;<b>2024년 12월 2일자 공개자료실 윈도우용 추천 프리웨어</b></span>입니다.</p>\n<p id=\"no_1\" data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000;\" data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>1. Hardcopy&nbsp;(화면&nbsp;내용을&nbsp;프린터로&nbsp;출력)<br /></b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp; &nbsp;화면&nbsp;캡처&nbsp;및&nbsp;인쇄를&nbsp;간편하게&nbsp;할&nbsp;수&nbsp;있는&nbsp;프로그램으로,&nbsp;기존의&nbsp;소프트웨어와&nbsp;달리&nbsp;'하드'&nbsp;캡처를&nbsp;제공합니다.&nbsp;설치&nbsp;후&nbsp;[Print&nbsp;Screen]&nbsp;키를&nbsp;누르면&nbsp;즉시&nbsp;화면&nbsp;전체가&nbsp;프린터로&nbsp;출력되며,&nbsp;활성&nbsp;창의&nbsp;최소화,&nbsp;최대화,&nbsp;닫기&nbsp;버튼&nbsp;옆에&nbsp;새로&nbsp;생긴&nbsp;녹색&nbsp;버튼을&nbsp;누르면&nbsp;현재&nbsp;창만&nbsp;출력할&nbsp;수&nbsp;있습니다.&nbsp;같은&nbsp;기능은&nbsp;[Alt]&nbsp;+&nbsp;[Print&nbsp;Screen]&nbsp;조합으로도&nbsp;실행&nbsp;가능합니다. <br /><br />또한&nbsp;Hardcopy는&nbsp;화면&nbsp;캡처&nbsp;및&nbsp;편집&nbsp;도구를&nbsp;포함하고&nbsp;있어&nbsp;작업&nbsp;표시줄&nbsp;아이콘을&nbsp;통해&nbsp;개체나&nbsp;사각형&nbsp;영역&nbsp;등&nbsp;다양한&nbsp;캡처&nbsp;옵션을&nbsp;제공합니다.&nbsp;이러한&nbsp;캡처는&nbsp;바로&nbsp;출력되지&nbsp;않고&nbsp;편집&nbsp;창에서&nbsp;제목&nbsp;추가,&nbsp;주석&nbsp;작성,&nbsp;색상&nbsp;조정&nbsp;등&nbsp;후속&nbsp;작업이&nbsp;가능합니다.&nbsp;더불어&nbsp;EXE와&nbsp;DLL&nbsp;파일에서&nbsp;비트맵과&nbsp;아이콘을&nbsp;추출하는&nbsp;기능도&nbsp;제공합니다. <br /><br />이 프로그램은 많은 옵션과 기능을 제공하며, 기본 사용법을 익히면서 점진적으로 활용할 수 있습니다. 무료로 사용할 수 있지만, 등록 시 더 많은 기능이 활성화됩니다. 캡처된 이미지는 다양한 포맷으로 저장 가능하며, 주된 목적은 화면 출력 기능에 초점을 맞춰 탁월한 성능을 제공합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Hardcopy.jpg\" data-origin-width=\"800\" data-origin-height=\"621\"><span data-url=\"https://blog.kakaocdn.net/dn/bKnr4b/btsK33czqer/AaDIl0Hn1ylzjitAqwYd9k/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bKnr4b/btsK33czqer/AaDIl0Hn1ylzjitAqwYd9k/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bKnr4b/btsK33czqer/AaDIl0Hn1ylzjitAqwYd9k/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbKnr4b%2FbtsK33czqer%2FAaDIl0Hn1ylzjitAqwYd9k%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Hardcopy.jpg\" data-origin-width=\"800\" data-origin-height=\"621\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶ 프리웨어 - 개인</p>\n<p data-ke-size=\"size18\">▶ Windows 10/11</p>\n<p data-ke-size=\"size18\">▶무료 다운로드◀</p>\n<figure id=\"og_1733101595752\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Hardcopy for Windows 11, 10, 8, 7, etc. (32+64 Bit)\" data-og-description=\"\" data-og-host=\"gen.hardcopy.de\" data-og-source-url=\"https://gen.hardcopy.de/\" data-og-url=\"https://gen.hardcopy.de/\" data-og-image=\"\"><a href=\"https://gen.hardcopy.de/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://gen.hardcopy.de/\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Hardcopy for Windows 11, 10, 8, 7, etc. (32+64 Bit)</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">&nbsp;</p>\n<p class=\"og-host\" data-ke-size=\"size16\">gen.hardcopy.de</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"no_2\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000;\" data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>2. PhraseExpress&nbsp;(다기능&nbsp;키보드&nbsp;매크로&nbsp;도구)</b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp; 텍스트&nbsp;자동&nbsp;완성&nbsp;및&nbsp;교체를&nbsp;통해&nbsp;생산성을&nbsp;높여주는&nbsp;도구로,&nbsp;거의&nbsp;모든&nbsp;Windows&nbsp;애플리케이션에서&nbsp;활용&nbsp;가능합니다.&nbsp; <br /><br />이&nbsp;프로그램은&nbsp;\"adr\"을&nbsp;입력하면&nbsp;주소로,&nbsp;\"sig\"를&nbsp;입력하면&nbsp;서명으로&nbsp;자동&nbsp;변환하는&nbsp;방식으로&nbsp;자주&nbsp;사용하는&nbsp;구문을&nbsp;자동으로&nbsp;확장합니다.&nbsp;사용자는&nbsp;원하는&nbsp;만큼&nbsp;구문을&nbsp;생성할&nbsp;수&nbsp;있으며,&nbsp;대부분의&nbsp;Windows&nbsp;프로그램에서&nbsp;동작합니다. <br /><br />자동&nbsp;맞춤법&nbsp;검사&nbsp;기능도&nbsp;유용합니다.&nbsp;별도의&nbsp;설정&nbsp;없이&nbsp;백그라운드에서&nbsp;작동하며&nbsp;사용자가&nbsp;입력한&nbsp;텍스트를&nbsp;모니터링하여&nbsp;오류를&nbsp;즉시&nbsp;수정합니다.&nbsp;이&nbsp;기능은&nbsp;Notepad,&nbsp;모든&nbsp;브라우저&nbsp;등&nbsp;텍스트&nbsp;입력이&nbsp;가능한&nbsp;모든&nbsp;곳에서&nbsp;사용&nbsp;가능합니다. <br /><br />클립보드&nbsp;캐시&nbsp;기능은&nbsp;최근에&nbsp;복사한&nbsp;내용을&nbsp;추적하여,&nbsp;실수로&nbsp;URL&nbsp;같은&nbsp;중요한&nbsp;내용을&nbsp;덮어썼더라도&nbsp;시스템&nbsp;트레이&nbsp;아이콘의&nbsp;Clipboard&nbsp;Express에서&nbsp;복원할&nbsp;수&nbsp;있습니다. <br /><br />또한,&nbsp;PhraseExpress는&nbsp;반복적으로&nbsp;입력되는&nbsp;텍스트를&nbsp;자동으로&nbsp;인식하여&nbsp;전체&nbsp;문장을&nbsp;완성하거나,&nbsp;매크로&nbsp;기능을&nbsp;통해&nbsp;텍스트&nbsp;단축키로&nbsp;특정&nbsp;작업을&nbsp;수행할&nbsp;수&nbsp;있습니다.&nbsp;예를&nbsp;들어&nbsp;\"word\"를&nbsp;입력하면&nbsp;Microsoft&nbsp;Word를&nbsp;실행하도록&nbsp;설정할&nbsp;수&nbsp;있습니다.&nbsp;다양한&nbsp;설정&nbsp;옵션을&nbsp;통해&nbsp;사용자&nbsp;취향에&nbsp;맞게&nbsp;프로그램을&nbsp;완벽히&nbsp;커스터마이징할&nbsp;수&nbsp;있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"PhraseExpress.png\" data-origin-width=\"1350\" data-origin-height=\"938\"><span data-url=\"https://blog.kakaocdn.net/dn/cDT04e/btsK2ZaVOxl/Ji48TBGh7N5ktMUvarkPLk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cDT04e/btsK2ZaVOxl/Ji48TBGh7N5ktMUvarkPLk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cDT04e/btsK2ZaVOxl/Ji48TBGh7N5ktMUvarkPLk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcDT04e%2FbtsK2ZaVOxl%2FJi48TBGh7N5ktMUvarkPLk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"PhraseExpress.png\" data-origin-width=\"1350\" data-origin-height=\"938\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인</p>\n<p data-ke-size=\"size18\">▶Windows 10/11</p>\n<p data-ke-size=\"size18\">▶무료 다운로드</p>\n<figure id=\"og_1733101611821\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Autotext - Text Expander - Macro Software\" data-og-description=\"Trusted By More Than 100,000 Customers ...as well as additional well-known companies, banks, clinics, law firms, medical practices, authorities and private users.\" data-og-host=\"www.phraseexpress.com\" data-og-source-url=\"https://www.phraseexpress.com/\" data-og-url=\"https://www.phraseexpress.com/\" data-og-image=\"\"><a href=\"https://www.phraseexpress.com/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.phraseexpress.com/\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Autotext - Text Expander - Macro Software</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Trusted By More Than 100,000 Customers ...as well as additional well-known companies, banks, clinics, law firms, medical practices, authorities and private users.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.phraseexpress.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"no_3\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000;\" data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>3. DiskPulse&nbsp;Free&nbsp;(하드디스크&nbsp;모니터링)</b></i></span></h2>\n<p data-ke-size=\"size18\">텍스트&nbsp;자동&nbsp;완성&nbsp;및&nbsp;교체를&nbsp;통해&nbsp;생산성을&nbsp;높여주는&nbsp;도구로,&nbsp;거의&nbsp;모든&nbsp;Windows&nbsp;애플리케이션에서&nbsp;활용&nbsp;가능합니다. <br /><br />이&nbsp;프로그램은&nbsp;\"adr\"을&nbsp;입력하면&nbsp;주소로,&nbsp;\"sig\"를&nbsp;입력하면&nbsp;서명으로&nbsp;자동&nbsp;변환하는&nbsp;방식으로&nbsp;자주&nbsp;사용하는&nbsp;구문을&nbsp;자동으로&nbsp;확장합니다.&nbsp;사용자는&nbsp;원하는&nbsp;만큼&nbsp;구문을&nbsp;생성할&nbsp;수&nbsp;있으며,&nbsp;대부분의&nbsp;Windows&nbsp;프로그램에서&nbsp;동작합니다. <br /><br />자동&nbsp;맞춤법&nbsp;검사&nbsp;기능도&nbsp;유용합니다.&nbsp;별도의&nbsp;설정&nbsp;없이&nbsp;백그라운드에서&nbsp;작동하며&nbsp;사용자가&nbsp;입력한&nbsp;텍스트를&nbsp;모니터링하여&nbsp;오류를&nbsp;즉시&nbsp;수정합니다.&nbsp;이&nbsp;기능은&nbsp;Notepad,&nbsp;모든&nbsp;브라우저&nbsp;등&nbsp;텍스트&nbsp;입력이&nbsp;가능한&nbsp;모든&nbsp;곳에서&nbsp;사용&nbsp;가능합니다. <br /><br />클립보드&nbsp;캐시&nbsp;기능은&nbsp;최근에&nbsp;복사한&nbsp;내용을&nbsp;추적하여,&nbsp;실수로&nbsp;URL&nbsp;같은&nbsp;중요한&nbsp;내용을&nbsp;덮어썼더라도&nbsp;시스템&nbsp;트레이&nbsp;아이콘의&nbsp;Clipboard&nbsp;Express에서&nbsp;복원할&nbsp;수&nbsp;있습니다. <br /><br />또한, PhraseExpress는 반복적으로 입력되는 텍스트를 자동으로 인식하여 전체 문장을 완성하거나, 매크로 기능을 통해 텍스트 단축키로 특정 작업을 수행할 수 있습니다. 예를 들어 \"word\"를 입력하면 Microsoft Word를 실행하도록 설정할 수 있습니다. 다양한 설정 옵션을 통해 사용자 취향에 맞게 프로그램을 완벽히 커스터마이징할 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"DiskPulse Free.png\" data-origin-width=\"808\" data-origin-height=\"563\"><span data-url=\"https://blog.kakaocdn.net/dn/yd6Jr/btsK2uJhOSS/UZyKUeb44ZHnF5fnBGT6hK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/yd6Jr/btsK2uJhOSS/UZyKUeb44ZHnF5fnBGT6hK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/yd6Jr/btsK2uJhOSS/UZyKUeb44ZHnF5fnBGT6hK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fyd6Jr%2FbtsK2uJhOSS%2FUZyKUeb44ZHnF5fnBGT6hK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"DiskPulse Free.png\" data-origin-width=\"808\" data-origin-height=\"563\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶ 프리웨어 - 개인</p>\n<p data-ke-size=\"size18\">▶Windows 10/11&nbsp;</p>\n<p data-ke-size=\"size18\">▶무료 다운로드 ◀</p>\n<figure id=\"og_1733101642601\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"DiskPulse - Disk Change Monitor\" data-og-description=\"DiskPulse News 27-Nov-2024 - DiskPulse v16.6 adds the ability to display pie charts showing the number of changed files and changed disk space per file extension, file type, user name, etc. for specific types of files according to one or more user-specifie\" data-og-host=\"www.diskpulse.com\" data-og-source-url=\"https://www.diskpulse.com/\" data-og-url=\"https://www.diskpulse.com/\" data-og-image=\"https://scrap.kakaocdn.net/dn/8qPkl/hyXGKR7MFB/InDBooVfjjwoNoSyssgkvk/img.jpg?width=340&amp;height=259&amp;face=0_0_340_259\"><a href=\"https://www.diskpulse.com/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.diskpulse.com/\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/8qPkl/hyXGKR7MFB/InDBooVfjjwoNoSyssgkvk/img.jpg?width=340&amp;height=259&amp;face=0_0_340_259');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">DiskPulse - Disk Change Monitor</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">DiskPulse News 27-Nov-2024 - DiskPulse v16.6 adds the ability to display pie charts showing the number of changed files and changed disk space per file extension, file type, user name, etc. for specific types of files according to one or more user-specifie</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.diskpulse.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"no_4\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000;\" data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>4. PilotEdit Lite (프로그래밍, 웹 개발에 특화된 에디터)<br /></b></i></span></h2>\n<p data-ke-size=\"size18\">텍스트&nbsp;자동&nbsp;완성&nbsp;및&nbsp;교체를&nbsp;통해&nbsp;생산성을&nbsp;높여주는&nbsp;도구로,&nbsp;거의&nbsp;모든&nbsp;Windows&nbsp;애플리케이션에서&nbsp;활용&nbsp;가능합니다. <br /><br />이&nbsp;프로그램은&nbsp;\"adr\"을&nbsp;입력하면&nbsp;주소로,&nbsp;\"sig\"를&nbsp;입력하면&nbsp;서명으로&nbsp;자동&nbsp;변환하는&nbsp;방식으로&nbsp;자주&nbsp;사용하는&nbsp;구문을&nbsp;자동으로&nbsp;확장합니다.&nbsp;사용자는&nbsp;원하는&nbsp;만큼&nbsp;구문을&nbsp;생성할&nbsp;수&nbsp;있으며,&nbsp;대부분의&nbsp;Windows&nbsp;프로그램에서&nbsp;동작합니다. <br /><br />자동&nbsp;맞춤법&nbsp;검사&nbsp;기능도&nbsp;유용합니다.&nbsp;별도의&nbsp;설정&nbsp;없이&nbsp;백그라운드에서&nbsp;작동하며&nbsp;사용자가&nbsp;입력한&nbsp;텍스트를&nbsp;모니터링하여&nbsp;오류를&nbsp;즉시&nbsp;수정합니다.&nbsp;이&nbsp;기능은&nbsp;Notepad,&nbsp;모든&nbsp;브라우저&nbsp;등&nbsp;텍스트&nbsp;입력이&nbsp;가능한&nbsp;모든&nbsp;곳에서&nbsp;사용&nbsp;가능합니다. <br /><br />클립보드&nbsp;캐시&nbsp;기능은&nbsp;최근에&nbsp;복사한&nbsp;내용을&nbsp;추적하여,&nbsp;실수로&nbsp;URL&nbsp;같은&nbsp;중요한&nbsp;내용을&nbsp;덮어썼더라도&nbsp;시스템&nbsp;트레이&nbsp;아이콘의&nbsp;Clipboard&nbsp;Express에서&nbsp;복원할&nbsp;수&nbsp;있습니다. <br /><br />또한, PhraseExpress는 반복적으로 입력되는 텍스트를 자동으로 인식하여 전체 문장을 완성하거나, 매크로 기능을 통해 텍스트 단축키로 특정 작업을 수행할 수 있습니다. 예를 들어 \"word\"를 입력하면 Microsoft Word를 실행하도록 설정할 수 있습니다. 다양한 설정 옵션을 통해 사용자 취향에 맞게 프로그램을 완벽히 커스터마이징할 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"PilotEdit Lite.png\" data-origin-width=\"676\" data-origin-height=\"559\"><span data-url=\"https://blog.kakaocdn.net/dn/bydU0D/btsK2vVEG0L/L1oZdbs3ZWvAjiE1YZca00/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bydU0D/btsK2vVEG0L/L1oZdbs3ZWvAjiE1YZca00/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bydU0D/btsK2vVEG0L/L1oZdbs3ZWvAjiE1YZca00/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbydU0D%2FbtsK2vVEG0L%2FL1oZdbs3ZWvAjiE1YZca00%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"PilotEdit Lite.png\" data-origin-width=\"676\" data-origin-height=\"559\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인</p>\n<p data-ke-size=\"size18\">▶Windows 10/11</p>\n<p data-ke-size=\"size18\">▶무료 다운로드 ◀</p>\n<figure id=\"og_1733101663899\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"PilotEdit - Edit and Compare Large Files\" data-og-description=\"PilotEdit is a handy text editor you can use for working with plain text files, as well as for coding projects in a bunch of popular programming languages: HTML, PHP, Java and more. - softonic.com editors\" data-og-host=\"www.pilotedit.com\" data-og-source-url=\"https://www.pilotedit.com/\" data-og-url=\"https://www.pilotedit.com/\" data-og-image=\"https://scrap.kakaocdn.net/dn/BjttR/hyXGCfte17/ollHcFDms25gIEkNbXwkrk/img.jpg?width=750&amp;height=1334&amp;face=0_0_750_1334,https://scrap.kakaocdn.net/dn/bVhQWW/hyXGKxPnNK/GeOFQD1N6VIcKoXrXKwlsK/img.jpg?width=375&amp;height=667&amp;face=0_0_375_667,https://scrap.kakaocdn.net/dn/eLD1G/hyXGG92bb3/tKjJpVbhrtWhH1t0hpzU71/img.jpg?width=375&amp;height=667&amp;face=0_0_375_667\"><a href=\"https://www.pilotedit.com/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.pilotedit.com/\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/BjttR/hyXGCfte17/ollHcFDms25gIEkNbXwkrk/img.jpg?width=750&amp;height=1334&amp;face=0_0_750_1334,https://scrap.kakaocdn.net/dn/bVhQWW/hyXGKxPnNK/GeOFQD1N6VIcKoXrXKwlsK/img.jpg?width=375&amp;height=667&amp;face=0_0_375_667,https://scrap.kakaocdn.net/dn/eLD1G/hyXGG92bb3/tKjJpVbhrtWhH1t0hpzU71/img.jpg?width=375&amp;height=667&amp;face=0_0_375_667');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">PilotEdit - Edit and Compare Large Files</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">PilotEdit is a handy text editor you can use for working with plain text files, as well as for coding projects in a bunch of popular programming languages: HTML, PHP, Java and more. - softonic.com editors</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.pilotedit.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"no_5\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000;\" data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>5. Fotor&nbsp;(이미지&nbsp;최적화&nbsp;도구)</b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp; 디지털&nbsp;이미지를&nbsp;간편하게&nbsp;최적화할&nbsp;수&nbsp;있는&nbsp;사용자&nbsp;친화적인&nbsp;사진&nbsp;편집&nbsp;도구로,&nbsp;JPEG,&nbsp;PNG와&nbsp;같은&nbsp;일반적인&nbsp;이미지&nbsp;파일뿐&nbsp;아니라&nbsp;다양한&nbsp;RAW&nbsp;포맷도&nbsp;지원합니다.&nbsp; <br /><br />조명&nbsp;문제가&nbsp;있는&nbsp;사진의&nbsp;경우,&nbsp;복잡한&nbsp;설정&nbsp;없이도&nbsp;촬영&nbsp;당시의&nbsp;조건을&nbsp;선택하는&nbsp;것만으로&nbsp;이미지를&nbsp;최적화할&nbsp;수&nbsp;있습니다.&nbsp;예를&nbsp;들어,&nbsp;\"역광\",&nbsp;\"흐림\",&nbsp;\"일몰\"&nbsp;등&nbsp;조건을&nbsp;선택하면&nbsp;프로그램이&nbsp;자동으로&nbsp;사진의&nbsp;밝기,&nbsp;대비,&nbsp;색상을&nbsp;조정해&nbsp;적합한&nbsp;결과를&nbsp;제공합니다.&nbsp; <br /><br />또한,&nbsp;사진을&nbsp;더욱&nbsp;흥미롭게&nbsp;꾸미고&nbsp;싶다면&nbsp;60개&nbsp;이상의&nbsp;컬러&nbsp;및&nbsp;조명&nbsp;효과를&nbsp;활용할&nbsp;수&nbsp;있습니다.&nbsp;\"클래식\",&nbsp;\"로모\",&nbsp;\"흑백\",&nbsp;\"비네트\"&nbsp;등&nbsp;다양한&nbsp;카테고리를&nbsp;통해&nbsp;각&nbsp;효과의&nbsp;미리보기를&nbsp;확인하고&nbsp;원하는&nbsp;스타일을&nbsp;클릭&nbsp;한&nbsp;번으로&nbsp;적용할&nbsp;수&nbsp;있습니다.&nbsp;여기에&nbsp;30가지&nbsp;이상의&nbsp;테두리&nbsp;옵션을&nbsp;제공하여&nbsp;사진에&nbsp;개성을&nbsp;더할&nbsp;수도&nbsp;있습니다. <br /><br />Fotor는&nbsp;사진&nbsp;편집&nbsp;효과뿐만&nbsp;아니라&nbsp;실용적인&nbsp;편집&nbsp;도구도&nbsp;제공합니다.&nbsp;이미지의&nbsp;회전,&nbsp;수평&nbsp;조정,&nbsp;선명도&nbsp;및&nbsp;블러&nbsp;효과&nbsp;적용,&nbsp;노출,&nbsp;밝기,&nbsp;대비,&nbsp;채도,&nbsp;색온도,&nbsp;색조&nbsp;조정&nbsp;등이&nbsp;가능하며,&nbsp;이미지&nbsp;자르기와&nbsp;EXIF&nbsp;데이터&nbsp;확인도&nbsp;지원합니다.&nbsp;특히&nbsp;Tilt-Shift&nbsp;효과는&nbsp;블러의&nbsp;강도와&nbsp;위치를&nbsp;세밀하게&nbsp;조정할&nbsp;수&nbsp;있어&nbsp;사진에&nbsp;독특한&nbsp;초점&nbsp;효과를&nbsp;줄&nbsp;수&nbsp;있습니다. <br /><br />Fotor는 복잡한 기술 없이도 쉽고 빠르게 사진을 최적화하거나 개성 있게 꾸밀 수 있는 도구로, 초보자부터 숙련된 사용자까지 폭넓게 활용할 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Fotor.png\" data-origin-width=\"1109\" data-origin-height=\"690\"><span data-url=\"https://blog.kakaocdn.net/dn/WV5JH/btsK2TV5rpj/3y1H605jvuXLb8TBTZmVA1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/WV5JH/btsK2TV5rpj/3y1H605jvuXLb8TBTZmVA1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/WV5JH/btsK2TV5rpj/3y1H605jvuXLb8TBTZmVA1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FWV5JH%2FbtsK2TV5rpj%2F3y1H605jvuXLb8TBTZmVA1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Fotor.png\" data-origin-width=\"1109\" data-origin-height=\"690\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인</p>\n<p data-ke-size=\"size18\">▶Windows 10/11</p>\n<p data-ke-size=\"size18\">▶무료 다운로드 ◀</p>\n<figure id=\"og_1733101689851\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Photo Editor: Free Online Photo Editing &amp; Image Editor | Fotor\" data-og-description=\"Enhance and edit photos with Fotor&rsquo;s free online photo editor. Crop, add text &amp; effects, retouch images, and more using powerful photo editing tools.\" data-og-host=\"www.fotor.com\" data-og-source-url=\"https://www.fotor.com/\" data-og-url=\"https://www.fotor.com/\" data-og-image=\"https://scrap.kakaocdn.net/dn/bx13By/hyXGAveFVe/ukoJPlVorcK5QTiu9cbmg1/img.png?width=1200&amp;height=900&amp;face=646_95_1172_670,https://scrap.kakaocdn.net/dn/gQZno/hyXGM3udtG/TcXaKKkE2vA1WQXdW0374K/img.png?width=1200&amp;height=900&amp;face=646_95_1172_670,https://scrap.kakaocdn.net/dn/8wS3N/hyXGAveFNB/R5kT54fRgqKNkU6cawL9V0/img.png?width=1200&amp;height=900&amp;face=646_95_1172_670\"><a href=\"https://www.fotor.com/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.fotor.com/\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/bx13By/hyXGAveFVe/ukoJPlVorcK5QTiu9cbmg1/img.png?width=1200&amp;height=900&amp;face=646_95_1172_670,https://scrap.kakaocdn.net/dn/gQZno/hyXGM3udtG/TcXaKKkE2vA1WQXdW0374K/img.png?width=1200&amp;height=900&amp;face=646_95_1172_670,https://scrap.kakaocdn.net/dn/8wS3N/hyXGAveFNB/R5kT54fRgqKNkU6cawL9V0/img.png?width=1200&amp;height=900&amp;face=646_95_1172_670');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Photo Editor: Free Online Photo Editing &amp; Image Editor | Fotor</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Enhance and edit photos with Fotor&rsquo;s free online photo editor. Crop, add text &amp; effects, retouch images, and more using powerful photo editing tools.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.fotor.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "네이버 소프트웨어와 같은 프로그램 소개 사이트가 종료된 후, 윈도우 운영체제를 사용하는 이용자들을 위해 공개 프리웨어 및 오픈소스 프로그램을 소개합니다. 유용한 무료 소프트웨어를 찾고자 하는 사용자들에게 정기적으로 알찬 정보를 제공합니다.\n\n\n \n 윈도우용 응용프로그램 (Application)은 수없이 많은 종류가 많은 개발자들에 의해 하루에도 수백,수천개가 새로 출시되고 그보다 더 많은 수의 프로그램들이 업데이트 됩니다. 이들 응용프로그램 (Application)은 비율을 지불해야하는 상용프로그램과 정품 구매를 확대하기 위해 공급하는 일종의 샘플 개념의 쉐어웨어, 무료로 사용할 수 있는 프리웨어등으로 크게 3가지로 나뉘게 되는데요.\n 물론 프리웨어에도 개인만 사용할 있다던가, 기업이나 관공서에서도 사용이 가능하다던가, 소스까지 같이 공개하여 맘대로 수정과 배포가 가능한 완전 무료등의 추가 분류가 필요합니다. 하지만, 개발자가 공개하는 무료배포의 의미가 정확하지 않는 프로그램도 많고, 저작권의 정의도 각양각색이라 본 블로그에서 소개하는 프리웨어도 최대한 확인이 가능한 범위에서 개인 또는 기업에서 사용가능한지를 구분하여 소개하고 있습니다.\n \n \n'어떤오후의 프리웨어 이야기'에서 추천하는\n 2024년 12월 2일자 공개자료실 윈도우용 추천 프리웨어입니다.\n \n \n1. Hardcopy (화면 내용을 프린터로 출력)\n\n   화면 캡처 및 인쇄를 간편하게 할 수 있는 프로그램으로, 기존의 소프트웨어와 달리 '하드' 캡처를 제공합니다. 설치 후 [Print Screen] 키를 누르면 즉시 화면 전체가 프린터로 출력되며, 활성 창의 최소화, 최대화, 닫기 버튼 옆에 새로 생긴 녹색 버튼을 누르면 현재 창만 출력할 수 있습니다. 같은 기능은 [Alt] + [Print Screen] 조합으로도 실행 가능합니다. \n또한 Hardcopy는 화면 캡처 및 편집 도구를 포함하고 있어 작업 표시줄 아이콘을 통해 개체나 사각형 영역 등 다양한 캡처 옵션을 제공합니다. 이러한 캡처는 바로 출력되지 않고 편집 창에서 제목 추가, 주석 작성, 색상 조정 등 후속 작업이 가능합니다. 더불어 EXE와 DLL 파일에서 비트맵과 아이콘을 추출하는 기능도 제공합니다. \n이 프로그램은 많은 옵션과 기능을 제공하며, 기본 사용법을 익히면서 점진적으로 활용할 수 있습니다. 무료로 사용할 수 있지만, 등록 시 더 많은 기능이 활성화됩니다. 캡처된 이미지는 다양한 포맷으로 저장 가능하며, 주된 목적은 화면 출력 기능에 초점을 맞춰 탁월한 성능을 제공합니다.\n\n\n▶ 프리웨어 - 개인\n▶ Windows 10/11\n▶무료 다운로드◀\n\n \nHardcopy for Windows 11, 10, 8, 7, etc. (32+64 Bit)\n \ngen.hardcopy.de\n\n \n \n \n \n \n2. PhraseExpress (다기능 키보드 매크로 도구)\n  텍스트 자동 완성 및 교체를 통해 생산성을 높여주는 도구로, 거의 모든 Windows 애플리케이션에서 활용 가능합니다.  \n이 프로그램은 \"adr\"을 입력하면 주소로, \"sig\"를 입력하면 서명으로 자동 변환하는 방식으로 자주 사용하는 구문을 자동으로 확장합니다. 사용자는 원하는 만큼 구문을 생성할 수 있으며, 대부분의 Windows 프로그램에서 동작합니다. \n자동 맞춤법 검사 기능도 유용합니다. 별도의 설정 없이 백그라운드에서 작동하며 사용자가 입력한 텍스트를 모니터링하여 오류를 즉시 수정합니다. 이 기능은 Notepad, 모든 브라우저 등 텍스트 입력이 가능한 모든 곳에서 사용 가능합니다. \n클립보드 캐시 기능은 최근에 복사한 내용을 추적하여, 실수로 URL 같은 중요한 내용을 덮어썼더라도 시스템 트레이 아이콘의 Clipboard Express에서 복원할 수 있습니다. \n또한, PhraseExpress는 반복적으로 입력되는 텍스트를 자동으로 인식하여 전체 문장을 완성하거나, 매크로 기능을 통해 텍스트 단축키로 특정 작업을 수행할 수 있습니다. 예를 들어 \"word\"를 입력하면 Microsoft Word를 실행하도록 설정할 수 있습니다. 다양한 설정 옵션을 통해 사용자 취향에 맞게 프로그램을 완벽히 커스터마이징할 수 있습니다.\n\n\n▶프리웨어 - 개인\n▶Windows 10/11\n▶무료 다운로드\n\n \nAutotext - Text Expander - Macro Software\nTrusted By More Than 100,000 Customers ...as well as additional well-known companies, banks, clinics, law firms, medical practices, authorities and private users.\nwww.phraseexpress.com\n\n \n \n \n \n \n3. DiskPulse Free (하드디스크 모니터링)\n텍스트 자동 완성 및 교체를 통해 생산성을 높여주는 도구로, 거의 모든 Windows 애플리케이션에서 활용 가능합니다. \n이 프로그램은 \"adr\"을 입력하면 주소로, \"sig\"를 입력하면 서명으로 자동 변환하는 방식으로 자주 사용하는 구문을 자동으로 확장합니다. 사용자는 원하는 만큼 구문을 생성할 수 있으며, 대부분의 Windows 프로그램에서 동작합니다. \n자동 맞춤법 검사 기능도 유용합니다. 별도의 설정 없이 백그라운드에서 작동하며 사용자가 입력한 텍스트를 모니터링하여 오류를 즉시 수정합니다. 이 기능은 Notepad, 모든 브라우저 등 텍스트 입력이 가능한 모든 곳에서 사용 가능합니다. \n클립보드 캐시 기능은 최근에 복사한 내용을 추적하여, 실수로 URL 같은 중요한 내용을 덮어썼더라도 시스템 트레이 아이콘의 Clipboard Express에서 복원할 수 있습니다. \n또한, PhraseExpress는 반복적으로 입력되는 텍스트를 자동으로 인식하여 전체 문장을 완성하거나, 매크로 기능을 통해 텍스트 단축키로 특정 작업을 수행할 수 있습니다. 예를 들어 \"word\"를 입력하면 Microsoft Word를 실행하도록 설정할 수 있습니다. 다양한 설정 옵션을 통해 사용자 취향에 맞게 프로그램을 완벽히 커스터마이징할 수 있습니다.\n\n\n▶ 프리웨어 - 개인\n▶Windows 10/11 \n▶무료 다운로드 ◀\n\n \nDiskPulse - Disk Change Monitor\nDiskPulse News 27-Nov-2024 - DiskPulse v16.6 adds the ability to display pie charts showing the number of changed files and changed disk space per file extension, file type, user name, etc. for specific types of files according to one or more user-specifie\nwww.diskpulse.com\n\n \n \n \n \n \n4. PilotEdit Lite (프로그래밍, 웹 개발에 특화된 에디터)\n\n텍스트 자동 완성 및 교체를 통해 생산성을 높여주는 도구로, 거의 모든 Windows 애플리케이션에서 활용 가능합니다. \n이 프로그램은 \"adr\"을 입력하면 주소로, \"sig\"를 입력하면 서명으로 자동 변환하는 방식으로 자주 사용하는 구문을 자동으로 확장합니다. 사용자는 원하는 만큼 구문을 생성할 수 있으며, 대부분의 Windows 프로그램에서 동작합니다. \n자동 맞춤법 검사 기능도 유용합니다. 별도의 설정 없이 백그라운드에서 작동하며 사용자가 입력한 텍스트를 모니터링하여 오류를 즉시 수정합니다. 이 기능은 Notepad, 모든 브라우저 등 텍스트 입력이 가능한 모든 곳에서 사용 가능합니다. \n클립보드 캐시 기능은 최근에 복사한 내용을 추적하여, 실수로 URL 같은 중요한 내용을 덮어썼더라도 시스템 트레이 아이콘의 Clipboard Express에서 복원할 수 있습니다. \n또한, PhraseExpress는 반복적으로 입력되는 텍스트를 자동으로 인식하여 전체 문장을 완성하거나, 매크로 기능을 통해 텍스트 단축키로 특정 작업을 수행할 수 있습니다. 예를 들어 \"word\"를 입력하면 Microsoft Word를 실행하도록 설정할 수 있습니다. 다양한 설정 옵션을 통해 사용자 취향에 맞게 프로그램을 완벽히 커스터마이징할 수 있습니다.\n\n\n▶프리웨어 - 개인\n▶Windows 10/11\n▶무료 다운로드 ◀\n\n \nPilotEdit - Edit and Compare Large Files\nPilotEdit is a handy text editor you can use for working with plain text files, as well as for coding projects in a bunch of popular programming languages: HTML, PHP, Java and more. - softonic.com editors\nwww.pilotedit.com\n\n \n \n \n \n \n5. Fotor (이미지 최적화 도구)\n  디지털 이미지를 간편하게 최적화할 수 있는 사용자 친화적인 사진 편집 도구로, JPEG, PNG와 같은 일반적인 이미지 파일뿐 아니라 다양한 RAW 포맷도 지원합니다.  \n조명 문제가 있는 사진의 경우, 복잡한 설정 없이도 촬영 당시의 조건을 선택하는 것만으로 이미지를 최적화할 수 있습니다. 예를 들어, \"역광\", \"흐림\", \"일몰\" 등 조건을 선택하면 프로그램이 자동으로 사진의 밝기, 대비, 색상을 조정해 적합한 결과를 제공합니다.  \n또한, 사진을 더욱 흥미롭게 꾸미고 싶다면 60개 이상의 컬러 및 조명 효과를 활용할 수 있습니다. \"클래식\", \"로모\", \"흑백\", \"비네트\" 등 다양한 카테고리를 통해 각 효과의 미리보기를 확인하고 원하는 스타일을 클릭 한 번으로 적용할 수 있습니다. 여기에 30가지 이상의 테두리 옵션을 제공하여 사진에 개성을 더할 수도 있습니다. \nFotor는 사진 편집 효과뿐만 아니라 실용적인 편집 도구도 제공합니다. 이미지의 회전, 수평 조정, 선명도 및 블러 효과 적용, 노출, 밝기, 대비, 채도, 색온도, 색조 조정 등이 가능하며, 이미지 자르기와 EXIF 데이터 확인도 지원합니다. 특히 Tilt-Shift 효과는 블러의 강도와 위치를 세밀하게 조정할 수 있어 사진에 독특한 초점 효과를 줄 수 있습니다. \nFotor는 복잡한 기술 없이도 쉽고 빠르게 사진을 최적화하거나 개성 있게 꾸밀 수 있는 도구로, 초보자부터 숙련된 사용자까지 폭넓게 활용할 수 있습니다.\n\n\n▶프리웨어 - 개인\n▶Windows 10/11\n▶무료 다운로드 ◀\n\n \nPhoto Editor: Free Online Photo Editing & Image Editor | Fotor\nEnhance and edit photos with Fotor’s free online photo editor. Crop, add text & effects, retouch images, and more using powerful photo editing tools.\nwww.fotor.com",
        "guid": "http://muzbox.tistory.com/483506",
        "categories": [
          "NEWS/프리웨어 뉴스",
          "hardcopy",
          "공개자료실",
          "이미지 최적화",
          "키보드 매크로",
          "편집 도구",
          "프로그래밍 에디터",
          "프리웨어",
          "프린터 출력",
          "하드디스크 모니터링",
          "화면 캡처"
        ],
        "isoDate": "2024-12-02T01:09:33.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "［RULIWEB］",
        "title": "[MULTI] 넓고 깊고 치열하고 몰입감 있다, 패스 오브 엑자일 2 얼리 액세스",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2270",
        "pubDate": "Sat, 07 Dec 2024 04:00:36 +0900",
        "author": "［RULIWEB］",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/24/12/07/1939d569c0b5104c1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2024-12-06T19:00:36.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "S&amp;P 500 만 투자해도 노후 준비 문제 없다.",
        "link": "http://serverdown.tistory.com/1038",
        "pubDate": "Sun, 8 Dec 2024 18:54:28 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1038#entry1038comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://youtu.be/PoWkJKNCKq8?t=2462\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://youtu.be/PoWkJKNCKq8?t=2462</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=PoWkJKNCKq8\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/uFXWT/hyXGBozBiT/1KSPWeEcmpVwAUZQPQXiGK/img.jpg?width=1280&amp;height=720&amp;face=868_108_1068_326,https://scrap.kakaocdn.net/dn/f9NS7/hyXGB912sU/5LKeEskdpT85OBVOhWEHAK/img.jpg?width=1280&amp;height=720&amp;face=868_108_1068_326\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"&quot;부동산 과몰입이 나라 망쳤다&quot; 노후 멸망하기 싫으면 국장, 부동산에서 돈 빼세요 | 채상욱 대표\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/PoWkJKNCKq8\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">중요한 이야기는 앞에서 길게 하구요</p>\n<p data-ke-size=\"size16\">요약부분은 41분 부터 나옵니다.</p>\n<p data-ke-size=\"size16\">\"미국 S&amp;P 500 계속 사라 노후준비된다.\" 가 핵심이고</p>\n<p data-ke-size=\"size16\">이게 되는 이유는</p>\n<p data-ke-size=\"size16\">현재 정부 관료들이 옛날 생각에 젓어 있으며<br />일본이 했던 짓을 그대로 할 것이라는 겁니다.</p>\n<p data-ke-size=\"size16\">환율을 계속 낮추면 물가가 올라서 해결된다는 생각인데<br />일본이 당했던 그대로 환율이 오르면 소비를 줄여서 침체에 빠지는 현상이 벌어질 것이라는 예상입니다.</p>\n<p data-ke-size=\"size16\">살아남으려면 해외자산을 사는게 맞다 라는 내용입니다.</p>\n<p data-ke-size=\"size16\">만약에 일본처럼 가는 방향이 확인되면 부동산도 다 처분해서 미국 주식 하라는 생각이십니다.<br />침체에 빠지면 부동산도 못살아납니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://youtu.be/PoWkJKNCKq8?t=2462\n\n\n\n중요한 이야기는 앞에서 길게 하구요\n요약부분은 41분 부터 나옵니다.\n\"미국 S&P 500 계속 사라 노후준비된다.\" 가 핵심이고\n이게 되는 이유는\n현재 정부 관료들이 옛날 생각에 젓어 있으며\n일본이 했던 짓을 그대로 할 것이라는 겁니다.\n환율을 계속 낮추면 물가가 올라서 해결된다는 생각인데\n일본이 당했던 그대로 환율이 오르면 소비를 줄여서 침체에 빠지는 현상이 벌어질 것이라는 예상입니다.\n살아남으려면 해외자산을 사는게 맞다 라는 내용입니다.\n만약에 일본처럼 가는 방향이 확인되면 부동산도 다 처분해서 미국 주식 하라는 생각이십니다.\n침체에 빠지면 부동산도 못살아납니다.",
        "guid": "http://serverdown.tistory.com/1038",
        "categories": [
          "투자",
          "미국주식",
          "은퇴"
        ],
        "isoDate": "2024-12-08T09:54:28.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "비상계업의 실제 의미 / 빠떼리아저씨",
        "link": "http://serverdown.tistory.com/1037",
        "pubDate": "Sun, 8 Dec 2024 10:01:07 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1037#entry1037comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=hgzyV5LvUKY\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=hgzyV5LvUKY</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=hgzyV5LvUKY\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/yogB5/hyXGFxM744/lubsbLC1nCKsLkNHk0WDDK/img.jpg?width=1280&amp;height=720&amp;face=320_116_1100_410,https://scrap.kakaocdn.net/dn/HfuvW/hyXKvtt2ai/NHr4YcYOUU0TC438blqKx1/img.jpg?width=1280&amp;height=720&amp;face=320_116_1100_410\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"드러난 계엄령의 이유!! 모든 건 대통령의 치밀하고 놀라운 계획이었다!! (계엄령특집  1편)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/hgzyV5LvUKY\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">나도 당연히 탄핵 될꺼라고 생각했는데<br />그런게 아닌가 봅니다.</p>\n<p data-ke-size=\"size16\">현재 상황이 탄핵이 부결되고 국회에 탄핵파와 반탄핵파가 갈렸습니다.<br />당연히 비상계엄이 실패 했는데 탄핵이 부결이라니 이상합니다.</p>\n<p data-ke-size=\"size16\">요약하자면 국민의힘 당 내에 친문 첩자를 골라내기 위한 비밀의 수 엿습니다.</p>\n<p data-ke-size=\"size16\">이 말이 맞다면 몇가지 가정이 맞아야합니다.</p>\n<p data-ke-size=\"size16\">1. 탄핵이 안 일어난다.<br />2. 종북세력이 진짜로 발견된다. (쯩거가 나온다.)<br />3. 25년에 전세계에서 한국이 주목 받게 된다. (주가 오른다.)<br />&nbsp; &nbsp; - 홀수 해<br />&nbsp; &nbsp; - 선거가 없는 해<br />&nbsp; &nbsp; - 다들 미장 갔다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=hgzyV5LvUKY\n\n\n\n나도 당연히 탄핵 될꺼라고 생각했는데\n그런게 아닌가 봅니다.\n현재 상황이 탄핵이 부결되고 국회에 탄핵파와 반탄핵파가 갈렸습니다.\n당연히 비상계엄이 실패 했는데 탄핵이 부결이라니 이상합니다.\n요약하자면 국민의힘 당 내에 친문 첩자를 골라내기 위한 비밀의 수 엿습니다.\n이 말이 맞다면 몇가지 가정이 맞아야합니다.\n1. 탄핵이 안 일어난다.\n2. 종북세력이 진짜로 발견된다. (쯩거가 나온다.)\n3. 25년에 전세계에서 한국이 주목 받게 된다. (주가 오른다.)\n    - 홀수 해\n    - 선거가 없는 해\n    - 다들 미장 갔다.",
        "guid": "http://serverdown.tistory.com/1037",
        "categories": [
          "유튜브",
          "계엄",
          "정치전략",
          "탄핵"
        ],
        "isoDate": "2024-12-08T01:01:07.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "미국주식 / ETF 요약 /한경글로벌마켓 / 2024-12-06",
        "link": "http://serverdown.tistory.com/1036",
        "pubDate": "Sat, 7 Dec 2024 13:45:26 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1036#entry1036comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=C0yy4YuKvGA\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=C0yy4YuKvGA</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=C0yy4YuKvGA\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bRZ72r/hyXGHI0HCr/LKqW1UZQhJQAfbgI8wGJN1/img.jpg?width=1280&amp;height=720&amp;face=496_244_624_384,https://scrap.kakaocdn.net/dn/TCw2f/hyXKxEJe8t/yCKjt3svzqxau2Pe0oPc8k/img.jpg?width=1280&amp;height=720&amp;face=496_244_624_384\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"11월 고용보고서 | 백악관 AI/크립토 담당국장 임명 | 골드만 픽 &quot;내년엔 회복할 종목&quot; | 벅셔가 \" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/C0yy4YuKvGA\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">1시 18븐 부터 나옵니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">SPXT - S&amp;P 500 에 기술주 뺀거 430개 종</h2>\n<p data-ke-size=\"size16\">S&amp;P 500 에서 기술주만 뺀 ETF&nbsp;</p>\n<p data-ke-size=\"size16\">구글 / 아마존 / 메타 / 테슬라 는 들어가 있다고 합니다.</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">기술주 많이 갔다고 판단해서 만든거 같군요 신기하네요</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">RSP - S&amp;P 500 동일 가중치</h2>\n<p data-ke-size=\"size16\">모든회사에 동일한 비중으로 투자하는 ETF 입니다.</p>\n<p data-ke-size=\"size16\">작은 회사에 더많이 들어가있다고 보시면 됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">JSTC - 성평등 및 환경을 중요하시 하는 회사에 투자</h2>\n<p data-ke-size=\"size16\">CEP 들이 왜이케 LGBT 나 PC주의 꺼내왔는지 알 수 있군요</p>\n<p data-ke-size=\"size16\">그거 주장하면 투자해주는 ETF 가 있었습니다.&nbsp;</p>\n<p data-ke-size=\"size16\">S&amp;P 500 보다 성과가 좋네요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">SGOB - 초단기 채권&nbsp;</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"835\" data-origin-height=\"279\"><span data-url=\"https://blog.kakaocdn.net/dn/1A7AP/btsLbmXtJvx/ZX0qOIVxswXUXNO6FQBGN1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/1A7AP/btsLbmXtJvx/ZX0qOIVxswXUXNO6FQBGN1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/1A7AP/btsLbmXtJvx/ZX0qOIVxswXUXNO6FQBGN1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F1A7AP%2FbtsLbmXtJvx%2FZX0qOIVxswXUXNO6FQBGN1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"835\" data-origin-height=\"279\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">차트모양이 특이하네요</p>\n<p data-ke-size=\"size16\">바당받고&nbsp; 파는 물량때문에 모양이 이런가 봅니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">MSTU - 마이크로스트레티지 2배</h2>\n<p data-ke-size=\"size16\">위아래로 흔들리니 재밌나봅니다.</p>\n<p data-ke-size=\"size16\">갈때는 어마어마하게 잘 갑니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">KORU - 한국 중대형주 3배</h2>\n<p data-ke-size=\"size16\">1시간 27분에 나옵니다.</p>\n<p data-ke-size=\"size16\">계엄령때 거래가 되었다고 합니다.</p>\n<p data-ke-size=\"size16\">-20% 가 터졌을때 산 사람들이 있나봅니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">비트코인</h2>\n<p data-ke-size=\"size16\">파월 푸틴 들도 비트코인이 좋다는 발언을 했었군요</p>\n<p data-ke-size=\"size16\">파월 - 달러랑 금보단 안좋지만 좋다.<br />푸틴 - 아무도 뺏을 수 없다 좋다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">GTBC CRPT BLOK -&nbsp; 코인 관련 사업 ETF</h2>\n<p data-ke-size=\"size16\">코인 관련 사업을 하는 회사에 투자하는 ETF 입니다.</p>\n<p data-ke-size=\"size16\">GBTC 가 좋네요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">여담</h2>\n<p data-ke-size=\"size16\">중국과 반도체에서 유출이 나온다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=C0yy4YuKvGA\n\n\n\n1시 18븐 부터 나옵니다.\n \nSPXT - S&P 500 에 기술주 뺀거 430개 종\nS&P 500 에서 기술주만 뺀 ETF \n구글 / 아마존 / 메타 / 테슬라 는 들어가 있다고 합니다.\n기술주 많이 갔다고 판단해서 만든거 같군요 신기하네요\n \nRSP - S&P 500 동일 가중치\n모든회사에 동일한 비중으로 투자하는 ETF 입니다.\n작은 회사에 더많이 들어가있다고 보시면 됩니다.\n \nJSTC - 성평등 및 환경을 중요하시 하는 회사에 투자\nCEP 들이 왜이케 LGBT 나 PC주의 꺼내왔는지 알 수 있군요\n그거 주장하면 투자해주는 ETF 가 있었습니다. \nS&P 500 보다 성과가 좋네요\n \nSGOB - 초단기 채권 \n\n\n차트모양이 특이하네요\n바당받고  파는 물량때문에 모양이 이런가 봅니다.\n \nMSTU - 마이크로스트레티지 2배\n위아래로 흔들리니 재밌나봅니다.\n갈때는 어마어마하게 잘 갑니다.\n \nKORU - 한국 중대형주 3배\n1시간 27분에 나옵니다.\n계엄령때 거래가 되었다고 합니다.\n-20% 가 터졌을때 산 사람들이 있나봅니다.\n \n \n비트코인\n파월 푸틴 들도 비트코인이 좋다는 발언을 했었군요\n파월 - 달러랑 금보단 안좋지만 좋다.\n푸틴 - 아무도 뺏을 수 없다 좋다.\n \nGTBC CRPT BLOK -  코인 관련 사업 ETF\n코인 관련 사업을 하는 회사에 투자하는 ETF 입니다.\nGBTC 가 좋네요\n \n \n여담\n중국과 반도체에서 유출이 나온다.",
        "guid": "http://serverdown.tistory.com/1036",
        "categories": [
          "투자",
          "ETF",
          "미국주식"
        ],
        "isoDate": "2024-12-07T04:45:26.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "무고따 고배당 투자 방법 / 작성중",
        "link": "http://serverdown.tistory.com/1035",
        "pubDate": "Fri, 6 Dec 2024 21:11:46 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1035#entry1035comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=uN9weFcFqkk\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=uN9weFcFqkk</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=uN9weFcFqkk\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/WgjHh/hyXGyL0WCE/yVKCqQQ1xzj9FUKWdlUVX0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/tUUXR/hyXKuOI73M/1pKnqqjtBtJxBkPkHJriNK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"무지성 고배당 따라하기 (배당, 복리, 리밸런싱, 셰넌의 도깨비)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/uN9weFcFqkk\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">아직 다 보진 못했습니다.</p>\n<p data-ke-size=\"size16\">누가 추천해줘서 보고 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">8분10초에 섀넌의 도깨비 에 대한 설명이 나옵니다.</p>\n<p data-ke-size=\"size16\">공유 시트: <a href=\"https://docs.google.com/spreadsheets/d/1-H_QmYmYRnOXkppIVcK-lAISVxtzKCVNtdrlfzS_j8o/edit?gid=0#gid=0\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://docs.google.com/spreadsheets/d/1-H_QmYmYRnOXkppIVcK-lAISVxtzKCVNtdrlfzS_j8o/edit?gid=0#gid=0</a></p>\n<p data-ke-size=\"size16\">이 시트를 보시면 사야할 회사를 알려줍니다.</p>\n<p data-ke-size=\"size16\">사야할 주식 정보는 유료 사이트에서 받아오네요.</p>\n<p data-ke-size=\"size16\">믿음이 가네요.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=uN9weFcFqkk\n\n\n\n아직 다 보진 못했습니다.\n누가 추천해줘서 보고 있습니다.\n \n8분10초에 섀넌의 도깨비 에 대한 설명이 나옵니다.\n공유 시트: https://docs.google.com/spreadsheets/d/1-H_QmYmYRnOXkppIVcK-lAISVxtzKCVNtdrlfzS_j8o/edit?gid=0#gid=0\n이 시트를 보시면 사야할 회사를 알려줍니다.\n사야할 주식 정보는 유료 사이트에서 받아오네요.\n믿음이 가네요.",
        "guid": "http://serverdown.tistory.com/1035",
        "categories": [
          "투자",
          "고배당"
        ],
        "isoDate": "2024-12-06T12:11:46.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "개 한태 이것저것 섞어먹이는 방송 / 피자 치킨 라면 / 피치라",
        "link": "http://serverdown.tistory.com/1034",
        "pubDate": "Fri, 6 Dec 2024 21:00:51 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1034#entry1034comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=cGn9hc8qXVM\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=cGn9hc8qXVM</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=cGn9hc8qXVM\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bPx1qS/hyXGHvp1IM/puL8AZeRQu9hYfyIl7mMh0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/bFjAox/hyXKtbbV2W/GK4FmQLkiPRic4QiEIokwk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"원조 개밥이라니 그게 무슨 소리니 트수트수야?\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/cGn9hc8qXVM\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">각각 주면 맛있을거 같은데</p>\n<p data-ke-size=\"size16\">라면 피자 치킨을 섞어주는 ㅠㅠ</p>\n<p data-ke-size=\"size16\">이것은 형벌입니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=cGn9hc8qXVM\n\n\n\n각각 주면 맛있을거 같은데\n라면 피자 치킨을 섞어주는 ㅠㅠ\n이것은 형벌입니다.",
        "guid": "http://serverdown.tistory.com/1034",
        "categories": [
          "유튜브",
          "피치라"
        ],
        "isoDate": "2024-12-06T12:00:51.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "미시시피 버블에 대해서 알아보자",
        "link": "http://serverdown.tistory.com/1033",
        "pubDate": "Fri, 6 Dec 2024 19:21:51 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1033#entry1033comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=u6Fb0dmMg4g&amp;t=1705s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=u6Fb0dmMg4g&amp;t=1705s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=u6Fb0dmMg4g\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bOzh4W/hyXKlYwVHe/CbN46SApR6PRDFp6Kznhy1/img.jpg?width=1280&amp;height=720&amp;face=332_100_1024_342,https://scrap.kakaocdn.net/dn/boJdEh/hyXKkyx1Xn/P9pTSBLtlKnGe7L2HtBWk0/img.jpg?width=1280&amp;height=720&amp;face=332_100_1024_342\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\" 빠바밤밤~ 빠바밤~ 빠바밤밤~ 빠바 바바바↗  #01 // 인디아나 존스: 그레이트 서클 | 4K\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/u6Fb0dmMg4g\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">역사적인 버블은 몇가지 있습니다.</p>\n<p data-ke-size=\"size16\">1. 튤립 버블 - 가짜일 가능성이 있음, 이 이야기를 쓴사람이 적당히 짜집기했다고함<br />희귀 튤림 뿌리가 비싸게 팔리면서<br />랜덤 뽑기의 가치가 생겨나 피어나지도 않은 뿌리가 비싸게 거래되면서<br />선물 거래가 발생했고 더이상 유지할 수 없을때<br />무너졌다고함</p>\n<p data-ke-size=\"size16\">2. 남해회사 버블 - 영국<br />노예무역 독점권 매매<br />어차피 망한 회사라 노예무역이 될리가 없었으나<br />소문만으로 주식이 급등함<br />뉴턴도 1회차엔 돈을 땃지만 2회차 투자에서 크게 날림</p>\n<p data-ke-size=\"size16\">3. 미시시피 버블 - 프랑스<br />영상에 나옴<br />지폐가 탄생하게됨</p>\n<p data-ke-size=\"size16\">4. 닷컴 버블&nbsp; - 미국<br />인터넷 초차깅에 닷컴만 붙이면 주가가 뛰었으며<br />이런 닷컴 회사들은 대부분 수익을 못내기 때문에<br />무너졌음</p>\n<p data-ke-size=\"size16\">5. 서브프라임 모기지 버블 - 미국<br />주택 담보대출을 갚을 수 없는 사람들에게도 마구잡이로 빌려주다<br />못갚게되자 터짐</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=u6Fb0dmMg4g&t=1705s\n\n\n\n \n역사적인 버블은 몇가지 있습니다.\n1. 튤립 버블 - 가짜일 가능성이 있음, 이 이야기를 쓴사람이 적당히 짜집기했다고함\n희귀 튤림 뿌리가 비싸게 팔리면서\n랜덤 뽑기의 가치가 생겨나 피어나지도 않은 뿌리가 비싸게 거래되면서\n선물 거래가 발생했고 더이상 유지할 수 없을때\n무너졌다고함\n2. 남해회사 버블 - 영국\n노예무역 독점권 매매\n어차피 망한 회사라 노예무역이 될리가 없었으나\n소문만으로 주식이 급등함\n뉴턴도 1회차엔 돈을 땃지만 2회차 투자에서 크게 날림\n3. 미시시피 버블 - 프랑스\n영상에 나옴\n지폐가 탄생하게됨\n4. 닷컴 버블  - 미국\n인터넷 초차깅에 닷컴만 붙이면 주가가 뛰었으며\n이런 닷컴 회사들은 대부분 수익을 못내기 때문에\n무너졌음\n5. 서브프라임 모기지 버블 - 미국\n주택 담보대출을 갚을 수 없는 사람들에게도 마구잡이로 빌려주다\n못갚게되자 터짐",
        "guid": "http://serverdown.tistory.com/1033",
        "categories": [
          "유튜브",
          "거품",
          "버블"
        ],
        "isoDate": "2024-12-06T10:21:51.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "미국 전략 자산 비트코인의 용도",
        "link": "http://serverdown.tistory.com/1032",
        "pubDate": "Fri, 6 Dec 2024 18:33:17 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1032#entry1032comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=G9b2t5ugsbs&amp;t=927s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=G9b2t5ugsbs&amp;t=927s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=G9b2t5ugsbs\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/oZXme/hyXGz5bgLU/SlwsE3DfMrJczCPKf12I6k/img.jpg?width=1280&amp;height=720&amp;face=216_108_1068_434,https://scrap.kakaocdn.net/dn/daGQcz/hyXKqMh6SD/ne82L65o6793FkTSP6T0NK/img.jpg?width=1280&amp;height=720&amp;face=216_108_1068_434\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"트럼프가 비트코인을 선택한 진짜 이유 (박근모 디지털애셋 편집장)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/G9b2t5ugsbs\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">내용을 보시면</p>\n<p data-ke-size=\"size16\">\"비트코인은 계속 오르기 때문에 미국 재정으로 사모으며 오를때 팔아 부채를 해결한다. \"<br />법안이 있습니다.</p>\n<p data-ke-size=\"size16\">우리가 알아야할 점은 계속 오른다는 것이죠<br />계속 오르니 사모으자는 간단한 아이디어를 알 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">또한 미국 민주당은 CDBC 로 정부가 발행해서 사람들에게 나눠주는 걸 생각했는데<br />트럼프는 그런거 없고 스테이블코인 육성 시킬꺼라는 것입니다.</p>\n<p data-ke-size=\"size16\">스테이블하면 생각나는게 리플의 스테이블 코인 발행 계획이 생각납니다.<br />해당 계획에 발 맞춰 스테이블 코인 사업을 진행할 것이라는거죠</p>\n<p data-ke-size=\"size16\">스테이블 코인 육성 제도를 보면 어떤 코인이 뜰지 알 수 있을꺼 같습니다.</p>\n<p data-ke-size=\"size16\">유용한 내용이였습니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=G9b2t5ugsbs&t=927s\n\n\n\n \n내용을 보시면\n\"비트코인은 계속 오르기 때문에 미국 재정으로 사모으며 오를때 팔아 부채를 해결한다. \"\n법안이 있습니다.\n우리가 알아야할 점은 계속 오른다는 것이죠\n계속 오르니 사모으자는 간단한 아이디어를 알 수 있습니다.\n \n또한 미국 민주당은 CDBC 로 정부가 발행해서 사람들에게 나눠주는 걸 생각했는데\n트럼프는 그런거 없고 스테이블코인 육성 시킬꺼라는 것입니다.\n스테이블하면 생각나는게 리플의 스테이블 코인 발행 계획이 생각납니다.\n해당 계획에 발 맞춰 스테이블 코인 사업을 진행할 것이라는거죠\n스테이블 코인 육성 제도를 보면 어떤 코인이 뜰지 알 수 있을꺼 같습니다.\n유용한 내용이였습니다.",
        "guid": "http://serverdown.tistory.com/1032",
        "categories": [
          "코인",
          "비트코인",
          "스테이블코인"
        ],
        "isoDate": "2024-12-06T09:33:17.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "비트코인 100k 돌파 / 리플 RLUSD 출시 연기/ 비트코인 100k 돌파",
        "link": "http://serverdown.tistory.com/1031",
        "pubDate": "Thu, 5 Dec 2024 16:05:29 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1031#entry1031comment",
        "content": "<p data-ke-size=\"size16\">비트코인 100k 돌파</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"855\" data-origin-height=\"543\"><span data-url=\"https://blog.kakaocdn.net/dn/biV4MW/btsK7Cf2iJ8/Kb9W5Q2nknK7RXbUEKLUi1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/biV4MW/btsK7Cf2iJ8/Kb9W5Q2nknK7RXbUEKLUi1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/biV4MW/btsK7Cf2iJ8/Kb9W5Q2nknK7RXbUEKLUi1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbiV4MW%2FbtsK7Cf2iJ8%2FKb9W5Q2nknK7RXbUEKLUi1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"855\" data-origin-height=\"543\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">올해 비트코인 차트구요</p>\n<p data-ke-size=\"size16\">뚫은게 호재겠죠</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">RLUSD 출시 연기</h2>\n<p data-ke-size=\"size16\">기사: <a href=\"https://www.blockstreet.co.kr/news/view?ud=2024120512400086953\">리플 RLUSD, 시장 기대 속 4일 출시 불발&hellip;XRP, 9% 하락 - 블록스트리트</a></p>\n<figure id=\"og_1733382152471\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"리플 RLUSD, 시장 기대 속 4일 출시 불발&hellip;XRP, 9% 하락 - 블록스트리트\" data-og-description=\"최근 4일 출시 루머로 큰 기대감을 모았던 리플사의 스테이블 코인 RLUSD가 시장의 기대와 달리 4일 출시되지 않으며 리플(XRP)이 하락했다. 리플사는 4일 공식 X 계정을 통해 \\&quot;뉴욕 금융서비스국(NY\" data-og-host=\"www.blockstreet.co.kr\" data-og-source-url=\"https://www.blockstreet.co.kr/news/view?ud=2024120512400086953\" data-og-url=\"https://www.blockstreet.co.kr/news/view?ud=2024120512400086953\" data-og-image=\"https://scrap.kakaocdn.net/dn/SRnNF/hyXGNCdvbN/bKAEVdZCe1UEOeNRkpcOk0/img.jpg?width=800&amp;height=420&amp;face=0_0_800_420,https://scrap.kakaocdn.net/dn/bNmGKQ/hyXGN94UPm/Fs41qQAziZK9ug0GFBuK01/img.jpg?width=800&amp;height=420&amp;face=0_0_800_420,https://scrap.kakaocdn.net/dn/5W6i6/hyXGMJ4ea4/MNOqNkd8g1lvB9GxmmnhP1/img.jpg?width=800&amp;height=420&amp;face=0_0_800_420\"><a href=\"https://www.blockstreet.co.kr/news/view?ud=2024120512400086953\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.blockstreet.co.kr/news/view?ud=2024120512400086953\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/SRnNF/hyXGNCdvbN/bKAEVdZCe1UEOeNRkpcOk0/img.jpg?width=800&amp;height=420&amp;face=0_0_800_420,https://scrap.kakaocdn.net/dn/bNmGKQ/hyXGN94UPm/Fs41qQAziZK9ug0GFBuK01/img.jpg?width=800&amp;height=420&amp;face=0_0_800_420,https://scrap.kakaocdn.net/dn/5W6i6/hyXGMJ4ea4/MNOqNkd8g1lvB9GxmmnhP1/img.jpg?width=800&amp;height=420&amp;face=0_0_800_420');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">리플 RLUSD, 시장 기대 속 4일 출시 불발&hellip;XRP, 9% 하락 - 블록스트리트</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">최근 4일 출시 루머로 큰 기대감을 모았던 리플사의 스테이블 코인 RLUSD가 시장의 기대와 달리 4일 출시되지 않으며 리플(XRP)이 하락했다. 리플사는 4일 공식 X 계정을 통해 \\\"뉴욕 금융서비스국(NY</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.blockstreet.co.kr</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">아무데도 파는데가 없더만&nbsp;</p>\n<p data-ke-size=\"size16\">준비해서 더 크게 오프닝 을 할려나봅니다.</p>\n<p data-ke-size=\"size16\">그래서 빠지는군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">결론</h2>\n<p data-ke-size=\"size16\">리플에서 비트코인으로 옮깁니다.</p>\n<p data-ke-size=\"size16\">리플반 비트반 맞췄습니다.</p>\n<p data-ke-size=\"size16\">리플은 바닥잡으면 다시 리벨런싱 할 것입니다.</p>",
        "contentSnippet": "비트코인 100k 돌파\n\n\n올해 비트코인 차트구요\n뚫은게 호재겠죠\n \nRLUSD 출시 연기\n기사: 리플 RLUSD, 시장 기대 속 4일 출시 불발…XRP, 9% 하락 - 블록스트리트\n\n \n리플 RLUSD, 시장 기대 속 4일 출시 불발…XRP, 9% 하락 - 블록스트리트\n최근 4일 출시 루머로 큰 기대감을 모았던 리플사의 스테이블 코인 RLUSD가 시장의 기대와 달리 4일 출시되지 않으며 리플(XRP)이 하락했다. 리플사는 4일 공식 X 계정을 통해 \\\"뉴욕 금융서비스국(NY\nwww.blockstreet.co.kr\n\n아무데도 파는데가 없더만 \n준비해서 더 크게 오프닝 을 할려나봅니다.\n그래서 빠지는군요\n \n결론\n리플에서 비트코인으로 옮깁니다.\n리플반 비트반 맞췄습니다.\n리플은 바닥잡으면 다시 리벨런싱 할 것입니다.",
        "guid": "http://serverdown.tistory.com/1031",
        "categories": [
          "리플",
          "비트코인"
        ],
        "isoDate": "2024-12-05T07:05:29.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "쿠팡 판매자는 손해보면서 파는 걸수도 있습니다.",
        "link": "http://serverdown.tistory.com/1030",
        "pubDate": "Thu, 5 Dec 2024 12:56:57 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1030#entry1030comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=NJ8u3-k7bSo\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=NJ8u3-k7bSo</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=NJ8u3-k7bSo\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/BCZ15/hyXKmbSAqv/EmUYwHDunMyk0PsjAtF460/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/lNVZZ/hyXKnhxOsh/LLLbd9etezZtDer2zpidn1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"95%가 모르는 쿠팡판매 진실 // 쿠팡으로 월 1억 벌어도 포기할 수 밖에 없는 이유!\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/NJ8u3-k7bSo\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">가격을 내리면 더 팔리긴할 것입니다.</p>\n<p data-ke-size=\"size16\">그러나 내가 파는 비용을 계산해보면 가격을 내리는 방법은 위헙합니다.</p>\n<p data-ke-size=\"size16\">자신만의 희귀물품을 판매해야합니다.</p>\n<p data-ke-size=\"size16\">공산품을 가격 경쟁으로 파시면 숨겨진 비용이 나중에 닥친다는 것입니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=NJ8u3-k7bSo\n\n\n\n \n가격을 내리면 더 팔리긴할 것입니다.\n그러나 내가 파는 비용을 계산해보면 가격을 내리는 방법은 위헙합니다.\n자신만의 희귀물품을 판매해야합니다.\n공산품을 가격 경쟁으로 파시면 숨겨진 비용이 나중에 닥친다는 것입니다.",
        "guid": "http://serverdown.tistory.com/1030",
        "categories": [
          "유튜브",
          "쿠팡"
        ],
        "isoDate": "2024-12-05T03:56:57.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "중국의 가짜 금 이 유통중이다. / 코인이 안전하다. / 은 레늄 이리듐 텅스텐",
        "link": "http://serverdown.tistory.com/1029",
        "pubDate": "Thu, 5 Dec 2024 12:18:45 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1029#entry1029comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=Cj0B3k80pCM\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=Cj0B3k80pCM</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=Cj0B3k80pCM\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/44DbG/hyXGFxqfEU/jq9kQHAtestBGztoOcRHf1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/ch8ouL/hyXGN3gHZy/Dru1nJMw53P3moEXFKgDOK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"【중국인사이트】 충격! 가짜 황금 제조 방법 4가지! 짝퉁 금괴, 전문가도 구별 어렵다?! (보도 이\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/Cj0B3k80pCM\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">가짜금을 만드는 몇가지 방법을 소개하고 있습니다.<br />일찍이 부터 이 방법을 사용했다고 합니다.</p>\n<p data-ke-size=\"size16\">1. 금 내부에 모래를 채운다. <br />&nbsp; &nbsp; - 무게가 다름<br />2. 금 내부에 은을 채운다. <br />&nbsp; &nbsp; - 무게가 다름, 모래보단 양반이넹<br />3. 남아프리카 주석금을 그냥 판다.<br />&nbsp; &nbsp; - 구분하기 어렵다. <br />&nbsp; &nbsp; - 무게가 다름<br />&nbsp; &nbsp; - 주석금은 금의 5% 가격이라고 합니다.<br />4. 구리 알루미늄 주석 을 섞어 만든다.<br />&nbsp; &nbsp; - 구분하기 어렵다.<br />5. 내부에 레늄을 섞는다.<br />&nbsp; &nbsp; - 무게로는 구분이 어렵다.<br />&nbsp; &nbsp; - 레늄은 금의 2% 가격이다.<br />6. 이리듐과 텅스텐을 섞는다.<br />&nbsp; &nbsp; - 이리듐과 텅스텐은 금의 10% 가격이다. (그나마 비싸넹)</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">실제로 금이 섞여있기 때문에 외관으로는 구분이 불가능합니다.</p>\n<p data-ke-size=\"size16\">몇가지 사례에서는 금의 무개가 동일한 주석 금을 내부에 섞어버려 중량으로도 구별이 불가능합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">내가 사둔 금은 팔기 전까지 진위를 확인 할 일이 거의 없습니다.</p>\n<p data-ke-size=\"size16\">즉 이제는 금을 매수하는 일이 전혀 안전하지 못하다는 것입니다.</p>\n<p data-ke-size=\"size16\">해외로 빼돌리기위해서라면 코인이 오히려 편리합니다.</p>\n<p data-ke-size=\"size16\">금은 무겁고 강도에 털릴 위험도 있으니까요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=Cj0B3k80pCM\n\n\n\n가짜금을 만드는 몇가지 방법을 소개하고 있습니다.\n일찍이 부터 이 방법을 사용했다고 합니다.\n1. 금 내부에 모래를 채운다. \n    - 무게가 다름\n2. 금 내부에 은을 채운다. \n    - 무게가 다름, 모래보단 양반이넹\n3. 남아프리카 주석금을 그냥 판다.\n    - 구분하기 어렵다. \n    - 무게가 다름\n    - 주석금은 금의 5% 가격이라고 합니다.\n4. 구리 알루미늄 주석 을 섞어 만든다.\n    - 구분하기 어렵다.\n5. 내부에 레늄을 섞는다.\n    - 무게로는 구분이 어렵다.\n    - 레늄은 금의 2% 가격이다.\n6. 이리듐과 텅스텐을 섞는다.\n    - 이리듐과 텅스텐은 금의 10% 가격이다. (그나마 비싸넹)\n \n실제로 금이 섞여있기 때문에 외관으로는 구분이 불가능합니다.\n몇가지 사례에서는 금의 무개가 동일한 주석 금을 내부에 섞어버려 중량으로도 구별이 불가능합니다.\n \n내가 사둔 금은 팔기 전까지 진위를 확인 할 일이 거의 없습니다.\n즉 이제는 금을 매수하는 일이 전혀 안전하지 못하다는 것입니다.\n해외로 빼돌리기위해서라면 코인이 오히려 편리합니다.\n금은 무겁고 강도에 털릴 위험도 있으니까요.",
        "guid": "http://serverdown.tistory.com/1029",
        "categories": [
          "코인",
          "금",
          "비트코인"
        ],
        "isoDate": "2024-12-05T03:18:45.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": [
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "권태기",
        "link": "http://jojoldu.tistory.com/812",
        "pubDate": "Fri, 6 Dec 2024 21:56:44 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "http://jojoldu.tistory.com/812#entry812comment",
        "content": "<p data-ke-size=\"size16\">오늘 아침에 일어나서 성운님의 사고실험 영상을 보는데 공감이 참 많이 되었다.</p>\n<p><iframe src=\"https://www.youtube.com/embed/pwfea1vlGTk?si=jJKMpPyQoynMyca4\" width=\"560\" height=\"315\" frameborder=\"\" allowfullscreen=\"true\"></iframe></p>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">조수용: 어떤 일을 해야하면 그쪽 분야에 대해서는 모드를 딱 좋아하는 모드로 바꿔서 엄청 좋아하기도 해요.<br />예전에 신용카드 프로젝트를 해야할때면 신용카드라는 걸 엄청 좋아해보는 거죠.<br />그렇게 좋아했던 사람은 아니지만, 엄청 좋아해서 신용카드 만들고 바꾸고 하는 매니아처럼 나를 담갔다 온다든지<br />카카오에서 일할 때는 모바일 서비스를 엄청 좋아하는 사람으로 모드를 전환시키는 거죠.<br />매일 앱 보고 있고 쓰고 불편하면 기억하고 그렇게 몰입하지 않으면 힘들고 재미가 없거든요.</p>\n<p data-ke-size=\"size16\">최성운: 방금 말씀하신게 <b>\"좋아하는 일\"도 훈련이나 프레임워크가 존재하는 일</b>일 수 있다고 얘기를 해주셨다.</p>\n<p data-ke-size=\"size16\">조수용: 무언가를 좋아한다는 것에 대한 제 방식의 정의는 \"<b>좋아하기 위해서는 먼저 알아야 한다</b>\" 는 게 먼저 깔려 있는 것이거든요.<br />예를 들어서 \"나 커피 좋아해\" 라고 말을 하려면<br />커피 녹차 등 중에서 커피를 좋아한다고 하는 건지<br />커피 중에서~ 까지 들어가는 건지는<br />완전히 다른 이야기 잖아요.<br />\"나 커피 중에서 아이스 아메리카노 좋아해\" -&gt; \"이정도면 커피를 좋아하는건가?\"<br />\"아 나는 스타벅스의 아이스 아메리카노를 좋아해\" -&gt; \"그 정도면 좋아하는 거야?\"<br />\"커피를 좋아한다는 걸 진짜 끝까지 가볼까?\"<br />이러면 진짜 엄청난 세상이 있죠.<br />원두며 로스팅이며 기계며 내리는 추출 압력이며 무슨 물을 써야되는지까지 가거든요.<br />그 정도까지 가는게 꼭 좋다는 게 아니라 \"내가 좋아하는 걸 찾아봐야겠어\" 라고 할때는 <b>얼마나 좋아하는지는 얼마나 아는지랑 같은 무게감을 가진다는 거에요</b>.<br />그냥 가볍게 툭 좋아해라고 얘기하는 것에서<br /><b>\"나 진짜 이런 게 좋아\" 라고 끝까지 들어가는 것</b><br />저는 그게 큰 분기점이라고 보거든요.<br />그런 사고를 할 수 있는가<br /><b>더 디테일하게 그 분야를 이해하려고 노력할 수 있는지</b>가 참 중요한데,<br />이 부분은 저는 훈련이 필요하다고 생각해요.</p>\n<p data-ke-size=\"size16\">내가 이걸 좀 즐기려는 마음을 가지고 \"한번 다 봐야 되겠다\" 라는 마음을 가지는 건 제 생각에 굉장히 중요한 첫 번째 훈련이에요.</p>\n<p data-ke-size=\"size16\">근데 대부분 그 훈련을 시작하게 되면 내가 생각지 못했던 매력포인트를 발견하게 돼요.<br />내가 처음에 겉핥기로 봤을 때는 \"에이 커피는 이런 거지\", \"위스키는 이런 거지\", \"와인은 이런 거지\" 라고 생각했던 게 있거든요.<br />근데 <b>자세히 들여다보니 안 보이던 세상이 있는 걸 알게 돼요</b>.<br />그때 재미가 탁탁 튀어오르는 걸 발견하게 돼요.<br />그러면 쭉 빨려들어가고 \"뭐야 이런 거였어?\"<br /><b>더 들어가고 더 들어가다 보면 내가 좋아하는 게 디테일해지죠</b>.</p>\n<p data-ke-size=\"size16\">이 과정을 반복하면서 살다 보면 어떤 태도가 생기냐면,<br /><b>무엇을 대할 때도 \"내가 지금 안봐서 그렇지, 그런 매력이 있을거야\"</b> 라고 생각하게 되요.<br />그래서 함부로 좋다 싫다라는 말을 잘 안해요.<br />\"내가 몰라서, 여기까지만 알아서 이걸 좋아하는 건데 더 알면 또 다른 세상이 있을거야\"<br />그리고 <b>똑같은 강도로 다른 사람을 인정하게 되요</b>.<br />\"저 사람이 저걸 좋아하는 데 뭔가 이유가 있을거야\"<br />그걸 평가절하하지 않고, 인정한다는 거죠.<br />그 단계까지 가는 게 되게 중요하거든요.<br />그러면 세상을 볼 때 까칠해지지가 않아요.<br />나는 이만큼 아니깐 이만큼 좋아하고<br />저 사람은 많이 아니까 저만큼 좋아하는 데 대해서도 \"와 멋있다 저기까지 아나봐\" 와 같이 다 인정이 되는거에요.</p>\n<p data-ke-size=\"size16\">그래야 내가 어느 순간에 무언가를 기획할 때 이 사람들을 다 머릿속에 넣을 수가 있는거죠.<br /><b>잘 알려고 하지 않고 \"나 이거 좋아하는데\" 라고 하는 건 의미가 없는 거에요</b>.<br /><b>세상에서 일을 잘하고 사는 데는 아무 도움이 안돼요</b>.</p>\n</blockquote>\n<p data-ke-size=\"size16\">재밌는 것은 이 내용이 <a href=\"https://product.kyobobook.co.kr/detail/S000001813651\">Grit</a>에도 비슷하게 언급되고 있었다.</p>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">6장<br />근본적으로 한동안 <b>어떤 일을 하면 지루해지는 것이 매우 자연스러운 반응</b>이기 때문이다.<br />모든 인간은 유아기 때부터 이미 봤던 물체에서는 시선을 거두고 새롭고 놀라운 대상을 바라보는 경향이 있다.<br />사실 관심 또는 흥미라는 영어 단어 <code>interest</code> 의 어원은 '<b>다르다</b>'라는 의미의 라틴어 <code>interesse</code> 이다.<br />말 그대로 <b>흥미로우려면 달라야 한다</b>.<br />우리는 천성적으로 새로운 사물을 좋아한다.<br />어떤 일이든 <b>한참이 지나면 싫증을 느끼는 것이 인간의 본성이지만 불가피한 일은 아니다</b>.<br />...<br />초보자가 느끼는 새로움과 전문가가 느끼는 새로움이 다르다.<br /><b>초보자에게 새로움은 이전에 접촉한 적이 없는 대상</b>이다.<br />반면에 <b>전문가에게 새로움은 '이전과 미묘한 차이가 있는 대상'</b> 이다.<br /><b>전문가들은 일반 사람들이 보지 못하는 세세한 차이를 알아보는 안목을 길러왔기 때문</b>이다.<br />...<br />당신의 관심사가 아무리 모호해도 <b>직업으로 삼기에는 몹시 싫은 일과 다른 것보다 나아 보이는 일</b>이 있을 것이다.<br />그게 시작이다.<br />...<br />당신이 할 수 있고 열정으로 발전할 일은 단 하나가 아니라 여러가지다.<br />'옳은'일 또는 '최선'인 일도 찾을 필요가 없다.<br />그냥 괜찮아 보이는 방향을 정하라.<br />얼마간 시도해보기 전에는 그 일이 당신과 잘 맞는지 알기 힘들 수도 있다.<br />...<br />마지막으로 <b>자신이 좋아하는 일을 몇 년째 하고 있지만 아직은 열정이라고 부를 수 없다면 관심을 어떻게 심화</b>시킬 수 있을지 살펴보라.<br />당신의 뇌는 새로움을 갈구하기 때문에 다른 일로 옮겨 가고 싶은 유혹을 느낄 것이며 그것이 가장 타당한 행동일 수 있다.<br />하지만 어떤 일이든 몇년 이상 지속적으로 노력해보고 싶다면 오로지 <b>마니아만이 알아볼 수 있는 미묘한 차이를 즐길 방법을 찾을 필요가 있다</b>.<br />...<br />\"<b>우리의 주의를 끄는 것은 새로움 속의 익숙함, 약간의 새로운 변화가 있는 익숙함이다</b>\".<br />자신의 열정을 좇으라는 명령이 나쁜 충고는 아니다.<br />하지만 우선 열정을 키울 방법부터 이해하라는 주문이 더욱 유용한 조언일 것이다.</p>\n</blockquote>\n<p data-ke-size=\"size16\">와이프의 아주 작은 변화를 알아챘을때 그걸 애정으로 받아들이는 것처럼,<br />내가 하고 있는 일, 내가 좋아하는 무언가도<br />아주 디테일하게 알게 되고, 작은 변화/개선를 알게될수록 그 대상을 더 좋아하게 되는 것 같다.</p>\n<p data-ke-size=\"size16\">이게 꼭 일 혹은 사람일 수도 있겠지만 조직/제품에도 반영할 수 있다.</p>\n<p data-ke-size=\"size16\">하나의 일을 몇 년간 하다보면,<br />하나의 제품을 몇 년간 다루다보면,<br />하나의 조직에서 몇 년간 다니다보면,<br />매번 똑같은 것 같고, 지루하다고 느낄 수 있다.<br />그럴수록 그걸 지루하다 vs 좋아한다의 관점으로 보기 보다는,<br />\"<b>디테일하게 봐야하는 시기, 더 깊게 공부해야하는 시기</b>\"의 관점으로 옮겨볼 수 있다면 새로운 세상이 열리는 것 같다.</p>\n<p data-ke-size=\"size16\">예전에는 한 회사를 오래 다닌 사람 혹은 하나의 일/제품을 오래 다룬 사람을 \"참을성/인내심이 많다\", \"무던하다\" 등 예민하지 않은 사람으로 표현했다.</p>\n<p data-ke-size=\"size16\">사실은 그 분들은 \"<b>아주 작은 변화를, 개선을 눈치챌 수 있을만큼 깊게 알고 있는 사람</b>\" 이였다는 생각이 든다.</p>",
        "contentSnippet": "오늘 아침에 일어나서 성운님의 사고실험 영상을 보는데 공감이 참 많이 되었다.\n\n조수용: 어떤 일을 해야하면 그쪽 분야에 대해서는 모드를 딱 좋아하는 모드로 바꿔서 엄청 좋아하기도 해요.\n예전에 신용카드 프로젝트를 해야할때면 신용카드라는 걸 엄청 좋아해보는 거죠.\n그렇게 좋아했던 사람은 아니지만, 엄청 좋아해서 신용카드 만들고 바꾸고 하는 매니아처럼 나를 담갔다 온다든지\n카카오에서 일할 때는 모바일 서비스를 엄청 좋아하는 사람으로 모드를 전환시키는 거죠.\n매일 앱 보고 있고 쓰고 불편하면 기억하고 그렇게 몰입하지 않으면 힘들고 재미가 없거든요.\n최성운: 방금 말씀하신게 \"좋아하는 일\"도 훈련이나 프레임워크가 존재하는 일일 수 있다고 얘기를 해주셨다.\n조수용: 무언가를 좋아한다는 것에 대한 제 방식의 정의는 \"좋아하기 위해서는 먼저 알아야 한다\" 는 게 먼저 깔려 있는 것이거든요.\n예를 들어서 \"나 커피 좋아해\" 라고 말을 하려면\n커피 녹차 등 중에서 커피를 좋아한다고 하는 건지\n커피 중에서~ 까지 들어가는 건지는\n완전히 다른 이야기 잖아요.\n\"나 커피 중에서 아이스 아메리카노 좋아해\" -> \"이정도면 커피를 좋아하는건가?\"\n\"아 나는 스타벅스의 아이스 아메리카노를 좋아해\" -> \"그 정도면 좋아하는 거야?\"\n\"커피를 좋아한다는 걸 진짜 끝까지 가볼까?\"\n이러면 진짜 엄청난 세상이 있죠.\n원두며 로스팅이며 기계며 내리는 추출 압력이며 무슨 물을 써야되는지까지 가거든요.\n그 정도까지 가는게 꼭 좋다는 게 아니라 \"내가 좋아하는 걸 찾아봐야겠어\" 라고 할때는 얼마나 좋아하는지는 얼마나 아는지랑 같은 무게감을 가진다는 거에요.\n그냥 가볍게 툭 좋아해라고 얘기하는 것에서\n\"나 진짜 이런 게 좋아\" 라고 끝까지 들어가는 것\n저는 그게 큰 분기점이라고 보거든요.\n그런 사고를 할 수 있는가\n더 디테일하게 그 분야를 이해하려고 노력할 수 있는지가 참 중요한데,\n이 부분은 저는 훈련이 필요하다고 생각해요.\n내가 이걸 좀 즐기려는 마음을 가지고 \"한번 다 봐야 되겠다\" 라는 마음을 가지는 건 제 생각에 굉장히 중요한 첫 번째 훈련이에요.\n근데 대부분 그 훈련을 시작하게 되면 내가 생각지 못했던 매력포인트를 발견하게 돼요.\n내가 처음에 겉핥기로 봤을 때는 \"에이 커피는 이런 거지\", \"위스키는 이런 거지\", \"와인은 이런 거지\" 라고 생각했던 게 있거든요.\n근데 자세히 들여다보니 안 보이던 세상이 있는 걸 알게 돼요.\n그때 재미가 탁탁 튀어오르는 걸 발견하게 돼요.\n그러면 쭉 빨려들어가고 \"뭐야 이런 거였어?\"\n더 들어가고 더 들어가다 보면 내가 좋아하는 게 디테일해지죠.\n이 과정을 반복하면서 살다 보면 어떤 태도가 생기냐면,\n무엇을 대할 때도 \"내가 지금 안봐서 그렇지, 그런 매력이 있을거야\" 라고 생각하게 되요.\n그래서 함부로 좋다 싫다라는 말을 잘 안해요.\n\"내가 몰라서, 여기까지만 알아서 이걸 좋아하는 건데 더 알면 또 다른 세상이 있을거야\"\n그리고 똑같은 강도로 다른 사람을 인정하게 되요.\n\"저 사람이 저걸 좋아하는 데 뭔가 이유가 있을거야\"\n그걸 평가절하하지 않고, 인정한다는 거죠.\n그 단계까지 가는 게 되게 중요하거든요.\n그러면 세상을 볼 때 까칠해지지가 않아요.\n나는 이만큼 아니깐 이만큼 좋아하고\n저 사람은 많이 아니까 저만큼 좋아하는 데 대해서도 \"와 멋있다 저기까지 아나봐\" 와 같이 다 인정이 되는거에요.\n그래야 내가 어느 순간에 무언가를 기획할 때 이 사람들을 다 머릿속에 넣을 수가 있는거죠.\n잘 알려고 하지 않고 \"나 이거 좋아하는데\" 라고 하는 건 의미가 없는 거에요.\n세상에서 일을 잘하고 사는 데는 아무 도움이 안돼요.\n재밌는 것은 이 내용이 Grit에도 비슷하게 언급되고 있었다.\n6장\n근본적으로 한동안 어떤 일을 하면 지루해지는 것이 매우 자연스러운 반응이기 때문이다.\n모든 인간은 유아기 때부터 이미 봤던 물체에서는 시선을 거두고 새롭고 놀라운 대상을 바라보는 경향이 있다.\n사실 관심 또는 흥미라는 영어 단어 interest 의 어원은 '다르다'라는 의미의 라틴어 interesse 이다.\n말 그대로 흥미로우려면 달라야 한다.\n우리는 천성적으로 새로운 사물을 좋아한다.\n어떤 일이든 한참이 지나면 싫증을 느끼는 것이 인간의 본성이지만 불가피한 일은 아니다.\n...\n초보자가 느끼는 새로움과 전문가가 느끼는 새로움이 다르다.\n초보자에게 새로움은 이전에 접촉한 적이 없는 대상이다.\n반면에 전문가에게 새로움은 '이전과 미묘한 차이가 있는 대상' 이다.\n전문가들은 일반 사람들이 보지 못하는 세세한 차이를 알아보는 안목을 길러왔기 때문이다.\n...\n당신의 관심사가 아무리 모호해도 직업으로 삼기에는 몹시 싫은 일과 다른 것보다 나아 보이는 일이 있을 것이다.\n그게 시작이다.\n...\n당신이 할 수 있고 열정으로 발전할 일은 단 하나가 아니라 여러가지다.\n'옳은'일 또는 '최선'인 일도 찾을 필요가 없다.\n그냥 괜찮아 보이는 방향을 정하라.\n얼마간 시도해보기 전에는 그 일이 당신과 잘 맞는지 알기 힘들 수도 있다.\n...\n마지막으로 자신이 좋아하는 일을 몇 년째 하고 있지만 아직은 열정이라고 부를 수 없다면 관심을 어떻게 심화시킬 수 있을지 살펴보라.\n당신의 뇌는 새로움을 갈구하기 때문에 다른 일로 옮겨 가고 싶은 유혹을 느낄 것이며 그것이 가장 타당한 행동일 수 있다.\n하지만 어떤 일이든 몇년 이상 지속적으로 노력해보고 싶다면 오로지 마니아만이 알아볼 수 있는 미묘한 차이를 즐길 방법을 찾을 필요가 있다.\n...\n\"우리의 주의를 끄는 것은 새로움 속의 익숙함, 약간의 새로운 변화가 있는 익숙함이다\".\n자신의 열정을 좇으라는 명령이 나쁜 충고는 아니다.\n하지만 우선 열정을 키울 방법부터 이해하라는 주문이 더욱 유용한 조언일 것이다.\n와이프의 아주 작은 변화를 알아챘을때 그걸 애정으로 받아들이는 것처럼,\n내가 하고 있는 일, 내가 좋아하는 무언가도\n아주 디테일하게 알게 되고, 작은 변화/개선를 알게될수록 그 대상을 더 좋아하게 되는 것 같다.\n이게 꼭 일 혹은 사람일 수도 있겠지만 조직/제품에도 반영할 수 있다.\n하나의 일을 몇 년간 하다보면,\n하나의 제품을 몇 년간 다루다보면,\n하나의 조직에서 몇 년간 다니다보면,\n매번 똑같은 것 같고, 지루하다고 느낄 수 있다.\n그럴수록 그걸 지루하다 vs 좋아한다의 관점으로 보기 보다는,\n\"디테일하게 봐야하는 시기, 더 깊게 공부해야하는 시기\"의 관점으로 옮겨볼 수 있다면 새로운 세상이 열리는 것 같다.\n예전에는 한 회사를 오래 다닌 사람 혹은 하나의 일/제품을 오래 다룬 사람을 \"참을성/인내심이 많다\", \"무던하다\" 등 예민하지 않은 사람으로 표현했다.\n사실은 그 분들은 \"아주 작은 변화를, 개선을 눈치챌 수 있을만큼 깊게 알고 있는 사람\" 이였다는 생각이 든다.",
        "guid": "http://jojoldu.tistory.com/812",
        "categories": [
          "생각정리",
          "권태기",
          "사고실험",
          "스타트업",
          "일",
          "조수용",
          "최성운"
        ],
        "isoDate": "2024-12-06T12:56:44.000Z"
      }
    ]
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": [
      {
        "title": "CSS clamp() 함수",
        "link": "https://hyeonseok.com/blog/926",
        "pubDate": "Sun, 08 Dec 2024 11:13:19 GMT",
        "content": "<p><code>width</code>와 <code>height</code>에는 <code>min/max</code> 값을 지정하는 별도의 속성이 있어서 레이아웃 구성에 유용하게 사용할 수 있다. 다른 속성에도 이와 같이 최대/최소값을 적용할 수 있으면 좋겠다는 생각이 드는 경우가 있는데 이럴 때 <code>clamp()</code>를 사용할 수 있다.</p>\r\n\r\n<script>\r\nconst css = document.createElement('style');\r\ncss.innerHTML = `\r\n.clamp-container {\r\n\tborder: 1px solid #00c;\r\n\tpadding: 4px;\r\n\tanimation: clamp-contianer-width 5s infinite;\r\n}\r\n.clamp-experiment {\r\n\twidth: clamp(100px, 75%, 200px);\r\n\tbackground: #0c0;\r\n\twhite-space: pre;\r\n\tmargin-bottom: 4px;\r\n\tpadding: 2em 0;\r\n}\r\n.clamp-control {\r\n\twidth: 75%;\r\n\tbackground: #ccc;\r\n\twhite-space: pre;\r\n\ttext-align: right;\r\n\tpadding: 0.2em 0;\r\n\tfont-size: 11px;\r\n\tline-height: 0.75;\r\n}\r\n@keyframes clamp-contianer-width {\r\n\t0% {\r\n\t\twidth: 100px;\r\n\t}\r\n\t50% {\r\n\t\twidth: 300px;\r\n\t}\r\n\t100% {\r\n\t\twidth: 100px;\r\n\t}\r\n}`;\r\ndocument.getElementsByTagName('head')[0].appendChild(css);\r\n</script>\r\n\r\n<div class=\"clamp-container\">\r\n\t<div class=\"clamp-experiment\">clamp(100px, 75%, 200px)</div>\r\n\t<div class=\"clamp-control\" style=\"width: 100px\">100px</div>\r\n\t<div class=\"clamp-control\" style=\"width: 75%;\">75%</div>\r\n\t<div class=\"clamp-control\" style=\"width: 200px;\">200px</div>\r\n</div>\r\n\r\n<p><code>width</code>에 <code>clamp(100px, 75%, 200px)</code>를 적용한 경우다. <code>min/max-width</code>를 적용한 것 처럼 <code>75%</code>가 <code>100px</code>-<code>200px</code> 사이에서만 적용되는 것을 볼 수 있다. 글자 크기를 화면 크기와 연동하는 경우와 같이 값이 너무 작거나 커지지 않게 제어하는데 유용하게 사용할 수 있다.</p>\r\n\r\n<p><code>calc()</code>나 <code>min()</code>, <code>max()</code>와도 같이 사용할 수 있다. <code>clamp(MIN, VAL, MAX)</code>는 <code>max(MIN, min(VAL, MAX))</code>와 동일하다고 하는데 웬만한 계산은 이제 다 가능할 것 같다. 값 제어를 위해 레퍼로 감싸야 하는 경우는 거의 없어질 것으로 생각된다.</p>",
        "contentSnippet": "width와 height에는 min/max 값을 지정하는 별도의 속성이 있어서 레이아웃 구성에 유용하게 사용할 수 있다. 다른 속성에도 이와 같이 최대/최소값을 적용할 수 있으면 좋겠다는 생각이 드는 경우가 있는데 이럴 때 clamp()를 사용할 수 있다.\n\r\n\r\n\r\nconst css = document.createElement('style');\r\ncss.innerHTML = `\r\n.clamp-container {\r\n\tborder: 1px solid #00c;\r\n\tpadding: 4px;\r\n\tanimation: clamp-contianer-width 5s infinite;\r\n}\r\n.clamp-experiment {\r\n\twidth: clamp(100px, 75%, 200px);\r\n\tbackground: #0c0;\r\n\twhite-space: pre;\r\n\tmargin-bottom: 4px;\r\n\tpadding: 2em 0;\r\n}\r\n.clamp-control {\r\n\twidth: 75%;\r\n\tbackground: #ccc;\r\n\twhite-space: pre;\r\n\ttext-align: right;\r\n\tpadding: 0.2em 0;\r\n\tfont-size: 11px;\r\n\tline-height: 0.75;\r\n}\r\n@keyframes clamp-contianer-width {\r\n\t0% {\r\n\t\twidth: 100px;\r\n\t}\r\n\t50% {\r\n\t\twidth: 300px;\r\n\t}\r\n\t100% {\r\n\t\twidth: 100px;\r\n\t}\r\n}`;\r\ndocument.getElementsByTagName('head')[0].appendChild(css);\r\n\r\n\r\n\r\n\t\nclamp(100px, 75%, 200px)\n\r\n\t\n100px\n\r\n\t\n75%\n\r\n\t\n200px\n\r\n\r\n\r\nwidth에 clamp(100px, 75%, 200px)를 적용한 경우다. min/max-width를 적용한 것 처럼 75%가 100px-200px 사이에서만 적용되는 것을 볼 수 있다. 글자 크기를 화면 크기와 연동하는 경우와 같이 값이 너무 작거나 커지지 않게 제어하는데 유용하게 사용할 수 있다.\n\r\n\r\ncalc()나 min(), max()와도 같이 사용할 수 있다. clamp(MIN, VAL, MAX)는 max(MIN, min(VAL, MAX))와 동일하다고 하는데 웬만한 계산은 이제 다 가능할 것 같다. 값 제어를 위해 레퍼로 감싸야 하는 경우는 거의 없어질 것으로 생각된다.",
        "guid": "https://hyeonseok.com/blog/926",
        "isoDate": "2024-12-08T11:13:19.000Z"
      }
    ]
  },
  {
    "name": "한상곤 - Sigmadream",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "HBase 복제를 이용해 마이그레이션하기",
        "link": "https://techblog.lycorp.co.jp/ko/migrating-hbase-with-hbase-replication",
        "pubDate": "Fri, 06 Dec 2024 03:00:00 GMT",
        "content": "안녕하세요. HBase 팀 이욱입니다. 저는 16년간 데이터베이스 엔지니어로 일해 왔습니다. DBA(database administrator)의 업무에는 다양한 작업이 있으며, 그...",
        "contentSnippet": "안녕하세요. HBase 팀 이욱입니다. 저는 16년간 데이터베이스 엔지니어로 일해 왔습니다. DBA(database administrator)의 업무에는 다양한 작업이 있으며, 그...",
        "guid": "https://techblog.lycorp.co.jp/ko/migrating-hbase-with-hbase-replication",
        "isoDate": "2024-12-06T03:00:00.000Z"
      },
      {
        "title": "코드 품질 개선 기법 1편: 한 번 엎지른 &lt;error&gt;는 다시 주워 담지 못한다",
        "link": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-1",
        "pubDate": "Tue, 03 Dec 2024 02:00:00 GMT",
        "content": "안녕하세요. 커뮤니케이션 앱 LINE의 모바일 클라이언트를 개발하고 있는 Ishikawa입니다. 저희 회사는 높은 개발 생산성을 유지하기 위해 코드 품질 및 개발 문화 개선에 힘쓰...",
        "contentSnippet": "안녕하세요. 커뮤니케이션 앱 LINE의 모바일 클라이언트를 개발하고 있는 Ishikawa입니다. 저희 회사는 높은 개발 생산성을 유지하기 위해 코드 품질 및 개발 문화 개선에 힘쓰...",
        "guid": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-1",
        "isoDate": "2024-12-03T02:00:00.000Z"
      },
      {
        "title": "코드 품질 개선 기법 시리즈 소개",
        "link": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-list",
        "pubDate": "Tue, 03 Dec 2024 02:00:00 GMT",
        "content": "LY Corporation의 개발 조직에서는 높은 개발 생산성을 유지하기 위해 코드 품질과 개발 문화 개선에 힘쓰고 있으며, 이와 관련된 다양한 활동 중 하나가 Review Com...",
        "contentSnippet": "LY Corporation의 개발 조직에서는 높은 개발 생산성을 유지하기 위해 코드 품질과 개발 문화 개선에 힘쓰고 있으며, 이와 관련된 다양한 활동 중 하나가 Review Com...",
        "guid": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-list",
        "isoDate": "2024-12-03T02:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "평등한 자본금",
        "link": "https://www.thestartupbible.com/2024/12/hyundais-founding-story.html",
        "pubDate": "Sun, 08 Dec 2024 22:08:06 +0000",
        "content:encodedSnippet": "올해 나는 꽤 많은 책을 읽었다. 보통 일 년에 50권을 목표로 정하고, 지난 5년 동안 매해 50권 정도의 책을 읽었는데, 올해는 60권을 돌파해서 기분이 참 좋다. 60권 이상 읽은 자랑은 다음 포스팅에서 해보려고 한다.\n어제 올해 62번째 책을 완독했는데, 현대그룹의 창업자 정주영 씨의 자서전 ‘이 땅에 태어나서’였다. 우리 사무실이 있는 구글스타트업캠퍼스에는 작은 사내 도서관이 있는데, 여기에 있는 책 중 하나였고, 그동안 이 책이 진열된 건 여러 번 봤지만, 페이지 수가 조금 많기도 하고, 너무 익숙한 한국 기업 이야기라서 그런지, 선뜻 손이 안 갔다. 드디어, 11월 말, 비행기에서 읽으려고 대여했는데, 굉장히 재미있게 읽었다. 실은, 그냥 재미있는 게 아니라, 올해 가장 감명 깊게 읽은 책 중 하나였고, 주위 사람들에게 읽어보라고 권장하고 싶은 책이다.\n현대라는 기업은 한국인들에겐 너무나 익숙한 이름이다. 어디를 가도 현대가 만든 제품을 우린 볼 수 있을 정도로 한국을 대표하는 대단한 기업이지만, 너무 익숙한 나머지 이 회사가 어떻게 시작됐고, 어떻게 성장했는지 제대로 아는 사람들은 별로 없을 것이다. 정주영 씨도 워낙 유명한 분이라서 맨손으로 현대를 시작했다는 건 대부분 알지만, 이분이 어떤 철학과 원칙을 기반으로 비즈니스를 했는지 아는 분들은 별로 없다. 나도 이 책을 읽기 전에는 전혀 몰랐으니까.\n책의 마지막 페이지를 덮고 나서 현대그룹에 대한 경외심이 생겼다. 현대에 대한 건지, 아니면 정주영 씨에 대한 건진 잘 모르겠지만, 우리가 스타트업 창업가와 그 회사를 동일시 하는 것과 같이, 나에겐 둘 다 동일하게 느껴지는 것 같다. 그리고 스스로 반성도 많이 했다. 나를 비롯해서 대부분 한국인들은 존경하거나 벤치마킹하고 싶어 하는 기업인들에 대해서 이야기하면, 한국보단 항상 외국인 CEO들에 대한 이야기를 많이 한다. 특히, 내가 일하는 스타트업 분야에서는 실리콘밸리의 창업가들에 대한 이야기가 주를 이룬다. 이들이 무에서 유를 만드는 과정에 대해서는 아주 자세히 알고 있고, 누구한테 얼마의 투자를 받아서 얼마나 단기간에 유니콘 기업을 만들었는지에 대해서는 누구나 소셜 미디어에 자주 포스팅을 하고 있지만, 한국 기업의 CEO나 한국의 창업가들에 대한 좋은 이야기는 상대적으로 덜 보이는 것 같다. 한국에도 대단한 기업과 이 기업을 만든 창업가들이 많은데, 우린 너무 밖에서만 좋은 role model을 찾으려고 하는 게 아닌지 반성했다.\n이 책을 읽으면서 내내 들었던 생각은, 내 등잔 밑이 참 어두웠다는 것이다. 정주영 씨의 자서전이긴 하지만, 이분의 인생 자체가 현대였기 때문에 이 책은 현대의 창업 이야기이고, 그 어떤 창업 이야기보다 드라마틱하고 재미있다. 이런 면에서는 나는 현대도 엄청난 스타트업이라고 생각한다. 여기서 세세한 서평을 쓰진 않겠다. 하지만, 스타트업에 관심 있는 분이라면 이 책을 꼭 권장하고 싶다. 아마도 정주영 씨의 이야기는 여기저기서 조각조각 많이 들었겠지만, 이 분이 어떻게 현대를 창업했고, 현대가 어떤 역경과 난관을 극복하면서 한국 최고의 회사가 됐는지, 이 자서전을 통해서 많이 배울 수 있을 것이다.\n이 책에서 가장 인상 깊었던, 하지만 가장 평범하기 그지없었던 말은 “시간은 누구에게나 평등하게 주어지는 자본금”이다. 그리고, 본인은 이 평등한 자본금을 열심히 활용한 사람 중의 한 명이라는 말을 하면서 이게 현대의 성공 비결이라고 했다. 이 자본금을 그냥 잘 활용한 게 아니라, 정주영 씨는 정말 오지게 잘 활용하신 분이라고 생각한다.\n나도 시간이라는 평등한 자본금을 잘 활용하고 있다고 생각했는데, 오늘부터 더 잘 활용해야겠다고 다짐한다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/12/hyundais-founding-story.html#comments",
        "content": "올해 나는 꽤 많은 책을 읽었다. 보통 일 년에 50권을 목표로 정하고, 지난 5년 동안 매해 50권 정도의 책을 읽었는데, 올해는 60권을 돌파해서 기분이 참 좋다. 60권 이상 읽은 자랑은 다음 포스팅에서 해보려고 한다. 어제 올해 62번째 책을 완독했는데, 현대그룹의 창업자 정주영 씨의 자서전 ‘이 땅에 태어나서’였다. 우리 사무실이 있는 구글스타트업캠퍼스에는 작은 사내 도서관이 있는데,(...)",
        "contentSnippet": "올해 나는 꽤 많은 책을 읽었다. 보통 일 년에 50권을 목표로 정하고, 지난 5년 동안 매해 50권 정도의 책을 읽었는데, 올해는 60권을 돌파해서 기분이 참 좋다. 60권 이상 읽은 자랑은 다음 포스팅에서 해보려고 한다. 어제 올해 62번째 책을 완독했는데, 현대그룹의 창업자 정주영 씨의 자서전 ‘이 땅에 태어나서’였다. 우리 사무실이 있는 구글스타트업캠퍼스에는 작은 사내 도서관이 있는데,(...)",
        "guid": "https://www.thestartupbible.com/?p=9300",
        "categories": [
          "Uncategorized",
          "books",
          "failure",
          "FoundersAtWork",
          "inspiring",
          "korea"
        ],
        "isoDate": "2024-12-08T22:08:06.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "똥 치우는 사람들",
        "link": "https://www.thestartupbible.com/2024/12/vc-is-a-tough-job.html",
        "pubDate": "Wed, 04 Dec 2024 21:35:00 +0000",
        "content:encodedSnippet": "스트롱에는 6명의 투자팀원이 있다. 이 중 스트롱의 리더십은 나를 포함해서 세 명이다. 나는 2012년 스트롱을 만든 후 계속 한국 시장에 투자했고, 나머지 두 분은 스트롱에 조인하기 전에 각자 다른 곳에서 직접 투자와 간접 투자의 경험을 쌓았다. 우리 셋 모두 2010년 초중반부터 한국 벤처 시장에서 일하기 시작했고, 이후 2022년 글로벌 불경기가 오기 전까진 거의 10년 이상 벤처 호황을 경험하고, 이 호황을 누리면서 투자 업무를 했다. 스트롱이 투자를 시작한 2012년부터 2022년, 10년 동안 경기는 약간의 up/down이 있었지만, 그동안 한 번도 제대로 된 불경기가 찾아온 적은 없었고, 나의 첫 10년 VC 인생 중 항상 경기는 좋을 거라는 순진한 생각을 한 적도 있다.\n코로나를 거치면서 세계 경기는 하향 조정되기 시작했고, 나를 비롯한 다른 시니어 동료분들은 VC 커리어에서 처음으로 불경기를 경험하면서, 돈이 메마르고, 불확실성이 모든 걸 지배하고, 벤처생태계 자체가 공황에 빠지면 어떤 일이 일어나고, 이럴 때 VC는 어떤 행동을 취해야 하는지 지난 2년 동안 매일 매일 새로운 걸 배우고 있다.\n우리의 다른 투자팀원 세 명은 리더십 동료와는 매우 다른 프로필을 갖고 있다. 일단 세 분 모두 다 젊다. 나도 정신적 나이만 따지면 젊지만, 이분들은 물리적인 나이가 모두 20대다. 그리고 스트롱 전에는 모두 학생이었다. 많은 VC들이 경력 없는 신입 직원은 안 뽑는데, 우린 채용 면에서도 남들과 다른 전략을 구사하고 있고, 심사역은 학교 졸업하자마자 바로 채용하는 걸 선호한다. 공통점이라면, 이 세 분 모두 스트롱에서 6개월 이상 인턴 생활을 했고, 이 기간에 우리도 인턴분들과 합을 맞춰봤고, 인턴분들도 스트롱이 본인들에게 맞는 조직인지를 시험하는 과정을 거쳤다.\n이분들은 대부분 2020년 이후에 스트롱에 조인하면서 VC 생활을 시작했는데, 내가 투자를 시작할 때와는 달리 세계 경기는 좋지 않았고, 시간이 갈수록 더욱더 안 좋아졌다. 내 기억으론 우리 주니어분들은 우리 포트폴리오가 힘든 시기를 거치면서 망가지고 있을 때 투자를 시작했다. 그래서 이분들은 투자는 원래 힘들고, 투자하는 회사는 대부분 망하고, VC는 투자보단 회사들이 어려울 때 뒤에서 더러운 일 처리하면서 힘든 일 하는 직업이라는 생각이 기본적으로 박혀 있다.\n이런 default mentality의 차이가 별거 아닌 것 같지만, 그 차이가 만드는 결과는 엄청나게 다를 것으로 생각한다. 이들이 벤처투자를 시작했던 타이밍은 VC 역사상 최악이지만, 앞으로는 더 좋아질 수밖에 없고, 지금의 힘든 상황 때문에 일할 때 항상 더 열심히 하고, 항상 더 겸손한 자세를 유지할 수 있다고 생각한다. 나 같은 사람은 벤처 투자를 시작하고 첫 10년은 너무나 좋은 타이밍이었기 때문에, VC 업무가 원래는 이렇게 힘들고 더러운 일 뒤치다꺼리 하는 게 아니라는 기본 사고 방식을 갖고 있지만, 우리 회사의 20대 심사역들은 180도 다른 기본 사고 방식을 갖고 있을 것이다.\n이들에겐, VC 업무는 원래 힘들고, 투자하는 회사마다 거의 다 망하는 게 정상이라는 기본 사고가 깔려있다. 그리고 사고가 터지면 – 하루에도 여러 개 – 직접 뒤에서 더러운 일을 하고, 똥을 치워야 하는 사람들이라는 걸 잘 알고 있다. 이런 트레이닝을 제대로 받고 있기 때문에, 나는 이들이 나중에 스트롱의 파트너가 되거나, 다른 VC나 회사의 임원이 되면, 그땐 산전수전 다 겪고 행동으로 보여주는 아주 좋은 리더가 될 것이라고 생각한다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/12/vc-is-a-tough-job.html#comments",
        "content": "스트롱에는 6명의 투자팀원이 있다. 이 중 스트롱의 리더십은 나를 포함해서 세 명이다. 나는 2012년 스트롱을 만든 후 계속 한국 시장에 투자했고, 나머지 두 분은 스트롱에 조인하기 전에 각자 다른 곳에서 직접 투자와 간접 투자의 경험을 쌓았다. 우리 셋 모두 2010년 초중반부터 한국 벤처 시장에서 일하기 시작했고, 이후 2022년 글로벌 불경기가 오기 전까진 거의 10년 이상(...)",
        "contentSnippet": "스트롱에는 6명의 투자팀원이 있다. 이 중 스트롱의 리더십은 나를 포함해서 세 명이다. 나는 2012년 스트롱을 만든 후 계속 한국 시장에 투자했고, 나머지 두 분은 스트롱에 조인하기 전에 각자 다른 곳에서 직접 투자와 간접 투자의 경험을 쌓았다. 우리 셋 모두 2010년 초중반부터 한국 벤처 시장에서 일하기 시작했고, 이후 2022년 글로벌 불경기가 오기 전까진 거의 10년 이상(...)",
        "guid": "https://www.thestartupbible.com/?p=9297",
        "categories": [
          "Uncategorized",
          "inspiring",
          "people",
          "Strong",
          "vc"
        ],
        "isoDate": "2024-12-04T21:35:00.000Z"
      }
    ]
  },
  {
    "name": "Build a Great Product",
    "category": "개인",
    "posts": []
  },
  {
    "name": "지금 써보러 갑니다",
    "category": "개인",
    "posts": []
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "토스, 데이터보호 준법 자문위원회 출범 2주년",
        "link": "https://blog.toss.im/article/privacy-toss",
        "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}외부 전문가로 구성된 독립 기구로 데이터 거버넌스 체계 고도화에 기여\n토스 고객 데이터 보호를 위한 정책과 운영 방안 논의 이어와\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n모바일 금융 서비스 ‘토스'를 운영하는 비바리퍼블리카(이하 ‘토스’)가 ‘데이터보호 준법 자문위원회(이하 ‘위원회’)’ 출범 2주년을 맞았다고 9일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n2022년 11월 출범한 위원회는 토스 고객 데이터 보호를 강화하고 관련 법령 준수를 독립적으로 점검하는 역할을 수행하는 자문 기구다. 위원장인 고려대 정보보호대학원 권헌영 교수를 필두로 동 대학원 김승주 교수, 법무법인 광장 김철준 고문이 위원으로 활동하고 있다.\n출범 이후 2년 동안 토스는 고객 데이터 보호를 위한 정책과 운영 방안을 위원회에 공유하며 자문을 받았다. △데이터 관리와 거버넌스 체계 고도화 △법규 준수와 규제 대응 △AI 관리 체계 수립 △고객 데이터 주권 강화 △데이터 보호 신뢰성 확보 방안 등이 주요 아젠다로 논의됐다.\n이를 기반으로 토스는 국내 핀테크 업계 최초로 CBPR(Cross Border Privacy Rule, 국경간 프라이버시보호규칙) 인증 획득, 외부 협력사와의 데이터 처리 관리를 위한 TPRM(Third Party Risk Management) 구축, 개인정보 안심 리포트 출시 등 구체적인 성과를 도출했다.\n특히 출범 2주년을 맞아 열린 5차 정기 회의에서는 개인정보보호법 개정에 따른 개인정보 수집 동의 개선 방안, 생체 데이터에 대한 기술적·관리적 보호 조치 방안 등을 위원회에 보고하고 의견을 수렴하는 자리를 가졌다.\n토스 관계자는 “위원회는 토스 데이터 이용 및 보호 현황을 독립적으로 감시하는 역할로 지난 2년간 토스가 선도적인 데이터 거버넌스 체계를 고도화하는 데 일조했다”며 “앞으로도 투명성과 신뢰성 강화를 위한 다양한 방안을 논의하고 금융업계 데이터 보호의 새로운 기준을 제시해 나가겠다”고 말했다.",
        "guid": "https://blog.toss.im/article/privacy-toss",
        "isoDate": "2024-12-09T00:00:00.000Z"
      },
      {
        "title": "은퇴 준비는 장기투자로 해야 하는 3가지 근거",
        "link": "https://blog.toss.im/article/retirement-plans-7",
        "pubDate": "Thu, 05 Dec 2024 11:59:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}이 글에서 알 수 있는 것\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1kxrhf3{white-space:pre-wrap;}단기투자의 장기투자의 수익률·변동성 차이\nIRP 계좌 지금 당장 해지하지 말아야 하는 이유\n\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n이직할 때마다 퇴직금 찾아서 여행 다녀오셨나요?\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n2022년 퇴직연금법 개정안이 시행되면서 퇴직금은 반드시 IRP 계좌로 받게 되었다.* 따라서 다니던 회사를 그만두고 다른 회사로 이직한다면 기존 회사에서 받을 퇴직금(퇴직연금)이 IRP 계좌로 들어온다.(이때 원래 IRP가 없었다면 가입해야 한다.) 그리고 이직한 회사에서는 새롭게 퇴직연금 적립이 시작된다. 문제는 여기서부터다. 이렇게 IRP 계좌로 수령한 돈은 은퇴까지 잘 굴러가고 있을까? 과연 IRP 계좌의 유지율은 얼마나 될까?\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*만 55세 이후에 퇴직하거나, 퇴직금이 300만 원 이하일 때는 IRP로 받지 않아도 된다.\n통계청 자료에 따르면 결과는 암담하다. 2022년 IRP 계좌 해지율은 98.2%였다. 연도별 IRP 해지율을 살펴보면, 2015년 91.4%, 2016년 93.8%, 2017년 96.2%, 2018년 101.1%, 2019년 102.5%, 2020년 98.2%로 나타났다. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}6년 치를 합산한 전체 해지율은 97.3%에 이른다. 이는 사실상 IRP 계좌를 유지하는 사람이 10명 중 1명이 될까 말까 한 수준이라는 의미다.\n6년 동안 1인당 평균 IRP 이관 금액은 1,520만 원, 1인당 평균 해지 금액은 1,329만 원으로 집계되었다. 금액이 상대적으로 크지 않다는 점도 해지의 주요 요인으로 볼 수 있다. 예를 들어, 1억 원이라면 사용하지 않고 유지하려고 노력하겠지만, 1,000만 원이라면 상대적으로 쉽게 사용할 수 있는 금액이라고 생각하는 것이다.\n실제로 사회초년생 시절 2~3년간 한 직장에서 일하다가 이직하면 손에 쥐는 퇴직금이 천만 원을 넘지 않는 경우가 대부분이다. 이직 후 잠시 쉬면서 그동안 열심히 일한 자신을 위해 해외여행을 다녀오거나, 오랫동안 눈여겨보았던 노트북이나 최신 휴대전화를 구매하고 싶은 마음이 들기 마련이다. 실제로 이러한 소비성 지출로 퇴직금을 쉽게 사용하는 경우도 흔하다.\n결국 IRP는 시간의 힘이 발휘되어야 효과적인 계좌이지만, 사람들은 이를 오래 유지하지 못하고 여지없이 해지해버리고 만다. 장기간 유지하며 몇십 년 뒤 얻을 수 있는 이점보다는, 당장 해지해서 손에 쥐는 돈이 더 커 보이는 것이다. 하지만 10년, 20년 넘게 IRP 계좌를 유지했을 때 어떤 효과가 있는지 제대로 생각해본 적이 있는가? 오늘은 왜 퇴직연금에서 장기투자가 중요한지, 그리고 장기투자를 했을 때 실제로 어떤 이점이 있는지 알아보자.\n왜 장기투자를 강조할까? 데이터가 증명하는 장기투자의 이점\n은퇴 준비에서 가장 중요한 핵심은 바로 ‘시간’이다. 20대에 첫 직장을 시작하면 은퇴까지 무려 30~40년이라는 긴 시간 동안 퇴직연금을 운영하게 된다. 하지만 많은 사람들이 장기투자의 중요성을 말로만 강조할 뿐, 실제로 왜 장기투자가 중요한지 제대로 이해하지 못하는 경우가 많고 실천하는 경우도 드물다. 이제 은퇴 준비에서 가장 중요한 요소인 ‘시간’의 가치를 제대로 짚어보자.\n이럴 때 데이터만큼 좋은 근거는 없다. 단기간(2년)과 장기간(10년)을 기준으로 투자했을 때 얼마나 변동성과 수익률 폭이 달라지는지 직접 살펴본다면 장기투자를 강조하는 이유를 단번에 이해할 수 있다.\n우선 똑같은 투자(똑같은 종목에 똑같은 금액)를 2년과 10년 두 가지 기간으로 나누어서 한다고 가정해보자. S&P500에 2000년 1월 1일부터 2024년 10월 30일까지 투자했다면 평균 연수익률을 7.5%, 연변동성(상승이나 하락의 변동폭)은 15%이다. 그리고 이 기간 동안 누적수익률은 503.42%이다. 그럼 이제 연수익률 7.5%와 연변동성 15%인 종목에 2년간 투자했을 경우와 10년간 투자했을 경우의 시뮬레이션을 각각 1,000번씩 진행해봤다. 이때 나온 결과는 아래 그래프에 있다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n그래프를 보면 두 가지 투자의 다른 결과가 한눈에 들어온다. 2년 단기투자의 연수익률은 그래프에서 파란색으로 표시된 영역처럼 연수익률 -20%부터 40% 이상까지 편차가 굉장히 크다. 10년 장기투자의 경우 초록색으로 표시된 영역에서 보이듯 연수익률 편차가 훨씬 적어진다. 게다가 가장 나쁜 연수익률도 단기투자의 -20%보다는 훨씬 낫다. 즉 2년 단기투자보다는 10년 장기투자가 불확실성의 범위가 훨씬 좁아진다는 결과를 간단하게 확인할 수 있다.\n장기투자에도 위험이 존재한다\n물론 10년 이상 기다린다고 해도 손실의 위험을 아예 피해갈 수 있는 투자는 없다. 2008년 금융위기 때 미국 주식시장은 50% 넘게 하락했다. 제아무리 포트폴리오를 다양하게 구성한다고 해도 이런 폭락장에 플러스 수익률을 유지할 수 있는 확률은 낮다. 실제로 유명 자산운용사나 국가기금 역시 큰 손실을 입었던 시기였다. 만약 이 시기에 공교롭게 은퇴를 하고 퇴직연금을 받는다면 어떨까?\n예를 들어 대표적인 은퇴 상품인 TDF를 살펴보자. TDF는 은퇴 시점에 주식배분율이 약 40%대로 떨어진다. TDF로 투자한 자산에서 약 40% 정도가 주식시장에 투자되어 있다는 의미다. 따라서 이로 인해 전체 수익률의 하락을 막을 길은 없으며, 자산의 가치가 곤두박질쳐서 실제로 손에 쥘 수 있는 돈이 적어진다. 제아무리 장기투자의 장점을 이야기한다고 해도 은퇴 시기에 급락장이 찾아와 손해 본다면 장기투자의 노력은 빛을 잃는다.\n하지만 중요한 것은 이런 위기가 일반적이지 않다는 사실이다. 미국 시장을 놓고 보면 이런 급락장은 100년에 세 번 정도 찾아왔다. 아래 그래프는 1927년부터 S&P500가 어떻게 달라졌는지를 보여주는데, 2008년 금융위기 때 S&P500가 절반 넘게 하락한 모습을 볼 수 있다. 이런 급락장은 1927년부터 살펴본다면 세 번이고, 2000년 이후에는 한 번이었다.\n\n하락의 시기가 세 번 정도 크게 있었지만 장기적으로는 두 배 이상 성장을 반복하면서 우상향하는 패턴을 보이고 있다. 출처=블룸버그, 맨그룹 분석(Bloomberg, Man Group calculations)\n조금 더 구체적으로 수익률을 살펴보자. 아래 자료는 각 연도별 수익률이 특정 구간에 얼마나 자주 속했는지를 보여준다. S&P500이 시작된 시점부터 -10% 이상의 급락장은 11번이었고, -30% 이상은 두 번뿐이었다. 또한 하락장보다 상승장이 더 많았다는 점도 한눈에 파악할 수 있다. 그렇다면 100년 동안 몇 번 오지 않을 위험이 무서워서 장기투자를 하지 않는다고 말할 수 있을까?\n\n출처=맥켄지 포트폴리오 애널리틱스(Mackenzie Portfolio Analytics)\n‘시간’은 확실성에 가까워질 수 있는 가장 쉽고 간단한 방법\n물론 은행의 예금 같은 원리보장형에 투자한다면 돈을 잃을 위험 없이 내가 미래에 얻을 수익이 확실하다. 하지만 이는 물가상승률과 비교해본다면 결국 돈을 잃는 결과와 다르지 않다. 최근 몇 년간 예적금 금리는 연 1~3% 수준이었지만, 같은 기간 물가상승률은 연 2~4%이었다. 금리가 2%이고 물가상승률이 3%라면, 실질 수익률은 -1%이다 보니, 스스로를 투자에 서툴다고 생각하는 사람들도 자산 분배를 다양하게 해둘 필요는 분명하다.\n그후 수익의 확실성을 높이는 방법은 꾸준히 넣고, 기다리는 것이다. 단기적인 수익률 변동에 일희일비하지 않고, 어딘가 돈 쓰고 싶은 욕구에 못 이겨 해지해버리지 말고, 장기 투자를 통해 시간의 힘을 활용하면 연금 적립금은 노후의 든든한 구석으로 돌아온다.\n이렇게 생각해보면 어떨까? IRP는 꺼낼 수 없는 돈주머니라고 생각하고 1) 꾸준히 절세 혜택을 누릴 정도의 일정 금액을 넣는 것, 2) 위험도나 시장을 잘 분배해 운용 지시하는 것만 하는 거다. 중요한 건 어린 시절 빨간 돼지저금통처럼 중간에 배를 가르지 않으려면 계획적인 금전 관리를 통해 중도 해지를 막는 것이다. 그리고 세월이 흘러 은퇴 시점이 왔을 때 소중히 여겨온 빨간 돼지저금통을 꺼낸다면 어떤 보상을 만나게 될지 기대되지 않는가?\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 주소은, 김현미(아이랩) Graphic 조수희, 이제현\n✱<노후 준비 액션플랜> 시리즈는 은퇴자금 관리를 돕는 🔗.css-114ityv{white-space:pre-wrap;cursor:pointer;-webkit-text-decoration:underline!important;text-decoration:underline!important;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}글라이드와 함께 만듭니다. 글라이드는 퇴직연금 투자, 관리, 인출 플랜 솔루션을 제공하는 아이랩의 소프트웨어 서비스입니다.",
        "content": "이직할 때마다 퇴직금 홀랑 찾아서 써버린 당신에게",
        "contentSnippet": "이직할 때마다 퇴직금 홀랑 찾아서 써버린 당신에게",
        "guid": "https://blog.toss.im/article/retirement-plans-7",
        "isoDate": "2024-12-05T11:59:00.000Z"
      },
      {
        "title": "워런 버핏, 포트폴리오를 움직이다: 투자 교훈과 시장 신호 읽기",
        "link": "https://blog.toss.im/article/economic-terms-39-warren-buffett-portfolio",
        "pubDate": "Thu, 05 Dec 2024 02:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-8atqhb{width:100%;}.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}💡 이 글에서 알 수 있는 것들\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1kxrhf3{white-space:pre-wrap;}워런 버핏이 22년 만에 처음 도전한 투자 포트폴리오, 어떻게 조정됐을까?\n워런 버핏의 ‘보물’로 불리는 애플. 그런데 왜 보유량을 줄였을까?\n워런 버핏 명언과 투자 철학에서 건져올리는 투자의 본질\n\n.css-1c1qox8{font-size:30px;letter-spacing:0em;line-height:1.55;font-weight:bold;color:var(--adaptiveGrey900);margin:40px 0 4px;}\n.css-p4abj2{display:contents;line-height:1.55;}🔖 이번 주 경제 용어\n워런 버핏 포트폴리오\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n이번 주 경제 용어는 글로벌 경제를 파악하기 위해 필요한 정보예요.\n\n.css-1pgssrp{max-width:100%;border-radius:16px;}\n워런 버핏이 이끄는 버크셔 해서웨이의 자산 배분 목록이에요.\n\n\n워런 버핏, 투자하는 사람이라면 누구나 들어왔을 이름이죠. 현명한 투자로 전 세계 투자자들에게 귀감이 되는 인물입니다. 그가 거주 중인 미국 네브래스카 주 오마하(Omaha)에서 유래한 별명으로, ‘오마하의 현인(Oracle of Omaha)’이라 불리기도 하죠.\n버핏은 세계적인 투자 기업 버크셔 해서웨이(Berkshire Hathaway)의 CEO이자 회장인데요. 그는 철저히 기업의 내재 가치를 분석하고, 장기 투자를 선호하는 ‘가치 투자’의 대가로 알려져 있어요. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}그는 단순히 주식을 사고파는 것을 넘어, 기업을 ‘소유한다’는 관점에서 투자를 바라보고 있죠.\n버핏의 철학은 그의 명언들 속에서도 빛을 발합니다. 간결하지만 깊은 의미를 담은 문장들은 투자자들에게 훌륭한 지침이 되고 있어요.\n.css-2sk6rv{font-size:19px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);white-space:pre-wrap;margin:24px 0;padding-left:20px;position:relative;}.css-2sk6rv::before{content:'';display:block;position:absolute;top:4px;left:0;width:2px;height:calc(100% - 4px * 2);padding:4px 0;background-color:var(--adaptiveGrey800);}\n“첫째, 절대 돈을 잃지 마라. 둘째, 첫 번째 규칙을 절대 잊지 마라.”.css-7mseny>*{margin-left:0;margin-right:0;}.css-7mseny>:last-child{margin-bottom:0;}blockquote>.css-7mseny:first-child>:first-child{margin-top:0;}\n→ 손실을 피하는 것이 이익을 얻는 것만큼이나 중요하다는 의미입니다. 큰 손실을 입으면 이를 만회하기 위해 더 높은 수익률이 필요하기 때문에, ‘손실을 최소화하는 것’이 장기적인 투자 성공의 핵심이죠.\n“10년 동안 보유하지 않을 주식이라면 10분도 보유하지 않는다”\n→ 타이밍을 노리며 자주 사고팔기보다는, 오랜 시간 보유할 만큼 가치 있는 기업을 신중히 선택하라는 조언입니다.\n\"썰물이 되면 누가 수영복을 입지 않았는지 알 수 있다\"\n→ 시장이 호황일 때는 누구나 성공적인 투자자처럼 보이지만, 위기 상황에서는 재정적 안정성과 준비 상태가 드러납니다. 위기에 대비하는 자세의 중요성을 일깨워주는 말입니다.\n“다른 사람들이 탐욕스러울 때 두려워하고, 다른 사람들이 두려워할 때 탐욕스러워하라.”\n→ 투자 심리와 시장 흐름을 거꾸로 읽으라는 조언입니다. 역발상 투자의 중요성을 강조한 명언입니다.\n버핏이 투자한 종목들은 그 자체로 흥미로운 이야기들을 담고 있습니다. 그는 자신이 잘 알고 좋아하는 제품이나 서비스를 기반으로 투자 결정을 내리는 경향이 있습니다.\n① 코카콜라\n버핏은 1988년 코카콜라 주식을 처음 매입한 이후 지금까지 꾸준히 보유하고 있습니다. 그는 하루에 코카콜라를 5캔 이상 마실 정도로 애정을 가지고 있으며, “나는 코카콜라를 마시며 살아왔고, 앞으로도 마실 것이다”라고 말하기도 했습니다. 이는 단순히 제품의 맛뿐 아니라 코카콜라의 강력한 브랜드 파워를 신뢰했기 때문입니다.\n② 애플\n버핏은 애플에 대해 \"단순히 기술 회사가 아니라 소비재 기업\"이라고 평가하며, 스마트폰과 같은 제품이 현대인의 필수품이 됐다는 점을 높이 샀습니다. 흥미로운 점은 버핏 본인은 기술에 익숙하지 않지만, 애플의 아이폰이 가진 독점적 시장 지위를 간파하고 투자에 나섰다는 사실입니다.\n그러나 미국 증권거래위원회(SEC)에 버크셔가 제출한 .css-15lwtdk{white-space:nowrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:none!important;text-decoration:none!important;}.css-17jayv2{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;cursor:pointer;-webkit-tap-highlight-color:transparent;white-space:nowrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:none!important;text-decoration:none!important;}.css-1fhic5j{-webkit-background-clip:text;background-clip:text;-webkit-text-fill-color:transparent;background-image:var(--wiki-text-linear-gradient);}13F 보고서.css-9dzhxd{margin-left:1px;vertical-align:middle;}\n\n\n\n에 따르면, 지난 9월 말 기준 보유 목록에 변동이 있었어요. 그간 버핏이 '보물'이라고 불렀던 애플 주식은 3개월 만에 보유량이 25% 감소했습니다. 4분기 연속 매도한 결과죠. 그럼에도 애플은 여전히 버크셔 해서웨이 포트폴리오에서 가장 큰 비중을 차지하고 있습니다.\n③ 아메리칸 익스프레스\n1960년대 ‘샐러드 오일 스캔들*’로 위기를 맞았을 때, 버핏은 과감히 투자해 대성공을 거두었습니다. 회사의 본질적 가치는 여전히 건재하다고 판단했기 때문이에요. 그는 이후 한 번도 이 주식을 팔지 않으며, 지금도 버크셔의 최대 투자처 목록 2위에 올라 있습니다.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}* 샐러드 오일 스캔들(Salad Oil Scandal): 1963년에 발생한 미국 역사상 가장 악명높은 금융 사기 사건 중 하나예요. 아메리칸 익스프레스를 포함한 여러 금융 기관에 막대한 손실을 초래했어요.\n이처럼 버핏의 투자 행보는 단순히 현재 상태만 바라보는 데 그치지 않고, 기업의 본질적 가치를 직관적으로 파악하는 데에서 비롯되었다는 걸 알 수 있습니다. 우리는 그의 명언과 에피소드를 단순한 투자 성공담이 아닌, 투자 철학으로 되새겨 보아야 할 것입니다.\n\n\n.css-2yhypk{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);font-style:italic;-webkit-text-decoration:underline!important;text-decoration:underline!important;}워런 버핏, 22년 만에 '여기' 투자했다…美 증시에 대한 경고?\n(SBSBiz  2024.11.26)\n워런 버핏이 이끄는 버크셔해서웨이가 22년 만에 처음으로 채권 투자에 나섰습니다.\n24일 니혼게이자이신문에 따르면 버핏은 최근 쌓은 현금성 자산 대부분을 유동성이 높은 단기 채권인 미국 재무부 단기재정증권에 투자했습니다. 단기재정증권 외 채권 투자를 포함하면, 9월 기준 버크셔의 채권 투자액은 3천40억 달러로 주식 투자액 2천716억 달러를 넘어섰습니다. 이는 2001~2002년 닷컴버블 붕괴 이후 처음입니다.\n버핏의 이같은 행보에 대해 업계는 미국 국채 금리에 비해 이례적으로 고평가된 미국 주식시장에 대한 경고로 받아들이고 있습니다.(중략)\n\n\n최근 워런 버핏의 투자 행보에 변화가 감지되고 있습니다. 그의 투자 회사인 버크셔 해서웨이가 미국 증권거래위원회(SEC)에 제출한 13F 보고서를 통해 힌트를 엿볼 수 있는데요.\n가장 주목해서 봐야 할 부분은 (1) 장기간 애정해온 애플 주식을 4분기 연속 매도한 것과 (2) '최애 은행주'로 불리던 뱅크오브아메리카를 비롯한 금융주 보유량도 줄였다는 점입니다. 이를 통해 그가 현재 주식 시장 전반에 대해 신중한 태도를 보이고 있다는 것을 알 수 있어요.\n한편, 눈에 띄는 점은 버크셔의 ‘현금 보유량’입니다. 현재 현금은 3,252억 달러(약 438조 원)로 1년 전보다 2배 늘어났으며, 이는 전체 자산의 30%에 달합니다. 버핏이 주식 매도를 통해 현금을 확보하면서, 주식보다 더 나은 대안에 대비하려는 모습으로 보입니다.\n22년 만에 채권 투자로 전환한 점도 눈에 띕니다. S&P500 주가지수의 예상 수익률과 미국 정부가 발행한 장기 채권의 금리를 비교하면, 현재 주식 시장이 22년 전과 비슷하게 고평가된 상태이기 때문에 전환한 것인데요. 다시 말해, 지금은 주식 투자로 얻을 수 있는 이익보다 채권에 투자해 안정적으로 얻는 이자가 더 매력적인 상황이라는 뜻입니다.\n\n📈 현재 주식 시장이 고평가되었다고 판단하는 이유는?\n\n주식 시장의 예상 수익률과 채권의 수익률을 비교하는 방법에서 비롯됩니다. 보통 주식 시장의 예상 수익률은 S&P500 지수의 이익 수익률 기준이고요. 채권 수익률은 미국 국채의 금리 기준이에요.\n이전에는 주식의 예상 수익률이 채권 금리보다 높았습니다. 주식 투자에는 늘 변동성과 위험이 따르기 때문이에요. 주식 투자자는 하이리스크, 하이리턴(high risk, high return)으로 더 큰 보상을 기대하기 마련이죠.\n그러나, 지금은 S&P500 수익률이 미국 장기 국채 수익률과 큰 차이가 없는 상황입니다. 이는 채권 투자로 안정적인 수익을 기대할 수 있는 상황에서 주식 투자의 매력이 상대적으로 낮아졌다는 것을 의미해요.\n주식의 이익 수익률이 낮다는 것은, 기업이 내는 이익 대비 주가가 매우 높게 형성되어 있다는 신호인데요. 이런 상황에 대해 주식 시장이 고평가되었다고 판단하며, 장기적으로 높은 수익률을 기대하기에도 어려운 상태를 시사합니다.\n\n워런 버핏의 포트폴리오 변화는 ‘현재 시장 상황에서 신중한 리스크 관리와 대안을 모색하는 전략’으로 해석됩니다. 개인 투자자들도 주식이나 코인에 무조건 올인하기보다, 현금 비중을 확보하며 리스크에 대비하는 자세가 필요하다는 점을 보여주죠. 자산 배분의 중요성을 다시 한번 상기시켜주는 움직임입니다. 내년에 미국 시장이 어떤 흐름으로 가는지 주의 깊게 살펴볼 필요가 있겠어요.\n\n\n자산배분: 투자자가 보유 자산을 주식, 채권, 현금 등 다양한 자산군에 나누어 배분하는 투자 전략. 리스크를 줄이고 안정적인 수익을 추구하기 위해 사용되며, 시장 상황에 따라 자산 비중을 조정하는 리밸런싱\n\n\n\n(Rebalancing)을 할 수 있어요.\n단기 국채: 만기가 1년 이내인 정부 발행 채권. 투자자가 일정 기간 후 약속된 이자를 받고 원금을 돌려받는 금융 상품이에요. 비교적 안정성이 높고, 금리가 비교적 높으며, 만기가 짧아 현금 유동화에 유리해요.\n버크셔 해서웨이: 워런 버핏이 운영하는 투자 회사. 버크셔 해서웨이는 다양한 산업에 걸쳐 투자하는 글로벌 투자 대기업으로, 주식·채권·부동산 등 여러 자산을 보유하고 있어요. 현재 미국 시총 8위에 올라있습니다.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 금혜원 Graphic 조수희 이동건",
        "content": "주식에서 채권으로, 버핏의 선택이 말하는 현재 경제 상황",
        "contentSnippet": "주식에서 채권으로, 버핏의 선택이 말하는 현재 경제 상황",
        "guid": "https://blog.toss.im/article/economic-terms-39-warren-buffett-portfolio",
        "isoDate": "2024-12-05T02:00:00.000Z"
      },
      {
        "title": "토스인컴, ‘연말정산 미리보기’ 서비스 오픈",
        "link": "https://blog.toss.im/article/tossincome-",
        "pubDate": "Wed, 04 Dec 2024 01:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}사용자가 직접 입력해야 하는 항목 최소화… “3분 만에 예상 결과 확인”\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n비바리퍼블리카(이하 토스)의 자회사 토스인컴(대표 박일용)이 내년 연말정산(2024년 귀속분)을 미리 준비하도록 돕는 ‘연말정산 미리보기’ 서비스를 오픈했다고 4일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n토스인컴 연말정산 미리보기는 정교하게 분류된 공제항목을 통해 내년 연말정산 환급액 또는 납부액을 모의로 계산해 볼 수 있는 서비스다. 사용자가 직접 입력해야 하는 항목을 최소화 해 예상 결과를 3분 만에 확인할 수 있게 한 것이 특징이다. 과거 연도 예상 환급액이 있을 경우 한 화면에서 편리하게 신청할 수 있는 것도 장점이다.\n올해 1월부터 9월까지 신용카드 사용액을 토대로 소비액을 산출할 뿐 아니라 상반기 간이지급명세서를 바탕으로 연간 총급여도 예측한다. 고용보험, 공적연금, 건강보험, 군인연금 등은 예측한 연간 총급여로 추정한다.\n그 외 의료비 등 공제항목에 필요한 정보들은 지난 연말정산 결과를 참고해 자동으로 입력한다. 원천징수세율은 기납부세액을 기반으로 추정하며 10월 현재 세법을 반영해 최종 예상 결과를 보여준다.\n토스인컴 연말정산 미리보기 서비스를 이용하기 위해서는 토스 앱 > 전체 탭 > ‘세금・납부・민원’ 카테고리 > ‘연말정산 미리보기’로 들어가거나 토스 앱 상단 돋보기 아이콘을 눌러 ‘연말정산 미리보기’를 검색하면 된다.\n토스인컴 관계자는 “사용자가 연말정산 예상 결과를 간편하게 확인하고 대비 전략을 준비할 수 있도록 돕기 위해 연말정산 미리보기 서비스를 출시했다”며“토스인컴은 개인이 스스로 해결하기 어려운 세무 영역의 불편을 해소하고 누구나 쉽고 정확하게 세금 정산을 할 수 있는 세상을 만들어 가겠다”고 말했다.\n한편 토스인컴은 토스가 지난 5월 세이브잇 운영사 택사스소프트를 인수하면서 출범했다. 토스인컴의 대표 서비스 ‘숨은 환급액 찾기’는 기한 후 신고 뿐 아니라 경정청구를 지원하고 중소기업 취업자 소득세 감면 등 다양한 항목의 셀프 신고를 지원하는 것이 특징이다.",
        "content": "3분 만에 예상 결과를 확인해 보세요.",
        "contentSnippet": "3분 만에 예상 결과를 확인해 보세요.",
        "guid": "https://blog.toss.im/article/tossincome-",
        "isoDate": "2024-12-04T01:00:00.000Z"
      },
      {
        "title": "토스, 세계 장애인의 날 맞아 ‘나만의 별자리 찾기’ 이벤트 실시",
        "link": "https://blog.toss.im/article/international-day-of-people-with-disability",
        "pubDate": "Tue, 03 Dec 2024 00:52:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}시각장애인을 위한 접근성 기능 간접 체험하고 토스페이로 기부… 오는 25일까지 진행\n유니세프 한국위원회, 사랑의열매에 기부금 전달 예정\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n모바일 금융 서비스 토스를 운영하는 비바리퍼블리카(이하 토스)가 세계 장애인의 날을 맞아 ‘나만의 별자리 찾기’ 이벤트를 진행한다고 3일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n나만의 별자리 찾기는 소리를 따라 모바일 화면을 손으로 쓸어서 별자리를 찾고 토스의 간편결제 서비스인 ‘토스페이’로 기부할 수 있는 이벤트이다. 12월 25일(수) 오후 23시 59분까지 열리는 이번 이벤트는 세계 장애인의 날을 맞아 시각장애인을 위한 접근성 기능인 ‘스크린 리더(Screen Reader)’를 알리고자 기획됐다. 스크린 리더는 모바일 화면의 텍스트를 음성으로 읽어주는 기능으로, iOS 운영체제에서는 ‘보이스오버(VoiceOver)’로 불린다.\n나만의 별자리는 이벤트 페이지에서 들리는 목소리 안내에 집중해 화면을 터치하면 찾을 수 있다. 소리에 집중하기 어려운 청각장애인들을 위한 별도의 화면도 준비했다. 별자리 선택 이후에는 세계 장애인의 날과 스크린 리더 기능에 대한 소개를 확인할 수 있다.\n기부를 희망할 경우 회당 최소 1천 원부터 최대 2백만 원까지 가능하다. 기부 횟수는 제한이 없으며 세액공제를 위한 기부금 영수증 발급 신청도 할 수 있다. 모인 기부금 전액은 유니세프 한국위원회와 사랑의열매에 전달해 장애 아동들을 지원하는 데 사용될 예정이다. 기부금의 모집 및 사용 내역은 각 기관에서 투명하게 공개할 계획이다.\n토스 관계자는 “이번 이벤트는 스크린 리더와 같은 접근성 기능을 모든 사용자들이 친숙하게 느낄 수 있도록 하기 위해 기획했다”라며 “토스는 누구나 동등하게 모바일 금융 서비스를 누릴 수 있는 환경을 조성하기 위해 노력하고 있으며, 앞으로도 그 노력을 이어갈 것”이라고 밝혔다.\n한편, 토스는 2022년부터 매년 연말 기부 이벤트를 꾸준히 이어오고 있다. 특히 지난해 연말 진행한 ‘도전! 산타 선발 대회’에는 총 39만 명의 사용자가 참여했다. 이벤트를 통해 모인 8억 3천만 원의 기부금은 3개 기관에 전달했다.",
        "content": "접근성 기능 간접 체험 후 토스페이로 기부까지",
        "contentSnippet": "접근성 기능 간접 체험 후 토스페이로 기부까지",
        "guid": "https://blog.toss.im/article/international-day-of-people-with-disability",
        "isoDate": "2024-12-03T00:52:00.000Z"
      },
      {
        "title": "토스, 신한은행과 ‘신한 토스페이 적금’ 출시",
        "link": "https://blog.toss.im/article/tosspay-shinhan",
        "pubDate": "Tue, 03 Dec 2024 00:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}토스페이로 월 1회 결제⋅충전 시 우대금리 최대 2.0%포인트 적용\n상품 출시 이벤트로 토스포인트 최대 4500원 제공\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n모바일 금융 서비스 ‘토스’를 운영하는 비바리퍼블리카(이하 ‘토스’)가 신한은행과 ‘신한 토스페이 적금’ 상품을 출시한다고 3일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n‘신한 토스페이 적금’은 토스에서만 가입할 수 있는 6개월 만기 자유적금 상품이다. 최대 월 30만 원까지 저축 가능하며, 기본금리 연 2.0%에 우대금리 2.5%포인트가 더해져 최고 연 4.5% 금리를 제공한다.\n우대금리는 △신한은행을 연결계좌로 토스페이 결제 및 충전 실적이 월 1회 이상인 경우 최대 4회 인정, 연 2.0%포인트 적용 △상품 가입 직전 1년간 신한은행 예⋅적금 미보유 고객 0.5%포인트이다.\n토스페이는 은행 계좌나 신용카드를 미리 등록해 두고 온라인과 오프라인에서 손쉽게 사용할 수 있는 간편결제 서비스다. 국내뿐만 아니라 해외 56개국에서도 결제 가능하며 사용처는 토스 앱 내에서 확인이 가능하다.\n토스는 이번 적금 상품을 가입하는 고객에게 토스포인트 2000원을 지원한다. 상품 가입 후 적금 잔액 30만 원 달성 시 1500원, 적금 3개월 유지 시 1000원을 제공하여 토스포인트 최대 4500원을 받을 수 있다.\n적금 상품은 ‘토스 앱’ > ‘홈’ > ‘계좌개설’ 메뉴에서 확인할 수 있으며, 토스 앱을 통해 ‘신한 SOL뱅크’ 앱에서 가입 절차가 진행된다. 적금 상품은 2025년 6월 30일까지 선착순 20만 좌 한도로 판매되며, 토스포인트 이벤트도 같은 기간 동안 진행한다.\n토스 관계자는 “토스페이를 이용하는 고객들이 복잡한 금리 조건 없이 간편하게 이용할 수 있는 적금 상품 마련을 위해 신한은행과 협력하게 되었다”며 “앞으로도 토스는 이용자에게 더 많은 혜택과 편리한 금융 생활 경험을 위해 노력할 것”이라고 밝혔다.",
        "content": "토스페이로 결제하고 우대금리 받아 가세요",
        "contentSnippet": "토스페이로 결제하고 우대금리 받아 가세요",
        "guid": "https://blog.toss.im/article/tosspay-shinhan",
        "isoDate": "2024-12-03T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]