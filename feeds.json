[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": [
      {
        "creator": "사소한 것들의 역사",
        "title": "비전공자도 이해할 수 있는 웹 개발의 역사",
        "link": "https://ppss.kr/archives/257673",
        "pubDate": "Fri, 22 Aug 2025 01:16:53 +0000",
        "content:encodedSnippet": "동영상이나, 음성 따위의 각종 멀티미디어를 이용하는 인터넷을 이르는 말. = 월드 와이드 웹.\n국립국어원 표준국어대사전\n \n시작하며\n요즘 글이 뜸했습니다. 사실 뉴스레터 서비스가 유료로 전환되고 나니, 예전처럼 손이 잘 안 가게 되네요. (한 번 발송할 때 마다 치킨 한 마리값이 사라집니다..ㅠㅠ)\n그래서 역사 콘텐츠를 텍스트가 아닌 다른 방식으로 즐길 수 있는 방법을 알아보고 있는데요, 그중 하나가 웹사이트였습니다. 그렇게 코딩을 시작하게 되었는데요. 코딩을 하며 배우는 웹의 기술들이 어떤 배경으로 탄생했는지가 궁금해지더라구요. 그래서 역사를 조사해 보았습니다.\n최대한 개발 지식이 없는 분들도 이해하실 수 있도록 글을 구성해 보았지만, 아무래도 다루는 내용이 조금 전문적이다 보니 쉽지는 않네요. 그리고 웹의 역사는 정말 방대하더라구요. 프론트엔드를 중점적으로 조사했는데, 그럼에도 분량 조절에는 완전히 실패했습니다. 시간 나실 때 천천히 읽어주시면 감사하겠습니다.\n \n1. 웹의 기반: 하이퍼텍스트\n웹의 출발점은 ‘하이퍼텍스트’라는 개념에서 시작됩니다. 하이퍼텍스트는 1963년, 테드 넬슨(Ted Nelson)이 책이나 문서처럼 선형적으로만 정보를 읽는 방식에서 벗어나 인간 사고처럼 자유롭게 연결되고 탐색 가능한 정보 구조를 만들고자 진행했던 ‘제너두(Xanadu)’라는 프로젝트에서 처음 사용됩니다. 모든 문서를 상호 연결하고, 문서의 부분 인용과 출처·변경 기록까지 영구적으로 추적할 수 있는 하이퍼텍스트 네트워크를 목표로 했습니다.\n이후 1967년, 브라운대학교의 앤드리스 반 댐(Andries van Dam)과 함께 실제로 하이퍼텍스트 편집 시스템을 구현하면서, 컴퓨터 기반의 하이퍼텍스트 시스템이 현실화되기 시작했습니다.\n\n1980년대에는 워드프로세서처럼 문서를 다루는 프로그램이 점점 발전하면서, 하이퍼텍스트 기능을 포함한 다양한 소프트웨어가 등장했습니다. 특히 1987년 애플이 발표한 ‘하이퍼카드(HyperCard)’는 프로그래밍 지식이 없어도 사용자가 직접 인터페이스를 만들고 멀티미디어 요소를 넣을 수 있는 환경을 제공하며 하이퍼텍스트 기술의 대중화를 이끌었습니다.\n \n2. 웹과 HTML의 등장\n\n1991년, 유럽입자물리연구소(CERN)의 물리학자 팀 버너스 리(Tim Berners-Lee)는 연구자들 간의 정보 공유를 위해 새로운 시스템을 제안합니다. 이 시스템은 인터넷 위에 하이퍼텍스트 기술을 얹는 형태로, 논문과 데이터를 연결하고 접근할 수 있게 만드는 것이 목적이었습니다. 바로 오늘날 우리가 사용하는 월드 와이드 웹(World Wide Web, WWW)의 시작입니다.\n기존 인터넷은 이메일, 파일 전송 등 통신 기능에 초점을 맞췄지만, 웹은 처음으로 콘텐츠 중심의 구조를 인터넷에 도입하며 인터넷 사용자의 범위와 목적을 크게 넓히는 계기가 되었습니다.\n이 웹 시스템의 핵심 구성 요소는 HTML(HyperText Markup Language)이었습니다. HTML은 웹페이지의 구조를 기술하는 언어로, 하이퍼링크를 포함한 텍스트, 이미지, 레이아웃 등의 요소를 브라우저에 표시할 수 있게 합니다.\n \n3. WWW vs 고퍼\n\n하지만 웹이 처음 등장했을 때는 생각보다 큰 주목을 받지 못했습니다. 논문 중심의 정보 공유라는 목적은 대중에게는 와 닿지 않았기 때문입니다. 대신, 1991년 미국 미네소타주립대학에서 만들어진 ‘고퍼(Gopher)’라는 다른 서비스가 인기 끌고 있었죠. 고퍼는 텍스트 기반 메뉴를 통해 원하는 정보를 찾아가는 구조로, 네트워크 속도가 느린 당시 환경에서도 빠르고 안정적인 성능을 제공했습니다.\n\n반면 웹은 이미지 기반의 인터페이스라서 느린 연결 환경에서 비효율적이었습니다. 특히 웹은 고성능 워크스테이션 ‘넥스트(NeXT)’ 컴퓨터의 운영체제인 ‘넥스트스텝(NeXTSTEP)’에서만 구현되었는데, 문제는 NeXT 컴퓨터가 많이 팔리지 않았다는 것이었죠. 웹이 널리 쓰이기 위해서는 다양한 운영체제에서 동작할 수 있도록 해야 했습니다.\n \n4. 웹브라우저의 등장과 서버의 탄생\n\n1993년, 시카고의 NCSA(국립 슈퍼컴퓨터 응용센터)에서 아르바이트를 하던 마크 앤드리센(Marc Andreessen)은 NCSA 소속 프로그래머인 에릭 비나(Eric Bina)와 함께 유닉스를 지원하는 웹 브라우저 ‘모자이크(Mosaic)’를 개발합니다.\n모자이크는 마우스를 이용해 인터넷을 탐색할 수 있는 클릭 인터페이스를 제공한 최초 브라우저로, 일반 사용자들도 손쉽게 웹을 사용할 수 있도록 만든 획기적인 프로그램이었습니다. 모자이크의 가능성을 확인한 NCSA는 인력을 보강해 같은 해 윈도우와 매킨토시 버전도 출시했습니다.\n그 결과 단 두 달 만에 100만 건이 넘는 다운로드를 기록하며 큰 성공을 거두었습니다. 이로써 웹은 고퍼를 제치고 대중화의 길에 들어서게 됩니다.\n웹이 대중에게 퍼지기 시작하면서 사람들은 단순히 문서를 읽는 데 그치지 않고, 직접 글을 남기거나 검색을 하는 등 웹과의 상호작용을 원하게 됩니다. 이렇게 사용자의 요청을 받아 서버가 실시간으로 처리해 주는 기능이 필요해졌고, 그에 따라 웹 서버에서 정보를 처리해 다시 웹페이지에 반영하는 ‘백엔드 기술’이 등장하게 됩니다.\n이때 등장한 기술이 NCSA에서 만들어진 CGI(Common Gateway Interface)입니다. 사용자가 웹페이지에서 입력을 보내면, 서버는 그 정보를 받아 CGI 프로그램을 실행해 결과를 만든 뒤 다시 웹페이지로 돌려보내는 방식이었죠.\n \n5. 1차 브라우저 전쟁 넷스케이프 vs 익스플로러 – CSS, Javascript, DOM\n\n모자이크의 성공에도 불구하고 모자이크 개발을 주도했던 아르바이트생 앤드리센은 정식 개발팀에 포함되지 못했고, 앤드리센은 NCSA를 떠나 넷스케이프(Netscape)를 창업합니다. 그리고 1994년 10월, ‘넷스케이프 네비게이터(Netscape Navigator)’라는 웹 브라우저를 출시합니다.\n‘넷스케이프 네비게이터’는 상업적인 용도가 아니라면 누구나 무료로 사용할 수 있었습니다. 덕분에 출시한 지 3개월도 채 되지 않아 200만 건이 넘는 다운로드를 기록하며 폭발적인 반응을 일으켰고, 넷스케이프 네비게이터는 웹의 상징이 되었죠.\n\n이 상황을 지켜보고 있던 마이크로소프트는 모자이크 브라우저에 라이선스 비용을 지불하고 ‘인터넷 익스플로러(Internet Explorer)’를 개발하여 1995년 브라우저 경쟁에 뛰어들었죠. 인터넷 익스플로러 2.0부터는 브라우저를 무료 제공을 하며 공격적으로 마케팅합니다.\n넷스케이프도 이에 맞서며 경쟁이 치열해집니다. 특히 1996년에는 웹사이트에서 사용자와 상호작용할 수 있게 해주는 JavaScript를 개발해 넷스케이프 네비게이터 2에 탑재합니다. 이에 질세라 MS도 같은 해 Jscript를 개발해 인터넷 익스플로러 3.0에 탑재하고, 뿐만 아니라 CSS(Cascading Style Sheets)라는 웹 디자인 기술을 도입해 주목받았죠. CSS는 HTML 내부에 직접 스타일을 입력하던 비효율적인 구조를 해결하며 웹의 시각적 표현을 풍부하게 만들어 주었습니다.\n\nJavaScript와 JScript 덕분에 웹사이트는 버튼 클릭, 마우스 오버 같은 간단한 인터랙션을 구현할 수 있게 되었습니다. 그러나 이때까지는 웹페이지의 구조나 내용 자체를 자유롭게 제어하긴 어려웠습니다.\n이를 해결하기 위한 기술로 등장한 것이 바로 DOM(Document Object Model)입니다. DOM은 웹페이지의 내용을 계층적 구조로 표현하여, 자바스크립트가 특정 요소를 선택하고 조작할 수 있도록 해주었습니다. 덕분에 사용자가 글자를 입력하면 그 값을 검사하거나, 버튼을 누르면 화면 구성이 바뀌거나, 필요한 부분만 서버에서 불러오는 기능도 가능해졌습니다.\n1997년 넷스케이프와 마이크로소프트가 각각 DOM 기능이 확장된 새로운 브라우저(Netscape Navigator 4.0과 IE 4.0)를 출시하면서 동적인 웹(DHTML)이 본격화됩니다. 하지만 두 회사가 DOM을 각기 다르게 만들었기 때문에, 한 웹사이트가 브라우저마다 다르게 보이거나 제대로 작동하지 않는 문제가 있었죠. 이런 문제를 ‘크로스 브라우징 이슈’라고 부릅니다.\n이러한 혼란은 웹 표준화의 필요성을 절감하게 했고, 이후 W3C와 같은 기구가 등장해 HTML, CSS, DOM 등의 명확한 명세를 정립하게 되는 계기로 작용합니다.\n\n익스플로러와 넷스케이프의 대결은 1997년에 종지부를 찍게 됩니다. MS가 Windows 98에 기본 브라우저로 인터넷 익스플로러를 탑재했습니다. 이미 브라우저가 깔려 있는 컴퓨터 사용자들은 굳이 다른 브라우저를 다운로드할 이유가 없기 때문에 넷스케이프의 점유율은 급감합니다.\n넷스케이프는 익스플로러와의 경쟁에서 밀려 결국 1998년, 미국의 큰 통신회사인 AOL에 42억 달러에 회사를 넘깁니다. 이후 인터넷 익스플로러는 독주를 이어가며 2002년에는 점유율 96%까지 올라가게 됩니다.\n \n6. 야후, 아마존 등의 등장 – PHP, JSP\n\n웹이 단순한 문서 공유의 도구를 넘어 일상 속 서비스 플랫폼으로 진화한 결정적인 전환점은 포털과 전자상거래의 등장입니다. 1994년 스탠퍼드 대학의 제리 양(Jerry Yang)과 데이빗 파일로(David Filo)는 인터넷 상의 수많은 웹사이트를 주제별로 분류한 디렉토리인 Jerry and David’s Guide to the World Wide Web를 만들었고, 이는 곧 ’야후(Yahoo!)’로 발전합니다. 야후는 단순한 링크 모음이 아닌, 정보를 분류하고 검색할 수 있는 웹의 첫 포털 개념을 대중에게 선보였죠.\n같은 시기 제프 베조스가 창업한 아마존은 책을 판매하는 온라인 쇼핑몰로 시작해, 웹을 통해 상품을 사고팔 수 있다는 인식을 확산시켰습니다. 이베이, 알리바바 같은 플랫폼도 비슷한 시기에 출범하며 웹은 정보 탐색에서 ‘상거래와 사용자 서비스’ 중심으로 패러다임을 바꾸기 시작합니다.\n이런 변화는 웹이 단순히 정적인 문서를 보여주는 수준에서 벗어나, 사용자 계정, 장바구니, 검색, 결제 등 실시간 데이터 처리가 필요해졌다는 의미였습니다. 즉, 웹의 동작 방식은 ‘프론트엔드’뿐 아니라, 사용자의 요청을 받아 처리하는 ‘서버 기술(백엔드)’의 발전이 필수였죠.\n기존에는 CGI(Common Gateway Interface)를 통해 이러한 요청을 처리했지만, CGI 방식은 매 요청마다 외부 프로그램을 새로 실행해야 했기에 서버에 부담이 컸고, 대규모 서비스 확장에도 적합하지 않았습니다. 이런 제약을 극복하기 위해 등장한 대표적인 기술이 바로 PHP와 Java Servlet입니다.\n\nPHP는 1995년 라스무스 러도프(Rasmus Lerdorf)가 개인 홈페이지 방문자 수를 집계하려 만든 도구에서 출발했습니다. HTML에 직접 프로그래밍 코드를 삽입할 수 있다는 특징 덕분에 빠르게 확산되었고, 설치가 간편하고 학습 난이도가 낮아 개인 블로그나 중소형 웹사이트에서 널리 쓰였습니다. 특히 WordPress와 같은 콘텐츠 관리 시스템(CMS)의 기반 언어로 채택되면서 웹의 보편적 도구로 자리잡게 됩니다.\n\n반면, 기업이나 금융권 등에서는 더 정교하고 안정적인 웹 기술이 필요했습니다. 이에 선 마이크로시스템즈(Sun Microsystems)는 1997년 Java 언어를 바탕으로 Java Servlet을 발표합니다. Java는 원래 가전제품에 사용되는 임베디드 소프트웨어를 위해 만들어졌는데, 이를 웹에 맞게 개량한 것이 Java Servlet이었죠.\nServlet은 CGI 방식의 비효율을 극복해, 서버 메모리를 효과적으로 관리하고 요청에 빠르게 응답할 수 있는 구조를 제공했습니다. 이후 JSP(Java Server Pages)가 등장하면서 Java 기반의 웹 서비스 구축도 본격화됩니다. 이같은 서버 측 기술의 발전으로 웹은 사용자의 요청에 따라 실시간으로 콘텐츠를 생성하고 처리할 수 있게 되었습니다.\n하지만 서버에서 데이터를 만들어도, 그것을 사용자 화면에 효율적으로 반영하는 방법이 미흡했죠. 당시 웹에서는 사용자의 요청이 있을 때마다 전체 페이지를 새로 불러왔기 때문에, 화면이 깜빡이거나 로딩 시간이 길어지는 등 사용자 경험이 크게 저하되었습니다. 특히 빠른 반응이 핵심인 전자상거래나 검색 서비스에서는 치명적인 한계로 작용했습니다.\n \n7. 구글 맵이 보여준 혁신: Ajax\n\n이러한 문제를 해결하고, 서버에서 생성된 데이터를 더 효율적으로 브라우저에 전달하기 위해 1999년에 등장한 기술이 Ajax(Asynchronous JavaScript and XML)였습니다. Ajax는 기존처럼 페이지 전체를 새로 고치지 않고도, 서버와 주고받는 데이터를 바탕으로 화면의 일부만을 바꿀 수 있게 해주는 기술입니다. 즉, 매번 전체 페이지를 갱신하는 것이 아닌 특정 영역만을 빠르게 바꿀 수 있게 된 것이죠. 이로 인해 부드러운 전환과 빠른 반응이 가능한 웹이 열린 것입니다.\n\nAjax는 2005년 Google Maps를 통해 전 세계 사용자에게 각인됩니다. Google Maps는 웹 기반임에도 데스크탑 소프트웨어처럼 자연스러운 스크롤과 빠른 줌 기능, 실시간 탐색을 제공해, Ajax의 혁신을 보여주었죠.\n \n8. 브라우저 춘추전국시대 – Flash, JQuery\n\n인터넷 익스플로러는 브라우저 시장을 장악했지만, 표준을 무시한 독자적인 구현, 잦은 보안 문제, 기능 업데이트 중단 등으로 비판을 받기 시작합니다. 이에 따라 대안 브라우저들이 등장합니다.\n2004년, 모질라 재단은 오픈소스 기반의 Firefox를 출시해 빠른 속도, 탭 브라우징, 확장 기능 등으로 주목을 받았고, 애플도 WebKit 엔진을 기반으로 Safari를 개발해 Mac OS에 기본 탑재했죠. 그 결과, Firefox, Safari, Opera 등 다양한 브라우저들이 공존하는 ‘브라우저 춘추전국시대’로 접어들게 됩니다.\n\n하지만 각 브라우저가 HTML, CSS, JavaScript를 해석하고 실행하는 방식이 제각각이었습니다. 이 시기에 주목받은 것이 Flash였습니다. Flash는 독립 실행 환경으로 브라우저와 상관없이 일관된 사용자 경험을 보장했고, 복잡한 애니메이션, 음악, 동영상 등을 손쉽게 구현할 수 있어 웹 기반 게임, 광고, 멀티미디어 사이트 등에서 널리 사용되었습니다.\n\nFlash, Sliverlight와 같은 외부 플러그인을 사용하지 않고 브라우저 간의 호환성 문제를 보다 근본적으로 해결한 것은 jQuery입니다. 2006년 존 레식(John Resig)에 의해 만들어진 jQuery는 복잡한 자바스크립트 기능을 간단한 문법으로 사용할 수 있게 해주었고, 브라우저마다 다른 DOM, 이벤트 처리, Ajax 방식의 차이를 통일된 방식으로 다룰 수 있게 해주는 API(기능 호출 방식)를 제공했습니다. 이를 통해 개발자는 복잡한 크로스 브라우징 문제를 걱정하지 않고, 웹의 동작을 더 쉽게 제어할 수 있게 되었습니다.\n \n9. Flash 가고 HTML5 온다\nFlash나 Silverlight 같은 별도의 플러그인에 의존한 멀티미디어 재생은 보안에 취약하고, 모바일 기기와의 호환도 떨어졌으며, 성능 문제도 잦았습니다.\n이런 문제를 해결하기 위해 HTML의 새로운 버전인 HTML5가 개발되었고, 2008년 초안이 공개된 뒤 2014년 정식 표준으로 채택됩니다. HTML5는 단순히 웹페이지의 구조를 구성하는 언어를 넘어, 웹 자체를 하나의 앱 실행 환경으로 발전시키기 위한 핵심 기술로 자리잡습니다.\nHTML5를 통해 브라우저만으로도 동영상과 음악을 재생할 수 있고, 캔버스를 활용한 그래픽 표현이나 사용자 위치 정보 활용, 드래그 앤 드롭 같은 다양한 상호작용 기능도 구현할 수 있게 되었습니다. 웹페이지의 구조도 더 명확하게 나눌 수 있게 되어, 사용자 경험과 접근성도 함께 향상되었죠. 결과적으로 HTML5는 웹을 단순한 문서 공유 도구에서 ‘앱이 실행되는 플랫폼’으로 바꾸는 전환점이 됩니다.\n특히 2010년, 애플이 아이폰에서 Flash 지원을 중단한다고 발표하면서 플러그인 중심의 웹 기술은 급속히 쇠퇴하고, HTML5 중심의 표준 웹 기술이 주류로 자리잡게 됩니다.\n \n10. 빠르고 간편해지는 백엔드 개발\n웹 개발은 점점 복잡해졌고, 이에 따라 웹 개발자들은 더 많은 기능을 더 빠른 시간 안에 구현해야 했죠. 이 과정에서 PHP는 개발 속도는 빠르지만 유지보수가 어렵고, Java는 안정성은 뛰어나지만 설정이 복잡하고 개발 속도가 느린 구조적인 한계에 부딪히게 됩니다.\n\n이런 상황에서 새로운 접근을 제시한 것이 바로 Ruby on Rails입니다. 2004년 데이비드 하이네마이어 한슨(David Heinemeier Hansson)이 만든 Rails는 Ruby 언어를 기반으로, 반복적인 코드를 줄이고 구성 요소를 표준화하며, 데이터베이스와의 연동까지 자동화하는 기능을 제공합니다. GitHub, Shopify, Twitter 같은 서비스들이 초기에 Rails를 채택하면서 그 영향력은 더욱 커졌습니다.\n\n비슷한 시기, Python 기반의 Django도 등장합니다. 원래는 지역 신문사의 콘텐츠 관리 시스템을 위해 개발되었지만, 빠른 개발과 보안 중심 설계 덕분에 교육기관, 언론사, 콘텐츠 서비스 등에서 널리 사용됩니다.\nDjango는 기본적으로 관리자 화면이 자동 생성되며, 복잡한 SQL문을 직접 작성하지 않고 파이썬 문법으로 데이터를 조작할 수 있었고, 템플릿 시스템까지 제공하며 웹 전반의 구조를 깔끔하게 정리할 수 있었습니다.\n이처럼 Ruby on Rails와 Django는 복잡한 서버 개발을 간결하게 만들었고, 웹 개발이 ‘빠른 프로토타입 제작 → 반복적 개선’이라는 새로운 문화로 변화하는 데 핵심적인 역할을 했습니다.\n \n11. 브라우저 시장을 제패한 크롬\n2000년대 중반, 구글은 더 이상 단순한 검색 서비스 기업이 아니라, 웹 자체를 하나의 운영체제처럼 만들겠다는 비전을 세우게 됩니다. 사용자 대부분이 웹 브라우저를 켜고 제일 먼저 방문하는 곳이 구글이었기에, 웹이 OS처럼 작동한다면 구글은 그 출발점에 설 수 있었죠.\n\n이를 위해 구글은 문서 작성(Google Docs), 이메일(Gmail), 캘린더 같은 웹 기반 소프트웨어를 차례로 개발합니다. 하지만 웹 애플리케이션을 제대로 작동시키기 위해서는 당시 브라우저의 성능으로는 한계가 있었습니다. 이에 구글은 스스로 브라우저를 만들기로 결정하고, 브라우저의 핵심 구성 요소인 자바스크립트 엔진도 직접 새로 개발하기로 합니다.\n그렇게 2008년 V8 JavaScript 엔진이 등장합니다. V8은 기존 엔진들과 달리 코드를 한 줄씩 해석하는 방식이 아니라, 전체 코드를 기계어로 바꿔 실행하는 JIT(Just-In-Time) 컴파일 방식을 채택합니다. 이로써 자바스크립트의 실행 속도가 획기적으로 빨라졌고, 브라우저에서 실제 데스크톱 앱에 가까운 복잡한 기능도 가능해졌습니다. 또한 멀티코어 CPU 환경에 최적화된 병렬 처리 기술도 적용되었죠.\n\nV8 엔진은 애플의 오픈소스 렌더링 엔진인 WebKit과 결합되어 같은 해 ‘크롬Chrome’ 브라우저로 완성됩니다. 크롬은 빠른 속도와 강력한 디버깅 도구, 간결한 사용자 인터페이스로 개발자와 일반 사용자 모두에게 큰 인기를 끌었고, 당시 인터넷 익스플로러가 독점하던 브라우저 시장에서 속도와 안정성, 개발 친화성을 무기로 빠르게 점유율을 확보해나갑니다. 2012년에는 세계 브라우저 점유율 1위로 올라서며 웹 개발의 새로운 표준 환경을 만들어갑니다.\n \n12. JavaScript할 줄 알죠? 이제 서버도 개발하세요: Node.js\n\n2009년, 라이언 달Ryan Dahl 은 구글의 V8 JavaScript 엔진을 기반으로 서버에서도 JavaScript를 실행할 수 있는 기술인 ‘Node.js’를 발표합니다. 이전까지는 브라우저(클라이언트)는 JavaScript, 서버는 PHP, Java, Python 같은 언어로 나뉘어 개발하는 것이 일반적이었지만, Node.js의 등장으로 한 명의 개발자가 프론트엔드와 백엔드를 모두 자바스크립트로 개발할 수 있는 시대가 열립니다. 따라서 빠른 개발과 인력 절감이 중요한 스타트업 환경에서 특히 큰 주목을 받게 됩니다.\nNode.js의 또 다른 혁신은 서버 작동 방식 자체를 바꿨다는 점입니다. 기존 서버는 요청이 들어올 때마다 새로운 프로세스나 스레드를 생성해 처리했지만, 이는 많은 사용자가 동시에 접속하면 서버에 과부하를 일으키기 쉬웠습니다. Node.js는 하나의 프로세스로 수천 개의 요청을 효율적으로 처리할 수 있도록 했습니다. 이 구조는 채팅, 알림, 실시간 데이터 처리 등 동시성이 중요한 서비스에 최적화되어 있었습니다.\n\n이러한 구조적 혁신과 함께 Node.js 생태계를 탄탄하게 만든 또 하나의 요소는 npm(Node Package Manager)이었습니다. 개발자는 자신이 만든 라이브러리나 도구를 npm에 등록하고, 다른 개발자는 이를 간편하게 설치해 사용할 수 있었죠. 이로 인해 JavaScript 기반의 수많은 유틸리티와 프레임워크가 빠르게 확산되었습니다.\n \n13. 복잡한 UI의 페이스북: React\n\n2000년대 후반, 페이스북은 전 세계 수억 명의 사용자를 확보하며 빠르게 성장합니다. 사용자가 늘어날수록 웹사이트가 처리해야 할 데이터도 많아지고, 사용자의 행동에 따라 화면을 실시간으로 반응시키는 일이 중요해졌습니다. 그러나 당시 주류였던 jQuery 기반의 방식은 화면 구성 요소를 일일이 제어해야 했고, 복잡한 UI에서는 유지보수와 성능 모두에 한계가 있었습니다.\n\n이 문제를 해결하기 위해 페이스북은 2013년, React라는 UI 라이브러리를 오픈소스로 공개합니다. React는 웹 화면을 ‘컴포넌트’라는 작은 단위로 나눠서 개발할 수 있게 만들었고, 각 컴포넌트는 상태(state)와 전달받은 데이터(props)를 바탕으로 화면을 그리도록 설계되었습니다.\n가장 혁신적인 점은 실제 화면(DOM)을 직접 조작하지 않고, 가상의 화면 구조인 Virtual DOM을 사용한다는 점이었습니다. Virtual DOM은 실제 DOM보다 훨씬 가볍기 때문에 빠르게 화면의 변화를 계산할 수 있었고, 변경이 필요한 부분만을 선별해 실제 DOM에 반영함으로써 효율적인 렌더링이 가능했습니다. 이를 통해 React는 복잡한 UI를 다루는 데 필요한 속도와 관리 편의성을 모두 갖추게 되었고, 곧 프론트엔드 개발의 새로운 표준으로 자리잡게 됩니다.\n \n14. React, Angular, Vue 삼국지\n\n페이스북이 React를 공개하기 전, 2010년에 구글은 이미 AngularJS라는 혁신적인 프레임워크를 선보였습니다.\nAngularJS는 기존 웹 개발에서 사용자가 입력하면 자바스크립트로 직접 DOM을 찾아서 내용을 바꿔야 했던 것과 달리 화면에 보여줄 내용을 미리 템플릿화해두고, 사용자가 그 안에 넣을 데이터만 바꾸면, 알아서 화면이 갱신되는 구조였어요. 이런 방식을 ‘양방향 바인딩’이라고 부릅니다. 하지만 이를 위해 AngularJS는 화면이 바뀌었는지를 주기적으로 계속 확인해야 했기에 페이지가 복잡해질수록 느려지고, 성능 문제도 생겼습니다.\n이런 한계를 극복하려고, 구글은 2016년 완전히 새롭게 만든 Angular 2를 발표합니다. Angular 2는 React의 컴포넌트 방식을 도입합니다. 그리고 Zone.js라는 기술을 이용해 변화가 생길 가능성이 있는 순간에만 화면의 변화를 감지해 성능 문제도 해결하죠. 하지만 기존 AngularJS와 호환되지 않아 기존 사용자들이 이탈했고, 구조가 복잡하고 배우기도 어려워 신규 유저 유입도 쉽지 않았습니다.\n\n이러한 Angular의 복잡함과 React의 JSX 문법에 익숙하지 않은 개발자들 사이에서 새로운 대안으로 떠오른 것이 Vue.js입니다. Vue는 구글의 개발자 에반 유(Evan You)가 React와 Angular의 장점만을 취합해 만든 프레임워크입니다. React처럼 컴포넌트 기반 구조를 따르되, HTML 중심의 템플릿 문법을 사용해 진입 장벽을 낮췄고, 상태 관리, 라우팅, 빌드 도구 등을 공식적으로 지원하면서 점진적 도입이 가능한 구조로 설계되었습니다.\n덕분에 Vue는 소규모 팀과 개인 개발자를 중심으로 빠르게 확산되며, Angular, React와 함께 프론트엔드 삼국지를 형성하게 됩니다.\n \n15. 메타 프레임워크의 시대: Next.js\nReact, Angular, Vue는 화면을 구성하는 데 강력했지만, 웹 애플리케이션 전체를 구축하기에는 부족한 점이 있었습니다. 예를 들어, 화면 이동(라우팅), 서버에서의 데이터 처리, 검색엔진 최적화(SEO) 같은 기능은 따로 구현해야 했기 때문입니다.\n\n이 문제를 해결하고자 등장한 것이 바로 Next.js입니다. 2016년 Vercel에서 발표된 Next.js는 React를 기반으로 하지만, 페이지 단위 라우팅, 서버사이드 렌더링(SSR), 정적 사이트 생성(SSG), 이미지 최적화, SEO 기능 등을 내장해, 복잡한 설정 없이 전체 웹사이트를 효율적으로 구성할 수 있게 해줍니다.\n이처럼 UI 도구에 그치지 않고, 백엔드와 배포까지 포괄하는 프레임워크*를 ‘메타 프레임워크(meta-framework)’라고 부릅니다. Next.js 이후 Vue 기반의 Nuxt.js, Svelte 기반의 SvelteKit, Solid 기반의 SolidStart 등도 등장하며 웹 개발의 흐름은 ‘통합과 자동화’로 진화해가고 있습니다.\n이 과정에서 또 하나 주목받은 기술이 있습니다. 바로 Svelte입니다. 기존 프레임워크들이 브라우저에서 Virtual DOM을 통해 DOM을 갱신한 반면, Svelte는 개발자가 작성한 코드를 컴파일 시점에 실제 DOM 조작 코드로 바꿔주는 방식입니다. 즉, 브라우저가 무겁게 계산하지 않아도 되고, Virtual DOM도 필요 없게 되는 것이죠. Svelte는 이런 점에서 프레임워크가 아니라 컴파일러에 더 가깝고, DOM을 ‘언제, 어떻게 바꿀지’에 대한 고민을 아예 없애버리는 접근으로 새로운 흐름을 만들어가고 있습니다.\n* 프레임워크\n자주 사용하는 기능들을 미리 구조화해 놓은 일종의 도구 모음입니다. 즉, 개발자가 일일이 기본부터 만들 필요 없이, 정해진 틀 안에서 빠르고 일관되게 개발할 수 있도록 돕는 도구이죠.\n이 글에서 언급된 프레임워크는 Ruby on Rails, Django, React, Angular, Vue, NEXT.js입니다.\n\n \nReference\n정지훈. (2014). 거의 모든 인터넷의 역사. 메디치미디어\n정지훈. (2025). 거의 모든 IT의 역사. 메디치미디어\n이동준. (2023). 자바스크립트(JavaScript)의 탄생 이유와 역사.\n안정현. (2021). [Web] 웹 서비스의 역사와 발전.\n김민정. (2022). 웹 브라우저의 역사.\n김민상. (2021). 짧게 써보는 웹 프론트엔드의 역사.\n원문: 사소한 것들의 역사\n이 필자의 다른 글 읽기\n네가 실험한 것을 어떻게 믿음?: 실험실의 역사\n전쟁에서 기업으로, 기업에서 가정으로 이동해 온 컴퓨터의 역사\n22kg→ 1kg의 다이어트 성공기: 노트북의 역사",
        "enclosure": {
          "type": "image/jpeg",
          "length": "0",
          "url": "https://ppss.kr/wp-content/uploads/2025/08/000.jpg"
        },
        "dc:creator": "사소한 것들의 역사",
        "content": "동영상이나, 음성 따위의 각종 멀티미디어를 이용하는 인터넷을 이르는 말. = 월드 와이드 웹. 국립국어원 표준국어대사전 &#160; 시작하며 요즘 글이 뜸했습니다. 사실 뉴스레터 서비스가 유료로 전환되고 나니, 예전처럼 손이 잘 안 가게 되네요. (한 번 발송할 때 마다 치킨 한 마리값이 사라집니다..ㅠㅠ) 그래서 역사 콘텐츠를 텍스트가 아닌 다른 방식으로 즐길 수 있는 방법을 알아보고 있는데요, 그중 [&#8230;]",
        "contentSnippet": "동영상이나, 음성 따위의 각종 멀티미디어를 이용하는 인터넷을 이르는 말. = 월드 와이드 웹. 국립국어원 표준국어대사전   시작하며 요즘 글이 뜸했습니다. 사실 뉴스레터 서비스가 유료로 전환되고 나니, 예전처럼 손이 잘 안 가게 되네요. (한 번 발송할 때 마다 치킨 한 마리값이 사라집니다..ㅠㅠ) 그래서 역사 콘텐츠를 텍스트가 아닌 다른 방식으로 즐길 수 있는 방법을 알아보고 있는데요, 그중 […]",
        "guid": "http://3.36.87.144/?p=257673",
        "categories": [
          "IT",
          "역사"
        ],
        "isoDate": "2025-08-22T01:16:53.000Z"
      }
    ]
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Enabling Kotlin incremental compilation on Buck2",
        "link": "https://engineering.fb.com/2025/08/26/open-source/enabling-kotlin-incremental-compilation-on-buck2/",
        "pubDate": "Tue, 26 Aug 2025 16:00:52 +0000",
        "content:encodedSnippet": "The Kotlin incremental compiler has been a true gem for developers chasing faster compilation since its introduction in build tools. Now, we’re excited to bring its benefits to Buck2 –  Meta’s build system – to unlock even more speed and efficiency for Kotlin developers.\n\nUnlike a traditional compiler that recompiles an entire module every time, an incremental compiler focuses only on what was changed. This cuts down compilation time in a big way, especially when modules contain a large number of source files.\nBuck2 promotes small modules as a key strategy for achieving fast build times. Our codebase followed that principle closely, and for a long time, it worked well. With only a handful of files in each module, and Buck2’s support for fast incremental builds and parallel execution, incremental compilation didn’t seem like something we needed.\nBut, let’s be real: Codebases grow, teams change, and reality sometimes drifts away from the original plan. Over time, some modules started getting bigger – either from legacy or just organic growth. And while big modules were still the exception, they started having quite an impact on build times.\nSo we gave the Kotlin incremental compiler a closer look – and we’re glad we did. The results? Some critical modules now build up to 3x faster. That’s a big win for developer productivity and overall build happiness. \nCurious about how we made it all work in Buck2? Keep reading. We’ll walk you through the steps we took to bring the Kotlin incremental compiler to life in our Android toolchain.\nStep 1: Integrating Kotlin’s Build Tools API\nAs of Kotlin 2.2.0, the only guaranteed public contract to use the compiler is through the command-line interface (CLI). But since the CLI doesn’t support incremental compilation (at least for now), it didn’t meet our needs. Alternatively, we could integrate the Kotlin incremental compiler directly via the internal compiler’s components – APIs that are technically accessible but not intended for public use. However, relying on them would’ve made our toolchain fragile and likely to break with every Kotlin update since there’s no guarantee of backward compatibility. That didn’t seem like the right path either.\nThen we came across the Build Tools API (KEEP), introduced in Kotlin 1.9.20 as the official integration point for the compiler – including support for incremental compilation. Although the API was still marked as experimental, we decided to give it a try. We knew it would eventually stabilize, and saw it as a great opportunity to get in early, provide feedback, and help shape its direction. Compared to using internal components, it offered a far more sustainable and future-proof approach to integration.\n Depending on kotlin-compiler? Watch out!\nIn the Java world, a shaded library is a modified version of the library where the class and package names are changed. This process – called shading – is a handy way to avoid classpath conflicts, prevent version clashes between libraries, and keeps internal details from leaking out.\nHere’s quick example:\n\n\nUnshaded (original) class: com.intellij.util.io.DataExternalizer\nShaded class: org.jetbrains.kotlin.com.intellij.util.io.DataExternalizer\nThe Build Tools API depends on the shaded version of the Kotlin compiler (kotlin-compiler-embeddable). But our Android toolchain was historically built with the unshaded one (kotlin-compiler). That mismatch led to java.lang.NoClassDefFoundError crashes when testing the integration because the shaded classes simply weren’t on the classpath.\nReplacing the unshaded compiler across the entire Android toolchain would’ve been a big effort. So to keep moving forward, we went with a quick workaround: We unshaded the Build Tools API instead.  Using the jarjar library, we stripped the org.jetbrains.kotlin prefix from class names and rebuilt the library.\nDon’t worry, once we had a working prototype and confirmed everything behaved as expected, we circled back and did it right – fully migrating our toolchain to use the shaded Kotlin compiler. That brought us back in line with the API’s expectations and gave us a more stable setup for the future.\nStep 2: Keeping previous output around for the incremental compiler\nTo compile incrementally, the Kotlin compiler needs access to the output from the previous build. Simple enough, but Buck2 deletes that output by default before rebuilding a module. \nWith incremental actions, you can configure Buck2 to skip the automatic cleanup of previous outputs. This gives your build actions access to everything from the last run. The tradeoff is that it’s now up to you to figure out what’s still useful and manually clean up the rest. It’s a bit more work, but it’s exactly what we needed to make incremental compilation possible.\nStep 3: Making the incremental compiler cache relocatable\nAt first, this might not seem like a big deal. You’re not planning to move your codebase around, so why worry about making the cache relocatable, right?\nWell… that’s until you realize you’re no longer in a tiny team, and you’re definitely not the only one building the project. Suddenly, it does matter.\nBuck2 supports distributed builds, which means your builds don’t have to run only on your local machine. They can be executed elsewhere, with the results sent back to you. And if your compiler cache isn’t relocatable, this setup can quickly lead to trouble – from conflicting overloads to strange ambiguity errors caused by mismatched paths in cached data.\nSo we made sure to configure the root project directory and the build directory explicitly in the incremental compilation settings. This keeps the compiler cache stable and reliable, no matter who runs the build or where it happens.\nStep 4: Configuring the incremental compiler\nIn a nutshell, to decide what needs to be recompiled, the Kotlin incremental compiler looks for changes in two places:\n\n\nFiles within the module being rebuilt.\nThe module’s dependencies.\nOnce the changes are found, the compiler figures out which files in the module are affected – whether by direct edits or through updated dependencies – and recompiles only those.\nTo get this process rolling, the compiler needs just a little nudge to understand how much work it really has to do.\nSo let’s give it that nudge!\nTracking changes inside the module\nWhen it comes to tracking changes, you’ve got two options: You can either let the compiler do its magic and detect changes automatically, or you can give it a hand by passing a list of modified files yourself. The first option is great if you don’t know which files have changed or if you just want to get something working quickly (like we did during prototyping). However, if you’re on a Kotlin version earlier than 2.1.20, you have to provide this information yourself. Automatic source change detection via the Build Tools API isn’t available prior to that. Even with newer versions, if the build tool already has the change list before compilation, it’s still worth using it to optimize the process.\nThis is where Buck’s incremental actions come in handy again! Not only can we preserve the output from the previous run, but we also get hash digests for every action input. By comparing those hashes with the ones from the last build, we can generate a list of changed files. From there, we pass that list to the compiler to kick off incremental compilation right away – no need for the compiler to do any change detection on its own.\nTracking changes in dependencies\nSometimes it’s not the module itself that changes, it’s something the module depends on. In these cases, the compiler relies on classpath snapshot. These snapshots capture the Application Binary Interface (ABI) of a library. By comparing the current snapshots to the previous one, the compiler can detect changes in dependencies and figure out which files in your module are affected. This adds an extra layer of filtering on top of standard compilation avoidance.\nIn Buck2, we added a dedicated action to generate classpath snapshots from library outputs. This artifact is then passed as an input to the consuming module, right alongside the library’s compiled output. The best part? Since it’s a separate action, it can be run remotely or be pulled from cache, so your machine doesn’t have to do the heavy lifting of extracting ABI at this step.\n\nIf, after all, only your module changes but your dependencies do not, the API also lets you skip the snapshot comparison entirely if your build tool handles the dependency analysis on its own. Since we already had the necessary data from Buck2’s incremental actions, adding this optimization was almost free.\nStep 5: Making compiler plugins work with the incremental compiler\nOne of the biggest challenges we faced when integrating the incremental compiler was making it play nicely with our custom compiler plugins, many of which are important to our build optimization strategy. This step was necessary for unlocking the full performance benefits of incremental compilation, but it came with two major issues we needed to solve.\n Problem 1: Incomplete results\nAs we already know, the input to the incremental compiler does not have to include all Kotlin source files. Our plugins weren’t designed for this and ended up producing incomplete results when run on just a subset of files. We had to make them incremental as well so they could handle partial inputs correctly.\n\n Problem 2: Multiple rounds of Compilation\nThe Kotlin incremental compiler doesn’t just recompile the files that changed in a module. It may also need to recompile other files in the same module that are affected by those changes. Figuring out the exact set of affected files is tricky, especially when circular dependencies come into play. To handle this, the incremental compiler approximates the affected set by compiling in multiple rounds within a single build.\nCurious how that works under the hood? The Kotlin blog on fast compilation has a great deep dive that’s worth checking out.\nThis behavior comes with a side effect, though. Since the compiler may run in multiple rounds with different sets of files, compiler plugins can also be triggered multiple times, each time with a different input. That can be problematic, as later plugin runs may override outputs produced by earlier ones. To avoid this, we updated our plugins to accumulate their results across rounds rather than replacing them.\n\nStep 6: Verifying the functionality of annotation processors\nMost of our annotation processors use Kotlin Symbol Processing (KSP2), which made this step pretty smooth. KSP2 is designed as a standalone tool that uses the Kotlin Analysis API to analyze source code. Unlike compiler plugins, it runs independently from the standard compilation flow. Thanks to this setup, we were able to continue using KSP2 without any changes.\n Bonus: KSP2 comes with its own built-in incremental processing support. It’s fully self-contained and doesn’t depend on the incremental compiler at all. \nBefore we adopted KSP2 (or when we were using an older version of the Kotlin Annotation Processing Tool (KAPT), which operates as a plugin) our annotation processors ran in a separate step dedicated solely to annotation processing. That step ran before the main compilation and was always non-incremental.\nStep 7: Enabling compilation against ABI\nTo maximize cache hits, Buck2 builds Android modules against the class ABI instead of the full JAR. For Kotlin targets, we use the jvm-abi-gen compiler plugin to generate class ABI during compilation.\nBut once we turned on incremental compilation, a couple of new challenges popped up:\nThe jvm-abi-gen plugin currently lacks direct support for incremental compilation, which ties back to the issues we mentioned earlier with compiler plugins.\nABI extraction now happens twice – once during compilation via jvm-abi-gen, and again when the incremental compiler creates classpath snapshots.\nIn theory, both problems could be solved by switching to full JAR compilation and relying on classpath snapshots to maintain cache hits. While that could work in principle, it would mean giving up some of the build optimizations we’ve already got in place – a trade-off that needs careful evaluation before making any changes.\nFor now, we’ve implemented a custom (yet suboptimal) solution that merges the newly generated ABI with the previous result. It gets the job done, but we’re still actively exploring better long-term alternatives.\nIdeally, we’d be able to reuse the information already collected for classpath snapshot or, even better, have this kind of support built directly into the Kotlin compiler. There’s an open ticket for that: KT-62881. Fingers crossed!\nStep 8: Testing\nMeasuring the impact of build changes is not an easy task. Benchmarking is great for getting a sense of a feature’s potential, but it doesn’t always reflect how things perform in “the real world.” Pre/post testing can help with that, but it’s tough to isolate the impact of a single change, especially when you’re not the only one pushing code. \nWe set up A/B testing to overcome these obstacles and measure the true impact of the Kotlin incremental compiler on Meta’s codebase with high confidence. It took a bit of extra work to keep the cache healthy across variants, but it gave us a clean, isolated view of how much difference the incremental compiler really made at scale.\nWe started with the largest modules –  the ones we already knew were slowing builds the most. Given their size and known impact, we expected to see benefits quickly. And sure enough, we did.\nThe impact of incremental compilation \nThe graph below shows early results on how enabling incremental compilation for selected targets impacts their local build times during incremental builds over a 4-week period. This includes not just compilation, but also annotation processing, and a few other optimisations we’ve added along the way.\nWith incremental compilation, we’ve seen about a 30% improvement for the average developer. And for modules without annotation processing, the speed nearly doubled. That was more than enough to convince us that the incremental compiler is here to stay. \n\nWhat’s next\nKotlin incremental compilation is now supported in Buck2, and we’re actively rolling it out across our codebase! For now, it’s available for internal use only, but we’re working on bringing it to the recently introduced open source toolchain as well.\nBut that’s not all! We’re also exploring ways to expand incrementality across the entire Android toolchain, including tools like Kosabi (the Kotlin counterpart to Jasabi), to deliver even faster build times and even better developer experience.\nTo learn more about Meta Open Source, visit our open source site, subscribe to our YouTube channel, or follow us on Facebook, Threads, X and LinkedIn.\nThe post Enabling Kotlin incremental compilation on Buck2 appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>The Kotlin incremental compiler has been a true gem for developers chasing faster compilation since its introduction in build tools. Now, we’re excited to bring its benefits to Buck2 –  Meta’s build system – to unlock even more speed and efficiency for Kotlin developers. Unlike a traditional compiler that recompiles an entire module every time, [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/08/26/open-source/enabling-kotlin-incremental-compilation-on-buck2/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/08/26/open-source/enabling-kotlin-incremental-compilation-on-buck2/\">Enabling Kotlin incremental compilation on Buck2</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "The Kotlin incremental compiler has been a true gem for developers chasing faster compilation since its introduction in build tools. Now, we’re excited to bring its benefits to Buck2 –  Meta’s build system – to unlock even more speed and efficiency for Kotlin developers. Unlike a traditional compiler that recompiles an entire module every time, [...]\nRead More...\nThe post Enabling Kotlin incremental compilation on Buck2 appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=22830",
        "categories": [
          "Open Source"
        ],
        "isoDate": "2025-08-26T16:00:52.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Julia Shashkova",
        "title": "IntelliJ IDEA 2025.1.5 Is Out!",
        "link": "https://blog.jetbrains.com/idea/2025/08/intellij-idea-2025-1-5/",
        "pubDate": "Thu, 28 Aug 2025 16:20:57 +0000",
        "content:encodedSnippet": "We’ve released another update for IntelliJ IDEA 2025.1 – v2025.1.5.\nYou can update to this version from inside the IDE, via the Toolbox App, or by using snaps for Ubuntu. You can also download it from our website.\nThis release includes the following updates:\nThe IDE interface now performs seamlessly during Google Meet screen sharing on macOS when a second monitor is connected. [JBR-7582]\nUrlClassLoader.getFiles now returns the expected instances of java.nio.file.Path without conflicting with other paths. [IJPL-187780] \nTo find out more about the resolved issues, please refer to the release notes.\nIf you encounter any issues or would like to make a suggestion or a feature request, please submit them to our issue tracker.\nHappy developing!",
        "dc:creator": "Julia Shashkova",
        "content": "We’ve released another update for IntelliJ IDEA 2025.1 – v2025.1.5. You can update to this version from inside the IDE, via the Toolbox App, or by using snaps for Ubuntu. You can also download it from our website. This release includes the following updates: To find out more about the resolved issues, please refer to [&#8230;]",
        "contentSnippet": "We’ve released another update for IntelliJ IDEA 2025.1 – v2025.1.5. You can update to this version from inside the IDE, via the Toolbox App, or by using snaps for Ubuntu. You can also download it from our website. This release includes the following updates: To find out more about the resolved issues, please refer to […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=594646",
        "categories": [
          "releases",
          "bug-fix-update",
          "intellij-idea-2025-1"
        ],
        "isoDate": "2025-08-28T16:20:57.000Z"
      },
      {
        "creator": "Vadim Briliantov",
        "title": "Koog 0.4.0 Is Out: Observable, Predictable, and Deployable Anywhere You Build",
        "link": "https://blog.jetbrains.com/ai/2025/08/koog-0-4-0-is-out-observable-predictable-and-deployable-anywhere-you-build/",
        "pubDate": "Thu, 28 Aug 2025 09:26:51 +0000",
        "content:encodedSnippet": "Featuring Langfuse and W&B Weave Support, Ktor Integration, Native Structured Output, iOS Target, GPT-5, and More.\nKoog 0.3.0 was about making agents smarter and persistent. Koog 0.4.0 is about making them observable, seamlessly deployable in your stack, and more predictable in their outputs – all while introducing support for new models and platforms.\nRead on to discover the key highlights of this release and the pain points it is designed to address.\nLearn more\n🕵️ Observe what your agents do with OpenTelemetry support for W&B Weave and Langfuse\nWhen something goes wrong with an agent in production, the first questions that pop up are “Where did the tokens go?” and “Why is this happening?”. Koog 0.4.0 comes with full OpenTelemetry support for both W&B Weave and Langfuse.\nSimply install the desired plugin on any agent and point it to your backend. You’ll be able to see the nested agentic events (nodes, tool calls, LLM requests, and system prompts), along with token and cost breakdowns for each request. In Langfuse, you can also visualize how a run fans out and converges, which is perfect for debugging complex graphs.\nW&B Weave setup:\nval agent = AIAgent(\n    ...\n) {\n    install(OpenTelemetry) {\n        addWeaveExporter(\n            weaveOtelBaseUrl = \"WEAVE_TELEMETRY_URL\",\n            weaveApiKey = \"WEAVE_API_KEY\",\n            weaveEntity = \"WEAVE_ENTITY\",\n            weaveProjectName = \"WEAVE_PROJECT_NAME\"\n        )\n    }\n}\nThis will allow you to see the traces from your agent in W&B Weave:\n\n\n\n\nLangfuse setup:\nval agent = AIAgent(\n    ...\n) {\n    install(OpenTelemetry) {\n        addLangfuseExporter(\n            langfuseUrl = \"LANGFUSE_URL\",\n            langfusePublicKey = \"LANGFUSE_PUBLIC_KEY\",\n            langfuseSecretKey = \"LANGFUSE_SECRET_KEY\"\n        )\n    }\n}\nThis allows you to see the agent traces and their graph visualisations in Langfuse:\n\n\n\n\nOnce everything is connected, head to your observability tool to inspect traces, usage, and costs.\n🧩 Drop-in Ktor integration to put Koog behind your API in minutes\nAlready have a Ktor server? Perfect! Just install Koog as a Ktor plugin, configure providers in application.conf or application.yaml, and call agents from any route. No more connecting LLM clients across modules – your routes just request an agent and are ready to go.\nNow you can configure Koog in application.yaml:\nkoog:\n  openai.apikey: \"$OPENAI_API_KEY:your-openai-api-key\"\n  anthropic.apikey: \"$ANTHROPIC_API_KEY:your-anthropic-api-key\"\n  google.apikey: \"$GOOGLE_API_KEY:your-google-api-key\"\n  openrouter.apikey: \"$OPENROUTER_API_KEY:your-openrouter-api-key\"\n  deepseek.apikey: \"$DEEPSEEK_API_KEY:your-deepseek-api-key\"\n  ollama.enabled: \"$DEBUG:false\"\nOr in code:\nfun Application.module() {\n    install(Koog) {\n        llm {\n            openAI(apiKey = \"your-openai-api-key\")\n            anthropic(apiKey = \"your-anthropic-api-key\")\n            ollama { baseUrl = \"http://localhost:11434\" }\n            google(apiKey = \"your-google-api-key\")\n            openRouter(apiKey = \"your-openrouter-api-key\")\n            deepSeek(apiKey = \"your-deepseek-api-key\")\n        }\n    }\n}\nNext, you can use aiAgent anywhere in your routes:\nrouting {\n    route(\"/ai\") {\n        post(\"/chat\") {\n            val userInput = call.receive<String>()\n            val output = aiAgent(\n                strategy = reActStrategy(),\n                model = OpenAIModels.Chat.GPT4_1,\n                input = userInput\n            )\n            call.respond(HttpStatusCode.OK, output)\n        }\n    }\n}\n🏛️ Structured output that actually holds up in production\nCalling an LLM and getting exactly the data format you need feels magical – until it stops working and the magic dries up. Koog 0.4.0 adds native structured output (supported by some LLMs) with a lot of pragmatic guardrails like retries and fixing strategies.\nWhen a model supports structured output, Koog uses it directly. Otherwise, Koog falls back to a tuned prompt and, if needed, retries with a fixing parser powered by a separate model until the payload looks exactly the way you need it to.\nDefine your schema once:\n@Serializable\n@LLMDescription(\"Weather forecast for a location\")\ndata class WeatherForecast(\n    @property:LLMDescription(\"Location name\") val location: String,\n    @property:LLMDescription(\"Temperature in Celsius\") val temperature: Int,\n    @property:LLMDescription(\"Weather conditions (e.g., sunny, cloudy, rainy)\") val conditions: String\n)\nYou decide which approach fits your use case best. Request data from the model natively when supported, and through prompts when it isn’t:\nval response = requestLLMStructured<WeatherForecast>()\nYou can add automatic fixing and examples to make it more resilient:\nval weather = requestLLMStructured<WeatherForecast>(\n    fixingParser = StructureFixingParser(\n        fixingModel = OpenAIModels.Chat.GPT4o,\n        retries = 5\n    ),\n    examples = listOf(\n        WeatherForecast(\"New York\", 22, \"cloudy\"),\n        WeatherForecast(\"Monaco\", 29, \"sunny\")\n    )\n)\n👋 Introducing the new Koog target – iOS\nKoog is now available on iOS as part of our focus on Kotlin Multiplatform. Build your agent once and ship it to iOS, Android, and JVM backends – all with the same strategy graphs, tests, and observability hooks. Note: Please use Koog version 0.4.1 to build for iOS.\n🤔 Tune how models think with GPT-5 and custom parameters\nWant your model to think harder on complex problems, or say less in chat-like flows? Version 0.4.0 adds GPT-5 support and custom LLM parameters, including settings like reasoningEffort, so you can balance quality, latency, and cost for each call.\nval params = OpenAIChatParams(\n    /* other params... */\n    reasoningEffort = ReasoningEffort.HIGH\n)\nval prompt = prompt(\"test\", params) {\n    system(\"You are a mathematician\")\n    user(\"Solve the equation: x^2 - 1 = 2x\")\n}\nopenAIClient.execute(prompt, model = OpenAIModels.Chat.GPT5)\n🔄 Fail smarter – production-grade retries for flaky calls and subgraphs\nIt’s inevitable – sometimes LLM calls time out, tools misbehave, or networks hiccup. Koog 0.4.0 introduces RetryingLLMClient, with Conservative, Production, and Aggressive presets, as well as fine-grained control when you need it:\nval baseClient = OpenAILLMClient(\"API_KEY\")\nval resilientClient = RetryingLLMClient(\n    delegate = baseClient,\n    config = RetryConfig.PRODUCTION  // or CONSERVATIVE, AGGRESSIVE, DISABLED\n)\nBecause retries work best with feedback, you can wrap any action (even part of a strategy) in subgraphWithRetry, approve or reject results programmatically, and give the LLM targeted hints on each attempt:\nsubgraphWithRetry(\n    condition = { result ->\n        if (result.isGood()) Approve\n        else Reject(feedback = \"Try again but think harder! $result looks off.\")\n    },\n    maxRetries = 5\n) {\n    /* any actions here that you want to retry */\n}\n📦 Out-of-the-box DeepSeek support \nPrefer DeepSeek models? Koog now ships with a DeepSeek client that includes ready-to-use models:\nval client = DeepSeekLLMClient(\"API_KEY\")\nclient.execute(\n    prompt = prompt(\"for-deepseek\") {\n        system(\"You are a philosopher\")\n        user(\"What is the meaning of life, the universe, and everything?\")\n    },\n    model = DeepSeekModels.DeepSeekReasoner\n)\nAs DeepSeek’s API and lineup of models continue to evolve, Koog gives you a simple and straightforward way to slot them into your agents.\n✨ Try Koog 0.4.0\nIf you’re building agents that must be observable, deployable, predictable, and truly multiplatform, Koog 0.4.0 is the right choice. Explore the docs, connect OpenTelemetry to W&B Weave or Langfuse, and drop Koog into your Ktor server to get an agent-ready backend in minutes.\n🤝 Your contributions make the difference\nWe’d like to take this opportunity to extend a huge thank-you to the entire community for contributing to the development of Koog through your feedback, issue reports, and pull requests!\nHere’s a list of this release’s top contributors:\nNathan Fallet added support for the iOS target.\nDidier Villevalois – added contextLength and maxOutputTokens to LLModel.\nSergey Kuznetsov – fixed URL generation in AzureOpenAIClientSettings.\nMicah – added the missing Document capabilities for LLModel across providers.\njonghoonpark – refined the NumberGuessingAgent example.\nAteş Görpelioğlu helped with adding tool arguments to OpenTelemetry events",
        "dc:creator": "Vadim Briliantov",
        "content": "Featuring Langfuse and W&#38;B Weave Support, Ktor Integration, Native Structured Output, iOS Target, GPT-5, and More. Koog 0.3.0 was about making agents smarter and persistent. Koog 0.4.0 is about making them observable, seamlessly deployable in your stack, and more predictable in their outputs – all while introducing support for new models and platforms. Read on [&#8230;]",
        "contentSnippet": "Featuring Langfuse and W&B Weave Support, Ktor Integration, Native Structured Output, iOS Target, GPT-5, and More. Koog 0.3.0 was about making agents smarter and persistent. Koog 0.4.0 is about making them observable, seamlessly deployable in your stack, and more predictable in their outputs – all while introducing support for new models and platforms. Read on […]",
        "guid": "https://blog.jetbrains.com/?post_type=ai&p=594576",
        "categories": [
          "news",
          "releases"
        ],
        "isoDate": "2025-08-28T09:26:51.000Z"
      },
      {
        "creator": "Mehul Harry",
        "title": "ReSharper’s New Out-of-Process Engine Cuts UI Freezes in Visual Studio by 80%",
        "link": "https://blog.jetbrains.com/dotnet/2025/08/28/resharper-s-new-out-of-process-engine-cuts-ui-freezes-in-visual-studio-by-80/",
        "pubDate": "Thu, 28 Aug 2025 07:00:00 +0000",
        "content:encodedSnippet": "Visual Studio power users love ReSharper’s deep analysis, but the cost has been the occasional UI hiccup that breaks the flow of work. In ReSharper 2025.2, analysis runs in a separate 64-bit worker out of Visual Studio’s UI process. Previously, ReSharper shared Visual Studio’s UI process, so long analyses could stall the UI thread. Now, Visual Studio keeps repainting while ReSharper crunches. \nWe tested this new approach on the Orchard Core solution. During Visual Studio launch, total UI freezes of 100 ms or longer fell from 26 s with ReSharper 2025.1.4 (in-process) to 10.1 s with ReSharper 2025.2 running out of process — a 61% reduction. The side-by-side UI-pause visualizer shows the experience during startup. Here’s how we measured it. \nTesting methods\nWe ran two measurements on the Orchard Core solution (about 223 projects). First, we used ETW MessageCheckDelay to detect UI freezes. For greater flexibility, we later switched to custom tooling that detects periods when the UI thread becomes unresponsive.\nWe then summed all UI freezes of 100 ms or longer occurring during Visual Studio launch, regardless of source.\nWe measured ReSharper 2025.1.4, ReSharper 2025.2 (in-process), ReSharper 2025.2 (out of process), and Visual Studio without any extension installed.\nStartup results – Visual Studio launch (100 ms or longer, all sources)\nThe graph below shows cumulative UI freezes of 100 ms or longer during Visual Studio startup: \n\n\n\n\nFor context, Visual Studio without ReSharper measured 6.3 s during Visual Studio startup in our lab. Deviation from our previous measurements is possible, as the tests were performed locally in different environments by different people using different methods. We are currently implementing even more optimizations for Out-of-Process mode.\nWhat changed under the hood\nMost analysis now runs out of process, so heavy work no longer blocks the Visual Studio UI thread.\nSmarter scheduling reduces contention during typing, completion, and navigation.\nCaches and indexes live in a separate process to avoid extra work inside Visual Studio.\nVisual comparison\nBelow is the side-by-side UI-pause visualizer demo, recorded in similar conditions to the previous table. It demonstrates opening and working in the Orchard Core solution on the same machine with both versions.\nLeft: ReSharper 2025.1.4 (in-process) · Right: ReSharper 2025.2 (out of process)\n\n\n\n\nThe bars at the bottom indicate intervals when the UI thread is unresponsive. A bar turns red when an interval is 100 ms or longer. During those times, typing or clicking in the IDE has no effect. At a glance, you’ll see fewer red bars on the right (out of process), indicating a smoother user experience.\nIf you’ve seen Visual Studio warn that ReSharper is slowing down your computer, Out-of-Process mode targets the root causes behind that warning, so you should now see fewer alerts.\nKnown limitations in 2025.2 (out of process)\nOut-of-Process mode still has some limitations, as it does not yet support the following functionality:\nAI-powered features\nDebugger integrations\nDPA, dotMemory, dotTrace, and dotCover integrations\nTemplate editor\nDiagramming tools\nWe’re actively working to bring these features into Out-of-Process mode, and you can follow our progress in YouTrack.\nLearn more about Out-of-Process mode and how to enable it on this page.\nWhat we’re improving next\nRight-click latency: Profiling highlighted hot spots in PsiFiles.GetPsiFiles and SqlInjectionPsiProvider.ComputeDataForFileContext. We’ve reduced the impact for 2025.2 and will continue to monitor them in real-world projects.\nMethodology and thresholds: We’ll keep validating on larger solutions and may adjust freeze thresholds as we learn more.\nTry it today\n\n\n\n\nThere are four ways to enable Out-of-Process mode in ReSharper 2025.2 or later.\nFrom the menu, go to Extensions | ReSharper | R# Out-of-Process and select Switch to Out-of-Process mode.\nFrom the menu, go to Extensions | ReSharper | Options | Environment | Products & Features and select Run ReSharper in a separate process (preview). When you click Apply, you may be prompted to restart ReSharper.\nUse the Go to action, Ctrl+Shift+A, and then simply type “Switch to Out-of-Process mode” and press Enter.\nIn the status bar (after you’ve enabled Out-of-Process mode at least once), click the R# Out-of-Process indicator and choose Switch to Out-of-Process mode.\nTo revert, you can use any of the paths above and select Switch to In-Process mode. If none of these work, you can start Visual Studio with /ReSharper.InProcess to temporarily revert to In-Process mode and save your choice in the options.\nPower user tip: Start Visual Studio with /ReSharper.OOP to launch directly in Out-of-Process mode.\nCall for feedback\nWhile we are encouraged by the results of our tests, we really want to know if the editor feels faster to you. We invite you to share frame drops, trace files, or even a quick screen recording GIF. We read every report.\nOptionally share anonymous usage statistics\nTo help us validate performance improvements at scale, you can opt in to ReSharper’s Usage Statistics program.\nOpt in: From the menu, go to Extensions | ReSharper | Options | Environment | Usage Statistics, check Participate anonymously in the Usage Statistics program, and then click Save.\nOnly aggregate, anonymous data is sent — no project names or source code. See the Options panel for details.Beyond raw speed, Out-of-Process mode helps ensure ReSharper remains a first-class bridge for Visual Studio users and a stepping-stone for anyone curious about our standalone IDE, Rider.",
        "dc:creator": "Mehul Harry",
        "content": "Visual Studio power users love ReSharper’s deep analysis, but the cost has been the occasional UI hiccup that breaks the flow of work. In ReSharper 2025.2, analysis runs in a separate 64-bit worker out of Visual Studio’s UI process. Previously, ReSharper shared Visual Studio’s UI process, so long analyses could stall the UI thread. Now, [&#8230;]",
        "contentSnippet": "Visual Studio power users love ReSharper’s deep analysis, but the cost has been the occasional UI hiccup that breaks the flow of work. In ReSharper 2025.2, analysis runs in a separate 64-bit worker out of Visual Studio’s UI process. Previously, ReSharper shared Visual Studio’s UI process, so long analyses could stall the UI thread. Now, […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=594839",
        "categories": [
          "how-tos",
          "news",
          "resharper",
          "oop",
          "out-of-process",
          "performance",
          "resharper_oop",
          "visual-studio"
        ],
        "isoDate": "2025-08-28T07:00:00.000Z"
      },
      {
        "creator": "Oleg Zinovyev",
        "title": "What’s Next for CLion: The 2025.3 Roadmap",
        "link": "https://blog.jetbrains.com/clion/2025/08/2025-3-roadmap/",
        "pubDate": "Wed, 27 Aug 2025 14:46:13 +0000",
        "content:encodedSnippet": "We’ve begun work on our next major release, 2025.3, which we plan to introduce in November. After reviewing your feedback and our strategic goals, we’ve prioritized the following:\n🚀  Transitioning to the CLion Nova language engine as the default.\n🏗️  Improvements to project formats and build tools.\n🎛️  Improvements to features for embedded development.\n🤖  Support for Junie, JetBrains’ smart coding agent.\nRead on to learn more about our planned updates.\nOur team is committed to creating an IDE that makes development smooth and productive. However, the following is only a preliminary roadmap. We can’t guarantee that all the issues and features listed below will be addressed and implemented in CLion 2025.3. Unexpected circumstances could require us to modify our plans or implementation timelines for some items.\nCLion Nova as the default engine\nThe CLion Nova language engine has been the default for new CLion users since v2024.2. Over the past year, we’ve added the most requested features and fixed critical bugs. We’re now ready to set CLion Nova as the default engine for all users in v2025.3.\nPlease note that you will still be able to use the legacy CLion Classic engine. However, we don’t plan to allocate further resources to its development. All new language-specific features will be available only in CLion Nova.\nWe’ll explain this update in more detail in an upcoming blog post.\nProject formats and build tools\nSysbuild support for nRF Connect SDK projects: In v2025.1, we introduced sysbuild support for Zephyr West projects, which works well with projects that use the vanilla Zephyr RTOS. However, the nRF Connect SDK uses a forked version of Zephyr and sysbuild as the default build tool, while CLion currently expects the default configuration to be non-sysbuild. As a result, CLion cannot read the nRF Connect SDK project information, so users cannot run or debug projects. We plan to solve this issue in v2025.3 (CPP-43380). For now, depending on the configuration, you can enter --no-sysbuild or --sysbuild in the advanced settings of your West project to run or debug an nRF Connect SDK project.\nSupport for Bazel 9: As part of our ongoing efforts to improve the Bazel plugin integration in CLion, we plan to add support for the next major version of the build tool. We recently took over the development of the Bazel for CLion plugin from Google. Our main goals are to improve the plugin’s stability and enhance the user experience.\nEmbedded development\nBundled PlatformIO: The current PlatformIO integration is provided by the corresponding plugin. In v2025.3, we plan to bundle the plugin so that you won’t need to install PlatformIO manually. We’ve already made several usability improvements to the current integration to ensure a smooth transition. These improvements include providing more information on various errors and how to fix them, enabling the import of a project using platformio.ini when no project model is available, and suggesting the reloading of a PlatformIO project when new files are added to the project root.\nImprovements to live watches: In v2025.2, we introduced the live watches feature, which allows you to monitor global variables in real time. In the next release, we plan to enhance the feature’s functionality by enabling you to view structure and peripheral registry values, export data in the CSV format, use autocompletion for variable names, and more.\nImprovements to ESP-IDF: We’re working on better integration with the ESP-IDF framework, improving it step by step. Several related updates will be introduced in v2025.3.\nDebugger\nImprovements to Qt renderers: Qt renderers, introduced earlier this year, allow you to view Qt-specific variables in a human-readable form. For the upcoming release, our focus will be on fixing some bugs that users reported (CPP-43815, CPP-44928). If you’re new to working with Qt projects in CLion, check out our documentation or this blog post from our colleagues at Qt: Developing Qt applications with CLion.\nSupport for Junie\nJunie is an AI coding agent that can serve as a full-fledged pair programmer. We’d hoped to complete the Junie integration in the previous release, but, unfortunately, it took more time than expected. We plan to complete it for the next release.\nConclusion\nThe Early Access Program is just around the corner and will give you the chance to try all the new features planned for the next major release for free. In the meantime, upgrade to CLion 2025.2 if you haven’t already done so, and let us know what you think!\nDOWNLOAD CLION 2025.2",
        "dc:creator": "Oleg Zinovyev",
        "content": "We’ve begun work on our next major release, 2025.3, which we plan to introduce in November. After reviewing your feedback and our strategic goals, we’ve prioritized the following: 🚀 Transitioning to the CLion Nova language engine as the default. 🏗️ Improvements to project formats and build tools. 🎛️ Improvements to features for embedded development. 🤖 [&#8230;]",
        "contentSnippet": "We’ve begun work on our next major release, 2025.3, which we plan to introduce in November. After reviewing your feedback and our strategic goals, we’ve prioritized the following: 🚀 Transitioning to the CLion Nova language engine as the default. 🏗️ Improvements to project formats and build tools. 🎛️ Improvements to features for embedded development. 🤖 […]",
        "guid": "https://blog.jetbrains.com/?post_type=clion&p=595211",
        "categories": [
          "news",
          "roadmap",
          "clionnova",
          "esp32",
          "junie",
          "platformio",
          "qt",
          "sysbuild",
          "zephyr-west"
        ],
        "isoDate": "2025-08-27T14:46:13.000Z"
      },
      {
        "creator": "Alyona Chernyaeva",
        "title": "Exploring Data Science With Kotlin: A Powerlifting Case Study",
        "link": "https://blog.jetbrains.com/kotlin/2025/08/exploring-data-science-with-kotlin-a-powerlifting-case-study/",
        "pubDate": "Wed, 27 Aug 2025 10:18:33 +0000",
        "content:encodedSnippet": "This is a guest post from Adele Carpenter. Adele is a Software Engineer and Consultant at Trifork Amsterdam, where she works on educational systems in the Kotlin/Java/Spring ecosystem and advises customers on their projects.\nTL;DR\nThis blog post uses a dataset from the sport of powerlifting to get you up and running with Kotlin Notebooks, DataFrame, and Kandy, using a PostgreSQL data source for your analysis. It covers:\nData science basics\nConnecting an external data source to your Kotlin Notebook\nAccessing and manipulating the data with DataFrame\nPlotting your findings with the Kandy Library\nThe sample project contains everything you need to create your first plot!\nHave you ever wanted to play around with a dataset, but the thought of setting up a python development environment seemed like too much of a hassle?\nOr was that only me?\nIn my work, I sit firmly in the Kotlin/JVM ecosystem. And I like it here. I also have a hobby that I am really passionate about: powerlifting. The sport where we wear funny little jumpsuits and try to lift as much weight as we can for one repetition in the squat, bench press, and deadlift.\nPowerlifting is somewhat of a niche sport; however, it is growing rapidly and has a strong, supportive community. It is also a data-driven sport that has birthed an open-source dataset containing the results of powerlifting competitions held all over the world. The full dataset is over 3.3 million rows and counting. I was really interested to see what insights lay inside, but I had never written a line of Python before, and didn’t feel like dumping 3.3 million rows in Excel. It’s also not a very elegant solution for a software engineer.\nWouldn’t it be great to use a familiar language and IDE while I’m learning data science?\nEnter Kotlin Notebook.\nKotlin for data science is nothing new: the JetBrains team has been doing great work in this area for some time, and the ecosystem just keeps getting better. You have all the building blocks you need to go from questions to answers in a very short time.\nKotlin Notebook is a plugin you can add to an IDE you’re already familiar with, IntelliJ IDEA, and can have you inspecting your dataset within minutes. The dataset does not have to be limited to niche hobbies. For example, has “the business” ever asked you a question for which you knew you had the data, but you didn’t know how to turn it into actionable information? Like the rate of adoption of a new feature you’d recently launched?\nGetting started\nTo get started, just download the Kotlin Notebook plugin from JetBrains Marketplace.\nThe next step is to connect your data source. A lot of examples you find online will have you import a .csv and manipulate it in memory as a dataframe. This is a fine approach for smaller datasets (up to 100,000 rows), but for larger datasets, it can end up being slow and impractical.\nThe Kotlin DataFrame library provides several convenient functions for accessing your datasource and manipulating the results as a dataframe. A dataframe is a tabular data structure consisting of rows and columns, similar to a spreadsheet or an SQL table. It is a common and powerful abstraction used in data science.\nThe rest of this article is going to assume that you’re following along with the sample project. However, if you have a database you’d like to explore, you can of course connect it up and try to draw out your own insights!\nThe sample project looks at participation in the sport of powerlifting in 2023.\nOpen up the sample project and take a look at my-first-notebook.ipynb.\nFirst, we import the Kotlin DataFrame and Kandy libraries.\nkotlin notebook\n\n%use kandy\n\n%use dataframe\nKandy is an open-source plotting library for Kotlin based on the lets-plot visualization library. Data is nice, but seeing is believing. Kandy helps us turn rows and columns full of numbers into actionable insights.\nBut before we can get plotting, we need data. We connect to the containerized Postgres database using a URL, username, and password. Then, we can fetch the contents of the powerlifting_data table using readSqlTable.\nkotlin notebook\n\nval dbConfig = DbConnectionConfig(URL, USER_NAME, PASSWORD)\n\nval data = DataFrame.readSqlTable(dbConfig, \"powerlifting_data\")\nImporting the entire table defeats the purpose of creating a database, so I would not recommend making this your standard workflow (especially if you have more than 100,000 rows). But for today’s exploratory purposes, it’s a fine place to start. Later, I’ll show you how to use SQL queries and dataframes together to help you work more efficiently. \nUnderstanding the dataset\nIn order to do data science well, you need to understand your dataset. Taking the time to get to know your dataset helps you avoid making incorrect assumptions and drawing (costly) incorrect conclusions. I cannot stress enough the importance of this step! This is why I started my data science journey with powerlifting. It’s a domain I have experienced firsthand, and it is much more than a dataset to me. Let me show you what I mean. \nWe can use the describe function from Kotlin Dataframe on the fetched data.\nkotlin notebook\n\ndata.describe()\n\n\n\n\nThe describe() function gives us some essential information about our powerlifting dataset. The column names are listed on the left, in the name column, alongside some summary statistics. Using the output, we can say:\nThe dataset has 178,972 rows.\nOf those, 104,960 are unique names (lifters).\nName, sex, event, equipment, place, federation, date, country, and meetname are mandatory fields.\nAll other fields are nullable (potentially empty).\nThe most common event is SBD and with minimal equipment (aka Raw).\nThere are also some other curious things that may not be clear if you do not understand powerlifting:\n1. The minimums for the squat, bench, and deadlift are all negative. This is how a missed lift is represented in the dataset. A missed lift is one that was attempted during the competition but was not completed successfully; therefore, it does not contribute to the final score or total for the lifter. This convention makes the mean and median values from the describe() function largely useless.\n2. The entries squat4kg, bench4kg, and deadlift4kg have a large number of null values. Fourth attempts are rare and do not count toward the TotalKg. They are used for recording single-lift records (e.g. deadlift world record) and can only be taken under special circumstances. For most purposes, you can leave these values out of your analyses.\nAnswering your first research question \nIn a powerlifting meet, each competitor attempts three lifts: squat, bench press, and deadlift. They get three attempts per lift, for a total of nine attempts. The heaviest successful attempt in each lift is added together for their total score.\nPrevailing powerlifting wisdom tells us that completing all lifts in a powerlifting meet to the required standard, aka going 9/9 (“nine for nine”), is the best way to have a successful meet. Here, success is defined not just in terms of maximizing your chances of a spot on the podium, but also for the mental benefits of achieving what you came for.\nSo, as a powerlifter myself, I was really curious to know:\nIs it really better to go nine for nine when chasing a win? Or is that YOLO deadlift actually a good idea?\nIn order to answer this question, we can start by plotting a simple distribution of the number of winners at each number of successful attempts. That’s what we’ll be working through in the rest of this post.\nCollecting only the data you need with SQL\nAs already mentioned, loading the whole database into memory to perform your analysis is next to impossible if your dataset is very large. So why not use SQL to only load the data that you need?\nIn order to answer the research question, I need to find the lifters who got first place in a meet, and then the number of successful lifts they made. Seems simple enough, right?\nAs data science practitioners, there is no teacher or answer book to tell us whether we are right or wrong. We need to combine our knowledge of the domain with sound data science practices and be able to defend any conclusions that we make.\nIn this case, from my experience in powerlifting, I know that\nIn some competitions, there is only one lifter per weight class, which means they will be awarded first place no matter how poorly they do. For this reason, setting a minimum number of entrants per weight class makes sense.\nIn the dataset, competitions are unique by meetname and date.\nFor a specific competition, a class is unique not just by weightclass, but also by division (e.g. juniors, open, and masters).\nSo that leads to the following query. You will see that I’ve filtered out null results in the query, but of course, you could do that directly in the dataframe using the filter function in the dataframe library.\nYou can see that I’ve written a function to return the string query. Of course, you can just write the string directly, but I like to create a function so that the query is easily modifiable with placeholders. For example, to look at a particular year/s or to quickly iterate on the number of entries (lifters) in a weight class. The ability to quickly iterate, learn, and discover is a key component of a successful data science workflow.\nkotlin notebook\n\nfun queryByTimePeriodAndEntries(startYear: String, endYear: String, entries: Int) = \n    \"\"\"\nSELECT\n    pd.*\nFROM\n    powerlifting_data pd\n        JOIN\n    (\n        SELECT\n            meet_name,\n            date,\n            weight_class_kg,\n            division,\n            COUNT(*) AS lifter_count\n        FROM\n            powerlifting_data\n        WHERE\n            date BETWEEN '$startYear-01-01' AND '$endYear-12-31'\n        GROUP BY\n            meet_name, date, weight_class_kg, division\n        HAVING\n            COUNT(*) >= $entries\n    ) AS qualified_classes\n    ON me.meet_name = qualified_classes.meet_name\n        AND me.date = qualified_classes.date\n        AND me.weight_class_kg = qualified_classes.weight_class_kg\n        AND me.division = qualified_classes.division\nWHERE\nme.event = 'SBD'\n  AND me.date BETWEEN '$startYear-01-01' AND '$endYear-12-31'\n  AND me.squat1_kg IS NOT NULL\n  AND me.squat2_kg IS NOT NULL\n  AND me.squat3_kg IS NOT NULL\n  AND me.bench1_kg IS NOT NULL\n  AND me.bench2_kg IS NOT NULL\n  AND me.bench3_kg IS NOT NULL\n  AND me.deadlift1_kg IS NOT NULL\n  AND me.deadlift2_kg IS NOT NULL\n  AND me.deadlift3_kg IS NOT NULL\n  AND me.best3_bench_kg IS NOT NULL\n  AND me.best3_squat_kg IS NOT NULL\n  AND me.best3_deadlift_kg IS NOT NULL\n  AND place != 'NS'; -- no shows are excluded\n    \"\"\"\n\n\n\n\nTo run our query, we can use the readSqlQuery method provided by the DataFrame library. In my experience, I found it a little fussy with white space, so I prefer to create a helper function, which you can find in util.Helpers. The helper function is called fetchResults. Such a function is likely to be used a lot, across multiple analyses. Further, since it simply executes a string query, it also doesn’t change very much. This makes it a good candidate to put into an external Helpers class that we can import into the notebook. Externalising functionality like this means we can keep the boilerplate out of our notebook by defining it once and importing it. \nIf the Helpers class didn’t import, make sure you go to the settings for this notebook and click on Select Modules to Use in the Notebook. Once you change this setting, you will need to restart your Kotlin Notebook Kernel. Then, util.Helpers will be available to import.\n\n\n\n\nSo to start our analysis, we build the query by specifying the startYear, endYear, and the minimum number of entries (lifters) per event.\nThen, we use the helper function to open the database connection, run the query, and then close the connection.\nkotlin notebook\n\nimport util.Helpers\n\nval helpers = Helpers()\n\nval query = queryByTimePeriodAndEntries(\"2023\", \"2023\", 3)\n\nval data = helpers.fetchResults(query)\nNow that we have the results, we can print the first 10 rows using the head function. This is a good habit to get into so you can check that your results make sense as you go and can identify any errors or curiosities early on. We could also run the describe function again to confirm the number of rows, and that we correctly removed null values for our nine lifts (squat1kg, squat2kg, squat3kg, bench1kg, etc.).\nkotlin notebook\n\ndata.head(10)\n\ndata.describe()\nWith this filtered raw data, we can use the DataFrame library to collect our results into a frame of two columns: successfulLifts and count.\nIn order to take advantage of Kotlin’s strong typing as we process our data using Kotlin DataFrame, we can define the schema LifterData with the @DataSchema annotation.\nSo we can define our data as follows:\nkotlin notebook\n\nimport org.jetbrains.kotlinx.dataframe.annotations.*\n\n@DataSchema\n\ninterface LifterData {\n\n    val place: String\n\n    val squat1kg: Double\n\n    val squat2kg: Double\n\n    val squat3kg: Double\n\n    val bench1kg: Double\n\n    val bench2kg: Double\n\n    val bench3kg: Double\n\n    val deadlift1kg: Double\n\n    val deadlift2kg: Double\n\n    val deadlift3kg: Double\n\n}\n\nval successfulLifts = column<Int>(\"successfulLifts\")\n\nval count = column<Int>(\"count\")\n\nval columns = listOf(\n\n    data.squat1kg, data.squat2kg, data.squat3kg,\n\n    data.bench1kg, data.bench2kg, data.bench3kg,\n\n    data.deadlift1kg, data.deadlift2kg, data.deadlift3kg\n\n)\nAs discussed earlier, a positive value for a lift indicates that it was successful. If it is negative, the lift was attempted, but it was ruled a “no lift” and not counted towards the total or final score for the lifter.\nSo using this knowledge, and the data structure we have defined, we can create a function addNumberOfSuccessfulLifts to modify our raw data returned from our SQL query.\nkotlin notebook\n\nfun addNumberOfSuccessfulLifts(data: DataFrame<LifterData>, firstPlaceOnly: Boolean = true): AnyFrame {\n\n    val df = if (firstPlaceOnly) data.filter { it.place == \"1\" } else data\n\n    return df.add(successfulLifts) {\n\n        columns.count { value -> it[value] > 0 }\n\n    }\n\n        .groupBy { it[successfulLifts] }\n\n        .aggregate {\n\n            count() into count\n\n        }\n\n        .drop { it[successfulLifts] in listOf(0, 1, 2) }\n\n        .sortBy(successfulLifts)\n\n}\nHere’s a simple breakdown of what addNumberOfSuccessfulLifts does:\n1. Counts successful lift attempts:\n   – It looks at nine columns: squat1kg, squat2kg, squat3kg, bench1kg, etc.\n   – If a value is greater than 0, it’s considered a successful attempt.\n   – It counts the number of successful attempts for each row and stores it in a new column called successfulLifts.\n2. Groups the data by the number of successfulLifts.\n3. Uses the aggregate function to count how many rows fall into each successfulLifts group (creating a count column).\n4. Removes any anomalous rows where lifters have 0, 1, or 2 successful lifts.\n5. Sorts the remaining data by successfulLifts in ascending order.\nTip!\nTo call addNumberOfSuccessfulLifts without typing errors, we need to cast data to the data schema LifterData we defined above.\nkotlin notebook\n\nval winnersDataFrame = addNumberOfSuccessfulLifts(data.cast<LifterData>())\nAfter calling addNumberOfSuccessfulLifts, we can confirm that it does as intended, by printing the results and inspecting them. The head function is not necessary here, as the dataframe is small, but since it’s good practice, you can make a habit of using it. If you ask for more rows than exist in the dataframe, then it will simply return the entire dataframe.\nkotlin notebook\n\nwinnersDataFrame // OR\n\nwinnersDataFrame.head(10)\n\n\n\n\nPlotting your results with Kandy\nNow the fun can begin… plotting our results with Kandy 🥳\nKandy is a declarative plotting library for Kotlin that allows for easy and intuitive data visualization. Lucky for us, Kandy and DataFrame are a match made in heaven.\nKandy uses code blocks to define plot elements and supports custom styles, themes, and layout adjustments.\nLet’s start with a simple bar chart to visualize the distribution of winners at each number of successful lift attempts. All we need to do is specify which column to map to the x-axis and which to map to the y-axis!\nkotlin notebook\n\nplot(winnersDataFrame) {\n\n    bars {\n\n        x(successfulLifts) \n\n        y(count)\n\n    }\n\n}\nWhich gives us:\n\n\n\n\nPlotting in this simple fashion will make use of default formatting and will use axis labels that are the same as the dataframe accessors. This is not ideal, so we can customize it a bit more. And while it looks like a lot of code, its declarative nature makes it easy to follow.\nkotlin notebook\n\nkandyConfig.themeApplied = false\n\nplot(winnersDataFrame) {\n\n    bars {\n\n        x(successfulLifts)\n\n        y(count) {\n\n            axis.name = \"Number of Winners\"\n\n            axis {\n\n                breaks(listOf(500,1000,1500,2000,2500,3000,3500,4000,4500,5000), format = \"d\")\n\n            }\n\n        }\n\n        fillColor = Color.hex(\"#fec92e\")\n\n        borderLine {\n\n            color = Color.hex(\"#777777\")\n\n            width = 0.5\n\n        }\n\n    }\n\n    layout {\n\n        title = \"Distribution of Winners by Successful Attempts\"\n\n        caption = \"Data: Open powerlifting meets 2023\"\n\n        size = 600 to 300 // default is 600 to 400\n\n        xAxisLabel = \"Successful Attempts\" // alternative to axis.name used for the y axis\n\n        style {\n\n            global {\n\n                text {\n\n                    fontFamily = FontFamily.custom(\"Helvetica Neue\")\n\n                }\n\n                plotCanvas {\n\n                    title {\n\n                        hJust = 0.5 // center the title\n\n                        margin = Margin(10.0)\n\n                        fontSize = 17.0\n\n                    }\n\n                    caption {\n\n                        hJust = 1.0 // align right\n\n                        margin = Margin(10.0, 0.0, 0.0, 0.0)\n\n                    }\n\n                    margin = Margin(0.0, 30.0, 0.0, 5.0)\n\n                }\n\n            }\n\n        }\n\n    }\n\n}.save(\"distribution-of-winners-custom-formatting.svg\")\nAs you can see, we have added a title and axis labels, changed the font, centered the title, and set some margins. We also set custom axis intervals, or breaks at multiples of 500.\nTip! \nKotlin notebooks will apply your chart formatting on top of your IDE theme. So to see what your chart will look like when exported with the .save() function, you can set kandyConfig.themeApplied = false.\nAnd so with these small changes applied, our chart now looks like this:\n\n\n\n\nLooking at this chart, it may be tempting to conclude that actually going 8/9 is the superior strategy in a powerlifting meet, since there are the most winners in this group. This stumped me for a few minutes as well until I realized that lifters who go nine for nine are a special breed and are probably just simply outnumbered. With this in mind, let’s do the visualization again to answer the question:\nOut of all lifters that achieve X number of successful attempts, what percentage of those get first place?\nYou may have already spotted the firstPlaceOnly boolean in the addNumberOfSuccessfulLifts function. By default, it is set to true. Now we can call the function again on our dataframe with firstPlaceOnly set to false, so that we get the distribution of successful attempts for all lifters.\nkotlin notebook\n\nval allLiftersDataFrame = addNumberOfSuccessfulLifts(data, false)\nNow we merge the two dataframes winnersDataFrame and allLiftersDataFrame into a new dataframe dfRatioWinners and calculate the proportion of winners at each number of successful attempts.\nkotlin notebook\n\nval dfRatioWinners =\n\n    dataFrameOf(winnersDataFrame.rename(count).into(winners).columns() + allLiftersDataFrame.select(count).rename(count).into(allLifters).columns())\n\n        .add(ratioWinners) {\n\n            (it[winners].toDouble() / it[allLifters].toDouble()) * 100.0\n\n        }\nHere’s what the code does:\n– Renames the count column in the winnersDataFrame to winners.\n– Selects and renames count in the allLiftersDataFrame to allLifters. The select is important as otherwise you are attempting to add the column successfulLifts into your new dataframe twice, which will throw a runtime error.\n– Combines both columns into the new dataframe.\n– Adds a new column ratioWinners. \n– Calculates winners as a percentage of alllifters. They are each cast to a double so that the division of Int is not rounded to zero before being multiplied by 100 (don’t ask me how long it took me to spot this bug the first time 😉).\nIf we print the resulting dataframe, we get:\nkotlin notebook\n\ndfRatioWinners\n\n\n\n\nPlotting this with Kandy allows us to identify any trend a little easier. You can see this time I’ve assigned the plot to a variable. I prefer this as it provides a little more flexibility in saving the plot or making use of multiplots such as plotBunch (more on this later).\nkotlin notebook\n\nval plotRatioWinners = plot(dfRatioWinners) {\n\n    bars {\n\n        x(successfulLifts) \n\n        y(ratioWinners) {\n\n            axis.name = \"Percentage\"\n\n            axis {\n\n                breaks(listOf(5,10,15,20, 25), format = \"{.0f}%\")\n\n            }\n\n        }\n\n        fillColor = Color.hex(\"#fec92e\")\n\n        borderLine {\n\n            color = Color.hex(\"#777777\")\n\n            width = 0.5\n\n        }\n\n    }\n\n    layout {\n\n        title = \"Percentage of First Places by Successful Lifts\"\n\n        subtitle = \"At least 3 lifters in weight class\"\n\n        caption = \"Data: Open powerlifting meets 2023\"\n\n        size = 600 to 300\n\n        xAxisLabel = \"Successful Attempts\"\n\n        style {\n\n            global {\n\n                text {\n\n                    fontFamily = FontFamily.custom(\"Helvetica Neue\")\n\n                }\n\n                plotCanvas {\n\n                    title {\n\n                        hJust = 0.5\n\n                        margin = Margin(10.0)\n\n                        fontSize = 14.0\n\n                    }\n\n                    subtitle {\n\n                        hJust = 0.5\n\n                        margin = Margin(5.0)\n\n                        fontSize = 11.0\n\n                    }\n\n                    caption {\n\n                        hJust = 1.0\n\n                        margin = Margin(10.0, 0.0, 0.0, 0.0)\n\n                    }\n\n                    margin = Margin(5.0, 30.0, 20.0, 5.0)\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n\nplotRatioWinners\n\n\n\n\nNow that we have removed the bias due to different group sizes, the story is now a little clearer and lends support to the hypothesis that going 9/9 increases your chances of winning.\nAlthough there were far more winners in 2023 who went 8/9 over 9/9, when we look at the percentage of lifters who went 9/9 and who won, we see that the rate of winning is 26.5% in the 9/9 group compared to 25.8% in the 8/9 group.\nWe can now create a multiplot to make a comparison of the two charts a little easier.\nComparing multiple plots with `plotBunch`\nTo compare both charts, you can use plotBunch. plotBunch is really handy as you can specify exactly how you want your charts arranged.\nkotlin notebook\n\nplotBunch {\n\n    add(plotWinners, 0, 0, 600, 300) // top x position, top y position, width, height\n\n    add(plotRatioWinners, 0, 300, 600, 300) // top y position set to height of chart on top (300)\n\n}\n\n\n\n\nAnswering the research question\nWith this simple analysis, we managed to show that there is indeed a higher rate of winning in the 9/9 group.\nSo, is this it? Does this mean we can say for certain that going 9/9 is always better? Not quite. We can still improve our analysis by:\nTrying to replicate this finding over a longer time, e.g. five or ten years.\nTrying to see if this finding holds for five or ten competitors per weight class.\nTrying to find if this holds at the elite level (elite level can be inferred by filtering on the value in the federation column. For example, if the federation is IPF, then these are international competitions).\nData science is as much about storytelling as it is about data. Call me old-fashioned, but what we’re calling AI in 2025 is really just supercharged data science. The models and methods driving the development of LLMs have their foundation in data science.\nThis is why it’s important to be critical of these models and the stories that they’re telling you. Ask any seasoned data scientist, and they will tell you just how easy it is to make a mistake and draw an incorrect conclusion.\nJust because the tools exist and are easy to use doesn’t mean that they are always going to give you the right answer.\nThe way that we can guard against costly mistakes is not just a sound understanding of data science basics, but also by understanding the domain in which we are operating. \nData science mindset\nEarlier, I mentioned the importance of having a quick and iterative workflow. The reason for this is so that we can run multiple simulations quickly, test assumptions, and get feedback. Doing this helps us build a deep and intimate knowledge of our dataset.\nWhen it comes to data science, iterating quickly is of more importance than your code being production-ready. It’s okay to “cheat” a little and write code you’re maybe a little bit ashamed of. If it helps you iterate quickly, then being a little bit ashamed is a trade-off worth making.\nKotlin Notebook, Kotlin DataFrame, and Kandy provide a nice balance here. They work seamlessly together to allow us to balance discovery with features we enjoy as backend developers, like type-checking and code completion. Further, by working in a familiar development environment such as IntelliJ IDEA and connecting to an external data source, we can start to interact with our data right away. Learning and discovering within minutes.\nSo what are you waiting for? What is something you are curious about? Is there a dataset for it? If so, you already have the tools to start discovering! 💪\nWhere to from here?\nIf you haven’t already, clone the sample repo. A bonus analysis can be found at the bottom of my-first-research-question.ipynb.\nInspired to investigate a topic of your own? Find a dataset about a topic you care about, Kaggle is a great place to start. No matter your chosen topic, remember to stay curious and iterate quickly!\nApply this in your day job. What are you or “the business” curious about? Connect an existing SQL data source and see what insights can be found.\nUse the sample repo as a source of inspiration for your analysis and let me know what you find. You can find me on Bluesky.\nAbout the author\nAdele Carpenter\nAdele Carpenter is a Software Engineer and Consultant at Trifork Amsterdam, where she works on systems for the educational sector. Most of her work day is spent in the Kotlin/Java/Spring ecosystem, although increasingly she plays a pivotal role as trusted advisor to Trifork’s customers.\nAdele is an experienced international speaker, having spoken at multiple editions of NDC, GOTO, Devoxx, and JavaZone. As a speaker, she uses her exposure to real-world customer projects, experiences outside of tech, and passion for story-telling to distill complex ideas into their essential parts. All with an air of good humor.\nWhen she’s not at her computer or on stage, you can find her in the gym pumping some serious iron as she pursues powerlifting.",
        "dc:creator": "Alyona Chernyaeva",
        "content": "This is a guest post from Adele Carpenter. Adele is a Software Engineer and Consultant at Trifork Amsterdam, where she works on educational systems in the Kotlin/Java/Spring ecosystem and advises customers on their projects. TL;DR This blog post uses a dataset from the sport of powerlifting to get you up and running with Kotlin Notebooks, [&#8230;]",
        "contentSnippet": "This is a guest post from Adele Carpenter. Adele is a Software Engineer and Consultant at Trifork Amsterdam, where she works on educational systems in the Kotlin/Java/Spring ecosystem and advises customers on their projects. TL;DR This blog post uses a dataset from the sport of powerlifting to get you up and running with Kotlin Notebooks, […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=593546",
        "isoDate": "2025-08-27T10:18:33.000Z"
      },
      {
        "creator": "Alena Gupaisova",
        "title": "Ready for the Best School Year Ever? Join Our STEM Clubs, Camps, and Competitions",
        "link": "https://blog.jetbrains.com/education/2025/08/27/new-school-year-2025-2026/",
        "pubDate": "Wed, 27 Aug 2025 07:45:19 +0000",
        "content:encodedSnippet": "The start of a new school year brings new chances to learn, grow, and geek out on the stuff you love. If you’re into math, coding, or AI, we’ve got you covered with fun and challenging activities. \nTable of Contents\n\nYouth Clubs\nMath Club\nAI Club\nCoding Club\n\nYouth Coding Challenge competition\nACTS camps\nACTS online\nACTS 2026.1\n\n\nYouth Clubs\nJoin one (or more) of our free online clubs to sharpen your skills, prep for olympiads, or just explore what you love with peers from around the world. Weekly sessions, expert instructors, and a global community await.\nMath Club\nThis is an opportunity to build your mathematical foundations so you can solve programming problems more effectively. \nYou get 10–15 progressively challenging problems to solve each week, plus a 90-minute live session on Saturdays. \nWith two difficulty levels to choose from, you can find content that suits your individual needs. \nInstructors:\n\nOlga Telesheva has over 15 years of experience teaching mathematics, including several years specializing in olympiad mathematics. \nFedor Bakharev holds a PhD in mathematics and is actively engaged in mathematical physics research, particularly in advancing the spectral theory of differential operators. \nTop performers will be awarded 5 points for their entrance test for the Computer Science and Artificial Intelligence BSc program at Neapolis University Pafos, which offers full JetBrains Foundation Scholarships. \nJoin the Math Club\n                                                    \nAI Club\nDive into AI: Learn the basics or even take a swing at reaching an olympiad level (like IOAI).\nParticipate in live sessions every Wednesday, and complete homework assignments to keep building your skills through the week.\nInstructor: \n\nAlex Avdiushenko has a PhD in math modeling and is an analyst on the JetBrains Education and Research team.\nJoin the AI Club\n                                                    \nCoding Club\nThis is a perfect opportunity for those with some experience in competitive programming who want to master their problem-solving skills.\nIt consists of a weekly mashup of problems from previous Codeforces contests, curated by the instructor. \nInstructor: \n\nPavel Mavrin is a 2004 ICPC World Champion, 2002 IOI Silver Medalist, and instructor at JetBrains Academy.\nJoin the Coding Club\n                                                    \nYouth Coding Challenge competition\nGet ready for the JetBrains Youth Coding Challenge, the competition for young coders! This year, it will be split into two parts: a coding competition in November 2025 and a math competition in early 2026.\n\n\n\n\nJust as you’d expect, the Youth Coding Challenge is a tough contest with participants from all over the world. But this time, winning comes with an even bigger prize: an invitation to the Algorithm and Code Training School camps, which will take place both online and in Romania.\nTwo leagues: Junior (ages 13–15) and Senior (ages 16–19)\nNovember 2, 9:00 am – 12:00 pm UTC\nRegister now!\n                                                    \n\n\n\n\nACTS camps\nThis season, we’re hosting not one, but two Algorithm and Code Training School camps: one online and one in-person in Romania!\nACTS online\nThis four-day online intensive camp is designed for school students aged 13–-19 who want to improve their skills in competitive programming.\nWhen: January 16–20, 2026\nWhere: Online\nIdeal for: Students looking to improve their knowledge and skills in key competitive programming topics and boost their performance in national and international competitions. \nWho’s eligible: Secondary school students aged 13–19\nHow to get an invitation: Participate in the Youth Coding Challenge competition and show your best.\nLearn more!\n                                                    \nACTS 2026.1\nWhen: January 24 – February 3, 2026\nWhere: Romania, the exact venue will be announced later.\nIdeal for: Students with a track record in coding competitions on the national level and olympiads who aim to excel internationally.\nWho’s eligible: Secondary school students aged 16–19, though country restrictions may apply. \nNumber of spots: Up to 60.\nCosts: The camp fee is EUR 100 and will cover meals and accommodation, while participants will be responsible for travel costs.\nHow to get an invitation: Participate in the Youth Coding Challenge competition and be among the top participants.\nMore opportunities: If you perform well at the camp, you may get fast-tracked to an interview for a JetBrains Foundation Scholarship for the Computer Science and Artificial Intelligence BSc program at Neapolis University Pafos and the Software, Data and Technology BSc program at Constructor University Bremen.\nLearn more!",
        "dc:creator": "Alena Gupaisova",
        "content": "The start of a new school year brings new chances to learn, grow, and geek out on the stuff you love. If you&#8217;re into math, coding, or AI, we’ve got you covered with fun and challenging activities.&#160; Youth Clubs Join one (or more) of our free online clubs to sharpen your skills, prep for olympiads, [&#8230;]",
        "contentSnippet": "The start of a new school year brings new chances to learn, grow, and geek out on the stuff you love. If you’re into math, coding, or AI, we’ve got you covered with fun and challenging activities.  Youth Clubs Join one (or more) of our free online clubs to sharpen your skills, prep for olympiads, […]",
        "guid": "https://blog.jetbrains.com/?post_type=education&p=594890",
        "categories": [
          "jetbrains-academy",
          "offline-programs",
          "csai",
          "sdt"
        ],
        "isoDate": "2025-08-27T07:45:19.000Z"
      },
      {
        "creator": "Ksenia Shneyveys",
        "title": "How Kotlin Notebook Helps You Teach Programming",
        "link": "https://blog.jetbrains.com/kotlin/2025/08/how-kotlin-notebook-helps-teach-programming/",
        "pubDate": "Tue, 26 Aug 2025 19:21:30 +0000",
        "content:encodedSnippet": "Kotlin Notebook is a great tool for educators who want to teach programming in a more hands-on way. It lets you combine runnable code, Markdown textual explanations, and visualizations in one interactive environment. There’s no need to switch between multiple windows with slides, live demos, and IDEs during lectures. You can use a single notebook to write, explain, and run Kotlin code – all in one place.\nWe spoke with Anastasiia Birillo, the Head of the Education Research Group at JetBrains and former Kotlin lecturer at Constructor University in Bremen, and Kotlin Notebook Team Lead Ilya Muradyan to see how the notebooks are actually used in classes.\nAnastasiia has made her course notebooks publicly available. Check out the full notebook directory. For comparison, see the ‘Programming in Kotlin’ public materials – a slide-based course format.\nKotlin notebooks rely on the Kotlin Notebook plugin, which is bundled and enabled in IntelliJ IDEA by default, making setup simple.\nGet started with Kotlin Notebook\n         \nReal classroom use\nIn her course at Constructor University, Anastasiia used notebooks to teach programming in Kotlin. Each topic was built around a structured notebook with organized chapters consisting of Kotlin code cells with immediate outputs and explanations written in Markdown. Students watched her walk through the material live and had a copy of the notebook to rerun everything on their own.\n“I wanted students to see the whole idea, not just disconnected snippets. Kotlin notebooks made that possible. It worked really well for the interactive format of lectures with examples, prototypes, and concept exploration – they complemented IntelliJ IDEA for larger projects and practice.”\n\n            \nAnastasiia Birillo\n                                                                Head of the Education Research Group at JetBrains and former Kotlin lecturer at Constructor University in Bremen\n                                    \nExplore real teaching notebooks used at Constructor University. Here are a few shared by Anastasia:\nCollections\nObject-Oriented Programming\nGenerics\nWhy teach with notebooks\nIncremental execution\nKotlin notebooks support cell-based execution, allowing you to show language constructs and code snippets in an isolated way, debugging, testing, and rerunning chunks of code without restarting your whole script. This structure makes them ideal for live demos, debugging, or step-by-step teaching and live walk-throughs.\n“Kotlin notebooks gave structure to my lectures,” Anastasiia says. “Students could focus on the concepts instead of reading whole code snippets.”\nMarkdown + code\nNotebooks combine different types of data in a single interactive space. Want to mix runnable code snippets with explanations and visualizations? Kotlin Notebook helps bring programming concepts to life!\nEasy setup and sharing\nEverything can be easily launched in preset environments. This is especially useful for online classes, where students engage with notebooks shared with them via GitHub with minimal tech overhead. You can also easily share your work between other clients supporting notebooks – see the README for more details. \nTry it yourself: Sample notebooks\nKotlin Notebook is an incredibly effective tool for explaining code and exploring concepts in a structured, runnable way. \n“Thousands of developers already use notebooks for their everyday tasks. We think they address educators’ needs pretty well. Give the notebooks a try and share your feedback with us.”\n\n            \nIlya Muradyan\n                                                                Kotlin Notebook Team Lead\n                                    \nIf you teach Kotlin, run programming workshops, or just want a better way to demo code, give Kotlin notebooks a try. They offer fast setup, more focused lessons, runnable lectures, and support for code, text, and visuals in one file. \nTry Kotlin Notebook now\n         \nHave you used Kotlin Notebook in your classroom or project? Let us know at education@kotlinlang.org. We’d love to hear how you are using it!",
        "dc:creator": "Ksenia Shneyveys",
        "content": "Kotlin Notebook is a great tool for educators who want to teach programming in a more hands-on way. It lets you combine runnable code, Markdown textual explanations, and visualizations in one interactive environment. There’s no need to switch between multiple windows with slides, live demos, and IDEs during lectures. You can use a single notebook [&#8230;]",
        "contentSnippet": "Kotlin Notebook is a great tool for educators who want to teach programming in a more hands-on way. It lets you combine runnable code, Markdown textual explanations, and visualizations in one interactive environment. There’s no need to switch between multiple windows with slides, live demos, and IDEs during lectures. You can use a single notebook […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=594750",
        "categories": [
          "news",
          "education",
          "education-research",
          "kotlin-notebook"
        ],
        "isoDate": "2025-08-26T19:21:30.000Z"
      },
      {
        "creator": "Olga Bedrina",
        "title": "How to Build a CI/CD Pipeline for iOS Projects",
        "link": "https://blog.jetbrains.com/teamcity/2025/08/cicd-for-ios/",
        "pubDate": "Tue, 26 Aug 2025 15:52:42 +0000",
        "content:encodedSnippet": "This article was brought to you by Kumar Harsh, draft.dev.\nDeveloping and releasing iOS applications involves navigating a complex web of code signing, provisioning profiles, multiple iOS versions, and stringent App Store guidelines/requirements. \nWithout an automated continuous integration, continuous delivery and/or deployment (CI/CD) pipeline, these challenges can lead to slower release cycles, increased errors, and inconsistent workflows.\nJetBrains TeamCity Cloud is an iOS DevOps CI/CD solution with support for Swift and Objective-C, macOS build agents, seamless integration with Xcode, and advanced configuration options via YAML. TeamCity simplifies the process of building, testing, and deploying iOS applications.\nIn this article, you will learn how to set up an end-to-end CI/CD pipeline for your iOS projects using TeamCity Cloud. It covers everything from integrating version control systems (VCSs) and automating builds with fastlane to signing and packaging your apps and deploying them to TestFlight.\nUnderstanding the iOS CI/CD pipeline\nA well-structured CI/CD pipeline for iOS applications automates repetitive tasks and ensures high-quality, consistent releases. Before you start building the pipeline, let’s break down the typical stages of an iOS pipeline and how TeamCity Cloud supports each part of the process.\nCode checkout and version control integration\nA typical pipeline begins with fetching the latest changes from your version control system (VCS), such as GitHub, GitLab, or Bitbucket. TeamCity offers built-in integrations for popular VCS providers, allowing you to easily connect your repository and configure access credentials.\n\n\n\n\nYou can set up build triggers so that the pipeline runs automatically on every push or pull request or commit to specific branches. This ensures your project is always tested against the latest code changes.\nBuilding iOS applications with Xcode\nOnce the code is checked out, the next step is to build the project. You can use either the default xcodebuild command line tool or any third-party tool, such as fastlane. In this step, the build tool compiles the source code, assembles resources, and generates the app bundle.\nYou can define build steps for different configurations—such as Debug, Release, or custom schemes—directly in TeamCity. When used with TeamCity Build Parameters, you can reuse the same pipeline for multiple configurations.\nWith Matrix Build on TeamCity, you can even take this a step further and generate multiple builds in parallel using a combination of values for your build parameters. This gives you the flexibility to target multiple environments or testing scenarios.\nExample of matrix builds in TeamCity\n\n\n\nTesting across multiple iOS versions\nTo maintain code quality and prevent regressions, you should always consider including automated testing. TeamCity optimizes automated tests through its parallel testing capabilities. It allows you to test across multiple simulated iOS versions and device configurations simultaneously, reducing feedback cycles and ensuring broader coverage.\nStatic code analysis and code coverage reporting\nStatic code analysis helps catch issues early in the development cycle. You can integrate tools like SwiftLint as build steps to enforce style and coding conventions.\nFor deeper insights, TeamCity supports code-quality tools, like JetBrains Qodana, and can generate code coverage reports to help evaluate test completeness and identify untested areas of your codebase.\nSigning and packaging (IPA files)\nOne of the more intricate parts of iOS CI/CD is managing code signing. Modern iOS DevOps practices recommend using a Git-based or file bucket-based store for certificates and keys. \nPopular tools, like fastlane, offer out-of-the-box support to implement and use these practices conveniently. You can always use git (with SSH authentication) or the AWS CLI tool to connect to your private certificates store from inside your pipelines and sign your apps as needed.\nDeploying to TestFlight or the App Store\nFinally, once your app is built, tested, and signed, it’s ready to be distributed. Tools like fastlane can automate the upload of your IPA files to TestFlight or the App Store from within your pipelines. Y\nou might need to configure App Store Connect or Apple’s application-specific passwords to make this work. But it makes it very easy to push changes to a dedicated TestFlight branch in your VCS repo, which are then uploaded to TestFlight within minutes.\nYou can also configure separate workflows for beta and production releases, include postdeployment notifications for your team, and monitor the deployment status via TeamCity’s dashboards.\nNow that you understand the usual components that make up an iOS pipeline, it’s time to build one yourself! Here’s a rough overview of what this pipeline does:\n\n\n\n\nPrerequisites\nYou’ll need the following before you can move ahead:\nAccess to a TeamCity server or TeamCity Cloud with Mac build agents. Feel free to create a TeamCity Cloud trial account here.\nAn iOS project hosted on GitHub. You can use one of your own projects or fork this one to your repo to follow along.\nAn Apple Developer Program account.\nAccess to the App Store Connect platform.\nfastlane installed locally.\nAn Amazon Web Service (AWS) Simple Storage Service (S3) bucket to store app-signing certificates and profiles.\nSetting up the iOS project\nThis tutorial uses fastlane to define the workflows that will be automated with TeamCity. It’s a popular mobile DevOps tool used across iOS and Android projects.\nInitializing fastlane\nOnce you have cloned the forked repo locally and set up fastlane, run the following command in a terminal inside your project directory:\nfastlane init\nSelect Automate beta distribution to TestFlight as the answer for What would you like to use fastlane for? \nThe CLI will then ask for your Apple ID username and attempt to log in to your App Store Connect account. Once it’s logged in, it will create a fastlane/ folder inside your project directory along with an Appfile. \nThis Appfile will contain the details about your project that you will supply during the fastlane init process. These details can include the app bundle, your Apple ID email, and your Apple Developer team ID.\nNote that for now, fastlane init will hard-code these values in the Appfile, but before pushing the fastlane files to your repo, you should replace these with environment variables; you’ll learn how to do this later in the tutorial.\nSetting up the beta lane\nNext, you need to paste the following contents into fastlane/Fastfile:\ndefault_platform(:ios)\n\nbefore_all do\n  create_keychain(\n    name: \"keychain\",\n    password: \"password\",\n    default_keychain: true,\n    unlock: true,\n    timeout: 3600,\n    lock_when_sleeps: false\n  )\n  match(type: \"appstore\", keychain_name: \"keychain\", keychain_password: \"password\", readonly: true)\nend\n\n\nplatform :ios do\n  desc \"Build and upload to TestFlight\"\n  lane :beta do |options|\n    # Increment build number\n    increment_build_number(xcodeproj: \"Facto.xcodeproj\")\n    \n    # Build the app\n    build_app(\n      scheme: \"Facto\",\n      configuration: \"Release\",\n      export_method: \"app-store\",\n      export_options: {\n        provisioningProfiles: {\n          \"dev.draft.Facto\" => \"Facto Distribution\"\n        }\n      }\n    )\n\n    api_key = app_store_connect_api_key(\n      key_id: options[:key_id],\n      issuer_id: options[:issuer_id],\n      key_filepath: File.absolute_path(\"tmp/AuthKey.p8\"),\n      duration: 1200,\n      in_house: false\n    )\n        \n    # Upload to TestFlight\n    pilot(\n      api_key: api_key,\n      skip_waiting_for_build_processing: true,\n      skip_submission: true\n    )\n    \n  end\nend\nThe Fastfile is where you define lanes—automated workflows that fastlane will run for you. The Fastfile above sets up a lane called beta to build and upload your iOS app to TestFlight.\nThe default_platform(:ios) statement tells fastlane that you’re working with an iOS project, so all lanes will assume this unless otherwise specified.\nThe before_all block runs before any lane is executed. It carries out two tasks before running any lanes:\ncreate_keychain: This creates and unlocks a temporary keychain for your build. This is safer and cleaner than using your login keychain directly. In CI systems, this is a mandatory step as the runner environment often doesn’t ship with a keychain.\nmatch: This uses match to fetch the appropriate App Store provisioning profile from a shared certificate repo and installs it into the keychain. readonly: true ensures that no new profiles are created during the process.\nThe beta lane is your main automation workflow. You’ll run this in TeamCity when you’re ready to build the app and push it to TestFlight.\nEach step in this lane performs a part of the TestFlight release process:\nincrement_build_number(xcodeproj: \"Facto.xcodeproj\") automatically increases the build number in your Xcode project. This is required for each TestFlight upload.\nbuild_app(...) builds your iOS app for distribution. It uses the Facto scheme based on the example app provided above, but please make sure to update it to your app’s scheme. Next, it uses the Release configuration and exports the app for the App Store (export_method: \"app-store\"). It also specifies the correct provisioning profile to use for the given bundle identifier. Make sure to update this to match your provisioning profile.\napi_key = app_store_connect_api_key(...) loads a private API key (named AuthKey.p8) to authenticate securely with App Store Connect. The key ID and issuer ID are passed in via options, so you can keep secrets outside the code. You will need to set these up in the CI system before you can run the beta lane.\nFinally, pilot(...) uploads the build to TestFlight using the previously generated api_key. It doesn’t wait for Apple’s build processing to finish or submit the build for App Review, which makes sense during internal testing.\nThis Fastfile allows you to simply call fastlane beta in your TeamCity job after setting up the necessary credentials and have fastlane take care of all deployment tasks.\nConfiguring fastlane match\nNow that your Fastfile is set up, the next step is to configure match, which will handle code signing for you. Code signing is a necessary part of the iOS build and distribution process, and match helps automate it in a safe and scalable way, which is especially useful when working in CI environments like TeamCity.\nTo do that, run the following in your project directory:\nfastlane match init\nThis command will guide you through a short process of configuring a few match preferences and will create a Matchfile for you at the end.\nAs part of this process, fastlane will prompt you to choose a storage backend. For this tutorial, select S3. Here’s why:\nEasier setup: Git-based storage typically requires configuring SSH keys or access tokens in your CI pipeline, which can be tedious and error-prone.\nBetter access control: With S3, you can use IAM roles, bucket policies, or presigned URLs to control who can access signing assets tightly.\nMore secure: S3 eliminates the need to expose or manage SSH credentials and can integrate with cloud-native security tooling for auditing and access logging.\nOnce the Matchfile is created, make sure to fill in your S3 bucket’s name in the s3_bucket(\"\") statement in the file.\nRun the following command to store your certificates and profiles in this bucket using match:\nfastlane match appstore\nThis command tells fastlane to generate or download the necessary signing certificates and provisioning profiles for App Store distribution.\nOnce that’s done, fastlane will upload your certificates and provisioning profiles to the S3 bucket and automatically pull them down during builds. You won’t need to manage or manually install signing files anymore; match will do it for you.\nAt this point, you should update your Appfile to remove the hard-coded credentials that fastlane init created. Storing sensitive values directly in configuration files poses a security risk if they’re accidentally committed to version control. \nInstead, you’ll use environment variables to supply these values securely. Replace the contents of the fastlane/Appfile file with the following:\napp_identifier ENV[\"APP_IDENTIFIER\"]\napple_id ENV[\"APPLE_ID\"]\nteam_id ENV[\"TEAM_ID\"]\nAt this point, you are ready to start building a TeamCity pipeline. Make sure to commit the fastlane folder and its contents (Appfile, Fastfile, and Matchfile) to your app’s GitHub repo before moving ahead.\nCreate a new project in TeamCity Cloud\nNow that your iOS project is set up with fastlane, it’s time to create a new project in TeamCity Cloud. This will be the foundation of your CI/CD pipeline.\nLet’s start with a project creation. Head over to your TeamCity Cloud instance and click the + sign in the menu on the left. Click Manually, choose the name for your project, and TeamCity will automatically fill out the Project ID for you. Then click Create:\n\n\n\n\nYou’ll then see the project overview page. Here, you can set up VCS roots for the project, define parameters and other settings. You can also choose whether you want to create a pipeline for the project or use a build configuration.\nHere’s a short description how the two differ:\nPipeline: A simplified alternative to build configurations linked in a build chain. Features a smart visual editor and allows you to use YAML for configuration-as-code.\nBuild configuration: Build configurations and pipelines represent actual CI/CD routines. A build configuration stores a sequence of build steps (basic operations to be performed during a build run), and settings required to execute these steps. \nIn this tutorial, we’ll proceed with pipelines. Click the + Create pipeline button in the UI.\n\n\n\n\nOn the next step, search for the repo that you forked. After you select the repo, you’ll see a few more fields on the page:\n\n\n\n\nHere, set a name for the pipeline and leave the other options as defaults. Once that’s done, click Create. This will create the pipeline for you. \nAlso, since you selected the default options when choosing the repo and creating the pipeline (set Default branch to main and Branches to monitor to All branches), this pipeline will be configured to run whenever a commit is pushed to any branch on the repo. You can change this option later if you want, though.\nOnce the pipeline is created, you’ll be navigated to the pipeline editor view, with options to create build configurations, add build steps, configure triggers, and set up your iOS deployment workflow:\n\n\n\n\nYou can now start configuring your jobs!\nConfigure build job\nYou’ll notice that an empty job has already been created for you with the name Job 1. You will update this job to set up your iOS development credentials and run the fastlane beta command.\nFirst of all, you need to set the runner for the job. By default, TeamCity runs jobs on a Linux-based runner. However, you need a macOS-based runner for building iOS projects, so in the right pane under Runs On, search for and select macOS 14 Sonoma Medium Arm64 as the runner:\n\n\n\n\nNext, in the Steps section of the same pane, click Script to add a new script-based step. This is where you will write the script for your fastlane beta call.\nName the step as Push beta and paste the following script in the Script content field:\nexport AWS_ACCESS_KEY_ID=%AWS_ACCESS_KEY_ID%\nexport AWS_SECRET_ACCESS_KEY=%AWS_SECRET_ACCESS_KEY%\nexport AWS_REGION=%AWS_REGION%\n\nmkdir -p fastlane/tmp\n\naws secretsmanager get-secret-value \\\n    --secret-id ASC_KEY \\\n    --output text \\\n    --query SecretString | base64 -d -o fastlane/tmp/AuthKey.p8\n\nexport KEY_ID=`aws secretsmanager get-secret-value \\\n    --secret-id ASC_KEY_ID \\\n    --output text \\\n    --query 'SecretString' | cut -d '\"' -f4`\n                   \nexport ISSUER_ID=`aws secretsmanager get-secret-value \\\n    --secret-id ASC_ISSUER_ID \\\n    --output text \\\n    --query 'SecretString' | cut -d '\"' -f4`\n\nexport APP_IDENTIFIER=`aws secretsmanager get-secret-value \\\n    --secret-id APP_IDENTIFIER \\\n    --output text \\\n    --query 'SecretString' | cut -d '\"' -f4`\n\nexport APPLE_ID=`aws secretsmanager get-secret-value \\\n    --secret-id APPLE_ID \\\n    --output text \\\n    --query 'SecretString' | cut -d '\"' -f4`\n\nexport MATCH_PASSWORD=`aws secretsmanager get-secret-value \\\n    --secret-id MATCH_PASSWORD \\\n    --output text \\\n    --query 'SecretString' | cut -d '\"' -f4`\n\nexport TEAM_ID=`aws secretsmanager get-secret-value \\\n    --secret-id TEAM_ID \\\n    --output text \\\n    --query 'SecretString' | cut -d '\"' -f4`\n\nbundle install\n\nbundle exec fastlane beta \\\n    key_id:\"$KEY_ID\" \\\n    issuer_id:\"$ISSUER_ID\"\n\n\n\n\nLet’s take a moment to understand what this script does:\nAWS credentials setup:\nexport AWS_ACCESS_KEY_ID=%AWS_ACCESS_KEY_ID%\nexport AWS_SECRET_ACCESS_KEY=%AWS_SECRET_ACCESS_KEY%\nexport AWS_REGION=%AWS_REGION%\nThese lines set up AWS credentials that will be used to access AWS Secrets Manager. The %VARIABLE% syntax is TeamCity’s way of referencing build parameters.\nApp Store Connect key setup:\nmkdir -p fastlane/tmp\naws secretsmanager get-secret-value \\\n    --secret-id ASC_KEY \\\n    --output text \\\n    --query SecretString | base64 -d -o fastlane/tmp/AuthKey.p8\nThis creates a temporary directory for the App Store Connect API key and downloads it from AWS Secrets Manager. The key is stored in Base64 format and needs to be decoded.\nEnvironment variables from Secrets:\nexport KEY_ID=`aws secretsmanager get-secret-value \\\n    --secret-id ASC_KEY_ID \\\n    --output text \\\n    --query 'SecretString' | cut -d '\"' -f4`\nThis pattern is repeated for all sensitive values (ISSUER_ID, APP_IDENTIFIER, APPLE_ID, MATCH_PASSWORD, and TEAM_ID). Each secret is retrieved from AWS Secrets Manager and stored as an environment variable. The cut -d '\"' -f4 command extracts the actual value from the JSON response.\nDependencies and execution:\nbundle install\nbundle exec fastlane beta \\\n    key_id:\"$KEY_ID\" \\\n    issuer_id:\"$ISSUER_ID\"\nFinally, the script installs Ruby dependencies using Bundler and runs the beta lane with the necessary parameters.\nThis approach has several security benefits:\nSensitive credentials are stored in AWS Secrets Manager, not in TeamCity.\nThe App Store Connect API key is only temporarily available during the build.\nAll sensitive values are passed as environment variables, not command line arguments.\nYou are able to use these tools (aws, bundle, base64, etc.) without having to install them because TeamCity-hosted runners ship with a list of preinstalled software.\nNote that using an external, secure credentials manager is always recommended in production environments, which is why it has been demonstrated above. \nHowever, if you just want to set up the pipeline quickly, you can choose to skip the next section and supply the credentials through TeamCity build parameters. But please make sure to always use credential managers in production.\nSet up AWS Secrets\nBefore you can run this script, you’ll need to set up the following secrets in AWS Secrets Manager:\nASC_KEY: Your App Store Connect API key file (.p8) in Base64 format\nASC_KEY_ID: Your App Store Connect API key ID\nASC_ISSUER_ID: Your App Store Connect API issuer ID\nAPP_IDENTIFIER: Your app’s bundle identifier\nAPPLE_ID: Your Apple ID email\nMATCH_PASSWORD: Password for encrypting/decrypting certificates in match\nTEAM_ID: Your Apple Developer team ID\nYou can follow this guide to create secrets through the AWS console. Make sure these secrets are set up correctly before moving ahead:\n\n\n\n\nSet up build parameters\nTo access these secrets from your pipeline, you need to provide the aws CLI tool with an access key and secret pair that has the necessary permissions to access the secret.\nNote that in TeamCity On-Premises, you can instead use the AWS Connection to provide your pipeline with a method to connect with your AWS resources with temporary credentials instead of exposing static ones.\nYou’ll need to set up three build parameters:\nAWS_ACCESS_KEY_ID: Your AWS access key\nAWS_SECRET_ACCESS_KEY: Your AWS secret key\nAWS_REGION: The AWS region where your secrets are stored (eg us-east-1)\nOnce you have generated these, head over to your pipeline details page and click Pipeline settings above Job Details:\n\n\n\n\nThe right pane will now show pipeline configuration details. You can find both parameters and secrets on this page. TeamCity secrets are build parameters whose actual values are stored securely by TeamCity, hidden away from the web UI, logs, YAML configurations, and other locations.\nYou will notice a + icon next to No Secrets. Click it to add new secrets. Add the secrets listed above. Once that’s done, here’s what the pipeline settings page should look like:\n\n\n\n\nWith these configurations in place, your build job is ready to run. When triggered, it will:\nset up the necessary Apple development credentials from AWS;\ndownload and configure the App Store Connect API key; and\nrun fastlane to build and deploy your app to TestFlight.\nTesting the pipeline\nTo trigger a build, you can either push a new commit to the repo or click the purple Run button at the top right of the TeamCity web portal. It should trigger a new build for you and take you to the build details page. In about four minutes, the build should complete running successfully:\n\n\n\n\nYou can explore the build logs in the right panel to understand how the build processed and read any warning, info, or error messages that were generated. TeamCity groups logs by steps, and searching for and downloading log files is a straightforward process.\nOnce the build completes successfully, you should receive an email from App Store Connect on the email address linked to your Apple ID:\n\n\n\n\nIf you log in to your App Store Connect portal, you will see the new version ready to be rolled out for testing:\n\n\n\n\nThis means that your iOS pipeline is working correctly!\nConclusion\nIn this guide, you learned how to build a modern CI/CD pipeline for iOS applications using TeamCity Cloud and fastlane, thus automating your entire workflow from local development to TestFlight deployment. \nThe result is a fully automated pipeline that picks up commits, runs builds, uploads to TestFlight, and provides complete visibility through dashboards, which creates a repeatable workflow that reduces manual effort, eliminates common errors, and ensures consistent app delivery.\nWhile this tutorial focused on TestFlight deployment, the same setup can be extended to include test automation, static analysis, App Store deployment, and team notifications. With TeamCity Cloud’s advanced features — such as live test reporting, matrix builds, and build chains — you have all the tools you need to scale your iOS delivery process as your app and team grow.\n\n                                \nStart a free trial",
        "dc:creator": "Olga Bedrina",
        "content": "This article was brought to you by Kumar Harsh, draft.dev. Developing and releasing iOS applications involves navigating a complex web of code signing, provisioning profiles, multiple iOS versions, and stringent App Store guidelines/requirements. Without an automated continuous integration, continuous delivery and/or deployment (CI/CD) pipeline, these challenges can lead to slower release cycles, increased errors, and [&#8230;]",
        "contentSnippet": "This article was brought to you by Kumar Harsh, draft.dev. Developing and releasing iOS applications involves navigating a complex web of code signing, provisioning profiles, multiple iOS versions, and stringent App Store guidelines/requirements. Without an automated continuous integration, continuous delivery and/or deployment (CI/CD) pipeline, these challenges can lead to slower release cycles, increased errors, and […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=594006",
        "categories": [
          "ios",
          "tutorials",
          "how-to",
          "tutorial"
        ],
        "isoDate": "2025-08-26T15:52:42.000Z"
      },
      {
        "creator": "Dmitry Pogrebnoy",
        "title": "Unveiling Ruby Debuggers: byebug, debug gem, and the Power of RubyMine",
        "link": "https://blog.jetbrains.com/ruby/2025/08/unveiling-ruby-debuggers-byebug-debug-gem-and-the-power-of-rubymine/",
        "pubDate": "Tue, 26 Aug 2025 07:11:53 +0000",
        "content:encodedSnippet": "Hello, Ruby developers!\nWhether you are a seasoned Ruby developer or just getting started, mastering the debugger will save you time and frustration when tracking down bugs. At RubyMine, we’ve spent years building debugging tools for Ruby. In this blog series, we’re sharing some of the insights we’ve gained along the way.\nIn this post, we’ll take a closer look at the internal workings of byebug and the debug gem, comparing their unique approaches, strengths, and limitations. We’ll also break down the architecture of the RubyMine debugger to see how it works. Finally, we’ll conduct an experiment to test the performance of these debuggers and find out which one comes out on top.\nThis is the third post in a series inspired by Demystifying Debuggers, a talk by Dmitry Pogrebnoy, RubyMine Team Lead, presented at EuRuKo 2024, RubyKaigi 2025 and RubyConf Africa 2025. In this post, we go deeper into how Ruby debuggers work under the hood and share insights about Ruby debuggers.\nIf you haven’t seen the earlier posts yet, we recommend starting there:\nMastering Ruby Debugging: From puts to Professional Tools\nInside Ruby Debuggers: TracePoint, Instruction Sequence, and CRuby API\nPrefer watching? You can also check out the original talk here: 🎥 Dmitry Pogrebnoy, “Demystifying Debugger”\nLet’s dive into the internals!\nIs the debugger an essential tool for Ruby developers?\nBefore we jump into how debuggers work, let’s take a step back and ask: How often do Ruby developers actually use a debugger? The answer might surprise you.\nThe need for and reliance on a debugger can vary greatly depending on the programming language and framework you’re using. It’s also influenced by the preferences of the developer community and the specific needs of the domain. Some developers might use a debugger all the time, while others might prefer different tools or methods for troubleshooting. Some of these tools were covered in the first post in the series.\nUnfortunately, there aren’t any reliable public stats on how often Ruby developers use debuggers overall. But thanks to anonymous usage data from RubyMine users, we can still get a rough sense of how common debugger usage is in real-world projects.\nThe pie chart below shows how often RubyMine users run their code using a debugger compared to other types of run configurations. These numbers come from anonymous usage stats collected in RubyMine 2025.1.\n\nAs we can see, almost every third run in RubyMine is a debugger run. This demonstrates just how essential and fundamental the debugger has become for professional Ruby developers. That’s why the RubyMine team tries to provide the smoothest possible debugger experience that will enhance your efforts in investigating problems.\nHow do Ruby debuggers work internally?\nIn the previous section, we covered the main building blocks of Ruby debuggers. Now it’s time to see how these components are applied in real-world tools. In this section, we’ll start with the byebug gem, then move on to the debug gem, and finally take a look at the RubyMine debugger. Let’s begin with byebug!\nSimplified model of the byebug debugger\nbyebug is a simple Ruby debugger. It provides essential features like breakpoints, basic stepping, and variable inspection. By default, it offers a command-line interface (CLI) for debugging, but there’s also an option to install and configure a plugin for GUI support in code editors. \nTo start a debugging session with byebug, you typically need to modify your project’s source code by inserting byebug statements, or run commands manually in the terminal, which require some adjustments to your project setup, especially when working with Rails applications.\nLet’s take a look at the simplified model of how byebug works. This code in the model should be executed before any code of the application that we are going to debug.\nbreakpoints = [] # list of breakpoints\ntracepoints = [] # contains a single tracepoint for each event type\n\n\n# For every type of tracepoint event\ntracepoints &lt;&lt; TracePoint.trace(:line) do |tp|\n breakpoint = breakpoints.find do |b|\n   tp.path == b.path &amp;&amp; tp.lineno == b.lineno\n end\n\n\n if breakpoint\n   handle_breakpoint(breakpoint)\n end\nend\n\n\n# Ordinal code execution\n# ...\nLet’s examine how this works. At its core, byebug maintains two important lists — one for storing breakpoints set by the user throughout the debugging session, and another for tracepoints. TracePoint is a instrumentation technology in Ruby that works by intercepting specific runtime events such as method calls, line executions, or exception raises and executing custom code when these events occur. Take a look at our previous blog post for more details.\nbyebug has one TracePoint for each type of event it tracks — one for line events, one for call events, and so on. Each TracePoint in the list follows a similar pattern. When a trace event occurs at runtime, the corresponding TracePoint is triggered, and byebug checks whether there’s a breakpoint set at that location by comparing file paths and line numbers. If a breakpoint is found, byebug pauses program execution and hands control to the developer, who can then inspect variables, step through code, evaluate expressions, or perform other debugger actions. If no breakpoint is found, execution simply continues until the next trace event, where the same process is repeated. This is how byebug detects breakpoints and stops at them during runtime.\nIt is a simple yet effective approach that works well and allows developers to debug their code. However, it comes with one major drawback — performance.\nWith each event emitted during program execution, byebug has to perform breakpoint checks — even when there’s only a single breakpoint set in the entire application. This means that if you place just one breakpoint somewhere in your code, the debugger will still check for breakpoint matches on every single trace event. It’s like having a security guard check every room in a building when you only need to monitor one specific door.\nConsequently, these constant checks add significant computational overhead when running code with byebug. Our performance tests show that applications can run more than 20 times slower under byebug compared to normal execution. This performance impact makes byebug challenging to use with complex real-world Rails applications, where execution time really matters. Fortunately, more modern debugging solutions have found ways to address this limitation.\nPerformant debug gem and TracePoint improvement\nOur next tool is the debug gem — a debugger designed for modern Ruby versions starting from 2.7. It provides CLI by default, but you can also set it up with a plugin to get GUI in code editors.\nJust like byebug, the debug gem requires you to modify your code by adding binding.break statements to start a debugging session. Alternatively, you can run it manually from the terminal, which may require some additional project configuration, especially in Rails applications.\nThe debug gem completely solves the significant performance limitation described in the previous section. Before we start with the debug gem, let’s take a look at the main feature that helped to overcome the performance problem.\nThe magic behind the strong performance of the debug gem is related to the TracePoint update that was released in Ruby 2.6 back in 2018.\nThis improvement added a key feature — TracePoints could now be targeted to specific lines of code or specific instruction sequences. No more checking for breakpoints on every event. Instead, TracePoints would only trigger exactly where breakpoints were set, solving the performance problem.\nLet’s look at a practical example of how this feature works.\ndef say_hello = puts \"Hello Ruby developers!\"\ndef say_goodbye = puts \"Goodbye Ruby developers!\"\n\n\niseq = RubyVM::InstructionSequence.of(method(:say_hello))\ntrace = TracePoint.new(:call) do |tp|\n puts \"Calling method '#{tp.method_id}'\"\nend\n\n\ntrace.enable(target: iseq)\n\n\nsay_hello\nsay_goodbye\n# => Calling method 'say_hello'\n# => Hello Ruby developers!\n# => Goodbye Ruby developers!\nHere we have two methods — say_hello and say_goodbye. The key change is that we’re targeting our TracePoint specifically to the instruction sequence of the first method only.\nLooking at the output in the comments, we can see how powerful and precise targeted TracePoints are. The TracePoint is triggered only for say_hello but is completely ignored for say_goodbye — exactly what we needed. This level of control is a major improvement over the old approach where TracePoints would fire for every method indiscriminately.\nThis example demonstrates a simplified version of how the debug gem uses TracePoint under the hood. Unlike byebug, which maintains a general-purpose list of TracePoints and checks every single trace event against all breakpoints, the debug gem takes a more efficient and targeted approach. It creates a dedicated TracePoint for each individual breakpoint and binds it directly to the corresponding location in the code — either a specific line or an instruction sequence.\nThis means the TracePoint will only trigger when that exact location is executed, eliminating the need for constant runtime checks across unrelated code paths. As a result, the debug gem introduces significantly less overhead and performs much better in practice. This difference becomes especially noticeable in large Ruby codebases or performance-sensitive environments, where byebug’s frequent event scanning can lead to substantial slowdowns.\nDespite its significant advantages, this TracePoint improvement wasn’t backported to Ruby versions before 2.6. As a result, the debug gem only supports Ruby 2.7 and newer versions where additional fixes for the TracePoint improvement were released. This circumstance leaves projects running on older Ruby versions without access to this powerful debugging tool, even though they might still need advanced debugging capabilities for investigating complex issues.\nStarting with Ruby 3.1, the debug gem is bundled as the default debugger. It’s an excellent starting point for many Ruby developers — especially those who haven’t yet explored more advanced tools like the RubyMine debugger to meet their growing need for a better debugging experience and more powerful capabilities.\nHow is the RubyMine debugger structured?\nAs we’ve seen, both popular open-source Ruby debuggers have their limitations. Byebug suffers from performance issues that make it impractical for large applications, while the debug gem doesn’t support Ruby versions before 2.7. This can be frustrating for professional developers who need reliable debugging capabilities across different Ruby versions. The RubyMine debugger solves these problems by supporting Ruby versions from 2.3 onwards, covering practically any Ruby version your application might use.\nOne significant benefit that sets the RubyMine debugger apart is that it doesn’t have any performance issues and maintains excellent speed even on older Ruby versions. This feature makes the RubyMine debugger the go-to debugging tool for professional Ruby developers, regardless of their project’s specific requirements.\nAnother advantage is a straightforward debugging experience, with all features available immediately after setup. There’s no need to modify your project configuration, install and configure extra plugins, or manage terminal commands to start debugging. It works even with production size Rails applications and lets you focus on solving problems rather than setting up tools.\nIn addition, the RubyMine debugger offers smart stepping — a feature that lets you step into a specific method when there are multiple calls on the same line. Instead of always entering the first call, it highlights all available options so you can choose the one you want. It’s especially useful for debugging chained or complex expressions — a level of control that other Ruby debuggers don’t offer.\nThe RubyMine debugger provides versatile debugging capabilities and a productivity-focused debugger experience. If you haven’t tried the RubyMine debugger yet, it’s definitely worth a chance.\nLet’s take a closer look at the architecture of the RubyMine debugger and how it’s built to be such a powerful tool.\nGeneral RubyMine debugger architecture\nThis is a high-level architecture of the RubyMine debugger.\n\nLet’s examine the diagram to understand how the RubyMine debugger works internally. The architecture consists of three main parts that work together to provide a smooth debugging experience.\nThe first component is the debase gem — the core backend of the RubyMine debugger. Written as a C extension, it handles all low-level operations like retrieving execution contexts, managing stack frames, and manipulating instruction sequences. This backend is responsible for direct interaction with Ruby internals, which makes it a convenient and efficient interface for other debugger components.\nThe second part is the ruby-debug-ide gem, which serves as the internal debugger frontend. This critical piece manages the communication between RubyMine and the backend by establishing and maintaining their connection. It handles the message protocol and processes commands coming from RubyMine. Additionally, it’s responsible for creating readable text representations of Ruby objects that developers will see in the RubyMine debugger Tool Window.\nFinally, there’s RubyMine itself. Its primary role is to provide a smooth and productive debugging experience. Most of the debugger features that enhance developer productivity — like smart stepping, inline-debugger values, and frames and breakpoints management — are mainly implemented at this level. The IDE also handles communication with the debugger frontend by sending commands and processing responses. \nHaving three separate parts with clear interfaces between them brings several key benefits. This modular structure significantly reduces the overall system complexity, making it easier to maintain and less prone to bugs. Each component can be developed independently and at its own pace, which streamlines development and makes maintenance more efficient.\nThe real RubyMine debugger architecture\nThe architecture we’ve discussed is a simplified view of the RubyMine debugger. While it helps you understand the core concepts, the real-world implementation has additional layers of complexity. Let’s dive deeper and explore how the actual system is structured.\n\nInstead of a single branch of debugger gems, there are two separate branches of debugger gems — a top branch and a bottom branch — each specified for different Ruby versions.\nThe top branch supports Ruby versions 2.3 through 2.7. These gems use several clever low-level hacks to achieve high performance without the TracePoint improvements we discussed earlier. While these hacks work effectively, they make the gems harder to maintain and extend. Still, this approach ensures excellent debugging capabilities for legacy Ruby applications.\nThe challenges of maintaining and extending the top branch gems led to the creation of the bottom branch of gems. This branch is designed specifically for modern Ruby and ensures a smooth debugging experience with Ruby versions 3.0 and onwards. Unlike the top branch, these gems don’t rely on low-level hacks. Instead, they leverage modern Ruby APIs and the improved TracePoint mechanism, resulting in a cleaner and more maintainable codebase. This approach not only simplifies the implementation but also makes it easier to add new features and support new Ruby versions.\nHaving two separate branches for different Ruby versions helps us keep the RubyMine debugger maintainable and performant. It lets us support legacy versions while steadily raising the quality bar and reliability of the debugging experience for modern Ruby.\nWhich debugger is the most performant?\nBefore we dive into performance, let’s quickly recap what we’ve covered so far. We began with an in-depth look at how the byebug debugger works internally and where it falls short. Then, we examined how the debug gem takes a different approach to overcome those limitations. Finally, we explored the architecture of the RubyMine Debugger and the advantages it brings to the table.\nNow, it’s time to ask the big practical question: which of these debuggers performs best?\nRather than guess, let’s put these debuggers to the test with a straightforward benchmarking experiment.\ndef fib(n)\n raise if n < 0 # place a breakpoint on this line\n return n if n < 2\n fib(n - 1) + fib(n - 2)\nend\n\n\nrequire 'benchmark'\nTOTAL_RUNS = 100\ntotal_time = TOTAL_RUNS.times.sum do\n Benchmark.realtime { fib(40) }\nend\n\n\nputs \"Avg real time elapsed: #{total_time/TOTAL_RUNS}\"\nWe use the Fibonacci method with an added condition specifically to set a breakpoint. Although the breakpoint is never hit, it allows us to measure how simply having a breakpoint in place can impact the performance of each debugger. To run the experiment, we used the benchmark gem and averaged the execution time over 100 runs to get stable, meaningful results.\nLet’s state the Ruby debugger and Ruby versions for that experiment to get reproducible results.\n\nRuby 2.6.10Ruby 3.4.2\nbyebug – 11.1.3debug gem – 1.10.0\nRubyMine debugger\n    • ruby-debug-ide – 2.3.24\n    • debase – 2.3.15 RubyMine debugger\n    • ruby-debug-ide – 3.0.2\n    • debase – 3.0.2\n\n\n\n\n\nFor this experiment, we’ll use the latest available versions of Ruby and debugger gems at the time of writing. We define two test groups based on Ruby versions they support. One for Ruby 2.6.10, representing older versions, and one for Ruby 3.4.2, representing modern versions. The Ruby 2.6.10 group includes byebug. The Ruby 3.4.2 group features the debug gem. The RubyMine debugger is included in both groups, but it uses different gem versions optimized for the respective Ruby version.\nLet’s run the benchmark and see how each debugger performs.\n\nRuby 2.6.10Ruby 3.4.2\nOriginal run17.7 sec15.8 sec\nbyebug529.1 sec✕\ndebug gem✕15.8 sec\nRubyMine debugger17.7 sec15.8 sec\n\n\n\n\n\nLet’s first examine the results for the older Ruby version. The most striking observation is the performance of byebug. The benchmark shows it runs about 30 times slower than the original code without any debugger attached — a significant performance hit that makes it impractical for debugging complex applications.\nOn the other hand, the RubyMine debugger shows no noticeable performance impact on older Ruby versions. This means that for applications running on older Ruby versions, particularly production applications, the RubyMine debugger stands out as the only practical option for effective debugging. While having limited choices isn’t ideal, this is the reality when working with older Ruby versions.\nLooking at a modern Ruby version group, the situation is much better. Both the RubyMine debugger and debug gem show excellent performance with no noticeable slowdown. This gives developers the freedom to choose either tool based on their specific needs and preferences. The availability of multiple performant debuggers empowers Ruby developers to choose the best tool for their situation and makes the Ruby debugging ecosystem stronger.\nOverall, the RubyMine debugger delivers consistently high performance across both old and new Ruby versions, while byebug significantly slows down execution and is impractical for complex applications. On newer Ruby versions, the debug gem matches RubyMine in speed, giving developers an open-source alternative.\nConclusion\nDebugging is a practical skill for every Ruby developer, and understanding the inner workings of Ruby debuggers can help you recognize each debugger’s limitations, choose the right tool for your needs, and avoid common pitfalls. In this post, we’ve examined the internal mechanics of Ruby debuggers like byebug, the debug gem, and the RubyMine debugger, highlighting the advantages and downsides of their approaches.\nByebug and the debug gem both offer basic debugging features like breakpoints, stepping, and variable inspection. The debug gem delivers significantly better performance than byebug, but it only supports Ruby versions 2.7 and newer. Byebug, on the other hand, works with older Ruby versions but tends to be much slower — especially in larger projects.\nThe RubyMine debugger stands out by combining the best of both worlds. It supports a wide range of Ruby versions, delivers strong performance across all of them, and offers a smooth, reliable debugging experience — even in complex Rails applications. On top of the basic features, RubyMine includes advanced capabilities like smart stepping, inline variable values, and more. You can explore the full set of features in the RubyMine debugging documentation.\nWe hope this post has helped clarify how Ruby debuggers work internally and provided useful insights for improving your debugging workflow.\nHappy coding, and may your bugs be rare and simple to squash!\nThe RubyMine team",
        "dc:creator": "Dmitry Pogrebnoy",
        "content": "Hello, Ruby developers! Whether you are a seasoned Ruby developer or just getting started, mastering the debugger will save you time and frustration when tracking down bugs. At RubyMine, we’ve spent years building debugging tools for Ruby. In this blog series, we’re sharing some of the insights we’ve gained along the way. In this post, [&#8230;]",
        "contentSnippet": "Hello, Ruby developers! Whether you are a seasoned Ruby developer or just getting started, mastering the debugger will save you time and frustration when tracking down bugs. At RubyMine, we’ve spent years building debugging tools for Ruby. In this blog series, we’re sharing some of the insights we’ve gained along the way. In this post, […]",
        "guid": "https://blog.jetbrains.com/?post_type=ruby&p=594034",
        "categories": [
          "rubymine"
        ],
        "isoDate": "2025-08-26T07:11:53.000Z"
      },
      {
        "creator": "Ekaterina Petrova",
        "title": "What’s Next for Kotlin Multiplatform and Compose Multiplatform – August 2025 Update",
        "link": "https://blog.jetbrains.com/kotlin/2025/08/kmp-roadmap-aug-2025/",
        "pubDate": "Mon, 25 Aug 2025 18:47:41 +0000",
        "content:encodedSnippet": "This post outlines our priorities and the general direction for our Kotlin Multiplatform and Compose Multiplatform projects over the next six to twelve months. Our goals for Kotlin Multiplatform are closely aligned with those detailed in the Kotlin roadmap. Be sure to check it out for more context around the direction we’re heading.\nKey priorities\nKotlin Multiplatform spans many areas, from language features and target-specific compilation to our IDE plugin. It’s a lot to track, so here are the three key priorities that guide our work:\n\n\n\n\n\nMake the iOS target a pleasure to work with\nWhile the iOS target matures, the developer experience still has room for improvement. Build speed remains a common Kotlin/Native concern, so we’re addressing it by fixing key issues to speed up builds across project types. We’ll also continue developing the experimental Swift Export feature to provide a better experience when calling Kotlin code from Swift.\n\n\n\n\nEnable more use cases for the web targets\nKotlin/JS already powers robust web apps, and Kotlin/Wasm is on track to be able to do the same soon. By promoting Compose for Web and Kotlin/Wasm to Beta, we expect to see pioneers starting to ship small- to medium-sized apps to production. We’re also enhancing JavaScript export to improve business logic sharing across platforms.\n\n\n\n\nImprove the developer experience in the IDE\nFollowing the first release of the Kotlin Multiplatform plugin earlier this year, we’re working to expand support with Windows and Linux versions, improved Swift integration, and essential web tooling. Our goal is to make IntelliJ IDEA and Android Studio exceptional environments for multiplatform development.\nCompose Multiplatform\nRelease Compose Multiplatform for Web in Beta\nThis Beta version embodies our commitment to support and evolve the existing APIs of Compose Multiplatform for Web. Most essential APIs will be available, enabling early adopters to confidently move to production with the existing feature set. After this Beta release, we will keep working on the remaining Compose APIs and further performance improvements. We heavily depend on your feedback, so please reach out on the Kotlinlang slack or report any issues on YouTrack.\nMake more ecosystem components available for Compose Multiplatform\nGoogle has developed excellent Jetpack libraries, which are already available for Android. We’re collaborating closely with Google to make more Jetpack libraries, such as Navigation 3 and Paging 3, available for Compose Multiplatform.\nImplement new text input on iOS \nThis new text input implementation provides a more native appearance and behavior. Additionally, it encompasses features like selection, magnification, integration with writing tools and text toolbar actions such as AutoFill and Passwords.\nCommonize Compose @Preview annotations\nOur goal is to simplify the use of @Preview annotations. Currently, there are three distinct @Preview annotations across different packages, making it challenging to determine the correct combination of annotation, platform, and IDE. \nKotlin Multiplatform IDE plugin\nSupport for Windows and Linux in the Kotlin Multiplatform IDE plugin\nWe’ve heard your requests and will be releasing the Kotlin Multiplatform plugin for Windows and Linux as well. On these platforms, you’ll be able to create KMP projects with the wizard, rely on preflight checks, use Compose Hot Reload and easily run apps for Android, web, desktop, and server. Due to Apple tooling restrictions, Swift support and iOS run configs won’t be available.\nImprove the Swift development experience with the Kotlin Multiplatform IDE plugin\nWe’re targeting several key improvements for Swift development:\nThe generated Kotlin code for Apple frameworks will be extended with documentation.\nThe quick documentation (QuickDoc) feature will be improved to consistently display documentation for Swift or Objective-C libraries imported through cinterop. \nSupport for Swift 6.2 and Xcode 26 will be added.\nWe’ll improve more advanced features like renaming, cross-navigation, and finding usages across languages. \nGeneral and quality improvements\nWe’re improving the KMP project wizard to better support both application and library developers.\nIntegrate web target workflows, including the JavaScript debugger, run configurations, and more options in the KMP project wizard.\nFor Compose Previews, we’re investing in better error reporting, automatic inspections, and analytics to improve reliability.\nUpgrading dependencies shouldn’t be a guessing game. We plan to introduce and maintain a compatibility matrix to clarify which IDE, Gradle plugin, and library versions work well together.\nKotlin/Native\nReducing Kotlin/Native build times \nTo reduce Kotlin/Native build times, we’re working on multiple areas:\nWe’re extending our performance analysis of all compilation phases across real-world projects, helping us identify and prevent regressions. \nWe’re optimizing the compiler internals, focusing specifically on build speed. \nLastly, we will replace the frequently misused kotlin.native.cacheKind property with a safer alternative to avoid unintentional build slowdowns.\nContinued development of Swift Export\nIn the short term, our goal for Swift Export is to match the capabilities you already have with Objective-C export. In addition, we plan to add built-in support for suspend functions and Flow in Swift Export, supporting concurrency on Apple platforms. In 2026, we aim for a stable release covering most features essential for idiomatic interoperability between Swift and Kotlin.\nKotlin/JS\nFallback to Kotlin/JS for Compose for Web\nAs part of the Compose for Web Beta, we will be introducing a compatibility mode using Kotlin/JS as a fallback. This broadens browser support for Compose for Web, which defaults to Kotlin/Wasm for performance. The fallback allows apps to run on older browsers that don’t support modern Wasm features like garbage collection or exception handling.\nExtending the capabilities of JavaScript Export\nWe’re improving how Kotlin declarations are exported to and consumed from JavaScript:\nExporting suspend functions (KT-56281)\nExporting value classes (KT-72198)\nExporting typealiases (KT-49795)\nAdding documentation to generated .d.ts files (KT-56493)\nAllowing Kotlin interfaces to be implemented from TypeScript\nKotlin/Wasm\nBeta release of the Kotlin/Wasm target\nTo promote Kotlin/Wasm to Beta, we aim to:\nImplement numerous compiler fixes focused on semantics and the developer experience\nReview and improve the quality of the standard library for Wasm\nAdd experimental annotations to interop APIs\nIntroduce toolchain improvements:\n\nProject sources will be served by default during development\nToolchain npm dependencies will be isolated from project dependencies\nSupport for multi-module compilation\nWe’re adding multi-module compilation support in Kotlin/Wasm to enable dynamic loading, plugin systems, and better build performance. This allows applications to load UI components on demand and benefit from improved caching and parallelization at build time.\nBuild tooling\nMaking Gradle build configurations more beginner friendly\nGradle is powerful but often overwhelming. To make KMP easier for beginners, we’ll allow dependencies to be declared at the project level and automatically propagate to all source sets, like in JVM and Android projects. We’re also working on a prototype for a new declarative Kotlin-based Gradle DSL via an ecosystem plugin to simplify build scripts and improve IDE support.\nReducing the effort to publish KMP libraries\nWe’re stabilizing klib cross-compilation across platforms, enabling you to build your library on continuous integration platforms without requiring macOS machines. We’re also simplifying the dependencies model and layout by removing unused features like partial downloads and multi-host publishing. Together, these changes will make multiplatform libraries easier to publish, consume, and integrate with third-party tools.\nProviding a Build tools API\nWe’re developing the Kotlin Build tools API as a unified entry point for build systems to integrate with Kotlin. This will reduce duplicated work, align feature behavior across tools, and make adding new build systems like Bazel or Buck much easier. \nFaster builds and imports with Gradle\nWe’re adding support for Gradle’s experimental Isolated Projects mode enabling parallel configuration for faster builds on large projects. We’re also aware of imports being rather slow and resource heavy. We will refine our benchmarks and fix bottlenecks, which should result in a smoother development experience.\nDocumentation and onboarding\nLearning a new technology can be challenging, but good guidance makes the path easier. Our current documentation focuses on beginners and basic scenarios, so we’ll expand it to cover real-world migrations of existing Android apps to Kotlin and Compose Multiplatform. With Klibs.io, we’re also making it easier to find the right libraries, which we’ll continue to develop and integrate into our guidance.",
        "dc:creator": "Ekaterina Petrova",
        "content": "This post outlines our priorities and the general direction for our Kotlin Multiplatform and Compose Multiplatform projects over the next six to twelve months. Our goals for Kotlin Multiplatform are closely aligned with those detailed in the Kotlin roadmap. Be sure to check it out for more context around the direction we&#8217;re heading. Key priorities [&#8230;]",
        "contentSnippet": "This post outlines our priorities and the general direction for our Kotlin Multiplatform and Compose Multiplatform projects over the next six to twelve months. Our goals for Kotlin Multiplatform are closely aligned with those detailed in the Kotlin roadmap. Be sure to check it out for more context around the direction we’re heading. Key priorities […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=593433",
        "categories": [
          "multiplatform",
          "kotlin-multiplatform"
        ],
        "isoDate": "2025-08-25T18:47:41.000Z"
      },
      {
        "creator": "Cheuk Ting Ho",
        "title": "Fine-Tuning and Deploying GPT Models Using Hugging Face Transformers",
        "link": "https://blog.jetbrains.com/pycharm/2025/08/fine-tuning-and-deploying-gpt-models-using-hugging-face-transformers/",
        "pubDate": "Mon, 25 Aug 2025 11:01:26 +0000",
        "content:encodedSnippet": "Hugging Face is currently a household name for machine learning researchers and enthusiasts. One of their biggest successes is Transformers, a model-definition framework for machine learning models in text, computer vision, audio, and video. Because of the vast repository of state-of-the-art machine learning models available on the Hugging Face Hub and the compatibility of Transformers with the majority of training frameworks, it is widely used for inference and model training.\nWhy do we want to fine-tune an AI model?\nFine-tuning AI models is crucial for tailoring their performance to specific tasks and datasets, enabling them to achieve higher accuracy and efficiency compared to using a general-purpose model. By adapting a pre-trained model, fine-tuning reduces the need for training from scratch, saving time and resources. It also allows for better handling of specific formats, nuances, and edge cases within a particular domain, leading to more reliable and tailored outputs.\nIn this blog post, we will fine-tune a GPT model with mathematical reasoning so it better handles math questions.\nUsing models from Hugging Face\nWhen using PyCharm, we can easily browse and add any models from Hugging Face. In a new Python file, from the Code menu at the top, select Insert HF Model.\n\n\n\n\nIn the menu that opens, you can browse models by category or start typing in the search bar at the top. When you select a model, you can see its description on the right.\n\n\n\n\nWhen you click Use Model, you will see a code snippet added to your file. And that’s it – You’re ready to start using your Hugging Face model.\n\n\n\n\nGPT (Generative Pre-Trained Transformer) models\nGPT models are very popular on the Hugging Face Hub, but what are they? GPTs are trained models that understand natural language and generate high-quality text. They are mainly used in tasks related to textual entailment, question answering, semantic similarity, and document classification. The most famous example is ChatGPT, created by OpenAI.\nA lot of OpenAI GPT models are available on the Hugging Face Hub, and we will learn how to use these models with Transformers, fine-tune them with our own data, and deploy them in an application.\nBenefits of using Transformers\nTransformers, together with other tools provided by Hugging Face, provides high-level tools for fine-tuning any sophisticated deep learning model. Instead of requiring you to fully understand a given model’s architecture and tokenization method, these tools help make models “plug and play” with any compatible training data, while also providing a large amount of customization in tokenization and training.\nTransformers in action\nTo get a closer look at Transformers in action, let’s see how we can use it to interact with a GPT model.\nInference using a pretrained model with a pipeline\nAfter selecting and adding the OpenAI GPT-2 model to the code, this is what we’ve got:\nfrom transformers import pipeline\n\n\npipe = pipeline(\"text-generation\", model=\"openai-community/gpt2\")\nBefore we can use it, we need to make a few preparations. First, we need to install a machine learning framework. In this example, we chose PyTorch. You can install it easily via the Python Packages window in PyCharm.\n\n\n\n\nThen we need to install Transformers using the `torch` option. You can do that by using the terminal – open it using the button on the left or use the ⌥ F12 (MacOS) or Alt + F12 (Windows) hotkey.\n\n\n\n\nIn the terminal, since we are using uv, we use the following commands to add it as a dependency and install it:\nuv add “transformers[torch]”\nuv sync\nIf you are using pip:\npip install “transformers[torch]”\nWe will also install a couple more libraries that we will need later, including python-dotenv, datasets, notebook, and ipywidgets. You can use either of the methods above to install them.\nAfter that, it may be best to add a GPU device to speed up the model. Depending on what you have on your machine, you can add it by setting the device parameter in pipeline. Since I am using a Mac M2 machine, I can set device=\"mps\" like this:\npipe = pipeline(\"text-generation\", model=\"openai-community/gpt2\", device=\"mps\")\nIf you have CUDA GPUs you can also set device=\"cuda\".\nNow that we’ve set up our pipeline, let’s try it out with a simple prompt:\nfrom transformers import pipeline\n\n\npipe = pipeline(\"text-generation\", model=\"openai-community/gpt2\", device=\"mps\")\n\n\nprint(pipe(\"A rectangle has a perimeter of 20 cm. If the length is 6 cm, what is the width?\", max_new_tokens=200))\nRun the script with the Run button () at the top:\n\n\n\n\nThe result will look something like this:\n[{'generated_text': 'A rectangle has a perimeter of 20 cm. If the length is 6 cm, what is the width?\\n\\nA rectangle has a perimeter of 20 cm. If the length is 6 cm, what is the width? A rectangle has a perimeter of 20 cm. If the width is 6 cm, what is the width? A rectangle has a perimeter of 20 cm. If the width is 6 cm, what is the width? A rectangle has a perimeter of 20 cm. If the width is 6 cm, what is the width?\\n\\nA rectangle has a perimeter of 20 cm. If the width is 6 cm, what is the width? A rectangle has a perimeter of 20 cm. If the width is 6 cm, what is the width? A rectangle has a perimeter of 20 cm. If the width is 6 cm, what is the width? A rectangle has a perimeter of 20 cm. If the width is 6 cm, what is the width?\\n\\nA rectangle has a perimeter of 20 cm. If the width is 6 cm, what is the width? A rectangle has a perimeter'}]\nThere isn’t much reasoning in this at all, only a bunch of nonsense. \nYou may also see this warning:\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThis is the default setting.You can also manually add it as below, so this warning disappears, but we don’t have to worry about it too much at this stage.\nprint(pipe(\"A rectangle has a perimeter of 20 cm. If the length is 6 cm, what is the width?\", max_new_tokens=200, pad_token_id=pipe.tokenizer.eos_token_id))\nNow that we’ve seen how GPT-2 behaves out of the box, let’s see if we can make it better at math reasoning with some fine-tuning.\nLoad and prepare a dataset from the Hugging Face Hub\nBefore we work on the GPT model, we first need training data. Let’s see how to get a dataset from the Hugging Face Hub.\nIf you haven’t already, sign up for a Hugging Face account and create an access token. We only need a `read` token for now. Store your token in a `.env` file, like so:\nHF_TOKEN=your-hugging-face-access-token\nWe will use this Math Reasoning Dataset, which has text describing some math reasoning. We will fine-tune our GPT model with this dataset so it can solve math problems more effectively.\nLet’s create a new Jupyter notebook, which we’ll use for fine-tuning because it lets us run different code snippets one by one and monitor the progress.\nIn the first cell, we use this script to load the dataset from the Hugging Face Hub:\nfrom datasets import load_dataset\nfrom dotenv import load_dotenv\nimport os\n\n\nload_dotenv()\ndataset = load_dataset(\"Cheukting/math-meta-reasoning-cleaned\", token=os.getenv(\"HF_TOKEN\"))\ndataset\nRun this cell (it may take a while, depending on your internet speed), which will download the dataset. When it’s done, we can have a look at the result:\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'text', 'token_count'],\n        num_rows: 987485\n    })\n})\n\n\n\n\nIf you are curious and want to have a peek at the data, you can do so in PyCharm. Open the Jupyter Variables window using the button on the right:\n\n\n\n\nExpand dataset and you will see the View as DataFrame option next to dataset[‘train’]:\n\n\n\n\nClick on it to take a look at the data in the Data View tool window:\n\n\n\n\nNext, we will tokenize the text in the dataset:\nfrom transformers import GPT2Tokenizer\n\n\ntokenizer = GPT2Tokenizer.from_pretrained(\"openai-community/gpt2\")\ntokenizer.pad_token = tokenizer.eos_token\n\n\ndef tokenize_function(examples):\n   return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=512)\n\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\nHere we use the GPT-2 tokenizer and set the pad_token to be the eos_token, which is the token indicating the end of line. After that, we will tokenize the text with a function. It may take a while the first time you run it, but after that it will be cached and will be faster if you have to run the cell again.\nThe dataset has almost 1 million rows for training. If you have enough computing power to process all of them, you can use them all. However, in this demonstration we’re training locally on a laptop, so I’d better only use a small portion!\ntokenized_datasets_split = tokenized_datasets[\"train\"].shard(num_shards=100, index=0).train_test_split(test_size=0.2, shuffle=True)\ntokenized_datasets_split\nHere I take only 1% of the data, and then perform train_test_split to split the dataset into two:\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'text', 'token_count', 'input_ids', 'attention_mask'],\n        num_rows: 7900\n    })\n    test: Dataset({\n        features: ['id', 'text', 'token_count', 'input_ids', 'attention_mask'],\n        num_rows: 1975\n    })\n})\n\n\n\n\nNow we are ready to fine-tune the GPT-2 model.\nFine-tune a GPT model\nIn the next empty cell, we will set our training arguments:\nfrom transformers import TrainingArguments\ntraining_args = TrainingArguments(\n   output_dir='./results',\n   num_train_epochs=5,\n   per_device_train_batch_size=8,\n   per_device_eval_batch_size=8,\n   warmup_steps=100,\n   weight_decay=0.01,\n   save_steps = 500,\n   logging_steps=100,\n   dataloader_pin_memory=False\n)\nMost of them are pretty standard for fine-tuning a model. However, depending on your computer setup, you may want to tweak a few things:\nBatch size – Finding the optimal batch size is important, since the larger the batch size is, the faster the training goes. However, there is a limit to how much memory is available for your CPU or GPU, so you may find there’s an upper threshold.\nEpochs – Having more epochs causes the training to take longer. You can decide how many epochs you need.\nSave steps – Save steps determine how often a checkpoint will be saved to disk. If the training is slow and there is a chance that it will stop unexpectedly, then you may want to save more often ( set this value lower).\n After we’ve configured our settings, we will put the trainer together in the next cell:\nfrom transformers import Trainer, DataCollatorForLanguageModeling\n\n\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n\n\ntrainer = Trainer(\n   model=model,\n   args=training_args,\n   train_dataset=tokenized_datasets_split['train'],\n   eval_dataset=tokenized_datasets_split['test'],\n   data_collator=data_collator,\n)\n\n\ntrainer.train(resume_from_checkpoint=False)\nWe set `resume_from_checkpoint=False`, but you can set it to `True` to continue from the last checkpoint if the training is interrupted.\nAfter the training finishes, we will evaluate and save the model:\ntrainer.evaluate(tokenized_datasets_split['test'])\ntrainer.save_model(\"./trained_model\")\nWe can now use the trained model in the pipeline. Let’s switch back to `model.py`, where we have used a pipeline with a pretrained model:\nfrom transformers import pipeline\n\n\npipe = pipeline(\"text-generation\", model=\"openai-community/gpt2\", device=\"mps\")\n\n\nprint(pipe(\"A rectangle has a perimeter of 20 cm. If the length is 6 cm, what is the width?\", max_new_tokens=200, pad_token_id=pipe.tokenizer.eos_token_id))\nNow let’s change `model=”openai-community/gpt2″` to `model=”./trained_model”` and see what we get:\n[{'generated_text': \"A rectangle has a perimeter of 20 cm. If the length is 6 cm, what is the width?\\nAlright, let me try to solve this problem as a student, and I'll let my thinking naturally fall into the common pitfall as described.\\n\\n---\\n\\n**Step 1: Attempting the Problem (falling into the pitfall)**\\n\\nWe have a rectangle with perimeter 20 cm. The length is 6 cm. We want the width.\\n\\nFirst, I need to find the area under the rectangle.\\n\\nLet’s set \\\\( A = 20 - 12 \\\\), where \\\\( A \\\\) is the perimeter.\\n\\n**Area under a rectangle:**  \\n\\\\[\\nA = (20-12)^2 + ((-12)^2)^2 = 20^2 + 12^2 = 24\\n\\\\]\\n\\nSo, \\\\( 24 = (20-12)^2 = 27 \\\\).\\n\\nNow, I’ll just divide both sides by 6 to find the area under the rectangle.\\n\"}]\nUnfortunately, it still does not solve the problem. However, it did come up with some mathematical formulas and reasoning that it didn’t use before. If you want, you can try fine-tuning the model a bit more with the data we didn’t use.\nIn the next section, we will see how we can deploy a fine-tuned model to API endpoints using both the tools provided by Hugging Face and FastAPI.\nDeploying a fine-tuned model\nThe easiest way to deploy a model in a server backend is to use FastAPI. Previously, I wrote a blog post about deploying a machine learning model with Fast API. While we won’t go into the same level of detail here, we will go over how to deploy our fine-tuned model.\nWith the help of Junie, we’ve created some scripts which you can see here. These scripts let us deploy a server backend with FastAPI endpoints. \nThere are some new dependencies that we need to add:\nuv add fastapi pydantic uvicorn\nuv sync\nLet’s have a look at some interesting points in the scripts, in `main.py`:\n# Initialize FastAPI app\napp = FastAPI(\n   title=\"Text Generation API\",\n   description=\"API for generating text using a fine-tuned model\",\n   version=\"1.0.0\"\n)\n\n\n# Initialize the model pipeline\ntry:\n   pipe = pipeline(\"text-generation\", model=\"../trained_model\", device=\"mps\")\nexcept Exception as e:\n   # Fallback to CPU if MPS is not available\n   try:\n       pipe = pipeline(\"text-generation\", model=\"../trained_model\", device=\"cpu\")\n   except Exception as e:\n       print(f\"Error loading model: {e}\")\n       pipe = None\nAfter initializing the app, the script will try to load the model into a pipeline. If a Metal GPU is not available, it will fall back to using the CPU. If you have a CUDA GPU instead of a Metal GPU, you can change `mps` to `cuda`.\n# Request model\nclass TextGenerationRequest(BaseModel):\n   prompt: str\n   max_new_tokens: int = 200\n  \n# Response model\nclass TextGenerationResponse(BaseModel):\n   generated_text: str\nTwo new classes are created, inheriting from Pydantic’s `BaseModel`.\nWe can also inspect our endpoints with the Endpoints tool window. Click on the globe next to `app = FastAPI` on line 11 and select Show All Endpoints.\n\n\n\n\nWe have three endpoints. Since the root endpoint is just a welcome message, we will look at the other two.\n@app.post(\"/generate\", response_model=TextGenerationResponse)\nasync def generate_text(request: TextGenerationRequest):\n   \"\"\"\n   Generate text based on the provided prompt.\n  \n   Args:\n       request: TextGenerationRequest containing the prompt and generation parameters\n      \n   Returns:\n       TextGenerationResponse with the generated text\n   \"\"\"\n   if pipe is None:\n       raise HTTPException(status_code=500, detail=\"Model not loaded properly\")\n  \n   try:\n       result = pipe(\n           request.prompt,\n           max_new_tokens=request.max_new_tokens,\n           pad_token_id=pipe.tokenizer.eos_token_id\n       )\n      \n       # Extract the generated text from the result\n       generated_text = result[0]['generated_text']\n      \n       return TextGenerationResponse(generated_text=generated_text)\n   except Exception as e:\n       raise HTTPException(status_code=500, detail=f\"Error generating text: {str(e)}\")\n\n\n\n\nThe `/generate` endpoint collects the request prompt and generates the response text with the model.\n@app.get(\"/health\")\nasync def health_check():\n   \"\"\"Check if the API and model are working properly.\"\"\"\n   if pipe is None:\n       raise HTTPException(status_code=500, detail=\"Model not loaded\")\n   return {\"status\": \"healthy\", \"model_loaded\": True}\nThe `/health` endpoint checks whether the model is loaded correctly. This can be useful if the client-side application needs to check before making the other endpoint available in its UI.\nIn `run.py`, we use uvicorn to run the server:\nimport uvicorn\n\n\nif __name__ == \"__main__\":\n   uvicorn.run(\"main:app\", host=\"0.0.0.0\", port=8000, reload=True)\nWhen we run this script, the server will be started at http://0.0.0.0:8000/.\nAfter we start running the server, we can go to http://0.0.0.0:8000/docs to test out the endpoints. \n\nWe can try this with the `/generate` endpoint:\n{\n  \"prompt\": \"5 people give each other a present. How many presents are given altogether?\",\n  \"max_new_tokens\": 300\n}\nThis is the response we get:\n{\n  \"generated_text\": \"5 people give each other a present. How many presents are given altogether?\\nAlright, let's try to solve the problem:\\n\\n**Problem**  \\n1. Each person gives each other a present. How many presents are given altogether?\\n2. How many \\\"gift\\\" are given altogether?\\n\\n**Common pitfall**  \\nAssuming that each present is a \\\"gift\\\" without considering the implications of the original condition.\\n\\n---\\n\\n### Step 1: Attempting the problem (falling into the pitfall)\\n\\nOkay, so I have two people giving each other a present, and I want to know how many are present. I remember that there are three types of gifts—gifts, gins, and ginses.\\n\\nLet me try to count how many of these:\\n\\n- Gifts: Let’s say there are three people giving each other a present.\\n- Gins: Let’s say there are three people giving each other a present.\\n- Ginses: Let’s say there are three people giving each other a present.\\n\\nSo, total gins and ginses would be:\\n\\n- Gins: \\\\( 2 \\\\times 3 = 1 \\\\), \\\\( 2 \\\\times 1 = 2 \\\\), \\\\( 1 \\\\times 1 = 1 \\\\), \\\\( 1 \\\\times 2 = 2 \\\\), so \\\\( 2 \\\\times 3 = 4 \\\\).\\n- Ginses: \\\\( 2 \\\\times 3 = 6 \\\\), \\\\(\"\n}\n\n\n\n\n\n\n\n\nFeel free to experiment with other requests.\nConclusion and next steps\nNow that you have successfully fine-tuned an LLM model like GPT-2 with a math reasoning dataset and deployed it with FastAPI, you can fine-tune a lot more of the open-source LLMs available on the Hugging Face Hub. You can experiment with fine-tuning other LLM models with either the open-source data there or your own datasets. If you want to (and the license of the original model allows), you can also upload your fine-tuned model on the Hugging Face Hub. Check out their documentation for how to do that.\nOne last remark regarding using or fine-tuning models with resources on the Hugging Face Hub – make sure to read the licenses of any model or dataset that you use to understand the conditions for working with those resources. Is it allowed to be used commercially? Do you need to credit the resources used?\nIn future blog posts, we will keep exploring more code examples involving Python, AI, machine learning, and data visualization.\nIn my opinion, PyCharm provides best-in-class Python support that ensures both speed and accuracy. Benefit from the smartest code completion, PEP 8 compliance checks, intelligent refactorings, and a variety of inspections to meet all your coding needs. As demonstrated in this blog post, PyCharm provides integration with the Hugging Face Hub, allowing you to browse and use models without leaving the IDE. This makes it suitable for a wide range of AI and LLM fine-tuning projects.\nDownload PyCharm Now",
        "dc:creator": "Cheuk Ting Ho",
        "content": "Hugging Face is currently a household name for machine learning researchers and enthusiasts. One of their biggest successes is Transformers, a model-definition framework for machine learning models in text, computer vision, audio, and video. Because of the vast repository of state-of-the-art machine learning models available on the Hugging Face Hub and the compatibility of Transformers [&#8230;]",
        "contentSnippet": "Hugging Face is currently a household name for machine learning researchers and enthusiasts. One of their biggest successes is Transformers, a model-definition framework for machine learning models in text, computer vision, audio, and video. Because of the vast repository of state-of-the-art machine learning models available on the Hugging Face Hub and the compatibility of Transformers […]",
        "guid": "https://blog.jetbrains.com/?post_type=pycharm&p=592844",
        "categories": [
          "data-science",
          "how-tos",
          "gpt",
          "hugging-face",
          "machine-learning"
        ],
        "isoDate": "2025-08-25T11:01:26.000Z"
      },
      {
        "creator": "Alina Dolgikh",
        "title": "Kotlin on the Backend – What’s New From KotlinConf 2025",
        "link": "https://blog.jetbrains.com/kotlin/2025/08/kotlin-on-the-backend-what-s-new-from-kotlinconf-2025/",
        "pubDate": "Fri, 22 Aug 2025 15:02:47 +0000",
        "content:encodedSnippet": "KotlinConf 2025 has firmly placed server-side Kotlin in the spotlight, and rightly so. Between Spring collaboration, an upgraded ecosystem, performance boosts, AI tooling, and the adoption of the language by big companies, this is Kotlin at its (backend) best. Here’s a breakdown of what was announced, what’s new, and what you absolutely must check out from the recordings of the server-side talks at KotlinConf 2025.\nThe biggest news was traditionally covered in the keynote and followed up by talks over two days. \nOne of the revelations from the keynote that received many positive reactions was that half of Kotlin users are using the language for backend development. This isn’t a sudden shift but something we have observed over the years in the past Kotlin Census and Developer Ecosystem reports.\nCheck out why developers continue to choose Kotlin for the backend in 2025 in the teaser video linked below, in which engineers from five major tech companies share their Kotlin journeys.\n\n\n\n\n\n\nThe full stories will be published soon on the Kotlin YouTube channel. \nA Strategic Partnership With Spring\nThe JetBrains and Spring teams announced a strategic partnership. The roadmap highlights include a complete null-safety guarantee for Kotlin and Spring apps, official Kotlin‑centric Spring tutorials and documentation, enhanced reflection performance using kotlinx.reflect, and evolving configuration DSLs.\nTwo sessions provided a deeper look into the world of Kotlin and Spring and its upcoming directions for development.\nRod Johnson, Spring’s original creator, spoke on why Kotlin with Spring delivers faster development with better maintainability. Spring Framework core committer Sébastien Deleuze presented updates in Spring Boot 4 that further refine Kotlin support, from annotation processing to coroutine integration.\n\n\n\n\n\n\n\n\n\n\n\n\n\nKtor: Built for Modern Scalable Backends\nKtor continues to evolve into a powerful, modern framework for scalable applications. The recent update introduced built-in support for dependency injection with coroutine-based lifecycle management, and a new HTMX module for smoother server-driven UI development. Other notable additions include support for suspendable application modules, Unix domain sockets for the CIO engine, and a Gradle version catalog for easier dependency management. \nCurrently, the team is working on the API documentation, starting with OpenAPI support.\nFor those working with Ktor (or planning to), these talks are must-watches:\n\n\n\n\n\n\n🎥 TalkPresenterWhy It Matters\nSimplifying Full-Stack Kotlin: A Fresh Take With HTMX and KtorAnders SveenChallenge the modern full-stack complexity and see how to build dynamic web apps with Ktor, HTMX, and kotlinx.html without SPA overhead.\nCoroutines and Structured Concurrency in KtorSimon VergauwenMaster robust and maintainable asynchronous patterns in real-world Ktor services.\nEvent-Driven Analytics: Building Real-Time Dashboards With Apache Flink and KtorViktor GamovLearn how to move beyond REST by using Apache Flink and Ktor to build real-time analytics dashboards with reactive, event-driven architecture. \n\n\n\n\n\nKotlin and AI with Koog, Mellum, and Junie\nJetBrains introduced a trio of AI tools designed for Kotlin development, including practical support for server-side tasks.\nKoog – a Kotlin-based framework designed to build and run AI agents entirely in idiomatic Kotlin. \nMellum – the JetBrains’ in-house LLM, which is now open-sourced and fine-tuned for code generation and intelligent assistance.\nJunie – the JetBrains AI coding agent integrated in your favorite IDE and able to target complex Kotlin development across server, mobile, and web domains. It’s now available in GitHub as part of the Early Access Program. Join the waitlist to try it for free.\n\n🎥 TalkPresenterWhy It Matters\nBuilding AI Agents in Kotlin with Koog Vadim BriliantovAn overview of AI agents, their building blocks, workflows, and how to build them effectively in Kotlin from the JetBrains AI Agents Platform tech lead.\nKotlin’s Gam[e]bit: LLM-less AI for Board GamesDmitro KuretsDiscover how Kotlin can power AI without relying on large language models.\nFrom 0 to h-AI-ro: high-speed track to AI for Kotlin developersUrs PeterThis talk gives you a clear and practical understanding of key terminology, concepts, and frameworks relevant to the Kotlin ecosystem in the world of AI\nBuilding an Agentic Platform with Kotlin: Powering one of Europe’s Largest LLM BotPatrick WhelanA look at some of the design decisions of the Arc framework, an open-sourced Kotlin-based AI framework, which will provide you with an understanding of the challenges in building an LLM application at this scale\nLangChain4j With QuarkusMax Rydahl Andersen, Konstantin PavlovThe talk explores tools integration, dependencies management, and Kotlin’s idiomatic features, helping to simplify AI workflows.\n\n\n\n\n\nA New Milestone: Exposed 1.0\nAfter substantial restructuring, Exposed 1.0 (now in Beta) delivers on its promise of a type‑safe, expressive, and idiomatic Kotlin SQL library. \nWith added support for full R2DBC, enabling non-blocking database operations through suspending functions and flows, new SQL features, improved onboarding materials, and a new IDE plugin, it removes friction from database operations while enhancing safety and maintainability. \nChantale Loncle’s talk dives into the details of what’s new and what’s next. Check it out below.\n\n\n\n\n\n\nWin With Kotlin Notebook\nRoman Belov, the lead of Kotlin Moonshots projects, shared a fun yet practical example of Kotlin Notebook in action: finding the longest possible sailing route in 24 hours without repeating waypoints. With Kotlin Notebook, even complex logic becomes intuitive and visual. Watch the talk to learn the full story!\n\n\n\n\n\n\nhttp4k: Pure Kotlin, Protocol Agnostic\nThe talk Full Stream Ahead: Breaking Protocol Barriers With http4k showcased a fully functional, coroutine-based approach to server-side development that sidesteps servlets entirely. It emphasized composability, lightweight design, and streaming I/O with functional purity.\n\n\n\n\n\n\nOther Server-Side-Related Talks\n\n🎥 TalkPresenterWhy It Matters\nThat’s Unpossible – A Full-Stack Side Project Webapp (Including a High-Fidelity UI!) All in Kotlin\nDan KimA practical walkthrough of building a fully functional web app entirely in Kotlin, from backend to high-fidelity UI.\n\nIoT Development With KotlinErik HellmanA hands-on look at building IoT applications using Kotlin, with key technologies and integration strategies.\nTaming Asynchronous Beasts: Debugging and Performance Tuning in a Coroutine World\nMarcin MoskałaAn expert-level deep dive into coroutine debugging and performance tuning from the author of Kotlin Coroutines: Deep Dive.\n\nKotlin Multiplatform’s Cross-Platform Brilliance at Norway’s 377-Year-Old National Postal ServiceAnshika KoulA real-world case study of Posten Bring, detailing how the national postal service used Kotlin on all platforms to modernize logistics at scale.\nKotlin Clean Architecture for Serverless: Business Logic You Can Take AnywhereElena van EngelenA clean architecture approach to structuring serverless Kotlin apps, focused on portable business logic across cloud providers.\nFrom Data to Insights: Building a Bluesky Bot powered by AIRaphael De LioHow to quickly collect, process, and analyze data using Kotlin – demonstrated via a Bluesky bot that extracts insights from real-time streams.\n\n\n\n\n\nThat wraps up our curated list of backend-focused talks at KotlinConf 2025. Explore them all via the conference website or mobile app, and share your favorites with the community.\nKotlin’s Backend Momentum\nKotlinConf 2025 made it unmistakably clear: Kotlin continues to thrive in server-side development. It’s pragmatic, loved by engineers, and increasingly adopted across infrastructures and domains from Spring and Flink to Kafka and serverless platforms. Much of this progress is powered by exceptional tooling from JetBrains, including intelligent IDE support and new AI integrations. \nThat being said, the biggest engine behind Kotlin’s evolution is the community: library maintainers, open-source contributors, companies scaling Kotlin in production, and speakers sharing hard-earned lessons. Thank you all very much, we wouldn’t be where we are without you!\nIf you’re evaluating Kotlin for backend development in 2025, now’s the time to give it a serious look. And if you’re already building with Kotlin – thank you! You’re shaping the future of a language that grows stronger with every contribution.",
        "dc:creator": "Alina Dolgikh",
        "content": "KotlinConf 2025 has firmly placed server-side Kotlin in the spotlight, and rightly so. Between Spring collaboration, an upgraded ecosystem, performance boosts, AI tooling, and the adoption of the language by big companies, this is Kotlin at its (backend) best. Here&#8217;s a breakdown of what was announced, what’s new, and what you absolutely must check out [&#8230;]",
        "contentSnippet": "KotlinConf 2025 has firmly placed server-side Kotlin in the spotlight, and rightly so. Between Spring collaboration, an upgraded ecosystem, performance boosts, AI tooling, and the adoption of the language by big companies, this is Kotlin at its (backend) best. Here’s a breakdown of what was announced, what’s new, and what you absolutely must check out […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=593682",
        "categories": [
          "community",
          "kotlinconf",
          "news",
          "server-side"
        ],
        "isoDate": "2025-08-22T15:02:47.000Z"
      }
    ]
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Rhea Patel",
        "title": "Roadmap for AI in Visual Studio (September)",
        "link": "https://devblogs.microsoft.com/visualstudio/roadmap-for-ai-in-visual-studio-september/",
        "pubDate": "Wed, 27 Aug 2025 18:02:11 +0000",
        "content:encodedSnippet": "Today, we’re excited to share our public roadmap, which outlines the next steps in evolving Visual Studio with AI-powered agentic experiences. With every month, we aim to deliver smarter, faster, and more intuitive tools that enhance your coding experience.\nDisclaimer: The items outlined here represent ongoing work for the month. They are not commitments or guarantees for delivery within the current month.\nWith that said, here is what we are working on!\nNew Modes for Debugging and Profiling: \nWe’re streamlining how you find and switch between modes and making sure both built-in and extension-provided modes can handle more complex workflows.\nTwo new agent-powered tools are in progress:\nProfiler agent\nDebugger agent \nSupporting Customization via Modes\nWe are making it seamless to integrate your workflows across your development stack into Visual Studio, tailoring them to you and your organization.\nCustom modes for Copilot Chat\nModel Context Protocol (MCP) Enabled in All Modes\nAgent Mode/Chat:                              \nWe’ve been listening to your feedback on Agent Mode and Chat, and we’re making some big improvements.\nFaster performance\nAgent Mode tool: Speed improvements for code mapping across more models\nBetter visibility\nAgent Mode Progress Indication\nAgent Mode as the default chat experience (Experiment)\nExpanding Agent Mode functionality\nAgent mode tool: run test(s) through test explorer and package search\nSmarter context retention\nProject memories for Copilot Chat\nPlanning/To dos in Copilot Chat\nInstruction file support for Copilot Chat\nMore control\nAllow Disabling Built-In Tools\nRedirect Agent Mode Mid Response\n \nModel Context Proctol (MCP) \nWe want you to bring your entire development stack into Visual Studio, supported by the same security, governance, and trust you expect from our product. To make this possible, we’re expanding support for these capabilities and making them easier to use.\nSupport Prompt\nSupport Resources\nSupport Sampling\nRegistry support for browsing and installing MCP servers\nEnabling governance to support allowlists for MCP servers\nModels\nWe’re committed to giving you access to the latest models, and in Visual Studio we carefully evaluate them to make sure you get the best possible experience. With the recent introduction of Bring Your Own Key, your choice of models is expanding even further.\nGitHub Copilot native support:\nClaude Opus 4.1\nGPT-5 Mini\nBring Your Own Key support:\nAzure Foundry\nCustom URLs (add your own endpoints)\n \nAzure Agentic DevOps\nWe’re bringing the power of agentic workflows and Azure-native capabilities directly into Visual Studio, so you can build, deploy, and manage your applications with the same security, governance, and trust you expect from our platform. The public preview is now available in Visual Studio 2022, featuring an automatic installation of Azure MCP for a seamless start.\nHere’s what’s coming next:\n1P Azure MCP installation in Visual Studio 2026\n\nPublishing and CI/CD (GitHub Actions & Azure DevOps) support to Azure App Service for .NET applications\nCustom modes tailored for Azure developers\nEditor improvements\nCopilot-powered code completions and suggestions in your editor are triggered effortlessly and can accelerate your daily programming. We want to deliver a smooth and intuitive experience for you when interacting with these suggestions that minimize potential conflicts.\nReceive next edit suggestions predicted based on your last edits\nCopilot keyboard shortcut to accept suggestion.\nUse Synthetic Text to Improve Copilot Completions Experiences\nTo make Visual Studio a truly AI-integrated IDE, we want to ensure that Copilot is seamlessly available at every step of your development workflow—not just for writing code, but also for searching, fixing errors, writing unit tests, and even committing and pushing your changes.\nCopilot Supported All-In-One Search Experience\nQuickly Get Copilot Assistance from Your Context Menu\nWe’re excited for you to try these new experiences soon. If you have feedback, post it in the developer community ticket linked above. For other ideas or suggestions, drop a comment below or create a new ticket—our team reviews them all.\nThanks \nThe post Roadmap for AI in Visual Studio (September) appeared first on Visual Studio Blog.",
        "dc:creator": "Rhea Patel",
        "comments": "https://devblogs.microsoft.com/visualstudio/roadmap-for-ai-in-visual-studio-september/#comments",
        "content": "<p>Today, we’re excited to share our public roadmap, which outlines the next steps in evolving Visual Studio with AI-powered agentic experiences. With every month, we aim to deliver smarter, faster, and more intuitive tools that enhance your coding experience. Disclaimer: The items outlined here represent ongoing work for the month. They are not commitments or [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/roadmap-for-ai-in-visual-studio-september/\">Roadmap for AI in Visual Studio (September)</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Today, we’re excited to share our public roadmap, which outlines the next steps in evolving Visual Studio with AI-powered agentic experiences. With every month, we aim to deliver smarter, faster, and more intuitive tools that enhance your coding experience. Disclaimer: The items outlined here represent ongoing work for the month. They are not commitments or […]\nThe post Roadmap for AI in Visual Studio (September) appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=254064",
        "categories": [
          "Copilot",
          "Visual Studio",
          "Agent",
          "Artificial Intelligence",
          "Chat",
          "Models",
          "Roadmap"
        ],
        "isoDate": "2025-08-27T18:02:11.000Z"
      },
      {
        "creator": "Mads Kristensen",
        "title": "The Visual Studio August Update is here – smarter AI, better debugging, and more control",
        "link": "https://devblogs.microsoft.com/visualstudio/the-visual-studio-august-update-is-here-smarter-ai-better-debugging-and-more-control/",
        "pubDate": "Tue, 26 Aug 2025 18:22:28 +0000",
        "content:encodedSnippet": "The August 2025 update for Visual Studio 2022 (v17.14) is now available, and it’s all about helping developers stay focused, productive, and in control. Whether you’re building games, tuning performance, or exploring AI, this release brings meaningful improvements that make everyday development smoother and smarter.\n\nGPT-5 support now available\nWe’re excited to announce that GPT-5 is now available in Visual Studio, bringing the latest advancements in AI directly to your development environment. With GPT-5 integration, you can leverage more powerful, accurate, and context-aware code suggestions and chat experiences. Whether you’re writing complex algorithms, refactoring large codebases, or brainstorming new features, GPT-5 helps you move faster and with greater confidence.\n\nConnect your entire stack with MCP\nWe’re excited to announce that MCP (Model Context Protocol) support is now generally available in Visual Studio. MCP is a powerful protocol that connects AI agents to external tools – like databases, code search, and deployment systems – without needing custom integrations for each one. Think of it as the HTTP of tool connectivity.\nWith this release, Visual Studio makes it easier than ever to manage and connect to MCP servers:\nOAuth support for any provider: Authenticate with any OAuth provider directly from Visual Studio using the new authorization spec.\nOne-click server install from the web: Add MCP servers with a single click from supported repositories – no more manual JSON editing.\nNew server add flow: Use the green plus button in the Copilot Chat tool picker to quickly configure and connect to new servers.\nGovernance controls: Organizations can now manage MCP access via GitHub policy settings for better compliance and control.\n\nThis update makes MCP a first-class experience in Visual Studio, helping teams unlock richer, real-time context across their entire engineering stack.\nSmarter Copilot Chat with better context\nCopilot Chat can now more reliably surface relevant code snippets. It now uses improved semantic code search to better identify when a query should trigger a code lookup. When that context is detected, it searches across your solution or workspace to retrieve the most relevant snippets, even from natural language descriptions, reducing the need to manually navigate your codebase.\n\nSign Up for Copilot with Google\nGetting started with Copilot is now easier than ever. You can sign up using your Google account directly from Visual Studio. It’s a fast, frictionless way to get up and running with AI-powered coding-no extra setup required.\n\nBring your own AI model to Chat\nWant more control over your AI experience? You can now connect your own language models to Visual Studio Chat using API keys from OpenAI, Google, or Anthropic. This gives you the flexibility to choose the model that best fits your workflow, whether you’re optimizing for performance, privacy, or experimentation.\n\nUnified debugging for Unreal Engine\nIf you’re working in C++ with Unreal Engine, debugging just got a major upgrade. Visual Studio now lets you debug Blueprint and native code together in a single session. You’ll see Blueprint data in the call stack and locals window, and you can even set breakpoints directly in Blueprint code.\n\nThis makes it easier to trace interactions and fix issues across both scripting layers.\nCopilot Suggestions when you want them\nPrefer a quieter editor? You can now disable automatic Copilot suggestions and trigger them manually with keyboard shortcuts. This gives you full control over when suggestions appear, helping you stay focused when you need to and get help when you want it.\nCleaner editing with collapsed suggestions\nNext Edit Suggestions (NES) are now hidden by default. Instead of popping up automatically, they appear as a subtle margin indicator when relevant. You decide when to engage, keeping your editor clean and distraction-free.\n\nAccept code completions partially\nHave you ever wanted to only accept the first couple words or lines of a Copilot code completions instead of accepting the whole thing? We are excited to announce that you will now be able to partially accept a completion word by word or line by line!\nGit context in Copilot Chat\nCopilot Chat now understands your Git history. You can reference commits and uncommitted changes directly in chat to summarize work, explain updates, or generate tests-all without leaving the editor.\n\nThis makes it easier to stay in flow while reviewing or refining your code.\nBuilt with your feedback\nMany of the features and fixes in this release come directly from the Developer Community. Your suggestions and bug reports continue to shape Visual Studio, and we’re grateful for your input. You can explore all the community-driven updates and fixes in the release notes.\nThanks again for your feedback and support. We’re excited to keep building Visual Studio with you-one update at a time. Let us know what you think, and as always, happy coding!\nThe post The Visual Studio August Update is here – smarter AI, better debugging, and more control appeared first on Visual Studio Blog.",
        "dc:creator": "Mads Kristensen",
        "comments": "https://devblogs.microsoft.com/visualstudio/the-visual-studio-august-update-is-here-smarter-ai-better-debugging-and-more-control/#comments",
        "content": "<p>The August 2025 update for Visual Studio 2022 (v17.14) is now available, and it’s all about helping developers stay focused, productive, and in control. Whether you&#8217;re building games, tuning performance, or exploring AI, this release brings meaningful improvements that make everyday development smoother and smarter. GPT-5 support now available We&#8217;re excited to announce that GPT-5 [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/the-visual-studio-august-update-is-here-smarter-ai-better-debugging-and-more-control/\">The Visual Studio August Update is here &#8211; smarter AI, better debugging, and more control</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "The August 2025 update for Visual Studio 2022 (v17.14) is now available, and it’s all about helping developers stay focused, productive, and in control. Whether you’re building games, tuning performance, or exploring AI, this release brings meaningful improvements that make everyday development smoother and smarter. GPT-5 support now available We’re excited to announce that GPT-5 […]\nThe post The Visual Studio August Update is here – smarter AI, better debugging, and more control appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=254076",
        "categories": [
          "Copilot",
          "Debug",
          "Git",
          "GitHub Copilot",
          "Productivity",
          "Visual Studio",
          "C++",
          "MCP",
          "Models",
          "Next Edits Suggestion",
          "Sign in"
        ],
        "isoDate": "2025-08-26T18:22:28.000Z"
      },
      {
        "creator": "Yun Jung Choi",
        "title": "GitHub Copilot for Azure (Preview) Launches in Visual Studio 2022 with Azure MCP Support",
        "link": "https://devblogs.microsoft.com/visualstudio/github-copilot-for-azure-preview-launches-in-visual-studio-2022-with-azure-mcp-support/",
        "pubDate": "Mon, 25 Aug 2025 18:36:28 +0000",
        "content:encodedSnippet": "The GitHub Copilot for Azure extension is now in Public Preview for Visual Studio 2022 (17.14+). It brings a curated set of Azure developer tools—exposed through the Azure MCP server—directly into GitHub Copilot Agent Mode in Visual Studio. The extension automatically installs and manages the Azure MCP server, so you can query resources, diagnose issues, deploy with azd, and run Azure CLI commands—all from the Copilot Chat.\nTry GitHub Copilot for Azure\n\nShip Azure features without leaving Visual Studio. Agent-powered, MCP-enabled, no extra setup.\n\nWhat’s in the Public Preview?\nZero-setup Azure MCP server\nThe extension automatically downloads and starts the Azure MCP server the first time you open Copilot Chat—no manual install required. (You’ll see it in the tools list in Agent Mode.)\n(Note: the MCP server version included with the extension may occasionally trail the latest upstream release by a few versions.)\nAgent Mode + Azure tools\nLet Copilot pick the right tools for your goal—or choose specific tools from the toolbox in the Copilot Chat window. Typical tasks include: list and inspect resources, diagnose issues, pull app logs, deploy with azd, run Azure CLI commands, and more.\nBroad Azure coverage via MCP tools\nThe suite of tools allows interaction with:\n Azure App Configuration\n Azure Best Practices\n Azure CLI Extension\n Azure Container Registry (ACR)\n Azure Cosmos DB (NoSQL Databases)\n Azure Data Explorer\n Azure Database for PostgreSQL – Flexible Server\n Azure Developer CLI (azd) Extension\n Azure Deploy\n Azure Function App\n Azure Key Vault\n Azure Kubernetes Service (AKS)\n Azure SQL Database, Elastic Pool, and Server\n Azure Storage\n…and many more!\nSee the full, continuously updated list in the Azure MCP server docs.\nGet started\nPrerequisites\nVisual Studio 2022 17.14 or later (Agent Mode + MCP support)\nAn active GitHub Copilot subscription and Copilot Chat enabled in Visual Studio\nA Microsoft account with access to an Azure subscription (or start free below)\nInstall & set up\nInstall the \nGitHub Copilot for Azure (Preview)\n extension for Visual Studio 2022.\nThe extension starts the Azure MCP server automatically—no manual setup required.\nOpen Copilot Chat and select Agent Mode.\n\n\n\nClick Select tools and check to enable the Azure Extension.\n\n\n\n\n\n\nIn your prompts, include resource details for best results (subscription, resource group, resource name).\nNew to Azure? Sign up free and get $200 in credit to explore services\nTry these example prompts\nThese examples assume you’re in Agent Mode with Azure tools enabled. Add subscription and resource group names where helpful.\n“Do I have any webapps in my current subscription?”\n“Look for a WebApp named `<appname>`. Does it have any recent downtime?”\n“Find what tenants I have access to and what I’m currently using.”\n“Provide the weburls for these ACA apps.”\nWhat’s next?\nWe’re committed to continuously expanding the Azure toolset and deepening the integration with Visual Studio, all on top of the robust MCP foundation that is now generally available in Visual Studio. If you’re already using GitHub Copilot, we encourage you to try out GitHub Copilot for Azure and experience the new capabilities firsthand. Your feedback is invaluable—let us know which Azure scenarios you’d like to automate next and help shape the future of GitHub Copilot for Azure!\nLearn how to share feedback in Visual Studio 2022\nAdditional learning\nModel Context Protocol (MCP) is Now Generally Available in Visual Studio  – Visual Studio Blog\nAgent mode is now generally available with MCP support – Visual Studio Blog\nCustomizing GitHub Copilot in Visual Studio with Custom Instructions (Part 5 of 8) | Microsoft Learn\nThe post GitHub Copilot for Azure (Preview) Launches in Visual Studio 2022 with Azure MCP Support appeared first on Visual Studio Blog.",
        "dc:creator": "Yun Jung Choi",
        "comments": "https://devblogs.microsoft.com/visualstudio/github-copilot-for-azure-preview-launches-in-visual-studio-2022-with-azure-mcp-support/#comments",
        "content": "<p>The GitHub Copilot for Azure extension is now in Public Preview for Visual Studio 2022 (17.14+). It brings a curated set of Azure developer tools—exposed through the Azure MCP server—directly into GitHub Copilot Agent Mode in Visual Studio. The extension automatically installs and manages the Azure MCP server, so you can query resources, diagnose issues, [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/github-copilot-for-azure-preview-launches-in-visual-studio-2022-with-azure-mcp-support/\">GitHub Copilot for Azure (Preview) Launches in Visual Studio 2022 with Azure MCP Support</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "The GitHub Copilot for Azure extension is now in Public Preview for Visual Studio 2022 (17.14+). It brings a curated set of Azure developer tools—exposed through the Azure MCP server—directly into GitHub Copilot Agent Mode in Visual Studio. The extension automatically installs and manages the Azure MCP server, so you can query resources, diagnose issues, […]\nThe post GitHub Copilot for Azure (Preview) Launches in Visual Studio 2022 with Azure MCP Support appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=253992",
        "categories": [
          "Azure",
          "Cloud",
          "Copilot",
          "Visual Studio",
          "Agent Mode",
          "agents",
          "GitHub Copilot",
          "LLM",
          "MCP",
          "microsoft",
          "Model Context Protocol",
          "Visual Studio 2022"
        ],
        "isoDate": "2025-08-25T18:36:28.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "\r\n                            Catie Keck\r\n            \t\t\t",
        "title": "Hack Week 2025: How these engineers liquid-cooled a GPU server",
        "link": "https://dropbox.tech/culture/hack-week-2025-liquid-cooling-gpu-server",
        "pubDate": "Wed, 27 Aug 2025 08:00:00 -0700",
        "content:encodedSnippet": "Hack Week 2025 at Dropbox centered on the theme “Keep It Simple,” offering opportunities for innovation, experimentation, and finding smart solutions to complex challenges. With in-person hubs in San Francisco, Seattle, and Warsaw—as well as the option to hack virtually—the July event brought together Dropbox developers to explore new ideas and build projects that could shape future products and workflows for tools like Dropbox Dash.\nOne standout effort, “Liquid Cooling CPU/GPU Hardware,” earned the Learn Fast award for accelerating learning and innovation. The team—Bobby Woolweaver, Daniel Coultas, Eddie del Rio, Eric Shobe, and Daniel Parker-Focht—designed a custom liquid cooling system for high-powered GPU servers to tackle the rising thermal demands of AI workloads. They built a lab setup, tested core components, and demonstrated significant benefits: 20–30°C lower operating temperatures under stress, quieter performance than air cooling, and the potential for power savings and environmental benefits.\nForward-looking in scope, the project explores next-generation GPU servers that may require liquid cooling due to increases in power consumption and heat generation. The team plans to expand testing with more liquid cooling labs in multiple data centers. We sat down with systems engineer Bobby Woolweaver and data center engineer Daniel Coultas to discuss their award-winning project and what it could mean for the future of infrastructure at Dropbox.\n\r\n\r\n \r\n\r\n@font-face {\r\nfont-family: 'AtlasGrotesk';\r\nsrc: url('https://cdn.prod.website-files.com/65dcd70b48edc3a7b446950e/65dce019c63112e617513c94_AtlasGrotesk-Medium-Web-vfl38XiTL.woff2') format('woff2');\r\nfont-weight: 500;\r\nfont-style: normal;\r\nfont-display: swap;\r\n}\r\n\r\n@font-face {\r\nfont-family: 'AtlasGrotesk';\r\nsrc: url('https://cdn.prod.website-files.com/65dcd70b48edc3a7b446950e/65dce019711b648fd1ccd24a_AtlasGrotesk-Regular-Web-vflk7bxjs.woff2') format('woff2');\r\nfont-weight: 400;\r\nfont-style: normal;\r\nfont-display: swap;\r\n}\r\n.xf-content-height {margin: 0;}\r\n#cta { font-family: AtlasGrotesk,sans-serif; font-size: .900rem; text-decoration: none; background: #f7f5f2; line-height: 1.69; box-sizing: border-box;}\r\n#cta-box { padding: 15px 20px 15px 20px; }\r\n#cta-hed {font-weight: 500;}\r\n#cta-indent {border-left: 5px solid #1e1919; padding-left:20px;}\r\n#cta a:link, #cta a:visited  {text-decoration: none;}\r\n#cta p { margin: 5px 0px 0px 0px; }\r\n\r\n.dr-theme-dark #cta {background: #000;}\r\n.dr-theme-dark #cta-box {border: 1px solid; border-bottom: 0;}\r\n.dr-theme-dark #cta-indent {border-left: 5px solid #f7f5f2;}\r\n.dr-theme-dark .button {background: #000;}\r\n\r\n.button {\r\n    background-color: #1e1919;\r\n    color:  #f7f5f2;\r\n    height: 2.5rem;\r\n    padding: 10px 5px 10px 20px;\r\n    font-size: 1rem;\r\n    font-weight: 500;\r\n    line-height: 1.2;\r\n    transition: all .3s;\r\n}\r\n\r\n.button:hover { background-color: #0061ff; }\r\n\r\nimg {vertical-align: middle; padding: 0px 1px 2px 0px;}\r\n\r\n.c17-plain-html {margin-bottom: 50px}\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n Dropbox Dash: Find anything. Protect everything.\n\r\n\r\nFind, organize, and protect your work with Dropbox Dash. Now with advanced search for video and images—plus generative AI capabilities across even more connected apps.\n\r\n\r\n\r\n\r\n\r\n\nSee what's new →\n\r\n\r\n\r\n\n\n    \n\n\n\n    \n\n\n\nYour experimental lab took home our Learn Fast award this year. Walk us through what you built and how.\n For the Hack Week project, we built our own liquid cooling system from scratch. Normally, these systems come pre-assembled with pumps, radiators, and fans, and you just plug them in. But since we had trouble sourcing a complete system in time, we decided to put one together ourselves. We used scaled-down versions of the same core components you’d see in a data center liquid cooling setup: radiators to exhaust heat, fans, a pump, a reservoir, tubing, manifolds, and some basic sensors. The sensors were key so we could monitor performance and make sure everything was pumping correctly before we connected any expensive GPUs. Once that was in place, we hooked it up to the server itself.\nWhat thermal performance observations did you make while working on this project?\n In terms of immediate thermal benefits, we saw a big difference. When running workloads on the liquid-cooled setup compared to our current air-cooled production system, temperatures were around 20–30°C lower under heavy stress tests. Though these were torture-style tests—even harsher than what we’d normally see in production.\nAnother key part of Hack Week was having the dedicated time to experiment with fan configurations. Since liquid cooling handled the CPUs and GPUs, we were able to remove or run many fans at lower speeds. We still needed some airflow for other components like DIMMs and the network card at the back, but those draw much less power and run at lower thermals compared to the GPUs and CPUs. Daniel even suggested building a specific airflow baffle to direct cooling to exactly where it’s needed.\n\r\n\r\n    \r\n        \r\n            \r\n    \r\n\r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n\r\n        \r\n        <!-- <img data-sly-test.highRes=\"false\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2025/august/hack-week-2025/body/OB3buGnk.jpeg 2x,  1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2025/august/hack-week-2025/body/OB3buGnk.jpeg\"\r\n             aria-hidden=\"\"\r\n             alt=\"\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"1600\"\r\n             data-sly-attribute.height=\"1200\"\r\n             data-aem-asset-id=\"decbf330-15bc-4063-af4e-414cb202e6ac:OB3buGnk.jpeg\"\r\n             data-trackable=\"true\" />\r\n        <img data-sly-test.highRes=\"false\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2025/august/hack-week-2025/body/OB3buGnk.jpeg 2x,  1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2025/august/hack-week-2025/body/OB3buGnk.jpeg\"\r\n             aria-hidden=\"\"\r\n             alt=\"\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"1600\"\r\n             data-sly-attribute.height=\"1200\"\r\n             data-aem-asset-id=\"decbf330-15bc-4063-af4e-414cb202e6ac:OB3buGnk.jpeg\"\r\n             data-trackable=\"true\" /> -->\r\n\r\n        \r\n         \r\n        \r\n    \r\n\r\n            \nThe liquid cooling team’s lab at Hack Week 2025\n\r\n        \r\n    \r\n\nLiquid cooling has been around for years. What first sparked your interest in exploring it as a potential solution for Dropbox?\n Liquid cooling has been around for a while, and the industry has been actively experimenting with it. We’ve followed the technology closely, including by attending conventions like the Open Compute Project summit where it’s a big topic. Bobby and I have seen these setups before and thought, this is really interesting—how could we apply it to Dropbox? We’ve had that question in the back of our minds for years now, and now we’re finally turning it into something concrete.\nBobby: Right. But it’s not as simple as just plugging in a liquid-cooled server. We need the right infrastructure in place so that if future high-performance servers require it, we’ll be ready. This project was about building that foundation.\nSo the challenge you’re solving for is future-focused—preparing for next-gen hardware and higher power needs?\n Exactly. It’s about handling both individual server power draw and the overall data center footprint. As new servers demand more power, sticking with only air cooling would force us to spread them out over more space. With liquid cooling, we can stay efficient—using less space, less energy, and potentially lowering costs.\nHow might this technology fit into our current and future infrastructure strategy, particularly with respect to our focus on supporting AI workloads?\n We’re seeing a greater need today for new solutions, especially with GPUs and AI workloads. These systems draw a huge amount of power and generate significant heat. While vendors aren’t yet requiring liquid cooling for their top-tier GPUs, we know it’s on the horizon. Air cooling may soon only support mid-range options.\nDaniel: And with Dropbox focusing more on AI initiatives, it gave us the push we needed. As we expand into GPU-heavy systems, it’s important to evaluate higher-powered setups. Hack Week was the perfect opportunity to explore that.\n\r\n\r\n    \r\n        \r\n            \r\n    \r\n\r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n\r\n        \r\n        <!-- <img data-sly-test.highRes=\"false\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2025/august/hack-week-2025/body/PJmnNZ_g.jpeg 2x,  1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2025/august/hack-week-2025/body/PJmnNZ_g.jpeg\"\r\n             aria-hidden=\"\"\r\n             alt=\"\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"1600\"\r\n             data-sly-attribute.height=\"1200\"\r\n             data-aem-asset-id=\"951ce483-71af-4f20-aed1-6c9629cd51e1:PJmnNZ_g.jpeg\"\r\n             data-trackable=\"true\" />\r\n        <img data-sly-test.highRes=\"false\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2025/august/hack-week-2025/body/PJmnNZ_g.jpeg 2x,  1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2025/august/hack-week-2025/body/PJmnNZ_g.jpeg\"\r\n             aria-hidden=\"\"\r\n             alt=\"\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"1600\"\r\n             data-sly-attribute.height=\"1200\"\r\n             data-aem-asset-id=\"951ce483-71af-4f20-aed1-6c9629cd51e1:PJmnNZ_g.jpeg\"\r\n             data-trackable=\"true\" /> -->\r\n\r\n        \r\n         \r\n        \r\n    \r\n\r\n            \nThe prototype liquid-cooled GPU server\n\r\n        \r\n    \r\n\nHack Week is a self-driven initiative where engineers are encouraged to explore projects independently. What resourcing or support were you given to explore this project?\n Dropbox has always made it possible for us to experiment. I’ve always felt supported to try new ideas. Our team was really interested in liquid cooling, and since Bobby’s team shared that interest, we were able to secure some funding to kick the project off. It gave us the chance to dive in ourselves and really have fun with it. Of course, we still have to balance it with our regular work, but we’ve been empowered to make the time and space to do that.\nBobby: I’d say the same. Both of our teams strongly believe this is an area we need to invest in—to research, lay the groundwork, and be ready for what’s coming. Once we showed that, we received support all the way up to move forward. So it’s been great to have that backing and be able to push ahead.\nIn-person events like Hack Week are an important part of the Virtual First experience at Dropbox. You both had the chance to attend in person for the first time this year. What did you enjoy about the experience? What were some of the benefits of working together in a physical space?\n I enjoyed getting to hack with the team and connect with people across the company that I don’t usually see. Being in the same room made it easy to bounce ideas off each other and solve issues quickly. For us in physical infrastructure, we usually kick off projects or bring-ups on site at a data center so we can quickly work through challenges and issues that are a normal part of any new project.\nDaniel: My experience is very similar to Bobby’s. Being in person, we have easy access to the minds of our peers. We can bounce ideas off them, pick up workflow improvements, and problem-solve very quickly.\nAdditional contributors to this project include Eric Shobe, Eddie del Rio, and Daniel Parker-Focht.\n~ ~ ~ \nIf building innovative products, experiences, and infrastructure excites you, come build the future with us! Visit jobs.dropbox.com to see our open roles, and follow @LifeInsideDropbox on Instagram and Facebook to see what it's like to create a more enlightened way of working.",
        "dc:creator": "\r\n                            Catie Keck\r\n            \t\t\t",
        "content": "null",
        "contentSnippet": "null",
        "guid": "https://dropbox.tech/culture/hack-week-2025-liquid-cooling-gpu-server",
        "categories": [
          "Culture",
          "AI",
          "Developers",
          "Infrastructure"
        ],
        "isoDate": "2025-08-27T15:00:00.000Z"
      }
    ]
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": [
      {
        "creator": "sunyzero",
        "title": "크롬 흰색창 혹은 흰색스크린 오류",
        "link": "https://sunyzero.tistory.com/318",
        "pubDate": "Sun, 24 Aug 2025 22:05:21 +0900",
        "author": "sunyzero",
        "comments": "https://sunyzero.tistory.com/318#entry318comment",
        "content": "<p data-ke-size=\"size16\">윈도 업데이트 후 크롬 브라우저가 온통 하얀색으로 나왔다. 해당 증상은 ANGLE graphics backend를 OpenGL을 사용하면서 그래픽 가속을 켜놓은 경우에만 발생하는 것으로 보인다. 따라서 ANGLE graphics backend 설정을 Default로 재설정해주면 해결할 수 있다. 아래는 ANGLE 설정을 재설정하는 방법이다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">1. 크롬의 흰색창 증상</h2>\n<p data-ke-size=\"size16\">증상은 아래처럼 Chrome browser 실행시 그냥 하얀 화면, 흰색창으로 나타나는 경우이다. 진짜 아무것도 보이지 않는다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"chrome_whitewindow_1.png\" data-origin-width=\"2007\" data-origin-height=\"1510\"><span data-url=\"https://blog.kakaocdn.net/dn/NeQRG/btsP35jX7xm/kHtDlXaxwIQ88AaU1tMUA1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/NeQRG/btsP35jX7xm/kHtDlXaxwIQ88AaU1tMUA1/img.png\" data-alt=\"Chrome white screen\"><img src=\"https://blog.kakaocdn.net/dn/NeQRG/btsP35jX7xm/kHtDlXaxwIQ88AaU1tMUA1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FNeQRG%2FbtsP35jX7xm%2FkHtDlXaxwIQ88AaU1tMUA1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"2007\" height=\"1510\" data-filename=\"chrome_whitewindow_1.png\" data-origin-width=\"2007\" data-origin-height=\"1510\"/></span><figcaption>Chrome white screen</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">2. 해결 방법</h2>\n<p data-ke-size=\"size16\">먼저 어떻게 해서든지 크롬 화면이 나오도록 실행해야 하는데, 이는 그래픽 가속을 끄는 옵션을 사용하면 된다. 먼저 실행된 크롬 브라우저를 종료한다. 대충 흰색 창의 우측 상단 X 마크가 있을 법한 위치를 눌러서 크롬을 닫는다. 혹은 창 선택 후 Alt+F4로 닫아도 된다.</p>\n<p data-ke-size=\"size16\">크롬이 닫힌 뒤에 Powershell을 하나 실행시킨다. 실행은 \"윈도우 + R\"키를 눌러서 나온 실행 창에서 powershell이라고 치면 된다. Powershell 에서 크롬이 설치된 디렉토리로 이동하는데, 경로는 보통 \"C:\\Program Files\\Google\\Chrome\\Application\" 이다. 아래처럼 cd (change directory) 명령을 사용하면 된다. 오타를 낼 것 같다면 Tab키를 사용해서 자동완성으로 디렉토리를 찾아가면 편리하다.</p>\n<pre id=\"code_1756039781195\" class=\"shell\" data-ke-language=\"shell\" data-ke-type=\"codeblock\"><code>cd \"C:\\Program Files\\Google\\Chrome\\Application\"</code></pre>\n<p data-ke-size=\"size16\">이제 해당 디렉토리에서 <span style=\"background-color: #f6e199;\">crhome.exe --disable-gpu</span> 명령으로 크롬을 실행한다. 아래는 powershell에서 명령하는 모습을 캡쳐한 그림 파일이다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"chrome_whitewindow_2.png\" data-origin-width=\"1721\" data-origin-height=\"226\"><span data-url=\"https://blog.kakaocdn.net/dn/seeLn/btsP24r5CZB/9SBoKk1PxTkK11VCjso7FK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/seeLn/btsP24r5CZB/9SBoKk1PxTkK11VCjso7FK/img.png\" data-alt=\"Chome disable gpu option\"><img src=\"https://blog.kakaocdn.net/dn/seeLn/btsP24r5CZB/9SBoKk1PxTkK11VCjso7FK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FseeLn%2FbtsP24r5CZB%2F9SBoKk1PxTkK11VCjso7FK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1721\" height=\"226\" data-filename=\"chrome_whitewindow_2.png\" data-origin-width=\"1721\" data-origin-height=\"226\"/></span><figcaption>Chome disable gpu option</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">이렇게 하면 이제 크롬 화면이 보일 것이다. 임시로 띄운 것이므로 여기서 설정을 손봐야 한다. 먼저 주소창에서 <span style=\"background-color: #f6e199;\">chrome://flags</span>를 실행한다. 그리고 주소창 아래의 돋보기 검색창에 <span style=\"background-color: #9feec3;\">ANGLE</span>을 타이핑하면 <span style=\"background-color: #9feec3;\">Choose ANGLE graphics backend</span>가 보일 것이다. 이 값이 Default가 아닌 OpenGL 같은 다른 값으로 되어있을 것이다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1301\" data-origin-height=\"530\"><span data-url=\"https://blog.kakaocdn.net/dn/bt3x36/btsP4oKlYYC/HR8RqUFVrsULUXUKNwJDd0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bt3x36/btsP4oKlYYC/HR8RqUFVrsULUXUKNwJDd0/img.png\" data-alt=\"chrome flags - Choose ANGLE graphics backend - OpenGL\"><img src=\"https://blog.kakaocdn.net/dn/bt3x36/btsP4oKlYYC/HR8RqUFVrsULUXUKNwJDd0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbt3x36%2FbtsP4oKlYYC%2FHR8RqUFVrsULUXUKNwJDd0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1301\" height=\"530\" data-origin-width=\"1301\" data-origin-height=\"530\"/></span><figcaption>chrome flags - Choose ANGLE graphics backend - OpenGL</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">이제 default로 값을 변경한 뒤에 크롬창 우측 하단에 재시작을 눌러주면 재시작 되면서 제대로 작동 될 것이다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"chrome_whitewindow_4.png\" data-origin-width=\"1311\" data-origin-height=\"557\"><span data-url=\"https://blog.kakaocdn.net/dn/HUMXz/btsP3ysTkzY/HGLNKXM4uFYrkraHUW5KYk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/HUMXz/btsP3ysTkzY/HGLNKXM4uFYrkraHUW5KYk/img.png\" data-alt=\"chrome flags - Choose ANGLE graphics backend - Default\"><img src=\"https://blog.kakaocdn.net/dn/HUMXz/btsP3ysTkzY/HGLNKXM4uFYrkraHUW5KYk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FHUMXz%2FbtsP3ysTkzY%2FHGLNKXM4uFYrkraHUW5KYk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1311\" height=\"557\" data-filename=\"chrome_whitewindow_4.png\" data-origin-width=\"1311\" data-origin-height=\"557\"/></span><figcaption>chrome flags - Choose ANGLE graphics backend - Default</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">만일 이렇게 설정 한뒤에도 계속 흰색창 화면이 나온다면 앞의 <span style=\"color: #333333; text-align: start;\"><span>&nbsp;</span></span><span style=\"background-color: #f6e199;\">crhome.exe --disable-gpu</span> 로 실행한 뒤에 \"<span style=\"background-color: #9feec3;\">설정</span>\"에서 \"<span style=\"background-color: #9feec3;\">시스템</span>\"의 \"<span style=\"background-color: #9feec3;\">가능한 경우 그래픽 가속 사용</span>\"을 꺼두는 방법 밖에 없다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1002\" data-origin-height=\"355\"><span data-url=\"https://blog.kakaocdn.net/dn/HvmnQ/btsP4d26QFh/NNjS7Cr77jXGkvQAJNP0i0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/HvmnQ/btsP4d26QFh/NNjS7Cr77jXGkvQAJNP0i0/img.png\" data-alt=\"크롬 - 설정 - 시스템 - 가능한 경우 그래픽 가속 사용\"><img src=\"https://blog.kakaocdn.net/dn/HvmnQ/btsP4d26QFh/NNjS7Cr77jXGkvQAJNP0i0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FHvmnQ%2FbtsP4d26QFh%2FNNjS7Cr77jXGkvQAJNP0i0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1002\" height=\"355\" data-origin-width=\"1002\" data-origin-height=\"355\"/></span><figcaption>크롬 - 설정 - 시스템 - 가능한 경우 그래픽 가속 사용</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">현재 문제가 발생한 이유는 OpenGL관련 부분이나 DirectX 부분을 업데이트하면서 뭔가 꼬인 것이 아닐까 하는 의심이 든다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">히스토리</h2>\n<p data-ke-size=\"size16\">2025.08.24 처음 글 씀</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "윈도 업데이트 후 크롬 브라우저가 온통 하얀색으로 나왔다. 해당 증상은 ANGLE graphics backend를 OpenGL을 사용하면서 그래픽 가속을 켜놓은 경우에만 발생하는 것으로 보인다. 따라서 ANGLE graphics backend 설정을 Default로 재설정해주면 해결할 수 있다. 아래는 ANGLE 설정을 재설정하는 방법이다.\n \n1. 크롬의 흰색창 증상\n증상은 아래처럼 Chrome browser 실행시 그냥 하얀 화면, 흰색창으로 나타나는 경우이다. 진짜 아무것도 보이지 않는다.\nChrome white screen\n\n\n \n2. 해결 방법\n먼저 어떻게 해서든지 크롬 화면이 나오도록 실행해야 하는데, 이는 그래픽 가속을 끄는 옵션을 사용하면 된다. 먼저 실행된 크롬 브라우저를 종료한다. 대충 흰색 창의 우측 상단 X 마크가 있을 법한 위치를 눌러서 크롬을 닫는다. 혹은 창 선택 후 Alt+F4로 닫아도 된다.\n크롬이 닫힌 뒤에 Powershell을 하나 실행시킨다. 실행은 \"윈도우 + R\"키를 눌러서 나온 실행 창에서 powershell이라고 치면 된다. Powershell 에서 크롬이 설치된 디렉토리로 이동하는데, 경로는 보통 \"C:\\Program Files\\Google\\Chrome\\Application\" 이다. 아래처럼 cd (change directory) 명령을 사용하면 된다. 오타를 낼 것 같다면 Tab키를 사용해서 자동완성으로 디렉토리를 찾아가면 편리하다.\ncd \"C:\\Program Files\\Google\\Chrome\\Application\"\n이제 해당 디렉토리에서 crhome.exe --disable-gpu 명령으로 크롬을 실행한다. 아래는 powershell에서 명령하는 모습을 캡쳐한 그림 파일이다.\nChome disable gpu option\n\n\n이렇게 하면 이제 크롬 화면이 보일 것이다. 임시로 띄운 것이므로 여기서 설정을 손봐야 한다. 먼저 주소창에서 chrome://flags를 실행한다. 그리고 주소창 아래의 돋보기 검색창에 ANGLE을 타이핑하면 Choose ANGLE graphics backend가 보일 것이다. 이 값이 Default가 아닌 OpenGL 같은 다른 값으로 되어있을 것이다.\nchrome flags - Choose ANGLE graphics backend - OpenGL\n\n\n이제 default로 값을 변경한 뒤에 크롬창 우측 하단에 재시작을 눌러주면 재시작 되면서 제대로 작동 될 것이다.\nchrome flags - Choose ANGLE graphics backend - Default\n\n\n만일 이렇게 설정 한뒤에도 계속 흰색창 화면이 나온다면 앞의  crhome.exe --disable-gpu 로 실행한 뒤에 \"설정\"에서 \"시스템\"의 \"가능한 경우 그래픽 가속 사용\"을 꺼두는 방법 밖에 없다.\n크롬 - 설정 - 시스템 - 가능한 경우 그래픽 가속 사용\n\n\n현재 문제가 발생한 이유는 OpenGL관련 부분이나 DirectX 부분을 업데이트하면서 뭔가 꼬인 것이 아닐까 하는 의심이 든다.\n \n \n히스토리\n2025.08.24 처음 글 씀",
        "guid": "https://sunyzero.tistory.com/318",
        "categories": [
          "컴퓨터 관련/윈도 패밀리",
          "Chrome disable GPU",
          "chrome OpenGL",
          "Chrome white screen window",
          "Chrome 그래픽 가속",
          "가능한 경우 그래픽 가속 사용 문제",
          "크롬 흰색스크린 문제",
          "크롬 흰색창 문제"
        ],
        "isoDate": "2025-08-24T13:05:21.000Z"
      }
    ]
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": [
      {
        "title": "Text, wav 를 통한 입술 모양 이미지 생성 방법",
        "link": "http://daddynkidsmakers.blogspot.com/2025/08/text-wav.html",
        "pubDate": "2025-08-22T21:31:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\"><div>이 글은 Text, wav 를 통한 입술 모양 이미지 생성 방법을 간략히 정리해 본다.</div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEj5HHRDaxKkRuRRKdYEwzTbmy-MkLswKGTH4fbDjH1l3_mcP8CRiLiFUpDMM7vw7nzASxFkG-vgWaUGclY1QxFOhG6n4Yys6PjRm8t55wTQJYt4A29hymEQI_8cwMQCZH3Gyxmf-6x4Yygszrs9F6peTFbjgJ0uxmYBlB_ztt7fQoxeIMpvNa4A7sz99-6B\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"482\" data-original-width=\"880\" height=\"175\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEj5HHRDaxKkRuRRKdYEwzTbmy-MkLswKGTH4fbDjH1l3_mcP8CRiLiFUpDMM7vw7nzASxFkG-vgWaUGclY1QxFOhG6n4Yys6PjRm8t55wTQJYt4A29hymEQI_8cwMQCZH3Gyxmf-6x4Yygszrs9F6peTFbjgJ0uxmYBlB_ztt7fQoxeIMpvNa4A7sz99-6B\" width=\"320\" /></a></div><br /></div><div><b>서론</b></div><div>디지털 휴먼 및 가상 아바타 기술의 발전에 따라, 텍스트 입력에 대한 실시간 립 애니메이션 생성 기술의 중요성이 증대되고 있다. 전통적인 방식은 텍스트로부터 완전한 오디오 파일을 생성한 후, 해당 파일을 기반으로 비디오 프레임을 합성하는 배치(Batch) 처리 방식을 채택한다. 그러나 이 방식은 오디오 파일 생성과 비디오 렌더링에 소요되는 시간으로 인해 상당한 지연(Latency)이 발생하며, 실시간 상호작용 애플리케이션에는 부적합하다. 본 글은 실시간 텍스트립싱크를 구현하기 위한 핵심 기술 요소를 분석한다.</div><div><br /></div><div><b>실시간 립싱크 구현을 위한 핵심 파이프라인</b></div><div>실시간 립싱크 시스템은 단일 모델이 아닌, 두 가지 핵심 기술이 순차적으로 결합된 파이프라인(Pipeline) 구조로 구현된다.</div><div><br /></div><div>1.&nbsp; 스트리밍 텍스트음성 변환 (Streaming TexttoSpeech, TTS)</div><div>&nbsp;실시간성을 확보하기 위한 첫 번째 단계는 스트리밍 TTS 엔진이다. 이는 입력 텍스트를 완성된 오디오 파일로 변환하는 것이 아니라, 연속적인 오디오 데이터 스트림(Stream)으로 즉시 생성하는 기술이다. 텍스트가 입력되는 즉시 오디오 청크(Chunk)가 생성되어 파이프라인의 후속 단계로 전달되므로, 전체 문장이 끝날 때까지 기다릴 필요가 없다. 이는 전체 지연 시간을 최소화하는 데 결정적인 역할을 한다.</div><div><br /></div><div>2.&nbsp; 저지연 얼굴 애니메이션 (Lowlatency Facial Animation)</div><div>&nbsp; &nbsp; 두 번째 단계는 스트리밍 TTS로부터 전달받은 오디오 청크를 입력받아, 이에 상응하는 입 모양 애니메이션을 즉각적으로 생성하는 모델이다. 이 모델은 오디오 파형, 음소(Phoneme), 또는 음성 특징(Feature)을 분석하여 얼굴 모델의 특정 파라미터를 제어한다. 여기서 핵심은 최소한의 연산으로 최대한 자연스러운 움직임을 생성하여, 오디오와 시각적 출력 사이의 동기화를 유지하는 것이다.</div><div><br /></div><div><b>구현 방식에 따른 기술적 접근</b></div><div>실시간 립싱크는 요구되는 성능과 사용 가능한 하드웨어 자원에 따라 다양한 접근 방식이 존재한다.</div><div><br /></div><div>1. 고성능 GPU 기반 솔루션: NVIDIA Riva 및 Audio2Face</div><div>NVIDIA에서 제공하는 이 솔루션은 현재 가장 높은 수준의 실시간성과 품질을 제공하는 산업 표준으로 평가된다. NVIDIA Riva는 고성종 스트리밍 TTS 엔진의 역할을 수행하며, Audio2Face는 Riva로부터 생성된 오디오 스트림을 입력받아 3D 아바타의 얼굴 메쉬(Mesh)를 실시간으로 정교하게 제어한다. 이 방식은 RTX 시리즈 이상의 고성능 GPU를 요구하지만, 매우 낮은 지연 시간과 사실적인 표정 변화를 구현할 수 있다는 장점이 있다.</div><div><br /></div><div>2. 경량화 오픈소스 모델 조합</div><div>제한된 하드웨어 환경에서는 경량화된 오픈소스 모델을 조합하여 시스템을 구축할 수 있다. 예를 들어, 빠른 추론 속도를 보이는 LivePortrait 또는 Wav2Lip과 같은 얼굴 애니메이션 모델과 PiperTTS와 같은 경량 스트리밍 TTS 엔진을 결합하는 방식이다. 이 접근법은 시스템의 전체적인 연산량을 줄여 소비자용 GPU 또는 CPU 환경에서도 실시간 처리를 가능하게 하는 것을 목표로 한다. 다만, 각 구성 요소를 연결하고 최적화하는 추가적인 개발 과정이 요구된다.</div><div><br /></div><div><b>MediaPipe</b></div><div>MediaPipe 라이브러리는 립싱크 시스템 구축에 있어 중요한 기반 기술을 제공한다. MediaPipe의 Face Landmarker 기능은 이미지나 비디오 프레임에서 478개의 3D 얼굴 랜드마크와 52개의 블렌드셰이프(Blendshapes)를 정밀하게 추출한다. 블렌드셰이프는 '입 벌리기', '미소' 등 특정 표정의 강도를 수치화한 데이터로, 3D 모델을 제어하는 표준 파라미터로 사용된다.</div><div><br /></div><div>그러나 MediaPipe 자체는 오디오 데이터를 해석하여 립싱크 애니메이션을 생성하는 기능을 포함하고 있지 않다. MediaPipe는 단지 얼굴의 기하학적 구조와 표정을 '표현'하고 '측정'하는 도구일 뿐이다. 따라서 MediaPipe를 활용한 립싱크 시스템을 구축하기 위해서는, 오디오 스트림을 입력받아 이에 상응하는 블렌드셰이프 값을 예측하는 별도의 '오디오투블렌드셰이프(AudiotoBlendshape)' 변환 모델이 반드시 필요하다. 이 모델이 오디오 분석 엔진의 역할을 수행하며, MediaPipe는 그 결과를 받아 시각적으로 렌더링하는 후처리단에 위치하게 된다.</div><div><br /></div><div><b>결론</b></div><div>실시간 텍스트 기반 립싱크는 단순한 모델 하나가 아닌, 스트리밍 TTS와 저지연 얼굴 애니메이션 모델이 유기적으로 결합된 파이프라인을 통해 구현되는 복합적인 기술이다. 고성능 환경에서는 NVIDIA의 솔루션이, 자원이 제한된 환경에서는 경량화된 오픈소스 모델들의 조합이 효과적인 대안이 될 수 있다. MediaPipe와 같은 라이브러리는 얼굴 애니메이션의 최종 출력단을 담당하는 핵심적인 구성 요소이지만, 그 자체만으로는 완전한 립싱크 솔루션이 될 수 없으며 오디오를 해석하는 별도의 AI 모델과의 연동이 필수적이다.&nbsp;</div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b>레퍼런스</b></div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><a href=\"https://ai.google.dev/edge/mediapipe/solutions/vision/face_landmarker?hl=ko\">얼굴 특징 감지 가이드 &nbsp;|&nbsp; Google AI Edge &nbsp;|&nbsp; Google AI for Developers</a></li><li><a href=\"https://github.com/nikitansg/Face-detection-mediapipe/blob/main/Mediapipe-Face-Detector.ipynb\">Face-detection-mediapipe/Mediapipe-Face-Detector.ipynb at main · nikitansg/Face-detection-mediapipe</a></li><li><a href=\"https://github.com/KwaiVGI/LivePortrait\">LivePortrait: Bring portraits to life!</a></li><li><a href=\"https://github.com/OpenTalker/SadTalker\">SadTalker: [CVPR 2023] SadTalker：Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation</a></li><li><a href=\"https://github.com/Rudrabha/Wav2Lip\">Wav2Lip: This repository contains the codes of \"A Lip Sync Expert Is All You Need for Speech to Lip Generation In the Wild\", published at ACM Multimedia 2020. For HD commercial model, please try out Sync Labs</a></li><li><a href=\"https://github.com/rhasspy/piper\">piper: A fast, local neural text to speech system</a></li><li><a href=\"https://github.com/TMElyralab/MuseTalk?tab=readme-ov-file#input-video\">TMElyralab/MuseTalk: MuseTalk: Real-Time High Quality Lip Synchorization with Latent Space Inpainting</a></li><li><a href=\"https://github.com/ali-vilab/dreamtalk\">dreamtalk: Official implementations for paper: DreamTalk: When Expressive Talking Head Generation Meets Diffusion Probabilistic Models</a></li><li><a href=\"https://build.nvidia.com/nvidia/audio2face-3d/api\">audio2face-3d Model by NVIDIA | NVIDIA NIM</a></li><li><a href=\"https://github.com/psyai-net/EmoTalk_release\">EmoTalk_release: This is the official source for our ICCV 2023 paper \"EmoTalk: Speech-Driven Emotional Disentanglement for 3D Face Animation\"</a></li></ul></div>",
        "contentSnippet": "이 글은 Text, wav 를 통한 입술 모양 이미지 생성 방법을 간략히 정리해 본다.\n\n\n\n서론\n디지털 휴먼 및 가상 아바타 기술의 발전에 따라, 텍스트 입력에 대한 실시간 립 애니메이션 생성 기술의 중요성이 증대되고 있다. 전통적인 방식은 텍스트로부터 완전한 오디오 파일을 생성한 후, 해당 파일을 기반으로 비디오 프레임을 합성하는 배치(Batch) 처리 방식을 채택한다. 그러나 이 방식은 오디오 파일 생성과 비디오 렌더링에 소요되는 시간으로 인해 상당한 지연(Latency)이 발생하며, 실시간 상호작용 애플리케이션에는 부적합하다. 본 글은 실시간 텍스트립싱크를 구현하기 위한 핵심 기술 요소를 분석한다.\n\n\n실시간 립싱크 구현을 위한 핵심 파이프라인\n실시간 립싱크 시스템은 단일 모델이 아닌, 두 가지 핵심 기술이 순차적으로 결합된 파이프라인(Pipeline) 구조로 구현된다.\n\n\n1.  스트리밍 텍스트음성 변환 (Streaming TexttoSpeech, TTS)\n 실시간성을 확보하기 위한 첫 번째 단계는 스트리밍 TTS 엔진이다. 이는 입력 텍스트를 완성된 오디오 파일로 변환하는 것이 아니라, 연속적인 오디오 데이터 스트림(Stream)으로 즉시 생성하는 기술이다. 텍스트가 입력되는 즉시 오디오 청크(Chunk)가 생성되어 파이프라인의 후속 단계로 전달되므로, 전체 문장이 끝날 때까지 기다릴 필요가 없다. 이는 전체 지연 시간을 최소화하는 데 결정적인 역할을 한다.\n\n\n2.  저지연 얼굴 애니메이션 (Lowlatency Facial Animation)\n    두 번째 단계는 스트리밍 TTS로부터 전달받은 오디오 청크를 입력받아, 이에 상응하는 입 모양 애니메이션을 즉각적으로 생성하는 모델이다. 이 모델은 오디오 파형, 음소(Phoneme), 또는 음성 특징(Feature)을 분석하여 얼굴 모델의 특정 파라미터를 제어한다. 여기서 핵심은 최소한의 연산으로 최대한 자연스러운 움직임을 생성하여, 오디오와 시각적 출력 사이의 동기화를 유지하는 것이다.\n\n\n구현 방식에 따른 기술적 접근\n실시간 립싱크는 요구되는 성능과 사용 가능한 하드웨어 자원에 따라 다양한 접근 방식이 존재한다.\n\n\n1. 고성능 GPU 기반 솔루션: NVIDIA Riva 및 Audio2Face\nNVIDIA에서 제공하는 이 솔루션은 현재 가장 높은 수준의 실시간성과 품질을 제공하는 산업 표준으로 평가된다. NVIDIA Riva는 고성종 스트리밍 TTS 엔진의 역할을 수행하며, Audio2Face는 Riva로부터 생성된 오디오 스트림을 입력받아 3D 아바타의 얼굴 메쉬(Mesh)를 실시간으로 정교하게 제어한다. 이 방식은 RTX 시리즈 이상의 고성능 GPU를 요구하지만, 매우 낮은 지연 시간과 사실적인 표정 변화를 구현할 수 있다는 장점이 있다.\n\n\n2. 경량화 오픈소스 모델 조합\n제한된 하드웨어 환경에서는 경량화된 오픈소스 모델을 조합하여 시스템을 구축할 수 있다. 예를 들어, 빠른 추론 속도를 보이는 LivePortrait 또는 Wav2Lip과 같은 얼굴 애니메이션 모델과 PiperTTS와 같은 경량 스트리밍 TTS 엔진을 결합하는 방식이다. 이 접근법은 시스템의 전체적인 연산량을 줄여 소비자용 GPU 또는 CPU 환경에서도 실시간 처리를 가능하게 하는 것을 목표로 한다. 다만, 각 구성 요소를 연결하고 최적화하는 추가적인 개발 과정이 요구된다.\n\n\nMediaPipe\nMediaPipe 라이브러리는 립싱크 시스템 구축에 있어 중요한 기반 기술을 제공한다. MediaPipe의 Face Landmarker 기능은 이미지나 비디오 프레임에서 478개의 3D 얼굴 랜드마크와 52개의 블렌드셰이프(Blendshapes)를 정밀하게 추출한다. 블렌드셰이프는 '입 벌리기', '미소' 등 특정 표정의 강도를 수치화한 데이터로, 3D 모델을 제어하는 표준 파라미터로 사용된다.\n\n\n그러나 MediaPipe 자체는 오디오 데이터를 해석하여 립싱크 애니메이션을 생성하는 기능을 포함하고 있지 않다. MediaPipe는 단지 얼굴의 기하학적 구조와 표정을 '표현'하고 '측정'하는 도구일 뿐이다. 따라서 MediaPipe를 활용한 립싱크 시스템을 구축하기 위해서는, 오디오 스트림을 입력받아 이에 상응하는 블렌드셰이프 값을 예측하는 별도의 '오디오투블렌드셰이프(AudiotoBlendshape)' 변환 모델이 반드시 필요하다. 이 모델이 오디오 분석 엔진의 역할을 수행하며, MediaPipe는 그 결과를 받아 시각적으로 렌더링하는 후처리단에 위치하게 된다.\n\n\n결론\n실시간 텍스트 기반 립싱크는 단순한 모델 하나가 아닌, 스트리밍 TTS와 저지연 얼굴 애니메이션 모델이 유기적으로 결합된 파이프라인을 통해 구현되는 복합적인 기술이다. 고성능 환경에서는 NVIDIA의 솔루션이, 자원이 제한된 환경에서는 경량화된 오픈소스 모델들의 조합이 효과적인 대안이 될 수 있다. MediaPipe와 같은 라이브러리는 얼굴 애니메이션의 최종 출력단을 담당하는 핵심적인 구성 요소이지만, 그 자체만으로는 완전한 립싱크 솔루션이 될 수 없으며 오디오를 해석하는 별도의 AI 모델과의 연동이 필수적이다. \n\n\n레퍼런스\n\n얼굴 특징 감지 가이드  |  Google AI Edge  |  Google AI for Developers\nFace-detection-mediapipe/Mediapipe-Face-Detector.ipynb at main · nikitansg/Face-detection-mediapipe\nLivePortrait: Bring portraits to life!\nSadTalker: [CVPR 2023] SadTalker：Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation\nWav2Lip: This repository contains the codes of \"A Lip Sync Expert Is All You Need for Speech to Lip Generation In the Wild\", published at ACM Multimedia 2020. For HD commercial model, please try out Sync Labs\npiper: A fast, local neural text to speech system\nTMElyralab/MuseTalk: MuseTalk: Real-Time High Quality Lip Synchorization with Latent Space Inpainting\ndreamtalk: Official implementations for paper: DreamTalk: When Expressive Talking Head Generation Meets Diffusion Probabilistic Models\naudio2face-3d Model by NVIDIA | NVIDIA NIM\nEmoTalk_release: This is the official source for our ICCV 2023 paper \"EmoTalk: Speech-Driven Emotional Disentanglement for 3D Face Animation\"",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-7460978912231468540",
        "isoDate": "2025-08-22T21:31:00.000Z"
      }
    ]
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "VIM vs AWK - 2nd",
        "link": "https://kangmyounghun.blogspot.com/2025/08/vim-vs-awk-2nd.html",
        "pubDate": "2025-08-24T04:04:00.002Z",
        "author": "강명훈",
        "content": "<div>강의 이해를 위해 요구되는 사전 지식들.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhsw93YWXT9F8smWJ6OHl9uOG0t7P2n6WMaDk1b6jO-zEjYm6H_qBeZ724yze7zFjkuDH-JtwcrEPGQ71hyphenhyphen-5tOioNtbxKNGAyjMb1vaYDge-DgyfKAmskwwhsh5V2A6NsNMZ_H3pcgn3fbr6QWV__5lPVm6D1nLkZDzsj_IGnQuyU-TzvVA8ZALHXQrQi2/s1348/pre.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"542\" data-original-width=\"1348\" height=\"161\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhsw93YWXT9F8smWJ6OHl9uOG0t7P2n6WMaDk1b6jO-zEjYm6H_qBeZ724yze7zFjkuDH-JtwcrEPGQ71hyphenhyphen-5tOioNtbxKNGAyjMb1vaYDge-DgyfKAmskwwhsh5V2A6NsNMZ_H3pcgn3fbr6QWV__5lPVm6D1nLkZDzsj_IGnQuyU-TzvVA8ZALHXQrQi2/w400-h161/pre.png\" width=\"400\" /></a></div><div><br /></div><div>필수 요건으로로 못박고 싶지만 그랬다간 망할까봐 권장으로 타협. 출강 기관 측은 아예 빼자고 하는데 그러고 싶진 않다. 내 강의 정체성이기 때문.</div><div><br /></div><span><a name='more'></a></span><div><b><span style=\"font-size: x-large;\">세상 모든 데이터는 문자열</span></b></div><div><br /></div><div>SQL이든 <span style=\"font-size: x-small;\">(엘라스틱/스플렁크 등의)</span> NoSQL이든, 세상 모든 DB는 문자열 데이터를 깎고 다듬어 테이블 구조로 바꾸는 전처리 작업을 필수로 거친다. 그래야 데이터 분석을 시작할 수 있으니까.</div><blockquote><blockquote style=\"text-align: center;\"><i><a href=\"https://kangmyounghun.blogspot.com/2016/06/blog-post_12.html\" target=\"_blank\">데이터는 테이블이다</a></i></blockquote><span style=\"font-size: x-small;\"></span></blockquote><br />데이터를 분석하려면 <strike><span style=\"font-size: x-small;\">엘라스틱이나 스플렁크가 아닌</span></strike> 데이터를 잘 알아야 한다. <span style=\"font-size: x-small;\">(의미 파악은 기본이고)</span> 전체적인 구조는 어떤지, 내 목적에 맞는 범위는 어딘지, 그 범위의 데이터를 어떻게 가공해야 원하는 분석이 가능한지에 대한 감을 잡을 수 있어야 한다. 이런 감각을 일깨워주는 가장 확실한 방법은 결국 데이터를 직접 만져보는 것.&nbsp;<div><i><a href=\"goog_933725584\"></a></i><blockquote style=\"text-align: center;\"><i><a href=\"https://www.joongang.co.kr/article/23409057\" target=\"_blank\">프로젝트에서 데이터의 공간 변환, 공간 탐색 등의 전문적 단계에 진입하기 전에 학생들에게 데이터를 가지고 온갖 자질구레한 관찰을 해보도록 강제한다. 데이터의 질감을 느끼는 단계다. 이 과정에서 통찰과 관점이 생긴다</a></i></blockquote></div><div><br /></div><div>이런 경험을 가장 쉽게 할 수 있는 환경이 바로 리눅스. 목적에 맞는 셋팅을 시도하는 과정에서 기본 편집기인 VIM을 사용할 수밖에 없으니까.&nbsp;</div><div><br /></div><div><b><span style=\"font-size: x-large;\">문자열 데이터를 다루는 감을 익히는 데 문자열 편집기보다 더 좋은 툴이 있을까?&nbsp;</span></b></div><div><br /></div><div>꼭 VIM 때문에만 리눅스 경험을 주문하는 것도 아니다. 사실 리눅스는 운영체제 자체가 문자열 데이터 처리를 위한 종합선물세트라고 해도 과언이 아니기 때문.</div><div><br /></div>\n<div>웹로그 메소드 발생 내역</div>\n<div class=\"colorscripter-code\" style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; overflow: auto; position: relative;\"><table cellpadding=\"0\" cellspacing=\"0\" class=\"colorscripter-code-table\" style=\"background-color: #fafafa; border-radius: 4px; border: none; margin: 0px; padding: 0px;\"><tbody><tr><td style=\"padding: 6px 0px; text-align: left;\"><div style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; line-height: 130%; margin: 0px; padding: 0px;\"><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">root@MHKANG:~<span style=\"color: #999999;\">#&nbsp;awk&nbsp;'{print&nbsp;$6}'&nbsp;2014.log&nbsp;|                             </span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;awk&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>F&nbsp;<span style=\"color: #63a35c;\">'\"'</span>&nbsp;<span style=\"color: #63a35c;\">'{print&nbsp;$2}'</span>&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;sort&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>u</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">CONNECT</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">GET</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">HEAD</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">POST</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">quit</div></div><div style=\"font-size: 9px; font-style: italic; margin-right: 5px; margin-top: -13px; text-align: right;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: #e5e5e5text-decoration:none;\" target=\"_blank\">Colored by Color Scripter</a></div></td><td style=\"padding: 0px 2px 4px 0px; vertical-align: bottom;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: white; text-decoration: none;\" target=\"_blank\"><span style=\"background-color: #e5e5e5; border-radius: 10px; color: white; font-size: 9px; padding: 1px; word-break: normal;\">cs</span></a></td></tr></tbody></table></div>\n<div><br /></div>\n<div>메소드 고유개수1</div>\n<div class=\"colorscripter-code\" style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; overflow: auto; position: relative;\"><table cellpadding=\"0\" cellspacing=\"0\" class=\"colorscripter-code-table\" style=\"background-color: #fafafa; border-radius: 4px; border: none; margin: 0px; padding: 0px;\"><tbody><tr><td style=\"padding: 6px 0px; text-align: left;\"><div style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; line-height: 130%; margin: 0px; padding: 0px;\"><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">root@MHKANG:~<span style=\"color: #999999;\">#&nbsp;awk&nbsp;'{print&nbsp;$6}'&nbsp;2014.log&nbsp;|                             </span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;awk&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>F&nbsp;<span style=\"color: #63a35c;\">'\"'</span>&nbsp;<span style=\"color: #63a35c;\">'{print&nbsp;$2}'</span>&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;sort&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>u&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;wc&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>l</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0099cc;\">6</span></div></div><div style=\"font-size: 9px; font-style: italic; margin-right: 5px; margin-top: -13px; text-align: right;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: #e5e5e5text-decoration:none;\" target=\"_blank\">Colored by Color Scripter</a></div></td><td style=\"padding: 0px 2px 4px 0px; vertical-align: bottom;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: white; text-decoration: none;\" target=\"_blank\"><span style=\"background-color: #e5e5e5; border-radius: 10px; color: white; font-size: 9px; padding: 1px; word-break: normal;\">cs</span></a></td></tr></tbody></table></div>\n<div><br /></div>\n<div>메소드 고유개수2</div>\n<div class=\"colorscripter-code\" style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; overflow: auto; position: relative;\"><table cellpadding=\"0\" cellspacing=\"0\" class=\"colorscripter-code-table\" style=\"background-color: #fafafa; border-radius: 4px; border: none; margin: 0px; padding: 0px;\"><tbody><tr><td style=\"padding: 6px 0px; text-align: left;\"><div style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; line-height: 130%; margin: 0px; padding: 0px;\"><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">root@MHKANG:~<span style=\"color: #999999;\">#&nbsp;awk&nbsp;'{print&nbsp;$6}'&nbsp;2014.log&nbsp;|                             </span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;awk&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>F&nbsp;<span style=\"color: #63a35c;\">'\"'</span>&nbsp;<span style=\"color: #63a35c;\">'{print&nbsp;$2}'</span>&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;awk&nbsp;<span style=\"color: #63a35c;\">'arr[$1]==\"\"&nbsp;{arr[$1]=\"x\"}&nbsp;END&nbsp;{print&nbsp;length(arr)}'</span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0099cc;\">6</span></div></div><div style=\"font-size: 9px; font-style: italic; margin-right: 5px; margin-top: -13px; text-align: right;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: #e5e5e5text-decoration:none;\" target=\"_blank\">Colored by Color Scripter</a></div></td><td style=\"padding: 0px 2px 4px 0px; vertical-align: bottom;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: white; text-decoration: none;\" target=\"_blank\"><span style=\"background-color: #e5e5e5; border-radius: 10px; color: white; font-size: 9px; padding: 1px; word-break: normal;\">cs</span></a></td></tr></tbody></table></div>\n<div><br /></div>\n<div>변수 고유개수</div>\n<div class=\"colorscripter-code\" style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; overflow: auto; position: relative;\"><table cellpadding=\"0\" cellspacing=\"0\" class=\"colorscripter-code-table\" style=\"background-color: #fafafa; border-radius: 4px; border: none; margin: 0px; padding: 0px;\"><tbody><tr><td style=\"padding: 6px 0px; text-align: left;\"><div style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; line-height: 130%; margin: 0px; padding: 0px;\"><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">root@MHKANG:~<span style=\"color: #999999;\">#&nbsp;awk&nbsp;'{if&nbsp;($7&nbsp;~&nbsp;/\\?/)&nbsp;print&nbsp;$7}'&nbsp;2014.log&nbsp;|              </span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;awk&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>F&nbsp;<span style=\"color: #63a35c;\">'?'</span>&nbsp;<span style=\"color: #63a35c;\">'{print&nbsp;$2}'</span>&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;sort&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>u&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;wc&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>l</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0099cc;\">63349</span></div></div><div style=\"font-size: 9px; font-style: italic; margin-right: 5px; margin-top: -13px; text-align: right;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: #e5e5e5text-decoration:none;\" target=\"_blank\">Colored by Color Scripter</a></div></td><td style=\"padding: 0px 2px 4px 0px; vertical-align: bottom;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: white; text-decoration: none;\" target=\"_blank\"><span style=\"background-color: #e5e5e5; border-radius: 10px; color: white; font-size: 9px; padding: 1px; word-break: normal;\">cs</span></a></td></tr></tbody></table></div>\n<div><br /></div>\n<div>변수 고유개수 차원 축소1</div>\n<div class=\"colorscripter-code\" style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; overflow: auto; position: relative;\"><table cellpadding=\"0\" cellspacing=\"0\" class=\"colorscripter-code-table\" style=\"background-color: #fafafa; border-radius: 4px; border: none; margin: 0px; padding: 0px;\"><tbody><tr><td style=\"padding: 6px 0px; text-align: left;\"><div style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; line-height: 130%; margin: 0px; padding: 0px;\"><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">root@MHKANG:~<span style=\"color: #999999;\">#&nbsp;awk&nbsp;'{if&nbsp;($7&nbsp;~&nbsp;/\\?/)&nbsp;print&nbsp;$7}'&nbsp;2014.log&nbsp;|             &nbsp;</span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;awk&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>F&nbsp;<span style=\"color: #63a35c;\">'?'</span>&nbsp;<span style=\"color: #63a35c;\">'{print&nbsp;$2}'</span>&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span>&nbsp;</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;sed&nbsp;<span style=\"color: #63a35c;\">'s/[0-9]//g'</span>&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span>&nbsp;</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;sort&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>u&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span>&nbsp;</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;wc&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>l</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0099cc;\">330</span></div></div><div style=\"font-size: 9px; font-style: italic; margin-right: 5px; margin-top: -13px; text-align: right;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: #e5e5e5text-decoration:none;\" target=\"_blank\">Colored by Color Scripter</a></div></td><td style=\"padding: 0px 2px 4px 0px; vertical-align: bottom;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: white; text-decoration: none;\" target=\"_blank\"><span style=\"background-color: #e5e5e5; border-radius: 10px; color: white; font-size: 9px; padding: 1px; word-break: normal;\">cs</span></a></td></tr></tbody></table></div>\n<div><br /></div><div>변수 고유개수 차원 축소2</div>\n<div class=\"colorscripter-code\" style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; overflow: auto; position: relative;\"><table cellpadding=\"0\" cellspacing=\"0\" class=\"colorscripter-code-table\" style=\"background-color: #fafafa; border-radius: 4px; border: none; margin: 0px; padding: 0px;\"><tbody><tr><td style=\"padding: 6px 0px; text-align: left;\"><div style=\"color: #010101; font-family: Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; line-height: 130%; margin: 0px; padding: 0px;\"><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\">root@MHKANG:~<span style=\"color: #999999;\">#&nbsp;awk&nbsp;'{if&nbsp;($7&nbsp;~&nbsp;/\\?/)&nbsp;print&nbsp;$7}'&nbsp;2014.log&nbsp;|&nbsp;             </span></div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;awk&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>F&nbsp;<span style=\"color: #63a35c;\">'?'</span>&nbsp;<span style=\"color: #63a35c;\">'{print&nbsp;$2}'</span>&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span>&nbsp;</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;awk&nbsp;<span style=\"color: #63a35c;\">'{gsub(\"[0-9]\",&nbsp;\"\")}1'</span>&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span>&nbsp;</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;sort&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>u&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">|</span>&nbsp;</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">&gt;</span>&nbsp;wc&nbsp;<span style=\"color: #0086b3;\"></span><span style=\"color: #a71d5d;\">-</span>l</div><div style=\"line-height: 130%; padding: 0px 6px; white-space: pre;\"><span style=\"color: #0099cc;\">330</span></div></div><div style=\"font-size: 9px; font-style: italic; margin-right: 5px; margin-top: -13px; text-align: right;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: #e5e5e5text-decoration:none;\" target=\"_blank\">Colored by Color Scripter</a></div></td><td style=\"padding: 0px 2px 4px 0px; vertical-align: bottom;\"><a href=\"http://colorscripter.com/info#e\" style=\"color: white; text-decoration: none;\" target=\"_blank\"><span style=\"background-color: #e5e5e5; border-radius: 10px; color: white; font-size: 9px; padding: 1px; word-break: normal;\">cs</span></a></td></tr></tbody></table></div>\n<div><br /></div>\n<div>이런 경험이 쌓이고 모여 데이터를 다루는 감각을 키워준다. 그런데 이 모든 작업이 VIM이라는 하나의 툴에서 다 가능하다. 정규표현식 지원 범위도 훨씬 넓다.</div><div><br /></div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg3VOMoSs-U2o0bkxu43iFAEJ_rJfOtii3m0NO4rdZ9vpoU7o0yUhXT2EWDZD9JCu2TBmfm-pBRd3sGp-GrEzmsSC0zgNDR7KoSmf63GvzfKc2EtkNCke48a3GzINWsyRyZeHhSfHdLNbZaaBkS7u13j1qUjneeclgNmzGZ61XFjz_s0yTCA7kaEPe6BlHl/s627/4a37d798-cb48-423c-a096-812ff4b848f6.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"627\" data-original-width=\"480\" height=\"320\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg3VOMoSs-U2o0bkxu43iFAEJ_rJfOtii3m0NO4rdZ9vpoU7o0yUhXT2EWDZD9JCu2TBmfm-pBRd3sGp-GrEzmsSC0zgNDR7KoSmf63GvzfKc2EtkNCke48a3GzINWsyRyZeHhSfHdLNbZaaBkS7u13j1qUjneeclgNmzGZ61XFjz_s0yTCA7kaEPe6BlHl/s320/4a37d798-cb48-423c-a096-812ff4b848f6.png\" width=\"245\" /></a></div><br /></div><div><b>관련 글</b></div><div><ul style=\"text-align: left;\"><li><a href=\"https://kangmyounghun.blogspot.com/2025/07/vim-vs-awk.html\">VIM vs AWK</a></li><li><a href=\"http://kangmyounghun.blogspot.kr/2016/07/vim.html\" target=\"\">VIM 사용 설명서</a></li></ul></div>",
        "contentSnippet": "강의 이해를 위해 요구되는 사전 지식들.\n\n\n\n\n\n필수 요건으로로 못박고 싶지만 그랬다간 망할까봐 권장으로 타협. 출강 기관 측은 아예 빼자고 하는데 그러고 싶진 않다. 내 강의 정체성이기 때문.\n\n\n세상 모든 데이터는 문자열\n\n\nSQL이든 (엘라스틱/스플렁크 등의) NoSQL이든, 세상 모든 DB는 문자열 데이터를 깎고 다듬어 테이블 구조로 바꾸는 전처리 작업을 필수로 거친다. 그래야 데이터 분석을 시작할 수 있으니까.\n\n데이터는 테이블이다\n\n데이터를 분석하려면 엘라스틱이나 스플렁크가 아닌 데이터를 잘 알아야 한다. (의미 파악은 기본이고) 전체적인 구조는 어떤지, 내 목적에 맞는 범위는 어딘지, 그 범위의 데이터를 어떻게 가공해야 원하는 분석이 가능한지에 대한 감을 잡을 수 있어야 한다. 이런 감각을 일깨워주는 가장 확실한 방법은 결국 데이터를 직접 만져보는 것. \n\n프로젝트에서 데이터의 공간 변환, 공간 탐색 등의 전문적 단계에 진입하기 전에 학생들에게 데이터를 가지고 온갖 자질구레한 관찰을 해보도록 강제한다. 데이터의 질감을 느끼는 단계다. 이 과정에서 통찰과 관점이 생긴다\n\n\n이런 경험을 가장 쉽게 할 수 있는 환경이 바로 리눅스. 목적에 맞는 셋팅을 시도하는 과정에서 기본 편집기인 VIM을 사용할 수밖에 없으니까. \n\n\n문자열 데이터를 다루는 감을 익히는 데 문자열 편집기보다 더 좋은 툴이 있을까? \n\n\n꼭 VIM 때문에만 리눅스 경험을 주문하는 것도 아니다. 사실 리눅스는 운영체제 자체가 문자열 데이터 처리를 위한 종합선물세트라고 해도 과언이 아니기 때문.\n\n\n웹로그 메소드 발생 내역\n\n\nroot@MHKANG:~# awk '{print $6}' 2014.log |                             \n> awk -F '\"' '{print $2}' |\n> sort -u\n-\nCONNECT\nGET\nHEAD\nPOST\nquit\n\nColored by Color Scripter\ncs\n\n\n\n\n메소드 고유개수1\n\n\nroot@MHKANG:~# awk '{print $6}' 2014.log |                             \n> awk -F '\"' '{print $2}' |\n> sort -u |\n> wc -l\n6\n\nColored by Color Scripter\ncs\n\n\n\n\n메소드 고유개수2\n\n\nroot@MHKANG:~# awk '{print $6}' 2014.log |                             \n> awk -F '\"' '{print $2}' |\n> awk 'arr[$1]==\"\" {arr[$1]=\"x\"} END {print length(arr)}'\n6\n\nColored by Color Scripter\ncs\n\n\n\n\n변수 고유개수\n\n\nroot@MHKANG:~# awk '{if ($7 ~ /\\?/) print $7}' 2014.log |              \n> awk -F '?' '{print $2}' |\n> sort -u |\n> wc -l\n63349\n\nColored by Color Scripter\ncs\n\n\n\n\n변수 고유개수 차원 축소1\n\n\nroot@MHKANG:~# awk '{if ($7 ~ /\\?/) print $7}' 2014.log |              \n> awk -F '?' '{print $2}' | \n> sed 's/[0-9]//g' | \n> sort -u | \n> wc -l\n330\n\nColored by Color Scripter\ncs\n\n\n\n\n변수 고유개수 차원 축소2\n\n\nroot@MHKANG:~# awk '{if ($7 ~ /\\?/) print $7}' 2014.log |              \n> awk -F '?' '{print $2}' | \n> awk '{gsub(\"[0-9]\", \"\")}1' | \n> sort -u | \n> wc -l\n330\n\nColored by Color Scripter\ncs\n\n\n\n\n이런 경험이 쌓이고 모여 데이터를 다루는 감각을 키워준다. 그런데 이 모든 작업이 VIM이라는 하나의 툴에서 다 가능하다. 정규표현식 지원 범위도 훨씬 넓다.\n\n\n\n\n관련 글\n\nVIM vs AWK\nVIM 사용 설명서",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-6996994550640788536",
        "isoDate": "2025-08-24T04:04:00.002Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "콘텐츠 제작 혁명! 무료 GPTS 3종으로 초고속, 고품질 콘텐츠 만드는 법",
        "link": "http://muzbox.tistory.com/483647",
        "pubDate": "Mon, 25 Aug 2025 19:08:36 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483647#entry483647comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #3c4043;\">\n<div style=\"background-color: #e8f4fd; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">단 하나의 아이디어, 사진, 혹은 링크만으로도 전문가 수준의 콘텐츠를 뚝딱! 제가 직접 개발한 <b>무료 GPTS 3종</b>으로 인스타그램, 스레드 맞춤 콘텐츠는 물론, AI 음악 작곡, 그리고 SEO 최적화 블로그 글까지 초고속으로, 그것도 고품질로 만드는 비법을 공개합니다. 콘텐츠 제작의 새로운 지평을 경험해보세요!</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✨ 콘텐츠 제작, 왜 이렇게 어려울까요?</b></h2>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"무료GPTS 3종공개.jpeg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/biHiV8/btsP4g0tCiw/eNrCa81Lt63UMDeldqRh9K/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/biHiV8/btsP4g0tCiw/eNrCa81Lt63UMDeldqRh9K/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/biHiV8/btsP4g0tCiw/eNrCa81Lt63UMDeldqRh9K/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbiHiV8%2FbtsP4g0tCiw%2FeNrCa81Lt63UMDeldqRh9K%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"콘텐츠 제작 혁명! 무료 GPTS 3종으로 초고속, 고품질 콘텐츠 만드는 법\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"무료GPTS 3종공개.jpeg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;정말 많은 분들이 콘텐츠 제작의 어려움에 공감하실 거예요. 어떤 플랫폼에 맞춰서 글을 써야 할지, 눈길을 사로잡는 이미지는 어떻게 만들지, 심지어는 나만의 배경 음악까지&hellip; 창작의 과정은 늘 끝없는 고민과 시행착오의 연속이었습니다. 제가 겪어본 바로는, 아이디어가 있어도 그걸 현실로 구현하는 과정에서 지쳐버리는 경우가 정말 많았죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">하지만 오늘, 이러한 고충을 한 번에 날려버릴 수 있는 제가 직접 만든 <b>세 가지 특별한 GPTS</b>를 소개해 드릴까 합니다. 이 도구들은 단순한 글쓰기 보조를 넘어, 각 플랫폼의 특성에 맞춰 콘텐츠를 최적화하고, 복잡한 음악 생성 프롬프트를 자동으로 만들어주며, 심지어는 SEO까지 고려한 블로그 포스트를 HTML 코드로 척척 완성해 준답니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이제는 아이디어나 사진 한 장, 아니면 그저 블로그 링크 하나만으로도 각 분야의 전문가처럼 콘텐츠를 손쉽게 제작할 수 있는 새로운 시대가 열렸다고 해도 과언이 아닙니다. 많은 분들이 '지피티팍인데 왜 GPT만 소개하나요?'라고 궁금해하실 텐데요. 기존 챗GPT 사용자분들이 많고, GPT를 활용한 무료 연재 기획의 일환으로 이번 GPTS들을 먼저 선보이게 되었습니다. 자, 그럼 바로 시작해볼까요?</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  챗 지피티, 인스타 앤 쓰레드 맞춤 콘텐츠 제작소: 플랫폼별 최적화의 마법</b></h2>\n<p data-ke-size=\"size16\">&nbsp;첫 번째로 소개해 드릴 GPTS는 바로 <b>'챗 지피티, 인스타 앤 쓰레드 맞춤 콘텐츠 제작소'</b>입니다. 이 GPTS의 핵심은 <b>플랫폼별 맞춤화</b>예요. 같은 내용이라도 쓰레드와 인스타그램에서는 전혀 다른 접근 방식이 필요하다는 것을 여러분도 잘 아실 거예요. 이 GPTS는 사용자의 요청에 따라 \"어떤 플랫폼에 맞춰 드릴까요?\"라고 물어보며, 마치 플랫폼 전문가처럼 콘텐츠를 재구성해줍니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; font-weight: 600;\" data-ke-size=\"size23\">✔️ 쓰레드(Threads) 콘텐츠 제작의 비밀</h3>\n<p data-ke-size=\"size16\">쓰레드는 정말 빠르게 정보를 소비하는 플랫폼이죠? 그래서 이 GPTS는 <b>간결하고 강렬한 문장</b>으로 콘텐츠를 만듭니다. 제가 직접 써보니, 경어체 대신 친근한 반말체를 사용하고, 사용자의 주의를 즉시 끌 수 있는 임팩트 있는 '후크 메시지'로 시작해서 핵심 정보를 번호로 나열하는 방식이 정말 효과적이더라구요.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; font-weight: 600;\" data-ke-size=\"size23\">✔️ 인스타그램(Instagram) 감성 콘텐츠의 완성</h3>\n<p data-ke-size=\"size16\">반면 인스타그램은 시각적 요소와 커뮤니티가 중심입니다. 그래서 이 GPTS는 <b>친근한 경어체</b>를 사용해 팔로워들과 대화하듯 접근하고, 텍스트뿐만 아니라 <b>이미지 컨셉까지 함께 제안</b>해줍니다. 인포그래픽과 상세한 캡션, 그리고 필수 해시태그까지, 그야말로 완성형 콘텐츠를 만들어주는 거죠. 솔직히 저도 매번 놀랍니다.</p>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>GPTS 활용 Tip:</b> 단 하나의 아이디어, 블로그 링크, 혹은 사진만으로도 인스타그램과 쓰레드에 최적화된 콘텐츠를 만들 수 있어요. 블로그 포스팅 후 쓰레드에 요약 내용을 올릴 때 정말 편리하답니다!</div>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; font-weight: 600;\" data-ke-size=\"size23\">실제 작동 사례 살펴보기</h3>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>명언 콘텐츠 제작:</b> 대화창에 \"마음 챙김 명언 2개\"를 입력한 후 인스타그램을 선택하면, 명언과 함께 인스타그램에 적합한 메시지, 해시태그가 작성되고 이미지 생성 여부를 물어봅니다. 몇 가지 질문에 응답하면 메시지에 맞는 이미지 생성 프롬프트가 출력되고, 잠시 후 멋진 이미지가 생성됩니다.</li>\n<li><b>블로그 요약 &amp; 공유:</b> 블로그 주소를 입력하면 기사를 요약하고 플랫폼 선택을 요청합니다. 쓰레드를 선택하면 이모지와 함께 쓰레드에 적합한 후크 메시지가 생성되고, 이미지 생성도 가능하죠.</li>\n<li><b>사진 기반 메시지:</b> 사진을 업로드하고 적합한 메시지를 요청한 뒤 인스타그램을 선택하면, 사진을 분석해 사진에 맞는 메시지와 해시태그를 인스타그램 형식에 맞춰 출력해줍니다. 정말 스마트하지 않나요?</li>\n</ul>\n<p data-ke-size=\"size16\">보신 것처럼, 이 GPTS는 단순히 글을 쓰는 것을 넘어, 각 플랫폼의 특성을 정확히 이해하고 최적의 콘텐츠를 완성해 줍니다. 이제 여러분의 콘텐츠 제작이 훨씬 더 스마트해질 거예요!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h4 data-ke-size=\"size20\"><i><span style=\"color: #ef5369;\"><b>챗GPT 인스타 &amp; 쓰레드 맞춤 콘텐츠 제작소 바로가기</b></span></i></h4>\n<figure id=\"og_1756116397686\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"ChatGPT - 챗GPT 인스타 &amp; 쓰레드 맞춤 콘텐츠 제작소\" data-og-description=\"이야기를 들어주고, 배우고, 도전하는 대화형 AI 시스템\" data-og-host=\"chatgpt.com\" data-og-source-url=\"https://chatgpt.com/g/g-sPwysm1aN-caesgpt-inseuta-sseuredeu-majcum-kontenceu-jejagso\" data-og-url=\"https://chatgpt.com/?locale=ko-KR\" data-og-image=\"\"><a href=\"https://chatgpt.com/g/g-sPwysm1aN-caesgpt-inseuta-sseuredeu-majcum-kontenceu-jejagso\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://chatgpt.com/g/g-sPwysm1aN-caesgpt-inseuta-sseuredeu-majcum-kontenceu-jejagso\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">ChatGPT - 챗GPT 인스타 &amp; 쓰레드 맞춤 콘텐츠 제작소</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">이야기를 들어주고, 배우고, 도전하는 대화형 AI 시스템</p>\n<p class=\"og-host\" data-ke-size=\"size16\">chatgpt.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  수노 4.5 프롬프트 제네레이터: 나만의 AI 음악 작곡가</b></h2>\n<p data-ke-size=\"size16\">두 번째 GPTS는 바로 <b>'수노 4.5 프롬프트 제네레이터'</b>입니다. 이 GPTS는 수노(Suno) 부문에서 글로벌 5위를 자랑하고, 'AI로 노래를 만들어 1억 번 남자'가 사용했다는 바로 그 도구입니다. 말 그대로 AI 음악 작곡의 혁명을 가져왔다고 할 수 있죠.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; font-weight: 600;\" data-ke-size=\"size23\">수노 4.5, 무엇이 달라졌나?</h3>\n<p data-ke-size=\"size16\">최고의 인공지능 프롬프트 기반 음악 생성 서비스인 수노가 버전 4.5로 업데이트되면서, 이전 4.0 버전과는 완전히 다른 차원의 프롬프트가 필요해졌습니다. 기존 4.0은 간결한 형태로 기본적인 음악 특성에만 집중했지만, 4.5부터는 <b>음향 텍스처, 악기 간 상호작용, 섹션별 전개</b>까지 구체적으로 설명하는 <b>전문적이고 세밀한 프롬프트</b>가 필수적이 되었죠. 바로 이러한 변화에 대응하기 위해 이 GPTS를 만들게 되었습니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; font-weight: 600;\" data-ke-size=\"size23\">90가지 히트곡 장르 데이터베이스의 힘</h3>\n<p data-ke-size=\"size16\">이 GPTS의 가장 특별한 기능은 바로 <b>글로벌 대표 히트곡 아흔 가지 장르별 데이터베이스</b>를 활용한다는 점입니다. 제가 직접 조사하고 정리한 PDF 문서에는 각 장르별 수노 프롬프트 예시와 구조 형식이 담겨 있는데, 이 GPTS는 사용자의 키워드에 가장 적합한 구조를 자동으로 찾아 적용해줍니다. 가사 생성 원리도 체계적이라, 프롬프트 생성 후 가사가 필요한지 물어보고 요청하면 해당 장르에 맞는 구조를 PDF에서 찾아 참조하여 멋진 가사를 만들어냅니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; font-weight: 600;\" data-ke-size=\"size23\">나만의 곡 만들기, 어렵지 않아요!</h3>\n<div style=\"background-color: #e8f0fe; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">\n<p data-ke-size=\"size16\">채팅창에 다음과 같이 입력해 보세요:</p>\n<ul style=\"margin-top: 10px; padding-left: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px;\"><b>'새로운 아침을 운동과 함께 시작하면서 듣는 시티팝 뮤직'</b></li>\n<li style=\"margin-bottom: 5px;\"><b>'마블 어벤저스 주제곡 느낌' (연주곡)</b></li>\n<li><b>'나훈아의 고향역' (가수와 곡 스타일)</b></li>\n</ul>\n</div>\n<p data-ke-size=\"size16\">이런 요청사항에 적합한 음악 생성 프롬프트(4.0 및 4.5 버전)가 생성되고, 가사 생성 여부를 묻습니다. 한국어 가사를 요청하면 아흔 가지 노래 목록에서 적합한 구조를 찾아 가사를 생성해줍니다. 심지어 '나훈아의 고향역'처럼 유명한 곡은 트로트 장르임을 인식하고 한국 고전 트로트 스타일의 프롬프트와 가사를 생성해내는 것을 보고 정말 놀랐습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이제 수노로 가서 GPTS가 생성한 음악 스타일, 노래 제목, 그리고 가사를 붙여넣고 생성 버튼만 누르면 작업 완료! 누구나 마음속에 품고 있던 자신만의 노래를 세상 밖으로 꺼내기가 막막하셨다면, '수노 4.5 프롬프트 제네레이터'가 여러분의 숨겨진 음악적 재능을 깨워줄 겁니다. 지금 바로 여러분의 이야기를 노래로 만들어보세요. 저도 얼마 전에 이 기능을 이용해서 기념일 축하곡을 만들었는데, 반응이 정말 좋았어요!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h4 data-ke-size=\"size20\"><span style=\"color: #ef5369;\"><i><b>Suno 4.5 Prompt Generator 바로가기</b></i></span></h4>\n<figure id=\"og_1756116424686\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"ChatGPT - Suno 4.5 Prompt Generator\" data-og-description=\"이야기를 들어주고, 배우고, 도전하는 대화형 AI 시스템\" data-og-host=\"chatgpt.com\" data-og-source-url=\"https://chatgpt.com/g/g-681480f8a4688191b94abd2af3c3390a-suno-4-5-prompt-generator\" data-og-url=\"https://chatgpt.com/?locale=ko-KR\" data-og-image=\"\"><a href=\"https://chatgpt.com/g/g-681480f8a4688191b94abd2af3c3390a-suno-4-5-prompt-generator\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://chatgpt.com/g/g-681480f8a4688191b94abd2af3c3390a-suno-4-5-prompt-generator\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">ChatGPT - Suno 4.5 Prompt Generator</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">이야기를 들어주고, 배우고, 도전하는 대화형 AI 시스템</p>\n<p class=\"og-host\" data-ke-size=\"size16\">chatgpt.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✍️ 시각화 블로그 기사 생성 GPTS: SEO 최적화 블로그 자동화</b></h2>\n<p data-ke-size=\"size16\">마지막으로 소개해 드릴 GPTS는 바로 <b>'시각화 블로그 기사 생성 GPTS'</b>입니다. 이 도구는 사용자가 간단한 주제나 키워드만 입력하면, <b>완전한 HTML 형식의 고품질 블로그 포스트</b>를 자동으로 생성해주는, 제가 정말 애정하는 GPTS입니다.</p>\n<div style=\"background-color: #fce8e6; border-left: 4px solid #d93025; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">⚠️ <b>중요 소식:</b> 그동안 HTML 소스 배포에 컨텍스트 용량 부족의 어려움이 있었지만, 이번 <b>GPT-5 업데이트</b>로 문제가 해결되어 챗GPT에서도 동일한 수준의 HTML 블로그 기사 생성이 가능해졌습니다! 플러스 사용자 기준으로 기존 8K 토큰에서 32K 토큰으로 약 4배 증가한 덕분이죠. 이제 3,000자 분량의 HTML 블로그 포스트를 한 번에 완성할 수 있어요.</div>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; font-weight: 600;\" data-ke-size=\"size23\">GPTs의 4단계 HTML 생성 원리</h3>\n<p data-ke-size=\"size16\">이 GPTS는 총 4단계의 체계적인 과정을 거쳐 블로그 기사를 HTML로 생성합니다. 정말 효율적이죠!</p>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>카테고리 선택:</b> 블로그 주제를 정하지 못했다면, 먼저 분야별 주제를 요청해 보세요. 재정 투자, IT 기술 등 총 8개의 카테고리 중 선택하면 GPT가 적절한 주제를 제안합니다.</li>\n<li><b>주제 보강 검토:</b> 선택된 주제가 사용자가 요청한 분량(글자 수)에 적합한지 검토합니다. 만약 분량이 부족할 것으로 예상되면, GPT가 주제를 보강해서 제안해줍니다. 이 과정이 글의 완성도를 높이는 데 아주 중요해요.</li>\n<li><b>컬러 테마 선택:</b> 총 10가지 컬러 테마 중에서 선택합니다. 이 테마에 따라 HTML 소스에 적용될 색상이 결정되어 시각적으로 아름다운 블로그를 만들 수 있습니다.</li>\n<li><b>HTML 생성:</b> 선택된 테마에 맞는 완전한 HTML 코드를 생성합니다. HTML 생성 완료 후에는 핵심 키워드, 대표 이미지 생성 프롬프트, SEO 최적화 제목 5개 등의 추가 정보와 함께 <b>스키마까지 자동으로 출력</b>되어 완벽한 SEO 최적화가 가능합니다.</li>\n</ol>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 12px; font-weight: 600;\" data-ke-size=\"size23\">어떻게 활용할 수 있을까요?</h3>\n<p data-ke-size=\"size16\">카테고리를 선택하여 진행하거나, 바로 주제를 입력하는 두 가지 방식으로 활용할 수 있습니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>카테고리 선택 예시:</b> 첫 화면에서 '분야별 블로그 주제를 제안해줘'를 클릭한 후, 예를 들어 2번 'IT, 기술' 분야를 선택합니다. GPT가 IT 관련 주제를 보여주는데, 여기서 하나를 선택하면 분량이 부족할 경우 주제를 자동으로 보강해줍니다. 그 다음 컬러 테마를 선택하면 바로 기사 작성 계획을 보여주며 HTML 기사를 생성합니다.</li>\n<li><b>주제 직접 입력 예시:</b> 대화창에 \"건강한 사람들의 아침 루틴\"과 같은 주제를 직접 입력해 보세요. 그러면 카테고리 선택 때와 동일하게 분량 조절을 위해 주제를 보강하고, 컬러 테마 선택 후 바로 기사를 작성합니다. 만약 생성된 기사 분량이 생각보다 적다면, \"관련된 섹션을 2개 더 추가하고 기사를 확장해\"라고 요청하여 풍부한 내용의 기사를 만들 수 있습니다.</li>\n</ul>\n<p data-ke-size=\"size16\">이처럼 '시각화 블로그 기사 생성 GPTS'를 활용하면 몇 번의 클릭과 간단한 요청만으로 <b>SEO까지 완벽하게 최적화된 고품질의 블로그 포스트</b>를 손쉽게 완성할 수 있습니다. 코드펜에서 결과물을 확인해보면, 정말 문제없이 기사가 잘 작성된 것을 볼 수 있을 거예요. 블로그 콘텐츠 제작의 효율을 극대화하고 싶다면 이 강력한 도구를 꼭 사용해보시길 바랍니다!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h4 data-ke-size=\"size20\"><span style=\"color: #ef5369;\"><i><b>시각화 블로그 기사 생성 바로가기</b></i></span></h4>\n<figure id=\"og_1756116453697\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"ChatGPT - 시각화 블로그 기사 생성\" data-og-description=\"이야기를 들어주고, 배우고, 도전하는 대화형 AI 시스템\" data-og-host=\"chatgpt.com\" data-og-source-url=\"https://chatgpt.com/g/g-68a79cc071288191b22eeb89edeb0608-sigaghwa-beulrogeu-gisa-saengseong\" data-og-url=\"https://chatgpt.com/?locale=ko-KR\" data-og-image=\"\"><a href=\"https://chatgpt.com/g/g-68a79cc071288191b22eeb89edeb0608-sigaghwa-beulrogeu-gisa-saengseong\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://chatgpt.com/g/g-68a79cc071288191b22eeb89edeb0608-sigaghwa-beulrogeu-gisa-saengseong\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">ChatGPT - 시각화 블로그 기사 생성</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">이야기를 들어주고, 배우고, 도전하는 대화형 AI 시스템</p>\n<p class=\"og-host\" data-ke-size=\"size16\">chatgpt.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<style>\n    /* This style block ensures the summary card is responsive on mobile devices. */\n    @media (max-width: 768px) {\n        .single-summary-card {\n            padding: 18px !important;\n        }\n        .single-summary-card .card-header-icon {\n            font-size: 28px !important;\n            margin-right: 10px !important;\n        }\n        .single-summary-card .card-header h3 {\n            font-size: 20px !important;\n        }\n        .single-summary-card .card-content {\n            font-size: 15px !important;\n            line-height: 1.5 !important;\n        }\n        .single-summary-card .card-content .section {\n            margin-bottom: 8px !important;\n        }\n        .single-summary-card .card-footer {\n            font-size: 13px !important;\n            padding-top: 10px !important;\n        }\n    }\n    @media (max-width: 480px) {\n        .single-summary-card {\n            padding: 15px !important;\n        }\n        .single-summary-card .card-header-icon {\n            font-size: 26px !important;\n        }\n        .single-summary-card .card-header h3 {\n            font-size: 18px !important;\n        }\n        .single-summary-card .card-content {\n            font-size: 14px !important;\n            line-height: 1.4 !important;\n        }\n        .single-summary-card .card-content .section {\n            margin-bottom: 6px !important;\n        }\n        .single-summary-card .card-footer {\n            font-size: 12px !important;\n            padding-top: 8px !important;\n        }\n    }\n</style>\n<div class=\"single-summary-card-container\" style=\"font-family: 'Noto Sans KR', sans-serif; display: flex; justify-content: center; align-items: center; padding: 20px 10px; background-color: transparent; margin: 20px 0;\">\n<div class=\"single-summary-card\" style=\"width: 100%; max-width: 700px; background-color: #f8f9fa; border-radius: 12px; box-shadow: 0 6px 18px rgba(0,0,0,0.12); padding: 25px; display: flex; flex-direction: column; overflow: hidden; border: 1px solid #dadce0; box-sizing: border-box; height: auto;\">\n<div class=\"card-header\" style=\"display: flex; align-items: center; border-bottom: 2px solid #1a73e8; padding-bottom: 12px; margin-bottom: 12px;\"><span style=\"font-size: 34px; color: #1a73e8; margin-right: 14px;\" class=\"card-header-icon\"> </span>\n<h3 style=\"font-size: 26px; color: #1a73e8; margin: 0; line-height: 1.3; font-weight: bold;\" data-ke-size=\"size23\">핵심 요약</h3>\n</div>\n<div class=\"card-content\" style=\"flex-grow: 1; display: flex; flex-direction: column; justify-content: space-around; font-size: 17px; line-height: 1.65; color: #3c4043;\">\n<div class=\"section\" style=\"margin-bottom: 10px;\"><b>✨ 첫 번째 핵심:</b> <b>무료 GPTS 3종으로 콘텐츠 제작의 모든 고민을 해결!</b></div>\n<div class=\"section\" style=\"margin-bottom: 10px;\"><b>  두 번째 핵심:</b> <b>플랫폼(인스타/쓰레드) 맞춤 콘텐츠, AI가 자동으로 최적화.</b></div>\n<div class=\"section\" style=\"margin-bottom: 10px;\"><b>  세 번째 핵심:</b> <b>수노 4.5 프롬프트 제네레이터로 전문적인 AI 음악 손쉽게 작곡.</b></div>\n<div class=\"section\" style=\"margin-bottom: 10px;\"><b> &zwj;  네 번째 핵심:</b> <b>GPT-5의 힘으로 SEO 최적화 HTML 블로그를 한 번에 생성.</b></div>\n</div>\n<div class=\"card-footer\" style=\"font-size: 14px; color: #5f6368; text-align: center; padding-top: 12px; border-top: 1px dashed #dadce0; margin-top: auto;\">이 GPTS들은 여러분의 시간과 노력을 절약하고 창의력을 극대화하는 데 도움을 줄 것입니다.</div>\n</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<div style=\"margin-bottom: 15px;\">\n<h3 style=\"font-size: 18px; color: #004d99; margin: 15px 0 8px; font-weight: 600;\" data-ke-size=\"size23\">Q1: 소개된 GPTS들은 모두 무료로 사용할 수 있나요?</h3>\n<p data-ke-size=\"size16\">A1: 네, 제가 직접 만든 이 3가지 GPTS는 모두 무료로 사용할 수 있도록 공개되었습니다. 챗GPT 플러스 사용자라면 누구든지 접근하여 활용할 수 있습니다. 단, 수노와 같은 외부 서비스 이용 시 해당 서비스의 정책에 따라 비용이 발생할 수 있습니다.</p>\n</div>\n<div style=\"margin-bottom: 15px;\">\n<h3 style=\"font-size: 18px; color: #004d99; margin: 15px 0 8px; font-weight: 600;\" data-ke-size=\"size23\">Q2: 블로그 기사 생성 GPTS가 HTML 코드를 생성한다고 했는데, 추가적인 편집이 필요한가요?</h3>\n<p data-ke-size=\"size16\">A2: 이 GPTS는 SEO에 최적화된 완전한 HTML 코드를 생성해주므로, 기본적인 구조와 스타일은 바로 사용할 수 있습니다. 물론, 개인의 브랜드 아이덴티티나 특정 디자인 요구사항에 맞춰 세부적인 편집이나 추가 스타일링을 하는 것은 얼마든지 가능하며, 코드펜에서 미리 확인하고 수정하는 것을 추천합니다.</p>\n</div>\n<div style=\"margin-bottom: 15px;\">\n<h3 style=\"font-size: 18px; color: #004d99; margin: 15px 0 8px; font-weight: 600;\" data-ke-size=\"size23\">Q3: 수노 4.5 프롬프트 제네레이터로 만든 음악은 상업적으로 이용할 수 있나요?</h3>\n<p data-ke-size=\"size16\">A3: 수노 4.5 프롬프트 제네레이터는 수노 서비스를 활용하여 음악을 만드는 것을 돕는 도구입니다. 생성된 음악의 상업적 이용 가능 여부는 수노(Suno) 서비스의 라이선스 및 이용 약관에 따라 달라지므로, 수노 공식 웹사이트에서 관련 정책을 확인하시는 것이 가장 정확합니다.</p>\n</div>\n<script type=\"application/ld+json\">\n  {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n      {\n        \"@type\": \"Question\",\n        \"name\": \"소개된 GPTS들은 모두 무료로 사용할 수 있나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"네, 제가 직접 만든 이 3가지 GPTS는 모두 무료로 사용할 수 있도록 공개되었습니다. 챗GPT 플러스 사용자라면 누구든지 접근하여 활용할 수 있습니다. 단, 수노와 같은 외부 서비스 이용 시 해당 서비스의 정책에 따라 비용이 발생할 수 있습니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"블로그 기사 생성 GPTS가 HTML 코드를 생성한다고 했는데, 추가적인 편집이 필요한가요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"이 GPTS는 SEO에 최적화된 완전한 HTML 코드를 생성해주므로, 기본적인 구조와 스타일은 바로 사용할 수 있습니다. 물론, 개인의 브랜드 아이덴티티나 특정 디자인 요구사항에 맞춰 세부적인 편집이나 추가 스타일링을 하는 것은 얼마든지 가능하며, 코드펜에서 미리 확인하고 수정하는 것을 추천합니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"수노 4.5 프롬프트 제네레이터로 만든 음악은 상업적으로 이용할 수 있나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"수노 4.5 프롬프트 제네레이터는 수노 서비스를 활용하여 음악을 만드는 것을 돕는 도구입니다. 생성된 음악의 상업적 이용 가능 여부는 수노(Suno) 서비스의 라이선스 및 이용 약관에 따라 달라지므로, 수노 공식 웹사이트에서 관련 정책을 확인하시는 것이 가장 정확합니다.\"\n        }\n      }\n    ]\n  }\n  </script>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>마무리하며: 콘텐츠 제작의 미래, 여러분의 손에!</b></h2>\n<p data-ke-size=\"size16\">이번 포스팅에서는 SNS 맞춤 콘텐츠 제작부터 AI 음악 작곡, 그리고 SEO에 최적화된 블로그 자동 생성까지, 여러분의 콘텐츠 제작을 훨씬 더 스마트하고 효율적으로 만들어 줄 <b>3가지 무료 GPTS</b>를 소개해 드렸습니다. 솔직히 저도 이 도구들을 만들면서 '와, 정말 여기까지 왔구나' 하고 감탄했거든요.</p>\n<p data-ke-size=\"size16\">이 GPTS들이 여러분의 창작 활동에 새로운 활력을 불어넣고, 시간과 노력을 절약하는 데 큰 도움이 되기를 진심으로 바랍니다. 콘텐츠 제작의 부담을 덜고, 더 많은 아이디어를 자유롭게 펼쳐나가시길 응원합니다!</p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=BgIQHYykMds\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/fyOqA/hyZC24SV1F/ocw11tJky5keBYm0cOsIB0/img.jpg?width=1280&amp;height=720&amp;face=706_116_890_318,https://scrap.kakaocdn.net/dn/oq6dh/hyZDWwcw0d/UTjRFK4m0IXBpsgkkzyWi0/img.jpg?width=1280&amp;height=720&amp;face=706_116_890_318\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"이 무료 GPTS 3개면, 당신도 오늘부터 콘텐츠 전문가가 됩니다 (SNS, AI음악, 블로그 자동화) | 챗GPT \" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/BgIQHYykMds\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n</div>",
        "contentSnippet": "단 하나의 아이디어, 사진, 혹은 링크만으로도 전문가 수준의 콘텐츠를 뚝딱! 제가 직접 개발한 무료 GPTS 3종으로 인스타그램, 스레드 맞춤 콘텐츠는 물론, AI 음악 작곡, 그리고 SEO 최적화 블로그 글까지 초고속으로, 그것도 고품질로 만드는 비법을 공개합니다. 콘텐츠 제작의 새로운 지평을 경험해보세요!\n✨ 콘텐츠 제작, 왜 이렇게 어려울까요?\n\n\n \n 정말 많은 분들이 콘텐츠 제작의 어려움에 공감하실 거예요. 어떤 플랫폼에 맞춰서 글을 써야 할지, 눈길을 사로잡는 이미지는 어떻게 만들지, 심지어는 나만의 배경 음악까지… 창작의 과정은 늘 끝없는 고민과 시행착오의 연속이었습니다. 제가 겪어본 바로는, 아이디어가 있어도 그걸 현실로 구현하는 과정에서 지쳐버리는 경우가 정말 많았죠.\n \n하지만 오늘, 이러한 고충을 한 번에 날려버릴 수 있는 제가 직접 만든 세 가지 특별한 GPTS를 소개해 드릴까 합니다. 이 도구들은 단순한 글쓰기 보조를 넘어, 각 플랫폼의 특성에 맞춰 콘텐츠를 최적화하고, 복잡한 음악 생성 프롬프트를 자동으로 만들어주며, 심지어는 SEO까지 고려한 블로그 포스트를 HTML 코드로 척척 완성해 준답니다.\n \n이제는 아이디어나 사진 한 장, 아니면 그저 블로그 링크 하나만으로도 각 분야의 전문가처럼 콘텐츠를 손쉽게 제작할 수 있는 새로운 시대가 열렸다고 해도 과언이 아닙니다. 많은 분들이 '지피티팍인데 왜 GPT만 소개하나요?'라고 궁금해하실 텐데요. 기존 챗GPT 사용자분들이 많고, GPT를 활용한 무료 연재 기획의 일환으로 이번 GPTS들을 먼저 선보이게 되었습니다. 자, 그럼 바로 시작해볼까요?\n  챗 지피티, 인스타 앤 쓰레드 맞춤 콘텐츠 제작소: 플랫폼별 최적화의 마법\n 첫 번째로 소개해 드릴 GPTS는 바로 '챗 지피티, 인스타 앤 쓰레드 맞춤 콘텐츠 제작소'입니다. 이 GPTS의 핵심은 플랫폼별 맞춤화예요. 같은 내용이라도 쓰레드와 인스타그램에서는 전혀 다른 접근 방식이 필요하다는 것을 여러분도 잘 아실 거예요. 이 GPTS는 사용자의 요청에 따라 \"어떤 플랫폼에 맞춰 드릴까요?\"라고 물어보며, 마치 플랫폼 전문가처럼 콘텐츠를 재구성해줍니다.\n✔️ 쓰레드(Threads) 콘텐츠 제작의 비밀\n쓰레드는 정말 빠르게 정보를 소비하는 플랫폼이죠? 그래서 이 GPTS는 간결하고 강렬한 문장으로 콘텐츠를 만듭니다. 제가 직접 써보니, 경어체 대신 친근한 반말체를 사용하고, 사용자의 주의를 즉시 끌 수 있는 임팩트 있는 '후크 메시지'로 시작해서 핵심 정보를 번호로 나열하는 방식이 정말 효과적이더라구요.\n✔️ 인스타그램(Instagram) 감성 콘텐츠의 완성\n반면 인스타그램은 시각적 요소와 커뮤니티가 중심입니다. 그래서 이 GPTS는 친근한 경어체를 사용해 팔로워들과 대화하듯 접근하고, 텍스트뿐만 아니라 이미지 컨셉까지 함께 제안해줍니다. 인포그래픽과 상세한 캡션, 그리고 필수 해시태그까지, 그야말로 완성형 콘텐츠를 만들어주는 거죠. 솔직히 저도 매번 놀랍니다.\n  GPTS 활용 Tip: 단 하나의 아이디어, 블로그 링크, 혹은 사진만으로도 인스타그램과 쓰레드에 최적화된 콘텐츠를 만들 수 있어요. 블로그 포스팅 후 쓰레드에 요약 내용을 올릴 때 정말 편리하답니다!\n실제 작동 사례 살펴보기\n명언 콘텐츠 제작: 대화창에 \"마음 챙김 명언 2개\"를 입력한 후 인스타그램을 선택하면, 명언과 함께 인스타그램에 적합한 메시지, 해시태그가 작성되고 이미지 생성 여부를 물어봅니다. 몇 가지 질문에 응답하면 메시지에 맞는 이미지 생성 프롬프트가 출력되고, 잠시 후 멋진 이미지가 생성됩니다.\n블로그 요약 & 공유: 블로그 주소를 입력하면 기사를 요약하고 플랫폼 선택을 요청합니다. 쓰레드를 선택하면 이모지와 함께 쓰레드에 적합한 후크 메시지가 생성되고, 이미지 생성도 가능하죠.\n사진 기반 메시지: 사진을 업로드하고 적합한 메시지를 요청한 뒤 인스타그램을 선택하면, 사진을 분석해 사진에 맞는 메시지와 해시태그를 인스타그램 형식에 맞춰 출력해줍니다. 정말 스마트하지 않나요?\n보신 것처럼, 이 GPTS는 단순히 글을 쓰는 것을 넘어, 각 플랫폼의 특성을 정확히 이해하고 최적의 콘텐츠를 완성해 줍니다. 이제 여러분의 콘텐츠 제작이 훨씬 더 스마트해질 거예요!\n \n챗GPT 인스타 & 쓰레드 맞춤 콘텐츠 제작소 바로가기\n\n \nChatGPT - 챗GPT 인스타 & 쓰레드 맞춤 콘텐츠 제작소\n이야기를 들어주고, 배우고, 도전하는 대화형 AI 시스템\nchatgpt.com\n\n \n  수노 4.5 프롬프트 제네레이터: 나만의 AI 음악 작곡가\n두 번째 GPTS는 바로 '수노 4.5 프롬프트 제네레이터'입니다. 이 GPTS는 수노(Suno) 부문에서 글로벌 5위를 자랑하고, 'AI로 노래를 만들어 1억 번 남자'가 사용했다는 바로 그 도구입니다. 말 그대로 AI 음악 작곡의 혁명을 가져왔다고 할 수 있죠.\n수노 4.5, 무엇이 달라졌나?\n최고의 인공지능 프롬프트 기반 음악 생성 서비스인 수노가 버전 4.5로 업데이트되면서, 이전 4.0 버전과는 완전히 다른 차원의 프롬프트가 필요해졌습니다. 기존 4.0은 간결한 형태로 기본적인 음악 특성에만 집중했지만, 4.5부터는 음향 텍스처, 악기 간 상호작용, 섹션별 전개까지 구체적으로 설명하는 전문적이고 세밀한 프롬프트가 필수적이 되었죠. 바로 이러한 변화에 대응하기 위해 이 GPTS를 만들게 되었습니다.\n90가지 히트곡 장르 데이터베이스의 힘\n이 GPTS의 가장 특별한 기능은 바로 글로벌 대표 히트곡 아흔 가지 장르별 데이터베이스를 활용한다는 점입니다. 제가 직접 조사하고 정리한 PDF 문서에는 각 장르별 수노 프롬프트 예시와 구조 형식이 담겨 있는데, 이 GPTS는 사용자의 키워드에 가장 적합한 구조를 자동으로 찾아 적용해줍니다. 가사 생성 원리도 체계적이라, 프롬프트 생성 후 가사가 필요한지 물어보고 요청하면 해당 장르에 맞는 구조를 PDF에서 찾아 참조하여 멋진 가사를 만들어냅니다.\n나만의 곡 만들기, 어렵지 않아요!\n채팅창에 다음과 같이 입력해 보세요:\n'새로운 아침을 운동과 함께 시작하면서 듣는 시티팝 뮤직'\n'마블 어벤저스 주제곡 느낌' (연주곡)\n'나훈아의 고향역' (가수와 곡 스타일)\n이런 요청사항에 적합한 음악 생성 프롬프트(4.0 및 4.5 버전)가 생성되고, 가사 생성 여부를 묻습니다. 한국어 가사를 요청하면 아흔 가지 노래 목록에서 적합한 구조를 찾아 가사를 생성해줍니다. 심지어 '나훈아의 고향역'처럼 유명한 곡은 트로트 장르임을 인식하고 한국 고전 트로트 스타일의 프롬프트와 가사를 생성해내는 것을 보고 정말 놀랐습니다.\n \n이제 수노로 가서 GPTS가 생성한 음악 스타일, 노래 제목, 그리고 가사를 붙여넣고 생성 버튼만 누르면 작업 완료! 누구나 마음속에 품고 있던 자신만의 노래를 세상 밖으로 꺼내기가 막막하셨다면, '수노 4.5 프롬프트 제네레이터'가 여러분의 숨겨진 음악적 재능을 깨워줄 겁니다. 지금 바로 여러분의 이야기를 노래로 만들어보세요. 저도 얼마 전에 이 기능을 이용해서 기념일 축하곡을 만들었는데, 반응이 정말 좋았어요!\n \nSuno 4.5 Prompt Generator 바로가기\n\n \nChatGPT - Suno 4.5 Prompt Generator\n이야기를 들어주고, 배우고, 도전하는 대화형 AI 시스템\nchatgpt.com\n\n \n✍️ 시각화 블로그 기사 생성 GPTS: SEO 최적화 블로그 자동화\n마지막으로 소개해 드릴 GPTS는 바로 '시각화 블로그 기사 생성 GPTS'입니다. 이 도구는 사용자가 간단한 주제나 키워드만 입력하면, 완전한 HTML 형식의 고품질 블로그 포스트를 자동으로 생성해주는, 제가 정말 애정하는 GPTS입니다.\n⚠️ 중요 소식: 그동안 HTML 소스 배포에 컨텍스트 용량 부족의 어려움이 있었지만, 이번 GPT-5 업데이트로 문제가 해결되어 챗GPT에서도 동일한 수준의 HTML 블로그 기사 생성이 가능해졌습니다! 플러스 사용자 기준으로 기존 8K 토큰에서 32K 토큰으로 약 4배 증가한 덕분이죠. 이제 3,000자 분량의 HTML 블로그 포스트를 한 번에 완성할 수 있어요.\nGPTs의 4단계 HTML 생성 원리\n이 GPTS는 총 4단계의 체계적인 과정을 거쳐 블로그 기사를 HTML로 생성합니다. 정말 효율적이죠!\n카테고리 선택: 블로그 주제를 정하지 못했다면, 먼저 분야별 주제를 요청해 보세요. 재정 투자, IT 기술 등 총 8개의 카테고리 중 선택하면 GPT가 적절한 주제를 제안합니다.\n주제 보강 검토: 선택된 주제가 사용자가 요청한 분량(글자 수)에 적합한지 검토합니다. 만약 분량이 부족할 것으로 예상되면, GPT가 주제를 보강해서 제안해줍니다. 이 과정이 글의 완성도를 높이는 데 아주 중요해요.\n컬러 테마 선택: 총 10가지 컬러 테마 중에서 선택합니다. 이 테마에 따라 HTML 소스에 적용될 색상이 결정되어 시각적으로 아름다운 블로그를 만들 수 있습니다.\nHTML 생성: 선택된 테마에 맞는 완전한 HTML 코드를 생성합니다. HTML 생성 완료 후에는 핵심 키워드, 대표 이미지 생성 프롬프트, SEO 최적화 제목 5개 등의 추가 정보와 함께 스키마까지 자동으로 출력되어 완벽한 SEO 최적화가 가능합니다.\n어떻게 활용할 수 있을까요?\n카테고리를 선택하여 진행하거나, 바로 주제를 입력하는 두 가지 방식으로 활용할 수 있습니다.\n카테고리 선택 예시: 첫 화면에서 '분야별 블로그 주제를 제안해줘'를 클릭한 후, 예를 들어 2번 'IT, 기술' 분야를 선택합니다. GPT가 IT 관련 주제를 보여주는데, 여기서 하나를 선택하면 분량이 부족할 경우 주제를 자동으로 보강해줍니다. 그 다음 컬러 테마를 선택하면 바로 기사 작성 계획을 보여주며 HTML 기사를 생성합니다.\n주제 직접 입력 예시: 대화창에 \"건강한 사람들의 아침 루틴\"과 같은 주제를 직접 입력해 보세요. 그러면 카테고리 선택 때와 동일하게 분량 조절을 위해 주제를 보강하고, 컬러 테마 선택 후 바로 기사를 작성합니다. 만약 생성된 기사 분량이 생각보다 적다면, \"관련된 섹션을 2개 더 추가하고 기사를 확장해\"라고 요청하여 풍부한 내용의 기사를 만들 수 있습니다.\n이처럼 '시각화 블로그 기사 생성 GPTS'를 활용하면 몇 번의 클릭과 간단한 요청만으로 SEO까지 완벽하게 최적화된 고품질의 블로그 포스트를 손쉽게 완성할 수 있습니다. 코드펜에서 결과물을 확인해보면, 정말 문제없이 기사가 잘 작성된 것을 볼 수 있을 거예요. 블로그 콘텐츠 제작의 효율을 극대화하고 싶다면 이 강력한 도구를 꼭 사용해보시길 바랍니다!\n \n시각화 블로그 기사 생성 바로가기\n\n \nChatGPT - 시각화 블로그 기사 생성\n이야기를 들어주고, 배우고, 도전하는 대화형 AI 시스템\nchatgpt.com\n\n \n \n핵심 요약\n✨ 첫 번째 핵심: 무료 GPTS 3종으로 콘텐츠 제작의 모든 고민을 해결!\n  두 번째 핵심: 플랫폼(인스타/쓰레드) 맞춤 콘텐츠, AI가 자동으로 최적화.\n  세 번째 핵심: 수노 4.5 프롬프트 제네레이터로 전문적인 AI 음악 손쉽게 작곡.\n ‍  네 번째 핵심: GPT-5의 힘으로 SEO 최적화 HTML 블로그를 한 번에 생성.\n이 GPTS들은 여러분의 시간과 노력을 절약하고 창의력을 극대화하는 데 도움을 줄 것입니다.\n❓ 자주 묻는 질문 (FAQ)\nQ1: 소개된 GPTS들은 모두 무료로 사용할 수 있나요?\nA1: 네, 제가 직접 만든 이 3가지 GPTS는 모두 무료로 사용할 수 있도록 공개되었습니다. 챗GPT 플러스 사용자라면 누구든지 접근하여 활용할 수 있습니다. 단, 수노와 같은 외부 서비스 이용 시 해당 서비스의 정책에 따라 비용이 발생할 수 있습니다.\nQ2: 블로그 기사 생성 GPTS가 HTML 코드를 생성한다고 했는데, 추가적인 편집이 필요한가요?\nA2: 이 GPTS는 SEO에 최적화된 완전한 HTML 코드를 생성해주므로, 기본적인 구조와 스타일은 바로 사용할 수 있습니다. 물론, 개인의 브랜드 아이덴티티나 특정 디자인 요구사항에 맞춰 세부적인 편집이나 추가 스타일링을 하는 것은 얼마든지 가능하며, 코드펜에서 미리 확인하고 수정하는 것을 추천합니다.\nQ3: 수노 4.5 프롬프트 제네레이터로 만든 음악은 상업적으로 이용할 수 있나요?\nA3: 수노 4.5 프롬프트 제네레이터는 수노 서비스를 활용하여 음악을 만드는 것을 돕는 도구입니다. 생성된 음악의 상업적 이용 가능 여부는 수노(Suno) 서비스의 라이선스 및 이용 약관에 따라 달라지므로, 수노 공식 웹사이트에서 관련 정책을 확인하시는 것이 가장 정확합니다.\n마무리하며: 콘텐츠 제작의 미래, 여러분의 손에!\n이번 포스팅에서는 SNS 맞춤 콘텐츠 제작부터 AI 음악 작곡, 그리고 SEO에 최적화된 블로그 자동 생성까지, 여러분의 콘텐츠 제작을 훨씬 더 스마트하고 효율적으로 만들어 줄 3가지 무료 GPTS를 소개해 드렸습니다. 솔직히 저도 이 도구들을 만들면서 '와, 정말 여기까지 왔구나' 하고 감탄했거든요.\n이 GPTS들이 여러분의 창작 활동에 새로운 활력을 불어넣고, 시간과 노력을 절약하는 데 큰 도움이 되기를 진심으로 바랍니다. 콘텐츠 제작의 부담을 덜고, 더 많은 아이디어를 자유롭게 펼쳐나가시길 응원합니다!",
        "guid": "http://muzbox.tistory.com/483647",
        "categories": [
          "AI, 미래기술/AI 챗봇 및 지침 무료 배포",
          "AI 블로그 생성",
          "ai 음악 작곡",
          "GPT-5 활용",
          "seo 최적화 블로그",
          "무료 gpts",
          "수노 AI 프롬프트",
          "쓰레드 마케팅",
          "인스타그램 콘텐츠 제작",
          "콘텐츠 마케팅 도구",
          "콘텐츠 제작 ai"
        ],
        "isoDate": "2025-08-25T10:08:36.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "클로드(Claude)가 내 이메일 습관을 바꾼 방법: 놀랍도록 쉬운 AI 활용법",
        "link": "http://muzbox.tistory.com/483646",
        "pubDate": "Mon, 25 Aug 2025 10:22:21 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483646#entry483646comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #3c4043;\">\n<div style=\"background-color: #e8f4fd; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">매일 쏟아지는 이메일 홍수 속에서 중요한 내용을 놓치진 않으셨나요? 오늘은 AI 비서 클로드(Claude)가 어떻게 제 이메일 습관을 완전히 바꿔 놓았는지, 그리고 이메일 과부하에서 벗어나 더 효율적인 업무 생활을 시작할 수 있게 도와주었는지 솔직한 후기를 들려드릴게요. 생각보다 훨씬 쉽고 강력한 경험에 깜짝 놀라실 거예요!</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  클로드, 이메일을 '읽고' '이해하다'니!</b></h2>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"클로드가 내 이메일 습관을 바꾼 방법.jpeg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/bFbhBx/btsP4r8a5hN/Kh3J9aZ3GsaSAs3XpKk3ok/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bFbhBx/btsP4r8a5hN/Kh3J9aZ3GsaSAs3XpKk3ok/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bFbhBx/btsP4r8a5hN/Kh3J9aZ3GsaSAs3XpKk3ok/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbFbhBx%2FbtsP4r8a5hN%2FKh3J9aZ3GsaSAs3XpKk3ok%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"클로드(Claude)가 내 이메일 습관을 바꾼 방법: 놀랍도록 쉬운 AI 활용법\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"클로드가 내 이메일 습관을 바꾼 방법.jpeg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;솔직히 고백하자면, 저는 제 이메일함을 한동안 거의 포기 상태로 방치하고 있었어요. 중요한 메일과 광고 메일이 뒤섞여 있어 일일이 확인하는 게 너무 번거로웠거든요. 그러다 문득, 클로드(Claude)의 <b>커넥터(Connectors) 기능</b>에 대한 소식을 듣게 되었죠. 과연 이 AI 챗봇이 제 혼돈의 이메일함을 정리해 줄 수 있을까, 반신반의하면서도 한번 시도해 보기로 했어요. 결과는&hellip; 기대 이상이었습니다.<br /><br /></p>\n<p data-ke-size=\"size16\">클로드의 커넥터 기능은 단순히 채팅 인터페이스를 넘어, AI를 다양한 외부 서비스와 연결해주는 생산성 허브로 변모시켰어요. 이메일, 캘린더 앱부터 결제 프로세서, 심지어 디자인 툴까지 수십 가지 서비스와 연결할 수 있더라고요. 물론, 이 멋진 기능은 유료 클로드 플랜(Max, Team, Enterprise, Pro) 사용자에게만 제공됩니다. 무료 티어에서는 대부분의 커넥터에 접근할 수 없다는 점은 참고하셔야 할 것 같아요.</p>\n<h3 data-ke-size=\"size23\">  <b>Gmail 연동, 생각보다 너무 쉬웠어요!</b></h3>\n<p data-ke-size=\"size16\">저는 처음에 API 설정 같은 복잡한 과정을 예상했어요. 그런데 막상 해보니, 웬걸? <b>채 1분도 걸리지 않아 Gmail 연동이 완료</b>되더라고요. 아래 간단한 절차를 따라 했더니 금세 끝났습니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"01.png\" data-origin-width=\"1000\" data-origin-height=\"600\"><span data-url=\"https://blog.kakaocdn.net/dn/OwfYP/btsP4HCW8s3/uj9KEUF2k7NAFDCKOHBET0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/OwfYP/btsP4HCW8s3/uj9KEUF2k7NAFDCKOHBET0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/OwfYP/btsP4HCW8s3/uj9KEUF2k7NAFDCKOHBET0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FOwfYP%2FbtsP4HCW8s3%2Fuj9KEUF2k7NAFDCKOHBET0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1000\" height=\"600\" data-filename=\"01.png\" data-origin-width=\"1000\" data-origin-height=\"600\"/></span></figure>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"02.png\" data-origin-width=\"995\" data-origin-height=\"599\"><span data-url=\"https://blog.kakaocdn.net/dn/mrlIH/btsP2KOe9VX/MKMUUyFt0unOmOCQbVhahK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/mrlIH/btsP2KOe9VX/MKMUUyFt0unOmOCQbVhahK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/mrlIH/btsP2KOe9VX/MKMUUyFt0unOmOCQbVhahK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FmrlIH%2FbtsP2KOe9VX%2FMKMUUyFt0unOmOCQbVhahK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"995\" height=\"599\" data-filename=\"02.png\" data-origin-width=\"995\" data-origin-height=\"599\"/></span></figure>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"03.png\" data-origin-width=\"989\" data-origin-height=\"594\"><span data-url=\"https://blog.kakaocdn.net/dn/c4HfCS/btsP3BpIJZk/E1SOwToKQ3OjAc83rIkzm1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/c4HfCS/btsP3BpIJZk/E1SOwToKQ3OjAc83rIkzm1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/c4HfCS/btsP3BpIJZk/E1SOwToKQ3OjAc83rIkzm1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc4HfCS%2FbtsP3BpIJZk%2FE1SOwToKQ3OjAc83rIkzm1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"989\" height=\"594\" data-filename=\"03.png\" data-origin-width=\"989\" data-origin-height=\"594\"/></span></figure>\n\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>Gmail과 클로드 연결 방법:</b>\n<ol style=\"margin-top: 10px; padding-left: 20px;\" data-ke-list-type=\"decimal\">\n<li style=\"margin-bottom: 5px;\">클로드에 접속해 좌측 하단의 '설정(Settings)'으로 이동합니다.</li>\n<li style=\"margin-bottom: 5px;\">메뉴 옵션에서 '커넥터(Connectors)'를 클릭합니다.</li>\n<li style=\"margin-bottom: 5px;\">아래로 스크롤하여 '커넥터 찾아보기(Browse Connectors)'를 선택합니다.</li>\n<li style=\"margin-bottom: 5px;\">목록에서 'Gmail'을 찾아 '+' 버튼을 클릭합니다.</li>\n<li style=\"margin-bottom: 5px;\">'계속(Continue)'을 클릭하고 클로드에게 Gmail 계정 접근 권한을 부여합니다.</li>\n<li style=\"margin-bottom: 5px;\">Google 인증 시스템의 메시지에 따라 필요한 권한을 승인합니다.</li>\n</ol>\n</div>\n<p data-ke-size=\"size16\">기술적인 부분에서는 <b>OAuth 2.0</b>을 사용해서 인증하더라고요. 클로드는 제 비밀번호를 저장하지 않고, 언제든지 Google 계정 설정을 통해 철회할 수 있는 임시 액세스 토큰을 얻는 방식이었어요. 개인 정보 보호에 신경 썼다는 점에서 안심이 되었습니다.<br /><br /></p>\n<p data-ke-size=\"size16\">정말 놀라웠던 점은 클로드가 단순히 텍스트를 읽는 것을 넘어 이메일의 <b>문맥을 이해하는 능력</b>이었어요. 대화 스레드를 인식하고, 후속 조치 패턴을 파악하며, 홍보성 이메일과 정말 중요한 메시지를 구별해내는 모습은 정말 인상 깊었습니다.</p>\n<p data-ke-size=\"size16\">다른 구글 서비스와의 연동도 유용했습니다. 구글 드라이브에서 문서 변경 사항을 요약해주는 것처럼, 클로드는 이메일과 캘린더 약속을 교차 참조하여 커뮤니케이션의 전체 맥락을 파악해주더군요. 업무용 앱과 연결하니 그 유용성이 더욱 빛을 발했어요. Gmail, Google 캘린더, Asana 사이를 오갈 필요 없이 클로드 인터페이스 하나로 모든 것을 처리할 수 있었죠.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✨ 놀라울 만큼 똑똑한 클로드의 이메일 요약 기능</b></h2>\n<p data-ke-size=\"size16\">클로드를 Gmail에 연결하고 나서, 저는 실제 상황에서 그 요약 기능을 시험해보기로 했어요. 솔직히 다른 AI 도구들이 종종 중요한 세부 사항을 놓치는 일반적인 요약을 제공하는 경우가 많아서 큰 기대를 하지는 않았습니다. 하지만 클로드는 저의 예상을 완전히 뒤엎었습니다.<br /><br /></p>\n<p data-ke-size=\"size16\">클로드의 이메일 요약은 단순한 텍스트 추출을 넘어섭니다. 문맥을 이해하고, 메시지 간의 관계를 파악하며, 정보성 내용과 조치가 필요한 내용을 정확히 구분하더라고요. 이건 정말 '똑똑하다'는 표현이 딱 맞는 것 같아요.<br /><br /></p>\n<p data-ke-size=\"size16\">저는 몇 가지 프롬프트로 클로드를 테스트해보았어요. 예를 들어, 이렇게 물어봤죠. <b>\"이번 주에 제가 답장해야 할 이메일은 뭐가 있을까요?\"</b> 그러자 클로드는 놀랍게도, 당장 조치가 필요한 클라이언트 문의 메일 2개를 정확히 식별해냈습니다. 반면, 제가 원했던 대로 홍보성 콘텐츠나 영수증, 뉴스레터, 자동 보안 알림 등은 완벽하게 걸러냈어요.<br /><br /></p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"963\" data-origin-height=\"582\"><span data-url=\"https://blog.kakaocdn.net/dn/JWzDZ/btsP4nkrWRU/yjrNlSlaPYfuU9k5MVQEwk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/JWzDZ/btsP4nkrWRU/yjrNlSlaPYfuU9k5MVQEwk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/JWzDZ/btsP4nkrWRU/yjrNlSlaPYfuU9k5MVQEwk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FJWzDZ%2FbtsP4nkrWRU%2FyjrNlSlaPYfuU9k5MVQEwk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"963\" height=\"582\" data-origin-width=\"963\" data-origin-height=\"582\"/></span></figure>\n\n<p data-ke-size=\"size16\"><br />조금 더 광범위한 질문도 해봤습니다. <b>\"지난 3일간 받은 이메일 중 주요 안건이 뭔가요?\"</b> 클로드는 다음과 같이 깔끔하게 정리해주더군요.</p>\n<ul style=\"list-style-type: disc; margin-left: 20px; color: #3c4043;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px;\">신규 프로젝트 진행 상황 업데이트</li>\n<li style=\"margin-bottom: 5px;\">주요 협력사와의 미팅 및 계약 관련 내용</li>\n<li style=\"margin-bottom: 5px;\">내부 시스템 개선을 위한 팀원 의견 수렴</li>\n</ul>\n<p data-ke-size=\"size16\">제가 일일이 메시지를 스크롤하며 패턴을 찾으려 애썼던 것보다 훨씬 더 유용했어요. 정말 시간을 엄청나게 절약할 수 있었죠.<br /><br /></p>\n<p data-ke-size=\"size16\">그리고 가장 중요한 테스트는 이거였어요. <b>\"혹시 지난 한 달간 제가 놓쳤을 만한 중요한 이메일이 있을까요?\"</b> 이 질문에 클로드는 제가 미처 확인하지 못했던 한 협업 제안 메일과 중요한 청구서 마감일 알림 메일을 찾아내 플래그를 달아주었어요. 만약 클로드가 아니었다면 큰 문제로 이어질 뻔한 상황이었죠. 단순히 읽는 것을 넘어, 마치 비서처럼 중요한 내용을 짚어주는 기능에 정말 감탄했습니다.<br /><br /></p>\n<p data-ke-size=\"size16\">특히 길고 복잡한 이메일 스레드를 요약해달라고 요청했을 때도 빛을 발했어요. 예를 들어, 프로젝트 지연에 대한 장황한 논의가 담긴 메일 스레드에서 클로드는 핵심 결정 사항과 다음 조치 항목만 정확히 추출해내고, 불필요한 논의는 깔끔하게 무시했습니다. 이게 바로 '해석'이죠, 단순한 정보 나열이 아니라요!</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  그렇지만 알아둬야 할 몇 가지 한계점</b></h2>\n<p data-ke-size=\"size16\">클로드의 이메일 통합 기능은 전반적으로 매우 만족스러웠지만, 완벽하지는 않았습니다. 몇 가지 알아두어야 할 점들이 있어요.</p>\n<div style=\"background-color: #fce8e6; border-left: 4px solid #d93025; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">⚠️ <b>클로드 이메일 통합의 한계:</b>\n<ul style=\"margin-top: 10px; padding-left: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px;\">클로드는 이메일을 <b>읽고 분석만 할 뿐, 직접 보내거나 예약할 수는 없습니다.</b> (아직까지는요!)</li>\n<li style=\"margin-bottom: 5px;\">이메일에 삽입된 <b>이미지는 현재 인식하지 못합니다.</b> 텍스트 기반 정보만 처리 가능해요.</li>\n<li style=\"margin-bottom: 5px;\">가장 눈에 띄는 것은 <b>속도</b>입니다. 간단한 요청은 빠르지만, 상세한 분석이나 방대한 양의 메일을 처리할 때는 조금 느리게 느껴질 수 있어요.</li>\n<li style=\"margin-bottom: 5px;\"><b>개인 정보 보호 문제</b>도 고려해야 합니다. Anthropic은 데이터를 학습에 사용하지 않는다고 명시했지만, 이메일이 AI에 의해 처리된다는 점은 인지하고 있어야겠죠.</li>\n<li style=\"margin-bottom: 5px;\"><b>복잡한 형식의 이메일</b>, 특히 디자인이 복잡한 마케팅 이메일은 문맥을 파악하는 데 어려움을 겪을 수 있습니다.</li>\n<li style=\"margin-bottom: 5px;\"><b>프롬프트 작성 능력</b>이 중요해요. 모호한 요청은 일반적인 결과를 낳고, 구체적인 요청은 훨씬 더 나은 통찰력을 제공합니다.</li>\n</ul>\n</div>\n<p data-ke-size=\"size16\">하지만 제 경험상, 클로드가 이메일 관리에서 절약해주는 시간은 가끔 발생하는 속도 저하나 형식 관련 문제점보다 훨씬 더 가치가 있었습니다. 만약 여러분도 이메일 과부하로 고통받고 있다면, 클로드는 분명 '인박스 제로(Inbox Zero)'를 달성하는 데 큰 도움을 줄 수 있을 거예요. 다만, 여러분의 판단과 검토를 완전히 대체하기보다는 <b>강력한 이메일 비서</b>로 활용하는 것이 가장 현명하다고 생각합니다.</p>\n<style>\n    /* This style block ensures the summary card is responsive on mobile devices. */\n    @media (max-width: 768px) {\n        .single-summary-card {\n            padding: 18px !important;\n        }\n        .single-summary-card .card-header-icon {\n            font-size: 28px !important;\n            margin-right: 10px !important;\n        }\n        .single-summary-card .card-header h3 {\n            font-size: 20px !important;\n        }\n        .single-summary-card .card-content {\n            font-size: 15px !important;\n            line-height: 1.5 !important;\n        }\n        .single-summary-card .card-content .section {\n            margin-bottom: 8px !important;\n        }\n        .single-summary-card .card-footer {\n            font-size: 13px !important;\n            padding-top: 10px !important;\n        }\n    }\n    @media (max-width: 480px) {\n        .single-summary-card {\n            padding: 15px !important;\n        }\n        .single-summary-card .card-header-icon {\n            font-size: 26px !important;\n        }\n        .single-summary-card .card-header h3 {\n            font-size: 18px !important;\n        }\n        .single-summary-card .card-content {\n            font-size: 14px !important;\n            line-height: 1.4 !important;\n        }\n        .single-summary-card .card-content .section {\n            margin-bottom: 6px !important;\n        }\n        .single-summary-card .card-footer {\n            font-size: 12px !important;\n            padding-top: 8px !important;\n        }\n    }\n</style>\n<div class=\"single-summary-card-container\" style=\"font-family: 'Noto Sans KR', sans-serif; display: flex; justify-content: center; align-items: center; padding: 20px 10px; background-color: transparent; margin: 20px 0;\">\n<div class=\"single-summary-card\" style=\"width: 100%; max-width: 700px; background-color: #f8f9fa; border-radius: 12px; box-shadow: 0 6px 18px rgba(0,0,0,0.12); padding: 25px; display: flex; flex-direction: column; overflow: hidden; border: 1px solid #dadce0; box-sizing: border-box; height: auto;\">\n<div class=\"card-header\" style=\"display: flex; align-items: center; border-bottom: 2px solid #1a73e8; padding-bottom: 12px; margin-bottom: 12px;\"><span style=\"font-size: 34px; color: #1a73e8; margin-right: 14px;\" class=\"card-header-icon\"> </span>\n<h3 style=\"font-size: 26px; color: #1a73e8; margin: 0; line-height: 1.3; font-weight: bold;\" data-ke-size=\"size23\">핵심 요약</h3>\n</div>\n<div class=\"card-content\" style=\"flex-grow: 1; display: flex; flex-direction: column; justify-content: space-around; font-size: 17px; line-height: 1.65; color: #3c4043;\">\n<div class=\"section\" style=\"margin-bottom: 10px;\"><b>✨ 첫 번째 핵심:</b> <b>클로드 커넥터로 Gmail을 손쉽게 연결, 단 1분 만에 AI 이메일 비서 설정 완료!</b></div>\n<div class=\"section\" style=\"margin-bottom: 10px;\"><b>  두 번째 핵심:</b> <b>클로드는 이메일의 문맥을 이해하고, 중요한 내용과 불필요한 광고를 정확히 구분하여 요약합니다.</b></div>\n<div class=\"section\" style=\"margin-bottom: 10px;\"><b>  세 번째 핵심:</b> <b>\"놓쳤을 중요한 메일\"을 찾아주어 업무 효율을 극대화하고, 위기 상황을 사전에 방지합니다.</b></div>\n<div class=\"section\" style=\"margin-bottom: 10px;\"><b> &zwj;  네 번째 핵심:</b> <b>일부 한계점(송신 불가, 이미지 미인식 등)이 있지만, 이메일 과부하 해결에 탁월한 보조 도구입니다.</b></div>\n</div>\n<div class=\"card-footer\" style=\"font-size: 14px; color: #5f6368; text-align: center; padding-top: 12px; border-top: 1px dashed #dadce0; margin-top: auto;\">클로드 유료 플랜 사용자라면 지금 바로 이메일 지옥에서 탈출할 기회! 여러분의 생산성을 한 단계 업그레이드해보세요.</div>\n</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-top: 20px; margin-bottom: 10px;\" data-ke-size=\"size23\"><b>Q1: 클로드의 이메일 요약 기능은 무료로 사용할 수 있나요?</b></h3>\n<p style=\"margin-bottom: 15px; color: #3c4043;\" data-ke-size=\"size16\"><b>A1:</b> 아쉽게도 클로드의 커넥터 기능은 유료 플랜(Max, Team, Enterprise, Pro)에서만 제공됩니다. 이메일 연동 및 요약 기능을 사용하시려면 유료 구독이 필요합니다.</p>\n</div>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-top: 20px; margin-bottom: 10px;\" data-ke-size=\"size23\"><b>Q2: 클로드가 제 이메일 내용을 학습에 사용하나요?</b></h3>\n<p style=\"margin-bottom: 15px; color: #3c4043;\" data-ke-size=\"size16\"><b>A2:</b> Anthropic은 클로드가 커넥터를 통해 처리하는 사용자 데이터를 모델 학습에 사용하지 않는다고 밝히고 있습니다. 개인 정보 보호 정책을 준수하며, 사용자는 언제든지 Gmail 접근 권한을 철회할 수 있습니다.</p>\n</div>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-top: 20px; margin-bottom: 10px;\" data-ke-size=\"size23\"><b>Q3: 클로드가 이메일에서 놓치는 정보는 없나요?</b></h3>\n<p style=\"margin-bottom: 15px; color: #3c4043;\" data-ke-size=\"size16\"><b>A3:</b> 클로드는 이메일의 문맥을 깊이 이해하고 중요한 내용을 잘 요약하지만, 몇 가지 한계점이 있습니다. 예를 들어, 이메일에 삽입된 이미지는 현재 인식하지 못하며, 매우 복잡한 형식의 마케팅 이메일은 문맥 파악에 어려움을 겪을 수 있습니다. 또한, 사용자 판단을 완전히 대체하기보다는 보조 도구로 활용하는 것이 좋습니다.</p>\n</div>\n<script type=\"application/ld+json\">\n  {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n      {\n        \"@type\": \"Question\",\n        \"name\": \"클로드의 이메일 요약 기능은 무료로 사용할 수 있나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"아쉽게도 클로드의 커넥터 기능은 유료 플랜(Max, Team, Enterprise, Pro)에서만 제공됩니다. 이메일 연동 및 요약 기능을 사용하시려면 유료 구독이 필요합니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"클로드가 제 이메일 내용을 학습에 사용하나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"Anthropic은 클로드가 커넥터를 통해 처리하는 사용자 데이터를 모델 학습에 사용하지 않는다고 밝히고 있습니다. 개인 정보 보호 정책을 준수하며, 사용자는 언제든지 Gmail 접근 권한을 철회할 수 있습니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"클로드가 이메일에서 놓치는 정보는 없나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"클로드는 이메일의 문맥을 깊이 이해하고 중요한 내용을 잘 요약하지만, 몇 가지 한계점이 있습니다. 예를 들어, 이메일에 삽입된 이미지는 현재 인식하지 못하며, 매우 복잡한 형식의 마케팅 이메일은 문맥 파악에 어려움을 겪을 수 있습니다. 또한, 사용자 판단을 완전히 대체하기보다는 보조 도구로 활용하는 것이 좋습니다.\"\n        }\n      }\n    ]\n  }\n  </script>\n<p data-ke-size=\"size16\">이메일 과부하로 지쳐있던 저에게 클로드의 이메일 통합 기능은 정말이지 한 줄기 빛과 같았어요. 이메일 관리에 들이던 시간을 절약하고, 더 중요한 일에 집중할 수 있게 된 거죠. 여러분도 이메일 스트레스에서 벗어나 생산성을 높이고 싶다면, 클로드를 활용한 스마트한 이메일 관리에 도전해보시는 건 어떨까요? 분명 후회하지 않으실 거예요!</p>\n</div>",
        "contentSnippet": "매일 쏟아지는 이메일 홍수 속에서 중요한 내용을 놓치진 않으셨나요? 오늘은 AI 비서 클로드(Claude)가 어떻게 제 이메일 습관을 완전히 바꿔 놓았는지, 그리고 이메일 과부하에서 벗어나 더 효율적인 업무 생활을 시작할 수 있게 도와주었는지 솔직한 후기를 들려드릴게요. 생각보다 훨씬 쉽고 강력한 경험에 깜짝 놀라실 거예요!\n  클로드, 이메일을 '읽고' '이해하다'니!\n\n\n \n 솔직히 고백하자면, 저는 제 이메일함을 한동안 거의 포기 상태로 방치하고 있었어요. 중요한 메일과 광고 메일이 뒤섞여 있어 일일이 확인하는 게 너무 번거로웠거든요. 그러다 문득, 클로드(Claude)의 커넥터(Connectors) 기능에 대한 소식을 듣게 되었죠. 과연 이 AI 챗봇이 제 혼돈의 이메일함을 정리해 줄 수 있을까, 반신반의하면서도 한번 시도해 보기로 했어요. 결과는… 기대 이상이었습니다.\n\n클로드의 커넥터 기능은 단순히 채팅 인터페이스를 넘어, AI를 다양한 외부 서비스와 연결해주는 생산성 허브로 변모시켰어요. 이메일, 캘린더 앱부터 결제 프로세서, 심지어 디자인 툴까지 수십 가지 서비스와 연결할 수 있더라고요. 물론, 이 멋진 기능은 유료 클로드 플랜(Max, Team, Enterprise, Pro) 사용자에게만 제공됩니다. 무료 티어에서는 대부분의 커넥터에 접근할 수 없다는 점은 참고하셔야 할 것 같아요.\n  Gmail 연동, 생각보다 너무 쉬웠어요!\n저는 처음에 API 설정 같은 복잡한 과정을 예상했어요. 그런데 막상 해보니, 웬걸? 채 1분도 걸리지 않아 Gmail 연동이 완료되더라고요. 아래 간단한 절차를 따라 했더니 금세 끝났습니다.\n\n\n\n\n  Gmail과 클로드 연결 방법:\n\n클로드에 접속해 좌측 하단의 '설정(Settings)'으로 이동합니다.\n메뉴 옵션에서 '커넥터(Connectors)'를 클릭합니다.\n아래로 스크롤하여 '커넥터 찾아보기(Browse Connectors)'를 선택합니다.\n목록에서 'Gmail'을 찾아 '+' 버튼을 클릭합니다.\n'계속(Continue)'을 클릭하고 클로드에게 Gmail 계정 접근 권한을 부여합니다.\nGoogle 인증 시스템의 메시지에 따라 필요한 권한을 승인합니다.\n기술적인 부분에서는 OAuth 2.0을 사용해서 인증하더라고요. 클로드는 제 비밀번호를 저장하지 않고, 언제든지 Google 계정 설정을 통해 철회할 수 있는 임시 액세스 토큰을 얻는 방식이었어요. 개인 정보 보호에 신경 썼다는 점에서 안심이 되었습니다.\n\n정말 놀라웠던 점은 클로드가 단순히 텍스트를 읽는 것을 넘어 이메일의 문맥을 이해하는 능력이었어요. 대화 스레드를 인식하고, 후속 조치 패턴을 파악하며, 홍보성 이메일과 정말 중요한 메시지를 구별해내는 모습은 정말 인상 깊었습니다.\n다른 구글 서비스와의 연동도 유용했습니다. 구글 드라이브에서 문서 변경 사항을 요약해주는 것처럼, 클로드는 이메일과 캘린더 약속을 교차 참조하여 커뮤니케이션의 전체 맥락을 파악해주더군요. 업무용 앱과 연결하니 그 유용성이 더욱 빛을 발했어요. Gmail, Google 캘린더, Asana 사이를 오갈 필요 없이 클로드 인터페이스 하나로 모든 것을 처리할 수 있었죠.\n✨ 놀라울 만큼 똑똑한 클로드의 이메일 요약 기능\n클로드를 Gmail에 연결하고 나서, 저는 실제 상황에서 그 요약 기능을 시험해보기로 했어요. 솔직히 다른 AI 도구들이 종종 중요한 세부 사항을 놓치는 일반적인 요약을 제공하는 경우가 많아서 큰 기대를 하지는 않았습니다. 하지만 클로드는 저의 예상을 완전히 뒤엎었습니다.\n\n클로드의 이메일 요약은 단순한 텍스트 추출을 넘어섭니다. 문맥을 이해하고, 메시지 간의 관계를 파악하며, 정보성 내용과 조치가 필요한 내용을 정확히 구분하더라고요. 이건 정말 '똑똑하다'는 표현이 딱 맞는 것 같아요.\n\n저는 몇 가지 프롬프트로 클로드를 테스트해보았어요. 예를 들어, 이렇게 물어봤죠. \"이번 주에 제가 답장해야 할 이메일은 뭐가 있을까요?\" 그러자 클로드는 놀랍게도, 당장 조치가 필요한 클라이언트 문의 메일 2개를 정확히 식별해냈습니다. 반면, 제가 원했던 대로 홍보성 콘텐츠나 영수증, 뉴스레터, 자동 보안 알림 등은 완벽하게 걸러냈어요.\n\n\n\n\n조금 더 광범위한 질문도 해봤습니다. \"지난 3일간 받은 이메일 중 주요 안건이 뭔가요?\" 클로드는 다음과 같이 깔끔하게 정리해주더군요.\n신규 프로젝트 진행 상황 업데이트\n주요 협력사와의 미팅 및 계약 관련 내용\n내부 시스템 개선을 위한 팀원 의견 수렴\n제가 일일이 메시지를 스크롤하며 패턴을 찾으려 애썼던 것보다 훨씬 더 유용했어요. 정말 시간을 엄청나게 절약할 수 있었죠.\n\n그리고 가장 중요한 테스트는 이거였어요. \"혹시 지난 한 달간 제가 놓쳤을 만한 중요한 이메일이 있을까요?\" 이 질문에 클로드는 제가 미처 확인하지 못했던 한 협업 제안 메일과 중요한 청구서 마감일 알림 메일을 찾아내 플래그를 달아주었어요. 만약 클로드가 아니었다면 큰 문제로 이어질 뻔한 상황이었죠. 단순히 읽는 것을 넘어, 마치 비서처럼 중요한 내용을 짚어주는 기능에 정말 감탄했습니다.\n\n특히 길고 복잡한 이메일 스레드를 요약해달라고 요청했을 때도 빛을 발했어요. 예를 들어, 프로젝트 지연에 대한 장황한 논의가 담긴 메일 스레드에서 클로드는 핵심 결정 사항과 다음 조치 항목만 정확히 추출해내고, 불필요한 논의는 깔끔하게 무시했습니다. 이게 바로 '해석'이죠, 단순한 정보 나열이 아니라요!\n  그렇지만 알아둬야 할 몇 가지 한계점\n클로드의 이메일 통합 기능은 전반적으로 매우 만족스러웠지만, 완벽하지는 않았습니다. 몇 가지 알아두어야 할 점들이 있어요.\n⚠️ 클로드 이메일 통합의 한계:\n\n클로드는 이메일을 읽고 분석만 할 뿐, 직접 보내거나 예약할 수는 없습니다. (아직까지는요!)\n이메일에 삽입된 이미지는 현재 인식하지 못합니다. 텍스트 기반 정보만 처리 가능해요.\n가장 눈에 띄는 것은 속도입니다. 간단한 요청은 빠르지만, 상세한 분석이나 방대한 양의 메일을 처리할 때는 조금 느리게 느껴질 수 있어요.\n개인 정보 보호 문제도 고려해야 합니다. Anthropic은 데이터를 학습에 사용하지 않는다고 명시했지만, 이메일이 AI에 의해 처리된다는 점은 인지하고 있어야겠죠.\n복잡한 형식의 이메일, 특히 디자인이 복잡한 마케팅 이메일은 문맥을 파악하는 데 어려움을 겪을 수 있습니다.\n프롬프트 작성 능력이 중요해요. 모호한 요청은 일반적인 결과를 낳고, 구체적인 요청은 훨씬 더 나은 통찰력을 제공합니다.\n하지만 제 경험상, 클로드가 이메일 관리에서 절약해주는 시간은 가끔 발생하는 속도 저하나 형식 관련 문제점보다 훨씬 더 가치가 있었습니다. 만약 여러분도 이메일 과부하로 고통받고 있다면, 클로드는 분명 '인박스 제로(Inbox Zero)'를 달성하는 데 큰 도움을 줄 수 있을 거예요. 다만, 여러분의 판단과 검토를 완전히 대체하기보다는 강력한 이메일 비서로 활용하는 것이 가장 현명하다고 생각합니다.\n \n핵심 요약\n✨ 첫 번째 핵심: 클로드 커넥터로 Gmail을 손쉽게 연결, 단 1분 만에 AI 이메일 비서 설정 완료!\n  두 번째 핵심: 클로드는 이메일의 문맥을 이해하고, 중요한 내용과 불필요한 광고를 정확히 구분하여 요약합니다.\n  세 번째 핵심: \"놓쳤을 중요한 메일\"을 찾아주어 업무 효율을 극대화하고, 위기 상황을 사전에 방지합니다.\n ‍  네 번째 핵심: 일부 한계점(송신 불가, 이미지 미인식 등)이 있지만, 이메일 과부하 해결에 탁월한 보조 도구입니다.\n클로드 유료 플랜 사용자라면 지금 바로 이메일 지옥에서 탈출할 기회! 여러분의 생산성을 한 단계 업그레이드해보세요.\n❓ 자주 묻는 질문 (FAQ)\nQ1: 클로드의 이메일 요약 기능은 무료로 사용할 수 있나요?\nA1: 아쉽게도 클로드의 커넥터 기능은 유료 플랜(Max, Team, Enterprise, Pro)에서만 제공됩니다. 이메일 연동 및 요약 기능을 사용하시려면 유료 구독이 필요합니다.\nQ2: 클로드가 제 이메일 내용을 학습에 사용하나요?\nA2: Anthropic은 클로드가 커넥터를 통해 처리하는 사용자 데이터를 모델 학습에 사용하지 않는다고 밝히고 있습니다. 개인 정보 보호 정책을 준수하며, 사용자는 언제든지 Gmail 접근 권한을 철회할 수 있습니다.\nQ3: 클로드가 이메일에서 놓치는 정보는 없나요?\nA3: 클로드는 이메일의 문맥을 깊이 이해하고 중요한 내용을 잘 요약하지만, 몇 가지 한계점이 있습니다. 예를 들어, 이메일에 삽입된 이미지는 현재 인식하지 못하며, 매우 복잡한 형식의 마케팅 이메일은 문맥 파악에 어려움을 겪을 수 있습니다. 또한, 사용자 판단을 완전히 대체하기보다는 보조 도구로 활용하는 것이 좋습니다.\n이메일 과부하로 지쳐있던 저에게 클로드의 이메일 통합 기능은 정말이지 한 줄기 빛과 같았어요. 이메일 관리에 들이던 시간을 절약하고, 더 중요한 일에 집중할 수 있게 된 거죠. 여러분도 이메일 스트레스에서 벗어나 생산성을 높이고 싶다면, 클로드를 활용한 스마트한 이메일 관리에 도전해보시는 건 어떨까요? 분명 후회하지 않으실 거예요!",
        "guid": "http://muzbox.tistory.com/483646",
        "categories": [
          "AI, 미래기술/AI 인사이트",
          "ai 생산성 도구",
          "AI 이메일 관리",
          "anthropic claude",
          "스마트 이메일 비서",
          "이메일 과부하 해결",
          "이메일 자동 분류",
          "지메일 AI 통합",
          "클로드 사용 후기",
          "클로드 이메일 요약",
          "클로드 커넥터"
        ],
        "isoDate": "2025-08-25T01:22:21.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "｜RULIWEB｜",
        "title": "배고픈 드래곤 소녀 육성기, 드래플린",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2351",
        "pubDate": "Wed, 27 Aug 2025 21:43:12 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/25/08/27/198eb8c667451ad6b.jpg\">",
        "contentSnippet": "",
        "categories": [
          "게임툰"
        ],
        "isoDate": "2025-08-27T12:43:12.000Z"
      },
      {
        "creator": "｜RULIWEB｜",
        "title": "악역영애 4컷 만화 - 16화, 보답인데스와",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2350",
        "pubDate": "Wed, 27 Aug 2025 21:26:17 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i1.ruliweb.com/thumb/25/08/27/198eb7dd0a951ad6b.jpg\">",
        "contentSnippet": "",
        "categories": [
          "웹툰"
        ],
        "isoDate": "2025-08-27T12:26:17.000Z"
      },
      {
        "creator": "샤말란의눈",
        "title": "[MULTI] 게임스컴 2025, 공식 방송 및 관련 기사 종합",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2349",
        "pubDate": "Mon, 25 Aug 2025 08:19:51 +0900",
        "author": "샤말란의눈",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/25/07/09/197ef69a13b13b2a1.png\">",
        "contentSnippet": "",
        "categories": [
          "특집"
        ],
        "isoDate": "2025-08-24T23:19:51.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": [
      {
        "title": "내가 가본 우리나라 앱 개발 뒷 이야기",
        "link": "https://jeho.page/essay/2025/08/27/my-korea-map.html",
        "pubDate": "2025-08-26T15:59:00.000Z",
        "author": "김재호",
        "content": "<p>며칠 전 공개했던 <a href=\"/essay/2025/08/01/my-korea-map.html\">내가 가본 우리나라</a> 웹사이트를 앱으로도 만들어봤습니다.<br />\n<a href=\"https://play.google.com/store/apps/details?id=com.my.koreamap&amp;hl=ko\">안드로이드</a>, <a href=\"https://apps.apple.com/kr/app/id6749817480\">아이폰</a> 그리고 맥 앱까지. (맥은 아직 심사 중이에요)</p>\n\n<p>간단한 아이디어였고 제가 쓰고 싶은 마음에 만들기도 했지만,<br />\n레일즈 8을 좀 더 알아보고자 하는 마음.<br />\n제 기술 스택을 정돈해 보고 싶은 마음이 있었어요.</p>\n\n<p>루비 온 레일즈, Vue.js, React<br />\nSwiftUI, 플러터, React Native, Universal Windows Platform</p>\n\n<p>계속 이렇게 공부만 하면서 왔다 갔다 해야 하나?<br />\n좀 잘 정리해서 내 주력 스택을 확정시킬 순 없을까?</p>\n\n<p>루비 온 레일즈 8의 기본 기능을 최대한 활용해 보고 싶었습니다.</p>\n<ul>\n  <li>Hotwire, Stimulus, Turbo, importmap을 통한 외부 종속성 없는 자바스크립트 환경.</li>\n  <li>Kamal 을 통한 배포.</li>\n  <li>Solid Queue를 통한 백그라운드 작업.</li>\n  <li>Solid Cache 캐싱.</li>\n  <li>sqlite와 홈서버로 프로덕션 환경 운영해 보기.</li>\n  <li><del>Hotwire Native를 통한 모바일 앱 개발까지.</del></li>\n</ul>\n\n<p>웹사이트를 다 만들고 나서 아주 홀가분했습니다. Hotwire에 대해 거의 아는 게 없었지만 AI 덕분에 수월했어요.<br />\nReact 같은 걸 쓸 필요가 있나? 하는 생각을 많이 했습니다. Webpack이나 Vite 같은 피곤한 도구들 안 봐도 되는 것도 정말 좋았고요.</p>\n\n<p>모바일 앱을 만들기 위해 <a href=\"https://native.hotwired.dev/\">Hotwire Native</a>와 이틀 정도 씨름하다가…<br />\n이건 도저히 안 되겠다. 더러워서 못 해먹겠다 하고 포기했습니다.</p>\n\n<p>결국 플러터를 선택해서 안드로이드, 아이폰, 맥 앱을 만들었습니다.<br />\n총 코드는 90% 정도가 레일즈이고 10% 정도가 플러터.</p>\n\n<p>클로드 코드로만 작업했고, 제가 직접 코드에 관여한 부분은 없었던 것 같아요.<br />\n클로드 코드를 사용할 때는 <a href=\"/essay/2025/07/23/context-swiching.html\">여러 작업을 병렬로 안 하고 최대한 순차적으로</a> 진행하려고 노력했습니다.<br />\n다른 프로젝트도 신경 쓰지 않고요. 안 그러면 제 머리가 따라갈 수 없어서.  <br />\n여담이지만 저는 클로드 코드에 mcp도 하나도 연결하지 않았고, 남들이 만든 agents.md 같은 것들도 잘 보지 않습니다. 노땅이 다 된 것 같아요.</p>\n\n<p>규모가 작은 앱이긴 하지만, 이번 작업으로 이 스택에 자신감이 생겼습니다.<br />\n앞으로도 새로운 서비스 만들 땐 이렇게 만들지 않을까 싶습니다. 😁\n<br />\n<br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2023/01/04/dont-say-ruby-is-slow.html\">루비가 느리다고?</a></li>\n  <li><a href=\"/essay/2024/04/29/home-server.html\">집에서 서버를 운영하는 게 가능한가요?</a></li>\n  <li><a href=\"/essay/2025/08/11/solo-developer.html\">진짜 1인 개발자 전성시대</a></li>\n</ul>",
        "contentSnippet": "며칠 전 공개했던 내가 가본 우리나라 웹사이트를 앱으로도 만들어봤습니다.\n안드로이드, 아이폰 그리고 맥 앱까지. (맥은 아직 심사 중이에요)\n간단한 아이디어였고 제가 쓰고 싶은 마음에 만들기도 했지만,\n루비 온 레일즈, Vue.js, React\n계속 이렇게 공부만 하면서 왔다 갔다 해야 하나?\n루비 온 레일즈 8의 기본 기능을 최대한 활용해 보고 싶었습니다.\nHotwire, Stimulus, Turbo, importmap을 통한 외부 종속성 없는 자바스크립트 환경.\nKamal 을 통한 배포.\nSolid Queue를 통한 백그라운드 작업.\nSolid Cache 캐싱.\nsqlite와 홈서버로 프로덕션 환경 운영해 보기.\nHotwire Native를 통한 모바일 앱 개발까지.\n웹사이트를 다 만들고 나서 아주 홀가분했습니다. Hotwire에 대해 거의 아는 게 없었지만 AI 덕분에 수월했어요.\n모바일 앱을 만들기 위해 Hotwire Native와 이틀 정도 씨름하다가…\n결국 플러터를 선택해서 안드로이드, 아이폰, 맥 앱을 만들었습니다.\n클로드 코드로만 작업했고, 제가 직접 코드에 관여한 부분은 없었던 것 같아요.\n여러 작업을 병렬로 안 하고 최대한 순차적으로 진행하려고 노력했습니다.\n규모가 작은 앱이긴 하지만, 이번 작업으로 이 스택에 자신감이 생겼습니다.\n함께 읽으면 좋은 글:\n루비가 느리다고?\n집에서 서버를 운영하는 게 가능한가요?\n진짜 1인 개발자 전성시대",
        "summary": "며칠 전 공개했던 내가 가본 우리나라 웹사이트를 앱으로도 만들어봤습니다. 안드로이드, 아이폰 그리고 맥 앱까지. (맥은 아직 심사 중이에요)",
        "id": "https://jeho.page/essay/2025/08/27/my-korea-map",
        "isoDate": "2025-08-26T15:59:00.000Z"
      }
    ]
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "유니티 옷감 머리 가슴 구현 / 매지카 클로우즈 애셋 / Magica Cloth",
        "link": "http://serverdown.tistory.com/1383",
        "pubDate": "Tue, 26 Aug 2025 20:59:15 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1383#entry1383comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"802\" data-origin-height=\"494\"><span data-url=\"https://blog.kakaocdn.net/dn/mbf6T/btsP564JOjY/aMF2BwYv7sdwPF6Fb21HJ0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/mbf6T/btsP564JOjY/aMF2BwYv7sdwPF6Fb21HJ0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/mbf6T/btsP564JOjY/aMF2BwYv7sdwPF6Fb21HJ0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fmbf6T%2FbtsP564JOjY%2FaMF2BwYv7sdwPF6Fb21HJ0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"802\" height=\"494\" data-origin-width=\"802\" data-origin-height=\"494\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">장점은 리깅 없이 구현할 수 있다는 것입니다.</p>\n<p data-ke-size=\"size16\">Boing 으로 해봤는데 Boing 은 뼈가 있어야합니다.</p>\n<p data-ke-size=\"size16\">불편하기도하고 옷감 퀄리티도 나지 않습니다.&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=Md-NCpkwt_Y\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=Md-NCpkwt_Y</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=Md-NCpkwt_Y\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bfpeVP/hyZC4IIetR/6d2XMHOPXBeQjeG0ykhO80/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/dzhnL4/hyZCYaGiQK/Nn4EhU6bCquRK1hbTPgxS0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"[유니티] Magica Cloth 2 에셋 소개 및 사용 방법.\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/Md-NCpkwt_Y\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상 참고하시구요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"441\" data-origin-height=\"182\"><span data-url=\"https://blog.kakaocdn.net/dn/dQOmxk/btsP7A4MPCO/K4tKdIAnhkFmsGevUcwU90/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dQOmxk/btsP7A4MPCO/K4tKdIAnhkFmsGevUcwU90/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dQOmxk/btsP7A4MPCO/K4tKdIAnhkFmsGevUcwU90/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdQOmxk%2FbtsP7A4MPCO%2FK4tKdIAnhkFmsGevUcwU90%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"441\" height=\"182\" data-origin-width=\"441\" data-origin-height=\"182\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">저는 할인 할때 사둡니다.</p>\n<p data-ke-size=\"size16\">버튜버에도 쓸 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "장점은 리깅 없이 구현할 수 있다는 것입니다.\nBoing 으로 해봤는데 Boing 은 뼈가 있어야합니다.\n불편하기도하고 옷감 퀄리티도 나지 않습니다. \n \n영상: https://www.youtube.com/watch?v=Md-NCpkwt_Y\n\n\n\n \n영상 참고하시구요\n \n\n\n저는 할인 할때 사둡니다.\n버튜버에도 쓸 수 있습니다.",
        "guid": "http://serverdown.tistory.com/1383",
        "categories": [
          "프로그래밍/유니티 에셋 리뷰",
          "매지카",
          "옷감",
          "유니티"
        ],
        "isoDate": "2025-08-26T11:59:15.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "게임 양산으로 대박이난 인디개발사 / 아울캐미 랩스 Owlchemy Labs",
        "link": "http://serverdown.tistory.com/1382",
        "pubDate": "Mon, 25 Aug 2025 17:41:35 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1382#entry1382comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"960\" data-origin-height=\"384\"><span data-url=\"https://blog.kakaocdn.net/dn/bYZCaK/btsP6LkAvkM/umnUqXKMmXAMNZH4Za3ru0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bYZCaK/btsP6LkAvkM/umnUqXKMmXAMNZH4Za3ru0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bYZCaK/btsP6LkAvkM/umnUqXKMmXAMNZH4Za3ru0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbYZCaK%2FbtsP6LkAvkM%2FumnUqXKMmXAMNZH4Za3ru0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"960\" height=\"384\" data-origin-width=\"960\" data-origin-height=\"384\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=VDFBVXhHYwc\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=VDFBVXhHYwc</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=VDFBVXhHYwc\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/v20Y0/hyZC4ayGT5/Gw4g09daumzv0NUmedjpV0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/hUwiJ/hyZDXojZA9/7hik49W5czNk41uUzkbstk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"앱스토어를 떠도는 쓰레기 게임들의 충격적 정체\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/VDFBVXhHYwc\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">똥게임들에 환멸을 느껴 게임을 자동으로 만들고</p>\n<p data-ke-size=\"size16\">배포하는 프로그램을 만들어 어마어마한 양의 게임을 출시한 이팀은 ...</p>\n<h2 data-ke-size=\"size26\">성공했습니다.</h2>\n<p data-ke-size=\"size16\">그들의 성공스토리를 배워봅시다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=VDFBVXhHYwc\n\n\n\n \n똥게임들에 환멸을 느껴 게임을 자동으로 만들고\n배포하는 프로그램을 만들어 어마어마한 양의 게임을 출시한 이팀은 ...\n성공했습니다.\n그들의 성공스토리를 배워봅시다.",
        "guid": "http://serverdown.tistory.com/1382",
        "categories": [
          "유튜브",
          "인디게임"
        ],
        "isoDate": "2025-08-25T08:41:35.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "카지노에서 왠 파판 브금이 ...",
        "link": "http://serverdown.tistory.com/1381",
        "pubDate": "Mon, 25 Aug 2025 12:33:09 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1381#entry1381comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"491\" data-origin-height=\"344\"><span data-url=\"https://blog.kakaocdn.net/dn/b7adwK/btsP4cJYJMO/z0umpvVbGtCrNTZgZQyvZK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/b7adwK/btsP4cJYJMO/z0umpvVbGtCrNTZgZQyvZK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/b7adwK/btsP4cJYJMO/z0umpvVbGtCrNTZgZQyvZK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb7adwK%2FbtsP4cJYJMO%2Fz0umpvVbGtCrNTZgZQyvZK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"491\" height=\"344\" data-origin-width=\"491\" data-origin-height=\"344\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=J2ZGFyysmLQ\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=J2ZGFyysmLQ</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=J2ZGFyysmLQ\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/ScFYI/hyZDWCTAM0/KBeUBIKLZr0kJfqO4LAvv1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/mBX8d/hyZDb8uL7d/HWkjN0vHFJCSJC4MtYke81/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"종로구보다 작은 도시 마카오에 도박에 죽고 도박에 사는 한국인들 밀착 취재! | KBS 20040528 방송\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/J2ZGFyysmLQ\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">4:44 에 나옵니다.</p>\n<p data-ke-size=\"size16\">파판x 브금 같군요</p>\n<p data-ke-size=\"size16\">세기말 분위기 나는군욥</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=J2ZGFyysmLQ\n\n\n\n4:44 에 나옵니다.\n파판x 브금 같군요\n세기말 분위기 나는군욥",
        "guid": "http://serverdown.tistory.com/1381",
        "categories": [
          "유튜브",
          "카지노"
        ],
        "isoDate": "2025-08-25T03:33:09.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "신기한 컴퓨터 아이오프너 / 피자 키를 누르면 피자가 주문된다. / i-Opener 아이오프너",
        "link": "http://serverdown.tistory.com/1380",
        "pubDate": "Sun, 24 Aug 2025 18:22:40 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1380#entry1380comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1100\" data-origin-height=\"438\"><span data-url=\"https://blog.kakaocdn.net/dn/bq1jRa/btsP5E6ndXI/k54UsKMe3z6LyFZUDcuO00/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bq1jRa/btsP5E6ndXI/k54UsKMe3z6LyFZUDcuO00/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bq1jRa/btsP5E6ndXI/k54UsKMe3z6LyFZUDcuO00/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbq1jRa%2FbtsP5E6ndXI%2Fk54UsKMe3z6LyFZUDcuO00%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1100\" height=\"438\" data-origin-width=\"1100\" data-origin-height=\"438\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">아이오프너는 90년대 후반 나온 컴퓨터 입니다.</p>\n<p data-ke-size=\"size16\">IT 버블 전에 나왔으시 신기한 물건이겠죠</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">키보드에 피자 키가 있다고 합니다. ㄷㄷ</p>\n<p data-ke-size=\"size16\">누르면 피자가 주문된다는군요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=IxpbNF8_bCM\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=IxpbNF8_bCM</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=IxpbNF8_bCM\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/H1AaL/hyZDS8e4PO/ImoJ2HIo78Kl2YBDoG67bk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/bDvSPE/hyZzKjHE7b/JoM9P71ZAq3QdOPPEEKp9k/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"9만 9천원 (99$) 에 팔던 컴퓨터 때문에 벌어진 10만 달러 소송, 아이오프너 사건\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/IxpbNF8_bCM\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 제품은 99 달러에 저렴하게 팔고</p>\n<p data-ke-size=\"size16\">인터넷통신비를 받아서 수익을 내려고 했습니다.</p>\n<p data-ke-size=\"size16\">전용 인터넷을 써야 동작하도록 만들긴했지만 ... 양덕들이 그만</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">하지만 제품을 뜯어본 사람들이 개조해서 일반 컴퓨터 처럼 쓰기 시작함에 따라</p>\n<p data-ke-size=\"size16\">손해가 나버린 비운의 컴퓨터 입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">전용 인터넷을 사용해주지않으면 당연히 사업이 정상적으로 운영될 수 없었기 때문에</p>\n<p data-ke-size=\"size16\">망해서 사라져 버렸습니다.</p>\n<p data-ke-size=\"size16\">안타깝군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">아이오프너 실기 영상: <a href=\"https://www.youtube.com/watch?v=gvlCM9bnhMo\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=gvlCM9bnhMo</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=gvlCM9bnhMo\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/brOZD9/hyZC3h7TVZ/3yIXef2HebKcqZBe2yU6V1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/JNboA/hyZDStEc1g/QZ5b8fnBJJDcn8qrVzZd2k/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"i-Opener - The $99 Computer That Cost a Company Millions\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/gvlCM9bnhMo\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "아이오프너는 90년대 후반 나온 컴퓨터 입니다.\nIT 버블 전에 나왔으시 신기한 물건이겠죠\n \n키보드에 피자 키가 있다고 합니다. ㄷㄷ\n누르면 피자가 주문된다는군요.\n \n영상: https://www.youtube.com/watch?v=IxpbNF8_bCM\n\n\n\n \n이 제품은 99 달러에 저렴하게 팔고\n인터넷통신비를 받아서 수익을 내려고 했습니다.\n전용 인터넷을 써야 동작하도록 만들긴했지만 ... 양덕들이 그만\n \n하지만 제품을 뜯어본 사람들이 개조해서 일반 컴퓨터 처럼 쓰기 시작함에 따라\n손해가 나버린 비운의 컴퓨터 입니다.\n \n전용 인터넷을 사용해주지않으면 당연히 사업이 정상적으로 운영될 수 없었기 때문에\n망해서 사라져 버렸습니다.\n안타깝군요\n \n \n \n \n아이오프너 실기 영상: https://www.youtube.com/watch?v=gvlCM9bnhMo",
        "guid": "http://serverdown.tistory.com/1380",
        "categories": [
          "유튜브"
        ],
        "isoDate": "2025-08-24T09:22:40.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "무한 애너지 획득을 위한 탄계",
        "link": "http://serverdown.tistory.com/1379",
        "pubDate": "Sun, 24 Aug 2025 00:22:04 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1379#entry1379comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"468\" data-origin-height=\"335\"><span data-url=\"https://blog.kakaocdn.net/dn/cgFc6t/btsP4iJVvsN/A1EXNPnUKPKFksHrtIaTyk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cgFc6t/btsP4iJVvsN/A1EXNPnUKPKFksHrtIaTyk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cgFc6t/btsP4iJVvsN/A1EXNPnUKPKFksHrtIaTyk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcgFc6t%2FbtsP4iJVvsN%2FA1EXNPnUKPKFksHrtIaTyk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"468\" height=\"335\" data-origin-width=\"468\" data-origin-height=\"335\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=daRSa6YZKyg\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=daRSa6YZKyg</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=daRSa6YZKyg\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bgGtxW/hyZC9CtZ0w/DWfjeph8lzafXzzdWPMGx1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/eGcOme/hyZzxq5FYb/l1tBVisEd9HWBdKzYhHo50/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"핵융합 상용화를 앞당길 뿐 아니라 인류가 처한 문제들을 해결해낼 혁신 기술\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/daRSa6YZKyg\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">원자력 발전은 지구에 있는걸 다 캐봐야 만년 정도 갑니다.</p>\n<p data-ke-size=\"size16\">하지막 핵폐기물은 5만년을 기다려야하기 때문에 무한희 쓸 수는 없습니다.</p>\n<p data-ke-size=\"size16\">그래서 영상에서는</p>\n<p data-ke-size=\"size16\">핵발전소를 돌린 전기로 입자가속기를 돌려 지구에서 삼중수소를 만드는 방법을 소개하고 있습니다.</p>\n<p data-ke-size=\"size16\">핵육합 발전은 아직 상용회되진 않았지만 이것까지 된다면</p>\n<p data-ke-size=\"size16\">핵발전소로 삼중수소를 만들고&nbsp;</p>\n<p data-ke-size=\"size16\">삼중수소로 핵융합발전을 하고</p>\n<p data-ke-size=\"size16\">전기로 공기중에 이산화 탄소로 석유까지 만들고 나면 무한 루프가 완성됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">거기다 무중성자 핵융합까지가면 그냥 바다물로 핵융합이 되기 때문에 위의 절차를 다 뛰어 넘을 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상에서 논란점은 에너지만 무한하다면 공기중의 이산화탄소를 석유로 돌릴 수 있다는거 ...</p>\n<p data-ke-size=\"size16\">와 쩐다..</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=daRSa6YZKyg\n\n\n\n \n원자력 발전은 지구에 있는걸 다 캐봐야 만년 정도 갑니다.\n하지막 핵폐기물은 5만년을 기다려야하기 때문에 무한희 쓸 수는 없습니다.\n그래서 영상에서는\n핵발전소를 돌린 전기로 입자가속기를 돌려 지구에서 삼중수소를 만드는 방법을 소개하고 있습니다.\n핵육합 발전은 아직 상용회되진 않았지만 이것까지 된다면\n핵발전소로 삼중수소를 만들고 \n삼중수소로 핵융합발전을 하고\n전기로 공기중에 이산화 탄소로 석유까지 만들고 나면 무한 루프가 완성됩니다.\n \n거기다 무중성자 핵융합까지가면 그냥 바다물로 핵융합이 되기 때문에 위의 절차를 다 뛰어 넘을 수 있습니다.\n \n영상에서 논란점은 에너지만 무한하다면 공기중의 이산화탄소를 석유로 돌릴 수 있다는거 ...\n와 쩐다..",
        "guid": "http://serverdown.tistory.com/1379",
        "categories": [
          "유튜브",
          "핵융합"
        ],
        "isoDate": "2025-08-23T15:22:04.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "망하는 도시에 모여든다. / 탕핑족의 밝은 미래 / 은퇴사연",
        "link": "http://serverdown.tistory.com/1378",
        "pubDate": "Sat, 23 Aug 2025 18:09:12 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1378#entry1378comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"610\" data-origin-height=\"338\"><span data-url=\"https://blog.kakaocdn.net/dn/5Kx5n/btsP4bqv2ab/8lyRlfL8vPuKqorvkvMzY0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/5Kx5n/btsP4bqv2ab/8lyRlfL8vPuKqorvkvMzY0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/5Kx5n/btsP4bqv2ab/8lyRlfL8vPuKqorvkvMzY0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F5Kx5n%2FbtsP4bqv2ab%2F8lyRlfL8vPuKqorvkvMzY0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"610\" height=\"338\" data-origin-width=\"610\" data-origin-height=\"338\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=JsMQvfApluk\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=JsMQvfApluk</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=JsMQvfApluk\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/mn8Qw/hyZC4VorQN/1wnCPkN06WwwKZAq9qItuk/img.jpg?width=1280&amp;height=720&amp;face=108_64_196_160,https://scrap.kakaocdn.net/dn/UjfKe/hyZDRuCduf/wLiVKSvRpiX4u5797VYM2k/img.jpg?width=1280&amp;height=720&amp;face=108_64_196_160\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"중국 몰락한 도시에서 일어나고 있는 기괴한 현상! 후이저우!\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/JsMQvfApluk\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">탕핑족이란</h2>\n<p data-ke-size=\"size16\">누워있는 사람이라는 뜻으로 중국 공산당의 영향을 벗어나기위해 아무것도 하지 않는 사람을 의미합니다.</p>\n<p data-ke-size=\"size16\">중국 공산당은 무슨일을하든 온갖명목의 세금과 벌금으로 뜻어가기 때문에 사화활동을 아예 안해버리는 방법을 씁니다.</p>\n<p data-ke-size=\"size16\">만약 활동을 한다해도 최소금액만 사용하고 고 나중을위해 모읍니다.+</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"text-align: start;\">중국의 부동산 몰락</span></h2>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">중국은 코로나이후 최악의 부동산 침체를 겪고 있습니다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">그러다보니 일부지역의 아파트 가격은 -90% 까지도 내려갔다고 합니다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">중국의 망한도시중에 관광지는 새로운 시장이 형성되고 있다고 합니다.</span></p>\n<p data-ke-size=\"size16\">쫄딱 망해서 월세를 포함해 모든 물가가 떡락하다보니 탕핑 족들이 이곳으로 모이고 있다고 합니다.</p>\n<p data-ke-size=\"size16\">월 50만원 이하로 생활한다고 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">부동산 소유자들에게는 나쁜일이겠지만</p>\n<p data-ke-size=\"size16\">물가가 낮아짐에 따라 사람이 모여들고 저렴한 생활이 가능하다고 합니다.</p>\n<p data-ke-size=\"size16\">그러다보니 시장도 돌아가고 도시가 정상적으로 돌아가게 되었다는</p>\n<p data-ke-size=\"size16\">훈훈한 이야기 였습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">어느곳이나 바닥을 치면 좋아지기 마련이거 같습니다..</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=JsMQvfApluk\n\n\n\n \n탕핑족이란\n누워있는 사람이라는 뜻으로 중국 공산당의 영향을 벗어나기위해 아무것도 하지 않는 사람을 의미합니다.\n중국 공산당은 무슨일을하든 온갖명목의 세금과 벌금으로 뜻어가기 때문에 사화활동을 아예 안해버리는 방법을 씁니다.\n만약 활동을 한다해도 최소금액만 사용하고 고 나중을위해 모읍니다.+\n \n중국의 부동산 몰락\n중국은 코로나이후 최악의 부동산 침체를 겪고 있습니다.\n그러다보니 일부지역의 아파트 가격은 -90% 까지도 내려갔다고 합니다.\n중국의 망한도시중에 관광지는 새로운 시장이 형성되고 있다고 합니다.\n쫄딱 망해서 월세를 포함해 모든 물가가 떡락하다보니 탕핑 족들이 이곳으로 모이고 있다고 합니다.\n월 50만원 이하로 생활한다고 합니다.\n \n부동산 소유자들에게는 나쁜일이겠지만\n물가가 낮아짐에 따라 사람이 모여들고 저렴한 생활이 가능하다고 합니다.\n그러다보니 시장도 돌아가고 도시가 정상적으로 돌아가게 되었다는\n훈훈한 이야기 였습니다.\n \n \n어느곳이나 바닥을 치면 좋아지기 마련이거 같습니다..",
        "guid": "http://serverdown.tistory.com/1378",
        "categories": [
          "유튜브",
          "은퇴",
          "중국",
          "탕핑족"
        ],
        "isoDate": "2025-08-23T09:09:12.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "케이팝 문화는 아타리 쇼크 처럼 될 가능성이 있다.",
        "link": "http://serverdown.tistory.com/1377",
        "pubDate": "Fri, 22 Aug 2025 20:43:52 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1377#entry1377comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"200\" data-origin-height=\"250\"><span data-url=\"https://blog.kakaocdn.net/dn/boO3aa/btsP13tuR8U/l8uOKZWF6kYRS2Ubd4qS00/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/boO3aa/btsP13tuR8U/l8uOKZWF6kYRS2Ubd4qS00/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/boO3aa/btsP13tuR8U/l8uOKZWF6kYRS2Ubd4qS00/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FboO3aa%2FbtsP13tuR8U%2Fl8uOKZWF6kYRS2Ubd4qS00%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"200\" height=\"250\" data-origin-width=\"200\" data-origin-height=\"250\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=LyQ5hhm90B4\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=LyQ5hhm90B4</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=LyQ5hhm90B4\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/nHbjK/hyZyfRHiX2/PZBfDUrTjGIgTPRhamEtg0/img.jpg?width=1280&amp;height=720&amp;face=30_184_518_390,https://scrap.kakaocdn.net/dn/cFBrES/hyZDMmrbhE/aks0my1REfgo0muHmK0WZ0/img.jpg?width=1280&amp;height=720&amp;face=30_184_518_390\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"영화에 나오는 한글이 미국에서 난리난 이유 | 케데헌이 만들어낸 미국의 사회 현상 | 해외반응\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/LyQ5hhm90B4\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">내용 중에 아타리쇼크가 나옵니다.</p>\n<p data-ke-size=\"size16\">무슨 이야기냐하면</p>\n<p data-ke-size=\"size16\">돈이되는걸 알게 되면 미디어가 어마어마한 양이 양산이 되는데</p>\n<p data-ke-size=\"size16\">그러면 돈만 먹으려고 떨어지는 퀄리티로 양상이 되며 나중에 버린다는 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">헐리우드에 중국 자본이 들어갈때도 영화에 역활이 엉성한 중국 배우가 나오면서</p>\n<p data-ke-size=\"size16\">퀀리티가 떨어지는 현상이 있었는데 그런식인거 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">꼭 그렇게 된다기 보다는 잘못되기 시작한다면</p>\n<p data-ke-size=\"size16\">이 문제로 잘못될 가능성이 있다고 보시면됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">10년후에나 있을일일 수도 있으니</p>\n<p data-ke-size=\"size16\">주의해야합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=LyQ5hhm90B4\n\n\n\n \n \n내용 중에 아타리쇼크가 나옵니다.\n무슨 이야기냐하면\n돈이되는걸 알게 되면 미디어가 어마어마한 양이 양산이 되는데\n그러면 돈만 먹으려고 떨어지는 퀄리티로 양상이 되며 나중에 버린다는 것입니다.\n \n헐리우드에 중국 자본이 들어갈때도 영화에 역활이 엉성한 중국 배우가 나오면서\n퀀리티가 떨어지는 현상이 있었는데 그런식인거 같습니다.\n \n꼭 그렇게 된다기 보다는 잘못되기 시작한다면\n이 문제로 잘못될 가능성이 있다고 보시면됩니다.\n \n10년후에나 있을일일 수도 있으니\n주의해야합니다.",
        "guid": "http://serverdown.tistory.com/1377",
        "categories": [
          "유튜브"
        ],
        "isoDate": "2025-08-22T11:43:52.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": []
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": [
      {
        "title": "의미에 맞는 href 사용",
        "link": "https://hyeonseok.com/blog/942",
        "pubDate": "Sun, 24 Aug 2025 15:39:59 GMT",
        "content": "<p>링크에 <code>onclick</code> 핸들러를 달 때 <code>href</code>에 <code>#</code>을 많이 사용하는데 특이하게 <code>http://</code>를 사용한 경우를 봤다. 딱히 신경쓰지 않고 있었는데 이로 인한 버그가 리포팅됐다.</p>\r\n\r\n<p><img src=\"/static/blog/semantic-href.png\" class=\"major\" alt=\"페이지 표시 오류가 발생한 사파리 브라우저\" /> 사파리는 링크를 롱탭해서 프리뷰를 볼 수 있는데 <code>http://</code>로 <code>href</code> 값을 정하면 프리뷰에서 오류가 발생한다. 이 외에도 새탭을 연다든가 북마크로 저장을 한다든가 할 때도 오류가 발생할 것이다.</p>\r\n\r\n<p><code>href</code> 값이 필요 없는 경우에는 <code>&lt;button&gt;</code> 요소를 사용하도록 하자. HTML의 의미가 왜 중요한지 말해주는 또 하나의 사례라고 할 수 있겠다.</p>",
        "contentSnippet": "링크에 onclick 핸들러를 달 때 href에 #을 많이 사용하는데 특이하게 http://를 사용한 경우를 봤다. 딱히 신경쓰지 않고 있었는데 이로 인한 버그가 리포팅됐다.\n\r\n\r\n 사파리는 링크를 롱탭해서 프리뷰를 볼 수 있는데 http://로 href 값을 정하면 프리뷰에서 오류가 발생한다. 이 외에도 새탭을 연다든가 북마크로 저장을 한다든가 할 때도 오류가 발생할 것이다.\n\r\n\r\nhref 값이 필요 없는 경우에는 <button> 요소를 사용하도록 하자. HTML의 의미가 왜 중요한지 말해주는 또 하나의 사례라고 할 수 있겠다.",
        "guid": "https://hyeonseok.com/blog/942",
        "isoDate": "2025-08-24T15:39:59.000Z"
      },
      {
        "title": "클라우드 플레어 뒤에 있는 웹서버에서 사용자 IP를 로그로 남기기",
        "link": "https://hyeonseok.com/blog/941",
        "pubDate": "Sat, 23 Aug 2025 22:10:51 GMT",
        "content": "<p>클라우드 플레어 뒤에 있는 웹서버의 로그를 보니 클라우드 플에어 프록시 서버의 IP를 남기고 있다. 클라우드 플레어는 <code>CF-Connecting-IP</code>로 실제 IP를 넘겨주고 있어서 이것을 이용하게 설정할 필요가 있다.</p>\r\n\r\n<p>엔진엑스의 <code>real_ip</code> 모듈을 사용하면 특정 IP 범위의 요청에서 <code>$remote_addr</code>의 값을 변경할 수 있게 해 준다. 클라우드 플레어의 IP 범위는 <a href=\"https://www.cloudflare.com/ips-v4/\">https://www.cloudflare.com/ips-v4/</a> 주소에서 텍스트 형태로 제공하고 있다. 이 것을 엔진엑스에서 <code>set_real_ip_from</code>으로 추가하고 클라우드 플레어가 전달해주는 실제 IP로 덮어 써주면 된다.</p>\r\n\r\n<pre><code>http {\r\n    set_real_ip_from 173.245.48.0/20;\r\n    set_real_ip_from 103.21.244.0/22;\r\n    set_real_ip_from 103.22.200.0/22;\r\n    set_real_ip_from 103.31.4.0/22;\r\n    set_real_ip_from 141.101.64.0/18;\r\n    set_real_ip_from 108.162.192.0/18;\r\n    set_real_ip_from 190.93.240.0/20;\r\n    set_real_ip_from 188.114.96.0/20;\r\n    set_real_ip_from 197.234.240.0/22;\r\n    set_real_ip_from 198.41.128.0/17;\r\n    set_real_ip_from 162.158.0.0/15;\r\n    set_real_ip_from 104.16.0.0/13;\r\n    set_real_ip_from 104.24.0.0/14;\r\n    set_real_ip_from 172.64.0.0/13;\r\n    set_real_ip_from 131.0.72.0/22;\r\n\r\n    real_ip_header CF-Connecting-IP;\r\n    ...\r\n}</code></pre>\r\n\r\n<p>이렇게 하면 로그 템플릿의 <code>$remote_addr</code>이 클라우드 플레어가 전달해주는 IP로 치환되어 저장되게 된다.</p>",
        "contentSnippet": "클라우드 플레어 뒤에 있는 웹서버의 로그를 보니 클라우드 플에어 프록시 서버의 IP를 남기고 있다. 클라우드 플레어는 CF-Connecting-IP로 실제 IP를 넘겨주고 있어서 이것을 이용하게 설정할 필요가 있다.\n\r\n\r\n엔진엑스의 real_ip 모듈을 사용하면 특정 IP 범위의 요청에서 $remote_addr의 값을 변경할 수 있게 해 준다. 클라우드 플레어의 IP 범위는 https://www.cloudflare.com/ips-v4/ 주소에서 텍스트 형태로 제공하고 있다. 이 것을 엔진엑스에서 set_real_ip_from으로 추가하고 클라우드 플레어가 전달해주는 실제 IP로 덮어 써주면 된다.\n\r\n\r\nhttp {\r\n    set_real_ip_from 173.245.48.0/20;\r\n    set_real_ip_from 103.21.244.0/22;\r\n    set_real_ip_from 103.22.200.0/22;\r\n    set_real_ip_from 103.31.4.0/22;\r\n    set_real_ip_from 141.101.64.0/18;\r\n    set_real_ip_from 108.162.192.0/18;\r\n    set_real_ip_from 190.93.240.0/20;\r\n    set_real_ip_from 188.114.96.0/20;\r\n    set_real_ip_from 197.234.240.0/22;\r\n    set_real_ip_from 198.41.128.0/17;\r\n    set_real_ip_from 162.158.0.0/15;\r\n    set_real_ip_from 104.16.0.0/13;\r\n    set_real_ip_from 104.24.0.0/14;\r\n    set_real_ip_from 172.64.0.0/13;\r\n    set_real_ip_from 131.0.72.0/22;\r\n\r\n    real_ip_header CF-Connecting-IP;\r\n    ...\r\n}\n\r\n\r\n이렇게 하면 로그 템플릿의 $remote_addr이 클라우드 플레어가 전달해주는 IP로 치환되어 저장되게 된다.",
        "guid": "https://hyeonseok.com/blog/941",
        "isoDate": "2025-08-23T22:10:51.000Z"
      }
    ]
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "코드 품질 개선 기법 18편: 함수만 보고 관계는 보지 못한다",
        "link": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-18",
        "pubDate": "Wed, 27 Aug 2025 02:00:00 GMT",
        "content": "이 글은 2024년 3월 21일에 일본어로 먼저 발행된 기사를 번역한 글입니다.LY Corporation은 높은 개발 생산성을 유지하기 위해 코드 품질 및 개발 문화 개선에 힘쓰고...",
        "contentSnippet": "이 글은 2024년 3월 21일에 일본어로 먼저 발행된 기사를 번역한 글입니다.LY Corporation은 높은 개발 생산성을 유지하기 위해 코드 품질 및 개발 문화 개선에 힘쓰고...",
        "guid": "https://techblog.lycorp.co.jp/ko/techniques-for-improving-code-quality-18",
        "isoDate": "2025-08-27T02:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "AI의 독",
        "link": "https://www.thestartupbible.com/2025/08/be-careful-what-you-ask-for-with-ai.html",
        "pubDate": "Wed, 27 Aug 2025 21:26:00 +0000",
        "content:encodedSnippet": "전에 내가 AI가 중요한 게 아니라 비즈니스가 더 중요하다는 글을 썼는데, 그 내용의 연장선상의 글이다. 요새 직업상 또는 비직업상 만나는 사람들이, 정도의 차이는 있지만, 모두 다 AI 이야기를 한다. 특히나 창업가들은 AI라는 이 거대한 tech 물결을 어떻게 더 잘 타서 남들보다 더 빨리, 그리고 더 멀리 갈 수 있을지 매일 고민하면서 부서와 업무와는 상관없이 전사적 AI 도입을 외치고 있다.\n실은, 기술의 변화에 민감하게 반응하고, 남들보다 빨리 이런 기술을 도입하는 건 여러 가지 면에서 바람직한 현상이다. 국가적으로도 한국은 AI 도입에 꽤 잘 대응하고 있다고 생각한다. 하지만, 모든 현상에는 양면이 있는데 AI에도 어두운 면이 있고, 최근에 만난 많은 창업가들이 AI의 독에 물렸다는 생각을 떨칠 수가 없다.\n많은 창업가들이 AI가 모든 것을 해결해 줄 것으로 생각한다. 이런 분들을 만나 보면 사람도 채용할 필요가 없고, 코딩도 배울 필요가 없고, 콘텐츠도 깊게 고민해서 만들 필요가 없고, 고객이나 협력업체에 보낼 이메일도 고민할 필요가 없다고 한다. 모든 걸 AI로 완벽하게 해결할 수 있다고 하는데, 나는 이와는 반대로 생각한다. 업무의 모든 면에서 우리가 기계의 도움을 받을 수 있지만, 결국 마지막 5%는 – 우리가 하는 일을 완성하고, 고객이 기꺼이 돈을 지불하는 게 이 마지막 5%이다 – 사람이 직접 해야 한다는 게 내 생각이다. 많은 전문가들이 초지능의 시대가 멀지 않았다고 하지만, 나는 인간은 초지능 그 이상의 지능, 창의력, 그리고 여기서 파생되는 응용력을 가졌고, 결국 누구나 다 AI를 활용해서 누구나 다 비슷한 걸 만들 수 있는 이 시대에 이길 수 있는 제품, 서비스 그리고 사업을 만들 수 있는 건 이런 인간의 능력이라고 생각한다.\n어떤 창업가는 지금까지 외부 투자 없이 연간 수십억 원의 매출을 만들었고, 영업이익까지 발생하는 좋은 브랜드를 만들었다. 처음으로 펀드레이징을 하는데, 투자받으면 AI에 올인해서 고객의 데이터를 축적한 후, AI를 활용해서 초개인화된 브랜드를 판매하겠다고 한다. 물론, 이 전략은 교과서적으론 매우 이상적인 방향으로 회사를 성장시킬 수 있다. 그런데 나는 이분에게 지금까지 특별하게 데이터를 활용하지도 않고 기술을 깊게 적용하지도 않고 잘했고, 지금까지 했던 그 방식으로 연 매출 천억 원 까지 할 수 있는데 굳이 지금, 이 시점에 기존의 방법을 버리고, 회사가 잘하지도 못하는 AI에 올인하는 180도 다른 전략을 도입하는 이유를 물어봤다.\n특별한 이유는 없었다. 그냥 너도나도 다 AI 이야기를 하고 있고, 주변에 사업하는 다른 창업가분들에게 물어보니 모두 다 AI가 미래라는 말을 하고, 본인이 봤을 때도 데이터를 활용해서 AI 에이전트를 통한 한 초개인화 된 전략이야말로 수조 원짜리 회사를 만들 수 있는 방법이기 때문이라고 했다. 그런데 이런 이유는 그 어떤 사업에 갖다 붙여도 말이 되는 너무나 말로 하기엔 쉽지만, 실행하기엔 정말 어려운 전략이다.\n이미 몇 회사들은 기존에 하던 방식으로 계속 사업을 해도 충분히 잘할 수 있고, 현재 매출의 10배까지 할 수 있음에도, 갑자기 회사의 방향을 AI에 올인 했다가 후회하고 있다. 멀쩡하게 잘 되던 사업을 버리고 AI에 올인 했는데, 그사이에 다른 경쟁사들이 이 회사가 원래 잘하고 있던 분야에서 시장을 야금야금 다 뺏어갔다. 그리고 AI에 몰방하는 게 우리 사업에 맞는 전략이 아니라는 걸 깨달았을 땐, 이미 너무 늦어버린 것이다.\n실은, 이런 회사들이 이렇게 방향을 급하게 바꾸게 된 배경엔 투자자들도 한몫했다. 투자하는 조건으로 무조건 AI native 회사로 체질 개선하는 걸 요구했고, 계속 AI 뽐뿌질을 했기 때문이다. \n이 글을 읽고 내가 AI를 과소평가하거나 무시한다고 생각하면 오산이다. 우리 사업의 본질과 비즈니스 모델에 대해 명확하게 이해하고, 우리 고객은 왜 우리 제품을 구매하는지 명확하게 판단한 후에 과연 우리는 AI를 어떻게 활용하면 현재 사업을 10배, 100배 이상 키울 수 있는지에 대해 진지하게 고민한 후에 행동으로 옮겼으면 하는 게 내가 말하고자 하는 포인트이다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/08/be-careful-what-you-ask-for-with-ai.html#respond",
        "content": "전에 내가 AI가 중요한 게 아니라 비즈니스가 더 중요하다는 글을 썼는데, 그 내용의 연장선상의 글이다. 요새 직업상 또는 비직업상 만나는 사람들이, 정도의 차이는 있지만, 모두 다 AI 이야기를 한다. 특히나 창업가들은 AI라는 이 거대한 tech 물결을 어떻게 더 잘 타서 남들보다 더 빨리, 그리고 더 멀리 갈 수 있을지 매일 고민하면서 부서와 업무와는 상관없이 전사적(...)",
        "contentSnippet": "전에 내가 AI가 중요한 게 아니라 비즈니스가 더 중요하다는 글을 썼는데, 그 내용의 연장선상의 글이다. 요새 직업상 또는 비직업상 만나는 사람들이, 정도의 차이는 있지만, 모두 다 AI 이야기를 한다. 특히나 창업가들은 AI라는 이 거대한 tech 물결을 어떻게 더 잘 타서 남들보다 더 빨리, 그리고 더 멀리 갈 수 있을지 매일 고민하면서 부서와 업무와는 상관없이 전사적(...)",
        "guid": "https://www.thestartupbible.com/?p=9542",
        "categories": [
          "Uncategorized",
          "ai",
          "FoundersAtWork",
          "strategy",
          "technology",
          "vc"
        ],
        "isoDate": "2025-08-27T21:26:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "안티들의 말은 무시해라",
        "link": "https://www.thestartupbible.com/2025/08/dont-listen-to-your-haters.html",
        "pubDate": "Sun, 24 Aug 2025 21:26:00 +0000",
        "content:encodedSnippet": "얼마 전에 요새 큰 고민이 있는 우리 투자사 대표와 이야기를 했다. 사업은 그냥 나쁘지 않게 진행되고 있는데, 이 회사의 제품에 대한 악플과 형편없는 리뷰 때문에 밤잠을 설치고 있었다.\n아마도 이런 고민을 하거나, 한 번 정도는 해 본 대표들이 있을 것이다. 특히나 일반 고객과 실물 시장과의 접점이 훨씬 많은 B2C 서비스 또는 먹고, 입고, 바르는 제품을 만들어서 판매하는 브랜드/D2C 스타트업을 운영하는 분이라면 엄청난 악플과 제품 리뷰를 쏟아내는 안티들에게 시달려 본 경험이 있을 것이다.\n이런 분들에게 내가 해주고 싶은 조언은 다음과 같다.\n우리 회사와 제품에 대한 안 좋은 피드백이 단순 증오성 내용이 아니라, 실제 우리 제품을 자주 사용하는 고객의 애정이 어린 피드백이라면, 그리고 정말로 이분들이 우리 회사와 제품의 미래를 걱정한다면, 이런 충고, 리뷰, 피드백은 아주 적극적으로 듣고, 수용하고, 반영하는 노력을 해야 한다. 이런 분들이 우리 제품을 구매하고 사용하고, 결국엔 우리 회사가 계속 존재하게 만들어 주는 고마운 찐팬이기 때문이다. 그리고 이런 분들이 남기는 글이나 영상은 그냥 봐도 회사와 제품에 대한 애정이 보일 것이다.\n하지만, 처음부터 끝까지 특별한 논리와 내용도 없이 주구장창 우리 제품과 회사를 욕하는 증오성 피드백이라면 – 그리고 이런 건 그냥 보면 알 수 있다 – 그냥 무시하면 된다. 어차피 이런 사람들은 우리의 팬도 아니고 고객도 아니고 그냥 우리의 안티다. 아마도 우리 제품을 한 번 정도 써봤거나, 아니면 아예 써보지도 않고 그냥 악감정으로 특별한 이유 없이 이런 증오성 악플과 혹평을 하는 것일 텐데 이런 사람들은 우리 회사에 전혀 도움이 안 되는 인간들이다.\n우리 제품을 구매하는 건 우리의 팬이지, 우리의 안티들이 아니다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/08/dont-listen-to-your-haters.html#comments",
        "content": "얼마 전에 요새 큰 고민이 있는 우리 투자사 대표와 이야기를 했다. 사업은 그냥 나쁘지 않게 진행되고 있는데, 이 회사의 제품에 대한 악플과 형편없는 리뷰 때문에 밤잠을 설치고 있었다. 아마도 이런 고민을 하거나, 한 번 정도는 해 본 대표들이 있을 것이다. 특히나 일반 고객과 실물 시장과의 접점이 훨씬 많은 B2C 서비스 또는 먹고, 입고, 바르는 제품을(...)",
        "contentSnippet": "얼마 전에 요새 큰 고민이 있는 우리 투자사 대표와 이야기를 했다. 사업은 그냥 나쁘지 않게 진행되고 있는데, 이 회사의 제품에 대한 악플과 형편없는 리뷰 때문에 밤잠을 설치고 있었다. 아마도 이런 고민을 하거나, 한 번 정도는 해 본 대표들이 있을 것이다. 특히나 일반 고객과 실물 시장과의 접점이 훨씬 많은 B2C 서비스 또는 먹고, 입고, 바르는 제품을(...)",
        "guid": "https://www.thestartupbible.com/?p=9540",
        "categories": [
          "Uncategorized",
          "B2C",
          "brand",
          "FoundersAtWork"
        ],
        "isoDate": "2025-08-24T21:26:00.000Z"
      }
    ]
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "토스, 아고다와 업무협약 체결..결제 편의성 강화 및 공동 프로모션 협력",
        "link": "https://toss.im/tossfeed/article/agoda",
        "pubDate": "Wed, 27 Aug 2025 08:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}26일 토스 본사서 협약식…토스 오규인 부사장, 아고다 줄리아나 리타노  부사장 등 참석\n아고다에 토스페이 도입, 양사 공동 마케팅 등으로 고객 편의성·혜택 강화\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n토스(운영사 비바리퍼블리카, 대표 이승건)가 글로벌 디지털 여행 플랫폼 아고다(Agoda)와 전략적 업무협약(MOU)을 체결했다고 27일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n26일 서울 강남구 역삼동 토스 본사에서 열린 협약식에는 토스 오규인 부사장, 아고다 줄리아나 리타노(Giuliana Riitano) 부사장 등 양사 주요 관계자가 참석했다. 양사는 토스 간편결제 서비스와 아고다의 글로벌 플랫폼을 연계해 고객 편의성과 혜택을 강화하는 협력을 본격화하기로 했다.\n이번 협약으로 아고다 플랫폼에서 여행 상품 결제 시 토스페이를 사용할 수 있게 된다. 토스는 간편하고 직관적인 결제 UX/UI를 통해 아고다 고객들에게 한층 편리한 결제 경험을 제공할 계획이다.\n양사는 공동 마케팅과 프로모션, 데이터 기반 신규 유저 확보 등 다양한 활동을 통해 고객 혜택을 강화하고 이용자 저변을 확대할 방침이다. 또한 해당 파트너십을 통해 토스 해외여행 홈 내 아고다 서비스를 연계하는 등 이용자 접점을 확대하고 편의성을 높이는 방안도 추진한다.\n토스 오규인 부사장은 “글로벌 대표 여행 플랫폼 아고다와의 협약이 토스페이 저변을 넓히는 중요한 계기가 될 것이라 기대한다”며 “고객이 결제 과정에서 더 큰 편의성과 혜택을 체감할 수 있도록 양사가 다양한 영역에서 협력을 이어갈 계획”이라고 말했다.\n아고다 줄리아나 리타노 부사장은 “대한민국을 대표하는 금융 플랫폼 토스와의 협약을 통해 아고다 고객들에게 보다 편리한 결제 환경 및 경험, 매력적인 고객 리워드를 제공할 수 있게 되어 기대가 크다”며 “앞으로도 양사가 긴밀하게 협력해 고객들의 니즈에 맞춘 새롭고 다양한 서비스와 혜택을 선보이겠다”고 밝혔다.",
        "content": "토스 오규인 부사장, 아고다 줄리아나 리타노  부사장 등 참석",
        "contentSnippet": "토스 오규인 부사장, 아고다 줄리아나 리타노  부사장 등 참석",
        "guid": "https://toss.im/tossfeed/article/agoda",
        "isoDate": "2025-08-27T08:00:00.000Z"
      },
      {
        "title": "토스인사이트, 첫 보고서 '스테이블코인: 새로운 금융 인프라의 부상' 발간  ",
        "link": "https://toss.im/tossfeed/article/39889",
        "pubDate": "Mon, 25 Aug 2025 22:55:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}스테이블코인 3부작 중 첫 번째… 금융·산업·정책 관점을 아우르는 분석\n산업 가치사슬·비즈니스 사례·글로벌 규제 동향을 체계적으로 정리\n정책 당국·금융기관·연구자에게 지속적 담론 및 전략 수립 기반 제공\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n토스(운영사 비바리퍼블리카, 대표 이승건)의 금융경영연구소 ‘토스인사이트(Toss Insight, 대표 손병두)’가 첫 보고서 ‘스테이블코인: 새로운 금융 인프라의 부상’을 발간했다고 26일 밝혔다. 총 3부작으로 기획된 스테이블코인 시리즈의 첫 권은 총론 성격으로, 금융·산업·정책 관점을 아우르는 분석을 담았다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n\n이번 보고서는 스테이블코인을 단순한 가상자산이 아닌, 금융정책과 민간 혁신이 교차하는 새로운 과제로 바라본다. 글로벌 차원에서 금융시스템의 안정성과 발전 방향이 논의되는 가운데, 무엇보다 사실관계를 정리하고 좌표계를 세우는 작업이 필요하다는 문제 의식에서 출발했다. 이를 위해 화폐이론·금융경제학·산업조직론의 관점을 교차 적용해 스테이블코인의 구조와 작동 원리를 종합적으로 다뤘다.\n보고서는 스테이블코인의 정의와 주요 특징을 정리하고, 이어 시장 현황과 확장 배경을 짚는다. 나아가 스테이블코인의 세 가지 가치사슬인 ▲인프라 산업 ▲발행·유통 산업 ▲응용 솔루션 산업을 분석한다. 이후 글로벌 발행사와 금융기업의 실제 사례와 규제 동향까지 폭넓게 조명한다.\n토스인사이트는 이번 보고서를 통해 스테이블코인이 지닌 기회와 과제를 균형 있게 짚어냈다. 특히 정책 당국과 금융기관, 연구 현장에서 참고할 수 있는 분석과 인사이트를 담아 디지털 화폐 시대에 필요한 정책적·산업적 대응 전략 마련에 기여할 것으로 기대하고 있다.\n홍기훈 토스인사이트 연구소장은 “스테이블코인은 기존 금융 체계와 디지털 경제를 연결하는 중요한 고리로 주목받고 있다”며 “이번 보고서가 스테이블코인에 대한 건설적 논의와 정책적 대응 방안을 설계하는 데 기초 자료로 활용되기를 바란다”고 밝혔다.\n한편, 토스인사이트는 핀테크 업권을 중심으로 금융 관련 정책을 분석하고 트렌드를 연구하는 기관이다. 금융산업 전반에 유의미한 메시지를 전달하고, 금융기관으로서 토스의 사회적 기여도를 높이기 위해 설립됐다. 이번 보고서를 시작으로, 스테이블코인의 ‘규제·감독 편’과 ‘비즈니스 전략 편’을 순차적으로 발간해 시리즈를 완성할 예정이다.\n\n.css-1qimhyf{white-space:pre-wrap;color:var(--adaptiveGrey500);}현재 보고서는 임시 채널인 토스피드를 통해 공개되며, 토스인사이트 공식 홈페이지가 오픈되면 이후 발간되는 보고서들은 해당 홈페이지에서 확인하실 수 있습니다. \n.css-1lvcgm8{padding:22px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;border-radius:20px;}\n.css-13ko30i{width:375px;}보고서 링크",
        "content": "토스의 금융경영연구소 토스인사이트 분석력이 담긴 첫 보고서 발간",
        "contentSnippet": "토스의 금융경영연구소 토스인사이트 분석력이 담긴 첫 보고서 발간",
        "guid": "https://toss.im/tossfeed/article/39889",
        "isoDate": "2025-08-25T22:55:00.000Z"
      },
      {
        "title": "토스페이먼츠, 항공예약발권시스템(GDS) 간편결제 국내 첫 도입",
        "link": "https://toss.im/tossfeed/article/GDS",
        "pubDate": "Mon, 25 Aug 2025 13:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}글로벌 3대 GDS 운영사 ‘세이버’ 및 ‘놀유니버스’와 기술 제휴\n이용자 편의성 제고, 여행사·항공사 매출 증대 기대\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n비바리퍼블리카(토스)의 전자지급결제대행(PG) 계열사 토스페이먼츠(대표 임한욱)가 세이버(Sabre) 및 놀유니버스와 기술 제휴를 맺고 항공예약발권시스템(GDS, Global Distribution System)에 간편결제를 도입했다고 25일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n세이버는 전 세계 항공사와 여행사를 연결하는 글로벌 3대 GDS 중 하나다. 160여 개 국가에서 매년 수십억 건의 예약과 발권을 처리하고 있다. 그동안 항공사 개별 홈페이지와 앱에서는 간편결제가 보편화됐지만, GDS 시스템에서는 여전히 신용카드 번호를 직접 입력하는 방식의 결제만 가능해 이용자 불편이 컸다.\n이번 제휴로 국내 최초로 세이버 예약 시스템에서도 간편결제가 가능해졌다. 고객의 카드 정보를 수집하지 않아 민감 정보의 노출 위험도 최소화했다. 이용자들은 몇 번의 터치만으로 안전하고 편리한 결제 환경을 누릴 수 있게 됐다. 이는 여행·항공 업계 전반의 디지털 결제 혁신을 앞당길 것으로 기대된다.\n첫 적용 사례는 놀유니버스가 운영하는 여행 플랫폼 ‘NOL 인터파크투어’다. 놀유니버스와 토스페이먼츠의 기술 협업으로 주요 간편결제 서비스 중 하나인 토스의 ‘토스페이’를 통한 항공권 결제가 적용됐다. 토스페이먼츠는 내년 상반기까지 네이버페이, 카카오페이 등 다른 간편결제 서비스도 세이버 시스템과 추가 연동할 예정이다.\n토스페이먼츠 관계자는 “간편결제 도입으로 이용자들은 항공권 구매 채널과 관계없이 빠르고 간편한 결제 경험을 누릴 수 있게 됐다”며 “놀유니버스를 시작으로 더 많은 여행사와 항공사가 고객 만족과 매출 성장을 이룰 수 있도록 결제 혁신을 지속 확산하겠다”고 말했다.",
        "content": " NOL 인터파크투어에 토스페이 항공권 결제 적용",
        "contentSnippet": "NOL 인터파크투어에 토스페이 항공권 결제 적용",
        "guid": "https://toss.im/tossfeed/article/GDS",
        "isoDate": "2025-08-25T13:00:00.000Z"
      },
      {
        "title": "소비쿠폰 8월 안에 다 쓰면 최대 5만 원 쿠폰 받을 수 있어요.",
        "link": "https://toss.im/tossfeed/article/money-policies-48",
        "pubDate": "Fri, 22 Aug 2025 01:09:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}1차 민생회복 소비쿠폰을 신용·체크카드로 받아서 .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}8월 31일까지 다 쓰면, 최대 5만 원 상당의 쿠폰을 받을 수 있는 이벤트에 자동 응모돼요. 이 이벤트는 카드사가 공동으로 진행하는 행사로, 총 31만 명의 당첨자를 선정할 예정이에요. \n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}당첨 금액\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n5만 원 (1만 명)\n1만 원 (10만 명)\n5천 원 (20만 명)\n\n이벤트 응모 방법\n아래 조건을 만족했다면, 따로 신청하지 않아도 자동으로 응모돼요.\n\n소비쿠폰을 카드사로 신청한 사람\n2025년 8월 31일까지 1차 소비쿠폰을 전액 사용한 사람\n\n당첨 결과는 9월 중, 각 카드사를 통해 안내받을 수 있어요. 당첨을 통해 지급받은 추가쿠폰은 기존 소비쿠폰과 동일하게 연 매출 30억 원 이하 소상공인 가맹점에서 쓸 수 있어요. 대형마트, 백화점, 온라인 쇼핑몰, 프랜차이즈 직영점 등에서는 사용할 수 없어요.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 권민지 이지영 Graphic 이제현",
        "content": "따로 신청하지 않아도 자동으로 응모돼요",
        "contentSnippet": "따로 신청하지 않아도 자동으로 응모돼요",
        "guid": "https://toss.im/tossfeed/article/money-policies-48",
        "isoDate": "2025-08-22T01:09:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]