[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Augustin Popa",
        "title": "Siemens Healthineers manages C++ libraries with vcpkg in an offline build environment",
        "link": "https://devblogs.microsoft.com/cppblog/siemens-healthineers-manages-c-libraries-with-vcpkg-in-an-offline-build-environment/",
        "pubDate": "Tue, 12 Nov 2024 23:10:37 +0000",
        "content:encodedSnippet": "vcpkg is a free and open-source C/C++ package manager maintained by Microsoft and the C++ community that runs on Windows, macOS, and Linux. Over the years we have heard from companies using vcpkg to manage dependencies at enterprise-scale. For this blog post, I spoke to Shrey Chauhan, a Senior DevOps Engineer with Siemens Healthineers.\nSiemens Healthineers adopted vcpkg in late 2023 after a successful proof of concept. Their main motivation was to improve their versioning and overall dependency management for C++ libraries in their offline, air-gapped build environment. They also like vcpkg’s integration with the Visual Studio IDE, extensive and evolving library support, and automatic dependency resolution.\nAbout Siemens Healthineers and development team\nShrey: The Ultrasound business area is an integral part of Siemens Healthineers. This advanced medical device features a comprehensive hardware layer and a full-stack windows-based software layer. Ultrasound Software teams handle the development of the entire software stack, while the DevOps team manages CI/CD processes, including building, packaging, deployment, and related tools.\nC++ development environment\nSiemens Healthineers develops on Windows and targets Windows x64. They use Visual Studio 2022 with MSBuild projects, and their project is a combination of C#, C++/CLI, and C++. They have around 300 developers maintaining over 6 million lines of code. In addition, they use Azure DevOps as their continuous integration system.\nHow they were managing C++ dependencies before vcpkg\nTheir team mostly consumes open-source dependencies. They were previously packaging the C++ dependencies in individual .zip packages, which were being downloaded from a JFrog Artifactory repository. This is a tedious process because the path to each .dll or .lib needs to be correct and could vary based on the package.\nQ: When did your team move to vcpkg and why did you ultimately choose to move to vcpkg?\nShrey: We moved to vcpkg around September or October 2023 with the main reasoning being improved versioning and dependency management of C++ libraries. We did a proof of concept to determine if it suited our needs with respect to our air-gapped build environment, which was successful after a little help from vcpkg team. Additional features we benefitted from:\nvcpkg is well integrated with Visual Studio IDE\nHas extensive library support, which is still evolving\nAutomatic dependency resolution\nIn Siemens Ultrasound, our builds/CI are on a protected network with restricted access to the Internet. By default, vcpkg downloads packages from source repositories (Internet) which did not work for us because of access restrictions. We were able to work with the vcpkg team to integrate custom Asset Caching (which was later documented under: How to create a x-script Asset Caching source for NuGet | Microsoft Learn) to use our own Azure DevOps NuGet feed as a source to upload & restore packages. This addressed our issue with the air-gapped environment and allowed us to reuse existing cached packages, making the process more efficient.\nQ: What is your overall impression of vcpkg?\nShrey: Overall, the feedback has been good so far. vcpkg does a great job of caching the built libraries, making the developers’ workflow efficient. It has also been easily accepted by developers because of its ease of use (i.e. no extra steps or setup was required).\nLearn More About vcpkg\nIf you want to learn more about vcpkg, check out our website at vcpkg.io and read the vcpkg overview in our documentation.\nIf you have a story you would like to share with us about your experiences with vcpkg, feel free to contact us at vcpkg@microsoft.com. You can submit bug reports in our GitHub issue tracker or make feature requests in our discussion forum.\nThe post Siemens Healthineers manages C++ libraries with vcpkg in an offline build environment appeared first on C++ Team Blog.",
        "dc:creator": "Augustin Popa",
        "comments": "https://devblogs.microsoft.com/cppblog/siemens-healthineers-manages-c-libraries-with-vcpkg-in-an-offline-build-environment/#respond",
        "content": "<p>vcpkg is a free and open-source C/C++ package manager maintained by Microsoft and the C++ community that runs on Windows, macOS, and Linux. Over the years we have heard from companies using vcpkg to manage dependencies at enterprise-scale. For this blog post, I spoke to Shrey Chauhan, a Senior DevOps Engineer with Siemens Healthineers. Siemens [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/siemens-healthineers-manages-c-libraries-with-vcpkg-in-an-offline-build-environment/\">Siemens Healthineers manages C++ libraries with vcpkg in an offline build environment</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "vcpkg is a free and open-source C/C++ package manager maintained by Microsoft and the C++ community that runs on Windows, macOS, and Linux. Over the years we have heard from companies using vcpkg to manage dependencies at enterprise-scale. For this blog post, I spoke to Shrey Chauhan, a Senior DevOps Engineer with Siemens Healthineers. Siemens […]\nThe post Siemens Healthineers manages C++ libraries with vcpkg in an offline build environment appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34928",
        "categories": [
          "C++",
          "Vcpkg",
          "CPP",
          "vcpkg"
        ],
        "isoDate": "2024-11-12T23:10:37.000Z"
      },
      {
        "creator": "Sy Brand",
        "title": "What’s New for C++ Developers in Visual Studio 2022 17.12",
        "link": "https://devblogs.microsoft.com/cppblog/whats-new-for-c-developers-in-visual-studio-2022-17-12/",
        "pubDate": "Tue, 12 Nov 2024 20:58:48 +0000",
        "content:encodedSnippet": "We are happy to announce that Visual Studio 2022 version 17.12 is now generally available! This post summarizes the new features you can find in this release for C++. You can download Visual Studio 2022 from the Visual Studio downloads page or upgrade your existing installation by following the Update Visual Studio Learn page.\nStandard Library and MSVC Compiler\nAs always, you can find all the details about our STL work in the changelog on GitHub. Thanks to everyone who contributed changes for this release!\nOn the conformance side, we have finished the implementation of C++23’s P2286R8 Formatting Ranges by implementing:\nFormatters for the container adaptors stack, queue, and priority_queue. #4825\nrange-default-formatter. #4716\n\n\nWe implemented multidimensional subscript operators in the compiler, which supports our existing <mdspan> implementation. For example, you can use the my_mdspan[i,j] syntax to index multidimensional spans. Here’s a full example:\n#include <mdspan>\r\n#include <print>\r\n\r\nusing namespace std;\r\nint main() {\r\n    const char* const str{\"CatDogElkFox\"};\r\n    //Defines a multidimensional view of str\r\n    mdspan<const char, extents<int, 4, 3>> m{str, 4, 3};\r\n\r\n    for (int i = 0; i < m.extents().extent(0); ++i) {\r\n        for (int j = 0; j < m.extents().extent(1); ++j) {\r\n            //Note the m[i, j] syntax\r\n            print(\"m[{}, {}]: '{}'; \", i, j, m[i, j]);\r\n        }\r\n        println();\r\n    }\r\n}\nThis release also comes with some new C++26 features:\nP2997R1 Removing The Common Reference Requirement From The Indirectly Invocable Concepts\nP0952R2 A New Specification For generate_canonical()\nP2968R2 Make std::ignore A First-Class Object\nYou’ll find improvements to several debug visualizers, including those for mutex/recursive_mutex and move_iterator.\nWe added lifetimebound attributes to min, max, clamp, ranges::min, ranges::max, and ranges::clamp, allowing MSVC code analysis and Clang -Wdangling to detect dangling references in improper usage. See the documentation for warnings C26815 and C26816 for more information about lifetimebound annotations.\nFinally, we improved the performance of several types and algorithms. The popcount() function now uses a compiler intrinsic on ARM64. We further improved the vectorized implementations of the minmax_element() and minmax() algorithm families, and optimized the search() and find_end() algorithms. We also overhauled the implementations of condition_variable and condition_variable_any, which has knock-on effects on the timed_mutex and recursive_timed_mutex types.\nC++ Productivity\nSet Command Line Arguments\nFor Unreal Engine projects, you can now set the command line arguments to pass to your application directly from the toolbar. This toolbar component will show up by default if you have the Game development with C++ workload installed. If you don’t see it, you can add it by right-clicking on the toolbar and selecting Set Arguments.\n\nWe’ll be adding support for this feature to non-UE projects in the future. See Pass command-line arguments while debugging on Microsoft Learn for documentation.\nOpen Folder for Unreal Engine uproject\nWe have added an additional entry point to open your Unreal Engine uproject with Visual Studio’s uproject support. You can now open your uproject directly from the File menu by selecting Open > Folder…. This will open your Unreal Engine project in Visual Studio.\nFor more information on how to use this feature, see the documentation on Microsoft Learn and our announcement blog post.\n\nChange Signature Improvements\nWe have updated the Change Signature interface, allowing you to add, remove, and rearrange parameters in the parameter configuration section. Additionally, you can change their order by selecting and dragging them to a new position.\nThe access methods remain the same: press Ctrl+. to trigger the Quick Actions and Refactorings menu and select Change Signature.\n\nBuild Insights\nRun Build Insights on Selected Files\nYou can select a few files, run Build Insights on them, and see exactly how these files impact build performance.\n\nFilter Projects\nYou can now filter results based on projects. Simply click the filter button on the filter column header and select the projects you want to filter.\n\nGlob Patterns to Filter Files\nThe File Path Filter is incredibly useful for narrowing down your analysis to specific directories or excluding paths that aren’t relevant to your task.\n\nEnhanced Save Experience\nNow you can designate a folder to automatically store the reports so you can easily access them during your investigation.\n\nView Explanations\nYou can now see a short description on how each tab of Build Insights can be used, along with a link to the documentation for a detailed explanation.\n\nPath Adjustments\nWe have hidden full and relative paths to reduce clutter. To see full paths, simply hover over the file. You will also see a new File Name column for both files and translation units, displayed by default to help you quickly identify files without parsing lengthy paths.\n\nGeneral Productivity\nCopy from the Error List\nWhen you copy an error from the Error List using Ctrl+C, now only the description is copied to the clipboard. This makes it easier to search for the error online or share it with others.\nYou can still copy the entire row by right-clicking the error and selecting Copy Row from the context menu or hitting Ctrl+Shift+C.\nIf what you wanted to do with the error description was to do a web search, then just hit Ctrl+F1 to search for information about the error online.\n\nDock the Code Search window\nIf you need Code or Feature Search to stay out of your way, you now have more control over the behavior of the search window.\nYou can now dock the search window and perform tool window actions with it, like Solution Explorer and others.\n\nAfter opening Code Search or Feature Search, click on the box icon at the top right to convert it into a tool window. You may choose to dock it elsewhere, pop it out, auto-hide, etc. You can revert to the dismissible window by closing the tool window and reopening search.\n\nWe’ve also simplified and cleaned up the previewing experience in search. There is now one button, indicated with an eye icon, to toggle the preview on and off.\n\nRefresh your Find results\nWe heard from a lot of users that it’s frustrating having to reopen the Find window and go through the motions of redoing a search to get updated results. Maybe you just refactored some code and want to confirm everything has been changed as expected, or you pulled some recent changes and need your recent Find operation to reflect those updates.\nAfter completing Find in Files, you will now have the option to refresh the results in the window. You’ll get your updated results without having to redo the search.\n\nNon-blocking Code Cleanup on save\nPreviously when a Code Cleanup action was run on save, you couldn’t perform any actions in the IDE. We’ve now enhanced this to operate in a non-blocking manner. The cleanup process will run in the background and can be automatically cancelled if you resume typing.\nGit\nManage file renaming\nWhen you rename files from the Solution Explorer, you’ll now be reminded to stage your changes to see the renames in Git.\n\nCopy Git link\nYou can now get a GitHub or Azure DevOps link to a specific line of code to make it easy to share with your colleagues. Access this option by right-clicking on some code and selecting Git > Copy GitHub/Azure DevOps Permalink.\n\nDebugging\nInline Return Values\nThe debugger now displays return values inline, making it much easier to see the return value of functions that have complex return statements.\n\nGitHub Copilot\nSmart Variable Inspection\nYou can now click on Ask Copilot next to the value of a variable to get AI-driven insights into what led to your current program state. For example, the following program has an off-by-one error in its loop condition, resulting in undefined behavior:\n\nIf you click Ask Copilot, it tells you what went wrong:\n\nFix my Code\nFor errors in the Visual Studio Error List, you can click Ask Copilot for an explanation and a fix to get suggestions on how to rectify your errors. For example, if we try to fix the code from the previous section by introducing a range based for loop, we might get the following error:\n\nCopilot suggests the following:\n\nDebug Failed Tests\nWe might fix the above issue and write a test case to ensure the function works, but then have a cat sit on our keyboard and accidentally initialize n_cats to 1 instead of 0. Fortunately, GitHub Copilot now comes with options to help debug the test failure:\n\nSelecting this option may give something like the following:\n\nSend us your feedback\nWe are very much interested in your feedback to continue to improve this experience. The comments below are open. Feedback can also be shared through Visual Studio Developer Community. You can also reach us on Twitter (@VisualC), or via email at visualcpp@microsoft.com.\nThe post What’s New for C++ Developers in Visual Studio 2022 17.12 appeared first on C++ Team Blog.",
        "dc:creator": "Sy Brand",
        "comments": "https://devblogs.microsoft.com/cppblog/whats-new-for-c-developers-in-visual-studio-2022-17-12/#comments",
        "content": "<p>We are happy to announce that Visual Studio 2022 version 17.12 is now generally available! This post summarizes the new features you can find in this release for C++. You can download Visual Studio 2022 from the Visual Studio downloads page or upgrade your existing installation by following the Update Visual Studio Learn page. Standard Library and MSVC [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/whats-new-for-c-developers-in-visual-studio-2022-17-12/\">What’s New for C++ Developers in Visual Studio 2022 17.12</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "We are happy to announce that Visual Studio 2022 version 17.12 is now generally available! This post summarizes the new features you can find in this release for C++. You can download Visual Studio 2022 from the Visual Studio downloads page or upgrade your existing installation by following the Update Visual Studio Learn page. Standard Library and MSVC […]\nThe post What’s New for C++ Developers in Visual Studio 2022 17.12 appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34893",
        "categories": [
          "C++"
        ],
        "isoDate": "2024-11-12T20:58:48.000Z"
      },
      {
        "creator": "Augustin Popa",
        "title": "What’s New in vcpkg (October 2024)",
        "link": "https://devblogs.microsoft.com/cppblog/whats-new-in-vcpkg-october-2024/",
        "pubDate": "Thu, 07 Nov 2024 06:06:12 +0000",
        "content:encodedSnippet": "This blog post summarizes changes to the vcpkg package manager as part of the 2024.10.21 registry release, 2024-10-18 tool release, as well as changes to vcpkg documentation throughout October. This release adds support for Azure universal packages as a binary caching provider and other minor improvements.\nCppCon Talk on Managing C++ Dependencies\nI also gave a talk at CppCon about 10 Problems Large Companies Have with Managing C++ Dependencies and How to Solve Them. Here is a video recording of the talk:\n\nIn particular, I talked about several vcpkg features that can help:\nSupporting build from source as a fallback without sacrificing the build-time savings of binary dependency acquisition.\nUpgrading dependencies as a set using baselines, rather than managing them individually, to avoid version conflicts / diamond problems.\nHow to continue working in an offline build environment using asset caching.\nGetting any open-source libraries installed and working with your project with minimal effort, while also automatically resolving transitive dependencies.\nSome stats for this period:\nThere are now 2,490 total ports available in the vcpkg curated registry. A port is a versioned recipe for building a package from source, such as a C or C++ library.\n7 new ports were added to the curated registry.\n422 updates were made to existing ports. As always, we validate each change to a port by building all other ports that depend on or are depended by the library that is being updated for our 13 main triplets.\n53 contributors made commits (not counting the vcpkg maintainers).\nThe main vcpkg repo has over 6,400 forks and 23,200 stars on GitHub.\nvcpkg changelog (2024.10.21 release)\nThe following changes were made in October:\nAdded support for Azure universal packages as a binary caching provider (PR: Microsoft/vcpkg-tool#1491).\nOther minor improvements.\nDocumentation changes\nAdded reference documentation for binary caching with Azure universal packages as a back-end (PR: Microsoft/vcpkg-docs#414).\nUpdated links, fixed typos, and added some clarifications to usage examples for vcpkg maintainer functions (PR: Microsoft/vcpkg-docs#381, thanks @Thomas1664!).\nClarified how default features should be used for vcpkg ports in maintainer guide (PR: Microsoft/vcpkg-docs#410).\nUpdated docs for vcpkg supported host environments (PR: Microsoft/vcpkg-docs#415).\nImprovements to example for packaging GitHub repos in vcpkg (PR: Microsoft/vcpkg-docs#405, thanks @andre-nguyen!).\nFixed nuget command for setapikey in Set up a vcpkg binary cache using a NuGet feed tutorial (PR: Microsoft/vcpkg-docs#381, thanks @Thomas1664!).\nIf you have any suggestions for our documentation, please submit an issue in our GitHub repo or see the box at the bottom of a particular article.\n\nTotal ports available for tested triplets\ntriplet\nports available\n\n\nx64-windows\n2,361\n\n\nx86-windows\n2,261\n\n\nx64-windows-static\n2,261\n\n\nx64-windows-static-md\n2,281\n\n\narm64-windows\n1,960\n\n\nx64-uwp\n1,307\n\n\narm64-uwp\n1,276\n\n\nx64-linux\n2,336\n\n\nx64-osx\n2,209\n\n\narm64-osx\n2,132\n\n\narm-neon-android\n1,635\n\n\nx64-android\n1,713\n\n\narm64-android\n1,685\n\n\n\nWhile vcpkg supports a much larger variety of target platforms and architectures (as community triplets), the list above is validated exhaustively to ensure updated ports don’t break other ports in the catalog.\nThank you to our contributors\nvcpkg couldn’t be where it is today without contributions from our open-source community. Thank you for your continued support! The following people contributed to the vcpkg, vcpkg-tool, or vcpkg-docs repos in this release (listed alphabetically by GitHub username):\nADKaster\nAenBleidd\nAl17OTON\nandre-nguyen\nautoantwort\nbraindigitalis\nc8ef\ncenit\nComputerKing12\ndbolduc\ndg0yt\nfran6co\nGabeRundlett\nGastineau\nhansingt\nHappySeaFox\nHosseinmoein\nlrineau\nJAicewizard\njandupej\njeremy-rifkin\njiayuehua\njohnwason\nkadirlua\nkwsp\nlemourin\nlukasberbuer\nmiyanyan\nm-kuhn\nNeumann-A\nnickdademo\nnlogozzo\nOlli1080\nOsyotr\nplevy\nPoldraunic\nRealTimeChris\nredboltz\nrmisev\nRT2Code\nrtzoeller\nShadowrom2020\nSHIINASAMA\nsiukosev\nstarfishmod\nSunBlack\nSuperCodeHero\nsweemer\ntalregev\nteo-tsirpanis\nThomas1664\nwaywardmonkeys\nwinsoft666\nLearn more\nYou can find the main release notes on GitHub. Recent updates to the vcpkg tool can be viewed on the vcpkg-tool Releases page. To contribute to vcpkg documentation, visit the vcpkg-docs repo. If you’re new to vcpkg or curious about how a package manager can make your life easier as a C/C++ developer, check out the vcpkg website – vcpkg.io.\nIf you would like to contribute to vcpkg and its library catalog, or want to give us feedback on anything, check out our GitHub repo. Please report bugs or request updates to ports in our issue tracker or join more general discussion in our discussion forum.\nThe post What’s New in vcpkg (October 2024) appeared first on C++ Team Blog.",
        "dc:creator": "Augustin Popa",
        "comments": "https://devblogs.microsoft.com/cppblog/whats-new-in-vcpkg-october-2024/#respond",
        "content": "<p>This blog post summarizes changes to the vcpkg package manager as part of the 2024.10.21 registry release, 2024-10-18 tool release, as well as changes to vcpkg documentation throughout October. This release adds support for Azure universal packages as a binary caching provider and other minor improvements. CppCon Talk on Managing C++ Dependencies I also gave [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/whats-new-in-vcpkg-october-2024/\">What’s New in vcpkg (October 2024)</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "This blog post summarizes changes to the vcpkg package manager as part of the 2024.10.21 registry release, 2024-10-18 tool release, as well as changes to vcpkg documentation throughout October. This release adds support for Azure universal packages as a binary caching provider and other minor improvements. CppCon Talk on Managing C++ Dependencies I also gave […]\nThe post What’s New in vcpkg (October 2024) appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34878",
        "categories": [
          "C++",
          "Vcpkg",
          "vcpkg"
        ],
        "isoDate": "2024-11-07T06:06:12.000Z"
      }
    ]
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "How Meta built large-scale cryptographic monitoring",
        "link": "https://engineering.fb.com/2024/11/12/security/how-meta-built-large-scale-cryptographic-monitoring/",
        "pubDate": "Tue, 12 Nov 2024 17:00:10 +0000",
        "content:encodedSnippet": "Cryptographic monitoring at scale has been instrumental in helping our engineers understand how cryptography is used at Meta.\nMonitoring has given us a distinct advantage in our efforts to proactively detect and remove weak cryptographic algorithms and has assisted with our general change safety and reliability efforts.\nWe’re sharing insights into our own cryptographic monitoring system, including challenges faced in its implementation, with the hope of assisting others in the industry aiming to deploy cryptographic monitoring at a similar scale.\nMeta’s managed cryptographic library, FBCrypto, plays an important role within Meta’s infrastructure and is used by the majority of our core infrastructure services. Given this, having a robust monitoring system in place for FBCrypto has been instrumental in ensuring its reliability as well as in helping our engineers understand how cryptography is used at Meta so they can make informed development decisions.\nMonitoring the health of our library allows us to detect and revert bugs before they reach production services. The data from our monitoring service provides insight into the usage of FBCrypto, allowing us to make data-driven decisions when deciding what improvements to make to the library. For example, it helps us identify components that need more attention either because they are on a hot path or are less stable.\nUnderstanding exactly how clients are using said library is a common pain point in managing any widely distributed library. But the improved understanding of FBCrypto provided by our monitoring helps us maintain a high bar for security posture. Since there is a limit to how much data a symmetric cryptographic key can protect, logging allows us to detect key overuse and rotate keys proactively. It also helps us build an inventory of cryptography usage, making it easy to identify the callsites of weakened algorithms that need to be migrated – a very important task because we need to proactively switch from weakened algorithms to newer, more robust ones as cryptography strength decays over time.\nMore generally, improved understanding helps us to make emergency algorithm migrations when a vulnerability of a primitive is discovered.\nMore recently, this is aiding our efforts to ensure post-quantum readiness in our asymmetric use cases. The available data improves our decision-making process while prioritizing quantum-vulnerable use cases\nHow cryptographic monitoring works at Meta\nEffective cryptographic monitoring requires storing persisted logs of cryptographic events, upon which diagnostic and analytic tools can be used to gather further insights. Supporting logging at the scale of FBCrypto requires an implementation with unique performance considerations in mind. Given that FBCrypto is used along many high-volume and critical code paths, a naive logging implementation could easily overwhelm a standard logging infrastructure or cause significant performance regressions. This is true for most widely distributed libraries and is especially true in the field of cryptography, where the sheer volume of usage can come as a complete surprise to those unfamiliar with the space. For example, we recently disclosed that roughly 0.05% of CPU cycles at Meta are spent on X25519 key exchange. \nMost of Meta’s logs are constructed and written via Scribe, Meta’s standard logging framework. From there, data persists in Scuba and Hive, Meta’s short-term and long term data stores, respectively.\nTypically, the Scribe API is called directly to construct a log for every “event” that needs to be logged. For FBCrypto, this would mean constructing a log for nearly every cryptographic operation that our library is used for. Unfortunately, given the sheer frequency of such operations, a solution like this would consume an unreasonable amount of write throughput and storage capacity. A common solution to this problem would be to introduce sampling (i.e., only log 1/X cryptographic operations, and increase X until we no longer have capacity concerns). However, we felt strongly about not introducing any sampling since doing so would result in most logs being omitted, giving us a less clear picture of the library’s usage.\nInstead, the logging uses a “buffering and flushing” strategy, in which cryptographic events are aggregated across time and flushed to a data store at a preconfigured interval.\nDuring the aggregation, a “count” is maintained for every unique event. When it comes time to flush, this count is exported along with the log to convey how often that particular event took place. \nBelow is a rough illustration of what this looks like:\n\nIn the above example, the key named “myKeyName” is used to perform encryption using the AES-GCM-SIV encryption algorithm (in practice we log more fields than just key name, method, and algorithm). The operation happens five times and is assigned on a count of five. Since machines often compute millions of cryptographic operations per day, this strategy can lead to significant compute savings in production. \nA client-side view\nThe aggregation and flushing is implemented within FBCrypto, so the logging and flushing code sits on the client hosts. When clients call a given cryptographic operation (e.g., “encrypt()”), the operation is performed and the log is added to our aggregated buffer. We refer to the object that holds the buffer as the “buffered logger.”\nNote that the logging does not change the interface of FBCrypto, so all of this is transparent to the clients of the library. \n\nIn multithreaded environments all threads will log to the same buffer. For this to be performant, we need to choose the right underlying data structure (see the section below on “Additional optimizations” for more details).\nWhile the aggregation works to reduce space and time overhead, the logs need to eventually be written to storage for further use. To do this, a background thread runs on the client host to periodically call the Scribe API to export the logs and flush the map’s contents. \nBelow is an overview of the overall flow: \n\nAdditional optimizations\nWe had to make some additional optimizations to support cryptographic monitoring on Meta’s major products (Facebook, Whatsapp, Instagram, etc.).\nWith careful design choices around the logging logic and data structures used, our cryptographic logging operates with no sampling and has had a negligible impact on compute performance across Meta’s fleet.\nPartially randomized flushing\nDue to the nature of our buffering and flushing strategy, certain clients who were running jobs that restarted large sets of machines at around the same time would have those machines’ logs get flushed at about the same time. This would result in “spiky” writes to the logging platform, followed by longer periods of underutilization between flushes. To normalize our write throughput, we distribute these spikes across time by applying a randomized delay on a per-host basis before logs are flushed for the first time. This leads to a more uniform flushing cadence, allowing for a more consistent load on Scribe. \nThe figure below demonstrates how this works:\n\nDerived crypto\nFBCrypto supports a feature called derived crypto, which allows “child” keysets to be derived from “parent” keysets by applying a key derivation function (KDF) to all the keys in the keyset with some salt. This feature is used by a few large-scale use cases that need to generate millions of keys.\nOur logging initially created a unique row in the buffered logger for every derived keyset, which used a lot of space and put increased load on backend data stores. To address this, we now aggregate the cryptographic operations of derived keys under the name of the parent key. This reduces our overall capacity needs without harming our ability to detect key overuse since, in the worst case, the aggregations would be a pessimistic counter for any given child key. \nThanks to this aggregation, we were able to cut down on the vast majority of our logging volume, compared to the space that would have been used with no aggregation. \nThe Folly library \nInternally, our buffering makes use of the folly::ConcurrentHashMap, which is built to be performant under heavy writes in multithreaded environments, while still guaranteeing atomic accesses.  \nUnified offerings\nMeta’s existing infrastructure and its emphasis on unified offerings are key to supporting this at scale (see the Scribe logging framework and the FBCrypto library). These properties often mean that solutions only have to be implemented once in order for the entire company to benefit.\nThis is especially true here. Most machines in Meta’s fleet can log to Scribe, giving us easy log ingestion support. Furthermore, the wide adoption of FBCrypto gives us insights into cryptographic operations without needing clients to migrate to a new library/API. \nFrom an engineering perspective, this helps us overcome many hurdles that others in the industry might face. For example, it helps us avoid fragmentation that might require multiple custom solutions to be implemented, which would increase our engineering workload.\nThe impact of cryptographic monitoring\nThe insights from our cryptographic monitoring efforts have served multiple use cases across our security and infrastructure reliability efforts.\nPreemptively mitigating security vulnerabilities\nThanks to our long retention window, we can monitor trends over time and use them for more predictive modeling and analysis. We can present our findings to cryptography experts, who can do further analysis and predict whether vulnerabilities may emerge. This allows us to preemptively identify clients using cryptography in risky ways and work with them to mitigate these issues before they become real security vulnerabilities. \nThis is particularly beneficial in preparation for the world of post-quantum cryptography (PQC), which requires us to find clients using vulnerable algorithms and ensure they are migrated off in a timely fashion. \nWe have also found that being able to preemptively detect these vulnerabilities well in advance has led to stronger support during cross-team collaborations. Thanks to the ample notice, teams can seamlessly integrate any necessary migration efforts into their roadmap with minimal interruption to their ongoing projects.\nPromoting infrastructure reliability\nOur root dataset has also served as a useful proxy for client health. This is partially thanks to the lack of sampling, as we can see the exact number of calls taking place, along with their respective success rates. This has been particularly important during large-scale migrations, where anomalous drops in success rate, call volume, etc., may indicate a bug in a new code path. Indeed, numerous detectors and alarms have been built off our dataset to help us perform big migrations safely.\nThe dataset also contains library versioning information, so we can monitor what versions of our library are running across the fleet in real-time. This has been especially useful for rolling out new features, as we can see exactly which clients have picked up the latest changes. This allows us to move faster and more confidently, even when running large-scale migrations across the fleet. \nChallenges to cryptographic monitoring\nSupporting cryptographic logging at Meta’s scale has had its own unique set of challenges.\nCapacity constraints\nDespite our optimizations, we have occasionally found ourselves putting increased load on Scribe (see point above about underestimating cryptographic usage) and have worked with the Scribe team to manage the unexpected increase in write throughput. Doing so has been relatively easy for the company, considering the design optimizations mentioned above.\nWe also occasionally put an increased load on Scuba, which is optimized to be performant for real-time data (i.e., warm storage) and can be inefficient if used for larger datasets. To minimize compute costs, we also rely on Hive tables for longer-term storage (i.e., cold storage). \nFlushing on shutdown\nBesides flushing the logs in the shared singleton map at a preconfigured time interval, client machines will also do one final flush to log all remaining contents of their log buffer to Scribe when a job is being shut down. We have found that operating in a “shutdown environment” can lead to a number of interesting scenarios, particularly when attempting to access Scribe and its dependencies. Many of these scenarios boil down to the nuances of folly::Singleton, which is Meta’s go-to library for managing singletons. Likewise, running something “on shutdown” in Java requires using only synchronous I/O code and operating quickly.\nOur next initiatives for cryptographic monitoring\nWhile our work thus far has been largely a success, there are many exciting avenues for improvements. For example, further optimizing Scribe throughput and Scuba storage utilization to make more efficient use of Meta’s infrastructure  \nWe will also continue to leverage the logging data to further develop monitoring and data analytics to promote security and reliability. On the security side, this means continuing to take an inventory of use cases that would be vulnerable in a PQC world and migrate them to more resilient algorithms/configurations. In terms of reliability, it means gaining a better understanding of the end-to-end latency for cryptography use cases.\nWithin all of this it’s also important that we continue driving the unification of cryptographic offerings and monitoring tooling. While FBCrypto provides a unified set of offerings, there are other cryptographic use cases across Meta that use a different set of tools for telemetry and data collection. More non-trivial work is needed to achieve full unification with all use cases.\nAcknowledgments\nThis work could not have been accomplished without the critical efforts of numerous folks, particularly Grace Wu, Ilya Maykov, Isaac Elbaz, and the rest of the CryptoEng team at Meta.\nThe post How Meta built large-scale cryptographic monitoring appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Cryptographic monitoring at scale has been instrumental in helping our engineers understand how cryptography is used at Meta. Monitoring has given us a distinct advantage in our efforts to proactively detect and remove weak cryptographic algorithms and has assisted with our general change safety and reliability efforts. We’re sharing insights into our own cryptographic monitoring [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/11/12/security/how-meta-built-large-scale-cryptographic-monitoring/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/11/12/security/how-meta-built-large-scale-cryptographic-monitoring/\">How Meta built large-scale cryptographic monitoring</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Cryptographic monitoring at scale has been instrumental in helping our engineers understand how cryptography is used at Meta. Monitoring has given us a distinct advantage in our efforts to proactively detect and remove weak cryptographic algorithms and has assisted with our general change safety and reliability efforts. We’re sharing insights into our own cryptographic monitoring [...]\nRead More...\nThe post How Meta built large-scale cryptographic monitoring appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21935",
        "categories": [
          "Security"
        ],
        "isoDate": "2024-11-12T17:00:10.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": [
      {
        "creator": "Netflix Technology Blog",
        "title": "Netflix’s Distributed Counter Abstraction",
        "link": "https://netflixtechblog.com/netflixs-distributed-counter-abstraction-8d0c45eb66b2?source=rss----2615bd06b42e---4",
        "pubDate": "Tue, 12 Nov 2024 20:45:23 GMT",
        "content:encodedSnippet": "By: Rajiv Shringi, Oleksii Tkachuk, Kartik Sathyanarayanan\nIntroduction\nIn our previous blog post, we introduced Netflix’s TimeSeries Abstraction, a distributed service designed to store and query large volumes of temporal event data with low millisecond latencies. Today, we’re excited to present the Distributed Counter Abstraction. This counting service, built on top of the TimeSeries Abstraction, enables distributed counting at scale while maintaining similar low latency performance. As with all our abstractions, we use our Data Gateway Control Plane to shard, configure, and deploy this service globally.\nDistributed counting is a challenging problem in computer science. In this blog post, we’ll explore the diverse counting requirements at Netflix, the challenges of achieving accurate counts in near real-time, and the rationale behind our chosen approach, including the necessary trade-offs.\nNote: When it comes to distributed counters, terms such as ‘accurate’ or ‘precise’ should be taken with a grain of salt. In this context, they refer to a count very close to accurate, presented with minimal delays.\nUse Cases and Requirements\nAt Netflix, our counting use cases include tracking millions of user interactions, monitoring how often specific features or experiences are shown to users, and counting multiple facets of data during A/B test experiments, among others.\nAt Netflix, these use cases can be classified into two broad categories:\n\nBest-Effort: For this category, the count doesn’t have to be very accurate or durable. However, this category requires near-immediate access to the current count at low latencies, all while keeping infrastructure costs to a minimum.\nEventually Consistent: This category needs accurate and durable counts, and is willing to tolerate a slight delay in accuracy and a slightly higher infrastructure cost as a trade-off.\n\nBoth categories share common requirements, such as high throughput and high availability. The table below provides a detailed overview of the diverse requirements across these two categories.\n\nDistributed Counter Abstraction\nTo meet the outlined requirements, the Counter Abstraction was designed to be highly configurable. It allows users to choose between different counting modes, such as Best-Effort or Eventually Consistent, while considering the documented trade-offs of each option. After selecting a mode, users can interact with APIs without needing to worry about the underlying storage mechanisms and counting methods.\nLet’s take a closer look at the structure and functionality of the API.\nAPI\nCounters are organized into separate namespaces that users set up for each of their specific use cases. Each namespace can be configured with different parameters, such as Type of Counter, Time-To-Live (TTL), and Counter Cardinality, using the service’s Control Plane.\nThe Counter Abstraction API resembles Java’s AtomicInteger interface:\nAddCount/AddAndGetCount: Adjusts the count for the specified counter by the given delta value within a dataset. The delta value can be positive or negative. The AddAndGetCount counterpart also returns the count after performing the add operation.\n{\n  \"namespace\": \"my_dataset\",\n  \"counter_name\": \"counter123\",\n  \"delta\": 2,\n  \"idempotency_token\": { \n    \"token\": \"some_event_id\",\n    \"generation_time\": \"2024-10-05T14:48:00Z\"\n  }\n}\nThe idempotency token can be used for counter types that support them. Clients can use this token to safely retry or hedge their requests. Failures in a distributed system are a given, and having the ability to safely retry requests enhances the reliability of the service.\nGetCount: Retrieves the count value of the specified counter within a dataset.\n{\n  \"namespace\": \"my_dataset\",\n  \"counter_name\": \"counter123\"\n}\nClearCount: Effectively resets the count to 0 for the specified counter within a dataset.\n{\n  \"namespace\": \"my_dataset\",\n  \"counter_name\": \"counter456\",\n  \"idempotency_token\": {...}\n}\nNow, let’s look at the different types of counters supported within the Abstraction.\nTypes of Counters\nThe service primarily supports two types of counters: Best-Effort and Eventually Consistent, along with a third experimental type: Accurate. In the following sections, we’ll describe the different approaches for these types of counters and the trade-offs associated with each.\nBest Effort Regional Counter\nThis type of counter is powered by EVCache, Netflix’s distributed caching solution built on the widely popular Memcached. It is suitable for use cases like A/B experiments, where many concurrent experiments are run for relatively short durations and an approximate count is sufficient. Setting aside the complexities of provisioning, resource allocation, and control plane management, the core of this solution is remarkably straightforward:\n// counter cache key\ncounterCacheKey = <namespace>:<counter_name>\n// add operation\nreturn delta > 0\n    ? cache.incr(counterCacheKey, delta, TTL)\n    : cache.decr(counterCacheKey, Math.abs(delta), TTL);\n// get operation\ncache.get(counterCacheKey);\n// clear counts from all replicas\ncache.delete(counterCacheKey, ReplicaPolicy.ALL);\nEVCache delivers extremely high throughput at low millisecond latency or better within a single region, enabling a multi-tenant setup within a shared cluster, saving infrastructure costs. However, there are some trade-offs: it lacks cross-region replication for the increment operation and does not provide consistency guarantees, which may be necessary for an accurate count. Additionally, idempotency is not natively supported, making it unsafe to retry or hedge requests.\nEventually Consistent Global Counter\nWhile some users may accept the limitations of a Best-Effort counter, others opt for precise counts, durability and global availability. In the following sections, we’ll explore various strategies for achieving durable and accurate counts. Our objective is to highlight the challenges inherent in global distributed counting and explain the reasoning behind our chosen approach.\nApproach 1: Storing a Single Row per Counter\nLet’s start simple by using a single row per counter key within a table in a globally replicated datastore.\n\nLet’s examine some of the drawbacks of this approach:\n\nLack of Idempotency: There is no idempotency key baked into the storage data-model preventing users from safely retrying requests. Implementing idempotency would likely require using an external system for such keys, which can further degrade performance or cause race conditions.\nHeavy Contention: To update counts reliably, every writer must perform a Compare-And-Swap operation for a given counter using locks or transactions. Depending on the throughput and concurrency of operations, this can lead to significant contention, heavily impacting performance.\n\nSecondary Keys: One way to reduce contention in this approach would be to use a secondary key, such as a bucket_id, which allows for distributing writes by splitting a given counter into buckets, while enabling reads to aggregate across buckets. The challenge lies in determining the appropriate number of buckets. A static number may still lead to contention with hot keys, while dynamically assigning the number of buckets per counter across millions of counters presents a more complex problem.\nLet’s see if we can iterate on our solution to overcome these drawbacks.\nApproach 2: Per Instance Aggregation\nTo address issues of hot keys and contention from writing to the same row in real-time, we could implement a strategy where each instance aggregates the counts in memory and then flushes them to disk at regular intervals. Introducing sufficient jitter to the flush process can further reduce contention.\n\nHowever, this solution presents a new set of issues:\n\nVulnerability to Data Loss: The solution is vulnerable to data loss for all in-memory data during instance failures, restarts, or deployments.\nInability to Reliably Reset Counts: Due to counting requests being distributed across multiple machines, it is challenging to establish consensus on the exact point in time when a counter reset occurred.\nLack of Idempotency: Similar to the previous approach, this method does not natively guarantee idempotency. One way to achieve idempotency is by consistently routing the same set of counters to the same instance. However, this approach may introduce additional complexities, such as leader election, and potential challenges with availability and latency in the write path.\n\nThat said, this approach may still be suitable in scenarios where these trade-offs are acceptable. However, let’s see if we can address some of these issues with a different event-based approach.\nApproach 3: Using Durable Queues\nIn this approach, we log counter events into a durable queuing system like Apache Kafka to prevent any potential data loss. By creating multiple topic partitions and hashing the counter key to a specific partition, we ensure that the same set of counters are processed by the same set of consumers. This setup simplifies facilitating idempotency checks and resetting counts. Furthermore, by leveraging additional stream processing frameworks such as Kafka Streams or Apache Flink, we can implement windowed aggregations.\n\nHowever, this approach comes with some challenges:\n\nPotential Delays: Having the same consumer process all the counts from a given partition can lead to backups and delays, resulting in stale counts.\nRebalancing Partitions: This approach requires auto-scaling and rebalancing of topic partitions as the cardinality of counters and throughput increases.\n\nFurthermore, all approaches that pre-aggregate counts make it challenging to support two of our requirements for accurate counters:\n\nAuditing of Counts: Auditing involves extracting data to an offline system for analysis to ensure that increments were applied correctly to reach the final value. This process can also be used to track the provenance of increments. However, auditing becomes infeasible when counts are aggregated without storing the individual increments.\nPotential Recounting: Similar to auditing, if adjustments to increments are necessary and recounting of events within a time window is required, pre-aggregating counts makes this infeasible.\n\nBarring those few requirements, this approach can still be effective if we determine the right way to scale our queue partitions and consumers while maintaining idempotency. However, let’s explore how we can adjust this approach to meet the auditing and recounting requirements.\nApproach 4: Event Log of Individual Increments\nIn this approach, we log each individual counter increment along with its event_time and event_id. The event_id can include the source information of where the increment originated. The combination of event_time and event_id can also serve as the idempotency key for the write.\n\nHowever, in its simplest form, this approach has several drawbacks:\n\nRead Latency: Each read request requires scanning all increments for a given counter potentially degrading performance.\nDuplicate Work: Multiple threads might duplicate the effort of aggregating the same set of counters during read operations, leading to wasted effort and subpar resource utilization.\nWide Partitions: If using a datastore like Apache Cassandra, storing many increments for the same counter could lead to a wide partition, affecting read performance.\nLarge Data Footprint: Storing each increment individually could also result in a substantial data footprint over time. Without an efficient data retention strategy, this approach may struggle to scale effectively.\n\nThe combined impact of these issues can lead to increased infrastructure costs that may be difficult to justify. However, adopting an event-driven approach seems to be a significant step forward in addressing some of the challenges we’ve encountered and meeting our requirements.\nHow can we improve this solution further?\nNetflix’s Approach\nWe use a combination of the previous approaches, where we log each counting activity as an event, and continuously aggregate these events in the background using queues and a sliding time window. Additionally, we employ a bucketing strategy to prevent wide partitions. In the following sections, we’ll explore how this approach addresses the previously mentioned drawbacks and meets all our requirements.\nNote: From here on, we will use the words “rollup” and “aggregate” interchangeably. They essentially mean the same thing, i.e., collecting individual counter increments/decrements and arriving at the final value.\nTimeSeries Event Store:\nWe chose the TimeSeries Data Abstraction as our event store, where counter mutations are ingested as event records. Some of the benefits of storing events in TimeSeries include:\nHigh-Performance: The TimeSeries abstraction already addresses many of our requirements, including high availability and throughput, reliable and fast performance, and more.\nReducing Code Complexity: We reduce a lot of code complexity in Counter Abstraction by delegating a major portion of the functionality to an existing service.\nTimeSeries Abstraction uses Cassandra as the underlying event store, but it can be configured to work with any persistent store. Here is what it looks like:\n\nHandling Wide Partitions: The time_bucket and event_bucket columns play a crucial role in breaking up a wide partition, preventing high-throughput counter events from overwhelming a given partition. For more information regarding this, refer to our previous blog.\nNo Over-Counting: The event_time, event_id and event_item_key columns form the idempotency key for the events for a given counter, enabling clients to retry safely without the risk of over-counting.\nEvent Ordering: TimeSeries orders all events in descending order of time allowing us to leverage this property for events like count resets.\nEvent Retention: The TimeSeries Abstraction includes retention policies to ensure that events are not stored indefinitely, saving disk space and reducing infrastructure costs. Once events have been aggregated and moved to a more cost-effective store for audits, there’s no need to retain them in the primary storage.\nNow, let’s see how these events are aggregated for a given counter.\nAggregating Count Events:\nAs mentioned earlier, collecting all individual increments for every read request would be cost-prohibitive in terms of read performance. Therefore, a background aggregation process is necessary to continually converge counts and ensure optimal read performance.\nBut how can we safely aggregate count events amidst ongoing write operations?\nThis is where the concept of Eventually Consistent counts becomes crucial. By intentionally lagging behind the current time by a safe margin, we ensure that aggregation always occurs within an immutable window.\nLets see what that looks like:\n\nLet’s break this down:\n\nlastRollupTs: This represents the most recent time when the counter value was last aggregated. For a counter being operated for the first time, this timestamp defaults to a reasonable time in the past.\nImmutable Window and Lag: Aggregation can only occur safely within an immutable window that is no longer receiving counter events. The “acceptLimit” parameter of the TimeSeries Abstraction plays a crucial role here, as it rejects incoming events with timestamps beyond this limit. During aggregations, this window is pushed slightly further back to account for clock skews.\n\nThis does mean that the counter value will lag behind its most recent update by some margin (typically in the order of seconds). This approach does leave the door open for missed events due to cross-region replication issues. See “Future Work” section at the end.\n\nAggregation Process: The rollup process aggregates all events in the aggregation window since the last rollup to arrive at the new value.\n\nRollup Store:\nWe save the results of this aggregation in a persistent store. The next aggregation will simply continue from this checkpoint.\n\nWe create one such Rollup table per dataset and use Cassandra as our persistent store. However, as you will soon see in the Control Plane section, the Counter service can be configured to work with any persistent store.\nLastWriteTs: Every time a given counter receives a write, we also log a last-write-timestamp as a columnar update in this table. This is done using Cassandra’s USING TIMESTAMP feature to predictably apply the Last-Write-Win (LWW) semantics. This timestamp is the same as the event_time for the event. In the subsequent sections, we’ll see how this timestamp is used to keep some counters in active rollup circulation until they have caught up to their latest value.\nRollup Cache\nTo optimize read performance, these values are cached in EVCache for each counter. We combine the lastRollupCount and lastRollupTs into a single cached value per counter to prevent potential mismatches between the count and its corresponding checkpoint timestamp.\n\nBut, how do we know which counters to trigger rollups for? Let’s explore our Write and Read path to understand this better.\nAdd/Clear Count:\n\nAn add or clear count request writes durably to the TimeSeries Abstraction and updates the last-write-timestamp in the Rollup store. If the durability acknowledgement fails, clients can retry their requests with the same idempotency token without the risk of overcounting. Upon durability, we send a fire-and-forget request to trigger the rollup for the request counter.\nGetCount:\n\nWe return the last rolled-up count as a quick point-read operation, accepting the trade-off of potentially delivering a slightly stale count. We also trigger a rollup during the read operation to advance the last-rollup-timestamp, enhancing the performance of subsequent aggregations. This process also self-remediates a stale count if any previous rollups had failed.\nWith this approach, the counts continually converge to their latest value. Now, let’s see how we scale this approach to millions of counters and thousands of concurrent operations using our Rollup Pipeline.\nRollup Pipeline:\nEach Counter-Rollup server operates a rollup pipeline to efficiently aggregate counts across millions of counters. This is where most of the complexity in Counter Abstraction comes in. In the following sections, we will share key details on how efficient aggregations are achieved.\nLight-Weight Roll-Up Event: As seen in our Write and Read paths above, every operation on a counter sends a light-weight event to the Rollup server:\nrollupEvent: {\n  \"namespace\": \"my_dataset\",\n  \"counter\": \"counter123\"\n}\nNote that this event does not include the increment. This is only an indication to the Rollup server that this counter has been accessed and now needs to be aggregated. Knowing exactly which specific counters need to be aggregated prevents scanning the entire event dataset for the purpose of aggregations.\n\nIn-Memory Rollup Queues: A given Rollup server instance runs a set of in-memory queues to receive rollup events and parallelize aggregations. In the first version of this service, we settled on using in-memory queues to reduce provisioning complexity, save on infrastructure costs, and make rebalancing the number of queues fairly straightforward. However, this comes with the trade-off of potentially missing rollup events in case of an instance crash. For more details, see the “Stale Counts” section in “Future Work.”\nMinimize Duplicate Effort: We use a fast non-cryptographic hash like XXHash to ensure that the same set of counters end up on the same queue. Further, we try to minimize the amount of duplicate aggregation work by having a separate rollup stack that chooses to run fewer beefier instances.\n\nAvailability and Race Conditions: Having a single Rollup server instance can minimize duplicate aggregation work but may create availability challenges for triggering rollups. If we choose to horizontally scale the Rollup servers, we allow threads to overwrite rollup values while avoiding any form of distributed locking mechanisms to maintain high availability and performance. This approach remains safe because aggregation occurs within an immutable window. Although the concept of now() may differ between threads, causing rollup values to sometimes fluctuate, the counts will eventually converge to an accurate value within each immutable aggregation window.\nRebalancing Queues: If we need to scale the number of queues, a simple Control Plane configuration update followed by a re-deploy is enough to rebalance the number of queues.\n      \"eventual_counter_config\": {             \n          \"queue_config\": {                    \n            \"num_queues\" : 8,  // change to 16 and re-deploy\n...\nHandling Deployments: During deployments, these queues shut down gracefully, draining all existing events first, while the new Rollup server instance starts up with potentially new queue configurations. There may be a brief period when both the old and new Rollup servers are active, but as mentioned before, this race condition is managed since aggregations occur within immutable windows.\nMinimize Rollup Effort: Receiving multiple events for the same counter doesn’t mean rolling it up multiple times. We drain these rollup events into a Set, ensuring a given counter is rolled up only once during a rollup window.\nEfficient Aggregation: Each rollup consumer processes a batch of counters simultaneously. Within each batch, it queries the underlying TimeSeries abstraction in parallel to aggregate events within specified time boundaries. The TimeSeries abstraction optimizes these range scans to achieve low millisecond latencies.\nDynamic Batching: The Rollup server dynamically adjusts the number of time partitions that need to be scanned based on cardinality of counters in order to prevent overwhelming the underlying store with many parallel read requests.\n\nAdaptive Back-Pressure: Each consumer waits for one batch to complete before issuing the rollups for the next batch. It adjusts the wait time between batches based on the performance of the previous batch. This approach provides back-pressure during rollups to prevent overwhelming the underlying TimeSeries store.\nHandling Convergence:\n\nIn order to prevent low-cardinality counters from lagging behind too much and subsequently scanning too many time partitions, they are kept in constant rollup circulation. For high-cardinality counters, continuously circulating them would consume excessive memory in our Rollup queues. This is where the last-write-timestamp mentioned previously plays a crucial role. The Rollup server inspects this timestamp to determine if a given counter needs to be re-queued, ensuring that we continue aggregating until it has fully caught up with the writes.\nNow, let’s see how we leverage this counter type to provide an up-to-date current count in near-realtime.\nExperimental: Accurate Global Counter\nWe are experimenting with a slightly modified version of the Eventually Consistent counter. Again, take the term ‘Accurate’ with a grain of salt. The key difference between this type of counter and its counterpart is that the delta, representing the counts since the last-rolled-up timestamp, is computed in real-time.\n\nAggregating this delta in real-time can impact the performance of this operation, depending on the number of events and partitions that need to be scanned to retrieve this delta. The same principle of rolling up in batches applies here to prevent scanning too many partitions in parallel.\n\nConversely, if the counters in this dataset are accessed frequently, the time gap for the delta remains narrow, making this approach of fetching current counts quite effective.\nNow, let’s see how all this complexity is managed by having a unified Control Plane configuration.\nControl Plane\nThe Data Gateway Platform Control Plane manages control settings for all abstractions and namespaces, including the Counter Abstraction. Below, is an example of a control plane configuration for a namespace that supports eventually consistent counters with low cardinality:\n\"persistence_configuration\": [\n  {\n    \"id\": \"CACHE\",                             // Counter cache config\n    \"scope\": \"dal=counter\",                                                   \n    \"physical_storage\": {\n      \"type\": \"EVCACHE\",                       // type of cache storage\n      \"cluster\": \"evcache_dgw_counter_tier1\"   // Shared EVCache cluster\n    }\n  },\n  {\n    \"id\": \"COUNTER_ROLLUP\",\n    \"scope\": \"dal=counter\",                    // Counter abstraction config\n    \"physical_storage\": {                     \n      \"type\": \"CASSANDRA\",                     // type of Rollup store\n      \"cluster\": \"cass_dgw_counter_uc1\",       // physical cluster name\n      \"dataset\": \"my_dataset_1\"                // namespace/dataset   \n    },\n    \"counter_cardinality\": \"LOW\",              // supported counter cardinality\n    \"config\": {\n      \"counter_type\": \"EVENTUAL\",              // Type of counter\n      \"eventual_counter_config\": {             // eventual counter type\n        \"internal_config\": {                  \n          \"queue_config\": {                    // adjust w.r.t cardinality\n            \"num_queues\" : 8,                  // Rollup queues per instance\n            \"coalesce_ms\": 10000,              // coalesce duration for rollups\n            \"capacity_bytes\": 16777216         // allocated memory per queue\n          },\n          \"rollup_batch_count\": 32             // parallelization factor\n        }\n      }\n    }\n  },\n  {\n    \"id\": \"EVENT_STORAGE\",\n    \"scope\": \"dal=ts\",                         // TimeSeries Event store\n    \"physical_storage\": {\n      \"type\": \"CASSANDRA\",                     // persistent store type\n      \"cluster\": \"cass_dgw_counter_uc1\",       // physical cluster name\n      \"dataset\": \"my_dataset_1\",               // keyspace name\n    },\n    \"config\": {                              \n      \"time_partition\": {                      // time-partitioning for events\n        \"buckets_per_id\": 4,                   // event buckets within\n        \"seconds_per_bucket\": \"600\",           // smaller width for LOW card\n        \"seconds_per_slice\": \"86400\",          // width of a time slice table\n      },\n      \"accept_limit\": \"5s\",                    // boundary for immutability\n    },\n    \"lifecycleConfigs\": {\n      \"lifecycleConfig\": [\n        {\n          \"type\": \"retention\",                 // Event retention\n          \"config\": {\n            \"close_after\": \"518400s\",\n            \"delete_after\": \"604800s\"          // 7 day count event retention\n          }\n        }\n      ]\n    }\n  }\n]\nUsing such a control plane configuration, we compose multiple abstraction layers using containers deployed on the same host, with each container fetching configuration specific to its scope.\n\nProvisioning\nAs with the TimeSeries abstraction, our automation uses a bunch of user inputs regarding their workload and cardinalities to arrive at the right set of infrastructure and related control plane configuration. You can learn more about this process in a talk given by one of our stunning colleagues, Joey Lynch : How Netflix optimally provisions infrastructure in the cloud.\nPerformance\nAt the time of writing this blog, this service was processing close to 75K count requests/second globally across the different API endpoints and datasets:\n\nwhile providing single-digit millisecond latencies for all its endpoints:\n\nFuture Work\nWhile our system is robust, we still have work to do in making it more reliable and enhancing its features. Some of that work includes:\n\nRegional Rollups: Cross-region replication issues can result in missed events from other regions. An alternate strategy involves establishing a rollup table for each region, and then tallying them in a global rollup table. A key challenge in this design would be effectively communicating the clearing of the counter across regions.\nError Detection and Stale Counts: Excessively stale counts can occur if rollup events are lost or if a rollups fails and isn’t retried. This isn’t an issue for frequently accessed counters, as they remain in rollup circulation. This issue is more pronounced for counters that aren’t accessed frequently. Typically, the initial read for such a counter will trigger a rollup, self-remediating the issue. However, for use cases that cannot accept potentially stale initial reads, we plan to implement improved error detection, rollup handoffs, and durable queues for resilient retries.\n\nConclusion\nDistributed counting remains a challenging problem in computer science. In this blog, we explored multiple approaches to implement and deploy a Counting service at scale. While there may be other methods for distributed counting, our goal has been to deliver blazing fast performance at low infrastructure costs while maintaining high availability and providing idempotency guarantees. Along the way, we make various trade-offs to meet the diverse counting requirements at Netflix. We hope you found this blog post insightful.\nStay tuned for Part 3 of Composite Abstractions at Netflix, where we’ll introduce our Graph Abstraction, a new service being built on top of the Key-Value Abstraction and the TimeSeries Abstraction to handle high-throughput, low-latency graphs.\nAcknowledgments\nSpecial thanks to our stunning colleagues who contributed to the Counter Abstraction’s success: Joey Lynch, Vinay Chella, Kaidan Fullerton, Tom DeVoe, Mengqing Wang\n\nNetflix’s Distributed Counter Abstraction was originally published in Netflix TechBlog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Netflix Technology Blog",
        "guid": "https://medium.com/p/8d0c45eb66b2",
        "categories": [
          "counter",
          "software-architecture",
          "system-design-interview",
          "distributed-systems",
          "scalability"
        ],
        "isoDate": "2024-11-12T20:45:23.000Z"
      }
    ]
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Alena Guzharina",
        "title": "Datalore On-Premises or Cloud: Which Suits You Best?",
        "link": "https://blog.jetbrains.com/datalore/2024/11/13/datalore-on-premises-or-cloud/",
        "pubDate": "Wed, 13 Nov 2024 17:03:40 +0000",
        "content:encodedSnippet": "In an era where data is the new currency, the ability to quickly gain actionable insights can be a game-changer for businesses and research institutions alike. Shortening the feedback loop between data scientists, analysts, and business intelligence teams can lead to more agile and responsive strategies, ultimately speeding up innovation and optimizing operations. \nJetBrains has always been at the forefront of this challenge, delivering best-in-class tools, including Datalore – the collaborative data science platform for analysts, business teams, and anyone else who needs quicker insights from their data.\nOne of the advantages of Datalore is that it offers two different operational models: On-Premises and Cloud. In this post, we will consider a few advantages of each model and cover the most typical challenges organizations might face when adding a new tool to their daily portfolio.\n\n\n\n\nWhen is Datalore On-Premises preferable?\nDatalore On-Premises is a self-managed installation in the environment of your choice – a private cloud, a public cloud, or even your own bare-metal server.\nWorking with internally hosted data\nMany companies host their databases fully on-premises instead of migrating them offsite. The reasons vary, from compliance factors to cost savings. However, this can lead to a problem. If the data is hosted locally, but the service that needs this data is located somewhere outside of the corporate perimeter, then the data becomes inaccessible to the service. \nThat said, on-premises deployments of data-consuming or processing services are the best solution in cases where you’re working with internally hosted data, as you have full control over the networking and security aspects. This allows you to customize your configuration without jeopardizing any security measures your organization has in place.\nExtended compliance requirements\nConsidering the nature of your data is important when choosing the right tool for processing it, as specific industries may impose additional requirements for data handling systems. \nFor example, if a US-based organization wants to process health-related data, compliance with HIPAA (the Health Insurance Portability and Accountability Act) is required, while compliance with PCI DSS is necessary in the global financial sector. These requirements are often eventually mandated by law or industry standards to apply to both the product and the organization as a whole.\nIn certain cases, as long as the data doesn’t leave the organizational perimeter, the product itself doesn’t have to undergo the whole process of vetting, testing, and certification by an independent third-party authority, like the Office for Civil Rights or the National Institute of Standards and Technology. \nIf you work in a context with extensive compliance standards, on-premises deployment is preferable. Otherwise, your choice of tool vendor becomes significantly limited, as both the tool and the vendor need to be in compliance and hold the necessary certifications, which are expensive and difficult to obtain.\nJetBrains is committed to maintaining the highest level of security when it comes to our data. An annual review by our external auditors recently confirmed our SOC 2 Type II compliance status.\nSpecific environment requirements\nAnother case where on-premises installations are particularly suitable is when there’s a high demand for customization, which is often something that SaaS platforms either can’t provide or can only provide in a limited capacity.\nHere’s a story from one Datalore customer who decided to go with an on-premises deployment:\n\nBy using Datalore On-Premises, we can customize the environment using Linux shell scripts built into the agent image used by Datalore. We can also install our own packages using pip, Poetry, dependency files, and more without any restrictions. This reduces the environment bootstrapping time, which is essential for us as a fast-paced team.\n      \n      Get Datalore On-Premises demo\n    \n\n\n\n\nWhen is Datalore Cloud preferable?\nDatalore Cloud is our software-as-a-service offering, managed and operated by JetBrains.\nNo-ops strategy\nDepending on your organizational goals and priorities, it may make more sense to completely avoid having anything on-premises, including servers and data storage. Instead, you can use managed services by various cloud providers, allowing you to focus on your daily tasks rather than worrying about infrastructure management.\nDatalore Cloud is particularly advantageous for organizations following a no-ops strategy because it eliminates the need for dedicated IT staff to manage hardware or software updates. Additionally, its extensive list of machines provides workload scaling capabilities, ensuring optimal performance as data workloads grow and reducing your organization’s operational burden.\nStarting your data journey\nWhen a team begins a project, they usually need to choose their infrastructure and tooling, a process that can be lengthy enough to have a visible impact on their timeline.\nDatalore Cloud speeds this process along because the only thing you need to start using it for data exploration is your browser. It also comes with a no-commitment 14-day free trial, allowing you to easily determine whether it meets your needs.\nOnce you’ve signed up for Datalore Cloud, you’re ready to explore your data immediately. With any of the paid Datalore Cloud tiers, you get 750 hours of computation time using 4 vCPUs and 16 GB of RAM (2 vCPUs and 4 GB of RAM for free tier users). We’ve found that these resources are sufficient in about 90% of cases, but if you need more, you can scale up with just a single click. Datalore Cloud has an extensive list of machine options that will suit even the most demanding users.\nFlexibility\nYour company’s tooling landscape can change rapidly, as your business requirements evolve together with your team. Because of this, it may not be wise to commit to the fixed, long-term seat capacity offered by Datalore On-Premises. \nFor Datalore Cloud, you have more flexibility in terms of seat capacity adjustments, with an option to scale your team’s capacity based on demand and your current requirements. Additionally, having the flexibility to choose between monthly and discounted annual commitments is a plus.\nAnother important aspect in choosing between the deployment models is the pricing structure. On-premises solutions typically carry an infrastructure setup burden, both on hardware and people, that increases its total cost of ownership.\nGiven the above, Datalore Cloud might be more beneficial if you have a demand for computation-intensive tasks but you either don’t have the expensive hardware required or don’t want to invest heavily into it. In that case, Datalore Cloud offers state-of-the-art environments prepared with all of the necessary resources at a fraction of what the hardware would cost.\n      \n      Try Datalore Cloud 14 days for free\n    \n\n\n\n\nI hope this article helped you get a better idea of which key factors to consider when deciding between on-premises and cloud computing for your business needs. \nIf you have any remaining questions, do not hesitate to schedule a call. We’d be happy to discuss your specific requirements in more detail.",
        "dc:creator": "Alena Guzharina",
        "content": "In an era where data is the new currency, the ability to quickly gain actionable insights can be a game-changer for businesses and research institutions alike. Shortening the feedback loop between data scientists, analysts, and business intelligence teams can lead to more agile and responsive strategies, ultimately speeding up innovation and optimizing operations.&#160; JetBrains has [&#8230;]",
        "contentSnippet": "In an era where data is the new currency, the ability to quickly gain actionable insights can be a game-changer for businesses and research institutions alike. Shortening the feedback loop between data scientists, analysts, and business intelligence teams can lead to more agile and responsive strategies, ultimately speeding up innovation and optimizing operations.  JetBrains has […]",
        "guid": "https://blog.jetbrains.com/?post_type=datalore&p=526021",
        "isoDate": "2024-11-13T17:03:40.000Z"
      },
      {
        "creator": "Maciej Gorywoda",
        "title": "IntelliJ Scala Plugin 2024.3 Is Out!",
        "link": "https://blog.jetbrains.com/scala/2024/11/13/intellij-scala-plugin-2024-3-is-out/",
        "pubDate": "Wed, 13 Nov 2024 15:40:41 +0000",
        "content:encodedSnippet": "Scala 3 support\nTransparent inline methods (experimental)\nTransparent inline methods in Scala 3 allow the compiler to reinterpret the method being inlined in the context of information known already at the compile time. Our support of this feature is still experimental and requires more work, but what we offer in this release already covers the most popular use cases. For example, when a transparent inline method serves as an entry point to a library that uses macro, you will now get much more information about the inferred types than before:\n\n\n\n\n\n\n\n\n\nFiguring out the result type of a transparent inline method call can often be quite complicated. To do this, we rely on the type information returned by the compiler, meaning that this feature is available only with Compiler-Based Highlighting. To enable the support for transparent inline methods in IntelliJ IDEA, go to Settings | Languages & Frameworks | Scala | Editor, ensure that the error highlighting mode is set to Compiler (as is the default for Scala 3), and check “Use types reported by the Scala compiler (experimental)”.\nWe are still working on many improvements to this feature. We encourage you to try it out and let us know your thoughts. Your feedback is very valuable to us.\nNamed tuples\nIntelliJ IDEA 2024.3 fully supports named tuples, a new experimental feature in Scala 3.5 that will become a standard feature in Scala 3.6. As the title suggests, named tuples allow you to name the components of a tuple so that they can be accessed with readable names.  On top of that, the compiler can infer the types of fields based on the assigned values.\nAs we move towards Scala 3.6, named tuples will become an integral part of the Scala language, and we are proud to say that the IntelliJ Scala Plugin has supported them from day one.\n\n\n\n\n\nOpaque type aliases\nAdditionally, IntelliJ IDEA is now better at recognizing opaque type aliases. We already recognized the opaque keyword, but in practice, IntelliJ IDEA has handled opaque type aliases just like standard (i.e., transparent) type aliases. Since the current release, they are treated as abstract types, meaning their underlying definitions are hidden from the outside code.\n\n\n\n\n\nScala CLI\nIntelliJ IDEA 2024.3 introduces improved support for Scala CLI projects. When you open a folder containing a project.scala file, the plugin automatically recognizes it as a Scala CLI project. Additionally, the new release provides a convenient way to create new Scala CLI projects through the New Project wizard. And, when you do this, you can add new Scala files to the project, just as you can for sbt-based projects. This makes it easier than ever to start developing Scala CLI applications in IntelliJ IDEA.\n\n\n\n\n\nMore improvements to Compiler-Based Highlighting\nOn top of the support for transparent inline methods, the new release comes with faster and more reliable Compiler-Based Highlighting.  We reduced the number of cases when multiple compilations were necessary, e.g., in situations where refactorings that affect multiple files result in many compilation requests. IntelliJ IDEA analyzes and batches these requests in the new release and then issues a single request with a broader compilation scope. This reduces CPU resource utilization and optimizes the compiler’s highlighting experience. We’ve also fixed some edge cases where duplicated parser errors are shown, both from the IDEA Scala parser and the compiler.\n\n\n\n\nNew project model for sbt projects (beta)\nWe’re introducing a new mode that better represents the structure of sbt projects in IntelliJ IDEA by organizing main and test sources into separate modules. The improved layout resolves several issues with compilation and highlighting and allows the use of distinct compiler options for main and test sources.\nThis feature is currently in “beta”. We strongly encourage you to try it out and share your feedback! Enable it via Settings | Build, Execution, Deployment | Build Tools | sbt and select “Create separate modules for production and test sources”.\n\n\n\n\nStay tuned for a blog post we plan to publish soon, describing this new feature in detail!\nThe debugger\nIn the debugger, we now support the new encoding of lazy vals introduced in Scala 3.3, and we reintroduced the “Initialize” button for lazy vals.\n\n\n\n\n\nAI Assistant\nCompleting just one line of code quite often is not enough, so since the new release, we have made multiline cloud-based code completion available for Scala. To enable it, go to Settings | Editor | General | Inline Completion, scroll down, and check “Enable cloud completion suggestions” if it’s not checked already. On the list below, check Scala.\n\n\n\n\nAs you can see in the following short video, if the AI Assistant decides it can reliably guess the following lines of code you want to write, it will propose the whole chunk. To do it, though, the AI Assistant requires a connection to the server – the local model can still only propose one-line completions – so be sure you can use it.\nThe AI Assistant comes with many other features that can help you in your work. You can read about them here.\n\n\n\n\n\nOther improvements\nWe improved the IDE performance and fixed certain bugs that led to the UI freezing. This happened sometimes during refactorings and actions, e.g., when you extended a Java interface in Scala and requested IntelliJ IDEA implement the new class members. In some other cases, when the action actually needs some time, a progress bar will be shown.\nAlso, if you open Run | Edit Configurations…, you will notice that the “Environment variables” field now accepts .env files. All Scala-related run configurations (Scalatest, MUnit, Specs2, uTest, Play Framework, SBT, and Scala REPL) can now read environment variables directly from an .env file – a popular format for storing environment-specific configuration variables as key-value pairs. This feature was implemented with help from the Scala community members. \n\n\n\n\n\nAs always, your feedback is very welcome. Please report any issues you find to YouTrack. If you have any questions, feel free to ask us on Discord.\nHappy developing!\nThe IntelliJ Scala Plugin team",
        "dc:creator": "Maciej Gorywoda",
        "content": "Scala 3 support Transparent inline methods (experimental) Transparent inline methods in Scala 3 allow the compiler to reinterpret the method being inlined in the context of information known already at the compile time. Our support of this feature is still experimental and requires more work, but what we offer in this release already covers the [&#8230;]",
        "contentSnippet": "Scala 3 support Transparent inline methods (experimental) Transparent inline methods in Scala 3 allow the compiler to reinterpret the method being inlined in the context of information known already at the compile time. Our support of this feature is still experimental and requires more work, but what we offer in this release already covers the […]",
        "guid": "https://blog.jetbrains.com/?post_type=scala&p=523404",
        "categories": [
          "news",
          "releases",
          "scala",
          "scala-programming",
          "intellij-idea"
        ],
        "isoDate": "2024-11-13T15:40:41.000Z"
      },
      {
        "creator": "Anna Ruban",
        "title": "Share Your Insights on Using Rider and Win a Prize!",
        "link": "https://blog.jetbrains.com/dotnet/2024/11/13/share-your-insights-on-using-rider-and-win-a-prize/",
        "pubDate": "Wed, 13 Nov 2024 15:38:40 +0000",
        "content:encodedSnippet": "We’re excited to invite you to participate in our research study, which will be an informal interview. In it, we’ll ask you about your workflows, your experiences with Rider, the challenges you typically encounter, and your aspirations, as this will help us tailor our solutions to better meet the needs of developers like you.\n\n\n\n\nThe interview will last no more than one hour and will be conducted in English. \nAs a token of our appreciation for your time and insights, you’ll receive your choice of either a USD 100 Amazon Gift Card or a one-year JetBrains All Products Pack subscription.\nReady to make an impact? Sign up for our study by clicking the button in this email and taking our short survey. If your profile matches our study criteria, we will follow up with an invitation via email.\nTake a survey\n                                                    \nKind regards,\nThe JetBrains team",
        "dc:creator": "Anna Ruban",
        "content": "We’re excited to invite you to participate in our research study, which will be an informal interview. In it, we’ll ask you about your workflows, your experiences with Rider, the challenges you typically encounter, and your aspirations, as this will help us tailor our solutions to better meet the needs of developers like you. The [&#8230;]",
        "contentSnippet": "We’re excited to invite you to participate in our research study, which will be an informal interview. In it, we’ll ask you about your workflows, your experiences with Rider, the challenges you typically encounter, and your aspirations, as this will help us tailor our solutions to better meet the needs of developers like you. The […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=525878",
        "categories": [
          "net-tools",
          "survey",
          "net",
          "rider"
        ],
        "isoDate": "2024-11-13T15:38:40.000Z"
      },
      {
        "creator": "Maria Kosukhina",
        "title": "IntelliJ IDEA 2024.3 Is Out!",
        "link": "https://blog.jetbrains.com/idea/2024/11/intellij-idea-2024-3/",
        "pubDate": "Wed, 13 Nov 2024 15:36:09 +0000",
        "content:encodedSnippet": "IntelliJ IDEA 2024.3, our final major release of the year, is here! This update brings a range of new features and enhancements across the IDE to improve your daily development workflows.\nYou can download this version from our website, update directly from within the IDE, use the free Toolbox App, or install it via snap packages for Ubuntu.\nDownload IntelliJ IDEA 2024.3\nKey highlights include a visual representation of your code’s logical structure in the Structure tool window, a smoother debugging experience for Kubernetes applications, and cluster-wide Kubernetes log access. This version also moves K2 mode out of Beta.\nWatch our video overview to see these improvements in action!\n\n\n\n\n\n\nThis blog post lists dozens of additional enhancements in version 2024.3. For a full list of new features with short demos, visit our What’s New page. \nHighlights \nThe Structure tool window now includes a Logical code structure alongside the familiar Physical structure. This allows you to view not only classes, methods, and fields but also the links and interactions between components in your project. \nWe’ve made debugging Kubernetes applications even easier. You can use the Add Tunnel for Remote Debug option to make your workstation a virtual part of the Kubernetes cluster, allowing you to swap in a pod and debug microservices locally with your preferred tools. \nIntelliJ IDEA now offers cluster-wide Kubernetes log access with streaming and pattern matching. This feature provides a centralized view of all events across pods, nodes, and services, helping you quickly identify issues without manually checking each log. \nK2 mode has officially moved out of Beta and is now Stable and ready for general use. \nAI Assistant\nIntelliJ IDEA 2024.3 introduces context-aware inline AI prompts, offering a seamless way to interact with AI Assistant directly in the editor. This feature supports Java, Kotlin, Scala, Groovy, JavaScript, TypeScript, Python, JSON, and YAML file formats.\nAI Assistant now offers simplified context management with an updated UI, making it easy to view, manage, and customize files, code selections, and project-wide instructions.\nYou can now select your preferred AI chat model, choosing from Google Gemini, OpenAI, or local models on your machine.\n\n\n\n\nLearn more about these updates in this blog post. All these features, along with the AI-powered enhancements mentioned below, are available with an active AI Assistant subscription.\nJava and Kotlin \nIn version 2024.3, IntelliJ IDEA’s data flow engine handles aliasing cases more accurately, leading to fewer false positives in inspections and a more reliable Java and Kotlin coding experience. \nIntelliJ IDEA’s code formatter features a new setting that allows you to retain blank lines between annotations and field declarations.\nWith K2 mode enabled, IntelliJ IDEA supports using non-local break and continue statements inside lambdas, as well as multi-dollar interpolation – experimental language features of Kotlin 2.1.\nScala\nVersion 2024.3 improves IntelliJ IDEA’s Scala 3 support, allowing you to use compiler-based type inference for transparent inline method calls and providing full support for named tuples. Additionally, IntelliJ IDEA is better at recognizing opaque types.\nThe IDE now recognizes Scala CLI projects when you open a folder with a project.scala file. You can also create new BSP-based Scala CLI projects via the New Project wizard and add Scala files, just like you do for sbt-based projects.\nWe’ve optimized compiler-based highlighting by reducing redundant compilation requests, resulting in better CPU efficiency, and we’ve resolved issues causing duplicated parser errors from both the parser and compiler.\nIntelliJ IDEA’s project model now represents sbt projects more accurately, separating production and test sources into distinct modules. This feature is currently in Beta.\nUser experience\nIn version 2024.3, spelling and grammar checks are accessible even while indexing is in progress. \nThe updated Run widget lets you launch multiple configurations simultaneously. Additionally, the widget displays controls for all running configurations, providing a clear overview of their statuses.\nWe’ve increased the default tab limit in the editor to 30, so you can now keep more tabs open before the IDE starts closing the ones used least recently. \nWe’ve optimized the placement of the Rename action in the context menu when called on elements in the editor and the Project tool window, making it more accessible at the top level. \nIntelliJ IDEA now automatically highlights all instances of any text you select within a file. \nWe’ve added dedicated icons for messages and i18n files to make them easier to identify.\nThe New popup for adding files to Java source roots now displays only the most relevant options, reducing clutter and streamlining your workflow.\nWe’ve enabled the floating toolbar for JSON, XML, YAML, and SQL files for easy access to context-based and AI-driven actions.\nTerminal\nThe new terminal (Beta) now offers faster command processing and completion, seamless session switching, and new customization options for prompt styles, session names, and environment variables for a smoother, more responsive experience. We’ve also updated the UI with a more compact design, reducing padding to maximize your screen real estate. \nVersion control systems \nIn version 2024.3, it is possible to commit specific changes directly from the editor. \nAI Assistant now helps generate accurate titles and descriptions for your pull and merge requests.\nThe Find in Files feature has been enhanced with a new Project Files Excluding Git-Ignored search option.\nYou can now control background checks during the commit process with a new Run advanced checks after a commit is done setting.\nThe Welcome screen now shows the branch name.\nDebugger\nThe HotSwap feature is now easier and more intuitive to use. When you edit code with an active debugger session, the IDE automatically detects the changes and prompts you to reload them via a convenient button in the editor. \nA new intention action allows you to set exception breakpoints from the editor without opening the Breakpoints dialog or browsing the stack trace in the console.\nYou can now measure execution time for multiple lines by using the Run to Cursor action, and each line’s execution time will be displayed directly in the editor’s gutter.\nIntelliJ IDEA 2024.3 now prints a merged stack trace, addressing the challenges of troubleshooting asynchronous code.\nBuild tools\nThe IDE now supports Maven’s split local repositories – a feature introduced in Maven 3.9 that allows you to separate local repositories according to your needs. \nWe’ve made parallel compilation the default in IntelliJ IDEA 2024.3. Now, you will see faster compilation times for all Maven-based projects compiled by the IDE, with optimized CPU and memory consumption. \nIntelliJ IDEA now automatically detects SSL issues during Maven syncs and builds, prompting you to accept untrusted certificates when necessary.\nThe first public EAP release of our new Bazel plugin for IntelliJ IDEA is now available. The plugin currently lets you open Bazel projects for Java and Kotlin, supports building, testing, running, and debugging Bazel targets, and offers Starlark syntax, completion, navigation, and debugging support.\n\n\n\n\nThe features and enhancements in version 2024.3 that are designed to facilitate work with frameworks, technologies, and databases, as well as the updates for profiling and web development, are accessible in IntelliJ IDEA Ultimate only.\nProfiler\nThe profiler now displays a heap memory usage graph above the thread lanes in the Timeline tab. \nFrameworks and technologies\nIntelliJ IDEA can now automatically generate derived query methods in Spring Data repositories, suggesting possible method names, providing the correct method signatures and return types, and updating repository code for you.\nVersion 2024.3 introduces the ability to access environment variables directly within the HTTP Client using the $env.ENV_VAR syntax.\nIn the HTTP Client, it is now possible to import and run requests – either all at once or specific ones by name – from one .http file to another.\nKtor 3.0, a toolkit for building server applications on the JVM with Kotlin, is out with new features and improved performance. Learn more.\nWe’ve greatly simplified the experience of debugging GraalVM native images with Docker containers, which means you can now build and debug native Java applications on any platform. \nDev Container builds now operate more smoothly on remote Docker engines, support for features is more consistent, and setting management for Dev Containers has been streamlined for improved efficiency.\nWe’ve added support for new Docker Compose attributes that give you better control over builds, resource management, service orchestration, and networking within Docker Compose.\nThis release introduces support for OpenTofu and greatly extends support for Terraform. \nWe continue to improve the reliability of projects that are hosted in the Windows Subsystem for Linux (WSL) and opened by developers from Windows in the IDE.\nKubernetes\nThe IDE now offers support for network policies, which are used to manage network traffic between pods in a cluster. \nWeb development\nWhen you use Find in Files in project directories, node_modules results are now excluded by default, reducing clutter from irrelevant files. \nWe’ve improved component navigation and renaming for Vue, Svelte, and Astro frameworks.\nIntelliJ IDEA provides greater support for Angular 19 projects.\nDatabase tools\nWhen you use AI Assistant for text-to-SQL tasks, the IDE now presents a handy in-editor diff, displaying both the original and AI-generated code for easy comparison.\nAI Assistant is now more helpful for handling SQL execution errors, offering two new actions – Explain with AI and Fix with AI.\nIntelliJ IDEA now supports fragment introspection and offers smart refresh for MySQL and MariaDB databases. \nA new inspection for an excessive number of JOIN clauses can be enabled from the IDE settings. \nTo make grid paging more noticeable in the data editor, we have moved the control for it from the toolbar to the bottom center of the data editor.\nOther \nLinux users should note that, as of version 2024.3, global menu support has been discontinued in IntelliJ IDEA.\n\n\n\n\nThese are the key improvements introduced in IntelliJ IDEA 2024.3. For a complete list of changes, please refer to the release notes.\nWe welcome your feedback on the new features and enhancements. Connect with us on X or leave a comment below. If you come across any bugs while using the IDE, please report them to our issue tracker.\nHappy developing!",
        "dc:creator": "Maria Kosukhina",
        "content": "IntelliJ IDEA 2024.3, our final major release of the year, is here! This update brings a range of new features and enhancements across the IDE to improve your daily development workflows. You can download this version from our website, update directly from within the IDE, use the free Toolbox App, or install it via snap [&#8230;]",
        "contentSnippet": "IntelliJ IDEA 2024.3, our final major release of the year, is here! This update brings a range of new features and enhancements across the IDE to improve your daily development workflows. You can download this version from our website, update directly from within the IDE, use the free Toolbox App, or install it via snap […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=523712",
        "categories": [
          "releases",
          "2024-3",
          "intellij-idea-2024-3"
        ],
        "isoDate": "2024-11-13T15:36:09.000Z"
      },
      {
        "creator": "Oleg Zinovyev",
        "title": "CLion 2024.3 Release Candidate Is Out",
        "link": "https://blog.jetbrains.com/clion/2024/11/2024-3-release-candidate/",
        "pubDate": "Wed, 13 Nov 2024 15:34:06 +0000",
        "content:encodedSnippet": "The next major CLion release is approaching, and the v2024.3 Release Candidate (RC) is already available. \n\n\n\n\nYou can download build 243.21565.198 from the link below, via the Toolbox App, or as a snap package if you’re using Ubuntu. You need an active subscription or a trial license to use the CLion 2024.3 RC.\nDOWNLOAD CLION 2024.3 RC\nWe’d like to thank all those who tested the IDE updates during the Early Access Program, gave us feedback, and helped polish the new features. Your contribution is invaluable to us.\nIf you’re unfamiliar with the key improvements coming in v2024.3, please read the previous blog post.\nSeveral bugs have been fixed in v2024.3 RC, including the following: \nAI Assistant now consistently responds to prompts.\nActive AI Assistant Pro licenses no longer falsely expire.\nUI freezes caused by deadlocks in InputContext no longer occur.\n\n\n\n\nRead the full release notes on YouTrack. Try this build and help us improve CLion by reporting any problems you find to our issue tracker. The final release is coming soon, so keep your eyes peeled!\nYour CLion team\nJetBrains\nThe Drive to Develop",
        "dc:creator": "Oleg Zinovyev",
        "content": "The next major CLion release is approaching, and the v2024.3 Release Candidate (RC) is already available. You can download build 243.21565.198 from the link below, via the Toolbox App, or as a snap package if you’re using Ubuntu. You need an active subscription or a trial license to use the CLion 2024.3 RC. DOWNLOAD CLION [&#8230;]",
        "contentSnippet": "The next major CLion release is approaching, and the v2024.3 Release Candidate (RC) is already available. You can download build 243.21565.198 from the link below, via the Toolbox App, or as a snap package if you’re using Ubuntu. You need an active subscription or a trial license to use the CLion 2024.3 RC. DOWNLOAD CLION […]",
        "guid": "https://blog.jetbrains.com/?post_type=clion&p=526231",
        "categories": [
          "eap",
          "news",
          "2024-3",
          "release-candidate"
        ],
        "isoDate": "2024-11-13T15:34:06.000Z"
      },
      {
        "creator": "Anna Zykova",
        "title": "RubyMine 2024.3: Rails 8 Support, Inline AI Prompts, Integration With RBS Collection, Ruby 3.4 Updates",
        "link": "https://blog.jetbrains.com/ruby/2024/11/rubymine-2024-3-rails-8-support/",
        "pubDate": "Wed, 13 Nov 2024 14:17:20 +0000",
        "content:encodedSnippet": "RubyMine 2024.3 is now available!\nThe latest version of JetBrains’ IDE for Ruby and Ruby on Rails comes with Rails 8 support, including Kamal 2 code completion, nilability annotations from schema.rb for type support, and Solid Queue and Solid Cache code insights. \nEnhanced by JetBrains AI Assistant, RubyMine now offers faster and more contextually aware cloud-based code completion, inline AI prompts, and more context about Rails applications for unit test generation. \nWith built-in integration with the RBS Collection, you can benefit from the type signatures included in the RBS Collection even if you don’t use RBS in your project. RubyMine 2024.3 also includes Ruby 3.4 updates, bundled spelling and grammar checks from Grazie, and much more!\nBelow is a brief overview of the most notable features. For a detailed description of this update, please visit our What’s New page.\nYou can get the new build from our website or via the free Toolbox App.\nRails 8 support\nKamal 2 support\nRails 8 provides support for deploying your applications with Kamal 2, and in RubyMine 2024.3, we’ve implemented code completion for Kamal 2 configurations.\n\n\n\n\nNilability annotations from schema.rb for type support\nRubyMine now recognizes the not-null type modifier for migration attributes and provides highlighting and warnings for incorrect nil assignments.\n\n\n\n\nCode insight for Solid Queue and Solid Cache\nIn RubyMine 2024.3, queue_schema.rb and cache_schema.rb files now feature specific icons and syntax highlighting.\n\n\n\n\nAI Assistant\nEnhanced cloud-based code completion\nRubyMine 2024.3 introduces faster and more contextually aware cloud-based code completion through the JetBrains AI Assistant plugin, featuring quality and speed improvements and adding support for multiline completion.\nPowered by the Mellum large language model (LLM), completion latency has been nearly cut down to one-tenth of what it was in previous versions, which means suggestions are almost instant. The acceptance rate for completion suggestions has approximately doubled, while the cancel rate has dropped to between half and a third of what it was in the previous version.\nPlease note that cloud-based code completion in AI Assistant is available only with an AI Pro subscription or an active free trial.\nInline AI prompts\nRubyMine 2024.3 introduces inline AI prompts, offering a seamless way to interact with AI Assistant directly in the editor. You can type requests in natural language, which AI Assistant instantly interprets and converts into code changes, marked with purple in the gutter for easy tracking. Inline AI prompts are context-aware, automatically including related files and symbols for more accurate code generation.\nThis feature is currently only available in *.rb files.\n\n\n\n\nImproved Rails context for unit tests\nRubyMine now provides AI Assistant with more context about Rails applications for better unit test generation.\nBuilt-in integration with the RBS Collection\nRubyMine now features built-in integration with the RBS Collection, a community-managed collection of RBS files for gems that do not include signatures.\nEven if you don’t use RBS in your project, you can still benefit from the type signatures included in the RBS Collection, with no additional effort required. RubyMine will automatically download and manage the type signatures for the project dependencies.\n\n\n\n\nAbility to use it as an alias for numbered parameters in blocks\nRubyMine now recognizes it as an alias for _1 in blocks without parameters, providing type support and conversion intentions for such usages.\nWe added a new error annotation that prevents you from using it in a block with regular numbered parameters.\n\n\n\n\nSupport for Ruby 3.4 “chilled” strings\nRubyMine now recognizes “chilled” strings, a new transitional state for string literals in Ruby 3.4. In projects without the frozen_string_literal pragma, strings are “chilled”. A “chilled” string will output a warning when modified; unlike a frozen string, it will not throw an error.\n\n\n\n\nError annotations for ambiguous anonymous arguments\nRubyMine now displays an error when you try to use anonymous block, rest, and keyword rest arguments in an ambiguous nested context.\n\n\n\n\nBundled spelling and grammar checks\nThe Grazie plugin is now available in RubyMine out of the box. It provides intelligent checks beyond simple spelling mistakes and typos. It understands grammar rules and can warn you about inappropriate style. Grazie checks are available in strings, HereDocs, comments, block comments, and RDoc files. \n\n\n\n\nYou can manage Grazie checks in Settings | Editor | Natural Languages | Grammar and Style | Scope.\n\n\n\n\nTo learn about the newest features as they come out, please follow RubyMine on X. \nWe invite you to share your thoughts in the comments below and to suggest and vote for new features in the issue tracker.\nHappy developing!\nThe RubyMine team",
        "dc:creator": "Anna Zykova",
        "content": "RubyMine 2024.3 is now available! The latest version of JetBrains’ IDE for Ruby and Ruby on Rails comes with Rails 8 support, including Kamal 2 code completion, nilability annotations from schema.rb for type support, and Solid Queue and Solid Cache code insights.&#160; Enhanced by JetBrains AI Assistant, RubyMine now offers faster and more contextually aware [&#8230;]",
        "contentSnippet": "RubyMine 2024.3 is now available! The latest version of JetBrains’ IDE for Ruby and Ruby on Rails comes with Rails 8 support, including Kamal 2 code completion, nilability annotations from schema.rb for type support, and Solid Queue and Solid Cache code insights.  Enhanced by JetBrains AI Assistant, RubyMine now offers faster and more contextually aware […]",
        "guid": "https://blog.jetbrains.com/?post_type=ruby&p=523767",
        "categories": [
          "releases",
          "rubymine",
          "release",
          "rubymine-2024-3"
        ],
        "isoDate": "2024-11-13T14:17:20.000Z"
      },
      {
        "creator": "Anna Maltseva",
        "title": "JetBrains AI Assistant 2024.3: Refine Your AI Experience With Model Selection, Enhanced Code Completion, and More",
        "link": "https://blog.jetbrains.com/ai/2024/11/jetbrains-ai-assistant-2024-3/",
        "pubDate": "Wed, 13 Nov 2024 14:13:38 +0000",
        "content:encodedSnippet": "JetBrains AI Assistant 2024.3 is here! A highlight of this release is the flexibility to choose your preferred chat model. Select between Google Gemini, OpenAI, or local models to tailor interactions for a more customized experience. \nThis update also brings advanced code completion for all major programming languages, improved context management, and the ability to generate inline prompts directly within the editor.\nMore control over your chat experience: Choose between Gemini, OpenAI, and local models \nYou can now select your preferred AI chat model, choosing from cloud model providers like Google Gemini and OpenAI, or connect to local models. This expanded selection allows you to customize the AI chat’s responses to your specific workflow, offering a more adaptable and personalized experience. \n\n\n\n\nGoogle’s Gemini models now available\nThe lineup of LLMs used by JetBrains AI now includes Gemini 1.5 Pro 002 and Flash 002. These models are designed to deliver advanced reasoning capabilities and optimized performance for a wide range of tasks. The Pro version excels in complex applications, while Flash is tailored for high-volume, low-latency scenarios. Now, AI Assistant users can leverage the power of Gemini models alongside our in-house Mellum and OpenAI options.\nLocal model support via Ollama\nIn addition to cloud-based models, you can now connect the AI chat to local models available through Ollama. This is particularly useful for users who need more control over their AI models, offering enhanced privacy, flexibility, and the ability to run models on local hardware. \nTo add an Ollama model to the chat you need to enable Ollama support in AI Assistant’s settings and configure the connection to your Ollama instance. \n\n\n\n\nImproved context management\nIn this update, we’ve made context handling in AI Assistant more transparent and intuitive. A revamped UI lets you view and manage every element included as context, providing full visibility and control. The open file and any selected code within it are now automatically added to the context, and you can easily add or remove files as needed, customizing the context to fit your workflow. Additionally, you can attach project-wide instructions to guide AI Assistant’s responses throughout your codebase. \n\nCloud code completion with broader language support\nJetBrains has released its own large language model (LLM) model, Mellum, specifically designed to enhance cloud-based code completion for developers. This new model, specialized for coding tasks, has expanded support for several new languages, including JavaScript, TypeScript, HTML, C#, C, C++, Go, PHP, and Ruby. Now, the code completion experience is unified across JetBrains IDEs, offering syntax highlighting for suggested code, the flexibility to accept suggestions token by token or line by line, and overall reduced latency.\n\nLocal code completion enhancements: Multi-line support for Python and contextual improvements\nLocal code completion has significantly improved, now offering multi-line suggestions for Python. Additionally, optimizations have been made across other programming languages. For Kotlin, retrieval-augmented generation (RAG) enables the model to pull information from multiple project files, ensuring the most relevant suggestions. The support for JavaScript, TypeScript, and CSS has also seen enhancements to their existing RAG functionality. Furthermore, local code completion has been introduced for HTML.\nThese improvements mean that suggestions appear faster across all languages, creating a more seamless coding experience. Best of all, local code completion is included for free in your IDE, allowing you to start utilizing these powerful features immediately.\nStreamlined in-editor experience with inline AI prompts\nThe new inline AI prompt feature in AI Assistant introduces a direct way to enter your prompts right in the editor. Just start typing your request in natural language and the AI Assistant will recognize it and generate a suggestion. Inline AI prompts are context-aware, automatically including related files and symbols for more accurate code generation. This feature supports Java, Kotlin, Scala, Groovy, JavaScript, TypeScript, Python, JSON, YAML, PHP, Ruby, and Go file formats, and is available to all AI Assistant users.\nWe also improved the visibility of changes applied. There is now a purple mark in the gutter next to lines changed by AI Assistant, so you can easily see what has been updated.\n\n\n\n\nMake multiple file-wide updates easily\nAI Assistant now offers file-wide code generation, enabling streamlined edits across an entire file. This functionality allows for modifications across multiple code sections, including adding necessary imports, updating references, and defining missing declarations.Currently available for Java and Kotlin, it is triggered by the Generate Code action when no specific selection is made in the editor, offering a seamless experience for broad, file-wide adjustments.\n\nGet instant answers about IDE features and settings in AI Chat\nSay goodbye to searching through settings or documentation! With the new /docs command, you can now access documentation-based answers directly in the AI chat. Simply ask AI Assistant about a feature, and it will provide interactive step-by-step guidance.\n\n\n\n\nAI-powered quick-fix for faster error resolution\nWhen a JetBrains IDE inspection flags a problem – whether it’s a syntax error, missing import, or something else – it suggests a quick-fix directly within the editor. With the latest update, Fix with AI takes this a step further. This new capability uses AI context awareness to suggest fixes that are more precise and applicable to your specific coding context, making it faster and easier to resolve coding problems without any manual input.\n\n\n\n\nExplore AI Assistant and share your feedback\nExplore these updates and let AI Assistant streamline your development workflow even further. As always, we look forward to hearing your feedback. You can also tell us about your experience via the Share your feedback link in the AI Assistant tool window or by submitting feature requests or bug reports in YouTrack.\nHappy developing!",
        "dc:creator": "Anna Maltseva",
        "content": "JetBrains AI Assistant 2024.3 is here! A highlight of this release is the flexibility to choose your preferred chat model. Select between Google Gemini, OpenAI, or local models to tailor interactions for a more customized experience.&#160; This update also brings advanced code completion for all major programming languages, improved context management, and the ability to [&#8230;]",
        "contentSnippet": "JetBrains AI Assistant 2024.3 is here! A highlight of this release is the flexibility to choose your preferred chat model. Select between Google Gemini, OpenAI, or local models to tailor interactions for a more customized experience.  This update also brings advanced code completion for all major programming languages, improved context management, and the ability to […]",
        "guid": "https://blog.jetbrains.com/?post_type=ai&p=525579",
        "categories": [
          "releases",
          "ai-assistant",
          "ai-assistant-release"
        ],
        "isoDate": "2024-11-13T14:13:38.000Z"
      },
      {
        "creator": "Sasha Ivanova",
        "title": "ReSharper 2024.3: Day-One C# 13 Support, Streamlined Code Cleanup, and Enhanced C++ Tools",
        "link": "https://blog.jetbrains.com/dotnet/2024/11/13/resharper-2024-3-release/",
        "pubDate": "Wed, 13 Nov 2024 14:06:04 +0000",
        "content:encodedSnippet": "We’re happy to announce the release of ReSharper 2024.3! This release marks an important step toward a new approach to our product updates. With version 2024.3, we’re working to align ReSharper’s releases with major .NET SDK updates, aiming to bring you the latest C# capabilities as early as possible. While we can’t guarantee this timing for every release, our goal is to reduce the wait for new features, so you may not always need to rely on our Early Access Program or wait for separate updates. \nDownload ReSharper 2024.3\n                                                    \nWithout further ado, let’s go over the enhancements this release brings! \n\n\n\n\n\n\n\n\nComplete C# 13 support\nReSharper 2024.3 delivers comprehensive support for C# 13, allowing you to take full advantage of the latest language features:\nParams Collections: The params keyword now supports various collection types, allowing for more efficient method signatures.\nPartial Properties: Easily organize property accessor implementations across multiple files.\nNew Lock Type: System.Threading.Lock offers a modern, efficient approach to thread synchronization.\nOverload Resolution Priority: Gain finer control over method overloads in complex scenarios with a new attribute.\nField Keyword: This preview feature allows direct access to backing fields in auto-properties, making property logic more straightforward.\n\n\n\n\nTo dive deeper into these C# 13 features, visit our dedicated blog post.\nCode styles and cleanup enhancements\nCode cleanup\nReSharper 2024.3 brings a major overhaul to code cleanup for faster, more robust performance. Now powered by the same engine as scoped quick-fixes, cleanup ensures thorough issue resolution, parallel preprocessing, and profile selection on a per-file basis.\nCode formatting\nNew formatting options offer more control over how your code is displayed:\nCustomize wrapping around the = operator.\nAdjust indentation for break statements within case labels.\nTreat case statements with break as simple statements for clearer code structure.\nNaming styles\nEnhanced naming conventions now support:\nSeparate options for local functions with async and Task-returning local functions without async.\nA new option for Task-returning methods in interfaces that don’t use the async modifier.\nSupport for multiline To-do comments\nReSharper now supports multiline To-do comments, letting you organize tasks over multiple lines to improve readability. Plus, the Peek To-do (Ctrl+Shift+click) action now uses an updated browser engine, making it easier to view linked external issues.\nTooltip colorization for a better user experience\nThis release includes colorized tooltips for about 600 error, warning, and informational messages, making it easier to understand code insights directly within the familiar editor color scheme.\nC++ support enhancements\nReSharper C++ 2024.3 includes several improvements to C++ support, particularly for Unreal Engine developers:\nOptimized performance for large solutions.\nThe new Move to Folder refactoring for organizing C++ files.\nEnhanced support for C++23, C23, and GNU language features.\nBetter Clang tooling interoperability.\nOptimized memory usage when working on large solutions with ReSharper C++ 2024.3\n\n\n\nExplore more on the  What’s New in ReSharper C++ 2024.3 page.\nDecompiler \nIL Code for Assembly Manifest\nThe IL Viewer now shows IL code for assembly manifests, including assembly info, custom attributes, referenced assemblies, and resources, offering deeper insights into assemblies.\nPrimary constructor support\nThe decompiler now displays primary constructors, helping you fully visualize object instantiation directly in the decompiled code.\nTell us what you think \nDownload ReSharper 2024.3 today and experience the enhancements aligned with the new .NET SDK release schedule. As always, you can find more information about the changes this release brings on the What’s New in ReSharper 2024.3 page, while all of the issues resolved in this release can be found on our issue tracker.\nYou may also be interested in checking out the blog posts about the latest updates to Rider and the .NET Tools. \nDownload ReSharper 2024.3\n                                                    \nWe look forward to hearing your thoughts  in the comments and via our usual feedback channels.",
        "dc:creator": "Sasha Ivanova",
        "content": "We’re happy to announce the release of ReSharper 2024.3! This release marks an important step toward a new approach to our product updates. With version 2024.3, we’re working to align ReSharper’s releases with major .NET SDK updates, aiming to bring you the latest C# capabilities as early as possible. While we can’t guarantee this timing [&#8230;]",
        "contentSnippet": "We’re happy to announce the release of ReSharper 2024.3! This release marks an important step toward a new approach to our product updates. With version 2024.3, we’re working to align ReSharper’s releases with major .NET SDK updates, aiming to bring you the latest C# capabilities as early as possible. While we can’t guarantee this timing […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=525944",
        "categories": [
          "net-tools",
          "news",
          "releases",
          "resharper",
          "release"
        ],
        "isoDate": "2024-11-13T14:06:04.000Z"
      },
      {
        "creator": "Sasha Ivanova",
        "title": "dotCover, dotMemory, dotPeek, and dotTrace 2024.3 Have Been Released!",
        "link": "https://blog.jetbrains.com/dotnet/2024/11/13/dotnet-tools-243-release/",
        "pubDate": "Wed, 13 Nov 2024 14:04:54 +0000",
        "content:encodedSnippet": "dotCover 2024.3, dotMemory 2024.3, dotPeek 2024.3, and dotTrace 2024.3 have been released and are ready for download! \nLet’s take a look at what’s new with these .NET tools.\n\n\n\n\ndotMemory 2024.3\nUnified UI across all operating systems for a consistent experience.\nReintroduced Creation Stack Trace and Back Traces views for memory issue identification.\nNew Icicle chart for dominator visualization and Sunburst chart for the Call Tree view on all OS.\nDownload dotMemory 2024.3\n                                                    \ndotTrace 2024.3\nUndo/Redo actions and filter history support for easier navigation through profiling sessions.\nDownload dotTrace 2024.3\n                                                    \ndotCover 2024.3\nStability improvements and bug fixes.\nDownload dotCover\n                                                    \ndotPeek 2024.3\nIL Viewer support for assembly manifests in the decompiler.\nSupport for primary constructors in decompiled code.\n\n\n\n    \nhttps://www.jetbrains.com/decompiler/download/\n                                                    \nIf you’re also interested in learning more about ReSharper 2024.3 or Rider 2024.3, please visit:\nWhat’s New in ReSharper.\nWhat’s New in Rider.",
        "dc:creator": "Sasha Ivanova",
        "content": "dotCover 2024.3, dotMemory 2024.3, dotPeek 2024.3, and dotTrace 2024.3 have been released and are ready for download!&#160; Let’s take a look at what’s new with these .NET tools. dotMemory 2024.3 dotTrace 2024.3 dotCover 2024.3 dotPeek 2024.3 If you’re also interested in learning more about ReSharper 2024.3 or Rider 2024.3, please visit:",
        "contentSnippet": "dotCover 2024.3, dotMemory 2024.3, dotPeek 2024.3, and dotTrace 2024.3 have been released and are ready for download!  Let’s take a look at what’s new with these .NET tools. dotMemory 2024.3 dotTrace 2024.3 dotCover 2024.3 dotPeek 2024.3 If you’re also interested in learning more about ReSharper 2024.3 or Rider 2024.3, please visit:",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=526025",
        "categories": [
          "net-tools",
          "dotcover",
          "dotmemory",
          "dotpeek",
          "dottrace",
          "news",
          "releases",
          "dotultimate"
        ],
        "isoDate": "2024-11-13T14:04:54.000Z"
      },
      {
        "creator": "Sasha Ivanova",
        "title": "Rider 2024.3: Same-Day Support for .NET 9 SDK and C# 13, Console Debugging for Game Dev, AI Enhancements, and More",
        "link": "https://blog.jetbrains.com/dotnet/2024/11/13/rider-2024-3-release/",
        "pubDate": "Wed, 13 Nov 2024 14:04:26 +0000",
        "content:encodedSnippet": "We’re thrilled to announce that Rider 2024.3 is here. This release marks a major change to our team’s development process. Starting with version 2024.3, we’re aiming to align updates to JetBrains Rider and ReSharper with major .NET SDK releases. While this isn’t a guaranteed timeline for every release, our goal is to minimize the wait time for new C# features, so you won’t have to rely on EAP builds to get the latest functionality.\nThis release brings comprehensive support for C# 13, advanced controllers for debugging multithreaded applications, the ability to run and debug Unreal Engine games on consoles, powerful new AI Assistant features, and a host of improvements for web and database development.\nDownload Rider 2024.3\n                                                    \n\n\n\n\nRead on to discover what’s new in Rider 2024.3!\nSame-day support for .NET 9 and C# 13\nAs mentioned above, Rider 2024.3 introduces same-day compatibility with the .NET 9 SDK, offering full support for the latest C# 13 features, such as params collections, partial properties, a new lock type, and the field keyword (preview feature).\nFor a deeper look at how Rider supports C# 13, check out our blog post on the new C# features.\nWindows Forms Designer for .NET projects \nThe Windows Forms Designer now supports projects targeting .NET 6.0 and newer, enabling you to create, view, and modify the UI of your Windows Forms applications. This experience brings nearly the same functionality as the classic Windows Forms Designer for .NET Framework.\n\n\n\n\nThere’s a small number of known issues associated with this feature (RIDER-119694, RIDER-119681, RIDER-118678), all of which can be expected to be resolved in our earliest updates to the 2024.3 release. \nTooltip colorization\nFor this release, we reviewed almost all C# error, warning, and informational messages and introduced text colorization wherever possible.\nApproximately 600 messages were upgraded with tooltips that are structured for easier reading and include the familiar colors from the editor for the included code elements.\n\n\n\n\nClick here for more information about UX/UI improvements in this release.\nMultiline TODO comments support\nRider 2024.3 now supports multiline TODO comments, allowing indented text on subsequent lines to be treated as part of the same TODO item. This enhancement makes it easier to group related notes and tasks together in your codebase. You can now add context to your TODOs across multiple lines, improving readability and organization.\n\n\n\n\nGame development enhancements\nRunning and Debugging Native Code on Consoles\nRider 2024.3 has reached a massive milestone by introducing support for running and debugging C++ on all major consoles! This includes games written with custom engines and Unreal Engine. Availability is strictly by request, and you must be part of the console’s official development program. Find out more here.\n\n\n\n\nIL2CPP debugging for Unity\nRider 2024.3 improves your debugging experience with IL2CPP builds, providing the same features you get with Mono. This means you will see Active Scene and this.gameObject nodes in the debugger, as well as Children and Components for GameObject instances. It also fixes issues with the Immediate window, the Collection view, and IL2CPP builds.\n\n\n\n\nImproved Godot support\nThis release also enhances the Godot debugging experience with support for the latest GDScript updates and improvements to Hot Reload, ensuring your development environment stays in sync with your creative process.\n\n\n\n\nAs always, you can find the full list of enhancements for game development on the What’s New in Rider 2024.3 page. \nAdvanced control over debugging \nRider 2024.3 introduces the ability to freeze and unfreeze individual threads, giving you precise control over multithreaded applications. With this feature, you can pause and resume threads independently, making it easier to isolate and resolve issues in complex debugging scenarios.\n\n\n\n\nExpanded AI Assistant functionality\nAI Assistant in Rider 2024.3 brings new capabilities to the development process. Inline AI prompts allow you to make quick code adjustments using natural language, while customizable chat models from Google Gemini, OpenAI, and local providers give you more control over your AI interactions, enabling a tailored experience that adapts to your workflow.\nRemote development moves out of Beta\nAfter extensive refinement, Rider’s remote development functionality is now officially out of Beta. Enjoy a near-local experience while working on remote codebases, with smooth support for code editing, debugging, version control, and unit testing. Discover what remote dev in Rider 2024.3 has to offer from this dedicated blog post.\n\n\n\n\nFor detailed setup instructions, visit our remote development documentation.\nWeb development improvements\nRider 2024.3 enhances the web development experience with smarter search in Find in Files, excluding node_modules by default for cleaner results. Improved component navigation and renaming for Vue, Svelte, and Astro components make maintaining code consistency across projects easier.\nLearn more here. \nWorking with databases\nJetBrains AI Assistant now supports SQL query troubleshooting directly in the editor. With AI-generated fixes for execution errors, your database workflow becomes even more efficient.\nLearn more here. \nTell us what you think\nAs always, you will find the full overview of enhancements included in the release on the What’s New in Rider 2024.3 page of our website and the full list of resolved issues on our issue tracker.\nYou may also be interested in checking out the blog posts about the latest updates to ReSharper and .NET Tools. \nDownload Rider 2024.3\n                                                    \nWe look forward to hearing your feedback as you explore the new features. Please share your thoughts in the comments or via the usual feedback channels. \nHappy coding!",
        "dc:creator": "Sasha Ivanova",
        "content": "We’re thrilled to announce that Rider 2024.3 is here. This release marks a major change to our team’s development process. Starting with version 2024.3, we’re aiming to align updates to JetBrains Rider and ReSharper with major .NET SDK releases. While this isn’t a guaranteed timeline for every release, our goal is to minimize the wait [&#8230;]",
        "contentSnippet": "We’re thrilled to announce that Rider 2024.3 is here. This release marks a major change to our team’s development process. Starting with version 2024.3, we’re aiming to align updates to JetBrains Rider and ReSharper with major .NET SDK releases. While this isn’t a guaranteed timeline for every release, our goal is to minimize the wait […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=525918",
        "categories": [
          "net-tools",
          "news",
          "releases",
          "rider",
          "net-9",
          "c-13",
          "gamedev",
          "game-development",
          "remote-development",
          "rider-2024-3"
        ],
        "isoDate": "2024-11-13T14:04:26.000Z"
      },
      {
        "creator": "Sasha Ivanova",
        "title": "Remote Development in Rider 2024.3",
        "link": "https://blog.jetbrains.com/dotnet/2024/11/13/remote-development-in-rider-2024-3/",
        "pubDate": "Wed, 13 Nov 2024 07:46:57 +0000",
        "content:encodedSnippet": "Remote development has long held promise for developers seeking flexibility. However, only in recent years has it become an indispensable part of modern development workflows that prioritize collaboration and scalability. Nowadays, developer teams often need to work from different locations while leveraging high-performance, shared environments that feel as reliable as their local setups.\nWith JetBrains Rider 2024.3, the remote development functionality completes its Beta phase, delivering a polished and consistent experience. This release brings infrastructure designed to make remote work feel familiar and dependable, so you can code with confidence wherever you are. \nIf you’re new to Rider’s remote capabilities or curious about its evolution, we recommend reading our blog post from March 2023 for a deep dive into its journey. For detailed guidance on getting started with the setup, visit Rider’s documentation.\nDownload Rider 2024.3\n                                                    \nOne important note: Linux is currently the only supported OS for remote hosting. With that in mind, let’s explore the workflows that remote development supports and see how closely they match the experience of using Rider on your local machine.\nEditing\nIn this release, we focused on optimizing the editor to reduce latency and ensure real-time responsiveness, making remote typing feel as natural as it would on a local setup. This improvement allows for a smooth, uninterrupted flow as you write and refine code.\nHot Reload\nWith Hot Reload, your code changes apply instantly, letting you test modifications immediately without restarting your application – a convenience that’s particularly important when working in remote environments. \nTo ensure that the changes applied to the application running on the remote machine are accessible in your local browser, Rider will forward the relevant open port from the remote machine to your local environment via the existing SSH connection.\nThe port forwarding process is semi-automatic: a dialog will pop up, asking if you’d like to open the URL. By clicking Open, you agree to forward the port, making the remote application accessible as if it were running locally. Additionally, you can check the Do not ask for ‘localhost’ box to streamline future access, allowing Rider to forward similar URLs without prompting.\n\n\n\n\nDebugging\nRider’s remote debugging aims to bring the same intuitive, snappy experience you’re used to locally. With the ability to set breakpoints, inspect variables, and step through code, debugging remotely feels smooth and familiar.\nProject and NuGet management\nRider’s remote development functionality offers you rich control over creating and managing projects based on the SDKs installed remotely. Such a setup means there’s no need to sync files back to your local machine, which is not only more efficient, but also enhances security by keeping all project data in the remote environment. \nNuGet package management via remote development is just as seamless. Rider 2024.3 lets you add, update, and manage dependencies directly on the remote machine, ensuring that package management feels familiar and intuitive, but without any need for local synchronization.\n\nUnit testing\nRun and evaluate unit tests on your remote project with ease. The test runner delivers immediate feedback, allowing you to make quick adjustments and ensure code quality – no matter where you’re working from.\n\nVersion control\nIntegrated version control makes it easy to keep code synced across environments. Directly manage commits, pulls, and pushes within the IDE with version control that is as streamlined and efficient as it is on local setups.\nDiagnostics widget for the main toolbar\nOnce you’ve established a remote connection, you’ll see that the main toolbar now features a new widget, which you can access by clicking on the remote connection address. \n\n\n\n\nThe widget provides a quick but comprehensive view of the status of your remote development environment. The Backend Status Details offers metrics such as CPU load, memory usage, disk space usage, and latency – all essential for monitoring resource consumption on the remote machine.\nIn addition to performance data, the widget also includes tabs with controls for managing the connection, allowing you to view network port configurations, output logs, and settings specific to the remote environment. \nWith Rider 2024.3, remote development workflows are closer than ever to a local experience. From editing to testing, the goal has been to make each workflow familiar and free of lag and latency.\nWe’d love to hear how remote development fits into your workflow, so please share your feedback. Your insights will help us continue shaping and refining the experience to serve your needs better.",
        "dc:creator": "Sasha Ivanova",
        "content": "Remote development has long held promise for developers seeking flexibility. However, only in recent years has it become an indispensable part of modern development workflows that prioritize collaboration and scalability. Nowadays, developer teams often need to work from different locations while leveraging high-performance, shared environments that feel as reliable as their local setups. With JetBrains [&#8230;]",
        "contentSnippet": "Remote development has long held promise for developers seeking flexibility. However, only in recent years has it become an indispensable part of modern development workflows that prioritize collaboration and scalability. Nowadays, developer teams often need to work from different locations while leveraging high-performance, shared environments that feel as reliable as their local setups. With JetBrains […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=524209",
        "categories": [
          "remote-development",
          "rider"
        ],
        "isoDate": "2024-11-13T07:46:57.000Z"
      },
      {
        "creator": "David Watson",
        "title": "WebStorm 2024.3: Built-In Database Tools and SQL Support, Better AI-driven Code Completion, and More",
        "link": "https://blog.jetbrains.com/webstorm/2024/11/webstorm-2024-3/",
        "pubDate": "Tue, 12 Nov 2024 16:05:08 +0000",
        "content:encodedSnippet": "Our third major release of 2024 is here! In this version, you’ll find built-in database tools and SQL support, various quality enhancements, better code completion with AI Assistant, and a whole lot more.\n\nDOWNLOAD WEBSTORM 2024.3\nIf you only have a few minutes to explore the highlights of WebStorm 2024.3, check out our quick review video above for the top highlights. If you want to dive deeper into what you can expect in the release, just carry on reading!\nThe new features and improvements in v2024.3 include:\nKey Highlights: Improved framework component navigation and renaming, built-in support for database tools and SQL, better code completion with AI Assistant.\nFrameworks and Technologies: Color preview for Tailwind CSS classes, improvements for Angular, and more.\nUser Experience: Optimized placement for the Rename action, cleaner search results for directories, highlighting for occurrences of selected text, and more.\nIntegrated Developer Tools: Option to disable background pre-commit checks, new Docker Compose build attributes, and more.\nKey Highlights\nImproved framework component navigation and renaming\nWebStorm 2024.3 now supports the Show component usages action for Vue, Svelte, and Astro and detects component usages both in imports and templates. You can also use this functionality by invoking the Find Usages action on the component file in the Project view:\n\n\n\n\nThe Rename refactoring has also been enhanced to include component usages renaming. When renaming a component file or explicitly defined name, the associated usages in templates will also be updated! This behavior can be disabled by toggling the Search for component usages option during the renaming process and in the Find dialog.\nBuilt-in support for database tools and SQL\nThe Database Tools and SQL plugin, which was previously only available via a separate paid subscription, is now bundled with WebStorm at no extra cost. You can query, create, and manage databases directly in the IDE. This extends WebStorm’s capabilities for backend and full-stack development. It also makes switching between JetBrains IDEs easier, as most of them include this functionality.\n\n\n\n\nBetter code completion with AI Assistant \nWebStorm 2024.3 has significantly improved AI-driven code completion for JavaScript and TypeScript. The new approach combines fast, local full-line completion with powerful cloud-based suggestions powered by JetBrains’ in-house LLMs. This hybrid approach enhances speed, accuracy, and usability while reducing the frequency of lengthy and irrelevant suggestions.\nHere are some of the key improvements:\nHighlighting is now applied to the suggested code, which previously was just plain gray text.\nPartial acceptance allows you to apply suggestions granularly, giving you more control over changes to your code:\n\nAccept suggestions word by word – ⌥ → / Alt+Right.\nAccept suggestions line by line – ⌘ → / Ctrl+Right.\nAs before, you can explicitly call completion with ⇧ ⌥ / / Shift+Alt.\nContext collection has been enhanced using RAG strategies.\nCompletion suggestions are now provided in more locations, and are now triggered during typing, not only on Enter keystrokes. Support for AI-based code completion has also been extended to HTML and CSS (including .css, .less, .scss, .sass, .pcss). Please refer to this blog post for more insights.\n\n\n\nFrameworks and Technologies\nColor preview for Tailwind CSS classes \nIn WebStorm 2024.3, color previews for Tailwind CSS classes are now shown inline in the editor. We’ve added support for the textDocument/documentColor method of the Language Server Protocol (LSP), so all LSP-based plugins now support this functionality out of the box.\n\n\n\nImprovements for Angular \nFor projects with Angular 19, WebStorm now defaults to standalone mode for components, directives, and pipes. Quick-fixes have been added to help convert between standalone and non-standalone components. Unused standalone imports can be automatically removed during code reformatting or via a new inspection. Support for the @let syntax has also been improved.\n\n\nCorrect handling of .prettierignore in subfolders \nWebStorm 2024.3 now properly handles .prettierignore files in subfolders with a package.json, ensuring ignored files aren’t formatted. A new option also lets you specify custom ignore files in Settings | Languages & Frameworks | JavaScript | Prettier.\n\n\n\nBundled Vue Language Server \nThe Vue Language Server is now bundled with WebStorm to enhance reliability and prevent issues with loading on WSL. We may do the same for Svelte, Astro, and other technologies in the future. \n\n\n\nImprovements for Svelte\nWebStorm 2024.3 provides support for the <script module> attribute, ensuring symbols from these blocks are resolved correctly. Additionally, there’s a new checkbox to disable SvelteKit a11y warnings, giving you more control over accessibility warnings. \n\n\n\nSupport for CSS exported via package.json \nWebStorm 2024.3 includes support for the exports field in package.json for CSS, Sass, SCSS, and Less. If styles are exported via package.json, WebStorm will no longer show warnings about unresolved variables.\nBun debugging support for Windows \nBasic Bun debugging, previously available only on macOS and Linux, is now supported on Windows. You can set breakpoints, step through code, inspect variables, and evaluate expressions within WebStorm.\nUser Experience\nOptimized placement for the Rename action\nWe’ve optimized the placement of the Rename action in the context menu when it’s called on elements in the editor and the Project tool window. The action is now at the top level, making it easier to quickly rename files, variables, and other elements.\n\n\n\nCleaner search results for directories\nWebStorm now excludes node_modules results by default when using Find in Files in project directories, reducing clutter from irrelevant files. You can restore the previous behavior by enabling the Search in library files when “Directory” is selected in Find in Files option under Settings | Advanced Settings.\n\n\n\nHighlight occurrences of selected text\nBy default, WebStorm will now automatically highlight all instances of the text you select within a file. This makes it easier to track where your selected text appears throughout your code. You can customize the feature in Settings | Editor | General | Appearance.\n\n\n\n.idea directory displayed by default\nPreviously, the .idea folder – a place where WebStorm stores internal configuration settings – was hidden by default. This made it harder for some users to commit project-wide configurations. To address this, we’ve made it visible in the Project tool window.\n\n\n\nBetter recognition of generated files\nWebStorm 2024.3 will automatically exclude unnecessary files in the dist folder from indexing to optimize CPU usage and decrease indexing time.\n\n\n\nBetter support for projects in WSL\nWe’ve improved the reliability of projects that are hosted on WSL and opened from Windows in WebStorm. In particular, support for symlinks has been added, and interaction with WSL has been switched to Hyper-V sockets, which has improved the performance of IDE interaction with WSL.\nNew features available during indexing\nWhen you open or update your project, WebStorm indexes it, making some features temporarily inaccessible. We’re working to improve this by allowing more functionality during indexing. With this update, Search Everywhere (Shift+Shift) now works for already indexed parts of the project, along with spelling and grammar checks.\nIntegrated Developer Tools\nOption to disable background pre-commit checks\nYou can now manage background checks during the commit process with a new option under Settings | Version Control | Commit | Advanced Commit Checks | Run advanced checks after a commit is done. This setting lets you decide if tests and inspections should run after making a commit. If you want to wait for these checks to complete, simply disable this option.\n\n\n\nNew Docker Compose build attributes\nWebStorm 2024.3 adds support for new Docker Compose attributes that give you better control over builds, resource management, service orchestration, and networking within Docker Compose, making development more efficient and flexible.\nImproved compatibility for Dev Container templates\nWe’ve improved the compatibility of Dev Container templates, which weren’t originally designed to operate in remote environments. Previously, Dev Container templates often included configurations that assumed local execution, leading to issues when running containers on remote Docker instances. Now, WebStorm ensures that templates that are not optimized for remote use still function correctly.\nThere are lots of new improvements and enhancements to try out in this latest WebStorm release. If you’d like a list of everything included in WebStorm 2024.3, please check out the release notes. We hope you enjoy this release. As always, please share your feedback with us and report any issues you find to our issue tracker.\nThe WebStorm team",
        "dc:creator": "David Watson",
        "content": "Our third major release of 2024 is here! In this version, you’ll find built-in database tools and SQL support, various quality enhancements, better code completion with AI Assistant, and a whole lot more. DOWNLOAD WEBSTORM 2024.3 If you only have a few minutes to explore the highlights of WebStorm 2024.3, check out our quick review [&#8230;]",
        "contentSnippet": "Our third major release of 2024 is here! In this version, you’ll find built-in database tools and SQL support, various quality enhancements, better code completion with AI Assistant, and a whole lot more. DOWNLOAD WEBSTORM 2024.3 If you only have a few minutes to explore the highlights of WebStorm 2024.3, check out our quick review […]",
        "guid": "https://blog.jetbrains.com/?post_type=webstorm&p=524492",
        "categories": [
          "news",
          "releases",
          "webstorm-2024-3"
        ],
        "isoDate": "2024-11-12T16:05:08.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": [
      {
        "creator": "Pei Xiong",
        "title": "Airbnb’s AI-powered photo tour using Vision Transformer",
        "link": "https://medium.com/airbnb-engineering/airbnbs-ai-powered-photo-tour-using-vision-transformer-e470535f76d4?source=rss----53c7c27702d5---4",
        "pubDate": "Wed, 13 Nov 2024 17:39:08 GMT",
        "content:encodedSnippet": "Boosting computer vision accuracy and performance at Airbnb\n\nBy: Pei Xiong, Aaron Yin, Jian Zhang, Lifan Yang, Lu Zhang, Dean Chen\nIntroduction\nIn recent years, the integration of artificial intelligence with travel platforms has transformed how people search for and book accommodations. As a leading global marketplace for unique travel experiences and accommodations, Airbnb constantly strives to enhance the guest experience by providing informative content about the variety of homes shared by our hosts. One of the ways we help guests better understand what a listing offers before they book is through our AI-powered photo tour feature.\nThe AI-powered photo tour in the Listings tab, which helps hosts better organize their listing photos, leverages vision transformers’ fine-tuned feature to assess a diverse set of listing images and accurately identify and classify photos based into specific rooms and spaces. In this blog post, we will dive into the inner workings of the photo tour including model selection, pretraining, fine-tuning techniques, and the trade-offs between computational costs and scalability. We will also specifically discuss how we enhanced model accuracy despite having limited training data.\nFigure 1: Photo Tour product powered by ML\nMethodology\nRoom Classification\nRoom-type classification is the first aspect of the photo tour, The goal of room classification is to accurately categorize images into 16 different room types designed in the Airbnb product such as ‘Bedroom’, ‘Full bathroom’, ‘Half bathroom’, ‘Living room’, and ‘Kitchen’, providing users with a comprehensive understanding of the available spaces. The challenge lies in the diversity of room layouts, lighting conditions, and the need for models that can generalize well across various environments.\nWe conducted experiments using several state-of-the-art models, including Vision Transformer (ViT) variants — ViT-base, ViT-large and different resolutions. Additionally, we explored the performance of ConvNext2, a recently proposed convolutional neural network with comparable performance to ViT, and MaxVit, a variant combining the strengths of both Vision Transformers and CNNs. At the beginning of this project, we tested these approaches on an image classification task with Airbnb’s host-provided data, and found that ViT outperforms the other approaches. Thus we chose ViT in our following studies.\nImage Similarity\nAnother key component of photo tour is image clustering, which groups the images of the same room into a cluster. A prerequisite of that is the ability to measure the similarity between two images, which indicates the probability that the two images belong to the same room. This is a supervised classification problem, with the input being two images, and the output being a binary label of 0 or 1. As shown in Figure 2, We employed a Siamese network that simultaneously processes two images, by applying the same image embedding model to each image, and subsequently computing the cosine similarity of the resulting embeddings.\nFigure 2: An illustration of Siamese network for image similarity\nAccuracy Improvement\nOur analysis found that the volume of training data is key to higher prediction accuracy. Doubling the training data volume typically leads to a reduction of error rate of ≈5% on average, with the effect being more significant in the earlier stages.\nFigure 3: correlation between data volume and accuracy\nUnfortunately, it is very expensive to acquire high-quality training data as it requires human labeling. Therefore, we needed to find other ways to improve model accuracy with a limited amount of training data. We followed these steps to improve model accuracy:\nStep 1 — Pre-training: We started from a pre-trained model on ImageNet. We took that model and trained it with a large amount of host-provided data, which has lower accuracy and only covers some of our class labels. This provided a baseline model for transfer learning in the following steps.\nStep 2 — Multi-task training: We fine-tuned the model from the previous step using both higher-accuracy training data for the target task (e.g., room-type classification), and an additional type of training data that has been labeled for another related task (e.g., object detection). This provided additional training data and created multiple different models for future steps.\nStep 3 — Ensemble learning: We created an ensemble from multiple models in Step 2, which was achieved through training with different auxiliary tasks, and by using different versions of ViTs (e.g., ViT-base vs. ViT-large, and/or those consuming images of size 224 vs 384). This approach allowed us to generate a diverse set of models, from which we selected the best performers to construct the final ensemble model.\nStep 4 — Distillation: Although the ensemble model has higher accuracy than any individual model, it requires more computational resources and thus increases the latency and cost of our product. We trained a distilled model to imitate the behavior of the ensemble model, which has similar accuracy but reduced computational cost by several folds.\nPre-training and Traditional Fine-tuning\nOur pretraining process involved harnessing the vast repository of Airbnb listing photos, comprising of millions of images, to train a Vision Transformer (ViT) model. While leveraging the Airbnb listing photos for pretraining provides a substantial advantage, there are also limitations in the dataset. There were inaccuracies or mislabels in the human-labeled dataset and they materially impacted the model’s ability to discern patterns effectively. Another notable limitation is the coverage of only four out of the total 16 room classifications within the pre-training dataset.\nTherefore, expanding the coverage of fine-tuning to include additional classes is imperative. We developed a detailed and updated guideline and generated a human-label dataset with the entirety of 16 room classifications. Iterative fine-tuning processes gradually encompassed the entirety of the 16 room types, contributing to a more comprehensive and versatile model.\nMulti-task Learning\nAcquiring high-quality human-labeled training data is a challenge due to the costly and time-consuming labeling process. Despite this, we had already accumulated a large repository of labeled data across other various tasks, including room-type classification, image quality prediction, same-room classification, category classification, and object detection. By fully utilizing this extensive and diversely labeled dataset, we significantly improved the prediction accuracy in our tasks. To achieve this, we implemented multi-task training that incorporates additional label classes from existing tasks, as demonstrated in Figure 4. Each learner is a vision transformer, and in addition to predicting a single set of labels, we allowed different learners to learn other label types, such as amenities and ImageNet21k labels, which further boosts overall performance as shown in Table 1.\nFigure 4: Multi-task learning illustration\nEnsemble Learning\nEnsemble learning is a powerful technique in machine learning that leverages diverse models with similar accuracies to achieve better accuracy and generalization.\nWe applied ensemble learning on diverse models with different architectures, model sizes, and auxiliary tasks such as amenities and ImageNet21k class predictions. Upon aggregating the predictions of the individual models, we observed a notable increase in the overall accuracy compared to any single model. The observed improvement is credited to the ensemble’s capability to address and reduce both misclassifications and inaccuracies of individual models, leading to more accurate predictions, despite the limited human-labeled training data.\n\nKnowledge Distillation\nWhile ensemble learning offers substantial gains in accuracy, it requires heightened computational resources as multiple large models are involved in each inference task. To prioritize model efficiency without compromising performance, we turned to knowledge distillation, a technique centered around transferring knowledge from a sophisticated ensemble of models to a more compact single model.\nOur distillation process transfers the knowledge encoded in both hard targets and the soft targets of a complex ensemble to a smaller and simpler model. Hard targets are ground-truth labels while the soft targets are the ensemble’s probabilistic predictions, enabling the smaller model to capture the nuanced decision boundaries learned by the ensemble. The overall training objective is a weighted combination of the two losses:\n\nwhere the first loss is the cross-entropy loss based on hard targets, the second loss is Kullback-Leibler divergence to evaluate the cross entropy between soft targets from the ensemble and the predictions of the student model, and the distillation coefficient determines the weight assigned to the distillation loss.\nRemarkably, our distilled model achieved performance metrics on par with the ensemble models, despite its significantly reduced inference time and resource requirements. This outcome demonstrates the efficacy of knowledge distillation in preserving the ensemble’s collective intelligence within a more streamlined model.\n\nGolden Evaluation\nAs part of the preparations for the launch of our end-to-end Photo Tour, we employed a rigorous evaluation process called “Golden Evaluation”, which mimics the actual user experience by calculating the minimum number of changes required to make the Photo Tour generated by our model identical to the human-labeled ground truth (i.e., the Golden Evaluation). In contrast to training data that is evenly distributed across classes, the golden evaluation processes at the Airbnb listing level, aiming to replicate the user’s perspective. We sampled listings, each containing an average of 25–30 photos, and defined accuracy as the minimum number of corrections required to make assignments consistent with human labels. These corrections refer to changes in room assignment, where a photo’s initial room prediction is modified to match the consensus room label provided by multiple human labels. For example, if a photo of bedroom 1 is falsely assigned to the living room, one correction is required to move it from the living room to bedroom 1.\n\nThere are photos that cannot be properly assigned to a named space. We classified miscellaneous photos, including close-up shots, images containing humans or animals, as well as nearby photos of shopping areas, restaurants, and parks, into the category labeled as “Others”. Furthermore, if a photo is of an empty space in a room such that we cannot judge its room location, we are allowed to designate some photos as “Unassigned”, which do not count in the accuracy calculation. This scenario occurs infrequently (as shown in Table 3), and is primarily used to let users decide in the most ambiguous cases. This evaluation served as the final launch criteria. Ultimately, we successfully reduced the error rate to 5.28%, passing the internal evaluation standard at Airbnb and Photo Tour was launched as a showcase feature in the November 2023 product launch.\n\nConclusion\nOur exploration of using Vision Transformers to improve our photo tour product has been successful and rewarding. By incorporating pretraining, multi-task learning, ensemble learning, and knowledge distillation, we’ve significantly enhanced model accuracy. Pretraining provided a strong foundation, while multi-task learning enriched the model’s ability to interpret diverse visuals. Ensemble learning combined model strengths for robust predictions, and knowledge distillation enabled efficient deployment without sacrificing accuracy.\nThe AI-powered photo tour was launched as part of Airbnb’s 2023 Winter Release. Since then, we have been diligently monitoring the performance of this product and continue to refine our models further for an even more seamless user experience.\nAcknowledgments\nWe would like to thank everyone involved in the project. A special thanks to the entire Airbnb user, listing, and platform team for their relentless efforts in developing and launching the product, ensuring its continued excellence. Additionally, we extend our gratitude to the Airbnb Machine Learning Infra team for their crucial support in building a robust infrastructure that photo tour relies upon.\nIf this type of work interests you, check out some of our related roles!\n\nAirbnb’s AI-powered photo tour using Vision Transformer was originally published in The Airbnb Tech Blog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Pei Xiong",
        "guid": "https://medium.com/p/e470535f76d4",
        "categories": [
          "engineering",
          "technology",
          "computer-vision",
          "machine-learning",
          "ai"
        ],
        "isoDate": "2024-11-13T17:39:08.000Z"
      },
      {
        "creator": "Sharmila Jesupaul",
        "title": "Adopting Bazel for Web at Scale",
        "link": "https://medium.com/airbnb-engineering/adopting-bazel-for-web-at-scale-a784b2dbe325?source=rss----53c7c27702d5---4",
        "pubDate": "Tue, 12 Nov 2024 18:22:17 GMT",
        "content:encodedSnippet": "How and Why We Migrated Airbnb’s Large-Scale Web Monorepo to Bazel\nBy: Brie Bunge and Sharmila Jesupaul\nIntroduction\nAt Airbnb, we’ve recently adopted Bazel — Google’s open source build tool–as our universal build system across backend, web, and iOS platforms. This post will cover our experience adopting Bazel for Airbnb’s large-scale (over 11 million lines of code) web monorepo. We’ll share how we prepared the code base, the principles that guided the migration, and the process of migrating selected CI jobs. Our goal is to share information that would have been valuable to us when we embarked on this journey and to contribute to the growing discussion around Bazel for web development.\nWhy did we do this?\nHistorically, we wrote bespoke build scripts and caching logic for various continuous integration (CI) jobs that proved challenging to maintain and consistently reached scaling limits as the repo grew. For example, our linter, ESLint, and TypeScript’s type checking did not support multi-threaded concurrency out-of-the-box. We extended our unit testing tool, Jest, to be the runner for these tools because it had an API to leverage multiple workers.\nIt was not sustainable to continually create workarounds to overcome the inefficiencies of our tooling which did not support concurrency and we were incurring a long-run maintenance cost. To tackle these challenges and to best support our growing codebase, we found that Bazel’s sophistication, parallelism, caching, and performance fulfilled our needs.\nAdditionally, Bazel is language agnostic. This facilitated consolidation onto a single, universal build system across Airbnb and allowed us to share common infrastructure and expertise. Now, an engineer who works on our backend monorepo can switch to the web monorepo and know how to build and test things.\nWhy was this hard?\nWhen we began the migration in 2021, there was no publicized industry precedent for integrating Bazel with web at scale outside of Google. Open source tooling didn’t work out-of-the-box, and leveraging remote build execution (RBE) introduced additional challenges. Our web codebase is large and contains many loose files, which led to performance issues when transmitting them to the remote environment. Additionally, we established migration principles that included improving or maintaining overall performance and reducing the impact on developers contributing to the monorepo during the transition. We effectively achieved both of these goals. Read on for more details.\nReadying the Repository\nWe did some work up front to make the repository Bazel-ready–namely, cycle breaking and automated BUILD.bazel file generation.\nCycle Breaking\nOur monorepo is laid out with projects under a top-level frontend/ directory. To start, we wanted to add BUILD.bazel files to each of the ~1000 top-level frontend directories. However, doing so created cycles in the dependency graph. This is not allowed in Bazel because there needs to be a DAG of build targets. Breaking these often felt like battling a hydra, as removing one cycle spawns more in its place. To accelerate the process, we modeled the problem as finding the minimum feedback arc set (MFAS)¹ to identify the minimal set of edges to remove leaving a DAG. This set presented the least disruption, level of effort, and surfaced pathological edges.\nAutomated BUILD.bazel Generation\nWe automatically generate BUILD.bazel files for the following reasons:\n\nMost contents are knowable from statically analyzable import / require statements.\nAutomation allowed us to quickly iterate on BUILD.bazel changes as we refined our rule definitions.\nIt would take time for the migration to complete and we didn’t want to ask users to keep these files up-to-date when they weren’t yet gaining value from them.\nManually keeping these files up-to-date would constitute an additional Bazel tax, regressing the developer experience.\n\nWe have a CLI tool called sync-configs that generates dependency-based configurations in the monorepo (e.g., tsconfig.json, project configuration, now BUILD.bazel). It uses jest-haste-map and watchman with a custom version of the dependencyExtractor to determine the file-level dependency graph and part of Gazelle to emit BUILD.bazel files. This CLI tool is similar to Gazelle but also generates additional web specific configuration files such as tsconfig.json files used in TypeScript compilation.\nCI Migration\nWith preparation work complete, we proceeded to migrate CI jobs to Bazel. This was a massive undertaking, so we divided the work into incremental milestones. We audited our CI jobs and chose to migrate the ones that would benefit the most: type checking, linting, and unit testing². To reduce the burden on our developers, we assigned the central Web Platform team the responsibility for porting CI jobs to Bazel. We proceeded one job at a time to deliver incremental value to developers sooner, gain confidence in our approach, focus our efforts, and build momentum. With each job, we ensured that the developer experience was high-quality, that performance improved, CI failures were reproducible locally, and that the tooling Bazel replaced was fully deprecated and removed.\nEnabling TypeScript\nWe started with the TypeScript (TS) CI job. We first tried the open source ts_project rule³. However, it didn’t work well with RBE due to the sheer number of inputs, so we wrote a custom rule to reduce the number and size of the inputs.\nThe biggest source of inputs came from node_modules. Prior to this, the files for each npm package were being uploaded individually. Since Bazel works well with Java, we packaged up a full tar and a TS-specific tar (only containing the *.ts and package.json) for each npm package along the lines of Java JAR files (essentially zips).\nAnother source of inputs came through transitive dependencies. Transitive node_modules and d.ts files in the sandbox were being included because technically they can be needed for subsequent project compilations. For example, suppose project foo depends on bar, and types from bar are exposed in foo’s emit. As a result, project baz which depends on foo would also need bar’s outputs in the sandbox. For long chains of dependencies, this can bloat the inputs significantly with files that aren’t actually needed. TypeScript has a — listFiles flag that tells us which files are part of the compilation. We can package up this limited set of files along with the emitted d.ts files into an output tsc.tar.gz file⁴. With this, targets need only include direct dependencies, rather than all transitive dependencies⁵.\nDiagram showing how we use tars and the — listFiles flag to prune inputs/outputs of :types targets\nThis custom rule unblocked switching to Bazel for TypeScript, as the job was now well under our CI runtime budget.\nBar chart showing the speed up from switching to using our custom genrule\nEnabling ESLint\nWe migrated the ESLint job next. Bazel works best with actions that are independent and have a narrow set of inputs. Some of our lint rules (e.g., special internal rules, import/export, import/extensions) inspected files outside of the linted file. We restricted our lint rules to those that could operate in isolation as a way of reducing input size and having only to lint directly affected files. This meant moving or deleting lint rules (e.g., those that were made redundant with TypeScript). As a result, we reduced CI times by over 70%.\nTime series graph showing the runtime speed-up in early May from only running ESLint on directly affected targets\nEnabling Jest\nOur next challenge was enabling Jest. This presented unique challenges, as we needed to bring along a much larger set of first and third-party dependencies, and there were more Bazel-specific failures to fix.\nWorker and Docker Cache\nWe tarred up dependencies to reduce input size, but extraction was still slow. To address this, we introduced caching. One layer of cache is on the remote worker and another is on the worker’s Docker container, baked into the image at build time. The Docker layer exists to avoid losing our cache when remote workers are auto-scaled. We run a cron job once a week to update the Docker image with the newest set of cached dependencies, striking a balance of keeping them fresh while avoiding image thrashing. For more details, check out this Bazel Community Day talk.\nDiagram showing symlinked npm dependencies to a Docker cache and worker cache\nThis added caching provided us with a ~25% speed up of our Jest unit testing CI job overall and reduced the time to extract our dependencies from 1–3 minutes to 3–7 seconds per target. This implementation required us to enable the NodeJS preserve-symlinks option and patch some of our tools that followed symlinks to their real paths. We extended this caching strategy to our Babel transformation cache, another source of poor performance.\nImplicit Dependencies\nNext, we needed to fix Bazel-specific test failures. Most of these were due to missing files. For any inputs not statically analyzable (e.g., referenced as a string without an import, babel plugin string referenced in .babelrc), we added support for a Bazel keep comment (e.g., // bazelKeep: path/to/file) which acts as though the file were imported. The advantages of this approach are:\n1. It is colocated with the code that uses the dependency,\n2. BUILD.bazel files don’t need to be manually edited to add/move # keep comments,\n3. There is no effect on runtime.\nA small number of tests were unsuitable for Bazel because they required a large view of the repository or a dynamic and implicit set of dependencies. We moved these tests out of our unit testing job to separate CI checks.\nPreventing Backsliding\nWith over 20,000 test files and hundreds of people actively working in the same repository, we needed to pursue test fixes such that they would not be undone as product development progressed.\nOur CI has three types of build queues:\n1. “Required”, which blocks changes,\n2. “Optional”, which is non-blocking,\n3. “Hidden”, which is non-blocking and not shown on PRs.\nAs we fixed tests, we moved them from “hidden” to “required” via a rule attribute. To ensure a single source of truth, tests run in “required” under Bazel were not run under the Jest setup being replaced.\n# frontend/app/script/__tests__/BUILD.bazel\njest_test(\n    name = \"jest_test\",\n    is_required = True, # makes this target a required check on pull requests \n    deps = [\n        \":source_library\",\n    ],\n)\nExample jest_test rule. This signifies that this target will run on the “required” build queue.\nWe wrote a script comparing before and after Bazel to determine migration-readiness, using the metrics of test runtime, code coverage stats, and failure rate. Fortunately, the bulk of tests could be enabled without additional changes, so we enabled these in batches. We divided and conquered the remaining burndown list of failures with the central team, Web Platform, fixing and updating tests in Bazel to avoid putting this burden on our developers. After a grace period, we fully disabled and deleted the non-Bazel Jest infrastructure and removed the is_required param.\nLocal Bazel Experience\nIn tandem with our CI migration, we ensured that developers can run Bazel locally to reproduce and iterate on CI failures. Our migration principles included delivering only what was on par with or superior to the existing developer experience and performance. JavaScript tools have developer-friendly CLI experiences (e.g., watch mode, targeting select files, rich interactivity) and IDE integrations that we wanted to retain. By default, frontend developers can continue using the tools they know and love, and in cases where it is beneficial they can opt into Bazel. Discrepancies between Bazel and non-Bazel are rare and when they do occur, developers have a means of resolving the issue. For example, developers can run a single script, failed-on-pr which will re-run any targets failing CI locally to easily reproduce issues.\nAnnotations on a failing build with scripts to recreate the failures, e.g. yak script jest:failed-on-pr\nWe also do some normalization of platform specific binaries so that we can reuse the cache between Linux and MacOS builds. This speeds up local development and CI jobs by sharing cache between a local developer’s macbook and linux machines in CI. For native npm packages (node-gyp dependencies) we exclude platform-specific files and build the package on the execution machine. The execution machine will be the machine executing the test or build process. We also use “universal binaries” (e.g., for node and zstd), where all platform binaries are included as inputs (so that inputs are consistent no matter which platform the action is run from) and the proper binary is chosen at runtime.\nConclusion\nAdopting Bazel for our core CI jobs yielded significant performance improvements for TypeScript type checking (34% faster), ESLint linting (35% faster), and Jest unit tests (42% faster incremental runs, 29% overall). Moreover, our CI can now better scale as the repo grows.\nNext, to further improve Bazel performance, we will be focusing on persisting a warm Bazel host across CI runs, taming our build graph, powering CI jobs that do not use Bazel with the Bazel build graph, and potentially exploring SquashFS to further compress and optimize our Bazel sandboxes.\nWe hope that sharing our journey has provided insights for organizations considering a Bazel migration for web.\nAcknowledgments\nThank you Madison Capps, Meghan Dow, Matt Insler, Janusz Kudelka, Joe Lencioni, Rae Liu, James Robinson, Joel Snyder, Elliott Sprehn, Fanying Ye, and various other internal and external partners who helped bring Bazel to Airbnb.\nWe are also grateful to the broader Bazel community for being welcoming and sharing ideas.\n****************\n[1]: This problem is NP-complete, though approximation algorithms have been devised that still guarantee no cycles; we chose the implementation outlined in “Breaking Cycles in Noisy Hierarchies”.\n[2]: After initial evaluation, we considered migrating web asset bundling as out of scope (though we may revisit this in the future) due to high level of effort, unknowns in the bundler landscape, and neutral return on investment given our recent adoption of Metro, as Metro’s architecture already factors in scalability features (e.g. parallelism, local and remote caching, and incremental builds).\n[3]: There are newer TS rules that may work well for you here.\n[4]: We later switched to using zstd instead of gzip because it produces archives that are better compressed and more deterministic, keeping tarballs consistent across different platforms.\n[5]: While unnecessary files may still be included, it’s a much narrower set (and could be pruned as a further optimization).\nAll product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.\n\nAdopting Bazel for Web at Scale was originally published in The Airbnb Tech Blog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Sharmila Jesupaul",
        "guid": "https://medium.com/p/a784b2dbe325",
        "categories": [
          "bazel",
          "migration",
          "web",
          "typescript",
          "engineering"
        ],
        "isoDate": "2024-11-12T18:22:17.000Z"
      },
      {
        "creator": "Dillon Davis",
        "title": "Transforming Location Retrieval at Airbnb: A Journey from Heuristics to Reinforcement Learning",
        "link": "https://medium.com/airbnb-engineering/transforming-location-retrieval-at-airbnb-a-journey-from-heuristics-to-reinforcement-learning-d33ffc4ddb8f?source=rss----53c7c27702d5---4",
        "pubDate": "Mon, 11 Nov 2024 18:14:35 GMT",
        "content:encodedSnippet": "How Airbnb leverages machine learning and reinforcement learning techniques to solve a unique information retrieval task in order to provide guests with unique, affordable, and differentiated accommodations around the world.\nBy: Dillon Davis, Huiji Gao, Thomas Legrand, Weiwei Guo, Malay Haldar, Alex Deng, Han Zhao, Liwei He, Sanjeev Katariya\nIntroduction\nAirbnb has transformed the way people travel around the globe. As Airbnb’s inventory spans diverse locations and property types, providing guests with relevant options in their search results has become increasingly complex. In this blog post, we’ll discuss shifting from using simple heuristics to advanced machine learning and reinforcement learning techniques to transform what we call location retrieval in order to address this challenge.\nThe Challenge of Location Retrieval\nGuests typically start searching by entering a destination in the search bar and expect the most relevant results to be surfaced. These destinations can be countries, states, cities, neighborhoods, streets, addresses, or points of interest. Unlike traditional travel accommodations, Airbnb listings are spread across different neighborhoods and surrounding areas. For example, a family searching for a vacation rental in San Francisco might find better options in nearby cities like Daly City, where there are larger single-family homes. Thus, the system needs to account for not just the searched location but also nearby areas that might offer better options for the guest. This is evidenced by the locations of booked listings when searching for San Francisco shown below.\n\nGiven Airbnb’s scale, we cannot rank every listing for every search. This presented a challenge to create a system that dynamically infers a relevant map area for a query. This system, known as location retrieval, needed to balance including a wide variety of listings to appeal to all guests’ needs while still being relevant to the query. Our search ranking models can then efficiently rank the subset of our inventory that is within the relevant map area and surface the most relevant inventory to our guests. This system and more is outlined below\n\nStarting with Heuristics: The Cold Start Problem\nInitially, Airbnb relied on heuristics to define map areas based on the type of search. For example, if a guest searched for a country, the system would use administrative boundaries to filter listings within that country. If they searched for a city, the system would create a 25-mile radius around the city center to retrieve listings.\nImproving these heuristics proved to be profoundly impactful. One such example is the introduction of a log scale parameterized smooth function to compute an expansion factor for the diagonal size of the administrative bounds of the searched destination. We applied this for very precise locations like addresses, buildings, and POI’s resulting in a 0.35% increase in uncancelled bookers on the platform when tested in an online A/B experiment against the baseline heuristics. Figures below demonstrate how search results for a building in Ibiza, Spain improved dramatically with this heuristic by surfacing significantly more and higher quality inventory.\n\nThese heuristics were simple and worked well enough to start, but they had limitations. They couldn’t differentiate between different types of searches (e.g., a family looking for a large home versus a solo traveler looking for a small apartment), and they didn’t adapt well to new data as Airbnb’s inventory and guest preferences evolved.\nExploring Statistics to Help Improve Location Retrieval\nWith more data available over time from these intuition based heuristics, we thought there might be a way to take advantage of this historical user booking behavior to improve location retrieval. We built a dataset for each travel destination that recorded where guests booked listings when searching for that destination. Based on this data, the system could create retrieval map areas that included 96% of the nearest booked listings for a given destination.\nWe tested these newly constructed retrieval map areas in lieu of the intuition based heuristics outlined above based on the hypothesis that it would provide guests a more bookable selection of inventory. While this statistical approach was more aligned with guest booking behavior, it still had limitations. It treated all searches for a location the same, regardless of specific search parameters like group size or travel dates. This uniform approach meant that some guests might not see the best listings for their particular needs. As a result, this statistics based method had no detectable increase in uncancelled bookers on the platform when tested against the heuristics outlined above in an online A/B experiment. This led us to believe that location retrieval may require more advanced techniques such as machine learning.\nAdvancing to Machine Learning\nInstead of only relying on past booking data, the new system could learn from various search parameters, such as the number of guests and stay duration. By analyzing this data, a model could predict more relevant map areas for each search, rather than applying a one-size-fits-all approach.\nFor example, a group of ten travelers searching for a San Francisco vacation rental might prefer larger homes in the suburbs, while solo travelers might prioritize central locations. The machine learning model could distinguish between these different preferences and adjust the retrieval map areas accordingly, providing more tailored results.\nWe constructed our machine learning model in the following manner. This is a result of three iterations that introduced the machine learning model, expanded its feature set, and expanded search attribution. The architecture is depicted in the figure below.\n\nTraining Examples: Searches issued by a booker by entering a destination in the search bar or manipulating the map that contained the booked listing in their search results on the same day or one day before the booking. We discard any bookings that are canceled 7 days after booking.\nTraining Features: We derive features directly from the search request such as location name, stay length, number of guests, price filters, location country, etc. There are 9 continuous features and 19 categorical features in total.\nTraining Labels: The latitude and longitude coordinates of the booked listing attributed to the search\nArchitecture: A two layer neural network of size 256 was chosen in order to have more flexibility for loss formulation compared to traditional regression and decision tree based approaches.\nModel Output: 4 floats that define the latitude and longitude offsets from the center latitude and longitude coordinates of the searched destination that represent the relevant map area.\nLoss: Trained to predict map areas that contain their associated booked listing while minimizing the size of the predicted map area and the occurrence of predictions that cannot construct a valid rectangular map area.\n\nThe machine learning system increased the recall of booked listings (i.e., how often the system retrieved a listing that was eventually booked) by 7.12% and reduced the size of the retrieval map area by 40.83%. It had a cumulative impact of +1.8% in uncancelled bookers on the platform. The initial model was evaluated against the baseline and each subsequent model iteration was evaluated against the preceding outgoing model.\nFigures below demonstrate how search results for a specific street in Lima, Peru improved dramatically with the model by surfacing results that are much closer to the searched street.\nBefore\n\nAfter\n\nExploring New Frontiers with Reinforcement Learning\nWhile machine learning improved the system’s ability to differentiate search results, there was still room for improvement, particularly in learning whether locations that had never been surfaced before were relevant to guests for a search. To address this, Airbnb introduced reinforcement learning to the location retrieval process.\nReinforcement learning allowed the system to continuously learn from guest interactions by surfacing new areas for a given destination and adjusting the retrieval map area based on guest booking behavior. This approach, known as a contextual multi-armed bandit problem, involved balancing exploration (surfacing new locations) with exploitation (surfacing previous successful locations). The system could actively experiment with different retrieval map areas learning from guest bookings to refine its predictions.\nApplying a contextual multi-armed bandit traditionally requires defining an active contextual estimator, a method for uncertainty estimation, and an exploration strategy. We took the following approach given product constraints, system constraints, and the nature of our model formulation. The architecture is depicted in the figure below.\n\nActive contextual estimation: We employed our existing machine learning model for location retrieval retrained on a daily basis to regularly learn from any new bookings data that we collect while surfacing previously unshown locations.\nUncertainty estimation: We modified our model architecture with a random dropout layer to generate 32 unique predictions for a given search (Monte Carlo Dropout). This allows us to measure the mean and standard deviation of our prediction while minimizing negative impact to system performance and changes to our existing model formulation.\nExploration Strategy: We compute an upper confidence bound using the mean and standard deviation of our prediction in order to construct larger retrieval map areas based on the model’s confidence in its prediction for the search.\n\nThis system successfully explored more for less-traveled locations where it was less confident and explored less for locations that are often searched and booked. For example, pictured below are the mean (inner) and upper confidence bound (outer) estimates of retrieval map areas for San Francisco, CA (left) and Smith Mountain Lake, Virginia (right). San Francisco is searched almost 25x more than Smith Mountain Lake with proportionately more bookings as well. As a result, the model is more confident in its retrieval map area estimate for San Francisco vs Smith Mountain Lake resulting in 2–3x less exploration for San Francisco queries vs Smith Mountain Lake.\n\nThe reinforcement learning system was also tested against the outgoing machine learning model in online A/B experiments showing a cumulative 0.51% increase in uncanceled bookers and 0.71% increase in 5 star trip rate over two iterations that introduced reinforcement learning and optimized scoring of the more complex model.\nConclusion: A Transformative Journey\nAirbnb’s journey from simple heuristics to sophisticated machine learning and reinforcement learning models demonstrates the power of data-driven approaches in transforming complex systems. By continually iterating and improving its location retrieval process, Airbnb has not only enhanced the relevance of its search results but also helped guests experience more 5 star trips.\nThis transformation cumulatively results in a 2.66% increase in uncanceled bookers — a major achievement for a company operating at Airbnb’s scale. More details can be found in our technical paper. As Airbnb continues to innovate, we are continuously evaluating and introducing more advanced features and retrieval mechanisms like retrieving with complex polygons . These will further refine and enhance the search experience for millions of guests worldwide.\nIf this type of work interests you, check out some of our related positions and more at Careers at Airbnb!\n****************\nAll product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.\n\nTransforming Location Retrieval at Airbnb: A Journey from Heuristics to Reinforcement Learning was originally published in The Airbnb Tech Blog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Dillon Davis",
        "guid": "https://medium.com/p/d33ffc4ddb8f",
        "categories": [
          "search-engines",
          "machine-learning",
          "information-retrieval",
          "engineering",
          "artificial-intelligence"
        ],
        "isoDate": "2024-11-11T18:14:35.000Z"
      }
    ]
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Mads Kristensen",
        "title": "First preview of Visual Studio 2022 v17.13  ",
        "link": "https://devblogs.microsoft.com/visualstudio/first-preview-of-visual-studio-2022-v17-13/",
        "pubDate": "Wed, 13 Nov 2024 15:14:05 +0000",
        "content:encodedSnippet": "We’re excited to announce the availability of Visual Studio 2022 v17.13 Preview 1 – the first preview of our next update to Visual Studio. This update focuses on providing fantastic developer experiences across the board, with a focus on stability & security, and AI & productivity. Download the preview and see the full list of enhancements in the release notes.  \n\nQuality & security \nEnsuring the highest standards of quality and security is paramount. Visual Studio 2022 v17.13 incorporates robust quality and security enhancements designed to provide a seamless and secure development environment. With improved diagnostics and debugging tools, developers can now identify and resolve issues more efficiently, leading to more reliable and stable applications. Furthermore, enhanced security features offer protection against potential threats, safeguarding your code and data. These improvements not only streamline your workflow but also bolster your confidence in delivering high-quality, secure software solutions. \nAI & productivity \nVisual Studio 2022 v17.13 integrates advanced AI to boost developer productivity by automating routine tasks, offering intelligent code suggestions, and enhancing coding efficiency. With AI-assisted code completion, refactoring tools, and personalized insights, developers can write cleaner, more efficient code and focus on complex, creative aspects of their projects, ultimately accelerating development cycles. This new release also brings general productivity improvements across the IDE, making it a robust tool for developers at every level. \n \nDownload Visual Studio Preview\n\nWe hope you enjoy this preview of Visual Studio, and we look forward to hearing what you think. You can share feedback with us via Developer Community, by reporting issues via report a problem and share your suggestions for new features or improvements to existing ones. \nYou can download the preview from our website or update it from within the IDE. Please note that you should not use this preview in production environments, and some extensions or workloads may not be compatible with it. \nThank you for using Visual Studio and happy coding! \nThe post First preview of Visual Studio 2022 v17.13   appeared first on Visual Studio Blog.",
        "dc:creator": "Mads Kristensen",
        "content": "<p>We’re excited to announce the availability of Visual Studio 2022 v17.13 Preview 1 – the first preview of our next update to Visual Studio. This update focuses on providing fantastic developer experiences across the board, with a focus on stability &#38; security, and AI &#38; productivity. Download the preview and see the full list of [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/first-preview-of-visual-studio-2022-v17-13/\">First preview of Visual Studio 2022 v17.13  </a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "We’re excited to announce the availability of Visual Studio 2022 v17.13 Preview 1 – the first preview of our next update to Visual Studio. This update focuses on providing fantastic developer experiences across the board, with a focus on stability & security, and AI & productivity. Download the preview and see the full list of […]\nThe post First preview of Visual Studio 2022 v17.13   appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251307",
        "categories": [
          "Visual Studio",
          "Preview Release"
        ],
        "isoDate": "2024-11-13T15:14:05.000Z"
      },
      {
        "creator": "Mads Kristensen",
        "title": "Visual Studio 2022 v17.12 with .NET 9",
        "link": "https://devblogs.microsoft.com/visualstudio/visual-studio-2022-v17-12-with-dotnet-9/",
        "pubDate": "Tue, 12 Nov 2024 18:12:48 +0000",
        "content:encodedSnippet": "We are thrilled to announce the General Availability (GA) of Visual Studio 2022 version 17.12. This update focuses on providing fantastic developer experiences for working with .NET 9 projects and new AI productivity features, along with continuous improvements for all developers.\n\nThanks to your continuous feature requests, we’ve incorporated many of them in this release. There’s something new for every developer. We have added several new tools and enhancements that simplify your workflow and improve productivity. Whether you’re looking for advanced debugging capabilities, more efficient code management, or enhanced security features, this update has it all.\n\nDownload Visual Studio 2022 v17.12\n\nFor detailed information on each new feature, check out the release notes. If you’re pressed for time, here are the key highlights.\nProductivity\nCopy from the Error List: Copying an error from the Error List now copies just the description instead of the entire row to the clipboard.\nGo to line anywhere in Code Search: In Code Search, you can now navigate to a specific line in the current document or other specified document.\nDock the Code Search window: You can now freely position the Code Search window with capabilities like docking and auto-hiding.\nCustomize collapsed text indicator: Set custom colors for the collapsed text indicator in the Visual Studio editor.\nRefresh your Find results: You can now refresh the results to a previous Find to get up-to-date search matches.\nMore space for horizontal scrollbar: You can now control the visibility of the file level indicators in CodeLens.\nNon-blocking Code Cleanup on save: When Code Cleanup is run on Save, it now operates in a non-blocking manner, for a smoother coding experience.\nGitHub Copilot\nAI smart variable inspection: Optimize your debugging workflow with Integrated AI variable inspection.\nAI-powered IEnumerable visualizer: AI-powered LINQ Editable Expressions in the IEnumerable visualizer.\nFix code with GitHub Copilot: GitHub Copilot assists you in resolving code issues.\nBetter AI completions for C#: GitHub Copilot brings in additional context from relevant source files to improve completions for C#.\nDebug tests with GitHub Copilot: Get help with debugging failed tests by using Debug Tests with GitHub Copilot.\nDebugging & diagnostics\nShows method return values when debugging: The debugger now displays inline return values for enhanced debugging efficiency.\nExport breakpoint groups with ease: Effortless import and export of breakpoint groups.\nBlazor WebAssembly debugging: An improved debugging experience for Blazor WebAssembly apps targeting .NET 9 or later.\nMeter Histogram in Profiler Counter Tool: Enhanced performance insights using Meter Histogram in Profiler Counter Tool.\nAnalyze memory use over time: Select and compare multiple memory snapshots using the Diagnostics Tool window.\nGit tooling\nManage file renaming with Git: Get peace of mind when renaming files with a new notification.\nPull requests using drafts and templates: Create pull request drafts and start your descriptions with templates in Visual Studio.\nCreate internal GitHub repos: Visual Studio now supports creating internal repos and includes guidance for each type of repository to give you more confidence when starting a new project.\nCopy Git link: You can get a GitHub or Azure DevOps link to a specific line of code to make it easy to share with your colleagues.\nCustomize your AI Git commit message: You can add additional instructions to the prompt for generating your Git commit message with GitHub Copilot.\nMulti-repo for GitHub and Azure DevOps: You can now create pull requests and link work items in multi-repo scenarios.\nIDE\nPreserve font across theme changes: Changing themes will now remember your font and font size preferences.\nMulti-Project Launch Configuration: Streamline debugging by setting up and saving launch profiles for specific projects within multi-project solutions. Share configurations effortlessly with your team.\nCopy files between instances: You can now copy files and folders from Solution Explorer in one instance of Visual Studio to another.\nMultiple GitHub accounts: You can now add multiple GitHub accounts and set an active account to drive GitHub features like GitHub Copilot and Version Control.\nCertificate Revocation Checks: Visual Studio now alerts you if it detects digital certificate problems during network calls.\nMotW security warnings: Mark of the web (MotW) security warnings are now integrated into the overall trust functionality.\nTeams Toolkit new AI templates: The Teams Toolkit onboards new AI Teams app templates.\nCloud\nAzure App Service publish security updates: Publishing to Azure App Service securely using integrated security updates.\nAzure WebJobs Linux support: Publishing to Azure WebJobs on Linux is now supported by right-click publish in Visual Studio.\nAzure Functions Flex Consumption: Publish to Azure Flex Consumption hosting plan, currently in Preview.\nConnected Services security update: Making your apps and development experienced more secure.\nDesktop\nEnhanced WinUI components search: Enhance WinUI project setup with improved Visual Studio Installer search, simplifying component location for developers.\nWeb\nRequest variables in HTTP files: HTTP files now support request variables. That is where you can send a request and then use data from the response, or request, in future requests.\nHTTP files shared environment: In HTTP environment files we have added support to share variables across environments.\nVitest support in JavaScript and TypeScript: When using JavaScript and TypeScript projects you can now author test cases with Vitest.\nInlay Hints support for more languages: Inlay Hint support has been added to JavaScript, TypeScript, Python and Razor as well as a setting to control its behavior.\nData\nSDK-style SQL projects in SSDT: You can now use the SDK-style project file format in your SQL Server Data Tools projects.\n.NET\nAchieve more with .NET 9: .NET 9 elevates cloud-native and intelligent app development, focusing on productivity enhancements, streamlined deployments, and accelerated AI integration.\nNuGet audits transitive packages: NuGet is changing default audit settings to include transitive packages.\nC++\nSet C++ Command Line Arguments: A new way to set your command line arguments right from the toolbar.\nBuild Insights view explanations: Learn how to use each tab of Build Insights via a newly added link to documentation.\nBuild Insights path adjustments: Get a clearer view of your file in Build Insights, see full path on hover.\nOpen Folder for Unreal Engine uproject: A new way of opening your uproject.\nChange signature improved: You can now effectively change signatures with our improved feature for C++.\nSHARE YOUR FEEDBACK AND STAY CONNECTED\nAs you use Visual Studio, let us know what you love, what you like, and where you’d like us to improve. You can share feedback with us via Developer Community: report any bugs or issues via report a problem and share your suggestions for new features or improvements to existing ones.\nStay connected with the Visual Studio team by following us on YouTube, Twitter, LinkedIn, Twitch and on Microsoft Learn.\nAs always, we appreciate the time you’ve spent reporting issues and hope you continue to give us feedback on how we’re doing and what we can improve.\nThe post Visual Studio 2022 v17.12 with .NET 9 appeared first on Visual Studio Blog.",
        "dc:creator": "Mads Kristensen",
        "content": "<p>We are thrilled to announce the General Availability (GA) of Visual Studio 2022 version 17.12. This update focuses on providing fantastic developer experiences for working with .NET 9 projects and new AI productivity features, along with continuous improvements for all developers. Thanks to your continuous feature requests, we&#8217;ve incorporated many of them in this release. [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/visual-studio-2022-v17-12-with-dotnet-9/\">Visual Studio 2022 v17.12 with .NET 9</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "We are thrilled to announce the General Availability (GA) of Visual Studio 2022 version 17.12. This update focuses on providing fantastic developer experiences for working with .NET 9 projects and new AI productivity features, along with continuous improvements for all developers. Thanks to your continuous feature requests, we’ve incorporated many of them in this release. […]\nThe post Visual Studio 2022 v17.12 with .NET 9 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251184",
        "categories": [
          "Visual Studio",
          "Release"
        ],
        "isoDate": "2024-11-12T18:12:48.000Z"
      },
      {
        "creator": "Mika Dumont",
        "title": "Better GitHub Copilot Completions for C#",
        "link": "https://devblogs.microsoft.com/visualstudio/better-github-copilot-completions-for-c/",
        "pubDate": "Mon, 11 Nov 2024 15:27:27 +0000",
        "content:encodedSnippet": "We’re excited to announce a significant enhancement to GitHub Copilot that elevates your C# coding experience. Introducing the new update: GitHub Copilot code completions now provide more accurate and relevant autocomplete suggestions by incorporating additional C# context.\nPreviously, GitHub Copilot generated suggestions based on the content of your currently active file and any other open files in your editor. While this approach was helpful, we have discovered that including more relevant context can greatly improve the quality of these suggestions.\nWith this latest update, GitHub Copilot now automatically considers semantically relevant files for additional context, even if these files are not open in your editor. This enhancement helps reduce hallucinations and ensures that you receive more pertinent and precise code completions.\nBefore: Semantically relevant files are not considered as context for GitHub Copilot Completions\n﻿without-related-files.mp4″ width=”560″ height=”315″ allowfullscreen=”allowfullscreen”>﻿\nAfter: Semantically relevant files are considered as context for GitHub Copilot Completions\n﻿﻿without-related-files.mp4″ width=”560″ height=”315″ allowfullscreen=”allowfullscreen”>﻿\nTo dive deeper into how this new feature works and how it can improve your coding productivity, check out our detailed blog post Improving GitHub Copilot Completions in Visual Studio for C# Developers on the .NET blog.\nStay tuned for more updates and thank you for being a part of our developer community.\nThe post Better GitHub Copilot Completions for C# appeared first on Visual Studio Blog.",
        "enclosure": {
          "url": "https://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2024/11/without-related-files.mp4",
          "length": "146986",
          "type": "video/mp4"
        },
        "dc:creator": "Mika Dumont",
        "content": "<p>We&#8217;re excited to announce a significant enhancement to GitHub Copilot that elevates your C# coding experience. Introducing the new update: GitHub Copilot code completions now provide more accurate and relevant autocomplete suggestions by incorporating additional C# context. Previously, GitHub Copilot generated suggestions based on the content of your currently active file and any other open [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/better-github-copilot-completions-for-c/\">Better GitHub Copilot Completions for C#</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "We’re excited to announce a significant enhancement to GitHub Copilot that elevates your C# coding experience. Introducing the new update: GitHub Copilot code completions now provide more accurate and relevant autocomplete suggestions by incorporating additional C# context. Previously, GitHub Copilot generated suggestions based on the content of your currently active file and any other open […]\nThe post Better GitHub Copilot Completions for C# appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251281",
        "categories": [
          "Copilot",
          "Visual Studio",
          "C#",
          "GitHub Copilot",
          "Visual Studio 2022"
        ],
        "isoDate": "2024-11-11T15:27:27.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": [
      {
        "creator": "권창현",
        "title": "학생 지도의 즐거움에 대하여",
        "link": "https://thoughts.chkwon.net/happy-advisor/",
        "pubDate": "Sun, 10 Nov 2024 06:17:06 +0000",
        "content:encodedSnippet": "지난해 8월에 한국에 들어와서 KAIST에서 근무한 지 1년이 지났다. 그동안 국내외에 계신 분들을 만날 때면, 한국에 들어가서 어떠냐, 좋으냐는 질문을 많이 들었고, 그때마다 “너무 좋아요, 행복해요”라는 말을 많이도 하고 다녔다.\n최근에 ‘나는 왜 한국 생활이 행복한가?’라는 질문에 대해 자세히 살펴볼 기회가 있었다. 내가 한국 생활에서 만족스러운 점들, 어떤 순간들에 재미를 느꼈는지는 어렴풋하게는 파악하고 있었지만, ‘왜?’라는 질문에 답하려고 시도한 것은 처음이다.\n \n\nKAIST 부임 벌써 1년. 바쁜지, 행복한지 묻는 중요한 질문 앞에서, 오늘 저녁 메뉴를 생각하며 고뇌에 빠진 모습이다.\n\n \n \n우선 정말 단순하게도 내가 태어나고 자란 나라, 한국이기 때문이다. 한국을 떠난 지 20년이나 됐기 때문에 나도 한국도 여러 가지 의미로 달라진 것은 사실이지만, 여전히 내가 태어난 나라이고, 언어적·문화적 뿌리를 공유하는 사람들이 많이 모여 사는 나라다. 이런 환경이 주는 알 수 없는 심리적 안정감이 있다.\nKAIST이기 때문이다. 이것은 몇 가지 의미를 갖고 있다. 첫째로는 내 모교라는 점이다. 내 추억이 있는 곳에서 일하는 것이 단순한 직장 이상의 의미를 준다. 둘째로는 한국 사회에서 KAIST가 가지는 지위 때문에 내게 주어지는 많은 기회들이 있다. 좋은 학생들을 만나기에도, 좋은 연구 프로젝트를 만나기에도 유리한 환경이다. 셋째로는 사회에 기여하기를 바라는 KAIST의 미션 때문이다. 한국 사회에 기여할 기회가 KAIST 교수에게만 주어지는 것은 아닐 테지만, 내가 개인적으로 갖고 있는 미션과 내가 속한 기관의 미션이 일치하는 점이 있다는 것에 대한 만족감이 있다.\n자극이 되는 동료 교수님들 때문이다. 내가 속한 학과 안팎에 지적으로 자극을 주시는 여러 동료 교수님들이 계시고, 그런 분들과 편안하게 어울리기도 하고 함께 일하기도 한다. 그분들의 프로페셔널한 모습도 자극이 많이 되지만, 그분들과 사적이며 내밀한 이야기를 나누기도 하며, 서로의 개인사를 공유하기도 한다. 그 과정에서 서로의 가치관에 대해 이야기도 해보는데, 그 과정이 많은 자극이 된다. 당연히, 미국이라고 그런 분들이 없었던 건 아니지만, 한국에는, KAIST에는 바로 옆 방에 계시기도 하고, 같은 건물, 같은 캠퍼스에 계신다. 그러다 보니 아무래도 그런 자극의 빈도가 높다.\n오믈렛 때문이다. 한국에 들어오면서 같은 학과 교수님과 창업을 하게 되었고, 아직까지는 순항 중이다. 창업하고, 동료를 모으고, 투자받고, 회사의 모양을 가꾸어 가면서 여러 가지 어려움이 있지만, 학교에서는 볼 수 없었던 새로운 도전을 맞이하고 있다. 그 도전들을 극복해나가는 과정에서 ‘내가 왜 그랬을까’라는 생각이 들 때도 있었지만, 내가 하고 있는 연구를 기반으로 한 회사를 만들고 있다는 것이 즐겁다. 훌륭한 동료들을 맞이했다는 것도 자랑스럽고, 그 사이에서 내가 할 수 있는 역할이 있다는 점도 흥미롭다. 나는 CTO 역할을 맡고 있지만, 인사, 법무, 계약, 재무, 세무 등 관련 일들도 많이 하면서 새로운 도전을 즐기고 있다. 교원의 기술 기반 회사 창업이라는 점이 KAIST의 미션과 부합한다는 것도 동기부여에 도움이 된다.\n그리고, 가장 중요하게, 내 학생들 때문이다.\n나는 한국에 와서 지금 만난 학생들을 지도하는 것이 매우 즐거운데, 그 이유에 대해 조금 더 곰곰이 생각해봤다. 이 말 하고 싶어서 이 글을 쓴다.\n내가 만난 KAIST 학생들은 그 누구보다 재능 넘치고 성실한 학생들이다. Work ethic이 매우 훌륭하고, 노력을 많이 기울이는 것에 대한 인내심이 높은 편이다. 이런 학생들을 마다할 교수가 어디 있겠나? 나는 이것만으로도 복받았다. 독립적인 사고, 자신의 의견에 대한 고집, 비정형 문제 해결 능력 등은 아직 부족한 편으로 보일 때도 있는데, 아직 학부 졸업한 지 1년밖에 안 된 학생들이니 당연할 것이라 생각된다. 부족한 점은 지도교수인 내가 잘 가이드해주고 조언해주면 될 일이다.\n언어와 문화를 공유하는 학생들이라는 점이 주는 이점이 꽤 있다. 학생들과 공부만 하고 연구만 하면 될 일이겠지만, 나는 그 과정에서 섬세한 피드백을 주는 것을 즐기는 사람이라는 것을 알게 되었다. 학생과 대화할 때 모국어가 아닌 영어로만 대화할 때와 비교해서는 커뮤니케이션의 해상도가 매우 높아진다. “잘 이해되었나요? 네, 이해했습니다.”와 같은 단순한 대화에서도 내가 그 학생에 대해 파악할 수 있는 것들이 많다. 그 학생의 표정과 몸짓, 말하는 억양 같은 것에서 읽을 수 있는 것들이 많고, 그에 맞게 내 다음 행동을 이어나갈 수 있다. 모든 사람들이 이런 해상도 높은 커뮤니케이션을 즐기는 것은 아니겠지만, 나는 그런 걸 즐기는 사람이었다. 미국에서는 경험하기 어려운 것들이었다. 물론, 이런 방식의 커뮤니케이션을 학생들도 즐기고 있는지, 학생들의 성장에 정말 도움이 될 것인지에 대해서는 아직 의문이 있으나, 다만 이런 방식이 내가 선호하고 즐기는 방식이라는 거다.\n한국 학교에서 한국 학생들을 가르치고 지도하여 성장에 도움을 주고 있다는 사실 그 자체가 주는 충족감이 있다. 한국으로 돌아오면서 남긴 글에서 미국에서 지낼 때는 내가 속한 커뮤니티를 명확히 구분하기가 쉽지 않아서 혼란스러웠다고 말한 바 있는데, 한국에 돌아와서야 아무래도 그 점들이 좀 더 명확해졌다. 한국 학생들을 성실히 지도한다는 것 자체가 내가 속한 커뮤니티에 기여할 수 있는 점이라고 생각되며, 그 점에서 학생 지도에 대한 동기부여가 잘 되고 있다.\n그런데, 아무리 이렇다고 한들, 학생들을 지도하는 점이 나를 그렇게까지 행복하게 만들 일인가?\n대체 왜?\n둘째 아이 키우는 것 같다. 이게 내 결론이다.\n흔히 첫째 아이는 부부가 직업적으로 경제적으로 가장 도전적인 상황에서 맞게 되는 경우가 많고, 부모로서의 경험 미숙 등으로 좀 더 엄격하게 대하게 되는 경향이 있다. 사랑스러운 아이지만, 필요 이상의 텐션을 유지하며 키우게 되어 부모와 아이 양쪽의 스트레스가 높아지기도 한다. 반면에 둘째 아이는 대체로 부부가 조금 더 안정되었을 때, 그리고 아이 양육 경험도 충분히 쌓였을 때 맞이하게 되며, 그래서 좀 더 여유가 있다. 흔히 ‘숨만 쉬어도 예쁘다’라는 표현으로 둘째 아이의 사랑스러움에 대해 이야기한다. 적어도 내 개인적인 경험과는 일치한다. 내 첫째 아이는 박사과정 막학기에 태어났고 엄마, 아빠가 모두 테뉴어 트랙 조교수일 때 자랐다. 둘째 아이는 엄마, 아빠가 모두 테뉴어를 받을 때쯤 나고 자랐다. 여전히 바쁘고 힘들었지만, 둘째 양육은 첫째 때와는 양상이 좀 다를 수밖에 없었다. 이런저런 이유로 첫째 아이는 좀 더 차분하고, 둘째 아이는 좀 더 애교 넘친다.\n한국에서 바로 테뉴어트랙을 시작한 교수님들도 첫 지도 학생 그룹이 기억에 많이 남으실 거다. 서로 혼란스러운 시기를 같이 공부하고 같이 연구하며 헤쳐 나가면서 교수와 학생 모두 성공적으로 커리어에 안착하고 독립적인 학자가 되어 졸업하는 시기를 보내면 서로 미운 정 고운 정 다 들 것이다. 하지만 그 과정에서 겪는 테뉴어 트랙 조교수의 스트레스가 무시무시할 수 있다. 미래에 대한 불확실성, 연구비 확보의 어려움, 연구 성과가 잘 나오지 않을 때 겪는 초조함 등으로 교수는 스트레스를 받고, 어쩌면 학생들에게 불필요하게 모질게 대하는 경우도 있을 테다. 학생들도 그 과정에서 힘들고 스트레스를 많이 받을 테고, 졸업할 때쯤이면 지도교수가 미워질지도 모른다. 첫째 아이를 양육하는 것과 비슷한 일이 생긴다.\n나는 미국에서 15년간 15명의 박사과정 학생을 지도하면서 이 과정을 모두 다 겪고 한국에 왔다. 다양한 유형의 학생을 이미 지도 해 본 적 있으며, 연구 역량도 쌓았고, 인적 네트워크도 갖추었으며, 테뉴어도 받아서 마음 조급할 일들은 많이 줄어들었다. 그래서 여유롭다. 위에서 말한 KAIST의 여러 이점들 때문에, 또 여러 멋진 동료 교수님들의 도움으로 첫해부터 매우 운이 좋게도 연구비에 대한 걱정도 많이 없는 상황이다. 내가 학생들에게 해주고 싶은 걸 충분히 해줄 수 있는 상황인 것 같다.\n이런 심적으로 물적으로 여유 있는 상황에서 학생 지도를 하니, 성실하고 재능 있는 내 학생들이 안 예뻐 보일 리 없다. 학생들을 지도하기 위해 만나는 주간 미팅이 즐겁지 않을 리 없다. 학생들이 조금씩 성장해 나가고 성취를 이뤄 나가는 걸 지켜보는 것이 조마조마하면서도 매우 즐겁다. 학생들에게 아쉬운 소리를 하는 경우가 없는 것은 아니지만, 학생들에게 좀 더 관대한 마음으로 조언을 해 줄 수 있다. 운 좋게 여유로운 상황에서 내 마음에 드는 훌륭한 학생들을 만나게 되었고, 그 과정이 매우 즐겁다. 학생들은 훌륭하고, 나만 잘하면 된다.\n‘숨만 쉬어도 예쁜’ 내 학생들은, 다만 숨을 좀 열심히 쉬어야 하기는 한다. 아직 대학원 1~2년 차들이라 수업 들으면서 숙제도 많은데, 내가 진행하고 있는 연구 프로젝트들도 좀 있고, 개인 연구도 진행해야 한다. 그걸 모두 다 해내야 하는데, 또 내가 신나서 벌리는 일들이 좀 있다. 그런 것들 서포트하느라 힘들어하기도 하지만, 아직까지는 모든 학생들이 다 잘 해나가고 있는 것 같다. 한계점에 가까워질 뻔한 일들도 몇 차례 있었던 것 같은데, 해상도 높은 커뮤니케이션의 도움으로 일단은 잘 지나간 것으로 믿고 있다. (이건 학생들 말도 들어봐야…)\n즐거운 마음으로 학생들을 지도하고 있고, 앞으로 좋은 연구자가 될 수 있도록 성실히 잘 지도해야겠다고 다짐한다. 내가 즐기는 만큼, 내 학생들도 나와 함께 공부하고 연구하는 것을 즐길 수 있으면 좋겠다. 학위 과정 중 언젠가 밑바닥으로 내려가는 학생들도 있을 텐데, 그때도 내가 도움이 될 수 있으면 좋겠다. 5년 뒤에도, 10년 뒤에도 계속 학생 지도하는 것이 이렇게 즐거웠으면 좋겠다는 생각을 많이 하고, 그러기 위해 지금부터 내가 해야 할 일이 무엇인지 고민이 많다.\n…\n셋째가 그렇게 예쁘다던데…",
        "dc:creator": "권창현",
        "comments": "https://thoughts.chkwon.net/happy-advisor/#respond",
        "content": "지난해 8월에 한국에 들어와서 KAIST에서 근무한 지 1년이 지났다. 그동안 국내외에 계신 분들을 만날 때면, 한국에 들어가서 어떠냐, 좋으냐는 질문을 많이 들었고, 그때마다 &#8220;너무 좋아요, 행복해요&#8221;라는 말을 많이도 하고 다녔다. 최근에 &#8216;나는 왜 한국&#46;&#46;&#46;",
        "contentSnippet": "지난해 8월에 한국에 들어와서 KAIST에서 근무한 지 1년이 지났다. 그동안 국내외에 계신 분들을 만날 때면, 한국에 들어가서 어떠냐, 좋으냐는 질문을 많이 들었고, 그때마다 “너무 좋아요, 행복해요”라는 말을 많이도 하고 다녔다. 최근에 ‘나는 왜 한국...",
        "guid": "https://thoughts.chkwon.net/?p=987",
        "categories": [
          "잡생각"
        ],
        "isoDate": "2024-11-10T06:17:06.000Z"
      }
    ]
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권영재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": [
      {
        "creator": "고종범",
        "title": "정말 어려운 비폭력 대화",
        "link": "https://brunch.co.kr/@@24SO/48",
        "pubDate": "Sun, 10 Nov 2024 01:42:07 GMT",
        "author": "고종범",
        "content": "비폭력대화라는 것을 접하게 된 것은 애자일 코칭을 배우면서이다. 애자일 코칭은 팀이나 조직이 애자일 방법론을 도입하고 적용할 때 도와주는 역할을 말한다. 애자일 방법론을 도입한다는 것은 변화를 만드는 것이고 변화에는 저항과 갈등이 발생하기 때문에 이를 해결하기 위한 방법으로 애자일 코칭이란 것을 배우게 되었다. 처음 배웠을 때는 좀 막연함이 있었고 사람들과<img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2F24SO%2Fimage%2FhbYaGt75CRMobQQ2X6fEfYpApz0.png\" width=\"500\" />",
        "contentSnippet": "비폭력대화라는 것을 접하게 된 것은 애자일 코칭을 배우면서이다. 애자일 코칭은 팀이나 조직이 애자일 방법론을 도입하고 적용할 때 도와주는 역할을 말한다. 애자일 방법론을 도입한다는 것은 변화를 만드는 것이고 변화에는 저항과 갈등이 발생하기 때문에 이를 해결하기 위한 방법으로 애자일 코칭이란 것을 배우게 되었다. 처음 배웠을 때는 좀 막연함이 있었고 사람들과",
        "guid": "https://brunch.co.kr/@@24SO/48",
        "isoDate": "2024-11-10T01:42:07.000Z"
      }
    ]
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김상훈",
    "category": "개인",
    "posts": [
      {
        "creator": "김상훈",
        "title": "머스크 X 트럼프",
        "link": "https://interpiler.com/2024/11/08/%eb%a8%b8%ec%8a%a4%ed%81%ac-x-%ed%8a%b8%eb%9f%bc%ed%94%84/",
        "pubDate": "Thu, 07 Nov 2024 23:42:30 +0000",
        "content:encodedSnippet": "22년 10월, 머스크가 약 50조 원에 가까운 돈을 들여 트위터를 인수했을 때, 많은 사람들이 머스크를 비웃었다. 지나치게 비싼 값이라는 이유였다. 실제로 트위터는 그 이후 광고 급감, 매출 급감, 사용자 급감 등 여러 악재를 맞으면서 이런 비난과 조소가 더 우세한 의견이 됐다.\n24년 말이 된 현재, 아무도 머스크의 충동적으로 보였던 결정을 비웃지 못하게 됐다. 머스크는 트위터의 이름을 X로 바꾼 뒤 세계 각국의 정치 지도자들을 X에서 지지하고, 칭송하고, 때로는 비난하며 들었다 놨다 했다. 인도는 테슬라 전기차에 부과하는 관세를 중국 전기차보다 훨씬 낮춰주면서 머스크에게 화답했고, 브라질은 스타링크 사업에 길을 열어줄 정도였다. 무엇보다 머스크는 X를 통해 세계 최고 권력자인 미국 대통령 당선을 직접적으로 도왔다. 기부금 측면에서, 미디어 영향력 측면에서, 그리고 뻔뻔함의 측면에서 모두 전례없는 선거였다.\n무엇보다 중요한 건 트럼프의 당선으로 이 새로운 형태의 금권선거에 면죄부가 주어질 것이란 점. 앞으로 소셜미디어를 인수하거나 독점해 자신이 원하는 메시지를 지지자들 중심으로 확산시키면서 막대한 자본으로 선거에 개입하는 기업가들이 계속 등장해도 이들을 비난하기 어렵게 됐다. 오늘은 공화당의 트럼프 편에 일론 머스크가 섰지만, 내일은 민주당의 누군가 편에 다른 실리콘밸리 아이돌이 선다고 해도 어색하지 않을 일.",
        "dc:creator": "김상훈",
        "comments": "https://interpiler.com/2024/11/08/%eb%a8%b8%ec%8a%a4%ed%81%ac-x-%ed%8a%b8%eb%9f%bc%ed%94%84/#respond",
        "content": "22년 10월, 머스크가 약 50조 원에 가까운 돈을 들여 트위터를 인수했을 때, 많은 사람들이 머스크를 비웃었다. 지나치게 비싼 값이라는 이유였다. 실제로 트위터는 그 이후 광고 급감, 매출 급감, 사용자 급감 등 여러 악재를 맞으면서 이런 비난과 조소가 더 우세한 의견이 됐다. 24년 말이 된 현재, 아무도 머스크의 충동적으로 보였던 결정을 비웃지 못하게 됐다. 머스크는 트위터의 &#8230; <a href=\"https://interpiler.com/2024/11/08/%eb%a8%b8%ec%8a%a4%ed%81%ac-x-%ed%8a%b8%eb%9f%bc%ed%94%84/\" class=\"more-link\">계속 읽기 <span class=\"screen-reader-text\">머스크 X 트럼프</span> <span class=\"meta-nav\">\t</span></a>",
        "contentSnippet": "22년 10월, 머스크가 약 50조 원에 가까운 돈을 들여 트위터를 인수했을 때, 많은 사람들이 머스크를 비웃었다. 지나치게 비싼 값이라는 이유였다. 실제로 트위터는 그 이후 광고 급감, 매출 급감, 사용자 급감 등 여러 악재를 맞으면서 이런 비난과 조소가 더 우세한 의견이 됐다. 24년 말이 된 현재, 아무도 머스크의 충동적으로 보였던 결정을 비웃지 못하게 됐다. 머스크는 트위터의 … 계속 읽기 머스크 X 트럼프",
        "guid": "http://interpiler.com/?p=1526",
        "categories": [
          "That's IT",
          "머스크",
          "트럼프",
          "트위터",
          "X"
        ],
        "isoDate": "2024-11-07T23:42:30.000Z"
      }
    ]
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": [
      {
        "title": "데이터 흐름(Data flow)을 이해해 보는 데 있어 필요한 것은? 짝퉁 개발자처럼 논하기",
        "link": "https://thdev.tech/dataflow/2024/11/09/Data-flow/",
        "pubDate": "Sat, 09 Nov 2024 00:00:00 +0000",
        "content": "<p>제미나이에게 <code class=\"language-plaintext highlighter-rouge\">개발에서 데이터 흐름이란?</code>를 알려달라고 했다.</p>\n\n<blockquote>\n  <p>개발에서 데이터 흐름은 어떤 시스템이나 소프트웨어에서 데이터가 생성되고, 변환되며, 저장되고, 전송되는 과정을 의미합니다. 마치 물이 강을 따라 흐르듯이, 데이터는 시스템 내에서 특정한 경로를 따라 이동하며 가치를 창출합니다.</p>\n</blockquote>\n\n<p>위키백과도 한번 확인해 보았다.</p>\n\n<p><a href=\"https://ko.wikipedia.org/wiki/%EB%8D%B0%EC%9D%B4%ED%84%B0_%ED%9D%90%EB%A6%84\">위키 백과 데이터 흐름 - 링크</a></p>\n\n<blockquote>\n  <p>데이터 흐름(Data flow, 데이터 플로)란 하나의 작업을 수행하기 위하여 실행되는 각각의 세부 작업들 사이에서 자료가 입력되고 출력되는 모습을 의미한다.</p>\n</blockquote>\n\n<p>결국 같은 말이다.</p>\n\n<p>우리가 매우 흔하게 사용하는 데이터 흐름을 가볍게 이해하는 표현으로 서문을 작성해 보았다.</p>\n\n<p>이 글에서 데이터 다양한 데이터 흐름을 이해하는 데 도움이 될만한 내용을 정리해 본 글인데, 실제 함수 위주이니 참고만 한다고 생각하길</p>\n\n<h3>이 글에서는</h3>\n<ul>\n  <li>함수의 blocking vs nonblocking</li>\n  <li>Observer pattern + stream</li>\n  <li>UDF(unidirectional data flow)</li>\n  <li>매우 주관적으로 작성한 글이다.</li>\n  <li>데이터 흐름(Data flow)에 대한 새로운 형태를 만드는 짝퉁 설명이니 재미로 읽기를</li>\n</ul>\n\n<!--more-->\n\n<h2>함수의 blocking vs nonblocking</h2>\n\n<p>함수에는 blocking과 nonblocking으로 구분된다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">fun</span> <span class=\"nf\">main</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"main\"</span><span class=\"p\">)</span>\n    <span class=\"nf\">someA</span><span class=\"p\">()</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"end)\n</span><span class=\"p\">}</span>\n\n<span class=\"k\">fun</span> <span class=\"nf\">someA</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"run some a\"</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>이 함수의 결과는 다음과 같다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">main</span>\n<span class=\"n\">run</span> <span class=\"n\">some</span> <span class=\"n\">a</span>\n<span class=\"n\">end</span>\n</code></pre></div></div>\n\n<p>이유는 간단하다. blocking이기 때문이다.</p>\n\n<p>그럼 아래의 코드는?</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">fun</span> <span class=\"nf\">main</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"main\"</span><span class=\"p\">)</span>\n    <span class=\"nf\">someA</span><span class=\"p\">()</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"end\"</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">fun</span> <span class=\"nf\">someA</span><span class=\"p\">()</span> <span class=\"p\">=</span> <span class=\"nc\">CoroutinesScope</span><span class=\"p\">().</span><span class=\"nf\">launch</span> <span class=\"p\">{</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"run coroutines)\n</span><span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>이 함수의 결과는 다음과 같을 수 있다.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>main\nend\nrun coroutines\n</code></pre></div></div>\n\n<p>이는 nonblocking이니 가능한 결과이지만 end 전에 coroutines이 실행되어 순서대로 나올 순 있다.</p>\n\n<p>여기서의 흐름은 처음 예제는 명확히 순서를 보장한다는 점이고, 후자는 비동기가 필요하기에 순서의 보장이 필요 없는 경우를 말한다.</p>\n\n<p>데이터 흐름에서 가장 중요한 부분은 비동기라고 할 수 있다.</p>\n\n<p><br /></p>\n\n<h3>그럼 아래의 코드는 blocking, nonblocking 중 어느 것일까?</h3>\n\n<p>아래 링크에 포함되어 있는 코드를 그대로 가져왔다.</p>\n\n<p><a href=\"https://kotlinlang.org/api/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/coroutine-scope.html\">coroutineScope - link</a></p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">fun</span> <span class=\"nf\">main</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"nc\">CoroutinesScope</span><span class=\"p\">().</span><span class=\"nf\">launch</span> <span class=\"p\">{</span>\n        <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"main\"</span><span class=\"p\">)</span>\n        <span class=\"nf\">showSomeData</span><span class=\"p\">()</span>\n        <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"end\"</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">suspend</span> <span class=\"k\">fun</span> <span class=\"nf\">showSomeData</span><span class=\"p\">()</span> <span class=\"p\">=</span> <span class=\"nf\">coroutineScope</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">data</span> <span class=\"p\">=</span> <span class=\"nf\">async</span><span class=\"p\">(</span><span class=\"nc\">Dispatchers</span><span class=\"p\">.</span><span class=\"nc\">IO</span><span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"c1\">// &lt;- extension on current scope</span>\n     <span class=\"o\">..</span><span class=\"p\">.</span> <span class=\"n\">load</span> <span class=\"n\">some</span> <span class=\"nc\">UI</span> <span class=\"n\">data</span> <span class=\"k\">for</span> <span class=\"n\">the</span> <span class=\"nc\">Main</span> <span class=\"n\">thread</span> <span class=\"o\">..</span><span class=\"p\">.</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"nf\">withContext</span><span class=\"p\">(</span><span class=\"nc\">Dispatchers</span><span class=\"p\">.</span><span class=\"nc\">Main</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n        <span class=\"nf\">doSomeWork</span><span class=\"p\">()</span>\n        <span class=\"kd\">val</span> <span class=\"py\">result</span> <span class=\"p\">=</span> <span class=\"n\">data</span><span class=\"p\">.</span><span class=\"nf\">await</span><span class=\"p\">()</span>\n        <span class=\"nf\">display</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<ul>\n  <li>main 함수는 blocking</li>\n  <li>main 함수의 CoroutinesScope().launch의 시작점은 nonblocking</li>\n  <li>launch { } 안의 내용은 blocking</li>\n  <li>showSomeData()의 async 시작 부분은 nonblocking</li>\n  <li>showSomeData()의 async 내부는 blocking</li>\n  <li>showSomeData()의 withContext 부분은 blocking</li>\n</ul>\n\n<p>이 코드는 blocking과 nonblocking이 매우 많이 뒤섞여있다.</p>\n\n<p>이런 코드가 아주 흔한 일이다. 여기서 동기와 비동기 부분을 명확히 이해해야 데이터 흐름을 빠르게 파악할 수 있다.</p>\n\n<p>이 코드는 이 글의 핵심은 아니지만 동기와 비동기를 이해하는 데 있어 중요한 코드이며, coroutines은 일반적인 함수의 사용만큼이나 쉽다는 점이다.</p>\n\n<p><br /></p>\n\n<h2>Observer pattern + stream</h2>\n\n<p>다음 문장은 어떤 부분을 설명하는 걸까?</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>물이 흐르고 있다. 이 흐르는 물에 새로운 물줄기를 추가했다.\n</code></pre></div></div>\n\n<p>이 설명은 개발에서 <code class=\"language-plaintext highlighter-rouge\">HotFlow</code>/<code class=\"language-plaintext highlighter-rouge\">HotObserve</code>에 대한 설명일 수 있지만 내가 적었으니 맞다.</p>\n\n<p>여기서 중요한 부분은 무엇일까?</p>\n\n<p>바로 흐름(flow)이다. Observer pattern에서 데이터 흐름을 설명하는 쉬운 방법 중 하나이다.</p>\n\n<p>물이 흐른다는 표현을 적었으니 흐르는구나를 알 수 있고, 지속적인 흐름을 의미할 수 있다.</p>\n\n<p>반대로 흐르지 않는 경우도 있는데 어떻게 설명해 볼 수 있을까?</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>나는 얼음이다. 땡 해주기 전에는 움직일 수 없다.\n</code></pre></div></div>\n\n<p><br /></p>\n\n<h3>Coroutines flow는?</h3>\n\n<p><a href=\"https://kotlinlang.org/docs/flow.html\">Asynchronous Flow - link</a></p>\n\n<blockquote>\n  <p>A suspending function asynchronously returns a single value, but how can we return multiple asynchronously computed values? This is where Kotlin Flows come in.</p>\n</blockquote>\n\n<p>코루틴 flow는 단일 값을 한 번씩 호출하여 사용할 수 있는 suspend 대신 지속적인 흐름을 가지기 위한 개념을 포함한다. 바로 Observer + stream을 포함한다.</p>\n\n<p><br /></p>\n\n<h3>HotFlow/ColdFlow?</h3>\n\n<p>서문에 적은 설명은 오류를 가질 수 있지만 HotFlow/ColdFlow를 각각 설명하기 쉬운 주제라고 생각하여 필자가 주로 설명하는 방식이다.</p>\n\n<p>HotFlow는 두 가지가 존재하는데</p>\n\n<ul>\n  <li>StateFlow</li>\n  <li>SharedFlow</li>\n</ul>\n\n<p>사용법이 다를 뿐 둘 다 HotFlow이다.</p>\n\n<p>ColdFlow는</p>\n\n<ul>\n  <li>flow {}</li>\n  <li>flowOf()</li>\n</ul>\n\n<p>flow의 시작점이다.</p>\n\n<p><br /></p>\n\n<h3>추가로 - O 어떤 걸로 구성되어 있을까?</h3>\n\n<p>이 글에서는 상세한 내용을 알아보기 위해서 적는 글은 아니니 가볍게 가볍게 어떤 구성으로 이루어져 있을까만 적어본다.</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">얼음</code>이거나 <code class=\"language-plaintext highlighter-rouge\">물이 흐르거나</code>로 표현할 수 있었던 이유는 흐르는 물 사이에 새로운 물줄기를 만들거나 얼음을 깨어 새로운 데이터 흐름을 추가할 수 있다는 소리인데</p>\n\n<p>요즘 안드로이드에서는 잘 사용하지 않는 ReactiveX 문서에는 여전히</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>ReactiveX is a combination of the best ideas from\nthe Observer pattern, the Iterator pattern, and functional programming\n</code></pre></div></div>\n\n<p>이라고 표현하고 있다.</p>\n\n<p>이 데이터 흐름을 이해하기 위해서는 결국 <code class=\"language-plaintext highlighter-rouge\">Observer pattern</code>과 <code class=\"language-plaintext highlighter-rouge\">Iterator pattern</code> 만 알아도 충분히 이해할 수 있다는 이야기다.</p>\n\n<p>그럼 안드로이드 개발에서 상태의 기억을 가지는 3가지 나열해 보면 아래와 같다.</p>\n\n<ul>\n  <li>RxJava - Subject 패턴들 4가지가 있으나 상황에 따라 다른 사용을 가짐</li>\n  <li>StateFlow</li>\n  <li>LiveData</li>\n</ul>\n\n<p>이들은 모두 데이터의 제공과 이를 소비하는 패턴으로 만들어져있다.</p>\n\n<p>이때 중요한 부분은 불변으로 데이터를 소비할 수 있도록 만들어주는 데 있다. 불변과 equals/hashCode의 중요성을 각각 확인할 수 있는 관련 글 2개를 링크로 추가한다.</p>\n\n<ul>\n  <li><a href=\"https://haeti.palms.blog/effective-kotlin\">Item 1. 가변성을 제한하라 - 안정성 - link</a></li>\n  <li><a href=\"https://medium.com/@mangbaam/kotlin-java-hashset-hashmap-%EB%82%B4%EB%B6%80-%EA%B5%AC%ED%98%84-%EC%82%B4%ED%8E%B4%EB%B3%B4%EA%B8%B0-032e352546b1\">[Kotlin/Java] HashSet, HashMap 내부 구현 살펴보기 - link</a></li>\n</ul>\n\n<p>추가로 RxJava를 제외한 Flow와 LiveData는 Android에서 라이프 사이클에 따른 처리가 잘 되어있는 반면 RxJava는 직접 처리해야 할 부분이 많고 현재는 레거시로 취급되니 궁금하신 분은 RxJava 관련 문서를 참고하시길</p>\n\n<p><br /></p>\n\n<h2>UDF(unidirectional data flow)</h2>\n\n<p>아키텍처를 적극 사용하는 현재는 데이터 흐름이 복잡할 수밖에 없다. 이를 가장 쉽게 설명할 수 있는 부분이 바로 UDF이다.</p>\n\n<p><a href=\"https://developer.android.com/develop/ui/compose/architecture\">Architecting your Compose UI - UDF 부분 참고 - link</a></p>\n\n<p>UDF는 단방향 데이터 플로우인데, 위에서 설명한 blocking, nonblocking 역시 단방향 플로우를 가진다.</p>\n\n<ul>\n  <li>A 함수를 실행</li>\n  <li>B 함수의 처리</li>\n  <li>다시 A 함수로 돌아와 이어가기</li>\n</ul>\n\n<p>데이터 흐름상 단방향이다.</p>\n\n<p>Observer pattern + stream에서는?</p>\n\n<ul>\n  <li>A 함수를 실행</li>\n  <li>B 함수에 구독을 요청하고, stream으로 데이터 흐름을 전달 받는 대기</li>\n  <li>A 함수로 돌아와 A 함수는 끝나고, Stream의 데이터 흐름을 대기</li>\n</ul>\n\n<p>동기와 비동기가 적절하게 포함되어 있는 형태이다.</p>\n\n<p><br /></p>\n\n<h3>아키텍처에서의 UDF</h3>\n\n<p>UDF는 데이터 흐름을 쉽게 이해하는 데 이를 아주 쉽게 설명한 설명이다.</p>\n\n<p>모든 흐름은 함수의 호출과 그 함수 안에서 새로운 함수의 호출 또는 구독으로 이루어진다. 이를 설명하는 가장 쉬운 방법이 UDF 인 것이다.</p>\n\n<p>그럼 아래의 코드에 대해서 UDF로 설명해 보자.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nd\">@Composable</span>\n<span class=\"k\">fun</span> <span class=\"nf\">Screen</span><span class=\"p\">(</span><span class=\"n\">viewModel</span><span class=\"p\">:</span> <span class=\"nc\">SomeViewModel</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">someUiState</span> <span class=\"k\">by</span> <span class=\"n\">viewModel</span><span class=\"p\">.</span><span class=\"n\">someUiState</span><span class=\"p\">.</span><span class=\"nf\">collectAsStateWithLifecycle</span><span class=\"p\">()</span>\n    \n    <span class=\"nc\">Screen</span><span class=\"p\">(</span>\n        <span class=\"n\">someUiState</span> <span class=\"p\">=</span> <span class=\"n\">someUiState</span><span class=\"p\">,</span>\n        <span class=\"n\">onClick</span> <span class=\"p\">=</span> <span class=\"p\">{</span> <span class=\"n\">viewModel</span><span class=\"p\">.</span><span class=\"nf\">fatchSome</span><span class=\"p\">()</span> <span class=\"p\">},</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">}</span>\n\n<span class=\"nd\">@Composable</span>\n<span class=\"k\">fun</span> <span class=\"nf\">Screen</span><span class=\"p\">(</span>\n    <span class=\"n\">someUiState</span><span class=\"p\">:</span> <span class=\"nc\">SomeUiState</span><span class=\"p\">,</span>\n    <span class=\"n\">onClick</span><span class=\"p\">:</span> <span class=\"p\">()</span> <span class=\"p\">-&gt;</span> <span class=\"nc\">Unit</span><span class=\"p\">,</span>\n<span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"nc\">Button</span><span class=\"p\">(</span>\n        <span class=\"n\">onClick</span> <span class=\"p\">=</span> <span class=\"n\">onClick</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">}</span>\n\n<span class=\"kd\">class</span> <span class=\"nc\">SomeViewModel</span><span class=\"p\">(</span>\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">someRepository</span><span class=\"p\">:</span> <span class=\"nc\">SomeRepository</span><span class=\"p\">,</span>\n<span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">_uiState</span> <span class=\"p\">=</span> <span class=\"nc\">MutableStateFlow</span><span class=\"p\">(</span><span class=\"nc\">SomeUiState</span><span class=\"p\">.</span><span class=\"nc\">Default</span><span class=\"p\">)</span>\n    <span class=\"kd\">val</span> <span class=\"py\">uiState</span> <span class=\"p\">=</span> <span class=\"n\">_uiState</span><span class=\"p\">.</span><span class=\"nf\">asStateFlow</span><span class=\"p\">()</span>\n\n    <span class=\"nf\">init</span> <span class=\"p\">{</span>\n        <span class=\"n\">someRepository</span><span class=\"p\">.</span><span class=\"nf\">flowSome</span><span class=\"p\">()</span>\n            <span class=\"p\">.</span><span class=\"nf\">map</span> <span class=\"p\">{</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"nf\">toState</span><span class=\"p\">()</span> <span class=\"p\">}</span>\n            <span class=\"p\">.</span><span class=\"nf\">onEach</span> <span class=\"p\">{</span> <span class=\"n\">_uiState</span><span class=\"p\">.</span><span class=\"n\">value</span> <span class=\"p\">=</span> <span class=\"n\">it</span> <span class=\"p\">}</span>\n            <span class=\"p\">.</span><span class=\"nf\">launchIn</span><span class=\"p\">(</span><span class=\"n\">viewModelScope</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"k\">fun</span> <span class=\"nf\">fatchSome</span><span class=\"p\">()</span> <span class=\"p\">=</span> <span class=\"n\">viewModelScope</span><span class=\"p\">.</span><span class=\"nf\">launch</span> <span class=\"p\">{</span>\n        <span class=\"n\">someRepository</span><span class=\"p\">.</span><span class=\"nf\">fatchSome</span><span class=\"p\">()</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"kd\">interface</span> <span class=\"nc\">SomeRepository</span> <span class=\"p\">{</span>\n\n    <span class=\"k\">fun</span> <span class=\"nf\">flowSome</span><span class=\"p\">():</span> <span class=\"nc\">Flow</span><span class=\"p\">&lt;</span><span class=\"nc\">SomeEntity</span><span class=\"p\">&gt;</span>\n\n    <span class=\"k\">suspend</span> <span class=\"k\">fun</span> <span class=\"nf\">fatchSome</span><span class=\"p\">()</span>\n<span class=\"p\">}</span>\n\n<span class=\"n\">calss</span> <span class=\"nc\">SomeRepsotiryImpl</span><span class=\"p\">(</span>\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">api</span><span class=\"p\">:</span> <span class=\"nc\">SomeApi</span><span class=\"p\">,</span>\n<span class=\"p\">)</span> <span class=\"p\">:</span> <span class=\"nc\">SomeRepository</span> <span class=\"p\">{</span>\n\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">flowSome</span> <span class=\"p\">=</span> <span class=\"nc\">MutableStateFlow</span><span class=\"p\">&lt;</span><span class=\"nc\">SomeEntity</span><span class=\"p\">?&gt;(</span><span class=\"k\">null</span><span class=\"p\">)</span>\n\n    <span class=\"k\">override</span> <span class=\"k\">fun</span> <span class=\"nf\">flowSome</span><span class=\"p\">():</span> <span class=\"nc\">Flow</span><span class=\"p\">&lt;</span><span class=\"nc\">SomeEntity</span><span class=\"p\">&gt;</span> <span class=\"p\">=</span>\n        <span class=\"n\">flowSome</span><span class=\"p\">.</span><span class=\"nf\">filterNotNull</span><span class=\"p\">()</span>\n\n    <span class=\"k\">override</span> <span class=\"k\">suspend</span> <span class=\"k\">fun</span> <span class=\"nf\">fatchSome</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n        <span class=\"kd\">val</span> <span class=\"py\">resutl</span> <span class=\"p\">=</span> <span class=\"n\">api</span><span class=\"p\">.</span><span class=\"nf\">fatchSome</span><span class=\"p\">()</span>\n        <span class=\"n\">flowSome</span><span class=\"p\">.</span><span class=\"n\">value</span> <span class=\"p\">=</span> <span class=\"n\">result</span><span class=\"p\">.</span><span class=\"nf\">toEntity</span><span class=\"p\">()</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>코드에 대한 설명은 제외하고 데이터 흐름만을 알아보자.</p>\n\n<ul>\n  <li>사용자의 onClick Event를 Composable 함수 Screen에서 발생</li>\n  <li>ViewModel fatchSome() 함수가 호출</li>\n  <li>ViewModel에서는 fatchSome() 함수에서 repository의 fatchSome() 함수를 호출\n    <ul>\n      <li>repository에서는 fatchSome 함수의 응답을 지속적인 흐름을 가지기 위해 flow를 별도로 가진다</li>\n    </ul>\n  </li>\n  <li>repository에서는 someApi를 통해 fatchSome()을 호출한다.</li>\n  <li>응답받은 fatchSome()의 결과를 flowSome에 전달한다.</li>\n  <li>ViewModel에서는 구독 중인 flowSome으로부터 응답을 받고, 상태를 변환하여 UI에 통지하여 UI를 갱신한다.</li>\n</ul>\n\n<p>이 코드는 아주 일반적인 UiState를 서버와의 통신을 통해 갱신하기 위한 부분이다. 여기서 조금 더 나아가면 리엑트의 이펙트까지 포함할 수 있다.</p>\n\n<p>말은 길지만 이 방식은 UDF로 설명하지 않았을 뿐 오래전부터 써오던 방식이다.</p>\n\n<p>그리고 다른 사람들에게 설명하는 가장 간단한 프로세스인데, 필자의 블로그에서도 다양하게 확인할 수 있는 과거의 글들이 많이 있다.</p>\n\n<p>UDF. 단방향을 통해 데이터 흐름을 설명할 수 있다는 부분이 중요한 포인트이다.</p>\n\n<p>이 시점에서 추가로 알아두면 좋은 글들을 나열한다.</p>\n\n<ul>\n  <li><a href=\"https://medium.com/@wisemuji/33910e8f09df\">Jetpack Compose로 UI 조합(Composition)하기 심화 - link</a></li>\n  <li><a href=\"https://thdev.tech/compose/2024/08/04/Android-Compose-Split-Funcation/\">Compose 함수는 어떤 조건으로 나누는것이 좋을까?(Stateful, stateless) - link</a></li>\n  <li><a href=\"https://chanho-study.tistory.com/150\">MVVM에서 MVI로 - link</a></li>\n  <li><a href=\"https://velog.io/@mraz3068/Circuit-Try-Out\">[Android / Compose] Circuit 찍먹 해보기 - link</a></li>\n</ul>\n\n<p>Composable 함수를 어떻게 분리하는 것이 좋을지에 대한 글과 MVI에 대한 설명의 글이다.</p>\n\n<p>그리고 직전에 작성했던 Theme를 다루는 내용도 있으니 함께 보아도 좋을 듯하다.</p>\n\n<ul>\n  <li><a href=\"https://thdev.tech/compose/2024/11/03/GetStream-Theme/\">안드로이드 Theme와 GetStream Theme를 알아보고 CompositionLocalProvider의 역할을 알아본다. - link</a></li>\n</ul>\n\n<p><br /></p>\n\n<h2>서버와의 데이터 흐름</h2>\n\n<p>데이터 흐름의 마지막을 서버와 데이터 흐름을 이야기해 볼 수 있지만 자세한 내용은 없이 어떤 도구를 활용하는지 정도만 이야기해 보려 한다.</p>\n\n<p>클라 입장에서는 서버와의 데이터 통신할 때는 json을 주로 활용한다. 최근에는 protobuf를 활용하는 곳도 많은데 장/단점이 있으니 각각 기술은 서버 개발자와 논의하면 좋다.</p>\n\n<ul>\n  <li>json : <a href=\"https://en.wikipedia.org/wiki/JSON\">JSON(JavaScript Object Notation) - link</a></li>\n  <li>xml : <a href=\"https://en.wikipedia.org/wiki/XML\">Extensible Markup Language (XML) - link</a></li>\n  <li>protobuf : <a href=\"https://en.wikipedia.org/wiki/Protocol_Buffers\">Protocol Buffers (Protobuf) - link</a></li>\n</ul>\n\n<p>데이터 흐름을 얼마나 더 넓게 보는지에 따라 서버에서 제공하는 직전까지의 데이터 흐름으로 설명할 것인지, 이를 넘어가서 설명할 것인지도 정의할 수 있을 것 같다.</p>\n\n<p>우리는 string 형태의 데이터를 주고받는 것이 일반적이지만 결국 이런 데이터는 0/1의 데이터로 변환된다.</p>\n\n<p><br /></p>\n\n<h3>서버까지 포함하여 데이터의 개념은?</h3>\n\n<p>필자는 클라 개발자라 서버에 대해 자세한 이해는 없으니 가볍게 설명해 보겠다.</p>\n\n<ul>\n  <li>클라에서의 데이터 응답을 http 통신을 통해 요청하게 된다.\n    <ul>\n      <li>이때 http는 블로킹 상태로 클라에서는 서버가 응답을 주기 전까지 대기하는데, 이때 클라에서는 UI 상 사용자에게 처리 중임을 알려준다.</li>\n    </ul>\n  </li>\n  <li>서버는 캐싱 상태를 체크하고, DB 서버에 응답을 요청한다.</li>\n  <li>DB 서버는 동기/비동기 상태로 entity를 전달해 주고, 이를 기반으로 클라와 약속한 json 데이터로 변환 후 bloking 상태의 http에 응답해 준다.</li>\n</ul>\n\n<p>클라 입장에서는 nonblocking이겠지만 nonblocking 이후에는 모두 blocking 상태로 서버도 동작한다는 점이다.</p>\n\n<p>서버는 사실상 blocking 작업 상태처럼 보이지만 nonblocking으로 보일 수 있다. 그 안에서 또 nonblocking 작업들이 일어나는 것이다.</p>\n\n<p>모든 처리가 완료되면 클라이언트는 이를 바탕으로 UI에 표현하는 작업을 할 수 있다.</p>\n\n<p>여기서는 아키텍처 개념이 포함될 수 있지만 이 글에서는 다루지 않고, 좀 더 넓은 개념의 아키텍처에 대한 이야기를 준비 중이다.</p>\n\n<p><br /></p>\n\n<h2>데이터 흐름으로 리액트를 이해할 수 있을까?</h2>\n\n<p>리덕스에 대해 제미나이의 응답은 아래와 같다.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>리덕스(Redux)는 자바스크립트 애플리케이션의 상태 관리를 위한 예측 가능한 상태 컨테이너이다.\n쉽게 말해, 애플리케이션의 데이터를 효율적으로 관리하고 예측 가능하게 만들어주는 도구라고 할 수 있다.\n</code></pre></div></div>\n\n<p>이미 많은 안드로이드 개념에서 리덕스 개념이 포함되어 있는데, UiState와 UDF? 부분일 것 같다.</p>\n\n<p>필자가 직접 iOS TCA를 접하고 있는데, 직접 써보고, 설명을 통해 파악한 리덕스 개념은 아래와 같다.</p>\n\n<ul>\n  <li>\n    <p><a href=\"https://github.com/pointfreeco/swift-composable-architecture\">The Composable Architecture - link</a></p>\n  </li>\n  <li>이벤트의 흐름 : 이벤트의 흐름은 최종 사용자가 가장 아래에 있으니 이를 거슬러 올라가듯 설명한다.\n  현재 나의 이벤트가 보이는 화면상이라면 이를 이전 화면에 전달한다. 이런 흐름의 설명이 업스트림으로 설명할 수 있다.</li>\n  <li>데이터 흐름 : 데이터는 위에서 아래로 흘러간다.\n  데이터 최신화 시 아래로 아래로 흘러간다. 이런 데이터 흐름을 통해 내가 필요한 부분을 캐치하고 화면을 갱신할 수 있다.</li>\n</ul>\n\n<p>검색과 짧은 지식으로 정리할 수 있는 개념은 딱 요 정도일 것 같다. Redux의 데이터 흐름 글이 있어 링크를 추가한다.</p>\n\n<p><a href=\"https://velog.io/@jos9187/Redux%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%9D%90%EB%A6%84\">Redux의 데이터 흐름 - link</a></p>\n\n<p>그리고 안드로이드에서 리액트 형태를 가장 잘 구현한 코드가 드로이드 카이기 아닐까 하여 링크를 추가한다.</p>\n\n<ul>\n  <li><a href=\"https://github.com/DroidKaigi/conference-app-2024\">DroidKaigi 2024 official app - link</a></li>\n</ul>\n\n<p><br /></p>\n\n<h2>마무리</h2>\n\n<p>데이터 흐름을 이해한다는 것은 더 많은 것을 볼 수 있고, 파악할 수 있음을 뜻한다고 생각한다.</p>\n\n<p>짝퉁처럼 개념을 이해하는 데 도움이 될 수 있으면 좋겠지만 이 글에서도 알 수 있는데 동기/비동기/ReactiveX 개념까지 알면 이를 통해 리액트의 리덕스 개념도 이해할 수 있는 시점이 된 것 같다.</p>\n\n<p>아직 부족한 부분이 많아서 이 내용으로 모든 걸 다 설명할 순 없지만 어느 정도 충분히 가장 표면적인 내용을 이해하는 데 도움이 되었길.</p>\n\n<p>마지막으로 재웅님의 안드로이드 면접 질문과 관련한 내용 중 compose 개념 설명이 잘 되어있어 링크를 추가한다.</p>\n\n<p><a href=\"https://skydoves.medium.com/top-9-android-developer-interview-questions-you-should-know-05e8fe2acd2c\">Top 9 Android Developer Interview Questions You Should Know - link</a></p>\n",
        "contentSnippet": "제미나이에게 개발에서 데이터 흐름이란?를 알려달라고 했다.\n개발에서 데이터 흐름은 어떤 시스템이나 소프트웨어에서 데이터가 생성되고, 변환되며, 저장되고, 전송되는 과정을 의미합니다. 마치 물이 강을 따라 흐르듯이, 데이터는 시스템 내에서 특정한 경로를 따라 이동하며 가치를 창출합니다.\n위키백과도 한번 확인해 보았다.\n위키 백과 데이터 흐름 - 링크\n데이터 흐름(Data flow, 데이터 플로)란 하나의 작업을 수행하기 위하여 실행되는 각각의 세부 작업들 사이에서 자료가 입력되고 출력되는 모습을 의미한다.\n결국 같은 말이다.\n우리가 매우 흔하게 사용하는 데이터 흐름을 가볍게 이해하는 표현으로 서문을 작성해 보았다.\n이 글에서 데이터 다양한 데이터 흐름을 이해하는 데 도움이 될만한 내용을 정리해 본 글인데, 실제 함수 위주이니 참고만 한다고 생각하길\n이 글에서는\n함수의 blocking vs nonblocking\nObserver pattern + stream\nUDF(unidirectional data flow)\n매우 주관적으로 작성한 글이다.\n데이터 흐름(Data flow)에 대한 새로운 형태를 만드는 짝퉁 설명이니 재미로 읽기를\n함수의 blocking vs nonblocking\n함수에는 blocking과 nonblocking으로 구분된다.\n\nfun main() {\n    println(\"main\")\n    someA()\n    println(\"end)\n}\n\nfun someA() {\n    println(\"run some a\")\n}\n\n\n이 함수의 결과는 다음과 같다.\n\nmain\nrun some a\nend\n\n\n이유는 간단하다. blocking이기 때문이다.\n그럼 아래의 코드는?\n\nfun main() {\n    println(\"main\")\n    someA()\n    println(\"end\")\n}\n\nfun someA() = CoroutinesScope().launch {\n    println(\"run coroutines)\n}\n\n\n이 함수의 결과는 다음과 같을 수 있다.\n\nmain\nend\nrun coroutines\n\n\n이는 nonblocking이니 가능한 결과이지만 end 전에 coroutines이 실행되어 순서대로 나올 순 있다.\n여기서의 흐름은 처음 예제는 명확히 순서를 보장한다는 점이고, 후자는 비동기가 필요하기에 순서의 보장이 필요 없는 경우를 말한다.\n데이터 흐름에서 가장 중요한 부분은 비동기라고 할 수 있다.\n\n그럼 아래의 코드는 blocking, nonblocking 중 어느 것일까?\n아래 링크에 포함되어 있는 코드를 그대로 가져왔다.\ncoroutineScope - link\n\nfun main() {\n    CoroutinesScope().launch {\n        println(\"main\")\n        showSomeData()\n        println(\"end\")\n    }\n}\n\nsuspend fun showSomeData() = coroutineScope {\n    val data = async(Dispatchers.IO) { // <- extension on current scope\n     ... load some UI data for the Main thread ...\n    }\n\n    withContext(Dispatchers.Main) {\n        doSomeWork()\n        val result = data.await()\n        display(result)\n    }\n}\n\n\nmain 함수는 blocking\nmain 함수의 CoroutinesScope().launch의 시작점은 nonblocking\nlaunch { } 안의 내용은 blocking\nshowSomeData()의 async 시작 부분은 nonblocking\nshowSomeData()의 async 내부는 blocking\nshowSomeData()의 withContext 부분은 blocking\n이 코드는 blocking과 nonblocking이 매우 많이 뒤섞여있다.\n이런 코드가 아주 흔한 일이다. 여기서 동기와 비동기 부분을 명확히 이해해야 데이터 흐름을 빠르게 파악할 수 있다.\n이 코드는 이 글의 핵심은 아니지만 동기와 비동기를 이해하는 데 있어 중요한 코드이며, coroutines은 일반적인 함수의 사용만큼이나 쉽다는 점이다.\n\nObserver pattern + stream\n다음 문장은 어떤 부분을 설명하는 걸까?\n\n물이 흐르고 있다. 이 흐르는 물에 새로운 물줄기를 추가했다.\n\n\n이 설명은 개발에서 HotFlow/HotObserve에 대한 설명일 수 있지만 내가 적었으니 맞다.\n여기서 중요한 부분은 무엇일까?\n바로 흐름(flow)이다. Observer pattern에서 데이터 흐름을 설명하는 쉬운 방법 중 하나이다.\n물이 흐른다는 표현을 적었으니 흐르는구나를 알 수 있고, 지속적인 흐름을 의미할 수 있다.\n반대로 흐르지 않는 경우도 있는데 어떻게 설명해 볼 수 있을까?\n\n나는 얼음이다. 땡 해주기 전에는 움직일 수 없다.\n\n\n\nCoroutines flow는?\nAsynchronous Flow - link\nA suspending function asynchronously returns a single value, but how can we return multiple asynchronously computed values? This is where Kotlin Flows come in.\n코루틴 flow는 단일 값을 한 번씩 호출하여 사용할 수 있는 suspend 대신 지속적인 흐름을 가지기 위한 개념을 포함한다. 바로 Observer + stream을 포함한다.\n\nHotFlow/ColdFlow?\n서문에 적은 설명은 오류를 가질 수 있지만 HotFlow/ColdFlow를 각각 설명하기 쉬운 주제라고 생각하여 필자가 주로 설명하는 방식이다.\nHotFlow는 두 가지가 존재하는데\nStateFlow\nSharedFlow\n사용법이 다를 뿐 둘 다 HotFlow이다.\nColdFlow는\nflow {}\nflowOf()\nflow의 시작점이다.\n\n추가로 - O 어떤 걸로 구성되어 있을까?\n이 글에서는 상세한 내용을 알아보기 위해서 적는 글은 아니니 가볍게 가볍게 어떤 구성으로 이루어져 있을까만 적어본다.\n얼음이거나 물이 흐르거나로 표현할 수 있었던 이유는 흐르는 물 사이에 새로운 물줄기를 만들거나 얼음을 깨어 새로운 데이터 흐름을 추가할 수 있다는 소리인데\n요즘 안드로이드에서는 잘 사용하지 않는 ReactiveX 문서에는 여전히\n\nReactiveX is a combination of the best ideas from\nthe Observer pattern, the Iterator pattern, and functional programming\n\n\n이라고 표현하고 있다.\n이 데이터 흐름을 이해하기 위해서는 결국 Observer pattern과 Iterator pattern 만 알아도 충분히 이해할 수 있다는 이야기다.\n그럼 안드로이드 개발에서 상태의 기억을 가지는 3가지 나열해 보면 아래와 같다.\nRxJava - Subject 패턴들 4가지가 있으나 상황에 따라 다른 사용을 가짐\nStateFlow\nLiveData\n이들은 모두 데이터의 제공과 이를 소비하는 패턴으로 만들어져있다.\n이때 중요한 부분은 불변으로 데이터를 소비할 수 있도록 만들어주는 데 있다. 불변과 equals/hashCode의 중요성을 각각 확인할 수 있는 관련 글 2개를 링크로 추가한다.\nItem 1. 가변성을 제한하라 - 안정성 - link\n[Kotlin/Java] HashSet, HashMap 내부 구현 살펴보기 - link\n추가로 RxJava를 제외한 Flow와 LiveData는 Android에서 라이프 사이클에 따른 처리가 잘 되어있는 반면 RxJava는 직접 처리해야 할 부분이 많고 현재는 레거시로 취급되니 궁금하신 분은 RxJava 관련 문서를 참고하시길\n\nUDF(unidirectional data flow)\n아키텍처를 적극 사용하는 현재는 데이터 흐름이 복잡할 수밖에 없다. 이를 가장 쉽게 설명할 수 있는 부분이 바로 UDF이다.\nArchitecting your Compose UI - UDF 부분 참고 - link\nUDF는 단방향 데이터 플로우인데, 위에서 설명한 blocking, nonblocking 역시 단방향 플로우를 가진다.\nA 함수를 실행\nB 함수의 처리\n다시 A 함수로 돌아와 이어가기\n데이터 흐름상 단방향이다.\nObserver pattern + stream에서는?\nA 함수를 실행\nB 함수에 구독을 요청하고, stream으로 데이터 흐름을 전달 받는 대기\nA 함수로 돌아와 A 함수는 끝나고, Stream의 데이터 흐름을 대기\n동기와 비동기가 적절하게 포함되어 있는 형태이다.\n\n아키텍처에서의 UDF\nUDF는 데이터 흐름을 쉽게 이해하는 데 이를 아주 쉽게 설명한 설명이다.\n모든 흐름은 함수의 호출과 그 함수 안에서 새로운 함수의 호출 또는 구독으로 이루어진다. 이를 설명하는 가장 쉬운 방법이 UDF 인 것이다.\n그럼 아래의 코드에 대해서 UDF로 설명해 보자.\n\n@Composable\nfun Screen(viewModel: SomeViewModel) {\n    val someUiState by viewModel.someUiState.collectAsStateWithLifecycle()\n    \n    Screen(\n        someUiState = someUiState,\n        onClick = { viewModel.fatchSome() },\n    )\n}\n\n@Composable\nfun Screen(\n    someUiState: SomeUiState,\n    onClick: () -> Unit,\n) {\n    Button(\n        onClick = onClick,\n    )\n}\n\nclass SomeViewModel(\n    private val someRepository: SomeRepository,\n) {\n    private val _uiState = MutableStateFlow(SomeUiState.Default)\n    val uiState = _uiState.asStateFlow()\n\n    init {\n        someRepository.flowSome()\n            .map { it.toState() }\n            .onEach { _uiState.value = it }\n            .launchIn(viewModelScope)\n    }\n\n    fun fatchSome() = viewModelScope.launch {\n        someRepository.fatchSome()\n    }\n}\n\ninterface SomeRepository {\n\n    fun flowSome(): Flow<SomeEntity>\n\n    suspend fun fatchSome()\n}\n\ncalss SomeRepsotiryImpl(\n    private val api: SomeApi,\n) : SomeRepository {\n\n    private val flowSome = MutableStateFlow<SomeEntity?>(null)\n\n    override fun flowSome(): Flow<SomeEntity> =\n        flowSome.filterNotNull()\n\n    override suspend fun fatchSome() {\n        val resutl = api.fatchSome()\n        flowSome.value = result.toEntity()\n    }\n}\n\n\n코드에 대한 설명은 제외하고 데이터 흐름만을 알아보자.\n사용자의 onClick Event를 Composable 함수 Screen에서 발생\nViewModel fatchSome() 함수가 호출\nViewModel에서는 fatchSome() 함수에서 repository의 fatchSome() 함수를 호출\n    \nrepository에서는 fatchSome 함수의 응답을 지속적인 흐름을 가지기 위해 flow를 별도로 가진다\nrepository에서는 someApi를 통해 fatchSome()을 호출한다.\n응답받은 fatchSome()의 결과를 flowSome에 전달한다.\nViewModel에서는 구독 중인 flowSome으로부터 응답을 받고, 상태를 변환하여 UI에 통지하여 UI를 갱신한다.\n이 코드는 아주 일반적인 UiState를 서버와의 통신을 통해 갱신하기 위한 부분이다. 여기서 조금 더 나아가면 리엑트의 이펙트까지 포함할 수 있다.\n말은 길지만 이 방식은 UDF로 설명하지 않았을 뿐 오래전부터 써오던 방식이다.\n그리고 다른 사람들에게 설명하는 가장 간단한 프로세스인데, 필자의 블로그에서도 다양하게 확인할 수 있는 과거의 글들이 많이 있다.\nUDF. 단방향을 통해 데이터 흐름을 설명할 수 있다는 부분이 중요한 포인트이다.\n이 시점에서 추가로 알아두면 좋은 글들을 나열한다.\nJetpack Compose로 UI 조합(Composition)하기 심화 - link\nCompose 함수는 어떤 조건으로 나누는것이 좋을까?(Stateful, stateless) - link\nMVVM에서 MVI로 - link\n[Android / Compose] Circuit 찍먹 해보기 - link\nComposable 함수를 어떻게 분리하는 것이 좋을지에 대한 글과 MVI에 대한 설명의 글이다.\n그리고 직전에 작성했던 Theme를 다루는 내용도 있으니 함께 보아도 좋을 듯하다.\n안드로이드 Theme와 GetStream Theme를 알아보고 CompositionLocalProvider의 역할을 알아본다. - link\n\n서버와의 데이터 흐름\n데이터 흐름의 마지막을 서버와 데이터 흐름을 이야기해 볼 수 있지만 자세한 내용은 없이 어떤 도구를 활용하는지 정도만 이야기해 보려 한다.\n클라 입장에서는 서버와의 데이터 통신할 때는 json을 주로 활용한다. 최근에는 protobuf를 활용하는 곳도 많은데 장/단점이 있으니 각각 기술은 서버 개발자와 논의하면 좋다.\njson : JSON(JavaScript Object Notation) - link\nxml : Extensible Markup Language (XML) - link\nprotobuf : Protocol Buffers (Protobuf) - link\n데이터 흐름을 얼마나 더 넓게 보는지에 따라 서버에서 제공하는 직전까지의 데이터 흐름으로 설명할 것인지, 이를 넘어가서 설명할 것인지도 정의할 수 있을 것 같다.\n우리는 string 형태의 데이터를 주고받는 것이 일반적이지만 결국 이런 데이터는 0/1의 데이터로 변환된다.\n\n서버까지 포함하여 데이터의 개념은?\n필자는 클라 개발자라 서버에 대해 자세한 이해는 없으니 가볍게 설명해 보겠다.\n클라에서의 데이터 응답을 http 통신을 통해 요청하게 된다.\n    \n이때 http는 블로킹 상태로 클라에서는 서버가 응답을 주기 전까지 대기하는데, 이때 클라에서는 UI 상 사용자에게 처리 중임을 알려준다.\n서버는 캐싱 상태를 체크하고, DB 서버에 응답을 요청한다.\nDB 서버는 동기/비동기 상태로 entity를 전달해 주고, 이를 기반으로 클라와 약속한 json 데이터로 변환 후 bloking 상태의 http에 응답해 준다.\n클라 입장에서는 nonblocking이겠지만 nonblocking 이후에는 모두 blocking 상태로 서버도 동작한다는 점이다.\n서버는 사실상 blocking 작업 상태처럼 보이지만 nonblocking으로 보일 수 있다. 그 안에서 또 nonblocking 작업들이 일어나는 것이다.\n모든 처리가 완료되면 클라이언트는 이를 바탕으로 UI에 표현하는 작업을 할 수 있다.\n여기서는 아키텍처 개념이 포함될 수 있지만 이 글에서는 다루지 않고, 좀 더 넓은 개념의 아키텍처에 대한 이야기를 준비 중이다.\n\n데이터 흐름으로 리액트를 이해할 수 있을까?\n리덕스에 대해 제미나이의 응답은 아래와 같다.\n\n리덕스(Redux)는 자바스크립트 애플리케이션의 상태 관리를 위한 예측 가능한 상태 컨테이너이다.\n쉽게 말해, 애플리케이션의 데이터를 효율적으로 관리하고 예측 가능하게 만들어주는 도구라고 할 수 있다.\n\n\n이미 많은 안드로이드 개념에서 리덕스 개념이 포함되어 있는데, UiState와 UDF? 부분일 것 같다.\n필자가 직접 iOS TCA를 접하고 있는데, 직접 써보고, 설명을 통해 파악한 리덕스 개념은 아래와 같다.\nThe Composable Architecture - link\n이벤트의 흐름 : 이벤트의 흐름은 최종 사용자가 가장 아래에 있으니 이를 거슬러 올라가듯 설명한다.\n  현재 나의 이벤트가 보이는 화면상이라면 이를 이전 화면에 전달한다. 이런 흐름의 설명이 업스트림으로 설명할 수 있다.\n데이터 흐름 : 데이터는 위에서 아래로 흘러간다.\n  데이터 최신화 시 아래로 아래로 흘러간다. 이런 데이터 흐름을 통해 내가 필요한 부분을 캐치하고 화면을 갱신할 수 있다.\n검색과 짧은 지식으로 정리할 수 있는 개념은 딱 요 정도일 것 같다. Redux의 데이터 흐름 글이 있어 링크를 추가한다.\nRedux의 데이터 흐름 - link\n그리고 안드로이드에서 리액트 형태를 가장 잘 구현한 코드가 드로이드 카이기 아닐까 하여 링크를 추가한다.\nDroidKaigi 2024 official app - link\n\n마무리\n데이터 흐름을 이해한다는 것은 더 많은 것을 볼 수 있고, 파악할 수 있음을 뜻한다고 생각한다.\n짝퉁처럼 개념을 이해하는 데 도움이 될 수 있으면 좋겠지만 이 글에서도 알 수 있는데 동기/비동기/ReactiveX 개념까지 알면 이를 통해 리액트의 리덕스 개념도 이해할 수 있는 시점이 된 것 같다.\n아직 부족한 부분이 많아서 이 내용으로 모든 걸 다 설명할 순 없지만 어느 정도 충분히 가장 표면적인 내용을 이해하는 데 도움이 되었길.\n마지막으로 재웅님의 안드로이드 면접 질문과 관련한 내용 중 compose 개념 설명이 잘 되어있어 링크를 추가한다.\nTop 9 Android Developer Interview Questions You Should Know - link",
        "guid": "https://thdev.tech/dataflow/2024/11/09/Data-flow/",
        "isoDate": "2024-11-09T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "VirtualBox 네트워크",
        "link": "https://kangmyounghun.blogspot.com/2024/11/virtualbox.html",
        "pubDate": "2024-11-10T05:02:00.004Z",
        "author": "강명훈",
        "content": "<div>집에서 잘 되는 브리지 모드가 밖에만 나가면 안 돼서 NAT 모드를 쓰는데 VM 복제 시 IP가 바뀌지 않는다. 맥어드레스를 바꿔도 안 됨. machine-id가 같아서 그런가?</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiNV-Xvln_p9C1dmXVmTNiGL5WQYVxIorVE6a1LhkZcc-I6ZD3YcdSFVjZXAh3XWVW68I0JeFkk-CjEsKSOD5vY1gkXO4-HAWGciNXFyLeFdqB4xtDZlDirPDHkqEO2jZhntXXIShCdF_Mefp2GZd6AlabKp1KZlAyBJNMnpCl-fLt_ngS3-9c84eK64Cjs/s795/virtualbox_nat.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"531\" data-original-width=\"795\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiNV-Xvln_p9C1dmXVmTNiGL5WQYVxIorVE6a1LhkZcc-I6ZD3YcdSFVjZXAh3XWVW68I0JeFkk-CjEsKSOD5vY1gkXO4-HAWGciNXFyLeFdqB4xtDZlDirPDHkqEO2jZhntXXIShCdF_Mefp2GZd6AlabKp1KZlAyBJNMnpCl-fLt_ngS3-9c84eK64Cjs/s16000/virtualbox_nat.png\" /></a></div><div></div><span><a name='more'></a></span><div><div><pre><code><div>[root@Snort ~]# ifconfig eth0</div><div>eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;&nbsp; mtu 1500</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet 10.0.2.15&nbsp; netmask 255.255.255.0&nbsp; broadcast 10.0.2.255</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet6 fe80::a00:27ff:fe6b:e0d9&nbsp; prefixlen 64&nbsp; scopeid 0x20&lt;link&gt;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; ether 08:00:27:6b:e0:d9&nbsp; txqueuelen 1000&nbsp; (Ethernet)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX packets 675055&nbsp; bytes 999902873 (953.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX errors 0&nbsp; dropped 0&nbsp; overruns 0&nbsp; frame 0</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX packets 78402&nbsp; bytes 4788435 (4.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX errors 0&nbsp; dropped 0 overruns 0&nbsp; carrier 0&nbsp; collisions 0</div></code></pre></div></div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjDOBwpWHacDeVJeHd4sjv0o7NEjtlc0R0b0K6eAxthyn7t4oAVWgfJvvt8lee2_rDM67KBOExMXOmfxrpcIzDY3D4_2LmnU3Z89Y4leIBSqmVB1sErMEoGlEj-HOGCWhoiqjkVGwRYsk5X3PDfIorBrlazSNwNyi3QlZXBSyFlofgIVvZEoaiU6F-qN_T6/s795/virtualbox_nat2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"531\" data-original-width=\"795\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjDOBwpWHacDeVJeHd4sjv0o7NEjtlc0R0b0K6eAxthyn7t4oAVWgfJvvt8lee2_rDM67KBOExMXOmfxrpcIzDY3D4_2LmnU3Z89Y4leIBSqmVB1sErMEoGlEj-HOGCWhoiqjkVGwRYsk5X3PDfIorBrlazSNwNyi3QlZXBSyFlofgIVvZEoaiU6F-qN_T6/s16000/virtualbox_nat2.png\" /></a></div><div><div><pre><code><div>[root@Snort ~]# ifconfig eth0</div><div>eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;&nbsp; mtu 1500</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet 10.0.2.15&nbsp; netmask 255.255.255.0&nbsp; broadcast 10.0.2.255</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet6 fe80::a00:27ff:fe6b:e0d9&nbsp; prefixlen 64&nbsp; scopeid 0x20&lt;link&gt;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; ether 08:00:27:6b:e0:d9&nbsp; txqueuelen 1000&nbsp; (Ethernet)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX packets 675055&nbsp; bytes 999902873 (953.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX errors 0&nbsp; dropped 0&nbsp; overruns 0&nbsp; frame 0</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX packets 78402&nbsp; bytes 4788435 (4.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX errors 0&nbsp; dropped 0 overruns 0&nbsp; carrier 0&nbsp; collisions 0</div></code></pre></div><br /></div><div><b><span style=\"font-size: x-large;\">NAT Network</span></b></div><div><br /></div><div>도구 &gt; 만들기 &gt; Nat Network 생성.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgsQDsetx-nF5g0uu5_y4bHOoCnIeldiewynH4wiTVu0cZ0KEi-v_Pyq0WEywZyvY9MgmimYmYoGYYpqtSMNsGYPabmM0lxCgCZ87TVeIrfW0sQ4QIRnAaIrS9k7r4QbC-MGxKQSl3zgYXuq92ExaHQcmpWetqQ8zO5bNiRf1Ax9hU2brihpXRuY0dSNwcJ/s904/virtualbox_nat_network.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"593\" data-original-width=\"904\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgsQDsetx-nF5g0uu5_y4bHOoCnIeldiewynH4wiTVu0cZ0KEi-v_Pyq0WEywZyvY9MgmimYmYoGYYpqtSMNsGYPabmM0lxCgCZ87TVeIrfW0sQ4QIRnAaIrS9k7r4QbC-MGxKQSl3zgYXuq92ExaHQcmpWetqQ8zO5bNiRf1Ax9hU2brihpXRuY0dSNwcJ/s16000/virtualbox_nat_network.png\" /></a></div><div><br /></div><div>어댑터 설정을 'NAT -&gt; NAT 네트워크'로 수정. 이후 맥어드레스 변경도 필수.</div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhc0DWCPTEN-rr5xnCYM0LdyhjXbcUZUMank6cVwbOfeT2sH9-OKnOnfvkpmgnjuVP_YIxDihd4iNQIs2PnHF9OiTQN_zvveHrQfkCB_cAJeh_1DuyvR13TeP-Klg-7EQgACBoUmJdnafmCfoT_PKRs7SQXDGHc350Y0m3jEhhCY4QdfTv6o1BRqVuBTdi1/s795/virtualbox_nat_network2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"531\" data-original-width=\"795\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhc0DWCPTEN-rr5xnCYM0LdyhjXbcUZUMank6cVwbOfeT2sH9-OKnOnfvkpmgnjuVP_YIxDihd4iNQIs2PnHF9OiTQN_zvveHrQfkCB_cAJeh_1DuyvR13TeP-Klg-7EQgACBoUmJdnafmCfoT_PKRs7SQXDGHc350Y0m3jEhhCY4QdfTv6o1BRqVuBTdi1/s16000/virtualbox_nat_network2.png\" /></a></div><div><div><pre><code><div>[root@Snort ~]# ifconfig eth0</div><div>eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;&nbsp; mtu 1500</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet 10.0.2.15&nbsp; netmask 255.255.255.0&nbsp; broadcast 10.0.2.255</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet6 fe80::a00:27ff:fe6b:e0d9&nbsp; prefixlen 64&nbsp; scopeid 0x20&lt;link&gt;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; ether 08:00:27:6b:e0:d9&nbsp; txqueuelen 1000&nbsp; (Ethernet)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX packets 675055&nbsp; bytes 999902873 (953.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX errors 0&nbsp; dropped 0&nbsp; overruns 0&nbsp; frame 0</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX packets 78402&nbsp; bytes 4788435 (4.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX errors 0&nbsp; dropped 0 overruns 0&nbsp; carrier 0&nbsp; collisions 0</div></code></pre></div></div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh13CUPx8mNmMYlfofiDXHPW3FEGIR-kihIhLGZy8Qpt0sGHV3cSZuhWSuRjhyOQKo23DXd_zzJp8wjH5LIGBetAJKXjBWtk-9u8p_ADPXHryzIGWbg-mrNF-bOM1C2KD2RQAwjGQySeBIWlXXvrqgrYOHuylqScI3GjRVRFKBe1c7yeS-hj92YlRUK6qW-/s795/virtualbox_nat_network3.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"531\" data-original-width=\"795\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh13CUPx8mNmMYlfofiDXHPW3FEGIR-kihIhLGZy8Qpt0sGHV3cSZuhWSuRjhyOQKo23DXd_zzJp8wjH5LIGBetAJKXjBWtk-9u8p_ADPXHryzIGWbg-mrNF-bOM1C2KD2RQAwjGQySeBIWlXXvrqgrYOHuylqScI3GjRVRFKBe1c7yeS-hj92YlRUK6qW-/s16000/virtualbox_nat_network3.png\" /></a></div><div><div><pre><code><div>[root@Snort ~]# ifconfig eth0</div><div>eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;&nbsp; mtu 1500</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet 10.0.2.4&nbsp; netmask 255.255.255.0&nbsp; broadcast 10.0.2.255</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet6 fe80::a00:27ff:fe6b:e0d9&nbsp; prefixlen 64&nbsp; scopeid 0x20&lt;link&gt;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; ether 08:00:27:6b:e0:d9&nbsp; txqueuelen 1000&nbsp; (Ethernet)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX packets 675055&nbsp; bytes 999902873 (953.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX errors 0&nbsp; dropped 0&nbsp; overruns 0&nbsp; frame 0</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX packets 78402&nbsp; bytes 4788435 (4.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX errors 0&nbsp; dropped 0 overruns 0&nbsp; carrier 0&nbsp; collisions 0</div></code></pre></div><br /></div><div>이 간단한 걸 몰라서 여태 헤맸네<span style=\"font-size: x-small;\">(..)</span></div><div><br /></div>",
        "contentSnippet": "집에서 잘 되는 브리지 모드가 밖에만 나가면 안 돼서 NAT 모드를 쓰는데 VM 복제 시 IP가 바뀌지 않는다. 맥어드레스를 바꿔도 안 됨. machine-id가 같아서 그런가?\n\n\n\n\n\n\n\n[root@Snort ~]# ifconfig eth0\neth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 10.0.2.15  netmask 255.255.255.0  broadcast 10.0.2.255\n        inet6 fe80::a00:27ff:fe6b:e0d9  prefixlen 64  scopeid 0x20<link>\n        ether 08:00:27:6b:e0:d9  txqueuelen 1000  (Ethernet)\n        RX packets 675055  bytes 999902873 (953.5 MiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 78402  bytes 4788435 (4.5 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n\n\n\n\n\n[root@Snort ~]# ifconfig eth0\neth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 10.0.2.15  netmask 255.255.255.0  broadcast 10.0.2.255\n        inet6 fe80::a00:27ff:fe6b:e0d9  prefixlen 64  scopeid 0x20<link>\n        ether 08:00:27:6b:e0:d9  txqueuelen 1000  (Ethernet)\n        RX packets 675055  bytes 999902873 (953.5 MiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 78402  bytes 4788435 (4.5 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n\n\nNAT Network\n\n\n도구 > 만들기 > Nat Network 생성.\n\n\n\n\n\n어댑터 설정을 'NAT -> NAT 네트워크'로 수정. 이후 맥어드레스 변경도 필수.\n\n\n\n\n[root@Snort ~]# ifconfig eth0\neth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 10.0.2.15  netmask 255.255.255.0  broadcast 10.0.2.255\n        inet6 fe80::a00:27ff:fe6b:e0d9  prefixlen 64  scopeid 0x20<link>\n        ether 08:00:27:6b:e0:d9  txqueuelen 1000  (Ethernet)\n        RX packets 675055  bytes 999902873 (953.5 MiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 78402  bytes 4788435 (4.5 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n\n\n\n\n\n\n[root@Snort ~]# ifconfig eth0\neth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 10.0.2.4  netmask 255.255.255.0  broadcast 10.0.2.255\n        inet6 fe80::a00:27ff:fe6b:e0d9  prefixlen 64  scopeid 0x20<link>\n        ether 08:00:27:6b:e0:d9  txqueuelen 1000  (Ethernet)\n        RX packets 675055  bytes 999902873 (953.5 MiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 78402  bytes 4788435 (4.5 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n\n\n이 간단한 걸 몰라서 여태 헤맸네(..)",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-8727583642918527329",
        "isoDate": "2024-11-10T05:02:00.004Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕홍",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김놀부",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "AI 최신 자료 검색 최강자, 퍼플렉시티(Perplexity) 활용법",
        "link": "http://muzbox.tistory.com/483497",
        "pubDate": "Wed, 13 Nov 2024 10:52:30 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483497#entry483497comment",
        "content": "<p data-ke-size=\"size16\">퍼플렉시티(Perplexity AI) 의 독보적인 기능과 활용 방법을 통해 정보 탐색, 연구 분석, 생산성 향상에 도움을 받을 수 있습니다. Copilot 기능과 실시간 업데이트로 업무 효율을 극대화하세요.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"퍼플렉시티 사용법.jpg\" data-origin-width=\"700\" data-origin-height=\"368\"><span data-url=\"https://blog.kakaocdn.net/dn/bWlh8Y/btsKFLYLP34/GoTpVX4zm3YQlFFj840VZK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bWlh8Y/btsKFLYLP34/GoTpVX4zm3YQlFFj840VZK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bWlh8Y/btsKFLYLP34/GoTpVX4zm3YQlFFj840VZK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbWlh8Y%2FbtsKFLYLP34%2FGoTpVX4zm3YQlFFj840VZK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"퍼플렉시티 활용법\" data-filename=\"퍼플렉시티 사용법.jpg\" data-origin-width=\"700\" data-origin-height=\"368\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;최근 몇 년간 인공지능(AI) 기술은 빠르게 발전하며 일상 생활과 업무 환경에 큰 변화를 가져왔습니다. 많은 사람들이 AI 도구에 대해 관심을 갖고 있지만, 여전히 AI 활용에 대한 부정적인 시각도 존재합니다. 저 역시 한때는 AI에 대해 회의적이었으나, <b>Perplexity AI</b>라는 새로운 도구를 사용하면서 생각이 완전히 바뀌었습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 글에서는 Perplexity AI가 어떻게 생산성을 높이고 일상적인 작업에 도움을 주는지, 특히 정보 탐색과 분석에서 어떤 혁신적인 기능을 제공하는지 알아보겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>Perplexity AI란 무엇인가?</b></span></h2>\n<p data-ke-size=\"size16\">Perplexity AI는 \"정보 탐색과 호기심을 위한 스위스 군용 칼\"로 불리며, 사용자의 질문에 대해 방대한 데이터베이스를 통해 실시간으로 답변을 제공합니다. 그 과정에서 정확한 출처를 제시하며, 최신 정보를 반영해 사용자에게 신뢰도 높은 결과를 제공합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>Perplexity AI의 주요 기능</b></span></h3>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>정보 검색 및 분석</b>: 사용자가 질문을 입력하면 AI가 신속하게 관련 데이터를 분석하여 정확한 답변을 제시합니다. 단순한 질문 답변을 넘어 복잡한 데이터 분석까지 가능해, 특히 연구와 학습에 유용합니다.</li>\n<li><b>다양한 AI 모델 지원</b>: 무료 버전과 유료 Pro 버전으로 나뉘어져 있으며, 유료 사용자는 Claude 3.5 Sonnet, GPT-4, Grok-2와 같은 다양한 모델을 선택할 수 있습니다. 이를 통해 특정 작업에 맞는 AI를 활용할 수 있습니다.</li>\n<li><b>문서 업로드 및 분석</b>: Pro 버전에서는 사용자가 문서를 업로드하면 해당 문서의 주요 내용을 요약하고 분석하는 기능도 제공합니다. 이로 인해 대량의 텍스트 데이터를 효율적으로 관리할 수 있습니다.</li>\n</ol>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>Perplexity AI의 차별화된 기능</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>1. 실시간 정보 업데이트와 정확한 출처 제공</b></span></h3>\n<p data-ke-size=\"size16\">많은 AI 도구들이 존재하지만 Perplexity AI는 특히 <b>실시간 정보 업데이트</b> 기능으로 차별화됩니다. 예를 들어, 특정 뉴스나 트렌드에 대해 질문하면 가장 최신의 정보가 반영된 답변을 제공합니다. 또한, 모든 답변에 <b>출처를 명확히 제시</b>하므로 사용자는 제시된 정보를 신뢰하고 참고할 수 있습니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>실시간 업데이트</b>: 검색할 때마다 최신 정보가 반영되어 더 정확한 답변을 제공합니다.</li>\n<li><b>출처 확인 기능</b>: 답변과 함께 관련된 출처를 명시하여 정보의 신뢰도를 높입니다. 특히 연구 논문 작성이나 학술 자료 수집에 유용합니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>2. Copilot 기능을 통한 맞춤형 검색 경험 제공</b></span></h3>\n<p data-ke-size=\"size16\">Perplexity AI의 <b>Copilot 기능</b>은 사용자의 질문에 대해 추가적인 질문을 던져 보다 정교하고 맞춤형 답변을 도출합니다. 이 기능은 사용자가 모호한 질문을 했을 때 추가적인 정보를 요구하여, 사용자가 원래 찾고자 했던 정보를 정확하게 찾아줍니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>개인화된 검색 지원</b>: Copilot이 사용자의 의도를 파악해 구체적인 정보를 제공합니다.</li>\n<li><b>대화형 인터페이스</b>: 질문에 대한 추가 질문을 통해 사용자 맞춤형 검색 결과를 제공합니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>3. 다양한 활용 사례</b></span></h3>\n<p data-ke-size=\"size16\">Perplexity AI는 단순한 검색 도구 이상의 가치를 제공합니다. 특히 다양한 분야에서 유용하게 활용될 수 있습니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>제품 조사</b>: 쇼핑할 때 여러 사이트를 비교하는 대신, Perplexity AI를 사용해 추천 제품을 찾을 수 있습니다. 예를 들어, 반려견 하네스를 찾는 데 사용했을 때, 다양한 리뷰와 평점을 기반으로 최적의 선택을 도와줍니다.</li>\n<li><b>과학적 자료 조사</b>: 운동 프로그램 설계 시, 근거 기반의 자료를 빠르게 수집하고 정리할 수 있습니다. 이를 통해 효과적인 운동 계획을 세우는 데 도움을 받았습니다.</li>\n<li><b>SEO 최적화</b>: 블로그나 웹사이트 콘텐츠 작성 시, 키워드 연구를 통해 더 나은 SEO 성과를 거둘 수 있도록 지원합니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>Perplexity AI 기본 사용법</b></span></h2>\n<p data-ke-size=\"size16\">퍼플렉시티 초기화면은 챗GPT와 비슷합니다. 퍼플렉시티의 기본 옵션은 '웹'검색이나, 모드 선택에서 다양한 옵션으로 사용자 응답 효율을 극대화 할 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"퍼플렉시티 사용법 2.jpg\" data-origin-width=\"823\" data-origin-height=\"443\"><span data-url=\"https://blog.kakaocdn.net/dn/nMTH2/btsKHtWCxh1/5GIOu7R84SrDceDoKkpUek/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/nMTH2/btsKHtWCxh1/5GIOu7R84SrDceDoKkpUek/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/nMTH2/btsKHtWCxh1/5GIOu7R84SrDceDoKkpUek/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FnMTH2%2FbtsKHtWCxh1%2F5GIOu7R84SrDceDoKkpUek%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"퍼플렉시티 사용법 2.jpg\" data-origin-width=\"823\" data-origin-height=\"443\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>Perplexity AI 활용 팁</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>1. 키워드 연구 및 SEO 최적화</b></span></h3>\n<p data-ke-size=\"size16\">Perplexity AI는 단순한 검색 도구를 넘어 <b>SEO 최적화 도구</b>로도 활용될 수 있습니다. 주제에 맞는 핵심 키워드를 찾아내어 콘텐츠의 가독성과 검색 순위를 높이는 데 도움을 줍니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>키워드 분석</b>: 특정 주제와 관련된 트렌드 키워드를 찾아 SEO 전략에 반영할 수 있습니다.</li>\n<li><b>SEO 성과 향상</b>: 블로그 포스팅이나 제품 페이지 최적화에 활용하여 검색 노출을 극대화할 수 있습니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>2. 학술 자료 정리 및 요약</b></span></h3>\n<p data-ke-size=\"size16\">Perplexity AI는 학술 논문이나 연구 자료를 <b>신속하게 분석하고 요약</b>하는 데 탁월합니다. 복잡한 논문을 빠르게 읽고 이해할 수 있어 연구자나 학생들에게 유용한 도구입니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>논문 요약</b>: 방대한 학술 자료를 요약하여 핵심 내용을 빠르게 파악할 수 있습니다.</li>\n<li><b>자료 검증</b>: AI가 제시한 출처를 통해 자료의 신뢰성을 직접 확인할 수 있습니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>3. 소비자 제품 리뷰 분석</b></span></h3>\n<p data-ke-size=\"size16\">Perplexity AI를 사용하면 다양한 리뷰와 평점을 분석하여 <b>소비자 제품 선택</b>에 도움을 받을 수 있습니다. 단순한 평점 비교를 넘어, 사용자 리뷰를 분석해 제품의 강점과 약점을 파악할 수 있습니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>구매 결정 지원</b>: 제품의 장단점을 한눈에 파악하여 현명한 소비 결정을 내릴 수 있습니다.</li>\n<li><b>제품 리뷰 요약</b>: 여러 리뷰를 요약해 시간 절약이 가능합니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>Perplexity AI 프롬프트 예시 모음</b></span></h2>\n<p data-ke-size=\"size16\">Perplexity AI를 최대한 효과적으로 활용하기 위해서는 <b>질문 방식과 프롬프트 설정</b>이 매우 중요합니다. 아래는 다양한 상황에서 활용할 수 있는 <b>프롬프트 예시</b>들을 제시합니다. 이를 통해 더 정확하고 유용한 정보를 빠르게 얻을 수 있습니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>1. 일반 정보 탐색</b></span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"퍼플렉시티 사용법 1.jpg\" data-origin-width=\"1134\" data-origin-height=\"635\"><span data-url=\"https://blog.kakaocdn.net/dn/lRBQ5/btsKHaCZstF/hY2Z8A59kcmNLMgXul22O1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/lRBQ5/btsKHaCZstF/hY2Z8A59kcmNLMgXul22O1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/lRBQ5/btsKHaCZstF/hY2Z8A59kcmNLMgXul22O1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FlRBQ5%2FbtsKHaCZstF%2FhY2Z8A59kcmNLMgXul22O1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"700\" height=\"392\" data-filename=\"퍼플렉시티 사용법 1.jpg\" data-origin-width=\"1134\" data-origin-height=\"635\"/></span></figure>\n</p>\n<h4 data-ke-size=\"size20\">질문 예시:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>\"2024년 웹 디자인 트렌드에 대해 알려줘.\"</li>\n<li>\"최신 스마트폰 모델 비교 분석 부탁해.\"</li>\n<li>\"AI 기반 마케팅 전략의 성공 사례를 설명해줘.\"</li>\n</ul>\n<h4 data-ke-size=\"size20\">프롬프트 팁:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>구체적인 연도나 키워드</b>를 포함해 최신 정보를 요청합니다.</li>\n<li>검색할 분야를 명확히 지정하여 결과의 정확도를 높입니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>2. 제품 리뷰 및 비교 분석</b></span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"퍼플렉시티 사용법 3.jpg\" data-origin-width=\"1121\" data-origin-height=\"592\"><span data-url=\"https://blog.kakaocdn.net/dn/bZzdOu/btsKFC17fgJ/GMeriPAoXk4llV8AykWLgK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bZzdOu/btsKFC17fgJ/GMeriPAoXk4llV8AykWLgK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bZzdOu/btsKFC17fgJ/GMeriPAoXk4llV8AykWLgK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbZzdOu%2FbtsKFC17fgJ%2FGMeriPAoXk4llV8AykWLgK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"퍼플렉시티 사용법 3.jpg\" data-origin-width=\"1121\" data-origin-height=\"592\"/></span></figure>\n</p>\n<h4 data-ke-size=\"size20\">질문 예시:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>\"현재 최고의 게이밍 노트북 추천해줘.\"</li>\n<li>\"무선 이어폰 중 가성비 좋은 제품 목록을 알려줘.\"</li>\n<li>\"반려견용 하네스 중 가장 인기 있는 제품은 무엇이야?\"</li>\n</ul>\n<h4 data-ke-size=\"size20\">프롬프트 팁:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>특정 요구 조건</b>(예: 예산, 기능, 브랜드)을 추가하여 결과를 세분화합니다.</li>\n<li><b>\"가장 평점이 높은\"</b>, <b>\"가성비 좋은\"</b>과 같은 수식어를 활용해 더욱 맞춤형 정보를 얻습니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>3. 학술 자료 분석 및 요약 (학문 모드 설정)</b></span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"퍼플렉시티 사용법 5.jpg\" data-origin-width=\"905\" data-origin-height=\"552\"><span data-url=\"https://blog.kakaocdn.net/dn/JU7vA/btsKGU1s2Vg/RTLV2CBfiVeFLrFaqTmbKk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/JU7vA/btsKGU1s2Vg/RTLV2CBfiVeFLrFaqTmbKk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/JU7vA/btsKGU1s2Vg/RTLV2CBfiVeFLrFaqTmbKk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FJU7vA%2FbtsKGU1s2Vg%2FRTLV2CBfiVeFLrFaqTmbKk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"퍼플렉시티 사용법 5.jpg\" data-origin-width=\"905\" data-origin-height=\"552\"/></span></figure>\n</p>\n<h4 data-ke-size=\"size20\">질문 예시:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>\"최신 비만 치료 방법에 대한 논문 요약해줘.\"</li>\n<li>\"전기 자동차 배터리 기술의 최신 연구 동향을 분석해줘.\"</li>\n<li>\"지속 가능한 에너지의 경제적 영향에 대한 학술 자료 추천해줘.\"</li>\n</ul>\n<h4 data-ke-size=\"size20\">프롬프트 팁:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>\"논문 요약\"</b>, <b>\"학술 자료\"</b> 등의 키워드를 추가해 전문 자료를 빠르게 찾아냅니다.</li>\n<li>특정 주제나 <b>\"연구 결과\"</b>, <b>\"메타 분석\"</b> 등과 같은 구체적인 용어를 사용해 더욱 깊이 있는 정보를 요청합니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>4. SEO 키워드 분석 및 콘텐츠 최적화</b></span></h3>\n<h4 data-ke-size=\"size20\">질문 예시:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>\"IT 블로그를 위한 2024년 SEO 키워드 추천해줘.\"</li>\n<li>\"마케팅 관련 블로그 포스팅에 효과적인 키워드 분석 부탁해.\"</li>\n<li>\"한국어 콘텐츠의 SEO 전략을 제시해줘.\"</li>\n</ul>\n<h4 data-ke-size=\"size20\">프롬프트 팁:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>\"블로그 주제\"</b>, <b>\"타겟 시장\"</b> 등을 명확히 하여 관련성 높은 키워드를 제안받습니다.</li>\n<li><b>\"검색 순위 향상\"</b>, <b>\"구글 SEO 최적화\"</b>와 같은 수식어를 추가해 SEO에 특화된 조언을 받습니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>5. 건강 및 웰니스 조언</b></span></h3>\n<h4 data-ke-size=\"size20\">질문 예시:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>\"근거 기반으로 다이어트 식단 계획 세워줘.\"</li>\n<li>\"중년 남성을 위한 근력 운동 프로그램 추천해.\"</li>\n<li>\"면역력을 높이는 자연적인 방법을 알려줘.\"</li>\n</ul>\n<h4 data-ke-size=\"size20\">프롬프트 팁:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>\"과학적 근거\"</b>, <b>\"증명된 연구\"</b> 등의 키워드를 사용하여 신뢰할 수 있는 정보를 얻습니다.</li>\n<li>특정 건강 상태나 목표(예: 체중 감량, 근력 향상)에 맞춘 프롬프트를 사용합니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>6. Copilot 기능 활용 예시</b></span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"퍼플렉시티 사용법 6.jpg\" data-origin-width=\"964\" data-origin-height=\"445\"><span data-url=\"https://blog.kakaocdn.net/dn/PD3Vg/btsKGNagfBk/6yETkLKvE0j0NA9GZXLBNK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/PD3Vg/btsKGNagfBk/6yETkLKvE0j0NA9GZXLBNK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/PD3Vg/btsKGNagfBk/6yETkLKvE0j0NA9GZXLBNK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FPD3Vg%2FbtsKGNagfBk%2F6yETkLKvE0j0NA9GZXLBNK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"퍼플렉시티 사용법 6.jpg\" data-origin-width=\"964\" data-origin-height=\"445\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">Copilot 기능을 활용하면 <b>추가적인 질문을 통해 검색 결과를 세분화</b>할 수 있습니다.</p>\n<h4 data-ke-size=\"size20\">예시 프롬프트 시나리오:</h4>\n<p data-ke-size=\"size16\"><b>사용자 질문</b>: \"2024년 마케팅 트렌드에 대해 알려줘.\"</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>Copilot 추가 질문: \"B2B 마케팅과 B2C 마케팅 중 어느 분야에 관심이 있나요?\"</li>\n<li><b>답변 후</b>: \"B2B 마케팅 전략에 대해 더 자세히 알려줘.\"</li>\n</ul>\n<p data-ke-size=\"size16\"><b>사용자 질문</b>: \"가장 효과적인 운동 루틴을 추천해줘.\"</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>Copilot 추가 질문: \"체중 감량을 목표로 하나요, 아니면 근력 강화를 목표로 하나요?\"</li>\n<li><b>답변 후</b>: \"근력 강화 운동에 집중하고 싶어.\"</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>7. 비즈니스 전략 및 분석</b></span></h3>\n<h4 data-ke-size=\"size20\">질문 예시:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>\"2024년 스타트업을 위한 효과적인 마케팅 전략 제안해줘.\"</li>\n<li>\"소매업에서 성공적인 고객 유지 전략을 분석해줘.\"</li>\n<li>\"B2B 세일즈를 위한 최신 트렌드를 알려줘.\"</li>\n</ul>\n<h4 data-ke-size=\"size20\">프롬프트 팁:</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>산업 분야</b>(예: IT, 헬스케어, 패션)와 <b>구체적인 전략</b>(예: 마케팅, 세일즈)을 명확히 지정하여 맞춤형 정보를 얻습니다.</li>\n<li><b>\"성공 사례\"</b>, <b>\"최신 트렌드\"</b> 등을 추가하여 깊이 있는 분석을 요청합니다.</li>\n</ul>\n<p data-ke-size=\"size16\">이러한 프롬프트 예시를 참고하여 <b>Perplexity AI</b>를 보다 효과적으로 활용해 보세요. 사용자의 질문 방식에 따라 <b>더 정밀하고 유용한 결과</b>를 얻을 수 있습니다.  </p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>마치며</b></span></h2>\n<p data-ke-size=\"size16\">&nbsp;Perplexity AI를 사용하기 전에는 AI 도구들이 단순한 자동화 도구에 불과하다고 생각했지만, 실제로 사용해 보니 업무 효율을 크게 높일 수 있다는 점을 깨달았습니다. 특히 실시간 정보 업데이트와 Copilot 기능은 정보를 보다 정확하고 빠르게 얻을 수 있도록 도와줍니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;AI 도구를 활용해 일상 업무에서 더 많은 가치를 창출하고 싶다면, Perplexity AI를 직접 사용해 보시길 권장합니다. 여러분도 이 도구를 사용하여 새로운 차원의 생산성을 경험해 보세요!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>Q&amp;A</b></span></h2>\n<h3 data-ke-size=\"size23\">1. Perplexity AI는 무료로 사용할 수 있나요?</h3>\n<p data-ke-size=\"size16\">네, Perplexity AI는 무료로 기본 기능을 제공하며, 유료 Pro 버전을 통해 더 많은 고급 기능을 사용할 수 있습니다. Pro 버전에서는 다양한 AI 모델 선택과 무제한 문서 업로드 분석 기능을 추가로 이용할 수 있습니다.</p>\n<h3 data-ke-size=\"size23\">2. Copilot 기능은 어떻게 활용하나요?</h3>\n<p data-ke-size=\"size16\">Copilot 기능은 사용자의 질문에 대한 추가적인 질문을 통해 보다 정확한 답변을 제공합니다. 이를 통해 보다 맞춤형 검색 결과를 얻을 수 있으며, 특히 모호한 질문에 대해 유용합니다.</p>\n<h3 data-ke-size=\"size23\">3. Perplexity AI는 어떤 상황에서 가장 유용한가요?</h3>\n<p data-ke-size=\"size16\">Perplexity AI는 제품 조사, 학술 자료 분석, SEO 최적화, 소비자 리뷰 분석 등 다양한 상황에서 유용하게 활용할 수 있습니다. 특히 빠르고 정확한 정보 탐색이 필요한 경우에 큰 도움을 줍니다.</p>",
        "contentSnippet": "퍼플렉시티(Perplexity AI) 의 독보적인 기능과 활용 방법을 통해 정보 탐색, 연구 분석, 생산성 향상에 도움을 받을 수 있습니다. Copilot 기능과 실시간 업데이트로 업무 효율을 극대화하세요.\n\n\n \n 최근 몇 년간 인공지능(AI) 기술은 빠르게 발전하며 일상 생활과 업무 환경에 큰 변화를 가져왔습니다. 많은 사람들이 AI 도구에 대해 관심을 갖고 있지만, 여전히 AI 활용에 대한 부정적인 시각도 존재합니다. 저 역시 한때는 AI에 대해 회의적이었으나, Perplexity AI라는 새로운 도구를 사용하면서 생각이 완전히 바뀌었습니다.\n \n이 글에서는 Perplexity AI가 어떻게 생산성을 높이고 일상적인 작업에 도움을 주는지, 특히 정보 탐색과 분석에서 어떤 혁신적인 기능을 제공하는지 알아보겠습니다.\n \nPerplexity AI란 무엇인가?\nPerplexity AI는 \"정보 탐색과 호기심을 위한 스위스 군용 칼\"로 불리며, 사용자의 질문에 대해 방대한 데이터베이스를 통해 실시간으로 답변을 제공합니다. 그 과정에서 정확한 출처를 제시하며, 최신 정보를 반영해 사용자에게 신뢰도 높은 결과를 제공합니다.\n \nPerplexity AI의 주요 기능\n정보 검색 및 분석: 사용자가 질문을 입력하면 AI가 신속하게 관련 데이터를 분석하여 정확한 답변을 제시합니다. 단순한 질문 답변을 넘어 복잡한 데이터 분석까지 가능해, 특히 연구와 학습에 유용합니다.\n다양한 AI 모델 지원: 무료 버전과 유료 Pro 버전으로 나뉘어져 있으며, 유료 사용자는 Claude 3.5 Sonnet, GPT-4, Grok-2와 같은 다양한 모델을 선택할 수 있습니다. 이를 통해 특정 작업에 맞는 AI를 활용할 수 있습니다.\n문서 업로드 및 분석: Pro 버전에서는 사용자가 문서를 업로드하면 해당 문서의 주요 내용을 요약하고 분석하는 기능도 제공합니다. 이로 인해 대량의 텍스트 데이터를 효율적으로 관리할 수 있습니다.\n \nPerplexity AI의 차별화된 기능\n1. 실시간 정보 업데이트와 정확한 출처 제공\n많은 AI 도구들이 존재하지만 Perplexity AI는 특히 실시간 정보 업데이트 기능으로 차별화됩니다. 예를 들어, 특정 뉴스나 트렌드에 대해 질문하면 가장 최신의 정보가 반영된 답변을 제공합니다. 또한, 모든 답변에 출처를 명확히 제시하므로 사용자는 제시된 정보를 신뢰하고 참고할 수 있습니다.\n실시간 업데이트: 검색할 때마다 최신 정보가 반영되어 더 정확한 답변을 제공합니다.\n출처 확인 기능: 답변과 함께 관련된 출처를 명시하여 정보의 신뢰도를 높입니다. 특히 연구 논문 작성이나 학술 자료 수집에 유용합니다.\n2. Copilot 기능을 통한 맞춤형 검색 경험 제공\nPerplexity AI의 Copilot 기능은 사용자의 질문에 대해 추가적인 질문을 던져 보다 정교하고 맞춤형 답변을 도출합니다. 이 기능은 사용자가 모호한 질문을 했을 때 추가적인 정보를 요구하여, 사용자가 원래 찾고자 했던 정보를 정확하게 찾아줍니다.\n개인화된 검색 지원: Copilot이 사용자의 의도를 파악해 구체적인 정보를 제공합니다.\n대화형 인터페이스: 질문에 대한 추가 질문을 통해 사용자 맞춤형 검색 결과를 제공합니다.\n3. 다양한 활용 사례\nPerplexity AI는 단순한 검색 도구 이상의 가치를 제공합니다. 특히 다양한 분야에서 유용하게 활용될 수 있습니다.\n제품 조사: 쇼핑할 때 여러 사이트를 비교하는 대신, Perplexity AI를 사용해 추천 제품을 찾을 수 있습니다. 예를 들어, 반려견 하네스를 찾는 데 사용했을 때, 다양한 리뷰와 평점을 기반으로 최적의 선택을 도와줍니다.\n과학적 자료 조사: 운동 프로그램 설계 시, 근거 기반의 자료를 빠르게 수집하고 정리할 수 있습니다. 이를 통해 효과적인 운동 계획을 세우는 데 도움을 받았습니다.\nSEO 최적화: 블로그나 웹사이트 콘텐츠 작성 시, 키워드 연구를 통해 더 나은 SEO 성과를 거둘 수 있도록 지원합니다.\n \nPerplexity AI 기본 사용법\n퍼플렉시티 초기화면은 챗GPT와 비슷합니다. 퍼플렉시티의 기본 옵션은 '웹'검색이나, 모드 선택에서 다양한 옵션으로 사용자 응답 효율을 극대화 할 수 있습니다.\n\n\n \n \nPerplexity AI 활용 팁\n1. 키워드 연구 및 SEO 최적화\nPerplexity AI는 단순한 검색 도구를 넘어 SEO 최적화 도구로도 활용될 수 있습니다. 주제에 맞는 핵심 키워드를 찾아내어 콘텐츠의 가독성과 검색 순위를 높이는 데 도움을 줍니다.\n키워드 분석: 특정 주제와 관련된 트렌드 키워드를 찾아 SEO 전략에 반영할 수 있습니다.\nSEO 성과 향상: 블로그 포스팅이나 제품 페이지 최적화에 활용하여 검색 노출을 극대화할 수 있습니다.\n2. 학술 자료 정리 및 요약\nPerplexity AI는 학술 논문이나 연구 자료를 신속하게 분석하고 요약하는 데 탁월합니다. 복잡한 논문을 빠르게 읽고 이해할 수 있어 연구자나 학생들에게 유용한 도구입니다.\n논문 요약: 방대한 학술 자료를 요약하여 핵심 내용을 빠르게 파악할 수 있습니다.\n자료 검증: AI가 제시한 출처를 통해 자료의 신뢰성을 직접 확인할 수 있습니다.\n3. 소비자 제품 리뷰 분석\nPerplexity AI를 사용하면 다양한 리뷰와 평점을 분석하여 소비자 제품 선택에 도움을 받을 수 있습니다. 단순한 평점 비교를 넘어, 사용자 리뷰를 분석해 제품의 강점과 약점을 파악할 수 있습니다.\n구매 결정 지원: 제품의 장단점을 한눈에 파악하여 현명한 소비 결정을 내릴 수 있습니다.\n제품 리뷰 요약: 여러 리뷰를 요약해 시간 절약이 가능합니다.\n \nPerplexity AI 프롬프트 예시 모음\nPerplexity AI를 최대한 효과적으로 활용하기 위해서는 질문 방식과 프롬프트 설정이 매우 중요합니다. 아래는 다양한 상황에서 활용할 수 있는 프롬프트 예시들을 제시합니다. 이를 통해 더 정확하고 유용한 정보를 빠르게 얻을 수 있습니다.\n1. 일반 정보 탐색\n\n\n질문 예시:\n\"2024년 웹 디자인 트렌드에 대해 알려줘.\"\n\"최신 스마트폰 모델 비교 분석 부탁해.\"\n\"AI 기반 마케팅 전략의 성공 사례를 설명해줘.\"\n프롬프트 팁:\n구체적인 연도나 키워드를 포함해 최신 정보를 요청합니다.\n검색할 분야를 명확히 지정하여 결과의 정확도를 높입니다.\n2. 제품 리뷰 및 비교 분석\n\n\n질문 예시:\n\"현재 최고의 게이밍 노트북 추천해줘.\"\n\"무선 이어폰 중 가성비 좋은 제품 목록을 알려줘.\"\n\"반려견용 하네스 중 가장 인기 있는 제품은 무엇이야?\"\n프롬프트 팁:\n특정 요구 조건(예: 예산, 기능, 브랜드)을 추가하여 결과를 세분화합니다.\n\"가장 평점이 높은\", \"가성비 좋은\"과 같은 수식어를 활용해 더욱 맞춤형 정보를 얻습니다.\n3. 학술 자료 분석 및 요약 (학문 모드 설정)\n\n\n질문 예시:\n\"최신 비만 치료 방법에 대한 논문 요약해줘.\"\n\"전기 자동차 배터리 기술의 최신 연구 동향을 분석해줘.\"\n\"지속 가능한 에너지의 경제적 영향에 대한 학술 자료 추천해줘.\"\n프롬프트 팁:\n\"논문 요약\", \"학술 자료\" 등의 키워드를 추가해 전문 자료를 빠르게 찾아냅니다.\n특정 주제나 \"연구 결과\", \"메타 분석\" 등과 같은 구체적인 용어를 사용해 더욱 깊이 있는 정보를 요청합니다.\n4. SEO 키워드 분석 및 콘텐츠 최적화\n질문 예시:\n\"IT 블로그를 위한 2024년 SEO 키워드 추천해줘.\"\n\"마케팅 관련 블로그 포스팅에 효과적인 키워드 분석 부탁해.\"\n\"한국어 콘텐츠의 SEO 전략을 제시해줘.\"\n프롬프트 팁:\n\"블로그 주제\", \"타겟 시장\" 등을 명확히 하여 관련성 높은 키워드를 제안받습니다.\n\"검색 순위 향상\", \"구글 SEO 최적화\"와 같은 수식어를 추가해 SEO에 특화된 조언을 받습니다.\n5. 건강 및 웰니스 조언\n질문 예시:\n\"근거 기반으로 다이어트 식단 계획 세워줘.\"\n\"중년 남성을 위한 근력 운동 프로그램 추천해.\"\n\"면역력을 높이는 자연적인 방법을 알려줘.\"\n프롬프트 팁:\n\"과학적 근거\", \"증명된 연구\" 등의 키워드를 사용하여 신뢰할 수 있는 정보를 얻습니다.\n특정 건강 상태나 목표(예: 체중 감량, 근력 향상)에 맞춘 프롬프트를 사용합니다.\n6. Copilot 기능 활용 예시\n\n\nCopilot 기능을 활용하면 추가적인 질문을 통해 검색 결과를 세분화할 수 있습니다.\n예시 프롬프트 시나리오:\n사용자 질문: \"2024년 마케팅 트렌드에 대해 알려줘.\"\nCopilot 추가 질문: \"B2B 마케팅과 B2C 마케팅 중 어느 분야에 관심이 있나요?\"\n답변 후: \"B2B 마케팅 전략에 대해 더 자세히 알려줘.\"\n사용자 질문: \"가장 효과적인 운동 루틴을 추천해줘.\"\nCopilot 추가 질문: \"체중 감량을 목표로 하나요, 아니면 근력 강화를 목표로 하나요?\"\n답변 후: \"근력 강화 운동에 집중하고 싶어.\"\n7. 비즈니스 전략 및 분석\n질문 예시:\n\"2024년 스타트업을 위한 효과적인 마케팅 전략 제안해줘.\"\n\"소매업에서 성공적인 고객 유지 전략을 분석해줘.\"\n\"B2B 세일즈를 위한 최신 트렌드를 알려줘.\"\n프롬프트 팁:\n산업 분야(예: IT, 헬스케어, 패션)와 구체적인 전략(예: 마케팅, 세일즈)을 명확히 지정하여 맞춤형 정보를 얻습니다.\n\"성공 사례\", \"최신 트렌드\" 등을 추가하여 깊이 있는 분석을 요청합니다.\n이러한 프롬프트 예시를 참고하여 Perplexity AI를 보다 효과적으로 활용해 보세요. 사용자의 질문 방식에 따라 더 정밀하고 유용한 결과를 얻을 수 있습니다.  \n \n \n마치며\n Perplexity AI를 사용하기 전에는 AI 도구들이 단순한 자동화 도구에 불과하다고 생각했지만, 실제로 사용해 보니 업무 효율을 크게 높일 수 있다는 점을 깨달았습니다. 특히 실시간 정보 업데이트와 Copilot 기능은 정보를 보다 정확하고 빠르게 얻을 수 있도록 도와줍니다.\n \n AI 도구를 활용해 일상 업무에서 더 많은 가치를 창출하고 싶다면, Perplexity AI를 직접 사용해 보시길 권장합니다. 여러분도 이 도구를 사용하여 새로운 차원의 생산성을 경험해 보세요!\n \nQ&A\n1. Perplexity AI는 무료로 사용할 수 있나요?\n네, Perplexity AI는 무료로 기본 기능을 제공하며, 유료 Pro 버전을 통해 더 많은 고급 기능을 사용할 수 있습니다. Pro 버전에서는 다양한 AI 모델 선택과 무제한 문서 업로드 분석 기능을 추가로 이용할 수 있습니다.\n2. Copilot 기능은 어떻게 활용하나요?\nCopilot 기능은 사용자의 질문에 대한 추가적인 질문을 통해 보다 정확한 답변을 제공합니다. 이를 통해 보다 맞춤형 검색 결과를 얻을 수 있으며, 특히 모호한 질문에 대해 유용합니다.\n3. Perplexity AI는 어떤 상황에서 가장 유용한가요?\nPerplexity AI는 제품 조사, 학술 자료 분석, SEO 최적화, 소비자 리뷰 분석 등 다양한 상황에서 유용하게 활용할 수 있습니다. 특히 빠르고 정확한 정보 탐색이 필요한 경우에 큰 도움을 줍니다.",
        "guid": "http://muzbox.tistory.com/483497",
        "categories": [
          "AI, 미래기술",
          "AI 도구",
          "ai 활용 사례",
          "copilot 기능",
          "perplexity ai",
          "생산성 향상",
          "실시간 업데이트",
          "정보 탐색",
          "퍼플렉시티",
          "퍼플렉시티 사용법",
          "학술 자료 분석"
        ],
        "isoDate": "2024-11-13T01:52:30.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "엑셀의 눈금선 색상을 변경하는 방법",
        "link": "http://muzbox.tistory.com/483496",
        "pubDate": "Mon, 11 Nov 2024 18:47:31 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483496#entry483496comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;Microsoft Excel에서 기본 그리드라인 색상을 변경하는 방법을 소개합니다. 기존의 회색에서 사용자가 원하는 색상으로 설정해, 시각적 효과를 향상시킬 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"엑셀 눈금선 색상 변경 방법.png\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/rEWXm/btsKE1NhK14/ZW5mvf3AUU38kDmgAo5kAk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/rEWXm/btsKE1NhK14/ZW5mvf3AUU38kDmgAo5kAk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/rEWXm/btsKE1NhK14/ZW5mvf3AUU38kDmgAo5kAk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FrEWXm%2FbtsKE1NhK14%2FZW5mvf3AUU38kDmgAo5kAk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"엑셀의 눈금선 색상을 변경하는 방법\" data-filename=\"엑셀 눈금선 색상 변경 방법.png\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;Microsoft Excel을 사용할 때 기본적으로 제공되는 회색 그리드라인을 별로 신경 쓰지 않았던 적이 있으신가요? 저 역시 25년 넘게 Excel을 사용하면서 그리드라인 색상에 대한 생각은 해본 적이 없었어요. 하지만 최근, Excel에서 기본 그리드라인 색상을 자유롭게 변경할 수 있는 설정을 발견했습니다. 이 기능을 활용하면 문서의 가독성을 높이고, 시각적으로 더 매력적인 스프레드시트를 만들 수 있습니다. 오늘은 Excel에서 그리드라인 색상을 변경하는 방법을 소개해 드릴게요.  </p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>Microsoft Excel 그리드라인 색상 변경 방법</b></span></h2>\n<h3 data-ke-size=\"size23\"><b><span style=\"color: #ee2323;\">Excel 옵션 메뉴에서 색상 변경</span></b></h3>\n<p data-ke-size=\"size16\"><b>1. Excel을 열고</b> 상단 메뉴에서 <b>파일(File)</b>을 클릭한 후, <b>옵션(Options)</b>으로 이동합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"01.png\" data-origin-width=\"1203\" data-origin-height=\"687\"><span data-url=\"https://blog.kakaocdn.net/dn/ZnPDh/btsKFn98J9E/SZ3WS9tkYXPsPCcukzjkk1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ZnPDh/btsKFn98J9E/SZ3WS9tkYXPsPCcukzjkk1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/ZnPDh/btsKFn98J9E/SZ3WS9tkYXPsPCcukzjkk1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FZnPDh%2FbtsKFn98J9E%2FSZ3WS9tkYXPsPCcukzjkk1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"01.png\" data-origin-width=\"1203\" data-origin-height=\"687\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>2.고급(Advanced)</b> 탭을 클릭하고, 스크롤을 내려 <b>현재 시트의 표시 옵션(Display options for this worksheet)</b> 항목을 찾습니다. <b>그리드라인 색상(Gridline color)</b> 선택기에서 원하는 색상을 선택합니다. <b>확인(OK)</b> 버튼을 눌러 설정을 저장합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"02.png\" data-origin-width=\"936\" data-origin-height=\"678\"><span data-url=\"https://blog.kakaocdn.net/dn/ofMKS/btsKDUVK4no/xeCD1frU2xjZYCrjKkTDzk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ofMKS/btsKDUVK4no/xeCD1frU2xjZYCrjKkTDzk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/ofMKS/btsKDUVK4no/xeCD1frU2xjZYCrjKkTDzk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FofMKS%2FbtsKDUVK4no%2FxeCD1frU2xjZYCrjKkTDzk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"02.png\" data-origin-width=\"936\" data-origin-height=\"678\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">3. 이제 문서에서 회색 그리드라인이 아닌, 사용자가 설정한 색상이 적용된 것을 볼 수 있습니다. 예를 들어, 빨간색으로 변경하면 다음과 같이 시트가 표시됩니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"03.png\" data-origin-width=\"1203\" data-origin-height=\"687\"><span data-url=\"https://blog.kakaocdn.net/dn/bI9sxR/btsKEeNhgan/Odn4ZfmLXl8lBa0zRKIxJk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bI9sxR/btsKEeNhgan/Odn4ZfmLXl8lBa0zRKIxJk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bI9sxR/btsKEeNhgan/Odn4ZfmLXl8lBa0zRKIxJk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbI9sxR%2FbtsKEeNhgan%2FOdn4ZfmLXl8lBa0zRKIxJk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"03.png\" data-origin-width=\"1203\" data-origin-height=\"687\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>색상 변경 시 유의 사항</b></span></h3>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>이 설정은 <b>현재 작업 중인 시트에만 적용</b>되며, 다른 Excel 파일이나 새로 생성하는 파일에는 적용되지 않습니다.</li>\n<li>다시 기본 색상으로 되돌리고 싶다면, 동일한 경로에서 <b>'자동(Automatic)'</b>으로 변경하면 됩니다.</li>\n<li>이 설정은 모든 최신 Excel 버전에서 사용할 수 있습니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>색상 변경의 활용 방법</b></span></h2>\n<p data-ke-size=\"size16\">Excel에서 그리드라인 색상을 변경하면, 시트의 가독성을 높이고, 중요한 데이터를 강조할 수 있습니다. 특히, 여러 시트 간에 시각적인 구분을 두고 싶을 때 유용하게 활용할 수 있습니다. 예를 들어, 재무 보고서에서 특정 시트의 데이터가 강조되어야 할 때 색상을 다르게 설정해 보세요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>마치며</b></span></h2>\n<p data-ke-size=\"size16\">Excel의 기본 설정을 활용하여 시각적인 변화를 줄 수 있다는 점이 참 흥미롭습니다. 이처럼 작은 변화가 문서의 가독성을 크게 높일 수 있어요. 여러분도 지금 바로 Excel을 열어, 그리드라인 색상을 변경해 보세요!  </p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>Q&amp;A</b></span></h2>\n<p data-ke-size=\"size18\"><b>Q1: Excel 그리드라인 색상을 변경해도 새 파일에는 적용되지 않나요?</b></p>\n<p data-ke-size=\"size18\">네, 현재 변경한 색상은 <b>현재 작업 중인 시트에만 적용</b>되며, 새 파일에는 기본 설정이 적용됩니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\"><b>Q2: 모든 버전의 Excel에서 그리드라인 색상을 변경할 수 있나요?</b></p>\n<p data-ke-size=\"size18\">네, 이 기능은 <b>모든 최신 Excel 버전에서 지원</b>됩니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\"><b>Q3: 그리드라인 색상 변경이 작업 속도에 영향을 줄 수 있나요?</b></p>\n<p data-ke-size=\"size18\">그리드라인 색상 변경은 <b>시각적 효과만 조정</b>할 뿐, Excel의 성능이나 작업 속도에는 영향을 주지 않습니다.</p>",
        "contentSnippet": "Microsoft Excel에서 기본 그리드라인 색상을 변경하는 방법을 소개합니다. 기존의 회색에서 사용자가 원하는 색상으로 설정해, 시각적 효과를 향상시킬 수 있습니다.\n \n\n\n \n Microsoft Excel을 사용할 때 기본적으로 제공되는 회색 그리드라인을 별로 신경 쓰지 않았던 적이 있으신가요? 저 역시 25년 넘게 Excel을 사용하면서 그리드라인 색상에 대한 생각은 해본 적이 없었어요. 하지만 최근, Excel에서 기본 그리드라인 색상을 자유롭게 변경할 수 있는 설정을 발견했습니다. 이 기능을 활용하면 문서의 가독성을 높이고, 시각적으로 더 매력적인 스프레드시트를 만들 수 있습니다. 오늘은 Excel에서 그리드라인 색상을 변경하는 방법을 소개해 드릴게요.  \n \n \nMicrosoft Excel 그리드라인 색상 변경 방법\nExcel 옵션 메뉴에서 색상 변경\n1. Excel을 열고 상단 메뉴에서 파일(File)을 클릭한 후, 옵션(Options)으로 이동합니다.\n\n\n \n \n2.고급(Advanced) 탭을 클릭하고, 스크롤을 내려 현재 시트의 표시 옵션(Display options for this worksheet) 항목을 찾습니다. 그리드라인 색상(Gridline color) 선택기에서 원하는 색상을 선택합니다. 확인(OK) 버튼을 눌러 설정을 저장합니다.\n\n\n \n3. 이제 문서에서 회색 그리드라인이 아닌, 사용자가 설정한 색상이 적용된 것을 볼 수 있습니다. 예를 들어, 빨간색으로 변경하면 다음과 같이 시트가 표시됩니다.\n\n\n \n \n색상 변경 시 유의 사항\n이 설정은 현재 작업 중인 시트에만 적용되며, 다른 Excel 파일이나 새로 생성하는 파일에는 적용되지 않습니다.\n다시 기본 색상으로 되돌리고 싶다면, 동일한 경로에서 '자동(Automatic)'으로 변경하면 됩니다.\n이 설정은 모든 최신 Excel 버전에서 사용할 수 있습니다.\n \n색상 변경의 활용 방법\nExcel에서 그리드라인 색상을 변경하면, 시트의 가독성을 높이고, 중요한 데이터를 강조할 수 있습니다. 특히, 여러 시트 간에 시각적인 구분을 두고 싶을 때 유용하게 활용할 수 있습니다. 예를 들어, 재무 보고서에서 특정 시트의 데이터가 강조되어야 할 때 색상을 다르게 설정해 보세요.\n \n마치며\nExcel의 기본 설정을 활용하여 시각적인 변화를 줄 수 있다는 점이 참 흥미롭습니다. 이처럼 작은 변화가 문서의 가독성을 크게 높일 수 있어요. 여러분도 지금 바로 Excel을 열어, 그리드라인 색상을 변경해 보세요!  \n \n \nQ&A\nQ1: Excel 그리드라인 색상을 변경해도 새 파일에는 적용되지 않나요?\n네, 현재 변경한 색상은 현재 작업 중인 시트에만 적용되며, 새 파일에는 기본 설정이 적용됩니다.\n \nQ2: 모든 버전의 Excel에서 그리드라인 색상을 변경할 수 있나요?\n네, 이 기능은 모든 최신 Excel 버전에서 지원됩니다.\n \nQ3: 그리드라인 색상 변경이 작업 속도에 영향을 줄 수 있나요?\n그리드라인 색상 변경은 시각적 효과만 조정할 뿐, Excel의 성능이나 작업 속도에는 영향을 주지 않습니다.",
        "guid": "http://muzbox.tistory.com/483496",
        "categories": [
          "오피스 프로그램 사용법/엑셀",
          "excel 설정",
          "excel 활용법",
          "엑셀",
          "엑셀 고급 설정",
          "엑셀 눈금선 색상변경",
          "엑셀 눈금선 칼라변경",
          "엑셀 팁"
        ],
        "isoDate": "2024-11-11T09:47:31.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "윈도우11 라이센스 OEM, Retail, Volume 차이와 확인 방법",
        "link": "http://muzbox.tistory.com/483495",
        "pubDate": "Fri, 8 Nov 2024 17:07:33 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483495#entry483495comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;윈도우11 라이센스 종류 확인하는 방법을 알아보세요. OEM, Retail, Volume 라이센스의 차이와 확인 방법을 상세히 안내해 드립니다. 올바른 라이센스 확인으로 정품 인증 문제를 예방하세요!</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"윈도우11 라인센스 확인방법.jpg\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/DQXHg/btsKBTWxCTW/KEE5kQ3xORAbKvECgGXgLk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/DQXHg/btsKBTWxCTW/KEE5kQ3xORAbKvECgGXgLk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/DQXHg/btsKBTWxCTW/KEE5kQ3xORAbKvECgGXgLk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FDQXHg%2FbtsKBTWxCTW%2FKEE5kQ3xORAbKvECgGXgLk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"윈도우11 라이센스 OEM, Retail, Volume 차이와 확인 방법\" data-filename=\"윈도우11 라인센스 확인방법.jpg\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;여러분은 윈도우11을 사용하면서 자신의 <b>윈도우 라이센스 종류</b>가 무엇인지 궁금해 본 적 있으신가요?   새로운 PC를 구입했거나 중고로 PC를 구매할 경우, 설치된 윈도우가 <b>정품인지 확인</b>하는 것은 매우 중요합니다. 특히, 라이센스 종류에 따라 PC 변경 시 재설치 가능 여부나 사용 제한이 달라질 수 있기 때문에, 자신이 보유한 라이센스 유형을 정확히 파악하는 것이 필요합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;윈도우11 라이센스는 OEM, Retail, Volume 라이센스로 크게 나뉘며, 각 유형마다 특징이 다릅니다. 이 글에서는 <b>윈도우11 라이센스 종류를 쉽게 확인하는 방법</b>을 단계별로 안내하고, 각 라이센스의 차이점을 설명해 드리겠습니다. 이 정보를 통해 여러분의 PC 라이센스를 더욱 효율적으로 관리하고 활용할 수 있기를 바랍니다.  </p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>윈도우11 라이센스 종류 이해하기</b></span></h2>\n<p data-ke-size=\"size16\">윈도우11의 라이센스는 사용 목적과 배포 방식에 따라 크게 <b>OEM</b>, <b>Retail</b>, <b>Volume</b>의 세 가지로 구분됩니다. 각 라이센스 유형은 설치, 재설치, PC 변경 시의 사용 제한 조건이 다릅니다. 아래에서 각각의 라이센스 유형을 자세히 설명드리겠습니다.</p>\n<h3 data-ke-size=\"size23\"><b><span style=\"color: #ee2323;\">  1. OEM 라이센스</span></b></h3>\n<p data-ke-size=\"size16\">OEM(Original Equipment Manufacturer) 라이센스는 주로 <b>PC 제조사</b>에서 사전에 설치된 상태로 제공되는 윈도우 버전입니다. 여러분이 새로 구입한 노트북이나 데스크탑 컴퓨터에는 대부분 이 OEM 라이센스가 포함되어 있을 것입니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>특징 및 사용 제한</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>특정 PC 하드웨어에 종속되며, <b>해당 PC에서만 사용 가능</b>합니다.</li>\n<li>만약 메인보드와 같은 주요 하드웨어를 교체하면 라이센스가 무효화될 수 있습니다.</li>\n<li>재설치는 가능하지만, 동일한 PC 내에서만 가능합니다.</li>\n</ul>\n</li>\n<li><b>장점</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>초기 설정이 완료된 상태로 제공되므로, 별도의 설치 과정 없이 바로 사용할 수 있어 <b>편리합니다</b>.</li>\n<li>상대적으로 저렴한 가격으로 제공됩니다.</li>\n</ul>\n</li>\n<li><b>단점</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>다른 PC로 <b>라이센스를 이전할 수 없으므로</b> 중고 PC를 구매할 때 주의해야 합니다.</li>\n<li>PC를 교체하거나 하드웨어를 업그레이드할 경우 <b>추가 라이센스 구매</b>가 필요할 수 있습니다.</li>\n</ul>\n</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>  2. Retail(리테일) 라이센스</b></span></h3>\n<p data-ke-size=\"size16\">리테일 라이센스는 일반 사용자들이 <b>마이크로소프트 스토어</b>나 공식 판매처에서 직접 구매할 수 있는 버전입니다. <b>가정용 사용자</b>나 <b>프리랜서</b>에게 가장 적합한 라이센스로, 기존 PC에서 새로운 PC로 <b>자유롭게 이전이 가능합니다</b>.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>특징 및 사용 제한</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>여러 번 재설치 가능하며, <b>다른 PC로 라이센스를 이전</b>할 수 있습니다.</li>\n<li>정품 인증을 받은 후에도 다른 PC로 이동할 수 있지만, <b>동시에 두 대의 PC에서 사용할 수는 없습니다</b>.</li>\n</ul>\n</li>\n<li><b>장점</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>PC 변경 시 <b>자유롭게 라이센스 이전</b>이 가능하므로, 새로운 PC를 구매하더라도 추가 비용이 들지 않습니다.</li>\n<li>고객 지원 및 업데이트가 보장되므로, <b>문제 발생 시 마이크로소프트의 지원</b>을 받을 수 있습니다.</li>\n</ul>\n</li>\n<li><b>단점</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>OEM 라이센스에 비해 <b>가격이 높습니다</b>.</li>\n<li>온라인 구매 시 가짜 라이센스에 주의해야 합니다.</li>\n</ul>\n</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>  3. Volume(볼륨) 라이센스</b></span></h3>\n<p data-ke-size=\"size16\">볼륨 라이센스는 주로 <b>기업이나 교육 기관</b>에서 대량으로 구매하는 라이센스 방식입니다. 대규모로 운영되는 조직에서 여러 대의 PC에 윈도우를 설치할 수 있도록 지원합니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>특징 및 사용 제한</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>여러 대의 PC에 동일한 라이센스 키를 사용하여 <b>대량 배포</b>할 수 있습니다.</li>\n<li>특정 기간 동안 유효한 <b>정품 인증 서버(KMS)</b>를 사용하여 인증합니다.</li>\n</ul>\n</li>\n<li><b>장점</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>대량 구매 시 비용을 절감</b>할 수 있어, IT 예산이 제한된 기업에 유리합니다.</li>\n<li>중앙 집중식 관리가 가능해, <b>조직 내 PC의 일괄 관리 및 유지보수</b>가 편리합니다.</li>\n</ul>\n</li>\n<li><b>단점</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>개인 사용자에게는 구매 및 사용이 <b>제한됩니다</b>.</li>\n<li>기간 만료 시 정품 인증이 해제되므로, <b>정기적인 갱신이 필요</b>합니다.</li>\n</ul>\n</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>윈도우11 라이센스 종류 확인 방법</b></span></h2>\n<p data-ke-size=\"size16\">이제 자신의 윈도우11 라이센스 종류를 확인하는 방법을 소개하겠습니다. 특히, 중고 PC를 구매했거나 라이센스를 이전할 계획이 있을 때 유용하게 사용할 수 있는 팁입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">윈도우11에서 라이센스 종류를 확인하는 가장 쉬운 방법 중 하나는 <b>명령 프롬프트(CMD)</b>를 사용하는 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>Step 1</b>: <code>윈도우 검색창</code>에 <code>cmd</code>를 입력한 후, '명령 프롬프트'를 <b>관리자 권한으로 실행</b>합니다. ▼</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"01.png\" data-origin-width=\"800\" data-origin-height=\"457\"><span data-url=\"https://blog.kakaocdn.net/dn/beUhuL/btsKCwGD3yg/J4wLLH8OOxwNkcmkTqAXJ1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/beUhuL/btsKCwGD3yg/J4wLLH8OOxwNkcmkTqAXJ1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/beUhuL/btsKCwGD3yg/J4wLLH8OOxwNkcmkTqAXJ1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbeUhuL%2FbtsKCwGD3yg%2FJ4wLLH8OOxwNkcmkTqAXJ1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"01.png\" data-origin-width=\"800\" data-origin-height=\"457\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\"><br /><b>Step 2</b><span style=\"letter-spacing: 0px;\">: 아래의 명령어를 입력한 후 Enter를 누릅니다. ▼</span></p>\n<pre class=\"jboss-cli\" style=\"letter-spacing: 0px;\"><code>slmgr /dli</code></pre>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>결과</b>: 몇 초 후 팝업 창이 열리며, <b>설치된 라이센스의 종류</b>(OEM, Retail, Volume)가 표시됩니다.</li>\n</ul>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"02.png\" data-origin-width=\"800\" data-origin-height=\"438\"><span data-url=\"https://blog.kakaocdn.net/dn/vksGi/btsKC3qnPfU/WxFYCJysaVCmCi7uKa9vE0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/vksGi/btsKC3qnPfU/WxFYCJysaVCmCi7uKa9vE0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/vksGi/btsKC3qnPfU/WxFYCJysaVCmCi7uKa9vE0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FvksGi%2FbtsKC3qnPfU%2FWxFYCJysaVCmCi7uKa9vE0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"02.png\" data-origin-width=\"800\" data-origin-height=\"438\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>마치며</b></span></h2>\n<p data-ke-size=\"size16\">윈도우11 라이센스 종류를 정확히 파악하는 것은 PC 사용 시 매우 중요합니다. 특히, 새로 구매한 PC의 라이센스가 정품인지 확인하거나 기존 PC를 업그레이드할 때 유용하게 활용할 수 있습니다. 이번 기회에 여러분의 윈도우 라이센스 상태를 확인하여 불필요한 비용 낭비를 줄여보세요!  </p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>Q&amp;A</b></span></h2>\n<h3 data-ke-size=\"size23\">Q1. OEM 라이센스를 Retail 라이센스로 변경할 수 있나요?</h3>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>직접 변경할 수는 없지만, <b>Retail 라이센스를 추가 구매</b>하여 새롭게 설치할 수는 있습니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\">Q2. 윈도우11 라이센스를 다른 PC로 이전할 수 있나요?</h3>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>Retail 라이센스는 가능하지만, <b>OEM 라이센스는 특정 PC에 종속되므로 이전이 불가능</b>합니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\">Q3. 중고 PC 구매 시 정품 인증 상태를 확인하려면 어떻게 해야 하나요?</h3>\n<p data-ke-size=\"size16\">명령 프롬프트에서 <code>slmgr /dli</code> 명령어를 사용하여 <b>정품 여부와 라이센스 종류를 확인</b>하세요.</p>",
        "contentSnippet": "윈도우11 라이센스 종류 확인하는 방법을 알아보세요. OEM, Retail, Volume 라이센스의 차이와 확인 방법을 상세히 안내해 드립니다. 올바른 라이센스 확인으로 정품 인증 문제를 예방하세요!\n\n\n \n 여러분은 윈도우11을 사용하면서 자신의 윈도우 라이센스 종류가 무엇인지 궁금해 본 적 있으신가요?   새로운 PC를 구입했거나 중고로 PC를 구매할 경우, 설치된 윈도우가 정품인지 확인하는 것은 매우 중요합니다. 특히, 라이센스 종류에 따라 PC 변경 시 재설치 가능 여부나 사용 제한이 달라질 수 있기 때문에, 자신이 보유한 라이센스 유형을 정확히 파악하는 것이 필요합니다.\n \n 윈도우11 라이센스는 OEM, Retail, Volume 라이센스로 크게 나뉘며, 각 유형마다 특징이 다릅니다. 이 글에서는 윈도우11 라이센스 종류를 쉽게 확인하는 방법을 단계별로 안내하고, 각 라이센스의 차이점을 설명해 드리겠습니다. 이 정보를 통해 여러분의 PC 라이센스를 더욱 효율적으로 관리하고 활용할 수 있기를 바랍니다.  \n \n윈도우11 라이센스 종류 이해하기\n윈도우11의 라이센스는 사용 목적과 배포 방식에 따라 크게 OEM, Retail, Volume의 세 가지로 구분됩니다. 각 라이센스 유형은 설치, 재설치, PC 변경 시의 사용 제한 조건이 다릅니다. 아래에서 각각의 라이센스 유형을 자세히 설명드리겠습니다.\n  1. OEM 라이센스\nOEM(Original Equipment Manufacturer) 라이센스는 주로 PC 제조사에서 사전에 설치된 상태로 제공되는 윈도우 버전입니다. 여러분이 새로 구입한 노트북이나 데스크탑 컴퓨터에는 대부분 이 OEM 라이센스가 포함되어 있을 것입니다.\n특징 및 사용 제한\n\n특정 PC 하드웨어에 종속되며, 해당 PC에서만 사용 가능합니다.\n만약 메인보드와 같은 주요 하드웨어를 교체하면 라이센스가 무효화될 수 있습니다.\n재설치는 가능하지만, 동일한 PC 내에서만 가능합니다.\n장점\n\n초기 설정이 완료된 상태로 제공되므로, 별도의 설치 과정 없이 바로 사용할 수 있어 편리합니다.\n상대적으로 저렴한 가격으로 제공됩니다.\n단점\n\n다른 PC로 라이센스를 이전할 수 없으므로 중고 PC를 구매할 때 주의해야 합니다.\nPC를 교체하거나 하드웨어를 업그레이드할 경우 추가 라이센스 구매가 필요할 수 있습니다.\n \n  2. Retail(리테일) 라이센스\n리테일 라이센스는 일반 사용자들이 마이크로소프트 스토어나 공식 판매처에서 직접 구매할 수 있는 버전입니다. 가정용 사용자나 프리랜서에게 가장 적합한 라이센스로, 기존 PC에서 새로운 PC로 자유롭게 이전이 가능합니다.\n특징 및 사용 제한\n\n여러 번 재설치 가능하며, 다른 PC로 라이센스를 이전할 수 있습니다.\n정품 인증을 받은 후에도 다른 PC로 이동할 수 있지만, 동시에 두 대의 PC에서 사용할 수는 없습니다.\n장점\n\nPC 변경 시 자유롭게 라이센스 이전이 가능하므로, 새로운 PC를 구매하더라도 추가 비용이 들지 않습니다.\n고객 지원 및 업데이트가 보장되므로, 문제 발생 시 마이크로소프트의 지원을 받을 수 있습니다.\n단점\n\nOEM 라이센스에 비해 가격이 높습니다.\n온라인 구매 시 가짜 라이센스에 주의해야 합니다.\n \n  3. Volume(볼륨) 라이센스\n볼륨 라이센스는 주로 기업이나 교육 기관에서 대량으로 구매하는 라이센스 방식입니다. 대규모로 운영되는 조직에서 여러 대의 PC에 윈도우를 설치할 수 있도록 지원합니다.\n특징 및 사용 제한\n\n여러 대의 PC에 동일한 라이센스 키를 사용하여 대량 배포할 수 있습니다.\n특정 기간 동안 유효한 정품 인증 서버(KMS)를 사용하여 인증합니다.\n장점\n\n대량 구매 시 비용을 절감할 수 있어, IT 예산이 제한된 기업에 유리합니다.\n중앙 집중식 관리가 가능해, 조직 내 PC의 일괄 관리 및 유지보수가 편리합니다.\n단점\n\n개인 사용자에게는 구매 및 사용이 제한됩니다.\n기간 만료 시 정품 인증이 해제되므로, 정기적인 갱신이 필요합니다.\n \n윈도우11 라이센스 종류 확인 방법\n이제 자신의 윈도우11 라이센스 종류를 확인하는 방법을 소개하겠습니다. 특히, 중고 PC를 구매했거나 라이센스를 이전할 계획이 있을 때 유용하게 사용할 수 있는 팁입니다.\n \n윈도우11에서 라이센스 종류를 확인하는 가장 쉬운 방법 중 하나는 명령 프롬프트(CMD)를 사용하는 것입니다.\n \nStep 1: 윈도우 검색창에 cmd를 입력한 후, '명령 프롬프트'를 관리자 권한으로 실행합니다. ▼\n\n\n\nStep 2: 아래의 명령어를 입력한 후 Enter를 누릅니다. ▼\nslmgr /dli\n결과: 몇 초 후 팝업 창이 열리며, 설치된 라이센스의 종류(OEM, Retail, Volume)가 표시됩니다.\n\n\n \n마치며\n윈도우11 라이센스 종류를 정확히 파악하는 것은 PC 사용 시 매우 중요합니다. 특히, 새로 구매한 PC의 라이센스가 정품인지 확인하거나 기존 PC를 업그레이드할 때 유용하게 활용할 수 있습니다. 이번 기회에 여러분의 윈도우 라이센스 상태를 확인하여 불필요한 비용 낭비를 줄여보세요!  \n \n \nQ&A\nQ1. OEM 라이센스를 Retail 라이센스로 변경할 수 있나요?\n직접 변경할 수는 없지만, Retail 라이센스를 추가 구매하여 새롭게 설치할 수는 있습니다.\nQ2. 윈도우11 라이센스를 다른 PC로 이전할 수 있나요?\nRetail 라이센스는 가능하지만, OEM 라이센스는 특정 PC에 종속되므로 이전이 불가능합니다.\nQ3. 중고 PC 구매 시 정품 인증 상태를 확인하려면 어떻게 해야 하나요?\n명령 프롬프트에서 slmgr /dli 명령어를 사용하여 정품 여부와 라이센스 종류를 확인하세요.",
        "guid": "http://muzbox.tistory.com/483495",
        "categories": [
          "윈도우 사용팁/윈도우11 사용법",
          "OEM",
          "pc 라이센스 이전",
          "powershell 활용",
          "retail",
          "라이센스 확인",
          "명령어 사용법",
          "볼륨 라이센스",
          "윈도우 설정",
          "윈도우11",
          "정품 인증"
        ],
        "isoDate": "2024-11-08T08:07:33.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "(RULIWEB`Д')/",
        "title": "[MULTI] 못내 아쉬운 그러나 대체불가능한, 삼국지 8 리메이크",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2266",
        "pubDate": "Fri, 08 Nov 2024 19:49:24 +0900",
        "author": "(RULIWEB`Д')/",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/24/11/08/1930b62f0c14c329e.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2024-11-08T10:49:24.000Z"
      },
      {
        "creator": "「RULIWEB」",
        "title": "[MULTI] 모부삼 이상 콜드워 미만, 콜 오브 듀티: 블랙 옵스 6",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2265",
        "pubDate": "Thu, 07 Nov 2024 19:43:18 +0900",
        "author": "「RULIWEB」",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i1.ruliweb.com/thumb/24/11/07/1930630bba84cacdc.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2024-11-07T10:43:18.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": [
      {
        "title": "경력이 쌓이면서 했던 고민들과 깨달은 것들",
        "link": "https://zzsza.github.io/diary/2024/11/08/thoughts-and-learnings-in-careers/",
        "pubDate": "Fri, 08 Nov 2024 00:00:00 +0000",
        "content": "<ul>\n  <li>이 글은 경력이 쌓이면서 했던 고민들과 깨달은 내용에 대해 작성한 글입니다</li>\n  <li>멘토링 때 종종 이 주제들에 대한 질문을 받아 글을 작성해봅니다</li>\n  <li>키워드 : 경력, 커리어, 개발자 커리어, 성장</li>\n</ul>\n\n<hr />\n\n<h1 id=\"살다-보면-우리는-고민이-생긴다\">살다 보면 우리는 고민이 생긴다</h1>\n<ul>\n  <li>회사에 다니기 전에는 취업 자체에 대한 고민만 했다. 이 시기엔 취업이 되느냐, 어떤 회사에 가느냐 등을 집중적으로 고민했던 것 같음</li>\n  <li>그러나 회사에 가면, 새로운 문제들이 생기기 시작함\n    <ul>\n      <li>회사에서 어떻게 일을 할 것인가?</li>\n      <li>어떻게 인정받을 수 있을까?</li>\n      <li>사람들과 어떻게 지내야 할까?</li>\n      <li>앞으로의 커리어는 어떻게 될까?</li>\n      <li>갑자기 어떤 일도 하기 싫은 번아웃이 온다면 어떻게 해야 할까?</li>\n      <li>내가 회사에서 일을 잘하는지 확인하려면?</li>\n    </ul>\n  </li>\n  <li>위 사례 외에도 굉장히 다양한 종류의 고민들이 생길 수 있고, 멘토링을 할 때 자주 나오는 주제들이다</li>\n  <li>자주 나오는 질문이나 했던 생각들을 정리하려고 한다</li>\n  <li>자세한 이야기를 하기 전에, <strong>이런 고민을 하는 것 자체가 문제가 아니고 내가 발전하려는 향상심이 있기에 생기는 현상</strong>이라고 생각\n    <ul>\n      <li>이런 생각이 드는 것이 당연하니 너무 걱정하지 않으셨으면 좋겠어요</li>\n      <li>이 글의 내용은 제 생각이 맞다는 관점이 아닌, 제가 어떻게 생각했는지를 담은 글입니다. 보시고 다른 생각이 드시면 ‘글쓴이는 이렇게 생각했구나’ 이렇게 생각해 주시면 좋을 것 같아요</li>\n    </ul>\n  </li>\n</ul>\n\n<hr />\n\n<p><br />\n<br /></p>\n\n<h2 id=\"1-좋은-커리어란-무엇일까-앞으로-어떻게-발전해야-할까\">1) 좋은 커리어란 무엇일까? 앞으로 어떻게 발전해야 할까?</h2>\n<ul>\n  <li>생각하게 된 배경\n    <ul>\n      <li>대략 2-3년 차에 많이 생각하는 주제(그러나 그 이후에도 이 고민은 계속된다. 답은 없고, 환경이 변하기 때문. 연차가 쌓이면 새로운 환경에 가고 새로운 의사 결정을 하게 될 수 있음)</li>\n      <li>입사하고 초반엔 새로운 일들이 많아서 해당 내용들을 습득하고, 주어진 일을 하나씩 하면서 정신없이 보냄\n        <ul>\n          <li>그러다가 1, 2년이 지나고 일이 익숙해질 때쯤 커리어에 대해 고민함</li>\n        </ul>\n      </li>\n      <li>이런 고민을 하게 된 배경은 다양하게 존재할 수 있는데, 업무가 지루하다고 생각하거나, 스스로가 생각하는 이 직무가 해야 하는 일이 정의되어 있지만 그걸 안하 고 있어서 고민하는 경우도 있음</li>\n      <li>아마 일이 즐겁고, 보람차고 프로젝트를 잘 진행하고 있다면 이런 고민은 하지 않을 가능성이 존재</li>\n      <li>컨퍼런스에서 발표를 보거나, 외부 요소(취업 시장이 어렵다는 이야기), 친구들과의 비교 등을 통해 이런 고민을 하게 될 수도 있음</li>\n    </ul>\n  </li>\n  <li>제 생각\n    <ul>\n      <li><strong>이 직무를 왜 시작하게 되었는지가 중요하고, 나에 대한 인지(메타인지)</strong>가 있으면 더 깊은 고민을 할 수 있음\n        <ul>\n          <li>내가 이 직무를 왜 하고 싶었는지, 초심은 무엇이었는지 등</li>\n          <li>내가 처음 원했던 방향을 계속 고수해야 한다는 생각은 아니고, 내가 최초의 방향을 잘 생각하고 있는지 고민하며, 그 이후 자신의 경험을 얹어서 새로운 길로 가야 할지 정리하는 것도 괜찮음</li>\n        </ul>\n      </li>\n      <li>살다 보면 초심을 잊고 살아가는 경우가 많고, 초심에 대한 내용을 블로그 등에 작성하고 지속적으로 보는 것도 좋다고 생각함</li>\n      <li><strong>좋은 커리어의 기준은 누가 정해주는 것이 아니라 스스로가 정의해야 함</strong>\n        <ul>\n          <li>다른 사람이 좋다는 A라는 기준이 나중에 시간이 흐르면 다르게 될 수도 있음. 과거의 시기와 요즘은 또 다르게 생각할 수도 있음</li>\n          <li>학생이나 신입은 경험이 없어서 기준이 적을 수 있고, 이럴 땐 다른 사람의 의견을 들어보기도 하는 것도 다 한 번쯤 경험함\n            <ul>\n              <li>그러나 나의 경험을 늘리면서 나만의 생각, 기준을 만들게 됨</li>\n            </ul>\n          </li>\n          <li>일반적으로 많이 나오는 연봉, 워라밸, 동료 등도 중요할 수 있지만 나의 근본적인 욕구나 이 직무를 선택한 이유에 따라 다를 수 있음\n            <ul>\n              <li>인정 욕구가 큰 사람에겐 워라밸보단 내 인정이 더 중요할 수 있음. 인정받기 위해 회사에서 성과를 높이려고 하고, 열심히 일하는 것이 즐거울 수 있음</li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n      <li>제가 생각하는 좋은 커리어는 <strong>“직무 하나에 나를 한정하지 말고 여러 경험을 하는 것. 문제 해결에 집중하는 것. 꾸준하게 계속 무언가를 시도하는 것”</strong>\n        <ul>\n          <li>여러 경험을 하다 보면 하고 싶지 않은 일을 할 수도 있지만, 그런 일도 경험으로 생각하는 편</li>\n          <li>다른 사람들이 하지 않았던 여러 경험들이 합쳐지면 나만의 고유한 영역이 될 수 있다. 제너럴한 영역을 여러 개가 있고, 각 영역을 아주 잘하면 그게 또 새로운 스페셜이 될 수 있다고 생각함</li>\n          <li>직무 관점에서도 MLOps나 Analytics Engineer가 하나의 직무에서 시작된 것이 아닌 다른 직무에서 확장되면서 생기는 직무라고 볼 수 있는데, 이와 유사하다고 생각</li>\n        </ul>\n      </li>\n      <li>저도 고민했던 시기가 있었음. 레트리카에서 데이터 분석가, 데이터 엔지니어 일을 조금씩 했었고 쏘카에선 데이터 분석가, 데이터 과학자, 머신러닝 엔지니어, 데이터 엔지니어, Engineering Manager 등을 경험했는데 너무 여러 가지를 경험해서 고민되기도 했지만 <strong>회사에서 요구하는 나의 역할을 최대한 잘 수행해 보자고 생각함</strong>\n        <ul>\n          <li>여러 경험을 했기에 직무의 협업 구조를 알 수 있고, 어떻게 프로젝트를 시작해야 할지, 사업부에선 어떤 관점으로 생각하는지 등을 모두 이해하게 됨</li>\n          <li>조직을 키우는 경험도 해보면서, 조직의 규모에 따라 어떤 방식으로 운영해야 할지에 대해 고민을 할 수 있게 되었음</li>\n        </ul>\n      </li>\n      <li><strong>때론 지금 하는 행동들에 너무 의지를 부여하지 않아도 괜찮았음. 시간이 지나서 그 의미를 찾는 경우도 있었음</strong>\n        <ul>\n          <li>의미를 너무 찾다가 시간이 지나갈 수도 있다는 이야기. 과거에 했던 것을 생각해보니 의미를 찾은 경우도 있기에 너무 의미를 찾는데 오래 걸린다면 잠시 실행해보는 것도 좋은 방법이라 생각(<strong>의미와 실행의 적절한 밸런스가 중요</strong>하다고 생각)</li>\n        </ul>\n      </li>\n      <li><strong>좋은 커리어의 기준은 시간의 흐름에 따라 다를 수 있다. 내가 어떤 결정을 할지 기준을 가지고 있는지가 더 중요할 수 있음</strong></li>\n      <li>저는 연차별로 성장의 정의가 다 달랐음. 1-2년 차의 성장은 나의 성장, 3-6년차의 성장은 팀과 조직의 성장, 그 이후의 성장은 잘 회복하며 지금 현상 유지하기가 성장이였음. 지금의 성장도 다른 방향으로 가는 중</li>\n    </ul>\n\n    <p><img src=\"https://www.dropbox.com/s/wc0hktxf2q9sher/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-11-08%20%EC%98%A4%ED%9B%84%203.39.30.png?raw=1\" /></p>\n\n    <ul>\n      <li>정리하면 <strong>좋은 커리어의 정의는 내가 하는 것이고, 타인이 정해주지 않음. 나에 대해 생각을 해보고 나의 기준을 만드는 것을 추천함. 또한 시간의 흐름에 따라 성장은 달라질 수 있고 과거의 경험들이 갑자기 깨달음을 주는 경우도 있으니 걱정하지 말고 지금 순간을 잘 지내는 것을 추천함</strong></li>\n    </ul>\n  </li>\n</ul>\n\n<hr />\n\n<p><br />\n<br /></p>\n\n<h2 id=\"2-데이터-과학자-데이터-분석가-데이터-직무의-고민-커리어를-어떻게-발전해야-할까\">2) 데이터 과학자, 데이터 분석가. 데이터 직무의 고민. 커리어를 어떻게 발전해야 할까?</h2>\n<ul>\n  <li>생각하게 된 배경\n    <ul>\n      <li>데이터 과학자나 데이터 분석가는 직무의 구분이 명확하지 않아 많은 사람들이 혼란스러워함(저도 과거에 그랬고, 요즘 커리어를 준비하는 분들도 여전히 혼란스러워함)\n        <ul>\n          <li><a href=\"https://zzsza.github.io/diary/2021/02/21/various-data-jobs/\">다양한 데이터 분석 직군</a> 글을 보면 직무의 이름으로 판단하지 말고 실제 하는 일을 기반으로 판단하라고 작성했음</li>\n        </ul>\n      </li>\n      <li>1번의 고민(좋은 커리어)와 연결되는 부분인데 데이터 직무는 데이터 분석가지만 하는 일이 회사마다 정말 다양함\n        <ul>\n          <li>어떤 회사에선 데이터 엔지니어링을 하면서 인프라도 구축해야 하고,</li>\n          <li>어떤 회사에선 대시보드 제작 위주로 진행되고</li>\n          <li>어떤 회사에선 데이터 추출 요청 위주의 업무가 진행되기도 함</li>\n          <li>위 상황과 더불어 데이터 관련 컨퍼런스에서 보면 다른 사람들은 멋진 업무 위주로 하는 것 같아서 자신과 업무를 비교하게 되는 경우도 존재</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n  <li>제 생각\n    <ul>\n      <li>이럴 때 현타가 오고 이직 준비를 할 수 있음</li>\n      <li>그러나 저는 데이터 관련 어떤 업무를 하더라도, 회사에서 필요한 업무라고 생각함. 다만 회사의 조직 규모의 차이가 있거나 데이터 문화의 차이가 존재할 뿐. 그 시기에 내가 다니고 있을 뿐이라 생각함</li>\n      <li>데이터 문화가 아직 잘 정착하지 못했다면 직접 데이터를 추출해서 제공해야 할 수 있고, 대시보드도 데이터 직무가 만들어야 할 수 있음\n        <ul>\n          <li>이런 상황은 왜 만들어지고, 개선하려면 어떻게 해야 할까?를 고민하는 것도 좋다고 생각</li>\n          <li>그럼 조직의 규모가 점점 커지면서 그 안에서 필요한 역할들이 무엇인지 알 수 있게 됨</li>\n          <li>이 부분은 국가의 발전, 역사 공부를 하면서 어떻게 해야 더 좋은 조직의 구조를 갖출 수 있을까를 생각했음</li>\n        </ul>\n      </li>\n      <li>이왕 업무를 진행할 때, <strong>너무 부정적으로 생각하는 것보다 이 업무를 한국 또는 세상에서 제일 잘하려면 어떻게 해야 할지를 고민함</strong>\n        <ul>\n          <li>단순 데이터 추출도 정말 빠르게 잘하려면? =&gt; 데이터를 잘 정리해 두는 것도 필요하고, 마트를 만드는 것도 필요하고, 쿼리를 실수 없이 작성하는 것도 필요</li>\n          <li>하나의 Task도 더 구체적으로 쪼개보면 필요한 역량이 여러 가지고, 그것을 더 잘하도록 시도할 수 있음</li>\n          <li>게임에서 하기 싫은 노가다 퀘스트를 하는 느낌일 수 있지만, 이런 퀘스트가 있어야 다음 퀘스트를 수월하게 진행할 수 있다고 생각함</li>\n        </ul>\n      </li>\n      <li><strong>다른 사람과 비교하는 순간 자존감이 떨어질 수 있음. 왜냐하면 비교 대상이 대부분 자신보다 더 좋은 상황인 사람과 비교하는 경우가 더 많기 때문</strong>\n        <ul>\n          <li>컨퍼런스에서 발표하는 내용은 부정적인 것보단 긍정적인 것, 인사이트가 있는 것을 주로 발표할 수 있음. 그리고 그 발표가 그 사람의 전부가 아니라 특정 단면을 공유한 것일 수 있음</li>\n          <li><strong>다른 사람의 길이 아닌, 그냥 나의 길을 가보자고 생각하는 것을 추천</strong></li>\n          <li>내 이야기를 영화로 치면 지금 기승전결에서 중간에 있다고 생각하고, 어려운 상황이 나오면 역시 영화에 위기 한번 와야지! 이런 생각을 하곤 함</li>\n        </ul>\n      </li>\n      <li>LLM이 발전하면서 1인 생산성이 늘어나고, 단순한 데이터 추출은 LLM으로 대체하려는 시도가 엄청 많이 존재함. 조만간 SQL 작성은 데이터 직무의 일이 아닐 수 있을 것 같음\n        <ul>\n          <li>대신 데이터 직무가 무엇을 해야 할까? 생각해 보면 사내의 컨설턴트 역할이 될 수도 있고, 데이터 문화를 만드는 역할, 의사 결정을 위주로 하는 역할 등 다양한 역할이 나올 수 있음</li>\n          <li>그러나 미래에도 과거처럼 작은 규모에선 직접 쿼리를 작성하는 시기도 있을 수 있음. 그래서 너무 걱정하는 것보단, 지금 하는 일을 잘하게 되면 나중에 도움이 되지 않을까 싶음</li>\n        </ul>\n      </li>\n      <li>커리어는 점진적으로 발전할 수 있으므로, 너무 조급하게 생각하지 말고 지금 할 수 있는 일부터 점진적으로 하는 것을 추천</li>\n      <li>저도 시간이 지나서 8년 차가 되었음. 그동안의 경험이 아직도 생생한데 시간이 참 빠름.\n        <ul>\n          <li>커리어 초반, 학생 시절엔 <strong>‘내가 될까?’</strong>에 집중했고 가능성이 있는지에 대한 질문을 많이 했음</li>\n          <li>그러다가 경력을 쌓으면서 <strong>‘내가 뭐가 될까’</strong>에 집중했음. 뭐가에 집중하면서 어떻게 해야 할까를 고민했음</li>\n          <li>그러다가 요즘은 <strong>‘내가 뭐든 되네’</strong>라는 생각을 함. 시간이 지나면 무엇이든 된다. 특정 시기에 내가 노력하지 않아도 회사의 업무를 하면서 경험이 쌓이고 있음. 혹은 내 개인 삶의 경험을 풍성하게 만들 수도 있는 것\n            <ul>\n              <li>무엇이든 되니 너무 걱정하지 말고 지금 하고 싶은 것이 뭘까, 어떻게 시간을 보낼까를 고민하고 하나씩 해보는 것이 좋지 않을까 싶음</li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n      <li><strong>저는 ‘커리어의 목표가 무엇인가요?’라는 질문을 받으면 딱히 없고 그냥 오늘같이 하루하루 잘 보내는 것이 목표라고 말함. 장기적인 비전은 있으면 좋지만, 너무 큰 목표같이 느껴질 수 있어서 현실적인 오늘을 잘 살려고 함</strong></li>\n      <li><strong>직무 관점에서 너무 직무 하나에 매몰되지 말고, 내가 얼마나 회사에 기여할 수 있고 사람들에게 도움을 줄 수 있을지를 생각하며 이 기준이 확장될 수 있는 기준으로 일하고 있음</strong></li>\n      <li>정리하면 <strong>어떤 일을 하더라도 회사에서 제일 잘하고, 세계에서 제일 잘하려면 어떻게 해야할까를 생각하면서 나의 길을 가려고 함. 좋은 커리어의 정의는 내가 하는 것이므로 내가 어떻게 하고 싶은지에 기반해서 하나씩 실행함. 직무에 한정되는 사람이 되지 말고 직무를 넘어서는 사람이 되려고 함</strong></li>\n    </ul>\n  </li>\n</ul>\n\n<hr />\n\n<p><br />\n<br /></p>\n\n<h2 id=\"3-좋은-선택-의사-결정이란-무엇일까\">3) 좋은 선택, 의사 결정이란 무엇일까?</h2>\n<ul>\n  <li>생각하게 된 배경\n    <ul>\n      <li>의사 결정이 중요하다는 것은 많이 듣는데 그걸 어떻게 잘하는가에 대해서는 배운 적이 적음. 그러다 보니 How를 고민하게 됨</li>\n      <li>멘토링 때도 종종 받는 질문으로 가장 중요한 순간의 선택, 후회하는 선택 등의 질문을 받음\n        <ul>\n          <li>아마 좋은 의사 결정, 좋은 선택하는 방법을 물어보는 질문이었던 것 같음</li>\n        </ul>\n      </li>\n      <li>의사 결정이 뭔가 한 번에 잘 돼야 할 것 같고, 틀리면 안 될 것 같은 고정 관념이 있었음</li>\n    </ul>\n  </li>\n  <li>제 생각\n    <ul>\n      <li>일단 저는 과거의 선택에 크게 연연하지 않는 성격. 과거 성격을 만약 돌릴 수 있다면 생각을 계속할 것 같은데, 그게 아니니까 현실을 직시한다. 그래서 과거 이야기를 물어봐도 잘 떠오르진 않음</li>\n      <li>이렇게 된 계기를 생각해 보면 20대 중반부터 뭘 해도 잘 되는 경험이 없었음. 실패, 불합격 등이 많았는데 그게 너무 많아지니까 오히려 현실을 너무 낙관하지 않고 적절한 상태로 바라보곤 했다. 그러다가 니체 책을 보고 니체의 사상에 영감을 받음</li>\n      <li>우선 “좋은” 이란 부분에 대한 정의가 필요함. 좋다라는 것은 상황에 따라 다를 수 있고, 구체적으로 정의가 된다면 지표로 나올 수 있음. 다만 지표로 나오지 않는다고 하면 너무 “좋은”에 집중하지 않으려고 함</li>\n      <li><strong>어떤 결정을 할 때, 들뜨지 않고 객관적으로 생각함</strong>\n        <ul>\n          <li>만약 지표로 표시할 수 있다면 지표를 정의한다. 숫자로 특정 상황을 표시하고, 이게 더 좋아지면 간다 등</li>\n          <li><strong>이 숫자가 높아질 때, 낮아질 때 어떤 Action을 할지 생각</strong>한다. 이런 과정을 Mental Simulation이라 부름\n            <ul>\n              <li><strong>멘탈 시뮬레이션은 특정 행동을 하는 것을 상상하고, 행동하기 전에 예상되는 결과를 시뮬레이션하는 능력</strong></li>\n              <li><strong>멘탈 시뮬레이션을 한다면 특정 순간의 지표가 좋지 않아도, 오르기 위해 어떤 것을 해야 할지 생각했으므로 다시 또 실행하면 됨</strong></li>\n            </ul>\n          </li>\n          <li>과거에 아쉬움이 있다면, 한 번 더 시도해서 아쉬움을 타파하면 그만이 아닐까 생각</li>\n          <li>한 번에 잘 되었던 적이 없어서 이 생각을 기본적으로 가지고 있는 것 같음</li>\n        </ul>\n      </li>\n      <li><strong>어떤 경험을 하고, 주기적으로 회고를 하면서 고민한다</strong>. 이 순간에 내가 왜 이 선택을 했지? 이때 뭐가 중요하다고 생각했지?\n        <ul>\n          <li>그 당시 기록이 있다면 그 기록을 보면서 다음엔 어떻게 해볼까를 고민한다</li>\n        </ul>\n      </li>\n      <li><strong>의사 결정 자체에 집중하는 것보다, 의사 결정을 대하는 태도나 의사 결정을 하는 과정에 신경을 쓰게 됨</strong></li>\n      <li><a href=\"https://inf.run/jfWT\">PM을 위한 데이터 리터러시</a> 강의에 의사 결정 파트가 있는데, 그때 의사 결정 TIP을 다음과 같이 공유했음\n        <ul>\n          <li>(1) 답을 내린다는 표현 대신 베팅한다는 표현하기 : 답을 내린다는 것은 너무 부담이 생김</li>\n          <li>(2) 에너지 레벨 고려하기 : 결정을 내리는 과정은 에너지를 많이 소모한다. 에너지를 덜 소모하며 결정할 방법을 고민함(같이 진행하기 등)</li>\n          <li>(3) 당연한 것은 없다 : 당연하다고 생각하지 말고 항상 다시 고민해 보기</li>\n          <li>(4) 개인적인 의사 결정에선 과감히 도전하는 것도 방법 : 회사에서 결정하는 것은 보수적으로 갈 수 있지만, 개인 관점에선 개방적으로 해보는 것도 방법. 이런 시도가 나의 안전지대(Comfort Zone)를 넘어설 수 있게 됨</li>\n          <li>(5) 결정했으면 그 결정이 좋은 결과를 내도록 노력하기 : 결정하고 아무것도 안 하는 것이 아닌 그게 되도록 하는 것이 중요함</li>\n          <li>(6) 사람은 결정으로 인한 실패를 피하고 싶은 성향이 있다 : 결과에 대해 받아들이고, 어떻게 개선할지 생각해 보는 것이 더 중요한 것 같다</li>\n          <li>(7) 큰 결정은 누구나 어렵다. 작은 결정부터 하나씩 : 작은 결정에서 점점 큰 결정으로 가자. 대표님들은 어떻게 결정하고 있는지 살펴보고 간접적으로 나라면? 생각해 보거나 대표님들이 어떤 결정을 어떤 흐름으로 했는지 물어보는 것도 방법</li>\n        </ul>\n      </li>\n      <li>의사 결정, 선택에 대한 원칙을 만들었다.\n        <ul>\n          <li>대표적인 원칙은 <strong>“만약 내일 내가 죽는데, 어떤 일을 하지 않아서 무덤 속에서 뛰쳐나올 것 같다면 지금 하자”</strong>\n            <ul>\n              <li>무덤 속에서 뛰쳐나올 것 같다고 하면 너무 답답해서 해야 할 것으로 생각한다. 그래서 “이거 무덤에서 뛰쳐나올 정도인가?”를 생각하는 편</li>\n            </ul>\n          </li>\n          <li><strong>좋은 결정보단, 상황에서 적절한 결정만 존재한다고 생각함. 그리고 결정하고 그 후의 실행이 중요하다</strong></li>\n          <li>이런 결정 원칙을 여러 개 만들고 주기적으로 수정하면 된다</li>\n          <li>또 다른 저의 원칙은 <a href=\"https://m.yes24.com/Goods/Detail/119016899\">데이터 과학자 원칙</a>에 작성되어 있음. 목차를 공유해 드리면\n            <ul>\n              <li>의도적으로 남다른 선택해보기</li>\n              <li>주기적으로 일하는 목적 찾기</li>\n              <li>제너럴리스트, 스페셜리스트 이분법으로 생각하지 않기</li>\n              <li>업무도 메타인지하며 목적 중심으로 생각하기</li>\n              <li>나의 세상 정의하기</li>\n              <li>회사에서 필요한 일과 내 흥미를 일치시키기</li>\n              <li>팀 현황을 파악해서 개선점 만들기</li>\n              <li>더 나은 커뮤니케이션 능력 기르기</li>\n              <li>비즈니스 모델과 데이터의 접점 분석하기</li>\n              <li>지금 힘들다면 여유가 있는지 생각해보기</li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n      <li>정리하면 <strong>좋은 의사 결정에 집중하는 것이 아닌 현재 상황이 어떤지, 지표로 표시해보고, 앞으로 뭘 해야할지 멘탈 시뮬레이션을 한 후에 결정한다. 결정을 한 후엔, 결정이 잘 될 수 있도록 노력함</strong>\n        <ul>\n          <li><strong>순간 순간엔 좋지 않다고 판단할 수 있지만, 시간이 지나면서 경험이 쌓이면 그런 경험들이 좋은 순간이 될 수 있음</strong></li>\n          <li>그래서 이 결정이 좋은가에 대해 생각하지 않게 된 것 같음. 그냥 내게 있는 정보를 가지고 최선의 수를 두고, 계속 고민할 뿐</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n</ul>\n\n<hr />\n\n<p><br />\n<br /></p>\n\n<h2 id=\"4-번아웃이-오면-어떻게-해야-할까\">4) 번아웃이 오면 어떻게 해야 할까?</h2>\n<ul>\n  <li>생각하게 된 배경\n    <ul>\n      <li>요즘 너무 번아웃이 심하거나 힘든 경우 이런 고민을 하게 된다</li>\n    </ul>\n  </li>\n  <li>제 생각\n    <ul>\n      <li>살다 보면 또 번아웃이 올 수 있다. 물론 회사에서 번아웃이 안 오는 사람들도 있고, 적당히 잘 유지하는 사람들도 있다. 어떤 경우엔 번아웃이었는데 시간이 지나고 깨닫는 경우도 있음</li>\n      <li>번아웃은 열심히 한 사람이 온다고 생각한다\n        <ul>\n          <li>일단 번아웃을 인정하기</li>\n          <li>번아웃을 나쁘게 생각하지 말고 긍정적으로 승화하기</li>\n          <li>잘 하고 있고, 잘 하다가 에너지가 부족해서 번아웃이 된 것. 에너지만 잘 채우면 된다</li>\n        </ul>\n      </li>\n      <li>번아웃 원인 분석하기\n        <ul>\n          <li>번아웃이 왜 오게 되었는가를 생각함</li>\n          <li>회사의 일이 많아서 그럴 수도 있고, 개인 약속이 너무 많아서 그럴 수도 있고, 제대로 쉬지 못해서, 다른 사람들은 잘 하는데 내가 상대적으로 뒤처진다고 생각해서 등 다양한 이유가 있음</li>\n          <li>여러 이유가 있을 수 있는데, 그 이유를 천천히 보면서 어떤 요인이 나를 이렇게 만들었는지 살펴본다. 과거의 경험과 비슷하면 그 요소가 내게 더 영향을 미칠 수 있다고 생각한다</li>\n        </ul>\n      </li>\n      <li>번아웃을 겪을 때 기록을 자주 해놓고, 번아웃에 대해 한판 정리를 했음\n        <ul>\n          <li>나만의 번아웃 패턴을 통해 어떻게 해야 해소할 수 있는지도 알 수 있게 되었음</li>\n          <li>인스타그램에 <a href=\"https://www.instagram.com/data.scientist/p/Cw5A1yALAFQ/?img_index=1\">번아웃에 빠졌을 때 번아웃을 극복하는 10가지 방법</a>이란 글을 작성했음</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/s/r5mee4n8p2a0ur0/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-11-08%20%EC%98%A4%ED%9B%84%203.35.16.png?raw=1\" /></p>\n\n<ul>\n  <li>번아웃과 관련되는 것이 잘 쉬는 것\n    <ul>\n      <li>잘 쉬어야 번아웃도 안 온다고 생각함</li>\n      <li>그래서 나만의 쉼 전략에 대해서도 고민했음. <a href=\"https://www.instagram.com/data.scientist/p/CxdJmQSLO-a/?img_index=1\">잘 쉬는 법에 대한 고찰</a></li>\n      <li>내가 언제 어떤 환경에 있어야 잘 쉰다고 생각하는지, 에너지가 채워지는지 등을 보고 정리함</li>\n      <li>이런 것들이 정리되니까 내가 에너지가 없으면 바로 그 행동을 하면 됨</li>\n      <li>청소하기 : 5 회복, 해외여행 가기 : 50 회복 등 이렇게 나만의 숫자를 채워봤다(숫자는 나중에 바뀔 수 있음)</li>\n    </ul>\n  </li>\n  <li><strong>너무 힘든 경우엔 아무것도 안 해도 괜찮음. 그런 시기도 충분히 있을 수 있고, 잘 회복에 집중해야 함</strong>\n    <ul>\n      <li>IT 업계에 있으면서 성장 지향적으로 살아야 한다는 말을 많이 듣는다. 나도 그렇게 살아왔는데, 어느 순간 너무 성장 성장!보다 나만의 삶을 정의하고 그런 삶을 형성하면 된다고 생각했다</li>\n      <li>이런 삶을 형성하는 과정에선 직무 관점에서 발전을 덜 할 수도 있음. 그러나 이게 문제는 아니라고 생각함</li>\n      <li>힘들 땐 잘 회복하는 것도 중요함. 회복하는 시기엔 회복에 집중하는 것을 추천</li>\n      <li>저 또한 6~7년 차 시절에, 회복에 집중했던 시기가 있음. 성장이란 것은 누적치라 생각해서 그냥 버티기만 해도 유지될 수 있어서 괜찮다고 생각함</li>\n    </ul>\n  </li>\n  <li>정리하면 <strong>번아웃의 원인을 분석해보고, 나의 번아웃 경험을 한판 정리한 후 앞으로 어떻게 번아웃에 빠질 수 있을지 도식을 그림. 또한 어떻게 쉬어야 할지에 대해서도 같이 생각함</strong></li>\n</ul>\n\n<hr />\n\n<p><br />\n<br /></p>\n\n<h2 id=\"그-외에-자주-나오는-고민-질문\">그 외에 자주 나오는 고민, 질문</h2>\n<ul>\n  <li>여러분들은 경력을 쌓으면서 어떤 고민을 하고 계신가요? 고민들도 궁금하네요</li>\n  <li>또 자주 나오는 질문들은 다음과 같음. 다음에 시간이 될 때 아래 내용으로 글을 작성해보려고 함\n    <ul>\n      <li>혹 다른 질문이 있다면 댓글 남겨주시면 참고해서 글을 작성해 볼게요</li>\n    </ul>\n  </li>\n  <li>추가로 자주 받는 질문들\n    <ul>\n      <li>제가 잘하고 있는지 확인하려면 어떻게 해야 할까요?</li>\n      <li>시간 관리는 어떻게 해야 할까요?</li>\n      <li>새로운 트렌드는 어떻게 따라가야 할까요?</li>\n      <li>기술을 추구하는게 맞을까요? 어떤 기술을 공부해야 할까요?</li>\n      <li>이직은 언제 해야 할까요?</li>\n      <li>전 물경력인 것 같아요</li>\n    </ul>\n  </li>\n</ul>\n\n<h2 id=\"정리\">정리</h2>\n<ul>\n  <li>위에 나온 것은 모두 제 생각이고 정답은 아니라고 생각함. 사람마다 다르게 생각할 수 있는 주제</li>\n  <li>제 이야기의 핵심은 <strong>나에 대해 인지(메타인지)하기, 나의 목표(비전) 정해보기, 계속 시도하기, 나만의 원칙 만들기</strong></li>\n</ul>\n\n<hr />\n\n<p><br />\n<br /></p>\n\n<ul>\n  <li>글 작성하는데 걸린 시간 : 75분\n    <ul>\n      <li>하고자 하는 이야기, 개요 정리 : 8분</li>\n      <li>초안 글 작성 : 52분</li>\n      <li>클로드/Cursor와 셀프 글 피드백 : 5분</li>\n      <li>2차 글 작성 : 10분</li>\n    </ul>\n  </li>\n</ul>\n",
        "contentSnippet": "이 글은 경력이 쌓이면서 했던 고민들과 깨달은 내용에 대해 작성한 글입니다\n멘토링 때 종종 이 주제들에 대한 질문을 받아 글을 작성해봅니다\n키워드 : 경력, 커리어, 개발자 커리어, 성장\n살다 보면 우리는 고민이 생긴다\n회사에 다니기 전에는 취업 자체에 대한 고민만 했다. 이 시기엔 취업이 되느냐, 어떤 회사에 가느냐 등을 집중적으로 고민했던 것 같음\n그러나 회사에 가면, 새로운 문제들이 생기기 시작함\n    \n회사에서 어떻게 일을 할 것인가?\n어떻게 인정받을 수 있을까?\n사람들과 어떻게 지내야 할까?\n앞으로의 커리어는 어떻게 될까?\n갑자기 어떤 일도 하기 싫은 번아웃이 온다면 어떻게 해야 할까?\n내가 회사에서 일을 잘하는지 확인하려면?\n위 사례 외에도 굉장히 다양한 종류의 고민들이 생길 수 있고, 멘토링을 할 때 자주 나오는 주제들이다\n자주 나오는 질문이나 했던 생각들을 정리하려고 한다\n자세한 이야기를 하기 전에, 이런 고민을 하는 것 자체가 문제가 아니고 내가 발전하려는 향상심이 있기에 생기는 현상이라고 생각\n    \n이런 생각이 드는 것이 당연하니 너무 걱정하지 않으셨으면 좋겠어요\n이 글의 내용은 제 생각이 맞다는 관점이 아닌, 제가 어떻게 생각했는지를 담은 글입니다. 보시고 다른 생각이 드시면 ‘글쓴이는 이렇게 생각했구나’ 이렇게 생각해 주시면 좋을 것 같아요\n\n\n1) 좋은 커리어란 무엇일까? 앞으로 어떻게 발전해야 할까?\n생각하게 된 배경\n    \n대략 2-3년 차에 많이 생각하는 주제(그러나 그 이후에도 이 고민은 계속된다. 답은 없고, 환경이 변하기 때문. 연차가 쌓이면 새로운 환경에 가고 새로운 의사 결정을 하게 될 수 있음)\n입사하고 초반엔 새로운 일들이 많아서 해당 내용들을 습득하고, 주어진 일을 하나씩 하면서 정신없이 보냄\n        \n그러다가 1, 2년이 지나고 일이 익숙해질 때쯤 커리어에 대해 고민함\n이런 고민을 하게 된 배경은 다양하게 존재할 수 있는데, 업무가 지루하다고 생각하거나, 스스로가 생각하는 이 직무가 해야 하는 일이 정의되어 있지만 그걸 안하 고 있어서 고민하는 경우도 있음\n아마 일이 즐겁고, 보람차고 프로젝트를 잘 진행하고 있다면 이런 고민은 하지 않을 가능성이 존재\n컨퍼런스에서 발표를 보거나, 외부 요소(취업 시장이 어렵다는 이야기), 친구들과의 비교 등을 통해 이런 고민을 하게 될 수도 있음\n제 생각\n    \n이 직무를 왜 시작하게 되었는지가 중요하고, 나에 대한 인지(메타인지)가 있으면 더 깊은 고민을 할 수 있음\n        \n내가 이 직무를 왜 하고 싶었는지, 초심은 무엇이었는지 등\n내가 처음 원했던 방향을 계속 고수해야 한다는 생각은 아니고, 내가 최초의 방향을 잘 생각하고 있는지 고민하며, 그 이후 자신의 경험을 얹어서 새로운 길로 가야 할지 정리하는 것도 괜찮음\n살다 보면 초심을 잊고 살아가는 경우가 많고, 초심에 대한 내용을 블로그 등에 작성하고 지속적으로 보는 것도 좋다고 생각함\n좋은 커리어의 기준은 누가 정해주는 것이 아니라 스스로가 정의해야 함\n        \n다른 사람이 좋다는 A라는 기준이 나중에 시간이 흐르면 다르게 될 수도 있음. 과거의 시기와 요즘은 또 다르게 생각할 수도 있음\n학생이나 신입은 경험이 없어서 기준이 적을 수 있고, 이럴 땐 다른 사람의 의견을 들어보기도 하는 것도 다 한 번쯤 경험함\n            \n그러나 나의 경험을 늘리면서 나만의 생각, 기준을 만들게 됨\n일반적으로 많이 나오는 연봉, 워라밸, 동료 등도 중요할 수 있지만 나의 근본적인 욕구나 이 직무를 선택한 이유에 따라 다를 수 있음\n            \n인정 욕구가 큰 사람에겐 워라밸보단 내 인정이 더 중요할 수 있음. 인정받기 위해 회사에서 성과를 높이려고 하고, 열심히 일하는 것이 즐거울 수 있음\n제가 생각하는 좋은 커리어는 “직무 하나에 나를 한정하지 말고 여러 경험을 하는 것. 문제 해결에 집중하는 것. 꾸준하게 계속 무언가를 시도하는 것”\n        \n여러 경험을 하다 보면 하고 싶지 않은 일을 할 수도 있지만, 그런 일도 경험으로 생각하는 편\n다른 사람들이 하지 않았던 여러 경험들이 합쳐지면 나만의 고유한 영역이 될 수 있다. 제너럴한 영역을 여러 개가 있고, 각 영역을 아주 잘하면 그게 또 새로운 스페셜이 될 수 있다고 생각함\n직무 관점에서도 MLOps나 Analytics Engineer가 하나의 직무에서 시작된 것이 아닌 다른 직무에서 확장되면서 생기는 직무라고 볼 수 있는데, 이와 유사하다고 생각\n저도 고민했던 시기가 있었음. 레트리카에서 데이터 분석가, 데이터 엔지니어 일을 조금씩 했었고 쏘카에선 데이터 분석가, 데이터 과학자, 머신러닝 엔지니어, 데이터 엔지니어, Engineering Manager 등을 경험했는데 너무 여러 가지를 경험해서 고민되기도 했지만 회사에서 요구하는 나의 역할을 최대한 잘 수행해 보자고 생각함\n        \n여러 경험을 했기에 직무의 협업 구조를 알 수 있고, 어떻게 프로젝트를 시작해야 할지, 사업부에선 어떤 관점으로 생각하는지 등을 모두 이해하게 됨\n조직을 키우는 경험도 해보면서, 조직의 규모에 따라 어떤 방식으로 운영해야 할지에 대해 고민을 할 수 있게 되었음\n때론 지금 하는 행동들에 너무 의지를 부여하지 않아도 괜찮았음. 시간이 지나서 그 의미를 찾는 경우도 있었음\n        \n의미를 너무 찾다가 시간이 지나갈 수도 있다는 이야기. 과거에 했던 것을 생각해보니 의미를 찾은 경우도 있기에 너무 의미를 찾는데 오래 걸린다면 잠시 실행해보는 것도 좋은 방법이라 생각(의미와 실행의 적절한 밸런스가 중요하다고 생각)\n좋은 커리어의 기준은 시간의 흐름에 따라 다를 수 있다. 내가 어떤 결정을 할지 기준을 가지고 있는지가 더 중요할 수 있음\n저는 연차별로 성장의 정의가 다 달랐음. 1-2년 차의 성장은 나의 성장, 3-6년차의 성장은 팀과 조직의 성장, 그 이후의 성장은 잘 회복하며 지금 현상 유지하기가 성장이였음. 지금의 성장도 다른 방향으로 가는 중\n\n정리하면 좋은 커리어의 정의는 내가 하는 것이고, 타인이 정해주지 않음. 나에 대해 생각을 해보고 나의 기준을 만드는 것을 추천함. 또한 시간의 흐름에 따라 성장은 달라질 수 있고 과거의 경험들이 갑자기 깨달음을 주는 경우도 있으니 걱정하지 말고 지금 순간을 잘 지내는 것을 추천함\n\n\n2) 데이터 과학자, 데이터 분석가. 데이터 직무의 고민. 커리어를 어떻게 발전해야 할까?\n생각하게 된 배경\n    \n데이터 과학자나 데이터 분석가는 직무의 구분이 명확하지 않아 많은 사람들이 혼란스러워함(저도 과거에 그랬고, 요즘 커리어를 준비하는 분들도 여전히 혼란스러워함)\n        \n다양한 데이터 분석 직군 글을 보면 직무의 이름으로 판단하지 말고 실제 하는 일을 기반으로 판단하라고 작성했음\n1번의 고민(좋은 커리어)와 연결되는 부분인데 데이터 직무는 데이터 분석가지만 하는 일이 회사마다 정말 다양함\n        \n어떤 회사에선 데이터 엔지니어링을 하면서 인프라도 구축해야 하고,\n어떤 회사에선 대시보드 제작 위주로 진행되고\n어떤 회사에선 데이터 추출 요청 위주의 업무가 진행되기도 함\n위 상황과 더불어 데이터 관련 컨퍼런스에서 보면 다른 사람들은 멋진 업무 위주로 하는 것 같아서 자신과 업무를 비교하게 되는 경우도 존재\n제 생각\n    \n이럴 때 현타가 오고 이직 준비를 할 수 있음\n그러나 저는 데이터 관련 어떤 업무를 하더라도, 회사에서 필요한 업무라고 생각함. 다만 회사의 조직 규모의 차이가 있거나 데이터 문화의 차이가 존재할 뿐. 그 시기에 내가 다니고 있을 뿐이라 생각함\n데이터 문화가 아직 잘 정착하지 못했다면 직접 데이터를 추출해서 제공해야 할 수 있고, 대시보드도 데이터 직무가 만들어야 할 수 있음\n        \n이런 상황은 왜 만들어지고, 개선하려면 어떻게 해야 할까?를 고민하는 것도 좋다고 생각\n그럼 조직의 규모가 점점 커지면서 그 안에서 필요한 역할들이 무엇인지 알 수 있게 됨\n이 부분은 국가의 발전, 역사 공부를 하면서 어떻게 해야 더 좋은 조직의 구조를 갖출 수 있을까를 생각했음\n이왕 업무를 진행할 때, 너무 부정적으로 생각하는 것보다 이 업무를 한국 또는 세상에서 제일 잘하려면 어떻게 해야 할지를 고민함\n        \n단순 데이터 추출도 정말 빠르게 잘하려면? => 데이터를 잘 정리해 두는 것도 필요하고, 마트를 만드는 것도 필요하고, 쿼리를 실수 없이 작성하는 것도 필요\n하나의 Task도 더 구체적으로 쪼개보면 필요한 역량이 여러 가지고, 그것을 더 잘하도록 시도할 수 있음\n게임에서 하기 싫은 노가다 퀘스트를 하는 느낌일 수 있지만, 이런 퀘스트가 있어야 다음 퀘스트를 수월하게 진행할 수 있다고 생각함\n다른 사람과 비교하는 순간 자존감이 떨어질 수 있음. 왜냐하면 비교 대상이 대부분 자신보다 더 좋은 상황인 사람과 비교하는 경우가 더 많기 때문\n        \n컨퍼런스에서 발표하는 내용은 부정적인 것보단 긍정적인 것, 인사이트가 있는 것을 주로 발표할 수 있음. 그리고 그 발표가 그 사람의 전부가 아니라 특정 단면을 공유한 것일 수 있음\n다른 사람의 길이 아닌, 그냥 나의 길을 가보자고 생각하는 것을 추천\n내 이야기를 영화로 치면 지금 기승전결에서 중간에 있다고 생각하고, 어려운 상황이 나오면 역시 영화에 위기 한번 와야지! 이런 생각을 하곤 함\nLLM이 발전하면서 1인 생산성이 늘어나고, 단순한 데이터 추출은 LLM으로 대체하려는 시도가 엄청 많이 존재함. 조만간 SQL 작성은 데이터 직무의 일이 아닐 수 있을 것 같음\n        \n대신 데이터 직무가 무엇을 해야 할까? 생각해 보면 사내의 컨설턴트 역할이 될 수도 있고, 데이터 문화를 만드는 역할, 의사 결정을 위주로 하는 역할 등 다양한 역할이 나올 수 있음\n그러나 미래에도 과거처럼 작은 규모에선 직접 쿼리를 작성하는 시기도 있을 수 있음. 그래서 너무 걱정하는 것보단, 지금 하는 일을 잘하게 되면 나중에 도움이 되지 않을까 싶음\n커리어는 점진적으로 발전할 수 있으므로, 너무 조급하게 생각하지 말고 지금 할 수 있는 일부터 점진적으로 하는 것을 추천\n저도 시간이 지나서 8년 차가 되었음. 그동안의 경험이 아직도 생생한데 시간이 참 빠름.\n        \n커리어 초반, 학생 시절엔 ‘내가 될까?’에 집중했고 가능성이 있는지에 대한 질문을 많이 했음\n그러다가 경력을 쌓으면서 ‘내가 뭐가 될까’에 집중했음. 뭐가에 집중하면서 어떻게 해야 할까를 고민했음\n그러다가 요즘은 ‘내가 뭐든 되네’라는 생각을 함. 시간이 지나면 무엇이든 된다. 특정 시기에 내가 노력하지 않아도 회사의 업무를 하면서 경험이 쌓이고 있음. 혹은 내 개인 삶의 경험을 풍성하게 만들 수도 있는 것\n            \n무엇이든 되니 너무 걱정하지 말고 지금 하고 싶은 것이 뭘까, 어떻게 시간을 보낼까를 고민하고 하나씩 해보는 것이 좋지 않을까 싶음\n저는 ‘커리어의 목표가 무엇인가요?’라는 질문을 받으면 딱히 없고 그냥 오늘같이 하루하루 잘 보내는 것이 목표라고 말함. 장기적인 비전은 있으면 좋지만, 너무 큰 목표같이 느껴질 수 있어서 현실적인 오늘을 잘 살려고 함\n직무 관점에서 너무 직무 하나에 매몰되지 말고, 내가 얼마나 회사에 기여할 수 있고 사람들에게 도움을 줄 수 있을지를 생각하며 이 기준이 확장될 수 있는 기준으로 일하고 있음\n정리하면 어떤 일을 하더라도 회사에서 제일 잘하고, 세계에서 제일 잘하려면 어떻게 해야할까를 생각하면서 나의 길을 가려고 함. 좋은 커리어의 정의는 내가 하는 것이므로 내가 어떻게 하고 싶은지에 기반해서 하나씩 실행함. 직무에 한정되는 사람이 되지 말고 직무를 넘어서는 사람이 되려고 함\n\n\n3) 좋은 선택, 의사 결정이란 무엇일까?\n생각하게 된 배경\n    \n의사 결정이 중요하다는 것은 많이 듣는데 그걸 어떻게 잘하는가에 대해서는 배운 적이 적음. 그러다 보니 How를 고민하게 됨\n멘토링 때도 종종 받는 질문으로 가장 중요한 순간의 선택, 후회하는 선택 등의 질문을 받음\n        \n아마 좋은 의사 결정, 좋은 선택하는 방법을 물어보는 질문이었던 것 같음\n의사 결정이 뭔가 한 번에 잘 돼야 할 것 같고, 틀리면 안 될 것 같은 고정 관념이 있었음\n제 생각\n    \n일단 저는 과거의 선택에 크게 연연하지 않는 성격. 과거 성격을 만약 돌릴 수 있다면 생각을 계속할 것 같은데, 그게 아니니까 현실을 직시한다. 그래서 과거 이야기를 물어봐도 잘 떠오르진 않음\n이렇게 된 계기를 생각해 보면 20대 중반부터 뭘 해도 잘 되는 경험이 없었음. 실패, 불합격 등이 많았는데 그게 너무 많아지니까 오히려 현실을 너무 낙관하지 않고 적절한 상태로 바라보곤 했다. 그러다가 니체 책을 보고 니체의 사상에 영감을 받음\n우선 “좋은” 이란 부분에 대한 정의가 필요함. 좋다라는 것은 상황에 따라 다를 수 있고, 구체적으로 정의가 된다면 지표로 나올 수 있음. 다만 지표로 나오지 않는다고 하면 너무 “좋은”에 집중하지 않으려고 함\n어떤 결정을 할 때, 들뜨지 않고 객관적으로 생각함\n        \n만약 지표로 표시할 수 있다면 지표를 정의한다. 숫자로 특정 상황을 표시하고, 이게 더 좋아지면 간다 등\n이 숫자가 높아질 때, 낮아질 때 어떤 Action을 할지 생각한다. 이런 과정을 Mental Simulation이라 부름\n            \n멘탈 시뮬레이션은 특정 행동을 하는 것을 상상하고, 행동하기 전에 예상되는 결과를 시뮬레이션하는 능력\n멘탈 시뮬레이션을 한다면 특정 순간의 지표가 좋지 않아도, 오르기 위해 어떤 것을 해야 할지 생각했으므로 다시 또 실행하면 됨\n과거에 아쉬움이 있다면, 한 번 더 시도해서 아쉬움을 타파하면 그만이 아닐까 생각\n한 번에 잘 되었던 적이 없어서 이 생각을 기본적으로 가지고 있는 것 같음\n어떤 경험을 하고, 주기적으로 회고를 하면서 고민한다. 이 순간에 내가 왜 이 선택을 했지? 이때 뭐가 중요하다고 생각했지?\n        \n그 당시 기록이 있다면 그 기록을 보면서 다음엔 어떻게 해볼까를 고민한다\n의사 결정 자체에 집중하는 것보다, 의사 결정을 대하는 태도나 의사 결정을 하는 과정에 신경을 쓰게 됨\nPM을 위한 데이터 리터러시 강의에 의사 결정 파트가 있는데, 그때 의사 결정 TIP을 다음과 같이 공유했음\n        \n(1) 답을 내린다는 표현 대신 베팅한다는 표현하기 : 답을 내린다는 것은 너무 부담이 생김\n(2) 에너지 레벨 고려하기 : 결정을 내리는 과정은 에너지를 많이 소모한다. 에너지를 덜 소모하며 결정할 방법을 고민함(같이 진행하기 등)\n(3) 당연한 것은 없다 : 당연하다고 생각하지 말고 항상 다시 고민해 보기\n(4) 개인적인 의사 결정에선 과감히 도전하는 것도 방법 : 회사에서 결정하는 것은 보수적으로 갈 수 있지만, 개인 관점에선 개방적으로 해보는 것도 방법. 이런 시도가 나의 안전지대(Comfort Zone)를 넘어설 수 있게 됨\n(5) 결정했으면 그 결정이 좋은 결과를 내도록 노력하기 : 결정하고 아무것도 안 하는 것이 아닌 그게 되도록 하는 것이 중요함\n(6) 사람은 결정으로 인한 실패를 피하고 싶은 성향이 있다 : 결과에 대해 받아들이고, 어떻게 개선할지 생각해 보는 것이 더 중요한 것 같다\n(7) 큰 결정은 누구나 어렵다. 작은 결정부터 하나씩 : 작은 결정에서 점점 큰 결정으로 가자. 대표님들은 어떻게 결정하고 있는지 살펴보고 간접적으로 나라면? 생각해 보거나 대표님들이 어떤 결정을 어떤 흐름으로 했는지 물어보는 것도 방법\n의사 결정, 선택에 대한 원칙을 만들었다.\n        \n대표적인 원칙은 “만약 내일 내가 죽는데, 어떤 일을 하지 않아서 무덤 속에서 뛰쳐나올 것 같다면 지금 하자”\n            \n무덤 속에서 뛰쳐나올 것 같다고 하면 너무 답답해서 해야 할 것으로 생각한다. 그래서 “이거 무덤에서 뛰쳐나올 정도인가?”를 생각하는 편\n좋은 결정보단, 상황에서 적절한 결정만 존재한다고 생각함. 그리고 결정하고 그 후의 실행이 중요하다\n이런 결정 원칙을 여러 개 만들고 주기적으로 수정하면 된다\n또 다른 저의 원칙은 데이터 과학자 원칙에 작성되어 있음. 목차를 공유해 드리면\n            \n의도적으로 남다른 선택해보기\n주기적으로 일하는 목적 찾기\n제너럴리스트, 스페셜리스트 이분법으로 생각하지 않기\n업무도 메타인지하며 목적 중심으로 생각하기\n나의 세상 정의하기\n회사에서 필요한 일과 내 흥미를 일치시키기\n팀 현황을 파악해서 개선점 만들기\n더 나은 커뮤니케이션 능력 기르기\n비즈니스 모델과 데이터의 접점 분석하기\n지금 힘들다면 여유가 있는지 생각해보기\n정리하면 좋은 의사 결정에 집중하는 것이 아닌 현재 상황이 어떤지, 지표로 표시해보고, 앞으로 뭘 해야할지 멘탈 시뮬레이션을 한 후에 결정한다. 결정을 한 후엔, 결정이 잘 될 수 있도록 노력함\n        \n순간 순간엔 좋지 않다고 판단할 수 있지만, 시간이 지나면서 경험이 쌓이면 그런 경험들이 좋은 순간이 될 수 있음\n그래서 이 결정이 좋은가에 대해 생각하지 않게 된 것 같음. 그냥 내게 있는 정보를 가지고 최선의 수를 두고, 계속 고민할 뿐\n\n\n4) 번아웃이 오면 어떻게 해야 할까?\n생각하게 된 배경\n    \n요즘 너무 번아웃이 심하거나 힘든 경우 이런 고민을 하게 된다\n제 생각\n    \n살다 보면 또 번아웃이 올 수 있다. 물론 회사에서 번아웃이 안 오는 사람들도 있고, 적당히 잘 유지하는 사람들도 있다. 어떤 경우엔 번아웃이었는데 시간이 지나고 깨닫는 경우도 있음\n번아웃은 열심히 한 사람이 온다고 생각한다\n        \n일단 번아웃을 인정하기\n번아웃을 나쁘게 생각하지 말고 긍정적으로 승화하기\n잘 하고 있고, 잘 하다가 에너지가 부족해서 번아웃이 된 것. 에너지만 잘 채우면 된다\n번아웃 원인 분석하기\n        \n번아웃이 왜 오게 되었는가를 생각함\n회사의 일이 많아서 그럴 수도 있고, 개인 약속이 너무 많아서 그럴 수도 있고, 제대로 쉬지 못해서, 다른 사람들은 잘 하는데 내가 상대적으로 뒤처진다고 생각해서 등 다양한 이유가 있음\n여러 이유가 있을 수 있는데, 그 이유를 천천히 보면서 어떤 요인이 나를 이렇게 만들었는지 살펴본다. 과거의 경험과 비슷하면 그 요소가 내게 더 영향을 미칠 수 있다고 생각한다\n번아웃을 겪을 때 기록을 자주 해놓고, 번아웃에 대해 한판 정리를 했음\n        \n나만의 번아웃 패턴을 통해 어떻게 해야 해소할 수 있는지도 알 수 있게 되었음\n인스타그램에 번아웃에 빠졌을 때 번아웃을 극복하는 10가지 방법이란 글을 작성했음\n\n번아웃과 관련되는 것이 잘 쉬는 것\n    \n잘 쉬어야 번아웃도 안 온다고 생각함\n그래서 나만의 쉼 전략에 대해서도 고민했음. 잘 쉬는 법에 대한 고찰\n내가 언제 어떤 환경에 있어야 잘 쉰다고 생각하는지, 에너지가 채워지는지 등을 보고 정리함\n이런 것들이 정리되니까 내가 에너지가 없으면 바로 그 행동을 하면 됨\n청소하기 : 5 회복, 해외여행 가기 : 50 회복 등 이렇게 나만의 숫자를 채워봤다(숫자는 나중에 바뀔 수 있음)\n너무 힘든 경우엔 아무것도 안 해도 괜찮음. 그런 시기도 충분히 있을 수 있고, 잘 회복에 집중해야 함\n    \nIT 업계에 있으면서 성장 지향적으로 살아야 한다는 말을 많이 듣는다. 나도 그렇게 살아왔는데, 어느 순간 너무 성장 성장!보다 나만의 삶을 정의하고 그런 삶을 형성하면 된다고 생각했다\n이런 삶을 형성하는 과정에선 직무 관점에서 발전을 덜 할 수도 있음. 그러나 이게 문제는 아니라고 생각함\n힘들 땐 잘 회복하는 것도 중요함. 회복하는 시기엔 회복에 집중하는 것을 추천\n저 또한 6~7년 차 시절에, 회복에 집중했던 시기가 있음. 성장이란 것은 누적치라 생각해서 그냥 버티기만 해도 유지될 수 있어서 괜찮다고 생각함\n정리하면 번아웃의 원인을 분석해보고, 나의 번아웃 경험을 한판 정리한 후 앞으로 어떻게 번아웃에 빠질 수 있을지 도식을 그림. 또한 어떻게 쉬어야 할지에 대해서도 같이 생각함\n\n\n그 외에 자주 나오는 고민, 질문\n여러분들은 경력을 쌓으면서 어떤 고민을 하고 계신가요? 고민들도 궁금하네요\n또 자주 나오는 질문들은 다음과 같음. 다음에 시간이 될 때 아래 내용으로 글을 작성해보려고 함\n    \n혹 다른 질문이 있다면 댓글 남겨주시면 참고해서 글을 작성해 볼게요\n추가로 자주 받는 질문들\n    \n제가 잘하고 있는지 확인하려면 어떻게 해야 할까요?\n시간 관리는 어떻게 해야 할까요?\n새로운 트렌드는 어떻게 따라가야 할까요?\n기술을 추구하는게 맞을까요? 어떤 기술을 공부해야 할까요?\n이직은 언제 해야 할까요?\n전 물경력인 것 같아요\n정리\n위에 나온 것은 모두 제 생각이고 정답은 아니라고 생각함. 사람마다 다르게 생각할 수 있는 주제\n제 이야기의 핵심은 나에 대해 인지(메타인지)하기, 나의 목표(비전) 정해보기, 계속 시도하기, 나만의 원칙 만들기\n\n\n글 작성하는데 걸린 시간 : 75분\n    \n하고자 하는 이야기, 개요 정리 : 8분\n초안 글 작성 : 52분\n클로드/Cursor와 셀프 글 피드백 : 5분\n2차 글 작성 : 10분",
        "guid": "https://zzsza.github.io/diary/2024/11/08/thoughts-and-learnings-in-careers/",
        "categories": [
          "diary",
          "diary"
        ],
        "isoDate": "2024-11-08T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "차트 공부 해봅시다. / 바닥이 나오는 과정",
        "link": "http://serverdown.tistory.com/962",
        "pubDate": "Thu, 14 Nov 2024 00:31:22 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/962#entry962comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"524\" data-origin-height=\"447\"><span data-url=\"https://blog.kakaocdn.net/dn/Bkdd4/btsKGRLKKb6/VZ8mXEiy88T8SJnvnsnfR1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Bkdd4/btsKGRLKKb6/VZ8mXEiy88T8SJnvnsnfR1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/Bkdd4/btsKGRLKKb6/VZ8mXEiy88T8SJnvnsnfR1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FBkdd4%2FbtsKGRLKKb6%2FVZ8mXEiy88T8SJnvnsnfR1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"524\" data-origin-height=\"447\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">국내 주식은 맛탱이가서 살리기 어려울꺼 같습니다.</p>\n<p data-ke-size=\"size16\">언젠간 반등하겠죠 코로나때 처럼 크게 오를꺼 같긴한데 그게 언제인지는 모릅니다.</p>\n<p data-ke-size=\"size16\">그 반등을 놓치지 않기 위해 차트공부를 해봅니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 차트는미국&nbsp; IONQ 현재 일봉 차트입니다.<br />IONQ 는 양자컴퓨터 회사죠.<br />정부 지원을 받나봅니다.</p>\n<p data-ke-size=\"size16\">반도체는 때리고 양자컴은 키우고 ... 어지럽군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">1번은 RSI 지표구요 30갔다 올라왔죠</p>\n<p data-ke-size=\"size16\">여기서 한당뒤에 한번더 바닥을 찍습니다.</p>\n<p data-ke-size=\"size16\">정말 긴시간의 텀을 두고 움직이네요. 급하면 지는 겁니다.</p>\n<p data-ke-size=\"size16\">그 뒤로 2달을 더 기다가 갑자기 올라갔습니다.</p>\n<p data-ke-size=\"size16\">한국증시도 지금 몇번째 \"바닥이니\" 를 시전 중이지만 바닥이 그렇게 쉽게 오지 않는다는 것을 배울 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">2번 지표는 MACD 입니다. 이평선이 점점 벌어지는 모양입니다.</p>\n<p data-ke-size=\"size16\">그러고 보니 그 근처에 거래량이 크게 증가하는것을 보실 수 있습니다.&nbsp;</p>\n<p data-ke-size=\"size16\">이러면 찐바닥인것입니다.</p>\n<p data-ke-size=\"size16\">그뒤로도 위아래로 난리라 들어갈 기회는 많았었는데 ...</p>\n<p data-ke-size=\"size16\">제가 양자컴퓨터를 무시했네요 ...</p>\n<p data-ke-size=\"size16\">당시에 태양광 열심히 보고 있었는데 그건 지옥갔습니다.</p>\n<p data-ke-size=\"size16\">다음번에는 무시하지 말아야 겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">한국도 RSI 지표를 보면 뭔가 답이 좀 있을꺼 같군요 RSI 가 살아나도 다시 3개월이 걸린다니 ....</p>\n<p data-ke-size=\"size16\">한참 남았다는 말이 이를때 쓰는건가봅니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">바닥이 나올때는 이런 패턴이 나오더라 쯤으로 알아주세요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "국내 주식은 맛탱이가서 살리기 어려울꺼 같습니다.\n언젠간 반등하겠죠 코로나때 처럼 크게 오를꺼 같긴한데 그게 언제인지는 모릅니다.\n그 반등을 놓치지 않기 위해 차트공부를 해봅니다.\n \n이 차트는미국  IONQ 현재 일봉 차트입니다.\nIONQ 는 양자컴퓨터 회사죠.\n정부 지원을 받나봅니다.\n반도체는 때리고 양자컴은 키우고 ... 어지럽군요\n \n1번은 RSI 지표구요 30갔다 올라왔죠\n여기서 한당뒤에 한번더 바닥을 찍습니다.\n정말 긴시간의 텀을 두고 움직이네요. 급하면 지는 겁니다.\n그 뒤로 2달을 더 기다가 갑자기 올라갔습니다.\n한국증시도 지금 몇번째 \"바닥이니\" 를 시전 중이지만 바닥이 그렇게 쉽게 오지 않는다는 것을 배울 수 있습니다.\n \n2번 지표는 MACD 입니다. 이평선이 점점 벌어지는 모양입니다.\n그러고 보니 그 근처에 거래량이 크게 증가하는것을 보실 수 있습니다. \n이러면 찐바닥인것입니다.\n그뒤로도 위아래로 난리라 들어갈 기회는 많았었는데 ...\n제가 양자컴퓨터를 무시했네요 ...\n당시에 태양광 열심히 보고 있었는데 그건 지옥갔습니다.\n다음번에는 무시하지 말아야 겠습니다.\n \n한국도 RSI 지표를 보면 뭔가 답이 좀 있을꺼 같군요 RSI 가 살아나도 다시 3개월이 걸린다니 ....\n한참 남았다는 말이 이를때 쓰는건가봅니다.\n \n바닥이 나올때는 이런 패턴이 나오더라 쯤으로 알아주세요.",
        "guid": "http://serverdown.tistory.com/962",
        "categories": [
          "투자",
          "오블완",
          "티스토리챌린지"
        ],
        "isoDate": "2024-11-13T15:31:22.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "새로운 주식 지식 채널 찾았습니다. / 열띵히하자",
        "link": "http://serverdown.tistory.com/961",
        "pubDate": "Wed, 13 Nov 2024 11:50:00 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/961#entry961comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=DZXbHptu1eQ\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=DZXbHptu1eQ</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=DZXbHptu1eQ\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/eL5pK/hyXzIF6J4q/5hcSuMCpb9ZDRF8NHgMgNK/img.jpg?width=1280&amp;height=720&amp;face=548_234_834_546,https://scrap.kakaocdn.net/dn/QNmaP/hyXzMhrcSJ/UKajQpHn1qw9s5cTgt4ktk/img.jpg?width=1280&amp;height=720&amp;face=548_234_834_546\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"2차전지는 이 기업만 최대한 사모우세요\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/DZXbHptu1eQ\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">구독자도 200명 정도인 이시점 빠르게 탑승해봅니다.</p>\n<p data-ke-size=\"size16\">일단 미국이랑 코인으로 벌어 다시 들어오겠습니다.</p>\n<p data-ke-size=\"size16\">한국은 오를때 금방 오릅니다.</p>\n<p data-ke-size=\"size16\">내년 2월 아니면 내년 11월 정도로 보고 있습니다..</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=DZXbHptu1eQ\n\n\n\n구독자도 200명 정도인 이시점 빠르게 탑승해봅니다.\n일단 미국이랑 코인으로 벌어 다시 들어오겠습니다.\n한국은 오를때 금방 오릅니다.\n내년 2월 아니면 내년 11월 정도로 보고 있습니다..",
        "guid": "http://serverdown.tistory.com/961",
        "categories": [
          "투자",
          "리더"
        ],
        "isoDate": "2024-11-13T02:50:00.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "비트액스 ckpool 설정 방법 / Bisaxe",
        "link": "http://serverdown.tistory.com/960",
        "pubDate": "Wed, 13 Nov 2024 00:34:27 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/960#entry960comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"713\" data-origin-height=\"568\"><span data-url=\"https://blog.kakaocdn.net/dn/cJP40D/btsKHuHTw2l/sfq9K6TsErKcXnVQZNAhJK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cJP40D/btsKHuHTw2l/sfq9K6TsErKcXnVQZNAhJK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cJP40D/btsKHuHTw2l/sfq9K6TsErKcXnVQZNAhJK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcJP40D%2FbtsKHuHTw2l%2Fsfq9K6TsErKcXnVQZNAhJK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"713\" data-origin-height=\"568\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">ckpool 홈페이지:<a href=\"https://solo.ckpool.org/\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://solo.ckpool.org/</a></p>\n<p data-ke-size=\"size16\">ckpool 운영방식 설명: <a href=\"https://bitcointalk.org/index.php?topic=5237323.0\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://bitcointalk.org/index.php?topic=5237323.0</a></p>\n<p data-ke-size=\"size16\">여기 룰 설명중에 이부분이 중요한거 같습니다.</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Note that if you do not find a block, you get no reward at all with solo mining.</span></p>\n<p data-ke-size=\"size16\">블록을&nbsp;찾지&nbsp;못하면&nbsp;솔로&nbsp;채굴을&nbsp;해도&nbsp;전혀&nbsp;보상을&nbsp;받을&nbsp;수&nbsp;없다는&nbsp;점에&nbsp;유의하세요.</p>\n<p data-ke-size=\"size16\"><br /><span style=\"text-align: start;\">2% goes to bc1q28kkr5hk4gnqe3evma6runjrd2pvqyp8fpwfzu to operate the pool and contribute to further ckpool code development.</span></p>\n<p data-ke-size=\"size16\">2%는&nbsp;bc1q28kkr5hk4gnqe3evma6runjrd2pvqyp8fpwfzu에&nbsp;전달되어&nbsp;풀을&nbsp;운영하고&nbsp;추가&nbsp;ckpool&nbsp;코드&nbsp;개발에&nbsp;기여합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">솔로 채굴이라 원래 보상없는 거구요<br />풀마다 운영 규칙이 조금씩 다르긴하더라구요</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">당첨되면 2% + 이체 수수료는 빼고</span> 즉시 전송해줍니다.</p>\n<p data-ke-size=\"size16\">단순하면서 좋은 룰 같습니다. 한두달에 한명정도 나오는거 같더군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">설정방법</h2>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Stratum URL: solo.ckpool.org</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Stratum Port: 4334</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Stratum User: 지갑주소.별명<br />예를 들어 제꺼는 bc1qc272dkew26ea46z2egmt22a3uplpzqgc7snlcs.bitaxekorean</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Stratum Password: x<br />아무거나 넣으라는데 보통 x 를 넣습니다.</span></p>\n<h2 data-ke-size=\"size26\"><span style=\"text-align: start;\">주의: 별명부분은 블록에 기록되고 모두가 볼 수 있으니 [개인정보] 넣지 마세요</span></h2>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "ckpool 홈페이지:https://solo.ckpool.org/\nckpool 운영방식 설명: https://bitcointalk.org/index.php?topic=5237323.0\n여기 룰 설명중에 이부분이 중요한거 같습니다.\nNote that if you do not find a block, you get no reward at all with solo mining.\n블록을 찾지 못하면 솔로 채굴을 해도 전혀 보상을 받을 수 없다는 점에 유의하세요.\n2% goes to bc1q28kkr5hk4gnqe3evma6runjrd2pvqyp8fpwfzu to operate the pool and contribute to further ckpool code development.\n2%는 bc1q28kkr5hk4gnqe3evma6runjrd2pvqyp8fpwfzu에 전달되어 풀을 운영하고 추가 ckpool 코드 개발에 기여합니다.\n \n솔로 채굴이라 원래 보상없는 거구요\n풀마다 운영 규칙이 조금씩 다르긴하더라구요\n당첨되면 2% + 이체 수수료는 빼고 즉시 전송해줍니다.\n단순하면서 좋은 룰 같습니다. 한두달에 한명정도 나오는거 같더군요\n \n설정방법\nStratum URL: solo.ckpool.org\nStratum Port: 4334\nStratum User: 지갑주소.별명\n예를 들어 제꺼는 bc1qc272dkew26ea46z2egmt22a3uplpzqgc7snlcs.bitaxekorean\nStratum Password: x\n아무거나 넣으라는데 보통 x 를 넣습니다.\n주의: 별명부분은 블록에 기록되고 모두가 볼 수 있으니 [개인정보] 넣지 마세요",
        "guid": "http://serverdown.tistory.com/960",
        "categories": [
          "코인",
          "비트액스",
          "오블완",
          "채굴",
          "티스토리챌린지"
        ],
        "isoDate": "2024-11-12T15:34:27.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "비트액스 열관리 / 과열 해결기 / 쿨링 패드 / 선풍기 / Bitaxe Overheat",
        "link": "http://serverdown.tistory.com/959",
        "pubDate": "Tue, 12 Nov 2024 17:14:32 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/959#entry959comment",
        "content": "<h2 data-ke-size=\"size26\">오버히트 에러 해결법 / 조치 방법</h2>\n<p data-ke-size=\"size16\">스샷1 - Setting 화면</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1155\" data-origin-height=\"511\"><span data-url=\"https://blog.kakaocdn.net/dn/54C4j/btsKFM31CGr/nlBbUn7RMyuJAapnmZDD60/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/54C4j/btsKFM31CGr/nlBbUn7RMyuJAapnmZDD60/img.png\"><img src=\"https://blog.kakaocdn.net/dn/54C4j/btsKFM31CGr/nlBbUn7RMyuJAapnmZDD60/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F54C4j%2FbtsKFM31CGr%2FnlBbUn7RMyuJAapnmZDD60%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"1155\" data-origin-height=\"511\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">과열이 되어 멈추면 Setting 화면에 빨간 버튼이 생깁니다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Disabled Overheat Mode</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">앗 이게 버튼인지 경고 문구인지 확인을 안해봤군요.</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">빨간색이라 누르면 안될꺼 같았습니다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">과열이 되면 채굴이 중단되고</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Frequency 와 <span style=\"text-align: start;\">Core Voltage 값이 비어있습니다.</span></span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\"><span style=\"text-align: start;\">이걸 default 값으로 바꾼후에 Save 및 Restart 를 해주시면 됩니다.</span></span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">스샷2 - Dashboard 화면</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1195\" data-origin-height=\"443\"><span data-url=\"https://blog.kakaocdn.net/dn/c7vgHv/btsKEXytGFH/WLD4slKdvk21cgLoUs9BI1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/c7vgHv/btsKEXytGFH/WLD4slKdvk21cgLoUs9BI1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/c7vgHv/btsKEXytGFH/WLD4slKdvk21cgLoUs9BI1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc7vgHv%2FbtsKEXytGFH%2FWLD4slKdvk21cgLoUs9BI1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"1195\" data-origin-height=\"443\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">과열 설정을 수정하지 않으면 Dashboard 화면 상단에 경고 문구가 듭니다.</p>\n<p data-ke-size=\"size16\">결국 Settings 에서 고치고 오라는 뜻입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">노트북 쿨링패드는 어떨까?</h2>\n<p data-ke-size=\"size16\">결론 부터 말하자면 쿨링 패드 보다 더 추천하는 방법은 선풍기 입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"548\" data-origin-height=\"582\"><span data-url=\"https://blog.kakaocdn.net/dn/dLLMXe/btsKF4J7EPf/Vre2Uyext90dWsyW4rAL7k/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dLLMXe/btsKF4J7EPf/Vre2Uyext90dWsyW4rAL7k/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dLLMXe/btsKF4J7EPf/Vre2Uyext90dWsyW4rAL7k/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdLLMXe%2FbtsKF4J7EPf%2FVre2Uyext90dWsyW4rAL7k%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"548\" data-origin-height=\"582\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">노트북 냉각 패드위에 올려놓은 사진인데요&nbsp;</p>\n<p data-ke-size=\"size16\">바람나오는 방향 잘 맞춰서 세워놓으면 효과가 있는거 같습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"502\" data-origin-height=\"477\"><span data-url=\"https://blog.kakaocdn.net/dn/bkPr7n/btsKFIm8Nxn/aeh4ptMVoP9M44kA8Kgya1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bkPr7n/btsKFIm8Nxn/aeh4ptMVoP9M44kA8Kgya1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bkPr7n/btsKFIm8Nxn/aeh4ptMVoP9M44kA8Kgya1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbkPr7n%2FbtsKFIm8Nxn%2Faeh4ptMVoP9M44kA8Kgya1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"502\" data-origin-height=\"477\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">결국 65도에서 57도까지 떨어졌습니당.</p>\n<p data-ke-size=\"size16\">노트북 쿨링패드 좋네요</p>\n<p data-ke-size=\"size16\">제껀 [링킨 LS-410] 인데 이건 싸고 별로구요 7천원</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"322\" data-origin-height=\"645\"><span data-url=\"https://blog.kakaocdn.net/dn/bZsCmd/btsKGBgPfEV/TfSnAdFj9YeQBJao2aCnPk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bZsCmd/btsKGBgPfEV/TfSnAdFj9YeQBJao2aCnPk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bZsCmd/btsKGBgPfEV/TfSnAdFj9YeQBJao2aCnPk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbZsCmd%2FbtsKGBgPfEV%2FTfSnAdFj9YeQBJao2aCnPk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"322\" data-origin-height=\"645\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">모양은이게 좋아보이네요 선풍기가 많네요</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"318\" data-origin-height=\"572\"><span data-url=\"https://blog.kakaocdn.net/dn/l0Pzb/btsKGG9WLWN/7khadzoHB3vTB7Pfnho2Ik/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/l0Pzb/btsKGG9WLWN/7khadzoHB3vTB7Pfnho2Ik/img.png\"><img src=\"https://blog.kakaocdn.net/dn/l0Pzb/btsKGG9WLWN/7khadzoHB3vTB7Pfnho2Ik/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fl0Pzb%2FbtsKGG9WLWN%2F7khadzoHB3vTB7Pfnho2Ik%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"318\" data-origin-height=\"572\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">좌우로 두개 분리된 제품은 이것입니다.</p>\n<p data-ke-size=\"size16\">채굴기는 작으니 좁은 공간에 강력하게 나와주는게 좋겟습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">더 좋은거 USB 선풍기</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"314\" data-origin-height=\"497\"><span data-url=\"https://blog.kakaocdn.net/dn/b3OQXM/btsKFnYcm0N/IuRzifiKpmkkTnq8xKSHPK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/b3OQXM/btsKFnYcm0N/IuRzifiKpmkkTnq8xKSHPK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/b3OQXM/btsKFnYcm0N/IuRzifiKpmkkTnq8xKSHPK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb3OQXM%2FbtsKFnYcm0N%2FIuRzifiKpmkkTnq8xKSHPK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"314\" data-origin-height=\"497\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">이게 수정이 얼만지는 모르겠는데 가격이 아주 저렴합니다.</p>\n<p data-ke-size=\"size16\">저는 1,300원에 두개 사봤습니다. 배송비 3,000원</p>\n<p data-ke-size=\"size16\">1. <span style=\"text-align: start;\">가격이 저렴</span>&nbsp;<br />2. <span style=\"text-align: start;\">직접 방향을 맞춰줄 수 있음</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"313\" data-origin-height=\"542\"><span data-url=\"https://blog.kakaocdn.net/dn/yRA1R/btsKGqtafNt/iMyx1ik5kskAnq5F4G93w1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/yRA1R/btsKGqtafNt/iMyx1ik5kskAnq5F4G93w1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/yRA1R/btsKGqtafNt/iMyx1ik5kskAnq5F4G93w1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FyRA1R%2FbtsKGqtafNt%2FiMyx1ik5kskAnq5F4G93w1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"313\" data-origin-height=\"542\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">바닥이 없는 선풍기는 스탠드 같은게 필요합니다.<br />usb 크래들이라고 부르는데 왜이케 비싸징 ㄷㄷㄷ</p>\n<p data-ke-size=\"size16\">저는 집에 하나 굴러다니는게 있군</p>\n<p data-ke-size=\"size16\">배송비까지 따지자면 적당한 미니 선풍기가 나을꺼 같군요</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"554\" data-origin-height=\"554\"><span data-url=\"https://blog.kakaocdn.net/dn/LSii2/btsKFq8tUd9/MRlqEhOKHNTpvWzuapcdL1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/LSii2/btsKFq8tUd9/MRlqEhOKHNTpvWzuapcdL1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/LSii2/btsKFq8tUd9/MRlqEhOKHNTpvWzuapcdL1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FLSii2%2FbtsKFq8tUd9%2FMRlqEhOKHNTpvWzuapcdL1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"554\" data-origin-height=\"554\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">1. usb 허브 / 전원 공급용<br />2. usb 선풍기</p>\n<p data-ke-size=\"size16\">아 usb 허브도 필요하군요 전원 공급을 위한거기때문에 아답타로 전원을 추가로 넣을 수 있는 모델이여야합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">채굴기가 속도를 제어하는 원리</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"298\" data-origin-height=\"422\"><span data-url=\"https://blog.kakaocdn.net/dn/chpgy2/btsKGLX6tKP/C1ZWIGU2Y7YSzgWPCHqlGk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/chpgy2/btsKGLX6tKP/C1ZWIGU2Y7YSzgWPCHqlGk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/chpgy2/btsKGLX6tKP/C1ZWIGU2Y7YSzgWPCHqlGk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fchpgy2%2FbtsKGLX6tKP%2FC1ZWIGU2Y7YSzgWPCHqlGk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"298\" data-origin-height=\"422\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">제가 찾아낸 규칙으로는&nbsp;</p>\n<p data-ke-size=\"size16\">온도가 올라가면 알아서 성능을 줄입니다. <br />열을 덜 내기 위한 조치 인거 같습니다.</p>\n<p data-ke-size=\"size16\">그러니까 열만 내려주면 채굴 속도도 빨라진다는 것입니다.</p>\n<p data-ke-size=\"size16\">채굴기 가격을 생각한다면 1 ~ 2 만원 더 쓰고 안정적으로 돌아가는게 더 중요할 것같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">스샷 찍고 보니 성능이랑 관계는 없는데&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: center;\">Voltage Regulator Temperature / 전압&nbsp;조정기&nbsp;온도</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: center;\">이 온도가 빨리 떨어지네요<br />이 값은 전원 공급용 반도체의 온도 값입니다.<br /></span><span style=\"text-align: center;\">보통&nbsp; cpu 보다 <span style=\"text-align: center;\">전압 조정기</span>가 먼저 고장나는데요<br /></span><span style=\"color: initial; text-align: center; letter-spacing: 0px;\">온도가 낮아지면 수명에 도움이 될 것 같습니다.<br /></span><span style=\"text-align: center;\">전원 공급 반도체는 성능이랑은 관련은 없습니다. <br />고장이 먼저 나는 부품이다 정도</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "오버히트 에러 해결법 / 조치 방법\n스샷1 - Setting 화면\n\n\n과열이 되어 멈추면 Setting 화면에 빨간 버튼이 생깁니다.\nDisabled Overheat Mode\n앗 이게 버튼인지 경고 문구인지 확인을 안해봤군요.\n빨간색이라 누르면 안될꺼 같았습니다.\n \n과열이 되면 채굴이 중단되고\nFrequency 와 Core Voltage 값이 비어있습니다.\n이걸 default 값으로 바꾼후에 Save 및 Restart 를 해주시면 됩니다.\n \n \n스샷2 - Dashboard 화면\n\n\n과열 설정을 수정하지 않으면 Dashboard 화면 상단에 경고 문구가 듭니다.\n결국 Settings 에서 고치고 오라는 뜻입니다.\n \n노트북 쿨링패드는 어떨까?\n결론 부터 말하자면 쿨링 패드 보다 더 추천하는 방법은 선풍기 입니다.\n\n\n노트북 냉각 패드위에 올려놓은 사진인데요 \n바람나오는 방향 잘 맞춰서 세워놓으면 효과가 있는거 같습니다.\n\n\n결국 65도에서 57도까지 떨어졌습니당.\n노트북 쿨링패드 좋네요\n제껀 [링킨 LS-410] 인데 이건 싸고 별로구요 7천원\n\n\n모양은이게 좋아보이네요 선풍기가 많네요\n\n\n좌우로 두개 분리된 제품은 이것입니다.\n채굴기는 작으니 좁은 공간에 강력하게 나와주는게 좋겟습니다.\n \n더 좋은거 USB 선풍기\n\n\n이게 수정이 얼만지는 모르겠는데 가격이 아주 저렴합니다.\n저는 1,300원에 두개 사봤습니다. 배송비 3,000원\n1. 가격이 저렴 \n2. 직접 방향을 맞춰줄 수 있음\n\n\n바닥이 없는 선풍기는 스탠드 같은게 필요합니다.\nusb 크래들이라고 부르는데 왜이케 비싸징 ㄷㄷㄷ\n저는 집에 하나 굴러다니는게 있군\n배송비까지 따지자면 적당한 미니 선풍기가 나을꺼 같군요\n\n\n1. usb 허브 / 전원 공급용\n2. usb 선풍기\n아 usb 허브도 필요하군요 전원 공급을 위한거기때문에 아답타로 전원을 추가로 넣을 수 있는 모델이여야합니다.\n \n채굴기가 속도를 제어하는 원리\n\n\n제가 찾아낸 규칙으로는 \n온도가 올라가면 알아서 성능을 줄입니다. \n열을 덜 내기 위한 조치 인거 같습니다.\n그러니까 열만 내려주면 채굴 속도도 빨라진다는 것입니다.\n채굴기 가격을 생각한다면 1 ~ 2 만원 더 쓰고 안정적으로 돌아가는게 더 중요할 것같습니다.\n \n스샷 찍고 보니 성능이랑 관계는 없는데 \nVoltage Regulator Temperature / 전압 조정기 온도\n이 온도가 빨리 떨어지네요\n이 값은 전원 공급용 반도체의 온도 값입니다.\n보통  cpu 보다 전압 조정기가 먼저 고장나는데요\n온도가 낮아지면 수명에 도움이 될 것 같습니다.\n전원 공급 반도체는 성능이랑은 관련은 없습니다. \n고장이 먼저 나는 부품이다 정도",
        "guid": "http://serverdown.tistory.com/959",
        "categories": [
          "코인"
        ],
        "isoDate": "2024-11-12T08:14:32.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "공포의 한자 공부",
        "link": "http://serverdown.tistory.com/958",
        "pubDate": "Tue, 12 Nov 2024 14:33:39 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/958#entry958comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=V6i2aiH8oac&amp;t=11s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=V6i2aiH8oac&amp;t=11s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=V6i2aiH8oac\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/NN3Nz/hyXwqz3qoL/kkSc2rkTt4PQKqHJT0xR30/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/zbPUq/hyXwmxFdbW/ygnUooI1ZBi66q9UFuOYo1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"고대에서 현대로 접어들며 의미와 발음이 전부 소실되어 버린 '유령 한자'에 얽힌 소름 끼치는 \" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/V6i2aiH8oac\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">한자 무서워</p>\n<p data-ke-size=\"size16\">입두개 달린 괴물 - 에어리언 아닌가</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=V6i2aiH8oac&t=11s\n\n\n\n한자 무서워\n입두개 달린 괴물 - 에어리언 아닌가",
        "guid": "http://serverdown.tistory.com/958",
        "categories": [
          "유튜브"
        ],
        "isoDate": "2024-11-12T05:33:39.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "금투세 폐지, 이젠 외국계 투자자들도 외치네요 ㄷㄷ",
        "link": "http://serverdown.tistory.com/957",
        "pubDate": "Tue, 12 Nov 2024 12:07:01 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/957#entry957comment",
        "content": "<p data-ke-size=\"size16\">기사: <a href=\"https://m.edaily.co.kr/News/Read?newsId=03132406639084736&amp;mediaCodeNo=257\">美행동주의 \"韓 증시, 금투세 폐지&middot;밸류업으로 매력 높아져\"</a></p>\n<figure id=\"og_1731380693228\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"美행동주의 &quot;韓 증시, 금투세 폐지&middot;밸류업으로 매력 높아져&quot;\" data-og-description=\"미국 행동주의 펀드인 돌턴인베스트먼트가 국내 증시에 대한 투자 매력도가 높아지고 있다고 11일 짚었다. 금융투자소득세(금투세) 폐지와 밸류업 정책 등으로 시장 환경이 개선됨에 따라 저평\" data-og-host=\"m.edaily.co.kr\" data-og-source-url=\"https://m.edaily.co.kr/News/Read?newsId=03132406639084736&amp;mediaCodeNo=257\" data-og-url=\"https://m.edaily.co.kr/News/Read?mediaCodeNo=257&amp;newsId=03132406639084736\" data-og-image=\"https://scrap.kakaocdn.net/dn/Bn5bN/hyXwjHHYoD/hOcAMjcXGP4AGz9GOFnN7k/img.jpg?width=670&amp;height=181&amp;face=0_0_670_181,https://scrap.kakaocdn.net/dn/cRBMKC/hyXwmLaq4U/Vk7GXKIgELeF1mUjNjuqI1/img.jpg?width=670&amp;height=181&amp;face=0_0_670_181\"><a href=\"https://m.edaily.co.kr/News/Read?newsId=03132406639084736&amp;mediaCodeNo=257\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://m.edaily.co.kr/News/Read?newsId=03132406639084736&amp;mediaCodeNo=257\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/Bn5bN/hyXwjHHYoD/hOcAMjcXGP4AGz9GOFnN7k/img.jpg?width=670&amp;height=181&amp;face=0_0_670_181,https://scrap.kakaocdn.net/dn/cRBMKC/hyXwmLaq4U/Vk7GXKIgELeF1mUjNjuqI1/img.jpg?width=670&amp;height=181&amp;face=0_0_670_181');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">美행동주의 \"韓 증시, 금투세 폐지&middot;밸류업으로 매력 높아져\"</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">미국 행동주의 펀드인 돌턴인베스트먼트가 국내 증시에 대한 투자 매력도가 높아지고 있다고 11일 짚었다. 금융투자소득세(금투세) 폐지와 밸류업 정책 등으로 시장 환경이 개선됨에 따라 저평</p>\n<p class=\"og-host\" data-ke-size=\"size16\">m.edaily.co.kr</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">이게 무슨일이죠 ㄷㄷㄷ&nbsp;</p>\n<p data-ke-size=\"size16\">12 -13일은 빠때리아저씨의 예언일 중 하나인데요</p>\n<p data-ke-size=\"size16\">표결 이야기가 나와야 할 대입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">외국계 투자자들도 금투세 보고 잇었네요</p>\n<p data-ke-size=\"size16\">민주당 놈들아 아니라메<br />금투세 도입해야 건전해진다메</p>\n<p data-ke-size=\"size16\">다 매국노 였습니다.<br />어덯게든 부동산 살리려고 증시에 돈을 빼개 만드네요</p>\n<p data-ke-size=\"size16\">그냥 푸념이였습니다.</p>\n<p data-ke-size=\"size16\">코인이랑 미국 주식은 잘되네요</p>",
        "contentSnippet": "기사: 美행동주의 \"韓 증시, 금투세 폐지·밸류업으로 매력 높아져\"\n\n \n美행동주의 \"韓 증시, 금투세 폐지·밸류업으로 매력 높아져\"\n미국 행동주의 펀드인 돌턴인베스트먼트가 국내 증시에 대한 투자 매력도가 높아지고 있다고 11일 짚었다. 금융투자소득세(금투세) 폐지와 밸류업 정책 등으로 시장 환경이 개선됨에 따라 저평\nm.edaily.co.kr\n\n이게 무슨일이죠 ㄷㄷㄷ \n12 -13일은 빠때리아저씨의 예언일 중 하나인데요\n표결 이야기가 나와야 할 대입니다.\n \n외국계 투자자들도 금투세 보고 잇었네요\n민주당 놈들아 아니라메\n금투세 도입해야 건전해진다메\n다 매국노 였습니다.\n어덯게든 부동산 살리려고 증시에 돈을 빼개 만드네요\n그냥 푸념이였습니다.\n코인이랑 미국 주식은 잘되네요",
        "guid": "http://serverdown.tistory.com/957",
        "categories": [
          "투자",
          "금투세"
        ],
        "isoDate": "2024-11-12T03:07:01.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "중국 은행 연쇄 파산 / 이상하게 해결을 안하고 ...",
        "link": "http://serverdown.tistory.com/956",
        "pubDate": "Tue, 12 Nov 2024 12:01:45 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/956#entry956comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=XiGgdsyzItQ\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=XiGgdsyzItQ</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=XiGgdsyzItQ\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/QHZ5E/hyXwi9NMa8/xSZjYTFRJk1r1OngkNAMd0/img.jpg?width=1280&amp;height=720&amp;face=116_110_226_230,https://scrap.kakaocdn.net/dn/itdXO/hyXwuoQ2Ko/7Jzez6z2iAvayLAUrD9jR1/img.jpg?width=1280&amp;height=720&amp;face=116_110_226_230\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"자기 돈도 마음대로 못 꺼내 쓰는 현실... 중국 서민들은 이제 뭘 믿어야 되나...?\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/XiGgdsyzItQ\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">중국이 맛이가서 신난 분들도 있고</p>\n<p data-ke-size=\"size16\">살아야 한국도 산다는 분들도 있고 그런 상황입니다.</p>\n<p data-ke-size=\"size16\">2차전지는 중국이랑 경쟁중이기 때문에 중국이 쓰러지면 좋아야되는데 연일 빠지네요 ㄷㄷㄷ</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상을 보시면 지방 은행이 하나 갑자기 문을 닫고 잠적했는데</p>\n<p data-ke-size=\"size16\">여기서 전개가 신기하게 되네요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">1. 은행 문닫고 도망감</p>\n<p data-ke-size=\"size16\">2. 사람들 항의함</p>\n<p data-ke-size=\"size16\">3. 은행 도망 사태의 기사가 내려감<br />&nbsp; &nbsp; &nbsp;(영상은 개인이 올려서 그런지 덜 내려간건지 아직 많다네요)</p>\n<p data-ke-size=\"size16\">공산당은 능력이 있기 때문에 얼마든지 잡을 수 있다고하는데<br />범인을 잡으면 되지 기사를 내리는 방식으로 진행되네요<br />그래서 이 사태가 공산당이랑 연결되어있다는 것을 의심할 수 잇습니다.</p>\n<p data-ke-size=\"size16\">그런데 ... 미국의 사레를 보면 은행 터지면 정부에서 돈찍어서 해결하면 되는데요</p>\n<p data-ke-size=\"size16\">중국은 왜 이걸 안하는지 모르겠습니다.</p>\n<p data-ke-size=\"size16\">설마 이런걸까요?</p>\n<p data-ke-size=\"size16\">1. 돈을 찍으면 위안화 가치가 떨어진다.<br />2. 돈은 공산당원들이 많이 가지고있다.<br />3. 본인들 재산을 지키기 위해 ???</p>\n<p data-ke-size=\"size16\">어질어질 합니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=XiGgdsyzItQ\n\n\n\n중국이 맛이가서 신난 분들도 있고\n살아야 한국도 산다는 분들도 있고 그런 상황입니다.\n2차전지는 중국이랑 경쟁중이기 때문에 중국이 쓰러지면 좋아야되는데 연일 빠지네요 ㄷㄷㄷ\n \n영상을 보시면 지방 은행이 하나 갑자기 문을 닫고 잠적했는데\n여기서 전개가 신기하게 되네요\n \n1. 은행 문닫고 도망감\n2. 사람들 항의함\n3. 은행 도망 사태의 기사가 내려감\n     (영상은 개인이 올려서 그런지 덜 내려간건지 아직 많다네요)\n공산당은 능력이 있기 때문에 얼마든지 잡을 수 있다고하는데\n범인을 잡으면 되지 기사를 내리는 방식으로 진행되네요\n그래서 이 사태가 공산당이랑 연결되어있다는 것을 의심할 수 잇습니다.\n그런데 ... 미국의 사레를 보면 은행 터지면 정부에서 돈찍어서 해결하면 되는데요\n중국은 왜 이걸 안하는지 모르겠습니다.\n설마 이런걸까요?\n1. 돈을 찍으면 위안화 가치가 떨어진다.\n2. 돈은 공산당원들이 많이 가지고있다.\n3. 본인들 재산을 지키기 위해 ???\n어질어질 합니다.",
        "guid": "http://serverdown.tistory.com/956",
        "categories": [
          "유튜브",
          "오블완",
          "중국",
          "티스토리챌린지"
        ],
        "isoDate": "2024-11-12T03:01:45.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "토스 미국 국채 1개월 상품은 연 5.4% 이자 주는군요",
        "link": "http://serverdown.tistory.com/955",
        "pubDate": "Mon, 11 Nov 2024 23:34:20 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/955#entry955comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"866\" data-origin-height=\"389\"><span data-url=\"https://blog.kakaocdn.net/dn/b1I4TO/btsKEdnrsTg/cwKfnFv34Zk1oxGKgzN1Tk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/b1I4TO/btsKEdnrsTg/cwKfnFv34Zk1oxGKgzN1Tk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/b1I4TO/btsKEdnrsTg/cwKfnFv34Zk1oxGKgzN1Tk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb1I4TO%2FbtsKEdnrsTg%2FcwKfnFv34Zk1oxGKgzN1Tk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"866\" data-origin-height=\"389\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">토스에 5% 짜리 예금이 있다길레 가서봤더니 미국 국채군요</p>\n<p data-ke-size=\"size16\">요즘같이 원화가 맛탱이 가고 있을땐 미국 구채가 좋습니다.</p>\n<p data-ke-size=\"size16\">원화가 강해지면 미국 국채는 안좋지만 ... <br />원화가 강해지다니요.<br />상상이 가지 않습니당.<br /><br /></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">구경하기</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"434\" data-origin-height=\"941\"><span data-url=\"https://blog.kakaocdn.net/dn/cgLNSP/btsKFinNAvD/9PKXU2wMP4l3mi3gumFCA1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cgLNSP/btsKFinNAvD/9PKXU2wMP4l3mi3gumFCA1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cgLNSP/btsKFinNAvD/9PKXU2wMP4l3mi3gumFCA1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcgLNSP%2FbtsKFinNAvD%2F9PKXU2wMP4l3mi3gumFCA1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"434\" data-origin-height=\"941\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">예상 수익이 어마어마하게 높은데요.<br />저렇게 줄리가 없겠죠.</p>\n<p data-ke-size=\"size16\">1개월 짜리 채권을 1년동안 계속 돌리면 받게될 금액 같습니다.<br />한마디로 낚는거죠</p>\n<p data-ke-size=\"size16\">한달 후 약 5,500 원 정도 받게 될 것 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">채권 체험기 - 구매 대기중</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"562\" data-origin-height=\"511\"><span data-url=\"https://blog.kakaocdn.net/dn/9zhzr/btsKFcnN3tL/UxDKp1T5o67bKZHWLvymKK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/9zhzr/btsKFcnN3tL/UxDKp1T5o67bKZHWLvymKK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/9zhzr/btsKFcnN3tL/UxDKp1T5o67bKZHWLvymKK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F9zhzr%2FbtsKFcnN3tL%2FUxDKp1T5o67bKZHWLvymKK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"562\" data-origin-height=\"511\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">바로 구매 되는건 아니고 대기타네요</p>\n<p data-ke-size=\"size16\">미국 정규장에서 구매되고 <br />매진되면 다음날 취소된다고 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">구매방법</h2>\n<p data-ke-size=\"size16\">메뉴의 위치 알려드리겠습니다.</p>\n<p data-ke-size=\"size16\">1. 돈 준비해두시구요 채권 한개가격이 138만원 입니다. $999 짜리라 그런가 봅니다.</p>\n<p data-ke-size=\"size16\">2. 하단 메뉴에 [증권] 으로 갑니다.</p>\n<p data-ke-size=\"size16\">3. 상단 메뉴에 [발견] 을 누릅니다.</p>\n<p data-ke-size=\"size16\">4. 바로 밑에 [채권] 버튼이 생깁니다. 누르세요</p>\n<p data-ke-size=\"size16\">5. [미국채권 1개월 후 만기]&nbsp; 를 누릅니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"410\" data-origin-height=\"196\"><span data-url=\"https://blog.kakaocdn.net/dn/kB3KW/btsKDUhlJHI/c1BhBm5Q6KFa9RPvnK7SN0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/kB3KW/btsKDUhlJHI/c1BhBm5Q6KFa9RPvnK7SN0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/kB3KW/btsKDUhlJHI/c1BhBm5Q6KFa9RPvnK7SN0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FkB3KW%2FbtsKDUhlJHI%2Fc1BhBm5Q6KFa9RPvnK7SN0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"410\" data-origin-height=\"196\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">와 6% 네 하면서 25년 15년 짜리 고르시면 힘들어집니다.<br />진짜로 25년 기다리는 수가 있으니 삼가해주세요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">주의점</h2>\n<p data-ke-size=\"size16\">이걸 사시면 137만원을 <span style=\"text-align: start;\">$</span>999 로 바꾸게 되는데요 환전 수수료는 없지만</p>\n<p data-ke-size=\"size16\">현재 환율 달러당 1,400 에서 내려가버리면<br />즉 원화가 올라서 달러당 1,350 원이 된다면 그 부분만큼은 손해가 난다고 보시면 됩니다.</p>\n<p data-ke-size=\"size16\">그래서 이상품은 원하 가치가 하락할때 하셔야합니다.</p>\n<p data-ke-size=\"size16\">한국은행이 금리 인상한다면 손해볼 수 있습니다.</p>\n<p data-ke-size=\"size16\">현재 한국 상태를 봐선 그럴일이 없어보이지만요.</p>\n<p data-ke-size=\"size16\">읽으시는 분은 주의하시기 바랍니다.<br />도중에 팔 수 있는지는 알아보고 적어드리겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "토스에 5% 짜리 예금이 있다길레 가서봤더니 미국 국채군요\n요즘같이 원화가 맛탱이 가고 있을땐 미국 구채가 좋습니다.\n원화가 강해지면 미국 국채는 안좋지만 ... \n원화가 강해지다니요.\n상상이 가지 않습니당.\n\n \n구경하기\n\n\n예상 수익이 어마어마하게 높은데요.\n저렇게 줄리가 없겠죠.\n1개월 짜리 채권을 1년동안 계속 돌리면 받게될 금액 같습니다.\n한마디로 낚는거죠\n한달 후 약 5,500 원 정도 받게 될 것 같습니다.\n \n채권 체험기 - 구매 대기중\n\n\n바로 구매 되는건 아니고 대기타네요\n미국 정규장에서 구매되고 \n매진되면 다음날 취소된다고 합니다.\n \n구매방법\n메뉴의 위치 알려드리겠습니다.\n1. 돈 준비해두시구요 채권 한개가격이 138만원 입니다. $999 짜리라 그런가 봅니다.\n2. 하단 메뉴에 [증권] 으로 갑니다.\n3. 상단 메뉴에 [발견] 을 누릅니다.\n4. 바로 밑에 [채권] 버튼이 생깁니다. 누르세요\n5. [미국채권 1개월 후 만기]  를 누릅니다.\n\n\n와 6% 네 하면서 25년 15년 짜리 고르시면 힘들어집니다.\n진짜로 25년 기다리는 수가 있으니 삼가해주세요\n \n주의점\n이걸 사시면 137만원을 $999 로 바꾸게 되는데요 환전 수수료는 없지만\n현재 환율 달러당 1,400 에서 내려가버리면\n즉 원화가 올라서 달러당 1,350 원이 된다면 그 부분만큼은 손해가 난다고 보시면 됩니다.\n그래서 이상품은 원하 가치가 하락할때 하셔야합니다.\n한국은행이 금리 인상한다면 손해볼 수 있습니다.\n현재 한국 상태를 봐선 그럴일이 없어보이지만요.\n읽으시는 분은 주의하시기 바랍니다.\n도중에 팔 수 있는지는 알아보고 적어드리겠습니다.",
        "guid": "http://serverdown.tistory.com/955",
        "categories": [
          "투자",
          "채권"
        ],
        "isoDate": "2024-11-11T14:34:20.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "비트액스 감마 채굴기 광고 + 설명 영상이 올라왔군요 / Bitaxe Gamma",
        "link": "http://serverdown.tistory.com/954",
        "pubDate": "Mon, 11 Nov 2024 20:40:28 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/954#entry954comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/p6hvc/btsKD5QsBEr/nVSwrtvFWJAWPFkPqT5SR0/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/p6hvc/btsKD5QsBEr/nVSwrtvFWJAWPFkPqT5SR0/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/p6hvc/btsKD5QsBEr/nVSwrtvFWJAWPFkPqT5SR0/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fp6hvc%2FbtsKD5QsBEr%2FnVSwrtvFWJAWPFkPqT5SR0%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=4bOT37MZOPY&amp;t=3s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=4bOT37MZOPY&amp;t=3s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=4bOT37MZOPY\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/eeG6pt/hyXwtXCUFa/IFJPqfpLGaNU7PXpIXoFW0/img.jpg?width=1280&amp;height=720&amp;face=738_128_854_256,https://scrap.kakaocdn.net/dn/QccoN/hyXwnwi3T1/CMtPZyMa1aKm1mv5w7WUm1/img.jpg?width=1280&amp;height=720&amp;face=738_128_854_256\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"Worlds smallest Bitcoin asic miner Bitaxe Gamma , hidden prize !\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/4bOT37MZOPY\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">썸네일을 보시면 이미 당첨될것 같이 적어뒀군요</p>\n<p data-ke-size=\"size16\">이렇게 해줘야 사람들이 보고 하겠군요</p>\n<p data-ke-size=\"size16\">영상에 셋팅 방법도 있으니 구입전에 참고 보시면 좋을 것 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">판매 페이지:<a href=\"https://mineshop.eu/-bitaxe-gamma\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\"> https://mineshop.eu/-bitaxe-gamma</a></p>\n<p data-ke-size=\"size16\">비트로닉스는 150 유로인데 여기는 195유로 군요<br />배짱장사 오지는군요<br />독같이 생겼구만</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/baabFY/btsKFG9xhfM/cwcwEz9TSK0of3c9lyreL1/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/baabFY/btsKFG9xhfM/cwcwEz9TSK0of3c9lyreL1/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/baabFY/btsKFG9xhfM/cwcwEz9TSK0of3c9lyreL1/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbaabFY%2FbtsKFG9xhfM%2FcwcwEz9TSK0of3c9lyreL1%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">방열판 땐 사진이 있군요 이렇게 생겼군요</p>\n<p data-ke-size=\"size16\">좀더 큰 방열판을 달고 싶군요</p>\n<p data-ke-size=\"size16\">이왕이면 그래픽 카드처럼 앞뒤로</p>\n<p data-ke-size=\"size16\">누가 만들어주려나...</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=4bOT37MZOPY&t=3s\n\n\n\n썸네일을 보시면 이미 당첨될것 같이 적어뒀군요\n이렇게 해줘야 사람들이 보고 하겠군요\n영상에 셋팅 방법도 있으니 구입전에 참고 보시면 좋을 것 같습니다.\n \n판매 페이지: https://mineshop.eu/-bitaxe-gamma\n비트로닉스는 150 유로인데 여기는 195유로 군요\n배짱장사 오지는군요\n독같이 생겼구만\n \n\n\n방열판 땐 사진이 있군요 이렇게 생겼군요\n좀더 큰 방열판을 달고 싶군요\n이왕이면 그래픽 카드처럼 앞뒤로\n누가 만들어주려나...",
        "guid": "http://serverdown.tistory.com/954",
        "categories": [
          "코인"
        ],
        "isoDate": "2024-11-11T11:40:28.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "지구온난화 잡았다. CO2 흡수 분말 탄생 / COF-999",
        "link": "http://serverdown.tistory.com/953",
        "pubDate": "Mon, 11 Nov 2024 20:28:09 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/953#entry953comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=AwHJryy_0vo\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=AwHJryy_0vo</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=AwHJryy_0vo\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/1yEWl/hyXwsdiSMl/KyLevYURyJK7v0gYwFGbTk/img.jpg?width=1280&amp;height=720&amp;face=216_124_386_310,https://scrap.kakaocdn.net/dn/QN0O4/hyXwsRUVhu/vjK15kG42Z2oqHVKS30cT0/img.jpg?width=1280&amp;height=720&amp;face=216_124_386_310\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"이산화 탄소를 마법같이 흡착하는 COF-999! 이산화 탄소의 흡착 능력과 제거하는 원리는 무엇일까?\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/AwHJryy_0vo\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">전기차 시대 이래서 오겠냐</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">뉴스: <a href=\"https://www.playforum.net/news/articleView.html?idxno=416783\">UC버클리, 탄소포집 기술 '게임체인저' 신소재 개발...이산화탄소 제거산업에 혁명 &lt; 산업/IR &lt; 기사본문 - 플레이포럼</a></p>\n<figure id=\"og_1731324456354\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"UC버클리, 탄소포집 기술 '게임체인저' 신소재 개발...이산화탄소 제거산업에 혁명 - 플레이포럼\" data-og-description=\"캘리포니아 버클리 대학교 연구진이 대기 중 이산화탄소를 포집하는 획기적인 신소재 COF-999를 개발했다고 밝혔다.다공성 소재인 \\'결합 유기 프레임워크(COF)\\'는 대기 중 탄소 포집에 필요한 내\" data-og-host=\"www.playforum.net\" data-og-source-url=\"https://www.playforum.net/news/articleView.html?idxno=416783\" data-og-url=\"https://www.playforum.net/news/articleView.html?idxno=416783\" data-og-image=\"https://scrap.kakaocdn.net/dn/cNwktt/hyXsTiRYvF/MMXAwlqr1ooMhwVjkVDwWK/img.jpg?width=600&amp;height=343&amp;face=0_0_600_343,https://scrap.kakaocdn.net/dn/p5wSO/hyXwnwiWXr/dLIde4Wg8qdK1qLONzwSw1/img.jpg?width=600&amp;height=343&amp;face=0_0_600_343\"><a href=\"https://www.playforum.net/news/articleView.html?idxno=416783\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.playforum.net/news/articleView.html?idxno=416783\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/cNwktt/hyXsTiRYvF/MMXAwlqr1ooMhwVjkVDwWK/img.jpg?width=600&amp;height=343&amp;face=0_0_600_343,https://scrap.kakaocdn.net/dn/p5wSO/hyXwnwiWXr/dLIde4Wg8qdK1qLONzwSw1/img.jpg?width=600&amp;height=343&amp;face=0_0_600_343');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">UC버클리, 탄소포집 기술 '게임체인저' 신소재 개발...이산화탄소 제거산업에 혁명 - 플레이포럼</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">캘리포니아 버클리 대학교 연구진이 대기 중 이산화탄소를 포집하는 획기적인 신소재 COF-999를 개발했다고 밝혔다.다공성 소재인 \\'결합 유기 프레임워크(COF)\\'는 대기 중 탄소 포집에 필요한 내</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.playforum.net</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 분말은 나무가 이산화 탄소를 흡수하는 효과와 동일한 기능이 있다고합니다.</p>\n<p data-ke-size=\"size16\">온난화를 간단하게 해결해버렸군요</p>\n<p data-ke-size=\"size16\">누가 양상할지가 중요할 것 같습니다.</p>\n<p data-ke-size=\"size16\">꾸준히 찾아봐야겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이렇게 간단히 온난화가 끝나버리다니 ...</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=AwHJryy_0vo\n\n\n\n전기차 시대 이래서 오겠냐\n \n뉴스: UC버클리, 탄소포집 기술 '게임체인저' 신소재 개발...이산화탄소 제거산업에 혁명 < 산업/IR < 기사본문 - 플레이포럼\n\n \nUC버클리, 탄소포집 기술 '게임체인저' 신소재 개발...이산화탄소 제거산업에 혁명 - 플레이포럼\n캘리포니아 버클리 대학교 연구진이 대기 중 이산화탄소를 포집하는 획기적인 신소재 COF-999를 개발했다고 밝혔다.다공성 소재인 \\'결합 유기 프레임워크(COF)\\'는 대기 중 탄소 포집에 필요한 내\nwww.playforum.net\n\n \n이 분말은 나무가 이산화 탄소를 흡수하는 효과와 동일한 기능이 있다고합니다.\n온난화를 간단하게 해결해버렸군요\n누가 양상할지가 중요할 것 같습니다.\n꾸준히 찾아봐야겠습니다.\n \n이렇게 간단히 온난화가 끝나버리다니 ...",
        "guid": "http://serverdown.tistory.com/953",
        "categories": [
          "유튜브"
        ],
        "isoDate": "2024-11-11T11:28:09.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": [
      {
        "creator": "coolspeed",
        "title": "라즈베리파이에서 LLM을 돌려봤다",
        "link": "https://coolspeed.wordpress.com/2024/11/10/%eb%9d%bc%ec%a6%88%eb%b2%a0%eb%a6%ac%ed%8c%8c%ec%9d%b4%ec%97%90%ec%84%9c-llm%ec%9d%84-%eb%8f%8c%eb%a0%a4%eb%b4%a4%eb%8b%a4/",
        "pubDate": "Sun, 10 Nov 2024 08:56:09 +0000",
        "content:encodedSnippet": "별건 없다. 그냥 Ollama 설치해서 돌리면 잘 돌아간다. 하지만 경험이 재미 있다.\n신용카드만한 컴퓨터에서 튜링테스트 통과할만한 인공지능이 작동하는 것을 목격하는 것은 신기한 경험이었다.\n방법\n라즈베리파이는 라즈베리파이 5, 8GB 램 버전을 썼다. LLM 모델은 2b 사이즈의 Gemma 2를 사용했다.\n(라즈베리파이를 포함한) 리눅스 환경에 Ollama 설치 방법:\nhttps://ollama.com/download/linux\n설치하고 나면 NVIDIA나 AMD의 그래픽카드가 탐지되지 않아서, CPU only로 돌릴거라는 메시지가 뜬다. 무시하면 된다.\nGemma 2 실행 방법:\nollama run gemma2:2b\n그러면 gemma2:2b 모델이 자동으로 다운로드 되고, 실행된다.\n프롬프트가 뜨면 이제부터 LLM과 대화할 수가 있다.",
        "dc:creator": "coolspeed",
        "comments": "https://coolspeed.wordpress.com/2024/11/10/%eb%9d%bc%ec%a6%88%eb%b2%a0%eb%a6%ac%ed%8c%8c%ec%9d%b4%ec%97%90%ec%84%9c-llm%ec%9d%84-%eb%8f%8c%eb%a0%a4%eb%b4%a4%eb%8b%a4/#respond",
        "content": "별건 없다. 그냥 Ollama 설치해서 돌리면 잘 돌아간다. 하지만 경험이 재미 있다. 신용카드만한 컴퓨터에서 튜링테스트 통과할만한 인공지능이 작동하는 것을 목격하는 것은 신기한 경험이었다. 방법 라즈베리파이는 라즈베리파이 5, 8GB 램 버전을 썼다. LLM 모델은 2b 사이즈의 Gemma 2를 사용했다. (라즈베리파이를 포함한) 리눅스 환경에 Ollama 설치 방법: https://ollama.com/download/linux 설치하고 나면 NVIDIA나 AMD의 그래픽카드가 탐지되지 않아서, CPU only로 [&#8230;]",
        "contentSnippet": "별건 없다. 그냥 Ollama 설치해서 돌리면 잘 돌아간다. 하지만 경험이 재미 있다. 신용카드만한 컴퓨터에서 튜링테스트 통과할만한 인공지능이 작동하는 것을 목격하는 것은 신기한 경험이었다. 방법 라즈베리파이는 라즈베리파이 5, 8GB 램 버전을 썼다. LLM 모델은 2b 사이즈의 Gemma 2를 사용했다. (라즈베리파이를 포함한) 리눅스 환경에 Ollama 설치 방법: https://ollama.com/download/linux 설치하고 나면 NVIDIA나 AMD의 그래픽카드가 탐지되지 않아서, CPU only로 […]",
        "guid": "http://coolspeed.wordpress.com/?p=3464",
        "categories": [
          "未分类"
        ],
        "isoDate": "2024-11-10T08:56:09.000Z"
      }
    ]
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": []
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "한상곤 - Sigmadream",
    "category": "개인",
    "posts": [
      {
        "creator": "Sangkon Han",
        "title": "내 맘대로 위클리 뉴스 - 2024년 44주(2024.11.03 - 2024.11.09)",
        "link": "https://www.sangkon.com/sigmadream_weekly_2024_44/",
        "pubDate": "Fri, 08 Nov 2024 18:06:00 GMT",
        "content:encodedSnippet": "Python\nWrite more pythonic code with context managers\nPython의 context managers를 활용하는 방법을 소개하는 기사 입니다.\nHost a FastAPI Application Without a Server\nFastAPI를 빠르게 배포하는 방법을 소개합니다.\nJavaScript\nConditional React hooks pattern\n\n조건부 Hooks을 활용하는 방법을 소개하는 기사 입니다.\nOOP\nBuilding a Full-Stack Application with Next.js and .NET API Backend\n\n.NET과 Next.js를 함꼐 활용하는 방법을 소개하는 기사 입니다.",
        "dc:creator": "Sangkon Han",
        "content": "<h2 id=\"python\">Python</h2>\n<ul>\n<li>\n<p><a href=\"https://hamatti.org/posts/write-more-pythonic-code-with-context-managers/?ref=sangkon.com\">Write more pythonic code with context managers</a></p>\n<ul>\n<li>Python&#xC758; context managers&#xB97C; &#xD65C;&#xC6A9;&#xD558;&#xB294; &#xBC29;&#xBC95;&#xC744; &#xC18C;&#xAC1C;&#xD558;&#xB294; &#xAE30;&#xC0AC; &#xC785;&#xB2C8;&#xB2E4;.</li>\n</ul>\n</li>\n<li>\n<p><a href=\"https://pinggy.io/blog/host_a_fastapi_app_without_a_server/?ref=sangkon.com\">Host a FastAPI Application Without a Server</a></p>\n<ul>\n<li>FastAPI&#xB97C; &#xBE60;&#xB974;&#xAC8C; &#xBC30;&#xD3EC;&#xD558;&#xB294; &#xBC29;&#xBC95;&#xC744; &#xC18C;&#xAC1C;</li></ul></li></ul>",
        "contentSnippet": "Python\nWrite more pythonic code with context managers\nPython의 context managers를 활용하는 방법을 소개하는 기사 입니다.\nHost a FastAPI Application Without a Server\nFastAPI를 빠르게 배포하는 방법을 소개",
        "guid": "672e5302bf78853c742b06ce",
        "categories": [
          "주간 뉴스"
        ],
        "isoDate": "2024-11-08T18:06:00.000Z"
      }
    ]
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": []
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": [
      {
        "title": "테크스펙은 문서가 아니다",
        "link": "https://blog.banksalad.com/tech/techspec-is-not-doc/",
        "pubDate": "Mon, 11 Nov 2024 00:00:00 GMT",
        "content": "안녕하세요. 뱅크샐러드에서 Tech Lead…",
        "contentSnippet": "안녕하세요. 뱅크샐러드에서 Tech Lead…",
        "guid": "https://blog.banksalad.com/tech/techspec-is-not-doc/",
        "isoDate": "2024-11-11T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": [
      {
        "title": "OpenInfra Asia Summit 2024 돌아보기",
        "link": "https://meetup.nhncloud.com/posts/389",
        "pubDate": "Mon, 11 Nov 2024 02:16:45 GMT",
        "content": "![1.jpg](https://image.toast.com/aaaadh/real/2024/techblog/1.jpg)\r\r\n\r\r\n\r\r\n> 본 콘텐츠는 OpenInfra Foundation의 공식 블로그 [Superuser](https://superuser.openinfra.dev/articles/openinfra-asia-summit-2024-recap/)에 영문본이 게시되었습니다.\r\r\n<br/>\r\r\n\r\r\n\r\r\n지난 9월 3일 개최된 오픈인프라 아시아 서밋(OpenInfra Summit Asia) 2024에 참여하는 좋은 기회를 얻게 되었습니다. 오픈인프라 아시아 서밋은 아시아 전역의 오픈소스 커뮤니티를 지원하기 위해 2023년 설립된 지역 허브인 [오픈인프라 아시아(OpenInfra Asia)](https://openinfraasia.org/)가 개최하는 첫 번째 서밋으로 그 자체로 매우 의미 있는 행사였습니다. 이번 서밋에는 앤트그룹, 화웨이 등 아시아 지역 유수의 기업이 참여했는데요. 그 중 [NHN Cloud](https://www.nhncloud.com/kr)도 아시아 지역의 핵심 클라우드 서비스 기업으로서 오픈스택 기술력과 그간의 커뮤니티 활동을 인정받아 오픈인프라 아시아의 창립 멤버로 초대되었다고 합니다.\r\r\n\r\r\n또한 이번 행사는 주요 오픈 소스 재단인 [Open Compute Project(OCP)](https://www.opencompute.org/) 재단과 공동으로 주최되어, 두 글로벌 오픈 소스 커뮤니티의 핵심 재단이 손잡은 만큼 규모도 크고 프로그램도 매우 다양하고 풍성하게 구성되었습니다.\r\r\n\r\r\n무려 240명이 넘는 연사가 190개 이상의 세션을 제공했으며, 리눅스, 오픈스택, Kubernetes 외 30개 이상의 오픈소스 프로젝트 등 다루는 주제도 무척 다양했습니다. 30개국이 넘는 국가에서 1500명이 넘는 참가자와 함께 저도 유익하고 인사이트가 풍부한 세션들을 들을 수 있었습니다.\r\r\n\r\r\n![2.jpg](https://image.toast.com/aaaadh/real/2024/techblog/2%281%29.jpg)\r\r\n귀중한 정보를 담은 세션들이 주로 영어와 한국어로 제공되었으며 영어 세션이 다수를 이루었습니다. 따라서 영어가 익숙지 않은 청중들을 위해 flitto 동시번역 서비스로 16개국 이상의 언어를 제공한다는 점이 무척 흥미로웠습니다. 세션 룸에 동시번역 서비스 QR 코드가 배치되어있어, 앱 다운없이 손쉽고 간편하게 접근할 수 있었습니다.\r\r\n\r\r\n많은 참가자들이 자신의 패드에서 번역 서비스를 통해 연사가 말하자마자 매끄럽게 번역된 콘텐츠를 접할 수 있었습니다.\r\r\n\r\r\n## Keynotes\r\r\n\r\r\n![3.jpg](https://image.toast.com/aaaadh/real/2024/techblog/3%281%29.jpg)\r\r\n오픈 인프라 재단의 최고운영책임자(COO)인 Mark Collier의 키노트가 무척 인상 깊었는데요. 인프라 전반의 트렌드 4가지를 일목요연하고 간결하게 정리해 주었습니다.\r\r\n\r\r\n### Digital Sovereignty\r\r\n\r\r\n\r\r\n내 데이터가 어디에 저장되고 누가 접근 가능하며 어떤 법률의 지배를 받는지에 대한 관심이 커지고 중요한 사안이 되었는데요. 이는 개인에 국한되지 않고, 국가 기관 및 정부에게도 중요한 사안이 되었습니다.\r\r\n대표적인 예로 프랑스의 주요 은행들이 오픈 스택을 채택해 자신들의 데이터 위치와 접근 권한, 적용되는 법률을 직접 관리하고 있습니다. 이렇게 주요 기관들이 자신들의 데이터를 매우 독점적으로 처리하고 보유하고자하는 트렌드는 전 세계적으로 나타나고 있습니다.\r\r\n\r\r\n이 같은 트렌드는 하드웨어 영역에서도 나타나고 있는데요. RISC-V가 그 예입니다.\r\r\n\r\r\n> RISC-V는 2010년 UC 버클리에서 개발한 오픈소스 RISC(Reduced Instruction Set Computer) 명령어 세트 아키텍처입니다. RISC-V 아키텍처를 통해 설계자는 최종 애플리케이션에 맞게 프로세서를 맞춤화하고 설계할 수 있습니다.\r\r\n\r\r\n즉 현재는 기존에 사용하는 프로그램이나 하드웨어에 대해 영구적인 접근 권한을 갖고 통제하고 원하는 대로 사용하고 싶어 하는 산업 전반의 트렌드가 있다고 합니다. 이 같은 트렌드로 오픈 소스 및 오픈 테크놀로지는 그 어느 때보다 중요해졌다고 합니다.\r\r\n\r\r\n### License Changes\r\r\n\r\r\n\r\r\n* Terraform\r\r\n예상치 못한 라이선스 변경으로 시장에 악영향을 미쳤지만, 오픈소스가 이에 대한 해결책을 제시해 줄 수 있습니다. Terraform의 라이선스 변경으로 인해 오픈 소스 프로젝트인 Open Tofu가 등장하여 테라폼을 대체하는 역할을 수행해 사용자들에게 신뢰를 제공하고 있습니다.\r\r\n\r\r\n* VMware\r\r\nVMware의 라이선스가 변경됨에 따라 많은 사용자들이 VMware에서 OpenStack으로 마이그레이션에 대한 관심이 커지고 있습니다. 대표적으로 미국의 주요 자동차 보험사인 GEICO가 최근 VMware를 버리고 오픈스택으로 대규모 클라우드 인프라를 구축해 큰 주목을 받았다고 합니다. Mark Collier는 마이그레이션에 관한 백서를 행사 당일에 [QR](https://www.openstack.org/vmware-migration-to-openstack-white-paper)로 공개하기도 했습니다.\r\r\n\r\r\n### Security Concerns\r\r\n\r\r\n\r\r\n최근 운영 중인 컨테이너 이미지의 87%에 치명적이거나 심각도가 높은 취약점이 있다는 사실이 밝혀져 우려를 자아내고 있습니다. 이 문제를 해결하기 위한 방안으로 오픈 인프라 재단에서 주최하는 카타 컨테이너(Kata Container) 프로젝트가 큰 주목을 받고 있습니다. 카타 컨테이너는 컨테이너의 속도와 가상 머신의 보안을 결합한 경량 가상화를 제공함으로써 속도와 보안 사이의 균형을 제공합니다. 컨테이너 환경 보안에 효과적이라는 점에서 Microsoft Azure, NVIDIA, AWS 등 주요 기업들이 카타 컨테이너에 투자하고 지원하고 있습니다.\r\r\n\r\r\n### AI Redefining Infra\r\r\n\r\r\n\r\r\nAI에 대한 기업들의 관심이 이례적입니다. 너도 나도 할 것 없이 기업들은 GPU를 최대한 많이 확보해 방대한 규모로 자신의 데이터 센터에 구축하고 있습니다. 기업이 AI 용량 구축에 거대한 투자하고 있으며, 오픈스택이 AI 워크 로드를 지원하는 데 중요한 역할을 하고 있습니다.\r\r\n\r\r\n이렇게 디지털 주권, 라이선스 변경, 보안 문제, 인공지능과 같이 네 가지 주요 트렌드로 오픈 소스에 대한 관심과 투자가 그 어느 때보다도 활발하게 일어나고 있고 오픈 소스 커뮤니티의 성장을 이끌고 있다고 합니다.\r\r\n\r\r\n## Sessions\r\r\n\r\r\n오픈인프라 아시아 서밋 2024에는 다양한 주제에 대해 심도 있는 내용을 다루는 세션이 많았는데요. 저는 그중 NHN Cloud 인프라서비스개발랩 박성우 이사님이 발표하신 세션 **Openstack of NHN Cloud from a network perspective**을 통해 오픈스택의 실제 적용 사례와 오픈스택의 한계점을 어떻게 보완했는지를 배울 수 있었습니다. 아래는 세션 내용의 일부를 요약해 보았습니다.\r\r\n\r\r\n### 1. Openstack of NHN Cloud from a network perspective\r\r\n\r\r\n![4.jpg](https://image.toast.com/aaaadh/real/2024/techblog/4%281%29.jpg)\r\r\n\r\r\n>  [영상 보러 가기](https://www.youtube.com/watch?v=IgXJq8jmuJI&t=1s)\r\r\n\r\r\nNHN Cloud는 2015년에 OpenStack의 Neutron 모듈을 활용해 네트워크를 구축하고 서비스를 시작했습니다. 하지만 서비스 초기 단계에서는 Neutron 모듈의 기본 기능만으로는 NHN Cloud의 서비스들을 효율적이고 안정적으로 운영하는 데 한계가 있었다고 합니다. 이중화가 불가능하고 장애 조치 및 스케일업 기능이 지원되지 않았기 때문입니다. 이번 세션에서는 NHN Cloud가 이러한 문제를 어떻게 해결했는지에 대해 자세히 다뤘습니다.\r\r\n\r\r\nNeutron의 기본 구조는 컴퓨트 노드 안에 큐라우터와 OVS integration bridge, 그리고 그 사이에 위치한 리눅스 브릿지로 구성됩니다. 여기에 IP 테이블을 연결하여 보안 규칙(Security Rules)을 설정하게 됩니다. 하지만 이 구조는 보안 규칙이 많아질수록 코드 오류의 원인을 파악하고 문제를 분석하는 데 어려움을 겪게 되며 유지 보수에 큰 부담이 따랐다고 합니다. 더구나 리눅스 브릿지는 OSI 모델의 2계층에서만 동작하기 때문에, 라우팅이나 IP 주소를 기반으로 트래픽을 처리하는 데도 한계가 있었습니다.\r\r\n\r\r\n![5.png](https://image.toast.com/aaaadh/real/2024/techblog/5.png)\r\r\n\r\r\n이러한 문제를 해결하기 위해 NHN Cloud는 컴퓨트 노드에서 리눅스 브릿지와 큐라우터를 제거하고, OVS integration bridge로 대체하는 방식을 채택했습니다. 네트워크를 VxLAN마다 나누고 각 브릿지와 연결하는 방식으로 구성하여 더 효율적인 네트워크 구조를 구현했습니다. 또한, NVIDIA의 SR-IOV Representer를 OVS bridge와 연결해 I/O 성능을 대폭 개선한 점이 인상 깊었습니다.\r\r\n\r\r\n> SR-IOV는 하나의 물리적 PCI Express 장치를 여러 가상 머신이 동시에 사용할 수 있게 해주는 기술로, 가상화 환경에서 매우 유용한 기술입니다.\r\r\n\r\r\n앞서 컴퓨트 노드에서 큐라우터를 제거했다고 했는데요. 이는 큐라우터의 한계를 극복하기 위한 조치로 랙 상단으로 이동시켰습니다. 즉, 각 랙이 하이퍼바이저처럼 작동하게 되어 컴퓨트 노드의 구조가 단순화되고, 최대 효율을 추구할 수 있었습니다.\r\r\n\r\r\n하지만 이러한 구조에서는 모든 트래픽이 랙 상단의 라우터로 집중되는 문제가 발생했습니다. 이를 해결하기 위해 NHN Cloud는 vSwitch를 개발했으며, 이 vSwitch는 5mpps(초당 500만 패킷)의 뛰어난 처리 속도를 자랑합니다.\r\r\n\r\r\n또한, VLAN에서 VxLAN으로 전환한 이유도 흥미로웠는데, 이는 고객 수가 증가함에 따라 퍼블릭 환경에서 여러 VPC(Virtual Private Cloud)를 생성해야 했기 때문입니다.\r\r\n\r\r\n### 보안과 안정성\r\r\n\r\r\n\r\r\n보안과 안정성 측면에서도 다양한 개선이 이루어졌습니다. 기본적으로 Neutron이 제공하는 Security Groups와 함께 Network ACL을 구성하여, 서버가 클라이언트 상태 정보를 저장하지 않아도 통신할 수 있는 환경을 구축했습니다. 또한, Internet Gateway 없이도 원격 호스트와 통신할 수 있도록 VPN Gateway를 연결해 네트워크 통신의 유연성을 강화했습니다.\r\r\n\r\r\n![6.png](https://image.toast.com/aaaadh/real/2024/techblog/6.png)\r\r\n\r\r\nNHN Cloud는 2015년 서비스 시작 이후, OpenStack Neutron에 다양한 기능을 추가하기 위해 여러 플러그인과 자체 개발한 에이전트들을 도입해왔는데요. 세션을 통해 NHN Cloud가 기존의 네트워크 문제를 혁신적으로 해결하고, 서비스 안정성과 보안을 동시에 강화한 점을 직접 확인할 수 있었습니다. 동시에 클라우드 네트워크 관리의 복잡성을 체감할 수 있었습니다.\r\r\n\r\r\n<br/>\r\r\n\r\r\n### 2. Bridging the Gap Between Community and Contributing Orgs\r\r\n\r\r\n![7.jpg](https://image.toast.com/aaaadh/real/2024/techblog/7.jpg)\r\r\n\r\r\n강의 형태로 진행되는 세션이 아닌 참석자들과 함께 자유롭게 토의하는 포럼 형태의 세션도 제공되었습니다. 그중 하나인 **Bridging the Gap Between Community and Contributing Orgs**은 오픈 소스 커뮤니티를 더욱 활성화하기 위해 자유롭게 의견을 공유하는 자리였습니다. 주요 논의는 신규 기여자와 기존 기여자가 모두를 위한 커뮤니케이션을 활성화하고 기여자 경험을 개선하기 위한 방안을 논의하는 세션이었습니다.\r\r\n\r\r\n다양한 국가의 수많은 사람들이 오픈인프라 프로젝트에 기여하고 있는 만큼 커뮤니케이션의 한계를 극복하고 다양성을 높이고자하는 열정이 느껴지는 세션이었습니다.\r\r\n\r\r\n## OpenStack’s Role in the Future\r\r\n\r\r\n\r\r\n오픈인프라 서밋 아시아 2024는 클라우드 산업의 혁신을 선도하는 오픈소스 커뮤니티의 중요성을 다시 한 번 강조한 행사였습니다.\r\r\n\r\r\n특히 VMware에서 오픈스택으로의 마이그레이션이 주목을 받으면서 확장 가능하고, 안전하며, 비용 효율적인 솔루션으로 오픈스택을 도입하려는 기업들이 전 세계적으로 많다는 것을 느낄 수 있었습니다.\r\r\n\r\r\n또한, AI와 같은 고성능 컴퓨팅을 위한 지속 가능한 인프라에 대한 요구가 커지고 있는 상황에서, 오픈인프라 커뮤니티는 혁신적이고 획기적인 솔루션으로 이러한 글로벌 과제에 대응할 준비가 충분히 갖추어져 있음을 확인할 수 있었습니다. 이번 서밋을 통해 오픈소스 기반 인프라의 미래와 지속 가능한 기술 개발에 대한 기대감이 더욱 커졌습니다.",
        "contentSnippet": "![1.jpg](https://image.toast.com/aaaadh/real/2024/techblog/1.jpg)\r\r\n\r\r\n\r\r\n> 본 콘텐츠는 OpenInfra Foundation의 공식 블로그 [Superuser](https://superuser.openinfra.dev/articles/openinfra-asia-summit-2024-recap/)에 영문본이 게시되었습니다.\r\r\n\r\r\n\r\r\n\r\r\n지난 9월 3일 개최된 오픈인프라 아시아 서밋(OpenInfra Summit Asia) 2024에 참여하는 좋은 기회를 얻게 되었습니다. 오픈인프라 아시아 서밋은 아시아 전역의 오픈소스 커뮤니티를 지원하기 위해 2023년 설립된 지역 허브인 [오픈인프라 아시아(OpenInfra Asia)](https://openinfraasia.org/)가 개최하는 첫 번째 서밋으로 그 자체로 매우 의미 있는 행사였습니다. 이번 서밋에는 앤트그룹, 화웨이 등 아시아 지역 유수의 기업이 참여했는데요. 그 중 [NHN Cloud](https://www.nhncloud.com/kr)도 아시아 지역의 핵심 클라우드 서비스 기업으로서 오픈스택 기술력과 그간의 커뮤니티 활동을 인정받아 오픈인프라 아시아의 창립 멤버로 초대되었다고 합니다.\r\r\n\r\r\n또한 이번 행사는 주요 오픈 소스 재단인 [Open Compute Project(OCP)](https://www.opencompute.org/) 재단과 공동으로 주최되어, 두 글로벌 오픈 소스 커뮤니티의 핵심 재단이 손잡은 만큼 규모도 크고 프로그램도 매우 다양하고 풍성하게 구성되었습니다.\r\r\n\r\r\n무려 240명이 넘는 연사가 190개 이상의 세션을 제공했으며, 리눅스, 오픈스택, Kubernetes 외 30개 이상의 오픈소스 프로젝트 등 다루는 주제도 무척 다양했습니다. 30개국이 넘는 국가에서 1500명이 넘는 참가자와 함께 저도 유익하고 인사이트가 풍부한 세션들을 들을 수 있었습니다.\r\r\n\r\r\n![2.jpg](https://image.toast.com/aaaadh/real/2024/techblog/2%281%29.jpg)\r\r\n귀중한 정보를 담은 세션들이 주로 영어와 한국어로 제공되었으며 영어 세션이 다수를 이루었습니다. 따라서 영어가 익숙지 않은 청중들을 위해 flitto 동시번역 서비스로 16개국 이상의 언어를 제공한다는 점이 무척 흥미로웠습니다. 세션 룸에 동시번역 서비스 QR 코드가 배치되어있어, 앱 다운없이 손쉽고 간편하게 접근할 수 있었습니다.\r\r\n\r\r\n많은 참가자들이 자신의 패드에서 번역 서비스를 통해 연사가 말하자마자 매끄럽게 번역된 콘텐츠를 접할 수 있었습니다.\r\r\n\r\r\n## Keynotes\r\r\n\r\r\n![3.jpg](https://image.toast.com/aaaadh/real/2024/techblog/3%281%29.jpg)\r\r\n오픈 인프라 재단의 최고운영책임자(COO)인 Mark Collier의 키노트가 무척 인상 깊었는데요. 인프라 전반의 트렌드 4가지를 일목요연하고 간결하게 정리해 주었습니다.\r\r\n\r\r\n### Digital Sovereignty\r\r\n\r\r\n\r\r\n내 데이터가 어디에 저장되고 누가 접근 가능하며 어떤 법률의 지배를 받는지에 대한 관심이 커지고 중요한 사안이 되었는데요. 이는 개인에 국한되지 않고, 국가 기관 및 정부에게도 중요한 사안이 되었습니다.\r\r\n대표적인 예로 프랑스의 주요 은행들이 오픈 스택을 채택해 자신들의 데이터 위치와 접근 권한, 적용되는 법률을 직접 관리하고 있습니다. 이렇게 주요 기관들이 자신들의 데이터를 매우 독점적으로 처리하고 보유하고자하는 트렌드는 전 세계적으로 나타나고 있습니다.\r\r\n\r\r\n이 같은 트렌드는 하드웨어 영역에서도 나타나고 있는데요. RISC-V가 그 예입니다.\r\r\n\r\r\n> RISC-V는 2010년 UC 버클리에서 개발한 오픈소스 RISC(Reduced Instruction Set Computer) 명령어 세트 아키텍처입니다. RISC-V 아키텍처를 통해 설계자는 최종 애플리케이션에 맞게 프로세서를 맞춤화하고 설계할 수 있습니다.\r\r\n\r\r\n즉 현재는 기존에 사용하는 프로그램이나 하드웨어에 대해 영구적인 접근 권한을 갖고 통제하고 원하는 대로 사용하고 싶어 하는 산업 전반의 트렌드가 있다고 합니다. 이 같은 트렌드로 오픈 소스 및 오픈 테크놀로지는 그 어느 때보다 중요해졌다고 합니다.\r\r\n\r\r\n### License Changes\r\r\n\r\r\n\r\r\n* Terraform\r\r\n예상치 못한 라이선스 변경으로 시장에 악영향을 미쳤지만, 오픈소스가 이에 대한 해결책을 제시해 줄 수 있습니다. Terraform의 라이선스 변경으로 인해 오픈 소스 프로젝트인 Open Tofu가 등장하여 테라폼을 대체하는 역할을 수행해 사용자들에게 신뢰를 제공하고 있습니다.\r\r\n\r\r\n* VMware\r\r\nVMware의 라이선스가 변경됨에 따라 많은 사용자들이 VMware에서 OpenStack으로 마이그레이션에 대한 관심이 커지고 있습니다. 대표적으로 미국의 주요 자동차 보험사인 GEICO가 최근 VMware를 버리고 오픈스택으로 대규모 클라우드 인프라를 구축해 큰 주목을 받았다고 합니다. Mark Collier는 마이그레이션에 관한 백서를 행사 당일에 [QR](https://www.openstack.org/vmware-migration-to-openstack-white-paper)로 공개하기도 했습니다.\r\r\n\r\r\n### Security Concerns\r\r\n\r\r\n\r\r\n최근 운영 중인 컨테이너 이미지의 87%에 치명적이거나 심각도가 높은 취약점이 있다는 사실이 밝혀져 우려를 자아내고 있습니다. 이 문제를 해결하기 위한 방안으로 오픈 인프라 재단에서 주최하는 카타 컨테이너(Kata Container) 프로젝트가 큰 주목을 받고 있습니다. 카타 컨테이너는 컨테이너의 속도와 가상 머신의 보안을 결합한 경량 가상화를 제공함으로써 속도와 보안 사이의 균형을 제공합니다. 컨테이너 환경 보안에 효과적이라는 점에서 Microsoft Azure, NVIDIA, AWS 등 주요 기업들이 카타 컨테이너에 투자하고 지원하고 있습니다.\r\r\n\r\r\n### AI Redefining Infra\r\r\n\r\r\n\r\r\nAI에 대한 기업들의 관심이 이례적입니다. 너도 나도 할 것 없이 기업들은 GPU를 최대한 많이 확보해 방대한 규모로 자신의 데이터 센터에 구축하고 있습니다. 기업이 AI 용량 구축에 거대한 투자하고 있으며, 오픈스택이 AI 워크 로드를 지원하는 데 중요한 역할을 하고 있습니다.\r\r\n\r\r\n이렇게 디지털 주권, 라이선스 변경, 보안 문제, 인공지능과 같이 네 가지 주요 트렌드로 오픈 소스에 대한 관심과 투자가 그 어느 때보다도 활발하게 일어나고 있고 오픈 소스 커뮤니티의 성장을 이끌고 있다고 합니다.\r\r\n\r\r\n## Sessions\r\r\n\r\r\n오픈인프라 아시아 서밋 2024에는 다양한 주제에 대해 심도 있는 내용을 다루는 세션이 많았는데요. 저는 그중 NHN Cloud 인프라서비스개발랩 박성우 이사님이 발표하신 세션 **Openstack of NHN Cloud from a network perspective**을 통해 오픈스택의 실제 적용 사례와 오픈스택의 한계점을 어떻게 보완했는지를 배울 수 있었습니다. 아래는 세션 내용의 일부를 요약해 보았습니다.\r\r\n\r\r\n### 1. Openstack of NHN Cloud from a network perspective\r\r\n\r\r\n![4.jpg](https://image.toast.com/aaaadh/real/2024/techblog/4%281%29.jpg)\r\r\n\r\r\n>  [영상 보러 가기](https://www.youtube.com/watch?v=IgXJq8jmuJI&t=1s)\r\r\n\r\r\nNHN Cloud는 2015년에 OpenStack의 Neutron 모듈을 활용해 네트워크를 구축하고 서비스를 시작했습니다. 하지만 서비스 초기 단계에서는 Neutron 모듈의 기본 기능만으로는 NHN Cloud의 서비스들을 효율적이고 안정적으로 운영하는 데 한계가 있었다고 합니다. 이중화가 불가능하고 장애 조치 및 스케일업 기능이 지원되지 않았기 때문입니다. 이번 세션에서는 NHN Cloud가 이러한 문제를 어떻게 해결했는지에 대해 자세히 다뤘습니다.\r\r\n\r\r\nNeutron의 기본 구조는 컴퓨트 노드 안에 큐라우터와 OVS integration bridge, 그리고 그 사이에 위치한 리눅스 브릿지로 구성됩니다. 여기에 IP 테이블을 연결하여 보안 규칙(Security Rules)을 설정하게 됩니다. 하지만 이 구조는 보안 규칙이 많아질수록 코드 오류의 원인을 파악하고 문제를 분석하는 데 어려움을 겪게 되며 유지 보수에 큰 부담이 따랐다고 합니다. 더구나 리눅스 브릿지는 OSI 모델의 2계층에서만 동작하기 때문에, 라우팅이나 IP 주소를 기반으로 트래픽을 처리하는 데도 한계가 있었습니다.\r\r\n\r\r\n![5.png](https://image.toast.com/aaaadh/real/2024/techblog/5.png)\r\r\n\r\r\n이러한 문제를 해결하기 위해 NHN Cloud는 컴퓨트 노드에서 리눅스 브릿지와 큐라우터를 제거하고, OVS integration bridge로 대체하는 방식을 채택했습니다. 네트워크를 VxLAN마다 나누고 각 브릿지와 연결하는 방식으로 구성하여 더 효율적인 네트워크 구조를 구현했습니다. 또한, NVIDIA의 SR-IOV Representer를 OVS bridge와 연결해 I/O 성능을 대폭 개선한 점이 인상 깊었습니다.\r\r\n\r\r\n> SR-IOV는 하나의 물리적 PCI Express 장치를 여러 가상 머신이 동시에 사용할 수 있게 해주는 기술로, 가상화 환경에서 매우 유용한 기술입니다.\r\r\n\r\r\n앞서 컴퓨트 노드에서 큐라우터를 제거했다고 했는데요. 이는 큐라우터의 한계를 극복하기 위한 조치로 랙 상단으로 이동시켰습니다. 즉, 각 랙이 하이퍼바이저처럼 작동하게 되어 컴퓨트 노드의 구조가 단순화되고, 최대 효율을 추구할 수 있었습니다.\r\r\n\r\r\n하지만 이러한 구조에서는 모든 트래픽이 랙 상단의 라우터로 집중되는 문제가 발생했습니다. 이를 해결하기 위해 NHN Cloud는 vSwitch를 개발했으며, 이 vSwitch는 5mpps(초당 500만 패킷)의 뛰어난 처리 속도를 자랑합니다.\r\r\n\r\r\n또한, VLAN에서 VxLAN으로 전환한 이유도 흥미로웠는데, 이는 고객 수가 증가함에 따라 퍼블릭 환경에서 여러 VPC(Virtual Private Cloud)를 생성해야 했기 때문입니다.\r\r\n\r\r\n### 보안과 안정성\r\r\n\r\r\n\r\r\n보안과 안정성 측면에서도 다양한 개선이 이루어졌습니다. 기본적으로 Neutron이 제공하는 Security Groups와 함께 Network ACL을 구성하여, 서버가 클라이언트 상태 정보를 저장하지 않아도 통신할 수 있는 환경을 구축했습니다. 또한, Internet Gateway 없이도 원격 호스트와 통신할 수 있도록 VPN Gateway를 연결해 네트워크 통신의 유연성을 강화했습니다.\r\r\n\r\r\n![6.png](https://image.toast.com/aaaadh/real/2024/techblog/6.png)\r\r\n\r\r\nNHN Cloud는 2015년 서비스 시작 이후, OpenStack Neutron에 다양한 기능을 추가하기 위해 여러 플러그인과 자체 개발한 에이전트들을 도입해왔는데요. 세션을 통해 NHN Cloud가 기존의 네트워크 문제를 혁신적으로 해결하고, 서비스 안정성과 보안을 동시에 강화한 점을 직접 확인할 수 있었습니다. 동시에 클라우드 네트워크 관리의 복잡성을 체감할 수 있었습니다.\r\r\n\r\r\n\r\r\n\r\r\n### 2. Bridging the Gap Between Community and Contributing Orgs\r\r\n\r\r\n![7.jpg](https://image.toast.com/aaaadh/real/2024/techblog/7.jpg)\r\r\n\r\r\n강의 형태로 진행되는 세션이 아닌 참석자들과 함께 자유롭게 토의하는 포럼 형태의 세션도 제공되었습니다. 그중 하나인 **Bridging the Gap Between Community and Contributing Orgs**은 오픈 소스 커뮤니티를 더욱 활성화하기 위해 자유롭게 의견을 공유하는 자리였습니다. 주요 논의는 신규 기여자와 기존 기여자가 모두를 위한 커뮤니케이션을 활성화하고 기여자 경험을 개선하기 위한 방안을 논의하는 세션이었습니다.\r\r\n\r\r\n다양한 국가의 수많은 사람들이 오픈인프라 프로젝트에 기여하고 있는 만큼 커뮤니케이션의 한계를 극복하고 다양성을 높이고자하는 열정이 느껴지는 세션이었습니다.\r\r\n\r\r\n## OpenStack’s Role in the Future\r\r\n\r\r\n\r\r\n오픈인프라 서밋 아시아 2024는 클라우드 산업의 혁신을 선도하는 오픈소스 커뮤니티의 중요성을 다시 한 번 강조한 행사였습니다.\r\r\n\r\r\n특히 VMware에서 오픈스택으로의 마이그레이션이 주목을 받으면서 확장 가능하고, 안전하며, 비용 효율적인 솔루션으로 오픈스택을 도입하려는 기업들이 전 세계적으로 많다는 것을 느낄 수 있었습니다.\r\r\n\r\r\n또한, AI와 같은 고성능 컴퓨팅을 위한 지속 가능한 인프라에 대한 요구가 커지고 있는 상황에서, 오픈인프라 커뮤니티는 혁신적이고 획기적인 솔루션으로 이러한 글로벌 과제에 대응할 준비가 충분히 갖추어져 있음을 확인할 수 있었습니다. 이번 서밋을 통해 오픈소스 기반 인프라의 미래와 지속 가능한 기술 개발에 대한 기대감이 더욱 커졌습니다.",
        "isoDate": "2024-11-11T02:16:45.000Z"
      }
    ]
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "전문지식과 경험",
        "link": "https://www.thestartupbible.com/2024/11/domain-expertise-and-experience.html",
        "pubDate": "Wed, 13 Nov 2024 21:43:00 +0000",
        "content:encodedSnippet": "흔히 성공적인 VC 투자를 하기 위해서는 투자자가 ‘pattern recognition’에 능해야 한다고 한다. 그동안의 투자 경험을 기반으로 어떤 창업가와 어떤 사업이 잘됐는지, 반대로 어떤 창업가와 어떤 사업이 잘 안됐는지, 이 모든 과거의 경험에서 패턴을 찾을 수 있다면, 이 패턴을 잘 분석해서 미래의 투자의 성공 확률을 높일 수 있다는 의미다. 아마도 어느 정도 투자를 한 VC라면, 대부분 자신만의 이런 패턴 분석 능력이 있을 것이고, 새로운 창업가와 사업을 볼 때 지속적으로 본인만의 패턴 DB를 참고해서 크고 작은 결정을 할 것이다.\n나도 투자를 시작했을 때, 유명한 VC나 내가 잘 아는 선배 VC들이 이런 패턴을 잘 찾아야 한다고 이야기하면, 그 말에 많이 동의했고, 이후 몇 년 동안 나도 투자하면서 경험한 실패와 성공을 바탕으로 성공 확률이 높은 창업가에 대한 패턴을 매핑하기 시작했다. 그런데 요샌 이 pattern recognition이 쓸모없다고 생각하고 있다. 지나고 나서 보면 “성공하는 창업가들은 모두 다 이런 패턴이 있었죠.”라고 끼워서 맞추는 이야기는 할 수 있지만, 이런 과거의 패턴을 기반으로 미래의 성공을 예측하는 건 과학적으로 접근해도 힘들다는 게 내 생각이다. 우린 수학적으로는 절대로 예측할 수 없는, 즉, 특정한 패턴을 따르지 않는, 그리고 잠재 능력의 한계가 존재하지 않는 사람(=창업가)에게 투자하기 때문에 그 어떤 과거의 패턴도 여기에 적용할 수 없기 때문이다.\n이런 패턴 중 대표적인 게 바로 창업가의 전문 지식과 직장 경험이다.\n예를 들면, 대부분의 VC는 어려운 AI 사업을 하는 창업가라면 이분이 컴퓨터공학이나 다른 공학 분야의 석사나 박사 학위가 있으면 남들보다 더 뛰어날 것이라는 생각을 할 것이다. 국내 대학에서 경영학과 학부를 졸업한 창업가와 미국 top 대학에서 컴퓨터 공학 박사 학위를 받은 창업가가 둘 다 AI 관련 스타트업을 하면, 대부분의 VC는 후자의 창업가에게 투자할 확률이 더 높다. 이게 일반적인 VC들의 패턴 인식 프로세스이다.\n모빌리티 분야에서 창업한 두 스타트업이 있는데, 한 회사는 현대자동차에서 오랫동안 관련 사업을 했던 분이 창업했고, 다른 스타트업은 완전히 상관없는 직장에서 일했던 분이 창업하면, 역시나 현대자동차 출신 창업가에 더 높은 점수를 줄 것이다.\n\n\n\n\n나는 그동안 정말 여러 창업가와 회사를 만나면서, 창업가의 학력과 학벌, 그리고 과거 직장 경험은 이 분이 새로 하려고 하는 사업의 성공 여부와는 정말 아무 상관이 없다는 패턴을 발견했다. 오히려 특정 분야에 대한 학문적인 백그라운드(=학력, 학벌)나 그 분야에서의 직장 경험이 없는 창업가들이 훨씬 더 신선한 시각으로 사업을 바라보고, 그 분야에 존재하는 문제점들을 완전히 새로운 방식으로 접근하는 걸 자주 봤다. 이들은 특정 분야에 대해 너무 많은 공부를 하거나, 너무 많은 경험이 있는 분들의 고정관념에서 벗어날 수 있기 때문에, 그동안 그 누구도 생각 못 했던 파괴적이고 참신한 문제 해결 방법을 시도할 수 있다. 물론, 잘 모르기 때문에 대부분의 방법은 실패하지만, 계속 시도하다 보면 엄청난 솔루션을 찾는 경우도 있고, 이러면 정말 큰 사업을 만들 수 있다.\n내가 자주 언급하는 건데, 특정 분야의 전문 지식과 경험이 너무 많으면, “원래 그건 안 돼.” , “내가 오래전부터 해봤는데, 그건 안 되는 거야.” 등의 편견이 마음속에 자리 잡고 있지만, 완전히 백지에서 문제를 해결하려고 하는 창업가들은 “방법이 없을까?” , “가능할 것 같아. 방법을 찾아보자.” , “원래 안 되는 건 없어. 왜 꼭 저렇게 해야 할까?” 등의 생각으로 뭐든지 새로운 시도를 하기 때문에 위에서 말한 일반적인 패턴 인식 레이다에 잘 안 걸린다.\n토스의 이승건 대표는 치과대학을 졸업했고, 실제로 의사 생활까지 좀 했다. 금융업을 학교에서 공부한 적도 없고, 관련 업계에서 일 한 경험도 없다. 하지만, 이 분과의 대화에 대한 내 개인적인 기억, 그리고 이승건 대표를 잘 아는 다른 분들의 기억에 의하면, 토스를 창업했을 때 대한민국 그 어떤 금융 전문가보다 이 시장의 생리와 문제점을 잘 파악하고 있었고, 아주 새로운 방식으로 금융산업의 문제점들을 해결하는 시도를 했다.\n얼마집이라는 모바일앱을 만드는 우리 투자사 한국프롭테크의 송지연 대표도 비슷하다. 이분은 원래 부동산이나 재건축/재개발과는 완전히 상관없는 분야에서 일했고, 학교에서 경제학을 공부했다. 그런데 부모님의 아파트가 재건축을 추진하는 과정에서 여러 가지 문제점을 경험했고, 시장의 현실과 앞으로 시장이 가야 할 미래 사이에 너무나 큰 간극이 존재한다는 걸 발견하고 이걸 직접 해결해 보기로 결심해서 창업했다. 그런데 우리가 봤을 땐, 이 시장에서 수십 년 동안 일한 직장인들이나 도시개발이나 부동산학과 교수들보다 훨씬 더 이 시장의 문제에 대해서 잘 이해하고 있고, 이걸 기술로 어떻게 해결할 수 있는지 매우 구체적인 (아직 증명되지 않은)해답을 갖고 있다.\n과연 특정 분야의 학업적 지식과 경험이 그렇게 중요한가? 내가 봤을 땐 별로 안 중요하다. 학업적 지식과 경험보다 더 중요한 건 그 시장의 현실에 대한 정확한 이해와 전문성인데, 이건 인터넷 검색과 발품을 팔면 누구나 다 획득 가능하다. 하지만 더 중요한 건, 문제를 해결하겠다는 의지다. 얼마나 집요하게 이 문제를 붙잡고, 얼마나 깊게 파고 들어갈 준비가 되어 있는지, 그리고 얼마나 절박하게 내가 이 싸움에서 이기고 싶은가의 문제이다. 결국, 결승전에서 이기는 건 가장 실력이 좋은 선수가 아니라 가장 간절하게 승리하고 싶어 하는 선수이기 때문이다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/11/domain-expertise-and-experience.html#respond",
        "content": "흔히 성공적인 VC 투자를 하기 위해서는 투자자가 ‘pattern recognition’에 능해야 한다고 한다. 그동안의 투자 경험을 기반으로 어떤 창업가와 어떤 사업이 잘됐는지, 반대로 어떤 창업가와 어떤 사업이 잘 안됐는지, 이 모든 과거의 경험에서 패턴을 찾을 수 있다면, 이 패턴을 잘 분석해서 미래의 투자의 성공 확률을 높일 수 있다는 의미다. 아마도 어느 정도 투자를 한 VC라면, 대부분(...)",
        "contentSnippet": "흔히 성공적인 VC 투자를 하기 위해서는 투자자가 ‘pattern recognition’에 능해야 한다고 한다. 그동안의 투자 경험을 기반으로 어떤 창업가와 어떤 사업이 잘됐는지, 반대로 어떤 창업가와 어떤 사업이 잘 안됐는지, 이 모든 과거의 경험에서 패턴을 찾을 수 있다면, 이 패턴을 잘 분석해서 미래의 투자의 성공 확률을 높일 수 있다는 의미다. 아마도 어느 정도 투자를 한 VC라면, 대부분(...)",
        "guid": "https://www.thestartupbible.com/?p=9266",
        "categories": [
          "Uncategorized",
          "failure",
          "FoundersAtWork",
          "inspiring",
          "mobile",
          "Strong",
          "technology",
          "vc"
        ],
        "isoDate": "2024-11-13T21:43:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "해자(垓字)는 없다",
        "link": "https://www.thestartupbible.com/2024/11/no-such-thing-as-a-moat-in-consumer-brands.html",
        "pubDate": "Sun, 10 Nov 2024 21:34:00 +0000",
        "content:encodedSnippet": "요새 VC들이 소비재 쪽의 사업은 상당히 보수적으로 검토하거나 아예 투자하지 않는 것 같은데, 우린 이런 분위기와는 상관없이 계속 이 분야에서 재미있는 일을 하고 있는 창업가들을 만나고, 투자하고 있다. 최근에도 생필품, 의류, 그리고 음식 분야에서 사업하고 있는 여러 창업가를 만났다. 자체 브랜드를 만들어서 직접 고객에게 자사몰, 그리고 다른 온라인 플랫폼이나 오프라인 유통 채널을 통해서 판매하고 있는데, 대부분 내가 이 글에서 말했던 그런 어려움을 사업의 단계와는 상관없이 직접 경험하고 있는 것 같았다.\n이분들과 이야기를 하면, 항상 등장하는 주재가 ‘해자(垓字)’이다. 사업의 종류에 상관없이 VC들이 창업가들에게 물어보는 게 그 사업만의 차별점, 진입장벽, 보호 장벽, 해자 관련 질문인데, “지금까지 비슷한 사업을 여러 번 검토했는데, 모두 다 비슷한 방식으로 비슷한 비즈니스 모델로 같은 시장에서 경쟁하는 것 같네요. 우리가 다른 경쟁사보다 더 잘할 수 있는, 우리만의 해자가 있나요?” , “이 사업이 잘되면 분명히 대기업도 같은 사업을 할 텐데요, 그 상황에서 우리가 이길 수 있는 우리만의 해자가 있을까요?”와 같은 유의 질문이다. 솔직히 이 질문에 대한 정답은 없다. 만약, 이 질문에 대한 답변이 투자에 결정적인 영향을 미친다면, 이런 질문을 한 VC는 결국엔 이 사업에 투자하지 않겠다는 의미다. 비슷한 분야에서 경쟁하는 회사들이 투자자를 설득할 만한 명확하고 논리적인 해자를 갖추긴 어렵고 – 특히, 이제 막 시작하는 초기 스타트업은 – 대기업이 이 분야에 진출했을 때 다윗 같은 스타트업이 골리앗 같은 대기업을 이길만한 해자는 없기 때문이다. 아니, 이론적으로 명확하고 논리적인 상상 속의 해자가 있더라도, 아마도 투자자는 이 말을 믿지 않을 것이다.\n특히나, 기술력이 뒷받침되는 소프트웨어 회사가 아니라, 공장에서 뭔가를 만들어서 판매하는 브랜드나 D2C 회사들은 이런 해자를 만드는 건 거의 불가능하다. 우리도 이 분야에서 사업하는 한국과 미국 회사에 꽤 많이 투자하면서 이 힘든 현실을 간접적으로 경험했고, 나는 몇 년 전부터 이런 현실을 인정하기 시작했다. 그리고, 이제 브랜드를 만드는 사업 분야에서 해자라는 건 존재하지 않는다는 걸 잘 받아들이고 있고, 아예 이 분야에서 사업하는 창업가들에겐 본인이 하는 사업의 해자는 무엇인지라는 질문을 하지 않는다.\n최근에 우리가 투자한 이런 D2C/브랜드 사업들을 보자: 제주 귤을 원료로 주스와 같은 다양한 시트러스 제품을 만드는 귤메달; 파워레이드나 게토레이드랑 같은 카테고리에 속한 기능성 스포츠 드링크 얼티밋포텐셜을 만드는 어센트스포츠; 그리고 반려동물을 위한 영양제 페노비스를 만드는 노즈워크. 모두 다 잘하고 있는 스타트업이지만, 다른 스타트업도 충분히 이 분야로 들어올 수 있고, 돈/시간/인력이 압도적으로 많은 대기업도 진출할 수 있는 매력적이고 규모가 나오는 시장이다. 이런 무시무시한 회사들이 우리 투자사들과 경쟁하기 시작하면 우리 창업가들은 어떤 해자를 만들면서 이길 수 있을까?\n정답은, 이들이 구축할 수 있는 해자는 없다. 이 치열한 분야에서 이기기 위해선 수단과 방법을 가리지 말고 모든 합법적인 방법을 동원해야 하고, 되도록 많은 소비자들의 눈에 노출되고, 그냥 무조건 많이 팔아서 매출 잘 만들어야 한다. 어떻게 많이 팔고, 어떻게 매출을 많이 만들 수 있을까? 이 또한 정답도 없고, 이를 위한 해자라는 것도 없다. 그냥 좋은 제품 만들고, 최대한 많은 채널을 통해서 유통하고, 동시에 마케팅도 잘 해야 한다. 나중에, 아주 나중에, 혹시나 자체 공장을 만들거나 우리 제품을 OEM 제조하는 공장을 인수해서 생산의 전 과정을 수직통합 할 수 있다면, 어쩌면 이건 품질관리, 공정관리, 수량 조정, 가격 조정 면에서 우리에게 해자가 될 수도 있다. 그런데 자체 공장에 대해서 고민하는 단계까지 왔다면, 이미 우린 시장에서 알아주고 인정해 주는 브랜드가 됐을 것이고, 여기에서 말한 대로, 특정 분야에서 가장 먼저 떠오르는 브랜드가 됐다면, 이 자체가 엄청난 해자가 될 수 있다.\n하지만, 누구나 다 아는 그 강력한 브랜드가 되기 전까지는, 해자라는 건 존재하지 않으니, 자꾸 우리만의 차별점이나 해자를 만들기 위해서 고민하지 말고, 그 시간에 그냥 물건 하나라도 더 팔아라. 대신, 남들보다 더 빠르게 움직이고, 너무 깊이 생각하기보단 get things done 전략으로 실행에 집중해라.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/11/no-such-thing-as-a-moat-in-consumer-brands.html#comments",
        "content": "요새 VC들이 소비재 쪽의 사업은 상당히 보수적으로 검토하거나 아예 투자하지 않는 것 같은데, 우린 이런 분위기와는 상관없이 계속 이 분야에서 재미있는 일을 하고 있는 창업가들을 만나고, 투자하고 있다. 최근에도 생필품, 의류, 그리고 음식 분야에서 사업하고 있는 여러 창업가를 만났다. 자체 브랜드를 만들어서 직접 고객에게 자사몰, 그리고 다른 온라인 플랫폼이나 오프라인 유통 채널을 통해서 판매하고 있는데,(...)",
        "contentSnippet": "요새 VC들이 소비재 쪽의 사업은 상당히 보수적으로 검토하거나 아예 투자하지 않는 것 같은데, 우린 이런 분위기와는 상관없이 계속 이 분야에서 재미있는 일을 하고 있는 창업가들을 만나고, 투자하고 있다. 최근에도 생필품, 의류, 그리고 음식 분야에서 사업하고 있는 여러 창업가를 만났다. 자체 브랜드를 만들어서 직접 고객에게 자사몰, 그리고 다른 온라인 플랫폼이나 오프라인 유통 채널을 통해서 판매하고 있는데,(...)",
        "guid": "https://www.thestartupbible.com/?p=9262",
        "categories": [
          "Uncategorized",
          "B2C",
          "brand",
          "consumer",
          "FoundersAtWork",
          "marketing",
          "strategy",
          "Strong",
          "vc"
        ],
        "isoDate": "2024-11-10T21:34:00.000Z"
      }
    ]
  },
  {
    "name": "Build a Great Product",
    "category": "개인",
    "posts": []
  },
  {
    "name": "지금 써보러 갑니다",
    "category": "개인",
    "posts": []
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "로제와 브루노 마스의 ⟨APT.⟩는 얼마를 벌었을까?",
        "link": "https://blog.toss.im/article/fandustry-03",
        "pubDate": "Tue, 12 Nov 2024 00:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}아파트 아파트… 아파트 아파트…. 이 단어가 머리에서 나가질 않는다. 로제와 브루노 마스의 목소리도 너무 좋다. 친구들과 아파트 게임을 하며 술 마실 나이는 아니지만, 누가 아파트 아파트~ 라고 술 게임을 하자고 하면 당장 그다음 구절을 이어 부를 자신은 있다. 물론 아무도 그걸 원하진 않겠지만.\n2024년 10월 18일에 발매된 로제 & 브루노 마스의 ⟨APT.⟩가 계속 화제다. 여러모로 상징적인 순간을 보여주는 곡인데, 음악적 평가만큼 차트 기록도 매우 높다. 음악적 평가는 조금 뒤로 미루고 일단 차트 기록만 살펴보자.\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}11월 3일 기준, ⟨APT.⟩는 아이튠즈, 스포티파이, 유튜브 글로벌 차트 1위를 차지하고 있다. 스포티파이의 누적 스트리밍은 1억 8,336만 9,499회, 유튜브에서는 2억 5,327만 1,907회다. 서비스별로 가장 많은 1위를 기록한 국가를 보면 인도네시아(아이튠즈 1위, 스포티파이 1위, 애플뮤직 1위, 유튜브 1위, 샤잠* 1위), 필리핀(아이튠즈 1위, 스포티파이 1위, 애플뮤직 1위, 유튜브 1위, 샤잠 1위), 호주(아이튠즈 1위, 스포티파이 1위, 유튜브 1위, 샤잠 1위), 대만(아이튠즈 1위, 스포티파이 1위, 애플뮤직 1위, 유튜브 1위), 일본(스포티파이 1위, 애플뮤직 1위, 샤잠 1위), 캐나다(스포티파이 1위, 유튜브 1위), 태국(애플뮤직 1위, 디저** 1위), 베트남(애플뮤직 1위, 유튜브 1위) 등이다. 한국은 애플뮤직과 샤잠에서 1위를 차지했다.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*노래를 들려주면 음원을 검색해 주는 플랫폼으로 2018년 애플이 인수했다. 2022년 월간 활성 사용자 수가 2억 2,500만 명이라고 발표했다.\n**Deezer. 프랑스 온라인 음악 스트리밍 서비스.\n이 정도의 결과라면 수익도 궁금하다. 음원 스트리밍에서의 수입은 여러 저작권이 더해진 총매출로, 국가별로 항목이 조금씩 다르다. 미국을 기준으로 보자면 크게 Sound Recording, Mechanical, Performance 항목을 기준으로 수익을 나누는데, 미국은 한국과 달리 업체별로 다른 기준을 적용하기 때문에 실제 수익은 당사자들만 안다. 물론 추정은 가능하다.\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\nSound Recording | 저작권 소유자에게 지급되는 금액. 대부분의 경우 음반사를  말하지만 포괄적으로 독립 아티스트, 프로듀서, 투자자도 포함된다.\nMechanical | 저작물을 디지털 및 물리적 형식으로 복제해 얻는 수익으로, 퍼블리셔에게 기계적으로 지급되는 로열티. 쉽게 말해 작사/작곡가가 버는 돈이다.\nPerformance | 음악 작품이 공식적으로 연주되거나 방송될 때마다 받는 로열티. ASCAP(미국 음악 저작권협회), BMI(방송음악협회), GMR(Global Music Rights) 및 SESAC 같은 공연 권리 단체들이 포함된다.\n\n미국의 음악 산업 전문 법무/컨설팅 회사인 매나트, 펠프스 앤 필립스(Manatt, Phelps & Phillips)는 음원 로열티를 지급하는 다수의 기업을 조사한 데이터를 기반으로 ‘.css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}음악 스트리밍 로열티 계산기’를 만들었다. 복잡한 수식은 뒤로 숨기고, 스포티파이나 애플뮤직의 재생수를 입력하면 총매출의 추정치가 나오는 계산기다. 추정치일 뿐이지만 대략 얼마 정도의 매출을 거뒀는지 짐작할 수는 있다.\n이제 ⟨APT.⟩의 숫자를 입력할 차례다. 이 노래는 전 세계 기준으로 단 2주 만에 스포티파이에서 1억 8,336만 9,499회 재생됐다. 사실 이 계산기는 미국 내 스트리밍 로열티만 계산하기 때문에 전 세계 누적 스트리밍 횟수를 그대로 넣으면 안 되지만(미국 내 스트리밍 횟수와 국가별 환율도 고려해야 하므로) 우리의 목적은 추정치를 확인하는 것이므로, 그냥 무식하게 이대로 넣어보자.\n결괏값은 두 개다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}.css-wgpbp3{display:block;margin-top:6px;}로제와 브루노 마스의 ⟨APT.⟩를 음악 스트리밍 로열티 계산기에 넣어본 결괏값 \n스포티파이는 87만 7,932달러(약 12억 1,198만 원)를, 애플뮤직은 155만 7,129달러(약 21억 4,961만 원)를 로열티로 제공한 것으로 추정된다. 음원이 발매된 지 단 2주 만에 33억 원의 매출을 낸 것이다. 물론 로제와 브루노 마스가 이 돈을 다 가져가는 건 아니다. 이들은 여기서 작곡, 작사, 편곡, 가창의 몫을 가져갈 것이다. 글로벌에서 성공한 히트곡이란 대략 이 정도의 매출을 만드는군, 이라는 참고 자료다. 그런데 모두가 스트리밍으로 이렇게 돈을 벌 수 있을까? 이건 정말 예외적인 경우가 아닐까?\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}스트리밍이 정말 돈이 될까?\n스트리밍 시장은 계속 성장하고 있다. 2023년 기준 전 세계 음악 스트리밍 시장 규모는 364억 9,000만 달러로 추정된다. 50조 569억 8,200만 원 정도의 규모다. 2023년부터 2031년까지의 음악 스트리밍 시장의 연평균 성장률(CAGR)은 8.7%를 기록할 것으로 전망되고, 규모도 거의 두 배에 달하는 713억 2,000만 달러에 이를 것으로 예상된다. 스트리밍 이전 시대와 비교하면 사실상 그 규모*를 넘어선 수치다.\n*세계 음악시장 매출은 .css-114ityv{white-space:pre-wrap;cursor:pointer;-webkit-text-decoration:underline!important;text-decoration:underline!important;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}1999년 278억 달러를 기록한 뒤, 2011년까지 12년 연속 감소했다.\n지금이야말로 음악을 사랑하는 사람들이 늘 꿈꾸던 ‘음악으로 충만한 세상’이다. 하지만 그 결과는 우리의 상상과는 완전히 다르다. 스포티파이에 등록된 음악은 1억 곡이 넘지만, 한 번도 재생되지 않은 곡도 수백만 곡에 이른다. 에드 시런과 테일러 스위프트는 2022년까지 스포티파이에서 약 7~8천만 달러를 정산받았지만, 어떤 싱어송라이터는 1년에 100달러 미만을 정산받는다.\n시장이 성장하면서 잠재적 기회는 많아졌지만, 대부분의 수익은 상위 10% 미만의 메이저에게 돌아간다. 소위 ‘메이저’라고 불리는 이들도 모두가 큰돈을 버는 건 아니다. 더 많은 재생 수를 위해서는 더 큰 비용을 써야 하고, 그마저도 지속 가능하고 안정적인 수익을 약속해 주지 않기 때문이다.\n만약 ⟨APT.⟩가 1980년대처럼 5,000원짜리 싱글 음반으로 판매됐다면 12억 1,198만 5,126원의 매출을 위해 1억 8,336만 9,499회의 스트리밍 대신 24만 장의 CD를 파는 것으로 충분했을 것이다. 이처럼 실물 음반에 비하면 스트리밍의 수익성은 낮다. 그렇다면 이런 환경에서 ‘디지털 콘텐츠’ 형태의 음악은 어떤 역할을 하고 있을까?\n유명하지만 돈을 못 버는, 콘텐츠의 역설\n20세기에는 ‘콘텐츠’란 말 자체가 없었다. 콘텐츠의 사전적 의미는 ‘네트워크로 유통되는 멀티미디어 파일’이니까. 전자 네트워크가 생기고 콘텐츠란 말이 태어나기 전의 음악 사업은 음반을 판매하는 것이 거의 유일한 수익 모델이었다. 음악은 음반으로 듣고, 영화는 DVD로 보고, 게임은 게임 타이틀로 하고, 책은 책을 읽어야 했던 것처럼 다른 걸 고려할 수 없었기 때문이다.\n다시 말해 20세기의 음악 산업은 제조업이었다. 음반을 만들고 판매해서 돈을 벌었다. TV에 출연하거나 뮤직비디오를 만들거나 심지어 콘서트를 여는 것도 피지컬(physical) 음반을 판매하기 위한 홍보 활동이었다. (이는 영화, 게임, 출판도 마찬가지였다.)\n그런데 21세기에 디지털 전환이 일어나면서 물리적인 제품에서 멀티미디어가 분리되어 통신망으로 유통되기 시작했고, 음악과 게임의 비즈니스 모델이 무너지기 시작했다. (영화와 출판은 이제야 비슷한 문제를 겪는 중이다). 유선 인터넷, 무선 인터넷, LTE와 5G까지 네트워크 기술이 발전하는 동안 음악과 게임은 다운로드, 스트리밍, 구독 모델을 만들며 새로운 환경에 대응해 왔고, 게임 산업은 ‘인앱 결제’라는 방식으로 비즈니스 모델 문제를 해결하기도 했다.\n그런데 이건 유통 및 공급자의 입장이다. 실제로 음악이나 게임을 만드는 저작권자들은 늘어난 경쟁과 줄어든 수익성의 틈에서 버티기 어려워지고 있다. 음악(콘텐츠)의 초과 공급 아래 콘텐츠 판매 수익은 0에 수렴하기 때문이다. 스포티파이에 하루 동안 업로드되는 신곡의 수, 유튜브에 1분 동안 업로드되는 콘텐츠의 개수, 1년에 발간되는 책의 권수, 킨들에서 발행되는 전자책의 양, 넷플릭스에 업로드되는 비디오 개수… 이 모든 숫자들은 커지고 있지만, 저작권자에게 돌아가는 수익은 적어지고 있다는 점에서 그야말로 풍요 속의 빈곤이다.\n앞서 언급한 ⟨APT.⟩의 사례처럼 ‘유명해지면 되는 것 아닌가?’라고 생각할 수 있다. 하지만 일단 넘치는 콘텐츠 시대에서 유명해지기 위해서는 (매우 운이 좋지 않은 이상) 돈이 많이 들 수밖에 없다. 수많은 콘텐츠 중에서 사람들의 높은 관심을 끌어야 하기 때문이다. 앞서 우리는 스포티파이를 통해 발생한 매출이 12억 원 정도일 것으로 추정했다.\n그런데 제작비는 얼마였을까? 2020년에 니키 미나즈의 피처링 가격이 곡당 6억 원 정도였다는 자료를 참고해, 2024년 브루노 마스의 피처링 비용은 적어도 10억 원이 들었을 것으로 예상해 보자. 그 외 작곡, 편곡, 레코딩, 뮤직비디오 제작비와 마케팅 비용 등을 감안한다면 ⟨APT.⟩ 한 곡의 제작비는 최소 15억 원으로 추정해 볼 수 있을 것이다.\n이렇게 돈을 써서 스트리밍 차트에서 1위를 했더라도, 유명세를 수익으로 전환하는 건 정말 어렵다. 음악이 좋다고 모두가 음반을 구매하거나 공연장에 가는 건 아니기 때문이다. 이런 상황에서 스트리밍만으로 손익분기점을 넘는 건 일반적으로 쉽지 않다. 음악 산업에서의 깔때기 구조*에 따르면, 추상적인 인기를 구체적인 사업으로 전환하는 건 매우 복잡하다. 이게 바로 ‘콘텐츠의 역설’, 유명한데 돈을 못 버는 상황이다.\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n💡 음악 산업에서의 깔때기 구조 \n\n소비자 행동 이론 중에 고객 퍼널 구조, 혹은 깔때기 구조라고 불리는 모델이 있다. 잠재적 소비자가 고객으로 변해 가는 과정을 분석하는 도구로, 음악에 빗대면 다음과 같다. \n\n음악에서 깔때기 구조는 스트리밍→음악→콘서트로 심화된다. 여기서 스트리밍은 관여도가 낮은 첫 단계다. 그 후 여러 요인들(듣기에 좋아서, 화제가 되어서, 추천곡으로 떠서 등) ‘좋아요’를 누르고 팔로우를 하면서 관여도가 높은(돈을 쓸 가능성이 높은) 고객으로 전환되고, 음반을 구매하거나 콘서트에도 올 수 있는 고객이 된다.\n\n그럼에도 스트리밍이 중요한 이유\n그렇다면 스트리밍 차트 1위는 수익과 관련해서는 아무런 쓸모도 없는 걸까? 아니, 그럼에도 차트 1위라는 화제는 여전히 필요하다. 스트리밍 차트 성적은 더 많은 기회를 만들기 때문이다. ⟨APT.⟩의 1위로 로제가 얻을 기회는 대략 다음과 같다.\n\n후속곡의 성공: ⟨APT.⟩는 로제가 올해 말에 발매할 솔로 1집의 선공개 싱글이었다. ⟨APT.⟩의 성공으로 이후 발표될 곡들에 대한 기대감이 높아졌고 수록곡들도 큰 인기를 얻을 수 있다.\n로제의 섭외비: 방송 출연료, 페스티벌 섭외비, 광고 출연료, 피처링 비용 등이 상승한다.\n로열티 정산 비율이 달라질 수 있다.\n\n이렇게 보면 스트리밍은 단순히 깔때기 구조의 하단에 위치하는 게 아닌, 기회비용을 높이는 전략이 된다. 이 과정에서 팬의 역할이 무엇보다 중요하다. 스트리밍은 팬을 만드는 도구이기도 하지만, 동시에 팬들이 스트리밍에 영향을 주기도 하기 때문이다.\n일반적으로 팬은 음악을 발표하고 활동을 지속하는 과정에서 만들어진다고 여겨졌다. 그러나 지금은 처음부터 팬이 필요하다. 1화에서 말했듯 팬은 소비자나 부가 가치가 아닌, 수익 그 자체를 만드는 존재이면서 산업을 지탱하는 기반이기 때문이다. 과거의 음악 산업이 팬을 아티스트 활동의 결과물로 여겼다면, 지금의 음악 산업은 팬을 처음부터 필요한 존재로 여긴다. 그렇기 때문에 데뷔와 함께, 혹은 데뷔 전에 이미 팬을 모을 수 있는 방법론을 고민한다. 신인 팀을 위한 오디션, 데뷔 전의 소셜 미디어 활동 등이 바로 그중 일부다.\n이렇게 처음부터 만들어진 팬은 (일반 소비자와 다르게) 아티스트와 밀도 높은 관계를 형성하고, 그로부터 지속 가능한 성장을 만든다. 미디어가 산산이 쪼개진 현재, 팬들은 자신의 취향과 맞는 콘텐츠를 찾아가며 그 과정에서 본인이 직접 브이로그 등의 콘텐츠를 제작해 아티스트를 알리는가 하면, 스트리밍 순위를 올리기 위한 집단행동을 하며 기업의 미디어 비용을 줄이는 역할도 맡는다.\n하지만 우리는 로제도, 브루노 마스도 아닌데 어떻게 팬을 만들 수 있을까? 여기에 정답은 없다. 당신이 뮤지션이라면 오디션 프로그램을 통해 팬을 만들 수도 있지만, 인스타그램 라이브나 소셜 미디어 활동 등을 통해 먼저 팬을 만들 수도 있다. 음악을 먼저 발표하는 게 아니라 여러 활동으로 팬을 구한 다음, 진짜 하고 싶은 것을 하는 시대가 온 것이다.\n음악에만 국한되는 얘기는 아니다. 영화도, 게임도, 글을 쓰는 저자도 마찬가지다. 지금 팬이 필요한 상황이라면, 팬이 모이고 성장하는 5단계를 참고해 보길 바란다. 아래는 내가 직접 만든 팬의 행동 변화 5단계로, 팬 비즈니스의 기반이 되는 구조다.\n팬의 행동 변화 5단계 .css-hokoge{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;counter-reset:numberedList;}.css-hokoge ul,.css-hokoge ol{margin:16px 0 0;}.css-hokoge>li{counter-increment:numberedList;margin-bottom:16px;padding-left:24px;}.css-hokoge>li:last-of-type{margin-bottom:0;}.css-hokoge>li>span{position:relative;}.css-hokoge>li>span>:first-child::before{content:counter(numberedList) '.';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n접촉(contact): 미디어 노출로 콘텐츠를 접하는 단계\n몰입(dive): 팔로우, 검색 등을 통해 적극적이지만 가벼운 관계를 형성하는 단계\n재미(play): 공유를 통해 제3자에게 정보를 공유하는 즐거움을 느끼는 단계\n사랑(love): 깊어지는 관계를 통해 감정과 관계의 밀도가 높아지는 단계\n헌신(devotion): 자신의 안정적인 감정 상태를 지키기 위해 행동하는 단계\n\n좋은 마케팅으로 짧은 성과는 낼 수 있다. 그러나 지속적이고 안정적인 성과를 내기 위해서는 반드시 팬이 필요하다. 그게 우리가 해결해야 할 문제다. \n\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 송수아 Graphic 이은호 이제현",
        "content": "디지털 콘텐츠 시대에 스트리밍의 역할",
        "contentSnippet": "디지털 콘텐츠 시대에 스트리밍의 역할",
        "guid": "https://blog.toss.im/article/fandustry-03",
        "isoDate": "2024-11-12T00:00:00.000Z"
      },
      {
        "title": "토스, 디자인 컨퍼런스 '심플리시티24' 개최",
        "link": "https://blog.toss.im/article/simplicity24",
        "pubDate": "Mon, 11 Nov 2024 23:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}모바일 금융 서비스 토스를 운영하는 비바리퍼블리카(이하 토스)가 디자인 컨퍼런스 '심플리시티24(Simplicity24)'를 개최한다고 12 일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n심플리시티는 토스 디자인팀의 경험과 노하우를 공유하는 컨퍼런스로, 올해로 3회째를 맞았다. 컨퍼런스 이름은 토스가 제품을 기획할 때 가장 중요하게 생각하는 원칙인 '단순함(Simplicity)'을 붙였다.\n올해는 모든 연사들이 ‘툴즈 프로덕트 디자이너(Tools Product Designer)’로 구성됐다. 툴즈 프로덕트 디자이너는 서비스를 만드는 팀원들이 더 효율적으로 일할 수 있도록 돕는 도구(Tool)를 만든다. 시중에 출시되지 않은 기능들을 구현해 생산성을 향상시키는 것이 특징이다.\n컨퍼런스의 주제는 'Simple Question, Big Wins: 성공의 문을 여는 가장 평범한 질문'이다. 주제에 맞게 세션의 제목은 모두 질문으로 시작한다. 총 11개의 세션은 △Wise Whys: 문제의 본질을 파고들어 모호함을 임팩트로 만들어낸 이야기 △Noise to Melody: 복잡한 이해관계 속에서 조화로운 솔루션을 발견한 이야기 △Beyond Frames: 역할과 제품의 틀에서 벗어나 새로운 답을 찾아낸 이야기 등 세 가지 트랙으로 구분했다.\n세션은 주제와 관련된 이미지와 자막이 화면에 함께 재생되는 '인터랙션 디자인(Interaction Design)'을 적용해 전달한다. 시작과 끝에는 영상을 삽입해 생동감 또한 높였다. 이를 통해 온라인 컨퍼런스임에도 일방적으로 내용을 전달하는 것이 아닌, 함께 생각하고 답을 고민할 수 있는 소통의 방식을 구현해 냈다.\n정희연 토스 CDO는 \"툴즈 프로덕트 디자인 분야는 생소한 만큼 다른 디자이너의 고민을 듣거나 레퍼런스를 참고하기 쉽지 않기 때문에 도움이 되기를 바라는 마음으로 이번 컨퍼런스를 기획했다”라며 “올해 심플리시티가 툴즈 프로덕트 디자이너를 꿈꾸는 분들에게, 그리고 효율적으로 문제를 해결하고 싶은 분들에게 많은 도움이 되었으면 좋겠다”라고 전했다.\n사전 신청을 완료한 경우 문자 및 이메일로 전달된 링크를 통해 세션 시청이 가능하다. 사전 신청을 하지 않았을 경우 심플리시티24 공식 홈페이지에 접속해 세션을 시청할 수 있다. 11월 24일(일)까지 시청 인증 이벤트도 진행한다. 세션 시청이 끝날 때 화면에 나타나는 인증 카드 중 하나를 개인 인스타그램 계정에 포스팅하면서 토스 디자인 챕터 계정을 태그하면 참여할 수 있다. 추첨을 통해 최대 100명에게 심플리시티24 굿즈를 증정한다.",
        "content": "툴즈 프로덕트 디자이너들이 연사로 참여… 11월 24일까지 시청 인증 이벤트 진행",
        "contentSnippet": "툴즈 프로덕트 디자이너들이 연사로 참여… 11월 24일까지 시청 인증 이벤트 진행",
        "guid": "https://blog.toss.im/article/simplicity24",
        "isoDate": "2024-11-11T23:00:00.000Z"
      },
      {
        "title": "토스, 금융보안원 주관 ‘금융보안 위협분석 대회’ 우승",
        "link": "https://blog.toss.im/article/Toss-Fiesta2024",
        "pubDate": "Mon, 11 Nov 2024 00:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}FIESTA 2024 참가…사이버 위협 관련 출제 문제 모두 풀며 최우수상 수상\n2021년부터 4번째 대회 우승…국내 최고 수준 보안 역량 입증\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n모바일 금융 서비스 ‘토스’를 운영하는 비바리퍼블리카(이하 ‘토스’)가 금융보안원 주관 ‘금융보안 위협분석 대회(FIESTA 2024)’에서 우승했다고 11일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n이 대회는 금융권 사이버 보안 위협분석 및 침해 대응 역량 강화를 목적으로 열리는 행사다. 실제 발생할 수 있는 사이버 위협 시나리오를 토대로 출제된 문제를 푸는 방식으로 우승자를 가린다. 올해 대회는 10월 4일부터 6일까지 사흘간 진행됐다.\n토스는 ‘디카페인 말차라떼’라는 팀명으로 보안팀 소속 최정수, 권재승, 강동석, 김재성 화이트해커가 참가했다. 이들은 특히 생성형 AI, 클라우드, 공급망 분야에서 침해 사고 대응 역량을 검증하는 문제들을 모두 풀어내며 대회 1위 쾌거를 이뤘다. 첫 출전인 2021년부터 올해까지 4년 연속 우승으로 국내 최고 수준 금융보안 역량을 입증했다.\n토스는 이번 대회에 참가한 4명을 비롯해 화이트해커로 구성된 팀을 두고 있다. 해당 팀은 사이버 공격에 대비한 훈련 등으로 토스 보안 체계 구축에 힘을 쏟고 있다. 상시로 버그바운티 챌린지(모의 해킹대회)를 운영하며 새로운 보안 기술을 연구에도 매진하고 있다.\n그 결과 ‘ISO27001’, ‘ISMS-P’, ‘PCI DSS Level1’, ‘ISO 27701’ 인증을 취득하는 등 보안과 정보보호 체계 전반에서 세계 최고 수준 평가를 받고 있다.\n토스 관계자는 “4년 연속 우승이라는 쾌거로 토스의 보안 역량을 더 확실하게 증명할 수 있어 기쁘다”라며 “앞으로도 보안 투자와 연구를 지속하며 고객들의 안전한 금융 생활을 위해 매진하겠다”라고 말했다.",
        "content": "4년 연속 쾌거",
        "contentSnippet": "4년 연속 쾌거",
        "guid": "https://blog.toss.im/article/Toss-Fiesta2024",
        "isoDate": "2024-11-11T00:00:00.000Z"
      },
      {
        "title": "‘탄소 손자국’의 힘, 나의 작은 실천이 지구의 미래를 바꿔요",
        "link": "https://blog.toss.im/article/economic-terms-35-carbon-handprint",
        "pubDate": "Thu, 07 Nov 2024 02:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-8atqhb{width:100%;}.css-1c1qox8{font-size:30px;letter-spacing:0em;line-height:1.55;font-weight:bold;color:var(--adaptiveGrey900);margin:40px 0 4px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-p4abj2{display:contents;line-height:1.55;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}🔖 이번 주 경제 용어\n탄소 손자국\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1iisb9p{display:contents;line-height:1.6;}\n.css-1pgssrp{max-width:100%;border-radius:16px;}\n.css-1kxrhf3{white-space:pre-wrap;}특정 상품이나 서비스를 사용하면서 줄일 수 있는 온실가스 배출량을 측정하는 것을 말해요.\n\n\n‘탄소 손자국(Carbon Handprint)’은 우리가 특정 상품이나 서비스를 사용함으로써 감축할 수 있는 온실가스 배출량을 의미하기에, 환경에 미치는 긍정적인 영향을 측정하는 새로운 개념인데요. 기존에 활용되던 개념인 ‘탄소 발자국(Carbon Footprint)’과는 비슷하면서 살짝 달라요.\n탄소 발자국은 상품의 원료, 생산, 소비, 폐기 등 전 과정에서 발생하는 온실가스 발생량을 이산화탄소 배출량으로 환산한 것인데요. 환경에 미치는 ‘부정적 영향'을 측정하는 데에 활용됩니다. 예를 들어, 자동차 운전, 항공 여행, 전기 사용 등이 모두 탄소 발자국을 증가시키는 활동에 해당하는 것이죠.\n반면, 탄소 손자국은 개인이나 조직이 환경에 기여하는 ‘긍정적 영향'을 측정하는 데에 활용됩니다. 온실가스 배출을 위한 노력의 성과를 측정하는 개념이니까요. 즉, 탄소 손자국은 탄소 발자국을 줄이기 위한 ‘노력의 성과’라고도 볼 수 있겠죠. 예를 들면, 에너지 효율이 높은 제품을 사용하거나, 재생 가능한 에너지를 사용하는 것이 탄소 손자국을 증가시키는 활동에 해당합니다.\n이러한 이유로 .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}탄소 발자국은 0에 가까워지도록 최소화하는 것이 목표이지만, 탄소 손자국은 최대한 늘리는 것이 목표가 됩니다.\n탄소 손자국은 크게 2가지로 구분합니다. (1) 기업과 같은 생산자가 생산 과정에서 탄소 배출량을 줄이는 경우, (2) 소비자가 상품을 사용함으로써 탄소 배출량을 줄이는 경우입니다.\n예를 들어, 기업이 공정을 개선해 고효율 냉장고를 생산했다면 생산 과정에서 탄소 발자국을 감축했다 = 즉, 탄소 손자국을 늘렸다 볼 수 있는 것이고요. 소비자가 냉장고 사용 과정에서 전력 소비를 절감하기 위해 노력했다면 또 한 번 탄소 손자국을 확보한 것입니다.\n이처럼 저탄소 제품을 생산하고 사용하는 과정에서 줄인 온실가스 배출량은 해당 제품을 제공한 기업의 성과로 인정되며, 친환경 이미지를 강화하는 데에 기여할 수 있습니다.\n\n\n.css-2yhypk{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);font-style:italic;-webkit-text-decoration:underline!important;text-decoration:underline!important;}\"극적으로 탄소배출량 줄인 이 남자가 소·양 대신 먹은 것“\n(한겨례 21 2024.8.17)\n1.5도 라이프스타일 보고서가 나온 이후, 개별적으로 실험하는 시민들이 등장했다. 영국의 환경운동가 로절린드 리드헤드는 2019년 보고서를 바탕으로 1년간 1t의 탄소만을 배출하는 삶을 시도했다. 처음엔 2050년 목표치인 0.7t에 도전했지만, 현재의 인프라로는 불가능하다고 판단해 1t으로 목표치를 바꾸고 성공했다. 올터는 리드헤드로부터 실험에 관한 이야기를 직접 듣고 실험에 참여하기로 결심했다. “사실 연간 1t은 불가능하다고 생각했어요. 연구소에서 제시한 (2030년 목표인) 2.5t을 목표로 해보기로 했죠.”\n연간 2.5t이라는 배출량도 하루로 치면 약 6.8㎏이다. 붉은 육류 위주의 한 끼 식사에서 배출되는 탄소가 약 7.7㎏ 정도이니, 연 배출 2.5t을 달성하기 위해선 먹거리부터 이동, 소비 등 삶의 전반적인 방식을 바꿔야 했다. 어떻게 가능했을까. 그의 첫 번째 전략은 교통수단의 변화였다. “북미 지역에서 발생하는 탄소배출량의 가장 큰 부분이 자동차입니다. 저는 1년 동안 운전을 완전히 포기했어요.”\n캐나다의 1명당 평균 탄소배출량 구성을 보면 교통이 35%로 가장 많다. 14.2t 중에 5t이 교통에서 배출된다. 올터가 운전을 포기할 수 있었던 이유는 부동산 개발업을 그만두고 환경 관련 웹사이트에 글을 올리는 작가 일을 시작했기 때문이다.\n“저는 운이 좋은 편이었어요. 집에서 일할 수 있었고 아이들도 근처에 있었고요. 제가 사는 도시는 쇼핑도 대부분 도보나 자전거로 할 수 있었어요. 또 대학에 강의를 나갈 때도 자전거를 타고 다닐 수 있었습니다.” 1년 동안 한 번 미국 뉴욕에 다녀온 것 외에는 비행기도 타지 않았다. 식단도 바꿨다. “고기를 포기하는 것은 어렵지만 소나 양을 포기하고 탄소 배출이 훨씬 적은 돼지와 닭만 먹는 것은 그리 어렵지 않았어요. 문제가 되는 건 소나 양과 같은 반추동물이죠.”(중략)\n\n\n전 세계적으로 기후변화에 대응하기 위한 목표는 ‘온실가스 배출을 크게 줄이는 것’입니다. ‘기후변화에 관한 정부간 협의체(IPCC)’는 지구의 온도를 1.5도 이하로 유지하기 위해서는, 개인이 3.4톤 이하의 탄소만 배출해야 한다고 발표했는데요. 이는 전체 온실가스 배출량을 인구 수로 나눈 단순 결과값이었습니다.\n하지만 2019년에 발표된 일본과 핀란드의 '1.5도 라이프스타일 보고서'는 더욱 현실적인 접근을 제안합니다. 각 개인의 생활 방식을 기준으로 탄소 배출을 분석한 것인데요. 보고서에 따르면, 전체 탄소 배출량의 72%가 가정에서의 소비와 관련 있으니 개인이 연간 2.5톤의 탄소만 배출하도록 더 노력해야 한다고 합니다. 더 나아가 2040년에는 1.4톤, 2050년에는 0.7톤까지 줄여야 한다고 했고요.\n기사에 나온 영국의 환경운동가 로절린드 리드헤드는, 실제로 이 보고서에서 제안하는 방향으로 1년간 1톤의 탄소만 배출하는 삶에 도전했습니다. 기사의 또다른 주인공 로이드 올터도 2.5톤 이내로 탄소배출량을 줄이기 위해 이전과 완전히 다른 라이프스타일을 택했고요.\n그렇다면 개인이 배출하는 탄소 양을 줄이기 위해, 우리는 실생활에서 어떤 방법들을 실천해볼 수 있을까요?\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n교통수단 바꾸기: 자동차 운전을 줄이고, 걷기, 자전거 타기, 대중교통 이용하기 등의 습관을 만들어 보세요. 특히 출퇴근할 때 자전거와 대중교통을 사용하면, 자연스럽게 운동이 되기 때문에 건강에도 좋습니다.\n식단 조절: 사육 과정에서 많은 탄소를 배출하는 소와 양 같은 붉은 고기 대신, 돼지나 닭 같이 탄소 배출이 적은 고기를 선택해 보세요. 더 나아가 채식 위주의 식사를 시도하는 것도 좋은 방법입니다.\n소비 습관 바꾸기: 전자제품과 의류 등의 제품을 최대한 오래 사용하고, 새로운 제품을 자주 구매하지 않도록 해요. 하나의 제품을 오래 사용하는 습관을 길러보는 것은 탄소 배출을 줄이는 데 큰 도움이 되겠죠.\n도시 환경 활용: 가까운 곳은 도보로 다니거나 자전거를 활용하는 등, 도시의 친환경적인 구조를 최대한 활용해 봅시다. 네덜란드와 같이 걷기, 자전거 타기에 최적화된 도시에서는 일상생활 속에서 자연스럽게 탄소 손자국을 늘릴 수 있습니다. 이처럼 도시 내 교통수단과 도보, 자전거 사용을 통해 배출량을 줄이는 습관은 탄소 손자국을 늘리는 데 큰 도움이 됩니다.\n\n이렇게 개인의 작은 생활 습관 변화로도 탄소 손자국을 확대할 수 있답니다. 동시에 정부와 기업 역시 탄소 배출을 줄이기 위해 힘을 모아야 합니다. 정부는 탄소 배출을 줄일 수 있도록 도시 설계를 하고, 기업은 생산 과정에서 탄소 배출이 적으면서 친환경 제품을 만들기 위해 노력해야겠죠.\n탄소 손자국을 늘리는 것은 단순히 환경 보호를 위한 수단을 너머, 장기적으로 지구에서 살아가는 우리 모두가 함께 기후 변화에 대응하는 중요한 역할을 하게 될 것입니다.\n\n\n탄소 중립: 최종적으로 탄소 배출량이 ‘0’이 되도록 하는 것을 목표로 하는 개념. 배출한 만큼의 탄소를 흡수하거나 상쇄하는 방법을 함께 수행해요. 나무 심기 같은 활동이 이에 해당됩니다.\n지속 가능한 생활(Sustainable Living): 현 세대가 사용하는 자원이 미래 세대의 자원까지 고갈시키지 않도록, 환경을 생각하며 생활하는 방식. 일회용품을 줄이고 재활용하는 것, 새 제품을 계속 구입하는 것보다 하나의 제품이나 서비스를 오래도록 이용하는 것이 지속 가능한 생활을 실천하는 방법이 될 수 있겠죠.\n\n\n.css-13d8cj1{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;margin:24px 0 8px;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:var(--adaptiveGrey700);}\n.css-1dzrkjz{width:16px;margin-right:8px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}\n.svg-icon-wrapper{position:relative;display:inline-block;width:24px;height:24px;}.svg-icon-wrapper >.svg-icon:empty+.svg-icon-fallback{visibility:visible;z-index:inherit;}.svg-icon{color:var(--adaptiveGrey900);display:inline-block;width:24px;height:24px;display:block;width:100%;height:100%;}.svg-icon svg,.svg-icon img{display:block;width:100%;height:100%;}.svg-icon--hide{display:none;}.svg-icon-fallback{position:absolute;left:0;right:0;top:0;z-index:z-index(hidden);visibility:hidden;display:block;width:100%;height:100%;}.svg-icon-fallback--show{visibility:visible;z-index:inherit;}\n참고 자료\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 금혜원 Graphic 조수희 이동건",
        "content": "탄소 발자국 줄이고, 탄소 손자국 늘리는 생활 습관",
        "contentSnippet": "탄소 발자국 줄이고, 탄소 손자국 늘리는 생활 습관",
        "guid": "https://blog.toss.im/article/economic-terms-35-carbon-handprint",
        "isoDate": "2024-11-07T02:00:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]