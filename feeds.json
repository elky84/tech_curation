[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Augustin Popa",
        "title": "Siemens Healthineers manages C++ libraries with vcpkg in an offline build environment",
        "link": "https://devblogs.microsoft.com/cppblog/siemens-healthineers-manages-c-libraries-with-vcpkg-in-an-offline-build-environment/",
        "pubDate": "Tue, 12 Nov 2024 23:10:37 +0000",
        "content:encodedSnippet": "vcpkg is a free and open-source C/C++ package manager maintained by Microsoft and the C++ community that runs on Windows, macOS, and Linux. Over the years we have heard from companies using vcpkg to manage dependencies at enterprise-scale. For this blog post, I spoke to Shrey Chauhan, a Senior DevOps Engineer with Siemens Healthineers.\nSiemens Healthineers adopted vcpkg in late 2023 after a successful proof of concept. Their main motivation was to improve their versioning and overall dependency management for C++ libraries in their offline, air-gapped build environment. They also like vcpkg’s integration with the Visual Studio IDE, extensive and evolving library support, and automatic dependency resolution.\nAbout Siemens Healthineers and development team\nShrey: The Ultrasound business area is an integral part of Siemens Healthineers. This advanced medical device features a comprehensive hardware layer and a full-stack windows-based software layer. Ultrasound Software teams handle the development of the entire software stack, while the DevOps team manages CI/CD processes, including building, packaging, deployment, and related tools.\nC++ development environment\nSiemens Healthineers develops on Windows and targets Windows x64. They use Visual Studio 2022 with MSBuild projects, and their project is a combination of C#, C++/CLI, and C++. They have around 300 developers maintaining over 6 million lines of code. In addition, they use Azure DevOps as their continuous integration system.\nHow they were managing C++ dependencies before vcpkg\nTheir team mostly consumes open-source dependencies. They were previously packaging the C++ dependencies in individual .zip packages, which were being downloaded from a JFrog Artifactory repository. This is a tedious process because the path to each .dll or .lib needs to be correct and could vary based on the package.\nQ: When did your team move to vcpkg and why did you ultimately choose to move to vcpkg?\nShrey: We moved to vcpkg around September or October 2023 with the main reasoning being improved versioning and dependency management of C++ libraries. We did a proof of concept to determine if it suited our needs with respect to our air-gapped build environment, which was successful after a little help from vcpkg team. Additional features we benefitted from:\nvcpkg is well integrated with Visual Studio IDE\nHas extensive library support, which is still evolving\nAutomatic dependency resolution\nIn Siemens Ultrasound, our builds/CI are on a protected network with restricted access to the Internet. By default, vcpkg downloads packages from source repositories (Internet) which did not work for us because of access restrictions. We were able to work with the vcpkg team to integrate custom Asset Caching (which was later documented under: How to create a x-script Asset Caching source for NuGet | Microsoft Learn) to use our own Azure DevOps NuGet feed as a source to upload & restore packages. This addressed our issue with the air-gapped environment and allowed us to reuse existing cached packages, making the process more efficient.\nQ: What is your overall impression of vcpkg?\nShrey: Overall, the feedback has been good so far. vcpkg does a great job of caching the built libraries, making the developers’ workflow efficient. It has also been easily accepted by developers because of its ease of use (i.e. no extra steps or setup was required).\nLearn More About vcpkg\nIf you want to learn more about vcpkg, check out our website at vcpkg.io and read the vcpkg overview in our documentation.\nIf you have a story you would like to share with us about your experiences with vcpkg, feel free to contact us at vcpkg@microsoft.com. You can submit bug reports in our GitHub issue tracker or make feature requests in our discussion forum.\nThe post Siemens Healthineers manages C++ libraries with vcpkg in an offline build environment appeared first on C++ Team Blog.",
        "dc:creator": "Augustin Popa",
        "comments": "https://devblogs.microsoft.com/cppblog/siemens-healthineers-manages-c-libraries-with-vcpkg-in-an-offline-build-environment/#respond",
        "content": "<p>vcpkg is a free and open-source C/C++ package manager maintained by Microsoft and the C++ community that runs on Windows, macOS, and Linux. Over the years we have heard from companies using vcpkg to manage dependencies at enterprise-scale. For this blog post, I spoke to Shrey Chauhan, a Senior DevOps Engineer with Siemens Healthineers. Siemens [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/siemens-healthineers-manages-c-libraries-with-vcpkg-in-an-offline-build-environment/\">Siemens Healthineers manages C++ libraries with vcpkg in an offline build environment</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "vcpkg is a free and open-source C/C++ package manager maintained by Microsoft and the C++ community that runs on Windows, macOS, and Linux. Over the years we have heard from companies using vcpkg to manage dependencies at enterprise-scale. For this blog post, I spoke to Shrey Chauhan, a Senior DevOps Engineer with Siemens Healthineers. Siemens […]\nThe post Siemens Healthineers manages C++ libraries with vcpkg in an offline build environment appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34928",
        "categories": [
          "C++",
          "Vcpkg",
          "CPP",
          "vcpkg"
        ],
        "isoDate": "2024-11-12T23:10:37.000Z"
      },
      {
        "creator": "Sy Brand",
        "title": "What’s New for C++ Developers in Visual Studio 2022 17.12",
        "link": "https://devblogs.microsoft.com/cppblog/whats-new-for-c-developers-in-visual-studio-2022-17-12/",
        "pubDate": "Tue, 12 Nov 2024 20:58:48 +0000",
        "content:encodedSnippet": "We are happy to announce that Visual Studio 2022 version 17.12 is now generally available! This post summarizes the new features you can find in this release for C++. You can download Visual Studio 2022 from the Visual Studio downloads page or upgrade your existing installation by following the Update Visual Studio Learn page.\nStandard Library and MSVC Compiler\nAs always, you can find all the details about our STL work in the changelog on GitHub. Thanks to everyone who contributed changes for this release!\nOn the conformance side, we have finished the implementation of C++23’s P2286R8 Formatting Ranges by implementing:\nFormatters for the container adaptors stack, queue, and priority_queue. #4825\nrange-default-formatter. #4716\n\n\nWe implemented multidimensional subscript operators in the compiler, which supports our existing <mdspan> implementation. For example, you can use the my_mdspan[i,j] syntax to index multidimensional spans. Here’s a full example:\n#include <mdspan>\r\n#include <print>\r\n\r\nusing namespace std;\r\nint main() {\r\n    const char* const str{\"CatDogElkFox\"};\r\n    //Defines a multidimensional view of str\r\n    mdspan<const char, extents<int, 4, 3>> m{str, 4, 3};\r\n\r\n    for (int i = 0; i < m.extents().extent(0); ++i) {\r\n        for (int j = 0; j < m.extents().extent(1); ++j) {\r\n            //Note the m[i, j] syntax\r\n            print(\"m[{}, {}]: '{}'; \", i, j, m[i, j]);\r\n        }\r\n        println();\r\n    }\r\n}\nThis release also comes with some new C++26 features:\nP2997R1 Removing The Common Reference Requirement From The Indirectly Invocable Concepts\nP0952R2 A New Specification For generate_canonical()\nP2968R2 Make std::ignore A First-Class Object\nYou’ll find improvements to several debug visualizers, including those for mutex/recursive_mutex and move_iterator.\nWe added lifetimebound attributes to min, max, clamp, ranges::min, ranges::max, and ranges::clamp, allowing MSVC code analysis and Clang -Wdangling to detect dangling references in improper usage. See the documentation for warnings C26815 and C26816 for more information about lifetimebound annotations.\nFinally, we improved the performance of several types and algorithms. The popcount() function now uses a compiler intrinsic on ARM64. We further improved the vectorized implementations of the minmax_element() and minmax() algorithm families, and optimized the search() and find_end() algorithms. We also overhauled the implementations of condition_variable and condition_variable_any, which has knock-on effects on the timed_mutex and recursive_timed_mutex types.\nC++ Productivity\nSet Command Line Arguments\nFor Unreal Engine projects, you can now set the command line arguments to pass to your application directly from the toolbar. This toolbar component will show up by default if you have the Game development with C++ workload installed. If you don’t see it, you can add it by right-clicking on the toolbar and selecting Set Arguments.\n\nWe’ll be adding support for this feature to non-UE projects in the future. See Pass command-line arguments while debugging on Microsoft Learn for documentation.\nOpen Folder for Unreal Engine uproject\nWe have added an additional entry point to open your Unreal Engine uproject with Visual Studio’s uproject support. You can now open your uproject directly from the File menu by selecting Open > Folder…. This will open your Unreal Engine project in Visual Studio.\nFor more information on how to use this feature, see the documentation on Microsoft Learn and our announcement blog post.\n\nChange Signature Improvements\nWe have updated the Change Signature interface, allowing you to add, remove, and rearrange parameters in the parameter configuration section. Additionally, you can change their order by selecting and dragging them to a new position.\nThe access methods remain the same: press Ctrl+. to trigger the Quick Actions and Refactorings menu and select Change Signature.\n\nBuild Insights\nRun Build Insights on Selected Files\nYou can select a few files, run Build Insights on them, and see exactly how these files impact build performance.\n\nFilter Projects\nYou can now filter results based on projects. Simply click the filter button on the filter column header and select the projects you want to filter.\n\nGlob Patterns to Filter Files\nThe File Path Filter is incredibly useful for narrowing down your analysis to specific directories or excluding paths that aren’t relevant to your task.\n\nEnhanced Save Experience\nNow you can designate a folder to automatically store the reports so you can easily access them during your investigation.\n\nView Explanations\nYou can now see a short description on how each tab of Build Insights can be used, along with a link to the documentation for a detailed explanation.\n\nPath Adjustments\nWe have hidden full and relative paths to reduce clutter. To see full paths, simply hover over the file. You will also see a new File Name column for both files and translation units, displayed by default to help you quickly identify files without parsing lengthy paths.\n\nGeneral Productivity\nCopy from the Error List\nWhen you copy an error from the Error List using Ctrl+C, now only the description is copied to the clipboard. This makes it easier to search for the error online or share it with others.\nYou can still copy the entire row by right-clicking the error and selecting Copy Row from the context menu or hitting Ctrl+Shift+C.\nIf what you wanted to do with the error description was to do a web search, then just hit Ctrl+F1 to search for information about the error online.\n\nDock the Code Search window\nIf you need Code or Feature Search to stay out of your way, you now have more control over the behavior of the search window.\nYou can now dock the search window and perform tool window actions with it, like Solution Explorer and others.\n\nAfter opening Code Search or Feature Search, click on the box icon at the top right to convert it into a tool window. You may choose to dock it elsewhere, pop it out, auto-hide, etc. You can revert to the dismissible window by closing the tool window and reopening search.\n\nWe’ve also simplified and cleaned up the previewing experience in search. There is now one button, indicated with an eye icon, to toggle the preview on and off.\n\nRefresh your Find results\nWe heard from a lot of users that it’s frustrating having to reopen the Find window and go through the motions of redoing a search to get updated results. Maybe you just refactored some code and want to confirm everything has been changed as expected, or you pulled some recent changes and need your recent Find operation to reflect those updates.\nAfter completing Find in Files, you will now have the option to refresh the results in the window. You’ll get your updated results without having to redo the search.\n\nNon-blocking Code Cleanup on save\nPreviously when a Code Cleanup action was run on save, you couldn’t perform any actions in the IDE. We’ve now enhanced this to operate in a non-blocking manner. The cleanup process will run in the background and can be automatically cancelled if you resume typing.\nGit\nManage file renaming\nWhen you rename files from the Solution Explorer, you’ll now be reminded to stage your changes to see the renames in Git.\n\nCopy Git link\nYou can now get a GitHub or Azure DevOps link to a specific line of code to make it easy to share with your colleagues. Access this option by right-clicking on some code and selecting Git > Copy GitHub/Azure DevOps Permalink.\n\nDebugging\nInline Return Values\nThe debugger now displays return values inline, making it much easier to see the return value of functions that have complex return statements.\n\nGitHub Copilot\nSmart Variable Inspection\nYou can now click on Ask Copilot next to the value of a variable to get AI-driven insights into what led to your current program state. For example, the following program has an off-by-one error in its loop condition, resulting in undefined behavior:\n\nIf you click Ask Copilot, it tells you what went wrong:\n\nFix my Code\nFor errors in the Visual Studio Error List, you can click Ask Copilot for an explanation and a fix to get suggestions on how to rectify your errors. For example, if we try to fix the code from the previous section by introducing a range based for loop, we might get the following error:\n\nCopilot suggests the following:\n\nDebug Failed Tests\nWe might fix the above issue and write a test case to ensure the function works, but then have a cat sit on our keyboard and accidentally initialize n_cats to 1 instead of 0. Fortunately, GitHub Copilot now comes with options to help debug the test failure:\n\nSelecting this option may give something like the following:\n\nSend us your feedback\nWe are very much interested in your feedback to continue to improve this experience. The comments below are open. Feedback can also be shared through Visual Studio Developer Community. You can also reach us on Twitter (@VisualC), or via email at visualcpp@microsoft.com.\nThe post What’s New for C++ Developers in Visual Studio 2022 17.12 appeared first on C++ Team Blog.",
        "dc:creator": "Sy Brand",
        "comments": "https://devblogs.microsoft.com/cppblog/whats-new-for-c-developers-in-visual-studio-2022-17-12/#respond",
        "content": "<p>We are happy to announce that Visual Studio 2022 version 17.12 is now generally available! This post summarizes the new features you can find in this release for C++. You can download Visual Studio 2022 from the Visual Studio downloads page or upgrade your existing installation by following the Update Visual Studio Learn page. Standard Library and MSVC [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/whats-new-for-c-developers-in-visual-studio-2022-17-12/\">What’s New for C++ Developers in Visual Studio 2022 17.12</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "We are happy to announce that Visual Studio 2022 version 17.12 is now generally available! This post summarizes the new features you can find in this release for C++. You can download Visual Studio 2022 from the Visual Studio downloads page or upgrade your existing installation by following the Update Visual Studio Learn page. Standard Library and MSVC […]\nThe post What’s New for C++ Developers in Visual Studio 2022 17.12 appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34893",
        "categories": [
          "C++"
        ],
        "isoDate": "2024-11-12T20:58:48.000Z"
      },
      {
        "creator": "Augustin Popa",
        "title": "What’s New in vcpkg (October 2024)",
        "link": "https://devblogs.microsoft.com/cppblog/whats-new-in-vcpkg-october-2024/",
        "pubDate": "Thu, 07 Nov 2024 06:06:12 +0000",
        "content:encodedSnippet": "This blog post summarizes changes to the vcpkg package manager as part of the 2024.10.21 registry release, 2024-10-18 tool release, as well as changes to vcpkg documentation throughout October. This release adds support for Azure universal packages as a binary caching provider and other minor improvements.\nCppCon Talk on Managing C++ Dependencies\nI also gave a talk at CppCon about 10 Problems Large Companies Have with Managing C++ Dependencies and How to Solve Them. Here is a video recording of the talk:\n\nIn particular, I talked about several vcpkg features that can help:\nSupporting build from source as a fallback without sacrificing the build-time savings of binary dependency acquisition.\nUpgrading dependencies as a set using baselines, rather than managing them individually, to avoid version conflicts / diamond problems.\nHow to continue working in an offline build environment using asset caching.\nGetting any open-source libraries installed and working with your project with minimal effort, while also automatically resolving transitive dependencies.\nSome stats for this period:\nThere are now 2,490 total ports available in the vcpkg curated registry. A port is a versioned recipe for building a package from source, such as a C or C++ library.\n7 new ports were added to the curated registry.\n422 updates were made to existing ports. As always, we validate each change to a port by building all other ports that depend on or are depended by the library that is being updated for our 13 main triplets.\n53 contributors made commits (not counting the vcpkg maintainers).\nThe main vcpkg repo has over 6,400 forks and 23,200 stars on GitHub.\nvcpkg changelog (2024.10.21 release)\nThe following changes were made in October:\nAdded support for Azure universal packages as a binary caching provider (PR: Microsoft/vcpkg-tool#1491).\nOther minor improvements.\nDocumentation changes\nAdded reference documentation for binary caching with Azure universal packages as a back-end (PR: Microsoft/vcpkg-docs#414).\nUpdated links, fixed typos, and added some clarifications to usage examples for vcpkg maintainer functions (PR: Microsoft/vcpkg-docs#381, thanks @Thomas1664!).\nClarified how default features should be used for vcpkg ports in maintainer guide (PR: Microsoft/vcpkg-docs#410).\nUpdated docs for vcpkg supported host environments (PR: Microsoft/vcpkg-docs#415).\nImprovements to example for packaging GitHub repos in vcpkg (PR: Microsoft/vcpkg-docs#405, thanks @andre-nguyen!).\nFixed nuget command for setapikey in Set up a vcpkg binary cache using a NuGet feed tutorial (PR: Microsoft/vcpkg-docs#381, thanks @Thomas1664!).\nIf you have any suggestions for our documentation, please submit an issue in our GitHub repo or see the box at the bottom of a particular article.\n\nTotal ports available for tested triplets\ntriplet\nports available\n\n\nx64-windows\n2,361\n\n\nx86-windows\n2,261\n\n\nx64-windows-static\n2,261\n\n\nx64-windows-static-md\n2,281\n\n\narm64-windows\n1,960\n\n\nx64-uwp\n1,307\n\n\narm64-uwp\n1,276\n\n\nx64-linux\n2,336\n\n\nx64-osx\n2,209\n\n\narm64-osx\n2,132\n\n\narm-neon-android\n1,635\n\n\nx64-android\n1,713\n\n\narm64-android\n1,685\n\n\n\nWhile vcpkg supports a much larger variety of target platforms and architectures (as community triplets), the list above is validated exhaustively to ensure updated ports don’t break other ports in the catalog.\nThank you to our contributors\nvcpkg couldn’t be where it is today without contributions from our open-source community. Thank you for your continued support! The following people contributed to the vcpkg, vcpkg-tool, or vcpkg-docs repos in this release (listed alphabetically by GitHub username):\nADKaster\nAenBleidd\nAl17OTON\nandre-nguyen\nautoantwort\nbraindigitalis\nc8ef\ncenit\nComputerKing12\ndbolduc\ndg0yt\nfran6co\nGabeRundlett\nGastineau\nhansingt\nHappySeaFox\nHosseinmoein\nlrineau\nJAicewizard\njandupej\njeremy-rifkin\njiayuehua\njohnwason\nkadirlua\nkwsp\nlemourin\nlukasberbuer\nmiyanyan\nm-kuhn\nNeumann-A\nnickdademo\nnlogozzo\nOlli1080\nOsyotr\nplevy\nPoldraunic\nRealTimeChris\nredboltz\nrmisev\nRT2Code\nrtzoeller\nShadowrom2020\nSHIINASAMA\nsiukosev\nstarfishmod\nSunBlack\nSuperCodeHero\nsweemer\ntalregev\nteo-tsirpanis\nThomas1664\nwaywardmonkeys\nwinsoft666\nLearn more\nYou can find the main release notes on GitHub. Recent updates to the vcpkg tool can be viewed on the vcpkg-tool Releases page. To contribute to vcpkg documentation, visit the vcpkg-docs repo. If you’re new to vcpkg or curious about how a package manager can make your life easier as a C/C++ developer, check out the vcpkg website – vcpkg.io.\nIf you would like to contribute to vcpkg and its library catalog, or want to give us feedback on anything, check out our GitHub repo. Please report bugs or request updates to ports in our issue tracker or join more general discussion in our discussion forum.\nThe post What’s New in vcpkg (October 2024) appeared first on C++ Team Blog.",
        "dc:creator": "Augustin Popa",
        "comments": "https://devblogs.microsoft.com/cppblog/whats-new-in-vcpkg-october-2024/#respond",
        "content": "<p>This blog post summarizes changes to the vcpkg package manager as part of the 2024.10.21 registry release, 2024-10-18 tool release, as well as changes to vcpkg documentation throughout October. This release adds support for Azure universal packages as a binary caching provider and other minor improvements. CppCon Talk on Managing C++ Dependencies I also gave [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/whats-new-in-vcpkg-october-2024/\">What’s New in vcpkg (October 2024)</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "This blog post summarizes changes to the vcpkg package manager as part of the 2024.10.21 registry release, 2024-10-18 tool release, as well as changes to vcpkg documentation throughout October. This release adds support for Azure universal packages as a binary caching provider and other minor improvements. CppCon Talk on Managing C++ Dependencies I also gave […]\nThe post What’s New in vcpkg (October 2024) appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34878",
        "categories": [
          "C++",
          "Vcpkg",
          "vcpkg"
        ],
        "isoDate": "2024-11-07T06:06:12.000Z"
      }
    ]
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "How Meta built large-scale cryptographic monitoring",
        "link": "https://engineering.fb.com/2024/11/12/security/how-meta-built-large-scale-cryptographic-monitoring/",
        "pubDate": "Tue, 12 Nov 2024 17:00:10 +0000",
        "content:encodedSnippet": "Cryptographic monitoring at scale has been instrumental in helping our engineers understand how cryptography is used at Meta.\nMonitoring has given us a distinct advantage in our efforts to proactively detect and remove weak cryptographic algorithms and has assisted with our general change safety and reliability efforts.\nWe’re sharing insights into our own cryptographic monitoring system, including challenges faced in its implementation, with the hope of assisting others in the industry aiming to deploy cryptographic monitoring at a similar scale.\nMeta’s managed cryptographic library, FBCrypto, plays an important role within Meta’s infrastructure and is used by the majority of our core infrastructure services. Given this, having a robust monitoring system in place for FBCrypto has been instrumental in ensuring its reliability as well as in helping our engineers understand how cryptography is used at Meta so they can make informed development decisions.\nMonitoring the health of our library allows us to detect and revert bugs before they reach production services. The data from our monitoring service provides insight into the usage of FBCrypto, allowing us to make data-driven decisions when deciding what improvements to make to the library. For example, it helps us identify components that need more attention either because they are on a hot path or are less stable.\nUnderstanding exactly how clients are using said library is a common pain point in managing any widely distributed library. But the improved understanding of FBCrypto provided by our monitoring helps us maintain a high bar for security posture. Since there is a limit to how much data a symmetric cryptographic key can protect, logging allows us to detect key overuse and rotate keys proactively. It also helps us build an inventory of cryptography usage, making it easy to identify the callsites of weakened algorithms that need to be migrated – a very important task because we need to proactively switch from weakened algorithms to newer, more robust ones as cryptography strength decays over time.\nMore generally, improved understanding helps us to make emergency algorithm migrations when a vulnerability of a primitive is discovered.\nMore recently, this is aiding our efforts to ensure post-quantum readiness in our asymmetric use cases. The available data improves our decision-making process while prioritizing quantum-vulnerable use cases\nHow cryptographic monitoring works at Meta\nEffective cryptographic monitoring requires storing persisted logs of cryptographic events, upon which diagnostic and analytic tools can be used to gather further insights. Supporting logging at the scale of FBCrypto requires an implementation with unique performance considerations in mind. Given that FBCrypto is used along many high-volume and critical code paths, a naive logging implementation could easily overwhelm a standard logging infrastructure or cause significant performance regressions. This is true for most widely distributed libraries and is especially true in the field of cryptography, where the sheer volume of usage can come as a complete surprise to those unfamiliar with the space. For example, we recently disclosed that roughly 0.05% of CPU cycles at Meta are spent on X25519 key exchange. \nMost of Meta’s logs are constructed and written via Scribe, Meta’s standard logging framework. From there, data persists in Scuba and Hive, Meta’s short-term and long term data stores, respectively.\nTypically, the Scribe API is called directly to construct a log for every “event” that needs to be logged. For FBCrypto, this would mean constructing a log for nearly every cryptographic operation that our library is used for. Unfortunately, given the sheer frequency of such operations, a solution like this would consume an unreasonable amount of write throughput and storage capacity. A common solution to this problem would be to introduce sampling (i.e., only log 1/X cryptographic operations, and increase X until we no longer have capacity concerns). However, we felt strongly about not introducing any sampling since doing so would result in most logs being omitted, giving us a less clear picture of the library’s usage.\nInstead, the logging uses a “buffering and flushing” strategy, in which cryptographic events are aggregated across time and flushed to a data store at a preconfigured interval.\nDuring the aggregation, a “count” is maintained for every unique event. When it comes time to flush, this count is exported along with the log to convey how often that particular event took place. \nBelow is a rough illustration of what this looks like:\n\nIn the above example, the key named “myKeyName” is used to perform encryption using the AES-GCM-SIV encryption algorithm (in practice we log more fields than just key name, method, and algorithm). The operation happens five times and is assigned on a count of five. Since machines often compute millions of cryptographic operations per day, this strategy can lead to significant compute savings in production. \nA client-side view\nThe aggregation and flushing is implemented within FBCrypto, so the logging and flushing code sits on the client hosts. When clients call a given cryptographic operation (e.g., “encrypt()”), the operation is performed and the log is added to our aggregated buffer. We refer to the object that holds the buffer as the “buffered logger.”\nNote that the logging does not change the interface of FBCrypto, so all of this is transparent to the clients of the library. \n\nIn multithreaded environments all threads will log to the same buffer. For this to be performant, we need to choose the right underlying data structure (see the section below on “Additional optimizations” for more details).\nWhile the aggregation works to reduce space and time overhead, the logs need to eventually be written to storage for further use. To do this, a background thread runs on the client host to periodically call the Scribe API to export the logs and flush the map’s contents. \nBelow is an overview of the overall flow: \n\nAdditional optimizations\nWe had to make some additional optimizations to support cryptographic monitoring on Meta’s major products (Facebook, Whatsapp, Instagram, etc.).\nWith careful design choices around the logging logic and data structures used, our cryptographic logging operates with no sampling and has had a negligible impact on compute performance across Meta’s fleet.\nPartially randomized flushing\nDue to the nature of our buffering and flushing strategy, certain clients who were running jobs that restarted large sets of machines at around the same time would have those machines’ logs get flushed at about the same time. This would result in “spiky” writes to the logging platform, followed by longer periods of underutilization between flushes. To normalize our write throughput, we distribute these spikes across time by applying a randomized delay on a per-host basis before logs are flushed for the first time. This leads to a more uniform flushing cadence, allowing for a more consistent load on Scribe. \nThe figure below demonstrates how this works:\n\nDerived crypto\nFBCrypto supports a feature called derived crypto, which allows “child” keysets to be derived from “parent” keysets by applying a key derivation function (KDF) to all the keys in the keyset with some salt. This feature is used by a few large-scale use cases that need to generate millions of keys.\nOur logging initially created a unique row in the buffered logger for every derived keyset, which used a lot of space and put increased load on backend data stores. To address this, we now aggregate the cryptographic operations of derived keys under the name of the parent key. This reduces our overall capacity needs without harming our ability to detect key overuse since, in the worst case, the aggregations would be a pessimistic counter for any given child key. \nThanks to this aggregation, we were able to cut down on the vast majority of our logging volume, compared to the space that would have been used with no aggregation. \nThe Folly library \nInternally, our buffering makes use of the folly::ConcurrentHashMap, which is built to be performant under heavy writes in multithreaded environments, while still guaranteeing atomic accesses.  \nUnified offerings\nMeta’s existing infrastructure and its emphasis on unified offerings are key to supporting this at scale (see the Scribe logging framework and the FBCrypto library). These properties often mean that solutions only have to be implemented once in order for the entire company to benefit.\nThis is especially true here. Most machines in Meta’s fleet can log to Scribe, giving us easy log ingestion support. Furthermore, the wide adoption of FBCrypto gives us insights into cryptographic operations without needing clients to migrate to a new library/API. \nFrom an engineering perspective, this helps us overcome many hurdles that others in the industry might face. For example, it helps us avoid fragmentation that might require multiple custom solutions to be implemented, which would increase our engineering workload.\nThe impact of cryptographic monitoring\nThe insights from our cryptographic monitoring efforts have served multiple use cases across our security and infrastructure reliability efforts.\nPreemptively mitigating security vulnerabilities\nThanks to our long retention window, we can monitor trends over time and use them for more predictive modeling and analysis. We can present our findings to cryptography experts, who can do further analysis and predict whether vulnerabilities may emerge. This allows us to preemptively identify clients using cryptography in risky ways and work with them to mitigate these issues before they become real security vulnerabilities. \nThis is particularly beneficial in preparation for the world of post-quantum cryptography (PQC), which requires us to find clients using vulnerable algorithms and ensure they are migrated off in a timely fashion. \nWe have also found that being able to preemptively detect these vulnerabilities well in advance has led to stronger support during cross-team collaborations. Thanks to the ample notice, teams can seamlessly integrate any necessary migration efforts into their roadmap with minimal interruption to their ongoing projects.\nPromoting infrastructure reliability\nOur root dataset has also served as a useful proxy for client health. This is partially thanks to the lack of sampling, as we can see the exact number of calls taking place, along with their respective success rates. This has been particularly important during large-scale migrations, where anomalous drops in success rate, call volume, etc., may indicate a bug in a new code path. Indeed, numerous detectors and alarms have been built off our dataset to help us perform big migrations safely.\nThe dataset also contains library versioning information, so we can monitor what versions of our library are running across the fleet in real-time. This has been especially useful for rolling out new features, as we can see exactly which clients have picked up the latest changes. This allows us to move faster and more confidently, even when running large-scale migrations across the fleet. \nChallenges to cryptographic monitoring\nSupporting cryptographic logging at Meta’s scale has had its own unique set of challenges.\nCapacity constraints\nDespite our optimizations, we have occasionally found ourselves putting increased load on Scribe (see point above about underestimating cryptographic usage) and have worked with the Scribe team to manage the unexpected increase in write throughput. Doing so has been relatively easy for the company, considering the design optimizations mentioned above.\nWe also occasionally put an increased load on Scuba, which is optimized to be performant for real-time data (i.e., warm storage) and can be inefficient if used for larger datasets. To minimize compute costs, we also rely on Hive tables for longer-term storage (i.e., cold storage). \nFlushing on shutdown\nBesides flushing the logs in the shared singleton map at a preconfigured time interval, client machines will also do one final flush to log all remaining contents of their log buffer to Scribe when a job is being shut down. We have found that operating in a “shutdown environment” can lead to a number of interesting scenarios, particularly when attempting to access Scribe and its dependencies. Many of these scenarios boil down to the nuances of folly::Singleton, which is Meta’s go-to library for managing singletons. Likewise, running something “on shutdown” in Java requires using only synchronous I/O code and operating quickly.\nOur next initiatives for cryptographic monitoring\nWhile our work thus far has been largely a success, there are many exciting avenues for improvements. For example, further optimizing Scribe throughput and Scuba storage utilization to make more efficient use of Meta’s infrastructure  \nWe will also continue to leverage the logging data to further develop monitoring and data analytics to promote security and reliability. On the security side, this means continuing to take an inventory of use cases that would be vulnerable in a PQC world and migrate them to more resilient algorithms/configurations. In terms of reliability, it means gaining a better understanding of the end-to-end latency for cryptography use cases.\nWithin all of this it’s also important that we continue driving the unification of cryptographic offerings and monitoring tooling. While FBCrypto provides a unified set of offerings, there are other cryptographic use cases across Meta that use a different set of tools for telemetry and data collection. More non-trivial work is needed to achieve full unification with all use cases.\nAcknowledgments\nThis work could not have been accomplished without the critical efforts of numerous folks, particularly Grace Wu, Ilya Maykov, Isaac Elbaz, and the rest of the CryptoEng team at Meta.\nThe post How Meta built large-scale cryptographic monitoring appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Cryptographic monitoring at scale has been instrumental in helping our engineers understand how cryptography is used at Meta. Monitoring has given us a distinct advantage in our efforts to proactively detect and remove weak cryptographic algorithms and has assisted with our general change safety and reliability efforts. We’re sharing insights into our own cryptographic monitoring [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/11/12/security/how-meta-built-large-scale-cryptographic-monitoring/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/11/12/security/how-meta-built-large-scale-cryptographic-monitoring/\">How Meta built large-scale cryptographic monitoring</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Cryptographic monitoring at scale has been instrumental in helping our engineers understand how cryptography is used at Meta. Monitoring has given us a distinct advantage in our efforts to proactively detect and remove weak cryptographic algorithms and has assisted with our general change safety and reliability efforts. We’re sharing insights into our own cryptographic monitoring [...]\nRead More...\nThe post How Meta built large-scale cryptographic monitoring appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21935",
        "categories": [
          "Security"
        ],
        "isoDate": "2024-11-12T17:00:10.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": [
      {
        "creator": "Netflix Technology Blog",
        "title": "Netflix’s Distributed Counter Abstraction",
        "link": "https://netflixtechblog.com/netflixs-distributed-counter-abstraction-8d0c45eb66b2?source=rss----2615bd06b42e---4",
        "pubDate": "Tue, 12 Nov 2024 20:45:23 GMT",
        "content:encodedSnippet": "By: Rajiv Shringi, Oleksii Tkachuk, Kartik Sathyanarayanan\nIntroduction\nIn our previous blog post, we introduced Netflix’s TimeSeries Abstraction, a distributed service designed to store and query large volumes of temporal event data with low millisecond latencies. Today, we’re excited to present the Distributed Counter Abstraction. This counting service, built on top of the TimeSeries Abstraction, enables distributed counting at scale while maintaining similar low latency performance. As with all our abstractions, we use our Data Gateway Control Plane to shard, configure, and deploy this service globally.\nDistributed counting is a challenging problem in computer science. In this blog post, we’ll explore the diverse counting requirements at Netflix, the challenges of achieving accurate counts in near real-time, and the rationale behind our chosen approach, including the necessary trade-offs.\nNote: When it comes to distributed counters, terms such as ‘accurate’ or ‘precise’ should be taken with a grain of salt. In this context, they refer to a count very close to accurate, presented with minimal delays.\nUse Cases and Requirements\nAt Netflix, our counting use cases include tracking millions of user interactions, monitoring how often specific features or experiences are shown to users, and counting multiple facets of data during A/B test experiments, among others.\nAt Netflix, these use cases can be classified into two broad categories:\n\nBest-Effort: For this category, the count doesn’t have to be very accurate or durable. However, this category requires near-immediate access to the current count at low latencies, all while keeping infrastructure costs to a minimum.\nEventually Consistent: This category needs accurate and durable counts, and is willing to tolerate a slight delay in accuracy and a slightly higher infrastructure cost as a trade-off.\n\nBoth categories share common requirements, such as high throughput and high availability. The table below provides a detailed overview of the diverse requirements across these two categories.\n\nDistributed Counter Abstraction\nTo meet the outlined requirements, the Counter Abstraction was designed to be highly configurable. It allows users to choose between different counting modes, such as Best-Effort or Eventually Consistent, while considering the documented trade-offs of each option. After selecting a mode, users can interact with APIs without needing to worry about the underlying storage mechanisms and counting methods.\nLet’s take a closer look at the structure and functionality of the API.\nAPI\nCounters are organized into separate namespaces that users set up for each of their specific use cases. Each namespace can be configured with different parameters, such as Type of Counter, Time-To-Live (TTL), and Counter Cardinality, using the service’s Control Plane.\nThe Counter Abstraction API resembles Java’s AtomicInteger interface:\nAddCount/AddAndGetCount: Adjusts the count for the specified counter by the given delta value within a dataset. The delta value can be positive or negative. The AddAndGetCount counterpart also returns the count after performing the add operation.\n{\n  \"namespace\": \"my_dataset\",\n  \"counter_name\": \"counter123\",\n  \"delta\": 2,\n  \"idempotency_token\": { \n    \"token\": \"some_event_id\",\n    \"generation_time\": \"2024-10-05T14:48:00Z\"\n  }\n}\nThe idempotency token can be used for counter types that support them. Clients can use this token to safely retry or hedge their requests. Failures in a distributed system are a given, and having the ability to safely retry requests enhances the reliability of the service.\nGetCount: Retrieves the count value of the specified counter within a dataset.\n{\n  \"namespace\": \"my_dataset\",\n  \"counter_name\": \"counter123\"\n}\nClearCount: Effectively resets the count to 0 for the specified counter within a dataset.\n{\n  \"namespace\": \"my_dataset\",\n  \"counter_name\": \"counter456\",\n  \"idempotency_token\": {...}\n}\nNow, let’s look at the different types of counters supported within the Abstraction.\nTypes of Counters\nThe service primarily supports two types of counters: Best-Effort and Eventually Consistent, along with a third experimental type: Accurate. In the following sections, we’ll describe the different approaches for these types of counters and the trade-offs associated with each.\nBest Effort Regional Counter\nThis type of counter is powered by EVCache, Netflix’s distributed caching solution built on the widely popular Memcached. It is suitable for use cases like A/B experiments, where many concurrent experiments are run for relatively short durations and an approximate count is sufficient. Setting aside the complexities of provisioning, resource allocation, and control plane management, the core of this solution is remarkably straightforward:\n// counter cache key\ncounterCacheKey = <namespace>:<counter_name>\n// add operation\nreturn delta > 0\n    ? cache.incr(counterCacheKey, delta, TTL)\n    : cache.decr(counterCacheKey, Math.abs(delta), TTL);\n// get operation\ncache.get(counterCacheKey);\n// clear counts from all replicas\ncache.delete(counterCacheKey, ReplicaPolicy.ALL);\nEVCache delivers extremely high throughput at low millisecond latency or better within a single region, enabling a multi-tenant setup within a shared cluster, saving infrastructure costs. However, there are some trade-offs: it lacks cross-region replication for the increment operation and does not provide consistency guarantees, which may be necessary for an accurate count. Additionally, idempotency is not natively supported, making it unsafe to retry or hedge requests.\nEventually Consistent Global Counter\nWhile some users may accept the limitations of a Best-Effort counter, others opt for precise counts, durability and global availability. In the following sections, we’ll explore various strategies for achieving durable and accurate counts. Our objective is to highlight the challenges inherent in global distributed counting and explain the reasoning behind our chosen approach.\nApproach 1: Storing a Single Row per Counter\nLet’s start simple by using a single row per counter key within a table in a globally replicated datastore.\n\nLet’s examine some of the drawbacks of this approach:\n\nLack of Idempotency: There is no idempotency key baked into the storage data-model preventing users from safely retrying requests. Implementing idempotency would likely require using an external system for such keys, which can further degrade performance or cause race conditions.\nHeavy Contention: To update counts reliably, every writer must perform a Compare-And-Swap operation for a given counter using locks or transactions. Depending on the throughput and concurrency of operations, this can lead to significant contention, heavily impacting performance.\n\nSecondary Keys: One way to reduce contention in this approach would be to use a secondary key, such as a bucket_id, which allows for distributing writes by splitting a given counter into buckets, while enabling reads to aggregate across buckets. The challenge lies in determining the appropriate number of buckets. A static number may still lead to contention with hot keys, while dynamically assigning the number of buckets per counter across millions of counters presents a more complex problem.\nLet’s see if we can iterate on our solution to overcome these drawbacks.\nApproach 2: Per Instance Aggregation\nTo address issues of hot keys and contention from writing to the same row in real-time, we could implement a strategy where each instance aggregates the counts in memory and then flushes them to disk at regular intervals. Introducing sufficient jitter to the flush process can further reduce contention.\n\nHowever, this solution presents a new set of issues:\n\nVulnerability to Data Loss: The solution is vulnerable to data loss for all in-memory data during instance failures, restarts, or deployments.\nInability to Reliably Reset Counts: Due to counting requests being distributed across multiple machines, it is challenging to establish consensus on the exact point in time when a counter reset occurred.\nLack of Idempotency: Similar to the previous approach, this method does not natively guarantee idempotency. One way to achieve idempotency is by consistently routing the same set of counters to the same instance. However, this approach may introduce additional complexities, such as leader election, and potential challenges with availability and latency in the write path.\n\nThat said, this approach may still be suitable in scenarios where these trade-offs are acceptable. However, let’s see if we can address some of these issues with a different event-based approach.\nApproach 3: Using Durable Queues\nIn this approach, we log counter events into a durable queuing system like Apache Kafka to prevent any potential data loss. By creating multiple topic partitions and hashing the counter key to a specific partition, we ensure that the same set of counters are processed by the same set of consumers. This setup simplifies facilitating idempotency checks and resetting counts. Furthermore, by leveraging additional stream processing frameworks such as Kafka Streams or Apache Flink, we can implement windowed aggregations.\n\nHowever, this approach comes with some challenges:\n\nPotential Delays: Having the same consumer process all the counts from a given partition can lead to backups and delays, resulting in stale counts.\nRebalancing Partitions: This approach requires auto-scaling and rebalancing of topic partitions as the cardinality of counters and throughput increases.\n\nFurthermore, all approaches that pre-aggregate counts make it challenging to support two of our requirements for accurate counters:\n\nAuditing of Counts: Auditing involves extracting data to an offline system for analysis to ensure that increments were applied correctly to reach the final value. This process can also be used to track the provenance of increments. However, auditing becomes infeasible when counts are aggregated without storing the individual increments.\nPotential Recounting: Similar to auditing, if adjustments to increments are necessary and recounting of events within a time window is required, pre-aggregating counts makes this infeasible.\n\nBarring those few requirements, this approach can still be effective if we determine the right way to scale our queue partitions and consumers while maintaining idempotency. However, let’s explore how we can adjust this approach to meet the auditing and recounting requirements.\nApproach 4: Event Log of Individual Increments\nIn this approach, we log each individual counter increment along with its event_time and event_id. The event_id can include the source information of where the increment originated. The combination of event_time and event_id can also serve as the idempotency key for the write.\n\nHowever, in its simplest form, this approach has several drawbacks:\n\nRead Latency: Each read request requires scanning all increments for a given counter potentially degrading performance.\nDuplicate Work: Multiple threads might duplicate the effort of aggregating the same set of counters during read operations, leading to wasted effort and subpar resource utilization.\nWide Partitions: If using a datastore like Apache Cassandra, storing many increments for the same counter could lead to a wide partition, affecting read performance.\nLarge Data Footprint: Storing each increment individually could also result in a substantial data footprint over time. Without an efficient data retention strategy, this approach may struggle to scale effectively.\n\nThe combined impact of these issues can lead to increased infrastructure costs that may be difficult to justify. However, adopting an event-driven approach seems to be a significant step forward in addressing some of the challenges we’ve encountered and meeting our requirements.\nHow can we improve this solution further?\nNetflix’s Approach\nWe use a combination of the previous approaches, where we log each counting activity as an event, and continuously aggregate these events in the background using queues and a sliding time window. Additionally, we employ a bucketing strategy to prevent wide partitions. In the following sections, we’ll explore how this approach addresses the previously mentioned drawbacks and meets all our requirements.\nNote: From here on, we will use the words “rollup” and “aggregate” interchangeably. They essentially mean the same thing, i.e., collecting individual counter increments/decrements and arriving at the final value.\nTimeSeries Event Store:\nWe chose the TimeSeries Data Abstraction as our event store, where counter mutations are ingested as event records. Some of the benefits of storing events in TimeSeries include:\nHigh-Performance: The TimeSeries abstraction already addresses many of our requirements, including high availability and throughput, reliable and fast performance, and more.\nReducing Code Complexity: We reduce a lot of code complexity in Counter Abstraction by delegating a major portion of the functionality to an existing service.\nTimeSeries Abstraction uses Cassandra as the underlying event store, but it can be configured to work with any persistent store. Here is what it looks like:\n\nHandling Wide Partitions: The time_bucket and event_bucket columns play a crucial role in breaking up a wide partition, preventing high-throughput counter events from overwhelming a given partition. For more information regarding this, refer to our previous blog.\nNo Over-Counting: The event_time, event_id and event_item_key columns form the idempotency key for the events for a given counter, enabling clients to retry safely without the risk of over-counting.\nEvent Ordering: TimeSeries orders all events in descending order of time allowing us to leverage this property for events like count resets.\nEvent Retention: The TimeSeries Abstraction includes retention policies to ensure that events are not stored indefinitely, saving disk space and reducing infrastructure costs. Once events have been aggregated and moved to a more cost-effective store for audits, there’s no need to retain them in the primary storage.\nNow, let’s see how these events are aggregated for a given counter.\nAggregating Count Events:\nAs mentioned earlier, collecting all individual increments for every read request would be cost-prohibitive in terms of read performance. Therefore, a background aggregation process is necessary to continually converge counts and ensure optimal read performance.\nBut how can we safely aggregate count events amidst ongoing write operations?\nThis is where the concept of Eventually Consistent counts becomes crucial. By intentionally lagging behind the current time by a safe margin, we ensure that aggregation always occurs within an immutable window.\nLets see what that looks like:\n\nLet’s break this down:\n\nlastRollupTs: This represents the most recent time when the counter value was last aggregated. For a counter being operated for the first time, this timestamp defaults to a reasonable time in the past.\nImmutable Window and Lag: Aggregation can only occur safely within an immutable window that is no longer receiving counter events. The “acceptLimit” parameter of the TimeSeries Abstraction plays a crucial role here, as it rejects incoming events with timestamps beyond this limit. During aggregations, this window is pushed slightly further back to account for clock skews.\n\nThis does mean that the counter value will lag behind its most recent update by some margin (typically in the order of seconds). This approach does leave the door open for missed events due to cross-region replication issues. See “Future Work” section at the end.\n\nAggregation Process: The rollup process aggregates all events in the aggregation window since the last rollup to arrive at the new value.\n\nRollup Store:\nWe save the results of this aggregation in a persistent store. The next aggregation will simply continue from this checkpoint.\n\nWe create one such Rollup table per dataset and use Cassandra as our persistent store. However, as you will soon see in the Control Plane section, the Counter service can be configured to work with any persistent store.\nLastWriteTs: Every time a given counter receives a write, we also log a last-write-timestamp as a columnar update in this table. This is done using Cassandra’s USING TIMESTAMP feature to predictably apply the Last-Write-Win (LWW) semantics. This timestamp is the same as the event_time for the event. In the subsequent sections, we’ll see how this timestamp is used to keep some counters in active rollup circulation until they have caught up to their latest value.\nRollup Cache\nTo optimize read performance, these values are cached in EVCache for each counter. We combine the lastRollupCount and lastRollupTs into a single cached value per counter to prevent potential mismatches between the count and its corresponding checkpoint timestamp.\n\nBut, how do we know which counters to trigger rollups for? Let’s explore our Write and Read path to understand this better.\nAdd/Clear Count:\n\nAn add or clear count request writes durably to the TimeSeries Abstraction and updates the last-write-timestamp in the Rollup store. If the durability acknowledgement fails, clients can retry their requests with the same idempotency token without the risk of overcounting. Upon durability, we send a fire-and-forget request to trigger the rollup for the request counter.\nGetCount:\n\nWe return the last rolled-up count as a quick point-read operation, accepting the trade-off of potentially delivering a slightly stale count. We also trigger a rollup during the read operation to advance the last-rollup-timestamp, enhancing the performance of subsequent aggregations. This process also self-remediates a stale count if any previous rollups had failed.\nWith this approach, the counts continually converge to their latest value. Now, let’s see how we scale this approach to millions of counters and thousands of concurrent operations using our Rollup Pipeline.\nRollup Pipeline:\nEach Counter-Rollup server operates a rollup pipeline to efficiently aggregate counts across millions of counters. This is where most of the complexity in Counter Abstraction comes in. In the following sections, we will share key details on how efficient aggregations are achieved.\nLight-Weight Roll-Up Event: As seen in our Write and Read paths above, every operation on a counter sends a light-weight event to the Rollup server:\nrollupEvent: {\n  \"namespace\": \"my_dataset\",\n  \"counter\": \"counter123\"\n}\nNote that this event does not include the increment. This is only an indication to the Rollup server that this counter has been accessed and now needs to be aggregated. Knowing exactly which specific counters need to be aggregated prevents scanning the entire event dataset for the purpose of aggregations.\n\nIn-Memory Rollup Queues: A given Rollup server instance runs a set of in-memory queues to receive rollup events and parallelize aggregations. In the first version of this service, we settled on using in-memory queues to reduce provisioning complexity, save on infrastructure costs, and make rebalancing the number of queues fairly straightforward. However, this comes with the trade-off of potentially missing rollup events in case of an instance crash. For more details, see the “Stale Counts” section in “Future Work.”\nMinimize Duplicate Effort: We use a fast non-cryptographic hash like XXHash to ensure that the same set of counters end up on the same queue. Further, we try to minimize the amount of duplicate aggregation work by having a separate rollup stack that chooses to run fewer beefier instances.\n\nAvailability and Race Conditions: Having a single Rollup server instance can minimize duplicate aggregation work but may create availability challenges for triggering rollups. If we choose to horizontally scale the Rollup servers, we allow threads to overwrite rollup values while avoiding any form of distributed locking mechanisms to maintain high availability and performance. This approach remains safe because aggregation occurs within an immutable window. Although the concept of now() may differ between threads, causing rollup values to sometimes fluctuate, the counts will eventually converge to an accurate value within each immutable aggregation window.\nRebalancing Queues: If we need to scale the number of queues, a simple Control Plane configuration update followed by a re-deploy is enough to rebalance the number of queues.\n      \"eventual_counter_config\": {             \n          \"queue_config\": {                    \n            \"num_queues\" : 8,  // change to 16 and re-deploy\n...\nHandling Deployments: During deployments, these queues shut down gracefully, draining all existing events first, while the new Rollup server instance starts up with potentially new queue configurations. There may be a brief period when both the old and new Rollup servers are active, but as mentioned before, this race condition is managed since aggregations occur within immutable windows.\nMinimize Rollup Effort: Receiving multiple events for the same counter doesn’t mean rolling it up multiple times. We drain these rollup events into a Set, ensuring a given counter is rolled up only once during a rollup window.\nEfficient Aggregation: Each rollup consumer processes a batch of counters simultaneously. Within each batch, it queries the underlying TimeSeries abstraction in parallel to aggregate events within specified time boundaries. The TimeSeries abstraction optimizes these range scans to achieve low millisecond latencies.\nDynamic Batching: The Rollup server dynamically adjusts the number of time partitions that need to be scanned based on cardinality of counters in order to prevent overwhelming the underlying store with many parallel read requests.\n\nAdaptive Back-Pressure: Each consumer waits for one batch to complete before issuing the rollups for the next batch. It adjusts the wait time between batches based on the performance of the previous batch. This approach provides back-pressure during rollups to prevent overwhelming the underlying TimeSeries store.\nHandling Convergence:\n\nIn order to prevent low-cardinality counters from lagging behind too much and subsequently scanning too many time partitions, they are kept in constant rollup circulation. For high-cardinality counters, continuously circulating them would consume excessive memory in our Rollup queues. This is where the last-write-timestamp mentioned previously plays a crucial role. The Rollup server inspects this timestamp to determine if a given counter needs to be re-queued, ensuring that we continue aggregating until it has fully caught up with the writes.\nNow, let’s see how we leverage this counter type to provide an up-to-date current count in near-realtime.\nExperimental: Accurate Global Counter\nWe are experimenting with a slightly modified version of the Eventually Consistent counter. Again, take the term ‘Accurate’ with a grain of salt. The key difference between this type of counter and its counterpart is that the delta, representing the counts since the last-rolled-up timestamp, is computed in real-time.\n\nAggregating this delta in real-time can impact the performance of this operation, depending on the number of events and partitions that need to be scanned to retrieve this delta. The same principle of rolling up in batches applies here to prevent scanning too many partitions in parallel.\n\nConversely, if the counters in this dataset are accessed frequently, the time gap for the delta remains narrow, making this approach of fetching current counts quite effective.\nNow, let’s see how all this complexity is managed by having a unified Control Plane configuration.\nControl Plane\nThe Data Gateway Platform Control Plane manages control settings for all abstractions and namespaces, including the Counter Abstraction. Below, is an example of a control plane configuration for a namespace that supports eventually consistent counters with low cardinality:\n\"persistence_configuration\": [\n  {\n    \"id\": \"CACHE\",                             // Counter cache config\n    \"scope\": \"dal=counter\",                                                   \n    \"physical_storage\": {\n      \"type\": \"EVCACHE\",                       // type of cache storage\n      \"cluster\": \"evcache_dgw_counter_tier1\"   // Shared EVCache cluster\n    }\n  },\n  {\n    \"id\": \"COUNTER_ROLLUP\",\n    \"scope\": \"dal=counter\",                    // Counter abstraction config\n    \"physical_storage\": {                     \n      \"type\": \"CASSANDRA\",                     // type of Rollup store\n      \"cluster\": \"cass_dgw_counter_uc1\",       // physical cluster name\n      \"dataset\": \"my_dataset_1\"                // namespace/dataset   \n    },\n    \"counter_cardinality\": \"LOW\",              // supported counter cardinality\n    \"config\": {\n      \"counter_type\": \"EVENTUAL\",              // Type of counter\n      \"eventual_counter_config\": {             // eventual counter type\n        \"internal_config\": {                  \n          \"queue_config\": {                    // adjust w.r.t cardinality\n            \"num_queues\" : 8,                  // Rollup queues per instance\n            \"coalesce_ms\": 10000,              // coalesce duration for rollups\n            \"capacity_bytes\": 16777216         // allocated memory per queue\n          },\n          \"rollup_batch_count\": 32             // parallelization factor\n        }\n      }\n    }\n  },\n  {\n    \"id\": \"EVENT_STORAGE\",\n    \"scope\": \"dal=ts\",                         // TimeSeries Event store\n    \"physical_storage\": {\n      \"type\": \"CASSANDRA\",                     // persistent store type\n      \"cluster\": \"cass_dgw_counter_uc1\",       // physical cluster name\n      \"dataset\": \"my_dataset_1\",               // keyspace name\n    },\n    \"config\": {                              \n      \"time_partition\": {                      // time-partitioning for events\n        \"buckets_per_id\": 4,                   // event buckets within\n        \"seconds_per_bucket\": \"600\",           // smaller width for LOW card\n        \"seconds_per_slice\": \"86400\",          // width of a time slice table\n      },\n      \"accept_limit\": \"5s\",                    // boundary for immutability\n    },\n    \"lifecycleConfigs\": {\n      \"lifecycleConfig\": [\n        {\n          \"type\": \"retention\",                 // Event retention\n          \"config\": {\n            \"close_after\": \"518400s\",\n            \"delete_after\": \"604800s\"          // 7 day count event retention\n          }\n        }\n      ]\n    }\n  }\n]\nUsing such a control plane configuration, we compose multiple abstraction layers using containers deployed on the same host, with each container fetching configuration specific to its scope.\n\nProvisioning\nAs with the TimeSeries abstraction, our automation uses a bunch of user inputs regarding their workload and cardinalities to arrive at the right set of infrastructure and related control plane configuration. You can learn more about this process in a talk given by one of our stunning colleagues, Joey Lynch : How Netflix optimally provisions infrastructure in the cloud.\nPerformance\nAt the time of writing this blog, this service was processing close to 75K count requests/second globally across the different API endpoints and datasets:\n\nwhile providing single-digit millisecond latencies for all its endpoints:\n\nFuture Work\nWhile our system is robust, we still have work to do in making it more reliable and enhancing its features. Some of that work includes:\n\nRegional Rollups: Cross-region replication issues can result in missed events from other regions. An alternate strategy involves establishing a rollup table for each region, and then tallying them in a global rollup table. A key challenge in this design would be effectively communicating the clearing of the counter across regions.\nError Detection and Stale Counts: Excessively stale counts can occur if rollup events are lost or if a rollups fails and isn’t retried. This isn’t an issue for frequently accessed counters, as they remain in rollup circulation. This issue is more pronounced for counters that aren’t accessed frequently. Typically, the initial read for such a counter will trigger a rollup, self-remediating the issue. However, for use cases that cannot accept potentially stale initial reads, we plan to implement improved error detection, rollup handoffs, and durable queues for resilient retries.\n\nConclusion\nDistributed counting remains a challenging problem in computer science. In this blog, we explored multiple approaches to implement and deploy a Counting service at scale. While there may be other methods for distributed counting, our goal has been to deliver blazing fast performance at low infrastructure costs while maintaining high availability and providing idempotency guarantees. Along the way, we make various trade-offs to meet the diverse counting requirements at Netflix. We hope you found this blog post insightful.\nStay tuned for Part 3 of Composite Abstractions at Netflix, where we’ll introduce our Graph Abstraction, a new service being built on top of the Key-Value Abstraction and the TimeSeries Abstraction to handle high-throughput, low-latency graphs.\nAcknowledgments\nSpecial thanks to our stunning colleagues who contributed to the Counter Abstraction’s success: Joey Lynch, Vinay Chella, Kaidan Fullerton, Tom DeVoe, Mengqing Wang\n\nNetflix’s Distributed Counter Abstraction was originally published in Netflix TechBlog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Netflix Technology Blog",
        "guid": "https://medium.com/p/8d0c45eb66b2",
        "categories": [
          "counter",
          "software-architecture",
          "system-design-interview",
          "distributed-systems",
          "scalability"
        ],
        "isoDate": "2024-11-12T20:45:23.000Z"
      }
    ]
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "David Watson",
        "title": "WebStorm 2024.3: Built-In Database Tools and SQL Support, Better AI-driven Code Completion, and More",
        "link": "https://blog.jetbrains.com/webstorm/2024/11/webstorm-2024-3/",
        "pubDate": "Tue, 12 Nov 2024 16:05:08 +0000",
        "content:encodedSnippet": "Our third major release of 2024 is here! In this version, you’ll find built-in database tools and SQL support, various quality enhancements, better code completion with AI Assistant, and a whole lot more.\n\nDOWNLOAD WEBSTORM 2024.3\nIf you only have a few minutes to explore the highlights of WebStorm 2024.3, check out our quick review video above for the top highlights. If you want to dive deeper into what you can expect in the release, just carry on reading!\nThe new features and improvements in v2024.3 include:\nKey Highlights: Improved framework component navigation and renaming, built-in support for database tools and SQL, better code completion with AI Assistant.\nFrameworks and Technologies: Color preview for Tailwind CSS classes, improvements for Angular, and more.\nUser Experience: Optimized placement for the Rename action, cleaner search results for directories, highlighting for occurrences of selected text, and more.\nIntegrated Developer Tools: Option to disable background pre-commit checks, new Docker Compose build attributes, and more.\nKey Highlights\nImproved framework component navigation and renaming\nWebStorm 2024.3 now supports the Show component usages action for Vue, Svelte, and Astro and detects component usages both in imports and templates. You can also use this functionality by invoking the Find Usages action on the component file in the Project view:\n\n\n\n\nThe Rename refactoring has also been enhanced to include component usages renaming. When renaming a component file or explicitly defined name, the associated usages in templates will also be updated! This behavior can be disabled by toggling the Search for component usages option during the renaming process and in the Find dialog.\nBuilt-in support for database tools and SQL\nThe Database Tools and SQL plugin, which was previously only available via a separate paid subscription, is now bundled with WebStorm at no extra cost. You can query, create, and manage databases directly in the IDE. This extends WebStorm’s capabilities for backend and full-stack development. It also makes switching between JetBrains IDEs easier, as most of them include this functionality.\n\n\n\n\nBetter code completion with AI Assistant \nWebStorm 2024.3 has significantly improved AI-driven code completion for JavaScript and TypeScript. The new approach combines fast, local full-line completion with powerful cloud-based suggestions powered by JetBrains’ in-house LLMs. This hybrid approach enhances speed, accuracy, and usability while reducing the frequency of lengthy and irrelevant suggestions.\nHere are some of the key improvements:\nHighlighting is now applied to the suggested code, which previously was just plain gray text.\nPartial acceptance allows you to apply suggestions granularly, giving you more control over changes to your code:\n\nAccept suggestions word by word – ⌥ → / Alt+Right.\nAccept suggestions line by line – ⌘ → / Ctrl+Right.\nAs before, you can explicitly call completion with ⇧ ⌥ / / Shift+Alt.\nContext collection has been enhanced using RAG strategies.\nCompletion suggestions are now provided in more locations, and are now triggered during typing, not only on Enter keystrokes. Support for AI-based code completion has also been extended to HTML and CSS (including .css, .less, .scss, .sass, .pcss). Please refer to this blog post for more insights.\n\n\n\nFrameworks and Technologies\nColor preview for Tailwind CSS classes \nIn WebStorm 2024.3, color previews for Tailwind CSS classes are now shown inline in the editor. We’ve added support for the textDocument/documentColor method of the Language Server Protocol (LSP), so all LSP-based plugins now support this functionality out of the box.\n\n\n\nImprovements for Angular \nFor projects with Angular 19, WebStorm now defaults to standalone mode for components, directives, and pipes. Quick-fixes have been added to help convert between standalone and non-standalone components. Unused standalone imports can be automatically removed during code reformatting or via a new inspection. Support for the @let syntax has also been improved.\n\n\nCorrect handling of .prettierignore in subfolders \nWebStorm 2024.3 now properly handles .prettierignore files in subfolders with a package.json, ensuring ignored files aren’t formatted. A new option also lets you specify custom ignore files in Settings | Languages & Frameworks | JavaScript | Prettier.\n\n\n\nBundled Vue Language Server \nThe Vue Language Server is now bundled with WebStorm to enhance reliability and prevent issues with loading on WSL. We may do the same for Svelte, Astro, and other technologies in the future. \n\n\n\nImprovements for Svelte\nWebStorm 2024.3 provides support for the <script module> attribute, ensuring symbols from these blocks are resolved correctly. Additionally, there’s a new checkbox to disable SvelteKit a11y warnings, giving you more control over accessibility warnings. \n\n\n\nSupport for CSS exported via package.json \nWebStorm 2024.3 includes support for the exports field in package.json for CSS, Sass, SCSS, and Less. If styles are exported via package.json, WebStorm will no longer show warnings about unresolved variables.\nBun debugging support for Windows \nBasic Bun debugging, previously available only on macOS and Linux, is now supported on Windows. You can set breakpoints, step through code, inspect variables, and evaluate expressions within WebStorm.\nUser Experience\nOptimized placement for the Rename action\nWe’ve optimized the placement of the Rename action in the context menu when it’s called on elements in the editor and the Project tool window. The action is now at the top level, making it easier to quickly rename files, variables, and other elements.\n\n\n\nCleaner search results for directories\nWebStorm now excludes node_modules results by default when using Find in Files in project directories, reducing clutter from irrelevant files. You can restore the previous behavior by enabling the Search in library files when “Directory” is selected in Find in Files option under Settings | Advanced Settings.\n\n\n\nHighlight occurrences of selected text\nBy default, WebStorm will now automatically highlight all instances of the text you select within a file. This makes it easier to track where your selected text appears throughout your code. You can customize the feature in Settings | Editor | General | Appearance.\n\n\n\n.idea directory displayed by default\nPreviously, the .idea folder – a place where WebStorm stores internal configuration settings – was hidden by default. This made it harder for some users to commit project-wide configurations. To address this, we’ve made it visible in the Project tool window.\n\n\n\nBetter recognition of generated files\nWebStorm 2024.3 will automatically exclude unnecessary files in the dist folder from indexing to optimize CPU usage and decrease indexing time.\n\n\n\nBetter support for projects in WSL\nWe’ve improved the reliability of projects that are hosted on WSL and opened from Windows in WebStorm. In particular, support for symlinks has been added, and interaction with WSL has been switched to Hyper-V sockets, which has improved the performance of IDE interaction with WSL.\nNew features available during indexing\nWhen you open or update your project, WebStorm indexes it, making some features temporarily inaccessible. We’re working to improve this by allowing more functionality during indexing. With this update, Search Everywhere (Shift+Shift) now works for already indexed parts of the project, along with spelling and grammar checks.\nIntegrated Developer Tools\nOption to disable background pre-commit checks\nYou can now manage background checks during the commit process with a new option under Settings | Version Control | Commit | Advanced Commit Checks | Run advanced checks after a commit is done. This setting lets you decide if tests and inspections should run after making a commit. If you want to wait for these checks to complete, simply disable this option.\n\n\n\nNew Docker Compose build attributes\nWebStorm 2024.3 adds support for new Docker Compose attributes that give you better control over builds, resource management, service orchestration, and networking within Docker Compose, making development more efficient and flexible.\nImproved compatibility for Dev Container templates\nWe’ve improved the compatibility of Dev Container templates, which weren’t originally designed to operate in remote environments. Previously, Dev Container templates often included configurations that assumed local execution, leading to issues when running containers on remote Docker instances. Now, WebStorm ensures that templates that are not optimized for remote use still function correctly.\nThere are lots of new improvements and enhancements to try out in this latest WebStorm release. If you’d like a list of everything included in WebStorm 2024.3, please check out the release notes. We hope you enjoy this release. As always, please share your feedback with us and report any issues you find to our issue tracker.\nThe WebStorm team",
        "dc:creator": "David Watson",
        "content": "Our third major release of 2024 is here! In this version, you’ll find built-in database tools and SQL support, various quality enhancements, better code completion with AI Assistant, and a whole lot more. DOWNLOAD WEBSTORM 2024.3 If you only have a few minutes to explore the highlights of WebStorm 2024.3, check out our quick review [&#8230;]",
        "contentSnippet": "Our third major release of 2024 is here! In this version, you’ll find built-in database tools and SQL support, various quality enhancements, better code completion with AI Assistant, and a whole lot more. DOWNLOAD WEBSTORM 2024.3 If you only have a few minutes to explore the highlights of WebStorm 2024.3, check out our quick review […]",
        "guid": "https://blog.jetbrains.com/?post_type=webstorm&p=524492",
        "categories": [
          "news",
          "releases",
          "webstorm-2024-3"
        ],
        "isoDate": "2024-11-12T16:05:08.000Z"
      },
      {
        "creator": "Matthias Koch",
        "title": "C# Language Support in ReSharper and Rider 2024.3",
        "link": "https://blog.jetbrains.com/dotnet/2024/11/12/csharp-language-support-in-resharper-and-rider-2024-3/",
        "pubDate": "Tue, 12 Nov 2024 15:26:18 +0000",
        "content:encodedSnippet": "Our upcoming 2024.3 release marks a huge milestone for our development process but especially for our users. ReSharper and Rider 2024.3 will be simshipped along with .NET 9 and C# 13! Yes, you heard right—no more waiting an extra few weeks or using our EAP builds to take advantage of the latest and greatest C# of all time. If all goes well (🤞), you can enjoy your most loved language in your most loved IDE starting tomorrow!\nDownload Rider 2024.3 Download ReSharper 2024.3 -->Download Rider 2024.3 RC Download ReSharper 2024.3 RC\nIn this blog post, we will cover new features that have been added to our C# language support over the 2024.3 release cycle. Note that some C# 13 features have already been covered in the 2024.2 release, including escape characters and ref struct interfaces. Make sure to check out our three-part series if you’ve missed it!\nPartial Properties\nOne of the most anticipated features in C# 13 are partial properties. Previously, the concept of partial members was limited to types and methods. While partial types (classes, structs, records) mainly help organize your code into multiple parts and avoid cluttered single files, partial members allow you to define a single member (methods, properties, indexers) in any of these parts with only one part implementing it. This concept becomes particularly powerful in combination with source generators that automatically provide the correct and optimized implementation based on your member definitions:\n// User code\r\npublic partial Person : INotifyPropertyChanged\r\n{\r\n    [JsonPropertyName(\"custom-name\")]\r\n    public partial string Name { get; set; }\r\n}\r\n\r\n// Generated code\r\npartial Person\r\n{\r\n    // More attributes allowed!\r\n    public partial string Name\r\n    {\r\n        get => field;\r\n        set => SetField(ref field, value);\r\n    }\r\n    // ...\r\n}\nCopy to clipboard\n\n            \nWith ReSharper and Rider 2024.3, we are adding support for partial properties syntax and updating our code highlightings and generators. For instance, you can generate property definitions through:\nThe Implement property in another part of class quick-fix\n\n\n    \n    Implementing a partial property in another part of the type\n\n\n\n\n\nThe Generate Partial Members action from the Alt+Enter menu\n\n\n    \n    Generating multiple partial properties\n\n\n\n\n\nThe code completion after typing partial\n\n\n    \n    Code completion for missing partial properties\n\n\n\n\n\n\nYou will also find new and updated context actions to manage existing partial definitions. For instance, you can change the accessibility from one part of a member definition, and it will reflect on all the other parts:\nChanging access modifiers or partial properties\n\n\n\n\nOr you can merge partial members into one definition:\nMerging partial properties into one definition\n\n\n\n\nField Keyword\nThe long-awaited field keyword for properties is finally coming to C# 13 as a preview feature. Previously, you had to explicitly declare a backing field for every non-trivial property. With the new field keyword, you can implement semi-auto-properties by referencing the compiler-generated backing field in your custom accessor:\n// Before C# 13\r\nclass Person\r\n{\r\n    private string _name;\r\n    public string Name\r\n    {\r\n        get => _name;\r\n        set => _name = value.Trim();\r\n    }\r\n}\r\n\r\n// From C# 13\r\nclass Person\r\n{\r\n    public string Name\r\n    {\r\n        get;\r\n        set => field = value.Trim();\r\n    }\r\n}\nCopy to clipboard\n\n            \nOnce you’ve added <LangVersion>preview</LangVersion> to your project file, ReSharper and Rider will recognize the old pattern and offer to Replace with ‘field’ keyword:\nReplacing backing fields with the field keyword\n\n\n\n\nReSharper and Rider will also help you to Remove redundant bodies where the property value is only returned or set:\nRemoving redundant bodies for accessor bodies\n\n\n\n\nWith this syntax, some popular patterns involving properties become notably compact. For instance, as part of ourINotifyPropertyChanged support, we’ve updated our To property with ‘SetField’ change notification context action to implement properties more efficiently and easy to read:\nImplementing property change notifications\n\n\n\n\nAnother very common pattern is input value validation. While previously, you were forced to implement getter/setter accessors and declare a backing field, ReSharper and Rider will now allow you to use parameter-checking context actions to convert to a succinct implementation for just the set or init accessor:\nAdding null checks for properties\n\n\n\n\nTo get the most compact formatting layout, make sure to enable Place simple accessor on single line in your code style settings!\nCode style settings for property accessors\n\n\n\n\nSystem.Threading.Lock Type\nIn .NET 9, we are getting a new type System.Threading.Lock designed for thread synchronization. In C#, you can implement thread synchronization through the lock statement over any reference type object. Often, this is done with a private object field that is created solely for locking purposes:\nclass LockObject\r\n{\r\n    private readonly object _syncRoot = new();\r\n\r\n    public void M()\r\n    {\r\n        lock (_syncRoot)\r\n        {\r\n            // work\r\n        }\r\n    }\r\n}\nCopy to clipboard\n\n            \nWhile technically alright, these object fields do not tell how they’re intended to be used apart from their name. Locking is often performed over existing objects accessible to other locking types, which can have unintended side effects. Firstly, entering the block can be unnecessarily delayed from other classes that lock on the same object. Secondly, since the runtime might have to promote the lock when Object.GetHashCode() is called or thread contention happens, the following lock acquisition or release will be slightly more expensive.\nThe System.Threading.Lock was introduced to solve both of the issues described above. It clearly expresses the intent of fields used for locking, while it also avoids performance degradation. In 2024.3, we detect old field synchronization patterns and offer the replacement with the Lock type:\nConverting to System.Threading.Lock in synchronization patterns\n\n\n\n\nMerge Switch-Case Sections\nIn our last 2024.2 release, we introduced a new quick-fix Extract Common Code, which can extract common statements from if and switch statements. In the new 2024.3 release, we are extending this family of code duplication fixes with a new quick-fix to merge duplicated switch cases into a single case with broader conditions:\nMerging duplicated switch section bodies\n\n\n\n\nAs a reminder, these inspections can also hint at code that was supposed to be different but ended up unchanged after copy-pasting it. So make sure to carefully investigate each duplication before merging it!\nIDE Tooltips Colorization\nAs with every release, we not only focus on supporting new language features but also enhancing existing functionality to ensure our .NET IDEs stay aligned with modern IDE capabilities. In this release, we reviewed nearly all C# errors, warnings, and informational messages to introduce editor-like text colorization wherever possible. Overall, approximately 600 messages were upgraded, making many of the tooltips you see daily more structured and easier to read:\nColorization and cleanup of tooltips\n\n\n\n\nAnd this is just the beginning—utilizing the colorization infrastructure, we plan to enhance other error messages, particularly type conversion errors. During the refactoring, we also introduced colorization in various other editor tooltips and popups:\nColorization of classes in ‘missing references’ popup (Rider only)\n\n\n\n\n\n    \n   Colorization of classes in type hierarchy popup (ReSharper only)\n\n\n\n\nObsolete and EditorBrowsable\nOver many years, we’ve been struggling to properly support [Obsolete] and [EditorBrowsable] in our code completion. That is mainly because we cannot afford to ask each code entity in a completion list (types, members) about its traits regarding these two attributes. Caching, one of the most obvious solutions, is not well-suited for the source code domain, where code semantics can change drastically with each keypress. However, it can be effective for compiled code from assemblies, though it has the drawback of using more memory and performance on the first read.\nIn 2024.3, we’ve managed to find the sweet spot of trade-offs to support both the [Obsolete] and [EditorBrowsable] attributes while also ensuring that the IDE performance remains unaffected. Types and members marked as obsolete are now de-prioritized in the completion list sorting. This should be particularly useful for Unity developers, where some common base classes have many obsolete members. Types and members marked with EditorBrowsableState.Never are filtered out from the list by default:\nFiltering and sorting in code completion lists\n\n\n\n\nYou can change the filter behavior for the [EditorBrowsable] attribute in the code completion settings:\nCode completion settings for the [EditorBrowsable] attribute\n\n\n\n\nOperation Priority Quick-Fixes\nIn C#, certain operations, such as enum flag checks or nested ternary conditional expressions, may require extra parentheses to ensure correct priority and readability. Adding these parentheses manually can be cumbersome and disrupt your coding flow. To streamline this, we’ve introduced a Prioritize operation using parentheses quick-fix that automatically inserts any necessary parentheses in these common scenarios, allowing you to focus on more critical aspects of your code:\nPrioritizing operations using parentheses\n\n\n\n\nConclusion\n.NET 9 and C# 13 bring powerful advancements in runtime and language. ReSharper and Rider are here to complement them with the best-in-class and most productive IDE experience! 🎤👋\nAs always—make sure to use the comment section below to let us know about other features around .NET and C# you’d like to see in your developer toolbox!",
        "dc:creator": "Matthias Koch",
        "content": "Our upcoming 2024.3 release marks a huge milestone for our development process but especially for our users. ReSharper and Rider 2024.3 will be simshipped along with .NET 9 and C# 13! Yes, you heard right—no more waiting an extra few weeks or using our EAP builds to take advantage of the latest and greatest C# [&#8230;]",
        "contentSnippet": "Our upcoming 2024.3 release marks a huge milestone for our development process but especially for our users. ReSharper and Rider 2024.3 will be simshipped along with .NET 9 and C# 13! Yes, you heard right—no more waiting an extra few weeks or using our EAP builds to take advantage of the latest and greatest C# […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=525492",
        "categories": [
          "net-tools",
          "how-tos",
          "net",
          "net-9",
          "c",
          "c-13",
          "resharper",
          "rider",
          "unity"
        ],
        "isoDate": "2024-11-12T15:26:18.000Z"
      },
      {
        "creator": "Siva Katamreddy",
        "title": "How to Use Flyway for Database Migrations in Spring Boot Applications",
        "link": "https://blog.jetbrains.com/idea/2024/11/how-to-use-flyway-for-database-migrations-in-spring-boot-applications/",
        "pubDate": "Tue, 12 Nov 2024 14:44:16 +0000",
        "content:encodedSnippet": "Most software applications use SQL databases on account of their reliability, consistency, and maturity when it comes to handling structured data. The database schema evolves over time as business requirements change to add new features or update existing ones.\nObject-relational mapping (ORM) frameworks like JPA/Hibernate provide an easy way to generate a database schema based on JPA entities, which can be convenient during development. For example, while using Spring Data JPA, you can configure the property spring.jpa.hibernate.ddl-auto=update to automatically create or update tables based on JPA entities.\nHowever, automatically updating the database schema based on JPA entity changes is risky and error-prone, especially in production environments. Instead, it is recommended to use a database migration tool like Flyway.\nIn this article, you will learn about the following topics:\nWhy using a database migration tool like Flyway is a good idea\nHow Flyway works\nHow to integrate Flyway with your Spring Boot application\nHow IntelliJ IDEA Ultimate helps you to generate Flyway migration scripts easily\nPrerequisites\nTo follow along with this tutorial, Please install the following software:\nJava 17 or later \nDocker (installation instructions)\nIntelliJ IDEA\n1. Why use a database migration tool?\nWhile ORM frameworks provide the ability to generate and update database schema based on JPA entity models, automatically updating your database schema based on JPA entity changes alone is risky and error-prone, especially in production environments.\nThe following are some of the issues associated with using JPA/Hibernate ddl-auto=true to apply database changes based on entity changes:\nWhile ORM frameworks try their best to map object properties to appropriate column types, they may not always map to the expected data types.\nJPA entity updates may not result in the expected DDL changes. For example, if you rename an entity property, then instead of renaming the column name, JPA/Hibernate creates a new column, leaving the old column unchanged.\nJPA/Hibernate’s schema update mechanism doesn’t account for vendor-specific optimizations, such as custom column types, table partitions, or index types. This can limit performance tuning or lead to suboptimal database performance.\n\n\n\n\nFor these reasons, it is recommended to use a database migration tool like Flyway.\nIn this article, we will explore how to use Flyway database migrations in a Spring Boot application.\n2. Introduction to Flyway\nFlyway is an open-source database migration tool that simplifies the process of managing and versioning database schema changes. \nWith Flyway, migration scripts are stored alongside application code, following a consistent, versioned approach that allows teams to manage database changes as part of their regular development workflow. Flyway supports a wide range of databases, including MySQL, PostgreSQL, Oracle, SQL Server, and many others.\nFlyway uses a simple versioning system to manage migration scripts. Each script is assigned a unique version number (e.g. V1__init.sql, V2__create_articles_table.sql), which Flyway uses to track which scripts have been applied and which are pending.\nThe naming convention for versioned migrations is:{Prefix}{Version}{Separator}{Description}{Suffix}\nBy default, for versioned migrations, {Prefix} is V, {Separator} is __, and {Suffix} is .sql.\nSome example names for Flyway database migrations are:\nV1__Init_Setup.sql\nV2__Add_status_col.sql\nV3.1__create_url_index.sql\nV3.2__add_updated_by_column_to_bookmarks_table.sql\nV4__Add_tags_table.sql\nOnce the migration scripts are created, you can apply them to a database either using the Flyway Java API or using the Flyway Maven or Gradle plugin.\nOnce applied, Flyway keeps track of the applied migrations in a table called flyway_schema_history as shown below:\n\n\n\n\nIMPORTANT: One of the key benefits of using versioned database migrations is to make it possible to reproduce the database creation process and know when a particular change has been introduced. This being the case, once a migration is applied to the database, you should not update the contents of the applied migration file. To make any changes to the database schema, you should always create a new migration script.\n3. Run a PostgreSQL database instance using Docker\nIf you don’t have a PostgreSQL database running, you can use Docker to run a PostgreSQL database container using the following command:\ndocker run -p 5432:5432 \\\n -e POSTGRES_PASSWORD=postgres \\\n -e POSTGRES_USER=postgres \\\n -e POSTGRES_DB=postgres \\\n    postgres:17\nThis command will pull the postgres:17 Docker image from Docker Hub if it hasn’t already been pulled, start a Postgres container, and map container port 5432 to host port 5432. The username, password, and database values are passed using environment variables.\n4. Create a Spring Boot project\nLet’s start by creating a new Spring Boot project and adding the following dependencies:\nSpring Web\nValidation\nSpring Data JPA\nPostgreSQL Driver\nFlyway Migration\nNOTE: If you are new to Spring Boot, then please check out the How to Build a CRUD REST API Using Spring Boot article to get started with Spring Boot.\nOnce the project has been created and opened in the IDE, you should see the following Flyway dependencies in the build.gradle file:\nimplementation 'org.flywaydb:flyway-core'\nimplementation 'org.flywaydb:flyway-database-postgresql'\nAs we have selected PostgreSQL Driver, the flyway-database-postgresql dependency should have been added. If you are using a different database then you need to make sure the respective Flyway database dependency has been added.\nSpring Boot provides out-of-the-box support for Flyway database migrations. Once the Flyway Migrations dependency is added, you can add your Flyway migration scripts in the src/main/resources/db/migration directory. When you start the application, Spring Boot will apply the pending Flyway migrations automatically.\nLet’s configure the database connection properties in the src/main/resources/application.properties file as follows:\nspring.datasource.url=jdbc:postgresql://localhost:5432/postgres\nspring.datasource.username=postgres\nspring.datasource.password=postgres\n5. Starting with a JPA-first approach\nWhile building a Java application using JPA, we can either follow the JPA-first or Database-first approach. Let’s say we want to go with the JPA-first approach by first creating the JPA entities instead of creating the database schema.\nFirst, let’s create a JPA entity called Bookmark with the properties id, title, url, createdAt, and updatedAt as follows:\npackage com.jetbrains.bookmarks;\n\nimport jakarta.persistence.*;\nimport jakarta.validation.constraints.NotNull;\nimport jakarta.validation.constraints.Size;\nimport org.hibernate.annotations.ColumnDefault;\nimport java.time.Instant;\n\n@Entity\n@Table(name = \"bookmarks\")\npublic class Bookmark {\n    @Id\n    @GeneratedValue(strategy = GenerationType.SEQUENCE, generator = \"bookmarks_id_gen\")\n    @SequenceGenerator(name = \"bookmarks_id_gen\", sequenceName = \"bookmark_id_seq\")\n    @Column(name = \"id\", nullable = false)\n    private Long id;\n\n    @Size(max = 200)\n    @NotNull\n    @Column(name = \"title\", nullable = false, length = 200)\n    private String title;\n\n    @Size(max = 500)\n    @NotNull\n    @Column(name = \"url\", nullable = false, length = 500)\n    private String url;\n\n    @NotNull\n    @ColumnDefault(\"now()\")\n    @Column(name = \"created_at\", nullable = false)\n    private Instant createdAt;\n\n    @Column(name = \"updated_at\")\n    private Instant updatedAt;\n\n    // setters & getters\n}\nFor the Bookmark entity, we’re using the database sequence-based primary key generation strategy.\nNow, we want to create our first Flyway migration for creating the bookmarks table. We can create the Flyway migration scripts manually or use IntelliJ IDEA’s support to generate the migrations from JPA entities.\nNOTE: IntelliJ IDEA Ultimate provides support for working with Flyway that makes it easy to create Flyway migrations. If you don’t have IntelliJ IDEA Ultimate, you can use IntelliJ IDEA Community and create the Flyway migration scripts manually to follow along with this article.\n6. Creating Flyway migrations manually\nWe can manually create a file with the name V1__create_bookmarks_table.sql under the src/main/resources/db/migration directory with the following content:\nCREATE SEQUENCE IF NOT EXISTS bookmark_id_seq START WITH 1 INCREMENT BY 50;\n\nCREATE TABLE bookmarks\n(\n   id         BIGINT                                    NOT NULL,\n   title      VARCHAR(200)                              NOT NULL,\n   url        VARCHAR(500)                              NOT NULL,\n   created_at TIMESTAMP WITHOUT TIME ZONE DEFAULT NOW() NOT NULL,\n   updated_at TIMESTAMP WITHOUT TIME ZONE,\n   CONSTRAINT pk_bookmarks PRIMARY KEY (id)\n);\nWhat if you are not sure how to write DDL statements or are unfamiliar with the syntax and column data types for your database? Imagine how much easier it would be if your IDE could generate these statements for you based on the specific database you’re using. Well, IntelliJ IDEA can do exactly that!\n7. Generating Flyway migrations using IntelliJ IDEA\nInstead of creating the migration script manually, we can use IntelliJ IDEA’s support to generate the initial Flyway migration from the existing JPA entities.\nFirst, let’s connect to the PostgreSQL database using IntelliJ IDEA’s database tools support and the following connection parameters:\nHost: localhost\nPort: 5432\nUsername: postgres\nPassword: postgres\nDatabase: postgres\nYou can open the Database tool window either by clicking on the database icon on the right-hand side toolbar or by going to View | Tool Windows | Database. Create a new data source for the PostgreSQL type and click on Test Connection to verify whether the database connection can be established successfully or not.\n\n\n\n\nNow, open the Persistence tool window by going to View | Tool Windows | Persistence. Then, right-click on the main persistence unit, and select New | Flyway Init Migration.\n\n\n\n\nThen, in the Flyway Init Schema Migration dialog, select Model as the Source type, PostgreSQL as the DB type, and then click OK.\n\n\n\n\nNow, IntelliJ IDEA will inspect the existing JPA models and show you the preview of the Flyway database migration script that is going to be generated.\n\n\n\n\nCreate a File name according to the Flyway naming convention: V1__create_bookmarks_table.sql, and click Save. Now, the V1__create_bookmarks_table.sql file will be created under the src/main/resources/db/migration directory.\nNow, if you run the Spring Boot application, the first Flyway migration ( V1__create_bookmarks_table.sql) will be applied and the bookmarks table will be created.\n8. Modify JPA entities and generate new migrations\nAs we have database migrations applied, we have both the JPA entity and database schema in sync. But as the application evolves, we may need to create new entities or modify existing ones based on our requirements. In this case, we need to keep track of what specific changes we made to existing entities so that we can create a corresponding migration script for those changes. \nLet’s say we want to categorize the bookmarks and also add an additional column called status to indicate whether a bookmark is in DRAFT or PUBLISHED state.\nCreate a new JPA entity called Category as follows:\npackage com.jetbrains.bookmarks;\n\nimport jakarta.persistence.Entity;\nimport jakarta.persistence.GeneratedValue;\nimport jakarta.persistence.GenerationType;\nimport jakarta.persistence.Id;\nimport jakarta.persistence.SequenceGenerator;\nimport jakarta.persistence.Table;\n\n@Entity\n@Table(name = \"categories\")\npublic class Category {\n   @Id\n   @GeneratedValue(strategy = GenerationType.SEQUENCE, generator = \"category_id_generator\")\n   @SequenceGenerator(name = \"category_id_generator\", sequenceName = \"category_id_seq\")\n   private Long id;\n\n   private String name;\n\n   // setters and getters\n}\nUpdate our Bookmark entity to add a String type property called status with a default value of DRAFT and a ManyToOne association with Category as follows:\npackage com.jetbrains.bookmarks;\n\nimport jakarta.persistence.Column;\nimport jakarta.persistence.Entity;\nimport jakarta.persistence.FetchType;\nimport jakarta.persistence.GeneratedValue;\nimport jakarta.persistence.GenerationType;\nimport jakarta.persistence.Id;\nimport jakarta.persistence.JoinColumn;\nimport jakarta.persistence.ManyToOne;\nimport jakarta.persistence.SequenceGenerator;\nimport jakarta.persistence.Table;\nimport org.hibernate.annotations.ColumnDefault;\n\nimport java.time.Instant;\n\n@Entity\n@Table(name = \"bookmarks\")\npublic class Bookmark {\n   //...\n   @ColumnDefault(\"'DRAFT'\")\n   @Column(name = \"status\", nullable = false)\n   private String status;\n  \n   @ManyToOne(fetch = FetchType.LAZY)\n   @JoinColumn(name = \"category_id\")\n   private Category category;\n\n   // setters and getters\n}\nTo make the corresponding changes to the database schema, we need to create the second Flyway migration script.\nBut, manually keeping track of the changes made to JPA entities and creating the migrations is tedious and error-prone.\nSo, instead of creating the script manually, we can use IntelliJ IDEA to generate the Flyway migration based on the differences between JPA entities and the existing database schema.\nFrom the Persistence tool window, right-click on the main persistence unit, and select New | Flyway Migration. Then in the Flyway Diff Migration dialog, select Model as the Source, DB as Target, and then click OK.\nNow, IntelliJ IDEA will inspect the JPA models and the existing database schema and show you a preview of the Flyway database migration script that is going to be generated.\nGive the File name as V2__add_status_category_to_bookmarks.sql, and click Save.\n\n\n\n\nNow, this V2__add_status_category_to_bookmarks.sql file will be created under the src/main/resources/db/migration directory with the following content:\nCREATE SEQUENCE IF NOT EXISTS category_id_seq START WITH 1 INCREMENT BY 50;\n\nCREATE TABLE categories\n(\n   id   BIGINT NOT NULL,\n   name VARCHAR(255),\n   CONSTRAINT pk_categories PRIMARY KEY (id)\n);\n\nALTER TABLE bookmarks\n   ADD category_id BIGINT;\n\nALTER TABLE bookmarks\n   ADD status VARCHAR(255) DEFAULT 'DRAFT';\n\nALTER TABLE bookmarks\n   ALTER COLUMN status SET NOT NULL;\n\nALTER TABLE bookmarks\n   ADD CONSTRAINT FK_ARTICLES_ON_CATEGORY FOREIGN KEY (category_id) REFERENCES categories (id);\nAs you can see, the second Flyway migration script generated contains the SQL script to create a categories table, as well as add a category_id foreign key and a status column with a default value of DRAFT to the bookmarks table.\nIf you restart the Spring Boot application and check the database, the categories table should have been created and the category_id and status columns should have been added to the bookmarks table.\n9. Update existing JPA entities from database schema changes\nSo far we have seen how to generate Flyway migrations from JPA entities. What if we want to create a Flyway migration script manually, apply it to the database, and then update the JPA entities according to those database schema changes?\nTo do this, let’s create a third Flyway migration script with file name V3__add_published_at_col_to_bookmarks.sql and the following content:\nALTER TABLE bookmarks ADD published_at timestamp;\nWe are now adding a new column called published_at to the bookmarks table.\nRestart the Spring Boot application and ensure that the published_at column has been added to the bookmarks table.\nTo keep both the database schema and JPA entities in sync, we need to add a publishedAt property to the Bookmark entity. Instead of making those changes manually, we can use IntelliJ IDEA’s feature to add or update entity attributes from the database.\nIn the Database tools window, right-click on the bookmarks table and select Create Entity Attributes from DB. The Entity Attributes from DB dialog will show the columns that have not yet been added to the Bookmark entity. Select the relevant columns and click OK.\n\n\n\n\nThe Bookmark entity will then be updated to add the publishedAt property as follows:\npackage com.jetbrains.bookmarks;\n\nimport jakarta.persistence.Column;\nimport jakarta.persistence.Entity;\nimport jakarta.persistence.FetchType;\nimport jakarta.persistence.GeneratedValue;\nimport jakarta.persistence.GenerationType;\nimport jakarta.persistence.Id;\nimport jakarta.persistence.JoinColumn;\nimport jakarta.persistence.ManyToOne;\nimport jakarta.persistence.SequenceGenerator;\nimport jakarta.persistence.Table;\nimport org.hibernate.annotations.ColumnDefault;\n\nimport java.time.Instant;\n\n\n@Entity\n@Table(name = \"bookmarks\")\npublic class Bookmark {\n   //...\n  \n   @Column(name = \"published_at\")\n   private Instant publishedAt;\n\n   // setters and getters\n}\nWhile you can create Flyway migrations manually, IntelliJ IDEA helps you create them automatically from JPA entity changes. What’s more, it also allows us to update the JPA entities from database changes more easily. This significantly reduces the amount of manual coding required, preventing potential errors and improving developer productivity.\nSummary\nIn this article, we have learned how to use Flyway for managing database migrations in a Spring Boot application. While using the JPA-first approach for building JPA-based applications, IntelliJ IDEA helps in creating Flyway migrations from JPA entities. As the application evolves we can update JPA entities and generate new Flyway migrations based on the differences between JPA entities and current database schema. Finally, we have seen how we can update JPA entities directly from database changes.\nTo learn more about Flyway, visit the official documentation.",
        "dc:creator": "Siva Katamreddy",
        "content": "Most software applications use SQL databases on account of their reliability, consistency, and maturity when it comes to handling structured data. The database schema evolves over time as business requirements change to add new features or update existing ones. Object-relational mapping (ORM) frameworks like JPA/Hibernate provide an easy way to generate a database schema based [&#8230;]",
        "contentSnippet": "Most software applications use SQL databases on account of their reliability, consistency, and maturity when it comes to handling structured data. The database schema evolves over time as business requirements change to add new features or update existing ones. Object-relational mapping (ORM) frameworks like JPA/Hibernate provide an easy way to generate a database schema based […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=523772",
        "categories": [
          "idea",
          "java",
          "tutorials",
          "flyway",
          "hibernate",
          "intellij-idea",
          "jpa",
          "spring",
          "spring-boot",
          "spring-data-jpa",
          "tutorial"
        ],
        "isoDate": "2024-11-12T14:44:16.000Z"
      },
      {
        "creator": "Svetlana Novikova",
        "title": "Writing Docs With Code Samples? Try Out the New Writerside EAP Release",
        "link": "https://blog.jetbrains.com/writerside/2024/11/writing-docs-with-code-samples-try-out-the-new-writerside-eap-release/",
        "pubDate": "Mon, 11 Nov 2024 15:11:57 +0000",
        "content:encodedSnippet": "Each Early Access release is designed to make writing documentation easier and more enjoyable. This update is based on your feedback and focuses on improving code blocks, but there is more! Thank you all for sharing your ideas. It’s a pleasure to keep improving our product for you.\nDownload Writerside\n                                    \nCode samples in documentation: Stick to the basics\nWhen I first started thinking about presenting code samples in technical documentation, the initial idea was about advanced features, like interactivity, robust linking between text and code, and sophisticated presentation options, such as substituting placeholders on the fly. \nHowever, the recent Unconference session at the Write The Docs Atlantic conference revealed something surprising – the most pressing concerns regarding code blocks weren’t about cutting-edge features, but about getting the fundamentals right.\n\n\n\n\nReality check: Know your audience\nAt the conference, the discussion quickly shifted from “How can we make our code samples more interactive?” to “What does our audience actually need?” This pivot highlighted a fundamental truth in technical writing: understanding your readers’ goals is more important than implementing cutting-edge features.\nThe 4 key insights regarding code blocks\nContext and purpose\nIt’s not about “short” versus “long” code samples – what matters is context and purpose. Tutorials need complete, real-world examples. API docs benefit from focused code blocks that demonstrate specific functionality. \nCopy-paste is the reality \nThere’s no way around it – regardless of experience level, people consistently copy and paste code samples. We can’t fight it, but we can use code blocks that are complete enough to work even when directly copy-pasted, or that indicate what to do to make them work. \nAs Chris Chinchilla points out in “Technical Writing for Software Development”, developers frequently copy and paste a series of code snippets into an editor because it’s a fundamental part of learning.\n\n\n\n\n\nDifferent strokes for different folks\nCode samples serve as learning material, and, like any other learning resource, one size does not fit all – different learning styles call for different examples. Beginners might need step-by-step breakdowns, while expert developers might prefer more comprehensive examples that they can tweak to fit their own needs without much hassle.\nComplementary tools\nSwagger specs and Postman collections are great companions to documentation, but not replacements. They help users move from learning to doing, once the concepts are clear.\nCode block maintenance: The hidden challenge\nAs products evolve, keeping code samples up to date is crucial – and challenging.\nHow can you efficiently update examples across documentation?\nWhen should you remove or deprecate outdated examples?\nWhat are the best strategies for version management?\nThese challenges aren’t new to us at JetBrains. We’ve explored several automation strategies in our previous post about keeping documentation up to date. Building on those insights, we’re now focusing on code sample maintenance.\nChris Chinchilla, in his recent book, outlines two approaches to documentation testing:\nManual testing: Writers regularly verify examples from a newcomer’s perspective.\nAutomated testing: Tests are integrated into CI/CD pipelines for continuous verification.\n\n\n\n\nAnother approach, called Docs as Tests, is being actively explored by Manny Silva. We highly recommend checking out both Chris’s book and Manny’s project for further inspiration.\nAs we continue to evolve Writerside’s code sample capabilities, we’re keeping this lesson in mind: the best features aren’t always the flashiest – they’re the ones that help writers meet their readers’ needs, whoever those readers may be.\nNew in Writerside EAP 9: Code block enhancements\nThe latest Writerside release focuses on practical improvements that directly address common challenges with code blocks:\nExternal code block references provides a single source of truth for code samples, reducing maintenance overhead.\n\n\n\n\nEnhanced language support ensures accurate syntax highlighting across more programming languages.\n\n\n\n\nNative support for .puml and .mermaid files streamlines the integration of diagrams with code samples.\n\n\n\n\nWorking with code samples? Help us stay up to date\nWe’ve learned that the best documentation improvements come from understanding real-world needs. Have you faced challenges with code samples in documentation? Which features make a difference in your daily work? \nWhether you’re a technical writer crafting examples or a software developer, we’d love to hear your perspective. Join the conversation in our Slack community and help shape the future of code samples in Writerside.\nJoin our Slack community 🤓\n                                    \nBut wait, there are more features and improvements!\nWriterside EAP 9 offers more than just improved code blocks:\nPDF CLI: Our builder can now produce PDFs alongside the web output.\nThe Good Docs integration: We’ve improved our recent integration of The Good Docs project templates.\nAPI documentation generation: You can now generate API docs as a new instance.\nTable of contents: This long-awaited feature provides a table of contents for topics with API docs.\nMulti-specification support: Generate documentation from multiple specification files.\n\n\n\n\n👉 Read the full release notes\nWe hope you like the new features. If you have feedback or ideas on how to make Writerside better, we’d love to hear from you!\nJoin our Slack community\n                                                                👉 Download Writerside 👈",
        "dc:creator": "Svetlana Novikova",
        "content": "Each Early Access release is designed to make writing documentation easier and more enjoyable. This update is based on your feedback and focuses on improving code blocks, but there is more! Thank you all for sharing your ideas. It’s a pleasure to keep improving our product for you. Code samples in documentation: Stick to the [&#8230;]",
        "contentSnippet": "Each Early Access release is designed to make writing documentation easier and more enjoyable. This update is based on your feedback and focuses on improving code blocks, but there is more! Thank you all for sharing your ideas. It’s a pleasure to keep improving our product for you. Code samples in documentation: Stick to the […]",
        "guid": "https://blog.jetbrains.com/?post_type=writerside&p=524824",
        "categories": [
          "eap",
          "news",
          "writerside"
        ],
        "isoDate": "2024-11-11T15:11:57.000Z"
      },
      {
        "creator": "Ilnur Galimov",
        "title": "Boosting Your Coding Projects With JetBrains AI Assistant: My Journey to Build a Flask Web App",
        "link": "https://blog.jetbrains.com/ai/2024/11/boosting-your-coding-projects-with-jetbrains-ai-assistant/",
        "pubDate": "Mon, 11 Nov 2024 13:22:34 +0000",
        "content:encodedSnippet": "TL;DR:\nIn this post, I walk through the process of enhancing a chatbot project from Hyperskill by adding a web interface with Flask, JavaScript, and HTML. I tried out JetBrains AI Assistant and documented how it helped me with common coding tasks like installing frameworks, debugging, and generating code snippets, streamlining my development workflow. \nFrom CLI to web UI: Exploring generative AI with Hyperskill\nWhile searching for new generative AI coding challenges, I came across the Simple Python CLI Chat project on Hyperskill, which teaches the basics of working with a generative AI API through the process of creating a basic chat assistant. The project was engaging, but I wanted to add an extra challenge by building a web interface to interact with the chat assistant in a more user-friendly way. After a bit of research, I decided to go with a setup that used Flask, JavaScript, and HTML. I already had experience with Flask from Hyperskill’s Python Backend Developer track, but my JavaScript knowledge from university was a bit rusty – that motivated me to look for tools that could help fill in the gaps.\n\n\n\n\nGetting started with JetBrains AI Assistant\nA colleague shared his experience using JetBrains AI Assistant to convert code from Kotlin to Python. Inspired, I decided to try it out myself and document my experience here. First, I cloned my Hyperskill project from GitHub and installed the JetBrains AI Assistant plugin through the AI Assistant tab. Installation went smoothly, and after restarting my IDE, I was ready to dive in.\n\n\n\n\nMultilingual feature test: Trying out Dutch\nAs soon as I started, AI Assistant asked if I wanted to receive responses in a custom language. Living and working in the Netherlands, I’m currently learning Dutch, so I switched the response language to Dutch to test out the multilingual capabilities. \nLong story short: it worked flawlessly! I later switched back to English, as my Dutch still has some room for improvement, but the feature left an impression. It made me think how useful it could be in multilingual work environments, especially here in Amsterdam, where developers often juggle multiple languages. With setup complete, I was ready to dive into my project.\n\n\n\n\n\n\n\n\nEasy Flask installation with JetBrains AI\nTo test out AI Assistant, I asked it how to install Flask. It recommended running the pip install Flask command, which I could execute directly in the terminal with a single click on Run Snippet. This quick execution feature saved time and was super convenient.\n\n\n\n\nBuilding the frontend: JavaScript and HTML\nWith Flask installed, I moved on to creating the frontend. I started with a JavaScript file for handling user inputs, server interactions, and keeping the UI updated, and an HTML file for structuring a simple chat interface. But before diving into these details, I had to transform my Hyperskill project into a working Flask app to act as a basic web server.\nSetting up the Flask server for AI communication\nTo start, I initialized a basic Flask app and created a route to handle POST requests from the chat interface. This route captured the user’s message, processed it, and returned a JSON response containing the AI’s reply. I also added error handling to ensure the server could respond with clear error messages. \nDebugging and fixing errors with AI Assistant\nAfter setting up the basic server, I ran it locally to make sure everything worked as expected. I encountered an error, so I used AI Assistant’s Explain with AI option, and within seconds, it suggested a solution, including a code snippet. By clicking Insert Snippet at Caret, I applied the fix, and my server finally started up! With this first hurdle cleared, I was able to move on to refining the JavaScript and HTML files.\n\n\n\n\n\n\n\n\n\n\n\n\nCreating a dynamic chat with the real-time Fetch API\nIn the JavaScript file, I wanted to ensure that messages could be fetched and displayed in real time, without the need for page reloads. Back in university, I would have achieved this with AJAX. But since that was nearly a decade ago, this time I opted for the more modern Fetch API. As I typed, AI Assistant offered code completion suggestions, which were especially useful for building a new file from scratch.\n\n\n\n\n\n\n\n\nLetting AI generate HTML: A little experiment\nWhen it came time to set up the HTML layout, I decided to let AI Assistant generate the initial structure for me. The result needed tweaking (for example, the Send button wasn’t functional and the layout wasn’t ideal), but it saved me a lot of time. While AI is great for generating code, it’s important to have enough knowledge to adjust and refine the output.\n\n\n\n\n\n\n\n\nLaunching the web app and… getting hungry!\nAfter some final adjustments, my web app was ready. I launched it, and everything worked seamlessly! But by this point, I was starving. As a lighthearted test, I asked the chatbot to give me a recipe for my favorite pasta, cacio e pepe – and it delivered! Having a functional AI chatbot and a pasta recipe felt like a win-win.\n\n\n\n\nCommitting code with AI’s help\nWith my app up and running, it was time to commit and push my changes to GitHub. AI Assistant even helped generate a commit message. While it was a bit too detailed, I kept the essential parts, which added a nice finishing touch to my coding session.\n\n\n\n\nDiscovering AI Assistant’s full range of features\nCurious to see what else the assistant could do, I explored the Options I Discover Features section. There’s a wealth of capabilities here to streamline the coding process, from multi-language support to debugging assistance and documentation generation.\n\n\n\n\nFinal thoughts: AI as a coding companion\nJetBrains AI Assistant proved to be a powerful tool throughout this project. It helped me accomplish key tasks like installing frameworks, troubleshooting server errors, generating code snippets, and even suggesting commit messages – all of which streamlined my workflow and saved time. Experimenting with its multilingual support also gave me insight into its flexibility for developers in diverse work environments.\nFor developers in multilingual or fast-paced settings, tools like AI Assistant can make a big difference. However, its effectiveness ultimately increases when paired with foundational coding knowledge. My advice to new programmers is this: try fixing errors independently before relying on AI. Doing so will sharpen your problem-solving skills and help you get the most out of AI assistance when you need it.\nThanks for joining me on this coding journey! Hopefully, this post inspires you to give JetBrains AI Assistant a try in your own projects. Explore its features, experiment, and make coding a little more fun. And don’t forget to reward yourself with some delicious pasta afterward!\nTill next time!",
        "dc:creator": "Ilnur Galimov",
        "content": "TL;DR: In this post, I walk through the process of enhancing a chatbot project from Hyperskill by adding a web interface with Flask, JavaScript, and HTML. I tried out JetBrains AI Assistant and documented how it helped me with common coding tasks like installing frameworks, debugging, and generating code snippets, streamlining my development workflow.&#160; From [&#8230;]",
        "contentSnippet": "TL;DR: In this post, I walk through the process of enhancing a chatbot project from Hyperskill by adding a web interface with Flask, JavaScript, and HTML. I tried out JetBrains AI Assistant and documented how it helped me with common coding tasks like installing frameworks, debugging, and generating code snippets, streamlining my development workflow.  From […]",
        "guid": "https://blog.jetbrains.com/?post_type=ai&p=523885",
        "categories": [
          "jetbrains-ai",
          "tutorials",
          "ai-assistance",
          "ai-assistant"
        ],
        "isoDate": "2024-11-11T13:22:34.000Z"
      },
      {
        "creator": "Matt Eikamp",
        "title": "Default Bundled Plugins in Fleet",
        "link": "https://blog.jetbrains.com/fleet/2024/11/default-bundled-plugins-in-fleet/",
        "pubDate": "Fri, 08 Nov 2024 14:06:26 +0000",
        "content:encodedSnippet": "Recently, we announced the public rollout of the Fleet Plugins SDK – a step that finally allows plugins to be created and shared among the Fleet community at large.\nBelieve it or not, this did not mark the very beginning of extensibility in Fleet. Fleet has always featured a variety of bundled plugins (currently upwards of 50!) to streamline your coding process.\nWe designed Fleet to be minimalist and focus on the essentials of programming so that you can avoid extension fatigue. Does this mean Fleet users should shy away from plugins? Of course not! We’re still working on finalizing Fleet’s extensibility program, but you can already make use of its existing bundled plugins.\nThese plugins can be selectively added to and removed from your Fleet workspace, or even marked as required for a given workspace. Here’s a quick rundown of how you can manage bundled plugins in Fleet.\nFleet’s default set of bundled plugins can be roughly broken down into the following categories:\nIntegrated tools and frameworks\nAI features\nLanguage-specific support\nCustomization\nRemote development\nIntegrated Tools and Frameworks\nFleet comes bundled with plugins supporting a plethora of integrated tools and frameworks, including Amper, Docker, Git, Gradle, Maven, and a whole host of others. Here’s the full list at a glance:\n\n\n\n\nWorthy of special mention is Amper, a JetBrains tool designed to provide a smoother experience with project configuration and toolability when working with Kotlin Multiplatform.\nMany of these plugins will require you to have Smart Mode running, but there are some (such as Prettier) that you can use even when running Fleet as a lightweight text editor.\nPlugins Supporting AI Features\nHere’s a quick glance at all the languages for which AI plugins are offered in Fleet by default. Keep in mind that this is just the beginning – we’ve got plenty of additional features on the way for even more languages.\n\n\n\n\nThis is in addition to Fleet’s support for AI Completion and Grazie – JetBrains’ AI writing companion for smoothing out your grammar and style.\nIf you want to give Fleet’s AI features a try, go ahead and request an AI Pro trial (free of charge for seven days).\nLanguage Support\nFrom a language standpoint, Fleet has always been highly versatile. It supports most major languages straight out of the box – no matter how simple or in-depth your project may be. Fleet analyzes your code to automatically detect your project configuration, including which language you’re coding in.\nTo get the most out of each language when Smart Mode is enabled (such as code completion, error detection, documentation, code reformatting, and navigation to usages and definitions), you can make use of pre-installed plugins for any the following languages:\n\n\n\n\nCustomization\nThe Fleet user experience is becoming ever more customizable. Members of the Fleet community can publish custom color theme plugins, but there are a few bundled plugins for this as well. The Grey Theme comes pre-installed, for instance, allowing you to tweak the look and feel of Fleet.\nFleet’s potential for customization does not stop at mere aesthetics. If you happen to be migrating from VSCode, the VSCode Keymap plugin will let you stick to the shortcuts you’re used to. As of the 1.41 release, Fleet gives you even more keymap options, including IntelliJ IDEA Classic, Emacs, Sublime Text, and Eclipse.\nThose who want to take things a step further with custom language support can use the TextMate plugin. This plugin makes it possible to add TextMate bundles – for example, in cases where you need code highlighting while Smart Mode is off or while coding in a language that isn’t supported in Fleet.\nRemote Development\nFleet has built-in support for remote development. When you’re on the go, you can use your local machine as a thin client while letting a more powerful machine at your home or office handle more resource-intensive tasks.\nFleet provides this out of the box, in contrast to VS Code, which requires you to install and configure extensions before you can use remote development features.\nStay tuned for more updates as we continue to add more to Fleet’s expandability program.",
        "dc:creator": "Matt Eikamp",
        "content": "Recently, we announced the public rollout of the Fleet Plugins SDK – a step that finally allows plugins to be created and shared among the Fleet community at large. Believe it or not, this did not mark the very beginning of extensibility in Fleet. Fleet has always featured a variety of bundled plugins (currently upwards [&#8230;]",
        "contentSnippet": "Recently, we announced the public rollout of the Fleet Plugins SDK – a step that finally allows plugins to be created and shared among the Fleet community at large. Believe it or not, this did not mark the very beginning of extensibility in Fleet. Fleet has always featured a variety of bundled plugins (currently upwards […]",
        "guid": "https://blog.jetbrains.com/?post_type=fleet&p=524223",
        "categories": [
          "plugins"
        ],
        "isoDate": "2024-11-08T14:06:26.000Z"
      },
      {
        "creator": "Maria Kosukhina",
        "title": "IntelliJ IDEA 2024.3 Release Candidate Is Out! ",
        "link": "https://blog.jetbrains.com/idea/2024/11/intellij-idea-2024-3-release-candidate/",
        "pubDate": "Fri, 08 Nov 2024 00:54:48 +0000",
        "content:encodedSnippet": "The IntelliJ IDEA 2024.3 Release Candidate is here! \nYou can download the latest build from our website, from the free Toolbox App, or by using snaps for Ubuntu.\n\n\n\n\nTo use this build, you need to have an active IntelliJ IDEA Ultimate subscription.\nWith the big release day approaching fast, our team is putting the finishing touches on the new version of the IDE. We’d like to extend a huge thank you to everyone who participated in the Early Access Program and shared feedback – your input truly makes a difference!\nFor a closer look at what’s expected in the upcoming release, check out our 2024.3 EAP blog posts. For the changes introduced in the latest build, check out the release notes. \nIf you find any bugs, please let us know through our issue tracker.\nStay tuned – IntelliJ IDEA 2024.3 will be officially out soon!\nHappy developing!",
        "dc:creator": "Maria Kosukhina",
        "content": "The IntelliJ IDEA 2024.3 Release Candidate is here!&#160; You can download the latest build from our website, from the free Toolbox App, or by using snaps for Ubuntu. To use this build, you need to have an active IntelliJ IDEA Ultimate subscription. With the big release day approaching fast, our team is putting the finishing [&#8230;]",
        "contentSnippet": "The IntelliJ IDEA 2024.3 Release Candidate is here!  You can download the latest build from our website, from the free Toolbox App, or by using snaps for Ubuntu. To use this build, you need to have an active IntelliJ IDEA Ultimate subscription. With the big release day approaching fast, our team is putting the finishing […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=523370",
        "categories": [
          "eap",
          "intellij-idea",
          "intellij-idea-2024-3"
        ],
        "isoDate": "2024-11-08T00:54:48.000Z"
      },
      {
        "creator": "Sasha Ivanova",
        "title": "The Rider 2024.3 Release Candidate Is Now Available",
        "link": "https://blog.jetbrains.com/dotnet/2024/11/07/the-rider-2024-3-rc/",
        "pubDate": "Thu, 07 Nov 2024 15:52:10 +0000",
        "content:encodedSnippet": "The next big release for Rider is just around the corner! If you’re eager to get a sneak peek, you can download the Release Candidate version of Rider 2024.3 from our website right now. \nDownload Rider 2024.3 RC\n                                                    \nHere are the feature highlights of the Rider 2024.3 RC build:\nSupport for .NET 9, including full support for C# 13 features like params collections, partial properties, and the field keyword (preview feature).\nWindows Forms Designer for .NET projects targeting .NET 6.0 and newer.\nAbility to freeze and unfreeze individual threads during debugging.\nSupport for running and debugging Unreal Engine games on consoles.\nBetter debugging experience with IL2CPP builds in Unity.\nImproved Hot Reload for Godot.\nSupport for multiline TODO comments.\nTooltip colorization for improved readability.\nInline AI prompts and easier context management with customizable AI chat model options in AI Assistant.\nRe-engineered code cleanup engine, enhanced naming conventions, and more flexible code formatting options.\nUpdated F# support, including type hints and improved code completion.\nEnhanced version control with branch name display on the Welcome screen and an option to disable background pre-commit checks.\nRemote development is now out of Beta, with stable support for core workflows.\nCleaner search results for web projects with Find in Files, improved component navigation for Vue, Svelte, and Astro, and inline color previews for Tailwind CSS classes.\nAI-powered text-to-SQL diffing and SQL error handling.\nIL Viewer support for assembly manifests and support for primary constructors in the decompiler.\nIf you encounter any issues when using the Rider 2024.3 Release Candidate, please let us know via our issue tracker.\nJust a reminder: There are a few ways you can download and install the latest preview build:\nGet it from our website.\nUse the Toolbox App.\nInstall this snap package from the Snapcraft store if using a compatible Linux distribution.\nWhich features and updates are you most excited about? Let us know in the comments below, or reach out to us on X.",
        "dc:creator": "Sasha Ivanova",
        "content": "The next big release for Rider is just around the corner! If you&#8217;re eager to get a sneak peek, you can download the Release Candidate version of Rider 2024.3 from our website right now.&#160; Here are the feature highlights of the Rider 2024.3 RC build: If you encounter any issues when using the Rider 2024.3 [&#8230;]",
        "contentSnippet": "The next big release for Rider is just around the corner! If you’re eager to get a sneak peek, you can download the Release Candidate version of Rider 2024.3 from our website right now.  Here are the feature highlights of the Rider 2024.3 RC build: If you encounter any issues when using the Rider 2024.3 […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=523303",
        "categories": [
          "news",
          "releases",
          "rider",
          "2024-3",
          "release-candidate"
        ],
        "isoDate": "2024-11-07T15:52:10.000Z"
      },
      {
        "creator": "Sasha Ivanova",
        "title": "The ReSharper and the .NET Tools 2024.3 Release Candidates Are Now Available",
        "link": "https://blog.jetbrains.com/dotnet/2024/11/07/rsrp-net-tools-2024-3-rc/",
        "pubDate": "Thu, 07 Nov 2024 15:52:07 +0000",
        "content:encodedSnippet": "Get a preview of all the latest features and improvements set to be shipped with the next major ReSharper and .NET tools releases by downloading the Release Candidate builds that have just landed.\nDownload ReSharper 2024.3\n                                                    \n\n\n\n\nHere are the lists of major improvements in each of the new builds:\nThe ReSharper 2024.3 Release Candidate\nComprehensive support for C# 13, including params collections, partial properties, a new lock type, and the field keyword (preview feature).\nEnhanced code cleanup and flexible formatting options.\nMore precise naming conventions for local functions and methods.\nSupport for multiline To-do comments for organized in-code task management.\nTooltip colorization for improved readability across C# messages.\nIL Viewer support for assembly manifests in the decompiler.\nSupport for primary constructors in decompiled code.\nThe ReSharper C++ 2024.3 Release Candidate\nMove to Folder refactoring for C++ files.\nSupport for new C++23, C23, and GNU language features.\nOptimized memory footprint in large solutions.\nImproved interoperability with Clang tooling.\nVarious code assistance features for Unreal Engine developers.\nBetter support for XML documentation comments.\nThe dotMemory 2024.3 Release Candidate\nUnified UI across all operating systems for a consistent experience.\nReintroduced Creation Stack Trace and Back Traces views for memory issue identification.\nNew Icicle chart for dominator visualization and Sunburst chart for the Call Tree view on all OS.\nThe dotTrace 2024.3 Release Candidate\nUndo/Redo actions and filter history support for easier navigation through profiling sessions.\nThe dotCover 2024.3 Release Candidate\nStability improvements and bug fixes.\nThe dotPeek 2024.3 Release Candidate\nIL Viewer support for assembly manifests in the decompiler.\nSupport for primary constructors in decompiled code.\n\n\n\n\n\n\n\n    \nhttps://www.jetbrains.com/resharper/nextversion/\n                                                    \nJust a reminder that you can download the latest build right now from the ReSharper 2024.3 EAP page or install it via the JetBrains Toolbox App.\nIt’s not too late to share your feedback on the newest features! Our developers are still putting the final touches on the upcoming release. Tell us what you think in the comments below or by reaching out to us on X.",
        "dc:creator": "Sasha Ivanova",
        "content": "Get a preview of all the latest features and improvements set to be shipped with the next major ReSharper and .NET tools releases by downloading the Release Candidate builds that have just landed. Here are the lists of major improvements in each of the new builds: The ReSharper 2024.3 Release Candidate The ReSharper C++ 2024.3 [&#8230;]",
        "contentSnippet": "Get a preview of all the latest features and improvements set to be shipped with the next major ReSharper and .NET tools releases by downloading the Release Candidate builds that have just landed. Here are the lists of major improvements in each of the new builds: The ReSharper 2024.3 Release Candidate The ReSharper C++ 2024.3 […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=523305",
        "categories": [
          "net-tools",
          "news",
          "releases",
          "resharpercplusplus",
          "resharper",
          "2024-3",
          "resharper-c"
        ],
        "isoDate": "2024-11-07T15:52:07.000Z"
      },
      {
        "creator": "Oleg Zinovyev",
        "title": "CLion 2024.3 Goes Beta With Enhanced CLion Nova, Debug Servers, and OpenCV Image Viewer",
        "link": "https://blog.jetbrains.com/clion/2024/11/clion-2024-3-beta/",
        "pubDate": "Wed, 06 Nov 2024 19:32:04 +0000",
        "content:encodedSnippet": "The Beta version of CLion 2024.3 is now available with key improvements and changes announced for the upcoming release. \n\n\n\n\nYou can download build 243.21565.87 from the link below, via the Toolbox App, or as a snap package if you’re using Ubuntu.\nDOWNLOAD CLION 2024.3 BETA\nRead the full release notes on YouTrack. Below is a brief overview of the major features and bug fixes that will be included in CLion 2024.3 and are already available in Beta.\nThe key features\nThroughout the 2024.3 EAP, we’ve added a variety of features for CLion Nova, embedded\ndevelopment, debugging, and more. Here are the most important ones.\nCLion Nova\nSome editor-related features, such as the call hierarchy, the gutter icon for recursive calls, and the Quick Definition popup have improved the user experience when working with CLion Nova.\nThe IDE frontend and backend improvements have significantly reduced CLion Nova’s memory footprint. This is particularly evident when handling large projects like Chromium.\nPredefined code styles from other projects allow you to choose from LLVM, Google, Qt, GNU, and more.\nEmbedded development\nThe Debug Servers configuration option helps you streamline the process of configuring debugging for embedded and remote development.\nSupport for debugging Zephyr West applications makes it easy to configure and run West debugging sessions directly in the IDE.\nEditable peripheral register values allow you to test different configurations and device states during debugging sessions without recompiling your source code or reloading your application or board.\nCLion’s static analysis toolset now includes a significant number of MISRA C++: 2023 checks, offering recommendations for using C++17 in safety-critical systems.\nDebugger\nWith the OpenCV image viewer, you can now view a two-dimensional OpenCV array as an image while debugging. Such an image is displayed in a separate dialog with various editing options.\nThe ability to attach the debugger to an unstarted process is helpful when you need to debug an executable launched by a third-party program or a script.\nYou can now view strings with JSON, XML, or HTML data formatted according to their code style directly in the debugger.\nOther features\nUpdated cloud completion powered by JetBrains AI Assistant now offers a wider range of usage scenarios and improved multiline code suggestions.\nProject status notifications have been moved from the top of the editor to a new widget in the status bar, making them less distracting.\nIf you’re just starting with CLion, you’ll notice the improved onboarding tips, which give you a clearer picture of the IDE’s capabilities right from the start.\nThe key bug fixes\nHere are the major bug fixes that we’ve included in CLion 2024.3 Beta:\nWhen a board is not defined for a new Zephyr West project or a West executable path is incorrect, CLion now warns you of the problem and offers to fix it. You’ll get a link that will take you to the corresponding section of your project settings, where you can define the board or path.\nThe Refresh button in the Call Hierarchy tool window now works as intended when the actual call hierarchy in the source code has been changed.\nAI Assistant again highlights C/C++ code in the chat when you ask it to explain code or suggest a refactoring, for example.\n\n\n\n\nDOWNLOAD CLION 2024.3 BETA\nYour CLion team\nJetBrains\nThe Drive to Develop",
        "dc:creator": "Oleg Zinovyev",
        "content": "The Beta version of CLion 2024.3 is now available with key improvements and changes announced for the upcoming release. You can download build 243.21565.87 from the link below, via the Toolbox App, or as a snap package if you’re using Ubuntu. DOWNLOAD CLION 2024.3 BETA Read the full release notes on YouTrack. Below is a [&#8230;]",
        "contentSnippet": "The Beta version of CLion 2024.3 is now available with key improvements and changes announced for the upcoming release. You can download build 243.21565.87 from the link below, via the Toolbox App, or as a snap package if you’re using Ubuntu. DOWNLOAD CLION 2024.3 BETA Read the full release notes on YouTrack. Below is a […]",
        "guid": "https://blog.jetbrains.com/?post_type=clion&p=522337",
        "categories": [
          "eap",
          "news",
          "ai-assistant",
          "clionnova",
          "debugger",
          "embedded",
          "zephyr-west"
        ],
        "isoDate": "2024-11-06T19:32:04.000Z"
      },
      {
        "creator": "Vladislav Grinin",
        "title": "Updates on Unreal Engine Support in TeamCity: UGS Integration and Open-Sourcing the Plugin",
        "link": "https://blog.jetbrains.com/teamcity/2024/11/unreal-engine-plugin-ugs-integration-and-open-sourcing/",
        "pubDate": "Wed, 06 Nov 2024 14:44:18 +0000",
        "content:encodedSnippet": "We’ve got a few exciting updates about the Unreal Engine plugin announced in the previous blog post. \nTL;DR – we’re adding Unreal Game Sync (UGS) integration and open-sourcing the plugin. These updates are all about making the CI/CD experience smoother for Unreal Engine devs and getting the community more involved.\nUGS\nBefore diving in, let’s quickly go over what Unreal Game Sync (UGS) is for anyone who might not be familiar with it or could use a refresher. In essence, UGS is a lightweight UI for Perforce. Typically, you need to build it from source to get started, and while its graphical client is a WinForms application available only on Windows, there is a command-line interface (CLI) version for other platforms. UGS has been around for a while and is widely used by game studios working with Unreal Engine as a collaboration tool.\nFrom a CI/CD perspective, UGS provides valuable insights into a project’s status (if properly set up), such as build statuses, the ability to flag specific changelists as problematic, and more. To give a better overview, here’s a rough diagram of the components involved:\n\n\n\n\nThere are quite a few components here, with the central one being the Metadata Server. While deploying it isn’t strictly necessary, it does enable the full feature set of UGS. This is also where CI/CD systems post build information. As shown, there are different possible implementations of the Metadata Server, and it’s worth briefly discussing each:\nEpic Metadata Service. This is the original and longest-standing version of the Metadata Server. It requires Windows, IIS, and the older .NET Framework 4.6.2.\nThird-party implementation. Thanks to the open-source nature of the server, it’s possible to create your own implementation. One example is RUGS, which is much easier to set up since it supports Docker.\nHorde. Technically, this is a full-fledged automation platform recently introduced by Epic. It includes a built-in UGS Metadata Server as well as its own build system. Although it has a built-in metadata server, it doesn’t allow publishing from external sources – the transition to Horde assumes that all metadata is generated internally. Horde is a bit outside the scope of this blog post, so we’re only mentioning it for the sake of completeness.\nEntities that the build system is supposed to post to the metadata server are called “badges” in UGS terms. These badges will then show up in the CIS (continuous integration status) column in UGS. It usually looks like this:\n\n\n\n\nAs far as we know, the metadata server endpoints don’t currently have authentication. It appears that the server is intended to be used within a secure, closed network, but this is just our understanding and not an official statement.\nFor a more complete definition of UGS please refer to the official documentation.\nUGS Integration in TeamCity\nLet’s take a look at UGS integration in TeamCity. As of the most recent plugin update, we support these two scenarios:\nPublishing a badge as a build status via the Commit Status Publisher.\nPublishing an arbitrary set of badges defined in your BuildGraph script.\nThis applies to the “distributed” execution mode – a special runner mode in which the BuildGraph definition of the build is converted into a set of builds in TeamCity (build chain). For more details, please refer to our previous blog post or the plugin documentation.\nThe first scenario is pretty straightforward. You only need to configure the Commit Status Publisher build feature and set up a few required parameters.\n\n\n\n\nThe second scenario is more complex. In your script, you can define a set of badges and link them to specific nodes to be tracked. Before diving into the scripts, here’s a quick reminder of how the plugin maps BuildGraph entities to TeamCity entities:\n\nBuildGraphTeamCity\nNodeBuild step\nAgentBuild\n\n\n\n\n\nFor example, if your build process includes compiling an editor, the script might look like this (with unimportant details omitted):\n<Agent Name=\"Build Editor and tools\" Type=\"...\">\n    <Node Name=\"Set binary version\">\n        ...\n    </Node>\n\n    <Node Name=\"Compile Tools\" Requires=\"Set binary version\">\n        ...\n    </Node>\n\n    <Node Name=\"Compile Editor\" Requires=\"Compile Tools\">\n        ...\n    </Node>\n</Agent>\n\n<Badge Name=\"Compile Editor\" Project=\"//UE5/Main/Samples/Games/Lyra\" Requires=\"Compile Editor\"/>\nHere, we define a badge named “Compile Editor” to track the execution of a node with the same name. In distributed BuildGraph mode, TeamCity will recognize this badge and update the build status as the process progresses.\nYou can define multiple badges to track different sets of nodes, and TeamCity will monitor all of them based on the specified dependencies:\n<Agent Name=\"Build A\" Type=\"A\">\n    <Node Name=\"Node 1\">\n        ...\n    </Node>\n</Agent>\n\n<Agent Name=\"Build B\" Type=\"B\">\n    <Node Name=\"Node 2\">\n        ...\n    </Node>\n</Agent>\n\n<Agent Name=\"Build C\" Type=\"C\">\n    <Node Name=\"Node 3\">\n        ...\n    </Node>\n</Agent>\n\n<Badge Name=\"BuildProject\" Project=\"//foo/bar/project\" Requires=\"Node A;Node B;Node C\"/>\nIn this example, there are three agents (each with a single node) that can potentially run concurrently, as they are assigned to different agents and have no dependencies on each other. Each build is tracked by a corresponding badge.\nThe badge will behave as follows:\n“Starting” – displayed as soon as any tracked dependency begins execution.\n“Success” – shown when all dependencies complete successfully.\n“Failure” – Indicated if any dependency encounters an error.\nFor complete examples, please refer to the plugin’s user guide on GitHub.\nOpen-sourcing the Plugin\nWe have received a lot of feedback since the plugin was introduced in May this year. Thank you to everyone who shared ideas for further development, submitted feature requests, or reported bugs! We’ve also been asked several times whether we’re going to open-source the plugin and, if so, when. That time is now!\nWith this step, we hope to:\nIncrease transparency and trust in the plugin’s codebase.\nEngage the community for contributions and improvements.\nSpeed up bug fixes and feature implementations.\nThe source code is now available on GitHub and the latest release is ready for download on the marketplace. We encourage you to submit feature requests, report any bugs you encounter, suggest enhancements, or fork the plugin and customize it to fit your needs.\nCheers!",
        "dc:creator": "Vladislav Grinin",
        "content": "We’ve got a few exciting updates about the Unreal Engine plugin announced in the previous blog post. TL;DR – we’re adding Unreal Game Sync (UGS) integration and open-sourcing the plugin. These updates are all about making the CI/CD experience smoother for Unreal Engine devs and getting the community more involved. UGS Before diving in, let’s [&#8230;]",
        "contentSnippet": "We’ve got a few exciting updates about the Unreal Engine plugin announced in the previous blog post. TL;DR – we’re adding Unreal Game Sync (UGS) integration and open-sourcing the plugin. These updates are all about making the CI/CD experience smoother for Unreal Engine devs and getting the community more involved. UGS Before diving in, let’s […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=523510",
        "categories": [
          "game-developement",
          "news",
          "unreal-engine"
        ],
        "isoDate": "2024-11-06T14:44:18.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": [
      {
        "creator": "Sharmila Jesupaul",
        "title": "Adopting Bazel for Web at Scale",
        "link": "https://medium.com/airbnb-engineering/adopting-bazel-for-web-at-scale-a784b2dbe325?source=rss----53c7c27702d5---4",
        "pubDate": "Tue, 12 Nov 2024 18:22:17 GMT",
        "content:encodedSnippet": "How and Why We Migrated Airbnb’s Large-Scale Web Monorepo to Bazel\nBy: Brie Bunge and Sharmila Jesupaul\nIntroduction\nAt Airbnb, we’ve recently adopted Bazel — Google’s open source build tool–as our universal build system across backend, web, and iOS platforms. This post will cover our experience adopting Bazel for Airbnb’s large-scale (over 11 million lines of code) web monorepo. We’ll share how we prepared the code base, the principles that guided the migration, and the process of migrating selected CI jobs. Our goal is to share information that would have been valuable to us when we embarked on this journey and to contribute to the growing discussion around Bazel for web development.\nWhy did we do this?\nHistorically, we wrote bespoke build scripts and caching logic for various continuous integration (CI) jobs that proved challenging to maintain and consistently reached scaling limits as the repo grew. For example, our linter, ESLint, and TypeScript’s type checking did not support multi-threaded concurrency out-of-the-box. We extended our unit testing tool, Jest, to be the runner for these tools because it had an API to leverage multiple workers.\nIt was not sustainable to continually create workarounds to overcome the inefficiencies of our tooling which did not support concurrency and we were incurring a long-run maintenance cost. To tackle these challenges and to best support our growing codebase, we found that Bazel’s sophistication, parallelism, caching, and performance fulfilled our needs.\nAdditionally, Bazel is language agnostic. This facilitated consolidation onto a single, universal build system across Airbnb and allowed us to share common infrastructure and expertise. Now, an engineer who works on our backend monorepo can switch to the web monorepo and know how to build and test things.\nWhy was this hard?\nWhen we began the migration in 2021, there was no publicized industry precedent for integrating Bazel with web at scale outside of Google. Open source tooling didn’t work out-of-the-box, and leveraging remote build execution (RBE) introduced additional challenges. Our web codebase is large and contains many loose files, which led to performance issues when transmitting them to the remote environment. Additionally, we established migration principles that included improving or maintaining overall performance and reducing the impact on developers contributing to the monorepo during the transition. We effectively achieved both of these goals. Read on for more details.\nReadying the Repository\nWe did some work up front to make the repository Bazel-ready–namely, cycle breaking and automated BUILD.bazel file generation.\nCycle Breaking\nOur monorepo is laid out with projects under a top-level frontend/ directory. To start, we wanted to add BUILD.bazel files to each of the ~1000 top-level frontend directories. However, doing so created cycles in the dependency graph. This is not allowed in Bazel because there needs to be a DAG of build targets. Breaking these often felt like battling a hydra, as removing one cycle spawns more in its place. To accelerate the process, we modeled the problem as finding the minimum feedback arc set (MFAS)¹ to identify the minimal set of edges to remove leaving a DAG. This set presented the least disruption, level of effort, and surfaced pathological edges.\nAutomated BUILD.bazel Generation\nWe automatically generate BUILD.bazel files for the following reasons:\n\nMost contents are knowable from statically analyzable import / require statements.\nAutomation allowed us to quickly iterate on BUILD.bazel changes as we refined our rule definitions.\nIt would take time for the migration to complete and we didn’t want to ask users to keep these files up-to-date when they weren’t yet gaining value from them.\nManually keeping these files up-to-date would constitute an additional Bazel tax, regressing the developer experience.\n\nWe have a CLI tool called sync-configs that generates dependency-based configurations in the monorepo (e.g., tsconfig.json, project configuration, now BUILD.bazel). It uses jest-haste-map and watchman with a custom version of the dependencyExtractor to determine the file-level dependency graph and part of Gazelle to emit BUILD.bazel files. This CLI tool is similar to Gazelle but also generates additional web specific configuration files such as tsconfig.json files used in TypeScript compilation.\nCI Migration\nWith preparation work complete, we proceeded to migrate CI jobs to Bazel. This was a massive undertaking, so we divided the work into incremental milestones. We audited our CI jobs and chose to migrate the ones that would benefit the most: type checking, linting, and unit testing². To reduce the burden on our developers, we assigned the central Web Platform team the responsibility for porting CI jobs to Bazel. We proceeded one job at a time to deliver incremental value to developers sooner, gain confidence in our approach, focus our efforts, and build momentum. With each job, we ensured that the developer experience was high-quality, that performance improved, CI failures were reproducible locally, and that the tooling Bazel replaced was fully deprecated and removed.\nEnabling TypeScript\nWe started with the TypeScript (TS) CI job. We first tried the open source ts_project rule³. However, it didn’t work well with RBE due to the sheer number of inputs, so we wrote a custom rule to reduce the number and size of the inputs.\nThe biggest source of inputs came from node_modules. Prior to this, the files for each npm package were being uploaded individually. Since Bazel works well with Java, we packaged up a full tar and a TS-specific tar (only containing the *.ts and package.json) for each npm package along the lines of Java JAR files (essentially zips).\nAnother source of inputs came through transitive dependencies. Transitive node_modules and d.ts files in the sandbox were being included because technically they can be needed for subsequent project compilations. For example, suppose project foo depends on bar, and types from bar are exposed in foo’s emit. As a result, project baz which depends on foo would also need bar’s outputs in the sandbox. For long chains of dependencies, this can bloat the inputs significantly with files that aren’t actually needed. TypeScript has a — listFiles flag that tells us which files are part of the compilation. We can package up this limited set of files along with the emitted d.ts files into an output tsc.tar.gz file⁴. With this, targets need only include direct dependencies, rather than all transitive dependencies⁵.\nDiagram showing how we use tars and the — listFiles flag to prune inputs/outputs of :types targets\nThis custom rule unblocked switching to Bazel for TypeScript, as the job was now well under our CI runtime budget.\nBar chart showing the speed up from switching to using our custom genrule\nEnabling ESLint\nWe migrated the ESLint job next. Bazel works best with actions that are independent and have a narrow set of inputs. Some of our lint rules (e.g., special internal rules, import/export, import/extensions) inspected files outside of the linted file. We restricted our lint rules to those that could operate in isolation as a way of reducing input size and having only to lint directly affected files. This meant moving or deleting lint rules (e.g., those that were made redundant with TypeScript). As a result, we reduced CI times by over 70%.\nTime series graph showing the runtime speed-up in early May from only running ESLint on directly affected targets\nEnabling Jest\nOur next challenge was enabling Jest. This presented unique challenges, as we needed to bring along a much larger set of first and third-party dependencies, and there were more Bazel-specific failures to fix.\nWorker and Docker Cache\nWe tarred up dependencies to reduce input size, but extraction was still slow. To address this, we introduced caching. One layer of cache is on the remote worker and another is on the worker’s Docker container, baked into the image at build time. The Docker layer exists to avoid losing our cache when remote workers are auto-scaled. We run a cron job once a week to update the Docker image with the newest set of cached dependencies, striking a balance of keeping them fresh while avoiding image thrashing. For more details, check out this Bazel Community Day talk.\nDiagram showing symlinked npm dependencies to a Docker cache and worker cache\nThis added caching provided us with a ~25% speed up of our Jest unit testing CI job overall and reduced the time to extract our dependencies from 1–3 minutes to 3–7 seconds per target. This implementation required us to enable the NodeJS preserve-symlinks option and patch some of our tools that followed symlinks to their real paths. We extended this caching strategy to our Babel transformation cache, another source of poor performance.\nImplicit Dependencies\nNext, we needed to fix Bazel-specific test failures. Most of these were due to missing files. For any inputs not statically analyzable (e.g., referenced as a string without an import, babel plugin string referenced in .babelrc), we added support for a Bazel keep comment (e.g., // bazelKeep: path/to/file) which acts as though the file were imported. The advantages of this approach are:\n1. It is colocated with the code that uses the dependency,\n2. BUILD.bazel files don’t need to be manually edited to add/move # keep comments,\n3. There is no effect on runtime.\nA small number of tests were unsuitable for Bazel because they required a large view of the repository or a dynamic and implicit set of dependencies. We moved these tests out of our unit testing job to separate CI checks.\nPreventing Backsliding\nWith over 20,000 test files and hundreds of people actively working in the same repository, we needed to pursue test fixes such that they would not be undone as product development progressed.\nOur CI has three types of build queues:\n1. “Required”, which blocks changes,\n2. “Optional”, which is non-blocking,\n3. “Hidden”, which is non-blocking and not shown on PRs.\nAs we fixed tests, we moved them from “hidden” to “required” via a rule attribute. To ensure a single source of truth, tests run in “required” under Bazel were not run under the Jest setup being replaced.\n# frontend/app/script/__tests__/BUILD.bazel\njest_test(\n    name = \"jest_test\",\n    is_required = True, # makes this target a required check on pull requests \n    deps = [\n        \":source_library\",\n    ],\n)\nExample jest_test rule. This signifies that this target will run on the “required” build queue.\nWe wrote a script comparing before and after Bazel to determine migration-readiness, using the metrics of test runtime, code coverage stats, and failure rate. Fortunately, the bulk of tests could be enabled without additional changes, so we enabled these in batches. We divided and conquered the remaining burndown list of failures with the central team, Web Platform, fixing and updating tests in Bazel to avoid putting this burden on our developers. After a grace period, we fully disabled and deleted the non-Bazel Jest infrastructure and removed the is_required param.\nLocal Bazel Experience\nIn tandem with our CI migration, we ensured that developers can run Bazel locally to reproduce and iterate on CI failures. Our migration principles included delivering only what was on par with or superior to the existing developer experience and performance. JavaScript tools have developer-friendly CLI experiences (e.g., watch mode, targeting select files, rich interactivity) and IDE integrations that we wanted to retain. By default, frontend developers can continue using the tools they know and love, and in cases where it is beneficial they can opt into Bazel. Discrepancies between Bazel and non-Bazel are rare and when they do occur, developers have a means of resolving the issue. For example, developers can run a single script, failed-on-pr which will re-run any targets failing CI locally to easily reproduce issues.\nAnnotations on a failing build with scripts to recreate the failures, e.g. yak script jest:failed-on-pr\nWe also do some normalization of platform specific binaries so that we can reuse the cache between Linux and MacOS builds. This speeds up local development and CI jobs by sharing cache between a local developer’s macbook and linux machines in CI. For native npm packages (node-gyp dependencies) we exclude platform-specific files and build the package on the execution machine. The execution machine will be the machine executing the test or build process. We also use “universal binaries” (e.g., for node and zstd), where all platform binaries are included as inputs (so that inputs are consistent no matter which platform the action is run from) and the proper binary is chosen at runtime.\nConclusion\nAdopting Bazel for our core CI jobs yielded significant performance improvements for TypeScript type checking (34% faster), ESLint linting (35% faster), and Jest unit tests (42% faster incremental runs, 29% overall). Moreover, our CI can now better scale as the repo grows.\nNext, to further improve Bazel performance, we will be focusing on persisting a warm Bazel host across CI runs, taming our build graph, powering CI jobs that do not use Bazel with the Bazel build graph, and potentially exploring SquashFS to further compress and optimize our Bazel sandboxes.\nWe hope that sharing our journey has provided insights for organizations considering a Bazel migration for web.\nAcknowledgments\nThank you Madison Capps, Meghan Dow, Matt Insler, Janusz Kudelka, Joe Lencioni, Rae Liu, James Robinson, Joel Snyder, Elliott Sprehn, Fanying Ye, and various other internal and external partners who helped bring Bazel to Airbnb.\nWe are also grateful to the broader Bazel community for being welcoming and sharing ideas.\n****************\n[1]: This problem is NP-complete, though approximation algorithms have been devised that still guarantee no cycles; we chose the implementation outlined in “Breaking Cycles in Noisy Hierarchies”.\n[2]: After initial evaluation, we considered migrating web asset bundling as out of scope (though we may revisit this in the future) due to high level of effort, unknowns in the bundler landscape, and neutral return on investment given our recent adoption of Metro, as Metro’s architecture already factors in scalability features (e.g. parallelism, local and remote caching, and incremental builds).\n[3]: There are newer TS rules that may work well for you here.\n[4]: We later switched to using zstd instead of gzip because it produces archives that are better compressed and more deterministic, keeping tarballs consistent across different platforms.\n[5]: While unnecessary files may still be included, it’s a much narrower set (and could be pruned as a further optimization).\nAll product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.\n\nAdopting Bazel for Web at Scale was originally published in The Airbnb Tech Blog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Sharmila Jesupaul",
        "guid": "https://medium.com/p/a784b2dbe325",
        "categories": [
          "bazel",
          "migration",
          "web",
          "typescript",
          "engineering"
        ],
        "isoDate": "2024-11-12T18:22:17.000Z"
      },
      {
        "creator": "Dillon Davis",
        "title": "Transforming Location Retrieval at Airbnb: A Journey from Heuristics to Reinforcement Learning",
        "link": "https://medium.com/airbnb-engineering/transforming-location-retrieval-at-airbnb-a-journey-from-heuristics-to-reinforcement-learning-d33ffc4ddb8f?source=rss----53c7c27702d5---4",
        "pubDate": "Mon, 11 Nov 2024 18:14:35 GMT",
        "content:encodedSnippet": "How Airbnb leverages machine learning and reinforcement learning techniques to solve a unique information retrieval task in order to provide guests with unique, affordable, and differentiated accommodations around the world.\nBy: Dillon Davis, Huiji Gao, Thomas Legrand, Weiwei Guo, Malay Haldar, Alex Deng, Han Zhao, Liwei He, Sanjeev Katariya\nIntroduction\nAirbnb has transformed the way people travel around the globe. As Airbnb’s inventory spans diverse locations and property types, providing guests with relevant options in their search results has become increasingly complex. In this blog post, we’ll discuss shifting from using simple heuristics to advanced machine learning and reinforcement learning techniques to transform what we call location retrieval in order to address this challenge.\nThe Challenge of Location Retrieval\nGuests typically start searching by entering a destination in the search bar and expect the most relevant results to be surfaced. These destinations can be countries, states, cities, neighborhoods, streets, addresses, or points of interest. Unlike traditional travel accommodations, Airbnb listings are spread across different neighborhoods and surrounding areas. For example, a family searching for a vacation rental in San Francisco might find better options in nearby cities like Daly City, where there are larger single-family homes. Thus, the system needs to account for not just the searched location but also nearby areas that might offer better options for the guest. This is evidenced by the locations of booked listings when searching for San Francisco shown below.\n\nGiven Airbnb’s scale, we cannot rank every listing for every search. This presented a challenge to create a system that dynamically infers a relevant map area for a query. This system, known as location retrieval, needed to balance including a wide variety of listings to appeal to all guests’ needs while still being relevant to the query. Our search ranking models can then efficiently rank the subset of our inventory that is within the relevant map area and surface the most relevant inventory to our guests. This system and more is outlined below\n\nStarting with Heuristics: The Cold Start Problem\nInitially, Airbnb relied on heuristics to define map areas based on the type of search. For example, if a guest searched for a country, the system would use administrative boundaries to filter listings within that country. If they searched for a city, the system would create a 25-mile radius around the city center to retrieve listings.\nImproving these heuristics proved to be profoundly impactful. One such example is the introduction of a log scale parameterized smooth function to compute an expansion factor for the diagonal size of the administrative bounds of the searched destination. We applied this for very precise locations like addresses, buildings, and POI’s resulting in a 0.35% increase in uncancelled bookers on the platform when tested in an online A/B experiment against the baseline heuristics. Figures below demonstrate how search results for a building in Ibiza, Spain improved dramatically with this heuristic by surfacing significantly more and higher quality inventory.\n\nThese heuristics were simple and worked well enough to start, but they had limitations. They couldn’t differentiate between different types of searches (e.g., a family looking for a large home versus a solo traveler looking for a small apartment), and they didn’t adapt well to new data as Airbnb’s inventory and guest preferences evolved.\nExploring Statistics to Help Improve Location Retrieval\nWith more data available over time from these intuition based heuristics, we thought there might be a way to take advantage of this historical user booking behavior to improve location retrieval. We built a dataset for each travel destination that recorded where guests booked listings when searching for that destination. Based on this data, the system could create retrieval map areas that included 96% of the nearest booked listings for a given destination.\nWe tested these newly constructed retrieval map areas in lieu of the intuition based heuristics outlined above based on the hypothesis that it would provide guests a more bookable selection of inventory. While this statistical approach was more aligned with guest booking behavior, it still had limitations. It treated all searches for a location the same, regardless of specific search parameters like group size or travel dates. This uniform approach meant that some guests might not see the best listings for their particular needs. As a result, this statistics based method had no detectable increase in uncancelled bookers on the platform when tested against the heuristics outlined above in an online A/B experiment. This led us to believe that location retrieval may require more advanced techniques such as machine learning.\nAdvancing to Machine Learning\nInstead of only relying on past booking data, the new system could learn from various search parameters, such as the number of guests and stay duration. By analyzing this data, a model could predict more relevant map areas for each search, rather than applying a one-size-fits-all approach.\nFor example, a group of ten travelers searching for a San Francisco vacation rental might prefer larger homes in the suburbs, while solo travelers might prioritize central locations. The machine learning model could distinguish between these different preferences and adjust the retrieval map areas accordingly, providing more tailored results.\nWe constructed our machine learning model in the following manner. This is a result of three iterations that introduced the machine learning model, expanded its feature set, and expanded search attribution. The architecture is depicted in the figure below.\n\nTraining Examples: Searches issued by a booker by entering a destination in the search bar or manipulating the map that contained the booked listing in their search results on the same day or one day before the booking. We discard any bookings that are canceled 7 days after booking.\nTraining Features: We derive features directly from the search request such as location name, stay length, number of guests, price filters, location country, etc. There are 9 continuous features and 19 categorical features in total.\nTraining Labels: The latitude and longitude coordinates of the booked listing attributed to the search\nArchitecture: A two layer neural network of size 256 was chosen in order to have more flexibility for loss formulation compared to traditional regression and decision tree based approaches.\nModel Output: 4 floats that define the latitude and longitude offsets from the center latitude and longitude coordinates of the searched destination that represent the relevant map area.\nLoss: Trained to predict map areas that contain their associated booked listing while minimizing the size of the predicted map area and the occurrence of predictions that cannot construct a valid rectangular map area.\n\nThe machine learning system increased the recall of booked listings (i.e., how often the system retrieved a listing that was eventually booked) by 7.12% and reduced the size of the retrieval map area by 40.83%. It had a cumulative impact of +1.8% in uncancelled bookers on the platform. The initial model was evaluated against the baseline and each subsequent model iteration was evaluated against the preceding outgoing model.\nFigures below demonstrate how search results for a specific street in Lima, Peru improved dramatically with the model by surfacing results that are much closer to the searched street.\nBefore\n\nAfter\n\nExploring New Frontiers with Reinforcement Learning\nWhile machine learning improved the system’s ability to differentiate search results, there was still room for improvement, particularly in learning whether locations that had never been surfaced before were relevant to guests for a search. To address this, Airbnb introduced reinforcement learning to the location retrieval process.\nReinforcement learning allowed the system to continuously learn from guest interactions by surfacing new areas for a given destination and adjusting the retrieval map area based on guest booking behavior. This approach, known as a contextual multi-armed bandit problem, involved balancing exploration (surfacing new locations) with exploitation (surfacing previous successful locations). The system could actively experiment with different retrieval map areas learning from guest bookings to refine its predictions.\nApplying a contextual multi-armed bandit traditionally requires defining an active contextual estimator, a method for uncertainty estimation, and an exploration strategy. We took the following approach given product constraints, system constraints, and the nature of our model formulation. The architecture is depicted in the figure below.\n\nActive contextual estimation: We employed our existing machine learning model for location retrieval retrained on a daily basis to regularly learn from any new bookings data that we collect while surfacing previously unshown locations.\nUncertainty estimation: We modified our model architecture with a random dropout layer to generate 32 unique predictions for a given search (Monte Carlo Dropout). This allows us to measure the mean and standard deviation of our prediction while minimizing negative impact to system performance and changes to our existing model formulation.\nExploration Strategy: We compute an upper confidence bound using the mean and standard deviation of our prediction in order to construct larger retrieval map areas based on the model’s confidence in its prediction for the search.\n\nThis system successfully explored more for less-traveled locations where it was less confident and explored less for locations that are often searched and booked. For example, pictured below are the mean (inner) and upper confidence bound (outer) estimates of retrieval map areas for San Francisco, CA (left) and Smith Mountain Lake, Virginia (right). San Francisco is searched almost 25x more than Smith Mountain Lake with proportionately more bookings as well. As a result, the model is more confident in its retrieval map area estimate for San Francisco vs Smith Mountain Lake resulting in 2–3x less exploration for San Francisco queries vs Smith Mountain Lake.\n\nThe reinforcement learning system was also tested against the outgoing machine learning model in online A/B experiments showing a cumulative 0.51% increase in uncanceled bookers and 0.71% increase in 5 star trip rate over two iterations that introduced reinforcement learning and optimized scoring of the more complex model.\nConclusion: A Transformative Journey\nAirbnb’s journey from simple heuristics to sophisticated machine learning and reinforcement learning models demonstrates the power of data-driven approaches in transforming complex systems. By continually iterating and improving its location retrieval process, Airbnb has not only enhanced the relevance of its search results but also helped guests experience more 5 star trips.\nThis transformation cumulatively results in a 2.66% increase in uncanceled bookers — a major achievement for a company operating at Airbnb’s scale. More details can be found in our technical paper. As Airbnb continues to innovate, we are continuously evaluating and introducing more advanced features and retrieval mechanisms like retrieving with complex polygons . These will further refine and enhance the search experience for millions of guests worldwide.\nIf this type of work interests you, check out some of our related positions and more at Careers at Airbnb!\n****************\nAll product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.\n\nTransforming Location Retrieval at Airbnb: A Journey from Heuristics to Reinforcement Learning was originally published in The Airbnb Tech Blog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Dillon Davis",
        "guid": "https://medium.com/p/d33ffc4ddb8f",
        "categories": [
          "search-engines",
          "machine-learning",
          "information-retrieval",
          "engineering",
          "artificial-intelligence"
        ],
        "isoDate": "2024-11-11T18:14:35.000Z"
      }
    ]
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Mads Kristensen",
        "title": "Visual Studio 2022 v17.12 with .NET 9",
        "link": "https://devblogs.microsoft.com/visualstudio/visual-studio-2022-v17-12-with-dotnet-9/",
        "pubDate": "Tue, 12 Nov 2024 18:12:48 +0000",
        "content:encodedSnippet": "We are thrilled to announce the General Availability (GA) of Visual Studio 2022 version 17.12. This update focuses on providing fantastic developer experiences for working with .NET 9 projects and new AI productivity features, along with continuous improvements for all developers.\n\nThanks to your continuous feature requests, we’ve incorporated many of them in this release. There’s something new for every developer. We have added several new tools and enhancements that simplify your workflow and improve productivity. Whether you’re looking for advanced debugging capabilities, more efficient code management, or enhanced security features, this update has it all.\n\nDownload Visual Studio 2022 v17.12\n\nFor detailed information on each new feature, check out the release notes. If you’re pressed for time, here are the key highlights.\nProductivity\nCopy from the Error List: Copying an error from the Error List now copies just the description instead of the entire row to the clipboard.\nGo to line anywhere in Code Search: In Code Search, you can now navigate to a specific line in the current document or other specified document.\nDock the Code Search window: You can now freely position the Code Search window with capabilities like docking and auto-hiding.\nCustomize collapsed text indicator: Set custom colors for the collapsed text indicator in the Visual Studio editor.\nRefresh your Find results: You can now refresh the results to a previous Find to get up-to-date search matches.\nMore space for horizontal scrollbar: You can now control the visibility of the file level indicators in CodeLens.\nNon-blocking Code Cleanup on save: When Code Cleanup is run on Save, it now operates in a non-blocking manner, for a smoother coding experience.\nGitHub Copilot\nAI smart variable inspection: Optimize your debugging workflow with Integrated AI variable inspection.\nAI-powered IEnumerable visualizer: AI-powered LINQ Editable Expressions in the IEnumerable visualizer.\nFix code with GitHub Copilot: GitHub Copilot assists you in resolving code issues.\nBetter AI completions for C#: GitHub Copilot brings in additional context from relevant source files to improve completions for C#.\nDebug tests with GitHub Copilot: Get help with debugging failed tests by using Debug Tests with GitHub Copilot.\nDebugging & diagnostics\nShows method return values when debugging: The debugger now displays inline return values for enhanced debugging efficiency.\nExport breakpoint groups with ease: Effortless import and export of breakpoint groups.\nBlazor WebAssembly debugging: An improved debugging experience for Blazor WebAssembly apps targeting .NET 9 or later.\nMeter Histogram in Profiler Counter Tool: Enhanced performance insights using Meter Histogram in Profiler Counter Tool.\nAnalyze memory use over time: Select and compare multiple memory snapshots using the Diagnostics Tool window.\nGit tooling\nManage file renaming with Git: Get peace of mind when renaming files with a new notification.\nPull requests using drafts and templates: Create pull request drafts and start your descriptions with templates in Visual Studio.\nCreate internal GitHub repos: Visual Studio now supports creating internal repos and includes guidance for each type of repository to give you more confidence when starting a new project.\nCopy Git link: You can get a GitHub or Azure DevOps link to a specific line of code to make it easy to share with your colleagues.\nCustomize your AI Git commit message: You can add additional instructions to the prompt for generating your Git commit message with GitHub Copilot.\nMulti-repo for GitHub and Azure DevOps: You can now create pull requests and link work items in multi-repo scenarios.\nIDE\nPreserve font across theme changes: Changing themes will now remember your font and font size preferences.\nMulti-Project Launch Configuration: Streamline debugging by setting up and saving launch profiles for specific projects within multi-project solutions. Share configurations effortlessly with your team.\nCopy files between instances: You can now copy files and folders from Solution Explorer in one instance of Visual Studio to another.\nMultiple GitHub accounts: You can now add multiple GitHub accounts and set an active account to drive GitHub features like GitHub Copilot and Version Control.\nCertificate Revocation Checks: Visual Studio now alerts you if it detects digital certificate problems during network calls.\nMotW security warnings: Mark of the web (MotW) security warnings are now integrated into the overall trust functionality.\nTeams Toolkit new AI templates: The Teams Toolkit onboards new AI Teams app templates.\nCloud\nAzure App Service publish security updates: Publishing to Azure App Service securely using integrated security updates.\nAzure WebJobs Linux support: Publishing to Azure WebJobs on Linux is now supported by right-click publish in Visual Studio.\nAzure Functions Flex Consumption: Publish to Azure Flex Consumption hosting plan, currently in Preview.\nConnected Services security update: Making your apps and development experienced more secure.\nDesktop\nEnhanced WinUI components search: Enhance WinUI project setup with improved Visual Studio Installer search, simplifying component location for developers.\nWeb\nRequest variables in HTTP files: HTTP files now support request variables. That is where you can send a request and then use data from the response, or request, in future requests.\nHTTP files shared environment: In HTTP environment files we have added support to share variables across environments.\nVitest support in JavaScript and TypeScript: When using JavaScript and TypeScript projects you can now author test cases with Vitest.\nInlay Hints support for more languages: Inlay Hint support has been added to JavaScript, TypeScript, Python and Razor as well as a setting to control its behavior.\nData\nSDK-style SQL projects in SSDT: You can now use the SDK-style project file format in your SQL Server Data Tools projects.\n.NET\nAchieve more with .NET 9: .NET 9 elevates cloud-native and intelligent app development, focusing on productivity enhancements, streamlined deployments, and accelerated AI integration.\nNuGet audits transitive packages: NuGet is changing default audit settings to include transitive packages.\nC++\nSet C++ Command Line Arguments: A new way to set your command line arguments right from the toolbar.\nBuild Insights view explanations: Learn how to use each tab of Build Insights via a newly added link to documentation.\nBuild Insights path adjustments: Get a clearer view of your file in Build Insights, see full path on hover.\nOpen Folder for Unreal Engine uproject: A new way of opening your uproject.\nChange signature improved: You can now effectively change signatures with our improved feature for C++.\nSHARE YOUR FEEDBACK AND STAY CONNECTED\nAs you use Visual Studio, let us know what you love, what you like, and where you’d like us to improve. You can share feedback with us via Developer Community: report any bugs or issues via report a problem and share your suggestions for new features or improvements to existing ones.\nStay connected with the Visual Studio team by following us on YouTube, Twitter, LinkedIn, Twitch and on Microsoft Learn.\nAs always, we appreciate the time you’ve spent reporting issues and hope you continue to give us feedback on how we’re doing and what we can improve.\nThe post Visual Studio 2022 v17.12 with .NET 9 appeared first on Visual Studio Blog.",
        "dc:creator": "Mads Kristensen",
        "content": "<p>We are thrilled to announce the General Availability (GA) of Visual Studio 2022 version 17.12. This update focuses on providing fantastic developer experiences for working with .NET 9 projects and new AI productivity features, along with continuous improvements for all developers. Thanks to your continuous feature requests, we&#8217;ve incorporated many of them in this release. [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/visual-studio-2022-v17-12-with-dotnet-9/\">Visual Studio 2022 v17.12 with .NET 9</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "We are thrilled to announce the General Availability (GA) of Visual Studio 2022 version 17.12. This update focuses on providing fantastic developer experiences for working with .NET 9 projects and new AI productivity features, along with continuous improvements for all developers. Thanks to your continuous feature requests, we’ve incorporated many of them in this release. […]\nThe post Visual Studio 2022 v17.12 with .NET 9 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251184",
        "categories": [
          "Visual Studio",
          "Release"
        ],
        "isoDate": "2024-11-12T18:12:48.000Z"
      },
      {
        "creator": "Mika Dumont",
        "title": "Better GitHub Copilot Completions for C#",
        "link": "https://devblogs.microsoft.com/visualstudio/better-github-copilot-completions-for-c/",
        "pubDate": "Mon, 11 Nov 2024 15:27:27 +0000",
        "content:encodedSnippet": "We’re excited to announce a significant enhancement to GitHub Copilot that elevates your C# coding experience. Introducing the new update: GitHub Copilot code completions now provide more accurate and relevant autocomplete suggestions by incorporating additional C# context.\nPreviously, GitHub Copilot generated suggestions based on the content of your currently active file and any other open files in your editor. While this approach was helpful, we have discovered that including more relevant context can greatly improve the quality of these suggestions.\nWith this latest update, GitHub Copilot now automatically considers semantically relevant files for additional context, even if these files are not open in your editor. This enhancement helps reduce hallucinations and ensures that you receive more pertinent and precise code completions.\nBefore: Semantically relevant files are not considered as context for GitHub Copilot Completions\n﻿without-related-files.mp4″ width=”560″ height=”315″ allowfullscreen=”allowfullscreen”>﻿\nAfter: Semantically relevant files are considered as context for GitHub Copilot Completions\n﻿﻿without-related-files.mp4″ width=”560″ height=”315″ allowfullscreen=”allowfullscreen”>﻿\nTo dive deeper into how this new feature works and how it can improve your coding productivity, check out our detailed blog post Improving GitHub Copilot Completions in Visual Studio for C# Developers on the .NET blog.\nStay tuned for more updates and thank you for being a part of our developer community.\nThe post Better GitHub Copilot Completions for C# appeared first on Visual Studio Blog.",
        "enclosure": {
          "url": "https://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2024/11/without-related-files.mp4",
          "length": "146986",
          "type": "video/mp4"
        },
        "dc:creator": "Mika Dumont",
        "content": "<p>We&#8217;re excited to announce a significant enhancement to GitHub Copilot that elevates your C# coding experience. Introducing the new update: GitHub Copilot code completions now provide more accurate and relevant autocomplete suggestions by incorporating additional C# context. Previously, GitHub Copilot generated suggestions based on the content of your currently active file and any other open [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/better-github-copilot-completions-for-c/\">Better GitHub Copilot Completions for C#</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "We’re excited to announce a significant enhancement to GitHub Copilot that elevates your C# coding experience. Introducing the new update: GitHub Copilot code completions now provide more accurate and relevant autocomplete suggestions by incorporating additional C# context. Previously, GitHub Copilot generated suggestions based on the content of your currently active file and any other open […]\nThe post Better GitHub Copilot Completions for C# appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251281",
        "categories": [
          "Copilot",
          "Visual Studio",
          "C#",
          "GitHub Copilot",
          "Visual Studio 2022"
        ],
        "isoDate": "2024-11-11T15:27:27.000Z"
      },
      {
        "creator": "Rhea Patel",
        "title": "Introducing a new, more conversational way to chat with GitHub Copilot",
        "link": "https://devblogs.microsoft.com/visualstudio/conversational-way-to-chat-with-github-copilot/",
        "pubDate": "Wed, 06 Nov 2024 16:46:22 +0000",
        "content:encodedSnippet": "In the fast-evolving world of software development, intuitive AI-driven interactions are becoming essential to unlocking new levels of productivity. Today, we’re excited to share our latest innovation – a guided chat experience within GitHub Copilot that reshapes how developers interact with AI. This guided chat experience is available in Visual Studio 2022 17.12 Preview 3 and above.\nThis guided way to chat was created with one clear goal in mind: to make interactions between developers and AI more natural, effective, and aligned with everyday workflows. It is our deep belief that conversational AI is the future of development, and we’re committed to leading that transformation.\nMaking Copilot Conversations Smarter and Simpler\nAs we’ve refined GitHub Copilot, one thing has become clear: while users appreciate the potential of AI-driven tools, there’s a learning curve. Developers have shared that crafting the right prompt can sometimes feel like a challenge—understanding how to phrase a question, knowing what context to include, and making the most of Copilot’s capabilities. In some cases, the experience left users feeling like they were getting too much or too little from their interactions.\nCustomer feedback highlights the challenge:\n“The chat experience is helpful, but I wish it felt more like an assistant—something that could help guide me and give me only what I need without extra noise.”\n“I love how Copilot just starts generating, but it sometimes feels like I have to sift through a lot to get to what I actually wanted.”\nThese insights inspired us to rethink how AI should work for developers. Rather than relying only on intent-based commands or predefined prompts, this chat allows for a more fluid, conversational experience—one that adapts to the user’s context and needs.\nHow does this work? \nOur guided chat experience takes Copilot beyond simple input-output exchanges, turning it into a collaborative assistant. When the context is clear, Copilot provides direct and relevant answers. When it isn’t, Copilot guides you by asking follow-up questions to ensure clarity and precision.\n\nThe implications are significant:\nMore Engagement: Developers spend less time figuring out how to phrase their prompts and more time focused on the task at hand.\nLess Complexity: Copilot’s ability to guide and clarify reduces the need for developers to navigate complex intent systems.\nIncreased Productivity: With less back-and-forth and more focused responses, developers can move faster through their workflows.\nIn our early trials, we’ve seen encouraging signs that Guided Chat makes a real difference. So we are excited for you all to try it out.\nAs we continue refining this guided way to chat, user feedback and engagement will be at the center of our improvements, ensuring that it delivers the intelligent and seamless experience developers need.\nThank you for your continuous feedback\nWe owe much of our progress to our users’ invaluable feedback. Your insights and suggestions have been instrumental in making Visual Studio better with each update. We appreciate your continuous support and look forward to bringing you more innovative features.\nThe post Introducing a new, more conversational way to chat with GitHub Copilot appeared first on Visual Studio Blog.",
        "dc:creator": "Rhea Patel",
        "content": "<p>In the fast-evolving world of software development, intuitive AI-driven interactions are becoming essential to unlocking new levels of productivity. Today, we’re excited to share our latest innovation &#8211; a guided chat experience within GitHub Copilot that reshapes how developers interact with AI. This guided chat experience is available in Visual Studio 2022 17.12 Preview 3 [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/conversational-way-to-chat-with-github-copilot/\">Introducing a new, more conversational way to chat with GitHub Copilot</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "In the fast-evolving world of software development, intuitive AI-driven interactions are becoming essential to unlocking new levels of productivity. Today, we’re excited to share our latest innovation – a guided chat experience within GitHub Copilot that reshapes how developers interact with AI. This guided chat experience is available in Visual Studio 2022 17.12 Preview 3 […]\nThe post Introducing a new, more conversational way to chat with GitHub Copilot appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=251224",
        "categories": [
          "Artificial Intelligence",
          "Copilot",
          "GitHub Copilot",
          "Visual Studio",
          "Conversational AI",
          "GitHub Copilot Chat"
        ],
        "isoDate": "2024-11-06T16:46:22.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": [
      {
        "creator": "권창현",
        "title": "학생 지도의 즐거움에 대하여",
        "link": "https://thoughts.chkwon.net/happy-advisor/",
        "pubDate": "Sun, 10 Nov 2024 06:17:06 +0000",
        "content:encodedSnippet": "지난해 8월에 한국에 들어와서 KAIST에서 근무한 지 1년이 지났다. 그동안 국내외에 계신 분들을 만날 때면, 한국에 들어가서 어떠냐, 좋으냐는 질문을 많이 들었고, 그때마다 “너무 좋아요, 행복해요”라는 말을 많이도 하고 다녔다.\n최근에 ‘나는 왜 한국 생활이 행복한가?’라는 질문에 대해 자세히 살펴볼 기회가 있었다. 내가 한국 생활에서 만족스러운 점들, 어떤 순간들에 재미를 느꼈는지는 어렴풋하게는 파악하고 있었지만, ‘왜?’라는 질문에 답하려고 시도한 것은 처음이다.\n \n\nKAIST 부임 벌써 1년. 바쁜지, 행복한지 묻는 중요한 질문 앞에서, 오늘 저녁 메뉴를 생각하며 고뇌에 빠진 모습이다.\n\n \n \n우선 정말 단순하게도 내가 태어나고 자란 나라, 한국이기 때문이다. 한국을 떠난 지 20년이나 됐기 때문에 나도 한국도 여러 가지 의미로 달라진 것은 사실이지만, 여전히 내가 태어난 나라이고, 언어적·문화적 뿌리를 공유하는 사람들이 많이 모여 사는 나라다. 이런 환경이 주는 알 수 없는 심리적 안정감이 있다.\nKAIST이기 때문이다. 이것은 몇 가지 의미를 갖고 있다. 첫째로는 내 모교라는 점이다. 내 추억이 있는 곳에서 일하는 것이 단순한 직장 이상의 의미를 준다. 둘째로는 한국 사회에서 KAIST가 가지는 지위 때문에 내게 주어지는 많은 기회들이 있다. 좋은 학생들을 만나기에도, 좋은 연구 프로젝트를 만나기에도 유리한 환경이다. 셋째로는 사회에 기여하기를 바라는 KAIST의 미션 때문이다. 한국 사회에 기여할 기회가 KAIST 교수에게만 주어지는 것은 아닐 테지만, 내가 개인적으로 갖고 있는 미션과 내가 속한 기관의 미션이 일치하는 점이 있다는 것에 대한 만족감이 있다.\n자극이 되는 동료 교수님들 때문이다. 내가 속한 학과 안팎에 지적으로 자극을 주시는 여러 동료 교수님들이 계시고, 그런 분들과 편안하게 어울리기도 하고 함께 일하기도 한다. 그분들의 프로페셔널한 모습도 자극이 많이 되지만, 그분들과 사적이며 내밀한 이야기를 나누기도 하며, 서로의 개인사를 공유하기도 한다. 그 과정에서 서로의 가치관에 대해 이야기도 해보는데, 그 과정이 많은 자극이 된다. 당연히, 미국이라고 그런 분들이 없었던 건 아니지만, 한국에는, KAIST에는 바로 옆 방에 계시기도 하고, 같은 건물, 같은 캠퍼스에 계신다. 그러다 보니 아무래도 그런 자극의 빈도가 높다.\n오믈렛 때문이다. 한국에 들어오면서 같은 학과 교수님과 창업을 하게 되었고, 아직까지는 순항 중이다. 창업하고, 동료를 모으고, 투자받고, 회사의 모양을 가꾸어 가면서 여러 가지 어려움이 있지만, 학교에서는 볼 수 없었던 새로운 도전을 맞이하고 있다. 그 도전들을 극복해나가는 과정에서 ‘내가 왜 그랬을까’라는 생각이 들 때도 있었지만, 내가 하고 있는 연구를 기반으로 한 회사를 만들고 있다는 것이 즐겁다. 훌륭한 동료들을 맞이했다는 것도 자랑스럽고, 그 사이에서 내가 할 수 있는 역할이 있다는 점도 흥미롭다. 나는 CTO 역할을 맡고 있지만, 인사, 법무, 계약, 재무, 세무 등 관련 일들도 많이 하면서 새로운 도전을 즐기고 있다. 교원의 기술 기반 회사 창업이라는 점이 KAIST의 미션과 부합한다는 것도 동기부여에 도움이 된다.\n그리고, 가장 중요하게, 내 학생들 때문이다.\n나는 한국에 와서 지금 만난 학생들을 지도하는 것이 매우 즐거운데, 그 이유에 대해 조금 더 곰곰이 생각해봤다. 이 말 하고 싶어서 이 글을 쓴다.\n내가 만난 KAIST 학생들은 그 누구보다 재능 넘치고 성실한 학생들이다. Work ethic이 매우 훌륭하고, 노력을 많이 기울이는 것에 대한 인내심이 높은 편이다. 이런 학생들을 마다할 교수가 어디 있겠나? 나는 이것만으로도 복받았다. 독립적인 사고, 자신의 의견에 대한 고집, 비정형 문제 해결 능력 등은 아직 부족한 편으로 보일 때도 있는데, 아직 학부 졸업한 지 1년밖에 안 된 학생들이니 당연할 것이라 생각된다. 부족한 점은 지도교수인 내가 잘 가이드해주고 조언해주면 될 일이다.\n언어와 문화를 공유하는 학생들이라는 점이 주는 이점이 꽤 있다. 학생들과 공부만 하고 연구만 하면 될 일이겠지만, 나는 그 과정에서 섬세한 피드백을 주는 것을 즐기는 사람이라는 것을 알게 되었다. 학생과 대화할 때 모국어가 아닌 영어로만 대화할 때와 비교해서는 커뮤니케이션의 해상도가 매우 높아진다. “잘 이해되었나요? 네, 이해했습니다.”와 같은 단순한 대화에서도 내가 그 학생에 대해 파악할 수 있는 것들이 많다. 그 학생의 표정과 몸짓, 말하는 억양 같은 것에서 읽을 수 있는 것들이 많고, 그에 맞게 내 다음 행동을 이어나갈 수 있다. 모든 사람들이 이런 해상도 높은 커뮤니케이션을 즐기는 것은 아니겠지만, 나는 그런 걸 즐기는 사람이었다. 미국에서는 경험하기 어려운 것들이었다. 물론, 이런 방식의 커뮤니케이션을 학생들도 즐기고 있는지, 학생들의 성장에 정말 도움이 될 것인지에 대해서는 아직 의문이 있으나, 다만 이런 방식이 내가 선호하고 즐기는 방식이라는 거다.\n한국 학교에서 한국 학생들을 가르치고 지도하여 성장에 도움을 주고 있다는 사실 그 자체가 주는 충족감이 있다. 한국으로 돌아오면서 남긴 글에서 미국에서 지낼 때는 내가 속한 커뮤니티를 명확히 구분하기가 쉽지 않아서 혼란스러웠다고 말한 바 있는데, 한국에 돌아와서야 아무래도 그 점들이 좀 더 명확해졌다. 한국 학생들을 성실히 지도한다는 것 자체가 내가 속한 커뮤니티에 기여할 수 있는 점이라고 생각되며, 그 점에서 학생 지도에 대한 동기부여가 잘 되고 있다.\n그런데, 아무리 이렇다고 한들, 학생들을 지도하는 점이 나를 그렇게까지 행복하게 만들 일인가?\n대체 왜?\n둘째 아이 키우는 것 같다. 이게 내 결론이다.\n흔히 첫째 아이는 부부가 직업적으로 경제적으로 가장 도전적인 상황에서 맞게 되는 경우가 많고, 부모로서의 경험 미숙 등으로 좀 더 엄격하게 대하게 되는 경향이 있다. 사랑스러운 아이지만, 필요 이상의 텐션을 유지하며 키우게 되어 부모와 아이 양쪽의 스트레스가 높아지기도 한다. 반면에 둘째 아이는 대체로 부부가 조금 더 안정되었을 때, 그리고 아이 양육 경험도 충분히 쌓였을 때 맞이하게 되며, 그래서 좀 더 여유가 있다. 흔히 ‘숨만 쉬어도 예쁘다’라는 표현으로 둘째 아이의 사랑스러움에 대해 이야기한다. 적어도 내 개인적인 경험과는 일치한다. 내 첫째 아이는 박사과정 막학기에 태어났고 엄마, 아빠가 모두 테뉴어 트랙 조교수일 때 자랐다. 둘째 아이는 엄마, 아빠가 모두 테뉴어를 받을 때쯤 나고 자랐다. 여전히 바쁘고 힘들었지만, 둘째 양육은 첫째 때와는 양상이 좀 다를 수밖에 없었다. 이런저런 이유로 첫째 아이는 좀 더 차분하고, 둘째 아이는 좀 더 애교 넘친다.\n한국에서 바로 테뉴어트랙을 시작한 교수님들도 첫 지도 학생 그룹이 기억에 많이 남으실 거다. 서로 혼란스러운 시기를 같이 공부하고 같이 연구하며 헤쳐 나가면서 교수와 학생 모두 성공적으로 커리어에 안착하고 독립적인 학자가 되어 졸업하는 시기를 보내면 서로 미운 정 고운 정 다 들 것이다. 하지만 그 과정에서 겪는 테뉴어 트랙 조교수의 스트레스가 무시무시할 수 있다. 미래에 대한 불확실성, 연구비 확보의 어려움, 연구 성과가 잘 나오지 않을 때 겪는 초조함 등으로 교수는 스트레스를 받고, 어쩌면 학생들에게 불필요하게 모질게 대하는 경우도 있을 테다. 학생들도 그 과정에서 힘들고 스트레스를 많이 받을 테고, 졸업할 때쯤이면 지도교수가 미워질지도 모른다. 첫째 아이를 양육하는 것과 비슷한 일이 생긴다.\n나는 미국에서 15년간 15명의 박사과정 학생을 지도하면서 이 과정을 모두 다 겪고 한국에 왔다. 다양한 유형의 학생을 이미 지도 해 본 적 있으며, 연구 역량도 쌓았고, 인적 네트워크도 갖추었으며, 테뉴어도 받아서 마음 조급할 일들은 많이 줄어들었다. 그래서 여유롭다. 위에서 말한 KAIST의 여러 이점들 때문에, 또 여러 멋진 동료 교수님들의 도움으로 첫해부터 매우 운이 좋게도 연구비에 대한 걱정도 많이 없는 상황이다. 내가 학생들에게 해주고 싶은 걸 충분히 해줄 수 있는 상황인 것 같다.\n이런 심적으로 물적으로 여유 있는 상황에서 학생 지도를 하니, 성실하고 재능 있는 내 학생들이 안 예뻐 보일 리 없다. 학생들을 지도하기 위해 만나는 주간 미팅이 즐겁지 않을 리 없다. 학생들이 조금씩 성장해 나가고 성취를 이뤄 나가는 걸 지켜보는 것이 조마조마하면서도 매우 즐겁다. 학생들에게 아쉬운 소리를 하는 경우가 없는 것은 아니지만, 학생들에게 좀 더 관대한 마음으로 조언을 해 줄 수 있다. 운 좋게 여유로운 상황에서 내 마음에 드는 훌륭한 학생들을 만나게 되었고, 그 과정이 매우 즐겁다. 학생들은 훌륭하고, 나만 잘하면 된다.\n‘숨만 쉬어도 예쁜’ 내 학생들은, 다만 숨을 좀 열심히 쉬어야 하기는 한다. 아직 대학원 1~2년 차들이라 수업 들으면서 숙제도 많은데, 내가 진행하고 있는 연구 프로젝트들도 좀 있고, 개인 연구도 진행해야 한다. 그걸 모두 다 해내야 하는데, 또 내가 신나서 벌리는 일들이 좀 있다. 그런 것들 서포트하느라 힘들어하기도 하지만, 아직까지는 모든 학생들이 다 잘 해나가고 있는 것 같다. 한계점에 가까워질 뻔한 일들도 몇 차례 있었던 것 같은데, 해상도 높은 커뮤니케이션의 도움으로 일단은 잘 지나간 것으로 믿고 있다. (이건 학생들 말도 들어봐야…)\n즐거운 마음으로 학생들을 지도하고 있고, 앞으로 좋은 연구자가 될 수 있도록 성실히 잘 지도해야겠다고 다짐한다. 내가 즐기는 만큼, 내 학생들도 나와 함께 공부하고 연구하는 것을 즐길 수 있으면 좋겠다. 학위 과정 중 언젠가 밑바닥으로 내려가는 학생들도 있을 텐데, 그때도 내가 도움이 될 수 있으면 좋겠다. 5년 뒤에도, 10년 뒤에도 계속 학생 지도하는 것이 이렇게 즐거웠으면 좋겠다는 생각을 많이 하고, 그러기 위해 지금부터 내가 해야 할 일이 무엇인지 고민이 많다.\n…\n셋째가 그렇게 예쁘다던데…",
        "dc:creator": "권창현",
        "comments": "https://thoughts.chkwon.net/happy-advisor/#respond",
        "content": "지난해 8월에 한국에 들어와서 KAIST에서 근무한 지 1년이 지났다. 그동안 국내외에 계신 분들을 만날 때면, 한국에 들어가서 어떠냐, 좋으냐는 질문을 많이 들었고, 그때마다 &#8220;너무 좋아요, 행복해요&#8221;라는 말을 많이도 하고 다녔다. 최근에 &#8216;나는 왜 한국&#46;&#46;&#46;",
        "contentSnippet": "지난해 8월에 한국에 들어와서 KAIST에서 근무한 지 1년이 지났다. 그동안 국내외에 계신 분들을 만날 때면, 한국에 들어가서 어떠냐, 좋으냐는 질문을 많이 들었고, 그때마다 “너무 좋아요, 행복해요”라는 말을 많이도 하고 다녔다. 최근에 ‘나는 왜 한국...",
        "guid": "https://thoughts.chkwon.net/?p=987",
        "categories": [
          "잡생각"
        ],
        "isoDate": "2024-11-10T06:17:06.000Z"
      }
    ]
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권영재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": [
      {
        "creator": "고종범",
        "title": "정말 어려운 비폭력 대화",
        "link": "https://brunch.co.kr/@@24SO/48",
        "pubDate": "Sun, 10 Nov 2024 01:42:07 GMT",
        "author": "고종범",
        "content": "비폭력대화라는 것을 접하게 된 것은 애자일 코칭을 배우면서이다. 애자일 코칭은 팀이나 조직이 애자일 방법론을 도입하고 적용할 때 도와주는 역할을 말한다. 애자일 방법론을 도입한다는 것은 변화를 만드는 것이고 변화에는 저항과 갈등이 발생하기 때문에 이를 해결하기 위한 방법으로 애자일 코칭이란 것을 배우게 되었다. 처음 배웠을 때는 좀 막연함이 있었고 사람들과<img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2F24SO%2Fimage%2FhbYaGt75CRMobQQ2X6fEfYpApz0.png\" width=\"500\" />",
        "contentSnippet": "비폭력대화라는 것을 접하게 된 것은 애자일 코칭을 배우면서이다. 애자일 코칭은 팀이나 조직이 애자일 방법론을 도입하고 적용할 때 도와주는 역할을 말한다. 애자일 방법론을 도입한다는 것은 변화를 만드는 것이고 변화에는 저항과 갈등이 발생하기 때문에 이를 해결하기 위한 방법으로 애자일 코칭이란 것을 배우게 되었다. 처음 배웠을 때는 좀 막연함이 있었고 사람들과",
        "guid": "https://brunch.co.kr/@@24SO/48",
        "isoDate": "2024-11-10T01:42:07.000Z"
      }
    ]
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김상훈",
    "category": "개인",
    "posts": [
      {
        "creator": "김상훈",
        "title": "머스크 X 트럼프",
        "link": "https://interpiler.com/2024/11/08/%eb%a8%b8%ec%8a%a4%ed%81%ac-x-%ed%8a%b8%eb%9f%bc%ed%94%84/",
        "pubDate": "Thu, 07 Nov 2024 23:42:30 +0000",
        "content:encodedSnippet": "22년 10월, 머스크가 약 50조 원에 가까운 돈을 들여 트위터를 인수했을 때, 많은 사람들이 머스크를 비웃었다. 지나치게 비싼 값이라는 이유였다. 실제로 트위터는 그 이후 광고 급감, 매출 급감, 사용자 급감 등 여러 악재를 맞으면서 이런 비난과 조소가 더 우세한 의견이 됐다.\n24년 말이 된 현재, 아무도 머스크의 충동적으로 보였던 결정을 비웃지 못하게 됐다. 머스크는 트위터의 이름을 X로 바꾼 뒤 세계 각국의 정치 지도자들을 X에서 지지하고, 칭송하고, 때로는 비난하며 들었다 놨다 했다. 인도는 테슬라 전기차에 부과하는 관세를 중국 전기차보다 훨씬 낮춰주면서 머스크에게 화답했고, 브라질은 스타링크 사업에 길을 열어줄 정도였다. 무엇보다 머스크는 X를 통해 세계 최고 권력자인 미국 대통령 당선을 직접적으로 도왔다. 기부금 측면에서, 미디어 영향력 측면에서, 그리고 뻔뻔함의 측면에서 모두 전례없는 선거였다.\n무엇보다 중요한 건 트럼프의 당선으로 이 새로운 형태의 금권선거에 면죄부가 주어질 것이란 점. 앞으로 소셜미디어를 인수하거나 독점해 자신이 원하는 메시지를 지지자들 중심으로 확산시키면서 막대한 자본으로 선거에 개입하는 기업가들이 계속 등장해도 이들을 비난하기 어렵게 됐다. 오늘은 공화당의 트럼프 편에 일론 머스크가 섰지만, 내일은 민주당의 누군가 편에 다른 실리콘밸리 아이돌이 선다고 해도 어색하지 않을 일.",
        "dc:creator": "김상훈",
        "comments": "https://interpiler.com/2024/11/08/%eb%a8%b8%ec%8a%a4%ed%81%ac-x-%ed%8a%b8%eb%9f%bc%ed%94%84/#respond",
        "content": "22년 10월, 머스크가 약 50조 원에 가까운 돈을 들여 트위터를 인수했을 때, 많은 사람들이 머스크를 비웃었다. 지나치게 비싼 값이라는 이유였다. 실제로 트위터는 그 이후 광고 급감, 매출 급감, 사용자 급감 등 여러 악재를 맞으면서 이런 비난과 조소가 더 우세한 의견이 됐다. 24년 말이 된 현재, 아무도 머스크의 충동적으로 보였던 결정을 비웃지 못하게 됐다. 머스크는 트위터의 &#8230; <a href=\"https://interpiler.com/2024/11/08/%eb%a8%b8%ec%8a%a4%ed%81%ac-x-%ed%8a%b8%eb%9f%bc%ed%94%84/\" class=\"more-link\">계속 읽기 <span class=\"screen-reader-text\">머스크 X 트럼프</span> <span class=\"meta-nav\">\t</span></a>",
        "contentSnippet": "22년 10월, 머스크가 약 50조 원에 가까운 돈을 들여 트위터를 인수했을 때, 많은 사람들이 머스크를 비웃었다. 지나치게 비싼 값이라는 이유였다. 실제로 트위터는 그 이후 광고 급감, 매출 급감, 사용자 급감 등 여러 악재를 맞으면서 이런 비난과 조소가 더 우세한 의견이 됐다. 24년 말이 된 현재, 아무도 머스크의 충동적으로 보였던 결정을 비웃지 못하게 됐다. 머스크는 트위터의 … 계속 읽기 머스크 X 트럼프",
        "guid": "http://interpiler.com/?p=1526",
        "categories": [
          "That's IT",
          "머스크",
          "트럼프",
          "트위터",
          "X"
        ],
        "isoDate": "2024-11-07T23:42:30.000Z"
      }
    ]
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": [
      {
        "title": "데이터 흐름(Data flow)을 이해해 보는 데 있어 필요한 것은? 짝퉁 개발자처럼 논하기",
        "link": "https://thdev.tech/dataflow/2024/11/09/Data-flow/",
        "pubDate": "Sat, 09 Nov 2024 00:00:00 +0000",
        "content": "<p>제미나이에게 <code class=\"language-plaintext highlighter-rouge\">개발에서 데이터 흐름이란?</code>를 알려달라고 했다.</p>\n\n<blockquote>\n  <p>개발에서 데이터 흐름은 어떤 시스템이나 소프트웨어에서 데이터가 생성되고, 변환되며, 저장되고, 전송되는 과정을 의미합니다. 마치 물이 강을 따라 흐르듯이, 데이터는 시스템 내에서 특정한 경로를 따라 이동하며 가치를 창출합니다.</p>\n</blockquote>\n\n<p>위키백과도 한번 확인해 보았다.</p>\n\n<p><a href=\"https://ko.wikipedia.org/wiki/%EB%8D%B0%EC%9D%B4%ED%84%B0_%ED%9D%90%EB%A6%84\">위키 백과 데이터 흐름 - 링크</a></p>\n\n<blockquote>\n  <p>데이터 흐름(Data flow, 데이터 플로)란 하나의 작업을 수행하기 위하여 실행되는 각각의 세부 작업들 사이에서 자료가 입력되고 출력되는 모습을 의미한다.</p>\n</blockquote>\n\n<p>결국 같은 말이다.</p>\n\n<p>우리가 매우 흔하게 사용하는 데이터 흐름을 가볍게 이해하는 표현으로 서문을 작성해 보았다.</p>\n\n<p>이 글에서 데이터 다양한 데이터 흐름을 이해하는 데 도움이 될만한 내용을 정리해 본 글인데, 실제 함수 위주이니 참고만 한다고 생각하길</p>\n\n<h3>이 글에서는</h3>\n<ul>\n  <li>함수의 blocking vs nonblocking</li>\n  <li>Observer pattern + stream</li>\n  <li>UDF(unidirectional data flow)</li>\n  <li>매우 주관적으로 작성한 글이다.</li>\n  <li>데이터 흐름(Data flow)에 대한 새로운 형태를 만드는 짝퉁 설명이니 재미로 읽기를</li>\n</ul>\n\n<!--more-->\n\n<h2>함수의 blocking vs nonblocking</h2>\n\n<p>함수에는 blocking과 nonblocking으로 구분된다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">fun</span> <span class=\"nf\">main</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"main\"</span><span class=\"p\">)</span>\n    <span class=\"nf\">someA</span><span class=\"p\">()</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"end)\n</span><span class=\"p\">}</span>\n\n<span class=\"k\">fun</span> <span class=\"nf\">someA</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"run some a\"</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>이 함수의 결과는 다음과 같다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">main</span>\n<span class=\"n\">run</span> <span class=\"n\">some</span> <span class=\"n\">a</span>\n<span class=\"n\">end</span>\n</code></pre></div></div>\n\n<p>이유는 간단하다. blocking이기 때문이다.</p>\n\n<p>그럼 아래의 코드는?</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">fun</span> <span class=\"nf\">main</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"main\"</span><span class=\"p\">)</span>\n    <span class=\"nf\">someA</span><span class=\"p\">()</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"end\"</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">fun</span> <span class=\"nf\">someA</span><span class=\"p\">()</span> <span class=\"p\">=</span> <span class=\"nc\">CoroutinesScope</span><span class=\"p\">().</span><span class=\"nf\">launch</span> <span class=\"p\">{</span>\n    <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"run coroutines)\n</span><span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>이 함수의 결과는 다음과 같을 수 있다.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>main\nend\nrun coroutines\n</code></pre></div></div>\n\n<p>이는 nonblocking이니 가능한 결과이지만 end 전에 coroutines이 실행되어 순서대로 나올 순 있다.</p>\n\n<p>여기서의 흐름은 처음 예제는 명확히 순서를 보장한다는 점이고, 후자는 비동기가 필요하기에 순서의 보장이 필요 없는 경우를 말한다.</p>\n\n<p>데이터 흐름에서 가장 중요한 부분은 비동기라고 할 수 있다.</p>\n\n<p><br /></p>\n\n<h3>그럼 아래의 코드는 blocking, nonblocking 중 어느 것일까?</h3>\n\n<p>아래 링크에 포함되어 있는 코드를 그대로 가져왔다.</p>\n\n<p><a href=\"https://kotlinlang.org/api/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/coroutine-scope.html\">coroutineScope - link</a></p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">fun</span> <span class=\"nf\">main</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"nc\">CoroutinesScope</span><span class=\"p\">().</span><span class=\"nf\">launch</span> <span class=\"p\">{</span>\n        <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"main\"</span><span class=\"p\">)</span>\n        <span class=\"nf\">showSomeData</span><span class=\"p\">()</span>\n        <span class=\"nf\">println</span><span class=\"p\">(</span><span class=\"s\">\"end\"</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">suspend</span> <span class=\"k\">fun</span> <span class=\"nf\">showSomeData</span><span class=\"p\">()</span> <span class=\"p\">=</span> <span class=\"nf\">coroutineScope</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">data</span> <span class=\"p\">=</span> <span class=\"nf\">async</span><span class=\"p\">(</span><span class=\"nc\">Dispatchers</span><span class=\"p\">.</span><span class=\"nc\">IO</span><span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"c1\">// &lt;- extension on current scope</span>\n     <span class=\"o\">..</span><span class=\"p\">.</span> <span class=\"n\">load</span> <span class=\"n\">some</span> <span class=\"nc\">UI</span> <span class=\"n\">data</span> <span class=\"k\">for</span> <span class=\"n\">the</span> <span class=\"nc\">Main</span> <span class=\"n\">thread</span> <span class=\"o\">..</span><span class=\"p\">.</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"nf\">withContext</span><span class=\"p\">(</span><span class=\"nc\">Dispatchers</span><span class=\"p\">.</span><span class=\"nc\">Main</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n        <span class=\"nf\">doSomeWork</span><span class=\"p\">()</span>\n        <span class=\"kd\">val</span> <span class=\"py\">result</span> <span class=\"p\">=</span> <span class=\"n\">data</span><span class=\"p\">.</span><span class=\"nf\">await</span><span class=\"p\">()</span>\n        <span class=\"nf\">display</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<ul>\n  <li>main 함수는 blocking</li>\n  <li>main 함수의 CoroutinesScope().launch의 시작점은 nonblocking</li>\n  <li>launch { } 안의 내용은 blocking</li>\n  <li>showSomeData()의 async 시작 부분은 nonblocking</li>\n  <li>showSomeData()의 async 내부는 blocking</li>\n  <li>showSomeData()의 withContext 부분은 blocking</li>\n</ul>\n\n<p>이 코드는 blocking과 nonblocking이 매우 많이 뒤섞여있다.</p>\n\n<p>이런 코드가 아주 흔한 일이다. 여기서 동기와 비동기 부분을 명확히 이해해야 데이터 흐름을 빠르게 파악할 수 있다.</p>\n\n<p>이 코드는 이 글의 핵심은 아니지만 동기와 비동기를 이해하는 데 있어 중요한 코드이며, coroutines은 일반적인 함수의 사용만큼이나 쉽다는 점이다.</p>\n\n<p><br /></p>\n\n<h2>Observer pattern + stream</h2>\n\n<p>다음 문장은 어떤 부분을 설명하는 걸까?</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>물이 흐르고 있다. 이 흐르는 물에 새로운 물줄기를 추가했다.\n</code></pre></div></div>\n\n<p>이 설명은 개발에서 <code class=\"language-plaintext highlighter-rouge\">HotFlow</code>/<code class=\"language-plaintext highlighter-rouge\">HotObserve</code>에 대한 설명일 수 있지만 내가 적었으니 맞다.</p>\n\n<p>여기서 중요한 부분은 무엇일까?</p>\n\n<p>바로 흐름(flow)이다. Observer pattern에서 데이터 흐름을 설명하는 쉬운 방법 중 하나이다.</p>\n\n<p>물이 흐른다는 표현을 적었으니 흐르는구나를 알 수 있고, 지속적인 흐름을 의미할 수 있다.</p>\n\n<p>반대로 흐르지 않는 경우도 있는데 어떻게 설명해 볼 수 있을까?</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>나는 얼음이다. 땡 해주기 전에는 움직일 수 없다.\n</code></pre></div></div>\n\n<p><br /></p>\n\n<h3>Coroutines flow는?</h3>\n\n<p><a href=\"https://kotlinlang.org/docs/flow.html\">Asynchronous Flow - link</a></p>\n\n<blockquote>\n  <p>A suspending function asynchronously returns a single value, but how can we return multiple asynchronously computed values? This is where Kotlin Flows come in.</p>\n</blockquote>\n\n<p>코루틴 flow는 단일 값을 한 번씩 호출하여 사용할 수 있는 suspend 대신 지속적인 흐름을 가지기 위한 개념을 포함한다. 바로 Observer + stream을 포함한다.</p>\n\n<p><br /></p>\n\n<h3>HotFlow/ColdFlow?</h3>\n\n<p>서문에 적은 설명은 오류를 가질 수 있지만 HotFlow/ColdFlow를 각각 설명하기 쉬운 주제라고 생각하여 필자가 주로 설명하는 방식이다.</p>\n\n<p>HotFlow는 두 가지가 존재하는데</p>\n\n<ul>\n  <li>StateFlow</li>\n  <li>SharedFlow</li>\n</ul>\n\n<p>사용법이 다를 뿐 둘 다 HotFlow이다.</p>\n\n<p>ColdFlow는</p>\n\n<ul>\n  <li>flow {}</li>\n  <li>flowOf()</li>\n</ul>\n\n<p>flow의 시작점이다.</p>\n\n<p><br /></p>\n\n<h3>추가로 - O 어떤 걸로 구성되어 있을까?</h3>\n\n<p>이 글에서는 상세한 내용을 알아보기 위해서 적는 글은 아니니 가볍게 가볍게 어떤 구성으로 이루어져 있을까만 적어본다.</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">얼음</code>이거나 <code class=\"language-plaintext highlighter-rouge\">물이 흐르거나</code>로 표현할 수 있었던 이유는 흐르는 물 사이에 새로운 물줄기를 만들거나 얼음을 깨어 새로운 데이터 흐름을 추가할 수 있다는 소리인데</p>\n\n<p>요즘 안드로이드에서는 잘 사용하지 않는 ReactiveX 문서에는 여전히</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>ReactiveX is a combination of the best ideas from\nthe Observer pattern, the Iterator pattern, and functional programming\n</code></pre></div></div>\n\n<p>이라고 표현하고 있다.</p>\n\n<p>이 데이터 흐름을 이해하기 위해서는 결국 <code class=\"language-plaintext highlighter-rouge\">Observer pattern</code>과 <code class=\"language-plaintext highlighter-rouge\">Iterator pattern</code> 만 알아도 충분히 이해할 수 있다는 이야기다.</p>\n\n<p>그럼 안드로이드 개발에서 상태의 기억을 가지는 3가지 나열해 보면 아래와 같다.</p>\n\n<ul>\n  <li>RxJava - Subject 패턴들 4가지가 있으나 상황에 따라 다른 사용을 가짐</li>\n  <li>StateFlow</li>\n  <li>LiveData</li>\n</ul>\n\n<p>이들은 모두 데이터의 제공과 이를 소비하는 패턴으로 만들어져있다.</p>\n\n<p>이때 중요한 부분은 불변으로 데이터를 소비할 수 있도록 만들어주는 데 있다. 불변과 equals/hashCode의 중요성을 각각 확인할 수 있는 관련 글 2개를 링크로 추가한다.</p>\n\n<ul>\n  <li><a href=\"https://haeti.palms.blog/effective-kotlin\">Item 1. 가변성을 제한하라 - 안정성 - link</a></li>\n  <li><a href=\"https://medium.com/@mangbaam/kotlin-java-hashset-hashmap-%EB%82%B4%EB%B6%80-%EA%B5%AC%ED%98%84-%EC%82%B4%ED%8E%B4%EB%B3%B4%EA%B8%B0-032e352546b1\">[Kotlin/Java] HashSet, HashMap 내부 구현 살펴보기 - link</a></li>\n</ul>\n\n<p>추가로 RxJava를 제외한 Flow와 LiveData는 Android에서 라이프 사이클에 따른 처리가 잘 되어있는 반면 RxJava는 직접 처리해야 할 부분이 많고 현재는 레거시로 취급되니 궁금하신 분은 RxJava 관련 문서를 참고하시길</p>\n\n<p><br /></p>\n\n<h2>UDF(unidirectional data flow)</h2>\n\n<p>아키텍처를 적극 사용하는 현재는 데이터 흐름이 복잡할 수밖에 없다. 이를 가장 쉽게 설명할 수 있는 부분이 바로 UDF이다.</p>\n\n<p><a href=\"https://developer.android.com/develop/ui/compose/architecture\">Architecting your Compose UI - UDF 부분 참고 - link</a></p>\n\n<p>UDF는 단방향 데이터 플로우인데, 위에서 설명한 blocking, nonblocking 역시 단방향 플로우를 가진다.</p>\n\n<ul>\n  <li>A 함수를 실행</li>\n  <li>B 함수의 처리</li>\n  <li>다시 A 함수로 돌아와 이어가기</li>\n</ul>\n\n<p>데이터 흐름상 단방향이다.</p>\n\n<p>Observer pattern + stream에서는?</p>\n\n<ul>\n  <li>A 함수를 실행</li>\n  <li>B 함수에 구독을 요청하고, stream으로 데이터 흐름을 전달 받는 대기</li>\n  <li>A 함수로 돌아와 A 함수는 끝나고, Stream의 데이터 흐름을 대기</li>\n</ul>\n\n<p>동기와 비동기가 적절하게 포함되어 있는 형태이다.</p>\n\n<p><br /></p>\n\n<h3>아키텍처에서의 UDF</h3>\n\n<p>UDF는 데이터 흐름을 쉽게 이해하는 데 이를 아주 쉽게 설명한 설명이다.</p>\n\n<p>모든 흐름은 함수의 호출과 그 함수 안에서 새로운 함수의 호출 또는 구독으로 이루어진다. 이를 설명하는 가장 쉬운 방법이 UDF 인 것이다.</p>\n\n<p>그럼 아래의 코드에 대해서 UDF로 설명해 보자.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nd\">@Composable</span>\n<span class=\"k\">fun</span> <span class=\"nf\">Screen</span><span class=\"p\">(</span><span class=\"n\">viewModel</span><span class=\"p\">:</span> <span class=\"nc\">SomeViewModel</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">someUiState</span> <span class=\"k\">by</span> <span class=\"n\">viewModel</span><span class=\"p\">.</span><span class=\"n\">someUiState</span><span class=\"p\">.</span><span class=\"nf\">collectAsStateWithLifecycle</span><span class=\"p\">()</span>\n    \n    <span class=\"nc\">Screen</span><span class=\"p\">(</span>\n        <span class=\"n\">someUiState</span> <span class=\"p\">=</span> <span class=\"n\">someUiState</span><span class=\"p\">,</span>\n        <span class=\"n\">onClick</span> <span class=\"p\">=</span> <span class=\"p\">{</span> <span class=\"n\">viewModel</span><span class=\"p\">.</span><span class=\"nf\">fatchSome</span><span class=\"p\">()</span> <span class=\"p\">},</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">}</span>\n\n<span class=\"nd\">@Composable</span>\n<span class=\"k\">fun</span> <span class=\"nf\">Screen</span><span class=\"p\">(</span>\n    <span class=\"n\">someUiState</span><span class=\"p\">:</span> <span class=\"nc\">SomeUiState</span><span class=\"p\">,</span>\n    <span class=\"n\">onClick</span><span class=\"p\">:</span> <span class=\"p\">()</span> <span class=\"p\">-&gt;</span> <span class=\"nc\">Unit</span><span class=\"p\">,</span>\n<span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"nc\">Button</span><span class=\"p\">(</span>\n        <span class=\"n\">onClick</span> <span class=\"p\">=</span> <span class=\"n\">onClick</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">}</span>\n\n<span class=\"kd\">class</span> <span class=\"nc\">SomeViewModel</span><span class=\"p\">(</span>\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">someRepository</span><span class=\"p\">:</span> <span class=\"nc\">SomeRepository</span><span class=\"p\">,</span>\n<span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">_uiState</span> <span class=\"p\">=</span> <span class=\"nc\">MutableStateFlow</span><span class=\"p\">(</span><span class=\"nc\">SomeUiState</span><span class=\"p\">.</span><span class=\"nc\">Default</span><span class=\"p\">)</span>\n    <span class=\"kd\">val</span> <span class=\"py\">uiState</span> <span class=\"p\">=</span> <span class=\"n\">_uiState</span><span class=\"p\">.</span><span class=\"nf\">asStateFlow</span><span class=\"p\">()</span>\n\n    <span class=\"nf\">init</span> <span class=\"p\">{</span>\n        <span class=\"n\">someRepository</span><span class=\"p\">.</span><span class=\"nf\">flowSome</span><span class=\"p\">()</span>\n            <span class=\"p\">.</span><span class=\"nf\">map</span> <span class=\"p\">{</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"nf\">toState</span><span class=\"p\">()</span> <span class=\"p\">}</span>\n            <span class=\"p\">.</span><span class=\"nf\">onEach</span> <span class=\"p\">{</span> <span class=\"n\">_uiState</span><span class=\"p\">.</span><span class=\"n\">value</span> <span class=\"p\">=</span> <span class=\"n\">it</span> <span class=\"p\">}</span>\n            <span class=\"p\">.</span><span class=\"nf\">launchIn</span><span class=\"p\">(</span><span class=\"n\">viewModelScope</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"k\">fun</span> <span class=\"nf\">fatchSome</span><span class=\"p\">()</span> <span class=\"p\">=</span> <span class=\"n\">viewModelScope</span><span class=\"p\">.</span><span class=\"nf\">launch</span> <span class=\"p\">{</span>\n        <span class=\"n\">someRepository</span><span class=\"p\">.</span><span class=\"nf\">fatchSome</span><span class=\"p\">()</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"kd\">interface</span> <span class=\"nc\">SomeRepository</span> <span class=\"p\">{</span>\n\n    <span class=\"k\">fun</span> <span class=\"nf\">flowSome</span><span class=\"p\">():</span> <span class=\"nc\">Flow</span><span class=\"p\">&lt;</span><span class=\"nc\">SomeEntity</span><span class=\"p\">&gt;</span>\n\n    <span class=\"k\">suspend</span> <span class=\"k\">fun</span> <span class=\"nf\">fatchSome</span><span class=\"p\">()</span>\n<span class=\"p\">}</span>\n\n<span class=\"n\">calss</span> <span class=\"nc\">SomeRepsotiryImpl</span><span class=\"p\">(</span>\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">api</span><span class=\"p\">:</span> <span class=\"nc\">SomeApi</span><span class=\"p\">,</span>\n<span class=\"p\">)</span> <span class=\"p\">:</span> <span class=\"nc\">SomeRepository</span> <span class=\"p\">{</span>\n\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">flowSome</span> <span class=\"p\">=</span> <span class=\"nc\">MutableStateFlow</span><span class=\"p\">&lt;</span><span class=\"nc\">SomeEntity</span><span class=\"p\">?&gt;(</span><span class=\"k\">null</span><span class=\"p\">)</span>\n\n    <span class=\"k\">override</span> <span class=\"k\">fun</span> <span class=\"nf\">flowSome</span><span class=\"p\">():</span> <span class=\"nc\">Flow</span><span class=\"p\">&lt;</span><span class=\"nc\">SomeEntity</span><span class=\"p\">&gt;</span> <span class=\"p\">=</span>\n        <span class=\"n\">flowSome</span><span class=\"p\">.</span><span class=\"nf\">filterNotNull</span><span class=\"p\">()</span>\n\n    <span class=\"k\">override</span> <span class=\"k\">suspend</span> <span class=\"k\">fun</span> <span class=\"nf\">fatchSome</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n        <span class=\"kd\">val</span> <span class=\"py\">resutl</span> <span class=\"p\">=</span> <span class=\"n\">api</span><span class=\"p\">.</span><span class=\"nf\">fatchSome</span><span class=\"p\">()</span>\n        <span class=\"n\">flowSome</span><span class=\"p\">.</span><span class=\"n\">value</span> <span class=\"p\">=</span> <span class=\"n\">result</span><span class=\"p\">.</span><span class=\"nf\">toEntity</span><span class=\"p\">()</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>코드에 대한 설명은 제외하고 데이터 흐름만을 알아보자.</p>\n\n<ul>\n  <li>사용자의 onClick Event를 Composable 함수 Screen에서 발생</li>\n  <li>ViewModel fatchSome() 함수가 호출</li>\n  <li>ViewModel에서는 fatchSome() 함수에서 repository의 fatchSome() 함수를 호출\n    <ul>\n      <li>repository에서는 fatchSome 함수의 응답을 지속적인 흐름을 가지기 위해 flow를 별도로 가진다</li>\n    </ul>\n  </li>\n  <li>repository에서는 someApi를 통해 fatchSome()을 호출한다.</li>\n  <li>응답받은 fatchSome()의 결과를 flowSome에 전달한다.</li>\n  <li>ViewModel에서는 구독 중인 flowSome으로부터 응답을 받고, 상태를 변환하여 UI에 통지하여 UI를 갱신한다.</li>\n</ul>\n\n<p>이 코드는 아주 일반적인 UiState를 서버와의 통신을 통해 갱신하기 위한 부분이다. 여기서 조금 더 나아가면 리엑트의 이펙트까지 포함할 수 있다.</p>\n\n<p>말은 길지만 이 방식은 UDF로 설명하지 않았을 뿐 오래전부터 써오던 방식이다.</p>\n\n<p>그리고 다른 사람들에게 설명하는 가장 간단한 프로세스인데, 필자의 블로그에서도 다양하게 확인할 수 있는 과거의 글들이 많이 있다.</p>\n\n<p>UDF. 단방향을 통해 데이터 흐름을 설명할 수 있다는 부분이 중요한 포인트이다.</p>\n\n<p>이 시점에서 추가로 알아두면 좋은 글들을 나열한다.</p>\n\n<ul>\n  <li><a href=\"https://medium.com/@wisemuji/33910e8f09df\">Jetpack Compose로 UI 조합(Composition)하기 심화 - link</a></li>\n  <li><a href=\"https://thdev.tech/compose/2024/08/04/Android-Compose-Split-Funcation/\">Compose 함수는 어떤 조건으로 나누는것이 좋을까?(Stateful, stateless) - link</a></li>\n  <li><a href=\"https://chanho-study.tistory.com/150\">MVVM에서 MVI로 - link</a></li>\n  <li><a href=\"https://velog.io/@mraz3068/Circuit-Try-Out\">[Android / Compose] Circuit 찍먹 해보기 - link</a></li>\n</ul>\n\n<p>Composable 함수를 어떻게 분리하는 것이 좋을지에 대한 글과 MVI에 대한 설명의 글이다.</p>\n\n<p>그리고 직전에 작성했던 Theme를 다루는 내용도 있으니 함께 보아도 좋을 듯하다.</p>\n\n<ul>\n  <li><a href=\"https://thdev.tech/compose/2024/11/03/GetStream-Theme/\">안드로이드 Theme와 GetStream Theme를 알아보고 CompositionLocalProvider의 역할을 알아본다. - link</a></li>\n</ul>\n\n<p><br /></p>\n\n<h2>서버와의 데이터 흐름</h2>\n\n<p>데이터 흐름의 마지막을 서버와 데이터 흐름을 이야기해 볼 수 있지만 자세한 내용은 없이 어떤 도구를 활용하는지 정도만 이야기해 보려 한다.</p>\n\n<p>클라 입장에서는 서버와의 데이터 통신할 때는 json을 주로 활용한다. 최근에는 protobuf를 활용하는 곳도 많은데 장/단점이 있으니 각각 기술은 서버 개발자와 논의하면 좋다.</p>\n\n<ul>\n  <li>json : <a href=\"https://en.wikipedia.org/wiki/JSON\">JSON(JavaScript Object Notation) - link</a></li>\n  <li>xml : <a href=\"https://en.wikipedia.org/wiki/XML\">Extensible Markup Language (XML) - link</a></li>\n  <li>protobuf : <a href=\"https://en.wikipedia.org/wiki/Protocol_Buffers\">Protocol Buffers (Protobuf) - link</a></li>\n</ul>\n\n<p>데이터 흐름을 얼마나 더 넓게 보는지에 따라 서버에서 제공하는 직전까지의 데이터 흐름으로 설명할 것인지, 이를 넘어가서 설명할 것인지도 정의할 수 있을 것 같다.</p>\n\n<p>우리는 string 형태의 데이터를 주고받는 것이 일반적이지만 결국 이런 데이터는 0/1의 데이터로 변환된다.</p>\n\n<p><br /></p>\n\n<h3>서버까지 포함하여 데이터의 개념은?</h3>\n\n<p>필자는 클라 개발자라 서버에 대해 자세한 이해는 없으니 가볍게 설명해 보겠다.</p>\n\n<ul>\n  <li>클라에서의 데이터 응답을 http 통신을 통해 요청하게 된다.\n    <ul>\n      <li>이때 http는 블로킹 상태로 클라에서는 서버가 응답을 주기 전까지 대기하는데, 이때 클라에서는 UI 상 사용자에게 처리 중임을 알려준다.</li>\n    </ul>\n  </li>\n  <li>서버는 캐싱 상태를 체크하고, DB 서버에 응답을 요청한다.</li>\n  <li>DB 서버는 동기/비동기 상태로 entity를 전달해 주고, 이를 기반으로 클라와 약속한 json 데이터로 변환 후 bloking 상태의 http에 응답해 준다.</li>\n</ul>\n\n<p>클라 입장에서는 nonblocking이겠지만 nonblocking 이후에는 모두 blocking 상태로 서버도 동작한다는 점이다.</p>\n\n<p>서버는 사실상 blocking 작업 상태처럼 보이지만 nonblocking으로 보일 수 있다. 그 안에서 또 nonblocking 작업들이 일어나는 것이다.</p>\n\n<p>모든 처리가 완료되면 클라이언트는 이를 바탕으로 UI에 표현하는 작업을 할 수 있다.</p>\n\n<p>여기서는 아키텍처 개념이 포함될 수 있지만 이 글에서는 다루지 않고, 좀 더 넓은 개념의 아키텍처에 대한 이야기를 준비 중이다.</p>\n\n<p><br /></p>\n\n<h2>데이터 흐름으로 리액트를 이해할 수 있을까?</h2>\n\n<p>리덕스에 대해 제미나이의 응답은 아래와 같다.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>리덕스(Redux)는 자바스크립트 애플리케이션의 상태 관리를 위한 예측 가능한 상태 컨테이너이다.\n쉽게 말해, 애플리케이션의 데이터를 효율적으로 관리하고 예측 가능하게 만들어주는 도구라고 할 수 있다.\n</code></pre></div></div>\n\n<p>이미 많은 안드로이드 개념에서 리덕스 개념이 포함되어 있는데, UiState와 UDF? 부분일 것 같다.</p>\n\n<p>필자가 직접 iOS TCA를 접하고 있는데, 직접 써보고, 설명을 통해 파악한 리덕스 개념은 아래와 같다.</p>\n\n<ul>\n  <li>\n    <p><a href=\"https://github.com/pointfreeco/swift-composable-architecture\">The Composable Architecture - link</a></p>\n  </li>\n  <li>이벤트의 흐름 : 이벤트의 흐름은 최종 사용자가 가장 아래에 있으니 이를 거슬러 올라가듯 설명한다.\n  현재 나의 이벤트가 보이는 화면상이라면 이를 이전 화면에 전달한다. 이런 흐름의 설명이 업스트림으로 설명할 수 있다.</li>\n  <li>데이터 흐름 : 데이터는 위에서 아래로 흘러간다.\n  데이터 최신화 시 아래로 아래로 흘러간다. 이런 데이터 흐름을 통해 내가 필요한 부분을 캐치하고 화면을 갱신할 수 있다.</li>\n</ul>\n\n<p>검색과 짧은 지식으로 정리할 수 있는 개념은 딱 요 정도일 것 같다. Redux의 데이터 흐름 글이 있어 링크를 추가한다.</p>\n\n<p><a href=\"https://velog.io/@jos9187/Redux%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%9D%90%EB%A6%84\">Redux의 데이터 흐름 - link</a></p>\n\n<p>그리고 안드로이드에서 리액트 형태를 가장 잘 구현한 코드가 드로이드 카이기 아닐까 하여 링크를 추가한다.</p>\n\n<ul>\n  <li><a href=\"https://github.com/DroidKaigi/conference-app-2024\">DroidKaigi 2024 official app - link</a></li>\n</ul>\n\n<p><br /></p>\n\n<h2>마무리</h2>\n\n<p>데이터 흐름을 이해한다는 것은 더 많은 것을 볼 수 있고, 파악할 수 있음을 뜻한다고 생각한다.</p>\n\n<p>짝퉁처럼 개념을 이해하는 데 도움이 될 수 있으면 좋겠지만 이 글에서도 알 수 있는데 동기/비동기/ReactiveX 개념까지 알면 이를 통해 리액트의 리덕스 개념도 이해할 수 있는 시점이 된 것 같다.</p>\n\n<p>아직 부족한 부분이 많아서 이 내용으로 모든 걸 다 설명할 순 없지만 어느 정도 충분히 가장 표면적인 내용을 이해하는 데 도움이 되었길.</p>\n\n<p>마지막으로 재웅님의 안드로이드 면접 질문과 관련한 내용 중 compose 개념 설명이 잘 되어있어 링크를 추가한다.</p>\n\n<p><a href=\"https://skydoves.medium.com/top-9-android-developer-interview-questions-you-should-know-05e8fe2acd2c\">Top 9 Android Developer Interview Questions You Should Know - link</a></p>\n",
        "contentSnippet": "제미나이에게 개발에서 데이터 흐름이란?를 알려달라고 했다.\n개발에서 데이터 흐름은 어떤 시스템이나 소프트웨어에서 데이터가 생성되고, 변환되며, 저장되고, 전송되는 과정을 의미합니다. 마치 물이 강을 따라 흐르듯이, 데이터는 시스템 내에서 특정한 경로를 따라 이동하며 가치를 창출합니다.\n위키백과도 한번 확인해 보았다.\n위키 백과 데이터 흐름 - 링크\n데이터 흐름(Data flow, 데이터 플로)란 하나의 작업을 수행하기 위하여 실행되는 각각의 세부 작업들 사이에서 자료가 입력되고 출력되는 모습을 의미한다.\n결국 같은 말이다.\n우리가 매우 흔하게 사용하는 데이터 흐름을 가볍게 이해하는 표현으로 서문을 작성해 보았다.\n이 글에서 데이터 다양한 데이터 흐름을 이해하는 데 도움이 될만한 내용을 정리해 본 글인데, 실제 함수 위주이니 참고만 한다고 생각하길\n이 글에서는\n함수의 blocking vs nonblocking\nObserver pattern + stream\nUDF(unidirectional data flow)\n매우 주관적으로 작성한 글이다.\n데이터 흐름(Data flow)에 대한 새로운 형태를 만드는 짝퉁 설명이니 재미로 읽기를\n함수의 blocking vs nonblocking\n함수에는 blocking과 nonblocking으로 구분된다.\n\nfun main() {\n    println(\"main\")\n    someA()\n    println(\"end)\n}\n\nfun someA() {\n    println(\"run some a\")\n}\n\n\n이 함수의 결과는 다음과 같다.\n\nmain\nrun some a\nend\n\n\n이유는 간단하다. blocking이기 때문이다.\n그럼 아래의 코드는?\n\nfun main() {\n    println(\"main\")\n    someA()\n    println(\"end\")\n}\n\nfun someA() = CoroutinesScope().launch {\n    println(\"run coroutines)\n}\n\n\n이 함수의 결과는 다음과 같을 수 있다.\n\nmain\nend\nrun coroutines\n\n\n이는 nonblocking이니 가능한 결과이지만 end 전에 coroutines이 실행되어 순서대로 나올 순 있다.\n여기서의 흐름은 처음 예제는 명확히 순서를 보장한다는 점이고, 후자는 비동기가 필요하기에 순서의 보장이 필요 없는 경우를 말한다.\n데이터 흐름에서 가장 중요한 부분은 비동기라고 할 수 있다.\n\n그럼 아래의 코드는 blocking, nonblocking 중 어느 것일까?\n아래 링크에 포함되어 있는 코드를 그대로 가져왔다.\ncoroutineScope - link\n\nfun main() {\n    CoroutinesScope().launch {\n        println(\"main\")\n        showSomeData()\n        println(\"end\")\n    }\n}\n\nsuspend fun showSomeData() = coroutineScope {\n    val data = async(Dispatchers.IO) { // <- extension on current scope\n     ... load some UI data for the Main thread ...\n    }\n\n    withContext(Dispatchers.Main) {\n        doSomeWork()\n        val result = data.await()\n        display(result)\n    }\n}\n\n\nmain 함수는 blocking\nmain 함수의 CoroutinesScope().launch의 시작점은 nonblocking\nlaunch { } 안의 내용은 blocking\nshowSomeData()의 async 시작 부분은 nonblocking\nshowSomeData()의 async 내부는 blocking\nshowSomeData()의 withContext 부분은 blocking\n이 코드는 blocking과 nonblocking이 매우 많이 뒤섞여있다.\n이런 코드가 아주 흔한 일이다. 여기서 동기와 비동기 부분을 명확히 이해해야 데이터 흐름을 빠르게 파악할 수 있다.\n이 코드는 이 글의 핵심은 아니지만 동기와 비동기를 이해하는 데 있어 중요한 코드이며, coroutines은 일반적인 함수의 사용만큼이나 쉽다는 점이다.\n\nObserver pattern + stream\n다음 문장은 어떤 부분을 설명하는 걸까?\n\n물이 흐르고 있다. 이 흐르는 물에 새로운 물줄기를 추가했다.\n\n\n이 설명은 개발에서 HotFlow/HotObserve에 대한 설명일 수 있지만 내가 적었으니 맞다.\n여기서 중요한 부분은 무엇일까?\n바로 흐름(flow)이다. Observer pattern에서 데이터 흐름을 설명하는 쉬운 방법 중 하나이다.\n물이 흐른다는 표현을 적었으니 흐르는구나를 알 수 있고, 지속적인 흐름을 의미할 수 있다.\n반대로 흐르지 않는 경우도 있는데 어떻게 설명해 볼 수 있을까?\n\n나는 얼음이다. 땡 해주기 전에는 움직일 수 없다.\n\n\n\nCoroutines flow는?\nAsynchronous Flow - link\nA suspending function asynchronously returns a single value, but how can we return multiple asynchronously computed values? This is where Kotlin Flows come in.\n코루틴 flow는 단일 값을 한 번씩 호출하여 사용할 수 있는 suspend 대신 지속적인 흐름을 가지기 위한 개념을 포함한다. 바로 Observer + stream을 포함한다.\n\nHotFlow/ColdFlow?\n서문에 적은 설명은 오류를 가질 수 있지만 HotFlow/ColdFlow를 각각 설명하기 쉬운 주제라고 생각하여 필자가 주로 설명하는 방식이다.\nHotFlow는 두 가지가 존재하는데\nStateFlow\nSharedFlow\n사용법이 다를 뿐 둘 다 HotFlow이다.\nColdFlow는\nflow {}\nflowOf()\nflow의 시작점이다.\n\n추가로 - O 어떤 걸로 구성되어 있을까?\n이 글에서는 상세한 내용을 알아보기 위해서 적는 글은 아니니 가볍게 가볍게 어떤 구성으로 이루어져 있을까만 적어본다.\n얼음이거나 물이 흐르거나로 표현할 수 있었던 이유는 흐르는 물 사이에 새로운 물줄기를 만들거나 얼음을 깨어 새로운 데이터 흐름을 추가할 수 있다는 소리인데\n요즘 안드로이드에서는 잘 사용하지 않는 ReactiveX 문서에는 여전히\n\nReactiveX is a combination of the best ideas from\nthe Observer pattern, the Iterator pattern, and functional programming\n\n\n이라고 표현하고 있다.\n이 데이터 흐름을 이해하기 위해서는 결국 Observer pattern과 Iterator pattern 만 알아도 충분히 이해할 수 있다는 이야기다.\n그럼 안드로이드 개발에서 상태의 기억을 가지는 3가지 나열해 보면 아래와 같다.\nRxJava - Subject 패턴들 4가지가 있으나 상황에 따라 다른 사용을 가짐\nStateFlow\nLiveData\n이들은 모두 데이터의 제공과 이를 소비하는 패턴으로 만들어져있다.\n이때 중요한 부분은 불변으로 데이터를 소비할 수 있도록 만들어주는 데 있다. 불변과 equals/hashCode의 중요성을 각각 확인할 수 있는 관련 글 2개를 링크로 추가한다.\nItem 1. 가변성을 제한하라 - 안정성 - link\n[Kotlin/Java] HashSet, HashMap 내부 구현 살펴보기 - link\n추가로 RxJava를 제외한 Flow와 LiveData는 Android에서 라이프 사이클에 따른 처리가 잘 되어있는 반면 RxJava는 직접 처리해야 할 부분이 많고 현재는 레거시로 취급되니 궁금하신 분은 RxJava 관련 문서를 참고하시길\n\nUDF(unidirectional data flow)\n아키텍처를 적극 사용하는 현재는 데이터 흐름이 복잡할 수밖에 없다. 이를 가장 쉽게 설명할 수 있는 부분이 바로 UDF이다.\nArchitecting your Compose UI - UDF 부분 참고 - link\nUDF는 단방향 데이터 플로우인데, 위에서 설명한 blocking, nonblocking 역시 단방향 플로우를 가진다.\nA 함수를 실행\nB 함수의 처리\n다시 A 함수로 돌아와 이어가기\n데이터 흐름상 단방향이다.\nObserver pattern + stream에서는?\nA 함수를 실행\nB 함수에 구독을 요청하고, stream으로 데이터 흐름을 전달 받는 대기\nA 함수로 돌아와 A 함수는 끝나고, Stream의 데이터 흐름을 대기\n동기와 비동기가 적절하게 포함되어 있는 형태이다.\n\n아키텍처에서의 UDF\nUDF는 데이터 흐름을 쉽게 이해하는 데 이를 아주 쉽게 설명한 설명이다.\n모든 흐름은 함수의 호출과 그 함수 안에서 새로운 함수의 호출 또는 구독으로 이루어진다. 이를 설명하는 가장 쉬운 방법이 UDF 인 것이다.\n그럼 아래의 코드에 대해서 UDF로 설명해 보자.\n\n@Composable\nfun Screen(viewModel: SomeViewModel) {\n    val someUiState by viewModel.someUiState.collectAsStateWithLifecycle()\n    \n    Screen(\n        someUiState = someUiState,\n        onClick = { viewModel.fatchSome() },\n    )\n}\n\n@Composable\nfun Screen(\n    someUiState: SomeUiState,\n    onClick: () -> Unit,\n) {\n    Button(\n        onClick = onClick,\n    )\n}\n\nclass SomeViewModel(\n    private val someRepository: SomeRepository,\n) {\n    private val _uiState = MutableStateFlow(SomeUiState.Default)\n    val uiState = _uiState.asStateFlow()\n\n    init {\n        someRepository.flowSome()\n            .map { it.toState() }\n            .onEach { _uiState.value = it }\n            .launchIn(viewModelScope)\n    }\n\n    fun fatchSome() = viewModelScope.launch {\n        someRepository.fatchSome()\n    }\n}\n\ninterface SomeRepository {\n\n    fun flowSome(): Flow<SomeEntity>\n\n    suspend fun fatchSome()\n}\n\ncalss SomeRepsotiryImpl(\n    private val api: SomeApi,\n) : SomeRepository {\n\n    private val flowSome = MutableStateFlow<SomeEntity?>(null)\n\n    override fun flowSome(): Flow<SomeEntity> =\n        flowSome.filterNotNull()\n\n    override suspend fun fatchSome() {\n        val resutl = api.fatchSome()\n        flowSome.value = result.toEntity()\n    }\n}\n\n\n코드에 대한 설명은 제외하고 데이터 흐름만을 알아보자.\n사용자의 onClick Event를 Composable 함수 Screen에서 발생\nViewModel fatchSome() 함수가 호출\nViewModel에서는 fatchSome() 함수에서 repository의 fatchSome() 함수를 호출\n    \nrepository에서는 fatchSome 함수의 응답을 지속적인 흐름을 가지기 위해 flow를 별도로 가진다\nrepository에서는 someApi를 통해 fatchSome()을 호출한다.\n응답받은 fatchSome()의 결과를 flowSome에 전달한다.\nViewModel에서는 구독 중인 flowSome으로부터 응답을 받고, 상태를 변환하여 UI에 통지하여 UI를 갱신한다.\n이 코드는 아주 일반적인 UiState를 서버와의 통신을 통해 갱신하기 위한 부분이다. 여기서 조금 더 나아가면 리엑트의 이펙트까지 포함할 수 있다.\n말은 길지만 이 방식은 UDF로 설명하지 않았을 뿐 오래전부터 써오던 방식이다.\n그리고 다른 사람들에게 설명하는 가장 간단한 프로세스인데, 필자의 블로그에서도 다양하게 확인할 수 있는 과거의 글들이 많이 있다.\nUDF. 단방향을 통해 데이터 흐름을 설명할 수 있다는 부분이 중요한 포인트이다.\n이 시점에서 추가로 알아두면 좋은 글들을 나열한다.\nJetpack Compose로 UI 조합(Composition)하기 심화 - link\nCompose 함수는 어떤 조건으로 나누는것이 좋을까?(Stateful, stateless) - link\nMVVM에서 MVI로 - link\n[Android / Compose] Circuit 찍먹 해보기 - link\nComposable 함수를 어떻게 분리하는 것이 좋을지에 대한 글과 MVI에 대한 설명의 글이다.\n그리고 직전에 작성했던 Theme를 다루는 내용도 있으니 함께 보아도 좋을 듯하다.\n안드로이드 Theme와 GetStream Theme를 알아보고 CompositionLocalProvider의 역할을 알아본다. - link\n\n서버와의 데이터 흐름\n데이터 흐름의 마지막을 서버와 데이터 흐름을 이야기해 볼 수 있지만 자세한 내용은 없이 어떤 도구를 활용하는지 정도만 이야기해 보려 한다.\n클라 입장에서는 서버와의 데이터 통신할 때는 json을 주로 활용한다. 최근에는 protobuf를 활용하는 곳도 많은데 장/단점이 있으니 각각 기술은 서버 개발자와 논의하면 좋다.\njson : JSON(JavaScript Object Notation) - link\nxml : Extensible Markup Language (XML) - link\nprotobuf : Protocol Buffers (Protobuf) - link\n데이터 흐름을 얼마나 더 넓게 보는지에 따라 서버에서 제공하는 직전까지의 데이터 흐름으로 설명할 것인지, 이를 넘어가서 설명할 것인지도 정의할 수 있을 것 같다.\n우리는 string 형태의 데이터를 주고받는 것이 일반적이지만 결국 이런 데이터는 0/1의 데이터로 변환된다.\n\n서버까지 포함하여 데이터의 개념은?\n필자는 클라 개발자라 서버에 대해 자세한 이해는 없으니 가볍게 설명해 보겠다.\n클라에서의 데이터 응답을 http 통신을 통해 요청하게 된다.\n    \n이때 http는 블로킹 상태로 클라에서는 서버가 응답을 주기 전까지 대기하는데, 이때 클라에서는 UI 상 사용자에게 처리 중임을 알려준다.\n서버는 캐싱 상태를 체크하고, DB 서버에 응답을 요청한다.\nDB 서버는 동기/비동기 상태로 entity를 전달해 주고, 이를 기반으로 클라와 약속한 json 데이터로 변환 후 bloking 상태의 http에 응답해 준다.\n클라 입장에서는 nonblocking이겠지만 nonblocking 이후에는 모두 blocking 상태로 서버도 동작한다는 점이다.\n서버는 사실상 blocking 작업 상태처럼 보이지만 nonblocking으로 보일 수 있다. 그 안에서 또 nonblocking 작업들이 일어나는 것이다.\n모든 처리가 완료되면 클라이언트는 이를 바탕으로 UI에 표현하는 작업을 할 수 있다.\n여기서는 아키텍처 개념이 포함될 수 있지만 이 글에서는 다루지 않고, 좀 더 넓은 개념의 아키텍처에 대한 이야기를 준비 중이다.\n\n데이터 흐름으로 리액트를 이해할 수 있을까?\n리덕스에 대해 제미나이의 응답은 아래와 같다.\n\n리덕스(Redux)는 자바스크립트 애플리케이션의 상태 관리를 위한 예측 가능한 상태 컨테이너이다.\n쉽게 말해, 애플리케이션의 데이터를 효율적으로 관리하고 예측 가능하게 만들어주는 도구라고 할 수 있다.\n\n\n이미 많은 안드로이드 개념에서 리덕스 개념이 포함되어 있는데, UiState와 UDF? 부분일 것 같다.\n필자가 직접 iOS TCA를 접하고 있는데, 직접 써보고, 설명을 통해 파악한 리덕스 개념은 아래와 같다.\nThe Composable Architecture - link\n이벤트의 흐름 : 이벤트의 흐름은 최종 사용자가 가장 아래에 있으니 이를 거슬러 올라가듯 설명한다.\n  현재 나의 이벤트가 보이는 화면상이라면 이를 이전 화면에 전달한다. 이런 흐름의 설명이 업스트림으로 설명할 수 있다.\n데이터 흐름 : 데이터는 위에서 아래로 흘러간다.\n  데이터 최신화 시 아래로 아래로 흘러간다. 이런 데이터 흐름을 통해 내가 필요한 부분을 캐치하고 화면을 갱신할 수 있다.\n검색과 짧은 지식으로 정리할 수 있는 개념은 딱 요 정도일 것 같다. Redux의 데이터 흐름 글이 있어 링크를 추가한다.\nRedux의 데이터 흐름 - link\n그리고 안드로이드에서 리액트 형태를 가장 잘 구현한 코드가 드로이드 카이기 아닐까 하여 링크를 추가한다.\nDroidKaigi 2024 official app - link\n\n마무리\n데이터 흐름을 이해한다는 것은 더 많은 것을 볼 수 있고, 파악할 수 있음을 뜻한다고 생각한다.\n짝퉁처럼 개념을 이해하는 데 도움이 될 수 있으면 좋겠지만 이 글에서도 알 수 있는데 동기/비동기/ReactiveX 개념까지 알면 이를 통해 리액트의 리덕스 개념도 이해할 수 있는 시점이 된 것 같다.\n아직 부족한 부분이 많아서 이 내용으로 모든 걸 다 설명할 순 없지만 어느 정도 충분히 가장 표면적인 내용을 이해하는 데 도움이 되었길.\n마지막으로 재웅님의 안드로이드 면접 질문과 관련한 내용 중 compose 개념 설명이 잘 되어있어 링크를 추가한다.\nTop 9 Android Developer Interview Questions You Should Know - link",
        "guid": "https://thdev.tech/dataflow/2024/11/09/Data-flow/",
        "isoDate": "2024-11-09T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "VirtualBox 네트워크",
        "link": "https://kangmyounghun.blogspot.com/2024/11/virtualbox.html",
        "pubDate": "2024-11-10T05:02:00.004Z",
        "author": "강명훈",
        "content": "<div>집에서 잘 되는 브리지 모드가 밖에만 나가면 안 돼서 NAT 모드를 쓰는데 VM 복제 시 IP가 바뀌지 않는다. 맥어드레스를 바꿔도 안 됨. machine-id가 같아서 그런가?</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiNV-Xvln_p9C1dmXVmTNiGL5WQYVxIorVE6a1LhkZcc-I6ZD3YcdSFVjZXAh3XWVW68I0JeFkk-CjEsKSOD5vY1gkXO4-HAWGciNXFyLeFdqB4xtDZlDirPDHkqEO2jZhntXXIShCdF_Mefp2GZd6AlabKp1KZlAyBJNMnpCl-fLt_ngS3-9c84eK64Cjs/s795/virtualbox_nat.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"531\" data-original-width=\"795\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiNV-Xvln_p9C1dmXVmTNiGL5WQYVxIorVE6a1LhkZcc-I6ZD3YcdSFVjZXAh3XWVW68I0JeFkk-CjEsKSOD5vY1gkXO4-HAWGciNXFyLeFdqB4xtDZlDirPDHkqEO2jZhntXXIShCdF_Mefp2GZd6AlabKp1KZlAyBJNMnpCl-fLt_ngS3-9c84eK64Cjs/s16000/virtualbox_nat.png\" /></a></div><div></div><span><a name='more'></a></span><div><div><pre><code><div>[root@Snort ~]# ifconfig eth0</div><div>eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;&nbsp; mtu 1500</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet 10.0.2.15&nbsp; netmask 255.255.255.0&nbsp; broadcast 10.0.2.255</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet6 fe80::a00:27ff:fe6b:e0d9&nbsp; prefixlen 64&nbsp; scopeid 0x20&lt;link&gt;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; ether 08:00:27:6b:e0:d9&nbsp; txqueuelen 1000&nbsp; (Ethernet)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX packets 675055&nbsp; bytes 999902873 (953.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX errors 0&nbsp; dropped 0&nbsp; overruns 0&nbsp; frame 0</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX packets 78402&nbsp; bytes 4788435 (4.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX errors 0&nbsp; dropped 0 overruns 0&nbsp; carrier 0&nbsp; collisions 0</div></code></pre></div></div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjDOBwpWHacDeVJeHd4sjv0o7NEjtlc0R0b0K6eAxthyn7t4oAVWgfJvvt8lee2_rDM67KBOExMXOmfxrpcIzDY3D4_2LmnU3Z89Y4leIBSqmVB1sErMEoGlEj-HOGCWhoiqjkVGwRYsk5X3PDfIorBrlazSNwNyi3QlZXBSyFlofgIVvZEoaiU6F-qN_T6/s795/virtualbox_nat2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"531\" data-original-width=\"795\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjDOBwpWHacDeVJeHd4sjv0o7NEjtlc0R0b0K6eAxthyn7t4oAVWgfJvvt8lee2_rDM67KBOExMXOmfxrpcIzDY3D4_2LmnU3Z89Y4leIBSqmVB1sErMEoGlEj-HOGCWhoiqjkVGwRYsk5X3PDfIorBrlazSNwNyi3QlZXBSyFlofgIVvZEoaiU6F-qN_T6/s16000/virtualbox_nat2.png\" /></a></div><div><div><pre><code><div>[root@Snort ~]# ifconfig eth0</div><div>eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;&nbsp; mtu 1500</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet 10.0.2.15&nbsp; netmask 255.255.255.0&nbsp; broadcast 10.0.2.255</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet6 fe80::a00:27ff:fe6b:e0d9&nbsp; prefixlen 64&nbsp; scopeid 0x20&lt;link&gt;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; ether 08:00:27:6b:e0:d9&nbsp; txqueuelen 1000&nbsp; (Ethernet)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX packets 675055&nbsp; bytes 999902873 (953.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX errors 0&nbsp; dropped 0&nbsp; overruns 0&nbsp; frame 0</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX packets 78402&nbsp; bytes 4788435 (4.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX errors 0&nbsp; dropped 0 overruns 0&nbsp; carrier 0&nbsp; collisions 0</div></code></pre></div><br /></div><div><b><span style=\"font-size: x-large;\">NAT Network</span></b></div><div><br /></div><div>도구 &gt; 만들기 &gt; Nat Network 생성.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgsQDsetx-nF5g0uu5_y4bHOoCnIeldiewynH4wiTVu0cZ0KEi-v_Pyq0WEywZyvY9MgmimYmYoGYYpqtSMNsGYPabmM0lxCgCZ87TVeIrfW0sQ4QIRnAaIrS9k7r4QbC-MGxKQSl3zgYXuq92ExaHQcmpWetqQ8zO5bNiRf1Ax9hU2brihpXRuY0dSNwcJ/s904/virtualbox_nat_network.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"593\" data-original-width=\"904\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgsQDsetx-nF5g0uu5_y4bHOoCnIeldiewynH4wiTVu0cZ0KEi-v_Pyq0WEywZyvY9MgmimYmYoGYYpqtSMNsGYPabmM0lxCgCZ87TVeIrfW0sQ4QIRnAaIrS9k7r4QbC-MGxKQSl3zgYXuq92ExaHQcmpWetqQ8zO5bNiRf1Ax9hU2brihpXRuY0dSNwcJ/s16000/virtualbox_nat_network.png\" /></a></div><div><br /></div><div>어댑터 설정을 'NAT -&gt; NAT 네트워크'로 수정. 이후 맥어드레스 변경도 필수.</div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhc0DWCPTEN-rr5xnCYM0LdyhjXbcUZUMank6cVwbOfeT2sH9-OKnOnfvkpmgnjuVP_YIxDihd4iNQIs2PnHF9OiTQN_zvveHrQfkCB_cAJeh_1DuyvR13TeP-Klg-7EQgACBoUmJdnafmCfoT_PKRs7SQXDGHc350Y0m3jEhhCY4QdfTv6o1BRqVuBTdi1/s795/virtualbox_nat_network2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"531\" data-original-width=\"795\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhc0DWCPTEN-rr5xnCYM0LdyhjXbcUZUMank6cVwbOfeT2sH9-OKnOnfvkpmgnjuVP_YIxDihd4iNQIs2PnHF9OiTQN_zvveHrQfkCB_cAJeh_1DuyvR13TeP-Klg-7EQgACBoUmJdnafmCfoT_PKRs7SQXDGHc350Y0m3jEhhCY4QdfTv6o1BRqVuBTdi1/s16000/virtualbox_nat_network2.png\" /></a></div><div><div><pre><code><div>[root@Snort ~]# ifconfig eth0</div><div>eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;&nbsp; mtu 1500</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet 10.0.2.15&nbsp; netmask 255.255.255.0&nbsp; broadcast 10.0.2.255</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet6 fe80::a00:27ff:fe6b:e0d9&nbsp; prefixlen 64&nbsp; scopeid 0x20&lt;link&gt;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; ether 08:00:27:6b:e0:d9&nbsp; txqueuelen 1000&nbsp; (Ethernet)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX packets 675055&nbsp; bytes 999902873 (953.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX errors 0&nbsp; dropped 0&nbsp; overruns 0&nbsp; frame 0</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX packets 78402&nbsp; bytes 4788435 (4.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX errors 0&nbsp; dropped 0 overruns 0&nbsp; carrier 0&nbsp; collisions 0</div></code></pre></div></div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh13CUPx8mNmMYlfofiDXHPW3FEGIR-kihIhLGZy8Qpt0sGHV3cSZuhWSuRjhyOQKo23DXd_zzJp8wjH5LIGBetAJKXjBWtk-9u8p_ADPXHryzIGWbg-mrNF-bOM1C2KD2RQAwjGQySeBIWlXXvrqgrYOHuylqScI3GjRVRFKBe1c7yeS-hj92YlRUK6qW-/s795/virtualbox_nat_network3.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"531\" data-original-width=\"795\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh13CUPx8mNmMYlfofiDXHPW3FEGIR-kihIhLGZy8Qpt0sGHV3cSZuhWSuRjhyOQKo23DXd_zzJp8wjH5LIGBetAJKXjBWtk-9u8p_ADPXHryzIGWbg-mrNF-bOM1C2KD2RQAwjGQySeBIWlXXvrqgrYOHuylqScI3GjRVRFKBe1c7yeS-hj92YlRUK6qW-/s16000/virtualbox_nat_network3.png\" /></a></div><div><div><pre><code><div>[root@Snort ~]# ifconfig eth0</div><div>eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;&nbsp; mtu 1500</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet 10.0.2.4&nbsp; netmask 255.255.255.0&nbsp; broadcast 10.0.2.255</div><div>&nbsp; &nbsp; &nbsp; &nbsp; inet6 fe80::a00:27ff:fe6b:e0d9&nbsp; prefixlen 64&nbsp; scopeid 0x20&lt;link&gt;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; ether 08:00:27:6b:e0:d9&nbsp; txqueuelen 1000&nbsp; (Ethernet)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX packets 675055&nbsp; bytes 999902873 (953.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; RX errors 0&nbsp; dropped 0&nbsp; overruns 0&nbsp; frame 0</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX packets 78402&nbsp; bytes 4788435 (4.5 MiB)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; TX errors 0&nbsp; dropped 0 overruns 0&nbsp; carrier 0&nbsp; collisions 0</div></code></pre></div><br /></div><div>이 간단한 걸 몰라서 여태 헤맸네<span style=\"font-size: x-small;\">(..)</span></div><div><br /></div>",
        "contentSnippet": "집에서 잘 되는 브리지 모드가 밖에만 나가면 안 돼서 NAT 모드를 쓰는데 VM 복제 시 IP가 바뀌지 않는다. 맥어드레스를 바꿔도 안 됨. machine-id가 같아서 그런가?\n\n\n\n\n\n\n\n[root@Snort ~]# ifconfig eth0\neth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 10.0.2.15  netmask 255.255.255.0  broadcast 10.0.2.255\n        inet6 fe80::a00:27ff:fe6b:e0d9  prefixlen 64  scopeid 0x20<link>\n        ether 08:00:27:6b:e0:d9  txqueuelen 1000  (Ethernet)\n        RX packets 675055  bytes 999902873 (953.5 MiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 78402  bytes 4788435 (4.5 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n\n\n\n\n\n[root@Snort ~]# ifconfig eth0\neth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 10.0.2.15  netmask 255.255.255.0  broadcast 10.0.2.255\n        inet6 fe80::a00:27ff:fe6b:e0d9  prefixlen 64  scopeid 0x20<link>\n        ether 08:00:27:6b:e0:d9  txqueuelen 1000  (Ethernet)\n        RX packets 675055  bytes 999902873 (953.5 MiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 78402  bytes 4788435 (4.5 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n\n\nNAT Network\n\n\n도구 > 만들기 > Nat Network 생성.\n\n\n\n\n\n어댑터 설정을 'NAT -> NAT 네트워크'로 수정. 이후 맥어드레스 변경도 필수.\n\n\n\n\n[root@Snort ~]# ifconfig eth0\neth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 10.0.2.15  netmask 255.255.255.0  broadcast 10.0.2.255\n        inet6 fe80::a00:27ff:fe6b:e0d9  prefixlen 64  scopeid 0x20<link>\n        ether 08:00:27:6b:e0:d9  txqueuelen 1000  (Ethernet)\n        RX packets 675055  bytes 999902873 (953.5 MiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 78402  bytes 4788435 (4.5 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n\n\n\n\n\n\n[root@Snort ~]# ifconfig eth0\neth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 10.0.2.4  netmask 255.255.255.0  broadcast 10.0.2.255\n        inet6 fe80::a00:27ff:fe6b:e0d9  prefixlen 64  scopeid 0x20<link>\n        ether 08:00:27:6b:e0:d9  txqueuelen 1000  (Ethernet)\n        RX packets 675055  bytes 999902873 (953.5 MiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 78402  bytes 4788435 (4.5 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n\n\n이 간단한 걸 몰라서 여태 헤맸네(..)",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-8727583642918527329",
        "isoDate": "2024-11-10T05:02:00.004Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕홍",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김놀부",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "엑셀의 눈금선 색상을 변경하는 방법",
        "link": "http://muzbox.tistory.com/483496",
        "pubDate": "Mon, 11 Nov 2024 18:47:31 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483496#entry483496comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;Microsoft Excel에서 기본 그리드라인 색상을 변경하는 방법을 소개합니다. 기존의 회색에서 사용자가 원하는 색상으로 설정해, 시각적 효과를 향상시킬 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"엑셀 눈금선 색상 변경 방법.png\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/rEWXm/btsKE1NhK14/ZW5mvf3AUU38kDmgAo5kAk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/rEWXm/btsKE1NhK14/ZW5mvf3AUU38kDmgAo5kAk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/rEWXm/btsKE1NhK14/ZW5mvf3AUU38kDmgAo5kAk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FrEWXm%2FbtsKE1NhK14%2FZW5mvf3AUU38kDmgAo5kAk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"엑셀의 눈금선 색상을 변경하는 방법\" data-filename=\"엑셀 눈금선 색상 변경 방법.png\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;Microsoft Excel을 사용할 때 기본적으로 제공되는 회색 그리드라인을 별로 신경 쓰지 않았던 적이 있으신가요? 저 역시 25년 넘게 Excel을 사용하면서 그리드라인 색상에 대한 생각은 해본 적이 없었어요. 하지만 최근, Excel에서 기본 그리드라인 색상을 자유롭게 변경할 수 있는 설정을 발견했습니다. 이 기능을 활용하면 문서의 가독성을 높이고, 시각적으로 더 매력적인 스프레드시트를 만들 수 있습니다. 오늘은 Excel에서 그리드라인 색상을 변경하는 방법을 소개해 드릴게요.  </p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>Microsoft Excel 그리드라인 색상 변경 방법</b></span></h2>\n<h3 data-ke-size=\"size23\"><b><span style=\"color: #ee2323;\">Excel 옵션 메뉴에서 색상 변경</span></b></h3>\n<p data-ke-size=\"size16\"><b>1. Excel을 열고</b> 상단 메뉴에서 <b>파일(File)</b>을 클릭한 후, <b>옵션(Options)</b>으로 이동합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"01.png\" data-origin-width=\"1203\" data-origin-height=\"687\"><span data-url=\"https://blog.kakaocdn.net/dn/ZnPDh/btsKFn98J9E/SZ3WS9tkYXPsPCcukzjkk1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ZnPDh/btsKFn98J9E/SZ3WS9tkYXPsPCcukzjkk1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/ZnPDh/btsKFn98J9E/SZ3WS9tkYXPsPCcukzjkk1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FZnPDh%2FbtsKFn98J9E%2FSZ3WS9tkYXPsPCcukzjkk1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"01.png\" data-origin-width=\"1203\" data-origin-height=\"687\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>2.고급(Advanced)</b> 탭을 클릭하고, 스크롤을 내려 <b>현재 시트의 표시 옵션(Display options for this worksheet)</b> 항목을 찾습니다. <b>그리드라인 색상(Gridline color)</b> 선택기에서 원하는 색상을 선택합니다. <b>확인(OK)</b> 버튼을 눌러 설정을 저장합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"02.png\" data-origin-width=\"936\" data-origin-height=\"678\"><span data-url=\"https://blog.kakaocdn.net/dn/ofMKS/btsKDUVK4no/xeCD1frU2xjZYCrjKkTDzk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ofMKS/btsKDUVK4no/xeCD1frU2xjZYCrjKkTDzk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/ofMKS/btsKDUVK4no/xeCD1frU2xjZYCrjKkTDzk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FofMKS%2FbtsKDUVK4no%2FxeCD1frU2xjZYCrjKkTDzk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"02.png\" data-origin-width=\"936\" data-origin-height=\"678\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">3. 이제 문서에서 회색 그리드라인이 아닌, 사용자가 설정한 색상이 적용된 것을 볼 수 있습니다. 예를 들어, 빨간색으로 변경하면 다음과 같이 시트가 표시됩니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"03.png\" data-origin-width=\"1203\" data-origin-height=\"687\"><span data-url=\"https://blog.kakaocdn.net/dn/bI9sxR/btsKEeNhgan/Odn4ZfmLXl8lBa0zRKIxJk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bI9sxR/btsKEeNhgan/Odn4ZfmLXl8lBa0zRKIxJk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bI9sxR/btsKEeNhgan/Odn4ZfmLXl8lBa0zRKIxJk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbI9sxR%2FbtsKEeNhgan%2FOdn4ZfmLXl8lBa0zRKIxJk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"03.png\" data-origin-width=\"1203\" data-origin-height=\"687\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>색상 변경 시 유의 사항</b></span></h3>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>이 설정은 <b>현재 작업 중인 시트에만 적용</b>되며, 다른 Excel 파일이나 새로 생성하는 파일에는 적용되지 않습니다.</li>\n<li>다시 기본 색상으로 되돌리고 싶다면, 동일한 경로에서 <b>'자동(Automatic)'</b>으로 변경하면 됩니다.</li>\n<li>이 설정은 모든 최신 Excel 버전에서 사용할 수 있습니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>색상 변경의 활용 방법</b></span></h2>\n<p data-ke-size=\"size16\">Excel에서 그리드라인 색상을 변경하면, 시트의 가독성을 높이고, 중요한 데이터를 강조할 수 있습니다. 특히, 여러 시트 간에 시각적인 구분을 두고 싶을 때 유용하게 활용할 수 있습니다. 예를 들어, 재무 보고서에서 특정 시트의 데이터가 강조되어야 할 때 색상을 다르게 설정해 보세요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>마치며</b></span></h2>\n<p data-ke-size=\"size16\">Excel의 기본 설정을 활용하여 시각적인 변화를 줄 수 있다는 점이 참 흥미롭습니다. 이처럼 작은 변화가 문서의 가독성을 크게 높일 수 있어요. 여러분도 지금 바로 Excel을 열어, 그리드라인 색상을 변경해 보세요!  </p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>Q&amp;A</b></span></h2>\n<p data-ke-size=\"size18\"><b>Q1: Excel 그리드라인 색상을 변경해도 새 파일에는 적용되지 않나요?</b></p>\n<p data-ke-size=\"size18\">네, 현재 변경한 색상은 <b>현재 작업 중인 시트에만 적용</b>되며, 새 파일에는 기본 설정이 적용됩니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\"><b>Q2: 모든 버전의 Excel에서 그리드라인 색상을 변경할 수 있나요?</b></p>\n<p data-ke-size=\"size18\">네, 이 기능은 <b>모든 최신 Excel 버전에서 지원</b>됩니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\"><b>Q3: 그리드라인 색상 변경이 작업 속도에 영향을 줄 수 있나요?</b></p>\n<p data-ke-size=\"size18\">그리드라인 색상 변경은 <b>시각적 효과만 조정</b>할 뿐, Excel의 성능이나 작업 속도에는 영향을 주지 않습니다.</p>",
        "contentSnippet": "Microsoft Excel에서 기본 그리드라인 색상을 변경하는 방법을 소개합니다. 기존의 회색에서 사용자가 원하는 색상으로 설정해, 시각적 효과를 향상시킬 수 있습니다.\n \n\n\n \n Microsoft Excel을 사용할 때 기본적으로 제공되는 회색 그리드라인을 별로 신경 쓰지 않았던 적이 있으신가요? 저 역시 25년 넘게 Excel을 사용하면서 그리드라인 색상에 대한 생각은 해본 적이 없었어요. 하지만 최근, Excel에서 기본 그리드라인 색상을 자유롭게 변경할 수 있는 설정을 발견했습니다. 이 기능을 활용하면 문서의 가독성을 높이고, 시각적으로 더 매력적인 스프레드시트를 만들 수 있습니다. 오늘은 Excel에서 그리드라인 색상을 변경하는 방법을 소개해 드릴게요.  \n \n \nMicrosoft Excel 그리드라인 색상 변경 방법\nExcel 옵션 메뉴에서 색상 변경\n1. Excel을 열고 상단 메뉴에서 파일(File)을 클릭한 후, 옵션(Options)으로 이동합니다.\n\n\n \n \n2.고급(Advanced) 탭을 클릭하고, 스크롤을 내려 현재 시트의 표시 옵션(Display options for this worksheet) 항목을 찾습니다. 그리드라인 색상(Gridline color) 선택기에서 원하는 색상을 선택합니다. 확인(OK) 버튼을 눌러 설정을 저장합니다.\n\n\n \n3. 이제 문서에서 회색 그리드라인이 아닌, 사용자가 설정한 색상이 적용된 것을 볼 수 있습니다. 예를 들어, 빨간색으로 변경하면 다음과 같이 시트가 표시됩니다.\n\n\n \n \n색상 변경 시 유의 사항\n이 설정은 현재 작업 중인 시트에만 적용되며, 다른 Excel 파일이나 새로 생성하는 파일에는 적용되지 않습니다.\n다시 기본 색상으로 되돌리고 싶다면, 동일한 경로에서 '자동(Automatic)'으로 변경하면 됩니다.\n이 설정은 모든 최신 Excel 버전에서 사용할 수 있습니다.\n \n색상 변경의 활용 방법\nExcel에서 그리드라인 색상을 변경하면, 시트의 가독성을 높이고, 중요한 데이터를 강조할 수 있습니다. 특히, 여러 시트 간에 시각적인 구분을 두고 싶을 때 유용하게 활용할 수 있습니다. 예를 들어, 재무 보고서에서 특정 시트의 데이터가 강조되어야 할 때 색상을 다르게 설정해 보세요.\n \n마치며\nExcel의 기본 설정을 활용하여 시각적인 변화를 줄 수 있다는 점이 참 흥미롭습니다. 이처럼 작은 변화가 문서의 가독성을 크게 높일 수 있어요. 여러분도 지금 바로 Excel을 열어, 그리드라인 색상을 변경해 보세요!  \n \n \nQ&A\nQ1: Excel 그리드라인 색상을 변경해도 새 파일에는 적용되지 않나요?\n네, 현재 변경한 색상은 현재 작업 중인 시트에만 적용되며, 새 파일에는 기본 설정이 적용됩니다.\n \nQ2: 모든 버전의 Excel에서 그리드라인 색상을 변경할 수 있나요?\n네, 이 기능은 모든 최신 Excel 버전에서 지원됩니다.\n \nQ3: 그리드라인 색상 변경이 작업 속도에 영향을 줄 수 있나요?\n그리드라인 색상 변경은 시각적 효과만 조정할 뿐, Excel의 성능이나 작업 속도에는 영향을 주지 않습니다.",
        "guid": "http://muzbox.tistory.com/483496",
        "categories": [
          "오피스 프로그램 사용법/엑셀",
          "excel 설정",
          "excel 활용법",
          "엑셀",
          "엑셀 고급 설정",
          "엑셀 눈금선 색상변경",
          "엑셀 눈금선 칼라변경",
          "엑셀 팁"
        ],
        "isoDate": "2024-11-11T09:47:31.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "윈도우11 라이센스 OEM, Retail, Volume 차이와 확인 방법",
        "link": "http://muzbox.tistory.com/483495",
        "pubDate": "Fri, 8 Nov 2024 17:07:33 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483495#entry483495comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;윈도우11 라이센스 종류 확인하는 방법을 알아보세요. OEM, Retail, Volume 라이센스의 차이와 확인 방법을 상세히 안내해 드립니다. 올바른 라이센스 확인으로 정품 인증 문제를 예방하세요!</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"윈도우11 라인센스 확인방법.jpg\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/DQXHg/btsKBTWxCTW/KEE5kQ3xORAbKvECgGXgLk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/DQXHg/btsKBTWxCTW/KEE5kQ3xORAbKvECgGXgLk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/DQXHg/btsKBTWxCTW/KEE5kQ3xORAbKvECgGXgLk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FDQXHg%2FbtsKBTWxCTW%2FKEE5kQ3xORAbKvECgGXgLk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"윈도우11 라이센스 OEM, Retail, Volume 차이와 확인 방법\" data-filename=\"윈도우11 라인센스 확인방법.jpg\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;여러분은 윈도우11을 사용하면서 자신의 <b>윈도우 라이센스 종류</b>가 무엇인지 궁금해 본 적 있으신가요?   새로운 PC를 구입했거나 중고로 PC를 구매할 경우, 설치된 윈도우가 <b>정품인지 확인</b>하는 것은 매우 중요합니다. 특히, 라이센스 종류에 따라 PC 변경 시 재설치 가능 여부나 사용 제한이 달라질 수 있기 때문에, 자신이 보유한 라이센스 유형을 정확히 파악하는 것이 필요합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;윈도우11 라이센스는 OEM, Retail, Volume 라이센스로 크게 나뉘며, 각 유형마다 특징이 다릅니다. 이 글에서는 <b>윈도우11 라이센스 종류를 쉽게 확인하는 방법</b>을 단계별로 안내하고, 각 라이센스의 차이점을 설명해 드리겠습니다. 이 정보를 통해 여러분의 PC 라이센스를 더욱 효율적으로 관리하고 활용할 수 있기를 바랍니다.  </p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>윈도우11 라이센스 종류 이해하기</b></span></h2>\n<p data-ke-size=\"size16\">윈도우11의 라이센스는 사용 목적과 배포 방식에 따라 크게 <b>OEM</b>, <b>Retail</b>, <b>Volume</b>의 세 가지로 구분됩니다. 각 라이센스 유형은 설치, 재설치, PC 변경 시의 사용 제한 조건이 다릅니다. 아래에서 각각의 라이센스 유형을 자세히 설명드리겠습니다.</p>\n<h3 data-ke-size=\"size23\"><b><span style=\"color: #ee2323;\">  1. OEM 라이센스</span></b></h3>\n<p data-ke-size=\"size16\">OEM(Original Equipment Manufacturer) 라이센스는 주로 <b>PC 제조사</b>에서 사전에 설치된 상태로 제공되는 윈도우 버전입니다. 여러분이 새로 구입한 노트북이나 데스크탑 컴퓨터에는 대부분 이 OEM 라이센스가 포함되어 있을 것입니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>특징 및 사용 제한</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>특정 PC 하드웨어에 종속되며, <b>해당 PC에서만 사용 가능</b>합니다.</li>\n<li>만약 메인보드와 같은 주요 하드웨어를 교체하면 라이센스가 무효화될 수 있습니다.</li>\n<li>재설치는 가능하지만, 동일한 PC 내에서만 가능합니다.</li>\n</ul>\n</li>\n<li><b>장점</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>초기 설정이 완료된 상태로 제공되므로, 별도의 설치 과정 없이 바로 사용할 수 있어 <b>편리합니다</b>.</li>\n<li>상대적으로 저렴한 가격으로 제공됩니다.</li>\n</ul>\n</li>\n<li><b>단점</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>다른 PC로 <b>라이센스를 이전할 수 없으므로</b> 중고 PC를 구매할 때 주의해야 합니다.</li>\n<li>PC를 교체하거나 하드웨어를 업그레이드할 경우 <b>추가 라이센스 구매</b>가 필요할 수 있습니다.</li>\n</ul>\n</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>  2. Retail(리테일) 라이센스</b></span></h3>\n<p data-ke-size=\"size16\">리테일 라이센스는 일반 사용자들이 <b>마이크로소프트 스토어</b>나 공식 판매처에서 직접 구매할 수 있는 버전입니다. <b>가정용 사용자</b>나 <b>프리랜서</b>에게 가장 적합한 라이센스로, 기존 PC에서 새로운 PC로 <b>자유롭게 이전이 가능합니다</b>.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>특징 및 사용 제한</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>여러 번 재설치 가능하며, <b>다른 PC로 라이센스를 이전</b>할 수 있습니다.</li>\n<li>정품 인증을 받은 후에도 다른 PC로 이동할 수 있지만, <b>동시에 두 대의 PC에서 사용할 수는 없습니다</b>.</li>\n</ul>\n</li>\n<li><b>장점</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>PC 변경 시 <b>자유롭게 라이센스 이전</b>이 가능하므로, 새로운 PC를 구매하더라도 추가 비용이 들지 않습니다.</li>\n<li>고객 지원 및 업데이트가 보장되므로, <b>문제 발생 시 마이크로소프트의 지원</b>을 받을 수 있습니다.</li>\n</ul>\n</li>\n<li><b>단점</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>OEM 라이센스에 비해 <b>가격이 높습니다</b>.</li>\n<li>온라인 구매 시 가짜 라이센스에 주의해야 합니다.</li>\n</ul>\n</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"><b>  3. Volume(볼륨) 라이센스</b></span></h3>\n<p data-ke-size=\"size16\">볼륨 라이센스는 주로 <b>기업이나 교육 기관</b>에서 대량으로 구매하는 라이센스 방식입니다. 대규모로 운영되는 조직에서 여러 대의 PC에 윈도우를 설치할 수 있도록 지원합니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>특징 및 사용 제한</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>여러 대의 PC에 동일한 라이센스 키를 사용하여 <b>대량 배포</b>할 수 있습니다.</li>\n<li>특정 기간 동안 유효한 <b>정품 인증 서버(KMS)</b>를 사용하여 인증합니다.</li>\n</ul>\n</li>\n<li><b>장점</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>대량 구매 시 비용을 절감</b>할 수 있어, IT 예산이 제한된 기업에 유리합니다.</li>\n<li>중앙 집중식 관리가 가능해, <b>조직 내 PC의 일괄 관리 및 유지보수</b>가 편리합니다.</li>\n</ul>\n</li>\n<li><b>단점</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>개인 사용자에게는 구매 및 사용이 <b>제한됩니다</b>.</li>\n<li>기간 만료 시 정품 인증이 해제되므로, <b>정기적인 갱신이 필요</b>합니다.</li>\n</ul>\n</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>윈도우11 라이센스 종류 확인 방법</b></span></h2>\n<p data-ke-size=\"size16\">이제 자신의 윈도우11 라이센스 종류를 확인하는 방법을 소개하겠습니다. 특히, 중고 PC를 구매했거나 라이센스를 이전할 계획이 있을 때 유용하게 사용할 수 있는 팁입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">윈도우11에서 라이센스 종류를 확인하는 가장 쉬운 방법 중 하나는 <b>명령 프롬프트(CMD)</b>를 사용하는 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>Step 1</b>: <code>윈도우 검색창</code>에 <code>cmd</code>를 입력한 후, '명령 프롬프트'를 <b>관리자 권한으로 실행</b>합니다. ▼</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"01.png\" data-origin-width=\"800\" data-origin-height=\"457\"><span data-url=\"https://blog.kakaocdn.net/dn/beUhuL/btsKCwGD3yg/J4wLLH8OOxwNkcmkTqAXJ1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/beUhuL/btsKCwGD3yg/J4wLLH8OOxwNkcmkTqAXJ1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/beUhuL/btsKCwGD3yg/J4wLLH8OOxwNkcmkTqAXJ1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbeUhuL%2FbtsKCwGD3yg%2FJ4wLLH8OOxwNkcmkTqAXJ1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"01.png\" data-origin-width=\"800\" data-origin-height=\"457\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\"><br /><b>Step 2</b><span style=\"letter-spacing: 0px;\">: 아래의 명령어를 입력한 후 Enter를 누릅니다. ▼</span></p>\n<pre class=\"jboss-cli\" style=\"letter-spacing: 0px;\"><code>slmgr /dli</code></pre>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>결과</b>: 몇 초 후 팝업 창이 열리며, <b>설치된 라이센스의 종류</b>(OEM, Retail, Volume)가 표시됩니다.</li>\n</ul>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"02.png\" data-origin-width=\"800\" data-origin-height=\"438\"><span data-url=\"https://blog.kakaocdn.net/dn/vksGi/btsKC3qnPfU/WxFYCJysaVCmCi7uKa9vE0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/vksGi/btsKC3qnPfU/WxFYCJysaVCmCi7uKa9vE0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/vksGi/btsKC3qnPfU/WxFYCJysaVCmCi7uKa9vE0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FvksGi%2FbtsKC3qnPfU%2FWxFYCJysaVCmCi7uKa9vE0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"02.png\" data-origin-width=\"800\" data-origin-height=\"438\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>마치며</b></span></h2>\n<p data-ke-size=\"size16\">윈도우11 라이센스 종류를 정확히 파악하는 것은 PC 사용 시 매우 중요합니다. 특히, 새로 구매한 PC의 라이센스가 정품인지 확인하거나 기존 PC를 업그레이드할 때 유용하게 활용할 수 있습니다. 이번 기회에 여러분의 윈도우 라이센스 상태를 확인하여 불필요한 비용 낭비를 줄여보세요!  </p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>Q&amp;A</b></span></h2>\n<h3 data-ke-size=\"size23\">Q1. OEM 라이센스를 Retail 라이센스로 변경할 수 있나요?</h3>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>직접 변경할 수는 없지만, <b>Retail 라이센스를 추가 구매</b>하여 새롭게 설치할 수는 있습니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\">Q2. 윈도우11 라이센스를 다른 PC로 이전할 수 있나요?</h3>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>Retail 라이센스는 가능하지만, <b>OEM 라이센스는 특정 PC에 종속되므로 이전이 불가능</b>합니다.</li>\n</ul>\n<h3 data-ke-size=\"size23\">Q3. 중고 PC 구매 시 정품 인증 상태를 확인하려면 어떻게 해야 하나요?</h3>\n<p data-ke-size=\"size16\">명령 프롬프트에서 <code>slmgr /dli</code> 명령어를 사용하여 <b>정품 여부와 라이센스 종류를 확인</b>하세요.</p>",
        "contentSnippet": "윈도우11 라이센스 종류 확인하는 방법을 알아보세요. OEM, Retail, Volume 라이센스의 차이와 확인 방법을 상세히 안내해 드립니다. 올바른 라이센스 확인으로 정품 인증 문제를 예방하세요!\n\n\n \n 여러분은 윈도우11을 사용하면서 자신의 윈도우 라이센스 종류가 무엇인지 궁금해 본 적 있으신가요?   새로운 PC를 구입했거나 중고로 PC를 구매할 경우, 설치된 윈도우가 정품인지 확인하는 것은 매우 중요합니다. 특히, 라이센스 종류에 따라 PC 변경 시 재설치 가능 여부나 사용 제한이 달라질 수 있기 때문에, 자신이 보유한 라이센스 유형을 정확히 파악하는 것이 필요합니다.\n \n 윈도우11 라이센스는 OEM, Retail, Volume 라이센스로 크게 나뉘며, 각 유형마다 특징이 다릅니다. 이 글에서는 윈도우11 라이센스 종류를 쉽게 확인하는 방법을 단계별로 안내하고, 각 라이센스의 차이점을 설명해 드리겠습니다. 이 정보를 통해 여러분의 PC 라이센스를 더욱 효율적으로 관리하고 활용할 수 있기를 바랍니다.  \n \n윈도우11 라이센스 종류 이해하기\n윈도우11의 라이센스는 사용 목적과 배포 방식에 따라 크게 OEM, Retail, Volume의 세 가지로 구분됩니다. 각 라이센스 유형은 설치, 재설치, PC 변경 시의 사용 제한 조건이 다릅니다. 아래에서 각각의 라이센스 유형을 자세히 설명드리겠습니다.\n  1. OEM 라이센스\nOEM(Original Equipment Manufacturer) 라이센스는 주로 PC 제조사에서 사전에 설치된 상태로 제공되는 윈도우 버전입니다. 여러분이 새로 구입한 노트북이나 데스크탑 컴퓨터에는 대부분 이 OEM 라이센스가 포함되어 있을 것입니다.\n특징 및 사용 제한\n\n특정 PC 하드웨어에 종속되며, 해당 PC에서만 사용 가능합니다.\n만약 메인보드와 같은 주요 하드웨어를 교체하면 라이센스가 무효화될 수 있습니다.\n재설치는 가능하지만, 동일한 PC 내에서만 가능합니다.\n장점\n\n초기 설정이 완료된 상태로 제공되므로, 별도의 설치 과정 없이 바로 사용할 수 있어 편리합니다.\n상대적으로 저렴한 가격으로 제공됩니다.\n단점\n\n다른 PC로 라이센스를 이전할 수 없으므로 중고 PC를 구매할 때 주의해야 합니다.\nPC를 교체하거나 하드웨어를 업그레이드할 경우 추가 라이센스 구매가 필요할 수 있습니다.\n \n  2. Retail(리테일) 라이센스\n리테일 라이센스는 일반 사용자들이 마이크로소프트 스토어나 공식 판매처에서 직접 구매할 수 있는 버전입니다. 가정용 사용자나 프리랜서에게 가장 적합한 라이센스로, 기존 PC에서 새로운 PC로 자유롭게 이전이 가능합니다.\n특징 및 사용 제한\n\n여러 번 재설치 가능하며, 다른 PC로 라이센스를 이전할 수 있습니다.\n정품 인증을 받은 후에도 다른 PC로 이동할 수 있지만, 동시에 두 대의 PC에서 사용할 수는 없습니다.\n장점\n\nPC 변경 시 자유롭게 라이센스 이전이 가능하므로, 새로운 PC를 구매하더라도 추가 비용이 들지 않습니다.\n고객 지원 및 업데이트가 보장되므로, 문제 발생 시 마이크로소프트의 지원을 받을 수 있습니다.\n단점\n\nOEM 라이센스에 비해 가격이 높습니다.\n온라인 구매 시 가짜 라이센스에 주의해야 합니다.\n \n  3. Volume(볼륨) 라이센스\n볼륨 라이센스는 주로 기업이나 교육 기관에서 대량으로 구매하는 라이센스 방식입니다. 대규모로 운영되는 조직에서 여러 대의 PC에 윈도우를 설치할 수 있도록 지원합니다.\n특징 및 사용 제한\n\n여러 대의 PC에 동일한 라이센스 키를 사용하여 대량 배포할 수 있습니다.\n특정 기간 동안 유효한 정품 인증 서버(KMS)를 사용하여 인증합니다.\n장점\n\n대량 구매 시 비용을 절감할 수 있어, IT 예산이 제한된 기업에 유리합니다.\n중앙 집중식 관리가 가능해, 조직 내 PC의 일괄 관리 및 유지보수가 편리합니다.\n단점\n\n개인 사용자에게는 구매 및 사용이 제한됩니다.\n기간 만료 시 정품 인증이 해제되므로, 정기적인 갱신이 필요합니다.\n \n윈도우11 라이센스 종류 확인 방법\n이제 자신의 윈도우11 라이센스 종류를 확인하는 방법을 소개하겠습니다. 특히, 중고 PC를 구매했거나 라이센스를 이전할 계획이 있을 때 유용하게 사용할 수 있는 팁입니다.\n \n윈도우11에서 라이센스 종류를 확인하는 가장 쉬운 방법 중 하나는 명령 프롬프트(CMD)를 사용하는 것입니다.\n \nStep 1: 윈도우 검색창에 cmd를 입력한 후, '명령 프롬프트'를 관리자 권한으로 실행합니다. ▼\n\n\n\nStep 2: 아래의 명령어를 입력한 후 Enter를 누릅니다. ▼\nslmgr /dli\n결과: 몇 초 후 팝업 창이 열리며, 설치된 라이센스의 종류(OEM, Retail, Volume)가 표시됩니다.\n\n\n \n마치며\n윈도우11 라이센스 종류를 정확히 파악하는 것은 PC 사용 시 매우 중요합니다. 특히, 새로 구매한 PC의 라이센스가 정품인지 확인하거나 기존 PC를 업그레이드할 때 유용하게 활용할 수 있습니다. 이번 기회에 여러분의 윈도우 라이센스 상태를 확인하여 불필요한 비용 낭비를 줄여보세요!  \n \n \nQ&A\nQ1. OEM 라이센스를 Retail 라이센스로 변경할 수 있나요?\n직접 변경할 수는 없지만, Retail 라이센스를 추가 구매하여 새롭게 설치할 수는 있습니다.\nQ2. 윈도우11 라이센스를 다른 PC로 이전할 수 있나요?\nRetail 라이센스는 가능하지만, OEM 라이센스는 특정 PC에 종속되므로 이전이 불가능합니다.\nQ3. 중고 PC 구매 시 정품 인증 상태를 확인하려면 어떻게 해야 하나요?\n명령 프롬프트에서 slmgr /dli 명령어를 사용하여 정품 여부와 라이센스 종류를 확인하세요.",
        "guid": "http://muzbox.tistory.com/483495",
        "categories": [
          "윈도우 사용팁/윈도우11 사용법",
          "OEM",
          "pc 라이센스 이전",
          "powershell 활용",
          "retail",
          "라이센스 확인",
          "명령어 사용법",
          "볼륨 라이센스",
          "윈도우 설정",
          "윈도우11",
          "정품 인증"
        ],
        "isoDate": "2024-11-08T08:07:33.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "애드센스 인페이지 광고 최적화 방법 (광고수, 광고 노출 간격)",
        "link": "http://muzbox.tistory.com/483494",
        "pubDate": "Wed, 6 Nov 2024 10:05:16 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483494#entry483494comment",
        "content": "<p data-ke-size=\"size16\">구글 애드센스 인페이지 광고 노출 수와 배치 간격 설정 방법을 알아보세요. 사용자 경험을 고려한 최적화 전략을 통해 수익성을 높일 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"구글 애드센스 인페이지광고 설정방법.png\" data-origin-width=\"991\" data-origin-height=\"731\"><span data-url=\"https://blog.kakaocdn.net/dn/dXoyJ8/btsKxjgOQwc/CaBNYOiMl1JwD2KYK344W1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dXoyJ8/btsKxjgOQwc/CaBNYOiMl1JwD2KYK344W1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dXoyJ8/btsKxjgOQwc/CaBNYOiMl1JwD2KYK344W1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdXoyJ8%2FbtsKxjgOQwc%2FCaBNYOiMl1JwD2KYK344W1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"애드센스 인페이지 광고 최적화 방법\" width=\"600\" height=\"443\" data-filename=\"구글 애드센스 인페이지광고 설정방법.png\" data-origin-width=\"991\" data-origin-height=\"731\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;구글 애드센스의 인페이지 형식 광고는 광고가 웹 콘텐츠와 자연스럽게 어우러져 사용자들이 쉽게 받아들일 수 있는 광고 형식입니다. 하지만 무조건적인 광고 배치는 오히려 사이트의 가독성을 떨어뜨리거나 사용자 이탈률을 높일 수 있습니다. 그렇다면 애드센스 인페이지 광고의 노출 수와 배치 간격을 어떻게 최적화할 수 있을까요? 이번 글에서 그 구체적인 방법을 알려드립니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000; text-align: start;\" data-ke-size=\"size26\">애드센스 인페이지 광고 설정방법</h2>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\">먼저, 애드센스에서 제공하는 인페이지 광고의 노출 수를 적절히 설정하는 것이 중요합니다. 너무 많은 광고가 페이지에 노출될 경우 사용자의 집중력이 분산되거나 광고에 대한 피로감이 생길 수 있습니다. 따라서 웹페이지의 길이와 내용에 따라 광고의 노출 수를 조정하는 것이 좋습니다.</p>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\">1. 애드센스 방문 후 좌측 메뉴에서 \"광고\"를 선택한 후 해당사이트에서&nbsp; ✏️&nbsp; 수정 버튼을 클릭합니다.▼</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"01.png\" data-origin-width=\"1309\" data-origin-height=\"720\"><span data-url=\"https://blog.kakaocdn.net/dn/euctUP/btsKw6aHgS0/pnIsFoQGthhujXI84dvbw0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/euctUP/btsKw6aHgS0/pnIsFoQGthhujXI84dvbw0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/euctUP/btsKw6aHgS0/pnIsFoQGthhujXI84dvbw0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FeuctUP%2FbtsKw6aHgS0%2FpnIsFoQGthhujXI84dvbw0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"01.png\" data-origin-width=\"1309\" data-origin-height=\"720\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">2. 자동광고 설정을 활성화 한 후 - 인페이지 형식을 클릭합니다. ▼</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"02.png\" data-origin-width=\"1311\" data-origin-height=\"777\"><span data-url=\"https://blog.kakaocdn.net/dn/FVELc/btsKyqGdb5Q/6TkaQ0TNKKSW7JgS7tkoD1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/FVELc/btsKyqGdb5Q/6TkaQ0TNKKSW7JgS7tkoD1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/FVELc/btsKyqGdb5Q/6TkaQ0TNKKSW7JgS7tkoD1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FFVELc%2FbtsKyqGdb5Q%2F6TkaQ0TNKKSW7JgS7tkoD1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"02.png\" data-origin-width=\"1311\" data-origin-height=\"777\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">3. 그림과 같이 광고 세부조정을 활성화 한 후 - 광고수, 간격등을 조정합니다. 조정이 완료되면 \"사이트에 적용\"버튼을 클릭하면 설정이 종료됩니다. ▼</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"03.png\" data-origin-width=\"1288\" data-origin-height=\"691\"><span data-url=\"https://blog.kakaocdn.net/dn/cuCCqK/btsKw3kY3uG/1Vy6mrdbk3g3RDc51vUbm1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cuCCqK/btsKw3kY3uG/1Vy6mrdbk3g3RDc51vUbm1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cuCCqK/btsKw3kY3uG/1Vy6mrdbk3g3RDc51vUbm1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcuCCqK%2FbtsKw3kY3uG%2F1Vy6mrdbk3g3RDc51vUbm1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"03.png\" data-origin-width=\"1288\" data-origin-height=\"691\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>애드센스 인페이지 광고 노출 수 설정하기</b></span></h2>\n<p data-ke-size=\"size16\">먼저, 애드센스에서 제공하는 인페이지 광고의 노출 수를 적절히 설정하는 것이 중요합니다. 너무 많은 광고가 페이지에 노출될 경우 사용자의 집중력이 분산되거나 광고에 대한 피로감이 생길 수 있습니다. 따라서 웹페이지의 길이와 내용에 따라 광고의 노출 수를 조정하는 것이 좋습니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>단락별 광고 배치</b>: 콘텐츠 길이에 맞춰 단락마다 광고를 배치하면 자연스러운 사용자 경험을 제공합니다. 예를 들어, 긴 글의 경우 첫 단락과 중간, 마지막에 광고를 배치해도 좋습니다.</li>\n<li><b>최대 노출 수 제한</b>: 페이지당 광고 노출 수는 구글의 정책에 따라 제한됩니다. 일반적으로 한 페이지에서 3~4개의 인페이지 광고를 초과하지 않도록 설정하는 것이 적절합니다.</li>\n<li><b>주요 섹션에 광고 배치</b>: 웹사이트에서 가장 눈에 잘 띄는 영역에 인페이지 광고를 배치하면 클릭률을 높이는 데 도움이 됩니다. 예를 들어, 글의 중간 부분이나 종료 직전 부분이 주요 위치로 활용될 수 있습니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>인페이지 광고의 배치 간격 설정하기</b></span></h2>\n<p data-ke-size=\"size16\">광고 배치 간격을 설정할 때는 사용자의 콘텐츠 소비 흐름을 방해하지 않는 것이 핵심입니다. 지나치게 짧은 간격으로 광고를 배치하면 오히려 사용자 경험이 악화될 수 있으므로 적절한 배치 간격을 유지하는 것이 중요합니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>본문 중 2~3 단락마다 배치</b>: 긴 글에서는 2~3 단락마다 한 번씩 광고를 배치하는 것이 자연스러운 흐름을 유지하는 데 효과적입니다.</li>\n<li><b>적당한 스크롤 간격 유지</b>: 스크롤을 통해 사용자들이 광고를 자연스럽게 접할 수 있도록 배치 간격을 조정합니다. 보통 화면 높이 기준으로 2~3개 스크롤 뒤에 광고가 나타나게 하는 것이 좋습니다.</li>\n<li><b>모바일과 데스크탑 구분</b>: 모바일 화면에서는 스크롤 속도가 빨라 광고 간격을 더 길게 설정할 필요가 있습니다. 데스크탑에서는 화면에 보이는 부분을 고려해 배치 간격을 조정합니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>사용자 경험을 고려한 광고 최적화 전략</b></span></h2>\n<p data-ke-size=\"size16\">광고를 효과적으로 배치하면서도 사용자 경험을 고려하는 것이 중요합니다. 사용자 경험을 고려한 광고 최적화 전략을 통해 광고 효과를 높이고 사이트 이탈률을 줄일 수 있습니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>광고 배치 테스트</b>: 여러 위치에 광고를 배치해보고 클릭률 및 이탈률을 분석해 최적의 배치를 찾습니다.</li>\n<li><b>광고와 콘텐츠 구분</b>: 광고가 콘텐츠와 혼동되지 않도록 광고 배경색이나 테두리를 활용해 구분합니다.</li>\n<li><b>속도 최적화</b>: 광고가 사이트 속도를 저하시킬 경우, 사용자 만족도가 떨어질 수 있으므로 로딩 속도를 유지하면서도 적절한 위치에 광고를 배치하는 것이 중요합니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>마치며</b></span></h2>\n<p data-ke-size=\"size16\">구글 애드센스 인페이지 광고의 효과를 극대화하려면, 사용자 경험을 저해하지 않으면서도 자연스럽게 광고가 노출될 수 있는 배치 전략이 필요합니다. 노출 수와 배치 간격을 잘 설정하면 광고 수익을 증대시키는 동시에 사용자 경험도 긍정적으로 유지할 수 있습니다. 실험과 분석을 통해 최적의 배치를 찾아보세요!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>Q&amp;A</b></span></h2>\n<h3 data-ke-size=\"size23\">Q1. 인페이지 광고와 배너 광고의 차이는 무엇인가요?</h3>\n<p data-ke-size=\"size16\"><b>A1.</b> 인페이지 광고는 콘텐츠와 자연스럽게 어우러져 표시되며, 사용자가 콘텐츠를 소비하면서 광고도 자연스럽게 보게 되는 형식입니다. 배너 광고는 주로 페이지 상단, 사이드바, 하단 등에 고정된 형태로 노출됩니다.</p>\n<h3 data-ke-size=\"size23\">Q2. 애드센스에서 광고 노출 수가 제한되는 이유는 무엇인가요?</h3>\n<p data-ke-size=\"size16\"><b>A2.</b> 구글 애드센스는 과도한 광고 노출로 인한 사용자 경험 저하를 방지하기 위해 광고 노출 수를 제한합니다. 이를 통해 광고주와 사용자 모두에게 긍정적인 경험을 제공하고자 합니다.</p>\n<h3 data-ke-size=\"size23\">Q3. 모바일과 데스크탑에서 광고 배치 전략이 다른 이유는 무엇인가요?</h3>\n<p data-ke-size=\"size16\"><b>A3.</b> 모바일에서는 화면 크기가 작고 스크롤 속도가 빠르기 때문에, 광고 간격을 더 넓게 설정하는 것이 효과적입니다. 데스크탑에서는 더 많은 광고를 한 화면에 자연스럽게 배치할 수 있어 전략이 다르게 적용됩니다.</p>",
        "contentSnippet": "구글 애드센스 인페이지 광고 노출 수와 배치 간격 설정 방법을 알아보세요. 사용자 경험을 고려한 최적화 전략을 통해 수익성을 높일 수 있습니다.\n\n\n \n 구글 애드센스의 인페이지 형식 광고는 광고가 웹 콘텐츠와 자연스럽게 어우러져 사용자들이 쉽게 받아들일 수 있는 광고 형식입니다. 하지만 무조건적인 광고 배치는 오히려 사이트의 가독성을 떨어뜨리거나 사용자 이탈률을 높일 수 있습니다. 그렇다면 애드센스 인페이지 광고의 노출 수와 배치 간격을 어떻게 최적화할 수 있을까요? 이번 글에서 그 구체적인 방법을 알려드립니다.\n \n애드센스 인페이지 광고 설정방법\n먼저, 애드센스에서 제공하는 인페이지 광고의 노출 수를 적절히 설정하는 것이 중요합니다. 너무 많은 광고가 페이지에 노출될 경우 사용자의 집중력이 분산되거나 광고에 대한 피로감이 생길 수 있습니다. 따라서 웹페이지의 길이와 내용에 따라 광고의 노출 수를 조정하는 것이 좋습니다.\n \n1. 애드센스 방문 후 좌측 메뉴에서 \"광고\"를 선택한 후 해당사이트에서  ✏️  수정 버튼을 클릭합니다.▼\n\n\n \n2. 자동광고 설정을 활성화 한 후 - 인페이지 형식을 클릭합니다. ▼\n\n\n \n3. 그림과 같이 광고 세부조정을 활성화 한 후 - 광고수, 간격등을 조정합니다. 조정이 완료되면 \"사이트에 적용\"버튼을 클릭하면 설정이 종료됩니다. ▼\n\n\n \n \n애드센스 인페이지 광고 노출 수 설정하기\n먼저, 애드센스에서 제공하는 인페이지 광고의 노출 수를 적절히 설정하는 것이 중요합니다. 너무 많은 광고가 페이지에 노출될 경우 사용자의 집중력이 분산되거나 광고에 대한 피로감이 생길 수 있습니다. 따라서 웹페이지의 길이와 내용에 따라 광고의 노출 수를 조정하는 것이 좋습니다.\n단락별 광고 배치: 콘텐츠 길이에 맞춰 단락마다 광고를 배치하면 자연스러운 사용자 경험을 제공합니다. 예를 들어, 긴 글의 경우 첫 단락과 중간, 마지막에 광고를 배치해도 좋습니다.\n최대 노출 수 제한: 페이지당 광고 노출 수는 구글의 정책에 따라 제한됩니다. 일반적으로 한 페이지에서 3~4개의 인페이지 광고를 초과하지 않도록 설정하는 것이 적절합니다.\n주요 섹션에 광고 배치: 웹사이트에서 가장 눈에 잘 띄는 영역에 인페이지 광고를 배치하면 클릭률을 높이는 데 도움이 됩니다. 예를 들어, 글의 중간 부분이나 종료 직전 부분이 주요 위치로 활용될 수 있습니다.\n \n인페이지 광고의 배치 간격 설정하기\n광고 배치 간격을 설정할 때는 사용자의 콘텐츠 소비 흐름을 방해하지 않는 것이 핵심입니다. 지나치게 짧은 간격으로 광고를 배치하면 오히려 사용자 경험이 악화될 수 있으므로 적절한 배치 간격을 유지하는 것이 중요합니다.\n본문 중 2~3 단락마다 배치: 긴 글에서는 2~3 단락마다 한 번씩 광고를 배치하는 것이 자연스러운 흐름을 유지하는 데 효과적입니다.\n적당한 스크롤 간격 유지: 스크롤을 통해 사용자들이 광고를 자연스럽게 접할 수 있도록 배치 간격을 조정합니다. 보통 화면 높이 기준으로 2~3개 스크롤 뒤에 광고가 나타나게 하는 것이 좋습니다.\n모바일과 데스크탑 구분: 모바일 화면에서는 스크롤 속도가 빨라 광고 간격을 더 길게 설정할 필요가 있습니다. 데스크탑에서는 화면에 보이는 부분을 고려해 배치 간격을 조정합니다.\n \n사용자 경험을 고려한 광고 최적화 전략\n광고를 효과적으로 배치하면서도 사용자 경험을 고려하는 것이 중요합니다. 사용자 경험을 고려한 광고 최적화 전략을 통해 광고 효과를 높이고 사이트 이탈률을 줄일 수 있습니다.\n광고 배치 테스트: 여러 위치에 광고를 배치해보고 클릭률 및 이탈률을 분석해 최적의 배치를 찾습니다.\n광고와 콘텐츠 구분: 광고가 콘텐츠와 혼동되지 않도록 광고 배경색이나 테두리를 활용해 구분합니다.\n속도 최적화: 광고가 사이트 속도를 저하시킬 경우, 사용자 만족도가 떨어질 수 있으므로 로딩 속도를 유지하면서도 적절한 위치에 광고를 배치하는 것이 중요합니다.\n \n마치며\n구글 애드센스 인페이지 광고의 효과를 극대화하려면, 사용자 경험을 저해하지 않으면서도 자연스럽게 광고가 노출될 수 있는 배치 전략이 필요합니다. 노출 수와 배치 간격을 잘 설정하면 광고 수익을 증대시키는 동시에 사용자 경험도 긍정적으로 유지할 수 있습니다. 실험과 분석을 통해 최적의 배치를 찾아보세요!\n \n \nQ&A\nQ1. 인페이지 광고와 배너 광고의 차이는 무엇인가요?\nA1. 인페이지 광고는 콘텐츠와 자연스럽게 어우러져 표시되며, 사용자가 콘텐츠를 소비하면서 광고도 자연스럽게 보게 되는 형식입니다. 배너 광고는 주로 페이지 상단, 사이드바, 하단 등에 고정된 형태로 노출됩니다.\nQ2. 애드센스에서 광고 노출 수가 제한되는 이유는 무엇인가요?\nA2. 구글 애드센스는 과도한 광고 노출로 인한 사용자 경험 저하를 방지하기 위해 광고 노출 수를 제한합니다. 이를 통해 광고주와 사용자 모두에게 긍정적인 경험을 제공하고자 합니다.\nQ3. 모바일과 데스크탑에서 광고 배치 전략이 다른 이유는 무엇인가요?\nA3. 모바일에서는 화면 크기가 작고 스크롤 속도가 빠르기 때문에, 광고 간격을 더 넓게 설정하는 것이 효과적입니다. 데스크탑에서는 더 많은 광고를 한 화면에 자연스럽게 배치할 수 있어 전략이 다르게 적용됩니다.",
        "guid": "http://muzbox.tistory.com/483494",
        "categories": [
          "Google 이야기/애드센스 노하우",
          "CTR",
          "광고노출수",
          "광고배치",
          "광고최적화",
          "구글애드센스",
          "데스크탑광고",
          "모바일광고",
          "배치간격",
          "사용자경험",
          "인페이지광고"
        ],
        "isoDate": "2024-11-06T01:05:16.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "(RULIWEB`Д')/",
        "title": "[MULTI] 못내 아쉬운 그러나 대체불가능한, 삼국지 8 리메이크",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2266",
        "pubDate": "Fri, 08 Nov 2024 19:49:24 +0900",
        "author": "(RULIWEB`Д')/",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/24/11/08/1930b62f0c14c329e.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2024-11-08T10:49:24.000Z"
      },
      {
        "creator": "「RULIWEB」",
        "title": "[MULTI] 모부삼 이상 콜드워 미만, 콜 오브 듀티: 블랙 옵스 6",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2265",
        "pubDate": "Thu, 07 Nov 2024 19:43:18 +0900",
        "author": "「RULIWEB」",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i1.ruliweb.com/thumb/24/11/07/1930630bba84cacdc.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2024-11-07T10:43:18.000Z"
      },
      {
        "creator": "샤말란의눈",
        "title": "[PS5] PS5 프로, 스펙 및 실제 게임에서의 시각적 차이",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2264",
        "pubDate": "Wed, 06 Nov 2024 20:10:16 +0900",
        "author": "샤말란의눈",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i1.ruliweb.com/thumb/24/11/04/192f2a45a1313b2a1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2024-11-06T11:10:16.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": [
      {
        "title": "경력이 쌓이면서 했던 고민들과 깨달은 것들",
        "link": "https://zzsza.github.io/diary/2024/11/08/thoughts-and-learnings-in-careers/",
        "pubDate": "Fri, 08 Nov 2024 00:00:00 +0000",
        "content": "<ul>\n  <li>이 글은 경력이 쌓이면서 했던 고민들과 깨달은 내용에 대해 작성한 글입니다</li>\n  <li>멘토링 때 종종 이 주제들에 대한 질문을 받아 글을 작성해봅니다</li>\n  <li>키워드 : 경력, 커리어, 개발자 커리어, 성장</li>\n</ul>\n\n<hr />\n\n<h1 id=\"살다-보면-우리는-고민이-생긴다\">살다 보면 우리는 고민이 생긴다</h1>\n<ul>\n  <li>회사에 다니기 전에는 취업 자체에 대한 고민만 했다. 이 시기엔 취업이 되느냐, 어떤 회사에 가느냐 등을 집중적으로 고민했던 것 같음</li>\n  <li>그러나 회사에 가면, 새로운 문제들이 생기기 시작함\n    <ul>\n      <li>회사에서 어떻게 일을 할 것인가?</li>\n      <li>어떻게 인정받을 수 있을까?</li>\n      <li>사람들과 어떻게 지내야 할까?</li>\n      <li>앞으로의 커리어는 어떻게 될까?</li>\n      <li>갑자기 어떤 일도 하기 싫은 번아웃이 온다면 어떻게 해야 할까?</li>\n      <li>내가 회사에서 일을 잘하는지 확인하려면?</li>\n    </ul>\n  </li>\n  <li>위 사례 외에도 굉장히 다양한 종류의 고민들이 생길 수 있고, 멘토링을 할 때 자주 나오는 주제들이다</li>\n  <li>자주 나오는 질문이나 했던 생각들을 정리하려고 한다</li>\n  <li>자세한 이야기를 하기 전에, <strong>이런 고민을 하는 것 자체가 문제가 아니고 내가 발전하려는 향상심이 있기에 생기는 현상</strong>이라고 생각\n    <ul>\n      <li>이런 생각이 드는 것이 당연하니 너무 걱정하지 않으셨으면 좋겠어요</li>\n      <li>이 글의 내용은 제 생각이 맞다는 관점이 아닌, 제가 어떻게 생각했는지를 담은 글입니다. 보시고 다른 생각이 드시면 ‘글쓴이는 이렇게 생각했구나’ 이렇게 생각해 주시면 좋을 것 같아요</li>\n    </ul>\n  </li>\n</ul>\n\n<hr />\n\n<p><br />\n<br /></p>\n\n<h2 id=\"1-좋은-커리어란-무엇일까-앞으로-어떻게-발전해야-할까\">1) 좋은 커리어란 무엇일까? 앞으로 어떻게 발전해야 할까?</h2>\n<ul>\n  <li>생각하게 된 배경\n    <ul>\n      <li>대략 2-3년 차에 많이 생각하는 주제(그러나 그 이후에도 이 고민은 계속된다. 답은 없고, 환경이 변하기 때문. 연차가 쌓이면 새로운 환경에 가고 새로운 의사 결정을 하게 될 수 있음)</li>\n      <li>입사하고 초반엔 새로운 일들이 많아서 해당 내용들을 습득하고, 주어진 일을 하나씩 하면서 정신없이 보냄\n        <ul>\n          <li>그러다가 1, 2년이 지나고 일이 익숙해질 때쯤 커리어에 대해 고민함</li>\n        </ul>\n      </li>\n      <li>이런 고민을 하게 된 배경은 다양하게 존재할 수 있는데, 업무가 지루하다고 생각하거나, 스스로가 생각하는 이 직무가 해야 하는 일이 정의되어 있지만 그걸 안하 고 있어서 고민하는 경우도 있음</li>\n      <li>아마 일이 즐겁고, 보람차고 프로젝트를 잘 진행하고 있다면 이런 고민은 하지 않을 가능성이 존재</li>\n      <li>컨퍼런스에서 발표를 보거나, 외부 요소(취업 시장이 어렵다는 이야기), 친구들과의 비교 등을 통해 이런 고민을 하게 될 수도 있음</li>\n    </ul>\n  </li>\n  <li>제 생각\n    <ul>\n      <li><strong>이 직무를 왜 시작하게 되었는지가 중요하고, 나에 대한 인지(메타인지)</strong>가 있으면 더 깊은 고민을 할 수 있음\n        <ul>\n          <li>내가 이 직무를 왜 하고 싶었는지, 초심은 무엇이었는지 등</li>\n          <li>내가 처음 원했던 방향을 계속 고수해야 한다는 생각은 아니고, 내가 최초의 방향을 잘 생각하고 있는지 고민하며, 그 이후 자신의 경험을 얹어서 새로운 길로 가야 할지 정리하는 것도 괜찮음</li>\n        </ul>\n      </li>\n      <li>살다 보면 초심을 잊고 살아가는 경우가 많고, 초심에 대한 내용을 블로그 등에 작성하고 지속적으로 보는 것도 좋다고 생각함</li>\n      <li><strong>좋은 커리어의 기준은 누가 정해주는 것이 아니라 스스로가 정의해야 함</strong>\n        <ul>\n          <li>다른 사람이 좋다는 A라는 기준이 나중에 시간이 흐르면 다르게 될 수도 있음. 과거의 시기와 요즘은 또 다르게 생각할 수도 있음</li>\n          <li>학생이나 신입은 경험이 없어서 기준이 적을 수 있고, 이럴 땐 다른 사람의 의견을 들어보기도 하는 것도 다 한 번쯤 경험함\n            <ul>\n              <li>그러나 나의 경험을 늘리면서 나만의 생각, 기준을 만들게 됨</li>\n            </ul>\n          </li>\n          <li>일반적으로 많이 나오는 연봉, 워라밸, 동료 등도 중요할 수 있지만 나의 근본적인 욕구나 이 직무를 선택한 이유에 따라 다를 수 있음\n            <ul>\n              <li>인정 욕구가 큰 사람에겐 워라밸보단 내 인정이 더 중요할 수 있음. 인정받기 위해 회사에서 성과를 높이려고 하고, 열심히 일하는 것이 즐거울 수 있음</li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n      <li>제가 생각하는 좋은 커리어는 <strong>“직무 하나에 나를 한정하지 말고 여러 경험을 하는 것. 문제 해결에 집중하는 것. 꾸준하게 계속 무언가를 시도하는 것”</strong>\n        <ul>\n          <li>여러 경험을 하다 보면 하고 싶지 않은 일을 할 수도 있지만, 그런 일도 경험으로 생각하는 편</li>\n          <li>다른 사람들이 하지 않았던 여러 경험들이 합쳐지면 나만의 고유한 영역이 될 수 있다. 제너럴한 영역을 여러 개가 있고, 각 영역을 아주 잘하면 그게 또 새로운 스페셜이 될 수 있다고 생각함</li>\n          <li>직무 관점에서도 MLOps나 Analytics Engineer가 하나의 직무에서 시작된 것이 아닌 다른 직무에서 확장되면서 생기는 직무라고 볼 수 있는데, 이와 유사하다고 생각</li>\n        </ul>\n      </li>\n      <li>저도 고민했던 시기가 있었음. 레트리카에서 데이터 분석가, 데이터 엔지니어 일을 조금씩 했었고 쏘카에선 데이터 분석가, 데이터 과학자, 머신러닝 엔지니어, 데이터 엔지니어, Engineering Manager 등을 경험했는데 너무 여러 가지를 경험해서 고민되기도 했지만 <strong>회사에서 요구하는 나의 역할을 최대한 잘 수행해 보자고 생각함</strong>\n        <ul>\n          <li>여러 경험을 했기에 직무의 협업 구조를 알 수 있고, 어떻게 프로젝트를 시작해야 할지, 사업부에선 어떤 관점으로 생각하는지 등을 모두 이해하게 됨</li>\n          <li>조직을 키우는 경험도 해보면서, 조직의 규모에 따라 어떤 방식으로 운영해야 할지에 대해 고민을 할 수 있게 되었음</li>\n        </ul>\n      </li>\n      <li><strong>때론 지금 하는 행동들에 너무 의지를 부여하지 않아도 괜찮았음. 시간이 지나서 그 의미를 찾는 경우도 있었음</strong>\n        <ul>\n          <li>의미를 너무 찾다가 시간이 지나갈 수도 있다는 이야기. 과거에 했던 것을 생각해보니 의미를 찾은 경우도 있기에 너무 의미를 찾는데 오래 걸린다면 잠시 실행해보는 것도 좋은 방법이라 생각(<strong>의미와 실행의 적절한 밸런스가 중요</strong>하다고 생각)</li>\n        </ul>\n      </li>\n      <li><strong>좋은 커리어의 기준은 시간의 흐름에 따라 다를 수 있다. 내가 어떤 결정을 할지 기준을 가지고 있는지가 더 중요할 수 있음</strong></li>\n      <li>저는 연차별로 성장의 정의가 다 달랐음. 1-2년 차의 성장은 나의 성장, 3-6년차의 성장은 팀과 조직의 성장, 그 이후의 성장은 잘 회복하며 지금 현상 유지하기가 성장이였음. 지금의 성장도 다른 방향으로 가는 중</li>\n    </ul>\n\n    <p><img src=\"https://www.dropbox.com/s/wc0hktxf2q9sher/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-11-08%20%EC%98%A4%ED%9B%84%203.39.30.png?raw=1\" /></p>\n\n    <ul>\n      <li>정리하면 <strong>좋은 커리어의 정의는 내가 하는 것이고, 타인이 정해주지 않음. 나에 대해 생각을 해보고 나의 기준을 만드는 것을 추천함. 또한 시간의 흐름에 따라 성장은 달라질 수 있고 과거의 경험들이 갑자기 깨달음을 주는 경우도 있으니 걱정하지 말고 지금 순간을 잘 지내는 것을 추천함</strong></li>\n    </ul>\n  </li>\n</ul>\n\n<hr />\n\n<p><br />\n<br /></p>\n\n<h2 id=\"2-데이터-과학자-데이터-분석가-데이터-직무의-고민-커리어를-어떻게-발전해야-할까\">2) 데이터 과학자, 데이터 분석가. 데이터 직무의 고민. 커리어를 어떻게 발전해야 할까?</h2>\n<ul>\n  <li>생각하게 된 배경\n    <ul>\n      <li>데이터 과학자나 데이터 분석가는 직무의 구분이 명확하지 않아 많은 사람들이 혼란스러워함(저도 과거에 그랬고, 요즘 커리어를 준비하는 분들도 여전히 혼란스러워함)\n        <ul>\n          <li><a href=\"https://zzsza.github.io/diary/2021/02/21/various-data-jobs/\">다양한 데이터 분석 직군</a> 글을 보면 직무의 이름으로 판단하지 말고 실제 하는 일을 기반으로 판단하라고 작성했음</li>\n        </ul>\n      </li>\n      <li>1번의 고민(좋은 커리어)와 연결되는 부분인데 데이터 직무는 데이터 분석가지만 하는 일이 회사마다 정말 다양함\n        <ul>\n          <li>어떤 회사에선 데이터 엔지니어링을 하면서 인프라도 구축해야 하고,</li>\n          <li>어떤 회사에선 대시보드 제작 위주로 진행되고</li>\n          <li>어떤 회사에선 데이터 추출 요청 위주의 업무가 진행되기도 함</li>\n          <li>위 상황과 더불어 데이터 관련 컨퍼런스에서 보면 다른 사람들은 멋진 업무 위주로 하는 것 같아서 자신과 업무를 비교하게 되는 경우도 존재</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n  <li>제 생각\n    <ul>\n      <li>이럴 때 현타가 오고 이직 준비를 할 수 있음</li>\n      <li>그러나 저는 데이터 관련 어떤 업무를 하더라도, 회사에서 필요한 업무라고 생각함. 다만 회사의 조직 규모의 차이가 있거나 데이터 문화의 차이가 존재할 뿐. 그 시기에 내가 다니고 있을 뿐이라 생각함</li>\n      <li>데이터 문화가 아직 잘 정착하지 못했다면 직접 데이터를 추출해서 제공해야 할 수 있고, 대시보드도 데이터 직무가 만들어야 할 수 있음\n        <ul>\n          <li>이런 상황은 왜 만들어지고, 개선하려면 어떻게 해야 할까?를 고민하는 것도 좋다고 생각</li>\n          <li>그럼 조직의 규모가 점점 커지면서 그 안에서 필요한 역할들이 무엇인지 알 수 있게 됨</li>\n          <li>이 부분은 국가의 발전, 역사 공부를 하면서 어떻게 해야 더 좋은 조직의 구조를 갖출 수 있을까를 생각했음</li>\n        </ul>\n      </li>\n      <li>이왕 업무를 진행할 때, <strong>너무 부정적으로 생각하는 것보다 이 업무를 한국 또는 세상에서 제일 잘하려면 어떻게 해야 할지를 고민함</strong>\n        <ul>\n          <li>단순 데이터 추출도 정말 빠르게 잘하려면? =&gt; 데이터를 잘 정리해 두는 것도 필요하고, 마트를 만드는 것도 필요하고, 쿼리를 실수 없이 작성하는 것도 필요</li>\n          <li>하나의 Task도 더 구체적으로 쪼개보면 필요한 역량이 여러 가지고, 그것을 더 잘하도록 시도할 수 있음</li>\n          <li>게임에서 하기 싫은 노가다 퀘스트를 하는 느낌일 수 있지만, 이런 퀘스트가 있어야 다음 퀘스트를 수월하게 진행할 수 있다고 생각함</li>\n        </ul>\n      </li>\n      <li><strong>다른 사람과 비교하는 순간 자존감이 떨어질 수 있음. 왜냐하면 비교 대상이 대부분 자신보다 더 좋은 상황인 사람과 비교하는 경우가 더 많기 때문</strong>\n        <ul>\n          <li>컨퍼런스에서 발표하는 내용은 부정적인 것보단 긍정적인 것, 인사이트가 있는 것을 주로 발표할 수 있음. 그리고 그 발표가 그 사람의 전부가 아니라 특정 단면을 공유한 것일 수 있음</li>\n          <li><strong>다른 사람의 길이 아닌, 그냥 나의 길을 가보자고 생각하는 것을 추천</strong></li>\n          <li>내 이야기를 영화로 치면 지금 기승전결에서 중간에 있다고 생각하고, 어려운 상황이 나오면 역시 영화에 위기 한번 와야지! 이런 생각을 하곤 함</li>\n        </ul>\n      </li>\n      <li>LLM이 발전하면서 1인 생산성이 늘어나고, 단순한 데이터 추출은 LLM으로 대체하려는 시도가 엄청 많이 존재함. 조만간 SQL 작성은 데이터 직무의 일이 아닐 수 있을 것 같음\n        <ul>\n          <li>대신 데이터 직무가 무엇을 해야 할까? 생각해 보면 사내의 컨설턴트 역할이 될 수도 있고, 데이터 문화를 만드는 역할, 의사 결정을 위주로 하는 역할 등 다양한 역할이 나올 수 있음</li>\n          <li>그러나 미래에도 과거처럼 작은 규모에선 직접 쿼리를 작성하는 시기도 있을 수 있음. 그래서 너무 걱정하는 것보단, 지금 하는 일을 잘하게 되면 나중에 도움이 되지 않을까 싶음</li>\n        </ul>\n      </li>\n      <li>커리어는 점진적으로 발전할 수 있으므로, 너무 조급하게 생각하지 말고 지금 할 수 있는 일부터 점진적으로 하는 것을 추천</li>\n      <li>저도 시간이 지나서 8년 차가 되었음. 그동안의 경험이 아직도 생생한데 시간이 참 빠름.\n        <ul>\n          <li>커리어 초반, 학생 시절엔 <strong>‘내가 될까?’</strong>에 집중했고 가능성이 있는지에 대한 질문을 많이 했음</li>\n          <li>그러다가 경력을 쌓으면서 <strong>‘내가 뭐가 될까’</strong>에 집중했음. 뭐가에 집중하면서 어떻게 해야 할까를 고민했음</li>\n          <li>그러다가 요즘은 <strong>‘내가 뭐든 되네’</strong>라는 생각을 함. 시간이 지나면 무엇이든 된다. 특정 시기에 내가 노력하지 않아도 회사의 업무를 하면서 경험이 쌓이고 있음. 혹은 내 개인 삶의 경험을 풍성하게 만들 수도 있는 것\n            <ul>\n              <li>무엇이든 되니 너무 걱정하지 말고 지금 하고 싶은 것이 뭘까, 어떻게 시간을 보낼까를 고민하고 하나씩 해보는 것이 좋지 않을까 싶음</li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n      <li><strong>저는 ‘커리어의 목표가 무엇인가요?’라는 질문을 받으면 딱히 없고 그냥 오늘같이 하루하루 잘 보내는 것이 목표라고 말함. 장기적인 비전은 있으면 좋지만, 너무 큰 목표같이 느껴질 수 있어서 현실적인 오늘을 잘 살려고 함</strong></li>\n      <li><strong>직무 관점에서 너무 직무 하나에 매몰되지 말고, 내가 얼마나 회사에 기여할 수 있고 사람들에게 도움을 줄 수 있을지를 생각하며 이 기준이 확장될 수 있는 기준으로 일하고 있음</strong></li>\n      <li>정리하면 <strong>어떤 일을 하더라도 회사에서 제일 잘하고, 세계에서 제일 잘하려면 어떻게 해야할까를 생각하면서 나의 길을 가려고 함. 좋은 커리어의 정의는 내가 하는 것이므로 내가 어떻게 하고 싶은지에 기반해서 하나씩 실행함. 직무에 한정되는 사람이 되지 말고 직무를 넘어서는 사람이 되려고 함</strong></li>\n    </ul>\n  </li>\n</ul>\n\n<hr />\n\n<p><br />\n<br /></p>\n\n<h2 id=\"3-좋은-선택-의사-결정이란-무엇일까\">3) 좋은 선택, 의사 결정이란 무엇일까?</h2>\n<ul>\n  <li>생각하게 된 배경\n    <ul>\n      <li>의사 결정이 중요하다는 것은 많이 듣는데 그걸 어떻게 잘하는가에 대해서는 배운 적이 적음. 그러다 보니 How를 고민하게 됨</li>\n      <li>멘토링 때도 종종 받는 질문으로 가장 중요한 순간의 선택, 후회하는 선택 등의 질문을 받음\n        <ul>\n          <li>아마 좋은 의사 결정, 좋은 선택하는 방법을 물어보는 질문이었던 것 같음</li>\n        </ul>\n      </li>\n      <li>의사 결정이 뭔가 한 번에 잘 돼야 할 것 같고, 틀리면 안 될 것 같은 고정 관념이 있었음</li>\n    </ul>\n  </li>\n  <li>제 생각\n    <ul>\n      <li>일단 저는 과거의 선택에 크게 연연하지 않는 성격. 과거 성격을 만약 돌릴 수 있다면 생각을 계속할 것 같은데, 그게 아니니까 현실을 직시한다. 그래서 과거 이야기를 물어봐도 잘 떠오르진 않음</li>\n      <li>이렇게 된 계기를 생각해 보면 20대 중반부터 뭘 해도 잘 되는 경험이 없었음. 실패, 불합격 등이 많았는데 그게 너무 많아지니까 오히려 현실을 너무 낙관하지 않고 적절한 상태로 바라보곤 했다. 그러다가 니체 책을 보고 니체의 사상에 영감을 받음</li>\n      <li>우선 “좋은” 이란 부분에 대한 정의가 필요함. 좋다라는 것은 상황에 따라 다를 수 있고, 구체적으로 정의가 된다면 지표로 나올 수 있음. 다만 지표로 나오지 않는다고 하면 너무 “좋은”에 집중하지 않으려고 함</li>\n      <li><strong>어떤 결정을 할 때, 들뜨지 않고 객관적으로 생각함</strong>\n        <ul>\n          <li>만약 지표로 표시할 수 있다면 지표를 정의한다. 숫자로 특정 상황을 표시하고, 이게 더 좋아지면 간다 등</li>\n          <li><strong>이 숫자가 높아질 때, 낮아질 때 어떤 Action을 할지 생각</strong>한다. 이런 과정을 Mental Simulation이라 부름\n            <ul>\n              <li><strong>멘탈 시뮬레이션은 특정 행동을 하는 것을 상상하고, 행동하기 전에 예상되는 결과를 시뮬레이션하는 능력</strong></li>\n              <li><strong>멘탈 시뮬레이션을 한다면 특정 순간의 지표가 좋지 않아도, 오르기 위해 어떤 것을 해야 할지 생각했으므로 다시 또 실행하면 됨</strong></li>\n            </ul>\n          </li>\n          <li>과거에 아쉬움이 있다면, 한 번 더 시도해서 아쉬움을 타파하면 그만이 아닐까 생각</li>\n          <li>한 번에 잘 되었던 적이 없어서 이 생각을 기본적으로 가지고 있는 것 같음</li>\n        </ul>\n      </li>\n      <li><strong>어떤 경험을 하고, 주기적으로 회고를 하면서 고민한다</strong>. 이 순간에 내가 왜 이 선택을 했지? 이때 뭐가 중요하다고 생각했지?\n        <ul>\n          <li>그 당시 기록이 있다면 그 기록을 보면서 다음엔 어떻게 해볼까를 고민한다</li>\n        </ul>\n      </li>\n      <li><strong>의사 결정 자체에 집중하는 것보다, 의사 결정을 대하는 태도나 의사 결정을 하는 과정에 신경을 쓰게 됨</strong></li>\n      <li><a href=\"https://inf.run/jfWT\">PM을 위한 데이터 리터러시</a> 강의에 의사 결정 파트가 있는데, 그때 의사 결정 TIP을 다음과 같이 공유했음\n        <ul>\n          <li>(1) 답을 내린다는 표현 대신 베팅한다는 표현하기 : 답을 내린다는 것은 너무 부담이 생김</li>\n          <li>(2) 에너지 레벨 고려하기 : 결정을 내리는 과정은 에너지를 많이 소모한다. 에너지를 덜 소모하며 결정할 방법을 고민함(같이 진행하기 등)</li>\n          <li>(3) 당연한 것은 없다 : 당연하다고 생각하지 말고 항상 다시 고민해 보기</li>\n          <li>(4) 개인적인 의사 결정에선 과감히 도전하는 것도 방법 : 회사에서 결정하는 것은 보수적으로 갈 수 있지만, 개인 관점에선 개방적으로 해보는 것도 방법. 이런 시도가 나의 안전지대(Comfort Zone)를 넘어설 수 있게 됨</li>\n          <li>(5) 결정했으면 그 결정이 좋은 결과를 내도록 노력하기 : 결정하고 아무것도 안 하는 것이 아닌 그게 되도록 하는 것이 중요함</li>\n          <li>(6) 사람은 결정으로 인한 실패를 피하고 싶은 성향이 있다 : 결과에 대해 받아들이고, 어떻게 개선할지 생각해 보는 것이 더 중요한 것 같다</li>\n          <li>(7) 큰 결정은 누구나 어렵다. 작은 결정부터 하나씩 : 작은 결정에서 점점 큰 결정으로 가자. 대표님들은 어떻게 결정하고 있는지 살펴보고 간접적으로 나라면? 생각해 보거나 대표님들이 어떤 결정을 어떤 흐름으로 했는지 물어보는 것도 방법</li>\n        </ul>\n      </li>\n      <li>의사 결정, 선택에 대한 원칙을 만들었다.\n        <ul>\n          <li>대표적인 원칙은 <strong>“만약 내일 내가 죽는데, 어떤 일을 하지 않아서 무덤 속에서 뛰쳐나올 것 같다면 지금 하자”</strong>\n            <ul>\n              <li>무덤 속에서 뛰쳐나올 것 같다고 하면 너무 답답해서 해야 할 것으로 생각한다. 그래서 “이거 무덤에서 뛰쳐나올 정도인가?”를 생각하는 편</li>\n            </ul>\n          </li>\n          <li><strong>좋은 결정보단, 상황에서 적절한 결정만 존재한다고 생각함. 그리고 결정하고 그 후의 실행이 중요하다</strong></li>\n          <li>이런 결정 원칙을 여러 개 만들고 주기적으로 수정하면 된다</li>\n          <li>또 다른 저의 원칙은 <a href=\"https://m.yes24.com/Goods/Detail/119016899\">데이터 과학자 원칙</a>에 작성되어 있음. 목차를 공유해 드리면\n            <ul>\n              <li>의도적으로 남다른 선택해보기</li>\n              <li>주기적으로 일하는 목적 찾기</li>\n              <li>제너럴리스트, 스페셜리스트 이분법으로 생각하지 않기</li>\n              <li>업무도 메타인지하며 목적 중심으로 생각하기</li>\n              <li>나의 세상 정의하기</li>\n              <li>회사에서 필요한 일과 내 흥미를 일치시키기</li>\n              <li>팀 현황을 파악해서 개선점 만들기</li>\n              <li>더 나은 커뮤니케이션 능력 기르기</li>\n              <li>비즈니스 모델과 데이터의 접점 분석하기</li>\n              <li>지금 힘들다면 여유가 있는지 생각해보기</li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n      <li>정리하면 <strong>좋은 의사 결정에 집중하는 것이 아닌 현재 상황이 어떤지, 지표로 표시해보고, 앞으로 뭘 해야할지 멘탈 시뮬레이션을 한 후에 결정한다. 결정을 한 후엔, 결정이 잘 될 수 있도록 노력함</strong>\n        <ul>\n          <li><strong>순간 순간엔 좋지 않다고 판단할 수 있지만, 시간이 지나면서 경험이 쌓이면 그런 경험들이 좋은 순간이 될 수 있음</strong></li>\n          <li>그래서 이 결정이 좋은가에 대해 생각하지 않게 된 것 같음. 그냥 내게 있는 정보를 가지고 최선의 수를 두고, 계속 고민할 뿐</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n</ul>\n\n<hr />\n\n<p><br />\n<br /></p>\n\n<h2 id=\"4-번아웃이-오면-어떻게-해야-할까\">4) 번아웃이 오면 어떻게 해야 할까?</h2>\n<ul>\n  <li>생각하게 된 배경\n    <ul>\n      <li>요즘 너무 번아웃이 심하거나 힘든 경우 이런 고민을 하게 된다</li>\n    </ul>\n  </li>\n  <li>제 생각\n    <ul>\n      <li>살다 보면 또 번아웃이 올 수 있다. 물론 회사에서 번아웃이 안 오는 사람들도 있고, 적당히 잘 유지하는 사람들도 있다. 어떤 경우엔 번아웃이었는데 시간이 지나고 깨닫는 경우도 있음</li>\n      <li>번아웃은 열심히 한 사람이 온다고 생각한다\n        <ul>\n          <li>일단 번아웃을 인정하기</li>\n          <li>번아웃을 나쁘게 생각하지 말고 긍정적으로 승화하기</li>\n          <li>잘 하고 있고, 잘 하다가 에너지가 부족해서 번아웃이 된 것. 에너지만 잘 채우면 된다</li>\n        </ul>\n      </li>\n      <li>번아웃 원인 분석하기\n        <ul>\n          <li>번아웃이 왜 오게 되었는가를 생각함</li>\n          <li>회사의 일이 많아서 그럴 수도 있고, 개인 약속이 너무 많아서 그럴 수도 있고, 제대로 쉬지 못해서, 다른 사람들은 잘 하는데 내가 상대적으로 뒤처진다고 생각해서 등 다양한 이유가 있음</li>\n          <li>여러 이유가 있을 수 있는데, 그 이유를 천천히 보면서 어떤 요인이 나를 이렇게 만들었는지 살펴본다. 과거의 경험과 비슷하면 그 요소가 내게 더 영향을 미칠 수 있다고 생각한다</li>\n        </ul>\n      </li>\n      <li>번아웃을 겪을 때 기록을 자주 해놓고, 번아웃에 대해 한판 정리를 했음\n        <ul>\n          <li>나만의 번아웃 패턴을 통해 어떻게 해야 해소할 수 있는지도 알 수 있게 되었음</li>\n          <li>인스타그램에 <a href=\"https://www.instagram.com/data.scientist/p/Cw5A1yALAFQ/?img_index=1\">번아웃에 빠졌을 때 번아웃을 극복하는 10가지 방법</a>이란 글을 작성했음</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/s/r5mee4n8p2a0ur0/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-11-08%20%EC%98%A4%ED%9B%84%203.35.16.png?raw=1\" /></p>\n\n<ul>\n  <li>번아웃과 관련되는 것이 잘 쉬는 것\n    <ul>\n      <li>잘 쉬어야 번아웃도 안 온다고 생각함</li>\n      <li>그래서 나만의 쉼 전략에 대해서도 고민했음. <a href=\"https://www.instagram.com/data.scientist/p/CxdJmQSLO-a/?img_index=1\">잘 쉬는 법에 대한 고찰</a></li>\n      <li>내가 언제 어떤 환경에 있어야 잘 쉰다고 생각하는지, 에너지가 채워지는지 등을 보고 정리함</li>\n      <li>이런 것들이 정리되니까 내가 에너지가 없으면 바로 그 행동을 하면 됨</li>\n      <li>청소하기 : 5 회복, 해외여행 가기 : 50 회복 등 이렇게 나만의 숫자를 채워봤다(숫자는 나중에 바뀔 수 있음)</li>\n    </ul>\n  </li>\n  <li><strong>너무 힘든 경우엔 아무것도 안 해도 괜찮음. 그런 시기도 충분히 있을 수 있고, 잘 회복에 집중해야 함</strong>\n    <ul>\n      <li>IT 업계에 있으면서 성장 지향적으로 살아야 한다는 말을 많이 듣는다. 나도 그렇게 살아왔는데, 어느 순간 너무 성장 성장!보다 나만의 삶을 정의하고 그런 삶을 형성하면 된다고 생각했다</li>\n      <li>이런 삶을 형성하는 과정에선 직무 관점에서 발전을 덜 할 수도 있음. 그러나 이게 문제는 아니라고 생각함</li>\n      <li>힘들 땐 잘 회복하는 것도 중요함. 회복하는 시기엔 회복에 집중하는 것을 추천</li>\n      <li>저 또한 6~7년 차 시절에, 회복에 집중했던 시기가 있음. 성장이란 것은 누적치라 생각해서 그냥 버티기만 해도 유지될 수 있어서 괜찮다고 생각함</li>\n    </ul>\n  </li>\n  <li>정리하면 <strong>번아웃의 원인을 분석해보고, 나의 번아웃 경험을 한판 정리한 후 앞으로 어떻게 번아웃에 빠질 수 있을지 도식을 그림. 또한 어떻게 쉬어야 할지에 대해서도 같이 생각함</strong></li>\n</ul>\n\n<hr />\n\n<p><br />\n<br /></p>\n\n<h2 id=\"그-외에-자주-나오는-고민-질문\">그 외에 자주 나오는 고민, 질문</h2>\n<ul>\n  <li>여러분들은 경력을 쌓으면서 어떤 고민을 하고 계신가요? 고민들도 궁금하네요</li>\n  <li>또 자주 나오는 질문들은 다음과 같음. 다음에 시간이 될 때 아래 내용으로 글을 작성해보려고 함\n    <ul>\n      <li>혹 다른 질문이 있다면 댓글 남겨주시면 참고해서 글을 작성해 볼게요</li>\n    </ul>\n  </li>\n  <li>추가로 자주 받는 질문들\n    <ul>\n      <li>제가 잘하고 있는지 확인하려면 어떻게 해야 할까요?</li>\n      <li>시간 관리는 어떻게 해야 할까요?</li>\n      <li>새로운 트렌드는 어떻게 따라가야 할까요?</li>\n      <li>기술을 추구하는게 맞을까요? 어떤 기술을 공부해야 할까요?</li>\n      <li>이직은 언제 해야 할까요?</li>\n      <li>전 물경력인 것 같아요</li>\n    </ul>\n  </li>\n</ul>\n\n<h2 id=\"정리\">정리</h2>\n<ul>\n  <li>위에 나온 것은 모두 제 생각이고 정답은 아니라고 생각함. 사람마다 다르게 생각할 수 있는 주제</li>\n  <li>제 이야기의 핵심은 <strong>나에 대해 인지(메타인지)하기, 나의 목표(비전) 정해보기, 계속 시도하기, 나만의 원칙 만들기</strong></li>\n</ul>\n\n<hr />\n\n<p><br />\n<br /></p>\n\n<ul>\n  <li>글 작성하는데 걸린 시간 : 75분\n    <ul>\n      <li>하고자 하는 이야기, 개요 정리 : 8분</li>\n      <li>초안 글 작성 : 52분</li>\n      <li>클로드/Cursor와 셀프 글 피드백 : 5분</li>\n      <li>2차 글 작성 : 10분</li>\n    </ul>\n  </li>\n</ul>\n",
        "contentSnippet": "이 글은 경력이 쌓이면서 했던 고민들과 깨달은 내용에 대해 작성한 글입니다\n멘토링 때 종종 이 주제들에 대한 질문을 받아 글을 작성해봅니다\n키워드 : 경력, 커리어, 개발자 커리어, 성장\n살다 보면 우리는 고민이 생긴다\n회사에 다니기 전에는 취업 자체에 대한 고민만 했다. 이 시기엔 취업이 되느냐, 어떤 회사에 가느냐 등을 집중적으로 고민했던 것 같음\n그러나 회사에 가면, 새로운 문제들이 생기기 시작함\n    \n회사에서 어떻게 일을 할 것인가?\n어떻게 인정받을 수 있을까?\n사람들과 어떻게 지내야 할까?\n앞으로의 커리어는 어떻게 될까?\n갑자기 어떤 일도 하기 싫은 번아웃이 온다면 어떻게 해야 할까?\n내가 회사에서 일을 잘하는지 확인하려면?\n위 사례 외에도 굉장히 다양한 종류의 고민들이 생길 수 있고, 멘토링을 할 때 자주 나오는 주제들이다\n자주 나오는 질문이나 했던 생각들을 정리하려고 한다\n자세한 이야기를 하기 전에, 이런 고민을 하는 것 자체가 문제가 아니고 내가 발전하려는 향상심이 있기에 생기는 현상이라고 생각\n    \n이런 생각이 드는 것이 당연하니 너무 걱정하지 않으셨으면 좋겠어요\n이 글의 내용은 제 생각이 맞다는 관점이 아닌, 제가 어떻게 생각했는지를 담은 글입니다. 보시고 다른 생각이 드시면 ‘글쓴이는 이렇게 생각했구나’ 이렇게 생각해 주시면 좋을 것 같아요\n\n\n1) 좋은 커리어란 무엇일까? 앞으로 어떻게 발전해야 할까?\n생각하게 된 배경\n    \n대략 2-3년 차에 많이 생각하는 주제(그러나 그 이후에도 이 고민은 계속된다. 답은 없고, 환경이 변하기 때문. 연차가 쌓이면 새로운 환경에 가고 새로운 의사 결정을 하게 될 수 있음)\n입사하고 초반엔 새로운 일들이 많아서 해당 내용들을 습득하고, 주어진 일을 하나씩 하면서 정신없이 보냄\n        \n그러다가 1, 2년이 지나고 일이 익숙해질 때쯤 커리어에 대해 고민함\n이런 고민을 하게 된 배경은 다양하게 존재할 수 있는데, 업무가 지루하다고 생각하거나, 스스로가 생각하는 이 직무가 해야 하는 일이 정의되어 있지만 그걸 안하 고 있어서 고민하는 경우도 있음\n아마 일이 즐겁고, 보람차고 프로젝트를 잘 진행하고 있다면 이런 고민은 하지 않을 가능성이 존재\n컨퍼런스에서 발표를 보거나, 외부 요소(취업 시장이 어렵다는 이야기), 친구들과의 비교 등을 통해 이런 고민을 하게 될 수도 있음\n제 생각\n    \n이 직무를 왜 시작하게 되었는지가 중요하고, 나에 대한 인지(메타인지)가 있으면 더 깊은 고민을 할 수 있음\n        \n내가 이 직무를 왜 하고 싶었는지, 초심은 무엇이었는지 등\n내가 처음 원했던 방향을 계속 고수해야 한다는 생각은 아니고, 내가 최초의 방향을 잘 생각하고 있는지 고민하며, 그 이후 자신의 경험을 얹어서 새로운 길로 가야 할지 정리하는 것도 괜찮음\n살다 보면 초심을 잊고 살아가는 경우가 많고, 초심에 대한 내용을 블로그 등에 작성하고 지속적으로 보는 것도 좋다고 생각함\n좋은 커리어의 기준은 누가 정해주는 것이 아니라 스스로가 정의해야 함\n        \n다른 사람이 좋다는 A라는 기준이 나중에 시간이 흐르면 다르게 될 수도 있음. 과거의 시기와 요즘은 또 다르게 생각할 수도 있음\n학생이나 신입은 경험이 없어서 기준이 적을 수 있고, 이럴 땐 다른 사람의 의견을 들어보기도 하는 것도 다 한 번쯤 경험함\n            \n그러나 나의 경험을 늘리면서 나만의 생각, 기준을 만들게 됨\n일반적으로 많이 나오는 연봉, 워라밸, 동료 등도 중요할 수 있지만 나의 근본적인 욕구나 이 직무를 선택한 이유에 따라 다를 수 있음\n            \n인정 욕구가 큰 사람에겐 워라밸보단 내 인정이 더 중요할 수 있음. 인정받기 위해 회사에서 성과를 높이려고 하고, 열심히 일하는 것이 즐거울 수 있음\n제가 생각하는 좋은 커리어는 “직무 하나에 나를 한정하지 말고 여러 경험을 하는 것. 문제 해결에 집중하는 것. 꾸준하게 계속 무언가를 시도하는 것”\n        \n여러 경험을 하다 보면 하고 싶지 않은 일을 할 수도 있지만, 그런 일도 경험으로 생각하는 편\n다른 사람들이 하지 않았던 여러 경험들이 합쳐지면 나만의 고유한 영역이 될 수 있다. 제너럴한 영역을 여러 개가 있고, 각 영역을 아주 잘하면 그게 또 새로운 스페셜이 될 수 있다고 생각함\n직무 관점에서도 MLOps나 Analytics Engineer가 하나의 직무에서 시작된 것이 아닌 다른 직무에서 확장되면서 생기는 직무라고 볼 수 있는데, 이와 유사하다고 생각\n저도 고민했던 시기가 있었음. 레트리카에서 데이터 분석가, 데이터 엔지니어 일을 조금씩 했었고 쏘카에선 데이터 분석가, 데이터 과학자, 머신러닝 엔지니어, 데이터 엔지니어, Engineering Manager 등을 경험했는데 너무 여러 가지를 경험해서 고민되기도 했지만 회사에서 요구하는 나의 역할을 최대한 잘 수행해 보자고 생각함\n        \n여러 경험을 했기에 직무의 협업 구조를 알 수 있고, 어떻게 프로젝트를 시작해야 할지, 사업부에선 어떤 관점으로 생각하는지 등을 모두 이해하게 됨\n조직을 키우는 경험도 해보면서, 조직의 규모에 따라 어떤 방식으로 운영해야 할지에 대해 고민을 할 수 있게 되었음\n때론 지금 하는 행동들에 너무 의지를 부여하지 않아도 괜찮았음. 시간이 지나서 그 의미를 찾는 경우도 있었음\n        \n의미를 너무 찾다가 시간이 지나갈 수도 있다는 이야기. 과거에 했던 것을 생각해보니 의미를 찾은 경우도 있기에 너무 의미를 찾는데 오래 걸린다면 잠시 실행해보는 것도 좋은 방법이라 생각(의미와 실행의 적절한 밸런스가 중요하다고 생각)\n좋은 커리어의 기준은 시간의 흐름에 따라 다를 수 있다. 내가 어떤 결정을 할지 기준을 가지고 있는지가 더 중요할 수 있음\n저는 연차별로 성장의 정의가 다 달랐음. 1-2년 차의 성장은 나의 성장, 3-6년차의 성장은 팀과 조직의 성장, 그 이후의 성장은 잘 회복하며 지금 현상 유지하기가 성장이였음. 지금의 성장도 다른 방향으로 가는 중\n\n정리하면 좋은 커리어의 정의는 내가 하는 것이고, 타인이 정해주지 않음. 나에 대해 생각을 해보고 나의 기준을 만드는 것을 추천함. 또한 시간의 흐름에 따라 성장은 달라질 수 있고 과거의 경험들이 갑자기 깨달음을 주는 경우도 있으니 걱정하지 말고 지금 순간을 잘 지내는 것을 추천함\n\n\n2) 데이터 과학자, 데이터 분석가. 데이터 직무의 고민. 커리어를 어떻게 발전해야 할까?\n생각하게 된 배경\n    \n데이터 과학자나 데이터 분석가는 직무의 구분이 명확하지 않아 많은 사람들이 혼란스러워함(저도 과거에 그랬고, 요즘 커리어를 준비하는 분들도 여전히 혼란스러워함)\n        \n다양한 데이터 분석 직군 글을 보면 직무의 이름으로 판단하지 말고 실제 하는 일을 기반으로 판단하라고 작성했음\n1번의 고민(좋은 커리어)와 연결되는 부분인데 데이터 직무는 데이터 분석가지만 하는 일이 회사마다 정말 다양함\n        \n어떤 회사에선 데이터 엔지니어링을 하면서 인프라도 구축해야 하고,\n어떤 회사에선 대시보드 제작 위주로 진행되고\n어떤 회사에선 데이터 추출 요청 위주의 업무가 진행되기도 함\n위 상황과 더불어 데이터 관련 컨퍼런스에서 보면 다른 사람들은 멋진 업무 위주로 하는 것 같아서 자신과 업무를 비교하게 되는 경우도 존재\n제 생각\n    \n이럴 때 현타가 오고 이직 준비를 할 수 있음\n그러나 저는 데이터 관련 어떤 업무를 하더라도, 회사에서 필요한 업무라고 생각함. 다만 회사의 조직 규모의 차이가 있거나 데이터 문화의 차이가 존재할 뿐. 그 시기에 내가 다니고 있을 뿐이라 생각함\n데이터 문화가 아직 잘 정착하지 못했다면 직접 데이터를 추출해서 제공해야 할 수 있고, 대시보드도 데이터 직무가 만들어야 할 수 있음\n        \n이런 상황은 왜 만들어지고, 개선하려면 어떻게 해야 할까?를 고민하는 것도 좋다고 생각\n그럼 조직의 규모가 점점 커지면서 그 안에서 필요한 역할들이 무엇인지 알 수 있게 됨\n이 부분은 국가의 발전, 역사 공부를 하면서 어떻게 해야 더 좋은 조직의 구조를 갖출 수 있을까를 생각했음\n이왕 업무를 진행할 때, 너무 부정적으로 생각하는 것보다 이 업무를 한국 또는 세상에서 제일 잘하려면 어떻게 해야 할지를 고민함\n        \n단순 데이터 추출도 정말 빠르게 잘하려면? => 데이터를 잘 정리해 두는 것도 필요하고, 마트를 만드는 것도 필요하고, 쿼리를 실수 없이 작성하는 것도 필요\n하나의 Task도 더 구체적으로 쪼개보면 필요한 역량이 여러 가지고, 그것을 더 잘하도록 시도할 수 있음\n게임에서 하기 싫은 노가다 퀘스트를 하는 느낌일 수 있지만, 이런 퀘스트가 있어야 다음 퀘스트를 수월하게 진행할 수 있다고 생각함\n다른 사람과 비교하는 순간 자존감이 떨어질 수 있음. 왜냐하면 비교 대상이 대부분 자신보다 더 좋은 상황인 사람과 비교하는 경우가 더 많기 때문\n        \n컨퍼런스에서 발표하는 내용은 부정적인 것보단 긍정적인 것, 인사이트가 있는 것을 주로 발표할 수 있음. 그리고 그 발표가 그 사람의 전부가 아니라 특정 단면을 공유한 것일 수 있음\n다른 사람의 길이 아닌, 그냥 나의 길을 가보자고 생각하는 것을 추천\n내 이야기를 영화로 치면 지금 기승전결에서 중간에 있다고 생각하고, 어려운 상황이 나오면 역시 영화에 위기 한번 와야지! 이런 생각을 하곤 함\nLLM이 발전하면서 1인 생산성이 늘어나고, 단순한 데이터 추출은 LLM으로 대체하려는 시도가 엄청 많이 존재함. 조만간 SQL 작성은 데이터 직무의 일이 아닐 수 있을 것 같음\n        \n대신 데이터 직무가 무엇을 해야 할까? 생각해 보면 사내의 컨설턴트 역할이 될 수도 있고, 데이터 문화를 만드는 역할, 의사 결정을 위주로 하는 역할 등 다양한 역할이 나올 수 있음\n그러나 미래에도 과거처럼 작은 규모에선 직접 쿼리를 작성하는 시기도 있을 수 있음. 그래서 너무 걱정하는 것보단, 지금 하는 일을 잘하게 되면 나중에 도움이 되지 않을까 싶음\n커리어는 점진적으로 발전할 수 있으므로, 너무 조급하게 생각하지 말고 지금 할 수 있는 일부터 점진적으로 하는 것을 추천\n저도 시간이 지나서 8년 차가 되었음. 그동안의 경험이 아직도 생생한데 시간이 참 빠름.\n        \n커리어 초반, 학생 시절엔 ‘내가 될까?’에 집중했고 가능성이 있는지에 대한 질문을 많이 했음\n그러다가 경력을 쌓으면서 ‘내가 뭐가 될까’에 집중했음. 뭐가에 집중하면서 어떻게 해야 할까를 고민했음\n그러다가 요즘은 ‘내가 뭐든 되네’라는 생각을 함. 시간이 지나면 무엇이든 된다. 특정 시기에 내가 노력하지 않아도 회사의 업무를 하면서 경험이 쌓이고 있음. 혹은 내 개인 삶의 경험을 풍성하게 만들 수도 있는 것\n            \n무엇이든 되니 너무 걱정하지 말고 지금 하고 싶은 것이 뭘까, 어떻게 시간을 보낼까를 고민하고 하나씩 해보는 것이 좋지 않을까 싶음\n저는 ‘커리어의 목표가 무엇인가요?’라는 질문을 받으면 딱히 없고 그냥 오늘같이 하루하루 잘 보내는 것이 목표라고 말함. 장기적인 비전은 있으면 좋지만, 너무 큰 목표같이 느껴질 수 있어서 현실적인 오늘을 잘 살려고 함\n직무 관점에서 너무 직무 하나에 매몰되지 말고, 내가 얼마나 회사에 기여할 수 있고 사람들에게 도움을 줄 수 있을지를 생각하며 이 기준이 확장될 수 있는 기준으로 일하고 있음\n정리하면 어떤 일을 하더라도 회사에서 제일 잘하고, 세계에서 제일 잘하려면 어떻게 해야할까를 생각하면서 나의 길을 가려고 함. 좋은 커리어의 정의는 내가 하는 것이므로 내가 어떻게 하고 싶은지에 기반해서 하나씩 실행함. 직무에 한정되는 사람이 되지 말고 직무를 넘어서는 사람이 되려고 함\n\n\n3) 좋은 선택, 의사 결정이란 무엇일까?\n생각하게 된 배경\n    \n의사 결정이 중요하다는 것은 많이 듣는데 그걸 어떻게 잘하는가에 대해서는 배운 적이 적음. 그러다 보니 How를 고민하게 됨\n멘토링 때도 종종 받는 질문으로 가장 중요한 순간의 선택, 후회하는 선택 등의 질문을 받음\n        \n아마 좋은 의사 결정, 좋은 선택하는 방법을 물어보는 질문이었던 것 같음\n의사 결정이 뭔가 한 번에 잘 돼야 할 것 같고, 틀리면 안 될 것 같은 고정 관념이 있었음\n제 생각\n    \n일단 저는 과거의 선택에 크게 연연하지 않는 성격. 과거 성격을 만약 돌릴 수 있다면 생각을 계속할 것 같은데, 그게 아니니까 현실을 직시한다. 그래서 과거 이야기를 물어봐도 잘 떠오르진 않음\n이렇게 된 계기를 생각해 보면 20대 중반부터 뭘 해도 잘 되는 경험이 없었음. 실패, 불합격 등이 많았는데 그게 너무 많아지니까 오히려 현실을 너무 낙관하지 않고 적절한 상태로 바라보곤 했다. 그러다가 니체 책을 보고 니체의 사상에 영감을 받음\n우선 “좋은” 이란 부분에 대한 정의가 필요함. 좋다라는 것은 상황에 따라 다를 수 있고, 구체적으로 정의가 된다면 지표로 나올 수 있음. 다만 지표로 나오지 않는다고 하면 너무 “좋은”에 집중하지 않으려고 함\n어떤 결정을 할 때, 들뜨지 않고 객관적으로 생각함\n        \n만약 지표로 표시할 수 있다면 지표를 정의한다. 숫자로 특정 상황을 표시하고, 이게 더 좋아지면 간다 등\n이 숫자가 높아질 때, 낮아질 때 어떤 Action을 할지 생각한다. 이런 과정을 Mental Simulation이라 부름\n            \n멘탈 시뮬레이션은 특정 행동을 하는 것을 상상하고, 행동하기 전에 예상되는 결과를 시뮬레이션하는 능력\n멘탈 시뮬레이션을 한다면 특정 순간의 지표가 좋지 않아도, 오르기 위해 어떤 것을 해야 할지 생각했으므로 다시 또 실행하면 됨\n과거에 아쉬움이 있다면, 한 번 더 시도해서 아쉬움을 타파하면 그만이 아닐까 생각\n한 번에 잘 되었던 적이 없어서 이 생각을 기본적으로 가지고 있는 것 같음\n어떤 경험을 하고, 주기적으로 회고를 하면서 고민한다. 이 순간에 내가 왜 이 선택을 했지? 이때 뭐가 중요하다고 생각했지?\n        \n그 당시 기록이 있다면 그 기록을 보면서 다음엔 어떻게 해볼까를 고민한다\n의사 결정 자체에 집중하는 것보다, 의사 결정을 대하는 태도나 의사 결정을 하는 과정에 신경을 쓰게 됨\nPM을 위한 데이터 리터러시 강의에 의사 결정 파트가 있는데, 그때 의사 결정 TIP을 다음과 같이 공유했음\n        \n(1) 답을 내린다는 표현 대신 베팅한다는 표현하기 : 답을 내린다는 것은 너무 부담이 생김\n(2) 에너지 레벨 고려하기 : 결정을 내리는 과정은 에너지를 많이 소모한다. 에너지를 덜 소모하며 결정할 방법을 고민함(같이 진행하기 등)\n(3) 당연한 것은 없다 : 당연하다고 생각하지 말고 항상 다시 고민해 보기\n(4) 개인적인 의사 결정에선 과감히 도전하는 것도 방법 : 회사에서 결정하는 것은 보수적으로 갈 수 있지만, 개인 관점에선 개방적으로 해보는 것도 방법. 이런 시도가 나의 안전지대(Comfort Zone)를 넘어설 수 있게 됨\n(5) 결정했으면 그 결정이 좋은 결과를 내도록 노력하기 : 결정하고 아무것도 안 하는 것이 아닌 그게 되도록 하는 것이 중요함\n(6) 사람은 결정으로 인한 실패를 피하고 싶은 성향이 있다 : 결과에 대해 받아들이고, 어떻게 개선할지 생각해 보는 것이 더 중요한 것 같다\n(7) 큰 결정은 누구나 어렵다. 작은 결정부터 하나씩 : 작은 결정에서 점점 큰 결정으로 가자. 대표님들은 어떻게 결정하고 있는지 살펴보고 간접적으로 나라면? 생각해 보거나 대표님들이 어떤 결정을 어떤 흐름으로 했는지 물어보는 것도 방법\n의사 결정, 선택에 대한 원칙을 만들었다.\n        \n대표적인 원칙은 “만약 내일 내가 죽는데, 어떤 일을 하지 않아서 무덤 속에서 뛰쳐나올 것 같다면 지금 하자”\n            \n무덤 속에서 뛰쳐나올 것 같다고 하면 너무 답답해서 해야 할 것으로 생각한다. 그래서 “이거 무덤에서 뛰쳐나올 정도인가?”를 생각하는 편\n좋은 결정보단, 상황에서 적절한 결정만 존재한다고 생각함. 그리고 결정하고 그 후의 실행이 중요하다\n이런 결정 원칙을 여러 개 만들고 주기적으로 수정하면 된다\n또 다른 저의 원칙은 데이터 과학자 원칙에 작성되어 있음. 목차를 공유해 드리면\n            \n의도적으로 남다른 선택해보기\n주기적으로 일하는 목적 찾기\n제너럴리스트, 스페셜리스트 이분법으로 생각하지 않기\n업무도 메타인지하며 목적 중심으로 생각하기\n나의 세상 정의하기\n회사에서 필요한 일과 내 흥미를 일치시키기\n팀 현황을 파악해서 개선점 만들기\n더 나은 커뮤니케이션 능력 기르기\n비즈니스 모델과 데이터의 접점 분석하기\n지금 힘들다면 여유가 있는지 생각해보기\n정리하면 좋은 의사 결정에 집중하는 것이 아닌 현재 상황이 어떤지, 지표로 표시해보고, 앞으로 뭘 해야할지 멘탈 시뮬레이션을 한 후에 결정한다. 결정을 한 후엔, 결정이 잘 될 수 있도록 노력함\n        \n순간 순간엔 좋지 않다고 판단할 수 있지만, 시간이 지나면서 경험이 쌓이면 그런 경험들이 좋은 순간이 될 수 있음\n그래서 이 결정이 좋은가에 대해 생각하지 않게 된 것 같음. 그냥 내게 있는 정보를 가지고 최선의 수를 두고, 계속 고민할 뿐\n\n\n4) 번아웃이 오면 어떻게 해야 할까?\n생각하게 된 배경\n    \n요즘 너무 번아웃이 심하거나 힘든 경우 이런 고민을 하게 된다\n제 생각\n    \n살다 보면 또 번아웃이 올 수 있다. 물론 회사에서 번아웃이 안 오는 사람들도 있고, 적당히 잘 유지하는 사람들도 있다. 어떤 경우엔 번아웃이었는데 시간이 지나고 깨닫는 경우도 있음\n번아웃은 열심히 한 사람이 온다고 생각한다\n        \n일단 번아웃을 인정하기\n번아웃을 나쁘게 생각하지 말고 긍정적으로 승화하기\n잘 하고 있고, 잘 하다가 에너지가 부족해서 번아웃이 된 것. 에너지만 잘 채우면 된다\n번아웃 원인 분석하기\n        \n번아웃이 왜 오게 되었는가를 생각함\n회사의 일이 많아서 그럴 수도 있고, 개인 약속이 너무 많아서 그럴 수도 있고, 제대로 쉬지 못해서, 다른 사람들은 잘 하는데 내가 상대적으로 뒤처진다고 생각해서 등 다양한 이유가 있음\n여러 이유가 있을 수 있는데, 그 이유를 천천히 보면서 어떤 요인이 나를 이렇게 만들었는지 살펴본다. 과거의 경험과 비슷하면 그 요소가 내게 더 영향을 미칠 수 있다고 생각한다\n번아웃을 겪을 때 기록을 자주 해놓고, 번아웃에 대해 한판 정리를 했음\n        \n나만의 번아웃 패턴을 통해 어떻게 해야 해소할 수 있는지도 알 수 있게 되었음\n인스타그램에 번아웃에 빠졌을 때 번아웃을 극복하는 10가지 방법이란 글을 작성했음\n\n번아웃과 관련되는 것이 잘 쉬는 것\n    \n잘 쉬어야 번아웃도 안 온다고 생각함\n그래서 나만의 쉼 전략에 대해서도 고민했음. 잘 쉬는 법에 대한 고찰\n내가 언제 어떤 환경에 있어야 잘 쉰다고 생각하는지, 에너지가 채워지는지 등을 보고 정리함\n이런 것들이 정리되니까 내가 에너지가 없으면 바로 그 행동을 하면 됨\n청소하기 : 5 회복, 해외여행 가기 : 50 회복 등 이렇게 나만의 숫자를 채워봤다(숫자는 나중에 바뀔 수 있음)\n너무 힘든 경우엔 아무것도 안 해도 괜찮음. 그런 시기도 충분히 있을 수 있고, 잘 회복에 집중해야 함\n    \nIT 업계에 있으면서 성장 지향적으로 살아야 한다는 말을 많이 듣는다. 나도 그렇게 살아왔는데, 어느 순간 너무 성장 성장!보다 나만의 삶을 정의하고 그런 삶을 형성하면 된다고 생각했다\n이런 삶을 형성하는 과정에선 직무 관점에서 발전을 덜 할 수도 있음. 그러나 이게 문제는 아니라고 생각함\n힘들 땐 잘 회복하는 것도 중요함. 회복하는 시기엔 회복에 집중하는 것을 추천\n저 또한 6~7년 차 시절에, 회복에 집중했던 시기가 있음. 성장이란 것은 누적치라 생각해서 그냥 버티기만 해도 유지될 수 있어서 괜찮다고 생각함\n정리하면 번아웃의 원인을 분석해보고, 나의 번아웃 경험을 한판 정리한 후 앞으로 어떻게 번아웃에 빠질 수 있을지 도식을 그림. 또한 어떻게 쉬어야 할지에 대해서도 같이 생각함\n\n\n그 외에 자주 나오는 고민, 질문\n여러분들은 경력을 쌓으면서 어떤 고민을 하고 계신가요? 고민들도 궁금하네요\n또 자주 나오는 질문들은 다음과 같음. 다음에 시간이 될 때 아래 내용으로 글을 작성해보려고 함\n    \n혹 다른 질문이 있다면 댓글 남겨주시면 참고해서 글을 작성해 볼게요\n추가로 자주 받는 질문들\n    \n제가 잘하고 있는지 확인하려면 어떻게 해야 할까요?\n시간 관리는 어떻게 해야 할까요?\n새로운 트렌드는 어떻게 따라가야 할까요?\n기술을 추구하는게 맞을까요? 어떤 기술을 공부해야 할까요?\n이직은 언제 해야 할까요?\n전 물경력인 것 같아요\n정리\n위에 나온 것은 모두 제 생각이고 정답은 아니라고 생각함. 사람마다 다르게 생각할 수 있는 주제\n제 이야기의 핵심은 나에 대해 인지(메타인지)하기, 나의 목표(비전) 정해보기, 계속 시도하기, 나만의 원칙 만들기\n\n\n글 작성하는데 걸린 시간 : 75분\n    \n하고자 하는 이야기, 개요 정리 : 8분\n초안 글 작성 : 52분\n클로드/Cursor와 셀프 글 피드백 : 5분\n2차 글 작성 : 10분",
        "guid": "https://zzsza.github.io/diary/2024/11/08/thoughts-and-learnings-in-careers/",
        "categories": [
          "diary",
          "diary"
        ],
        "isoDate": "2024-11-08T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "비트액스 ckpool 설정 방법 / Bisaxe",
        "link": "http://serverdown.tistory.com/960",
        "pubDate": "Wed, 13 Nov 2024 00:34:27 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/960#entry960comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"713\" data-origin-height=\"568\"><span data-url=\"https://blog.kakaocdn.net/dn/cJP40D/btsKHuHTw2l/sfq9K6TsErKcXnVQZNAhJK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cJP40D/btsKHuHTw2l/sfq9K6TsErKcXnVQZNAhJK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cJP40D/btsKHuHTw2l/sfq9K6TsErKcXnVQZNAhJK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcJP40D%2FbtsKHuHTw2l%2Fsfq9K6TsErKcXnVQZNAhJK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"713\" data-origin-height=\"568\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">ckpool 홈페이지:<a href=\"https://solo.ckpool.org/\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://solo.ckpool.org/</a></p>\n<p data-ke-size=\"size16\">ckpool 운영방식 설명: <a href=\"https://bitcointalk.org/index.php?topic=5237323.0\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://bitcointalk.org/index.php?topic=5237323.0</a></p>\n<p data-ke-size=\"size16\">여기 룰 설명중에 이부분이 중요한거 같습니다.</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Note that if you do not find a block, you get no reward at all with solo mining.</span></p>\n<p data-ke-size=\"size16\">블록을&nbsp;찾지&nbsp;못하면&nbsp;솔로&nbsp;채굴을&nbsp;해도&nbsp;전혀&nbsp;보상을&nbsp;받을&nbsp;수&nbsp;없다는&nbsp;점에&nbsp;유의하세요.</p>\n<p data-ke-size=\"size16\"><br /><span style=\"text-align: start;\">2% goes to bc1q28kkr5hk4gnqe3evma6runjrd2pvqyp8fpwfzu to operate the pool and contribute to further ckpool code development.</span></p>\n<p data-ke-size=\"size16\">2%는&nbsp;bc1q28kkr5hk4gnqe3evma6runjrd2pvqyp8fpwfzu에&nbsp;전달되어&nbsp;풀을&nbsp;운영하고&nbsp;추가&nbsp;ckpool&nbsp;코드&nbsp;개발에&nbsp;기여합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">솔로 채굴이라 원래 보상없는 거구요<br />풀마다 운영 규칙이 조금씩 다르긴하더라구요</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">당첨되면 2% + 이체 수수료는 빼고</span> 즉시 전송해줍니다.</p>\n<p data-ke-size=\"size16\">단순하면서 좋은 룰 같습니다. 한두달에 한명정도 나오는거 같더군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">설정방법</h2>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Stratum URL: solo.ckpool.org</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Stratum Port: 4334</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Stratum User: 지갑주소.별명<br />예를 들어 제꺼는 bc1qc272dkew26ea46z2egmt22a3uplpzqgc7snlcs.bitaxekorean</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Stratum Password: x<br />아무거나 넣으라는데 보통 x 를 넣습니다.</span></p>\n<h2 data-ke-size=\"size26\"><span style=\"text-align: start;\">주의: 별명부분은 블록에 기록되고 모두가 볼 수 있으니 [개인정보] 넣지 마세요</span></h2>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "ckpool 홈페이지:https://solo.ckpool.org/\nckpool 운영방식 설명: https://bitcointalk.org/index.php?topic=5237323.0\n여기 룰 설명중에 이부분이 중요한거 같습니다.\nNote that if you do not find a block, you get no reward at all with solo mining.\n블록을 찾지 못하면 솔로 채굴을 해도 전혀 보상을 받을 수 없다는 점에 유의하세요.\n2% goes to bc1q28kkr5hk4gnqe3evma6runjrd2pvqyp8fpwfzu to operate the pool and contribute to further ckpool code development.\n2%는 bc1q28kkr5hk4gnqe3evma6runjrd2pvqyp8fpwfzu에 전달되어 풀을 운영하고 추가 ckpool 코드 개발에 기여합니다.\n \n솔로 채굴이라 원래 보상없는 거구요\n풀마다 운영 규칙이 조금씩 다르긴하더라구요\n당첨되면 2% + 이체 수수료는 빼고 즉시 전송해줍니다.\n단순하면서 좋은 룰 같습니다. 한두달에 한명정도 나오는거 같더군요\n \n설정방법\nStratum URL: solo.ckpool.org\nStratum Port: 4334\nStratum User: 지갑주소.별명\n예를 들어 제꺼는 bc1qc272dkew26ea46z2egmt22a3uplpzqgc7snlcs.bitaxekorean\nStratum Password: x\n아무거나 넣으라는데 보통 x 를 넣습니다.\n주의: 별명부분은 블록에 기록되고 모두가 볼 수 있으니 [개인정보] 넣지 마세요",
        "guid": "http://serverdown.tistory.com/960",
        "categories": [
          "코인",
          "비트액스",
          "오블완",
          "채굴",
          "티스토리챌린지"
        ],
        "isoDate": "2024-11-12T15:34:27.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "비트엑스 과열 상황 및 해결 / 노트북 쿨링 패드 / Bitaxe Overheat",
        "link": "http://serverdown.tistory.com/959",
        "pubDate": "Tue, 12 Nov 2024 17:14:32 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/959#entry959comment",
        "content": "<p data-ke-size=\"size16\">스샷1 - Setting 화면</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1155\" data-origin-height=\"511\"><span data-url=\"https://blog.kakaocdn.net/dn/54C4j/btsKFM31CGr/nlBbUn7RMyuJAapnmZDD60/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/54C4j/btsKFM31CGr/nlBbUn7RMyuJAapnmZDD60/img.png\"><img src=\"https://blog.kakaocdn.net/dn/54C4j/btsKFM31CGr/nlBbUn7RMyuJAapnmZDD60/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F54C4j%2FbtsKFM31CGr%2FnlBbUn7RMyuJAapnmZDD60%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"1155\" data-origin-height=\"511\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">과열이 되어 멈추면 Setting 화면에 빨간 버튼이 생깁니다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Disabled Overheat Mode</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">앗 이게 버튼인지 경고 문구인지 확인을 안해봤군요.</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">빨간색이라 누르면 안될꺼 같았습니다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">과열이 되면 채굴이 중단되고</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Frequency 와 <span style=\"text-align: start;\">Core Voltage 값이 비어있습니다.</span></span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\"><span style=\"text-align: start;\">이걸 default 값으로 바꾼후에 Save 및 Restart 를 해주시면 됩니다.</span></span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">스샷2 - Dashboard 화면</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1195\" data-origin-height=\"443\"><span data-url=\"https://blog.kakaocdn.net/dn/c7vgHv/btsKEXytGFH/WLD4slKdvk21cgLoUs9BI1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/c7vgHv/btsKEXytGFH/WLD4slKdvk21cgLoUs9BI1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/c7vgHv/btsKEXytGFH/WLD4slKdvk21cgLoUs9BI1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc7vgHv%2FbtsKEXytGFH%2FWLD4slKdvk21cgLoUs9BI1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"1195\" data-origin-height=\"443\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">과열 설정을 수정하지 않으면 Dashboard 화면 상단에 경고 문구가 듭니다.</p>\n<p data-ke-size=\"size16\">결국 Settings 에서 고치고 오라는 뜻입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"548\" data-origin-height=\"582\"><span data-url=\"https://blog.kakaocdn.net/dn/dLLMXe/btsKF4J7EPf/Vre2Uyext90dWsyW4rAL7k/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dLLMXe/btsKF4J7EPf/Vre2Uyext90dWsyW4rAL7k/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dLLMXe/btsKF4J7EPf/Vre2Uyext90dWsyW4rAL7k/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdLLMXe%2FbtsKF4J7EPf%2FVre2Uyext90dWsyW4rAL7k%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"548\" data-origin-height=\"582\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">노트북 냉각 패드위에 올려놓은 사진인데요&nbsp;</p>\n<p data-ke-size=\"size16\">바람나오는 방향 잘 맞춰서 세워놓으면 효과가 있는거 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"502\" data-origin-height=\"477\"><span data-url=\"https://blog.kakaocdn.net/dn/bkPr7n/btsKFIm8Nxn/aeh4ptMVoP9M44kA8Kgya1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bkPr7n/btsKFIm8Nxn/aeh4ptMVoP9M44kA8Kgya1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bkPr7n/btsKFIm8Nxn/aeh4ptMVoP9M44kA8Kgya1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbkPr7n%2FbtsKFIm8Nxn%2Faeh4ptMVoP9M44kA8Kgya1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"502\" data-origin-height=\"477\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">결국 65도에서 57도까지 떨어졌습니당.</p>\n<p data-ke-size=\"size16\">노트북 쿨링패드 좋네요</p>\n<p data-ke-size=\"size16\">제껀 [링킨 LS-410] 인데 이건 싸고 별로구요 7천원</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"322\" data-origin-height=\"645\"><span data-url=\"https://blog.kakaocdn.net/dn/bZsCmd/btsKGBgPfEV/TfSnAdFj9YeQBJao2aCnPk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bZsCmd/btsKGBgPfEV/TfSnAdFj9YeQBJao2aCnPk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bZsCmd/btsKGBgPfEV/TfSnAdFj9YeQBJao2aCnPk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbZsCmd%2FbtsKGBgPfEV%2FTfSnAdFj9YeQBJao2aCnPk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"322\" data-origin-height=\"645\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">모양은이게 좋아보이네요 선풍기가 많네요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"318\" data-origin-height=\"572\"><span data-url=\"https://blog.kakaocdn.net/dn/l0Pzb/btsKGG9WLWN/7khadzoHB3vTB7Pfnho2Ik/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/l0Pzb/btsKGG9WLWN/7khadzoHB3vTB7Pfnho2Ik/img.png\"><img src=\"https://blog.kakaocdn.net/dn/l0Pzb/btsKGG9WLWN/7khadzoHB3vTB7Pfnho2Ik/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fl0Pzb%2FbtsKGG9WLWN%2F7khadzoHB3vTB7Pfnho2Ik%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"318\" data-origin-height=\"572\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">좌우로 두개 분리된 제품은 이것입니다.</p>\n<p data-ke-size=\"size16\">채굴기는 작으니 좁은 공간에 강력하게 나와주는게 좋겟습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "스샷1 - Setting 화면\n\n\n과열이 되어 멈추면 Setting 화면에 빨간 버튼이 생깁니다.\nDisabled Overheat Mode\n앗 이게 버튼인지 경고 문구인지 확인을 안해봤군요.\n빨간색이라 누르면 안될꺼 같았습니다.\n \n과열이 되면 채굴이 중단되고\nFrequency 와 Core Voltage 값이 비어있습니다.\n이걸 default 값으로 바꾼후에 Save 및 Restart 를 해주시면 됩니다.\n \n \n스샷2 - Dashboard 화면\n\n\n과열 설정을 수정하지 않으면 Dashboard 화면 상단에 경고 문구가 듭니다.\n결국 Settings 에서 고치고 오라는 뜻입니다.\n \n\n\n노트북 냉각 패드위에 올려놓은 사진인데요 \n바람나오는 방향 잘 맞춰서 세워놓으면 효과가 있는거 같습니다.\n \n\n\n결국 65도에서 57도까지 떨어졌습니당.\n노트북 쿨링패드 좋네요\n제껀 [링킨 LS-410] 인데 이건 싸고 별로구요 7천원\n\n\n모양은이게 좋아보이네요 선풍기가 많네요\n \n\n\n좌우로 두개 분리된 제품은 이것입니다.\n채굴기는 작으니 좁은 공간에 강력하게 나와주는게 좋겟습니다.",
        "guid": "http://serverdown.tistory.com/959",
        "categories": [
          "코인"
        ],
        "isoDate": "2024-11-12T08:14:32.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "공포의 한자 공부",
        "link": "http://serverdown.tistory.com/958",
        "pubDate": "Tue, 12 Nov 2024 14:33:39 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/958#entry958comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=V6i2aiH8oac&amp;t=11s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=V6i2aiH8oac&amp;t=11s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=V6i2aiH8oac\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/NN3Nz/hyXwqz3qoL/kkSc2rkTt4PQKqHJT0xR30/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/zbPUq/hyXwmxFdbW/ygnUooI1ZBi66q9UFuOYo1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"고대에서 현대로 접어들며 의미와 발음이 전부 소실되어 버린 '유령 한자'에 얽힌 소름 끼치는 \" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/V6i2aiH8oac\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">한자 무서워</p>\n<p data-ke-size=\"size16\">입두개 달린 괴물 - 에어리언 아닌가</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=V6i2aiH8oac&t=11s\n\n\n\n한자 무서워\n입두개 달린 괴물 - 에어리언 아닌가",
        "guid": "http://serverdown.tistory.com/958",
        "categories": [
          "유튜브"
        ],
        "isoDate": "2024-11-12T05:33:39.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "금투세 폐지, 이젠 외국계 투자자들도 외치네요 ㄷㄷ",
        "link": "http://serverdown.tistory.com/957",
        "pubDate": "Tue, 12 Nov 2024 12:07:01 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/957#entry957comment",
        "content": "<p data-ke-size=\"size16\">기사: <a href=\"https://m.edaily.co.kr/News/Read?newsId=03132406639084736&amp;mediaCodeNo=257\">美행동주의 \"韓 증시, 금투세 폐지&middot;밸류업으로 매력 높아져\"</a></p>\n<figure id=\"og_1731380693228\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"美행동주의 &quot;韓 증시, 금투세 폐지&middot;밸류업으로 매력 높아져&quot;\" data-og-description=\"미국 행동주의 펀드인 돌턴인베스트먼트가 국내 증시에 대한 투자 매력도가 높아지고 있다고 11일 짚었다. 금융투자소득세(금투세) 폐지와 밸류업 정책 등으로 시장 환경이 개선됨에 따라 저평\" data-og-host=\"m.edaily.co.kr\" data-og-source-url=\"https://m.edaily.co.kr/News/Read?newsId=03132406639084736&amp;mediaCodeNo=257\" data-og-url=\"https://m.edaily.co.kr/News/Read?mediaCodeNo=257&amp;newsId=03132406639084736\" data-og-image=\"https://scrap.kakaocdn.net/dn/Bn5bN/hyXwjHHYoD/hOcAMjcXGP4AGz9GOFnN7k/img.jpg?width=670&amp;height=181&amp;face=0_0_670_181,https://scrap.kakaocdn.net/dn/cRBMKC/hyXwmLaq4U/Vk7GXKIgELeF1mUjNjuqI1/img.jpg?width=670&amp;height=181&amp;face=0_0_670_181\"><a href=\"https://m.edaily.co.kr/News/Read?newsId=03132406639084736&amp;mediaCodeNo=257\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://m.edaily.co.kr/News/Read?newsId=03132406639084736&amp;mediaCodeNo=257\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/Bn5bN/hyXwjHHYoD/hOcAMjcXGP4AGz9GOFnN7k/img.jpg?width=670&amp;height=181&amp;face=0_0_670_181,https://scrap.kakaocdn.net/dn/cRBMKC/hyXwmLaq4U/Vk7GXKIgELeF1mUjNjuqI1/img.jpg?width=670&amp;height=181&amp;face=0_0_670_181');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">美행동주의 \"韓 증시, 금투세 폐지&middot;밸류업으로 매력 높아져\"</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">미국 행동주의 펀드인 돌턴인베스트먼트가 국내 증시에 대한 투자 매력도가 높아지고 있다고 11일 짚었다. 금융투자소득세(금투세) 폐지와 밸류업 정책 등으로 시장 환경이 개선됨에 따라 저평</p>\n<p class=\"og-host\" data-ke-size=\"size16\">m.edaily.co.kr</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">이게 무슨일이죠 ㄷㄷㄷ&nbsp;</p>\n<p data-ke-size=\"size16\">12 -13일은 빠때리아저씨의 예언일 중 하나인데요</p>\n<p data-ke-size=\"size16\">표결 이야기가 나와야 할 대입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">외국계 투자자들도 금투세 보고 잇었네요</p>\n<p data-ke-size=\"size16\">민주당 놈들아 아니라메<br />금투세 도입해야 건전해진다메</p>\n<p data-ke-size=\"size16\">다 매국노 였습니다.<br />어덯게든 부동산 살리려고 증시에 돈을 빼개 만드네요</p>\n<p data-ke-size=\"size16\">그냥 푸념이였습니다.</p>\n<p data-ke-size=\"size16\">코인이랑 미국 주식은 잘되네요</p>",
        "contentSnippet": "기사: 美행동주의 \"韓 증시, 금투세 폐지·밸류업으로 매력 높아져\"\n\n \n美행동주의 \"韓 증시, 금투세 폐지·밸류업으로 매력 높아져\"\n미국 행동주의 펀드인 돌턴인베스트먼트가 국내 증시에 대한 투자 매력도가 높아지고 있다고 11일 짚었다. 금융투자소득세(금투세) 폐지와 밸류업 정책 등으로 시장 환경이 개선됨에 따라 저평\nm.edaily.co.kr\n\n이게 무슨일이죠 ㄷㄷㄷ \n12 -13일은 빠때리아저씨의 예언일 중 하나인데요\n표결 이야기가 나와야 할 대입니다.\n \n외국계 투자자들도 금투세 보고 잇었네요\n민주당 놈들아 아니라메\n금투세 도입해야 건전해진다메\n다 매국노 였습니다.\n어덯게든 부동산 살리려고 증시에 돈을 빼개 만드네요\n그냥 푸념이였습니다.\n코인이랑 미국 주식은 잘되네요",
        "guid": "http://serverdown.tistory.com/957",
        "categories": [
          "투자",
          "금투세"
        ],
        "isoDate": "2024-11-12T03:07:01.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "중국 은행 연쇄 파산 / 이상하게 해결을 안하고 ...",
        "link": "http://serverdown.tistory.com/956",
        "pubDate": "Tue, 12 Nov 2024 12:01:45 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/956#entry956comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=XiGgdsyzItQ\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=XiGgdsyzItQ</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=XiGgdsyzItQ\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/QHZ5E/hyXwi9NMa8/xSZjYTFRJk1r1OngkNAMd0/img.jpg?width=1280&amp;height=720&amp;face=116_110_226_230,https://scrap.kakaocdn.net/dn/itdXO/hyXwuoQ2Ko/7Jzez6z2iAvayLAUrD9jR1/img.jpg?width=1280&amp;height=720&amp;face=116_110_226_230\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"자기 돈도 마음대로 못 꺼내 쓰는 현실... 중국 서민들은 이제 뭘 믿어야 되나...?\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/XiGgdsyzItQ\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">중국이 맛이가서 신난 분들도 있고</p>\n<p data-ke-size=\"size16\">살아야 한국도 산다는 분들도 있고 그런 상황입니다.</p>\n<p data-ke-size=\"size16\">2차전지는 중국이랑 경쟁중이기 때문에 중국이 쓰러지면 좋아야되는데 연일 빠지네요 ㄷㄷㄷ</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상을 보시면 지방 은행이 하나 갑자기 문을 닫고 잠적했는데</p>\n<p data-ke-size=\"size16\">여기서 전개가 신기하게 되네요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">1. 은행 문닫고 도망감</p>\n<p data-ke-size=\"size16\">2. 사람들 항의함</p>\n<p data-ke-size=\"size16\">3. 은행 도망 사태의 기사가 내려감<br />&nbsp; &nbsp; &nbsp;(영상은 개인이 올려서 그런지 덜 내려간건지 아직 많다네요)</p>\n<p data-ke-size=\"size16\">공산당은 능력이 있기 때문에 얼마든지 잡을 수 있다고하는데<br />범인을 잡으면 되지 기사를 내리는 방식으로 진행되네요<br />그래서 이 사태가 공산당이랑 연결되어있다는 것을 의심할 수 잇습니다.</p>\n<p data-ke-size=\"size16\">그런데 ... 미국의 사레를 보면 은행 터지면 정부에서 돈찍어서 해결하면 되는데요</p>\n<p data-ke-size=\"size16\">중국은 왜 이걸 안하는지 모르겠습니다.</p>\n<p data-ke-size=\"size16\">설마 이런걸까요?</p>\n<p data-ke-size=\"size16\">1. 돈을 찍으면 위안화 가치가 떨어진다.<br />2. 돈은 공산당원들이 많이 가지고있다.<br />3. 본인들 재산을 지키기 위해 ???</p>\n<p data-ke-size=\"size16\">어질어질 합니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=XiGgdsyzItQ\n\n\n\n중국이 맛이가서 신난 분들도 있고\n살아야 한국도 산다는 분들도 있고 그런 상황입니다.\n2차전지는 중국이랑 경쟁중이기 때문에 중국이 쓰러지면 좋아야되는데 연일 빠지네요 ㄷㄷㄷ\n \n영상을 보시면 지방 은행이 하나 갑자기 문을 닫고 잠적했는데\n여기서 전개가 신기하게 되네요\n \n1. 은행 문닫고 도망감\n2. 사람들 항의함\n3. 은행 도망 사태의 기사가 내려감\n     (영상은 개인이 올려서 그런지 덜 내려간건지 아직 많다네요)\n공산당은 능력이 있기 때문에 얼마든지 잡을 수 있다고하는데\n범인을 잡으면 되지 기사를 내리는 방식으로 진행되네요\n그래서 이 사태가 공산당이랑 연결되어있다는 것을 의심할 수 잇습니다.\n그런데 ... 미국의 사레를 보면 은행 터지면 정부에서 돈찍어서 해결하면 되는데요\n중국은 왜 이걸 안하는지 모르겠습니다.\n설마 이런걸까요?\n1. 돈을 찍으면 위안화 가치가 떨어진다.\n2. 돈은 공산당원들이 많이 가지고있다.\n3. 본인들 재산을 지키기 위해 ???\n어질어질 합니다.",
        "guid": "http://serverdown.tistory.com/956",
        "categories": [
          "유튜브",
          "오블완",
          "중국",
          "티스토리챌린지"
        ],
        "isoDate": "2024-11-12T03:01:45.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "토스 미국 국채 1개월 상품은 연 5.4% 이자 주는군요",
        "link": "http://serverdown.tistory.com/955",
        "pubDate": "Mon, 11 Nov 2024 23:34:20 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/955#entry955comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"866\" data-origin-height=\"389\"><span data-url=\"https://blog.kakaocdn.net/dn/b1I4TO/btsKEdnrsTg/cwKfnFv34Zk1oxGKgzN1Tk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/b1I4TO/btsKEdnrsTg/cwKfnFv34Zk1oxGKgzN1Tk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/b1I4TO/btsKEdnrsTg/cwKfnFv34Zk1oxGKgzN1Tk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb1I4TO%2FbtsKEdnrsTg%2FcwKfnFv34Zk1oxGKgzN1Tk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"866\" data-origin-height=\"389\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">토스에 5% 짜리 예금이 있다길레 가서봤더니 미국 국채군요</p>\n<p data-ke-size=\"size16\">요즘같이 원화가 맛탱이 가고 있을땐 미국 구채가 좋습니다.</p>\n<p data-ke-size=\"size16\">원화가 강해지면 미국 국채는 안좋지만 ... <br />원화가 강해지다니요.<br />상상이 가지 않습니당.<br /><br /></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">구경하기</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"434\" data-origin-height=\"941\"><span data-url=\"https://blog.kakaocdn.net/dn/cgLNSP/btsKFinNAvD/9PKXU2wMP4l3mi3gumFCA1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cgLNSP/btsKFinNAvD/9PKXU2wMP4l3mi3gumFCA1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cgLNSP/btsKFinNAvD/9PKXU2wMP4l3mi3gumFCA1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcgLNSP%2FbtsKFinNAvD%2F9PKXU2wMP4l3mi3gumFCA1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"434\" data-origin-height=\"941\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">예상 수익이 어마어마하게 높은데요.<br />저렇게 줄리가 없겠죠.</p>\n<p data-ke-size=\"size16\">1개월 짜리 채권을 1년동안 계속 돌리면 받게될 금액 같습니다.<br />한마디로 낚는거죠</p>\n<p data-ke-size=\"size16\">한달 후 약 5,500 원 정도 받게 될 것 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">채권 체험기 - 구매 대기중</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"562\" data-origin-height=\"511\"><span data-url=\"https://blog.kakaocdn.net/dn/9zhzr/btsKFcnN3tL/UxDKp1T5o67bKZHWLvymKK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/9zhzr/btsKFcnN3tL/UxDKp1T5o67bKZHWLvymKK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/9zhzr/btsKFcnN3tL/UxDKp1T5o67bKZHWLvymKK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F9zhzr%2FbtsKFcnN3tL%2FUxDKp1T5o67bKZHWLvymKK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"562\" data-origin-height=\"511\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">바로 구매 되는건 아니고 대기타네요</p>\n<p data-ke-size=\"size16\">미국 정규장에서 구매되고 <br />매진되면 다음날 취소된다고 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">구매방법</h2>\n<p data-ke-size=\"size16\">메뉴의 위치 알려드리겠습니다.</p>\n<p data-ke-size=\"size16\">1. 돈 준비해두시구요 채권 한개가격이 138만원 입니다. $999 짜리라 그런가 봅니다.</p>\n<p data-ke-size=\"size16\">2. 하단 메뉴에 [증권] 으로 갑니다.</p>\n<p data-ke-size=\"size16\">3. 상단 메뉴에 [발견] 을 누릅니다.</p>\n<p data-ke-size=\"size16\">4. 바로 밑에 [채권] 버튼이 생깁니다. 누르세요</p>\n<p data-ke-size=\"size16\">5. [미국채권 1개월 후 만기]&nbsp; 를 누릅니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"410\" data-origin-height=\"196\"><span data-url=\"https://blog.kakaocdn.net/dn/kB3KW/btsKDUhlJHI/c1BhBm5Q6KFa9RPvnK7SN0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/kB3KW/btsKDUhlJHI/c1BhBm5Q6KFa9RPvnK7SN0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/kB3KW/btsKDUhlJHI/c1BhBm5Q6KFa9RPvnK7SN0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FkB3KW%2FbtsKDUhlJHI%2Fc1BhBm5Q6KFa9RPvnK7SN0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"410\" data-origin-height=\"196\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">와 6% 네 하면서 25년 15년 짜리 고르시면 힘들어집니다.<br />진짜로 25년 기다리는 수가 있으니 삼가해주세요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">주의점</h2>\n<p data-ke-size=\"size16\">이걸 사시면 137만원을 <span style=\"text-align: start;\">$</span>999 로 바꾸게 되는데요 환전 수수료는 없지만</p>\n<p data-ke-size=\"size16\">현재 환율 달러당 1,400 에서 내려가버리면<br />즉 원화가 올라서 달러당 1,350 원이 된다면 그 부분만큼은 손해가 난다고 보시면 됩니다.</p>\n<p data-ke-size=\"size16\">그래서 이상품은 원하 가치가 하락할때 하셔야합니다.</p>\n<p data-ke-size=\"size16\">한국은행이 금리 인상한다면 손해볼 수 있습니다.</p>\n<p data-ke-size=\"size16\">현재 한국 상태를 봐선 그럴일이 없어보이지만요.</p>\n<p data-ke-size=\"size16\">읽으시는 분은 주의하시기 바랍니다.<br />도중에 팔 수 있는지는 알아보고 적어드리겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "토스에 5% 짜리 예금이 있다길레 가서봤더니 미국 국채군요\n요즘같이 원화가 맛탱이 가고 있을땐 미국 구채가 좋습니다.\n원화가 강해지면 미국 국채는 안좋지만 ... \n원화가 강해지다니요.\n상상이 가지 않습니당.\n\n \n구경하기\n\n\n예상 수익이 어마어마하게 높은데요.\n저렇게 줄리가 없겠죠.\n1개월 짜리 채권을 1년동안 계속 돌리면 받게될 금액 같습니다.\n한마디로 낚는거죠\n한달 후 약 5,500 원 정도 받게 될 것 같습니다.\n \n채권 체험기 - 구매 대기중\n\n\n바로 구매 되는건 아니고 대기타네요\n미국 정규장에서 구매되고 \n매진되면 다음날 취소된다고 합니다.\n \n구매방법\n메뉴의 위치 알려드리겠습니다.\n1. 돈 준비해두시구요 채권 한개가격이 138만원 입니다. $999 짜리라 그런가 봅니다.\n2. 하단 메뉴에 [증권] 으로 갑니다.\n3. 상단 메뉴에 [발견] 을 누릅니다.\n4. 바로 밑에 [채권] 버튼이 생깁니다. 누르세요\n5. [미국채권 1개월 후 만기]  를 누릅니다.\n\n\n와 6% 네 하면서 25년 15년 짜리 고르시면 힘들어집니다.\n진짜로 25년 기다리는 수가 있으니 삼가해주세요\n \n주의점\n이걸 사시면 137만원을 $999 로 바꾸게 되는데요 환전 수수료는 없지만\n현재 환율 달러당 1,400 에서 내려가버리면\n즉 원화가 올라서 달러당 1,350 원이 된다면 그 부분만큼은 손해가 난다고 보시면 됩니다.\n그래서 이상품은 원하 가치가 하락할때 하셔야합니다.\n한국은행이 금리 인상한다면 손해볼 수 있습니다.\n현재 한국 상태를 봐선 그럴일이 없어보이지만요.\n읽으시는 분은 주의하시기 바랍니다.\n도중에 팔 수 있는지는 알아보고 적어드리겠습니다.",
        "guid": "http://serverdown.tistory.com/955",
        "categories": [
          "투자",
          "채권"
        ],
        "isoDate": "2024-11-11T14:34:20.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "비트액스 감마 채굴기 광고 + 설명 영상이 올라왔군요 / Bitaxe Gamma",
        "link": "http://serverdown.tistory.com/954",
        "pubDate": "Mon, 11 Nov 2024 20:40:28 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/954#entry954comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/p6hvc/btsKD5QsBEr/nVSwrtvFWJAWPFkPqT5SR0/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/p6hvc/btsKD5QsBEr/nVSwrtvFWJAWPFkPqT5SR0/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/p6hvc/btsKD5QsBEr/nVSwrtvFWJAWPFkPqT5SR0/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fp6hvc%2FbtsKD5QsBEr%2FnVSwrtvFWJAWPFkPqT5SR0%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=4bOT37MZOPY&amp;t=3s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=4bOT37MZOPY&amp;t=3s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=4bOT37MZOPY\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/eeG6pt/hyXwtXCUFa/IFJPqfpLGaNU7PXpIXoFW0/img.jpg?width=1280&amp;height=720&amp;face=738_128_854_256,https://scrap.kakaocdn.net/dn/QccoN/hyXwnwi3T1/CMtPZyMa1aKm1mv5w7WUm1/img.jpg?width=1280&amp;height=720&amp;face=738_128_854_256\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"Worlds smallest Bitcoin asic miner Bitaxe Gamma , hidden prize !\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/4bOT37MZOPY\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">썸네일을 보시면 이미 당첨될것 같이 적어뒀군요</p>\n<p data-ke-size=\"size16\">이렇게 해줘야 사람들이 보고 하겠군요</p>\n<p data-ke-size=\"size16\">영상에 셋팅 방법도 있으니 구입전에 참고 보시면 좋을 것 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">판매 페이지:<a href=\"https://mineshop.eu/-bitaxe-gamma\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\"> https://mineshop.eu/-bitaxe-gamma</a></p>\n<p data-ke-size=\"size16\">비트로닉스는 150 유로인데 여기는 195유로 군요<br />배짱장사 오지는군요<br />독같이 생겼구만</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/baabFY/btsKFG9xhfM/cwcwEz9TSK0of3c9lyreL1/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/baabFY/btsKFG9xhfM/cwcwEz9TSK0of3c9lyreL1/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/baabFY/btsKFG9xhfM/cwcwEz9TSK0of3c9lyreL1/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbaabFY%2FbtsKFG9xhfM%2FcwcwEz9TSK0of3c9lyreL1%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">방열판 땐 사진이 있군요 이렇게 생겼군요</p>\n<p data-ke-size=\"size16\">좀더 큰 방열판을 달고 싶군요</p>\n<p data-ke-size=\"size16\">이왕이면 그래픽 카드처럼 앞뒤로</p>\n<p data-ke-size=\"size16\">누가 만들어주려나...</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=4bOT37MZOPY&t=3s\n\n\n\n썸네일을 보시면 이미 당첨될것 같이 적어뒀군요\n이렇게 해줘야 사람들이 보고 하겠군요\n영상에 셋팅 방법도 있으니 구입전에 참고 보시면 좋을 것 같습니다.\n \n판매 페이지: https://mineshop.eu/-bitaxe-gamma\n비트로닉스는 150 유로인데 여기는 195유로 군요\n배짱장사 오지는군요\n독같이 생겼구만\n \n\n\n방열판 땐 사진이 있군요 이렇게 생겼군요\n좀더 큰 방열판을 달고 싶군요\n이왕이면 그래픽 카드처럼 앞뒤로\n누가 만들어주려나...",
        "guid": "http://serverdown.tistory.com/954",
        "categories": [
          "코인"
        ],
        "isoDate": "2024-11-11T11:40:28.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "지구온난화 잡았다. CO2 흡수 분말 탄생 / COF-999",
        "link": "http://serverdown.tistory.com/953",
        "pubDate": "Mon, 11 Nov 2024 20:28:09 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/953#entry953comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=AwHJryy_0vo\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=AwHJryy_0vo</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=AwHJryy_0vo\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/1yEWl/hyXwsdiSMl/KyLevYURyJK7v0gYwFGbTk/img.jpg?width=1280&amp;height=720&amp;face=216_124_386_310,https://scrap.kakaocdn.net/dn/QN0O4/hyXwsRUVhu/vjK15kG42Z2oqHVKS30cT0/img.jpg?width=1280&amp;height=720&amp;face=216_124_386_310\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"이산화 탄소를 마법같이 흡착하는 COF-999! 이산화 탄소의 흡착 능력과 제거하는 원리는 무엇일까?\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/AwHJryy_0vo\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">전기차 시대 이래서 오겠냐</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">뉴스: <a href=\"https://www.playforum.net/news/articleView.html?idxno=416783\">UC버클리, 탄소포집 기술 '게임체인저' 신소재 개발...이산화탄소 제거산업에 혁명 &lt; 산업/IR &lt; 기사본문 - 플레이포럼</a></p>\n<figure id=\"og_1731324456354\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"UC버클리, 탄소포집 기술 '게임체인저' 신소재 개발...이산화탄소 제거산업에 혁명 - 플레이포럼\" data-og-description=\"캘리포니아 버클리 대학교 연구진이 대기 중 이산화탄소를 포집하는 획기적인 신소재 COF-999를 개발했다고 밝혔다.다공성 소재인 \\'결합 유기 프레임워크(COF)\\'는 대기 중 탄소 포집에 필요한 내\" data-og-host=\"www.playforum.net\" data-og-source-url=\"https://www.playforum.net/news/articleView.html?idxno=416783\" data-og-url=\"https://www.playforum.net/news/articleView.html?idxno=416783\" data-og-image=\"https://scrap.kakaocdn.net/dn/cNwktt/hyXsTiRYvF/MMXAwlqr1ooMhwVjkVDwWK/img.jpg?width=600&amp;height=343&amp;face=0_0_600_343,https://scrap.kakaocdn.net/dn/p5wSO/hyXwnwiWXr/dLIde4Wg8qdK1qLONzwSw1/img.jpg?width=600&amp;height=343&amp;face=0_0_600_343\"><a href=\"https://www.playforum.net/news/articleView.html?idxno=416783\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.playforum.net/news/articleView.html?idxno=416783\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/cNwktt/hyXsTiRYvF/MMXAwlqr1ooMhwVjkVDwWK/img.jpg?width=600&amp;height=343&amp;face=0_0_600_343,https://scrap.kakaocdn.net/dn/p5wSO/hyXwnwiWXr/dLIde4Wg8qdK1qLONzwSw1/img.jpg?width=600&amp;height=343&amp;face=0_0_600_343');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">UC버클리, 탄소포집 기술 '게임체인저' 신소재 개발...이산화탄소 제거산업에 혁명 - 플레이포럼</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">캘리포니아 버클리 대학교 연구진이 대기 중 이산화탄소를 포집하는 획기적인 신소재 COF-999를 개발했다고 밝혔다.다공성 소재인 \\'결합 유기 프레임워크(COF)\\'는 대기 중 탄소 포집에 필요한 내</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.playforum.net</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 분말은 나무가 이산화 탄소를 흡수하는 효과와 동일한 기능이 있다고합니다.</p>\n<p data-ke-size=\"size16\">온난화를 간단하게 해결해버렸군요</p>\n<p data-ke-size=\"size16\">누가 양상할지가 중요할 것 같습니다.</p>\n<p data-ke-size=\"size16\">꾸준히 찾아봐야겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이렇게 간단히 온난화가 끝나버리다니 ...</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=AwHJryy_0vo\n\n\n\n전기차 시대 이래서 오겠냐\n \n뉴스: UC버클리, 탄소포집 기술 '게임체인저' 신소재 개발...이산화탄소 제거산업에 혁명 < 산업/IR < 기사본문 - 플레이포럼\n\n \nUC버클리, 탄소포집 기술 '게임체인저' 신소재 개발...이산화탄소 제거산업에 혁명 - 플레이포럼\n캘리포니아 버클리 대학교 연구진이 대기 중 이산화탄소를 포집하는 획기적인 신소재 COF-999를 개발했다고 밝혔다.다공성 소재인 \\'결합 유기 프레임워크(COF)\\'는 대기 중 탄소 포집에 필요한 내\nwww.playforum.net\n\n \n이 분말은 나무가 이산화 탄소를 흡수하는 효과와 동일한 기능이 있다고합니다.\n온난화를 간단하게 해결해버렸군요\n누가 양상할지가 중요할 것 같습니다.\n꾸준히 찾아봐야겠습니다.\n \n이렇게 간단히 온난화가 끝나버리다니 ...",
        "guid": "http://serverdown.tistory.com/953",
        "categories": [
          "유튜브"
        ],
        "isoDate": "2024-11-11T11:28:09.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "베이비도지코인 채굴 6주차 기록 26% 달정중 / BABYDOGE",
        "link": "http://serverdown.tistory.com/952",
        "pubDate": "Mon, 11 Nov 2024 20:04:39 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/952#entry952comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"225\" data-origin-height=\"225\"><span data-url=\"https://blog.kakaocdn.net/dn/F2sCi/btsKEm5tuyu/AEYKfI6ELEyvn1k1WqVpUk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/F2sCi/btsKEm5tuyu/AEYKfI6ELEyvn1k1WqVpUk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/F2sCi/btsKEm5tuyu/AEYKfI6ELEyvn1k1WqVpUk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FF2sCi%2FbtsKEm5tuyu%2FAEYKfI6ELEyvn1k1WqVpUk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"225\" data-origin-height=\"225\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">2024-11-11 6주차 기록</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"535\" data-origin-height=\"747\"><span data-url=\"https://blog.kakaocdn.net/dn/bh1LP7/btsKEGWWg28/LHarBcuRz8ZjkV4egRYSA0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bh1LP7/btsKEGWWg28/LHarBcuRz8ZjkV4egRYSA0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bh1LP7/btsKEGWWg28/LHarBcuRz8ZjkV4egRYSA0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbh1LP7%2FbtsKEGWWg28%2FLHarBcuRz8ZjkV4egRYSA0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"535\" data-origin-height=\"747\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">이번엔 1주동안 거의 8% 를 올렸군</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">이번에 중고 그래픽카드를 주문할 예정입니다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">1060 -&gt; 2070 으로요 가격은 21.5만원 정도 하네요</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"318\" data-origin-height=\"542\"><span data-url=\"https://blog.kakaocdn.net/dn/dL5DU0/btsKEFjsPM0/aOl1lhugcsxcnziwiKjBRk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dL5DU0/btsKEFjsPM0/aOl1lhugcsxcnziwiKjBRk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dL5DU0/btsKEFjsPM0/aOl1lhugcsxcnziwiKjBRk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdL5DU0%2FbtsKEFjsPM0%2FaOl1lhugcsxcnziwiKjBRk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"318\" data-origin-height=\"542\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">쿠팡에 중고 파네요 돈만 더주면 2080 을 26만원에 살수 있지만</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">컴터가 팬 3개 짜리가 안들어가네요 이정도로 만족하는걸루...</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">성능은 2배 정도 기대 됩니다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">영상: <a href=\"https://www.youtube.com/watch?v=pTp7evChXv8\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=pTp7evChXv8</a></span></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=pTp7evChXv8\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/w9QpF/hyXsXeo3AD/eVZOcG51PHi08LKVeb9mvk/img.jpg?width=1280&amp;height=720&amp;face=306_318_576_612,https://scrap.kakaocdn.net/dn/b2ZBmD/hyXwo22TMV/qIIxvWFlw9buXbTGvReWLk/img.jpg?width=1280&amp;height=720&amp;face=306_318_576_612\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"코인.. 이종목.. 놓치면 큰일 나나.. 안절부절\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/pTp7evChXv8\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">사면가 아저씨는 끝도 없이 리플 베이비도지코인 밀고 계십니다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">----</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">이전글은 거의 의미 없겠지만 남겨둡니다.</span></p>\n<p data-ke-size=\"size16\">이전글 : <a href=\"https://serverdown.tistory.com/875\">베이비도지코인 채굴 5주차 기록 17% 달정중 / BABYDOGE</a></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "2024-11-11 6주차 기록\n\n\n이번엔 1주동안 거의 8% 를 올렸군\n이번에 중고 그래픽카드를 주문할 예정입니다.\n1060 -> 2070 으로요 가격은 21.5만원 정도 하네요\n\n\n쿠팡에 중고 파네요 돈만 더주면 2080 을 26만원에 살수 있지만\n컴터가 팬 3개 짜리가 안들어가네요 이정도로 만족하는걸루...\n성능은 2배 정도 기대 됩니다.\n \n영상: https://www.youtube.com/watch?v=pTp7evChXv8\n\n\n\n \n사면가 아저씨는 끝도 없이 리플 베이비도지코인 밀고 계십니다.\n \n----\n이전글은 거의 의미 없겠지만 남겨둡니다.\n이전글 : 베이비도지코인 채굴 5주차 기록 17% 달정중 / BABYDOGE",
        "guid": "http://serverdown.tistory.com/952",
        "categories": [
          "코인",
          "babydoge",
          "unminable",
          "베이비도지",
          "채굴",
          "코인"
        ],
        "isoDate": "2024-11-11T11:04:39.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "비트코인 채굴기를 선풍기로 도와주자 / Bitaxe Gamma",
        "link": "http://serverdown.tistory.com/951",
        "pubDate": "Mon, 11 Nov 2024 16:26:14 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/951#entry951comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"311\" data-origin-height=\"417\"><span data-url=\"https://blog.kakaocdn.net/dn/dosgcl/btsKFl5oxA5/P5ROWbKpEHDf041suqzVw0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dosgcl/btsKFl5oxA5/P5ROWbKpEHDf041suqzVw0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dosgcl/btsKFl5oxA5/P5ROWbKpEHDf041suqzVw0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fdosgcl%2FbtsKFl5oxA5%2FP5ROWbKpEHDf041suqzVw0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"311\" data-origin-height=\"417\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">1주일 채굴해보면서 온도와 전쟁이 시작되었습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">알게된 사실은</p>\n<p data-ke-size=\"size16\">1. 온도가 80도 까지가면 채굴이 중단됩니다.</p>\n<p data-ke-size=\"size16\">2. 성능을 높이면 온도가 올라간다.</p>\n<p data-ke-size=\"size16\">3. 바람을 많이 넣어주면 온도는 내려간다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">냉각팬을 100% 로 돌립니다.</h2>\n<p data-ke-size=\"size16\">가장 쉬운 방법으로 냉각팬을 자동으로 설정하면 70% 까지만 돌아갑니다.<br />수동으로 설정하고 100% 까지 올렸습니다.<br />효과는 좋았습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">추가로 선풍기를 틀어보았습니다.</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"347\" data-origin-height=\"274\"><span data-url=\"https://blog.kakaocdn.net/dn/tQPDa/btsKDqAJ8uk/Ll8Ebp0colPpvDcE9Y0FZ1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/tQPDa/btsKDqAJ8uk/Ll8Ebp0colPpvDcE9Y0FZ1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/tQPDa/btsKDqAJ8uk/Ll8Ebp0colPpvDcE9Y0FZ1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FtQPDa%2FbtsKDqAJ8uk%2FLl8Ebp0colPpvDcE9Y0FZ1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"347\" data-origin-height=\"274\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">왼족은 비트액스구요 <br />오른쪽은 커다란 선풍기를 돌려줬습니다.</p>\n<p data-ke-size=\"size16\">아래쪽이 냉각팬 바람 방향입니다. <br />반대로도 돌릴 수 있더군요<br />선풍기랑 동일한 방향으로 맞춰줬습니다.</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">효과는 엄청났습니다.<br />다 필요 없고 선풍기 큰게 짱입니다.<br /></span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">선풍기 틀어주면 68도 정도 되는걸 <br />선풍기 틀어주면 55도까지 내려갔습니다.</span></p>\n<p data-ke-size=\"size16\">냉각팬은 거의 의미 없는 정도였습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">노트북 쿨링 패드를 달아보자</h2>\n<p data-ke-size=\"size16\">해당글은 별도로 작성되었습니다.</p>\n<p data-ke-size=\"size16\">글링그: <a href=\"https://serverdown.tistory.com/959\">비트엑스 과열 상황 및 해결 / 노트북 쿨링 패드 / Bitaxe Overheat</a></p>\n<figure id=\"og_1731403788620\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"비트엑스 과열 상황 및 해결 / 노트북 쿨링 패드 / Bitaxe Overheat\" data-og-description=\"스샷1 - Setting 화면과열이 되어 멈추면 Setting 화면에 빨간 버튼이 생깁니다.Disabled Overheat Mode앗 이게 버튼인지 경고 문구인지 확인을 안해봤군요.빨간색이라 누르면 안될꺼 같았습니다.&nbsp;과열이 \" data-og-host=\"serverdown.tistory.com\" data-og-source-url=\"https://serverdown.tistory.com/959\" data-og-url=\"https://serverdown.tistory.com/959\" data-og-image=\"https://scrap.kakaocdn.net/dn/bgixkc/hyXwhQJoCh/OZFSIMDuM6gfebs5rI3nG1/img.png?width=800&amp;height=353&amp;face=0_0_800_353,https://scrap.kakaocdn.net/dn/dEMYmX/hyXwuP379i/hfLigLeZEvSYKajKN2cEi1/img.png?width=800&amp;height=353&amp;face=0_0_800_353,https://scrap.kakaocdn.net/dn/b2HOTr/hyXwiB4Ja7/laDzgz4oV06T2AW3zkX4Ak/img.png?width=1155&amp;height=511&amp;face=0_0_1155_511\"><a href=\"https://serverdown.tistory.com/959\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://serverdown.tistory.com/959\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/bgixkc/hyXwhQJoCh/OZFSIMDuM6gfebs5rI3nG1/img.png?width=800&amp;height=353&amp;face=0_0_800_353,https://scrap.kakaocdn.net/dn/dEMYmX/hyXwuP379i/hfLigLeZEvSYKajKN2cEi1/img.png?width=800&amp;height=353&amp;face=0_0_800_353,https://scrap.kakaocdn.net/dn/b2HOTr/hyXwiB4Ja7/laDzgz4oV06T2AW3zkX4Ak/img.png?width=1155&amp;height=511&amp;face=0_0_1155_511');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">비트엑스 과열 상황 및 해결 / 노트북 쿨링 패드 / Bitaxe Overheat</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">스샷1 - Setting 화면과열이 되어 멈추면 Setting 화면에 빨간 버튼이 생깁니다.Disabled Overheat Mode앗 이게 버튼인지 경고 문구인지 확인을 안해봤군요.빨간색이라 누르면 안될꺼 같았습니다.&nbsp;과열이</p>\n<p class=\"og-host\" data-ke-size=\"size16\">serverdown.tistory.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">핵심은 노트북 쿨링 패드가 효과가 좋습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">설정값</h2>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">Frequency : 575<br /></span> <span style=\"text-align: start;\">Core Voltage : 1150<br />Fan Speed : 100%</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">이 환경에서 1.2TH/s 가 나왔고 <br />속도를 올리니 5분쯤 돌다 실패하였고<br />코어 볼트 올려봐도 별차이가 없었습니다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">이것저것 만지면 오히려 속도가 떨어지는 문제도 생기고 온도만 관리하는게 좋을꺼 같습니다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "1주일 채굴해보면서 온도와 전쟁이 시작되었습니다.\n \n알게된 사실은\n1. 온도가 80도 까지가면 채굴이 중단됩니다.\n2. 성능을 높이면 온도가 올라간다.\n3. 바람을 많이 넣어주면 온도는 내려간다.\n \n냉각팬을 100% 로 돌립니다.\n가장 쉬운 방법으로 냉각팬을 자동으로 설정하면 70% 까지만 돌아갑니다.\n수동으로 설정하고 100% 까지 올렸습니다.\n효과는 좋았습니다.\n \n추가로 선풍기를 틀어보았습니다.\n\n\n왼족은 비트액스구요 \n오른쪽은 커다란 선풍기를 돌려줬습니다.\n아래쪽이 냉각팬 바람 방향입니다. \n반대로도 돌릴 수 있더군요\n선풍기랑 동일한 방향으로 맞춰줬습니다.\n효과는 엄청났습니다.\n다 필요 없고 선풍기 큰게 짱입니다.\n\n선풍기 틀어주면 68도 정도 되는걸 \n선풍기 틀어주면 55도까지 내려갔습니다.\n냉각팬은 거의 의미 없는 정도였습니다.\n \n노트북 쿨링 패드를 달아보자\n해당글은 별도로 작성되었습니다.\n글링그: 비트엑스 과열 상황 및 해결 / 노트북 쿨링 패드 / Bitaxe Overheat\n\n \n비트엑스 과열 상황 및 해결 / 노트북 쿨링 패드 / Bitaxe Overheat\n스샷1 - Setting 화면과열이 되어 멈추면 Setting 화면에 빨간 버튼이 생깁니다.Disabled Overheat Mode앗 이게 버튼인지 경고 문구인지 확인을 안해봤군요.빨간색이라 누르면 안될꺼 같았습니다. 과열이\nserverdown.tistory.com\n\n핵심은 노트북 쿨링 패드가 효과가 좋습니다.\n \n설정값\nFrequency : 575\n Core Voltage : 1150\nFan Speed : 100%\n이 환경에서 1.2TH/s 가 나왔고 \n속도를 올리니 5분쯤 돌다 실패하였고\n코어 볼트 올려봐도 별차이가 없었습니다.\n이것저것 만지면 오히려 속도가 떨어지는 문제도 생기고 온도만 관리하는게 좋을꺼 같습니다.",
        "guid": "http://serverdown.tistory.com/951",
        "categories": [
          "코인"
        ],
        "isoDate": "2024-11-11T07:26:14.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": [
      {
        "creator": "coolspeed",
        "title": "라즈베리파이에서 LLM을 돌려봤다",
        "link": "https://coolspeed.wordpress.com/2024/11/10/%eb%9d%bc%ec%a6%88%eb%b2%a0%eb%a6%ac%ed%8c%8c%ec%9d%b4%ec%97%90%ec%84%9c-llm%ec%9d%84-%eb%8f%8c%eb%a0%a4%eb%b4%a4%eb%8b%a4/",
        "pubDate": "Sun, 10 Nov 2024 08:56:09 +0000",
        "content:encodedSnippet": "별건 없다. 그냥 Ollama 설치해서 돌리면 잘 돌아간다. 하지만 경험이 재미 있다.\n신용카드만한 컴퓨터에서 튜링테스트 통과할만한 인공지능이 작동하는 것을 목격하는 것은 신기한 경험이었다.\n방법\n라즈베리파이는 라즈베리파이 5, 8GB 램 버전을 썼다. LLM 모델은 2b 사이즈의 Gemma 2를 사용했다.\n(라즈베리파이를 포함한) 리눅스 환경에 Ollama 설치 방법:\nhttps://ollama.com/download/linux\n설치하고 나면 NVIDIA나 AMD의 그래픽카드가 탐지되지 않아서, CPU only로 돌릴거라는 메시지가 뜬다. 무시하면 된다.\nGemma 2 실행 방법:\nollama run gemma2:2b\n그러면 gemma2:2b 모델이 자동으로 다운로드 되고, 실행된다.\n프롬프트가 뜨면 이제부터 LLM과 대화할 수가 있다.",
        "dc:creator": "coolspeed",
        "comments": "https://coolspeed.wordpress.com/2024/11/10/%eb%9d%bc%ec%a6%88%eb%b2%a0%eb%a6%ac%ed%8c%8c%ec%9d%b4%ec%97%90%ec%84%9c-llm%ec%9d%84-%eb%8f%8c%eb%a0%a4%eb%b4%a4%eb%8b%a4/#respond",
        "content": "별건 없다. 그냥 Ollama 설치해서 돌리면 잘 돌아간다. 하지만 경험이 재미 있다. 신용카드만한 컴퓨터에서 튜링테스트 통과할만한 인공지능이 작동하는 것을 목격하는 것은 신기한 경험이었다. 방법 라즈베리파이는 라즈베리파이 5, 8GB 램 버전을 썼다. LLM 모델은 2b 사이즈의 Gemma 2를 사용했다. (라즈베리파이를 포함한) 리눅스 환경에 Ollama 설치 방법: https://ollama.com/download/linux 설치하고 나면 NVIDIA나 AMD의 그래픽카드가 탐지되지 않아서, CPU only로 [&#8230;]",
        "contentSnippet": "별건 없다. 그냥 Ollama 설치해서 돌리면 잘 돌아간다. 하지만 경험이 재미 있다. 신용카드만한 컴퓨터에서 튜링테스트 통과할만한 인공지능이 작동하는 것을 목격하는 것은 신기한 경험이었다. 방법 라즈베리파이는 라즈베리파이 5, 8GB 램 버전을 썼다. LLM 모델은 2b 사이즈의 Gemma 2를 사용했다. (라즈베리파이를 포함한) 리눅스 환경에 Ollama 설치 방법: https://ollama.com/download/linux 설치하고 나면 NVIDIA나 AMD의 그래픽카드가 탐지되지 않아서, CPU only로 […]",
        "guid": "http://coolspeed.wordpress.com/?p=3464",
        "categories": [
          "未分类"
        ],
        "isoDate": "2024-11-10T08:56:09.000Z"
      }
    ]
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": []
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "한상곤 - Sigmadream",
    "category": "개인",
    "posts": [
      {
        "creator": "Sangkon Han",
        "title": "내 맘대로 위클리 뉴스 - 2024년 44주(2024.11.03 - 2024.11.09)",
        "link": "https://www.sangkon.com/sigmadream_weekly_2024_44/",
        "pubDate": "Fri, 08 Nov 2024 18:06:00 GMT",
        "content:encodedSnippet": "Python\nWrite more pythonic code with context managers\nPython의 context managers를 활용하는 방법을 소개하는 기사 입니다.\nHost a FastAPI Application Without a Server\nFastAPI를 빠르게 배포하는 방법을 소개합니다.\nJavaScript\nConditional React hooks pattern\n\n조건부 Hooks을 활용하는 방법을 소개하는 기사 입니다.\nOOP\nBuilding a Full-Stack Application with Next.js and .NET API Backend\n\n.NET과 Next.js를 함꼐 활용하는 방법을 소개하는 기사 입니다.",
        "dc:creator": "Sangkon Han",
        "content": "<h2 id=\"python\">Python</h2>\n<ul>\n<li>\n<p><a href=\"https://hamatti.org/posts/write-more-pythonic-code-with-context-managers/?ref=sangkon.com\">Write more pythonic code with context managers</a></p>\n<ul>\n<li>Python&#xC758; context managers&#xB97C; &#xD65C;&#xC6A9;&#xD558;&#xB294; &#xBC29;&#xBC95;&#xC744; &#xC18C;&#xAC1C;&#xD558;&#xB294; &#xAE30;&#xC0AC; &#xC785;&#xB2C8;&#xB2E4;.</li>\n</ul>\n</li>\n<li>\n<p><a href=\"https://pinggy.io/blog/host_a_fastapi_app_without_a_server/?ref=sangkon.com\">Host a FastAPI Application Without a Server</a></p>\n<ul>\n<li>FastAPI&#xB97C; &#xBE60;&#xB974;&#xAC8C; &#xBC30;&#xD3EC;&#xD558;&#xB294; &#xBC29;&#xBC95;&#xC744; &#xC18C;&#xAC1C;</li></ul></li></ul>",
        "contentSnippet": "Python\nWrite more pythonic code with context managers\nPython의 context managers를 활용하는 방법을 소개하는 기사 입니다.\nHost a FastAPI Application Without a Server\nFastAPI를 빠르게 배포하는 방법을 소개",
        "guid": "672e5302bf78853c742b06ce",
        "categories": [
          "주간 뉴스"
        ],
        "isoDate": "2024-11-08T18:06:00.000Z"
      }
    ]
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": []
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": [
      {
        "title": "테크스펙은 문서가 아니다",
        "link": "https://blog.banksalad.com/tech/techspec-is-not-doc/",
        "pubDate": "Mon, 11 Nov 2024 00:00:00 GMT",
        "content": "안녕하세요. 뱅크샐러드에서 Tech Lead…",
        "contentSnippet": "안녕하세요. 뱅크샐러드에서 Tech Lead…",
        "guid": "https://blog.banksalad.com/tech/techspec-is-not-doc/",
        "isoDate": "2024-11-11T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": [
      {
        "title": "OpenInfra Asia Summit 2024 돌아보기",
        "link": "https://meetup.nhncloud.com/posts/389",
        "pubDate": "Mon, 11 Nov 2024 02:16:45 GMT",
        "content": "![1.jpg](https://image.toast.com/aaaadh/real/2024/techblog/1.jpg)\r\r\n\r\r\n\r\r\n> 본 콘텐츠는 OpenInfra Foundation의 공식 블로그 [Superuser](https://superuser.openinfra.dev/articles/openinfra-asia-summit-2024-recap/)에 영문본이 게시되었습니다.\r\r\n<br/>\r\r\n\r\r\n\r\r\n지난 9월 3일 개최된 오픈인프라 아시아 서밋(OpenInfra Summit Asia) 2024에 참여하는 좋은 기회를 얻게 되었습니다. 오픈인프라 아시아 서밋은 아시아 전역의 오픈소스 커뮤니티를 지원하기 위해 2023년 설립된 지역 허브인 [오픈인프라 아시아(OpenInfra Asia)](https://openinfraasia.org/)가 개최하는 첫 번째 서밋으로 그 자체로 매우 의미 있는 행사였습니다. 이번 서밋에는 앤트그룹, 화웨이 등 아시아 지역 유수의 기업이 참여했는데요. 그 중 [NHN Cloud](https://www.nhncloud.com/kr)도 아시아 지역의 핵심 클라우드 서비스 기업으로서 오픈스택 기술력과 그간의 커뮤니티 활동을 인정받아 오픈인프라 아시아의 창립 멤버로 초대되었다고 합니다.\r\r\n\r\r\n또한 이번 행사는 주요 오픈 소스 재단인 [Open Compute Project(OCP)](https://www.opencompute.org/) 재단과 공동으로 주최되어, 두 글로벌 오픈 소스 커뮤니티의 핵심 재단이 손잡은 만큼 규모도 크고 프로그램도 매우 다양하고 풍성하게 구성되었습니다.\r\r\n\r\r\n무려 240명이 넘는 연사가 190개 이상의 세션을 제공했으며, 리눅스, 오픈스택, Kubernetes 외 30개 이상의 오픈소스 프로젝트 등 다루는 주제도 무척 다양했습니다. 30개국이 넘는 국가에서 1500명이 넘는 참가자와 함께 저도 유익하고 인사이트가 풍부한 세션들을 들을 수 있었습니다.\r\r\n\r\r\n![2.jpg](https://image.toast.com/aaaadh/real/2024/techblog/2%281%29.jpg)\r\r\n귀중한 정보를 담은 세션들이 주로 영어와 한국어로 제공되었으며 영어 세션이 다수를 이루었습니다. 따라서 영어가 익숙지 않은 청중들을 위해 flitto 동시번역 서비스로 16개국 이상의 언어를 제공한다는 점이 무척 흥미로웠습니다. 세션 룸에 동시번역 서비스 QR 코드가 배치되어있어, 앱 다운없이 손쉽고 간편하게 접근할 수 있었습니다.\r\r\n\r\r\n많은 참가자들이 자신의 패드에서 번역 서비스를 통해 연사가 말하자마자 매끄럽게 번역된 콘텐츠를 접할 수 있었습니다.\r\r\n\r\r\n## Keynotes\r\r\n\r\r\n![3.jpg](https://image.toast.com/aaaadh/real/2024/techblog/3%281%29.jpg)\r\r\n오픈 인프라 재단의 최고운영책임자(COO)인 Mark Collier의 키노트가 무척 인상 깊었는데요. 인프라 전반의 트렌드 4가지를 일목요연하고 간결하게 정리해 주었습니다.\r\r\n\r\r\n### Digital Sovereignty\r\r\n\r\r\n\r\r\n내 데이터가 어디에 저장되고 누가 접근 가능하며 어떤 법률의 지배를 받는지에 대한 관심이 커지고 중요한 사안이 되었는데요. 이는 개인에 국한되지 않고, 국가 기관 및 정부에게도 중요한 사안이 되었습니다.\r\r\n대표적인 예로 프랑스의 주요 은행들이 오픈 스택을 채택해 자신들의 데이터 위치와 접근 권한, 적용되는 법률을 직접 관리하고 있습니다. 이렇게 주요 기관들이 자신들의 데이터를 매우 독점적으로 처리하고 보유하고자하는 트렌드는 전 세계적으로 나타나고 있습니다.\r\r\n\r\r\n이 같은 트렌드는 하드웨어 영역에서도 나타나고 있는데요. RISC-V가 그 예입니다.\r\r\n\r\r\n> RISC-V는 2010년 UC 버클리에서 개발한 오픈소스 RISC(Reduced Instruction Set Computer) 명령어 세트 아키텍처입니다. RISC-V 아키텍처를 통해 설계자는 최종 애플리케이션에 맞게 프로세서를 맞춤화하고 설계할 수 있습니다.\r\r\n\r\r\n즉 현재는 기존에 사용하는 프로그램이나 하드웨어에 대해 영구적인 접근 권한을 갖고 통제하고 원하는 대로 사용하고 싶어 하는 산업 전반의 트렌드가 있다고 합니다. 이 같은 트렌드로 오픈 소스 및 오픈 테크놀로지는 그 어느 때보다 중요해졌다고 합니다.\r\r\n\r\r\n### License Changes\r\r\n\r\r\n\r\r\n* Terraform\r\r\n예상치 못한 라이선스 변경으로 시장에 악영향을 미쳤지만, 오픈소스가 이에 대한 해결책을 제시해 줄 수 있습니다. Terraform의 라이선스 변경으로 인해 오픈 소스 프로젝트인 Open Tofu가 등장하여 테라폼을 대체하는 역할을 수행해 사용자들에게 신뢰를 제공하고 있습니다.\r\r\n\r\r\n* VMware\r\r\nVMware의 라이선스가 변경됨에 따라 많은 사용자들이 VMware에서 OpenStack으로 마이그레이션에 대한 관심이 커지고 있습니다. 대표적으로 미국의 주요 자동차 보험사인 GEICO가 최근 VMware를 버리고 오픈스택으로 대규모 클라우드 인프라를 구축해 큰 주목을 받았다고 합니다. Mark Collier는 마이그레이션에 관한 백서를 행사 당일에 [QR](https://www.openstack.org/vmware-migration-to-openstack-white-paper)로 공개하기도 했습니다.\r\r\n\r\r\n### Security Concerns\r\r\n\r\r\n\r\r\n최근 운영 중인 컨테이너 이미지의 87%에 치명적이거나 심각도가 높은 취약점이 있다는 사실이 밝혀져 우려를 자아내고 있습니다. 이 문제를 해결하기 위한 방안으로 오픈 인프라 재단에서 주최하는 카타 컨테이너(Kata Container) 프로젝트가 큰 주목을 받고 있습니다. 카타 컨테이너는 컨테이너의 속도와 가상 머신의 보안을 결합한 경량 가상화를 제공함으로써 속도와 보안 사이의 균형을 제공합니다. 컨테이너 환경 보안에 효과적이라는 점에서 Microsoft Azure, NVIDIA, AWS 등 주요 기업들이 카타 컨테이너에 투자하고 지원하고 있습니다.\r\r\n\r\r\n### AI Redefining Infra\r\r\n\r\r\n\r\r\nAI에 대한 기업들의 관심이 이례적입니다. 너도 나도 할 것 없이 기업들은 GPU를 최대한 많이 확보해 방대한 규모로 자신의 데이터 센터에 구축하고 있습니다. 기업이 AI 용량 구축에 거대한 투자하고 있으며, 오픈스택이 AI 워크 로드를 지원하는 데 중요한 역할을 하고 있습니다.\r\r\n\r\r\n이렇게 디지털 주권, 라이선스 변경, 보안 문제, 인공지능과 같이 네 가지 주요 트렌드로 오픈 소스에 대한 관심과 투자가 그 어느 때보다도 활발하게 일어나고 있고 오픈 소스 커뮤니티의 성장을 이끌고 있다고 합니다.\r\r\n\r\r\n## Sessions\r\r\n\r\r\n오픈인프라 아시아 서밋 2024에는 다양한 주제에 대해 심도 있는 내용을 다루는 세션이 많았는데요. 저는 그중 NHN Cloud 인프라서비스개발랩 박성우 이사님이 발표하신 세션 **Openstack of NHN Cloud from a network perspective**을 통해 오픈스택의 실제 적용 사례와 오픈스택의 한계점을 어떻게 보완했는지를 배울 수 있었습니다. 아래는 세션 내용의 일부를 요약해 보았습니다.\r\r\n\r\r\n### 1. Openstack of NHN Cloud from a network perspective\r\r\n\r\r\n![4.jpg](https://image.toast.com/aaaadh/real/2024/techblog/4%281%29.jpg)\r\r\n\r\r\n>  [영상 보러 가기](https://www.youtube.com/watch?v=IgXJq8jmuJI&t=1s)\r\r\n\r\r\nNHN Cloud는 2015년에 OpenStack의 Neutron 모듈을 활용해 네트워크를 구축하고 서비스를 시작했습니다. 하지만 서비스 초기 단계에서는 Neutron 모듈의 기본 기능만으로는 NHN Cloud의 서비스들을 효율적이고 안정적으로 운영하는 데 한계가 있었다고 합니다. 이중화가 불가능하고 장애 조치 및 스케일업 기능이 지원되지 않았기 때문입니다. 이번 세션에서는 NHN Cloud가 이러한 문제를 어떻게 해결했는지에 대해 자세히 다뤘습니다.\r\r\n\r\r\nNeutron의 기본 구조는 컴퓨트 노드 안에 큐라우터와 OVS integration bridge, 그리고 그 사이에 위치한 리눅스 브릿지로 구성됩니다. 여기에 IP 테이블을 연결하여 보안 규칙(Security Rules)을 설정하게 됩니다. 하지만 이 구조는 보안 규칙이 많아질수록 코드 오류의 원인을 파악하고 문제를 분석하는 데 어려움을 겪게 되며 유지 보수에 큰 부담이 따랐다고 합니다. 더구나 리눅스 브릿지는 OSI 모델의 2계층에서만 동작하기 때문에, 라우팅이나 IP 주소를 기반으로 트래픽을 처리하는 데도 한계가 있었습니다.\r\r\n\r\r\n![5.png](https://image.toast.com/aaaadh/real/2024/techblog/5.png)\r\r\n\r\r\n이러한 문제를 해결하기 위해 NHN Cloud는 컴퓨트 노드에서 리눅스 브릿지와 큐라우터를 제거하고, OVS integration bridge로 대체하는 방식을 채택했습니다. 네트워크를 VxLAN마다 나누고 각 브릿지와 연결하는 방식으로 구성하여 더 효율적인 네트워크 구조를 구현했습니다. 또한, NVIDIA의 SR-IOV Representer를 OVS bridge와 연결해 I/O 성능을 대폭 개선한 점이 인상 깊었습니다.\r\r\n\r\r\n> SR-IOV는 하나의 물리적 PCI Express 장치를 여러 가상 머신이 동시에 사용할 수 있게 해주는 기술로, 가상화 환경에서 매우 유용한 기술입니다.\r\r\n\r\r\n앞서 컴퓨트 노드에서 큐라우터를 제거했다고 했는데요. 이는 큐라우터의 한계를 극복하기 위한 조치로 랙 상단으로 이동시켰습니다. 즉, 각 랙이 하이퍼바이저처럼 작동하게 되어 컴퓨트 노드의 구조가 단순화되고, 최대 효율을 추구할 수 있었습니다.\r\r\n\r\r\n하지만 이러한 구조에서는 모든 트래픽이 랙 상단의 라우터로 집중되는 문제가 발생했습니다. 이를 해결하기 위해 NHN Cloud는 vSwitch를 개발했으며, 이 vSwitch는 5mpps(초당 500만 패킷)의 뛰어난 처리 속도를 자랑합니다.\r\r\n\r\r\n또한, VLAN에서 VxLAN으로 전환한 이유도 흥미로웠는데, 이는 고객 수가 증가함에 따라 퍼블릭 환경에서 여러 VPC(Virtual Private Cloud)를 생성해야 했기 때문입니다.\r\r\n\r\r\n### 보안과 안정성\r\r\n\r\r\n\r\r\n보안과 안정성 측면에서도 다양한 개선이 이루어졌습니다. 기본적으로 Neutron이 제공하는 Security Groups와 함께 Network ACL을 구성하여, 서버가 클라이언트 상태 정보를 저장하지 않아도 통신할 수 있는 환경을 구축했습니다. 또한, Internet Gateway 없이도 원격 호스트와 통신할 수 있도록 VPN Gateway를 연결해 네트워크 통신의 유연성을 강화했습니다.\r\r\n\r\r\n![6.png](https://image.toast.com/aaaadh/real/2024/techblog/6.png)\r\r\n\r\r\nNHN Cloud는 2015년 서비스 시작 이후, OpenStack Neutron에 다양한 기능을 추가하기 위해 여러 플러그인과 자체 개발한 에이전트들을 도입해왔는데요. 세션을 통해 NHN Cloud가 기존의 네트워크 문제를 혁신적으로 해결하고, 서비스 안정성과 보안을 동시에 강화한 점을 직접 확인할 수 있었습니다. 동시에 클라우드 네트워크 관리의 복잡성을 체감할 수 있었습니다.\r\r\n\r\r\n<br/>\r\r\n\r\r\n### 2. Bridging the Gap Between Community and Contributing Orgs\r\r\n\r\r\n![7.jpg](https://image.toast.com/aaaadh/real/2024/techblog/7.jpg)\r\r\n\r\r\n강의 형태로 진행되는 세션이 아닌 참석자들과 함께 자유롭게 토의하는 포럼 형태의 세션도 제공되었습니다. 그중 하나인 **Bridging the Gap Between Community and Contributing Orgs**은 오픈 소스 커뮤니티를 더욱 활성화하기 위해 자유롭게 의견을 공유하는 자리였습니다. 주요 논의는 신규 기여자와 기존 기여자가 모두를 위한 커뮤니케이션을 활성화하고 기여자 경험을 개선하기 위한 방안을 논의하는 세션이었습니다.\r\r\n\r\r\n다양한 국가의 수많은 사람들이 오픈인프라 프로젝트에 기여하고 있는 만큼 커뮤니케이션의 한계를 극복하고 다양성을 높이고자하는 열정이 느껴지는 세션이었습니다.\r\r\n\r\r\n## OpenStack’s Role in the Future\r\r\n\r\r\n\r\r\n오픈인프라 서밋 아시아 2024는 클라우드 산업의 혁신을 선도하는 오픈소스 커뮤니티의 중요성을 다시 한 번 강조한 행사였습니다.\r\r\n\r\r\n특히 VMware에서 오픈스택으로의 마이그레이션이 주목을 받으면서 확장 가능하고, 안전하며, 비용 효율적인 솔루션으로 오픈스택을 도입하려는 기업들이 전 세계적으로 많다는 것을 느낄 수 있었습니다.\r\r\n\r\r\n또한, AI와 같은 고성능 컴퓨팅을 위한 지속 가능한 인프라에 대한 요구가 커지고 있는 상황에서, 오픈인프라 커뮤니티는 혁신적이고 획기적인 솔루션으로 이러한 글로벌 과제에 대응할 준비가 충분히 갖추어져 있음을 확인할 수 있었습니다. 이번 서밋을 통해 오픈소스 기반 인프라의 미래와 지속 가능한 기술 개발에 대한 기대감이 더욱 커졌습니다.",
        "contentSnippet": "![1.jpg](https://image.toast.com/aaaadh/real/2024/techblog/1.jpg)\r\r\n\r\r\n\r\r\n> 본 콘텐츠는 OpenInfra Foundation의 공식 블로그 [Superuser](https://superuser.openinfra.dev/articles/openinfra-asia-summit-2024-recap/)에 영문본이 게시되었습니다.\r\r\n\r\r\n\r\r\n\r\r\n지난 9월 3일 개최된 오픈인프라 아시아 서밋(OpenInfra Summit Asia) 2024에 참여하는 좋은 기회를 얻게 되었습니다. 오픈인프라 아시아 서밋은 아시아 전역의 오픈소스 커뮤니티를 지원하기 위해 2023년 설립된 지역 허브인 [오픈인프라 아시아(OpenInfra Asia)](https://openinfraasia.org/)가 개최하는 첫 번째 서밋으로 그 자체로 매우 의미 있는 행사였습니다. 이번 서밋에는 앤트그룹, 화웨이 등 아시아 지역 유수의 기업이 참여했는데요. 그 중 [NHN Cloud](https://www.nhncloud.com/kr)도 아시아 지역의 핵심 클라우드 서비스 기업으로서 오픈스택 기술력과 그간의 커뮤니티 활동을 인정받아 오픈인프라 아시아의 창립 멤버로 초대되었다고 합니다.\r\r\n\r\r\n또한 이번 행사는 주요 오픈 소스 재단인 [Open Compute Project(OCP)](https://www.opencompute.org/) 재단과 공동으로 주최되어, 두 글로벌 오픈 소스 커뮤니티의 핵심 재단이 손잡은 만큼 규모도 크고 프로그램도 매우 다양하고 풍성하게 구성되었습니다.\r\r\n\r\r\n무려 240명이 넘는 연사가 190개 이상의 세션을 제공했으며, 리눅스, 오픈스택, Kubernetes 외 30개 이상의 오픈소스 프로젝트 등 다루는 주제도 무척 다양했습니다. 30개국이 넘는 국가에서 1500명이 넘는 참가자와 함께 저도 유익하고 인사이트가 풍부한 세션들을 들을 수 있었습니다.\r\r\n\r\r\n![2.jpg](https://image.toast.com/aaaadh/real/2024/techblog/2%281%29.jpg)\r\r\n귀중한 정보를 담은 세션들이 주로 영어와 한국어로 제공되었으며 영어 세션이 다수를 이루었습니다. 따라서 영어가 익숙지 않은 청중들을 위해 flitto 동시번역 서비스로 16개국 이상의 언어를 제공한다는 점이 무척 흥미로웠습니다. 세션 룸에 동시번역 서비스 QR 코드가 배치되어있어, 앱 다운없이 손쉽고 간편하게 접근할 수 있었습니다.\r\r\n\r\r\n많은 참가자들이 자신의 패드에서 번역 서비스를 통해 연사가 말하자마자 매끄럽게 번역된 콘텐츠를 접할 수 있었습니다.\r\r\n\r\r\n## Keynotes\r\r\n\r\r\n![3.jpg](https://image.toast.com/aaaadh/real/2024/techblog/3%281%29.jpg)\r\r\n오픈 인프라 재단의 최고운영책임자(COO)인 Mark Collier의 키노트가 무척 인상 깊었는데요. 인프라 전반의 트렌드 4가지를 일목요연하고 간결하게 정리해 주었습니다.\r\r\n\r\r\n### Digital Sovereignty\r\r\n\r\r\n\r\r\n내 데이터가 어디에 저장되고 누가 접근 가능하며 어떤 법률의 지배를 받는지에 대한 관심이 커지고 중요한 사안이 되었는데요. 이는 개인에 국한되지 않고, 국가 기관 및 정부에게도 중요한 사안이 되었습니다.\r\r\n대표적인 예로 프랑스의 주요 은행들이 오픈 스택을 채택해 자신들의 데이터 위치와 접근 권한, 적용되는 법률을 직접 관리하고 있습니다. 이렇게 주요 기관들이 자신들의 데이터를 매우 독점적으로 처리하고 보유하고자하는 트렌드는 전 세계적으로 나타나고 있습니다.\r\r\n\r\r\n이 같은 트렌드는 하드웨어 영역에서도 나타나고 있는데요. RISC-V가 그 예입니다.\r\r\n\r\r\n> RISC-V는 2010년 UC 버클리에서 개발한 오픈소스 RISC(Reduced Instruction Set Computer) 명령어 세트 아키텍처입니다. RISC-V 아키텍처를 통해 설계자는 최종 애플리케이션에 맞게 프로세서를 맞춤화하고 설계할 수 있습니다.\r\r\n\r\r\n즉 현재는 기존에 사용하는 프로그램이나 하드웨어에 대해 영구적인 접근 권한을 갖고 통제하고 원하는 대로 사용하고 싶어 하는 산업 전반의 트렌드가 있다고 합니다. 이 같은 트렌드로 오픈 소스 및 오픈 테크놀로지는 그 어느 때보다 중요해졌다고 합니다.\r\r\n\r\r\n### License Changes\r\r\n\r\r\n\r\r\n* Terraform\r\r\n예상치 못한 라이선스 변경으로 시장에 악영향을 미쳤지만, 오픈소스가 이에 대한 해결책을 제시해 줄 수 있습니다. Terraform의 라이선스 변경으로 인해 오픈 소스 프로젝트인 Open Tofu가 등장하여 테라폼을 대체하는 역할을 수행해 사용자들에게 신뢰를 제공하고 있습니다.\r\r\n\r\r\n* VMware\r\r\nVMware의 라이선스가 변경됨에 따라 많은 사용자들이 VMware에서 OpenStack으로 마이그레이션에 대한 관심이 커지고 있습니다. 대표적으로 미국의 주요 자동차 보험사인 GEICO가 최근 VMware를 버리고 오픈스택으로 대규모 클라우드 인프라를 구축해 큰 주목을 받았다고 합니다. Mark Collier는 마이그레이션에 관한 백서를 행사 당일에 [QR](https://www.openstack.org/vmware-migration-to-openstack-white-paper)로 공개하기도 했습니다.\r\r\n\r\r\n### Security Concerns\r\r\n\r\r\n\r\r\n최근 운영 중인 컨테이너 이미지의 87%에 치명적이거나 심각도가 높은 취약점이 있다는 사실이 밝혀져 우려를 자아내고 있습니다. 이 문제를 해결하기 위한 방안으로 오픈 인프라 재단에서 주최하는 카타 컨테이너(Kata Container) 프로젝트가 큰 주목을 받고 있습니다. 카타 컨테이너는 컨테이너의 속도와 가상 머신의 보안을 결합한 경량 가상화를 제공함으로써 속도와 보안 사이의 균형을 제공합니다. 컨테이너 환경 보안에 효과적이라는 점에서 Microsoft Azure, NVIDIA, AWS 등 주요 기업들이 카타 컨테이너에 투자하고 지원하고 있습니다.\r\r\n\r\r\n### AI Redefining Infra\r\r\n\r\r\n\r\r\nAI에 대한 기업들의 관심이 이례적입니다. 너도 나도 할 것 없이 기업들은 GPU를 최대한 많이 확보해 방대한 규모로 자신의 데이터 센터에 구축하고 있습니다. 기업이 AI 용량 구축에 거대한 투자하고 있으며, 오픈스택이 AI 워크 로드를 지원하는 데 중요한 역할을 하고 있습니다.\r\r\n\r\r\n이렇게 디지털 주권, 라이선스 변경, 보안 문제, 인공지능과 같이 네 가지 주요 트렌드로 오픈 소스에 대한 관심과 투자가 그 어느 때보다도 활발하게 일어나고 있고 오픈 소스 커뮤니티의 성장을 이끌고 있다고 합니다.\r\r\n\r\r\n## Sessions\r\r\n\r\r\n오픈인프라 아시아 서밋 2024에는 다양한 주제에 대해 심도 있는 내용을 다루는 세션이 많았는데요. 저는 그중 NHN Cloud 인프라서비스개발랩 박성우 이사님이 발표하신 세션 **Openstack of NHN Cloud from a network perspective**을 통해 오픈스택의 실제 적용 사례와 오픈스택의 한계점을 어떻게 보완했는지를 배울 수 있었습니다. 아래는 세션 내용의 일부를 요약해 보았습니다.\r\r\n\r\r\n### 1. Openstack of NHN Cloud from a network perspective\r\r\n\r\r\n![4.jpg](https://image.toast.com/aaaadh/real/2024/techblog/4%281%29.jpg)\r\r\n\r\r\n>  [영상 보러 가기](https://www.youtube.com/watch?v=IgXJq8jmuJI&t=1s)\r\r\n\r\r\nNHN Cloud는 2015년에 OpenStack의 Neutron 모듈을 활용해 네트워크를 구축하고 서비스를 시작했습니다. 하지만 서비스 초기 단계에서는 Neutron 모듈의 기본 기능만으로는 NHN Cloud의 서비스들을 효율적이고 안정적으로 운영하는 데 한계가 있었다고 합니다. 이중화가 불가능하고 장애 조치 및 스케일업 기능이 지원되지 않았기 때문입니다. 이번 세션에서는 NHN Cloud가 이러한 문제를 어떻게 해결했는지에 대해 자세히 다뤘습니다.\r\r\n\r\r\nNeutron의 기본 구조는 컴퓨트 노드 안에 큐라우터와 OVS integration bridge, 그리고 그 사이에 위치한 리눅스 브릿지로 구성됩니다. 여기에 IP 테이블을 연결하여 보안 규칙(Security Rules)을 설정하게 됩니다. 하지만 이 구조는 보안 규칙이 많아질수록 코드 오류의 원인을 파악하고 문제를 분석하는 데 어려움을 겪게 되며 유지 보수에 큰 부담이 따랐다고 합니다. 더구나 리눅스 브릿지는 OSI 모델의 2계층에서만 동작하기 때문에, 라우팅이나 IP 주소를 기반으로 트래픽을 처리하는 데도 한계가 있었습니다.\r\r\n\r\r\n![5.png](https://image.toast.com/aaaadh/real/2024/techblog/5.png)\r\r\n\r\r\n이러한 문제를 해결하기 위해 NHN Cloud는 컴퓨트 노드에서 리눅스 브릿지와 큐라우터를 제거하고, OVS integration bridge로 대체하는 방식을 채택했습니다. 네트워크를 VxLAN마다 나누고 각 브릿지와 연결하는 방식으로 구성하여 더 효율적인 네트워크 구조를 구현했습니다. 또한, NVIDIA의 SR-IOV Representer를 OVS bridge와 연결해 I/O 성능을 대폭 개선한 점이 인상 깊었습니다.\r\r\n\r\r\n> SR-IOV는 하나의 물리적 PCI Express 장치를 여러 가상 머신이 동시에 사용할 수 있게 해주는 기술로, 가상화 환경에서 매우 유용한 기술입니다.\r\r\n\r\r\n앞서 컴퓨트 노드에서 큐라우터를 제거했다고 했는데요. 이는 큐라우터의 한계를 극복하기 위한 조치로 랙 상단으로 이동시켰습니다. 즉, 각 랙이 하이퍼바이저처럼 작동하게 되어 컴퓨트 노드의 구조가 단순화되고, 최대 효율을 추구할 수 있었습니다.\r\r\n\r\r\n하지만 이러한 구조에서는 모든 트래픽이 랙 상단의 라우터로 집중되는 문제가 발생했습니다. 이를 해결하기 위해 NHN Cloud는 vSwitch를 개발했으며, 이 vSwitch는 5mpps(초당 500만 패킷)의 뛰어난 처리 속도를 자랑합니다.\r\r\n\r\r\n또한, VLAN에서 VxLAN으로 전환한 이유도 흥미로웠는데, 이는 고객 수가 증가함에 따라 퍼블릭 환경에서 여러 VPC(Virtual Private Cloud)를 생성해야 했기 때문입니다.\r\r\n\r\r\n### 보안과 안정성\r\r\n\r\r\n\r\r\n보안과 안정성 측면에서도 다양한 개선이 이루어졌습니다. 기본적으로 Neutron이 제공하는 Security Groups와 함께 Network ACL을 구성하여, 서버가 클라이언트 상태 정보를 저장하지 않아도 통신할 수 있는 환경을 구축했습니다. 또한, Internet Gateway 없이도 원격 호스트와 통신할 수 있도록 VPN Gateway를 연결해 네트워크 통신의 유연성을 강화했습니다.\r\r\n\r\r\n![6.png](https://image.toast.com/aaaadh/real/2024/techblog/6.png)\r\r\n\r\r\nNHN Cloud는 2015년 서비스 시작 이후, OpenStack Neutron에 다양한 기능을 추가하기 위해 여러 플러그인과 자체 개발한 에이전트들을 도입해왔는데요. 세션을 통해 NHN Cloud가 기존의 네트워크 문제를 혁신적으로 해결하고, 서비스 안정성과 보안을 동시에 강화한 점을 직접 확인할 수 있었습니다. 동시에 클라우드 네트워크 관리의 복잡성을 체감할 수 있었습니다.\r\r\n\r\r\n\r\r\n\r\r\n### 2. Bridging the Gap Between Community and Contributing Orgs\r\r\n\r\r\n![7.jpg](https://image.toast.com/aaaadh/real/2024/techblog/7.jpg)\r\r\n\r\r\n강의 형태로 진행되는 세션이 아닌 참석자들과 함께 자유롭게 토의하는 포럼 형태의 세션도 제공되었습니다. 그중 하나인 **Bridging the Gap Between Community and Contributing Orgs**은 오픈 소스 커뮤니티를 더욱 활성화하기 위해 자유롭게 의견을 공유하는 자리였습니다. 주요 논의는 신규 기여자와 기존 기여자가 모두를 위한 커뮤니케이션을 활성화하고 기여자 경험을 개선하기 위한 방안을 논의하는 세션이었습니다.\r\r\n\r\r\n다양한 국가의 수많은 사람들이 오픈인프라 프로젝트에 기여하고 있는 만큼 커뮤니케이션의 한계를 극복하고 다양성을 높이고자하는 열정이 느껴지는 세션이었습니다.\r\r\n\r\r\n## OpenStack’s Role in the Future\r\r\n\r\r\n\r\r\n오픈인프라 서밋 아시아 2024는 클라우드 산업의 혁신을 선도하는 오픈소스 커뮤니티의 중요성을 다시 한 번 강조한 행사였습니다.\r\r\n\r\r\n특히 VMware에서 오픈스택으로의 마이그레이션이 주목을 받으면서 확장 가능하고, 안전하며, 비용 효율적인 솔루션으로 오픈스택을 도입하려는 기업들이 전 세계적으로 많다는 것을 느낄 수 있었습니다.\r\r\n\r\r\n또한, AI와 같은 고성능 컴퓨팅을 위한 지속 가능한 인프라에 대한 요구가 커지고 있는 상황에서, 오픈인프라 커뮤니티는 혁신적이고 획기적인 솔루션으로 이러한 글로벌 과제에 대응할 준비가 충분히 갖추어져 있음을 확인할 수 있었습니다. 이번 서밋을 통해 오픈소스 기반 인프라의 미래와 지속 가능한 기술 개발에 대한 기대감이 더욱 커졌습니다.",
        "isoDate": "2024-11-11T02:16:45.000Z"
      }
    ]
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "해자(垓字)는 없다",
        "link": "https://www.thestartupbible.com/2024/11/no-such-thing-as-a-moat-in-consumer-brands.html",
        "pubDate": "Sun, 10 Nov 2024 21:34:00 +0000",
        "content:encodedSnippet": "요새 VC들이 소비재 쪽의 사업은 상당히 보수적으로 검토하거나 아예 투자하지 않는 것 같은데, 우린 이런 분위기와는 상관없이 계속 이 분야에서 재미있는 일을 하고 있는 창업가들을 만나고, 투자하고 있다. 최근에도 생필품, 의류, 그리고 음식 분야에서 사업하고 있는 여러 창업가를 만났다. 자체 브랜드를 만들어서 직접 고객에게 자사몰, 그리고 다른 온라인 플랫폼이나 오프라인 유통 채널을 통해서 판매하고 있는데, 대부분 내가 이 글에서 말했던 그런 어려움을 사업의 단계와는 상관없이 직접 경험하고 있는 것 같았다.\n이분들과 이야기를 하면, 항상 등장하는 주재가 ‘해자(垓字)’이다. 사업의 종류에 상관없이 VC들이 창업가들에게 물어보는 게 그 사업만의 차별점, 진입장벽, 보호 장벽, 해자 관련 질문인데, “지금까지 비슷한 사업을 여러 번 검토했는데, 모두 다 비슷한 방식으로 비슷한 비즈니스 모델로 같은 시장에서 경쟁하는 것 같네요. 우리가 다른 경쟁사보다 더 잘할 수 있는, 우리만의 해자가 있나요?” , “이 사업이 잘되면 분명히 대기업도 같은 사업을 할 텐데요, 그 상황에서 우리가 이길 수 있는 우리만의 해자가 있을까요?”와 같은 유의 질문이다. 솔직히 이 질문에 대한 정답은 없다. 만약, 이 질문에 대한 답변이 투자에 결정적인 영향을 미친다면, 이런 질문을 한 VC는 결국엔 이 사업에 투자하지 않겠다는 의미다. 비슷한 분야에서 경쟁하는 회사들이 투자자를 설득할 만한 명확하고 논리적인 해자를 갖추긴 어렵고 – 특히, 이제 막 시작하는 초기 스타트업은 – 대기업이 이 분야에 진출했을 때 다윗 같은 스타트업이 골리앗 같은 대기업을 이길만한 해자는 없기 때문이다. 아니, 이론적으로 명확하고 논리적인 상상 속의 해자가 있더라도, 아마도 투자자는 이 말을 믿지 않을 것이다.\n특히나, 기술력이 뒷받침되는 소프트웨어 회사가 아니라, 공장에서 뭔가를 만들어서 판매하는 브랜드나 D2C 회사들은 이런 해자를 만드는 건 거의 불가능하다. 우리도 이 분야에서 사업하는 한국과 미국 회사에 꽤 많이 투자하면서 이 힘든 현실을 간접적으로 경험했고, 나는 몇 년 전부터 이런 현실을 인정하기 시작했다. 그리고, 이제 브랜드를 만드는 사업 분야에서 해자라는 건 존재하지 않는다는 걸 잘 받아들이고 있고, 아예 이 분야에서 사업하는 창업가들에겐 본인이 하는 사업의 해자는 무엇인지라는 질문을 하지 않는다.\n최근에 우리가 투자한 이런 D2C/브랜드 사업들을 보자: 제주 귤을 원료로 주스와 같은 다양한 시트러스 제품을 만드는 귤메달; 파워레이드나 게토레이드랑 같은 카테고리에 속한 기능성 스포츠 드링크 얼티밋포텐셜을 만드는 어센트스포츠; 그리고 반려동물을 위한 영양제 페노비스를 만드는 노즈워크. 모두 다 잘하고 있는 스타트업이지만, 다른 스타트업도 충분히 이 분야로 들어올 수 있고, 돈/시간/인력이 압도적으로 많은 대기업도 진출할 수 있는 매력적이고 규모가 나오는 시장이다. 이런 무시무시한 회사들이 우리 투자사들과 경쟁하기 시작하면 우리 창업가들은 어떤 해자를 만들면서 이길 수 있을까?\n정답은, 이들이 구축할 수 있는 해자는 없다. 이 치열한 분야에서 이기기 위해선 수단과 방법을 가리지 말고 모든 합법적인 방법을 동원해야 하고, 되도록 많은 소비자들의 눈에 노출되고, 그냥 무조건 많이 팔아서 매출 잘 만들어야 한다. 어떻게 많이 팔고, 어떻게 매출을 많이 만들 수 있을까? 이 또한 정답도 없고, 이를 위한 해자라는 것도 없다. 그냥 좋은 제품 만들고, 최대한 많은 채널을 통해서 유통하고, 동시에 마케팅도 잘 해야 한다. 나중에, 아주 나중에, 혹시나 자체 공장을 만들거나 우리 제품을 OEM 제조하는 공장을 인수해서 생산의 전 과정을 수직통합 할 수 있다면, 어쩌면 이건 품질관리, 공정관리, 수량 조정, 가격 조정 면에서 우리에게 해자가 될 수도 있다. 그런데 자체 공장에 대해서 고민하는 단계까지 왔다면, 이미 우린 시장에서 알아주고 인정해 주는 브랜드가 됐을 것이고, 여기에서 말한 대로, 특정 분야에서 가장 먼저 떠오르는 브랜드가 됐다면, 이 자체가 엄청난 해자가 될 수 있다.\n하지만, 누구나 다 아는 그 강력한 브랜드가 되기 전까지는, 해자라는 건 존재하지 않으니, 자꾸 우리만의 차별점이나 해자를 만들기 위해서 고민하지 말고, 그 시간에 그냥 물건 하나라도 더 팔아라. 대신, 남들보다 더 빠르게 움직이고, 너무 깊이 생각하기보단 get things done 전략으로 실행에 집중해라.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/11/no-such-thing-as-a-moat-in-consumer-brands.html#respond",
        "content": "요새 VC들이 소비재 쪽의 사업은 상당히 보수적으로 검토하거나 아예 투자하지 않는 것 같은데, 우린 이런 분위기와는 상관없이 계속 이 분야에서 재미있는 일을 하고 있는 창업가들을 만나고, 투자하고 있다. 최근에도 생필품, 의류, 그리고 음식 분야에서 사업하고 있는 여러 창업가를 만났다. 자체 브랜드를 만들어서 직접 고객에게 자사몰, 그리고 다른 온라인 플랫폼이나 오프라인 유통 채널을 통해서 판매하고 있는데,(...)",
        "contentSnippet": "요새 VC들이 소비재 쪽의 사업은 상당히 보수적으로 검토하거나 아예 투자하지 않는 것 같은데, 우린 이런 분위기와는 상관없이 계속 이 분야에서 재미있는 일을 하고 있는 창업가들을 만나고, 투자하고 있다. 최근에도 생필품, 의류, 그리고 음식 분야에서 사업하고 있는 여러 창업가를 만났다. 자체 브랜드를 만들어서 직접 고객에게 자사몰, 그리고 다른 온라인 플랫폼이나 오프라인 유통 채널을 통해서 판매하고 있는데,(...)",
        "guid": "https://www.thestartupbible.com/?p=9262",
        "categories": [
          "Uncategorized",
          "B2C",
          "brand",
          "consumer",
          "FoundersAtWork",
          "marketing",
          "strategy",
          "Strong",
          "vc"
        ],
        "isoDate": "2024-11-10T21:34:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "이제 안심해도 됩니다",
        "link": "https://www.thestartupbible.com/2024/11/in-good-hands.html",
        "pubDate": "Wed, 06 Nov 2024 21:23:00 +0000",
        "content:encodedSnippet": "영어에서 많이 사용하는 문장 중 “You are in good hands”라는 말이 있다. 말 그대로 믿을만한 손이 나를 잘 잡고 있으니 걱정하지 말고 안심해도 된다는 의미다. 다양한 상황에서 이 말을 하는데, 비즈니스 상황 외에 내가 가장 많이 이 말을 들었던 건 미국 영화나 드라마에서 주인공이 적진에 침투해서 인질을 구출하면서 안심시키는 장면이 아닐까 싶다. 나도 영어로 대화할 땐 이 말을 꽤 자주 사용하는데, 투자자로서 내가 우리 투자사 대표님들에게 주로 하는 말이다.\n스트롱이 첫 번째 기관 투자를 했다면, 이 스타트업의 대표에게 “우리가 한국에서 투자를 제일 잘하는 VC도 아니고, 우리한테 투자를 받으면 회사가 꼭 성공하는 것도 아니지만, 그래도 you are in good hands 입니다. 저희는 회사들이 힘들 때 뒤에서 같이 고민하고 같이 궂은일을 할 준비가 되어 있는 투자자예요.”라는 말을 자주 한다. 우리 투자사 중 80% 이상이 우리가 첫 번째 기관투자를 했으니, 대부분의 대표님들에게 이런 말을 한다고 봐도 된다.\n솔직히 한국어로 “우리랑 같이 하니까 앞으론 걱정하지 말고 안심해도 됩니다.”라고 말하는 거랑 영어로 “You are in good hands”라고 하는 거랑 느낌이나 어감이 많이 다르긴 하다. 영어로 하는 게 임팩트가 훨씬 더 크긴 한데, 어쨌든 이 말은 내가 투자자로서 창업가들에게 자주 하는 말이다.\n그런데 얼마 전에 이 반대의 상황을 경험했다. 우리가 여러 번 투자한 스타트업의 대표가 나한테 “You are in good hands.”라고 했는데, 이 말을 듣고 뭔가 기분이 묘하긴 했다. 기분이 묘했다는 게 나빴다는 건 전혀 아니고, 오히려 그 반대였다. 내가 항상 불안해하는 창업가분들에게 이 말을 하면, 이분들의 표정이 조금은 더 편해지고, 심적으로 안정감을 찾는 것 같았는데, 나도 그런 느낌이 들었다고나 할까? “아, 이 말을 들으니, 이런 기분이 드네. 좋구먼.” 뭐, 이런 생각을 했던 것 같다.\n그 회사의 자세한 상황에 대해서 여기서 말하진 않겠다. 그런데 모든 스타트업이 그렇듯이 항상 돈은 없고, 항상 사업은 불안하고, 항상 원하는 수치는 안 나오는, 그런 전형적인 초기 스타트업이 대부분 거치는 긴 어둠의 터널을 지나는 중이었다. 우리는 사업을 직접 하는 사람은 아니지만, 이런 힘든 시기를 겪고 있는 창업가들과 워낙 많이 교류하다 보니, 이들과의 대화 속에서 항상 우리의 걱정과 근심이 직간접적으로 반영된다. 그날도 이야기하면서 이런 나의 우려가 표출됐던 것 같은데, 이분이 나를 똑바로 보면서, “걱정하지 마세요. You are in good hands.”라는 말을 했다. 이 말을 듣고 정말로 얼마나 안심이 되던지, 아마도 그분은 잘 모를 것이다.\n그래서 어느 순간부터 나는 우리에게 자금을 제공해 주는 해외 LP 분들이 글로벌 경기, 한국의 경기, 북한, 스트롱의 포트폴리오, 스트롱의 어려운 상황들 등에 대해서 우려를 표시하면, “Don’t worry. You are in good hands.”라는 말을 하기 시작했다. 우리의 창업가분들이 우리에게 큰 안심을 제공하듯이, 내가 하는 이 말도 우리의 LP들에게 큰 안심을 줄 수 있길 바란다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/11/in-good-hands.html#comments",
        "content": "영어에서 많이 사용하는 문장 중 “You are in good hands”라는 말이 있다. 말 그대로 믿을만한 손이 나를 잘 잡고 있으니 걱정하지 말고 안심해도 된다는 의미다. 다양한 상황에서 이 말을 하는데, 비즈니스 상황 외에 내가 가장 많이 이 말을 들었던 건 미국 영화나 드라마에서 주인공이 적진에 침투해서 인질을 구출하면서 안심시키는 장면이 아닐까 싶다. 나도 영어로 대화할(...)",
        "contentSnippet": "영어에서 많이 사용하는 문장 중 “You are in good hands”라는 말이 있다. 말 그대로 믿을만한 손이 나를 잘 잡고 있으니 걱정하지 말고 안심해도 된다는 의미다. 다양한 상황에서 이 말을 하는데, 비즈니스 상황 외에 내가 가장 많이 이 말을 들었던 건 미국 영화나 드라마에서 주인공이 적진에 침투해서 인질을 구출하면서 안심시키는 장면이 아닐까 싶다. 나도 영어로 대화할(...)",
        "guid": "https://www.thestartupbible.com/?p=9259",
        "categories": [
          "Uncategorized",
          "B2C",
          "FoundersAtWork",
          "fundraising",
          "inspiring",
          "Strong"
        ],
        "isoDate": "2024-11-06T21:23:00.000Z"
      }
    ]
  },
  {
    "name": "Build a Great Product",
    "category": "개인",
    "posts": []
  },
  {
    "name": "지금 써보러 갑니다",
    "category": "개인",
    "posts": []
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "로제와 브루노 마스의 ⟨APT.⟩는 얼마를 벌었을까?",
        "link": "https://blog.toss.im/article/fandustry-03",
        "pubDate": "Tue, 12 Nov 2024 00:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}아파트 아파트… 아파트 아파트…. 이 단어가 머리에서 나가질 않는다. 로제와 브루노 마스의 목소리도 너무 좋다. 친구들과 아파트 게임을 하며 술 마실 나이는 아니지만, 누가 아파트 아파트~ 라고 술 게임을 하자고 하면 당장 그다음 구절을 이어 부를 자신은 있다. 물론 아무도 그걸 원하진 않겠지만.\n2024년 10월 18일에 발매된 로제 & 브루노 마스의 ⟨APT.⟩가 계속 화제다. 여러모로 상징적인 순간을 보여주는 곡인데, 음악적 평가만큼 차트 기록도 매우 높다. 음악적 평가는 조금 뒤로 미루고 일단 차트 기록만 살펴보자.\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}11월 3일 기준, ⟨APT.⟩는 아이튠즈, 스포티파이, 유튜브 글로벌 차트 1위를 차지하고 있다. 스포티파이의 누적 스트리밍은 1억 8,336만 9,499회, 유튜브에서는 2억 5,327만 1,907회다. 서비스별로 가장 많은 1위를 기록한 국가를 보면 인도네시아(아이튠즈 1위, 스포티파이 1위, 애플뮤직 1위, 유튜브 1위, 샤잠* 1위), 필리핀(아이튠즈 1위, 스포티파이 1위, 애플뮤직 1위, 유튜브 1위, 샤잠 1위), 호주(아이튠즈 1위, 스포티파이 1위, 유튜브 1위, 샤잠 1위), 대만(아이튠즈 1위, 스포티파이 1위, 애플뮤직 1위, 유튜브 1위), 일본(스포티파이 1위, 애플뮤직 1위, 샤잠 1위), 캐나다(스포티파이 1위, 유튜브 1위), 태국(애플뮤직 1위, 디저** 1위), 베트남(애플뮤직 1위, 유튜브 1위) 등이다. 한국은 애플뮤직과 샤잠에서 1위를 차지했다.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*노래를 들려주면 음원을 검색해 주는 플랫폼으로 2018년 애플이 인수했다. 2022년 월간 활성 사용자 수가 2억 2,500만 명이라고 발표했다.\n**Deezer. 프랑스 온라인 음악 스트리밍 서비스.\n이 정도의 결과라면 수익도 궁금하다. 음원 스트리밍에서의 수입은 여러 저작권이 더해진 총매출로, 국가별로 항목이 조금씩 다르다. 미국을 기준으로 보자면 크게 Sound Recording, Mechanical, Performance 항목을 기준으로 수익을 나누는데, 미국은 한국과 달리 업체별로 다른 기준을 적용하기 때문에 실제 수익은 당사자들만 안다. 물론 추정은 가능하다.\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\nSound Recording | 저작권 소유자에게 지급되는 금액. 대부분의 경우 음반사를  말하지만 포괄적으로 독립 아티스트, 프로듀서, 투자자도 포함된다.\nMechanical | 저작물을 디지털 및 물리적 형식으로 복제해 얻는 수익으로, 퍼블리셔에게 기계적으로 지급되는 로열티. 쉽게 말해 작사/작곡가가 버는 돈이다.\nPerformance | 음악 작품이 공식적으로 연주되거나 방송될 때마다 받는 로열티. ASCAP(미국 음악 저작권협회), BMI(방송음악협회), GMR(Global Music Rights) 및 SESAC 같은 공연 권리 단체들이 포함된다.\n\n미국의 음악 산업 전문 법무/컨설팅 회사인 매나트, 펠프스 앤 필립스(Manatt, Phelps & Phillips)는 음원 로열티를 지급하는 다수의 기업을 조사한 데이터를 기반으로 ‘.css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}음악 스트리밍 로열티 계산기’를 만들었다. 복잡한 수식은 뒤로 숨기고, 스포티파이나 애플뮤직의 재생수를 입력하면 총매출의 추정치가 나오는 계산기다. 추정치일 뿐이지만 대략 얼마 정도의 매출을 거뒀는지 짐작할 수는 있다.\n이제 ⟨APT.⟩의 숫자를 입력할 차례다. 이 노래는 전 세계 기준으로 단 2주 만에 스포티파이에서 1억 8,336만 9,499회 재생됐다. 사실 이 계산기는 미국 내 스트리밍 로열티만 계산하기 때문에 전 세계 누적 스트리밍 횟수를 그대로 넣으면 안 되지만(미국 내 스트리밍 횟수와 국가별 환율도 고려해야 하므로) 우리의 목적은 추정치를 확인하는 것이므로, 그냥 무식하게 이대로 넣어보자.\n결괏값은 두 개다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}.css-wgpbp3{display:block;margin-top:6px;}로제와 브루노 마스의 ⟨APT.⟩를 음악 스트리밍 로열티 계산기에 넣어본 결괏값 \n스포티파이는 87만 7,932달러(약 12억 1,198만 원)를, 애플뮤직은 155만 7,129달러(약 21억 4,961만 원)를 로열티로 제공한 것으로 추정된다. 음원이 발매된 지 단 2주 만에 33억 원의 매출을 낸 것이다. 물론 로제와 브루노 마스가 이 돈을 다 가져가는 건 아니다. 이들은 여기서 작곡, 작사, 편곡, 가창의 몫을 가져갈 것이다. 글로벌에서 성공한 히트곡이란 대략 이 정도의 매출을 만드는군, 이라는 참고 자료다. 그런데 모두가 스트리밍으로 이렇게 돈을 벌 수 있을까? 이건 정말 예외적인 경우가 아닐까?\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}스트리밍이 정말 돈이 될까?\n스트리밍 시장은 계속 성장하고 있다. 2023년 기준 전 세계 음악 스트리밍 시장 규모는 364억 9,000만 달러로 추정된다. 50조 569억 8,200만 원 정도의 규모다. 2023년부터 2031년까지의 음악 스트리밍 시장의 연평균 성장률(CAGR)은 8.7%를 기록할 것으로 전망되고, 규모도 거의 두 배에 달하는 713억 2,000만 달러에 이를 것으로 예상된다. 스트리밍 이전 시대와 비교하면 사실상 그 규모*를 넘어선 수치다.\n*세계 음악시장 매출은 .css-114ityv{white-space:pre-wrap;cursor:pointer;-webkit-text-decoration:underline!important;text-decoration:underline!important;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}1999년 278억 달러를 기록한 뒤, 2011년까지 12년 연속 감소했다.\n지금이야말로 음악을 사랑하는 사람들이 늘 꿈꾸던 ‘음악으로 충만한 세상’이다. 하지만 그 결과는 우리의 상상과는 완전히 다르다. 스포티파이에 등록된 음악은 1억 곡이 넘지만, 한 번도 재생되지 않은 곡도 수백만 곡에 이른다. 에드 시런과 테일러 스위프트는 2022년까지 스포티파이에서 약 7~8천만 달러를 정산받았지만, 어떤 싱어송라이터는 1년에 100달러 미만을 정산받는다.\n시장이 성장하면서 잠재적 기회는 많아졌지만, 대부분의 수익은 상위 10% 미만의 메이저에게 돌아간다. 소위 ‘메이저’라고 불리는 이들도 모두가 큰돈을 버는 건 아니다. 더 많은 재생 수를 위해서는 더 큰 비용을 써야 하고, 그마저도 지속 가능하고 안정적인 수익을 약속해 주지 않기 때문이다.\n만약 ⟨APT.⟩가 1980년대처럼 5,000원짜리 싱글 음반으로 판매됐다면 12억 1,198만 5,126원의 매출을 위해 1억 8,336만 9,499회의 스트리밍 대신 24만 장의 CD를 파는 것으로 충분했을 것이다. 이처럼 실물 음반에 비하면 스트리밍의 수익성은 낮다. 그렇다면 이런 환경에서 ‘디지털 콘텐츠’ 형태의 음악은 어떤 역할을 하고 있을까?\n유명하지만 돈을 못 버는, 콘텐츠의 역설\n20세기에는 ‘콘텐츠’란 말 자체가 없었다. 콘텐츠의 사전적 의미는 ‘네트워크로 유통되는 멀티미디어 파일’이니까. 전자 네트워크가 생기고 콘텐츠란 말이 태어나기 전의 음악 사업은 음반을 판매하는 것이 거의 유일한 수익 모델이었다. 음악은 음반으로 듣고, 영화는 DVD로 보고, 게임은 게임 타이틀로 하고, 책은 책을 읽어야 했던 것처럼 다른 걸 고려할 수 없었기 때문이다.\n다시 말해 20세기의 음악 산업은 제조업이었다. 음반을 만들고 판매해서 돈을 벌었다. TV에 출연하거나 뮤직비디오를 만들거나 심지어 콘서트를 여는 것도 피지컬(physical) 음반을 판매하기 위한 홍보 활동이었다. (이는 영화, 게임, 출판도 마찬가지였다.)\n그런데 21세기에 디지털 전환이 일어나면서 물리적인 제품에서 멀티미디어가 분리되어 통신망으로 유통되기 시작했고, 음악과 게임의 비즈니스 모델이 무너지기 시작했다. (영화와 출판은 이제야 비슷한 문제를 겪는 중이다). 유선 인터넷, 무선 인터넷, LTE와 5G까지 네트워크 기술이 발전하는 동안 음악과 게임은 다운로드, 스트리밍, 구독 모델을 만들며 새로운 환경에 대응해 왔고, 게임 산업은 ‘인앱 결제’라는 방식으로 비즈니스 모델 문제를 해결하기도 했다.\n그런데 이건 유통 및 공급자의 입장이다. 실제로 음악이나 게임을 만드는 저작권자들은 늘어난 경쟁과 줄어든 수익성의 틈에서 버티기 어려워지고 있다. 음악(콘텐츠)의 초과 공급 아래 콘텐츠 판매 수익은 0에 수렴하기 때문이다. 스포티파이에 하루 동안 업로드되는 신곡의 수, 유튜브에 1분 동안 업로드되는 콘텐츠의 개수, 1년에 발간되는 책의 권수, 킨들에서 발행되는 전자책의 양, 넷플릭스에 업로드되는 비디오 개수… 이 모든 숫자들은 커지고 있지만, 저작권자에게 돌아가는 수익은 적어지고 있다는 점에서 그야말로 풍요 속의 빈곤이다.\n앞서 언급한 ⟨APT.⟩의 사례처럼 ‘유명해지면 되는 것 아닌가?’라고 생각할 수 있다. 하지만 일단 넘치는 콘텐츠 시대에서 유명해지기 위해서는 (매우 운이 좋지 않은 이상) 돈이 많이 들 수밖에 없다. 수많은 콘텐츠 중에서 사람들의 높은 관심을 끌어야 하기 때문이다. 앞서 우리는 스포티파이를 통해 발생한 매출이 12억 원 정도일 것으로 추정했다.\n그런데 제작비는 얼마였을까? 2020년에 니키 미나즈의 피처링 가격이 곡당 6억 원 정도였다는 자료를 참고해, 2024년 브루노 마스의 피처링 비용은 적어도 10억 원이 들었을 것으로 예상해 보자. 그 외 작곡, 편곡, 레코딩, 뮤직비디오 제작비와 마케팅 비용 등을 감안한다면 ⟨APT.⟩ 한 곡의 제작비는 최소 15억 원으로 추정해 볼 수 있을 것이다.\n이렇게 돈을 써서 스트리밍 차트에서 1위를 했더라도, 유명세를 수익으로 전환하는 건 정말 어렵다. 음악이 좋다고 모두가 음반을 구매하거나 공연장에 가는 건 아니기 때문이다. 이런 상황에서 스트리밍만으로 손익분기점을 넘는 건 일반적으로 쉽지 않다. 음악 산업에서의 깔때기 구조*에 따르면, 추상적인 인기를 구체적인 사업으로 전환하는 건 매우 복잡하다. 이게 바로 ‘콘텐츠의 역설’, 유명한데 돈을 못 버는 상황이다.\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n💡 음악 산업에서의 깔때기 구조 \n\n소비자 행동 이론 중에 고객 퍼널 구조, 혹은 깔때기 구조라고 불리는 모델이 있다. 잠재적 소비자가 고객으로 변해 가는 과정을 분석하는 도구로, 음악에 빗대면 다음과 같다. \n\n음악에서 깔때기 구조는 스트리밍→음악→콘서트로 심화된다. 여기서 스트리밍은 관여도가 낮은 첫 단계다. 그 후 여러 요인들(듣기에 좋아서, 화제가 되어서, 추천곡으로 떠서 등) ‘좋아요’를 누르고 팔로우를 하면서 관여도가 높은(돈을 쓸 가능성이 높은) 고객으로 전환되고, 음반을 구매하거나 콘서트에도 올 수 있는 고객이 된다.\n\n그럼에도 스트리밍이 중요한 이유\n그렇다면 스트리밍 차트 1위는 수익과 관련해서는 아무런 쓸모도 없는 걸까? 아니, 그럼에도 차트 1위라는 화제는 여전히 필요하다. 스트리밍 차트 성적은 더 많은 기회를 만들기 때문이다. ⟨APT.⟩의 1위로 로제가 얻을 기회는 대략 다음과 같다.\n\n후속곡의 성공: ⟨APT.⟩는 로제가 올해 말에 발매할 솔로 1집의 선공개 싱글이었다. ⟨APT.⟩의 성공으로 이후 발표될 곡들에 대한 기대감이 높아졌고 수록곡들도 큰 인기를 얻을 수 있다.\n로제의 섭외비: 방송 출연료, 페스티벌 섭외비, 광고 출연료, 피처링 비용 등이 상승한다.\n로열티 정산 비율이 달라질 수 있다.\n\n이렇게 보면 스트리밍은 단순히 깔때기 구조의 하단에 위치하는 게 아닌, 기회비용을 높이는 전략이 된다. 이 과정에서 팬의 역할이 무엇보다 중요하다. 스트리밍은 팬을 만드는 도구이기도 하지만, 동시에 팬들이 스트리밍에 영향을 주기도 하기 때문이다.\n일반적으로 팬은 음악을 발표하고 활동을 지속하는 과정에서 만들어진다고 여겨졌다. 그러나 지금은 처음부터 팬이 필요하다. 1화에서 말했듯 팬은 소비자나 부가 가치가 아닌, 수익 그 자체를 만드는 존재이면서 산업을 지탱하는 기반이기 때문이다. 과거의 음악 산업이 팬을 아티스트 활동의 결과물로 여겼다면, 지금의 음악 산업은 팬을 처음부터 필요한 존재로 여긴다. 그렇기 때문에 데뷔와 함께, 혹은 데뷔 전에 이미 팬을 모을 수 있는 방법론을 고민한다. 신인 팀을 위한 오디션, 데뷔 전의 소셜 미디어 활동 등이 바로 그중 일부다.\n이렇게 처음부터 만들어진 팬은 (일반 소비자와 다르게) 아티스트와 밀도 높은 관계를 형성하고, 그로부터 지속 가능한 성장을 만든다. 미디어가 산산이 쪼개진 현재, 팬들은 자신의 취향과 맞는 콘텐츠를 찾아가며 그 과정에서 본인이 직접 브이로그 등의 콘텐츠를 제작해 아티스트를 알리는가 하면, 스트리밍 순위를 올리기 위한 집단행동을 하며 기업의 미디어 비용을 줄이는 역할도 맡는다.\n하지만 우리는 로제도, 브루노 마스도 아닌데 어떻게 팬을 만들 수 있을까? 여기에 정답은 없다. 당신이 뮤지션이라면 오디션 프로그램을 통해 팬을 만들 수도 있지만, 인스타그램 라이브나 소셜 미디어 활동 등을 통해 먼저 팬을 만들 수도 있다. 음악을 먼저 발표하는 게 아니라 여러 활동으로 팬을 구한 다음, 진짜 하고 싶은 것을 하는 시대가 온 것이다.\n음악에만 국한되는 얘기는 아니다. 영화도, 게임도, 글을 쓰는 저자도 마찬가지다. 지금 팬이 필요한 상황이라면, 팬이 모이고 성장하는 5단계를 참고해 보길 바란다. 아래는 내가 직접 만든 팬의 행동 변화 5단계로, 팬 비즈니스의 기반이 되는 구조다.\n팬의 행동 변화 5단계 .css-hokoge{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;counter-reset:numberedList;}.css-hokoge ul,.css-hokoge ol{margin:16px 0 0;}.css-hokoge>li{counter-increment:numberedList;margin-bottom:16px;padding-left:24px;}.css-hokoge>li:last-of-type{margin-bottom:0;}.css-hokoge>li>span{position:relative;}.css-hokoge>li>span>:first-child::before{content:counter(numberedList) '.';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n접촉(contact): 미디어 노출로 콘텐츠를 접하는 단계\n몰입(dive): 팔로우, 검색 등을 통해 적극적이지만 가벼운 관계를 형성하는 단계\n재미(play): 공유를 통해 제3자에게 정보를 공유하는 즐거움을 느끼는 단계\n사랑(love): 깊어지는 관계를 통해 감정과 관계의 밀도가 높아지는 단계\n헌신(devotion): 자신의 안정적인 감정 상태를 지키기 위해 행동하는 단계\n\n좋은 마케팅으로 짧은 성과는 낼 수 있다. 그러나 지속적이고 안정적인 성과를 내기 위해서는 반드시 팬이 필요하다. 그게 우리가 해결해야 할 문제다. \n\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 송수아 Graphic 이은호 이제현",
        "content": "디지털 콘텐츠 시대에 스트리밍의 역할",
        "contentSnippet": "디지털 콘텐츠 시대에 스트리밍의 역할",
        "guid": "https://blog.toss.im/article/fandustry-03",
        "isoDate": "2024-11-12T00:00:00.000Z"
      },
      {
        "title": "토스, 금융보안원 주관 ‘금융보안 위협분석 대회’ 우승",
        "link": "https://blog.toss.im/article/Toss-Fiesta2024",
        "pubDate": "Mon, 11 Nov 2024 00:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}FIESTA 2024 참가…사이버 위협 관련 출제 문제 모두 풀며 최우수상 수상\n2021년부터 4번째 대회 우승…국내 최고 수준 보안 역량 입증\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n모바일 금융 서비스 ‘토스’를 운영하는 비바리퍼블리카(이하 ‘토스’)가 금융보안원 주관 ‘금융보안 위협분석 대회(FIESTA 2024)’에서 우승했다고 11일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n이 대회는 금융권 사이버 보안 위협분석 및 침해 대응 역량 강화를 목적으로 열리는 행사다. 실제 발생할 수 있는 사이버 위협 시나리오를 토대로 출제된 문제를 푸는 방식으로 우승자를 가린다. 올해 대회는 10월 4일부터 6일까지 사흘간 진행됐다.\n토스는 ‘디카페인 말차라떼’라는 팀명으로 보안팀 소속 최정수, 권재승, 강동석, 김재성 화이트해커가 참가했다. 이들은 특히 생성형 AI, 클라우드, 공급망 분야에서 침해 사고 대응 역량을 검증하는 문제들을 모두 풀어내며 대회 1위 쾌거를 이뤘다. 첫 출전인 2021년부터 올해까지 4년 연속 우승으로 국내 최고 수준 금융보안 역량을 입증했다.\n토스는 이번 대회에 참가한 4명을 비롯해 화이트해커로 구성된 팀을 두고 있다. 해당 팀은 사이버 공격에 대비한 훈련 등으로 토스 보안 체계 구축에 힘을 쏟고 있다. 상시로 버그바운티 챌린지(모의 해킹대회)를 운영하며 새로운 보안 기술을 연구에도 매진하고 있다.\n그 결과 ‘ISO27001’, ‘ISMS-P’, ‘PCI DSS Level1’, ‘ISO 27701’ 인증을 취득하는 등 보안과 정보보호 체계 전반에서 세계 최고 수준 평가를 받고 있다.\n토스 관계자는 “4년 연속 우승이라는 쾌거로 토스의 보안 역량을 더 확실하게 증명할 수 있어 기쁘다”라며 “앞으로도 보안 투자와 연구를 지속하며 고객들의 안전한 금융 생활을 위해 매진하겠다”라고 말했다.",
        "content": "4년 연속 쾌거",
        "contentSnippet": "4년 연속 쾌거",
        "guid": "https://blog.toss.im/article/Toss-Fiesta2024",
        "isoDate": "2024-11-11T00:00:00.000Z"
      },
      {
        "title": "‘탄소 손자국’의 힘, 나의 작은 실천이 지구의 미래를 바꿔요",
        "link": "https://blog.toss.im/article/economic-terms-35-carbon-handprint",
        "pubDate": "Thu, 07 Nov 2024 02:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-8atqhb{width:100%;}.css-1c1qox8{font-size:30px;letter-spacing:0em;line-height:1.55;font-weight:bold;color:var(--adaptiveGrey900);margin:40px 0 4px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-p4abj2{display:contents;line-height:1.55;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}🔖 이번 주 경제 용어\n탄소 손자국\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1iisb9p{display:contents;line-height:1.6;}\n.css-1pgssrp{max-width:100%;border-radius:16px;}\n.css-1kxrhf3{white-space:pre-wrap;}특정 상품이나 서비스를 사용하면서 줄일 수 있는 온실가스 배출량을 측정하는 것을 말해요.\n\n\n‘탄소 손자국(Carbon Handprint)’은 우리가 특정 상품이나 서비스를 사용함으로써 감축할 수 있는 온실가스 배출량을 의미하기에, 환경에 미치는 긍정적인 영향을 측정하는 새로운 개념인데요. 기존에 활용되던 개념인 ‘탄소 발자국(Carbon Footprint)’과는 비슷하면서 살짝 달라요.\n탄소 발자국은 상품의 원료, 생산, 소비, 폐기 등 전 과정에서 발생하는 온실가스 발생량을 이산화탄소 배출량으로 환산한 것인데요. 환경에 미치는 ‘부정적 영향'을 측정하는 데에 활용됩니다. 예를 들어, 자동차 운전, 항공 여행, 전기 사용 등이 모두 탄소 발자국을 증가시키는 활동에 해당하는 것이죠.\n반면, 탄소 손자국은 개인이나 조직이 환경에 기여하는 ‘긍정적 영향'을 측정하는 데에 활용됩니다. 온실가스 배출을 위한 노력의 성과를 측정하는 개념이니까요. 즉, 탄소 손자국은 탄소 발자국을 줄이기 위한 ‘노력의 성과’라고도 볼 수 있겠죠. 예를 들면, 에너지 효율이 높은 제품을 사용하거나, 재생 가능한 에너지를 사용하는 것이 탄소 손자국을 증가시키는 활동에 해당합니다.\n이러한 이유로 .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}탄소 발자국은 0에 가까워지도록 최소화하는 것이 목표이지만, 탄소 손자국은 최대한 늘리는 것이 목표가 됩니다.\n탄소 손자국은 크게 2가지로 구분합니다. (1) 기업과 같은 생산자가 생산 과정에서 탄소 배출량을 줄이는 경우, (2) 소비자가 상품을 사용함으로써 탄소 배출량을 줄이는 경우입니다.\n예를 들어, 기업이 공정을 개선해 고효율 냉장고를 생산했다면 생산 과정에서 탄소 발자국을 감축했다 = 즉, 탄소 손자국을 늘렸다 볼 수 있는 것이고요. 소비자가 냉장고 사용 과정에서 전력 소비를 절감하기 위해 노력했다면 또 한 번 탄소 손자국을 확보한 것입니다.\n이처럼 저탄소 제품을 생산하고 사용하는 과정에서 줄인 온실가스 배출량은 해당 제품을 제공한 기업의 성과로 인정되며, 친환경 이미지를 강화하는 데에 기여할 수 있습니다.\n\n\n.css-2yhypk{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);font-style:italic;-webkit-text-decoration:underline!important;text-decoration:underline!important;}\"극적으로 탄소배출량 줄인 이 남자가 소·양 대신 먹은 것“\n(한겨례 21 2024.8.17)\n1.5도 라이프스타일 보고서가 나온 이후, 개별적으로 실험하는 시민들이 등장했다. 영국의 환경운동가 로절린드 리드헤드는 2019년 보고서를 바탕으로 1년간 1t의 탄소만을 배출하는 삶을 시도했다. 처음엔 2050년 목표치인 0.7t에 도전했지만, 현재의 인프라로는 불가능하다고 판단해 1t으로 목표치를 바꾸고 성공했다. 올터는 리드헤드로부터 실험에 관한 이야기를 직접 듣고 실험에 참여하기로 결심했다. “사실 연간 1t은 불가능하다고 생각했어요. 연구소에서 제시한 (2030년 목표인) 2.5t을 목표로 해보기로 했죠.”\n연간 2.5t이라는 배출량도 하루로 치면 약 6.8㎏이다. 붉은 육류 위주의 한 끼 식사에서 배출되는 탄소가 약 7.7㎏ 정도이니, 연 배출 2.5t을 달성하기 위해선 먹거리부터 이동, 소비 등 삶의 전반적인 방식을 바꿔야 했다. 어떻게 가능했을까. 그의 첫 번째 전략은 교통수단의 변화였다. “북미 지역에서 발생하는 탄소배출량의 가장 큰 부분이 자동차입니다. 저는 1년 동안 운전을 완전히 포기했어요.”\n캐나다의 1명당 평균 탄소배출량 구성을 보면 교통이 35%로 가장 많다. 14.2t 중에 5t이 교통에서 배출된다. 올터가 운전을 포기할 수 있었던 이유는 부동산 개발업을 그만두고 환경 관련 웹사이트에 글을 올리는 작가 일을 시작했기 때문이다.\n“저는 운이 좋은 편이었어요. 집에서 일할 수 있었고 아이들도 근처에 있었고요. 제가 사는 도시는 쇼핑도 대부분 도보나 자전거로 할 수 있었어요. 또 대학에 강의를 나갈 때도 자전거를 타고 다닐 수 있었습니다.” 1년 동안 한 번 미국 뉴욕에 다녀온 것 외에는 비행기도 타지 않았다. 식단도 바꿨다. “고기를 포기하는 것은 어렵지만 소나 양을 포기하고 탄소 배출이 훨씬 적은 돼지와 닭만 먹는 것은 그리 어렵지 않았어요. 문제가 되는 건 소나 양과 같은 반추동물이죠.”(중략)\n\n\n전 세계적으로 기후변화에 대응하기 위한 목표는 ‘온실가스 배출을 크게 줄이는 것’입니다. ‘기후변화에 관한 정부간 협의체(IPCC)’는 지구의 온도를 1.5도 이하로 유지하기 위해서는, 개인이 3.4톤 이하의 탄소만 배출해야 한다고 발표했는데요. 이는 전체 온실가스 배출량을 인구 수로 나눈 단순 결과값이었습니다.\n하지만 2019년에 발표된 일본과 핀란드의 '1.5도 라이프스타일 보고서'는 더욱 현실적인 접근을 제안합니다. 각 개인의 생활 방식을 기준으로 탄소 배출을 분석한 것인데요. 보고서에 따르면, 전체 탄소 배출량의 72%가 가정에서의 소비와 관련 있으니 개인이 연간 2.5톤의 탄소만 배출하도록 더 노력해야 한다고 합니다. 더 나아가 2040년에는 1.4톤, 2050년에는 0.7톤까지 줄여야 한다고 했고요.\n기사에 나온 영국의 환경운동가 로절린드 리드헤드는, 실제로 이 보고서에서 제안하는 방향으로 1년간 1톤의 탄소만 배출하는 삶에 도전했습니다. 기사의 또다른 주인공 로이드 올터도 2.5톤 이내로 탄소배출량을 줄이기 위해 이전과 완전히 다른 라이프스타일을 택했고요.\n그렇다면 개인이 배출하는 탄소 양을 줄이기 위해, 우리는 실생활에서 어떤 방법들을 실천해볼 수 있을까요?\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n교통수단 바꾸기: 자동차 운전을 줄이고, 걷기, 자전거 타기, 대중교통 이용하기 등의 습관을 만들어 보세요. 특히 출퇴근할 때 자전거와 대중교통을 사용하면, 자연스럽게 운동이 되기 때문에 건강에도 좋습니다.\n식단 조절: 사육 과정에서 많은 탄소를 배출하는 소와 양 같은 붉은 고기 대신, 돼지나 닭 같이 탄소 배출이 적은 고기를 선택해 보세요. 더 나아가 채식 위주의 식사를 시도하는 것도 좋은 방법입니다.\n소비 습관 바꾸기: 전자제품과 의류 등의 제품을 최대한 오래 사용하고, 새로운 제품을 자주 구매하지 않도록 해요. 하나의 제품을 오래 사용하는 습관을 길러보는 것은 탄소 배출을 줄이는 데 큰 도움이 되겠죠.\n도시 환경 활용: 가까운 곳은 도보로 다니거나 자전거를 활용하는 등, 도시의 친환경적인 구조를 최대한 활용해 봅시다. 네덜란드와 같이 걷기, 자전거 타기에 최적화된 도시에서는 일상생활 속에서 자연스럽게 탄소 손자국을 늘릴 수 있습니다. 이처럼 도시 내 교통수단과 도보, 자전거 사용을 통해 배출량을 줄이는 습관은 탄소 손자국을 늘리는 데 큰 도움이 됩니다.\n\n이렇게 개인의 작은 생활 습관 변화로도 탄소 손자국을 확대할 수 있답니다. 동시에 정부와 기업 역시 탄소 배출을 줄이기 위해 힘을 모아야 합니다. 정부는 탄소 배출을 줄일 수 있도록 도시 설계를 하고, 기업은 생산 과정에서 탄소 배출이 적으면서 친환경 제품을 만들기 위해 노력해야겠죠.\n탄소 손자국을 늘리는 것은 단순히 환경 보호를 위한 수단을 너머, 장기적으로 지구에서 살아가는 우리 모두가 함께 기후 변화에 대응하는 중요한 역할을 하게 될 것입니다.\n\n\n탄소 중립: 최종적으로 탄소 배출량이 ‘0’이 되도록 하는 것을 목표로 하는 개념. 배출한 만큼의 탄소를 흡수하거나 상쇄하는 방법을 함께 수행해요. 나무 심기 같은 활동이 이에 해당됩니다.\n지속 가능한 생활(Sustainable Living): 현 세대가 사용하는 자원이 미래 세대의 자원까지 고갈시키지 않도록, 환경을 생각하며 생활하는 방식. 일회용품을 줄이고 재활용하는 것, 새 제품을 계속 구입하는 것보다 하나의 제품이나 서비스를 오래도록 이용하는 것이 지속 가능한 생활을 실천하는 방법이 될 수 있겠죠.\n\n\n.css-13d8cj1{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;margin:24px 0 8px;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:var(--adaptiveGrey700);}\n.css-1dzrkjz{width:16px;margin-right:8px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}\n.svg-icon-wrapper{position:relative;display:inline-block;width:24px;height:24px;}.svg-icon-wrapper >.svg-icon:empty+.svg-icon-fallback{visibility:visible;z-index:inherit;}.svg-icon{color:var(--adaptiveGrey900);display:inline-block;width:24px;height:24px;display:block;width:100%;height:100%;}.svg-icon svg,.svg-icon img{display:block;width:100%;height:100%;}.svg-icon--hide{display:none;}.svg-icon-fallback{position:absolute;left:0;right:0;top:0;z-index:z-index(hidden);visibility:hidden;display:block;width:100%;height:100%;}.svg-icon-fallback--show{visibility:visible;z-index:inherit;}\n참고 자료\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 금혜원 Graphic 조수희 이동건",
        "content": "탄소 발자국 줄이고, 탄소 손자국 늘리는 생활 습관",
        "contentSnippet": "탄소 발자국 줄이고, 탄소 손자국 늘리는 생활 습관",
        "guid": "https://blog.toss.im/article/economic-terms-35-carbon-handprint",
        "isoDate": "2024-11-07T02:00:00.000Z"
      },
      {
        "title": "토스플레이스, 2024 서울 카페쇼 참가",
        "link": "https://blog.toss.im/article/tossplace-cafeshow",
        "pubDate": "Wed, 06 Nov 2024 23:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}아시아 최대 규모 커피 박람회 참가… 매장 운영 효율 높이는 솔루션 대거 소개\n토스플레이스 전시관, 개막 첫 날 6일 관람객 1천3백여 명 방문\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n비바리퍼블리카(토스)의 결제 단말기 제조 및 결제 솔루션 공급 자회사 토스플레이스(대표 최재호)가 이달 6일부터 9일까지 나흘간 서울 코엑스에서 열리는 ‘2024 서울 카페쇼’에 참가해 전용 전시관을 운영한다고 7일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n서울 카페쇼 개막 첫 날인 6일 토스플레이스 전시관을 방문한 관람객은 1천3백여 명으로 집계됐다. 전시 주제는 '요즘 카페, 요즘 결제. 토스 단말기'다. 토스 단말기는 심미성을 고려한 콤팩트한 디자인과 직관적인 인터페이스를 적용하고 신용카드부터 삼성·애플페이, QR 간편결제까지 모든 결제 방식과 ‘키오스크 모드’ 등 다양한 부가서비스를 지원해 카페와 베이커리 업종에서 특히 수요가 높다.\n전시관은 자영업자가 토스 단말기를 활용해 매장 운영 효율을 높일 수 있는 솔루션을 체험하는 ‘체험존’과 단말기 설치 전문 상담을 받을 수 있는 ‘상담존’으로 구성됐다. 선보이는 솔루션은 ▲인건비 줄여주는 ‘키오스크 모드’ ▲모바일로 미리 주문하는 ‘픽업주문’ ▲첫 방문 고객도 단골로 만드는 ‘포인트’ 적립과 ‘스탬프’ 기능이 대표적이다.\n결제 체험을 하면 타포린백, 커피 드립백, 생수 등 굿즈를 제공하는 현장 이벤트도 운영한다. 이 이벤트는 토스플레이스 전시관을 방문하는 관람객 누구나 참여할 수 있다.\n토스플레이스 관계자는 “결제는 매장 매출과 직결되는 핵심적인 부분이자 고객의 이용 경험을 완성 시키는 중요한 단계\"라며 “편리한 결제 뿐 아니라 카페와 베이커리 업종에 맞는 다양한 솔루션도 지속 선보여 자영업자의 성공을 지원하겠다”고 말했다.\n한편 올해 23회째를 맞이한 서울 카페쇼는 글로벌 커피 비즈니스 플랫폼으로 거듭난 아시아 최대 규모 커피 박람회다. 이번 서울 카페쇼는 전 세계 36개국에서 681개 업체, 3천891개 브랜드가 참여해 역대 최대 규모로 조성됐다.",
        "content": "‘요즘 카페, 요즘 결제. 토스 단말기’로 코엑스에서 전시 선보여",
        "contentSnippet": "‘요즘 카페, 요즘 결제. 토스 단말기’로 코엑스에서 전시 선보여",
        "guid": "https://blog.toss.im/article/tossplace-cafeshow",
        "isoDate": "2024-11-06T23:00:00.000Z"
      },
      {
        "title": "토스, 광고 서비스 세미나 ‘토스애즈 파트너 데이 2024’ 성료",
        "link": "https://blog.toss.im/article/tossads-partnerday",
        "pubDate": "Wed, 06 Nov 2024 22:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}세 번째 광고 서비스 오프라인 세미나...광고주에 ‘토스애즈’ 소개\n토스 김형빈 광고사업총괄 연사로 나서 토스애즈의 강점 설명\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n모바일 금융 서비스 ‘토스’를 운영하는 비바리퍼블리카(이하 ‘토스’)가 광고 업계에 자사 광고 서비스 ‘토스애즈’를 소개하기 위한 ‘토스애즈 파트너 데이 2024 (Toss Ads Partner Day 2024)’를 성료 했다고 7일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n이번 행사는 토스가 광고 업계를 대상으로 연 세 번째 오프라인 대규모 행사다. 6일 서울 강남구 역삼동 조선팰리스에서 열린 행사에는 토스 김형빈 광고사업총괄을 비롯해 금융권, 통신사, 유통, 이커머스 등 다양한 광고 업계 종사자 200여 명이 참석했다.\n김형빈 광고사업총괄이 첫 번째 연사로 나서 ‘토스애즈의 2024년, 파트너와 그려나갈 비전’을 주제로 포문을 열었다. 토스애즈 강점인 오디언스, 데이터, 성과 측정에 대해 소개하고 토스애즈만의 우수한 데이터 솔루션을 기반으로 파트너십 전략을 설명했다.\n마케팅 인사이트 세션에는 케이뱅크 퍼포먼스&그로스 마케터 이동원 매니저와 LG 유플러스 디지털 그로스 김주연 PO가 패널로 나섰다. 이들은 업계 마케팅 동향 분석을 시작으로 토스애즈 성공사례와 잠재력 등을 공유했다.\n행사에 참석한 한 광고주 관계자는 “정교한 타겟팅을 지향하는 토스애즈에 대한 만족도가 평소에도 높았다”며 “다양한 업계의 광고주들이 한자리에 모여 러닝 쉐어 할 수 있는 장을 만들어준 토스에게 감사하다”고 말했다.\n토스 관계자는 “토스가 본격적으로 광고 사업을 전개한지 1년 만에 누적 광고주 수가 7배로 성장했다”며 “앞으로도 꾸준히 광고주와 함께 비즈니스 문제를 해결하며 성장하는 좋은 파트너가 될 수 있도록 노력할 것”이라고 밝혔다.\n한편 토스는 지난 4월 26일 광고 에이전시를 대상으로 첫 오프라인 행사 ‘토스애즈 인사이트 세미나(Toss Ads Insight Seminar for Agency)’를 열었다. 광고 업계 종사자 약 120여 명이 참석한 가운데 토스 이승건 대표가 ‘쿠키리스 시대의 디지털 마케팅’을 주제로 발표했다.",
        "content": "광고 사업 1년 만에 누적 광고주 수 7배 성장",
        "contentSnippet": "광고 사업 1년 만에 누적 광고주 수 7배 성장",
        "guid": "https://blog.toss.im/article/tossads-partnerday",
        "isoDate": "2024-11-06T22:00:00.000Z"
      },
      {
        "title": "토스, BNK경남은행과 업무협약…사회초년생 신용대출 상품 출시",
        "link": "https://blog.toss.im/article/tossbnk",
        "pubDate": "Wed, 06 Nov 2024 05:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}6일 토스 본사서 협약 체결…씬파일러를 위한 신용대출 상품 출시\n‘비대면 대출 신청 절차' 개선으로 별도 앱 설치 필요 없이 편리하게 이용 가능\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n모바일 금융 서비스 ‘토스’를 운영하는 비바리퍼블리카(이하 ‘토스’)가 BNK경남은행과 사회초년생 신용대출 상품 출시를 위한 업무협약을 체결했다고 6일 밝혔다.\n협약식은 6일 서울 강남구 역삼동 토스 본사에서 진행되었으며, 토스 이승건 대표와 BNK경남은행 예경탁 은행장 등 양사 주요 관계자들이 참석했다. 이번 협약으로 양사는 새로운 대출 상품 출시에 이어 다양한 영역에서 비즈니스 파트너로서 상호 협력할 계획이다.\n‘사회초년생을 위한 신용대출’ 상품을 위해 토스는 대안평가정보인 토스스코어를 제공하고, BNK경남 은행은 대출 재원을 마련한다. 또한, ‘비대면 대출 신청 절차’를 개선해 추가 앱 설치나 별도 회원가입 없이 바로 대출 신청을 할 수 있는 편의성을 제공한다.\n향후 토스와 BNK경남은행은 대출 대상자를 개인사업자와 전문직군 등으로 확대하고, 건전한 대출 모집 환경 조성을 위한 주택담보대출 모집인 비교 서비스도 출시할 계획이다.\n토스 이승건 대표는 “누구에게나 편리하고 평등한 금융을 만든다는 미션을 가진 토스와 상생 금융을 지향하는 BNK경남은행이 만나 협력한다는 점에서 의미가 깊다”며 “이번 협약으로 사회초년생뿐만 아니라 더 다양한 금융 소비자 계층을 위한 사업을 펼칠 수 있을 것으로 기대한다”고 말했다.\nBNK경남은행 예경탁 은행장은 “디지털금융을 강화하기 위해 국내 유일 글로벌 100대 유니콘 기업인 토스와 전략적 사업제휴 협약을 맺고 협력하게 됐다”며 “BNK경남은행과 토스가 갖고 있는 디지털 기술을 잘 활용한다면 고객들에게 편리한 금융 서비스를 손쉽게 제공할 것으로 기대한다”고 말했다.",
        "content": "11월 6일 토스가 BNK경남은행과 신용대출 상품 출시 업무협약을 체결했어요. ",
        "contentSnippet": "11월 6일 토스가 BNK경남은행과 신용대출 상품 출시 업무협약을 체결했어요.",
        "guid": "https://blog.toss.im/article/tossbnk",
        "isoDate": "2024-11-06T05:00:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]