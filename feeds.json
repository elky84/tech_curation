[
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Adapting the Facebook Reels RecSys AI Model Based on User Feedback",
        "link": "https://engineering.fb.com/2026/01/14/ml-applications/adapting-the-facebook-reels-recsys-ai-model-based-on-user-feedback/",
        "pubDate": "Wed, 14 Jan 2026 20:51:33 +0000",
        "content:encodedSnippet": "We’ve improved personalized video recommendations on Facebook Reels by moving beyond metrics such as likes and watch time and directly leveraging user feedback. \nOur new User True Interest Survey (UTIS) model, now helps surface more niche, high-quality content and boosts engagement, retention, and satisfaction.\nWe’re doubling down on personalization, tackling challenges like sparse user data and bias, and exploring advanced AI to make recommendations even smarter and more diverse.\nOur paper, “Improve the Personalization of Large-Scale Ranking Systems by Integrating User Survey Feedback” shares full details on this work. \nDelivering personalized video recommendations is a common challenge for user satisfaction and long-term engagement on large-scale social platforms. At Facebook Reels, we’ve been working to close this gap by focusing on “interest matching” – ensuring that the content people see truly aligns with their unique preferences. By combining large-scale user surveys with recent advances in machine learning, we are now able to better understand and model what people genuinely care about, which has led to significant improvements in both recommendation quality and overall user satisfaction.\nWhy True Interest Matters\nTraditional recommendation systems often rely on engagement signals – such as likes, shares, and watch time – or heuristics to infer user interests. However, these signals can be noisy and may not fully capture the nuances of what people actually care about or want to see. Models trained only on these signals tend to recommend content that has high short-term user value measured by watch time and engagement but doesn’t capture true interests that are important for long-term utility of the product. To bridge this gap, we needed a more direct way to measure user perception of content relevance. Our research shows that effective interest matching goes beyond simple topic alignment; it also encompasses factors like audio, production style, mood, and motivation. By accurately capturing these dimensions, we can deliver recommendations that feel more relevant and personalized, encouraging people to return to the app more frequently.\nRecommendation systems are typically optimized based on user interactions on the product, such as watch time, likes, shares, etc. However, by incorporating user perception feedback – like interest match and novelty – we can significantly improve relevance, quality, and the overall ecosystem.\n\nHow We Measured User Perception\nTo validate our approach, we launched large-scale, randomized surveys within the video feed, asking users, “How well does this video match your interests?” These surveys were deployed across Facebook Reels and other video surfaces, enabling us to collect thousands of in-context responses from users every day. The results revealed that previous interest heuristics only achieved a 48.3% precision in identifying true interests, highlighting the need for a more robust measurement framework. \nBy weighting responses to correct for sampling and nonresponse bias, we built a comprehensive dataset that accurately reflects real user preferences – moving beyond implicit engagement signals to leverage direct, real-time user feedback.\n\nFramework: User True Interest Survey (UTIS) Model\nDaily, a certain proportion of users viewing sessions on the platform are randomly chosen to display a single-question survey asking, “To what extent does this video match your interests?” on a 1-5 scale. The survey aims to gather real-time feedback from users about the content they have just viewed.\nThe main candidate ranking model used by the platform is a large multi-task, multi-label model. We trained a lightweight UTIS alignment model layer on the collected user survey responses using existing predictions of the main model as input features. The survey responses used to train our model were binarized for easy modelling and denoises variance in responses. In addition, new features were engineered to capture user behavior, content attributes, and interest signals with the object function to optimize predicting users’ interest-matching extent.\nThe UTIS model outputs the probability that a user is satisfied with a video, and is designed to be interpretable, allowing us to understand the factors contributing to users’ interest matching experience.\nUser perception feedback collected using surveys are extremely sparse but such feedback can be generalized in large scale recommendation systems using our novel model “Perception Layer” architecture that uses existing event predictions as additional features.\nIntegrating the UTIS Model in the Main Ranking System\nWe have experimented with and deployed several use cases of the UTIS model in our ranking funnel, all of which showed successful tier 0 user retention metric improvements:\nLate Stage Ranking (LSR): UTIS is deployed in parallel to the LSR model, providing an additional input feature into the final value formula. This allows fine-tuning of the final ranking stage to incorporate true interests while balancing other concerns.\nEarly Stage Ranking (Retrieval): UTIS is used to reconstruct users’ true interest profiles by aggregating survey data to predict affinity for any given user-video pair, allowing us to re-rank the user interest profile and source more candidates relevant to users’ true interests. Also, large sequences based on user-to-item retrieval models are aligned using knowledge distillation based objectives trained on UTIS predictions from LSR as labels. \nThe UTIS model score is now one of the inputs to our ranking system. Videos predicted to be of high interest receive a modest boost, while those with low predicted interest are demoted. This approach has led to: \nIncreased delivery of high-quality, niche content. \nA reduction in low-quality, generic popularity based recommendations.\nImprovements in like, share, and follow rates.\nImproved user engagement and retention metrics.\nSince launching this approach, we’ve observed robust offline and online performance\nOffline Performance: The UTIS model delivered an improvement in accuracy and reliability over the heuristic rule baseline. Accuracy increased from 59.5% to 71.5%, precision improved from 48.3% to 63.2%, and recall increased from 45.4% to 66.1%. These gains demonstrate the model’s ability to help in accurately identifying users’ interest preferences.\nOnline Performance: Large-scale A/B testing with over 10 million users confirmed these improvements in real-world settings. The UTIS model consistently outperformed the baseline, driving higher user engagement and retention. Notably, we saw a +5.4% increase in high survey ratings, a -6.84% reduction in low survey ratings, a +5.2% boost in total user engagement, and a -0.34% decrease in integrity violations. These results highlight the model’s effectiveness in improving user experience and matching users with relevant interests.\nFuture Work for Interest Recommendations\nBy integrating survey-based measurement with machine learning, we are creating a more engaging and personalized experience – delivering content on Facebook Reels that feels truly tailored to each user and encourages repeat visits. While survey-driven modeling has already improved our recommendations, there remain important opportunities for improvement, such as better serving users with sparse engagement histories, reducing bias in survey sampling and delivery, further personalizing recommendations for diverse user cohorts and improving the diversity of recommendations. To address these challenges and continue advancing relevance and quality, we are also exploring advanced modeling techniques, including large language models and more granular user representations.\nRead the Paper\nImprove the Personalization of Large-Scale Ranking Systems by Integrating User Survey Feedback\n    background-color: #0064E0;      /* Meta Blue */\n    color: #ffffff !important;      /* Force white text */\n    padding: 10px 20px;             /* Button size */\n    border: none;                   /* No border */\n    border-radius: 5px;             /* Rounded corners */\n    cursor: pointer;                /* Pointer cursor on hover */\n    text-decoration: none;          /* Remove underline */\n    display: inline-block;          /* Button-like display */\n    font-weight: bold;              /* Optional: bold text */\n    transition: color 0.3s ease, background-color 0.3s ease; /* Smooth transitions */\n  }\n  .meta-btn:hover {\n    color: #808080 !important;      /* Grey text on hover */\n  }\n\nThe post Adapting the Facebook Reels RecSys AI Model Based on User Feedback appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>We’ve improved personalized video recommendations on Facebook Reels by moving beyond metrics such as likes and watch time and directly leveraging user feedback.  Our new User True Interest Survey (UTIS) model, now helps surface more niche, high-quality content and boosts engagement, retention, and satisfaction. We’re doubling down on personalization, tackling challenges like sparse user data [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2026/01/14/ml-applications/adapting-the-facebook-reels-recsys-ai-model-based-on-user-feedback/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2026/01/14/ml-applications/adapting-the-facebook-reels-recsys-ai-model-based-on-user-feedback/\">Adapting the Facebook Reels RecSys AI Model Based on User Feedback</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "We’ve improved personalized video recommendations on Facebook Reels by moving beyond metrics such as likes and watch time and directly leveraging user feedback.  Our new User True Interest Survey (UTIS) model, now helps surface more niche, high-quality content and boosts engagement, retention, and satisfaction. We’re doubling down on personalization, tackling challenges like sparse user data [...]\nRead More...\nThe post Adapting the Facebook Reels RecSys AI Model Based on User Feedback appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=23389",
        "categories": [
          "ML Applications",
          "Video Engineering"
        ],
        "isoDate": "2026-01-14T20:51:33.000Z"
      },
      {
        "creator": "",
        "title": "CSS at Scale With StyleX",
        "link": "https://engineering.fb.com/2026/01/12/web/css-at-scale-with-stylex/",
        "pubDate": "Mon, 12 Jan 2026 18:34:59 +0000",
        "content:encodedSnippet": "Build a large enough website with a large enough codebase, and you’ll eventually find that CSS presents challenges at scale. It’s no different at Meta, which is why we open-sourced StyleX, a solution for CSS at scale. StyleX combines the ergonomics of CSS-in-JS with the performance of static CSS. It allows atomic styling of components while deduplicating definitions to reduce bundle size and exposes a simple API for developers.\nStyleX has become the standard at companies like Figma and Snowflake. Here at Meta, it’s the standard styling system across Facebook, Instagram, WhatsApp, Messenger, and Threads.\nOn this episode of the Meta Tech Podcast, meet Melissa, a software engineer at Meta and one of StyleX’s maintainers.  Pascal Hartig talks to her about all things StyleX—its origins, how open source has been a force multiplier for the project, and what it’s like interacting with large companies across the industry as they’ve adopted StyleX.\n\nDownload or listen to the episode below:\n\nYou can also find the episode wherever you get your podcasts, including:\nSpotify\nApple Podcasts\nPocket Casts\nThe Meta Tech Podcast is a podcast, brought to you by Meta, where we highlight the work Meta’s engineers are doing at every level – from low-level frameworks to end-user features.\nSend us feedback on Instagram, Threads, or X.\nAnd if you’re interested in learning more about career opportunities at Meta visit the Meta Careers page.\nThe post CSS at Scale With StyleX appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Build a large enough website with a large enough codebase, and you’ll eventually find that CSS presents challenges at scale. It’s no different at Meta, which is why we open-sourced StyleX, a solution for CSS at scale. StyleX combines the ergonomics of CSS-in-JS with the performance of static CSS. It allows atomic styling of components [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2026/01/12/web/css-at-scale-with-stylex/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2026/01/12/web/css-at-scale-with-stylex/\">CSS at Scale With StyleX</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Build a large enough website with a large enough codebase, and you’ll eventually find that CSS presents challenges at scale. It’s no different at Meta, which is why we open-sourced StyleX, a solution for CSS at scale. StyleX combines the ergonomics of CSS-in-JS with the performance of static CSS. It allows atomic styling of components [...]\nRead More...\nThe post CSS at Scale With StyleX appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=23515",
        "categories": [
          "Culture",
          "Open Source",
          "Web",
          "Meta Tech Podcast"
        ],
        "isoDate": "2026-01-12T18:34:59.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Aleksandra Krupskaya",
        "title": "TransformConf: a New Conference on AI in Software Development",
        "link": "https://blog.jetbrains.com/blog/2026/01/15/transformconf-a-new-conference-on-ai-in-software-development/",
        "pubDate": "Thu, 15 Jan 2026 12:43:46 +0000",
        "content:encodedSnippet": "TransformConf, a new event focused on how AI is transforming software development, is coming in 2026!\nSave the date: September 15–16, London, UK. Early bird tickets are already available!\nGet early bird tickets\n                                                    \nAI is revolutionizing software development – that much barely needs saying. AI is already a daily tool for 85% of developers, and 68% expect AI proficiency to become a non-negotiable part of job descriptions within the next few years (according to the State of Developer Ecosystem Report 2025).\nAt JetBrains, we leverage it every day. AI is changing how we write, review, and ship code. We build AI-powered products like AI Assistant and Junie, train models like Mellum, and create frameworks like Koog so others can build their own AI agents.\nWhile everyone’s talking about AI, the conversations vary wildly, from doomsday scenarios to starry-eyed optimism, and everything in between. TransformConf is our attempt to create space for practical discussions. We want you to bring home more than cool merch – we want you to leave with insights you can immediately apply to your work.\nSince 2017, we’ve organized KotlinConf, the biggest yearly Kotlin event and a true celebration of the community. We know how impactful offline events can be. Our hope is that TransformConf becomes the place to discuss AI in software development in a way that impacts both today and tomorrow, a community where you feel at home, and a source of development and inspiration.\nKey details\nThe first TransformConf will take place September 15–16, 2026, at Tobacco Dock in London, UK.\nWho is it for?\nAnyone who is building AI, using AI tools, integrating AI into their products, platforms, and workflows, or preparing to do so. Developers are always at the heart of everything we do, so expect an engineering focus, but we also want to see ML researchers and engineers, DevOps specialists, technical leaders, architects, developer experience and productivity engineers, and anyone on product teams working with AI in production.\nWhat to expect?\nTwo days in London, packed with educational talks, peer discussions, booth meetings, professional reflection, and some fun activities. We’re planning 45-minute and 15-minute talks across three parallel tracks. The program will cover these practical and forward-looking topics:\nBuilding, deploying, and maintaining AI systems end to end\nAligning AI development across disciplines\nAdvanced modeling and training techniques\nDeveloper education and techniques in an AI-driven landscape\nLong-term changes to programming, teams, and the software industry\nSeparating myths from reality, addressing ethics, compliance, and long-term impact\nRethinking developer productivity and human-AI collaboration\nHow do I stay in touch?\nIf TransformConf is something you’re interested in, subscribe to our newsletter for updates on speakers, the program, tickets, and more. \nWhat about speaking and partnership opportunities?\nThe call for speakers is open! Check out the details and apply here. If you’re interested in partnership opportunities, contact us here.\nGet early bird tickets\n                                                    \nSee you in September in London!\nThe JetBrains team",
        "dc:creator": "Aleksandra Krupskaya",
        "content": "TransformConf, a new event focused on how AI is transforming software development, is coming in 2026! Save the date: September 15–16, London, UK. Early bird tickets are already available! AI is revolutionizing software development – that much barely needs saying. AI is already a daily tool for 85% of developers, and 68% expect AI proficiency [&#8230;]",
        "contentSnippet": "TransformConf, a new event focused on how AI is transforming software development, is coming in 2026! Save the date: September 15–16, London, UK. Early bird tickets are already available! AI is revolutionizing software development – that much barely needs saying. AI is already a daily tool for 85% of developers, and 68% expect AI proficiency […]",
        "guid": "https://blog.jetbrains.com/?post_type=blog&p=673222",
        "categories": [
          "events",
          "transformconf"
        ],
        "isoDate": "2026-01-15T12:43:46.000Z"
      },
      {
        "creator": "Maciej Gorywoda",
        "title": "Scala 3.8 Support in the Scala Plugin",
        "link": "https://blog.jetbrains.com/scala/2026/01/15/scala-38-support-in-the-scala-plugin/",
        "pubDate": "Thu, 15 Jan 2026 12:08:14 +0000",
        "content:encodedSnippet": "Hello everyone,\nAs I write these words, the Scala compiler team is wrapping up the Scala 3.8 release. It’s the last major release before a feature freeze. The next one, 3.9, will be the new Long-Term Support version. The compiler team decided that most of the work between 3.8 and 3.9 will go into stabilization, while new features and other improvements will be released with Scala 3.8. By providing support for the new Scala 3.8 features now, we’re able to give you the opportunity to enjoy and test them immediately. This will give both our team and the compiler team the opportunity to collect more and better feedback from you.\n\n\n\n\nThe into modifier\nThere’s a new modifier in Scala syntax, into, that can be used in two ways: as a wrapper over a type or as a soft keyword in front of classes, traits, opaque type aliases, and enum types. By wrapping a type with into[T] – for example, a type of a function parameter – we indicate that any type implicitly convertible to the declared type inside the into wrapper is accepted without requiring the implicitConversions import. The Scala plugin understands this mechanism, correctly infers types, and highlights cases where the conversion isn’t possible. In the future, using an implicit conversion without the implicitConversions import will be treated as an error.\n\n\n\n\nNotice that into is used as a type wrapper for elems, but at the same time we can still use elems.iterator as if elems was of the underlying type IterableOnce[A].\nAlternatively, if the type is in your codebase, you can also add the into modifier to indicate that implicit conversions into that type should always be allowed.\n\n\n\n\nPlease note that the warning displayed in the video appears only if Compiler-Based Highlighting is enabled.\nYou can read more about the into modifier in the Scala 3 documentation.\n\n\n\n\nScala 3.8 requires JDK 17+\nIn the new Scala release, the minimum required JDK version has been updated to 17. The latest version of the Scala plugin supports this requirement in two ways:\nIn the New Project Wizard: If you select Scala 3.8+ or newer, but choose a JDK version older than 17, a warning popup that reads “JDK >= 17 is required with Scala 3.8” will appear.\n\n\n\n\n\n\n\n\n\n\nIn existing projects: If your Scala project or any of its modules requires Scala 3.8+ but is being compiled on a JDK version lower than 17, IntelliJ IDEA will display a special warning.\n\n\n\n\n\n“Better fors”\n“Better fors” might sound a bit awkward for a feature name, but it introduces a significant and long-anticipated syntax relaxation for Scala’s for-comprehensions. Previously, a for-comprehension had to start with a generator, such as number <- List(1, 2, 3). If you wanted to use an alias, like list = List(1, 2, 3), you had to place it after a generator or define it before the entire for-comprehension and save the result as a value. Now, Scala 3.8 and the Scala plugin support having just the alias before a generator and transforming it into a value automatically. \n\n\n\n\n\nBasic support for capture checking\nThe Scala standard library is now compiled and published using Scala 3. You can see it in the Project view of a Scala 3.8 project. Simply scroll down and unfold the following path: External Libraries | sbt:org.scala-lang.scala-library-3.8.0:jar | scala-lang.scala-library-3.8.0:jar. There, you can find and open standard library source files, for example IterableOnce.\n\n\n\n\n\n\n\n\nAs you can see in the screenshots, the code in the Scala 3.8 version of this class already uses one of the new features: capture checking. Currently, the Scala plugin only supports basic syntax for capture checking, and even this support is experimental. Our goal was to enable you to navigate the Scala standard library code without encountering error highlighting, view type information for captures, and jump to their declarations.\n\n\n\n\nThe runtimeChecked method\nThe runtimeChecked method is an extension method defined in scala.Predef that can be called on any expression. When an expression ends with .runtimeChecked, it is exempt from certain static checks in the compiler, such as pattern match exhaustivity. The Scala plugin supports this feature out of the box. For example, if you write a pattern match that misses some cases – as in the screenshot below that defines all days of the week, but then uses only five of them in a match case – the Scala plugin displays a warning that the pattern matching is not exhaustive. If you decorate the value used for pattern matching with .runtimeChecked, the warning will not be displayed.\n\n\n\n\n\nLooking ahead\nThe features highlighted in this article are where the Scala plugin’s support is most visible to users. However, there are numerous other changes we’ve made in preparation for the Scala 3.8 release. In the near future, we will continue to improve our Scala 3 support, including some of the new Scala 3.8 features. Expect more updates in the form of blog posts, release notes, and videos.\nThe features highlighted in this article are where the Scala plugin’s support is most visible to users. However, there are numerous other changes we’ve made in preparation for the Scala 3.8 release. In the near future, we will continue to improve our Scala 3 support, including some of the new Scala 3.8 features. Expect more updates in the form of blog posts, release notes, and videos.\n\n\n\n\n\nAs always, your feedback is invaluable. Please report any issues you encounter in YouTrack,, and feel free to share your questions, thoughts and suggestions on Discord.\nWe’re always happy to help.\nHappy developing!\nThe Scala team at JetBrains",
        "dc:creator": "Maciej Gorywoda",
        "content": "Hello everyone, As I write these words, the Scala compiler team is wrapping up the Scala 3.8 release. It&#8217;s the last major release before a feature freeze. The next one, 3.9, will be the new Long-Term Support version. The compiler team decided that most of the work between 3.8 and 3.9 will go into stabilization, [&#8230;]",
        "contentSnippet": "Hello everyone, As I write these words, the Scala compiler team is wrapping up the Scala 3.8 release. It’s the last major release before a feature freeze. The next one, 3.9, will be the new Long-Term Support version. The compiler team decided that most of the work between 3.8 and 3.9 will go into stabilization, […]",
        "guid": "https://blog.jetbrains.com/?post_type=scala&p=672397",
        "categories": [
          "news",
          "releases",
          "scala",
          "scala-programming",
          "intellij-idea"
        ],
        "isoDate": "2026-01-15T12:08:14.000Z"
      },
      {
        "creator": "Kerry Beetge",
        "title": "Introducing Global Project Configuration: One Place to Manage All Your Qodana Rules",
        "link": "https://blog.jetbrains.com/qodana/2026/01/introducing-global-project-configuration-one-place-to-manage-all-your-qodana-rules/",
        "pubDate": "Wed, 14 Jan 2026 09:06:12 +0000",
        "content:encodedSnippet": "Global Project Configuration is a new feature that helps Qodana users manage linter settings across an entire organization or team – all from one location. Until now, maintaining consistent code quality rules meant updating configuration profiles in every individual repository. \nWhether you were approving new licenses, adjusting rule severity, or defining custom patterns for hardcoded passwords, changes had to be repeated manually across multiple projects. However, as organizations scale, this approach becomes slow, error-prone, and difficult to audit.\nGlobal Project Configuration solves this. It provides a streamlined, reusable, organization-wide mechanism for defining and enforcing code quality standards – without limiting the flexibility individual projects may need.\nBook Demo\nWhy Global Project Configuration matters\nWith this new capability, you can:\nEstablish organization-wide standards once, and apply them everywhere.\nEnforce best practices without sacrificing project-specific adjustments.\nApply and update rules at scale, instantly affecting any linked projects.\nReduce duplication and manual overhead, especially for large repositories or distributed teams.\nImprove consistency across teams, languages, and tech stacks.\nThis makes Qodana easier to manage, more adaptable to real-world work, and much more scalable.\nHow it works\nGlobal Project Configuration is powered by a dedicated repository in which your organization stores the configuration files to be used during Qodana analysis. You can structure this repository in a way that suits your workflow, organizing configurations logically and referencing others to encourage reuse.\n\n\n\n\n\nConfiguring for teams: A practical example\nLet’s look at how different teams might take advantage of this feature.\nImagine your organization creates a global Base configuration containing universal coding standards shared across all teams. From there:\nTeam A, which uses Lombok in Java development, inherits from Base and adds stricter Lombok-related rules. They apply this configuration only to their own projects.\nTeam B, maintaining a legacy project, inherits from Base but disables most checks except for security rules. This allows them to focus on critical issues without being overwhelmed by unrelated warnings.\nEach team tailors the standards to their needs – while still aligning with the organization’s overall quality strategy.\nApplying configurations to projects\nOnce a project is linked to a configuration:\nQodana automatically applies it on the next run.\nAny changes pushed to the configuration repository are picked up and applied seamlessly.\nYou can view all configurations and their associated projects in the Qodana Cloud UI, making management transparent and intuitive.\nEverything is centralized, traceable, and easy to maintain.\nGet started with Qodana’s Global Project Configuration\n\nVisit Qodana Cloud → Settings → Global Configurations in the product, or view our documentation for a full guide on creating the configuration repository, syncing it with Qodana Cloud, and linking configurations to specific projects.\nView Setup",
        "dc:creator": "Kerry Beetge",
        "content": "Global Project Configuration is a new feature that helps Qodana users manage linter settings across an entire organization or team &#8211; all from one location. Until now, maintaining consistent code quality rules meant updating configuration profiles in every individual repository.&#160; Whether you were approving new licenses, adjusting rule severity, or defining custom patterns for hardcoded [&#8230;]",
        "contentSnippet": "Global Project Configuration is a new feature that helps Qodana users manage linter settings across an entire organization or team – all from one location. Until now, maintaining consistent code quality rules meant updating configuration profiles in every individual repository.  Whether you were approving new licenses, adjusting rule severity, or defining custom patterns for hardcoded […]",
        "guid": "https://blog.jetbrains.com/?post_type=qodana&p=674592",
        "isoDate": "2026-01-14T09:06:12.000Z"
      },
      {
        "creator": "Sofia Kulikova",
        "title": "Insights Into China’s Developer Landscape: Key Trends From the JetBrains Developer Ecosystem Survey 2025",
        "link": "https://blog.jetbrains.com/research/2026/01/insights-into-china-s-developer-landscape-key-trends/",
        "pubDate": "Tue, 13 Jan 2026 16:11:09 +0000",
        "content:encodedSnippet": "Every year, thousands of developers take part in the JetBrains Developer Ecosystem Survey, helping us map the evolving landscape of software development worldwide. Published in eight languages with data from 20 geographical regions, the survey includes China – a fast-evolving market that shares many global characteristics while retaining distinct traits of its own. \nFor example, Java remains the most widely used language in many Chinese industries – a pattern that differs from global trends and reflects the country’s vast mobile and enterprise sectors. At the same time, rising adoption of Go and TypeScript points to a growing focus on scalability, developer experience, and modern web architectures.\nThanks to the contributions of our survey participants, we’re able to offer a closer look at the Chinese developer ecosystem, including insights not featured in our published infographics. We hope these findings are valuable not only to developers working in China, but also to those less familiar with the market who may find it fascinating to compare local practices with global trends.\nSoftware development trends in China: It’s all in the details\nBroadly, the coding landscape in China looks similar to that of many other regions: STEM graduates with backgrounds in computer science, trained in widely adopted languages and tools, applying their skills in various industries. But to understand what truly shapes this market, it’s vital to look beneath the surface – and that’s where the differences emerge.\n 1.  The prevalence of Java for coding\nWhile Java remains a popular development language worldwide, it is far more common among Chinese developers than in most other regions.\n\n\n\n\nGlobally, an average of 27.76% of professional developers use Java as their primary development language, with Java, JavaScript, and Python forming a relatively balanced “big three”. In China, however, Java stands out clearly: it’s the first choice of 58.17% of Chinese developers.\n\n\n\n    \n“The dominance of Java in the Chinese market is fundamentally driven by the explosive growth of its internet industry and the resulting established technology stacks. China’s massive wave of e-commerce, fintech, and social media startups standardized on Java in their early stages. They built their core, high-throughput, distributed systems on proven Java frameworks like Spring and Apache Dubbo. This created a massive ecosystem and a self-reinforcing cycle: Companies use Java because the talent pool is large, and developers learn Java because that’s where the jobs are.\n\r\nThere’s also the Android factor. Before Kotlin became the preferred language, the massive adoption of Android smartphones in China cemented Java’s position for years as the primary language for mobile app development, further expanding its developer base.”\n\n            \nJoseph Du\n                                                                Customer Success Engineer\n                                    \n2. Widespread mini-app adoption vs. limited cloud service development in China\nIn Developer Ecosystem 2025, Chinese developers show a significantly higher tendency to develop mini-apps compared to the global developer community: 30.27% of professional developers in China are involved in mini-app development. The two most popular solutions are uni-app (35.06%) and Weixin native (34.21%), though 22.39% of developers report dissatisfaction with the current tooling ecosystem.\nMini-apps (小程序) are deeply integrated into daily life in China. A single mobile app can host a wide range of services, from messaging and taxi booking to food delivery and business registration. These lightweight applications run inside larger platforms and typically rely on platform-specific frameworks, such as WeChat Mini Programs and uni-app, combining JavaScript, custom markup languages, and CSS-like styles.\nThis year, the WebStorm team introduced a highly requested WeChat Mini Program plugin for working with Weixin native, with support from user research. This plugin adds native support for WXML, WXSS, and WXS syntax, allowing developers to work directly in WebStorm without switching between the WeChat IDE and their primary editor. It also reduces time spent checking component documentation. More details about the WeChat Mini Program plugin are available in this blog post.\n\n\n\n\n3.  Publicly traded companies outweigh privately owned ones\nOur third theme looks at where developers work and the types of organizations they are part of. The chart displays a diverse mix of company types, highlighting how the distribution in China differs from the global picture.\n\n\n\n\n\nPrivately owned companies: Chinese respondents are more likely to work for startups (24%) and large publicly traded companies (24%), compared to the global averages of 16% and 16%, respectively. The more striking difference, however, lies in ownership structure – only 22% of Chinese developers work for private companies, compared to 32% worldwide.\nMultinational corporations: Just 10% of developers in China are employed by multinationals, far below the global average of 19%.\nB2B vs. B2C: Business orientation also differs. In China, 39% of developers work in B2B and 28% in B2C, compared to 58% in B2B and 35% in B2C globally. This suggests a stronger consumer-facing focus in the Chinese market, where developers more often contribute to end-user products and services.\n\n\n\n\n4.  A perspective on low-code / no-code\nChinese developers show a stronger tendency to actively engage with low-code/no-code platforms compared to the global average.\n\n\n\n\nChinese developers are more likely to both build applications using these tools (17% vs. 10% globally) and to develop systems that support other users (14% vs. 4%). Business process automation (BPA) remains the top use case worldwide and in China.\nThe big gap appears in building websites and applications: 30% of Chinese respondents use low-code/no-code for building websites and applications, compared to just 17% globally.\n\n\n\n\nGlobally, low-code/no-code is still viewed primarily as a tool for business processes and rapid prototyping. In China, however, it has become part of a broader productivity-driven culture, with developers not only using these tools themselves but also enabling others to build and automate through them.\n5. Chinese LLM landscape: Foreign LLMs remain the top choice\nChinese developers show a distinct pattern in their use of AI tools. GitHub Copilot is significantly less popular in China than worldwide (26% vs. 38%), while Cursor has gained remarkable traction and is used by 23% of Chinese developers compared to 11% globally.\nGlobal leaders like ChatGPT and Claude are also far less represented in China. Instead, local alternatives, such as DeepSeek and TONGYI Lingma, play a major role, reflecting a strong preference for domestic or self-hosted solutions.\nNote: The list of LLMs in the survey was limited, with no open field. As a result, the findings reflect only the tools included in the questionnaire rather than the full market landscape.\n\n\n\n\nClosing thoughts\nThe insights in this post go beyond what you’ll find in our public infographics, which do not include comparison filters. We’re glad to share these deeper perspectives into the Chinese developer ecosystem, and we’re especially grateful to everyone who took part in our survey – your contributions make it possible for us to capture and understand these unique trends.\nIf you’d like to take part in future studies and help us learn more about how developers work around the world, we invite you to join the JetBrains Tech Insights Lab. \nTo stay updated on new findings, stories, and behind-the-scenes perspectives, subscribe to the JetBrains Research Blog.",
        "dc:creator": "Sofia Kulikova",
        "content": "Every year, thousands of developers take part in the JetBrains Developer Ecosystem Survey, helping us map the evolving landscape of software development worldwide. Published in eight languages with data from 20 geographical regions, the survey includes China –&#160;a fast-evolving market that shares many global characteristics while retaining distinct traits of its own.&#160; For example, Java [&#8230;]",
        "contentSnippet": "Every year, thousands of developers take part in the JetBrains Developer Ecosystem Survey, helping us map the evolving landscape of software development worldwide. Published in eight languages with data from 20 geographical regions, the survey includes China – a fast-evolving market that shares many global characteristics while retaining distinct traits of its own.  For example, Java […]",
        "guid": "https://blog.jetbrains.com/?post_type=research&p=672795",
        "categories": [
          "articles-2",
          "deveco",
          "industry-trends",
          "china",
          "jetbrains-research"
        ],
        "isoDate": "2026-01-13T16:11:09.000Z"
      },
      {
        "creator": "Elvira Mustafina",
        "title": "Compose Multiplatform 1.10.0: Unified @Preview, Navigation 3, and Stable Compose Hot Reload",
        "link": "https://blog.jetbrains.com/kotlin/2026/01/compose-multiplatform-1-10-0/",
        "pubDate": "Tue, 13 Jan 2026 14:48:34 +0000",
        "content:encodedSnippet": "Compose Multiplatform 1.10.0 has been released! We’re continually developing our multiplatform APIs and expanding support for Jetpack libraries commonly used on Android.\nHere are the highlights of this release:\nOne common @Preview annotation to rule them all\nNavigation 3 is available on non-Android targets\nStable and bundled Compose Hot Reload\n\n\n\n\nGet Started with Compose Multiplatform\nFor a complete overview of the changes, check out What’s new in Compose Multiplatform 1.10.0 or the release notes on GitHub.\nCommon @Preview annotation\nPreviously, we had three separate @Preview annotations across different packages, which made it challenging to figure out the correct combination of annotation, platform, and IDE.\nWith this release, we’ve unified previews under a single @Preview annotation that works in your commonMain source set:\n\n\n\n\nAll other annotations have been deprecated. But fear not – IDE quick-fix suggestions will help you easily update your dependencies to androidx.compose.ui.tooling.preview.Preview.\nNavigation 3\nWe’ve introduced support for Navigation 3, a new library for managing navigation. With Navigation 3, you can manipulate your navigation stack directly, making tasks like adding or removing destinations more straightforward.\nTo help you get started, we’ve compiled a set of Navigation 3 recipes with examples of common usage patterns for Compose Multiplatform.\n\n\n\n\nCompose Hot Reload\nCompose Hot Reload is designed to speed up UI iteration by letting you instantly see changes without restarting the application:\n\n                        \n\n\nThe Compose Hot Reload plugin is now stable – check out this deep-dive blog post to learn more about how it works. It’s now bundled with the Compose Multiplatform Gradle plugin and enabled by default, so no additional configuration is required.\nTry Compose Hot Reload\nThese are just the highlights – this release includes numerous updates across platforms, including the introduction of more transparent dependency management for Compose Multiplatform libraries with direct library references.\nMake sure to check out the full version in our documentation. If you encounter any issues, please report them on our issue tracker.",
        "dc:creator": "Elvira Mustafina",
        "content": "Compose Multiplatform 1.10.0 has been released! We’re continually developing our multiplatform APIs and expanding support for Jetpack libraries commonly used on Android. Here are the highlights of this release: Get Started with Compose Multiplatform For a complete overview of the changes, check out What’s new in Compose Multiplatform 1.10.0 or the release notes on GitHub. [&#8230;]",
        "contentSnippet": "Compose Multiplatform 1.10.0 has been released! We’re continually developing our multiplatform APIs and expanding support for Jetpack libraries commonly used on Android. Here are the highlights of this release: Get Started with Compose Multiplatform For a complete overview of the changes, check out What’s new in Compose Multiplatform 1.10.0 or the release notes on GitHub. […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=674389",
        "categories": [
          "multiplatform",
          "compose-hot-reload",
          "compose-multiplatform"
        ],
        "isoDate": "2026-01-13T14:48:34.000Z"
      },
      {
        "creator": "Sebastian Sellmair",
        "title": "The Journey to Compose Hot Reload 1.0.0",
        "link": "https://blog.jetbrains.com/kotlin/2026/01/the-journey-to-compose-hot-reload-1-0-0/",
        "pubDate": "Tue, 13 Jan 2026 14:47:58 +0000",
        "content:encodedSnippet": "Compose Hot Reload has just been promoted to stable with our 1.0.0 release. We worked hard to build a technology that is easy to use and well-integrated into existing tools while also requiring zero configuration from users. The tool is bundled with Compose Multiplatform, starting from version 1.10 (see our dedicated release blog post). While we’re happy to have built tooling that doesn’t really require users to think about its technical implementation, we’re also immensely proud of the engineering behind the project. This blog post highlights some of the technical aspects we find most interesting and provides a high-level overview of how Compose Hot Reload works under the hood.\n\n\n\n\nWhat we’ve built so far\nCompose Multiplatform is a declarative framework for sharing UIs across multiple platforms. Typically, if you’d like to launch a Compose application during development, you need to invoke the corresponding Gradle build tasks or otherwise launch it directly from within the IDE. This is also the case with Compose Hot Reload. Launching your application can be done by invoking the ./gradlew :myApp:hotRunJvm task or clicking Run with Compose Hot Reload in IntelliJ IDEA (assuming that the Kotlin Multiplatform plugin has already been installed).\nOnce the app launches in hot-reload mode, we see a floating toolbar right next to the application window. Changing code within IntelliJ IDEA and clicking Save (Cmd+S/Ctrl+S) will recompile the relevant code, perform a hot reload, and update the UI accordingly while preserving all parts of the state that are still considered valid.\nNote: Screen recordings were made using the latest Compose Hot Reload version, 1.1, which differs visually from the 1.0 release but is conceptually equivalent.\n\n\n\n\nBeyond simply changing the image resources, Compose Hot Reload lets you make almost arbitrary changes to your code, including but not limited to adding and removing functions, classes, and parameters – in short, all the kinds of changes you typically make during regular development.\nThe floating toolbar next to your application offers additional features, such as the ability to view logs, manually trigger a reload, and reset the UI state, as well as status indications and more. One of the most critical aspects of any hot-reload user experience, however, is communicating whether something went wrong. As the developer, you should always be acutely aware when reloading fails, causing your current code changes not to be reflected in the application. This could happen, for example, if you try to reload but the code cannot compile and requires your attention. In such cases, Compose Hot Reload will prominently display the error right in the target application’s window.\n\n\n\n\nLet’s decompose Compose Hot Reload\nLooking at the example above, let’s break Compose Hot Reload into its separate components and try to understand their individual purposes. In this section, we will recreate the process of building the core of Compose Hot Reload from the ground up, before proceeding to an explanation of the more technical details in the following sections.\nFirst things first, the main requirement for Compose Hot Reload is the ability to update the application while it is running dynamically. To achieve this, we need to answer two questions: How do we reload code that is already running dynamically, and when should we do it? Without first answering these questions, the technology will not work. \nThe how part can be achieved in multiple ways in the JVM world: using custom classloaders, JVM hot swapping, and via various other methods. But what really makes Compose Hot Reload work so well is the JetBrains Runtime and its DCEVM implementation, which we’ll cover in detail later.\nWith the how being taken care of by DCEVM, we need to decide on the when. In other words, we need a way to run the application with DCEVM, detect when the user makes changes, recompile the code, and trigger the reload. That’s right, we need an integration with the application’s build system – a plugin that will provide us access to applications’ build and launch configurations.\nIt would seem that these components should provide everything we need, right? We can integrate with the application’s build system and trigger code reloads when the user changes their code! Unfortunately, it’s not that simple. You see, dynamically changing the code will not re-render the application’s UI. Even worse, changes to the code can now lead to errors when interacting with the UI. For example, what will happen if a user interacts with a button that no longer exists in the code? Therefore, we also need a way to interact with the Compose framework and re-render the UI when necessary. Luckily, the Compose Runtime provides APIs to invalidate states and re-render UIs, so we just need to correctly invoke them after the code is reloaded.\nGood news: these three components are sufficient to provide the core functionality of Compose Hot Reload! But to truly elevate the user experience, we need to provide quick visual feedback on the current state of the hot reload. That’s why Compose Hot Reload also offers:\nIn-app notifications about the state of any hot reloads.\nA custom toolbar next to the application window, which allows us to track the status and control the state of a given hot reload.\nIntegration with an IDE that allows you to easily run the application with Compose Hot Reload and monitor its state.\nNow that you have the rough outline of Compose Hot Reload, let’s dive deeper into its technical implementation. There is a lot to discover!\nReloading code dynamically: DCEVM and the JetBrains Runtime \nAs previously mentioned, Compose Hot Reload relies heavily on the JetBrains Runtime to run the user code. Not only is the JetBrains Runtime specialized in building UI applications, it is also, to date, the only JVM to implement the DCEVM proposal published in 2011 by Thomas Würthinger, Christian Wimmer, and Lukas Stadler. This proposal enhances virtual machines’ ability to reload code. Where a regular JVM is limited to just reloading function bodies, DCEVM proposes “unrestricted and safe dynamic code evolution for Java”, which lifts the restrictions and supports almost arbitrary code changes. Here’s an example demonstrating how the JetBrains Runtime can perform more complex reloads:\n\n\n\n\nThe given program creates an instance of the class Foo and prints it every second in an endless loop.\nWhen reloading, the class was modified, and a second property y was added. This begs the question: How can the program and the current state be reloaded in this way? Once the developer edits the code and compiles it, Compose Hot Reload sends the updated .class files to the currently running application, requesting that it reload. The request will be handled over several subsequent steps. \nThe first step can be called “verification”: The JetBrains Runtime will check whether the new .class files are valid and can generally be reloaded. If the code passes all checks, it can proceed to the second stage, “loading”. Then, the JetBrains Runtime will load all classes into what we call a “side universe”. This will represent the application code (all loaded classes) after the reload.\n\n\n\n\nAt this point, the side universe can be thought of as a second instance of your application, containing all updated application code, but without any state or threads executing. The above example shows the changed Foo.class marked in green, indicating that it points to an updated version of the class.\nThe current state of the application is then required to migrate objects to this side universe: We call this a “state transfer”. This state transfer is implemented as a special garbage collection (GC) pass. GC has a few properties that are useful for implementing the state transfer. Not only is it possible to “stop the world” (wait for all application threads to reach safe points), but GC is also allowed to allocate new memory and move objects to new locations!\nTo demonstrate this for the previous example, we can look at the instance created by val foo = Foo(1). The actual instance might look something like this in your memory:\n\n\n\n\nThis is where the object currently resides at a known memory location. The memory representation of our object starts with a 16-byte header containing metadata about our object, for example, a pointer or a compressed pointer to our runtime representation of the class (called Klass). Right after the header, we can find the actual fields stored in the object. In our case, we see the value 1 associated with the property x. Memory before or after our object is unknown and could contain basically anything. When a reload changes a class’s layout by adding or removing properties, it becomes clear that the object needs to be adjusted.\nThis is where the nature of GC works well for migrating the object. GC can allocate a new block of memory to account for the object’s new size, and then start migrating the object by copying its previous values. In the chosen example, we added one more int field, requiring us to allocate 32 additional bits of memory. Since the x field was unchanged, we can just copy the previous value to its new location. However, a decision has to be made on how to treat the newly introduced field y. Re-running the constructor is not feasible, so DCEVM uses the JVM defaults: null, 0, and false.\n\n\n\n\nNote that the new object has a different header that points to the new Klass object, representing the reloaded code.\nOnce all objects are migrated, all pointers to them will be updated to point to the migrated objects. In our example above, the instance Foo has moved to a new memory location and now carries a y property. \nBefore we can resume the application, the runtime needs to consider that previous optimizations and just-in-time compilations to machine code might be invalid. For this reason, the code is then “de-optimized”. Once the application resumes, the JIT compiler is free to kick in again, optimizing our code and returning the application to the previous level of performance.\nJava agents FTW\nDCEVM is an amazing technology that allows you to dynamically reload and redefine code while it is executing. However, to make it actually work, we need a way to call its APIs from the user application. \nLuckily, the JVM has a way to implement that – it’s called a Java agent. A Java agent is a Java library that can be attached to any Java program and execute code before the target program starts.\nTo create a Java agent, we need to declare a class with a premain method. This method, as the name suggests, will be executed before the target application’s main, i.e. during JVM startup. The method takes a String argument and an instance of java.lang.instrument.Instrumentation as its parameters.\nfun premain(args: String, instrumentation: Instrumentation)\njava.lang.instrument.Instrumentation is a part of the Java Instrumentation API, which allows agents to observe, modify, and redefine classes at runtime. When you are using the JetBrains Runtime, java.lang.instrument.Instrumentation provides you with access to DCEVM via its redefineClasses method implementation.\nSo, in the case of Compose Hot Reload, the Java agent’s function is relatively straightforward: We attach it to the target application and launch a background task/thread in the premain. This background task will invoke instrumentation.redefineClasses with new classes whenever it receives information about changes to the application’s code. \nFinally, we just need to package our agent as a standalone JAR and give the agent information required by the JVM in the manifest file:\nPremain-Class: org.jetbrains.compose.reload.agent.ComposeHotReloadAgent\nCan-Redefine-Classes: true  // declare that we intend to redefine classes\nIn practice, we use the Compose Hot Reload agent for much more than just redefining classes via DCEVM. We will cover its other functions in the following sections.\nYou may have noticed that we boldly skipped one of the most important parts of any hot reload by simply claiming that the agent “receives information about changes in the code”. It is, indeed, not so simple. However, to get the whole picture, we first have to dive into another complex subsystem of Compose Hot Reload – its integration with build systems.\nBuilding a zero-configuration tool\nThe combination of the JetBrains Runtime’s ability to reload code and an agent that can listen for reload requests form the core functionality of Compose Hot Reload. Integrating these components into a zero-configuration product requires careful integration into build tools. The following describes how the Gradle plugin is implemented, but hot reload is also available in Amper. The user-facing workflows can be separated into two typical kinds of builds: In the first, the user compiles the application and intends to launch it in hot-reload mode. In the second kind of build, there will be multiple reloads. These consist of incrementally compiling the code, and then sending the reload request to the agent after a given change. Reload requests typically contain all .class files that have been either changed, added, or modified. While reloading can be triggered manually, it is typically managed either by Compose Hot Reload itself or by the IDE, which watches source files for changes. \nThis leads to two questions: \nHow can the set of changed files be resolved efficiently when reloading?\nHow can other tools reliably issue reloads?\n\n\n\n\nThe flow of launching the application already gives a lot of insights into how the overall system works, and it is relatively straightforward: \nThe entire project is compiled, as usual, and produces the corresponding .class files. Typically, applications can launch directly afterwards by launching the JVM with all necessary arguments (classpath, properties, JVM arguments, user arguments, etc.). A hot reload run will then perform two additional steps before actually launching.\nAfter the compilation finishes, a snapshot of the classpath is taken. It’s worth mentioning that Compose Hot Reload differentiates the classpath into a hot and cold part. Dependencies resolved from remote repositories are considered cold because they won’t change during a hot reload session. Code compiled by the current build, however, is considered hot. The snapshot is therefore only taken of the hot part of the classpath and contains all known .class files, each with a checksum of its contents.\nThe second task performed by hot reload is to produce special hot-reload arguments for the run. For convenience and to support restarting the application, these arguments will be stored in an .argfile. The most important arguments being:\n-XX:+AllowEnhancedClassRedefinition, which enables the JetBrains Runtime’s DCEVM capabilities.\n-javaagent:/.../hot-reload-agent-1.1.0.jar, which adds our agent to the application.\n-Dcompose.reload.buildSystem=Gradle, which tells Compose Hot Reload to use the Gradle recompiler backend.\n-Dgradle.build.root=/.../myProject, which tells Compose Hot Reload where the current Gradle project is located.\n-Dgradle.build.project=:app, which indicates which Gradle project was launched for hot reload.\n-Dgradle.build.task=hotReloadJvmMain, which tells Compose Hot Reload which Gradle task can be executed to issue a reload.\n-Dcompose.reload.devToolsClasspath=..., which provides the floating toolbar application classpath.\n-Dcompose.reload.devToolsEnabled=true, which enables the floating toolbar application.\nGiven that the application now has all the information necessary to start reloads by invoking the provided Gradle task at the provided location, Compose Hot Reload will start a supervisor process called devTools. This is the same process that will then provide the floating toolbar window. This process will either start a continuous Gradle build for reloading or wait for external events (such as you clicking Reload, or the IDE sending a signal to reload). \nSuch signals can be sent through the orchestration protocol, which we’ll talk about in more detail later. For now, it is just essential to know that the application will host a TCP server that allows components, such as Gradle, Amper, or the IDE, to communicate with each other.\nRequests to reload the application will trigger the corresponding reload task. Such a Gradle invocation will be marked as isHotReloadBuild and will get the application server port forwarded as orchestration.port.\nOnce the project is compiled incrementally, the snapshot will be rebuilt incrementally as well. Comparing the previous snapshot to the new one is quick and produces a map of .class files that are either added, removed, or modified. \nThe last task is to connect to the application using the provided port and send a request to reload those files. The agent will handle this request and reload the code using the JetBrains Runtime.\n\n\n\n\nSince all relevant tasks can be created automatically by inferring them from the Kotlin Gradle Plugin model, the tool can be used effectively without any further configuration. Launching from the CLI only requires calling the corresponding hotRunJvm task. IntelliJ IDEA can import hot reload tasks during the Gradle sync process and create corresponding run gutters.\nBut what about the UI?\nAs we mentioned before, being able to reload the code does not guarantee that Compose Hot Reload will magically start working. Modern applications are far too complex for that to happen. Therefore, after reloading the code, we need to propagate those updates throughout the application, re-rendering the UI, resetting the state, cleaning the references to the old code, etc. \nNow, to do that correctly, we first need to understand how Compose code actually works. Let’s take a look at how our App function from the previous examples is represented.\n@Composable\nfun App() {\n   var clicks by remember { mutableStateOf(0) }\n   MaterialTheme {\n       Column(\n           horizontalAlignment = Alignment.CenterHorizontally,\n       ) {\n           Button(onClick = { clicks++ }) {\n               Text(\"Clicks: $clicks\")\n           }\n\n\n           Icon(\n               imageResource(Res.drawable.Kodee_Assets_Digital_Kodee_greeting),\n               contentDescription = \"Kodee!!!\",\n               modifier = Modifier,\n               tint = Color.Unspecified\n           )\n       }\n   }\n}\nCompose splits the code into sections called groups and assigns each group a unique integer key. As an approximation, you can think that each scope (e.g. each {} pair in the code) corresponds to a separate group. The groups are organized in a tree-like structure that corresponds to their relations in the source code. In this image, green nodes correspond to Compose groups created by the App function, blue nodes represent other Composable functions called in the App function, and white nodes represent state information. \nWhen the Compose Runtime detects that some parts of the UI need to be re-rendered, it marks the groups corresponding to those components as invalid. It then re-executes all the code corresponding to those groups, creating an updated version of the tree. Subsequently, this means that the state created by any invalidated groups will be reset. For example, if we invalidate the group with the key -419397569, the mutable state with the counter will not be reset, while all the other code will be re-executed.\n\n\n\n\nNow that we have a high-level understanding of the Compose representation, how do we actually implement hot reload? Well, the intuitive option would be to reuse the Compose Runtime’s existing functionality: If the code changes, we invalidate all groups corresponding to that code. This will allow us to:\nRe-render only the necessary parts of the UI.\nPreserve the state whenever possible.\nClean up all references to the old code.\nTo do that, we need to understand:\nWhat code has been changed?\nWhich Compose groups need to be invalidated because of that change?\nAnd here, the Compose Hot Reload agent comes into play one more time.\nBytecode analysis\nWhen compiling the application, the Compose plugin changes the intermediate representation (IR) of the Composable functions and inserts additional instructions for the Compose Runtime. For example, the bytecode of the App function will start with the following instruction: $composer.startRestartGroup(1359525739).\nHere, startRestartGroup is a special instruction of the Compose Runtime that marks the start of a new group, and its argument is the key for this group. Correspondingly, the end of this group will be marked by a call to endRestartGroup. This means that all the information that we’re interested in is actually contained in the bytecode; we just need to extract it.\nLuckily, the Java agent allows us to hook into the target application and inspect all the classes while they are loading. We use the ASM library to analyze classes, and for each method, we build our own representation of the Compose tree. By locating the startGroup and endGroup calls, we can determine the bounds (and keys) of Compose groups, and their locations in the code define the parent-child relations between them. Conditional branches inside a function can be parsed by tracking jump instructions and their target labels.\n\n\n\n\nFor each Compose group, we determine its key, its relations with other groups, its dependencies on different methods, and its hash. The group’s hash value attempts to capture its semantics; for simplicity, we can think of it as a hash of all the bytecode instructions in this group. It allows us to quickly determine whether the group’s code has changed semantically during reloads.\nTracking changes\nNow that we know how to extract information from the bytecode, we need to think about how to apply it. As we mentioned, a Java agent allows us to analyze every class before it has been loaded. This will enable us to analyze classes not only during initial loading, but also during reloads. Thus, during reload, we can keep track of both the old and new versions of each class and monitor changes.\n\n\n\n\nWhen the class is reloaded, we can compare both its old and new runtime information and invalidate groups using the following rules.\nIf the code hash of a Compose group is changed, invalidate it.\nIf the code hash of a non-Compose function is changed, invalidate all Compose groups that are (transitively) dependent on it. Since we keep track of the entire runtime, we can efficiently compute all method dependencies.\nAfter that, the only thing left to do is to save the new version of the runtime as the current one.\nThe compiler doesn’t like your hot reload stuff\nEven though the core idea of the code invalidation and UI re-rendering approach is not particularly complicated, the path to Compose Hot Reload’s success was blocked by many obstacles and hurdles we had to overcome. Many of them stemmed from the fact that the Kotlin compiler and Compose plugin weren’t built with DCEVM and hot swapping in mind. Therefore, bytecode produced by those tools often behaved unexpectedly during hot reload. In this section, we will highlight some of the technical difficulties we encountered during the development of Compose Hot Reload and how we solved them.\nAll your lambdas belong to us\nBoth Kotlin and Compose encourage heavy use of lambda functions. However, lambda functions were a significant source of inconsistency in the bytecode produced by the Kotlin compiler, mainly due to their names. Users do not provide names for lambda functions; therefore, the compiler generates them itself, using predefined rules to determine each lambda’s name. Unfortunately, those rules are not designed with hot reload in mind.\nThere are two ways a lambda function can be compiled to the bytecode: anonymous classes and indy lambdas. The first way suggests that a lambda is compiled as a class that implements one of Kotlin’s FunctionN interfaces, and the lambda’s body is placed inside the invoke method of this class.\nThe indy way suggests that a lambda is compiled as a function inside the original class, which is then converted into an object in the runtime via the JVM’s invokedynamic instruction and the LambdaMetafactory.\nfun bar() =\n   foo { println(it) }\n\n\nfun foo(a: (Int) -> Unit) {\n   listOf(1, 2, 3).forEach(a)\n}\nClass-based lambda:\nfinal class org/example/project/MainKt$bar$1 extends kotlin/jvm/internal/Lambda implements kotlin/jvm/functions/Function1 {\n   // access flags 0x0\n   <init>()V\n           L0\n   ALOAD 0\n   ICONST_1\n   INVOKESPECIAL kotlin/jvm/internal/Lambda.<init> (I)V\n   RETURN\n\n\n   // access flags 0x11\n   public final invoke(I)V\n   GETSTATIC java/lang/System.out : Ljava/io/PrintStream;\n   ILOAD 1\n   INVOKEVIRTUAL java/io/PrintStream.println (I)V\n   RETURN\n}\nIndy lambda:\npublic final static bar()V\nINVOKEDYNAMIC invoke()Lkotlin/jvm/functions/Function1; [\n// handle kind 0x6 : INVOKESTATIC\njava/lang/invoke/LambdaMetafactory.metafactory(Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite;\n// arguments:\n(Ljava/lang/Object;)Ljava/lang/Object;,\n// handle kind 0x6 : INVOKESTATIC\norg/example/project/MainKt.bar$lambda$0(I)Lkotlin/Unit;,\n(Ljava/lang/Integer;)Lkotlin/Unit;\n]\nINVOKESTATIC org/example/project/MainKt.foo (Lkotlin/jvm/functions/Function1;)V\nRETURN\n\n\nprivate final static bar$lambda$0(I)Lkotlin/Unit;\nGETSTATIC java/lang/System.out : Ljava/io/PrintStream;\nILOAD 0\nINVOKEVIRTUAL java/io/PrintStream.println (I)V\nGETSTATIC kotlin/Unit.INSTANCE : Lkotlin/Unit;\nARETURN\nComposableSingleton classes\nCompose attempts to emit every composable lambda function as a singleton, meaning there is only one instance of that lambda function in existence. Therefore, it compiles all the composable lambdas as classes with a ComposableSingleton prefix in their names. Before Kotlin 2.1.20, the Compose compiler traversed nested functions using depth-first search and assigned each lambda class a unique name just using a counter. \nThe problem, however, arises when we introduce changes to the original code:\n\n\n\n\nAs you can see, just by adding a single new call to Surface, we caused two significant changes:\nEach lambda class changed, because adding a new lambda at the bottom of the tree caused all the lambda classes in the file to be renamed.\nThe class named ComposableSingleton$AppKt$lambda-0 changed its interface from Function3 to Function2, which causes an error in the JetBrains Runtime during reload, as before version 21.0.8, the JetBrains Runtime did not support changes to class interfaces.\nObviously, these kinds of dramatic bytecode changes are not good when hot reloading. Therefore, we changed how the Compose compiler generates names for composable singleton lambdas. Starting from version 2.1.20, the Compose compiler uses group keys as a stable, unique name for composable lambdas:\n\n\n\n\nThis change ensures that changes to composable lambdas do not cause errors or excessive invalidations in Compose Hot Reload.\nIndy lambdas\nWe encountered similar problems with the names generated for indy lambdas by the Kotlin compiler: Adding a nested lambda anywhere in the code renames all other lambdas.\n\n\n\n\nThis issue leads to the same problems as we observed with ComposableSingletons. However, this issue was reinforced by the fact that it affects all lambdas in the code, and Kotlin switched to indy lambdas by default in 2.0.0.\nTo solve this problem, we have changed the Kotlin compiler. As of Kotlin 2.2.20, indices for indy lambda names are unique for each scope they appear in. This guarantees that:\nRandom changes at the beginning of the file will not affect lambda names at the end of the file.\nAdding nested lambdas will not affect all the other lambdas declared in the class.\n\n\n\n\nFunctionKeyMeta annotations\nThe whole functionality of Compose Hot Reload relies on the fact that we can extract information about Compose from the bytecode. However, consider this example:\n@Composable\nfun App() {\n   Button(onClick = { }) {\n       Text(\"Click me!!!\")\n   }\n}\nThe lambda, passed to a Button call, only creates a single text field and does not create any new Compose groups. The (decompiled) bytecode of this lambda function looks like this:\nfinal class ComposableSingletons$AppKt$lambda$-794152384$1 implements Function3<RowScope, Composer, Integer, Unit> {\n\n\n   @FunctionKeyMeta(\n       key = -794152384,\n       startOffset = 568,\n       endOffset = 603\n   )\n   @Composable\n   public final void invoke(RowScope $this$Button, Composer $composer, int $changed) {\n       Intrinsics.checkNotNullParameter($this$Button, \"$this$Button\");\n       ComposerKt.sourceInformation($composer, \"C17@578L19:App.kt\");\n       if ($composer.shouldExecute(($changed & 17) != 16, $changed & 1)) {\n       if (ComposerKt.isTraceInProgress()) {\n           ComposerKt.traceEventStart(-794152384, $changed, -1, \"ComposableSingletons$AppKt.lambda$-794152384.<anonymous> (App.kt:17)\");\n       }\n\n\n       TextKt.Text--4IGK_g(\"Click me!!!\", (Modifier)null, 0L, 0L, (FontStyle)null, (FontWeight)null, (FontFamily)null, 0L, (TextDecoration)null, (TextAlign)null, 0L, 0, false, 0, 0, (Function1)null, (TextStyle)null, $composer, 6, 0, 131070);\n       if (ComposerKt.isTraceInProgress()) {\n           ComposerKt.traceEventEnd();\n       }\n   } else {\n       $composer.skipToGroupEnd();\n   }\n   }\n}\nAs you may notice, the source code of the invoke function does not contain any calls to startGroup or endGroup methods, and we can’t reliably extract the group information from it. The only way to access it is to read the FunctionKeyMeta annotation. This is a special annotation emitted by the Compose compiler that is intended to be used by tooling. \nHowever, before version 2.1.20, there was no way to generate FunctionKeyMeta annotations on composable functions, and there was no way to infer the group key from the bytecode of the compiled composable lambdas. We introduced this option in Kotlin 2.1.20 (which is why it is the required version of Kotlin if you want to use Compose Hot Reload) and enabled it by default in Kotlin 2.2.0.\nLifting the limits of the JetBrains Runtime\nWith the compiler tamed to emit bytecode that can be reloaded, another set of potential issues needs to be solved. One such issue surfaced very early in our testing. What should happen to the state that was statically initialized? The state in question here is not a UI state, stored by Compose, but static values, such as top-level properties. Take a look at the following test, which failed in early versions of Compose Hot Reload.\n\n\n\n\nThe test first defines an enum with the cases A, B, and C, then compiles and reloads the enum definition so that it also contains the case D. This failure is due to the EnumCases.entries being stored statically on the enum class. Once this collection is initialized, reloading this code will not magically cause its state to change to include the new case. Similarly, any other top-level property or static value would not change.\nThis is analogous to managing the state within the Compose framework, which means the same problems need to be solved. \nWe still need a way to reinitialize static values, and we need to know when to do so. This time around, we can answer the question of when to do so much more easily: Our bytecode analysis engine is perfectly capable of finding which functions and properties are considered dirty. However, reinitializing static fields is not as straightforward as calling a function. First, many static fields are also declared as final; re-assigning values cannot be done by calling a given function again, as it would require reflection. Second, the code that initializes statics lives inside a function called clinit. This function cannot be simply invoked, as it’s supposed to be invoked during class loading by the JVM itself. The problem requires transforming the code of .class files that will subsequently be reloaded. The transformation removes all final modifiers from static fields and copies the body of the clinit function to a new, synthetic $chr$clinit function (where chr is short for Compose Hot Reload). When reloading, the clinit method of several classes can be marked as dirty. We enqueue those classes for reinitialization and call them in topological order, according to their dependencies.\n\n\n\n\nWhen this project started, one of the stated limitations of the JetBrains Runtime was that reloads were rejected if either the superclass or any of a class’s interfaces changed while the class had active instances. Since some Kotlin lambdas still compile to abstract classes that implement Function1, Function2, and other interfaces, the limitation prevented some valid user code from reloading. We were able to produce lambda class names that were unique in Compose and much more tame outside of Compose, but users could occasionally encounter this limitation. We’re happy to announce that the team working on the JetBrains Runtime, especially Vladimir Dvorak, has lifted the restriction on changing interfaces and is now working on changing superclasses as well.\nThe orchestration protocol\nWe have previously seen that different processes need to communicate with each other. There are two concepts we can deduce from the required communication:\nEvents: Single-shot pieces of data (something that happened to which other parts of the system can react).\nStates: Current statuses of different Compose Hot Reload components that are continuously updated and available across the entire orchestration. For example, the ReloadState can either be Ok, Reloading, or Failed. This is not just a single event, but a universal state that each component can interact with. You can see that this ReloadState will be displayed in the application, the floating toolbar, and the IDE. \nTypically, such communication patterns can be modelled using higher-level abstractions, such as HTTP, and many would think that Ktor, or kotlinx.rpc might be fitting technologies. We, however, believe that technologies like Compose Hot Reload need to prioritize compatibility over our own developer experience. Using external libraries inside our devtools application is not a problem, but the communication with the user application requires code to run inside the user’s application, and polluting the user’s classpath might lead to frustrating compatibility issues. Shading such libraries can work, but most of those libraries would require kotlinx.coroutines. While kotlinx.coroutines can be shaded, it is designed to be a system-level library, and we would like to keep it this way.\nTherefore, we opted to implement all of the server/client code without any external dependencies. To model async code accurately, we even implemented a tiny coroutines runtime that allows launching tasks, switching threads, offering a Queue option (analogous to a Channel in kotlinx.coroutines), and more. \nThe key aspect of this protocol is that it is both forward- and backwards-compatible. This bi-directional compatibility is verified by running tests in a special way, but we’ll go into more detail on that later.\nDefining a state within a single process is hard enough to get right, but defining it across multiple processes raises the question of how to implement it safely. State updates in Compose Hot Reload are defined atomically and are done through an atomic update function. This means that racing threads, even racing processes, will be able to conveniently update a given state while using a pattern that is widely adopted by application developers:\n\n\n\n\nThe provided update function ensures atomic updates to the state. Like an AtomicReference or a MutableSharedFlow, this update function might be called multiple times if proposed updates are rejected. To enable such atomic updates across numerous processes, the OrchestrationServer acts as the source of truth: Any participant trying to update the state will send binary Update requests to the server. These requests will contain the binary (serialized) form of the expected state and the binary form of the updated state. \nThe server processes all requests in a single Queue. If the expected binary matches, the update gets accepted, and the updated state binary is distributed to all clients. If many threads or processes are racing to update a given state value, the expected binary representation might have changed so that it no longer matches the update request. Such updates will be rejected; the client will receive the new underlying state value, call the update function again, and send a new update request.\n\n\n\n\nFast visual feedback\nWe’ve now covered the internal workings of Compose Hot Reload. But as interesting as all that is, in our opinion, fast visual feedback is the most important part of the hot reload experience. So, how can we provide this feedback, and more importantly, share it across different processes? Well, the key to doing this is the states that are shared between all processes via the orchestration protocol. The hot-reload-devtooling-api module introduces them:\nWindowsState. By hooking into the user application process and intercepting all the ComposeWindow.setContent invocations, we can keep track of all the windows created by the user application. Each window is assigned a unique windowId, and we keep information about the current position of all windows.\npublic class WindowsState(\n   public val windows: Map<WindowId, WindowState>\n) : OrchestrationState {\n   public class WindowState(\n       public val x: Int,\n       public val y: Int,\n       public val width: Int,\n       public val height: Int,\n       public val isAlwaysOnTop: Boolean\n   )\n}\nReloadState. ReloadState keeps track of the current reload status. Basically, it tracks all orchestration messages and updates the state based on reload, recompile, or build status messages exchanged between the processes. \npublic sealed class ReloadState : OrchestrationState {\n   public abstract val time: Instant\n\n\n   public class Ok(\n       override val time: Instant,\n   ) : ReloadState()\n\n\n   public class Reloading(\n       override val time: Instant,\n       public val reloadRequestId: OrchestrationMessageId?\n   ) : ReloadState() {\n\n\n   public class Failed(\n       override val time: Instant,\n       public val reason: String,\n   ) : ReloadState()\n}\nReloadCountState. In addition to the reload state, it is also nice to keep track of the history of reload attempts. Working on the UI of your application and seeing that you have iterated on it over 30 times already is a very inspiring feeling!\npublic class ReloadCountState(\n   \t    public val successfulReloads: Int = 0,\n   \t    public val failedReloads: Int = 0\n) : OrchestrationState\nAs we mentioned before, all these states are shared between the processes. So if you feel like it, you can actually create your own UI tooling for Compose Hot Reload! \nIn-app effects\nThe Compose Hot Reload agent hooks to the user application process and intercepts Compose calls that initialize the window: ComposeWindow.setContent and ComposeDialog.setContent. To be more precise, we don’t just intercept these calls; we actually replace them with our own implementation that wraps the user content into a special DevelopmentEntryPoint function.\n@Composable\npublic fun DevelopmentEntryPoint(\n   window: Window,\n   child: @Composable () -> Unit\n) {\n   startWindowManager(window)\n   val currentHotReloadState by hotReloadState.collectAsState()\n\n\n   CompositionLocalProvider(hotReloadStateLocal provides currentHotReloadState) {\n       key(currentHotReloadState.key) {\n           when {\n               reloadEffectsEnabled -> ReloadEffects(child)\n               else -> child()\n           }\n       }\n   }\n}\nThis is a very high-level implementation of the DevelopmentEntryPoint. As you can see, it provides us with three key features:\nWe start a window manager that updates the WindowState of the current window.\nWe wrap the user app’s contents in a separate scope guarded by a special hot-reload state. If we ever want to reset the user application’s UI state, we can do so by resetting the hot-reload state.\nWe wrap the user content into the ReloadEffects function, which renders all in-app effects based on the shared states.\nFloating toolbar\nThe floating toolbar, or the Compose Hot Reload Dev tools window, is a separate process that starts together with the user application and connects to the orchestration. Then, it just tracks the WindowsState, and launches a new toolbar for each window of the user application. The toolbar just tracks the target window’s state and updates its position accordingly.\nThe toolbar also contains action buttons that control the user application: Reload UI, Reset UI, and Shutdown. These actions are implemented via the orchestration protocol as well: Clicking a button just triggers a corresponding orchestration message to be sent to all connected processes. Each process then knows how to handle received commands.\n\n\n\n\nIDE integration\nIDE support for Compose Hot Reload is implemented in the Kotlin Multiplatform plugin. When you open a Kotlin Multiplatform project in your IDE, the KMP plugin checks whether the Compose Hot Reload plugin is applied to the project. If it is, the KMP plugin also checks the versions for compatibility (IDEs support Compose Hot Reload versions from 1.0.0-beta07 onward). Via IDE integration with the build systems, the KMP plugin can extract all the information needed to run the app in hot-reload mode. And when you click on the Run button in the gutter next to main, the KMP plugin automatically generates a new run configuration with hot reload enabled.\n\n\n\n\nEverything else works very similarly to the Dev tools window. The KMP plugin connects to the orchestration server of the running application and displays information about the app’s current state: logs, reload status, errors, etc.\nTesting\nThis project required the team to think about many components across the entire Kotlin and JetBrains technology stack, and we have spent a lot of time debugging, experimenting, and writing production code. We would like to claim that most of our time was spent on our project infrastructure. However, we estimate that roughly 30% of all our commits were purely for introducing test infrastructure, highlighting how complicated testing a system that reloads code can be.\nHot-reload unit tests\nTests running assertions within the JVM that reload code are called hot-reload unit tests. An example of such a test case was shown earlier in this blog post.\n\n\n\n\nThe tests here can define code of interest right next to the actual test function. But the real magic happens when calling the compileAndReload method. \nThis method allows us to compile the provided source code within the current process and reload it. Once this compileAndReload method finishes, we can safely assume the new code is available and begin to write assertions. The example above shows a test that defines an enum with three cases. After reloading the enum with one case added, we can safely assert that the .entries property contains the newly added case. This test suite implements a custom test executor for Gradle, which launches each test case in a fresh JetBrains Runtime with hot reload enabled and provides a Kotlin compiler for the compileAndReload function. We used such tests in cases where reloading either crashed or had some issues, as mentioned previously (reinitializing statics).\nHotReloadTestFixture: Orchestration-based tests\nSince this project integrates into many other systems, having a heavier, end-to-end test fixture at our disposal seems natural. Similar to how Gradle plugins would write Gradle integration tests using Gradle-specific fixtures, we have implemented a HotReloadTestFixture that launches actual applications with Gradle in hot-reload mode and communicates with Gradle and the application using the previously mentioned orchestration protocol. Such tests were implemented to cover the integration with the JDWP commands for reloading and testing generic Gradle tasks, but they were also very useful for building screenshot tests:\n\n\n\n\nJust as unit tests do, orchestration-based tests have a convenient way to replace code, thanks to the HotReloadTestFixture; however, this test fixture actually changes source code on disk and thus relies on the entire Gradle/Compose Hot Reload machinery to pick the change up correctly, issue the reload request, and perform other relevant actions, right up until Compose actually updates the UI. After that, the test then takes a screenshot. We have many tests that ensure, through screenshots, that the code change was handled properly, i.e. that only the corresponding state was reset and the UI picked up the changes.\nTesting the backwards and forwards compatibility of the orchestration protocol\nAs we mentioned before, compatibility is one of the key properties of the orchestration protocol. For example, the IDE might have a different client version bundled compared to the server version hosted by the application. \nSuch compatibility tests typically define a communication flow between a server and a client. Let’s say the client connects, the server sends a message Foo, and the client responds with Bar. Now, to test the compatibility, this flow will be separated into two parts: \nThe first part is called main, which contains one side of the communication (e.g. the server’s) and runs with the currently compiled version of the code. The second part is called Isolate, and this code will be running in a separate process, launched with the previous JARs of the protocol.\n\n\n\n\nThe Isolate class can be defined right next to the test function, making it easy to write compatibility test cases where both ends of the communication are close together. Still, only one will be launched in isolation, running the test against many different, previously released versions of Compose Hot Reload.\nContinuing the journey\nCompose Hot Reload is a very complex technical project, and we are proud of the engineering work behind it. We tried to highlight what we consider the most interesting aspects of Compose Hot Reload in this blog post. But if you are interested in learning more about the project, check out our GitHub repository. And don’t hesitate to create new issues or discussions if you have any questions or ideas.\nCompose Hot Reload version 1.0.0 is bundled automatically with the latest Compose Multiplatform 1.10 release. But we are continuing to work on improving both the IDE experience and the underlying technology. So check out our latest releases and share your feedback!",
        "dc:creator": "Sebastian Sellmair",
        "content": "Compose Hot Reload has just been promoted to stable with our 1.0.0 release. We worked hard to build a technology that is easy to use and well-integrated into existing tools while also requiring zero configuration from users. The tool is bundled with Compose Multiplatform, starting from version 1.10 (see our dedicated release blog post). While [&#8230;]",
        "contentSnippet": "Compose Hot Reload has just been promoted to stable with our 1.0.0 release. We worked hard to build a technology that is easy to use and well-integrated into existing tools while also requiring zero configuration from users. The tool is bundled with Compose Multiplatform, starting from version 1.10 (see our dedicated release blog post). While […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=673207",
        "categories": [
          "multiplatform",
          "compose-hot-reload",
          "compose-multiplatform"
        ],
        "isoDate": "2026-01-13T14:47:58.000Z"
      },
      {
        "creator": "Oleg Zinovyev",
        "title": "What’s Next for CLion: The 2026.1 Roadmap",
        "link": "https://blog.jetbrains.com/clion/2026/01/2026-1-roadmap/",
        "pubDate": "Tue, 13 Jan 2026 09:21:09 +0000",
        "content:encodedSnippet": "We’re now working on our next major release, which we plan to deliver in March. In our latest stable version (v2025.3), we introduced many features and enhancements, so for the next release, we’ve decided to focus on maintenance and bug fixes rather than introducing new functionality. With that in mind, we’ve prioritized the following areas for v2026.1:\nLanguage support\nBuild tools and project formats\nFeatures for embedded development\nDebugging\n\n\n\n\nRead on to learn more about our planned updates.\nOur team is committed to creating an IDE that makes development smooth and productive. However, the following is only a preliminary roadmap. We can’t guarantee that all of the issues and features listed below will be addressed and implemented in CLion 2026.1. Unexpected circumstances could require us to modify our plans or implementation timelines for some items.\nLanguage support\nFor CLion’s language support, we plan to concentrate on improving the coding experience, refining compile-time debugging capabilities, and updating testing framework integration.\nLanguage and editor features\nThe CLion Nova language engine powers all of the recent performance and accuracy improvements in CLion. In v2025.3, this engine has become the default for all users, replacing the legacy CLion Classic engine.\nWhile we’re not aiming for complete feature parity between CLion Nova and CLion Classic, we remain committed to implementing the most popular features from the legacy engine. Here’s what we’re adding in this release:\nSupport for Clang blocks (CPP-37839): This non-standard extension provides a lambda-like syntax for creating closures in C and C++. It’s useful for writing concise, type-safe, and context-aware callbacks or asynchronous code.\nSupport for GCC nested functions (RSCPP-35876): This GCC extension lets you define a function inside another function, with the inner function accessible only within the outer function’s scope. This is particularly valuable in embedded systems, where it can help users optimize code and better manage limited resources.\nCode folding improvements: CLion automatically recognizes certain code structures and allows you to fold them. In v2026.1, we plan to support additional code structure types and regions that you can fold to help you better organize your code.\nGo to Usages and Go to Declaration popup improvements (CPP-45132, CPP-46560): We want to address several UX issues with this popup, such as displaying unnecessary information and unintuitive grouping of a function’s declaration and usages.\nConstexpr Debugger improvements\nIn v2025.3, we introduced the Constexpr Debugger, a tool that enables compile-time debugging of constexpr and consteval code, which is hard or impossible to debug at runtime. We’ll continue to refine the Constexpr Debugger and fix bugs in the next release.\nUpdates to unit testing frameworks\nCLion supports multiple unit test frameworks, such as GoogleTest, Catch2, Boost.Test, and doctest. In v2026.1, we plan to revise our support for these frameworks and update it where necessary – for example, by adding support for the latest framework features or removing obsolete ones.\nWe also plan to make unit test integration independent of the CMake project format. This will allow other project formats, like Meson (CPP-35147) or the JSON compilation database, to utilize the comprehensive test functionality that is currently available only for CMake projects.\nBuild tools and project formats\nHere, we’ll focus on enhancing Bazel support with new tools, optimizing the CLion update process, and expanding code insight capabilities for complex embedded projects.\nBazel support improvements\nLast year, we took over the development of the Bazel for CLion plugin from Google and have since continued to improve its stability and user experience. For the upcoming release, we plan to add support for several new Bazel features and tools, including:\nStarlark REPL: Bazel includes an official read-eval-print loop (REPL) for the Starlark language, allowing you to explore its semantics. We plan to bundle the REPL and offer a dedicated, interactive shell session directly within the IDE, facilitating easy experimentation with Starlark.\nExeclog parser: Bazel’s build execution logs, for example, generated by using \nthe --execution_log_compact_file flag, are a valuable resource for advanced build analysis and debugging performance issues. We’ll integrate the Bazel execution log parser, which will let you easily parse these logs and diff two log files simultaneously.\nConfiguration transitions: Transitions are a powerful Bazel feature that allows you to compile C and C++ projects for multiple architectures simultaneously. Currently, our plugin only supports the default configuration. If your project uses configuration transitions, the plugin ignores them, and it’s not possible to see code insight for different configurations. We plan to add full support for transitions so you can get accurate code insight for all configurations in your project.\nPerformance improvements: We continually work to enhance the plugin’s performance and will make related updates in v2026.1. One example is the header cache, which is used for headers generated during the build process or those from virtual include paths. This cache stores headers in a format optimized for CLion, improving overall performance.\n\n\n\n\nAdditionally, our plugin is already compatible with Bazel 9.\nFor more details on recent Bazel updates and announcements, check out our BazelCon 2025 recap.\nAccelerating CLion updates on Windows\nSome Windows users have reported that CLion updates take too long. To address this, we plan to remove unnecessary components and optimize packaging in the installer. This will reduce the installer size and speed up the updates for Windows and other supported operating systems.\nConfiguration profiles for West projects\nWe plan to add the ability to create configuration profiles for West projects, similar to CMake profiles (CPP-42799). This will streamline working with multiple build configurations that use different build parameters or target different boards, making it easy to switch between configurations on the fly.\nCode insight features for external projects\nProjects in popular embedded frameworks, such as West, STM32, and ESP-IDF, are often divided into multiple parts. Some of these parts may be external projects with respect to the primary project. These external projects are listed in the CMake ExternalProject_Add() section. For example, in a dual-core setup, one application acts as the primary application (a primary project), while the other one runs on the coprocessor and is responsible only for communication (an external project). Similarly, when using Arm® TrustZone® technology or a bootloader, one application may have elevated privileges, while the other retains regular privileges. An external project may also contain system dependencies used only for building.\nThese external projects would benefit from having the same code insight features as the primary project, such as error detection, warnings, search for usages, and refactoring. Currently, this is only possible if you load an external project as a separate project model, which can be unnecessary or cumbersome in many cases.\nWe want to generate a compile_commands.json file from an external project’s CMake configuration. This will enable you to load the external project as part of the primary CMake project and access code insight features, making it more convenient to work with complex, multi-part projects.\nUnbundling Cygwin\nWe plan to remove the pre-defined Cygwin setup from our list of default CLion toolchains and release it as a separate plugin. This plugin will be available to download from JetBrains Marketplace. There are two main reasons behind this decision:\nThe very low number of users.\nThe uncertainty of the Cygwin project’s future, especially since WSL can replace Cygwin in most cases.\n\n\n\n\nIf you use Cygwin in CLion and have concerns about this change, please comment below or contact our Support team. We’ll do our best to help you find a suitable solution.\nEmbedded development\nMost improvements in embedded development support will be related to live watches and debug servers.\nUpdates to live watches\nIn the latest release, live watches received several UX improvements, including the ability to export data in CSV format and view peripheral register values. For the upcoming release, we’ll continue refining the feature and fixing reported issues. To learn more about live watches, see our documentation.\nOpenOCD debug server\nWe’ve developed dedicated debug servers for different projects, such as STM32CubeMX and ESP-IDF, but not yet for OpenOCD. Although OpenOCD users can still use a generic debug server, this isn’t optimal. In the next release, we plan to add a dedicated debug server for OpenOCD, making it even more convenient to create and manage debug configurations for different targets.\nDebugger\nIn the last release, we introduced support for the Debug Adapter Protocol (DAP). This feature allows you to work with third-party debuggers that use DAP, expanding your options beyond LLDB and GDB.\nImproving the DAP integration will be our main priority in the debugger updates. We plan to address reported issues and add the ability to communicate with DAP servers via a TCP port (CPP-46675).\nConclusion\nThe Early Access Program is just around the corner and will give you the chance to try all of the new features planned for the next major release for free. In the meantime, upgrade to CLion 2025.3 if you haven’t already done so, and let us know what you think!\nDOWNLOAD CLION 2025.3",
        "dc:creator": "Oleg Zinovyev",
        "content": "We’re now working on our next major release, which we plan to deliver in March. In our latest stable version (v2025.3), we introduced many features and enhancements, so for the next release, we’ve decided to focus on maintenance and bug fixes rather than introducing new functionality. With that in mind, we’ve prioritized the following areas [&#8230;]",
        "contentSnippet": "We’re now working on our next major release, which we plan to deliver in March. In our latest stable version (v2025.3), we introduced many features and enhancements, so for the next release, we’ve decided to focus on maintenance and bug fixes rather than introducing new functionality. With that in mind, we’ve prioritized the following areas […]",
        "guid": "https://blog.jetbrains.com/?post_type=clion&p=670428",
        "categories": [
          "news",
          "roadmap",
          "bazel",
          "clionnova",
          "constexpr",
          "dap",
          "gcc",
          "live-watches"
        ],
        "isoDate": "2026-01-13T09:21:09.000Z"
      },
      {
        "creator": "Bruno Lannoo",
        "title": "Building AI Agents in Kotlin – Part 4: Delegation and Sub-Agents",
        "link": "https://blog.jetbrains.com/ai/2026/01/building-ai-agents-in-kotlin-part-4-delegation-and-sub-agents/",
        "pubDate": "Tue, 13 Jan 2026 08:27:09 +0000",
        "content:encodedSnippet": "Previously in this series:\nBuilding AI Agents in Kotlin – Part 1: A Minimal Coding Agent\nBuilding AI Agents in Kotlin – Part 2: A Deeper Dive Into Tools\nBuilding AI Agents in Kotlin – Part 3: Under Observation\nIn the previous installment, we saw how to set up tracing, which brings us to two new questions: What should we experiment with based on the information this tool provides? And what parts of our agent could we improve using its observations?\nThe first idea we had was to experiment with sub-agents, or more specifically, a find sub-agent. This will give us a chance to have a look at how Koog makes it easier to implement common patterns like sub-agents. Our hypothesis is that a find sub-agent might reduce overall cost while maintaining, or even improving, performance.\nWhy would we think that? Well, the main driver of cost is context growth. Each LLM request contains the full context from start to finish, which means each subsequent request is more expensive (at least in terms of input tokens) than the previous one. If we could limit context growth, especially early in the agent’s run, we might significantly reduce cost. An unnecessarily large context could also distract the agent from its core task. Therefore, by narrowing the context, we might even see a performance improvement, though that’s harder to predict.\nThe find functionality is particularly suited for removal from the long-term context. When searching for something, you typically open many files that don’t contain your target. Remembering those dead ends isn’t useful. Remembering what you actually found is. You could think of this as a natural way of compressing the agent’s history (we’ll look at actual compression in a later article).\nThis task is also a good candidate for a sub-agent because it’s relatively simple. That simplicity means we could also make use of the sub-agent’s ability to use a different LLM model. In this case, a faster and cheaper one. This offers flexibility that regular compression doesn’t.\nOf course, we could have built a traditional procedural tool to do this. In fact, we did build one called RegexSearchTool, but for the purposes of this experiment, we put it inside the find agent rather than directly in the main agent. This approach provides us with flexibility in terms of model choice while also incorporating an extra layer of intelligence.\nThe find agent\nTo be able to have a sub-agent pattern, we first need a second agent. We’ve already covered agent creation in depth in Part 1 of the series, so we won’t spend much time on this now. However, a few details are still worth noting.\nFirst, a minor point: We’re using GPT4.1 Mini for this sub-agent because its task is much simpler and doesn’t require a model as capable as the one used by the main agent.\nSecond, it’s useful to look at which tools this agent can access. Like the main agent, it has access to the ListDirectoryTool and ReadFileTool, but not the EditFileTool or ExecuteShellCommandTool. We’ve also given it access to the new procedural search tool we mentioned above, RegexSearchTool, which allows us to search a comprehensive range of files inside a folder and its subfolders using a regex pattern.\nToolRegistry {\n    tool(ListDirectoryTool(JVMFileSystemProvider.ReadOnly))\n    tool(ReadFileTool(JVMFileSystemProvider.ReadOnly))\n    tool(RegexSearchTool(JVMFileSystemProvider.ReadOnly))\n}\nFor more detailed information, check out the full implementation here.\nBuilding a find sub-agent\n\n\n\n\nFirst things first – what is a sub-agent? A sub-agent is really quite simple; it is an agent that is being controlled by another agent. In this specific case, we are working with the agent-as-a-tool sub-agent pattern, where the sub-agent is running inside a tool that is provided to the main agent.\nCreating a sub-agent turns out to be straightforward. We know a tool is essentially a function paired with descriptors that the agent can read to understand when and how to call it. We could simply define a tool whose .execute() function calls our sub-agent. But Koog provides tools to remove even this boilerplate:\nfun createFindAgentTool(): Tool<*, *> {\n    return AIAgentService\n        .fromAgent(findAgent as GraphAIAgent<String, String>)\n        .createAgentTool<String, String>(\n            agentName = \"__find_in_codebase_agent__\",\n            agentDescription = \"\"\"\n                <when to call your agent>\n            \"\"\".trimIndent(),\n            inputDescription = \"\"\"\n                <how to call your agent>\n            \"\"\".trimIndent()\n        )\n}\nYou could think of this as roughly equivalent to:\npublic class FindAgentTool(): Tool<FindAgentTool.Args, FindAgentTool.Result>() {\n   override val name: String = \"__find_in_codebase_agent__\"\n   override val description: String = \"\"\"\n      <when to call your agent>\n   \"\"\"\n   @Serializable\n   public data class Args(\n      @property: LLMDescription(\n         \"\"\"\n            <how to call your agent>\n         \"\"\"\n      )\n      val input: String\n   )\n   @Serializable\n   public data class Result(\n\tval output: String\n   )\n   override suspend fun execute(args: Args): Result = when {\n      output = findAgent.run(args.input)\n      Result(output)\n   }\n}\nIn either case, the only things we need to do are: \nCreate our sub-agent.\nGive it an agentName.\nSpecify when to call the agent through the agentDescription prompt.\nSpecify how to call the agent through the inputDescription prompt.\nThe prompts are, perhaps, the trickiest part. There’s plenty of room for fine-tuning. But there’s some indication that newer LLMs need less precisely tuned prompts, so perfectly fine-tuned prompts may not be worth our time. We’re still exploring this topic ourselves, and it will take more experimentation to really come to a strong conclusion.\nOne thing we did notice is that, if we’re not careful with the prompts, the main agent sometimes confuses the find agent with a simple Ctrl+F / ⌘F function, sending only the tokens it wants to search for. That’s clearly suboptimal. With so little context, the find agent can’t reason about what it should actually be looking for. To address this, we include instructions requiring the main agent to specify why it’s looking for something. That way, the find agent can fully leverage its intelligence to find the actual thing the main agent is looking for.\n\"\"\"\nThis tool is powered by an intelligent micro agent that analyzes and understands code context to find specific elements in your codebase.\nUnlike simple text search (Ctrl+F / ⌘F), it intelligently interprets your query to locate classes, functions, variables, or files that best match your intent.\nIt requires a detailed query describing what to search for, why you need this information, and an absolute path defining the search scope.\n...\n\"\"\"\n\nQuery WITH highlighting (not Ctrl+F /⌘F)Query WITHOUT highlighting (not Ctrl+F /⌘F)\n\nSearch for changes in get_search_results regarding unnecessary joins to see if there are comment or logic on unnecessary joins.get_search_results\nSearch for environment variable usage with SKLEARN_ALLOW or similar in repository to find potential bypass of check_build.SKLEARN_ALLOW\n\n\n\n\n\nWe also noticed that the main agent sometimes still chooses to call the shell tool with a grep command instead of the find agent, which undermines the entire purpose of having a dedicated sub-agent. To avoid this pattern, we added this section to the main system prompt in order to push it harder:\n\"\"\"\n...\nYou also have an intelligent find micro agent at your disposal,\nwhich can help you find code components and other constructs more\ncheaply than you can yourself. Lean on it for any and all\nsearch operations. Do not use shell execution for find tasks.\n...\n\"\"\"\nWe also took some lessons from years of IDE development. When you search in your IDE, you don’t just get file paths and line numbers. You get snippets of the code around each match. This helps you quickly determine whether that’s actually what you were looking for without opening every file.\nWe wanted to create a similar experience for the main agent, which is why we prompt the find sub-agent to include snippets in its results:\n\"\"\"\n...\nPrioritize accuracy and relevance in your search results.\n* For each result, provide a clear and concise explanation of why it was selected.\n* The explanation should state the specific criteria that led to its selection.\n* If the match is partial or inferred, clearly state the limitations and potential inaccuracies.\n* Include only relevant snippets in the results.\n...\nThis way, the main agent gets the same rich context we get as engineers, without needing to read through entire files just to verify it found the right thing.\nThis is the “natural compression” we mentioned in the opening. The find agent opens many files, follows dead ends, and explores the codebase. But the main agent only sees the results: relevant file paths, snippets, and explanations. All that exploration stays in the find agent’s context and disappears after it returns. Only the stuff that really mattered is then added to the main agent’s context.\nThe trade-offs\nUsing a sub-agent has its benefits, but it also has downsides. This is certainly the kind of change that warrants experimentation to show whether it delivers the benefits we’re hoping for without too many sacrifices.\nThe first trade-off is cost and time. While shortening the context in the main thread helps bring down the cost and time there, we now also have to pay and wait for a number of LLM calls in the sub-agent. The hope is that the total cost and time spent are less, but that depends on how the main agent uses the sub-agent. If it ends up doing a large number of small queries, that benefit might not materialize. We will look at the costs when we run the benchmarks again in a later section, and we will just assume that cost and time are correlated.\nWe did notice this happening in some of our runs, so we added a segment to the tool’s agentDescription that explains the issue to the main agent and tries to limit the frequency of such high volumes of small queries:\n\"\"\"\n...\nWhile this agent is much more cost efficient at executing searches than using shell commands, it does lose context in between searches. So give preference to clustering similar searches in one call rather than doing multiple calls to this tool.\n...\n\"\"\"\n\n\n\n\nA second trade-off is that this approach treats context retention in a far more black-and-white way than humans do. We may not pull everything that happened in the past into active memory, but we do keep vague impressions of what happened and can retrieve additional context when needed. There are ways to model this kind of behavior, but they are far beyond the scope of the current iteration of our agent and are more related to the deep and complex subject of agentic memory.\nAnother challenge is that it creates more complexity in tracing. In Langfuse, we no longer only have to look at the trace of just one agent. Indeed, we might even need to look at the behavior from multiple perspectives – both the full view and each agent separately.\nThink wider: The engineering team analogy\nThis technique of using sub-agents isn’t limited to simple cases like the find agent. You could, for example, replicate the separation of concerns in team structures by assigning analysis, implementation, testing, and planning to different sub-agents. \nIt’s still an open question whether an agent with all these capabilities does better or worse than a system where such capabilities are divided among sub-agents, but it’s not hard to imagine potential benefits. Think of Conway’s law: “Organizations design systems that mirror their communication structure.” One interpretation is that these communication structures evolved to discover efficient patterns worth keeping. The reverse Conway maneuver even suggests this is desirable.\nCould the same be true for role distribution? Maybe the division of tasks across different specializations in software teams also evolved to discover efficient ways of working. Maybe LLMs could benefit from that, too.\nYet this is not guaranteed. The efficiencies might stem largely from spreading the human learning processes, and this might not apply to LLMs. But in the book Clean Code, we read about wearing different hats: a writer hat (creator), a reader hat (maintainer), and a tester hat (tester). The idea is to focus on one role without being distracted by the perspectives of the others. This suggests task division goes deeper than just learning efficiency, meaning it might indeed be relevant to LLMs.\n\n\n\n\nAll of this is to say that you can take sub-agents a lot further, but whether this is a beneficial approach is still unproven. It’s still an art form for now, not a hard science.\nBenchmark results: Testing the hypothesis\nWe’re happy to report that our version without the find sub-agent shows a cost of about $814, or $1.63 per instance, while our version with this sub-agent shows a cost of about $733, or $1.47 per instance. That’s a 10% cost saving, which is definitely worth noting.\nOne interesting observation is how strongly the results depend on the choice of LLM for the sub-agent. In a smaller experiment, we tried keeping our sub-agent connected to GPT-5 Codex, and that dramatically increased the cost to $3.30 per example, averaged over 50 examples.\n\nExperimentSuccess rateCost per instance\nPart 03 (Langfuse)56% (278/500)$1.63 ($814/500)\nPart 04 (sub-agent GPT4.1 mini)58% (290/500)$1.47 ($733/500) \nPart 04 (sub-agent GPT-5 Codex)58% (29/50)$3.30 ($165/50)\n\n\n\n\n\nHowever, it is interesting to note that we hypothesized two ways to reduce cost. The first was shrinking the context size through the natural compression achieved by task handoffs, and the second was offloading work to a cheaper model. The data suggests that just splitting off a sub-agent (and keeping the GPT-5 Codex model) actually increases the cost significantly, so our first method doesn’t seem to work, while our second (cheaper models) is the one that seems to do the trick – though this may not be rigorous proof.\nAs for performance improvements, we see a small uptick from 56% to 58%. This could be within the tolerance of statistical variance, but it’s encouraging that performance at least stayed consistent while we reduced costs.\nConclusion\nWe’ve seen that creating sub-agents is both simple and potentially powerful. Koog provides convenient tooling to streamline the process even further, leaving only the prompts for the agent-as-a-tool for you to define.\nThis technique clearly delivers worthwhile cost savings. We achieved nearly a 10% reduction – a clear, measurable improvement. The performance impact is less clear, but it does look like it might be some gains there, too.\nAt the same time, these kinds of evaluations are expensive. Even with reduced costs, this benchmark still totaled $730. That’s why, in the next part, we will take a closer look at another strategy for lowering costs: a more general approach to compression. In it, we’ll answer the question, “How do you prevent your context from growing indefinitely, and your costs growing with it?”",
        "dc:creator": "Bruno Lannoo",
        "content": "Previously in this series: In the previous installment, we saw how to set up tracing, which brings us to two new questions: What should we experiment with based on the information this tool provides? And what parts of our agent could we improve using its observations? The first idea we had was to experiment with [&#8230;]",
        "contentSnippet": "Previously in this series: In the previous installment, we saw how to set up tracing, which brings us to two new questions: What should we experiment with based on the information this tool provides? And what parts of our agent could we improve using its observations? The first idea we had was to experiment with […]",
        "guid": "https://blog.jetbrains.com/?post_type=ai&p=672689",
        "categories": [
          "kotlin",
          "tutorials",
          "ai",
          "ai-agents"
        ],
        "isoDate": "2026-01-13T08:27:09.000Z"
      },
      {
        "creator": "Ksenia Shneyveys",
        "title": "Advent of Code 2025 in Kotlin: Puzzles, Prizes, and Community",
        "link": "https://blog.jetbrains.com/kotlin/2026/01/advent-of-code-2025-in-kotlin/",
        "pubDate": "Mon, 12 Jan 2026 19:33:14 +0000",
        "content:encodedSnippet": "Thank you to everyone who participated in Advent of Code 2025 in Kotlin! Once again, it was a joy to see so many of you sharing solutions, cheering each other on in Slack, and keeping the holiday coding spirit alive.\nThis year, we kicked things off with five days of livestreams on December 1–5, with Sebastian Aigner and fantastic guests solving puzzles live, discussing strategies, and showing off idiomatic Kotlin approaches.\nIf you missed the streams or want to revisit a clever trick, you can still catch up with the recordings:\n\n\n\n\n\n\nCommunity\nThe Advent of Code puzzles remain available all year round, and so does the community energy. The #advent-of-code channel in the Kotlinlang Slack was once again full of:\nCreative Kotlin snippets\nNon-spoiler hints\nLots of encouragement\nWhether you took part in discussions every day or just lurked and learned, thank you for making the channel such a friendly, collaborative space.\nJoin the AoC channel in Slack\nWinners\nAs in previous years, we invited you to solve Advent of Code puzzles in Kotlin, join our Kotlin leaderboards, and share your solutions on GitHub with the aoc-2025-in-kotlin topic for a chance to win special Kotlin prizes.\nThis year, we’re celebrating nine winners across three categories: Fastest to Solve, Random, and Community.\nFastest to Solve\nThese three contestants topped the combined Kotlin leaderboards, consistently solving the puzzles at impressive speed:\nKroppeb\nAndrejStratmann\n770grappenmaker\n\n\n\n\n\nCongratulations on those lightning-fast stars and Kotlin-powered solutions!\nRandom winners\nTo give everyone a chance regardless of speed, we also randomly selected three prize winners from all the participants:\nlbcp\nFelixDombek\nbjdupuis\n\n\n\n\nIf you see your name here, keep an eye on your inbox. We’ll be in touch about your prize soon.\nCommunity winners\nFinally, Advent of Code in Kotlin wouldn’t be the same without the people who answer questions, share insights and alternative solutions, help newcomers get started, and keep the #advent-of-code channel buzzing throughout December.\nThis year, we’d like to give a special shout-out to these three community stars:\njakubgwozdz\nbj0\nephemient\n\n\n\n\n\nThank you for your team spirit in the Kotlin community!\nKeep learning and solving\nAdvent of Code might be over for this year, but the puzzles and the learning opportunities remain. If you’d like to keep sharpening your skills and prepare for future events, here are some resources:\nAdvent of Code 2025 in Kotlin YouTube playlist.\nSolutions to Advent of Code puzzles from previous years in idiomatic Kotlin.\nA tutorial on how to explore and solve programming puzzles using Kotlin Notebooks.\n\n\n\n\nWe want to say a huge thank-you, as always, to Eric Wastl and the Advent of Code team for creating such a beloved set of puzzles year after year.\nLet’s keep exploring Kotlin, solving algorithmic challenges, and supporting each other. We hope to see you for the next Advent of Code in Kotlin! 🎄",
        "dc:creator": "Ksenia Shneyveys",
        "content": "Thank you to everyone who participated in Advent of Code 2025 in Kotlin! Once again, it was a joy to see so many of you sharing solutions, cheering each other on in Slack, and keeping the holiday coding spirit alive. This year, we kicked things off with five days of livestreams on December 1–5, with [&#8230;]",
        "contentSnippet": "Thank you to everyone who participated in Advent of Code 2025 in Kotlin! Once again, it was a joy to see so many of you sharing solutions, cheering each other on in Slack, and keeping the holiday coding spirit alive. This year, we kicked things off with five days of livestreams on December 1–5, with […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=673883",
        "categories": [
          "education",
          "news",
          "advent-of-code",
          "aoc",
          "prizes"
        ],
        "isoDate": "2026-01-12T19:33:14.000Z"
      },
      {
        "creator": "Dmitrii Korovin",
        "title": "How to Troubleshoot Builds With TeamCity Dashboards",
        "link": "https://blog.jetbrains.com/teamcity/2026/01/how-to-troubleshoot-teamcity-builds-using-dashboards/",
        "pubDate": "Mon, 12 Jan 2026 17:16:46 +0000",
        "content:encodedSnippet": "This article was brought to you by Damaso Sanoja, draft.dev.\nIf you’re spending your mornings debugging Jenkins pipeline failures, waiting for builds that should take minutes but stretch into hours, or scrambling to identify which plugin update broke your deployment process, you’re not alone. These daily troubleshooting battles with legacy CI/CD systems drain engineering time that could be spent building features and delivering value.\nTeamCity’s built-in health signals help you address these everyday struggles head-on by surfacing the root causes of your pipeline problems before they escalate. Instead of hunting through logs to understand why builds fail, you get clear visibility into success rates, build duration trends, and bottleneck identification. When issues arise, comprehensive test reporting and failure analysis help you pinpoint what broke and why, turning hours of detective work into minutes of targeted fixes.\nIn this article, you’ll learn how TeamCity’s monitoring and diagnostic capabilities give you the insights needed to maintain stable and fast pipelines and spend more time on what matters most – shipping quality software.\nEnsuring stability and quality in every release\nConsistently shipping stable, high-quality code is non-negotiable; unstable releases undermine customer trust, inflate support costs, and create compounding technical debt. But how do you know your pipeline is stable and which levers improve quality?\nTeamCity’s Statistics Charts offer precise answers that translate complexity into clarity.\nMonitor success rates for continuous stability\nSuccess rate is an important metric of any CI/CD: It tracks the percentage of passing builds over time, spotlighting trends and sudden changes.\nHigh success rates indicate predictable pipelines and effective feedback loops, while dips signal fragility, demanding immediate attention.\n\n\n\n\nVisualize test failures to diagnose quality risks\nFailure rates provide additional insight: While the success rate gives you a pass/fail snapshot, overlaying failed test counts helps pinpoint when and how systemic issues emerge, revealing what releases are more problematic.\nIn the same Statistics tab, toggle Show failed in the Test Count graph to make test failures visible.\n\n\n\n\nAccess high-level failure data in seconds\nRapidly spotting patterns, like back-to-back failures, allows for proactive fixes before technical debt accumulates.\nUse the Overview tab for a high-level summary of all builds for a project, listed with their statuses, durations, changes, and failure indicators.\n\n\n\n\nInvestigate failures with one click\nClick into any build for detailed information regarding the status of every step, their duration, code-inspection results, changes in the code, and more:\n\n\n\n\nFollow the evidence: Click the Tests tab to get the full breakdown of which tests failed, whether they’re new or recurring, and contextual details that guide targeted fixes:\n\n\n\n\nFrom the Tests tab, you can drill deeper into individual test behavior by accessing the test history page. Click the three-dot menu to the right of any test name to open this view, which reveals patterns in test failures, such as how frequently the test fails, which build agents experience issues, when failures began, and trends over time. This historical perspective helps you distinguish between flaky tests and genuine regressions, making it easier to prioritize fixes based on impact and recurrence.\n\n\n\n\nTo complete the feedback loop, the Build Log offers a searchable, chronological trace of every step for uncovering underlying errors and misconfigurations behind failed tests.\n\n\n\n\nFrom failures to code quality: Tracking what matters\nAfter tracing a failure, comprehensive quality assurance means going beyond green builds to deep code insights. TeamCity’s Statistics tab offers dedicated charts for Code Inspections and Code Coverage to track technical debt and ensure essential logic is tested. You can also extend TeamCity’s dashboard by adding custom tabs with your own reports to the build results interface, enabling you to incorporate specialized metrics and third-party analysis tools directly into your workflow.\n\n\n\n\nClicking any point in the Code Coverage chart brings you to that build’s Coverage tab. Depending on your configured tool (in this example, coverage.py), you’ll find granular coverage reports here. These insights clarify which parts of your codebase are thoroughly tested versus those at risk of silent failure.\n\n\n\n\nUnderstanding where failures occur and which code remains untested raises quality, shortens feedback loops, and reduces risk for every subsequent release.\nAccelerating delivery: Measuring and improving release velocity\nOnce stability and quality are established, the next challenge for any engineering team is maximizing how quickly new value reaches users.\nTeamCity’s analytic charts and dashboards surface velocity as a multidimensional flow to help you drive meaningful gains in delivery speed without sacrificing rigor. You can enhance these analytics by reporting custom statistic values using TeamCity service messages directly from your build steps, allowing you to track metrics like code coverage percentages, inspection results, and other team-specific indicators alongside TeamCity’s built-in measurements.\nMonitoring release cadence for continuous value delivery\nEvery successful production release puts features, fixes, and security improvements directly into the hands of customers. That’s why tracking how often your CI/CD pipeline ships code is a critical health signal for agility and operational efficiency.\nFrequent deployments mean smaller, safer changes and less risk per release.\nTeamCity charts like Time Spent in Queue and Build Times help you identify when and how production deployments occur to quickly spot accelerations or slowdowns in delivery cadence.\n\n\n\n\nShortening cycle time for a faster feedback loop\nSpeed isn’t just about shipping more often; it’s also about reducing the interval between code commit and user impact. This end-to-end cycle time is an important health signal that defines your delivery pipeline’s efficiency and how quickly improvements make it to production.\nTeamCity’s flexibility allows for custom charts that highlight patterns in end-to-end delivery duration. For instance, you can build an Average Deployment Time graph using the Starting Build on Agent and Finishing Build on Server metrics:\n\n\n\n\nImproving failure response time to minimize impact\nThe speed at which your team responds to and recovers from production failures is a pivotal indicator of both resilience and operational maturity. TeamCity’s Time to Fix Tests and detailed build duration analytics show you how quickly errors surface and get resolved so you can quantify the impact of failures and how effectively you recover.\n\n\n\n\nMonitoring build duration for sustainable velocity\nVelocity also depends on how little time is wasted in each cycle. Analyzing Build Times and Build Duration by Stage reveals how efficiently your pipeline processes changes to help you maintain momentum and ensure timely deployments.\n\n\n\n\nDiagnosing bottlenecks: Pinpointing and resolving pipeline inefficiencies\nWhile fast delivery accelerates value, a truly effective pipeline depends on quickly surfacing and eliminating waste before slowdowns become systemic. Efficiently diagnosing bottlenecks prevents frustration, boosts developer productivity, and ensures that each iteration is an opportunity for improvement, not an exercise in firefighting.\nTeamCity’s analytics transform this process from guesswork into surgical, data-driven action.\nSpotting build spikes with actionable trends\nAnalyzing build duration trends is one of the most effective ways to identify pipeline inefficiencies. A sudden spike on the Build Times chart instantly highlights a potential issue, whether due to environmental issues, unusually long tests, or integration problems.\nFor example, you can use the Build Duration by Stage custom chart to pinpoint where in the pipeline bottlenecks occur as soon as unusual patterns emerge.\n\n\n\n\nInvestigating test duration: Finding the crawl in your pipeline\nLong build times can often be traced back to problematic tests. You can use the Tests tab in any build to check on the status, name, and duration of every test.\n\n\n\n\nIf the test duration is abnormally high, you can click on it for a historical trend chart that lets you identify when the test began slowing down and in what context.\n\n\n\n\nSimply click on any test to mute it or assign ownership for further investigation, ensuring accountability and rapid feedback.\n\n\n\n\nDetecting and managing flaky tests automatically\nFlaky tests (those that fail unpredictably) can silently degrade confidence in your pipeline and are notoriously difficult to spot through duration analysis alone.\nTeamCity proactively flags flaky tests and surfaces them in the dedicated Flaky Tests tab at the project level. Here, you see the test name, failure count, flip rate, and insights into the causes for flakiness that you can act on.\n\n\n\n\nFlaky tests are also prominently flagged in the Overview code inspection section for any failed build. Click into the test entry for a detailed stack trace, or open the error in the Build Log for a deeper dive.\n\n\n\n\nUsing test reports for root-cause analysis\nAlong with flaky test management, TeamCity’s Tests tab flags these problematic tests and offers a Test History report on clicking. These reports let you compare failure patterns across builds by listing status, duration, build number, changes, agent, and precise timestamps side by side. Additionally, an intuitive history chart enables quick trend analysis.\n\n\n\n\nConclusion\nMoving beyond the daily cycle of troubleshooting builds requires more than patch fixes and workarounds. TeamCity provides the diagnostic clarity you need with built-in health signals that reveal build duration trends, success rate patterns, and failure root causes – without having to dive through endless plugin configurations or log files.\nInstead of spending hours investigating why builds randomly fail or trying to identify which plugin update broke your deployment chain, TeamCity’s comprehensive monitoring gives you immediate visibility into pipeline bottlenecks and stability issues. The integrated test reporting eliminates guesswork so you can pinpoint problems quickly and maintain consistent delivery performance.",
        "dc:creator": "Dmitrii Korovin",
        "content": "This article was brought to you by Damaso Sanoja, draft.dev. If you&#8217;re spending your mornings debugging Jenkins pipeline failures, waiting for builds that should take minutes but stretch into hours, or scrambling to identify which plugin update broke your deployment process, you&#8217;re not alone. These daily troubleshooting battles with legacy CI/CD systems drain engineering time [&#8230;]",
        "contentSnippet": "This article was brought to you by Damaso Sanoja, draft.dev. If you’re spending your mornings debugging Jenkins pipeline failures, waiting for builds that should take minutes but stretch into hours, or scrambling to identify which plugin update broke your deployment process, you’re not alone. These daily troubleshooting battles with legacy CI/CD systems drain engineering time […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=673380",
        "categories": [
          "best-practices",
          "teamcity-2",
          "devopspains",
          "docker"
        ],
        "isoDate": "2026-01-12T17:16:46.000Z"
      },
      {
        "creator": "Dominika Stankiewicz",
        "title": "Dancing Backwards With Go",
        "link": "https://blog.jetbrains.com/go/2026/01/12/dancing-backwards-with-go/",
        "pubDate": "Mon, 12 Jan 2026 12:07:51 +0000",
        "content:encodedSnippet": "This is a guest post from John Arundel, a Go writer and teacher who runs a free email course for Go learners. His book The Power of Go: Tests is a love letter to test-driven development in Go.\n“Fred Astaire? Sure, he was great, but don’t forget Ginger Rogers did everything he did… backwards, and in high heels.”\n\n            \nBob Thaves\n                                                        \nHave you ever tried programming backwards? If not, you’re in for a treat! You won’t even need to wear high heels.\n(If you want to, though, go for it—you’ll look fabulous!)\nThe function that never was\nSuppose we want to write a Go function that checks whether a given slice is sorted (that is, its elements are in order).\nFor example, if the input is {1, 2, 3}, the answer should be true, because the slice is sorted. On the other hand, if the input is {3, 1, 2}, we should get false, because the slice is not sorted.\nMost people would probably start writing some function IsSorted. That’s fine for Fred Astaire. Just for fun, though, shall we try tackling this problem backwards, like Ginger Rogers?\nWe’ll start by imagining that we already have the IsSorted function, and we’ll try to write a test for it. Once we have the test, we’ll go on to write the function.Let’s fire up GoLand and select File / New / Project… / sorted.\n\n\n\n\nNext, we’ll use New / Go File to create a source file, and name it sorted_test.go.\nWe’ll start by declaring:\npackage sorted_test\nAll Go tests have the same signature, so the test snippet saves us writing it. We’ll type test, and press Tab to complete:\nfunc TestName(t *testing.T) {\n\n}\nWe’re invited to replace Name with a description of the behavior to test. How about:\nfunc TestIsSorted_IsTrueForSortedSlice(t *testing.T) {\n\n}\nSounds believable, so let’s fill in the rest:\nfunc TestIsSorted_IsTrueForSortedSlice(t *testing.T) {\n    t.Parallel()\n    input := []int{1, 2, 3}\n    if !sorted.IsSorted(input) {\n        t.Errorf(\"got false for %v\", input)\n    }\n}\nIf the result of calling IsSorted on this input is false, the test fails. Straightforward!\nThe fastest route to failure\nWe know IsSorted doesn’t exist yet, but before we implement it, we need to know if this test will actually detect bugs in IsSorted. That’s what tests are for, after all.\nLet’s write as little code as we possibly can to get this test compiling and failing. The first problem GoLand tells us about is “Unresolved reference sorted”. Fair enough!\nWe need to create the sorted package, so let’s set up another new file: New / Go File / sorted.go.\nNow we have a quick-fix action available in the test: import sorted. Great!\n\n\n\n\nWe still have an unresolved reference IsSorted, but now we can use the quick fix Create Function IsSorted. Here’s the result:\nfunc IsSorted(input []int) bool {\n\n}\nGood start, but now GoLand says “Missing the return statement at end of function.” Here’s the quick fix: Add return statement.\n\n\n\n\nNow we have:\nfunc IsSorted(input []int) bool {\n    return\n}\nAlmost there, but now we have the error “not enough arguments to return.” Quick fix again: Add missing return values.\nfunc IsSorted(input []int) bool {\n    return false\n}\n“But this won’t work!” I hear you wail. “It always returns false no matter what the input!”\nYour wailing is on point, dear reader, but remember, we want a non-working implementation, and now we have one. This is the perfect time to check if our test will actually detect a bug in IsSorted—for instance, that it always returns false!\nLet’s click the green triangle next to the test name to run the test. We assume it will fail, but you never know—that’s why we check:\nsorted_test.go:12: got false for [1 2 3]\n--- FAIL: TestIsSorted_IsTrueForSortedSlice (0.00s)\n\n\n\n\nSuccess! (I said this was backwards.)\n\n\n\n\nCranking up the difficulty\nWe could trivially change IsSorted to return true instead of false to make this pass, but that doesn’t really get us anywhere. IsSorted needs to be able to distinguish between sorted and unsorted slices, not just return a fixed value.\nWe want two tests, for two different behaviours: that IsSorted is true for sorted inputs, and that it’s false for unsorted ones.\nfunc TestIsSorted_IsTrueForSortedSlice(t *testing.T) {\n    t.Parallel()\n    input := []int{1, 2, 3}\n    if !sorted.IsSorted(input) {\n        t.Errorf(\"got false for %v\", input)\n    }\n}\n\nfunc TestIsSorted_IsFalseForUnsortedSlice(t *testing.T) {\n    t.Parallel()\n    input := []int{1, 3, 2}\n    if sorted.IsSorted(input) {\n        t.Errorf(\"got true for %v\", input)\n    }\n}\nA fixed-value implementation could pass one test or the other, but not both. Let’s prove it, using the Ctrl-Shift-R shortcut to run all tests in this file:\n\n\n\n\nHow little work do you think we can do to get both tests passing?\nBaby’s first steps\nIf any elements are not in order, then at some point we’ll encounter a number that’s smaller than the previous one. The simplest, dumbest way I can think of to detect that is:\nfunc IsSorted(input []int) bool {\n    prev := 0\n    for _, v := range input {\n        if v < prev {\n            return false\n        }\n    }\n    return true\n}\nIt seems reasonable, but I could stare at this code all day and not be sure whether it’s correct or not. Let’s check:\n=== FAIL:  TestIsSorted_IsFalseForUnsortedSlice\n    sorted_test.go:20: got true for [1 3 2]\n\n\n\n\nOops. I forgot to update prev with each new number (not enough coffee today). Let’s add a prev = v to the loop:\nfunc IsSorted(input []int) bool {\n    prev := 0\n    for _, v := range input {\n        if v < prev {\n            return false\n        }\n        prev = v\n    }\n    return true\n}\nThis passes both tests now, but is it really correct? Again, we could have a staring contest with this code looking for bugs, and we might find some, or we might not.\n\n\n\n\nThe backwards programmer’s approach, though, is to stare at the tests instead. Can we think of some more test cases that might trip up a buggy implementation of IsSorted?\nWhat about a slice that contains repeated numbers, for example?\nfunc TestIsSorted_IsTrueForSortedSliceWithRepeat(t *testing.T) {\n    t.Parallel()\n    input := []int{1, 2, 2}\n    if !sorted.IsSorted(input) {\n        t.Errorf(\"got false for %v\", input)\n    }\n}\nThis passes, which is encouraging. But I notice that the test logic is the same for all our “sorted” tests, so let’s combine them into a single table test.\n\n\n\n\nCases on the table\nGoLand can write this table test for us, if we right-click on the IsSorted function and select Generate / Test for function:\nfunc TestIsSorted(t *testing.T) {\n    type args struct {\n        input []int\n    }\n    tests := []struct {\n        name string\n        args args\n        want bool\n    }{\n        // TODO: Add test cases.\n    }\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            if got := sorted.IsSorted(tt.args.input); got != tt.want {\n                t.Errorf(\"IsSorted() = %v, want %v\", got, tt.want)\n            }\n        })\n    }\n}\nNot bad, but this generated code is just a suggestion: we don’t have to follow it slavishly. Let’s make a few small tweaks:\nWe’ll run the test in parallel\nWe’ll organise the test cases as a map, keyed by name\nWe don’t need to specify want every time, because it’s always true in this test\nSo:\nfunc TestIsSorted_IsTrueForSortedSlicesWith(t *testing.T) {\n    t.Parallel()\n    inputs := map[string][]int{\n        \"all elements different\": {1, 2, 3},\n        \"repeated elements\":      {1, 2, 2},\n    }\n    for name, input := range inputs {\n        t.Run(name, func(t *testing.T) {\n            if !sorted.IsSorted(input) {\n                t.Errorf(\"got false for %v\", input)\n            }\n        })\n    }\n}\nUsing t.Run turns each case into a named subtest, and all our subtests can share the same function body, which simplifies things.\n\n\n\n\nThis replaces the two old IsTrue tests, so now let’s add another table test for IsFalse:\nfunc TestIsSorted_IsFalseForUnsortedSlicesWith(t *testing.T) {\n    t.Parallel()\n    inputs := map[string][]int{\n        \"all elements different\": {1, 3, 2},\n        \"repeated elements\":      {3, 2, 2},\n    }\n    for name, input := range inputs {\n        t.Run(name, func(t *testing.T) {\n            if sorted.IsSorted(input) {\n                t.Errorf(\"got true for %v\", input)\n            }\n        })\n    }\n}\nLooking good. Time for a well-earned break, I think. Would you care for some tea and cake?\nDon’t be so negative!\nWhile I was nibbling at a moist, fudgy chocolate brownie just now, I thought: prev starts at zero, but what if the first element is negative? Then we’d wrongly return false for a sorted slice, because v < prev. Yikes!\nYour conventional programmer—Fred Astaire, if you like—would jump straight into fixing IsSorted. But we’re backwards programmers, so we’ll use the Ginger Rogers technique: first write a failing test, then make it pass.\nfunc TestIsSorted_IsTrueForSortedSlicesWith(t *testing.T) {\n    t.Parallel()\n    inputs := map[string][]int{\n        \"all elements different\": {1, 2, 3},\n        \"repeated elements\":      {1, 2, 2},\n        \"negative first element\": {-1, 2, 3},\n    }\n    ...\nThis fails as expected:\n\n\n\n\nNow we can fix it. Let’s initialize prev to the first element of input and then loop over the remaining elements:\nfunc IsSorted(input []int) bool {\n    prev := input[0]\n    for _, v := range input[1:] {\n        if v < prev {\n            return false\n        }\n        prev = v\n    }\n    return true\n}\nAnd:\n\n\n\n\nOh glory be, oh happy day! We can ship the package to production and go out for our team pizza night (extra pepperoni on mine, please).\nLater that same week…\nWell, everything was fine for a few days, but then a bug report came in from a customer: IsSorted panicked when they called it with an empty slice (oh dear).\nWell, we can fix this—backwards! Let’s add the customer’s “no elements” test case to our table:\nfunc TestIsSorted_IsTrueForSortedSlicesWith(t *testing.T) {\n    t.Parallel()\n    inputs := map[string][]int{\n        \"all elements different\": {1, 2, 3},\n        \"repeated elements\":      {1, 2, 2},\n        \"negative first element\": {-1, 2, 3},\n        \"no elements\":            {},\n    }\n    ...\nThis should reproduce the bug report:\n\n\n\n\nNext, we’ll locate the panic using the stack trace:\nsorted.IsSorted(...)\n    /yumyum/cake/yesplease/sorted/sorted.go:4\nThis is a link, so clicking the filename teleports us straight to the offending line:\nprev := input[0]\nAn empty slice has no elements, hence the panic. But it is sorted, so we can simply return true straight away in this case:\nif len(input) == 0 {\n    return true\n}\n\n\n\n\nAnd while we’re here, let’s handle a one-element slice the same way. New test case:\nfunc TestIsSorted_IsTrueForSortedSlicesWith(t *testing.T) {\n    t.Parallel()\n    inputs := map[string][]int{\n        \"all elements different\": {1, 2, 3},\n        \"repeated elements\":      {1, 2, 2},\n        \"negative first element\": {-1, 2, 3},\n        \"no elements\":            {},\n        \"one element\":            {1},\n    }\n    ...\nA small tweak to the function:\nif len(input) < 2 {\n    return true\n}\nTests are passing, and customers are happy. Another win for backwards programming!\n\n\n\n\nCutting out the calories\nA little while later, a new member of the team, Alyssa, is looking at our current version of IsSorted:\nfunc IsSorted(input []int) bool {\n    if len(input) < 2 {\n        return true\n    }\n    prev := input[0]\n    for _, v := range input[1:] {\n        if v < prev {\n            return false\n        }\n        prev = v\n    }\n    return true\n}\n“You know,” she says, “there’s a function for this in the standard library. I think we could replace all this code with just…”\nreturn slices.IsSorted(input)\nHuge if true! Well, we know exactly how to find out: run the tests.\nJust for fun, let’s use the gotestdox tool, which both runs the tests and prints their names as English sentences. “Tests as docs”, if you like.\ngo run github.com/bitfield/gotestdox/cmd/gotestdox@latest\n\n\n\n\nWonderful! This is exactly the kind of radical refactoring idea we hoped you’d bring to the team, Alyssa P. Hacker. And backwards programming helped make it safe: by writing our tests first, we made sure that any new code is always covered by tests.\nThe way forward?\nSo that’s backwards programming. Once you’ve tried it, it doesn’t really seem so backwards after all, does it?\nNext time you have a feature to add or a bug to fix, then, why not try doing the backwards quickstep yourself? It’s as easy as “red, green, refactor”:\nAdd a failing test (“red”)\nMake it pass (“green”)\nTidy up, optimise, and check that all tests still pass (“refactor”)\nJust remember to always look where you’re going, and try not to trip over your own feet. Shall we dance?",
        "dc:creator": "Dominika Stankiewicz",
        "content": "This is a guest post from John Arundel, a Go writer and teacher who runs a free email course for Go learners. His book The Power of Go: Tests is a love letter to test-driven development in Go. Have you ever tried programming backwards? If not, you’re in for a treat! You won’t even need [&#8230;]",
        "contentSnippet": "This is a guest post from John Arundel, a Go writer and teacher who runs a free email course for Go learners. His book The Power of Go: Tests is a love letter to test-driven development in Go. Have you ever tried programming backwards? If not, you’re in for a treat! You won’t even need […]",
        "guid": "https://blog.jetbrains.com/?post_type=go&p=672799",
        "categories": [
          "goland",
          "go",
          "golang"
        ],
        "isoDate": "2026-01-12T12:07:51.000Z"
      },
      {
        "creator": "Innokentii Burtsev",
        "title": "Bringing Real Users Into a Product Team Gathering – A JetBrains Research Story",
        "link": "https://blog.jetbrains.com/research/2026/01/bringing-real-users-into-a-product-team-gathering-a-jetbrains-research-story/",
        "pubDate": "Fri, 09 Jan 2026 12:37:47 +0000",
        "content:encodedSnippet": "In product development, assumptions about how people will use a tool don’t always align with the practical reality.\nLast spring, during a gathering of our Junie team, we set out to bridge that gap by trying something new. We ran two hands-on user workshops – one online and another in our Belgrade office. For the first time ever, we brought external users directly into an internal event.\nHere’s what happened, what we discovered, and why we think this approach is worth repeating – both for us and for other research and product teams.\nWhy we did it\nAt JetBrains, user research is a continuous effort. Our UX Research team, part of the larger Strategic Research and Market Intelligence team, conducts studies, surveys, and experiments for multiple products. Usually, our role is to provide synthesized insights to product teams.\nThis time, however, we wanted to flip the model. Instead of delivering results, we created a space where everyone on the product team – developers, designers, and managers – could experience first-hand contact with real users.\nThat kind of direct exposure can help foster empathy and transform abstract feedback into tangible improvements.\nOvercoming the challenges\nIt wasn’t all smooth sailing:\nRecruitment: We had just two weeks to recruit participants and prepare interview guides. We solved it through snowball sampling, reaching out via personal connections.\nRewards: Reward logistics were tricky, as some countries don’t support common gift card providers.\nTraining: Many team members had never conducted live interviews before, so we gave them a crash course on user research.\nThese adjustments proved that meaningful research activities can happen even under tight constraints.\nThe online sessions\nWe met with five active users via video to explore how they work with Junie, what tasks it helps them complete, and where they see room for improvement.\nAfter the interviews, the team regrouped to share observations and brainstorm potential roadmap ideas.\nIn-person workshop \nFive small business owners joined us in our Belgrade office.\nEach team had 1.5 hours to create a working website using our tool and then present the results.\nThis “build together” format exposed strengths and weaknesses in real-time, with deeper insights often hidden in surveys or retrospective interviews.\n📌 Key takeaways\nBy embedding live user sessions into a team gathering, we:\n✅ Gave non-researchers a chance to practice their interviewing and observation skills.\n✅ Sparked product discussions grounded in real, shared experiences rather than reports.\n✅ Strengthened the connection between roadmap decisions and user needs.\nEven a short, structured user research activity during an in-person team workshop or planning session can make feedback tangible, accelerate learning, and increase empathy, proving that UX research doesn’t have to be separate from everyday product development.\nThe key is to keep it simple, prepare teams with just enough guidance, and focus on authentic user interaction.\n💬 Want to take part in future JetBrains research?\nJoin our research panel to get early access to product experiments, test new features, and share your feedback directly with our teams.\n👉 Sign up here to join the JetBrains Tech Insights Lab",
        "dc:creator": "Innokentii Burtsev",
        "content": "In product development, assumptions about how people will use a tool don’t always align with the practical reality. Last spring, during a gathering of our Junie team, we set out to bridge that gap by trying something new. We ran two hands-on user workshops – one online and another in our Belgrade office. For the [&#8230;]",
        "contentSnippet": "In product development, assumptions about how people will use a tool don’t always align with the practical reality. Last spring, during a gathering of our Junie team, we set out to bridge that gap by trying something new. We ran two hands-on user workshops – one online and another in our Belgrade office. For the […]",
        "guid": "https://blog.jetbrains.com/?post_type=research&p=672757",
        "categories": [
          "research",
          "jetbrains-tech-insights-lab"
        ],
        "isoDate": "2026-01-09T12:37:47.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": [
      {
        "creator": "Gerum Haile",
        "title": "Pay As a Local",
        "link": "https://medium.com/airbnb-engineering/pay-as-a-local-bef469b72f32?source=rss----53c7c27702d5---4",
        "pubDate": "Mon, 12 Jan 2026 18:02:56 GMT",
        "content:encodedSnippet": "How Airbnb rolled out 20+ locally relevant payment methods worldwide in just 14 months\nBy: Gerum Haile, Bo Shi, Yujia Liu, Yanwei Bai, Bo Yuan, Rory MacQueen, Yixia Mao\n\nAcross the more than 220 global markets that Airbnb operates in, cards are the primary way that guests pay for stays, experiences, and services. However, to help make our platform accessible to more people, reduce friction at checkout, and drive more adoption, we introduced trusted, locally preferred payment methods — called local payment methods or LPMs. By offering and supporting these payment methods, Airbnb enables guests everywhere to choose what works best for them.\nIn this blog post, we’ll discuss the implementation details behind our Pay as a Local initiative, which allowed us to launch 20+ local payment methods across multiple markets in just over one year.\nLPMs: What they are, why they matter, and our discovery and selection process\nLocal payment methods go beyond traditional cards and include:\n\nCountry or region-specific digital wallets (such as M-Pesa or MTN, MoMo)\nOnline bank transfers (such as Online Banking Czech, Online Banking Slovakia)\nReal-time or instant bank payments (such as PIX, UPI)\nLocal payment schemes (such as EFTPOS, Cartes Bancaires)\n\nBy embracing LPMs, Airbnb helps make travel more inclusive and seamless for people around the world. LPMs help the platform to:\n\nBoost conversion and bookings by offering guests familiar, trusted payment options.\nUnlock new markets where credit card usage is low or non-existent.\nBuild accessibility for guests without credit cards or traditional banking access.\n\nThrough our research on local payment methods (LPMs), we identified over 300 unique payment options worldwide. For the initial phase of the LPM initiative, we used a structured qualification framework to select which local payment methods we would support. We evaluated the top 75 travel markets and selected the top one to two payment methods per market — excluding those without a clear travel use case — and arrived at a shortlist of just over 20 LPMs best suited for integration into our payment platform.\nBackground on Airbnb’s payment platform\nAirbnb’s payments platform is designed to decouple payment logic from the core business (i.e., stays, experiences, and services), allowing for greater flexibility and scalability. The platform efficiently coordinates both guest pay-ins and host payouts by working with regulated payment service providers and financial partners.\nBeyond payment processing, the system also supports robust payment trust and compliance functions.\nModernization\nAs part of a multi-year replatforming initiative for our payments architecture called Payments LTA (long-term architecture), we shifted from a monolithic system to a capability-oriented services system structured by domains, using a domain-driven decomposition approach. This modernization approach reduced our time to market, increased reusability and extensibility, and empowered greater team autonomy.\nThe core payment domain delivers essential capabilities for pay-in, payout, and payment intermediation. It consists of multiple subdomains, including Pay-in, Payout, Transaction Fulfillment, Processing, Wallet & instruments, Ledger, Incentives & Stored Value, Issuing, and Settlement & Reconciliation.\nReplatforming as an enabler for local payment method expansion\nThe processing subdomain enables integration with third-party payment service providers (PSPs) and supports API and file-based vendor integration, as well as switching and routing capabilities. As part of our replatforming initiative, we adopted a connector and plugin-based architecture for onboarding new third-party payment service providers. This strategy has significantly reduced the time required to integrate new PSPs in different markets.\nDuring this replatforming effort, we also introduced Multi-Step Transactions (MST): a processor-agnostic framework that supports payment flows completed across multiple stages. MST defines a PSP-agnostic transaction language to describe the intermediate steps required in a payment, such as submitting supplemental data or handling dynamic interactions. These steps, called Actions, can include:\n\nRedirects\nStrong customer authentication (SCA) frictions (challenges, fingerprinting)\nPayment method — specific flows\n\nWhen a PSP indicates that an additional user action is required, its vendor plugin normalizes the request into an ActionPayload and returns it with a transaction intent status of ACTION_REQUIRED. This architecture ensures consistent handling of complex, multi-step payment experiences across diverse PSPs and markets.\n\nLPM integration architecture\nWhile our modernized payment platform laid the foundation for enabling LPMs, these payment methods come with a unique set of challenges. Many local methods require users to complete transactions in third-party wallet apps. This introduces complexity in app switching, session hand-off, and synchronization between Airbnb and external digital wallets.\nEach local payment vendor also exposes different APIs and behaviors across charge, refund, and settlement flows, making integration and standardization difficult.\nTechnical approach\nWe analyzed the end-to-end behavior of our 20+ LPMs, and identified three foundational payment flows that capture the full spectrum of user and system interactions. By distilling LPM behaviors into these standardized payment flow archetypes, we established a unified framework for integration:\n\nRedirect flow: Guests are redirected to a third-party site or app to complete the payment, then return to Airbnb to finalize their booking (e.g., Naver Pay, GoPay, FPX).\nAsync flow: Guests complete payment externally after receiving a prompt (such as a QR code or push notification), and Airbnb receives payment confirmation asynchronously via webhooks (e.g., Pix, MB Way, Blik).\nDirect flow: Guests enter their payment credentials directly within Airbnb’s interface, allowing real-time processing similar to traditional card payments (e.g., Carte Bancaires, Apple Pay).\n\nThis standardized approach has enabled significant reusability across integrations and substantially reduced the engineering effort required to support new payment methods.\nAsynchronous payment orchestration\nSince many guests complete payments through external providers, we redesigned our payment orchestration — building on top of MST — to support payment flows that require user actions outside Airbnb (redirect flows and async flows).\nFor redirect flows, where guests complete the payment on a third-party app or website:\n\nAirbnb’s payments platform sends a charge request to the local payment vendor, whose response includes a redirectUrl.\nOur platform redirects the user to the external app or website to complete the payment.\nOnce the payment is successfully completed, the user is redirected back to Airbnb with a result token. Airbnb’s payments platform then uses this token to securely confirm and finalize the payment with the local processor.\n\nFor async flows (which typically involve scanning a QR code):\n\nAirbnb’s payments platform sends a charge request to the local payment vendor, whose response includes a qrCodeData.\nThe checkout page displays the QR code for the user to scan and complete the payment in their wallet app.\nAfter the payment succeeds, the vendor sends a webhook notification to Airbnb’s payments platform, which updates the payment status to success and confirms the user’s order.\n\nNaver Pay: Redirect To Naver Pay Website\nNaver Pay is one of the fastest-growing digital payment methods in South Korea. As of early 2025, it has reached over 30.6 million active users, representing approximately 60% of the South Korean population. Enabling Naver Pay in the South Korean market not only helps deliver a more seamless and familiar payment experience for local guests, but also expands Airbnb’s reach to new users who prefer using Naver Pay as their primary payment method.\n\nPix: Scan A QR Code\nPix is an instant payment system developed by the Central Bank of Brazil, enabling 24/7 real-time money transfers through methods such as QR codes or Pix keys. Its adoption has been extraordinary — by late 2024, more than 76% of Brazil’s population was using Pix, making it the country’s most popular payment method, surpassing cash, credit, and debit cards. In 2024 alone, Pix processed over BRL 26.4 trillion (approximately USD 4.6 trillion) in transaction volume, underscoring its pivotal role in Brazil’s digital payment ecosystem.\n\nConfig-driven payment method integration\nAirbnb embraced a config-driven approach, powered by a central YAML-based Payment Method Config that acts as a single source of truth for flows, eligibility, input fields, refund rules, and more. Instead of scattering payment method logic across the frontend, backend, and various services, we consolidate all relevant details in this config. Both core payment services and frontend experiences dynamically reference this single source of truth, ensuring consistency for eligibility checks, UI rendering, and business rules. This unified approach dramatically reduces duplication, manual updates, and errors across the stack, making integration and maintenance faster and more reliable.\nThese configs also drive automated code generation for backend services using code generation tools, producing Java classes, DTOs, enums, schema, and integration scaffolding. As a result, integrating or updating a payment method is largely declarative — just a config change. This streamlines launches from months to weeks and makes ongoing maintenance far simpler.\n\nPayment widget\nOur payment widget — the payment method UI embedded into the checkout page — includes the list of available payment methods and handles the user’s inputs. Local payment methods often require specialized input forms (such as CPF for Pix) and have unique country/currency eligibility.\nRather than hardcoding forms and rules into the client, we centralize both form-field specification and eligibility checks in the backend. Servers send configuration payloads to clients defining exactly which fields to collect, which validation rules to apply, and which payment options to render. This empowers the frontend to dynamically adapt UI and validation for each payment method, accelerating launches and keeping user experiences fresh without frequent client releases.\nFor example, Pix in Brazil requires the guest’s first name, last name, and CPF (tax ID), which we collect and transmit as required to complete the payment.\n\nBelow is a diagram illustrating how dynamic payment method configurations are delivered from the backend to the frontend, enabling tailored checkout presentations for each payment method.\n\nBuilding confidence through better testability\nTesting local payment methods can be difficult, because developers often don’t have access to local wallets. Yet with such a broad range of payment methods and complex flows, comprehensive testing is essential to prevent regressions and ensure seamless functionality.\nTo address this, we enhanced Airbnb’s in-house Payment Service Provider (PSP) Emulator, enabling realistic simulation of PSP interactions for both redirect and asynchronous payment methods. The Emulator allows developers to test end-to-end payment scenarios without relying on unstable (or nonexistent) PSP sandboxes. For redirect payments, the Emulator provides a simple UI mirroring PSP acquirer pages, allowing testers to explicitly approve or decline transactions for precise scenario control. For async methods, it returns QR code details and automatically schedules webhook emission tasks upon receiving a /payments request — delivering a complete, reliable testing environment across diverse LPMs.\n\nScaling observability for local payment methods\nMaintaining high reliability and availability is critical for Airbnb’s global payment system. As we expand to support many new local payment methods, we face increasing complexity: greater dependencies on external PSPs and wide variations in payment behaviors. For example, a real-time card payment and a redirect flow like Naver Pay follow completely different technical paths. That diversity makes observability difficult — a single “payment success rate” may represent card health well, but say little about an asynchronous LPM. Without proper visibility, regressions can go unnoticed until they affect real users. As dozens of new LPMs go live, observability has become the foundation of reliability.\nTo address this, we built a centralized monitoring framework that unifies metrics across all layers, from client to PSP. When launching a new LPM, onboarding now requires a single config change; add the method name, and metrics begin streaming automatically:\n\nClient metrics — user-level flow health from clients\nPayment backend metrics — API-level metrics for payment flows\nPSP metrics — API-level visibility between Airbnb and the PSP\nWebhook metrics — async completion status for redirect methods or refunds\n\nWe have also standardized the alerting rules across our platform’s Client, Backend, PSP, and Webhook layers using composite alerts and anomaly detection. Each alert follows a consistent pattern (failure count, rate, time window), e.g., “Naver Pay resume failures > 5 and failure rate > 20% in 30 minutes.” This design minimizes false positives during low-traffic periods.\nThis framework scales effectively, providing end-to-end visibility from user click to PSP confirmation. It enables engineers to trace issues in minutes rather than hours, whether those issues were caused by internal changes or external outages. By turning observability into a shared, automated layer, we were able to strengthen the backbone of payment reliability while accelerating the rollout of new LPMs worldwide.\nImpact\nThe Pay as a Local initiative delivered significant business and technical impact:\n\nMeaningful booking uplift: We observed meaningful uplift in bookings and new users in markets where we launched local payment methods\nFaster integrations: Reduced integration time significantly through reusable flows and config-driven automation.\nStronger reliability: Improved observability for early outage detection, standardized testing to prevent regressions, and streamlined vendor escalation and on-call processes for global resilience.\n\nConclusion\nSupporting local payment methods helps Airbnb to stay competitive and relevant in the global travel industry. These payment options help improve checkout conversion, drive adoption, and unlock new growth opportunities.\nThis post outlined how the Airbnb payment platform has evolved to support local payment methods at scale — through asynchronous payment orchestration, config-driven onboarding, centralized observability, and robust testability. Together, these capabilities enable faster integrations, lower maintenance overhead, and offer a more seamless, localized checkout experience for guests worldwide.\nAs Airbnb continues to expand globally, our payments platform will keep evolving with the same principles of extensibility, reliability, and scalability, ensuring that guests everywhere can pay confidently, using the methods they know and trust.\nAcknowledgments\nWe had many people at Airbnb contributing to this big rearchitecture, but countless thanks to Mini Atwal, Ashish Singla, Musaab At-Taras,Linmin Yang, Yong Rhyu, Yohannes Tsegay, Livar Cunha, Praveena Subrahmanyam, Steve Ickes, Vijaykumar Borkar, Vibhu Ramani, Aashna Jain, Abhishek Ghosh, Abhishek Patel, Adithya Tammavarapu, Akai Hsieh, Akash Budhia, Amar Parkash, Amee Mewada, Ankita Balakrushan Tate, Bharath Kumar Chandramouli, Bo Shi, Bo Yuan. Callum Li. Carlos Townsend Pico, Chanakya Daparthy, Charles Tang, Cibi Pari, Cindy Jaimez, Cindy Shi, Dan Yo, Daniela Nobre, Danielle Zegelstein, David Cordoba, David Drinan, Dawei Wang, Dechuan Xu, Denise Francisco, Denny Liang, Dimi Matcovschi, Divya Verma, Feifeng Yang, Gabriel Siqueira, Sunny Wallia, Prashant Jamlakar, Daniel Kriske, Giovanni Iniguez, Haojie Zhang, Haokun Chen, Haoti Zhong, Harriet Russell, Harshit Gupta, Henrique Moreira Indio do Brasil, Ishan Ishan, Jenny Shen, Jerroid Marks, Jiafang Jiang, Joey Yin, Jon Chew, Karen Kuo, Katie Turley, Letian Zhang, Maneesh Lall, Manish Singhal, Maria Daneri, Mark Jang, Mengfei Ren, Michelle Desiderio, Mohit Dhawan, Nam Kim, Nerea Ruiz Alvarez, Nikita Kapoor, Oliver Zhang, Omer Faruk Gul, Pallavi Sharma, Prateek Sri, Rae Huang, Rohit Krishnan Dandayudham, Rory MacQueen, Ruize Liu, Sam Bitter, Sam Tang, Saran Singh. Sardana Sai Anil, Serdar Yildirim, Shwetha Saibanna, Silvia Crespo Sanchez, Simon Xia, Stella Dong, Stella Su, Stephanie Leung, Steve Cao, Sumit Ranjan, Tay Rauch, Thanigaivelan Manickavelu, Tiffany Selby, Toland Hon, Trish Burgess,Vishal Garg, Vivian Lue, Vyom Rastogi, William Betz, Xi Wen, Xing Xing, Xuanxuan Wu, Yangguang Li, Yanwei Bai, Yeung Song, Yixia Mao, Yujia Liu. Yun Cho, Zhenhui Zhu, Ziyun Ye\n****************\nAll product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.\n\nPay As a Local was originally published in The Airbnb Tech Blog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Gerum Haile",
        "guid": "https://medium.com/p/bef469b72f32",
        "categories": [
          "payments",
          "tech",
          "technology",
          "engineering"
        ],
        "isoDate": "2026-01-12T18:02:56.000Z"
      }
    ]
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Jessie Houghton",
        "title": "Copilot Memories",
        "link": "https://devblogs.microsoft.com/visualstudio/copilot-memories/",
        "pubDate": "Thu, 15 Jan 2026 13:00:33 +0000",
        "content:encodedSnippet": "Are you wasting time reviewing code for nits on code standards, project preferences, or important contribution guidelines? We know the pain. It’s all too easy for best practices and those tiny but critical team details to slip through the cracks, resulting in inconsistencies, confusion, and wasted time. But now, there’s a smarter way to ensure everyone’s always on the same page! \nHow Copilot memories make teamwork effortless \nIntroducing Copilot memories, a new feature that empowers every developer and team to capture, remember, and share their coding preferences and important project guidelines, automatically! \nIntelligent detection just for you and your team \nCopilot memories continuously learns how you and your team likes to work. It intelligently detects unique preferences within your projects as you prompt. No more manual reminders or digging through old messages. Copilot keeps track of what matters most, so you don’t have to. \nConfirmation nudges you can trust \nWorried about Copilot making changes without you knowing? Don’t be! Whenever Copilot is ready to save a new memory or update an existing one, you’ll receive a clear confirmation nudge. You’re always in control. Simply review, accept, or adjust as needed before preferences are updated. \nSmart categorization, right where you need it \nCopilot memories doesn’t just remember information. It also helps you organize it exactly where you expect to find it. Each memory gives you the option to save preferences in your personal user preference file %USERPROFILE%/copilot-instructions.md or in the version-controlled repo-level instructions in the /.github/copilot-instructions.md. Copilot intelligently merges the results into your existing files or creates new ones.\nBenefits for every developer and team \nWith Copilot memories, your projects automatically become more consistent and easier to onboard to. New team members can instantly see “how we do things here,” and seasoned pros save time by letting Copilot handle the details. It’s project-aware and makes documentation part of your natural workflow. \nCheck out the new Visual Studio Hub  \nStay connected with everything Visual Studio in one place! Visit the Visual Studio Hub for the latest release notes, YouTube videos, social updates, and community discussions.  \nAppreciation for your feedback  \nYour feedback helps us improve Visual Studio, making it an even more powerful tool for developers. We are immensely grateful for your contributions and look forward to your continued support. By sharing your thoughts, ideas, and any issues you encounter through Developer Community, you help us improve and shape the future of Visual Studio. \nThe post Copilot Memories appeared first on Visual Studio Blog.",
        "dc:creator": "Jessie Houghton",
        "comments": "https://devblogs.microsoft.com/visualstudio/copilot-memories/#comments",
        "content": "<p>Are you wasting time reviewing code for nits on code standards, project preferences, or important contribution guidelines? We know the pain. It’s all too easy for best practices and those tiny but critical team details to slip through the cracks, resulting in inconsistencies, confusion, and wasted time. But now, there’s a smarter way to ensure everyone’s always on the same [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/copilot-memories/\">Copilot Memories</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Are you wasting time reviewing code for nits on code standards, project preferences, or important contribution guidelines? We know the pain. It’s all too easy for best practices and those tiny but critical team details to slip through the cracks, resulting in inconsistencies, confusion, and wasted time. But now, there’s a smarter way to ensure everyone’s always on the same […]\nThe post Copilot Memories appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=255205",
        "categories": [
          "Visual Studio"
        ],
        "isoDate": "2026-01-15T13:00:33.000Z"
      }
    ]
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": [
      {
        "creator": "charsyam",
        "title": "The era of “Know-Right”",
        "link": "https://charsyam.wordpress.com/2026/01/11/the-era-of-know-right-2/",
        "pubDate": "Sun, 11 Jan 2026 06:20:33 +0000",
        "content:encodedSnippet": "The paradigm of knowledge keeps changing. In the beginning, it was the era of know-how. An individual’s experience and mastery were the greatest assets, passed down only within a person’s head or a limited part of an organization. The central question in that era was naturally “How do we implement this?” Anyone who could answer that how well was considered a valuable talent and central to work.\nThen time passed through the eras of know-what and know-where. As information became easier to find and more high-quality content was created, developers could get a lot of work done simply by searching Google, Stack Overflow, and other sources. Still, the core was know-how — because the quality of information was high enough that finding it generally meant it was reliable.\nBut now that period is becoming the era of “Know-Right.” (I’m not sure if this term really exists or is correct — I’m using it for my own thinking…) Information can be composed easily (I think “composed” is more accurate than “searched”), but now we must verify the reliability of that information. (I’m using AI assistance to write this, so you should verify this text’s reliability too.)\n\n\n\n\n\n\n\n\nHere is a simple summary in a table:\n\n\n\n\n\n\nCategoryKnow-howKnow-whatKnow-whereKnow-Right\n\nFocus Era1990s ~ mid-2000slate 2000s ~ mid-2010slate 2010s ~ early 2020smid-2020s ~ (AI era)\nCore QuestionHow do I implement this?What should I use?Where is the answer?Is this answer really correct?\nLocation of KnowledgePersonal experience, internal docsOfficial docs, patterns, best practicesSearch engines, GitHub, Q&AContext, constraints, system understanding\nDeveloper StrengthSkilled hands-on abilityCorrect selection abilityFast searching abilityJudgment, validation, reasoning ability\nLearning MethodRepetition, trial-and-errorCase study, comparative learningOptimized search, reference tracingDeep understanding + cross-validation\nCause of FailureLack of experienceWrong choicesCopy-paste lacking contextAccepting without verification\nRole of AIAlmost noneReference toolPowerful searcherBoth a subject of judgment and a tool\n\n\n\n\n\nSo how does this change the way we think? For example, think about a simple Redis failure problem:\n\nEraDeveloper Reaction\n\nKnow-how“We tuned it this way before and fixed it.”\nKnow-what“This issue is caused by KEYS; use SCAN instead.”\nKnow-where“There’s a solution in the official docs and on GitHub.”\nKnow-Right“For this workload, SCAN is also risky, and the real problem is the data model.”\n\n\n\n\n\nWhen ChatGPT first came out, things weren’t this extreme, but the pace of change keeps increasing and the importance of verification is growing. Now the question arises: So how should people prepare for this? Does it necessarily mean that humans must verify everything?\nSome people say that, just as we don’t verify every line of machine code the compiler generates and managers don’t review every result a team member produces, we should accept a certain level of mistakes. That perspective isn’t wrong. But still, a single mistake can cause a huge problem — and while humans can sometimes understand their own mistakes, AI mistakes might be unknowable. (There is no definitive answer here — in a few years this discussion itself might be meaningless.)\nOne technique to improve LLM reliability is test-time scaling: using a smaller model to evaluate what the larger model generates and filtering out responses below a reliability threshold — effectively enhancing performance by throwing out low-confidence results. This resembles using other models (or smaller ones) to verify output, and it shows why evaluating trustworthiness of results is becoming more crucial for people who use this information.\nSo my question becomes: How should “people” be educated in this era? …I’ll leave that discussion for another time (maybe — I’m still thinking about it).",
        "dc:creator": "charsyam",
        "comments": "https://charsyam.wordpress.com/2026/01/11/the-era-of-know-right-2/#respond",
        "content": "The paradigm of knowledge keeps changing. In the beginning, it was the era of know-how. An individual’s experience and mastery were the greatest assets, passed down only within a person’s head or a limited part of an organization. The central question in that era was naturally “How do we implement this?” Anyone who could answer [&#8230;]",
        "contentSnippet": "The paradigm of knowledge keeps changing. In the beginning, it was the era of know-how. An individual’s experience and mastery were the greatest assets, passed down only within a person’s head or a limited part of an organization. The central question in that era was naturally “How do we implement this?” Anyone who could answer […]",
        "guid": "http://charsyam.wordpress.com/?p=3626",
        "categories": [
          "Uncategorized"
        ],
        "isoDate": "2026-01-11T06:20:33.000Z"
      },
      {
        "creator": "charsyam",
        "title": "[책 리뷰] AI 자율학습 밑바닥부터 배우는 AI 에이전트",
        "link": "https://charsyam.wordpress.com/2026/01/11/%ec%b1%85-%eb%a6%ac%eb%b7%b0-ai-%ec%9e%90%ec%9c%a8%ed%95%99%ec%8a%b5-%eb%b0%91%eb%b0%94%eb%8b%a5%eb%b6%80%ed%84%b0-%eb%b0%b0%ec%9a%b0%eb%8a%94-ai-%ec%97%90%ec%9d%b4%ec%a0%84%ed%8a%b8/",
        "pubDate": "Sun, 11 Jan 2026 03:08:12 +0000",
        "content:encodedSnippet": "“해당 도서는 길벗출판사의 협찬으로 출판사에서 도서를 제공받았습니다.”\n\n\n\n\nAI 관련 일을 하게 되었지만, 사실 AI 자체는 잘 모르는 상태이다보니, AI에 학습이 필요한\n상황이었는데, AI를 이용하는 기본적인 방법은 OpenAI와 같은 LLM api를 호출하는 것이지만,\n현재는 좀 더 복잡한 작업을 위해서 AI 에이전트를 이용하는 것이 일반적이다. 그러기 위해서\n아예 쉽게 할 수 있는 n8n 부터, 좀 더 다양하게 구성이 가능하고(코딩도 필요한) LangChain이나\nLangGraph 를 이용하기도 합니다.\n그런데 이런 내용을 처음부터 보면, 좀 더 어렵습니다. 좀 더 쉽게 내용을 이해하는 방법이 없을까?\n하고 고민을 하게 되는데, 이 책은 이해를 목적으로 이런 프레임워크를 사용하지 않고 AI 에이전트\n를 만드는 방법에 대해서 설명하고 있습니다.(원리를 설명한다가 더 좋을듯 하네요.)\n그래서 따라하기 형식이기도 하고 내용 자체는 처음에 이해하기 쉽게 되어 있습니다. 프롬프트 체이닝\n부터 시작해서 LLM 라우팅에 대한 설명, 각각의 작업을 조율해서 결과를 내는 오케스트레이션-워커 개념\n그리고 최종적인 평가까지 전체를 가볍게 다루고 있습니다.(그래서 실제로 LangChain이나 LangGraph에\n대해서 더 알고 싶으신 분은 해당 기술을 다루는 책을 보시는게 좋습니다.)\n다만 이런 개념을 이해하고 프레임워크를 사용하면, 어떤 개념이 들어가는지, 그게 안된다면 어떻게\n적용할 수 있는지에 대해서 더 쉽게 적용할 수 있게 됩니다. AI 에이전트가 복잡하다고 생각하시면\n가볍게 기본적인 컨셉을 이해하고 더 복잡한 내용에 도전하시기에 좋은 책입니다.",
        "dc:creator": "charsyam",
        "comments": "https://charsyam.wordpress.com/2026/01/11/%ec%b1%85-%eb%a6%ac%eb%b7%b0-ai-%ec%9e%90%ec%9c%a8%ed%95%99%ec%8a%b5-%eb%b0%91%eb%b0%94%eb%8b%a5%eb%b6%80%ed%84%b0-%eb%b0%b0%ec%9a%b0%eb%8a%94-ai-%ec%97%90%ec%9d%b4%ec%a0%84%ed%8a%b8/#respond",
        "content": "&#8220;해당 도서는 길벗출판사의 협찬으로 출판사에서 도서를 제공받았습니다.&#8221; AI 관련 일을 하게 되었지만, 사실 AI 자체는 잘 모르는 상태이다보니, AI에 학습이 필요한상황이었는데, AI를 이용하는 기본적인 방법은 OpenAI와 같은 LLM api를 호출하는 것이지만,현재는 좀 더 복잡한 작업을 위해서 AI 에이전트를 이용하는 것이 일반적이다. 그러기 위해서아예 쉽게 할 수 있는 n8n 부터, 좀 더 다양하게 구성이 가능하고(코딩도 필요한) [&#8230;]",
        "contentSnippet": "“해당 도서는 길벗출판사의 협찬으로 출판사에서 도서를 제공받았습니다.” AI 관련 일을 하게 되었지만, 사실 AI 자체는 잘 모르는 상태이다보니, AI에 학습이 필요한상황이었는데, AI를 이용하는 기본적인 방법은 OpenAI와 같은 LLM api를 호출하는 것이지만,현재는 좀 더 복잡한 작업을 위해서 AI 에이전트를 이용하는 것이 일반적이다. 그러기 위해서아예 쉽게 할 수 있는 n8n 부터, 좀 더 다양하게 구성이 가능하고(코딩도 필요한) […]",
        "guid": "http://charsyam.wordpress.com/?p=3618",
        "categories": [
          "Uncategorized"
        ],
        "isoDate": "2026-01-11T03:08:12.000Z"
      },
      {
        "creator": "charsyam",
        "title": "The era of “Know-Right”",
        "link": "https://charsyam.wordpress.com/2026/01/10/the-era-of-know-right/",
        "pubDate": "Sat, 10 Jan 2026 14:43:37 +0000",
        "content:encodedSnippet": "지식의 패러다임은 계속 바뀌고 있다. 초기에는 know-how 의 시대였다. 개인의 경험과 숙련이 가장 큰 자산이고, 이런 것들이 사람의 머릿속이나 일부 조직내에서만 전수되는 그런 시대였다. 그래서 know-how의 시대의 핵심 질문은 “어떻게” 였다. 당연하지만 이 어떻게를 잘 하는 사람이 인재로써 중요한 가치를 가지고, 일의 중점에 있게 되었다.\n 그런 시기가 점점 know-what, know-where의 시대를 거쳐오게 되지만, 예전보다 정보를 찾기가 쉬워지고, 많은 퀄리티 있는 정보가 생성되면서, 개발자들은 구글, 스택오버플로우드등을 검색해서 많은 일을 처리할 수 있었다. 그래도 그 안의 핵심은 know-how 였다. 정보들의 퀄리티가 높았기 때문에, 찾기만 하면 어느정도의 신뢰도가 보장이 되던 시기.\n 그런데 그 시기가 이제 “Know-Right” 의 시대가 되고 있다.(Know-Right 라는 단어가 있는지, 맞는지는 잘 모르겠지만, 일단 나는 내 마음대로 생각해서 쓰고 있는…) 정보는 쉽게 구성이 되지만(찾는다고 하지 않고 구성된다라는 용어를 쓰는게 맞다고 생각한다.) 그 정보의 신뢰도를 검증해야 하는 시기이다.(이 글을 쓰는데도 AI의 도움을 얻고 있으니, 신뢰도를 검증하셔야 한다.)\n\n\n\n\n\n 일단 간단히 표로 정리하면 다음과 같다.\n\n구분Know-howKnow-whatKnow-whereKnow-right\n\n중심 시기1990s ~ 2000s 중반2000s 후반 ~ 2010s 중반2010s 후반 ~ 2020s 초2020s 중반 ~ (AI 시대)\n핵심 질문어떻게 구현하지?무엇을 쓰는 게 맞지?답이 어디에 있지?이 답이 정말 맞나?\n지식의 위치개인 경험, 내부 문서공식 문서, 패턴, 베스트 프랙티스검색 엔진, GitHub, Q&A맥락·제약·시스템 이해\n개발자 경쟁력숙련된 손기술올바른 선택 능력빠른 탐색 능력판단·검증·추론 능력\n학습 방식반복 경험, 시행착오사례 학습, 비교 학습검색 최적화, 레퍼런스 추적깊이 있는 이해 + 교차 검증\n실패의 원인경험 부족잘못된 선택맥락 없는 복붙검증 없는 수용\nAI의 역할거의 없음참고 도구강력한 탐색기판단 대상이자 도구\n\n\n\n\n\n 그렇다면 사고 방식은 어떻게 바뀌고 있을까? 예를 들어 간단히 Redis의 장애문제를 생각해보자.\n\n시대개발자의 반응\n\nKnow-how“예전에 이렇게 튜닝해서 해결했어”\nKnow-what“이 문제는 KEYS가 원인이고 SCAN을 써야 해”\nKnow-where“공식 문서랑 이 GitHub 이슈에 해결책 있어”\nKnow-right“이 워크로드에선 SCAN도 위험하고, 데이터 모델이 문제야”\n\n\n\n\n\n ChatGPT가 나온 초기만 해도 이 정도는 아니었다고 생각하지만, 그 변경 속도는 점점 더 바뀌면서 검증의 중요성이 점점 더 커지고 있다. 그런데 여기서 드는 고민은 이것이다. 그렇다면 사람은 어떻게 이를 대비해야 하는가? 꼭 사람이 검증할 필요는 있을까?\n 일부에서 어떤 분들은, 어차피 우리가 컴파일러가 만드는 기계어를 검증하지 않는 것처럼, 팀에서 매니저가, 팀원의 모든 결과를 직접 다 검토하지 않는 것처럼, 어느 정도의 실수는 용납할 수 있어야 한다라는 의견도 있다. 물론 이것도 틀린 의견이 아니다. 그렇지만 여전히 실수 하나가 굉장히 큰 문제를 만들 수 있고, 사람의 실수는 그 문제를 어느정도 파악하고 있지만, AI의 문제는 그럴 수 없지 않냐라는 의견도 있다.(여기서 답은 없다. 몇년만 지나도 이런 논쟁 조차도 의미가 없을 수 가 있기 때문에…)\n LLM의 성능을 높이는 기법주엥 test-time scaling 이라는 방법이 있다. LLM이 생성하는 내용을 더 성능이 작은 SLM으로 평가해서 어느 정도 점수 이하인 것은 버림으로써 도리어 성능을 높일 수 있다는 방법인데, 어느정도 가드레일을 주거나, 나온 결과의 신뢰성을 평가하기 위해서 다른 LLM(혹은 SLM)을 쓰는 것과 유사한데… 신뢰도가 낮은 결과는 버림으로써, 신뢰를 확보한다는 것인데… 이런 정보를 써야 하는 입장에서는 이런 부분을 더더욱 중요하게 봐야 하는 시대가 온 것다.\n 그래서 생기는 나의 고민은 그렇다면 이런 시기에 “사람”의 교육은 어떻게 되어야 하냐인데… 이 이야기는 다음 기회에… 해보기로 하자.(안할수도 있다. 현재 고민만 하고 있어서…)",
        "dc:creator": "charsyam",
        "comments": "https://charsyam.wordpress.com/2026/01/10/the-era-of-know-right/#respond",
        "content": "지식의 패러다임은 계속 바뀌고 있다. 초기에는 know-how 의 시대였다. 개인의 경험과 숙련이 가장 큰 자산이고, 이런 것들이 사람의 머릿속이나 일부 조직내에서만 전수되는 그런 시대였다. 그래서 know-how의 시대의 핵심 질문은 &#8220;어떻게&#8221; 였다. 당연하지만 이 어떻게를 잘 하는 사람이 인재로써 중요한 가치를 가지고, 일의 중점에 있게 되었다. 그런 시기가 점점 know-what, know-where의 시대를 거쳐오게 되지만, 예전보다 정보를 [&#8230;]",
        "contentSnippet": "지식의 패러다임은 계속 바뀌고 있다. 초기에는 know-how 의 시대였다. 개인의 경험과 숙련이 가장 큰 자산이고, 이런 것들이 사람의 머릿속이나 일부 조직내에서만 전수되는 그런 시대였다. 그래서 know-how의 시대의 핵심 질문은 “어떻게” 였다. 당연하지만 이 어떻게를 잘 하는 사람이 인재로써 중요한 가치를 가지고, 일의 중점에 있게 되었다. 그런 시기가 점점 know-what, know-where의 시대를 거쳐오게 되지만, 예전보다 정보를 […]",
        "guid": "http://charsyam.wordpress.com/?p=3604",
        "categories": [
          "Uncategorized"
        ],
        "isoDate": "2026-01-10T14:43:37.000Z"
      }
    ]
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "Splunk의 xml 처리",
        "link": "https://kangmyounghun.blogspot.com/2026/01/splunk-xml.html",
        "pubDate": "2026-01-11T05:18:00.001Z",
        "author": "강명훈",
        "content": "<div>xml 포맷을 갖는 <a href=\"https://kangmyounghun.blogspot.com/2021/01/sysmon-dns.html\" target=\"_blank\">sysmon 이벤트</a> 로그. 가장 중요한 EventData 계층은 동일한 Data 자식 계층이 반복되는 중첩 구조를 가지고 있다.&nbsp;</div><div><div><pre><code>&lt;Event&gt;\n\t&lt;System&gt;\n\t\t&lt;Provider Name=\"Linux-Sysmon\" Guid=\"{ff032593-a8d3-4f13-b0d6-01fc615a0f97}\"/&gt;\n\t\t&lt;EventID&gt;5&lt;/EventID&gt;\n\t\t&lt;Version&gt;3&lt;/Version&gt;\n\t\t&lt;Level&gt;4&lt;/Level&gt;\n\t\t&lt;Task&gt;5&lt;/Task&gt;\n\t\t&lt;Opcode&gt;0&lt;/Opcode&gt;\n\t\t&lt;Keywords&gt;0x8000000000000000&lt;/Keywords&gt;\n\t\t&lt;TimeCreated SystemTime=\"2026-01-04T18:12:34.451516000Z\"/&gt;\n<span><a name='more'></a></span>\t\t&lt;EventRecordID&gt;8660&lt;/EventRecordID&gt;\n\t\t&lt;Correlation/&gt;\n\t\t&lt;Execution ProcessID=\"947\" ThreadID=\"947\"/&gt;\n\t\t&lt;Channel&gt;Linux-Sysmon/Operational&lt;/Channel&gt;\n\t\t&lt;Computer&gt;rocky&lt;/Computer&gt;\n\t\t&lt;Security UserId=\"0\"/&gt;\n\t&lt;/System&gt;\n\t&lt;EventData&gt;\n\t\t&lt;Data Name=\"RuleName\"&gt;-&lt;/Data&gt;\n\t\t&lt;Data Name=\"UtcTime\"&gt;2026-01-04 18:12:34.454&lt;/Data&gt;\n\t\t&lt;Data Name=\"ProcessGuid\"&gt;{00000000-0000-0000-0000-000000000000}&lt;/Data&gt;\n\t\t&lt;Data Name=\"ProcessId\"&gt;2481&lt;/Data&gt;\n\t\t&lt;Data Name=\"Image\"&gt;&amp;lt;unknown process&amp;gt;&lt;/Data&gt;\n\t\t&lt;Data Name=\"User\"&gt;root&lt;/Data&gt;\n\t&lt;/EventData&gt;\n&lt;/Event&gt;</code></pre></div></div>\n<div><br /></div><div>다음은&nbsp;<a href=\"https://help.splunk.com/en/splunk-enterprise/search/spl-search-reference/9.4/search-commands/xmlkv\" target=\"_blank\">xmlkv</a>&nbsp;명령어를 이용한 테이블 구조 변환 결과. 여러 개의 Data 계층이 하나의 필드로만 추출된다. 마지막 User 속성이 이전 속성을 덮어쓴 결과.</div><div><br /></div>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgHCo0bubFZvDGfWdAjslIwt7hceBbChSeijUNkEasuhRkBw-TG1ZMyTqtPhyh3_0MkIre4Leus3kwJEdTsCYPeIwYjsekVtWiMki6UUcnvcbPtka_WXi-JRfTeXJr6q54Wxui09pfhgAKsj9FcBBR2v0KhaAfCaBVbpTKUjs2aLccwuTcY274Q_apdm00H/s804/xmlkv.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"804\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgHCo0bubFZvDGfWdAjslIwt7hceBbChSeijUNkEasuhRkBw-TG1ZMyTqtPhyh3_0MkIre4Leus3kwJEdTsCYPeIwYjsekVtWiMki6UUcnvcbPtka_WXi-JRfTeXJr6q54Wxui09pfhgAKsj9FcBBR2v0KhaAfCaBVbpTKUjs2aLccwuTcY274Q_apdm00H/s16000/xmlkv.png\" /></a></div>\n<div><br /></div><div>이때 xml 계층 경로를 지정할 수 있는 <a href=\"https://help.splunk.com/en/splunk-enterprise/search/spl-search-reference/9.4/search-commands/xpath\" target=\"_blank\">xpath</a>를 사용하면 원하는 테이블 구조를 만들 수 있다.</div><div><br /></div>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhj0ZKIviPCwWpH4kWt571VmodA_akarsxsevp0sJWdPBg4a7z4Ynia_ril-yVHU1h4wTylCURVHQVFq9YxG45THkQgAsCnLACAzTYV2i9iBUsO8Bpa_Efx4KgNfhrWIZ-L6ngS7598fCbrpBfHBxfwgFx4KcrviYgHT7J1UEUAOM2B4j4OpEhsboizCWk_/s1024/xpath.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"625\" data-original-width=\"1024\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhj0ZKIviPCwWpH4kWt571VmodA_akarsxsevp0sJWdPBg4a7z4Ynia_ril-yVHU1h4wTylCURVHQVFq9YxG45THkQgAsCnLACAzTYV2i9iBUsO8Bpa_Efx4KgNfhrWIZ-L6ngS7598fCbrpBfHBxfwgFx4KcrviYgHT7J1UEUAOM2B4j4OpEhsboizCWk_/s16000/xpath.png\" /></a></div>\n<br /><div>json과 xml을 모두 지원하는 <a href=\"https://help.splunk.com/en/splunk-enterprise/search/spl-search-reference/9.4/search-commands/spath\" target=\"_blank\">spath</a>&nbsp;명령어를 사용할 수도 있는데,</div><div><br /></div>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhYvFikJ1Gzbam-j16sfikZTOfE-ygniYZb3qItSMq7ACGUtgUmEJb3vaRDBMsjJ1GmgzrLyBwzCRoLKCldaGM03Gd3C2m6eCg3DqGJnm_QiEA-SqlNSFFMYoHQb54SMh_W886ZRDst5OE3kZL-F4QcE5AhVRtIDnk41Hf1BxmU2wzlxNUleEobJs18MwjN/s1024/spath.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1024\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhYvFikJ1Gzbam-j16sfikZTOfE-ygniYZb3qItSMq7ACGUtgUmEJb3vaRDBMsjJ1GmgzrLyBwzCRoLKCldaGM03Gd3C2m6eCg3DqGJnm_QiEA-SqlNSFFMYoHQb54SMh_W886ZRDst5OE3kZL-F4QcE5AhVRtIDnk41Hf1BxmU2wzlxNUleEobJs18MwjN/s16000/spath.png\" /></a></div>\n<div><br /></div><div>대신 데이터가 xml 태그로만 이루어져 있어야 함.</div><br />\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgN4jFJs_gRk2zqcpxjcLrZXlZuWm9e6mQKCWbx7J-WuG3N1Qx9885DhbygX2MUgSVDgmo1S3grSat6xZ9O4NeZ0K3T-Zf7_xA6R9bf3U6NLdCgOtBkcBQt-YsjcKrZfjtULvw2SS8s3OqPJGNmHBKfGyWtFXO1ywHvFfQr7YNKsbNXBFUxVSxp8QF_u56Q/s737/spath2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"737\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgN4jFJs_gRk2zqcpxjcLrZXlZuWm9e6mQKCWbx7J-WuG3N1Qx9885DhbygX2MUgSVDgmo1S3grSat6xZ9O4NeZ0K3T-Zf7_xA6R9bf3U6NLdCgOtBkcBQt-YsjcKrZfjtULvw2SS8s3OqPJGNmHBKfGyWtFXO1ywHvFfQr7YNKsbNXBFUxVSxp8QF_u56Q/s16000/spath2.png\" /></a></div>\n<div><br /></div><div>경로 지정 구문도 좀 더 단순한 편.</div><br />\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj7X2EDjp2na2WXKHrSz8Cmdg02W4sti-abUhBOgCLLg0wbPfWHm2hw2dAscwmJCpu3L2PnPOTp8d9JmJfN2ESnN9WczlGqURYJCNraL5TUIfil_hKpll4orKrHe54HBMnU9R8QCpTz-c5csJMEQ8dMmgDtrjKsnb5PmzJ11OBon0BYp4YmnqFCfyITlAGG/s1134/spath3.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1134\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj7X2EDjp2na2WXKHrSz8Cmdg02W4sti-abUhBOgCLLg0wbPfWHm2hw2dAscwmJCpu3L2PnPOTp8d9JmJfN2ESnN9WczlGqURYJCNraL5TUIfil_hKpll4orKrHe54HBMnU9R8QCpTz-c5csJMEQ8dMmgDtrjKsnb5PmzJ11OBon0BYp4YmnqFCfyITlAGG/s16000/spath3.png\" /></a></div>\n<div><br /></div><div><a href=\"https://help.splunk.com/en/splunk-enterprise/search/spl-search-reference/9.4/evaluation-functions/text-functions#ccdbf2f5_ab78_49aa_9c59_da4e52977128--en__spath.28.26lt.3Bvalue.26gt.3B.2C.26lt.3Bpath.26gt.3B.29\" target=\"_blank\">eval 명령어 함수</a>로도 사용 가능.</div><br />\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj2X8vqBoUd2sMdzBk7QjemrbJLkxvNlxb73M728T5L4N7Ucz8Ei1G5EjdLSOK2nSnc3i7sfMVeJWDSDjOCdiqFLq6h1YjP3munZXpZFeko2KGnacsWAGreocU9xvbJXpADjCu3zgcCzMBUBH63Eq5S7D3OPbC5xC0HV4BMX28MkujWFV8fapqVib28TiH-/s1134/spath4.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1134\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj2X8vqBoUd2sMdzBk7QjemrbJLkxvNlxb73M728T5L4N7Ucz8Ei1G5EjdLSOK2nSnc3i7sfMVeJWDSDjOCdiqFLq6h1YjP3munZXpZFeko2KGnacsWAGreocU9xvbJXpADjCu3zgcCzMBUBH63Eq5S7D3OPbC5xC0HV4BMX28MkujWFV8fapqVib28TiH-/s16000/spath4.png\" /></a></div>\n<br /><div><div><b>관련 글</b></div><div><ul><li><a href=\"https://kangmyounghun.blogspot.com/2018/02/xpath.html\" target=\"\">xpath를 이용한 이벤트 로그 필터링</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2026/01/logstash-xml.html\">Logstash 필터 xml</a></li></ul></div></div>",
        "contentSnippet": "xml 포맷을 갖는 sysmon 이벤트 로그. 가장 중요한 EventData 계층은 동일한 Data 자식 계층이 반복되는 중첩 구조를 가지고 있다. \n\n<Event>\n\t<System>\n\t\t<Provider Name=\"Linux-Sysmon\" Guid=\"{ff032593-a8d3-4f13-b0d6-01fc615a0f97}\"/>\n\t\t<EventID>5</EventID>\n\t\t<Version>3</Version>\n\t\t<Level>4</Level>\n\t\t<Task>5</Task>\n\t\t<Opcode>0</Opcode>\n\t\t<Keywords>0x8000000000000000</Keywords>\n\t\t<TimeCreated SystemTime=\"2026-01-04T18:12:34.451516000Z\"/>\n\t\t<EventRecordID>8660</EventRecordID>\n\t\t<Correlation/>\n\t\t<Execution ProcessID=\"947\" ThreadID=\"947\"/>\n\t\t<Channel>Linux-Sysmon/Operational</Channel>\n\t\t<Computer>rocky</Computer>\n\t\t<Security UserId=\"0\"/>\n\t</System>\n\t<EventData>\n\t\t<Data Name=\"RuleName\">-</Data>\n\t\t<Data Name=\"UtcTime\">2026-01-04 18:12:34.454</Data>\n\t\t<Data Name=\"ProcessGuid\">{00000000-0000-0000-0000-000000000000}</Data>\n\t\t<Data Name=\"ProcessId\">2481</Data>\n\t\t<Data Name=\"Image\">&lt;unknown process&gt;</Data>\n\t\t<Data Name=\"User\">root</Data>\n\t</EventData>\n</Event>\n\n\n다음은 xmlkv 명령어를 이용한 테이블 구조 변환 결과. 여러 개의 Data 계층이 하나의 필드로만 추출된다. 마지막 User 속성이 이전 속성을 덮어쓴 결과.\n\n\n\n\n이때 xml 계층 경로를 지정할 수 있는 xpath를 사용하면 원하는 테이블 구조를 만들 수 있다.\n\n\n\njson과 xml을 모두 지원하는 spath 명령어를 사용할 수도 있는데,\n\n\n\n\n대신 데이터가 xml 태그로만 이루어져 있어야 함.\n\n\n\n경로 지정 구문도 좀 더 단순한 편.\n\n\n\neval 명령어 함수로도 사용 가능.\n\n\n\n관련 글\n\nxpath를 이용한 이벤트 로그 필터링\nLogstash 필터 xml",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-7634218921962122888",
        "isoDate": "2026-01-11T05:18:00.001Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": [
      {
        "creator": "고명환",
        "title": "도메인 AI란? 2026년 정부 R&amp;D 지원 확대 흐름 - 스타트업(창업)",
        "link": "https://brunch.co.kr/@@LOc/324",
        "pubDate": "Thu, 15 Jan 2026 04:33:26 GMT",
        "author": "고명환",
        "content": "1. 도메인(Domain AI)란 무엇인가   도메인 AI는 '모든 걸 조금씩 아는 범용 AI'가 아니라, 특정 산업/업무 영역(제조, 의료, 금융, 법무, 물류, 건설, 공동 등)의 데이터, 용어, 규정, 업무 흐름을 깊게 학습/연결해 '현장에서 바로 성과(정확도, 시간절감, 리스크 감소)'를 내는 특화 AI를 말합니다. 예를 들어, 제조 현장의 설비 데<img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FlXHMOAqJ0I1uqeYMPFJviGrpUZA.png\" width=\"500\" />",
        "contentSnippet": "1. 도메인(Domain AI)란 무엇인가   도메인 AI는 '모든 걸 조금씩 아는 범용 AI'가 아니라, 특정 산업/업무 영역(제조, 의료, 금융, 법무, 물류, 건설, 공동 등)의 데이터, 용어, 규정, 업무 흐름을 깊게 학습/연결해 '현장에서 바로 성과(정확도, 시간절감, 리스크 감소)'를 내는 특화 AI를 말합니다. 예를 들어, 제조 현장의 설비 데",
        "guid": "https://brunch.co.kr/@@LOc/324",
        "isoDate": "2026-01-15T04:33:26.000Z"
      },
      {
        "creator": "고명환",
        "title": "초기 스타트업 중진공 정책자금, 브로커 없이 받는 법 - 스타트업(창업)",
        "link": "https://brunch.co.kr/@@LOc/323",
        "pubDate": "Wed, 14 Jan 2026 06:06:04 GMT",
        "author": "고명환",
        "content": "1. 2026 정책자금 브로커 피해 예방법   정책자금은 원칙적으로 중진공 온라인(디지털지점)에서 기업이 직접 신청할 수 있습니다. 그런데도 매년 '정책자금 확정' '심사역 연결' 등을 내세운 브로커 피해가 반복됩니다. 이번 글에서는 브로커를 10초 만에 판별하는 방법과 사장님이 직접 신청으로 안정하게 승인 가능성을 올리는 방법을 체크리스트로 정리합니다. <img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FnxxNbFl2gHmtVEBJeTdijMdBLpo.jpg\" width=\"500\" />",
        "contentSnippet": "1. 2026 정책자금 브로커 피해 예방법   정책자금은 원칙적으로 중진공 온라인(디지털지점)에서 기업이 직접 신청할 수 있습니다. 그런데도 매년 '정책자금 확정' '심사역 연결' 등을 내세운 브로커 피해가 반복됩니다. 이번 글에서는 브로커를 10초 만에 판별하는 방법과 사장님이 직접 신청으로 안정하게 승인 가능성을 올리는 방법을 체크리스트로 정리합니다.",
        "guid": "https://brunch.co.kr/@@LOc/323",
        "isoDate": "2026-01-14T06:06:04.000Z"
      }
    ]
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "'생각의 수준'을 높이는 8가지 브레인스토밍 프롬프트",
        "link": "https://muzbox.tistory.com/483700",
        "pubDate": "Fri, 16 Jan 2026 08:34:44 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "https://muzbox.tistory.com/483700#entry483700comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #212121;\">\n<div style=\"background-color: #e8f5e9; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">\n<p style=\"margin-bottom: 0;\" data-ke-size=\"size16\">여러분은 브레인스토밍을 할 때 막막함을 느끼시나요? 방대한 아이디어가 필요한데 어디서부터 시작해야 할지 모르겠다고요? 2026년, 이제 ChatGPT는 단순한 정보 제공자를 넘어 여러분의 <b>'생각의 수준'을 한 차원 높여줄 유능한 브레인스토밍 파트너</b>가 될 수 있습니다. 오늘은 제가 직접 사용하며 효과를 본, 창의적인 사고를 돕는 8가지 ChatGPT 프롬프트를 공개합니다. 평범한 아이디어를 벗어나 실용적이고 깊이 있는 통찰력을 얻고 싶은 분들을 위해 준비했어요.</p>\n</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/5dW8u/dJMcac9DEe0/4sKie3rjLmr5A4JovC3jj1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/5dW8u/dJMcac9DEe0/4sKie3rjLmr5A4JovC3jj1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/5dW8u/dJMcac9DEe0/4sKie3rjLmr5A4JovC3jj1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F5dW8u%2FdJMcac9DEe0%2F4sKie3rjLmr5A4JovC3jj1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"노트북 화면 속 ChatGPT와 함께 아이디어를 발상하고 정리하는 모습. 현대적인 작업 공간에서 자연 친화적인 초록색과 따뜻한 빛이 어우러져 창의적인 분위기를 연출합니다.\" loading=\"lazy\" width=\"500\" height=\"500\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">솔직히 말하면, 우리는 ChatGPT를 너무 쉽게 생각하는 경향이 있는 것 같아요. 그냥 질문을 던지면 답을 뱉어내는 <b>'아이디어 자판기'</b>처럼 말이죠. 하지만 제가 직접 겪어보니, 제대로 활용하면 정말 놀라운 <b>'브레인스토밍 파트너'</b>가 될 수 있다는 걸 깨달았습니다. 우리가 머리를 쥐어짜며 생각의 흐름을 만들 때, ChatGPT는 그 아이디어의 <b>볼륨과 구조를 잡아주는 역할</b>을 톡톡히 해내죠. 제가 오랫동안 마케팅과 웹 개발 분야에서 일하며 숱하게 브레인스토밍을 해왔는데, 최근 챗GPT와 함께하면서 아이디어의 명확성과 범위가 확연히 넓어지는 것을 경험하고 있습니다. 수많은 선배들의 지혜와 레딧 같은 커뮤니티에서 얻은 영감을 바탕으로, 퍼져 있던 생각들을 <b>실행 가능한 아이디어</b>로 다듬는 데 최적화된 프롬프트 8가지를 소개할게요. 저의 뉴스레터를 장기적으로 흥미롭게 유지하는 방법이라는 주제로 같이 고민해보면 더 와닿으실 거예요.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>1. 맥락을 이해시키는 것부터 시작하세요: 일반적인 아이디어를 피하는 첫걸음</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">아무리 인공지능이라도 우리 마음을 꿰뚫어 볼 수는 없잖아요? 그래서 저는 항상 브레인스토밍 세션을 시작하기 전에 ChatGPT에게 <b>명확한 지침</b>을 줍니다. 마치 유능한 팀원에게 프로젝트 브리핑을 하듯이요. 이 <b>'핵심 프롬프트'</b>는 전체 대화의 틀을 잡고, 챗GPT가 뻔하거나 피상적인 아이디어를 내놓는 걸 미리 방지해 주는 역할을 해요. 복잡한 콘텐츠 기획이나 개인적인 목표 설정 같은 작업에 특히 유용하더라고요. 처음부터 이렇게 세부적으로 조율해두면 나중에 불필요한 노력을 훨씬 줄일 수 있습니다. 핵심은 <b>맥락, 명확성, 그리고 의도</b>라는 점, 잊지 마세요!</p>\n<div style=\"background-color: #e8f5e9; border-left: 4px solid #2e7d32; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">\n<p style=\"margin-bottom: 5px; color: #212121;\" data-ke-size=\"size16\">  <b>프롬프트 활용 팁:</b></p>\n<ul style=\"list-style-type: disc; margin-left: 20px; padding-left: 0; color: #212121;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>Goal(목표)</b>: 최종적으로 무엇을 얻고 싶은지 명확히 하세요.</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>Context(맥락)</b>: 대상, 제약 조건, 시간, 자원 등 배경 정보를 상세히 설명하세요.</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>Process(과정)</b>: 어떤 방식으로 진행할지 (예: 질문 개수, 프레임워크 제안 등) 구체적으로 알려주세요.</li>\n</ul>\n</div>\n<div style=\"background-color: #f1f8e9; border: 1px solid #a5d6a7; padding: 15px; margin: 20px 0; border-radius: 8px; overflow-x: auto;\">\n<pre class=\"prolog\" style=\"margin: 0; padding: 0; white-space: pre-wrap; word-wrap: break-word;\"><code>당신은 저의 구조화된 브레인스토밍 파트너입니다.\n목표: [주제/문제/결과물 설명]에 대해 브레인스토밍하는 것을 도와주세요.\n맥락: [대상, 제약 조건, 기한, 자원].\n과정: 최대 5개의 명확화 질문을 하나씩 해주세요.\n사용할 수 있는 3-5가지의 다른 브레인스토밍 프레임워크를 제안해주세요 (예: SCAMPER, 마인드맵, 가정, 제약, 첫 번째 원칙).\n제가 하나를 선택하면, 간결하고 번호가 매겨진 목록으로 브레인스토밍을 안내해주세요. 이때 구체성과 실용성을 목표로 합니다.\n궁극적으로, 최고의 아이디어를 3-5가지 테마로 분류하고 구체적인 다음 단계를 제안해주세요.\n간결한 글머리 기호를 사용하고 일반적인 조언은 피해주세요.\n        </code></pre>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>2. 다양한 아이디어로 물꼬를 트세요: 양으로 승부하는 발산적 사고</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">아이디어가 막힐 때 가장 빠르고 확실한 방법은 <b>일단 많은 아이디어를 쏟아내는 것</b>이라고 생각해요. 심지어 좀 터무니없는 아이디어라도 괜찮아요! 초기 단계에서는 아이디어의 질보다는 <b>속도와 범위</b>가 훨씬 중요합니다. 이 프롬프트는 ChatGPT와 우리 뇌의 시동을 거는 역할을 해요. 나중에 걸러내고 우선순위를 정하는 건 그때 가서 해도 늦지 않습니다.</p>\n<div style=\"background-color: #e8f5e9; border-left: 4px solid #2e7d32; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">\n<p style=\"margin-bottom: 5px; color: #212121;\" data-ke-size=\"size16\">  <b>뉴스레터 아이디어 적용 예시:</b></p>\n<ul style=\"list-style-type: disc; margin-left: 20px; padding-left: 0; color: #212121;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px; color: #212121;\">뉴스레터의 메인 콘텐츠를 짧은 숏폼 비디오로 전환 (요즘 대세죠!)</li>\n<li style=\"margin-bottom: 5px; color: #212121;\">구독자들이 직접 참여하는 '익명 고민 상담소' 코너 운영</li>\n<li style=\"margin-bottom: 5px; color: #212121;\">매주 다른 분야의 전문가를 초대해 인터뷰 시리즈 진행</li>\n</ul>\n</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">프롬프트의 마지막 단계가 정말 중요해요. <b>'가장 유망한 아이디어 5가지 표시'</b>가 없다면, 그냥 방치되는 목록으로 끝나버릴 수도 있거든요. 번호가 매겨진 목록은 나중에 특정 아이디어를 참조할 때도 편리하고요. 개인적인 경험으로는, 종종 <b>목록의 뒷부분에 숨어있는 기발한 아이디어</b>들이 많았습니다. ChatGPT와 마인드맵 도구를 함께 사용하면 아이디어 간의 연관성을 찾는 데 큰 도움이 될 거예요.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/cx30E5/dJMcacaMVhh/WZnipYK02qn5cczWiglkPK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cx30E5/dJMcacaMVhh/WZnipYK02qn5cczWiglkPK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cx30E5/dJMcacaMVhh/WZnipYK02qn5cczWiglkPK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fcx30E5%2FdJMcacaMVhh%2FWZnipYK02qn5cczWiglkPK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"카오스에서 질서로 변하는 발산적 사고의 흐름을 보여주는 이미지. 어지러운 아이디어들이 챗GPT의 도움으로 점차 구조화되는 모습을 초록색 계열로 표현했습니다.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<div style=\"background-color: #f1f8e9; border: 1px solid #a5d6a7; padding: 15px; margin: 20px 0; border-radius: 8px; overflow-x: auto;\">\n<pre class=\"prolog\" style=\"margin: 0; padding: 0; white-space: pre-wrap; word-wrap: break-word;\"><code>[주제]에 대해 발산적 브레인스토밍을 해봅시다.\n제약 조건: [예산/시간/산업/대상/기타].\n1단계: 명확한 것부터 파격적인 것까지 20가지의 빠르고 대략적인 아이디어를 번호가 매겨진 목록으로 생성해주세요.\n2단계: 각 아이디어에 대해 왜 효과적일 수 있는지에 대한 짧은 문구를 추가해주세요.\n3단계: 영향력 대비 노력 측면에서 가장 유망해 보이는 5가지 아이디어를 표시해주세요.\n        </code></pre>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>3. 역 브레인스토밍으로 숨겨진 문제점 찾기: 실패를 통해 성공 배우기</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">생각해보니, 성공하는 방법만 고민할 필요는 없더라고요. <b>역 브레인스토밍(Reverse Brainstorming)</b>은 문제를 뒤집어서 '어떻게 하면 실패할 수 있을까?'를 묻는 기법입니다. 마치 일이 터지기 전에 미리 사후 검토(Pre-mortem)를 하는 것과 비슷하죠. 저는 이 프롬프트를 통해 어떤 아이디어가 <b>'괜찮긴 한데 뭔가 부족하다'</b>고 느껴질 때 그 이유를 파악하는 데 활용합니다.</p>\n<div style=\"background-color: #fffde7; border-left: 4px solid #fbc02d; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">\n<p style=\"margin-bottom: 5px; color: #212121;\" data-ke-size=\"size16\">⚠️ <b>뉴스레터 아이디어 적용 예시 (역발상):</b></p>\n<ul style=\"list-style-type: disc; margin-left: 20px; padding-left: 0; color: #212121;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>문제:</b> 뉴스레터 이탈률을 높이는 방법은?</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>해결책:</b> 과도한 광고 삽입 (뒤집으면: 광고를 최소화하고 콘텐츠 집중)</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>해결책:</b> 매주 비슷한 내용만 반복 (뒤집으면: 다양한 형식과 주제로 신선함 유지)</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>해결책:</b> 발행 주기를 불규칙하게 (뒤집으면: 일관된 발행 주기 유지)</li>\n</ul>\n</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 프롬프트는 약한 아이디어와 흔한 실수를 빠르게 파악하게 해줘요. 만약 아이디어가 너무 일반적이라 실패한다면, <b>더 틈새시장을 노리는 것</b>이 해결책이 될 수 있고, 너무 복잡해서 실패한다면 <b>간단하게 만드는 것</b>이 답이 될 수 있죠. 정말 유용한 전략입니다!</p>\n<div style=\"background-color: #f1f8e9; border: 1px solid #a5d6a7; padding: 15px; margin: 20px 0; border-radius: 8px; overflow-x: auto;\">\n<pre class=\"prolog\" style=\"margin: 0; padding: 0; white-space: pre-wrap; word-wrap: break-word;\"><code>[주제]에 대해 역 브레인스토밍을 사용하세요.\n이 문제를 악화시킬 수 있는 15가지 방법을 나열하세요.\n각각의 \"악화\" 아이디어를 건설적인 아이디어 또는 보호 장치로 전환하세요.\n전환된 목록을 구체적이고 테스트 가능한 행동 또는 개념으로 제시하세요.\n        </code></pre>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>4. 무작위 단어로 상상력 점프하기: 기발한 연결고리 만들기</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">모든 아이디어가 비슷하게 들리기 시작할 때, 저는 가끔 <b>'무작위성'</b>의 도움을 받아요. 예전에는 사전을 펼치거나 신문을 보면서 뜬금없는 단어에서 영감을 얻기도 했죠. 이 프롬프트는 전혀 관련 없어 보이는 입력값들을 한데 모아 <b>새로운 연결고리</b>를 찾도록 강제합니다. 아, 그런데 이거 뇌세포에 정말 무리가 갈 때도 있어요... 그래서 챗GPT가 이렇게 도움이 될 줄은 몰랐네요!</p>\n<div style=\"background-color: #e8f5e9; border-left: 4px solid #2e7d32; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">\n<p style=\"margin-bottom: 5px; color: #212121;\" data-ke-size=\"size16\">  <b>뉴스레터 아이디어 적용 예시 (무작위 단어: '나무'):</b></p>\n<ul style=\"list-style-type: disc; margin-left: 20px; padding-left: 0; color: #212121;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>은유:</b> 나무의 나이테처럼 구독자들의 성장 과정을 담는 콘텐츠 시리즈 기획</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>제약:</b> '나무'라는 단어의 의미를 벗어나지 않게 친환경, 지속 가능성 테마의 콘텐츠만 다루기</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>관점:</b> 뉴스레터를 '지식의 숲'으로 비유하여 구독자들이 각자 나무를 심고 가꾸는 커뮤니티 조성</li>\n</ul>\n</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">사실 무작위 단어 그 자체는 중요하지 않아요. 중요한 건 그 단어들을 <b>은유, 제약, 또는 평소에는 고려하지 않았을 관점</b>으로 번역하는 과정에서 가치가 생긴다는 점입니다. 정말 신기하죠?!</p>\n<div style=\"background-color: #f1f8e9; border: 1px solid #a5d6a7; padding: 15px; margin: 20px 0; border-radius: 8px; overflow-x: auto;\">\n<pre class=\"angelscript\" style=\"margin: 0; padding: 0; white-space: pre-wrap; word-wrap: break-word;\"><code>[주제]에 대한 창의적이고 명확하지 않은 아이디어를 원합니다.\n1단계: 무작위의 관련 없는 트리거 단어 5개를 생성하세요.\n2단계: 각 단어에 대해 아이디어를 영감을 주거나 수정할 수 있는 세 가지 방법을 보여주세요.\n3단계: 도출된 가장 흥미로운 방향 5가지를 요약하세요.\n        </code></pre>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>5. SCAMPER 프레임워크로 체계적인 사고 확장하기</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">에드워드 드 보노(Edward de Bono)가 측면 사고(Lateral Thinking)를 대중화시켰죠. <b>SCAMPER</b>는 측면 사고를 위한 고전적인 창의성 프레임워크인데, AI와 함께 사용하면 정말 눈부시게 빠릅니다! 이 프레임워크는 <b>특정 아이디어를 다양한 각도에서 질문하고 변형</b>하며 새로운 가능성을 탐색하도록 돕습니다.</p>\n<table style=\"width: 100%; border-collapse: collapse; margin: 20px 0; font-size: 15px; border: 1px solid #a5d6a7;\" data-ke-align=\"alignLeft\">\n<thead style=\"background-color: #c8e6c9;\">\n<tr>\n<th style=\"border: 1px solid #a5d6a7; padding: 10px; text-align: left; color: #212121;\">요소</th>\n<th style=\"border: 1px solid #a5d6a7; padding: 10px; text-align: left; color: #212121;\">의미</th>\n<th style=\"border: 1px solid #a5d6a7; padding: 10px; text-align: left; color: #212121;\">뉴스레터 아이디어 예시</th>\n</tr>\n</thead>\n<tbody>\n<tr style=\"background-color: #f1f8e9;\">\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\"><b>S</b>ubstitute</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">대체하기</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">텍스트 콘텐츠를 짧은 오디오 클립으로 대체</td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\"><b>C</b>ombine</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">결합하기</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">주간 칼럼과 독자 Q&amp;A 코너를 결합하여 '전문가에게 묻다' 시리즈</td>\n</tr>\n<tr style=\"background-color: #f1f8e9;\">\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\"><b>A</b>dapt</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">적응하기</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">타 산업의 성공적인 콘텐츠 전략을 뉴스레터에 적용</td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\"><b>M</b>odify</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">수정/확대/축소</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">메인 칼럼의 길이를 확 줄이고 대신 인포그래픽으로 시각화</td>\n</tr>\n<tr style=\"background-color: #f1f8e9;\">\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\"><b>P</b>ut to other uses</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">다른 용도로 활용</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">뉴스레터 콘텐츠를 활용해 소셜 미디어 카드뉴스 제작</td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\"><b>E</b>liminate</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">제거하기</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">모든 광고 제거, 오직 순수 콘텐츠에만 집중</td>\n</tr>\n<tr style=\"background-color: #f1f8e9;\">\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\"><b>R</b>everse</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">뒤집기/재배열</td>\n<td style=\"border: 1px solid #a5d6a7; padding: 10px; color: #212121;\">결론을 먼저 보여주고 그 이유를 설명하는 콘텐츠 구성</td>\n</tr>\n</tbody>\n</table>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/QKpLU/dJMcafehv24/3JCcjKKTFj298eGcWp1H7k/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/QKpLU/dJMcafehv24/3JCcjKKTFj298eGcWp1H7k/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/QKpLU/dJMcafehv24/3JCcjKKTFj298eGcWp1H7k/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FQKpLU%2FdJMcafehv24%2F3JCcjKKTFj298eGcWp1H7k%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"SCAMPER 프레임워크를 시각적으로 보여주는 인포그래픽. 각 요소(대체, 결합, 적용, 수정, 다른 용도, 제거, 재배열)가 아이콘과 함께 중앙 아이디어를 둘러싸고 있어 체계적인 사고 과정을 나타냅니다.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 프롬프트는 <b>이미 어느 정도 구체화된 아이디어</b>에 적용할 때 빛을 발합니다. 그래서 저는 브레인스토밍 과정의 후반부에 이 프롬프트를 사용하는 편이에요. 특정 기능을 제거하거나 두 가지 요소를 결합하는 것 같은 <b>작은 변화가 아이디어의 명확성이나 유용성을 극적으로 향상</b>시키는 것을 자주 경험할 수 있을 겁니다.</p>\n<div style=\"background-color: #f1f8e9; border: 1px solid #a5d6a7; padding: 15px; margin: 20px 0; border-radius: 8px; overflow-x: auto;\">\n<pre class=\"prolog\" style=\"margin: 0; padding: 0; white-space: pre-wrap; word-wrap: break-word;\"><code>SCAMPER 프레임워크를 사용하여 [제품/프로젝트/주제]에 대해 브레인스토밍하세요.\n각 요소(Substitute, Combine, Adapt, Modify, Put to other uses, Eliminate, Reverse)에 대해:\n일반적인 조언이 아닌 3-5가지 구체적인 아이디어를 생성하세요.\n각 아이디어를 한 문장으로 유지하세요.\n모든 SCAMPER 단계에서 가장 좋은 아이디어 5가지의 짧은 목록으로 마무리하세요.\n        </code></pre>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>6. SWOT 분석으로 아이디어를 현실에 대입하기: 전략적 점검</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">아이디어가 아무리 좋아 보여도 현실성이 없으면 무용지물이잖아요? <b>SWOT 분석</b> 스타일의 프롬프트는 브레인스토밍을 <b>현실 세계로 끌어와</b> 앞으로 발생할 수 있는 <b>상충 관계(Trade-offs)</b>를 미리 보여줍니다. 저는 종종 이 프롬프트를 통해 '보기에는 좋은 아이디어'가 실질적으로 어떤 문제점을 안고 있는지 파악하고 싶을 때 사용하곤 해요.</p>\n<div style=\"background-color: #e8f5e9; border-left: 4px solid #2e7d32; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">\n<p style=\"margin-bottom: 5px; color: #212121;\" data-ke-size=\"size16\">  <b>뉴스레터 아이디어 적용 예시 (SWOT):</b></p>\n<ul style=\"list-style-type: disc; margin-left: 20px; padding-left: 0; color: #212121;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>강점 활용:</b> '전문가 인터뷰' 강점을 살려 해당 분야 최고 권위자를 초빙하는 특별 시리즈 기획</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>약점 보완:</b> '콘텐츠 제작 시간 부족' 약점을 해결하기 위해 구독자 참여형 콘텐츠 비중 확대</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>기회 포착:</b> '트렌드 변화' 기회를 활용해 AI 기술 트렌드를 빠르게 분석하는 섹션 신설</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>위협 방어:</b> '경쟁사 증가' 위협에 대비해 뉴스레터만의 독점적인 커뮤니티 기능 강화</li>\n</ul>\n</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 분석을 통해 얻은 통찰력은 아이디어의 질을 높이고 실행력을 개선하는 데 결정적인 역할을 합니다. 시각적인 다이어그램 도구를 함께 사용하면 아이디어를 한눈에 파악하는 데 더욱 효과적일 거예요. 솔직히 말해서, 이 과정 없이는 뭔가 중요한 걸 놓치고 있는 느낌이 들 때가 많아요.</p>\n<div style=\"background-color: #f1f8e9; border: 1px solid #a5d6a7; padding: 15px; margin: 20px 0; border-radius: 8px; overflow-x: auto;\">\n<pre class=\"angelscript\" style=\"margin: 0; padding: 0; white-space: pre-wrap; word-wrap: break-word;\"><code>[아이디어 또는 프로젝트]에 대해 SWOT 방식의 브레인스토밍 세션을 실행하세요.\n5-7가지 강점, 5-7가지 약점, 5-7가지 기회, 5-7가지 위협을 나열하세요.\n이것들로부터 다음을 나열하세요:\n강점을 두 배로 활용하는 아이디어 3가지\n약점을 고치거나 우회하는 아이디어 3가지\n기회를 포착하는 아이디어 3가지\n위협에 대비하는 아이디어 3가지\n모든 것을 간결한 글머리 기호로 제시하세요.\n        </code></pre>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>7. 역할극으로 다양한 관점 얻기: 미처 몰랐던 니즈 발굴</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">우리는 모두 자기만의 시각에 갇히기 쉬워요. <b>역할극 브레인스토밍(Rolestorming)</b>은 다른 사람의 입장이 되어 생각해보는 기법인데, 제품이나 프로세스의 <b>페인 포인트(Pain Point)</b>를 찾는 데 정말 탁월한 효과를 발휘합니다. 내가 미처 생각하지 못했던 필요나 개선점들을 발견하게 해주거든요.</p>\n<div style=\"background-color: #e8f5e9; border-left: 4px solid #2e7d32; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">\n<p style=\"margin-bottom: 5px; color: #212121;\" data-ke-size=\"size16\">  <b>뉴스레터 아이디어 적용 예시 (페르소나):</b></p>\n<ul style=\"list-style-type: disc; margin-left: 20px; padding-left: 0; color: #212121;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>초보 사용자:</b> '용어가 너무 어려워요. 초보자를 위한 쉬운 설명이나 용어 사전이 필요해요.'</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>파워 사용자:</b> '심화 자료나 다른 전문가와의 네트워킹 기회가 있으면 좋겠어요.'</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>경쟁사:</b> '이 뉴스레터는 특정 주제에 대한 심층 분석이 부족하고, 인터랙티브 요소가 약해.'</li>\n</ul>\n</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">작가로서, 저는 이 프롬프트 덕분에 다양한 독자층의 니즈를 파악하고 콘텐츠를 미세 조정하는 데 큰 도움을 받았습니다. 여러 페르소나에서 공통적으로 발견되는 인사이트는 콘텐츠를 더 넓은 독자층에 맞게 다듬는 데 정말 핵심적이라고 할 수 있죠. 아마 여러분도 이 과정을 통해 예상치 못한 보물을 발견하실 거예요.</p>\n<div style=\"background-color: #f1f8e9; border: 1px solid #a5d6a7; padding: 15px; margin: 20px 0; border-radius: 8px; overflow-x: auto;\">\n<pre class=\"prolog\" style=\"margin: 0; padding: 0; white-space: pre-wrap; word-wrap: break-word;\"><code>[주제]에 대해 \"역할 브레인스토밍\"을 할 것입니다.\n다음 관점에서 생각하세요:\n&ndash; 초보자\n&ndash; 파워 사용자\n&ndash; 주요 이해관계자\n&ndash; 경쟁사\n각 페르소나에 대해 그들이 주장할 5가지 아이디어, 요청 또는 개선 사항을 나열하세요.\n그리고 최고의 아이디어를 하나의 우선순위 목록으로 통합하세요.\n        </code></pre>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>8. 아이디어를 실행 가능한 로드맵으로 전환하기: 실질적인 계획</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">브레인스토밍이 아무리 멋진 아이디어를 쏟아냈어도, 그것들이 그냥 문서 속에서 잠들어버린다면 아무 소용이 없겠죠? 이 프롬프트는 <b>아이디어를 실제 행동으로 옮길 수 있는 구체적인 로드맵으로 전환</b>시켜 줍니다. 단순히 직감에만 의존하는 것이 아니라, <b>영향력(Impact)과 노력(Effort)</b>을 기준으로 아이디어를 평가하게 함으로써 가장 효과적인 계획을 세울 수 있도록 도와줘요. 제가 겪어본 바로는, 최상의 아이디어는 직감과 어느 정도의 객관적인 증거 사이의 균형에서 나온다고 생각합니다.</p>\n<div style=\"background-color: #e8f5e9; border-left: 4px solid #2e7d32; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">\n<p style=\"margin-bottom: 5px; color: #212121;\" data-ke-size=\"size16\">  <b>아이디어 분류 기준:</b></p>\n<ul style=\"list-style-type: disc; margin-left: 20px; padding-left: 0; color: #212121;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>Quick wins (빠른 성과):</b> 적은 노력으로 큰 영향력을 낼 수 있는 아이디어</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>Long bets (장기 투자):</b> 큰 노력이 필요하지만 장기적으로 엄청난 영향력을 가져올 아이디어</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>Experiments (실험):</b> 시도해 볼 만하지만 불확실성이 있는 아이디어</li>\n<li style=\"margin-bottom: 5px; color: #212121;\"><b>Cancel (취소):</b> 영향력은 낮고 노력은 많이 드는 비효율적인 아이디어</li>\n</ul>\n</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/U88XA/dJMcahiRBOO/A7K7LwyPI2AQU9xP7s79vK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/U88XA/dJMcahiRBOO/A7K7LwyPI2AQU9xP7s79vK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/U88XA/dJMcahiRBOO/A7K7LwyPI2AQU9xP7s79vK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FU88XA%2FdJMcahiRBOO%2FA7K7LwyPI2AQU9xP7s79vK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"이블 위에 펼쳐진 전략적 로드맵 이미지. '빠른 성과', '장기 투자', '실험', '취소' 섹션으로 명확히 구분되어 있으며, 손이 로드맵을 가리키며 실행 가능한 계획을 나타냅니다.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">제대로 된 브레인스토밍의 마지막은 항상 <b>실행 가능한 계획</b>이어야 한다고 생각해요. 챗GPT와 함께라면 이런 과정도 훨씬 체계적이고 효율적으로 진행할 수 있습니다. 예를 들어, 뉴스레터 관련 아이디어 3가지에 대해 2주간의 실행 계획을 세우는 거죠. 정말 생산적이지 않나요?</p>\n<div style=\"background-color: #f1f8e9; border: 1px solid #a5d6a7; padding: 15px; margin: 20px 0; border-radius: 8px; overflow-x: auto;\">\n<pre class=\"angelscript\" style=\"margin: 0; padding: 0; white-space: pre-wrap; word-wrap: break-word;\"><code>제가 제공하는 아이디어 목록을 실용적인 실행 로드맵으로 전환하세요.\n각 아이디어를 영향력(1-5)과 노력(1-5) 기준으로 평가하고 간략한 설명을 덧붙이세요.\n이를 빠른 성과(Quick wins), 장기 투자(Long bets), 실험(Experiments), 취소(Cancel)로 분류하세요.\n최고의 아이디어 3개를 테스트하기 위한 구체적인 작업이 포함된 2주 실행 계획을 제안하세요.\n        </code></pre>\n</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">생산적인 브레인스토밍은 단순히 더 좋은 아이디어를 내는 것을 넘어, <b>우리 자신의 맹점(Blind Spots)을 이해하는 과정</b>이기도 합니다. 모든 프롬프트를 다 사용할 필요는 없어요 (물론 다 사용하면 좋긴 합니다!). 초기 설정 프롬프트로 시작한 뒤, 발산적 프롬프트 하나와 SWOT 분석 같은 '아이디어 검증용' 프롬프트를 조합해보세요. 아마 생각지도 못했던 <b>명확성의 비약적인 상승</b>을 경험하게 될 겁니다. 2026년, ChatGPT와 함께 여러분의 생각의 지평을 더욱 넓혀나가시길 바랍니다!</p>\n<div style=\"background-color: #f1f8e9; border: 1px solid #a5d6a7; border-radius: 8px; padding: 25px; margin: 40px 0; box-shadow: 0 4px 12px rgba(0,0,0,0.1);\">\n<div style=\"border-bottom: 1px solid #2e7d32; padding-bottom: 15px; margin-bottom: 20px;\">\n<p style=\"font-size: 26px; color: #2e7d32; font-weight: bold; margin: 0;\" data-ke-size=\"size16\">  핵심 요약</p>\n</div>\n<p style=\"font-size: 17px; margin-bottom: 10px;\" data-ke-size=\"size16\"><b>1. 명확한 컨텍스트 설정:</b> ChatGPT에게 구체적인 목표와 제약 조건을 미리 알려 일반적인 답변을 방지하세요.</p>\n<p style=\"font-size: 17px; margin-bottom: 10px;\" data-ke-size=\"size16\"><b>2. 다양한 사고 확장:</b> 발산적 사고, 역 브레인스토밍, 무작위 단어, SCAMPER를 활용해 사고의 폭을 넓히세요.</p>\n<p style=\"font-size: 17px; margin-bottom: 10px;\" data-ke-size=\"size16\"><b>3. 아이디어 현실 점검:</b> SWOT 분석과 역할극을 통해 아이디어의 강점, 약점, 기회, 위협을 파악하고 다양한 관점을 통합하세요.</p>\n<p style=\"font-size: 17px; margin-bottom: 0px;\" data-ke-size=\"size16\"><b>4. 실행 가능한 로드맵:</b> 아이디어를 영향력과 노력 기준으로 평가하고, 단기 성과, 장기 투자, 실험, 취소 항목으로 분류하여 구체적인 실행 계획을 세우세요.</p>\n<div style=\"margin-top: 20px; padding-top: 15px; border-top: 1px dashed #aed581;\">\n<p style=\"font-size: 14px; color: #aed581; margin: 0;\" data-ke-size=\"size16\">  이 프롬프트들을 활용하면 여러분의 브레인스토밍이 훨씬 더 깊고 실용적으로 변할 거예요!</p>\n</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #2e7d32, #005005); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<div style=\"margin-bottom: 15px;\">\n<p style=\"font-size: 18px; color: #2e7d32; margin-bottom: 5px;\" data-ke-size=\"size16\"><b>Q1: ChatGPT 브레인스토밍 프롬프트를 사용할 때 가장 중요한 점은 무엇인가요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">가장 중요한 건 <b>명확한 컨텍스트와 목표를 설정</b>하는 거예요. ChatGPT를 단순한 아이디어 자동판매기가 아닌, 구조화된 브레인스토밍 파트너로 생각하고 구체적인 지침을 제공할수록 훨씬 더 유용하고 깊이 있는 결과를 얻을 수 있답니다. 마치 유능한 팀원에게 정확한 프로젝트 브리핑을 하는 것과 비슷하다고 보면 돼요!</p>\n</div>\n<div style=\"margin-bottom: 15px;\">\n<p style=\"font-size: 18px; color: #2e7d32; margin-bottom: 5px;\" data-ke-size=\"size16\"><b>Q2: 여러 프롬프트를 어떻게 조합해서 사용하는 것이 좋을까요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">저는 보통 <b>초기 설정 프롬프트(#1)로 시작</b>해서, 발산적 사고를 위한 프롬프트(#2)로 아이디어의 양을 늘려요. 그 다음, 역 브레인스토밍(#3)이나 SWOT 분석(#6) 같은 <b>'검증용' 프롬프트</b>로 아이디어를 점검하죠. 이렇게 하면 초기 아이디어의 맹점을 파악하고 보완할 수 있어서 정말 도움이 된답니다. 상황에 따라 SCAMPER(#5)나 역할극(#7)을 추가해서 더 깊이 있는 아이디어를 발굴하기도 해요.</p>\n</div>\n<div style=\"margin-bottom: 15px;\">\n<p style=\"font-size: 18px; color: #2e7d32; margin-bottom: 5px;\" data-ke-size=\"size16\"><b>Q3: ChatGPT가 생성한 아이디어가 너무 일반적일 때는 어떻게 해야 할까요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">음, 이런 경우도 자주 있죠! 그럴 때는 먼저 <b>컨텍스트를 더 구체적으로 설명</b>하는 게 좋아요. 예를 들어, \"이 아이디어를 20대 여성 직장인을 위한 뉴스레터에 적용한다면?\" 같이 대상 독자나 특정 상황을 더 명확히 제시하는 거죠. 그리고 역 브레인스토밍(#3)을 통해 '어떻게 하면 이 아이디어를 망칠 수 있을까?'를 고민해보면, 의외로 신선한 해결책이 나올 때가 많아요.</p>\n</div>\n<div style=\"margin-bottom: 0;\">\n<p style=\"font-size: 18px; color: #2e7d32; margin-bottom: 5px;\" data-ke-size=\"size16\"><b>Q4: 이 프롬프트들을 어디에 활용하면 가장 효과적일까요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">개인적으로는 <b>콘텐츠 기획, 마케팅 전략 수립, 제품 개발 아이디어 도출, 개인적인 목표 설정</b> 등 다양한 분야에서 활용도가 높았어요. 특히 혼자서 막막할 때나 팀원들과 새로운 시각이 필요할 때 ChatGPT를 유능한 동료 삼아 이 프롬프트들을 적용해보면, 생각지도 못한 인사이트를 얻을 수 있을 거예요.</p>\n</div>\n<script type=\"application/ld+json\">\n        {\n          \"@context\": \"https://schema.org\",\n          \"@type\": \"FAQPage\",\n          \"mainEntity\": [\n            {\n              \"@type\": \"Question\",\n              \"name\": \"ChatGPT 브레인스토밍 프롬프트를 사용할 때 가장 중요한 점은 무엇인가요?\",\n              \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"가장 중요한 건 명확한 컨텍스트와 목표를 설정하는 거예요. ChatGPT를 단순한 아이디어 자동판매기가 아닌, 구조화된 브레인스토밍 파트너로 생각하고 구체적인 지침을 제공할수록 훨씬 더 유용하고 깊이 있는 결과를 얻을 수 있답니다. 마치 유능한 팀원에게 정확한 프로젝트 브리핑을 하는 것과 비슷하다고 보면 돼요!\"\n              }\n            },\n            {\n              \"@type\": \"Question\",\n              \"name\": \"여러 프롬프트를 어떻게 조합해서 사용하는 것이 좋을까요?\",\n              \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"저는 보통 초기 설정 프롬프트(#1)로 시작해서, 발산적 사고를 위한 프롬프트(#2)로 아이디어의 양을 늘려요. 그 다음, 역 브레인스토밍(#3)이나 SWOT 분석(#6) 같은 '검증용' 프롬프트로 아이디어를 점검하죠. 이렇게 하면 초기 아이디어의 맹점을 파악하고 보완할 수 있어서 정말 도움이 된답니다. 상황에 따라 SCAMPER(#5)나 역할극(#7)을 추가해서 더 깊이 있는 아이디어를 발굴하기도 해요.\"\n              }\n            },\n            {\n              \"@type\": \"Question\",\n              \"name\": \"ChatGPT가 생성한 아이디어가 너무 일반적일 때는 어떻게 해야 할까요?\",\n              \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"음, 이런 경우도 자주 있죠! 그럴 때는 먼저 컨텍스트를 더 구체적으로 설명하는 게 좋아요. 예를 들어, '이 아이디어를 20대 여성 직장인을 위한 뉴스레터에 적용한다면?' 같이 대상 독자나 특정 상황을 더 명확히 제시하는 거죠. 그리고 역 브레인스토밍(#3)을 통해 '어떻게 하면 이 아이디어를 망칠 수 있을까?'를 고민해보면, 의외로 신선한 해결책이 나올 때가 많아요.\"\n              }\n            },\n            {\n              \"@type\": \"Question\",\n              \"name\": \"이 프롬프트들을 어디에 활용하면 가장 효과적일까요?\",\n              \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"개인적으로는 콘텐츠 기획, 마케팅 전략 수립, 제품 개발 아이디어 도출, 개인적인 목표 설정 등 다양한 분야에서 활용도가 높았어요. 특히 혼자서 막막할 때나 팀원들과 새로운 시각이 필요할 때 ChatGPT를 유능한 동료 삼아 이 프롬프트들을 적용해보면, 생각지도 못한 인사이트를 얻을 수 있을 거예요.\"\n              }\n            }\n          ]\n        }\n    </script>\n</div>",
        "contentSnippet": "여러분은 브레인스토밍을 할 때 막막함을 느끼시나요? 방대한 아이디어가 필요한데 어디서부터 시작해야 할지 모르겠다고요? 2026년, 이제 ChatGPT는 단순한 정보 제공자를 넘어 여러분의 '생각의 수준'을 한 차원 높여줄 유능한 브레인스토밍 파트너가 될 수 있습니다. 오늘은 제가 직접 사용하며 효과를 본, 창의적인 사고를 돕는 8가지 ChatGPT 프롬프트를 공개합니다. 평범한 아이디어를 벗어나 실용적이고 깊이 있는 통찰력을 얻고 싶은 분들을 위해 준비했어요.\n\n\n솔직히 말하면, 우리는 ChatGPT를 너무 쉽게 생각하는 경향이 있는 것 같아요. 그냥 질문을 던지면 답을 뱉어내는 '아이디어 자판기'처럼 말이죠. 하지만 제가 직접 겪어보니, 제대로 활용하면 정말 놀라운 '브레인스토밍 파트너'가 될 수 있다는 걸 깨달았습니다. 우리가 머리를 쥐어짜며 생각의 흐름을 만들 때, ChatGPT는 그 아이디어의 볼륨과 구조를 잡아주는 역할을 톡톡히 해내죠. 제가 오랫동안 마케팅과 웹 개발 분야에서 일하며 숱하게 브레인스토밍을 해왔는데, 최근 챗GPT와 함께하면서 아이디어의 명확성과 범위가 확연히 넓어지는 것을 경험하고 있습니다. 수많은 선배들의 지혜와 레딧 같은 커뮤니티에서 얻은 영감을 바탕으로, 퍼져 있던 생각들을 실행 가능한 아이디어로 다듬는 데 최적화된 프롬프트 8가지를 소개할게요. 저의 뉴스레터를 장기적으로 흥미롭게 유지하는 방법이라는 주제로 같이 고민해보면 더 와닿으실 거예요.\n1. 맥락을 이해시키는 것부터 시작하세요: 일반적인 아이디어를 피하는 첫걸음\n아무리 인공지능이라도 우리 마음을 꿰뚫어 볼 수는 없잖아요? 그래서 저는 항상 브레인스토밍 세션을 시작하기 전에 ChatGPT에게 명확한 지침을 줍니다. 마치 유능한 팀원에게 프로젝트 브리핑을 하듯이요. 이 '핵심 프롬프트'는 전체 대화의 틀을 잡고, 챗GPT가 뻔하거나 피상적인 아이디어를 내놓는 걸 미리 방지해 주는 역할을 해요. 복잡한 콘텐츠 기획이나 개인적인 목표 설정 같은 작업에 특히 유용하더라고요. 처음부터 이렇게 세부적으로 조율해두면 나중에 불필요한 노력을 훨씬 줄일 수 있습니다. 핵심은 맥락, 명확성, 그리고 의도라는 점, 잊지 마세요!\n  프롬프트 활용 팁:\nGoal(목표): 최종적으로 무엇을 얻고 싶은지 명확히 하세요.\nContext(맥락): 대상, 제약 조건, 시간, 자원 등 배경 정보를 상세히 설명하세요.\nProcess(과정): 어떤 방식으로 진행할지 (예: 질문 개수, 프레임워크 제안 등) 구체적으로 알려주세요.\n당신은 저의 구조화된 브레인스토밍 파트너입니다.\n목표: [주제/문제/결과물 설명]에 대해 브레인스토밍하는 것을 도와주세요.\n맥락: [대상, 제약 조건, 기한, 자원].\n과정: 최대 5개의 명확화 질문을 하나씩 해주세요.\n사용할 수 있는 3-5가지의 다른 브레인스토밍 프레임워크를 제안해주세요 (예: SCAMPER, 마인드맵, 가정, 제약, 첫 번째 원칙).\n제가 하나를 선택하면, 간결하고 번호가 매겨진 목록으로 브레인스토밍을 안내해주세요. 이때 구체성과 실용성을 목표로 합니다.\n궁극적으로, 최고의 아이디어를 3-5가지 테마로 분류하고 구체적인 다음 단계를 제안해주세요.\n간결한 글머리 기호를 사용하고 일반적인 조언은 피해주세요.\n        \n2. 다양한 아이디어로 물꼬를 트세요: 양으로 승부하는 발산적 사고\n아이디어가 막힐 때 가장 빠르고 확실한 방법은 일단 많은 아이디어를 쏟아내는 것이라고 생각해요. 심지어 좀 터무니없는 아이디어라도 괜찮아요! 초기 단계에서는 아이디어의 질보다는 속도와 범위가 훨씬 중요합니다. 이 프롬프트는 ChatGPT와 우리 뇌의 시동을 거는 역할을 해요. 나중에 걸러내고 우선순위를 정하는 건 그때 가서 해도 늦지 않습니다.\n  뉴스레터 아이디어 적용 예시:\n뉴스레터의 메인 콘텐츠를 짧은 숏폼 비디오로 전환 (요즘 대세죠!)\n구독자들이 직접 참여하는 '익명 고민 상담소' 코너 운영\n매주 다른 분야의 전문가를 초대해 인터뷰 시리즈 진행\n프롬프트의 마지막 단계가 정말 중요해요. '가장 유망한 아이디어 5가지 표시'가 없다면, 그냥 방치되는 목록으로 끝나버릴 수도 있거든요. 번호가 매겨진 목록은 나중에 특정 아이디어를 참조할 때도 편리하고요. 개인적인 경험으로는, 종종 목록의 뒷부분에 숨어있는 기발한 아이디어들이 많았습니다. ChatGPT와 마인드맵 도구를 함께 사용하면 아이디어 간의 연관성을 찾는 데 큰 도움이 될 거예요.\n\n\n\n[주제]에 대해 발산적 브레인스토밍을 해봅시다.\n제약 조건: [예산/시간/산업/대상/기타].\n1단계: 명확한 것부터 파격적인 것까지 20가지의 빠르고 대략적인 아이디어를 번호가 매겨진 목록으로 생성해주세요.\n2단계: 각 아이디어에 대해 왜 효과적일 수 있는지에 대한 짧은 문구를 추가해주세요.\n3단계: 영향력 대비 노력 측면에서 가장 유망해 보이는 5가지 아이디어를 표시해주세요.\n        \n3. 역 브레인스토밍으로 숨겨진 문제점 찾기: 실패를 통해 성공 배우기\n생각해보니, 성공하는 방법만 고민할 필요는 없더라고요. 역 브레인스토밍(Reverse Brainstorming)은 문제를 뒤집어서 '어떻게 하면 실패할 수 있을까?'를 묻는 기법입니다. 마치 일이 터지기 전에 미리 사후 검토(Pre-mortem)를 하는 것과 비슷하죠. 저는 이 프롬프트를 통해 어떤 아이디어가 '괜찮긴 한데 뭔가 부족하다'고 느껴질 때 그 이유를 파악하는 데 활용합니다.\n⚠️ 뉴스레터 아이디어 적용 예시 (역발상):\n문제: 뉴스레터 이탈률을 높이는 방법은?\n해결책: 과도한 광고 삽입 (뒤집으면: 광고를 최소화하고 콘텐츠 집중)\n해결책: 매주 비슷한 내용만 반복 (뒤집으면: 다양한 형식과 주제로 신선함 유지)\n해결책: 발행 주기를 불규칙하게 (뒤집으면: 일관된 발행 주기 유지)\n이 프롬프트는 약한 아이디어와 흔한 실수를 빠르게 파악하게 해줘요. 만약 아이디어가 너무 일반적이라 실패한다면, 더 틈새시장을 노리는 것이 해결책이 될 수 있고, 너무 복잡해서 실패한다면 간단하게 만드는 것이 답이 될 수 있죠. 정말 유용한 전략입니다!\n[주제]에 대해 역 브레인스토밍을 사용하세요.\n이 문제를 악화시킬 수 있는 15가지 방법을 나열하세요.\n각각의 \"악화\" 아이디어를 건설적인 아이디어 또는 보호 장치로 전환하세요.\n전환된 목록을 구체적이고 테스트 가능한 행동 또는 개념으로 제시하세요.\n        \n4. 무작위 단어로 상상력 점프하기: 기발한 연결고리 만들기\n모든 아이디어가 비슷하게 들리기 시작할 때, 저는 가끔 '무작위성'의 도움을 받아요. 예전에는 사전을 펼치거나 신문을 보면서 뜬금없는 단어에서 영감을 얻기도 했죠. 이 프롬프트는 전혀 관련 없어 보이는 입력값들을 한데 모아 새로운 연결고리를 찾도록 강제합니다. 아, 그런데 이거 뇌세포에 정말 무리가 갈 때도 있어요... 그래서 챗GPT가 이렇게 도움이 될 줄은 몰랐네요!\n  뉴스레터 아이디어 적용 예시 (무작위 단어: '나무'):\n은유: 나무의 나이테처럼 구독자들의 성장 과정을 담는 콘텐츠 시리즈 기획\n제약: '나무'라는 단어의 의미를 벗어나지 않게 친환경, 지속 가능성 테마의 콘텐츠만 다루기\n관점: 뉴스레터를 '지식의 숲'으로 비유하여 구독자들이 각자 나무를 심고 가꾸는 커뮤니티 조성\n사실 무작위 단어 그 자체는 중요하지 않아요. 중요한 건 그 단어들을 은유, 제약, 또는 평소에는 고려하지 않았을 관점으로 번역하는 과정에서 가치가 생긴다는 점입니다. 정말 신기하죠?!\n[주제]에 대한 창의적이고 명확하지 않은 아이디어를 원합니다.\n1단계: 무작위의 관련 없는 트리거 단어 5개를 생성하세요.\n2단계: 각 단어에 대해 아이디어를 영감을 주거나 수정할 수 있는 세 가지 방법을 보여주세요.\n3단계: 도출된 가장 흥미로운 방향 5가지를 요약하세요.\n        \n5. SCAMPER 프레임워크로 체계적인 사고 확장하기\n에드워드 드 보노(Edward de Bono)가 측면 사고(Lateral Thinking)를 대중화시켰죠. SCAMPER는 측면 사고를 위한 고전적인 창의성 프레임워크인데, AI와 함께 사용하면 정말 눈부시게 빠릅니다! 이 프레임워크는 특정 아이디어를 다양한 각도에서 질문하고 변형하며 새로운 가능성을 탐색하도록 돕습니다.\n요소\n의미\n뉴스레터 아이디어 예시\n\n\n\n\nSubstitute\n대체하기\n텍스트 콘텐츠를 짧은 오디오 클립으로 대체\n\n\nCombine\n결합하기\n주간 칼럼과 독자 Q&A 코너를 결합하여 '전문가에게 묻다' 시리즈\n\n\nAdapt\n적응하기\n타 산업의 성공적인 콘텐츠 전략을 뉴스레터에 적용\n\n\nModify\n수정/확대/축소\n메인 칼럼의 길이를 확 줄이고 대신 인포그래픽으로 시각화\n\n\nPut to other uses\n다른 용도로 활용\n뉴스레터 콘텐츠를 활용해 소셜 미디어 카드뉴스 제작\n\n\nEliminate\n제거하기\n모든 광고 제거, 오직 순수 콘텐츠에만 집중\n\n\nReverse\n뒤집기/재배열\n결론을 먼저 보여주고 그 이유를 설명하는 콘텐츠 구성\n\n\n\n\n\n이 프롬프트는 이미 어느 정도 구체화된 아이디어에 적용할 때 빛을 발합니다. 그래서 저는 브레인스토밍 과정의 후반부에 이 프롬프트를 사용하는 편이에요. 특정 기능을 제거하거나 두 가지 요소를 결합하는 것 같은 작은 변화가 아이디어의 명확성이나 유용성을 극적으로 향상시키는 것을 자주 경험할 수 있을 겁니다.\nSCAMPER 프레임워크를 사용하여 [제품/프로젝트/주제]에 대해 브레인스토밍하세요.\n각 요소(Substitute, Combine, Adapt, Modify, Put to other uses, Eliminate, Reverse)에 대해:\n일반적인 조언이 아닌 3-5가지 구체적인 아이디어를 생성하세요.\n각 아이디어를 한 문장으로 유지하세요.\n모든 SCAMPER 단계에서 가장 좋은 아이디어 5가지의 짧은 목록으로 마무리하세요.\n        \n6. SWOT 분석으로 아이디어를 현실에 대입하기: 전략적 점검\n아이디어가 아무리 좋아 보여도 현실성이 없으면 무용지물이잖아요? SWOT 분석 스타일의 프롬프트는 브레인스토밍을 현실 세계로 끌어와 앞으로 발생할 수 있는 상충 관계(Trade-offs)를 미리 보여줍니다. 저는 종종 이 프롬프트를 통해 '보기에는 좋은 아이디어'가 실질적으로 어떤 문제점을 안고 있는지 파악하고 싶을 때 사용하곤 해요.\n  뉴스레터 아이디어 적용 예시 (SWOT):\n강점 활용: '전문가 인터뷰' 강점을 살려 해당 분야 최고 권위자를 초빙하는 특별 시리즈 기획\n약점 보완: '콘텐츠 제작 시간 부족' 약점을 해결하기 위해 구독자 참여형 콘텐츠 비중 확대\n기회 포착: '트렌드 변화' 기회를 활용해 AI 기술 트렌드를 빠르게 분석하는 섹션 신설\n위협 방어: '경쟁사 증가' 위협에 대비해 뉴스레터만의 독점적인 커뮤니티 기능 강화\n이 분석을 통해 얻은 통찰력은 아이디어의 질을 높이고 실행력을 개선하는 데 결정적인 역할을 합니다. 시각적인 다이어그램 도구를 함께 사용하면 아이디어를 한눈에 파악하는 데 더욱 효과적일 거예요. 솔직히 말해서, 이 과정 없이는 뭔가 중요한 걸 놓치고 있는 느낌이 들 때가 많아요.\n[아이디어 또는 프로젝트]에 대해 SWOT 방식의 브레인스토밍 세션을 실행하세요.\n5-7가지 강점, 5-7가지 약점, 5-7가지 기회, 5-7가지 위협을 나열하세요.\n이것들로부터 다음을 나열하세요:\n강점을 두 배로 활용하는 아이디어 3가지\n약점을 고치거나 우회하는 아이디어 3가지\n기회를 포착하는 아이디어 3가지\n위협에 대비하는 아이디어 3가지\n모든 것을 간결한 글머리 기호로 제시하세요.\n        \n7. 역할극으로 다양한 관점 얻기: 미처 몰랐던 니즈 발굴\n우리는 모두 자기만의 시각에 갇히기 쉬워요. 역할극 브레인스토밍(Rolestorming)은 다른 사람의 입장이 되어 생각해보는 기법인데, 제품이나 프로세스의 페인 포인트(Pain Point)를 찾는 데 정말 탁월한 효과를 발휘합니다. 내가 미처 생각하지 못했던 필요나 개선점들을 발견하게 해주거든요.\n  뉴스레터 아이디어 적용 예시 (페르소나):\n초보 사용자: '용어가 너무 어려워요. 초보자를 위한 쉬운 설명이나 용어 사전이 필요해요.'\n파워 사용자: '심화 자료나 다른 전문가와의 네트워킹 기회가 있으면 좋겠어요.'\n경쟁사: '이 뉴스레터는 특정 주제에 대한 심층 분석이 부족하고, 인터랙티브 요소가 약해.'\n작가로서, 저는 이 프롬프트 덕분에 다양한 독자층의 니즈를 파악하고 콘텐츠를 미세 조정하는 데 큰 도움을 받았습니다. 여러 페르소나에서 공통적으로 발견되는 인사이트는 콘텐츠를 더 넓은 독자층에 맞게 다듬는 데 정말 핵심적이라고 할 수 있죠. 아마 여러분도 이 과정을 통해 예상치 못한 보물을 발견하실 거예요.\n[주제]에 대해 \"역할 브레인스토밍\"을 할 것입니다.\n다음 관점에서 생각하세요:\n– 초보자\n– 파워 사용자\n– 주요 이해관계자\n– 경쟁사\n각 페르소나에 대해 그들이 주장할 5가지 아이디어, 요청 또는 개선 사항을 나열하세요.\n그리고 최고의 아이디어를 하나의 우선순위 목록으로 통합하세요.\n        \n8. 아이디어를 실행 가능한 로드맵으로 전환하기: 실질적인 계획\n브레인스토밍이 아무리 멋진 아이디어를 쏟아냈어도, 그것들이 그냥 문서 속에서 잠들어버린다면 아무 소용이 없겠죠? 이 프롬프트는 아이디어를 실제 행동으로 옮길 수 있는 구체적인 로드맵으로 전환시켜 줍니다. 단순히 직감에만 의존하는 것이 아니라, 영향력(Impact)과 노력(Effort)을 기준으로 아이디어를 평가하게 함으로써 가장 효과적인 계획을 세울 수 있도록 도와줘요. 제가 겪어본 바로는, 최상의 아이디어는 직감과 어느 정도의 객관적인 증거 사이의 균형에서 나온다고 생각합니다.\n  아이디어 분류 기준:\nQuick wins (빠른 성과): 적은 노력으로 큰 영향력을 낼 수 있는 아이디어\nLong bets (장기 투자): 큰 노력이 필요하지만 장기적으로 엄청난 영향력을 가져올 아이디어\nExperiments (실험): 시도해 볼 만하지만 불확실성이 있는 아이디어\nCancel (취소): 영향력은 낮고 노력은 많이 드는 비효율적인 아이디어\n\n\n제대로 된 브레인스토밍의 마지막은 항상 실행 가능한 계획이어야 한다고 생각해요. 챗GPT와 함께라면 이런 과정도 훨씬 체계적이고 효율적으로 진행할 수 있습니다. 예를 들어, 뉴스레터 관련 아이디어 3가지에 대해 2주간의 실행 계획을 세우는 거죠. 정말 생산적이지 않나요?\n제가 제공하는 아이디어 목록을 실용적인 실행 로드맵으로 전환하세요.\n각 아이디어를 영향력(1-5)과 노력(1-5) 기준으로 평가하고 간략한 설명을 덧붙이세요.\n이를 빠른 성과(Quick wins), 장기 투자(Long bets), 실험(Experiments), 취소(Cancel)로 분류하세요.\n최고의 아이디어 3개를 테스트하기 위한 구체적인 작업이 포함된 2주 실행 계획을 제안하세요.\n        \n생산적인 브레인스토밍은 단순히 더 좋은 아이디어를 내는 것을 넘어, 우리 자신의 맹점(Blind Spots)을 이해하는 과정이기도 합니다. 모든 프롬프트를 다 사용할 필요는 없어요 (물론 다 사용하면 좋긴 합니다!). 초기 설정 프롬프트로 시작한 뒤, 발산적 프롬프트 하나와 SWOT 분석 같은 '아이디어 검증용' 프롬프트를 조합해보세요. 아마 생각지도 못했던 명확성의 비약적인 상승을 경험하게 될 겁니다. 2026년, ChatGPT와 함께 여러분의 생각의 지평을 더욱 넓혀나가시길 바랍니다!\n  핵심 요약\n1. 명확한 컨텍스트 설정: ChatGPT에게 구체적인 목표와 제약 조건을 미리 알려 일반적인 답변을 방지하세요.\n2. 다양한 사고 확장: 발산적 사고, 역 브레인스토밍, 무작위 단어, SCAMPER를 활용해 사고의 폭을 넓히세요.\n3. 아이디어 현실 점검: SWOT 분석과 역할극을 통해 아이디어의 강점, 약점, 기회, 위협을 파악하고 다양한 관점을 통합하세요.\n4. 실행 가능한 로드맵: 아이디어를 영향력과 노력 기준으로 평가하고, 단기 성과, 장기 투자, 실험, 취소 항목으로 분류하여 구체적인 실행 계획을 세우세요.\n  이 프롬프트들을 활용하면 여러분의 브레인스토밍이 훨씬 더 깊고 실용적으로 변할 거예요!\n❓ 자주 묻는 질문 (FAQ)\nQ1: ChatGPT 브레인스토밍 프롬프트를 사용할 때 가장 중요한 점은 무엇인가요?\n가장 중요한 건 명확한 컨텍스트와 목표를 설정하는 거예요. ChatGPT를 단순한 아이디어 자동판매기가 아닌, 구조화된 브레인스토밍 파트너로 생각하고 구체적인 지침을 제공할수록 훨씬 더 유용하고 깊이 있는 결과를 얻을 수 있답니다. 마치 유능한 팀원에게 정확한 프로젝트 브리핑을 하는 것과 비슷하다고 보면 돼요!\nQ2: 여러 프롬프트를 어떻게 조합해서 사용하는 것이 좋을까요?\n저는 보통 초기 설정 프롬프트(#1)로 시작해서, 발산적 사고를 위한 프롬프트(#2)로 아이디어의 양을 늘려요. 그 다음, 역 브레인스토밍(#3)이나 SWOT 분석(#6) 같은 '검증용' 프롬프트로 아이디어를 점검하죠. 이렇게 하면 초기 아이디어의 맹점을 파악하고 보완할 수 있어서 정말 도움이 된답니다. 상황에 따라 SCAMPER(#5)나 역할극(#7)을 추가해서 더 깊이 있는 아이디어를 발굴하기도 해요.\nQ3: ChatGPT가 생성한 아이디어가 너무 일반적일 때는 어떻게 해야 할까요?\n음, 이런 경우도 자주 있죠! 그럴 때는 먼저 컨텍스트를 더 구체적으로 설명하는 게 좋아요. 예를 들어, \"이 아이디어를 20대 여성 직장인을 위한 뉴스레터에 적용한다면?\" 같이 대상 독자나 특정 상황을 더 명확히 제시하는 거죠. 그리고 역 브레인스토밍(#3)을 통해 '어떻게 하면 이 아이디어를 망칠 수 있을까?'를 고민해보면, 의외로 신선한 해결책이 나올 때가 많아요.\nQ4: 이 프롬프트들을 어디에 활용하면 가장 효과적일까요?\n개인적으로는 콘텐츠 기획, 마케팅 전략 수립, 제품 개발 아이디어 도출, 개인적인 목표 설정 등 다양한 분야에서 활용도가 높았어요. 특히 혼자서 막막할 때나 팀원들과 새로운 시각이 필요할 때 ChatGPT를 유능한 동료 삼아 이 프롬프트들을 적용해보면, 생각지도 못한 인사이트를 얻을 수 있을 거예요.\n\n\n        {\n          \"@context\": \"https://schema.org\",\n          \"@type\": \"FAQPage\",\n          \"mainEntity\": [\n            {\n              \"@type\": \"Question\",\n              \"name\": \"ChatGPT 브레인스토밍 프롬프트를 사용할 때 가장 중요한 점은 무엇인가요?\",\n              \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"가장 중요한 건 명확한 컨텍스트와 목표를 설정하는 거예요. ChatGPT를 단순한 아이디어 자동판매기가 아닌, 구조화된 브레인스토밍 파트너로 생각하고 구체적인 지침을 제공할수록 훨씬 더 유용하고 깊이 있는 결과를 얻을 수 있답니다. 마치 유능한 팀원에게 정확한 프로젝트 브리핑을 하는 것과 비슷하다고 보면 돼요!\"\n              }\n            },\n            {\n              \"@type\": \"Question\",\n              \"name\": \"여러 프롬프트를 어떻게 조합해서 사용하는 것이 좋을까요?\",\n              \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"저는 보통 초기 설정 프롬프트(#1)로 시작해서, 발산적 사고를 위한 프롬프트(#2)로 아이디어의 양을 늘려요. 그 다음, 역 브레인스토밍(#3)이나 SWOT 분석(#6) 같은 '검증용' 프롬프트로 아이디어를 점검하죠. 이렇게 하면 초기 아이디어의 맹점을 파악하고 보완할 수 있어서 정말 도움이 된답니다. 상황에 따라 SCAMPER(#5)나 역할극(#7)을 추가해서 더 깊이 있는 아이디어를 발굴하기도 해요.\"\n              }\n            },\n            {\n              \"@type\": \"Question\",\n              \"name\": \"ChatGPT가 생성한 아이디어가 너무 일반적일 때는 어떻게 해야 할까요?\",\n              \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"음, 이런 경우도 자주 있죠! 그럴 때는 먼저 컨텍스트를 더 구체적으로 설명하는 게 좋아요. 예를 들어, '이 아이디어를 20대 여성 직장인을 위한 뉴스레터에 적용한다면?' 같이 대상 독자나 특정 상황을 더 명확히 제시하는 거죠. 그리고 역 브레인스토밍(#3)을 통해 '어떻게 하면 이 아이디어를 망칠 수 있을까?'를 고민해보면, 의외로 신선한 해결책이 나올 때가 많아요.\"\n              }\n            },\n            {\n              \"@type\": \"Question\",\n              \"name\": \"이 프롬프트들을 어디에 활용하면 가장 효과적일까요?\",\n              \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"개인적으로는 콘텐츠 기획, 마케팅 전략 수립, 제품 개발 아이디어 도출, 개인적인 목표 설정 등 다양한 분야에서 활용도가 높았어요. 특히 혼자서 막막할 때나 팀원들과 새로운 시각이 필요할 때 ChatGPT를 유능한 동료 삼아 이 프롬프트들을 적용해보면, 생각지도 못한 인사이트를 얻을 수 있을 거예요.\"\n              }\n            }\n          ]\n        }",
        "guid": "https://muzbox.tistory.com/483700",
        "categories": [
          "AI, 미래기술/프롬프트 다이어리",
          "AI 아이디어",
          "ChatGPT 브레인스토밍",
          "SCAMPER 프레임워크",
          "SWOT 분석",
          "뉴스레터 기획",
          "디지털 마케팅 전략",
          "문제 해결 기법",
          "생산성 향상 프롬프트",
          "역 브레인스토밍",
          "창의적 사고"
        ],
        "isoDate": "2026-01-15T23:34:44.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "2026년 전문가들이 극찬한 AI 3대장 심층 분석 (ChatGPT Plus, Adobe Firefly, Notion AI)",
        "link": "https://muzbox.tistory.com/483699",
        "pubDate": "Wed, 14 Jan 2026 10:26:50 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "https://muzbox.tistory.com/483699#entry483699comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #3c4043;\">\n<div style=\"background-color: #e8f4fd; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">매일 새로운 AI 도구가 쏟아져 나오는 2026년, 어떤 도구가 정말 우리의 시간과 돈을 투자할 가치가 있을까요? 수많은 AI 서비스 중에서 제가 직접 경험하고 전문가들이 극찬하는 단 세 가지 AI 도구, ChatGPT Plus, Adobe Firefly, 그리고 Notion AI를 심층 분석합니다. 이 글을 통해 여러분의 업무 생산성과 창의력을 한 차원 높여줄 현명한 AI 선택 가이드를 얻어가시길 바랍니다.</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/duPw4D/dJMcaiaZnWp/b4nortkleHifKECoWKQJgk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/duPw4D/dJMcaiaZnWp/b4nortkleHifKECoWKQJgk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/duPw4D/dJMcaiaZnWp/b4nortkleHifKECoWKQJgk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FduPw4D%2FdJMcaiaZnWp%2Fb4nortkleHifKECoWKQJgk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"2026년 미래형 사무실에서 ChatGPT Plus, Adobe Firefly, Notion AI 세 가지 AI 도구를 활용하여 생산성을 높이는 전문가들의 모습.\" loading=\"lazy\" width=\"500\" height=\"500\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>AI 홍수 시대, 진짜배기를 찾아서  </b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">사랑하든 싫어하든, 인공지능은 2026년 현재 우리의 삶 곳곳에 스며들어 있습니다. 매일같이 창의력, 생산성, 글쓰기 능력을 향상시키고 삶을 더 쉽게 만들어주겠다고 약속하는 새로운 AI 도구들이 쏟아져 나오고 있죠. 하지만 AI 시장이 팽창하면서 혼란도 함께 가중되고 있습니다. 너무나도 유혹적인 선택지, 수많은 구독 서비스, 인상적인 기능 목록 속에서 필요한지조차 불분명한 AI 도구에 쉽게 지갑을 열게 되는 경우가 많습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">하지만 모든 AI 도구가 똑같지는 않습니다. 어떤 도구들은 터무니없이 비싸거나 그저 겉만 번지르르한 기능으로 가득한 반면, 소수의 도구들은 실제로 비용을 정당화할 만큼 뛰어난 성능을 발휘합니다. 저는 지난 몇 년간 생산성, 이미지 생성 등 다양한 분야의 여러 AI 도구들을 직접 시험하고 사용해봤어요. 솔직히 말해서 대부분의 AI 도구는 돈 낭비라고 생각했습니다. 그럼에도 불구하고, 실제로 돈을 지불할 가치가 있다고 확신하는 세 가지 도구를 발견했습니다. 이제 그 세 가지 AI 3대장을 심층적으로 파헤쳐 볼 시간입니다.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>1. ChatGPT Plus: 대화형 AI의 기준을 높이다  </b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">혹시 AI 챗봇을 사용해보고는 기대 이하였다고 실망한 적 있으신가요? 아마 여러분만 그런 것은 아닐 거예요. 무료 버전의 챗봇들은 보통 느린 속도, 기본 모델, 사용량 제한, 그리고 한정된 기능을 제공하기 마련이죠. 저 역시 몇 주 동안 ChatGPT 무료 버전을 사용했습니다. 주로 아이디어를 브레인스토밍하고, 복잡한 정보를 요약하고, 일정을 계획하거나, 새로운 쇼핑 리서치 기능을 시도하는 데 사용했죠.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">몇 주간 사용한 후, 저는 ChatGPT Plus로 업그레이드를 결정했습니다. 이미 많은 친구들이 사용하며 만족하고 있었거든요. 그리고 Plus 버전으로 전환했을 때, 단순히 업그레이드를 넘어선 <b>완전히 새로운 경험</b>이라는 것을 깨달았습니다. 정말 <b>게임 체인저</b>였어요.</p>\n<h3 data-ke-size=\"size23\"><b>ChatGPT Plus, 왜 전문가들의 선택일까요?</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">월 20달러라는 합리적인 비용으로, 여러분은 <b>더 나은 추론 능력을 가진 최첨단 ChatGPT 5 모델</b>에 접근할 수 있게 됩니다. 이 모델은 복잡한 프롬프트를 훨씬 더 잘 처리하고, 맥락을 정확하게 이해하며, <b>더 스마트하고 신뢰할 수 있는 답변</b>을 제공합니다. 게다가 피크 시간대에 대기할 필요 없이 우선적인 접근 권한을 얻어 더 빠른 응답을 받을 수 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">무엇보다 ChatGPT Plus는 <b>더 나은 설명, 뛰어난 지원, 그리고 창의적인 답변</b>을 제공하는 데 탁월합니다. 비즈니스 아이디어를 브레인스토밍하고 싶을 때, 코드를 디버깅해야 할 때, 답변에 창의성을 더하고 싶을 때, 또는 일상적인 작업을 자동화하고 싶을 때, ChatGPT Plus의 고급 모델은 비교할 수 없는 신뢰할 수 있는 결과를 제공할 것입니다.</p>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  팁: ChatGPT Plus를 사용하면 복잡한 데이터 분석, 장문의 보고서 요약, 심지어 특정 주제에 대한 심도 있는 연구까지 훨씬 빠르고 정확하게 수행할 수 있습니다. 여러분의 디지털 비서가 한 단계 더 진화하는 경험을 할 수 있을 거예요.</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/JCTWC/dJMcadAHa12/cRPIEgIeZB7AgL6hpry2OK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/JCTWC/dJMcadAHa12/cRPIEgIeZB7AgL6hpry2OK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/JCTWC/dJMcadAHa12/cRPIEgIeZB7AgL6hpry2OK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FJCTWC%2FdJMcadAHa12%2FcRPIEgIeZB7AgL6hpry2OK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>2. Adobe Firefly: 창의력을 현실로, 상업적 활용까지  </b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">만약 여러분이 소셜 미디어 게시물, 일러스트레이션, 제품 이미지 또는 디자인 프로토타입과 같은 시각적 콘텐츠를 생성하는 사람이라면, 이미 인기 있는 생성형 이미지 도구들을 사용해봤을 가능성이 높습니다. 이들 중 많은 도구가 무료로 제공되지만, 소수의 도구만이 <b>놀라운 수준의 창의적 제어력</b>을 선사합니다. 저는 Google의 Nano Banana, Midjourney, Canva, 그리고 Adobe Firefly를 사용해봤고, 각기 독특한 강점과 단점을 가지고 있었죠.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">그중에서도 저에게 특히 인상 깊었던 AI 이미지 생성 도구는 바로 <b>Adobe Firefly</b>였습니다. Firefly는 아름다운 Pinterest 스타일의 이미지를 자유롭게 만들 수 있게 해줄 뿐만 아니라, <b>전문가 수준의 에셋</b>을 제공하고 <b>상업적으로 안전하게 사용할 수 있는 결과물</b>을 생성해줍니다. Firefly는 가장 유능한 텍스트-이미지 생성기 중 하나로, 텍스트 프롬프트만으로 <b>텍스트 효과까지 적용</b>할 수 있습니다.</p>\n<h3 data-ke-size=\"size23\"><b>Firefly의 핵심 기능과 통합의 힘</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">저는 온라인 비즈니스와 소셜 미디어를 위한 몇몇 이미지를 생성해 보았는데, 결과물이 정말 마음에 들었습니다. Firefly는 여러분의 창의적인 갈증을 해소해줄 수많은 스타일을 제공합니다. Firefly의 가장 큰 장점 중 하나는 <b>Adobe Creative Cloud와의 완벽한 통합</b>입니다. 덕분에 Generative Fill(생성형 채우기), Generative Recolor(생성형 재색상), Generative Expand(생성형 확장)와 같은 뛰어난 기능들을 Photoshop, Premiere Pro, Illustrator 등 핵심 앱 내에서 바로 사용할 수 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">무료 버전은 제한된 크레딧, 워터마크가 있는 결과물, 기본적인 기능만 제공하며 Adobe 앱과의 통합은 불가능합니다. 저는 무료 버전을 사용해보고 그 결과물에 너무 감탄한 나머지, 결국 프로 버전으로 업그레이드했습니다. 프로 버전은 추가 크레딧, 프리미엄 기능, Adobe 앱 통합, 그리고 ChatGPT 및 Gemini와 같은 파트너 AI 모델에 대한 접근을 가능하게 합니다.</p>\n<div style=\"background-color: #fce8e6; border-left: 4px solid #d93025; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">⚠️ 주의: 생성형 AI 이미지의 저작권 문제나 상업적 이용 가능 여부는 플랫폼마다 다릅니다. Adobe Firefly는 상업적 사용에 안전하다고 명시하고 있으나, 다른 도구를 사용할 때는 반드시 라이선스 규정을 확인해야 합니다.</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">만약 여러분이 디지털 아티스트, 소셜 미디어 관리자 또는 소규모 사업자라면, Firefly의 유료 버전은 충분히 그만한 가치를 할 것입니다. 특히 기존 어도비 사용자라면 워크플로우를 혁신할 수 있는 최고의 도구가 될 거예요.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/cyYeS0/dJMcabCVs9H/DeS6MtBtBdaDZRT573gyBk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cyYeS0/dJMcabCVs9H/DeS6MtBtBdaDZRT573gyBk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cyYeS0/dJMcabCVs9H/DeS6MtBtBdaDZRT573gyBk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcyYeS0%2FdJMcabCVs9H%2FDeS6MtBtBdaDZRT573gyBk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"Adobe Firefly의 강력한 생성형 이미지 기능을 활용해 독창적인 비주얼 콘텐츠를 만드는 디지털 아티스트.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>3. Notion AI: 스마트한 작업 공간의 완성  </b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">Notion은 이미 강력한 디지털 워크스페이스로서 우리의 정리 정돈을 돕는 유능한 도구입니다. 여기에 Notion AI가 더해지면 여러분의 생산성은 완전히 새로운 수준으로 도약합니다. 텍스트를 생성하는 데 도움이 되는 많은 도구들이 있지만, Notion AI는 <b>기존 Notion 워크스페이스에 통합</b>되어 있어 훨씬 더 유용하고 손쉽게 사용할 수 있다는 장점이 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">Notion AI는 글쓰기 도우미, AI 챗봇, 그리고 스마트 검색 엔진 역할을 한 곳에서 모두 수행합니다. 블로그 게시물 초안을 작성하거나, 아이디어를 브레인스토밍하고, 페이지를 다른 언어로 번역하는 등 훨씬 더 많은 작업을 할 수 있죠. 또한, 여러분의 워크스페이스 또는 Slack, Google Drive와 같은 연결된 앱에서 특정 질문을 할 수도 있습니다. 예를 들어, &ldquo;내 최종 선정 피치는 무엇이었지?&rdquo;라고 물으면, Notion AI가 최근 Slack 대화를 스캔하여 관련 결과를 가져다줄 것입니다.</p>\n<h3 data-ke-size=\"size23\"><b>Notion AI로 달라지는 워크플로우</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">Notion AI는 문서 디자인 개선을 제안하거나 PDF를 분석하여 핵심 요점을 추출해주는 데도 도움을 줄 수 있습니다. 저는 몇 년 동안 Notion을 사용해왔고, 무료 버전도 상당히 관대하다고 생각했습니다. 하지만 유료 버전은 협업 도구, 무제한 파일 업로드, 우선 지원, 비공개 팀 공간 등 유용한 추가 혜택을 제공합니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">특히 유료 버전에서 제공되는 Notion AI는 이 워크스페이스를 단순한 아이디어 기록 공간이 아니라, <b>모든 업무의 파트너</b>로 탈바꿈시켰습니다. 만약 여러분이 프리랜서, 크리에이터, 또는 작업을 정리하고 자주 협업해야 하는 사람이라면, Notion의 유료 구독에 투자하는 것은 매우 합리적인 선택이 될 것입니다.</p>\n<table style=\"width: 100%; border-collapse: collapse; margin: 25px 0; color: #3c4043;\" data-ke-align=\"alignLeft\">\n<thead>\n<tr style=\"background-color: #e8eaed;\">\n<th style=\"border: 1px solid #dadce0; padding: 12px; text-align: left; color: #3c4043;\">주요 AI 기능</th>\n<th style=\"border: 1px solid #dadce0; padding: 12px; text-align: left; color: #3c4043;\">활용 예시 및 이점</th>\n</tr>\n</thead>\n<tbody>\n<tr style=\"background-color: #f1f3f4;\">\n<td style=\"border: 1px solid #dadce0; padding: 12px; color: #3c4043;\">텍스트 생성 및 편집</td>\n<td style=\"border: 1px solid #dadce0; padding: 12px; color: #3c4043;\">블로그 초안, 아이디어 브레인스토밍, 보고서 요약, 문법 교정 등을 Notion 내에서 바로 처리</td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #dadce0; padding: 12px; color: #3c4043;\">워크스페이스 질문/검색</td>\n<td style=\"border: 1px solid #dadce0; padding: 12px; color: #3c4043;\">Slack, Google Drive 등 연동된 앱의 정보까지 통합 검색하여 필요한 정보를 빠르게 찾음</td>\n</tr>\n<tr style=\"background-color: #f1f3f4;\">\n<td style=\"border: 1px solid #dadce0; padding: 12px; color: #3c4043;\">PDF 분석 및 요약</td>\n<td style=\"border: 1px solid #dadce0; padding: 12px; color: #3c4043;\">긴 PDF 문서의 핵심 내용을 파악하고 질문에 대한 답변을 얻어 시간 절약</td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #dadce0; padding: 12px; color: #3c4043;\">디자인 및 레이아웃 개선</td>\n<td style=\"border: 1px solid #dadce0; padding: 12px; color: #3c4043;\">Notion 페이지의 가독성 및 시각적 매력을 높이는 AI 기반 제안 받기</td>\n</tr>\n</tbody>\n</table>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>AI 도구, 언제 유료 버전을 선택해야 할까요?  </b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">피드에 뜨는 모든 AI 도구에 비용을 지불하고 싶은 유혹을 느끼는 것은 당연합니다. 하지만 신중한 접근 방식은 불필요한 디지털 혼란과 지출을 피하는 데 도움이 될 수 있습니다. 만약 여러분이 <b>전문가이거나 AI를 계획, 글쓰기, 코딩, 또는 창의적인 워크플로우에 깊이 통합하려는 사람</b>이라면, AI 도구에 비용을 지불하는 것이 합리적입니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">유료 버전은 다음과 같은 이점을 제공합니다:</p>\n<ul style=\"list-style-type: disc; padding-left: 20px; margin-bottom: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px;\"><b>더욱 고급스러운 기능</b>: 무료 버전에는 없는 전문가용 기능을 활용할 수 있습니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>강화된 보안 및 신뢰성</b>: 민감한 데이터를 다루거나 중요한 프로젝트에 사용할 때 더욱 안심할 수 있습니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>고품질 결과물</b>: 더 유능한 AI 모델에 접근하여 훨씬 정교하고 만족스러운 결과물을 얻을 수 있습니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>우선 지원 및 통합 혜택</b>: 문제 발생 시 빠른 지원을 받거나 다른 서비스와의 연동성을 높일 수 있습니다.</li>\n</ul>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">결론적으로, AI를 집약적으로 사용하고 고품질 결과를 얻기 위해 더 유능한 AI 모델에 접근하고 싶다면 유료 버전은 충분히 그 가치를 합니다. 반면에 AI를 가끔씩만 사용하고 작업을 자동화하는 데 AI에 의존하지 않는 캐주얼 사용자라면, 무료 버전을 고수하는 것도 좋은 생각입니다. 무료 버전만으로도 여러분의 요구 사항과 기대치의 80%는 충족될 수 있습니다. 무료 버전은 가벼운 사용이나 실험에는 훌륭하지만, 깊이와 신뢰성이 부족할 수 있습니다. 이 점을 크게 신경 쓰지 않는다면 무료 버전을 계속 사용하는 것이 현명할 수 있습니다.</p>\n<!-- 핵심 요약 카드 -->\n<div style=\"background-color: #f8f9fa; border: 1px solid #dadce0; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); padding: 25px; margin: 30px 0;\">\n<div style=\"font-size: 26px; color: #1a73e8; font-weight: bold; margin-bottom: 15px; padding-bottom: 10px; border-bottom: 2px solid #1a73e8;\">  핵심 요약</div>\n<div style=\"font-size: 17px; line-height: 1.8; color: #3c4043;\">\n<p style=\"margin-bottom: 10px;\" data-ke-size=\"size16\">1. <b>ChatGPT Plus</b>는 더욱 <b>정교한 추론 능력</b>과 <b>빠른 응답 속도</b>로 전문적인 작업에 필수적입니다.</p>\n<p style=\"margin-bottom: 10px;\" data-ke-size=\"size16\">2. <b>Adobe Firefly</b>는 <b>상업적으로 안전한 고품질 이미지</b>를 생성하며, Adobe Creative Cloud와의 <b>최고의 통합성</b>을 자랑합니다.</p>\n<p style=\"margin-bottom: 10px;\" data-ke-size=\"size16\">3. <b>Notion AI</b>는 기존 Notion 워크스페이스에 <b>AI 기능을 완벽하게 통합</b>하여 생산성을 극대화하는 올인원 비서입니다.</p>\n<p style=\"margin-bottom: 0;\" data-ke-size=\"size16\">4. AI 유료 버전은 <b>집약적인 사용</b>과 <b>고품질 결과</b>가 필요한 전문가에게, 무료 버전은 <b>가벼운 실험 및 캐주얼 사용자</b>에게 적합합니다.</p>\n</div>\n<div style=\"font-size: 14px; color: #5f6368; margin-top: 25px; padding-top: 15px; border-top: 1px solid #dadce0;\">* 이 정보는 2026년 1월 14일 기준으로 작성되었습니다.</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q1: 2026년 현재, 어떤 AI 도구가 가장 전문가에게 추천되나요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A1: 2026년 현재, 전문가들 사이에서 가장 각광받고 있는 AI 도구는 ChatGPT Plus, Adobe Firefly, Notion AI입니다. 이들은 각자의 분야에서 독보적인 기능과 효율성을 제공하여 작업의 질과 생산성을 크게 향상시킬 수 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q2: ChatGPT Plus는 무료 버전과 비교하여 어떤 점이 크게 다른가요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A2: ChatGPT Plus는 최신 모델인 ChatGPT 5 접근, 피크 시간대 대기열 없음, 더 빠른 응답 속도, 복잡한 프롬프트 처리 능력 향상, 그리고 훨씬 더 정교하고 창의적인 답변을 제공합니다. 이는 비즈니스 아이디어 구상, 코드 디버깅, 콘텐츠 생성 등 전문적인 작업에 필수적인 요소입니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q3: Adobe Firefly를 사용해야 하는 주된 이유는 무엇인가요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A3: Adobe Firefly는 상업적으로 안전하게 사용할 수 있는 고품질 이미지를 생성하며, 텍스트 효과 적용 등 강력한 텍스트-이미지 변환 기능을 제공합니다. 특히 Adobe Creative Cloud 제품군과의 완벽한 통합으로 기존 디자인 워크플로우를 더욱 효율적으로 만듭니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q4: Notion AI가 다른 생산성 AI 도구와 차별화되는 점은 무엇인가요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A4: Notion AI는 기존 Notion 워크스페이스에 깊이 통합되어 있어, 별도의 도구를 오갈 필요 없이 바로 작업을 수행할 수 있습니다. 글쓰기, 아이디어 구상, 번역은 물론, 연결된 앱(Slack, Google Drive 등)의 정보를 바탕으로 스마트 검색과 요약 기능을 제공하여 통합적인 생산성 향상을 돕습니다.</p>\n<script type=\"application/ld+json\">\n    {\n      \"@context\": \"https://schema.org\",\n      \"@type\": \"FAQPage\",\n      \"mainEntity\": [\n        {\n          \"@type\": \"Question\",\n          \"name\": \"2026년 현재, 어떤 AI 도구가 가장 전문가에게 추천되나요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"2026년 현재, 전문가들 사이에서 가장 각광받고 있는 AI 도구는 ChatGPT Plus, Adobe Firefly, Notion AI입니다. 이들은 각자의 분야에서 독보적인 기능과 효율성을 제공하여 작업의 질과 생산성을 크게 향상시킬 수 있습니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"ChatGPT Plus는 무료 버전과 비교하여 어떤 점이 크게 다른가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"ChatGPT Plus는 최신 모델인 ChatGPT 5 접근, 피크 시간대 대기열 없음, 더 빠른 응답 속도, 복잡한 프롬프트 처리 능력 향상, 그리고 훨씬 더 정교하고 창의적인 답변을 제공합니다. 이는 비즈니스 아이디어 구상, 코드 디버깅, 콘텐츠 생성 등 전문적인 작업에 필수적인 요소입니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"Adobe Firefly를 사용해야 하는 주된 이유는 무엇인가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"Adobe Firefly는 상업적으로 안전하게 사용할 수 있는 고품질 이미지를 생성하며, 텍스트 효과 적용 등 강력한 텍스트-이미지 변환 기능을 제공합니다. 특히 Adobe Creative Cloud 제품군과의 완벽한 통합으로 기존 디자인 워크플로우를 더욱 효율적으로 만듭니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"Notion AI가 다른 생산성 AI 도구와 차별화되는 점은 무엇인가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"Notion AI는 기존 Notion 워크스페이스에 깊이 통합되어 있어, 별도의 도구를 오갈 필요 없이 바로 작업을 수행할 수 있습니다. 글쓰기, 아이디어 구상, 번역은 물론, 연결된 앱(Slack, Google Drive 등)의 정보를 바탕으로 스마트 검색과 요약 기능을 제공하여 통합적인 생산성 향상을 돕습니다.\"\n          }\n        }\n      ]\n    }\n    </script>\n<p style=\"margin-bottom: 20px; font-size: 15px; text-align: center; color: #5f6368; margin-top: 30px;\" data-ke-size=\"size16\">AI 기술은 계속해서 발전하고 있습니다. 오늘 소개된 AI 3대장이 여러분의 2026년을 더욱 빛나게 하기를 바랍니다. <br />궁금한 점이나 의견이 있다면 언제든지 댓글로 남겨주세요!</p>\n</div>",
        "contentSnippet": "매일 새로운 AI 도구가 쏟아져 나오는 2026년, 어떤 도구가 정말 우리의 시간과 돈을 투자할 가치가 있을까요? 수많은 AI 서비스 중에서 제가 직접 경험하고 전문가들이 극찬하는 단 세 가지 AI 도구, ChatGPT Plus, Adobe Firefly, 그리고 Notion AI를 심층 분석합니다. 이 글을 통해 여러분의 업무 생산성과 창의력을 한 차원 높여줄 현명한 AI 선택 가이드를 얻어가시길 바랍니다.\n\n\nAI 홍수 시대, 진짜배기를 찾아서  \n사랑하든 싫어하든, 인공지능은 2026년 현재 우리의 삶 곳곳에 스며들어 있습니다. 매일같이 창의력, 생산성, 글쓰기 능력을 향상시키고 삶을 더 쉽게 만들어주겠다고 약속하는 새로운 AI 도구들이 쏟아져 나오고 있죠. 하지만 AI 시장이 팽창하면서 혼란도 함께 가중되고 있습니다. 너무나도 유혹적인 선택지, 수많은 구독 서비스, 인상적인 기능 목록 속에서 필요한지조차 불분명한 AI 도구에 쉽게 지갑을 열게 되는 경우가 많습니다.\n하지만 모든 AI 도구가 똑같지는 않습니다. 어떤 도구들은 터무니없이 비싸거나 그저 겉만 번지르르한 기능으로 가득한 반면, 소수의 도구들은 실제로 비용을 정당화할 만큼 뛰어난 성능을 발휘합니다. 저는 지난 몇 년간 생산성, 이미지 생성 등 다양한 분야의 여러 AI 도구들을 직접 시험하고 사용해봤어요. 솔직히 말해서 대부분의 AI 도구는 돈 낭비라고 생각했습니다. 그럼에도 불구하고, 실제로 돈을 지불할 가치가 있다고 확신하는 세 가지 도구를 발견했습니다. 이제 그 세 가지 AI 3대장을 심층적으로 파헤쳐 볼 시간입니다.\n1. ChatGPT Plus: 대화형 AI의 기준을 높이다  \n혹시 AI 챗봇을 사용해보고는 기대 이하였다고 실망한 적 있으신가요? 아마 여러분만 그런 것은 아닐 거예요. 무료 버전의 챗봇들은 보통 느린 속도, 기본 모델, 사용량 제한, 그리고 한정된 기능을 제공하기 마련이죠. 저 역시 몇 주 동안 ChatGPT 무료 버전을 사용했습니다. 주로 아이디어를 브레인스토밍하고, 복잡한 정보를 요약하고, 일정을 계획하거나, 새로운 쇼핑 리서치 기능을 시도하는 데 사용했죠.\n몇 주간 사용한 후, 저는 ChatGPT Plus로 업그레이드를 결정했습니다. 이미 많은 친구들이 사용하며 만족하고 있었거든요. 그리고 Plus 버전으로 전환했을 때, 단순히 업그레이드를 넘어선 완전히 새로운 경험이라는 것을 깨달았습니다. 정말 게임 체인저였어요.\nChatGPT Plus, 왜 전문가들의 선택일까요?\n월 20달러라는 합리적인 비용으로, 여러분은 더 나은 추론 능력을 가진 최첨단 ChatGPT 5 모델에 접근할 수 있게 됩니다. 이 모델은 복잡한 프롬프트를 훨씬 더 잘 처리하고, 맥락을 정확하게 이해하며, 더 스마트하고 신뢰할 수 있는 답변을 제공합니다. 게다가 피크 시간대에 대기할 필요 없이 우선적인 접근 권한을 얻어 더 빠른 응답을 받을 수 있습니다.\n무엇보다 ChatGPT Plus는 더 나은 설명, 뛰어난 지원, 그리고 창의적인 답변을 제공하는 데 탁월합니다. 비즈니스 아이디어를 브레인스토밍하고 싶을 때, 코드를 디버깅해야 할 때, 답변에 창의성을 더하고 싶을 때, 또는 일상적인 작업을 자동화하고 싶을 때, ChatGPT Plus의 고급 모델은 비교할 수 없는 신뢰할 수 있는 결과를 제공할 것입니다.\n  팁: ChatGPT Plus를 사용하면 복잡한 데이터 분석, 장문의 보고서 요약, 심지어 특정 주제에 대한 심도 있는 연구까지 훨씬 빠르고 정확하게 수행할 수 있습니다. 여러분의 디지털 비서가 한 단계 더 진화하는 경험을 할 수 있을 거예요.\n\n\n2. Adobe Firefly: 창의력을 현실로, 상업적 활용까지  \n만약 여러분이 소셜 미디어 게시물, 일러스트레이션, 제품 이미지 또는 디자인 프로토타입과 같은 시각적 콘텐츠를 생성하는 사람이라면, 이미 인기 있는 생성형 이미지 도구들을 사용해봤을 가능성이 높습니다. 이들 중 많은 도구가 무료로 제공되지만, 소수의 도구만이 놀라운 수준의 창의적 제어력을 선사합니다. 저는 Google의 Nano Banana, Midjourney, Canva, 그리고 Adobe Firefly를 사용해봤고, 각기 독특한 강점과 단점을 가지고 있었죠.\n그중에서도 저에게 특히 인상 깊었던 AI 이미지 생성 도구는 바로 Adobe Firefly였습니다. Firefly는 아름다운 Pinterest 스타일의 이미지를 자유롭게 만들 수 있게 해줄 뿐만 아니라, 전문가 수준의 에셋을 제공하고 상업적으로 안전하게 사용할 수 있는 결과물을 생성해줍니다. Firefly는 가장 유능한 텍스트-이미지 생성기 중 하나로, 텍스트 프롬프트만으로 텍스트 효과까지 적용할 수 있습니다.\nFirefly의 핵심 기능과 통합의 힘\n저는 온라인 비즈니스와 소셜 미디어를 위한 몇몇 이미지를 생성해 보았는데, 결과물이 정말 마음에 들었습니다. Firefly는 여러분의 창의적인 갈증을 해소해줄 수많은 스타일을 제공합니다. Firefly의 가장 큰 장점 중 하나는 Adobe Creative Cloud와의 완벽한 통합입니다. 덕분에 Generative Fill(생성형 채우기), Generative Recolor(생성형 재색상), Generative Expand(생성형 확장)와 같은 뛰어난 기능들을 Photoshop, Premiere Pro, Illustrator 등 핵심 앱 내에서 바로 사용할 수 있습니다.\n무료 버전은 제한된 크레딧, 워터마크가 있는 결과물, 기본적인 기능만 제공하며 Adobe 앱과의 통합은 불가능합니다. 저는 무료 버전을 사용해보고 그 결과물에 너무 감탄한 나머지, 결국 프로 버전으로 업그레이드했습니다. 프로 버전은 추가 크레딧, 프리미엄 기능, Adobe 앱 통합, 그리고 ChatGPT 및 Gemini와 같은 파트너 AI 모델에 대한 접근을 가능하게 합니다.\n⚠️ 주의: 생성형 AI 이미지의 저작권 문제나 상업적 이용 가능 여부는 플랫폼마다 다릅니다. Adobe Firefly는 상업적 사용에 안전하다고 명시하고 있으나, 다른 도구를 사용할 때는 반드시 라이선스 규정을 확인해야 합니다.\n만약 여러분이 디지털 아티스트, 소셜 미디어 관리자 또는 소규모 사업자라면, Firefly의 유료 버전은 충분히 그만한 가치를 할 것입니다. 특히 기존 어도비 사용자라면 워크플로우를 혁신할 수 있는 최고의 도구가 될 거예요.\n\n\n3. Notion AI: 스마트한 작업 공간의 완성  \nNotion은 이미 강력한 디지털 워크스페이스로서 우리의 정리 정돈을 돕는 유능한 도구입니다. 여기에 Notion AI가 더해지면 여러분의 생산성은 완전히 새로운 수준으로 도약합니다. 텍스트를 생성하는 데 도움이 되는 많은 도구들이 있지만, Notion AI는 기존 Notion 워크스페이스에 통합되어 있어 훨씬 더 유용하고 손쉽게 사용할 수 있다는 장점이 있습니다.\nNotion AI는 글쓰기 도우미, AI 챗봇, 그리고 스마트 검색 엔진 역할을 한 곳에서 모두 수행합니다. 블로그 게시물 초안을 작성하거나, 아이디어를 브레인스토밍하고, 페이지를 다른 언어로 번역하는 등 훨씬 더 많은 작업을 할 수 있죠. 또한, 여러분의 워크스페이스 또는 Slack, Google Drive와 같은 연결된 앱에서 특정 질문을 할 수도 있습니다. 예를 들어, “내 최종 선정 피치는 무엇이었지?”라고 물으면, Notion AI가 최근 Slack 대화를 스캔하여 관련 결과를 가져다줄 것입니다.\nNotion AI로 달라지는 워크플로우\nNotion AI는 문서 디자인 개선을 제안하거나 PDF를 분석하여 핵심 요점을 추출해주는 데도 도움을 줄 수 있습니다. 저는 몇 년 동안 Notion을 사용해왔고, 무료 버전도 상당히 관대하다고 생각했습니다. 하지만 유료 버전은 협업 도구, 무제한 파일 업로드, 우선 지원, 비공개 팀 공간 등 유용한 추가 혜택을 제공합니다.\n특히 유료 버전에서 제공되는 Notion AI는 이 워크스페이스를 단순한 아이디어 기록 공간이 아니라, 모든 업무의 파트너로 탈바꿈시켰습니다. 만약 여러분이 프리랜서, 크리에이터, 또는 작업을 정리하고 자주 협업해야 하는 사람이라면, Notion의 유료 구독에 투자하는 것은 매우 합리적인 선택이 될 것입니다.\n주요 AI 기능\n활용 예시 및 이점\n\n\n\n\n텍스트 생성 및 편집\n블로그 초안, 아이디어 브레인스토밍, 보고서 요약, 문법 교정 등을 Notion 내에서 바로 처리\n\n\n워크스페이스 질문/검색\nSlack, Google Drive 등 연동된 앱의 정보까지 통합 검색하여 필요한 정보를 빠르게 찾음\n\n\nPDF 분석 및 요약\n긴 PDF 문서의 핵심 내용을 파악하고 질문에 대한 답변을 얻어 시간 절약\n\n\n디자인 및 레이아웃 개선\nNotion 페이지의 가독성 및 시각적 매력을 높이는 AI 기반 제안 받기\n\n\n\nAI 도구, 언제 유료 버전을 선택해야 할까요?  \n피드에 뜨는 모든 AI 도구에 비용을 지불하고 싶은 유혹을 느끼는 것은 당연합니다. 하지만 신중한 접근 방식은 불필요한 디지털 혼란과 지출을 피하는 데 도움이 될 수 있습니다. 만약 여러분이 전문가이거나 AI를 계획, 글쓰기, 코딩, 또는 창의적인 워크플로우에 깊이 통합하려는 사람이라면, AI 도구에 비용을 지불하는 것이 합리적입니다.\n유료 버전은 다음과 같은 이점을 제공합니다:\n더욱 고급스러운 기능: 무료 버전에는 없는 전문가용 기능을 활용할 수 있습니다.\n강화된 보안 및 신뢰성: 민감한 데이터를 다루거나 중요한 프로젝트에 사용할 때 더욱 안심할 수 있습니다.\n고품질 결과물: 더 유능한 AI 모델에 접근하여 훨씬 정교하고 만족스러운 결과물을 얻을 수 있습니다.\n우선 지원 및 통합 혜택: 문제 발생 시 빠른 지원을 받거나 다른 서비스와의 연동성을 높일 수 있습니다.\n결론적으로, AI를 집약적으로 사용하고 고품질 결과를 얻기 위해 더 유능한 AI 모델에 접근하고 싶다면 유료 버전은 충분히 그 가치를 합니다. 반면에 AI를 가끔씩만 사용하고 작업을 자동화하는 데 AI에 의존하지 않는 캐주얼 사용자라면, 무료 버전을 고수하는 것도 좋은 생각입니다. 무료 버전만으로도 여러분의 요구 사항과 기대치의 80%는 충족될 수 있습니다. 무료 버전은 가벼운 사용이나 실험에는 훌륭하지만, 깊이와 신뢰성이 부족할 수 있습니다. 이 점을 크게 신경 쓰지 않는다면 무료 버전을 계속 사용하는 것이 현명할 수 있습니다.\n  핵심 요약\n1. ChatGPT Plus는 더욱 정교한 추론 능력과 빠른 응답 속도로 전문적인 작업에 필수적입니다.\n2. Adobe Firefly는 상업적으로 안전한 고품질 이미지를 생성하며, Adobe Creative Cloud와의 최고의 통합성을 자랑합니다.\n3. Notion AI는 기존 Notion 워크스페이스에 AI 기능을 완벽하게 통합하여 생산성을 극대화하는 올인원 비서입니다.\n4. AI 유료 버전은 집약적인 사용과 고품질 결과가 필요한 전문가에게, 무료 버전은 가벼운 실험 및 캐주얼 사용자에게 적합합니다.\n* 이 정보는 2026년 1월 14일 기준으로 작성되었습니다.\n❓ 자주 묻는 질문 (FAQ)\nQ1: 2026년 현재, 어떤 AI 도구가 가장 전문가에게 추천되나요?\nA1: 2026년 현재, 전문가들 사이에서 가장 각광받고 있는 AI 도구는 ChatGPT Plus, Adobe Firefly, Notion AI입니다. 이들은 각자의 분야에서 독보적인 기능과 효율성을 제공하여 작업의 질과 생산성을 크게 향상시킬 수 있습니다.\nQ2: ChatGPT Plus는 무료 버전과 비교하여 어떤 점이 크게 다른가요?\nA2: ChatGPT Plus는 최신 모델인 ChatGPT 5 접근, 피크 시간대 대기열 없음, 더 빠른 응답 속도, 복잡한 프롬프트 처리 능력 향상, 그리고 훨씬 더 정교하고 창의적인 답변을 제공합니다. 이는 비즈니스 아이디어 구상, 코드 디버깅, 콘텐츠 생성 등 전문적인 작업에 필수적인 요소입니다.\nQ3: Adobe Firefly를 사용해야 하는 주된 이유는 무엇인가요?\nA3: Adobe Firefly는 상업적으로 안전하게 사용할 수 있는 고품질 이미지를 생성하며, 텍스트 효과 적용 등 강력한 텍스트-이미지 변환 기능을 제공합니다. 특히 Adobe Creative Cloud 제품군과의 완벽한 통합으로 기존 디자인 워크플로우를 더욱 효율적으로 만듭니다.\nQ4: Notion AI가 다른 생산성 AI 도구와 차별화되는 점은 무엇인가요?\nA4: Notion AI는 기존 Notion 워크스페이스에 깊이 통합되어 있어, 별도의 도구를 오갈 필요 없이 바로 작업을 수행할 수 있습니다. 글쓰기, 아이디어 구상, 번역은 물론, 연결된 앱(Slack, Google Drive 등)의 정보를 바탕으로 스마트 검색과 요약 기능을 제공하여 통합적인 생산성 향상을 돕습니다.\nAI 기술은 계속해서 발전하고 있습니다. 오늘 소개된 AI 3대장이 여러분의 2026년을 더욱 빛나게 하기를 바랍니다. \n궁금한 점이나 의견이 있다면 언제든지 댓글로 남겨주세요!",
        "guid": "https://muzbox.tistory.com/483699",
        "categories": [
          "AI, 미래기술/AI 인사이트",
          "2026년 AI 도구",
          "Adobe Firefly 활용",
          "AI 유료 버전 장점",
          "AI 이미지 생성",
          "ai 챗봇 비교",
          "ai 협업 도구",
          "chatgpt plus 기능",
          "Notion AI 생산성",
          "생성형 ai 추천",
          "전문가 AI 추천"
        ],
        "isoDate": "2026-01-14T01:26:50.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "SEO는 끝났다? 2026년 콘텐츠 성공 공식, 생성형 엔진 최적화(GEO) 마스터하",
        "link": "https://muzbox.tistory.com/483698",
        "pubDate": "Sun, 11 Jan 2026 12:16:50 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "https://muzbox.tistory.com/483698#entry483698comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #3c4043;\">\n<div style=\"background-color: #e8f4fd; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">2026년, 디지털 콘텐츠 시장은 거대한 변화의 물결에 휩싸였습니다. 이제는 단순히 키워드를 나열하는 SEO 시대가 아닌, 생성형 AI 검색(SGE/CUE)이 지배하는 <b>GEO(Generative Engine Optimization)</b> 시대가 도래했죠. AI는 더 이상 단순한 도구가 아니라, 콘텐츠의 생존과 수익을 결정하는 핵심 플레이어가 되었습니다. 이 글에서는 <b>AI 슬롭(AI Slop)</b>의 함정을 피하고, <b>HIT(Human in the Loop) 전략</b>을 통해 여러분의 콘텐츠를 AI 시대의 핵심 자산으로 만드는 구체적인 방법을 제시합니다. 키워드의 종말부터 제로 클릭 검색, 유튜브 알고리즘의 변화, 그리고 커뮤니티 기반 수익화까지, 새로운 디지털 수익화 공식을 파헤쳐 보세요.</p>\n</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/blxTmx/dJMcajnl3Z1/oeMoVmmfCgNW82y61wZZqk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/blxTmx/dJMcajnl3Z1/oeMoVmmfCgNW82y61wZZqk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/blxTmx/dJMcajnl3Z1/oeMoVmmfCgNW82y61wZZqk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FblxTmx%2FdJMcajnl3Z1%2FoeMoVmmfCgNW82y61wZZqk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"낡은 돋보기가 있는 SEO 영역에서 빛나는 AI 네트워크로 전환되는 디지털 풍경. AI가 콘텐츠를 선별하고 인용하는 GEO 시대의 도래를 상징합니다.\" loading=\"lazy\" width=\"500\" height=\"500\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">여러분, 2026년 바로 이 시점에서 혹시 유튜브나 블로그 수익이 갑자기 0원이 될 수도 있다는 사실을 알고 계셨나요? 물론, 단순히 겁을 주려는 이야기는 아닙니다. 구글과 유튜브의 새로운 AI 알고리즘이 여러분의 콘텐츠를 &lsquo;AI 스팸&rsquo;으로 분류하는 순간, 공들여 만든 모든 것이 검색 결과에서 사라져 버릴 수 있다는 현실적인 경고입니다. 실제로 일부 유튜브 쇼츠 채널들이 이미 이 <b>AI 슬롭(AI Slop)</b>이라는 함정에 빠져 어려움을 겪고 있고요. 그렇다면 이 거대한 변화 속에서 우리는 어떻게 살아남을 수 있을까요? 이 위기를 오히려 기회로 바꾸는 방법은 없을까요? 지금부터 2026년 디지털 수익화의 새로운 공식을 하나하나 파헤쳐 보겠습니다.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  2026년, 디지털 수익의 대격변: SEO에서 GEO로</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">최근 최신 컨설팅 보고서들을 리서치하면서 정말 놀라운 사실을 깨달았습니다. 우리가 익히 알던 기존의 검색 방식, 즉 <b>SEO(Search Engine Optimization)</b> 게임의 룰이 완전히 바뀌었다는 것입니다. 아니, 바뀌었다기보다는 이제는 거의 종착역에 도달했다고 보는 게 맞을 것 같아요. 이제는 <b>GEO(Generative Engine Optimization)</b>, 즉 생성형 엔진 최적화라는 완전히 새로운 게임이 시작된 거죠. 이 변화는 단순히 검색 알고리즘의 업데이트 수준을 넘어선, 디지털 수익 생태계 전체의 대격변을 의미합니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">그렇다면 이 AI가 모든 것을 지배하는 새로운 환경에서 어떻게 해야 내 블로그나 유튜브 채널이 알고리즘의 처벌을 피하고, 오히려 AI의 선택을 받는 핵심 자산이 될 수 있을까요? 우리의 목표는 명확합니다. AI를 단순히 글이나 영상을 좀 더 편리하게 만들어주는 &lsquo;도우미&rsquo; 정도로 생각하는 것이 아니라, 우리의 가장 강력한 <b>전략적 무기</b>로 활용하는 방법을 알아내는 것이죠. 이제 AI는 선택이 아닌 필수이자, 제대로 활용한다면 상상 이상의 성과를 가져다줄 열쇠가 될 겁니다.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  키워드의 종말과 주제 권위성의 시대</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">가장 근본적인 변화부터 짚고 넘어가죠. 바로 <b>키워드의 종말</b>입니다. 예전에는 '강남역 맛집'이라는 글을 쓸 때, 본문에 이 단어를 스무 번씩 반복해서 넣는 것이 일종의 '정석'처럼 여겨졌죠. 하지만 2026년 현재, 이런 전략은 더 이상 아무런 의미가 없습니다. 아니, 오히려 <b>어뷰징(abusing)</b>으로 분류되어 감점 요인이 될 수도 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">구글의 <b>SGE(Search Generative Experience)</b>나 네이버의 CUE와 같은 생성형 엔진들은 이제 단어의 개수를 세는 것을 넘어, 콘텐츠의 <b>문맥과 의도</b>를 파악합니다. 그들이 집중하는 핵심은 단 하나입니다. <b>&ldquo;이 콘텐츠를 만든 사람이 이 주제에 대해 얼마나 깊이 있는 진짜 전문가인가?&rdquo;</b> 바로 이 '주제 권위성'을 평가하는 거죠.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">예를 들어, 여러분이 'AI 콘텐츠 마케팅'이라는 주제로 블로그를 운영한다고 가정해 봅시다. 과거에는 이 키워드를 포함한 글을 여러 개 발행했을 거예요. 하지만 이제는 접근법이 완전히 달라져야 합니다. 'AI 마케팅의 미래는?', 'AI 마케팅 툴 10가지 비교', 'AI 마케팅 실패 사례 분석' 등 사람들이 이 주제에 대해 궁금해할 만한 50개 이상의 세부 질문에 대해 각각 깊이 있는 답변을 제공하는 <b>콘텐츠 클러스터(Content Cluster)</b>를 구축해야 합니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">전체 콘텐츠의 80% 이상을 하나의 전문 주제에 집중할 때, AI는 비로소 여러분을 '믿을 만한 전문가'로 인식하고 검색 결과 상단에 적극적으로 노출하기 시작합니다. 여러 주제를 얕게 다루는 시대는 이제 정말 끝났다고 봐도 무방합니다.</p>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>GEO 시대의 핵심:</b> AI는 단순히 키워드가 아닌, 콘텐츠의 <b>문맥과 작성자의 전문성</b>을 평가합니다. 하나의 주제에 깊이 파고들어 '주제 권위성'을 확보하는 것이 중요해요.</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  제로 클릭 검색과 새로운 포지션 제로</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">여기서 더 충격적인 사실이 있습니다. 아무리 열심히 노력해서 전문가로 인정받아도, 정작 사람들이 여러분의 사이트를 클릭하지 않을 수도 있다는 거예요. 우리는 이를 <b>제로 클릭 검색(Zero-Click Search)</b>이라고 부릅니다. 말 그대로 검색 결과 페이지에서 웹사이트로의 클릭이 발생하지 않는 현상이죠. 최신 데이터에 따르면, 데스크톱 검색의 무려 46.5%, 거의 절반에 달하는 사용자들이 AI가 요약해 준 답변만 보고 검색을 끝내버린다고 합니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이러한 변화로 인해 실제로 일부 글로벌 기업들은 자연 검색을 통한 방문자 수가 70%에서 80%까지 폭락하는 경험을 했습니다. 어제까지 1만 명이 방문하던 블로그에 갑자기 2천 명만 들어온다고 상상해 보세요. 정말 끔찍한 시나리오가 아닐 수 없습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">따라서 이제 우리의 목표는 단순히 '클릭'이 되어서는 안 됩니다. 우리의 새로운 목표는 AI가 만들어낸 답변에 여러분의 이름이나 브랜드가 <b>인용</b>되는 것입니다. 예를 들어, '이 내용에 대한 더 자세한 정보는 OOO의 블로그를 참고했습니다'와 같이 출처로 명시되는 것이죠. 이것이 바로 <b>새로운 포지션 제로(Position Zero)</b>, 즉 검색 결과 1위보다도 더 높은, AI 시대의 최고의 자리입니다. 내 콘텐츠가 AI 답변의 핵심 근거 자료로 채택되도록 만드는 것, 이것이 바로 GEO 시대의 진정한 승리 공식입니다.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  2026년형 유튜브 알고리즘의 진실: 시청자 만족도</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이러한 변화의 물결은 유튜브에서도 거세게 몰아치고 있습니다. 어떻게 보면 검색 엔진보다 훨씬 더 직접적이고 강력한 영향을 미치고 있다고 생각해요. 과거 유튜브 성공 공식은 뭐였을까요? 맞습니다. 조회수와 시청 시간이었죠. 그래서 어떻게든 자극적인 썸네일과 제목으로 클릭을 유도하고, 일단 시청자를 영상에 붙잡아두는 것이 중요했습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">하지만 2026년 현재, 유튜브 알고리즘은 오직 단 하나의 지표, 바로 <b>시청자 만족도</b>에만 집착합니다. 예를 들어, '초특가 아이폰 공짜로 사는 법' 같은 썸네일에 이끌려 영상을 클릭했는데, 막상 내용은 별것 없는 광고뿐이라면 시청자는 어떻게 반응할까요? 당연히 10초도 안 보고 영상을 꺼버리겠죠. 과거에는 이런 행동이 단순히 '이탈률이 높구나' 정도로 끝났지만, 이제는 다릅니다. 이탈하는 시청자의 행동 하나하나가 '이 채널은 시청자를 속이는 나쁜 채널'이라는 강력한 <b>패널티 신호</b>로 쌓이게 됩니다. 그리고 이 패널티는 해당 영상 하나로 끝나는 것이 아니라, 채널 전체의 노출량을 심각하게 깎아버리는 결과를 초래하죠.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이제부터 유튜브에서의 유일한 성공 공식은 아주 명확해졌습니다. 시청자가 여러분의 영상을 다 보고 나서 '아, 진짜 시간을 잘 썼다. 이 채널 구독하길 정말 잘했다'고 <b>진심으로 느끼게 만드는 것</b>. 이것이 바로 전부입니다. 시청자의 진정한 만족이 곧 채널의 성장으로 직결되는 시대가 온 거죠.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>⚙️ 3단계 하이브리드 퍼널 전략: AI 시대의 유튜브 성공 공식</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">그렇다면 이 완전히 새로운 전쟁터에서 우리는 어떻게 구체적으로 승리할 수 있을까요? 바로 2026년형 유튜브 성공 공식, <b>3단계 하이브리드 퍼널(Funnel) 전략</b>입니다. 이 전략은 AI 시대에 최적화된 시청자 유입부터 수익화까지의 로드맵을 제시합니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; font-weight: 600;\" data-ke-size=\"size23\">1단계: 유입 (Inflow) - 쇼츠를 정교한 필터로 활용</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 단계의 핵심 무기는 바로 <b>쇼츠(Shorts)</b>입니다. 하지만 여기서 우리는 쇼츠에 대한 기존의 생각을 완전히 바꿔야 해요. 2026년에 쇼츠는 더 이상 단순한 바이럴 도구가 아닙니다. 아무에게나 노출되어 조회수를 높이는 것이 아니라, <b>정확한 타깃 시청자만 걸러내는 아주 정교한 필터</b>로서의 역할을 수행해야 합니다. 주제에 관심도 없는 불특정 다수를 끌어모으는 것은 오히려 채널의 정체성을 흐리고 알고리즘에 나쁜 신호를 주는 최악의 전략이 될 수 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">예를 들어 볼까요? 여러분이 최신 스마트폰을 깊이 있게 리뷰하는 기술 채널을 운영한다고 가정해 봅시다. 여기서 갑자기 요즘 유행하는 댄스 챌린지 쇼츠를 올리면 어떻게 될까요? 물론 조회수는 잠깐 폭발할 수도 있겠죠. 하지만 그 영상을 보고 들어온 수만 명의 사람들은 여러분의 전문적인 기술 리뷰에는 전혀 관심이 없을 겁니다. 이런 상황은 알고리즘에게 '이 채널은 정체성이 모호하니 기술에 관심 있는 사람들에게 추천하지 말아야겠다'는 신호를 줄 수 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">대신에, 앞으로 리뷰할 스마트폰의 카메라 줌 기능을 100배 땡겨보는 10초짜리 쇼츠를 올려보세요. 그러면 정말 그 스마트폰 카메라 성능에 관심 있는 <b>잠재 고객들만</b> 여러분 채널로 유입될 겁니다. 이것이 바로 하이브리드 퍼널의 시작이자, 진짜 팬이 될 사람들을 모으는 첫 단추입니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/s9FqS/dJMcacohGrD/NoR9KDbqVeu0jh84ns1JT0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/s9FqS/dJMcacohGrD/NoR9KDbqVeu0jh84ns1JT0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/s9FqS/dJMcacohGrD/NoR9KDbqVeu0jh84ns1JT0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fs9FqS%2FdJMcacohGrD%2FNoR9KDbqVeu0jh84ns1JT0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"정교하게 데이터 흐름을 걸러내는 푸른색 디지털 필터. 유튜브 쇼츠가 특정 타깃 시청자를 선별하는 과정을 상징합니다.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; font-weight: 600;\" data-ke-size=\"size23\">2단계: 신뢰 구축 (Building Trust) - 롱폼과 LVR 지표</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">쇼츠라는 정교한 필터로 걸러진, 내 주제에 진짜 관심 있는 시청자들에게는 이제 <b>롱폼(Long-form)</b>, 즉 긴 영상으로 깊이 있는 정보를 제공하며 <b>신뢰</b>를 구축해야 합니다. '당신은 나를 믿어도 좋다'는 확실한 신호를 주는 단계죠. 여기서 핵심은 알고리즘에게 '이 영상은 시청자들을 아주 만족시키고 있습니다'라는 구체적인 신호를 계속 보내는 것입니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">아주 중요한 숫자를 하나 제시해 드릴게요. 바로 <b>좋아요/조회수 비율, LVR(Like View Ratio)</b>입니다. 이 비율이 2%라면 그냥 보통 영상이지만, <b>만약 4%를 넘어간다면</b> 유튜브 알고리즘은 '아, 이건 아주 훌륭한 영상이구나. 널리 알려야겠다'고 판단하여 추천을 폭발적으로 늘려준다고 합니다. 조회수가 1만 회인 영상이라면 좋아요가 최소 400개는 찍혀야 한다는 뜻이죠. LVR은 시청자가 '내 시간을 쓸 가치가 있었다'고 느끼는 가장 확실한 피드백이기 때문입니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">그럼 이 만족도를 어떻게 높일 수 있을까요? 두 가지 핵심 기술이 있습니다.</p>\n<ul style=\"list-style-type: disc; margin-left: 20px; margin-bottom: 20px; color: #3c4043;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px;\"><b>영상 시작 5초 안에 핵심 가치 제시:</b> '이 영상을 끝까지 보시면 당신은 이걸 얻어갈 수 있습니다'라는 명확한 가치를 제시해야 합니다. 두리뭉실하게 시작하면 시청자는 바로 이탈합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>2~3분마다 시각적 변화:</b> 사람의 집중력은 생각보다 짧습니다. 2~3분마다 의식적으로 화면 전환, 그래프 자료, 자막 강조 등 시각적인 변화를 주어 시청 유지율을 높여야 합니다.</li>\n</ul>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이러한 기술들로 시청 유지율을 높이고, 영상 마지막에는 '오늘 내용이 유익했다면 좋아요로 알려주세요'라고 정중하게 요청하여 LVR 4%를 달성하는 것, 이것이 이 단계의 중요한 목표입니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; font-weight: 600;\" data-ke-size=\"size23\">3단계: 수익화 (Monetization) - 커뮤니티 기반의 지속 가능한 수익</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">솔직히 말해서 2026년에 애드센스(AdSense)와 같은 광고 수익에만 의존하는 것은 매우 위험한 생각입니다. 최근 광고 수익의 중요도는 계속해서 낮아지고 있어요. 진짜 돈, 지속 가능한 수익은 여러분의 채널을 열성적으로 지지하는 팬덤, 바로 <b>커뮤니티</b>에서 나옵니다. 핵심 수익원은 크게 세 가지로 볼 수 있습니다.</p>\n<ul style=\"list-style-type: decimal; margin-left: 20px; margin-bottom: 20px; color: #3c4043;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px;\"><b>멤버십 (Memberships):</b> 채널의 유료 멤버십을 통해 독점 콘텐츠나 혜택을 제공합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>슈퍼챗 (Super Chat) 및 후원:</b> 라이브 스트리밍 시 시청자들의 자발적인 후원을 유도합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>브랜드 협력 (Brand Partnerships):</b> 채널의 전문성을 인정하는 브랜드와의 협업을 통해 수익을 창출합니다.</li>\n</ul>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">여기서 가장 중요한 건 '왜 나를 후원해야 하는가?'에 대한 명확한 <b>가치</b>를 제시하는 겁니다. 옛날처럼 '여러분의 후원이 제게 큰 힘이 됩니다' 같은 감성적인 호소는 더 이상 통하지 않아요. 시청자들은 명확한 가치 교환을 원합니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">예를 들면 이런 거죠. '제 채널에 VIP 멤버가 되시면 매주 목요일 저와 함께하는 비공개 실시간 Q&amp;A에 참여하실 수 있고, 제가 만드는 모든 강의 자료 원본 파일을 미리 받아보실 수 있습니다.' 어때요? 아주 구체적이고 매력적인 혜택을 줘야 하는 겁니다. 이것은 구글에 의존하는 것이 아니라, <b>당당한 비즈니스 모델</b>입니다. 이 개념으로 접근해야만 여러분의 채널이 단순한 취미가 아니라 지속 가능한 사업체가 될 수 있습니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/bCMGi4/dJMcahb3gwj/gYbL52FXkwFrxZhtt4K6k0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bCMGi4/dJMcahb3gwj/gYbL52FXkwFrxZhtt4K6k0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bCMGi4/dJMcahb3gwj/gYbL52FXkwFrxZhtt4K6k0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbCMGi4%2FdJMcahb3gwj%2FgYbL52FXkwFrxZhtt4K6k0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"서로 소통하며 활발하게 교류하는 다채로운 온라인 커뮤니티. 멤버십과 슈퍼챗을 통한 채널 수익화 및 팬덤 구축을 상징합니다.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✨ AI 자동화의 빛과 그림자: 생산성 혁명 vs. AI 슬롭 페널티</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이제 정말 흥미로운 이야기, <b>AI 자동화</b>로 넘어가 보겠습니다. AI는 마치 강력한 마법 지팡이 같아요. 이걸 잘 쓰면 생산성을 10배 이상 높이는 혁명의 도구가 되지만, 잘못 휘두르면 여러분의 모든 것을 파괴하는 저주의 함정이 될 수도 있습니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; font-weight: 600;\" data-ke-size=\"size23\">AI의 빛: 상상을 초월하는 생산성 향상</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">AI를 제대로만 활용하면 우리의 생산성은 정말 상상을 초월할 정도로 높아집니다. 여기서 강조할 세 가지 핵심 기술이 있어요.</p>\n<ol style=\"list-style-type: decimal; margin-left: 20px; margin-bottom: 20px; color: #3c4043;\" data-ke-list-type=\"decimal\">\n<li style=\"margin-bottom: 10px;\"><b>AI 에이전트 리서치:</b> 퍼플렉시티(Perplexity) 같은 AI 검색 엔진을 사용해 보세요. 예전에는 특정 주제 자료를 모으려고 논문 뒤지고, 해외 기사 번역하느라 6시간 넘게 걸렸죠. 이제 AI에게 질문 하나만 던지면 단 15분 만에 전 세계 최신 정보를 싹 요약해서 보고서 형태로 만들어 줍니다. 이건 단순히 시간을 아끼는 수준이 아니라, 콘텐츠의 깊이 자체가 달라지는 경험을 선사합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>멀티모달 영상 편집:</b> 이건 정말 혁명적입니다. 1시간짜리 강연 영상을 녹화했다고 칩시다. 팩토리(Factory)나 디스크립트(Descript) 같은 툴에 올리기만 하면, AI가 영상의 핵심 내용을 자동으로 분석해서 30분 안에 쇼츠 영상 10개를 뚝딱 만들어줍니다. 편집자 한 명의 몫을 AI가 거뜬히 해내는 셈이죠.</li>\n<li style=\"margin-bottom: 10px;\"><b>AI 다국어 더빙:</b> 일레븐랩스(ElevenLabs)나 헤이젠(HeyGen) 같은 서비스를 이용하면, 한국어로 만든 단 하나의 영상으로 무려 120개 언어의 더빙 버전을 만들 수 있습니다. 놀라운 건, 여러분의 목소리 톤과 감정을 그대로 유지하면서도 말이죠. 예전에는 이런 작업을 위해 수천만 원이 들었지만, 이제는 그 비용의 1/5 수준으로 줄었습니다. 여러분의 콘텐츠가 전 세계 시장에 동시에 진출할 수 있는 문이 활짝 열린 겁니다.</li>\n</ol>\n<h3 style=\"font-size: 19px; color: #d93025; margin: 25px 0 10px; font-weight: 600;\" data-ke-size=\"size23\">AI의 그림자: AI 슬롭(AI Slop) 페널티의 실체</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">하지만, 여기서부터가 정말 중요합니다. 이렇게 AI로 편리하게 대량으로 찍어낸 저품질 콘텐츠를 전문가들은 <b>AI 슬롭(AI Slop)</b>, 우리말로는 'AI 오물'이라고 부르거든요. 그리고 구글과 유튜브는 이 AI 슬롭을 무려 95% 이상의 무서운 정확도로 잡아냅니다. 알고리즘이 AI 슬롭을 탐지하는 신호는 아주 명확하다고 해요.</p>\n<ul style=\"list-style-type: disc; margin-left: 20px; margin-bottom: 20px; color: #3c4043;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px;\"><b>반복적인 문장 구조와 딱딱한 톤:</b> 여러 영상이나 글에서 똑같은 문장 구조나 기계적인 톤이 반복되는 경우.</li>\n<li style=\"margin-bottom: 10px;\"><b>감정 없는 로봇 같은 기계음:</b> 영상에서 감정의 높낮이가 없는 기계음이 사용된 경우.</li>\n<li style=\"margin-bottom: 10px;\"><b>불분명한 출처:</b> 이 콘텐츠를 누가 만들었는지 출처가 불분명한 경우.</li>\n<li style=\"margin-bottom: 10px;\"><b>시청자들의 부정적 피드백:</b> 사용자들이 '관심 없음' 버튼을 누르거나 '이거 AI가 만들었죠?' 같은 부정적인 댓글이 달리는 경우.</li>\n</ul>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이런 데이터가 쌓이면 바로 경고등이 켜지는 겁니다. 한번 AI 슬롭으로 찍히면 그 타격은 정말 치명적이에요. 한 연구 결과를 보니, 저품질 AI 영상은 인간이 직접 만든 일반 영상보다 트래픽이 무려 <b>5.44배나 감소</b>했다고 합니다. 이건 단순히 노출이 좀 줄어드는 수준이 아니에요. 심지어 기존 구독자 수를 알고리즘이 줄여버리는 조치까지 적용하기 시작했다는 겁니다. 100% 자동화로 편하게 돈 벌려다가, 내 채널 자체가 그냥 공중분해될 수 있다는 뜻이죠.</p>\n<div style=\"background-color: #fce8e6; border-left: 4px solid #d93025; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">⚠️ <b>AI 슬롭 경고:</b> 100% AI 자동화는 편리함을 넘어 <b>디지털 자폭 행위</b>가 될 수 있습니다. 알고리즘은 AI가 만든 저품질 콘텐츠를 정확하게 탐지하며, 이는 채널 트래픽 및 구독자 수 감소로 이어집니다.</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  HIT 전략: 인간 개입 시스템 (Human in the Loop)</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">그렇다면 이 문제점에 대한 해답은 뭘까요? AI를 아예 쓰지 말아야 할까요? 아니요, 그건 절대 아닙니다. 2026년 디지털 콘텐츠 시장의 최종 승리 전략은 바로 <b>HIT(Human in the Loop)</b>, 즉 <b>인간 개입 시스템</b>입니다. AI만으로 모든 것을 자동화하는 채널도, 오직 인간의 노동력만으로 콘텐츠를 만드는 채널도 아닌, 인간과 AI의 장점만을 전략적으로 결합하는 채널이 모든 것을 차지하게 될 겁니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">여기서 '진정성 차익 거래'라는 아주 흥미로운 개념이 등장합니다. AI가 만든 그럴싸한 콘텐츠가 세상에 넘쳐날수록, 역설적으로 <b>인간의 손길이 닿은 날것 그대로의 진정성 있는 콘텐츠의 가치</b>가 희귀해져 폭등한다는 의미입니다. 마치 공장에서 찍어낸 기성품들 사이에서 장인이 한 땀 한 땀 만든 수제품이 훨씬 비싸게 팔리는 것과 같은 원리죠.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">핵심은 <b>역할 분담</b>입니다. 반복적인 작업, 자료 조사, 데이터 분석, 초안 생성 같은 지루하고 힘든 일은 AI라는 유능한 비서에게 맡기세요. 그리고 인간인 여러분은 더 중요한 일에 집중하는 겁니다. 바로 전체적인 방향을 잡는 <b>전략 수립</b>, 중요한 <b>최종 판단</b>, 그리고 AI가 절대로 흉내 낼 수 없는 여러분만의 <b>인간적인 감성과 경험</b>을 콘텐츠에 불어넣는 것이죠. AI의 압도적인 효율성과 인간의 따뜻한 진정성이 만날 때, 그 누구도 따라올 수 없는 강력한 경쟁 우위가 생기는 겁니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/R6iby/dJMcacIBlY2/nmaNnJpfmH00pSK05KVbOk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/R6iby/dJMcacIBlY2/nmaNnJpfmH00pSK05KVbOk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/R6iby/dJMcacIBlY2/nmaNnJpfmH00pSK05KVbOk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FR6iby%2FdJMcacIBlY2%2FnmaNnJpfmH00pSK05KVbOk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"AI 로봇이 반복 작업을 처리하고 인간이 전략 수립과 감성을 더하는 'HIT' 전략의 시각화. AI와 인간의 협업을 통한 콘텐츠 제작을 나타냅니다.\n⏳ 실제 콘텐츠 제작 워크플로: 90분의 기적\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>⏳ 실제 콘텐츠 제작 워크플로: 90분의 기적</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">그럼 실제 콘텐츠 제작 과정을 시간 단위로 한번 쪼개볼까요? HIT 전략이 어떻게 우리의 일상에 적용될 수 있는지 명확하게 보여드릴게요.</p>\n<table style=\"width: 100%; border-collapse: collapse; margin-bottom: 20px; border: 1px solid #dadce0;\" data-ke-align=\"alignLeft\">\n<thead style=\"background-color: #e8eaed;\">\n<tr>\n<th style=\"padding: 12px; border: 1px solid #dadce0; text-align: left; color: #3c4043;\">단계</th>\n<th style=\"padding: 12px; border: 1px solid #dadce0; text-align: left; color: #3c4043;\">주체</th>\n<th style=\"padding: 12px; border: 1px solid #dadce0; text-align: left; color: #3c4043;\">활동 내용</th>\n<th style=\"padding: 12px; border: 1px solid #dadce0; text-align: left; color: #3c4043;\">소요 시간</th>\n</tr>\n</thead>\n<tbody>\n<tr style=\"background-color: #f1f3f4;\">\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">1. 자료 리서치</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">AI</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">전 세계 최신 정보 요약 및 보고서 생성</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">15분</td>\n</tr>\n<tr>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">2. 기획 및 전략 수립</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">인간</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">핵심 메시지, 스토리라인 구상</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">30분</td>\n</tr>\n<tr style=\"background-color: #f1f3f4;\">\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">3. 초안 생성</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">AI</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">기획에 맞춰 대본/글 초안 자동 생성</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">즉시</td>\n</tr>\n<tr>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">4. 최종 검토 및 인간적 터치</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">인간</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">경험담, 비유, 유머 추가, 글 다듬기</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">45분</td>\n</tr>\n<tr style=\"background-color: #f1f3f4;\">\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">5. 발행 및 홍보</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">AI</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">SNS 홍보 문구, 발행 등 마무리 작업</td>\n<td style=\"padding: 12px; border: 1px solid #dadce0; color: #3c4043;\">즉시</td>\n</tr>\n</tbody>\n</table>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">놀랍지 않나요? 예전에는 4시간에서 8시간까지 걸리던 고품질 콘텐츠 하나가 단 90분 안에 완성되는 겁니다. 80%의 시간을 절약하면서도 콘텐츠의 품질은 인간의 마지막 터치로 극대화할 수 있습니다. 꼭 기억하세요. AI로 뼈대를 세우되, 마지막 10분은 반드시 여러분의 영혼, 즉 여러분의 경험과 진정성으로 채워 넣어야 합니다. 그것이 AI 슬롭 페널티라는 저주를 피하고 2026년에 성공하는 유일한 길입니다.</p>\n<div style=\"background-color: #f8f9fa; border: 1px solid #dadce0; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); padding: 25px; margin: 40px 0;\">\n<div style=\"font-size: 26px; color: #1a73e8; font-weight: bold; margin-bottom: 15px; padding-bottom: 10px; border-bottom: 2px solid #1a73e8;\">  핵심 요약</div>\n<p style=\"font-size: 17px; margin-bottom: 15px; line-height: 1.8;\" data-ke-size=\"size16\">✅ <b>SEO는 죽었다? GEO 시대의 도래:</b> AI는 키워드 대신 '주제 권위성'과 '콘텐츠 클러스터'에 집중하며, AI의 인용을 받는 '새로운 포지션 제로'가 핵심 목표입니다.</p>\n<p style=\"font-size: 17px; margin-bottom: 15px; line-height: 1.8;\" data-ke-size=\"size16\">✅ <b>유튜브 알고리즘의 변화:</b> 조회수보다 '시청자 만족도'에 집중하세요. 쇼츠는 '정교한 필터'로, 롱폼은 LVR(좋아요/조회수 비율 4% 이상)을 통한 '신뢰 구축'에 활용해야 합니다.</p>\n<p style=\"font-size: 17px; margin-bottom: 15px; line-height: 1.8;\" data-ke-size=\"size16\">✅ <b>AI의 양면성:</b> AI는 생산성을 10배 높이는 도구이지만, 100% 자동화된 저품질 'AI 슬롭'은 치명적인 페널티로 이어집니다. AI 활용 시 '인간적 터치'가 필수입니다.</p>\n<p style=\"font-size: 17px; margin-bottom: 0; line-height: 1.8;\" data-ke-size=\"size16\">✅ <b>HIT 전략으로 살아남기:</b> AI에게는 반복 작업을, 인간에게는 전략 수립과 '진정성'을 부여하는 'Human in the Loop' 시스템이 AI 시대 콘텐츠 제작의 최종 승리 공식입니다.</p>\n<div style=\"font-size: 14px; color: #5f6368; margin-top: 20px; padding-top: 15px; border-top: 1px dashed #dadce0;\">이러한 변화에 능동적으로 대응해야만 2026년 이후의 디지털 콘텐츠 시장에서 지속 가능한 성공을 거둘 수 있습니다.</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q1: GEO(생성형 엔진 최적화)는 무엇이며, 기존 SEO와 어떻게 다른가요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A1: GEO는 생성형 AI 검색 엔진(SGE, CUE 등)에 콘텐츠를 최적화하는 전략입니다. 기존 SEO가 특정 키워드 반복과 검색량에 초점을 맞췄다면, GEO는 AI가 콘텐츠의 문맥과 작성자의 '주제 권위성'을 파악하여 답변에 인용하도록 만드는 것을 목표로 합니다. 이제는 키워드 밀도보다 콘텐츠의 깊이와 전문성이 훨씬 중요해졌습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q2: '제로 클릭 검색' 시대에 웹사이트 트래픽을 늘리는 방법은 무엇인가요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A2: 제로 클릭 검색으로 인해 직접적인 웹사이트 방문은 줄어들 수 있습니다. 이 시대의 목표는 AI가 생성하는 답변에 여러분의 콘텐츠가 '출처'로 인용되는 '새로운 포지션 제로'를 달성하는 것입니다. 이를 위해서는 하나의 전문 주제에 대한 깊이 있는 '콘텐츠 클러스터'를 구축하여 AI가 여러분을 해당 분야의 권위 있는 정보원으로 인식하도록 해야 합니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q3: 유튜브에서 'AI 슬롭' 페널티를 피하고 성공하려면 어떻게 해야 하나요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A3: AI 슬롭은 AI가 만든 저품질 콘텐츠를 의미하며, 유튜브 알고리즘은 이를 정확하게 탐지하여 채널에 페널티를 줍니다. 이를 피하려면 'HIT(Human in the Loop) 전략'을 사용해야 합니다. AI에게는 자료 조사나 초안 생성 같은 반복 작업을 맡기고, 인간인 여러분은 콘텐츠의 전략 수립, 최종 검토, 그리고 인간적인 감성과 경험을 불어넣는 역할에 집중하여 진정성 있는 고품질 콘텐츠를 만들어야 합니다.</p>\n<script type=\"application/ld+json\">\n  {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n      {\n        \"@type\": \"Question\",\n        \"name\": \"GEO(생성형 엔진 최적화)는 무엇이며, 기존 SEO와 어떻게 다른가요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"GEO는 생성형 AI 검색 엔진(SGE, CUE 등)에 콘텐츠를 최적화하는 전략입니다. 기존 SEO가 특정 키워드 반복과 검색량에 초점을 맞췄다면, GEO는 AI가 콘텐츠의 문맥과 작성자의 '주제 권위성'을 파악하여 답변에 인용하도록 만드는 것을 목표로 합니다. 이제는 키워드 밀도보다 콘텐츠의 깊이와 전문성이 훨씬 중요해졌습니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"'제로 클릭 검색' 시대에 웹사이트 트래픽을 늘리는 방법은 무엇인가요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"제로 클릭 검색으로 인해 직접적인 웹사이트 방문은 줄어들 수 있습니다. 이 시대의 목표는 AI가 생성하는 답변에 여러분의 콘텐츠가 '출처'로 인용되는 '새로운 포지션 제로'를 달성하는 것입니다. 이를 위해서는 하나의 전문 주제에 대한 깊이 있는 '콘텐츠 클러스터'를 구축하여 AI가 여러분을 해당 분야의 권위 있는 정보원으로 인식하도록 해야 합니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"유튜브에서 'AI 슬롭' 페널티를 피하고 성공하려면 어떻게 해야 하나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"AI 슬롭은 AI가 만든 저품질 콘텐츠를 의미하며, 유튜브 알고리즘은 이를 정확하게 탐지하여 채널에 페널티를 줍니다. 이를 피하려면 'HIT(Human in the Loop) 전략'을 사용해야 합니다. AI에게는 자료 조사나 초안 생성 같은 반복 작업을 맡기고, 인간인 여러분은 콘텐츠의 전략 수립, 최종 검토, 그리고 인간적인 감성과 경험을 불어넣는 역할에 집중하여 진정성 있는 고품질 콘텐츠를 만들어야 합니다.\"\n        }\n      }\n    ]\n  }\n  </script>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">오늘 분석한 내용, 머릿속이 조금 복잡하셨을 수도 있겠네요. 제가 딱 세 문장으로 핵심을 요약해 드리겠습니다. 첫째, <b>AI는 당신의 유능한 부사수일 뿐, 전략을 짜고 최종 결정을 내리는 CEO는 언제나 당신 자신이어야 합니다.</b> 둘째, <b>쇼츠라는 필터로 진짜 타깃을 모으고, 롱폼 영상으로 깊은 신뢰를 쌓고, 커뮤니티를 통해 진짜 수익을 내십시오.</b> 셋째, <b>100% 자동화는 편리함이 아니라 디지털 자폭 행위입니다. AI가 만든 초안에 당신의 경험과 진정성이라는 영혼을 반드시 불어넣으십시오.</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">마지막으로, 오늘 밤 혼자 조용히 생각해 볼 만한 질문을 하나 던지며 마무리하겠습니다. 2026년에 디지털 시장은 규모의 경쟁이 아니라 정교함과 진정성의 경쟁입니다. 이제 AI는 당신의 글, 당신의 영상, 심지어 당신의 목소리까지 거의 완벽하게 복제할 수 있는 세상이 왔습니다. 그렇다면 <b>AI가 절대로 복제할 수 없는, 오직 당신만이 가진 고유한 가치는 무엇입니까?</b> 여러분의 콘텐츠에서 한번 그 답을 찾아보시길 바랍니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 글이 AI 시대의 콘텐츠 전략을 세우는 데 도움이 되셨기를 진심으로 바랍니다. 감사합니다!</p>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>⚙️ '2026 AI 시대 디지털 생존 가이드' 무료배포!</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">기존의 검색 방식은 끝났습니다. 위기를 기회로 만드는 GEO 전략과 수익화의 모든 것.<br /><br />2026년,&nbsp;여러분의&nbsp;유튜브나&nbsp;블로그&nbsp;수익이&nbsp;한순간에&nbsp;0원이&nbsp;될&nbsp;수&nbsp;있습니다.&nbsp;구글과&nbsp;유튜브의&nbsp;새로운&nbsp;AI&nbsp;알고리즘이&nbsp;여러분의&nbsp;콘텐츠를&nbsp;'AI&nbsp;스팸'으로&nbsp;감지하는&nbsp;순간,&nbsp;공들여&nbsp;만든&nbsp;결과물들은&nbsp;디지털&nbsp;심해&nbsp;속으로&nbsp;사라져&nbsp;보이지&nbsp;않게&nbsp;됩니다. <br /><br />이것은 겁을 주기 위함이 아니라 현실입니다. 기존의 SEO 게임 룰은 끝났습니다. 이제는 생성형 엔진 최적, 즉 GEO(Generative Engine Optimization)의 시대입니다. 이 가이드북은 AI를 가장 강력한 전략적 무기로 만들어 여러분의 채널을 핵심 자산으로 키워내는 구체적인 실행 계획을 담고 있습니다.</p>\n<figure id=\"og_1768104473779\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"2026 AI 시대 디지털 생존 전략 가이드북\" data-og-description=\"\" data-og-host=\"2026-ai-survival-guide.vercel.app\" data-og-source-url=\"https://2026-ai-survival-guide.vercel.app/\" data-og-url=\"https://2026-ai-survival-guide.vercel.app/\" data-og-image=\"\"><a href=\"https://2026-ai-survival-guide.vercel.app/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://2026-ai-survival-guide.vercel.app/\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">2026 AI 시대 디지털 생존 전략 가이드북</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">&nbsp;</p>\n<p class=\"og-host\" data-ke-size=\"size16\">2026-ai-survival-guide.vercel.app</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=OZDMIdvQ-pQ\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/Sbrmd/hyZQUE5W2a/SbCD51k0V7iv8NwJFu9GB0/img.jpg?width=1280&amp;height=720&amp;face=996_328_1140_484,https://scrap.kakaocdn.net/dn/b7DXd4/hyZQLakBn4/qVKYJ1VAMyxONGnxt3VBl1/img.jpg?width=1280&amp;height=720&amp;face=996_328_1140_484\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"2026년 유튜브 수익 '0원' 되는 진짜 이유: AI 슬롭(Slop) 페널티를 피하는 유일한 방법\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/OZDMIdvQ-pQ\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<div id=\"gtx-trans\" style=\"position: absolute; left: -18px; top: 9809.79px;\">\n<div class=\"gtx-trans-icon\">&nbsp;</div>\n</div>",
        "contentSnippet": "2026년, 디지털 콘텐츠 시장은 거대한 변화의 물결에 휩싸였습니다. 이제는 단순히 키워드를 나열하는 SEO 시대가 아닌, 생성형 AI 검색(SGE/CUE)이 지배하는 GEO(Generative Engine Optimization) 시대가 도래했죠. AI는 더 이상 단순한 도구가 아니라, 콘텐츠의 생존과 수익을 결정하는 핵심 플레이어가 되었습니다. 이 글에서는 AI 슬롭(AI Slop)의 함정을 피하고, HIT(Human in the Loop) 전략을 통해 여러분의 콘텐츠를 AI 시대의 핵심 자산으로 만드는 구체적인 방법을 제시합니다. 키워드의 종말부터 제로 클릭 검색, 유튜브 알고리즘의 변화, 그리고 커뮤니티 기반 수익화까지, 새로운 디지털 수익화 공식을 파헤쳐 보세요.\n\n\n여러분, 2026년 바로 이 시점에서 혹시 유튜브나 블로그 수익이 갑자기 0원이 될 수도 있다는 사실을 알고 계셨나요? 물론, 단순히 겁을 주려는 이야기는 아닙니다. 구글과 유튜브의 새로운 AI 알고리즘이 여러분의 콘텐츠를 ‘AI 스팸’으로 분류하는 순간, 공들여 만든 모든 것이 검색 결과에서 사라져 버릴 수 있다는 현실적인 경고입니다. 실제로 일부 유튜브 쇼츠 채널들이 이미 이 AI 슬롭(AI Slop)이라는 함정에 빠져 어려움을 겪고 있고요. 그렇다면 이 거대한 변화 속에서 우리는 어떻게 살아남을 수 있을까요? 이 위기를 오히려 기회로 바꾸는 방법은 없을까요? 지금부터 2026년 디지털 수익화의 새로운 공식을 하나하나 파헤쳐 보겠습니다.\n  2026년, 디지털 수익의 대격변: SEO에서 GEO로\n최근 최신 컨설팅 보고서들을 리서치하면서 정말 놀라운 사실을 깨달았습니다. 우리가 익히 알던 기존의 검색 방식, 즉 SEO(Search Engine Optimization) 게임의 룰이 완전히 바뀌었다는 것입니다. 아니, 바뀌었다기보다는 이제는 거의 종착역에 도달했다고 보는 게 맞을 것 같아요. 이제는 GEO(Generative Engine Optimization), 즉 생성형 엔진 최적화라는 완전히 새로운 게임이 시작된 거죠. 이 변화는 단순히 검색 알고리즘의 업데이트 수준을 넘어선, 디지털 수익 생태계 전체의 대격변을 의미합니다.\n그렇다면 이 AI가 모든 것을 지배하는 새로운 환경에서 어떻게 해야 내 블로그나 유튜브 채널이 알고리즘의 처벌을 피하고, 오히려 AI의 선택을 받는 핵심 자산이 될 수 있을까요? 우리의 목표는 명확합니다. AI를 단순히 글이나 영상을 좀 더 편리하게 만들어주는 ‘도우미’ 정도로 생각하는 것이 아니라, 우리의 가장 강력한 전략적 무기로 활용하는 방법을 알아내는 것이죠. 이제 AI는 선택이 아닌 필수이자, 제대로 활용한다면 상상 이상의 성과를 가져다줄 열쇠가 될 겁니다.\n  키워드의 종말과 주제 권위성의 시대\n가장 근본적인 변화부터 짚고 넘어가죠. 바로 키워드의 종말입니다. 예전에는 '강남역 맛집'이라는 글을 쓸 때, 본문에 이 단어를 스무 번씩 반복해서 넣는 것이 일종의 '정석'처럼 여겨졌죠. 하지만 2026년 현재, 이런 전략은 더 이상 아무런 의미가 없습니다. 아니, 오히려 어뷰징(abusing)으로 분류되어 감점 요인이 될 수도 있습니다.\n구글의 SGE(Search Generative Experience)나 네이버의 CUE와 같은 생성형 엔진들은 이제 단어의 개수를 세는 것을 넘어, 콘텐츠의 문맥과 의도를 파악합니다. 그들이 집중하는 핵심은 단 하나입니다. “이 콘텐츠를 만든 사람이 이 주제에 대해 얼마나 깊이 있는 진짜 전문가인가?” 바로 이 '주제 권위성'을 평가하는 거죠.\n예를 들어, 여러분이 'AI 콘텐츠 마케팅'이라는 주제로 블로그를 운영한다고 가정해 봅시다. 과거에는 이 키워드를 포함한 글을 여러 개 발행했을 거예요. 하지만 이제는 접근법이 완전히 달라져야 합니다. 'AI 마케팅의 미래는?', 'AI 마케팅 툴 10가지 비교', 'AI 마케팅 실패 사례 분석' 등 사람들이 이 주제에 대해 궁금해할 만한 50개 이상의 세부 질문에 대해 각각 깊이 있는 답변을 제공하는 콘텐츠 클러스터(Content Cluster)를 구축해야 합니다.\n전체 콘텐츠의 80% 이상을 하나의 전문 주제에 집중할 때, AI는 비로소 여러분을 '믿을 만한 전문가'로 인식하고 검색 결과 상단에 적극적으로 노출하기 시작합니다. 여러 주제를 얕게 다루는 시대는 이제 정말 끝났다고 봐도 무방합니다.\n  GEO 시대의 핵심: AI는 단순히 키워드가 아닌, 콘텐츠의 문맥과 작성자의 전문성을 평가합니다. 하나의 주제에 깊이 파고들어 '주제 권위성'을 확보하는 것이 중요해요.\n  제로 클릭 검색과 새로운 포지션 제로\n여기서 더 충격적인 사실이 있습니다. 아무리 열심히 노력해서 전문가로 인정받아도, 정작 사람들이 여러분의 사이트를 클릭하지 않을 수도 있다는 거예요. 우리는 이를 제로 클릭 검색(Zero-Click Search)이라고 부릅니다. 말 그대로 검색 결과 페이지에서 웹사이트로의 클릭이 발생하지 않는 현상이죠. 최신 데이터에 따르면, 데스크톱 검색의 무려 46.5%, 거의 절반에 달하는 사용자들이 AI가 요약해 준 답변만 보고 검색을 끝내버린다고 합니다.\n이러한 변화로 인해 실제로 일부 글로벌 기업들은 자연 검색을 통한 방문자 수가 70%에서 80%까지 폭락하는 경험을 했습니다. 어제까지 1만 명이 방문하던 블로그에 갑자기 2천 명만 들어온다고 상상해 보세요. 정말 끔찍한 시나리오가 아닐 수 없습니다.\n따라서 이제 우리의 목표는 단순히 '클릭'이 되어서는 안 됩니다. 우리의 새로운 목표는 AI가 만들어낸 답변에 여러분의 이름이나 브랜드가 인용되는 것입니다. 예를 들어, '이 내용에 대한 더 자세한 정보는 OOO의 블로그를 참고했습니다'와 같이 출처로 명시되는 것이죠. 이것이 바로 새로운 포지션 제로(Position Zero), 즉 검색 결과 1위보다도 더 높은, AI 시대의 최고의 자리입니다. 내 콘텐츠가 AI 답변의 핵심 근거 자료로 채택되도록 만드는 것, 이것이 바로 GEO 시대의 진정한 승리 공식입니다.\n  2026년형 유튜브 알고리즘의 진실: 시청자 만족도\n이러한 변화의 물결은 유튜브에서도 거세게 몰아치고 있습니다. 어떻게 보면 검색 엔진보다 훨씬 더 직접적이고 강력한 영향을 미치고 있다고 생각해요. 과거 유튜브 성공 공식은 뭐였을까요? 맞습니다. 조회수와 시청 시간이었죠. 그래서 어떻게든 자극적인 썸네일과 제목으로 클릭을 유도하고, 일단 시청자를 영상에 붙잡아두는 것이 중요했습니다.\n하지만 2026년 현재, 유튜브 알고리즘은 오직 단 하나의 지표, 바로 시청자 만족도에만 집착합니다. 예를 들어, '초특가 아이폰 공짜로 사는 법' 같은 썸네일에 이끌려 영상을 클릭했는데, 막상 내용은 별것 없는 광고뿐이라면 시청자는 어떻게 반응할까요? 당연히 10초도 안 보고 영상을 꺼버리겠죠. 과거에는 이런 행동이 단순히 '이탈률이 높구나' 정도로 끝났지만, 이제는 다릅니다. 이탈하는 시청자의 행동 하나하나가 '이 채널은 시청자를 속이는 나쁜 채널'이라는 강력한 패널티 신호로 쌓이게 됩니다. 그리고 이 패널티는 해당 영상 하나로 끝나는 것이 아니라, 채널 전체의 노출량을 심각하게 깎아버리는 결과를 초래하죠.\n이제부터 유튜브에서의 유일한 성공 공식은 아주 명확해졌습니다. 시청자가 여러분의 영상을 다 보고 나서 '아, 진짜 시간을 잘 썼다. 이 채널 구독하길 정말 잘했다'고 진심으로 느끼게 만드는 것. 이것이 바로 전부입니다. 시청자의 진정한 만족이 곧 채널의 성장으로 직결되는 시대가 온 거죠.\n⚙️ 3단계 하이브리드 퍼널 전략: AI 시대의 유튜브 성공 공식\n그렇다면 이 완전히 새로운 전쟁터에서 우리는 어떻게 구체적으로 승리할 수 있을까요? 바로 2026년형 유튜브 성공 공식, 3단계 하이브리드 퍼널(Funnel) 전략입니다. 이 전략은 AI 시대에 최적화된 시청자 유입부터 수익화까지의 로드맵을 제시합니다.\n1단계: 유입 (Inflow) - 쇼츠를 정교한 필터로 활용\n이 단계의 핵심 무기는 바로 쇼츠(Shorts)입니다. 하지만 여기서 우리는 쇼츠에 대한 기존의 생각을 완전히 바꿔야 해요. 2026년에 쇼츠는 더 이상 단순한 바이럴 도구가 아닙니다. 아무에게나 노출되어 조회수를 높이는 것이 아니라, 정확한 타깃 시청자만 걸러내는 아주 정교한 필터로서의 역할을 수행해야 합니다. 주제에 관심도 없는 불특정 다수를 끌어모으는 것은 오히려 채널의 정체성을 흐리고 알고리즘에 나쁜 신호를 주는 최악의 전략이 될 수 있습니다.\n예를 들어 볼까요? 여러분이 최신 스마트폰을 깊이 있게 리뷰하는 기술 채널을 운영한다고 가정해 봅시다. 여기서 갑자기 요즘 유행하는 댄스 챌린지 쇼츠를 올리면 어떻게 될까요? 물론 조회수는 잠깐 폭발할 수도 있겠죠. 하지만 그 영상을 보고 들어온 수만 명의 사람들은 여러분의 전문적인 기술 리뷰에는 전혀 관심이 없을 겁니다. 이런 상황은 알고리즘에게 '이 채널은 정체성이 모호하니 기술에 관심 있는 사람들에게 추천하지 말아야겠다'는 신호를 줄 수 있습니다.\n대신에, 앞으로 리뷰할 스마트폰의 카메라 줌 기능을 100배 땡겨보는 10초짜리 쇼츠를 올려보세요. 그러면 정말 그 스마트폰 카메라 성능에 관심 있는 잠재 고객들만 여러분 채널로 유입될 겁니다. 이것이 바로 하이브리드 퍼널의 시작이자, 진짜 팬이 될 사람들을 모으는 첫 단추입니다.\n\n\n2단계: 신뢰 구축 (Building Trust) - 롱폼과 LVR 지표\n쇼츠라는 정교한 필터로 걸러진, 내 주제에 진짜 관심 있는 시청자들에게는 이제 롱폼(Long-form), 즉 긴 영상으로 깊이 있는 정보를 제공하며 신뢰를 구축해야 합니다. '당신은 나를 믿어도 좋다'는 확실한 신호를 주는 단계죠. 여기서 핵심은 알고리즘에게 '이 영상은 시청자들을 아주 만족시키고 있습니다'라는 구체적인 신호를 계속 보내는 것입니다.\n아주 중요한 숫자를 하나 제시해 드릴게요. 바로 좋아요/조회수 비율, LVR(Like View Ratio)입니다. 이 비율이 2%라면 그냥 보통 영상이지만, 만약 4%를 넘어간다면 유튜브 알고리즘은 '아, 이건 아주 훌륭한 영상이구나. 널리 알려야겠다'고 판단하여 추천을 폭발적으로 늘려준다고 합니다. 조회수가 1만 회인 영상이라면 좋아요가 최소 400개는 찍혀야 한다는 뜻이죠. LVR은 시청자가 '내 시간을 쓸 가치가 있었다'고 느끼는 가장 확실한 피드백이기 때문입니다.\n그럼 이 만족도를 어떻게 높일 수 있을까요? 두 가지 핵심 기술이 있습니다.\n영상 시작 5초 안에 핵심 가치 제시: '이 영상을 끝까지 보시면 당신은 이걸 얻어갈 수 있습니다'라는 명확한 가치를 제시해야 합니다. 두리뭉실하게 시작하면 시청자는 바로 이탈합니다.\n2~3분마다 시각적 변화: 사람의 집중력은 생각보다 짧습니다. 2~3분마다 의식적으로 화면 전환, 그래프 자료, 자막 강조 등 시각적인 변화를 주어 시청 유지율을 높여야 합니다.\n이러한 기술들로 시청 유지율을 높이고, 영상 마지막에는 '오늘 내용이 유익했다면 좋아요로 알려주세요'라고 정중하게 요청하여 LVR 4%를 달성하는 것, 이것이 이 단계의 중요한 목표입니다.\n3단계: 수익화 (Monetization) - 커뮤니티 기반의 지속 가능한 수익\n솔직히 말해서 2026년에 애드센스(AdSense)와 같은 광고 수익에만 의존하는 것은 매우 위험한 생각입니다. 최근 광고 수익의 중요도는 계속해서 낮아지고 있어요. 진짜 돈, 지속 가능한 수익은 여러분의 채널을 열성적으로 지지하는 팬덤, 바로 커뮤니티에서 나옵니다. 핵심 수익원은 크게 세 가지로 볼 수 있습니다.\n멤버십 (Memberships): 채널의 유료 멤버십을 통해 독점 콘텐츠나 혜택을 제공합니다.\n슈퍼챗 (Super Chat) 및 후원: 라이브 스트리밍 시 시청자들의 자발적인 후원을 유도합니다.\n브랜드 협력 (Brand Partnerships): 채널의 전문성을 인정하는 브랜드와의 협업을 통해 수익을 창출합니다.\n여기서 가장 중요한 건 '왜 나를 후원해야 하는가?'에 대한 명확한 가치를 제시하는 겁니다. 옛날처럼 '여러분의 후원이 제게 큰 힘이 됩니다' 같은 감성적인 호소는 더 이상 통하지 않아요. 시청자들은 명확한 가치 교환을 원합니다.\n예를 들면 이런 거죠. '제 채널에 VIP 멤버가 되시면 매주 목요일 저와 함께하는 비공개 실시간 Q&A에 참여하실 수 있고, 제가 만드는 모든 강의 자료 원본 파일을 미리 받아보실 수 있습니다.' 어때요? 아주 구체적이고 매력적인 혜택을 줘야 하는 겁니다. 이것은 구글에 의존하는 것이 아니라, 당당한 비즈니스 모델입니다. 이 개념으로 접근해야만 여러분의 채널이 단순한 취미가 아니라 지속 가능한 사업체가 될 수 있습니다.\n\n\n✨ AI 자동화의 빛과 그림자: 생산성 혁명 vs. AI 슬롭 페널티\n이제 정말 흥미로운 이야기, AI 자동화로 넘어가 보겠습니다. AI는 마치 강력한 마법 지팡이 같아요. 이걸 잘 쓰면 생산성을 10배 이상 높이는 혁명의 도구가 되지만, 잘못 휘두르면 여러분의 모든 것을 파괴하는 저주의 함정이 될 수도 있습니다.\nAI의 빛: 상상을 초월하는 생산성 향상\nAI를 제대로만 활용하면 우리의 생산성은 정말 상상을 초월할 정도로 높아집니다. 여기서 강조할 세 가지 핵심 기술이 있어요.\nAI 에이전트 리서치: 퍼플렉시티(Perplexity) 같은 AI 검색 엔진을 사용해 보세요. 예전에는 특정 주제 자료를 모으려고 논문 뒤지고, 해외 기사 번역하느라 6시간 넘게 걸렸죠. 이제 AI에게 질문 하나만 던지면 단 15분 만에 전 세계 최신 정보를 싹 요약해서 보고서 형태로 만들어 줍니다. 이건 단순히 시간을 아끼는 수준이 아니라, 콘텐츠의 깊이 자체가 달라지는 경험을 선사합니다.\n멀티모달 영상 편집: 이건 정말 혁명적입니다. 1시간짜리 강연 영상을 녹화했다고 칩시다. 팩토리(Factory)나 디스크립트(Descript) 같은 툴에 올리기만 하면, AI가 영상의 핵심 내용을 자동으로 분석해서 30분 안에 쇼츠 영상 10개를 뚝딱 만들어줍니다. 편집자 한 명의 몫을 AI가 거뜬히 해내는 셈이죠.\nAI 다국어 더빙: 일레븐랩스(ElevenLabs)나 헤이젠(HeyGen) 같은 서비스를 이용하면, 한국어로 만든 단 하나의 영상으로 무려 120개 언어의 더빙 버전을 만들 수 있습니다. 놀라운 건, 여러분의 목소리 톤과 감정을 그대로 유지하면서도 말이죠. 예전에는 이런 작업을 위해 수천만 원이 들었지만, 이제는 그 비용의 1/5 수준으로 줄었습니다. 여러분의 콘텐츠가 전 세계 시장에 동시에 진출할 수 있는 문이 활짝 열린 겁니다.\nAI의 그림자: AI 슬롭(AI Slop) 페널티의 실체\n하지만, 여기서부터가 정말 중요합니다. 이렇게 AI로 편리하게 대량으로 찍어낸 저품질 콘텐츠를 전문가들은 AI 슬롭(AI Slop), 우리말로는 'AI 오물'이라고 부르거든요. 그리고 구글과 유튜브는 이 AI 슬롭을 무려 95% 이상의 무서운 정확도로 잡아냅니다. 알고리즘이 AI 슬롭을 탐지하는 신호는 아주 명확하다고 해요.\n반복적인 문장 구조와 딱딱한 톤: 여러 영상이나 글에서 똑같은 문장 구조나 기계적인 톤이 반복되는 경우.\n감정 없는 로봇 같은 기계음: 영상에서 감정의 높낮이가 없는 기계음이 사용된 경우.\n불분명한 출처: 이 콘텐츠를 누가 만들었는지 출처가 불분명한 경우.\n시청자들의 부정적 피드백: 사용자들이 '관심 없음' 버튼을 누르거나 '이거 AI가 만들었죠?' 같은 부정적인 댓글이 달리는 경우.\n이런 데이터가 쌓이면 바로 경고등이 켜지는 겁니다. 한번 AI 슬롭으로 찍히면 그 타격은 정말 치명적이에요. 한 연구 결과를 보니, 저품질 AI 영상은 인간이 직접 만든 일반 영상보다 트래픽이 무려 5.44배나 감소했다고 합니다. 이건 단순히 노출이 좀 줄어드는 수준이 아니에요. 심지어 기존 구독자 수를 알고리즘이 줄여버리는 조치까지 적용하기 시작했다는 겁니다. 100% 자동화로 편하게 돈 벌려다가, 내 채널 자체가 그냥 공중분해될 수 있다는 뜻이죠.\n⚠️ AI 슬롭 경고: 100% AI 자동화는 편리함을 넘어 디지털 자폭 행위가 될 수 있습니다. 알고리즘은 AI가 만든 저품질 콘텐츠를 정확하게 탐지하며, 이는 채널 트래픽 및 구독자 수 감소로 이어집니다.\n  HIT 전략: 인간 개입 시스템 (Human in the Loop)\n그렇다면 이 문제점에 대한 해답은 뭘까요? AI를 아예 쓰지 말아야 할까요? 아니요, 그건 절대 아닙니다. 2026년 디지털 콘텐츠 시장의 최종 승리 전략은 바로 HIT(Human in the Loop), 즉 인간 개입 시스템입니다. AI만으로 모든 것을 자동화하는 채널도, 오직 인간의 노동력만으로 콘텐츠를 만드는 채널도 아닌, 인간과 AI의 장점만을 전략적으로 결합하는 채널이 모든 것을 차지하게 될 겁니다.\n여기서 '진정성 차익 거래'라는 아주 흥미로운 개념이 등장합니다. AI가 만든 그럴싸한 콘텐츠가 세상에 넘쳐날수록, 역설적으로 인간의 손길이 닿은 날것 그대로의 진정성 있는 콘텐츠의 가치가 희귀해져 폭등한다는 의미입니다. 마치 공장에서 찍어낸 기성품들 사이에서 장인이 한 땀 한 땀 만든 수제품이 훨씬 비싸게 팔리는 것과 같은 원리죠.\n핵심은 역할 분담입니다. 반복적인 작업, 자료 조사, 데이터 분석, 초안 생성 같은 지루하고 힘든 일은 AI라는 유능한 비서에게 맡기세요. 그리고 인간인 여러분은 더 중요한 일에 집중하는 겁니다. 바로 전체적인 방향을 잡는 전략 수립, 중요한 최종 판단, 그리고 AI가 절대로 흉내 낼 수 없는 여러분만의 인간적인 감성과 경험을 콘텐츠에 불어넣는 것이죠. AI의 압도적인 효율성과 인간의 따뜻한 진정성이 만날 때, 그 누구도 따라올 수 없는 강력한 경쟁 우위가 생기는 겁니다.\n\n\n⏳ 실제 콘텐츠 제작 워크플로: 90분의 기적\n그럼 실제 콘텐츠 제작 과정을 시간 단위로 한번 쪼개볼까요? HIT 전략이 어떻게 우리의 일상에 적용될 수 있는지 명확하게 보여드릴게요.\n단계\n주체\n활동 내용\n소요 시간\n\n\n\n\n1. 자료 리서치\nAI\n전 세계 최신 정보 요약 및 보고서 생성\n15분\n\n\n2. 기획 및 전략 수립\n인간\n핵심 메시지, 스토리라인 구상\n30분\n\n\n3. 초안 생성\nAI\n기획에 맞춰 대본/글 초안 자동 생성\n즉시\n\n\n4. 최종 검토 및 인간적 터치\n인간\n경험담, 비유, 유머 추가, 글 다듬기\n45분\n\n\n5. 발행 및 홍보\nAI\nSNS 홍보 문구, 발행 등 마무리 작업\n즉시\n\n\n\n놀랍지 않나요? 예전에는 4시간에서 8시간까지 걸리던 고품질 콘텐츠 하나가 단 90분 안에 완성되는 겁니다. 80%의 시간을 절약하면서도 콘텐츠의 품질은 인간의 마지막 터치로 극대화할 수 있습니다. 꼭 기억하세요. AI로 뼈대를 세우되, 마지막 10분은 반드시 여러분의 영혼, 즉 여러분의 경험과 진정성으로 채워 넣어야 합니다. 그것이 AI 슬롭 페널티라는 저주를 피하고 2026년에 성공하는 유일한 길입니다.\n  핵심 요약\n✅ SEO는 죽었다? GEO 시대의 도래: AI는 키워드 대신 '주제 권위성'과 '콘텐츠 클러스터'에 집중하며, AI의 인용을 받는 '새로운 포지션 제로'가 핵심 목표입니다.\n✅ 유튜브 알고리즘의 변화: 조회수보다 '시청자 만족도'에 집중하세요. 쇼츠는 '정교한 필터'로, 롱폼은 LVR(좋아요/조회수 비율 4% 이상)을 통한 '신뢰 구축'에 활용해야 합니다.\n✅ AI의 양면성: AI는 생산성을 10배 높이는 도구이지만, 100% 자동화된 저품질 'AI 슬롭'은 치명적인 페널티로 이어집니다. AI 활용 시 '인간적 터치'가 필수입니다.\n✅ HIT 전략으로 살아남기: AI에게는 반복 작업을, 인간에게는 전략 수립과 '진정성'을 부여하는 'Human in the Loop' 시스템이 AI 시대 콘텐츠 제작의 최종 승리 공식입니다.\n이러한 변화에 능동적으로 대응해야만 2026년 이후의 디지털 콘텐츠 시장에서 지속 가능한 성공을 거둘 수 있습니다.\n❓ 자주 묻는 질문 (FAQ)\nQ1: GEO(생성형 엔진 최적화)는 무엇이며, 기존 SEO와 어떻게 다른가요?\nA1: GEO는 생성형 AI 검색 엔진(SGE, CUE 등)에 콘텐츠를 최적화하는 전략입니다. 기존 SEO가 특정 키워드 반복과 검색량에 초점을 맞췄다면, GEO는 AI가 콘텐츠의 문맥과 작성자의 '주제 권위성'을 파악하여 답변에 인용하도록 만드는 것을 목표로 합니다. 이제는 키워드 밀도보다 콘텐츠의 깊이와 전문성이 훨씬 중요해졌습니다.\nQ2: '제로 클릭 검색' 시대에 웹사이트 트래픽을 늘리는 방법은 무엇인가요?\nA2: 제로 클릭 검색으로 인해 직접적인 웹사이트 방문은 줄어들 수 있습니다. 이 시대의 목표는 AI가 생성하는 답변에 여러분의 콘텐츠가 '출처'로 인용되는 '새로운 포지션 제로'를 달성하는 것입니다. 이를 위해서는 하나의 전문 주제에 대한 깊이 있는 '콘텐츠 클러스터'를 구축하여 AI가 여러분을 해당 분야의 권위 있는 정보원으로 인식하도록 해야 합니다.\nQ3: 유튜브에서 'AI 슬롭' 페널티를 피하고 성공하려면 어떻게 해야 하나요?\nA3: AI 슬롭은 AI가 만든 저품질 콘텐츠를 의미하며, 유튜브 알고리즘은 이를 정확하게 탐지하여 채널에 페널티를 줍니다. 이를 피하려면 'HIT(Human in the Loop) 전략'을 사용해야 합니다. AI에게는 자료 조사나 초안 생성 같은 반복 작업을 맡기고, 인간인 여러분은 콘텐츠의 전략 수립, 최종 검토, 그리고 인간적인 감성과 경험을 불어넣는 역할에 집중하여 진정성 있는 고품질 콘텐츠를 만들어야 합니다.\n오늘 분석한 내용, 머릿속이 조금 복잡하셨을 수도 있겠네요. 제가 딱 세 문장으로 핵심을 요약해 드리겠습니다. 첫째, AI는 당신의 유능한 부사수일 뿐, 전략을 짜고 최종 결정을 내리는 CEO는 언제나 당신 자신이어야 합니다. 둘째, 쇼츠라는 필터로 진짜 타깃을 모으고, 롱폼 영상으로 깊은 신뢰를 쌓고, 커뮤니티를 통해 진짜 수익을 내십시오. 셋째, 100% 자동화는 편리함이 아니라 디지털 자폭 행위입니다. AI가 만든 초안에 당신의 경험과 진정성이라는 영혼을 반드시 불어넣으십시오.\n마지막으로, 오늘 밤 혼자 조용히 생각해 볼 만한 질문을 하나 던지며 마무리하겠습니다. 2026년에 디지털 시장은 규모의 경쟁이 아니라 정교함과 진정성의 경쟁입니다. 이제 AI는 당신의 글, 당신의 영상, 심지어 당신의 목소리까지 거의 완벽하게 복제할 수 있는 세상이 왔습니다. 그렇다면 AI가 절대로 복제할 수 없는, 오직 당신만이 가진 고유한 가치는 무엇입니까? 여러분의 콘텐츠에서 한번 그 답을 찾아보시길 바랍니다.\n이 글이 AI 시대의 콘텐츠 전략을 세우는 데 도움이 되셨기를 진심으로 바랍니다. 감사합니다!\n⚙️ '2026 AI 시대 디지털 생존 가이드' 무료배포!\n기존의 검색 방식은 끝났습니다. 위기를 기회로 만드는 GEO 전략과 수익화의 모든 것.\n2026년, 여러분의 유튜브나 블로그 수익이 한순간에 0원이 될 수 있습니다. 구글과 유튜브의 새로운 AI 알고리즘이 여러분의 콘텐츠를 'AI 스팸'으로 감지하는 순간, 공들여 만든 결과물들은 디지털 심해 속으로 사라져 보이지 않게 됩니다. \n이것은 겁을 주기 위함이 아니라 현실입니다. 기존의 SEO 게임 룰은 끝났습니다. 이제는 생성형 엔진 최적, 즉 GEO(Generative Engine Optimization)의 시대입니다. 이 가이드북은 AI를 가장 강력한 전략적 무기로 만들어 여러분의 채널을 핵심 자산으로 키워내는 구체적인 실행 계획을 담고 있습니다.\n\n \n2026 AI 시대 디지털 생존 전략 가이드북\n \n2026-ai-survival-guide.vercel.app",
        "guid": "https://muzbox.tistory.com/483698",
        "categories": [
          "AI, 미래기술/AI 인사이트",
          "ai슬롭",
          "AI알고리즘",
          "Geo",
          "디지털수익화전략",
          "생성형엔진최적화",
          "유튜브수익화2026",
          "제로클릭검색",
          "주제권위성",
          "콘텐츠클러스터",
          "휴먼인더루프"
        ],
        "isoDate": "2026-01-11T03:16:50.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "｜RULIWEB｜",
        "title": "보드 위의 새옹지마, 더 게임 오브 라이프 for NS",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2410",
        "pubDate": "Thu, 15 Jan 2026 17:44:43 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/26/01/15/19bc0cda9f251ad6b.webp\">",
        "contentSnippet": "",
        "categories": [
          "게임툰"
        ],
        "isoDate": "2026-01-15T08:44:43.000Z"
      },
      {
        "creator": "｜RULIWEB｜",
        "title": "악역영애 4컷 만화 - 35화, 영애 없는 영애 학교 근황 데스와",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2409",
        "pubDate": "Wed, 14 Jan 2026 21:25:36 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/26/01/14/19bbc775ac351ad6b.webp\">",
        "contentSnippet": "",
        "categories": [
          "웹툰"
        ],
        "isoDate": "2026-01-14T12:25:36.000Z"
      },
      {
        "creator": "샤말란의눈",
        "title": "[MULTI] 나의 히어로 아카데미아 올즈 저스티스, 진일보한 연출과 게임 모드",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2408",
        "pubDate": "Tue, 13 Jan 2026 00:01:33 +0900",
        "author": "샤말란의눈",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/26/01/10/19ba39cb90213b2a1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "프리뷰"
        ],
        "isoDate": "2026-01-12T15:01:33.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "buildgame v1 - 앱토스 NFT 게임 개발 시작했습니다.",
        "link": "https://serverdown.tistory.com/1557",
        "pubDate": "Thu, 15 Jan 2026 22:33:05 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1557#entry1557comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"464\" data-origin-height=\"196\"><span data-url=\"https://blog.kakaocdn.net/dn/ykf46/dJMcadOelQc/jymJlhbt7D9UwdYNMXI8N1/img.gif\" data-phocus=\"https://blog.kakaocdn.net/dn/ykf46/dJMcadOelQc/jymJlhbt7D9UwdYNMXI8N1/img.gif\"><img src=\"https://blog.kakaocdn.net/dn/ykf46/dJMcadOelQc/jymJlhbt7D9UwdYNMXI8N1/img.gif\" srcset=\"https://blog.kakaocdn.net/dn/ykf46/dJMcadOelQc/jymJlhbt7D9UwdYNMXI8N1/img.gif\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"464\" height=\"196\" data-origin-width=\"464\" data-origin-height=\"196\"/></span></figure>\n</p>\n<h2 data-ke-size=\"size26\">시작</h2>\n<p data-ke-size=\"size16\">NFT 으로 게임을 적용시킬 예정입니다.</p>\n<p data-ke-size=\"size16\">spum 언제 써보나 하다 이제 붙여 봤습니다.</p>\n<p data-ke-size=\"size16\">케릭터 이동을 구현했습니다.</p>\n<p data-ke-size=\"size16\">앞으로 꾸준히 연재하겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">계획</h2>\n<p data-ke-size=\"size16\"><a href=\"https://www.youtube.com/watch?v=0atlSxgwOtc\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=0atlSxgwOtc</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=0atlSxgwOtc\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/hCwgz/dJMb8PGpEem/EQZPigtP8FeMcHH3PQaTr0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/cR5doU/dJMb8RjVppt/EyAmnI602o50gdgPeTudk0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/bl4vQV/dJMb86nQ1uz/aPaltP3Ro0KHaF0PN5ccJ1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"393일차 #2 - 다시 NFT / APTOS (앱토스)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/0atlSxgwOtc\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">제 앱토스 NFT 시작 영상입니다.</p>\n<p data-ke-size=\"size16\">한번 봐주시구요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">개발 순서</h2>\n<p data-ke-size=\"size16\">1. 드래곤퀘스트 (영상 끝부분 참조) 비슷한 카메라 시점으로 블록 쌓기를 구현합니다.</p>\n<p data-ke-size=\"size16\">2. NFT 를 사용해 로그인하고 내 정보를 저장합니다.</p>\n<p data-ke-size=\"size16\">3. NFT 에 케릭터 아이템 땅 같은걸 저장합니다.</p>\n<p data-ke-size=\"size16\">4. NFT 를 판매해 실제 아이템 거래를 구현합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "시작\nNFT 으로 게임을 적용시킬 예정입니다.\nspum 언제 써보나 하다 이제 붙여 봤습니다.\n케릭터 이동을 구현했습니다.\n앞으로 꾸준히 연재하겠습니다.\n \n \n계획\nhttps://www.youtube.com/watch?v=0atlSxgwOtc\n\n\n\n \n제 앱토스 NFT 시작 영상입니다.\n한번 봐주시구요\n \n개발 순서\n1. 드래곤퀘스트 (영상 끝부분 참조) 비슷한 카메라 시점으로 블록 쌓기를 구현합니다.\n2. NFT 를 사용해 로그인하고 내 정보를 저장합니다.\n3. NFT 에 케릭터 아이템 땅 같은걸 저장합니다.\n4. NFT 를 판매해 실제 아이템 거래를 구현합니다.",
        "guid": "https://serverdown.tistory.com/1557",
        "categories": [
          "프로그래밍/자작",
          "buildgame"
        ],
        "isoDate": "2026-01-15T13:33:05.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "픽샐장인의 등장 / AI 코딩 / 1인개발자",
        "link": "https://serverdown.tistory.com/1556",
        "pubDate": "Mon, 12 Jan 2026 00:25:23 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1556#entry1556comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"232\" data-origin-height=\"223\"><span data-url=\"https://blog.kakaocdn.net/dn/3FA6B/dJMcagjUR0B/GzNz0KnhAcpy9kPTa7syR1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/3FA6B/dJMcagjUR0B/GzNz0KnhAcpy9kPTa7syR1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/3FA6B/dJMcagjUR0B/GzNz0KnhAcpy9kPTa7syR1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F3FA6B%2FdJMcagjUR0B%2FGzNz0KnhAcpy9kPTa7syR1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"232\" height=\"223\" data-origin-width=\"232\" data-origin-height=\"223\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">채널명이 길군요&nbsp;</p>\n<p data-ke-size=\"size16\">마른비&nbsp;내리는&nbsp;밤&nbsp;잠은&nbsp;안오고</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"874\" data-origin-height=\"229\"><span data-url=\"https://blog.kakaocdn.net/dn/Mrb62/dJMcajnme2M/gF2EQnMo7W8UiANlFpQkK1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Mrb62/dJMcajnme2M/gF2EQnMo7W8UiANlFpQkK1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/Mrb62/dJMcajnme2M/gF2EQnMo7W8UiANlFpQkK1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FMrb62%2FdJMcajnme2M%2FgF2EQnMo7W8UiANlFpQkK1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"874\" height=\"229\" data-origin-width=\"874\" data-origin-height=\"229\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">클로드 코드로 여러가지를 결과물이 나와서&nbsp;</p>\n<p data-ke-size=\"size16\">공유하는 영상이였습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=EPefUj1D0X4&amp;t=167s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=EPefUj1D0X4&amp;t=167s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=EPefUj1D0X4\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/dNVEP0/hyZQHeJ9Rr/wvtXZf4CQjyLlg4WzIWuJ1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/ZO1xX/hyZQV495ct/HezfMKZ4RlJN221if7ueJ0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"AI에게 나는 어떤 개발자일까?? [1월 중간 개발 회고]\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/EPefUj1D0X4\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">랜딩 페이지</p>\n<p data-ke-size=\"size16\"><a href=\"https://www.youtube.com/redirect?event=comments&amp;redir_token=QUFFLUhqbkJRUDdzRXZ0UUczT21zMUoxMFRxdzdLeXBGZ3xBQ3Jtc0tuS0R4M0RodWVGS0czN0ZBRVdvN2RMcTFBMnZ1SlBMYTZuRTlGSl9zMkllajlwaFdqbERoXzJDU2dJM08wUGExenVIVmRRT3hTUTNfMkU1M21pNWxhdFJKZnY1UC1Eb3VsQ1o5QnBZejhscVd3bm1saw&amp;q=https%3A%2F%2Fwww.play-t.art%2F\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/redirect?event=comments&amp;redir_token=QUFFLUhqbkJRUDdzRXZ0UUczT21zMUoxMFRxdzdLeXBGZ3xBQ3Jtc0tuS0R4M0RodWVGS0czN0ZBRVdvN2RMcTFBMnZ1SlBMYTZuRTlGSl9zMkllajlwaFdqbERoXzJDU2dJM08wUGExenVIVmRRT3hTUTNfMkU1M21pNWxhdFJKZnY1UC1Eb3VsQ1o5QnBZejhscVd3bm1saw&amp;q=https%3A%2F%2Fwww.play-t.art%2F</a></p>\n<figure id=\"og_1768144983190\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"YouTube\" data-og-description=\"\" data-og-host=\"www.youtube.com\" data-og-source-url=\"https://www.youtube.com/redirect?event=comments&amp;redir_token=QUFFLUhqbkJRUDdzRXZ0UUczT21zMUoxMFRxdzdLeXBGZ3xBQ3Jtc0tuS0R4M0RodWVGS0czN0ZBRVdvN2RMcTFBMnZ1SlBMYTZuRTlGSl9zMkllajlwaFdqbERoXzJDU2dJM08wUGExenVIVmRRT3hTUTNfMkU1M21pNWxhdFJKZnY1UC1Eb3VsQ1o5QnBZejhscVd3bm1saw&amp;q=https%3A%2F%2Fwww.play-t.art%2F\" data-og-url=\"https://www.youtube.com/redirect?event=comments&amp;q=https%3A%2F%2Fwww.play-t.art%2F&amp;redir_token=QUFFLUhqbkJRUDdzRXZ0UUczT21zMUoxMFRxdzdLeXBGZ3xBQ3Jtc0tuS0R4M0RodWVGS0czN0ZBRVdvN2RMcTFBMnZ1SlBMYTZuRTlGSl9zMkllajlwaFdqbERoXzJDU2dJM08wUGExenVIVmRRT3hTUTNfMkU1M21pNWxhdFJKZnY1UC1Eb3VsQ1o5QnBZejhscVd3bm1saw\" data-og-image=\"\"><a href=\"https://www.youtube.com/redirect?event=comments&amp;redir_token=QUFFLUhqbkJRUDdzRXZ0UUczT21zMUoxMFRxdzdLeXBGZ3xBQ3Jtc0tuS0R4M0RodWVGS0czN0ZBRVdvN2RMcTFBMnZ1SlBMYTZuRTlGSl9zMkllajlwaFdqbERoXzJDU2dJM08wUGExenVIVmRRT3hTUTNfMkU1M21pNWxhdFJKZnY1UC1Eb3VsQ1o5QnBZejhscVd3bm1saw&amp;q=https%3A%2F%2Fwww.play-t.art%2F\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.youtube.com/redirect?event=comments&amp;redir_token=QUFFLUhqbkJRUDdzRXZ0UUczT21zMUoxMFRxdzdLeXBGZ3xBQ3Jtc0tuS0R4M0RodWVGS0czN0ZBRVdvN2RMcTFBMnZ1SlBMYTZuRTlGSl9zMkllajlwaFdqbERoXzJDU2dJM08wUGExenVIVmRRT3hTUTNfMkU1M21pNWxhdFJKZnY1UC1Eb3VsQ1o5QnBZejhscVd3bm1saw&amp;q=https%3A%2F%2Fwww.play-t.art%2F\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">YouTube</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">&nbsp;</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.youtube.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">결과물 페이지 <a href=\"https://www.play-t.art/\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.play-t.art/</a></p>\n<figure id=\"og_1768145227797\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Playtart - 픽셀아트 강의 &amp; 외주 플랫폼\" data-og-description=\"픽셀아트 강의 &amp; 외주플레이타르트 픽셀아트, AI 웹사이트 제작, 창작자 생존 전략까지. 개인 창작자 중심의 미니 플랫폼입니다.\" data-og-host=\"www.play-t.art\" data-og-source-url=\"https://www.play-t.art/\" data-og-url=\"https://www.play-t.art/\" data-og-image=\"\"><a href=\"https://www.play-t.art/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.play-t.art/\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Playtart - 픽셀아트 강의 &amp; 외주 플랫폼</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">픽셀아트 강의 &amp; 외주플레이타르트 픽셀아트, AI 웹사이트 제작, 창작자 생존 전략까지. 개인 창작자 중심의 미니 플랫폼입니다.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.play-t.art</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">들어가서 봤는데 픽셀아트 퀄이 촣습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">전직 프로그래머 였나봅니다.</p>\n<p data-ke-size=\"size16\">현재는 픽셀아트 하시는거 같습니다.</p>\n<p data-ke-size=\"size16\">코딩도 하구요</p>\n<p data-ke-size=\"size16\">주시해야할 것 같습니다.</p>",
        "contentSnippet": "채널명이 길군요 \n마른비 내리는 밤 잠은 안오고\n\n\n \n클로드 코드로 여러가지를 결과물이 나와서 \n공유하는 영상이였습니다.\n \n영상: https://www.youtube.com/watch?v=EPefUj1D0X4&t=167s\n\n\n\n랜딩 페이지\nhttps://www.youtube.com/redirect?event=comments&redir_token=QUFFLUhqbkJRUDdzRXZ0UUczT21zMUoxMFRxdzdLeXBGZ3xBQ3Jtc0tuS0R4M0RodWVGS0czN0ZBRVdvN2RMcTFBMnZ1SlBMYTZuRTlGSl9zMkllajlwaFdqbERoXzJDU2dJM08wUGExenVIVmRRT3hTUTNfMkU1M21pNWxhdFJKZnY1UC1Eb3VsQ1o5QnBZejhscVd3bm1saw&q=https%3A%2F%2Fwww.play-t.art%2F\n\n \nYouTube\n \nwww.youtube.com\n\n \n결과물 페이지 https://www.play-t.art/\n\n \nPlaytart - 픽셀아트 강의 & 외주 플랫폼\n픽셀아트 강의 & 외주플레이타르트 픽셀아트, AI 웹사이트 제작, 창작자 생존 전략까지. 개인 창작자 중심의 미니 플랫폼입니다.\nwww.play-t.art\n\n들어가서 봤는데 픽셀아트 퀄이 촣습니다.\n \n \n전직 프로그래머 였나봅니다.\n현재는 픽셀아트 하시는거 같습니다.\n코딩도 하구요\n주시해야할 것 같습니다.",
        "guid": "https://serverdown.tistory.com/1556",
        "categories": [
          "프로그래밍/개발메모"
        ],
        "isoDate": "2026-01-11T15:25:23.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "SQLite 이제 적극적으로 사용하자",
        "link": "https://serverdown.tistory.com/1555",
        "pubDate": "Sat, 10 Jan 2026 16:46:58 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1555#entry1555comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"522\" data-origin-height=\"368\"><span data-url=\"https://blog.kakaocdn.net/dn/bdxhfW/dJMcad1JXcY/lKAFzuxM9KV6FxgF4q6tCK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bdxhfW/dJMcad1JXcY/lKAFzuxM9KV6FxgF4q6tCK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bdxhfW/dJMcad1JXcY/lKAFzuxM9KV6FxgF4q6tCK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbdxhfW%2FdJMcad1JXcY%2FlKAFzuxM9KV6FxgF4q6tCK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"522\" height=\"368\" data-origin-width=\"522\" data-origin-height=\"368\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=TFASrm63wYc\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=TFASrm63wYc</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=TFASrm63wYc\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/dLxGlV/hyZQNeOiuq/6cugkYNYxt4keGKokBAIgk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/cmQdSX/hyZRjdGTKW/vmuidypVknOel1PTmOKfTK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/3Xo66/hyZRdLkkLA/ufaEkveSE0i67buLwaXKGK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"Rails 8이 PostgreSQL 대신 SQLite를 권하는 진짜 이유\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/TFASrm63wYc\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">효율 때문이다.</h2>\n<p data-ke-size=\"size16\">- 맴캐시<br />- SQL&nbsp;<br />- REDIS&nbsp;</p>\n<p data-ke-size=\"size16\">이런거 다 따로 사용하면 서비스 비용이 증가합니다.</p>\n<p data-ke-size=\"size16\">시작은 SQLite 에 다 때려 넣고 비용을 절양합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">스타트가 망하는 이유에서 배우자</h2>\n<p data-ke-size=\"size16\">스타트업 이 망하는 이유는 저급한 서비스가 아닙니다.</p>\n<p data-ke-size=\"size16\">수요업는 시장에 들어간 것입니다.</p>\n<p data-ke-size=\"size16\">차라리 빠르고 쉽게 만들고 적은 비용으로 망하는 것이 좋습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=TFASrm63wYc\n\n\n\n \n효율 때문이다.\n- 맴캐시\n- SQL \n- REDIS \n이런거 다 따로 사용하면 서비스 비용이 증가합니다.\n시작은 SQLite 에 다 때려 넣고 비용을 절양합니다.\n \n스타트가 망하는 이유에서 배우자\n스타트업 이 망하는 이유는 저급한 서비스가 아닙니다.\n수요업는 시장에 들어간 것입니다.\n차라리 빠르고 쉽게 만들고 적은 비용으로 망하는 것이 좋습니다.",
        "guid": "https://serverdown.tistory.com/1555",
        "categories": [
          "프로그래밍/개발메모",
          "SQLite"
        ],
        "isoDate": "2026-01-10T07:46:58.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "유니티 라이팅 - 기본부더 다시 배우자",
        "link": "https://serverdown.tistory.com/1554",
        "pubDate": "Sat, 10 Jan 2026 16:29:00 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1554#entry1554comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"347\" data-origin-height=\"145\"><span data-url=\"https://blog.kakaocdn.net/dn/bVfNLR/dJMcafSRcGR/I15hTSOxJFuuP5yFmRjBn1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bVfNLR/dJMcafSRcGR/I15hTSOxJFuuP5yFmRjBn1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bVfNLR/dJMcafSRcGR/I15hTSOxJFuuP5yFmRjBn1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbVfNLR%2FdJMcafSRcGR%2FI15hTSOxJFuuP5yFmRjBn1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"347\" height=\"145\" data-origin-width=\"347\" data-origin-height=\"145\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=KxqQrx--cJU\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=KxqQrx--cJU</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=KxqQrx--cJU\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/wleka/hyZQRuK9tZ/qoIbozq6IKaEzLvkXh5nW1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/R8M3o/hyZQ3KgNxX/gIKDrFNAoAaOb8QyLWtxk0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/BuZtm/hyZRk4JRsE/lXAMoek8D0I4rbIucuQsG0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"유니티 빛 그 자체\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/KxqQrx--cJU\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">한참 까먹고 있었는데 다시보니 유용한 내용이였습니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=KxqQrx--cJU\n\n\n\n \n한참 까먹고 있었는데 다시보니 유용한 내용이였습니다.",
        "guid": "https://serverdown.tistory.com/1554",
        "categories": [
          "프로그래밍/개발메모",
          "유니티"
        ],
        "isoDate": "2026-01-10T07:29:00.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": []
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": [
      {
        "title": "사피엔스",
        "link": "https://hyeonseok.com/blog/948",
        "pubDate": "Sun, 11 Jan 2026 11:53:18 GMT",
        "content": "<p><img src=\"/static/blog/sapiens.jpg\" class=\"major\" alt=\"사피엔스 책 표지\"> 워낙 유명한 책이다. 히브리어로 쓰여져서 무려 30여개의 언어로 변역됐다고 한다. 그러면 이 책은 히브리어에서 번역된 것일까 영어에서 번역된 것일까 갑자기 궁금해졌서 찾아봤다. 2011년 히브어로 책이 나오고 2014년 영어판이 나오면서 유명해 졌다고 한다. 한국어 판은 이 영어판을 번역해서 2015년 김영사에서 출간한 책이라고 한다. 책 제목만 봤을땐 철학적이어서 너무 어렵지 않을까 싶었는데 읽어보니 역사책이지만 지극히 과학적이고 곳곳에 유쾌한 상상력들이 가미되어 있어서 아주 재미있다.</p>\r\n\r\n<p>인류는 어떻게 다른 종과 달랐고 현재 어떤 위치에 있는지 깊은 통찰력을 보여준다. 네안데르탈인이나 다른 인간 종들이 있었지만 사피엔스가 다 쓸어버렸다는 데에서는 좀 충격도 받았다. 인류는 정말 독보적으로 지구를 변화시켰고 앞으로도 그럴 것으로 생각된다. 현재의 과학으로 일어나는 일을 봤을 때 사피엔스가 계속될지에 대한 질문도 아주 날카로왔다. AI가 큰 역할을 할 것 같은데 사피엔스가 진화론적인 관점에서 계속 존재할지는 나도 부정적이다.</p>\r\n\r\n<p>앞으로 큰 변화가 있을 것 같은데 이런 변화를 어떤 관점으로 봐야 할지를 다시 생각할 수 있게 해주는 좋은 책이다. 특히 인류의 많은 문화나 개념들이 종교와 같이 상상을 토대로 한 것이라는 관점은 참으로 신선하다. 인류에 대해서 많은 것을 배웠고 지금 일어나는 일들을 이해하는데 많은 도움이 되었다.</p>",
        "contentSnippet": "워낙 유명한 책이다. 히브리어로 쓰여져서 무려 30여개의 언어로 변역됐다고 한다. 그러면 이 책은 히브리어에서 번역된 것일까 영어에서 번역된 것일까 갑자기 궁금해졌서 찾아봤다. 2011년 히브어로 책이 나오고 2014년 영어판이 나오면서 유명해 졌다고 한다. 한국어 판은 이 영어판을 번역해서 2015년 김영사에서 출간한 책이라고 한다. 책 제목만 봤을땐 철학적이어서 너무 어렵지 않을까 싶었는데 읽어보니 역사책이지만 지극히 과학적이고 곳곳에 유쾌한 상상력들이 가미되어 있어서 아주 재미있다.\n\r\n\r\n인류는 어떻게 다른 종과 달랐고 현재 어떤 위치에 있는지 깊은 통찰력을 보여준다. 네안데르탈인이나 다른 인간 종들이 있었지만 사피엔스가 다 쓸어버렸다는 데에서는 좀 충격도 받았다. 인류는 정말 독보적으로 지구를 변화시켰고 앞으로도 그럴 것으로 생각된다. 현재의 과학으로 일어나는 일을 봤을 때 사피엔스가 계속될지에 대한 질문도 아주 날카로왔다. AI가 큰 역할을 할 것 같은데 사피엔스가 진화론적인 관점에서 계속 존재할지는 나도 부정적이다.\n\r\n\r\n앞으로 큰 변화가 있을 것 같은데 이런 변화를 어떤 관점으로 봐야 할지를 다시 생각할 수 있게 해주는 좋은 책이다. 특히 인류의 많은 문화나 개념들이 종교와 같이 상상을 토대로 한 것이라는 관점은 참으로 신선하다. 인류에 대해서 많은 것을 배웠고 지금 일어나는 일들을 이해하는데 많은 도움이 되었다.",
        "guid": "https://hyeonseok.com/blog/948",
        "isoDate": "2026-01-11T11:53:18.000Z"
      }
    ]
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "엔터프라이즈 LLM 서비스 구축기 1: 컨텍스트 엔지니어링",
        "link": "https://techblog.lycorp.co.jp/ko/building-an-llm-service-for-enterprise-1-context-engineering",
        "pubDate": "Wed, 14 Jan 2026 02:00:00 GMT",
        "content": "들어가며안녕하세요. Cloud AI Platform 팀에서 AI 어시스턴트의 PM 및 기술 리딩을 맡고 있는 한우형입니다. 클라우드 환경에 AI를 도입해 운영 생산성을 높이는 일을...",
        "contentSnippet": "들어가며안녕하세요. Cloud AI Platform 팀에서 AI 어시스턴트의 PM 및 기술 리딩을 맡고 있는 한우형입니다. 클라우드 환경에 AI를 도입해 운영 생산성을 높이는 일을...",
        "guid": "https://techblog.lycorp.co.jp/ko/building-an-llm-service-for-enterprise-1-context-engineering",
        "isoDate": "2026-01-14T02:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": [
      {
        "title": "2025 re:Invent 여정",
        "link": "https://blog.banksalad.com/tech/aws-reinvent-2025/",
        "pubDate": "Tue, 13 Jan 2026 00:00:00 GMT",
        "content": "2025 re:Invent 여정 AWS re:Invent…",
        "contentSnippet": "2025 re:Invent 여정 AWS re:Invent…",
        "guid": "https://blog.banksalad.com/tech/aws-reinvent-2025/",
        "isoDate": "2026-01-13T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "두 번 실수하지 말자",
        "link": "https://www.thestartupbible.com/2026/01/never-miss-twice.html",
        "pubDate": "Wed, 14 Jan 2026 21:34:00 +0000",
        "content:encodedSnippet": "바로 전 글에서 골프 이야기를 잠깐 했는데, 같은 내용으로 이 포스팅을 시작해 본다. 실제로 골프를 쳤던 방콕 골프장에서 1번 홀이 어려운 파 5였고, 여기서 나는 4개 오버해서 9개를 친 적이 있다.(골프 용어로는 쿼드러플인데, 절대로 해서는 안 되는 점수다). 그리고 그다음 2번 홀은 파3인데, 여기서 3개 오버하면서 6개를 쳐서 소위 말하는 양파를 했고, 3번 홀은 파4인데 6개를 쳐서 더블보기를 했다. 이렇게 치고 나니 18홀 중 3개를 쳤는데 점수는 이미 9+가 됐다. 그리고 이후 4번 홀부터 내 마인드는 어차피 이번 라운딩은 망했으니까 그냥 대충 막 쳐야겠다였고, 정말로 막 쳐서 최악의 점수가 나왔다. 그리고 막 치는 4시간 내내 이번 게임은 망했으니까, 다음에 제대로 쳐야지 생각했다.\n그런데 나중에 숙소로 돌아와서 생각해 보니, 정말 후회가 많이 됐고, 그날 내 행동에 대해 짜증이 많이 났다. 첫 3개 홀을 못 쳤으면, 그 다음엔 잘 치기 위해서 더 집중해야 했는데, 나는 그냥 이생망(=이번 생은 망했다)의 마인드로 고칠 수 있는 실수를 안 고치고 계속 실수했고, 이렇게 해서 조금만 경기가 안 풀리면 그냥 막 치는 게 습관화됐을 가능성이 매우 크다. 최악의 행동이었다.\n요새 내가 듣는 몇 팟캐스트의 단골이 ‘Atomic Habits’의 저자 제임스 클리어인데, 이 책에서 정확하게 이런 행동을 절대로 하지 말라고 하면서 “한 번 실수는 사고지만, 두 번 실수는 새로운 습관의 시작이 될 수 있다.”라는 말을 한다. 무슨 말이냐 하면, 내가 초반에 골프를 못 친건 사고지만, 이후에 포기하고 마음먹고 그냥 계속 실수한 건 나쁜 습관의 시작이 된다는 말이다.\n새해 결심을 아침에 운동을 열심히 하기로 했다면, 그리고 이게 작심삼일이 되는 나쁜 습관으로 바뀌는 걸 원치 않는다면, 매일 몸을 움직여야 한다. 아침 일찍 미팅이 있어서 하루 빠지고, 그다음 날은 늦게 일어나서 또 빠지면, 그냥 이번 주는 운동 안 하고 다음 주부터 열심히 해야지라는 생각을 많은 분들이 하는데, 이렇게 되면 일 년 내내 절대로 운동하지 않는다. 아침 일찍 미팅이 있어서 운동을 안 한 건 실수다. 그리고 늦게 일어나서 못 한 것도 실수다. 하지만, 그다음 날 곧바로 이 실수를 바로잡고 운동을 해야 한다. 안 그러면 운동하지 않는 행동이 습관화되기 때문이다.\n새해 결심이 다이어트라서 식단 관리를 잘하다가 화요일 저녁에 피자 한 판을 다 먹는 칼로리 폭탄 실수를 했다면, 그다음 날은 다시 제대로 식단 관리를 하면 된다. 하지만, 많은 사람들이 이렇게 먹으면 기분이 상하고 어차피 식단 망했기 때문에 이번 주는 그냥 막 먹고 다음 주부터 다시 식단 관리하자라는 생각으로 일주일 내내 막 먹는다. 이렇게 두 번, 세 번 실수하면 막 먹는 게 습관이 돼서 다이어트는 물 건너간다. 누구도 완벽할 순 없고, 누구나 다 실수할 수 있는데, 중요한 건 그 시점에 바로 고치는 것이다. 이생망 기분으로 두 번 실수하면, 정말로 이생망된다.\n운동을 빠지면, 다시 하면 된다. 잘하다가 또 빠지면, 그 이후에 또다시 하며 된다. 다이어트하는데 칼로리 폭탄을 먹었다면, 그다음 끼니는 건강하게 먹으면 된다. 건강하게 먹다가 어느 날 혼자서 치킨 한 마리랑 맥주를 먹었다면, 그다음 끼니부터 또 식단 관리하면 된다.\n제임스 클리어의 두 번 실수하지 않는 프레임은 다음과 같다. 하루를 4쿼터로 나누고, 이 중 4쿼터를 모두 완벽하게 살면 좋겠지만, 그렇게 하기는 너무 힘드니까 4쿼터 중 한 쿼터만 실수하는 걸 목표로 삼으라고 한다. 한 쿼터만 실수하고, 나머지 세 쿼터는 실수하지 않는 걸 목표로 하면 나름 좋은 습관을 만드는 인생을 살 수 있다고 한다.\n한 번 실수했을 때 너무 자책하거나 실망하지 말고, 곧바로 다시 시도하는 게 연속적으로 실패하는 습관의 형성을 방지할 수 있다. “이생망”이라는 말은 우리가 절대로 생각해서도 안 되고, 입에 담아서도 안 되는 말이다. 다음 생은 없으니까.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2026/01/never-miss-twice.html#respond",
        "content": "바로 전 글에서 골프 이야기를 잠깐 했는데, 같은 내용으로 이 포스팅을 시작해 본다. 실제로 골프를 쳤던 방콕 골프장에서 1번 홀이 어려운 파 5였고, 여기서 나는 4개 오버해서 9개를 친 적이 있다.(골프 용어로는 쿼드러플인데, 절대로 해서는 안 되는 점수다). 그리고 그다음 2번 홀은 파3인데, 여기서 3개 오버하면서 6개를 쳐서 소위 말하는 양파를 했고, 3번 홀은 파4인데(...)",
        "contentSnippet": "바로 전 글에서 골프 이야기를 잠깐 했는데, 같은 내용으로 이 포스팅을 시작해 본다. 실제로 골프를 쳤던 방콕 골프장에서 1번 홀이 어려운 파 5였고, 여기서 나는 4개 오버해서 9개를 친 적이 있다.(골프 용어로는 쿼드러플인데, 절대로 해서는 안 되는 점수다). 그리고 그다음 2번 홀은 파3인데, 여기서 3개 오버하면서 6개를 쳐서 소위 말하는 양파를 했고, 3번 홀은 파4인데(...)",
        "guid": "https://www.thestartupbible.com/?p=9663",
        "categories": [
          "Uncategorized",
          "consistency",
          "failure",
          "FoundersAtWork",
          "habit",
          "inspiring"
        ],
        "isoDate": "2026-01-14T21:34:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "지금 제대로 해라",
        "link": "https://www.thestartupbible.com/2026/01/do-the-right-thing-now-not-later.html",
        "pubDate": "Sun, 11 Jan 2026 21:35:00 +0000",
        "content:encodedSnippet": "작년 연말에 따뜻한 방콕에서 며칠 동안 휴식을 가졌다. 말이 휴식이지만, 우린 워낙 적은 인력이 많은 일을 하고, 각자 맡은 일이 있어서 일하면서 쉬는 일정이었는데, 일보다는 휴식을 더 많이 하려고 노력했다.\n이 기간에 골프를 몇 번 쳤는데, 골프 라운딩이 끝나고 점수표를 보면 매번 이런 아쉬움의 말들을 했다. “1번 홀 파 5에서 물에 두 번 빠져서 4오버만 안 했다면 80대 쳤을 텐데.” , “13번 홀에서 퍼팅을 두 개로 끝냈다면 그 홀은 파했을 텐데. 오늘 퍼팅이 별로네.” , “아이언은 완벽했는데 드라이버가 오늘 협조를 안 해주네.”\n이후 숙소로 돌아와서 다시 업무를 처리하면서 몇몇 투자사 대표님들과 이메일, 카톡, 통화를 했는데, 이들이 이런 말들을 했다. “아쉽네요. 런웨이가 3개월만 더 있었다면 잘했을 텐데요.” , “그때 그 투자가 됐어야 하는데” , “굳이 그 기능을 개발하는데 시간, 사람, 돈을 그때 안 써야 했는데” , “그때 그 정도의 매출을 해야 했는데”\n실은 위에서 우리 투자사 대표들이 하는 말은 1년 내내 너무 많이 듣는 말이고, 들을 때마다 나도 같이 아쉬워하는데, 이날은 대표님들의 아쉬움과 오전의 내 골프 라운딩의 아쉬움이 머릿속에서 겹치면서 한 가지의 작은 깨달음과 배움이 있었다. 그건 바로 이게 인생이고, 인생에서 ‘그때’는 다시 오지 않기 때문에 그때, 또는 지금 무조건 최선을 다해서 잘해야 한다는 점이다. 그리고 그 순간이 지났다면, 결과에 대해서 다시는 생각하지 않고, 불평하지도 않고, 아쉬워하지도 않고, 그냥 바로 다음 수를 생각하고 거기에 집중해야 한다는 점이다.\n내 골프 라운딩에서 공이 물에 빠지지 않았다면, 모든 퍼팅을 세 개 대신 두 개로 마무리했다면, 그 칩샷을 삐직하지 않았다면,,,그러면 당연히 점수가 훨씬 더 좋았을 것이고, 최고의 골프 경기를 했을 텐데. 이런 후회는 시간 낭비다. 그때 티박스에 올랐을 때, 그린 위에 있을 때, 그때 나는 정신 차리고 제대로 해야 했다. 왜냐하면 기회라는 건 여러 번 오지 않고, 다시는 ‘그때’가 오지 않기 때문이다.\n런웨이가 3개월만 더 있었다면 새로운 기능을 출시해서 회사를 흑자전환 시켰을 텐데, 아쉽지만, 지금은 런웨이가 끝났다. 몇 달 전에 런웨이가 남아 있을 때, 그때 제대로 잘 해야 했다. 그때 그 투자를 받았다면 회사는 반등했을 텐데, 아쉽지만, 투자를 못 받아서 은행 잔고는 바닥났다. 그럼 그때 투자를 받았어야 한다. 그때 그 돈을 쓰지 말아야 했는데, 아쉽지만 이미 돈은 썼고 우린 장래가 어두운 돈 없는 스타트업이 됐다. 아쉽지만, 그때 잘 해야 했고, 그때 제대로 된 판단을 해서 돈을 안 썼어야 한다.\n이게 인생이다. 다시는 ‘그때’가 오지 않는다. 지금 제대로 해라. 그때 제대로 안 했다면, 지금 제대로 해라. 그때에 대한 아쉬움과 불평은 도움이 안 된다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2026/01/do-the-right-thing-now-not-later.html#comments",
        "content": "작년 연말에 따뜻한 방콕에서 며칠 동안 휴식을 가졌다. 말이 휴식이지만, 우린 워낙 적은 인력이 많은 일을 하고, 각자 맡은 일이 있어서 일하면서 쉬는 일정이었는데, 일보다는 휴식을 더 많이 하려고 노력했다. 이 기간에 골프를 몇 번 쳤는데, 골프 라운딩이 끝나고 점수표를 보면 매번 이런 아쉬움의 말들을 했다. “1번 홀 파 5에서 물에 두 번 빠져서 4오버만(...)",
        "contentSnippet": "작년 연말에 따뜻한 방콕에서 며칠 동안 휴식을 가졌다. 말이 휴식이지만, 우린 워낙 적은 인력이 많은 일을 하고, 각자 맡은 일이 있어서 일하면서 쉬는 일정이었는데, 일보다는 휴식을 더 많이 하려고 노력했다. 이 기간에 골프를 몇 번 쳤는데, 골프 라운딩이 끝나고 점수표를 보면 매번 이런 아쉬움의 말들을 했다. “1번 홀 파 5에서 물에 두 번 빠져서 4오버만(...)",
        "guid": "https://www.thestartupbible.com/?p=9660",
        "categories": [
          "Uncategorized",
          "failure",
          "FoundersAtWork",
          "general"
        ],
        "isoDate": "2026-01-11T21:35:00.000Z"
      }
    ]
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "2026년부터 이렇게 달라집니다: 새로운 금융·복지·노동 정책 26가지",
        "link": "https://toss.im/tossfeed/article/new-policies-2026",
        "pubDate": "Wed, 14 Jan 2026 06:22:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}2026년에도 정부 부처의 다양한 정책이 나왔어요. 최저임금 인상부터 대중교통비 지원까지, 우리 일상에 직접 영향을 주는 변화들이에요. 여러 정책 중에서 꼭 챙겨볼 만한 26가지를 선정해 정리했어요.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}누구에게나 해당되는\n일상 속 변화\n1. 최저임금 10,320원\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}2026년 최저임금은 시간당 10,320원으로 2025년(10,030원)보다 2.9% 올랐어요. 주 40시간 근무 기준으로 계산하면, 주휴수당을 포함해 월 215만 6,880원을 받을 수 있어요.\n2. 실업급여 상승\n실업급여 하루 최대 지급액이 6만 6,000원에서 6만 8,100원으로 올랐어요. 한 달로 계산하면 약 6만 3,000원을 더 받게 돼요.\n3. 많이 탈수록 돌려받는 대중교통비\n대중교통을 자주 이용하는 사람을 위한 새로운 환급 제도가 시작돼요. 새로 도입되는 ‘모두의 카드’는 이용 횟수에 제한이 있었던 K-패스와 달리 일정 금액 이상 사용한 대중교통비를 돌려주는 방식이에요. 기존에 K-패스를 사용하고 있었다면 별도로 신청하지 않아도 대중교통 이용 금액에 따라 가장 많은 환급 혜택이 자동으로 적용돼요.\n4. 따로 계산하는 배당소득세\n고배당 상장법인*에서 받은 배당소득을 종합소득 과세 대상에서 제외해 분리과세하는 배당소득 분리과세도 시작돼요. 그동안은 연 2,000만 원을 초과하는 금융소득이 다른 종합소득과 합산되어 누진세율이 적용되었지만, 이제는 배당 규모에 따라 차등 세율이 적용돼 세금 부담이 줄어들 수 있어요.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*국내에 상장된 기업 중 현금배당액이 전년 대비 감소하지 않았으면서 배당성향 40% 이상이거나 배당성향이 25% 이상 및 전년 대비 10% 이상 배당이 증가한 상장법인. 투자회사, 공모·사모펀드, SPC, 부동산 리츠, 배당 ETF 상품 등은 해당하지 않아요.\n5. 자동으로 신청되는 금리인하요구권\n그동안은 대출 이후 소득이 늘거나 신용점수가 올라도, 금리인하요구권에 대해 잘 몰라서 지나치는 경우가 많았어요. 상반기부터는 토스처럼 마이데이터 서비스*를 활용하는 핀테크 앱에서 신용 상태와 소득 변화를 자동으로 확인해 금리인하요구권을 신청해줘요.\n* 여러 금융기관에 흩어진 금융소비자의 정보를 한곳에 모아 관리하는 서비스\n6. 전기·전자제품 회수·재활용 의무 모든 제품으로 확대\n가정에서 사용하는 모든 전기·전자제품이 생산자 책임 재활용(EPR)* 제도 대상으로 확대돼요. 작년까지는 세탁기, 냉장고, TV, 컴퓨터 등 중·대형 기기 50종만 해당됐는데, 이제 건조기, 전기자전거, 보조배터리, 블루투스 이어폰, 휴대용 선풍기까지 모든 전기·전자제품을 폐기물 스티커 없이 무상으로 수거해요.\n* Extended Producer Responsibility: 제품 생산자에게 제품 및 포장재의 폐기물 수거 및 재활용 의무를 부여하는 제도\n7. 농어촌 여행하면 50% 돌려받는 여행비\n인구감소지역으로 여행을 가면 여행 경비의 50%를 지역화폐로 돌려받을 수 있어요. 개인은 최대 10만 원, 단체는 최대 20만 원까지 지원받을 수 있어요. 여행지역에 사전 신청해 혜택 대상자로 선정되면, 여행을 마친 뒤 환급받는 방식이에요. 인구감소지역 84곳 중 공모로 선정된 20곳을 대상으로 상반기에 시행될 예정이에요.\n8. 고향사랑기부금 세액공제 확대\n10만 원 초과 20만 원 이하 고향사랑기부금에 대한 세액공제율이 15%에서 40%로 올라요. 주소지 외 지역에 20만 원을 기부하면 10만 원은 전액 공제되고, 나머지 10만 원은 지방소득세 포함 44%가 공제돼 총 14만 4,000원의 세액공제를 받을 수 있어요. 여기에 기부금액의 30% 한도로 답례품도 받을 수 있어서, 20만 원으로 20만 4,000원의 혜택을 볼 수 있죠.\n일을 한다면\n알아야 하는 정책\n9. 국민연금 보험료율·소득대체율 인상\n국민연금 보험료율이 9%에서 9.5%로 인상됐어요. 직장인은 늘어난 보험료를 회사와 절반씩 나눠 부담하고, 지역가입자나 자영업자는 전액을 본인이 부담해요. 월 300만 원 소득 기준으로 직장인은 약 7,500원, 지역가입자는 약 15,000원을 더 내야 해요.\n부담만 늘어나는 것은 아니에요. 보험료율과 함께 소득대체율*도 41.5%에서 43%로 올랐어요. 이 비율이 높아지면 연금 가입자가 노후에 받는 연금액도 커져요. 매달 내는 돈이 조금씩 늘지만, 그만큼 노후의 소득 안전망도 커지는 거죠.\n* 가입자의 생애 평균 소득에서 연금액이 차지하는 비율\n10. 3년 만에 인상된 건강보험료율\n건강보험료율도 7.09%에서 7.19%로 올랐어요. 월 300만 원 소득 기준으로 직장가입자는 약 1,500원이 올라 10만 7,850원, 지역가입자는 약 3,000원이 올라 21만 5,700원을 건강보험료로 내게 돼요.\n11. 중소기업 직장인을 위한 든든한 한 끼\n인구감소지역에서 근무하는 중소기업 직장인들은 아침이나 점심 중 한 끼를 지원받아요. 아침밥 지원은 1월부터 시행되며, 백반이나 김밥처럼 쌀로 만든 식사를 1,000원에 먹을 수 있어요. 하반기부터 시행되는 점심밥 지원은 근로지 내 식당에서 결제한 점심 식사값의 20%를 월 4만 원 한도로 할인 받는 정책이에요.\n12. 일손부족일자리 동행인센티브 신설\n직업훈련이나 일 경험 프로그램을 수료한 50세 이상 중장년층이 제조업, 운수업, 창고업 등 인력이 부족한 업종에 취업하면 인센티브를 받을 수 있어요. 근로자가 6개월, 12개월 근속할 경우 정부에게 각각 180만 원씩, 총 360만 원을 지급 받아요.\n아이 키우는 부모라면\n꼭 챙겨야 할 정보\n13. 육아기 10시 출근제 시작\n육아기 자녀를 둔 근로자가 돌봄 시간을 확보할 수 있도록 ‘육아기 10시 출근제’ 지원 사업이 새로 생겼어요. 만 12세 이하 자녀를 둔 근로자에게 임금 감소 없이 근로시간 단축을 허용한 중소·중견 사업주에게 정부가 근로자 1인당 월 30만 원을 지원하는 제도예요. 회사가 이 제도를 운영하는지 확인해보세요. 단, 육아기 근로시간 단축 제도와는 중복 지원되지 않아요.\n14. 늘어난 육아기 근로시간 단축 급여\n자녀 양육을 위해 근로시간을 줄인 근로자에게 지급되는 육아기 근로시간 단축 급여 상한액이 올랐어요. 주당 근무 시간을 10시간까지 줄이면 월 최대 250만 원, 10시간 이상 줄이면 최대 160만 원까지 지원돼요.\n15. 출산전후휴가 급여 상한액 증가\n출산전후휴가 급여 상한액이 월 210만 원에서 220만 원으로 올랐어요. 출산전후휴가는 총 90일이에요. 이 가운데 앞 60일은 회사가 급여를 지급하고, 남은 30일은 고용보험에서 지급해요. 근로자가 속한 회사가 우선지원대상기업*이라면 앞 60일 급여의 일부를 정부가 회사에 지원해줘요. 이때 정부가 회사에 지원하는 최대 금액이 월 220만 원으로 올랐어요. 남은 30일은 고용보험에서 지급되며, 이 기간에도 월 최대 220만 원까지 받을 수 있어요.\n* 상시 근로자 수가 제조업의 경우 500인 이하, 건설업ㆍ광업ㆍ운수업ㆍ창고업ㆍ통신업의 경우 300인 이하, 기타 산업의 경우 100인 이하인 중소기업\n16. 자녀 기준으로 넓어진 보육수당 비과세 한도\n만 6세 이하 자녀의 보육과 관련해서 지급받는 비과세 한도가 근로자 1인당 월 20만 원에서 자녀 1인당 월 20만 원으로 확대돼요. 자녀가 2명이면 40만 원, 3명이면 60만 원까지 비과세 혜택을 받을 수 있어요.\n17. 자녀수에 따라 커지는 신용카드 소득공제 혜택\n자녀 수에 따른 신용카드 소득공제 기본한도가 확대됐어요. 작년에는 연간 총급여 7,000만 원 이하인 경우 자녀 수와 무관하게 300만 원이었는데, 올해부터는 자녀 1명이면 350만 원, 자녀 2명 이상이면 400만 원으로 늘어나요. 총급여 7,000만 원 초과자는 무자녀일 때 250만 원, 자녀 1명일 때 275만 원, 자녀 2명 이상일 때 300만 원까지 공제받을 수 있어요.\n18. 초등 저학년 예체능 학원비 세제지원\n교육비 세액공제 대상에 만 9세 미만 자녀의 예체능 학원비도 포함됐어요. 이제 피아노, 태권도, 미술 등의 학원비도 연말정산 때 15% 세액공제받을 수 있어요.\n19. 육아휴직자 주담대 원금상환유예\n육아휴직 기간에는 주택담보대출 원금을 갚지 않고 이자만 내면 돼요. 본인이나 배우자가 육아휴직 중이라면 1월 31일부터 신청할 수 있어요. 집값이 9억 원 이하인 1주택자가 대출받은 지 1년 이상 된 경우 신청 가능해요. 육아휴직이 길어지면 최대 3년까지 연장할 수 있어요.\n20. 장난감도 이제 분리배출 대상\n생산자 책임 재활용(EPR) 제도 대상에 완구류도 추가됐어요. 그동안 레고를 비롯한 플라스틱 완구류는 재활용 의무대상에서 빠져 종량제봉투에 담아 버려야 했지만, 이제는 일반 플라스틱과 동일하게 분리배출할 수 있어요. 버려진 완구류는 회수 후 플레이크 형태로 만들어져 건설자재로 다시 쓰여요. 단, 배터리가 들어간 전기·전자제품 완구는 폭발 위험이 있어 소형가전 전용 수거함이나 지자체 전자제품 회수체계로 배출해야 해요.\n청년들을 위한\n새로운 기회\n21. 청년미래적금 신설\n6월에 청년미래적금이 출시돼요. 기존 청년도약계좌를 대신하는 상품으로, 가입 기간을 5년에서 3년으로 줄여 부담을 낮췄어요. 매달 저축하면 은행 이자와 별도로 정부가 저축액의 일정 비율을 지원금으로 적립해주고, 이자 소득은 전액 비과세예요. 이를 연 이자율로 환산하면 일반형은 최대 12%, 우대형은 16.9% 수준이죠. 우대형 가입자가 월 50만 원씩 3년 동안 저축하면, 정부 기여금을 더해 최대 2,200만 원의 목돈을 모을 수 있어요. 만 19~34세 청년 중 개인소득 6,000만 원 이하, 기준 중위소득 200% 이하라면 가입할 수 있어요.\n22. 청년일자리도약장려금 비수도권 우대지원\n비수도권 중소기업에서 2년간 근무하면 장려금을 받을 수 있어요. 근무 지역에 따라 일반 지역은 480만 원, 우대지원지역은 600만 원, 특별지원지역은 최대 720만 원까지 지원돼요.\n23. 대학생·대학원생 학자금대출\n취업 후 상환 학자금대출은 학부생과 대학원생이 재학 중 상환 부담 없이 학업에 전념하고 취업 후 상환하는 제도예요. 원래는 가구소득에 따라 신청할 수 있었지만, 올해부터 등록금 대출에 한해 소득이나 재산과 관계없이 누구나 신청할 수 있게 되었어요.\n24. 계속 이어지는 청년월세지원\n2025년까지만 운영 예정이었던 청년월세지원사업이 이제 상시 사업으로 바뀌어요. 만 19~34세 청년 중 기준 중위소득 60% 이하이면서 원가구* 소득이 기준 중위소득 100% 이하라면 24개월간 월 최대 20만 원의 월세를 지원받을 수 있어요.\n* 청년 가구와 부모를 포함한 가구\n25. 혜택이 넓어진 청년문화예술패스\n청년들에게 공연·전시 관람비 15만원을 지원하던 문화예술패스의 혜택이 더 커졌어요. 지원 대상은 만 19세에서 만 19~20세로 확대됐고, 비수도권에 거주하는 청년은 지원금이 20만 원으로 늘어났어요.\n26. 예비군 훈련비 상승\n2박 3일 동원훈련에 참가하는 1~4년 차 예비군 훈련비가 8만 2,000원에서 9만 5,000원으로, 4일간 출퇴근 방식 동원훈련 참가자 훈련비는 4만 원에서 5만 원으로 올라요. 5, 6년 차 예비군이 기본훈련과 작계훈련에 참가할 경우에는 별도 훈련비 2만 원을 지급해요.\n* 이 콘텐츠는 기획재정부에서 발간한 .css-114ityv{white-space:pre-wrap;cursor:pointer;-webkit-text-decoration:underline!important;text-decoration:underline!important;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}<2026년부터 이렇게 달라집니다>를 참고해서 작성되었습니다.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 윤동해 Graphic 윤자영",
        "content": "나를 위한 정책, 놓치지 말고 챙겨봐요",
        "contentSnippet": "나를 위한 정책, 놓치지 말고 챙겨봐요",
        "guid": "https://toss.im/tossfeed/article/new-policies-2026",
        "isoDate": "2026-01-14T06:22:00.000Z"
      },
      {
        "title": "토스 뮤직비디오 〈Spectrum〉, 영화관에서 만나요",
        "link": "https://toss.im/tossfeed/article/spectrum-theater",
        "pubDate": "Fri, 09 Jan 2026 01:38:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}좋아하는 영화를 떠올리면, 작품만큼이나 그 영화를 만났던 공간이 함께 기억에 남습니다. 세상을 바라보는 다양한 창작자들의 시선이 소개되는 독립영화관에서 누군가는 처음 알게 된 감독의 작품을 만나고, 또 누군가는 오래오래 마음에 남는 한 장면을 발견합니다.\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}지난 11월 공개한 토스의 뮤직비디오 〈Spectrum〉을 1월 한 달간 전국 10개의 독립영화관에서 만날 수 있어요. 인디밴드 아도이(ADOY)와 16팀의 비주얼 아티스트가 참여한 이 작품은 “어떤 세상에서 살고 싶나요?”라는 질문을 던집니다. 각자의 시선이 모여 빛나는 〈Spectrum〉처럼, 영화적 다양성을 지켜온 독립예술영화관에서 여러분이 꿈꾸는 세상의 모습을 그려보세요.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}1. 무비랜드\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n주소: 서울 성동구 연무장길 5-5\n뮤직비디오 상영 기간: 2025.12.25-2026.1.18 목·금·토·일요일\n\n\n.css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}무비랜드(@movieland.archive)는 서울 성수동에 위치한 30석 규모의 소극장입니다. 매달 큐레이터를 선정해 그들이 고른 구작 영화를 상영합니다. 코미디언 문상훈, 감독 신우석, 배우 이제훈, 박정민, 뮤지션 넉살, 자이언티 등 지금까지 다양한 직업인들이 무비랜드 큐레이터로 참여했어요. 큐레이터의 이야기는 인터뷰 콘텐츠, 포스터와 티켓 아트워크, 소장품 전시, 상영회 등 다양한 형태로 확장됩니다.\n🍿 상영시간표 & 예매하기 \n\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}사진: 무비랜드 \n2. 아트나인 \n\n\n주소: 서울 동작구 동작대로 89 12층\n뮤직비디오 상영 기간: 2025.12.24-2026.1.31\n\n\n아트나인(@artninecinema)은 2013년에 개관한 서울 강남권 최초의 예술영화관입니다. 총 150석 규모의 두 개 상영관이 마련되어 있으며, 관객이 영화에 온전히 몰입할 수 있도록 최적화된 환경에서 엄선된 작품들을 선보입니다. 매주 월요일에는 ‘해피 먼데이’ 이벤트를 통해 모든 영화를 조조요금인 7,000원*에 관람할 수 있습니다.\n*단, 배급사 요청에 의한 일부 영화 제외 및 이벤트 상영 제외\n🍿 상영시간표 & 예매하기 \n\n사진: 아트나인 \n3. 필름포럼\n\n\n주소: 서울 서대문구 성산로 527 하늬솔빌딩 A동 B1\n뮤직비디오 상영 기간: 2026.1.3-2026.1.31*\n*1,2관 마지막 작품 상영 전 송출\n\n\n필름포럼(@filmforum_cinema)은 서울 신촌에 위치한 예술영화전용관으로, 총 90석 규모의 1관과 52석 규모의 2관을 운영하고 있습니다. 독립·예술영화를 중심으로, 관객이 편안하게 머물며 영화를 만날 수 있는 환경을 지향합니다. ‘마음이 쉬어가는 곳’이라는 문장은 필름포럼이 추구하는 공간의 태도를 담고 있습니다.\n이곳에는 영화관을 비롯해 음료와 함께 영화의 여운을 즐길 수 있는 카페, 영화 음악을 감상할 수 있는 'LP 감상실'과 ‘필포 사진관’이 함께 자리하고 있습니다. 계절 영화 기획전과 단편영화 기획상영 등 다양한 프로그램을 통해, 일상 속에서 영화를 조금 더 깊이 경험할 수 있는 문화 공간으로 운영되고 있습니다.\n🍿 상영시간표 & 예매하기 \n\n사진: 필름포럼 \n4. 헤이리시네마\n\n\n주소: 경기 파주시 탄현면 헤이리마을길 93-119 커피공장103 3층\n뮤직비디오 상영 기간: 2026.1.2-2026.1.31\n\n\n헤이리시네마(@heyri_cinema)는 30석의 편안한 쇼파가 마련된 소규모 단관 극장으로 신선한 원두 커피를 즐기며 영화를 볼 수 있는 예술영화관입니다. 지상 3층에 위치하여, 영화를 보고 나오면 통유리를 통해 탁 트인 헤이리 마을의 풍경을 함께 즐길 수 있어요.\n🍿 상영시간표 & 예매하기 \n\n사진: 헤이리시네마\n5. 오오극장\n\n\n주소: 대구 중구 국채보상로 537\n뮤직비디오 상영 기간: 2025.12.22-2026.1.31\n\n\n오오극장(@55cine)은 2015년 대구 독립영화인들의 제안과 시민의 후원으로 문을 연 독립영화 전용관입니다. 지역 최초이자 대구 유일의 공간으로, 한국 독립영화를 중심으로 상영을 이어오고 있습니다. 55석 규모의 소극장으로, 극장의 이름 역시 상영관 좌석수에서 비롯되었어요.\n매년 2월에는 개관을 기념하는 특별전을 열어 해마다 주제에 맞는 좋은 독립영화를 소개하고, 연말에는 한 해 동안 대구에서 제작된 독립영화를 총망라하는 등 다채로운 기획전을 선보입니다. 극장 한편에 자리한 ‘삼삼다방’은 관객이 영화의 여운을 나누며 머물 수 있는 공간으로, 독립영화와 함께 대안예술 전시가 상시로 이루어지는 복합문화공간으로 운영되고 있습니다.\n🍿 상영시간표 & 예매하기 \n\n사진: 오오극장\n6. 광주독립영화관\n\n\n주소: 광주 동구 제봉로 96 광주영상복합문화관 6층\n뮤직비디오 상영 기간: 2025.12.29-2026.1.31\n\n\n광주독립영화관(@gjcinema)은 광주·전남 지역에서 유일하게 운영되는 독립영화 전용관입니다. 1년 내내 다채로운 독립영화를 만날 수 있고, 한국과 광주의 독립영화를 세계와 연결하고자 다양한 방식을 실험해 오고 있어요. 2025년 이탈리아문화원, 파리 포럼 데 이마주, 주한퀘벡정부대표부 등과의 협업을 통해 광주를 국제적인 문화적 대화의 장으로 확장하고 있습니다.\n🍿 상영시간표 & 예매하기 \n\n사진: 광주독립영화관 \n7. 강릉독립예술극장 신영\n\n\n주소: 강원 강릉시 경강로 2100 4층\n뮤직비디오 상영 기간: 2025.12.22-2026.1.31\n\n\n강릉독립예술극장 신영(@indiesy)은 강원 지역 최초의 민간 독립·예술영화 전용관입니다. 1960년대부터 강릉 시민들의 약속 장소로 자리해 온 ‘신영극장’이 2009년 문을 닫은 뒤, ‘강릉씨네마떼끄’를 통해 2012년 독립·예술영화 전용관으로 재탄생했습니다. 강릉씨네마떼끄는 1996년 강릉에서 출발한 비영리 민간단체로 1999년부터 정동진독립영화제를 꾸준히 개최·운영하고 있어요.\n1개관 111석 규모의 상영관과 로비에는 3,300여 장의 DVD와 블루레이를 비롯해 영화 에세이와 평론집, 현재 발행 중인 영화 잡지 등 다양한 영화 관련 자료가 비치되어 있습니다. 일부 자료는 관객이 직접 대여할 수도 있어요.\n🍿 상영시간표 & 예매하기 \n\n사진: 강릉독립예술극장 신영 \n8. 무사이 독립영화관\n\n\n주소: 부산 북구 산성로 12번길 21 지하1층\n뮤직비디오 상영 기간: 2025.12.22-2026.1.31\n*1.5-1.12 휴관\n\n\n무사이 독립영화관(@mousai.official)은 30석 규모의 소규모 영화관입니다. 빠른 소비보다는 여운을 남기는 영화를 중심으로 상영하며, 관객이 차분히 영화에 몰입할 수 있는 환경을 갖추고 있습니다. ‘무사이’라는 이름은 ‘생각을 불러일으키다’라는 뜻을 지닌 그리스어에서 가져왔습니다. \n이곳에는 독립영화관을 비롯해 작가와의 만남과 북토크, 글쓰기 프로그램이 운영되는 독립책방, 음료와 디저트를 제공하는 쌀빵 베이커리가 함께 자리하고 있습니다. 각 공간은 일상 속에서 예술을 자연스럽게 경험하고, 사람과 이야기가 이어질 수 있도록 구성된 문화 커뮤니티로 운영되고 있습니다.\n🍿 상영시간표 & 예매하기 \n\n사진: 무사이 독립영화관 \n9. 인디플러스 천안\n\n\n주소: 충남 천안시 동남구 중앙로 111\n뮤직비디오 상영 기간: 2025.12.24-2026.1.31\n\n\n인디플러스 천안(@indieplusca)은 충청남도에서 유일하게 운영되는 독립‧예술영화 전용관입니다. 50석 규모의 상영관에는 장애인석이 마련되어 있어 누구나 영화를 즐길 수 있는 환경을 갖추고 있으며, 정기 상영과 기획전을 통해 최신 독립‧예술영화를 꾸준히 소개합니다. \n천안독립영화상영회와 시민 서포터즈가 함께하는 ‘천씨네 영화상영회’, 배리어프리 영화 상영 등 다양한 프로그램을 운영하며, 관객과의 대화(GV)와 소규모 행사 등을 통해 영화 감상의 경험을 공동체적인 문화로 확장해 나가고 있어요.\n🍿 상영시간표 & 예매하기 \n\n사진: 인디플러스 천안 \n10. 안동중앙아트시네마\n\n\n주소: 경북 안동시 문화광장길 45\n뮤직비디오 상영 기간: 2026.1.2-2026.1.31\n\n\n안동중앙아트시네마(@joongangcinema.andong)는 경북 북부 지역에서 유일하게 예술영화를 만날 수 있는 공간이자 경북 북부 영화문화를 이어오는 중심 역할을 해왔습니다. 지역의 영상문화 콘텐츠, 문화 복지, 축제 등과 연계해 지역의 필요에 따라 다양한 역할을 맡아가고 있습니다. 한 해 평균 140편 안팎의 작품을 소개하며, 지역민들이 다양한 영화를 접할 수 있는 선택지를 꾸준히 마련하고 있습니다.\n🍿 상영시간표 & 예매하기 \n\n사진: 안동중앙아트시네마",
        "content": "토스 뮤직비디오를 만날 수 있는 전국 독립예술영화관 10곳 ",
        "contentSnippet": "토스 뮤직비디오를 만날 수 있는 전국 독립예술영화관 10곳",
        "guid": "https://toss.im/tossfeed/article/spectrum-theater",
        "isoDate": "2026-01-09T01:38:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]