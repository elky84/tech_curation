[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Nelson Daniel Troncoso",
        "title": "What’s New in Visual Studio Build Insights 17.12",
        "link": "https://devblogs.microsoft.com/cppblog/build-insights-17-12/",
        "pubDate": "Thu, 12 Sep 2024 20:56:58 +0000",
        "content:encodedSnippet": "We are excited to announce the latest Visual Studio 2022 17.12 Build Insights features. These updates provide developers with greater control and accuracy when diagnosing and optimizing C++ builds directly within Visual Studio.\nDownload Visual Studio 2022 17.12 Preview\nWe extend our thanks to the developer community, particularly our game studio partners, for providing invaluable feedback. Your input plays a vital role in shaping these new features.\nLearn more about Build Insights with our tutorials and documentation:\nC++ Build Insights | Microsoft Learn \nTutorial: Troubleshoot function inlining on build time | Microsoft Learn \nTutorial: Troubleshoot header file impact on build time | Microsoft Learn\nRun Build Insights on Selected Files\nThis feature is a game-changer for those who want to target specific files without analyzing the entire project. You can select a few files, run Build Insights on them, and see exactly how these files impact build performance. It’s perfect for fine-tuning your project and making targeted optimizations. \n\nFilter Projects \nWorking in a multi-project environment? The Project Filter feature allows you to focus your diagnostics on the projects most relevant to your current work. For instance, you can filter the analysis to focus solely on the core components of a specific project, making it easier to pinpoint areas that need optimization. \n \nFilter Files Using a Glob Pattern\nThe File Path Filter is incredibly useful for narrowing down your analysis to specific directories or excluding paths that aren’t relevant to your task. For example, you can exclude third-party libraries and focus only on parts of the codebase critical to the current build. \n \nView Explanation with Documentation Link\nYou can now see a short description of how each tab of Build Insights can be used, along with a link to the documentation for a detailed explanation. \n\nEnhanced Save Experience \nNow you can designate a folder to automatically store the reports so you can easily access them during your investigation. This will save you the work of manually specifying a folder each time you save your reports. \n \n \nPath Updates\nWe have added a File Name column for both files and translation units. displayed by default to help you quickly identify files without parsing lengthy paths. Additionally, we have hidden full and relative paths to reduce clutter. To see full paths, simply hover over the file.  \n\nNew Metrics \nWe have added two new columns, “Exclusive Duration” (Self) and “Inclusive Duration” (Total): \nExclusive Duration: Measures the time spent solely on the current task. \nInclusive Duration: Captures the total time spent on a task, including all nested tasks. \n \nRenaming of Time Column to Wall Time Responsibility \nWhen we introduced the “Time” column in Visual Studio Build Insights, we aimed to simplify the naming. However, we’ve found that it may cause confusion. While the column has always shown Wall Clock Time Responsibility (WCTR) or Wall Time Responsibility —which adjusts for parallelism by factoring in how tasks overlap — many users assumed it represented raw task duration. \nTo provide better clarity, we’re renaming this column to “Wall Time Responsibility”. This more accurately reflects what the data is measuring: the true impact of each task on the overall build time, especially in parallel environments. We believe this change will help developers gain clearer insights and optimize their builds more effectively. \nSend Us Your Feedback! \nReady to experience the new features in Visual Studio 2022 17.12? Download it today and start optimizing your C++ builds with Build Insights. Don’t forget to share your feedback with us to help shape future updates! \nLet us know your thoughts and what additional capabilities you’d like to see from this feature next! We are actively developing this feature set and would love to hear what would improve your workflow even more. The comments below are open for us to track any requests. You can also find us on Twitter (@VisualC) or via email at visualcpp@microsoft.com. To open a bug, please see Visual Studio Feedback. \nThe post What’s New in Visual Studio Build Insights 17.12 appeared first on C++ Team Blog.",
        "dc:creator": "Nelson Daniel Troncoso",
        "comments": "https://devblogs.microsoft.com/cppblog/build-insights-17-12/#comments",
        "content": "<p>We are excited to announce the latest Visual Studio 2022 17.12 Build Insights features. These updates provide developers with greater control and accuracy when diagnosing and optimizing C++ builds directly within Visual Studio. Download Visual Studio 2022 17.12 Preview We extend our thanks to the developer community, particularly our game studio partners, for providing invaluable [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/build-insights-17-12/\">What’s New in Visual Studio Build Insights 17.12</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "We are excited to announce the latest Visual Studio 2022 17.12 Build Insights features. These updates provide developers with greater control and accuracy when diagnosing and optimizing C++ builds directly within Visual Studio. Download Visual Studio 2022 17.12 Preview We extend our thanks to the developer community, particularly our game studio partners, for providing invaluable […]\nThe post What’s New in Visual Studio Build Insights 17.12 appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34646",
        "categories": [
          "Announcement",
          "Build Insights",
          "Build Optimization",
          "C++"
        ],
        "isoDate": "2024-09-12T20:56:58.000Z"
      },
      {
        "creator": "Sy Brand",
        "title": "Microsoft C++ Team at CppCon 2024",
        "link": "https://devblogs.microsoft.com/cppblog/microsoft-c-team-at-cppcon-2024/",
        "pubDate": "Thu, 12 Sep 2024 17:03:30 +0000",
        "content:encodedSnippet": "As always our team will be at CppCon this year with a host of presentations. Many of us will also be present at our team’s booth in the main hall for the first four days of the conference. Come say hi and let us know if you have any questions about our talks, products, or anything else! You can also join the #visual_studio channel on the CppCon Discord to talk to us (note: to join, head to #directory channel first, and check the checkbox next to “Visual Studio” box).\nWe’re also running a survey for attendees. If you have a moment, please take our survey. It’s quick and you could win a duffel bag or utility bag.\nHere’s the lineup:\nMonday 16th​\nPeering Forward: C++’s Next Decade — Herb Sutter – 8:45am\nSo You Think You Can Hash – Victor Ciura​ – 2:00pm\nTuesday​ 17th​\n10 Problems Large Companies have with Dependency Management and How to Solve Them – Augustin Popa – 4:45pm​\n​Thursday 19th​​\nWhat’s New for Visual Studio Code – Sinem Akinci and Alexandra Kemper – 3:15pm\nFriday 20th​​\nWhat’s New for Visual Studio – Mryam Girmay and Michael Price – 1:30pm\nThe post Microsoft C++ Team at CppCon 2024 appeared first on C++ Team Blog.",
        "dc:creator": "Sy Brand",
        "comments": "https://devblogs.microsoft.com/cppblog/microsoft-c-team-at-cppcon-2024/#respond",
        "content": "<p>&#160; As always our team will be at CppCon this year with a host of presentations. Many of us will also be present at our team’s booth in the main hall for the first four days of the conference. Come say hi and let us know if you have any questions about our talks, products, [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/microsoft-c-team-at-cppcon-2024/\">Microsoft C++ Team at CppCon 2024</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "As always our team will be at CppCon this year with a host of presentations. Many of us will also be present at our team’s booth in the main hall for the first four days of the conference. Come say hi and let us know if you have any questions about our talks, products, […]\nThe post Microsoft C++ Team at CppCon 2024 appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34584",
        "categories": [
          "Announcement",
          "C++"
        ],
        "isoDate": "2024-09-12T17:03:30.000Z"
      },
      {
        "creator": "Sinem Akinci",
        "title": "Fix C++ warnings and errors with Copilot: Introducing AI-Assisted Code Fixes in Visual Studio",
        "link": "https://devblogs.microsoft.com/cppblog/fix-c-warnings-and-errors-with-copilot-introducing-ai-assisted-code-fixes-in-visual-studio/",
        "pubDate": "Wed, 11 Sep 2024 10:00:41 +0000",
        "content:encodedSnippet": "Stuck on an unfamiliar build error? Want to resolve your code errors quickly? Copilot is now integrated into Visual Studio error workflows to assist you with understanding and resolving C++ errors and warnings.\nTo access this new feature, you will need an active Copilot subscription and the latest 17.11 GA version of Visual Studio.\nHow does it work?\nThere are two different entry points to accommodate where you are at in your error workflow:\nThe Quick Action lightbulb proposes a fix of a given error inline in your code window.\nThe Error List Integration invokes Copilot in the chat window to explain the error code and showcase a proposed fix.\nSemantically relevant code snippets from your active file and related files are automatically included as context to increase the relevant of the proposed fix.\nFix with Copilot in the Quick Action Lightbulb\nCopilot is integrated into the Quick Action lightbulb in your code editor, so that you can invoke Copilot and view proposed fixes inline with a few simple clicks. Just hover over the diagnostic squiggle or double-click on a diagnostic message in your Error List to access Fix with Copilot via Quick Action Lightbulb.\nFrom here, Copilot will invoke the /fix command with semantically relevant C++ code snippets to propose a fix for your code.\n\nYou can edit the proposed code, accept any changes inline, or ask any follow-up questions in the inline Copilot Chat pane, without having to navigate away from the code editor.\nExplain and Fix with Copilot in the Error List\nIf you want to learn more about the error itself, Copilot is integrated in the Error List to invoke by selecting the Copilot icon to the left of a code warning or error to provide an explanation alongside a proposed fix through the Chat pane. This can be beneficial for more complex fixes, as it can provide multiple code snippets across several files and a deeper understanding of the error itself.\n\nGiven the same relevant C++ context, it will help you more deeply understand the error code and propose a fix for the code. You also can ask follow-up questions or add any additional details via the Chat pane to probe further.\n\nWhat do you think?\nPlease let us know anything you’d like to see added to this feature or your experiences with this fixing experience. We have a survey available for any feedback here: https://www.surveymonkey.com/r/RKG68YN. You’ll need an active GitHub Copilot subscription. Download the latest version of Visual Studio and give it a try.\nIn addition, our team is working hard on improving C++ integrations with Copilot Chat, so please let us know any other enhancements you’d like to see to your C++ workflows and content you’d like to see.\nWe welcome all types of feedback on your experience with the product. Comment below, or you can find us via email at visualcpp@microsoft.com or via X at @VisualC.\nThe post Fix C++ warnings and errors with Copilot: Introducing AI-Assisted Code Fixes in Visual Studio appeared first on C++ Team Blog.",
        "dc:creator": "Sinem Akinci",
        "comments": "https://devblogs.microsoft.com/cppblog/fix-c-warnings-and-errors-with-copilot-introducing-ai-assisted-code-fixes-in-visual-studio/#comments",
        "content": "<p>Stuck on an unfamiliar build error? Want to resolve your code errors quickly? Copilot is now integrated into Visual Studio error workflows to assist you with understanding and resolving C++ errors and warnings. To access this new feature, you will need an active Copilot subscription and the latest 17.11 GA version of Visual Studio. How [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/fix-c-warnings-and-errors-with-copilot-introducing-ai-assisted-code-fixes-in-visual-studio/\">Fix C++ warnings and errors with Copilot: Introducing AI-Assisted Code Fixes in Visual Studio</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "Stuck on an unfamiliar build error? Want to resolve your code errors quickly? Copilot is now integrated into Visual Studio error workflows to assist you with understanding and resolving C++ errors and warnings. To access this new feature, you will need an active Copilot subscription and the latest 17.11 GA version of Visual Studio. How […]\nThe post Fix C++ warnings and errors with Copilot: Introducing AI-Assisted Code Fixes in Visual Studio appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34627",
        "categories": [
          "C++",
          "Copilot"
        ],
        "isoDate": "2024-09-11T10:00:41.000Z"
      },
      {
        "creator": "Augustin Popa",
        "title": "Askia, an Ipsos company, achieved faster, reproducible builds with vcpkg",
        "link": "https://devblogs.microsoft.com/cppblog/askia-an-ipsos-company-achieved-faster-reproducible-builds-with-vcpkg/",
        "pubDate": "Mon, 09 Sep 2024 19:09:56 +0000",
        "content:encodedSnippet": "vcpkg is a free and open-source C/C++ package manager maintained by Microsoft and the C++ community that runs on Windows, macOS, and Linux. Over the years we have heard from companies using vcpkg to manage dependencies at enterprise-scale. In this interview, I spoke to Dimitri Rochette, a lead developer at Askia, an Ipsos company, about vcpkg’s impact on their team.\n\nAfter switching to vcpkg and CMake, Askia was able to reduce build times for their dependencies by using the vcpkg binary caching feature and reduce their code size by about 300,000 lines by eliminating project files, scripts, and copied dependencies. Switching to vcpkg also allowed them to ensure consistent and reproducible builds across multiple platforms, access a vast array of libraries, streamline their onboarding process as their development team grew, and standardize the use of microservices in a multi-repository environment.\nQ: Can you tell us about your company and team?\nAskia, a software company with two decades of experience, specializes in the development of tools for survey creation, response collection, and data analysis. In 2020, Ipsos, a global leader in market research, acquired Askia with the aim of collaboratively developing a platform that aligns with their ambitious goals. At the time of acquisition, Askia was a team of 30. However, with substantial investment from Ipsos, the team expanded rapidly to 90 members within just two years.\nQ: Can you tell us about your C++ development environment?\nAll our teams utilize the latest Visual Studio 2022. For C++ development, we employ two compilers: MSVC and GCC13. Our projects are all built with CMake and vcpkg. We’ve also implemented additional setup scripts in PowerShell 7 (PWSH) to ensure portability between Windows and Linux. These scripts handle the setup of developer and CI machines, GitHub tokens, NuGet caching, the initial cloning of vcpkg, and database creation for clusters or unit tests. We’re quite satisfied with CMake, despite the initial setup being challenging. The integration with Visual Studio continues to improve, and maintaining a single project for two platforms has been a significant advantage.\nWithin our project scope, the majority of our code is written in C++. We initially started with C++17 and have now transitioned to C++23. We strive to stay updated with the latest stable compilers for MSVC and GCC. Occasionally, we face challenges waiting for implementations to be available on both compilers. C++ code is on our critical path, and we aim to minimize latency as much as possible. We also have numerous services in C#.Net8, which is the most commonly used language company wise. We have a significant amount of T-SQL code as we heavily rely on SQL Server for our C++ services. For the frontend, we took a chance on Svelte before its 1.0 release, and we are extremely satisfied with the outcome today.\nOur development environment is based on Windows, while our production target is Ubuntu 22.04, housed within Docker containers. Despite this, all our code is compatible with Windows and is compiled using MSVC. This allows us to exchange services between both platforms.\nOur Docker container is structured in four layers, all built on Ubuntu 22.04:\nBase Image: This includes additional apt repositories, security measures, and an ODBC driver.\n\nDev: This layer is equipped with all the necessary tools for developers. It’s used as a workspace by developers and by the continuous integration (CI) system to execute unit tests.\n\nStatic Analysis: This layer is used by the CI system for static analysis and includes SonarCloud and its prerequisites.\nProduction: This is the image that runs the release version. It’s used by the CI system to install binaries of the Dev build on a clean image and is then uploaded for Kubernetes consumption.\nWe utilize the same images for both developers and CI, leveraging vcpkg binary caching (with GitHub serving as a NuGet server). This means that each build by a developer or CI either downloads or builds and uploads the result to the shared cache. We have 274 packages, with the main ones being downloaded 300 times per month. The ability to save even a single compilation of packages like OpenSSL or Python is greatly appreciated by the team and reduces our CI build times and costs.\nOur current codebase is relatively compact, comprising approximately 40,000 lines of C++ code, which are divided across various repositories for services and components. Our legacy codebase is significantly larger, containing more than 2 million lines of C++ code. The introduction of CMake and vcpkg to our main repository resulted in a reduction of about 10% (or 300,000 lines), which included project files, scripts, and copied dependencies.\nWe utilize GitHub as our continuous integration system. Given that we have scripts to configure developer tools and machines, as well as standard Docker images, we leverage these in our CI environment. The same image used by developers for their work is also used in GitHub CI. Additionally, on GitHub, we employ the other layers of our Docker container for building our release version and executing unit tests.\nQ: What kinds of C++ libraries do you consume?\nFor first-party private/internal libraries, we have established a vcpkg registry with our shared library. Those packages are allowed to use any other library provided by vcpkg. This includes a wrapper for asynchronous messaging (librabbitmq), a wrapper for logging (spdlog), a configuration file with an override system (nlohmann-json), our HTTP server (boost-beast), plugins for our HTTP server (boost asio, curl, fmt), a JWT token checker (jwt-cpp, cppcodec, OpenSSL), and Python scripts (boost-python, python3). The most crucial package for us is our CMake scripts, which define all output folders, all parameters per platform (compiler, C++ version, debug/release, Windows SDK, UNICODE, _UNICODE, NOMINMAX, etc.), our CMake function for tagging versions with git hash and version files, branch name, scripts to create zip or NuGet as output of build, and scripts to copy dependency DLLs.\nAs for open-source dependencies, we directly utilize boost, fmt, gtest, magic-enum, nanodbc, nlohmann-json, spdlog, pybind11, librabbitmq, openssl, and libcurl.\nWe also have a significant amount of MFC and some third-party controls in our legacy codebase. In our new codebase, LaunchDarkly is used by C# projects, so it may be used in C++ in the future.\nQ: How were you managing C++ dependencies before vcpkg?\nIn our legacy stack, which is based on the Windows GUI in MFC, we had a variety of methods for managing dependencies. These included:\nIncluding them as source\nIncluding them as source with modifications\nUsing public NuGet packages with MSBuild projects\nIncluding them as pre-compiled binaries\nThe system was functional, but it was challenging to keep track of what was used and in which version. The ABI break before 2015 served as a useful reminder to consider upgrading our NuGet packages. Our initial inventory of repository candidates for the CMake/vcpkg migration took some time, but all the standard ones were relatively easy to identify.\nQ: When did your team move to vcpkg and why did you ultimately choose it?\nI had previously used vcpkg at another company to develop a Windows/Linux Qt tool. The use of CMake/vcpkg was a lifesaver, eliminating the need to manage both Visual Studio and Xcode projects. When I joined the company in 2019, I found the build process to be quite cumbersome. We were heavily reliant on Jenkins, with numerous scripts and file copies pre/post-build. Many projects required relative builds of other projects. My first proof of concept was converting some projects to CMake, which involved converting NuGet dependencies to vcpkg. The integration of cmakeconfig.json into Visual Studio 2019 facilitated user acceptance. We maintained both sln + CMake in the repository for about a year in case we encountered any issues.\nThe acquisition by Ipsos brought significant changes. The need for scalability necessitated major modifications. We had to develop new microservices, and as the team became more familiar with the advantages of CMake/vcpkg, we made vcpkg mandatory for all new projects. The primary goal at this stage was to expedite the onboarding of new developers. We aimed to minimize the steps required to launch and debug a unit test as much as possible. We have iteratively improved this process, and today, the steps take less than half a day.\nThe steps include:\nInstalling Visual Studio with C++\nInstalling ODBCDriver\nCloning vcpkg\nCreating a GitHub token for binary caching\nWith these steps, all our C++ projects could be cloned, compiled, and debugged in unit tests. If you install Docker and create the reference image, you can target both Windows and Linux.\nSo, yes, vcpkg has been instrumental in our onboarding process. We have tripled the team size in a few years. Standardizing the tools helps developers working on one repository to easily transition to another.\nQ: What is your overall impression of vcpkg?\nvcpkg has been a game-changer in my 25 years of working with C++. It has revolutionized the way we manage dependencies by ensuring consistent and reproducible builds across multiple platforms. With a vast array of libraries at our disposal, we have the flexibility to create or extend libraries as needed. The caching feature significantly speeds up our build process. Moreover, vcpkg has streamlined our onboarding process and standardized the use of microservices in a multi-repository environment.\nLearn More About vcpkg\nIf you want to learn more about vcpkg, check out our website at vcpkg.io and read the vcpkg overview in our documentation.\nIf you have a story you would like to share with us about your experiences with vcpkg, feel free to contact us at vcpkg@microsoft.com. You can submit bug reports in our GitHub issue tracker or make feature requests in our discussion forum.\nThe post Askia, an Ipsos company, achieved faster, reproducible builds with vcpkg appeared first on C++ Team Blog.",
        "dc:creator": "Augustin Popa",
        "comments": "https://devblogs.microsoft.com/cppblog/askia-an-ipsos-company-achieved-faster-reproducible-builds-with-vcpkg/#respond",
        "content": "<p>vcpkg is a free and open-source C/C++ package manager maintained by Microsoft and the C++ community that runs on Windows, macOS, and Linux. Over the years we have heard from companies using vcpkg to manage dependencies at enterprise-scale. In this interview, I spoke to Dimitri Rochette, a lead developer at Askia, an Ipsos company, about [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/askia-an-ipsos-company-achieved-faster-reproducible-builds-with-vcpkg/\">Askia, an Ipsos company, achieved faster, reproducible builds with vcpkg</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "vcpkg is a free and open-source C/C++ package manager maintained by Microsoft and the C++ community that runs on Windows, macOS, and Linux. Over the years we have heard from companies using vcpkg to manage dependencies at enterprise-scale. In this interview, I spoke to Dimitri Rochette, a lead developer at Askia, an Ipsos company, about […]\nThe post Askia, an Ipsos company, achieved faster, reproducible builds with vcpkg appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34577",
        "categories": [
          "C++",
          "Vcpkg",
          "vcpkg"
        ],
        "isoDate": "2024-09-09T19:09:56.000Z"
      }
    ]
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Simulator-based reinforcement learning for data center cooling optimization",
        "link": "https://engineering.fb.com/2024/09/10/data-center-engineering/simulator-based-reinforcement-learning-for-data-center-cooling-optimization/",
        "pubDate": "Tue, 10 Sep 2024 16:00:31 +0000",
        "content:encodedSnippet": "We’re sharing more about the role that reinforcement learning plays in helping us optimize our data centers’ environmental controls.\nOur reinforcement learning-based approach has helped us reduce energy consumption and water usage across various weather conditions in our data centers.  \nMeta is revamping its new data center design to optimize for artificial intelligence and the same methodology will be applicable for future data center optimizations as well.\nEfficiency is one of the key components of Meta’s approach to designing, building, and operating sustainable data centers. Besides the IT load, cooling is the primary consumer of energy and water in the data center environment. Improving the cooling efficiency helps reduce our energy use, water use, and greenhouse gas (GHG) emissions and also helps address one of the greatest challenges of all – climate change.\nMost of Meta’s existing data centers use outdoor air and evaporative cooling systems to maintain environmental conditions within the envelope of temperature between 65°F and 85°F (18°C and 30°C) and relative humidity between 13 and 80%. As water and energy are consumed in the conditioning of this air, optimizing the amount of supply airflow that has to be conditioned is a high priority in terms of improving operational efficiency. \nSince 2021, we have been leveraging AI to optimize the amount of airflow supply into data centers for cooling purposes. Using simulator-based reinforcement learning, we have, on average, reduced the supply fan energy consumption at one of the pilot regions by 20% and water usage by 4% across various weather conditions.\nPreviously, we shared how a physics-based thermal simulator helps us optimize our data centers’ environmental controls. Now, we will shed more light on the role of reinforcement learning in the solution. As Meta is revamping its new data center design to optimize for artificial intelligence, the same methodology will be applicable for future data center optimizations as well to improve operational efficiency.\nHow cooling works at Meta’s data centers \nCurrently, Meta’s data centers adopt a two-tiered penthouse design that utilizes 100% outside air for cooling. As shown in Figure 1, the air enters the facility through louvers on the second-floor “penthouse,” with modulating dampers regulating the volume of outside air. The air passes through a mixing room, where outdoor air, if too cold, can be mixed with heat from server exhaust when needed to regulate the temperature. \nThe air then passes through a series of air filters and a misting chamber where the evaporative cooling and humidification (ECH) system is used to further control the temperature and humidity. The air continues through a fan wall that pushes the air through openings in the floor that serve as an air shaft leading into the server area on the first floor. The hot air coming out from the server exhaust will be contained in the hot aisle, through exhaust shafts, and eventually released out of the building with the help of relief fans. \nWater is mainly used in two ways: evaporative cooling and humidification. The evaporative cooling system converts water into vapor to lower the temperature when the outside air is too hot, while the humidification process maintains the humidity level if the air is too dry. As a result of this design, we believe Meta’s data centers are among the most advanced, energy and water efficient data centers in the world.\nFigure 1: The penthouse cooling system within Meta’s data centers.\nIn order to supply air within the defined operating envelope, the penthouse relies on the building management system (BMS) to monitor and control different components of the mechanical system. This system performs the task of conditioning the intake air from outside by mixing, humidifying/dehumidifying, evaporative cooling, or a combination of these operations. \nThere are three major control loops responsible for adjusting setpoints for supply air: temperature, humidity, and airflow. The airflow setpoint is typically calculated based on a small set of input variables like current IT load, cold aisle temperature, and differential pressure between the cold aisle and hot aisle. The logic is often very simple at a linear scale, but becomes very difficult to accurately model as these values at different locations in the data center are coupled to one another and highly dependent on complex local boundary conditions. However, the amount of airflow will largely dictate the energy used by the supply fan arrays and water consumption when cooling or humidification is required. Therefore, optimizing the airflow setpoint would have the greatest impact in regards to further improving the cooling efficiency given the fact that the temperature and humidity boundary of the operating envelope is fixed.\nA reinforcement learning approach to data center cooling\nReinforcement learning (RL) is good at modeling control systems as sequential state machines. It functions as a software agent that determines what action to take at each state based on some transition model – which leads to a different state – and constantly gets feedback from the environment in terms of reward. In the end, the agent learns the best policy model (typically parameterized by a deep neural network) to achieve the optimal accumulated reward. The data center cooling control can be naturally modeled under this paradigm.\nAt any given time, the state of a data center can be represented by a set of environmental variables monitored by many different sensors for outside air, supply air, cold aisle and hot aisle, plus IT load (i.e., power consumption by servers), etc. The action is to control setpoints – for example, the supply airflow setpoint that determines how fast the supply fans run to meet the demand. The policy is the function mapping from the state space to action space (i.e., determining the appropriate airflow setpoint based on current state conditions). Now the task is to leverage historical data we have collected from thousands of sensors in our data centers – augmented with simulated data of potential, but not yet experienced conditions – and train a better policy model that gives us better reward in terms of energy or water usage efficiency. \nThe idea of using AI for data center cooling optimization is not new. There are also various RL approaches reported such as, transforming cooling optimization via deep reinforcement learning and data center cooling using model-predictive control. \nHowever, applying the control policy determined by an online RL model may result in various risks including breaches of service requirements and even thermal unsafety. To address this challenge, we adopted an offline simulator based RL approach. As illustrated in Figure 2, our RL agent operates in a simulated environment by starting from real-life historical observations, S. It then explores the action space, feeding into the simulator to predict the anticipated new state S’ and reward, R, given each sampled action, A. From there it collects the pairs (S, A) that have the best reward to form a new training data set to update the parameterized policy model.\nFigure 2: Our simulated-based offline RL approach.\nOur simulator is a physics-based model of building energy use that takes as inputs time series such as weather data, IT load, and setpoint schedules. The model is built with data center building parameters, including geometry, construction materials, HVAC, system configurations, component efficiencies, and control strategies. It uses differential equations to output the dynamic system response, such as the thermal load and resulting energy use, along with related metrics like cold aisle temperature and differential pressure profiles. \nThe simulator plays a very important role here since our goal is to optimize energy and water usage while keeping the data center condition under specs so hardware performance isn’t affected. More specifically, we want to keep the rise in cold aisle temperature below a certain threshold, or a positive pressurization from cold aisle to hot aisle, to minimize the parasitic heat caused by recirculation. \nAdditionally, the physics-based simulator enables us to train the RL model with all possible scenarios, not only those present in the historical data. This increases reliability during outlier events and allows for rapid deployment in newly commissioned data centers.\nResults of our RL approach\nIn 2021, we started a pilot at one of Meta’s data center regions – having the RL model directly controlling the supply airflow setpoint. Figure 3 shows a comparison of the new setpoint, in the unit of cubic feet per minute (CFM) as the red line to the original BMS setpoint (as the dotted blue line) over one week’s duration for illustration purposes.\nFigure 3: A comparison of the RL model versus the original BMS setpoint.\nThe fluctuation is mainly determined by the supply air temperature and server load cycles at different times of day. More importantly, as shown in Figure 4, the data center temperature conditions never went out of spec, with reduced airflow supply with respect to both cold aisle average and maximum temperature compared against the supply air temperature.\nFigure 4: A data center temperature profile under RL model control.\nIt is noticeable that the CFM savings vary under different supply air temperatures as the univariate chart in Figure 5 shows. The CFM savings can easily be converted to energy savings used by the supply fans. Under hot and dry conditions, when evaporative cooling or humidification is required, using less air will result in less water usage as well. Over the past couple years of the pilot, on average, we were able to reduce the supply fan energy consumption by 20% and water usage by 4% across various weather conditions.  \nFigure 5. A breakdown of airflow savings at different supply air temperatures.\nFuture work for AI in data center optimization\nThis effort has opened the door to transform how our data centers operate. By introducing automated predictions and continuous optimizations for tuning environment conditions in our data centers we can bend the cost curve and reduce effort on labor intensive tasks.\n\nMeta is breaking ground on new types of data centers that are designed to optimize for artificial intelligence. We plan to apply the same methodology presented here to our future data centers at the design phase to help ensure they’re optimized for sustainability from day one of their operations.\nWe’re also currently rolling out our RL approach to data center cooling to our existing data centers. Over the couple of years we expect to achieve significant energy and water usage savings to contribute to Meta’s long- term sustainability goals. \nAcknowledgements\nWe would like to thank our partners in IDC Facility Operations (Butch Howard, Randy Ridgway, James Monahan, Jose Montes, Larame Cummings, Gerson Arteaga Ramirez, John Fabian, and many others) for their support.\nThe post Simulator-based reinforcement learning for data center cooling optimization appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>We’re sharing more about the role that reinforcement learning plays in helping us optimize our data centers’ environmental controls. Our reinforcement learning-based approach has helped us reduce energy consumption and water usage across various weather conditions in our data centers.   Meta is revamping its new data center design to optimize for artificial intelligence and the [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/09/10/data-center-engineering/simulator-based-reinforcement-learning-for-data-center-cooling-optimization/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/09/10/data-center-engineering/simulator-based-reinforcement-learning-for-data-center-cooling-optimization/\">Simulator-based reinforcement learning for data center cooling optimization</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "We’re sharing more about the role that reinforcement learning plays in helping us optimize our data centers’ environmental controls. Our reinforcement learning-based approach has helped us reduce energy consumption and water usage across various weather conditions in our data centers.   Meta is revamping its new data center design to optimize for artificial intelligence and the [...]\nRead More...\nThe post Simulator-based reinforcement learning for data center cooling optimization appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21675",
        "categories": [
          "Data Center Engineering",
          "ML Applications"
        ],
        "isoDate": "2024-09-10T16:00:31.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": [
      {
        "creator": "Netflix Technology Blog",
        "title": "Pushy to the Limit: Evolving Netflix’s WebSocket proxy for the future",
        "link": "https://netflixtechblog.com/pushy-to-the-limit-evolving-netflixs-websocket-proxy-for-the-future-b468bc0ff658?source=rss----2615bd06b42e---4",
        "pubDate": "Tue, 10 Sep 2024 19:15:34 GMT",
        "content:encodedSnippet": "By Karthik Yagna, Baskar Odayarkoil, and Alex Ellis\nPushy is Netflix’s WebSocket server that maintains persistent WebSocket connections with devices running the Netflix application. This allows data to be sent to the device from backend services on demand, without the need for continually polling requests from the device. Over the last few years, Pushy has seen tremendous growth, evolving from its role as a best-effort message delivery service to be an integral part of the Netflix ecosystem. This post describes how we’ve grown and scaled Pushy to meet its new and future needs, as it handles hundreds of millions of concurrent WebSocket connections, delivers hundreds of thousands of messages per second, and maintains a steady 99.999% message delivery reliability rate.\nHistory & motivation\nThere were two main motivating use cases that drove Pushy’s initial development and usage. The first was voice control, where you can play a title or search using your virtual assistant with a voice command like “Show me Stranger Things on Netflix.” (See How to use voice controls with Netflix if you want to do this yourself!).\nIf we consider the Alexa use case, we can see how this partnership with Amazon enabled this to work. Once they receive the voice command, we allow them to make an authenticated call through apiproxy, our streaming edge proxy, to our internal voice service. This call includes metadata, such as the user’s information and details about the command, such as the specific show to play. The voice service then constructs a message for the device and places it on the message queue, which is then processed and sent to Pushy to deliver to the device. Finally, the device receives the message, and the action, such as “Show me Stranger Things on Netflix”, is performed. This initial functionality was built out for FireTVs and was expanded from there.\nSample system diagram for an Alexa voice command. Where aws ends and the internet begins is an exercise left to the reader.\nThe other main use case was RENO, the Rapid Event Notification System mentioned above. Before the integration with Pushy, the TV UI would continuously poll a backend service to see if there were any row updates to get the latest information. These requests would happen every few seconds, which ended up creating extraneous requests to the backend and were costly for devices, which are frequently resource constrained. The integration with WebSockets and Pushy alleviated both of these points, allowing the origin service to send row updates as they were ready, resulting in lower request rates and cost savings.\nFor more background on Pushy, you can see this InfoQ talk by Susheel Aroskar. Since that presentation, Pushy has grown in both size and scope, and this article will be discussing the investments we’ve made to evolve Pushy for the next generation of features.\nClient Reach\nThis integration was initially rolled out for Fire TVs, PS4s, Samsung TVs, and LG TVs, leading to a reach of about 30 million candidate devices. With these clear benefits, we continued to build out this functionality for more devices, enabling the same efficiency wins. As of today, we’ve expanded our list of candidate devices even further to nearly a billion devices, including mobile devices running the Netflix app and the website experience. We’ve even extended support to older devices that lack modern capabilities, like support for TLS and HTTPS requests. For those, we’ve enabled secure communication from client to Pushy via an encryption/decryption layer on each, allowing for confidential messages to flow between the device and server.\nScaling to handle that growth (and more)\nGrowth\nWith that extended reach, Pushy has gotten busier. Over the last five years, Pushy has gone from tens of millions of concurrent connections to hundreds of millions of concurrent connections, and it regularly reaches 300,000 messages sent per second. To support this growth, we’ve revisited Pushy’s past assumptions and design decisions with an eye towards both Pushy’s future role and future stability. Pushy had been relatively hands-free operationally over the last few years, and as we updated Pushy to fit its evolving role, our goal was also to get it into a stable state for the next few years. This is particularly important as we build out new functionality that relies on Pushy; a strong, stable infrastructure foundation allows our partners to continue to build on top of Pushy with confidence.\nThroughout this evolution, we’ve been able to maintain high availability and a consistent message delivery rate, with Pushy successfully maintaining 99.999% reliability for message delivery over the last few months. When our partners want to deliver a message to a device, it’s our job to make sure they can do so.\nHere are a few of the ways we’ve evolved Pushy to handle its growing scale.\nA few of the related services in Pushy’s immediate ecosystem and the changes we’ve made for them.\nMessage processor\nOne aspect that we invested in was the evolution of the asynchronous message processor. The previous version of the message processor was a Mantis stream-processing job that processed messages from the message queue. It was very efficient, but it had a set job size, requiring manual intervention if we wanted to horizontally scale it, and it required manual intervention when rolling out a new version.\nIt served Pushy’s needs well for many years. As the scale of the messages being processed increased and we were making more code changes in the message processor, we found ourselves looking for something more flexible. In particular, we were looking for some of the features we enjoy with our other services: automatic horizontal scaling, canaries, automated red/black rollouts, and more observability. With this in mind, we rewrote the message processor as a standalone Spring Boot service using Netflix paved-path components. Its job is the same, but it does so with easy rollouts, canary configuration that lets us roll changes safely, and autoscaling policies we’ve defined to let it handle varying volumes.\nRewriting always comes with a risk, and it’s never the first solution we reach for, particularly when working with a system that’s in place and working well. In this case, we found that the burden from maintaining and improving the custom stream processing job was increasing, and we made the judgment call to do the rewrite. Part of the reason we did so was the clear role that the message processor played — we weren’t rewriting a huge monolithic service, but instead a well-scoped component that had explicit goals, well-defined success criteria, and a clear path towards improvement. Since the rewrite was completed in mid-2023, the message processor component has been completely zero touch, happily automated and running reliably on its own.\nPush Registry\nFor most of its life, Pushy has used Dynomite for keeping track of device connection metadata in its Push Registry. Dynomite is a Netflix open source wrapper around Redis that provides a few additional features like auto-sharding and cross-region replication, and it provided Pushy with low latency and easy record expiry, both of which are critical for Pushy’s workload.\nAs Pushy’s portfolio grew, we experienced some pain points with Dynomite. Dynomite had great performance, but it required manual scaling as the system grew. The folks on the Cloud Data Engineering (CDE) team, the ones building the paved path for internal data at Netflix, graciously helped us scale it up and make adjustments, but it ended up being an involved process as we kept growing.\nThese pain points coincided with the introduction of KeyValue, which was a new offering from the CDE team that is roughly “HashMap as a service” for Netflix developers. KeyValue is an abstraction over the storage engine itself, which allows us to choose the best storage engine that meets our SLO needs. In our case, we value low latency — the faster we can read from KeyValue, the faster these messages can get delivered. With CDE’s help, we migrated our Push Registry to use KV instead, and we have been extremely satisfied with the result. After tuning our store for Pushy’s needs, it has been on autopilot since, appropriately scaling and serving our requests with very low latency.\nScaling Pushy horizontally and vertically\nMost of the other services our team runs, like apiproxy, the streaming edge proxy, are CPU bound, and we have autoscaling policies that scale them horizontally when we see an increase in CPU usage. This maps well to their workload — more HTTP requests means more CPU used, and we can scale up and down accordingly.\nPushy has slightly different performance characteristics, with each node maintaining many connections and delivering messages on demand. In Pushy’s case, CPU usage is consistently low, since most of the connections are parked and waiting for an occasional message. Instead of relying on CPU, we scale Pushy on the number of connections, with exponential scaling to scale faster after higher thresholds are reached. We load balance the initial HTTP requests to establish the connections and rely on a reconnect protocol where devices will reconnect every 30 minutes or so, with some staggering, that gives us a steady stream of reconnecting devices to balance connections across all available instances.\nFor a few years, our scaling policy had been that we would add new instances when the average number of connections reached 60,000 connections per instance. For a couple hundred million devices, this meant that we were regularly running thousands of Pushy instances. We can horizontally scale Pushy to our heart’s content, but we would be less content with our bill and would have to shard Pushy further to get around NLB connection limits. This evolution effort aligned well with an internal focus on cost efficiency, and we used this as an opportunity to revisit these earlier assumptions with an eye towards efficiency.\nBoth of these would be helped by increasing the number of connections that each Pushy node could handle, reducing the total number of Pushy instances and running more efficiently with the right balance between instance type, instance cost, and maximum concurrent connections. It would also allow us to have more breathing room with the NLB limits, reducing the toil of additional sharding as we continue to grow. That being said, increasing the number of connections per node is not without its own drawbacks. When a Pushy instance goes down, the devices that were connected to it will immediately try to reconnect. By increasing the number of connections per instance, it means that we would be increasing the number of devices that would be immediately trying to reconnect. We could have a million connections per instance, but a down node would lead to a thundering herd of a million devices reconnecting at the same time.\nThis delicate balance led to us doing a deep evaluation of many instance types and performance tuning options. Striking that balance, we ended up with instances that handle an average of 200,000 connections per node, with breathing room to go up to 400,000 connections if we had to. This makes for a nice balance between CPU usage, memory usage, and the thundering herd when a device connects. We’ve also enhanced our autoscaling policies to scale exponentially; the farther we are past our target average connection count, the more instances we’ll add. These improvements have enabled Pushy to be almost entirely hands off operationally, giving us plenty of flexibility as more devices come online in different patterns.\nReliability & building a stable foundation\nAlongside these efforts to scale Pushy for the future, we also took a close look at our reliability after finding some connectivity edge cases during recent feature development. We found a few areas for improvement around the connection between Pushy and the device, with failures due to Pushy attempting to send messages on a connection that had failed without notifying Pushy. Ideally something like a silent failure wouldn’t happen, but we frequently see odd client behavior, particularly on older devices.\nIn collaboration with the client teams, we were able to make some improvements. On the client side, better connection handling and improvements around the reconnect flow meant that they were more likely to reconnect appropriately. In Pushy, we added additional heartbeats, idle connection cleanup, and better connection tracking, which meant that we were keeping around fewer and fewer stale connections.\nWhile these improvements were mostly around those edge cases for the feature development, they had the side benefit of bumping our message delivery rates up even further. We already had a good message delivery rate, but this additional bump has enabled Pushy to regularly average 5 9s of message delivery reliability.\nPush message delivery success rate over a recent 2-week period.\nRecent developments\nWith this stable foundation and all of these connections, what can we now do with them? This question has been the driving force behind nearly all of the recent features built on top of Pushy, and it’s an exciting question to ask, particularly as an infrastructure team.\nShift towards direct push\nThe first change from Pushy’s traditional role is what we call direct push; instead of a backend service dropping the message on the asynchronous message queue, it can instead leverage the Push library to skip the asynchronous queue entirely. When called to deliver a message in the direct path, the Push library will look up the Pushy connected to the target device in the Push Registry, then send the message directly to that Pushy. Pushy will respond with a status code reflecting whether it was able to successfully deliver the message or it encountered an error, and the Push library will bubble that up to the calling code in the service.\nThe system diagram for the direct and indirect push paths.\nSusheel, the original author of Pushy, added this functionality as an optional path, but for years, nearly all backend services relied on the indirect path with its “best-effort” being good enough for their use cases. In recent years, we’ve seen usage of this direct path really take off as the needs of backend services have grown. In particular, rather than being just best effort, these direct messages allow the calling service to have immediate feedback about the delivery, letting them retry if a device they’re targeting has gone offline.\nThese days, messages sent via direct push make up the majority of messages sent through Pushy. For example, for a recent 24 hour period, direct messages averaged around 160,000 messages per second and indirect averaged at around 50,000 messages per second..\nGraph of direct vs indirect messages per second.\nDevice to device messaging\nAs we’ve thought through this evolving use case, our concept of a message sender has also evolved. What if we wanted to move past Pushy’s pattern of delivering server-side messages? What if we wanted to have a device send a message to a backend service, or maybe even to another device? Our messages had traditionally been unidirectional as we send messages from the server to the device, but we now leverage these bidirectional connections and direct device messaging to enable what we call device to device messaging. This device to device messaging supported early phone-to-TV communication in support of games like Triviaverse, and it’s the messaging foundation for our Companion Mode as TVs and phones communicate back and forth.\nA screenshot of one of the authors playing Triviaquest with a mobile device as the controller.\nThis requires higher level knowledge of the system, where we need to know not just information about a single device, but more broader information, like what devices are connected for an account that the phone can pair with. This also enables things like subscribing to device events to know when another device comes online and when they’re available to pair or send a message to. This has been built out with an additional service that receives device connection information from Pushy. These events, sent over a Kafka topic, let the service keep track of the device list for a given account. Devices can subscribe to these events, allowing them to receive a message from the service when another device for the same account comes online.\nPushy and its relationship with the Device List Service for discovering other devices.\nThis device list enables the discoverability aspect of these device to device messages. Once the devices have this knowledge of the other devices connected for the same account, they’re able to choose a target device from this list that they can then send messages to.\nOnce a device has that list, it can send a message to Pushy over its WebSocket connection with that device as the target in what we call a device to device message (1 in the diagram below). Pushy looks up the target device’s metadata in the Push registry (2) and sends the message to the second Pushy that the target device is connected to (3), as if it was the backend service in the direct push pattern above. That Pushy delivers the message to the target device (4), and the original Pushy will receive a status code in response, which it can pass back to the source device (5).\nA basic order of events for a device to device message.\nThe messaging protocol\nWe’ve defined a basic JSON-based message protocol for device to device messaging that lets these messages be passed from the source device to the target device. As a networking team, we naturally lean towards abstracting the communication layer with encapsulation wherever possible. This generalized message means that device teams are able to define their own protocols on top of these messages — Pushy would just be the transport layer, happily forwarding messages back and forth.\nThe client app protocol, built on top of the device to device protocol, built on top of Pushy.\nThis generalization paid off in terms of investment and operational support. We built the majority of this functionality in October 2022, and we’ve only needed small tweaks since then. We needed nearly no modifications as client teams built out the functionality on top of this layer, defining the higher level application-specific protocols that powered the features they were building. We really do enjoy working with our partner teams, but if we’re able to give them the freedom to build on top of our infrastructure layer without us getting involved, then we’re able to increase their velocity, make their lives easier, and play our infrastructure roles as message platform providers.\nWith early features in experimentation, Pushy sees an average of 1000 device to device messages per second, a number that will only continue to grow.\nGraph of device to device messages per second.\nThe Netty-gritty details\nIn Pushy, we handle incoming WebSocket messages in our PushClientProtocolHandler (code pointer to class in Zuul that we extend), which extends Netty’s ChannelInboundHandlerAdapter and is added to the Netty pipeline for each client connection. We listen for incoming WebSocket messages from the connected device in its channelRead method and parse the incoming message. If it’s a device to device message, we pass the message, the ChannelHandlerContext, and the PushUserAuth information about the connection’s identity to our DeviceToDeviceManager.\nA rough overview of the internal organization for these components.\nThe DeviceToDeviceManager is responsible for validating the message, doing some bookkeeping, and kicking off an async call that validates that the device is an authorized target, looks up the Pushy for the target device in the local cache (or makes a call to the data store if it’s not found), and forwards on the message. We run this asynchronously to avoid any event loop blocking due to these calls. The DeviceToDeviceManager is also responsible for observability, with metrics around cache hits, calls to the data store, message delivery rates, and latency percentile measurements. We’ve relied heavily on these metrics for alerts and optimizations — Pushy really is a metrics service that occasionally will deliver a message or two!\nSecurity\nAs the edge of the Netflix cloud, security considerations are always top of mind. With every connection over HTTPS, we’ve limited these messages to just authenticated WebSocket connections, added rate limiting, and added authorization checks to ensure that a device is able to target another device — you may have the best intentions in mind, but I’d strongly prefer it if you weren’t able to send arbitrary data to my personal TV from yours (and vice versa, I’m sure!).\nLatency and other considerations\nOne main consideration with the products built on top of this is latency, particularly when this feature is used for anything interactive within the Netflix app.\nWe’ve added caching to Pushy to reduce the number of lookups in the hotpath for things that are unlikely to change frequently, like a device’s allowed list of targets and the Pushy instance the target device is connected to. We have to do some lookups on the initial messages to know where to send them, but it enables us to send subsequent messages faster without any KeyValue lookups. For these requests where caching removed KeyValue from the hot path, we were able to greatly speed things up. From the incoming message arriving at Pushy to the response being sent back to the device, we reduced median latency to less than a millisecond, with the 99th percentile of latency at less than 4ms.\nOur KeyValue latency is usually very low, but we have seen brief periods of elevated read latencies due to underlying issues in our KeyValue datastore. Overall latencies increased for other parts of Pushy, like client registration, but we saw very little increase in device to device latency with this caching in place.\nCultural aspects that enable this work\nPushy’s scale and system design considerations make the work technically interesting, but we also deliberately focus on non-technical aspects that have helped to drive Pushy’s growth. We focus on iterative development that solves the hardest problem first, with projects frequently starting with quick hacks or prototypes to prove out a feature. As we do this initial version, we do our best to keep an eye towards the future, allowing us to move quickly from supporting a single, focused use case to a broad, generalized solution. For example, for our cross-device messaging, we were able to solve hard problems in the early work for Triviaverse that we later leveraged for the generic device to device solution.\nAs one can immediately see in the system diagrams above, Pushy does not exist in a vacuum, with projects frequently involving at least half a dozen teams. Trust, experience, communication, and strong relationships all enable this to work. Our team wouldn’t exist without our platform users, and we certainly wouldn’t be here writing this post without all of the work our product and client teams do. This has also emphasized the importance of building and sharing — if we’re able to get a prototype together with a device team, we’re able to then show it off to seed ideas from other teams. It’s one thing to mention that you can send these messages, but it’s another to show off the TV responding to the first click of the phone controller button!\nThe future of Pushy\nIf there’s anything certain in this world, it’s that Pushy will continue to grow and evolve. We have many new features in the works, like WebSocket message proxying, WebSocket message tracing, a global broadcast mechanism, and subscription functionality in support of Games and Live. With all of this investment, Pushy is a stable, reinforced foundation, ready for this next generation of features.\nWe’ll be writing about those new features as well — stay tuned for future posts.\nSpecial thanks to our stunning colleagues Jeremy Kelly and Justin Guerra who have both been invaluable to Pushy’s growth and the WebSocket ecosystem at large. We would also like to thank our larger teams and our numerous partners for their great work; it truly takes a village!\n\nPushy to the Limit: Evolving Netflix’s WebSocket proxy for the future was originally published in Netflix TechBlog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Netflix Technology Blog",
        "guid": "https://medium.com/p/b468bc0ff658",
        "isoDate": "2024-09-10T19:15:34.000Z"
      },
      {
        "creator": "Netflix Technology Blog",
        "title": "Noisy Neighbor Detection with eBPF",
        "link": "https://netflixtechblog.com/noisy-neighbor-detection-with-ebpf-64b1f4b3bbdd?source=rss----2615bd06b42e---4",
        "pubDate": "Tue, 10 Sep 2024 18:00:21 GMT",
        "content:encodedSnippet": "By Jose Fernandez, Sebastien Dabdoub, Jason Koch, Artem Tkachuk\nThe Compute and Performance Engineering teams at Netflix regularly investigate performance issues in our multi-tenant environment. The first step is determining whether the problem originates from the application or the underlying infrastructure. One issue that often complicates this process is the \"noisy neighbor\" problem. On Titus, our multi-tenant compute platform, a \"noisy neighbor\" refers to a container or system service that heavily utilizes the server's resources, causing performance degradation in adjacent containers. We usually focus on CPU utilization because it is our workloads’ most frequent source of noisy neighbor issues.\nDetecting the effects of noisy neighbors is complex. Traditional performance analysis tools such as perf can introduce significant overhead, risking further performance degradation. Additionally, these tools are typically deployed after the fact, which is too late for effective investigation. Another challenge is that debugging noisy neighbor issues requires significant low-level expertise and specialized tooling. In this blog post, we'll reveal how we leveraged eBPF to achieve continuous, low-overhead instrumentation of the Linux scheduler, enabling effective self-serve monitoring of noisy neighbor issues. You’ll learn how Linux kernel instrumentation can improve your infrastructure observability with deeper insights and enhanced monitoring.\nContinuous Instrumentation of the Linux Scheduler\nTo ensure the reliability of our workloads that depend on low latency responses, we instrumented the run queue latency for each container, which measures the time processes spend in the scheduling queue before being dispatched to the CPU. Extended waiting in this queue can be a telltale of performance issues, especially when containers are not utilizing their total CPU allocation. Continuous instrumentation is critical to catching such matters as they emerge, and eBPF, with its hooks into the Linux scheduler with minimal overhead, enabled us to monitor run queue latency efficiently.\nTo emit a run queue latency metric, we leveraged three eBPF hooks: sched_wakeup, sched_wakeup_new, and sched_switch.\nDiagram of how run queue latency is measured and instrumented\nThe sched_wakeup and sched_wakeup_new hooks are invoked when a process changes state from 'sleeping' to 'runnable.' They let us identify when a process is ready to run and is waiting for CPU time. During this event, we generate a timestamp and store it in an eBPF hash map using the process ID as the key.\nstruct {\n    __uint(type, BPF_MAP_TYPE_HASH);\n    __uint(max_entries, MAX_TASK_ENTRIES);\n    __uint(key_size, sizeof(u32));\n    __uint(value_size, sizeof(u64));\n} runq_enqueued SEC(\".maps\");\nSEC(\"tp_btf/sched_wakeup\")\nint tp_sched_wakeup(u64 *ctx)\n{    struct task_struct *task = (void *)ctx[0];\n    u32 pid = task->pid;\n    u64 ts = bpf_ktime_get_ns();\n    bpf_map_update_elem(&runq_enqueued, &pid, &ts, BPF_NOEXIST);\n    return 0;\n}\nConversely, the sched_switch hook is triggered when the CPU switches between processes. This hook provides pointers to the process currently utilizing the CPU and the process about to take over. We use the upcoming task's process ID (PID) to fetch the timestamp from the eBPF map. This timestamp represents when the process entered the queue, which we had previously stored. We then calculate the run queue latency by simply subtracting the timestamps.\nSEC(\"tp_btf/sched_switch\")\nint tp_sched_switch(u64 *ctx)\n{    struct task_struct *prev = (struct task_struct *)ctx[1];\n    struct task_struct *next = (struct task_struct *)ctx[2];\n    u32 prev_pid = prev->pid;\n    u32 next_pid = next->pid;\n     // fetch timestamp of when the next task was enqueued\n    u64 *tsp = bpf_map_lookup_elem(&runq_enqueued, &next_pid);\n    if (tsp == NULL) {\n        return 0; // missed enqueue\n    }\n    // calculate runq latency before deleting the stored timestamp\n    u64 now = bpf_ktime_get_ns();\n    u64 runq_lat = now - *tsp;\n    // delete pid from enqueued map\n    bpf_map_delete_elem(&runq_enqueued, &next_pid);\n    ....\nOne of the advantages of eBPF is its ability to provide pointers to the actual kernel data structures representing processes or threads, also known as tasks in kernel terminology. This feature enables access to a wealth of information stored about a process. We required the process's cgroup ID to associate it with a container for our specific use case. However, the cgroup information in the process struct is safeguarded by an RCU (Read Copy Update) lock.\nTo safely access this RCU-protected information, we can leverage kfuncs in eBPF. kfuncs are kernel functions that can be called from eBPF programs. There are kfuncs available to lock and unlock RCU read-side critical sections. These functions ensure that our eBPF program remains safe and efficient while retrieving the cgroup ID from the task struct.\nvoid bpf_rcu_read_lock(void) __ksym;\nvoid bpf_rcu_read_unlock(void) __ksym;\nu64 get_task_cgroup_id(struct task_struct *task)\n{    struct css_set *cgroups;\n    u64 cgroup_id;\n    bpf_rcu_read_lock();\n    cgroups = task->cgroups;\n    cgroup_id = cgroups->dfl_cgrp->kn->id;\n    bpf_rcu_read_unlock();\n    return cgroup_id;\n}\nOnce the data is ready, we must package it and send it to userspace. For this purpose, we chose the eBPF ring buffer. It is efficient, high-performing, and user-friendly. It can handle variable-length data records and allows data reading without necessitating extra memory copying or syscalls. However, the sheer number of data points was causing the userspace program to use too much CPU, so we implemented a rate limiter in eBPF to sample the data.\nstruct {\n    __uint(type, BPF_MAP_TYPE_RINGBUF);\n    __uint(max_entries, RINGBUF_SIZE_BYTES);\n} events SEC(\".maps\");\nstruct {\n    __uint(type, BPF_MAP_TYPE_PERCPU_HASH);\n    __uint(max_entries, MAX_TASK_ENTRIES);\n    __uint(key_size, sizeof(u64));\n    __uint(value_size, sizeof(u64));\n} cgroup_id_to_last_event_ts SEC(\".maps\");\nstruct runq_event {\n    u64 prev_cgroup_id;\n    u64 cgroup_id;\n    u64 runq_lat;\n    u64 ts;\n};\nSEC(\"tp_btf/sched_switch\")\nint tp_sched_switch(u64 *ctx)\n{    // ....\n    // The previous code\n    // ....\n     u64 prev_cgroup_id = get_task_cgroup_id(prev);\n    u64 cgroup_id = get_task_cgroup_id(next);\n     // per-cgroup-id-per-CPU rate-limiting \n    // to balance observability with performance overhead\n    u64 *last_ts = \n        bpf_map_lookup_elem(&cgroup_id_to_last_event_ts, &cgroup_id);\n    u64 last_ts_val = last_ts == NULL ? 0 : *last_ts;\n    // check the rate limit for the cgroup_id in consideration\n    // before doing more work\n    if (now - last_ts_val < RATE_LIMIT_NS) {\n        // Rate limit exceeded, drop the event\n        return 0;\n    }\n    struct runq_event *event;\n    event = bpf_ringbuf_reserve(&events, sizeof(*event), 0);\n  \n    if (event) {\n        event->prev_cgroup_id = prev_cgroup_id;\n        event->cgroup_id = cgroup_id;\n        event->runq_lat = runq_lat;\n        event->ts = now;\n        bpf_ringbuf_submit(event, 0);\n        // Update the last event timestamp for the current cgroup_id\n        bpf_map_update_elem(&cgroup_id_to_last_event_ts, &cgroup_id,\n            &now, BPF_ANY);\n    }\n    return 0;\n}\nOur userspace application, developed in Go, processes events from the ring buffer to emit metrics to our metrics backend, Atlas. Each event includes a run queue latency sample with a cgroup ID, which we associate with containers running on the host. We categorize it as a system service if no such association is found. When a cgroup ID is associated with a container, we emit a percentile timer Atlas metric (runq.latency) for that container. We also increment a counter metric (sched.switch.out) to monitor preemptions occurring for the container's processes. Access to the prev_cgroup_id of the preempted process allows us to tag the metric with the cause of the preemption, whether it's due to a process within the same container (or cgroup), a process in another container, or a system service.\nIt's important to highlight that both the runq.latency metric and the sched.switch.out metrics are needed to determine if a container is affected by noisy neighbors, which is the goal we aim to achieve — relying solely on the runq.latency metric can lead to misconceptions. For example, if a container is at or over its cgroup CPU limit, the scheduler will throttle it, resulting in an apparent spike in run queue latency due to delays in the queue. If we were only to consider this metric, we might incorrectly attribute the performance degradation to noisy neighbors when it's actually because the container is hitting its CPU quota. However, simultaneous spikes in both metrics, mainly when the cause is a different container or system process, clearly indicate a noisy neighbor issue.\nA Noisy Neighbor Story\nBelow is the runq.latency metric for a server running a single container with ample CPU capacity. The 99th percentile averages 83.4µs (microseconds), serving as our baseline. Although there are some spikes reaching 400µs, the latency remains within acceptable parameters.\ncontainer1’s 99th percentile runq.latency averages 83µs (microseconds), with spikes up to 400µs, without adjacent containers. This serves as our baseline for a container not contending for CPU on a host.\nAt 10:35, launching container2, which fully utilized all CPUs on the host, caused a significant 131-millisecond spike (131,000 microseconds) in container1's P99 run queue latency. This spike would be noticeable in the userspace application if it were serving HTTP traffic. If userspace app owners reported an unexplained latency spike, we could quickly identify the noisy neighbor issue through run queue latency metrics.\nLaunching container2 at 10:35, which maxes out all CPUs on the host, caused a 131-millisecond spike in container1’s P99 run queue latency due to increased preemptions by system processes. This indicates a noisy neighbor issue, where system services compete for CPU time with containers.\nThe sched.switch.out metric indicates that the spike was due to increased preemptions by system processes, highlighting a noisy neighbor issue where system services compete with containers for CPU time. Our metrics show that the noisy neighbors were actually system processes, likely triggered by container2 consuming all available CPU capacity.\nOptimizing eBPF Code\nWe developed an open-source eBPF process monitoring tool called bpftop to measure the overhead of eBPF code in this kernel hot path. Our profiling with bpftop shows that the instrumentation adds less than 600 nanoseconds to each sched_* hook. We conducted a performance analysis on a Java service running in a container, and the instrumentation did not introduce significant overhead. The performance variance with the run queue profiling code active versus inactive was not measurable in milliseconds.\nDuring our research on how eBPF statistics are measured in the kernel, we identified an opportunity to improve the calculation. We submitted this patch, which was included in the Linux kernel 6.10 release.\n\nThrough trial and error and using bpftop, we identified several optimizations that helped maintain low overhead for our eBPF code:\n\nWe found that BPF_MAP_TYPE_HASH was the most performant for storing enqueued timestamps. Using BPF_MAP_TYPE_TASK_STORAGE resulted in nearly a twofold performance decline. BPF_MAP_TYPE_PERCPU_HASH was slightly less performant than BPF_MAP_TYPE_HASH, which was unexpected and requires further investigation.\nBPF_MAP_TYPE_LRU_HASH maps are 40–50 nanoseconds slower per operation than regular hash maps. Due to space concerns from PID churn, we initially used them for enqueued timestamps. Ultimately, we settled on BPF_MAP_TYPE_HASH with an increased size to mitigate this risk.\nThe BPF_CORE_READ helper adds 20–30 nanoseconds per invocation. In the case of raw tracepoints, specifically those that are \"BTF-enabled\" (tp_btf/*), it is safe and more efficient to access the task struct members directly. Andrii Nakryiko recommends this approach in this blog post.\nThe sched_switch, sched_wakeup, and sched_wakeup_new are all triggered for kernel tasks, which are identifiable by their PID of 0. We found monitoring these tasks unnecessary, so we implemented several early exit conditions and conditional logic to prevent executing costly operations, such as accessing BPF maps, when dealing with a kernel task. Notably, kernel tasks operate through the scheduler queue like any regular process.\n\nConclusion\nOur findings highlight the value of low-overhead continuous instrumentation of the Linux kernel with eBPF. We have integrated these metrics into customer dashboards, enabling actionable insights and guiding multitenancy performance discussions. We can also now use these metrics to refine CPU isolation strategies to minimize the impact of noisy neighbors. Additionally, thanks to these metrics, we've gained deeper insights into the Linux scheduler.\nThis work has also deepened our understanding of eBPF technology and underscored the importance of tools like bpftop for optimizing eBPF code. As eBPF adoption increases, we foresee more infrastructure observability and business logic shifting to it. One promising project in this space is sched_ext, which has the potential to revolutionize how scheduling decisions are made and tailored to specific workload needs.\n\nNoisy Neighbor Detection with eBPF was originally published in Netflix TechBlog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Netflix Technology Blog",
        "guid": "https://medium.com/p/64b1f4b3bbdd",
        "categories": [
          "observability",
          "linux",
          "ebpf",
          "performance",
          "containers"
        ],
        "isoDate": "2024-09-10T18:00:21.000Z"
      }
    ]
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Khalid Abuhakmeh",
        "title": "Introduction to Htmx for Spring Boot Developers",
        "link": "https://blog.jetbrains.com/idea/2024/09/introduction-to-htmx-for-spring-boot-developers/",
        "pubDate": "Fri, 13 Sep 2024 09:51:18 +0000",
        "content:encodedSnippet": "Starting a new project can be both exciting and challenging at the same time. Choosing what technologies will help you deliver your solution comes with the cost associated with those choices. Each additional technology can bring issues and dependencies that can lead to incremental decreases in progress that can grind your project to a stop. The front end is a common place where developers might experience decision fatigue. The popularity of frontend frameworks such as React, Angular, and Vue brings a lot of value and expensive tradeoffs in tooling, security considerations, network traffic, and heavy initial payloads. If you’re feeling overwhelmed when making a front-end decision for your next project, this post is for you.\nIn this post, we’ll explore an up-and-coming library called Htmx that allows you to leverage your existing Spring Boot knowledge to deliver interactive user experiences while circumventing some of the frustrations you may have felt with other front-end frameworks. By the end of this post, you should be confident enough to add Htmx to a new or existing Spring Boot project.\nDownload IntelliJ IDEA\n                                                    \nWhat is Htmx?\nTo understand what Htmx is, we must first understand philosophically what the library is attempting to accomplish. \nHtmx is unabashedly proud to be in the Hypermedia camp. Hypermedia is a term coined in 1965 by Ted Nelson, and it focuses on the idea that a single document may contain several interactive elements, such as text, images, videos, and links to other documents. If this sounds a lot like HTML, then you’d be right. HTML is the canonical example of this concept and has successfully delivered the internet we know today. Then, in 2015, the web development landscape changed.\nDuring the Web 2.0 era, web development began moving to separate the UI elements of web experiences into frontend and backend. Backend APIs delivered JSON or XML because these payloads were smaller than full HTML payloads. The front end was responsible for transforming data into presentational HTML using JavaScript. This pattern worked around limitations in the client and rendering speed and, at the time, delivered a better user experience to visitors. Since that time, a few things have changed:\nInternet speeds are significantly faster overall\nClients are much more efficient in rendering HTML\nJavaScript and JSON payloads have ballooned\nJavaScript tooling has become increasingly complex\nRegarding Htmx, in the context of modern applications, frontend frameworks may be a more considerable burden than the problems they claim to help solve. So, how does Htmx work differently?\nHtmx focuses on a declarative programming style, allowing you to decorate your existing HTML output with Htmx-specific attributes. These attributes give those HTML elements more functionality than they may typically have. The fundamental flow of all Htmx includes the following:\nA client-side trigger that raises an event\nThe event typically triggers a web request to a server backend\nThe server responds with an HTML fragment\nHtmx replaces an existing DOM element with the response\nLet’s look at a simple Htmx example, which we will implement using Spring Boot later.\n<button hx-post=\"/clicked\"\n    hx-trigger=\"click\"\n    hx-target=\"#parent-div\"\n    hx-swap=\"outerHTML\"\n>\n    Click Me!\n</button>\nThe hx- attributes allow this button to trigger an HTTP POST whenever clicked. Once the server responds, we will find the #parent-div and swap it with the resulting HTML.\nThese attributes are not exclusive to any HTML element and can be combined to create rich experiences. For example, here is a search box that triggers a request whenever the user changes the value:\n<input type=\"text\" name=\"q\"\n    hx-get=\"/trigger_delay\"\n    hx-trigger=\"keyup changed delay:500ms\"\n    hx-target=\"#search-results\"\n    placeholder=\"Search...\"\n>\n<div id=\"search-results\"></div>\nThis particular example also defines a delay of 500ms before making a request to the server, as a way to not make requests while the user is still typing, so that the server only receives the most relevant search queries and not all of them – a technique called “debouncing”.\nNow that you have a general idea of Htmx, let’s add it to a Spring Boot sample project and implement the backend for both snippets.\nYour first Htmx experience in Spring Boot\nBefore starting, I recommend installing the Htmx Support plugin for JetBrains IDEs. It will make your Htmx development experience that much better. Thanks, Hugo Mesquita!\nUse the New Project dialog in IntelliJ IDEA to create a new Spring Boot project. If you already have a Spring Boot project, skip this step.\n\n\n\n\nOn the next screen, choose the Spring Web and Thymeleaf dependencies.\n\n\n\n\nLet’s start by first creating a new HomeController class. This will be where we add our application logic for our first sample.\npackage org.example.htmxdemo;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.GetMapping;\n\n@Controller\npublic class HomeController {\n    @GetMapping(\"/\")\n    public String home() {\n        return \"index\";\n    }\n}\nNext, let’s create our index HTML template file under resources/templates/index.html. Be sure to paste the following contents. The dependencies are already included in the head tag of the provided HTML and will be retrieved by the client when the page is rendered to users.\n<!DOCTYPE HTML>\n<html xmlns:th=\"http://www.thymeleaf.org\" lang=\"en\">\n<head>\n    <title>Getting Started: Serving Web Content</title>\n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"/>\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n    <meta name=\"color-scheme\" content=\"light dark\" />\n    <title>Htmx Demo</title>\n    <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/@picocss/pico@2/css/pico.min.css\" >\n    <script src=\"https://unpkg.com/htmx.org@2.0.1\"></script>\n</head>\n<body>\n    <main class=\"container\">\n        <section>\n        <h1>Htmx Demo</h1>\n        <div id=\"parent-div\"></div>\n        <button hx-post=\"/clicked\"\n                hx-trigger=\"click\"\n                hx-target=\"#parent-div\"\n                hx-swap=\"outerHTML\">\n            Click Me!\n        </button>\n        </section>\n    </main>\n</body>\n</html>\nHtmx is a no-build library, meaning you don’t need any additional dependencies to use it. As you notice, in the head element of our template, we only need a script reference to the library in our HTML. I’ve also included a CSS library, PicoCSS, to make things more aesthetically pleasing. Your output may look slightly different based on your development environment’s light/dark mode settings.\nEventually, you’ll want to download and store all third-party files alongside your code for a production setting.\nNext, return to the HomeController and implement the /clicked endpoint. Remember, this needs to be handled using the POST HTTP method. Using the appropriate HTTP methods to handle interactions can be essential to Htmx development. Generally, use GET for immutable calls and POST, PUT, and DELETE for mutating calls.\npackage org.example.htmxdemo;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.ui.Model;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PostMapping;\n\nimport java.time.LocalDateTime;\n\n@Controller\npublic class HomeController {\n    @GetMapping(\"/\")\n    public String home() {\n        return \"index\";\n    }\n\n    @PostMapping(\"/clicked\")\n    public String clicked(Model model) {\n        model.addAttribute(\"now\", LocalDateTime.now().toString());\n        return \"clicked :: result\";\n    }\n}\nFinally, let’s implement our HTML fragment in clicked.html, which we’ll place next to our other template files in resources/templates/.\n<!DOCTYPE html>\n<html xmlns=\"http://www.w3.org/1999/xhtml\"\n      xmlns:th=\"http://www.thymeleaf.org\" lang=\"en\">\n<head>\n  <title>fragments</title>\n</head>\n<body>\n  <div th:fragment=\"result\" id=\"parent-div\">\n    <p th:text=\"${now}\"></p>\n  </div>\n</body>\n</html>\nRunning our application, we can now click the button on our page and see the interface update in real-time.\n\n\n\n\nCongratulations. You have successfully handled the first of many Htmx requests to come!\nNow, let’s implement that search textbox for a more complex scenario.\nHtmx-powered Search in Spring Boot\nWe will add a new search feature to our sample, implementing the snippet previously shown. Let’s first update our HTML snippet to include the search user interface. In index.html, update the contents to match the following:\n<!DOCTYPE HTML>\n<html xmlns:th=\"http://www.thymeleaf.org\" lang=\"en\">\n<head>\n    <title>Getting Started: Serving Web Content</title>\n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"/>\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n    <meta name=\"color-scheme\" content=\"light dark\" />\n    <title>Htmx Demo</title>\n    <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/@picocss/pico@2/css/pico.min.css\" >\n    <script src=\"https://unpkg.com/htmx.org@2.0.1\"></script>\n</head>\n<body>\n    <main class=\"container\">\n        <section>\n        <h1>Htmx Demo</h1>\n        <div id=\"parent-div\"></div>\n        <button hx-post=\"/clicked\"\n                hx-trigger=\"click\"\n                hx-target=\"#parent-div\"\n                hx-swap=\"outerHTML\">\n            Click Me!\n        </button>\n        </section>\n\n        <section>\n            <input type=\"text\"\n                   name=\"q\"\n                   hx-get=\"/search\"\n                   hx-trigger=\"keyup changed delay:500ms\"\n                   hx-target=\"#search-results\"\n                   placeholder=\"Search...\"\n            >\n            <div th:replace=\"search::results\">\n            </div>\n        </section>\n\n    </main>\n</body>\n</html>\nCreate a new search.html file in resources/templates/ and copy the following content into the newly created file.\n<!DOCTYPE html>\n<html xmlns=\"http://www.w3.org/1999/xhtml\"\n      xmlns:th=\"http://www.thymeleaf.org\" lang=\"en\">\n<head>\n    <title>fragments</title>\n</head>\n<body>\n<div id=\"search-results\" th:fragment=\"results\">\n    <ul th:each=\"result: ${results}\">\n        <li th:text=\"${result}\"></li>\n    </ul>\n</div>\n</body>\n</html>\nThis file contains our response fragment, which will display the results of the user-initiated search. Let’s update our HomeController one last time:\npackage org.example.htmxdemo;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.ui.Model;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PostMapping;\n\nimport java.time.LocalDateTime;\nimport java.util.List;\n\n@Controller\npublic class HomeController {\n\n    static List<String> searchResults =\n            List.of(\"one\", \"two\", \"three\", \"four\", \"five\");\n\n    @GetMapping(\"/\")\n    public String home(Model model) {\n        model.addAttribute(\"results\", searchResults);\n        return \"index\";\n    }\n\n    @GetMapping(\"/search\")\n    public String search(String q, Model model) {\n        var filtered = searchResults\n                .stream()\n                .filter(s -> s.startsWith(q.toLowerCase()))\n                .toList();\n\n        model.addAttribute(\"results\", filtered);\n        return \"search :: results\";\n    }\n\n    @PostMapping(\"/clicked\")\n    public String clicked(Model model) {\n        model.addAttribute(\"now\", LocalDateTime.now().toString());\n        return \"clicked :: result\";\n    }\n}\nLet’s pause here and consider what we’re doing with our HomeController class.\nOur home method sets the search results for the initial experience.\nOur index.html uses the search :: results fragment\nWhen the user types, the /search endpoint handles the query and returns the modified search :: results fragment with our new results.\nAll of this logic happens using our knowledge of Spring Boot and Thymeleaf. That’s pretty amazing. Rerun the application and start typing into the search box to see the filtered results.\n\n\n\n\nIt might not seem like it, but you implemented some complex Htmx scenarios. There’s still more to learn, and the basics described in this post are a great starting point.\nCommunity References\nHtmx has a growing community of excited developers, and we wanted to share some of their work with you. Knowing there is community enthusiasm for Htmx may help reduce your anxiety about adopting the technology.\nOfficial Htmx site and documentation – https://htmx.org/ \nJosh Long – HTMX and Spring Boot\nSivaLabs – Spring Boot Thymeleaf HTMX Tutorial\nDan Vega – Getting started with HTMX in Spring Boot with Thymeleaf\nWill Iverson –Spring Boot + HTMX = Easy Full Stack\nWim Deblauwe – Spring Tips: HTMX\nThose willing to look past the backend technology can also check out my guide series Htmx for ASP.NET Core developers, which has many samples and techniques that can be adapted to Spring Boot.\nFor folks seriously getting into Htmx development, check out the Spring Boot and Thymeleaf library for htmx, which adds helpful elements to your Spring Boot application.\nAlso, to get the sample code featured in this post, fellow Developer Advocate Marit van Djik pushed a complete sample to her GitHub repository. \nConclusion\nIf you suffer from front-end fatigue and prefer to work with backend tools like Spring Boot and Thymeleaf, you may consider Htmx for your next solution. In my opinion, one of Htmx’s strongest selling points is that you can layer it in incrementally. Some pages in your web application may utilize Htmx heavily, while others do not mention It. This can speed up your deliverables considerably, as you spend less time wrestling with JavaScript build tools and more time building solutions that users will love.\nWe hope you enjoyed this post. We’d love to hear about your experience integrating Htmx and Spring Boot. If you have any questions or feedback, please feel free to comment.",
        "dc:creator": "Khalid Abuhakmeh",
        "content": "Starting a new project can be both exciting and challenging at the same time. Choosing what technologies will help you deliver your solution comes with the cost associated with those choices. Each additional technology can bring issues and dependencies that can lead to incremental decreases in progress that can grind your project to a stop. [&#8230;]",
        "contentSnippet": "Starting a new project can be both exciting and challenging at the same time. Choosing what technologies will help you deliver your solution comes with the cost associated with those choices. Each additional technology can bring issues and dependencies that can lead to incremental decreases in progress that can grind your project to a stop. […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=498678",
        "categories": [
          "idea",
          "java",
          "htmx",
          "intellij-idea",
          "spring"
        ],
        "isoDate": "2024-09-13T09:51:18.000Z"
      },
      {
        "creator": "Vitaly Bragilevsky",
        "title": "Fleet Plugins – Now With Сustom Keymaps",
        "link": "https://blog.jetbrains.com/fleet/2024/09/fleet-plugins-now-with-sustom-keymaps/",
        "pubDate": "Thu, 12 Sep 2024 15:46:07 +0000",
        "content:encodedSnippet": "About a month ago, we launched a mechanism for publishing your color theme as a plugin. With the recent updates, we are extending Fleet plugin applicability even further by allowing you to publish your custom keymaps. You can now map Fleet actions to specific key combinations to streamline your development experience and share the resulting keymap with others.\nCustomizing keyboard shortcuts\nKeyboard shortcuts can significantly boost your productivity as a software developer, but they can also slow you down if they’re not the shortcuts you’re used to. Unfortunately, there’s no one-size-fits-all solution. We put much effort into creating Fleet’s default keymap – we wanted it to respect the system defaults, have familiar shortcuts from other apps like Cmd/Ctrl+K, and be as lightweight as possible to give users the freedom to add their own shortcuts without creating conflicts. However, we understand that it might not be to everyone’s liking. So, we made several customization options available.\nFirst, we added several other keymap options that might work better for you. To switch between them, go to the customization menu by clicking the gear icon in the top-right corner of your Fleet window:\n\n\n\n\nThe Keymap dialog allows you to select your preferred keymap:\n\n\n\n\nSecond, we allow keymap customization in the Keymap view (it can be launched by the Help | Keymap menu item or the Edit Keymap… action):\n\n\n\n\nThe idea behind keymap customization is as follows: \nThere’s a long list of actions available in Fleet.\nYou can select any action and then replace the assigned shortcut, remove it, or add a new one.\nIt’s possible to restore the default shortcuts (those originally defined in your selected keymap).\nFleet stores your customizations in the user.json file, for example:\n{\n  \"keymap\": [\n\t{\n\t\t\"key\": \"shift-cmd-s\",\n\t\t\"action\": \"show-file-symbols\"\n\t},\n\t{\n\t\t\"key\": \"shift-ctrl-a\",\n\t\t\"action\": \"toggle-distraction-free-mode\"\n\t},\n\t{\n\t\t\"key\": \"ctrl-o\",\n\t\t\"action\": \"-open-in\"\n\t}\n  ]\n}\nThe keymap array in this example lists all the assignments that differ from the keymap currently selected in Fleet. Let’s call it a delta keymap. For every shortcut assignment, we specify a key and an action ID. Removing a default shortcut is expressed as an action ID with the leading ‘-’ symbol (for example, -open-in). Adding several shortcuts for a single action can be expressed by adding several key/action pairs. Fleet supports viewing and editing this delta keymap JSON file directly via the Edit Keymap in JSON File… action.\nIf you’ve heavily customized your keymap and think it makes you more productive, you might want to share it with others. Let’s see how you can publish your keymap as a Fleet plugin.\nPublishing custom keymap as a Fleet plugin\nLike theme plugins, we start packaging a custom keymap by creating a new project from the dedicated keymap plugin template on GitHub. Three things need to be adjusted in the project.\nFirst, you must put a keymap JSON file with a complete list of assigned shortcuts in the my-keymap-plugin/frontendImpl/src/jvmMain/resources/ folder. The easiest way to build such a file is to manually merge the default Fleet keymap (my-custom-keymap.json in the template) with your customizations (the delta keymap) in user.json. There’s one caveat, though. Delta keymap is used for the current operating system, but a complete keymap JSON file is supposed to be useful across different OSes. You can use the ”win”, “mac”, or “linux” key values to set shortcuts specific to the respective operating system. The value of the ”key” field serves as a fallback option. Use definitions in my-custom-keymap.json as an example.\nLet’s call this new complete keymap file super-productive.json.\nSecond, you need to register your keymap as a contribution of your plugin in the my-keymap-plugin/frontendImpl/src/jvmMain/kotlin/fleet/sample/frontendImpl/MyKeymapPlugin.kt file:\npackage fleet.sample.frontendImpl\n\nimport fleet.frontend.keymap.KeymapId\nimport fleet.frontend.keymap.registerKeymap\nimport fleet.kernel.plugins.ContributionScope\nimport fleet.kernel.plugins.Plugin\nimport fleet.kernel.plugins.PluginScope\n\nclass MyKeymapPlugin : Plugin<Unit> {\n\n    companion object : Plugin.Key<Unit>\n\n    override val key: Plugin.Key<Unit> = MyKeymapPlugin\n\n    override fun ContributionScope.load(pluginScope: PluginScope) {\n        registerKeymap(\n            id = KeymapId(\"super-productive\"), \n            presentableName = \"Fleet Super Productive\")\n    }\n}\nThe keymap ID must be the same as the name of the keymap JSON file (without an extension).\nThird, we need to configure the plugin itself. The plugin should have a unique id, a readable name, and a description. The name and the description are visible both on Marketplace and in Fleet’s Plugins view (use the Plugins… action to open it). These parameters are set in the my-keymap-plugin/build.gradle.kts file, for example:\nplugins {\n\tbase\n\talias(libs.plugins.fleet.plugin)\n}\n\nversion = \"0.1.0\"\n\nfleetPlugin {\n\tid = \"pro.bravit.super.keymap\"\n\tmetadata {\n\t\treadableName = \"Fleet Super Productive\"\n\t\tdescription = \"Super productive keymap for Fleet\"\n\t}\n\tfleetRuntime {\n\t\tversion = libs.versions.fleet.runtime\n\t}\n}\nOnce we are done editing the files, we can launch Fleet with the plugin in development by opening the Run dialog and choosing the Run Fleet with local plugin run configuration. The Fleet instance will be launched after a bit of compilation and will have our keymap available in the Select Keymap… dialog:\n\n\n\n\nWe can also check out the Plugins view to make sure that the plugin has been loaded:\n\n\n\n\nWhile experimenting with your new keymap, you can get your changes as a delta keymap (as described in the previous section) and then transfer them to the complete keymap JSON file. Note that any changes you make to your complete keymap JSON file now won’t be immediately visible in the running Fleet instance. You need to restart Fleet with the Run Fleet with local plugin run configuration selected in order for your changes to take effect.\nOnce you finish editing and testing your keymap, please follow the instructions from the documentation to publish your new keymap plugin to JetBrains Marketplace. The Marketplace team will check the uploaded plugin, and following their approval, it will become available for anyone to install from the Plugins view in Fleet:\n\n\n\n\nConclusion\nWe now allow you to publish your custom color themes and keymaps as Fleet plugins. Some users have already done so. But this is just the beginning. You can do much more to customize Fleet’s behavior with plugins. The road ahead is long and full of possibilities.\nStay with us on this journey!",
        "dc:creator": "Vitaly Bragilevsky",
        "content": "About a month ago, we launched a mechanism for publishing your color theme as a plugin. With the recent updates, we are extending Fleet plugin applicability even further by allowing you to publish your custom keymaps. You can now map Fleet actions to specific key combinations to streamline your development experience and share the resulting [&#8230;]",
        "contentSnippet": "About a month ago, we launched a mechanism for publishing your color theme as a plugin. With the recent updates, we are extending Fleet plugin applicability even further by allowing you to publish your custom keymaps. You can now map Fleet actions to specific key combinations to streamline your development experience and share the resulting […]",
        "guid": "https://blog.jetbrains.com/?post_type=fleet&p=509574",
        "categories": [
          "plugin-development",
          "news",
          "plugins"
        ],
        "isoDate": "2024-09-12T15:46:07.000Z"
      },
      {
        "creator": "Ksenia Shneyveys",
        "title": "Create With Kotlin Multiplatform and Win a Trip to KotlinConf 2025!",
        "link": "https://blog.jetbrains.com/kotlin/2024/09/kotlin-multiplatform-contest/",
        "pubDate": "Thu, 12 Sep 2024 13:55:31 +0000",
        "content:encodedSnippet": "To all students and recent graduates: The Kotlin Foundation is excited to announce the launch of the Kotlin Multiplatform Contest! Showcase your creativity and coding skills by building a cross-platform project using Kotlin Multiplatform and win a trip to KotlinConf 2025, the largest Kotlin event of the year. \nTake part\nKotlin Multiplatform allows you to create apps that run on Android, iOS, desktop, web, and server – all from a single codebase. Now is your chance to put this technology to the test and show off what you can build. Experts from the Kotlin Multiplatform team at JetBrains will support you with regular live Q&A sessions!\nThe creators of the top three projects will win a trip to KotlinConf 2025 in Copenhagen, Denmark, taking place on May 22–23, 2025! Plus, the authors of all valid entries will receive Kotlin souvenirs. \nKey dates:\nContest starts on September 9, 2024\nSubmission deadline is January 14, 2025\nWinners are announced on January 24, 2025\n\n\n\n\nHow to participate:\n1. Join the community: Stay updated and get guidance by joining our dedicated Slack channel. We’ll announce the live Q&A sessions with Kotlin Multiplatform experts from JetBrains there.\n2. Read and agree to the complete contest rules.\n3. Build your project: Your project must use Kotlin Multiplatform and run on at least two platforms. Get creative – choose a topic that excites you and shows off the power of Kotlin Multiplatform.\n4. Submit: Upload your project to GitHub with a comprehensive README file and clear instructions on how to launch it on all supported platforms.\nEligibility:\nYou must be at least 18 years old.\nYou must be currently enrolled or have been enrolled in an accredited educational program within the last 12 months.\nRead the complete rules\nPrizes:\nThe authors of the top three projects will win a trip to KotlinConf 2025 in Copenhagen, Denmark, taking place on May 22–23, 2025, including travel, accommodation, and conference tickets. They will also get recognition on the KotlinConf website and social media channels and receive swag.\nThe contributors of all other valid entries will receive neat Kotlin souvenirs for participating.\n\n\n\n\nHelpful materials:\nKotlin Multiplatform official documentation.\nPeopleInSpace – multiplatform sample projects.\nMore samples of multiplatform projects.\nCompose Multiplatform – a video tutorial.\n\n\n\n\nPrevious winners:\nAhmet Burak Ilhan, Istanbul Biruni University, Turkey, DoGoodMobile\nBrian Kamau Mbigo, Multimedia University of Kenya, Kenya, VisioZoezi\nMaciej Procyk, University of Warsaw, Poland, Mini-games\nPatrycja Bachleda, Florida Institute of Technology, USA, College Advisor\nSamson Aricha Momanyi, Technical University of Mombasa, Kenya, Organiks\nCaleb Asira Etemesi, Strathmore University, Kenya, Pixly\n\n\n\n\nTake advantage of this incredible opportunity to learn, create, and win. Whether you’re new to Kotlin Multiplatform or an experienced developer, this contest is a fantastic way to explore the technology, learn from the experts, and connect with the global Kotlin community!\nFor more details, visit the Kotlin Multiplatform Contest page.\nWe’re excited to see what you build. Good luck!",
        "dc:creator": "Ksenia Shneyveys",
        "content": "To all students and recent graduates: The Kotlin Foundation is excited to announce the launch of the Kotlin Multiplatform Contest! Showcase your creativity and coding skills by building a cross-platform project using Kotlin Multiplatform and win a trip to KotlinConf 2025, the largest Kotlin event of the year.  Take part Kotlin Multiplatform allows you to [&#8230;]",
        "contentSnippet": "To all students and recent graduates: The Kotlin Foundation is excited to announce the launch of the Kotlin Multiplatform Contest! Showcase your creativity and coding skills by building a cross-platform project using Kotlin Multiplatform and win a trip to KotlinConf 2025, the largest Kotlin event of the year.  Take part Kotlin Multiplatform allows you to […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=509883",
        "categories": [
          "news",
          "contest",
          "kotlin-multiplatform"
        ],
        "isoDate": "2024-09-12T13:55:31.000Z"
      },
      {
        "creator": "Dzhamshed Khaitov",
        "title": "Introducing the New TeamCity Plugin for IntelliJ IDEA",
        "link": "https://blog.jetbrains.com/teamcity/2024/09/new-teamcity-plugin-intellij-idea/",
        "pubDate": "Thu, 12 Sep 2024 10:28:58 +0000",
        "content:encodedSnippet": "We’re excited to announce the release of the updated TeamCity plugin for IntelliJ IDEA! 🎉 You can now download it directly from JetBrains Marketplace.\nUsing the plugin, you can trigger TeamCity builds directly from within your IDE and test any changes before committing them to the version control system.\n\n\n\n\n\n\nWhy get the new plugin?\nThis plugin has been built from the ground up to ensure it will eventually be able to replace the existing TeamCity plugin once support for the most frequently used and requested features has been added. \nHere’s what’s new in the plugin:\nWe’ve added functionality enabling you to link TeamCity projects and build configurations to your IDE project so that you only see build configurations related to your IDE project.\nWith the help of the remote run feature, you can run build configurations on your local changes without committing them to the VCS.\nThe plugin’s tool window now contains a new Personal Builds tab where past personal builds are listed. It also shows live updates of all builds executed using the remote run feature.\n\n\n\n\n\nNow it’s possible to select a build configuration and watch its build status for each commit in the VCS Log tool window.\n\n\n\n\nKey benefits of this updated plugin include:\nThe ability to manually configure which TeamCity projects relate to your code, giving you more control over your builds.\n\n\n\n\nEnhanced performance that significantly reduces lag between your actions in the IDE and the TeamCity server’s response.\nWe’re actively developing this plugin and planning to add even more features in upcoming releases. Your feedback is critical in shaping the tool to better meet the needs of IntelliJ IDEA developers. \nYou can install both the old and new plugin versions side by side, so feel free to compare and explore!\nHow to get started with the TeamCity plugin for IntelliJ IDEA\nInitial setup\n1. Download the plugin from Marketplace.\n2. Once the plugin is installed, open your project in IntelliJ IDEA and invoke the plugin’s settings using the Tools | TeamCity (Experimental) | Settings… menu.\n\n\n\n\n3. Click Log In and enter the following values:\nServer URL – the HTTP(S) address of your TeamCity server.\nAccess token – your user access token that can be generated on the Your Profile | Access Tokens page in TeamCity.\n\n\n\n\nWith the new plugin, you can link build configurations from TeamCity directly to the project you have open. In the old plugin, this had to be configured through VCS roots, which wasn’t an easy process.\nNow, users only need to create a given configuration once, and it will be saved in the source code. Everyone who downloads the project will then have it automatically configured and available without the need to set it up themselves.\nTesting your local changes\nOne of the key benefits of the TeamCity IDEA plugins (both old and new) is the ability to run builds with your local changes before they are pushed to a remote branch, also known as a remote run. This allows you to spot issues without breaking the build for everyone else on your team.\nHere’s how you can initiate a remote run from your IDE.\n1. Make some changes to your code.\n2. Go to Tools | TeamCity (Experimental) | Remote Run….\n\n\n\n\n3. Then, under Remote Run… | Settings…, click the target build configurations that you want to run with your local changes. The plugin will then remember your choice and run builds for the same configuration(s) on subsequent remote runs. You can configure these project-configuration relations in the plugin settings.\n\n\n\n\nLink your projects to TeamCity build configurations\nSetting up project-configuration relations allows you to explicitly choose which configurations should be triggered depending on the introduced changes.\nTeamCity’s IntelliJ IDEA integration enables you to choose the linking scope, selecting whether you want to link the whole project or only individual project modules to your TeamCity build configurations.\n\n\n\n\n1. Click Tools | TeamCity (Experimental) | Settings… to open the plugin’s settings.\n2. Choose the required Linking scope value:\nPROJECT – allows you to link the entire IntelliJ IDEA project to the target build configuration(s). This option works best when you need to trigger builds of the same configuration(s) regardless of which part of your code changed.\nMODULE – allows you to link individual modules to corresponding build configurations. For example, you can run both Build and Test configurations if the main module of your application changes, and only the Test configuration if you edit a separate module with unit and functional tests. This mode also benefits mono repositories where each module is a separate project with its own target build configuration(s).\nShare your feedback\nWe’re still working on making the new plugin ready to replace the old one. For the time being, you can download both plugins – they won’t interfere with each other.\nIs there any functionality that you’d like us to add to the new plugin? Let us know in the comments below! We want to make the plugin as useful as possible, and your feedback can help us do exactly that.\nHappy building!",
        "dc:creator": "Dzhamshed Khaitov",
        "content": "We’re excited to announce the release of the updated TeamCity plugin for IntelliJ IDEA! 🎉 You can now download it directly from JetBrains Marketplace. Using the plugin, you can trigger TeamCity builds directly from within your IDE and test any changes before committing them to the version control system. Why get the new plugin? This [&#8230;]",
        "contentSnippet": "We’re excited to announce the release of the updated TeamCity plugin for IntelliJ IDEA! 🎉 You can now download it directly from JetBrains Marketplace. Using the plugin, you can trigger TeamCity builds directly from within your IDE and test any changes before committing them to the version control system. Why get the new plugin? This […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=509571",
        "categories": [
          "plugins",
          "news",
          "release"
        ],
        "isoDate": "2024-09-12T10:28:58.000Z"
      },
      {
        "creator": "Maria Kosukhina",
        "title": "IntelliJ IDEA 2024.3 EAP Is Open! ",
        "link": "https://blog.jetbrains.com/idea/2024/09/intellij-idea-2024-3-eap/",
        "pubDate": "Thu, 12 Sep 2024 08:59:05 +0000",
        "content:encodedSnippet": "The Early Access Program for IntelliJ IDEA 2024.3 is officially underway! The first EAP build is now available, offering you an early look at the first portion of improvements introduced for the next major release.\nYou can download this version from our website, update directly from within the IDE, use the free Toolbox App, or install via snap packages for Ubuntu.\n\n\n\n\nDownload IntelliJ IDEA 2024.3 EAP 1\nNew to the EAP? Our introductory blog post explains how the program works, why your feedback is important, and how you can get involved.\nStay tuned for the EAP updates over the next few weeks to try out new features in IntelliJ IDEA. Try them out, provide your feedback, and play a part in shaping the future of the IDE.\nAI Assistant\nInline AI prompt\nWe’re introducing a new, seamless way to interact with AI Assistant directly in the editor: an experimental inline input that detects and processes your requests as you type. This lets you express your intentions in natural language, which AI Assistant instantly interprets and converts into code changes without any extra steps. This feature is currently available for Java and Kotlin.\nSimply type your prompt where you’d like to make adjustments, hit Tab, and if the result isn’t quite right, you can undo the changes by hitting Ctrl+Z and modify your prompt before trying again.\n\n\n\n\nJava and Kotlin\nImprovements in constant conditions\nWe’ve significantly improved the support for our data flow engine, particularly in handling aliasing cases. This enhancement applies to both Kotlin and Java, allowing for more accurate analysis in scenarios where references may point to the same instance.\nLet’s take a look at an example: \n\n\n\n\nPreviously, IntelliJ IDEA would consider a1 and a2 as completely separate instances, which is generally a reasonable assumption. However, this is not always the case. \n\n\n\n\nIf we pass the same reference to both arguments, the function actually prints ALIASED! – indicating that a1 and a2 are, in fact, the same instance.\n\n\n\n\nWith the improved data flow engine, IntelliJ IDEA now handles such aliasing cases more accurately, leading to fewer false positives in inspections and a more reliable coding experience.\nK2 mode enabled by default \nStarting with 2024.3 EAP 1 and continuing through all upcoming EAP builds, K2 mode will be enabled by default. K2 mode is the new Kotlin support implementation in IntelliJ IDEA, designed to improve IDE stability and lay the groundwork for future Kotlin language features. For more details, check out our blog post.\nOur goal is to make K2 mode the default in future releases, and your feedback is crucial to help us fine-tune it. Share your experience with us on our public Slack channel or via YouTrack to help ensure K2 launches at its best!\nNot all K1 API-dependent plugins are currently compatible with K2 mode. To help plugin authors speed up the migration process, we’ve prepared a migration guide for those using the K1 plugin API. You can also reach out to us on our Slack channel to ask questions.\n\n\n\n\nMulti-dollar interpolation support in Kotlin\nStarting with this build, IntelliJ IDEA with K2 mode enabled supports an experimental language feature – multi-dollar interpolation. This feature simplifies working with strings that include literal $ symbols, eliminating the need for workarounds like ${'$'}.\nFor example, declaring JSON schemas in your code now looks cleaner:\n\n\n\n\nUser experience\nSpelling and grammar checks during indexing\nBuilding on the progress made in the 2024.2 release, we’re continuing to optimize wait times during project model building and indexing, ensuring essential features are available immediately. With this update, spelling and grammar checks are now accessible even while indexing is in progress. This allows you to catch errors, such as those in Markdown documents and documentation tags, without waiting for indexing to finish.\n\n\n\n\nBranch name display on the Welcome screen\nThe Welcome screen now shows the branch name to help you stay organized when handling multiple project versions and easily switch between working directories.\n\n\n\n\nWorkspaces in IntelliJ IDEA\nThis EAP build includes the recently announced Workspaces feature, allowing you to manage multiple projects simultaneously, with each project using its own technology stack and build tool, and running independently. For now, setting up your workspace requires installing a plugin from JetBrains Marketplace. You can find more details on the concept, usage scenarios, and implementation in this dedicated blog post.\nThis feature is in its early development stage. We encourage you to try it out and share your feedback to help us refine and improve it for your needs.\n\n\n\n\nThese are the most notable updates from the first week of the IntelliJ IDEA 2024.3 Early Access Program. For a full overview of the changes in this EAP build, check out the release notes.\nStay tuned to our blog for weekly updates as we continue to add new features for the next major release. Your feedback is critical to us, so please share your thoughts on the latest additions by commenting on this post or reaching out to us on X. If you encounter any bugs, please report them via our issue tracker.",
        "dc:creator": "Maria Kosukhina",
        "content": "The Early Access Program for IntelliJ IDEA 2024.3 is officially underway! The first EAP build is now available, offering you an early look at the first portion of improvements introduced for the next major release. You can download this version from our website, update directly from within the IDE, use the free Toolbox App, or [&#8230;]",
        "contentSnippet": "The Early Access Program for IntelliJ IDEA 2024.3 is officially underway! The first EAP build is now available, offering you an early look at the first portion of improvements introduced for the next major release. You can download this version from our website, update directly from within the IDE, use the free Toolbox App, or […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=509055",
        "categories": [
          "eap",
          "2024-3-eap",
          "early-access-program",
          "intellij-idea",
          "intellij-idea-2024-3",
          "intellij-idea-2024-3-eap"
        ],
        "isoDate": "2024-09-12T08:59:05.000Z"
      },
      {
        "creator": "David Watson",
        "title": "What’s Next: The WebStorm 2024.3 Roadmap",
        "link": "https://blog.jetbrains.com/webstorm/2024/09/what-s-next-the-webstorm-2024-3-roadmap/",
        "pubDate": "Wed, 11 Sep 2024 13:30:20 +0000",
        "content:encodedSnippet": "In August of this year, we released WebStorm 2024.2, our second major update for 2024. Thank you to everyone who is already using it and providing feedback. \nWith August now behind us, we’d like to announce what we’ve got planned for the next release of WebStorm, which is scheduled for the middle of November, with our usual disclaimer: these plans are subject to change. \nAlso, as usual, we’ll be releasing EAP builds in the run-up to this release. We encourage you to try these builds, provide feedback on the features, and report any issues you discover. At this stage, you can significantly impact the product’s development.\nOur primary focus with this release is on improving the stability and quality of WebStorm and some of its subsystems. Here are our most significant plans for WebStorm 2024.3:\nWebStorm@next TypeScript engine – We’ve been working on delivering our TypeScript engine for the last year. We’re excited to announce significant performance improvements in WebStorm@next, with minimal functionality regression. If it meets our strict quality criteria by the end of the 2024.3 Early Access Program (EAP), it will be enabled by default in the release. Initially, WebStorm@next will focus on TypeScript, React, and Angular, with Vue potentially included if optimizations are completed. \nDatabase plugin – We’re going to reconsider how the current Database Tools and SQL plugin license model works with WebStorm subscriptions, and try to find a more suitable solution. This plugin provides you with database tools to query, create, and manage databases and full SQL language support.\nTailwind CSS color preview – We’re enhancing our Tailwind integration by adding color previews, making it easier to quickly identify the colors that are applied to elements. (WEB-47817).\nNew functionality during indexing – To improve the startup experience and reduce waiting times, certain dumb functionality (WEB-64105, WEB-64106, and WEB-64107) will now be accessible during indexing.\nImproved test framework support – Certain limitations of the current test framework support can cause test files to be misidentified. We’ll be making significant internal changes and general test framework support improvements to fix this issue (WEB-64971 and WEB-67720).\nEnhanced Show Component Usages – We’re updating how WebStorm handles components. Template usages will now be recognized as part of the file, improving both the Show Component Usages action for Vue, Svelte, and Astro, as well as the Rename feature (WEB-65061).\nDisable SvelteKit a11y warnings option – We’ll add a new option to disable accessibility (a11y) warnings from the Svelte Language Service (WEB-62537).\nMonorepo project improvements – We’ll make searches in monorepo projects more focused and manageable by excluding search results from node_modules in the Find in Files directory tab by default (WEB-25601).\nEnhanced monorepo imports – We’ll improve the handling of imports in monorepos to reduce the number of incorrect imports from libraries or subprojects. This will address common issues related to auto-generated output folders like dist (WEB-68309) and problems associated with the partial support for the exports field in package.json (WEB-68290).\nSupport for exports in CSS – We’re adding support for the exports field in package.json for CSS files (WEB-55017).\n.idea directory displayed by default – Historically, the .idea folder has been hidden by default. Moving forward, we’ve decided to display all files in the projects to enhance transparency (WEB-68009).\nImproved JSX attribute experience  – We’ll no longer include the equal sign (=) for boolean JSX attributes (WEB-62632).\nAngular template usages displayed with class usages – We’re making Angular usage tracking more intuitive. When you invoke Show Usages on an Angular class, WebStorm will now display usages from templates as well (WEB-68183).\nUnused import inspections for Angular – We plan to introduce unused import inspections for Angular NgModule and standalone components, allowing you to reduce the number of unnecessary dependencies by identifying and removing unused imports (WEB-38266). This will also be added to version 2024.2.\nBundled Vue, Svelte, and Astro language servers – We plan to bundle the primary language services to enhance product reliability, prevent issues with language-server loading on WSL, and address security concerns associated with downloading language servers from the internet.\n\n\n\n\nThat’s all for now! Check out the 2024.3 Early Access Program to test these features as they become available!\nThe WebStorm team",
        "dc:creator": "David Watson",
        "content": "In August of this year, we released WebStorm 2024.2, our second major update for 2024. Thank you to everyone who is already using it and providing feedback.&#160; With August now behind us, we’d like to announce what we’ve got planned for the next release of WebStorm, which is scheduled for the middle of November, with [&#8230;]",
        "contentSnippet": "In August of this year, we released WebStorm 2024.2, our second major update for 2024. Thank you to everyone who is already using it and providing feedback.  With August now behind us, we’d like to announce what we’ve got planned for the next release of WebStorm, which is scheduled for the middle of November, with […]",
        "guid": "https://blog.jetbrains.com/?post_type=webstorm&p=509199",
        "isoDate": "2024-09-11T13:30:20.000Z"
      },
      {
        "creator": "Ruslan Akhmetzianov",
        "title": "The GoLand 2024.3 Early Access Program Has Started!",
        "link": "https://blog.jetbrains.com/go/2024/09/11/the-goland-2024-3-early-access-program-has-started/",
        "pubDate": "Wed, 11 Sep 2024 11:29:08 +0000",
        "content:encodedSnippet": "The Early Access Program (EAP) for GoLand 2024.3 is now open! For this release the team will be focusing on performance, Go language support (including for type parameters), and UX and stability improvements to provide gophers with a smooth development experience.\nThe first EAP build can be downloaded via the Toolbox App, from our website, or as a snap package for Ubuntu. You can also get it from inside GoLand by selecting Check IDE updates for Early Access Program in Settings | Appearance & Behavior | System Settings | Updates.\n      \n        Download GoLand 2024.3 EAP\n    \n\n\n\n\nWhat’s new in GoLand 2024.3 EAP 1\nThe first EAP release introduces the following updates:\nFixes for various cases in which error highlighting was returning false positives, such as:\n\nInference for T at the call site of generic functions.\nType inference while using the river library.\nConstrained types in function calls with type parameters.\nCondition is always true/false for min/max functions when evaluating call arguments.\nStability improvements for some remote development scenarios.\nPerformance improvements for the execution of go list.\nGoLand also includes many updates and bug fixes coming in WebStorm and DataGrip, as well as some neat features from IntelliJ IDEA. Check them out!\nFurther plans\nDuring this EAP cycle, we plan to continue implementing support for the Go SDK and Go Tools updates, and introduce improvements to GoLand’s UI/UX. Here are some of the highlights of our current plans, but we encourage you to vote for the issues you want to see fixed and the features you want us to implement:\nGO-3404: Inspection for circular imports – Circular imports can be quite confusing, especially in complex scenarios. We are planning to introduce an inspection for such cases.\nGO-16425: Running multiple Go services in parallel via a single UI – To provide the best possible development experience, we plan to implement a handy UI solution that allows you to run multiple configurations.\nUX improvements and more Gopher icons in the UI – We are also working on improving the discoverability of various intention actions and refactorings that are already available. Some cute changes will be made for the EAP.\nEarly Access Program 101\nIf you’re not familiar with our Early Access Program (EAP), here’s a brief overview: \nEAP builds let you try out the latest features and enhancements in GoLand while we continue working on them. These builds are not fully tested and might be unstable, but this is where you can help us. By taking these builds and their new features for a test drive in your real-world projects and scenarios, you can help us polish them. This way, when the final version is released, it will work smoothly for you.\nThe EAP lets you be among the first to try out the newest features.\nEAP builds are free to use for 30 days from the build date. You can use this period as an extended trial of GoLand.\nWe provide a series of EAP builds until a stable release is almost ready. For the upcoming 2024.3 version, the EAP period will last until the end of October.\nIn each release cycle, we offer a free one-year GoLand subscription to the most active evaluators and users who helped us make GoLand better by sharing their product experience, feedback, and suggestions.\nFresh builds come out almost every day. If you don’t want to wait for the official EAP build announcements, you can download our nightly builds, which are only available via the Toolbox App. Note that the nightly builds often do not meet the quality standards for official EAP builds, and they don’t come with release notes. Like EAP builds, they expire within 30 days of being released.\n\n\n\n\nThat’s it for now! Stay tuned for future updates!",
        "dc:creator": "Ruslan Akhmetzianov",
        "content": "The Early Access Program (EAP) for GoLand 2024.3 is now open! For this release the team will be focusing on performance, Go language support (including for type parameters), and UX and stability improvements to provide gophers with a smooth development experience. The first EAP build can be downloaded via the Toolbox App, from our website, [&#8230;]",
        "contentSnippet": "The Early Access Program (EAP) for GoLand 2024.3 is now open! For this release the team will be focusing on performance, Go language support (including for type parameters), and UX and stability improvements to provide gophers with a smooth development experience. The first EAP build can be downloaded via the Toolbox App, from our website, […]",
        "guid": "https://blog.jetbrains.com/?post_type=go&p=509353",
        "categories": [
          "goland",
          "releases",
          "eap",
          "release"
        ],
        "isoDate": "2024-09-11T11:29:08.000Z"
      },
      {
        "creator": "Oleg Zinovyev",
        "title": "What’s Next for CLion: The 2024.3 Roadmap",
        "link": "https://blog.jetbrains.com/clion/2024/09/2024-3-roadmap/",
        "pubDate": "Wed, 11 Sep 2024 07:11:41 +0000",
        "content:encodedSnippet": "The second major release of CLion this year, 2024.2, introduced many improvements and advanced features. These include full line code completion for С++ that runs locally, Zephyr West support, and updates to the new CLion Nova language engine. If you still haven’t tried CLion 2024.2, download and try it today.\nDOWNLOAD CLION 2024.2\nWe’ve begun our work on the next release, 2024.3, and are prioritizing improvements in the following areas:\n🚀 CLion Nova functionality and stability\n🤖 Embedded development\n🏗️ Project formats and build tools\nRead on to learn more about the planned updates.\nThe following is a preliminary plan and not a promise or commitment. Tasks might be changed or rescheduled for various reasons. We can’t guarantee that all the issues listed below will be addressed in CLion 2024.3.\nCLion Nova\nCLion Nova is a new language engine that improves the IDE’s performance and accuracy. Since v2024.2, it has become the default language engine for new CLion users. For the 2024.3 release, we are working on some of the most requested features and improvements in CLion Nova related to project navigation, remote development, code style, and more.\nNew features\nHere are the features we plan to add to CLion Nova:\nCall hierarchy displays a function’s callers and callees (CPP-22675). This is one of the most anticipated features missing from CLion Nova compared to CLion Classic.\nMISRA C++:2023 is the latest edition of MISRA C++, which provides guidelines for using C++17 in safety-critical systems. We’ll add support for MISRA C++:2023 checks in the new release; the full list will be announced later. The MISRA C++:2023 checks will complement the currently supported MISRA C 2012 and MISRA C++ 2008 checks.\nFrontend-based typing assistance for remote development\nThe remote development mode in CLion Nova is still in beta. However, we are constantly improving its performance, stability, and functionality to make it production-ready sooner. In v2024.3, we plan to improve the responsiveness of the typing assistant. It is responsible for auto-inserting pair parentheses, brackets, and quotes, as well as smart indentation when pressing Enter, and other important actions.\nCLion now performs typing assistance on the server side, not the client side. The network round-trip time adds a noticeable delay between typing and the assistance results. To solve this problem, we move the typing assistance to the client side.\nThis solution is part of our broader project to move the typing assistance from CLion’s backend to the frontend. First, we will implement this optimization only for the local development scenario. The overall goal is to improve both remote and local development, eventually making typing assistance in the remote mode just as fast as it is in the local mode.\nSettings-related improvements\nThere are several important settings that CLion Nova still lacks. In v2024.3, we will add support for some of them, including those related to code styles:\nPredefined code styles, such as Google, LLVM, and GNU (CPP-36365).\nHeader Guard Style, which helps keep header naming according to your pattern (CPP-36933).\nWe will also be working on various settings-related issues to improve the user experience.\nProject formats\nWe plan to fix the problem where newly added .cpp and .h files are treated as not belonging to any project target, which causes code analysis to fail (CPP-37734, CPP-38040).\nEmbedded development\nOur ongoing efforts are focused on expanding CLion’s functionality and tailoring it to meet the needs of embedded developers across all their use cases. We already support different types of hardware and toolchains. In v2024.3, we will add a new feature for managing debugging servers more easily. This feature simplifies the configuration and execution of specific run/debug configurations for selected projects, such as OpenOCD, Zephyr, or J-Link. Roughly speaking, the feature will instruct CLion how and where to run a configuration. You can configure a debugger type, environment variables, connection, and other settings for each specific project.\nAnother helpful feature that we plan to include in this update is predefined debug targets (a tentative title), which are like preconfigured templates and will help speed up the configuration of debugging servers.\nProject formats and build tools\nCLion 2024.2 introduced Zephyr West support for creating and building Zephyr RTOS-based projects. We are gathering your feedback and continuing to improve Zephyr West support accordingly. One of the major features we plan to add in v2024.3 is the ability to run the native west debug command to make debugging more convenient (CPP-39392).\nWe would appreciate your participation in our user interviews, designed to help us improve Zephyr West support in CLion. You will be rewarded for your time and meaningful feedback.\nThere is also a lot of work related to Bazel support. One of the key features we plan to add is basic support for the MSVC compiler for Windows users.\nDebugger\nWe are working on a new debugger feature that will make it easier to develop OpenCV-based applications and will be helpful in computer vision, machine learning, and game development (CPP-3659). This feature allows you to view bitmap image data temporarily stored in memory while the program is running. It provides a watch window for viewing bitmaps during debugging. The first version of this feature will support OpenCV image types like cv::Mat.\nCall for feedback\nYour feedback is important to us, as your experiences and insights are essential to our mission to continuously improve CLion. Please share your ideas in the comments section below or submit them to our issue tracker. \nThe free Early Access Program is just around the corner. In the meantime, upgrade to CLion 2024.2 if you haven’t already done so, and let us know what you think.\nDOWNLOAD CLION 2024.2\nYour CLion team\nJetBrains\nThe Drive to Develop",
        "dc:creator": "Oleg Zinovyev",
        "content": "The second major release of CLion this year, 2024.2, introduced many improvements and advanced features. These include full line code completion for С++ that runs locally, Zephyr West support, and updates to the new CLion Nova language engine. If you still haven’t tried CLion 2024.2, download and try it today. DOWNLOAD CLION 2024.2 We’ve begun [&#8230;]",
        "contentSnippet": "The second major release of CLion this year, 2024.2, introduced many improvements and advanced features. These include full line code completion for С++ that runs locally, Zephyr West support, and updates to the new CLion Nova language engine. If you still haven’t tried CLion 2024.2, download and try it today. DOWNLOAD CLION 2024.2 We’ve begun […]",
        "guid": "https://blog.jetbrains.com/?post_type=clion&p=509003",
        "categories": [
          "news",
          "roadmap",
          "2024-3",
          "clionnova",
          "debugger",
          "embedded",
          "zephyr-west"
        ],
        "isoDate": "2024-09-11T07:11:41.000Z"
      },
      {
        "creator": "Stanislav Garkusha",
        "title": "How to Use Jupyter Notebooks in PyCharm",
        "link": "https://blog.jetbrains.com/pycharm/2024/09/how-to-use-jupyter-notebooks-in-pycharm/",
        "pubDate": "Mon, 09 Sep 2024 13:45:37 +0000",
        "content:encodedSnippet": "PyCharm is one of the most well-known data science tools, offering excellent out-of-the-box support for Python, SQL, and other languages. PyCharm also provides integrations for Databricks, Hugging Face and many other important tools. All these features allow you to write good code and work with your data and projects faster. \nPyCharm Professional’s support for Jupyter notebooks combines the interactive nature of Jupyter notebooks with PyCharm’s superior code quality and data-related features. This blog post will explore how PyCharm’s Jupyter support can significantly boost your productivity.\n\n\n\n\nWatch this video to get a comprehensive overview of using Jupyter notebooks in PyCharm and learn how you can speed up your data workflows. \n\n\n\n\n\n\nSpeed up data analysis\nGet acquainted with your data\nWhen you start working on your project, it is extremely important to understand what data you have, including information about the size of your dataset, any problems with it, and its  patterns. For this purpose, your pandas and Polars DataFrames can be rendered in Jupyter outputs in Excel-like tables. The tables are fully interactive, so you can easily sort one or multiple columns and browse and view your data, you can choose how many rows will be shown in a table and perform many other operations.\n\n\n\n\nThe table also provides some important information for example:\nYou can find the the size of a table in its header. \n\n\n\n\n\n You can find the data type symbols in the column headers.\n\n\n\n\n\nYou can also use JetBrains AI Assistant to get information about your DataFrame by clicking on the  icon.\n\n\n\n\nEasily spot issues with the data\nAfter getting acquainted with your data, you need to clean it. This an important step, but it is also extremely time consuming because there are all sorts of problems you could find, including missing values, outliers, inconsistencies in data types, and so on. Indeed, according to the State of Developer Ecosystem 2023 report, nearly 50% of Data Professionals dedicate 30% of their time or more to data preparation. Fortunately, PyCharm offers a variety of features that streamline the data-cleaning process.\nSome insights are already available in the column headers. \nFirst, we can easily spot the amount of missing data for each column because it is highlighted in red. Also, we may be able to see at a glance whether some of our columns have outliers. For example, in the bath column, the maximum value is significantly higher than the ninety-fifth percentile. Therefore, we can expect that this column has at least one outlier and requires our attention.\n\n\n\n\nAdditionally, you might suspect there’s an issue with the data if the data type does not match the expected one. For example, the header of the total_sqft column below is marked with the  symbol, which in PyCharm indicates that the column contains the Object data type. The most appropriate data type for a column like total_sqft would likely be float or integer, however, so we may expect there to be inconsistencies in the data types within the column, which could affect data processing and analysis. After sorting, we notice one possible reason for the discrepancy: the use of text in data and ranges instead of numerical values.\n\n\n\n\nSo, our suspicion that the column had data-type inconsistencies was proven correct. As this example shows, small details in the table header can provide important information about your data and alert you to issues that need to be addressed, so it’s always worth checking.You can also use no-code visualizations to gather information about whether your data needs to be cleaned. Simply click on the  icon in the top-left corner of the table. There are many available visualization options, including histograms, that can be used to see where the peaks of the distribution are, whether the distribution is skewed or symmetrical, and whether there are any outliers.\n\n\n\n\nOf course, you can use code to gather information about your dataset and fix any problems you’ve identified. However, the mentioned low-code features often provide valuable insights about your data and can help you work with it much faster.\nCode faster \nCode completion and quick documentation\nA significant portion of a data professional’s job involves writing code. Fortunately, PyCharm is well known for its features that allow you to write code significantly faster. For example, local ML-powered full line code completion can provide suggestions for entire lines of code.\n\n\n\n\nAnother useful feature is quick documentation, which appears when you hover the cursor over your code. This allows you to gather information about functions and other code elements without having to leave the IDE.\n\n\n\n\nRefactorings\nOf course, working with code and data is an interactive process, and you may often decide to make some changes in your code – for example, to rename a variable. Going through the whole file or, in some cases, the entire project, would be cumbersome and time consuming. We can use PyCharm’s refactoring capabilities to rename a variable, introduce a constant, and make many other changes in your code. For example, in this case, I want to rename the DataFrame to make it shorter. I simply use the the Rename refactoring to make the necessary changes.\n\n\n\n\nPyCharm offers a vast number of different refactoring options. To dive deeper into this functionality, watch this video.\nFix problems\nIt is practically impossible to write code without there being any mistakes or typos. PyCharm has a vast array of features that allow you to spot and address issues faster. You will notice the Inspection widget in the top-right corner if it finds any problems.  \n\nFor example, I forgot to import a library in my project and made several typos in the doc so let’s take a look how PyCharm can help here. \nFirst of all, the problem with the library import:\n\n\n\n\nAdditionally, with Jupyter traceback, you can see the line where the error occurred and get a link to the code. This makes the bug-fixing process much easier. Here, I have a typo in line 3. I can easily navigate to it by clicking on the blue text.\n\n\n\n\nAdditionally if you would like to get more information and suggestion how to fix the problem, you can use JetBrains AI Assistant by clicking on Explain with AI. \n\n\n\n\nOf course, that is just the tip of the iceberg. We recommend reading the documentation to better understand all the features PyCharm offers to help you maintain code quality.\nNavigate easily\nFor the majority of cases, data science work involves a lot of experimentation, with the journey from start to finish rarely resembling a straight line.\nDuring this experimentation process, you have to go back and forth between different parts of your project and between cells in order to find the best solution for a given problem. Therefore, it is essential for you to be able to navigate smoothly through your project and files. Let’s take a look at how PyCharm can help in this respect.\nFirst of all, you can use the classic CMD+F (Mac) or CTRL+F (Windows) shortcut for searching in your notebook. This basic search functionality offers some additional filters like Match Case or Regex.\n\n\n\n\nYou can use Markdown cells to structure the document and navigate it easily.\n\n\n\n\nIf you would like to highlight some cells so you can come back to them later, you can mark them with #TODO or #FIXME, and they will be made available for you to dissect in a dedicated window.\n\n\n\n\nOr you can use tags to highlight some cells so you’ll be able to spot them more easily.\n\n\n\n\nIn some cases, you may need to see the most recently executed cell; in this case, you can simply use the Go To option. \n\n\n\n\nSave your work\nBecause teamwork is essential for data professionals, you need tooling that makes sharing the results of your work easy. One popular solution is Git, which PyCharm supports with features like notebook versioning and version comparison using the Diff view. You can find an in-depth overview of the functionality in this tutorial.\nAnother useful feature is Local History, which automatically saves your progress and allows you to revert to previous steps with just a few clicks.\n\n\n\n\nUse the full power of AI Assistant\nJetBrains AI Assistant helps you automate repetitive tasks, optimize your code, and enhance your productivity. In Jupyter notebooks, it also offers several unique features in addition to those that are available in any JetBrains tool. \nClick the  icon to get insights regarding your data. You can also ask additional questions regarding the dataset or ask AI Assistant to do something – for example, “write some code that solves the missing data problem”.\n\n\n\n\nAI data visualization\nPressing the icon  will suggest some useful visualizations for your data. AI Assistant will generate the proper code in the chat section for your data.\n\n\n\n\nAI cell\nAI Assistant can create a cell based on a prompt. You can simply ask it to create a visualization or do something else with your code or data, and it will generate the code that you requested. \n\n\n\n\nDebugger\nPyCharm offers advanced debugging capabilities to enhance your experience in Jupyter notebooks. The integrated Jupyter debugger allows you to set breakpoints, inspect variables, and evaluate expressions directly within your notebooks. This powerful tool helps you step through your code cell by cell, making it easier to identify and fix issues as they arise. Read our blog post on how you can debug a Jupyter notebook in PyCharm for a real-life example.\n\n\n\n\nGet started with PyCharm Professional\nPyCharm’s Jupyter support enhances your data science workflows by combining the interactive aspects of Jupyter notebooks with advanced IDE features. It accelerates data analysis with interactive tables and AI assistance, improves coding efficiency with code completion and refactoring, and simplifies error detection and navigation. PyCharm’s seamless Git integration and powerful debugging tools further boost productivity, making it essential for data professionals.\nDownload PyCharm Professional to try it out for yourself! Get an extended trial today and experience the difference PyCharm Professional can make in your data science endeavors.Use the promo code “PyCharmNotebooks” at checkout to activate your free 60-day subscription to PyCharm Professional. The free subscription is available for individual users only.\nActivate your 60-day trial\n                                                    \nExplore our official documentation to fully unlock PyCharm’s potential for your projects.",
        "dc:creator": "Stanislav Garkusha",
        "content": "PyCharm is one of the most well-known data science tools, offering excellent out-of-the-box support for Python, SQL, and other languages. PyCharm also provides integrations for Databricks, Hugging Face and many other important tools. All these features allow you to write good code and work with your data and projects faster.&#160; PyCharm Professional’s support for Jupyter [&#8230;]",
        "contentSnippet": "PyCharm is one of the most well-known data science tools, offering excellent out-of-the-box support for Python, SQL, and other languages. PyCharm also provides integrations for Databricks, Hugging Face and many other important tools. All these features allow you to write good code and work with your data and projects faster.  PyCharm Professional’s support for Jupyter […]",
        "guid": "https://blog.jetbrains.com/?post_type=pycharm&p=508361",
        "categories": [
          "data-science",
          "how-tos",
          "jupyter",
          "jupyter-notebooks"
        ],
        "isoDate": "2024-09-09T13:45:37.000Z"
      },
      {
        "creator": "Sergey Kozlovskiy",
        "title": "Celebrate Tester’s Day With JetBrains Aqua – 50% OFF!",
        "link": "https://blog.jetbrains.com/qa/2024/09/celebrate-tester-s-day-with-jetbrains-aqua-50-off/",
        "pubDate": "Mon, 09 Sep 2024 11:00:58 +0000",
        "content:encodedSnippet": "JetBrains Aqua is proud to join the global tech community in celebrating International Tester’s Day on September 9. This day recognizes the crucial contributions of QA professionals, who ensure that the software we rely on functions flawlessly and delivers a superior user experience.\n      \n        Buy Aqua – 50% OFF\n    \n\n\n\n\nWhy testers are our everyday heroes\nIn today’s fast-paced, ever-evolving software industry, quality is not just an option – it’s a necessity. Testers are quality gatekeepers, often working behind the scenes to detect bugs and find vulnerabilities. Testers ensure our products are reliable, secure, and ready for the real world. Their attention to detail and dedication to finding issues before they reach users make them a crucial part of every development team.\nHow JetBrains Aqua empowers testers\nAqua is the first IDE created specifically for test automation. Aqua supports Selenium, Cypress, and Playwright. It’s a polyglot IDE that understands Java, Python, JavaScript, TypeScript, Kotlin, and SQL. With Aqua, you can get straight to testing without having to install and configure lots of plugins.\nYour work deserves the best tools, and Aqua is designed to help you perform your job more efficiently and maintain high-quality standards.\nA special thank you\nIn honor of International Tester’s Day, we’re offering a 50% discount on JetBrains Aqua commercial subscriptions. This is the perfect opportunity to equip yourself with a tool designed to elevate your testing game.\nClaim your discount and take your test automation to the next level. This offer is available from September 9 until October 9, so don’t miss out!\nCelebrate with us!\nLet’s use this day to celebrate the testing profession and acknowledge its continuous dedication to quality. Share your favorite testing moments, tips, and bug-finding stories with the community using the hashtag #TestersDay. And don’t forget to tag us @JetBrainsAqua so we can celebrate together!\nThank you for making software better and more reliable every day. We’re excited to support you on your journey! Happy Tester’s Day! 🎉\nYour JetBrains Aqua team",
        "dc:creator": "Sergey Kozlovskiy",
        "content": "JetBrains Aqua is proud to join the global tech community in celebrating International Tester’s Day on September 9. This day recognizes the crucial contributions of QA professionals, who ensure that the software we rely on functions flawlessly and delivers a superior user experience. Buy Aqua – 50% OFF Why testers are our everyday heroes In [&#8230;]",
        "contentSnippet": "JetBrains Aqua is proud to join the global tech community in celebrating International Tester’s Day on September 9. This day recognizes the crucial contributions of QA professionals, who ensure that the software we rely on functions flawlessly and delivers a superior user experience. Buy Aqua – 50% OFF Why testers are our everyday heroes In […]",
        "guid": "https://blog.jetbrains.com/?post_type=qa&p=508140",
        "isoDate": "2024-09-09T11:00:58.000Z"
      },
      {
        "creator": "Daniela Bentrup",
        "title": "Fleet 1.40 Is Here With Compose Preview for Android, Inlay Hints for Generating Documentation for PHP and Groovy, and Other Improvements",
        "link": "https://blog.jetbrains.com/fleet/2024/09/fleet-1-40-is-here-with-compose-preview-for-android-inlay-hints-for-generating-documentation-for-php-and-groovy-and-other-improvements/",
        "pubDate": "Mon, 09 Sep 2024 07:38:22 +0000",
        "content:encodedSnippet": "Fleet 1.40 is now available! In this release, we’ve introduced some new features while also focusing on many important bug fixes. Your feedback is vital to making Fleet even better. Please report any problems you encounter to our issue tracker, or add a vote to an existing issue to express your support.\nYou can update to this version using the Toolbox App. Let’s take a closer look at the highlights.\nDownload Fleet 1.40\nNew features\nFleet 1.40 introduces Compose Preview for Android. Since previewing an app’s UI in the IDE is one of the most critical scenarios for every mobile developer, this feature significantly improves the multiplatform development experience for Android developers. You can now leverage powerful preview customization tools from Android Studio in Android sources such as multi-preview, parameter providers, and annotation options.\n\n\n\n\n\nBut there’s more! Along with previews for Android code, we’ve also added the option to render Android previews from common code. For projects with both Android and regular JVM targets, you can now choose which platform to render against (Android or Desktop).\nWe’ve added inlay hints for generating documentation for PHP and Groovy. Fleet already supported this feature for Java, Kotlin, and JavaScript. Just type /** and press Enter to bring up the Generate Documentation option, and then press ⌥↵ / Alt+Enter to show the tooltip.\nImprovements\nFleet 1.40 introduces a new shortcut for the Build & Refresh action when running Android Preview. ⌥⇧⌘R on macOS or Ctrl+Shift+F5 on Windows.\nThe Generate Code template is now hidden  when you are logged out.\nWhen you generate code with AI Assistant, the editor now scrolls along with the generated content.\n\n\n\nBug fixes\nWe’ve also fixed several bugs:\nUndoing the renaming of a file no longer deletes the file [FL-27850].\nSoft wraps now work correctly in the diff viewer [FL-19723].\nGradle run configurations are executed successfully, even when passing parameters with spaces [FL-28619].\nThe Git Push action is now available after you create a new branch with a new commit [FL-27285].\nUsing Page Up and Page Down quickly scrolls as expected [FL-23471].\nSee the full release notes for more details about Fleet 1.40.\nStay tuned for further exciting announcements.\nJoin the JetBrains Tech Insights Lab to participate in surveys, interviews, and UX studies, and help us make JetBrains Fleet better!",
        "dc:creator": "Daniela Bentrup",
        "content": "Fleet 1.40 is now available! In this release, we’ve introduced some new features while also focusing on many important bug fixes. Your feedback is vital to making Fleet even better. Please report any problems you encounter to our issue tracker, or add a vote to an existing issue to express your support. You can update [&#8230;]",
        "contentSnippet": "Fleet 1.40 is now available! In this release, we’ve introduced some new features while also focusing on many important bug fixes. Your feedback is vital to making Fleet even better. Please report any problems you encounter to our issue tracker, or add a vote to an existing issue to express your support. You can update […]",
        "guid": "https://blog.jetbrains.com/?post_type=fleet&p=507729",
        "categories": [
          "news",
          "releases"
        ],
        "isoDate": "2024-09-09T07:38:22.000Z"
      },
      {
        "creator": "Roman Pronskiy",
        "title": "PHP Annotated – September 2024",
        "link": "https://blog.jetbrains.com/phpstorm/2024/09/php-annotated-september-2024/",
        "pubDate": "Mon, 09 Sep 2024 03:57:21 +0000",
        "content:encodedSnippet": "Welcome to the September edition of PHP Annotated! After a brief summer break, we’re back with all things PHP. This recap is carefully handcrafted and brings you the most interesting developments in the PHP community over the past couple of months, so you don’t have to sift through the noise—we’ve done it for you.\n@media (min-width: 769px) { main .article-section .content ul:not([class]):not([id]) li ul:not([class]):not([id]) { margin-top: 0; margin-bottom: 24px; } } main .article-section .content ul:not([class]):not([id]) li, main .article-section .content ul:not([class]):not([id]) > li {padding-bottom: 18px;}  main .article-section .content ul:not([class]):not([id]) li ul:not([class]):not([id]) li {padding-bottom: 0;} img.alignico {margin-right: 10px;margin-top: 5px;float: left;}  summary {display: list-item;cursor: pointer;font-style: italic; } section.article-section a {color: #7755f3} code {color: red;} #roman-pronskiy,.copy-heading:has(#roman-pronskiy){margin-top: 0;} main li a[href^=\"https://github.com\"]:before {background: no-repeat 2px center url(data:image/svg+xml;utf8;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNCIgaGVpZ2h0PSIxNCIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDMyIDMyIj48cGF0aCBmaWxsPSIjMjQyOTJFIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0xNiAwYTE2IDE2IDAgMCAwLTUgMzEuMmMuNy4xIDEtLjQgMS0uOHYtM2MtNCAuOC01LTEtNS40LTEuOC0uMS0uNS0xLTItMS42LTIuMy0uNi0uMy0xLjQtMSAwLTEgMS4yIDAgMi4xIDEuMSAyLjQgMS42IDEuNSAyLjQgMy44IDEuNyA0LjcgMS4zLjEtMSAuNi0xLjcgMS0yLjEtMy41LS40LTcuMy0xLjgtNy4zLTggMC0xLjcuNy0zLjEgMS43LTQuMi0uMi0uNC0uNy0yIC4xLTQuMyAwIDAgMS40LS40IDQuNCAxLjdhMTQuOCAxNC44IDAgMCAxIDggMGMzLjEtMi4xIDQuNC0xLjcgNC40LTEuNyAxIDIuMi40IDMuOS4yIDQuM2E2IDYgMCAwIDEgMS42IDQuM2MwIDYuMS0zLjcgNy41LTcuMyA3LjkuNi41IDEuMSAxLjQgMS4xIDN2NC4zYzAgLjQuMyAxIDEuMS44QTE2IDE2IDAgMCAwIDE2IDBaIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiLz48L3N2Zz4=);content: \"\";padding-left: 20px;} main li a[href^=\"https://www.youtube.com\"]:before {background: no-repeat 0px center url(\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' height='100%25' version='1.1' viewBox='0 0 68 48' width='100%25'%3E%3Cpath class='ytp-large-play-button-bg' d='m .66,37.62 c 0,0 .66,4.70 2.70,6.77 2.58,2.71 5.98,2.63 7.49,2.91 5.43,.52 23.10,.68 23.12,.68 .00,-1.3e-5 14.29,-0.02 23.81,-0.71 1.32,-0.15 4.22,-0.17 6.81,-2.89 2.03,-2.07 2.70,-6.77 2.70,-6.77 0,0 .67,-5.52 .67,-11.04 l 0,-5.17 c 0,-5.52 -0.67,-11.04 -0.67,-11.04 0,0 -0.66,-4.70 -2.70,-6.77 C 62.03,.86 59.13,.84 57.80,.69 48.28,0 34.00,0 34.00,0 33.97,0 19.69,0 10.18,.69 8.85,.84 5.95,.86 3.36,3.58 1.32,5.65 .66,10.35 .66,10.35 c 0,0 -0.55,4.50 -0.66,9.45 l 0,8.36 c .10,4.94 .66,9.45 .66,9.45 z' fill='%23FF0000' fill-opacity='0.81'%3E%3C/path%3E%3Cpath d='m 26.96,13.67 18.37,9.62 -18.37,9.55 -0.00,-19.17 z' fill='%23fff'%3E%3C/path%3E%3Cpath d='M 45.02,23.46 45.32,23.28 26.96,13.67 43.32,24.34 45.02,23.46 z' fill='%23ccc'%3E%3C/path%3E%3C/svg%3E\"); content: \"\";padding-left: 18px;background-size: 16px;}\nHighlights\nLaravel raises a $57 million Series A from Accel\nRight after the Laracon US, Taylor Otwell posted a tweet announcing a $57M investment from Accel, a renowned venture capital firm.\nCongratulations to Taylor and the team!\nCheck out this video interview to learn more:\n\n        \nPHP 8.4.0 Beta 4 is available for testing\nUpdates for PHP 8.4 are released every two weeks, following the timeline. The final release is expected on November 21.\nThe feature freeze took effect on August 13, meaning the set of new features is now locked in, and any major changes will be postponed to the next PHP version.\nSome of the most notable changes in PHP 8.4 include:\nProperty hooks\nAsymmetric Visibility\nnew MyClass()->method() without parentheses\nLazy Objects\nNew HTML5 Support\nNew functions for working with arrays: array_find(), array_find_key(), array_any(), and array_all().\nFor a detailed list of what’s coming in PHP 8.4 see php.watch, stitcher.io, or Ash Allen posts.\n        Try PHP 8.4:\nOn Mac, you can install it using Homebrew through the Nightly channel via shivammathur/homebrew-php.\nFor other platforms, Docker images are probably the easiest way to try it out with no hassle.\nFor a quick local test, PHP 8.4 is also available on Herd.\nState of Generics and Collections 💜\nArnaud Le Blanc, Derick Rethans, and Larry Garfield have published a comprehensive research article on the current state of generics in PHP. The article covers all possible implementations with the pros and cons of each.\nYou can join the ongoing discussion on the mailing list and Reddit.\nIn the meantime, you can start leveraging of generics with PHPDoc blocks.\nShutting down Packagist.org support for Composer 1.x\n        With over 95% of Composer updates now using v2, Composer v1 will be officially shut down on August 1, 2025.\n    \nPhpStorm 2024.2 is out\n        Highlights include: \nLog files support\nCompletion in the new terminal\nEditing from a floating toolbar\nPER Coding Style\nNew UI Becomes the Default\nFundraiser by Joe Watkins : A big ask from a big community\nJoe Watkins (@krakjoe), a pillar of the PHP community, needs help. Joe is one of the creators of The PHP Foundation and author of several PHP tools you’ve likely used in your work, including pcov, phpthreads, and parallel.\nAfter battling severe health issues, he’s facing homelessness & loss of life-saving meds. Please donate if you can and help reshare ❤️‍🩹\n\"PHP is beautiful and powerful\"\n        \n    \nPHP Core\n✅ RFC: Asymmetric Visibility v2 💜\n        Thanks to Ilija Tovilo’s and Larry Garfield’s proposal, PHP 8.4 will have asymmetric visibility, i.e. possibility to make properties public for reading (get) and private for changing (set). The syntax was inspired by Swift.\n    \n✅ RFC: Lazy Objects 💜\n        Lazy objects are standard objects except that their initialization is deferred until one of their properties is accessed (including non-existing ones). This can be useful\nVery likely, the lazy objects won’t be used directly by most PHP users, but package and framework authors will benefit from it a lot as it allows them to remove a lot of boilerplate code. Here is for example how symfony/var-exporter will be simplified:\n        \n    \n✅ RFC: Transform exit() from a language construct into a standard function 💜\nGina Peter Banyard proposed to make exit() a proper function with the following signature: function exit(string|int $status = 0): never {}\nThe benefit is that it will properly validate the arguments passed and throw a TypeError if you pass something irrelevant, such as an array or resource.\n📣 RFC: Improve language coherence for the behaviour of offsets and containers 💜\nPHP supports offset accesses using brackets [] with the following notation $container[$offset]. However, the behavior of such accesses depends not only on the container type and offset, but also on the operation that is performed when accessing the offset. The existing behavior is highly inconsistent and difficult to predict.\nGina Peter Banyard proposes to improve language consistency for offsets and containers.\n📣 RFC: Function Autoloading v4\n        Robert Landers proposes to add the ability to autoload functions by adding a 4th parameter to spl_autoload_register(…). Then with a simple PSR-4-like autoloader for functions, the code example could look like this:\nspl_autoload_register(function ($function_name) {...}, false, false, SPL_AUTOLOAD_FUNCTION);   \n\nThere is an alternative more comprehensive proposal from Gina P. Banyard: RFC: New core autoloading mechanism with support for function autoloading.\n📣 RFC: Default expression\n        Paul Morris proposes to introduce the default expression in argument-passing contexts to use the default value of the function or method.\nfunction greetingEveryone($greeting = 'Hello', $subject = 'World') {  \n    return sprintf('%s, %s!', $greeting, $subject);  \n}  \n\necho greetingEveryone(default, ‘Earth’)); // Hello, Earth!  \n\n        A similar proposal has been declined in the past, and it seems the problem has already been solved with the named arguments\n    \nTools\narokettu/composer-license-manager – The plugin for Composer that allows specifying license policies, e.g. list of allowed licenses for a project and avoid proprietary packages, packages with non-permissive licenses such as GPL, or no license at all. 🔗\n    \nphp-tui/php-tui – A framework for creating console applications in PHP with pseudo graphical UI. terminal user interfaces (TUIs)\ncomposer/pcre – PCRE wrapping library that offers type-safe preg_* replacements.\n    \nclementtalleu/php-redis-om – A PHP object mapper for Redis. Check out the intro article for more details.\n    \nSammyjo20/ssh-php – The ridiculously simple starting point for building PHP SSH apps.\n    \nServBay – A local dev environment, alternative to Laravel Herd.\n    \nHiEventsDev/Hi.Events – Open-source event management and ticket selling platform.\n    \nfreescout-help-desk/freescout – Free self-hosted help desk & shared mailbox (Zendesk / Help Scout alternative).\n    \nsavinmikhail/Comments-Density – Analyze the comment density and quality in PHP files to maintain and improve code documentation quality.\n    \nprasathmani/tinyfilemanager – Single-file PHP file manager, browser and manage your files efficiently and easily with tinyfilemanager.\n    \nTicketSwap/phpstan-error-formatter – A minimalistic error formatter for PHPStan.\n    \n\n    \nAI\nTransformersPHP\nIt’s a PHP package that lets you run pretrained models from HuggingFace directly in PHP – no API, no extra server required.\nThe package is designed to be functionally equivalent to the popular Python Transformers library. So it’s easy to start using if you’re familiar with ML.\nHere are some use-cases:\nBuilding a Background Removal Tool with Laravel and TransformersPHP.\nHow to translate content programmatically using AI and TransformersPHP.\nHow to auto-generate the image Alt-Text using AI and Transformers PHP.\nMachine Learning with PHP.\nUnder the hood, it uses ONNX Runtime and Math libray Rindow via FFI. And the cool part is that it handles everything for you, even downloading all the libs according to your OS with a small Composer plugin: CodeWithKyrian/transformers-libsloader.\nllm-agents-php/agents – LLM Agents abstraction.\nThis package is a framework for creating, managing, and deploying AI agents within PHP environments. The library aims to simplify using Retrieval-Augmented Generation (RAG) techniques into PHP projects.\nCheck out a sample-app and a video showcase: Building a Blog with LLM Agents.\nSymfony\nFunctional Tests with Symfony and Webhook component by Pierre Emmanuel Capel.\nBundling Your Symfony UX Twig Components by Yonel Ceruto.\nzenstruck/console-extra – A modular set of features to reduce configuration boilerplate for your Symfony commands.\nSymfony 7.1 curated new features\nLaravel\nLaracon US 2024\nLast week, the flagship Laravel conference happened in Dallas, TX. Some big announcements were made, including:\nLaravel Cloud\nPest 3\nInvertia.js v2\nLaravel VS Code extension\nA few cool features for Laravel 11\nThe State of Laravel Survey 2024\nThe results of the annual survey are now published and have some interesting insights.\nCheck Brent’s overview of the results on YouTube.\nBuilt with Laravel – Nice inspo catalog.\nLaravel Config Problem: Is It Time for a Revolution?.\nLearn to master Query Scopes in Laravel by Ashley Allen.\nHow to test all routes in your Laravel app by writing just a single Pest test by Freek Van der Herten.\nAdding real-time chat in 14 lines of code with Laravel Reverb and Livewire by Simon Hamp.\nBuilding Desktop Applications using Native PHP with Simon Hamp by Laravel News.\nI challenged myself to run Laravel with rryqszq4/ngx-php, and ended up benchmarking other runtimes along the way:\n        \n    \nOther Frameworks\nPhalcon + Swoole in High Load Micro Service – A case study on using Swoole to turn PHP into a high-performance powerhouse!\nUsing Laminas Continuous Integration by Julian Somesan.\nCurrent Maintenance Status of Laminas & Mezzio Packages by Julian Somesan.\nMisc\nSlowly introducing static analysis without changing everything by Joel Clermont.\nArray Shapes For Preg Match Matches by Markus Staab.\nContainer Efficiency in Modular Monoliths: Symfony vs. Laravel by Kamil Ruczyński.\nTo double quote or not, that’s the question! by Florian Engelhardt.\nScope and Downgrade your PHP Tools for Everyone to Use by Tomas Votruba.\nThe #[\\Override] Attribute in PHP by Ashley Allen.\nStore Code Discussions in Git using Git Notes by Wouter de Jong – This is how Symfony stores GitHub Discussions in Git.\nChoosing a PHP Library based on Performance by Benjamin Eberlei.\nHow to use PHP-VCR to record and replay API calls in PHP – by Imen Ezzine.\nInheritance in modern programming languages is different… by Brent.\nHow to build a game engine in a CMS, in PHP by Jack Wilkinson.\nHow Craft CMS built Craft Cloud – A case study from Bref, the serverless PHP tool.\nConferences\nThese PHP events are all worth a visit, and some are still accepting presentation proposals:\nAPI Platfrom Conference – Lille, France, September 19-20.\nCascadiaPHP 2024 – Portland, OR, USA, October 24-26.\nPHPCon Poland 2024 – Wisła, Poland, October 25–26.\nLaracon AU – Brisbane, Australia, November 7–8.\nInternational PHP Conference – Munich, Germany, November 11‒15.\nSymfonyCon 2024 – Vienna, Austria, December 5–6.\nLaracon EU 2025 – Amsterdam, The Netherlands, February 3-4. CFP 🆕\nPHP UK Conference 2025 – London, UK, February 19. CFP 🆕\nphp[tek] 2025 – Chicago, IL, USA, May 20-22. CFP 🆕\nTo find a PHP meetup happening near you, check out the calendar on php.net.\nFun\nJavaScript Bloat in 2024 by Niki Tonsky – “Gitlab needs 13 MB of JS code just to display a static landing page.”\n\n\n    \nIf you have any interesting or useful links to share via PHP Annotated, please leave a comment on this post or let us know on X/Twitter.\nSubscribe to PHP Annotated\nRoman Pronskiy\nDeveloper Advocate at @PhpStorm, Operations Manager at @The PHP Foundation.\nTwitter | GitHub",
        "dc:creator": "Roman Pronskiy",
        "content": "Welcome to the September edition of PHP Annotated! After a brief summer break, we’re back with all things PHP. This recap is carefully handcrafted and brings you the most interesting developments in the PHP community over the past couple of months, so you don’t have to sift through the noise—we’ve done it for you. Highlights [&#8230;]",
        "contentSnippet": "Welcome to the September edition of PHP Annotated! After a brief summer break, we’re back with all things PHP. This recap is carefully handcrafted and brings you the most interesting developments in the PHP community over the past couple of months, so you don’t have to sift through the noise—we’ve done it for you. Highlights […]",
        "guid": "https://blog.jetbrains.com/?post_type=phpstorm&p=508283",
        "categories": [
          "news",
          "laravel",
          "php",
          "php-8-3",
          "php-8-4",
          "php-annotated-monthly",
          "rfc",
          "symfony"
        ],
        "isoDate": "2024-09-09T03:57:21.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": [
      {
        "creator": "Xiangmin Liang",
        "title": "Riverbed Data Hydration — Part 1",
        "link": "https://medium.com/airbnb-engineering/riverbed-data-hydration-part-1-e7011d62d946?source=rss----53c7c27702d5---4",
        "pubDate": "Tue, 10 Sep 2024 16:01:29 GMT",
        "content:encodedSnippet": "Riverbed Data Hydration — Part 1\nby: Xiangmin Liang, Sivakumar Bhavanari, Amre Shakim\n\nA deep dive into the streaming aspect of the Lambda architecture framework that optimizes how data is consumed from system-of-record data stores and updates secondary read-optimized stores at Airbnb.\nOverview\nIn our previous blog post we introduced the motivation and high-level architecture of Riverbed. As a recap, Riverbed is a part of Airbnb’s tech stack designed to streamline and optimize how data is consumed from system-of-record data stores and update secondary read-optimized stores. The framework is built around the concept of ‘materialized views’ — denormalized representations of data that can be queried in a predictable, efficient manner. The primary goal of Riverbed is to improve scalability, enable more efficient data fetching patterns, and provide enhanced filtering and search capabilities for a better user experience. It achieves this by keeping the read-optimized store up-to-date with the system-of-record data stores, and by making it easier for developers to build and manage pipelines that stitch together data from various data sources.\nIn this blog post, we will delve deeper into the streaming aspect of the Lambda architecture framework. We’ll discuss step by step its critical components and explain how it constructs and sinks the materialized view from the Change Data Capture (CDC) events of various online data sources. Specifically, we’ll take a closer look at the join transformation within the Notification Pipeline, illustrating how we designed a DAG-like data structure to efficiently join different data sources together in a memory-efficient manner.\nTo make the framework and its components easier to understand, let’s begin with a simplified example of a Riverbed pipeline definition:\n{\n  Review {\n    id @documentId\n    review\n    User {\n      id\n      firstName\n      lastName\n    }\n  }\n}\nRiverbed provides a declarative schema-based interface for customers to define Riverbed pipelines. From the sample definition above, a Riverbed pipeline is configured to integrate data sources from the Review and User entities, generating Riverbed sink documents with the review ID as the materialized view document ID.\nBased on this definition, Riverbed generates two types of streaming pipelines:\n\nSource Pipelines: Two pipelines consume CDC events from the Review and User tables respectively and publish Apache Kafka® events known as notification events, indicating which documents need to be refreshed.\nNotification Pipeline: This pipeline consumes the notification events published by the source pipelines and constructs materialized view documents to be written into sink stores.\n\nNow, let us delve deeper into these two types of pipelines.\nSource Pipeline\nPicture 1. High-level system diagram of Riverbed\nPicture 1 shows the Source Pipeline as the first component in Riverbed. It is an auto-generated pipeline that listens to changes in system-of-record data sources. When changes occur, the Source Pipeline constructs NotificationEvents and emits them onto the Notification Kafka® topic to notify the Notification Pipeline on which documents should be refreshed. In the event-driven architecture of Riverbed, the Source Pipeline acts as the initial trigger for real-time updates in the read-optimized store. It not only ensures that the mutations in the underlying data sources are appropriately captured and communicated to the Notification Pipeline for subsequent processing, but also is the key solution for the concurrency and versioning issues in the framework.\nWhile the emphasis of this blog post is the Notification Pipeline, a detailed exploration of the Source Pipeline — especially its critical role in maintaining real-time data consistency and its interaction with Notification Pipelines — will be discussed in the next blog post of this series.\nNotification Pipeline\nPicture 2. Notification Pipeline components\nThe Notification Pipeline is the core component of the Riverbed framework. It consumes Notification events, then queries dependent data sources and stitches together “documents” that are written into a read-optimized sink to support a materialized view. A notification event is processed by the following operations:\n\nIngestion: For every change to a data source that the Read-Optimized Store is dependent on, we must re-index all affected documents to ensure freshness of data. In this step, Notification Pipeline consumes Notification events from Kafka® and deserializes them into objects that simply contain the document ID and primary source ID.\nJoin: Based on these deserialized objects, Notification Pipeline queries various data stores to fetch all data sources that are necessary for building the materialized view.\nStitch: This step models the join results from various data sources into a comprehensive Java Pojo called StitchModel, so that engineers can perform further customized data processing on it.\nOperate: In this step, a chain of various operators including filter, map, flatMap, etc, containing product-specific business logic can be applied to the StitchModel to convert it into the final document structure that will be stored in the index.\nSink: As the last step, documents can be drained into various data sinks to refresh the materialized views.\n\nAmong these operations, Join, Stitch and Sink are the most important as well as the most complicated ones. In the following sections, we will dive deeper into their design.\nData Source Join\nOne of the most crucial and intricate operations in Riverbed’s Notification Pipeline is the Join operation. A Join operation starts from the primary source ID and then fetches data for all data sources associated with the materialized view based on their relationship.\nJoinConditionsDag\nIn Riverbed, we use JoinConditionsDag, a Directed Acyclic Graph, to store the relationship metadata among data sources, where each node represents one unique data source and each edge represents the join condition between two data sources. In the Notification Pipelines, JoinConditionsDag’s root node is always a metadata node for the notification event which contains the document ID and the primary source ID. The join condition connecting to the notification event node reflects the join condition to query the primary source. Below is a sample JoinConditionsDag defining the join relationship between the primary source Listing and some of its related data sources:\nPicture 3: JoinConditionsDag Sample\nGiven notification events are used to indicate which document needs to be refreshed and does not contain any source data, Notification Pipeline joins data sources starting from the primary source ID provided by the Notification event. Guided by the JoinConditionsDag, when the Notification Pipeline processes a Notification event containing the primarySourceId, it queries the Listing table to fetch Listing data where the id matches primarySourceId. Subsequently, leveraging this Listing data, it queries the ListingDescription and Room tables to retrieve listing descriptions and rooms data, respectively, where the listingId equals id of Listing. In a similar manner, RoomAmenity data is obtained with roomId matching the id of the Room data.\nJoinResultsDag\nNow, we have the JoinConditionsDag guiding the Notification Pipeline to fetch all data sources. However, the question arises: how can we efficiently store the query results? One straightforward option is to flatten all the joined results into a table-like structure. Yet, this approach can consume a significant amount of memory, especially when performing joins with high cardinality. To optimize memory usage, we designed another DAG-like data structure named JoinResultsDag.\nPicture 4: JoinResultsDag Structure\nThere are two major components in a JoinResultsDag. Cell is the atomic container for a data record. Each cell maintains its own successor relationships by mapping successor data source aliases to the CellGroups. CellGroup is the container to store the joined records from one data source. Each data source table record is stored in each Cell.\nAs mentioned above, the biggest difference and the advantage of using a DAG-based data structure instead of using the traditional flat join table is that it can efficiently store a large amount of join result data especially when there is a 1:M or M:N join relationship between data sources. For example, we have one pipeline to create materialized views for Airbnb Listings with information about all their Listing rooms, which also have lots of room amenities. If we use the traditional flat join table, it will look like the following table.\n\nObviously, storing joined results using a flat table structure demands extensive resources for both storage and processing. In contrast, JoinResultsDag effectively mitigates data duplication by allowing multiple successor nodes to refer back to the same ancestor nodes.\nPicture 5: JoinResultsDag Example\nNow with JoinConditionsDag representing the relationship among all data sources and JoinResultsDag storing all the results, joins can be performed in Riverbed roughly as follows:\nStarting from the NotificationEvent, Riverbed first initializes a JoinResultsDag with the deserialized Notification event as root. Then guided by the JoinConditionsDag and following a depth-first-search traverse, it visits the data store of each source, queries data based on the join conditions defined on the JoinConditionsDag edges, encapsulates the query results rows inside each Cell and then continues fetching the data of its dependencies until finished visiting all data sources.\nStitching of Data\nWith the joined results now stored in JoinResultsDag, an additional operation is necessary to transform these varied data pieces into a more usable and functional model. This enables engineers to apply their custom operators, mapping the data onto their specifically designed Sink Document. We refer to this process as the Stitch Operation, resulting in what is known as the StitchModel.\nThe StitchModel, a Java POJO derived from the custom pipeline definition, serves as the intermediate data model that not only contains the actual data but also contains useful metadata about the event such as document ID, version, mutation source, etc.\nAfter the StitchModel metadata is generated, with the help of the JoinResultsDag, the Stitch operation is more straightforward. It maps the JoinResultsDag into a JSON model with the same structure and then converts the JSON model into the custom defined Java POJO utilizing the GSON library.\nSink data\nThe final stage in Riverbed’s Notification Pipeline is to write documents into data sinks. In Riverbed, sinks define where the processed data, now in the form of documents, will be ingested after the preceding operations are completed. Riverbed allows for multiple sinks, including Apache Hive(™) and Kafka®, so the same data can be ingested into multiple storage locations if required. This flexibility is a key advantage of the Notification Pipeline, enabling it to cater to a wide variety of use cases.\nRiverbed writes documents into data sinks via their write APIs. For the best performance, it encapsulates a collection of documents into the API request and then makes use of the batched write API of each data sink to update multiple documents efficiently.\nSummary\nIn conclusion, we’ve navigated the critical steps of Riverbed’s streaming system within the Lambda architecture framework, focusing on the construction of materialized views from CDC events. Our highlight on the join transformation within the Notification Pipeline showcased a DAG-like structure for efficient and memory-conscious data joining. This discussion has shed light on the architectural approach to constructing materialized views in streaming and introduced innovative data structure designs for optimizing streaming data joins. Looking ahead, we will delve deeper into the Source Pipeline of the streaming system and explore the batch system of Riverbed, continuing our journey through advanced data architecture solutions.\nIf this kind of work sounds appealing to you, check out our open roles — we’re hiring!\n\nRiverbed Data Hydration — Part 1 was originally published in The Airbnb Tech Blog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Xiangmin Liang",
        "guid": "https://medium.com/p/e7011d62d946",
        "categories": [
          "data",
          "infrastructure",
          "data-science",
          "engineering",
          "architecture"
        ],
        "isoDate": "2024-09-10T16:01:29.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "article New updates to Planner comment notifications and settings in Planner Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Dominic Nahous",
        "title": "VisualStudio.Extensibility 17.11: Settings and more Remote UI support",
        "link": "https://devblogs.microsoft.com/visualstudio/visualstudio-extensibility-17-11-settings-and-more-remote-ui-support/",
        "pubDate": "Thu, 12 Sep 2024 10:00:43 +0000",
        "content:encodedSnippet": "We continue to invest in the VisualStudio.Extensibility SDK to allow users like you to create extensions that run faster and smoother than ever before! VisualStudio.Extensibility helps you build extensions that run outside the main Visual Studio IDE process for improved performance and reliability. Additional benefits include a sleek and intuitive .NET 8-based API and comprehensive, well-maintained documentation to help you develop amazing extensions faster than ever before.\nThis 17.11 release builds on our previous releases, bringing support for defining user-configurable settings for your extensions to allow your users to customize their experience along with even more enhancements to remote UI features. We’ve also made substantial updates to our project query API documentation.\nGet started with VisualStudio.Extensibility\n\nFor the latest up-to-date docs and installation instructions, visit https://aka.ms/VisualStudio.Extensibility. We encourage you to report bugs and suggest features via the issue tracker on our GitHub repo, where you can also find extension samples to help you get started.\nWhat’s new for VisualStudio.Extensibility?\nOur 17.11 release of VisualStudio.Extensibility includes the following features:\nCustomize your extensions further with settings support\nShow images and use context menus in Remote UI\nEnhance your tool windows with toolbars\nWe’ve also refreshed and updated the project query API documentation based on feedback from extension developers like you!\nCustomize your extensions further with settings support\nWith this release of VisualStudio.Extensibility, we’ve enabled a handful of APIs that allow you to define settings for your extensions. This allows your end users to alter the behavior of the extension by adjusting values you’ve elected to define as settings.\nIn order to support this scenario, you’ll now find APIs specific to defining, accessing, and writing settings in your extension. To add settings to your extension, first add a definition for your setting in a class in the extension.\nIf you’d like to learn more about how to define and leverage settings in your apps, refer to the VisualStudio.Extensibility settings article. You’ll find more details along with samples to get you coding quickly!\nNote that the settings API, like VisualStudio.Extensibility, supports Hot Loading of settings. This allows your extension’s settings to be discovered without requiring your users to restart Visual Studio.\nShow images and use context menus in Remote UI\nAs the VisualStudio.Extensibility model prioritizes extensions running outside of the Visual Studio process, it introduces a challenge when adding UI support to extensions as most UI frameworks are in-process. To get around this, there is a set of classes called Remote UI that allow you to define WPF controls in an out-of-process extension and then show them as part of the Visual Studio UI.\nWith this release, you can now add a context menu to a Remote UI control from XAML, a familiar experience if you’ve ever added a context menu in standard WPF. You’ll also be able to use Remote UI XAML to show either custom images or images that already exist in the Visual Studio catalog. This gives you additional options for providing users with useful information in a visual format and can help you increase your extension’s UI appeal!\nVisit the Other Remote UI concepts documentation for code samples and more information.\nEnhance your tool windows with toolbars\nYou can now use VisualStudio.Extensibility to add toolbars to your extension’s tool windows to give your users a quick and easy way to access or leverage features in your extension.\nSee the Add a toolbar to a tool window section in the tool window overview doc to learn more about creating, adding content to, showing, and controlling the visibility of tool windows – and of course to learn more about adding toolbars to those tool windows.\nProject Query API documentation updates\nIn response to your valuable feedback, we have revamped our documentation to better serve your needs. As we transition to a new model, our project query documentation is evolving to leverage VisualStudio.Extensibility project query wrappers for accessing and modifying solutions/projects. To explore the updated documentation, please refer to Query the Project API (VisualStudio.Extensibility). For details specific to project query using Visual Studio SDK, you can visit Query the Project API (Visual Studio SDK).\nAbout experimental APIs, breaking changes, and how we make decisions about VisualStudio.Extensibility\nIn reviewing feedback from our issue tracker, we realized it would be useful to outline information about some of the decisions we’ve made around VisualStudio.Extensibility. With this new extensibility model, we carefully consider exactly what should and should not be supported based on two major criteria: your feedback and the design goals of the project. One recent example: we decided not to support the ability to programmatically invoke VSCT (Visual Studio Command Table)-based commands via VisualStudio.Extensibility. This decision aligned with established principles for VisualStudio.Extensibility for a few reasons:\nVSCT based commands are synchronous. VisualStudio.Extensibility extensions operate asynchronously in a separate process.\nAs there’s no guarantee that UI state will remain coherent due to the asynchronous nature of the invocation from another process or thread, allowing invocation could lead to unpredictable user experiences.\nVSCT-based commands allow input and output of any type. VisualStudio.Extensibility extensions can run out of process. This imposes limitations around the types of input and output data that can be serialized.\nDirect command invocation breaks our commitment to having consistent, easy-to-use APIs as it would essentially introduce another set of APIs that are more macro/script-like.\nAs we continue increasing the surface area of the VisualStudio.Extensibility SDK, we’ll rely on this framework to inform decisions on API coverage and availability. The API is growing and changing. We aim to minimize breaking changes and ensure stability and a consistent experience for you, our extension developers. When we make changes because of customer feedback or internal changes, we’ll communicate it formally with plenty of notice on the VisualStudio.Extensibility breaking changes page. We’ll use the following guidelines for breaking changes to experimental APIs:\nBreaking changes can be made as part of LTSC minor version releases of Visual Studio.\n\nA list of breaking changes for the release will be shared by Preview 2 of that release.\nThe list will be shared in the breaking changes doc linked above.\nRemoval of APIs may be formally deprecated by marking the type or by using the [Obsolete] attribute.\n\nThis will also happen by Preview 2 of the release in which they’ll be removed.\nMost APIs in VisualStudio.Extensibility are stable, which means we do not plan to make any breaking changes to them. For these, we want to replicate the stability expectations associated with the existing VS SDK:\nBreaking changes to VisualStudio.Extensibility APIs or RPC contracts will only happen as part of a major version release of Visual Studio.\n\nThe list of breaking changes will be available by Preview 1 of the release.\nAny API removal will happen formally by marking the type or by using the [Obsolete] attribute.\nDemotion of stable APIs to experimental is considered a breaking change and will be formally announced.\nWe can’t do this without you!\nThe time and effort you’ve spent reporting issues and sharing suggestions so far has been instrumental in shaping VisualStudio.Extensibility. We need your help as we continue to develop VisualStudio.Extensibility! Please try out this preview release and let us know what you think. Check out the docs, browse the code samples, and build your first extension. You can send feedback and report issues through our issue tracker.\nTo request features, look at Developer Community to see if someone else made a similar request first. Create a new one if you can’t find a similar request. By checking for similar requests and upvoting and commenting on them, you help us better prioritize requests. Give VisualStudio.Extensibility a try today and share your thoughts with us!\nThe post VisualStudio.Extensibility 17.11: Settings and more Remote UI support appeared first on Visual Studio Blog.",
        "dc:creator": "Dominic Nahous",
        "content": "<p>We continue to invest in the VisualStudio.Extensibility SDK to allow users like you to create extensions that run faster and smoother than ever before! VisualStudio.Extensibility helps you build extensions that run outside the main Visual Studio IDE process for improved performance and reliability. Additional benefits include a sleek and intuitive .NET 8-based API and comprehensive, [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/visualstudio-extensibility-17-11-settings-and-more-remote-ui-support/\">VisualStudio.Extensibility 17.11: Settings and more Remote UI support</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "We continue to invest in the VisualStudio.Extensibility SDK to allow users like you to create extensions that run faster and smoother than ever before! VisualStudio.Extensibility helps you build extensions that run outside the main Visual Studio IDE process for improved performance and reliability. Additional benefits include a sleek and intuitive .NET 8-based API and comprehensive, […]\nThe post VisualStudio.Extensibility 17.11: Settings and more Remote UI support appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=250567",
        "categories": [
          "Extensibility",
          "Visual Studio",
          "Extensions"
        ],
        "isoDate": "2024-09-12T10:00:43.000Z"
      },
      {
        "creator": "Leah Tran",
        "title": "Search scoping helps you find what you’re looking for",
        "link": "https://devblogs.microsoft.com/visualstudio/search-scoping-helps-you-find-what-youre-looking-for/",
        "pubDate": "Wed, 11 Sep 2024 10:00:38 +0000",
        "content:encodedSnippet": "If you’re working on a large and complex solution, you might find yourself overwhelmed by the number of results when you use code search in Visual Studio. You might be looking for a specific class, method, or variable, but end up scrolling through pages of irrelevant matches. Wouldn’t it be nice if you could narrow down your search scope to only the parts of the solution that you care about?\nIn the latest update of Visual Studio, you can now use the new scoping options in code search to filter your results by the entire solution, the current project, or the current document. You can also toggle the inclusion of external files in your search.\nThis way, you can quickly and easily find what you need without getting lost in the noise.\n\nHow to Use Scoping in Code Search\nTo access the new scoping options, open the Code Search window by pressing Ctrl+T or clicking on the Search button (magnifying glass icon) at the top of the IDE. You’ll see a drop-down menu at the far right of the search box that lets you choose between different scopes.\nYou can select one of the following options:\nEntire solution\nCurrent project\nCurrent document\n\nYou can also click on the checkbox next to Search in external items to toggle the inclusion of code files that are not part of your solution.\nYou can set different scopes for different filters, and your selections will be remembered across sessions. For example, you can set the default filter to search through the entire solution, and the member filter to search through the current document. This way, you can switch between various levels of granularity depending on what you’re looking for.\nHere’s an example of how code search scoping can help you find what you need faster. Suppose you want to find a method called GetProducts in your solution. If you use the default filter and scope, you might get hundreds of results from various projects. But if you use the member filter and scope it to the current project, you will get a narrower set of results that are relevant to your current context.\nWe Hope You Enjoy This Feature\nWe hope that code search scoping will make your coding experience more productive and enjoyable. We’d love to hear your feedback on this feature and any other suggestions you have for improving code search in Visual Studio 2022. You can leave a comment below, use the Report a Problem tool in Visual Studio, or head over to the Developer Community website.\nThank you for your continuous feedback and support, which helps us make Visual Studio better every day.\nThe post Search scoping helps you find what you’re looking for appeared first on Visual Studio Blog.",
        "dc:creator": "Leah Tran",
        "content": "<p>If you&#8217;re working on a large and complex solution, you might find yourself overwhelmed by the number of results when you use code search in Visual Studio. You might be looking for a specific class, method, or variable, but end up scrolling through pages of irrelevant matches. Wouldn&#8217;t it be nice if you could narrow [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/search-scoping-helps-you-find-what-youre-looking-for/\">Search scoping helps you find what you’re looking for</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "If you’re working on a large and complex solution, you might find yourself overwhelmed by the number of results when you use code search in Visual Studio. You might be looking for a specific class, method, or variable, but end up scrolling through pages of irrelevant matches. Wouldn’t it be nice if you could narrow […]\nThe post Search scoping helps you find what you’re looking for appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=250542",
        "categories": [
          "Productivity",
          "Visual Studio",
          "code search",
          "Search"
        ],
        "isoDate": "2024-09-11T10:00:38.000Z"
      },
      {
        "creator": "Anders Sundheim",
        "title": "Break for Async User-Unhandled exceptions in the Visual Studio Debugger",
        "link": "https://devblogs.microsoft.com/visualstudio/break-for-async-user-unhandled-exceptions-in-the-visual-studio-debugger/",
        "pubDate": "Tue, 10 Sep 2024 10:00:16 +0000",
        "content:encodedSnippet": "Before .NET 9, the debugger was unable to track exceptions thrown from user-code async methods into non-user code framework methods, such as ASP.NET middleware. We are pleased to announce that you will now start seeing the debugger stop for these user-unhandled exceptions in your ASP.NET applications, as well as anywhere else this might happen!\n\nSummary\nDebugging asynchronous code, especially in frameworks like ASP.NET Core, can be tricky due to the potential for exceptions to be thrown across asynchronous boundaries.\nNow, the Visual Studio Debugger will automatically break when an async Task method throws an exception back to framework code. This will allow you to easily identify and diagnose issues in your ASP.NET applications, leading to faster debugging cycles and improved productivity. Read below for more details about how user-unhandled exceptions work and how the debugger handles async methods.\nPlease note that this is for .NET 9 and newer projects only.\nDetails\nThe Visual Studio Debugger will enter a break state when exceptions are thrown under three different conditions:\nFirst chance exceptions, where exception settings indicate that the debugger should break whenever exceptions of the specified type are thrown.\nUnhandled exceptions, where the exception is unhandled and no catch handler is found.\nUser-unhandled exceptions, where Just My Code is enabled, and an exception was found to have traveled through user code before a catch handler was found in non-user code.\nUser-unhandled exceptions are the target of the change to account for async user-unhandled scenarios.\nAll async Task<T> functions in C# compile to a state machine with an implicit catch handler that catches all exceptions thrown in the Task, sets IsFaulted, and adds the Exception to the AggregateException in Task.Exception.\nWhen a Task is “unwrapped”, typically either via the preferred await or .Result, the stored exception is rethrown to the caller as would happen in a synchronous method and the implicit catch handling is not typically important or observed.\nTo a debugger, on the other hand, this looks like exceptions are being handled! An exception was thrown, it was caught in “user code” (the compiled result of async Task<T> DoSomethingAsync(...)), and any non-user code awaiting that Task will throw the exception again from non-user code. It is important to note that when Just My Code is enabled, the runtime will avoid sending the debugger events for exceptions that were not thrown in user code, significantly improving performance.\nNow consider this behavior in a typical ASP.NET MVC Controller, when Just My Code is enabled:\n[HttpPost]\npublic async Task<ActionResult<TodoItem>> PostTodoItem(TodoItem todoItem)\n{\n_context.TodoItems.Add(todoItem);\nawait _context.SaveChangesAsync(); // imagine this throws some Exception\nreturn CreatedAtAction(nameof(GetTodoItem), new { id = todoItem.Id }, todoItem);\n}\nIf SaveChangesAsync() throws an unhandled Exception, it will:\n1. Immediately catch it and fault the Task. The debugger is notified, but its user code throwing and catching, so the process continues.\n2. async Task<ActionResult<TodoItem>> PostTodoItem will unwrap the faulted Task, rethrow the Exception, and catch it again. Again, the debugger is notified, but nothing is amiss here (and there might be user code that might eventually await it to catch the exception, we cannot see into the future!)\n3. Whatever non-user library/framework middleware that is awaiting PostTodoItem will unwrap that Task and rethrow the exception, but since Just My Code is enabled, the debugger is oblivious – that exception was not thrown from user code and caught in non-user code, it was thrown from non-user code.\nThus, changes were required in the runtime to allow the debugger to indicate that we’d like to keep an eye on a particular exception object, so that if the compiled catch handler of a user-code async Task<T> method catches an exception, we continue to be notified about that exception object in case it is rethrown in non-user code. That way, if an exception is thrown through an ASP.NET MVC Controller, the debugger can break for user-unhandled.\nLimitations\nThere are some limitations with this approach, notably the fact that the debugger is not actually stopped on the PostTodoItem frame in the example above, it is stopped at the frame below it, where the exception was rethrown and caught in non-user code:\nApp!MyMVCApp.DbContextOptions<TodoContext>.SaveChangesAsync() Line 10\nApp!MyMVCApp.TodoController.PostTodoItem(TodoItem todoItem) Line 5\n[External Code] <- The debugger will stop here\nThis means the frames the exception was thrown from have been unwound past and are not necessarily valid to do variable evaluations on. A GC (Garbage Collection) may have occurred, variables may have been changed, and so on. The debugger will create fake [Exception] frames to represent the context in which the exception was originally thrown, and will attempt to save information from the async state machine to evaluate variables as best as it can, but certain things get nulled out by the compiler as part of async Task exception handling, notably:\nLocal reference type variables\nLocal value types with reference fields, or value types that reference other value types with reference fields.\nParameters and class fields/properties will stay intact, as will the exception itself.\nFor more information, see the original feature request in the public dotnet runtime repository here: https://github.com/dotnet/runtime/issues/12488.\nTo disable entering break state for async user-unhandled, you can run (in the associated Visual Studio Developer Command Prompt)\nvsregedit set local hklm Debugger\\EngineSwitches DisableBreakForAsyncUserUnhandled dword 1\nor otherwise set the indicated key for the target installation of Visual Studio.\nLibrary authors who do not want the debugger to stop on expected exceptions thrown into their functions can use the [DebuggerDisableUserUnhandledExceptions] attribute introduced in .NET 9 Preview 7, and either rethrow the exception or call the new Debugger.BreakForUserUnhandledException(Exception e) function when the exception is unexpected. You can find the API proposal and discussion for this pair of APIs here: https://github.com/dotnet/runtime/issues/103105.\nThank you!\nWe appreciate the time you’ve spent reporting issues/suggestions and hope you continue to give us feedback when using Visual Studio on what you like and what we can improve. Your feedback is critical to help us make Visual Studio the best tool it can be! You can share feedback with us via Developer Community: report any bugs or issues via report a problem and share your suggestions for new features or improvements to existing ones.\nStay connected with the Visual Studio team by following us on YouTube, Twitter, LinkedIn, Twitch and on Microsoft Learn.\nThe post Break for Async User-Unhandled exceptions in the Visual Studio Debugger appeared first on Visual Studio Blog.",
        "dc:creator": "Anders Sundheim",
        "content": "<p>Before .NET 9, the debugger was unable to track exceptions thrown from user-code async methods into non-user code framework methods, such as ASP.NET middleware. We are pleased to announce that you will now start seeing the debugger stop for these user-unhandled exceptions in your ASP.NET applications, as well as anywhere else this might happen! Summary [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/break-for-async-user-unhandled-exceptions-in-the-visual-studio-debugger/\">Break for Async User-Unhandled exceptions in the Visual Studio Debugger</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Before .NET 9, the debugger was unable to track exceptions thrown from user-code async methods into non-user code framework methods, such as ASP.NET middleware. We are pleased to announce that you will now start seeing the debugger stop for these user-unhandled exceptions in your ASP.NET applications, as well as anywhere else this might happen! Summary […]\nThe post Break for Async User-Unhandled exceptions in the Visual Studio Debugger appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=250536",
        "categories": [
          "Debug",
          "Productivity",
          "Visual Studio",
          "Debugger"
        ],
        "isoDate": "2024-09-10T10:00:16.000Z"
      },
      {
        "creator": "Harshada Hole",
        "title": "Supercharge C++ Debugging with AI-Generated breakpoint expressions",
        "link": "https://devblogs.microsoft.com/visualstudio/supercharge-c-debugging-with-ai-generated-breakpoint-expressions/",
        "pubDate": "Mon, 09 Sep 2024 13:39:25 +0000",
        "content:encodedSnippet": "Have you ever spent hours debugging your C++ code, struggling to set up the right conditional breakpoint or tracepoint? Or wished for a smarter way to obtain detailed runtime information without manually crafting complex expressions? You’re in luck! With Visual Studio 2022, the latest GitHub Copilot feature now offers AI-generated expressions for both conditional breakpoints and tracepoints, available from C# 17.10 and now extended to C++. With these AI-generated conditional breakpoints and tracepoints, you can now automate the creation of intelligent expressions tailored to your specific debugging needs, significantly speeding up the process and enhancing your ability to diagnose and resolve issues.\n\nWhat are conditional breakpoints and tracepoints?\nConditional breakpoints and tracepoints are powerful debugging tools that enhance your ability to control and monitor code execution. A conditional breakpoint pauses execution only when a specified condition is true, making it ideal for targeting specific scenarios. For example, you can halt code only when a variable exceeds a certain value or a function is called with particular parameters, while a Tracepoints enable logging of messages to the output window or a file without interrupting code execution and replaces traditional ‘printf’ statements, offering detailed runtime insights without the need for code recompilation.\nThese tools are invaluable for identifying bugs, testing various scenarios, and tracking variables and expression values without manually stepping through each line of code. However, crafting the correct expressions for conditional breakpoints or tracepoints can be challenging and time-consuming, especially when remembering the correct syntax in complex codebases.\nFortunately, with GitHub Copilot you have the flexibility to choose from predefined conditions that suit your needs or to define custom conditions for precise and efficient debugging.\nHow can AI-generated expressions help you debug faster?\nVisual Studio 2022 integrates with GitHub Copilot, AI-powered code completion tool that suggests lines of code or entire functions, effectively acting as a pair programmer that enhances coding efficiency. When you position the cursor in the textbox for a conditional breakpoint or tracepoint, GitHub Copilot promptly provides three AI-generated expression suggestions based on your codebase. You can choose the most suitable condition or create your own custom conditions as needed.\nWith AI-generated expressions, you can save time and effort by letting GitHub Copilot do the hard work for you. You can also discover new ways of writing expressions that you might not have thought of before. AI-generated expressions can help you debug your code faster and more effectively and learn from the suggestions along the way.\nHow to use AI-generated expressions in Visual Studio 2022?\nTo use AI-generated expressions for conditional breakpoints and tracepoints in Visual Studio 2022, you need to have a GitHub account and sign in with GitHub in Visual Studio. You also need to make sure Tools > Options > Debugging > enable AI suggestions for breakpoint expressions” is enabled.\nOnce you have enabled GitHub Copilot, you can start using AI-generated expressions for conditional breakpoints and tracepoints in your C++ code.\n\nYou can also use keyboard shortcuts to navigate and select the suggestions. Use Ctrl+Space to invoke the suggestion list, use the up and down arrow keys to move through the list, and use Enter to select a suggestion.\nTry it and let us know what you think\nWe hope you enjoy using AI-generated expressions for conditional breakpoints and tracepoints in Visual Studio 2022. This feature aims to make debugging your C++ code faster and easier. We’d love your feedback and suggestions for improvement. Please leave a comment below or use the Send Feedback button in Visual Studio.\nLearn more about other Copilot assisted features in Visual Studio by checking out additional resources Debug with GitHub Copilot – Visual Studio (Windows) | Microsoft Learn\nStay connected with the Visual Studio team by following us on Twitter @VS_Debugger, Twitter @VisualStudio, Twitter @VisualC YouTube, and LinkedIn.\nDownload Visual Studio 17.11\n\nThe post Supercharge C++ Debugging with AI-Generated breakpoint expressions appeared first on Visual Studio Blog.",
        "dc:creator": "Harshada Hole",
        "content": "<p>Have you ever spent hours debugging your C++ code, struggling to set up the right conditional breakpoint or tracepoint? Or wished for a smarter way to obtain detailed runtime information without manually crafting complex expressions? You&#8217;re in luck! With Visual Studio 2022, the latest GitHub Copilot feature now offers AI-generated expressions for both conditional breakpoints [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/supercharge-c-debugging-with-ai-generated-breakpoint-expressions/\">Supercharge C++ Debugging with AI-Generated breakpoint expressions</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Have you ever spent hours debugging your C++ code, struggling to set up the right conditional breakpoint or tracepoint? Or wished for a smarter way to obtain detailed runtime information without manually crafting complex expressions? You’re in luck! With Visual Studio 2022, the latest GitHub Copilot feature now offers AI-generated expressions for both conditional breakpoints […]\nThe post Supercharge C++ Debugging with AI-Generated breakpoint expressions appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=250522",
        "categories": [
          "Debug",
          "Productivity",
          "Team and Development",
          "Visual Studio",
          "Breakpoints",
          "Debugging and Diagnostics"
        ],
        "isoDate": "2024-09-09T13:39:25.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "\r\n                            Dropbox Developer Support Team\r\n            \t\t\t",
        "title": "Customizing scopes in the OAuth app authorization flow",
        "link": "https://dropbox.tech/developers/customizing-scopes-in-oauth-flow",
        "pubDate": "Fri, 13 Sep 2024 07:30:00 -0700",
        "content:encodedSnippet": "As you may know, the Dropbox API authorization system uses \"scopes\" for granular control over what functionality an app can access. This allows app developers to select what API functionality their apps can use, so that users can feel more comfortable granting apps access to their accounts. This can help give users peace of mind that the apps will only be able to perform the operations that the apps actually need. It may not be obvious though that you can further customize exactly which scopes your app requests and when. Let's look at the options for configuring and customizing scopes in more detail.\n\nFirst, it's important to note that the scopes you enable on the Permissions tab of the app's page on the App Console define the maximum, as well as the default, set of scopes that the app can request. For example, let's look at a user-linked app. By default, it has the account_info.read scope, which is required to be registered for user-linked apps. We'll also enable files.content.read and files.metadata.read  scopes for this example.\n\r\n\r\n    \r\n        \r\n            \r\n    \r\n\r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n\r\n        \r\n        <!-- <img data-sly-test.highRes=\"false\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/09/customizing-scopes/scopes-config.png 2x,  1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/09/customizing-scopes/scopes-config.png\"\r\n             aria-hidden=\"\"\r\n             alt=\"A screenshot showing the app’s scopes configuration.\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"1075\"\r\n             data-sly-attribute.height=\"654\"\r\n             data-aem-asset-id=\"01375274-d59e-4ee8-8836-8b6157c80c45:scopes-config.png\"\r\n             data-trackable=\"true\" />\r\n        <img data-sly-test.highRes=\"false\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/09/customizing-scopes/scopes-config.png 2x,  1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/09/customizing-scopes/scopes-config.png\"\r\n             aria-hidden=\"\"\r\n             alt=\"\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"1075\"\r\n             data-sly-attribute.height=\"654\"\r\n             data-aem-asset-id=\"01375274-d59e-4ee8-8836-8b6157c80c45:scopes-config.png\"\r\n             data-trackable=\"true\" /> -->\r\n\r\n        \r\n         \r\n        \r\n    \r\n\r\n            \nA screenshot showing the app’s scopes configuration.\n\r\n        \r\n    \r\n\nWhen we send a user to the app authorization page, by default, they'll be prompted to authorize the app with all of those scopes:\nhttps://www.dropbox.com/oauth2/authorize?client_id=&response_type=code\n\r\n\r\n    \r\n        \r\n            \r\n    \r\n\r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n\r\n        \r\n        <!-- <img data-sly-test.highRes=\"false\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/09/customizing-scopes/authorize-default.png 2x,  1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/09/customizing-scopes/authorize-default.png\"\r\n             aria-hidden=\"\"\r\n             alt=\"A screenshot of the app authorization page defaulting to the scopes registered to the app.\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"776\"\r\n             data-sly-attribute.height=\"455\"\r\n             data-aem-asset-id=\"c7a5be91-16a3-4004-b721-c4be66d38a2f:authorize-default.png\"\r\n             data-trackable=\"true\" />\r\n        <img data-sly-test.highRes=\"false\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/09/customizing-scopes/authorize-default.png 2x,  1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/09/customizing-scopes/authorize-default.png\"\r\n             aria-hidden=\"\"\r\n             alt=\"\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"776\"\r\n             data-sly-attribute.height=\"455\"\r\n             data-aem-asset-id=\"c7a5be91-16a3-4004-b721-c4be66d38a2f:authorize-default.png\"\r\n             data-trackable=\"true\" /> -->\r\n\r\n        \r\n         \r\n        \r\n    \r\n\r\n            \nA screenshot of the app authorization page defaulting to the scopes registered to the app.\n\r\n        \r\n    \r\n\nHowever, if you don't need all of the scopes that are currently enabled on the app, you can instead set the scope parameter on the /oauth2/authorize URL you construct. In that parameter, you can put a space-delimited list of scopes to specify just a sub-set of scopes to request for that authorization. This can be useful in scenarios where the app doesn't need all of the app's potential access, or as a way to more gradually gain the user's trust.\nhttps://www.dropbox.com/oauth2/authorize?client_id=&response_type=code&scope=files.metadata.read\n\r\n\r\n    \r\n        \r\n            \r\n    \r\n\r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n\r\n        \r\n        <!-- <img data-sly-test.highRes=\"false\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/09/customizing-scopes/authorize-subset.png 2x,  1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/09/customizing-scopes/authorize-subset.png\"\r\n             aria-hidden=\"\"\r\n             alt=\"A screenshot of the app authorization page requesting a sub-set of the scopes registered to the app.\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"776\"\r\n             data-sly-attribute.height=\"455\"\r\n             data-aem-asset-id=\"dff648aa-f841-43b0-bde1-a88c9c56d94b:authorize-subset.png\"\r\n             data-trackable=\"true\" />\r\n        <img data-sly-test.highRes=\"false\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/09/customizing-scopes/authorize-subset.png 2x,  1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/09/customizing-scopes/authorize-subset.png\"\r\n             aria-hidden=\"\"\r\n             alt=\"\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"776\"\r\n             data-sly-attribute.height=\"455\"\r\n             data-aem-asset-id=\"dff648aa-f841-43b0-bde1-a88c9c56d94b:authorize-subset.png\"\r\n             data-trackable=\"true\" /> -->\r\n\r\n        \r\n         \r\n        \r\n    \r\n\r\n            \nA screenshot of the app authorization page requesting a sub-set of the scopes registered to the app.\n\r\n        \r\n    \r\n\nTip: Note how even though account_info.read is required to be enabled on the app itself, you don't have to request it during authorization. For more privacy-oriented scenarios where the app doesn't need access to the user's account information, you can set the scope parameter without the account_info.read scope as above. \nIf a user authorizes the app using that /oauth2/authorize URL, the app will then receive a payload like the following when it subsequently makes the corresponding call to /oauth2/token using the resulting authorization code:\n\r\n\r\n\r\n\r\n\r\n\n\r\n\r\n\r\n    \r\n        Copy\r\n    \r\n    \n\r\n{\r\n  \"access_token\": \"\",\r\n  \"token_type\": \"bearer\",\r\n  \"expires_in\": 14400,\r\n  \"scope\": \"files.metadata.read\",\r\n  \"uid\": \"\",\r\n  \"account_id\": \"\"\r\n}\n\r\n\r\n\r\n\r\n\n\r\n\n\nIf the app needs additional scopes later, it can prompt the user to authorize the app again, with the scope parameter configured with more scopes, or without the scope parameter set at all, to request all of the app’s scopes.\n\nYou can also use the include_granted_scopes parameter to make it easier to request additional scopes without explicitly listing the previously granted scopes again. For example, if we then additionally want the app to be able to read the content of files in that same user’s account, we would construct another URL like this:\n\nhttps://www.dropbox.com/oauth2/authorize?client_id=&response_type=code&scope=files.content.read&include_granted_scopes=user\n\r\n\r\n    \r\n        \r\n            \r\n    \r\n\r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n\r\n        \r\n        <!-- <img data-sly-test.highRes=\"false\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/09/customizing-scopes/authorize-additional.png 2x,  1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/09/customizing-scopes/authorize-additional.png\"\r\n             aria-hidden=\"\"\r\n             alt=\"A screenshot of the app authorization page requesting additional scopes registered to the app.\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"776\"\r\n             data-sly-attribute.height=\"455\"\r\n             data-aem-asset-id=\"e0f65b7d-dac5-4075-a187-7a56e168ca8d:authorize-additional.png\"\r\n             data-trackable=\"true\" />\r\n        <img data-sly-test.highRes=\"false\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/09/customizing-scopes/authorize-additional.png 2x,  1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/09/customizing-scopes/authorize-additional.png\"\r\n             aria-hidden=\"\"\r\n             alt=\"\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"776\"\r\n             data-sly-attribute.height=\"455\"\r\n             data-aem-asset-id=\"e0f65b7d-dac5-4075-a187-7a56e168ca8d:authorize-additional.png\"\r\n             data-trackable=\"true\" /> -->\r\n\r\n        \r\n         \r\n        \r\n    \r\n\r\n            \nA screenshot of the app authorization page requesting additional scopes registered to the app.\n\r\n        \r\n    \r\n\nIf the user authorizes the app using that /oauth2/authorize URL, the app will then receive a payload like the following when it subsequently makes the corresponding call to /oauth2/token using the resulting authorization code:\n\r\n\r\n\r\n\r\n\r\n\n\r\n\r\n\r\n    \r\n        Copy\r\n    \r\n    \n\r\n{\r\n  \"access_token\": \"\",\r\n  \"token_type\": \"bearer\",\r\n  \"expires_in\": 14400,\r\n  \"scope\": \"files.content.read files.metadata.read\",\r\n  \"uid\": \"\",\r\n  \"account_id\": \"\"\r\n}\n\r\n\r\n\r\n\r\n\n\r\n\n\nNote how this time, the access token has permission to both files.metadata.read as well as files.content.read.\nour \"Using OAuth 2.0 with offline access\" blog post for information on that.\nforum or via our contact form.",
        "dc:creator": "\r\n                            Dropbox Developer Support Team\r\n            \t\t\t",
        "content": "Learn how to configure and customize which scopes your app requests during the Dropbox OAuth 2 app authorization flow.",
        "contentSnippet": "Learn how to configure and customize which scopes your app requests during the Dropbox OAuth 2 app authorization flow.",
        "guid": "https://dropbox.tech/developers/customizing-scopes-in-oauth-flow",
        "categories": [
          "OAuth flow",
          "Authorization",
          "Scopes",
          "Tips and Tricks",
          "Oauth"
        ],
        "isoDate": "2024-09-13T14:30:00.000Z"
      }
    ]
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권영재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김병환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": [
      {
        "creator": "고종범",
        "title": "미뤄두었던 것들의 학습",
        "link": "https://brunch.co.kr/@@24SO/47",
        "pubDate": "Fri, 13 Sep 2024 09:09:27 GMT",
        "author": "고종범",
        "content": "지난주 글을 쓴다는 게 한주가 밀려버렸다. 뻔한 핑계지만 정신없는 일정에 토요일 예외적인 일정이 있다 보니 그렇게 되었다. 그래서 오늘은 쓸 이야기가 많다.  미뤄두었던 것들의 학습 지금 진행하고 있는 일이 조금 여유로워지면서 미뤄두었던 것들의 학습을 수행하고 있다. 매번 이렇게 밀린 학습 할 때 드는 생각은 평소에도 할 수 있으며 왜 몰아서 할까라는 생각<img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2F24SO%2Fimage%2FffEjsDYpieDGycrOAKj0Z2_9Hn4.png\" width=\"500\" />",
        "contentSnippet": "지난주 글을 쓴다는 게 한주가 밀려버렸다. 뻔한 핑계지만 정신없는 일정에 토요일 예외적인 일정이 있다 보니 그렇게 되었다. 그래서 오늘은 쓸 이야기가 많다.  미뤄두었던 것들의 학습 지금 진행하고 있는 일이 조금 여유로워지면서 미뤄두었던 것들의 학습을 수행하고 있다. 매번 이렇게 밀린 학습 할 때 드는 생각은 평소에도 할 수 있으며 왜 몰아서 할까라는 생각",
        "guid": "https://brunch.co.kr/@@24SO/47",
        "isoDate": "2024-09-13T09:09:27.000Z"
      }
    ]
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김상훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "내가 처음이 아니다",
        "link": "https://kangmyounghun.blogspot.com/2024/09/blog-post.html",
        "pubDate": "2024-09-11T04:18:00.002Z",
        "author": "강명훈",
        "content": "<div>하나의 <a href=\"https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html\" target=\"_blank\">로그스태시 파이프라인</a>에서 서로 다른 데이터를 수집, 서로 다른 인덱스에 저장하는 구성에 대한 질문을 받았다. 방법은 input 구간에서 출처별로 수집 플러그인을 분리한 후, output 구간에서 조건에 따라 저장명을 달리하는 것.</div><div>\n<pre><code><div>input {</div><div>&nbsp;file {</div><div>&nbsp; path =&gt; \"a.log\"</div><div>&nbsp;}</div><div><br /></div><div><div>&nbsp;file {</div><div>&nbsp; path =&gt; \"b.log\"</div><div>&nbsp;}</div></div><div>}</div><div><br /></div><div><span><a name='more'></a></span>output {</div><div>&nbsp;if [path] == \"a.log\" {</div><div>&nbsp; elasticsearch {</div><div>&nbsp; &nbsp;index =&gt; \"index_a\"</div><div>&nbsp; }</div><div>&nbsp;} else {</div><div><div>&nbsp; elasticsearch {</div><div>&nbsp; &nbsp;index =&gt; \"index_b\"</div><div>&nbsp; }</div></div><div>&nbsp;}</div><div>}</div></code></pre>\n<div><br /></div><div>데이터 전처리를 잘 하면 분석이 쉬워진다가 강의 주제인지라&nbsp;<a href=\"https://www.elastic.co/guide/en/logstash/current/filter-plugins.html\" target=\"_blank\">filter 구간</a>&nbsp;활용에 집중한다. 자연스럽게 input이나 output 멀티 구성에 대한 필요성을 느낀 적이 없음. 개인의 경험은 한계가 있다. 그래서 타인의 경험이 공유될 때 강의가 재밌어진다.</div><div><br /></div><div>당연히 질문에 대한 답을 처음부터 알지 못했다. 하지만 답을 찾는 게 어렵진 않았다. 모르면 물어보면 되니까.</div><div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwf2tckxDTqxGtOLyhirUiEgQWsZUp5eocJAi1JTrOpsXJw-njHpZu2E2j-hhtf7r7kgfr6j28-maw2jYWOt__b2GdDuKq1Mz6aJzk8QH7gmjkyw-J4kiwnCEiaNHoczAqwlw3dIp2_aaEPiVNzM73drEVCnuRmDrYKXYVrzx1-wjqzWLK6sruJKBCXxvv/s1280/u_r_not_first.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"704\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwf2tckxDTqxGtOLyhirUiEgQWsZUp5eocJAi1JTrOpsXJw-njHpZu2E2j-hhtf7r7kgfr6j28-maw2jYWOt__b2GdDuKq1Mz6aJzk8QH7gmjkyw-J4kiwnCEiaNHoczAqwlw3dIp2_aaEPiVNzM73drEVCnuRmDrYKXYVrzx1-wjqzWLK6sruJKBCXxvv/s520/u_r_not_first.png\" width=\"520\" /></a></div><div><br /></div></div><div>엘라스틱이 나온 지 10년이 넘었고, 그동안 수백만 이상의 사용자들이 엘라스틱을 사용했다. 그중에 나와 같은 목적을 가진 사람이 한 명도 없다면 정말 이상하지 않을까? 하늘 아래 새로운 거 없고, 사람 생각하는 거 크게 다르지 않다.</div><div><br /></div><div>나와 같은 문제로 고민하는 사람이 수 만은 될 것이고, 그중엔 반드시 문제를 해결한 사람이, 그리고 그 해결책을 공유하는 사람이 존재한다. 검색만 잘 하면 된다는 얘기. 이때 원하는 검색 결과를 얻기 위한 조건은 단 하나.</div><div><br /></div><div><b><span style=\"font-size: x-large;\">질문이 뚜렷해야 한다</span></b></div><div><br /></div><div>질문을 명확히 정의할 수 있어야 한다는 얘기. 그게 가능하려면 결국 내가 하고 싶은 게 구체적이어야 한다. 하고 싶은 게 뚜렷하지 않은 상태에서는 뭘 질문해야 할지 알 수도 없고, 설령 질문을 한들 누구도 답을 주기 어렵다. 뭘 원하는지 알기 힘든 질문이니까.</div><div><blockquote style=\"text-align: center;\"><i>목적이 뚜렷하다면 아무리 새롭고 어려운 기술이라도 즐겁게 배움에 임할 수 있으며, 좋은 질문을 할 수 있고, 좋은 답을 구할 수 있다. 설령 좋은 답을 얻지 못하더라도 최소한 그 답에 가까워질 수 있다</i> - <span style=\"font-size: x-small;\">Elasticsearch로 알아보는 이상징후 분석 (249p)</span></blockquote><span style=\"font-size: x-small;\"></span></div><div><br /></div><div>물론 그저 엘라스틱 박사가 되고 싶은 거라면 공식 문서를 모조리 외워버리는 방법도 있다. 하지만 그게 가능하다면 같은 노력을 했을 때 인생이 더 풍요로워지는 다른 분야가 있지 않을까? 결국 툴을 잘 쓰려면 명확한 사용처가 있어야 한다.</div><div><br /></div><div>하고 싶은 게 뚜렷하다면 엘라스틱이나 스플렁크는 배우기 쉽다. 제품 인기도 만큼 커뮤니티가 활발하고, 같은 목적을 위한 삽질 끝에 나보다 먼저 문제를 해결한 선배들이 많기 때문. 그래서 팁이라면 그냥 구글 검색보다 커뮤니티 우선 검색이 구체적인 사례 수집에 유리하다.</div><div><br /></div>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj4K7J0uWByZGBRVH6N_rl4smTJVc9l24kYKty2wqZJ4jzc4z28LwOn6uqFGY6HmpYOyAcO9qqvBeeuoLBKOcIOUHEx3LnqhJG9ZMWHDL5ULsDVzZj9bEVcKqjpMKTOmZFIlTr4mKCJc7jNyc36AfzPinxzVbbwlsdpGdWCub38MuETnhCHcjCzvsmRtswB/s1280/u_r_not_first2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"704\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj4K7J0uWByZGBRVH6N_rl4smTJVc9l24kYKty2wqZJ4jzc4z28LwOn6uqFGY6HmpYOyAcO9qqvBeeuoLBKOcIOUHEx3LnqhJG9ZMWHDL5ULsDVzZj9bEVcKqjpMKTOmZFIlTr4mKCJc7jNyc36AfzPinxzVbbwlsdpGdWCub38MuETnhCHcjCzvsmRtswB/s520/u_r_not_first2.png\" width=\"520\" /></a></div>\n<div><br /></div><div>기억하자. 내가 뭔가 하고 싶은 게 있다면, 나만 하고 싶어 하는 게 아니다. 반드시 먼저 시도한 이들이 있다.</div><div><br /></div><div><b>관련 글</b><br /><ul><li><a href=\"https://kangmyounghun.blogspot.com/2022/01/2nd.html\" target=\"\">엘라스틱이 쉬웠던 이유 - 2nd</a></li></ul></div></div>",
        "contentSnippet": "하나의 로그스태시 파이프라인에서 서로 다른 데이터를 수집, 서로 다른 인덱스에 저장하는 구성에 대한 질문을 받았다. 방법은 input 구간에서 출처별로 수집 플러그인을 분리한 후, output 구간에서 조건에 따라 저장명을 달리하는 것.\n\n\ninput {\n file {\n  path => \"a.log\"\n }\n\n\n file {\n  path => \"b.log\"\n }\n\n}\n\noutput {\n if [path] == \"a.log\" {\n  elasticsearch {\n   index => \"index_a\"\n  }\n } else {\n\n  elasticsearch {\n   index => \"index_b\"\n  }\n\n }\n}\n\n\n데이터 전처리를 잘 하면 분석이 쉬워진다가 강의 주제인지라 filter 구간 활용에 집중한다. 자연스럽게 input이나 output 멀티 구성에 대한 필요성을 느낀 적이 없음. 개인의 경험은 한계가 있다. 그래서 타인의 경험이 공유될 때 강의가 재밌어진다.\n\n\n당연히 질문에 대한 답을 처음부터 알지 못했다. 하지만 답을 찾는 게 어렵진 않았다. 모르면 물어보면 되니까.\n\n\n\n\n\n엘라스틱이 나온 지 10년이 넘었고, 그동안 수백만 이상의 사용자들이 엘라스틱을 사용했다. 그중에 나와 같은 목적을 가진 사람이 한 명도 없다면 정말 이상하지 않을까? 하늘 아래 새로운 거 없고, 사람 생각하는 거 크게 다르지 않다.\n\n\n나와 같은 문제로 고민하는 사람이 수 만은 될 것이고, 그중엔 반드시 문제를 해결한 사람이, 그리고 그 해결책을 공유하는 사람이 존재한다. 검색만 잘 하면 된다는 얘기. 이때 원하는 검색 결과를 얻기 위한 조건은 단 하나.\n\n\n질문이 뚜렷해야 한다\n\n\n질문을 명확히 정의할 수 있어야 한다는 얘기. 그게 가능하려면 결국 내가 하고 싶은 게 구체적이어야 한다. 하고 싶은 게 뚜렷하지 않은 상태에서는 뭘 질문해야 할지 알 수도 없고, 설령 질문을 한들 누구도 답을 주기 어렵다. 뭘 원하는지 알기 힘든 질문이니까.\n\n목적이 뚜렷하다면 아무리 새롭고 어려운 기술이라도 즐겁게 배움에 임할 수 있으며, 좋은 질문을 할 수 있고, 좋은 답을 구할 수 있다. 설령 좋은 답을 얻지 못하더라도 최소한 그 답에 가까워질 수 있다 - Elasticsearch로 알아보는 이상징후 분석 (249p)\n\n\n\n물론 그저 엘라스틱 박사가 되고 싶은 거라면 공식 문서를 모조리 외워버리는 방법도 있다. 하지만 그게 가능하다면 같은 노력을 했을 때 인생이 더 풍요로워지는 다른 분야가 있지 않을까? 결국 툴을 잘 쓰려면 명확한 사용처가 있어야 한다.\n\n\n하고 싶은 게 뚜렷하다면 엘라스틱이나 스플렁크는 배우기 쉽다. 제품 인기도 만큼 커뮤니티가 활발하고, 같은 목적을 위한 삽질 끝에 나보다 먼저 문제를 해결한 선배들이 많기 때문. 그래서 팁이라면 그냥 구글 검색보다 커뮤니티 우선 검색이 구체적인 사례 수집에 유리하다.\n\n\n\n\n기억하자. 내가 뭔가 하고 싶은 게 있다면, 나만 하고 싶어 하는 게 아니다. 반드시 먼저 시도한 이들이 있다.\n\n\n관련 글\n\n엘라스틱이 쉬웠던 이유 - 2nd",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-1623305934797223552",
        "isoDate": "2024-09-11T04:18:00.002Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕홍",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": [
      {
        "creator": "베누시안",
        "title": "한림 웹폰트",
        "link": "http://martian36.tistory.com/1636",
        "pubDate": "Sun, 8 Sep 2024 15:00:16 +0900",
        "author": "베누시안",
        "comments": "http://martian36.tistory.com/1636#entry1636comment",
        "content": "<p data-ke-size=\"size16\">한림대학교의료원에서 제작한 폰트를 기반으로 웹폰트를 만들었습니다. 본래 눈누에 웹폰트가 있으나 레귤러만 있어서 필요에 따라 모든 서체를 웹폰트로 만들었습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"fileblock\" data-ke-align=\"alignCenter\"><a href=\"https://blog.kakaocdn.net/dn/biTlKA/btsJueuoRWS/lvbn6p1dPNt1kJ1KrpXYUk/Hallym2350.zip?attach=1&amp;knm=tfile.zip\" class=\"\">\n    <div class=\"image\"></div>\n    <div class=\"desc\"><div class=\"filename\"><span class=\"name\">Hallym2350.zip</span></div>\n<div class=\"size\">2.27MB</div>\n</div>\n  </a></figure>\n<figure class=\"fileblock\" data-ke-align=\"alignCenter\"><a href=\"https://blog.kakaocdn.net/dn/070Ky/btsJvwgiyAn/inwuYY6c5kWpbnjaFFcVe1/Hallym-All.zip?attach=1&amp;knm=tfile.zip\" class=\"\">\n    <div class=\"image\"></div>\n    <div class=\"desc\"><div class=\"filename\"><span class=\"name\">Hallym-All.zip</span></div>\n<div class=\"size\">4.33MB</div>\n</div>\n  </a></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">Hallym2350은 많이 쓰이는 한글을 2350개만 추가한 것이고 All은 모든 글꼴을 포함했습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">Hallym2350의 파일을 압축해제하고 Html 파일을 열면 아래처럼 글자를 볼 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"009.jpg\" data-origin-width=\"983\" data-origin-height=\"1294\"><span data-url=\"https://blog.kakaocdn.net/dn/cF8ao8/btsJvpOUqyS/jFvRqpSmCJVNepQ2Xzk83k/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cF8ao8/btsJvpOUqyS/jFvRqpSmCJVNepQ2Xzk83k/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cF8ao8/btsJvpOUqyS/jFvRqpSmCJVNepQ2Xzk83k/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcF8ao8%2FbtsJvpOUqyS%2FjFvRqpSmCJVNepQ2Xzk83k%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"009.jpg\" data-origin-width=\"983\" data-origin-height=\"1294\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">All은 아래처러 각종 기호도 포함돼있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"010.jpg\" data-origin-width=\"976\" data-origin-height=\"1289\"><span data-url=\"https://blog.kakaocdn.net/dn/p1l8F/btsJuHXcD2P/J61exvOszVGRHklSkhbkEk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/p1l8F/btsJuHXcD2P/J61exvOszVGRHklSkhbkEk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/p1l8F/btsJuHXcD2P/J61exvOszVGRHklSkhbkEk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fp1l8F%2FbtsJuHXcD2P%2FJ61exvOszVGRHklSkhbkEk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"010.jpg\" data-origin-width=\"976\" data-origin-height=\"1289\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">웹폰트 사용법은 css 파일과 woff 파일 등을 폴더에 넣고 아래처럼 임포트를 해주면 됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">@import&nbsp;url(\"assets/hallym/stylesheet.css\");</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">폰트 굵기에 따라서 아래처럼 폰트 패밀리 이름을 정해주면 됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">.home-top&nbsp;h3&nbsp;{ <br />font-family: 'hallym_mjoregular' !important;<br />font-size:&nbsp;26px; <br />}</p>",
        "contentSnippet": "한림대학교의료원에서 제작한 폰트를 기반으로 웹폰트를 만들었습니다. 본래 눈누에 웹폰트가 있으나 레귤러만 있어서 필요에 따라 모든 서체를 웹폰트로 만들었습니다.\n \n\n    \n\n    \nHallym2350.zip\n2.27MB\n\n\n    \n\n    \nHallym-All.zip\n4.33MB\n\n\n \nHallym2350은 많이 쓰이는 한글을 2350개만 추가한 것이고 All은 모든 글꼴을 포함했습니다.\n \nHallym2350의 파일을 압축해제하고 Html 파일을 열면 아래처럼 글자를 볼 수 있습니다.\n \n\n\n \nAll은 아래처러 각종 기호도 포함돼있습니다.\n \n\n\n \n웹폰트 사용법은 css 파일과 woff 파일 등을 폴더에 넣고 아래처럼 임포트를 해주면 됩니다.\n \n@import url(\"assets/hallym/stylesheet.css\");\n \n폰트 굵기에 따라서 아래처럼 폰트 패밀리 이름을 정해주면 됩니다.\n \n.home-top h3 { \nfont-family: 'hallym_mjoregular' !important;\nfont-size: 26px; \n}",
        "guid": "http://martian36.tistory.com/1636",
        "categories": [
          "폰트/한글폰트"
        ],
        "isoDate": "2024-09-08T06:00:16.000Z"
      },
      {
        "creator": "베누시안",
        "title": "워드프레스에서 갑작스러운 문제 발생의 원인은 플러그인 충돌",
        "link": "http://martian36.tistory.com/1635",
        "pubDate": "Sun, 8 Sep 2024 11:14:11 +0900",
        "author": "베누시안",
        "comments": "http://martian36.tistory.com/1635#entry1635comment",
        "content": "<p data-ke-size=\"size16\">우커머스 쇼핑몰을 개발하다보면 제일 먼저 하는 것이 테마와 모든 플러그인을 설치하고 결제까지 진행해서 테스트 결제를 완료합니다. 그 이후로는 원하는 기능과 디자인을 진행합니다. 기능개선을 위해 별도의 플러그인을 설치하기도 하죠. 이러다보면 기존에 잘 작동하던 기능도 갑자기 안되기도 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"001.jpg\" data-origin-width=\"1527\" data-origin-height=\"978\"><span data-url=\"https://blog.kakaocdn.net/dn/cpJy7Q/btsJu8zNAlc/U5C8kDNqQVqBc9JoVEsDjK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cpJy7Q/btsJu8zNAlc/U5C8kDNqQVqBc9JoVEsDjK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cpJy7Q/btsJu8zNAlc/U5C8kDNqQVqBc9JoVEsDjK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcpJy7Q%2FbtsJu8zNAlc%2FU5C8kDNqQVqBc9JoVEsDjK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"001.jpg\" data-origin-width=\"1527\" data-origin-height=\"978\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">장바구니에 들어가니 위처럼 숏코드가 나타납니다. 원래대로라면 아래처럼 나타나야 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"002.jpg\" data-origin-width=\"1528\" data-origin-height=\"980\"><span data-url=\"https://blog.kakaocdn.net/dn/VeTet/btsJuAjhUwZ/mZLijISfkqAiM5Kxy8R86K/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/VeTet/btsJuAjhUwZ/mZLijISfkqAiM5Kxy8R86K/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/VeTet/btsJuAjhUwZ/mZLijISfkqAiM5Kxy8R86K/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FVeTet%2FbtsJuAjhUwZ%2FmZLijISfkqAiM5Kxy8R86K%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"002.jpg\" data-origin-width=\"1528\" data-origin-height=\"980\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">우커머스 숏코드가 작동하지 않는 것이죠. 다른 숏코드로 그런가 해서 결제페이지로 가도 마찬가지로 작동하지 않습니다. 그래서 아래의 화면으로 가서 각 페이지들이 연결이 잘 돼있나 확인해봅니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"003.jpg\" data-origin-width=\"1112\" data-origin-height=\"746\"><span data-url=\"https://blog.kakaocdn.net/dn/U6mlA/btsJusTmAKK/I8hF0vzNgzG5maUgUt84a0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/U6mlA/btsJusTmAKK/I8hF0vzNgzG5maUgUt84a0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/U6mlA/btsJusTmAKK/I8hF0vzNgzG5maUgUt84a0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FU6mlA%2FbtsJusTmAKK%2FI8hF0vzNgzG5maUgUt84a0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"003.jpg\" data-origin-width=\"1112\" data-origin-height=\"746\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">원래 대로 제대로 돼있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">뭐가 문제일까.. 이런 경우는 처음입니다. 플러그인이 문제일 것이다라고 생각하고 테마를 기본 테마로 변경하고 플러그인을 다섯 개씩 비활성화 해봅니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"004.jpg\" data-origin-width=\"833\" data-origin-height=\"501\"><span data-url=\"https://blog.kakaocdn.net/dn/bhVjwk/btsJv7G2rQP/Avy7SYhAqXcJP4nk9zmrH0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bhVjwk/btsJv7G2rQP/Avy7SYhAqXcJP4nk9zmrH0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bhVjwk/btsJv7G2rQP/Avy7SYhAqXcJP4nk9zmrH0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbhVjwk%2FbtsJv7G2rQP%2FAvy7SYhAqXcJP4nk9zmrH0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"004.jpg\" data-origin-width=\"833\" data-origin-height=\"501\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">문제의 플러그인을 찾았습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>Disable Elements for WPBakery Page Builder</b></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">위 플러그인의 기능은 페이지빌더에 나타나는 각종 엘리먼트(요소)들을 비활성화해서 편집화면을 간단하게 보이도록 할 수 있는 아주 유용한 플러그인입니다. 이것을 사용하지 않으면 아래처럼 엄청나게 많은 요소들이 나타납니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"005.jpg\" data-origin-width=\"2637\" data-origin-height=\"1089\"><span data-url=\"https://blog.kakaocdn.net/dn/c2UOgP/btsJvvn3YA6/TuExidEL3hiNxQILJXna51/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/c2UOgP/btsJvvn3YA6/TuExidEL3hiNxQILJXna51/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/c2UOgP/btsJvvn3YA6/TuExidEL3hiNxQILJXna51/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc2UOgP%2FbtsJvvn3YA6%2FTuExidEL3hiNxQILJXna51%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"005.jpg\" data-origin-width=\"2637\" data-origin-height=\"1089\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">원하는 요소를 찾기도 어렵죠. 자주 사용하거나 필수 요소만 나타나도록 한다면 좋겠죠? 이를 사용하면 아래처럼 간단하게 보입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"006.jpg\" data-origin-width=\"2659\" data-origin-height=\"489\"><span data-url=\"https://blog.kakaocdn.net/dn/Gu5d1/btsJvbDkhbH/F4zfgKJIpSbmKi0SibmNn1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/Gu5d1/btsJvbDkhbH/F4zfgKJIpSbmKi0SibmNn1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/Gu5d1/btsJvbDkhbH/F4zfgKJIpSbmKi0SibmNn1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FGu5d1%2FbtsJvbDkhbH%2FF4zfgKJIpSbmKi0SibmNn1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"006.jpg\" data-origin-width=\"2659\" data-origin-height=\"489\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">원하는 요소를 바로 찾을 수 있죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">뭐가 문제였을까 생각해보니 우커머스 관련 페이지를 만드는 숏코드가 있는 요소가 포함돼지 않았기 때문입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"007.jpg\" data-origin-width=\"1042\" data-origin-height=\"1000\"><span data-url=\"https://blog.kakaocdn.net/dn/b16NEI/btsJuUaMsvo/zhGZtudfmQNH4wwjGKekT1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/b16NEI/btsJuUaMsvo/zhGZtudfmQNH4wwjGKekT1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/b16NEI/btsJuUaMsvo/zhGZtudfmQNH4wwjGKekT1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb16NEI%2FbtsJuUaMsvo%2FzhGZtudfmQNH4wwjGKekT1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"007.jpg\" data-origin-width=\"1042\" data-origin-height=\"1000\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 플러그인의 설정화면으로 가서 해당 숏코드가 있는 요소를 활성화 하니 이제 제대로 보입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"008.jpg\" data-origin-width=\"1506\" data-origin-height=\"1020\"><span data-url=\"https://blog.kakaocdn.net/dn/evWUqO/btsJt0JTos0/TiwKqkfTAt0pivMFdwrUbk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/evWUqO/btsJt0JTos0/TiwKqkfTAt0pivMFdwrUbk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/evWUqO/btsJt0JTos0/TiwKqkfTAt0pivMFdwrUbk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FevWUqO%2FbtsJt0JTos0%2FTiwKqkfTAt0pivMFdwrUbk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"008.jpg\" data-origin-width=\"1506\" data-origin-height=\"1020\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">수많은 사이트를 만들어봤는데도 처음 보는 문제를 접하게 되면 상당히 당황스럽습니다. 설마하던 플러그인에서 문제가 발생할줄이야 꿈에도 생각지 못했지만 항상 그렇듯이 기본은 우선 플러그인을 비활성화 해보는 것이 좋습니다.</p>",
        "contentSnippet": "우커머스 쇼핑몰을 개발하다보면 제일 먼저 하는 것이 테마와 모든 플러그인을 설치하고 결제까지 진행해서 테스트 결제를 완료합니다. 그 이후로는 원하는 기능과 디자인을 진행합니다. 기능개선을 위해 별도의 플러그인을 설치하기도 하죠. 이러다보면 기존에 잘 작동하던 기능도 갑자기 안되기도 합니다.\n \n\n\n \n장바구니에 들어가니 위처럼 숏코드가 나타납니다. 원래대로라면 아래처럼 나타나야 합니다.\n \n\n\n \n우커머스 숏코드가 작동하지 않는 것이죠. 다른 숏코드로 그런가 해서 결제페이지로 가도 마찬가지로 작동하지 않습니다. 그래서 아래의 화면으로 가서 각 페이지들이 연결이 잘 돼있나 확인해봅니다.\n \n\n\n \n원래 대로 제대로 돼있습니다.\n \n뭐가 문제일까.. 이런 경우는 처음입니다. 플러그인이 문제일 것이다라고 생각하고 테마를 기본 테마로 변경하고 플러그인을 다섯 개씩 비활성화 해봅니다.\n \n\n\n \n문제의 플러그인을 찾았습니다.\n \nDisable Elements for WPBakery Page Builder\n \n위 플러그인의 기능은 페이지빌더에 나타나는 각종 엘리먼트(요소)들을 비활성화해서 편집화면을 간단하게 보이도록 할 수 있는 아주 유용한 플러그인입니다. 이것을 사용하지 않으면 아래처럼 엄청나게 많은 요소들이 나타납니다.\n \n\n\n \n원하는 요소를 찾기도 어렵죠. 자주 사용하거나 필수 요소만 나타나도록 한다면 좋겠죠? 이를 사용하면 아래처럼 간단하게 보입니다.\n \n\n\n \n원하는 요소를 바로 찾을 수 있죠.\n \n뭐가 문제였을까 생각해보니 우커머스 관련 페이지를 만드는 숏코드가 있는 요소가 포함돼지 않았기 때문입니다.\n \n\n\n \n이 플러그인의 설정화면으로 가서 해당 숏코드가 있는 요소를 활성화 하니 이제 제대로 보입니다.\n \n\n\n \n수많은 사이트를 만들어봤는데도 처음 보는 문제를 접하게 되면 상당히 당황스럽습니다. 설마하던 플러그인에서 문제가 발생할줄이야 꿈에도 생각지 못했지만 항상 그렇듯이 기본은 우선 플러그인을 비활성화 해보는 것이 좋습니다.",
        "guid": "http://martian36.tistory.com/1635",
        "categories": [
          "워드프레스/플러그인"
        ],
        "isoDate": "2024-09-08T02:14:11.000Z"
      }
    ]
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김놀부",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "아이폰 16 꼭 필요할까?",
        "link": "http://muzbox.tistory.com/483469",
        "pubDate": "Fri, 13 Sep 2024 11:24:19 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483469#entry483469comment",
        "content": "<p data-ke-size=\"size16\">애플이 발표한 최신 아이폰 16, 하지만 많은 사람들이 기존의 아이폰을 교체할 이유를 찾지 못하고 있습니다. 성능, 배터리 수명, 새로운 기능이 부족한 점 등, 아이폰 16 업그레이드가 필요한지 고민하는 모든 이유를 다루어봅니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"611\" data-origin-height=\"650\"><span data-url=\"https://blog.kakaocdn.net/dn/PfZ4S/btsJCnQq4gP/hySpoWXx4jvxifb3yQuNtK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/PfZ4S/btsJCnQq4gP/hySpoWXx4jvxifb3yQuNtK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/PfZ4S/btsJCnQq4gP/hySpoWXx4jvxifb3yQuNtK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FPfZ4S%2FbtsJCnQq4gP%2FhySpoWXx4jvxifb3yQuNtK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"아이폰 16 꼭 필요할까?\" width=\"500\" height=\"532\" data-origin-width=\"611\" data-origin-height=\"650\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;아이폰 16이 출시되었지만, 많은 사용자들은 새로운 모델로의 업그레이드에 대해 회의적인 반응을 보이고 있습니다. 특히, 이미 성능이 뛰어난 아이폰 13 프로 사용자들은 굳이 수백 달러를 더 써가며 새로운 기기로 전환할 필요성을 느끼지 못하고 있습니다. 이 글에서는 아이폰 16 업그레이드가 왜 많은 사람들에게 매력적이지 않은지, 그리고 기존 모델들이 여전히 충분히 강력한 이유를 알아봅니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>1. 아이폰 13 프로의 뛰어난 성능</b></span></h2>\n<p data-ke-size=\"size16\">아이폰 13 프로는 여전히 최고의 성능을 자랑합니다. 출시된 지 3년이 지났음에도 불구하고, 일상적인 사용에서 성능 저하를 거의 느낄 수 없습니다. 물론 아이폰 16의 새 모델과 비교하면 웹페이지 로딩 속도나 고사양 게임의 처리 성능에서 약간의 차이가 있을 수 있지만, 실제 사용에서는 거의 느끼지 못할 정도입니다. 이는 특히 애플의 강력한 A15 바이오닉 칩과 120Hz 프로모션 디스플레이 덕분입니다. 반면, 아이폰 16의 기본 모델은 여전히 60Hz 주사율을 유지하고 있어 120Hz의 부드러운 화면 전환에 익숙해진 사용자들에게는 큰 매력이 없습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>2. 배터리 성능과 지속성</b></span></h2>\n<p data-ke-size=\"size16\">아이폰 13 프로의 배터리 성능도 눈에 띕니다. 3년 간의 헤비한 사용에도 불구하고 배터리 상태는 89%를 유지하고 있습니다. 이는 최적화된 충전 시스템과 최신 배터리 관리 기술 덕분에 가능한 일입니다. 예를 들어, 아이폰 11의 경우 새로운 배터리를 장착한 지 1년 만에 90%로 떨어진 반면, 아이폰 13 프로는 그 이상의 지속성을 보여주고 있습니다. 또한, 기기 외관도 거의 손상이 없으며, 약간의 기스 외에는 큰 문제가 없습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"892\" data-origin-height=\"708\"><span data-url=\"https://blog.kakaocdn.net/dn/bWgFXa/btsJz5dkyYj/rkpEakL04k8sHPAo7NK7U1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bWgFXa/btsJz5dkyYj/rkpEakL04k8sHPAo7NK7U1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bWgFXa/btsJz5dkyYj/rkpEakL04k8sHPAo7NK7U1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbWgFXa%2FbtsJz5dkyYj%2FrkpEakL04k8sHPAo7NK7U1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"아이폰 13, 15, 16 일반 사양 비교\" data-origin-width=\"892\" data-origin-height=\"708\"/></span></figure>\n</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>3. 새로운 기능의 부재</b></span></h2>\n<p data-ke-size=\"size16\">아이폰 16의 새로운 기능들은 기존 사용자들에게 크게 매력적이지 않을 수 있습니다. 이번 모델은 애플의 대규모 언어 모델과 생성형 AI 기능을 포함하지만, 이는 맥북과 같은 고성능 장치에서 더 유용하게 사용할 수 있는 기능입니다. 예를 들어, 서리(Siri)의 향상된 인공지능 기능이나 애플 인텔리전스(Apple Intelligence)는 주로 데스크탑 작업에서 더 자주 활용될 가능성이 높습니다. 따라서 아이폰에서의 이러한 기능 부족은 사용자에게 큰 문제로 다가오지 않을 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>4. 미래를 위한 업그레이드 대기</b></span></h2>\n<p data-ke-size=\"size16\">&nbsp;아이폰 16을 구매하지 않고 기다리는 것이 더 나은 이유도 있습니다. 예를 들어, 2025년에는 아이폰 17 에어와 같은 새로운 모델이 출시될 예정이며, 항상 켜져 있는 120Hz 디스플레이, 화면 아래에 있는 페이스 ID 센서 등 더욱 혁신적인 기능이 탑재될 가능성이 있습니다. 이러한 이유로, 많은 사용자가 현재의 기기를 계속 사용하면서 다음 모델을 기다리는 것이 더 현명한 선택일 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>5. iOS 업데이트와 지속적인 지원</b></span></h2>\n<p data-ke-size=\"size16\">애플은 자사 기기들에 대해 장기간의 소프트웨어 지원을 제공하고 있습니다. 현재 아이폰 XR조차도 iOS 18을 지원하며, 아이폰 13 프로는 2027년까지 소프트웨어 업데이트를 받을 것으로 예상됩니다. 이러한 장기적인 지원 덕분에, 사용자들은 더 오래 기존 기기를 사용할 수 있으며, 소프트웨어 지원이 끝날 때까지 새로운 기능과 보안 패치를 지속적으로 받을 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>결론</b></span></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"710\" data-origin-height=\"487\"><span data-url=\"https://blog.kakaocdn.net/dn/m75vp/btsJA7AZKED/Lyax6W6k55JYQOiJIujLHK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/m75vp/btsJA7AZKED/Lyax6W6k55JYQOiJIujLHK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/m75vp/btsJA7AZKED/Lyax6W6k55JYQOiJIujLHK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fm75vp%2FbtsJA7AZKED%2FLyax6W6k55JYQOiJIujLHK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"아이폰 16 꼭 필요할까?\" data-origin-width=\"710\" data-origin-height=\"487\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">아이폰 16은 분명 매력적인 기능을 갖추고 있지만, 많은 사용자들에게는 충분한 업그레이드 이유가 되지 않습니다. 성능, 배터리 수명, 새로운 기능의 실용성 등을 고려할 때, 기존 아이폰을 사용하는 것이 여전히 충분히 만족스러운 선택이 될 수 있습니다. 다음 모델에 대한 기대감과 현재 기기의 뛰어난 성능은, 지금 당장 아이폰 16으로 업그레이드하지 않는 것이 더 나은 선택임을 보여줍니다.</p>",
        "contentSnippet": "애플이 발표한 최신 아이폰 16, 하지만 많은 사람들이 기존의 아이폰을 교체할 이유를 찾지 못하고 있습니다. 성능, 배터리 수명, 새로운 기능이 부족한 점 등, 아이폰 16 업그레이드가 필요한지 고민하는 모든 이유를 다루어봅니다.\n\n\n \n 아이폰 16이 출시되었지만, 많은 사용자들은 새로운 모델로의 업그레이드에 대해 회의적인 반응을 보이고 있습니다. 특히, 이미 성능이 뛰어난 아이폰 13 프로 사용자들은 굳이 수백 달러를 더 써가며 새로운 기기로 전환할 필요성을 느끼지 못하고 있습니다. 이 글에서는 아이폰 16 업그레이드가 왜 많은 사람들에게 매력적이지 않은지, 그리고 기존 모델들이 여전히 충분히 강력한 이유를 알아봅니다.\n \n \n1. 아이폰 13 프로의 뛰어난 성능\n아이폰 13 프로는 여전히 최고의 성능을 자랑합니다. 출시된 지 3년이 지났음에도 불구하고, 일상적인 사용에서 성능 저하를 거의 느낄 수 없습니다. 물론 아이폰 16의 새 모델과 비교하면 웹페이지 로딩 속도나 고사양 게임의 처리 성능에서 약간의 차이가 있을 수 있지만, 실제 사용에서는 거의 느끼지 못할 정도입니다. 이는 특히 애플의 강력한 A15 바이오닉 칩과 120Hz 프로모션 디스플레이 덕분입니다. 반면, 아이폰 16의 기본 모델은 여전히 60Hz 주사율을 유지하고 있어 120Hz의 부드러운 화면 전환에 익숙해진 사용자들에게는 큰 매력이 없습니다.\n \n \n2. 배터리 성능과 지속성\n아이폰 13 프로의 배터리 성능도 눈에 띕니다. 3년 간의 헤비한 사용에도 불구하고 배터리 상태는 89%를 유지하고 있습니다. 이는 최적화된 충전 시스템과 최신 배터리 관리 기술 덕분에 가능한 일입니다. 예를 들어, 아이폰 11의 경우 새로운 배터리를 장착한 지 1년 만에 90%로 떨어진 반면, 아이폰 13 프로는 그 이상의 지속성을 보여주고 있습니다. 또한, 기기 외관도 거의 손상이 없으며, 약간의 기스 외에는 큰 문제가 없습니다.\n \n\n\n3. 새로운 기능의 부재\n아이폰 16의 새로운 기능들은 기존 사용자들에게 크게 매력적이지 않을 수 있습니다. 이번 모델은 애플의 대규모 언어 모델과 생성형 AI 기능을 포함하지만, 이는 맥북과 같은 고성능 장치에서 더 유용하게 사용할 수 있는 기능입니다. 예를 들어, 서리(Siri)의 향상된 인공지능 기능이나 애플 인텔리전스(Apple Intelligence)는 주로 데스크탑 작업에서 더 자주 활용될 가능성이 높습니다. 따라서 아이폰에서의 이러한 기능 부족은 사용자에게 큰 문제로 다가오지 않을 것입니다.\n \n \n4. 미래를 위한 업그레이드 대기\n 아이폰 16을 구매하지 않고 기다리는 것이 더 나은 이유도 있습니다. 예를 들어, 2025년에는 아이폰 17 에어와 같은 새로운 모델이 출시될 예정이며, 항상 켜져 있는 120Hz 디스플레이, 화면 아래에 있는 페이스 ID 센서 등 더욱 혁신적인 기능이 탑재될 가능성이 있습니다. 이러한 이유로, 많은 사용자가 현재의 기기를 계속 사용하면서 다음 모델을 기다리는 것이 더 현명한 선택일 수 있습니다.\n \n \n5. iOS 업데이트와 지속적인 지원\n애플은 자사 기기들에 대해 장기간의 소프트웨어 지원을 제공하고 있습니다. 현재 아이폰 XR조차도 iOS 18을 지원하며, 아이폰 13 프로는 2027년까지 소프트웨어 업데이트를 받을 것으로 예상됩니다. 이러한 장기적인 지원 덕분에, 사용자들은 더 오래 기존 기기를 사용할 수 있으며, 소프트웨어 지원이 끝날 때까지 새로운 기능과 보안 패치를 지속적으로 받을 수 있습니다.\n \n \n결론\n\n\n아이폰 16은 분명 매력적인 기능을 갖추고 있지만, 많은 사용자들에게는 충분한 업그레이드 이유가 되지 않습니다. 성능, 배터리 수명, 새로운 기능의 실용성 등을 고려할 때, 기존 아이폰을 사용하는 것이 여전히 충분히 만족스러운 선택이 될 수 있습니다. 다음 모델에 대한 기대감과 현재 기기의 뛰어난 성능은, 지금 당장 아이폰 16으로 업그레이드하지 않는 것이 더 나은 선택임을 보여줍니다.",
        "guid": "http://muzbox.tistory.com/483469",
        "categories": [
          "NEWS/IT 뉴스",
          "120Hz 디스플레이",
          "ios 업데이트",
          "배터리 성능",
          "소프트웨어 지원",
          "아이폰 13 프로",
          "아이폰 16 업그레이드",
          "아이폰 17",
          "애플 인텔리전스"
        ],
        "isoDate": "2024-09-13T02:24:19.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "가성비부터 프리미엄까지, 2024년 최고의 무선 이어폰",
        "link": "http://muzbox.tistory.com/483468",
        "pubDate": "Wed, 11 Sep 2024 08:30:01 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483468#entry483468comment",
        "content": "<p data-ke-size=\"size16\">2024년 최고의 무선 이어폰을 소개합니다. Apple AirPods Pro의 뛰어난 소프트웨어 커스터마이징, Bose QC Ultra의 자연스러운 노이즈 캔슬링, Soundcore Liberty 4 NC의 합리적인 가격과 긴 배터리 수명을 비교하여 최적의 선택을 도와드립니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"1231231.png\" data-origin-width=\"2000\" data-origin-height=\"1125\"><span data-url=\"https://blog.kakaocdn.net/dn/3WxRg/btsJxjIJ4kh/16sKPwGqZKaSEDpvzugbA1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/3WxRg/btsJxjIJ4kh/16sKPwGqZKaSEDpvzugbA1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/3WxRg/btsJxjIJ4kh/16sKPwGqZKaSEDpvzugbA1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F3WxRg%2FbtsJxjIJ4kh%2F16sKPwGqZKaSEDpvzugbA1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"가성비부터 프리미엄까지, 2024년 최고의 무선 이어폰\" data-filename=\"1231231.png\" data-origin-width=\"2000\" data-origin-height=\"1125\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">무선 이어폰 시장은 최근 몇 년 사이에 급격한 발전을 이루었습니다. Apple이 iPhone과 함께 제공되던 EarPods의 케이블을 없애면서 무선 이어폰 시장에 큰 변화를 일으켰고, 이후 수많은 브랜드들이 뒤따라 나오기 시작했습니다. 하지만 이렇게 많은 선택지 속에서 자신에게 가장 적합한 무선 이어폰을 찾는 일은 쉽지 않습니다. 이번 기사에서는 다양한 상황에서 최고의 성능을 발휘하는 무선 이어폰들을 추천하며, 각 제품의 장단점을 상세히 분석해보겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>1. Apple AirPods Pro: 최고의 소프트웨어와 놀라운 음질</b></span></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"1a.jpg\" data-origin-width=\"492\" data-origin-height=\"492\"><span data-url=\"https://blog.kakaocdn.net/dn/cnQhOC/btsJwSdX673/PUXuOVyBLAghfDkiynUrWk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cnQhOC/btsJwSdX673/PUXuOVyBLAghfDkiynUrWk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cnQhOC/btsJwSdX673/PUXuOVyBLAghfDkiynUrWk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcnQhOC%2FbtsJwSdX673%2FPUXuOVyBLAghfDkiynUrWk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"1a.jpg\" data-origin-width=\"492\" data-origin-height=\"492\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">Apple AirPods Pro는 여전히 무선 이어폰 시장에서 최고의 선택 중 하나로 꼽힙니다. 특히 Apple 사용자뿐만 아니라 모든 무선 이어폰 사용자에게 적합한 기능을 제공합니다. 이 이어폰의 주요 장점은 뛰어난 소프트웨어 커스터마이징, 탁월한 공간 오디오 기능, 그리고 효과적인 노이즈 캔슬링 기능입니다. Apple은 오디오 연구에 엄청난 투자를 하여 탁월한 적응형 노이즈 캔슬링 기능을 제공하며, 이는 시끄러운 커피숍에서의 잡음이나 HVAC 시스템의 소음을 완벽하게 차단해줍니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">AirPods Pro의 음질도 매우 인상적입니다. Apple의 새로운 Adaptive 및 Spatial Audio 기능 덕분에 주변 환경과 귀 모양에 맞춰 소리를 조정하며, 모든 음악 장르에 적합한 고품질 사운드를 제공합니다. 다만, 배터리 사용 시간은 광고된 30시간보다 약간 짧은 20~25시간 정도로 측정되었습니다. 이는 실제 사용 환경에 따라 다를 수 있지만, 여전히 인상적인 성능입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"1b.jpg\" data-origin-width=\"902\" data-origin-height=\"1125\"><span data-url=\"https://blog.kakaocdn.net/dn/O5oiP/btsJytw66nD/aXenNFeZ9ojCZYkA5kWnv1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/O5oiP/btsJytw66nD/aXenNFeZ9ojCZYkA5kWnv1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/O5oiP/btsJytw66nD/aXenNFeZ9ojCZYkA5kWnv1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FO5oiP%2FbtsJytw66nD%2FaXenNFeZ9ojCZYkA5kWnv1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"1b.jpg\" data-origin-width=\"902\" data-origin-height=\"1125\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b><i>장점:</i></b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>뛰어난 노이즈 캔슬링</li>\n<li>인상적인 적응형 오디오 기능</li>\n<li>견고한 디자인과 마감</li>\n</ul>\n<p data-ke-size=\"size16\"><b><i>단점:</i></b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>배터리 수명이 광고보다 짧음</li>\n<li>높은 가격대</li>\n</ul>\n<div class=\"product-details-button-wrapper\">\n    <style>\n        .product-details-button-wrapper .button-container {\n            display: flex;\n            justify-content: center;\n            align-items: center;\n            padding: 20px 0;\n        }\n        .product-details-button-wrapper .product-details-button {\n            width: 600px;\n            height: 100px;\n            font-family: '맑은 고딕', 'Malgun Gothic', sans-serif;\n            font-weight: bold;\n            font-size: 24px;\n            color: white;\n            background: linear-gradient(145deg, #3498db, #2980b9);\n            border: 4px solid #1f618d;\n            border-radius: 15px;\n            cursor: pointer;\n            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);\n            transition: all 0.3s ease;\n            overflow: hidden;\n            position: relative;\n        }\n        .product-details-button-wrapper .product-details-button:hover {\n            transform: translateY(-3px);\n            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);\n        }\n        .product-details-button-wrapper .button-text {\n            position: relative;\n            z-index: 1;\n            animation: sparkle 1.5s infinite;\n        }\n        @keyframes sparkle {\n            0%, 100% { opacity: 1; }\n            50% { opacity: 0.7; }\n        }\n    </style>\n    <div class=\"button-container\">\n        <button class=\"product-details-button\">\n            <span class=\"button-text\">제품 상세 정보는 여기를 클릭하세요</span>\n        </button>\n    </div>\n    <script>\n        (function() {\n            var wrapper = document.currentScript.closest('.product-details-button-wrapper');\n            var button = wrapper.querySelector('.product-details-button');\n            // URL을 여기에 삽입하세요\n            var productDetailsUrl = \"https://link.coupang.com/a/bRC9ov\";\n            button.addEventListener(\"click\", function() {\n                window.open(productDetailsUrl, '_blank');\n            });\n        })();\n    </script>\n    <p style=\"text-align: center;\" data-ke-size=\"size14\"><span style=\"background-color: #ffffff; color: #0f0f0f; text-align: start;\">&lt;이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.&gt;</span></p>\n</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>2. Bose QC Ultra Earbuds: 자연스러운 노이즈 캔슬링과 맞춤형 사운드</b></span></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"2a.png\" data-origin-width=\"492\" data-origin-height=\"492\"><span data-url=\"https://blog.kakaocdn.net/dn/7PjMk/btsJyGpruSk/OGIk6kd6sAY8eKkE2nUkXK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/7PjMk/btsJyGpruSk/OGIk6kd6sAY8eKkE2nUkXK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/7PjMk/btsJyGpruSk/OGIk6kd6sAY8eKkE2nUkXK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F7PjMk%2FbtsJyGpruSk%2FOGIk6kd6sAY8eKkE2nUkXK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"2a.png\" data-origin-width=\"492\" data-origin-height=\"492\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">Bose QC Ultra 이어버드는 Bose의 특유의 자연스럽고 효과적인 노이즈 캔슬링 기능으로 주목받습니다. 이 이어폰은 특히 기차역, 시끄러운 거리, 그리고 야간 사용 등 다양한 상황에서 사용해도 음악의 질을 유지하면서 주변 소음을 잘 차단해줍니다. Bose Music 앱을 통해 소리를 사용자 취향에 맞게 조정할 수 있는 기능도 제공합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">다만, 배터리 수명은 이어버드 자체로는 약 6시간, 케이스를 사용할 경우 추가 10~12시간 정도로 다소 제한적입니다. 하지만 저렴한 가격과 인상적인 사운드 품질 덕분에 여전히 많은 소비자들에게 매력적인 선택지입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"2b.jpg\" data-origin-width=\"737\" data-origin-height=\"856\"><span data-url=\"https://blog.kakaocdn.net/dn/szUC0/btsJwPheSp8/JtKgjKNIxL926zZxXCBVMK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/szUC0/btsJwPheSp8/JtKgjKNIxL926zZxXCBVMK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/szUC0/btsJwPheSp8/JtKgjKNIxL926zZxXCBVMK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FszUC0%2FbtsJwPheSp8%2FJtKgjKNIxL926zZxXCBVMK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"2b.jpg\" data-origin-width=\"737\" data-origin-height=\"856\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b><i>장점:</i></b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>탁월하고 자연스러운 노이즈 캔슬링</li>\n<li>견고한 소리 품질과 맞춤화 가능</li>\n<li>아름다운 디자인과 착용감</li>\n</ul>\n<p data-ke-size=\"size16\"><b><i>단점:</i></b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>케이스와 함께 사용 시 배터리 수명이 제한적</li>\n<li>블루투스 연결 문제 발생 가능성</li>\n</ul>\n<div class=\"product-details-button-wrapper\">\n    <style>\n        .product-details-button-wrapper .button-container {\n            display: flex;\n            justify-content: center;\n            align-items: center;\n            padding: 20px 0;\n        }\n        .product-details-button-wrapper .product-details-button {\n            width: 600px;\n            height: 100px;\n            font-family: '맑은 고딕', 'Malgun Gothic', sans-serif;\n            font-weight: bold;\n            font-size: 24px;\n            color: white;\n            background: linear-gradient(145deg, #3498db, #2980b9);\n            border: 4px solid #1f618d;\n            border-radius: 15px;\n            cursor: pointer;\n            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);\n            transition: all 0.3s ease;\n            overflow: hidden;\n            position: relative;\n        }\n        .product-details-button-wrapper .product-details-button:hover {\n            transform: translateY(-3px);\n            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);\n        }\n        .product-details-button-wrapper .button-text {\n            position: relative;\n            z-index: 1;\n            animation: sparkle 1.5s infinite;\n        }\n        @keyframes sparkle {\n            0%, 100% { opacity: 1; }\n            50% { opacity: 0.7; }\n        }\n    </style>\n    <div class=\"button-container\">\n        <button class=\"product-details-button\">\n            <span class=\"button-text\">제품 상세 정보는 여기를 클릭하세요</span>\n        </button>\n    </div>\n    <script>\n        (function() {\n            var wrapper = document.currentScript.closest('.product-details-button-wrapper');\n            var button = wrapper.querySelector('.product-details-button');\n            // URL을 여기에 삽입하세요\n            var productDetailsUrl = \"https://link.coupang.com/a/bRC9K8\";\n            button.addEventListener(\"click\", function() {\n                window.open(productDetailsUrl, '_blank');\n            });\n        })();\n    </script>\n    <p style=\"text-align: center;\" data-ke-size=\"size14\"><span style=\"background-color: #ffffff; color: #0f0f0f; text-align: start;\">&lt;이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.&gt;</span></p>\n</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>3. Soundcore Liberty 4 NC: 가격 대비 높은 성능과 긴 배터리 수명</b></span></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"3a.jpg\" data-origin-width=\"492\" data-origin-height=\"492\"><span data-url=\"https://blog.kakaocdn.net/dn/3UqPZ/btsJxw829MQ/K9EQuIcnTwtj3Ah956OWqK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/3UqPZ/btsJxw829MQ/K9EQuIcnTwtj3Ah956OWqK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/3UqPZ/btsJxw829MQ/K9EQuIcnTwtj3Ah956OWqK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F3UqPZ%2FbtsJxw829MQ%2FK9EQuIcnTwtj3Ah956OWqK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"3a.jpg\" data-origin-width=\"492\" data-origin-height=\"492\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">Soundcore Liberty 4 NC는 합리적인 가격에 고성능의 무선 이어폰을 제공하여 가성비를 중요시하는 소비자들에게 좋은 선택입니다. 이 제품은 최대 50시간의 배터리 수명을 제공하며, 한번 충전으로 최대 10시간 사용이 가능합니다. 디자인도 독특하여 이어폰을 꺼내고 넣는 동작이 편리하게 설계되어 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">사운드 품질 측면에서는 가격 대비 매우 우수하지만, Apple이나 Bose의 고급 제품보다는 약간 부족할 수 있습니다. 플라스틱 소재를 사용하여 무게를 줄인 점은 장점이지만, 프리미엄 느낌이 부족할 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"3b.jpg\" data-origin-width=\"772\" data-origin-height=\"771\"><span data-url=\"https://blog.kakaocdn.net/dn/c08lkR/btsJwSkIvAR/doKHe0E1elbk1tIXindrF0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/c08lkR/btsJwSkIvAR/doKHe0E1elbk1tIXindrF0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/c08lkR/btsJwSkIvAR/doKHe0E1elbk1tIXindrF0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc08lkR%2FbtsJwSkIvAR%2FdoKHe0E1elbk1tIXindrF0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"3b.jpg\" data-origin-width=\"772\" data-origin-height=\"771\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b><i>장점:</i></b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>뛰어난 가성비</li>\n<li>긴 배터리 수명</li>\n<li>재미있는 디자인과 다양한 색상</li>\n</ul>\n<p data-ke-size=\"size16\"><b><i>단점:</i></b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>음질이 Apple이나 Bose 제품보다 다소 떨어짐</li>\n<li>플라스틱 소재 사용으로 프리미엄 느낌이 부족</li>\n</ul>\n<div class=\"product-details-button-wrapper\">\n    <style>\n        .product-details-button-wrapper .button-container {\n            display: flex;\n            justify-content: center;\n            align-items: center;\n            padding: 20px 0;\n        }\n        .product-details-button-wrapper .product-details-button {\n            width: 600px;\n            height: 100px;\n            font-family: '맑은 고딕', 'Malgun Gothic', sans-serif;\n            font-weight: bold;\n            font-size: 24px;\n            color: white;\n            background: linear-gradient(145deg, #3498db, #2980b9);\n            border: 4px solid #1f618d;\n            border-radius: 15px;\n            cursor: pointer;\n            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);\n            transition: all 0.3s ease;\n            overflow: hidden;\n            position: relative;\n        }\n        .product-details-button-wrapper .product-details-button:hover {\n            transform: translateY(-3px);\n            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);\n        }\n        .product-details-button-wrapper .button-text {\n            position: relative;\n            z-index: 1;\n            animation: sparkle 1.5s infinite;\n        }\n        @keyframes sparkle {\n            0%, 100% { opacity: 1; }\n            50% { opacity: 0.7; }\n        }\n    </style>\n    <div class=\"button-container\">\n        <button class=\"product-details-button\">\n            <span class=\"button-text\">제품 상세 정보는 여기를 클릭하세요</span>\n        </button>\n    </div>\n    <script>\n        (function() {\n            var wrapper = document.currentScript.closest('.product-details-button-wrapper');\n            var button = wrapper.querySelector('.product-details-button');\n            // URL을 여기에 삽입하세요\n            var productDetailsUrl = \"https://link.coupang.com/a/bRC9YC\";\n            button.addEventListener(\"click\", function() {\n                window.open(productDetailsUrl, '_blank');\n            });\n        })();\n    </script>\n    <p style=\"text-align: center;\" data-ke-size=\"size14\"><span style=\"background-color: #ffffff; color: #0f0f0f; text-align: start;\">&lt;이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.&gt;</span></p>\n</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>결론</b></span></h2>\n<p data-ke-size=\"size16\">무선 이어폰을 선택할 때는 사용자의 필요와 예산에 맞춰 다양한 옵션을 고려해야 합니다. Apple AirPods Pro는 최고급 성능과 기능을 자랑하며, Bose QC Ultra Earbuds는 자연스러운 노이즈 캔슬링과 뛰어난 사운드 품질을 제공합니다. Soundcore Liberty 4 NC는 가성비를 중시하는 소비자에게 적합한 제품입니다. 각 제품의 장단점을 잘 비교해보시고, 자신에게 가장 잘 맞는 무선 이어폰을 선택하시기 바랍니다.</p>\n<div id=\"gtx-trans\" style=\"position: absolute; left: -64px; top: 6781.2px;\">\n<div class=\"gtx-trans-icon\">&nbsp;</div>\n</div>",
        "contentSnippet": "2024년 최고의 무선 이어폰을 소개합니다. Apple AirPods Pro의 뛰어난 소프트웨어 커스터마이징, Bose QC Ultra의 자연스러운 노이즈 캔슬링, Soundcore Liberty 4 NC의 합리적인 가격과 긴 배터리 수명을 비교하여 최적의 선택을 도와드립니다.\n\n\n \n무선 이어폰 시장은 최근 몇 년 사이에 급격한 발전을 이루었습니다. Apple이 iPhone과 함께 제공되던 EarPods의 케이블을 없애면서 무선 이어폰 시장에 큰 변화를 일으켰고, 이후 수많은 브랜드들이 뒤따라 나오기 시작했습니다. 하지만 이렇게 많은 선택지 속에서 자신에게 가장 적합한 무선 이어폰을 찾는 일은 쉽지 않습니다. 이번 기사에서는 다양한 상황에서 최고의 성능을 발휘하는 무선 이어폰들을 추천하며, 각 제품의 장단점을 상세히 분석해보겠습니다.\n \n \n1. Apple AirPods Pro: 최고의 소프트웨어와 놀라운 음질\n\n\nApple AirPods Pro는 여전히 무선 이어폰 시장에서 최고의 선택 중 하나로 꼽힙니다. 특히 Apple 사용자뿐만 아니라 모든 무선 이어폰 사용자에게 적합한 기능을 제공합니다. 이 이어폰의 주요 장점은 뛰어난 소프트웨어 커스터마이징, 탁월한 공간 오디오 기능, 그리고 효과적인 노이즈 캔슬링 기능입니다. Apple은 오디오 연구에 엄청난 투자를 하여 탁월한 적응형 노이즈 캔슬링 기능을 제공하며, 이는 시끄러운 커피숍에서의 잡음이나 HVAC 시스템의 소음을 완벽하게 차단해줍니다.\n \nAirPods Pro의 음질도 매우 인상적입니다. Apple의 새로운 Adaptive 및 Spatial Audio 기능 덕분에 주변 환경과 귀 모양에 맞춰 소리를 조정하며, 모든 음악 장르에 적합한 고품질 사운드를 제공합니다. 다만, 배터리 사용 시간은 광고된 30시간보다 약간 짧은 20~25시간 정도로 측정되었습니다. 이는 실제 사용 환경에 따라 다를 수 있지만, 여전히 인상적인 성능입니다.\n\n\n \n장점:\n뛰어난 노이즈 캔슬링\n인상적인 적응형 오디오 기능\n견고한 디자인과 마감\n단점:\n배터리 수명이 광고보다 짧음\n높은 가격대\n제품 상세 정보는 여기를 클릭하세요\n        \n    \n<이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.>\n \n \n2. Bose QC Ultra Earbuds: 자연스러운 노이즈 캔슬링과 맞춤형 사운드\n\n\nBose QC Ultra 이어버드는 Bose의 특유의 자연스럽고 효과적인 노이즈 캔슬링 기능으로 주목받습니다. 이 이어폰은 특히 기차역, 시끄러운 거리, 그리고 야간 사용 등 다양한 상황에서 사용해도 음악의 질을 유지하면서 주변 소음을 잘 차단해줍니다. Bose Music 앱을 통해 소리를 사용자 취향에 맞게 조정할 수 있는 기능도 제공합니다.\n \n다만, 배터리 수명은 이어버드 자체로는 약 6시간, 케이스를 사용할 경우 추가 10~12시간 정도로 다소 제한적입니다. 하지만 저렴한 가격과 인상적인 사운드 품질 덕분에 여전히 많은 소비자들에게 매력적인 선택지입니다.\n\n\n \n장점:\n탁월하고 자연스러운 노이즈 캔슬링\n견고한 소리 품질과 맞춤화 가능\n아름다운 디자인과 착용감\n단점:\n케이스와 함께 사용 시 배터리 수명이 제한적\n블루투스 연결 문제 발생 가능성\n제품 상세 정보는 여기를 클릭하세요\n        \n    \n<이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.>\n \n \n3. Soundcore Liberty 4 NC: 가격 대비 높은 성능과 긴 배터리 수명\n\n\nSoundcore Liberty 4 NC는 합리적인 가격에 고성능의 무선 이어폰을 제공하여 가성비를 중요시하는 소비자들에게 좋은 선택입니다. 이 제품은 최대 50시간의 배터리 수명을 제공하며, 한번 충전으로 최대 10시간 사용이 가능합니다. 디자인도 독특하여 이어폰을 꺼내고 넣는 동작이 편리하게 설계되어 있습니다.\n \n사운드 품질 측면에서는 가격 대비 매우 우수하지만, Apple이나 Bose의 고급 제품보다는 약간 부족할 수 있습니다. 플라스틱 소재를 사용하여 무게를 줄인 점은 장점이지만, 프리미엄 느낌이 부족할 수 있습니다.\n\n\n \n장점:\n뛰어난 가성비\n긴 배터리 수명\n재미있는 디자인과 다양한 색상\n단점:\n음질이 Apple이나 Bose 제품보다 다소 떨어짐\n플라스틱 소재 사용으로 프리미엄 느낌이 부족\n제품 상세 정보는 여기를 클릭하세요\n        \n    \n<이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.>\n \n \n결론\n무선 이어폰을 선택할 때는 사용자의 필요와 예산에 맞춰 다양한 옵션을 고려해야 합니다. Apple AirPods Pro는 최고급 성능과 기능을 자랑하며, Bose QC Ultra Earbuds는 자연스러운 노이즈 캔슬링과 뛰어난 사운드 품질을 제공합니다. Soundcore Liberty 4 NC는 가성비를 중시하는 소비자에게 적합한 제품입니다. 각 제품의 장단점을 잘 비교해보시고, 자신에게 가장 잘 맞는 무선 이어폰을 선택하시기 바랍니다.",
        "guid": "http://muzbox.tistory.com/483468",
        "categories": [
          "신제품 리뷰/주변기기",
          "2024 최고의 이어폰",
          "Apple AirPods Pro",
          "bose qc ultra",
          "soundcore liberty 4 nc",
          "가성비 좋은 이어폰",
          "고품질 음향 기기",
          "노이즈 캔슬링 이어폰",
          "무선 이어폰",
          "블루투스 이어폰"
        ],
        "isoDate": "2024-09-10T23:30:01.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "인텔 코어 i5 vs AMD 라이젠 5, 어떤 CPU가 더 나을까?",
        "link": "http://muzbox.tistory.com/483467",
        "pubDate": "Mon, 9 Sep 2024 09:12:09 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483467#entry483467comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;AMD의 라이젠 5와 인텔의 코어 i5는 오늘날 가장 인기 있는 미드레인지 CPU입니다. 이 두 제품 중 어떤 것을 선택해야 할지 고민되시나요? 각 프로세서의 성능, 아키텍처, 전력 소비량, 가격 등의 요소를 비교하여 어느 제품이 더 나은 선택인지 알아보세요.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"cpu compare.jpg\" data-origin-width=\"747\" data-origin-height=\"747\"><span data-url=\"https://blog.kakaocdn.net/dn/bFQLkn/btsJvoWYkZM/ljTqlxUWFagdzteKbSXXWK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bFQLkn/btsJvoWYkZM/ljTqlxUWFagdzteKbSXXWK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bFQLkn/btsJvoWYkZM/ljTqlxUWFagdzteKbSXXWK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbFQLkn%2FbtsJvoWYkZM%2FljTqlxUWFagdzteKbSXXWK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"인텔 코어 i5 vs AMD 라이젠 5, 어떤 CPU가 더 나을까?\" width=\"500\" height=\"500\" data-filename=\"cpu compare.jpg\" data-origin-width=\"747\" data-origin-height=\"747\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;CPU는 컴퓨터 성능의 핵심 요소 중 하나로, 올바른 선택은 사용자 경험에 큰 영향을 미칩니다. 미드레인지 CPU의 대표적인 두 경쟁자인 인텔 코어 i5와 AMD 라이젠 5는 모두 게이머와 전문가들에게 매우 인기 있는 옵션입니다. 그러나 이 두 제품 간의 차이점과 각 프로세서가 제공하는 가치를 명확히 이해해야 합니다. 이 블로그에서는 인텔 코어 i5와 AMD 라이젠 5를 다양한 측면에서 비교하여 어떤 CPU가 여러분에게 더 적합한지에 대해 알아봅니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>인텔 코어 i5와 AMD 라이젠 5의 기본 비교</b></span></h2>\n<p data-ke-size=\"size16\"><span style=\"color: #ee2323;\"><b>인텔 코어 i5의 특장점</b></span><br />인텔 코어 i5는 2009년에 처음 출시되었으며, 성능과 효율성 사이에서 뛰어난 균형을 제공합니다. 이 CPU는 하이브리드 아키텍처를 사용하여 성능 지향적인 코어(P-코어)와 에너지 효율이 높은 코어(E-코어)를 결합하여 리소스 사용을 최적화합니다. 코어 i5는 싱글 코어 성능에서 AMD 라이젠 5보다 약간 앞서지만, 멀티코어 성능에서는 라이젠 5에 뒤처지는 경향이 있습니다. 이 프로세서는 하이퍼스레딩을 지원하여 각 물리적 코어가 두 개의 스레드를 동시에 처리할 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"color: #ee2323;\"><b>AMD 라이젠 5의 특장점</b></span><br />AMD 라이젠 5는 2017년에 출시된 이후 뛰어난 멀티스레딩 성능과 경쟁력 있는 가격으로 주목받고 있습니다. Zen 아키텍처를 기반으로 하는 이 프로세서는 보통 인텔보다 더 많은 코어 수와 빠른 클럭 속도를 제공합니다. 최신 Zen 5 아키텍처는 16%의 성능 향상과 전력 소비의 큰 감소를 가져왔습니다. 그러나 인텔 코어 i5와 달리, 라이젠 5는 통합 그래픽이 없기 때문에 별도의 GPU가 필요합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b><span style=\"color: #006dd7;\">인텔 코어 i5 vs AMD 라이젠 5: 성능 비교</span></b></h2>\n<p data-ke-size=\"size16\"><span style=\"color: #ee2323;\"><b>입문형: 코어 i5-12600K vs 라이젠 5 5600X</b></span><br />이 두 CPU는 예산에 민감한 빌드를 위해 적합하며 일상적인 작업과 가벼운 게임을 처리할 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"코어 i5-12600K vs 라이젠 5 5600X.png\" data-origin-width=\"844\" data-origin-height=\"639\"><span data-url=\"https://blog.kakaocdn.net/dn/bjWa1b/btsJwaYjxpT/H2ZedVipUbc1PqknEjj2k1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bjWa1b/btsJwaYjxpT/H2ZedVipUbc1PqknEjj2k1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bjWa1b/btsJwaYjxpT/H2ZedVipUbc1PqknEjj2k1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbjWa1b%2FbtsJwaYjxpT%2FH2ZedVipUbc1PqknEjj2k1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"코어 i5-12600K vs 라이젠 5 5600X.png\" data-origin-width=\"844\" data-origin-height=\"639\"/></span></figure>\n</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>아키텍처 및 코어 수</b>: 코어 i5-12600K는 6개의 성능 코어와 4개의 효율 코어로 구성된 10개의 코어와 16개의 스레드를 제공합니다. 반면에 AMD 라이젠 5 5600X는 6개의 코어와 12개의 스레드를 가지고 있습니다.</li>\n<li><b>클럭 속도</b>: 코어 i5-12600K는 최대 4.9GHz까지 부스트가 가능하며, 라이젠 5 5600X는 최대 4.6GHz입니다.</li>\n<li><b>캐시 및 메모리 타입</b>: 코어 i5-12600K는 20MB의 스마트 캐시를 제공하는 반면, 라이젠 5 5600X는 32MB의 L3 캐시를 갖추고 있습니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"color: #ee2323;\"><b>중급형: 코어 i5-13600K vs 라이젠 5 7600X</b></span><br />중급형 프로세서로, 고사양 게임이나 비디오 편집과 같은 보다 높은 요구 사항을 처리할 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"코어 i5-13600K vs 라이젠 5 7600X.png\" data-origin-width=\"843\" data-origin-height=\"640\"><span data-url=\"https://blog.kakaocdn.net/dn/cluU5t/btsJwcPhwux/ZiHdPJPGJU4xd7bePOVvM0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cluU5t/btsJwcPhwux/ZiHdPJPGJU4xd7bePOVvM0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cluU5t/btsJwcPhwux/ZiHdPJPGJU4xd7bePOVvM0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcluU5t%2FbtsJwcPhwux%2FZiHdPJPGJU4xd7bePOVvM0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"코어 i5-13600K vs 라이젠 5 7600X.png\" data-origin-width=\"843\" data-origin-height=\"640\"/></span></figure>\n</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>아키텍처 및 코어 수</b>: 코어 i5-13600K는 14개의 코어(6개의 성능 + 8개의 효율 코어)와 20개의 스레드를 제공하며, 라이젠 5 7600X는 6개의 코어와 12개의 스레드를 가지고 있습니다.</li>\n<li><b>전력 소비</b>: 라이젠 5 7600X는 105W의 낮은 전력 소비를 자랑하며, 코어 i5-13600K는 125W입니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"color: #ee2323;\"><b>고급형: 코어 i5-14600K vs 라이젠 5 9600X</b></span><br />이 프로세서들은 고사양 작업을 처리하기에 적합합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"코어 i5-14600K vs 라이젠 5 9600X.png\" data-origin-width=\"842\" data-origin-height=\"642\"><span data-url=\"https://blog.kakaocdn.net/dn/outBD/btsJvRR86VD/NkdXejqJVWlnjTOoZoUk11/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/outBD/btsJvRR86VD/NkdXejqJVWlnjTOoZoUk11/img.png\"><img src=\"https://blog.kakaocdn.net/dn/outBD/btsJvRR86VD/NkdXejqJVWlnjTOoZoUk11/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FoutBD%2FbtsJvRR86VD%2FNkdXejqJVWlnjTOoZoUk11%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"코어 i5-14600K vs 라이젠 5 9600X.png\" data-origin-width=\"842\" data-origin-height=\"642\"/></span></figure>\n</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>아키텍처 및 코어 수</b>: 라이젠 5 9600X는 6개의 코어와 12개의 스레드를 제공하며, 코어 i5-14600K는 14개의 코어(6개의 성능 코어와 8개의 효율 코어)와 20개의 스레드를 갖추고 있습니다.</li>\n<li><b>성능 및 가격 비교</b>: 코어 i5-14600K는 $350의 가격으로 라이젠 5 9600X의 $279보다 비싸지만, 더 나은 종합 성능을 제공합니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>결론: 어떤 CPU를 선택해야 할까요?</b></span></h2>\n<p data-ke-size=\"size16\">결국, 인텔 코어 i5와 AMD 라이젠 5는 각각 다른 시장을 겨냥하고 있습니다. 라이젠 5는 높은 클럭 속도와 더 낮은 TDP를 제공하며, 코어 i5는 전반적인 성능에서 더 높은 점수를 받습니다. 게이머와 콘텐츠 제작자는 싱글 코어 성능이 뛰어난 코어 i5를 선호할 수 있으며, 멀티태스킹과 에너지 효율성을 중요시하는 사용자는 라이젠 5를 선택할 가능성이 큽니다. 최종 선택은 예산과 용도에 따라 달라집니다.</p>",
        "contentSnippet": "AMD의 라이젠 5와 인텔의 코어 i5는 오늘날 가장 인기 있는 미드레인지 CPU입니다. 이 두 제품 중 어떤 것을 선택해야 할지 고민되시나요? 각 프로세서의 성능, 아키텍처, 전력 소비량, 가격 등의 요소를 비교하여 어느 제품이 더 나은 선택인지 알아보세요.\n\n\n \n CPU는 컴퓨터 성능의 핵심 요소 중 하나로, 올바른 선택은 사용자 경험에 큰 영향을 미칩니다. 미드레인지 CPU의 대표적인 두 경쟁자인 인텔 코어 i5와 AMD 라이젠 5는 모두 게이머와 전문가들에게 매우 인기 있는 옵션입니다. 그러나 이 두 제품 간의 차이점과 각 프로세서가 제공하는 가치를 명확히 이해해야 합니다. 이 블로그에서는 인텔 코어 i5와 AMD 라이젠 5를 다양한 측면에서 비교하여 어떤 CPU가 여러분에게 더 적합한지에 대해 알아봅니다.\n \n \n \n인텔 코어 i5와 AMD 라이젠 5의 기본 비교\n인텔 코어 i5의 특장점\n인텔 코어 i5는 2009년에 처음 출시되었으며, 성능과 효율성 사이에서 뛰어난 균형을 제공합니다. 이 CPU는 하이브리드 아키텍처를 사용하여 성능 지향적인 코어(P-코어)와 에너지 효율이 높은 코어(E-코어)를 결합하여 리소스 사용을 최적화합니다. 코어 i5는 싱글 코어 성능에서 AMD 라이젠 5보다 약간 앞서지만, 멀티코어 성능에서는 라이젠 5에 뒤처지는 경향이 있습니다. 이 프로세서는 하이퍼스레딩을 지원하여 각 물리적 코어가 두 개의 스레드를 동시에 처리할 수 있습니다.\n \nAMD 라이젠 5의 특장점\nAMD 라이젠 5는 2017년에 출시된 이후 뛰어난 멀티스레딩 성능과 경쟁력 있는 가격으로 주목받고 있습니다. Zen 아키텍처를 기반으로 하는 이 프로세서는 보통 인텔보다 더 많은 코어 수와 빠른 클럭 속도를 제공합니다. 최신 Zen 5 아키텍처는 16%의 성능 향상과 전력 소비의 큰 감소를 가져왔습니다. 그러나 인텔 코어 i5와 달리, 라이젠 5는 통합 그래픽이 없기 때문에 별도의 GPU가 필요합니다.\n \n \n인텔 코어 i5 vs AMD 라이젠 5: 성능 비교\n입문형: 코어 i5-12600K vs 라이젠 5 5600X\n이 두 CPU는 예산에 민감한 빌드를 위해 적합하며 일상적인 작업과 가벼운 게임을 처리할 수 있습니다.\n\n\n\n아키텍처 및 코어 수: 코어 i5-12600K는 6개의 성능 코어와 4개의 효율 코어로 구성된 10개의 코어와 16개의 스레드를 제공합니다. 반면에 AMD 라이젠 5 5600X는 6개의 코어와 12개의 스레드를 가지고 있습니다.\n클럭 속도: 코어 i5-12600K는 최대 4.9GHz까지 부스트가 가능하며, 라이젠 5 5600X는 최대 4.6GHz입니다.\n캐시 및 메모리 타입: 코어 i5-12600K는 20MB의 스마트 캐시를 제공하는 반면, 라이젠 5 5600X는 32MB의 L3 캐시를 갖추고 있습니다.\n \n중급형: 코어 i5-13600K vs 라이젠 5 7600X\n중급형 프로세서로, 고사양 게임이나 비디오 편집과 같은 보다 높은 요구 사항을 처리할 수 있습니다.\n\n\n\n아키텍처 및 코어 수: 코어 i5-13600K는 14개의 코어(6개의 성능 + 8개의 효율 코어)와 20개의 스레드를 제공하며, 라이젠 5 7600X는 6개의 코어와 12개의 스레드를 가지고 있습니다.\n전력 소비: 라이젠 5 7600X는 105W의 낮은 전력 소비를 자랑하며, 코어 i5-13600K는 125W입니다.\n \n고급형: 코어 i5-14600K vs 라이젠 5 9600X\n이 프로세서들은 고사양 작업을 처리하기에 적합합니다.\n\n\n\n아키텍처 및 코어 수: 라이젠 5 9600X는 6개의 코어와 12개의 스레드를 제공하며, 코어 i5-14600K는 14개의 코어(6개의 성능 코어와 8개의 효율 코어)와 20개의 스레드를 갖추고 있습니다.\n성능 및 가격 비교: 코어 i5-14600K는 $350의 가격으로 라이젠 5 9600X의 $279보다 비싸지만, 더 나은 종합 성능을 제공합니다.\n \n결론: 어떤 CPU를 선택해야 할까요?\n결국, 인텔 코어 i5와 AMD 라이젠 5는 각각 다른 시장을 겨냥하고 있습니다. 라이젠 5는 높은 클럭 속도와 더 낮은 TDP를 제공하며, 코어 i5는 전반적인 성능에서 더 높은 점수를 받습니다. 게이머와 콘텐츠 제작자는 싱글 코어 성능이 뛰어난 코어 i5를 선호할 수 있으며, 멀티태스킹과 에너지 효율성을 중요시하는 사용자는 라이젠 5를 선택할 가능성이 큽니다. 최종 선택은 예산과 용도에 따라 달라집니다.",
        "guid": "http://muzbox.tistory.com/483467",
        "categories": [
          "윈도우 사용팁/하드웨어",
          "amd 라이젠 5",
          "cpu추천",
          "게이밍 cpu",
          "멀티스레딩 성능",
          "미드레인지 cpu 비교",
          "싱글 코어 성능",
          "인텔 코어 i5",
          "전력 소비 비교",
          "프로세서 성능",
          "하이브리드 아키텍처"
        ],
        "isoDate": "2024-09-09T00:12:09.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "「RULIWEB」",
        "title": "[MULTI] 강대강의 유혈 호드슈터, WH40k: 스페이스 마린 2",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2250",
        "pubDate": "Thu, 12 Sep 2024 17:35:10 +0900",
        "author": "「RULIWEB」",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i1.ruliweb.com/thumb/24/09/12/191e55acc0a4cacdc.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2024-09-12T08:35:10.000Z"
      },
      {
        "creator": "(RULIWEB`Д')/",
        "title": "[MULTI] 건프라란… 자유다! 건담 브레이커 4",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2249",
        "pubDate": "Wed, 11 Sep 2024 19:40:29 +0900",
        "author": "(RULIWEB`Д')/",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/24/09/11/191e0a995d14c329e.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2024-09-11T10:40:29.000Z"
      },
      {
        "creator": "［RULIWEB］",
        "title": "[MULTI] 풍선 근육 오픈 월드, 스타워즈 아웃로",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2248",
        "pubDate": "Tue, 10 Sep 2024 15:05:44 +0900",
        "author": "［RULIWEB］",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/24/09/10/191da89412a5104c1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2024-09-10T06:05:44.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "khris'log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": [
      {
        "title": "Excel상에서 WebAssembly판 Python을 실행 가능하게 하는 애드온 Anaconda Code",
        "link": "https://jacking75.github.io/tech_20240911/",
        "pubDate": "Wed, 11 Sep 2024 00:00:00 +0900",
        "content": "<iframe width=\"1024\" height=\"1024\" src=\"https://docs.google.com/document/d/1c7CbAi55VlnfiMQ6JQZDQn6AidbJW6RknQSpe58qTBo/pub?embedded=true\"></iframe>\n\n",
        "contentSnippet": "",
        "guid": "https://jacking75.github.io/tech_20240911/",
        "isoDate": "2024-09-10T15:00:00.000Z"
      }
    ]
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": [
      {
        "title": "커피한잔 명예의 전당",
        "link": "https://jeho.page/essay/2024/09/13/hall-of-fame.html",
        "pubDate": "2024-09-12T22:33:00.000Z",
        "author": "김재호",
        "content": "<p>조건문에 <code class=\"language-plaintext highlighter-rouge\">!</code> 하나를 빼먹어서 생긴 버그.<br />\n이 버그를 2년 동안이나 모르고 있다가 얼마 전에 발견했습니다.</p>\n\n<p>제가 만들고 있는 소개팅 서비스인 <a href=\"https://withcoffee.app\">커피한잔</a>에서는 채팅방이 오랫동안 지속될 경우 사용자들에게 알림 메일이 발송됩니다.<br />\n만약 커플이 되었다면 저에게 알려달라는 메일.</p>\n\n<p>이 메일이 버그로 인해 무려 2년 가까이 발송이 되지 않고 있었던 것.</p>\n\n<p>참나, 이걸 모르고 있었다니.<br />\n테스트를 안 짜둔 걸 반성하는 한 편, 서비스 감각이 이렇게 무뎌졌나 싶어서 스스로에게 화가 나기도 했습니다.</p>\n\n<p>코드를 정리하고, 그동안 안 보내진 메일을 발송했더니…<br />\n사용자들에게 답장이 속속 오기 시작합니다.<br />\n무려 15 커플이 이미 결혼했다고. 감사하다고.</p>\n\n<p>메일을 받을 때마다 놀랍고 기뻤습니다.<br />\n이 소중한 메일들을 잘 정리하고 싶다는 생각이 들어서 아예 웹페이지로 만들어버렸습니다.</p>\n\n<p><img src=\"/assets/img/hall_of_fame.png\" alt=\"커피한잔 명예의 전당\" /><br />\n<em>커피한잔 <a href=\"https://withcoffee.app/couples\">명예의 전당</a></em></p>\n\n<p>8년 가까이 서비스하면서 생긴 추억이자 자랑거리가 됐습니다.</p>\n\n<p><br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2021/09/07/왜-하필-소개팅-어플을-만들기로-했어요.html\">왜 하필 소개팅 어플을 만들기로 했어요?</a></li>\n</ul>",
        "contentSnippet": "조건문에 ! 하나를 빼먹어서 생긴 버그.\n제가 만들고 있는 소개팅 서비스인 커피한잔에서는 채팅방이 오랫동안 지속될 경우 사용자들에게 알림 메일이 발송됩니다.\n이 메일이 버그로 인해 무려 2년 가까이 발송이 되지 않고 있었던 것.\n참나, 이걸 모르고 있었다니.\n코드를 정리하고, 그동안 안 보내진 메일을 발송했더니…\n메일을 받을 때마다 놀랍고 기뻤습니다.\n\n커피한잔 명예의 전당\n8년 가까이 서비스하면서 생긴 추억이자 자랑거리가 됐습니다.\n\n함께 읽으면 좋은 글:\n왜 하필 소개팅 어플을 만들기로 했어요?",
        "summary": "조건문에 ! 하나를 빼먹어서 생긴 버그. 이 버그를 2년 동안이나 모르고 있다가 얼마 전에 발견했습니다.",
        "id": "https://jeho.page/essay/2024/09/13/hall-of-fame",
        "isoDate": "2024-09-12T22:33:00.000Z"
      }
    ]
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "if 를 읽기 쉽게 쓰는 방법",
        "link": "http://serverdown.tistory.com/803",
        "pubDate": "Fri, 13 Sep 2024 16:56:18 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/803#entry803comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/shorts/Zmx0Ou5TNJs\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/shorts/Zmx0Ou5TNJs</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/shorts/Zmx0Ou5TNJs\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/NtMrN/hyW24p9ZPP/xVZL0GwjQUh7ZemFxvQcOK/img.jpg?width=405&amp;height=720&amp;face=0_0_405_720,https://scrap.kakaocdn.net/dn/cFNyXX/hyW22ToYcP/VZpspL3AfjLfFUSadtJCo0/img.jpg?width=405&amp;height=720&amp;face=0_0_405_720\" data-video-width=\"405\" data-video-height=\"720\" data-video-origin-width=\"405\" data-video-origin-height=\"720\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"Nesting &quot;If Statements&quot; Is Bad. Do This Instead.\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/Zmx0Ou5TNJs\" width=\"405\" height=\"720\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">여러게 써서 산처럼 쌓지말고&nbsp;</p>\n<p data-ke-size=\"size16\">영상처럼 하세요</p>\n<p data-ke-size=\"size16\">하나씩 써서 아닌조건에서 return 으로 나가면</p>\n<p data-ke-size=\"size16\">괄호가 쌓여서 산처럼 쌓이는걸 방지합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/shorts/Zmx0Ou5TNJs\n\n\n\n여러게 써서 산처럼 쌓지말고 \n영상처럼 하세요\n하나씩 써서 아닌조건에서 return 으로 나가면\n괄호가 쌓여서 산처럼 쌓이는걸 방지합니다.",
        "guid": "http://serverdown.tistory.com/803",
        "categories": [
          "프로그래밍/개발메모",
          "코딩"
        ],
        "isoDate": "2024-09-13T07:56:18.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "flutter 풀러터 하기전에 반드시 알아야하는 기초지식",
        "link": "http://serverdown.tistory.com/802",
        "pubDate": "Fri, 13 Sep 2024 16:24:39 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/802#entry802comment",
        "content": "<p style=\"background-color: #000000; color: #000000; text-align: start;\" data-ke-size=\"size16\">풀러터는 참 좋습니다. 그런데 처음 시작하기에는 너무 이상한 셋팅이 있습니다.<br />바로 문법 체크인데 이거는 초보자는 시작부터 안돌아가서 좌절하게 만드는게 기본 값입니다.</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://youtu.be/mLQ-ehf3d6Y?list=PLfLgtT94nNq1izG4R2WDN517iPX4WXH3C&amp;t=60\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://youtu.be/mLQ-ehf3d6Y?list=PLfLgtT94nNq1izG4R2WDN517iPX4WXH3C&amp;t=60</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=mLQ-ehf3d6Y\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cmlF2U/hyW2VGKHJK/WH1Gaj5JxyXkK4MCIqEWgK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"쉬운 플러터 1강 : 기본 위젯4개 알면 기초 끝\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/mLQ-ehf3d6Y\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">여기서 네줄 넣으라는 부분이 문제라는 거구요</p>\n<p data-ke-size=\"size16\">저는 빨리배우려고 튜터리얼 페이지를 보면서 하고있는데요<br />여기서도 강조해서 글을 써봤습니다.<br /><br /></p>\n<p data-ke-size=\"size16\">처음에 이거 안따라하면 입문 포기하니 꼭 따라하세요<br />제가 플러터 2, 3 들어올때 컴파일 안되는거 보고 파로 접었었던 기억이 ...</p>\n<p data-ke-size=\"size16\">본문: <a href=\"https://codelabs.developers.google.com/codelabs/flutter-codelab-first?hl=ko#2\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://codelabs.developers.google.com/codelabs/flutter-codelab-first?hl=ko#2</a></p>\n<figure id=\"og_1726212041789\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"첫 번째 Flutter 앱 &nbsp;|&nbsp; Google Codelabs\" data-og-description=\"이 Codelab에서는 멋진 이름을 무작위로 생성하는 Flutter 앱을 빌드하는 방법을 알아봅니다.\" data-og-host=\"codelabs.developers.google.com\" data-og-source-url=\"https://codelabs.developers.google.com/codelabs/flutter-codelab-first?hl=ko#2\" data-og-url=\"https://codelabs.developers.google.com/codelabs/flutter-codelab-first?hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/tJzRt/hyW2YKeqew/bHmVG8cYsKiHu8ztqFSjXK/img.png?width=1454&amp;height=1156&amp;face=0_0_1454_1156,https://scrap.kakaocdn.net/dn/uAukO/hyW21Ac2qd/4sh5JuaUDqaSOu5TGAYO60/img.png?width=1600&amp;height=949&amp;face=0_0_1600_949,https://scrap.kakaocdn.net/dn/gA0vM/hyW23Lyoeb/Tp1OJua5V6BmSlk2lujQ5K/img.png?width=1136&amp;height=1266&amp;face=0_0_1136_1266\"><a href=\"https://codelabs.developers.google.com/codelabs/flutter-codelab-first?hl=ko#2\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://codelabs.developers.google.com/codelabs/flutter-codelab-first?hl=ko#2\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/tJzRt/hyW2YKeqew/bHmVG8cYsKiHu8ztqFSjXK/img.png?width=1454&amp;height=1156&amp;face=0_0_1454_1156,https://scrap.kakaocdn.net/dn/uAukO/hyW21Ac2qd/4sh5JuaUDqaSOu5TGAYO60/img.png?width=1600&amp;height=949&amp;face=0_0_1600_949,https://scrap.kakaocdn.net/dn/gA0vM/hyW23Lyoeb/Tp1OJua5V6BmSlk2lujQ5K/img.png?width=1136&amp;height=1266&amp;face=0_0_1136_1266');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">첫 번째 Flutter 앱 &nbsp;|&nbsp; Google Codelabs</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">이 Codelab에서는 멋진 이름을 무작위로 생성하는 Flutter 앱을 빌드하는 방법을 알아봅니다.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">codelabs.developers.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">요약하자면&nbsp;</p>\n<p data-ke-size=\"size16\">아래의 파일 내용을 동일하게 붙여넣으셔야합니다.</p>\n<p data-ke-size=\"size16\">pubspec.yaml - 사용할 라이브러리에 대한 셋팅<br />analysis_options.yaml - 문법체크 끄는 옵션<br />lib/main.dart - 우리가 코딩한 본문</p>\n<p data-ke-size=\"size16\">main.dart 는 알아서 영상이나 문서 참고해서 하시면 되긴하는데</p>\n<p data-ke-size=\"size16\">위에 두 파일은 꼭 따라서 넣으세요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">Android studio 보단</p>\n<p data-ke-size=\"size16\">vscode 에서 하는게 좋군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "풀러터는 참 좋습니다. 그런데 처음 시작하기에는 너무 이상한 셋팅이 있습니다.\n바로 문법 체크인데 이거는 초보자는 시작부터 안돌아가서 좌절하게 만드는게 기본 값입니다.\n영상: https://youtu.be/mLQ-ehf3d6Y?list=PLfLgtT94nNq1izG4R2WDN517iPX4WXH3C&t=60\n\n\n\n여기서 네줄 넣으라는 부분이 문제라는 거구요\n저는 빨리배우려고 튜터리얼 페이지를 보면서 하고있는데요\n여기서도 강조해서 글을 써봤습니다.\n\n처음에 이거 안따라하면 입문 포기하니 꼭 따라하세요\n제가 플러터 2, 3 들어올때 컴파일 안되는거 보고 파로 접었었던 기억이 ...\n본문: https://codelabs.developers.google.com/codelabs/flutter-codelab-first?hl=ko#2\n\n \n첫 번째 Flutter 앱  |  Google Codelabs\n이 Codelab에서는 멋진 이름을 무작위로 생성하는 Flutter 앱을 빌드하는 방법을 알아봅니다.\ncodelabs.developers.google.com\n\n \n요약하자면 \n아래의 파일 내용을 동일하게 붙여넣으셔야합니다.\npubspec.yaml - 사용할 라이브러리에 대한 셋팅\nanalysis_options.yaml - 문법체크 끄는 옵션\nlib/main.dart - 우리가 코딩한 본문\nmain.dart 는 알아서 영상이나 문서 참고해서 하시면 되긴하는데\n위에 두 파일은 꼭 따라서 넣으세요\n \nAndroid studio 보단\nvscode 에서 하는게 좋군요",
        "guid": "http://serverdown.tistory.com/802",
        "categories": [
          "프로그래밍/개발메모",
          "dart",
          "FLUTTER"
        ],
        "isoDate": "2024-09-13T07:24:39.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "flutter dart 코드 저장할때 줄바꿈이 이상해지는 문제",
        "link": "http://serverdown.tistory.com/801",
        "pubDate": "Fri, 13 Sep 2024 11:56:37 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/801#entry801comment",
        "content": "<p data-ke-size=\"size16\">원본: <a href=\"https://stackoverflow.com/questions/71472282/vs-code-flutter-code-automatically-shrinks-to-one-line-after-saving-file-or-rest\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://stackoverflow.com/questions/71472282/vs-code-flutter-code-automatically-shrinks-to-one-line-after-saving-file-or-rest</a></p>\n<figure id=\"og_1726196067889\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"VS Code Flutter code automatically shrinks to one line after saving file or restarting editor\" data-og-description=\"I like to program in flutter in individual lines for each child and it's components, i recently moved to VS Code from Android Studio after having some problems with it, but i noticed that in VS Code,\" data-og-host=\"stackoverflow.com\" data-og-source-url=\"https://stackoverflow.com/questions/71472282/vs-code-flutter-code-automatically-shrinks-to-one-line-after-saving-file-or-rest\" data-og-url=\"https://stackoverflow.com/questions/71472282/vs-code-flutter-code-automatically-shrinks-to-one-line-after-saving-file-or-rest\" data-og-image=\"https://scrap.kakaocdn.net/dn/vetEy/hyW2PsV4Uc/OkayW5EReBVKQUcP2QwgK1/img.png?width=316&amp;height=316&amp;face=0_0_316_316,https://scrap.kakaocdn.net/dn/bVCrgg/hyW2TIQ9Wb/RJyWC3gSJghnbCGhsBsWsk/img.png?width=516&amp;height=255&amp;face=0_0_516_255\"><a href=\"https://stackoverflow.com/questions/71472282/vs-code-flutter-code-automatically-shrinks-to-one-line-after-saving-file-or-rest\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://stackoverflow.com/questions/71472282/vs-code-flutter-code-automatically-shrinks-to-one-line-after-saving-file-or-rest\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/vetEy/hyW2PsV4Uc/OkayW5EReBVKQUcP2QwgK1/img.png?width=316&amp;height=316&amp;face=0_0_316_316,https://scrap.kakaocdn.net/dn/bVCrgg/hyW2TIQ9Wb/RJyWC3gSJghnbCGhsBsWsk/img.png?width=516&amp;height=255&amp;face=0_0_516_255');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">VS Code Flutter code automatically shrinks to one line after saving file or restarting editor</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">I like to program in flutter in individual lines for each child and it's components, i recently moved to VS Code from Android Studio after having some problems with it, but i noticed that in VS Code,</p>\n<p class=\"og-host\" data-ke-size=\"size16\">stackoverflow.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">저장할대 혼자 한줄로 바꿔버리는데 미춰버립니다.</p>\n<p data-ke-size=\"size16\">이럴때는 마지막에 콤마를 넣어주라는군요 해보니 잘되네요</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"761\" data-origin-height=\"406\"><span data-url=\"https://blog.kakaocdn.net/dn/SAaqP/btsJCm45e0r/lSMRkZwvZT52Aj9LtP2IQ1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/SAaqP/btsJCm45e0r/lSMRkZwvZT52Aj9LtP2IQ1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/SAaqP/btsJCm45e0r/lSMRkZwvZT52Aj9LtP2IQ1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FSAaqP%2FbtsJCm45e0r%2FlSMRkZwvZT52Aj9LtP2IQ1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"761\" data-origin-height=\"406\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">봐주기 힘든 코드인데&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"575\" data-origin-height=\"429\"><span data-url=\"https://blog.kakaocdn.net/dn/bW4BYF/btsJz1PCQZT/WN6XcZ15KuB7hD2rSsJjKK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bW4BYF/btsJz1PCQZT/WN6XcZ15KuB7hD2rSsJjKK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bW4BYF/btsJz1PCQZT/WN6XcZ15KuB7hD2rSsJjKK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbW4BYF%2FbtsJz1PCQZT%2FWN6XcZ15KuB7hD2rSsJjKK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"575\" data-origin-height=\"429\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">괄호 끝에 콤마 넣어주자 잘 나옵니다.</p>\n<p data-ke-size=\"size16\">엉망진창이군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "원본: https://stackoverflow.com/questions/71472282/vs-code-flutter-code-automatically-shrinks-to-one-line-after-saving-file-or-rest\n\n \nVS Code Flutter code automatically shrinks to one line after saving file or restarting editor\nI like to program in flutter in individual lines for each child and it's components, i recently moved to VS Code from Android Studio after having some problems with it, but i noticed that in VS Code,\nstackoverflow.com\n\n \n저장할대 혼자 한줄로 바꿔버리는데 미춰버립니다.\n이럴때는 마지막에 콤마를 넣어주라는군요 해보니 잘되네요\n\n\n봐주기 힘든 코드인데 \n\n\n \n괄호 끝에 콤마 넣어주자 잘 나옵니다.\n엉망진창이군요",
        "guid": "http://serverdown.tistory.com/801",
        "categories": [
          "dart",
          "FLUTTER"
        ],
        "isoDate": "2024-09-13T02:56:37.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "노안을 대비하여 갤럭시 기능을 익혀봐자",
        "link": "http://serverdown.tistory.com/800",
        "pubDate": "Thu, 12 Sep 2024 10:55:55 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/800#entry800comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=r7m-_68bzws\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=r7m-_68bzws</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=r7m-_68bzws\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/ccuysT/hyW22eAFkx/M8IgeyPveU0expP1BZApt0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"삼성 스마트폰  화면확대 기능 사용하는 방법(안드로이드, 갤럭시노트10플러스, 삼성스마트폰)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/r7m-_68bzws\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">화면확대를 쉽게 하는 법을 알려주는 영상입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">두번째는 색반전 바로가기 버튼</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=jYcDq0Mq_Oo\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=jYcDq0Mq_Oo</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=jYcDq0Mq_Oo\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/LGMDV/hyW23Llavj/VDZFr1ZydJiy7jMgkDKo11/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"How to get rid of the color inversion shortcut on Android phone\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/jYcDq0Mq_Oo\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">사람들아마 힌색 바탕이 맞을 수도 있고 검은색 바탕이 맞을 수도 있다고합니다.</p>\n<p data-ke-size=\"size16\">저는 힌색이 번져 보여서 검은 바탕을 선호 하구요</p>\n<p data-ke-size=\"size16\">기본UI 아닌 앱이나 웹페이지 볼때는 이게 뒤죽박죽이라&nbsp; 바꿔줘야합니다.</p>\n<p data-ke-size=\"size16\">그래서 단축키가 있나 검색해봤는데 한국사람중엔 영상으로 만든사람이 없군요</p>\n<p data-ke-size=\"size16\">아무도 없다면 영상으로 빨리 만들어야겠습니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=r7m-_68bzws\n\n\n\n \n화면확대를 쉽게 하는 법을 알려주는 영상입니다.\n \n두번째는 색반전 바로가기 버튼\n영상: https://www.youtube.com/watch?v=jYcDq0Mq_Oo\n\n\n\n \n사람들아마 힌색 바탕이 맞을 수도 있고 검은색 바탕이 맞을 수도 있다고합니다.\n저는 힌색이 번져 보여서 검은 바탕을 선호 하구요\n기본UI 아닌 앱이나 웹페이지 볼때는 이게 뒤죽박죽이라  바꿔줘야합니다.\n그래서 단축키가 있나 검색해봤는데 한국사람중엔 영상으로 만든사람이 없군요\n아무도 없다면 영상으로 빨리 만들어야겠습니다.",
        "guid": "http://serverdown.tistory.com/800",
        "categories": [
          "유튜브"
        ],
        "isoDate": "2024-09-12T01:55:55.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "정부 창업지원금 관련 내용",
        "link": "http://serverdown.tistory.com/798",
        "pubDate": "Mon, 9 Sep 2024 22:41:39 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/798#entry798comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=VdAZmGlEV20\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=VdAZmGlEV20</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=VdAZmGlEV20\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/FGkXD/hyW2SWZsKx/xokg4Y8gT789J9VTRRxwdK/img.jpg?width=1280&amp;height=720&amp;face=790_130_1028_390\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"(대출아님) 정부창업지원금으로 무자본 창업했어요 (2천만원~1억원 받기 | 예비창업패키지)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/VdAZmGlEV20\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">정부지원금 받는 내용인데 보통인물은 아닌듯</p>\n<p data-ke-size=\"size16\">대충 이런식으로 진행되서 받는다는건데</p>\n<p data-ke-size=\"size16\">한번에 되는 사람도 있고 몇년을 해도 안되는 사람도 있으니&nbsp;</p>\n<p data-ke-size=\"size16\">능력안된다 싶으면 도망을 추천</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">---------</p>\n<p data-ke-size=\"size16\">게임 개발 앱개발 지원급음&nbsp;</p>\n<p data-ke-size=\"size16\">년초에 코카? koca 에서 지원금 공고가 뜨면 지원하는거라고 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">-------</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=Ckv3nhDdM5Y\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=Ckv3nhDdM5Y</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=Ckv3nhDdM5Y\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/oydI5/hyW24b4DUV/Ro3Hl81eURyKhfb8Iviutk/img.jpg?width=640&amp;height=480&amp;face=0_0_640_480\" data-video-width=\"640\" data-video-height=\"480\" data-video-origin-width=\"640\" data-video-origin-height=\"480\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"2022년 상반기, 총 지원금 1억5천만원을 품에 안은 영광의 게임은? [제 16회 경기게임오디션] 스케\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/Ckv3nhDdM5Y\" width=\"640\" height=\"480\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">지역마다 따로 뭔가 진행중이기 아이디어는 미리 준비해야할듯</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">내용 찾는대로 추가해야할듯 방법은 많네</p>\n<p data-ke-size=\"size16\">통과 못할 뿐이지</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=VdAZmGlEV20\n\n\n\n \n정부지원금 받는 내용인데 보통인물은 아닌듯\n대충 이런식으로 진행되서 받는다는건데\n한번에 되는 사람도 있고 몇년을 해도 안되는 사람도 있으니 \n능력안된다 싶으면 도망을 추천\n \n---------\n게임 개발 앱개발 지원급음 \n년초에 코카? koca 에서 지원금 공고가 뜨면 지원하는거라고 합니다.\n \n \n \n-------\n영상: https://www.youtube.com/watch?v=Ckv3nhDdM5Y\n\n\n\n지역마다 따로 뭔가 진행중이기 아이디어는 미리 준비해야할듯\n \n \n내용 찾는대로 추가해야할듯 방법은 많네\n통과 못할 뿐이지",
        "guid": "http://serverdown.tistory.com/798",
        "categories": [
          "유튜브"
        ],
        "isoDate": "2024-09-09T13:41:39.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Hybrid's Notes",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": [
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "스즈키 히로키 - 마키아벨리의 군주론을 읽다",
        "link": "http://jojoldu.tistory.com/804",
        "pubDate": "Sat, 14 Sep 2024 00:24:01 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "http://jojoldu.tistory.com/804#entry804comment",
        "content": "<p data-ke-size=\"size16\"><a href=\"https://m.yes24.com/Goods/Detail/41790780\">스즈키 히로키의 \"마키아벨리의 군주론을 읽다\"</a>를 읽고 생각나는 구절들을 정리했다.</p>\n<h2 data-ke-size=\"size26\">1장</h2>\n<h4 data-ke-size=\"size20\">구두쇠가 되어도 좋다</h4>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">\"군주는 인색하다는 평판에 개의치 않아도 된다.<br />백성을 지키기 위해서도, 자신을 지키기 위해서도 (중략) 그래야 한다.<br />구두쇠가 되는 것은 지배자가 자신의 자리를 보존하기 위한 하나의 악덕이다.\"<br />...<br />낭비하는 리더는 큰일을 치를 때마다 국민에게 피해를 주고 원망을 받는 반면에, 절약하는 리더는 국민의 지지를 받으면서 큰일을 해냅니다.</p>\n</blockquote>\n<p data-ke-size=\"size16\">유동성이 풍부한 스타트업 투자 호황기의 대표님들이 생각난다.<br />그 시절에 낭비를 했던 리더분들은 대단히 힘든 시기를 보내었고,<br />당시에 투자금을 필요한 곳에만 적절하게 사용하신 분들은 지금 혹한기 시절에 오히려 더 성과를 내고 있다.<br />인건비의 과도한 투자로 요즘의 시기가 어렵다는 뉴스가 많다.<br />실제로 그런 것인지 아닌지는 회사마다 다르다고 본다.</p>\n<p data-ke-size=\"size16\">다만, 소프트웨어 개발자에게 높은 연봉을 주면 그만큼의 성과가 나오는 것이냐에 대해서는 스타트업 전체적으로 평가중인 것 같다.<br />최근에 핫하게 공유된 박영록님의 트윗이 있다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><a href=\"https://twitter.com/pakyoungrok/status/1829342829543674238\">거래액 100억 이하는 네이버 스마트 스토어가 최선의 선택이다</a></li>\n<li><a href=\"https://twitter.com/pakyoungrok/status/1829158146369290521\">우리나라 이커머스들이 적자가 많은 건 경쟁이 과도한 것도 있지만, 소프트웨어 생산성이 너무 낮은 것도 원인 중 하나가 아닐까 싶다</a></li>\n</ul>\n<p data-ke-size=\"size16\">그리고 작년엔 생활용품 커머스 <a href=\"https://cbiz.chosun.com/svc/bulletin/bulletin_art.html?contid=2023032600041\">와이즐리가 회사의 핵심 가치를 최저가 상품으로 보고 개발팀을 모두 없애고 Saas로 커머스를 대신했다</a>는 소식도 있다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"1.png\" data-origin-width=\"1426\" data-origin-height=\"874\"><span data-url=\"https://blog.kakaocdn.net/dn/bFETe7/btsJCC3fL95/IvAG16R49vUHZ0y8SLFJJk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bFETe7/btsJCC3fL95/IvAG16R49vUHZ0y8SLFJJk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bFETe7/btsJCC3fL95/IvAG16R49vUHZ0y8SLFJJk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbFETe7%2FbtsJCC3fL95%2FIvAG16R49vUHZ0y8SLFJJk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"743\" height=\"455\" data-filename=\"1.png\" data-origin-width=\"1426\" data-origin-height=\"874\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">에전에는 우리 회사의 본질이 무엇이건간에 소프트웨어 개발자에게 무조건적인 투자를 했다면, 현재는 소프트웨어 개발자가 이 서비스, 이 제품의 \"써야할 곳\" 인지 아닌지 우리 회사의 본질이 무엇이냐 판단하는 시기인것 같다.</p>\n<h2 data-ke-size=\"size26\">2장</h2>\n<h4 data-ke-size=\"size20\">운을 탓하지 마라</h4>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">\"오래도록 자리를 지킨 이탈리아의 제후가 마지막에 나라를 빼앗겼다고 운명을 탓하면 곤란하다.<br />그것은 운명이 아니라 태만 탓이다.\"<br />...<br />손에 넣은 것을 잃었다면 군주인 당신의 태만 탓입니다.<br />사랑하는 것을 잃는 것도, 부를 얻거나 소중한 사람과 나누는 행복을 놓치는 것도 군주인 당신의 태만이 문제가 된 것입니다.</p>\n</blockquote>\n<p data-ke-size=\"size16\">이 내용은 \"<a href=\"https://www.linkedin.com/posts/douglasguen_qwurbaqya-swmtnktxuslhqsvsmp-qsvsmpstcslh-activity-7229268927057383424-M1rn?utm_source=share&amp;utm_medium=member_desktop\">스타트업이 망한 것은 모두 스타트업 대표님의 잘못이다</a>\" 와 일맥상통한다고 생각했다.</p>\n<p data-ke-size=\"size16\">다만, 원론적으로 그렇게 생각할 수는 있다고 보지만, 개인적으로는 마음에 들진 않는다.<br />군주론은 전체적으로 \"현실의 불확실성\" 을 너무나 배제하고 이야기한다.<br />이게 시대 배경에 따른 차이인가 싶었지만, 현재 발생하는 모든 불행한 일이 일이 정말 그 사람의 노력 부족 때문인가? 싶다.</p>\n<p data-ke-size=\"size16\">나는 '운'의 요소를 대단히 믿는 편이다.<br />다만, 그래서 모든 것에 대해 운 탓을 한다기 보다는, \"운을 모을 수 있다\" 고 보는 편이다.</p>\n<p data-ke-size=\"size16\">세상에는 많은 운이 적용되고 있고, 이 운은 모을 수 있기 때문에 매일 매일 운을 모으는 행위를 하는 것이 필요하다.</p>\n<p data-ke-size=\"size16\">지나가는 쓰레기를 줍는다거나,<br />작은 일에 감사함을 표한다거나,<br />주변 동료들에게 친절함을 베푸는 등<br />그런 행위가 운을 모으는 것이라고 믿고 그렇게 운을 모아 내가 목표로 하는 곳에 다 쏟아지길 바랄뿐이다.</p>\n<h4 data-ke-size=\"size20\">대담하게 오르고 성실하게 지켜라</h4>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">\"겁에 질리거나 잘못된 조언에 따르거나 해서 결단을 미루면 자신을 지키는 단검을 손에서 놓지 못하게 된다.\"<br />...<br />처음에 잔혹함을 발휘하지 못하고 망설이다가 필요할 때마다 조금씩 발휘한다면, 원한을 품는 사람이 점점 늘어나 군주는 자신을 지키는 일에 급급해질 수 밖에 없습니다.</p>\n</blockquote>\n<p data-ke-size=\"size16\">Runway 가 1년 밖에 남지 않은 상황에서 희망퇴직, 구조조정을 한다면 어떤 방식이 가장 효과적일까?<br />이 문장은 위 질문에 대한 답변을 한 것 같았다.</p>\n<p data-ke-size=\"size16\">100명의 인원을 30명으로 줄여야만 Runway 가 1년에서 2년으로 늘어날 수 있는 상황에서 1) 한번에 70명과 헤어지는 것이 좋을까, 2) 20~30명씩 천천히 나눠서 헤어지면서 총 70명과 헤어지는 것이 좋을까</p>\n<p data-ke-size=\"size16\">이 책에서는 1) \"한번에 70명과 헤어지는 것\" 을 선택하라고 한다.<br />그리고 실제로 그렇게 선택한 실제 사례가 최근에 있었다.</p>\n<p data-ke-size=\"size16\">머스크가 트위터를 인수하고 하루에 전 직원의 50%를 해고한 이야기가 한참 화제였다.<br />당시에 트위터에 있던 분의 구조조정 과정을 만화가 공유되기도 했다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><a href=\"https://tobe.aladin.co.kr/s/9193\">무모한 안식년</a></li>\n</ul>\n<p data-ke-size=\"size16\">남은 사람들을 위해, 앞으로를 위해 한번에 잔혹함을 발휘하는게 낫다고 하지만, 실제로 그런 상황이 발생할때 그럴 수 있을까?<br />그런 상황이 생기는 것이 가장 두렵다.</p>\n<h2 data-ke-size=\"size26\">3장</h2>\n<h4 data-ke-size=\"size20\">해결사가 되라</h4>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">사장은 직원이 해결할 수 없는 문제를 해결하고, 상사는 부하가 해결할 수 없는 문제를 해결할 수 있어야 합니다.<br />...<br />다른 사람도 할 수 있는 일을 돕는 것이 아닙니다.</p>\n</blockquote>\n<p data-ke-size=\"size16\">팀원간의 갈등이나 조직간의 갈등 등 실무자가 해결할 수 없는 문제를 해결하는데 집중해야한다는 내용이라 공감되었다.<br />다만, 이건 조직의 현재 상황에 따라 달라질 수 있을 것 같다.</p>\n<p data-ke-size=\"size16\">조직의 실무 역량이 낮을 때는 팀원들이 해결할 수 없는 전문성에 관련된 문제를 풀어야하고,<br />조직의 실무 역량이 높을 때는 전문성에 관련된 문제가 아닌 조직대 조직, 사람대 사람의 문제를 풀어야하는 것 같다.</p>\n<h2 data-ke-size=\"size26\">4장</h2>\n<h4 data-ke-size=\"size20\">불만에 의해 움직이는 것은 다른 불만을 끌어당길 뿐이다</h4>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">\"구정권에 대한 불만으로 신군주를 옹립하고 지지한 사람들을 아군으로 삼기보다는 구정권에 만족하고 신군주를 적대한 사람들을 아군으로 삼는 편이 훨씬 편하다.\"<br />...<br />구정권에 만족하고 소임을 다하고 있던 사람은 결국 신정권에도 적응하게 됩니다.<br />그들이 움직이는 동기는 조직을 적절히 운영하는 일에 있기 때문입니다.<br />구정권의 장점에 주목해서 생활하고 있던 그들의 '장점을 보는 경향' 이 당신의 신정권에도 적용되는 것입니다.</p>\n</blockquote>\n<p data-ke-size=\"size16\">경력직을 채용할때 전 회사의 퇴사 사유를 물어보는 것과 동일한 것 같다.<br />전 직장에서 불만을 갖고 퇴사한 사람을 데려와서 우리 팀을 만족시키게 하는 것보다는 전 직장에서 불만 없이 만족하면서 다니는 사람을 우리팀으로 데려오는 것이 훨씬 더 성공적인 경력직 채용임을 몇번 경험했다.</p>\n<p data-ke-size=\"size16\">그래서 면접에서도 전 회사의 단점 보다는 장점을 이야기하는 사람이 좋다.<br />하지만 대부분은 전 회사의 어떠한 점이 불편했기 때문에 이직하는 것이라서 그러기는 쉽지 않을것 같다.</p>\n<h2 data-ke-size=\"size26\">5장</h2>\n<h4 data-ke-size=\"size20\">자신답게 패자가 되기보다 자신답지 않게 승자가 되라</h4>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">\"인간은 천성에서 좀처럼 벗어나지 못한다.<br />또한 한번 성공을 맛본 방식이 있다면 쉽게 버리지 못한다.<br />용의주도한 사람이 과감하게 행동해야할 시기가 왔을 때 지켜보기만 하다가 끝내 파멸하는 경우가 있다.<br />이 사람이 시대와 상황에 따라 자신의 기질을 바꾸었다면 틀림없이 파멸을 면할 수 있었을 것이다.\"</p>\n<p data-ke-size=\"size16\">자신답게 산다거나 있는 그대로의 모습으로 산다는 것은 매력적인 일입니다.<br />...<br />시대가 변하면 가치도 변합니다.<br />군주는 야망을 이루기 위해 때로는 천성을 버려야 합니다.<br /><b>자신다움에 집착하지 않는 것</b>, 이것이 군주가 승리를 쟁취하기 위한 기본 자세입니다.</p>\n</blockquote>\n<p data-ke-size=\"size16\">변화에 적극 대응하라는 말을 표현하는 여러가지 문장이 있겠지만, 이 문장이 가장 강렬하게 다가오는 것 같다.<br />\"후회 없는 경기\", \"나다운 시합\" 등의 이야기가 많지만,<br />그건 본인의 고유한 경기 스타일을 버리지 못해 생긴 이야기라고 생각한다.<br />위대한 선수가 되려면 \"나다운 시합 보다는 \"이기는 시합\"을 해야한다.<br />이 지점을 명확히 지적해준 것 같다.</p>\n<h4 data-ke-size=\"size20\">사람들은 꿈을 성취할 수 있다는 희망으로 따라온다</h4>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">군주가 부여하는 혹독한 임무를 부하가 거부하지 않는 이유는 군주가 말하는 정의가 곧 그들의 꿈이기 때문입니다.<br />그렇기에 시련을 견디고 함께 위업을 성취하고자 노력하는 것입니다.<br />진실한 권력은 민중이 당신을 꼭 필요한 존재라고 여길 때 나옵니다.</p>\n</blockquote>\n<p data-ke-size=\"size16\">스타트업이 가지고 있어야할 가장 핵심은 결국 \"회사가 가고자하는 목표가 결국 본인에게도 도달하고 싶은 목표\" 이기 때문인 것 같다.</p>\n<p data-ke-size=\"size16\">끝까지 가는 것이 중요하다.<br />그래야 구성원들도 이 리더가 우리의 꿈을 포기하지 않았다는 믿음을 가질 수 있다.<br />리더의 자리를 오래 하다보면 결국 지쳐서 중도 하차하는 경우를 자주 본다.<br />위대한 제국을 만든 리더들은 대부분 원대한 목표를 달성할때까지 끝까지 본인이 주도한다.<br />중도하차하지 않는다.</p>\n<p data-ke-size=\"size16\">하지만, 얼마나 심적으로 힘들었을까를 생각해보면 그 분들을 지지하고 싶다.<br />보통 10년이상은 다들 밤낮없이, 외롭게 어려운 결정들을 해왔을텐데, 그걸 더 하라고 강요할 수 있을까?<br />그래서 정말 본인이 끝까지 계속해서 끌고가는 리더분들은 반쯤 미쳐있어야만 가능한 것 같다.</p>\n<p data-ke-size=\"size16\">그리고 그런 리더들은 구성원들의 꿈을 이뤄줄 수 있지 않았을까 싶다.</p>",
        "contentSnippet": "스즈키 히로키의 \"마키아벨리의 군주론을 읽다\"를 읽고 생각나는 구절들을 정리했다.\n1장\n구두쇠가 되어도 좋다\n\"군주는 인색하다는 평판에 개의치 않아도 된다.\n백성을 지키기 위해서도, 자신을 지키기 위해서도 (중략) 그래야 한다.\n구두쇠가 되는 것은 지배자가 자신의 자리를 보존하기 위한 하나의 악덕이다.\"\n...\n낭비하는 리더는 큰일을 치를 때마다 국민에게 피해를 주고 원망을 받는 반면에, 절약하는 리더는 국민의 지지를 받으면서 큰일을 해냅니다.\n유동성이 풍부한 스타트업 투자 호황기의 대표님들이 생각난다.\n그 시절에 낭비를 했던 리더분들은 대단히 힘든 시기를 보내었고,\n당시에 투자금을 필요한 곳에만 적절하게 사용하신 분들은 지금 혹한기 시절에 오히려 더 성과를 내고 있다.\n인건비의 과도한 투자로 요즘의 시기가 어렵다는 뉴스가 많다.\n실제로 그런 것인지 아닌지는 회사마다 다르다고 본다.\n다만, 소프트웨어 개발자에게 높은 연봉을 주면 그만큼의 성과가 나오는 것이냐에 대해서는 스타트업 전체적으로 평가중인 것 같다.\n최근에 핫하게 공유된 박영록님의 트윗이 있다.\n거래액 100억 이하는 네이버 스마트 스토어가 최선의 선택이다\n우리나라 이커머스들이 적자가 많은 건 경쟁이 과도한 것도 있지만, 소프트웨어 생산성이 너무 낮은 것도 원인 중 하나가 아닐까 싶다\n그리고 작년엔 생활용품 커머스 와이즐리가 회사의 핵심 가치를 최저가 상품으로 보고 개발팀을 모두 없애고 Saas로 커머스를 대신했다는 소식도 있다.\n\n\n에전에는 우리 회사의 본질이 무엇이건간에 소프트웨어 개발자에게 무조건적인 투자를 했다면, 현재는 소프트웨어 개발자가 이 서비스, 이 제품의 \"써야할 곳\" 인지 아닌지 우리 회사의 본질이 무엇이냐 판단하는 시기인것 같다.\n2장\n운을 탓하지 마라\n\"오래도록 자리를 지킨 이탈리아의 제후가 마지막에 나라를 빼앗겼다고 운명을 탓하면 곤란하다.\n그것은 운명이 아니라 태만 탓이다.\"\n...\n손에 넣은 것을 잃었다면 군주인 당신의 태만 탓입니다.\n사랑하는 것을 잃는 것도, 부를 얻거나 소중한 사람과 나누는 행복을 놓치는 것도 군주인 당신의 태만이 문제가 된 것입니다.\n이 내용은 \"스타트업이 망한 것은 모두 스타트업 대표님의 잘못이다\" 와 일맥상통한다고 생각했다.\n다만, 원론적으로 그렇게 생각할 수는 있다고 보지만, 개인적으로는 마음에 들진 않는다.\n군주론은 전체적으로 \"현실의 불확실성\" 을 너무나 배제하고 이야기한다.\n이게 시대 배경에 따른 차이인가 싶었지만, 현재 발생하는 모든 불행한 일이 일이 정말 그 사람의 노력 부족 때문인가? 싶다.\n나는 '운'의 요소를 대단히 믿는 편이다.\n다만, 그래서 모든 것에 대해 운 탓을 한다기 보다는, \"운을 모을 수 있다\" 고 보는 편이다.\n세상에는 많은 운이 적용되고 있고, 이 운은 모을 수 있기 때문에 매일 매일 운을 모으는 행위를 하는 것이 필요하다.\n지나가는 쓰레기를 줍는다거나,\n작은 일에 감사함을 표한다거나,\n주변 동료들에게 친절함을 베푸는 등\n그런 행위가 운을 모으는 것이라고 믿고 그렇게 운을 모아 내가 목표로 하는 곳에 다 쏟아지길 바랄뿐이다.\n대담하게 오르고 성실하게 지켜라\n\"겁에 질리거나 잘못된 조언에 따르거나 해서 결단을 미루면 자신을 지키는 단검을 손에서 놓지 못하게 된다.\"\n...\n처음에 잔혹함을 발휘하지 못하고 망설이다가 필요할 때마다 조금씩 발휘한다면, 원한을 품는 사람이 점점 늘어나 군주는 자신을 지키는 일에 급급해질 수 밖에 없습니다.\nRunway 가 1년 밖에 남지 않은 상황에서 희망퇴직, 구조조정을 한다면 어떤 방식이 가장 효과적일까?\n이 문장은 위 질문에 대한 답변을 한 것 같았다.\n100명의 인원을 30명으로 줄여야만 Runway 가 1년에서 2년으로 늘어날 수 있는 상황에서 1) 한번에 70명과 헤어지는 것이 좋을까, 2) 20~30명씩 천천히 나눠서 헤어지면서 총 70명과 헤어지는 것이 좋을까\n이 책에서는 1) \"한번에 70명과 헤어지는 것\" 을 선택하라고 한다.\n그리고 실제로 그렇게 선택한 실제 사례가 최근에 있었다.\n머스크가 트위터를 인수하고 하루에 전 직원의 50%를 해고한 이야기가 한참 화제였다.\n당시에 트위터에 있던 분의 구조조정 과정을 만화가 공유되기도 했다.\n무모한 안식년\n남은 사람들을 위해, 앞으로를 위해 한번에 잔혹함을 발휘하는게 낫다고 하지만, 실제로 그런 상황이 발생할때 그럴 수 있을까?\n그런 상황이 생기는 것이 가장 두렵다.\n3장\n해결사가 되라\n사장은 직원이 해결할 수 없는 문제를 해결하고, 상사는 부하가 해결할 수 없는 문제를 해결할 수 있어야 합니다.\n...\n다른 사람도 할 수 있는 일을 돕는 것이 아닙니다.\n팀원간의 갈등이나 조직간의 갈등 등 실무자가 해결할 수 없는 문제를 해결하는데 집중해야한다는 내용이라 공감되었다.\n다만, 이건 조직의 현재 상황에 따라 달라질 수 있을 것 같다.\n조직의 실무 역량이 낮을 때는 팀원들이 해결할 수 없는 전문성에 관련된 문제를 풀어야하고,\n조직의 실무 역량이 높을 때는 전문성에 관련된 문제가 아닌 조직대 조직, 사람대 사람의 문제를 풀어야하는 것 같다.\n4장\n불만에 의해 움직이는 것은 다른 불만을 끌어당길 뿐이다\n\"구정권에 대한 불만으로 신군주를 옹립하고 지지한 사람들을 아군으로 삼기보다는 구정권에 만족하고 신군주를 적대한 사람들을 아군으로 삼는 편이 훨씬 편하다.\"\n...\n구정권에 만족하고 소임을 다하고 있던 사람은 결국 신정권에도 적응하게 됩니다.\n그들이 움직이는 동기는 조직을 적절히 운영하는 일에 있기 때문입니다.\n구정권의 장점에 주목해서 생활하고 있던 그들의 '장점을 보는 경향' 이 당신의 신정권에도 적용되는 것입니다.\n경력직을 채용할때 전 회사의 퇴사 사유를 물어보는 것과 동일한 것 같다.\n전 직장에서 불만을 갖고 퇴사한 사람을 데려와서 우리 팀을 만족시키게 하는 것보다는 전 직장에서 불만 없이 만족하면서 다니는 사람을 우리팀으로 데려오는 것이 훨씬 더 성공적인 경력직 채용임을 몇번 경험했다.\n그래서 면접에서도 전 회사의 단점 보다는 장점을 이야기하는 사람이 좋다.\n하지만 대부분은 전 회사의 어떠한 점이 불편했기 때문에 이직하는 것이라서 그러기는 쉽지 않을것 같다.\n5장\n자신답게 패자가 되기보다 자신답지 않게 승자가 되라\n\"인간은 천성에서 좀처럼 벗어나지 못한다.\n또한 한번 성공을 맛본 방식이 있다면 쉽게 버리지 못한다.\n용의주도한 사람이 과감하게 행동해야할 시기가 왔을 때 지켜보기만 하다가 끝내 파멸하는 경우가 있다.\n이 사람이 시대와 상황에 따라 자신의 기질을 바꾸었다면 틀림없이 파멸을 면할 수 있었을 것이다.\"\n자신답게 산다거나 있는 그대로의 모습으로 산다는 것은 매력적인 일입니다.\n...\n시대가 변하면 가치도 변합니다.\n군주는 야망을 이루기 위해 때로는 천성을 버려야 합니다.\n자신다움에 집착하지 않는 것, 이것이 군주가 승리를 쟁취하기 위한 기본 자세입니다.\n변화에 적극 대응하라는 말을 표현하는 여러가지 문장이 있겠지만, 이 문장이 가장 강렬하게 다가오는 것 같다.\n\"후회 없는 경기\", \"나다운 시합\" 등의 이야기가 많지만,\n그건 본인의 고유한 경기 스타일을 버리지 못해 생긴 이야기라고 생각한다.\n위대한 선수가 되려면 \"나다운 시합 보다는 \"이기는 시합\"을 해야한다.\n이 지점을 명확히 지적해준 것 같다.\n사람들은 꿈을 성취할 수 있다는 희망으로 따라온다\n군주가 부여하는 혹독한 임무를 부하가 거부하지 않는 이유는 군주가 말하는 정의가 곧 그들의 꿈이기 때문입니다.\n그렇기에 시련을 견디고 함께 위업을 성취하고자 노력하는 것입니다.\n진실한 권력은 민중이 당신을 꼭 필요한 존재라고 여길 때 나옵니다.\n스타트업이 가지고 있어야할 가장 핵심은 결국 \"회사가 가고자하는 목표가 결국 본인에게도 도달하고 싶은 목표\" 이기 때문인 것 같다.\n끝까지 가는 것이 중요하다.\n그래야 구성원들도 이 리더가 우리의 꿈을 포기하지 않았다는 믿음을 가질 수 있다.\n리더의 자리를 오래 하다보면 결국 지쳐서 중도 하차하는 경우를 자주 본다.\n위대한 제국을 만든 리더들은 대부분 원대한 목표를 달성할때까지 끝까지 본인이 주도한다.\n중도하차하지 않는다.\n하지만, 얼마나 심적으로 힘들었을까를 생각해보면 그 분들을 지지하고 싶다.\n보통 10년이상은 다들 밤낮없이, 외롭게 어려운 결정들을 해왔을텐데, 그걸 더 하라고 강요할 수 있을까?\n그래서 정말 본인이 끝까지 계속해서 끌고가는 리더분들은 반쯤 미쳐있어야만 가능한 것 같다.\n그리고 그런 리더들은 구성원들의 꿈을 이뤄줄 수 있지 않았을까 싶다.",
        "guid": "http://jojoldu.tistory.com/804",
        "categories": [
          "도서",
          "군주론",
          "마키아벨리",
          "스즈키 히로키",
          "스타트업"
        ],
        "isoDate": "2024-09-13T15:24:01.000Z"
      }
    ]
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": [
      {
        "title": "WebP의 품질과 파일 크기",
        "link": "https://hyeonseok.com/blog/918",
        "pubDate": "Sat, 07 Sep 2024 22:50:43 GMT",
        "content": "<p>웹피(WebP)를 저장 할 때 품질을 얼마로 정해야 품질과 파일 크기 사이에서 적당한 지점을 찾을 수 있을지 실험을 좀 해봤다. 먼저 웹피에 대해서 알아보려면 <a href=\"https://kr.bandisoft.com/honeycam/webp/what-is-webp/\">반디소프트</a>나 <a href=\"https://developers.google.com/speed/webp?hl=ko\">구글</a>, <a href=\"https://blog.tinify.com/pros-and-cons-webp-images/\">타이니파이</a>의 글을 참고하면 좋다. 간단히 말하면 구글에서 만든 무손실과 손실, 알파채널, 애니메이션까지 지원하면서 기존 포맷 보다 작은 파일 크기를 유지하는 최근에 가장 각광 받고 있는 이미지 포맷이다. <a href=\"https://caniuse.com/?search=webp\">대부분의 브라우저에서 지원</a>한다.</p>\r\n\r\n<p>무손실로 저장을 해도 PNG에 비해 26%가 작다니 사용하지 않을 이유가 없다. 다만 손실의 경우에는 파일 크기는 획기적으로 줄어들지만 그만큼 품질도 희생되기 때문에 JPG 사용하는 기분으로 쓰면 된다. 품질은 0에서 100까지 지정할 수 있는데 생각보다 유실되는 디테일이 많아서 품질을 많이 낮춰서 사용하기는 힘들다.</p>\r\n\r\n<table style=\"width: 20em\">\r\n  <caption>WebP 품질에 따른 파일 크기 변화</caption>\r\n  <thead>\r\n    <tr>\r\n      <th>Quality</th>\r\n      <th>Size (KB)</th>\r\n    </tr>\r\n  </thead>\r\n  <tbody>\r\n    <tr>\r\n      <th>10</th>\r\n      <td>42</td>\r\n    </tr>\r\n    <tr>\r\n      <th>20</th>\r\n      <td>50</td>\r\n    </tr>\r\n    <tr>\r\n      <th>30</th>\r\n      <td>58</td>\r\n    </tr>\r\n    <tr>\r\n      <th>40</th>\r\n      <td>66</td>\r\n    </tr>\r\n    <tr>\r\n      <th>50</th>\r\n      <td>72</td>\r\n    </tr>\r\n    <tr>\r\n      <th>60</th>\r\n      <td>77</td>\r\n    </tr>\r\n    <tr>\r\n      <th>70</th>\r\n      <td>84</td>\r\n    </tr>\r\n    <tr>\r\n      <th>80</th>\r\n      <td>99</td>\r\n    </tr>\r\n    <tr>\r\n      <th>90</th>\r\n      <td>131</td>\r\n    </tr>\r\n    <tr>\r\n      <th>100</th>\r\n      <td>344</td>\r\n    </tr>\r\n  </tbody>\r\n</table>\r\n\r\n<p><img src=\"/static/blog/webp-quality-and-size.png\" class=\"major\" alt=\"WebP의 품질이 80까지는 크기가 급격히 줄다가 그 이하에서는 선형적으로 줄어들고 있다.\" /> 90정도의 품질을 선택해도 크기가 반이하로 줄고 80아래부터는 품질 저하에 비해 크기가 많이 줄지 않기 때문에 90이나 80정도를 사용하면 충분할 것 같다. 내 경우는 품질이 크게 중요하지 않아서 일단 50으로 잡기는 했다. 하지만 품질이 떨어짐에 따라 손실되는 이미지 디테일이 매우 심하기 때문에 이미지 손상에 대해서 어느정도 감수는 해야 한다.</p>\r\n\r\n<p><img src=\"/static/blog/bandisoft-webp-quality.png\" class=\"major\" alt=\"반디소프트의 정적 이미지와 애니메이션 이미지의 품질별 크기 비교, 유사한 경향성을 보여주고 있다.\" /> <a href=\"https://kr.bandisoft.com/honeycam/webp/webp-quality/\">반디소프트 글 중에서 품질을 다룬 것</a>이 있는데 그래프로 그려보면 거의 비슷한 경향성을 가지고 있어서 웹피의 품질 설정이 어느정도 예측 가능한 일관성을 가지고 있는 것으로 생각된다. 아직은 내가 쓰는 툴이 무손실 웹피를 편하게 지원하지 않아서 바로 바꾸지는 못했는데 웹피의 흥행은 앞으로 시간 문제로 생각된다. 이미 많이 사용되고 있다.</p>",
        "contentSnippet": "웹피(WebP)를 저장 할 때 품질을 얼마로 정해야 품질과 파일 크기 사이에서 적당한 지점을 찾을 수 있을지 실험을 좀 해봤다. 먼저 웹피에 대해서 알아보려면 반디소프트나 구글, 타이니파이의 글을 참고하면 좋다. 간단히 말하면 구글에서 만든 무손실과 손실, 알파채널, 애니메이션까지 지원하면서 기존 포맷 보다 작은 파일 크기를 유지하는 최근에 가장 각광 받고 있는 이미지 포맷이다. 대부분의 브라우저에서 지원한다.\n\r\n\r\n무손실로 저장을 해도 PNG에 비해 26%가 작다니 사용하지 않을 이유가 없다. 다만 손실의 경우에는 파일 크기는 획기적으로 줄어들지만 그만큼 품질도 희생되기 때문에 JPG 사용하는 기분으로 쓰면 된다. 품질은 0에서 100까지 지정할 수 있는데 생각보다 유실되는 디테일이 많아서 품질을 많이 낮춰서 사용하기는 힘들다.\n\r\n\r\n\r\n  WebP 품질에 따른 파일 크기 변화\r\n  \r\n    \n\r\n      Quality\r\n      Size (KB)\r\n    \n\r\n  \r\n  \r\n    \n\r\n      10\r\n      42\r\n    \n\r\n    \n\r\n      20\r\n      50\r\n    \n\r\n    \n\r\n      30\r\n      58\r\n    \n\r\n    \n\r\n      40\r\n      66\r\n    \n\r\n    \n\r\n      50\r\n      72\r\n    \n\r\n    \n\r\n      60\r\n      77\r\n    \n\r\n    \n\r\n      70\r\n      84\r\n    \n\r\n    \n\r\n      80\r\n      99\r\n    \n\r\n    \n\r\n      90\r\n      131\r\n    \n\r\n    \n\r\n      100\r\n      344\r\n    \n\r\n  \r\n\r\n\r\n 90정도의 품질을 선택해도 크기가 반이하로 줄고 80아래부터는 품질 저하에 비해 크기가 많이 줄지 않기 때문에 90이나 80정도를 사용하면 충분할 것 같다. 내 경우는 품질이 크게 중요하지 않아서 일단 50으로 잡기는 했다. 하지만 품질이 떨어짐에 따라 손실되는 이미지 디테일이 매우 심하기 때문에 이미지 손상에 대해서 어느정도 감수는 해야 한다.\n\r\n\r\n 반디소프트 글 중에서 품질을 다룬 것이 있는데 그래프로 그려보면 거의 비슷한 경향성을 가지고 있어서 웹피의 품질 설정이 어느정도 예측 가능한 일관성을 가지고 있는 것으로 생각된다. 아직은 내가 쓰는 툴이 무손실 웹피를 편하게 지원하지 않아서 바로 바꾸지는 못했는데 웹피의 흥행은 앞으로 시간 문제로 생각된다. 이미 많이 사용되고 있다.",
        "guid": "https://hyeonseok.com/blog/918",
        "isoDate": "2024-09-07T22:50:43.000Z"
      }
    ]
  },
  {
    "name": "한상곤 - Sigmadream",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "FIDO2 클라이언트 SDK 오픈소스 소개",
        "link": "https://techblog.lycorp.co.jp/ko/introducing-fido2-client-sdk-open-source",
        "pubDate": "Fri, 13 Sep 2024 03:00:00 GMT",
        "content": "들어가며\n안녕하세요. Security R&D 팀에서 FIDO2 클라이언트 개발을 담당하고 있는 김도연, 김영현입니다.\n공개 키 암호화를 기반으로 한 FIDO는 패스워드나 SMS O...",
        "contentSnippet": "들어가며\n안녕하세요. Security R&D 팀에서 FIDO2 클라이언트 개발을 담당하고 있는 김도연, 김영현입니다.\n공개 키 암호화를 기반으로 한 FIDO는 패스워드나 SMS O...",
        "guid": "https://techblog.lycorp.co.jp/ko/introducing-fido2-client-sdk-open-source",
        "isoDate": "2024-09-13T03:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": [
      {
        "title": "API 가이드 vs. API 스펙, 뭐가 다른거야?",
        "link": "https://meetup.nhncloud.com/posts/386",
        "pubDate": "Wed, 11 Sep 2024 00:44:35 GMT",
        "content": "![final_섬네일민트2.png](https://image.toast.com/aaaadh/real/2024/techblog/finaluC12CuB124uC77CuBBFCuD2B82.png)\r\r\n\r\r\n## 들어가며\r\r\n\r\r\nAPI(application programming interface)는 우리가 인지하지 못하는 동안에도 일상생활의 곳곳에 밀접하게 연관되어 있습니다. 날씨 정보 조회에서부터 소셜 미디어 로그인까지 우리가 의식하지 않는 순간에도 API를 호출하고 데이터를 주고받고 있는데요. 작년 TESLA가 서드 파티 애플리케이션을 지원하기 위한 공식 API와 [API 문서](https://developer.tesla.com/docs/fleet-api/getting-started/what-is-fleet-api)를 공개하면서 이제 API가 전 산업분야에서 활발히 사용 중인 걸 알 수 있었습니다. 아카마이 테크놀로지가 발표한 [조사](https://www.akamai.com/newsroom/press-release/state-of-the-internet-security-retail-attacks-and-api-traffic)에 따르면 API 호출로 인한 웹 트래픽이 전체 웹 트래픽의 83퍼센트를 차지한다고 합니다. 이렇게 API가 마치 물처럼 없어선 안 될 요소가 되면서 동시에 API 문서의 중요성도 함께 커지고 있습니다.\r\r\n\r\r\n여러 서비스들의 기술 문서를 보다 보면 API 가이드 또는 API 명세, API 레퍼런스 같은 용어들을 자주 마주칠 수 있는데요. 과연 이 용어들이 같은 의미를 가지고 있을까요?\r\r\n\r\r\n사실 API 문서와 API 스펙은 비슷해 보이지만 다른 의미를 가지고 있습니다.\r\r\nAPI 스펙(API specification)이란 무엇일까요? API 문서(API documentation)를 의미하는 것일까요?\r\r\n\r\r\n## API 문서? API 스펙?\r\r\n\r\r\nAPI 가이드, API 레퍼런스는 모두 API 문서(API documentation)입니다. API 문서는 API 사용 방법을 주로 다룹니다. 독자는 개발자 또는 API를 사용하는 일반 사용자입니다. API 호출 시 필요한 파라미터와 반환되는 응답, 오류 메시지, JavaScript, Python과 같이 자주 사용되는 개발 언어로 작성된 샘플 코드 등을 제공해 독자가 읽고 쉽게 이해할 수 있도록 돕는 문서입니다. 따라서 잘 작성된 API 가이드는 API를 즉시 테스트해 볼 수 있도록 빠른 시작 가이드, 튜토리얼, 오류 처리 방법 등 다양한 정보를 담고있습니다.\r\r\n\r\r\n그렇다면 ‘API 스펙’은 무엇을 의미할까요?\r\r\n\r\r\n만약 나만의 API를 개발했다고 합시다. 이 API로 사업을 계획하고 있다면, 이를 사용할 고객, 거래처, 팀원에게 API를 명확하게 설명하는 것이 매우 중요할 것입니다. 반복적이지만 군더더기 없이 간결하게 API를 설명하는 것이 API를 활용한 비즈니스를 성공적으로 이끄는 데 매우 중요할 텐데요. 이를 가능케 하는 것이 바로 `API 스펙`입니다.\r\r\n\r\r\nAPI 스펙이란 `단순하고 명확한 언어로 작성된 API의 청사진 혹은 API 설계도면`(또는 설계 규격)을 뜻합니다. 다시 말해 특정 API에 대한 모든 정보를 항목화한 명세입니다. 잘 작성된 API 스펙은 해당 애플리케이션을 구석구석 살펴보지 않아도, 즉시 이해할 수 있습니다.\r\r\n\r\r\nAPI 스펙은 API가 어떻게 동작하고 다른 API와 어떻게 상호작용하는지를 다룹니다. API 문서는 API를 사용하고 싶은 개발자를 위한 것이라면 API 스펙은 API를 빌드하고자하는 개발자를 위해 작성된 것입니다. API 스펙은 API가 가진 각각의 동작에 대해 더 상세하게 기재되어 있습니다. API에 포함된 오브젝트, 값, 파라미터는 물론이고 해당 API가 사용하는 데이터 모델에 대한 정보를 담고 있습니다. 즉 API 스펙은 해당 API의 동작 방식과 다른 API와 상호 작용에 대해 상세하게 기술한 문서입니다.\r\r\n\r\r\n![화면 캡처 2024-09-04 154738.png](https://image.toast.com/aaaadh/real/2024/techblog/uD654uBA74%20uCEA1uCC98%2020240904%20154738.png)\r\r\n\r\r\n\r\r\nAPI 스펙은 API를 맨 처음 개발할 때부터 API를 기술하는 API 문서를 제작하는 데 있어 가장 필수적인 도구입니다. API 스펙이 아주 잘 정립되어 있다면 생소한 코드를 분석하는 골치 아픈 일을 건너뛰고 API를 훨씬 더 일관되고 안정적으로 구현할 수 있습니다. 사실 ‘API 스펙’이란 개념이 등장하기 전엔, API 개발하는 과정은 팀마다 회사마다 제각각이고 질서가 없었는데요. 그 결과, 완성된 힘들게 개발한 API를 연동하는 것이 무척 어렵고 복잡하고 비효율적이었습니다. 이는 곧 서비스의 매력도를 크게 떨어뜨리는 결과를 가져오게 되죠.\r\r\n\r\r\n![비교_new1.png](https://image.toast.com/aaaadh/real/2024/techblog/uBE44uAD50new1.png)\r\r\n\r\r\n## OpenAPI의 등장\r\r\n\r\r\n‘API 스펙’이란 개념이 주목받기 시작한 때는 2010년 지금은 너무나 잘 알려진 Swagger가 등장하면서부터입니다. Swagger는 API를 문서화하고, 정의하고 인터랙션 하기 위해 필요한 모든 것을 제공하는 `오픈소스 소프트웨어 프레임워크`인데요. 풀어서 설명하면, Swagger는 RESTful API(웹에서 사용되는 자원을 효율적이고 안정적으로 사용할 수 있게 하는 REST 원칙을 잘 따르는 API)를 설계하고, 빌드하고, 이에 대한 문서도 작성할 수 있도록 하는 도구입니다. 여기에 더해 빌드한 API를 호출해 볼수도 있습니다.\r\r\n\r\r\nAPI를 작성할 수 있다는 점에는 Swagger는 API 정의 언어라고도 하는데요. 다음에 나올 내용에서 계속 등장하니 기억해 주시기 바랍니다.\r\r\nSwagger로 작성한 API 스펙인 Swagger Specification이 API 스펙의 표준으로 널리 사용되었는데, 이후 2015년 Swagger 개발사인 SmartBear가 Swagger Specification을 리눅스 재단 산하의 **오픈API 이니셔티브**에 기부하면서 Swagger Specification은 <strong>OpenAPI Specification(OAS)</strong>라는 공식 명칭을 가지게 되었고 OAS는 표준 API 스펙으로 자리잡게되었습니다. 오픈 API 이니셔티브는 API 기술하는 방식을 표준화하자는 목표 아래 현재도 활발하게 API 생태계 발전에 기여하고있습니다. 2024년 9월 기준, OAS는 버전 [3.1.0](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.1.0.md) 까지 업데이트되었습니다.\r\r\n\r\r\n다시 말하자면 OpenAPI는 Swagger와 마찬가지로 API 정의 언어(API description language)이며, OpenAPI로 작성한 API 스펙을 OAS(OpenAPI Specification)라고 합니다.\r\r\n\r\r\nOAS는 이제 API 스펙의 표준으로 인식되며 현재 가장 많이 사용되는 API 스펙입니다. OAS를 활용하면 기계가 인식할 수 있는 형태로 API를 설계할 수 있고, 더 나아가 API 문서와 클라이언트 SDK 등을 생성하고 인증과 오류 처리 방법, 보안과 같은 디테일한 정보도 기술할 수 있습니다.\r\r\n\r\r\n## TypeSpec의 등장\r\r\n\r\r\n이렇게 OAS가 API 스펙의 표준으로 굳건하게 입지를 다지는 중에 최근 Microsoft가 새로운 API 정의 언어인 TypeSpec을 출시했습니다.\r\r\n<span style=\"\">TypeSpec은 Microsoft Graph 개발팀이 마치 코드를 작성하는 것처럼 유연하고 편리하게 API 스펙을 작성하고 싶다는 생각에서 탄생했습니다.</span>\r\r\n\r\r\nAPI 콘퍼런스인 [Nordic APIs](https://www.youtube.com/watch?v=yfCYrKaojDo&t=731s)에서 Microsoft Azure SDK 팀리더는 무수히 많은 문서와 라이브러리를 일관되고 용이하게 관리하기 위해 API 정의 언어로 TypeSpec을 활용한다고 합니다. 내부에서 API와 SDK 문서를 일관되게 관리하기 위한 API 작성 가이드라인이 있지만, Azure 서비스가 급속하게 성장하다 보니 각기 다른 언어로 작성된 API 문서를 효율적으로 관리하기가 어려워졌고 이런 상황에서 TypeSpec으로 API를 정의하면 API 스펙을 크게 간소화할 수 있고, API 가이드라인을 재사용 가능한 코드로 만들면 신규인력도 이를 빠르고 쉽게 적용하여 API 문서를 작성할 수 있다고 하는데요.\r\r\n\r\r\n마치 코드를 작성하는 것과 같이 API 스펙을 작성해서 Design-First 접근법(API 설계 시 API 스펙을 먼저 작성하는 접근법)을 실현하기 위해 TypeSpec을 활발히 사용 중이라고 밝혔습니다.\r\r\n\r\r\n반복해서 나오는 API 정의 언어와 API 스펙의 개념을 구분하면 아래와 같습니다.\r\r\n\r\r\n![자산 2.png](https://image.toast.com/aaaadh/real/2024/techblog/uC790uC0B0%202.png)\r\r\n\r\r\n그렇다면 OpenAPI와 TypeSpec으로 작성한 API 스펙이 어떻게 다른지 한번 살펴보겠습니다.\r\r\n예로 아래와 같이 동작하는 API가 있습니다.\r\r\n\r\r\n### 사용자 관리 API\r\r\n\r\r\n* 사용자 목록 조회(List)\r\r\n* ID로 사용자 단일 조회(Read)\r\r\n* 신규 사용자 생성(Create)\r\r\n* 사용자 정보 수정(Update)\r\r\n* 사용자 삭제(Delete)\r\r\n\r\r\n## OpenAPI vs TypeSpec\r\r\n\r\r\nTypeSpec과 OpenAPI로 각각 사용자 관리 API 스펙을 작성하면 아래와 같습니다\r\r\n\r\r\n![codereview_.png](https://image.toast.com/aaaadh/real/2024/techblog/codereview.png)\r\r\n\r\r\n이 두 API 정의 언어의 장점과 단점은 분명한데요. TypeSpec은 코드를 작성하는 것과 유사하게 API 스펙을 작성할 수 있고, OpenAPI 대비 좀 더 경량화된 언어인 반면, 아직 OpenAPI보다 지원하는 서드파티 툴이 적다는 단점이 있습니다. 또한 OpenAPI는 호환 가능한 툴이 매우 다양하고 관련 생태계가 활성화되어있지만 API의 규모가 커질수록 길이가 너무 길어지고 복잡해지는 단점을 가지고 있습니다.\r\r\n\r\r\nTypeSpec은 OpenAPI를 완벽히 대체하기는 어려울 것이라는 의견도 있습니다만, 그보다 TypeSpec을 활용해 코드를 작성하는 것처럼 재사용 가능하고 확장 가능한 API 스펙을 만들 수 있고, OpenAPI 툴 체인과 쉽게 연동이 가능하여 이는 결국 API 생태계를 더욱 풍성하게 만들 것이란 의견이 많습니다.\r\r\n\r\r\nTypeSpec과 OpenAPI와 같은 API 정의 언어로 API 스펙을 작성할 때 누릴 수 있는 이점을 정리해 보면 아래와 같습니다.\r\r\n\r\r\n* 일관성\r\r\n    * API 스펙, 즉 API 규격이 잘 정립되어 있다면, 신규 API가 출시되었을 때, API 스펙에 부합하는지를 검증할 수 있습니다. 이로써 API의 작동 방식을 더욱 빠르고 쉽게 이해할 수 있습니다.\r\r\n    * API들이 일관된 규격에 맞게 설계되므로, 이는 백엔드 개발자와 프론트엔드 개발자 간 커뮤니케이션을 매끄럽게 만들어줍니다.\r\r\n* 문서 자동화\r\r\n    * Swagger 같은 API 문서 자동화 툴과 호환할 수 있어, API 문서에 포함된 API 엔드포인트를 즉시 테스트해 볼 수 있습니다.\r\r\n* 쉬운 유지 보수와 테스트\r\r\n    * 일관된 규격에 맞게 설계된 API는 물론 그렇지 않은 API보다 이해하기가 더 쉬우므로, API 업데이트 혹은 버전업을 더 빠르게 수행할 수 있습니다.\r\r\n\r\r\n## 나가며\r\r\n\r\r\nAPI 가이드와 API 스펙은 평소 자주 혼용되어 그 개념을 정확히 알고자 이렇게 기술 공유 글을 작성하게 되었는데요, 이번 계기로 API 스펙이 API 문서와 어떻게 다른지 알 수 있었습니다.\r\r\n비즈니스 관점에서 잘 작성된 API 스펙과 API 가이드는 API가 약속한 대로 작동할 것이라는 계약서와 같은 역할을 하고 이는 신뢰성과도 직결되는데요, 더 나아가 완성도 있는 애플리케이션 구축의 토대가 된다는 점을 고려하면 앞으로 API 스펙의 중요성은 커질 것입니다. 긴 글 읽어주셔서 감사합니다.\r\r\n\r\r\n## 참고자료\r\r\n\r\r\n* [https://nordicapis.com/what-is-an-api-definition/](https://nordicapis.com/what-is-an-api-definition/)\r\r\n* [https://swagger.io/resources/articles/difference-between-api-documentation-specification/](https://swagger.io/resources/articles/difference-between-api-documentation-specification/)\r\r\n* [https://github.com/OAI/OpenAPI-Specification/blob/main/examples/v2.0/json/petstore-expanded.json](https://github.com/OAI/OpenAPI-Specification/blob/main/examples/v2.0/json/petstore-expanded.json)\r\r\n* [https://medium.com/another-integration-blog/your-api-specification-is-not-your-api-documentation-4dcc33d23823](https://medium.com/another-integration-blog/your-api-specification-is-not-your-api-documentation-4dcc33d23823)\r\r\n* [https://www.moesif.com/blog/technical/api-design/Benefits-of-using-the-OpenAPI-Swagger-specification-for-your-API/](https://www.moesif.com/blog/technical/api-design/Benefits-of-using-the-OpenAPI-Swagger-specification-for-your-API/)\r\r\n* [https://blog.postman.com/openapi-vs-swagger/](https://blog.postman.com/openapi-vs-swagger/)\r\r\n* [https://www.youtube.com/watch?v=yfCYrKaojDo&t=731s](https://www.youtube.com/watch?v=yfCYrKaojDo&t=731s)\r\r\n\r\r\n![footer.png](https://image.toast.com/aaaadh/real/2024/techblog/footer.png)",
        "contentSnippet": "![final_섬네일민트2.png](https://image.toast.com/aaaadh/real/2024/techblog/finaluC12CuB124uC77CuBBFCuD2B82.png)\r\r\n\r\r\n## 들어가며\r\r\n\r\r\nAPI(application programming interface)는 우리가 인지하지 못하는 동안에도 일상생활의 곳곳에 밀접하게 연관되어 있습니다. 날씨 정보 조회에서부터 소셜 미디어 로그인까지 우리가 의식하지 않는 순간에도 API를 호출하고 데이터를 주고받고 있는데요. 작년 TESLA가 서드 파티 애플리케이션을 지원하기 위한 공식 API와 [API 문서](https://developer.tesla.com/docs/fleet-api/getting-started/what-is-fleet-api)를 공개하면서 이제 API가 전 산업분야에서 활발히 사용 중인 걸 알 수 있었습니다. 아카마이 테크놀로지가 발표한 [조사](https://www.akamai.com/newsroom/press-release/state-of-the-internet-security-retail-attacks-and-api-traffic)에 따르면 API 호출로 인한 웹 트래픽이 전체 웹 트래픽의 83퍼센트를 차지한다고 합니다. 이렇게 API가 마치 물처럼 없어선 안 될 요소가 되면서 동시에 API 문서의 중요성도 함께 커지고 있습니다.\r\r\n\r\r\n여러 서비스들의 기술 문서를 보다 보면 API 가이드 또는 API 명세, API 레퍼런스 같은 용어들을 자주 마주칠 수 있는데요. 과연 이 용어들이 같은 의미를 가지고 있을까요?\r\r\n\r\r\n사실 API 문서와 API 스펙은 비슷해 보이지만 다른 의미를 가지고 있습니다.\r\r\nAPI 스펙(API specification)이란 무엇일까요? API 문서(API documentation)를 의미하는 것일까요?\r\r\n\r\r\n## API 문서? API 스펙?\r\r\n\r\r\nAPI 가이드, API 레퍼런스는 모두 API 문서(API documentation)입니다. API 문서는 API 사용 방법을 주로 다룹니다. 독자는 개발자 또는 API를 사용하는 일반 사용자입니다. API 호출 시 필요한 파라미터와 반환되는 응답, 오류 메시지, JavaScript, Python과 같이 자주 사용되는 개발 언어로 작성된 샘플 코드 등을 제공해 독자가 읽고 쉽게 이해할 수 있도록 돕는 문서입니다. 따라서 잘 작성된 API 가이드는 API를 즉시 테스트해 볼 수 있도록 빠른 시작 가이드, 튜토리얼, 오류 처리 방법 등 다양한 정보를 담고있습니다.\r\r\n\r\r\n그렇다면 ‘API 스펙’은 무엇을 의미할까요?\r\r\n\r\r\n만약 나만의 API를 개발했다고 합시다. 이 API로 사업을 계획하고 있다면, 이를 사용할 고객, 거래처, 팀원에게 API를 명확하게 설명하는 것이 매우 중요할 것입니다. 반복적이지만 군더더기 없이 간결하게 API를 설명하는 것이 API를 활용한 비즈니스를 성공적으로 이끄는 데 매우 중요할 텐데요. 이를 가능케 하는 것이 바로 `API 스펙`입니다.\r\r\n\r\r\nAPI 스펙이란 `단순하고 명확한 언어로 작성된 API의 청사진 혹은 API 설계도면`(또는 설계 규격)을 뜻합니다. 다시 말해 특정 API에 대한 모든 정보를 항목화한 명세입니다. 잘 작성된 API 스펙은 해당 애플리케이션을 구석구석 살펴보지 않아도, 즉시 이해할 수 있습니다.\r\r\n\r\r\nAPI 스펙은 API가 어떻게 동작하고 다른 API와 어떻게 상호작용하는지를 다룹니다. API 문서는 API를 사용하고 싶은 개발자를 위한 것이라면 API 스펙은 API를 빌드하고자하는 개발자를 위해 작성된 것입니다. API 스펙은 API가 가진 각각의 동작에 대해 더 상세하게 기재되어 있습니다. API에 포함된 오브젝트, 값, 파라미터는 물론이고 해당 API가 사용하는 데이터 모델에 대한 정보를 담고 있습니다. 즉 API 스펙은 해당 API의 동작 방식과 다른 API와 상호 작용에 대해 상세하게 기술한 문서입니다.\r\r\n\r\r\n![화면 캡처 2024-09-04 154738.png](https://image.toast.com/aaaadh/real/2024/techblog/uD654uBA74%20uCEA1uCC98%2020240904%20154738.png)\r\r\n\r\r\n\r\r\nAPI 스펙은 API를 맨 처음 개발할 때부터 API를 기술하는 API 문서를 제작하는 데 있어 가장 필수적인 도구입니다. API 스펙이 아주 잘 정립되어 있다면 생소한 코드를 분석하는 골치 아픈 일을 건너뛰고 API를 훨씬 더 일관되고 안정적으로 구현할 수 있습니다. 사실 ‘API 스펙’이란 개념이 등장하기 전엔, API 개발하는 과정은 팀마다 회사마다 제각각이고 질서가 없었는데요. 그 결과, 완성된 힘들게 개발한 API를 연동하는 것이 무척 어렵고 복잡하고 비효율적이었습니다. 이는 곧 서비스의 매력도를 크게 떨어뜨리는 결과를 가져오게 되죠.\r\r\n\r\r\n![비교_new1.png](https://image.toast.com/aaaadh/real/2024/techblog/uBE44uAD50new1.png)\r\r\n\r\r\n## OpenAPI의 등장\r\r\n\r\r\n‘API 스펙’이란 개념이 주목받기 시작한 때는 2010년 지금은 너무나 잘 알려진 Swagger가 등장하면서부터입니다. Swagger는 API를 문서화하고, 정의하고 인터랙션 하기 위해 필요한 모든 것을 제공하는 `오픈소스 소프트웨어 프레임워크`인데요. 풀어서 설명하면, Swagger는 RESTful API(웹에서 사용되는 자원을 효율적이고 안정적으로 사용할 수 있게 하는 REST 원칙을 잘 따르는 API)를 설계하고, 빌드하고, 이에 대한 문서도 작성할 수 있도록 하는 도구입니다. 여기에 더해 빌드한 API를 호출해 볼수도 있습니다.\r\r\n\r\r\nAPI를 작성할 수 있다는 점에는 Swagger는 API 정의 언어라고도 하는데요. 다음에 나올 내용에서 계속 등장하니 기억해 주시기 바랍니다.\r\r\nSwagger로 작성한 API 스펙인 Swagger Specification이 API 스펙의 표준으로 널리 사용되었는데, 이후 2015년 Swagger 개발사인 SmartBear가 Swagger Specification을 리눅스 재단 산하의 **오픈API 이니셔티브**에 기부하면서 Swagger Specification은 OpenAPI Specification(OAS)라는 공식 명칭을 가지게 되었고 OAS는 표준 API 스펙으로 자리잡게되었습니다. 오픈 API 이니셔티브는 API 기술하는 방식을 표준화하자는 목표 아래 현재도 활발하게 API 생태계 발전에 기여하고있습니다. 2024년 9월 기준, OAS는 버전 [3.1.0](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.1.0.md) 까지 업데이트되었습니다.\r\r\n\r\r\n다시 말하자면 OpenAPI는 Swagger와 마찬가지로 API 정의 언어(API description language)이며, OpenAPI로 작성한 API 스펙을 OAS(OpenAPI Specification)라고 합니다.\r\r\n\r\r\nOAS는 이제 API 스펙의 표준으로 인식되며 현재 가장 많이 사용되는 API 스펙입니다. OAS를 활용하면 기계가 인식할 수 있는 형태로 API를 설계할 수 있고, 더 나아가 API 문서와 클라이언트 SDK 등을 생성하고 인증과 오류 처리 방법, 보안과 같은 디테일한 정보도 기술할 수 있습니다.\r\r\n\r\r\n## TypeSpec의 등장\r\r\n\r\r\n이렇게 OAS가 API 스펙의 표준으로 굳건하게 입지를 다지는 중에 최근 Microsoft가 새로운 API 정의 언어인 TypeSpec을 출시했습니다.\r\r\nTypeSpec은 Microsoft Graph 개발팀이 마치 코드를 작성하는 것처럼 유연하고 편리하게 API 스펙을 작성하고 싶다는 생각에서 탄생했습니다.\r\r\n\r\r\nAPI 콘퍼런스인 [Nordic APIs](https://www.youtube.com/watch?v=yfCYrKaojDo&t=731s)에서 Microsoft Azure SDK 팀리더는 무수히 많은 문서와 라이브러리를 일관되고 용이하게 관리하기 위해 API 정의 언어로 TypeSpec을 활용한다고 합니다. 내부에서 API와 SDK 문서를 일관되게 관리하기 위한 API 작성 가이드라인이 있지만, Azure 서비스가 급속하게 성장하다 보니 각기 다른 언어로 작성된 API 문서를 효율적으로 관리하기가 어려워졌고 이런 상황에서 TypeSpec으로 API를 정의하면 API 스펙을 크게 간소화할 수 있고, API 가이드라인을 재사용 가능한 코드로 만들면 신규인력도 이를 빠르고 쉽게 적용하여 API 문서를 작성할 수 있다고 하는데요.\r\r\n\r\r\n마치 코드를 작성하는 것과 같이 API 스펙을 작성해서 Design-First 접근법(API 설계 시 API 스펙을 먼저 작성하는 접근법)을 실현하기 위해 TypeSpec을 활발히 사용 중이라고 밝혔습니다.\r\r\n\r\r\n반복해서 나오는 API 정의 언어와 API 스펙의 개념을 구분하면 아래와 같습니다.\r\r\n\r\r\n![자산 2.png](https://image.toast.com/aaaadh/real/2024/techblog/uC790uC0B0%202.png)\r\r\n\r\r\n그렇다면 OpenAPI와 TypeSpec으로 작성한 API 스펙이 어떻게 다른지 한번 살펴보겠습니다.\r\r\n예로 아래와 같이 동작하는 API가 있습니다.\r\r\n\r\r\n### 사용자 관리 API\r\r\n\r\r\n* 사용자 목록 조회(List)\r\r\n* ID로 사용자 단일 조회(Read)\r\r\n* 신규 사용자 생성(Create)\r\r\n* 사용자 정보 수정(Update)\r\r\n* 사용자 삭제(Delete)\r\r\n\r\r\n## OpenAPI vs TypeSpec\r\r\n\r\r\nTypeSpec과 OpenAPI로 각각 사용자 관리 API 스펙을 작성하면 아래와 같습니다\r\r\n\r\r\n![codereview_.png](https://image.toast.com/aaaadh/real/2024/techblog/codereview.png)\r\r\n\r\r\n이 두 API 정의 언어의 장점과 단점은 분명한데요. TypeSpec은 코드를 작성하는 것과 유사하게 API 스펙을 작성할 수 있고, OpenAPI 대비 좀 더 경량화된 언어인 반면, 아직 OpenAPI보다 지원하는 서드파티 툴이 적다는 단점이 있습니다. 또한 OpenAPI는 호환 가능한 툴이 매우 다양하고 관련 생태계가 활성화되어있지만 API의 규모가 커질수록 길이가 너무 길어지고 복잡해지는 단점을 가지고 있습니다.\r\r\n\r\r\nTypeSpec은 OpenAPI를 완벽히 대체하기는 어려울 것이라는 의견도 있습니다만, 그보다 TypeSpec을 활용해 코드를 작성하는 것처럼 재사용 가능하고 확장 가능한 API 스펙을 만들 수 있고, OpenAPI 툴 체인과 쉽게 연동이 가능하여 이는 결국 API 생태계를 더욱 풍성하게 만들 것이란 의견이 많습니다.\r\r\n\r\r\nTypeSpec과 OpenAPI와 같은 API 정의 언어로 API 스펙을 작성할 때 누릴 수 있는 이점을 정리해 보면 아래와 같습니다.\r\r\n\r\r\n* 일관성\r\r\n    * API 스펙, 즉 API 규격이 잘 정립되어 있다면, 신규 API가 출시되었을 때, API 스펙에 부합하는지를 검증할 수 있습니다. 이로써 API의 작동 방식을 더욱 빠르고 쉽게 이해할 수 있습니다.\r\r\n    * API들이 일관된 규격에 맞게 설계되므로, 이는 백엔드 개발자와 프론트엔드 개발자 간 커뮤니케이션을 매끄럽게 만들어줍니다.\r\r\n* 문서 자동화\r\r\n    * Swagger 같은 API 문서 자동화 툴과 호환할 수 있어, API 문서에 포함된 API 엔드포인트를 즉시 테스트해 볼 수 있습니다.\r\r\n* 쉬운 유지 보수와 테스트\r\r\n    * 일관된 규격에 맞게 설계된 API는 물론 그렇지 않은 API보다 이해하기가 더 쉬우므로, API 업데이트 혹은 버전업을 더 빠르게 수행할 수 있습니다.\r\r\n\r\r\n## 나가며\r\r\n\r\r\nAPI 가이드와 API 스펙은 평소 자주 혼용되어 그 개념을 정확히 알고자 이렇게 기술 공유 글을 작성하게 되었는데요, 이번 계기로 API 스펙이 API 문서와 어떻게 다른지 알 수 있었습니다.\r\r\n비즈니스 관점에서 잘 작성된 API 스펙과 API 가이드는 API가 약속한 대로 작동할 것이라는 계약서와 같은 역할을 하고 이는 신뢰성과도 직결되는데요, 더 나아가 완성도 있는 애플리케이션 구축의 토대가 된다는 점을 고려하면 앞으로 API 스펙의 중요성은 커질 것입니다. 긴 글 읽어주셔서 감사합니다.\r\r\n\r\r\n## 참고자료\r\r\n\r\r\n* [https://nordicapis.com/what-is-an-api-definition/](https://nordicapis.com/what-is-an-api-definition/)\r\r\n* [https://swagger.io/resources/articles/difference-between-api-documentation-specification/](https://swagger.io/resources/articles/difference-between-api-documentation-specification/)\r\r\n* [https://github.com/OAI/OpenAPI-Specification/blob/main/examples/v2.0/json/petstore-expanded.json](https://github.com/OAI/OpenAPI-Specification/blob/main/examples/v2.0/json/petstore-expanded.json)\r\r\n* [https://medium.com/another-integration-blog/your-api-specification-is-not-your-api-documentation-4dcc33d23823](https://medium.com/another-integration-blog/your-api-specification-is-not-your-api-documentation-4dcc33d23823)\r\r\n* [https://www.moesif.com/blog/technical/api-design/Benefits-of-using-the-OpenAPI-Swagger-specification-for-your-API/](https://www.moesif.com/blog/technical/api-design/Benefits-of-using-the-OpenAPI-Swagger-specification-for-your-API/)\r\r\n* [https://blog.postman.com/openapi-vs-swagger/](https://blog.postman.com/openapi-vs-swagger/)\r\r\n* [https://www.youtube.com/watch?v=yfCYrKaojDo&t=731s](https://www.youtube.com/watch?v=yfCYrKaojDo&t=731s)\r\r\n\r\r\n![footer.png](https://image.toast.com/aaaadh/real/2024/techblog/footer.png)",
        "isoDate": "2024-09-11T00:44:35.000Z"
      }
    ]
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "이한",
    "category": "개인",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "분위기",
        "link": "https://www.thestartupbible.com/2024/09/the-vibe.html",
        "pubDate": "Wed, 11 Sep 2024 19:00:00 +0000",
        "content:encodedSnippet": "우린 매주 화요일 오전에 전체 주간 미팅을 하고, 이때 현재 투자 검토하고 있는 회사들에 대한 이야기를 하고 결정하는 투자심의위원회(투심위) 미팅도 같이한다. 다양한 경로를 통해서 알게 된 회사들에 대해서 각자의 의견을 들어보고, 투자할지 말지 결정하는데, 모든 사업이 다르고, 비슷한 사업이라도 창업자가 다르기 때문에, 결정의 결과는 항상 다르다.\n내가 얼마 전에 어떤 회사에 대해서, “비즈니스모델은 괜찮은 것 같은데, 그 창업가의 분위기가 좀 별로였다.”라는 굉장히 애매모호하고, 주관적이고, 비과학적인 발언을 했는데, 참 신기하게도 이 말에 동의하는 분이 몇 명 있었다. 어쨌든, 꼬집어서 그 이유를 정확하게 말할 순 없었지만, 뭔가 느낌이 좋지 않았던 그런 미팅이었다. 결국 우린 이 회사를 더 이상 검토하지 않았는데, 이 전에도 우린 분위기가 이상하거나, 이보다 더 애매모호하게 “느낌이 쎄해서” 그냥 겉으로 보면 괜찮은 사업 같은데 한 번의 미팅 이후에 더 이상 검토를 하지 않은 곳들이 꽤 있었다.\n한 사람과 이야기를 해보면, 이 사람이 지금까지 살아온 인생이 다양한 방식으로 표출된다. 어떤 사람은 이게 인상에서 어느 정도 보이고, 어떤 사람은 말투에서 이분이 어떤 성향의 사람이고 지금까지 어떤 인생을 살아왔는지 대략 느껴진다. 그리고 조금 더 미팅하면서 더 다양한 말을 섞어보면, 옷차림, 인상, 눈빛, 몸짓, 목소리, 단어 하나하나 등을 통해서 이 사람의 에너지와 분위기가 느껴진다. 우린 온갖 종류의 창업가들을 매일 다양하게 많이 만나는데, 더 많은 사람을 만날수록 이분들의 성공 가능성을 예측할 수 있는 정확도가 향상되진 않는다. 이렇게 되면 너무 좋겠지만, 사람은 정말 복잡한 생명체라서 어디로 튈지 모르기 때문에 솔직히 말해서 우리의 판단이 틀리는 경우가 더 많다. 하지만, 그 사람의 분위기가 좋은지 안 좋은진 정확하게 판단할 수 있다고 믿고 있다.\n창업가들과 10분 정도만 이야기해 봐도 이분들이 정말로 본인이 하는 사업에 확신이 있는지, 모든 사람들이 반대해도 계속 이 사업을 할 의지가 있는지, 그리고 정말로 투자를 받고 싶은 의지가 있는지 꽤 정확하게 파악할 수 있다. 위에서 내가 말 한 그런 다양한 외부의 시그널이 이 창업가의 내면의 의지를 꽤 정확하게 반영하는데, 이런 걸 통틀어서 종합한 게 이 글에서 말하고자 하는 그 분위기이다. 내가 전에 우린 창업가들의 거창한 것보단, 매우 작은 것들을 관찰한다고 했는데, 이 작은 것들도 분위기랑 밀접한 연관이 있다.\n나도 투자자들을 만날 땐, 평소보다 이 내면의 에너지에 신경을 많이 쓴다. 우리가 창업가들과 10분만 이야기해도, 분위기를 금방 느낄 수 있듯이, 우리 같은 펀드에 출자하는 LP들도 나랑 10분만 이야기해 보면, 내가 긍정적인 에너지를 분출하는 바이브를 형성하는 사람인지 아닌지 금방 파악 가능할 것이고, 실은 거기서 우리에게 돈을 줄지 안 줄지 바로 결정이 나는 것이다. 참고로 에너지 레벨이 높다는 게, 동작이 과격하고 목소리가 큰 게 아니다. 조용하고 차분해도 긍정적인 분위기는 그대로 상대방에게 다양한 방식을 통해서 전달된다.\n그래서 나는 모든 중요한 일을 할 때, 내가 기분이 좋아야 하고, 내 내면의 분위기가 긍정적이어야 하고, 내 에너지 레벨이 높아야 한다고 생각한다. 가장 좋은 방법은 루틴을 반복하는 것이다. 잘 자고, 잘 운동하고, 잘 먹어야 한다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/09/the-vibe.html#respond",
        "content": "우린 매주 화요일 오전에 전체 주간 미팅을 하고, 이때 현재 투자 검토하고 있는 회사들에 대한 이야기를 하고 결정하는 투자심의위원회(투심위) 미팅도 같이한다. 다양한 경로를 통해서 알게 된 회사들에 대해서 각자의 의견을 들어보고, 투자할지 말지 결정하는데, 모든 사업이 다르고, 비슷한 사업이라도 창업자가 다르기 때문에, 결정의 결과는 항상 다르다. 내가 얼마 전에 어떤 회사에 대해서, “비즈니스모델은 괜찮은 것(...)",
        "contentSnippet": "우린 매주 화요일 오전에 전체 주간 미팅을 하고, 이때 현재 투자 검토하고 있는 회사들에 대한 이야기를 하고 결정하는 투자심의위원회(투심위) 미팅도 같이한다. 다양한 경로를 통해서 알게 된 회사들에 대해서 각자의 의견을 들어보고, 투자할지 말지 결정하는데, 모든 사업이 다르고, 비슷한 사업이라도 창업자가 다르기 때문에, 결정의 결과는 항상 다르다. 내가 얼마 전에 어떤 회사에 대해서, “비즈니스모델은 괜찮은 것(...)",
        "guid": "https://www.thestartupbible.com/?p=9214",
        "categories": [
          "Uncategorized",
          "fundraising",
          "general",
          "people",
          "Strong",
          "vc"
        ],
        "isoDate": "2024-09-11T19:00:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "노가다에 대해서",
        "link": "https://www.thestartupbible.com/2024/09/not-scalable-until-scalable.html",
        "pubDate": "Sun, 08 Sep 2024 19:03:02 +0000",
        "content:encodedSnippet": "투자자나 창업가나 스케일에 대한 이야기를 자주 한다. 우리가 자주 하는 질문은 과연 특정 사업이 얼마나 빠르게, 그리고 얼마나 효율적으로 성장이 가능할까인데 영어로 이 질문을 하면 “이 비즈니스가 얼마나 scalable 할까?” 정도가 되지 않을까 싶다.\n대부분의 유니콘 회사가 아주 빠르게 성장을 했고, 스케일이라는 말을 스타트업 분야에서 워낙 많이 사용하기 때문에, 많은 창업가들이 이 단어에 집착한다고 난 생각한다. 아주 효율적으로, 아주 빠르게 성장하는 건 당연히 좋고, 투자자로서 나도 스케일이 가능한 사업을 발견하면 좋아하지만, 솔직히 말해서 쉽게, 그리고 빠르게 성장할 수 있는 비즈니스는 요새 정말 찾기 힘들다. 나는 오히려 이런 비즈니스가 있다고 하면 약간 의심하고, 너무 많은 창업가들이 필요 이상으로 스케일이라는 말에 집착하는 것 같다.\n최근에 워낙 경기가 안 좋다 보니, 많은 창업가들이 성장보단 생존에 집중하고 있는데, 계속 성장을 하고 싶어 하는 창업가들은 이런 상황이 죽고 싶어질 정도로 답답할 것이다. 우리 투자사 대표 몇 분은 이런 답답함과 짜증 남에 대해서 우리랑 편안하게 자주 이야기하는 편인데, 최근에 했던 이런 대화가 기억난다. B2B 제품을 만들고 있는데 영업 속도가 느리고 매출 성장이 너무 더뎌서 매우 초조해하고 스트레스 받고 있는 분과의 미팅이었다.\n일단, 기업에 판매할 B2B 제품은 소비자에게 직접 판매하는 B2C 제품보단 주로 시간과 노력이 많이 들어간다. 우리가 투자한 어떤 B2B SaaS 회사들은 제품만 만드는 데 1년이 걸리는 경우도 있다. 이렇게 힘들게 제품을 만들었는데, 이 제품을 기업 고객에게 판매하는 건, 더 힘들고 시간이 많이 필요하다. 첫 번째 B2B 고객을 확보하기 위해서 한 달 이상 영업하는 경우도 자주 보는데, 이렇게 해서 확보한 고객에게 발생하는 매출은 기대 이하이다. 이분은 이런 식으로 하면, 일 년 열심히 영업해도 유료 고객이 15개도 안 될 것이고, 이들로부터 나오는 매출도 크지 않아서, 과연 내가 맞는 방법으로 사업을 하고 있는지, 이렇게 고객 한 명 한 명씩 영업하는 방법이 맞는 건지 스스로에 대한 불신이 있었다. 그리고 주위에서 ‘미친 성장’을 하는 다른 스타트업같이 아주 효율적으로 노가다 없이 스케일 할 수 있는 방법에 대해 깊은 고민을 하고 있었다.\n나는 개인적으로 이 회사는 아주 잘될 것이라고 믿는다. 내 솔직한 의견은, B2C 제품이나, B2B 제품이나, 노가다 없이 스케일 할 수 있는 방법은 없다. 언론에서는 마치 쉽게 사업을 확장하고, 스케일이라는 말을 모든 스타트업이 가져야 할 필수 덕목같이 포장하는데, 나는 큰 스케일은 수많은 작은 노가다가 축적될 때 나올 수 있다고 생각한다. 요샌 웬만한 사람들이 다 사용하는 드롭박스 같은 제품도 사업 초반에는 창업자가 직접 지인들 사무실을 방문해서 이들의 PC에 제품을 설치해 주고, 사용법을 가르쳐주면서 성장했고, 에어비앤비도 창업자들이 직접 호스트의 숙소를 방문해서 사진을 찍어서 대신 올려주면서 성장했다. 우리 투자사 당근도 판교에서 아주 작게 시작했는데, 창업자들이 직접 물건을 하나씩 올려서 판매하면서 시작했다.\n동네 가게를 위한 B2B 제품을 만들고 있다면, 우리가 만든 제품을 어떻게 하면 최소한의 노력으로 가장 많은 동네 가게 사장님들에게 한 방에 크게 노출할 수 있는지 고민할 시간에, 그냥 하루 종일 동네 가게 문 두드리고 찾아가서 영업하는 게 맞는 방법이라고 생각한다. 이렇게 하루 종일 뚜벅뚜벅 걸어 다니면서 고객의 목소리를 직접 듣고, 이들에게 직접 제품을 설치해 주다 보면, 진짜 사업에 대해서 배울 수 있고, 세상이 정확히 어떻게 돌아가는지 몸으로 배우게 된다. 그러면서도 이렇게 고객 한 명씩 상대하면서 노가다 작업을 하는 게 맞는 방법인지 계속 스스로 의심하겠지만, 고객 한 명이 두 명이 되고, 두 명이 다섯 명이 되고, 다섯 명이 50명이 되면서, 그때부터 사업엔 스케일이 생길 것이다. 하지만, 스케일이 생기기 전 까진 그냥 옛날 방식대로 하나씩 해야 한다. 소위 말하는 노가다를 뛰어야 한다.\n스케일은 가만히 책상에 앉아서 손가락으로 만들어지지 않는다. 직접 발로 뛰어야 하고, 이런 노가다를 계속하다 보면 어느 순간 큰 스케일이 만들어진다. 대신, 멈추지 말고 계속 해야 한다. 내가 이전 포스팅에서도 말했지만, 세상의 모든 큰 일은 아주 작은 일을 계속하는 것에서 시작된다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/09/not-scalable-until-scalable.html#comments",
        "content": "투자자나 창업가나 스케일에 대한 이야기를 자주 한다. 우리가 자주 하는 질문은 과연 특정 사업이 얼마나 빠르게, 그리고 얼마나 효율적으로 성장이 가능할까인데 영어로 이 질문을 하면 “이 비즈니스가 얼마나 scalable 할까?” 정도가 되지 않을까 싶다. 대부분의 유니콘 회사가 아주 빠르게 성장을 했고, 스케일이라는 말을 스타트업 분야에서 워낙 많이 사용하기 때문에, 많은 창업가들이 이 단어에 집착한다고 난(...)",
        "contentSnippet": "투자자나 창업가나 스케일에 대한 이야기를 자주 한다. 우리가 자주 하는 질문은 과연 특정 사업이 얼마나 빠르게, 그리고 얼마나 효율적으로 성장이 가능할까인데 영어로 이 질문을 하면 “이 비즈니스가 얼마나 scalable 할까?” 정도가 되지 않을까 싶다. 대부분의 유니콘 회사가 아주 빠르게 성장을 했고, 스케일이라는 말을 스타트업 분야에서 워낙 많이 사용하기 때문에, 많은 창업가들이 이 단어에 집착한다고 난(...)",
        "guid": "https://www.thestartupbible.com/?p=9206",
        "categories": [
          "Uncategorized",
          "B2B",
          "FoundersAtWork",
          "hustle",
          "inspiring",
          "unicorn",
          "스타트업 바이블 1",
          "스타트업 바이블 2",
          "스타트업 바이블 QA"
        ],
        "isoDate": "2024-09-08T19:03:02.000Z"
      }
    ]
  },
  {
    "name": "Build a Great Product",
    "category": "개인",
    "posts": []
  },
  {
    "name": "지금 써보러 갑니다",
    "category": "개인",
    "posts": []
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": [
      {
        "creator": "kimchihill",
        "title": "Tomasz Tunguz’s AI Sales Playbook: Insights from the Field",
        "link": "https://kimchihill.com/2024/09/13/scaling-gen-ai-sales/?utm_source=rss&utm_medium=rss&utm_campaign=scaling-gen-ai-sales",
        "pubDate": "Fri, 13 Sep 2024 11:37:42 +0000",
        "content:encodedSnippet": "Tomasz Tunguz’s recent article on selling AI and software struck a chord with me. As AI adoption grows, both buyers and sellers are facing new challenges—especially around scaling and discovery. Below are my thoughts on his key points, based on my live experiences selling the AI chatbot at Sendbird, and how they relate to what we’re seeing in the market. Check out the full article here: https://tomtunguz.com/software-playbook \nSelling AI is being discovered because the technology is new. Buyers don’t know how to use it or how to buy it.\nI fully agree with this and would emphasize it from two perspectives: selling to both enterprises and SMBs comes with discovery challenges. For enterprises, based on various studies and papers I’ve read, many buyers struggle with scaling their generative AI projects after initial adoption. They face issues expanding AI usage beyond a single application and unlocking its full potential while managing risks. For SMBs, there is still a significant technology and discovery gap. Similar to blockchain, the jargon and user interfaces of most generative AI applications remain too technical, and the product—as well as the introduction of the service—needs to be more user-friendly.\nBecause the sales motions are new, we can’t apply the previous playbook to the new sales process. The CEO/founder should hire a sales leader that they fully trust who focuses on ultimate success. The sales process is a part of the product.\nI strongly agree that the sales process is integral to the product experience. Beyond self-serve onboarding, we must also offer an easy pathway for mid-market and enterprise users to engage with our sales or technical teams when needed. Even during the sales demo, we can start by showcasing a prototype chatbot tailored to the prospect’s website. This not only accelerates technical due diligence but also delivers a faster ‘wow’ moment. The sales and product experience should be tightly integrated.\nBetween PLG vs. sales-led, more companies were sales-led. If starting with PLG, the template sells the product. Fight the empty box problem with great concrete templates that demonstrate how to use AI. If selling top-down, most of the conversations today are at the C-suite rather than the mid-market predominantly because the buying process is new.\nI firmly believe in this. Our platform, paired with strong templates, can effectively sell our AI chatbot product. For example, offering a user-friendly graphical interface for prompt templates instead of relying on text-based ones allows prospects to grasp the product’s potential without much technical effort. However, I remain cautious about top-down selling. If our SaaS product or PMF isn’t fully ready, customization efforts could disrupt our PLG motion. I’m not against taking on SI roles, but we must ensure we don’t become an SI company at our core.\nFiguring out how to consistently produce wow moments with non-deterministic software is essential.\nAbsolutely. This is a key focus for our product and marketing teams, and one of our OKRs this quarter is to improve conversion rates by driving consistent wow moments for our users.\nThe room was split on the pricing model: seats, usage, or some hybrid. Ultimately, pricing captures 15-30% of the value the software/AI creates. Developing a strong case for this with buyers will be key because the ROI question from buyers is real, especially as the broader software market feels pressure.\nValue-based pricing is an excellent approach, but we also face perception challenges. Many customers still view AI products through the lens of past investments, like seat-based pricing models and ROI measured by traditional KPIs, such as cost per inbound/outbound call. We need to pioneer new value-based pricing anchors for AI, and while the challenges are significant, I’m ready to face them head-on.\nOnly VCs care about the word agents/agentic: for most enterprises, agents mean a customer support agent. Many teams don’t care about the underlying technology; they seek a solution to their problem.\nAgreed. We’re still refining our ICP. We’re seeing enterprise leads from Heads of Data Science who have developed their own LLMs but now seek alternatives like Sendbird, where they can achieve faster value. At the same time, Heads of CS/CX are looking to solve business challenges but are frustrated by stalled internal projects.\nThe post Tomasz Tunguz’s AI Sales Playbook: Insights from the Field appeared first on Kimchi hill.",
        "dc:creator": "kimchihill",
        "comments": "https://kimchihill.com/2024/09/13/scaling-gen-ai-sales/#respond",
        "content": "<p>Tomasz Tunguz&#8217;s recent article on selling AI and software struck a chord with me. As AI adoption grows, both buyers and sellers are facing new challenges—especially around scaling and discovery. Below are my thoughts on his key points, based on my live experiences selling the AI chatbot at Sendbird, and how they relate to what<a class=\"more-link\" href=\"https://kimchihill.com/2024/09/13/scaling-gen-ai-sales/\">Continue reading <span class=\"screen-reader-text\">\"Tomasz Tunguz&#8217;s AI Sales Playbook: Insights from the Field\"</span></a></p>\nThe post <a href=\"https://kimchihill.com/2024/09/13/scaling-gen-ai-sales/\">Tomasz Tunguz’s AI Sales Playbook: Insights from the Field</a> appeared first on <a href=\"https://kimchihill.com\">Kimchi hill</a>.",
        "contentSnippet": "Tomasz Tunguz’s recent article on selling AI and software struck a chord with me. As AI adoption grows, both buyers and sellers are facing new challenges—especially around scaling and discovery. Below are my thoughts on his key points, based on my live experiences selling the AI chatbot at Sendbird, and how they relate to whatContinue reading \"Tomasz Tunguz’s AI Sales Playbook: Insights from the Field\"\nTomasz Tunguz’s AI Sales Playbook: Insights from the Field appeared first on Kimchi hill.",
        "guid": "https://kimchihill.com/?p=2773",
        "categories": [
          "English essay"
        ],
        "isoDate": "2024-09-13T11:37:42.000Z"
      }
    ]
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "정신과 병원 처음 가면 치료비 얼마일까?",
        "link": "https://blog.toss.im/article/monthly-tosspick-2024-8",
        "pubDate": "Fri, 13 Sep 2024 00:36:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}세계 최고를 기록하는 우리나라 자살률이 지난해보다 10% 더 늘었습니다. 보건복지부에 따르면 올해 1월부터 5월까지 6,375명이 스스로 생을 마감했으며, 이는 지난해 같은 기간보다 10.1% 증가한 수치라고 합니다. 지난 한 해 동안 자살로 생을 마감한 사람은 모두 1만 3,770명.  2020년 이후 가장 높은 수치인데요. 올해는 작년보다 자살 사망자 수가 더 늘어날 것으로 예측됩니다.\n우리나라는 오랜 기간 ‘OECD 자살률 1위'라는 꼬리표를 달고 있습니다. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}21년 동안, 단 두 번을 제외하고 줄곧 자살률 1위를 차지하고 있죠.* 결코 익숙해지거나, 무뎌져서는 안 될 불명예입니다. 자살 원인 중 큰 비중을 차지하는 것은 ‘정신적 문제'입니다.** 건강한 정신과 마음은 ‘내 삶'을 잘 살아내기 위해 필요하지만, 마음의 건강을 돌보는 일은 더 이상 개인의 영역이 아닌 사회와 국가의 과제로 인식되고 있습니다.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*2016년과 2017년에는 리투아니아가 자살률 1위, 우리나라는 2위를 기록했다. \n**정부 분석에 따르면, 2021년 자살 원인 중 정신적 문제가 38.9%로 가장 큰 비중을 차지했다.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}마음이 무너질 때 발생하는 경제적 손실\n세계보건기구(WHO)는 사람들의 불안과 우울을 제때 치료하지 않으면, 국내총생산이 4%가량 감소하는 것으로 추정합니다.* 정신건강 문제는 생산력 저하, 직장생활자의 경우 결근, 병가, 실직, 퇴사 등으로 이어지기 때문인데요. 2009년 고용노동부는 우울증을 겪는 근로자 1인당 결근으로 연간 252만 원, 비효율 근무로 연간 488만 원의 비용 손실이 있다고 발표하기도 했었죠.\n*2023 세계보건기구(WHO)와 국제노동기구(ILO)가 발표한 '직장 노동자들에 대한 정신 건강 관리 지침'\n정신건강 문제를 경제적 관점에서 바라보는 일이 낯설게 느껴질지 모릅니다. 하지만 마음의 건강을 지키지 못하면, 우리의 삶을 지탱하는 가장 기본적인 경제활동도 함께 무너지게 됩니다. 근로소득을 위해 일터로 향하거나, 소비로 작지만 확실한 행복을 챙기는 일상적인 일들이 어렵고 힘들어집니다. 때문에 많은 국가들은 정신건강을 국가 차원의 문제로 인식하고 투자하고 있죠.\n영국은 올해 국민 정신건강 프로그램 예산을 늘려 11억 파운드(약 1조 9,200억 원) 투자합니다. 더 많은 사람들이 치료를 받을 수 있도록 하고, 한 사람이 받는 치료의 횟수를 늘리는 데 집중한다고 해요. 노르웨이의 경우, 국민 정신건강을 증진시키기 위한 프로그램에 투자해 취업률을 높였고, 사회복지비용이 줄면서 투자대비 3.6배의 경제적 이익을 얻기도 했습니다.\n우리나라도 2021년부터 5년간 정신건강 분야에 약 2조 원을 투자하겠다는 계획을 발표했습니다. 우울과 불안을 겪는 사람들을 위한 심리상담 서비스 ‘전국민 마음투자' 지원을 16만 명까지 늘리고, 자살을 시도한 청년은 소득수준과 관계없이 치료비를 지원하고, 24시간 전문상담 운영 등의 노력이 이어지고 있습니다.\n매월 하나의 키워드를 선정해 경제적 시선으로 질문을 던져보는 <월간 토스픽>. 이번 달에는 정신의학과 전문의와 함께 우리 마음을 건강하게 돌보기 위해서 필요한 비용과 방법에 대해 이야기 나눠봅니다.\n\n\n정신과 병원 처음 가면 치료비 얼마일까?\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n🎙️ Interviewee .css-wi4a2c{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;font-weight:bold;}정신과의사 뇌부자들\n\n정신건강의학과 전문의 김지용, 오동훈, 허규형이 ‘진짜 정신과 이야기’를 전하는 유튜브 채널. 정신과에 대한 편견을 낮추고자 2017년 팟캐스트 채널로 활동을 시작, 현재는 유튜브로 무대를 옮겨서 활동 중이다. 정신질환에 대한 정확한 정보를 전달해 오해를 바로 잡는 것부터 드라마나 영화 속 캐릭터 분석, 특정한 행동에 담긴 사람들의 심리까지 다양한 주제를 쉽고 편안하게 풀어낸다.\n\nQ1. 일상을 살다가 어떤 증상이 있을 때 마음 건강을 체크하면 좋을까요? ‘병원에 가야 할 때’의 기준이 있나요?\n오동훈(이하 ‘동훈'): 마음 건강의 이상 징후는 다양하게 나타납니다. 우울증을 예로 들면 기분의 저하를 직접적으로 느끼는 사람도 있지만, 피로감이나 에너지가 달린다는 느낌으로 나타나기도 하죠. 그래서 ‘이 증상이 있을 때'라고 한 가지를 꼽기는 쉽지 않습니다. 다만 정신과 질환을 진단할 때 공통적으로 적용하는 기준은 ‘사회적, 직업적 기능에 이상이 생겼을 때'예요.\n사회적 기능의 이상이란 평소보다 더 사람들을 만나고 싶지 않아서 대인관계를 피한다든지, 신경이 날카로워져서 다른 사람들과 트러블이 늘어난다든지 하는 변화를 말합니다. 직업적 기능의 변화는 업무 효율이 부쩍 떨어지고, 제시간에 출근을 못해서 부정적인 평가를 반복적으로 받는 것이 예시이고요. 이런 문제가 자꾸 생기면 마음에 이상이 생기지 않았나 고민해볼 필요가 있습니다. 가능하다면 믿을 만한 사람에게 직접 털어놓고 의견을 들어보는 것도 방법이에요. 내가 캐치하지 못한 부분을 주변에서는 이미 인지하고 있기도 합니다.\n김지용(이하 ‘지용'): 예전에 이 질문에 대해서 허규형 선생님이 했던 대답이 인상적이어서 저도 자주 쓰는데, ‘가야 되는 건가?’라는 생각이 들 때면 가야 할 때라고 생각합니다. 몸 어딘가가 아프면 스스로 정확한 병명을 몰라도 내과, 이비인후과, 정형외과 등에 자연스럽게 가서 진료를 먼저 받아보게 되죠. 그리고 별 문제 아니란 얘기를 들으면 정말 다행이라고 여기며 홀가분하게 나오고요. 그런데 정신과는 심리적 문턱이 높다 보니까 고민하시다가 초기에 치료할 타이밍을 놓치는 경우가 많습니다.\n허규형(이하 ‘규형'): 세 가지 변화가 있으면 고민이 필요해요..css-1swx3yz{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;font-weight:bold;} 수면의 변화, 식욕의 변화, 흥미의 변화입니다. 평소 내 패턴과 비교해서 잠이 너무 안 오거나 너무 많이 잘 때, 입맛이 너무 없거나 너무 많이 먹을 때, 재밌게 하던 것들에서 재미를 느끼지 못할 때는 점검해보시기 바랍니다.\nQ2. 온라인상에 ‘우울증 자가진단 체크리스트' 같은 것이 떠돌아 다니는데, 신뢰할 만한가요?\n규형: 출처가 불분명한 체크리스트만으로 속단하는 것은 조심하셔야 하고요, 검색해서 나오는 것 중 우울증 진단에 사용하는 ‘CES-D, PHQ-9’, ADHD 진단에 쓰는 ‘ASRS’는 저작권 없이 해볼 수 있는 검사 중에 추천할 만한 것들입니다. 보건복지부 국립정신건강센터에서 운영하는 .css-1ly3pih{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey800);background-color:#3fd59936;-webkit-text-decoration:underline!important;text-decoration:underline!important;}국가정신건강정보포털이라는 웹사이트가 있는데요, 거기서 질환별 자가검진을 해보는 것도 추천드려요.\n지용: 마음이 힘들 때 체크리스트를 이용해 스스로를 돌아보는 것은 나쁘지 않다고 생각합니다. 대부분 DSM이라는, 정신과에서 사용하는 진단 편람상 등재된 기준을 바탕으로 만들어져 있어서 어느 정도 스크리닝하는 데 도움이 될 수 있어요.\n그런데 솔직히 정신과 진단은 간단한 일이 아닙니다. 전문가들도 헷갈릴 때가 많고, 오래 진료를 받아온 환자의 진단이 나중에 바뀌는 경우도 있지요. 같은 증상이라도 다양한 질병에서 비롯됐을 수 있기 때문에 테스트 결과는 ‘내가 의사를 한 번 만나봐야 하는 상태구나'라는 정도로 받아들여주시면 좋겠습니다.\nQ3. 마음건강 관리에 있어 우리나라 사람이 유독 힘들어하는 요인이 있는지요?\n동훈: 예전보다 많이 나아졌지만 여전히 정신과적 문제를 ‘의지의 문제'로 취급하는 경향이 남아 있어요. 그래서 우울증 같은 병이 생겨도 내가 나약해서 생긴 문제라고 생각해 병원 찾는 것을 미루고, 진단을 받아도 치부를 들킨 것처럼 부정하거나 치료를 거부하는 모습을 보입니다.\n그런데 다른 병들처럼 우울증도 증상 발생 후 얼마나 빨리 치료받느냐가 예후에 영향을 많이 미쳐요. 미룰수록 치료가 어렵고 회복에 더 긴 시간이 필요한 것도 똑같고요. 우리가 감기에 걸렸을 때 나약해서 생긴 거라고 생각하지 않듯이, 마음의 문제 또한 치료받아야 하는 질환으로 받아들여야 합니다.\n지용: 대부분 정신과 질환에는 수면 문제가 동반되고, 회복을 위해서는 충분한 수면 시간이 필요해요. 위에서 말씀하셨듯 정신질환은 의지의 문제가 아니라 뇌의 문제이기 때문이죠. 뇌과학 연구에 의하면 사람들의 99%는 7~9시간 사이가 적정 수면시간이라고 해요. 7시간 미만은 안 잔 것과 비슷하다는 연구 결과도 있고요. 그런데 우리나라 평균 수면 시간은 꾸준히 세계 최하위권으로, 7시간 미만으로 보고됩니다. 우리나라는 충분히 자는 것을 게으르다고 보는 시각이 있고, 스스로도 죄책감을 가지는 경우가 많아요. 수면 부족은 우리가 간과해온 정신질환 발병의 큰 원인이 될 수 있습니다.\nQ4. 처음 병원에 가면 어떤 방법으로 진료를 받게 되나요?\n동훈: 첫 진료(초진) 시에는 내원 목적과 심리 상태를 파악하기 위해 일정 분량의 설문지를 작성해요. 그러고 나서 응답 내용을 바탕으로 약 40분 정도 상담을 진행하고요. 지금 가진 가장 큰 불편함은 무엇인지, 언제부터 시작되었는지, 거기에 영향을 준 스트레스나 외부적 요인은 어떤게 있었는지 등을 면담을 통해 파악하고 진단을 내리게 됩니다.\n한 번의 면담으로 충분한 정보를 얻기 어렵다면 추가적인 세션을 갖거나, 심리검사를 진행해서 보다 정확하게 진단을 내리기도 해요. 면담 혹은 검사 결과를 바탕으로 치료 계획을 세우고 그에 맞춰서 실제 치료를 진행하게 되는데, 보통 초진 이후의 진료는 20분 내외로 진행되고 병원에 오시는 주기는 치료 경과에 따라 1~4주 사이에서 정합니다.\n지용: 지금까지 말씀드린 절차는 저희가 근무한 병원을 기준으로 한 것이고, 같은 개인 정신과 의원이라고 할지라도 병원마다 진료 방침과 절차가 다를 수 있어요. 저희 셋도 서로 약간씩 다르거든요. 짧게 증상만 물어보고 약물 처방 위주의 3분 진료를 위주로 진행되는 곳도, 충분한 상담시간을 두는 것을 목표로 하는 곳들도 있죠. 꼭 어디가 좋다 쉽게 정의내릴 수 없는 것이, 환자들도 각자 선호하는 스타일이 달라요. 저는 충분히 얘기 나눠보고 싶은데 그걸 불편해하시고 빠른 처방을 바라시는 분들도 꽤 계시거든요. 그래서 가장 좋은 건 방문하고자 하는 병원에 미리 문의를 하는 거예요. 초진 시간은 보통 얼마나 되는지, 기본적으로 진행되는 검사가 있는지, 대강의 진료비가 어떻게 되는지 등에 대해 알아보시면 좋겠습니다.\nQ5. 정신과 진료비나 치료비는 보통 얼마쯤 예상하면 될까요?\n규형: 치료비도 일괄적으로 말씀드리기는 어려워요. 치료 옵션이 다양하고, 면담 시간이나 기법 등에 따라 비용이 세분화되어 있기 때문이죠. 또 기관의 규모가 의원급인지, 대학병원 같은 상급 종합병원인지에 따라서도 환자가 지급해야 하는 부담률에 차등이 있어요.\n그래도 대략적인 선을 말씀드리자면 상담과 약물 처방을 포함해 초진 시에는 4~5만 원, 재진 시에는 2만 원대 정도를 생각하시면 됩니다. 심리 검사의 경우도 어떤 검사들이 포함되었는지 그 구성에 따라 20만 원대부터 40만 원대까지 다양해요.\nQ6. 정신과 치료는 의료보험과 실비보험 적용이 되나요?\n지용: 정신과 치료도 내과, 소아과 등 다른 의료 영역과 마찬가지로 건강보험 적용을 받아요. 뿐만 아니라 다른 과에 비해 환자가 부담해야 하는 비급여 영역이 굉장히 적은 편입니다.\n실비보험 적용되는지도 진료실에서 종종 질문을 받는데요, 가입한 상품마다 보장 범위가 달라서 바로 대답해드리기는 어려웠어요. 예전에는 정신과 치료가 기간이 오래 걸리고 예후가 좋지 않다는 이유로 대부분의 보험 상품에서 배제되는 경향이 강했지만, 금융감독원에서 실손보험 표준약관을 개선한 뒤로는 보장해주는 상품이 예전보다 늘어났습니다.\nQ7. 정신과 진료 기록이 나에게 불리하게 활용될 일, 정말 없을까요?\n동훈: 정신과 진료 기록은 본인 외에 가족을 포함해서 누구도 임의로 열람할 수 없어요. 면담 시 이야기한 것을 기록하는 진료기록부는 내용 또한 타 병원이나 건강보험공단에도 전송되지 않고요. 특정 질병으로 진료를 받았다는 질병 코드는 건강보험에 이력이 남지만 타인이 조회하는 것은 불가능합니다.\n몇몇 분들이 걱정하는 것처럼 입시나 취업 과정에서 불이익을 받을 가능성도 거의 없어요. ‘거의'라고 표현한 것은 국정원, 항공사 파일럿처럼 일부 특수 직군의 경우 본인의 동의를 얻어 정신과 치료 이력을 조회하기 때문입니다.\nQ8. 정신과 약은 의존성이 높아 평생 먹어야 한다는 걱정에 대해 어떻게 생각하시는지요?\n동훈: 정신과 약이 의존성이 높다는 것은 편견입니다. 물론 신경안정제나 수면제와 같은 몇몇 약을 장기간 복용하면 내성과 금단 증상이 나타나는 것이 사실인데, 일정 기간 동안 적정량을 사용한다는 전제하에서는 어렵지 않게 약을 줄여서 끊을 수 있어요. 그리고 그 외의 항우울제나 기분조절제, 항정신병약물 등 주 치료제로 사용되는 대부분의 약들은 의존성이 없습니다.\n그렇다면 왜 이런 편견이 생겼을까요? 우선 치료 기간이 비교적 길기 때문일 겁니다. 보통 초진으로 우울증 환자분이 오면 저는 9개월에서 1년가량 치료 유지가 필요하다고 말씀드려요. 충분히 좋아졌어도 일정 기간 치료를 해야 재발을 막을 수 있기 때문입니다. 그런데 ‘나는 다 좋아진 거 같은데 굳이 약을 계속 먹어야 할까?’ 하며 이 기간을 견디지 못하시는 경우가 많아요. 임의로 약을 중단하면 증상이 재발해 병원을 찾는 일도 생깁니다. 이러한 과정이 반복되면 “몇년간 약을 먹어도 병이 낫지 않는다\"는 인식이 생기게 돼요.\nQ9. 정신과 병원과 심리상담소는 각각 어떤 때 가야 하고, 받는 치료는 어떻게 다른지요?\n규형: 내가 어떤 문제를 가진 건지, 어떤 치료를 받아야 하는 건지 잘 모르는 상황이라면 우선 병원에 내원하는 것을 권유드려요. 정신과 의사들은 정해진 기준에 맞춰 어떤 정신질환인지 진단하도록 훈련받은 사람들이므로 문제를 정확히 파악해내는 데 좀 더 강점이 있다고 생각합니다.\n병원에서는 상담치료 외에 약물치료, 자기장이나 전류를 이용해 뇌를 직접 자극하는 TDCS나 TMS 같은 치료들도 이뤄져요. 이렇게 다양한 치료적 옵션이 존재하기 때문에, 적합한 선택지를 고를 수 있는 여지도 크다는 것을 참고하시면 좋을 것 같습니다.\n동훈: 심리상담소에서는 병원에 비해 더 긴 시간 동안 상담 전문가에게 내 이야기를 할 수 있다는 장점이 있어요. 병원마다 차이가 있겠지만 보통 재진 진료는 20분 내외로 이뤄집니다. 하지만 상담소에서는 한 세션당 40분에서 1시간가량을 할애하기 때문에 여유 있게 풀어놓고 싶었던 이야기를 할 수 있고, 결과적으로 좀 더 깊이 있는 상담이 이루어질 여지가 있다는 것이 이점이라고 생각합니다.\nQ10. 정신과와 심리상담소는 환자의 증상에 따라 서로 추천하기도 한다고 들었습니다. 자주 있는 일인가요?\n동훈: 심리상담소에서도 충분히 좋은 도움을 받을 수 있어요. 특히, 상대적으로 긴 면담을 정기적으로 원하시는 경우에 좋은 선택이 될 수 있습니다. 다만 특정 심리상담소 방문을 추천할 때는 저와 같이 근무했거나 직접 만나뵌 경험이 있어서 인품과 치료 방식을 알고 있을 때만 드려요. 환자분이 가셔서 잘 맞지 않거나 불편한 상황이 생길 수 있기 때문에 신중해질 수밖에 없습니다.\n규형: 저도 상담을 추천드리는 경우가 꽤 자주 있습니다. 기본적으로 긴 상담을 원하시는 분이나 부부 상담, 커플 상담, 가족 상담처럼 여러 사람이 함께 상담해야 하는 경우에 심리상담소를 권유해요. 저 역시 연계된 심리상담소가 따로 있는 것은 아니라서, 근처에 공인된 자격증을 가진 분을 찾아가도록 안내해 드립니다. 예를 들어 한국상담심리학회 공인 상담심리사나 보건복지부 공인 정신건강임상심리사 같은 자격증을 확인하시면 됩니다.\nQ11. 어떤 기준으로 좋은(혹은 나쁜) 정신과 의사나 심리상담사라는 판단을 할 수 있을까요? 치료 잘 받는 방법이 있나요?\n동훈: 심리 치료와 정신과 치료 모두 가능한 한 가까운 곳에서 받는 것이 좋다고 생각합니다. 짧지 않은 기간 동안 치료를 잘 받기 위해서는 회사나 집에서 가까워서 가기 편한 곳을 선택하는 게 중요해요. 근처 병원이나 상담소 중에서 치료자의 이력이나 첫인상을 보고 마음에 드는 곳을 찾았다면, 전화를 걸어 치료 절차에 대해 문의해보세요. 예를 들어, 일반적인 치료 시간, 대략적인 비용, 예약제로 운영되는지 여부 등을 물어볼 수 있습니다. 특히 정신과 병원의 경우, 약 처방 위주로 짧게 진료하는 곳도 있고, 상담을 충분히 하는 곳도 있어요. 그렇다고 해서 짧게 진료한다고 무조건 나쁜 것은 아니고, 상담을 길게 한다고 해서 항상 좋은 것도 아니에요. 각자의 필요와 상황에 맞게 결정하면 됩니다. 치료자가 자신과 잘 맞을지는 직접 경험해 보기 전에는 알 수 없지만, 이러한 과정을 거치면 시행착오를 줄이는 데 도움이 될 수 있습니다.\n규형: 정신과 의사나 상담사와 환자(내담자) 간에도 '케미'가 분명히 존재합니다. 어떤 치료자가 누군가에게는 별로일 수 있지만, 다른 사람에게는 매우 좋은 치료자가 될 수 있고, 그 반대의 경우도 있죠. 만약 치료자가 자신과 맞지 않는 것 같다면 그 부분에 대해 솔직히 이야기하고 서로 맞춰 가는 것을 추천드립니다. 그래도 안 맞으면 치료자를 바꾸는 것도 얼마든지 가능하고요. 처음부터 딱 맞는 사람을 기대하지 않는 것도 좋은 방법입니다.\nQ12. 정신과 병원을 찾아가는 것도, 회당 10만 원 내외인 상담료를 부담하며 심리상담소를 찾아가는 것도 결심이 잘 서지 않는다면 시도해볼 방법이 있을까요?\n동훈: 각 지자체가 운영하는 정신건강복지센터에 일정 회기 동안 무료로 상담을 제공하는 프로그램이 있어요. 병원이나 상담소에 바로 가는 것이 부담스럽다면, 이러한 프로그램을 먼저 이용해보는 것도 좋은 방법입니다. 그 과정에서 만약 보다 전문적인 치료가 필요하다고 판단되면, 병원으로 연계해 줄 수도 있습니다.\n지용: 정신질환이 만성화되면 사회적 혹은 경제적으로 어려운 상황에 처하게 돼서 치료 자체가 힘들어지는 경우가 많습니다. 그래서 무료로 제공되는 치료 프로그램들이 매우 소중하죠. 하지만 무료 프로그램들은 제한된 자원으로 여러 사람에게 도움을 주려다 보니 아직 아쉬운 점들이 있고, 특히 장기간 지속되기가 어려워요. 이러한 한계를 인식하고 무료 프로그램을 본격적인 치료로 이어지는 첫 단계 정도로 생각해주시면 좋겠습니다.\n우리 사회에서는 아직도 정신 치료와 상담의 가치를 낮게 보는 경향이 있는 것 같아요. 예를 들어, \"말 좀 들어주고 누구나 할 수 있는 이야기해주면서 돈을 받느냐\"는 식의 시각이 있죠. 하지만 우리의 정신을 담는 그릇인 뇌는 우리 몸에서 가장 중요한 장기이며, 그 정신을 다루는 상담 치료는 우리의 인생에 매우 중요한 영향을 미칩니다. 자신의 삶을 변화시키기 위해 적절한 투자를 한다는 마인드를 지니면 더 큰 변화를 경험하실 수 있을 거라고 생각합니다.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 주소은, 이지영 Graphic 조수희",
        "content": "월간 토스픽 08. 마음건강의 값",
        "contentSnippet": "월간 토스픽 08. 마음건강의 값",
        "guid": "https://blog.toss.im/article/monthly-tosspick-2024-8",
        "isoDate": "2024-09-13T00:36:00.000Z"
      },
      {
        "title": "토스, 개발자 컨퍼런스 ‘슬래시24’ 성황리에 마쳐",
        "link": "https://blog.toss.im/article/slash24",
        "pubDate": "Fri, 13 Sep 2024 00:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}1,500명 참가 선발에 신청자 11,000명 이상 신청 접수… 참가자 95%가 다음 행사 참여에 긍정 답변\n최신 기술 트렌드를 배울 수 있었다는 평가 이어져\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n모바일 금융 서비스 ‘토스’를 운영하는 비바리퍼블리카(이하 ‘토스’)가 개발자 컨퍼런스 ‘슬래시 24(SLASH 24)’를 성황리에 마쳤다고 13일 밝혔다.\n올해로 4회를 맞은 슬래시는 행사 전부터 뜨거운 관심이 이어졌다. 지난 2일까지 접수된 참가 신청에는 11,000명 이상의 지원자가 몰린 가운데, 참가 신청자의 직무 분포는 서버(Server)와 프론트엔드(Frontend)가 각 30%대로 가장 높은 비율을 차지했다. 접수 시작과 함께 공개된 오프닝 필름은 유튜브 조회수 79만 회를 넘어섰다.\n본 행사는 12일(목) 오전 10시부터 오후 4시까지 코엑스 그랜드볼룸에서 열렸다. 토스, 토스뱅크, 토스증권, 토스페이먼츠, 토스플레이스 등 5개 법인에서 45명의 엔지니어가 연사로 참여해 29개의 메인 세션과 3개의 스페셜 세션을 진행했다.\n첫 순서는 토스의 테크놀로지 총괄 이형석 최고기술책임자(CTO)의 발표로 시작됐다. 이형석 CTO는 토스의 성장 과정을 이야기하며 자율과 책임을 강조하는 조직문화, 자기주도적 학습, 동료 간 협력을 통해 어려운 문제들을 해결해왔다는 점을 강조했다.\n메인 세션은 세 개의 장소에서 열렸다. 각 장소마다 강연 시작 전부터 입장을 기다리는 줄이 길게 이어지며 참가자들의 열기를 실감케 했다. ‘리크루팅 존’, ‘럭키드로우 존’ 등 다양한 이벤트 부스 또한 성황리에 운영됐다. 특히 강연을 진행한 연사들과 세션에 대한 질의를 하거나 기술적 고민을 나눌 수 있는 ‘데브챗(DevChat) 존’은 참가자들의 뜨거운 관심을 받았다.\n행사 만족도도 매우 높았다. 참가자 1,500여 명을 대상으로 설문조사를 진행한 결과, 다음에도 슬래시에 참여하겠다는 응답이 약 95%를 기록했다. 또한 “토스의 업무 방식을 좀 더 생생하게 알 수 있어 좋았다\", “최신 기술 트렌드를 알게 됐다\", “오프라인으로 진행된 부분에서 더욱 깊이감이 느껴졌다\" 등 긍정적인 반응이 잇따랐다.\n토스 관계자는 “올해 슬래시는 처음 오프라인 행사로 진행되는 만큼, 현장에서 느낄 수 있는 장점들을 극대화하고자 했다”라며 “앞으로 계속될 슬래시의 여정도 기대해 주시기를 바란다\"라고 전했다.",
        "content": "참가자 95%가 다음 행사 참여에 긍정 답변",
        "contentSnippet": "참가자 95%가 다음 행사 참여에 긍정 답변",
        "guid": "https://blog.toss.im/article/slash24",
        "isoDate": "2024-09-13T00:00:00.000Z"
      },
      {
        "title": "추석 연휴 직후로 예정된 미국 기준금리 발표, 빅 컷 or 베이비 컷?",
        "link": "https://blog.toss.im/article/economic-terms-27-bigcut-babycut",
        "pubDate": "Thu, 12 Sep 2024 02:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-8atqhb{width:100%;}.css-1c1qox8{font-size:30px;letter-spacing:0em;line-height:1.55;font-weight:bold;color:var(--adaptiveGrey900);margin:40px 0 4px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-p4abj2{display:contents;line-height:1.55;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}🔖 이번 주 경제 용어\n빅 컷 or 베이비 컷\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}이번 주 경제 용어는 글로벌 경제를 파악하기 위해 필요한 정보예요.\n\n.css-1pgssrp{max-width:100%;border-radius:16px;}\n금리 인하 폭에 따라 구분되는 중앙은행의 통화정책 용어로, 금리를 많이 내리면 빅 컷, 금리를 적게 내리면 베이비 컷이라고 해요. 빅컷은 보통 0.5%p인하, 베이비 컷은 0.25%p인하를 의미해요.\n\n\n코로나19 팬데믹 이후, 전 세계는 치솟는 물가로 인해 혼란에 빠졌습니다. 이때 미국 연방준비제도(연준, Fed: Federal Reserve Board), 유럽 중앙은행(ECB: European Central Bank), 영국 영란은행(BoE: Bank of England), 한국은행(BOK: Bank of Korea) 등 주요국 중앙은행들은 통화정책을 통해 물가를 잡기 위해 분투했지요.\n대표적인 방법으로 주요국 중앙은행들은 물가 상승을 억제하기 위해 기준금리를 올려 시중의 통화량을 줄이는 정책을 펼쳤습니다.\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n⛓️ 물가와 기준금리의 관계\n\n📈 물가가 상승하면 물건 가격이 비싸집니다. \n인플레이션이 일어나는거죠. 사람들의 생활비가 늘어나고 돈을 더 써야 생활이 유지되니 시장이 과열됩니다. 중앙은행은 이러한 경제 과열을 막기 위해 기준금리를 올려요. 금리가 오르면 돈을 빌리는 비용이 비싸지니, 사람들은 돈을 덜 빌리고 덜 쓰게 되겠죠. 이는 소비와 투자를 줄이고 경제 활동을 둔화시켜, 인플레이션을 억제하는 효과가 있습니다.\n📉 물가 상승률이 낮거나 물가가 떨어지면 물건 가격도 내려갑니다. \n사람들은 계속 싸지는 물건 가격을 보면서, ‘나중에 더 싸지겠지' 생각하며 물건을 사지 않고 기다려요. 시장이 비활성화되겠죠. 중앙은행은 사람들이 돈을 더 쓰게 만들고 싶어요. 경제를 활성화시키기 위해 기준금리를 내립니다. 금리가 낮으면 돈을 빌리는 비용이 싸지니, 사람들은 돈을 더 빌리고 더 쓰게 되겠죠. 돈을 더 쉽게 빌릴 수 있게 되니 소비와 투자가 촉진됩니다. 이는 경제 활동을 활발하게 만들고 물가를 적정 수준으로 올리는 효과를 가져와요.\n\n이렇게 금리를 인상하여 물가를 안정시키려는 노력이 계속된 지 2년이 지난 지금, 물가상승률이 목표 수준인 전년 대비 2%까지 내려오자, 중앙은행들은 금리 인하를 고려하기 시작했습니다. 이처럼 금리 정책이 전환되는 시점을 ‘피봇(Pivot: 중요한 전환점)’이라고 부릅니다.\n금리가 세계 경제에 가장 큰 영향을 미치는 요소인 만큼, 미국의 중앙은행인 연방준비제도(연준, Fed)가 기준금리를 얼마나 크게 내릴지에 대한 관심이 집중되고 있어요.\n이와 관련해 경제 기사에서 자주 등장하는 용어가 바로 ‘빅 컷(Big Cut)’과 ‘베이비 컷(Baby Cut)’인데요. 이 두 용어는 중앙은행이 기준금리를 얼마나 크게 인하할지를 나타냅니다.\n여기서 ‘컷(Cut)’은 금리를 내리는 폭을 의미하는데요. 빅컷은 보통 0.5%p 인하를 의미하며, 경제가 심각한 침체에 빠졌을 때 강력한 경기 부양을 위해 사용됩니다. 반면 베이비컷은 0.25%p 인하를 의미하며, 경제 상황이 다소 불확실하지만 급격한 조정은 필요하지 않을 때 선택돼요.\n참고로 2년 전 금리 인상기에는 ‘컷(Cut)’ 대신 ‘스텝(Step)’이라는 용어가 사용되었는데요. 스텝은 컷과 반대로 금리를 인상하는 폭을 말합니다. 보통 0.25%p 인상하는 것이 일반적이며, 이를 ‘베이비 스텝(Baby Step)’이라고 해요. 이보다 인상폭이 좀 더 큰 0.5%p 인상은 ‘빅 스텝(Big Step)’이라고 하고요.\n그러고 보니 베이비 컷과 베이비 스텝, 빅 컷과 빅 스텝이 서로 유사한 구조를 가지고 있네요. 한 판 표로 정리해서 보면 다음과 같습니다.\n\n\n\n.css-2yhypk{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);font-style:italic;-webkit-text-decoration:underline!important;text-decoration:underline!important;}'빅컷'이냐 '베이비컷'이냐…9월 원달러 향방은\n(뉴시스 2024.9.2)\n미국의 9월 금리가 기정사실화되는 가운데 '빅 컷(0.5%포인트 인하)'인지, '베이비 컷(0.25%포인트 인하)'인지에 관심이 쏠리고 있다. 제롬 파월 연방준비제도 의장의 연설을 통해 고용 지표를 금리 결정의 주요 근거로 삼을 것을 시사한 만큼 이번주 발표되는 고용보고서가 환율 변곡점이 될 것이란 시각이다.\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}미국 경기 경착륙이 확인된다면 '빅컷' 가능성이 높아지며 달러값이 큰 폭으로 떨어질 가능성도 있다. 다만 미 고용시장이 둔화되고 있지만, 우려할 수준은 아닐 것으로 보면서 0.5%포인트 인하 가능성을 낮게 보는 의견도 있다. 시장에서는 고용 데이터가 낙관적으로 나올 것이란 관측이 높아지면서 9월 예상환율로 현 수준인 1330원대에서 움직일 것이란 전망이 힘을 받고 있다.\n2일 서울외환시장에서 오전 10시30분 현재 원·달러는 전거래일 오후 3시 30분 종가(1336.0원) 보다 1.0원 오른 1337.0원에 거래 중이다. (중략)\n\n\n미국 연방준비제도(연준, Fed)가 마침내 금리 인하를 준비하고 있다는 신호를 보냈습니다. 물가상승률이 목표치인 2%에 점점 가까워지고 고용률 둔화가 가시화되면서, 이제 금리를 내릴 시기가 다가온 것이죠.\n기준 금리 인하가 확실시되는 상황에서 핵심은 얼마나 ‘강하게’ 금리를 내릴 것인가입니다. 현재 두 가지 시나리오가 제시되고 있습니다.\n첫 번째는 '빅 컷(Big Cut)'으로, 한 번에 0.5%p를 크게 인하하는 방식입니다. 지난 6일 발표된 8월 미국 비농업 부문의 신규 고용이 전월 대비 14만 2,000명 늘며, 월가 예상치(16만 4,000명)를 밑돌자, 빅 컷이 힘을 받기도 했어요.\n이렇게 되면 경기 부양 효과가 상당히 크겠지만, 그만큼 달러 가치가 크게 하락할 가능성도 있습니다. 달러가 약세를 보이면 미국 수출 기업들에게는 유리하지만, 수입품 가격이 오르면서 물가에 다시 압력이 가해질 수 있겠죠.\n두 번째 시나리오는 '베이비 컷(Baby Cut)'입니다. 0.25%p만 살짝 내리는 방법인데요. 주요국 중앙은행이 금리를 인하할 때 통상 0.25%p씩 수정하는 경우가 많기 때문에, 시장에서는 베이비 컷이 더 높은 확률로 점쳐지고 있는 상황입니다.\n이 경우 경기 부양 효과는 조금 덜하겠지만, 달러가 급격하게 약세로 돌아서지는 않을 가능성이 큽니다. 만약 연준이 이 방식을 선택한다면, 시장 변동성은 최소화하면서 신중하게 금리 조정을 이어가려는 선택이 되겠지요.\n결론적으로 미국 경제의 물가와 고용 상황은 금리 인하를 예고하고 있고, 얼마나 강하게 금리가 내릴지 모두가 주목하고 있는 상황입니다. 오는 9월 17~18일에 열리는 연방공개시장위원회(FOMC) 회의에서 최종 결정이 나올 것으로 예상되는데요. 이때 발표되는 결과에 따라 달러 가치와 원·달러 환율에 큰 영향이 미칠 것으로 예상돼요. 앞으로의 시장 반응과 경제 지표에 더욱더 주목해야 할 시점이라 볼 수 있겠습니다.\n기준금리 발표는 18일 오후 2시, 제롬 파월 연준 의장의 발언은 오후 2시 30분에 진행될 예정인데요. (한국 시간 기준으로는 연휴 다음날인 19일 새벽 3시, 3시 30분) 국내 투자자들 입장에서는 FOMC 직전 3일간 추석 연휴로 인해 포지션을 조정할 기회 없이 미국의 통화정책 결과를 받아들이게 되는 셈입니다.\n이에 전문가들은 현금 비중을 높이고 주식 비중을 축소하는 등 상대적으로 변동성이 작은 종목에 투자할 것을 권유하고 있어요. 특히 원/달러 환율이 하락하면서 단기간 내 환차익을 실현하고자 하는 욕구가 높아진 외국인이 국내 주식시장에 유입되며 지수를 끌어내릴 수 있기 때문에, 외국인 보유 비중이 적은 종목 중심으로 대응하는 것이 필요하다는 의견도 있습니다.\n앞으로의 시장은 경기 향방과 9월에 결정될 금리 인하 폭에 대한 설전이 오고가며 한두 차례 큰 변동성이 나타날 가능성이 있어 보입니다. 기술적 반등이 나올 수도 있으며, 반도체·IT·자동차·기계 등의 업종에서 단기 트레이딩의 움직임이 보일 수 있다는 것도 참고할 수 있겠습니다.\n\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n기준 금리: 다른 금리들에 영향을 주는 기준점이 되는 금리. 중앙은행의 정책금리로, 경제 전반에 걸쳐 금리 수준을 결정하는 중요한 지표로 활용돼요. 경기 과열로 물가가 너무 오르면 기준금리를 올려 시중의 돈을 거둬들이고, 경기 침체로 시중에 돈이 돌지 못하면 기준금리를 낮춰 시중에 유동성을 공급함으로써 경제를 안정적으로 유지하려 합니다.\n양적 완화: 금리 인하를 통한 경기 부양 효과가 한계가 있을 때, 중앙은행이 국채나 금융자산을 대규모로 매입하여 시중에 유동성을 직접 공급하는 것. 중앙은행은 양적 완화를 통해 신용경색을 해소하고, 경제 성장을 촉진하기를 기대해요.\n물가안정 목표제: 중앙은행이 중기적으로 달성해야 할 물가상승률 목표치를 미리 제시하고 이를 유지하려는 제도. 현재 미국 연방준비제도(Fed)와 한국은행의 인플레이션 목표는 통상 2%인데요. 이 목표치에 근접하면 금리 인하나 인상이 고려됩니다.\n\n\n.css-13d8cj1{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;margin:24px 0 8px;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:var(--adaptiveGrey700);}\n.css-1dzrkjz{width:16px;margin-right:8px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}\n.svg-icon-wrapper{position:relative;display:inline-block;width:24px;height:24px;}.svg-icon-wrapper >.svg-icon:empty+.svg-icon-fallback{visibility:visible;z-index:inherit;}.svg-icon{color:var(--adaptiveGrey900);display:inline-block;width:24px;height:24px;display:block;width:100%;height:100%;}.svg-icon svg,.svg-icon img{display:block;width:100%;height:100%;}.svg-icon--hide{display:none;}.svg-icon-fallback{position:absolute;left:0;right:0;top:0;z-index:z-index(hidden);visibility:hidden;display:block;width:100%;height:100%;}.svg-icon-fallback--show{visibility:visible;z-index:inherit;}\n참고자료\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 금혜원 Graphic 조수희 이동건",
        "content": "곧 금리 인하가 예상되는데요, 과연 얼마나 내려갈지 모두가 주목하고 있어요.",
        "contentSnippet": "곧 금리 인하가 예상되는데요, 과연 얼마나 내려갈지 모두가 주목하고 있어요.",
        "guid": "https://blog.toss.im/article/economic-terms-27-bigcut-babycut",
        "isoDate": "2024-09-12T02:00:00.000Z"
      },
      {
        "title": "왜 은행마다 이자율이 조금씩 다른 걸까?",
        "link": "https://blog.toss.im/article/everyday-economics-18-bank-interest-rate",
        "pubDate": "Wed, 11 Sep 2024 12:23:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-94on8q{white-space:pre-wrap;color:#c770e4;font-weight:bold;}에디터 G (이하 G):.css-1kxrhf3{white-space:pre-wrap;} 교수님, 얼마 전 대출을 알아보려고 토스앱을 켰는데요. 여러 은행의 대출 상품이 리스트로 쭉 뜨는데, 은행마다 이자율이 조금씩 다르더라고요. 같은 금액의 대출금을 빌리더라도, A 은행에서는 3.5%의 이자율인 반면 B 은행에서는 4.2%의 이자율을 보여주는 거예요. 왜 같은 돈을 빌리더라도 은행마다 이렇게 이자율에 차이가 나는 걸까요?\n.css-12p6bv8{white-space:pre-wrap;color:#15c47e;font-weight:bold;}교수 K (이하 K): 요즘은 은행에 직접 방문하지 않고도 모바일로 간편하게 여러 대출을 비교할 수 있게 되면서, 은행마다 대출 금리가 다르다는 것을 더 잘 파악할 수 있게 된 것 같아요.\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}은행마다 이자율이 다른 이유에 대해 가장 먼저 생각해 볼 수 있는 것은, 리스크(risk: 위험) 관점인데요. 각 은행들의 리스크를 관리하는 방법이 다르기 때문입니다.\n은행은 다양한 리스크에 노출되어 있습니다. 예를 들면, 금리, 환율, 주가 변동 등 금융 시장의 변화로 인해 손실이 발생할 수 있는 시장 리스크(market risk)가 있고요. 은행 내부의 프로세스, 시스템 오류, 직원의 실수 등으로 인해 손실이 발생할 수 있는 운영 리스크(operational risk)도 있습니다. 또한 자금을 적시에 조달하지 못해 지불 의무를 이행하지 못하게 되는 유동성 리스크(liquidity risk)도 있고요.\nG: 엄청나게 다양한 리스크가 있군요. 은행 입장에서 가장 중요하게 생각하는 리스크는 어떤 것이려나요?\nK: 앞서 언급한 리스크 이외에 또다른 리스크가 있는데요. 은행이 가장 신경 쓰는 리스크는 바로, .css-1swx3yz{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;font-weight:bold;}신용 리스크(credit risk)입니다.\n신용 리스크는 대출을 받아간 고객이 원리금(원금+이자)을 상환하지 못할 가능성을 의미하는데요. 이는 은행의 재무 건전성과 직결됩니다. 신용 리스크가 현실화되면 은행은 대출 손실을 입게 되어 자산 건전성이 악화되기 때문이죠.\nG: 그렇겠네요. 그래서 은행에서 돈을 빌릴 때, 제가 대출을 잘 갚을 수 있는 사람인지 확인하는 절차가 꽤 복잡한 이유가 있는 거고요. 하지만 빌려준 돈을 못 갚을 가능성은 언제나 있으니, 은행 입장에선 항상 신용 리스크가 존재한다고 볼 수 있겠군요. 그렇다면 이러한 신용 리스크가 발생하는 이유에 대해서도 자세히 설명해주실 수 있을까요?\nK: 그럼요. 저희 시리즈의 취지에 맞게 경제학 관점에서 좀더 자세하게 설명해 드릴게요. 먼저 신용 리스크가 발생하는 원인으로는 ‘정보의 비대칭성(asymmetric information)’과 ‘역선택(adverse selection)’을 들 수 있습니다.\n정보의 비대칭성이란 거래 당사자 간의 정보가 균등하게 공유되지 않는 상황을 의미합니다.\n예를 들어, 은행에 투자 자금 1천만 원을 빌리러 온 김안정 씨와 이모험 씨가 있다고 가정해 볼게요. 김안정 씨는 안정적인 투자를 선호하는 사람이기 때문에, 5% 수익이 확실히 보장되는 사업에 투자를 하려고 합니다. 평소 조금씩 모아둔 비상금도 있어서 1천만 원을 빌려도 나중에 상환하는 데에 큰 문제가 없어요.\n반면, 이모험 씨는 모험적인 투자를 선호합니다. 성공 확률은 매우 낮지만, 만약 성공하게 되면 1,000%의 수익을 얻을 수 있는 사업에 투자하려고 합니다. 그러나 얼마 전에 지인으로부터 이미 많은 돈을 빌린 터라, 이번에 은행에서 1천만 원을 빌리면 나중에 상환할 수 있을지 불확실한 상황입니다.\n만약, 은행이 김안정 씨와 이모험 씨의 상황에 대한 정보를 완전하게 알고 있다면 어떤 결과가 나올까요?\nG: 음… 안정적인 투자를 선호하면서 모아둔 비상금도 있는 김안정 씨에게는 돈을 빌려줄 가능성이 높지만, 모험적인 투자를 선호하면서 지인에게 빌린 돈까지 있는 이모험 씨에게는 돈을 안 빌려줄 가능성이 높을 것 같아요.\nK: 그렇죠. 상식적으로 그들의 상황을 모두 안다면 에디터 님이 말씀하신 결과가 나올 겁니다. 하지만 은행은 김안정 씨와 이모험 씨의 이런 투자 성향과 상환 능력의 차이에 대해 전혀 모를 수도 있어요. 즉, ‘정보의 비대칭성’은 이처럼 돈을 빌리는 사람이 가진 정보와 은행이 가진 정보 사이에 차이가 나는 경우를 말합니다.\n정보의 비대칭성이 존재하는 상황을 좀 더 살펴보도록 하죠. 김안정 씨는 보수적인 투자자이기 때문에 기대 수익률 5%와 비교해서 대출 이자율이 더 높다면, 아마 대출 신청을 하지 않을 것입니다. 반면, 한탕을 노리는 이모험 씨는 높은 이자를 지불하더라도 은행으로부터 적극적으로 돈을 빌리려 할 것이고요.\n결과적으로, 은행은 이모험 씨처럼 위험이 높은 사람들에게만 대출을 해주는 상황이 발생할 수 있습니다. 이와 같이 정보의 비대칭성으로 인해 발생하는 문제를 ‘역선택’이라 해요.\nG: 오, 그렇군요. 당연히 김안정 씨에게 돈을 빌려줄 가능성이 높을 거라 생각했는데, 김안정 씨는 애초에 대출을 신청하지 않을 가능성이 높고 이모험 씨는 대출을 신청할 가능성이 높으니 예상과 반대되는 결과가 펼쳐지는 거네요. 아무래도 현실에서는 은행 입장에서 돈을 빌리고자 하는 사람들의 모든 상황을 파악하기가 어려우니 이런 결과가 나올 수밖에 없겠어요.\nK: 맞습니다. 그래서 은행은 정보의 비대칭성과 역선택 문제에 다양한 방식으로 대응하고 있어요. 대표적인 예가 바로 신용 점수, 재정 상태, 소득 수준 등의 정보를 이용해 고객의 신용도를 평가하는 것인데요. 이 때 은행마다 사용하는 신용 평가 모델이 다를 수 있습니다. 어떤 은행은 외부 신용 평가 기관의 점수를 주로 사용하는 반면, 다른 은행은 자체적으로 개발한 모델을 사용하여 신용 위험을 평가할 수 있죠.\n또한 각 은행마다 신용 평가 시 고려하는 요소가 다를 수 있습니다. 예를 들어, 소득 수준, 부채 비율, 직업 안정성, 금융 거래 내역 등을 평가할 때 각 요소의 비중을 다르게 설정할 수 있는 것이죠. 신용 평가에 사용하는 데이터도 서로 다를 수 있습니다. 대형 은행들은 고객의 기존 거래 내역, 예금 계좌 정보 등을 포함해 더 많은 내부 데이터를 활용할 수 있을 거고요.\n또한 은행마다 리스크를 허용하는 정도도 다르기 때문에, 같은 신용도를 가진 고객이라도 평가 결과가 서로 다르게 나올 수 있답니다. 리스크를 더 잘 수용할 수 있는 은행은 높은 점수를 부여하고, 보수적인 은행은 낮은 점수를 줄 수 있는 것이죠.\nG: 아하, 은행마다 고객의 신용도를 측정하는 방식이 다르기 때문에, 대출 금리와 이자율에도 차이가 발생하게 되는 것이군요.\nK: 맞아요. 이제 시각을 좀더 넓혀서 더 다양한 종류의 금융기관들의 이자율이 서로 다른 이유도 한번 살펴볼까요? 이번 기회에 우리나라에 존재하는 금융기관의 종류를 겸사겸사 정리해볼 겸 말이죠.\n현재 우리나라의 금융기관이 제공하는 금융 서비스는 유형에 따라 아래 표와 같이 구분할 수 있습니다. 은행, 비은행 예금취급기관, 보험회사, 금융투자업자, 기타 금융기관, 그리고 공적금융기관 등으로 나눌 수 있어요.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}은행\n\n먼저, 은행은 일반은행과 특수은행으로 나뉩니다. 일반은행은 시중은행, 지방은행, 외국은행 국내지점 등으로 구성되는데요. 주로 예금, 대출, 지급결제 등의 업무를 수행하고 있습니다.\n참고로, 현재 우리나라의 시중은행에는 신한은행, 우리은행, 하나은행, 한국씨티은행, iM뱅크(구 대구은행), KB국민은행, SC제일은행(가나다 순)과 토스뱅크를 비롯한 인터넷전문은행들이 포함된답니다.\n한편, 특수은행은 특정 목적을 위해 설립된 은행이에요. KDB산업은행, 한국수출입은행, IBK기업은행, NH농협은행, Sh수협은행 등이 있습니다.\n\n\n비은행 예금취급기관\n\n말 그대로 은행은 아니지만 예금 업무를 수행하는 기관인데요. 상호저축은행, 신용협동기구, 우체국예금, 종합금융회사 등으로 구성됩니다.\n상호저축은행은 특정한 지역의 서민 및 소규모 기업을 대상으로 대출을 제공하고 있어요. 조합원들을 대상으로 금융 서비스를 제공하며 공동 이익을 추구하는 신용협동기구에는 신협, 새마을금고, 농협, 수협 등이 포함됩니다. 우체국예금은 전국에 분포된 우체국을 통해 민간금융이 취약한 지역을 지원하는 국영 금융을 말하고요.\n\n\n보험회사\n\n크게 생명보험회사, 손해보험회사, 우체국보험, 공제기관 등으로 나뉩니다.\n생명보험회사는 사망, 질병, 노후 등에 대비한 보험과 관련된 업무를 하는 금융회사이고요. 손해보험회사는 화재, 자동차 및 해상사고 등과 같이 재산 및 사고 손실에 대비한 보험을 고유업무로 하는데요. 재보험회사와 보증보험회사도 손해보험회사에 포함됩니다. 우체국보험은 국가기관이 취급하는 국영보험이며, 공제기관의 경우 유사보험을 취급한답니다.\n\n\n금융투자회사\n\n투자매매·중개업자, 집합투자업자, 투자자문·일임업자, 신탁업자 등으로 분류됩니다.\n이 가운데 우리가 잘 알고 있는 증권회사는 투자매매·중개업자에 속하는데요. 주로 증권 및 채권과 관련된 위탁매매, 발행 및 인수 업무를 수행합니다. 은행의 경우 예금을 받아 기업에게 대출을 해주는 반면, 증권회사는 증권을 매개로 기업과 투자자를 직접 연결시킨다는 점에서 차이를 보인답니다.\n\n\n기타 금융기관\n\n금융지주회사, 여신전문금융회사, 벤처캐피탈회사, 증권금융회사, 대부업자 등이 있어요.\n이 중 여신전문금융회사는 고객으로부터 자금을 예치받는 수신(deposit) 기능 없이, 돈을 빌려주는 여신(lending) 업무만 취급하는 금융기관을 말합니다. 여신전문금융회사의 예로는 신용카드회사, 리스회사, 할부금융회사, 신기술사업금융회사 등이 있습니다.\n\n\n공적금융기관\n\n특정한 정책적 목적을 위해 설립된 기관으로, 한국무역보험공사, 한국주택금융공사, 한국자산관리공사, 한국투자공사, 서민금융진흥원 등이 포함돼요.\n\n\nG: 엄청나게 다양한 종류의 금융기관이 있군요! 서로 어떻게 다른지 잘 알아볼 수 있었어요. 글을 저장해 두고 다음에 다시 살펴봐야 겠어요.\nK: 좋습니다. 앞서 설명드린 금융기관들은 자금 조달 방식에 있어 서로 차이를 보이는데요. 이를 통해 각 금융기관들마다 다른 이자율을 제시하는 이유를 설명할 수 있답니다.\n예를 들어, 은행의 경우 주로 개인 및 기업 예금을 통해 자금을 조달해요. 또한, 채권 발행과 중앙은행에서의 차입, 다른 금융기관과의 대출 거래도 활용합니다. 이를 통해 은행은 비교적 안정적이고 대규모의 자금 조달이 가능하기 때문에, 예금 금리가 상대적으로 낮고 대출 금리도 경쟁력 있는 수준으로 제공할 수 있습니다.\n반면, 저축은행은 은행보다 금리를 높게 설정한 개인 예금을 통해 자금을 조달합니다. 또한 고위험 대출에 집중하기 때문에 리스크를 보상하기 위한 목적으로 대출 금리가 상대적으로 높답니다. 이는 저축은행이 은행보다 작은 규모로 운영되며, 고객 기반도 다르기 때문이에요.\n보험사의 경우, 고객이 납부하는 보험료가 주요 자금 조달원입니다. 이 보험료를 주식, 채권, 부동산 등 다양한 투자처에 투자하여 수익을 창출해요.\n생명보험회사는 장기적인 투자 수익을 목표로 하므로, 안정적인 수익을 제공할 수 있는 자산에 주로 투자합니다. 반면, 손해보험회사는 상대적으로 단기 계약이 많고 다양한 리스크를 보장하기 때문에, 주로 유동성이 높은 자산에 투자하는 경향이 강합니다.\n이렇게 확보된 자금을 바탕으로, 보험사들은 보험계약자들이 가입한 보험 상품의 해지환급금을 담보로 대출을 해주는 약관대출뿐만 아니라 신용대출과 부동산담보대출도 취급하고 있습니다.\n보험사의 대출 금리는 중앙은행의 기준 금리와 더불어 계약자의 신용도, 자산운용의 기대 수익률, 시장 금리, 담보 가액 등을 고려하여 결정되는데요. 제2금융권에 속하는 보험사는 일반적으로 제1금융권의 시중은행보다 금리가 높은 편입니다.\n그런데 금융당국이 가계부채 관리를 위해 제1금융권에 대한 규제를 강화하면서 시중은행들이 금리를 지속적으로 올린 결과, 얼마 전 보험사의 금리가 시중은행의 금리보다 낮아지는 금리 역전 현상이 발생하기도 했습니다.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}* 출처: .css-114ityv{white-space:pre-wrap;cursor:pointer;-webkit-text-decoration:underline!important;text-decoration:underline!important;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}[단독] 초유의 주담대 ‘금리 역전’… 보험사, 은행보다 낮아졌다 (한국경제) \n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n🏦 제1금융권, 제2금융권 금리도 차이가 꽤 나는데 왜 그런가요?\n\n제1금융권은 은행(일반은행, 특수은행)을 말합니다. 제2금융권은 앞에서 살펴본 금융기관들 중 은행을 제외한 금융기관들을 통칭하는 용어라고 생각하시면 됩니다.\n제2금융권 대출은, 대출 자격이 까다로운 제1금융권에서 대출을 받지 못하거나 신용등급이 낮은 고객을 대상으로 하는 경우가 상대적으로 많아요. 그래서 신용 리스크가 높아지고요. 이를 보상하기 위해 제1금융권보다 더 높은 금리를 부과하는 경향이 강하답니다.\n또한 제2금융권은 제1금융권에 비해 예금 유치가 적고 자금 시장에서의 차입 비용이 더 높기 때문에, 대출 금리도 제1금융권보다 올라가게 되는 것이지요.\n\n한편 증권사는 중개 기능을 주업무로 수행하고 있기 때문에, 자금 조달 방식이 은행이나 타금융기관과 차이를 보입니다.\n증권사의 자금조달원은 크게 두 가지인데요. 첫 번째는 투자자들의 증권 계좌에 들어있는 예수금(예수부채)이고요. 두 번째는 주가연계증권(ELS)과 같은 파생결합증권, 회사채, 기업어음(CP), 환매조건부채권(RP), 발행어음 등을 통해 자금을 차입하는 것(차입부채)입니다.\n증권사에서도 돈을 빌려주는데요. 고객이 주식을 사기 위해 필요한 자금이 부족할 때, 증권 계좌에 있는 주식을 담보로 빌려줍니다. 이를 신용거래 대출(마진 론)이라고 불러요. 증권사는 시장 금리, 고객의 신용도, 담보로 제공된 주식의 가치 변동성 등을 고려하여 대출 금리를 설정하게 됩니다.\nG: 은행, 저축은행, 보험회사, 증권회사… 모두 각자가 가지고 있는 고유한 비즈니스 모델에 따라 서로 다른 방법으로 자금을 조달하고 있군요. 자금 조달 비용이 서로 달라지기 때문에 각 금융기관들마다 이자율이 달라지는 거겠네요.\nK: 정확히 이해하셨어요. 각 금융기관에 대해 하나하나 설명드려서 조금 어려우셨을 수 있는데요. 결국 금융기관들마다 이자율이 달라지는 이유는 각자의 비즈니스 모델과 자금 조달 방법, 그리고 그 비용이 서로 다르기 때문입니다. 이 점을 이해하시면 금리가 차이 나는 이유도 금방 이해하실 수 있을 거예요.\nG: 각 금융기관의 이자율, 금리에 영향을 미치는 또다른 요인도 있을까요?\nK: 이외에도 특정 지역이나 고객층을 대상으로 한 경쟁 상황이 이자율에 영향을 미치기도 하고요. 운영 비용이 높은 금융기관은 이를 보상하기 위해 이자율을 높게 설정할 수도 있습니다. 또한 정부의 규제와 중앙은행의 통화 정책에 의해서도 이자율은 영향을 받기 마련이고요.\n오늘은 은행들마다 왜 이자율에 차이가 나는지와 더불어, 우리나라에 존재하는 금융기관들의 종류와 각 금융기관별로 이자율이 다른 이유까지 살펴 봤습니다. 혹시 앞으로 금융기관과 금리에 대한 뉴스를 보게 된다면, 오늘 내용을 한번 떠올려보면 좋을 것 같네요.\n.css-13d8cj1{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;margin:24px 0 8px;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:var(--adaptiveGrey700);}\n.css-1dzrkjz{width:16px;margin-right:8px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}\n.svg-icon-wrapper{position:relative;display:inline-block;width:24px;height:24px;}.svg-icon-wrapper >.svg-icon:empty+.svg-icon-fallback{visibility:visible;z-index:inherit;}.svg-icon{color:var(--adaptiveGrey900);display:inline-block;width:24px;height:24px;display:block;width:100%;height:100%;}.svg-icon svg,.svg-icon img{display:block;width:100%;height:100%;}.svg-icon--hide{display:none;}.svg-icon-fallback{position:absolute;left:0;right:0;top:0;z-index:z-index(hidden);visibility:hidden;display:block;width:100%;height:100%;}.svg-icon-fallback--show{visibility:visible;z-index:inherit;}\n참고자료\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 금혜원 Graphic 조수희 이제현",
        "content": "각 은행이 리스크(위험)를 관리하는 방법이 다르기 때문이에요.",
        "contentSnippet": "각 은행이 리스크(위험)를 관리하는 방법이 다르기 때문이에요.",
        "guid": "https://blog.toss.im/article/everyday-economics-18-bank-interest-rate",
        "isoDate": "2024-09-11T12:23:00.000Z"
      },
      {
        "title": "누구나 팬이 필요하다 ",
        "link": "https://blog.toss.im/article/fandustry-01",
        "pubDate": "Mon, 09 Sep 2024 23:36:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}2016년의 일이다. 평소에 갈 일 없던 모임, 그러니까 주로 대기업 임원들이나 스타트업 대표들의 네트워킹 모임에 초대받은 적이 있다. 그런 곳에서는 다들 어느 기업에서 무슨 업무를 맡고 있다는 식으로 자기 소개를 하기 때문에 당시 회사도 없고 직무도 없던 나로서는 괜히 자기소개에 자신이 없어지기도 했다. ‘00전자에서 웨어러블 사업을 총괄하고 있습니다’라는 중후한 소개 말에 이어 ‘저는 음악평론 하는데, 아니, 클래식은 아니고요, 대중음악인데, 아니 케이팝만 하는 건 아니고 인디 음악도 하는데, 아니, 평론이란 게 별점 매기는 건 또 아니지만서도, 네 뭐 서비스 기획도 했고, 콘텐츠도 만들고 에 또…’ 하는 게 얼마나 뻘쭘했을지 상상해보라. \n어휴 괜히 왔네, 후회하던 찰나 뒷줄의 나이 지긋한 여성분이 자기 소개를 하는데 ‘00기업에서 마케팅만 30년을 맡고 있습니다’ 하더니 조금 부끄러운 듯 한 마디를 보탰다. “그리고… 저는 아미입니다.”\n그 한마디에 주변 여성들의 호응하는 목소리가 커졌다. ‘저도 아미에요!’ ‘상무님, 멋있으세요!’ 남성들도 관심을 보였다. ‘아미가 뭐에요?’ ‘에이 BTS 그거요…’ 그 한 마디에 대체로 근엄하고 지루했던 자리에 활기가 넘치기 시작했다. ‘어이쿠, 나도 그냥 샤이니 팬이라고 소개할 걸!’ 하는 후회는 안했다. (나도 소셜 포지션이 있답니다~) 대신, ‘이제는 덕질이 커리어와 같은 레벨이 되었구나’라는 생각이 떠올랐다.\n그리고 8년이 지났다. 지금 ‘아미’는 팬덤의 대명사이자 케이팝의 글로벌 영향력을 상징하는 단어가 되었다. 또한 팬덤은 일종의 개념으로도 자리잡고 있다. 2016년엔 대기업 상무님의 ‘덕밍아웃’이 쿨하게 여겨졌다면, 2024년엔 신입 마케터 채용 조건에 ‘덕질’을 언급할 만큼 일반화되었다. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}이제 팬덤은 사업적으로도, 산업적으로도 중요한 요소가 되었다.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}음악 산업에서 팬덤이 중요해진 이유\n2024년 현재, 스포티파이 기준 하루에 업로드되는 음악은 12만 곡 정도다. 오타가 아니다. 12만 곡이다. 1곡 당 최소 3분으로 잡으면(음악의 길이는 점점 짧아져서 이젠 3분 30초가 보통이다) 총 6천 시간, 250일이 된다. 하루에 업로드되는 음악을 듣는 데에만 거의 1년의 시간이 필요하다. 그런데 음악만 이럴까? 유튜브는 더하다. 2018년 기준으로 유튜브에는 1분마다 약 500시간 분량의 콘텐츠가 업로드되는데, 이걸 다 보려면 82년이 걸린다.\n그러니까 콘텐츠의 생산 수준은 이미 상식을 벗어났다는 얘기다. 그래도 생산 속도가 좀 느리진 않을까? 천만에. 생성형 AI가 가세하면서 그 속도는 상상 이상으로 빨라지고 있다. 1년만 지나도 영상과 음악 콘텐츠는 지금의 몇 배는 늘어날 수 있다. 우리는 인류 역사상 한 번도 경험하지 못한 콘텐츠 무한공급의 시대를 살고 있다. 그리고 이 시대야말로 문화예술을 사랑하는 사람들이 상상하던 바로 그 ‘문화 예술이 일상이 된 시대’다. 어서오세요, 문화 예술 콘텐츠가 흘러넘치는 디스토피아에.\n생산자로서는 노출이 중요해질 수밖에 없다. 세상 어딜 둘러봐도 ‘마케팅’이 문제고, 곳곳에서 마케터가 자주 눈에 띄는 이유다. 그런데 마케팅의 역할은 애초에 광고 집행이 아니라 효율적인 시장을 개발하는 것이다. 시장이 있어야 광고도 쓸모 있으니까. 그런데 지금은 미디어가 많아도 너무 많다. 기껏해야 텔레비전, 신문, 잡지, 라디오가 전부였던 ‘매스 미디어’ 시대에는 몇 개의 광고만으로도 큰 관심을 얻을 수 있었다. 우리 제품을 사주세요! 우리 음악을 들어주세요! 우리 영화 보러 극장에 오세요!\n하지만 지금은 무수히 많은 콘텐츠 채널과 앱 서비스가 알아서 돌아가는 시대다. 스마트폰 사용자는 전세계 55억명을 돌파했고, 이들은 스마트폰을 개인용 TV, 극장, 오디오, 게임기로 쓰고 있다. 55억개의 미디어가 존재하는 셈이다. 있는 줄도 몰랐던 유튜브 채널의 구독자가 5만, 10만, 20만이라는 걸 알게 되었을 때 얼마나 당황스러웠는지 떠올려보자. 2024년은 콘텐츠도 많은데 그걸 안내하고 유통하는 채널도 무수히 많은 시대다.\n그래서 팬덤이 중요해졌다. 팬덤의 부상은 미디어 분화의 결과다. 팬덤은 명확한 타깃의 총합이다. 홍보 효과가 큰 반면, 마케팅 비용은 적게 든다. 전환율도 높다. 팬은 기능이나 가격이 아니라 스토리와 드라마에 끌리는 사람들이다. 그래서 공감이 중요하다. 소비자들은 천천히 마음을 열다가  마침내 시간과 애정이라는 고귀한 ‘자원’을 쓰는 팬이 된다. 한국의 케이팝 팬들은 이들을 ‘덕후’라고 부른다. 다른 업계에서는 ‘찐팬’이라고 부른다. 해외에서는? ‘슈퍼 팬’이라고 부른다.\n슈퍼 팬은 왜 중요할까? \n음악 업계에서 ‘슈퍼 팬’이란 말이 유행한 것은 최근의 일이다. 음악, 영화, TV에 대한 방대한 데이터를 분석하는 회사 루미네이트(1990년에 빌보드 차트의 현대적 솔루션을 만든 회사다)는 2023년 7월에 50페이지 분량의 상반기 음악시장 보고서를 발표했는데, 여기서 ‘슈퍼 팬’이라는 개념이 본격적으로 등장했다.\n음악 산업에서 슈퍼 팬은 스트리밍 청취, 뮤직비디오 시청, 음반 구매*, 공연 참여, 굿즈 구매 등 최소 5가지 이상의 방법으로 한 아티스트의 콘텐츠를 소비하고 관계를 맺는 사람들로 정의한다. 미국의 슈퍼 팬은 일반 리스너와 비교해서 매달 음악에 80% 이상의 돈을 쓰는데 루미네이트는 이러한 슈퍼 팬이 미국 음악 시장 전체에서 최소한 15%를 차지한다고 분석했다. 특히 밀레니얼 세대(22% 이상), Z세대(13% 이상)가 주요 그룹이다.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*일단 피지컬(실물) 앨범을 구매한다면 슈퍼 팬이 될 가능성이 2배 이상 높다.\n우리는 이 슈퍼 팬이 대부분 케이팝 팬일 거라고 예상하지만 놀랍게도 아니다. 압도적으로 높은 것은 아프로-팝(블랙뮤직)의 팬들이고, 그 다음이 케이팝, 그 다음에 EDM이다. 다만 케이팝 팬들은 다른 장르 팬들에 비해 음반과 굿즈를 더 많이 구매한다. 그래서 미국 음악 업계는 요즘 케이팝에 관심이 많다. 대체 무슨 요술을 부리길래 저렇게 많은 팬들이 저렇게 많은 CD와 굿즈를 사는 걸까? 2024년인데! 딱 이런 궁금증이 케이팝에 대한 관심과 호감을 키운다. 유니버설뮤직그룹(UMG)이 하이브와 계약을 맺고, 워너뮤직그룹(WMG)이 위버스와 비슷한 .css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}팬덤 플랫폼을 만들겠다고 하는 것도 같은 이유다.\n사실 음악 산업의 비즈니스 모델은 슈퍼 팬을 찾는 방법에서부터 시작된다. 이때 팬을 찾는 방법론은 기존의 마케팅 방법론과는 다를 수밖에 없다. 팬은 소비자가 아니다. 팬은 부가 가치도 아니다. 팬은 수익 그 자체를 만드는 존재이면서 동시에 산업을 지탱하는 기반이기도 하다. 콘텐츠 비즈니스에서 슈퍼 팬은 비즈니스 모델의 처음이자 끝이다. 그런데 또한, 팬은 비즈니스 관점으로만 설명할 수 없는 존재다. 수익율과 전환율 같은 이런저런 지표를 관통하면서 팬은 마침내 문화를 만든다. 그래서 중요하다. 팬을 찾고 싶다면 결국 팬을 관찰하고 팬 문화를 경험할 수밖에 없다. 그걸 통해 팬을 어떻게 정의하고, 팬과 어떤 관계를 맺으며, 팬과 무엇을 함께 할 것인지 발견할 수밖에 없다. 그게 바로 팬덤 비즈니스다.\n팬덤 비즈니스를 하고 싶다면\n음악 산업의 슈퍼 팬을 이해해야 한다\n사실, 음악계 뿐 아니라 누구든 팬을 원하는 시대다. 여기서 ‘누구나’란 말이 질소로 빵빵한 과자 포장지 같을지 모르겠지만, 사실은 사실이다. 정말로 누구나 팬을 원한다.\n2021년부터 ‘팬덤 경영’을 강조한 LG는 지금도 팬을 만들기 위해 다양한 전략을 구사하고 있다. 애플은 말할 것도 없고, 짝퉁으로 놀림받던 샤오미와 다이소도 이제는 팬덤을 기반으로 사업을 확장한다. [어벤저스4: 엔드 게임] 이후 지지부진하던 마블은 어떤가? 얼마 전 공개한 [어벤져스5: 둠스데이]의 메인 빌런 ‘닥터 둠’으로 로버트 다우니 주니어를 섭외했다. 그가 연기한 슈퍼히어로이자 팬층이 두터웠던 ‘아이언 맨’은 전작에서 사망해 MCU에서 영영 사라졌는데, 신작에서 갑자기 우주 최강 빌런으로 부활한 것이다. 마블은 이제 꽤 복잡한 퍼즐을 맞춰야겠지만, 팬들은 일단 열광했다.\nF&B 업계에서도 팬은 중요하다. 올해 4월, ‘한식의 글로벌'이라는 주제로 [난로 인사이트 2024]라는 컨퍼런스가 열렸다. 행사에는 월드 챔피언 레스토랑으로 꼽히는 스페인의 센트럴(Central)과 디스푸르타르(Disfrutar)의 셰프들, 미국에서 한식 푸드트럭의 신화를 쓴 컵밥(CUPBOP)의 송정훈 대표, 유럽에서 한식 프랜차이즈를 개척 중인 요리(YORI)의 김종순 대표와 같은 사업가들이 참여했는데, 그곳에서 나는 케이팝과 뉴진스, 팬덤 비즈니스에 대해 발표했다. 행사가 끝나고도 여러 셰프들과 자리를 옮기며 글로벌, 브랜딩, 팬덤에 대해 동이 틀 때까지 대화를 나눴다.\n유튜브가 매년 발행하는 ‘컬쳐 & 트렌드 리포트’의 2024년 주제*도 '팬덤'이었다. 유튜버만큼 팬들이 중요하다는 얘기였다. 그야말로, 지금은 팬의 시대다. 그래서 아티스트나 크리에이터들 뿐 아니라 브랜드 마케터, 콘텐츠 기획자들은 팬을 관찰하고, 팬 문화를 더 많이 경험할 필요가 있다. \n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n📝 유튜브의 컬쳐 & 트렌드 리포트 2024에서는 \n\n팬이 콘텐츠 소비자가 아니라 적극적인 창작자로 진화하고 있다는 점을 짚었다. 숏폼 동영상 제작 툴과 생성형 AI 등 기술 발전으로 팬 참여가 급진적으로 쉬워지면서 캐주얼 팬이 적극적으로 돈을 지불하는 빅 팬이 되거나, 팬심으로 수익까지 창출하는 프로 팬으로 변화하고 있다는 것이다. \n특히 미국의 Z세대 65%가 자신을 ‘크리에이터'로 인식하고, 그 중 8%가 프로 팬으로서 수익을 창출한다는 부분이 흥미로웠다. 20세기의 팬들이 대상을 동경하면서 추종했다면, 21세기 팬들은 대상을 가지고 놀면서 수평적인 관계를 만든다.\n\n앞서 언급한 루미네이트의 보고서에는 음악의 슈퍼 팬이 왜 중요할 수밖에 없는지에 대한 이유가 등장한다. 음악의 슈퍼 팬은 스포츠 팬*에 비해 브랜드 파트너십에 매우 호의적이다. 쉽게 말해 아티스트가 어떤 브랜드의 광고 모델이 된다고 해도 거부감이 거의 없다. 음악이 브랜드 광고에 쓰여도 그러려니 한다. 오히려 자연스럽게 브랜드 구매로 이어지거나, 다른 사람들에게 적극적으로 그 브랜드를 알리기도 한다. 심지어 음악 팬들은 스포츠 팬에 비해 온라인 쇼핑이나 화장품, 배달 음식에 대해서도 더 호의적이다. \n*미국 사회에서 팬은, 한국과 달리 여전히 서브컬쳐에 머무는 존재다. 할리우드 청춘 영화나 드라마에서 사회성 부족한 인물이 ‘덕후’나 ‘너드’ 캐릭터로 등장하는 것도 그런 이유다. 그나마 ‘의미있는 집단’으로서의 슈퍼 팬은 스포츠에 국한되는데, 보통 미식축구, 농구, 야구 팬들을 대상으로 한 연구가 많았다. 음악의 슈퍼 팬에 대한 연구는 이제 시작 단계다. 그래서 종종 스포츠의 팬들과 비교된다. \n쉽게 말해, 음악 팬들은 일반 소비자보다 자신이 좋아하는 것에 더 많은 돈과 시간을 쓴다. 우리 비즈니스의 팬덤을 음악의 슈퍼 팬처럼 만들 수 있다면 얼마나 좋을까? 이게 바로 화장품 회사든 대기업이든, 음악 팬들을 이해하고 음악 산업을 살펴야봐야 할 이유다. \n\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 송수아 Graphic 이은호",
        "content": "비즈니스를 한다면, 음악 산업의 팬덤에 주목해야 하는 이유 ",
        "contentSnippet": "비즈니스를 한다면, 음악 산업의 팬덤에 주목해야 하는 이유",
        "guid": "https://blog.toss.im/article/fandustry-01",
        "isoDate": "2024-09-09T23:36:00.000Z"
      },
      {
        "title": "조선 시대 제사상 비용은 얼마였을까?",
        "link": "https://blog.toss.im/article/behindthemoney-7",
        "pubDate": "Mon, 09 Sep 2024 08:12:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}우리나라를 포함한 동아시아에는 오래된 믿음이 있다. ‘조상신이 가족을 돌보고 복을 준다.’ 사람을 돕는 신은 오직 죽은 자들, 그것도 가족 단위로 조상들만이 후손들을 돕는다고 믿었다. 물론 동아시아에도 옥황상제, 산신, 용왕 등 다양한 신들이 있지만 이런 자연신들은 자신들의 영역을 관장할 뿐 인간계에는 개입하지 않는다.\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}조상이 후손을 돕는다는 믿음은 유교 문화에 흡수되었고, 이러한 믿음에 따라 동아시아 제사 문화의 기본 단위는 ‘가족'이 되었다. 지금까지 가족 단위로 제사를 지내는 것은 수천 년에 걸쳐 내려온 오래된 동아시아 사람들의 믿음과 전통 때문인 것이다.\n하지만 오래된 전통이라도 시대에 따라 형태와 모양은 변하기 마련이다. 온라인에 보이는 요즘 제사 풍경은 그야말로 각양각색. 할머니, 할아버지가 생전에 좋아하시던 음식을 제사상에 올리기도 하고, 피자나 치킨이 제사상의 주인이 되기도 한다. 그렇다면, 옛날 제사상에는 어떤 음식이 올랐을까?\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}800년 전 제사상 엿보기\n시대별로 제사상에 오른 음식에 대해 명확히 설명하기는 어렵다. 제사 음식에 대한 구체적인 기록이 많지 않기도 하다. 수백 년 전통을 자랑하는 종갓집 제사상도 대부분 조선 후기의 문화를 반영하기 때문에 우리가 상상하는 제사상과 큰 차이가 없다.\n그럼에도 과거 기록은 몇 가지 흥미로운 사실을 알려준다. 고려 시대 의학서 ‘향약구급방'을 보면 연근, 도라지, 토란, 아욱, 상치, 무, 배추, 우엉 같은 채소를 제사상에 올렸다. 국가의 큰 제사에는 미나리, 죽순, 무청 등을 올렸다.\n시대에 따라 다양한 채소와 과일이 제사상에 올랐지만, 복숭아만큼은 제사상에 오르지 못했다. 공자의 제자들은 복숭아가 과일 중에 가장 하등품이고, 조상님들께 바치기에는 천박한 과일이라고 보았다. 반면,\n떡은 제사상에나 올리는 귀한 음식이었다. 전통사회에서는 쌀이 귀했기 때문에 떡을 만드는 것은 사치스러운 문화였고 제사상 혹은 잔칫상에서나 볼 수 있는 음식이었다.\n예나 지금이나 부담스러웠던 제사 비용\n2023년 추석 차례상 평균 비용은 30만 3,002원이었다.* 해마다 물가가 오르고 제사 비용에 대한 부담이 커지니 명절이 되면 제사상을 간소화하자는 기사가 쏟아진다. ‘옛날 제사상은 화려하지 않았다', ‘명문가일수록 제사상이 단출했다'는 식의 기사를 한 번쯤 보았을 것이다. 하지만 옛날 제사상이 간소했다는 주장은 1970년대 이후 정부 정책 영향의 결과이지 역사적 사실은 아니다.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*한국농수산식품유통공사 조사 결과\n오늘날에는 명절 차례와 가족 제사를 지내는 정도지만 과거에는 국가에서 제례를 지내고, 마을에서는 동제를 지내고, 절기마다 제사를 지냈다. 제사는 삶의 일부였다. 더구나 제사는 공동체의 축제였기 때문에 최대한 성대하게 치러졌다.\n조선시대에도 제사상을 차리는 데는 비용이 많이 들었다. 제사 비용을 충당하기 위해 ‘위토(位土)’라는 제도가 따로 있을 정도였다. 위토는 제사를 위한 토지로써 문중에서 공동으로 소유했던 땅이다. 위토에서 나오는 곡식을 팔아 제사 비용을 마련하거나 위토에 소작을 주어서 돈을 마련하기도 했다. 조선 시대에는 가문에 재산이 많고 크게 번성하면 문중을 중심으로 성대한 제사를 지냈다. 명절 때 차례는 물론이고 4대조에 이르는 조상의 기일에 맞추어서 일년 내내 제사를 지냈다.\n일반 평민들 역시 형편에 맞추어 제사를 지냈다. 형편이 어려워서 제사상이 단출할 수는 있어도 제사를 지내지 않는 경우를 상상하기는 어렵다. 물 한 사발이라도 올려놓고 치성을 드려야 하는 것이 법도인바, 최초로 제사를 거부하여 진산사건(1791)*을 일으킨 윤지충은 정조의 명에 따라 목숨을 잃고 가문이 풍비박산되었다.\n*1791년, 전라도 진산(珍山)의 윤지충, 권상연 두 선비가 부모의 제사를 거부하고 위패를 불태운 사건. 두 사람은 천주교 신자였으며 교리에 따라 조상의 제사를 거부했다.\n1934년, 일제강점기에는 제사 비용을 마련하지 못해서 음독자살 했던 어느 부부의 이야기가 신문에 보도된 적이 있었다. 제사 비용에 대한 부담뿐만 아니라 식민지 시절 가난한 백성의 고달픈 살림살이에 대한 애환을 담고 있는 기사이다.\n.css-2sk6rv{font-size:19px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);white-space:pre-wrap;margin:24px 0;padding-left:20px;position:relative;}.css-2sk6rv::before{content:'';display:block;position:absolute;top:4px;left:0;width:2px;height:calc(100% - 4px * 2);padding:4px 0;background-color:var(--adaptiveGrey800);}\n.css-1odxvuk{white-space:pre-wrap;font-style:italic;}“부부간 싸움 끝에 양재물을 먹고 자살하였는데.. 모친의 제사 지낼 비용을 십원만 부조해달라는 편지를 받고... 가난한 생활을 견딜 수 없어.. 비관자살을 하였다.\"\n- 1934. 2. 19. 조선일보.css-7mseny>*{margin-left:0;margin-right:0;}.css-7mseny>:last-child{margin-bottom:0;}blockquote>.css-7mseny:first-child>:first-child{margin-top:0;}\n갈비찜 대신 사태찜, 식혜 대신 화채 \n나라에서 정해주는 제사상 가이드\n6.25전쟁 이후 산업화가 진행되면서 사람들은 농촌을 떠나 도시에 정착했고, 경제성장에 버금가는 물가상승 덕분에 제사상 비용은 점차 사회 문제가 되었다.\n한정된 월급에서, 날로 물가는 오르고 따라서 필수의 씀씀이가 자꾸 늘어가는데 반비례하여 제사비용으로 돌아가는 예산은 축소될 수밖에 없다. 종가라고 해서 모든 것을 우리에게만 전담시킬 것이 아니라 세 집에서 분담하는 것이 바람직한 일이다. 분노를 삭이듯 침통하게 눈을 감고 계시던 숙부가 천천히 고개를 들었다. \n\n“일언이 폐지하고 이런 문제에 네가 나설 일이 아니야. 네 남편이 있잖아. 네 남편이, 네가 살림을 맡고서부터 젯상은 날로 형편이 없어졌어. 두고보자 보자 했더니 이건 한술 더 떠서 뭔시 어쩌고 어째? 아니 그래 갑자기 이 집이 망하기라도 했다는게냐 엉? 항창 그렇다 치자. 네 남편을 통해 얘기하는거야.”\n- 1973. 1. 4. 동아일보\n위의 내용은 ‘제삿날’이라는 1970년대 동아일보 기사의 일부이다. 치솟는 물가와 부담스러운 제사 비용 때문에 장손의 며느리가 제사 비용을 분담하자고 했다가 숙부들의 분노와 반발을 샀다는 내용이다. 숙부들은 ‘너가 며느리로 들어온 후 제사상이 형편없어졌다.’, ‘할 얘기 있으면 너가 아니라 네 남편이 해야 한다’ 등 모욕적인 말도 서슴치 않았다.\n1960년대 이후 한국 사회는 과도한 제사 비용을 해소하기 위해 머리를 맞대기 시작한다. 정부에서는 전통적인 관혼상제의 허례허식을 줄이고, 절차의 간소화를 위한 ‘가정의례준칙’을 만들어 검소한 제사상을 강제했다. 가족끼리 제사와 차례 비용을 분담하는 방식 역시 이때부터 나온 이야기다.\n첫째, 제사를 꼭 맏아들이 주관할 필요는 없다. 둘째, 형식보다는 내면이기 때문에 고인이 평소 좋아하던 음식으로 제사상을 차리거나 고인의 유품 같은 것을 놓을 것을 권장한다. 셋째, 축문은 한문이 아닌 한글로 써서 조상과 자손 간의 유대 관계를 강화한다. 1970년대 유신 시절 정부는 한바탕 제사상과의 전쟁을 치렀는데 그럼에도 불구하고 제사 자체를 폐지하는 데는 이르지 못했다.\n1980년대가 되면 더욱 구체적인 제사상 가이드가 등장한다. ‘다섯 명 기준으로 2~3만 원 정도’를 적정 제사 비용으로 보았고 이를 실천하기 위해 소고기가 아닌 돼지고기나 닭고기 사용을 권장했고 갈비찜보다는 사태찜, 버섯은 송이버섯보다는 표고버섯이나 느타리버섯, 식혜보다는 화채를 사용하면 비용을 낮출 수 있다는 것이다. 유신 체제 때 강제하던 가정의례준칙은 1999년 폐지되었지만, 90년대 초반까지 보다 실용적인 해법을 도모하며 제사 비용을 아끼려는 노력은 계속 이어졌다.\n하마터면 사라질 뻔했던 추석\n사실 제사 비용보다 문제가 되었던 것은 추석을 비롯한 명절 자체를 없애버리려는 시도였다. 1927년 조선을 점령한 일본은 공휴일제도를 법제화했다. 원시제(양력 1월 3일), 신무천황제(양력 4월 3일), 신상제(양력 10월 17일), 명치절(양력 11월 3일) 등 새롭게 마련된 절기는 철저하게 일본의 문화를 바탕으로 했다.\n그중 신상제는 천황이 신에게 햇곡식을 바치는 제도로써 추석을 대체하는 제도였다. 우리 민족의 명절은 음력을 따라 계산되었는데 일제는 서구화를 도모하면서 양력 공휴일제를 강요한 것이다. 심지어 명절을 맞이해 단체 삭발을 강요하기도 했다. 소위 '스포츠 머리'로 깨끗하고 단정하게 머리를 밀어버리라는 근본없는 문화가 생기기도 했다.\n해방이 되고나니 미국의 영향을 받아 추석을 ‘추석감사일’, 즉 추수감사절과 같은 날로 만들고자 했으니 이 또한 웃지 못할 해프닝이었다. 우여곡절을 거치며 1989년이 되어서야 지금과 같이 음력을 바탕으로 한 설·추석 3일 연휴제가 만들어졌다.\n놀라운 것은 이 기간에도 명절 문화는 유지가 되었다는 점이다. 공휴일이 아니더라도, 일제가 억압을 하고, 정부가 못하게 하더라도 사람들은 명절이 되면 모였고, 세시 풍속을 즐겼고, 덕담을 나누었다. 따져보니 추석은 100년 만에 부활한 셈이다. 앞으로 명절 풍경은 어떻게 변하게 될까? 시대에 어울리는 풍요롭고, 스트레스 없는 추석 명절 문화가 만들어지길 기대해본다.\n.css-13d8cj1{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;margin:24px 0 8px;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:var(--adaptiveGrey700);}\n.css-1dzrkjz{width:16px;margin-right:8px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}\n.svg-icon-wrapper{position:relative;display:inline-block;width:24px;height:24px;}.svg-icon-wrapper >.svg-icon:empty+.svg-icon-fallback{visibility:visible;z-index:inherit;}.svg-icon{color:var(--adaptiveGrey900);display:inline-block;width:24px;height:24px;display:block;width:100%;height:100%;}.svg-icon svg,.svg-icon img{display:block;width:100%;height:100%;}.svg-icon--hide{display:none;}.svg-icon-fallback{position:absolute;left:0;right:0;top:0;z-index:z-index(hidden);visibility:hidden;display:block;width:100%;height:100%;}.svg-icon-fallback--show{visibility:visible;z-index:inherit;}\n참고자료\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 이지영 Graphic 이은호",
        "content": "옛날 제사상이 간소했다는 주장, 역사적 사실은 아니다.",
        "contentSnippet": "옛날 제사상이 간소했다는 주장, 역사적 사실은 아니다.",
        "guid": "https://blog.toss.im/article/behindthemoney-7",
        "isoDate": "2024-09-09T08:12:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]