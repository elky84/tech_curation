[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Sinem Akinci",
        "title": "Understand your C++ symbols using Copilot in Visual Studio’s Quick Info",
        "link": "https://devblogs.microsoft.com/cppblog/understand-your-c-symbols-using-copilot-in-visual-studios-quick-info/",
        "pubDate": "Tue, 18 Jun 2024 09:00:30 +0000",
        "content:encodedSnippet": "Navigating your codebase and forget what exactly that method does? Looking for quick, easy-to-digest information on your code at any point in your development journey?\nWe are excited to announce that now when you hover over symbols in your codebase, you’ll be able to invoke Copilot conveniently within the Quick Info dialog to learn more about a given symbol and enhance existing or lacking code documentation.\nHow it works\nNormally, in the Quick info window, you would see comments or xml documentation if it was generated by your team in the code, which can sometimes be unrelated to what the given symbol does. Copilot can help augment existing documentation or lacking documentation.\nJust hover over your symbol of interest and click on the link to learn more about what it does in natural language, rather than having to go to the definition and parse through all the code.\n\n\nCopilot uses the declaration and definition of the given symbol to provide you an understanding of it at any invocation.\nFor example, when working with unfamiliar library code, there is often context from the source code of the symbol definition to infer the purpose of the symbol.\n\n\nTry it out\nThis feature is available in any C++ codebase as of Visual Studio 2022 version 17.10. Stay tuned for upcoming support for other languages and please let us know anything you’d like to see added to this feature. You’ll need an active GitHub Copilot subscription. Download the latest version of Visual Studio and give it a try.\nIn addition, our team is working hard on improving C++ integrations with Copilot Chat, so please let us know any other enhancements you’d like to see to your C++ workflows and content you’d like to see.\nWe welcome all types of feedback on your experience with the product. Comment below, or you can find us via email at visualcpp@microsoft.com or via X at @VisualC.\nThe post Understand your C++ symbols using Copilot in Visual Studio’s Quick Info appeared first on C++ Team Blog.",
        "dc:creator": "Sinem Akinci",
        "comments": "https://devblogs.microsoft.com/cppblog/understand-your-c-symbols-using-copilot-in-visual-studios-quick-info/#comments",
        "content": "<p>Navigating your codebase and forget what exactly that method does? Looking for quick, easy-to-digest information on your code at any point in your development journey?<br />\nWe are excited to announce that now when you hover over symbols in your codebase, you&#8217;ll be able to invoke Copilot conveniently within the Quick Info dialog to learn more about a given symbol and enhance existing or lacking code documentation.</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/understand-your-c-symbols-using-copilot-in-visual-studios-quick-info/\">Understand your C++ symbols using Copilot in Visual Studio&#8217;s Quick Info</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "Navigating your codebase and forget what exactly that method does? Looking for quick, easy-to-digest information on your code at any point in your development journey?\nThe post Understand your C++ symbols using Copilot in Visual Studio’s Quick Info appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34348",
        "categories": [
          "C++",
          "Copilot"
        ],
        "isoDate": "2024-06-18T09:00:30.000Z"
      }
    ]
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Leveraging AI for efficient incident response",
        "link": "https://engineering.fb.com/2024/06/24/data-infrastructure/leveraging-ai-for-efficient-incident-response/",
        "pubDate": "Mon, 24 Jun 2024 16:00:57 +0000",
        "content:encodedSnippet": "We’re sharing how we streamline system reliability investigations using a new AI-assisted root cause analysis system.\nThe system uses a combination of heuristic-based retrieval and large language model-based ranking to speed up root cause identification during investigations.\nOur testing has shown this new system achieves 42% accuracy in identifying root causes for investigations at their creation time related to our web monorepo.\nInvestigation is a critical part of ensuring system reliability, and a prerequisite to mitigating issues quickly. This is why Meta is investing in advancing our suite of investigation tooling with tools like Hawkeye, which we use internally for debugging end-to-end machine learning workflows.\nNow, we’re leveraging AI to advance our investigation tools even further. We’ve streamlined our investigations through a combination of heuristic-based retrieval and large language model (LLM)-based ranking to provide AI-assisted root cause analysis. During backtesting, this system has achieved promising results: 42% accuracy in identifying root causes for investigations at their creation time related to our web monorepo.\n\nInvestigations at Meta\nEvery investigation is unique. But identifying the root cause of an issue is necessary to mitigate it properly.  Investigating issues in systems dependent on monolithic repositories can present scalability challenges due to the accumulating number of changes involved across many teams. In addition, responders need to build context on the investigation to start working on it, e.g., what is broken, which systems are involved, and who might be impacted. \nThese challenges can make investigating anomalies a complex and time consuming process. AI offers an opportunity to streamline the process, reducing the time needed and helping responders make better decisions. We focused on building a system capable of identifying potential code changes that might be the root cause for a given investigation.\nFigure 1: A responder’s view of an investigation journey.\nOur approach to root cause isolation\nThe system incorporates a novel heuristics-based retriever that is capable of reducing the search space from thousands of changes to a few hundred without significant reduction in accuracy using, for example., code and directory ownership or exploring the runtime code graph of impacted systems. Once we have reduced the search space to a few hundred changes relevant to the ongoing investigation, we rely on a LLM-based ranker system to identify the root cause across these changes.\nFigure 2: The system flow for our AI-assisted root cause analysis system.\nThe ranker system uses a Llama model to further reduce the search space from hundreds of potential code changes to a list of the top five. We explored different ranking algorithms and prompting scenarios and found that ranking through election was most effective to accommodate context window limitations and enable the model to reason across different changes. To rank the changes, we structure prompts to contain a maximum of 20 changes at a time, asking the LLM to identify the top five changes. The output across the LLM requests are aggregated and the process is repeated until we have only five candidates left. Based on exhaustive backtesting, with historical investigations and the information available at their start, 42% of these investigations had the root cause in the top five suggested code changes.\nFigure 3: Ranking possible code changes through election.\nTraining\nThe biggest lever to achieving 42% accuracy was fine-tuning a Llama 2 (7B) model using historical investigations for which we knew the underlying root cause. We started by running continued pre-training (CPT) using limited and approved internal wikis, Q&As, and code to expose the model to Meta artifacts. Later, we ran a supervised fine-tuning (SFT) phase where we mixed Llama 2’s original SFT data with more internal context and a dedicated investigation root cause analysis (RCA) SFT dataset to teach the model to follow RCA instructions.\nFigure 4: The Llama 2 (7B) root cause analysis training process.\nOur RCA SFT dataset consists of ~5,000 instruction-tuning examples with details of 2-20 changes from our retriever, including the known root cause, and information known about the investigation at its start, e.g., its title and observed impact. Naturally, the available information density is low at this point, however this allows us to perform better in similar real-world scenarios when we have limited information at the beginning of the investigation. \nUsing the same fine-tuning data format for each possible culprit then allows us to gather the model’s llog probabilities(logprobs) and rank our search space based on relevancy to a given investigation. We then curated a set of similar fine-tuning examples where we expect the model to yield a list of potential code changes likely responsible for the issue ordered by their logprobs-ranked relevance, with the expected root cause at the start. Appending this new dataset to the original RCA SFT dataset and re-running SFT gives the model the ability to respond appropriately to prompts asking for ranked lists of changes relevant to the investigation.\nFigure 5: The process for generating fine-tuning prompts to enable the LLM to produce ranked lists.\nThe future of AI-assisted Investigations\nThe application of AI in this context presents both opportunities and risks. For instance, it can reduce effort and time needed to root cause an investigation significantly, but it can potentially suggest wrong root causes and mislead engineers. To mitigate this, we ensure that all employee-facing features prioritize closed feedback loops and explainability of results. This strategy ensures that responders can independently reproduce the results generated by our systems to validate their results. We also rely on confidence measurement methodologies to detect low confidence answers and avoid recommending them to the users – sacrificing reach in favor of precision.\nBy integrating AI-based systems into our internal tools we’ve successfully leveraged them for tasks like onboarding engineers to investigations and root cause isolation. Looking ahead, we envision expanding the capabilities of these systems to autonomously execute full workflows and validate their results. Additionally, we anticipate that we can further streamline the development process by utilizing AI to detect potential incidents prior to code push, thereby proactively mitigating risks before they arise.\nAcknowledgements\nWe wish to thank contributors to this effort across many teams throughout Meta, particularly Alexandra Antiochou, Beliz Gokkaya, Julian Smida, Keito Uchiyama, Shubham Somani; and our leadership: Alexey Subach, Ahmad Mamdouh Abdou, Shahin Sefati, Shah Rahman, Sharon Zeng, and Zach Rait. \nThe post Leveraging AI for efficient incident response appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>We’re sharing how we streamline system reliability investigations using a new AI-assisted root cause analysis system. The system uses a combination of heuristic-based retrieval and large language model-based ranking to speed up root cause identification during investigations. Our testing has shown this new system achieves 42% accuracy in identifying root causes for investigations at their [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/06/24/data-infrastructure/leveraging-ai-for-efficient-incident-response/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/06/24/data-infrastructure/leveraging-ai-for-efficient-incident-response/\">Leveraging AI for efficient incident response</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "We’re sharing how we streamline system reliability investigations using a new AI-assisted root cause analysis system. The system uses a combination of heuristic-based retrieval and large language model-based ranking to speed up root cause identification during investigations. Our testing has shown this new system achieves 42% accuracy in identifying root causes for investigations at their [...]\nRead More...\nThe post Leveraging AI for efficient incident response appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21393",
        "categories": [
          "Data Infrastructure",
          "DevInfra",
          "ML Applications"
        ],
        "isoDate": "2024-06-24T16:00:57.000Z"
      },
      {
        "creator": "",
        "title": "PVF: A novel metric for understanding AI systems’ vulnerability against SDCs in model parameters",
        "link": "https://engineering.fb.com/2024/06/19/data-infrastructure/parameter-vulnerability-factor-pvf-ai-silent-data-corruption/",
        "pubDate": "Wed, 19 Jun 2024 16:00:46 +0000",
        "content:encodedSnippet": "We’re introducing parameter vulnerability factor (PVF), a novel metric for understanding and measuring AI systems’ vulnerability against silent data corruptions (SDCs) in model parameters.\nPVF can be tailored to different AI models and tasks, adapted to different hardware faults, and even extended to the training phase of AI models.\nWe’re sharing results of our own case studies using PVF to measure the impact of SDCs in model parameters, as well as potential methods of identifying SDCs in model parameters.\nReliability is an important aspect of any successful AI implementation. But the growing complexity and diversity of AI hardware systems also brings an increased risk of hardware faults such as bit flips. Manufacturing defects, aging components, or environmental factors can lead to data corruptions – errors or alterations in data that can occur during storage, transmission, or processing and result in unintended changes in information.\nSilent data corruptions (SDCs), where an undetected hardware fault results in erroneous application behavior, have become increasingly prevalent and difficult to detect. Within AI systems, an SDC can create what is referred to as parameter corruption, where AI model parameters are corrupted and their original values are altered.\nWhen this occurs during AI inference/servicing it can potentially lead to incorrect or degraded model output for users, ultimately affecting the quality and reliability of AI services.\nFigure 1 shows an example of this, where a single bit flip can drastically alter the output of a ResNet model. \nFigure 1: Flipping a random bit of one parameter in the 1st convolution (conv) layer in ResNet-18 drastically alters the model’s output.\n \nWith this escalating thread in mind, there are two important questions: How vulnerable are AI models to parameter corruptions? And how do different parts (such as modules and layers) of the models exhibit different vulnerability levels to parameter corruptions?\nAnswering these questions is an important part of delivering reliable AI systems and services and offers valuable insights for guiding AI hardware system design, such as when assigning AI model parameters or software variables to hardware blocks with differing fault protection capabilities. Additionally, it can provide important information for formulating strategies to detect and mitigate SDCs in AI systems in an efficient and effective manner.\nParameter vulnerability factor (PVF) is a novel metric we’ve introduced with the aim to standardize the quantification of AI model vulnerability against parameter corruptions. PVF is a versatile metric that can be tailored to different AI models/tasks and is also adaptable to different hardware fault models. Furthermore, PVF can be extended to the training phase to evaluate the effects of parameter corruptions on the model’s convergence capability.\nWhat is PVF?\nPVF is inspired by the architectural vulnerability factor (AVF) metric used within the computer architecture community. We define a model parameter’s PVF as the probability that a corruption in that specific model parameter will lead to an incorrect output. Similar to AVF, this statistical concept can be derived from statistically extensive and meaningful fault injection (FI) experiments. \nPVF has several features:\nParameter-level quantitative assessment\nAs a quantitative metric, PVF concentrates on parameter-level vulnerability, calculating the likelihood that a corruption in a specific model parameter will lead to an incorrect model output. This “parameter” can be defined at different scales and granularities, such as an individual parameter or a group of parameters.\nScalability across AI models/tasks\nPVF is scalable and applicable across a wide range of AI models, tasks, and hardware fault models.\nProvides insights for guiding AI system design\nPVF can provide valuable insights for AI system designers, guiding them in making informed decisions about balancing fault protection with performance and efficiency. For example, engineers might leverage PVF to help map higher vulnerable parameters to better-protected hardware blocks and explore tradeoffs on latency, power, and reliability by enabling a surgical approach to fault tolerance at selective locations instead of a catch-all/none approach. \nCan be used as a standard metric for AI vulnerability/resilience evaluation\nPVF has the potential to unify and standardize such practices, making it easier to compare the reliability of different AI systems/parameters and fostering open collaboration and progress in the industry and research community.\nHow PVF works\nSimilar to AVF as a statistical concept, PVF needs to be derived through a large number of FI  experiments that are statistically meaningful. Figure 2 shows an overall flow to compute PVF through a FI process. We’ve presented a case study on the open-source DLRM inference with more details and example case studies in our paper.\nFigure 2: Computing PVF through FI.\nFigure 3 illustrates the PVF of three DLRM parameter components, embedding table, bot-MLP, and top-MLP, under 1, 2, 4, 8, 16, 32, 64, and 128 bit flips during each inference. We observe different vulnerability levels across different parts of DLRM. For example, under a single bit flip, the embedding table has relatively low PVF; this is attributed to embedding tables being highly sparse, and parameter corruptions are only activated when the particular corrupted parameter is activated by the corresponding sparse feature. However, top-MLP can have 0.4% under even a single bit flip. This is significant – for every 1000 inferences, four inferences will be incorrect. This highlights the importance of protecting specific vulnerable parameters for a given model based on the PVF measurement. \nFigure 3: The PVF of DLRM parameters under random bit flips.\nWe observe that with 128 bit flips during each inference, for MLP components, PVF has increased to 40% and 10% for top-MLP and bot-MLP components respectively, while observing multiple NaN values. Top-MLP component has higher PVF than bot-MLP. This is attributed to the top-MLP being closer to the final model, and hence has less of a chance to be mitigated by inherent error masking probability of neural layers. \nThe applicability of PVF\nPVF is a versatile metric where the definition of an “incorrect output” (which will vary based on the model/task) can be adapted to suit user requirements. To adapt PVF to various hardware fault models the method to calculate PVF remains consistent as depicted in Figure 2. The only modification required is the manner in which the fault is injected, based on the assumed fault models. \nFurthermore, PVF can be extended to the training phase to evaluate the effects of parameter corruptions on the model’s convergence capability. During training, the model’s parameters are iteratively updated to minimize a loss function. A corruption in a parameter could potentially disrupt this learning process, preventing the model from converging to an optimal solution. By applying the PVF concept during training, we could quantify the probability that a corruption in each parameter would result in such a convergence failure.\nDr. DNA and further exploration avenues for PVF\nThe logical progression after understanding AI vulnerability to SDCs is to identify and lessen their impact on AI systems. To initiate this, we’ve introduced Dr. DNA, a method designed to detect and mitigate SDCs that occur during deep learning model inference. Specifically, we formulate and extract a set of unique SDC signatures from the distribution of neuron activations (DNA), based on which we propose early-stage detection and mitigation of SDCs during DNN inference. \nWe perform an extensive evaluation across 10 representative DNN models used in three common tasks (vision, GenAI, and segmentation) including ResNet, Vision Transformer, EfficientNet, YOLO, etc., under four different error models. Results show that Dr. DNA  achieves a 100% SDC detection rate for most cases, a 95% detection rate on average and a >90% detection rate across all cases, representing 20-70% improvement over baselines. Dr. DNA can also mitigate the impact of SDCs by effectively recovering DNN model performance with <1% memory overhead and <2.5% latency overhead. \nRead the research papers\nPVF (Parameter Vulnerability Factor): A Novel Metric for Understanding AI Vulnerability Against SDCs in Model Parameters \nDr. DNA: Combating Silent Data Corruptions in Deep Learning using Distribution of Neuron Activations\nThe post PVF: A novel metric for understanding AI systems’ vulnerability against SDCs in model parameters appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>We’re introducing parameter vulnerability factor (PVF), a novel metric for understanding and measuring AI systems’ vulnerability against silent data corruptions (SDCs) in model parameters. PVF can be tailored to different AI models and tasks, adapted to different hardware faults, and even extended to the training phase of AI models. We’re sharing results of our own [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/06/19/data-infrastructure/parameter-vulnerability-factor-pvf-ai-silent-data-corruption/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/06/19/data-infrastructure/parameter-vulnerability-factor-pvf-ai-silent-data-corruption/\">PVF: A novel metric for understanding AI systems’ vulnerability against SDCs in model parameters</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "We’re introducing parameter vulnerability factor (PVF), a novel metric for understanding and measuring AI systems’ vulnerability against silent data corruptions (SDCs) in model parameters. PVF can be tailored to different AI models and tasks, adapted to different hardware faults, and even extended to the training phase of AI models. We’re sharing results of our own [...]\nRead More...\nThe post PVF: A novel metric for understanding AI systems’ vulnerability against SDCs in model parameters appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21376",
        "categories": [
          "Data Infrastructure"
        ],
        "isoDate": "2024-06-19T16:00:46.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": [
      {
        "creator": "Netflix Technology Blog",
        "title": "A Recap of the Data Engineering Open Forum at Netflix",
        "link": "https://netflixtechblog.com/a-recap-of-the-data-engineering-open-forum-at-netflix-6b4d4410b88f?source=rss----2615bd06b42e---4",
        "pubDate": "Thu, 20 Jun 2024 15:01:27 GMT",
        "content:encodedSnippet": "A summary of sessions at the first Data Engineering Open Forum at Netflix on April 18th, 2024\nThe Data Engineering Open Forum at Netflix on April 18th, 2024.\nAt Netflix, we aspire to entertain the world, and our data engineering teams play a crucial role in this mission by enabling data-driven decision-making at scale. Netflix is not the only place where data engineers are solving challenging problems with creative solutions. On April 18th, 2024, we hosted the inaugural Data Engineering Open Forum at our Los Gatos office, bringing together data engineers from various industries to share, learn, and connect.\nAt the conference, our speakers share their unique perspectives on modern developments, immediate challenges, and future prospects of data engineering. We are excited to share the recordings of talks from the conference with the rest of the world.\nOpening Remarks\nRecording\nSpeaker: Max Schmeiser (Vice President of Studio and Content Data Science & Engineering)\nSummary: Max Schmeiser extends a warm welcome to all attendees, marking the beginning of our inaugural Data Engineering Open Forum.\nEvolving from Rule-based Classifier: Machine Learning Powered Auto Remediation in Netflix Data Platform\nRecording\nSpeakers:\n\nStephanie Vezich Tamayo (Senior Machine Learning Engineer at Netflix)\nBinbing Hou (Senior Software Engineer at Netflix)\n\nSummary: At Netflix, hundreds of thousands of workflows and millions of jobs are running every day on our big data platform, but diagnosing and remediating job failures can impose considerable operational burdens. To handle errors efficiently, Netflix developed a rule-based classifier for error classification called “Pensive.” However, as the system has increased in scale and complexity, Pensive has been facing challenges due to its limited support for operational automation, especially for handling memory configuration errors and unclassified errors. To address these challenges, we have developed a new feature called “Auto Remediation,” which integrates the rules-based classifier with an ML service.\nAutomating the Data Architect: Generative AI for Enterprise Data Modeling\nRecording\nSpeaker: Jide Ogunjobi (Founder & CTO at Context Data)\nSummary: As organizations accumulate ever-larger stores of data across disparate systems, efficiently querying and gaining insights from enterprise data remain ongoing challenges. To address this, we propose developing an intelligent agent that can automatically discover, map, and query all data within an enterprise. This “Enterprise Data Model/Architect Agent” employs generative AI techniques for autonomous enterprise data modeling and architecture.\nTulika Bhatt, Senior Data Engineer at Netflix, shared how her team manages impression data at scale.\nReal-Time Delivery of Impressions at Scale\nRecording\nSpeaker: Tulika Bhatt (Senior Data Engineer at Netflix)\nSummary: Netflix generates approximately 18 billion impressions daily. These impressions significantly influence a viewer’s browsing experience, as they are essential for powering video ranker algorithms and computing adaptive pages, With the evolution of user interfaces to be more responsive to in-session interactions, coupled with the growing demand for real-time adaptive recommendations, it has become highly imperative that these impressions are provided on a near real-time basis. This talk will delve into the creative solutions Netflix deploys to manage this high-volume, real-time data requirement while balancing scalability and cost.\nReflections on Building a Data Platform From the Ground Up in a Post-GDPR World\nRecording\nSpeaker: Jessica Larson (Data Engineer & Author of “Snowflake Access Control”)\nSummary: The requirements for creating a new data warehouse in the post-GDPR world are significantly different from those of the pre-GDPR world, such as the need to prioritize sensitive data protection and regulatory compliance over performance and cost. In this talk, Jessica Larson shares her takeaways from building a new data platform post-GDPR.\nUnbundling the Data Warehouse: The Case for Independent Storage\nRecording\nSpeaker: Jason Reid (Co-founder & Head of Product at Tabular)\nSummary: Unbundling a data warehouse means splitting it into constituent and modular components that interact via open standard interfaces. In this talk, Jason Reid discusses the pros and cons of both data warehouse bundling and unbundling in terms of performance, governance, and flexibility, and he examines how the trend of data warehouse unbundling will impact the data engineering landscape in the next 5 years.\nClark Wright, Staff Analytics Engineer at Airbnb, talked about the concept of Data Quality Score at Airbnb.\nData Quality Score: How We Evolved the Data Quality Strategy at Airbnb\nRecording\nSpeaker: Clark Wright (Staff Analytics Engineer at Airbnb)\nSummary: Recently, Airbnb published a post to their Tech Blog called Data Quality Score: The next chapter of data quality at Airbnb. In this talk, Clark Wright shares the narrative of how data practitioners at Airbnb recognized the need for higher-quality data and then proposed, conceptualized, and launched Airbnb’s first Data Quality Score.\nData Productivity at Scale\nRecording\nSpeaker: Iaroslav Zeigerman (Co-Founder and Chief Architect at Tobiko Data)\nSummary: The development and evolution of data pipelines are hindered by outdated tooling compared to software development. Creating new development environments is cumbersome: Populating them with data is compute-intensive, and the deployment process is error-prone, leading to higher costs, slower iteration, and unreliable data. SQLMesh, an open-source project born from our collective experience at companies like Airbnb, Apple, Google, and Netflix, is designed to handle the complexities of evolving data pipelines at an internet scale. In this talk, Iaroslav Zeigerman discusses challenges faced by data practitioners today and how core SQLMesh concepts solve them.\nLast but not least, thank you to the organizers of the Data Engineering Open Forum: Chris Colburn, Xinran Waibel, Jai Balani, Rashmi Shamprasad, and Patricia Ho.\nUntil next time!\nIf you are interested in attending a future Data Engineering Open Forum, we highly recommend you join our Google Group to stay tuned to event announcements.\n\nA Recap of the Data Engineering Open Forum at Netflix was originally published in Netflix TechBlog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Netflix Technology Blog",
        "guid": "https://medium.com/p/6b4d4410b88f",
        "categories": [
          "data-engineering",
          "data-science",
          "technology",
          "software-engineering",
          "data"
        ],
        "isoDate": "2024-06-20T15:01:27.000Z"
      },
      {
        "creator": "Netflix Technology Blog",
        "title": "Video annotator: building video classifiers using vision-language models and active learning",
        "link": "https://netflixtechblog.com/video-annotator-building-video-classifiers-using-vision-language-models-and-active-learning-8ebdda0b2db4?source=rss----2615bd06b42e---4",
        "pubDate": "Wed, 19 Jun 2024 15:29:29 GMT",
        "content:encodedSnippet": "Video annotator: a framework for efficiently building video classifiers using vision-language models and active learning\nAmir Ziai, Aneesh Vartakavi, Kelli Griggs, Eugene Lok, Yvonne Jukes, Alex Alonso, Vi Iyengar, Anna Pulido\nhttps://medium.com/media/02a5bbf97c619182adba24b45e42edcb/href\nIntroduction\nProblem\nHigh-quality and consistent annotations are fundamental to the successful development of robust machine learning models. Conventional techniques for training machine learning classifiers are resource intensive. They involve a cycle where domain experts annotate a dataset, which is then transferred to data scientists to train models, review outcomes, and make changes. This labeling process tends to be time-consuming and inefficient, sometimes halting after a few annotation cycles.\nImplications\nConsequently, less effort is invested in annotating high-quality datasets compared to iterating on complex models and algorithmic methods to improve performance and fix edge cases. As a result, ML systems grow rapidly in complexity.\nFurthermore, constraints on time and resources often result in leveraging third-party annotators rather than domain experts. These annotators perform the labeling task without a deep understanding of the model’s intended deployment or usage, often making consistent labeling of borderline or hard examples, especially in more subjective tasks, a challenge.\nThis necessitates multiple review rounds with domain experts, leading to unexpected costs and delays. This lengthy cycle can also result in model drift, as it takes longer to fix edge cases and deploy new models, potentially hurting usefulness and stakeholder trust.\nSolution\nWe suggest that more direct involvement of domain experts, using a human-in-the-loop system, can resolve many of these practical challenges. We introduce a novel framework, Video Annotator (VA), which leverages active learning techniques and zero-shot capabilities of large vision-language models to guide users to focus their efforts on progressively harder examples, enhancing the model’s sample efficiency and keeping costs low.\nVA seamlessly integrates model building into the data annotation process, facilitating user validation of the model before deployment, therefore helping with building trust and fostering a sense of ownership. VA also supports a continuous annotation process, allowing users to rapidly deploy models, monitor their quality in production, and swiftly fix any edge cases by annotating a few more examples and deploying a new model version.\nThis self-service architecture empowers users to make improvements without active involvement of data scientists or third-party annotators, allowing for fast iteration.\nVideo understanding\nWe design VA to assist in granular video understanding which requires the identification of visuals, concepts, and events within video segments. Video understanding is fundamental for numerous applications such as search and discovery, personalization, and the creation of promotional assets. Our framework allows users to efficiently train machine learning models for video understanding by developing an extensible set of binary video classifiers, which power scalable scoring and retrieval of a vast catalog of content.\nVideo classification\nVideo classification is the task of assigning a label to an arbitrary-length video clip, often accompanied by a probability or prediction score, as illustrated in Fig 1.\nFig 1- Functional view of a binary video classifier. A few-second clip from ”Operation Varsity Blues: The College Admissions Scandal” is passed to a binary classifier for detecting the ”establishing shots” label. The classifier outputs a very high score (score is between 0 and 1), indicating that the video clip is very likely an establishing shot. In filmmaking, an establishing shot is a wide shot (i.e. video clip between two consecutive cuts) of a building or a landscape that is intended for establishing the time and location of the scene.\nVideo understanding via an extensible set of video classifiers\nBinary classification allows for independence and flexibility, allowing us to add or improve one model independent of the others. It also has the additional benefit of being easier to understand and build for our users. Combining the predictions of multiple models allows us a deeper understanding of the video content at various levels of granularity, illustrated in Fig 2.\nFig 2- Three video clips and the corresponding binary classifier scores for three video understanding labels. Note that these labels are not mutually exclusive. Video clips are from Operation Varsity Blues: The College Admissions Scandal, 6 Underground, and Leave The World Behind, respectively.\nVideo Annotator (VA)\nIn this section, we describe VA’s three-step process for building video classifiers.\nStep 1 — search\nUsers begin by finding an initial set of examples within a large, diverse corpus to bootstrap the annotation process. We leverage text-to-video search to enable this, powered by video and text encoders from a Vision-Language Model to extract embeddings. For example, an annotator working on the establishing shots model may start the process by searching for “wide shots of buildings”, illustrated in Fig 3.\nFig 3- Step 1 — Text-to-video search to bootstrap the annotation process.\nStep 2 — active learning\nThe next stage involves a classic Active Learning loop. VA then builds a lightweight binary classifier over the video embeddings, which is subsequently used to score all clips in the corpus, and presents some examples within feeds for further annotation and refinement, as illustrated in Fig 4.\nFig 4- Step 2 — Active Learning loop. The annotator clicks on build, which initiates classifier training and scoring of all clips in a video corpus. Scored clips are organized in four feeds.\nThe top-scoring positive and negative feeds display examples with the highest and lowest scores respectively. Our users reported that this provided a valuable indication as to whether the classifier has picked up the correct concepts in the early stages of training and spot cases of bias in the training data that they were able to subsequently fix. We also include a feed of “borderline” examples that the model is not confident about. This feed helps with discovering interesting edge cases and inspires the need for labeling additional concepts. Finally, the random feed consists of randomly selected clips and helps to annotate diverse examples which is important for generalization.\nThe annotator can label additional clips in any of the feeds and build a new classifier and repeat as many times as desired.\nStep 3 — review\nThe last step simply presents the user with all annotated clips. It’s a good opportunity to spot annotation mistakes and to identify ideas and concepts for further annotation via search in step 1. From this step, users often go back to step 1 or step 2 to refine their annotations.\nExperiments\nTo evaluate VA, we asked three video experts to annotate a diverse set of 56 labels across a video corpus of 500k shots. We compared VA to the performance of a few baseline methods, and observed that VA leads to the creation of higher quality video classifiers. Fig 5 compares VA’s performance to baselines as a function of the number of annotated clips.\nFig 5- Model quality (i.e. Average Precision) as a function of the number of annotated clips for the “establishing shots” label. We observe that all methods outperform the baseline, and that all methods benefit from additional annotated data, albeit to varying degrees.\nYou can find more details about VA and our experiments in this paper.\nConclusion\nWe presented Video Annotator (VA), an interactive framework that addresses many challenges associated with conventional techniques for training machine learning classifiers. VA leverages the zero-shot capabilities of large vision-language models and active learning techniques to enhance sample efficiency and reduce costs. It offers a unique approach to annotating, managing, and iterating on video classification datasets, emphasizing the direct involvement of domain experts in a human-in-the-loop system. By enabling these users to rapidly make informed decisions on hard samples during the annotation process, VA increases the system’s overall efficiency. Moreover, it allows for a continuous annotation process, allowing users to swiftly deploy models, monitor their quality in production, and rapidly fix any edge cases.\nThis self-service architecture empowers domain experts to make improvements without the active involvement of data scientists or third-party annotators, and fosters a sense of ownership, thereby building trust in the system.\nWe conducted experiments to study the performance of VA, and found that it yields a median 8.3 point improvement in Average Precision relative to the most competitive baseline across a wide-ranging assortment of video understanding tasks. We release a dataset with 153k labels across 56 video understanding tasks annotated by three professional video editors using VA, and also release code to replicate our experiments.\n\nVideo annotator: building video classifiers using vision-language models and active learning was originally published in Netflix TechBlog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Netflix Technology Blog",
        "guid": "https://medium.com/p/8ebdda0b2db4",
        "categories": [
          "video-editing",
          "artificial-intelligence",
          "machine-learning"
        ],
        "isoDate": "2024-06-19T15:29:29.000Z"
      }
    ]
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Alexander Kurakin",
        "title": "Bug Fixes for ReSharper 2024.1.4 and Rider 2024.1.4 Are Now Available! ",
        "link": "https://blog.jetbrains.com/dotnet/2024/06/24/resharper-rider-2024-1-4/",
        "pubDate": "Mon, 24 Jun 2024 20:15:03 +0000",
        "content:encodedSnippet": "The new bug fixes for the 2024.1 release are available to download. \nReSharper\nReSharper 2024.1.4 fixes a couple of notable issues:\nWe’ve fixed a StackOverflow exception on calling Find Usages or Go to Declaration features on strings from resources (RSRP-496787).  \nWe’ve eliminated a code analysis error that occurred when referencing .NET Framework 4.8.1 in a .NET 8 project (RSRP-496682). \nYou can find the full list of fixed issues here.\nDownload ReSharper\n                                                    \nRider\nIn addition to fixed issues from ReSharper, Rider 2024.1.4 delivers several important fixes of its own: \nNo more deadlocks in solutions with .editorconfig files (RIDER-107157).\nRider doesn’t lose Blueprint usages in Unreal Engine solutions if changes are made to Blueprints (RIDER-112251).\nFor the full list of fixed issues, please refer to this page.\nDownload Rider",
        "dc:creator": "Alexander Kurakin",
        "content": "The new bug fixes for the 2024.1 release are available to download.&#160; ReSharper ReSharper 2024.1.4 fixes a couple of notable issues: You can find the full list of fixed issues here. Rider In addition to fixed issues from ReSharper, Rider 2024.1.4 delivers several important fixes of its own:&#160; For the full list of fixed issues, [&#8230;]",
        "contentSnippet": "The new bug fixes for the 2024.1 release are available to download.  ReSharper ReSharper 2024.1.4 fixes a couple of notable issues: You can find the full list of fixed issues here. Rider In addition to fixed issues from ReSharper, Rider 2024.1.4 delivers several important fixes of its own:  For the full list of fixed issues, […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=486485",
        "categories": [
          "net-tools",
          "releases",
          "rider",
          "resharper"
        ],
        "isoDate": "2024-06-24T20:15:03.000Z"
      },
      {
        "creator": "Ksenia Shneyveys",
        "title": "All KotlinConf Recordings Are Now Available. Enjoy!",
        "link": "https://blog.jetbrains.com/kotlin/2024/06/kotlinconf24-recordings/",
        "pubDate": "Mon, 24 Jun 2024 11:57:07 +0000",
        "content:encodedSnippet": "You can now find all of the session recordings from KotlinConf’24 on the conference website!\nSessions are also being added to the Kotlin YouTube channel:\n\n\n\n\n\n\nPhotos and slides from some of the sessions are also available – click on a talk and select “Download slides” for the latter.\nDon’t miss these additional materials from the conference:\nA roundup of the highlights from the keynote in this blog post.\nKotlinConfersations, interviews with speakers and attendees hosted by Huyen Tue Dao.\nKotlinConf 2024 was held in Copenhagen, Denmark, from May 22–24, drawing over 2,000 attendees, speakers, and partners. The event began with a workshop day and continued with two days of sessions. The powerful keynote featured Jeffrey van Gogh (Google), Michail Zarečenskij, Julie Gunderson (both Amazon Web Services), Eve Matthaey (Meta), and Egor Tolstoy, Ekaterina Petrova, Vsevolod Tolstopyatov, Sebastian Aigner, Svetlana Isakova (all JetBrains) as speakers. The event concluded with a closing panel hosted by Hadi Hariri, featuring different folks from the Kotlin community answering questions.\nCatch all of the action from KotlinConf’24 and keep up with the latest conference updates by following KotlinConf on X.",
        "dc:creator": "Ksenia Shneyveys",
        "content": "You can now find all of the session recordings from KotlinConf’24 on the conference website! Sessions are also being added to the Kotlin YouTube channel: Photos and slides from some of the sessions are also available – click on a talk and select &#8220;Download slides&#8221; for the latter. Don&#8217;t miss these additional materials from the [&#8230;]",
        "contentSnippet": "You can now find all of the session recordings from KotlinConf’24 on the conference website! Sessions are also being added to the Kotlin YouTube channel: Photos and slides from some of the sessions are also available – click on a talk and select “Download slides” for the latter. Don’t miss these additional materials from the […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=486500",
        "categories": [
          "news",
          "kotlinconf"
        ],
        "isoDate": "2024-06-24T11:57:07.000Z"
      },
      {
        "creator": "Maria Kosukhina",
        "title": "IntelliJ IDEA 2024.1.4 Is Out!",
        "link": "https://blog.jetbrains.com/idea/2024/06/intellij-idea-2024-1-4/",
        "pubDate": "Fri, 21 Jun 2024 10:07:04 +0000",
        "content:encodedSnippet": "IntelliJ IDEA 2024.1.4 has arrived with several valuable fixes.\nYou can update to this version from inside the IDE, using the Toolbox App, or using snaps if you are a Ubuntu user. You can also download it from our website.\nHere are the most notable updates included in v2024.1.4:\nCode validation no longer produces incorrect code highlighting caused by freezes while reevaluating inspections. [IJPL-28967]\nWe fixed the issue causing the IDE to lag when editing code. [IJPL-149640, IJPL-156086]\nThe Unknown HTTP header inspection once again loads settings from the inspection profile correctly. [IJPL-65369]\nThe IDE no longer fails to perform operations, citing the Too complex, sorry message. [IJPL-1116]\nUpdating plugins from the Welcome screen now works as expected again. [IJPL-6076]\nThe Enable Project-Wide Analysis action is once again available in the Problems tool window. [IJPL-156560]\n\n\n\n\nTo find out more details about the issues resolved, please refer to the release notes.\nIf you encounter any bugs, please report them to our issue tracker.\nHappy developing!",
        "dc:creator": "Maria Kosukhina",
        "content": "IntelliJ IDEA 2024.1.4 has arrived with several valuable fixes. You can update to this version from inside the IDE, using the&#160;Toolbox App, or using snaps if you are a Ubuntu user. You can also download it from our&#160;website. Here are the most notable updates included in v2024.1.4: To find out more details about the issues [&#8230;]",
        "contentSnippet": "IntelliJ IDEA 2024.1.4 has arrived with several valuable fixes. You can update to this version from inside the IDE, using the Toolbox App, or using snaps if you are a Ubuntu user. You can also download it from our website. Here are the most notable updates included in v2024.1.4: To find out more details about the issues […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=485008",
        "categories": [
          "releases",
          "2024-1",
          "bug-fix-update",
          "intellij-idea",
          "intellij-idea-2024-1"
        ],
        "isoDate": "2024-06-21T10:07:04.000Z"
      },
      {
        "creator": "David Watson",
        "title": "WebStorm 2024.1.5 Is Now Available",
        "link": "https://blog.jetbrains.com/webstorm/2024/06/webstorm-2024-1-5/",
        "pubDate": "Fri, 21 Jun 2024 10:02:03 +0000",
        "content:encodedSnippet": "WebStorm 2024.1.5, the fifth update for WebStorm 2024.1, is now available! It contains several improvements from the platform. \nYou can update to v2024.1.5 by using the Toolbox App, installing it right from the IDE, or downloading it from our website. \nNotable improvements\nHere are some of the notable updates included in v2024.1.5:\nWe’ve fixed the issue causing inspections to show persistent errors that do not refresh during editing (IJPL-28967).\nWe’ve fixed the performance issue causing a delay with caret movement and input (IJPL-149640).\nWe’ve fixed the issue preventing WebStorm from loading profile settings for inspections (IJPL-65369).\nWe’ve fixed a regression issue causing a significant slowdown of the IDE (IJPL-156086).\nWe’ve fixed the severe input and cursor movement lag issues when the show tool window names and background image options are enabled (IJPL-149213).\nWebStorm no longer fails to perform operations, citing the “Too complex, sorry” message (IJPL-1116).\nWe’ve removed the Start Trial confirmation dialog (IJPL-149888).\nWe’ve fixed the issue causing background actions on the main toolbar to get stuck (IJPL-155988).\nUpdating plugins from the Welcome screen works as expected again (IJPL-6076).\nThe Enable Project-Wide Analysis action is again available in the Problems tool window (IJPL-156560).\nThat’s all for today! For the full list of issues addressed in WebStorm 2024.1.5, please see the release notes.\nThe WebStorm team",
        "dc:creator": "David Watson",
        "content": "WebStorm 2024.1.5, the fifth update for WebStorm 2024.1, is now available! It contains several improvements from the platform.&#160; You can update to v2024.1.5 by using the Toolbox App, installing it right from the IDE, or downloading it from our website.&#160; Notable improvements Here are some of the notable updates included in v2024.1.5: That’s all for [&#8230;]",
        "contentSnippet": "WebStorm 2024.1.5, the fifth update for WebStorm 2024.1, is now available! It contains several improvements from the platform.  You can update to v2024.1.5 by using the Toolbox App, installing it right from the IDE, or downloading it from our website.  Notable improvements Here are some of the notable updates included in v2024.1.5: That’s all for […]",
        "guid": "https://blog.jetbrains.com/?post_type=webstorm&p=486104",
        "categories": [
          "releases",
          "webstorm-2024-1"
        ],
        "isoDate": "2024-06-21T10:02:03.000Z"
      },
      {
        "creator": "Maria Kosukhina",
        "title": "IntelliJ IDEA 2024.2 EAP 6: Streamlined Log Management, Enhanced Gradle Build Script Experience, and More",
        "link": "https://blog.jetbrains.com/idea/2024/06/intellij-idea-2024-2-eap-6/",
        "pubDate": "Fri, 21 Jun 2024 06:03:42 +0000",
        "content:encodedSnippet": "IntelliJ IDEA 2024.2 EAP 6 is out! \nYou can get the latest build from our website, through the free Toolbox App, or via snaps for Ubuntu. \nDownload IntelliJ IDEA 2024.2 EAP 6\nThe latest build offers a streamlined user experience with Gradle build scripts, enhanced logging support for Java and Kotlin, and improvements to support Terraform development. To learn about the updates introduced in the previous EAP builds, check out the dedicated 2024.2 EAP section of our blog. \nJava / Kotlin\nEnhanced log management for Java and Kotlin\nContinuing our efforts to improve log handling, IntelliJ IDEA 2024.2 EAP 6 features several notable enhancements for both Java and Kotlin developers, building on the improvements made in the 2024.1 release.\nFirst, we’ve introduced string literal code highlighting, making it easier to distinguish placeholders within string literals. Additionally, the new argument resolution feature allows you to navigate seamlessly from a placeholder in the string literal to its corresponding argument.\n\n\n\n\nThe latest build also includes updated and new inspections for logging statements. We’ve modified the inspection that identifies and warns you about mismatched numbers of parameters in logger calls, taking into account the specifics of the logger being used. For example, the inspection won’t trigger a warning if the extra argument is of the Exception type.\n\n\n\n\nAnother inspection suggests converting System.out.println statements to logger calls, even if the logger is not yet defined.\n\n\n\n\nFurthermore, a new quick-fix is available to add guards for logger calls. The inspection is disabled by default. To enable it in the editor, you can adjust the severity levels in the settings.\n\n\n\n\nBuild tools \nImproved experience with Gradle build scripts\nStarting from IntelliJ IDEA 2024.2 EAP 6, the IDE provides an improved experience with build scripts thanks to the new navigation and highlighting features in Gradle build scripts. First, IntelliJ IDEA now provides smooth and accurate navigation to the Gradle plugins declared in build scripts. \n\n\n\n\nBesides that, we’ve implemented navigation between version catalog files and build scripts in libs.versions.toml file, as well as an option to run registered tasks directly from the gutter.\n\n\n\n\n\nFrameworks and technologies \nEnhanced support for Terraform \nWe’ve significantly extended coding assistance capabilities for Terraform code. \nFirst, full line code completion is now available for Terraform development. Powered by a local large language model (LLM), this functionality predicts entire lines of code, boosting your productivity. \n\n\n\n\nThe in-editor language support for Terraform has been significantly improved in IntelliJ IDEA. This includes essential code insight features such as context-aware code completion, refined syntax highlighting, and an enhanced error detection system with quick-fix suggestions. Additionally, we’ve made the IDE faster by enabling autocompletion and syntax highlighting for Terraform even before indexing is complete, allowing you to start coding more quickly.\nWe’ve also added a feature that shows documentation tooltips when you hover over elements in your Terraform code. This allows you to see relevant information instantly, helping you understand and use Terraform resources more effectively without breaking your workflow.\n\n\n\n\nThese are the most notable updates included in the IntelliJ IDEA 2024.2 EAP 6 build. For the full list of changes, refer to the release notes.\nWe value your feedback during the Early Access Program and eagerly await your comments regarding the new features on X (formerly Twitter) or below. If you find a bug, please report it in our issue tracker.\nHappy developing!",
        "dc:creator": "Maria Kosukhina",
        "content": "IntelliJ IDEA 2024.2 EAP 6 is out!&#160; You can get the latest build from our website, through the free Toolbox App, or via snaps for Ubuntu.&#160; Download IntelliJ IDEA 2024.2 EAP 6 The latest build offers a streamlined user experience with Gradle build scripts, enhanced logging support for Java and Kotlin, and improvements to support [&#8230;]",
        "contentSnippet": "IntelliJ IDEA 2024.2 EAP 6 is out!  You can get the latest build from our website, through the free Toolbox App, or via snaps for Ubuntu.  Download IntelliJ IDEA 2024.2 EAP 6 The latest build offers a streamlined user experience with Gradle build scripts, enhanced logging support for Java and Kotlin, and improvements to support […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=485485",
        "categories": [
          "eap",
          "2024-2-eap",
          "early-access-program",
          "intellij-idea",
          "intellij-idea-2024-2-eap"
        ],
        "isoDate": "2024-06-21T06:03:42.000Z"
      },
      {
        "creator": "Khalid Abuhakmeh",
        "title": "dotCover Command Line Tools for Automation Testing Code Coverage",
        "link": "https://blog.jetbrains.com/dotnet/2024/06/20/dotcover-command-line-tools-for-automation-testing-code-coverage/",
        "pubDate": "Thu, 20 Jun 2024 12:45:54 +0000",
        "content:encodedSnippet": "The ultimate goal of creating a testing strategy is to be confident that you and your team have done their due diligence to deliver a quality product. Test harnesses typically include a mix of unit tests, integration testing, automation, and manual testing, each with advantages and disadvantages for your overall strategy. Determining the effectiveness of your plan requires data collected during test runs, and with code coverage reports, you quantify how each style of testing contributes to your confidence levels.\nWhile code coverage is strongly associated with unit testing libraries such as xUnit, NUnit, or MSTest, the JetBrains tool dotCover can provide code coverage in many scenarios. In this post, we’ll see how to install the dotCover command line tool and gather results from any .NET process, regardless of the execution environment, including local, CI/CD, and production environments.\nDownload and try dotCover\n                                                    \nGetting Started with dotCover Command Line\ndotCover is available as a .NET CLI tool, and you can install it in any environment where you can run a dotnet process. The command line tool supports Windows (x86/x64/ARM64), Linux (x64 / ARM / ARM64 / Musl x64 / Musl ARM64), and macOS (x64 / ARM64). You can install it either as a global or local tool. \nFrom the command line, use the following command to install the tooling.\ndotnet tool install --global JetBrains.dotCover.CommandLineTools\nConfirm the tool is installed globally by running the following command.\ndotnet-dotcover --help\nIssues with global installations typically result from the installation folder for global tools not appearing in the PATH environment variable.\nFor local installation to a .NET Solution, use the following command from the root of the solution folder.\ndotnet new tool-manifest\ndotnet tool install --local JetBrains.dotCover.CommandLineTools\nOnce installed locally, run the following command from the root of your solution to verify a correct installation.\ndotnet dotcover help\nWe’re now ready to start code coverage testing any .NET application. Also, at any point, you can learn more about any command using the following format.\ndotnet dotcover help <command>\nCoverage Analysis for .NET Processes\nI’ve written a straightforward console application with various branching paths for this post. We’ll see if our manual testing can verify that we’ve hit all the branches correctly.\nvar run = true;\nConsole.WriteLine(\"Waiting for input...\");\n\nwhile (run)\n{\n    var key = Console.ReadKey();\n    \n    Console.Clear();\n\n    switch (key.Key)\n    {\n        case ConsoleKey.A:\n            Console.WriteLine(\"A is for 🍎\");\n            break;\n        case ConsoleKey.D:\n            Console.WriteLine(\"D is for 💎\");\n            break;\n        case ConsoleKey.F:\n            Console.WriteLine(\"F is for 👨‍🌾\");\n            break;\n        case ConsoleKey.S:\n            Console.WriteLine(\"S is for 🐍\");\n            break;\n        case ConsoleKey.X:\n            run = false;\n            Console.WriteLine(\"👋 Bye-Bye now\");\n            break;\n        default:\n            Console.WriteLine(\"🤷 I have no clue\");\n            break;\n    }\n}\n\n\n\n\ndotCover allows you to run any dotnet command under coverage analysis, with the most common entry points being exec and test. You can also start code coverage analysis on one or more currently running .NET processes.\nSince this application has no unit tests, we’ll use exec to start our application and then manually attempt to hit each branch. dotCover requires that any process have PDBs available to provide coverage analysis correctly.\nWe’ll use the following command from the command line to start a coverage analysis session on our console application. You’ll want to change the command to point to your project’s dll.\ndotnet dotcover cover-dotnet --ReportType=HTML --TargetArguments=CoverageExample.dll --Output=./\nThis command launches our executable under coverage analysis, waiting for an exit code to stop the session.\n(base) ~/RiderProjects/CoverageExample\ndotnet dotcover cover-dotnet --ReportType=HTML --TargetArguments=CoverageExample.dll --Output=./\n👋 Bye-Bye now\n[JetBrains dotCover] Coverage session finished [5/30/2024 1:25:02PM]\n[JetBrains dotCover] Coverage results post-processing started [5/30/2024 1:25:02PM]\n[JetBrains dotCover] Report generation started [5/30/2024 1:25:02PM]\n[JetBrains dotCover] Report generation finished [5/30/2024 1:25:02PM]\n[JetBrains dotCover] Coverage results post-processing finished [5/30/2024 1:25:02PM]\nOnce completed, we can open our coverage report to see if we’ve hit all the essential parts of our application logic.\n\n\n\n\nVery cool. Let’s talk about some more scenarios.\nNote: You can open dotCover reports directly in ReSharper or dotCover and inspect differences between different runs.\nHelpful Tips and Tricks\nWhile manual testing with coverage analysis is a fun example, you may need more practical testing strategies. The following sections will advise setting up more complex use cases with dotCover.\nDownload OS-specific tooling\nWhile installing the dotCover tooling using the dotnet CLI is convenient for development environments. You can also download an OS-specific version from our download page. The downloaded artifacts can help you build custom Docker images without needing an SDK-based base image or an internet connection to NuGet.\nChange a Container’s Entry Point\nMany folks rely on containerization to provide reliable and repeatable infrastructure for automation testing. As you’ve seen previously, you can use the dotnet-dotcover command to launch your .NET applications. Change your Docker images to use the dotnet-dotcover process as your new EntryPoint and use the --Output flag to write the report to a persistent volume for future retrieval.\nRival Abdrakhmanov describes this process in his blog post, “Diagnostic tools inside Docker container”.\nTerminal Access to Containers\nSometimes, you can log on to running containers and execute the dotnet-dotcover command via orchestration. Terminal access can help you start and stop coverage analysis based on the lifecycle of automated tests such as Selenium or Playwright, which are a breeze to write with JetBrains Aqua.\nMerging Multiple Reports into One\nRegardless of the number of unique processes under coverage analysis, you can always produce a single report. Use the merge command to integrate multiple sources into a single report.\ndotnet dotcover merge --source=Snapshot1.dcvr;Snapshot2.dcvr\nThink about adding an XML Configuration\nYou can manage dotCover settings in XML, making it easier to evolve and fine-tune the coverage analysis process. Create an XML file and pass it as an argument using the --xml flag.\n<ReportParams>\n    <Source><!-- Coverage snapshot file name. --></Source>\n    <Output><!-- Path to the resulting XML report. --></Output>\n    <Output><!-- Path to the resulting JSON report. --></Output>\n    <ReportType>XML</ReportType>\n    <ReportType>JSON</ReportType>\n\n    <!-- Remove auto-implemented properties from report.\n    <HideAutoProperties>True</HideAutoProperties>\n    -->\n\n    <!-- Remove specified files from report. Ant-style patterns are supported here.\n    <ExcludeFileMasks>\n      <Mask>ProjectFolder/**/*.generated.cs</Mask>\n      <Mask>ProjectFolder/**/*.tmp.cs</Mask>\n    </ExcludeFileMasks>\n    -->\n  </ReportParams>    \nDon’t Forget the help command\ndotCover’s built-in help menus offer great advice for every internal command. With the use of the help command, you can quickly figure out what to do, providing the support and confidence you need to use dotCover effectively. \nConclusion\nAs seen in this post, you can add dotCover outside typical unit testing scenarios. Adding automation testing using tools such as Selenium or Playwright doesn’t mean you have to give up on code coverage, especially with the incredible power of dotCover. \nWe hope you found this post helpful. Let us know if you have any questions.\nimage credit: Matthew Henry",
        "dc:creator": "Khalid Abuhakmeh",
        "content": "The ultimate goal of creating a testing strategy is to be confident that you and your team have done their due diligence to deliver a quality product. Test harnesses typically include a mix of unit tests, integration testing, automation, and manual testing, each with advantages and disadvantages for your overall strategy. Determining the effectiveness of [&#8230;]",
        "contentSnippet": "The ultimate goal of creating a testing strategy is to be confident that you and your team have done their due diligence to deliver a quality product. Test harnesses typically include a mix of unit tests, integration testing, automation, and manual testing, each with advantages and disadvantages for your overall strategy. Determining the effectiveness of […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=479413",
        "categories": [
          "net-tools",
          "automated-testing",
          "c",
          "code-coverage",
          "dotcover"
        ],
        "isoDate": "2024-06-20T12:45:54.000Z"
      },
      {
        "creator": "Anastasiia Pogorelova",
        "title": "JetBrains Academy for Teams: How to Pitch It to Your Manager",
        "link": "https://blog.jetbrains.com/education/2024/06/20/pitch-jetbrains-academy-to-your-manager/",
        "pubDate": "Thu, 20 Jun 2024 11:58:20 +0000",
        "content:encodedSnippet": "As a passionate coder using JetBrains Academy, you already know the incredible benefits of our project-based learning platform. Now imagine amplifying those benefits across your entire team. \nHere is why and how you should pitch JetBrains Academy for Teams to your employer.\n\n\n\n    \nFREE TRIAL FOR TEAMS\n                                                    \nWhy professional development is essential\nIn the ever-evolving world of tech, keeping up is essential, but staying ahead is even\nbetter. Here’s why investing in learning can be a game-changer for you and your team: \nClose skill gaps: 45% of engineering companies struggle with skill gaps. Upskilling can bridge these gaps, ensuring your team is prepared for new projects and initiatives.\nEnhance engagement and retention: 94% of employees say they would stay longer at a company that invests in their careers. Investing in training can boost morale and reduce turnover.\nFacilitate smooth transitions: Whether onboarding new hires or preparing for tech stack migrations, continuous learning ensures smoother transitions and internal transfers.\nExplore your company’s professional development opportunities\nBefore you make your pitch, it’s a good idea to сheck out what professional development and learning opportunities your company already offers. This can help you frame your request in a way that aligns with existing initiatives. Maybe your company already has a budget for training or a process for approving new tools and resources.\nFind out who is the right person to talk to about the approval process. Is it your direct manager, the HR department, or someone else? Once you’ve done this, you’ll be ready to make a more informed and strategic pitch.\nStructure your pitch\n1. Highlight what you’re learning and its impact\nStart by sharing your personal experience with JetBrains Academy. Explain what you’ve been learning and how it has benefited your current work or future professional goals. \nFor example:\nMaxim, while working in Product Management, decided to learn Python through JetBrains Academy. He completed the Python with Algorithms for Tech Interviews and Python Backend Developer with Flask tracks. \nThe hands-on projects and personalized study plans made it easy to grasp new concepts and apply them. After a few months, he felt confident enough to apply for the Junior Python Developer role at his company and transferred to the development team.\n2. Explain why JetBrains Academy is the right choice\nSo, why JetBrains Academy? For starters, JetBrains Academy taps into JetBrains’ more than 20 years of experience in creating developer tools. JetBrains is trusted by 90 of the Fortune Global Top 100 companies. Chances are good that your company is already using some of our tools for development, which ensures seamless integration and a familiar environment.\nJetBrains Academy offers project-based learning tracks, which are hosted on the Hyperskill platform and backed by JetBrains tools. This means your team will be able to put new knowledge into practice by creating real-world applications while working with professional tools they’ll use daily.\nNow, let’s get to the part where you’re pitching the idea to the whole team. You could say:\n“Imagine if our whole team had access to this! We could all benefit from the seamless integration with the IDEs we already use. Learning how to use the tools is as important as learning how to code. Plus, each of us would get a personalized study plan, so we could learn at our own pace and level.”\nEmphasize the key features that would be beneficial for your whole team:\n\nIntegration with JetBrains IDEsYour team develops their skills in the same IDE editors they use daily. \nPersonalized learning pathsEach team member receives a tailored study plan, progressing at a pace that reinforces knowledge effectively.\nOrganizational dashboardTrack team progress and comply with privacy policies, ensuring a secure and efficient learning environment.\nSSO and free course creation                         Simplify access with single sign-on and create custom courses to align with your company’s specific needs.\nCertificates of completionMotivate and recognize your team’s achievements with personalized certificates.\n\n\n\n\n\n3. Real-life benefits for the team\nThink about how different parts of your organization could benefit. Here are a few use cases your team lead might consider:\nUpskilling tech support, QA departments, or junior developers.\nGetting ready for new projects that require skills the team currently lacks.\nAssisting non-IT employees in gaining a basic understanding of technical skills, useful for collaboration with tech departments.\n\n\n\n\n\nEncouraging your manager to invest in a team-wide subscription to JetBrains Academy can elevate your entire team’s performance and morale. \nStart with the free 10-day trial with full access to JetBrains Academy for Organizations. \nUnlimited yearly access is $399 per user, including a free owner account to manage your team.\n\n\n\n\n\n\nUse these tips to structure your pitch and highlight the awesome benefits of continuous learning with JetBrains Academy. Good luck!\nIf you have any questions or would like to share your feedback, feel free to leave a comment below or contact us at academy@jetbrains.com.\nHappy learning!\nYour JetBrains Academy team",
        "dc:creator": "Anastasiia Pogorelova",
        "content": "As a passionate coder using JetBrains Academy, you already know the incredible benefits of our project-based learning platform. Now imagine amplifying those benefits across your entire team.&#160; Here is why and how you should pitch JetBrains Academy for Teams to your employer. Why professional development is essential In the ever-evolving world of tech, keeping up [&#8230;]",
        "contentSnippet": "As a passionate coder using JetBrains Academy, you already know the incredible benefits of our project-based learning platform. Now imagine amplifying those benefits across your entire team.  Here is why and how you should pitch JetBrains Academy for Teams to your employer. Why professional development is essential In the ever-evolving world of tech, keeping up […]",
        "guid": "https://blog.jetbrains.com/?post_type=education&p=485982",
        "categories": [
          "jetbrains-academy",
          "project-based-learning",
          "teams",
          "hyperskill",
          "jetbrains-academy-for-organizations"
        ],
        "isoDate": "2024-06-20T11:58:20.000Z"
      },
      {
        "creator": "Vitaly Bragilevsky",
        "title": "Custom Fleet Plugins for Your Kotlin Codebase",
        "link": "https://blog.jetbrains.com/fleet/2024/06/custom-fleet-plugins-for-your-kotlin-codebase/",
        "pubDate": "Thu, 20 Jun 2024 09:57:33 +0000",
        "content:encodedSnippet": "Fleet is a code editor designed from scratch to be an extendable platform. Many pieces of Fleet’s functionality are implemented as plugins. While the Fleet team is working toward the Fleet Plugins Public Preview, we decided to share some ideas, details, and examples of why and how external developers are supposed to develop their own plugins for Fleet. This blog post is based on the material from the lightning talk at KotlinConf 2024.\nFleet and Kotlin: Available functionality and ideas for customization\nFleet can be used to work with codebases in Kotlin right from the outset. In Smart Mode, you can employ the power of the IntelliJ backend. On top of Fleet, you can rely on the built-in Kotlin Multiplatform tooling or build your projects with Amper. Although all this functionality is already available out of the box, some customizations might also be needed. \nFor example, your project might employ custom resources. A custom view for those resources might be a helpful feature. If your project relies on external tools, it might be tempting to integrate them into Fleet. If you care about codebase quality, you might enjoy having quick access to source code metrics such as the total size of your codebase, cyclomatic complexity, metrics regarding code abstraction complexity, or relevance of code comments to the code itself. Anything like that might be implemented as a custom plugin for Fleet if unavailable elsewhere.\nIn this blog post, we’ll use a running example of a plugin that counts all the top-level functions declared in a source file and reports them via a custom notification:\n\n\n\n\nNote that changes in the source file are propagated to the notification description immediately. Despite being relatively simple (its implementation takes only a hundred lines of code), this plugin helps us see several crucial ideas behind the Fleet platform. \nFleet architecture for plugin developers\nTo support remote development and collaboration, Fleet has a distributed architecture, clearly separating such components as:\nFrontends – the user-facing parts of any Fleet application.\nWorkspace – the part responsible for registering participating components and maintaining a shared state between all of them.\nBackends – headless services responsible for implementing Smart Mode features (such as static analysis, advanced search, code navigation, and more). \nThe same structure is reflected in Fleet plugins:\n\n\n\n\nFleet plugins typically implement frontend and workspace parts, communicating with backend components. The backend’s implementation depends on the chosen service. For example, when working with Kotlin, the backend part of a Fleet plugin should be an IntelliJ Platform plugin.\nFleet itself is implemented in Kotlin, and plugin developers should write their plugin code in Kotlin. Coding for Fleet therefore requires a good working knowledge of Kotlin and its more advanced concepts, such as DSL (domain-specific language) development or structured concurrency with coroutines. \nTo write efficient code for Fleet, developers have to keep the following two key principles in mind:\n1: Fleet is a transactional distributed database with reactive queries (see the other blog post for more internal details).\n2: Fleet embraces coroutines and structured concurrency.\nEvery change in the UI is technically a transaction over the Fleet state database. Every coroutine launched by a plugin is controlled by Fleet and canceled automatically if the plugin is unloaded. Plugins themselves are also a part of Fleet’s state and are managed according to the same rules as everything else in Fleet. Both loading and unloading a plugin are transactions. Let’s see how these principles affect plugins’ source code.\nImplementing a custom plugin: Counting functions in a Kotlin file\nThe Count Functions plugin defines only the frontend part: It contributes an action that displays a notification with the number of top-level functions in a Kotlin source file. The full source code of the plugin is available on GitHub.\nAll the plugin’s code comes from a single Kotlin file and has the following structure:\n\n\n\n\nWe provide the main plugin’s class FunCounter, which is loaded via the JVM’s ServiceLoader, as well as several functions that perform our desired task.\nGradle configuration\nFleet plugins are developed using Gradle. The main Gradle configuration file specifies the plugin’s most important details:\nversion = \"0.1.0\"\n\nfleetPlugin {\n    id = \"pro.bravit.fleetPlugin.funCounter\"\n    metadata {\n        readableName = \"Count Functions\"\n        description = \"This plugin contributes an action...\"\n    }\n   fleetRuntime {\n       version = \"1.35.115\"\n   }\n   pluginDependencies {\n       plugin(\"fleet.kotlin\")\n   }\n}\nWhile we’re targeting a specific Fleet runtime, it’s also possible to set a range of supported versions. Additionally, we’re declaring dependencies on other Fleet plugins. The fleet.kotlin plugin gives us access to packages providing classes and methods to work with an abstract syntax tree (AST) of a Kotlin source file.\nA plugin class\nThe FunCounter class is an entry point to a frontend part of the plugin. It declares several components required for Fleet plugin bookkeeping and also loads all the contributed functionality.\ntypealias FunCounterAPI = Unit\nclass FunCounter : Plugin<FunCounterAPI> {\n\n   companion object : Plugin.Key<FunCounterAPI>\n   override val key: Plugin.Key<FunCounterAPI> = FunCounter\n\n   override fun ContributionScope.load(pluginScope: PluginScope) {\n       notificationCategory(countFunctionsNotification)\n       actions {\n           setupCountFunctionsAction(pluginScope)\n       }\n   }\n}\nIn this example, we’re contributing a notification category and an action. Our plugin doesn’t provide any APIs, so we’ll use Unit as a generic parameter for the Plugin interface. This class is mentioned in the module-info.java as the one providing a plugin implementation:\nmodule pro.bravit.fleetPlugin.funCounter {\n   // module requirements\n   // exports\n   provides fleet.kernel.plugins.Plugin with pro.bravit.fleetPlugin.funCounter.FunCounter;\n}\nNote the pluginScope argument of the load method: It’s a coroutine scope used by Fleet to control all the coroutines launched by a plugin. If a plugin is unloaded, then all of its coroutines are canceled.\nIn the rest of this article, we’ll look at the implementation of the contributed functionality. \nManaging notifications\nManaging notifications in Fleet usually involves the following two components:\nWe define a notification category so that Fleet can manage all the notifications coming from a plugin.\nWe make Fleet show a notification whenever needed.\nApart from that, we’ll also make it update a notification whenever new information becomes available. Although notifications are not the best place to display information that changes with time, these ones are simple enough to serve as an example here.\nThe notification category is a simple data class value:\nval countFunctionsNotification = NotificationCategory(\n   id = NotificationCategoryId(\"CountFunctions\"),\n   readableName = \"Count Functions\"\n)\nCreating a notification is a bit more complicated: \nprivate suspend fun createCountFunctionsNotification(editor: EditorEntity): NotificationEntity {\n   val fileName = editor.layout?.ownerTab()?.displayName() ?: \"Unknown file\"\n   val title = \"Function counter ($fileName)\"\n   val description = \"Number of top-level functions: ?\"\n   return change {\n       val notification = showNotification(\n           countFunctionsNotification,\n           title, NotificationIcon.Info, description,\n           isSticky = true\n       )\n       cascadeDelete(editor, notification)\n       notification\n   }\n}\nThe code above demonstrates several important features of Fleet’s plugin machinery:\nThe Entity suffix found in EditorEntity and NotificationEntity reminds us that we’re working with database entities. These entities are represented by Kotlin values and are managed by Fleet. They can be created, looked up, and updated as needed. Entities from Fleet itself provide us with information about what’s going on in the Fleet instance (for example, we get the name of the loaded file via editor.layout?.ownerTab()?.displayName())\nChanges in the database are executed in transactions. We introduce transactions with change-blocks.\nNote the cascadeDelete call: With it, we can establish relations between entities in the database. In this case, we ask Fleet to delete a freshly created notification when the corresponding editor is deleted.\nThe showNotification function comes from the Fleet Notification API. It creates and displays a notification and then returns a created notification entity so that we can manage it later.\nIn many cases, Fleet plugin code follows the same pattern, manipulating database entities. Entities are created and updated (in transactions), or we just use the information we’ve extracted from them.  \nTo update the notification, we need to execute another transaction:\nprivate suspend fun updateCountFunctionsNotification(\n\t\t\t\t\tnotification: NotificationEntity, \n\t\t\t\t\tnumberOfFunctions: Int) {\n   val description = \"Number of top-level functions: $numberOfFunctions\"\n   change {\n       notification.description = description\n   }\n}\nNote that both functions above are suspend functions. We have to run them from Kotlin coroutines. We’ll get back to this shortly.\nDeclaring actions\nThe main functionality this plugin provides is the Count Functions action. Fleet actions have the following life cycle:\nThey are registered in the ContributionScope.load plugin’s method.\nFleet shows available actions in the Actions list. Depending on the way an action is defined, it can be missing from that list (if the action’s static prerequisites are not met) or it can be grayed out (if the action’s dynamic prerequisites are not met).\nFleet executes an action whenever the corresponding action is triggered by a user. In most cases, actions are executed by launching a Kotlin coroutine that then provides the required functionality. \nThe Fleet Action API provides a way to declare actions. It starts with the actions block containing action definitions. Now, let’s look at setting up the Count Functions action:\nprivate fun ActionRegistrar.setupCountFunctionsAction(pluginScope: PluginScope) {\n   action(id = \"Count-Functions\", name = \"Count Functions\") {\n       val requiredEditor = required(FleetDataKeys.LastEditorEntity)\n       dynamic {\n           val editor = requiredEditor.value\n           if (editor.document.mediaType == MediaType(\"text\", \"kotlin\")) {\n               callback {\n                   pluginScope.launch {\n                       performCountFunctionsAction(editor)\n                   }\n               }\n           }\n       }\n   }\n}\nThe static requirement for this action is the availability of an editor: If there’s no focused editor, the Count Functions action makes no sense. We specify this requirement by requesting FleetDataKeys.LastEditorEntity in the first line of the action block. Then, we use the dynamic block to specify the dynamic requirement. The document loaded in the editor must contain Kotlin source code. If this requirement is met, we provide a callback block to define code that is executed whenever the action is triggered. As explained above, the execution of the action starts with launching a coroutine in the plugin’s coroutine scope. \nThe Fleet Action API and many other Fleet APIs apply Kotlin DSL builders to describe functionality contributed to Fleet. In this example, we’ve used several Action DSL components, including action, dynamic, and callback, to introduce an action definition, specify its dynamic requirements, and provide an implementation, respectively. \nPerforming actions with reactive queries\nThe central piece of the Count Functions plugin implementation is propagating changes in the source code’s AST to the notification’s description:\n\n\n\n\nThe corresponding code comes in the performCountFunctionsAction function:\nprivate suspend fun performCountFunctionsAction(editor: EditorEntity) {\n   withEntities(editor) {\n       val notification = createCountFunctionsNotification(editor)\n       withEntities(notification) {\n           query {\n               editor.document.syntaxes\n                  ?.firstNotNullOfOrNull(ASTContainer::getDataAsync)\n           }.collectLatest { ast ->\n               val numberOfFunctions = countFunctions(ast?.await())\n               updateCountFunctionsNotification(notification, numberOfFunctions)\n           }\n       }\n   }\n}\nNote the following important parts of this function:\nWe use the withEntities function to introduce suspend blocks that depend on the existence of the referenced entities. If the corresponding entity does not exist anymore, the coroutine is canceled. This approach greatly simplifies implementation, as we have a guarantee that these entities exist in these blocks so that we can safely work with them.\nThe query {} block specifies a subscription request to the Fleet database regarding all the changes occurring to the mentioned entities. These requests are the cornerstone of the Fleet Query API: We can subscribe to changes in the database in order to react to them in a timely manner.\nQueries give us something that closely resembles Kotlin’s asynchronous flows. We collect the flow’s elements and process them as needed. In this case, the flow’s element comes as a Kotlin’s Deferred AST value. We’ll then wait for this value to get an up-to-date AST to count all the top-level functions in it.\nWe don’t need to think about the action’s completion. It will be active until it’s canceled as a result of deleting the entities referenced in withEntities or unloading the plugin itself. \nWorking with a Kotlin source code\nThe final piece of functionality is the countFunctions function. It represents a small exercise in navigating through Kotlin’s source code AST:\nprivate fun countFunctions(tree: AST<*>?): Int =\n   tree?.root()\n       ?.children()\n       ?.count {\n           it.type.toString() == \"FUN\"\n       } ?: 0\nTo use the corresponding types and methods, we had to introduce a dependency to the fleet.kotlin plugin earlier. To simplify the implementation, we return 0 for every unexpected value in AST, without thinking too much about error handling. \nConclusion\nFleet plugin APIs and the corresponding tooling are a work in progress. This blog post offers a sneak peek at how plugin developers are supposed to develop their own plugins for Fleet. The whole plugin development experience is based on two principles: (1) Fleet is a distributed database, and (2) Fleet embraces structured concurrency with coroutines. To make it easier to contribute custom functionality, Fleet provides a set of APIs for database entity and transaction management, actions, notifications, and many other things. Stay tuned for the Fleet Plugins Public Preview to develop your own plugins for Fleet!",
        "dc:creator": "Vitaly Bragilevsky",
        "content": "Fleet is a code editor designed from scratch to be an extendable platform. Many pieces of Fleet’s functionality are implemented as plugins. While the Fleet team is working toward the Fleet Plugins Public Preview, we decided to share some ideas, details, and examples of why and how external developers are supposed to develop their own [&#8230;]",
        "contentSnippet": "Fleet is a code editor designed from scratch to be an extendable platform. Many pieces of Fleet’s functionality are implemented as plugins. While the Fleet team is working toward the Fleet Plugins Public Preview, we decided to share some ideas, details, and examples of why and how external developers are supposed to develop their own […]",
        "guid": "https://blog.jetbrains.com/?post_type=fleet&p=481751",
        "categories": [
          "fleet",
          "kotlin",
          "plugin"
        ],
        "isoDate": "2024-06-20T09:57:33.000Z"
      },
      {
        "creator": "Andrey Gushchin",
        "title": "CLion 2024.1.4 Is Out! Nova Now Available by Default for New Users",
        "link": "https://blog.jetbrains.com/clion/2024/06/2024-1-4-update-is-out/",
        "pubDate": "Wed, 19 Jun 2024 16:26:48 +0000",
        "content:encodedSnippet": "Since November 2023, our team has been diligently working on the implementation of the ReSharper C++/Rider C++ language engine. This project was initiated with a clear focus on our users, aiming to address the long-standing performance and quality issues of CLion, which were caused by the usage of the slowly performing engine.\nThe most notable benefits for our users are as follows:\nFaster highlighting speeds, especially in the case of incremental code updates\nA more responsive UI\nFaster Find Usages\nSignificantly fewer freezes and hangs when refactoring\nFaster test indexing\nToday, we’re thrilled to announce that a new, more powerful language engine (also known as Nova) is now available by default for all new users right after the installation!\nIf, after installation, CLion detects no settings from its previous installation, or if a user chooses not to import them, the new language engine will be enabled.\nDownload build 241.18034.45 from our website, through the Toolbox App, as a snap package for Ubuntu, or via a patch from inside the IDE and experience exceptional performance and efficiency.\nDOWNLOAD CLION\nAs promised in the roadmap for the 2024.2 release, we’re still working hard to close the feature gap between the classic language engine and the new one. Once this work is complete, we’ll make the new engine the default option for existing users.\nWe also encourage you to try the ReSharper C++ language engine, which can be enabled via Advanced Settings. To do so, go to Settings / Preferences | Advanced Settings | CLion | Use the ReSharper C++ language engine (CLion Nova).\n\n\n\n\nYour feedback matters to us! Share your ideas in the comments section below or submit them to our issue tracker. We’re also interested in scheduling short calls with our users to learn about specific cases in more detail. Let us know if you’re willing to share your feedback about the new engine by commenting below!\nDOWNLOAD CLION\nYour CLion team\nJetBrains\nThe Drive to Develop",
        "dc:creator": "Andrey Gushchin",
        "content": "Since November 2023, our team has been diligently working on the implementation of the ReSharper C++/Rider C++ language engine. This project was initiated with a clear focus on our users, aiming to address the long-standing performance and quality issues of CLion, which were caused by the usage of the slowly performing engine. The most notable [&#8230;]",
        "contentSnippet": "Since November 2023, our team has been diligently working on the implementation of the ReSharper C++/Rider C++ language engine. This project was initiated with a clear focus on our users, aiming to address the long-standing performance and quality issues of CLion, which were caused by the usage of the slowly performing engine. The most notable […]",
        "guid": "https://blog.jetbrains.com/?post_type=clion&p=485777",
        "categories": [
          "news",
          "releases",
          "clionnova"
        ],
        "isoDate": "2024-06-19T16:26:48.000Z"
      },
      {
        "creator": "Vladislav Minaev",
        "title": "WebStorm 2024.2 EAP Digest #2: New TypeScript Engine, Ability to Run .ts Files, Git and Markdown Improvements",
        "link": "https://blog.jetbrains.com/webstorm/2024/06/webstorm-2024-2-eap2/",
        "pubDate": "Wed, 19 Jun 2024 14:37:43 +0000",
        "content:encodedSnippet": "We’re halfway through the Early Access Program for WebStorm 2024.2! It’s been a while since we walked you through the latest improvements and features in this release, so it’s about time for an update. Read on to learn about the key changes that made it into the EAP builds in the past few weeks. For more information, check out our previous blog posts.\nThe Toolbox App is the easiest way to get the EAP builds and keep both your stable and EAP versions up to date. You can also manually download the EAP builds from our website.\n\nDOWNLOAD WEBSTORM 2024.2 EAP\n\n\n\n\nImportant! WebStorm EAP builds are not fully tested and might be unstable.\nPlease try the latest EAP build and share your feedback with us. You can do so using our issue tracker or by leaving a comment on this blog post.\nKey highlights\nDirectly run and debug TypeScript files without any configuration\nSince EAP3, WebStorm IDE provides the ability to run TypeScript files directly within the IDE without any additional setup. This feature allows users to run and debug TypeScript files directly within the IDE without any additional setup, utilizing the integrated tsx bundler. You can now execute TypeScript files from different entry points, including the file context menu, the Run widget, and the “Current file” configuration for scratch files. The bundled loader eliminates the need for extra dependencies, though it does come with some limitations, such as requiring Node 18 or higher, no type-checking, and limited support for tsconfig.json. You can disable the bundled loader in the configuration settings if it’s not needed.\n\n\n\n\nNew TypeScript engine now enabled by default\nThe WebStorm@next program has introduced a new TypeScript engine, to enhance type evaluation and overall performance. This engine uses the TypeScript language server, improving type inference and compatibility. Here is a case in point.\nThe new engine promises a smoother development experience and ongoing improvements for better support across various frameworks. The new engine has been enabled by default since EAP4. You can toggle it using Settings | Languages & Frameworks | TypeScript > Use types from server option:\n\n\n\n\nImproved commit graph in the Log tab\nTo improve the visual perception of the commit graph in the Log tab of the Git tool window, we’ve refined the color encoding and layout of branch lines. Important branch lines now consistently remain on the left-hand side of the graph and retain their designated colors, making them easier to identify and follow. \nPreviously, commits from important branches were sometimes not correctly laid out or colored because their heads were contained within less important branches. This update ensures that important branches are always clearly visible and consistently colored.\n\n\n\n\nSupport for math syntax in Markdown files \nWebStorm can now natively render mathematical expressions in Markdown files. In WebStorm 2024.2, you can use $ to insert inline math expressions and $$ for code blocks containing math content.\n\n\n\n\nImproved Customize Main Toolbar dialog\nWe’ve redesigned the layout and behavior of the UI elements in the Customize Main Toolbar dialog, making it more intuitive and organized. Now, it’s easier to search for, add, and delete actions in the main toolbar.\n\n\n\n\nOther highlights\nWe’ve resolved the following longstanding issues:\nWEB-64879 WebStorm won’t update JavaScript import paths after moving a directory.\nWEB-59986 Typescript/tsx: Code completion does not honor overrides via module augmentation.\nThat’s it for today. For the full list of improvements available in the latest EAP builds, check out the release notes. Stay tuned for our next EAP digest!",
        "dc:creator": "Vladislav Minaev",
        "content": "We’re halfway through the Early Access Program for WebStorm 2024.2! It’s been a while since we walked you through the latest improvements and features in this release, so it’s about time for an update. Read on to learn about the key changes that made it into the EAP builds in the past few weeks. For [&#8230;]",
        "contentSnippet": "We’re halfway through the Early Access Program for WebStorm 2024.2! It’s been a while since we walked you through the latest improvements and features in this release, so it’s about time for an update. Read on to learn about the key changes that made it into the EAP builds in the past few weeks. For […]",
        "guid": "https://blog.jetbrains.com/?post_type=webstorm&p=485749",
        "categories": [
          "eap",
          "webstorm-2024-2"
        ],
        "isoDate": "2024-06-19T14:37:43.000Z"
      },
      {
        "creator": "Svetlana Novikova",
        "title": "Let’s Bring Science Into API Documentation",
        "link": "https://blog.jetbrains.com/writerside/2024/06/let-s-bring-science-into-api-documentation/",
        "pubDate": "Wed, 19 Jun 2024 13:23:25 +0000",
        "content:encodedSnippet": "In today’s fast-paced development environment, effective API documentation is not just nice to have; it’s a necessity. This blog post explores how understanding pattern recognition and learning styles can revolutionize the way we create API documentation. By examining the different types of knowledge present in API references and catering to diverse developer learning strategies, we can create documentation that is not only informative but also engaging and intuitive. \nThis blog post stems from Lana Novikova’s presentation at the apidays Paris conference – a central hub and one of the biggest events for all things API. Lana is a product manager for JetBrains Writerside and has over 10 years of experience in technical writing, including API documentation.\n\n\n\n\nPattern recognition\nNeuroscience reveals a fascinating truth: Our brains are expert pattern detectors. We excel at identifying, interpreting, and connecting information, even when encountering it for the first time. This inherent skill, known as pattern recognition, holds significant implications for API documentation, which has a strict structure reflecting the API’s architecture.\nIn their study Patterns of Knowledge in API Reference Documentation, researchers Walid Maalej and Martin P. Robillard conducted an interesting experiment where they scrutinized API reference documentation for JDK 6 and .NET 4.0. Within these documents, they discovered 12 different “knowledge types” (a specific category of information that users may seek when interacting with an API), including functionality and behavior, directives, and purpose and rationale.\nThey also identified a “non-informational” knowledge type, i.e., uninformative, repetitive text that serves no actual purpose. \nThe study highlighted significant variations in the distribution of these knowledge types across the two documentation sets, suggesting that different APIs might prioritize different types of information. For instance, JDK documentation leans toward conceptual knowledge, while its .NET counterpart emphasizes API structure and usage patterns.\n\n\n\n\nAs technical writers, we can harness these findings to create more efficient documentation. Here’s how:\nEvaluate your API documentation through the lens of these knowledge types. Are certain types overrepresented or missing? \nDevelop and use documentation templates tailored to the knowledge type typically associated with specific API elements.\nMany products, including Writerside, offer ready-made templates for document creation. Here, I want to express my appreciation for The Good Docs project, which maintains an excellent template library for various knowledge types. If you’re interested in using or contributing to these templates, you’re most welcome to do so! We are also discussing a partnership with The Good Docs project, and we will soon announce something exciting together. Stay tuned! \nWriterside includes an out-of-the-box API project template that proposes a boilerplate API project structure and includes an API overview, a quick start guide, a reference section, and a changelog page. You can jump-start your API docs project using this template and then tailor it to your specific use case.\n\n\n\n\nLearning styles\nJust like a good teacher adapts their methods to different students, effective API documentation should cater to diverse learning styles. Recognizing these individual preferences is crucial for making the learning process smoother and more enjoyable.\nMichael Meng, Stephanie Steinhardt, and Andreas Schubert’s research reinforces this point. Their study observed how developers interact with unfamiliar APIs, revealing distinct approaches based on individual learning styles. Understanding these approaches can help us tailor documentation to better meet developers’ needs.\nThe research shows that developers spend nearly as much time reading documentation (49%) as they do coding (51%).\nFurthermore, developers tend to rely on API references, recipes, and samples as their go-to resources when using API documentation. This preference indicates that practical usage guides are more valuable to developers than abstract concepts. The study also revealed considerable variation among participants regarding the time allocated to individual content categories, which further emphasizes the diversity in learning styles and information-seeking behaviors.\n\n\n\n\nFrom their findings, Meng, Steinhardt, and Schubert identified three developer personas, each with distinct information-seeking strategies for learning new APIs:\nSystematic learners seek to understand the API and the entities it operates before using it.\nOpportunistic learners aim for the quickest start without prior understanding or documentation review.\nPragmatic learners combine elements of both systematic and opportunistic approaches.\nIt’s important to note that a learning style is not a label or a tool for categorization, but rather an individual’s preferred approach to learning, which we should respect and take into account. Behavioral diversity keeps the ecosystem dynamic, and recognizing it in API documentation could be the key to resonating with a broader audience.\nApplying scientific principles to enhance API documentation\nAs technical writers, we are like surfers trying to catch developers’ waves. We can’t control the waves, but we can understand their rhythms and adapt our strategy to ride them successfully. That’s where scientific principles come into play. Just like the knowledge of wave patterns enhances a surfer’s performance, understanding the principles of pattern recognition and learning styles can transform our approach to API documentation.\nWe can achieve this by:\nProviding comprehensive code examples, catering to opportunistic learners who prefer hands-on exploration.\nOffering layered and in-depth background knowledge, supporting systematic learners who seek a deeper understanding of the underlying concepts.\nFurthermore, features that suit all learning styles and facilitate an understanding of the API are beneficial for everyone. \nIn conclusion, effective API documentation isn’t just about providing accurate information, it’s about making exploration enjoyable and the learning process intuitive. With great API documentation, developers won’t just learn how to use our APIs, they’ll also enjoy the learning experience.\nWriterside lets you mix manual API descriptions with auto-generated references to cater to the needs of any developer persona. You can choose to generate the entire API reference or select specific tags or operations. You can also generate separate pages for API objects or include them on the same pages as the operations to provide all the information in one place.\n\n\n\n\nWhile there may not be specific literature on applying these principles directly to API documentation, many resources tackle elements of learning theory, instructional design, and behavioral theory that can be adapted for technical writing. We’ve highlighted some of them in the resource section below. \nFeel free to don your lab coat and conduct some research yourself! Although it may not always be feasible to replicate the extensive studies mentioned earlier, there are simpler methods that can still provide valuable insights.\nConsider techniques like:\nContent analysis with color coding: Highlight different knowledge types within your documentation to assess their distribution and identify potential gaps or imbalances. We at Writerside are considering delegating this task to AI. If that sounds interesting to you, please upvote this ticket.\nObservational studies: Ask a fellow developer to approach your API documentation as a new user, starting from the API portal. Observe their navigation patterns, information-seeking behavior, and any points of friction they encounter.\nHeatmap analysis: If your analytics system provides heatmaps, analyze user interactions on your API documentation pages to understand which sections receive the most attention, what the happy path is, and which areas might be overlooked.\nThese insights can provide a roadmap for improving your API documentation, leading to a smoother and more enjoyable developer experience.\nRemember, there are no rigid guidelines or definitive solutions in technical writing. However, if there were one golden rule, it’d be this: Write with your users in mind, especially now that you know how their minds work. So, keep experimenting and learning, and most importantly, enjoy the writing process!\nGive your API docs their rightful place with Writerside! Learn more.\nResources for further exploration:\nPatterns of Knowledge in API Reference Documentation by Walid Maalej and Martin P. Robillard: https://www.cs.mcgill.ca/~martin/papers/tse2013a.pdf. \nHow Developers Use API Documentation: An Observation Study by Michael Meng, Stephanie Steinhardt, and Andreas Schubert: https://sigdoc.acm.org/wp-content/uploads/2019/01/CDQ18002_Meng_Steinhardt_Schubert.pdf. \nLearning Science for Instructional Designers: From Cognition to Application by Clark N. Quinn.\nDesign for How People Learn by Julie Dirksen.\nMake It Stick: The Science of Successful Learning by Peter C. Brown, Henry L. Roediger III, and Mark A. McDaniel.",
        "dc:creator": "Svetlana Novikova",
        "content": "In today&#8217;s fast-paced development environment, effective API documentation is not just nice to have; it’s a necessity. This blog post explores how understanding pattern recognition and learning styles can revolutionize the way we create API documentation. By examining the different types of knowledge present in API references and catering to diverse developer learning strategies, we [&#8230;]",
        "contentSnippet": "In today’s fast-paced development environment, effective API documentation is not just nice to have; it’s a necessity. This blog post explores how understanding pattern recognition and learning styles can revolutionize the way we create API documentation. By examining the different types of knowledge present in API references and catering to diverse developer learning strategies, we […]",
        "guid": "https://blog.jetbrains.com/?post_type=writerside&p=485617",
        "categories": [
          "api",
          "documentation",
          "openapi"
        ],
        "isoDate": "2024-06-19T13:23:25.000Z"
      },
      {
        "creator": "Evgenia Verbina",
        "title": "How to Move From pandas to Polars",
        "link": "https://blog.jetbrains.com/pycharm/2024/06/how-to-move-from-pandas-to-polars/",
        "pubDate": "Wed, 19 Jun 2024 11:48:42 +0000",
        "content:encodedSnippet": "This is a guest post from Cheuk Ting Ho, a data scientist who contributes to multiple open-source libraries, such as pandas and Polars.\n\n\n\n\nYou’ve probably heard about Polars – it is now firmly in the spotlight in the data science community. \nAre you still using pandas and would like to try out Polars? Are you worried that it will take a lot of effort to migrate your projects from pandas to Polars? You might be concerned that Polars won’t be compatible with your existing pipeline or the other tools you are currently using.\nFear not! In this article, I will answer these questions so you can decide whether to migrate to using Polars or not. I will also provide some tips for those of you who have already decided to migrate.\n\n\n\n\nHow is Polars different from pandas?\nPolars is known for its speed and security, as it is written in Rust and based on Apache Arrow. For details about Polars vs. pandas, you can see our other blog post here. In short, while Polars’ backend architecture is different from pandas’, the creator and community around Polars have tried to maintain a Python API that is very similar to pandas’. At first glance, Polars code is very similar to pandas code. Fun fact – some contributors to pandas are also contributors to Polars. Due to this, the barrier for pandas users to start using Polars is relatively low. However, as it is still a different library, it is worth double-checking the differences between the two.\nAdvantages of using Polars\nHave you struggled when using pandas for a relatively large data set? Do you think pandas is using too much RAM and slowing your computer down while working locally? Polars may solve this problem by using its lazy API. Intermediate steps won’t be executed unless needed, saving memory for the intermediate steps in some cases.\nAnother advantage Polars has is that, since it is written in Rust, it can make use of concurrency much better than pandas. Python is traditionally single-threaded, and although pandas uses the NumPy backend to speed up some operations, it is still mainly written in Python and has certain limitations in its multithreading capabilities.\nTools that make the switch easy\nAs Polars’ popularity grows, there is more and more support for Polars in popular tools for data scientists, including scikit-learn and HoloViz.\nPyCharm, the most popular IDE used by data scientists, provides a similar experience when you work with pandas and Polars. This makes the process of migration smoother. For example, interactive tables allow you to easily see the information about your DataFrame, such as the number of rows and columns.\nTry PyCharm for free\n\n\n\n\nPyCharm has an excellent pagination feature – if you want to see more results per page, you can easily configure that via a drop-down menu:\n\n\n\n\nYou can see the statistical summary for the data when you hover the cursor over the column name:\n\n\n\n\nYou can also sort the data for inspection with a few clicks in the header. You can also use the multi-sorting functionality – after sorting the table once, press and hold ⌥ (macOS) or Alt (Windows) and click on the second column you want the table to be sorted by. For example, here, we can sort by island and bill_length_mm in the table.\n\n\n\n\nTo get more insights from the DataFrame, you can switch to chat view with the icon on the left:\n\n\n\n\nYou can also change how the data is shown in the settings, showing different columns and using different graph types:\n\n\n\n\nIt also helps you to auto-complete methods when using Polars, very handy when you are starting to use Polars and not familiar with all of the methods that it provides. To understand more about full line code completion in JetBrains IDEs, please check out this article. \n\n\n\n\nYou can also access the official documentation quickly by clicking the Polars icon in the top-right corner of the table, which is really handy.\n\n\n\n\nHow to migrate from pandas to Polars\nIf you’re now convinced to migrate to Polars, your final questions might be about the extent of changes needed for your existing code and how easy it is to learn Polars, especially considering your years of experience and muscle memory with pandas.\nSimilarities between pandas and Polars\nPolars provides APIs similar to pandas, most notably the read_csv(), head(), tail(), and describe() for a glance at what the data looks like. It also provides similar data manipulation functions like join() and groupby()/ group_by(), and aggregation functions like mean() and sum().\nBefore going into the migration, let’s look at these code examples in Polars and pandas.\nExample 1 – Calculating the mean score for each class\npandas\nimport pandas as pd\n\ndf_student = pd.read_csv(\"student_info.csv\")\n\nprint(df_student.dtypes)\n\ndf_score = pd.read_csv(\"student_score.csv\")\n\nprint(df_score.head())\n\ndf_class = df_student.join(df_score.set_index(\"name\"), on=\"name\").drop(\"name\", axis=1)\n\ndf_mean_score = df_class.groupby(\"class\").mean()\n\nprint(df_mean_score)\nPolars\nimport polars as pl\n\ndf_student = pl.read_csv(\"student_info.csv\")\n\nprint(df_student.dtypes)\n\ndf_score = pl.read_csv(\"student_score.csv\")\n\nprint(df_score.head())\n\ndf_class = df_student.join(df_score, on=\"name\").drop(\"name\")\n\ndf_mean_score = df_class.group_by(\"class\").mean()\n\nprint(df_mean_score)\nPolars provides similar io methods like read_csv. You can also inspect the dtypes, do data cleaning with drop, and do groupby with aggregation functions like mean.\nExample 2 – Calculating the rolling mean of temperatures\npandas\nimport pandas as pd\n\ndf_temp = pd.read_csv(\"temp_record.csv\", index_col=\"date\", parse_dates=True, dtype={\"temp\":int})\n\nprint(df_temp.dtypes)\n\nprint(df_temp.head())\n\ndf_temp.rolling(2).mean()\nPolars\nimport polars as pl\n\ndf_temp = pl.read_csv(\"temp_record.csv\", try_parse_dates=True, dtypes={\"temp\":int}).set_sorted(\"date\")\n\nprint(df_temp.dtypes)\n\nprint(df_temp.head())\n\ndf_temp.rolling(\"date\", period=\"2d\").agg(pl.mean(\"temp\"))\nReading with date as index in Polars can also be done with read_csv, with a slight difference in the function arguments. Rolling mean (or other types of aggregation) can also be done in Polars.\nAs you can see, these code examples are very similar, with only slight differences. If you are an experienced pandas user, I am sure your journey using Polars will be quite smooth.\nTips for migrating from pandas to Polars\nAs for code that was previously written in pandas, how can you migrate it to Polars? What are the differences in syntax that may trip you up? Here are some tips that may be useful:\nSelecting and filtering\nIn pandas, we use .loc / .iloc and [] to select part of the data in a data frame. However, in Polars, we use .select to do so. For example, in pandas df[\"age\"] or df.loc[:,\"age\"] becomes df.select(\"age\") in Polars.\nIn pandas, we can also create a mask to filter out data. However, in Polars, we will use .filter instead. For example, in pandas df[\"age\" > 18] becomes df.filter(pl.col(\"a\") > 18) in Polars.\nAll of the code that involves selecting and filtering data needs to be rewritten accordingly.\nUse .with_columns instead of .assign\nA slight difference between pandas and Polars is that, in pandas we use .assign to create new columns by applying certain logic and operations to existing columns. In Polars, this is done with .with_columns. For example:\nIn pandas\ndf_rec.assign(\n\n    diameter = lambda df: (df.x + df.y) * 2,\n\n    area = lambda df: df.x * df.y\n\n)\nbecomes\ndf_rec.with_columns(\n\n    diameter = (pl.col(\"x\") + pl.col(\"y\")) * 2,\n\n    area = pl.col(\"x\") * pl.col(\"y\")\n\n)\nin Polars.\n.with_columns can replace groupby\nIn addition to assigning a new column with simple logic and operations, .with_columns offers more advanced capabilities. With a little trick, you can perform operations similar to groupby in pandas by using window functions:\nIn pandas\ndf = pd.DataFrame({\n\n    \"class\": [\"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \"b\"],\n\n    \"score\": [\"80\", \"39\", \"67\", \"28\", \"77\", \"90\", \"44\"],\n\n})\n\ndf[\"avg_score\"] = df.groupby(\"class\")[\"score\"].transform(\"mean\")\nbecomes\ndf.with_columns(\n\n    pl.col(\"score\").mean().over(\"class\").alias(\"avg_score\")\n\n)\nin Polars.\nUse scan_csv instead of read_csv if you can\nAlthough read_csv also works in Polars, by using scan_csv instead of read_csv it will turn to lazy evaluation mode and benefit from the lazy API mentioned above.\nBuilding pipelines properly with lazy API\nIn pandas, we usually use .pipe to build data pipelines. However, since Polars works a bit differently, especially when using the lazy API, we want the pipeline to be executed only once. So, we need to adjust the code accordingly. For example:\nInstead of this pandas code snippet:\ndef discount(df):\n\n    df[\"30_percent_off\"] = df[\"price\"] * 0.7\n\n    return df\n\ndef vat(df):\n\n    df[\"vat\"] = df[\"price\"] * 0.2\n\n    return df\n\ndef total_cost(df):\n\n    df[\"total\"] = df[\"30_percent_off\"] + df[\"vat\"]\n\n    return df\n\n(df\n\n .pipe(discount)\n\n .pipe(vat)\n\n .pipe(total_cost)\n\n)\nWe will have the following one in Polars:\ndef discount(input_col)r:\n\n    return pl.col(input_col).mul(0.7).alias(\"70_percent_off\")\n\ndef vat(input_col):\n\n    return pl.col(input_col).mul(0.2).alias(\"vat\")\n\ndef total_cost(input_col1, input_col2):\n\n    return pl.col(input_col1).add(pl.col(input_col2).alias(\"total\")\n\ndf.with_columns(\n\n    discount(\"price\"),\n\n    val(\"price\"),\n\n    total_cost(\"30_percent_off\", \"vat\"),\n\n)\nMissing data: No more NaN\nDo you find NaN in pandas confusing? There is no NaN in Polars! Since NaN is an object in NumPy and Polars doesn’t use NumPy as the backend, all missing data will now be null instead. For details about null and NaN in Polars, check out the documentation.\nExploratory data analysis with Polars\nPolars provides a similar API to pandas, and with hvPlot, you can easily create a simple plotting function with exploratory data analysis in Polars. Here I will show two examples, one creating simple statistical information from your data set, and the other plotting simple graphs to understand the data.\nSummary statistics from dataset\nWhen using pandas, the most common way to get a summary statistic is to use describe. In Polars, we can also use describe in a similar manner. For example, we have a DataFrame with some numerical data and missing data:\n\n\n\n\nWe can use describe to get summary statistics:\n\n\n\n\nNotice how object types are treated – in this example, the column name gives a different result compared to pandas. In pandas, a column with object type will result in categorical data like this:\n\n\n\n\nIn Polars, the result is similar to numeric data, which makes less sense:\n\n\n\n\nSimple plotting with Polars DataFrame\nTo better visualize of the data, we might want to plot some graphs to help us evaluate the data more efficiently. Here is how to do so with the plot method in Polars.\nFirst of all, since Polars uses hvPlot as backend, make sure that it is installed. You can find the hvPlot User Guide here. Next, since hvPlot will output the graph as an interactive Bokeh graph, we need to use output_notebook from bokeh.plotting to make sure it will show inline in the notebook. Add this code at the top of your notebook:\nfrom bokeh.plotting import output_notebook\n\noutput_notebook()\nAlso, make sure your notebook is trusted. This is done by simply checking the checkbox in the top-right of the display when using PyCharm.\n\n\n\n\nNext, you can use the plot method in Polars. For example, to make a scatter plot, you have to specify the columns to be used as the x- and y-axis, and you can also specify the column to be used as color of the points:\ndf.plot.scatter(x=\"body_mass_g\", y=\"bill_length_mm\", color=\"species\")\nThis will give you a nice plot of the different data points of different penguin species for inspection:\n\n\n\n\nOf course, scatter plots aren’t your only option. In Polars, you can use similar steps to create any type of plot that is supported by hvPlot. For example, hist can be done like this:\ndf.plot.hist(\"body_mass_g\", by=[\"species\",\"sex\"])\n\n\n\n\nFor a full list of plot types supported by hvPlot, you can have a look at the hvPlot reference gallery.\nConclusion\nI hope the information provided here will help you on your way with using Polars. Polars is an open-source project that is actively maintained and developed. If you have suggestions or questions, I recommend reaching out to the Polars community.\nAbout the author\n\nCheuk Ting Ho\nCheuk has been a Data Scientist at various companies – a job that demands high numerical and programming skills, especially in Python. Following her passion for the tech community, Cheuk has been a Developer Advocate for three years. She also contributes to multiple open-source libraries like Hypothesis, Pytest, pandas, Polars, PyO3, Jupyter Notebook, and Django. Cheuk is currently a consultant and trainer at CMD Limes.",
        "dc:creator": "Evgenia Verbina",
        "content": "This is a guest post from Cheuk Ting Ho, a data scientist who contributes to multiple open-source libraries, such as pandas and Polars. You’ve probably heard about Polars – it is now firmly in the spotlight in the data science community.&#160; Are you still using pandas and would like to try out Polars? Are you [&#8230;]",
        "contentSnippet": "This is a guest post from Cheuk Ting Ho, a data scientist who contributes to multiple open-source libraries, such as pandas and Polars. You’ve probably heard about Polars – it is now firmly in the spotlight in the data science community.  Are you still using pandas and would like to try out Polars? Are you […]",
        "guid": "https://blog.jetbrains.com/?post_type=pycharm&p=482405",
        "categories": [
          "data-science",
          "tutorials",
          "pandas",
          "polars"
        ],
        "isoDate": "2024-06-19T11:48:42.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "article New updates to Planner comment notifications and settings in Planner Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Christine Ruana",
        "title": "Keep Visual Studio automatically updated and secure through Microsoft Update",
        "link": "https://devblogs.microsoft.com/visualstudio/automatically-install-visual-studio-security-updates-through-microsoft-update/",
        "pubDate": "Wed, 19 Jun 2024 17:30:59 +0000",
        "content:encodedSnippet": "Visual Studio is coming to Microsoft Update! We’re pleased to announce that starting in August 2024, developers who are not part of an organization managed by an IT administrator can choose to receive monthly Visual Studio security updates through the Microsoft Update (MU) system on “patch Tuesdays”.  This new update option will be available for Visual Studio 2022, Visual Studio 2019, and Visual Studio 2017. It won’t be available for the Preview channel.\nHow to enable Visual Studio updates through MU\nOpen Windows Settings and go to Windows Update > Advanced Options. If you can toggle the option at the top “Receive updates for other Microsoft products”, then you control your machine’s update policies and can choose to receive updates for Visual Studio and other Microsoft products from MU. We encourage you to enroll in this capability, as it’s by far the easiest way to stay updated and secure on a monthly cadence. If this option is greyed out and you can’t toggle it, this new feature does not apply to your machine (even if it is turned on) because your administrator controls your update policies.\nFigure 1 – Microsoft Update policy that is controlled by the user\nHow it works\nAs with other Visual Studio update methods, Visual Studio must be closed to apply these updates. MU will never force-close Visual Studio to apply the update. Updates delivered through Microsoft Update typically happen during machine idle time at night. Once you have opted into receiving Visual Studio updates through MU, just remember to periodically save your work and close Visual Studio in the evening to make sure that the update isn’t blocked. The next morning, you can verify in the Windows Update history that the latest Visual Studio security update was successfully applied. You can also initiate the update manually on demand by closing Visual Studio and pressing the Windows Update “Check for updates” button.\nOpting out of MU updates for Visual Studio\nIf you have chosen to receive updates for other Microsoft products, but you don’t want to receive Visual Studio updates from MU, you can set this registry key value to opt out:\n[HKLM\\Software\\Policies\\Microsoft\\VisualStudio\\Setup]\n“VSthroughMUUpdatesOptOut”=dword:1\nPreview the experience through July 2024\nYou can try out this new experience through July 2024 in advance of it rolling out in August. To opt in to the preview, toggle “Receive updates for other Microsoft products” to On, and set this registry key value:\n[HKLM\\Software\\Policies\\Microsoft\\VisualStudio\\Setup]\n“PreviewAutomaticUpdates”=dword:1\nStarting in August 2024, this registry key won’t be necessary.\nDuring June and July, the updates will have a “[Microsoft Update Preview]” prefix in the title. These updates are the same update as if you manually installed it from within the Visual Studio IDE.\nFigure 2 – Visual Studio security updates delivered during the Preview timeframe\n \nPlanned improvements\nThere are a few improvements to this experience that we’re working on.\nIf you rollback an update, you can temporarily use the registry key to opt out of MU updates for Visual Studio to prevent the update from automatically being re-applied. We’re working on a reliable experience for this.\nWe’re working to improve the error messages in the Windows Update UI, such as for the condition that the update was cancelled because Visual Studio was open.\nIf you use the “Check for Updates” button in the Windows Update UI, the progress bar will appear to be stuck at 0% until the update finishes, at which point it will immediately go to 100%. Visual Studio updates can take a while, so we ask for your patience while we improve the progress bar.\nWhat about IT Admin managed machines?\nWe’ve delivered a rich set of managed update solutions via Visual Studio Administrator Updates, which allow IT administrators in organizations to deploy monthly Visual Studio security updates by using Windows Update for Business. Over 1500 organizations, including Microsoft, currently use this solution to automatically install Visual Studio security updates on hundreds of thousands of machines each month.\nConclusion\nIf you’re an individual user that controls your own machine’s update policies, we hope you enroll in this solution to automatically receive and install updates for Visual Studio along with other Microsoft products. We welcome your feedback on this Automatic Update experience.\nWe appreciate the time you’ve spent reporting issues/suggestions and hope you continue to give us feedback when using Visual Studio on what you like and what we can improve. Your feedback is critical to help us make Visual Studio the best tool it can be! You can share feedback with us via Developer Community: report any bugs or issues via report a problem and share your suggestions for new features or improvements to existing ones.\nStay connected with the Visual Studio team by following us on YouTube, Twitter, LinkedIn, Twitch and on Microsoft Learn.\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nThe post Keep Visual Studio automatically updated and secure through Microsoft Update appeared first on Visual Studio Blog.",
        "dc:creator": "Christine Ruana",
        "content": "<p>Visual Studio is coming to Microsoft Update! We’re pleased to announce that starting in August 2024, developers who are not part of an organization managed by an IT administrator can choose to receive monthly Visual Studio security updates through the Microsoft Update (MU) system on &#8220;patch Tuesdays&#8221;. </p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/automatically-install-visual-studio-security-updates-through-microsoft-update/\">Keep Visual Studio automatically updated and secure through Microsoft Update</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Visual Studio is coming to Microsoft Update! We’re pleased to announce that starting in August 2024, developers who are not part of an organization managed by an IT administrator can choose to receive monthly Visual Studio security updates through the Microsoft Update (MU) system on “patch Tuesdays”. \nThe post Keep Visual Studio automatically updated and secure through Microsoft Update appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=249465",
        "categories": [
          "Visual Studio",
          "Microsoft Update",
          "security",
          "Update"
        ],
        "isoDate": "2024-06-19T17:30:59.000Z"
      },
      {
        "creator": "Mark Downie",
        "title": "Easily navigate code delegates while debugging",
        "link": "https://devblogs.microsoft.com/visualstudio/easily-navigate-code-delegates-while-debugging/",
        "pubDate": "Tue, 18 Jun 2024 15:34:17 +0000",
        "content:encodedSnippet": "Delegates are everywhere in modern code; a delegate is a type that represents references to methods with a particular parameter list and return type. Developers use delegates to pass methods as arguments to other methods. One example you may be familiar with is with event handlers. Handlers are methods you can invoke through delegates. Delegates remind me of C++ function pointers, but of course delegates are fully object-oriented.\nThere are a few ways to represent delegates, there is, for example, Func delegate. This generic delegate represents a method that takes one or more parameters and returns a value of a specified type. Here is an example (with a lambda expression):\nFunc<int, int> Multiplier = n => n * 5;\nint val = Multiplier(5);\nConsole.WriteLine(val);\nThe most recent variation of this concept is Action, which provides a more convenient shorthand. When you use Action you do not have to explicitly define a delegate that encapsulates a method with a single parameter. Here is an example:\nAction<string> outputFunc = GetOutputRoutine();\noutputFunc(\"Hello, World!\");\nstatic Action<string> GetOutputRoutine()\n{   return MyConsoleWriter;\n}\nstatic void MyConsoleWriter(string input)\n{   Console.WriteLine(\"Console: {0}\", input);\n}\nSo, this is a nice lesson, but why am I mentioning all this? While I find passing methods around like parameters is convenient when writing code, I also wish it were easier to follow while debugging. You can of course easily step into these methods, but I often want to quickly navigate to the underlying code represented by the delegate before or after stepping, and with the latest updates to Visual Studio 17.10 it’s incredibly easy.\nWhen you pause while debugging, you can hover over any delegate and get a convenient go to source link, here is an example with a Func delegate.\n\nThe Go to Source indicator makes it clear, in this example, that you will get redirected back to the lambda expression.\nPlease note this is not just for managed code situations, this also supports C++ function pointers and std::function.\nWe appreciate your feedback to help us improve Visual Studio and make it the best tool for you! You can share feedback with us via Developer Community: report any bugs or issues via report a problem and share your suggestions for new features or improvements to existing ones.\nPlease stay connected with the Visual Studio Debugger team on Twitter.\n \nThe post Easily navigate code delegates while debugging appeared first on Visual Studio Blog.",
        "dc:creator": "Mark Downie",
        "content": "<p>Delegates are everywhere in modern code; a delegate is a type that represents references to methods with a particular parameter list and return type. Developers use delegates to pass methods as arguments to other methods. One example you may be familiar with is with event handlers.</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/easily-navigate-code-delegates-while-debugging/\">Easily navigate code delegates while debugging</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Delegates are everywhere in modern code; a delegate is a type that represents references to methods with a particular parameter list and return type. Developers use delegates to pass methods as arguments to other methods. One example you may be familiar with is with event handlers.\nThe post Easily navigate code delegates while debugging appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=249489",
        "categories": [
          "Visual Studio",
          "Debugging and Diagnostics"
        ],
        "isoDate": "2024-06-18T15:34:17.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": [
      {
        "creator": "Beejei",
        "title": "Programming in the LLM Era #2 — How",
        "link": "https://beejei.medium.com/programming-in-the-llm-era-2-how-4071ac6e4245?source=rss-9f14ea26d32f------2",
        "pubDate": "Fri, 21 Jun 2024 00:52:51 GMT",
        "content:encodedSnippet": "Programming in the LLM Era #2 — How\nSeamless Collaboration — Dall-E\nEliminating the Understanding Gap Between Development Teams\nWhen developing a service targeted at general users, it’s common knowledge that there are typically Frontend and Backend developers involved. While there are many other categories, focusing on these two can illustrate the point. These roles are often at odds due to their separation of concerns. Even when addressing the same value, such as “efficiency,” their strategies can vastly differ. For a Frontend developer, efficiency means smooth loading and high responsiveness in a web browser. For a Backend developer, efficiency pertains to the server resource usage and cost-effectiveness.\nThese technology-driven areas can be approached in numerous ways, depending on the perspective. However, from a business standpoint, trying to maximize usability and profitability within a reasonable cost often results in vague directives like “cost-effective efficiency.” This makes it challenging to pinpoint specific methodologies, often leading developers to default to familiar technology stacks.\nUsing LLMs can simplify these dilemmas. By providing appropriate conditions and requesting code, the output can serve as a guideline. The key is to create prompts that require minimal technical detail while yielding satisfactory results. This approach ensures that any developer can easily align with the output, fostering better collaboration.\nEliminating the Gap in Code Reviews\nThe second point is about eliminating the gap in traditional code reviews. While code reviews help developers produce higher quality code over time, they can be a source of significant stress. The original author often prefers to stick to their approach, even if there are minor issues. Simple, agreed-upon changes can be made easily, but complex situations make code reviews difficult and time-consuming. This leads to high costs and delays in project completion. Culturally, code reviews can be an opportunity to build camaraderie, but they are still challenging and heavily reliant on individuals’ soft skills.\nBy using LLMs to generate code, everyone can take on the role of a code reviewer. Instead of traditional code review processes, developers can focus on refining the prompts and checking the output. This iterative process allows the team to align more closely with each other’s expectations. As the team reviews and adjusts the prompts together, they maintain a similar vision for the final product. Over time, this repeated collaboration fosters stronger bonds and more effective teamwork.\nBridging the Gap Between Planning and Execution\nThe third point is about closing the gap between planning and execution. Planning is often established by upper management based on the company’s grand vision. However, these plans frequently overlook the day-to-day tasks that need to be done. As plans trickle down to individual teams, they have to contend with ongoing tasks, backlogs, communication with other teams, and internal coordination. This results in increasingly rough plans with declining achievement rates.\nUsing LLMs can help reduce the time needed to reach planned goals. This allows for more detailed planning that aligns with the company’s aspirations. Employees can more easily align with the company’s direction, resulting in a more dynamic organization. With LLMs streamlining the execution of tasks, plans can be more specific and ambitious, fostering a more cohesive and agile workforce.",
        "dc:creator": "Beejei",
        "guid": "https://medium.com/p/4071ac6e4245",
        "categories": [
          "development",
          "chatgpt",
          "llm"
        ],
        "isoDate": "2024-06-21T00:52:51.000Z"
      },
      {
        "creator": "Beejei",
        "title": "Programming in the LLM Era #1 -Why",
        "link": "https://beejei.medium.com/programming-in-the-llm-era-1-why-8965f525c300?source=rss-9f14ea26d32f------2",
        "pubDate": "Thu, 20 Jun 2024 11:59:11 GMT",
        "content:encodedSnippet": "A modern workspace featuring a computer with code — Dall-E generated image\nThe Focus Should Be on Managing Prompts, Not Code\nMany developers find it challenging to create systems integrated with LLMs (Large Language Models) because the outputs from LLMs are not deterministic. However, I believe this very trait is a strength of LLMs, allowing them to adapt to changing realities and produce adaptable code.\nIn traditional development environments, developers strive to meticulously model data and maintain strict types and API information. This rigorous approach can increase the workload and make development more challenging, leading to higher fatigue. But if we shift our focus to managing prompts effectively, and if we can consistently receive improved outputs as code from LLMs, developers can concentrate more on the tasks they want to solve while obtaining high-quality code.\nData Always Exceeds Expectations\nData, unless in a closed environment, always exceeds expectations. Anyone who has modeled database tables has likely encountered user inputs that exceed expected field sizes. Time zones assumed to be fixed for calculations can fail due to political or cultural changes. Exchange rates fluctuate daily, and the cost of cloud resources can change at any moment. Even well-managed data can be unpredictable.\nForms and Excel files, where user freedom is involved, present even greater challenges. They often contain typos or incorrectly copied information, and special characters with unique meanings must be handled cautiously, often using regex functions. In such scenarios, how well can a developer’s data model use real-world information? In the era of LLMs, these issues can be better managed. LLMs can process various forms of unstructured data and respond flexibly to unexpected situations.\nThe Problem of Defining Semantics\nThe incorrect definition of semantics is also a problem. Semantic layers define information for permanent use, but these definitions often fail to capture reality. For example, phone numbers, email addresses, social media account information, names, and genders. Which of these can you be sure will remain unchanged for over 30 years? People are already accustomed to changing personal information.\nMany government agencies’ operations have yet to catch up with this reality, but we must recognize that data and the meanings of the names referring to that data are dynamic. Developers fond of modeling might prefer strong connections like unique keys or foreign keys, but in reality, these values are not always reliable.\nFor instance, it is unclear who might act as your guardian or proxy in a hospital. Transforming ambiguous real-world information into overly rigid definitions in a project is problematic. It is challenging to maintain consensus with such an approach in a constantly changing world.\nThinking Like Humans\nBoth the developers creating programs and the users using them are humans, and thinking like humans is more natural. Hence, future productive activities that require time and effort should be described as naturally as possible in the way humans think to maximize productivity and collaboration.\nDespite the perceived abundance of developers, they are proportionally as rare as endangered species relative to the global population. By changing how developers work, we can unlock immense potential. If we develop technology aligned with human thought processes and improve collaboration efficiency, we can produce better results in less time.",
        "dc:creator": "Beejei",
        "guid": "https://medium.com/p/8965f525c300",
        "categories": [
          "development",
          "llm",
          "chatgpt"
        ],
        "isoDate": "2024-06-20T11:59:11.000Z"
      }
    ]
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": [
      {
        "title": "GPU 거지 딥러닝 서버 만들기",
        "link": "http://daddynkidsmakers.blogspot.com/2024/06/gpu.html",
        "pubDate": "2024-06-23T05:28:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">이 글은&nbsp;GPU 거지?를 위한 딥러닝 서버 구축 방법을 간략히 알아본다.&nbsp;</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhyY3jxdHp9FTH8y4K8EeVXrPGRlNV_hJRMl4ia3WSSOwjoS4-w4ohJk9dXvFf0SUiqHle0xkCrwXpzbMHf02_7gNkMCJPuQG0aA5_J5a-uEP5IWkohQ4eg79CLQrMl5iFYjeVWTm2njcOWveVPoxpPoy2oDuJtQlOcqa0edQBoot-nUIqJPfW8rwkTBu2U\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"194\" data-original-width=\"259\" height=\"240\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhyY3jxdHp9FTH8y4K8EeVXrPGRlNV_hJRMl4ia3WSSOwjoS4-w4ohJk9dXvFf0SUiqHle0xkCrwXpzbMHf02_7gNkMCJPuQG0aA5_J5a-uEP5IWkohQ4eg79CLQrMl5iFYjeVWTm2njcOWveVPoxpPoy2oDuJtQlOcqa0edQBoot-nUIqJPfW8rwkTBu2U\" width=\"320\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgvokHVnzJnaBK5Y12GCjsR13L0rSJBsamOiRPiU7KtgsyBefq6xZelJuuc8jPkUaVRKknODB9ErqEWLuUKDVWvZQzfCBor_nS0S7f_4lQrJpQYGpmnuk28v8FpW88W_-7UwDn0vlpS3P81it8SmXoI-jj6AFGDApB9372RtaZTmW243eLAK7ZC2OdnWnDh\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"960\" data-original-width=\"1280\" height=\"240\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgvokHVnzJnaBK5Y12GCjsR13L0rSJBsamOiRPiU7KtgsyBefq6xZelJuuc8jPkUaVRKknODB9ErqEWLuUKDVWvZQzfCBor_nS0S7f_4lQrJpQYGpmnuk28v8FpW88W_-7UwDn0vlpS3P81it8SmXoI-jj6AFGDApB9372RtaZTmW243eLAK7ZC2OdnWnDh\" width=\"320\" /></a></div></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://www.ebay.com/itm/225110549185?itmmeta=01J11V603QMATRXW6DK4MJDFMW&amp;hash=item3469a262c1:g:s9EAAOSwjhRi8aPq&amp;itmprp=enc%3AAQAJAAAA8EisE7hYOfIW9NJwekQvSZjEOAVsBQ62JDkJBNADgEw8PyMBbC861ZA98bGSlK6vDL52gunRJrp5d7XOyiXh87qHgckiTqtuqdfWcFx6P4wCg5siVGnCoYY8oLG7Gpf9mTEFcWW%2BFT2paKgmvsHQ2rgpo0aMDs1UushDHyk77%2F2sbk2gfsS8ipOejc7TGzA%2FnPagaEluiSl5Sq6b8LGNHU5H4dK1TZwVcvsmjZjMcu8vpYOHNtJfwXeuIYaosXX8EknELlW%2ByuoJ8N5cH6m2kl9zfkklqGj72192TwMdW8YqKmpMosH55%2FvBL1SWQ9X97A%3D%3D%7Ctkp%3ABk9SR_qBmLuIZA\">ASUS ESC4000 G4 2U 8Bays Dual 2nd Gen Scalable Processor Rackmount GPU Server | eBay</a></div><br /></div><div style=\"text-align: left;\">많은 정부 과제, 용역, LLM 열풍 등으로 인해 NVIDIA GPU 서버 수요가 폭증하고 있다. 이에 덩달아, GPU 인플레이션이 심한데, 업체에서 구매하면 A100 x 4 way server 가격만 약 1억이다. 이를 개별 부품을 사서 조립하면, 6~7천만원 수준에서 GPU 서버를 얻을 수 있다. 물론, 업체에서 서비스로 설치해주는 리눅스 OS, NVIDIA 드라이버 등 소프트웨어는 본인이 모두 해결해야 단점은 있다.&nbsp;</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b>필요성</b></div><div style=\"text-align: left;\">본인이 취미?로 CNN계열 YOLO 모델을 학습, 개발할 때는 그 당시로는 대용량 8GB GPU를 사용하면 나름 빵빵한 스펙이었다.&nbsp;</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">그러나, LLM 기술이 릴리즈되면서, 모든 것이 달라졌다. 예를 들어, 70B 파라메터를 가진 LLM 모델을 학습하거나 튜닝하기 위해서는 700GB 이상의 GPU 메모리가 필요하며, 80GB 용량을 가진 NVIDIA A100이 1,300 ~ 1,500만원이니, 대략 2억 가까이되는 리소스가 필요한 상황이 되어버렸다.&nbsp;</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgS9ocdIrpDwV4Efxhddt-4iZIfSGQeJK95ogW5hy3ThGcDKq-mcJOP-Xniz06_WRVLU6cmA51DZI1aHdvUTXZTfPKWWqWwVSAGIq6XkzEw3yfqB4VjP2lHMR8AbLWv4ptnns9fXn4lSznZn8W9K5b1r_tPYFpSDQodp1S9VAp-YKxFVyd4D_KvBttb4aR-/s694/oom.JPG\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"226\" data-original-width=\"694\" height=\"130\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgS9ocdIrpDwV4Efxhddt-4iZIfSGQeJK95ogW5hy3ThGcDKq-mcJOP-Xniz06_WRVLU6cmA51DZI1aHdvUTXZTfPKWWqWwVSAGIq6XkzEw3yfqB4VjP2lHMR8AbLWv4ptnns9fXn4lSznZn8W9K5b1r_tPYFpSDQodp1S9VAp-YKxFVyd4D_KvBttb4aR-/w400-h130/oom.JPG\" width=\"400\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">LLM 모델 튜닝, 학습에서 빈번한 Out of Memory 에러</div><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div></div><div style=\"text-align: left;\">실제로, 배치 데이터를 GPU에 올리고 학습하기 위해서는 이 용량의 몇 배가 필요할 수 있어, 금액은 더 올라가게 되어 있다(국내에서도 이 정도 인프라를 갖춘 IT업체가 많지 않다. 대부분 Lora와 같은 작은 메모리를 이용한 파인튜닝 정도이거나, 해외 빅테크 업체가 개발된 LLM의 사전 학습된 모델을 사용해 튜닝하는 수준이다).</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">이런 이유로, 본인이 LLM모델을 직접 개발하고 싶다면, 가성비있게 다중 GPU지원하는 서버를 개발할 필요가 생긴다.&nbsp;</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b>다중 GPU 서버 구축하기</b></div><div style=\"text-align: left;\"><div>다중 GPU 구축할 때 주요 고려 사항은 다음과 같다.</div><div><ul style=\"text-align: left;\"><li>메모리(VRAM)</li><li>성능(Tensor 코어, 클럭 속도)</li><li>슬롯 너비</li><li>사용 전력</li><li>다중 GPU 지원 마더보드</li><li>냉각 처리</li><li>넉넉한 케이스 크기</li></ul></div><div>딥러닝 작업을 위해서는 많은 메모리가 필요하다. LLM은 미세 조정하기에도 방대하며, 컴퓨터 비전 작업은 특히 3D 네트워크에서 메모리 집약적일 수 있다. 당연히 찾아야 할 가장 중요한 측면은 GPU VRAM이다. LLM의 경우 최소 24GB 메모리를 권장하고 컴퓨터 비전 작업의 경우 12GB 이하로 내려가지 않는다.</div><div><br /></div><div>두 번째 기준은 FLOPS(초당 부동 소수점 연산)로 추정할 수 있는 성능이다.</div><div>과거의 중요한 숫자는 회로의 CUDA 코어 수였다. 그러나 딥 러닝의 등장으로 NVIDIA는 클럭당 더 많은 FMA(Fused Multiply-Add) 연산을 수행할 수 있는 특수 텐서 코어를 도입했다.&nbsp;</div><div><br /></div><div>다른 GPU의 성능을 비교할 때는 각별히 주의해야 하다. 다른 세대/아키텍처의 Tensor 코어는 비교할 수 없다. 예를 들어, A100은 256개의 FP16 FMA 작동/클럭을 수행하는 반면 V100은 64개의 \"유일한\" 작업을 수행한다. 또한 이전 아키텍처(Turing, Volta)는 32비트 텐서 연산을 지원하지 않는다. 비교를 더 어렵게 만드는 것은 NVIDIA가 백서에서도 항상 FMA를 보고하는 것은 아니며 동일한 아키텍처의 GPU가 다른 FMA를 가질 수 있다는 것이다. 참고로, GPT는 수많은 A100을 사용해 학습되었다.</div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjs2UWxCl5mkn_YynXEVOMJGs07ub_3-42zoXLFyQ4XBNvofMMVi_jF-35u3AQvKgmYkk5eZt1hfHjnOKBPTyxBYrz8DYQAlLBKw0OV8xabMRkUo6km5Wh58Ng_H8bdvUWP4hSLLGTSJiNKSkTAcMLoQdsZpmue00EKqd-Egz63F-cim8-Wzkotl-m5Hgk3\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"315\" data-original-width=\"310\" height=\"240\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjs2UWxCl5mkn_YynXEVOMJGs07ub_3-42zoXLFyQ4XBNvofMMVi_jF-35u3AQvKgmYkk5eZt1hfHjnOKBPTyxBYrz8DYQAlLBKw0OV8xabMRkUo6km5Wh58Ng_H8bdvUWP4hSLLGTSJiNKSkTAcMLoQdsZpmue00EKqd-Egz63F-cim8-Wzkotl-m5Hgk3\" width=\"236\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">NVIDIA A100 (80GB. 가격은 12,000 ~ 15,000만원 사이)</div><br /></div><div>멀티 GPU 시스템을 구축할 때는 GPU를 PC 케이스에 물리적으로 맞추는 방법을 계획해야 하다. GPU가 점점 더 커지고 있기 때문에, 특히 게임 시리즈에서는 이것이 더 큰 문제가 되고 있다. 소비자용 마더보드에는 최대 7개의 PCIe 슬롯이 있으며 PC 케이스는 이 설정을 기반으로 제작됩니다. 4090은 제조업체에 따라 4개의 슬롯을 쉽게 차지할 수 있으므로 이것이 문제가 되는 이유를 알 수 있다. 또한 과열을 방지하기 위해 송풍기 스타일이 아니거나 수냉식이 아닌 GPU 사이에 최소 1개의 슬롯을 남겨 두어야 하다. 다음과 같은 옵션이 있다.</div><div><br /></div><div>수냉식은 최대 2개의 슬롯을 차지하고 비싸다. AIO(All-in-One) 솔루션을 얻지 못하면 맞춤형 수냉식 루프를 구축해야 하다. AIO 라디에이터가 케이스에 맞지 않을 수 있으므로 여러 개의 수냉식 GPU를 장착하려는 경우에도 마찬가지이다.&nbsp;</div><div><br /></div><div>최신 GPU는 점점 더 많은 전력을 소비하다. 예를 들어, 4090은 450W가 필요하고 H100은 최대 700W를 얻을 수 있다. GPU가 끌어올 수 있는 최대 전력을 줄이는 데 필요한 것은 다음과 같다.</div><div><br /></div><div>sudo nvidia-smi -i &lt;GPU_index&gt; -pl &lt;power_limit&gt;</div><div><br /></div><div>다음 단계는 여러 GPU를 허용하는 마더보드를 선택하는 것이다. 여기서 주요 고려 사항은 PCIe 레인이다. 각 카드에 대해 각각 x8 레인이 있는 최소 PCIe 3.0 슬롯이 필요하다. PCIe 4.0 또는 5.0은 더 드물며 대부분의 딥 러닝 사용 사례에 필요하지 않는다. 간격을 확인하고 GPU가 실제로 원하는 곳으로 이동할 수 있는지 확인하라.&nbsp;</div><div><br /></div><div>마더보드는 여러 GPU를 연동하기 위한 Multiple GPU와, SLI 혹은 NVLink 규약을 지원해야 한다. 이 규약은 다중 GPU 간 메모리를 합치고, 공유하며, 이들간 데이터 전송 속도를 최적화한다. 다음은 그 리스트를 보여준다.&nbsp;</div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhEemEAGq0JVB3Lpbf1J5Lny8_H1bEJvCSZ-vffQuJx2hYAES_dbvg2kFhBDNyvj-iw9u-hb59Q-0-kLofRqfZf5EwiKeMNuMukwTe1NeFxggKaeNPV4I7-PYQ1IR4Gux02IhA2XTamva6pNr5ZllslKPeANFWR0jEpLv_I0XganrIGBHDC7nwaYX-wbKrX\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"456\" data-original-width=\"543\" height=\"269\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhEemEAGq0JVB3Lpbf1J5Lny8_H1bEJvCSZ-vffQuJx2hYAES_dbvg2kFhBDNyvj-iw9u-hb59Q-0-kLofRqfZf5EwiKeMNuMukwTe1NeFxggKaeNPV4I7-PYQ1IR4Gux02IhA2XTamva6pNr5ZllslKPeANFWR0jEpLv_I0XganrIGBHDC7nwaYX-wbKrX=w320-h269\" width=\"320\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEi9QRBYgkvVSk78f69OEBA52Gbmx6T3uv62a6rfGcqZDMFCS3-mI971atotuU6lxzxpjihLiPPLIAQ3NLVBesw6PxzzMVcIl4RPw5chLhL1Pf-BEjUMQSf6mqyxxIIbeRVxS8uXA_C7on2YHEzpmDK7Mx-a-0uRJ6BHU8PTJmw81Bf7v-lDEHbqAX1zfSN0\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"348\" data-original-width=\"565\" height=\"246\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEi9QRBYgkvVSk78f69OEBA52Gbmx6T3uv62a6rfGcqZDMFCS3-mI971atotuU6lxzxpjihLiPPLIAQ3NLVBesw6PxzzMVcIl4RPw5chLhL1Pf-BEjUMQSf6mqyxxIIbeRVxS8uXA_C7on2YHEzpmDK7Mx-a-0uRJ6BHU8PTJmw81Bf7v-lDEHbqAX1zfSN0=w400-h246\" width=\"400\" /></a></div><br /></div><div><b>마무리</b></div></div><div style=\"text-align: left;\"><div><div>앞의 고려사항이 복잡하다면, GPU 서버 랙 구입을 감안할 수 있다. 더 비싸지만, 안정적이다. 다음은 이런 부분이 고려된 GPU 서버를 보여준다.</div></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><iframe allowfullscreen=\"\" class=\"BLOG_video_class\" height=\"266\" src=\"https://www.youtube.com/embed/MWxXAGFyvTc\" width=\"320\" youtube-src-id=\"MWxXAGFyvTc\"></iframe></div><div><br /></div></div><div style=\"text-align: left;\"><b>레퍼런스</b></div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><a href=\"https://www.asus.com/commercial-servers-workstations/pro-ws-x299-sage-ii/\">Pro WS X299 SAGE II | Servers &amp; Workstations | ASUS Global</a></li><li><a href=\"https://adriangcoder.medium.com/building-a-multi-gpu-deep-learning-machine-on-a-budget-3f3b717d80a9\">Building a Multi-GPU Deep Learning Machine on a budget | by Adrian G | Medium</a></li><li><a href=\"https://www.asus.com/us/site/motherboards/intel-x299-gamer-creator/deeplearning/lambda/\">Lambda | Deep Learning | ASUS US</a></li><li><a href=\"https://towardsdatascience.com/how-to-build-a-multi-gpu-system-for-deep-learning-in-2023-e5bbb905d935#:~:text=The%20next%20step%20of%20the,for%20most%20deep%20learning%20usecases.\">Build a Multi-GPU System for Deep Learning in 2023 | Towards Data Science</a></li><li><a href=\"https://www.asus.com/commercial-servers-workstations/pro-ws-x299-sage-ii/\">Pro WS X299 SAGE II | Servers &amp; Workstations | ASUS Global</a></li></ul></div>",
        "contentSnippet": "이 글은 GPU 거지?를 위한 딥러닝 서버 구축 방법을 간략히 알아본다. \n\n\n\n\n\nASUS ESC4000 G4 2U 8Bays Dual 2nd Gen Scalable Processor Rackmount GPU Server | eBay\n\n많은 정부 과제, 용역, LLM 열풍 등으로 인해 NVIDIA GPU 서버 수요가 폭증하고 있다. 이에 덩달아, GPU 인플레이션이 심한데, 업체에서 구매하면 A100 x 4 way server 가격만 약 1억이다. 이를 개별 부품을 사서 조립하면, 6~7천만원 수준에서 GPU 서버를 얻을 수 있다. 물론, 업체에서 서비스로 설치해주는 리눅스 OS, NVIDIA 드라이버 등 소프트웨어는 본인이 모두 해결해야 단점은 있다. \n\n\n필요성\n본인이 취미?로 CNN계열 YOLO 모델을 학습, 개발할 때는 그 당시로는 대용량 8GB GPU를 사용하면 나름 빵빵한 스펙이었다. \n\n\n그러나, LLM 기술이 릴리즈되면서, 모든 것이 달라졌다. 예를 들어, 70B 파라메터를 가진 LLM 모델을 학습하거나 튜닝하기 위해서는 700GB 이상의 GPU 메모리가 필요하며, 80GB 용량을 가진 NVIDIA A100이 1,300 ~ 1,500만원이니, 대략 2억 가까이되는 리소스가 필요한 상황이 되어버렸다. \n\n\nLLM 모델 튜닝, 학습에서 빈번한 Out of Memory 에러\n\n\n실제로, 배치 데이터를 GPU에 올리고 학습하기 위해서는 이 용량의 몇 배가 필요할 수 있어, 금액은 더 올라가게 되어 있다(국내에서도 이 정도 인프라를 갖춘 IT업체가 많지 않다. 대부분 Lora와 같은 작은 메모리를 이용한 파인튜닝 정도이거나, 해외 빅테크 업체가 개발된 LLM의 사전 학습된 모델을 사용해 튜닝하는 수준이다).\n\n\n이런 이유로, 본인이 LLM모델을 직접 개발하고 싶다면, 가성비있게 다중 GPU지원하는 서버를 개발할 필요가 생긴다. \n\n\n다중 GPU 서버 구축하기\n\n다중 GPU 구축할 때 주요 고려 사항은 다음과 같다.\n\n메모리(VRAM)\n성능(Tensor 코어, 클럭 속도)\n슬롯 너비\n사용 전력\n다중 GPU 지원 마더보드\n냉각 처리\n넉넉한 케이스 크기\n\n딥러닝 작업을 위해서는 많은 메모리가 필요하다. LLM은 미세 조정하기에도 방대하며, 컴퓨터 비전 작업은 특히 3D 네트워크에서 메모리 집약적일 수 있다. 당연히 찾아야 할 가장 중요한 측면은 GPU VRAM이다. LLM의 경우 최소 24GB 메모리를 권장하고 컴퓨터 비전 작업의 경우 12GB 이하로 내려가지 않는다.\n\n\n두 번째 기준은 FLOPS(초당 부동 소수점 연산)로 추정할 수 있는 성능이다.\n과거의 중요한 숫자는 회로의 CUDA 코어 수였다. 그러나 딥 러닝의 등장으로 NVIDIA는 클럭당 더 많은 FMA(Fused Multiply-Add) 연산을 수행할 수 있는 특수 텐서 코어를 도입했다. \n\n\n다른 GPU의 성능을 비교할 때는 각별히 주의해야 하다. 다른 세대/아키텍처의 Tensor 코어는 비교할 수 없다. 예를 들어, A100은 256개의 FP16 FMA 작동/클럭을 수행하는 반면 V100은 64개의 \"유일한\" 작업을 수행한다. 또한 이전 아키텍처(Turing, Volta)는 32비트 텐서 연산을 지원하지 않는다. 비교를 더 어렵게 만드는 것은 NVIDIA가 백서에서도 항상 FMA를 보고하는 것은 아니며 동일한 아키텍처의 GPU가 다른 FMA를 가질 수 있다는 것이다. 참고로, GPT는 수많은 A100을 사용해 학습되었다.\n\n\nNVIDIA A100 (80GB. 가격은 12,000 ~ 15,000만원 사이)\n\n멀티 GPU 시스템을 구축할 때는 GPU를 PC 케이스에 물리적으로 맞추는 방법을 계획해야 하다. GPU가 점점 더 커지고 있기 때문에, 특히 게임 시리즈에서는 이것이 더 큰 문제가 되고 있다. 소비자용 마더보드에는 최대 7개의 PCIe 슬롯이 있으며 PC 케이스는 이 설정을 기반으로 제작됩니다. 4090은 제조업체에 따라 4개의 슬롯을 쉽게 차지할 수 있으므로 이것이 문제가 되는 이유를 알 수 있다. 또한 과열을 방지하기 위해 송풍기 스타일이 아니거나 수냉식이 아닌 GPU 사이에 최소 1개의 슬롯을 남겨 두어야 하다. 다음과 같은 옵션이 있다.\n\n\n수냉식은 최대 2개의 슬롯을 차지하고 비싸다. AIO(All-in-One) 솔루션을 얻지 못하면 맞춤형 수냉식 루프를 구축해야 하다. AIO 라디에이터가 케이스에 맞지 않을 수 있으므로 여러 개의 수냉식 GPU를 장착하려는 경우에도 마찬가지이다. \n\n\n최신 GPU는 점점 더 많은 전력을 소비하다. 예를 들어, 4090은 450W가 필요하고 H100은 최대 700W를 얻을 수 있다. GPU가 끌어올 수 있는 최대 전력을 줄이는 데 필요한 것은 다음과 같다.\n\n\nsudo nvidia-smi -i <GPU_index> -pl <power_limit>\n\n\n다음 단계는 여러 GPU를 허용하는 마더보드를 선택하는 것이다. 여기서 주요 고려 사항은 PCIe 레인이다. 각 카드에 대해 각각 x8 레인이 있는 최소 PCIe 3.0 슬롯이 필요하다. PCIe 4.0 또는 5.0은 더 드물며 대부분의 딥 러닝 사용 사례에 필요하지 않는다. 간격을 확인하고 GPU가 실제로 원하는 곳으로 이동할 수 있는지 확인하라. \n\n\n마더보드는 여러 GPU를 연동하기 위한 Multiple GPU와, SLI 혹은 NVLink 규약을 지원해야 한다. 이 규약은 다중 GPU 간 메모리를 합치고, 공유하며, 이들간 데이터 전송 속도를 최적화한다. 다음은 그 리스트를 보여준다. \n\n\n\n\n마무리\n\n\n앞의 고려사항이 복잡하다면, GPU 서버 랙 구입을 감안할 수 있다. 더 비싸지만, 안정적이다. 다음은 이런 부분이 고려된 GPU 서버를 보여준다.\n\n\n\n\n레퍼런스\n\nPro WS X299 SAGE II | Servers & Workstations | ASUS Global\nBuilding a Multi-GPU Deep Learning Machine on a budget | by Adrian G | Medium\nLambda | Deep Learning | ASUS US\nBuild a Multi-GPU System for Deep Learning in 2023 | Towards Data Science\nPro WS X299 SAGE II | Servers & Workstations | ASUS Global",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-3734208096456279404",
        "isoDate": "2024-06-23T05:28:00.000Z"
      },
      {
        "title": "Weights & Biases로  딥러닝 모델 개발 프로세스 기록, 분석, 가시화 및 모델 튜닝하기",
        "link": "http://daddynkidsmakers.blogspot.com/2024/06/weights-biases.html",
        "pubDate": "2024-06-21T07:49:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">딥러닝 모델들을 개발하다 보면, 수많은 종류의 데이터셋, 하이퍼모델 파라메터 튜닝 등으로 인해 관리해야 할 자료들이 매우 복잡해진다는 것을 알게 된다. Weights &amp; Biases (W&amp;B) 회사는 이름 그대로 완벽한 모델 학습을 위해 필요한 Weights &amp; Biases를 모니터링, 관리할 수 있는 로그 도구이다. 즉, 딥러닝 모델 개발자를 위한 프로세스 로그 및 가시화 플랫폼을 제공한다.&nbsp;</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjv5Nez6boz4ciN-vuWPnZ2hGNHcsaKTJWHNikWDMzWWMnRwrM45ut3Jhuc4AOmZaCFkC8Ma1lxMThj4V2zHtS7v6o-0Zvl7iRxEJUXTYcMndbTIiDnDucqh0SK8mZkaifmVtXOkJU50LJywNaaQChC-M3jWTmoUFkCijzBm8Vk79EZDElUcCtswvAa9SQj\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"540\" data-original-width=\"960\" height=\"225\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjv5Nez6boz4ciN-vuWPnZ2hGNHcsaKTJWHNikWDMzWWMnRwrM45ut3Jhuc4AOmZaCFkC8Ma1lxMThj4V2zHtS7v6o-0Zvl7iRxEJUXTYcMndbTIiDnDucqh0SK8mZkaifmVtXOkJU50LJywNaaQChC-M3jWTmoUFkCijzBm8Vk79EZDElUcCtswvAa9SQj=w400-h225\" width=\"400\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">W&amp;B(AI Summer)</div><br /></div><div style=\"text-align: left;\">매우 직관적인 이름을 가진 이 스타트업은 Tensorboard와 유사하지만, 적은 코드로 모델 개발에 많은 통찰력을 준다. 이 W&amp;B(WandB) 라이브러리를 사용하면, 딥러닝 모델 학습 시 지저분하게 붙어 나가는 로그 처리를 매우 간단한 함수 몇 개로 처리할 수 있다. 통합된 데시보드 형태로 다양한 모델 학습 품질 지표를 확인 및 비교할 수 있다. 이외, 학습 모델 하이퍼 파라메터 관리와 튜닝 및 비교 보고서 생성 기능을 제공한다. 로그는 숫자, 텍스트, 이미지 등 다양한 포맷을 지원한다.&nbsp;</div><div style=\"text-align: left;\"><div style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgUPLogcemSukKiuTCB0j37hxU-YrTgXFc-14TlaMAmZRV4QE02guoMmWYevt_8GB6UUkVH2E4hZj-G0bsJbDLwpo0SkXH4rJLbJMkm1K6ovOlujjnkJ9WHQJxe_vp-TBj6JX0uQ1Yav45quf_KXLviQvRQeiGqYV7IQGBApKUj1c6JhEcmZCB6VkweH6wB\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"1042\" data-original-width=\"2033\" height=\"205\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgUPLogcemSukKiuTCB0j37hxU-YrTgXFc-14TlaMAmZRV4QE02guoMmWYevt_8GB6UUkVH2E4hZj-G0bsJbDLwpo0SkXH4rJLbJMkm1K6ovOlujjnkJ9WHQJxe_vp-TBj6JX0uQ1Yav45quf_KXLviQvRQeiGqYV7IQGBApKUj1c6JhEcmZCB6VkweH6wB=w400-h205\" width=\"400\" /></a></div><div style=\"text-align: center;\">W&amp;B 딥러닝 모델 개발 프로세스 가시화 데쉬보드</div><div style=\"text-align: center;\"><br /></div></div><div style=\"text-align: left;\">이 글은 딥러닝 모델 학습 로그, 가시화만 집중해 살펴본다. 글 마무리에 W&amp;B의 개발 배경도 간단히 알아본다.&nbsp;&nbsp;</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b>사용법</b></div><div style=\"text-align: left;\">다음 링크 방문해 회원 가입한다.&nbsp;</div><div style=\"text-align: left;\"><div><ul style=\"text-align: left;\"><li><a href=\"https://wandb.ai/\">wandb.ai</a>&nbsp;website</li></ul></div></div><div style=\"text-align: left;\">회원 가입하고, 다음 그림과 같이 홈 메뉴에서 키 토큰 값을 얻어 복사한다. 이 키는 wandb API를 사용할 때 필요하다.</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhisx_F16oiOYwWThwiSeVEsU05yDrZ5xDubg_d_68_aF4Y6YstMxGm5o61LriRMIufrYHy8atkCxc_xM4L0f0aOG7P3fK7df5S16qnmHjC8zKW3yc5uwiDaiIFjIs9n-yAAn1GCVRKI7BxQ2N6kcjhHESKg_J_EjSS49PL5nXfE-JxSTEszBdYo74eU-ul\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"1087\" data-original-width=\"2023\" height=\"215\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhisx_F16oiOYwWThwiSeVEsU05yDrZ5xDubg_d_68_aF4Y6YstMxGm5o61LriRMIufrYHy8atkCxc_xM4L0f0aOG7P3fK7df5S16qnmHjC8zKW3yc5uwiDaiIFjIs9n-yAAn1GCVRKI7BxQ2N6kcjhHESKg_J_EjSS49PL5nXfE-JxSTEszBdYo74eU-ul=w400-h215\" width=\"400\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjRpfUPW0F6yCOaWncGNCfqGYDO7RwQJlXU7WkIKmeLcDkargQwMniBOlfSNTk6TFf0zjxXvfhYaf9PzCce0DytrcBdqbHnAOEXGHWzJJo_GgTU2yz5q__K42vmi8uul_3kB3bR9WQYjMxgtw7E4VhBVjqklUqlAOExtjSpNqRsviRcdrEQEkkyj8QhflBK\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"608\" data-original-width=\"861\" height=\"283\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjRpfUPW0F6yCOaWncGNCfqGYDO7RwQJlXU7WkIKmeLcDkargQwMniBOlfSNTk6TFf0zjxXvfhYaf9PzCce0DytrcBdqbHnAOEXGHWzJJo_GgTU2yz5q__K42vmi8uul_3kB3bR9WQYjMxgtw7E4VhBVjqklUqlAOExtjSpNqRsviRcdrEQEkkyj8QhflBK=w400-h283\" width=\"400\" /></a></div></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">터미널에서 다음을 실행해 설치한다.&nbsp;</div><div style=\"text-align: left;\">pip install wandb</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b>예시 및 결과</b></div><div style=\"text-align: left;\">다음과 같이 cosine 데이터를 학습하는 간단한 코드를 만들어 본다. W&amp;B로 로그를 기록하도록 몇몇 함수를 호출할 것이다. 앞에서 얻은 키 토큰은 다음 코드에 해당 부분에 입력해 준다.</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><div>import os</div><div>from tqdm import tqdm</div><div>import matplotlib.pyplot as plt</div><div>import numpy as np</div><div>import wandb</div><div>import torch</div><div>import torch.nn as nn</div><div>import torch.optim as optim</div><div>from torchviz import make_dot</div><div><br /></div><div>device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')</div><div>print(f\"Using device: {device}\")</div><div><br /></div><div>class SimpleMLP(nn.Module):</div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span>def __init__(self):</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t\t</span>super(SimpleMLP, self).__init__()</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t\t</span>self.fc1 = nn.Linear(1, 50)</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t\t</span>self.fc2 = nn.Linear(50, 1)</span></div><div><br /></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span>def forward(self, x):</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t\t</span>x = torch.relu(self.fc1(x))</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t\t</span>x = self.fc2(x)</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t\t</span>return x</span></div><div><br /></div><div># Generate cosine dataset</div><div>def generate_cosine_data(num_samples=100):</div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span>x = torch.linspace(-2 * torch.pi, 2 * torch.pi, num_samples).view(-1, 1)</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span>y = torch.cos(x)</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span>return x, y</span></div><div><br /></div><div># Instantiate the model, loss function, and optimizer</div><div>model = SimpleMLP()</div><div>model.to(device)</div><div>criterion = nn.MSELoss()</div><div>optimizer = optim.SGD(model.parameters(), lr=0.01)</div><div><br /></div><div>wandb.login(key='') # 여기에 키값 입력</div><div>api = wandb.Api()</div><div><span style=\"white-space: pre;\">\t</span></div><div>wandb.init(project=\"train_cosin\",&nbsp;</div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span>config={</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t\t</span>\"optimizer\": \"SGD\",</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t\t</span>\"learning_rate\": 0.01,</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t\t</span>\"architecture\": \"SimpleMLP\",</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t\t</span>\"dataset\": \"cosine\"<span style=\"white-space: pre;\">\t\t</span></span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span>})</span></div><div>wandb.watch(model, criterion, log=\"all\")&nbsp; # 모든 지표 기록</div><div><br /></div><div># 학습 데이터 생성</div><div>x, y = generate_cosine_data()</div><div>x, y = x.to(device), y.to(device)</div><div><br /></div><div># 학습</div><div>prediction = None</div><div>num_epochs = 10000</div><div>image_files = []</div><div>for epoch in tqdm(range(num_epochs)):</div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span># Forward pass</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span>outputs = model(x)</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span>prediction = outputs</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span>loss = criterion(outputs, y)</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span>print(f\"Epoch: {epoch}, Loss: {loss.item()}\")</span></div><div><br /></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span># Backward pass and optimization</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span>optimizer.zero_grad()</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span>loss.backward()</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span>optimizer.step()</span></div><div><span style=\"white-space: pre;\">\t</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span># Visualize the gradients of the first epoch using wandb</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span>layer_name = ''</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span>grad_cpu = data_cpu = None</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span>for name, param in model.named_parameters():</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t\t</span>if param.requires_grad and param.grad is not None:</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t\t\t</span>layer_name = name</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t\t\t</span>grad_cpu = param.grad.detach().cpu()</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t\t\t</span>data_cpu = param.data.detach().cpu()</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t\t\t</span>break</span></div><div><br /></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span>log_data = {\"epoch\": epoch, \"loss\": loss.item(), \"outputs\": outputs.detach().cpu().numpy(),&nbsp;</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t\t\t\t</span>f'{layer_name}_gradients': wandb.Histogram(grad_cpu),&nbsp;</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t\t\t\t</span>f'{layer_name}_weights': wandb.Histogram(data_cpu)}</span></div><div><span style=\"white-space: normal;\"><span style=\"white-space: pre;\">\t</span>wandb.log(log_data) # 에폭, 로스, 출력, 기울기, 가중치 로그 기록</span></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">학습된 결과는 다음과 같다. 잘 학습된 것을 알 수 있다.</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhmUgttokbUGqTdsJjcqPjNbgHjg_zDL-_EW-q4CEdWLkvFo1iiLQi0NIISQcEJnTZN1mSFq4qvo7HAWJjdwMDNZplPCpatkZUjneq9PSwdNNM1cYz2GDqZaBaKi0zuAIk4Fn2VV-BTVdOZpBJ68ZuenJXu3Ukr1XmFGKMaJS2V0qRwN3c78ICrrfT50t-H\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"524\" data-original-width=\"710\" height=\"236\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhmUgttokbUGqTdsJjcqPjNbgHjg_zDL-_EW-q4CEdWLkvFo1iiLQi0NIISQcEJnTZN1mSFq4qvo7HAWJjdwMDNZplPCpatkZUjneq9PSwdNNM1cYz2GDqZaBaKi0zuAIk4Fn2VV-BTVdOZpBJ68ZuenJXu3Ukr1XmFGKMaJS2V0qRwN3c78ICrrfT50t-H\" width=\"320\" /></a></div><br /></div><div style=\"text-align: left;\"><a href=\"https://wandb.ai/\">W&amp;B 웹사이트</a>&nbsp;<a href=\"https://wandb.ai/mac999/train_cosin?nw=nwusermac999\">나의 프로젝트</a>의 데쉬보드를 확인한다.&nbsp;</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgcYlozisJNORfC20z29s8kXJerR5zhr-W8kcmyVn3Rd8KwoHsRSMi5RjWZYJbMWRe7VJlxvVI7n9oKhmjBWiDknpxP5j3OjXbSsTBIET6s0PSjh50J7HA2LpovBlGjR5vFf2ccMKQNLu6xjppvs-yQBFBUFv95kxt8FCMoFVF8H8VM19lwVsarHU6iQTWf\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"1093\" data-original-width=\"982\" height=\"400\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgcYlozisJNORfC20z29s8kXJerR5zhr-W8kcmyVn3Rd8KwoHsRSMi5RjWZYJbMWRe7VJlxvVI7n9oKhmjBWiDknpxP5j3OjXbSsTBIET6s0PSjh50J7HA2LpovBlGjR5vFf2ccMKQNLu6xjppvs-yQBFBUFv95kxt8FCMoFVF8H8VM19lwVsarHU6iQTWf=w360-h400\" width=\"360\" /></a></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">데쉬보드에서는 각 단계 별 기울기, 가중치, 로스 등이 어떻게 변화하는 지를 손쉽게 확인할 수 있다.&nbsp;</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">각 차트 데이터는 엑셀 등 포맷으로 저장 가능하다.&nbsp;</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">로짓 출력값을 확인해 보자. 초기 에폭에서는 학습되지 않은 임의 값을 출력하지만, 학습될 수록 y에 근사한 패턴으로 출력되는 것을 확인할 수 있다.</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjGYbP23V2GXRIM6RJsx3jv0Fv6THAJH1GOFRMJot88Mf3DEtPsByxLUK70jBuJNkCoByPOD4_VkgL8EMaxUTkX4kuX94qR6Ik-tHV9_XUQfM43Y94XIAsYbPY0AAL7m_H1jGMwskruCdVOr6Y0D3p5pjIBFNGMAqfJBfLXCjPKbEq-jhUqEbDjI6Sae2GI\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"931\" data-original-width=\"1936\" height=\"193\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjGYbP23V2GXRIM6RJsx3jv0Fv6THAJH1GOFRMJot88Mf3DEtPsByxLUK70jBuJNkCoByPOD4_VkgL8EMaxUTkX4kuX94qR6Ik-tHV9_XUQfM43Y94XIAsYbPY0AAL7m_H1jGMwskruCdVOr6Y0D3p5pjIBFNGMAqfJBfLXCjPKbEq-jhUqEbDjI6Sae2GI=w400-h193\" width=\"400\" /></a></div>엑셀 출력된 데이터를 보면, cosine 패턴으로 수렴한 예측값이 점차 많아지는 것을 확인할 수 있다.&nbsp;</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEiesZo-FZEdyAIoH5JTAY3JHPDUHUn6LYVGjZbY_Oie_Fd-FI8oilbxmRY6PUx97kKQVzQ1p-d7el5QwV7wwhSvQe9kLtV7E9fpUzmD3g86_pRLDaOSS7K1GlMIIxcR4rdh0L0VoMf6RqdsAZyOwXkcqeYupGx2PiJpD_0dOG_p_-Gc84gBBfrr-jRtho44\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"403\" data-original-width=\"1580\" height=\"165\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEiesZo-FZEdyAIoH5JTAY3JHPDUHUn6LYVGjZbY_Oie_Fd-FI8oilbxmRY6PUx97kKQVzQ1p-d7el5QwV7wwhSvQe9kLtV7E9fpUzmD3g86_pRLDaOSS7K1GlMIIxcR4rdh0L0VoMf6RqdsAZyOwXkcqeYupGx2PiJpD_0dOG_p_-Gc84gBBfrr-jRtho44=w640-h165\" width=\"640\" /></a></div><br /></div><div style=\"text-align: left;\">다음 경우는 모델의 바이어스 히스토그램 차트 데이터를 보여준다.&nbsp;</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjPRCnikw_0DGKxAEoa2qmKBGNc1jMbQpewRZBmkfu8ed7XnyvtOVRjU-J6VKhNrgAAGYRUiyJfkDAoH_TFTQvkNTmdDakNm_x7m5wA4ie3Cez95J2iiBKmKWbwU-H54SmmmXQKEXeAw_j38OTaN8WupO_Oc6t2uLCbjANMxpEL0x1o_cySBok6b9_rtVmU\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"866\" data-original-width=\"1926\" height=\"180\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjPRCnikw_0DGKxAEoa2qmKBGNc1jMbQpewRZBmkfu8ed7XnyvtOVRjU-J6VKhNrgAAGYRUiyJfkDAoH_TFTQvkNTmdDakNm_x7m5wA4ie3Cez95J2iiBKmKWbwU-H54SmmmXQKEXeAw_j38OTaN8WupO_Oc6t2uLCbjANMxpEL0x1o_cySBok6b9_rtVmU=w400-h180\" width=\"400\" /></a></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">엑셀로 다운로드하면, 모델 학습 데이터의 특정 범위에 속한 값의 누적 데이터를 쉽게 확인할 수 있다.</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjgRmKXub3EWyf0aVUShKw5YjnTmSfF4AGHbGDj_ZIkhBU39GowrMd_gk5bYRbU6iE8TBqe087xOptmJ8Dx0tyHeDgN_or6lhJIrptj5Jw_fZEnCoGKpsBZeaSlsNoJBzHKXGrt3oclMmFmqLprniDE9Hf2QYm2pPRX6fMSMxHiBbguErFTb7I675W1UJLG\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"412\" data-original-width=\"2012\" height=\"133\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjgRmKXub3EWyf0aVUShKw5YjnTmSfF4AGHbGDj_ZIkhBU39GowrMd_gk5bYRbU6iE8TBqe087xOptmJ8Dx0tyHeDgN_or6lhJIrptj5Jw_fZEnCoGKpsBZeaSlsNoJBzHKXGrt3oclMmFmqLprniDE9Hf2QYm2pPRX6fMSMxHiBbguErFTb7I675W1UJLG=w640-h133\" width=\"640\" /></a></div><br /></div><div style=\"text-align: left;\">다음과 같이 리포트 기능을 사용해, 모델 학습 품질을 검토할 수 있다.</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjTOwnKp6beo7YTjT9jdDbMNilOyIk0fFKwYsXCoSSUPF8KmwzGNQAKK9zR7llhnc9t8jwHmOa-rTlVKV4Lckv1bUel9ioe89qM4OTQqZKGbg22Ihy6Gygxf6iZnjOPzvwvYJL2zNmssdd4wFuolGZvUqDtR1Sov4XYYEZegCXoI_Calrl_rPNNZlmgYTq4\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"1047\" data-original-width=\"1989\" height=\"210\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjTOwnKp6beo7YTjT9jdDbMNilOyIk0fFKwYsXCoSSUPF8KmwzGNQAKK9zR7llhnc9t8jwHmOa-rTlVKV4Lckv1bUel9ioe89qM4OTQqZKGbg22Ihy6Gygxf6iZnjOPzvwvYJL2zNmssdd4wFuolGZvUqDtR1Sov4XYYEZegCXoI_Calrl_rPNNZlmgYTq4=w400-h210\" width=\"400\" /></a></div><br /></div><div style=\"text-align: left;\"><b>마무리</b></div><div style=\"text-align: left;\">W&amp;B는 루카스 비왈드(Lukas Biewald)가 2017년 설립한 딥러닝 모델 학습 서비스를 제공하는 스타트업이다. 이 회사는 딥러닝 개발자에 필요한 실무적인 도구를 개발한다. 그는 딥러닝 연구 초창기부터 머신러닝 연구자 및 개발자로 있으면서, 실무자의 어려움을 알고 있었다.&nbsp;</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhfNIluClhuvx4uCwa1PDhLx9ghmMz-NjV8PPaKFT89Najd_lP5N2m-NWLbOToxej3ku-qGu293r1yux9kkhW91g38yIvzaLIbJZssa3IZzC3Sy01_fzoouhFubujYUza_kon9Jg064O8IeFvLu39n6egiptc8tbhGGjZxmrQ5YAoPfu7z-2KZvHZE1XSsC\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"174\" data-original-width=\"431\" height=\"113\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhfNIluClhuvx4uCwa1PDhLx9ghmMz-NjV8PPaKFT89Najd_lP5N2m-NWLbOToxej3ku-qGu293r1yux9kkhW91g38yIvzaLIbJZssa3IZzC3Sy01_fzoouhFubujYUza_kon9Jg064O8IeFvLu39n6egiptc8tbhGGjZxmrQ5YAoPfu7z-2KZvHZE1XSsC=w280-h113\" width=\"280\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><span style=\"text-align: left;\">Lukas Biewald (2018)</span></div><br /></div><div style=\"text-align: left;\">OpenAI는 W&amp;B의 첫번째 고객이다. 이 도구는 머신러닝 개발자의 많은 수작업 프로세스를 자동화하여, 모델 학습 과정을 모니터링, 추적하고, 직관적인 학습 모델 디버깅, 검사 및 설명이 가능하도록 하여, 체계적으로 이 과정을 관리한다. 이 회사는 현재 700,000명 이상의 유료 사용자를 보유하고 있으며, 대부분, OpenAI와 같이 빅테크 기업들 개발자이 사용자이다.&nbsp;</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgsFnWMhIr_lTqrAA0haBaRCsTOS6xxmQfEGYYj6jC4QkKJwaJE5mAGr2Ty4ZWaaoqFbRSV8g985BoAb2aXUCl8rTU5TUiLrDUSF4uR0_jxPQYsn2ZiHZHfGoEE9f-I9H_RMgPB2-Hqi3qJ6FnIP7obqnPPDAxVtdLu1-gBuN5-Z21zlvYfdw2td98sZmFo\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"1039\" data-original-width=\"1200\" height=\"240\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgsFnWMhIr_lTqrAA0haBaRCsTOS6xxmQfEGYYj6jC4QkKJwaJE5mAGr2Ty4ZWaaoqFbRSV8g985BoAb2aXUCl8rTU5TUiLrDUSF4uR0_jxPQYsn2ZiHZHfGoEE9f-I9H_RMgPB2-Hqi3qJ6FnIP7obqnPPDAxVtdLu1-gBuN5-Z21zlvYfdw2td98sZmFo\" width=\"277\" /></a></div></div><div class=\"separator\" style=\"clear: both; text-align: center;\">W&amp;B 창업자 루카드 비왈드 및 핵심 파트너(<a href=\"https://www.bizjournals.com/sanfrancisco/inno/stories/fundings/2023/08/09/san-francisco-ai-observability-startup-raises-50m.html\" style=\"text-align: left;\">San Francisco responsible AI startup Weights &amp; Biases raises $50M - San Francisco Business Times</a>.&nbsp;<a href=\"https://techcrunch.com/2018/05/31/weights-biases-raises-5m-to-build-development-tools-for-machine-learning/\" style=\"text-align: left;\">Weights &amp; Biases raises $5M to build development tools for machine learning</a>)</div><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div></div><div style=\"text-align: left;\">이 회사는 현재까지 $250M 펀딩 투자받았다. 이 금액은 원화로 3,500억(환율 1400원 기준)에 해당한다. 현재 W&amp;B는 핵심기술을 개발하며, 기업공개를 준비하고 있다.</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEioHJn1YfJFNPs7FXraDQ_vgsVoKe3pqQECyhSLQI1SV_Apmbi7dB5Ph6fMhdjw08IxE2gYtmr9q33OGkCPC5lRxfnDTQiSCTS-Iy0FxUjBCHWWcPZYBSwOwwFMV36cBN5JblG2sehJwJ8gQLIoVql5Li_de-Yy4umb_kCCtNJ6q3jrNHVJASZRZZWniBUQ\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"890\" data-original-width=\"992\" height=\"358\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEioHJn1YfJFNPs7FXraDQ_vgsVoKe3pqQECyhSLQI1SV_Apmbi7dB5Ph6fMhdjw08IxE2gYtmr9q33OGkCPC5lRxfnDTQiSCTS-Iy0FxUjBCHWWcPZYBSwOwwFMV36cBN5JblG2sehJwJ8gQLIoVql5Li_de-Yy4umb_kCCtNJ6q3jrNHVJASZRZZWniBUQ=w400-h358\" width=\"400\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://www.crunchbase.com/organization/weights-biases/company_financials\">Weights &amp; Biases - Funding, Financials, Valuation</a></div><br /></div><div style=\"text-align: left;\"><b>부록: 딥러닝 모델의 해 탐색 과정 탐색 과정 가시화 원리</b></div><div style=\"text-align: left;\">여기서 딥러닝 모델의 해 탐색 과정을 가시화하는 원리를 간략히 살펴보자. 딥러닝 모델은 빅 데이터를 통계적 학습하여, y에 가장 가까운&nbsp;ŷ = w·x + b 를 탐색하는 과정이다. 그러므로, 가장 loss = y - ŷ가 작은 weight w, bais b를 찾는 것이 목적이다. 그러므로, 제대로 해를 탐색하는 지 확인하려면, epoch당 loss와 w:b 차트를 확인하는 것이 중요하다.&nbsp;</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">모델을 구성하는 레이어 유닛이 여러개라면, w:b도 여기에 비례해 많으므로, 원리만 살펴보기 위해, 매우 간단한 ŷ = w·x + b 수식을 학습하는 단순한 딥러닝 모델을 학습한다고 가정한다.</div><div style=\"text-align: left;\"><span style=\"font-size: x-small;\"><br /></span></div><div style=\"text-align: left;\"><div><span style=\"font-size: x-small;\"># 데이터 생성</span></div><div><span style=\"font-size: x-small;\">import numpy as np</span></div><div><span style=\"font-size: x-small;\">import matplotlib.pyplot as plt</span></div><div><span style=\"font-size: x-small;\"><br /></span></div><div><span style=\"font-size: x-small;\">np.random.seed(20240215)</span></div><div><span style=\"font-size: x-small;\">n = 50</span></div><div><span style=\"font-size: x-small;\">x = np.array(np.random.randn(n), dtype=np.float32)</span></div><div><span style=\"font-size: x-small;\">y = np.array(</span></div><div><span style=\"font-size: x-small;\">&nbsp; 0.75 * x**2 + 1.0 * x + 2.0 + 0.3 * np.random.randn(n),</span></div><div><span style=\"font-size: x-small;\">&nbsp; dtype=np.float32) # 데이터 임의로 생성할 수식</span></div><div><span style=\"font-size: x-small;\"><br /></span></div><div><span style=\"font-size: x-small;\">plt.scatter(x, y, facecolors='none', edgecolors='b')</span></div><div><span style=\"font-size: x-small;\">plt.scatter(x, y, c='r')</span></div><div><span style=\"font-size: x-small;\">plt.show()</span></div><div><span style=\"font-size: x-small;\"><br /></span></div><div><span style=\"font-size: x-small;\"># 데이터 학습 모델 준비</span></div><div><span style=\"font-size: x-small;\">import torch</span></div><div><span style=\"font-size: x-small;\"><br /></span></div><div><span style=\"font-size: x-small;\">model = torch.nn.Linear(1, 1)</span></div><div><span style=\"font-size: x-small;\">model.weight.data.fill_(6.0)</span></div><div><span style=\"font-size: x-small;\">model.bias.data.fill_(-3.0)</span></div><div><span style=\"font-size: x-small;\"><br /></span></div><div><span style=\"font-size: x-small;\"># 손실 함수 준비</span></div><div><span style=\"font-size: x-small;\">loss_fn = torch.nn.MSELoss()</span></div><div><span style=\"font-size: x-small;\">learning_rate = 0.1</span></div><div><span style=\"font-size: x-small;\">epochs = 100</span></div><div><span style=\"font-size: x-small;\">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)</span></div><div><span style=\"font-size: x-small;\"><br /></span></div><div><span style=\"font-size: x-small;\"># 학습</span></div><div><span style=\"font-size: x-small;\">models = [[model.weight.item(), model.bias.item()]]</span></div><div><span style=\"font-size: x-small;\">for epoch in range(epochs):</span></div><div><span style=\"font-size: x-small;\">&nbsp; inputs = torch.from_numpy(x).requires_grad_().reshape(-1, 1)</span></div><div><span style=\"font-size: x-small;\">&nbsp; labels = torch.from_numpy(y).reshape(-1, 1)</span></div><div><span style=\"font-size: x-small;\"><br /></span></div><div><span style=\"font-size: x-small;\">&nbsp; optimizer.zero_grad()</span></div><div><span style=\"font-size: x-small;\">&nbsp; outputs = model(inputs)</span></div><div><span style=\"font-size: x-small;\">&nbsp; loss = loss_fn(outputs, labels)</span></div><div><span style=\"font-size: x-small;\">&nbsp; loss.backward()</span></div><div><span style=\"font-size: x-small;\">&nbsp; optimizer.step()</span></div><div><span style=\"font-size: x-small;\">&nbsp; print('epoch {}, loss {}'.format(epoch, loss.item()))</span></div><div><span style=\"font-size: x-small;\">&nbsp; models.append([model.weight.item(), model.bias.item()])</span></div><div><span style=\"font-size: x-small;\"><br /></span></div><div><span style=\"font-size: x-small;\"># 모델 예측 값 비교 출력</span></div><div><span style=\"font-size: x-small;\">weight = model.weight.item()</span></div><div><span style=\"font-size: x-small;\">bias = model.bias.item()</span></div><div><span style=\"font-size: x-small;\">plt.scatter(x, y, facecolors='none', edgecolors='b')</span></div><div><span style=\"font-size: x-small;\">plt.plot(</span></div><div><span style=\"font-size: x-small;\">&nbsp; [x.min(), x.max()],</span></div><div><span style=\"font-size: x-small;\">&nbsp; [weight * x.min() + bias, weight * x.max() + bias],</span></div><div><span style=\"font-size: x-small;\">&nbsp; c='r')</span></div><div><span style=\"font-size: x-small;\">plt.show()</span></div><div><span style=\"font-size: x-small;\"><br /></span></div><div><span style=\"font-size: x-small;\"># loss map 작성</span></div><div><span style=\"font-size: x-small;\">def get_loss_map(loss_fn, x, y):</span></div><div><span style=\"font-size: x-small;\">&nbsp; \"\"\"Maps the loss function on a 100-by-100 grid between (-5, -5) and (8, 8).\"\"\"</span></div><div><span style=\"font-size: x-small;\">&nbsp; losses = [[0.0] * 101 for _ in range(101)]</span></div><div><span style=\"font-size: x-small;\">&nbsp; x = torch.from_numpy(x)</span></div><div><span style=\"font-size: x-small;\">&nbsp; y = torch.from_numpy(y)</span></div><div><span style=\"font-size: x-small;\">&nbsp; for wi in range(101):</span></div><div><span style=\"font-size: x-small;\">&nbsp; &nbsp; for wb in range(101):</span></div><div><span style=\"font-size: x-small;\">&nbsp; &nbsp; &nbsp; w = -5.0 + 13.0 * wi / 100.0</span></div><div><span style=\"font-size: x-small;\">&nbsp; &nbsp; &nbsp; b = -5.0 + 13.0 * wb / 100.0</span></div><div><span style=\"font-size: x-small;\">&nbsp; &nbsp; &nbsp; ywb = x * w + b</span></div><div><span style=\"font-size: x-small;\">&nbsp; &nbsp; &nbsp; losses[wi][wb] = loss_fn(ywb, y).item()</span></div><div><span style=\"font-size: x-small;\"><br /></span></div><div><span style=\"font-size: x-small;\">&nbsp; return list(reversed(losses))&nbsp; # Because y will be reversed.</span></div><div><span style=\"font-size: x-small;\"><br /></span></div><div><span style=\"font-size: x-small;\"># w:b 2차원 loss map 상 해 탐색 path 가시화&nbsp;</span></div><div><span style=\"font-size: x-small;\">import pylab</span></div><div><span style=\"font-size: x-small;\"><br /></span></div><div><span style=\"font-size: x-small;\">loss_fn = torch.nn.MSELoss()</span></div><div><span style=\"font-size: x-small;\">losses = get_loss_map(loss_fn, x, y)</span></div><div><span style=\"font-size: x-small;\">cm = pylab.get_cmap('terrain')</span></div><div><span style=\"font-size: x-small;\">fig, ax = plt.subplots()</span></div><div><span style=\"font-size: x-small;\">plt.xlabel('Bias')</span></div><div><span style=\"font-size: x-small;\">plt.ylabel('Weight')</span></div><div><span style=\"font-size: x-small;\">i = ax.imshow(losses, cmap=cm, interpolation='nearest', extent=[-5, 8, -5, 8])</span></div><div><span style=\"font-size: x-small;\"><br /></span></div><div><span style=\"font-size: x-small;\">model_weights, model_biases = zip(*models)</span></div><div><span style=\"font-size: x-small;\">ax.scatter(model_biases, model_weights, c='r', marker='+')</span></div><div><span style=\"font-size: x-small;\">ax.plot(model_biases, model_weights, c='r')</span></div><div><span style=\"font-size: x-small;\"><br /></span></div><div><span style=\"font-size: x-small;\">fig.colorbar(i)</span></div><div><span style=\"font-size: x-small;\">plt.show()</span></div><div><span style=\"font-size: x-small;\"><br /></span></div><div>결과는 다음과 같다.&nbsp;</div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjWSWh4nIMWmP2l7Ax4ORoC4mG_yUleJYMyBppC3RuCeUCr7y-CJnYRrhl53p8bXlyTA7CDVUzIGQmgGgTI0FSOdsZtujHsYSCrETRfev1_oT6pjW2oNbknjuH9Qte6hww8eAkBxqGY94Ot8Eq0vplqigY2ip73o75WwdtVsFaSawAfOCx39vNMMSRmpzgL\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"693\" data-original-width=\"828\" height=\"240\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjWSWh4nIMWmP2l7Ax4ORoC4mG_yUleJYMyBppC3RuCeUCr7y-CJnYRrhl53p8bXlyTA7CDVUzIGQmgGgTI0FSOdsZtujHsYSCrETRfev1_oT6pjW2oNbknjuH9Qte6hww8eAkBxqGY94Ot8Eq0vplqigY2ip73o75WwdtVsFaSawAfOCx39vNMMSRmpzgL\" width=\"287\" /></a></div></div></div><div style=\"text-align: left;\">loss함수를 바꿔가며, 해가 어떻게 탐색되는 지 확인해 보면, 다음과 같다. 데이터 특성에 따라 적절한 전략을 써야 한다는 것을 알 수 있다.&nbsp;</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgxXZ3UN76RCcrA2QSTNHvcWCAOLTS1kIWTTX4tvN8XcgBZdYiZVI4uomOvRkFptC-Aqocr_99ZVAf8CaVzoe6HAI6LCQ4JcACZxy8Io3LmDm3SbUzg-kmk3VnOwIJuGUuFjln0CgM7dr0OylFKOUdYtaA24iEl5KA4KpW7YFuy_vVA0iFduliVS_R2c_mc\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"721\" data-original-width=\"828\" height=\"348\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgxXZ3UN76RCcrA2QSTNHvcWCAOLTS1kIWTTX4tvN8XcgBZdYiZVI4uomOvRkFptC-Aqocr_99ZVAf8CaVzoe6HAI6LCQ4JcACZxy8Io3LmDm3SbUzg-kmk3VnOwIJuGUuFjln0CgM7dr0OylFKOUdYtaA24iEl5KA4KpW7YFuy_vVA0iFduliVS_R2c_mc=w400-h348\" width=\"400\" /></a></div>이 경우에는 w, b 인 2차원이라 시각화가 쉬웠으나, 3차원 이상이면, 다른 가시화 방법을 사용해야 한다.&nbsp;</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b>레퍼런스</b></div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><a href=\"https://theaisummer.com/weights-and-biases-tutorial/\">A complete Weights and Biases tutorial | AI Summer (theaisummer.com)</a></li><li><a href=\"https://towardsdatascience.com/visualizing-gradient-descent-parameters-in-torch-332a63d1e5c5\">Visualizing Gradient Descent Parameters in Torch | by P.G. Baumstarck | Towards Data Science</a></li><li><a href=\"https://www.geeksforgeeks.org/what-is-automl-in-machine-learning/\">What is AutoML in Machine Learning? - GeeksforGeeks</a></li><li><a href=\"https://cruizbran.medium.com/auto-ml-49f065978c78\">Auto ML. The options | by Ignacio Ruiz | Medium</a></li></ul></div>",
        "contentSnippet": "딥러닝 모델들을 개발하다 보면, 수많은 종류의 데이터셋, 하이퍼모델 파라메터 튜닝 등으로 인해 관리해야 할 자료들이 매우 복잡해진다는 것을 알게 된다. Weights & Biases (W&B) 회사는 이름 그대로 완벽한 모델 학습을 위해 필요한 Weights & Biases를 모니터링, 관리할 수 있는 로그 도구이다. 즉, 딥러닝 모델 개발자를 위한 프로세스 로그 및 가시화 플랫폼을 제공한다. \n\n\nW&B(AI Summer)\n\n매우 직관적인 이름을 가진 이 스타트업은 Tensorboard와 유사하지만, 적은 코드로 모델 개발에 많은 통찰력을 준다. 이 W&B(WandB) 라이브러리를 사용하면, 딥러닝 모델 학습 시 지저분하게 붙어 나가는 로그 처리를 매우 간단한 함수 몇 개로 처리할 수 있다. 통합된 데시보드 형태로 다양한 모델 학습 품질 지표를 확인 및 비교할 수 있다. 이외, 학습 모델 하이퍼 파라메터 관리와 튜닝 및 비교 보고서 생성 기능을 제공한다. 로그는 숫자, 텍스트, 이미지 등 다양한 포맷을 지원한다. \n\n\nW&B 딥러닝 모델 개발 프로세스 가시화 데쉬보드\n\n\n이 글은 딥러닝 모델 학습 로그, 가시화만 집중해 살펴본다. 글 마무리에 W&B의 개발 배경도 간단히 알아본다.  \n\n\n사용법\n다음 링크 방문해 회원 가입한다. \n\n\nwandb.ai website\n\n\n회원 가입하고, 다음 그림과 같이 홈 메뉴에서 키 토큰 값을 얻어 복사한다. 이 키는 wandb API를 사용할 때 필요하다.\n\n\n\n\n\n\n\n터미널에서 다음을 실행해 설치한다. \npip install wandb\n\n\n예시 및 결과\n다음과 같이 cosine 데이터를 학습하는 간단한 코드를 만들어 본다. W&B로 로그를 기록하도록 몇몇 함수를 호출할 것이다. 앞에서 얻은 키 토큰은 다음 코드에 해당 부분에 입력해 준다.\n\n\nimport os\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport wandb\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchviz import make_dot\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n\nclass SimpleMLP(nn.Module):\n\tdef __init__(self):\n\t\tsuper(SimpleMLP, self).__init__()\n\t\tself.fc1 = nn.Linear(1, 50)\n\t\tself.fc2 = nn.Linear(50, 1)\n\n\n\tdef forward(self, x):\n\t\tx = torch.relu(self.fc1(x))\n\t\tx = self.fc2(x)\n\t\treturn x\n\n\n# Generate cosine dataset\ndef generate_cosine_data(num_samples=100):\n\tx = torch.linspace(-2 * torch.pi, 2 * torch.pi, num_samples).view(-1, 1)\n\ty = torch.cos(x)\n\treturn x, y\n\n\n# Instantiate the model, loss function, and optimizer\nmodel = SimpleMLP()\nmodel.to(device)\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\n\nwandb.login(key='') # 여기에 키값 입력\napi = wandb.Api()\n\t\nwandb.init(project=\"train_cosin\", \n\tconfig={\n\t\t\"optimizer\": \"SGD\",\n\t\t\"learning_rate\": 0.01,\n\t\t\"architecture\": \"SimpleMLP\",\n\t\t\"dataset\": \"cosine\"\t\t\n\t})\nwandb.watch(model, criterion, log=\"all\")  # 모든 지표 기록\n\n\n# 학습 데이터 생성\nx, y = generate_cosine_data()\nx, y = x.to(device), y.to(device)\n\n\n# 학습\nprediction = None\nnum_epochs = 10000\nimage_files = []\nfor epoch in tqdm(range(num_epochs)):\n\t# Forward pass\n\toutputs = model(x)\n\tprediction = outputs\n\tloss = criterion(outputs, y)\n\tprint(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n\n\n\t# Backward pass and optimization\n\toptimizer.zero_grad()\n\tloss.backward()\n\toptimizer.step()\n\t\n\t# Visualize the gradients of the first epoch using wandb\n\tlayer_name = ''\n\tgrad_cpu = data_cpu = None\n\tfor name, param in model.named_parameters():\n\t\tif param.requires_grad and param.grad is not None:\n\t\t\tlayer_name = name\n\t\t\tgrad_cpu = param.grad.detach().cpu()\n\t\t\tdata_cpu = param.data.detach().cpu()\n\t\t\tbreak\n\n\n\tlog_data = {\"epoch\": epoch, \"loss\": loss.item(), \"outputs\": outputs.detach().cpu().numpy(), \n\t\t\t\tf'{layer_name}_gradients': wandb.Histogram(grad_cpu), \n\t\t\t\tf'{layer_name}_weights': wandb.Histogram(data_cpu)}\n\twandb.log(log_data) # 에폭, 로스, 출력, 기울기, 가중치 로그 기록\n\n\n학습된 결과는 다음과 같다. 잘 학습된 것을 알 수 있다.\n\n\n\nW&B 웹사이트 나의 프로젝트의 데쉬보드를 확인한다. \n\n\n\n\n데쉬보드에서는 각 단계 별 기울기, 가중치, 로스 등이 어떻게 변화하는 지를 손쉽게 확인할 수 있다. \n\n\n각 차트 데이터는 엑셀 등 포맷으로 저장 가능하다. \n\n\n로짓 출력값을 확인해 보자. 초기 에폭에서는 학습되지 않은 임의 값을 출력하지만, 학습될 수록 y에 근사한 패턴으로 출력되는 것을 확인할 수 있다.\n\n\n엑셀 출력된 데이터를 보면, cosine 패턴으로 수렴한 예측값이 점차 많아지는 것을 확인할 수 있다. \n\n\n\n다음 경우는 모델의 바이어스 히스토그램 차트 데이터를 보여준다. \n\n\n\n\n엑셀로 다운로드하면, 모델 학습 데이터의 특정 범위에 속한 값의 누적 데이터를 쉽게 확인할 수 있다.\n\n\n\n다음과 같이 리포트 기능을 사용해, 모델 학습 품질을 검토할 수 있다.\n\n\n\n마무리\nW&B는 루카스 비왈드(Lukas Biewald)가 2017년 설립한 딥러닝 모델 학습 서비스를 제공하는 스타트업이다. 이 회사는 딥러닝 개발자에 필요한 실무적인 도구를 개발한다. 그는 딥러닝 연구 초창기부터 머신러닝 연구자 및 개발자로 있으면서, 실무자의 어려움을 알고 있었다. \n\n\nLukas Biewald (2018)\n\nOpenAI는 W&B의 첫번째 고객이다. 이 도구는 머신러닝 개발자의 많은 수작업 프로세스를 자동화하여, 모델 학습 과정을 모니터링, 추적하고, 직관적인 학습 모델 디버깅, 검사 및 설명이 가능하도록 하여, 체계적으로 이 과정을 관리한다. 이 회사는 현재 700,000명 이상의 유료 사용자를 보유하고 있으며, 대부분, OpenAI와 같이 빅테크 기업들 개발자이 사용자이다. \n\n\n\nW&B 창업자 루카드 비왈드 및 핵심 파트너(San Francisco responsible AI startup Weights & Biases raises $50M - San Francisco Business Times. Weights & Biases raises $5M to build development tools for machine learning)\n\n\n이 회사는 현재까지 $250M 펀딩 투자받았다. 이 금액은 원화로 3,500억(환율 1400원 기준)에 해당한다. 현재 W&B는 핵심기술을 개발하며, 기업공개를 준비하고 있다.\n\n\nWeights & Biases - Funding, Financials, Valuation\n\n부록: 딥러닝 모델의 해 탐색 과정 탐색 과정 가시화 원리\n여기서 딥러닝 모델의 해 탐색 과정을 가시화하는 원리를 간략히 살펴보자. 딥러닝 모델은 빅 데이터를 통계적 학습하여, y에 가장 가까운 ŷ = w·x + b 를 탐색하는 과정이다. 그러므로, 가장 loss = y - ŷ가 작은 weight w, bais b를 찾는 것이 목적이다. 그러므로, 제대로 해를 탐색하는 지 확인하려면, epoch당 loss와 w:b 차트를 확인하는 것이 중요하다. \n\n\n모델을 구성하는 레이어 유닛이 여러개라면, w:b도 여기에 비례해 많으므로, 원리만 살펴보기 위해, 매우 간단한 ŷ = w·x + b 수식을 학습하는 단순한 딥러닝 모델을 학습한다고 가정한다.\n\n\n\n# 데이터 생성\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nnp.random.seed(20240215)\nn = 50\nx = np.array(np.random.randn(n), dtype=np.float32)\ny = np.array(\n  0.75 * x**2 + 1.0 * x + 2.0 + 0.3 * np.random.randn(n),\n  dtype=np.float32) # 데이터 임의로 생성할 수식\n\n\nplt.scatter(x, y, facecolors='none', edgecolors='b')\nplt.scatter(x, y, c='r')\nplt.show()\n\n\n# 데이터 학습 모델 준비\nimport torch\n\n\nmodel = torch.nn.Linear(1, 1)\nmodel.weight.data.fill_(6.0)\nmodel.bias.data.fill_(-3.0)\n\n\n# 손실 함수 준비\nloss_fn = torch.nn.MSELoss()\nlearning_rate = 0.1\nepochs = 100\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\n\n# 학습\nmodels = [[model.weight.item(), model.bias.item()]]\nfor epoch in range(epochs):\n  inputs = torch.from_numpy(x).requires_grad_().reshape(-1, 1)\n  labels = torch.from_numpy(y).reshape(-1, 1)\n\n\n  optimizer.zero_grad()\n  outputs = model(inputs)\n  loss = loss_fn(outputs, labels)\n  loss.backward()\n  optimizer.step()\n  print('epoch {}, loss {}'.format(epoch, loss.item()))\n  models.append([model.weight.item(), model.bias.item()])\n\n\n# 모델 예측 값 비교 출력\nweight = model.weight.item()\nbias = model.bias.item()\nplt.scatter(x, y, facecolors='none', edgecolors='b')\nplt.plot(\n  [x.min(), x.max()],\n  [weight * x.min() + bias, weight * x.max() + bias],\n  c='r')\nplt.show()\n\n\n# loss map 작성\ndef get_loss_map(loss_fn, x, y):\n  \"\"\"Maps the loss function on a 100-by-100 grid between (-5, -5) and (8, 8).\"\"\"\n  losses = [[0.0] * 101 for _ in range(101)]\n  x = torch.from_numpy(x)\n  y = torch.from_numpy(y)\n  for wi in range(101):\n    for wb in range(101):\n      w = -5.0 + 13.0 * wi / 100.0\n      b = -5.0 + 13.0 * wb / 100.0\n      ywb = x * w + b\n      losses[wi][wb] = loss_fn(ywb, y).item()\n\n\n  return list(reversed(losses))  # Because y will be reversed.\n\n\n# w:b 2차원 loss map 상 해 탐색 path 가시화 \nimport pylab\n\n\nloss_fn = torch.nn.MSELoss()\nlosses = get_loss_map(loss_fn, x, y)\ncm = pylab.get_cmap('terrain')\nfig, ax = plt.subplots()\nplt.xlabel('Bias')\nplt.ylabel('Weight')\ni = ax.imshow(losses, cmap=cm, interpolation='nearest', extent=[-5, 8, -5, 8])\n\n\nmodel_weights, model_biases = zip(*models)\nax.scatter(model_biases, model_weights, c='r', marker='+')\nax.plot(model_biases, model_weights, c='r')\n\n\nfig.colorbar(i)\nplt.show()\n\n\n결과는 다음과 같다. \n\n\n\nloss함수를 바꿔가며, 해가 어떻게 탐색되는 지 확인해 보면, 다음과 같다. 데이터 특성에 따라 적절한 전략을 써야 한다는 것을 알 수 있다. \n\n\n이 경우에는 w, b 인 2차원이라 시각화가 쉬웠으나, 3차원 이상이면, 다른 가시화 방법을 사용해야 한다. \n\n\n레퍼런스\n\nA complete Weights and Biases tutorial | AI Summer (theaisummer.com)\nVisualizing Gradient Descent Parameters in Torch | by P.G. Baumstarck | Towards Data Science\nWhat is AutoML in Machine Learning? - GeeksforGeeks\nAuto ML. The options | by Ignacio Ruiz | Medium",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-5395180824671467701",
        "isoDate": "2024-06-21T07:49:00.000Z"
      },
      {
        "title": "도메인 모델 성능개선을 위한 Lora 기반 LLAMA3 모델 파인튜닝하기",
        "link": "http://daddynkidsmakers.blogspot.com/2024/06/lora-llama3.html",
        "pubDate": "2024-06-21T01:47:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">이 글은&nbsp;Lora 기반 LLAMA3 모델 파인튜닝하는 방법을 간략히 보여준다. 이를 통해, 특정 도메인의 LLM 모델 생성 정확도를 향상시킬 수 있다.</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEivO-JPv31asTFlMJ9hxAv_0n63icDloIzHGL81i5REKv4gsbyn76oMOTRCWBgQQvOO_gGs8SkOe1Nr1Mg-yYyPTa228TExPwnArl19qmm5Xhoyp2qIQNV5_2EEs9f7DbU2sNxcHkvMAis1hEy3vARody2nihhXZHv8J_ncm-SmjMFRHlJWnppTxqcDewnt\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"600\" data-original-width=\"1200\" height=\"160\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEivO-JPv31asTFlMJ9hxAv_0n63icDloIzHGL81i5REKv4gsbyn76oMOTRCWBgQQvOO_gGs8SkOe1Nr1Mg-yYyPTa228TExPwnArl19qmm5Xhoyp2qIQNV5_2EEs9f7DbU2sNxcHkvMAis1hEy3vARody2nihhXZHv8J_ncm-SmjMFRHlJWnppTxqcDewnt\" width=\"320\" /></a></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b><span style=\"font-size: medium;\">머리말</span></b></div><div style=\"text-align: left;\"><div>LLAMA3는 메타가 개발한 LLM 제품이다. 모델은 15조 개의 토큰으로 구성된 광범위한 데이터 세트에서 훈련되었다(라마 2의 경우 2T 토큰과 비교). 700억 개의 파라미터 모델과 더 작은 80억 개의 파라미터 모델의 두 가지 모델 크기가 출시되었다. 70B 모델은 MMLU 벤치마크에서 82점, HumanEval 벤치마크에서 81.7점을 기록하며 이미 인상적인 성능을 보여주었다.</div><div><br /></div><div>라마 3 모델은 컨텍스트 길이를 최대 8,192개 토큰(라마 2의 경우 4,096개 토큰)까지 늘렸으며, RoPE를 통해 최대 32k까지 확장할 수 있다. 또한 이 모델은 128K 토큰 어휘가 있는 새로운 토크나이저를 사용하여 텍스트를 인코딩하는 데 필요한 토큰 수를 15% 줄이다.&nbsp;</div><div><br /></div><div><b><span style=\"font-size: medium;\">파인튜닝 개념</span></b></div><div>파인튜닝(fine turning. 미세 조정)전략은 활용된 데이터에 따라 달라지며, 이는 네 가지 유형으로 분류할 수 있다.</div><div><ul style=\"text-align: left;\"><li>감독 미세 조정</li><li>퓨샷 학습(Few-shot Learning)</li><li>전체 전이 학습</li><li>도메인별 미세 조정</li><li>감독 미세 조정</li></ul></div><div>이 방법은 미세 조정에 대한 표준 접근 방식을 나타낸다. 모델은 텍스트 분류, 질문 답변 또는 명명된 엔터티 인식과 같이 수행하려는 특정 작업에 맞게 조정된 레이블이 지정된 데이터 세트를 사용하여 추가 학습을 거친다. 예를 들어 감정 분석에서 모델은 해당 감정으로 주석이 달린 텍스트 샘플로 구성된 데이터 세트에서 학습된다.</div><div><br /></div><div><b>퓨샷 학습(Few-Shot Learning)</b></div><div>레이블이 지정된 대규모 데이터 세트를 어셈블하는 것이 비현실적인 것으로 판명된 시나리오에서는 솔루션을 제공하기 위해 몇 가지 학습 단계가 개입한다. 이 기술은 입력 프롬프트를 시작할 때 원하는 작업에 대한 몇 가지 <a href=\"https://medium.com/thedeephub/a-practical-guide-for-rag-and-few-shot-prompting-in-langchain-0b0e18dc9df5\">예제</a>(또는 샷)를 모델에 제공한다. 이렇게 함으로써 모델은 철저한 미세 조정 요법 없이 작업에 대한 더 나은 컨텍스트 이해를 얻을 수 있다.</div><div><br /></div></div></div><blockquote style=\"border: none; margin: 0px 0px 0px 40px; padding: 0px; text-align: left;\"><div style=\"text-align: left;\"><div style=\"text-align: left;\"><div><div><span style=\"font-size: x-small;\">few_shot_examples = [</span></div></div></div></div><div style=\"text-align: left;\"><div style=\"text-align: left;\"><div><div><span style=\"font-size: x-small;\">{\"input\":\"Could you please clarify the terms outlined in section 3.2 of the contract?\",</span></div></div></div></div><div style=\"text-align: left;\"><div style=\"text-align: left;\"><div><div><span style=\"font-size: x-small;\">\"output\":\"Certainly, I will provide clarification on the terms in section 3.2.\"},</span></div></div></div></div><div style=\"text-align: left;\"><div style=\"text-align: left;\"><div><div><span style=\"font-size: x-small;\">{\"input\":\"We are interested in extending the payment deadline to 30 days instead of the current 15 days. Additionally, we would like to add a clause regarding late payment penalties.\",</span></div></div></div></div><div style=\"text-align: left;\"><div style=\"text-align: left;\"><div><div><span style=\"font-size: x-small;\">\"output\":\"Our request is to extend the payment deadline to 30 days and include a clause on late payment penalties.\"},</span></div></div></div></div><div style=\"text-align: left;\"><div style=\"text-align: left;\"><div><div><span style=\"font-size: x-small;\">{\"input\":\"\"\"The current indemnification clause seems too broad. We would like to narrow it down to cover only direct damages and exclude consequential damages.</span></div></div></div></div><div style=\"text-align: left;\"><div style=\"text-align: left;\"><div><div><span style=\"font-size: x-small;\">Additionally, we propose including a dispute resolution clause specifying arbitration as the preferred method of resolving disputes.\"\"\",</span></div></div></div></div><div style=\"text-align: left;\"><div style=\"text-align: left;\"><div><div><span style=\"font-size: x-small;\">\"output\":\"\"\"We suggest revising the indemnification clause to limit it to covering direct damages and excluding consequential damages.</span></div></div></div></div><div style=\"text-align: left;\"><div style=\"text-align: left;\"><div><div><span style=\"font-size: x-small;\">Furthermore, we recommend adding a dispute resolution clause that specifies arbitration as the preferred method of resolving disputes.\"\"\"},</span></div></div></div></div><div style=\"text-align: left;\"><div style=\"text-align: left;\"><div><div><span style=\"font-size: x-small;\">{\"input\":\"I believe the proposed changes are acceptable.\",</span></div></div></div></div><div style=\"text-align: left;\"><div style=\"text-align: left;\"><div><div><span style=\"font-size: x-small;\">\"output\":\"Thank you for your feedback. I will proceed with implementing the proposed changes.\"}</span></div></div></div></div><div style=\"text-align: left;\"><div style=\"text-align: left;\"><div><div><span style=\"font-size: x-small;\">]</span></div></div></div></div></blockquote><div style=\"text-align: left;\"><div style=\"text-align: left;\"><div><br /></div><div><b>전체 전이 학습</b></div><div>모든 미세 조정 방법에는 일종의 전이 학습이 포함되지만, 이 범주는 특히 모델이 원래 학습 목표와 다른 작업을 수행할 수 있도록 한다. 핵심은 광범위하고 일반적인 데이터 세트에서 모델이 축적한 지식을 활용하여 보다 전문적이거나 관련 작업에 적용하는 데 있다.</div><div><br /></div><div><b>도메인별 미세 조정</b></div><div>이 미세 조정 변형은 특정 도메인 또는 산업과 관련된 텍스트를 이해하고 생성하도록 모델을 적응시키는 것을 목표로 한다. 모델은 대상 도메인과 관련된 텍스트로 구성된 데이터 세트를 사용하여 미세 조정을 거치므로 도메인별 작업에 대한 컨텍스트 파악과 숙련도가 향상된다. 예를 들어, 의료 애플리케이션용 챗봇을 개발하기 위해 모델은 의료 기록에 대해 훈련되어 의료 영역 내에서 언어 이해 능력을 개선해야 한다.</div><div><br /></div><div>미세 조정 과정에서 업데이트되는 모델 가중치에 따라 두 가지 유형의 미세 조정이 있다.</div><div><br /></div><div><b>파라미터 효율 미세 조정(PEFT)</b></div><div>전체 미세 조정이라고 하는 이 포괄적인 미세 조정 방법에는 모든 모델 가중치를 업데이트하여 최적화된 버전을 만드는 작업이 포함된다. 그러나 사전 학습과 유사한 메모리 및 계산 리소스에 대한 상당한 요구 사항을 부과하므로 학습 중에 저장 및 처리를 관리하기 위한 강력한 인프라가 필요한다.</div><div><br /></div><div><b>파라미터 효율 미세 조정(PEFT)</b></div><div>매개 변수 효율적인 미세 조정 또는 간단히 <a href=\"https://www.datacamp.com/tutorial/llama3-fine-tuning-locally\">PEFT</a>는 명령 미세 조정 방법론에서 전체 미세 조정에 대한 보다 리소스 효율적인 대안을 나타낸다. 전체 LLM 미세 조정은 상당한 계산 오버헤드를 수반하여 메모리 할당에 문제를 제기하는 반면, PEFT는 매개변수의 하위 집합만 업데이트하고 나머지는 효과적으로 \"고정\"하는 솔루션을 제공한다. 이 접근 방식은 학습 가능한 매개 변수의 수를 줄여 메모리 요구 사항을 완화하고 치명적인 망각을 방지한다. 완전한 미세 조정과 달리 PEFT는 이전에 습득한 지식을 유지하면서 원래 LLM 가중치를 보존한다. 이 기능은 여러 작업을 미세 조정할 때 스토리지 제약 조건을 완화하는 데 유리한 것으로 입증되었다. LoRA(Low-Rank Adaptation) 및 QLoRA(Quantized Low-Rank Adaptation)와 같이 널리 채택된 기술은 파라미터 효율적인 미세 조정을 달성하기 위한 효과적인 방법을 보여준다.</div><div><br /></div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEh1xBGvzoSB-DvUMUFOseSfHViN1xtXuCZuL03N2Nb8is9B3ID-5uQpAtMjPd0PmaS6p_M7ikJcp_C3am5p6AnGoZHMY1xq0ZCCfKOEQRUQdHthMebvzR_25Jgltb9vrPQE2c4cFjmXlxvKLccTYpJv-iwA3P0iWZ1iCcgCzj5QDPWj7cBUPLNaXmbiA4e9\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"635\" data-original-width=\"1586\" height=\"160\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEh1xBGvzoSB-DvUMUFOseSfHViN1xtXuCZuL03N2Nb8is9B3ID-5uQpAtMjPd0PmaS6p_M7ikJcp_C3am5p6AnGoZHMY1xq0ZCCfKOEQRUQdHthMebvzR_25Jgltb9vrPQE2c4cFjmXlxvKLccTYpJv-iwA3P0iWZ1iCcgCzj5QDPWj7cBUPLNaXmbiA4e9=w400-h160\" width=\"400\" /></a></div><div><b>ReFT</b></div><div>언어 모델은 토큰 시퀀스의 상황에 맞는 표현을 생성해야 한다.&nbsp;</div><div><a href=\"https://medium.com/@syed_hasan/finetuning-llama-3-using-reft-representation-fine-tuning-technique-00f4fe1f497c\">ReFT</a>(표현 미세 조정)은 n개 입력 토큰 x = (x1, . . . , xn)의 시퀀스가 주어지면 모델은 먼저 이러한 토큰을 표현 목록에 포함한다. 그런 다음, 모델 계층은 은닉 표현의 j번째 리스트 h(j)를 이전 은닉 표현 리스트 h(j−1)의 함수로 연속적으로 계산한다. 각 은닉 표현은 벡터입니다. LM은 최종 은닉 표현을 사용하여 예측을 생성한다.</div><div><br /></div><div>PyReFT는 학습 개입을 통해 내부 언어모델 표현적응을 지원하는 표현 미세 조정(ReFT) 라이브러리이다. 적은 수의 미세 조정 매개변수와 강력한 성능을 통해 Pyreft는 미세 조정 효율성을 높이고 미세 조정 비용을 줄일 수 있다.</div></div><div><br /></div><div><b>LoRA 및 QLoRa</b></div><div>LoRA는 향상된 미세 조정 접근 방식으로, 사전 훈련된 대규모 언어 모델의 가중치 행렬에 근접한 두 개의 작은 행렬만 미세 조정하여 LoRA 어댑터를 형성함으로써 기존 방법에서 벗어난다. 그런 다음 이 미세 조정된 어댑터는 후속 추론 작업을 위해 미리 학습된 모델에 통합된다. 특정 작업 또는 사용 사례에 대한 LoRA 미세 조정이 완료되면 그 결과는 변경되지 않은 원본 LLM과 함께 훨씬 더 작은 \"LoRA 어댑터\"의 출현으로 이어지며, 이는 종종 원래 LLM 크기(GB가 아닌 MB로 측정됨)의 일부에 불과한다. 추론하는 동안 LoRA 어댑터는 원래 LLM과 융합되어야 한다. 이 접근 방식은 많은 LoRA 어댑터가 원래 LLM의 용도를 효과적으로 변경할 수 있으므로 여러 작업 및 사용 사례를 처리할 때 전체 메모리 요구 사항을 줄일 수 있다는 주요 이점을 제공한다.</div><div><br /></div><div>QLoRA는 LoRA에 비해 메모리 효율성이 더욱 향상되었음을 나타낸다. LoRA 어댑터의 가중치를 더 낮은 정밀도(일반적으로 원래 4비트 대신 8비트)로 양자화하여 LoRA 기술을 개선한다. 이 추가 최적화는 메모리 공간과 스토리지 오버헤드를 크게 줄이다. QLoRA에서 사전 훈련된 모델은 양자화된 4비트 가중치로 GPU 메모리에 로드되며, 이는 LoRA에서 사용되는 8비트 정밀도에서 벗어난다. 이러한 비트 정밀도 감소에도 불구하고 QLoRA는 이전 제품과 비슷한 수준의 효율성을 유지하여 성능 저하 없이 메모리 사용을 최적화하는 능력을 보여준다.</div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b><span style=\"font-size: medium;\">라마3 파인튜닝 모델 개발&nbsp;</span></b></div><div style=\"text-align: left;\"><b>개발 환경</b></div><div style=\"text-align: left;\">앞의 내용을 고려해, 라마3를 파인튜닝한다. 개발환경은 다음과 같다.</div><div style=\"text-align: left;\"><div><div>pip install -U transformers&nbsp;</div><div>pip install -U datasets&nbsp;</div><div>pip install -U accelerate&nbsp;</div><div>pip install -U peft&nbsp;</div><div>pip install -U trl&nbsp;</div><div>pip install -U bitsandbytes&nbsp;</div><div>pip install -U wandb</div></div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">저렴한 비용으로 학습 모델을 개발하기 위해, Lora, 양자화를 사용한다. 사전 학습모델은 허깅페이스(HF)에서 제공하는 LLAMA3-8B모델을 사용한다.&nbsp;</div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEiIRKarbfJMJAC07a2AqVryhdCBM0qBcpXmwk9T2SbC0fnvUABY-3JvegiZZNNBt61pzvReABWqlQrGP6xMdBSq67CNah5tjPPKxCYpWY_HeEZzcnZ_ckoCLcnYsJkjtpELXtr1Hti-7R5Uufl5Ig1eOTPlot5H9aY6RpmRB_B1sqjJYED4wJyre1ZXm5xU\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"958\" data-original-width=\"968\" height=\"240\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEiIRKarbfJMJAC07a2AqVryhdCBM0qBcpXmwk9T2SbC0fnvUABY-3JvegiZZNNBt61pzvReABWqlQrGP6xMdBSq67CNah5tjPPKxCYpWY_HeEZzcnZ_ckoCLcnYsJkjtpELXtr1Hti-7R5Uufl5Ig1eOTPlot5H9aY6RpmRB_B1sqjJYED4wJyre1ZXm5xU\" width=\"243\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://huggingface.co/Undi95/Meta-Llama-3-8B-hf/tree/main\">Meta-Llama-3-8B-hf at main (huggingface.co)</a></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">파인튜닝할 데이터는&nbsp;<a href=\"https://huggingface.co/datasets/ruslanmv/ai-medical-chatbot\">ruslanmv/ai-medical-chatbot · Datasets at Hugging Face</a>&nbsp;를 사용한다.&nbsp;</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgijKnkUoBzTd8S0lzed7MX60IfoielH-Z5F1tM8oydUwzi1WkWVa0rjOc_JE3htfrvcpCm8DqawnKdBLTMM2B_FdiANxL_vGGk_N8N5b62yEJ5g-pyrRYgjwwxV0wkkxhMZpl9M8-Tvt2kBtX-Fo02-rpbBXfMki_LvToIR0yZWEzptjL9NfsqiSUijUyK\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"914\" data-original-width=\"1811\" height=\"263\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgijKnkUoBzTd8S0lzed7MX60IfoielH-Z5F1tM8oydUwzi1WkWVa0rjOc_JE3htfrvcpCm8DqawnKdBLTMM2B_FdiANxL_vGGk_N8N5b62yEJ5g-pyrRYgjwwxV0wkkxhMZpl9M8-Tvt2kBtX-Fo02-rpbBXfMki_LvToIR0yZWEzptjL9NfsqiSUijUyK=w519-h263\" width=\"519\" /></a></div><br /></div><div style=\"text-align: left;\">구현 코드는 다음과 같다.</div><div style=\"text-align: left;\"># 파이썬 패키지 임포트</div><div style=\"text-align: left;\"><div>from transformers import (</div><div>&nbsp; &nbsp; AutoModelForCausalLM,</div><div>&nbsp; &nbsp; AutoTokenizer,</div><div>&nbsp; &nbsp; BitsAndBytesConfig,</div><div>&nbsp; &nbsp; HfArgumentParser,</div><div>&nbsp; &nbsp; TrainingArguments,</div><div>&nbsp; &nbsp; pipeline,</div><div>&nbsp; &nbsp; logging,</div><div>)</div><div>from peft import (</div><div>&nbsp; &nbsp; LoraConfig,</div><div>&nbsp; &nbsp; PeftModel,</div><div>&nbsp; &nbsp; prepare_model_for_kbit_training,</div><div>&nbsp; &nbsp; get_peft_model,</div><div>)</div><div>import os, torch, wandb</div><div>from datasets import load_dataset</div><div>from trl import SFTTrainer, setup_chat_format</div><div><br /></div><div># 허깅페이스및 W&amp;B 키 토큰 이용해 로그인. 미리 사전 발급받아야 함.</div><div>from huggingface_hub import login # https://www.kaggle.com/discussions/product-feedback/114053</div><div>login(token = 'input your HF token')&nbsp; # HF 키 토큰 입력</div><div><br /></div><div>wandb.login(key='input your WandB token')&nbsp; # W&amp;B 키 토큰 입력</div><div>run = wandb.init(</div><div>&nbsp; &nbsp; project='Fine-tune Llama 3 8B on Medical Dataset',&nbsp;</div><div>&nbsp; &nbsp; job_type=\"training\",&nbsp;</div><div>&nbsp; &nbsp; anonymous=\"allow\"</div><div>)</div><div><br /></div><div># 사전학습모델 설정</div><div>from transformers import AutoTokenizer, AutoModelForCausalLM</div><div><br /></div><div>base_model = \"Undi95/Meta-Llama-3-8B-hf\"&nbsp;</div><div>dataset_name = \"ruslanmv/ai-medical-chatbot\" # 사용할 데이터셋</div><div>new_model = \"llama-3-8b-chat-doctor\"&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;# 파인튜닝 모델 이름</div><div><br /></div><div>torch_dtype = torch.float16</div><div>attn_implementation = \"eager\"</div><div><br /></div><div># QLoRA 설정</div><div>bnb_config = BitsAndBytesConfig(</div><div>&nbsp; &nbsp; load_in_4bit=True, # 4bit 양자화</div><div>&nbsp; &nbsp; bnb_4bit_quant_type=\"nf4\",</div><div>&nbsp; &nbsp; bnb_4bit_compute_dtype=torch_dtype,</div><div>&nbsp; &nbsp; bnb_4bit_use_double_quant=True,</div><div>)</div><div><br /></div><div>model = AutoModelForCausalLM.from_pretrained(</div><div>&nbsp; &nbsp; base_model,</div><div>&nbsp; &nbsp; quantization_config=bnb_config,</div><div>&nbsp; &nbsp; device_map=\"auto\",</div><div>&nbsp; &nbsp; attn_implementation=attn_implementation</div><div>)</div><div><br /></div><div># 토크나이저 및 모델 로딩</div><div><div>tokenizer = AutoTokenizer.from_pretrained(base_model)</div><div>model, tokenizer = setup_chat_format(model, tokenizer)</div></div><div><br /></div><div># Lora 설정</div><div>peft_config = LoraConfig(</div><div>&nbsp; &nbsp; r=16,</div><div>&nbsp; &nbsp; lora_alpha=32,</div><div>&nbsp; &nbsp; lora_dropout=0.05,</div><div>&nbsp; &nbsp; bias=\"none\",</div><div>&nbsp; &nbsp; task_type=\"CAUSAL_LM\",</div><div>&nbsp; &nbsp; target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']</div><div>)</div><div>model = get_peft_model(model, peft_config)&nbsp; # 파라메터 튜닝 설정</div><div><br /></div><div># 데이터셋 로딩</div><div>dataset = load_dataset(dataset_name, split=\"all\")</div><div>dataset = dataset.shuffle(seed=65).select(range(1000)) # 파인튜닝 예시 위해 1000개만 사용</div><div><br /></div><div>def format_chat_template(row):</div><div>&nbsp; &nbsp; row_json = [{\"role\": \"user\", \"content\": row[\"Patient\"]},</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;{\"role\": \"assistant\", \"content\": row[\"Doctor\"]}]</div><div>&nbsp; &nbsp; row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)</div><div>&nbsp; &nbsp; return row</div><div><br /></div><div>dataset = dataset.map(</div><div>&nbsp; &nbsp; format_chat_template,</div><div>&nbsp; &nbsp; num_proc=4,</div><div>)</div><div><br /></div><div>print(dataset['text'][3])</div><div><br /></div><div><div>dataset = dataset.train_test_split(test_size=0.1) # 데이터 검증 세트 분할</div></div><div><br /></div><div># 모델 하이퍼파라메터 설정. 참고.&nbsp;<a href=\"https://www.datacamp.com/tutorial/fine-tuning-llama-2\">Fine-Tuning LLaMA 2: A Step-by-Step Guide to Customizing the Large Language Model | DataCamp</a></div><div>training_arguments = TrainingArguments(</div><div>&nbsp; &nbsp; output_dir=new_model,</div><div>&nbsp; &nbsp; per_device_train_batch_size=1,</div><div>&nbsp; &nbsp; per_device_eval_batch_size=1,</div><div>&nbsp; &nbsp; gradient_accumulation_steps=2,</div><div>&nbsp; &nbsp; optim=\"paged_adamw_32bit\",</div><div>&nbsp; &nbsp; num_train_epochs=1,</div><div>&nbsp; &nbsp; evaluation_strategy=\"steps\",</div><div>&nbsp; &nbsp; eval_steps=0.2,</div><div>&nbsp; &nbsp; logging_steps=1,</div><div>&nbsp; &nbsp; warmup_steps=10,</div><div>&nbsp; &nbsp; logging_strategy=\"steps\",</div><div>&nbsp; &nbsp; learning_rate=2e-4,</div><div>&nbsp; &nbsp; fp16=False,</div><div>&nbsp; &nbsp; bf16=False,</div><div>&nbsp; &nbsp; group_by_length=True,</div><div>&nbsp; &nbsp; report_to=\"wandb\"</div><div>)</div><div><br /></div><div># 지도미세조정(SFT) 설정</div><div>trainer = SFTTrainer(</div><div>&nbsp; &nbsp; model=model,</div><div>&nbsp; &nbsp; train_dataset=dataset[\"train\"],</div><div>&nbsp; &nbsp; eval_dataset=dataset[\"test\"],</div><div>&nbsp; &nbsp; peft_config=peft_config,</div><div>&nbsp; &nbsp; max_seq_length=512,</div><div>&nbsp; &nbsp; dataset_text_field=\"text\",</div><div>&nbsp; &nbsp; tokenizer=tokenizer,</div><div>&nbsp; &nbsp; args=training_arguments,</div><div>&nbsp; &nbsp; packing= False,</div><div>)</div><div><br /></div><div># 미세조정 모델학습</div><div>trainer.train()</div><div><br /></div><div># W&amp;B 로그 종료</div><div>wandb.finish()</div><div>model.config.use_cache = True</div><div><br /></div><div># 테스트</div><div>messages = [</div><div>&nbsp; &nbsp; {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; \"role\": \"user\",</div><div>&nbsp; &nbsp; &nbsp; &nbsp; \"content\": \"Hello doctor, I have bad acne. How do I get rid of it?\"</div><div>&nbsp; &nbsp; }</div><div>]</div><div>prompt = tokenizer.apply_chat_template(messages, tokenize=False,&nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;add_generation_prompt=True)</div><div>inputs = tokenizer(prompt, return_tensors='pt', padding=True,&nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;truncation=True).to(\"cuda\")</div><div>outputs = model.generate(**inputs, max_length=150,&nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;num_return_sequences=1)</div><div>text = tokenizer.decode(outputs[0], skip_special_tokens=True)</div><div>print(text.split(\"assistant\")[1])</div><div><br /></div><div># 파인튜닝된 모델을 허깅페이스 허브에 업로드함</div><div>trainer.model.save_pretrained(new_model)</div><div>trainer.model.push_to_hub(new_model, use_temp_dir=False)</div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">실행 결과는 다음과 같다.</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgOsJ6wlSBJrG-7S4k6ELsO2YLj_VZGjOeQl7GP332_PW7La37gcrgLg7auFnTzCBJQHw4x3rpxkEJa_xp3qlo0btkLqlQ0LpsttT2iSHd57YMvW4Dbim5fTgZRyHNBQEjbxms6Fk6XW_rL9hPRf1vQoHsMEynVMz7z1yORTZsxSKYqV-5ay0Ay1oJ3CrLo\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"372\" data-original-width=\"1853\" height=\"64\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgOsJ6wlSBJrG-7S4k6ELsO2YLj_VZGjOeQl7GP332_PW7La37gcrgLg7auFnTzCBJQHw4x3rpxkEJa_xp3qlo0btkLqlQ0LpsttT2iSHd57YMvW4Dbim5fTgZRyHNBQEjbxms6Fk6XW_rL9hPRf1vQoHsMEynVMz7z1yORTZsxSKYqV-5ay0Ay1oJ3CrLo\" width=\"320\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhiXjEIhuTMcYBwwc9TUtjo2sVu6JmYbD_TApKmuXHnXISkYSVj-RCO2kCG0Px3GNZTvsj0y1pHNtxsD23wXdWLyv59hEhlx5vL-94UO2tmt7Q64A7IdN7nNafUMMLMfeVWbqp4GKHmvQvWV7GjzF75ZYyk0YNteX-hAJsDpB_8RMd87VV8V2CrNbRbahOM\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"430\" data-original-width=\"819\" height=\"168\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhiXjEIhuTMcYBwwc9TUtjo2sVu6JmYbD_TApKmuXHnXISkYSVj-RCO2kCG0Px3GNZTvsj0y1pHNtxsD23wXdWLyv59hEhlx5vL-94UO2tmt7Q64A7IdN7nNafUMMLMfeVWbqp4GKHmvQvWV7GjzF75ZYyk0YNteX-hAJsDpB_8RMd87VV8V2CrNbRbahOM\" width=\"320\" /></a></div><br /><br /></div><b>레퍼런스<br /></b><ul style=\"text-align: left;\"><li><a href=\"https://medium.com/@miloszivic99/finetuning-large-language-models-customize-llama-3-8b-for-your-needs-bfe0f43cd239\">Finetuning Large Language Models: Customize Llama 3 8B For Your Needs | by Milos Zivic | Apr, 2024 | Medium</a></li><li><a href=\"https://huggingface.co/Undi95/Meta-Llama-3-8B-hf\">Undi95/Meta-Llama-3-8B-hf · Hugging Face</a></li><li><a href=\"https://mlops.community/budget-instruction-fine-tuning-of-llama-3-8b-instructon-medical-data-with-hugging-face-google-colab-and-unsloth/\">Budget Instruction Fine-tuning of Llama 3 8B Instruct(on Medical Data) with Hugging Face, Google Colab and Unsloth - MLOps Community</a></li><li><a href=\"https://pytorch.org/torchtune/main/install.html\">torchtune main documentation (pytorch.org)</a>, <a href=\"https://arxiv.org/pdf/2305.11206\">LIMA</a></li><li><a href=\"https://github.com/pytorch/torchtune\">pytorch/torchtune: A Native-PyTorch Library for LLM Fine-tuning (github.com)</a></li><li><a href=\"https://huggingface.co/MLP-KTLim/llama-3-Korean-Bllossom-8B\">llama-3-Korean-Bllossom-8B · Hugging Face</a></li><li><a href=\"https://www.datacamp.com/tutorial/llama3-fine-tuning-locally\">Fine-Tuning Llama 3 and Using It Locally: A Step-by-Step Guide | DataCamp</a></li><li><a href=\"https://huggingface.co/blog/mlabonne/orpo-llama-3\">Fine-tune Llama 3 with ORPO (huggingface.co)</a></li><li><a href=\"https://medium.com/@syed_hasan/finetuning-llama-3-using-reft-representation-fine-tuning-technique-00f4fe1f497c\">Finetuning Llama-3 using ReFT (Representation Fine-Tuning) Technique | by Syed Hasan | Apr, 2024 | Medium</a></li><li><a href=\"https://www.philschmid.de/fsdp-qlora-llama3\">Efficiently fine-tune Llama 3 with PyTorch FSDP and Q-Lora (philschmid.de)</a></li><li><a href=\"https://llama.meta.com/docs/how-to-guides/fine-tuning/\">Fine-tuning | How-to guides (meta.com)</a></li><li><a href=\"https://github.com/ggerganov/llama.cpp/discussions/2904\">Fine tuning GPU memory requirements · ggerganov/llama.cpp · Discussion #2904 (github.com)</a></li><li><a href=\"https://anakin.ai/blog/how-to-fine-tune-llama-3/\">How to Fine-Tune LLaMA 3: An Easy Guide (anakin.ai)</a></li><li><a href=\"https://huggingface.co/datasets/heegyu/kowikitext\">kowikitext · Datasets at Hugging Face</a>,&nbsp;<a href=\"https://github.com/lovit/kowikitext/\">kowikitext (github.com)</a></li></ul><div>다음은 파인튜닝 후 RAG처리 전략에 대한 레퍼런스이다.&nbsp;</div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><a href=\"https://blog.langchain.dev/applying-openai-rag/\">Applying OpenAI's RAG Strategies (langchain.dev)</a></li><li><a href=\"https://blog.langchain.dev/query-transformations/\">Query Transformations (langchain.dev)</a></li></ul></div></div>",
        "contentSnippet": "이 글은 Lora 기반 LLAMA3 모델 파인튜닝하는 방법을 간략히 보여준다. 이를 통해, 특정 도메인의 LLM 모델 생성 정확도를 향상시킬 수 있다.\n\n\n\n\n\n머리말\n\nLLAMA3는 메타가 개발한 LLM 제품이다. 모델은 15조 개의 토큰으로 구성된 광범위한 데이터 세트에서 훈련되었다(라마 2의 경우 2T 토큰과 비교). 700억 개의 파라미터 모델과 더 작은 80억 개의 파라미터 모델의 두 가지 모델 크기가 출시되었다. 70B 모델은 MMLU 벤치마크에서 82점, HumanEval 벤치마크에서 81.7점을 기록하며 이미 인상적인 성능을 보여주었다.\n\n\n라마 3 모델은 컨텍스트 길이를 최대 8,192개 토큰(라마 2의 경우 4,096개 토큰)까지 늘렸으며, RoPE를 통해 최대 32k까지 확장할 수 있다. 또한 이 모델은 128K 토큰 어휘가 있는 새로운 토크나이저를 사용하여 텍스트를 인코딩하는 데 필요한 토큰 수를 15% 줄이다. \n\n\n파인튜닝 개념\n파인튜닝(fine turning. 미세 조정)전략은 활용된 데이터에 따라 달라지며, 이는 네 가지 유형으로 분류할 수 있다.\n\n감독 미세 조정\n퓨샷 학습(Few-shot Learning)\n전체 전이 학습\n도메인별 미세 조정\n감독 미세 조정\n\n이 방법은 미세 조정에 대한 표준 접근 방식을 나타낸다. 모델은 텍스트 분류, 질문 답변 또는 명명된 엔터티 인식과 같이 수행하려는 특정 작업에 맞게 조정된 레이블이 지정된 데이터 세트를 사용하여 추가 학습을 거친다. 예를 들어 감정 분석에서 모델은 해당 감정으로 주석이 달린 텍스트 샘플로 구성된 데이터 세트에서 학습된다.\n\n\n퓨샷 학습(Few-Shot Learning)\n레이블이 지정된 대규모 데이터 세트를 어셈블하는 것이 비현실적인 것으로 판명된 시나리오에서는 솔루션을 제공하기 위해 몇 가지 학습 단계가 개입한다. 이 기술은 입력 프롬프트를 시작할 때 원하는 작업에 대한 몇 가지 예제(또는 샷)를 모델에 제공한다. 이렇게 함으로써 모델은 철저한 미세 조정 요법 없이 작업에 대한 더 나은 컨텍스트 이해를 얻을 수 있다.\n\n\n\n\n\nfew_shot_examples = [\n\n\n\n{\"input\":\"Could you please clarify the terms outlined in section 3.2 of the contract?\",\n\n\n\n\"output\":\"Certainly, I will provide clarification on the terms in section 3.2.\"},\n\n\n\n{\"input\":\"We are interested in extending the payment deadline to 30 days instead of the current 15 days. Additionally, we would like to add a clause regarding late payment penalties.\",\n\n\n\n\"output\":\"Our request is to extend the payment deadline to 30 days and include a clause on late payment penalties.\"},\n\n\n\n{\"input\":\"\"\"The current indemnification clause seems too broad. We would like to narrow it down to cover only direct damages and exclude consequential damages.\n\n\n\nAdditionally, we propose including a dispute resolution clause specifying arbitration as the preferred method of resolving disputes.\"\"\",\n\n\n\n\"output\":\"\"\"We suggest revising the indemnification clause to limit it to covering direct damages and excluding consequential damages.\n\n\n\nFurthermore, we recommend adding a dispute resolution clause that specifies arbitration as the preferred method of resolving disputes.\"\"\"},\n\n\n\n{\"input\":\"I believe the proposed changes are acceptable.\",\n\n\n\n\"output\":\"Thank you for your feedback. I will proceed with implementing the proposed changes.\"}\n\n\n\n]\n\n\n\n\n\n전체 전이 학습\n모든 미세 조정 방법에는 일종의 전이 학습이 포함되지만, 이 범주는 특히 모델이 원래 학습 목표와 다른 작업을 수행할 수 있도록 한다. 핵심은 광범위하고 일반적인 데이터 세트에서 모델이 축적한 지식을 활용하여 보다 전문적이거나 관련 작업에 적용하는 데 있다.\n\n\n도메인별 미세 조정\n이 미세 조정 변형은 특정 도메인 또는 산업과 관련된 텍스트를 이해하고 생성하도록 모델을 적응시키는 것을 목표로 한다. 모델은 대상 도메인과 관련된 텍스트로 구성된 데이터 세트를 사용하여 미세 조정을 거치므로 도메인별 작업에 대한 컨텍스트 파악과 숙련도가 향상된다. 예를 들어, 의료 애플리케이션용 챗봇을 개발하기 위해 모델은 의료 기록에 대해 훈련되어 의료 영역 내에서 언어 이해 능력을 개선해야 한다.\n\n\n미세 조정 과정에서 업데이트되는 모델 가중치에 따라 두 가지 유형의 미세 조정이 있다.\n\n\n파라미터 효율 미세 조정(PEFT)\n전체 미세 조정이라고 하는 이 포괄적인 미세 조정 방법에는 모든 모델 가중치를 업데이트하여 최적화된 버전을 만드는 작업이 포함된다. 그러나 사전 학습과 유사한 메모리 및 계산 리소스에 대한 상당한 요구 사항을 부과하므로 학습 중에 저장 및 처리를 관리하기 위한 강력한 인프라가 필요한다.\n\n\n파라미터 효율 미세 조정(PEFT)\n매개 변수 효율적인 미세 조정 또는 간단히 PEFT는 명령 미세 조정 방법론에서 전체 미세 조정에 대한 보다 리소스 효율적인 대안을 나타낸다. 전체 LLM 미세 조정은 상당한 계산 오버헤드를 수반하여 메모리 할당에 문제를 제기하는 반면, PEFT는 매개변수의 하위 집합만 업데이트하고 나머지는 효과적으로 \"고정\"하는 솔루션을 제공한다. 이 접근 방식은 학습 가능한 매개 변수의 수를 줄여 메모리 요구 사항을 완화하고 치명적인 망각을 방지한다. 완전한 미세 조정과 달리 PEFT는 이전에 습득한 지식을 유지하면서 원래 LLM 가중치를 보존한다. 이 기능은 여러 작업을 미세 조정할 때 스토리지 제약 조건을 완화하는 데 유리한 것으로 입증되었다. LoRA(Low-Rank Adaptation) 및 QLoRA(Quantized Low-Rank Adaptation)와 같이 널리 채택된 기술은 파라미터 효율적인 미세 조정을 달성하기 위한 효과적인 방법을 보여준다.\n\n\n\nReFT\n언어 모델은 토큰 시퀀스의 상황에 맞는 표현을 생성해야 한다. \nReFT(표현 미세 조정)은 n개 입력 토큰 x = (x1, . . . , xn)의 시퀀스가 주어지면 모델은 먼저 이러한 토큰을 표현 목록에 포함한다. 그런 다음, 모델 계층은 은닉 표현의 j번째 리스트 h(j)를 이전 은닉 표현 리스트 h(j−1)의 함수로 연속적으로 계산한다. 각 은닉 표현은 벡터입니다. LM은 최종 은닉 표현을 사용하여 예측을 생성한다.\n\n\nPyReFT는 학습 개입을 통해 내부 언어모델 표현적응을 지원하는 표현 미세 조정(ReFT) 라이브러리이다. 적은 수의 미세 조정 매개변수와 강력한 성능을 통해 Pyreft는 미세 조정 효율성을 높이고 미세 조정 비용을 줄일 수 있다.\n\n\nLoRA 및 QLoRa\nLoRA는 향상된 미세 조정 접근 방식으로, 사전 훈련된 대규모 언어 모델의 가중치 행렬에 근접한 두 개의 작은 행렬만 미세 조정하여 LoRA 어댑터를 형성함으로써 기존 방법에서 벗어난다. 그런 다음 이 미세 조정된 어댑터는 후속 추론 작업을 위해 미리 학습된 모델에 통합된다. 특정 작업 또는 사용 사례에 대한 LoRA 미세 조정이 완료되면 그 결과는 변경되지 않은 원본 LLM과 함께 훨씬 더 작은 \"LoRA 어댑터\"의 출현으로 이어지며, 이는 종종 원래 LLM 크기(GB가 아닌 MB로 측정됨)의 일부에 불과한다. 추론하는 동안 LoRA 어댑터는 원래 LLM과 융합되어야 한다. 이 접근 방식은 많은 LoRA 어댑터가 원래 LLM의 용도를 효과적으로 변경할 수 있으므로 여러 작업 및 사용 사례를 처리할 때 전체 메모리 요구 사항을 줄일 수 있다는 주요 이점을 제공한다.\n\n\nQLoRA는 LoRA에 비해 메모리 효율성이 더욱 향상되었음을 나타낸다. LoRA 어댑터의 가중치를 더 낮은 정밀도(일반적으로 원래 4비트 대신 8비트)로 양자화하여 LoRA 기술을 개선한다. 이 추가 최적화는 메모리 공간과 스토리지 오버헤드를 크게 줄이다. QLoRA에서 사전 훈련된 모델은 양자화된 4비트 가중치로 GPU 메모리에 로드되며, 이는 LoRA에서 사용되는 8비트 정밀도에서 벗어난다. 이러한 비트 정밀도 감소에도 불구하고 QLoRA는 이전 제품과 비슷한 수준의 효율성을 유지하여 성능 저하 없이 메모리 사용을 최적화하는 능력을 보여준다.\n\n\n라마3 파인튜닝 모델 개발 \n개발 환경\n앞의 내용을 고려해, 라마3를 파인튜닝한다. 개발환경은 다음과 같다.\n\npip install -U transformers \npip install -U datasets \npip install -U accelerate \npip install -U peft \npip install -U trl \npip install -U bitsandbytes \npip install -U wandb\n\n\n\n\n저렴한 비용으로 학습 모델을 개발하기 위해, Lora, 양자화를 사용한다. 사전 학습모델은 허깅페이스(HF)에서 제공하는 LLAMA3-8B모델을 사용한다. \n\nMeta-Llama-3-8B-hf at main (huggingface.co)\n\n\n파인튜닝할 데이터는 ruslanmv/ai-medical-chatbot · Datasets at Hugging Face 를 사용한다. \n\n\n\n구현 코드는 다음과 같다.\n# 파이썬 패키지 임포트\n\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    prepare_model_for_kbit_training,\n    get_peft_model,\n)\nimport os, torch, wandb\nfrom datasets import load_dataset\nfrom trl import SFTTrainer, setup_chat_format\n\n\n# 허깅페이스및 W&B 키 토큰 이용해 로그인. 미리 사전 발급받아야 함.\nfrom huggingface_hub import login # https://www.kaggle.com/discussions/product-feedback/114053\nlogin(token = 'input your HF token')  # HF 키 토큰 입력\n\n\nwandb.login(key='input your WandB token')  # W&B 키 토큰 입력\nrun = wandb.init(\n    project='Fine-tune Llama 3 8B on Medical Dataset', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)\n\n\n# 사전학습모델 설정\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n\nbase_model = \"Undi95/Meta-Llama-3-8B-hf\" \ndataset_name = \"ruslanmv/ai-medical-chatbot\" # 사용할 데이터셋\nnew_model = \"llama-3-8b-chat-doctor\"           # 파인튜닝 모델 이름\n\n\ntorch_dtype = torch.float16\nattn_implementation = \"eager\"\n\n\n# QLoRA 설정\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True, # 4bit 양자화\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=attn_implementation\n)\n\n\n# 토크나이저 및 모델 로딩\n\ntokenizer = AutoTokenizer.from_pretrained(base_model)\nmodel, tokenizer = setup_chat_format(model, tokenizer)\n\n\n# Lora 설정\npeft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n)\nmodel = get_peft_model(model, peft_config)  # 파라메터 튜닝 설정\n\n\n# 데이터셋 로딩\ndataset = load_dataset(dataset_name, split=\"all\")\ndataset = dataset.shuffle(seed=65).select(range(1000)) # 파인튜닝 예시 위해 1000개만 사용\n\n\ndef format_chat_template(row):\n    row_json = [{\"role\": \"user\", \"content\": row[\"Patient\"]},\n               {\"role\": \"assistant\", \"content\": row[\"Doctor\"]}]\n    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n    return row\n\n\ndataset = dataset.map(\n    format_chat_template,\n    num_proc=4,\n)\n\n\nprint(dataset['text'][3])\n\n\ndataset = dataset.train_test_split(test_size=0.1) # 데이터 검증 세트 분할\n\n\n# 모델 하이퍼파라메터 설정. 참고. Fine-Tuning LLaMA 2: A Step-by-Step Guide to Customizing the Large Language Model | DataCamp\ntraining_arguments = TrainingArguments(\n    output_dir=new_model,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=2,\n    optim=\"paged_adamw_32bit\",\n    num_train_epochs=1,\n    evaluation_strategy=\"steps\",\n    eval_steps=0.2,\n    logging_steps=1,\n    warmup_steps=10,\n    logging_strategy=\"steps\",\n    learning_rate=2e-4,\n    fp16=False,\n    bf16=False,\n    group_by_length=True,\n    report_to=\"wandb\"\n)\n\n\n# 지도미세조정(SFT) 설정\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    peft_config=peft_config,\n    max_seq_length=512,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing= False,\n)\n\n\n# 미세조정 모델학습\ntrainer.train()\n\n\n# W&B 로그 종료\nwandb.finish()\nmodel.config.use_cache = True\n\n\n# 테스트\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"Hello doctor, I have bad acne. How do I get rid of it?\"\n    }\n]\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, \n                                       add_generation_prompt=True)\ninputs = tokenizer(prompt, return_tensors='pt', padding=True, \n                   truncation=True).to(\"cuda\")\noutputs = model.generate(**inputs, max_length=150, \n                         num_return_sequences=1)\ntext = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(text.split(\"assistant\")[1])\n\n\n# 파인튜닝된 모델을 허깅페이스 허브에 업로드함\ntrainer.model.save_pretrained(new_model)\ntrainer.model.push_to_hub(new_model, use_temp_dir=False)\n\n\n실행 결과는 다음과 같다.\n\n\n\n\n레퍼런스\n\nFinetuning Large Language Models: Customize Llama 3 8B For Your Needs | by Milos Zivic | Apr, 2024 | Medium\nUndi95/Meta-Llama-3-8B-hf · Hugging Face\nBudget Instruction Fine-tuning of Llama 3 8B Instruct(on Medical Data) with Hugging Face, Google Colab and Unsloth - MLOps Community\ntorchtune main documentation (pytorch.org), LIMA\npytorch/torchtune: A Native-PyTorch Library for LLM Fine-tuning (github.com)\nllama-3-Korean-Bllossom-8B · Hugging Face\nFine-Tuning Llama 3 and Using It Locally: A Step-by-Step Guide | DataCamp\nFine-tune Llama 3 with ORPO (huggingface.co)\nFinetuning Llama-3 using ReFT (Representation Fine-Tuning) Technique | by Syed Hasan | Apr, 2024 | Medium\nEfficiently fine-tune Llama 3 with PyTorch FSDP and Q-Lora (philschmid.de)\nFine-tuning | How-to guides (meta.com)\nFine tuning GPU memory requirements · ggerganov/llama.cpp · Discussion #2904 (github.com)\nHow to Fine-Tune LLaMA 3: An Easy Guide (anakin.ai)\nkowikitext · Datasets at Hugging Face, kowikitext (github.com)\n\n다음은 파인튜닝 후 RAG처리 전략에 대한 레퍼런스이다. \n\nApplying OpenAI's RAG Strategies (langchain.dev)\nQuery Transformations (langchain.dev)",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-6440721014895432690",
        "isoDate": "2024-06-21T01:47:00.000Z"
      },
      {
        "title": "NLP의 핵심. 토큰, 임베딩 모델 파인튜닝",
        "link": "http://daddynkidsmakers.blogspot.com/2024/06/nlp.html",
        "pubDate": "2024-06-20T02:42:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">이 글은 LLM NLP처리의 핵심인 토큰, 임베딩 모델 파인튜닝에 대한 내용을 간략히 다룬다.&nbsp;<br /></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjdtFPzVXJo-FpMzg755V6l-C1vSvouzcyrxYR9JU7pRd3R7_lQLCUDlMIGQrhcDV5eZ6iddZsgM8FHl5sBSEw2ssbdrGxP_vn8spPvkYHSB7fUVbeWUEXRIYunL2-3V9c3l4RzSDUPiHNmsy_39IyyGhDdqCL-aogV_EY6ENs4DYKH9qk7zzFjriBdVgR-\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"360\" data-original-width=\"480\" height=\"240\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjdtFPzVXJo-FpMzg755V6l-C1vSvouzcyrxYR9JU7pRd3R7_lQLCUDlMIGQrhcDV5eZ6iddZsgM8FHl5sBSEw2ssbdrGxP_vn8spPvkYHSB7fUVbeWUEXRIYunL2-3V9c3l4RzSDUPiHNmsy_39IyyGhDdqCL-aogV_EY6ENs4DYKH9qk7zzFjriBdVgR-\" width=\"320\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">TIKTOKEN 라이브러리</div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\"><b>배경 - 도메인 의존 정보</b></div><div style=\"text-align: left;\">의학과 같은 특별한 분야에서는 기존 LLM이 제대로 정보를 생성하지 못하는 경우가 많다. 이런 문제는 파인튜닝할 때 크게 나타난다. 사실, 토큰과 임베딩은 입력 시퀀스에 대한 출력을 학습, 예측할 때 훈련의 전제가 되는 LLM의 기본조건이다.&nbsp;</div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">토큰 사전과 임베딩 모델이 다르면, 제대로 된 모델 학습, 예측, 패턴 계산 결과를 얻기 어렵다. 그러므로, LLM을 사용하기 전에 미리 이 점을 명확히 확인해야 한다. 만약, 이런 전제가 만족될 수 없다면, <a href=\"https://huggingface.co/tomaszki/llama-3-a/raw/main/vocab.json\">LLM 토큰</a> 개발, 파인튜닝 및 사전 모델학습이 필요하다.&nbsp;</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiGJkuNmb9VoaDwHakxUDZ7fTa7IJ2ToAqTyozvTunuRes3oE_4pIUzTBbGZTyypHvexXaLGwB1h0sUWwck0VTIH-VwU5qjk52k-H1179vy6bxOJgyMnJJ7j46MAyHh2dZz5BkARRHARkp4k60JYncGrvkKDV2NWvGdpm62j6omjW6z9PxCVjz_iqcgSG0F/s364/a16.JPG\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"241\" data-original-width=\"364\" height=\"171\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiGJkuNmb9VoaDwHakxUDZ7fTa7IJ2ToAqTyozvTunuRes3oE_4pIUzTBbGZTyypHvexXaLGwB1h0sUWwck0VTIH-VwU5qjk52k-H1179vy6bxOJgyMnJJ7j46MAyHh2dZz5BkARRHARkp4k60JYncGrvkKDV2NWvGdpm62j6omjW6z9PxCVjz_iqcgSG0F/w257-h171/a16.JPG\" width=\"257\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\">숫자 토큰화 결과(OOV. Out-Of-Vocabulary 문제)</div><div><br /></div></div><div style=\"text-align: left;\"><b>개발환경</b></div><div style=\"text-align: left;\">실습을 위해 다음을 설치한다.</div><div style=\"text-align: left;\"><div>pip install transformers torch</div><div><br /></div><div><div>참고로, 다음은 파인튜닝에 사용하는 도구를 보여준다.</div><div><ul><li>Torch: 텐서 계산 및 딥 러닝을 위한 핵심 라이브러리이다.</li><li>peft: 낮은 순위의 적응 기술을 사용하여 대규모 언어 모델을 효율적으로 미세 조정할 수 있다. 특히 리소스가 제한된 장치에서 학습 가능한 매개 변수의 수를 줄여 모델을 압축하고 더 빠르게 미세 조정할 수 있다.</li><li>bitsandbytes: 신경망에 대한 양자화 및 이진화 기술을 제공하여 모델 압축을 지원한다. 모델 압축에 도움이 되므로 메모리와 계산 능력이 제한된 에지 장치에 모델을 보다 실현 가능하게 만들 수 있다.</li><li>Transformers: 대규모 언어 모델 작업을 간소화하여 사전 학습된 모델 및 학습 파이프라인을 제공한다.</li><li>trl: 대규모 언어 모델의 경우 효율적인 모델 학습 및 최적화에 중점을 둔다.</li><li>accelerate: 다양한 하드웨어 플랫폼에서 학습 및 추론을 가속화한다.</li><li>dataset: 기계 학습 작업을 위한 데이터 세트 로드 및 준비를 간소화한다.</li><li>pipeline: 사용자 지정 학습 없이 일반적인 NLP 작업에 대해 사전 학습된 모델의 사용을 간소화한다.</li><li>pyarrow: 효율적인 데이터 로드 및 처리를 위해 사용될 수 있다.</li><li>LoraConfig: LoRA 기반 미세 조정을 위한 구성 매개변수를 보유한다.</li><li>SFTTrainer: 모델 학습, 최적화 및 평가를 처리한다.</li></ul></div><div><b>토큰 사전&nbsp;</b></div></div></div><div style=\"text-align: left;\">LLM 파인튜닝이나 RAG 시 토큰 사전이 없으면, 제대로 학습되지 않는다. 입력 시퀀스의 토큰이 사전에 없으면, 토큰은 분리된다. 분리된 토큰들은 각자 다른 맥락을 가지도록 학습된다. 다음 코드를 실행하면, 그 내용을 확인할 수 있다. 이런 문제는 유전자 해석 등 다양한 문제에서 발생된다.&nbsp;</div><div style=\"text-align: left;\">from transformers import DistilBertTokenizerFast, DistilBertModel</div><div style=\"text-align: left;\"><div><br /></div><div>tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")</div><div>tokens = tokenizer.encode('This is a IfcBuilding.', return_tensors='pt')</div><div>print(\"These are tokens!\", tokens)</div><div>for token in tokens[0]:</div><div>&nbsp; &nbsp; print(\"This are decoded tokens!\", tokenizer.decode([token]))</div><div><br /></div><div>model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")</div><div>print(model.embeddings.word_embeddings(tokens))</div><div>for e in model.embeddings.word_embeddings(tokens)[0]:</div><div>&nbsp; &nbsp; print(\"This is an embedding!\", e)</div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">다음 코드를 실행해보면, 좀 더 많은 문제점을 확인할 수 있다.</div><div style=\"text-align: left;\"><div>from transformers import BertTokenizer, BertModel</div><div>bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')</div><div><br /></div><div>example_sen = (</div><div>&nbsp; &nbsp; \"\"\"</div><div>&nbsp; &nbsp; The United States and Russia sought to lower the temperature in a&nbsp;</div><div>&nbsp; &nbsp; heated standoff over Ukraine,even as they reported no breakthroughs&nbsp;</div><div>&nbsp; &nbsp; in high-stakes talks on Friday aimed at preventing a feared Russian invasion</div><div>&nbsp; &nbsp; \"\"\"</div><div>)</div><div>print(bert_tokenizer.tokenize(example_sen))</div><div><br /></div><div>결과는 다음과 같다.&nbsp;</div><div>['the', 'united', 'states', 'and', 'russia', 'sought', 'to', 'lower', 'the', 'temperature', 'in', 'a', 'heated', 'stand', '##off', 'over', 'ukraine', ',', 'even', 'as', 'they', 'reported', 'no', 'breakthrough', '##s', 'in', 'high', '-', 'stakes', 'talks', 'on', 'friday', 'aimed', 'at', 'preventing', 'a', 'feared', 'russian', 'invasion']</div></div><div style=\"text-align: left;\"><br /></div><div style=\"text-align: left;\">이 경우, 토큰을 추가하거나, 하나로 합치는 것을 고려할 필요가 있다.</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div></div><div style=\"text-align: left;\"><b>토큰 추가와 임베딩 공간</b></div><div style=\"text-align: left;\">BERT를 이용해 토큰 사전과 임베딩을 실습해본다.</div><div style=\"text-align: left;\">일반적으로 허깅페이스 라이브러리에서 LLM모델에 대한 토큰 추가가 가능한 tokenizer를 제공해 준다. 토큰을 추가하면, 임베딩 차원에 영향을 주므로, 해당 크기를 수정해야 한다. 다음은 이를 고려한 코드를 보여준다.&nbsp;</div><div style=\"text-align: left;\"><div>from transformers import AutoTokenizer, AutoModelForCausalLM</div><div><br /></div><div># 사전 학습모델 및 토크나이저 로딩</div><div>model = AutoModelForCausalLM.from_pretrained('model-name')</div><div><div>tokenizer = AutoTokenizer.from_pretrained('model-name')</div></div><div><br /></div><div># 토큰 추가</div><div>new_tokens = ['newword1', 'newword2']</div><div>tokenizer.add_tokens(new_tokens)</div><div><br /></div><div># 임베딩 공간 리사이즈&nbsp;</div><div>model.resize_token_embeddings(len(tokenizer))</div><div><br /></div><div># 추가된 토큰과 함께 파인튜닝.&nbsp;</div><div># (fine-tuning code here)</div><div><br /></div><div><b>BPE(Byte Pair Encoding) 토큰 압축</b></div><div><div>BPE는 바이트 쌍 인코딩(Byte pair Encoding)을 의미하며, 데이터의 가장 일반적인 연속 바이트 쌍을 해당 데이터 내에 발생하지 않는 바이트로 대체하는 데이터 압축 형태이다. 결과 데이터에 대해 프로세스가 반복적으로 반복된다. 자연어 처리(NLP) 및 기계 학습의 맥락에서 BPE는 하위 단어 토큰화 방법으로 사용된다.&nbsp;</div><div><br /></div><div>단어를 보다 관리하기 쉬운 하위 단어나 기호로 분할하여 대규모 어휘를 효율적으로 인코딩할 수 있다. 이 접근 방식은 어휘의 크기를 크게 줄이고 희귀 단어나 OOV(어휘에서 벗어난) 용어를 처리하는 모델의 능력을 향상시킬 수 있다.</div><div><br /></div><div>NLP에 BPE를 적용하는 기본 단계는 다음과 같다.</div><div><ul style=\"text-align: left;\"><li>텍스트를 단어로 나눈 다음 문자로 나누고 각 문자(또는 문자 시퀀스)의 빈도를 계산한다.</li><li>인접한 문자 또는 문자 시퀀스의 가장 빈번한 쌍을 반복적으로 찾아, 이를 새로운 문자 시퀀스로 병합한다.</li><li>원하는 어휘 크기에 도달할 때까지 또는 더 이상 병합으로 인해 어휘 크기가 크게 줄어들 때까지 병합 프로세스를 반복한다.</li></ul></div><div>BPE는 언어 모델링, 텍스트 생성, 특히 BERT(Bidirection Encoder Representations from Transformers)와 같은 변환기 기반 모델과 같은 다양한 NLP 모델 및 작업에 널리 채택되어 광범위한 어휘를 효율적으로 처리하는 데 도움이 된다.</div></div><div><br /></div><div>다음은 그 예제를 보여준다.</div><div>from tokenizers import Tokenizer, models, pre_tokenizers, trainers</div><div><div><br /></div><div>tokenizer = Tokenizer(models.BPE()) # 토큰화 얻기</div><div><br /></div><div>tokenizer.pre_tokenizer = pre_tokenizers.Whitespace() # 사용자 토큰 처리 객체</div><div>def custom_pre_tokenizer(sequence): # 사용자 토큰 정의</div><div>&nbsp; &nbsp; # Define rules to combine tokens, e.g., \"new word\" -&gt; \"newword\"</div><div>&nbsp; &nbsp; combined_sequence = sequence.replace(\"new word\", \"newword\")</div><div>&nbsp; &nbsp; return combined_sequence</div><div><br /></div><div># 토큰 훈련. custom pre-tokenizer 활용함.</div><div>trainer = trainers.BpeTrainer()</div><div>tokenizer.train(files=[\"path/to/training/data.txt\"], trainer=trainer, pre_tokenizer=custom_pre_tokenizer)</div><div><br /></div><div># 훈련된 토큰 저장</div><div>tokenizer.save(\"path/to/customized_tokenizer.json\")</div></div><div><br /></div><div><div><b>임베딩 모델 파인튜닝</b></div></div><div>다음은 토큰을 추가하고, 임베딩 모델을 파인튜닝하는&nbsp;보여준다.</div><div><br /></div><div><div>from transformers import BertTokenizerFast, BertModel</div><div>import torch</div><div>from torch import nn</div><div><br /></div><div># BERT 토크나이저 사전학습모델 로딩</div><div>tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')</div><div>print(tokenizer.tokenize(\"[CLS] Hello world, how are you?\"))</div><div><br /></div><div>print(tokenizer.tokenize(\"[newtoken] Hello world, how are you?\"))</div><div>tokenizer.add_tokens(['[newtoken]'])</div><div><br /></div><div><div>다음과 같이, [newtoken] 토큰 추가 전 테스트. 토큰이 한단어가 아닌 분할 출력된 것 확인</div><div>['[',</div><div>&nbsp;'newt',</div><div>&nbsp;'##oke',</div><div>&nbsp;'##n',</div><div>&nbsp;']',</div><div>&nbsp;'hello',</div><div>&nbsp;'world',</div><div>&nbsp;',',</div><div>&nbsp;'how',</div><div>&nbsp;'are',</div><div>&nbsp;'you',</div><div>&nbsp;'?']</div></div><div><br /></div><div>토큰을 추가하고 다시 토큰화를 한다.</div><div><div>tokenizer.add_tokens(['[newtoken]'])</div><div>tokenizer.tokenize(\"[newtoken] Hello world, how are you?\")</div></div><div><br /></div><div>제대로 토큰화가 된다.&nbsp;</div><div>['[newtoken]', 'hello', 'world', ',', 'how', 'are', 'you', '?']</div><div><br /></div><div>토큰값을 확인해 본다.</div><div>tokenized = tokenizer(\"[newtoken] Hello world, how are you?\", add_special_tokens=False, return_tensors=\"pt\")</div><div>print(tokenized['input_ids'])</div><div><br /></div><div>tkn = tokenized['input_ids'][0, 0]</div><div>print(\"First token:\", tkn)</div><div>print(\"Decoded:\", tokenizer.decode(tkn))</div><div><br /></div><div>다음과 같이, 토큰값이 잘 할당된 것을 알 수 있다.</div><div><div>tensor([[30522,&nbsp; 7592,&nbsp; 2088,&nbsp; 1010,&nbsp; 2129,&nbsp; 2024,&nbsp; 2017,&nbsp; 1029]])</div><div>First token: tensor(30522)</div><div>Decoded: [newtoken]</div></div><div><br /></div><div>임베딩 모델 학습을 위한 BERT 로딩하고, 앞의 토큰 리스트를 모델에 입력한다.</div><div>model = BertModel.from_pretrained('bert-base-uncased')</div><div>print(model.embeddings)</div><div><br /></div><div>try:</div><div>&nbsp; &nbsp; out = model(**tokenized)</div><div>&nbsp; &nbsp; out.last_hidden_state</div><div>except Exception as e:</div><div>&nbsp; &nbsp; print(e)</div><div><br /></div><div>임베딩 모델이 추가된 토큰을 학습하지 않았으므로, out of range 에러가 출력될 것이다.&nbsp;</div><div>다음 코드로 BERT 모델의토큰 공간 크기를 확인해 본다.</div><div>weights = model.embeddings.word_embeddings.weight.data</div><div>print(weights.shape)</div><div><br /></div><div>출력은 다음과 같이 30522이다.</div><div><div>torch.Size([30522, 768])</div></div><div><br /></div><div>이제 [CLS] 토큰을 임베딩 모델에 추가해보자.&nbsp;</div><div>new_weights = torch.cat((weights, weights[101:102]), 0)</div><div>new_emb = nn.Embedding.from_pretrained(new_weights, padding_idx=0, freeze=False)</div><div>print(new_emb)</div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiOFsQaKRDg14K_tV9HjnNhajL96t-NH-TXtnuwVdvailYbH6radvdePHtRZ9sY44tvAjGi7WBJhEtRF-Q82223dlK4wUg0zULyInMPfGdATBT-CRkZp5VnpTXs0XQF-0aDPjb9qnKePF7TTweBTDhmcKAeMb_f18iy2pQYL6AUy4RZ8ItPDQIGlkbI1Upv/s592/T1.JPG\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"239\" data-original-width=\"592\" height=\"161\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiOFsQaKRDg14K_tV9HjnNhajL96t-NH-TXtnuwVdvailYbH6radvdePHtRZ9sY44tvAjGi7WBJhEtRF-Q82223dlK4wUg0zULyInMPfGdATBT-CRkZp5VnpTXs0XQF-0aDPjb9qnKePF7TTweBTDhmcKAeMb_f18iy2pQYL6AUy4RZ8ItPDQIGlkbI1Upv/w400-h161/T1.JPG\" width=\"400\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://tinkerd.net/blog/machine-learning/bert-tokenization/\">Understanding BERT | Tokenization (tinkerd.net)</a></div><div><br /></div><div>다음과 같이 30523으로 토큰 크기가 증가되었다.&nbsp;</div><div><div>Embedding(30523, 768, padding_idx=0)</div></div><div><br /></div><div>새 레이어를 모델 마지막에 추가한다.</div><div>model.embeddings.word_embeddings = new_emb</div><div>print(model.embeddings)</div><div><br /></div><div>그 결과로 임베딩 모델의 word_embeddings가 업데이트된다.</div><div><div>BertEmbeddings(</div><div>&nbsp; (word_embeddings): Embedding(30523, 768, padding_idx=0)</div><div>&nbsp; (position_embeddings): Embedding(512, 768)</div><div>&nbsp; (token_type_embeddings): Embedding(2, 768)</div><div>&nbsp; (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)</div><div>&nbsp; (dropout): Dropout(p=0.1, inplace=False)</div><div>)</div></div><div><br /></div><div>앞의 토큰 시퀀스 리스트를 입력한다. 그럼, 제대로 결과가 출력될 것이다.</div><div>out = model(**tokenized)</div><div>print(out.last_hidden_state)</div><div><br /></div><div>다음 코드를 실행하면, 추가된 모델이 동일한 결과를 가지는 것을 알 수 있다.</div><div>model = BertModel.from_pretrained('bert-base-uncased')</div><div>out2 = model(</div><div>&nbsp; &nbsp; **tokenizer(\"[CLS] Hello world, how are you?\", add_special_tokens=False, return_tensors=\"pt\")</div><div>)</div><div><br /></div><div>out3 = torch.all(out.last_hidden_state == out2.last_hidden_state)</div><div>output(out3)</div></div></div><div style=\"text-align: left;\"><b><br /></b></div><div style=\"text-align: left;\"><b>마무리</b></div><div style=\"text-align: left;\"><div>LLM 파인튜닝이나 RAG 시 학습 데이터에 포함된 토큰에 대한 적절한 사전이 없으면, 제대로 학습되지 않는다. 이 글은 LLM NLP처리의 핵심인 토큰, 임베딩 모델 파인튜닝에 대한 내용을 간략히 다룬다.&nbsp;</div><div><br /></div></div><div style=\"text-align: left;\"><b>레퍼런스</b></div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><a href=\"https://medium.com/@ilyesrezgui46/enhance-your-gpt-experience-tiktoken-unveiled-free-token-counting-for-prompts-with-python-code-51851883825b\">Enhance Your GPT Experience: Tiktoken Unveiled — Free Token Counting for Prompts (with Python Code!) | by Ilyes Rezgui | Medium</a></li><li><a href=\"https://www.ai-bio.info/huggingface-bertformaskedlm-finetuning\">huggingface BertForMaskedLM fine-tuning (ai-bio.info)</a></li><li><a href=\"https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/split_by_token/\">Split by tokens | 🦜️🔗 LangChain</a></li><li><a href=\"https://huggingface.co/tomaszki/llama-3-a/raw/main/vocab.json\">huggingface.co/tomaszki/llama-3-a/raw/main/vocab.json</a></li><li><a href=\"https://wikidocs.net/234002\">TokenTextSplitter</a></li><li><a href=\"https://medium.com/@pierre_guillou/nlp-how-to-add-a-domain-specific-vocabulary-new-tokens-to-a-subword-tokenizer-already-trained-33ab15613a41\">NLP | How to add a domain-specific vocabulary (new tokens) to a subword tokenizer already trained like BERT WordPiece | by Pierre Guillou | Medium</a></li><li><a href=\"https://huggingface.co/blog/lmassaron/fine-tuning-llms-on-kaggle-notebooks\">Fine-tuning a large language model on Kaggle Notebooks (or even on your own computer) for solving real-world tasks (huggingface.co)</a></li><li><a href=\"https://medium.com/@gobishangar11/llama-2-a-detailed-guide-to-fine-tuning-the-large-language-model-8968f77bcd15\">LLaMA 2: A Detailed Guide to Fine-Tuning the Large Language Model | by Gobi Shangar | Medium</a></li><li><a href=\"https://tuanatran.medium.com/fine-tuning-large-language-model-with-hugging-face-pytorch-adce80dce2ad\">Fine-Tuning Large Language Model with Hugging Face &amp; PyTorch | by Tuan Tran | Medium</a></li></ul></div>",
        "contentSnippet": "이 글은 LLM NLP처리의 핵심인 토큰, 임베딩 모델 파인튜닝에 대한 내용을 간략히 다룬다. \n\n\n\n\nTIKTOKEN 라이브러리\n\n\n배경 - 도메인 의존 정보\n의학과 같은 특별한 분야에서는 기존 LLM이 제대로 정보를 생성하지 못하는 경우가 많다. 이런 문제는 파인튜닝할 때 크게 나타난다. 사실, 토큰과 임베딩은 입력 시퀀스에 대한 출력을 학습, 예측할 때 훈련의 전제가 되는 LLM의 기본조건이다. \n\n\n토큰 사전과 임베딩 모델이 다르면, 제대로 된 모델 학습, 예측, 패턴 계산 결과를 얻기 어렵다. 그러므로, LLM을 사용하기 전에 미리 이 점을 명확히 확인해야 한다. 만약, 이런 전제가 만족될 수 없다면, LLM 토큰 개발, 파인튜닝 및 사전 모델학습이 필요하다. \n\n\n숫자 토큰화 결과(OOV. Out-Of-Vocabulary 문제)\n\n\n개발환경\n실습을 위해 다음을 설치한다.\n\npip install transformers torch\n\n\n참고로, 다음은 파인튜닝에 사용하는 도구를 보여준다.\n\nTorch: 텐서 계산 및 딥 러닝을 위한 핵심 라이브러리이다.\npeft: 낮은 순위의 적응 기술을 사용하여 대규모 언어 모델을 효율적으로 미세 조정할 수 있다. 특히 리소스가 제한된 장치에서 학습 가능한 매개 변수의 수를 줄여 모델을 압축하고 더 빠르게 미세 조정할 수 있다.\nbitsandbytes: 신경망에 대한 양자화 및 이진화 기술을 제공하여 모델 압축을 지원한다. 모델 압축에 도움이 되므로 메모리와 계산 능력이 제한된 에지 장치에 모델을 보다 실현 가능하게 만들 수 있다.\nTransformers: 대규모 언어 모델 작업을 간소화하여 사전 학습된 모델 및 학습 파이프라인을 제공한다.\ntrl: 대규모 언어 모델의 경우 효율적인 모델 학습 및 최적화에 중점을 둔다.\naccelerate: 다양한 하드웨어 플랫폼에서 학습 및 추론을 가속화한다.\ndataset: 기계 학습 작업을 위한 데이터 세트 로드 및 준비를 간소화한다.\npipeline: 사용자 지정 학습 없이 일반적인 NLP 작업에 대해 사전 학습된 모델의 사용을 간소화한다.\npyarrow: 효율적인 데이터 로드 및 처리를 위해 사용될 수 있다.\nLoraConfig: LoRA 기반 미세 조정을 위한 구성 매개변수를 보유한다.\nSFTTrainer: 모델 학습, 최적화 및 평가를 처리한다.\n\n토큰 사전 \n\nLLM 파인튜닝이나 RAG 시 토큰 사전이 없으면, 제대로 학습되지 않는다. 입력 시퀀스의 토큰이 사전에 없으면, 토큰은 분리된다. 분리된 토큰들은 각자 다른 맥락을 가지도록 학습된다. 다음 코드를 실행하면, 그 내용을 확인할 수 있다. 이런 문제는 유전자 해석 등 다양한 문제에서 발생된다. \nfrom transformers import DistilBertTokenizerFast, DistilBertModel\n\n\ntokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\ntokens = tokenizer.encode('This is a IfcBuilding.', return_tensors='pt')\nprint(\"These are tokens!\", tokens)\nfor token in tokens[0]:\n    print(\"This are decoded tokens!\", tokenizer.decode([token]))\n\n\nmodel = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\nprint(model.embeddings.word_embeddings(tokens))\nfor e in model.embeddings.word_embeddings(tokens)[0]:\n    print(\"This is an embedding!\", e)\n\n\n다음 코드를 실행해보면, 좀 더 많은 문제점을 확인할 수 있다.\n\nfrom transformers import BertTokenizer, BertModel\nbert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n\nexample_sen = (\n    \"\"\"\n    The United States and Russia sought to lower the temperature in a \n    heated standoff over Ukraine,even as they reported no breakthroughs \n    in high-stakes talks on Friday aimed at preventing a feared Russian invasion\n    \"\"\"\n)\nprint(bert_tokenizer.tokenize(example_sen))\n\n\n결과는 다음과 같다. \n['the', 'united', 'states', 'and', 'russia', 'sought', 'to', 'lower', 'the', 'temperature', 'in', 'a', 'heated', 'stand', '##off', 'over', 'ukraine', ',', 'even', 'as', 'they', 'reported', 'no', 'breakthrough', '##s', 'in', 'high', '-', 'stakes', 'talks', 'on', 'friday', 'aimed', 'at', 'preventing', 'a', 'feared', 'russian', 'invasion']\n\n\n이 경우, 토큰을 추가하거나, 하나로 합치는 것을 고려할 필요가 있다.\n\n\n\n토큰 추가와 임베딩 공간\nBERT를 이용해 토큰 사전과 임베딩을 실습해본다.\n일반적으로 허깅페이스 라이브러리에서 LLM모델에 대한 토큰 추가가 가능한 tokenizer를 제공해 준다. 토큰을 추가하면, 임베딩 차원에 영향을 주므로, 해당 크기를 수정해야 한다. 다음은 이를 고려한 코드를 보여준다. \n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n\n# 사전 학습모델 및 토크나이저 로딩\nmodel = AutoModelForCausalLM.from_pretrained('model-name')\n\ntokenizer = AutoTokenizer.from_pretrained('model-name')\n\n\n# 토큰 추가\nnew_tokens = ['newword1', 'newword2']\ntokenizer.add_tokens(new_tokens)\n\n\n# 임베딩 공간 리사이즈 \nmodel.resize_token_embeddings(len(tokenizer))\n\n\n# 추가된 토큰과 함께 파인튜닝. \n# (fine-tuning code here)\n\n\nBPE(Byte Pair Encoding) 토큰 압축\n\nBPE는 바이트 쌍 인코딩(Byte pair Encoding)을 의미하며, 데이터의 가장 일반적인 연속 바이트 쌍을 해당 데이터 내에 발생하지 않는 바이트로 대체하는 데이터 압축 형태이다. 결과 데이터에 대해 프로세스가 반복적으로 반복된다. 자연어 처리(NLP) 및 기계 학습의 맥락에서 BPE는 하위 단어 토큰화 방법으로 사용된다. \n\n\n단어를 보다 관리하기 쉬운 하위 단어나 기호로 분할하여 대규모 어휘를 효율적으로 인코딩할 수 있다. 이 접근 방식은 어휘의 크기를 크게 줄이고 희귀 단어나 OOV(어휘에서 벗어난) 용어를 처리하는 모델의 능력을 향상시킬 수 있다.\n\n\nNLP에 BPE를 적용하는 기본 단계는 다음과 같다.\n\n텍스트를 단어로 나눈 다음 문자로 나누고 각 문자(또는 문자 시퀀스)의 빈도를 계산한다.\n인접한 문자 또는 문자 시퀀스의 가장 빈번한 쌍을 반복적으로 찾아, 이를 새로운 문자 시퀀스로 병합한다.\n원하는 어휘 크기에 도달할 때까지 또는 더 이상 병합으로 인해 어휘 크기가 크게 줄어들 때까지 병합 프로세스를 반복한다.\n\nBPE는 언어 모델링, 텍스트 생성, 특히 BERT(Bidirection Encoder Representations from Transformers)와 같은 변환기 기반 모델과 같은 다양한 NLP 모델 및 작업에 널리 채택되어 광범위한 어휘를 효율적으로 처리하는 데 도움이 된다.\n\n\n다음은 그 예제를 보여준다.\nfrom tokenizers import Tokenizer, models, pre_tokenizers, trainers\n\n\ntokenizer = Tokenizer(models.BPE()) # 토큰화 얻기\n\n\ntokenizer.pre_tokenizer = pre_tokenizers.Whitespace() # 사용자 토큰 처리 객체\ndef custom_pre_tokenizer(sequence): # 사용자 토큰 정의\n    # Define rules to combine tokens, e.g., \"new word\" -> \"newword\"\n    combined_sequence = sequence.replace(\"new word\", \"newword\")\n    return combined_sequence\n\n\n# 토큰 훈련. custom pre-tokenizer 활용함.\ntrainer = trainers.BpeTrainer()\ntokenizer.train(files=[\"path/to/training/data.txt\"], trainer=trainer, pre_tokenizer=custom_pre_tokenizer)\n\n\n# 훈련된 토큰 저장\ntokenizer.save(\"path/to/customized_tokenizer.json\")\n\n\n\n임베딩 모델 파인튜닝\n\n다음은 토큰을 추가하고, 임베딩 모델을 파인튜닝하는 보여준다.\n\n\nfrom transformers import BertTokenizerFast, BertModel\nimport torch\nfrom torch import nn\n\n\n# BERT 토크나이저 사전학습모델 로딩\ntokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\nprint(tokenizer.tokenize(\"[CLS] Hello world, how are you?\"))\n\n\nprint(tokenizer.tokenize(\"[newtoken] Hello world, how are you?\"))\ntokenizer.add_tokens(['[newtoken]'])\n\n\n다음과 같이, [newtoken] 토큰 추가 전 테스트. 토큰이 한단어가 아닌 분할 출력된 것 확인\n['[',\n 'newt',\n '##oke',\n '##n',\n ']',\n 'hello',\n 'world',\n ',',\n 'how',\n 'are',\n 'you',\n '?']\n\n\n토큰을 추가하고 다시 토큰화를 한다.\n\ntokenizer.add_tokens(['[newtoken]'])\ntokenizer.tokenize(\"[newtoken] Hello world, how are you?\")\n\n\n제대로 토큰화가 된다. \n['[newtoken]', 'hello', 'world', ',', 'how', 'are', 'you', '?']\n\n\n토큰값을 확인해 본다.\ntokenized = tokenizer(\"[newtoken] Hello world, how are you?\", add_special_tokens=False, return_tensors=\"pt\")\nprint(tokenized['input_ids'])\n\n\ntkn = tokenized['input_ids'][0, 0]\nprint(\"First token:\", tkn)\nprint(\"Decoded:\", tokenizer.decode(tkn))\n\n\n다음과 같이, 토큰값이 잘 할당된 것을 알 수 있다.\n\ntensor([[30522,  7592,  2088,  1010,  2129,  2024,  2017,  1029]])\nFirst token: tensor(30522)\nDecoded: [newtoken]\n\n\n임베딩 모델 학습을 위한 BERT 로딩하고, 앞의 토큰 리스트를 모델에 입력한다.\nmodel = BertModel.from_pretrained('bert-base-uncased')\nprint(model.embeddings)\n\n\ntry:\n    out = model(**tokenized)\n    out.last_hidden_state\nexcept Exception as e:\n    print(e)\n\n\n임베딩 모델이 추가된 토큰을 학습하지 않았으므로, out of range 에러가 출력될 것이다. \n다음 코드로 BERT 모델의토큰 공간 크기를 확인해 본다.\nweights = model.embeddings.word_embeddings.weight.data\nprint(weights.shape)\n\n\n출력은 다음과 같이 30522이다.\n\ntorch.Size([30522, 768])\n\n\n이제 [CLS] 토큰을 임베딩 모델에 추가해보자. \nnew_weights = torch.cat((weights, weights[101:102]), 0)\nnew_emb = nn.Embedding.from_pretrained(new_weights, padding_idx=0, freeze=False)\nprint(new_emb)\n\nUnderstanding BERT | Tokenization (tinkerd.net)\n\n\n다음과 같이 30523으로 토큰 크기가 증가되었다. \n\nEmbedding(30523, 768, padding_idx=0)\n\n\n새 레이어를 모델 마지막에 추가한다.\nmodel.embeddings.word_embeddings = new_emb\nprint(model.embeddings)\n\n\n그 결과로 임베딩 모델의 word_embeddings가 업데이트된다.\n\nBertEmbeddings(\n  (word_embeddings): Embedding(30523, 768, padding_idx=0)\n  (position_embeddings): Embedding(512, 768)\n  (token_type_embeddings): Embedding(2, 768)\n  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n)\n\n\n앞의 토큰 시퀀스 리스트를 입력한다. 그럼, 제대로 결과가 출력될 것이다.\nout = model(**tokenized)\nprint(out.last_hidden_state)\n\n\n다음 코드를 실행하면, 추가된 모델이 동일한 결과를 가지는 것을 알 수 있다.\nmodel = BertModel.from_pretrained('bert-base-uncased')\nout2 = model(\n    **tokenizer(\"[CLS] Hello world, how are you?\", add_special_tokens=False, return_tensors=\"pt\")\n)\n\n\nout3 = torch.all(out.last_hidden_state == out2.last_hidden_state)\noutput(out3)\n\n\n\n마무리\n\nLLM 파인튜닝이나 RAG 시 학습 데이터에 포함된 토큰에 대한 적절한 사전이 없으면, 제대로 학습되지 않는다. 이 글은 LLM NLP처리의 핵심인 토큰, 임베딩 모델 파인튜닝에 대한 내용을 간략히 다룬다. \n\n\n레퍼런스\n\nEnhance Your GPT Experience: Tiktoken Unveiled — Free Token Counting for Prompts (with Python Code!) | by Ilyes Rezgui | Medium\nhuggingface BertForMaskedLM fine-tuning (ai-bio.info)\nSplit by tokens | 🦜️🔗 LangChain\nhuggingface.co/tomaszki/llama-3-a/raw/main/vocab.json\nTokenTextSplitter\nNLP | How to add a domain-specific vocabulary (new tokens) to a subword tokenizer already trained like BERT WordPiece | by Pierre Guillou | Medium\nFine-tuning a large language model on Kaggle Notebooks (or even on your own computer) for solving real-world tasks (huggingface.co)\nLLaMA 2: A Detailed Guide to Fine-Tuning the Large Language Model | by Gobi Shangar | Medium\nFine-Tuning Large Language Model with Hugging Face & PyTorch | by Tuan Tran | Medium",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-5784072672755351339",
        "isoDate": "2024-06-20T02:42:00.000Z"
      }
    ]
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권영재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김병환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": [
      {
        "creator": "김준형",
        "title": "고소득자는 세금을 많이 내서 존중받아야 한다?!",
        "link": "https://medium.com/@ghilbut/%EA%B3%A0%EC%86%8C%EB%93%9D%EC%9E%90%EB%8A%94-%EC%84%B8%EA%B8%88%EC%9D%84-%EB%A7%8E%EC%9D%B4-%EB%82%B4%EC%84%9C-%EC%A1%B4%EC%A4%91%EB%B0%9B%EC%95%84%EC%95%BC-%ED%95%9C%EB%8B%A4-a1db27fa5086?source=rss-8482dec25ee1------2",
        "pubDate": "Sat, 22 Jun 2024 05:38:57 GMT",
        "content:encodedSnippet": "링크드인에 이름있는 스타트업의 대표가 쓴 글이다. 한국 사회의 단면을 보여준다. 주장의 빈약한 부분들을 짚어보자.\n\n사람은 모두 존중 받아야 한다. 소득과 세금에 따라 차등하는 가치가 아니다. 돈을 냈으니 반드시 존중을 받아내겠다는 자세가 지금 한국에 만연한 갑질 문화의 근원이다. 마이클 샐던의 ‘돈으로 살 수 없는 것들’에서 돈으로 가치 매김 할 수 없는 것에 가격표를 붙이면 부패한다고 했다. 존중은 대체 얼만큼의 고소득 및 세금과 교환할 수 있을까?\n연예인들과 유명인들도 구설수에 오르고 무고를 당한다. 우연히 유명해진 일반인들도 그렇다. 대기업 대표나 임원도 다르지 않다. 유명세에 따라오는 현상일 뿐이다. 단지, 구설수에 오른다고 사람들이 그들을 존중하지 않는다고 일반화 하는 것은 확대 해석의 오류이며, 소득과 세금을 이유로 존중을 강요하는 것은 매우 이상하다. 오히려 그들이 구설수에 오르는 이유는 그 대가를 받기에 충분한 역할과 결과가 있었는지 의문이 들기 때문일 수 있다. 큰 폭의 주가 하락이나 주주가치 훼손, 실적 악화와 대규모 정리해고 와중에도 대주주와 특정 임원들만 높은 연봉과 보너스를 받는다면 구설수에 오를 수 있지 않을까?\n존중은 받는 것이지 달라고 요구하는 것이 아니다. 우리는 한국이 여전히 유전무죄무전유죄의 국가라고 자평한다. 탈세에 관대하고 경제사범의 처벌이 매우 가벼우며 사기에 의한 수익의 환수와 피해의 복구가 불가능하다. 부당경쟁과 담합, 불공정 행위의 과징금이 매우 가벼워 오히려 불법을 장려한다. 땅콩회항, 라면상무, 네이버 직원 자살, 대기업들의 물적 분할에 의한 주식가치 훼손과 소액주주의 피해, 주식회사 임원들의 부도덕한 주식 처분에 의한 임직원들과 주주들의 피해, 유명인들과 부자들의 음주운전에 대한 관대한 처벌, 고가차량 소유주들의 각종 패악질 등 부를 쌓은 자들의 사회적 해악이 매일매일 기사에 오른다. 한줌 권력과 돈만 있으면 무슨 짓이든 해도 된다는 사회 부적응자들이 나날이 늘어난다. 반면에 고소득층의 부정적 인식을 강화하는 사건사고들에 대한 자정작용은 전무하다. 워런 버핏이 빌 게이츠와 같은 부자들에게 기부를 독려하고 기부하지 않는 부자들을 폄훼하는 것과 대조적이다. 이러한 상황에서 고소득자라는 이유만으로 존경심을 보이라는 것은 흡사 멕시코에서 마약상들을 존경하라는 것과 같다. 멕시코 마약 카르텔은 멕시코 경제에 매우 큰 기여를 한다.\n세금은 국가에 내는 지대비용이다. 고소득자가 세금을 더 많이 내는 이유 중에는 국가 인프라에 의한 이익을 더 많이 보았기 때문이 있다. 국가 인프라는 정부의 공공시스템과 도로/항만/공항/전기/수도 등 기간시설들이다. 한국의 가장 중요한 기간 시설들은 박정희 시대에 독일과 사우디 등에 파견되었던 노동자들이 벌어온 외화와 일제 강점기 피해의 대가로 얻어온 일본의 차관, 베트남 참전의 대가 등으로 구축되었다. 즉, 닭이 먼저냐 달걀이 먼저냐를 따지자면 고소득자들은 부모 세대의 피와 땀으로 구축된 인프라를 이용해 돈을 벌어 세금으로 사용료를 지불하는 것이다. 국가는 사용료를 받아 인프라를 유지/보수/확장하고 사회 안전망을 강화한다. 이는 기업의 영리활동과 다르지 않다.\n사회 안전망에 사용되는 세금은 고소득층이 저소득층에 내리는 은혜가 아니다. 사회 안전망이 무너지고 치안이 나빠지면 고소득자의 재산을 목표로 하는 폭력 범죄도 증가한다. 극단적으로 브라질이나 필리핀처럼 무장한 사설 경호원들이 가족들을 24시간 밀착 보호해야 할 수 있다. 그렇다고 사설 경호원이 모든 강력 범죄를 막아내지도 못한다. 필리핀에서 경찰들이 돈을 목적으로 한인 사업가를 납치 및 살해한 사건이 있었다. 심지어 무장 경비업체가 보호하는 타운하우스에서 일어난 일이다. 사회 안전망의 붕괴는 국내에서도 이런 범죄를 가능하게 할 수 있다. 세금을 내서 이런 불상사를 막는 것은 고소득층 자신들을 위한 것이기도 하다.\n전 세계적으로 양극화가 심화 될수록 소득에 따른 거주지 구분이 뚜렷해 진다. 그리고 돈이 많은 지역의 인프라와 편의 시설이 상대적으로 수준 높게 유지되고 개선된다. 한국에서 조사된 바는 없지만, 선진국의 연구에 의하면 고소득층의 환경에 쓰이는 세금이 그들이 내는 세금보다 많다. 즉, 낙후된 지역을 개선하는데는 재개발과 같이 매우 큰 재원이 필요하기 때문에 세금 투입에 큰 장벽이 있는 반면, 고소득층의 환경은 점진적 개선이 용이하기 때문에 꾸준하게 세금이 투입되고 있다. 저소득층의 거주지가 재개발된다고 해도 저소득층에게 이익이 돌아가는 것이 아니라 오히려 그들은 거주지에서 쫒겨나고 쾌적한 환경은 더 부유한 사람들에게 돌아간다. 즉, 고소득자들이 내는 세금은 그들의 주거 환경을 위해 재사용되는 부분이 많다.\n한국은 부동산 정책을 부양하고 금융기업들과 대기업들을 지원하는데 막대한 세금을 쓰고 있다. 이는 고소득층의 수익과 재산을 보전하고 증식하는데 기여한다. 즉, 자신들의 세금은 자신들의 재산을 위해 쓰이고 있다.\n세금에는 재산세와 소득세 같은 직접세도 있지만, 유류와 공산품등에 붙는 간접세도 있다. 일부 경제학자들과 사회학자들에 의하면 직접세와 간접세를 모두 합하면, 고소득자와 고액자산가의 세금이 저소득층과 취약계층에게 충분히 분배되고 있는가에 대해 난색을 표하는 의견들도 있다. 오히려 소비의 상대적 가치를 계산하면 가난할수록 단위 소비에 드는 비용과 세금이 더 비싸다는 주장도 있다. 이런 연구들은 높은 세금을 내는 사람들이 충분히 많은 기여를 한다는 주장을 약화시킨다.\n세금을 통한 부의 재분배는 전적으로 국가의 예산 집행에 달려있다. 정부의 예산 배분에 따라 고소득층의 세금으로 저소득층이 받는 혜택은 미미할 수 있다. 또한, 채권을 통해 적자 재정을 운영한다면 저소득층 지원이 세금에 의한 것인지 국가 채무에 의한 것인지도 모호하다. 따라서 높은 세금에 대한 대가는 저소득층이 아닌 국가에게 주장해야 맞다.\n고소득층이 세금을 많이 내는 만큼 존경받고 싶다면, 부정축재와 부패를 배격하고 그들의 소득이 투명하고 정당한 경제활동을 통해 축적되었다는 이미지를 구축하는 것이 우선이다. 또한, 세금이 부동산 부양이나 포퓰리즘보다는 국가 시스템과 사회 안전망을 위해 올바르게 쓰이도록 정치적인 압력을 행사하는 모습을 보이는 것 또한 필요하다. 그리고 소득과 재산이 많더라도 윤리와 품격을 갖추지 않는 자들은 무리에 어울릴 수 없다는 모습을 보여야 한다. 이러한 품격을 대중이 알게 된다면 없던 존중과 존경도 절로 샘솟을 것이다. 현재의 한국은 무슨 짓을 해도 돈만 많으면 된다는 인식이 확대되고 있기 때문에 고소득자의 이미지도 마냥 긍정적일 수만은 없다.\n\n옳은 일은 꾸준히 해도 주변에서 알기 힘들다. 보통 100을 잘해도 자연스럽게 드러나는 것은 겨우 1 정도 뿐이며, 그마저도 드러나는데 매우 긴 시간이 걸린다. 그리고 존경 받는 사람들은 그 꾸준함의 끝에서 우연히 대중에게 발견되기 때문에 가치가 있는 것이다. 세금을 많이 내기 때문이 아니라…",
        "dc:creator": "김준형",
        "guid": "https://medium.com/p/a1db27fa5086",
        "categories": [
          "noblesse-oblige",
          "wealth",
          "taxes",
          "respect"
        ],
        "isoDate": "2024-06-22T05:38:57.000Z"
      }
    ]
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김상훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "Splunk의 eval과 rex - 4th",
        "link": "https://kangmyounghun.blogspot.com/2024/06/splunk-eval-rex-4th.html",
        "pubDate": "2024-06-23T05:25:00.001Z",
        "author": "강명훈",
        "content": "<div><span style=\"font-family: courier;\">.</span>을 기준으로 첫 번째 문자열을 추출하는 정규표현식.</div><div><br /></div>\n<table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhxAzokGS4mQzX9sc7bwFX8S1rEWWROzmoEzRNaxExcyHy0YR-JbTxaOxIvtkAQWG8222PvTUOuUnCOqJR6ErRHgyNo5bP9TIY8KqwxQj2IbOZZzMiCvCy5xlTn11cFbQwrmP-y4eD-IVVotoyE2EG_IAPjmJKXzq7mZG5oGdbYFL2tzslRNvlzZibmtqVF/s1280/regex.png\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"613\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhxAzokGS4mQzX9sc7bwFX8S1rEWWROzmoEzRNaxExcyHy0YR-JbTxaOxIvtkAQWG8222PvTUOuUnCOqJR6ErRHgyNo5bP9TIY8KqwxQj2IbOZZzMiCvCy5xlTn11cFbQwrmP-y4eD-IVVotoyE2EG_IAPjmJKXzq7mZG5oGdbYFL2tzslRNvlzZibmtqVF/s520/regex.png\" width=\"520\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><b>한 줄 테스트</b></td></tr></tbody></table><div><br /></div><div><span><a name='more'></a></span>rex에서는 잘 동작한다.</div><div><br /></div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjILbQ_pVKUvQygEgXFWZVzDYu0_UuPjj37PeXph-RHPIMTdUZFuNfdW2s-4II_ePPAjSAbDHS12vPBedNOSECy94enrnWACEC42kEKKoDMOVMGT7fenwJNvnapJ7JE4A24lCAvuwzlHcX9_cK7pV2v7s21KqvIexLbDFmnXUDMBqAze8ic9oPCCyyGqZ1a/s991/splunk_rex.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"991\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjILbQ_pVKUvQygEgXFWZVzDYu0_UuPjj37PeXph-RHPIMTdUZFuNfdW2s-4II_ePPAjSAbDHS12vPBedNOSECy94enrnWACEC42kEKKoDMOVMGT7fenwJNvnapJ7JE4A24lCAvuwzlHcX9_cK7pV2v7s21KqvIexLbDFmnXUDMBqAze8ic9oPCCyyGqZ1a/s520/splunk_rex.png\" width=\"520\" /></a></div><br /><div>그런데 같은 정규표현식이 eval replace 함수에서는 다른 결과를 가져옴.</div></div><br />\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgfc-ZwLVQ2t8YBN2DLQKNb9KTbhCIkpEVH7AWJNlhnOm9wFVz0mUPoJOp0p29CIOvaJaqvQRNR43JzPaFCsrQu3zPXrE-9NwV8mLBdAerDSKIncAS2m88Q4wM1J1wGMP9w8kbo6LSVAhYxAExde2Tg4dB9DuvGXf5JPvHB48SZvBQaCMeV_G01vvpBmGD0/s991/splunk_eval_replace.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"991\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgfc-ZwLVQ2t8YBN2DLQKNb9KTbhCIkpEVH7AWJNlhnOm9wFVz0mUPoJOp0p29CIOvaJaqvQRNR43JzPaFCsrQu3zPXrE-9NwV8mLBdAerDSKIncAS2m88Q4wM1J1wGMP9w8kbo6LSVAhYxAExde2Tg4dB9DuvGXf5JPvHB48SZvBQaCMeV_G01vvpBmGD0/s520/splunk_eval_replace.png\" width=\"520\" /></a></div><div><br /></div><div>이유는 Message 필드가 단일값이 아닌 다중값이기 때문. 정규표현식이 모든 줄 단위 검색 결과를 가져왔다는 얘기.</div><div><br /></div>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiB7wdA22j-aXegKk__HCcyjifYdzi7ySAfNdN5SzzQG6EJ5RAtQgn97YYdputJZR9irpM6PgMMM64jz2Oy11Cvpvf2wPnu_dZMUshdSzKNcJdgETgNh0lodaqNnogEjeRLMBiMTaFI7hFS3Bkr2Zm_nh5QNY8YcWIEdj3-uzr2xAsFkjTDfyQMs0FduiDU/s1280/multi_values.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"667\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiB7wdA22j-aXegKk__HCcyjifYdzi7ySAfNdN5SzzQG6EJ5RAtQgn97YYdputJZR9irpM6PgMMM64jz2Oy11Cvpvf2wPnu_dZMUshdSzKNcJdgETgNh0lodaqNnogEjeRLMBiMTaFI7hFS3Bkr2Zm_nh5QNY8YcWIEdj3-uzr2xAsFkjTDfyQMs0FduiDU/s520/multi_values.png\" width=\"520\" /></a></div><div><br /></div><b><span style=\"font-size: x-large;\">rex는 왜 다를까?</span></b><div><br /></div><div>정규표현식은 패턴 일치가 발생하는 순간 검색을 중단하는 게 기본 동작. 일치하는 모든 패턴을 검색하려면 글로벌<span style=\"font-size: x-small;\">(g)</span> 모드를 사용해야 한다. <span style=\"font-size: x-small;\">(글로벌 모드 지원 여부는 환경에 따라 다름)</span></div><div><br /></div>\n<table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgI8YhyiKZmu9Td0LikklKil85u6Jxp46BmWjVI52AhC_cSBqYc_YZZpgnqQVZX8cTonCBIvqId8i_YdPVNZOA22YSVXfoQuigbOFxdrFFkk3qt-0xhyphenhyphenN3wZGRYZdWN9dCtMXFsoHvLrqrZfGOTlekYzy37HoXrACBfxayamWt9XQv4h80wiRjCHctAUaC5/s1105/regex_global.png\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1105\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgI8YhyiKZmu9Td0LikklKil85u6Jxp46BmWjVI52AhC_cSBqYc_YZZpgnqQVZX8cTonCBIvqId8i_YdPVNZOA22YSVXfoQuigbOFxdrFFkk3qt-0xhyphenhyphenN3wZGRYZdWN9dCtMXFsoHvLrqrZfGOTlekYzy37HoXrACBfxayamWt9XQv4h80wiRjCHctAUaC5/s520/regex_global.png\" width=\"520\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><b>두 줄 테스트</b></td></tr></tbody></table><br />\n<div>다음은 rex <a href=\"https://docs.splunk.com/Documentation/Splunk/9.2.1/SearchReference/Rex#Optional_arguments\" target=\"_blank\">max_match</a> 제한<span style=\"font-size: x-small;\">(기본값 1: 1회 검색)</span>을 해제한 결과. 정규표현식에서 글로벌 모드를 사용한 결과, eval replace 함수와 같은 결과를 보여준다.&nbsp;</div><div><br /></div><div>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhEpXKQJKK0I7BFkSsmu6_idtmk7hCJTtt7ivGLF_dT2Omg3qx6-59jOELEfE7ce-cqSY8OcPYCgx1odgl6EJAucTIjsACp8Z78o0FL9C-SUV48DBRh8Zx2tFr43_2h-bqIiaHC4x_P9HkSSWpBonkCIlGHV8JCnKK93eTHpwzTWOn0JC54MpdfHRZ6_jHj/s988/splunk_rex_max_match.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"988\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhEpXKQJKK0I7BFkSsmu6_idtmk7hCJTtt7ivGLF_dT2Omg3qx6-59jOELEfE7ce-cqSY8OcPYCgx1odgl6EJAucTIjsACp8Z78o0FL9C-SUV48DBRh8Zx2tFr43_2h-bqIiaHC4x_P9HkSSWpBonkCIlGHV8JCnKK93eTHpwzTWOn0JC54MpdfHRZ6_jHj/s520/splunk_rex_max_match.png\" width=\"520\" /></a></div><br />\n<div>eval replace 함수는 글로벌 모드를 기본 사용한다는 얘기. 그런데 이걸 조절하는 옵션은 따로 제공하지 않는다. 정규표현식이 줄 구분을 무시하도록 <a href=\"https://www.regular-expressions.info/modifiers.html\" target=\"_blank\">한 줄<span style=\"font-size: x-small;\">(single line)</span> 검색 모드</a> 적용.</div><div><br /></div>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj8xvPtLe10yw46YkxldZJU-rqxqN_THWDJW-xw3Wxzh4yG6seEMWRoMU1HyLpaS1RBkT4O3H2_34Tqg37tEMwG9rGGVddLBSHXLwc6dPilNnqs1NpyzadFsh67veujJEbr6oSYH06dIZvVVYL8o6vhbYD5SkFte5tKXIKDwXC5iSxEb7DviFAiLwoZPQbF/s960/splunk_eval_replace_single_line.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"960\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj8xvPtLe10yw46YkxldZJU-rqxqN_THWDJW-xw3Wxzh4yG6seEMWRoMU1HyLpaS1RBkT4O3H2_34Tqg37tEMwG9rGGVddLBSHXLwc6dPilNnqs1NpyzadFsh67veujJEbr6oSYH06dIZvVVYL8o6vhbYD5SkFte5tKXIKDwXC5iSxEb7DviFAiLwoZPQbF/s520/splunk_eval_replace_single_line.png\" width=\"520\" /></a></div><div><br /></div>\n<table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEifN0DRpbgIEBOVpJRsvdscGnb5GR-SkqDoFnGJRD5w6hRM8OD0skGDy5oEKW0vqBXq9H8NfEeMDxJQUhsUR6Im5BlRDrwrsHiBUZyvW-ckRtw7Jlhq0eJ57e8EvMmnjnTyAXmFXTxgPAMiPEv3xTblPtMCFVD7nCENY-6GIC5uCiCcpl3HdSleMBTZg64p/s1280/regex_single_line.png\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"616\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEifN0DRpbgIEBOVpJRsvdscGnb5GR-SkqDoFnGJRD5w6hRM8OD0skGDy5oEKW0vqBXq9H8NfEeMDxJQUhsUR6Im5BlRDrwrsHiBUZyvW-ckRtw7Jlhq0eJ57e8EvMmnjnTyAXmFXTxgPAMiPEv3xTblPtMCFVD7nCENY-6GIC5uCiCcpl3HdSleMBTZg64p/s520/regex_single_line.png\" width=\"520\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><b>두 줄 테스트</b></td></tr></tbody></table><div><br /></div><div>참고로 rex는 이렇게 해도 된다. 1회 검색이 기본이라 첫 번째 줄만 검색하기 때문.</div><div><br /></div>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjD9nOQAhoEDbROg2eZ2IAnaKOz_AOWbCNtoNK0SQvYXaN4qS1DPzuyIUI88781zi9MEEuQlgow-G7IMOnHkpF6haqc22GR7lweKatcVm-bj6U16TD8ZmcKmn40mwpsjOd2xJc0ACkQz1aeBbmvMiHCfPNPorBdw6ZwgX3VBsKTCub97gQBlDOxvlovD9aP/s905/splunk_rex2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"905\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjD9nOQAhoEDbROg2eZ2IAnaKOz_AOWbCNtoNK0SQvYXaN4qS1DPzuyIUI88781zi9MEEuQlgow-G7IMOnHkpF6haqc22GR7lweKatcVm-bj6U16TD8ZmcKmn40mwpsjOd2xJc0ACkQz1aeBbmvMiHCfPNPorBdw6ZwgX3VBsKTCub97gQBlDOxvlovD9aP/s520/splunk_rex2.png\" width=\"520\" /></a></div><div><br /></div><div><div><b>관련 글</b></div><div><ul><li><a href=\"https://kangmyounghun.blogspot.com/2024/05/splunk-eval-rex-3rd.html\">Splunk의 eval과 rex - 3rd</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2021/08/splunk-eval-rex.html\">Splunk의 eval과 rex</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2024/02/splunk_25.html\">Splunk의 조건문</a></li></ul></div></div></div>",
        "contentSnippet": ".을 기준으로 첫 번째 문자열을 추출하는 정규표현식.\n\n\n\n\n한 줄 테스트\n\n\n\nrex에서는 잘 동작한다.\n\n\n\n\n그런데 같은 정규표현식이 eval replace 함수에서는 다른 결과를 가져옴.\n\n\n\n\n이유는 Message 필드가 단일값이 아닌 다중값이기 때문. 정규표현식이 모든 줄 단위 검색 결과를 가져왔다는 얘기.\n\n\n\n\nrex는 왜 다를까?\n\n정규표현식은 패턴 일치가 발생하는 순간 검색을 중단하는 게 기본 동작. 일치하는 모든 패턴을 검색하려면 글로벌(g) 모드를 사용해야 한다. (글로벌 모드 지원 여부는 환경에 따라 다름)\n\n\n\n\n두 줄 테스트\n\n\n다음은 rex max_match 제한(기본값 1: 1회 검색)을 해제한 결과. 정규표현식에서 글로벌 모드를 사용한 결과, eval replace 함수와 같은 결과를 보여준다. \n\n\n\n\neval replace 함수는 글로벌 모드를 기본 사용한다는 얘기. 그런데 이걸 조절하는 옵션은 따로 제공하지 않는다. 정규표현식이 줄 구분을 무시하도록 한 줄(single line) 검색 모드 적용.\n\n\n\n\n\n\n\n두 줄 테스트\n\n\n\n참고로 rex는 이렇게 해도 된다. 1회 검색이 기본이라 첫 번째 줄만 검색하기 때문.\n\n\n\n\n\n관련 글\n\nSplunk의 eval과 rex - 3rd\nSplunk의 eval과 rex\nSplunk의 조건문",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-4087014396549553775",
        "isoDate": "2024-06-23T05:25:00.001Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕홍",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": [
      {
        "title": "데이터 중심 애플리케이션 설계(Designing Data-Intensive Applications)",
        "link": "https://sungjk.github.io/2024/06/22/ddia.html",
        "pubDate": "2024-06-22T00:00:00+00:00",
        "content": "\n            \n            &lt;h2 id=&quot;1장-신뢰할-수-있고-확장-가능하며-유지보수하기-쉬운-애플리케이션&quot;&gt;1장. 신뢰할 수 있고 확장 가능하며 유지보수하기 쉬운 애플리케이션&lt;/h2&gt;\n\n&lt;p&gt;p.6&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;신뢰성(Reliability)&lt;/strong&gt;\n하드웨어나 소프트웨여 결함, 심지어 인적 오류(human error) 같은 역경에 직면하더라도 시스템은 지속적으로 올바르게 동작(원하는 성능 수준에서 정확한 기능을 수행)해야 한다.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;확장성(Scalability)&lt;/strong&gt;\n시스템의 데이터 양, 트래픽 양, 복잡도가 증가하면서 이를 처리할 수 있는 적절한 방법이 있어야 한다.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;유지보수성(Maintainability)&lt;/strong&gt;\n시간이 지남에 따라 여러 다양한 사람들이 시스템 상에서 작업(현재 작업을 유지보수하고 새로운 사용 사례를 시스템에 적용하는 엔지니어링과 운영)할 것이기 때문에 모든 사용자가 시스템 상에서 생산적으로 작업할 수 있게 해야 한다.&lt;/p&gt;\n\n&lt;p&gt;p.6-7&lt;/p&gt;\n\n&lt;p&gt;소프트웨어의 일반적인 기대치&lt;/p&gt;\n&lt;ul&gt;\n  &lt;li&gt;애플리케이션 사용자가 거대한 기능을 수행한다.&lt;/li&gt;\n  &lt;li&gt;시스템은 사용자가 범한 실수나 예상치 못한 소프트웨어 사용법을 허용할 수 있다.&lt;/li&gt;\n  &lt;li&gt;시스템 성능은 예상된 부하와 데이터 양에서 필수적인 사용 사례를 충분히 만족한다.&lt;/li&gt;\n  &lt;li&gt;시스템은 허가되지 않은 접근과 오남용을 방지한다.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;잘못될 수 있는 일을 결함(fault)이라 부른다. 그리고 결함을 예측하고 대처할 수 있는 시스템을 내결함성(fault-tolerant) 또는 탄력성(resilient)을 지녔다고 말한다.&lt;/p&gt;\n\n&lt;p&gt;결함은 장애(failure)와 동일하지 않다. 일반적으로 결함은 사양에서 벗어난 시스템의 한 구성 요소로 정의되지만, 장애는 사용자에게 필요한 서비스를 제공하지 못하고 시스템 전체가 멈춘 경우다. … 대개 결함으로 인해 장애가 발생하지 않게끔 내결함성 구조를 설계하는 것이 가장 좋다.&lt;/p&gt;\n\n&lt;p&gt;p.9-10&lt;/p&gt;\n\n&lt;p&gt;대규모 인터넷 서비스에 대한 한 연구에 따르면 운영자의 설정 오류가 중단의 주요원인인 반면 하드웨어(서버나 네트워크) 결함은 중단 원인의 10~25% 정도에 그친다.&lt;/p&gt;\n&lt;ul&gt;\n  &lt;li&gt;오류의 가능성을 최소화하는 방향으로 시스템을 설계하라&lt;/li&gt;\n  &lt;li&gt;사람의 실수로 장애가 발생할 수 있는 부분을 분리하라&lt;/li&gt;\n  &lt;li&gt;모든 수준에서 철저하게 테스트하라&lt;/li&gt;\n  &lt;li&gt;인적 오류를 빠르고 쉽게 복구할 수 있게 하라&lt;/li&gt;\n  &lt;li&gt;모니터링 대책을 마연하라&lt;/li&gt;\n  &lt;li&gt;조작 교육과 실슴을 시행하라&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;p.11\n부하는 &lt;strong&gt;부하 매개변수(load paramter)&lt;/strong&gt;라 부르는 몇 개의 숫자로 나타낼 수 있다. … 부하 매개변수로 웹 서버의 초당 요청 수, 데이터베이스의 읽기 대 쓰기 비율, 대화방의 동시 활성 사용자(active user), 캐시 적중률 등이 될 수 있다.&lt;/p&gt;\n\n&lt;p&gt;p.19 유지보수성&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;운용성(operability)&lt;/strong&gt;\n운영팀이 시스템을 원활하게 운영할 수 있게 쉽게 만들어라.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;단순성(Simplicity)&lt;/strong&gt;\n시스템에서 복잡도를 최대한 제거해 새로운 엔지니어가 시스템을 이해하기 쉽게 만들어라(사용자 인터페이스의 단순성과는 다르다는 점에 유의하라).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;발전성(Evolvability)&lt;/strong&gt;\n엔지니어가 이후에 시스템을 쉽게 변경할 수 있게 하라. 그래야 요구사항 변경 같은 예기치 않은 사용 사례를 적용하기 쉽다. 이 속성은 유연성(extensibility), 수정 가능성(modifiability), 적응성(plasticity)으로 알려져 있다.&lt;/p&gt;\n\n&lt;p&gt;p.20 좋은 운영성&lt;/p&gt;\n&lt;ul&gt;\n  &lt;li&gt;좋은 모니터링으로 런타임(runtime) 동작과 시스템의 내부에 대한 가시성 제공&lt;/li&gt;\n  &lt;li&gt;표준 도구를 이용해 자동화와 통합을 위한 우수한 지원을 제공&lt;/li&gt;\n  &lt;li&gt;개별 장비 의존성을 회피. 유지보수를 위해 장비를 내리더라도 시스템 전체에 영향을 주지 않고 계속해서 운영 가능해야 함&lt;/li&gt;\n  &lt;li&gt;좋은 문서와 이해하기 쉬운 운영 모델(예를 들어 “X를 하면 Y가 발생한다”) 제공&lt;/li&gt;\n  &lt;li&gt;만족할 만한 기본 동작을 제공하고, 필요할 때 기본값을 다시 정의할 수 있는 자유를 관리자에게 부여&lt;/li&gt;\n  &lt;li&gt;적절하게 자기 회복(self-healing)이 가능할 뿐 아니라 필요에 따라 관리자가 시스템 상태를 수동으로 제어할 수 있게 함&lt;/li&gt;\n  &lt;li&gt;예측 가능하게 동작하고 예기치 않은 상황을 최소화함&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;hr /&gt;\n\n&lt;h2 id=&quot;2장-데이터-모델과-질의-언어&quot;&gt;2장. 데이터 모델과 질의 언어&lt;/h2&gt;\n\n&lt;p&gt;p.32 지역성(locality). JSON 표현에서는 모든 관련 정보가 한 곳에 있어 질의 하나로 충분하다.&lt;/p&gt;\n\n&lt;p&gt;p.40 쓰기 스키마(schema-on-write)(관계형 데이터베이스의 전통적인 접근 방식으로 스키마는 명시적이고 데이터 베이스는 쓰여진 모든 데이터가 스키마를 따르고 있음을 보장한다)와 반대되는 읽기 스키마(schema-on-read)(데이터 구조는 암묵적이고 데이터를 읽을 때만 해석된다)&lt;/p&gt;\n\n&lt;p&gt;p.43 선언형 질의\nSQL이나 관계 대수 같은 선언형 질의 언어에서는 목표를 달성하기 위한 방법이 아니라,  알고자 하는 데이터의 패턴, 즉 결과가 충족해야 하는 조건과 데이터를 어떻게 변환(예를 들어 정렬, 그룹화, 집계)할지를 지정하기만 하면 된다.&lt;/p&gt;\n\n&lt;hr /&gt;\n\n&lt;h2 id=&quot;3장-저장소와-검색&quot;&gt;3장: 저장소와 검색&lt;/h2&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;p.72 특정 작업부(workload) 유형에서 좋은 성능을 내게끔 저장소 엔진을 조정하려면 저장소 엔진이 내부에서 수행되는 작업에 대해 대략적인 개념을 이해할 필요가 있다.&lt;/li&gt;\n  &lt;li&gt;p.74 색인을 잘 선택했다면 읽기 질의 속도가 향상된다. 하지만 모든 색인은 쓰기 속도를 떨어뜨린다.&lt;/li&gt;\n  &lt;li&gt;p.74 키를 데이터 파일의 바이트 오프셋에 매핑해 인메모리 해시 맵을 유지하는 전략이다.&lt;/li&gt;\n  &lt;li&gt;p.74 값을 조회하려면 해시 맵을 사용해 데이터 파일에서 오프셋을 찾아 해당 위치를 구하고 값을 읽는다.&lt;/li&gt;\n  &lt;li&gt;p.75 컴팩션은 로그에서 중복된 키를 버리고 각 키의 최신 갱신 값만 유지하는 것을 의미한다.&lt;/li&gt;\n  &lt;li&gt;p.77 불행하게도 디스크 상의 해시 맵에 좋은 성능을 기대하기란 어렵다. 이는 무작위 접근 I/O가 많이 필요하고 디스크가 가득 찼을 때 확장하는 비용이 비싸며 해시 충돌 해소를 위해 성가신 로직이 필요하다.&lt;/li&gt;\n  &lt;li&gt;p.78 해시 테이블은 범위 질의(range query)에 효율적이지 않다.&lt;/li&gt;\n  &lt;li&gt;p.79 그래도 handbag과 handsome 키의 오프셋을 알고 있고 정렬돼 있으므로 handiwork는 두 키 사이에 있다는 사실을 알 수 있다.&lt;/li&gt;\n  &lt;li&gt;p.80 저장소 엔진\n    &lt;ul&gt;\n      &lt;li&gt;쓰기가 들어오면 인메모리 균형 트리(balanced tree) 데이터 구조(예를 들어 레드 블랙 트리)에 추가한다. 이 인메모리 트리는 멤테이블(memtable)이라고도 한다.&lt;/li&gt;\n      &lt;li&gt;멤테이블이 보통 수 메가바이트 정도의 임곗값보다 커지면 SS테이블 파일로 디스크에 기록한다. 트리가 이미 키로 정렬된 키-값 쌍을 유지하고 있기 때문에 효율적으로 수행할 수 있다. 새로운 SS테이블 파일은 데이터베이스의 가장 최신 세그먼트가 된다. SS테이블을 디스크에 기록하는 동안 쓰기는 새로운 멤테이블 인스턴스에 기록한다.&lt;/li&gt;\n      &lt;li&gt;읽기 요청을 제공하려면 먼저 멤테이블에서 키를 찾아야 한다. 그다음 디스크 상의 가장 최신 세그먼트에서 찾는다. 그다음으로 두 번째 오래된 세그먼트, 세 번째 오래된 세그먼트 등에서 찾는다.&lt;/li&gt;\n      &lt;li&gt;가끔 세그먼트 파일을 합치고 덮어 쓰여지거나 삭제된 값을 버리는 병합과 컴팩션 과정을 수행한다. 이 과정은 백그라운드에서 수행된다.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;p.80 정렬된 파일 병합과 컴팩션 원리를 기반으로 하는 저장소 엔진을 LSM 저장소 엔진이라 부른다.&lt;/li&gt;\n  &lt;li&gt;p.81 키를 단어(용어)로, 값은 단어를 포함한 모든 문서의 ID 목록(포스팅 목록(postings list))으로 하는 키-값 구조로 구현한다.&lt;/li&gt;\n  &lt;li&gt;p.81 블룸 필터는 키가 데이터베이스에 존재하지 않음을 알려주므로 존재하지 않는 키를 위한 불필요한 디스크 읽기를 많이 절약할 수 있다.&lt;/li&gt;\n  &lt;li&gt;p.81 백그라운드에서 연쇄적으로 SS테이블을 지속적으로 병합하는 것이다. 이 개념은 데이터셋이 가능한 메모리보다 훨씬 더 크더라도 여전히 효과적이다. 데이터가 정렬된 순서로 저장돼 있다면 범위 질의를 효율적으로 실행할 수 있다.&lt;/li&gt;\n  &lt;li&gt;p.82 B 트리는 전통적으로 4KB 크기(때로는 더 큰)의 고정 크기 블록이나 페이지로 나누고 한 번에 하나의 페이지에 읽기 또는 쓰기를 한다. 디스크가 고정 크기 블록으로 배열되기 때문에 이런 설계는 근본적으로 하드웨어와 조금 더 밀접한 관련이 있다.&lt;/li&gt;\n  &lt;li&gt;p.83 새로운 키를 수용한 페이지에 충분한 여유 공간이 없다면 페이지 하나를 반쯤 채워진 페이지 둘로 나누고 상위 페이지가 새로운 키 범위의 하위 부분들을 알 수 있게 갱신한다.&lt;/li&gt;\n  &lt;li&gt;p.99 칼럼 지향 저장소. 모든 값을 하나의 로우에 함께 저장하지 않는 대신 각 칼럼별로 모든 값을 함께 저장한다. 각 칼럼을 개별 파일에 저장하면 질의에 사용되는 칼럼만 읽고 구분 분석하면 된다. 이 방식을 사용하면 작업량이 많이 줄어든다.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;hr /&gt;\n\n&lt;h2 id=&quot;05장-복제&quot;&gt;05장: 복제&lt;/h2&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;p.156 동기식 복제의 장점은 팔로워가 리더와 일관성 있게 최신 데이터 복사본을 가지는 것을 보장한다. 갑자기 리더가 작동하지 않아도 데이터는 팔로워에서 계속 사용할 수 있음을 확신할 수 있다. 단점은 (팔로워가 죽거나 네트워크 문제나 다른 어떤 이유로 인해) 동기 팔로워가 응답하지 않는다면 쓰기가 처리될 수 없다는 것이다. 리더는 모든 쓰기를 차단(block)하고 동기 복제 서버가 다시 사용할 수 있을때까지 기다려야 한다.&lt;/li&gt;\n  &lt;li&gt;p.159 팔로워 중 하나를 새로운 리더로 승격해야 하고 클라이언트는 새로운 리더로 쓰기를 전송하기 위해 재설정이 필요하며 다른 팔로워는 새로운 리더로부터 데이터 변경을 소비하기 시작해야 한다. 이 과정을 장애 복구(failover)라 한다.&lt;/li&gt;\n  &lt;li&gt;p.167 Monotonic Read: 각 사용자의 읽기가 항상 동일한 복제 서버에서 수행되게끔 하는 것&lt;/li&gt;\n  &lt;li&gt;p.168 Consistent Prefix Read: 일련의 쓰기가 특정 순서로 발생한다면 이 쓰기를 읽는 모든 사용자는 같은 순서로 쓰여진 내용을 보게 됨을 보장한다.&lt;/li&gt;\n  &lt;li&gt;p.174 충돌을 처리하는 제일 간단한 전략은 충돌을 피하는 것이다. 특정 레코드의 모든 쓰기가 동일한 리더를 거치도록 애플리케이션이 보장한다면 충돌은 발생하지 않는다.&lt;/li&gt;\n  &lt;li&gt;p.175 Automatic Conflict Resolution\n    &lt;ul&gt;\n      &lt;li&gt;&lt;a href=&quot;https://assets.amazon.science/ac/1d/eb50c4064c538c8ac440ce6a1d91/dynamo-amazons-highly-available-key-value-store.pdf&quot;&gt;Dynamo: Amazon’s Highly Available Key-value Store&lt;/a&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;p.179 Dynamo Style: 리더의 개념을 버리고 모든 복제 서버가 클라이언트로부터 쓰기를 직접 받을 수 있게 허용하는 접근 방식&lt;/li&gt;\n  &lt;li&gt;p.180 Outdated 해결: 클라이언트가 데이터베이스에서 읽을 때 하나의 복제 서버로 요청을 보내지 않고 읽기 요청을 병렬로 여러 노드에 전송. 클라이언트는 여러 노드에서 다른 응답을 받음. 즉, 한 노드에서는 최신 값을 받고 다른 노드에서는 오래된 값을 받음. 이 때 버전 숫자를 사용해 어떤 값이 최신 내용인지 결정.&lt;/li&gt;\n  &lt;li&gt;p.180 Anti-entropy\n    &lt;ul&gt;\n      &lt;li&gt;&lt;a href=&quot;https://medium.com/@adityashete009/anti-entropy-and-merkel-trees-amazon-dynamodb-part-4-efbf1f7285c0&quot;&gt;Anti-Entropy and Merkel Trees: Amazon DynamoDB (Part 4)&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=&quot;https://www.hemantkgupta.com/p/insights-from-paper-part-ii-dynamo&quot;&gt;Insights from paper (Part II) — Dynamo: Amazon’s Highly Available Key-value Store&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=&quot;https://efficientcodeblog.wordpress.com/2017/12/26/read-repair-and-anti-entropy-two-ways-to-remedy-replication-lag-in-dynamo-style-datastores-leaderless-replication/&quot;&gt;Read Repair and Anti-Entropy : Two Ways To Remedy Replication Lag in Dynamo-style Datastores (Leaderless Replication)&lt;/a&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;p.188. Concurrent: 한 작업이 다른 작업 이전에 발생했는지가 동시성의 의미를 정의하는 핵심. 사실 작업이 다른 작업보다 먼저 발생하지 않으면 (즉 어느 작업도 다른 작업에 대해 알지 못한다면) 단순히 동시 작업이라 말한다.\n    &lt;ul&gt;\n      &lt;li&gt;동시성을 정의하기 위해 정확한 시각은 중요하지 않다. 두 작업이 발생한 물리적인 시각보다 각 작업이 서로 알지 못하면 단순히 두 작업은 동시에 수행됐다 말한다.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;hr /&gt;\n\n&lt;h2 id=&quot;06장-파티셔닝&quot;&gt;06장: 파티셔닝&lt;/h2&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;p199 데이터셋이 매우 크거나 질의 처리량이 매우 높다면 복제만으로는 부족하고 데이터를 파티션으로 쪼갤 필요가 있다. 이 작업을 샤딩이라고도 한다.&lt;/li&gt;\n  &lt;li&gt;p200 파티셔닝하는 주된 이유는 확장성.  단일 파티션에 실행되는 질의를 생각해 보면 각 노드에서 자신의 파티션에 해당하는 질의를 독립적으로 실행할 수 있으므로 노드를 추가함으로써 질의 처리량을 늘릴 수 있다. 크고 복잡한 질의는 훨씬 더 어렵기는 하지만 여러 노드에서 병렬 실행이 가능하다.&lt;/li&gt;\n  &lt;li&gt;p203 키 범위 기준 파티셔닝은 특정한 접근 패턴이 핫스팟을 유발하는 단점이 있다.&lt;/li&gt;\n  &lt;li&gt;p203 좋은 해시 함수는 쏠린 데이터를 입력으로 받아 균일하게 분산되게 한다.&lt;/li&gt;\n  &lt;li&gt;p204 파티셔닝에 키의 해시값을 사용해서 파티셔닝하면 키 범위 파티셔닝의 좋은 속성을 잃어 버린다. 바로 범위 질의를 효율적으로 실행할 수 있는 능력이다. 전에는 인접했던 키들이 이제는 모든 파티션에 흩어져서 정렬 순서가 유지되지 않는다.&lt;/li&gt;\n  &lt;li&gt;p204 복합 키의 첫 번째 컬럼에 값 범위로 검색하는 질의를 쓸 수 없지만,  첫 번째 칼럼에 고정된 값을 지정하면 키의 다른 컬럼에 대해서는 범위 스캔 가능&lt;/li&gt;\n  &lt;li&gt;Partitioning Secondary Indexes by Document:\n    &lt;ul&gt;\n      &lt;li&gt;p207 각 파티션이 독립적. 자신의 보조 인덱스를 유지하며 그 파티션에 속하는 문서만 담당. 다른 파티션에 어떤 데이터가 저장되는지는 신경 쓰지 않음.&lt;/li&gt;\n      &lt;li&gt;p207 보조 인덱스를 써서 읽는 질의는 큰 비용 발생. 여러 파티션에서 질의를 병렬 실행하더라도 꼬리 지연 시간 증폭이 발생하기 쉬움.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;Partitioning Secondary Indexes by Term:\n    &lt;ul&gt;\n      &lt;li&gt;p208 모든 파티션의 데이터를 담당하는 전역 색인을 만들 수도 있음&lt;/li&gt;\n      &lt;li&gt;p208 용어 자체로 파티셔닝하면 범위 스캔에 유용함.  반면 용어의 해시값을 사용해 파티셔닝하면 부하가 좀 더 고르게 분산됨.&lt;/li&gt;\n      &lt;li&gt;p208 읽기 효율적.  쓰기가 느리고 복잡함.&lt;/li&gt;\n      &lt;li&gt;p209 대개 비동기로 갱신됨.  쓰기를 실행한 후 바로 인덱스를 읽으면 변경 사항이 반영되지 않을 수도 있다.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;Rebalancing Partitions:\n    &lt;ul&gt;\n      &lt;li&gt;p209 리밸런싱:  클러스터에서 한 노드가 담당하던 부하를 다른 노드로 옮기는 과정&lt;/li&gt;\n      &lt;li&gt;p210 mod 연산 쓰지 마라.  리밸런싱 비용 지나치게 커지고, 데이터를 필요 이상으로 이동하지 않는 방법 필요.&lt;/li&gt;\n      &lt;li&gt;p211 파티션 개수 고정:  파티션이 너무 크면 리밸런싱을 실행할 때와 노드 장애로부터 복구 비용이 큼.  그러나 파티션이 너무 작으면 오버헤드가 너무 커짐.&lt;/li&gt;\n      &lt;li&gt;p212 동적 파티셔닝:  파티션 개수가 전체 데이터 용량에 맞춰 조정되는 이점.  파티션 개수가 데이터셋 크기에 비례.  데이터 양이 작으면 파티션 개수가 적어도 되므로 오버헤드 적다.   HBase, MongoDB는 빈 디비에 초기 파티션 집합 설정(pre-splitting)&lt;/li&gt;\n      &lt;li&gt;p213 노드 비례 파티셔닝:  노드 대수가 변함 없는 동안은 개별 파티션 크기가 데이터셋 크기에 비례.  노드 대수 늘리면 파티션 크기 다시 작아짐.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;카산드라\n    &lt;ul&gt;\n      &lt;li&gt;https://d2.naver.com/helloworld/1039&lt;/li&gt;\n      &lt;li&gt;https://tjddnjs.tistory.com/91&lt;/li&gt;\n      &lt;li&gt;p.213 리밸런싱 알고리즘 &lt;a href=&quot;https://www.datastax.com/blog/new-token-allocation-algorithm-cassandra-30&quot;&gt;New token allocation algorithm in Cassandra 3.0&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;p.216 가십 프로토콜  &lt;a href=&quot;https://docs.datastax.com/en/cassandra-oss/3.x/cassandra/architecture/archGossipAbout.html&quot;&gt;Apache Cassandra™ 3.x - Internode communications (gossip)&lt;/a&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;hr /&gt;\n\n&lt;h2 id=&quot;07장-트랜잭션&quot;&gt;07장: 트랜잭션&lt;/h2&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;p222 트랜잭션은 전체가 성공(commit)하거나 실패(abort, rollback).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h4 id=&quot;p223-acid&quot;&gt;p223 ACID&lt;/h4&gt;\n\n&lt;p&gt;&lt;strong&gt;Atomicity&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Not\n    &lt;ul&gt;\n      &lt;li&gt;In the context of ACID, atomicity is &lt;strong&gt;&lt;em&gt;not&lt;/em&gt;&lt;/strong&gt; about concurrency.&lt;/li&gt;\n      &lt;li&gt;It does not describe what happens if several processes try to access the same data at the same time, because that is covered under the letter &lt;em&gt;I&lt;/em&gt;, for &lt;em&gt;&lt;strong&gt;isolation&lt;/strong&gt;.&lt;/em&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;여러 쓰기 작업이 하나의 원자적인 트랜잭션으로 묶여 있는데 결함 때문에 완료(commit)될 수 없다면 abort되고 데이터베이스는 이 트랜잭션에서 지금까지 실행한 쓰기를 무시하거나 취소(undo) 해야 한다.&lt;/li&gt;\n  &lt;li&gt;Perhaps &lt;strong&gt;&lt;em&gt;abortability&lt;/em&gt;&lt;/strong&gt; would have been a better term than &lt;em&gt;&lt;strong&gt;atomicity&lt;/strong&gt;.&lt;/em&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Consistency&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;The idea of ACID consistency is that you have certain statements about your data (&lt;strong&gt;&lt;em&gt;invariants&lt;/em&gt;&lt;/strong&gt;) that must always be true.&lt;/li&gt;\n  &lt;li&gt;it’s the application’s responsibility to define its transactions correctly so that they preserve consistency.&lt;/li&gt;\n  &lt;li&gt;The letter C doesn’t really belong in ACID.\n    &lt;ul&gt;\n      &lt;li&gt;&lt;strong&gt;Atomicity&lt;/strong&gt;, &lt;strong&gt;Isolation&lt;/strong&gt;, &lt;strong&gt;Durability&lt;/strong&gt; are properties of the database, whereas &lt;strong&gt;Consistency&lt;/strong&gt; (in the ACID sense) is a property of the application.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Isolation&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;In the sense of ACID means that concurrently executing transactions are isolated from each other: they cannot step on each other’s toes.&lt;/li&gt;\n  &lt;li&gt;The database ensures that when the transactions have committed, the result is the same as if they had run &lt;strong&gt;&lt;em&gt;serially&lt;/em&gt;&lt;/strong&gt; (one after another), even though in reality they may have run concurrently.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;img src=&quot;/images/2024/06/22/07-transaction-race-conditon.png&quot; alt=&quot;transaction-race-conditon&quot; title=&quot;transaction-race-conditon&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Durability&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;any data it has written will not be forgotten.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Single-Object and Multi-Object Operations&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;&lt;strong&gt;atomicity&lt;/strong&gt; and &lt;strong&gt;isolation&lt;/strong&gt; describe what the database should do if a client makes several writes within the same transaction.\n    &lt;ul&gt;\n      &lt;li&gt;&lt;strong&gt;&lt;em&gt;Atomicity:&lt;/em&gt;&lt;/strong&gt;  If an error occurs halfway through a sequence of writes, the transaction should be aborted, and the writes made up to that point should be discarded. In other words, the database saves you from having to worry about partial failure, by giving an all-or-nothing guarantee.&lt;/li&gt;\n      &lt;li&gt;&lt;em&gt;&lt;strong&gt;Isolation&lt;/strong&gt;:&lt;/em&gt;  Concurrently running transactions shouldn’t interfere with each other. For example, if one transaction makes several writes, then another transaction should see either all or none of those writes, but not some subset.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;A transaction is usually understood as a mechanism for grouping multiple operations on multiple objects into one unit of execution.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Handling errors and aborts&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;&lt;strong&gt;best effort&lt;/strong&gt;:  “the database will do as much as it can, and if it runs into an error, it won’t undo something it has already done”.  so it’s the application’s responsibility to recover from errors.&lt;/li&gt;\n  &lt;li&gt;the whole point of aborts is to enable safe retries.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;p232-weak-isolation-levels&quot;&gt;p232 &lt;strong&gt;Weak Isolation Levels&lt;/strong&gt;&lt;/h3&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;&lt;strong&gt;&lt;em&gt;serializable&lt;/em&gt; isolation&lt;/strong&gt;:  the database guarantees that transactions have the same effect as if they ran &lt;em&gt;serially&lt;/em&gt; (i.e., one at a time, without any concurrency).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Read Committed&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n  &lt;li&gt;When reading from the database, you will only see data that has been committed\n(no &lt;em&gt;dirty reads&lt;/em&gt;).\n    &lt;ul&gt;\n      &lt;li&gt;아직 커밋되지 않은 롤백 데이터 읽을 수 있음  If the database allows dirty reads, that means a transaction may see data that is later rolled back—i.e., which is never actually committed to the database. Reasoning about the consequences quickly becomes mind-bending.&lt;/li&gt;\n      &lt;li&gt;새 값이 커밋돼야만 다른 트랜잭션들이 새 값을 읽을 수 있음. While the transaction is ongoing, any other transactions that read the object are simply given the old value. Only when the new value is committed do transactions switch over to reading the new value.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;When writing to the database, you will only overwrite data that has been committed (no &lt;em&gt;dirty writes&lt;/em&gt;).&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;p236-240. Snapshot Isolation and Repeatable Read&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Read skew is considered acceptable under read committed isolation.\n    &lt;ul&gt;\n      &lt;li&gt;skew; &lt;em&gt;timing anomaly&lt;/em&gt;.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;&lt;strong&gt;&lt;em&gt;readers never block writers, and writers never block readers&lt;/em&gt;&lt;/strong&gt;.&lt;/li&gt;\n  &lt;li&gt;&lt;strong&gt;&lt;em&gt;multi-version concurrency control&lt;/em&gt; (MVCC)&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;img src=&quot;/images/2024/06/22/07-transaction-multi-version.png&quot; alt=&quot;transaction-multi-version&quot; title=&quot;transaction-multi-version&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;객체를 볼 수 있는 조건:\n    &lt;ul&gt;\n      &lt;li&gt;읽기 트랜잭션 실행 시점에 이미 커밋된 상태여야함. At the time when the reader’s transaction started, the transaction that created the\n  object had already committed.&lt;/li&gt;\n      &lt;li&gt;The object is not marked for deletion, or if it is, the transaction that requested\n  deletion had not yet committed at the time when the reader’s transaction started.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;p242-preventing-lost-updates&quot;&gt;&lt;strong&gt;p242~ Preventing Lost Updates&lt;/strong&gt;&lt;/h3&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;The read committed and snapshot isolation levels:  동시 쓰기할 때 read-only 트랜잭션이 무엇을 볼 수 있는지. The guarantees of what a read-only transaction can see in the presence of concurrent writes.&lt;/li&gt;\n  &lt;li&gt;If two transactions do this concurrently, one of the modifications can be lost, because the second write does not include the first modification. (later write &lt;em&gt;clobbers&lt;/em&gt; the earlier write.)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Atomic write operations&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;MongoDB(document db);  atomic operations for making local modifications to a part of a JSON document.&lt;/li&gt;\n  &lt;li&gt;Redis;  atomic operations for modifying data structures such as priority queues.&lt;/li&gt;\n  &lt;li&gt;Atomic operations are usually implemented by taking an exclusive lock on the object.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Explicit locking&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT **FOR UPDATE**;&lt;/code&gt;&lt;/li&gt;\n  &lt;li&gt;It’s easy to forget to add a necessary lock somewhere in the code, and thus introduce a race condition.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Compare-and-set&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;마지막으로 읽은 후로 변경되지 않았을 때만 갱신 허용.  To avoid lost updates by allowing an update to happen only if the value has not changed since you last read it.&lt;/li&gt;\n  &lt;li&gt;if the database allows the WHERE clause to read from an old snapshot, this statement may not prevent lost updates.\n    &lt;ul&gt;\n      &lt;li&gt;because the condition may be true even though another concurrent write is occurring.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Conflict resolution and replication&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;여러 충돌 버전 생성을 허용하고 사후에 충돌 해소. Allow concurrent writes to create several conflicting versions of a value (also known as &lt;em&gt;siblings&lt;/em&gt;), and to use application code or\nspecial data structures to resolve and merge these versions after the fact.&lt;/li&gt;\n  &lt;li&gt;최종 쓰기 승리는 갱신 손실 발생하기 쉬움.  The &lt;strong&gt;&lt;em&gt;last write wins&lt;/em&gt; (LWW)&lt;/strong&gt; conflict resolution method is prone to lost updates.  LWW is the default in many replicated databases.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;p246 Write Skew and Phantoms&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Characterizing write skew&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;쓰기 스큐는 두 트랜잭션이 다른 객체 갱신.  dirty write와 lost update는 다른 트랜잭션이 하나의 동일 객체 갱신.   Write skew can occur if two transactions read the same objects, and then update some of those objects (different transactions may update different objects). In the special case where different transactions update the same object, you get a dirty write or lost update anomaly (depending on the timing).&lt;/li&gt;\n  &lt;li&gt;직렬성 격리로 write skew 자동 방지.  Automatically preventing write skew requires true serializable isolation.&lt;/li&gt;\n  &lt;li&gt;차선책; serializable isolation 사용할 수 없으면 트랜잭션이 의존하는 로우 잠그기.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Phantoms causing write skew&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;&lt;em&gt;&lt;strong&gt;phantom&lt;/strong&gt;:&lt;/em&gt;  쓰기가 다른 트랜잭션의 검색 질의 결과를 바구는 현상.  Where a write in one transaction changes the result of a search query in another transaction.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;AWS Summit &amp;lt;채널톡의 RDBMS에서 NoSQL 전환&amp;gt; 세션 내용&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;특정 시점 스파이크 트래픽과 리소스 비효율 문제 해결을 위해 DynamoDB 도입&lt;/li&gt;\n  &lt;li&gt;채팅 뱃지 카운트 트랜잭션 동시성 처리: Optimistic lock 이용해서 conflicts 발생시 exponential backoff&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;img src=&quot;/images/2024/06/22/07-aws-summit-dynamodb-0.png&quot; alt=&quot;aws-summit-dynamodb&quot; title=&quot;aws-summit-dynamodb&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;img src=&quot;/images/2024/06/22/07-aws-summit-dynamodb-1.png&quot; alt=&quot;aws-summit-dynamodb&quot; title=&quot;aws-summit-dynamodb&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;img src=&quot;/images/2024/06/22/07-aws-summit-dynamodb-2.png&quot; alt=&quot;aws-summit-dynamodb&quot; title=&quot;aws-summit-dynamodb&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;img src=&quot;/images/2024/06/22/07-aws-summit-dynamodb-3.png&quot; alt=&quot;aws-summit-dynamodb&quot; title=&quot;aws-summit-dynamodb&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;\n\n&lt;h3 id=&quot;p251-serializability&quot;&gt;&lt;strong&gt;p251 Serializability&lt;/strong&gt;&lt;/h3&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Testing for concurrency issues is hard, because they are usually nondeterministic — problems only occur if you get unlucky with the timing.&lt;/li&gt;\n  &lt;li&gt;the strongest isolation level.&lt;/li&gt;\n  &lt;li&gt;It guarantees that even though transactions may execute in parallel, the end result is the same as if they had executed one at a time, &lt;strong&gt;&lt;em&gt;serially&lt;/em&gt;&lt;/strong&gt;, without any concurrency.&lt;/li&gt;\n  &lt;li&gt;the database prevents &lt;strong&gt;&lt;em&gt;all&lt;/em&gt;&lt;/strong&gt; possible race conditions.&lt;/li&gt;\n  &lt;li&gt;2007년경이 돼서야 단일 스레드 루프에서 트랜잭션 실행하는게 실현 가능하다고 결론 내림\n    &lt;ul&gt;\n      &lt;li&gt;램 가격.  모든 데이터를 메모리 적재해서 트랜잭션 빠르게 실행.&lt;/li&gt;\n      &lt;li&gt;OLTP 트랜잭션이 보통 짧고 실행하는 읽기와 쓰기 개수가 적음.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;단일 스레드 기반 시스템이 동시성을 지원하는 시스템보다 성능이 나을때가 있음.  잠금 오버헤드 피할 수 있기 때문.  A system designed for single-threaded execution can sometimes perform better than a system that supports concurrency, because it can avoid the coordination overhead of locking.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Encapsulating transactions in stored procedures&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;데이터가 모두 메모리에 있고 프로시저는 네트워크나 디스크 I/O 대기 없이 매우 빠르게 실행된다고 가정.  Provided that all data required by a transaction is in memory, the stored procedure can execute very fast, without waiting for any network or disk I/O.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;img src=&quot;/images/2024/06/22/07-transaction-difference.png&quot; alt=&quot;transaction-difference&quot; title=&quot;transaction-difference&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Partitioning&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;동시성 제어는 간단해지지만 단일 장비의 단일 CPU 코어 속도 제한. Executing all transactions serially makes concurrency control much simpler, but limits the transaction throughput of the database to the speed of a single CPU core on a\nsingle machine.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Two-Phase Locking (2PL)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;2PL:  쓰기는 다른 쓰기와 읽기 진행하지 못하게 막음. writers don’t just block other writers; they also block readers and vice versa.&lt;/li&gt;\n  &lt;li&gt;Snapshot isolation:  읽기와 쓰기 양쪽 모두 막지 못하는 원칙.  the mantra &lt;em&gt;readers never block writers, and writers never block.&lt;/em&gt;&lt;/li&gt;\n  &lt;li&gt;lock: &lt;strong&gt;&lt;em&gt;shared mode&lt;/em&gt;&lt;/strong&gt; or in &lt;strong&gt;&lt;em&gt;exclusive mode&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;\n  &lt;li&gt;Performance\n    &lt;ul&gt;\n      &lt;li&gt;This is partly due to the overhead of acquiring and releasing all those locks, but more importantly due to reduced concurrency.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;Pessimistic vs. optimistic concurrency control\n    &lt;ul&gt;\n      &lt;li&gt;&lt;strong&gt;Pessimistic&lt;/strong&gt;: if anything might possibly go wrong (as indicated by a lock held by another transaction), it’s better to wait until the situation is safe again before doing anything.&lt;/li&gt;\n      &lt;li&gt;&lt;strong&gt;Optimistic&lt;/strong&gt;: instead of blocking if something potentially dangerous happens, transactions continue anyway, in the hope that everything will turn out all right.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Performance of serializable snapshot isolation&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;잠금 때문에 트랜잭션 차단될 필요 없음. Compared to two-phase locking, the big advantage of serializable snapshot isolation is that one transaction doesn’t need to block waiting for locks held by another transaction.&lt;/li&gt;\n  &lt;li&gt;The rate of aborts significantly affects the overall performance of SSI. For example, a transaction that reads and writes data over a long period of time is likely to run into conflicts and abort, so SSI requires that read-write transactions be fairly short (long- running read-only transactions may be okay)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;hr /&gt;\n\n&lt;h2 id=&quot;08장-분산-시스템의-골칫거리&quot;&gt;08장: 분산 시스템의 골칫거리&lt;/h2&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;p274 엔지니어로서의 우리의 임부는 모든 게 잘못되더라도 제 역할을 해내는 시스템을 구축하는것.  In the end, our task as engineers is to build systems that do their job (i.e., meet the guarantees that users are expecting), in spite of everything going wrong.&lt;/li&gt;\n  &lt;li&gt;&lt;strong&gt;Faults and Partial Failures&lt;/strong&gt;\n    &lt;ul&gt;\n      &lt;li&gt;&lt;strong&gt;&lt;em&gt;deterministic&lt;/em&gt;&lt;/strong&gt;: ex. 하드웨어가 올바르게 동작하면 같은 연산은 항상 같은 결과를 낸다.&lt;/li&gt;\n      &lt;li&gt;&lt;strong&gt;&lt;em&gt;partial failure&lt;/em&gt;&lt;/strong&gt;: 분산 시스템에서 시스템의 일부만 고장. &lt;strong&gt;&lt;em&gt;nondeterministic&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;p276 분산 시스템이 동작하게 만들려면 partial failure 가능성을 받아들이고 소프트웨어에 &lt;strong&gt;내결함성 메커니즘&lt;/strong&gt;(fault-tolerance mechanisms)을 넣어야 한다. 신뢰성 없는 구성 요소를 사용해 신뢰성 있는 시스템을 구축해야 함.   In other words, we need to build a reliable system from unreliable components.&lt;/li&gt;\n  &lt;li&gt;&lt;strong&gt;Unreliable Networks&lt;/strong&gt;\n    &lt;ul&gt;\n      &lt;li&gt;p279 비동기 네트워크.. 유일한 정보는 응답을 아직 받지 못했다는 것. 응답을 다른 노드로 요청을 보내서 응답을 받지 못했다면 그 이유를 아는 것은 불가능.   이런 문제를 다루는 흔한 방법이 타임아웃.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;&lt;strong&gt;Timeouts and Unbounded Delays&lt;/strong&gt;\n    &lt;ul&gt;\n      &lt;li&gt;타임아웃이 길면 노드가 죽었다고 선언될 때까지 기다리는 시간이 길어짐.  타임아웃이 짧으면 결함을 빨리 발견하지만  노드가 일시적으로 느려졌을 뿐인데도 죽었다고 잘못 선언할 가능성.&lt;/li&gt;\n      &lt;li&gt;2d + r;  d: 전송 시간, r: 요청 처리 시간&lt;/li&gt;\n      &lt;li&gt;기약 없는 지연(unbounded delay): 패킷을 가능한 한 빨리 보내려고 하지만 패킷이 도착하는데 걸리는 시간에 상한치는 없다.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Network congestion and queueing&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;p282 TCP 흐름제어(flow control). 노드가 네트워크 링크나 수신 노드에 과부하를 가하지 않도록 자신의 송신율을 제한.&lt;/li&gt;\n  &lt;li&gt;TCP는 어떤 타임아웃(왕복 시간을 관찰해서 계산)  안에 확인 응답을 받지 않으면 패킷이 손실됐다고 간주하고 손실된 패킷은 자동으로 재전송.  애플리케이션에게는 패킷 손실이나 재전송이 보이지 않지만 그 결과로 생기는 지연 발생(타임아웃 만료 + 재전송 패킷 확인 응답)\n    &lt;ul&gt;\n      &lt;li&gt;&lt;a href=&quot;https://alden-kang.tistory.com/20&quot;&gt;Connection Timeout과 Read Timeout 살펴보기&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=&quot;https://brunch.co.kr/@alden/15&quot;&gt;TCP retransmission과 튜닝 포인트&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;두 글 요약하자면 → 커넥션 타임아웃은 3초로 적당한거같다. TCP 는 재전송 메커니즘이 있어서 이 때 타임아웃이 1초임. 그래서 3초 정도가 적덩한거같다. Read Timeout 은 300ms 였어서 1초&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;p284  고정된 타임아웃을 설정하는 대신 시스템이 지속적으로 응답 시간과 그들의 변동성을 측정,   관찰된 응답 시간 분포에 따라 타임아웃을 자동 조정.\n    &lt;ul&gt;\n      &lt;li&gt;&lt;a href=&quot;https://doc.akka.io/docs/akka/current/typed/failure-detector.html&quot;&gt;Phi Accrual Failure Detector - akka&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=&quot;https://medium.com/@arpitbhayani/phi-%CF%86-accrual-failure-detection-79c21ce53a7a&quot;&gt;Phi φ Accrual Failure Detection&lt;/a&gt;\n        &lt;ol&gt;\n          &lt;li&gt;&lt;strong&gt;Suspicion Level (φ value):&lt;/strong&gt;\n            &lt;ul&gt;\n              &lt;li&gt;φ 값은 수신된 하트비트(heartbeat) 사이의 시간 간격을 기반으로 계산. 이 값은 현재 네트워크 상태를 반영하도록 지속적으로 조정. φ 값이 높을수록 노드가 실패했을 가능성이 높다는 것을 의미.&lt;/li&gt;\n            &lt;/ul&gt;\n          &lt;/li&gt;\n          &lt;li&gt;&lt;strong&gt;Heartbeat Intervals&lt;/strong&gt;:\n            &lt;ul&gt;\n              &lt;li&gt;노드로부터 모니터링. interval은 샘플 윈도우에 저장되어 분포를 추정하고 의심 수준을 계산하는 데 사용&lt;/li&gt;\n            &lt;/ul&gt;\n          &lt;/li&gt;\n          &lt;li&gt;&lt;strong&gt;Dynamic Thresholds&lt;/strong&gt;:\n            &lt;ul&gt;\n              &lt;li&gt;φ 값은 시스템이 다양한 동적 임계값을 설정. 예를 들어, φ 값이 특정 임계값을 초과하면 노드를 실패한 것으로 간주할 수 있지만, 더 낮은 φ 값에서는 예방 조치를 시작할 수 있다.&lt;/li&gt;\n            &lt;/ul&gt;\n          &lt;/li&gt;\n        &lt;/ol&gt;\n      &lt;/li&gt;\n      &lt;li&gt;A → B → C 순으로 호출한다고 하자. A를 관리하고있다면 B에서 지연된건지 C에서 지연된건지 찾는데, 데이터독으로 트레이싱하고있어서, 최근 n일 기준으로 API 의 latency 를 보고. 가령 B→C가 50ms 라면 Read Timeout 고려해서 500ms 정도로 잡고, A→B 구간에서는 500보다 좀 더 크게 잡고.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Synchronous Versus Asynchronous Networks&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;p284 전화 네트워크. 고정 회선.\n    &lt;ul&gt;\n      &lt;li&gt;bounded delay(제한 있는 지연):  네트워크의 다음 홉에 통화당 16비트 공간을 미리 할당.  그리고 큐 대기가 없으므로 종단 지연 시간의 최대치가 고정되어 있음.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Can we not simply make network delays predictable?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;데이터센터 네트워크와 인터넷은 패킨 교환 사용;  bursty traffic 에 최적화&lt;/li&gt;\n  &lt;li&gt;회선; 통화를 하는 동안 보내는 초당 비트 개수가 상당히 고정돼 있는 음성과 영상 통화에 적합&lt;/li&gt;\n  &lt;li&gt;웹 페이지 요청, 이메일 전송, 파일 전송은 특별한 대역폭 요구사항 없음. 단지 가능하면 빨리 완료되기를 바람.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;p287 Unreliable Clocks&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;시간, 시계와 관련된 질문을 Durations(지속 시간), Points in time(시점)에 따라 기술&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Synchronized clocks for global snapshots&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;p295 스패너에 대한 이야기(feat. ChatGPT):\n    &lt;ul&gt;\n      &lt;li&gt;데이터베이스 내의 여러 트랜잭션 간의 인과 관계를 고려하여 타임스탬프를 부여\n        &lt;ul&gt;\n          &lt;li&gt;&lt;strong&gt;트랜잭션 타임스탬프:&lt;/strong&gt; 각 트랜잭션이 완료된 시점(시간). 트랜잭션의 순서를 정하고, 데이터의 일관성을 유지하는 데 중요&lt;/li&gt;\n          &lt;li&gt;&lt;strong&gt;인과성(Causality)&lt;/strong&gt;: 한 트랜잭션이 다른 트랜잭션에 영향을 미치는 관계.  예를 들어, 트랜잭션 A가 트랜잭션 B보다 먼저 실행되고, B가 A의 결과에 의존하는 경우, A는 B의 원인이 된다.\n      1. &lt;strong&gt;TrueTime API&lt;/strong&gt;:&lt;/li&gt;\n          &lt;li&gt;TrueTime API를 사용하여 각 트랜잭션에 정확한 타임스탬프를 부여. TrueTime은 GPS 및 원자시계 정보를 활용하여 매우 정확한 시각 정보를 제공.&lt;/li&gt;\n          &lt;li&gt;TrueTime의 사용으로 인해 각 트랜잭션의 완료 시점에 대해 상한(earliest) 및 하한(latest) 시간을 알 수 있으며, 이를 통해 트랜잭션 간의 정확한 순서를 결정.\n      2. &lt;strong&gt;트랜잭션 순서 보장&lt;/strong&gt;:&lt;/li&gt;\n          &lt;li&gt;트랜잭션 간의 인과 관계를 보장하기 위해, 이전 트랜잭션이 완료된 후에만 다음 트랜잭션을 수행. 이는 인과 관계가 반영된 타임스탬프를 부여하는데 중요한 역할을 한다.\n      3. &lt;strong&gt;Globally Consistent Reads and Writes&lt;/strong&gt;:&lt;/li&gt;\n          &lt;li&gt;이러한 타임스탬프 메커니즘 덕분에, Spanner는 전 세계에 분산된 데이터베이스에서도 강력한 일관성을 유지할 수 있습니다. 각 트랜잭션의 타임스탬프가 인과성을 반영하기 때문에, 사용자는 일관된 데이터를 읽고 쓸 수 있습니다.&lt;/li&gt;\n        &lt;/ul&gt;\n      &lt;/li&gt;\n      &lt;li&gt;&lt;a href=&quot;https://cloud.google.com/spanner/docs/true-time-external-consistency&quot;&gt;Spanner: TrueTime and external consistency&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=&quot;https://pdfs.semanticscholar.org/e3d0/9699c66bd0b89f663954bf8b043491368620.pdf&quot;&gt;Spanner: Google’s Globally-Distributed Database&lt;/a&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Process Pauses&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;note) p297. 실행 중인 스레드를 어떤 시점에 선점(preempt)하고 얼마만의 시간이 흐른후 재개할 수 있다.  선점된 스레드는 이를 알아채지 못한다.  이 문제는 단일 장비에서 다중 스레드 코드를 thread-safe 하게 만드는 것과 비슷.   컨텍스트 스위치가 임의로 발생할 수 있고 병렬(parallelism)이 발생할 수 도 있으므로 타이밍에 대해 어떤 가정도 할 수 없다.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Knowledge, Truth, and Lies&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;p300 인식하고 측정하는 수단을 믿을 수 없다면 그 지식을 어떻게 확신할 수 있나? How sure can we be of that knowledge, if the mechanisms for perception and measurement are unreliable?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;The Truth Is Defined by the Majority&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;p301 노드가 상황에 대한 자신의 판단을 반드시 믿을 수 있는 것은 아님.  분산 시스템은 한 노드에만 의존할 수는 없다. 노드에 언제든 장애가 나서 잠재적으로 시스템이 멈추고 복구할 수 없게 될 수도 있기 때문이다.  &lt;strong&gt;정족수(quorum)&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Fencing tokens&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;p303 잠금이 승인될 때마다 증가하는 숫자.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;img src=&quot;/images/2024/06/22/08-fencing-token.png&quot; alt=&quot;fencing-token&quot; title=&quot;fencing-token&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;자원 자체가 이미 처리된 것보다 오래된 토큰을 사용해서 쓰는 것을 거부함으로써 토큰을 확인하는 활동적인 역할을 맡아야 함.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Byzantine Faults&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;p304 어떤 노드가 실제로는 받지 않은 특정 메시지를 받았다고 주장…&lt;/li&gt;\n  &lt;li&gt;비잔틴 결함(&lt;em&gt;Byzantine fault&lt;/em&gt;), 비잔틴 장군 문제(&lt;em&gt;Byzantine Generals Problem&lt;/em&gt;)\n    &lt;ul&gt;\n      &lt;li&gt;&lt;a href=&quot;https://monday9pm.com/%EB%A9%94%EC%8B%9C%EC%A7%80-%EC%A0%84%EB%8B%AC-%EC%A0%84%EB%9E%B5%EA%B3%BC-%EB%91%90-%EC%9E%A5%EA%B5%B0-%EB%AC%B8%EC%A0%9C-message-delivery-semantics-and-two-generals-problem-f8f1c7646c0b&quot;&gt;&lt;strong&gt;메시지 전달 전략과 두 장군 문제(Message Delivery Semantics and Two Generals’ Problem)&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=&quot;https://lwn.net/Articles/540368/&quot;&gt;&lt;strong&gt;ELC: SpaceX lessons learned&lt;/strong&gt;&lt;/a&gt;\n        &lt;ul&gt;\n          &lt;li&gt;SpaceX에서는 Falcon, Dragon, Grasshopper 등의 비행 제어, 지상 스테이션, 개발자 데스크톱까지 모든 것이 리눅스.&lt;/li&gt;\n          &lt;li&gt;fault-tolerant(내결함성/결함 허용)을 위해 3중으로 시스템을 구성하고 비잔틴 장군 알고리즘을 사용. 우주 정거장(ISS)에 접근할 때, 결함 허용 수준을 만족해야만 정거장에 접근할 수 있음.  이를 위해 삼중 중복 컴퓨터를 사용해서 필요한 수준의 결함 허용을 달성.&lt;/li&gt;\n          &lt;li&gt;비잔틴 장군 알고리즘은 컴퓨터들이 동의하지 않는 상황을 처리하는 데 사용. 이런 상황은 방사선 사건으로 인해 메모리나 레지스터 값이 변경되는 경우 발생.&lt;/li&gt;\n        &lt;/ul&gt;\n      &lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Byzantine fault-tolerant&lt;/em&gt;&lt;/strong&gt; :  일부 노드가 오작동하고 프로토콜을 준수하지 않거나 악의적인 공격자가 네트워크를 방해하더라도 시스템이 계속 올바르게 동작&lt;/li&gt;\n  &lt;li&gt;보통 비잔틴 결함이 없다고 가정할 수 있다. 우리 조직이 모든 노드 제어.. 방사선 수준은 큰 문제 아님..&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Safety and liveness&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;p308  안전성(나쁜 일은 일어나지 않는다), 활동성(좋은 일은 결국 일어난다).  Safety is often informally defined as &lt;strong&gt;&lt;em&gt;nothing bad happens&lt;/em&gt;&lt;/strong&gt;, and liveness as &lt;strong&gt;&lt;em&gt;something good eventually happens&lt;/em&gt;&lt;/strong&gt;.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;정리&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;결함을 견뎌내려면 그것을 감지하는 게 첫 걸음이지만 그것조차 어렵다.&lt;/li&gt;\n  &lt;li&gt;대부분의 시스템은 노드에 장애가 발생했는지 알 수 있는 정확한 메커니즘이 없어서 대부분의 분산 알고리즘은 원격 노드를 아직 쓸 수 있는지 결정하기 위해 타임아웃을 사용.&lt;/li&gt;\n  &lt;li&gt;그러나 타임아웃은 네트워크 장애와 노드 장애를 구별할 수 없고 변동이 큰 네트워크 지연 때문에 때때로 노드가 죽은 것으로 잘못 의심받을 수 있다.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;hr /&gt;\n\n&lt;h2 id=&quot;09장-일관성과-합의p349&quot;&gt;09장: 일관성과 합의(~p.349)&lt;/h2&gt;\n\n&lt;p&gt;&lt;strong&gt;p.321 Consistency Guarantees&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;약한 보장(weak guarantee): 복제 데이터 베이스는 대부분 최소한 &lt;strong&gt;최종적 일관성&lt;/strong&gt;(&lt;strong&gt;&lt;em&gt;eventual consistency**)&lt;/em&gt;을 제공한다. 하지만 언제 **수렴&lt;/strong&gt;(&lt;strong&gt;&lt;em&gt;convergence&lt;/em&gt;&lt;/strong&gt;) 될 지 모름.&lt;/li&gt;\n  &lt;li&gt;강한 보장(strongest consistency):  데이터 시스템이 선택적으로 제공. 성능이 나쁘거나 약한 보장을 제공하는 시스템보다 내결함성이 약할 수 있음.&lt;/li&gt;\n  &lt;li&gt;트랜잭션 격리 수준과의 차이점;\n    &lt;ul&gt;\n      &lt;li&gt;트랜잭션 격리:  주로 동시에 실행되는 트랜잭션 때문에 발생하는 경쟁 조건을 회피하는 것에 관한 것.&lt;/li&gt;\n      &lt;li&gt;분산 일관성:  대개 지연과 결함이 있더라도 복제본의 상태를 코디네이션하는 것&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;p322 &lt;strong&gt;Linearizability&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;“데이터베이스가 복제본이 하나만 있다면 훨씬 더 단순해 지지 않을까?”  원자적 일관성(&lt;em&gt;atomic consistency&lt;/em&gt;), 강한 일관성(&lt;em&gt;strong consistency&lt;/em&gt;), 즉각 일관성(&lt;em&gt;immediate consistency&lt;/em&gt;), 외부 일관성(&lt;em&gt;external consistency&lt;/em&gt;)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;img src=&quot;/images/2024/06/22/09-consistency.png&quot; alt=&quot;consistency&quot; title=&quot;consistency&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;최신성 보장(recency guarantee)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;시스템에 선형성을 부여하는 것&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*cas*(*x*, *v*old, *v*new) ⇒ *r*&lt;/code&gt;:\n    &lt;ul&gt;\n      &lt;li&gt;클라이언트가 cas(compare-and-set) 연산 요청&lt;/li&gt;\n      &lt;li&gt;레지스터 x의 현재 값이 Vold과 같으면 Vnew로 설정하고 아니면 오류 발환(error)&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;img src=&quot;/images/2024/06/22/09-linearizability.png&quot; alt=&quot;linearizability&quot; title=&quot;linearizability&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;p332 요약; 다이나모 스타일 복제를 하는 리더 없는 시스템은 선형성을 제공하지 않는다고 보는 게 안전.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;p333 선형성의 비용&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;단일 리더 설정에서 데이터센터 사이에 연결 끊기면 선형성 읽기 불가능.  팔로워로부터 읽을 수는 있지만 데이터가 뒤쳐졌을 수 있다(비선형적).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;p335 CAP&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;네트워크 결함이 생기면 선형성과 완전한 가용성 사이에서 선택해야 함.  CAP는 &lt;strong&gt;네트워크 분단이 생겼을때 일관성과 가용성 중 하나를 선택&lt;/strong&gt;하라는 의미.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;p342 비인과적 일련번호 생성기(Noncausal sequence number generators)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;노드별) 각 노드 개별로 독립적인 일련번호 집합 생성. 예) 한 노드는 홀수만, 다른 노드는 짝수만 생성.&lt;/li&gt;\n  &lt;li&gt;잘 동작하지만 생성한 일련번호가 인과성에 일관적이지 않음(timestamp 불일치)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;p343 Lamport timestamps&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;&amp;lt;카운터, 노드&amp;gt; ID 조합.&lt;/li&gt;\n  &lt;li&gt;때때로 카운터 값이 같을 수 있지만 타임스탬프에 노드 ID를 포함시켜서 각 타임스탬프 유일.&lt;/li&gt;\n  &lt;li&gt;물리적 일 기준 시계와 아무 관련이 없지만 전체 순서화를 제공.&lt;/li&gt;\n  &lt;li&gt;버전 벡터와의 차이;\n    &lt;ul&gt;\n      &lt;li&gt;버전 벡터:  두 연산이 동시적인지 또는 어떤 연산이 다른 연산에 인과적으로 의존하는지 구별&lt;/li&gt;\n      &lt;li&gt;램포트 타임스탬프:  항상 전체 순서화를 강제화&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Total Order Broadcast&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;p346  후속 메시지가 이미 전달됐다면 노드는 그 순서의 앞에 메시지를 소급적으로 끼워넣는 게 허용되지 않는다.  전체 순서 브로드캐스트가 타임스탬프 순서화보다 강하다.&lt;/li&gt;\n  &lt;li&gt;p347 선형성과의 차이\n    &lt;ul&gt;\n      &lt;li&gt;전체 순서 브로드캐스트는 비동기식.  메시지는 고정된 순서로 신뢰성 있게 전달되도록 보장.   하지만 언제 메시지가 전달되는지 보장되지 않음.&lt;/li&gt;\n      &lt;li&gt;선형성은 최신성 보장. 읽기가 최근에 쓰여진 값을 보는 게 보장.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;hr /&gt;\n\n&lt;h2 id=&quot;09장-분산-트랜잭션과-합의p349&quot;&gt;09장: 분산 트랜잭션과 합의(p.349~)&lt;/h2&gt;\n\n&lt;p&gt;p349 Consensus&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;합의:  여러 노드들이 뭔가에 동의하게 만드는 것&lt;/li&gt;\n  &lt;li&gt;리더 선출(Leader election):  단일 리더 복제를 사용하는 DB에서 모든 노드는 어떤 노드가 리더인지 동의해야 함.&lt;/li&gt;\n  &lt;li&gt;원자적 커밋(Atomic commit): 트랜잭션 원자성을 유지하고 싶다면 모든 노드가 트랜잭션의 결과에 동의해야 함.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;p351 원자적 커밋과 2PC(Two-Phase Commit) why?&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;트랜잭션의 결과는 항상 커밋 Success 이거나 Abort.  The outcome of a transaction is either a &lt;strong&gt;successful&lt;/strong&gt; commit, in which case all of the transaction’s writes are made durable, or an &lt;strong&gt;abort&lt;/strong&gt;, in which case all of the transaction’s writes are rolled back (i.e., undone or discarded).&lt;/li&gt;\n  &lt;li&gt;트랜잭션에 여러 노드가 관여하게 되면 어떤 노드에서는 커밋이 성공하고 다른 노드에서는 실패해서 원자성 보장을 위반하기 쉽다.  어떤 노드가 트랜잭션을 Commit 하지만 다른 노드는 Abort 한다면 노드들이 서로 일관성이 없어진다.&lt;/li&gt;\n  &lt;li&gt;트랜잭션 커밋은 되돌릴 수 없어야 한다.  보상 트랜잭션(compensating transaction)은 취소 가능하지만 분리된 트랜잭션 개념으로 이해해야 한다.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;p.352-355  2PC&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;2PC는 여러 노드에 걸친 원자적 트랜잭션 Commit 되게 함. 즉 모든 노드가 커밋되거나 모든 노드가 Abort 되도록 보장하는 알고리즘&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;img src=&quot;/images/2024/06/22/09-2pc.png&quot; alt=&quot;2pc&quot; title=&quot;2pc&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;코디네이터(coordinator, transaction manager), 데이터베이스 노드들을 트랜잭션 참여자(participant)&lt;/li&gt;\n  &lt;li&gt;애플리케이션이 Commit할 준비가 되면 코디네이터가 1단계 시작 → 각 노드에 준비 요청을 보내서 커밋할 수 있는지 물어본다 → 그 후 코디네이터는 참여자들의 응답을 추적\n    &lt;ul&gt;\n      &lt;li&gt;모든 참여자가 커밋할 준비가 됐다면 “yes” 응답 → 코디네이터는 2단계에서 커밋 요청(commit request)하고 실제로 커밋 발생&lt;/li&gt;\n      &lt;li&gt;참여자 중 누구라도 “no” 응답 → 코디네이터는 2단게에서 모든 노드에 Abort 요청&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;코디네이터 장애시,  2PC가 완료될 수 있는 유일한 방법은 코디네이터가 복구되기를 기다리는것 뿐.\n    &lt;ul&gt;\n      &lt;li&gt;코디네이터가 Commit 이나 Abort 요청 보내기 전에 디스크에 있는 트랜잭션 로그에 기록&lt;/li&gt;\n      &lt;li&gt;코디네이터가 복구될 때 트랜잭션 로그를 읽어서 모든 의심스러운 트랜잭션들의 상태를 결정&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;p358-360  XA transactions&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;트랜잭션 코디네이터와 연결되는 인터페이스를 제공하는 API.  트랜잭션 코디네이터는 XA API를 구현.&lt;/li&gt;\n  &lt;li&gt;애플리케이션이 네트워크 드라이버나 클라이언트 라이브러리를 사용해 참여자 DB나 메시징 서비스와 통신한다고 가정.&lt;/li&gt;\n  &lt;li&gt;애플리케이션 프로세그가 죽거나 애플리케이션이 실행중인 장비가 죽으면 코디네이터도 함께 사라짐&lt;/li&gt;\n  &lt;li&gt;코디네이터 장애 복구 문제.  유일한 방법은 관리자가 수동으로 트랜잭션을 커밋하거나 롤백할지 결정하는 것.&lt;/li&gt;\n  &lt;li&gt;\n    &lt;p&gt;JDBC 분산 트랜잭션&lt;/p&gt;\n\n    &lt;p&gt;JDBC(Java Database Connectivity)의 트랜잭션은 로컬. 이는 단일 연결이 트랜잭션의 모든 작업을 수행하며 연결은 한 번에 하나의 트랜잭션에 대해서만 작업할 수 있음을 의미.&lt;/p&gt;\n\n    &lt;p&gt;하나의 트랜잭션에 대한 모든 작업이 완료되거나 실패한 경우, 작업을 영구적으로 만들기 위해 커밋 또는 롤백이 호출되고 새 트랜잭션이 시작된다.  그러나 Java에서는 로컬 트랜잭션을 넘어서는 기능을 제공하는 고급 트랜잭션 지원도 있고, Java 트랜잭션 API에서 제공한다.&lt;/p&gt;\n\n    &lt;p&gt;Java Transaction API(JTA)는 복잡한 트랜잭션을 지원.  또한 연결 객체에서 트랜잭션을 분리하는 기능도 제공합니다.  JDBC가 객체 데이터베이스 연결(ODBC) 및 X/Open 호출 수준 인터페이스(CLI) 명세를 모델로 삼았듯이, JTA는 X/Open eXtended Architecture(XA) 명세를 모델로 삼습니다. JTA와 JDBC는 연결 객체에서 트랜잭션을 분리하기 위해 함께 작동. 연결 객체에서 트랜잭션을 분리함으로써 단일 연결이 여러 트랜잭션을 동시에 처리할 수 있다.  반대로 여러 연결이 단일 트랜잭션을 처리할 수도 있음.&lt;/p&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;p360 분산 트랜잭션의 제약&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;XA 트랜잭션은 여러 참여 데이터 시스템이 서로 일관성을 유지하게 하는 실제적이고 중요한 문제를 해결해 주지만, XA 트랜잭션도 중요한 운영상 문제를 가져온다.&lt;/li&gt;\n  &lt;li&gt;핵심 구현은 트랜잭션의 코디네이터 자체가 일종의 데이터베이스여야 하고, 따라서 다른 중요한 데이터베이스와 동일하게 신경 써서 접근해야함.\n    &lt;ul&gt;\n      &lt;li&gt;분산 트랜잭션은 &lt;strong&gt;장애를 증폭&lt;/strong&gt;시키는 경향이 있으며 이는 내결함성을 지닌 시스템을 구축하려는 목적에 어긋난다.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;p361 내결함성을 지닌 합의(Fault-Tolerant Consensus)&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;합의 알고리즘이 만족해야 할 속성\n    &lt;ul&gt;\n      &lt;li&gt;균일한 동의(Uniform agreement):  어떤 두 노드도 다르게 결정하지 않음&lt;/li&gt;\n      &lt;li&gt;무결성(Integrity): 어떤 노드도 두 번 결정하지 않음&lt;/li&gt;\n      &lt;li&gt;유효성(Validity): 한 노드가 값 v를 결정한다면 v는 어떤 노드에서 제안된 것이다.&lt;/li&gt;\n      &lt;li&gt;종료(Termination): 죽지 않은 모든 노드는 결국 어떤 값을 결정한다.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;카프카 Zookeeper → Raft consensus\n    &lt;ul&gt;\n      &lt;li&gt;&lt;a href=&quot;https://seongjin.me/raft-consensus-algorithm/&quot;&gt;https://seongjin.me/raft-consensus-algorithm/&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=&quot;https://devocean.sk.com/blog/techBoardDetail.do?ID=165711&quot;&gt;https://devocean.sk.com/blog/techBoardDetail.do?ID=165711&lt;/a&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;a href=&quot;https://devocean.sk.com/blog/techBoardDetail.do?ID=165737&quot;&gt;https://devocean.sk.com/blog/techBoardDetail.do?ID=165737&lt;/a&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;p365 에포크 번호 붙이기와 정족수&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;현재 리더가 죽었다고 생각될 때마다 새 노드를 선출하기 위해 노드 사이에서 투표를 해서 에포크 번호가 높은 리더가 이겨서 리더가 된다.&lt;/li&gt;\n  &lt;li&gt;리더가 뭔가를 결정하도록 허용하기 전에 충돌되는 결정을 할 지도 모르는 에포크 번호가 더 높은 리더가 없는지 먼저 확인해야 한다.&lt;/li&gt;\n  &lt;li&gt;노드의 정족수로부터 투표를 받아서 리더를 판단합니다. 정족수는 항상은 아니지만 노드의 과반수로 구성된다.&lt;/li&gt;\n  &lt;li&gt;2PC는 “yes” 투표가 필요하지만,  내결함성을 지닌 합의 알고리즘은 노드의 과반수로부터만 투표.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;p367 멤버십과 코디네이션 서비스&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;HBase, 하둡, 노바, 카프카는 모두 &lt;strong&gt;주키퍼&lt;/strong&gt;에 의존.&lt;/li&gt;\n  &lt;li&gt;주키퍼 기능\n    &lt;ul&gt;\n      &lt;li&gt;&lt;strong&gt;선형적 원자적 연산(Linearizable atomic operations):&lt;/strong&gt;  원자적 compare-and-set 연산을 사용해 잠금을 구현&lt;/li&gt;\n      &lt;li&gt;&lt;strong&gt;연산의 전체 순서화(Total ordering of operations):&lt;/strong&gt;  펜싱 토큰 등을 사용해 클라이언트 충돌 막기&lt;/li&gt;\n      &lt;li&gt;&lt;strong&gt;장애 감지(Failure detection):&lt;/strong&gt; 세션에서 획득한 잠금은 세션이 타임아웃 됐을 때 자동으로 해제되도록 설정&lt;/li&gt;\n      &lt;li&gt;&lt;strong&gt;변경 알림(Change notifications):&lt;/strong&gt;  클라이언트는 다른 클라이언트가 생성한 잠금과 값을 읽을 수 있을 뿐만 아니라 거기에 변경이 있는지 감시할 수 있다.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;p369 Service discovery,  Membership services&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;Service discovery: 특정 서비스에 연결하려면 어떤 IP 주소로 접속해야 하는지 알아내는 용도로도 자주 사용.&lt;/li&gt;\n  &lt;li&gt;Membership services:  클러스터에서 어떤 노드가 현재 활성화된 살아 있는 멤버인지 결정.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;hr /&gt;\n\n&lt;h2 id=&quot;11장-스트림-처리p453&quot;&gt;11장: 스트림 처리(~p453)&lt;/h2&gt;\n\n&lt;p&gt;p382 레코드 시스템과 파생 데이터 시스템&lt;/p&gt;\n\n&lt;table&gt;\n  &lt;thead&gt;\n    &lt;tr&gt;\n      &lt;th&gt;레코드 시스템(Systems of record)&lt;/th&gt;\n      &lt;th&gt;파생 데이터 시스템(Derived data systems)&lt;/th&gt;\n    &lt;/tr&gt;\n  &lt;/thead&gt;\n  &lt;tbody&gt;\n    &lt;tr&gt;\n      &lt;td&gt;믿을 수 있는 데이터 버전을 저장&lt;/td&gt;\n      &lt;td&gt;다른 시스템에 존재하는 데이터를 가져와 특정 방식으로 변환하고 처리한 결과&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;진실의 근원(source of truth). 사용자의 입력과 같은 새로운 데이터가 들어오면 먼저 레코드 시스템에 저장&lt;/td&gt;\n      &lt;td&gt;데이터를 잃게 되더라도 원천 데이터로부터 다시 생성 가능&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;일반적으로 정규화를 거쳐 정확하게 한 번 표현된다.  레코드 시스템과 다른 시스템 간에 차이가 난다면 레코드 시스템이 옳다.&lt;/td&gt;\n      &lt;td&gt;필요한 데이터가 캐시에 있다면 캐시에서 제공하고, 그렇지 않다면 기반 데이터베이스를 거쳐 제공할 수 있다.&lt;/td&gt;\n    &lt;/tr&gt;\n  &lt;/tbody&gt;\n&lt;/table&gt;\n\n&lt;p&gt;p436 &lt;strong&gt;이벤트 스트림 전송(Transmitting Event Streams)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;&lt;strong&gt;이벤트&lt;/strong&gt;\n    &lt;ul&gt;\n      &lt;li&gt;스트림 처리 문맥(stream processing context)에서 레코드는 보통 &lt;strong&gt;이벤트&lt;/strong&gt;라고 한다.&lt;/li&gt;\n      &lt;li&gt;특정 시점에 일어난 사건에 대한 세부 사항을 포함하는, 작고 독립된 불변 객체라는 점에서 본질적으로 동일하다.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;생성자(producer)와 소비자(consumer)\n    &lt;ul&gt;\n      &lt;li&gt;생산자(producer), 발행자(publisher), 발송자(sender)&lt;/li&gt;\n      &lt;li&gt;소비자(consumer), 구독자(subscriber), 수신자(recipient)&lt;/li&gt;\n      &lt;li&gt;레코드 식별(그룹핑)\n        &lt;ul&gt;\n          &lt;li&gt;파일 시스템: 파일 이름으로 관련 레코드 식별&lt;/li&gt;\n          &lt;li&gt;스트림 시스템: 토픽(topic)이나 스트림으로 관련 이벤트 그룹핑&lt;/li&gt;\n        &lt;/ul&gt;\n      &lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;메시징-시스템-p438&quot;&gt;메시징 시스템 p438&lt;/h3&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;\n    &lt;p&gt;메시지 시스템에 대한 질문(Publish, Subscribe 모델)&lt;/p&gt;\n\n    &lt;p&gt;Q 소비자가 메시지 처리하는 속도보다 생산자가 메시지 전송하는게 빠른 경우(생산자 &amp;gt; 소비자)&lt;/p&gt;\n\n    &lt;ul&gt;\n      &lt;li&gt;메시지를 버리기&lt;/li&gt;\n      &lt;li&gt;큐에 메시지 버퍼링하기&lt;/li&gt;\n      &lt;li&gt;배압(backpressure) 적용:\n        &lt;ul&gt;\n          &lt;li&gt;생산자가 메시지를 더 보내지 못하게 막기&lt;/li&gt;\n          &lt;li&gt;유닉스 파이프와 TCP가 사용&lt;/li&gt;\n        &lt;/ul&gt;\n      &lt;/li&gt;\n    &lt;/ul&gt;\n\n    &lt;p&gt;Q 노드가 죽거나 일시적으로 오프라인이 된다면?&lt;/p&gt;\n\n    &lt;ul&gt;\n      &lt;li&gt;디스크에 기록하거나 복제본 생성을 하거나 둘 모두를 해야 한다.&lt;/li&gt;\n      &lt;li&gt;메시지를 잃어도 괜찮다면 같은 하드웨어에서 처리량은 높이고 지연 시간은 낮출 수 있다.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;생산자에서 소비자로 메시지 직접 전달:  프로토콜이 네트워크 상에서 패킷 유실을 감지하고 재전송하더라도 직접 메시지 시스템은 일반적으로 생산자와 소비자가 항상 온라인 상태라고 가정&lt;/li&gt;\n  &lt;li&gt;\n    &lt;p&gt;p440 메시지 브로커와 데이터베이스 비교&lt;/p&gt;\n\n    &lt;table&gt;\n      &lt;thead&gt;\n        &lt;tr&gt;\n          &lt;th&gt;데이터베이스(Databases)&lt;/th&gt;\n          &lt;th&gt;메시지 브로커(Message brokers)&lt;/th&gt;\n        &lt;/tr&gt;\n      &lt;/thead&gt;\n      &lt;tbody&gt;\n        &lt;tr&gt;\n          &lt;td&gt;명시적으로 데이터가 삭제될 때까지 데이터 보관&lt;/td&gt;\n          &lt;td&gt;대부분 소비자에게 데이터 배달이 성공할 경우 자동으로 메시지 삭제. 대부분 메시지를 빨리 지우기 때문에 작업 집합이 상당히 작다고 가정(큐 크기가 작다). 소비자 처리가 느려서 메시지 브로커가 많은 메시지를 버퍼링해야 한다면, 개별 메시지 처리 시간이 길어지고 전체 처리량이 저하됨&lt;/td&gt;\n        &lt;/tr&gt;\n        &lt;tr&gt;\n          &lt;td&gt;보조 색인을 지원. 데이터 검색을 위한 다양한 방법 지원&lt;/td&gt;\n          &lt;td&gt;특정 패턴과 부합하는 토픽의 부분 집합을 구독하는 방식 지원&lt;/td&gt;\n        &lt;/tr&gt;\n        &lt;tr&gt;\n          &lt;td&gt;일반적으로 질의 시점의 데이터 스냅숏을 기준으로 질의&lt;/td&gt;\n          &lt;td&gt;임의 질의를 지원하지 않음. 데이터가 변하면 클라이언트에게 전달&lt;/td&gt;\n        &lt;/tr&gt;\n      &lt;/tbody&gt;\n    &lt;/table&gt;\n  &lt;/li&gt;\n  &lt;li&gt;p441 복수 소비자(Multiple consumers)\n    &lt;ul&gt;\n      &lt;li&gt;로드 밸런싱(Load balancing):\n        &lt;ul&gt;\n          &lt;li&gt;각 메시지는 소비자 중 &lt;strong&gt;하나&lt;/strong&gt;로 전달&lt;/li&gt;\n          &lt;li&gt;메시지를 처리하는 비용이 비싸서 처리를 병렬화하기 위해 소비자를 추가하고 싶을때 유용&lt;/li&gt;\n        &lt;/ul&gt;\n      &lt;/li&gt;\n      &lt;li&gt;팬 아웃(Fan-out):\n        &lt;ul&gt;\n          &lt;li&gt;각 메시지는 &lt;strong&gt;모든&lt;/strong&gt; 소비자에게 전달&lt;/li&gt;\n          &lt;li&gt;여러 독립적인 소비자가 브로드캐스팅된 동일한 메시지를 서로 간섭 없이 리스닝 가능&lt;/li&gt;\n        &lt;/ul&gt;\n      &lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;img src=&quot;/images/2024/06/22/11-fanout.png&quot; alt=&quot;fanout&quot; title=&quot;fanout&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;\n\n&lt;p&gt;p442 확인 응답과 재전송(Acknowledgments and redelivery)&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;생산자: m1 → m2 → m3 → m4 → m5&lt;/li&gt;\n  &lt;li&gt;소비자2가 m3 처리중 장애 발생해서 소비자1로 m3 메시지 재전송.&lt;/li&gt;\n  &lt;li&gt;소비자 1에서는 m4 → m3 → m5 순으로 메시지 처리&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;img src=&quot;/images/2024/06/22/11-consumer.png&quot; alt=&quot;consumer&quot; title=&quot;consumer&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;소비자마다 독립된 큐를 사용하면, 즉 부하 균형 분산 기능을 사용하지 않는다면 이 문제를 피할 수 있다.\n    &lt;ul&gt;\n      &lt;li&gt;카프카 토픽의 파티션 키(해시) - stickness&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;메시지가 서로 완전히 독립적이라면 메시지 순서가 바뀌는 것은 문제가 되지 않는다.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;p443-파티셔닝된-로그partitioned-logs&quot;&gt;p443 파티셔닝된 로그(Partitioned Logs)&lt;/h3&gt;\n\n&lt;p&gt;&lt;strong&gt;로그 기반 메시지 브로커(log- based message brokers)&lt;/strong&gt;:  데이터베이스의 지속성 있는 저장 방법과 메시징 시스템의 지연 시간이 짧은 알림 기능을 조합&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;\n    &lt;p&gt;로그를 사용한 메시지 저장소&lt;/p&gt;\n\n    &lt;p&gt;로그 == 파티션&lt;/p&gt;\n\n    &lt;ul&gt;\n      &lt;li&gt;\n        &lt;p&gt;&lt;strong&gt;p445 로그 파티셔닝(the log can be partitioned)&lt;/strong&gt;: 디스크 하나를 쓸 때보다 처리량을 높이기 위해 확장하는 방법&lt;/p&gt;\n\n        &lt;blockquote&gt;\n          &lt;ul&gt;\n            &lt;li&gt;하나의 파티션을 처리하는 작업을 공유하는 소비자 둘로 나누어 로드 밸런싱하는 방식을 사용할 수 있다.  양쪽 소비자 모두 모든 메시지를 읽지만 그 중 하나는 짝수 오프셋 메시지만 처리하고, 다른 소비자는 홀수 오프셋 메시지만 처리하는 방식.&lt;/li&gt;\n            &lt;li&gt;스레드 풀 사용을 사용해 메시지 처리 분산하는 방식. 소비자 오프셋 관리가 복잡해진다. 일반적으로 한 파티션은 단일 스레드가 처리하는 것이 적절하고,  병렬성을 높이고 싶다면 파티션 수를 늘리는 게 좋다.&lt;/li&gt;\n          &lt;/ul&gt;\n        &lt;/blockquote&gt;\n      &lt;/li&gt;\n      &lt;li&gt;\n        &lt;p&gt;단 다른 파티션 간 메시지의 순서는 보장하지 않는다.&lt;/p&gt;\n      &lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;img src=&quot;/images/2024/06/22/11-partition.png&quot; alt=&quot;partition&quot; title=&quot;partition&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;\n    &lt;p&gt;p444 로그 방식과 전통적인 메시징 방식의 비교&lt;/p&gt;\n\n    &lt;p&gt;로그 기반 접근법은 팬 아웃 메시지 방식 제공:&lt;/p&gt;\n\n    &lt;ul&gt;\n      &lt;li&gt;소비자가 서로 영향 없이 독립적으로 로그를 읽을 수 있고 메시지를 읽어도 로그에서 삭제되지 않는다.&lt;/li&gt;\n    &lt;/ul&gt;\n\n    &lt;p&gt;각 클라이언트는 할당된 파티션의 메시지를 모두 소비:&lt;/p&gt;\n\n    &lt;ul&gt;\n      &lt;li&gt;토픽 하나를 소비하는 작업을 공유하는 노드 수는 많아야 해당 토픽의 로그 파티션 수로 제한.  같은 파티션 내 메시지는 같은 노드로 전달되기 때문.&lt;/li&gt;\n      &lt;li&gt;특정 메시지 처리가 느리면 파티션 내 후속 메시지 처리가 지연된다(head-of-line blocking).&lt;/li&gt;\n    &lt;/ul&gt;\n\n    &lt;table&gt;\n      &lt;tbody&gt;\n        &lt;tr&gt;\n          &lt;td&gt;메시지 처리 비용 비싼 경우, 메시지 단위로 병렬화 처리 하고 싶은 경우, 메시지 순서는 그렇게 중요하지 않은 경우&lt;/td&gt;\n          &lt;td&gt;JMS / AMQP 방식의 메시지 브로커 적합&lt;/td&gt;\n        &lt;/tr&gt;\n        &lt;tr&gt;\n          &lt;td&gt;처리량이 많은 경우, 메시지를 처리하는 속도가 빠른 경우, 메시지 순서가 중요한 경우&lt;/td&gt;\n          &lt;td&gt;로그 기반 접근법 적합&lt;/td&gt;\n        &lt;/tr&gt;\n      &lt;/tbody&gt;\n    &lt;/table&gt;\n  &lt;/li&gt;\n  &lt;li&gt;p445 소비자 오프셋(Consumer offsets)\n    &lt;ul&gt;\n      &lt;li&gt;브로커는 주기적으로 소비자 오프셋을 기록&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;p446 디스크 공간 사용\n    &lt;ul&gt;\n      &lt;li&gt;로그는 크기가 제한된 버퍼로 구현하고,  버퍼가 가득 차면 오래된 메시지 순서대로 버린다.&lt;/li&gt;\n      &lt;li&gt;원형 버퍼(circular buffer), 링 버퍼(ring buffer)&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;데이터베이스와-스트림&quot;&gt;데이터베이스와 스트림&lt;/h3&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;p448 데이터베이스에 뭔가를 기록한다는 사실은 캡처해서 저장하고 처리할 수 있는 이벤트다.&lt;/li&gt;\n  &lt;li&gt;p448 시스템 동기화 유지하기&lt;/li&gt;\n  &lt;li&gt;이중 기록(dual write)의 심각한 문제\n    &lt;ul&gt;\n      &lt;li&gt;문제 1) 타이밍이 좋지 않아 요청이 서로 교차한 경우, 두 시스템은 오류가 발생하지 않았음에도 영원히 서로 불일치 상태로 남음.&lt;/li&gt;\n      &lt;li&gt;문제2) 한쪽 쓰기가 성공할 때, 다른쪽 쓰기는 실패할 수 있다.  동시성 문제라기보다는 내결함성 문제로 두 시스템 간 불일치가 발생하는 현상.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;img src=&quot;/images/2024/06/22/11-dual-write.png&quot; alt=&quot;dual-write&quot; title=&quot;dual-write&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;&lt;strong&gt;p450 변경 데이터 캡처(Change Data Capture)&lt;/strong&gt;\n    &lt;ul&gt;\n      &lt;li&gt;데이터베이스에 기록하는 모든 데이터의 변화를 관찰해 다른 시스템으로 데이터를 복제할 수 있는 형태로 추출하는 과정&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;img src=&quot;/images/2024/06/22/11-cdc.png&quot; alt=&quot;cdc&quot; title=&quot;cdc&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;파생 데이터 시스템이 레코드 시스템의 정확한 데이터 복제본을 가지게 하기 위해,  레코드 시스템에 발생하는 모든 변경 사항을 파생 데이터 시스템에 반영하는 것을 보장하는 메커니즘&lt;/li&gt;\n  &lt;li&gt;\n    &lt;p&gt;멕스웰(maxwell), 디비지움(debezium): binlog를 파싱해 유사한 방식으로 mysql용 변경 데이터 캡처를 구현&lt;/p&gt;\n  &lt;/li&gt;\n  &lt;li&gt;p452 초기 스냅숏(Initial snapshot):\n    &lt;ul&gt;\n      &lt;li&gt;데이터베이스에서 발생한 모든 변경 로그가 있다면,  로그를 재현해서 데이터베이스의 전체 상태를 재구축 가능&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;p452 로그 컴팩션(Log compaction):\n    &lt;ul&gt;\n      &lt;li&gt;저장 엔진은 주기적으로 같은 키의 로그 레코드를 찾아 중복을 제거&lt;/li&gt;\n      &lt;li&gt;각 키에 대해 가장 최근에 갱신된 내용만 유지&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;p453 변경 스트림용 API 지원\n    &lt;ul&gt;\n      &lt;li&gt;kafka connect;\n        &lt;ul&gt;\n          &lt;li&gt;변경 이벤트를 스트림하는데 카프카 사용&lt;/li&gt;\n          &lt;li&gt;검색 색인과 같은 파생 데이터 시스템을 갱신하는데 사용 가능&lt;/li&gt;\n          &lt;li&gt;스트림 처리 시스템에도 이벤트 공급이 가능&lt;/li&gt;\n        &lt;/ul&gt;\n      &lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;hr /&gt;\n\n&lt;h2 id=&quot;11장-스트림-처리p45411장-끝&quot;&gt;11장: 스트림 처리(p454~11장 끝)&lt;/h2&gt;\n\n&lt;p&gt;&lt;strong&gt;이벤트 소싱(event sourcing)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;CDC:\n    &lt;ul&gt;\n      &lt;li&gt;데이터베이스를 변경 가능한 방식으로 사용해 레코드를 자유롭게 갱신하고 삭제&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;이벤트 소싱:\n    &lt;ul&gt;\n      &lt;li&gt;이벤트 로그에 기록된 불변 이벤트를 기반으로 명시적으로 구축&lt;/li&gt;\n      &lt;li&gt;이벤트 저장은 추가만 가능하고 갱신이나 삭제는 권장하지 않거나 금지&lt;/li&gt;\n      &lt;li&gt;어떤 상황이 발생한 후에 상황 파악이 쉽기 때문에 디버깅에 도움이 되고 버그 방지&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;이벤트 로그에서 현재 상태 파생하기&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;시스템에 기록한 데이터를 표현한 이벤트 로그를 가져와 사용자에게 보여주기에 적당한 애플리케이션 상태(시스템에서 데이터를 읽는 방식)로 변환해야 한다.\n    &lt;ul&gt;\n      &lt;li&gt;예시; 현재 장바구니 내용(변경 사항은 관심사 x)&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;CDC: 레코드의 가장 새로운 버전만 보유.  같은 키의 이전 이벤트는 로그 컴팩션을 통해 버린다&lt;/li&gt;\n  &lt;li&gt;이벤트 소싱: 뒤에 발생한 이벤트가 앞선 이벤트를 덮어쓰지 않는다. 마지막 상태 재구축을 위해서는 이벤트의 전체 히스토리가 필요하다.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;p455 명령과 이벤트&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;명령이 실행 가능한지 확인.&lt;/li&gt;\n  &lt;li&gt;무결성이 검증되고 명령이 승인되면 명령은 지속성 있는 불변 이벤트가 된다.&lt;/li&gt;\n  &lt;li&gt;명령의 유효성은 이벤트가 되기 전에 동기식으로 검증해야 한다.\n    &lt;ul&gt;\n      &lt;li&gt;좌석 예약 예시.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;p456 상태와 스트림 그리고 불변성&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;상태의 본질을 변하는 것이다. 상태가 어떻게 바뀌었든 항상 이런 변화를 일으킨 일련의 이벤트가 있다.&lt;/li&gt;\n  &lt;li&gt;변경 가능한 상태와 추가 전용 불변 이벤트 로그는 마치 동전의 양면과 같이 서로 모순이다. 모든 &lt;strong&gt;변경 로그(changelog)&lt;/strong&gt;는 시간이 지남에 따라 바뀌는 상태를 나타낸다.&lt;/li&gt;\n  &lt;li&gt;변경 로그를 지속성 있게 저장한다면 상태를 간단히 재생성할 수 있는 효과가 있다. 이벤트 로그를 레코드 시스템으로 생각하고 모든 변경 가능 상태를 이벤트 로그로부터 파생된 것으로 생각하면 시스템을 거치는 데이터 흐름에 관해 추론하기 쉽다.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;p458 동일한 이벤트 로그로 여러 가지 뷰 만들기&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;CQRS(Command Query Responsibility Segregation)&lt;/li&gt;\n  &lt;li&gt;읽기 최적화된 뷰(read-optimized views)는 데이터를 비정규화하는 것이 전적으로 합리적이다.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;동시성 제어&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;이벤트가 아직 읽기 뷰에 반영되지 않았을 가능성&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;p460 불변성의 한계&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;성능적인 이유 외에도. 사생활 침해 규제로 인해 개인 정보 지울 필요가 있다든지, 데이터 보호법에 따라 잘못된 정보를 삭제해야 한다든지, 민감한 정보가 우발적으로 노출되는 것을 방지해야 하는 경우&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;p461-스트림-처리&quot;&gt;&lt;strong&gt;p461 스트림 처리&lt;/strong&gt;&lt;/h3&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;몇 분 동안 실행된 일괄 처리 작업은 실패한 태스크를 처음부터 재시작하는 것으로 충분,  하지만 몇 년 동안 실행 중인 스트림 작업은 장애 발생 이후 처음부터 재시작하는 방법은 비현실적.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;p462 복잡한 이벤트 처리&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;CEP(Complex event processing): 특정 이벤트 패턴을 검색해야 하는 애플리케이션에 적합&lt;/li&gt;\n  &lt;li&gt;스트림 분석(Stream analytics): 연속한 특정 이벤트 패턴을 찾는 것보다 대량의 이벤트를 집계하고 통계적 지표를 뽑는 것을 더 우선.\n    &lt;ul&gt;\n      &lt;li&gt;특정 유형의 이벤트 빈도 측정(시간당 얼마나 자주 발생하는지)&lt;/li&gt;\n      &lt;li&gt;특정 기간에 걸친 값의 이동 평균(ROLLING AVERAGE) 계산&lt;/li&gt;\n      &lt;li&gt;이전 시간 간격과 현재 통계값의 비교(추세 감지,  지난주 대비 비정상적으로 높거나 낮은 지표에 대해 경고)&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;p464 구체화 뷰(materialized views) 유지하기&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;이벤트 소싱에서 애플리케이션 상태는 이벤트 로그를 적용함으로써 유지된다.  여기서 애플리케이션 상태는 일종의 구체화 뷰다.&lt;/li&gt;\n  &lt;li&gt;구체화 뷰를 만들려면 잠재적으로 임의의 시간 범위에 발생한 모든 이벤트가 필요하다.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;p464 스트림 상에서 검색하기&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;질의를 먼저 저장.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;메시지 전달과 RPC&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;메시지 전달이 stream 처리, RPC는 액터.  액터는 1:1로 메시지 주고 받는 형태.  스트림 처리는 카프카처럼 데이터 파이프라인 구축.  스트림 처리는 메시지 관심있는 사람 여러명이 관심.  1:1 / 1:n 또는 n:m&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;액터:\n    &lt;ul&gt;\n      &lt;li&gt;주로 동시성 관리, 통신 모듈을 분산 실행하는 매커니즘&lt;/li&gt;\n      &lt;li&gt;액터간 통신은 주로 단기적이고 일대일&lt;/li&gt;\n      &lt;li&gt;임의의 방식으로 통신 가능&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;스트림 처리:\n    &lt;ul&gt;\n      &lt;li&gt;기본적으로 데이터 관리 기법&lt;/li&gt;\n      &lt;li&gt;지속성 있고 다중 구독 가능&lt;/li&gt;\n      &lt;li&gt;비순환 파이프라인에 설정됨.&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;p468 어떤 시계를 사용할 것인가?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;잘못된 장치 시계를 조정하는 한 가지 방법: 세 가지 타임스탬프를 로그로 남기기&lt;/p&gt;\n\n&lt;ol&gt;\n  &lt;li&gt;이벤트가 발생한 시간 - 장치 시계&lt;/li&gt;\n  &lt;li&gt;이벤트를 서버로 보낸 시간 - 장치 시계&lt;/li&gt;\n  &lt;li&gt;서버에서 이벤트를 받은 시간 - 서버 시계&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;2와 3 차이를 구하면 장치 시계와 서버 시계 간의 오프셋 추정 가능.  계산한 오프셋을 이벤트 타임스탬프에 적용해 이벤트가 실제로 발생한 시간을 추정.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;p469 윈도우 유형&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;텀블링 윈도우(Tumbling window)&lt;/li&gt;\n  &lt;li&gt;홉핑 윈도우(Hopping window)&lt;/li&gt;\n  &lt;li&gt;슬라이딩 윈도우(Sliding window)&lt;/li&gt;\n  &lt;li&gt;세션 윈도우(Session window)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;p474-내결함성fault-tolerance&quot;&gt;p474 내결함성(&lt;strong&gt;Fault Tolerance)&lt;/strong&gt;&lt;/h3&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;태스크를 재시작하는 것은 사실 레코드를 여러 번 처리할 수도 있다는 뜻. 출력은 한 번만 처리된 것으로 보이는 효과.\n    &lt;ul&gt;\n      &lt;li&gt;&lt;strong&gt;exactly-once semantics(정확히 한 번 시맨틱), effectively-once(결과적으로 한 번)&lt;/strong&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;Microbatching and checkpointing(마이크로 일괄 처리와 체크포인트)&lt;/li&gt;\n  &lt;li&gt;Atomic commit revisited(원자적 커밋 재검토)&lt;/li&gt;\n  &lt;li&gt;멱등성(Idempotence)&lt;/li&gt;\n  &lt;li&gt;실패 후에 상태 재구축하기(Rebuilding state after a failure)&lt;/li&gt;\n&lt;/ul&gt;\n\n\n            \n          ",
        "contentSnippet": "<h2 id=\"1장-신뢰할-수-있고-확장-가능하며-유지보수하기-쉬운-애플리케이션\">1장. 신뢰할 수 있고 확장 가능하며 유지보수하기 쉬운 애플리케이션</h2>\n\n<p>p.6</p>\n\n<p><strong>신뢰성(Reliability)</strong>\n하드웨어나 소프트웨여 결함, 심지어 인적 오류(human error) 같은 역경에 직면하더라도 시스템은 지속적으로 올바르게 동작(원하는 성능 수준에서 정확한 기능을 수행)해야 한다.</p>\n\n<p><strong>확장성(Scalability)</strong>\n시스템의 데이터 양, 트래픽 양, 복잡도가 증가하면서 이를 처리할 수 있는 적절한 방법이 있어야 한다.</p>\n\n<p><strong>유지보수성(Maintainability)</strong>\n시간이 지남에 따라 여러 다양한 사람들이 시스템 상에서 작업(현재 작업을 유지보수하고 새로운 사용 사례를 시스템에 적용하는 엔지니어링과 운영)할 것이기 때문에 모든 사용자가 시스템 상에서 생산적으로 작업할 수 있게 해야 한다.</p>\n\n<p>p.6-7</p>\n\n<p>소프트웨어의 일반적인 기대치</p>\n<ul>\n  <li>애플리케이션 사용자가 거대한 기능을 수행한다.</li>\n  <li>시스템은 사용자가 범한 실수나 예상치 못한 소프트웨어 사용법을 허용할 수 있다.</li>\n  <li>시스템 성능은 예상된 부하와 데이터 양에서 필수적인 사용 사례를 충분히 만족한다.</li>\n  <li>시스템은 허가되지 않은 접근과 오남용을 방지한다.</li>\n</ul>\n\n<p>잘못될 수 있는 일을 결함(fault)이라 부른다. 그리고 결함을 예측하고 대처할 수 있는 시스템을 내결함성(fault-tolerant) 또는 탄력성(resilient)을 지녔다고 말한다.</p>\n\n<p>결함은 장애(failure)와 동일하지 않다. 일반적으로 결함은 사양에서 벗어난 시스템의 한 구성 요소로 정의되지만, 장애는 사용자에게 필요한 서비스를 제공하지 못하고 시스템 전체가 멈춘 경우다. … 대개 결함으로 인해 장애가 발생하지 않게끔 내결함성 구조를 설계하는 것이 가장 좋다.</p>\n\n<p>p.9-10</p>\n\n<p>대규모 인터넷 서비스에 대한 한 연구에 따르면 운영자의 설정 오류가 중단의 주요원인인 반면 하드웨어(서버나 네트워크) 결함은 중단 원인의 10~25% 정도에 그친다.</p>\n<ul>\n  <li>오류의 가능성을 최소화하는 방향으로 시스템을 설계하라</li>\n  <li>사람의 실수로 장애가 발생할 수 있는 부분을 분리하라</li>\n  <li>모든 수준에서 철저하게 테스트하라</li>\n  <li>인적 오류를 빠르고 쉽게 복구할 수 있게 하라</li>\n  <li>모니터링 대책을 마연하라</li>\n  <li>조작 교육과 실슴을 시행하라</li>\n</ul>\n\n<p>p.11\n부하는 <strong>부하 매개변수(load paramter)</strong>라 부르는 몇 개의 숫자로 나타낼 수 있다. … 부하 매개변수로 웹 서버의 초당 요청 수, 데이터베이스의 읽기 대 쓰기 비율, 대화방의 동시 활성 사용자(active user), 캐시 적중률 등이 될 수 있다.</p>\n\n<p>p.19 유지보수성</p>\n\n<p><strong>운용성(operability)</strong>\n운영팀이 시스템을 원활하게 운영할 수 있게 쉽게 만들어라.</p>\n\n<p><strong>단순성(Simplicity)</strong>\n시스템에서 복잡도를 최대한 제거해 새로운 엔지니어가 시스템을 이해하기 쉽게 만들어라(사용자 인터페이스의 단순성과는 다르다는 점에 유의하라).</p>\n\n<p><strong>발전성(Evolvability)</strong>\n엔지니어가 이후에 시스템을 쉽게 변경할 수 있게 하라. 그래야 요구사항 변경 같은 예기치 않은 사용 사례를 적용하기 쉽다. 이 속성은 유연성(extensibility), 수정 가능성(modifiability), 적응성(plasticity)으로 알려져 있다.</p>\n\n<p>p.20 좋은 운영성</p>\n<ul>\n  <li>좋은 모니터링으로 런타임(runtime) 동작과 시스템의 내부에 대한 가시성 제공</li>\n  <li>표준 도구를 이용해 자동화와 통합을 위한 우수한 지원을 제공</li>\n  <li>개별 장비 의존성을 회피. 유지보수를 위해 장비를 내리더라도 시스템 전체에 영향을 주지 않고 계속해서 운영 가능해야 함</li>\n  <li>좋은 문서와 이해하기 쉬운 운영 모델(예를 들어 “X를 하면 Y가 발생한다”) 제공</li>\n  <li>만족할 만한 기본 동작을 제공하고, 필요할 때 기본값을 다시 정의할 수 있는 자유를 관리자에게 부여</li>\n  <li>적절하게 자기 회복(self-healing)이 가능할 뿐 아니라 필요에 따라 관리자가 시스템 상태를 수동으로 제어할 수 있게 함</li>\n  <li>예측 가능하게 동작하고 예기치 않은 상황을 최소화함</li>\n</ul>\n\n<hr />\n\n<h2 id=\"2장-데이터-모델과-질의-언어\">2장. 데이터 모델과 질의 언어</h2>\n\n<p>p.32 지역성(locality). JSON 표현에서는 모든 관련 정보가 한 곳에 있어 질의 하나로 충분하다.</p>\n\n<p>p.40 쓰기 스키마(schema-on-write)(관계형 데이터베이스의 전통적인 접근 방식으로 스키마는 명시적이고 데이터 베이스는 쓰여진 모든 데이터가 스키마를 따르고 있음을 보장한다)와 반대되는 읽기 스키마(schema-on-read)(데이터 구조는 암묵적이고 데이터를 읽을 때만 해석된다)</p>\n\n<p>p.43 선언형 질의\nSQL이나 관계 대수 같은 선언형 질의 언어에서는 목표를 달성하기 위한 방법이 아니라,  알고자 하는 데이터의 패턴, 즉 결과가 충족해야 하는 조건과 데이터를 어떻게 변환(예를 들어 정렬, 그룹화, 집계)할지를 지정하기만 하면 된다.</p>\n\n<hr />\n\n<h2 id=\"3장-저장소와-검색\">3장: 저장소와 검색</h2>\n\n<ul>\n  <li>p.72 특정 작업부(workload) 유형에서 좋은 성능을 내게끔 저장소 엔진을 조정하려면 저장소 엔진이 내부에서 수행되는 작업에 대해 대략적인 개념을 이해할 필요가 있다.</li>\n  <li>p.74 색인을 잘 선택했다면 읽기 질의 속도가 향상된다. 하지만 모든 색인은 쓰기 속도를 떨어뜨린다.</li>\n  <li>p.74 키를 데이터 파일의 바이트 오프셋에 매핑해 인메모리 해시 맵을 유지하는 전략이다.</li>\n  <li>p.74 값을 조회하려면 해시 맵을 사용해 데이터 파일에서 오프셋을 찾아 해당 위치를 구하고 값을 읽는다.</li>\n  <li>p.75 컴팩션은 로그에서 중복된 키를 버리고 각 키의 최신 갱신 값만 유지하는 것을 의미한다.</li>\n  <li>p.77 불행하게도 디스크 상의 해시 맵에 좋은 성능을 기대하기란 어렵다. 이는 무작위 접근 I/O가 많이 필요하고 디스크가 가득 찼을 때 확장하는 비용이 비싸며 해시 충돌 해소를 위해 성가신 로직이 필요하다.</li>\n  <li>p.78 해시 테이블은 범위 질의(range query)에 효율적이지 않다.</li>\n  <li>p.79 그래도 handbag과 handsome 키의 오프셋을 알고 있고 정렬돼 있으므로 handiwork는 두 키 사이에 있다는 사실을 알 수 있다.</li>\n  <li>p.80 저장소 엔진\n    <ul>\n      <li>쓰기가 들어오면 인메모리 균형 트리(balanced tree) 데이터 구조(예를 들어 레드 블랙 트리)에 추가한다. 이 인메모리 트리는 멤테이블(memtable)이라고도 한다.</li>\n      <li>멤테이블이 보통 수 메가바이트 정도의 임곗값보다 커지면 SS테이블 파일로 디스크에 기록한다. 트리가 이미 키로 정렬된 키-값 쌍을 유지하고 있기 때문에 효율적으로 수행할 수 있다. 새로운 SS테이블 파일은 데이터베이스의 가장 최신 세그먼트가 된다. SS테이블을 디스크에 기록하는 동안 쓰기는 새로운 멤테이블 인스턴스에 기록한다.</li>\n      <li>읽기 요청을 제공하려면 먼저 멤테이블에서 키를 찾아야 한다. 그다음 디스크 상의 가장 최신 세그먼트에서 찾는다. 그다음으로 두 번째 오래된 세그먼트, 세 번째 오래된 세그먼트 등에서 찾는다.</li>\n      <li>가끔 세그먼트 파일을 합치고 덮어 쓰여지거나 삭제된 값을 버리는 병합과 컴팩션 과정을 수행한다. 이 과정은 백그라운드에서 수행된다.</li>\n    </ul>\n  </li>\n  <li>p.80 정렬된 파일 병합과 컴팩션 원리를 기반으로 하는 저장소 엔진을 LSM 저장소 엔진이라 부른다.</li>\n  <li>p.81 키를 단어(용어)로, 값은 단어를 포함한 모든 문서의 ID 목록(포스팅 목록(postings list))으로 하는 키-값 구조로 구현한다.</li>\n  <li>p.81 블룸 필터는 키가 데이터베이스에 존재하지 않음을 알려주므로 존재하지 않는 키를 위한 불필요한 디스크 읽기를 많이 절약할 수 있다.</li>\n  <li>p.81 백그라운드에서 연쇄적으로 SS테이블을 지속적으로 병합하는 것이다. 이 개념은 데이터셋이 가능한 메모리보다 훨씬 더 크더라도 여전히 효과적이다. 데이터가 정렬된 순서로 저장돼 있다면 범위 질의를 효율적으로 실행할 수 있다.</li>\n  <li>p.82 B 트리는 전통적으로 4KB 크기(때로는 더 큰)의 고정 크기 블록이나 페이지로 나누고 한 번에 하나의 페이지에 읽기 또는 쓰기를 한다. 디스크가 고정 크기 블록으로 배열되기 때문에 이런 설계는 근본적으로 하드웨어와 조금 더 밀접한 관련이 있다.</li>\n  <li>p.83 새로운 키를 수용한 페이지에 충분한 여유 공간이 없다면 페이지 하나를 반쯤 채워진 페이지 둘로 나누고 상위 페이지가 새로운 키 범위의 하위 부분들을 알 수 있게 갱신한다.</li>\n  <li>p.99 칼럼 지향 저장소. 모든 값을 하나의 로우에 함께 저장하지 않는 대신 각 칼럼별로 모든 값을 함께 저장한다. 각 칼럼을 개별 파일에 저장하면 질의에 사용되는 칼럼만 읽고 구분 분석하면 된다. 이 방식을 사용하면 작업량이 많이 줄어든다.</li>\n</ul>\n\n<hr />\n\n<h2 id=\"05장-복제\">05장: 복제</h2>\n\n<ul>\n  <li>p.156 동기식 복제의 장점은 팔로워가 리더와 일관성 있게 최신 데이터 복사본을 가지는 것을 보장한다. 갑자기 리더가 작동하지 않아도 데이터는 팔로워에서 계속 사용할 수 있음을 확신할 수 있다. 단점은 (팔로워가 죽거나 네트워크 문제나 다른 어떤 이유로 인해) 동기 팔로워가 응답하지 않는다면 쓰기가 처리될 수 없다는 것이다. 리더는 모든 쓰기를 차단(block)하고 동기 복제 서버가 다시 사용할 수 있을때까지 기다려야 한다.</li>\n  <li>p.159 팔로워 중 하나를 새로운 리더로 승격해야 하고 클라이언트는 새로운 리더로 쓰기를 전송하기 위해 재설정이 필요하며 다른 팔로워는 새로운 리더로부터 데이터 변경을 소비하기 시작해야 한다. 이 과정을 장애 복구(failover)라 한다.</li>\n  <li>p.167 Monotonic Read: 각 사용자의 읽기가 항상 동일한 복제 서버에서 수행되게끔 하는 것</li>\n  <li>p.168 Consistent Prefix Read: 일련의 쓰기가 특정 순서로 발생한다면 이 쓰기를 읽는 모든 사용자는 같은 순서로 쓰여진 내용을 보게 됨을 보장한다.</li>\n  <li>p.174 충돌을 처리하는 제일 간단한 전략은 충돌을 피하는 것이다. 특정 레코드의 모든 쓰기가 동일한 리더를 거치도록 애플리케이션이 보장한다면 충돌은 발생하지 않는다.</li>\n  <li>p.175 Automatic Conflict Resolution\n    <ul>\n      <li><a href=\"https://assets.amazon.science/ac/1d/eb50c4064c538c8ac440ce6a1d91/dynamo-amazons-highly-available-key-value-store.pdf\">Dynamo: Amazon’s Highly Available Key-value Store</a></li>\n    </ul>\n  </li>\n  <li>p.179 Dynamo Style: 리더의 개념을 버리고 모든 복제 서버가 클라이언트로부터 쓰기를 직접 받을 수 있게 허용하는 접근 방식</li>\n  <li>p.180 Outdated 해결: 클라이언트가 데이터베이스에서 읽을 때 하나의 복제 서버로 요청을 보내지 않고 읽기 요청을 병렬로 여러 노드에 전송. 클라이언트는 여러 노드에서 다른 응답을 받음. 즉, 한 노드에서는 최신 값을 받고 다른 노드에서는 오래된 값을 받음. 이 때 버전 숫자를 사용해 어떤 값이 최신 내용인지 결정.</li>\n  <li>p.180 Anti-entropy\n    <ul>\n      <li><a href=\"https://medium.com/@adityashete009/anti-entropy-and-merkel-trees-amazon-dynamodb-part-4-efbf1f7285c0\">Anti-Entropy and Merkel Trees: Amazon DynamoDB (Part 4)</a></li>\n      <li><a href=\"https://www.hemantkgupta.com/p/insights-from-paper-part-ii-dynamo\">Insights from paper (Part II) — Dynamo: Amazon’s Highly Available Key-value Store</a></li>\n      <li><a href=\"https://efficientcodeblog.wordpress.com/2017/12/26/read-repair-and-anti-entropy-two-ways-to-remedy-replication-lag-in-dynamo-style-datastores-leaderless-replication/\">Read Repair and Anti-Entropy : Two Ways To Remedy Replication Lag in Dynamo-style Datastores (Leaderless Replication)</a></li>\n    </ul>\n  </li>\n  <li>p.188. Concurrent: 한 작업이 다른 작업 이전에 발생했는지가 동시성의 의미를 정의하는 핵심. 사실 작업이 다른 작업보다 먼저 발생하지 않으면 (즉 어느 작업도 다른 작업에 대해 알지 못한다면) 단순히 동시 작업이라 말한다.\n    <ul>\n      <li>동시성을 정의하기 위해 정확한 시각은 중요하지 않다. 두 작업이 발생한 물리적인 시각보다 각 작업이 서로 알지 못하면 단순히 두 작업은 동시에 수행됐다 말한다.</li>\n    </ul>\n  </li>\n</ul>\n\n<hr />\n\n<h2 id=\"06장-파티셔닝\">06장: 파티셔닝</h2>\n\n<ul>\n  <li>p199 데이터셋이 매우 크거나 질의 처리량이 매우 높다면 복제만으로는 부족하고 데이터를 파티션으로 쪼갤 필요가 있다. 이 작업을 샤딩이라고도 한다.</li>\n  <li>p200 파티셔닝하는 주된 이유는 확장성.  단일 파티션에 실행되는 질의를 생각해 보면 각 노드에서 자신의 파티션에 해당하는 질의를 독립적으로 실행할 수 있으므로 노드를 추가함으로써 질의 처리량을 늘릴 수 있다. 크고 복잡한 질의는 훨씬 더 어렵기는 하지만 여러 노드에서 병렬 실행이 가능하다.</li>\n  <li>p203 키 범위 기준 파티셔닝은 특정한 접근 패턴이 핫스팟을 유발하는 단점이 있다.</li>\n  <li>p203 좋은 해시 함수는 쏠린 데이터를 입력으로 받아 균일하게 분산되게 한다.</li>\n  <li>p204 파티셔닝에 키의 해시값을 사용해서 파티셔닝하면 키 범위 파티셔닝의 좋은 속성을 잃어 버린다. 바로 범위 질의를 효율적으로 실행할 수 있는 능력이다. 전에는 인접했던 키들이 이제는 모든 파티션에 흩어져서 정렬 순서가 유지되지 않는다.</li>\n  <li>p204 복합 키의 첫 번째 컬럼에 값 범위로 검색하는 질의를 쓸 수 없지만,  첫 번째 칼럼에 고정된 값을 지정하면 키의 다른 컬럼에 대해서는 범위 스캔 가능</li>\n  <li>Partitioning Secondary Indexes by Document:\n    <ul>\n      <li>p207 각 파티션이 독립적. 자신의 보조 인덱스를 유지하며 그 파티션에 속하는 문서만 담당. 다른 파티션에 어떤 데이터가 저장되는지는 신경 쓰지 않음.</li>\n      <li>p207 보조 인덱스를 써서 읽는 질의는 큰 비용 발생. 여러 파티션에서 질의를 병렬 실행하더라도 꼬리 지연 시간 증폭이 발생하기 쉬움.</li>\n    </ul>\n  </li>\n  <li>Partitioning Secondary Indexes by Term:\n    <ul>\n      <li>p208 모든 파티션의 데이터를 담당하는 전역 색인을 만들 수도 있음</li>\n      <li>p208 용어 자체로 파티셔닝하면 범위 스캔에 유용함.  반면 용어의 해시값을 사용해 파티셔닝하면 부하가 좀 더 고르게 분산됨.</li>\n      <li>p208 읽기 효율적.  쓰기가 느리고 복잡함.</li>\n      <li>p209 대개 비동기로 갱신됨.  쓰기를 실행한 후 바로 인덱스를 읽으면 변경 사항이 반영되지 않을 수도 있다.</li>\n    </ul>\n  </li>\n  <li>Rebalancing Partitions:\n    <ul>\n      <li>p209 리밸런싱:  클러스터에서 한 노드가 담당하던 부하를 다른 노드로 옮기는 과정</li>\n      <li>p210 mod 연산 쓰지 마라.  리밸런싱 비용 지나치게 커지고, 데이터를 필요 이상으로 이동하지 않는 방법 필요.</li>\n      <li>p211 파티션 개수 고정:  파티션이 너무 크면 리밸런싱을 실행할 때와 노드 장애로부터 복구 비용이 큼.  그러나 파티션이 너무 작으면 오버헤드가 너무 커짐.</li>\n      <li>p212 동적 파티셔닝:  파티션 개수가 전체 데이터 용량에 맞춰 조정되는 이점.  파티션 개수가 데이터셋 크기에 비례.  데이터 양이 작으면 파티션 개수가 적어도 되므로 오버헤드 적다.   HBase, MongoDB는 빈 디비에 초기 파티션 집합 설정(pre-splitting)</li>\n      <li>p213 노드 비례 파티셔닝:  노드 대수가 변함 없는 동안은 개별 파티션 크기가 데이터셋 크기에 비례.  노드 대수 늘리면 파티션 크기 다시 작아짐.</li>\n    </ul>\n  </li>\n  <li>카산드라\n    <ul>\n      <li>https://d2.naver.com/helloworld/1039</li>\n      <li>https://tjddnjs.tistory.com/91</li>\n      <li>p.213 리밸런싱 알고리즘 <a href=\"https://www.datastax.com/blog/new-token-allocation-algorithm-cassandra-30\">New token allocation algorithm in Cassandra 3.0</a></li>\n      <li>p.216 가십 프로토콜  <a href=\"https://docs.datastax.com/en/cassandra-oss/3.x/cassandra/architecture/archGossipAbout.html\">Apache Cassandra™ 3.x - Internode communications (gossip)</a></li>\n    </ul>\n  </li>\n</ul>\n\n<hr />\n\n<h2 id=\"07장-트랜잭션\">07장: 트랜잭션</h2>\n\n<ul>\n  <li>p222 트랜잭션은 전체가 성공(commit)하거나 실패(abort, rollback).</li>\n</ul>\n\n<h4 id=\"p223-acid\">p223 ACID</h4>\n\n<p><strong>Atomicity</strong></p>\n\n<ul>\n  <li>Not\n    <ul>\n      <li>In the context of ACID, atomicity is <strong><em>not</em></strong> about concurrency.</li>\n      <li>It does not describe what happens if several processes try to access the same data at the same time, because that is covered under the letter <em>I</em>, for <em><strong>isolation</strong>.</em></li>\n    </ul>\n  </li>\n  <li>여러 쓰기 작업이 하나의 원자적인 트랜잭션으로 묶여 있는데 결함 때문에 완료(commit)될 수 없다면 abort되고 데이터베이스는 이 트랜잭션에서 지금까지 실행한 쓰기를 무시하거나 취소(undo) 해야 한다.</li>\n  <li>Perhaps <strong><em>abortability</em></strong> would have been a better term than <em><strong>atomicity</strong>.</em></li>\n</ul>\n\n<p>Consistency</p>\n\n<ul>\n  <li>The idea of ACID consistency is that you have certain statements about your data (<strong><em>invariants</em></strong>) that must always be true.</li>\n  <li>it’s the application’s responsibility to define its transactions correctly so that they preserve consistency.</li>\n  <li>The letter C doesn’t really belong in ACID.\n    <ul>\n      <li><strong>Atomicity</strong>, <strong>Isolation</strong>, <strong>Durability</strong> are properties of the database, whereas <strong>Consistency</strong> (in the ACID sense) is a property of the application.</li>\n    </ul>\n  </li>\n</ul>\n\n<p><strong>Isolation</strong></p>\n\n<ul>\n  <li>In the sense of ACID means that concurrently executing transactions are isolated from each other: they cannot step on each other’s toes.</li>\n  <li>The database ensures that when the transactions have committed, the result is the same as if they had run <strong><em>serially</em></strong> (one after another), even though in reality they may have run concurrently.</li>\n</ul>\n\n<p><img src=\"/images/2024/06/22/07-transaction-race-conditon.png\" alt=\"transaction-race-conditon\" title=\"transaction-race-conditon\" class=\"center-image\" /></p>\n\n<p><strong>Durability</strong></p>\n\n<ul>\n  <li>any data it has written will not be forgotten.</li>\n</ul>\n\n<p><strong>Single-Object and Multi-Object Operations</strong></p>\n\n<ul>\n  <li><strong>atomicity</strong> and <strong>isolation</strong> describe what the database should do if a client makes several writes within the same transaction.\n    <ul>\n      <li><strong><em>Atomicity:</em></strong>  If an error occurs halfway through a sequence of writes, the transaction should be aborted, and the writes made up to that point should be discarded. In other words, the database saves you from having to worry about partial failure, by giving an all-or-nothing guarantee.</li>\n      <li><em><strong>Isolation</strong>:</em>  Concurrently running transactions shouldn’t interfere with each other. For example, if one transaction makes several writes, then another transaction should see either all or none of those writes, but not some subset.</li>\n    </ul>\n  </li>\n  <li>A transaction is usually understood as a mechanism for grouping multiple operations on multiple objects into one unit of execution.</li>\n</ul>\n\n<p><strong>Handling errors and aborts</strong></p>\n\n<ul>\n  <li><strong>best effort</strong>:  “the database will do as much as it can, and if it runs into an error, it won’t undo something it has already done”.  so it’s the application’s responsibility to recover from errors.</li>\n  <li>the whole point of aborts is to enable safe retries.</li>\n</ul>\n\n<h3 id=\"p232-weak-isolation-levels\">p232 <strong>Weak Isolation Levels</strong></h3>\n\n<ul>\n  <li><strong><em>serializable</em> isolation</strong>:  the database guarantees that transactions have the same effect as if they ran <em>serially</em> (i.e., one at a time, without any concurrency).</li>\n</ul>\n\n<p><strong>Read Committed</strong></p>\n\n<ol>\n  <li>When reading from the database, you will only see data that has been committed\n(no <em>dirty reads</em>).\n    <ul>\n      <li>아직 커밋되지 않은 롤백 데이터 읽을 수 있음  If the database allows dirty reads, that means a transaction may see data that is later rolled back—i.e., which is never actually committed to the database. Reasoning about the consequences quickly becomes mind-bending.</li>\n      <li>새 값이 커밋돼야만 다른 트랜잭션들이 새 값을 읽을 수 있음. While the transaction is ongoing, any other transactions that read the object are simply given the old value. Only when the new value is committed do transactions switch over to reading the new value.</li>\n    </ul>\n  </li>\n  <li>When writing to the database, you will only overwrite data that has been committed (no <em>dirty writes</em>).</li>\n</ol>\n\n<p><strong>p236-240. Snapshot Isolation and Repeatable Read</strong></p>\n\n<ul>\n  <li>Read skew is considered acceptable under read committed isolation.\n    <ul>\n      <li>skew; <em>timing anomaly</em>.</li>\n    </ul>\n  </li>\n  <li><strong><em>readers never block writers, and writers never block readers</em></strong>.</li>\n  <li><strong><em>multi-version concurrency control</em> (MVCC)</strong></li>\n</ul>\n\n<p><img src=\"/images/2024/06/22/07-transaction-multi-version.png\" alt=\"transaction-multi-version\" title=\"transaction-multi-version\" class=\"center-image\" /></p>\n\n<ul>\n  <li>객체를 볼 수 있는 조건:\n    <ul>\n      <li>읽기 트랜잭션 실행 시점에 이미 커밋된 상태여야함. At the time when the reader’s transaction started, the transaction that created the\n  object had already committed.</li>\n      <li>The object is not marked for deletion, or if it is, the transaction that requested\n  deletion had not yet committed at the time when the reader’s transaction started.</li>\n    </ul>\n  </li>\n</ul>\n\n<h3 id=\"p242-preventing-lost-updates\"><strong>p242~ Preventing Lost Updates</strong></h3>\n\n<ul>\n  <li>The read committed and snapshot isolation levels:  동시 쓰기할 때 read-only 트랜잭션이 무엇을 볼 수 있는지. The guarantees of what a read-only transaction can see in the presence of concurrent writes.</li>\n  <li>If two transactions do this concurrently, one of the modifications can be lost, because the second write does not include the first modification. (later write <em>clobbers</em> the earlier write.)</li>\n</ul>\n\n<p><strong>Atomic write operations</strong></p>\n\n<ul>\n  <li>MongoDB(document db);  atomic operations for making local modifications to a part of a JSON document.</li>\n  <li>Redis;  atomic operations for modifying data structures such as priority queues.</li>\n  <li>Atomic operations are usually implemented by taking an exclusive lock on the object.</li>\n</ul>\n\n<p><strong>Explicit locking</strong></p>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">SELECT **FOR UPDATE**;</code></li>\n  <li>It’s easy to forget to add a necessary lock somewhere in the code, and thus introduce a race condition.</li>\n</ul>\n\n<p><strong>Compare-and-set</strong></p>\n\n<ul>\n  <li>마지막으로 읽은 후로 변경되지 않았을 때만 갱신 허용.  To avoid lost updates by allowing an update to happen only if the value has not changed since you last read it.</li>\n  <li>if the database allows the WHERE clause to read from an old snapshot, this statement may not prevent lost updates.\n    <ul>\n      <li>because the condition may be true even though another concurrent write is occurring.</li>\n    </ul>\n  </li>\n</ul>\n\n<p><strong>Conflict resolution and replication</strong></p>\n\n<ul>\n  <li>여러 충돌 버전 생성을 허용하고 사후에 충돌 해소. Allow concurrent writes to create several conflicting versions of a value (also known as <em>siblings</em>), and to use application code or\nspecial data structures to resolve and merge these versions after the fact.</li>\n  <li>최종 쓰기 승리는 갱신 손실 발생하기 쉬움.  The <strong><em>last write wins</em> (LWW)</strong> conflict resolution method is prone to lost updates.  LWW is the default in many replicated databases.</li>\n</ul>\n\n<p><strong>p246 Write Skew and Phantoms</strong></p>\n\n<p><strong>Characterizing write skew</strong></p>\n\n<ul>\n  <li>쓰기 스큐는 두 트랜잭션이 다른 객체 갱신.  dirty write와 lost update는 다른 트랜잭션이 하나의 동일 객체 갱신.   Write skew can occur if two transactions read the same objects, and then update some of those objects (different transactions may update different objects). In the special case where different transactions update the same object, you get a dirty write or lost update anomaly (depending on the timing).</li>\n  <li>직렬성 격리로 write skew 자동 방지.  Automatically preventing write skew requires true serializable isolation.</li>\n  <li>차선책; serializable isolation 사용할 수 없으면 트랜잭션이 의존하는 로우 잠그기.</li>\n</ul>\n\n<p><strong>Phantoms causing write skew</strong></p>\n\n<ul>\n  <li><em><strong>phantom</strong>:</em>  쓰기가 다른 트랜잭션의 검색 질의 결과를 바구는 현상.  Where a write in one transaction changes the result of a search query in another transaction.</li>\n</ul>\n\n<p>AWS Summit &lt;채널톡의 RDBMS에서 NoSQL 전환&gt; 세션 내용</p>\n\n<ul>\n  <li>특정 시점 스파이크 트래픽과 리소스 비효율 문제 해결을 위해 DynamoDB 도입</li>\n  <li>채팅 뱃지 카운트 트랜잭션 동시성 처리: Optimistic lock 이용해서 conflicts 발생시 exponential backoff</li>\n</ul>\n\n<p><img src=\"/images/2024/06/22/07-aws-summit-dynamodb-0.png\" alt=\"aws-summit-dynamodb\" title=\"aws-summit-dynamodb\" class=\"center-image\" /></p>\n\n<p><img src=\"/images/2024/06/22/07-aws-summit-dynamodb-1.png\" alt=\"aws-summit-dynamodb\" title=\"aws-summit-dynamodb\" class=\"center-image\" /></p>\n\n<p><img src=\"/images/2024/06/22/07-aws-summit-dynamodb-2.png\" alt=\"aws-summit-dynamodb\" title=\"aws-summit-dynamodb\" class=\"center-image\" /></p>\n\n<p><img src=\"/images/2024/06/22/07-aws-summit-dynamodb-3.png\" alt=\"aws-summit-dynamodb\" title=\"aws-summit-dynamodb\" class=\"center-image\" /></p>\n\n<h3 id=\"p251-serializability\"><strong>p251 Serializability</strong></h3>\n\n<ul>\n  <li>Testing for concurrency issues is hard, because they are usually nondeterministic — problems only occur if you get unlucky with the timing.</li>\n  <li>the strongest isolation level.</li>\n  <li>It guarantees that even though transactions may execute in parallel, the end result is the same as if they had executed one at a time, <strong><em>serially</em></strong>, without any concurrency.</li>\n  <li>the database prevents <strong><em>all</em></strong> possible race conditions.</li>\n  <li>2007년경이 돼서야 단일 스레드 루프에서 트랜잭션 실행하는게 실현 가능하다고 결론 내림\n    <ul>\n      <li>램 가격.  모든 데이터를 메모리 적재해서 트랜잭션 빠르게 실행.</li>\n      <li>OLTP 트랜잭션이 보통 짧고 실행하는 읽기와 쓰기 개수가 적음.</li>\n    </ul>\n  </li>\n  <li>단일 스레드 기반 시스템이 동시성을 지원하는 시스템보다 성능이 나을때가 있음.  잠금 오버헤드 피할 수 있기 때문.  A system designed for single-threaded execution can sometimes perform better than a system that supports concurrency, because it can avoid the coordination overhead of locking.</li>\n</ul>\n\n<p><strong>Encapsulating transactions in stored procedures</strong></p>\n\n<ul>\n  <li>데이터가 모두 메모리에 있고 프로시저는 네트워크나 디스크 I/O 대기 없이 매우 빠르게 실행된다고 가정.  Provided that all data required by a transaction is in memory, the stored procedure can execute very fast, without waiting for any network or disk I/O.</li>\n</ul>\n\n<p><img src=\"/images/2024/06/22/07-transaction-difference.png\" alt=\"transaction-difference\" title=\"transaction-difference\" class=\"center-image\" /></p>\n\n<p><strong>Partitioning</strong></p>\n\n<ul>\n  <li>동시성 제어는 간단해지지만 단일 장비의 단일 CPU 코어 속도 제한. Executing all transactions serially makes concurrency control much simpler, but limits the transaction throughput of the database to the speed of a single CPU core on a\nsingle machine.</li>\n</ul>\n\n<p><strong>Two-Phase Locking (2PL)</strong></p>\n\n<ul>\n  <li>2PL:  쓰기는 다른 쓰기와 읽기 진행하지 못하게 막음. writers don’t just block other writers; they also block readers and vice versa.</li>\n  <li>Snapshot isolation:  읽기와 쓰기 양쪽 모두 막지 못하는 원칙.  the mantra <em>readers never block writers, and writers never block.</em></li>\n  <li>lock: <strong><em>shared mode</em></strong> or in <strong><em>exclusive mode</em></strong></li>\n  <li>Performance\n    <ul>\n      <li>This is partly due to the overhead of acquiring and releasing all those locks, but more importantly due to reduced concurrency.</li>\n    </ul>\n  </li>\n  <li>Pessimistic vs. optimistic concurrency control\n    <ul>\n      <li><strong>Pessimistic</strong>: if anything might possibly go wrong (as indicated by a lock held by another transaction), it’s better to wait until the situation is safe again before doing anything.</li>\n      <li><strong>Optimistic</strong>: instead of blocking if something potentially dangerous happens, transactions continue anyway, in the hope that everything will turn out all right.</li>\n    </ul>\n  </li>\n</ul>\n\n<p>Performance of serializable snapshot isolation</p>\n\n<ul>\n  <li>잠금 때문에 트랜잭션 차단될 필요 없음. Compared to two-phase locking, the big advantage of serializable snapshot isolation is that one transaction doesn’t need to block waiting for locks held by another transaction.</li>\n  <li>The rate of aborts significantly affects the overall performance of SSI. For example, a transaction that reads and writes data over a long period of time is likely to run into conflicts and abort, so SSI requires that read-write transactions be fairly short (long- running read-only transactions may be okay)</li>\n</ul>\n\n<hr />\n\n<h2 id=\"08장-분산-시스템의-골칫거리\">08장: 분산 시스템의 골칫거리</h2>\n\n<ul>\n  <li>p274 엔지니어로서의 우리의 임부는 모든 게 잘못되더라도 제 역할을 해내는 시스템을 구축하는것.  In the end, our task as engineers is to build systems that do their job (i.e., meet the guarantees that users are expecting), in spite of everything going wrong.</li>\n  <li><strong>Faults and Partial Failures</strong>\n    <ul>\n      <li><strong><em>deterministic</em></strong>: ex. 하드웨어가 올바르게 동작하면 같은 연산은 항상 같은 결과를 낸다.</li>\n      <li><strong><em>partial failure</em></strong>: 분산 시스템에서 시스템의 일부만 고장. <strong><em>nondeterministic</em></strong></li>\n    </ul>\n  </li>\n  <li>p276 분산 시스템이 동작하게 만들려면 partial failure 가능성을 받아들이고 소프트웨어에 <strong>내결함성 메커니즘</strong>(fault-tolerance mechanisms)을 넣어야 한다. 신뢰성 없는 구성 요소를 사용해 신뢰성 있는 시스템을 구축해야 함.   In other words, we need to build a reliable system from unreliable components.</li>\n  <li><strong>Unreliable Networks</strong>\n    <ul>\n      <li>p279 비동기 네트워크.. 유일한 정보는 응답을 아직 받지 못했다는 것. 응답을 다른 노드로 요청을 보내서 응답을 받지 못했다면 그 이유를 아는 것은 불가능.   이런 문제를 다루는 흔한 방법이 타임아웃.</li>\n    </ul>\n  </li>\n  <li><strong>Timeouts and Unbounded Delays</strong>\n    <ul>\n      <li>타임아웃이 길면 노드가 죽었다고 선언될 때까지 기다리는 시간이 길어짐.  타임아웃이 짧으면 결함을 빨리 발견하지만  노드가 일시적으로 느려졌을 뿐인데도 죽었다고 잘못 선언할 가능성.</li>\n      <li>2d + r;  d: 전송 시간, r: 요청 처리 시간</li>\n      <li>기약 없는 지연(unbounded delay): 패킷을 가능한 한 빨리 보내려고 하지만 패킷이 도착하는데 걸리는 시간에 상한치는 없다.</li>\n    </ul>\n  </li>\n</ul>\n\n<p><strong>Network congestion and queueing</strong></p>\n\n<ul>\n  <li>p282 TCP 흐름제어(flow control). 노드가 네트워크 링크나 수신 노드에 과부하를 가하지 않도록 자신의 송신율을 제한.</li>\n  <li>TCP는 어떤 타임아웃(왕복 시간을 관찰해서 계산)  안에 확인 응답을 받지 않으면 패킷이 손실됐다고 간주하고 손실된 패킷은 자동으로 재전송.  애플리케이션에게는 패킷 손실이나 재전송이 보이지 않지만 그 결과로 생기는 지연 발생(타임아웃 만료 + 재전송 패킷 확인 응답)\n    <ul>\n      <li><a href=\"https://alden-kang.tistory.com/20\">Connection Timeout과 Read Timeout 살펴보기</a></li>\n      <li><a href=\"https://brunch.co.kr/@alden/15\">TCP retransmission과 튜닝 포인트</a></li>\n      <li>두 글 요약하자면 → 커넥션 타임아웃은 3초로 적당한거같다. TCP 는 재전송 메커니즘이 있어서 이 때 타임아웃이 1초임. 그래서 3초 정도가 적덩한거같다. Read Timeout 은 300ms 였어서 1초</li>\n    </ul>\n  </li>\n  <li>p284  고정된 타임아웃을 설정하는 대신 시스템이 지속적으로 응답 시간과 그들의 변동성을 측정,   관찰된 응답 시간 분포에 따라 타임아웃을 자동 조정.\n    <ul>\n      <li><a href=\"https://doc.akka.io/docs/akka/current/typed/failure-detector.html\">Phi Accrual Failure Detector - akka</a></li>\n      <li><a href=\"https://medium.com/@arpitbhayani/phi-%CF%86-accrual-failure-detection-79c21ce53a7a\">Phi φ Accrual Failure Detection</a>\n        <ol>\n          <li><strong>Suspicion Level (φ value):</strong>\n            <ul>\n              <li>φ 값은 수신된 하트비트(heartbeat) 사이의 시간 간격을 기반으로 계산. 이 값은 현재 네트워크 상태를 반영하도록 지속적으로 조정. φ 값이 높을수록 노드가 실패했을 가능성이 높다는 것을 의미.</li>\n            </ul>\n          </li>\n          <li><strong>Heartbeat Intervals</strong>:\n            <ul>\n              <li>노드로부터 모니터링. interval은 샘플 윈도우에 저장되어 분포를 추정하고 의심 수준을 계산하는 데 사용</li>\n            </ul>\n          </li>\n          <li><strong>Dynamic Thresholds</strong>:\n            <ul>\n              <li>φ 값은 시스템이 다양한 동적 임계값을 설정. 예를 들어, φ 값이 특정 임계값을 초과하면 노드를 실패한 것으로 간주할 수 있지만, 더 낮은 φ 값에서는 예방 조치를 시작할 수 있다.</li>\n            </ul>\n          </li>\n        </ol>\n      </li>\n      <li>A → B → C 순으로 호출한다고 하자. A를 관리하고있다면 B에서 지연된건지 C에서 지연된건지 찾는데, 데이터독으로 트레이싱하고있어서, 최근 n일 기준으로 API 의 latency 를 보고. 가령 B→C가 50ms 라면 Read Timeout 고려해서 500ms 정도로 잡고, A→B 구간에서는 500보다 좀 더 크게 잡고.</li>\n    </ul>\n  </li>\n</ul>\n\n<p><strong>Synchronous Versus Asynchronous Networks</strong></p>\n\n<ul>\n  <li>p284 전화 네트워크. 고정 회선.\n    <ul>\n      <li>bounded delay(제한 있는 지연):  네트워크의 다음 홉에 통화당 16비트 공간을 미리 할당.  그리고 큐 대기가 없으므로 종단 지연 시간의 최대치가 고정되어 있음.</li>\n    </ul>\n  </li>\n</ul>\n\n<p><strong>Can we not simply make network delays predictable?</strong></p>\n\n<ul>\n  <li>데이터센터 네트워크와 인터넷은 패킨 교환 사용;  bursty traffic 에 최적화</li>\n  <li>회선; 통화를 하는 동안 보내는 초당 비트 개수가 상당히 고정돼 있는 음성과 영상 통화에 적합</li>\n  <li>웹 페이지 요청, 이메일 전송, 파일 전송은 특별한 대역폭 요구사항 없음. 단지 가능하면 빨리 완료되기를 바람.</li>\n</ul>\n\n<p><strong>p287 Unreliable Clocks</strong></p>\n\n<ul>\n  <li>시간, 시계와 관련된 질문을 Durations(지속 시간), Points in time(시점)에 따라 기술</li>\n</ul>\n\n<p><strong>Synchronized clocks for global snapshots</strong></p>\n\n<ul>\n  <li>p295 스패너에 대한 이야기(feat. ChatGPT):\n    <ul>\n      <li>데이터베이스 내의 여러 트랜잭션 간의 인과 관계를 고려하여 타임스탬프를 부여\n        <ul>\n          <li><strong>트랜잭션 타임스탬프:</strong> 각 트랜잭션이 완료된 시점(시간). 트랜잭션의 순서를 정하고, 데이터의 일관성을 유지하는 데 중요</li>\n          <li><strong>인과성(Causality)</strong>: 한 트랜잭션이 다른 트랜잭션에 영향을 미치는 관계.  예를 들어, 트랜잭션 A가 트랜잭션 B보다 먼저 실행되고, B가 A의 결과에 의존하는 경우, A는 B의 원인이 된다.\n      1. <strong>TrueTime API</strong>:</li>\n          <li>TrueTime API를 사용하여 각 트랜잭션에 정확한 타임스탬프를 부여. TrueTime은 GPS 및 원자시계 정보를 활용하여 매우 정확한 시각 정보를 제공.</li>\n          <li>TrueTime의 사용으로 인해 각 트랜잭션의 완료 시점에 대해 상한(earliest) 및 하한(latest) 시간을 알 수 있으며, 이를 통해 트랜잭션 간의 정확한 순서를 결정.\n      2. <strong>트랜잭션 순서 보장</strong>:</li>\n          <li>트랜잭션 간의 인과 관계를 보장하기 위해, 이전 트랜잭션이 완료된 후에만 다음 트랜잭션을 수행. 이는 인과 관계가 반영된 타임스탬프를 부여하는데 중요한 역할을 한다.\n      3. <strong>Globally Consistent Reads and Writes</strong>:</li>\n          <li>이러한 타임스탬프 메커니즘 덕분에, Spanner는 전 세계에 분산된 데이터베이스에서도 강력한 일관성을 유지할 수 있습니다. 각 트랜잭션의 타임스탬프가 인과성을 반영하기 때문에, 사용자는 일관된 데이터를 읽고 쓸 수 있습니다.</li>\n        </ul>\n      </li>\n      <li><a href=\"https://cloud.google.com/spanner/docs/true-time-external-consistency\">Spanner: TrueTime and external consistency</a></li>\n      <li><a href=\"https://pdfs.semanticscholar.org/e3d0/9699c66bd0b89f663954bf8b043491368620.pdf\">Spanner: Google’s Globally-Distributed Database</a></li>\n    </ul>\n  </li>\n</ul>\n\n<p><strong>Process Pauses</strong></p>\n\n<ul>\n  <li>note) p297. 실행 중인 스레드를 어떤 시점에 선점(preempt)하고 얼마만의 시간이 흐른후 재개할 수 있다.  선점된 스레드는 이를 알아채지 못한다.  이 문제는 단일 장비에서 다중 스레드 코드를 thread-safe 하게 만드는 것과 비슷.   컨텍스트 스위치가 임의로 발생할 수 있고 병렬(parallelism)이 발생할 수 도 있으므로 타이밍에 대해 어떤 가정도 할 수 없다.</li>\n</ul>\n\n<p><strong>Knowledge, Truth, and Lies</strong></p>\n\n<ul>\n  <li>p300 인식하고 측정하는 수단을 믿을 수 없다면 그 지식을 어떻게 확신할 수 있나? How sure can we be of that knowledge, if the mechanisms for perception and measurement are unreliable?</li>\n</ul>\n\n<p><strong>The Truth Is Defined by the Majority</strong></p>\n\n<ul>\n  <li>p301 노드가 상황에 대한 자신의 판단을 반드시 믿을 수 있는 것은 아님.  분산 시스템은 한 노드에만 의존할 수는 없다. 노드에 언제든 장애가 나서 잠재적으로 시스템이 멈추고 복구할 수 없게 될 수도 있기 때문이다.  <strong>정족수(quorum)</strong></li>\n</ul>\n\n<p><strong>Fencing tokens</strong></p>\n\n<ul>\n  <li>p303 잠금이 승인될 때마다 증가하는 숫자.</li>\n</ul>\n\n<p><img src=\"/images/2024/06/22/08-fencing-token.png\" alt=\"fencing-token\" title=\"fencing-token\" class=\"center-image\" /></p>\n\n<ul>\n  <li>자원 자체가 이미 처리된 것보다 오래된 토큰을 사용해서 쓰는 것을 거부함으로써 토큰을 확인하는 활동적인 역할을 맡아야 함.</li>\n</ul>\n\n<p><strong>Byzantine Faults</strong></p>\n\n<ul>\n  <li>p304 어떤 노드가 실제로는 받지 않은 특정 메시지를 받았다고 주장…</li>\n  <li>비잔틴 결함(<em>Byzantine fault</em>), 비잔틴 장군 문제(<em>Byzantine Generals Problem</em>)\n    <ul>\n      <li><a href=\"https://monday9pm.com/%EB%A9%94%EC%8B%9C%EC%A7%80-%EC%A0%84%EB%8B%AC-%EC%A0%84%EB%9E%B5%EA%B3%BC-%EB%91%90-%EC%9E%A5%EA%B5%B0-%EB%AC%B8%EC%A0%9C-message-delivery-semantics-and-two-generals-problem-f8f1c7646c0b\"><strong>메시지 전달 전략과 두 장군 문제(Message Delivery Semantics and Two Generals’ Problem)</strong></a></li>\n      <li><a href=\"https://lwn.net/Articles/540368/\"><strong>ELC: SpaceX lessons learned</strong></a>\n        <ul>\n          <li>SpaceX에서는 Falcon, Dragon, Grasshopper 등의 비행 제어, 지상 스테이션, 개발자 데스크톱까지 모든 것이 리눅스.</li>\n          <li>fault-tolerant(내결함성/결함 허용)을 위해 3중으로 시스템을 구성하고 비잔틴 장군 알고리즘을 사용. 우주 정거장(ISS)에 접근할 때, 결함 허용 수준을 만족해야만 정거장에 접근할 수 있음.  이를 위해 삼중 중복 컴퓨터를 사용해서 필요한 수준의 결함 허용을 달성.</li>\n          <li>비잔틴 장군 알고리즘은 컴퓨터들이 동의하지 않는 상황을 처리하는 데 사용. 이런 상황은 방사선 사건으로 인해 메모리나 레지스터 값이 변경되는 경우 발생.</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n  <li><strong><em>Byzantine fault-tolerant</em></strong> :  일부 노드가 오작동하고 프로토콜을 준수하지 않거나 악의적인 공격자가 네트워크를 방해하더라도 시스템이 계속 올바르게 동작</li>\n  <li>보통 비잔틴 결함이 없다고 가정할 수 있다. 우리 조직이 모든 노드 제어.. 방사선 수준은 큰 문제 아님..</li>\n</ul>\n\n<p><strong>Safety and liveness</strong></p>\n\n<ul>\n  <li>p308  안전성(나쁜 일은 일어나지 않는다), 활동성(좋은 일은 결국 일어난다).  Safety is often informally defined as <strong><em>nothing bad happens</em></strong>, and liveness as <strong><em>something good eventually happens</em></strong>.</li>\n</ul>\n\n<p>정리</p>\n\n<ul>\n  <li>결함을 견뎌내려면 그것을 감지하는 게 첫 걸음이지만 그것조차 어렵다.</li>\n  <li>대부분의 시스템은 노드에 장애가 발생했는지 알 수 있는 정확한 메커니즘이 없어서 대부분의 분산 알고리즘은 원격 노드를 아직 쓸 수 있는지 결정하기 위해 타임아웃을 사용.</li>\n  <li>그러나 타임아웃은 네트워크 장애와 노드 장애를 구별할 수 없고 변동이 큰 네트워크 지연 때문에 때때로 노드가 죽은 것으로 잘못 의심받을 수 있다.</li>\n</ul>\n\n<hr />\n\n<h2 id=\"09장-일관성과-합의p349\">09장: 일관성과 합의(~p.349)</h2>\n\n<p><strong>p.321 Consistency Guarantees</strong></p>\n\n<ul>\n  <li>약한 보장(weak guarantee): 복제 데이터 베이스는 대부분 최소한 <strong>최종적 일관성</strong>(<strong><em>eventual consistency**)</em>을 제공한다. 하지만 언제 **수렴</strong>(<strong><em>convergence</em></strong>) 될 지 모름.</li>\n  <li>강한 보장(strongest consistency):  데이터 시스템이 선택적으로 제공. 성능이 나쁘거나 약한 보장을 제공하는 시스템보다 내결함성이 약할 수 있음.</li>\n  <li>트랜잭션 격리 수준과의 차이점;\n    <ul>\n      <li>트랜잭션 격리:  주로 동시에 실행되는 트랜잭션 때문에 발생하는 경쟁 조건을 회피하는 것에 관한 것.</li>\n      <li>분산 일관성:  대개 지연과 결함이 있더라도 복제본의 상태를 코디네이션하는 것</li>\n    </ul>\n  </li>\n</ul>\n\n<p>p322 <strong>Linearizability</strong></p>\n\n<ul>\n  <li>“데이터베이스가 복제본이 하나만 있다면 훨씬 더 단순해 지지 않을까?”  원자적 일관성(<em>atomic consistency</em>), 강한 일관성(<em>strong consistency</em>), 즉각 일관성(<em>immediate consistency</em>), 외부 일관성(<em>external consistency</em>)</li>\n</ul>\n\n<p><img src=\"/images/2024/06/22/09-consistency.png\" alt=\"consistency\" title=\"consistency\" class=\"center-image\" /></p>\n\n<ul>\n  <li>최신성 보장(recency guarantee)</li>\n</ul>\n\n<p>시스템에 선형성을 부여하는 것</p>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">*cas*(*x*, *v*old, *v*new) ⇒ *r*</code>:\n    <ul>\n      <li>클라이언트가 cas(compare-and-set) 연산 요청</li>\n      <li>레지스터 x의 현재 값이 Vold과 같으면 Vnew로 설정하고 아니면 오류 발환(error)</li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"/images/2024/06/22/09-linearizability.png\" alt=\"linearizability\" title=\"linearizability\" class=\"center-image\" /></p>\n\n<ul>\n  <li>p332 요약; 다이나모 스타일 복제를 하는 리더 없는 시스템은 선형성을 제공하지 않는다고 보는 게 안전.</li>\n</ul>\n\n<p>p333 선형성의 비용</p>\n\n<ul>\n  <li>단일 리더 설정에서 데이터센터 사이에 연결 끊기면 선형성 읽기 불가능.  팔로워로부터 읽을 수는 있지만 데이터가 뒤쳐졌을 수 있다(비선형적).</li>\n</ul>\n\n<p>p335 CAP</p>\n\n<ul>\n  <li>네트워크 결함이 생기면 선형성과 완전한 가용성 사이에서 선택해야 함.  CAP는 <strong>네트워크 분단이 생겼을때 일관성과 가용성 중 하나를 선택</strong>하라는 의미.</li>\n</ul>\n\n<p><strong>p342 비인과적 일련번호 생성기(Noncausal sequence number generators)</strong></p>\n\n<ul>\n  <li>노드별) 각 노드 개별로 독립적인 일련번호 집합 생성. 예) 한 노드는 홀수만, 다른 노드는 짝수만 생성.</li>\n  <li>잘 동작하지만 생성한 일련번호가 인과성에 일관적이지 않음(timestamp 불일치)</li>\n</ul>\n\n<p><strong>p343 Lamport timestamps</strong></p>\n\n<ul>\n  <li>&lt;카운터, 노드&gt; ID 조합.</li>\n  <li>때때로 카운터 값이 같을 수 있지만 타임스탬프에 노드 ID를 포함시켜서 각 타임스탬프 유일.</li>\n  <li>물리적 일 기준 시계와 아무 관련이 없지만 전체 순서화를 제공.</li>\n  <li>버전 벡터와의 차이;\n    <ul>\n      <li>버전 벡터:  두 연산이 동시적인지 또는 어떤 연산이 다른 연산에 인과적으로 의존하는지 구별</li>\n      <li>램포트 타임스탬프:  항상 전체 순서화를 강제화</li>\n    </ul>\n  </li>\n</ul>\n\n<p><strong>Total Order Broadcast</strong></p>\n\n<ul>\n  <li>p346  후속 메시지가 이미 전달됐다면 노드는 그 순서의 앞에 메시지를 소급적으로 끼워넣는 게 허용되지 않는다.  전체 순서 브로드캐스트가 타임스탬프 순서화보다 강하다.</li>\n  <li>p347 선형성과의 차이\n    <ul>\n      <li>전체 순서 브로드캐스트는 비동기식.  메시지는 고정된 순서로 신뢰성 있게 전달되도록 보장.   하지만 언제 메시지가 전달되는지 보장되지 않음.</li>\n      <li>선형성은 최신성 보장. 읽기가 최근에 쓰여진 값을 보는 게 보장.</li>\n    </ul>\n  </li>\n</ul>\n\n<hr />\n\n<h2 id=\"09장-분산-트랜잭션과-합의p349\">09장: 분산 트랜잭션과 합의(p.349~)</h2>\n\n<p>p349 Consensus</p>\n\n<ul>\n  <li>합의:  여러 노드들이 뭔가에 동의하게 만드는 것</li>\n  <li>리더 선출(Leader election):  단일 리더 복제를 사용하는 DB에서 모든 노드는 어떤 노드가 리더인지 동의해야 함.</li>\n  <li>원자적 커밋(Atomic commit): 트랜잭션 원자성을 유지하고 싶다면 모든 노드가 트랜잭션의 결과에 동의해야 함.</li>\n</ul>\n\n<p>p351 원자적 커밋과 2PC(Two-Phase Commit) why?</p>\n\n<ul>\n  <li>트랜잭션의 결과는 항상 커밋 Success 이거나 Abort.  The outcome of a transaction is either a <strong>successful</strong> commit, in which case all of the transaction’s writes are made durable, or an <strong>abort</strong>, in which case all of the transaction’s writes are rolled back (i.e., undone or discarded).</li>\n  <li>트랜잭션에 여러 노드가 관여하게 되면 어떤 노드에서는 커밋이 성공하고 다른 노드에서는 실패해서 원자성 보장을 위반하기 쉽다.  어떤 노드가 트랜잭션을 Commit 하지만 다른 노드는 Abort 한다면 노드들이 서로 일관성이 없어진다.</li>\n  <li>트랜잭션 커밋은 되돌릴 수 없어야 한다.  보상 트랜잭션(compensating transaction)은 취소 가능하지만 분리된 트랜잭션 개념으로 이해해야 한다.</li>\n</ul>\n\n<p>p.352-355  2PC</p>\n\n<ul>\n  <li>2PC는 여러 노드에 걸친 원자적 트랜잭션 Commit 되게 함. 즉 모든 노드가 커밋되거나 모든 노드가 Abort 되도록 보장하는 알고리즘</li>\n</ul>\n\n<p><img src=\"/images/2024/06/22/09-2pc.png\" alt=\"2pc\" title=\"2pc\" class=\"center-image\" /></p>\n\n<ul>\n  <li>코디네이터(coordinator, transaction manager), 데이터베이스 노드들을 트랜잭션 참여자(participant)</li>\n  <li>애플리케이션이 Commit할 준비가 되면 코디네이터가 1단계 시작 → 각 노드에 준비 요청을 보내서 커밋할 수 있는지 물어본다 → 그 후 코디네이터는 참여자들의 응답을 추적\n    <ul>\n      <li>모든 참여자가 커밋할 준비가 됐다면 “yes” 응답 → 코디네이터는 2단계에서 커밋 요청(commit request)하고 실제로 커밋 발생</li>\n      <li>참여자 중 누구라도 “no” 응답 → 코디네이터는 2단게에서 모든 노드에 Abort 요청</li>\n    </ul>\n  </li>\n  <li>코디네이터 장애시,  2PC가 완료될 수 있는 유일한 방법은 코디네이터가 복구되기를 기다리는것 뿐.\n    <ul>\n      <li>코디네이터가 Commit 이나 Abort 요청 보내기 전에 디스크에 있는 트랜잭션 로그에 기록</li>\n      <li>코디네이터가 복구될 때 트랜잭션 로그를 읽어서 모든 의심스러운 트랜잭션들의 상태를 결정</li>\n    </ul>\n  </li>\n</ul>\n\n<p>p358-360  XA transactions</p>\n\n<ul>\n  <li>트랜잭션 코디네이터와 연결되는 인터페이스를 제공하는 API.  트랜잭션 코디네이터는 XA API를 구현.</li>\n  <li>애플리케이션이 네트워크 드라이버나 클라이언트 라이브러리를 사용해 참여자 DB나 메시징 서비스와 통신한다고 가정.</li>\n  <li>애플리케이션 프로세그가 죽거나 애플리케이션이 실행중인 장비가 죽으면 코디네이터도 함께 사라짐</li>\n  <li>코디네이터 장애 복구 문제.  유일한 방법은 관리자가 수동으로 트랜잭션을 커밋하거나 롤백할지 결정하는 것.</li>\n  <li>\n    <p>JDBC 분산 트랜잭션</p>\n\n    <p>JDBC(Java Database Connectivity)의 트랜잭션은 로컬. 이는 단일 연결이 트랜잭션의 모든 작업을 수행하며 연결은 한 번에 하나의 트랜잭션에 대해서만 작업할 수 있음을 의미.</p>\n\n    <p>하나의 트랜잭션에 대한 모든 작업이 완료되거나 실패한 경우, 작업을 영구적으로 만들기 위해 커밋 또는 롤백이 호출되고 새 트랜잭션이 시작된다.  그러나 Java에서는 로컬 트랜잭션을 넘어서는 기능을 제공하는 고급 트랜잭션 지원도 있고, Java 트랜잭션 API에서 제공한다.</p>\n\n    <p>Java Transaction API(JTA)는 복잡한 트랜잭션을 지원.  또한 연결 객체에서 트랜잭션을 분리하는 기능도 제공합니다.  JDBC가 객체 데이터베이스 연결(ODBC) 및 X/Open 호출 수준 인터페이스(CLI) 명세를 모델로 삼았듯이, JTA는 X/Open eXtended Architecture(XA) 명세를 모델로 삼습니다. JTA와 JDBC는 연결 객체에서 트랜잭션을 분리하기 위해 함께 작동. 연결 객체에서 트랜잭션을 분리함으로써 단일 연결이 여러 트랜잭션을 동시에 처리할 수 있다.  반대로 여러 연결이 단일 트랜잭션을 처리할 수도 있음.</p>\n  </li>\n</ul>\n\n<p>p360 분산 트랜잭션의 제약</p>\n\n<ul>\n  <li>XA 트랜잭션은 여러 참여 데이터 시스템이 서로 일관성을 유지하게 하는 실제적이고 중요한 문제를 해결해 주지만, XA 트랜잭션도 중요한 운영상 문제를 가져온다.</li>\n  <li>핵심 구현은 트랜잭션의 코디네이터 자체가 일종의 데이터베이스여야 하고, 따라서 다른 중요한 데이터베이스와 동일하게 신경 써서 접근해야함.\n    <ul>\n      <li>분산 트랜잭션은 <strong>장애를 증폭</strong>시키는 경향이 있으며 이는 내결함성을 지닌 시스템을 구축하려는 목적에 어긋난다.</li>\n    </ul>\n  </li>\n</ul>\n\n<p>p361 내결함성을 지닌 합의(Fault-Tolerant Consensus)</p>\n\n<ul>\n  <li>합의 알고리즘이 만족해야 할 속성\n    <ul>\n      <li>균일한 동의(Uniform agreement):  어떤 두 노드도 다르게 결정하지 않음</li>\n      <li>무결성(Integrity): 어떤 노드도 두 번 결정하지 않음</li>\n      <li>유효성(Validity): 한 노드가 값 v를 결정한다면 v는 어떤 노드에서 제안된 것이다.</li>\n      <li>종료(Termination): 죽지 않은 모든 노드는 결국 어떤 값을 결정한다.</li>\n    </ul>\n  </li>\n  <li>카프카 Zookeeper → Raft consensus\n    <ul>\n      <li><a href=\"https://seongjin.me/raft-consensus-algorithm/\">https://seongjin.me/raft-consensus-algorithm/</a></li>\n      <li><a href=\"https://devocean.sk.com/blog/techBoardDetail.do?ID=165711\">https://devocean.sk.com/blog/techBoardDetail.do?ID=165711</a></li>\n      <li><a href=\"https://devocean.sk.com/blog/techBoardDetail.do?ID=165737\">https://devocean.sk.com/blog/techBoardDetail.do?ID=165737</a></li>\n    </ul>\n  </li>\n</ul>\n\n<p>p365 에포크 번호 붙이기와 정족수</p>\n\n<ul>\n  <li>현재 리더가 죽었다고 생각될 때마다 새 노드를 선출하기 위해 노드 사이에서 투표를 해서 에포크 번호가 높은 리더가 이겨서 리더가 된다.</li>\n  <li>리더가 뭔가를 결정하도록 허용하기 전에 충돌되는 결정을 할 지도 모르는 에포크 번호가 더 높은 리더가 없는지 먼저 확인해야 한다.</li>\n  <li>노드의 정족수로부터 투표를 받아서 리더를 판단합니다. 정족수는 항상은 아니지만 노드의 과반수로 구성된다.</li>\n  <li>2PC는 “yes” 투표가 필요하지만,  내결함성을 지닌 합의 알고리즘은 노드의 과반수로부터만 투표.</li>\n</ul>\n\n<p>p367 멤버십과 코디네이션 서비스</p>\n\n<ul>\n  <li>HBase, 하둡, 노바, 카프카는 모두 <strong>주키퍼</strong>에 의존.</li>\n  <li>주키퍼 기능\n    <ul>\n      <li><strong>선형적 원자적 연산(Linearizable atomic operations):</strong>  원자적 compare-and-set 연산을 사용해 잠금을 구현</li>\n      <li><strong>연산의 전체 순서화(Total ordering of operations):</strong>  펜싱 토큰 등을 사용해 클라이언트 충돌 막기</li>\n      <li><strong>장애 감지(Failure detection):</strong> 세션에서 획득한 잠금은 세션이 타임아웃 됐을 때 자동으로 해제되도록 설정</li>\n      <li><strong>변경 알림(Change notifications):</strong>  클라이언트는 다른 클라이언트가 생성한 잠금과 값을 읽을 수 있을 뿐만 아니라 거기에 변경이 있는지 감시할 수 있다.</li>\n    </ul>\n  </li>\n</ul>\n\n<p>p369 Service discovery,  Membership services</p>\n\n<ul>\n  <li>Service discovery: 특정 서비스에 연결하려면 어떤 IP 주소로 접속해야 하는지 알아내는 용도로도 자주 사용.</li>\n  <li>Membership services:  클러스터에서 어떤 노드가 현재 활성화된 살아 있는 멤버인지 결정.</li>\n</ul>\n\n<hr />\n\n<h2 id=\"11장-스트림-처리p453\">11장: 스트림 처리(~p453)</h2>\n\n<p>p382 레코드 시스템과 파생 데이터 시스템</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>레코드 시스템(Systems of record)</th>\n      <th>파생 데이터 시스템(Derived data systems)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>믿을 수 있는 데이터 버전을 저장</td>\n      <td>다른 시스템에 존재하는 데이터를 가져와 특정 방식으로 변환하고 처리한 결과</td>\n    </tr>\n    <tr>\n      <td>진실의 근원(source of truth). 사용자의 입력과 같은 새로운 데이터가 들어오면 먼저 레코드 시스템에 저장</td>\n      <td>데이터를 잃게 되더라도 원천 데이터로부터 다시 생성 가능</td>\n    </tr>\n    <tr>\n      <td>일반적으로 정규화를 거쳐 정확하게 한 번 표현된다.  레코드 시스템과 다른 시스템 간에 차이가 난다면 레코드 시스템이 옳다.</td>\n      <td>필요한 데이터가 캐시에 있다면 캐시에서 제공하고, 그렇지 않다면 기반 데이터베이스를 거쳐 제공할 수 있다.</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>p436 <strong>이벤트 스트림 전송(Transmitting Event Streams)</strong></p>\n\n<ul>\n  <li><strong>이벤트</strong>\n    <ul>\n      <li>스트림 처리 문맥(stream processing context)에서 레코드는 보통 <strong>이벤트</strong>라고 한다.</li>\n      <li>특정 시점에 일어난 사건에 대한 세부 사항을 포함하는, 작고 독립된 불변 객체라는 점에서 본질적으로 동일하다.</li>\n    </ul>\n  </li>\n  <li>생성자(producer)와 소비자(consumer)\n    <ul>\n      <li>생산자(producer), 발행자(publisher), 발송자(sender)</li>\n      <li>소비자(consumer), 구독자(subscriber), 수신자(recipient)</li>\n      <li>레코드 식별(그룹핑)\n        <ul>\n          <li>파일 시스템: 파일 이름으로 관련 레코드 식별</li>\n          <li>스트림 시스템: 토픽(topic)이나 스트림으로 관련 이벤트 그룹핑</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n</ul>\n\n<h3 id=\"메시징-시스템-p438\">메시징 시스템 p438</h3>\n\n<ul>\n  <li>\n    <p>메시지 시스템에 대한 질문(Publish, Subscribe 모델)</p>\n\n    <p>Q 소비자가 메시지 처리하는 속도보다 생산자가 메시지 전송하는게 빠른 경우(생산자 &gt; 소비자)</p>\n\n    <ul>\n      <li>메시지를 버리기</li>\n      <li>큐에 메시지 버퍼링하기</li>\n      <li>배압(backpressure) 적용:\n        <ul>\n          <li>생산자가 메시지를 더 보내지 못하게 막기</li>\n          <li>유닉스 파이프와 TCP가 사용</li>\n        </ul>\n      </li>\n    </ul>\n\n    <p>Q 노드가 죽거나 일시적으로 오프라인이 된다면?</p>\n\n    <ul>\n      <li>디스크에 기록하거나 복제본 생성을 하거나 둘 모두를 해야 한다.</li>\n      <li>메시지를 잃어도 괜찮다면 같은 하드웨어에서 처리량은 높이고 지연 시간은 낮출 수 있다.</li>\n    </ul>\n  </li>\n  <li>생산자에서 소비자로 메시지 직접 전달:  프로토콜이 네트워크 상에서 패킷 유실을 감지하고 재전송하더라도 직접 메시지 시스템은 일반적으로 생산자와 소비자가 항상 온라인 상태라고 가정</li>\n  <li>\n    <p>p440 메시지 브로커와 데이터베이스 비교</p>\n\n    <table>\n      <thead>\n        <tr>\n          <th>데이터베이스(Databases)</th>\n          <th>메시지 브로커(Message brokers)</th>\n        </tr>\n      </thead>\n      <tbody>\n        <tr>\n          <td>명시적으로 데이터가 삭제될 때까지 데이터 보관</td>\n          <td>대부분 소비자에게 데이터 배달이 성공할 경우 자동으로 메시지 삭제. 대부분 메시지를 빨리 지우기 때문에 작업 집합이 상당히 작다고 가정(큐 크기가 작다). 소비자 처리가 느려서 메시지 브로커가 많은 메시지를 버퍼링해야 한다면, 개별 메시지 처리 시간이 길어지고 전체 처리량이 저하됨</td>\n        </tr>\n        <tr>\n          <td>보조 색인을 지원. 데이터 검색을 위한 다양한 방법 지원</td>\n          <td>특정 패턴과 부합하는 토픽의 부분 집합을 구독하는 방식 지원</td>\n        </tr>\n        <tr>\n          <td>일반적으로 질의 시점의 데이터 스냅숏을 기준으로 질의</td>\n          <td>임의 질의를 지원하지 않음. 데이터가 변하면 클라이언트에게 전달</td>\n        </tr>\n      </tbody>\n    </table>\n  </li>\n  <li>p441 복수 소비자(Multiple consumers)\n    <ul>\n      <li>로드 밸런싱(Load balancing):\n        <ul>\n          <li>각 메시지는 소비자 중 <strong>하나</strong>로 전달</li>\n          <li>메시지를 처리하는 비용이 비싸서 처리를 병렬화하기 위해 소비자를 추가하고 싶을때 유용</li>\n        </ul>\n      </li>\n      <li>팬 아웃(Fan-out):\n        <ul>\n          <li>각 메시지는 <strong>모든</strong> 소비자에게 전달</li>\n          <li>여러 독립적인 소비자가 브로드캐스팅된 동일한 메시지를 서로 간섭 없이 리스닝 가능</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"/images/2024/06/22/11-fanout.png\" alt=\"fanout\" title=\"fanout\" class=\"center-image\" /></p>\n\n<p>p442 확인 응답과 재전송(Acknowledgments and redelivery)</p>\n\n<ul>\n  <li>생산자: m1 → m2 → m3 → m4 → m5</li>\n  <li>소비자2가 m3 처리중 장애 발생해서 소비자1로 m3 메시지 재전송.</li>\n  <li>소비자 1에서는 m4 → m3 → m5 순으로 메시지 처리</li>\n</ul>\n\n<p><img src=\"/images/2024/06/22/11-consumer.png\" alt=\"consumer\" title=\"consumer\" class=\"center-image\" /></p>\n\n<ul>\n  <li>소비자마다 독립된 큐를 사용하면, 즉 부하 균형 분산 기능을 사용하지 않는다면 이 문제를 피할 수 있다.\n    <ul>\n      <li>카프카 토픽의 파티션 키(해시) - stickness</li>\n    </ul>\n  </li>\n  <li>메시지가 서로 완전히 독립적이라면 메시지 순서가 바뀌는 것은 문제가 되지 않는다.</li>\n</ul>\n\n<h3 id=\"p443-파티셔닝된-로그partitioned-logs\">p443 파티셔닝된 로그(Partitioned Logs)</h3>\n\n<p><strong>로그 기반 메시지 브로커(log- based message brokers)</strong>:  데이터베이스의 지속성 있는 저장 방법과 메시징 시스템의 지연 시간이 짧은 알림 기능을 조합</p>\n\n<ul>\n  <li>\n    <p>로그를 사용한 메시지 저장소</p>\n\n    <p>로그 == 파티션</p>\n\n    <ul>\n      <li>\n        <p><strong>p445 로그 파티셔닝(the log can be partitioned)</strong>: 디스크 하나를 쓸 때보다 처리량을 높이기 위해 확장하는 방법</p>\n\n        <blockquote>\n          <ul>\n            <li>하나의 파티션을 처리하는 작업을 공유하는 소비자 둘로 나누어 로드 밸런싱하는 방식을 사용할 수 있다.  양쪽 소비자 모두 모든 메시지를 읽지만 그 중 하나는 짝수 오프셋 메시지만 처리하고, 다른 소비자는 홀수 오프셋 메시지만 처리하는 방식.</li>\n            <li>스레드 풀 사용을 사용해 메시지 처리 분산하는 방식. 소비자 오프셋 관리가 복잡해진다. 일반적으로 한 파티션은 단일 스레드가 처리하는 것이 적절하고,  병렬성을 높이고 싶다면 파티션 수를 늘리는 게 좋다.</li>\n          </ul>\n        </blockquote>\n      </li>\n      <li>\n        <p>단 다른 파티션 간 메시지의 순서는 보장하지 않는다.</p>\n      </li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"/images/2024/06/22/11-partition.png\" alt=\"partition\" title=\"partition\" class=\"center-image\" /></p>\n\n<ul>\n  <li>\n    <p>p444 로그 방식과 전통적인 메시징 방식의 비교</p>\n\n    <p>로그 기반 접근법은 팬 아웃 메시지 방식 제공:</p>\n\n    <ul>\n      <li>소비자가 서로 영향 없이 독립적으로 로그를 읽을 수 있고 메시지를 읽어도 로그에서 삭제되지 않는다.</li>\n    </ul>\n\n    <p>각 클라이언트는 할당된 파티션의 메시지를 모두 소비:</p>\n\n    <ul>\n      <li>토픽 하나를 소비하는 작업을 공유하는 노드 수는 많아야 해당 토픽의 로그 파티션 수로 제한.  같은 파티션 내 메시지는 같은 노드로 전달되기 때문.</li>\n      <li>특정 메시지 처리가 느리면 파티션 내 후속 메시지 처리가 지연된다(head-of-line blocking).</li>\n    </ul>\n\n    <table>\n      <tbody>\n        <tr>\n          <td>메시지 처리 비용 비싼 경우, 메시지 단위로 병렬화 처리 하고 싶은 경우, 메시지 순서는 그렇게 중요하지 않은 경우</td>\n          <td>JMS / AMQP 방식의 메시지 브로커 적합</td>\n        </tr>\n        <tr>\n          <td>처리량이 많은 경우, 메시지를 처리하는 속도가 빠른 경우, 메시지 순서가 중요한 경우</td>\n          <td>로그 기반 접근법 적합</td>\n        </tr>\n      </tbody>\n    </table>\n  </li>\n  <li>p445 소비자 오프셋(Consumer offsets)\n    <ul>\n      <li>브로커는 주기적으로 소비자 오프셋을 기록</li>\n    </ul>\n  </li>\n  <li>p446 디스크 공간 사용\n    <ul>\n      <li>로그는 크기가 제한된 버퍼로 구현하고,  버퍼가 가득 차면 오래된 메시지 순서대로 버린다.</li>\n      <li>원형 버퍼(circular buffer), 링 버퍼(ring buffer)</li>\n    </ul>\n  </li>\n</ul>\n\n<h3 id=\"데이터베이스와-스트림\">데이터베이스와 스트림</h3>\n\n<ul>\n  <li>p448 데이터베이스에 뭔가를 기록한다는 사실은 캡처해서 저장하고 처리할 수 있는 이벤트다.</li>\n  <li>p448 시스템 동기화 유지하기</li>\n  <li>이중 기록(dual write)의 심각한 문제\n    <ul>\n      <li>문제 1) 타이밍이 좋지 않아 요청이 서로 교차한 경우, 두 시스템은 오류가 발생하지 않았음에도 영원히 서로 불일치 상태로 남음.</li>\n      <li>문제2) 한쪽 쓰기가 성공할 때, 다른쪽 쓰기는 실패할 수 있다.  동시성 문제라기보다는 내결함성 문제로 두 시스템 간 불일치가 발생하는 현상.</li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"/images/2024/06/22/11-dual-write.png\" alt=\"dual-write\" title=\"dual-write\" class=\"center-image\" /></p>\n\n<ul>\n  <li><strong>p450 변경 데이터 캡처(Change Data Capture)</strong>\n    <ul>\n      <li>데이터베이스에 기록하는 모든 데이터의 변화를 관찰해 다른 시스템으로 데이터를 복제할 수 있는 형태로 추출하는 과정</li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"/images/2024/06/22/11-cdc.png\" alt=\"cdc\" title=\"cdc\" class=\"center-image\" /></p>\n\n<ul>\n  <li>파생 데이터 시스템이 레코드 시스템의 정확한 데이터 복제본을 가지게 하기 위해,  레코드 시스템에 발생하는 모든 변경 사항을 파생 데이터 시스템에 반영하는 것을 보장하는 메커니즘</li>\n  <li>\n    <p>멕스웰(maxwell), 디비지움(debezium): binlog를 파싱해 유사한 방식으로 mysql용 변경 데이터 캡처를 구현</p>\n  </li>\n  <li>p452 초기 스냅숏(Initial snapshot):\n    <ul>\n      <li>데이터베이스에서 발생한 모든 변경 로그가 있다면,  로그를 재현해서 데이터베이스의 전체 상태를 재구축 가능</li>\n    </ul>\n  </li>\n  <li>p452 로그 컴팩션(Log compaction):\n    <ul>\n      <li>저장 엔진은 주기적으로 같은 키의 로그 레코드를 찾아 중복을 제거</li>\n      <li>각 키에 대해 가장 최근에 갱신된 내용만 유지</li>\n    </ul>\n  </li>\n  <li>p453 변경 스트림용 API 지원\n    <ul>\n      <li>kafka connect;\n        <ul>\n          <li>변경 이벤트를 스트림하는데 카프카 사용</li>\n          <li>검색 색인과 같은 파생 데이터 시스템을 갱신하는데 사용 가능</li>\n          <li>스트림 처리 시스템에도 이벤트 공급이 가능</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n</ul>\n\n<hr />\n\n<h2 id=\"11장-스트림-처리p45411장-끝\">11장: 스트림 처리(p454~11장 끝)</h2>\n\n<p><strong>이벤트 소싱(event sourcing)</strong></p>\n\n<ul>\n  <li>CDC:\n    <ul>\n      <li>데이터베이스를 변경 가능한 방식으로 사용해 레코드를 자유롭게 갱신하고 삭제</li>\n    </ul>\n  </li>\n  <li>이벤트 소싱:\n    <ul>\n      <li>이벤트 로그에 기록된 불변 이벤트를 기반으로 명시적으로 구축</li>\n      <li>이벤트 저장은 추가만 가능하고 갱신이나 삭제는 권장하지 않거나 금지</li>\n      <li>어떤 상황이 발생한 후에 상황 파악이 쉽기 때문에 디버깅에 도움이 되고 버그 방지</li>\n    </ul>\n  </li>\n</ul>\n\n<p><strong>이벤트 로그에서 현재 상태 파생하기</strong></p>\n\n<ul>\n  <li>시스템에 기록한 데이터를 표현한 이벤트 로그를 가져와 사용자에게 보여주기에 적당한 애플리케이션 상태(시스템에서 데이터를 읽는 방식)로 변환해야 한다.\n    <ul>\n      <li>예시; 현재 장바구니 내용(변경 사항은 관심사 x)</li>\n    </ul>\n  </li>\n  <li>CDC: 레코드의 가장 새로운 버전만 보유.  같은 키의 이전 이벤트는 로그 컴팩션을 통해 버린다</li>\n  <li>이벤트 소싱: 뒤에 발생한 이벤트가 앞선 이벤트를 덮어쓰지 않는다. 마지막 상태 재구축을 위해서는 이벤트의 전체 히스토리가 필요하다.</li>\n</ul>\n\n<p><strong>p455 명령과 이벤트</strong></p>\n\n<ul>\n  <li>명령이 실행 가능한지 확인.</li>\n  <li>무결성이 검증되고 명령이 승인되면 명령은 지속성 있는 불변 이벤트가 된다.</li>\n  <li>명령의 유효성은 이벤트가 되기 전에 동기식으로 검증해야 한다.\n    <ul>\n      <li>좌석 예약 예시.</li>\n    </ul>\n  </li>\n</ul>\n\n<p><strong>p456 상태와 스트림 그리고 불변성</strong></p>\n\n<ul>\n  <li>상태의 본질을 변하는 것이다. 상태가 어떻게 바뀌었든 항상 이런 변화를 일으킨 일련의 이벤트가 있다.</li>\n  <li>변경 가능한 상태와 추가 전용 불변 이벤트 로그는 마치 동전의 양면과 같이 서로 모순이다. 모든 <strong>변경 로그(changelog)</strong>는 시간이 지남에 따라 바뀌는 상태를 나타낸다.</li>\n  <li>변경 로그를 지속성 있게 저장한다면 상태를 간단히 재생성할 수 있는 효과가 있다. 이벤트 로그를 레코드 시스템으로 생각하고 모든 변경 가능 상태를 이벤트 로그로부터 파생된 것으로 생각하면 시스템을 거치는 데이터 흐름에 관해 추론하기 쉽다.</li>\n</ul>\n\n<p><strong>p458 동일한 이벤트 로그로 여러 가지 뷰 만들기</strong></p>\n\n<ul>\n  <li>CQRS(Command Query Responsibility Segregation)</li>\n  <li>읽기 최적화된 뷰(read-optimized views)는 데이터를 비정규화하는 것이 전적으로 합리적이다.</li>\n</ul>\n\n<p><strong>동시성 제어</strong></p>\n\n<ul>\n  <li>이벤트가 아직 읽기 뷰에 반영되지 않았을 가능성</li>\n</ul>\n\n<p><strong>p460 불변성의 한계</strong></p>\n\n<ul>\n  <li>성능적인 이유 외에도. 사생활 침해 규제로 인해 개인 정보 지울 필요가 있다든지, 데이터 보호법에 따라 잘못된 정보를 삭제해야 한다든지, 민감한 정보가 우발적으로 노출되는 것을 방지해야 하는 경우</li>\n</ul>\n\n<h3 id=\"p461-스트림-처리\"><strong>p461 스트림 처리</strong></h3>\n\n<ul>\n  <li>몇 분 동안 실행된 일괄 처리 작업은 실패한 태스크를 처음부터 재시작하는 것으로 충분,  하지만 몇 년 동안 실행 중인 스트림 작업은 장애 발생 이후 처음부터 재시작하는 방법은 비현실적.</li>\n</ul>\n\n<p><strong>p462 복잡한 이벤트 처리</strong></p>\n\n<ul>\n  <li>CEP(Complex event processing): 특정 이벤트 패턴을 검색해야 하는 애플리케이션에 적합</li>\n  <li>스트림 분석(Stream analytics): 연속한 특정 이벤트 패턴을 찾는 것보다 대량의 이벤트를 집계하고 통계적 지표를 뽑는 것을 더 우선.\n    <ul>\n      <li>특정 유형의 이벤트 빈도 측정(시간당 얼마나 자주 발생하는지)</li>\n      <li>특정 기간에 걸친 값의 이동 평균(ROLLING AVERAGE) 계산</li>\n      <li>이전 시간 간격과 현재 통계값의 비교(추세 감지,  지난주 대비 비정상적으로 높거나 낮은 지표에 대해 경고)</li>\n    </ul>\n  </li>\n</ul>\n\n<p><strong>p464 구체화 뷰(materialized views) 유지하기</strong></p>\n\n<ul>\n  <li>이벤트 소싱에서 애플리케이션 상태는 이벤트 로그를 적용함으로써 유지된다.  여기서 애플리케이션 상태는 일종의 구체화 뷰다.</li>\n  <li>구체화 뷰를 만들려면 잠재적으로 임의의 시간 범위에 발생한 모든 이벤트가 필요하다.</li>\n</ul>\n\n<p><strong>p464 스트림 상에서 검색하기</strong></p>\n\n<ul>\n  <li>질의를 먼저 저장.</li>\n</ul>\n\n<p><strong>메시지 전달과 RPC</strong></p>\n\n<p>메시지 전달이 stream 처리, RPC는 액터.  액터는 1:1로 메시지 주고 받는 형태.  스트림 처리는 카프카처럼 데이터 파이프라인 구축.  스트림 처리는 메시지 관심있는 사람 여러명이 관심.  1:1 / 1:n 또는 n:m</p>\n\n<ul>\n  <li>액터:\n    <ul>\n      <li>주로 동시성 관리, 통신 모듈을 분산 실행하는 매커니즘</li>\n      <li>액터간 통신은 주로 단기적이고 일대일</li>\n      <li>임의의 방식으로 통신 가능</li>\n    </ul>\n  </li>\n  <li>스트림 처리:\n    <ul>\n      <li>기본적으로 데이터 관리 기법</li>\n      <li>지속성 있고 다중 구독 가능</li>\n      <li>비순환 파이프라인에 설정됨.</li>\n    </ul>\n  </li>\n</ul>\n\n<p><strong>p468 어떤 시계를 사용할 것인가?</strong></p>\n\n<p>잘못된 장치 시계를 조정하는 한 가지 방법: 세 가지 타임스탬프를 로그로 남기기</p>\n\n<ol>\n  <li>이벤트가 발생한 시간 - 장치 시계</li>\n  <li>이벤트를 서버로 보낸 시간 - 장치 시계</li>\n  <li>서버에서 이벤트를 받은 시간 - 서버 시계</li>\n</ol>\n\n<p>2와 3 차이를 구하면 장치 시계와 서버 시계 간의 오프셋 추정 가능.  계산한 오프셋을 이벤트 타임스탬프에 적용해 이벤트가 실제로 발생한 시간을 추정.</p>\n\n<p><strong>p469 윈도우 유형</strong></p>\n\n<ul>\n  <li>텀블링 윈도우(Tumbling window)</li>\n  <li>홉핑 윈도우(Hopping window)</li>\n  <li>슬라이딩 윈도우(Sliding window)</li>\n  <li>세션 윈도우(Session window)</li>\n</ul>\n\n<h3 id=\"p474-내결함성fault-tolerance\">p474 내결함성(<strong>Fault Tolerance)</strong></h3>\n\n<ul>\n  <li>태스크를 재시작하는 것은 사실 레코드를 여러 번 처리할 수도 있다는 뜻. 출력은 한 번만 처리된 것으로 보이는 효과.\n    <ul>\n      <li><strong>exactly-once semantics(정확히 한 번 시맨틱), effectively-once(결과적으로 한 번)</strong></li>\n    </ul>\n  </li>\n  <li>Microbatching and checkpointing(마이크로 일괄 처리와 체크포인트)</li>\n  <li>Atomic commit revisited(원자적 커밋 재검토)</li>\n  <li>멱등성(Idempotence)</li>\n  <li>실패 후에 상태 재구축하기(Rebuilding state after a failure)</li>\n</ul>",
        "guid": "https://sungjk.github.io/2024/06/22/ddia.html",
        "isoDate": "2024-06-22T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김놀부",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "안드로이드 추천 앱, 추천 어플 (24.6.24) 중고등학생 전용 SNS, 디어스, 문서를 PDF로 스캔하기, 반려동물 커뮤니티, 예술 중심 소셜 플랫폼",
        "link": "http://muzbox.tistory.com/2000",
        "pubDate": "Mon, 24 Jun 2024 08:06:28 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/2000#entry2000comment",
        "content": "<p style=\"text-align: left;\" data-ke-size=\"size16\">구글플레이 스토어에 등록된 유용한 앱 5개를&nbsp; 소개합니다. 새로운 기능, 사용자 경험 향상을 위한 앱들을 발견하고, 일상생활을 더욱 편리하게 만들어 줄 최고의 앱들을 찾아보세요.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"안드로이드 추천앱.png\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/Q585t/btsH8AlrCXT/dirdDG0wqmDFEpLUkh6Tk0/img.png\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/Q585t/btsH8AlrCXT/dirdDG0wqmDFEpLUkh6Tk0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FQ585t%2FbtsH8AlrCXT%2FdirdDG0wqmDFEpLUkh6Tk0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"안드로이드 추천 앱, 추천 어플\" data-filename=\"안드로이드 추천앱.png\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;안드로이드 앱스토어인 구글 플레이 스토어에는 하루에도 엄청난 수의 앱과 게임이 신규로 등록됩니다. 이 모든앱들을 사용자가 확인하고 양질의 앱을 선택하는 것이 사실상 불가능 하다는 얘기죠.&nbsp; <br /><br />또한, 최근들어 강화되었다 하지만 여전히 구글 플레이스토어에는 유해한 앱들이 사라지지 않고 이들 앱으로 피해를 보는 사용자도 많습니다. 본 블로그에서는 일주일에 한 번정도 운영자가 직접 유용하고 편리한 앱을 엄선하여 소개합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: left;\" data-ke-size=\"size16\"><b>'어떤오후의 프리웨어 이야기'에서 추천하는 </b><b><span style=\"color: #ee2323;\">2024년 6월 24일자 '안드로이드 추천 앱'</span>입니다.</b><b></b></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>1. 디어스 - 크리에이터와 팬들이 소통할 수 있는 온라인 플랫폼</b></span></h2>\n<p data-ke-size=\"size16\">&nbsp; 디어스는&nbsp;크리에이터와&nbsp;팬들이&nbsp;소통할&nbsp;수&nbsp;있는&nbsp;특별한&nbsp;온라인&nbsp;플랫폼입니다.&nbsp;이&nbsp;앱에서는&nbsp;크리에이터와&nbsp;팬들이&nbsp;'스페이스'라는&nbsp;공간에서&nbsp;자유롭게&nbsp;소통하고&nbsp;콘텐츠를&nbsp;공유할&nbsp;수&nbsp;있습니다.&nbsp;디어스는&nbsp;다양한&nbsp;이벤트와&nbsp;최신&nbsp;콘텐츠를&nbsp;제공하며,&nbsp;모바일&nbsp;티케팅&nbsp;서비스도&nbsp;간편하게&nbsp;이용할&nbsp;수&nbsp;있습니다.&nbsp;또한,&nbsp;팬들은&nbsp;좋아하는&nbsp;크리에이터의&nbsp;일정과&nbsp;활동을&nbsp;캘린더&nbsp;기능을&nbsp;통해&nbsp;한눈에&nbsp;확인할&nbsp;수&nbsp;있습니다.&nbsp;이&nbsp;플랫폼은&nbsp;크리에이터와&nbsp;팬들이&nbsp;하나가&nbsp;되어&nbsp;즐길&nbsp;수&nbsp;있는&nbsp;새로운&nbsp;형태의&nbsp;커뮤니티&nbsp;공간을&nbsp;제공합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"디어스.jpg\" data-origin-width=\"803\" data-origin-height=\"1421\"><span data-url=\"https://blog.kakaocdn.net/dn/b8Xc5e/btsH8UqbeAg/kn1cwXGWapHRU5FErwwYdK/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/b8Xc5e/btsH8UqbeAg/kn1cwXGWapHRU5FErwwYdK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb8Xc5e%2FbtsH8UqbeAg%2Fkn1cwXGWapHRU5FErwwYdK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"디어스 - 크리에이터와 팬들이 소통할 수 있는 온라인 플랫폼\" width=\"740\" height=\"1310\" data-filename=\"디어스.jpg\" data-origin-width=\"803\" data-origin-height=\"1421\"/></span></figure>\n</p>\n<figure id=\"og_1719183541098\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"디어스 - Google Play 앱\" data-og-description=\"크리에이터와 팬, 우리가 되는 공간\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.binary.theus\" data-og-url=\"https://play.google.com/store/apps/details?id=com.binary.theus&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/BgdL2/hyWoPOY1Bo/r40yayDdA5lMkdkkba6ECK/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/bk0GhV/hyWrNaTKRL/Yyd5ywRc5U8J1Am4vc2oW0/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/Wk3fi/hyWrZ3twUJ/FqYVvAK0pVOYvWmOgSE681/img.png?width=240&amp;height=240&amp;face=0_0_240_240\"><a href=\"https://play.google.com/store/apps/details?id=com.binary.theus\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.binary.theus\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/BgdL2/hyWoPOY1Bo/r40yayDdA5lMkdkkba6ECK/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/bk0GhV/hyWrNaTKRL/Yyd5ywRc5U8J1Am4vc2oW0/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/Wk3fi/hyWrZ3twUJ/FqYVvAK0pVOYvWmOgSE681/img.png?width=240&amp;height=240&amp;face=0_0_240_240');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">디어스 - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">크리에이터와 팬, 우리가 되는 공간</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>2. OMG&nbsp;-&nbsp;중고등학생&nbsp;전용&nbsp;SNS</b></span></h2>\n<p data-ke-size=\"size16\">OMG는&nbsp;중고등학생들을&nbsp;위한&nbsp;익명&nbsp;SNS&nbsp;플랫폼으로,&nbsp;친구들과&nbsp;익명으로&nbsp;속마음을&nbsp;나누고&nbsp;투표할&nbsp;수&nbsp;있는&nbsp;서비스입니다.&nbsp;이&nbsp;앱을&nbsp;통해&nbsp;사용자는&nbsp;자신에&nbsp;대한&nbsp;친구들의&nbsp;생각을&nbsp;알아볼&nbsp;수&nbsp;있으며,&nbsp;직접&nbsp;만든&nbsp;질문에&nbsp;대한&nbsp;응답도&nbsp;받을&nbsp;수&nbsp;있습니다.&nbsp;OMG는&nbsp;또한&nbsp;학교&nbsp;내&nbsp;인기&nbsp;투표와&nbsp;같은&nbsp;재미있는&nbsp;기능을&nbsp;제공하여&nbsp;학교&nbsp;생활을&nbsp;더욱&nbsp;흥미롭게&nbsp;만듭니다.&nbsp;더&nbsp;나아가,&nbsp;전국의&nbsp;또래&nbsp;친구들과&nbsp;소통하고&nbsp;다양한&nbsp;챌린지에&nbsp;참여할&nbsp;수&nbsp;있어,&nbsp;폭넓은&nbsp;교류와&nbsp;재미를&nbsp;경험할&nbsp;수&nbsp;있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"OMG.jpg\" data-origin-width=\"803\" data-origin-height=\"1421\"><span data-url=\"https://blog.kakaocdn.net/dn/91tIP/btsH9ENGbfM/qF2rHep1gC5fgfGuzVYmV1/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/91tIP/btsH9ENGbfM/qF2rHep1gC5fgfGuzVYmV1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F91tIP%2FbtsH9ENGbfM%2FqF2rHep1gC5fgfGuzVYmV1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"OMG - 중고등학생 전용 SNS\" width=\"740\" height=\"1310\" data-filename=\"OMG.jpg\" data-origin-width=\"803\" data-origin-height=\"1421\"/></span></figure>\n</p>\n<figure id=\"og_1719183581909\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"OMG - 중고등학생 전용 SNS - Google Play 앱\" data-og-description=\"내 친구들과 익명으로 더 재밌게 소통하고, 전국의 또래 친구들과도 부담없이 소통해보세요!\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=io.trinitystudio.omg\" data-og-url=\"https://play.google.com/store/apps/details?id=io.trinitystudio.omg&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/bg3FVj/hyWozL8tNl/GNVPrJkzbaHSPpOt0aRPdK/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/dLSdRj/hyWoJnHibK/FClzKHe59Vj6Hzh7Ah5wb0/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/15eNI/hyWrQenEHd/aRhcLeWpybGYBx1XijKeDK/img.png?width=240&amp;height=240&amp;face=0_0_240_240\"><a href=\"https://play.google.com/store/apps/details?id=io.trinitystudio.omg\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=io.trinitystudio.omg\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/bg3FVj/hyWozL8tNl/GNVPrJkzbaHSPpOt0aRPdK/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/dLSdRj/hyWoJnHibK/FClzKHe59Vj6Hzh7Ah5wb0/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/15eNI/hyWrQenEHd/aRhcLeWpybGYBx1XijKeDK/img.png?width=240&amp;height=240&amp;face=0_0_240_240');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">OMG - 중고등학생 전용 SNS - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">내 친구들과 익명으로 더 재밌게 소통하고, 전국의 또래 친구들과도 부담없이 소통해보세요!</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>3. CamScanner&nbsp;-&nbsp;문서를&nbsp;PDF로&nbsp;스캔하기</b></span></h2>\n<p data-ke-size=\"size16\">&nbsp; CamScanner는&nbsp;스마트폰을&nbsp;이용해&nbsp;문서를&nbsp;스캔하고&nbsp;관리할&nbsp;수&nbsp;있는&nbsp;다목적&nbsp;앱입니다.&nbsp;이&nbsp;앱은&nbsp;고품질&nbsp;이미지&nbsp;처리&nbsp;기술을&nbsp;사용하여&nbsp;문서를&nbsp;스캔하고,&nbsp;OCR&nbsp;기능으로&nbsp;텍스트를&nbsp;인식하며,&nbsp;클라우드&nbsp;저장소를&nbsp;통해&nbsp;여러&nbsp;기기&nbsp;간&nbsp;동기화를&nbsp;지원합니다.&nbsp;CamScanner는&nbsp;문서&nbsp;공유,&nbsp;프린트,&nbsp;팩스&nbsp;기능도&nbsp;제공하여&nbsp;비즈니스맨,&nbsp;학생,&nbsp;디자이너&nbsp;등&nbsp;다양한&nbsp;사용자들의&nbsp;needs를&nbsp;충족시킵니다.&nbsp;무료&nbsp;버전과&nbsp;고급&nbsp;계정이&nbsp;있어&nbsp;사용자의&nbsp;필요에&nbsp;따라&nbsp;선택할&nbsp;수&nbsp;있으며,&nbsp;전&nbsp;세계적으로&nbsp;4000만&nbsp;명&nbsp;이상의&nbsp;사용자가&nbsp;이용하고&nbsp;있는&nbsp;인기&nbsp;앱입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"CamScanner.jpg\" data-origin-width=\"803\" data-origin-height=\"1421\"><span data-url=\"https://blog.kakaocdn.net/dn/bn4wmG/btsH9JuwQsG/wNDPZKZk4Yc76vm7AEh4w0/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/bn4wmG/btsH9JuwQsG/wNDPZKZk4Yc76vm7AEh4w0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbn4wmG%2FbtsH9JuwQsG%2FwNDPZKZk4Yc76vm7AEh4w0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"CamScanner - 문서를 PDF로 스캔하기\" width=\"740\" height=\"1310\" data-filename=\"CamScanner.jpg\" data-origin-width=\"803\" data-origin-height=\"1421\"/></span></figure>\n</p>\n<figure id=\"og_1719183614772\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"CamScanner - 문서를 PDF로 스캔하기 - Google Play 앱\" data-og-description=\"쉽고 간편한 1:1 고화질 정밀스캔, PDF/Word/IMG 다양한 편집, 포맷 저장, 이미지 텍스트 인식 지원, 지금 바로 다운로드하세요!\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.intsig.camscanner\" data-og-url=\"https://play.google.com/store/apps/details?id=com.intsig.camscanner&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/bKgkNJ/hyWoMxVPZw/Js9JkH4gzJGb4JB94fvI3k/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/uWSrg/hyWrQrVeZE/ZpaCwkrF2E8TrJU287BDXK/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/vQCtk/hyWoCWqvSe/YoDb87DO3ZyQiXra5tiop0/img.png?width=240&amp;height=240&amp;face=0_0_240_240\"><a href=\"https://play.google.com/store/apps/details?id=com.intsig.camscanner\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.intsig.camscanner\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/bKgkNJ/hyWoMxVPZw/Js9JkH4gzJGb4JB94fvI3k/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/uWSrg/hyWrQrVeZE/ZpaCwkrF2E8TrJU287BDXK/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/vQCtk/hyWoCWqvSe/YoDb87DO3ZyQiXra5tiop0/img.png?width=240&amp;height=240&amp;face=0_0_240_240');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">CamScanner - 문서를 PDF로 스캔하기 - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">쉽고 간편한 1:1 고화질 정밀스캔, PDF/Word/IMG 다양한 편집, 포맷 저장, 이미지 텍스트 인식 지원, 지금 바로 다운로드하세요!</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b><span style=\"color: #006dd7;\">4. 피피&nbsp;-&nbsp;우리동네&nbsp;반려동물&nbsp;커뮤니티</span><br /></b></h2>\n<p data-ke-size=\"size16\">\"피피\"는&nbsp;동네&nbsp;반려동물과&nbsp;반려인들의&nbsp;이야기를&nbsp;공유하는&nbsp;소셜&nbsp;플랫폼입니다.&nbsp;이&nbsp;앱을&nbsp;통해&nbsp;사용자들은&nbsp;자신의&nbsp;반려동물을&nbsp;동네&nbsp;사람들에게&nbsp;소개하고,&nbsp;다른&nbsp;동네의&nbsp;반려동물들도&nbsp;구경할&nbsp;수&nbsp;있습니다.&nbsp;또한,&nbsp;반려인들이&nbsp;추천하는&nbsp;장소&nbsp;정보를&nbsp;공유하고&nbsp;자신만의&nbsp;추억이&nbsp;있는&nbsp;장소를&nbsp;지도에&nbsp;표시할&nbsp;수&nbsp;있습니다.&nbsp;\"피피\"는&nbsp;사용자들의&nbsp;활동에&nbsp;따라&nbsp;클로버를&nbsp;제공하며,&nbsp;이를&nbsp;통해&nbsp;다양한&nbsp;혜택을&nbsp;받을&nbsp;수&nbsp;있고&nbsp;동물&nbsp;친구들에게도&nbsp;도움을&nbsp;줄&nbsp;수&nbsp;있습니다.&nbsp;이&nbsp;앱은&nbsp;지역&nbsp;기반의&nbsp;반려동물&nbsp;커뮤니티를&nbsp;형성하여&nbsp;반려인들&nbsp;간의&nbsp;소통과&nbsp;정보&nbsp;공유를&nbsp;촉진합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"피피.jpg\" data-origin-width=\"661\" data-origin-height=\"1421\"><span data-url=\"https://blog.kakaocdn.net/dn/T0xf1/btsH9ZYkluB/lJM7X74MqIcIPH0IVQYH60/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/T0xf1/btsH9ZYkluB/lJM7X74MqIcIPH0IVQYH60/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FT0xf1%2FbtsH9ZYkluB%2FlJM7X74MqIcIPH0IVQYH60%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"피피 - 우리동네 반려동물 커뮤니티\" width=\"740\" height=\"1591\" data-filename=\"피피.jpg\" data-origin-width=\"661\" data-origin-height=\"1421\"/></span></figure>\n</p>\n<figure id=\"og_1719183650046\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"피피 - 우리동네 반려동물 커뮤니티 - Google Play 앱\" data-og-description=\"동네 반려생활의 시작, 피피\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.PPFriends.PP.android\" data-og-url=\"https://play.google.com/store/apps/details?id=com.PPFriends.PP.android&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/IS0WK/hyWrT91HjZ/LZUr0D6GfKn5m8jA3SXjHK/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/nxoBE/hyWoPVKR46/nkL9k10kJt3j5dHpqMDN10/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/b5Howf/hyWoEmodWP/bQRb5DOVx04IHgb6ebRxv0/img.png?width=240&amp;height=240&amp;face=0_0_240_240\"><a href=\"https://play.google.com/store/apps/details?id=com.PPFriends.PP.android\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.PPFriends.PP.android\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/IS0WK/hyWrT91HjZ/LZUr0D6GfKn5m8jA3SXjHK/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/nxoBE/hyWoPVKR46/nkL9k10kJt3j5dHpqMDN10/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/b5Howf/hyWoEmodWP/bQRb5DOVx04IHgb6ebRxv0/img.png?width=240&amp;height=240&amp;face=0_0_240_240');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">피피 - 우리동네 반려동물 커뮤니티 - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">동네 반려생활의 시작, 피피</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>5. 하입앤 HypeN - 아티스트와 팬들을 연결하는 예술 중심 소셜 플랫폼 </b></span></h2>\n<p data-ke-size=\"size16\">HypeN은 아티스트와 팬들을 연결하는 예술 중심 소셜 플랫폼입니다. 이 앱에서 사용자들은 작품에 'HYPE'를 누르고 개인 아트 갤러리를 만들 수 있으며, 작가들의 일상과 작품 활동을 팔로우하고 소통할 수 있습니다. 또한 HypeN은 독점 DROP 이벤트를 통해 작가의 드로잉이나 브랜드 콜라보레이션 상품을 제공하며, 다양한 카테고리의 예술 작품을 검색하고 탐색할 수 있는 기능을 제공합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"하입앤.jpg\" data-origin-width=\"803\" data-origin-height=\"1421\"><span data-url=\"https://blog.kakaocdn.net/dn/bejqQQ/btsH9Yd3Y5W/EWkFVii9qnKINw8otHS5rK/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/bejqQQ/btsH9Yd3Y5W/EWkFVii9qnKINw8otHS5rK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbejqQQ%2FbtsH9Yd3Y5W%2FEWkFVii9qnKINw8otHS5rK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"하입앤 HypeN - 아티스트와 팬들을 연결하는 예술 중심 소셜 플랫폼\" width=\"740\" height=\"1310\" data-filename=\"하입앤.jpg\" data-origin-width=\"803\" data-origin-height=\"1421\"/></span></figure>\n</p>\n<figure id=\"og_1719183685455\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"하입앤 HypeN - Google Play 앱\" data-og-description=\"아트를 더 가깝게\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.im.hypen\" data-og-url=\"https://play.google.com/store/apps/details?id=com.im.hypen&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/2Pc55/hyWoBXtKsM/TEfIU7265mglsqoAoRKsLK/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/PYaPR/hyWoJ83UQh/YNSdfxSGRNKL9jsEFEAZnK/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/R3lmE/hyWr0g0Gmd/lIHiY7ocDvrVUdhLM9Ea30/img.png?width=240&amp;height=240&amp;face=0_0_240_240\"><a href=\"https://play.google.com/store/apps/details?id=com.im.hypen\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.im.hypen\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/2Pc55/hyWoBXtKsM/TEfIU7265mglsqoAoRKsLK/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/PYaPR/hyWoJ83UQh/YNSdfxSGRNKL9jsEFEAZnK/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/R3lmE/hyWr0g0Gmd/lIHiY7ocDvrVUdhLM9Ea30/img.png?width=240&amp;height=240&amp;face=0_0_240_240');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">하입앤 HypeN - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">아트를 더 가깝게</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>",
        "contentSnippet": "구글플레이 스토어에 등록된 유용한 앱 5개를  소개합니다. 새로운 기능, 사용자 경험 향상을 위한 앱들을 발견하고, 일상생활을 더욱 편리하게 만들어 줄 최고의 앱들을 찾아보세요.\n\n\n \n 안드로이드 앱스토어인 구글 플레이 스토어에는 하루에도 엄청난 수의 앱과 게임이 신규로 등록됩니다. 이 모든앱들을 사용자가 확인하고 양질의 앱을 선택하는 것이 사실상 불가능 하다는 얘기죠.  \n또한, 최근들어 강화되었다 하지만 여전히 구글 플레이스토어에는 유해한 앱들이 사라지지 않고 이들 앱으로 피해를 보는 사용자도 많습니다. 본 블로그에서는 일주일에 한 번정도 운영자가 직접 유용하고 편리한 앱을 엄선하여 소개합니다.\n \n'어떤오후의 프리웨어 이야기'에서 추천하는 2024년 6월 24일자 '안드로이드 추천 앱'입니다.\n \n1. 디어스 - 크리에이터와 팬들이 소통할 수 있는 온라인 플랫폼\n  디어스는 크리에이터와 팬들이 소통할 수 있는 특별한 온라인 플랫폼입니다. 이 앱에서는 크리에이터와 팬들이 '스페이스'라는 공간에서 자유롭게 소통하고 콘텐츠를 공유할 수 있습니다. 디어스는 다양한 이벤트와 최신 콘텐츠를 제공하며, 모바일 티케팅 서비스도 간편하게 이용할 수 있습니다. 또한, 팬들은 좋아하는 크리에이터의 일정과 활동을 캘린더 기능을 통해 한눈에 확인할 수 있습니다. 이 플랫폼은 크리에이터와 팬들이 하나가 되어 즐길 수 있는 새로운 형태의 커뮤니티 공간을 제공합니다.\n\n\n\n \n디어스 - Google Play 앱\n크리에이터와 팬, 우리가 되는 공간\nplay.google.com\n\n \n \n \n2. OMG - 중고등학생 전용 SNS\nOMG는 중고등학생들을 위한 익명 SNS 플랫폼으로, 친구들과 익명으로 속마음을 나누고 투표할 수 있는 서비스입니다. 이 앱을 통해 사용자는 자신에 대한 친구들의 생각을 알아볼 수 있으며, 직접 만든 질문에 대한 응답도 받을 수 있습니다. OMG는 또한 학교 내 인기 투표와 같은 재미있는 기능을 제공하여 학교 생활을 더욱 흥미롭게 만듭니다. 더 나아가, 전국의 또래 친구들과 소통하고 다양한 챌린지에 참여할 수 있어, 폭넓은 교류와 재미를 경험할 수 있습니다.\n\n\n\n \nOMG - 중고등학생 전용 SNS - Google Play 앱\n내 친구들과 익명으로 더 재밌게 소통하고, 전국의 또래 친구들과도 부담없이 소통해보세요!\nplay.google.com\n\n \n \n \n3. CamScanner - 문서를 PDF로 스캔하기\n  CamScanner는 스마트폰을 이용해 문서를 스캔하고 관리할 수 있는 다목적 앱입니다. 이 앱은 고품질 이미지 처리 기술을 사용하여 문서를 스캔하고, OCR 기능으로 텍스트를 인식하며, 클라우드 저장소를 통해 여러 기기 간 동기화를 지원합니다. CamScanner는 문서 공유, 프린트, 팩스 기능도 제공하여 비즈니스맨, 학생, 디자이너 등 다양한 사용자들의 needs를 충족시킵니다. 무료 버전과 고급 계정이 있어 사용자의 필요에 따라 선택할 수 있으며, 전 세계적으로 4000만 명 이상의 사용자가 이용하고 있는 인기 앱입니다.\n\n\n\n \nCamScanner - 문서를 PDF로 스캔하기 - Google Play 앱\n쉽고 간편한 1:1 고화질 정밀스캔, PDF/Word/IMG 다양한 편집, 포맷 저장, 이미지 텍스트 인식 지원, 지금 바로 다운로드하세요!\nplay.google.com\n\n \n \n \n4. 피피 - 우리동네 반려동물 커뮤니티\n\n\"피피\"는 동네 반려동물과 반려인들의 이야기를 공유하는 소셜 플랫폼입니다. 이 앱을 통해 사용자들은 자신의 반려동물을 동네 사람들에게 소개하고, 다른 동네의 반려동물들도 구경할 수 있습니다. 또한, 반려인들이 추천하는 장소 정보를 공유하고 자신만의 추억이 있는 장소를 지도에 표시할 수 있습니다. \"피피\"는 사용자들의 활동에 따라 클로버를 제공하며, 이를 통해 다양한 혜택을 받을 수 있고 동물 친구들에게도 도움을 줄 수 있습니다. 이 앱은 지역 기반의 반려동물 커뮤니티를 형성하여 반려인들 간의 소통과 정보 공유를 촉진합니다.\n\n\n\n \n피피 - 우리동네 반려동물 커뮤니티 - Google Play 앱\n동네 반려생활의 시작, 피피\nplay.google.com\n\n \n \n \n5. 하입앤 HypeN - 아티스트와 팬들을 연결하는 예술 중심 소셜 플랫폼 \nHypeN은 아티스트와 팬들을 연결하는 예술 중심 소셜 플랫폼입니다. 이 앱에서 사용자들은 작품에 'HYPE'를 누르고 개인 아트 갤러리를 만들 수 있으며, 작가들의 일상과 작품 활동을 팔로우하고 소통할 수 있습니다. 또한 HypeN은 독점 DROP 이벤트를 통해 작가의 드로잉이나 브랜드 콜라보레이션 상품을 제공하며, 다양한 카테고리의 예술 작품을 검색하고 탐색할 수 있는 기능을 제공합니다.\n\n\n\n \n하입앤 HypeN - Google Play 앱\n아트를 더 가깝게\nplay.google.com",
        "guid": "http://muzbox.tistory.com/2000",
        "categories": [
          "ANDROID &amp; 모바일/추천 무료 앱",
          "디어스",
          "모바일",
          "문서를 pdf로 스캔하기",
          "반려동물 커뮤니티",
          "안드로이드 추천 앱",
          "예술 중심 소셜 플랫폼",
          "중고등학생 전용 sns",
          "추천 어플"
        ],
        "isoDate": "2024-06-23T23:06:28.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "바이러스 치료 최강, MZK 다운로드 방법과 자세한 사용법",
        "link": "http://muzbox.tistory.com/1307",
        "pubDate": "Sun, 23 Jun 2024 22:30:21 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/1307#entry1307comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;MZK는 단순한 백신 프로그램이 아닌, 다양한 명령어를 모아둔 스크립트 파일로, 복잡한 문제를 효과적으로 해결합니다. 이 기사에서는 MZK를 이용해 악성코드를 제거하는 방법을 단계별로 설명합니다.&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthContent\" data-filename=\"00.jpg\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/rIvVC/btq1Qn7A1K4/OA40qWmNrm6siBAkanjWf1/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/rIvVC/btq1Qn7A1K4/OA40qWmNrm6siBAkanjWf1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FrIvVC%2Fbtq1Qn7A1K4%2FOA40qWmNrm6siBAkanjWf1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"00.jpg\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"font-size: 12pt;\">악성코드나 바이러스로 고생하신 경험이 있으신 분들이라면 MZK의 강력함을 잘 아실겁니다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 class=\"hdg-03\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 7px; padding: 0px 5px 7px 0px; border-width: 0px 0px 1px; border-bottom: 1px solid #dadada; font-size: 16px; box-sizing: border-box; float: none; clear: both; font-weight: bold; line-height: 1.4; color: #333333; font-style: normal; font-variant: normal; letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px; background-color: #ffffff;\" data-ke-size=\"size23\"><span style=\"margin: 0px; padding: 1px 0px 2px 9px; border-width: 0px 0px 0px 5px; border-style: solid; border-left-color: #3366ff; font-size: 16px; box-sizing: border-box; display: block;\"><span style=\"font-family: NanumGothic; font-size: 18pt;\">MZK 란?</span><br /></span></h3>\n<p data-ke-size=\"size16\"><span style=\"font-size: 12pt;\">MZK는 </span><span style=\"font-size: 12pt;\">Malware Zero Kit의 약자로 V3 처럼 백신 프로그램이라기 보다 악성코드나 바이러스를 효과적으로 처리하기 위한 명령어들을 모아둔 스크립트 파일입니다. 따라서 EXE</span><span style=\"font-size: 12pt;\">형태의 실행파일이 아닌 명령어들을 모아서 실행하는 BAT 파일로 실행됩니다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"font-size: 12pt;\">지금은 워낙 유명해져 컴퓨터에 대해 관심인 있는 분중에 </span><span style=\"font-size: 12pt;\">MZK를 모르는 사람이 거의 없지만 초기에 V3로도 알약으로도 해결되지 않는 문제를 MZK를 통해 해결했다는 분들의 경험담이 인터넷에 자주 올라오곤 했습니다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"font-size: 12pt;\">MZK의 제거 대상은악성코드(바이러스, 트로이 목마 등), 악성 애드웨어(광고 프로그램), 위협 가능성 및 심각한 불편함 유발이 확인된 불필요하거나 잠재적으로 원하지 않는 프로그램(PUA/PUP)입니다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"font-size: 12pt;\">저도 해결되지 않던 악성코드 제거나 이유</span><span style=\"font-size: 12pt;\">모를 PC 오작동 문제를 MZK로 해결한 경험이 수차례 있습니다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"font-size: 12pt;\">MZK 실행을 원활하게 실행하기 위해서는 PC를 재 부팅하여 '안전모드 환경 -명령 프롬프트 모드'에서 구동하는것을 권장하나 초보분들에는 조금 어려운 부분이라 판단되는데요.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"font-size: 12pt;\">MZK를 이용하여 악성코드를 치료하는 방법을 소개합니다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 class=\"hdg-03\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 7px; padding: 0px 5px 7px 0px; border-width: 0px 0px 1px; border-bottom: 1px solid #dadada; font-size: 16px; box-sizing: border-box; float: none; clear: both; font-weight: bold; line-height: 1.4; color: #333333; font-style: normal; font-variant: normal; letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px; background-color: #ffffff;\" data-ke-size=\"size23\"><span style=\"margin: 0px; padding: 1px 0px 2px 9px; border-width: 0px 0px 0px 5px; border-style: solid; border-left-color: #3366ff; font-size: 16px; box-sizing: border-box; display: block;\"><span style=\"font-family: NanumGothic; font-size: 18pt;\">따라하기</span><br /></span></h3>\n<p data-ke-size=\"size16\"><span style=\"font-size: 12pt;\">1. 먼저 '</span><span style=\"font-size: 12pt;\">Malware Zero</span><span style=\"font-size: 12pt;\">' 사이트에 방문하시어 MZK 를 다운받습니다.▼<span style=\"font-size: 12pt; color: #0055ff;\"> - 다운로드 링크는 본문 맨아래 참고</span></span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthContent\" data-origin-width=\"700\" data-origin-height=\"427\"><span data-url=\"https://t1.daumcdn.net/cfile/tistory/99450E505CDA8F4802?original\" data-lightbox=\"lightbox\"><img src=\"https://t1.daumcdn.net/cfile/tistory/99450E505CDA8F4802\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99450E505CDA8F4802\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"700\" height=\"427\" data-origin-width=\"700\" data-origin-height=\"427\"/></span></figure>\n</p>\n<p style=\"text-align: center; clear: none; float: none;\" data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"font-size: 12pt;\">2. 다운 받은 압축파일을 해제한후 start.bat 를 실행합니다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"font-size: 12pt;\"> * 윈도우에서 실행을 해도 되지만 PC 환경에 따라 검사 시간이 오래걸릴 수 있으니 안전모드에서 실행하는 것을 권장합니다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"font-size: 12pt;\"> 안전모드 부팅후 명령프롬프트 모드에서 실행하는 것을 대비해서 가능하면 그림과 같이 C:\\ 에 압축을 푸시기 바랍니다.</span><span style=\"font-size: 12pt;\">▼</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthContent\" data-origin-width=\"700\" data-origin-height=\"428\"><span data-url=\"https://t1.daumcdn.net/cfile/tistory/998A83455CDA8F5D0A?original\" data-lightbox=\"lightbox\"><img src=\"https://t1.daumcdn.net/cfile/tistory/998A83455CDA8F5D0A\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F998A83455CDA8F5D0A\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"700\" height=\"428\" data-origin-width=\"700\" data-origin-height=\"428\"/></span></figure>\n</p>\n<p style=\"text-align: center; clear: none; float: none;\" data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"font-size: 12pt;\">3. PC를 재부팅합니다. 이때 안전모드 (명령 프롬프트 사용)을 선택합니다.</span><span style=\"font-size: 16px;\">▼</span></p>\n<blockquote data-ke-style=\"style3\">\n<p data-ke-size=\"size16\"><b><span style=\"font-size: 12pt;\">■ Windows Vista, 7</span></b></p>\n<p data-ke-size=\"size16\"><span style=\"font-size: 12pt;\"> 초기 Windows 부팅 화면이 나오기 바로 전 잠깐의 검은 화면 상태에서 F8 키를 누르면 나오는 고급 부팅 화면에서 선택</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b><span style=\"font-size: 12pt;\">■ Windows 8</span></b></p>\n<p data-ke-size=\"size16\"><span style=\"font-size: 12pt;\"> 설정(단축: 윈도우 + I 키) &rarr; PC 설정 변경 &rarr; 업데이트 및 복구 &rarr; 복구 &rarr; 고급 시작 옵션 &rarr; 다시 시작 &rarr; 문제 해결 &rarr; 고급 옵션 &rarr; 시작 설정 &rarr; 다시 시작 &rarr; 고급 부팅 화면에서 선택</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b><span style=\"font-size: 12pt;\">■ Windows 10</span></b></p>\n<p data-ke-size=\"size16\"><span style=\"font-size: 12pt;\"> 설정(단축: 윈도우 + I 키) &rarr; 업데이트 및 복구 &rarr; 복구 &rarr; 고급 시작 옵션 &rarr; 다시 시작 &rarr; 문제 해결 &rarr; 고급 옵션 &rarr; 시작 설정 &rarr; 다시 시작 &rarr; 고급 부팅 화면에서 선택</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n</blockquote>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthContent\" data-origin-width=\"640\" data-origin-height=\"365\"><span data-url=\"https://t1.daumcdn.net/cfile/tistory/997C8D4F5B2B789507?original\" data-lightbox=\"lightbox\"><img src=\"https://t1.daumcdn.net/cfile/tistory/997C8D4F5B2B789507\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F997C8D4F5B2B789507\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"640\" height=\"365\" data-origin-width=\"640\" data-origin-height=\"365\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"font-size: 12pt;\">4. 프롬프트 상태에서 그림과 같이 명령어을 입력하여 MZK 가 설치된경로로 이동한 후 start.bat 를 실행합니다.</span><span style=\"font-size: 16px;\">▼</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthContent\" data-origin-width=\"385\" data-origin-height=\"243\"><span data-url=\"https://t1.daumcdn.net/cfile/tistory/99FE4A4D5CDA906802?original\" data-lightbox=\"lightbox\"><img src=\"https://t1.daumcdn.net/cfile/tistory/99FE4A4D5CDA906802\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99FE4A4D5CDA906802\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"385\" height=\"243\" data-origin-width=\"385\" data-origin-height=\"243\"/></span></figure>\n</p>\n<p style=\"text-align: center; clear: none; float: none;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: center; clear: none; float: none;\" data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"font-size: 12pt;\">5. MZK 실행 초기화면입니다. 스크립트 초기화중으로 잠시 기다립니다.</span><span style=\"font-size: 16px;\">▼</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthContent\" data-origin-width=\"640\" data-origin-height=\"365\"><span data-url=\"https://t1.daumcdn.net/cfile/tistory/99ECB2335B2B789618?original\" data-lightbox=\"lightbox\"><img src=\"https://t1.daumcdn.net/cfile/tistory/99ECB2335B2B789618\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99ECB2335B2B789618\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"640\" height=\"365\" data-origin-width=\"640\" data-origin-height=\"365\"/></span></figure>\n</p>\n<p style=\"text-align: center; clear: none; float: none;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: center; clear: none; float: none;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: left; clear: none; float: none;\" data-ke-size=\"size16\"><span style=\"font-size: 12pt;\">6. 검사진행전 숙지사항이 공지됩니다. 잘 읽어보시고 'Y'를 클릭</span><span style=\"font-size: 16px;\">▼</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthContent\" data-origin-width=\"640\" data-origin-height=\"365\"><span data-url=\"https://t1.daumcdn.net/cfile/tistory/993A9E4E5B2B78950A?original\" data-lightbox=\"lightbox\"><img src=\"https://t1.daumcdn.net/cfile/tistory/993A9E4E5B2B78950A\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F993A9E4E5B2B78950A\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"640\" height=\"365\" data-origin-width=\"640\" data-origin-height=\"365\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"font-size: 12pt;\">7. 다음 팝업창에서도 'Y' </span><span style=\"font-size: 16px;\">▼</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthContent\" data-origin-width=\"640\" data-origin-height=\"365\"><span data-url=\"https://t1.daumcdn.net/cfile/tistory/995AAA485B2B78960A?original\" data-lightbox=\"lightbox\"><img src=\"https://t1.daumcdn.net/cfile/tistory/995AAA485B2B78960A\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F995AAA485B2B78960A\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"640\" height=\"365\" data-origin-width=\"640\" data-origin-height=\"365\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"font-size: 12pt;\">8. 검사가 시작되었습니다.</span><span style=\"font-size: 16px;\">▼</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthContent\" data-origin-width=\"640\" data-origin-height=\"365\"><span data-url=\"https://t1.daumcdn.net/cfile/tistory/99585F405B2B78953B?original\" data-lightbox=\"lightbox\"><img src=\"https://t1.daumcdn.net/cfile/tistory/99585F405B2B78953B\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99585F405B2B78953B\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"640\" height=\"365\" data-origin-width=\"640\" data-origin-height=\"365\"/></span></figure>\n</p>\n<p style=\"text-align: center; clear: none; float: none;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: left; clear: none; float: none;\" data-ke-size=\"size16\"><span style=\"font-size: 12pt;\">9. 검사중에 PC 에서 이상이 발견되면 화면이 적색으로 변경됩니다. 몇가지 문제가 보이는군요.</span><span style=\"font-size: 16px;\">▼</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthContent\" data-origin-width=\"640\" data-origin-height=\"365\"><span data-url=\"https://t1.daumcdn.net/cfile/tistory/99A8A1415B2B789538?original\" data-lightbox=\"lightbox\"><img src=\"https://t1.daumcdn.net/cfile/tistory/99A8A1415B2B789538\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99A8A1415B2B789538\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"640\" height=\"365\" data-origin-width=\"640\" data-origin-height=\"365\"/></span></figure>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthContent\" data-origin-width=\"640\" data-origin-height=\"365\"><span data-url=\"https://t1.daumcdn.net/cfile/tistory/9953D6345B2B789536?original\" data-lightbox=\"lightbox\"><img src=\"https://t1.daumcdn.net/cfile/tistory/9953D6345B2B789536\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F9953D6345B2B789536\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"640\" height=\"365\" data-origin-width=\"640\" data-origin-height=\"365\"/></span></figure>\n</p>\n<p style=\"text-align: center; clear: none; float: none;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: center; clear: none; float: none;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: left; clear: none; float: none;\" data-ke-size=\"size16\"><span style=\"font-size: 12pt;\">10. 검사가 완료 되었습니다. 진단</span><span style=\"font-size: 12pt;\">내역을 확인하기 위해 '확인'버튼을 클릭합니다.</span><span style=\"font-size: 16px;\">▼</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthContent\" data-origin-width=\"640\" data-origin-height=\"365\"><span data-url=\"https://t1.daumcdn.net/cfile/tistory/9973823B5B2B789505?original\" data-lightbox=\"lightbox\"><img src=\"https://t1.daumcdn.net/cfile/tistory/9973823B5B2B789505\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F9973823B5B2B789505\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"640\" height=\"365\" data-origin-width=\"640\" data-origin-height=\"365\"/></span></figure>\n</p>\n<p style=\"text-align: center; clear: none; float: none;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: left; clear: none; float: none;\" data-ke-size=\"size16\"><span style=\"font-size: 12pt;\">11. 그림과 같이 진단 내역을 확인할 수 있습니다.</span><span style=\"font-size: 16px;\">▼</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthContent\" data-origin-width=\"640\" data-origin-height=\"365\"><span data-url=\"https://t1.daumcdn.net/cfile/tistory/995DDC475B2B789505?original\" data-lightbox=\"lightbox\"><img src=\"https://t1.daumcdn.net/cfile/tistory/995DDC475B2B789505\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F995DDC475B2B789505\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"640\" height=\"365\" data-origin-width=\"640\" data-origin-height=\"365\"/></span></figure>\n</p>\n<p style=\"text-align: center; clear: none; float: none;\" data-ke-size=\"size16\">&nbsp;</p>\n<h3 class=\"hdg-03\" style=\"box-sizing: border-box; line-height: 1.4; color: #333333; margin: 0px 0px 7px; padding: 0px 5px 7px 0px; border-width: 0px 0px 1px; border-image: initial; letter-spacing: 1px; word-spacing: 3px; float: none; clear: both; border-color: initial initial #dadada #55555b; border-style: initial initial solid solid;\" data-ke-size=\"size23\"><span style=\"box-sizing: border-box; margin: 0px; padding: 1px 0px 2px 9px; border-width: 0px 0px 0px 5px; border-style: solid; border-left-color: #3366ff; display: block;\"><span><span style=\"font-size: 24px;\">MZK 다운받기</span></span></span></h3>\n<p style=\"box-sizing: border-box; margin: 1em 0px; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 12px; padding-top: 0px !important; padding-bottom: 0px !important;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"box-sizing: border-box; margin: 1em 0px; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 12px; padding-top: 0px !important; padding-bottom: 0px !important;\" data-ke-size=\"size16\"><span style=\"box-sizing: border-box; font-size: 12pt;\"><span style=\"box-sizing: border-box; font-weight: bold;\"></span></span><span style=\"box-sizing: border-box; font-weight: bold;\"><span style=\"box-sizing: border-box; font-size: 12pt;\">》</span></span><span style=\"box-sizing: border-box; font-size: 12pt;\"><span style=\"box-sizing: border-box; font-weight: bold;\">License</span> : 프리웨어 (</span><span style=\"box-sizing: border-box; font-size: 12pt;\">개인무료, 기업무료) 기부환영.</span></p>\n<p style=\"box-sizing: border-box; margin: 1em 0px; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 12px; padding-top: 0px !important; padding-bottom: 0px !important;\" data-ke-size=\"size16\"><span style=\"box-sizing: border-box; font-size: 12pt;\"><span style=\"box-sizing: border-box; font-weight: bold;\"> 》 다운로드 바로가기</span></span></p>\n<p style=\"box-sizing: border-box; margin: 1em 0px; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 12px; padding-top: 0px !important; padding-bottom: 0px !important;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"box-sizing: border-box; margin: 1em 0px; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 12px; padding-top: 0px !important; padding-bottom: 0px !important; text-align: center;\" data-ke-size=\"size16\"><span style=\"box-sizing: border-box; font-size: 12pt;\"><span style=\"font-size: 18pt;\"><b><a class=\"tx-link\" href=\"https://malzero.xyz/\" target=\"_blank\" rel=\"noopener\"><span style=\"color: #0900ff;\">https://malzero.xyz/</span></a></b></span></span></p>",
        "contentSnippet": "MZK는 단순한 백신 프로그램이 아닌, 다양한 명령어를 모아둔 스크립트 파일로, 복잡한 문제를 효과적으로 해결합니다. 이 기사에서는 MZK를 이용해 악성코드를 제거하는 방법을 단계별로 설명합니다. \n \n\n\n \n악성코드나 바이러스로 고생하신 경험이 있으신 분들이라면 MZK의 강력함을 잘 아실겁니다.\n \n \nMZK 란?\n\nMZK는 Malware Zero Kit의 약자로 V3 처럼 백신 프로그램이라기 보다 악성코드나 바이러스를 효과적으로 처리하기 위한 명령어들을 모아둔 스크립트 파일입니다. 따라서 EXE형태의 실행파일이 아닌 명령어들을 모아서 실행하는 BAT 파일로 실행됩니다.\n \n지금은 워낙 유명해져 컴퓨터에 대해 관심인 있는 분중에 MZK를 모르는 사람이 거의 없지만 초기에 V3로도 알약으로도 해결되지 않는 문제를 MZK를 통해 해결했다는 분들의 경험담이 인터넷에 자주 올라오곤 했습니다.\n \nMZK의 제거 대상은악성코드(바이러스, 트로이 목마 등), 악성 애드웨어(광고 프로그램), 위협 가능성 및 심각한 불편함 유발이 확인된 불필요하거나 잠재적으로 원하지 않는 프로그램(PUA/PUP)입니다.\n \n저도 해결되지 않던 악성코드 제거나 이유모를 PC 오작동 문제를 MZK로 해결한 경험이 수차례 있습니다.\n \nMZK 실행을 원활하게 실행하기 위해서는 PC를 재 부팅하여 '안전모드 환경 -명령 프롬프트 모드'에서 구동하는것을 권장하나 초보분들에는 조금 어려운 부분이라 판단되는데요.\n \nMZK를 이용하여 악성코드를 치료하는 방법을 소개합니다.\n \n \n따라하기\n\n1. 먼저 'Malware Zero' 사이트에 방문하시어 MZK 를 다운받습니다.▼ - 다운로드 링크는 본문 맨아래 참고\n\n\n \n \n \n2. 다운 받은 압축파일을 해제한후 start.bat 를 실행합니다.\n * 윈도우에서 실행을 해도 되지만 PC 환경에 따라 검사 시간이 오래걸릴 수 있으니 안전모드에서 실행하는 것을 권장합니다.\n 안전모드 부팅후 명령프롬프트 모드에서 실행하는 것을 대비해서 가능하면 그림과 같이 C:\\ 에 압축을 푸시기 바랍니다.▼\n\n\n \n \n \n3. PC를 재부팅합니다. 이때 안전모드 (명령 프롬프트 사용)을 선택합니다.▼\n■ Windows Vista, 7\n 초기 Windows 부팅 화면이 나오기 바로 전 잠깐의 검은 화면 상태에서 F8 키를 누르면 나오는 고급 부팅 화면에서 선택\n \n■ Windows 8\n 설정(단축: 윈도우 + I 키) → PC 설정 변경 → 업데이트 및 복구 → 복구 → 고급 시작 옵션 → 다시 시작 → 문제 해결 → 고급 옵션 → 시작 설정 → 다시 시작 → 고급 부팅 화면에서 선택\n \n■ Windows 10\n 설정(단축: 윈도우 + I 키) → 업데이트 및 복구 → 복구 → 고급 시작 옵션 → 다시 시작 → 문제 해결 → 고급 옵션 → 시작 설정 → 다시 시작 → 고급 부팅 화면에서 선택\n \n \n\n\n \n \n4. 프롬프트 상태에서 그림과 같이 명령어을 입력하여 MZK 가 설치된경로로 이동한 후 start.bat 를 실행합니다.▼\n\n\n \n \n \n5. MZK 실행 초기화면입니다. 스크립트 초기화중으로 잠시 기다립니다.▼\n\n\n \n \n6. 검사진행전 숙지사항이 공지됩니다. 잘 읽어보시고 'Y'를 클릭▼\n\n\n \n \n7. 다음 팝업창에서도 'Y' ▼\n\n\n \n8. 검사가 시작되었습니다.▼\n\n\n \n9. 검사중에 PC 에서 이상이 발견되면 화면이 적색으로 변경됩니다. 몇가지 문제가 보이는군요.▼\n\n\n\n \n \n10. 검사가 완료 되었습니다. 진단내역을 확인하기 위해 '확인'버튼을 클릭합니다.▼\n\n\n \n11. 그림과 같이 진단 내역을 확인할 수 있습니다.▼\n\n\n \nMZK 다운받기\n \n》License : 프리웨어 (개인무료, 기업무료) 기부환영.\n 》 다운로드 바로가기\n \nhttps://malzero.xyz/",
        "guid": "http://muzbox.tistory.com/1307",
        "categories": [
          "추천 프리웨어/시스템관리,보안",
          "광고제거",
          "맬웨어",
          "멀웨어 제거 프로그램 추천",
          "무료 바이러스 백신",
          "무료 악성코드 제거 프로그램",
          "바이러스",
          "악성코드",
          "악성코드 제거 프로그램",
          "유해 프로그램 제거"
        ],
        "isoDate": "2024-06-23T13:30:21.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "똑키, 즐겨찾기도 되는 단축키 뷰어",
        "link": "http://muzbox.tistory.com/1999",
        "pubDate": "Thu, 20 Jun 2024 16:20:13 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/1999#entry1999comment",
        "content": "<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp; 다양한 프로그램의 단축키를 쉽게 검색하고 즐겨찾기에 추가할 수 있는 똑키를 소개합니다. 문서 작업, 디자인, 게임 등에서 작업 효율을 높여주는 필수 프로그램이라 생각합니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<table style=\"border-collapse: collapse; width: 95.6979%; height: 248px;\" border=\"1\" data-ke-align=\"alignLeft\">\n<tbody>\n<tr style=\"height: 62px;\"><!-- 첫 번째 열에 배경색을 노란색으로 설정 -->\n<td style=\"width: 13.1835%; height: 62px; text-align: center; background-color: #555555;\"><span style=\"color: #ffffff;\"><b>분류</b></span></td>\n<td style=\"width: 22.4483%; height: 62px; text-align: center;\">문서작업/단축키</td>\n<td style=\"width: 64.3682%; height: 248px; text-align: center;\" rowspan=\"4\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"똑키.png\" data-origin-width=\"336\" data-origin-height=\"448\"><span data-url=\"https://blog.kakaocdn.net/dn/ctLVp0/btsH7iXsRFA/kr7xldQkI4gye9FABqt380/img.png\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/ctLVp0/btsH7iXsRFA/kr7xldQkI4gye9FABqt380/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FctLVp0%2FbtsH7iXsRFA%2Fkr7xldQkI4gye9FABqt380%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"238\" height=\"317\" data-filename=\"똑키.png\" data-origin-width=\"336\" data-origin-height=\"448\"/></span></figure>\n</td>\n</tr>\n<tr style=\"height: 62px;\"><!-- 첫 번째 열에 배경색을 노란색으로 설정 -->\n<td style=\"width: 13.1835%; height: 62px; text-align: center; background-color: #555555;\"><span style=\"color: #ffffff;\"><b>사용범위</b></span></td>\n<td style=\"width: 22.4483%; height: 62px; text-align: center;\">무료(개인)</td>\n</tr>\n<tr style=\"height: 62px;\"><!-- 첫 번째 열에 배경색을 노란색으로 설정 -->\n<td style=\"width: 13.1835%; height: 62px; text-align: center; background-color: #555555;\"><span style=\"color: #ffffff;\"><b>사용환경</b></span></td>\n<td style=\"width: 22.4483%; height: 62px; text-align: center;\">Windows</td>\n</tr>\n<tr style=\"height: 62px;\"><!-- 첫 번째 열에 배경색을 노란색으로 설정 -->\n<td style=\"width: 13.1835%; height: 62px; text-align: center; background-color: #555555;\"><span style=\"color: #ffffff;\"><b>제작사</b></span></td>\n<td style=\"width: 22.4483%; height: 62px; text-align: center;\"><a href=\"https://trendsoftware.co.kr/\" target=\"_blank\" rel=\"noopener\">트렌드소프트웨어</a></td>\n</tr>\n</tbody>\n</table>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b> 프로그램 소개</b></h2>\n<p data-ke-size=\"size18\">&nbsp;현대인의 일상에서 컴퓨터는 필수적인 도구입니다. 업무를 처리하거나, 디자인 작업을 하거나, 게임을 즐기기 위해 우리는 컴퓨터 앞에 많은 시간을 할애합니다. 하지만 컴퓨터 작업 속도를 높이는 가장 간단하고 효과적인 방법은 바로 단축키를 활용하는 것인데요. 단축키를 잘 활용하면 불필요한 마우스 클릭을 줄이고, 작업 시간을 크게 단축할 수 있기때문이죠.<br /><br />이번 포스팅에서는 다양한 프로그램의 단축키를 쉽고 빠르게 검색하고 즐겨찾기에 추가할 수 있는 프로그램, <span style=\"color: #ee2323;\"><b>똑키</b></span>에 대해 소개합니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"똑키 단축키 뷰어.png\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/U7oev/btsH5vEe98q/OVCgmgcK1aEigz8z0elR3k/img.png\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/U7oev/btsH5vEe98q/OVCgmgcK1aEigz8z0elR3k/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FU7oev%2FbtsH5vEe98q%2FOVCgmgcK1aEigz8z0elR3k%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"똑키 단축키 뷰어.png\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b> 주요 특징</b></h2>\n<p data-ke-size=\"size18\">&nbsp;<span style=\"color: #ee2323;\"><b>똑키</b></span>는 다양한 프로그램의 단축키를 쉽고 빠르게 검색할 수 있는 프로그램입니다. 이 프로그램은 사용자가 찾고자 하는 단축키를 간편하게 검색할 수 있도록 도와주며, 자주 사용하는 단축키를 즐겨찾기에 추가하여 언제든지 빠르게 접근할 수 있게 합니다. 문서 작업, 디자인 및 영상 편집, PC 게임, 개발자 명령어, 메신저 등 여러 분야의 단축키를 지원하여 사용자들의 다양한 요구를 충족시킵니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"똑키.jpg\" data-origin-width=\"720\" data-origin-height=\"441\"><span data-url=\"https://blog.kakaocdn.net/dn/dxW0ij/btsH7iJXxfZ/o0HRGRQRG2S92slCRjgmC1/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/dxW0ij/btsH7iJXxfZ/o0HRGRQRG2S92slCRjgmC1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdxW0ij%2FbtsH7iJXxfZ%2Fo0HRGRQRG2S92slCRjgmC1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"똑키.jpg\" data-origin-width=\"720\" data-origin-height=\"441\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\"><span style=\"color: #ef5369;\"><b>1. 간편한 검색 기능</b></span></p>\n<p data-ke-size=\"size18\">똑키는 직관적인 검색 인터페이스를 제공하여 사용자가 원하는 단축키를 손쉽게 검색할 수 있습니다. 검색창에 키워드를 입력하면 관련 단축키 목록이 바로 나타나며, 필요한 정보를 빠르게 찾을 수 있습니다.</p>\n<p data-ke-size=\"size18\"><br /><span style=\"color: #ef5369;\"><b>2. 즐겨찾기 기능</b></span> </p>\n<p data-ke-size=\"size18\">자주&nbsp;사용하는&nbsp;단축키를&nbsp;즐겨찾기에&nbsp;추가하여&nbsp;언제든지&nbsp;빠르게&nbsp;접근할&nbsp;수&nbsp;있습니다.&nbsp;즐겨찾기에&nbsp;저장된&nbsp;단축키는&nbsp;상단&nbsp;메뉴에서&nbsp;쉽게&nbsp;확인할&nbsp;수&nbsp;있어&nbsp;다시&nbsp;찾아볼&nbsp;필요&nbsp;없이&nbsp;즉시&nbsp;사용할&nbsp;수&nbsp;있습니다. <br /><br /><span style=\"color: #ef5369;\"><b>3. 다양한 프로그램 지원</b></span><br />똑키는&nbsp;문서&nbsp;작업&nbsp;프로그램(예:&nbsp;Excel,&nbsp;Word),&nbsp;디자인&nbsp;및&nbsp;영상&nbsp;편집&nbsp;프로그램(예:&nbsp;Photoshop,&nbsp;Premiere),&nbsp;PC&nbsp;게임,&nbsp;개발자&nbsp;명령어,&nbsp;메신저&nbsp;등&nbsp;다양한&nbsp;프로그램의&nbsp;단축키를&nbsp;지원합니다.&nbsp;이를&nbsp;통해&nbsp;사용자는&nbsp;여러&nbsp;프로그램에서&nbsp;단축키를&nbsp;익히고&nbsp;활용할&nbsp;수&nbsp;있습니다. <br /><br /><span style=\"color: #ef5369;\"><b>4. 유용한 단축키 추천</b></span><br />똑키는&nbsp;사용자들에게&nbsp;작업&nbsp;효율을&nbsp;높여주는&nbsp;유용한&nbsp;단축키를&nbsp;추천합니다.&nbsp;불필요한&nbsp;마우스&nbsp;클릭을&nbsp;줄이고,&nbsp;작업&nbsp;속도를&nbsp;두&nbsp;배로&nbsp;올려주는&nbsp;단축키를&nbsp;제공하여&nbsp;사용자들의&nbsp;생산성을&nbsp;극대화합니다. <br /><br /><span style=\"color: #ef5369;\"><b>5. 실무 엑셀 함수 모음</b></span> <br />특히, 엑셀 작업을 자주 하는 사용자들을 위해 실무에서 자주 사용하는 엑셀 함수 모음을 제공합니다. 엑린이들도 쉽게 사용할 수 있도록 잘 정리되어 있어 업무 효율을 크게 높일 수 있습니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b>  프로그램 장단점</b></h2>\n<h4 data-ke-size=\"size20\"><b> 장점</b></h4>\n<blockquote data-ke-style=\"style3\"><b>1. 작업 효율성 향상:</b> 다양한 프로그램의 단축키를 쉽게 배우고 사용할 수 있어, 마우스 클릭을 줄이고 생산성을 높일 수 있습니다. <br /><b>2. 직관적인 인터페이스:</b> 초보자도 쉽게 사용할 수 있는 간단한 인터페이스를 제공합니다. <br /><b>3. 즐겨찾기 기능:</b> 자주 사용하는 단축키를 즐겨찾기에 추가하여 빠르게 접근할 수 있습니다. <br /><b>4. 다양한 프로그램 지원:</b> 여러 종류의 프로그램에서 단축키를 배우고 사용할 수 있도록 지원합니다. <br /><b>5. 유용한 단축키 추천:</b> 필요한 단축키를 추천하여 작업 효율을 높여줍니다.</blockquote>\n<h4 data-ke-size=\"size20\"><b> 단점</b></h4>\n<blockquote data-ke-style=\"style3\"><b>1. 일부 프로그램의 단축키 미지원:</b> 모든 프로그램의 단축키를 지원하지 않아, 필요한 경우 사용자가 직접 찾아야 할 수 있습니다. <br /><b>2. 초보자에게 어려움:</b> 단축키를 처음 배우는 사용자에게는 초기 학습이 어려울 수 있습니다. <br /><b>3. 기능 부족:</b> 단축키 외의 추가 기능이 부족하여, 특정 기능이 필요한 사용자는 다른 프로그램을 찾아야 할 수도 있습니다.</blockquote>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b> &nbsp;간단 사용법</b></h2>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\"><span style=\"color: #ef5369;\"><b>1.&nbsp;프로그램&nbsp;설치&nbsp;및&nbsp;실행</b></span> <br />&nbsp; &nbsp;- 똑키 공식 웹사이트 또는 아래 링크에서 설치 파일을 다운로드합니다. <br />&nbsp;&nbsp;&nbsp;-&nbsp;다운로드한&nbsp;설치&nbsp;파일을&nbsp;실행하여&nbsp;설치&nbsp;과정을&nbsp;진행합니다. <br />&nbsp;&nbsp;&nbsp;-&nbsp;설치가&nbsp;완료되면&nbsp;바탕화면&nbsp;또는&nbsp;시작&nbsp;메뉴에서&nbsp;똑키&nbsp;아이콘을&nbsp;클릭하여&nbsp;프로그램을&nbsp;실행합니다. <br /><br /><span style=\"color: #ef5369;\"><b>2. 단축키가 필요한 프로그램 검색</b></span> <br />- 프로그램을 실행하면 메인 화면 상단에 검색창이 나타납니다. <br />- 찾고자 하는 단축키와 관련된 프로그램명을 입력합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"똑키 단축키 검색.jpg\" data-origin-width=\"801\" data-origin-height=\"535\"><span data-url=\"https://blog.kakaocdn.net/dn/Mgxd1/btsH6YycKwN/Mcf1ZYNxksd9uk7PSukiLK/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/Mgxd1/btsH6YycKwN/Mcf1ZYNxksd9uk7PSukiLK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FMgxd1%2FbtsH6YycKwN%2FMcf1ZYNxksd9uk7PSukiLK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"700\" height=\"468\" data-filename=\"똑키 단축키 검색.jpg\" data-origin-width=\"801\" data-origin-height=\"535\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\"><span style=\"color: #ef5369;\"><b>3. 프로그램별 단축키 탐색</b></span><br />&nbsp; 각 프로그램별로 기능별 카테고리가 나누어져 있어 필요한 단축키를 쉽게 찾을 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"검색2.jpg\" data-origin-width=\"336\" data-origin-height=\"528\"><span data-url=\"https://blog.kakaocdn.net/dn/ZRVyG/btsH5eJyj0Y/vPyQmia1hSKligmOzPx031/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/ZRVyG/btsH5eJyj0Y/vPyQmia1hSKligmOzPx031/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FZRVyG%2FbtsH5eJyj0Y%2FvPyQmia1hSKligmOzPx031%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"검색2.jpg\" data-origin-width=\"336\" data-origin-height=\"528\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\"><br /><span style=\"color: #ef5369;\"><b>4. 즐겨찾기 추가</b></span> <br />&nbsp;- 검색 결과에서 자주 사용할 단축키를 선택합니다. <br />&nbsp;- 해당 단축키 오른쪽에 있는 즐겨찾기 노란 아이콘을 클릭하여 즐겨찾기에 추가합니다. <br />&nbsp;- 즐겨찾기에 추가된 단축키는 메인 화면 상단의 즐겨찾기 메뉴에서 확인할 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"즐겨찾기.jpg\" data-origin-width=\"336\" data-origin-height=\"464\"><span data-url=\"https://blog.kakaocdn.net/dn/b8i8CD/btsH6cxaq0D/IoxXKgaFJhqKStRT3QUuD1/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/b8i8CD/btsH6cxaq0D/IoxXKgaFJhqKStRT3QUuD1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb8i8CD%2FbtsH6cxaq0D%2FIoxXKgaFJhqKStRT3QUuD1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"즐겨찾기.jpg\" data-origin-width=\"336\" data-origin-height=\"464\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 style=\"color: #000000; text-align: start;\" data-ke-size=\"size26\"><b>  라이센스 정책</b></h2>\n<p data-ke-size=\"size18\">똑키는 자유롭게 설치하여 사용이 가능한 프리웨어입니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b> 효과적인 활용 방법&nbsp;&nbsp;</b></h2>\n<p data-ke-size=\"size18\"><span style=\"color: #ef5369;\"><b>1. 자주 사용하는 단축키 익히기</b></span> <br />&nbsp;문서나 이미지, 영상 편집 작업 시 자주 사용하는 단축키를 익히면 작업 속도를 크게 향상시킬 수 있습니다. 예를 들어, 엑셀의 복사(Ctrl + C), 붙여넣기(Ctrl + V), 셀 병합(Alt + H + M + M) 등의 단축키를 익혀두면 반복적인 작업을 빠르게 처리할 수 있습니다. <br /><br /><span style=\"color: #ef5369;\"><b>2. 게임에서의 단축키 활용</b></span> <br />게임에서도 단축키는 중요한 역할을 합니다. 각 게임별로 중요한 단축키를 미리 숙지하여 사용하면 게임 플레이가 한층 더 원활해지고, 반응 속도도 빨라질 수 있습니다. 예를 들어, FPS 게임에서 무기 변경(Q), 리로드(R) 등의 단축키를 익혀두면 게임에서의 전투력을 높일 수 있습니다. <br /><br /><span style=\"color: #ef5369;\"><b>3. 실무 엑셀 함수 모음 활용</b></span> <br />엑셀을 자주 사용하는 업무 환경에서 실무 엑셀 함수 모음을 활용하면 업무 효율을 극대화할 수 있습니다. 기본적인 함수부터 고급 함수까지 다양하게 제공되므로, 필요한 함수를 바로 찾아 사용할 수 있습니다.</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b>⬇️ 프로그램 다운로드</b></h2>\n\n<p data-ke-size=\"size16\">&nbsp;</p>\n<figure id=\"og_1718867779975\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"트렌드소프트웨어 똑똑단축키 프로그램\" data-og-description=\"트렌드소프트웨어 똑똑단축키, 엑셀, 윈도우, 게임, 프로그램 단축키 정보 프로그램 입니다.\" data-og-host=\"trendsoftware.co.kr\" data-og-source-url=\"https://trendsoftware.co.kr/ddockey\" data-og-url=\"https://trendsoftware.co.kr/ddockey\" data-og-image=\"https://scrap.kakaocdn.net/dn/bxt7HX/hyWoFEJmDt/2Kk5p4G4enCLVxFsBvlN91/img.png?width=1920&amp;height=1901&amp;face=0_0_1920_1901,https://scrap.kakaocdn.net/dn/AjGwo/hyWoKTy7VM/N7v5UFHyZdCIRkj2KbSKj1/img.png?width=1920&amp;height=1765&amp;face=0_0_1920_1765\"><a href=\"https://trendsoftware.co.kr/ddockey\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://trendsoftware.co.kr/ddockey\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/bxt7HX/hyWoFEJmDt/2Kk5p4G4enCLVxFsBvlN91/img.png?width=1920&amp;height=1901&amp;face=0_0_1920_1901,https://scrap.kakaocdn.net/dn/AjGwo/hyWoKTy7VM/N7v5UFHyZdCIRkj2KbSKj1/img.png?width=1920&amp;height=1765&amp;face=0_0_1920_1765');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">트렌드소프트웨어 똑똑단축키 프로그램</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">트렌드소프트웨어 똑똑단축키, 엑셀, 윈도우, 게임, 프로그램 단축키 정보 프로그램 입니다.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">trendsoftware.co.kr</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "다양한 프로그램의 단축키를 쉽게 검색하고 즐겨찾기에 추가할 수 있는 똑키를 소개합니다. 문서 작업, 디자인, 게임 등에서 작업 효율을 높여주는 필수 프로그램이라 생각합니다.\n \n\n분류\n문서작업/단축키\n\n\n\n\n사용범위\n무료(개인)\n\n\n사용환경\nWindows\n\n\n제작사\n트렌드소프트웨어\n\n\n\n \n 프로그램 소개\n 현대인의 일상에서 컴퓨터는 필수적인 도구입니다. 업무를 처리하거나, 디자인 작업을 하거나, 게임을 즐기기 위해 우리는 컴퓨터 앞에 많은 시간을 할애합니다. 하지만 컴퓨터 작업 속도를 높이는 가장 간단하고 효과적인 방법은 바로 단축키를 활용하는 것인데요. 단축키를 잘 활용하면 불필요한 마우스 클릭을 줄이고, 작업 시간을 크게 단축할 수 있기때문이죠.\n이번 포스팅에서는 다양한 프로그램의 단축키를 쉽고 빠르게 검색하고 즐겨찾기에 추가할 수 있는 프로그램, 똑키에 대해 소개합니다.\n \n\n\n \n \n 주요 특징\n 똑키는 다양한 프로그램의 단축키를 쉽고 빠르게 검색할 수 있는 프로그램입니다. 이 프로그램은 사용자가 찾고자 하는 단축키를 간편하게 검색할 수 있도록 도와주며, 자주 사용하는 단축키를 즐겨찾기에 추가하여 언제든지 빠르게 접근할 수 있게 합니다. 문서 작업, 디자인 및 영상 편집, PC 게임, 개발자 명령어, 메신저 등 여러 분야의 단축키를 지원하여 사용자들의 다양한 요구를 충족시킵니다.\n\n\n \n1. 간편한 검색 기능\n똑키는 직관적인 검색 인터페이스를 제공하여 사용자가 원하는 단축키를 손쉽게 검색할 수 있습니다. 검색창에 키워드를 입력하면 관련 단축키 목록이 바로 나타나며, 필요한 정보를 빠르게 찾을 수 있습니다.\n2. 즐겨찾기 기능 \n자주 사용하는 단축키를 즐겨찾기에 추가하여 언제든지 빠르게 접근할 수 있습니다. 즐겨찾기에 저장된 단축키는 상단 메뉴에서 쉽게 확인할 수 있어 다시 찾아볼 필요 없이 즉시 사용할 수 있습니다. \n3. 다양한 프로그램 지원\n똑키는 문서 작업 프로그램(예: Excel, Word), 디자인 및 영상 편집 프로그램(예: Photoshop, Premiere), PC 게임, 개발자 명령어, 메신저 등 다양한 프로그램의 단축키를 지원합니다. 이를 통해 사용자는 여러 프로그램에서 단축키를 익히고 활용할 수 있습니다. \n4. 유용한 단축키 추천\n똑키는 사용자들에게 작업 효율을 높여주는 유용한 단축키를 추천합니다. 불필요한 마우스 클릭을 줄이고, 작업 속도를 두 배로 올려주는 단축키를 제공하여 사용자들의 생산성을 극대화합니다. \n5. 실무 엑셀 함수 모음 \n특히, 엑셀 작업을 자주 하는 사용자들을 위해 실무에서 자주 사용하는 엑셀 함수 모음을 제공합니다. 엑린이들도 쉽게 사용할 수 있도록 잘 정리되어 있어 업무 효율을 크게 높일 수 있습니다.\n \n \n  프로그램 장단점\n 장점\n1. 작업 효율성 향상: 다양한 프로그램의 단축키를 쉽게 배우고 사용할 수 있어, 마우스 클릭을 줄이고 생산성을 높일 수 있습니다. \n2. 직관적인 인터페이스: 초보자도 쉽게 사용할 수 있는 간단한 인터페이스를 제공합니다. \n3. 즐겨찾기 기능: 자주 사용하는 단축키를 즐겨찾기에 추가하여 빠르게 접근할 수 있습니다. \n4. 다양한 프로그램 지원: 여러 종류의 프로그램에서 단축키를 배우고 사용할 수 있도록 지원합니다. \n5. 유용한 단축키 추천: 필요한 단축키를 추천하여 작업 효율을 높여줍니다.\n 단점\n1. 일부 프로그램의 단축키 미지원: 모든 프로그램의 단축키를 지원하지 않아, 필요한 경우 사용자가 직접 찾아야 할 수 있습니다. \n2. 초보자에게 어려움: 단축키를 처음 배우는 사용자에게는 초기 학습이 어려울 수 있습니다. \n3. 기능 부족: 단축키 외의 추가 기능이 부족하여, 특정 기능이 필요한 사용자는 다른 프로그램을 찾아야 할 수도 있습니다.\n \n \n  간단 사용법\n \n1. 프로그램 설치 및 실행 \n   - 똑키 공식 웹사이트 또는 아래 링크에서 설치 파일을 다운로드합니다. \n   - 다운로드한 설치 파일을 실행하여 설치 과정을 진행합니다. \n   - 설치가 완료되면 바탕화면 또는 시작 메뉴에서 똑키 아이콘을 클릭하여 프로그램을 실행합니다. \n2. 단축키가 필요한 프로그램 검색 \n- 프로그램을 실행하면 메인 화면 상단에 검색창이 나타납니다. \n- 찾고자 하는 단축키와 관련된 프로그램명을 입력합니다.\n\n\n \n3. 프로그램별 단축키 탐색\n  각 프로그램별로 기능별 카테고리가 나누어져 있어 필요한 단축키를 쉽게 찾을 수 있습니다.\n\n\n\n4. 즐겨찾기 추가 \n - 검색 결과에서 자주 사용할 단축키를 선택합니다. \n - 해당 단축키 오른쪽에 있는 즐겨찾기 노란 아이콘을 클릭하여 즐겨찾기에 추가합니다. \n - 즐겨찾기에 추가된 단축키는 메인 화면 상단의 즐겨찾기 메뉴에서 확인할 수 있습니다.\n\n\n \n  라이센스 정책\n똑키는 자유롭게 설치하여 사용이 가능한 프리웨어입니다.\n \n \n 효과적인 활용 방법  \n1. 자주 사용하는 단축키 익히기 \n 문서나 이미지, 영상 편집 작업 시 자주 사용하는 단축키를 익히면 작업 속도를 크게 향상시킬 수 있습니다. 예를 들어, 엑셀의 복사(Ctrl + C), 붙여넣기(Ctrl + V), 셀 병합(Alt + H + M + M) 등의 단축키를 익혀두면 반복적인 작업을 빠르게 처리할 수 있습니다. \n2. 게임에서의 단축키 활용 \n게임에서도 단축키는 중요한 역할을 합니다. 각 게임별로 중요한 단축키를 미리 숙지하여 사용하면 게임 플레이가 한층 더 원활해지고, 반응 속도도 빨라질 수 있습니다. 예를 들어, FPS 게임에서 무기 변경(Q), 리로드(R) 등의 단축키를 익혀두면 게임에서의 전투력을 높일 수 있습니다. \n3. 실무 엑셀 함수 모음 활용 \n엑셀을 자주 사용하는 업무 환경에서 실무 엑셀 함수 모음을 활용하면 업무 효율을 극대화할 수 있습니다. 기본적인 함수부터 고급 함수까지 다양하게 제공되므로, 필요한 함수를 바로 찾아 사용할 수 있습니다.\n \n⬇️ 프로그램 다운로드\n \n\n \n트렌드소프트웨어 똑똑단축키 프로그램\n트렌드소프트웨어 똑똑단축키, 엑셀, 윈도우, 게임, 프로그램 단축키 정보 프로그램 입니다.\ntrendsoftware.co.kr",
        "guid": "http://muzbox.tistory.com/1999",
        "categories": [
          "추천 프리웨어/문서,업무",
          "단축키 검색 프로그램",
          "디자인 단축키",
          "똑키 단축키",
          "문서 작업 단축키",
          "엑셀 함수 모음",
          "작업 효율 향상"
        ],
        "isoDate": "2024-06-20T07:20:13.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": [
      {
        "creator": "늑돌이",
        "title": "LG디스플레이, 밝고 오래가는 13인치 탠덤 OLED 업계 최초 양산에 성공",
        "link": "http://lazion.com/2513708",
        "pubDate": "Mon, 24 Jun 2024 10:41:03 +0900",
        "author": "늑돌이",
        "comments": "http://lazion.com/2513708#entry2513708comment",
        "content": "<h3 data-ke-size=\"size23\"><b>LG디스플레이</b>가 <b>업계 최초</b>로 수명과 밝기를 높이고 소비전력은 줄인 <b>노트북용 13인치 탠덤(Tandem) OLED 양산</b>에 성공했습니다.</h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>탠덤(Tandem) OLED는 무엇?</b></span></h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"56632.jpg\" data-origin-width=\"826\" data-origin-height=\"620\"><span data-url=\"https://blog.kakaocdn.net/dn/cJXrNs/btsIaG5dm1o/tPVHHyBmbNNjYc0v5dBcsk/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/cJXrNs/btsIaG5dm1o/tPVHHyBmbNNjYc0v5dBcsk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcJXrNs%2FbtsIaG5dm1o%2FtPVHHyBmbNNjYc0v5dBcsk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"56632.jpg\" data-origin-width=\"826\" data-origin-height=\"620\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">지난 2019년 LG디스플레이가 처음으로 상용화에 성공한 탠덤(Tandem) OLED는 <b>레드&middot;그린&middot;블루(RGB) 유기발광층을 2개 층으로 쌓는 방식</b>으로 <b>장수명, 고휘도</b>를 구현, 기존 1개 층인 OLED 패널 대비 내구성과 성능이 뛰어납니다.&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">특히 OLED 소자에 가해지는 에너지를 분산시켜 보다 오랫동안 안정적으로 작동할 수 있어 품질 기준이 까다로운 차량용 OLED에 처음 적용되었으며, <b>노트북</b>, 모니터, <b>태블릿</b> 등 화면 사용 시간이 상대적으로 긴 IT 제품에도 잘 어울립니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">참고로 노트북 패널에 탠덤 OLED가 적용된 것은 이번이 처음으로, LG디스플레이는 노트북 사용 환경에 맞춘 탠덤 OLED를 새롭게 개발했습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>LG디스플레이의 노트북용 탠덤 OLED 패널의 특징</b></span></h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">LG디스플레이가 업계 최초로 양산을 시작한<b> 13인치 노트북용 탠덤 OLED 패널</b>의 주요 특징은 다음과 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>기존 OLED 패널 대비 <b>수명은 2배, 밝기는 3배</b>까지 향상시킬 수 있고, <b>소비전력은 최대 40% 저감</b> 가능해 일반 노트북뿐 아니라 AI 노트북 등 고성능 IT 기기에도 최적화되어 있습니다.<br /><br /></li>\n<li>부품 설계 및 구조 개선 등을 통해 기존 노트북용 OLED 대비 <b>약 40% 얇아지고, 28% 가벼워져</b> 날렵한 디자인을 구현하고 휴대성을 높일 수 있습니다.<br /><br /></li>\n<li><b>WQXGA+(2880x1800)</b> 고해상도, 디지털영화협회(DCI) 표준 색 영역 <b>DCI-P3를 100% 충족</b>하는 정확한 색 표현력으로 높은 화질을 자랑합니다.<br /><br /></li>\n<li>화소 스스로 빛을 내는 OLED 특유의 무한대의 명암비를 바탕으로 비디오전자공학표준협회(VESA)의 디스플레이 <b>HDR(High Dynamic Range) 트루 블랙 500</b> 기준을 충족합니다.<br /><br /></li>\n<li>터치 센서를 패널 안에 내장, 성능을 높인 고감도 토털 터치 솔루션을 탑재해 정확한 터치감을 구현합니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">LG디스플레이가 이미 양산에 들어간 만큼 조만간 13.3인치 탠덤 OLED 패널을 이용한 노트북이나 태블릿 제품을 만나볼 수 있을 것으로 보입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: right;\" data-ke-size=\"size16\">(출처 : LG디스플레이)</p>",
        "contentSnippet": "LG디스플레이가 업계 최초로 수명과 밝기를 높이고 소비전력은 줄인 노트북용 13인치 탠덤(Tandem) OLED 양산에 성공했습니다.\n \n탠덤(Tandem) OLED는 무엇?\n \n\n\n \n지난 2019년 LG디스플레이가 처음으로 상용화에 성공한 탠덤(Tandem) OLED는 레드·그린·블루(RGB) 유기발광층을 2개 층으로 쌓는 방식으로 장수명, 고휘도를 구현, 기존 1개 층인 OLED 패널 대비 내구성과 성능이 뛰어납니다. \n \n특히 OLED 소자에 가해지는 에너지를 분산시켜 보다 오랫동안 안정적으로 작동할 수 있어 품질 기준이 까다로운 차량용 OLED에 처음 적용되었으며, 노트북, 모니터, 태블릿 등 화면 사용 시간이 상대적으로 긴 IT 제품에도 잘 어울립니다.\n \n참고로 노트북 패널에 탠덤 OLED가 적용된 것은 이번이 처음으로, LG디스플레이는 노트북 사용 환경에 맞춘 탠덤 OLED를 새롭게 개발했습니다.\n \n \nLG디스플레이의 노트북용 탠덤 OLED 패널의 특징\n \nLG디스플레이가 업계 최초로 양산을 시작한 13인치 노트북용 탠덤 OLED 패널의 주요 특징은 다음과 같습니다.\n \n기존 OLED 패널 대비 수명은 2배, 밝기는 3배까지 향상시킬 수 있고, 소비전력은 최대 40% 저감 가능해 일반 노트북뿐 아니라 AI 노트북 등 고성능 IT 기기에도 최적화되어 있습니다.\n\n부품 설계 및 구조 개선 등을 통해 기존 노트북용 OLED 대비 약 40% 얇아지고, 28% 가벼워져 날렵한 디자인을 구현하고 휴대성을 높일 수 있습니다.\n\nWQXGA+(2880x1800) 고해상도, 디지털영화협회(DCI) 표준 색 영역 DCI-P3를 100% 충족하는 정확한 색 표현력으로 높은 화질을 자랑합니다.\n\n화소 스스로 빛을 내는 OLED 특유의 무한대의 명암비를 바탕으로 비디오전자공학표준협회(VESA)의 디스플레이 HDR(High Dynamic Range) 트루 블랙 500 기준을 충족합니다.\n\n터치 센서를 패널 안에 내장, 성능을 높인 고감도 토털 터치 솔루션을 탑재해 정확한 터치감을 구현합니다.\n \nLG디스플레이가 이미 양산에 들어간 만큼 조만간 13.3인치 탠덤 OLED 패널을 이용한 노트북이나 태블릿 제품을 만나볼 수 있을 것으로 보입니다.\n \n(출처 : LG디스플레이)",
        "guid": "http://lazion.com/2513708",
        "categories": [
          "#TV#디스플레이#프로젝터",
          "Display",
          "ipad",
          "Laptop",
          "LG Display",
          "News",
          "OLED",
          "tandem oled"
        ],
        "isoDate": "2024-06-24T01:41:03.000Z"
      },
      {
        "creator": "늑돌이",
        "title": "삼성, 에너지 절약 강화한 스마트싱스 에너지(SmartThings Energy) 서비스 개편",
        "link": "http://lazion.com/2513706",
        "pubDate": "Thu, 20 Jun 2024 11:33:34 +0900",
        "author": "늑돌이",
        "comments": "http://lazion.com/2513706#entry2513706comment",
        "content": "<h3 data-ke-size=\"size23\">삼성전자가 에너지 절약 기능 중심으로 <b>스마트싱스 에너지(SmartThings Energy)</b> 서비스를 오늘(20일) 개편했습니다.</h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"2009358633_20240619182812_6407040536_web.jpg\" data-origin-width=\"2530\" data-origin-height=\"1628\"><span data-url=\"https://blog.kakaocdn.net/dn/0qA3T/btsH5036GkT/Lij2A8qdX4QVJVWBTJMIHk/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/0qA3T/btsH5036GkT/Lij2A8qdX4QVJVWBTJMIHk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F0qA3T%2FbtsH5036GkT%2FLij2A8qdX4QVJVWBTJMIHk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"2009358633_20240619182812_6407040536_web.jpg\" data-origin-width=\"2530\" data-origin-height=\"1628\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">삼성 스마트싱스 에너지는 에너지의 사용량을 실시간으로 알려주고 AI 절감 솔루션을 제공하는 홈 에너지 관리 서비스로 세계 97개국 601만 명이 사용하고 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>삼성 스마트싱스 에너지 서비스, 달라진 점은?</b></span></h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>AI 절약 모드</b><br />AI 절약 모드로 기기를 미리 설정해 두면, 옵션에 따라 누진 단계에 이르기 전 또는 탄소 배출이 높은 시간 등에 AI 절약 모드를 실행하여 에너지를 절약하고, AI를 통해 사용 환경이나 전기요금 체계, 사용자 편의를 고려한 월말 사용량 예측 등을 제공합니다.<br />다만 누진 단계는 국내에서만 쓸 수 있으며, 스마트싱스와 연결할 스마트 미터기는 별도 구매가 필요합니다. <br /><br /></li>\n<li><b>게임 요소 접목</b><br />에너지 모니터링 및 절약량을 환산한 점수인 에너지 등급, 스마트싱스 에너지 서비스 활동에 참여하여 모으는 활동 배지, 전력 사용량 절감 알림(DR 발령)시 절약한 전기 사용량만큼 혜택을 받는 에너지 절약 미션* 등을 도입했습니다.<br />특히 AI 절약 모드를 통해 에너지를 일일 400Wh 이상 절약한 경우, 에너지 스탬프 최대 1개를 제공하며, 7월 1일부터 에너지 스탬프 1개는 <b>삼성전자 멤버십 포인트 100점</b>으로 전환 가능합니다.<br />삼성전자 멤버십 포인트는 삼성닷컴, 전국 삼성스토어와 이마트&middot;홈플러스 등 오프라인에서도 사용할 수 있습니다.<br /><br /></li>\n</ul>\n<blockquote data-ke-style=\"style3\">*에너지 절약 미션(DR) : 전력 사용량이 많은 시간에 전력거래소나 지자체가 전력 사용량 절감을 권고하고(DR 발령) 이에 맞춰 개별 세대가 전기 사용량을 줄일 경우, 인센티브를 지급하는 제도임</blockquote>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: right;\" data-ke-size=\"size16\">(출처 : <a href=\"https://www.samsung.com/sec/\" target=\"_blank\" rel=\"noopener\">삼성전자</a>)</p>\n<p style=\"text-align: right;\" data-ke-size=\"size16\">&nbsp;</p>\n<h4 style=\"text-align: left;\" data-ke-size=\"size20\">관련 글</h4>\n<figure id=\"og_1718850677813\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"삼성 스마트싱스 제품, 지속적인 업데이트 강조하는 스마트 포워드 본격화\" data-og-description=\"삼성전자가 스마트싱스(SmartThings) 기반의 스마트 포워드(Smart Forward) 서비스를 본격화합니다.&nbsp;스마트 포워드는 정기적이고 지속적인 소프트웨어 업데이트를 제공해, 신제품이 아니더라도 최신 \" data-og-host=\"lazion.com\" data-og-source-url=\"https://lazion.com/2513650\" data-og-url=\"https://lazion.com/2513650\" data-og-image=\"https://scrap.kakaocdn.net/dn/pPtOW/hyWoJUzSdq/Kt5mjkUr5xVejdAazXR5Hk/img.jpg?width=800&amp;height=532&amp;face=326_141_403_226,https://scrap.kakaocdn.net/dn/NYWYX/hyWoI9dVQa/R7qwxh07eqKh5YKYHOHKYk/img.jpg?width=800&amp;height=532&amp;face=326_141_403_226,https://scrap.kakaocdn.net/dn/betoMh/hyWoI2szfp/AX0yDuc04G8R9rKLLhwiv1/img.jpg?width=1000&amp;height=666&amp;face=414_175_504_275\"><a href=\"https://lazion.com/2513650\" rel=\"noopener\" data-source-url=\"https://lazion.com/2513650\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/pPtOW/hyWoJUzSdq/Kt5mjkUr5xVejdAazXR5Hk/img.jpg?width=800&amp;height=532&amp;face=326_141_403_226,https://scrap.kakaocdn.net/dn/NYWYX/hyWoI9dVQa/R7qwxh07eqKh5YKYHOHKYk/img.jpg?width=800&amp;height=532&amp;face=326_141_403_226,https://scrap.kakaocdn.net/dn/betoMh/hyWoI2szfp/AX0yDuc04G8R9rKLLhwiv1/img.jpg?width=1000&amp;height=666&amp;face=414_175_504_275');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">삼성 스마트싱스 제품, 지속적인 업데이트 강조하는 스마트 포워드 본격화</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">삼성전자가 스마트싱스(SmartThings) 기반의 스마트 포워드(Smart Forward) 서비스를 본격화합니다.&nbsp;스마트 포워드는 정기적이고 지속적인 소프트웨어 업데이트를 제공해, 신제품이 아니더라도 최신</p>\n<p class=\"og-host\" data-ke-size=\"size16\">lazion.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "삼성전자가 에너지 절약 기능 중심으로 스마트싱스 에너지(SmartThings Energy) 서비스를 오늘(20일) 개편했습니다.\n \n\n\n \n삼성 스마트싱스 에너지는 에너지의 사용량을 실시간으로 알려주고 AI 절감 솔루션을 제공하는 홈 에너지 관리 서비스로 세계 97개국 601만 명이 사용하고 있습니다.\n \n삼성 스마트싱스 에너지 서비스, 달라진 점은?\n \nAI 절약 모드\nAI 절약 모드로 기기를 미리 설정해 두면, 옵션에 따라 누진 단계에 이르기 전 또는 탄소 배출이 높은 시간 등에 AI 절약 모드를 실행하여 에너지를 절약하고, AI를 통해 사용 환경이나 전기요금 체계, 사용자 편의를 고려한 월말 사용량 예측 등을 제공합니다.\n다만 누진 단계는 국내에서만 쓸 수 있으며, 스마트싱스와 연결할 스마트 미터기는 별도 구매가 필요합니다. \n\n게임 요소 접목\n에너지 모니터링 및 절약량을 환산한 점수인 에너지 등급, 스마트싱스 에너지 서비스 활동에 참여하여 모으는 활동 배지, 전력 사용량 절감 알림(DR 발령)시 절약한 전기 사용량만큼 혜택을 받는 에너지 절약 미션* 등을 도입했습니다.\n특히 AI 절약 모드를 통해 에너지를 일일 400Wh 이상 절약한 경우, 에너지 스탬프 최대 1개를 제공하며, 7월 1일부터 에너지 스탬프 1개는 삼성전자 멤버십 포인트 100점으로 전환 가능합니다.\n삼성전자 멤버십 포인트는 삼성닷컴, 전국 삼성스토어와 이마트·홈플러스 등 오프라인에서도 사용할 수 있습니다.\n\n*에너지 절약 미션(DR) : 전력 사용량이 많은 시간에 전력거래소나 지자체가 전력 사용량 절감을 권고하고(DR 발령) 이에 맞춰 개별 세대가 전기 사용량을 줄일 경우, 인센티브를 지급하는 제도임\n \n(출처 : 삼성전자)\n \n관련 글\n\n \n삼성 스마트싱스 제품, 지속적인 업데이트 강조하는 스마트 포워드 본격화\n삼성전자가 스마트싱스(SmartThings) 기반의 스마트 포워드(Smart Forward) 서비스를 본격화합니다. 스마트 포워드는 정기적이고 지속적인 소프트웨어 업데이트를 제공해, 신제품이 아니더라도 최신\nlazion.com",
        "guid": "http://lazion.com/2513706",
        "categories": [
          "#가전#음식#문화",
          "AI",
          "Ha",
          "IOT",
          "News",
          "Samsung",
          "SEC",
          "Smartthings"
        ],
        "isoDate": "2024-06-20T02:33:34.000Z"
      },
      {
        "creator": "늑돌이",
        "title": "삼성, 중저가 5G폰 갤럭시 A35 5G 한국 출시! RAM은 6GB",
        "link": "http://lazion.com/2513705",
        "pubDate": "Thu, 20 Jun 2024 10:08:12 +0900",
        "author": "늑돌이",
        "comments": "http://lazion.com/2513705#entry2513705comment",
        "content": "<p data-ke-size=\"size16\">삼성전자가 중저가 5G폰 갤럭시 A35 5G를 오는 21일 국내에 출시합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><b><span style=\"color: #006dd7;\">갤럭시 A35 5G 가격은?</span></b></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"003 - 삼성전자-모바일-갤럭시-갤럭시-A35-5G-출시-2-e1718779850889.jpg\" data-origin-width=\"1000\" data-origin-height=\"667\"><span data-url=\"https://blog.kakaocdn.net/dn/LBBgg/btsH4ATiAy1/cPXtYq6fSaxxB2KoR9rB00/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/LBBgg/btsH4ATiAy1/cPXtYq6fSaxxB2KoR9rB00/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FLBBgg%2FbtsH4ATiAy1%2FcPXtYq6fSaxxB2KoR9rB00%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"003 - 삼성전자-모바일-갤럭시-갤럭시-A35-5G-출시-2-e1718779850889.jpg\" data-origin-width=\"1000\" data-origin-height=\"667\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">국내이동통신 3사와 자급제 모델로 출시되는 <b>갤럭시 A35 5G의 가격은 49만 9,400원</b>입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>갤럭시 A35 5G 주요 특징</b></span></h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"002 - 삼성전자-모바일-갤럭시-갤럭시-A35-5G-출시-1-e1718779744456.jpg\" data-origin-width=\"1000\" data-origin-height=\"667\"><span data-url=\"https://blog.kakaocdn.net/dn/dgu6Oj/btsH5khZJfF/FJPlVxMxmfHBbeeKQktyaK/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/dgu6Oj/btsH5khZJfF/FJPlVxMxmfHBbeeKQktyaK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fdgu6Oj%2FbtsH5khZJfF%2FFJPlVxMxmfHBbeeKQktyaK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"002 - 삼성전자-모바일-갤럭시-갤럭시-A35-5G-출시-1-e1718779744456.jpg\" data-origin-width=\"1000\" data-origin-height=\"667\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">라이트 블루, 라이트 바이올렛, 블루 블랙의 3가지 색상으로 출시되는 갤럭시 A35 5G의 주요 특징은 다음과 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>디스플레이<br /><b>168.3mm(6.6형) 대화면 슈퍼 아몰레드 화면은 120Hz 고주사율</b>을 지원하며, 비전부스터로 최대 1,000니트의 밝기를 지원하고 색상 대비를 극대화해 다양한 조도 환경에서도 선명한 화질을 구현합니다. 편안하게 보기(Eye Comfort Shield)은 블루라이트를 줄여줘 눈의 피로를 최소화해줍니다.<br /><br /></li>\n<li><b>RAM은 6GB</b><br /><b>램크루지</b>라는 명성을 여전히 이어갑니다. 해외에는 RAM 8GB 모델도 있지만 우리나라에는 6GB 모델 밖에 안 나옵니다.</li>\n<li>카메라<br />후면에는 5,000만 화소의 광각 카메라를 비롯해, 800만 화소의 초광각 카메라, 500만 화소의 접사 카메라가, 전면에는 1,300만 화소 카메라가 탑재되었습니다. <br />후면 카메라에는 OIS(광학식 손떨림 보정)와 향상된 VDIS(동영상 손떨림 보정) 기능이 탑재돼 흔들림이나 움직임이 많은 상황에서도 또렷하고 매끄러운 촬영이 가능하며, 나이토그래피 기능으로 야간이나 어두운 환경에서 선명한 촬영이 가능합니다.<br /><br /></li>\n<li>배터리/저장소/방수방진<br /><b>5,000mAh의 대용량 배터리</b>를 채용하고, 최대 25W의 충전을 지원(25W 충전기 별매)합니다. <br />스토리지는 128G가 탑재됐으며, 최대 1TB의 마이크로SD 카드를 추가할 수 있습니다.<br />IP67 등급의 방수∙방진이 가능합니다.<br /><br /></li>\n<li><b>삼성월렛</b>과 삼성 녹스<br />삼성월렛을 통해 결제부터 모바일 신분증, 탑승권, 전자증명서, 쿠폰, 멤버십 등을 사용할 수 있으며 데이터를 안전하게 보호하는 삼성 녹스(Knox)도 탑재되었습니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>갤럭시 A35 5G 출시 기념 이벤트</b></span></h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"004 - 삼성전자-모바일-갤럭시-갤럭시-A35-5G-출시-3-e1718779867991.jpg\" data-origin-width=\"1000\" data-origin-height=\"667\"><span data-url=\"https://blog.kakaocdn.net/dn/Meomq/btsH6Aw4glc/qjN6rwKB2yYSauGxoQwku0/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/Meomq/btsH6Aw4glc/qjN6rwKB2yYSauGxoQwku0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FMeomq%2FbtsH6Aw4glc%2FqjN6rwKB2yYSauGxoQwku0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"004 - 삼성전자-모바일-갤럭시-갤럭시-A35-5G-출시-3-e1718779867991.jpg\" data-origin-width=\"1000\" data-origin-height=\"667\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">삼성전자는 갤럭시 A35 5G의 국내 출시를 기념해 9월 30일까지 구매 및 개통한 고객을 대상으로 윌라 3개월 무료 체험권과 추가 3개월 30% 할인권, 유튜브 프리미엄 2개월 무료 체험권과 마이크로소프트 365 베이직 6개월 체험권을 제공합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><b><span style=\"color: #006dd7;\">RAM만 8GB였다면...</span></b></h3>\n<p data-ke-size=\"size16\">RAM이 8GB였다면 추천할만한 모델인데, 6GB라니 좀 애매하네요.<br /><br /></p>\n<p data-ke-size=\"size16\">아시다시피 갈수록 스마트폰이 처리하는 일의 종류나 양이 늘어나는 만큼 대부분의 경우 RAM은 많을수록 좋습니다. 전세계 RAM 반도체 생산 1위라는 삼성전자의 이런 짠내나는 스펙 제한을 보면 많이 아쉽네요. 해외판에는 8GB 모델 선택이 가능한데 정작 우리나라에서는 선택 자체가 불가능합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<table style=\"border-collapse: collapse; width: 100%;\" border=\"1\" width=\"623\" data-ke-align=\"alignLeft\" data-ke-style=\"style12\">\n<tbody>\n<tr>\n<td style=\"width: 15%;\" colspan=\"3\"><span><span style=\"color: #ffffff;\"><b>갤럭시 A35 5G 스펙(제원/사양)<br /></b></span></span></td>\n</tr>\n<tr>\n<td style=\"width: 3.48837%;\"><b>디스플레이</b></td>\n<td style=\"width: 11.5058%;\" colspan=\"2\">6.6인치 FHD+<span><span><span><span>슈퍼 AMOLED 디스플레이 </span></span></span></span><br /><span><span><span><span>최대 120Hz 재생률 </span></span></span></span><br />비전 부스터</td>\n</tr>\n<tr>\n<td style=\"width: 3.48837%;\"><b>크기 및 무게 </b></td>\n<td style=\"width: 11.5058%;\" colspan=\"2\">161.7 x 78.0 x 8.2mm, 209g</td>\n</tr>\n<tr>\n<td style=\"width: 3.48837%;\"><b>카메라 </b></td>\n<td style=\"width: 11.5058%;\" colspan=\"2\">후면 : 8MP 초광각 카메라<span> F2.2, </span>50MP 메인 카메라<span>&middot; F1.8, AF/OIS, </span>5MP 매크로 카메라<span> F2.4 <br />전면 : 13MP 전면 카메라</span><span> F2.2</span></td>\n</tr>\n<tr>\n<td style=\"width: 3.48837%;\"><b>RAM<br /></b></td>\n<td style=\"width: 11.5058%;\" colspan=\"2\"><span><span><span><span>6GB<br /></span></span></span></span></td>\n</tr>\n<tr>\n<td style=\"width: 3.48837%;\"><b>스토리지 </b></td>\n<td colspan=\"2\"><span><span><span><span>128GB / 마이크로SD 카드<span><span><span><span>(별매)</span></span></span></span> 최대 1TB 추가 가능</span></span></span></span></td>\n</tr>\n<tr>\n<td style=\"width: 3.48837%;\"><b>배터리 </b></td>\n<td style=\"width: 11.5058%;\" colspan=\"2\">5,000mAh</td>\n</tr>\n<tr>\n<td style=\"width: 3.48837%;\"><b>OS</b></td>\n<td style=\"width: 11.5058%;\" colspan=\"2\">안드로이드 14 <br />원 UI 6.1</td>\n</tr>\n<tr>\n<td style=\"width: 3.48837%;\"><b>보안 </b></td>\n<td style=\"width: 11.5058%;\" colspan=\"2\">삼성 녹스</td>\n</tr>\n</tbody>\n</table>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: right;\" data-ke-size=\"size16\">(출처 : <a href=\"https://www.samsung.com/sec/\" target=\"_blank\" rel=\"noopener\">삼성전자</a>)</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h4 data-ke-size=\"size20\">관련 글</h4>\n<figure id=\"og_1718845888180\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"삼성 중급형 갤럭시 A55와 갤럭시 A35 발표, S24보다 더 중요?\" data-og-description=\"삼성전자 갤럭시 시리즈의 플래그십 모델은 갤럭시 S 시리즈입니다만, 실제로 많이 팔리는 모델은 더 저렴한 제품이죠. 그런 의미에서 갤럭시 A 시리즈는 삼성전자 스마트폰 판매에서 없어서는 \" data-og-host=\"lazion.com\" data-og-source-url=\"https://lazion.com/2513603\" data-og-url=\"https://lazion.com/2513603\" data-og-image=\"https://scrap.kakaocdn.net/dn/dQew0F/hyWoEFKGx3/mc24V4NDcrqdmsKhHty2u0/img.jpg?width=800&amp;height=533&amp;face=0_0_800_533,https://scrap.kakaocdn.net/dn/WMBFG/hyWoNvVzxN/aqAkF8eKKKy3Nmu86KV8O1/img.jpg?width=800&amp;height=533&amp;face=0_0_800_533,https://scrap.kakaocdn.net/dn/CsfAp/hyWoMqe4kL/Pq7vLPO0meycuWXjSyshTK/img.jpg?width=4500&amp;height=3000&amp;face=0_0_4500_3000\"><a href=\"https://lazion.com/2513603\" rel=\"noopener\" data-source-url=\"https://lazion.com/2513603\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/dQew0F/hyWoEFKGx3/mc24V4NDcrqdmsKhHty2u0/img.jpg?width=800&amp;height=533&amp;face=0_0_800_533,https://scrap.kakaocdn.net/dn/WMBFG/hyWoNvVzxN/aqAkF8eKKKy3Nmu86KV8O1/img.jpg?width=800&amp;height=533&amp;face=0_0_800_533,https://scrap.kakaocdn.net/dn/CsfAp/hyWoMqe4kL/Pq7vLPO0meycuWXjSyshTK/img.jpg?width=4500&amp;height=3000&amp;face=0_0_4500_3000');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">삼성 중급형 갤럭시 A55와 갤럭시 A35 발표, S24보다 더 중요?</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">삼성전자 갤럭시 시리즈의 플래그십 모델은 갤럭시 S 시리즈입니다만, 실제로 많이 팔리는 모델은 더 저렴한 제품이죠. 그런 의미에서 갤럭시 A 시리즈는 삼성전자 스마트폰 판매에서 없어서는</p>\n<p class=\"og-host\" data-ke-size=\"size16\">lazion.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "삼성전자가 중저가 5G폰 갤럭시 A35 5G를 오는 21일 국내에 출시합니다.\n \n갤럭시 A35 5G 가격은?\n\n\n \n국내이동통신 3사와 자급제 모델로 출시되는 갤럭시 A35 5G의 가격은 49만 9,400원입니다.\n \n \n갤럭시 A35 5G 주요 특징\n \n\n\n \n라이트 블루, 라이트 바이올렛, 블루 블랙의 3가지 색상으로 출시되는 갤럭시 A35 5G의 주요 특징은 다음과 같습니다.\n \n디스플레이\n168.3mm(6.6형) 대화면 슈퍼 아몰레드 화면은 120Hz 고주사율을 지원하며, 비전부스터로 최대 1,000니트의 밝기를 지원하고 색상 대비를 극대화해 다양한 조도 환경에서도 선명한 화질을 구현합니다. 편안하게 보기(Eye Comfort Shield)은 블루라이트를 줄여줘 눈의 피로를 최소화해줍니다.\n\nRAM은 6GB\n램크루지라는 명성을 여전히 이어갑니다. 해외에는 RAM 8GB 모델도 있지만 우리나라에는 6GB 모델 밖에 안 나옵니다.\n카메라\n후면에는 5,000만 화소의 광각 카메라를 비롯해, 800만 화소의 초광각 카메라, 500만 화소의 접사 카메라가, 전면에는 1,300만 화소 카메라가 탑재되었습니다. \n후면 카메라에는 OIS(광학식 손떨림 보정)와 향상된 VDIS(동영상 손떨림 보정) 기능이 탑재돼 흔들림이나 움직임이 많은 상황에서도 또렷하고 매끄러운 촬영이 가능하며, 나이토그래피 기능으로 야간이나 어두운 환경에서 선명한 촬영이 가능합니다.\n\n배터리/저장소/방수방진\n5,000mAh의 대용량 배터리를 채용하고, 최대 25W의 충전을 지원(25W 충전기 별매)합니다. \n스토리지는 128G가 탑재됐으며, 최대 1TB의 마이크로SD 카드를 추가할 수 있습니다.\nIP67 등급의 방수∙방진이 가능합니다.\n\n삼성월렛과 삼성 녹스\n삼성월렛을 통해 결제부터 모바일 신분증, 탑승권, 전자증명서, 쿠폰, 멤버십 등을 사용할 수 있으며 데이터를 안전하게 보호하는 삼성 녹스(Knox)도 탑재되었습니다.\n \n갤럭시 A35 5G 출시 기념 이벤트\n \n\n\n \n삼성전자는 갤럭시 A35 5G의 국내 출시를 기념해 9월 30일까지 구매 및 개통한 고객을 대상으로 윌라 3개월 무료 체험권과 추가 3개월 30% 할인권, 유튜브 프리미엄 2개월 무료 체험권과 마이크로소프트 365 베이직 6개월 체험권을 제공합니다.\n \nRAM만 8GB였다면...\nRAM이 8GB였다면 추천할만한 모델인데, 6GB라니 좀 애매하네요.\n\n아시다시피 갈수록 스마트폰이 처리하는 일의 종류나 양이 늘어나는 만큼 대부분의 경우 RAM은 많을수록 좋습니다. 전세계 RAM 반도체 생산 1위라는 삼성전자의 이런 짠내나는 스펙 제한을 보면 많이 아쉽네요. 해외판에는 8GB 모델 선택이 가능한데 정작 우리나라에서는 선택 자체가 불가능합니다.\n \n갤럭시 A35 5G 스펙(제원/사양)\n\n\n\n디스플레이\n6.6인치 FHD+슈퍼 AMOLED 디스플레이 \n최대 120Hz 재생률 \n비전 부스터\n\n\n크기 및 무게 \n161.7 x 78.0 x 8.2mm, 209g\n\n\n카메라 \n후면 : 8MP 초광각 카메라 F2.2, 50MP 메인 카메라· F1.8, AF/OIS, 5MP 매크로 카메라 F2.4 \n전면 : 13MP 전면 카메라 F2.2\n\n\nRAM\n\n6GB\n\n\n\n스토리지 \n128GB / 마이크로SD 카드(별매) 최대 1TB 추가 가능\n\n\n배터리 \n5,000mAh\n\n\nOS\n안드로이드 14 \n원 UI 6.1\n\n\n보안 \n삼성 녹스\n\n\n\n \n(출처 : 삼성전자)\n \n \n관련 글\n\n \n삼성 중급형 갤럭시 A55와 갤럭시 A35 발표, S24보다 더 중요?\n삼성전자 갤럭시 시리즈의 플래그십 모델은 갤럭시 S 시리즈입니다만, 실제로 많이 팔리는 모델은 더 저렴한 제품이죠. 그런 의미에서 갤럭시 A 시리즈는 삼성전자 스마트폰 판매에서 없어서는\nlazion.com",
        "guid": "http://lazion.com/2513705",
        "categories": [
          "#더작은모바일/#스마트폰#PDA#PMP",
          "Galaxy",
          "Galaxy A",
          "Galaxy A35 5G",
          "News",
          "Samsung",
          "SEC",
          "smartphone",
          "램크루지"
        ],
        "isoDate": "2024-06-20T01:08:12.000Z"
      },
      {
        "creator": "늑돌이",
        "title": "RISC-V 노트북? 딥컴퓨팅, 8코어&middot;우분투의 DC-ROMA RISC-V Laptop II 발표",
        "link": "http://lazion.com/2513704",
        "pubDate": "Wed, 19 Jun 2024 16:07:15 +0900",
        "author": "늑돌이",
        "comments": "http://lazion.com/2513704#entry2513704comment",
        "content": "<h3 data-ke-size=\"size23\">세계 최초로 RISC-V 아키텍처를 이용한 노트북을 내놓았던 <b>딥컴퓨팅(DeepComputing)</b>에서 그 후속으로 <b>DC-ROMA RISC-V Laptop II</b>를 내놓았습니다.</h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"DC-ROMAII_UBUNTU-DESKTOP0612-2048x1546-vert.jpg\" data-origin-width=\"1600\" data-origin-height=\"1208\"><span data-url=\"https://blog.kakaocdn.net/dn/FEho3/btsH42uua4A/KuhNYLLCSkhKOAOsId6BB0/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/FEho3/btsH42uua4A/KuhNYLLCSkhKOAOsId6BB0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FFEho3%2FbtsH42uua4A%2FKuhNYLLCSkhKOAOsId6BB0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"DC-ROMAII_UBUNTU-DESKTOP0612-2048x1546-vert.jpg\" data-origin-width=\"1600\" data-origin-height=\"1208\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>DC-ROMA RISC-V Laptop II의 특징</b></span></h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">오픈소스 아키텍처 기술로 유명한 RISC-V는 낮은 성능으로 가능한 부문 위주로 시장에 진출해 왔습니다만, 이 제품은 그냥 PC로 나왔습니다. 다만 일반인용 노트북 PC라기 보다는 개발용으로 나온 제품입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>CPU는 SpacemiT K1</b><br /><br /><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"DC-ROMA-RISC-V-Laptop-II_chip.png\" data-origin-width=\"484\" data-origin-height=\"293\"><span data-url=\"https://blog.kakaocdn.net/dn/9VO79/btsH4VPIGdg/p8MeNcAUWSBAU7apIvBD11/img.png\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/9VO79/btsH4VPIGdg/p8MeNcAUWSBAU7apIvBD11/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F9VO79%2FbtsH4VPIGdg%2Fp8MeNcAUWSBAU7apIvBD11%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"DC-ROMA-RISC-V-Laptop-II_chip.png\" data-origin-width=\"484\" data-origin-height=\"293\"/></span></figure>\n<br />DC-ROMA RISC-V Laptop II는 최대 2.0GHz로 실행되는 SpacemiT의 SoC K1을 최초로 탑재하고 나왔습니다. <br />K1은 1.5GHz에서 실행되는 전작의 4코어 SoC에 비해 성능과 에너지 효율성을 두 배로 향상시켰으며, 256비트 길이의 RISC-V 고성능 컴퓨팅 RVA 22 프로파일 RVV 1.0을 지원하고 IME 그룹 설계 원칙에 기반한 맞춤형 매트릭스 작동 명령으로 강력한 AI 퓨전 컴퓨팅 엔진(최대 2TOPS@INT)을 갖춘 세계 최초의 SoC입니다. <br /><br /></li>\n<li><b>개발용 노트북PC</b><br /><br /><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"DC-ROMA-RISC-V-Laptop-II_09.png\" data-origin-width=\"547\" data-origin-height=\"506\"><span data-url=\"https://blog.kakaocdn.net/dn/bK6KpR/btsH42nKwqN/98dITjuQNJPueQQ1boGnM1/img.png\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/bK6KpR/btsH42nKwqN/98dITjuQNJPueQQ1boGnM1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbK6KpR%2FbtsH42nKwqN%2F98dITjuQNJPueQQ1boGnM1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"DC-ROMA-RISC-V-Laptop-II_09.png\" data-origin-width=\"547\" data-origin-height=\"506\"/></span></figure>\n<br />화면은 14.1인치 풀HD 해상도의 IPS 패널이며, 올메탈 케이스로 전작 대비 나아진 내구성과 함께 열 방출 성능도 좋아졌습니다. RAM은 8/16GB 선택 가능하며 저장소는 1TB까지 제공합니다. 무게는 1.36kg에 배터리는 최대 8시간까지 사용가능합니다.<br /><br /><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"DC-ROMA-RISC-V-Laptop-II_255.png\" data-origin-width=\"1153\" data-origin-height=\"797\"><span data-url=\"https://blog.kakaocdn.net/dn/xf5Xw/btsH5Y5KAzM/kd6naOcrO2RllfnS9YGzq1/img.png\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/xf5Xw/btsH5Y5KAzM/kd6naOcrO2RllfnS9YGzq1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fxf5Xw%2FbtsH5Y5KAzM%2Fkd6naOcrO2RllfnS9YGzq1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"DC-ROMA-RISC-V-Laptop-II_255.png\" data-origin-width=\"1153\" data-origin-height=\"797\"/></span></figure>\n<br />일반적인 PC와는 다르게 개발을 주 목적으로 만들어졌기 때문에 개발용 8핀 인터페이스가 존재합니다.<br /><br /></li>\n<li><b>OS는 우분투 리눅스</b><br />리눅스 분야에서 가장 대중적인 Canonical사의 우분투(Ubuntu) 리눅스가 DC-ROMA RISC-V Laptop II로 이식되었습니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>DC-ROMA RISC-V Laptop II의 출시 일자와 가격</b></span></h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"DC-ROMA-RISC-V-Laptop-II_21.png\" data-origin-width=\"590\" data-origin-height=\"463\"><span data-url=\"https://blog.kakaocdn.net/dn/Bm7vp/btsH37Q59bO/YxJ0sLa0oT2qkWSUA7LVy1/img.png\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/Bm7vp/btsH37Q59bO/YxJ0sLa0oT2qkWSUA7LVy1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FBm7vp%2FbtsH37Q59bO%2FYxJ0sLa0oT2qkWSUA7LVy1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"DC-ROMA-RISC-V-Laptop-II_21.png\" data-origin-width=\"590\" data-origin-height=\"463\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">DC-ROMA RISC-V Laptop II는 6월 24일부터 28일까지 열리는 RISC-V Summit Europe 2024에서 처음 선보일 예정입니다. 예약판매는 6월 18일부터입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b> DC-ROMA RISC-V Laptop II의 가격은 스펙에 따라 55만1천원부터</b> 시작합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">더 자세한 내용은 <a href=\"https://deepcomputing.io/product/dc-roma-risc-v-laptop-ii/\" target=\"_blank\" rel=\"noopener\">이곳을 확인해 보시기 바랍니다.</a></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: right;\" data-ke-size=\"size16\">(자료 출처 : DeepComputing)</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "세계 최초로 RISC-V 아키텍처를 이용한 노트북을 내놓았던 딥컴퓨팅(DeepComputing)에서 그 후속으로 DC-ROMA RISC-V Laptop II를 내놓았습니다.\n \n\n\n \nDC-ROMA RISC-V Laptop II의 특징\n \n오픈소스 아키텍처 기술로 유명한 RISC-V는 낮은 성능으로 가능한 부문 위주로 시장에 진출해 왔습니다만, 이 제품은 그냥 PC로 나왔습니다. 다만 일반인용 노트북 PC라기 보다는 개발용으로 나온 제품입니다.\n \nCPU는 SpacemiT K1\n\nDC-ROMA RISC-V Laptop II는 최대 2.0GHz로 실행되는 SpacemiT의 SoC K1을 최초로 탑재하고 나왔습니다. \nK1은 1.5GHz에서 실행되는 전작의 4코어 SoC에 비해 성능과 에너지 효율성을 두 배로 향상시켰으며, 256비트 길이의 RISC-V 고성능 컴퓨팅 RVA 22 프로파일 RVV 1.0을 지원하고 IME 그룹 설계 원칙에 기반한 맞춤형 매트릭스 작동 명령으로 강력한 AI 퓨전 컴퓨팅 엔진(최대 2TOPS@INT)을 갖춘 세계 최초의 SoC입니다. \n\n개발용 노트북PC\n\n화면은 14.1인치 풀HD 해상도의 IPS 패널이며, 올메탈 케이스로 전작 대비 나아진 내구성과 함께 열 방출 성능도 좋아졌습니다. RAM은 8/16GB 선택 가능하며 저장소는 1TB까지 제공합니다. 무게는 1.36kg에 배터리는 최대 8시간까지 사용가능합니다.\n\n일반적인 PC와는 다르게 개발을 주 목적으로 만들어졌기 때문에 개발용 8핀 인터페이스가 존재합니다.\n\nOS는 우분투 리눅스\n리눅스 분야에서 가장 대중적인 Canonical사의 우분투(Ubuntu) 리눅스가 DC-ROMA RISC-V Laptop II로 이식되었습니다.\n \nDC-ROMA RISC-V Laptop II의 출시 일자와 가격\n \n\n\n \nDC-ROMA RISC-V Laptop II는 6월 24일부터 28일까지 열리는 RISC-V Summit Europe 2024에서 처음 선보일 예정입니다. 예약판매는 6월 18일부터입니다.\n \n DC-ROMA RISC-V Laptop II의 가격은 스펙에 따라 55만1천원부터 시작합니다.\n \n더 자세한 내용은 이곳을 확인해 보시기 바랍니다.\n \n(자료 출처 : DeepComputing)",
        "guid": "http://lazion.com/2513704",
        "categories": [
          "#작은PC/#노트북PC",
          "dc-roma risc-v laptop",
          "deepcomputing",
          "Laptop",
          "News",
          "PC",
          "Risc-V"
        ],
        "isoDate": "2024-06-19T07:07:15.000Z"
      },
      {
        "creator": "늑돌이",
        "title": "Adobe도, 배틀그라운드도 안 되는 삼성 갤럭시 북4 엣지(코파일럿+ PC)의 심각한 호환성 문제",
        "link": "http://lazion.com/2513703",
        "pubDate": "Tue, 18 Jun 2024 13:01:49 +0900",
        "author": "늑돌이",
        "comments": "http://lazion.com/2513703#entry2513703comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"003 - 갤럭시-북4-엣지-공개2-1024x682.jpg\" data-origin-width=\"1024\" data-origin-height=\"682\"><span data-url=\"https://blog.kakaocdn.net/dn/AyJE8/btsH1hl0oMe/2WuLvibQYilNjfnF6jNHaK/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/AyJE8/btsH1hl0oMe/2WuLvibQYilNjfnF6jNHaK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FAyJE8%2FbtsH1hl0oMe%2F2WuLvibQYilNjfnF6jNHaK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"003 - 갤럭시-북4-엣지-공개2-1024x682.jpg\" data-origin-width=\"1024\" data-origin-height=\"682\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">오늘 삼성전자가 갤럭시 북4 엣지를 대한민국에 출시했습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">문제는 이 제품이 코파일럿+ PC라는 점이고 현존하는 코파일럿+ PC는 모두 <b>인텔/AMD가 아닌 퀄컴 스냅드래곤 X 엘리트 프로세서를 탑재</b>했습니다. 당연히 호환성 문제가 생길 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">그래서 갤럭시 북4 엣지 출시 소식과 함께 <b>출시된 3종의 갤럭시 북4 엣지 시리즈 NT960XMA, NT960XMB, NT940XMA의 호환성</b>에 대한 2024년 6월 기준으로 올라온 삼성전자의 공지를 정리해 봤습니다. 아래에서 나오지 않은 경우에도 문제가 발생할 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">참고로 이러한 <b>호환성 문제는 갤럭시 북4 엣지 뿐만 아니라 비슷한 하드웨어 구성을 가진 다른 회사의 코파일럿+ PC에서도 비슷하게 생길 가능성이 높습니다.</b></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>갤럭시 북4 엣지와 호환되지 않는 애플리케이션(어플리케이션)</b> </span></h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">삼성전자가 공지한 바에 따르면 <b>다음과 같은 애플리케이션(어플리케이션) 들이 호환되지 않습니다.</b></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Firefox_Screenshot_2024-06-18T03-21-31.095Z_web.jpg\" data-origin-width=\"2094\" data-origin-height=\"1046\"><span data-url=\"https://blog.kakaocdn.net/dn/A4JOM/btsH2PV8KY6/q5sNK7fjzWH0WUBIRJcsw1/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/A4JOM/btsH2PV8KY6/q5sNK7fjzWH0WUBIRJcsw1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FA4JOM%2FbtsH2PV8KY6%2Fq5sNK7fjzWH0WUBIRJcsw1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Firefox_Screenshot_2024-06-18T03-21-31.095Z_web.jpg\" data-origin-width=\"2094\" data-origin-height=\"1046\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">안티 바이러스나 VPN은 그렇다쳐도 <b>Adobe InDesign, Adobe Illustrator, Adobe After Effects, Adobe Premiere</b> 같은 업계 대표격인 어도비 사의 디자인/영상 편집 애플리케이션이 안 되는 부분은 많이 아쉽네요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">게임에서도 <b>리그 오브 레전드(LoL), FC Online, 배틀그라운드(PUBG), 서든어택(Sudden Attack), 포트나이트(Fortnite), 데드 바이 데이라이트(Dead By Deadlight), 발로란트(Valorant), 아펙스 레전드(Apex Legends), 리니지M, 콜 오브 듀티(Call of Duty) MW3, 폴가이즈(Fall Guys), 언차티드(Uncharted), 헤일로 인피니트(Halo Inifinite), VR챗(Chat), 레전드 오브 룬테라&nbsp;</b> 등 유명한 게임 타이틀이 안 됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">여기에 더해서 블루스택이나 녹스플레이어, 구글 플레이게임, LD Player 같은 안드로이드 호환 플레이어들도 안 됩니다. 네이버 이북 리더나 네이버 마이박스도 있군요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">위에 나오지 않은 경우에도 문제가 발생할 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>갤럭시 북4 엣지와 호환되지 않는 웹사이트</b></span></h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">웹사이트 중에서도 아래 사이트 들은 갤럭시 북4 엣지에서 정상적으로 사용할 수 없습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Firefox_Screenshot_2024-06-18T03-21-07.263Z_web.jpg\" data-origin-width=\"2096\" data-origin-height=\"1232\"><span data-url=\"https://blog.kakaocdn.net/dn/o4cTf/btsH1GeLcSR/PBAZWiwelubJoEZQY3SpIk/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/o4cTf/btsH1GeLcSR/PBAZWiwelubJoEZQY3SpIk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fo4cTf%2FbtsH1GeLcSR%2FPBAZWiwelubJoEZQY3SpIk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Firefox_Screenshot_2024-06-18T03-21-07.263Z_web.jpg\" data-origin-width=\"2096\" data-origin-height=\"1232\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">BNK 경남은행, 우리카드, 현대해상, 신한투자증권, 미래에셋증권, DB금융투자, 우리은행, NH농협손해보험 웹사이트가 해당됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">위에 나오지 않은 사이트에서도 문제가 발생할 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>갤럭시 북4 엣지와 호환되지 않는 프린터 문제 해결방법</b></span></h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">갤럭시 북4 엣지는 일부 프린터와 문제를 일으킬 수 있습니다. 다음과 같은 조치를 권하고 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Firefox_Screenshot_2024-06-18T03-21-57.663Z_web.jpg\" data-origin-width=\"2118\" data-origin-height=\"1412\"><span data-url=\"https://blog.kakaocdn.net/dn/wDLST/btsH2oLsBiv/lX6yq6JeEaGKxMIloDgi4k/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/wDLST/btsH2oLsBiv/lX6yq6JeEaGKxMIloDgi4k/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FwDLST%2FbtsH2oLsBiv%2FlX6yq6JeEaGKxMIloDgi4k%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Firefox_Screenshot_2024-06-18T03-21-57.663Z_web.jpg\" data-origin-width=\"2118\" data-origin-height=\"1412\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>갤럭시 북4 엣지와 코파일럿+ PC, 호환성이라는 벽을 넘을 수 있을까?</b></span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"002 - 갤럭시-북4-엣지-공개3-e1716244829471.jpg\" data-origin-width=\"1000\" data-origin-height=\"667\"><span data-url=\"https://blog.kakaocdn.net/dn/cjU7r2/btsH3yGjIc2/DHv61aoDHoSU0Zj3KBPlBK/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/cjU7r2/btsH3yGjIc2/DHv61aoDHoSU0Zj3KBPlBK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcjU7r2%2FbtsH3yGjIc2%2FDHv61aoDHoSU0Zj3KBPlBK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"002 - 갤럭시-북4-엣지-공개3-e1716244829471.jpg\" data-origin-width=\"1000\" data-origin-height=\"667\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">이번에 삼성전자가 공지한 내용에 따르면 <b>코파일럿+ PC로서 가지는 갤럭시 북4 엣지의 호환성 문제는 결코 가벼운게 아닙니다.</b> 특히 개발사나 웹사이트 운영 업체가 본격적으로 개입하지 않으면 해결이 도저히 불가능한 것들도 보입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"color: #0593d3;\"><b> 이 정도면 <span style=\"color: #0593d3;\"><b>지금 시점에서는 </b></span>윈도우PC를 쓰겠다는 보통 사용자들에게 코파일럿+ PC는 권할 수 없을 정도입니다.</b></span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">만약 이를 모르고 구입한 이용자들이 코파일럿+ PC, 즉 퀄컴 스냅드래곤 엘리트를 담은 윈도우PC에 실망한다면 <a href=\"https://lazion.com/2513674\"><span style=\"color: #0593d3;\">마이크로소프트가 코파일럿+ PC에 담은 야망</span></a>은 큰 타격을 받겠죠.</p>\n<p data-ke-size=\"size16\">어떤 식으로든 빠른 시간 안에 해결하지 않으면 소비자들은 좋은 평가를 내리지 않을 겁니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: right;\" data-ke-size=\"size16\">(자료 출처 : <a href=\"https://www.samsung.com/sec/event/GalaxyBook4Edge/comp/\" target=\"_blank\" rel=\"noopener\">삼성전자</a>)</p>",
        "contentSnippet": "오늘 삼성전자가 갤럭시 북4 엣지를 대한민국에 출시했습니다.\n \n문제는 이 제품이 코파일럿+ PC라는 점이고 현존하는 코파일럿+ PC는 모두 인텔/AMD가 아닌 퀄컴 스냅드래곤 X 엘리트 프로세서를 탑재했습니다. 당연히 호환성 문제가 생길 수 있습니다.\n \n그래서 갤럭시 북4 엣지 출시 소식과 함께 출시된 3종의 갤럭시 북4 엣지 시리즈 NT960XMA, NT960XMB, NT940XMA의 호환성에 대한 2024년 6월 기준으로 올라온 삼성전자의 공지를 정리해 봤습니다. 아래에서 나오지 않은 경우에도 문제가 발생할 수 있습니다.\n \n참고로 이러한 호환성 문제는 갤럭시 북4 엣지 뿐만 아니라 비슷한 하드웨어 구성을 가진 다른 회사의 코파일럿+ PC에서도 비슷하게 생길 가능성이 높습니다.\n \n \n갤럭시 북4 엣지와 호환되지 않는 애플리케이션(어플리케이션) \n \n삼성전자가 공지한 바에 따르면 다음과 같은 애플리케이션(어플리케이션) 들이 호환되지 않습니다.\n \n\n\n \n안티 바이러스나 VPN은 그렇다쳐도 Adobe InDesign, Adobe Illustrator, Adobe After Effects, Adobe Premiere 같은 업계 대표격인 어도비 사의 디자인/영상 편집 애플리케이션이 안 되는 부분은 많이 아쉽네요.\n \n게임에서도 리그 오브 레전드(LoL), FC Online, 배틀그라운드(PUBG), 서든어택(Sudden Attack), 포트나이트(Fortnite), 데드 바이 데이라이트(Dead By Deadlight), 발로란트(Valorant), 아펙스 레전드(Apex Legends), 리니지M, 콜 오브 듀티(Call of Duty) MW3, 폴가이즈(Fall Guys), 언차티드(Uncharted), 헤일로 인피니트(Halo Inifinite), VR챗(Chat), 레전드 오브 룬테라  등 유명한 게임 타이틀이 안 됩니다.\n \n여기에 더해서 블루스택이나 녹스플레이어, 구글 플레이게임, LD Player 같은 안드로이드 호환 플레이어들도 안 됩니다. 네이버 이북 리더나 네이버 마이박스도 있군요.\n \n위에 나오지 않은 경우에도 문제가 발생할 수 있습니다.\n \n갤럭시 북4 엣지와 호환되지 않는 웹사이트\n \n웹사이트 중에서도 아래 사이트 들은 갤럭시 북4 엣지에서 정상적으로 사용할 수 없습니다.\n \n\n\n \nBNK 경남은행, 우리카드, 현대해상, 신한투자증권, 미래에셋증권, DB금융투자, 우리은행, NH농협손해보험 웹사이트가 해당됩니다.\n \n위에 나오지 않은 사이트에서도 문제가 발생할 수 있습니다.\n \n \n갤럭시 북4 엣지와 호환되지 않는 프린터 문제 해결방법\n \n갤럭시 북4 엣지는 일부 프린터와 문제를 일으킬 수 있습니다. 다음과 같은 조치를 권하고 있습니다.\n \n\n\n \n \n갤럭시 북4 엣지와 코파일럿+ PC, 호환성이라는 벽을 넘을 수 있을까?\n\n\n이번에 삼성전자가 공지한 내용에 따르면 코파일럿+ PC로서 가지는 갤럭시 북4 엣지의 호환성 문제는 결코 가벼운게 아닙니다. 특히 개발사나 웹사이트 운영 업체가 본격적으로 개입하지 않으면 해결이 도저히 불가능한 것들도 보입니다.\n \n 이 정도면 지금 시점에서는 윈도우PC를 쓰겠다는 보통 사용자들에게 코파일럿+ PC는 권할 수 없을 정도입니다.\n \n만약 이를 모르고 구입한 이용자들이 코파일럿+ PC, 즉 퀄컴 스냅드래곤 엘리트를 담은 윈도우PC에 실망한다면 마이크로소프트가 코파일럿+ PC에 담은 야망은 큰 타격을 받겠죠.\n어떤 식으로든 빠른 시간 안에 해결하지 않으면 소비자들은 좋은 평가를 내리지 않을 겁니다.\n \n(자료 출처 : 삼성전자)",
        "guid": "http://lazion.com/2513703",
        "categories": [
          "#작은PC/#노트북PC",
          "copliot+ pc",
          "galaxy book4 edge",
          "Laptop",
          "News",
          "PC",
          "Samsung",
          "SEC"
        ],
        "isoDate": "2024-06-18T04:01:49.000Z"
      },
      {
        "creator": "늑돌이",
        "title": "삼성 AI 코파일럿+ PC 갤럭시 북4 엣지 한국 출시! 문제는 호환성?",
        "link": "http://lazion.com/2513702",
        "pubDate": "Tue, 18 Jun 2024 12:31:42 +0900",
        "author": "늑돌이",
        "comments": "http://lazion.com/2513702#entry2513702comment",
        "content": "<h3 data-ke-size=\"size23\">삼성전자가 국내 제조사 유일의 <b>코파일럿+ PC인 갤럭시 북4 엣지</b>를 오늘(18일) 대한민국에 출시합니다.</h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"003 - 삼성전자-AI-PC-갤럭시-북4-엣지-국내-출시3_web.jpg\" data-origin-width=\"1000\" data-origin-height=\"652\"><span data-url=\"https://blog.kakaocdn.net/dn/vfYCQ/btsH12PpSR4/Ya8CXHasiJFFjJkLz59L20/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/vfYCQ/btsH12PpSR4/Ya8CXHasiJFFjJkLz59L20/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FvfYCQ%2FbtsH12PpSR4%2FYa8CXHasiJFFjJkLz59L20%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"003 - 삼성전자-AI-PC-갤럭시-북4-엣지-국내-출시3_web.jpg\" data-origin-width=\"1000\" data-origin-height=\"652\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>갤럭시 북4 엣지의 특징</b></span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"001 - 갤럭시-북4-엣지-공개1-e1716244787889.jpg\" data-origin-width=\"1000\" data-origin-height=\"667\"><span data-url=\"https://blog.kakaocdn.net/dn/DPAOx/btsH3qVPa57/LxBlHaxSLx4Ic8UPzcyTb0/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/DPAOx/btsH3qVPa57/LxBlHaxSLx4Ic8UPzcyTb0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FDPAOx%2FbtsH3qVPa57%2FLxBlHaxSLx4Ic8UPzcyTb0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"001 - 갤럭시-북4-엣지-공개1-e1716244787889.jpg\" data-origin-width=\"1000\" data-origin-height=\"667\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">갤럭시 북4 엣지는 인텔이나 AMD가 아닌 스냅드래곤 X 엘리트 프로세서를 탑재하여 마이크로소프트의 AI 서비스 브랜드인 코파일럿 서비스를 충실히 수행할 수 있는 <a href=\"https://lazion.com/2513674\" target=\"_blank\" rel=\"noopener\">코파일럿+ PC</a>입니다. 갤럭시 북4 엣지에 대해서는 라지온에서 한번 다룬 바 있으니&nbsp; 아래 링크에서 참고하시기 바랍니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<figure id=\"og_1718679158303\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"삼성, 국내 최초 코파일럿+ PC로 AI 강화된 갤럭시 북4 엣지 발표\" data-og-description=\"삼성전자가 스냅드래곤 X 엘리트와 코파일럿+ PC(Copilot+&nbsp;PC)로 하이브리드 AI를 쓸 수 있는 갤럭시 북4 엣지 노트북 PC를 공개했습니다.&nbsp;갤럭시 북4 엣지, 어떤 제품?&nbsp;갤럭시 북4 엣지는 퀄컴 스냅\" data-og-host=\"lazion.com\" data-og-source-url=\"https://lazion.com/2513673\" data-og-url=\"https://lazion.com/2513673\" data-og-image=\"https://scrap.kakaocdn.net/dn/RoOX1/hyWljQokVN/ot8akIaBocp3p8lHMmV3Xk/img.jpg?width=800&amp;height=532&amp;face=0_0_800_532,https://scrap.kakaocdn.net/dn/bsyaej/hyWldvPSUB/ek2ja6ll1SR8iaPJLStKd1/img.jpg?width=800&amp;height=532&amp;face=0_0_800_532,https://scrap.kakaocdn.net/dn/MYZJx/hyWoAXfuCb/ecFP7LMBh7h0E5hGStr2YK/img.jpg?width=1000&amp;height=1200&amp;face=0_0_1000_1200\"><a href=\"https://lazion.com/2513673\" rel=\"noopener\" data-source-url=\"https://lazion.com/2513673\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/RoOX1/hyWljQokVN/ot8akIaBocp3p8lHMmV3Xk/img.jpg?width=800&amp;height=532&amp;face=0_0_800_532,https://scrap.kakaocdn.net/dn/bsyaej/hyWldvPSUB/ek2ja6ll1SR8iaPJLStKd1/img.jpg?width=800&amp;height=532&amp;face=0_0_800_532,https://scrap.kakaocdn.net/dn/MYZJx/hyWoAXfuCb/ecFP7LMBh7h0E5hGStr2YK/img.jpg?width=1000&amp;height=1200&amp;face=0_0_1000_1200');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">삼성, 국내 최초 코파일럿+ PC로 AI 강화된 갤럭시 북4 엣지 발표</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">삼성전자가 스냅드래곤 X 엘리트와 코파일럿+ PC(Copilot+&nbsp;PC)로 하이브리드 AI를 쓸 수 있는 갤럭시 북4 엣지 노트북 PC를 공개했습니다.&nbsp;갤럭시 북4 엣지, 어떤 제품?&nbsp;갤럭시 북4 엣지는 퀄컴 스냅</p>\n<p class=\"og-host\" data-ke-size=\"size16\">lazion.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>갤럭시 북4 엣지의 종류와 가격</b></span></h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">갤럭시 북4 엣지는 프로세서와 저장소, 화면 크기에 따라 총 세가지 모델로 나오는데, 그 가격은 다음과 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>NT960XMB - 40.6cm(16형) / Snapdragon X Elite X1E-84-100 / eUFS 1TB : 265만원</li>\n<li>NT960XMA - 40.6cm(16형) / Snapdragon X Elite X1E-80-100 / eUFS 512GB : 235만원</li>\n<li>NT940XMA - 35.6cm(14형) / Snapdragon X Elite X1E-80-100 / eUFS 512GB : 215만원</li>\n</ul>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"004 - MicrosoftTeams-image-5.jpg\" data-origin-width=\"1000\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/bVTOEc/btsH1kwcCCs/H2MbiVwyZ5fSbC9UU3XGz0/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/bVTOEc/btsH1kwcCCs/H2MbiVwyZ5fSbC9UU3XGz0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbVTOEc%2FbtsH1kwcCCs%2FH2MbiVwyZ5fSbC9UU3XGz0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"004 - MicrosoftTeams-image-5.jpg\" data-origin-width=\"1000\" data-origin-height=\"1200\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>갤럭시 북4 엣지 판매 장소</b></span></h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"001 - 삼성전자-AI-PC-갤럭시-북4-엣지-국내-출시1_web.jpg\" data-origin-width=\"1000\" data-origin-height=\"666\"><span data-url=\"https://blog.kakaocdn.net/dn/buqSs7/btsH1PpbkWz/prgLtiOpPU4VhVe4f8s1nk/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/buqSs7/btsH1PpbkWz/prgLtiOpPU4VhVe4f8s1nk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbuqSs7%2FbtsH1PpbkWz%2FprgLtiOpPU4VhVe4f8s1nk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"001 - 삼성전자-AI-PC-갤럭시-북4-엣지-국내-출시1_web.jpg\" data-origin-width=\"1000\" data-origin-height=\"666\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">전국 삼성스토어, 전자랜드 등 오프라인 매장과 삼성닷컴, 11번가, G마켓 등 온라인 몰에서 구매 가능합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>갤럭시 북4 엣지 출시 기념 이벤트</b></span></h3>\n<p data-ke-size=\"size16\"><br />6월 30일까지 갤럭시 북4 엣지를 구입한 고객에게 다음과 같은 사은품을 제공합니다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>네이키드니스 브랜드 파우치</li>\n<li>MS365 퍼스널</li>\n<li>삼성케어플러스 12개월 이용권</li>\n</ul>\n<p data-ke-size=\"size16\">이 밖에도 삼성에듀, 대성마이맥, 코멘토, 다락원 등 입시∙어학∙취업의 다양한 분야 교육 콘텐츠 수강권, 굿노트 1년 이용권, 예스24 크레마 클럽 60일 이용권, 네이버 바이브 3개월 50% 할인권을 제공합니다.<br /><br />특히 기존에 사용하던 노트북을 반납하면서 갤럭시 북4 엣지를 구매할 경우 PC 브랜드와 모델에 따라 최대 25만원까지 추가 보상해주는 갤럭시 AI PC로 바꿔보상 프로그램도 운영합니다.<br /><br /></p>\n<p data-ke-size=\"size16\">참고로 <a href=\"https://www.samsung.com/sec/event/galaxy-book4-edge/launching/\" target=\"_blank\" rel=\"noopener\">삼성닷컴을 비롯해서</a> 다양한 판매처에서<b> 자체적인 할인 이벤트를 진행 중</b>이니 비교 및 확인 후 구입하시기 바랍니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>구입하기 전! 갤럭시 북4 엣지 호환성 문제 확인<br /></b></span></h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">갤럭시 북4 엣지는 현재 <a href=\"https://lazion.com/2513703\"><b>기존 윈도우 애플리케이션이나 게임들, 웹사이트, 프린터 등에 호환성 문제</b></a>가 있습니다. 아래 내용 참고하시고, 구입에 신중을 기하시기 바랍니다.</p>\n<figure id=\"og_1718683399899\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"Adobe도, 배틀그라운드도 안 되는 삼성 갤럭시 북4 엣지(코파일럿+ PC)의 심각한 호환성 문제\" data-og-description=\"오늘 삼성전자가 갤럭시 북4 엣지를 대한민국에 출시했습니다.&nbsp;문제는 이 제품이 코파일럿+ PC라는 점이고 현존하는 코파일럿+ PC는 모두 인텔/AMD가 아닌 퀄컴 스냅드래곤 엘리트 프로세서를 탑\" data-og-host=\"lazion.com\" data-og-source-url=\"https://lazion.com/2513703\" data-og-url=\"https://lazion.com/2513703\" data-og-image=\"https://scrap.kakaocdn.net/dn/Sg2IF/hyWljJA6un/m3fe73rKL4Y9ZWbbM7W0yK/img.jpg?width=800&amp;height=533&amp;face=0_0_800_533,https://scrap.kakaocdn.net/dn/BJl0W/hyWlkodAr3/cGQ7pl1obIt3U6mnCWtal1/img.jpg?width=800&amp;height=533&amp;face=0_0_800_533,https://scrap.kakaocdn.net/dn/BrkhI/hyWlaMEK0i/y5gUYMqIxEnPt2mkpEtVUk/img.jpg?width=2118&amp;height=1412&amp;face=0_0_2118_1412\"><a href=\"https://lazion.com/2513703\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://lazion.com/2513703\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/Sg2IF/hyWljJA6un/m3fe73rKL4Y9ZWbbM7W0yK/img.jpg?width=800&amp;height=533&amp;face=0_0_800_533,https://scrap.kakaocdn.net/dn/BJl0W/hyWlkodAr3/cGQ7pl1obIt3U6mnCWtal1/img.jpg?width=800&amp;height=533&amp;face=0_0_800_533,https://scrap.kakaocdn.net/dn/BrkhI/hyWlaMEK0i/y5gUYMqIxEnPt2mkpEtVUk/img.jpg?width=2118&amp;height=1412&amp;face=0_0_2118_1412');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Adobe도, 배틀그라운드도 안 되는 삼성 갤럭시 북4 엣지(코파일럿+ PC)의 심각한 호환성 문제</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">오늘 삼성전자가 갤럭시 북4 엣지를 대한민국에 출시했습니다.&nbsp;문제는 이 제품이 코파일럿+ PC라는 점이고 현존하는 코파일럿+ PC는 모두 인텔/AMD가 아닌 퀄컴 스냅드래곤 엘리트 프로세서를 탑</p>\n<p class=\"og-host\" data-ke-size=\"size16\">lazion.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: right;\" data-ke-size=\"size16\">(출처 : <a href=\"https://www.samsung.com/sec/\" target=\"_blank\" rel=\"noopener\">삼성전자</a>)</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "삼성전자가 국내 제조사 유일의 코파일럿+ PC인 갤럭시 북4 엣지를 오늘(18일) 대한민국에 출시합니다.\n \n\n\n \n갤럭시 북4 엣지의 특징\n\n\n \n갤럭시 북4 엣지는 인텔이나 AMD가 아닌 스냅드래곤 X 엘리트 프로세서를 탑재하여 마이크로소프트의 AI 서비스 브랜드인 코파일럿 서비스를 충실히 수행할 수 있는 코파일럿+ PC입니다. 갤럭시 북4 엣지에 대해서는 라지온에서 한번 다룬 바 있으니  아래 링크에서 참고하시기 바랍니다.\n \n\n \n삼성, 국내 최초 코파일럿+ PC로 AI 강화된 갤럭시 북4 엣지 발표\n삼성전자가 스냅드래곤 X 엘리트와 코파일럿+ PC(Copilot+ PC)로 하이브리드 AI를 쓸 수 있는 갤럭시 북4 엣지 노트북 PC를 공개했습니다. 갤럭시 북4 엣지, 어떤 제품? 갤럭시 북4 엣지는 퀄컴 스냅\nlazion.com\n\n \n \n갤럭시 북4 엣지의 종류와 가격\n \n갤럭시 북4 엣지는 프로세서와 저장소, 화면 크기에 따라 총 세가지 모델로 나오는데, 그 가격은 다음과 같습니다.\n \nNT960XMB - 40.6cm(16형) / Snapdragon X Elite X1E-84-100 / eUFS 1TB : 265만원\nNT960XMA - 40.6cm(16형) / Snapdragon X Elite X1E-80-100 / eUFS 512GB : 235만원\nNT940XMA - 35.6cm(14형) / Snapdragon X Elite X1E-80-100 / eUFS 512GB : 215만원\n\n\n \n \n갤럭시 북4 엣지 판매 장소\n \n\n\n \n전국 삼성스토어, 전자랜드 등 오프라인 매장과 삼성닷컴, 11번가, G마켓 등 온라인 몰에서 구매 가능합니다.\n \n \n갤럭시 북4 엣지 출시 기념 이벤트\n6월 30일까지 갤럭시 북4 엣지를 구입한 고객에게 다음과 같은 사은품을 제공합니다.\n네이키드니스 브랜드 파우치\nMS365 퍼스널\n삼성케어플러스 12개월 이용권\n이 밖에도 삼성에듀, 대성마이맥, 코멘토, 다락원 등 입시∙어학∙취업의 다양한 분야 교육 콘텐츠 수강권, 굿노트 1년 이용권, 예스24 크레마 클럽 60일 이용권, 네이버 바이브 3개월 50% 할인권을 제공합니다.\n특히 기존에 사용하던 노트북을 반납하면서 갤럭시 북4 엣지를 구매할 경우 PC 브랜드와 모델에 따라 최대 25만원까지 추가 보상해주는 갤럭시 AI PC로 바꿔보상 프로그램도 운영합니다.\n\n참고로 삼성닷컴을 비롯해서 다양한 판매처에서 자체적인 할인 이벤트를 진행 중이니 비교 및 확인 후 구입하시기 바랍니다.\n \n \n구입하기 전! 갤럭시 북4 엣지 호환성 문제 확인\n\n \n갤럭시 북4 엣지는 현재 기존 윈도우 애플리케이션이나 게임들, 웹사이트, 프린터 등에 호환성 문제가 있습니다. 아래 내용 참고하시고, 구입에 신중을 기하시기 바랍니다.\n\n \nAdobe도, 배틀그라운드도 안 되는 삼성 갤럭시 북4 엣지(코파일럿+ PC)의 심각한 호환성 문제\n오늘 삼성전자가 갤럭시 북4 엣지를 대한민국에 출시했습니다. 문제는 이 제품이 코파일럿+ PC라는 점이고 현존하는 코파일럿+ PC는 모두 인텔/AMD가 아닌 퀄컴 스냅드래곤 엘리트 프로세서를 탑\nlazion.com\n\n \n \n(출처 : 삼성전자)",
        "guid": "http://lazion.com/2513702",
        "categories": [
          "#작은PC/#노트북PC",
          "copilot+ pc",
          "galaxy book",
          "galaxy book4 edge",
          "Laptop",
          "News",
          "PC",
          "Samsung",
          "SEC"
        ],
        "isoDate": "2024-06-18T03:31:42.000Z"
      },
      {
        "creator": "늑돌이",
        "title": "니콘, 고화질&middot;고속의 풀프레임 미러리스 Z6III 카메라 발표",
        "link": "http://lazion.com/2513701",
        "pubDate": "Tue, 18 Jun 2024 10:59:04 +0900",
        "author": "늑돌이",
        "comments": "http://lazion.com/2513701#entry2513701comment",
        "content": "<h3 data-ke-size=\"size23\">일본 <b>니콘(Nikon)</b>이 2천4백5십만화소 풀프레임 미러리스 카메라 <b>Z6III</b>를 발표했습니다.</h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Z6III_24-120_4.jpg\" data-origin-width=\"1600\" data-origin-height=\"1361\"><span data-url=\"https://blog.kakaocdn.net/dn/2Aq2n/btsH1jDZykf/tPgvPyjQN1hwnIMx9LEkN1/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/2Aq2n/btsH1jDZykf/tPgvPyjQN1hwnIMx9LEkN1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F2Aq2n%2FbtsH1jDZykf%2FtPgvPyjQN1hwnIMx9LEkN1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Z6III_24-120_4.jpg\" data-origin-width=\"1600\" data-origin-height=\"1361\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">니콘 Z6III는 세계 최초로 부분적층형(Partially-Stacked) CMOS 센서를 채용했으며, EXPEED 7 이미지 처리 엔진과 결합하여 전작 Z6II 대비 리드아웃(readout) 속도가 약 3.5배 빨라졌습니다. 이를 통해 6K 내부 N-RAW 및 ProRes RAW 비디오 및 최대 240p의 Full HD 비디오 촬영이 가능하며, 프리릴리즈 캡쳐 기능으로 초당 120장의 사진 촬영도 가능합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Z6III_24-70_4_top.jpg\" data-origin-width=\"1294\" data-origin-height=\"1600\"><span data-url=\"https://blog.kakaocdn.net/dn/XwFWP/btsH3xAxOYN/jugD8x9LkdTUKi97emIYY0/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/XwFWP/btsH3xAxOYN/jugD8x9LkdTUKi97emIYY0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FXwFWP%2FbtsH3xAxOYN%2FjugD8x9LkdTUKi97emIYY0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Z6III_24-70_4_top.jpg\" data-origin-width=\"1294\" data-origin-height=\"1600\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">미러리스 카메라 가운데 가장 밝은 EVF를 자랑하며, Z8 및 Z9에서 이어받은 다중 피사체 감지 기능을 포함한 빠른 AF 시스템 또한 갖추고 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><b><span style=\"color: #006dd7;\">Nikon Z6III의 주요 특징</span></b></h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>세계 최초의 부분 적층형(Partially-Stacked) 센서<br /><br /><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Z6III_image_sensor.jpg\" data-origin-width=\"1600\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/Y1s3Y/btsH2CvTbpE/I0vJSKtc6pDWQxrH495vMk/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/Y1s3Y/btsH2CvTbpE/I0vJSKtc6pDWQxrH495vMk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FY1s3Y%2FbtsH2CvTbpE%2FI0vJSKtc6pDWQxrH495vMk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Z6III_image_sensor.jpg\" data-origin-width=\"1600\" data-origin-height=\"1200\"/></span></figure>\n<br />Z6III에 최초로 적용된 이 센서는 이미징 영역 위와 아래에 여러 개의 고속 처리 회로가 적층되어 있으며 Z8 및 Z9와 같은 EXPEED 7 처리 엔진과 결합하여 빠른 속도와 강력한 기능을 제공합니다.<br /><br /></li>\n<li>업그레이드된 AF<br />Z6II보다 최대 20% 더 빨라지고 AF 감지 범위가 -10 EV로 확장되어 어두운 상황에서도 더 쉽게 초점을 맞출 수 있습니다.<br /><br /></li>\n<li>진보한 피사체 감지<br />Z6III는 Z8 및 Z9의 기술을 활용하여 사람, 동물 및 차량을 포함한 9가지 피사체 유형을 자동으로 감지합니다. 3D 추적, 자동 영역 AF, 광역 AF, 동적 영역 AF 등 고급 AF 모드를 제공하며, 맞춤형 광역 AF 패턴으로 지정 영역 내의 피사체를 감지하고 추적할 수 있습니다.<br /><br /></li>\n<li>최대 120fps 프리릴리즈(Pre-Release) 캡처<br />새가 날아오르는 순간, 번개가 치는 순간, 게임에서 승리하는 골 등 놓칠 수 있는 장면을 찍을 수 있습니다. 셔터 버튼을 반쯤 누르면 이미지 버퍼링이 시작되며, 셔터를 끝까지 누르면 Z6III는 최대 1초 전에 촬영한 이미지를 저장합니다.<br /><br /></li>\n<li>내부 6K RAW 비디오<br />Z6III는 12비트 6K/60p N-RAW 및 6K/30p ProRes RAW, 10비트 5.4K ProRes 422 및 H.265 비디오 형식으로 촬영할 수 있습니다. <br />이를 통해 영화 제작자는 후반 작업에서 최대한의 해상도로 4K 영상 편집이 가능합니다. 또한 Z6III의 최대 비디오 해상도인 6K를 활용하여 오버샘플링된 4K UHD/60p 비디오 영상을 제작할 수 있습니다.<br />참고로 Z6III의 효율적인 방열 설계로 <b>최대 125분 동안 연속 4K UHD/60p 녹화</b>가 가능합니다.<br /><br /></li>\n<li>미러리스 카메라 중 가장 밝은 EVF<br /><br /><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Z6III_skeleton_EVF.jpg\" data-origin-width=\"1600\" data-origin-height=\"1131\"><span data-url=\"https://blog.kakaocdn.net/dn/n33lr/btsH264jwpn/qzLZGFvlZEKvhTABYWzlok/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/n33lr/btsH264jwpn/qzLZGFvlZEKvhTABYWzlok/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fn33lr%2FbtsH264jwpn%2FqzLZGFvlZEKvhTABYWzlok%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Z6III_skeleton_EVF.jpg\" data-origin-width=\"1600\" data-origin-height=\"1131\"/></span></figure>\n<br />최대 4,000cd/㎡(nits) 밝기의 Z6III의 5,760k 도트 전자 뷰파인더는 밝은 야외 상황에서도 선명하고 상세한 뷰를 제공합니다. 동급 최고의 밝기와 고해상도 외에도 Z6III의 EVF는 미러리스 카메라 중 최초로 DCI-P3에 해당하는 색 영역을 지원합니다.<br /><br /></li>\n<li>다이나믹 Full HD/240p 슬로우 모션 촬영<br />Z6III는 10비트 Full HD/240p H.265 비디오 촬영으로 최대 10배의 슬로우 모션 영상 캡처가 가능합니다.<br /><br /></li>\n<li>뛰어난 저조도 성능<br />Z6III의 넓은 기본 ISO 범위는 100-64,000(동영상 촬영시에서는 51,200)이며 초저조도 촬영을 위해 204,800까지 확장 가능합니다. Z6III의 EXPEED 7 이미지 처리 엔진은 맞춤형 노이즈 감소를 가능하게 하여 건물과 같은 피사체의 미세한 디테일을 유지하면서 이미지의 평평한 영역에서 거친 노이즈를 효과적으로 최소화합니다.<br /><br /></li>\n<li>8.0 스톱 떨림 줄임(vibration reduction)<br />내장된 5축 이미지 안정화 기능으로 최대 8.0스탑의 떨림 줄임 기능을 제공합니다. 핸드헬드 촬영시 피사체를 선명하게 유지하고 ISO를 낮추면서 느린 셔터 속도를 즐길 수 있습니다. Focus Point VR 기능이 있어 액티브 초점 포인트를 우선적으로 안정화합니다. <br /><br /></li>\n<li>회전형 LCD 화면<br /><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Z6III_24-70_4_top_tilt_monitor.jpg\" data-origin-width=\"1600\" data-origin-height=\"1302\"><span data-url=\"https://blog.kakaocdn.net/dn/qbeXe/btsH2BDKBi8/02eGiYhBZCWDhkZUr9NjG0/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/qbeXe/btsH2BDKBi8/02eGiYhBZCWDhkZUr9NjG0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FqbeXe%2FbtsH2BDKBi8%2F02eGiYhBZCWDhkZUr9NjG0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Z6III_24-70_4_top_tilt_monitor.jpg\" data-origin-width=\"1600\" data-origin-height=\"1302\"/></span></figure>\n3.2인치 후면 LCD 터치스크린은 비디오 촬영 및 셀프 촬영을 위해 전면으로 회전시킬 수 있으며 낮은 위치에서 촬영을 위해 화면 각도의 조절도 가능합니다.<br /><br /></li>\n<li>고해상도 픽셀 시프트 모드<br />픽셀 시프트 모드에서 Z6III의 센서는 4, 8, 16 또는 32 노출에 걸쳐 섬세하게 이동하여 최대 약 9600만 화소의 해상도로 색상과 디테일을 향상시킵니다.<br /><br /></li>\n<li>Z8 수준의 만듦새<br /><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Z6III_back.jpg\" data-origin-width=\"1600\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/bX0ESU/btsH279ZARC/NZ624WqRNmjTpzhQimUnh1/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/bX0ESU/btsH279ZARC/NZ624WqRNmjTpzhQimUnh1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbX0ESU%2FbtsH279ZARC%2FNZ624WqRNmjTpzhQimUnh1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Z6III_back.jpg\" data-origin-width=\"1600\" data-origin-height=\"1200\"/></span></figure>\n니콘의 플래그십 모델인 Z8 수준의 품질로 만들어진 Z6III는 마그네슘 합금과 Sereebo 소재로 제작되어 좋은 내구성과 가벼운 무게로 본체 기준 670g에 불과합니다. Z6III는 Z8과 동일한 수준으로 방진/방습 처리되어 있으며최저 14&deg;F/-10&deg;C에서 작동 가능한 등급을 받았습니다.<br /><br /></li>\n<li>Flexible Color Picture Control <br />Z6III는 NX Studio의 Flexible Color Picture Control 기능을 지원합니다. 강력한 컬러 블렌더 및 컬러 그레이딩 기능을 사용하여 카메라에 Custom Picture Control로 업로드할 수 있는 사용자 정의 사전 설정을 만들 수 있습니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>새로운 니콘 이미징 클라우드와 MB-N14 배터리 팩</b> </span></h3>\n<p data-ke-size=\"size16\"><br /><b>니콘 이미징 클라우드(NIKON IMAGING CLOUD)</b>는 Z6III 이용자를 위한 새로운 무료 클라우드 서비스입니다.</p>\n<p data-ke-size=\"size16\">카메라 설정 제안, Cloud Picture Control 사전 설정을 얻을 수 있으며, Z6III로 직업 Wi-Fi를 통해 연결하여 촬영한 사진을 NIKON IMAGE SPACE를 비롯한 다양한 클라우드 스토리지 서비스에 자동으로 업로드할 수 있습니다.</p>\n<p data-ke-size=\"size16\">니콘 이미징 클라우드와 Wi-Fi 연결하여 Z6III의 카메라 펌웨어를 최신 버전으로 업데이트할 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Z6III_sealing_front_MB-N14.jpg\" data-origin-width=\"1600\" data-origin-height=\"1131\"><span data-url=\"https://blog.kakaocdn.net/dn/UYeoi/btsH17b2fLm/kkqLT9hbpBAQXkKbD2gZfK/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/UYeoi/btsH17b2fLm/kkqLT9hbpBAQXkKbD2gZfK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FUYeoi%2FbtsH17b2fLm%2FkkqLT9hbpBAQXkKbD2gZfK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Z6III_sealing_front_MB-N14.jpg\" data-origin-width=\"1600\" data-origin-height=\"1131\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\"><br /><b>MB-N14 배터리 팩</b>은 Z6III, Z7II 및 Z6II용 셔터 버튼이 통합된 옵션 전원 배터리 팩입니다. MB-N14에는 EN-EL15c 2개를 수용할 수 있으며 약 1.9배 더 많은 사진과 비디오 촬영이 가능합니다. MB-N14는 Z6III와 동일한 방진 및 방적 기능을 제공할 뿐만 아니라 &minus;10&deg;C/14&deg;F의 추운 조건에서도 사용할 수 있습니다.</p>\n<p data-ke-size=\"size16\">MB-N14는 두 개의 배터리 중 하나를 제거해도 계속 전원을 공급하는 핫 스왑 전원 배터리 팩으로, 내장된 USB 커넥터로MB-N14가 카메라에 장착되지 않은 경우에도 MB-N14에 삽입된 배터리를 충전할 수 있습니다.<br /><br /></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>니콘 Z6III의 가격과 출시 일정</b></span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Z6III_24-70_4_fronttop.jpg\" data-origin-width=\"1600\" data-origin-height=\"1600\"><span data-url=\"https://blog.kakaocdn.net/dn/08zAF/btsH2berkPK/2ORnaegAEMIx3Gr6M2VlJK/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/08zAF/btsH2berkPK/2ORnaegAEMIx3Gr6M2VlJK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F08zAF%2FbtsH2berkPK%2F2ORnaegAEMIx3Gr6M2VlJK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Z6III_24-70_4_fronttop.jpg\" data-origin-width=\"1600\" data-origin-height=\"1600\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">새로운 <b>니콘 Z6III의 가격은 본체 기준 $2,499.95(약 345만원), NIKKOR Z 24-70mm f/4 렌즈와 포함 키트로 $3,099.95(약428만원)</b>입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Z6III_24-70_4_left.jpg\" data-origin-width=\"1600\" data-origin-height=\"1024\"><span data-url=\"https://blog.kakaocdn.net/dn/bt5Lgq/btsH2ragP4f/k6Pkk63pGM8T6az1Y5mdGk/img.jpg\" data-lightbox=\"lightbox\"><img src=\"https://blog.kakaocdn.net/dn/bt5Lgq/btsH2ragP4f/k6Pkk63pGM8T6az1Y5mdGk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbt5Lgq%2FbtsH2ragP4f%2Fk6Pkk63pGM8T6az1Y5mdGk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"Z6III_24-70_4_left.jpg\" data-origin-width=\"1600\" data-origin-height=\"1024\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\"><b>니콘 Z6III의 출시 시기는 오는 6월 말</b>로 예정되어 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">MB-N14 배터리 팩의 가격은 $359.95(약 49만7천원)이며, 올 여름 출시 예정입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: right;\" data-ke-size=\"size16\">(자료 출처 : <a href=\"https://www.nikonusa.com/\" target=\"_blank\" rel=\"noopener\">니콘</a>)</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "일본 니콘(Nikon)이 2천4백5십만화소 풀프레임 미러리스 카메라 Z6III를 발표했습니다.\n\n\n니콘 Z6III는 세계 최초로 부분적층형(Partially-Stacked) CMOS 센서를 채용했으며, EXPEED 7 이미지 처리 엔진과 결합하여 전작 Z6II 대비 리드아웃(readout) 속도가 약 3.5배 빨라졌습니다. 이를 통해 6K 내부 N-RAW 및 ProRes RAW 비디오 및 최대 240p의 Full HD 비디오 촬영이 가능하며, 프리릴리즈 캡쳐 기능으로 초당 120장의 사진 촬영도 가능합니다.\n\n\n미러리스 카메라 가운데 가장 밝은 EVF를 자랑하며, Z8 및 Z9에서 이어받은 다중 피사체 감지 기능을 포함한 빠른 AF 시스템 또한 갖추고 있습니다.\n \nNikon Z6III의 주요 특징\n \n세계 최초의 부분 적층형(Partially-Stacked) 센서\n\nZ6III에 최초로 적용된 이 센서는 이미징 영역 위와 아래에 여러 개의 고속 처리 회로가 적층되어 있으며 Z8 및 Z9와 같은 EXPEED 7 처리 엔진과 결합하여 빠른 속도와 강력한 기능을 제공합니다.\n\n업그레이드된 AF\nZ6II보다 최대 20% 더 빨라지고 AF 감지 범위가 -10 EV로 확장되어 어두운 상황에서도 더 쉽게 초점을 맞출 수 있습니다.\n\n진보한 피사체 감지\nZ6III는 Z8 및 Z9의 기술을 활용하여 사람, 동물 및 차량을 포함한 9가지 피사체 유형을 자동으로 감지합니다. 3D 추적, 자동 영역 AF, 광역 AF, 동적 영역 AF 등 고급 AF 모드를 제공하며, 맞춤형 광역 AF 패턴으로 지정 영역 내의 피사체를 감지하고 추적할 수 있습니다.\n\n최대 120fps 프리릴리즈(Pre-Release) 캡처\n새가 날아오르는 순간, 번개가 치는 순간, 게임에서 승리하는 골 등 놓칠 수 있는 장면을 찍을 수 있습니다. 셔터 버튼을 반쯤 누르면 이미지 버퍼링이 시작되며, 셔터를 끝까지 누르면 Z6III는 최대 1초 전에 촬영한 이미지를 저장합니다.\n\n내부 6K RAW 비디오\nZ6III는 12비트 6K/60p N-RAW 및 6K/30p ProRes RAW, 10비트 5.4K ProRes 422 및 H.265 비디오 형식으로 촬영할 수 있습니다. \n이를 통해 영화 제작자는 후반 작업에서 최대한의 해상도로 4K 영상 편집이 가능합니다. 또한 Z6III의 최대 비디오 해상도인 6K를 활용하여 오버샘플링된 4K UHD/60p 비디오 영상을 제작할 수 있습니다.\n참고로 Z6III의 효율적인 방열 설계로 최대 125분 동안 연속 4K UHD/60p 녹화가 가능합니다.\n\n미러리스 카메라 중 가장 밝은 EVF\n\n최대 4,000cd/㎡(nits) 밝기의 Z6III의 5,760k 도트 전자 뷰파인더는 밝은 야외 상황에서도 선명하고 상세한 뷰를 제공합니다. 동급 최고의 밝기와 고해상도 외에도 Z6III의 EVF는 미러리스 카메라 중 최초로 DCI-P3에 해당하는 색 영역을 지원합니다.\n\n다이나믹 Full HD/240p 슬로우 모션 촬영\nZ6III는 10비트 Full HD/240p H.265 비디오 촬영으로 최대 10배의 슬로우 모션 영상 캡처가 가능합니다.\n\n뛰어난 저조도 성능\nZ6III의 넓은 기본 ISO 범위는 100-64,000(동영상 촬영시에서는 51,200)이며 초저조도 촬영을 위해 204,800까지 확장 가능합니다. Z6III의 EXPEED 7 이미지 처리 엔진은 맞춤형 노이즈 감소를 가능하게 하여 건물과 같은 피사체의 미세한 디테일을 유지하면서 이미지의 평평한 영역에서 거친 노이즈를 효과적으로 최소화합니다.\n\n8.0 스톱 떨림 줄임(vibration reduction)\n내장된 5축 이미지 안정화 기능으로 최대 8.0스탑의 떨림 줄임 기능을 제공합니다. 핸드헬드 촬영시 피사체를 선명하게 유지하고 ISO를 낮추면서 느린 셔터 속도를 즐길 수 있습니다. Focus Point VR 기능이 있어 액티브 초점 포인트를 우선적으로 안정화합니다. \n\n회전형 LCD 화면\n\n3.2인치 후면 LCD 터치스크린은 비디오 촬영 및 셀프 촬영을 위해 전면으로 회전시킬 수 있으며 낮은 위치에서 촬영을 위해 화면 각도의 조절도 가능합니다.\n\n고해상도 픽셀 시프트 모드\n픽셀 시프트 모드에서 Z6III의 센서는 4, 8, 16 또는 32 노출에 걸쳐 섬세하게 이동하여 최대 약 9600만 화소의 해상도로 색상과 디테일을 향상시킵니다.\n\nZ8 수준의 만듦새\n\n니콘의 플래그십 모델인 Z8 수준의 품질로 만들어진 Z6III는 마그네슘 합금과 Sereebo 소재로 제작되어 좋은 내구성과 가벼운 무게로 본체 기준 670g에 불과합니다. Z6III는 Z8과 동일한 수준으로 방진/방습 처리되어 있으며최저 14°F/-10°C에서 작동 가능한 등급을 받았습니다.\n\nFlexible Color Picture Control \nZ6III는 NX Studio의 Flexible Color Picture Control 기능을 지원합니다. 강력한 컬러 블렌더 및 컬러 그레이딩 기능을 사용하여 카메라에 Custom Picture Control로 업로드할 수 있는 사용자 정의 사전 설정을 만들 수 있습니다.\n \n \n새로운 니콘 이미징 클라우드와 MB-N14 배터리 팩 \n니콘 이미징 클라우드(NIKON IMAGING CLOUD)는 Z6III 이용자를 위한 새로운 무료 클라우드 서비스입니다.\n카메라 설정 제안, Cloud Picture Control 사전 설정을 얻을 수 있으며, Z6III로 직업 Wi-Fi를 통해 연결하여 촬영한 사진을 NIKON IMAGE SPACE를 비롯한 다양한 클라우드 스토리지 서비스에 자동으로 업로드할 수 있습니다.\n니콘 이미징 클라우드와 Wi-Fi 연결하여 Z6III의 카메라 펌웨어를 최신 버전으로 업데이트할 수 있습니다.\n \n\n\n\nMB-N14 배터리 팩은 Z6III, Z7II 및 Z6II용 셔터 버튼이 통합된 옵션 전원 배터리 팩입니다. MB-N14에는 EN-EL15c 2개를 수용할 수 있으며 약 1.9배 더 많은 사진과 비디오 촬영이 가능합니다. MB-N14는 Z6III와 동일한 방진 및 방적 기능을 제공할 뿐만 아니라 −10°C/14°F의 추운 조건에서도 사용할 수 있습니다.\nMB-N14는 두 개의 배터리 중 하나를 제거해도 계속 전원을 공급하는 핫 스왑 전원 배터리 팩으로, 내장된 USB 커넥터로MB-N14가 카메라에 장착되지 않은 경우에도 MB-N14에 삽입된 배터리를 충전할 수 있습니다.\n\n \n니콘 Z6III의 가격과 출시 일정\n\n\n새로운 니콘 Z6III의 가격은 본체 기준 $2,499.95(약 345만원), NIKKOR Z 24-70mm f/4 렌즈와 포함 키트로 $3,099.95(약428만원)입니다.\n\n\n니콘 Z6III의 출시 시기는 오는 6월 말로 예정되어 있습니다.\n \nMB-N14 배터리 팩의 가격은 $359.95(약 49만7천원)이며, 올 여름 출시 예정입니다.\n \n(자료 출처 : 니콘)",
        "guid": "http://lazion.com/2513701",
        "categories": [
          "#카메라#녹음기",
          "Camera",
          "Mirrorless",
          "News",
          "Nikon",
          "z6iii"
        ],
        "isoDate": "2024-06-18T01:59:04.000Z"
      }
    ]
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": []
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "khris'log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": []
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Hybrid's Notes",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": [
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "결혼생활도 커리어처럼",
        "link": "https://jojoldu.tistory.com/790",
        "pubDate": "Mon, 24 Jun 2024 08:40:19 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "https://jojoldu.tistory.com/790#entry790comment",
        "content": "<p data-ke-size=\"size16\">다른 사람들이 쉽게 하거나 관심을 가지는 일상적인 것들에 대해 크게 관심이 없는 사람이라서 나 스스로가 어딘가 나사 하나가 빠져있다는 생각을 종종 한다.<br />그래서 커리어 외에 다른 것에 대해 다른 사람들의 조언을 들을때면 크게 와닿지 못하고, 갸우뚱 할 때가 자주 있었다.</p>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"6\" data-ke-size=\"size16\">결혼을 준비하면서도 앞으로의 내 결혼 생활을 어떻게 해야하나 여러 책이나 조언들을 들어도 추상적이여서 나 같이 뭔가가 부족한 사람에게는 머릿 속으로 잘 그려지지 않았다.</p>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"8\" data-ke-size=\"size16\">어떤때면 어떻게 해라 라는 조언이 들릴때면 그럼 이럴땐 어떡하지? 저럴땐 어떡하지? 등의 생각이 자연스럽게 들어서 머릿속만 더 복잡해졌다.</p>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"10\" data-ke-size=\"size16\">예전에 빈지노 &amp; 미초바 부부의 연애/결혼 생활 영상을 보면서 \"이 커플은 어떻게 이렇게 오래 만나고도 이쁘게 사랑할 수 있지?\" 라며 되게 닮고싶다는 생각을 했었다.</p>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"12\" data-ke-size=\"size16\">그러다<span>&nbsp;</span><a style=\"color: #0088cc;\" href=\"https://www.youtube.com/shorts/62tub-_q8Yo\">빈지노님의 짧은 인터뷰</a><span>&nbsp;</span>를 봤는데 \"<b>결혼 생활도 커리어처럼</b>\" 이라는 말이 너무 직관적이고 명확했다.</p>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"14\" data-ke-size=\"size16\">나한테는 구체적인 어떤 방법론들 보다도 이게 훨씬 더 선명한 방법으로 다가왔다.</p>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"16\" data-ke-size=\"size16\">감정적 순간에서도 최선의 선택을 하기 위한 노력이나<br />함께 정한 규칙을 누구보다 잘 지키기 위한 노력,<br />내가 하고 싶은 말 보다는 상대가 듣고 싶은 말을 하기 위한 노력,<br />지금 보다는 더 나은 상황을 만들기 위한 고민 등등</p>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"21\" data-ke-size=\"size16\">\"<b>커리어를 위해 내가 해왔던 노력들을 그대로 결혼생활에 이어가면 되는구나</b>\" 싶어서 나 같이 어딘가 나사 하나가 빠진 사람에게도 선명하게 느껴지는 와닿은 조언이였다.</p>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"23\" data-ke-size=\"size16\">이렇게 생각 해도 잘 할 수 있을지 어떨지는 모르겠지만,<br />커리어처럼 결혼생활도 잘 해볼 수 있겠다, 잘 해봐야겠다는 생각이 가득해졌다.</p>",
        "contentSnippet": "다른 사람들이 쉽게 하거나 관심을 가지는 일상적인 것들에 대해 크게 관심이 없는 사람이라서 나 스스로가 어딘가 나사 하나가 빠져있다는 생각을 종종 한다.\n그래서 커리어 외에 다른 것에 대해 다른 사람들의 조언을 들을때면 크게 와닿지 못하고, 갸우뚱 할 때가 자주 있었다.\n결혼을 준비하면서도 앞으로의 내 결혼 생활을 어떻게 해야하나 여러 책이나 조언들을 들어도 추상적이여서 나 같이 뭔가가 부족한 사람에게는 머릿 속으로 잘 그려지지 않았다.\n어떤때면 어떻게 해라 라는 조언이 들릴때면 그럼 이럴땐 어떡하지? 저럴땐 어떡하지? 등의 생각이 자연스럽게 들어서 머릿속만 더 복잡해졌다.\n예전에 빈지노 & 미초바 부부의 연애/결혼 생활 영상을 보면서 \"이 커플은 어떻게 이렇게 오래 만나고도 이쁘게 사랑할 수 있지?\" 라며 되게 닮고싶다는 생각을 했었다.\n그러다 빈지노님의 짧은 인터뷰 를 봤는데 \"결혼 생활도 커리어처럼\" 이라는 말이 너무 직관적이고 명확했다.\n나한테는 구체적인 어떤 방법론들 보다도 이게 훨씬 더 선명한 방법으로 다가왔다.\n감정적 순간에서도 최선의 선택을 하기 위한 노력이나\n함께 정한 규칙을 누구보다 잘 지키기 위한 노력,\n내가 하고 싶은 말 보다는 상대가 듣고 싶은 말을 하기 위한 노력,\n지금 보다는 더 나은 상황을 만들기 위한 고민 등등\n\"커리어를 위해 내가 해왔던 노력들을 그대로 결혼생활에 이어가면 되는구나\" 싶어서 나 같이 어딘가 나사 하나가 빠진 사람에게도 선명하게 느껴지는 와닿은 조언이였다.\n이렇게 생각 해도 잘 할 수 있을지 어떨지는 모르겠지만,\n커리어처럼 결혼생활도 잘 해볼 수 있겠다, 잘 해봐야겠다는 생각이 가득해졌다.",
        "guid": "https://jojoldu.tistory.com/790",
        "categories": [
          "생각정리",
          "결혼",
          "일상"
        ],
        "isoDate": "2024-06-23T23:40:19.000Z"
      },
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "[Mac] Java 21 &amp; Gradle 8 설치하기",
        "link": "https://jojoldu.tistory.com/789",
        "pubDate": "Sun, 23 Jun 2024 12:06:06 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "https://jojoldu.tistory.com/789#entry789comment",
        "content": "<p data-ke-size=\"size16\">Java 21이 2023년 9월에 출시 된지 1년이 되어가고 있고,<span>&nbsp;</span><a style=\"color: #0088cc;\" href=\"https://www.infoworld.com/article/3689880/jdk-21-the-new-features-in-java-21.html\">여러 신규 기능</a>이 패치 되었기도 하여서 개인 노트북에 JDK 21 설치를 하기로 했다.</p>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"5\" data-ke-size=\"size16\"><a style=\"color: #0088cc;\" href=\"https://whichjdk.com/ko/\">whichjdk.com</a>를 보면 크게 2가지 버전의 JDK를 추천한다.</p>\n<ul style=\"list-style-type: disc; background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"7\" data-ke-list-type=\"disc\">\n<li data-source-line=\"7\">Amazon Corretto\n<ul style=\"list-style-type: circle;\" data-source-line=\"8\" data-ke-list-type=\"circle\">\n<li data-source-line=\"8\">AWS의 Amazon Linux 2에서 Java 애플리케이션을 직접 실행하는 경우 최적화된 버전</li>\n</ul>\n</li>\n<li data-source-line=\"9\">Adoptium Eclipse Temurin\n<ul style=\"list-style-type: circle;\" data-source-line=\"10\" data-ke-list-type=\"circle\">\n<li data-source-line=\"10\">오픈 소스 소프트웨어에 대한 리소스와 전문 거버넌스 모델을 제공하는 Eclipse 재단 산하의 최상위 프로젝트</li>\n<li data-source-line=\"11\">Red Hat, IBM, Microsoft, Azul, iJUG 등 Java 기술에 전략적 관심을 갖고 있는 주요 기업 및 조직으로 구성</li>\n<li data-source-line=\"12\">이전의 AdoptOpenJDK 프로젝트는 Eclipse Adoptium으로 이전됨</li>\n</ul>\n</li>\n</ul>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"14\" data-ke-size=\"size16\">현재 여러 팀에서도 대부분 이 중 하나로 선택해서 사용중이다.</p>\n<ul style=\"list-style-type: disc; background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"16\" data-ke-list-type=\"disc\">\n<li data-source-line=\"16\"><a style=\"color: #0088cc;\" href=\"https://www.facebook.com/jojoldu/posts/pfbid0woHLzFSoaYwom5HNEfSYFtDsythkiQdkqakKpxJLC92w1dBn5dQyDpZPVJgk9uUMl?notif_id=1718758810997688&amp;notif_t=feedback_reaction_generic&amp;ref=notif\">(페이스북) 다들 개발팀 로컬 PC는 JDK 어느것들을 사용하시나요?</a></li>\n<li data-source-line=\"17\"><a style=\"color: #0088cc;\" href=\"https://twitter.com/jojoldu/status/1803228699225104577\">(트위터) 다들 개발팀 로컬 PC는 JDK 어느것들을 사용하시나요?</a></li>\n</ul>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"19\" data-ke-size=\"size16\">온프레미스 기반의 회사에서는 당연하게도 Temurin을 사용중이고, AWS를 사용중인 팀에서도 요즘 같이 컨테이너 환경에서는 특정 클라우드 벤더사의 JDK만 써야하는 제약이 있지 않다보니 Temurin을 사용하는 경우가 많다.</p>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"21\" data-ke-size=\"size16\">이 글에서도 속한 회사의 인프라 환경에 크게 제약을 받지 않는 오픈소스인 Temurin 21 로 설치를 진행한다.</p>\n<h3 id=\"adoptium-eclipse-temurin-21-설치\" style=\"background-color: #ffffff; color: #000000; text-align: start;\" data-source-line=\"23\" data-ke-size=\"size23\">Adoptium Eclipse Temurin 21 설치</h3>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"25\" data-ke-size=\"size16\">(설치 안되어있다면)<span>&nbsp;</span>cask<span>&nbsp;</span>를 설치하고</p>\n<pre class=\"mipsasm\" style=\"background-color: #f5f5f5; color: #333333; text-align: left;\" data-source-line=\"27\" data-info=\"bash {data-source-line=&quot;27&quot;}\" data-role=\"codeBlock\"><code>brew install cask\n</code></pre>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"31\" data-ke-size=\"size16\"><b>Temurin 21 설치</b>한다.</p>\n<pre class=\"angelscript\" style=\"background-color: #f5f5f5; color: #333333; text-align: left;\" data-source-line=\"33\" data-info=\"bash {data-source-line=&quot;33&quot;}\" data-role=\"codeBlock\"><code>brew install --cask temurin@21\n</code></pre>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"37\" data-ke-size=\"size16\">설치가 완료되면 잘 설치되어있는지 확인해본다.</p>\n<pre class=\"angelscript\" style=\"background-color: #f5f5f5; color: #333333; text-align: left;\" data-source-line=\"39\" data-info=\"bash {data-source-line=&quot;39&quot;}\" data-role=\"codeBlock\"><code>$ java --version\nopenjdk 21.0.3 2024-04-16 LTS\nOpenJDK Runtime Environment Temurin-21.0.3+9 (build 21.0.3+9-LTS)\nOpenJDK 64-Bit Server VM Temurin-21.0.3+9 (build 21.0.3+9-LTS, mixed mode)\n</code></pre>\n<h3 id=\"jenv-설치\" style=\"background-color: #ffffff; color: #000000; text-align: start;\" data-source-line=\"46\" data-ke-size=\"size23\">jenv 설치</h3>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"48\" data-ke-size=\"size16\">정상혁님의<span>&nbsp;</span><a style=\"color: #0088cc;\" href=\"https://blog.benelog.net/installing-jdk\">\"여러 개의 JDK를 설치하고 선택해서 사용하기\"</a>을 보면 여러 JDK 버전 관리 도구들에 대한 소개가 나온다.</p>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"50\" data-ke-size=\"size16\">SDKMAN 의 경우 JDK 설치까지 편하게 사용 가능하지만, 버전 변경에 대해 불편한 점이 많다.<br />반면<span>&nbsp;</span><b>jenv는 JDK 설치는 수동으로 진행해야하지만, 그 이후 버전 관리에 대해서는 다양하고 편리하게</b><span>&nbsp;</span>사용할 수 있어 여기서는<span>&nbsp;</span><a style=\"color: #0088cc;\" href=\"https://www.jenv.be/\">jenv</a><span>&nbsp;</span>로 진행한다.</p>\n<pre class=\"mipsasm\" style=\"background-color: #f5f5f5; color: #333333; text-align: left;\" data-source-line=\"53\" data-info=\"bash {data-source-line=&quot;53&quot;}\" data-role=\"codeBlock\"><code>$ brew install jenv\n</code></pre>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"57\" data-ke-size=\"size16\">설치된 jenv 를 등록하기 위해<span>&nbsp;</span>~/.bashrc<span>&nbsp;</span>또는<span>&nbsp;</span>~/.bash_profile<span>&nbsp;</span>혹은<span>&nbsp;</span>~/.zsh에 아래 내용을 추가한다.</p>\n<pre class=\"routeros\" style=\"background-color: #f5f5f5; color: #333333; text-align: left;\" data-source-line=\"59\" data-info=\"bash {data-source-line=&quot;59&quot;}\" data-role=\"codeBlock\"><code>export PATH=\"$HOME/.jenv/bin:$PATH\"\neval \"$(jenv init -)\"\n</code></pre>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"64\" data-ke-size=\"size16\">아래와 같이 직접 명령어를 수행해서 추가해도 된다.</p>\n<pre class=\"jboss-cli\" style=\"background-color: #f5f5f5; color: #333333; text-align: left;\" data-source-line=\"66\" data-info=\"bash {data-source-line=&quot;66&quot;}\" data-role=\"codeBlock\"><code>$ echo 'export PATH=\"$HOME/.jenv/bin:$PATH\"' &gt;&gt; ~/.zshrc\n$ echo 'eval \"$(jenv init -)\"' &gt;&gt; ~/.zshrc\n</code></pre>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"71\" data-ke-size=\"size16\">아래 명령어들도 차례로 수행한다.</p>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"73\" data-ke-size=\"size16\"><b>Enable the export plugin</b></p>\n<pre class=\"shell\" style=\"background-color: #f5f5f5; color: #333333; text-align: left;\" data-source-line=\"75\" data-info=\"bash {data-source-line=&quot;75&quot;}\" data-role=\"codeBlock\"><code>$ eval \"$(jenv init -)\"\n$ jenv enable-plugin export\n</code></pre>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"80\" data-ke-size=\"size16\"><b>Restart your shell</b></p>\n<pre class=\"shell\" style=\"background-color: #f5f5f5; color: #333333; text-align: left;\" data-source-line=\"82\" data-info=\"bash {data-source-line=&quot;82&quot;}\" data-role=\"codeBlock\"><code>$ exec $SHELL -l\n</code></pre>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"86\" data-ke-size=\"size16\">jenv 설정이 완료되었다면, 위에서 설치한 temurin21 JDK를 jenv에 등록한다.</p>\n<pre class=\"awk\" style=\"background-color: #f5f5f5; color: #333333; text-align: left;\" data-source-line=\"88\" data-info=\"bash {data-source-line=&quot;88&quot;}\" data-role=\"codeBlock\"><code>$ jenv add /Library/Java/JavaVirtualMachines/temurin-21.jdk/Contents/Home\n</code></pre>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"92\" data-ke-size=\"size16\">jenv에 잘 등록되었는지 확인해본다.</p>\n<pre class=\"routeros\" style=\"background-color: #f5f5f5; color: #333333; text-align: left;\" data-source-line=\"94\" data-info=\"bash {data-source-line=&quot;94&quot;}\" data-role=\"codeBlock\"><code>$ jenv versions\n* system (set by /Users/jojoldu/.jenv/version)\n  21\n  21.0\n  21.0.3\n  temurin64-21.0.3\n</code></pre>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"103\" data-ke-size=\"size16\">JAVA_HOME에도 jenv 로 설정된 버전을 인식할 수 있도록 아래 명령어로 글로벌 JDK 버전을 변경한다.</p>\n<pre class=\"angelscript\" style=\"background-color: #f5f5f5; color: #333333; text-align: left;\" data-source-line=\"105\" data-info=\"bash {data-source-line=&quot;105&quot;}\" data-role=\"codeBlock\"><code>$ jenv global 21.0.3\n</code></pre>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"109\" data-ke-size=\"size16\">(이걸 하지 않으면 Gradle 등에서 JAVA_HOME 인식을 하지 못한다.)</p>\n<h2 id=\"gradle-8-설치\" style=\"background-color: #ffffff; color: #000000; text-align: start;\" data-source-line=\"111\" data-ke-size=\"size26\">Gradle 8 설치</h2>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"113\" data-ke-size=\"size16\">sdkman은 JDK 외에도 여러 JVM 진영의 도구들을 설치, 관리하기 편리한 도구이다.<br />그래서 Gradle 은<span>&nbsp;</span><a style=\"color: #0088cc;\" href=\"https://sdkman.io/install\">sdkman</a>을 통해 진행한다.</p>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"116\" data-ke-size=\"size16\">먼저 sdkman 을 설치한다.</p>\n<pre class=\"shell\" style=\"background-color: #f5f5f5; color: #333333; text-align: left;\" data-source-line=\"118\" data-info=\"bash {data-source-line=&quot;118&quot;}\" data-role=\"codeBlock\"><code>$ curl -s \"https://get.sdkman.io\" | bash\n$ source \"$HOME/.sdkman/bin/sdkman-init.sh\"\n</code></pre>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"123\" data-ke-size=\"size16\">설치된 sdkman 을 통해 Gradle 최신 버전을 설치한다.</p>\n<pre class=\"angelscript\" style=\"background-color: #f5f5f5; color: #333333; text-align: left;\" data-source-line=\"125\" data-info=\"bash {data-source-line=&quot;125&quot;}\" data-role=\"codeBlock\"><code>$ sdk install gradle 8.8\n</code></pre>\n<p style=\"background-color: #ffffff; color: #333333; text-align: start;\" data-source-line=\"129\" data-ke-size=\"size16\">잘 설치되었는지 아래 명령어로 gradle 버전을 확인해본다.</p>\n<pre class=\"yaml\" style=\"background-color: #f5f5f5; color: #333333; text-align: left;\" data-source-line=\"131\" data-info=\"bash {data-source-line=&quot;131&quot;}\" data-role=\"codeBlock\"><code>$ gradle -v\n------------------------------------------------------------\nGradle 8.8\n------------------------------------------------------------\n\nBuild time:   2024-05-31 21:46:56 UTC\nRevision:     4bd1b3d3fc3f31db5a26eecb416a165b8cc36082\n\nKotlin:       1.9.22\nGroovy:       3.0.21\nAnt:          Apache Ant(TM) version 1.10.13 compiled on January 4 2023\nJVM:          21.0.3 (Eclipse Adoptium 21.0.3+9-LTS)\nOS:           Mac OS X 14.1.2 aarch64</code></pre>",
        "contentSnippet": "Java 21이 2023년 9월에 출시 된지 1년이 되어가고 있고, 여러 신규 기능이 패치 되었기도 하여서 개인 노트북에 JDK 21 설치를 하기로 했다.\nwhichjdk.com를 보면 크게 2가지 버전의 JDK를 추천한다.\nAmazon Corretto\n\nAWS의 Amazon Linux 2에서 Java 애플리케이션을 직접 실행하는 경우 최적화된 버전\nAdoptium Eclipse Temurin\n\n오픈 소스 소프트웨어에 대한 리소스와 전문 거버넌스 모델을 제공하는 Eclipse 재단 산하의 최상위 프로젝트\nRed Hat, IBM, Microsoft, Azul, iJUG 등 Java 기술에 전략적 관심을 갖고 있는 주요 기업 및 조직으로 구성\n이전의 AdoptOpenJDK 프로젝트는 Eclipse Adoptium으로 이전됨\n현재 여러 팀에서도 대부분 이 중 하나로 선택해서 사용중이다.\n(페이스북) 다들 개발팀 로컬 PC는 JDK 어느것들을 사용하시나요?\n(트위터) 다들 개발팀 로컬 PC는 JDK 어느것들을 사용하시나요?\n온프레미스 기반의 회사에서는 당연하게도 Temurin을 사용중이고, AWS를 사용중인 팀에서도 요즘 같이 컨테이너 환경에서는 특정 클라우드 벤더사의 JDK만 써야하는 제약이 있지 않다보니 Temurin을 사용하는 경우가 많다.\n이 글에서도 속한 회사의 인프라 환경에 크게 제약을 받지 않는 오픈소스인 Temurin 21 로 설치를 진행한다.\nAdoptium Eclipse Temurin 21 설치\n(설치 안되어있다면) cask 를 설치하고\nbrew install cask\n\nTemurin 21 설치한다.\nbrew install --cask temurin@21\n\n설치가 완료되면 잘 설치되어있는지 확인해본다.\n$ java --version\nopenjdk 21.0.3 2024-04-16 LTS\nOpenJDK Runtime Environment Temurin-21.0.3+9 (build 21.0.3+9-LTS)\nOpenJDK 64-Bit Server VM Temurin-21.0.3+9 (build 21.0.3+9-LTS, mixed mode)\n\njenv 설치\n정상혁님의 \"여러 개의 JDK를 설치하고 선택해서 사용하기\"을 보면 여러 JDK 버전 관리 도구들에 대한 소개가 나온다.\nSDKMAN 의 경우 JDK 설치까지 편하게 사용 가능하지만, 버전 변경에 대해 불편한 점이 많다.\n반면 jenv는 JDK 설치는 수동으로 진행해야하지만, 그 이후 버전 관리에 대해서는 다양하고 편리하게 사용할 수 있어 여기서는 jenv 로 진행한다.\n$ brew install jenv\n\n설치된 jenv 를 등록하기 위해 ~/.bashrc 또는 ~/.bash_profile 혹은 ~/.zsh에 아래 내용을 추가한다.\nexport PATH=\"$HOME/.jenv/bin:$PATH\"\neval \"$(jenv init -)\"\n\n아래와 같이 직접 명령어를 수행해서 추가해도 된다.\n$ echo 'export PATH=\"$HOME/.jenv/bin:$PATH\"' >> ~/.zshrc\n$ echo 'eval \"$(jenv init -)\"' >> ~/.zshrc\n\n아래 명령어들도 차례로 수행한다.\nEnable the export plugin\n$ eval \"$(jenv init -)\"\n$ jenv enable-plugin export\n\nRestart your shell\n$ exec $SHELL -l\n\njenv 설정이 완료되었다면, 위에서 설치한 temurin21 JDK를 jenv에 등록한다.\n$ jenv add /Library/Java/JavaVirtualMachines/temurin-21.jdk/Contents/Home\n\njenv에 잘 등록되었는지 확인해본다.\n$ jenv versions\n* system (set by /Users/jojoldu/.jenv/version)\n  21\n  21.0\n  21.0.3\n  temurin64-21.0.3\n\nJAVA_HOME에도 jenv 로 설정된 버전을 인식할 수 있도록 아래 명령어로 글로벌 JDK 버전을 변경한다.\n$ jenv global 21.0.3\n\n(이걸 하지 않으면 Gradle 등에서 JAVA_HOME 인식을 하지 못한다.)\nGradle 8 설치\nsdkman은 JDK 외에도 여러 JVM 진영의 도구들을 설치, 관리하기 편리한 도구이다.\n그래서 Gradle 은 sdkman을 통해 진행한다.\n먼저 sdkman 을 설치한다.\n$ curl -s \"https://get.sdkman.io\" | bash\n$ source \"$HOME/.sdkman/bin/sdkman-init.sh\"\n\n설치된 sdkman 을 통해 Gradle 최신 버전을 설치한다.\n$ sdk install gradle 8.8\n\n잘 설치되었는지 아래 명령어로 gradle 버전을 확인해본다.\n$ gradle -v\n------------------------------------------------------------\nGradle 8.8\n------------------------------------------------------------\n\nBuild time:   2024-05-31 21:46:56 UTC\nRevision:     4bd1b3d3fc3f31db5a26eecb416a165b8cc36082\n\nKotlin:       1.9.22\nGroovy:       3.0.21\nAnt:          Apache Ant(TM) version 1.10.13 compiled on January 4 2023\nJVM:          21.0.3 (Eclipse Adoptium 21.0.3+9-LTS)\nOS:           Mac OS X 14.1.2 aarch64",
        "guid": "https://jojoldu.tistory.com/789",
        "categories": [
          "개발환경",
          "adoptium eclipse temurin",
          "amazon corretto",
          "gradle",
          "java 21",
          "jdk 21",
          "개발환경"
        ],
        "isoDate": "2024-06-23T03:06:06.000Z"
      },
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "[PostgreSQL] 단일 테이블 컬럼을 최대한 활용하기",
        "link": "https://jojoldu.tistory.com/788",
        "pubDate": "Tue, 18 Jun 2024 10:00:41 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "https://jojoldu.tistory.com/788#entry788comment",
        "content": "<blockquote data-ke-style=\"style1\"><p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Serif KR';\"><p><strong>PostgreSQL 14</strong> 에서 진행되었다.</p>\n</span></p></blockquote><p>간혹 쿼리들을 보면 단일 테이블 (<code>from 테이블</code>)의 컬럼으로 모든 <strong>조회 조건이 완성</strong> 가능한데, <code>join 테이블</code> 의 조건을 함께 사용하여 성능 저하를 일으키는 경우가 종종 있다.</p>\n<p>데이터가 몇개 없을때는 큰 차이를 못 느끼지만, 수십만건 이상이 적재된 여러 테이블을 중첩 Join 할 경우 큰 차이가 느껴지게 된다.<br>이를 비교해보자.</p>\n<h2>문제</h2>\n<p>아래의 쿼리는 <code>review</code> 테이블과 연관된 여러 테이블의 정보를 모으고, 이를 페이징 처리하여 제공해야하는 기능이다.</p>\n<pre><code>select *\nfrom &quot;review&quot; as review\nleft join &quot;users&quot; as &quot;user&quot; on review.&quot;user_id&quot; = &quot;user&quot;.&quot;id&quot;\nleft join &quot;courses&quot; as course on review.&quot;course_id&quot; = course.&quot;id&quot;\nleft join &quot;files&quot; as file on course.&quot;cover_file&quot; = file.&quot;id&quot;\nwhere review.&quot;type&quot; = ?\n  and review.&quot;status&quot; = ?\n  and review.&quot;content&quot; is not null\n  and course.&quot;id&quot; in (?)\norder by review.&quot;id&quot; + 0 desc\nlimit 10 offset 20;</code></pre><p>이 쿼리의 특이점은 <code>where ~ and course.&quot;id&quot; in (?)</code> 이다.<br><code>left join</code>의 대상인 <code>courses</code> 의 컬럼을 사용하여 조회 조건에 포함시킨 것이다.</p>\n<p>이 쿼리의 실행 계획은 다음과 같다.</p>\n<pre><code>Limit  (cost=1554.48..1554.50 rows=10 width=4845) (actual time=189.062..189.067 rows=10 loops=1)\n  -&gt;  Sort  (cost=1554.43..1555.11 rows=275 width=4845) (actual time=189.057..189.064 rows=30 loops=1)\n        Sort Key: ((review.id + 0)) DESC\n        Sort Method: top-N heapsort  Memory: 273kB\n        -&gt;  Nested Loop Left Join  (cost=1.56..1546.30 rows=275 width=4845) (actual time=0.105..136.710 rows=25047 loops=1)\n              -&gt;  Nested Loop  (cost=1.13..1313.55 rows=275 width=4174) (actual time=0.085..28.784 rows=25047 loops=1)\n                    -&gt;  Nested Loop Left Join  (cost=0.71..95.53 rows=19 width=3944) (actual time=0.029..0.363 rows=19 loops=1)\n                          -&gt;  Index Scan using courses_pkey on courses course  (cost=0.29..45.32 rows=19 width=2810) (actual time=0.014..0.158 rows=19 loops=1)\n&quot;                                Index Cond: (id = ANY (&#39;{?,?,?,?,?}&#39;::integer[]))&quot;\n                          -&gt;  Index Scan using files_pkey on files file  (cost=0.42..2.64 rows=1 width=1134) (actual time=0.006..0.006 rows=1 loops=19)\n                                Index Cond: (id = course.cover_file)\n                    -&gt;  Index Scan using idx_review_2 on review  (cost=0.42..63.50 rows=61 width=230) (actual time=0.023..1.093 rows=1318 loops=19)\n                          Index Cond: (course_id = course.id)\n                          Filter: ((content IS NOT NULL) AND ((type)::text = &#39;COURSE_REVIEW&#39;::text) AND ((status)::text = &#39;PUBLIC&#39;::text))\n                          Rows Removed by Filter: 40\n&quot;              -&gt;  Index Scan using users_pkey on users &quot;&quot;user&quot;&quot;  (cost=0.43..0.84 rows=1 width=663) (actual time=0.003..0.003 rows=1 loops=25047)&quot;\n                    Index Cond: (id = review.user_id)\nPlanning Time: 0.852 ms\nExecution Time: 189.201 ms</code></pre><p>189ms가 느린 것은 아니지만, 각 테이블들의 크기에 비해 만족스럽지 못하다.<br>여러 중첩 조인과 선 필터, PostgreSQL 14의 Memoize 등 성능 효과를 전혀 보지 못하고 있다.<br>이를 개선해보자.</p>\n<h2>해결</h2>\n<p>위 쿼리를 자세히 살펴보면 <code>left join &quot;courses&quot; as course on review.&quot;course_id&quot; = course.&quot;id&quot;</code> 와 <code>where ~ and course.&quot;id&quot; in (?)</code> 를 통해 <code>courses.id</code>와 <code>review.course_id</code>가 동일한 값임을 알 수 있다.</p>\n<p>즉, <strong>굳이 Join 테이블인 courses가 없어도 조회 조건이 완성 가능</strong>하다.<br>이를 통해 <strong>Join 전에 필터링을 먼저 수행한 후 조인을 하여 성능 개선</strong>을 할 수 있다.</p>\n<pre><code>select *\nfrom &quot;review&quot; as review\nleft join &quot;users&quot; as &quot;user&quot; on review.&quot;user_id&quot; = &quot;user&quot;.&quot;id&quot;\nleft join &quot;courses&quot; as course on review.&quot;course_id&quot; = course.&quot;id&quot;\nleft join &quot;files&quot; as file on course.&quot;cover_file&quot; = file.&quot;id&quot;\nwhere review.&quot;type&quot; = ?\n  and review.&quot;status&quot; = ?\n  and review.&quot;content&quot; is not null\n  and review.&quot;course_id&quot; in (?)\norder by review.&quot;id&quot; + 0 desc\nlimit 10 offset 20;</code></pre><p>아래와 같이 한 줄의 쿼리만 변경되었다.</p>\n<ul>\n<li><code>where ~ and course.&quot;id&quot; in (?)</code> -&gt; <code>where ~ and review.&quot;course_id&quot; in (?)</code> 로 변경</li>\n</ul>\n<p>이에 대한 실행 계획은 다음과 같다.</p>\n<pre><code>Limit  (cost=14642.94..14662.08 rows=10 width=4845) (actual time=15.138..17.700 rows=10 loops=1)\n  -&gt;  Nested Loop Left Join  (cost=14604.67..63642.32 rows=25627 width=4845) (actual time=14.706..17.696 rows=30 loops=1)\n        -&gt;  Nested Loop Left Join  (cost=14604.24..54240.69 rows=25627 width=3703) (actual time=14.676..17.538 rows=30 loops=1)\n              -&gt;  Nested Loop Left Join  (cost=14603.94..51735.94 rows=25627 width=893) (actual time=14.645..17.345 rows=30 loops=1)\n                    -&gt;  Gather Merge  (cost=14603.50..17635.34 rows=25627 width=230) (actual time=14.599..17.062 rows=30 loops=1)\n                          Workers Planned: 3\n                          Workers Launched: 3\n                          -&gt;  Sort  (cost=13603.46..13624.13 rows=8267 width=230) (actual time=11.147..11.166 rows=143 loops=4)\n                                Sort Key: ((review.id + 0)) DESC\n                                Sort Method: quicksort  Memory: 3360kB\n                                Worker 0:  Sort Method: quicksort  Memory: 2501kB\n                                Worker 1:  Sort Method: quicksort  Memory: 2931kB\n                                Worker 2:  Sort Method: quicksort  Memory: 3130kB\n                                -&gt;  Parallel Bitmap Heap Scan on review  (cost=308.21..13065.56 rows=8267 width=230) (actual time=0.599..7.222 rows=6262 loops=4)\n&quot;                                      Recheck Cond: (course_id = ANY (&#39;{?,?,?,?,?}&#39;::integer[]))&quot;\n                                      Filter: ((content IS NOT NULL) AND ((type)::text = &#39;COURSE_REVIEW&#39;::text) AND ((status)::text = &#39;PUBLIC&#39;::text))\n                                      Rows Removed by Filter: 191\n                                      Heap Blocks: exact=1838\n                                      -&gt;  Bitmap Index Scan on idx_review_2  (cost=0.00..301.75 rows=26405 width=0) (actual time=1.512..1.513 rows=25850 loops=1)\n&quot;                                            Index Cond: (course_id = ANY (&#39;{?,?,?,?,?}&#39;::integer[]))&quot;\n                    -&gt;  Memoize  (cost=0.44..1.61 rows=1 width=663) (actual time=0.009..0.009 rows=1 loops=30)\n                          Cache Key: review.user_id\n                          Cache Mode: logical\n                          Hits: 3  Misses: 27  Evictions: 0  Overflows: 0  Memory Usage: 10kB\n&quot;                          -&gt;  Index Scan using users_pkey on users &quot;&quot;user&quot;&quot;  (cost=0.43..1.60 rows=1 width=663) (actual time=0.007..0.007 rows=1 loops=27)&quot;\n                                Index Cond: (id = review.user_id)\n              -&gt;  Memoize  (cost=0.30..0.75 rows=1 width=2810) (actual time=0.005..0.005 rows=1 loops=30)\n                    Cache Key: review.course_id\n                    Cache Mode: logical\n                    Hits: 16  Misses: 14  Evictions: 0  Overflows: 0  Memory Usage: 26kB\n                    -&gt;  Index Scan using courses_pkey on courses course  (cost=0.29..0.74 rows=1 width=2810) (actual time=0.006..0.006 rows=1 loops=14)\n                          Index Cond: (id = review.course_id)\n        -&gt;  Memoize  (cost=0.43..1.78 rows=1 width=1134) (actual time=0.004..0.004 rows=1 loops=30)\n              Cache Key: course.cover_file\n              Cache Mode: logical\n              Hits: 16  Misses: 14  Evictions: 0  Overflows: 0  Memory Usage: 12kB\n              -&gt;  Index Scan using files_pkey on files file  (cost=0.42..1.77 rows=1 width=1134) (actual time=0.005..0.005 rows=1 loops=14)\n                    Index Cond: (id = course.cover_file)\nPlanning Time: 0.876 ms\nExecution Time: 18.506 ms</code></pre><p>단일 테이블로 선 필터링을 하게 되어 <strong>Join 대상이 줄어듬</strong>과 동시에 <a href=\"https://jojoldu.tistory.com/700\">Memoize</a> 등 캐시 효과도 볼 수 있게 되었다.</p>\n<p>189ms → 18 ms로 <strong>대략 1,000% 성능 개선</strong>이 되었다.</p>\n<h2>마무리</h2>\n<p>복잡한 쿼리를 작성하다보면 나도 모르게 여러 테이블의 컬럼을 활용하여 조건문을 완성할때가 있다.<br>Join의 조건을 보고 단일 테이블의 컬럼을 최대한 활용할 수 있다면 이를 최대한 활용하자.</p>",
        "contentSnippet": "PostgreSQL 14 에서 진행되었다.\n\n간혹 쿼리들을 보면 단일 테이블 (from 테이블)의 컬럼으로 모든 조회 조건이 완성 가능한데, join 테이블 의 조건을 함께 사용하여 성능 저하를 일으키는 경우가 종종 있다.\n데이터가 몇개 없을때는 큰 차이를 못 느끼지만, 수십만건 이상이 적재된 여러 테이블을 중첩 Join 할 경우 큰 차이가 느껴지게 된다.\n이를 비교해보자.\n문제\n아래의 쿼리는 review 테이블과 연관된 여러 테이블의 정보를 모으고, 이를 페이징 처리하여 제공해야하는 기능이다.\nselect *\nfrom \"review\" as review\nleft join \"users\" as \"user\" on review.\"user_id\" = \"user\".\"id\"\nleft join \"courses\" as course on review.\"course_id\" = course.\"id\"\nleft join \"files\" as file on course.\"cover_file\" = file.\"id\"\nwhere review.\"type\" = ?\n  and review.\"status\" = ?\n  and review.\"content\" is not null\n  and course.\"id\" in (?)\norder by review.\"id\" + 0 desc\nlimit 10 offset 20;\n이 쿼리의 특이점은 where ~ and course.\"id\" in (?) 이다.\nleft join의 대상인 courses 의 컬럼을 사용하여 조회 조건에 포함시킨 것이다.\n이 쿼리의 실행 계획은 다음과 같다.\nLimit  (cost=1554.48..1554.50 rows=10 width=4845) (actual time=189.062..189.067 rows=10 loops=1)\n  ->  Sort  (cost=1554.43..1555.11 rows=275 width=4845) (actual time=189.057..189.064 rows=30 loops=1)\n        Sort Key: ((review.id + 0)) DESC\n        Sort Method: top-N heapsort  Memory: 273kB\n        ->  Nested Loop Left Join  (cost=1.56..1546.30 rows=275 width=4845) (actual time=0.105..136.710 rows=25047 loops=1)\n              ->  Nested Loop  (cost=1.13..1313.55 rows=275 width=4174) (actual time=0.085..28.784 rows=25047 loops=1)\n                    ->  Nested Loop Left Join  (cost=0.71..95.53 rows=19 width=3944) (actual time=0.029..0.363 rows=19 loops=1)\n                          ->  Index Scan using courses_pkey on courses course  (cost=0.29..45.32 rows=19 width=2810) (actual time=0.014..0.158 rows=19 loops=1)\n\"                                Index Cond: (id = ANY ('{?,?,?,?,?}'::integer[]))\"\n                          ->  Index Scan using files_pkey on files file  (cost=0.42..2.64 rows=1 width=1134) (actual time=0.006..0.006 rows=1 loops=19)\n                                Index Cond: (id = course.cover_file)\n                    ->  Index Scan using idx_review_2 on review  (cost=0.42..63.50 rows=61 width=230) (actual time=0.023..1.093 rows=1318 loops=19)\n                          Index Cond: (course_id = course.id)\n                          Filter: ((content IS NOT NULL) AND ((type)::text = 'COURSE_REVIEW'::text) AND ((status)::text = 'PUBLIC'::text))\n                          Rows Removed by Filter: 40\n\"              ->  Index Scan using users_pkey on users \"\"user\"\"  (cost=0.43..0.84 rows=1 width=663) (actual time=0.003..0.003 rows=1 loops=25047)\"\n                    Index Cond: (id = review.user_id)\nPlanning Time: 0.852 ms\nExecution Time: 189.201 ms\n189ms가 느린 것은 아니지만, 각 테이블들의 크기에 비해 만족스럽지 못하다.\n여러 중첩 조인과 선 필터, PostgreSQL 14의 Memoize 등 성능 효과를 전혀 보지 못하고 있다.\n이를 개선해보자.\n해결\n위 쿼리를 자세히 살펴보면 left join \"courses\" as course on review.\"course_id\" = course.\"id\" 와 where ~ and course.\"id\" in (?) 를 통해 courses.id와 review.course_id가 동일한 값임을 알 수 있다.\n즉, 굳이 Join 테이블인 courses가 없어도 조회 조건이 완성 가능하다.\n이를 통해 Join 전에 필터링을 먼저 수행한 후 조인을 하여 성능 개선을 할 수 있다.\nselect *\nfrom \"review\" as review\nleft join \"users\" as \"user\" on review.\"user_id\" = \"user\".\"id\"\nleft join \"courses\" as course on review.\"course_id\" = course.\"id\"\nleft join \"files\" as file on course.\"cover_file\" = file.\"id\"\nwhere review.\"type\" = ?\n  and review.\"status\" = ?\n  and review.\"content\" is not null\n  and review.\"course_id\" in (?)\norder by review.\"id\" + 0 desc\nlimit 10 offset 20;\n아래와 같이 한 줄의 쿼리만 변경되었다.\nwhere ~ and course.\"id\" in (?) -> where ~ and review.\"course_id\" in (?) 로 변경\n이에 대한 실행 계획은 다음과 같다.\nLimit  (cost=14642.94..14662.08 rows=10 width=4845) (actual time=15.138..17.700 rows=10 loops=1)\n  ->  Nested Loop Left Join  (cost=14604.67..63642.32 rows=25627 width=4845) (actual time=14.706..17.696 rows=30 loops=1)\n        ->  Nested Loop Left Join  (cost=14604.24..54240.69 rows=25627 width=3703) (actual time=14.676..17.538 rows=30 loops=1)\n              ->  Nested Loop Left Join  (cost=14603.94..51735.94 rows=25627 width=893) (actual time=14.645..17.345 rows=30 loops=1)\n                    ->  Gather Merge  (cost=14603.50..17635.34 rows=25627 width=230) (actual time=14.599..17.062 rows=30 loops=1)\n                          Workers Planned: 3\n                          Workers Launched: 3\n                          ->  Sort  (cost=13603.46..13624.13 rows=8267 width=230) (actual time=11.147..11.166 rows=143 loops=4)\n                                Sort Key: ((review.id + 0)) DESC\n                                Sort Method: quicksort  Memory: 3360kB\n                                Worker 0:  Sort Method: quicksort  Memory: 2501kB\n                                Worker 1:  Sort Method: quicksort  Memory: 2931kB\n                                Worker 2:  Sort Method: quicksort  Memory: 3130kB\n                                ->  Parallel Bitmap Heap Scan on review  (cost=308.21..13065.56 rows=8267 width=230) (actual time=0.599..7.222 rows=6262 loops=4)\n\"                                      Recheck Cond: (course_id = ANY ('{?,?,?,?,?}'::integer[]))\"\n                                      Filter: ((content IS NOT NULL) AND ((type)::text = 'COURSE_REVIEW'::text) AND ((status)::text = 'PUBLIC'::text))\n                                      Rows Removed by Filter: 191\n                                      Heap Blocks: exact=1838\n                                      ->  Bitmap Index Scan on idx_review_2  (cost=0.00..301.75 rows=26405 width=0) (actual time=1.512..1.513 rows=25850 loops=1)\n\"                                            Index Cond: (course_id = ANY ('{?,?,?,?,?}'::integer[]))\"\n                    ->  Memoize  (cost=0.44..1.61 rows=1 width=663) (actual time=0.009..0.009 rows=1 loops=30)\n                          Cache Key: review.user_id\n                          Cache Mode: logical\n                          Hits: 3  Misses: 27  Evictions: 0  Overflows: 0  Memory Usage: 10kB\n\"                          ->  Index Scan using users_pkey on users \"\"user\"\"  (cost=0.43..1.60 rows=1 width=663) (actual time=0.007..0.007 rows=1 loops=27)\"\n                                Index Cond: (id = review.user_id)\n              ->  Memoize  (cost=0.30..0.75 rows=1 width=2810) (actual time=0.005..0.005 rows=1 loops=30)\n                    Cache Key: review.course_id\n                    Cache Mode: logical\n                    Hits: 16  Misses: 14  Evictions: 0  Overflows: 0  Memory Usage: 26kB\n                    ->  Index Scan using courses_pkey on courses course  (cost=0.29..0.74 rows=1 width=2810) (actual time=0.006..0.006 rows=1 loops=14)\n                          Index Cond: (id = review.course_id)\n        ->  Memoize  (cost=0.43..1.78 rows=1 width=1134) (actual time=0.004..0.004 rows=1 loops=30)\n              Cache Key: course.cover_file\n              Cache Mode: logical\n              Hits: 16  Misses: 14  Evictions: 0  Overflows: 0  Memory Usage: 12kB\n              ->  Index Scan using files_pkey on files file  (cost=0.42..1.77 rows=1 width=1134) (actual time=0.005..0.005 rows=1 loops=14)\n                    Index Cond: (id = course.cover_file)\nPlanning Time: 0.876 ms\nExecution Time: 18.506 ms\n단일 테이블로 선 필터링을 하게 되어 Join 대상이 줄어듬과 동시에 Memoize 등 캐시 효과도 볼 수 있게 되었다.\n189ms → 18 ms로 대략 1,000% 성능 개선이 되었다.\n마무리\n복잡한 쿼리를 작성하다보면 나도 모르게 여러 테이블의 컬럼을 활용하여 조건문을 완성할때가 있다.\nJoin의 조건을 보고 단일 테이블의 컬럼을 최대한 활용할 수 있다면 이를 최대한 활용하자.",
        "guid": "https://jojoldu.tistory.com/788",
        "categories": [
          "Database",
          "PostgreSQL",
          "RDBMS",
          "데이터베이스 튜닝",
          "성능 튜닝",
          "쿼리 튜닝"
        ],
        "isoDate": "2024-06-18T01:00:41.000Z"
      }
    ]
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "한상곤 - Sigmadream",
    "category": "개인",
    "posts": [
      {
        "creator": "Sangkon Han",
        "title": "내 맘대로 위클리 뉴스 - 2024년 24주(2024.06.16 - 2024.06.22)",
        "link": "https://www.sangkon.com/sigmadream_weekly_2024_24-2/",
        "pubDate": "Sat, 22 Jun 2024 19:16:00 GMT",
        "content:encodedSnippet": "Python\nHow to Move From pandas to Polars\n\n요즘 각광받는 Polars와 기존에 많이 사용하는 Pandas에 대한 기사 입니다.\nJavaScript\nBuild a drag and drop to-do list\n칸반 스타일의 할 일을 간략하게 실습해 볼 수 있는 튜토리얼 기사입니다.\nReact 19 – New Hooks Explained with Examples\nReact 19에 도입되는 4가지 새로운 Hooks에 대해서 간략하게 소개하는 기사 입니다.\nOOP\nThe Pitfalls of Comparing BigDecimals in Java\n\nBigDecimal을 사용하실 때 참고하세요.\nEtc\nA Beautiful and Timely Python Multi-page Streamlit Application\nStarting and Stopping uvicorn in the Background\nBUILDING A BLUESKY ITALIAN ART BOT\nParsing Python ASTs 20x Faster with Rust\nBuilding Generative AI apps with .NET 8\nUsing PostgreSQL with .NET and Entra ID",
        "dc:creator": "Sangkon Han",
        "content": "<h2 id=\"python\">Python</h2>\n<ul>\n<li><a href=\"https://blog.jetbrains.com/pycharm/2024/06/how-to-move-from-pandas-to-polars/?ref=sangkon.com\">How to Move From pandas to Polars</a>\n<ul>\n<li>&#xC694;&#xC998; &#xAC01;&#xAD11;&#xBC1B;&#xB294; <code>Polars</code>&#xC640; &#xAE30;&#xC874;&#xC5D0; &#xB9CE;&#xC774; &#xC0AC;&#xC6A9;&#xD558;&#xB294; <code>Pandas</code>&#xC5D0; &#xB300;&#xD55C; &#xAE30;&#xC0AC; &#xC785;&#xB2C8;&#xB2E4;.</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"javascript\">JavaScript</h2>\n<ul>\n<li>\n<p><a href=\"https://reactpractice.dev/exercise/build-a-drag-and-drop-to-do-list/?ref=sangkon.com\">Build a drag and drop to-do list</a></p>\n<ul>\n<li>&#xCE78;&#xBC18; &#xC2A4;&#xD0C0;&#xC77C;&#xC758; &#xD560; &#xC77C;</li></ul></li></ul>",
        "contentSnippet": "Python\nHow to Move From pandas to Polars\n\n요즘 각광받는 Polars와 기존에 많이 사용하는 Pandas에 대한 기사 입니다.\nJavaScript\nBuild a drag and drop to-do list\n칸반 스타일의 할 일",
        "guid": "6678748f4d836e346732ccc5",
        "categories": [
          "주간 뉴스"
        ],
        "isoDate": "2024-06-22T19:16:00.000Z"
      }
    ]
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "오픈챗 해시태그 예측을 위한 다중 레이블 분류 모델 개발하기",
        "link": "https://techblog.lycorp.co.jp/ko/multi-label-classification-model-for-openchat-hashtag-prediction",
        "pubDate": "Wed, 19 Jun 2024 02:00:00 GMT",
        "content": "들어가며\n안녕하세요. AI Services Lab 팀의 ML 엔지니어 박희웅입니다. 저희 팀에서는 오픈챗과 관련된 다양한 AI/ML 모델을 개발해 서빙하고 있는데요. 앞서 오프라인...",
        "contentSnippet": "들어가며\n안녕하세요. AI Services Lab 팀의 ML 엔지니어 박희웅입니다. 저희 팀에서는 오픈챗과 관련된 다양한 AI/ML 모델을 개발해 서빙하고 있는데요. 앞서 오프라인...",
        "guid": "https://techblog.lycorp.co.jp/ko/multi-label-classification-model-for-openchat-hashtag-prediction",
        "isoDate": "2024-06-19T02:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": [
      {
        "title": "보이스피싱 애플리케이션 분석 2부",
        "link": "https://meetup.nhncloud.com/posts/383",
        "pubDate": "Tue, 18 Jun 2024 06:37:08 GMT",
        "content": "![NHN Cloud_meetup banner_voicefishing_202406-02-01.png](https://image.toast.com/aaaadh/alpha/2024/techblog/NHN%20Cloudmeetup%20bannervoicefishing2024060201.png)\r\r\n\r\r\n# 들어가며\r\r\n\r\r\n안녕하세요. NHN Cloud 서비스보안팀 지우중입니다.\r\r\n많은 분들이 보이스피싱 애플리케이션 분석 1부를 재밌고 흥미롭게 읽어주셔서 빠르게 2부를 준비했습니다.\r\r\n보이스피싱 애플리케이션 분석 2부에서는 보이스 피싱 애플리케이션에서 어떤 데이터를 C&C서버(*Command & Control Server: 해커가 공격을 수행하기 위해 제어하는 서버*)로 보내는지, 피해자 단말기에서는 어떤 일이 일어나는지 알아보겠습니다.\r\r\n또한, 보이스피싱 애플리케이션의 핵심인 전화 가로채기, 오디오 도청, 위치 추적(GPS), 불법 촬영, SMS 탈취에 대한 분석 내용을 공유하려고 합니다.\r\r\n그럼, 바로 보이스피싱 애플리케이션 분석 2부 시작하겠습니다!\r\r\n\r\r\n***\r\r\n\r\r\n# 피해자 단말기 등록\r\r\n\r\r\n먼저, 결론부터 말씀드리자면 보이스피싱 애플리케이션에서는 피해자 단말기에서 지속적인 모니터링 및 제어 등을 하기 위해 피해자 단말기를 등록하는 과정이 필요합니다.\r\r\n보이스피싱 애플리케이션을 설치한 후 실행하자마자 발생하는 패킷[[1]](https://developer.mozilla.org/ko/docs/Glossary/Packet)을 분석하면, 서버에 피해자의 단말기 정보를 전송하면서 등록 절차를 완료하는 것을 확인할 수 있습니다.\r\r\n이 과정에서 피해자의 전화번호, 통신사, 단말기 정보 등이 포함된 데이터가 전송되는 것을 확인할 수 있었습니다.\r\r\n피해자 단말기를 등록하는 패킷은 아래와 같이 POST 형식으로 [http://137.220.230.51/17](http://137.220.230.51/17) 으로 postVal이라는 값을 전송하는 것을 볼 수 있습니다.\r\r\n![1.png](https://image.toast.com/aaaadh/alpha/2024/techblog/1%281%29.png)\r\r\n\r\r\n패킷 내용을 보시면 postVal의 값은 평문이 아닌 알 수 없는 값을 C&C 서버로 전송하는 걸 알 수 있습니다.\r\r\n하지만 분석하는 입장에서는 정확히 postVal의 값이 어떤 내용인지 알아야 합니다.\r\r\n그 이유는 보이스피싱 범죄자들 입장에서는 postVal 값이 어떤 목적으로 서버로 보내는지 알고 있겠지만 분석하는 입장에서는 평문의 postVal 값을 알아야만 애플리케이션을 실행하자마자 postVal 값을 서버로 보내는 이유를 추측할 수 있기 때문입니다.<br>\r\r\n따라서 postVal 값이 어떻게 생성되는지 그 위치를 찾을 필요가 있습니다.\r\r\n분석한 결과, 아래의 코드가 해당 패킷을 생성하는 코드로 확인되었습니다.\r\r\n![2.png](https://image.toast.com/aaaadh/alpha/2024/techblog/2.png)\r\r\n위의 코드에서 ①번을 자세히 살펴보겠습니다.\r\r\n![3.png](https://image.toast.com/aaaadh/alpha/2024/techblog/3.png)\r\r\nreqBody란 request 패킷의 body 부분을 의미합니다.\r\r\n즉, 서버로 요청하는 실제 데이터가 존재하는 영역이라고 생각하시면 됩니다.\r\r\n코드를 분석하면, s5라는 값은 ②번에서 만들어지며 s4는 ③번에서 만들어지는 것을 알 수 있습니다.\r\r\n③번을 통해서 서버로 보낼 데이터의 형식은 JSON[[2]](https://namu.wiki/w/JSON)으로 보내는 것을 확인할 수 있으며 변수 s4의 값은 아래의 `a.b()` 메서드에서 반환된 값을 의미합니다.\r\r\n![4.png](https://image.toast.com/aaaadh/alpha/2024/techblog/4.png)\r\r\n따라서 변수 s4의 값을 확인하기 위해서는 `a.b()` 메서드를 살펴볼 필요가 있습니다.\r\r\n![5.png](https://image.toast.com/aaaadh/alpha/2024/techblog/5.png)\r\r\n`a.b()` 메서드를 확인한 결과, AES/CBC/PKCS5Padding[[3]](https://namu.wiki/w/AES) 알고리즘을 사용하며 key는 \"rb!nBwXv4C%Gr^84\", IV[[4]](https://ko.wikipedia.org/wiki/%EC%B4%88%EA%B8%B0%ED%99%94_%EB%B2%A1%ED%84%B0)값은 \"1234567812345678\"을 사용하는 것을 확인할 수 있습니다.\r\r\n즉, 어떤 값을 암호화하여 최종적으로 Base64 인코딩[[5]](https://ko.wikipedia.org/wiki/%EB%B2%A0%EC%9D%B4%EC%8A%A464)을 수행한 후 반환하고 있는 것을 알 수 있습니다.\r\r\n따라서 암호화를 수행하기 전 평문값을 알 수 있다면 보이스피싱 범죄자들에게 어떤 데이터를 보내는지 알 수 있습니다.\r\r\n여기에는 2가지 방법이 있습니다.\r\r\n첫 번째로는 `a.b()` 메서드를 후킹(*프로그램에서 구성 요소 간에 발생하는 함수 호출, 메시지, 이벤트 등을 중간에서 바꾸거나 가로채는 명령, 방법, 기술이나 행위*)하여 cleartext라는 인자값을 출력하는 방법과 두 번째로는 암호화된 값을 복호화하는 방법이 있습니다. 위의 그림에서 보셨다시피 암호화 과정에 사용한 암호화 알고리즘은 AES 암호화로 대표적인 대칭키 암호화 알고리즘입니다.\r\r\n대칭키 암호화의 가장 큰 특징은 암호화와 복호화를 할 때 사용하는 Key와 IV 값이 같다는 점입니다.\r\r\n따라서 Key와 IV 값이 노출되었기 때문에 두 번째 방법을 이용하면 다음과 같이 평문의 데이터를 확인할 수 있습니다.\r\r\n![6.png](https://image.toast.com/aaaadh/alpha/2024/techblog/6.png)\r\r\n위의 값을 추측해 보면 app_id는 보이스피싱 애플리케이션을 만든 조직에서 부여한 값인 것으로 추측됩니다.\r\r\npid 값은 해당 단말기의 Google 계정과 관련된 값으로 보이며 나머지 값은 피해자 단말기의 정보라고 보시면 됩니다.\r\r\n여기서 왜 app_id가 17이지? 라는 생각이 들 수도 있는데요.\r\r\n보이스피싱 범죄자들은 1개의 보이스피싱 애플리케이션을 만드는 것이 아니라 조직적으로 대량의 악성 애플리케이션을 만듭니다.\r\r\n쉽게 예를 들자면, 보이스피싱 애플리케이션 및 악성 애플리케이션 100개를 만들어 배포한 후 app_id가 없으면 관리적인 측면에서 어떤 악성 애플리케이션에서 요청한 패킷인지 관리하기가 힘들어집니다.\r\r\n![7.png](https://image.toast.com/aaaadh/alpha/2024/techblog/7.png)\r\r\n따라서 위의 그림처럼 각 애플리케이션에 app_id를 부여한 후 app_id 번호에 맞게 서버를 구성한다든지, 피해자들을 속이기 위한 보이스피싱 시나리오 등 관리 및 기타 목적으로 app_id를 부여한 것으로 추측됩니다.\r\r\n범죄자들은 자신의 서버에서 피해자가 자신들이 만든 보이스피싱 애플리케이션이 설치된 후 단말기 등록 패킷을 기다린 후 app_id와 휴대폰 번호(p_no) 등을 보고 자신들이 정한 시나리오 및 목적에 따라 피해자들을 속이기 시작합니다.\r\r\n즉, 빠르게 피해자들을 속이기 위해 필요한 데이터라고 생각해 주시면 될 것 같습니다.\r\r\n여기서 말하는 시나리오란 아래의 영상을 참고하시면 쉽게 이해가 될 것 같습니다.\r\r\n>  [영상 바로 가기](https://www.youtube.com/watch?v=eapWmmBFK6s&t=533)\r\r\n\r\r\n하지만 분석 과정에서 단말기 등록 패킷이 발생한 후 C&C 서버에서는 아무런 응답이 오지 않았는데요.\r\r\n그 이유는 보이스피싱 조직들은 C&C 서버를 일정 기간 운영한 후 이전 및 폐쇄하는 경향이 있는데 현재 분석하는 보이스피싱 애플리케이션의 C&C 서버도 마찬가지로 이전 및 폐쇄한 것으로 보입니다.\r\r\n사실 이 부분이 분석하는 과정에서 가장 아쉬운 부분이었습니다.<br>\r\r\n실제로 동작하는 C&C 서버였다면 실시간으로 데이터를 주고받으면서 정확하게 분석할 수 있었지만 이렇게 서버와의 통신이 없다면 사실 완벽한 분석은 어렵다고 볼 수 있습니다.\r\r\n하지만 최대한 해당 보이스피싱 애플리케이션의 특징을 분석해 보고자 노력하였습니다.\r\r\n\r\r\n# 화면 분석\r\r\n\r\r\n## 1. APK 추가 설치\r\r\n\r\r\n분석 당시 저는 'C&C 서버에서 응답이 없어 이제 어떻게 분석을 진행해야 하지?' 라는 생각과 함께 아래의 애플리케이션 첫 화면을 보면서 고민에 빠져있었습니다.\r\r\n\r\r\n![8.png](https://image.toast.com/aaaadh/alpha/2024/techblog/8.png)\r\r\n고민하던 도중 '잠시만.. C&C 서버에서 응답이 없었는데 지금 내가 보고 있는 화면은 뭐지? 어디서 보내준 거지?' 라는 생각이 문득 들었습니다. 그래서 바로 다시 네트워크 패킷을 분석하였습니다.\r\r\n하지만 어떤 패킷에서도 해당 화면에 대한 데이터는 존재하지 않았습니다. 통신 구간이 아니면 남아 있는 것은 APK 파일밖에 없습니다.\r\r\n그래서 다시 APK 파일을 추가로 분석하였습니다.\r\r\nAPK 파일을 분석하던 도중 assets 디렉토리에 다음과 같은 파일이 존재했습니다.\r\r\n![9.png](https://image.toast.com/aaaadh/alpha/2024/techblog/9.png)\r\r\nassets 디렉토리에 존재하는 MP3 파일을 재생해 보면 금융 위원회, 검찰청 민원 상담실, 금감원 콜센터에 전화하면 들리는 안내 음성 파일들이었습니다.\r\r\n위의 MP3 파일은 전화 가로채기 수법에 활용되며 피해자를 속이기 위한 파일임을 추측할 수 있었습니다.\r\r\n또한 MP3 파일 이외 plbFhm.apk, uSBxbR.apk 파일이 존재했습니다.\r\r\n이는 해당 보이스피싱 애플리케이션에서 사용하고 있는 또 다른 APK 파일이라는 것을 확인할 수 있었는데요.\r\r\n하지만 마지막으로 남은 tspTFl.sz 파일은 어떤 파일인지 알 수 없었습니다.\r\r\n주로 `.sz` 확장자는 압축된 파일 형식 중 하나입니다.\r\r\n압축된 파일이 맞는지 확인하기 위해 Hex Editor로 해당 파일을 열어 보았습니다.\r\r\n![10.png](https://image.toast.com/aaaadh/alpha/2024/techblog/10%281%29.png)\r\r\n다행스럽게도 PK 파일 포맷[[7]](https://namu.wiki/w/%ED%8C%8C%EC%9D%BC%20%EC%8B%9C%EA%B7%B8%EB%8B%88%EC%B2%98)으로 되어있는 것을 확인하였으며 파일 자체로는 암호화가 되어있지 않았습니다.\r\r\n이 tspTFl.sz 파일을 열어보기 위해 확장자를 `. zip`으로 변경 후 파일을 열어보았습니다.\r\r\n![11.png](https://image.toast.com/aaaadh/alpha/2024/techblog/11%281%29.png)\r\r\n열어본 결과 html 파일과 js 폴더, 알 수 없는 폴더가 존재하였습니다.\r\r\n어떤 파일인지 분석을 진행하기 위해 압축 풀기를 수행하였지만, 다음과 같이 패스워드가 설정되어 있었습니다.\r\r\n![12.png](https://image.toast.com/aaaadh/alpha/2024/techblog/12.png)\r\r\n\r\r\n패스워드가 설정된 것으로 보아, 중요한 파일인 것 같았는데요.\r\r\n이 패스워드를 분석하기 위해 APK 파일 분석을 진행하였습니다.\r\r\n분석한 결과, 아래의 그림처럼 패스워드는 `\"s********a\"`로 하드코딩 되어 있었으며 발견된 패스워드로 압축 파일을 해제할 수 있었습니다.\r\r\n![13.png](https://image.toast.com/aaaadh/alpha/2024/techblog/13.png)\r\r\n압축이 풀린 html 파일을 열어보면 애플리케이션의 첫 화면인 것을 알 수 있었습니다.\r\r\n![14.png](https://image.toast.com/aaaadh/alpha/2024/techblog/14.png)\r\r\n위의 결과로 C&C 서버에서 화면 데이터를 받아오지 않아도 첫 화면을 볼 수 있었던 이유를 알아냈습니다.\r\r\n또한 ivrvyeuimagesivrvyeu 디렉토리에는 상담원으로 예상되는 사진 파일(도용된 사진으로 추측됩니다)과 애플리케이션의 화면을 구성하는 그림 파일들이 저장된 것을 확인할 수 있었습니다.\r\r\n![15.png](https://image.toast.com/aaaadh/real/2024/techblog/15.png)\r\r\n그래도 아쉬운 마음에 '다른 메뉴를 클릭하면 다른 C&C 서버가 동작하지 않을까?' 생각을 해서 아래의 **대출 승인 사례** 메뉴를 클릭해 보았습니다.\r\r\n\r\r\n![16_rv.png](https://image.toast.com/aaaadh/real/2024/techblog/16rv.png)\r\r\n\r\r\n위 그림에서 보시는 것처럼 **대출 승인 사례**를 클릭하자 다음과 같은 알림이 발생했습니다.\r\r\n```\r\r\n    - 금융상품을 만드는건 어렵지만 불필요한 과정을 찾아 알기위하여 간편한 모바일로 알기쉽게 설계했다.(그림 1)\r\r\n    - 보안상 새로운 업데이트가 있습니다. 새버전을 설치해시기 바랍니다.(그림 2)\r\r\n```\r\r\n\r\r\n알림 문구도 어딘가 어색해 보이는 게 한국에서 만든 애플리케이션이 아닌 것을 추측할 수 있습니다.\r\r\n이러한 문구는 또 다른 악성 애플리케이션의 설치를 유도하는 전형적인 악성 애플리케이션의 특징 중 하나입니다.\r\r\n앞에서 살펴보았던 assets 디렉토리에 존재하는 plbFhm.apk 파일을 설치하도록 유도하는 문구였습니다.\r\r\n![17.png](https://image.toast.com/aaaadh/alpha/2024/techblog/17.png)\r\r\n이렇게 애플리케이션을 설계한 이유는 간단합니다.\r\r\n제일 먼저 설치하는 애플리케이션에서 모든 악성 행위를 수행한다면 쉽게 분석이 가능하기 때문에 탐지와 분석을 힘들게 하기 위함입니다.\r\r\nplbFhm.apk 파일을 대략적으로 정리하자면 암호화된 DEX 파일 2개와 총 5개의 MP3 파일이 존재합니다.\r\r\n![18.png](https://image.toast.com/aaaadh/alpha/2024/techblog/18.png)\r\r\n\r\r\n암호화된 DEX 파일이 존재하는 이상 plbFhm.apk도 분석하기 위해서는 암호화된 DEX 파일은 복호화해야 합니다.\r\r\n이 과정은 1편에서 자세히 소개해 드렸기 때문에 2편에서는 넘어가도록 하겠습니다.\r\r\n조금 더 자세한 분석을 진행하기 위해 plbFhm.apk를 설치해 보았습니다.\r\r\n설치하는 순간 수많은 Permission(권한)을 요구하는 것을 볼 수 있습니다.\r\r\n예를 들어, 문자(SMS), 연락처, 사진, 동영상, GPS 등 사생활과 밀접하게 연관된 권한을 요구하는데요.\r\r\n![19.png](https://image.toast.com/aaaadh/alpha/2024/techblog/19.png)\r\r\n그렇다면 이렇게 많은 권한을 요구하는 이유가 무엇일까요?\r\r\n당연히 악성 행위를 하기 위함입니다.<br>\r\r\n그렇다면 왜 이렇게 민감한 권한이 필요한지를 알아보기 위해 위 권한 모두 사용을 허용해 줍니다.\r\r\n그 후 다시 하단의 **대출 승인 사례** 메뉴 버튼을 클릭해 봅니다.\r\r\n![20.png](https://image.toast.com/aaaadh/alpha/2024/techblog/20.png)\r\r\n![20-1.png](https://image.toast.com/aaaadh/alpha/2024/techblog/201.png)\r\r\n이번에는 보안 업데이트가 존재한다면서 또 다른 악성 애플리케이션 설치를 유도합니다.\r\r\nuSBxbR.apk도 plbFhm.apk 파일처럼 암호화된 DEX 파일 2개와 총 3개의 MP3 파일이 존재하였으며 해당 APK 파일도 똑같이 암호화된 DEX 파일을 복호화한 후 분석을 진행하였습니다.\r\r\n자 여기까지 복잡하실 수 있는데 아래의 그림으로 다시 한번 정리해 드리겠습니다.\r\r\n![21.png](https://image.toast.com/aaaadh/alpha/2024/techblog/21%281%29.png)\r\r\n위의 그림을 설명해 드리자면 Base.apk(껍질) 즉, 처음으로 설치하고 실행하는 APK 파일은 핵심이 아닌 껍질을 의미합니다.\r\r\n그 후 2개의 진주(핵심)는 추가로 설치한 2개의 APK 파일이라고 생각하시면 됩니다.\r\r\n즉, 보이스피싱 애플리케이션의 핵심 모듈 및 악성 행위를 하는 코드들은 2개의 진주(핵심)에 존재했으며 2개의 진주(APK)가 보이스 애플리케이션의 핵심이라고 생각하시면 됩니다.\r\r\n\r\r\n## 2. 상담 내용 작성\r\r\n\r\r\n위에 추가로 설치한 2개의 APK 파일 설치가 끝난 후에 아래의 **대출 승인 사례**를 클릭해 보면 피해자들을 속이기 위해 실제 **대출 승인 사례**를 보여주는 것을 확인할 수 있습니다.\r\r\n![22.png](https://image.toast.com/aaaadh/alpha/2024/techblog/22.png)\r\r\n당연히 실제로는 존재하지 않는 사례들입니다.\r\r\n위의 메뉴에서의 핵심은 **상담 신청하기** 메뉴인 것으로 확인되었습니다.\r\r\n![23.png](https://image.toast.com/aaaadh/alpha/2024/techblog/23.png)\r\r\n아래와 같이 상담 신청 내용을 작성하기 위해 **신청하기**를 클릭해 봅니다.\r\r\n![24.png](https://image.toast.com/aaaadh/alpha/2024/techblog/24.png)\r\r\n상담에 필요한 기본적인 정보를 입력하고 **신청하기** 버튼 클릭 후 신청 완료로 최종적으로 상담 신청을 완료합니다.\r\r\n그렇다면 이제 어떻게 될까요?\r\r\n위에서 입력한 상담에 필요한 정보는 user_info라는 파일 이름으로 악성 애플리케이션 내부 저장소에 저장됩니다.\r\r\n![25.png](https://image.toast.com/aaaadh/alpha/2024/techblog/25.png)\r\r\nuser_info 파일을 열어보면 다음과 같이 아까 상담 신청에서 입력한 정보가 저장된 것을 알 수 있습니다.\r\r\n![26.png](https://image.toast.com/aaaadh/alpha/2024/techblog/26.png)\r\r\n위의 정보 마지막에 gongzuo, nianxin, edu, dizhi이라는 알 수 없는 단어가 존재하였습니다.\r\r\n그대로 발음 해보니 중국어와 비슷하여 검색해본 결과 다음과 같았습니다.\r\r\n![27.png](https://image.toast.com/aaaadh/alpha/2024/techblog/27.png)\r\r\n\r\r\n따라서 해당 보이스피싱 애플리케이션은 중국에서 만들어졌다는 것을 알 수 있었습니다.\r\r\n정리해 보면, **상담 신청**이라는 메뉴의 목적은 'user_info'라는 파일을 생성하여 해커가 원하는 대출 금액, 연봉, 직업 등의 정보를 획득하기 위한 목적이었음을 알 수 있습니다.\r\r\n\r\r\n# Permission이란\r\r\n\r\r\n위에서 잠깐 언급하였지만 Permission(권한)이라는 개념에 대해 짧게나마 설명하고 넘어가 보도록 하겠습니다.\r\r\nAndroid와 iOS에서는 애플리케이션을 설치할 때 설치된 단말기의 특정 기능이나 정보에 접근하기 위해 사용자로부터 허락을 받아야 하는 메커니즘이 필수인데요.\r\r\n여러분이 사용하는 단말기에서 애플리케이션을 설치할 때 아래의 그림을 한 번쯤은 보셨을 겁니다.\r\r\n![28.png](https://image.toast.com/aaaadh/alpha/2024/techblog/28.png)\r\r\n이렇게 애플리케이션에서 사용할 권한을 사용자에게 알려주고 허락을 구하는 메커니즘이라고 생각하시면 됩니다.\r\r\n그럼 이런 권한은 어디에 정의되어 있을까요?\r\r\n바로 Androidmanifest.xml[[8]](https://developer.android.com/guide/topics/manifest/manifest-intro?hl=ko)에 정의되어 있습니다.\r\r\n아래 목록은 실제 분석 중인 보이스피싱 애플리케이션의 Androidmanifest.xml에 정의되어 있는 권한 중 일부입니다.\r\r\n![29.png](https://image.toast.com/aaaadh/alpha/2024/techblog/29.png)\r\r\n이제 왜 이런 권한을 요구하는지, 권한을 허용하면 어떤 일이 발생하는지, 보이스피싱 애플리케이션에서 주로 사용되는 오디오 도청, 위치(GPS), 사진과 동영상, 발신 전화 경로 전환, SMS 접근 총 5개의 권한에 대해서 자세히 살펴보도록 하겠습니다.\r\r\n\r\r\n# 보이스피싱 애플리케이션의 5가지 악성 행위\r\r\n\r\r\n보이스피싱 애플리케이션을 분석하면서 정말 다양한 악성 행위가 있다는 것을 느꼈습니다.\r\r\n기사와 영상으로 보는 것보다 직접 구현해 보고 테스트를 해보면서 바뀐 생각이 '보이스피싱을 왜 당할까?'라는 생각은 사라지고 '아, 이 정도면 진짜 당할 수도 있겠구나'라고 생각이 바뀌었습니다.<br>\r\r\n이렇게 제 생각이 바뀐 이유는 총 5개였습니다.\r\r\n보이스피싱 애플리케이션에서 오디오 도청, 위치 추적, 사진 및 동영상 불법 촬영, 발신 전화 경로 전환, SMS 탈취 총 5개의 권한에 접근하였으며 해당 권한에 접근할 수 있다면 1편에서 잠깐 소개해 드렸던 영화 보이스와 스마트폰을 떨어뜨렸을 뿐인 데의 영화 속 피해자들처럼 삶이 붕괴하기까지는 정말 시간 문제인 것 같았습니다.\r\r\n따라서 위의 5개의 권한에 대해서 자세히 알아보도록 하겠습니다.\r\r\n\r\r\n## 1. 오디오 도청\r\r\n\r\r\n오디오를 녹음하기 위해서는 다음과 같은 권한이 필요합니다.\r\r\n![29-1.png](https://image.toast.com/aaaadh/alpha/2024/techblog/291.png)\r\r\n위의 권한을 사용하는 곳을 분석한 결과 아래의 코드처럼 /sdcard/에 log라는 디렉토리에 MP4라는 파일 형식으로 녹음된 파일이 저장되는 것을 알 수 있습니다.\r\r\n![30.png](https://image.toast.com/aaaadh/alpha/2024/techblog/30.png)\r\r\n위에서 저장소 위치가 SD_CARD이기 때문에 SD 카드 권한이 필요한 것입니다.\r\r\n![30-1.png](https://image.toast.com/aaaadh/alpha/2024/techblog/301.png)\r\r\n그럼, 언제 위의 권한을 사용하는 걸까요?\r\r\n바로 통화할 때 RECORD_AUDIO 권한을 사용해서 통화 내용을 녹음합니다.\r\r\n피해자가 수신 또는 발신을 하면 보이스피싱 범죄자들이 가지고 있는 전화번호 리스트에서 수신지와 발신지 전화번호를 체크합니다.\r\r\n해당 리스트에 수신지 또는 발신지의 번호가 존재하면 그때부터 녹음이 시작된다는 의미입니다.\r\r\n즉, 어디로 전화를 거는지 또는 어디에서 전화를 받는지 알 수 있으며 어떤 목적으로 통화한 것인지 다 알 수 있다는 의미입니다.\r\r\n그럼, 전화번호 리스트는 어떻게 관리되고 있을까요?\r\r\n분석 결과 아래의 코드처럼 전화번호는 C&C 서버에서 실시간으로 업데이트되는 것을 알 수 있었습니다.\r\r\n![31.png](https://image.toast.com/aaaadh/alpha/2024/techblog/31.png)\r\r\n또한, 녹음된 통화 파일은 아래의 코드처럼 `http://137.220.230.51/101` 파일을 전송하는 것을 알 수 있었습니다.\r\r\n![32.png](https://image.toast.com/aaaadh/alpha/2024/techblog/32%281%29.png)\r\r\n여기서 조금만 다르게 생각을 해봅시다.\r\r\n현재 도청과 감청의 기술은 엄청나게 발달했다고 합니다.\r\r\n위의 내용과 함께 생각해 보면 우리 모두가 일상생활 중 항상 들고다니는 큰 도청기가 있습니다.\r\r\n바로 휴대전화입니다.<br>\r\r\n위의 방법은 보이스피싱 범죄를 위한 애플리케이션으로 만들어진 보이스피싱 애플리케이션입니다.\r\r\n그렇기 때문에 통화 녹음에 대한 기능만 존재했습니다.\r\r\n근데 만약 보이스피싱 애플리케이션이 아니라면 어떤 사태가 발생할까요?<br>\r\r\n바로 위에서 말씀드렸던 악성 애플리케이션이 설치된 단말기가 하나의 큰 도청기가 되는 것입니다.\r\r\n이를 조금 더 이해하기 쉽게 데모 영상을 짧게 만들어봤습니다.\r\r\n데모 영상을 보시기 전에 먼저 말씀드리자면 왼쪽이 악성 애플리케이션에 설치된 피해자의 단말기입니다.\r\r\n오른쪽이 해커가 만든 서버입니다.\r\r\n해커는 악성 애플리케이션을 설치한 단말기에서 도청을 하기 위해 **Start** 버튼을 클릭합니다.\r\r\n그럼, 이제 휴대전화의 마이크를 통해 모든 소리가 녹음됩니다.\r\r\n그 후 해커는 **Stop** 버튼을 클릭해서 녹음된 파일을 전송받습니다.\r\r\n그런 다음 해커는 녹음된 파일을 재생해서 어떤 소리가 녹음되어 있는지 확인합니다.\r\r\n![33.png](https://image.toast.com/aaaadh/alpha/2024/techblog/33.png)\r\r\n\r\r\n>  [영상 바로 가기](https://youtu.be/xh9gyT9lrpA)\r\r\n\r\r\n이렇게 해커 및 범죄자는 피해자 주변의 소리를 언제 어디서든 들을 수가 있으며 이를 바탕으로 협박과 2차 피해를 줄 수 있습니다.\r\r\n\r\r\n## 2. 위치 추적\r\r\n\r\r\n다음은 GPS 권한입니다.\r\r\n보이스피싱 범죄자들은 피해자가 자신들이 원하는 위치로 가고 있는지, 혹은 경찰서나 다른 곳으로 가고 있는지 확인하기 위해 GPS 데이터를 활용해서 실시간으로 피해자의 위치를 파악합니다.\r\r\n분석 결과 보이스피싱 애플리케이션은 아래의 총 3가지의 권한으로 피해자의 위치를 추적하는데 사용하였습니다.\r\r\n![33-1.png](https://image.toast.com/aaaadh/alpha/2024/techblog/331.png)\r\r\n분석 결과, 위의 권한을 사용한 코드는 다음과 같습니다.\r\r\n![34.png](https://image.toast.com/aaaadh/alpha/2024/techblog/34.png)\r\r\n또한 추가로 분석한 결과, 위의 코드를 통해 피해자의 위치를 추척하고 추척한 위치 데이터를 DB에 저장하는 행위도 발견하였습니다.\r\r\n![35.png](https://image.toast.com/aaaadh/alpha/2024/techblog/35.png)\r\r\n아래의 데모 영상을 보시기 전에 잠깐 부가적인 설명을 하겠습니다.\r\r\n보이스피싱 범죄자들은 자신들의 웹 서버에서 **Start**를 클릭하여 피해자의 위치 정보를 수집합니다.\r\r\n**Start**를 클릭하면 피해자의 단말기(스마트폰)에서 현재 위치 정보를 DB 파일 또는 파일로 저장합니다.\r\r\n해당 파일과 데이터로 현재 피해자의 위치를 알아냅니다.\r\r\n따라서 데모 영상을 보여드리기 위해 운동 삼아 석촌 호수공원을 한 바퀴 걸었습니다. (실제 위치 정보를 수집하기 위해)\r\r\n보이스피싱 범죄자는 피해자의 위치가 궁금하여 **Start** 버튼을 클릭합니다.\r\r\n피해자의 위치 정보는 실시간으로 보이스피싱 범죄자들의 서버로 전송되어 사용자의 위치를 지도에 표시해 줍니다.\r\r\n아래의 데모 영상을 보시면 쉽게 이해가 될 겁니다.\r\r\n\r\r\n![36.png](https://image.toast.com/aaaadh/alpha/2024/techblog/36.png)\r\r\n>  [영상 바로 가기](https://youtu.be/iUsvY4wiCJU)\r\r\n\r\r\n## 3. 불법 촬영\r\r\n\r\r\n보이스피싱 애플리케이션을 설치할 당시 사진과 동영상에 대한 권한을 요구하였습니다.\r\r\n![36-1.png](https://image.toast.com/aaaadh/alpha/2024/techblog/361.png)\r\r\n\r\r\n위의 권한이 사진 및 동영상을 촬영하기 위한 카메라에 대한 권한입니다.\r\r\n분석 결과, 제가 분석한 보이스피싱 애플리케이션에서는 권한만 추가되어 있을 뿐 카메라 권한을 가지고 범죄에 활용한 코드는 존재하지 않았습니다.\r\r\n하지만 생각해 보면 보이스 피싱 범죄자들은 피해자의 현재 장소 또는 사진 및 영상을 협박의 수단으로 활용할 수 있기 때문에 짧게 데모 영상을 만들어 봤습니다.\r\r\n보이스피싱 범죄자들은 자신들의 웹 서버에서 **Start** 버튼을 클릭합니다.\r\r\n**Start** 버튼을 클릭하면 카메라의 전면, 후면에 접근하여 각각 사진을 촬영한 다음 보이스피싱 범죄자들의 서버로 전송하는 데모 영상입니다.<br>\r\r\n먼저 피해자는 평소처럼 유튜브를 시청하고 있었습니다.\r\r\n이때 보이스피싱 범죄자들은 앞에서 설명해 드린 카메라 권한이 있기 때문에 **Start** 버튼을 클릭해 원격에서 피해자의 카메라 전면과 후면에 접근하여 각각 사진을 촬영합니다.\r\r\n그 후 범죄자의 서버로 촬영한 사진을 업로드하여 확인할 수 있습니다.\r\r\n![37.png](https://image.toast.com/aaaadh/alpha/2024/techblog/37.png)\r\r\n>  [영상 바로 가기](https://youtu.be/5IS_zQesG2c)  \r\r\n\r\r\n위 데모 영상처럼 사진 촬영밖에 없지만 카메라 권한이 있기 때문에 동영상 촬영도 손쉽게 할 수 있습니다.\r\r\n\r\r\n## 4. SMS 탈취\r\r\n\r\r\n다음은 문자(SMS)에 접근할 수 있는 권한입니다.\r\r\n![38.png](https://image.toast.com/aaaadh/alpha/2024/techblog/38.png)\r\r\n사용자가 위의 권한을 허용한다면 애플리케이션에서 문자에 접근할 수 있습니다.\r\r\n위의 권한으로 피해자 단말기에 존재하는 SMS에 접근하여 보낸 사람의 이름, 전화번호, 문자 내용, 시간 등 문자에 대한 대부분의 정보에 접근하여 데이터를 탈취하는 것을 확인할 수 있었습니다.\r\r\n관련된 코드는 아래와 같습니다.\r\r\n![39.png](https://image.toast.com/aaaadh/alpha/2024/techblog/39.png)\r\r\nSMS 데이터에 접근해서 저장된 이름(display_name) 또한 저장되는 것을 확인하였습니다.\r\r\n![40.png](https://image.toast.com/aaaadh/alpha/2024/techblog/40.png)\r\r\n이렇게 저장된 이름과 전화번호가 탈취된다면 피해자의 단말기에 저장된 수많은 사람도 보안 위협의 대상이 될 가능성이 존재합니다.\r\r\n아래의 데모 영상은 수신자에게 오는 SMS를 실시간으로 보이스 피싱 범죄자들의 서버로 전송하는 데모 영상입니다.\r\r\nSender는 수신자(피해자)에게 문자를 보냅니다.\r\r\n이때 그림과 같이 인증 번호일 수도 있고, 중요한 내용을 담은 문자일 수 있습니다.\r\r\n![41.png](https://image.toast.com/aaaadh/alpha/2024/techblog/41.png)\r\r\n아래의 코드는 SMS 정보를 탈취하는 코드 중 일부입니다.\r\r\n이렇게 새로운 SMS를 피해자가 수신하게 되면 보이스 피싱 범죄자들의 서버로 전송하도록 합니다.\r\r\nSMS 내용을 탈취하는 기능은 백그라운드에서 실행되며 SMS를 수신하고 발신할 때 보이스 피싱 범죄자들에게 똑같이 전송되게 됩니다.\r\r\n![42.png](https://image.toast.com/aaaadh/alpha/2024/techblog/42.png)\r\r\n![43.png](https://image.toast.com/aaaadh/alpha/2024/techblog/43.png)\r\r\n\r\r\n>  [영상 바로 가기](https://youtu.be/Cex079bPAPQ)\r\r\n\r\r\n\r\r\n## 5. 수신 및 발신 경로 변조와 차단\r\r\n\r\r\n다음은 보이스피싱 애플리케이션의 핵심인 수신 및 발신 전화 변조에 관한 내용에 관해서 설명해 드리겠습니다.\r\r\n먼저 수신 및 발신 전화의 경로를 변조하기 위해서는 아래와 같이 전화와 관련된 권한이 필요합니다.\r\r\n![44.png](https://image.toast.com/aaaadh/alpha/2024/techblog/44.png)\r\r\n이를 설명해 드리기에 앞서 아래의 Youtube 영상을 잠깐 보고 오시겠습니다.\r\r\n\r\r\n * [https://www.youtube.com/watch?v=i73GuJWpROQ&t=25s](https://www.youtube.com/watch?v=i73GuJWpROQ&t=25s)\r\r\n * [https://www.youtube.com/watch?v=YTH-drhg0Hw&t=344s](https://www.youtube.com/watch?v=YTH-drhg0Hw&t=344s)\r\r\n \r\r\n영상에서 보셨던 것처럼 언론과 기사에서는 '전화 가로채기'라는 기법으로 많이 소개되어 있습니다.\r\r\n보이스피싱 애플리케이션에 감염된 피해자가 확인을 위해 금융기관에 전화(발신)를 걸면 보이스피싱 범죄자들이 수집한 전화번호 리스트에 있는지 없는지 판단한 후 없으면 정상적인 수신자에게 발신하게 됩니다.\r\r\n하지만 범죄자들이 수집한 전화번호 리스트에 존재한다면 위 영상에서 보신 것처럼 자신들에게 발신이 오도록 전화번호를 변조합니다.\r\r\n아래의 그림은 위의 설명을 이해하기 쉽게 도식화한 것입니다(그림에 나와있는 기관은 무관합니다).\r\r\n![45.png](https://image.toast.com/aaaadh/alpha/2024/techblog/45%283%29.png)\r\r\n하지만 제가 분석한 보이스피싱 애플리케이션에서는 피해자가 발신할 때 자신들이 수집한 전화번호 리스트에 존재한다면 발신 자체를 하지 못하도록 차단하는 기법을 사용하였습니다.\r\r\n아래의 그림은 현재 분석하는 보이스 애플리케이션에서 사용하는 기법을 이해하기 쉽도록 도식화한 것입니다.\r\r\n![46.png](https://image.toast.com/aaaadh/alpha/2024/techblog/46%283%29.png)\r\r\n수신과 발신 경로 변조 및 차단은 보이스 피싱 애플리케이션의 핵심이기 때문에 위 4가지 기법보다는 핵심을 조금 자세히 설명하려고 합니다.\r\r\n![47.png](https://image.toast.com/aaaadh/alpha/2024/techblog/47.png)\r\r\n위의 코드를 분석한 결과, `Intent`[[9]](https://developer.android.com/reference/android/content/Intent)를 통해 피해자의 발신 여부를 판단합니다.\r\r\n`Intent`는 애플리케이션 컴포넌트 간에 실행을 요청하는 메시지나 데이터를 전달하는 역할을 합니다.\r\r\n예를 들어, 활동(Activity), 서비스(Service), 브로드캐스트 리시버(BroadcastReceiver) 등을 시작할 때 `Intent`를 사용합니다.\r\r\nintent.getAction() 메서드는 `Intent`에 설정된 action 문자열을 반환합니다.\r\r\n이 문자열을 사용하여 `Intent`가 수행하려는 구체적인 작업이 \"android.intent.action.NEW_OUTGOING_CALL\"이라면 v3는 true가 됩니다.\r\r\n이는 새로운 발신 전화가 시작됐음을 의미합니다.\r\r\n새로운 발신 전화가 시작되었으면 intent.getStringExtra(\"android.intent.extra.PHONE_NUMBER\")를 실행하여 발신하려는 전화번호를 `Intent`로부터 추출합니다.\r\r\n아래의 코드는 발신 번호와 수집한 전화번호를 비교하기 위해 수집한 전화번호와 비교하는 코드입니다.\r\r\n![48.png](https://image.toast.com/aaaadh/alpha/2024/techblog/48.png)\r\r\n\r\r\n위의 코드는 allNoMap이라는 HashMap에 Kit.Z(context)이 반환하는 값을 저장합니다.\r\r\n즉, `Kit.Z()` 메서드가 반환하는 값은 보이스피싱 범죄자들이 수집한 전화번호를 의미합니다.\r\r\nAllNoBean allNoBean = (AllNoBean)allNoMap.get(number); 코드의 의미는 allNoMap이라는 수집된 번호에서 발신 전화번호가 있는지 확인하는 기능을 합니다.\r\r\n만약 존재한다면 `getCome()` 메서드는 0을 반환하고 this.setResultData(null); 코드로 발신을 중단합니다.\r\r\n발신을 중단한다는 의미는 발신 자체를 못 하게 막아버린다고 생각하시면 됩니다.\r\r\n아쉽게도 C&C 서버에서 수집한 전화번호에 대한 데이터를 받아와야 하지만 현재 C&C 서버와 통신이 되지 않아 수집한 전화번호에 대한 데이터는 애플리케이션에 존재하지 않았습니다.<br>\r\r\n이제 데모 영상을 보시겠습니다.\r\r\n> [영상 바로 가기](https://youtu.be/32bLJJcV4pU)\r\r\n\r\r\n먼저 피해자는 보이스피싱 범죄자들에게 걸려 온 전화를 받고 확인차 금융위원회, 금융감독원, 금융권 등에 확인을 하기 위해서 전화합니다. (영상에서는 NHN Cloud 대표 전화번호)<br>\r\r\n이때 보이스피싱 애플리케이션은 수집된 전화번호 리스트에서 발신한 번호가 존재한다면 정상적인 경로가 아닌 해커 또는 보이스피싱 범죄자들에게 발신이 되도록 경로를 변조합니다.\r\r\n피해자는 확인을 위해 금융권 등에 전화를 하였지만 실제로는 범죄자들에게 다시 전화를 걸게 되는 것입니다.\r\r\n또한 통화 기록도 수정하여 실제 정상적으로 통화를 했다고 착각하게 만들어 안심시킵니다.\r\r\n![49.png](https://image.toast.com/aaaadh/alpha/2024/techblog/49.png)\r\r\n\r\r\n\r\r\n여기까지 보이스피싱 애플리케이션의 대표적인 악성 행위 5가지에 대해서 알아보았습니다.\r\r\n이러한 행위들은 사용자의 개인정보를 노리거나 금전적인 손실을 초래할 수 있으므로, 각별한 주의가 필요합니다. \r\r\n\r\r\n# 마치며\r\r\n\r\r\n개인적으로 이번 보이스피싱 애플리케이션에 대한 분석을 진행하면서 많은 것을 배우고 느낀 시간이었습니다.\r\r\n정보를 찾아보고 데이터를 분석하며, 최대한 많은 분들이 이해하기 쉬운 형태로 정리하는 과정 또한 좋은 경험이 되었는데요. 보이스피싱, 그 영향력이 얼마나 큰 지에 대한 깊은 이해를 얻을 수 있었던 좋은 기회였습니다.<br>\r\r\n사실 힘든 것보다 매우 재밌었습니다.\r\r\n특히 데모 영상을 만들기 위해 직접 애플리케이션과 서버, 웹 사이트를 개발해 보면서 개발자분들의 전문성과 노력에 대해 다시 한번 생각하는 시간이 되었습니다.\r\r\n이번 보이스피싱 애플리케이션 분석 내용을 통해 모바일 보안뿐만 아니라 보안에 대한 경각심이 조금이라도 생기셨다면 큰 보람을 느낄 것 같습니다.\r\r\n끝으로, 기술의 발전이 무조건 좋은 것이 아니라, 우리에게 가져다주는 편리함과 동시에 우리가 직면할 수 있는 잠재적인 보안 위험성에 대해서도 한 번쯤은 생각해 보는 계기가 되었으면 좋겠습니다.\r\r\n보이스피싱 애플리케이션 분석 1편과 2편의 긴 내용을 읽어 주셔서 감사합니다.\r\r\n\r\r\n# 참고 문헌\r\r\n\r\r\n> [1] [Packet](https://developer.mozilla.org/ko/docs/Glossary/Packet)\r\r\n> [2] [JSON](https://namu.wiki/w/JSON)\r\r\n> [3] [AES](https://namu.wiki/w/AES)\r\r\n> [4] [초기화 벡터](https://ko.wikipedia.org/wiki/%EC%B4%88%EA%B8%B0%ED%99%94_%EB%B2%A1%ED%84%B0)\r\r\n> [5] [베이스64](https://ko.wikipedia.org/wiki/%EB%B2%A0%EC%9D%B4%EC%8A%A464)\r\r\n> [6] [https://www.youtube.com/watch?v=eapWmmBFK6s&t=533](https://www.youtube.com/watch?v=eapWmmBFK6s&t=533)\r\r\n> [7] [파일 시그니처](https://namu.wiki/w/%ED%8C%8C%EC%9D%BC%20%EC%8B%9C%EA%B7%B8%EB%8B%88%EC%B2%98)\r\r\n> [8] [https://developer.android.com/guide/topics/manifest/manifest-intro?hl=ko](https://developer.android.com/guide/topics/manifest/manifest-intro?hl=ko)\r\r\n> [9] [https://developer.android.com/reference/android/content/Intent](https://developer.android.com/reference/android/content/Intent)",
        "contentSnippet": "![NHN Cloud_meetup banner_voicefishing_202406-02-01.png](https://image.toast.com/aaaadh/alpha/2024/techblog/NHN%20Cloudmeetup%20bannervoicefishing2024060201.png)\r\r\n\r\r\n# 들어가며\r\r\n\r\r\n안녕하세요. NHN Cloud 서비스보안팀 지우중입니다.\r\r\n많은 분들이 보이스피싱 애플리케이션 분석 1부를 재밌고 흥미롭게 읽어주셔서 빠르게 2부를 준비했습니다.\r\r\n보이스피싱 애플리케이션 분석 2부에서는 보이스 피싱 애플리케이션에서 어떤 데이터를 C&C서버(*Command & Control Server: 해커가 공격을 수행하기 위해 제어하는 서버*)로 보내는지, 피해자 단말기에서는 어떤 일이 일어나는지 알아보겠습니다.\r\r\n또한, 보이스피싱 애플리케이션의 핵심인 전화 가로채기, 오디오 도청, 위치 추적(GPS), 불법 촬영, SMS 탈취에 대한 분석 내용을 공유하려고 합니다.\r\r\n그럼, 바로 보이스피싱 애플리케이션 분석 2부 시작하겠습니다!\r\r\n\r\r\n***\r\r\n\r\r\n# 피해자 단말기 등록\r\r\n\r\r\n먼저, 결론부터 말씀드리자면 보이스피싱 애플리케이션에서는 피해자 단말기에서 지속적인 모니터링 및 제어 등을 하기 위해 피해자 단말기를 등록하는 과정이 필요합니다.\r\r\n보이스피싱 애플리케이션을 설치한 후 실행하자마자 발생하는 패킷[[1]](https://developer.mozilla.org/ko/docs/Glossary/Packet)을 분석하면, 서버에 피해자의 단말기 정보를 전송하면서 등록 절차를 완료하는 것을 확인할 수 있습니다.\r\r\n이 과정에서 피해자의 전화번호, 통신사, 단말기 정보 등이 포함된 데이터가 전송되는 것을 확인할 수 있었습니다.\r\r\n피해자 단말기를 등록하는 패킷은 아래와 같이 POST 형식으로 [http://137.220.230.51/17](http://137.220.230.51/17) 으로 postVal이라는 값을 전송하는 것을 볼 수 있습니다.\r\r\n![1.png](https://image.toast.com/aaaadh/alpha/2024/techblog/1%281%29.png)\r\r\n\r\r\n패킷 내용을 보시면 postVal의 값은 평문이 아닌 알 수 없는 값을 C&C 서버로 전송하는 걸 알 수 있습니다.\r\r\n하지만 분석하는 입장에서는 정확히 postVal의 값이 어떤 내용인지 알아야 합니다.\r\r\n그 이유는 보이스피싱 범죄자들 입장에서는 postVal 값이 어떤 목적으로 서버로 보내는지 알고 있겠지만 분석하는 입장에서는 평문의 postVal 값을 알아야만 애플리케이션을 실행하자마자 postVal 값을 서버로 보내는 이유를 추측할 수 있기 때문입니다.\n\r\r\n따라서 postVal 값이 어떻게 생성되는지 그 위치를 찾을 필요가 있습니다.\r\r\n분석한 결과, 아래의 코드가 해당 패킷을 생성하는 코드로 확인되었습니다.\r\r\n![2.png](https://image.toast.com/aaaadh/alpha/2024/techblog/2.png)\r\r\n위의 코드에서 ①번을 자세히 살펴보겠습니다.\r\r\n![3.png](https://image.toast.com/aaaadh/alpha/2024/techblog/3.png)\r\r\nreqBody란 request 패킷의 body 부분을 의미합니다.\r\r\n즉, 서버로 요청하는 실제 데이터가 존재하는 영역이라고 생각하시면 됩니다.\r\r\n코드를 분석하면, s5라는 값은 ②번에서 만들어지며 s4는 ③번에서 만들어지는 것을 알 수 있습니다.\r\r\n③번을 통해서 서버로 보낼 데이터의 형식은 JSON[[2]](https://namu.wiki/w/JSON)으로 보내는 것을 확인할 수 있으며 변수 s4의 값은 아래의 `a.b()` 메서드에서 반환된 값을 의미합니다.\r\r\n![4.png](https://image.toast.com/aaaadh/alpha/2024/techblog/4.png)\r\r\n따라서 변수 s4의 값을 확인하기 위해서는 `a.b()` 메서드를 살펴볼 필요가 있습니다.\r\r\n![5.png](https://image.toast.com/aaaadh/alpha/2024/techblog/5.png)\r\r\n`a.b()` 메서드를 확인한 결과, AES/CBC/PKCS5Padding[[3]](https://namu.wiki/w/AES) 알고리즘을 사용하며 key는 \"rb!nBwXv4C%Gr^84\", IV[[4]](https://ko.wikipedia.org/wiki/%EC%B4%88%EA%B8%B0%ED%99%94_%EB%B2%A1%ED%84%B0)값은 \"1234567812345678\"을 사용하는 것을 확인할 수 있습니다.\r\r\n즉, 어떤 값을 암호화하여 최종적으로 Base64 인코딩[[5]](https://ko.wikipedia.org/wiki/%EB%B2%A0%EC%9D%B4%EC%8A%A464)을 수행한 후 반환하고 있는 것을 알 수 있습니다.\r\r\n따라서 암호화를 수행하기 전 평문값을 알 수 있다면 보이스피싱 범죄자들에게 어떤 데이터를 보내는지 알 수 있습니다.\r\r\n여기에는 2가지 방법이 있습니다.\r\r\n첫 번째로는 `a.b()` 메서드를 후킹(*프로그램에서 구성 요소 간에 발생하는 함수 호출, 메시지, 이벤트 등을 중간에서 바꾸거나 가로채는 명령, 방법, 기술이나 행위*)하여 cleartext라는 인자값을 출력하는 방법과 두 번째로는 암호화된 값을 복호화하는 방법이 있습니다. 위의 그림에서 보셨다시피 암호화 과정에 사용한 암호화 알고리즘은 AES 암호화로 대표적인 대칭키 암호화 알고리즘입니다.\r\r\n대칭키 암호화의 가장 큰 특징은 암호화와 복호화를 할 때 사용하는 Key와 IV 값이 같다는 점입니다.\r\r\n따라서 Key와 IV 값이 노출되었기 때문에 두 번째 방법을 이용하면 다음과 같이 평문의 데이터를 확인할 수 있습니다.\r\r\n![6.png](https://image.toast.com/aaaadh/alpha/2024/techblog/6.png)\r\r\n위의 값을 추측해 보면 app_id는 보이스피싱 애플리케이션을 만든 조직에서 부여한 값인 것으로 추측됩니다.\r\r\npid 값은 해당 단말기의 Google 계정과 관련된 값으로 보이며 나머지 값은 피해자 단말기의 정보라고 보시면 됩니다.\r\r\n여기서 왜 app_id가 17이지? 라는 생각이 들 수도 있는데요.\r\r\n보이스피싱 범죄자들은 1개의 보이스피싱 애플리케이션을 만드는 것이 아니라 조직적으로 대량의 악성 애플리케이션을 만듭니다.\r\r\n쉽게 예를 들자면, 보이스피싱 애플리케이션 및 악성 애플리케이션 100개를 만들어 배포한 후 app_id가 없으면 관리적인 측면에서 어떤 악성 애플리케이션에서 요청한 패킷인지 관리하기가 힘들어집니다.\r\r\n![7.png](https://image.toast.com/aaaadh/alpha/2024/techblog/7.png)\r\r\n따라서 위의 그림처럼 각 애플리케이션에 app_id를 부여한 후 app_id 번호에 맞게 서버를 구성한다든지, 피해자들을 속이기 위한 보이스피싱 시나리오 등 관리 및 기타 목적으로 app_id를 부여한 것으로 추측됩니다.\r\r\n범죄자들은 자신의 서버에서 피해자가 자신들이 만든 보이스피싱 애플리케이션이 설치된 후 단말기 등록 패킷을 기다린 후 app_id와 휴대폰 번호(p_no) 등을 보고 자신들이 정한 시나리오 및 목적에 따라 피해자들을 속이기 시작합니다.\r\r\n즉, 빠르게 피해자들을 속이기 위해 필요한 데이터라고 생각해 주시면 될 것 같습니다.\r\r\n여기서 말하는 시나리오란 아래의 영상을 참고하시면 쉽게 이해가 될 것 같습니다.\r\r\n>  [영상 바로 가기](https://www.youtube.com/watch?v=eapWmmBFK6s&t=533)\r\r\n\r\r\n하지만 분석 과정에서 단말기 등록 패킷이 발생한 후 C&C 서버에서는 아무런 응답이 오지 않았는데요.\r\r\n그 이유는 보이스피싱 조직들은 C&C 서버를 일정 기간 운영한 후 이전 및 폐쇄하는 경향이 있는데 현재 분석하는 보이스피싱 애플리케이션의 C&C 서버도 마찬가지로 이전 및 폐쇄한 것으로 보입니다.\r\r\n사실 이 부분이 분석하는 과정에서 가장 아쉬운 부분이었습니다.\n\r\r\n실제로 동작하는 C&C 서버였다면 실시간으로 데이터를 주고받으면서 정확하게 분석할 수 있었지만 이렇게 서버와의 통신이 없다면 사실 완벽한 분석은 어렵다고 볼 수 있습니다.\r\r\n하지만 최대한 해당 보이스피싱 애플리케이션의 특징을 분석해 보고자 노력하였습니다.\r\r\n\r\r\n# 화면 분석\r\r\n\r\r\n## 1. APK 추가 설치\r\r\n\r\r\n분석 당시 저는 'C&C 서버에서 응답이 없어 이제 어떻게 분석을 진행해야 하지?' 라는 생각과 함께 아래의 애플리케이션 첫 화면을 보면서 고민에 빠져있었습니다.\r\r\n\r\r\n![8.png](https://image.toast.com/aaaadh/alpha/2024/techblog/8.png)\r\r\n고민하던 도중 '잠시만.. C&C 서버에서 응답이 없었는데 지금 내가 보고 있는 화면은 뭐지? 어디서 보내준 거지?' 라는 생각이 문득 들었습니다. 그래서 바로 다시 네트워크 패킷을 분석하였습니다.\r\r\n하지만 어떤 패킷에서도 해당 화면에 대한 데이터는 존재하지 않았습니다. 통신 구간이 아니면 남아 있는 것은 APK 파일밖에 없습니다.\r\r\n그래서 다시 APK 파일을 추가로 분석하였습니다.\r\r\nAPK 파일을 분석하던 도중 assets 디렉토리에 다음과 같은 파일이 존재했습니다.\r\r\n![9.png](https://image.toast.com/aaaadh/alpha/2024/techblog/9.png)\r\r\nassets 디렉토리에 존재하는 MP3 파일을 재생해 보면 금융 위원회, 검찰청 민원 상담실, 금감원 콜센터에 전화하면 들리는 안내 음성 파일들이었습니다.\r\r\n위의 MP3 파일은 전화 가로채기 수법에 활용되며 피해자를 속이기 위한 파일임을 추측할 수 있었습니다.\r\r\n또한 MP3 파일 이외 plbFhm.apk, uSBxbR.apk 파일이 존재했습니다.\r\r\n이는 해당 보이스피싱 애플리케이션에서 사용하고 있는 또 다른 APK 파일이라는 것을 확인할 수 있었는데요.\r\r\n하지만 마지막으로 남은 tspTFl.sz 파일은 어떤 파일인지 알 수 없었습니다.\r\r\n주로 `.sz` 확장자는 압축된 파일 형식 중 하나입니다.\r\r\n압축된 파일이 맞는지 확인하기 위해 Hex Editor로 해당 파일을 열어 보았습니다.\r\r\n![10.png](https://image.toast.com/aaaadh/alpha/2024/techblog/10%281%29.png)\r\r\n다행스럽게도 PK 파일 포맷[[7]](https://namu.wiki/w/%ED%8C%8C%EC%9D%BC%20%EC%8B%9C%EA%B7%B8%EB%8B%88%EC%B2%98)으로 되어있는 것을 확인하였으며 파일 자체로는 암호화가 되어있지 않았습니다.\r\r\n이 tspTFl.sz 파일을 열어보기 위해 확장자를 `. zip`으로 변경 후 파일을 열어보았습니다.\r\r\n![11.png](https://image.toast.com/aaaadh/alpha/2024/techblog/11%281%29.png)\r\r\n열어본 결과 html 파일과 js 폴더, 알 수 없는 폴더가 존재하였습니다.\r\r\n어떤 파일인지 분석을 진행하기 위해 압축 풀기를 수행하였지만, 다음과 같이 패스워드가 설정되어 있었습니다.\r\r\n![12.png](https://image.toast.com/aaaadh/alpha/2024/techblog/12.png)\r\r\n\r\r\n패스워드가 설정된 것으로 보아, 중요한 파일인 것 같았는데요.\r\r\n이 패스워드를 분석하기 위해 APK 파일 분석을 진행하였습니다.\r\r\n분석한 결과, 아래의 그림처럼 패스워드는 `\"s********a\"`로 하드코딩 되어 있었으며 발견된 패스워드로 압축 파일을 해제할 수 있었습니다.\r\r\n![13.png](https://image.toast.com/aaaadh/alpha/2024/techblog/13.png)\r\r\n압축이 풀린 html 파일을 열어보면 애플리케이션의 첫 화면인 것을 알 수 있었습니다.\r\r\n![14.png](https://image.toast.com/aaaadh/alpha/2024/techblog/14.png)\r\r\n위의 결과로 C&C 서버에서 화면 데이터를 받아오지 않아도 첫 화면을 볼 수 있었던 이유를 알아냈습니다.\r\r\n또한 ivrvyeuimagesivrvyeu 디렉토리에는 상담원으로 예상되는 사진 파일(도용된 사진으로 추측됩니다)과 애플리케이션의 화면을 구성하는 그림 파일들이 저장된 것을 확인할 수 있었습니다.\r\r\n![15.png](https://image.toast.com/aaaadh/real/2024/techblog/15.png)\r\r\n그래도 아쉬운 마음에 '다른 메뉴를 클릭하면 다른 C&C 서버가 동작하지 않을까?' 생각을 해서 아래의 **대출 승인 사례** 메뉴를 클릭해 보았습니다.\r\r\n\r\r\n![16_rv.png](https://image.toast.com/aaaadh/real/2024/techblog/16rv.png)\r\r\n\r\r\n위 그림에서 보시는 것처럼 **대출 승인 사례**를 클릭하자 다음과 같은 알림이 발생했습니다.\r\r\n```\r\r\n    - 금융상품을 만드는건 어렵지만 불필요한 과정을 찾아 알기위하여 간편한 모바일로 알기쉽게 설계했다.(그림 1)\r\r\n    - 보안상 새로운 업데이트가 있습니다. 새버전을 설치해시기 바랍니다.(그림 2)\r\r\n```\r\r\n\r\r\n알림 문구도 어딘가 어색해 보이는 게 한국에서 만든 애플리케이션이 아닌 것을 추측할 수 있습니다.\r\r\n이러한 문구는 또 다른 악성 애플리케이션의 설치를 유도하는 전형적인 악성 애플리케이션의 특징 중 하나입니다.\r\r\n앞에서 살펴보았던 assets 디렉토리에 존재하는 plbFhm.apk 파일을 설치하도록 유도하는 문구였습니다.\r\r\n![17.png](https://image.toast.com/aaaadh/alpha/2024/techblog/17.png)\r\r\n이렇게 애플리케이션을 설계한 이유는 간단합니다.\r\r\n제일 먼저 설치하는 애플리케이션에서 모든 악성 행위를 수행한다면 쉽게 분석이 가능하기 때문에 탐지와 분석을 힘들게 하기 위함입니다.\r\r\nplbFhm.apk 파일을 대략적으로 정리하자면 암호화된 DEX 파일 2개와 총 5개의 MP3 파일이 존재합니다.\r\r\n![18.png](https://image.toast.com/aaaadh/alpha/2024/techblog/18.png)\r\r\n\r\r\n암호화된 DEX 파일이 존재하는 이상 plbFhm.apk도 분석하기 위해서는 암호화된 DEX 파일은 복호화해야 합니다.\r\r\n이 과정은 1편에서 자세히 소개해 드렸기 때문에 2편에서는 넘어가도록 하겠습니다.\r\r\n조금 더 자세한 분석을 진행하기 위해 plbFhm.apk를 설치해 보았습니다.\r\r\n설치하는 순간 수많은 Permission(권한)을 요구하는 것을 볼 수 있습니다.\r\r\n예를 들어, 문자(SMS), 연락처, 사진, 동영상, GPS 등 사생활과 밀접하게 연관된 권한을 요구하는데요.\r\r\n![19.png](https://image.toast.com/aaaadh/alpha/2024/techblog/19.png)\r\r\n그렇다면 이렇게 많은 권한을 요구하는 이유가 무엇일까요?\r\r\n당연히 악성 행위를 하기 위함입니다.\n\r\r\n그렇다면 왜 이렇게 민감한 권한이 필요한지를 알아보기 위해 위 권한 모두 사용을 허용해 줍니다.\r\r\n그 후 다시 하단의 **대출 승인 사례** 메뉴 버튼을 클릭해 봅니다.\r\r\n![20.png](https://image.toast.com/aaaadh/alpha/2024/techblog/20.png)\r\r\n![20-1.png](https://image.toast.com/aaaadh/alpha/2024/techblog/201.png)\r\r\n이번에는 보안 업데이트가 존재한다면서 또 다른 악성 애플리케이션 설치를 유도합니다.\r\r\nuSBxbR.apk도 plbFhm.apk 파일처럼 암호화된 DEX 파일 2개와 총 3개의 MP3 파일이 존재하였으며 해당 APK 파일도 똑같이 암호화된 DEX 파일을 복호화한 후 분석을 진행하였습니다.\r\r\n자 여기까지 복잡하실 수 있는데 아래의 그림으로 다시 한번 정리해 드리겠습니다.\r\r\n![21.png](https://image.toast.com/aaaadh/alpha/2024/techblog/21%281%29.png)\r\r\n위의 그림을 설명해 드리자면 Base.apk(껍질) 즉, 처음으로 설치하고 실행하는 APK 파일은 핵심이 아닌 껍질을 의미합니다.\r\r\n그 후 2개의 진주(핵심)는 추가로 설치한 2개의 APK 파일이라고 생각하시면 됩니다.\r\r\n즉, 보이스피싱 애플리케이션의 핵심 모듈 및 악성 행위를 하는 코드들은 2개의 진주(핵심)에 존재했으며 2개의 진주(APK)가 보이스 애플리케이션의 핵심이라고 생각하시면 됩니다.\r\r\n\r\r\n## 2. 상담 내용 작성\r\r\n\r\r\n위에 추가로 설치한 2개의 APK 파일 설치가 끝난 후에 아래의 **대출 승인 사례**를 클릭해 보면 피해자들을 속이기 위해 실제 **대출 승인 사례**를 보여주는 것을 확인할 수 있습니다.\r\r\n![22.png](https://image.toast.com/aaaadh/alpha/2024/techblog/22.png)\r\r\n당연히 실제로는 존재하지 않는 사례들입니다.\r\r\n위의 메뉴에서의 핵심은 **상담 신청하기** 메뉴인 것으로 확인되었습니다.\r\r\n![23.png](https://image.toast.com/aaaadh/alpha/2024/techblog/23.png)\r\r\n아래와 같이 상담 신청 내용을 작성하기 위해 **신청하기**를 클릭해 봅니다.\r\r\n![24.png](https://image.toast.com/aaaadh/alpha/2024/techblog/24.png)\r\r\n상담에 필요한 기본적인 정보를 입력하고 **신청하기** 버튼 클릭 후 신청 완료로 최종적으로 상담 신청을 완료합니다.\r\r\n그렇다면 이제 어떻게 될까요?\r\r\n위에서 입력한 상담에 필요한 정보는 user_info라는 파일 이름으로 악성 애플리케이션 내부 저장소에 저장됩니다.\r\r\n![25.png](https://image.toast.com/aaaadh/alpha/2024/techblog/25.png)\r\r\nuser_info 파일을 열어보면 다음과 같이 아까 상담 신청에서 입력한 정보가 저장된 것을 알 수 있습니다.\r\r\n![26.png](https://image.toast.com/aaaadh/alpha/2024/techblog/26.png)\r\r\n위의 정보 마지막에 gongzuo, nianxin, edu, dizhi이라는 알 수 없는 단어가 존재하였습니다.\r\r\n그대로 발음 해보니 중국어와 비슷하여 검색해본 결과 다음과 같았습니다.\r\r\n![27.png](https://image.toast.com/aaaadh/alpha/2024/techblog/27.png)\r\r\n\r\r\n따라서 해당 보이스피싱 애플리케이션은 중국에서 만들어졌다는 것을 알 수 있었습니다.\r\r\n정리해 보면, **상담 신청**이라는 메뉴의 목적은 'user_info'라는 파일을 생성하여 해커가 원하는 대출 금액, 연봉, 직업 등의 정보를 획득하기 위한 목적이었음을 알 수 있습니다.\r\r\n\r\r\n# Permission이란\r\r\n\r\r\n위에서 잠깐 언급하였지만 Permission(권한)이라는 개념에 대해 짧게나마 설명하고 넘어가 보도록 하겠습니다.\r\r\nAndroid와 iOS에서는 애플리케이션을 설치할 때 설치된 단말기의 특정 기능이나 정보에 접근하기 위해 사용자로부터 허락을 받아야 하는 메커니즘이 필수인데요.\r\r\n여러분이 사용하는 단말기에서 애플리케이션을 설치할 때 아래의 그림을 한 번쯤은 보셨을 겁니다.\r\r\n![28.png](https://image.toast.com/aaaadh/alpha/2024/techblog/28.png)\r\r\n이렇게 애플리케이션에서 사용할 권한을 사용자에게 알려주고 허락을 구하는 메커니즘이라고 생각하시면 됩니다.\r\r\n그럼 이런 권한은 어디에 정의되어 있을까요?\r\r\n바로 Androidmanifest.xml[[8]](https://developer.android.com/guide/topics/manifest/manifest-intro?hl=ko)에 정의되어 있습니다.\r\r\n아래 목록은 실제 분석 중인 보이스피싱 애플리케이션의 Androidmanifest.xml에 정의되어 있는 권한 중 일부입니다.\r\r\n![29.png](https://image.toast.com/aaaadh/alpha/2024/techblog/29.png)\r\r\n이제 왜 이런 권한을 요구하는지, 권한을 허용하면 어떤 일이 발생하는지, 보이스피싱 애플리케이션에서 주로 사용되는 오디오 도청, 위치(GPS), 사진과 동영상, 발신 전화 경로 전환, SMS 접근 총 5개의 권한에 대해서 자세히 살펴보도록 하겠습니다.\r\r\n\r\r\n# 보이스피싱 애플리케이션의 5가지 악성 행위\r\r\n\r\r\n보이스피싱 애플리케이션을 분석하면서 정말 다양한 악성 행위가 있다는 것을 느꼈습니다.\r\r\n기사와 영상으로 보는 것보다 직접 구현해 보고 테스트를 해보면서 바뀐 생각이 '보이스피싱을 왜 당할까?'라는 생각은 사라지고 '아, 이 정도면 진짜 당할 수도 있겠구나'라고 생각이 바뀌었습니다.\n\r\r\n이렇게 제 생각이 바뀐 이유는 총 5개였습니다.\r\r\n보이스피싱 애플리케이션에서 오디오 도청, 위치 추적, 사진 및 동영상 불법 촬영, 발신 전화 경로 전환, SMS 탈취 총 5개의 권한에 접근하였으며 해당 권한에 접근할 수 있다면 1편에서 잠깐 소개해 드렸던 영화 보이스와 스마트폰을 떨어뜨렸을 뿐인 데의 영화 속 피해자들처럼 삶이 붕괴하기까지는 정말 시간 문제인 것 같았습니다.\r\r\n따라서 위의 5개의 권한에 대해서 자세히 알아보도록 하겠습니다.\r\r\n\r\r\n## 1. 오디오 도청\r\r\n\r\r\n오디오를 녹음하기 위해서는 다음과 같은 권한이 필요합니다.\r\r\n![29-1.png](https://image.toast.com/aaaadh/alpha/2024/techblog/291.png)\r\r\n위의 권한을 사용하는 곳을 분석한 결과 아래의 코드처럼 /sdcard/에 log라는 디렉토리에 MP4라는 파일 형식으로 녹음된 파일이 저장되는 것을 알 수 있습니다.\r\r\n![30.png](https://image.toast.com/aaaadh/alpha/2024/techblog/30.png)\r\r\n위에서 저장소 위치가 SD_CARD이기 때문에 SD 카드 권한이 필요한 것입니다.\r\r\n![30-1.png](https://image.toast.com/aaaadh/alpha/2024/techblog/301.png)\r\r\n그럼, 언제 위의 권한을 사용하는 걸까요?\r\r\n바로 통화할 때 RECORD_AUDIO 권한을 사용해서 통화 내용을 녹음합니다.\r\r\n피해자가 수신 또는 발신을 하면 보이스피싱 범죄자들이 가지고 있는 전화번호 리스트에서 수신지와 발신지 전화번호를 체크합니다.\r\r\n해당 리스트에 수신지 또는 발신지의 번호가 존재하면 그때부터 녹음이 시작된다는 의미입니다.\r\r\n즉, 어디로 전화를 거는지 또는 어디에서 전화를 받는지 알 수 있으며 어떤 목적으로 통화한 것인지 다 알 수 있다는 의미입니다.\r\r\n그럼, 전화번호 리스트는 어떻게 관리되고 있을까요?\r\r\n분석 결과 아래의 코드처럼 전화번호는 C&C 서버에서 실시간으로 업데이트되는 것을 알 수 있었습니다.\r\r\n![31.png](https://image.toast.com/aaaadh/alpha/2024/techblog/31.png)\r\r\n또한, 녹음된 통화 파일은 아래의 코드처럼 `http://137.220.230.51/101` 파일을 전송하는 것을 알 수 있었습니다.\r\r\n![32.png](https://image.toast.com/aaaadh/alpha/2024/techblog/32%281%29.png)\r\r\n여기서 조금만 다르게 생각을 해봅시다.\r\r\n현재 도청과 감청의 기술은 엄청나게 발달했다고 합니다.\r\r\n위의 내용과 함께 생각해 보면 우리 모두가 일상생활 중 항상 들고다니는 큰 도청기가 있습니다.\r\r\n바로 휴대전화입니다.\n\r\r\n위의 방법은 보이스피싱 범죄를 위한 애플리케이션으로 만들어진 보이스피싱 애플리케이션입니다.\r\r\n그렇기 때문에 통화 녹음에 대한 기능만 존재했습니다.\r\r\n근데 만약 보이스피싱 애플리케이션이 아니라면 어떤 사태가 발생할까요?\n\r\r\n바로 위에서 말씀드렸던 악성 애플리케이션이 설치된 단말기가 하나의 큰 도청기가 되는 것입니다.\r\r\n이를 조금 더 이해하기 쉽게 데모 영상을 짧게 만들어봤습니다.\r\r\n데모 영상을 보시기 전에 먼저 말씀드리자면 왼쪽이 악성 애플리케이션에 설치된 피해자의 단말기입니다.\r\r\n오른쪽이 해커가 만든 서버입니다.\r\r\n해커는 악성 애플리케이션을 설치한 단말기에서 도청을 하기 위해 **Start** 버튼을 클릭합니다.\r\r\n그럼, 이제 휴대전화의 마이크를 통해 모든 소리가 녹음됩니다.\r\r\n그 후 해커는 **Stop** 버튼을 클릭해서 녹음된 파일을 전송받습니다.\r\r\n그런 다음 해커는 녹음된 파일을 재생해서 어떤 소리가 녹음되어 있는지 확인합니다.\r\r\n![33.png](https://image.toast.com/aaaadh/alpha/2024/techblog/33.png)\r\r\n\r\r\n>  [영상 바로 가기](https://youtu.be/xh9gyT9lrpA)\r\r\n\r\r\n이렇게 해커 및 범죄자는 피해자 주변의 소리를 언제 어디서든 들을 수가 있으며 이를 바탕으로 협박과 2차 피해를 줄 수 있습니다.\r\r\n\r\r\n## 2. 위치 추적\r\r\n\r\r\n다음은 GPS 권한입니다.\r\r\n보이스피싱 범죄자들은 피해자가 자신들이 원하는 위치로 가고 있는지, 혹은 경찰서나 다른 곳으로 가고 있는지 확인하기 위해 GPS 데이터를 활용해서 실시간으로 피해자의 위치를 파악합니다.\r\r\n분석 결과 보이스피싱 애플리케이션은 아래의 총 3가지의 권한으로 피해자의 위치를 추적하는데 사용하였습니다.\r\r\n![33-1.png](https://image.toast.com/aaaadh/alpha/2024/techblog/331.png)\r\r\n분석 결과, 위의 권한을 사용한 코드는 다음과 같습니다.\r\r\n![34.png](https://image.toast.com/aaaadh/alpha/2024/techblog/34.png)\r\r\n또한 추가로 분석한 결과, 위의 코드를 통해 피해자의 위치를 추척하고 추척한 위치 데이터를 DB에 저장하는 행위도 발견하였습니다.\r\r\n![35.png](https://image.toast.com/aaaadh/alpha/2024/techblog/35.png)\r\r\n아래의 데모 영상을 보시기 전에 잠깐 부가적인 설명을 하겠습니다.\r\r\n보이스피싱 범죄자들은 자신들의 웹 서버에서 **Start**를 클릭하여 피해자의 위치 정보를 수집합니다.\r\r\n**Start**를 클릭하면 피해자의 단말기(스마트폰)에서 현재 위치 정보를 DB 파일 또는 파일로 저장합니다.\r\r\n해당 파일과 데이터로 현재 피해자의 위치를 알아냅니다.\r\r\n따라서 데모 영상을 보여드리기 위해 운동 삼아 석촌 호수공원을 한 바퀴 걸었습니다. (실제 위치 정보를 수집하기 위해)\r\r\n보이스피싱 범죄자는 피해자의 위치가 궁금하여 **Start** 버튼을 클릭합니다.\r\r\n피해자의 위치 정보는 실시간으로 보이스피싱 범죄자들의 서버로 전송되어 사용자의 위치를 지도에 표시해 줍니다.\r\r\n아래의 데모 영상을 보시면 쉽게 이해가 될 겁니다.\r\r\n\r\r\n![36.png](https://image.toast.com/aaaadh/alpha/2024/techblog/36.png)\r\r\n>  [영상 바로 가기](https://youtu.be/iUsvY4wiCJU)\r\r\n\r\r\n## 3. 불법 촬영\r\r\n\r\r\n보이스피싱 애플리케이션을 설치할 당시 사진과 동영상에 대한 권한을 요구하였습니다.\r\r\n![36-1.png](https://image.toast.com/aaaadh/alpha/2024/techblog/361.png)\r\r\n\r\r\n위의 권한이 사진 및 동영상을 촬영하기 위한 카메라에 대한 권한입니다.\r\r\n분석 결과, 제가 분석한 보이스피싱 애플리케이션에서는 권한만 추가되어 있을 뿐 카메라 권한을 가지고 범죄에 활용한 코드는 존재하지 않았습니다.\r\r\n하지만 생각해 보면 보이스 피싱 범죄자들은 피해자의 현재 장소 또는 사진 및 영상을 협박의 수단으로 활용할 수 있기 때문에 짧게 데모 영상을 만들어 봤습니다.\r\r\n보이스피싱 범죄자들은 자신들의 웹 서버에서 **Start** 버튼을 클릭합니다.\r\r\n**Start** 버튼을 클릭하면 카메라의 전면, 후면에 접근하여 각각 사진을 촬영한 다음 보이스피싱 범죄자들의 서버로 전송하는 데모 영상입니다.\n\r\r\n먼저 피해자는 평소처럼 유튜브를 시청하고 있었습니다.\r\r\n이때 보이스피싱 범죄자들은 앞에서 설명해 드린 카메라 권한이 있기 때문에 **Start** 버튼을 클릭해 원격에서 피해자의 카메라 전면과 후면에 접근하여 각각 사진을 촬영합니다.\r\r\n그 후 범죄자의 서버로 촬영한 사진을 업로드하여 확인할 수 있습니다.\r\r\n![37.png](https://image.toast.com/aaaadh/alpha/2024/techblog/37.png)\r\r\n>  [영상 바로 가기](https://youtu.be/5IS_zQesG2c)  \r\r\n\r\r\n위 데모 영상처럼 사진 촬영밖에 없지만 카메라 권한이 있기 때문에 동영상 촬영도 손쉽게 할 수 있습니다.\r\r\n\r\r\n## 4. SMS 탈취\r\r\n\r\r\n다음은 문자(SMS)에 접근할 수 있는 권한입니다.\r\r\n![38.png](https://image.toast.com/aaaadh/alpha/2024/techblog/38.png)\r\r\n사용자가 위의 권한을 허용한다면 애플리케이션에서 문자에 접근할 수 있습니다.\r\r\n위의 권한으로 피해자 단말기에 존재하는 SMS에 접근하여 보낸 사람의 이름, 전화번호, 문자 내용, 시간 등 문자에 대한 대부분의 정보에 접근하여 데이터를 탈취하는 것을 확인할 수 있었습니다.\r\r\n관련된 코드는 아래와 같습니다.\r\r\n![39.png](https://image.toast.com/aaaadh/alpha/2024/techblog/39.png)\r\r\nSMS 데이터에 접근해서 저장된 이름(display_name) 또한 저장되는 것을 확인하였습니다.\r\r\n![40.png](https://image.toast.com/aaaadh/alpha/2024/techblog/40.png)\r\r\n이렇게 저장된 이름과 전화번호가 탈취된다면 피해자의 단말기에 저장된 수많은 사람도 보안 위협의 대상이 될 가능성이 존재합니다.\r\r\n아래의 데모 영상은 수신자에게 오는 SMS를 실시간으로 보이스 피싱 범죄자들의 서버로 전송하는 데모 영상입니다.\r\r\nSender는 수신자(피해자)에게 문자를 보냅니다.\r\r\n이때 그림과 같이 인증 번호일 수도 있고, 중요한 내용을 담은 문자일 수 있습니다.\r\r\n![41.png](https://image.toast.com/aaaadh/alpha/2024/techblog/41.png)\r\r\n아래의 코드는 SMS 정보를 탈취하는 코드 중 일부입니다.\r\r\n이렇게 새로운 SMS를 피해자가 수신하게 되면 보이스 피싱 범죄자들의 서버로 전송하도록 합니다.\r\r\nSMS 내용을 탈취하는 기능은 백그라운드에서 실행되며 SMS를 수신하고 발신할 때 보이스 피싱 범죄자들에게 똑같이 전송되게 됩니다.\r\r\n![42.png](https://image.toast.com/aaaadh/alpha/2024/techblog/42.png)\r\r\n![43.png](https://image.toast.com/aaaadh/alpha/2024/techblog/43.png)\r\r\n\r\r\n>  [영상 바로 가기](https://youtu.be/Cex079bPAPQ)\r\r\n\r\r\n\r\r\n## 5. 수신 및 발신 경로 변조와 차단\r\r\n\r\r\n다음은 보이스피싱 애플리케이션의 핵심인 수신 및 발신 전화 변조에 관한 내용에 관해서 설명해 드리겠습니다.\r\r\n먼저 수신 및 발신 전화의 경로를 변조하기 위해서는 아래와 같이 전화와 관련된 권한이 필요합니다.\r\r\n![44.png](https://image.toast.com/aaaadh/alpha/2024/techblog/44.png)\r\r\n이를 설명해 드리기에 앞서 아래의 Youtube 영상을 잠깐 보고 오시겠습니다.\r\r\n\r\r\n * [https://www.youtube.com/watch?v=i73GuJWpROQ&t=25s](https://www.youtube.com/watch?v=i73GuJWpROQ&t=25s)\r\r\n * [https://www.youtube.com/watch?v=YTH-drhg0Hw&t=344s](https://www.youtube.com/watch?v=YTH-drhg0Hw&t=344s)\r\r\n \r\r\n영상에서 보셨던 것처럼 언론과 기사에서는 '전화 가로채기'라는 기법으로 많이 소개되어 있습니다.\r\r\n보이스피싱 애플리케이션에 감염된 피해자가 확인을 위해 금융기관에 전화(발신)를 걸면 보이스피싱 범죄자들이 수집한 전화번호 리스트에 있는지 없는지 판단한 후 없으면 정상적인 수신자에게 발신하게 됩니다.\r\r\n하지만 범죄자들이 수집한 전화번호 리스트에 존재한다면 위 영상에서 보신 것처럼 자신들에게 발신이 오도록 전화번호를 변조합니다.\r\r\n아래의 그림은 위의 설명을 이해하기 쉽게 도식화한 것입니다(그림에 나와있는 기관은 무관합니다).\r\r\n![45.png](https://image.toast.com/aaaadh/alpha/2024/techblog/45%283%29.png)\r\r\n하지만 제가 분석한 보이스피싱 애플리케이션에서는 피해자가 발신할 때 자신들이 수집한 전화번호 리스트에 존재한다면 발신 자체를 하지 못하도록 차단하는 기법을 사용하였습니다.\r\r\n아래의 그림은 현재 분석하는 보이스 애플리케이션에서 사용하는 기법을 이해하기 쉽도록 도식화한 것입니다.\r\r\n![46.png](https://image.toast.com/aaaadh/alpha/2024/techblog/46%283%29.png)\r\r\n수신과 발신 경로 변조 및 차단은 보이스 피싱 애플리케이션의 핵심이기 때문에 위 4가지 기법보다는 핵심을 조금 자세히 설명하려고 합니다.\r\r\n![47.png](https://image.toast.com/aaaadh/alpha/2024/techblog/47.png)\r\r\n위의 코드를 분석한 결과, `Intent`[[9]](https://developer.android.com/reference/android/content/Intent)를 통해 피해자의 발신 여부를 판단합니다.\r\r\n`Intent`는 애플리케이션 컴포넌트 간에 실행을 요청하는 메시지나 데이터를 전달하는 역할을 합니다.\r\r\n예를 들어, 활동(Activity), 서비스(Service), 브로드캐스트 리시버(BroadcastReceiver) 등을 시작할 때 `Intent`를 사용합니다.\r\r\nintent.getAction() 메서드는 `Intent`에 설정된 action 문자열을 반환합니다.\r\r\n이 문자열을 사용하여 `Intent`가 수행하려는 구체적인 작업이 \"android.intent.action.NEW_OUTGOING_CALL\"이라면 v3는 true가 됩니다.\r\r\n이는 새로운 발신 전화가 시작됐음을 의미합니다.\r\r\n새로운 발신 전화가 시작되었으면 intent.getStringExtra(\"android.intent.extra.PHONE_NUMBER\")를 실행하여 발신하려는 전화번호를 `Intent`로부터 추출합니다.\r\r\n아래의 코드는 발신 번호와 수집한 전화번호를 비교하기 위해 수집한 전화번호와 비교하는 코드입니다.\r\r\n![48.png](https://image.toast.com/aaaadh/alpha/2024/techblog/48.png)\r\r\n\r\r\n위의 코드는 allNoMap이라는 HashMap에 Kit.Z(context)이 반환하는 값을 저장합니다.\r\r\n즉, `Kit.Z()` 메서드가 반환하는 값은 보이스피싱 범죄자들이 수집한 전화번호를 의미합니다.\r\r\nAllNoBean allNoBean = (AllNoBean)allNoMap.get(number); 코드의 의미는 allNoMap이라는 수집된 번호에서 발신 전화번호가 있는지 확인하는 기능을 합니다.\r\r\n만약 존재한다면 `getCome()` 메서드는 0을 반환하고 this.setResultData(null); 코드로 발신을 중단합니다.\r\r\n발신을 중단한다는 의미는 발신 자체를 못 하게 막아버린다고 생각하시면 됩니다.\r\r\n아쉽게도 C&C 서버에서 수집한 전화번호에 대한 데이터를 받아와야 하지만 현재 C&C 서버와 통신이 되지 않아 수집한 전화번호에 대한 데이터는 애플리케이션에 존재하지 않았습니다.\n\r\r\n이제 데모 영상을 보시겠습니다.\r\r\n> [영상 바로 가기](https://youtu.be/32bLJJcV4pU)\r\r\n\r\r\n먼저 피해자는 보이스피싱 범죄자들에게 걸려 온 전화를 받고 확인차 금융위원회, 금융감독원, 금융권 등에 확인을 하기 위해서 전화합니다. (영상에서는 NHN Cloud 대표 전화번호)\n\r\r\n이때 보이스피싱 애플리케이션은 수집된 전화번호 리스트에서 발신한 번호가 존재한다면 정상적인 경로가 아닌 해커 또는 보이스피싱 범죄자들에게 발신이 되도록 경로를 변조합니다.\r\r\n피해자는 확인을 위해 금융권 등에 전화를 하였지만 실제로는 범죄자들에게 다시 전화를 걸게 되는 것입니다.\r\r\n또한 통화 기록도 수정하여 실제 정상적으로 통화를 했다고 착각하게 만들어 안심시킵니다.\r\r\n![49.png](https://image.toast.com/aaaadh/alpha/2024/techblog/49.png)\r\r\n\r\r\n\r\r\n여기까지 보이스피싱 애플리케이션의 대표적인 악성 행위 5가지에 대해서 알아보았습니다.\r\r\n이러한 행위들은 사용자의 개인정보를 노리거나 금전적인 손실을 초래할 수 있으므로, 각별한 주의가 필요합니다. \r\r\n\r\r\n# 마치며\r\r\n\r\r\n개인적으로 이번 보이스피싱 애플리케이션에 대한 분석을 진행하면서 많은 것을 배우고 느낀 시간이었습니다.\r\r\n정보를 찾아보고 데이터를 분석하며, 최대한 많은 분들이 이해하기 쉬운 형태로 정리하는 과정 또한 좋은 경험이 되었는데요. 보이스피싱, 그 영향력이 얼마나 큰 지에 대한 깊은 이해를 얻을 수 있었던 좋은 기회였습니다.\n\r\r\n사실 힘든 것보다 매우 재밌었습니다.\r\r\n특히 데모 영상을 만들기 위해 직접 애플리케이션과 서버, 웹 사이트를 개발해 보면서 개발자분들의 전문성과 노력에 대해 다시 한번 생각하는 시간이 되었습니다.\r\r\n이번 보이스피싱 애플리케이션 분석 내용을 통해 모바일 보안뿐만 아니라 보안에 대한 경각심이 조금이라도 생기셨다면 큰 보람을 느낄 것 같습니다.\r\r\n끝으로, 기술의 발전이 무조건 좋은 것이 아니라, 우리에게 가져다주는 편리함과 동시에 우리가 직면할 수 있는 잠재적인 보안 위험성에 대해서도 한 번쯤은 생각해 보는 계기가 되었으면 좋겠습니다.\r\r\n보이스피싱 애플리케이션 분석 1편과 2편의 긴 내용을 읽어 주셔서 감사합니다.\r\r\n\r\r\n# 참고 문헌\r\r\n\r\r\n> [1] [Packet](https://developer.mozilla.org/ko/docs/Glossary/Packet)\r\r\n> [2] [JSON](https://namu.wiki/w/JSON)\r\r\n> [3] [AES](https://namu.wiki/w/AES)\r\r\n> [4] [초기화 벡터](https://ko.wikipedia.org/wiki/%EC%B4%88%EA%B8%B0%ED%99%94_%EB%B2%A1%ED%84%B0)\r\r\n> [5] [베이스64](https://ko.wikipedia.org/wiki/%EB%B2%A0%EC%9D%B4%EC%8A%A464)\r\r\n> [6] [https://www.youtube.com/watch?v=eapWmmBFK6s&t=533](https://www.youtube.com/watch?v=eapWmmBFK6s&t=533)\r\r\n> [7] [파일 시그니처](https://namu.wiki/w/%ED%8C%8C%EC%9D%BC%20%EC%8B%9C%EA%B7%B8%EB%8B%88%EC%B2%98)\r\r\n> [8] [https://developer.android.com/guide/topics/manifest/manifest-intro?hl=ko](https://developer.android.com/guide/topics/manifest/manifest-intro?hl=ko)\r\r\n> [9] [https://developer.android.com/reference/android/content/Intent](https://developer.android.com/reference/android/content/Intent)",
        "isoDate": "2024-06-18T06:37:08.000Z"
      }
    ]
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "이한",
    "category": "개인",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": [
      {
        "creator": "호돌맨",
        "title": "광명찾는 Intellij vmoption 설정 값",
        "link": "https://hodolman.com/59",
        "pubDate": "Mon, 24 Jun 2024 10:17:29 +0900",
        "author": "호돌맨",
        "comments": "https://hodolman.com/59#entry59comment",
        "content": "<h2>Intellij vmoption</h2>\n<ul>\n<li>Zulu JDK 17버젼 사용중.</li>\n<li>Intellij 프로젝트 3~5개에서 자바 애플리케이션 6개정도 띄워놓는 게 일반적</li>\n<li>이 전에는 컴퓨타가 너무 버벅여서 작업하기가 너무 힘들었음</li>\n<li>아래 값으로 개발환경 광명찾음</li>\n<li>단 한번도 Intellij가 버벅이지 않음</li>\n</ul>\n<pre><code>-ea\n-server\n-Xms1024m\n-Xmx5120m\n-Xss256k\n-XX:+UnlockExperimentalVMOptions\n-XX:-UseSerialGC\n-XX:-UseParallelGC\n-XX:-UseG1GC\n-XX:+UseZGC\n-XX:+IgnoreUnrecognizedVMOptions\n-XX:+HeapDumpOnOutOfMemoryError\n-XX:-OmitStackTraceInFastThrow\n-XX:ReservedCodeCacheSize=512m\n-XX:SoftRefLRUPolicyMSPerMB=50\n-XX:+UseStringCache\n-XX:+UseStringDeduplication\n-XX:+AggressiveOpts\n-XX:+AlwaysPreTouch\n-XX:+OptimizeStringConcat\n-XX:+UseFastAccessorMethods\n-Dide.no.platform.update=true\n-Djava.net.preferIPv4Stack=true\n-Djdk.attach.allowAttachSelf=true\n-Djdk.module.illegalAccess.silent=true\n-Dkotlinx.coroutines.debug=off\n-Dsun.io.useCanonCaches=false\n-Dsun.java2d.d3d=false\n-Dsun.java2d.metal=true\n-Dsun.java2d.opengl=false\n-Dsun.tools.attach.tmp.only=true\n-Dsun.awt.mac.a11y.enabled=false\n--add-exports=java.desktop/com.apple.eawt.event=ALL-UNNAMED\n--add-exports=java.desktop/com.apple.eawt=ALL-UNNAMED\n--add-exports=java.desktop/com.apple.laf=ALL-UNNAMED\n--add-exports=java.desktop/sun.awt.image=ALL-UNNAMED\n--add-exports=java.desktop/sun.font=ALL-UNNAMED\n--add-opens=java.base/java.io=ALL-UNNAMED\n--add-opens=java.base/java.lang.reflect=ALL-UNNAMED\n--add-opens=java.base/java.lang=ALL-UNNAMED\n--add-opens=java.base/java.net=ALL-UNNAMED\n--add-opens=java.base/java.nio.charset=ALL-UNNAMED\n--add-opens=java.base/java.text=ALL-UNNAMED\n--add-opens=java.base/java.time=ALL-UNNAMED\n--add-opens=java.base/java.util.concurrent=ALL-UNNAMED\n--add-opens=java.base/java.util=ALL-UNNAMED\n--add-opens=java.base/jdk.internal.org.objectweb.asm.tree=ALL-UNNAMED\n--add-opens=java.base/jdk.internal.org.objectweb.asm=ALL-UNNAMED\n--add-opens=java.base/jdk.internal.vm=ALL-UNNAMED\n--add-opens=java.base/sun.nio.ch=ALL-UNNAMED\n--add-opens=java.desktop/com.apple.eawt.event=ALL-UNNAMED\n--add-opens=java.desktop/com.apple.eawt=ALL-UNNAMED\n--add-opens=java.desktop/com.apple.laf=ALL-UNNAMED\n--add-opens=java.desktop/java.awt.dnd.peer=ALL-UNNAMED\n--add-opens=java.desktop/java.awt.event=ALL-UNNAMED\n--add-opens=java.desktop/java.awt.image=ALL-UNNAMED\n--add-opens=java.desktop/java.awt.peer=ALL-UNNAMED\n--add-opens=java.desktop/java.awt=ALL-UNNAMED\n--add-opens=java.desktop/javax.swing.plaf.basic=ALL-UNNAMED\n--add-opens=java.desktop/javax.swing.text.html=ALL-UNNAMED\n--add-opens=java.desktop/javax.swing=ALL-UNNAMED\n--add-opens=java.desktop/sun.awt.datatransfer=ALL-UNNAMED\n--add-opens=java.desktop/sun.awt.image=ALL-UNNAMED\n--add-opens=java.desktop/sun.awt.windows=ALL-UNNAMED\n--add-opens=java.desktop/sun.awt.X11=ALL-UNNAMED\n--add-opens=java.desktop/sun.awt=ALL-UNNAMED\n--add-opens=java.desktop/sun.font=ALL-UNNAMED\n--add-opens=java.desktop/sun.java2d=ALL-UNNAMED\n--add-opens=java.desktop/sun.lwawt.macosx=ALL-UNNAMED\n--add-opens=java.desktop/sun.lwawt=ALL-UNNAMED\n--add-opens=java.desktop/sun.swing=ALL-UNNAMED\n--add-opens=jdk.attach/sun.tools.attach=ALL-UNNAMED\n—add-opens=jdk.internal.jvmstat/sun.jvmstat.monitor=ALL-UNNAMED\n—add-opens=jdk.jdi/com.sun.tools.jdi=ALL-UNNAMED\n-Dide.managed.by.toolbox=/Applications/JetBrains Toolbox.app/Contents/MacOS/jetbrains-toolbox\n-Dtoolbox.notification.token=96384ae9-2756-497b-8309-23240f1e3002\n-Dtoolbox.notification.portFile=/Users/hodolman/Library/Caches/JetBrains/Toolbox/ports/1732101961.port</code></pre>",
        "contentSnippet": "Intellij vmoption\nZulu JDK 17버젼 사용중.\nIntellij 프로젝트 3~5개에서 자바 애플리케이션 6개정도 띄워놓는 게 일반적\n이 전에는 컴퓨타가 너무 버벅여서 작업하기가 너무 힘들었음\n아래 값으로 개발환경 광명찾음\n단 한번도 Intellij가 버벅이지 않음\n-ea\n-server\n-Xms1024m\n-Xmx5120m\n-Xss256k\n-XX:+UnlockExperimentalVMOptions\n-XX:-UseSerialGC\n-XX:-UseParallelGC\n-XX:-UseG1GC\n-XX:+UseZGC\n-XX:+IgnoreUnrecognizedVMOptions\n-XX:+HeapDumpOnOutOfMemoryError\n-XX:-OmitStackTraceInFastThrow\n-XX:ReservedCodeCacheSize=512m\n-XX:SoftRefLRUPolicyMSPerMB=50\n-XX:+UseStringCache\n-XX:+UseStringDeduplication\n-XX:+AggressiveOpts\n-XX:+AlwaysPreTouch\n-XX:+OptimizeStringConcat\n-XX:+UseFastAccessorMethods\n-Dide.no.platform.update=true\n-Djava.net.preferIPv4Stack=true\n-Djdk.attach.allowAttachSelf=true\n-Djdk.module.illegalAccess.silent=true\n-Dkotlinx.coroutines.debug=off\n-Dsun.io.useCanonCaches=false\n-Dsun.java2d.d3d=false\n-Dsun.java2d.metal=true\n-Dsun.java2d.opengl=false\n-Dsun.tools.attach.tmp.only=true\n-Dsun.awt.mac.a11y.enabled=false\n--add-exports=java.desktop/com.apple.eawt.event=ALL-UNNAMED\n--add-exports=java.desktop/com.apple.eawt=ALL-UNNAMED\n--add-exports=java.desktop/com.apple.laf=ALL-UNNAMED\n--add-exports=java.desktop/sun.awt.image=ALL-UNNAMED\n--add-exports=java.desktop/sun.font=ALL-UNNAMED\n--add-opens=java.base/java.io=ALL-UNNAMED\n--add-opens=java.base/java.lang.reflect=ALL-UNNAMED\n--add-opens=java.base/java.lang=ALL-UNNAMED\n--add-opens=java.base/java.net=ALL-UNNAMED\n--add-opens=java.base/java.nio.charset=ALL-UNNAMED\n--add-opens=java.base/java.text=ALL-UNNAMED\n--add-opens=java.base/java.time=ALL-UNNAMED\n--add-opens=java.base/java.util.concurrent=ALL-UNNAMED\n--add-opens=java.base/java.util=ALL-UNNAMED\n--add-opens=java.base/jdk.internal.org.objectweb.asm.tree=ALL-UNNAMED\n--add-opens=java.base/jdk.internal.org.objectweb.asm=ALL-UNNAMED\n--add-opens=java.base/jdk.internal.vm=ALL-UNNAMED\n--add-opens=java.base/sun.nio.ch=ALL-UNNAMED\n--add-opens=java.desktop/com.apple.eawt.event=ALL-UNNAMED\n--add-opens=java.desktop/com.apple.eawt=ALL-UNNAMED\n--add-opens=java.desktop/com.apple.laf=ALL-UNNAMED\n--add-opens=java.desktop/java.awt.dnd.peer=ALL-UNNAMED\n--add-opens=java.desktop/java.awt.event=ALL-UNNAMED\n--add-opens=java.desktop/java.awt.image=ALL-UNNAMED\n--add-opens=java.desktop/java.awt.peer=ALL-UNNAMED\n--add-opens=java.desktop/java.awt=ALL-UNNAMED\n--add-opens=java.desktop/javax.swing.plaf.basic=ALL-UNNAMED\n--add-opens=java.desktop/javax.swing.text.html=ALL-UNNAMED\n--add-opens=java.desktop/javax.swing=ALL-UNNAMED\n--add-opens=java.desktop/sun.awt.datatransfer=ALL-UNNAMED\n--add-opens=java.desktop/sun.awt.image=ALL-UNNAMED\n--add-opens=java.desktop/sun.awt.windows=ALL-UNNAMED\n--add-opens=java.desktop/sun.awt.X11=ALL-UNNAMED\n--add-opens=java.desktop/sun.awt=ALL-UNNAMED\n--add-opens=java.desktop/sun.font=ALL-UNNAMED\n--add-opens=java.desktop/sun.java2d=ALL-UNNAMED\n--add-opens=java.desktop/sun.lwawt.macosx=ALL-UNNAMED\n--add-opens=java.desktop/sun.lwawt=ALL-UNNAMED\n--add-opens=java.desktop/sun.swing=ALL-UNNAMED\n--add-opens=jdk.attach/sun.tools.attach=ALL-UNNAMED\n—add-opens=jdk.internal.jvmstat/sun.jvmstat.monitor=ALL-UNNAMED\n—add-opens=jdk.jdi/com.sun.tools.jdi=ALL-UNNAMED\n-Dide.managed.by.toolbox=/Applications/JetBrains Toolbox.app/Contents/MacOS/jetbrains-toolbox\n-Dtoolbox.notification.token=96384ae9-2756-497b-8309-23240f1e3002\n-Dtoolbox.notification.portFile=/Users/hodolman/Library/Caches/JetBrains/Toolbox/ports/1732101961.port",
        "guid": "https://hodolman.com/59",
        "isoDate": "2024-06-24T01:17:29.000Z"
      }
    ]
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "인생에서 가장 도움이 되는 수업",
        "link": "https://www.thestartupbible.com/2024/06/public-speaking-and-writing-are-the-most-undervalued-classes.html",
        "pubDate": "Sun, 23 Jun 2024 21:24:00 +0000",
        "content:encodedSnippet": "자주는 아니지만, 나도 가끔 세미나와 강연 요청을 받는다. 바쁘기도 하고, 내가 전문적으로 강연을 하는 사람은 아니라서 대부분 다 사양하고 거절하지만, 없는 시간을 만들어서라도 기꺼이 하는 게 딱 하나 있는데, 바로 학생들을 대상으로 하는 강연이나 세미나이다. 두 가지 이유가 있다. 하나는 학생들이 미래의 창업가들이고, 이들이 스트롱의 미래 고객이기 때문에, 잠재 고객을 만나서 이들에게 스트롱벤처스에 대한 홍보를 하기 위해서이다. 두 번째 이유는 어쩌면 업무적이기도 하지만, 개인적인 이유도 있는데, 바로 학생들과 이야기하면서 나도 큰 배움을 얻기 때문이다.\n내 나이의 절반도 안 되는 학생들에게 내가 뭘 배울 수 있겠느냐는 생각할 수도 있지만, 그렇기 때문에 오히려 나는 더 배울 수 있는 것들이 많다고 생각한다. 학생들 대부분 아직 경험이 없는데, 경험이 없기 때문에 경험이 많은 사람들이 마음속에 갖고 있는 편견이 없고, 편견이 없기 때문에 어떻게 보면 너무 뻔하지만, 자세히 생각해 보면 굉장히 의미 있는 상상과 질문들을 많이 한다. 바로 이런 대화를 하면서 나는 생각도 많이 하고 꽤 많은 배움을 얻을 수 있다. 그리고, 젊은 학생들과 이야기하다 보면 그냥 왠지 나도 더 젊어지는 것 같고, 더 긍정적인 마인드를 얻게 되는 것 같아서 좋다.\n학생들과 이야기하다 보면, 이 질문을 자주 받는다. “기홍님은 지금 생각해 봤을 때, 학교에서 배웠던 내용 중, 일하면서 가장 도움이 많이 됐던 수업은 어떤 거였나요?”\n이 질문을 받으면 나는 생각도 하지 않고 ‘Public Speaking(말하기)’과 ‘Writing(쓰기)’ 수업이라고 자신 있게 말해준다. 내가 한국에서 학교 다닐 땐 이런 수업이 존재하지 않아서, 나는 미국에서 유학할 때 말하기와 쓰기 수업을 들었는데, 요샌 한국에서도 이런 수업이 제공되는 거로 알고 있다. 전공을 불문하고 모든 대학생들에게 이 두 수업을 되도록 졸업하기 전에, 시간 날 때마다 수강하는 걸 강력하게 추천한다.\n나는 오랫동안 글을 쓰긴 했다. 초등학교 때부터 지금까지 공부를 위한 글쓰기나 취미를 위한 글쓰기는 꾸준히 해왔고, 나름 나만의 스타일로 글을 쓰면서 내 생각을 정리하는 동시에, 이 생각을 남에게 명확하게 전달하는 데에는 어느 정도 성공하고 있다고 생각한다. 하지만, 아직도 부족해서 매일 일정 시간을 할애해서 글을 쓰고 있다. 글을 매일 쓰면 글쓰기 실력은 누구나 향상할 수 있다. 하지만, 더 잘 쓰고 싶으면 쓰는 동시에 많이 읽어야 한다. 참고로, 나는 매년 50권의 책을 읽으려고 노력한다. 글쓰기는 이렇게 평생 연습을 하고 있기 때문에 쓰기 수업은 미국에서 유학할 때 한 번 들었다. 이 수업의 핵심은, 글을 잘 쓰고 싶다면, 많이, 그리고 자주 써야 하고, 이만큼 많이, 그리고 자주 읽어야 한다는 것이다.\n말하기는 내가 항상 자신이 없었던 분야였다. 그런데, 대학원에 가니까 나보다 실력도 없고 멍청한 학생들이 남들 앞에서 말을 논리적으로 잘하면서 내 밥그릇과 기회를 빼앗아 가는 걸 직접 경험하면서, 나도 말을 좀 잘해야겠다는 결심을 했고, 대학원에서 ‘Public Speaking’이라는 수업을 2학기나 들었다. 이 수업은 3학점짜리 수업이니까 총 6학점을 들은 것이다. 실은, 나와 1대 1로 연습/훈련을 했던 코치는 학부생이었는데, 노벨 물리학상을 받은 스탠포드 교수보다 나에겐 훨씬 더 뛰어나고 인상 깊었던 선생님이었다. 수업마다 특정 주제에 대해서 각자 3~5분 동안 발표를 하고, 이걸 동영상으로 촬영한 후 코치와 함께 자세하게 분석해서 발표 실력을 지속적으로 개선해 나가는 과정을 반복하게 된다. 나는 첫 학기에 B-를 받았지만 – 참고로 B 이하는 매우 형편없는 점수이다 – 그 다음 학기는 B+를 받았다. 성적은 조금 향상했지만 내 발표 실력과 청중 앞에 섰을 때의 자신감은 10배 정도 상승했다.\n나는 꽤 많은 사람들을 만나는데, 상당히 자주 깜짝깜짝 놀랄 때가 있다. 이렇게 공부도 많이 하고, 일도 오래 한 사람들이, 본인의 생각을 남들에게 말이나 글로 전달하는 걸 보면, 초등학생 수준으로도 미달일 때가 많기 때문이다.\n지금 이 글을 읽는 학생들이 있다면, 이분들에겐 더욱더 강력하게 ‘말하기’와 ‘쓰기’ 수업을 추천한다. 직장인들이라면, 이분들에게도 강력하게 추천한다. 절대 후회하지 않을 것이다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/06/public-speaking-and-writing-are-the-most-undervalued-classes.html#respond",
        "content": "자주는 아니지만, 나도 가끔 세미나와 강연 요청을 받는다. 바쁘기도 하고, 내가 전문적으로 강연을 하는 사람은 아니라서 대부분 다 사양하고 거절하지만, 없는 시간을 만들어서라도 기꺼이 하는 게 딱 하나 있는데, 바로 학생들을 대상으로 하는 강연이나 세미나이다. 두 가지 이유가 있다. 하나는 학생들이 미래의 창업가들이고, 이들이 스트롱의 미래 고객이기 때문에, 잠재 고객을 만나서 이들에게 스트롱벤처스에 대한 홍보를(...)",
        "contentSnippet": "자주는 아니지만, 나도 가끔 세미나와 강연 요청을 받는다. 바쁘기도 하고, 내가 전문적으로 강연을 하는 사람은 아니라서 대부분 다 사양하고 거절하지만, 없는 시간을 만들어서라도 기꺼이 하는 게 딱 하나 있는데, 바로 학생들을 대상으로 하는 강연이나 세미나이다. 두 가지 이유가 있다. 하나는 학생들이 미래의 창업가들이고, 이들이 스트롱의 미래 고객이기 때문에, 잠재 고객을 만나서 이들에게 스트롱벤처스에 대한 홍보를(...)",
        "guid": "https://www.thestartupbible.com/?p=9134",
        "categories": [
          "Uncategorized",
          "books",
          "education",
          "FoundersAtWork",
          "스타트업 바이블 QA"
        ],
        "isoDate": "2024-06-23T21:24:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "컴백",
        "link": "https://www.thestartupbible.com/2024/06/the-great-comeback.html",
        "pubDate": "Wed, 19 Jun 2024 21:31:00 +0000",
        "content:encodedSnippet": "얼마 전에 4대 메이저 테니스 대회 중 하나인 프랑스 오픈이 끝났다. 2주 동안 밤늦게까지 거의 매일 테니스를 봐서 행복했지만, 내가 좋아하는 선수들은 이제 대부분 은퇴했거나 늙어서 초반에 탈락했다. 이 중 우승 가능성이 아직도 높았던 조코비치 선수가 우승하길 바랬는데, 준준결승전에 부상으로 인해서 기권패 했다.\n나는 이번에 조코비치 선수의 경기를 다 봤는데, 모든 경기마다 안타까움과 경외감의 두 가지 감정이 교체했다. 거의 완벽함을 자랑하던 선수가 나이 들면서 젊은 선수들에게 밀리는 걸 볼 때마다 역시 아무리 체력이 좋고 몸 관리를 잘해도 세월을 이길 수 없다는 안타까움과 아쉬움이 있었지만, 반대로, 이제 거의 40세가 된 이 선수가 20대 초반 선수들과 체력적으로 대등한 경기를 하는 걸 보면 정말 대단하다는 경외심이 생겼다.\n특히, 이번 프랑스 오픈 시합에서 인상 깊었던 점은 이 노장의 컴백 능력이었다. 남자 테니스는 5세트 중 3세트를 먼저 이겨야 하는데, 5세트를 모두 플레이하면, 그리고 정말 치열한 경기를 펼치면 5시간 이상 걸린다. 사업도 그렇지만, 운동 경기도 분위기와 흐름이라는 게 있어서, 이 분위기와 흐름이 내 쪽으로 오지 않으면 상승모드를 유지하는 게 정말 어렵다. 테니스의 경우 세트 스코어가 2대 1이면, 네 번째 세트에서 경기는 3대 1로 거의 종료된다. 즉, 2세트를 뒤지고 있으면, 그 이후에 다시 흐름을 뺏어오는 게 거의 불가능하다.\n그런데 조코비치는 이런 통계에 포함되길 거부하는 선수다. 나는 그동안 이 선수가 세트 스코어 2대 0으로 뒤지고 있는 상황에서 완벽하게 컴백해서 결국엔 다섯 번째 세트까지 가서 3대 2로 이기는 걸 너무 많이 봤다. 실은, 너무 많이 봐서 이 선수에겐 이게 당연한 것 같이 느껴지지만, 현실적으론 거의 불가능한 컴백을 조코비치는 밥 먹듯이 하고 있다는 점이 정말 놀랍다. 그리고 아무리 나이를 먹어도 이런 불가능한 컴백을 이번 프랑스 오픈에서도 여러 번 보여줬다. 3 라운드와 4라운드 모두 세트스코어 2대 1로 지고 있던 상황에서 결국엔 다섯 번째 세트까지 경기를 끌고 가서, 4시간 반이 넘는 시합을 하면서 두 번이나 3대 2로 역전승했다.\n아무리 뛰어나고 위대한 선수들도 이런 컴백을 하기는 쉽지 않은데, 어떻게 조코비치는 반복적으로 이렇게 컴백 할 수 있을까? 결국엔 정신력, 체력, 자기관리, 그리고 끝까지 포기하지 않는 끈기 때문이라고 생각한다. 운동선수들은 – 특히, 팀이 아닌 개인에게 퍼포먼스의 100%를 의지해야 하는 테니스와 같은 – 몸이 돈이기 때문에 정말 체력을 종교와도 같이 관리하는데 조코비치는 이런 운동선수 중에서도 심할 정도로 관리를 잘 한다. 몇 년 전에 메이저 대회 우승한 후에 초콜릿을 딱 한 입 먹은 후에 우승을 자축한 일화가 유명하지만, 이런 관리 스타일은 이 선수의 일상생활이다. 이런 자기 관리에서 오는 체력과 정신력은 다른 선수들이 흉내조차 낼 수 없을 정도다.\n창업가들은 하루하루가 이렇게 뒤지고 있는 경기에서 컴백해야 하는 전쟁이다. 다른 경쟁 스타트업과의 경기에서 항상 지기 때문에 컴백해야 한다. 대기업과의 경기에서 이미 진 상태로 시작하기 때문에 컴백해야 한다. 자신의 제품과의 경기에서 지기 때문에 컴백해야 한다. 고객과의 경기에서도 항상 지기 때문에 컴백해야 한다. 회사에 사람이 많아지면, 직원들에게도 치이면서 지기 때문에 항상 컴백해야 한다. 도대체 이기는 경기는 하나도 없기 때문에, 모든 면에서 매일, 매시간, 매 순간 컴백해야 한다.\n이렇게 계속 컴백하기 위해서는 조코비치같이 창업가들도 몸과 마음을 잘 단련하고, 절제하고, 관리해야 한다. 운동도 매일 해야 하고, 음식도 절제해야 하고, 술도 절제해야 하고, 항상 최상의 컨디션으로 일하고, 뒤지는 경기에서도 항상 컴백할 수 있게 항상 스스로를 관리해야 한다. 이게 안 되면 오랫동안 지속되는 사업을 만들 수가 없다.\n*참고로, 조코비치가 이번에 준준결승에서 기권한 이유는 늙어서 체력이 약해서라기 보단, 그 전 경기가 주최 측의 잘못된 결정으로 너무 늦게 밤 11시에 시작해서 새벽 3시가 넘어서 끝났기 때문이다. 이렇게 누적된 피로로 그다음 날 다시 경기하는 건 말도 안 된다고 생각했기 때문에 기권했다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/06/the-great-comeback.html#comments",
        "content": "얼마 전에 4대 메이저 테니스 대회 중 하나인 프랑스 오픈이 끝났다. 2주 동안 밤늦게까지 거의 매일 테니스를 봐서 행복했지만, 내가 좋아하는 선수들은 이제 대부분 은퇴했거나 늙어서 초반에 탈락했다. 이 중 우승 가능성이 아직도 높았던 조코비치 선수가 우승하길 바랬는데, 준준결승전에 부상으로 인해서 기권패 했다. 나는 이번에 조코비치 선수의 경기를 다 봤는데, 모든 경기마다 안타까움과 경외감의 두(...)",
        "contentSnippet": "얼마 전에 4대 메이저 테니스 대회 중 하나인 프랑스 오픈이 끝났다. 2주 동안 밤늦게까지 거의 매일 테니스를 봐서 행복했지만, 내가 좋아하는 선수들은 이제 대부분 은퇴했거나 늙어서 초반에 탈락했다. 이 중 우승 가능성이 아직도 높았던 조코비치 선수가 우승하길 바랬는데, 준준결승전에 부상으로 인해서 기권패 했다. 나는 이번에 조코비치 선수의 경기를 다 봤는데, 모든 경기마다 안타까움과 경외감의 두(...)",
        "guid": "https://www.thestartupbible.com/?p=9131",
        "categories": [
          "Uncategorized",
          "discipline",
          "FoundersAtWork",
          "sports"
        ],
        "isoDate": "2024-06-19T21:31:00.000Z"
      }
    ]
  },
  {
    "name": "Build a Great Product",
    "category": "개인",
    "posts": []
  },
  {
    "name": "지금 써보러 갑니다",
    "category": "개인",
    "posts": []
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "환전 없이 토스로 해외 결제 하는 법",
        "link": "https://blog.toss.im/article/tosspay-offline-pay",
        "pubDate": "Mon, 24 Jun 2024 06:15:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-oni540{position:relative;width:100%;height:0;padding-bottom:56.25%;}\n.css-122y91a{position:absolute;top:0;left:0;width:100%;height:100%;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}\n.css-1kxrhf3{white-space:pre-wrap;}일본 여행 가면 동전으로 계산하는 것도 어렵고, 환전한 돈 부족할까 봐 신경쓰였을 텐데요. 토스페이 해외결제 서비스를 이용하면 일본에서도 한국에서처럼 결제할 수 있어요.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n토스 해외 결제 사용 방법 \n1. 홈 화면 하단에 ‘토스페이’를 선택한 뒤 오른쪽 상단의 ‘현장결제’를 눌러주세요. \n.css-1pgssrp{max-width:100%;border-radius:16px;}.css-wgpbp3{display:block;margin-top:6px;}.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}토스 해외 결제 하는 법\n2. 해외 결제를 위한 동의를 진행하면 해외 결제 준비가 모두 끝나요. \n\n3. 결제하려는 나라를 눌러 선택하면 해외에서도 바로 결제할 수 있는 결제 바코드와 QR코드가 만들어지는데요. 편의점, 식당 등 알리페이+ 로고가 있는 모든 곳에서 바로 결제할 수 있어요.\n\n‘토스페이 해외결제’ 서비스를 이용하면 QR스캔으로 바로 결제할 수 있고, 원화로 결제되기 때문에 별도의 환전 절차도 필요 없어요.  현재 말레이시아, 일본, 싱가포르, 중국 등 총 42개 나라에서 토스페이로 결제할 수 있어요.",
        "content": "42개 나라의 알리페이+ 가맹점에서 사용할 수 있어요.",
        "contentSnippet": "42개 나라의 알리페이+ 가맹점에서 사용할 수 있어요.",
        "guid": "https://blog.toss.im/article/tosspay-offline-pay",
        "isoDate": "2024-06-24T06:15:00.000Z"
      },
      {
        "title": "고령 운전자 안전운전 교육부터 치매 안심 상담까지 ",
        "link": "https://blog.toss.im/article/money-policies-14",
        "pubDate": "Fri, 21 Jun 2024 01:47:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}고령 시대를 맞이한 한국, 어르신을 위한 다양한 정책적 지원을 마련하고 있어요. 크게 일자리 정책과 돌봄 정책으로 나눠 소개합니다.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}활기찬 노후 생활을 위한 일자리 정책\n⓵ 신중년 경력형 일자리\n50세 이상 70세 미만, 경력과 자격이 있지만 현재는 미취업 상태인 신중년을 위한 재취업 지원 제도예요. \n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}최저임금 이상의 임금(주휴 수당, 연차수당 포함)과 4대 보험 가입을 지원해요. 단 자치단체별로 일자리 사업의 세부 계획과 근로 시간, 임금 수준 등이 다를 수 있어요. 고용노동부 (1350, moel.go.kr)에 문의해주세요.\n⓶ 노인 일자리 및 사회활동 지원\n어르신들이 경력과 능력에 맞는 일자리 혹은 사회 활동에 참여할 수 있도록 지원해요. \n(1) 노노케어, 취약계층 지원봉사 등 노인이 지역 사회에 기여하고 성취감을 얻을 수 있는 ‘공익 활동' \n(2) 취약계층 돌봄, 안전 등 공공 서비스를 제공하는 ‘사회 서비스형' 일자리 \n(3) 민간 기업이나 시장형사업단 등에 취업을 알선하거나 인턴 기회를 제공하는 ‘민간형’ 으로 구분돼요. \n\n주소지 행정복지센터나 노인복지관, 시니어클럽, 대한노인회 지회 등에서 신청할 수 있어요.\n⓷ 고령 운전자 교통 안전 교육\n일자리와 직접 관련은 없지만, 65세 이상 운전자가 운전에 필요한 인지 능력을 가지고 있는지 검사하고 안전 교육을 받을 수 있는 프로그램이에요. \n65세 이상 운전자는 모두 참여할 수 있고, 75세 이상 운전자 중 면허 갱신 대상자는 의무적으로 안전교육을 받아야 해요. 도로교통공단 통합민원실(1577-1120) 또는 경찰청 콜센터(182)를 통해 자세한 내용을 확인해보세요.\n건강한 노후를 위한 돌봄 정책\n⓸ 노인 장기요양 시설 및 재가 서비스\n65세 이상이거나 노인성 질병을 앓아 장기요양등급 판정을 받았다면 맞춤형 돌봄 서비스를 받을 수 있어요. \n노인요양시설에서 지내는 경우 장기요양 급여비용의 20%는 본인이 부담하고, 가정에 머물면서 방문 요양, 목욕, 간호 지원 등을 받는 수급자는 15%를 본인이 부담해요. 기초생활수급자나 저소득층은 본인부담금을 경감 또는 면제 받을 수 있어요. 국민건강보험공단을 통해 신청할 수 있습니다.\n⓹ 치매 안심센터 & 치매상담 콜센터\n전국 256개 치매 안심센터에서는 예방, 상담, 조기 진단, 교육까지 치매에 대한 두려움을 해소하고, 보호와 관리에 관한 정보를 얻을 수 있어요. \n치매 상태에 따른 인지 및 신체 활동 프로그램을 운영하고, 치료 관리비, 기저귀, 물티슈 등을 제공해요. 치매노인이 성년후견제도를 이용할 수 있도록 지원하기도 해요. \n또 치매상담콜센터(1899-9988)에서는 전문상담사로부터 전화 상담을 받을 수 있어요.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 정경화 Graphic 조수희",
        "content": "100세 시대를 준비하는 실버 정책",
        "contentSnippet": "100세 시대를 준비하는 실버 정책",
        "guid": "https://blog.toss.im/article/money-policies-14",
        "isoDate": "2024-06-21T01:47:00.000Z"
      },
      {
        "title": "모디노믹스, 경제 대국 인도로 향할 수 있을까",
        "link": "https://blog.toss.im/article/economic-terms-18-modinomics",
        "pubDate": "Thu, 20 Jun 2024 02:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-8atqhb{width:100%;}.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}💡 이 글이 필요한 순간\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1kxrhf3{white-space:pre-wrap;}급성장중인 인도 경제 현황에 대해 좀더 자세히 알고 싶을 때\n모디노믹스가 우리나라에 어떤 영향을 주는지 궁금할 때\n\n.css-1c1qox8{font-size:30px;letter-spacing:0em;line-height:1.55;font-weight:bold;color:var(--adaptiveGrey900);margin:40px 0 4px;}\n.css-p4abj2{display:contents;line-height:1.55;}🔖 이번 주 경제 용어\n모디노믹스\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n이번 주 경제 용어는 글로벌 경제를 파악하기 위해 필요한 정보예요.\n\n.css-1pgssrp{max-width:100%;border-radius:16px;}\n인도 총리 나렌드라 모디가 추진하는 경제정책이에요.\n\n\n인도 경제는 최근 몇 년간 눈에 띄는 성장을 이루며 글로벌 시장에서 주목받고 있습니다. 14억 인구의 강력한 내수 시장과 젊은 노동 인구, 그리고 강화된 제조 및 서비스 산업 덕분에 인도는 2022년 1분기에 세계 GDP 순위에서 영국을 제치고 5위를 차지했어요.\n전문가들은 인도가 몇 년 내로 일본을 추월하여 세계 4위 경제 대국이 될 것으로 보고 있으며, 이미 2023년에는 인구 수에서 중국을 추월하여 세계 1위가 되었습니다. 이러한 인구 구조적 장점을 바탕으로 인도는 '세계의 공장'으로서의 위치를 확고히 할 것으로 예상됩니다.\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}인도는 나렌드라 모디 총리의 리더십 하에 인도는 글로벌 제조업 허브로 변모하고자 하는 야심찬 계획을 추진해 왔는데요. 테슬라, 애플, 현대자동차와 같은 세계적인 기업들을 유치하기 위한 노력이 계속되고 있습니다. 이러한 기업들은 인도의 방대한 인구와 성장하는 소비 시장을 고려하여 대규모 투자를 검토하고 있어요.\n이 외에도 모디 총리는 인도의 인프라를 개선하기 위해 '스마트 시티(Smart City)' 정책을 추진했고, 농산물 유통 체계를 개선하고 농업 기술 개발을 지원하는 등 농업 개혁을 실시했습니다. 인도의 디지털 경제를 육성하기 위해 '디지털 인디아(Digital India)' 정책도 추진하고 있고요.\n이러한 정책들은 모두 '모디노믹스 (Modinomics)' 라는 용어로 집약됩니다. 나렌드라 모디(Narendra Modi)이름과 '경제학(Economics)'을 결합한 말로 인도 경제의 새로운 방향을 상징하고 있습니다.\n\n\n.css-2yhypk{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);font-style:italic;-webkit-text-decoration:underline!important;text-decoration:underline!important;}인도 총선, 여권 연합 승리 확정… 모디 총리 3연임 가닥\n(조선비즈 2024.06.05)\n나렌드라 모디 인도 총리가 4일(현지시각) 여당 연합인 국민민주연합(NDA)의 총선 승리를 선언하며 자축했다.\n이날 로이터통신에 따르면 모디 총리는 “국민들의 열망을 이루기 위해 우리는 새로운 에너지, 새로운 열정, 새로운 결의로 전진할 것임을 확신한다”고 말했다. 이어 “모든 노동자들의 헌신과 지칠 줄 모르는 노력에 대해 진심으로 감사와 축하를 표한다”고 했다.\n모디 총리는 소셜미디어 엑스(X)에도 “국민들이 3회 연속으로 여권 연합인 NDA를 믿어 줬다”며 “이는 인도 역사상 가장 역사적인 위업”이라고 평가했다. 인도 선거관리위원회에 따르면 NDA는 총 543개 의석 중 최소 291석을 확보해 과반을 차지했다.\n모디 총리의 총리직 3연임도 가시화됐다. 인도국민당(BJP) 대변인은 “NDA는 3기 정부를 구성하게 된다. 모디 총리가 3번째로 취임한다”고 밝혔다. 인도 정치사에서 3연임을 달성한 총리는 자와할랄 네루 초대 총리 이래 최초다.\n당초 현지에서는 여당 연합이 과반 의석을 차지하더라도 모디 총리의 소속 정당 BJP의 성적이 저조하면 총리직에 대한 입지가 흔들릴 것이라는 관측이 나왔다. 그러나 NDA는 BJP가 단독 과반을 얻지 못할 것이라는 전망 속에서도 모디 총리에 대한 지지를 표명하며 가능성을 일축했다.(중략)\n\n\n인도는 의원내각제 국가로 상하원 선거를 진행합니다. 인도 하원 의원은 임기가 5년이며 국민의 직접 선거를 통해 선출돼요. 하원 의석수는 총 543석이고, 올해 4월 19일부터 6월 1일까지 진행된 인도 총선이 바로 하원 의원을 뽑는 선거였습니다. 하원 의석 다수를 차지한 정당이 집권하며, 집권당 당수가 총리로 선출되는 방식이에요.\n6월 4일에 발표된 인도 총선 결과는 많은 이들에게 놀라움을 주었습니다. 여당 연합인 국민민주연합(NDA)가 승리했으나, 나렌드라 모디 총리가 이끄는 인도국민당(BJP)은 240석 획득에 그쳐 2014년 집권 이후 처음으로 단독 과반 확보에 실패했기 때문입니다.\n이는 모디 총리에게 세 번째 임기 동안 모디노믹스를 강력하게 추진하는 데 어려움을 줄 수 있습니다. 선거 결과에 영향을 준 요인으로는 ➀무슬림 커뮤니티의 반발 격화, ➁경제 성장에 따른 부의 격차 확대, ➂치솟은 물가 등이 꼽힙니다.\n다만 현 총리인 모디 총리가 압도적인 표차로 이긴 게 아니라서, 인도 증시에 일시적인 불안정성을 가져왔습니다. 하지만 장기적인 관점에서 볼 때 투자의 좋은 기회가 될 수도 있습니다. 모디 총리의 경제 정책인 '모디노믹스'는 여전히 제조업 부흥을 목표로 하고 있고, 이번 선거 결과가 그 방향성에는 크게 영향을 주지 않았다는 평가를 받고 있거든요.\n또한, 모디 정부는 인프라 투자를 포함한 여러 경제 활성화 조치를 예고하고 있는데요. 이는 국민의 소비력을 높이고 시장을 활성화하는 데 기여할 것으로 기대되고 있답니다. 이러한 조치들은 인도 증시에 장기적인 투자 기회를 제공할 수 있음을 시사하고 있어요.\n\n\n레이거노믹스(Reaganomics): 미국의 제 40대 대통령인 로널드 레이건이 추진한 경제 정책. .css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}세출의 삭감, 소득세의 대폭 감세, 기업에 대한 정부 규제의 완화, 안정적인 금융 정책 등이 핵심이라 볼 수 있어요.\n대처리즘(Thatcherism): 영국의 전 총리 마거릿 대처가 추진한 경제 정책. 자유시장 경제를 중시하고 정부의 개입을 최소화하는 것이 특징이에요.\n아베노믹스(Abenomics): 일본의 전 총리 아베 신조가 추진한 경제 정책. 20년 가까이 이어져 온 디플레이션과 엔고(円高) 탈출을 위해, 대규모 양적 완화와 재정지출 확대, 구조 개혁 등을 시행했어요.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 금혜원 Graphic 조수희 이동건",
        "content": "인도 경제는 최근 몇 년간 눈에 띄는 성장을 이루며 글로벌 시장에서 주목받고 있어요.",
        "contentSnippet": "인도 경제는 최근 몇 년간 눈에 띄는 성장을 이루며 글로벌 시장에서 주목받고 있어요.",
        "guid": "https://blog.toss.im/article/economic-terms-18-modinomics",
        "isoDate": "2024-06-20T02:00:00.000Z"
      },
      {
        "title": "걸그룹이 시청률 1% ‘음방’을 포기하지 못하는 이유",
        "link": "https://blog.toss.im/article/girl-groups-economics-08",
        "pubDate": "Wed, 19 Jun 2024 00:05:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}📌 .css-q3ktjb{white-space:pre-wrap;font-weight:bold;}이 글에서 알 수 있는 것들\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n걸그룹의 가요 프로그램 출연이 가져다주는 경제적 효과\n경제 용어 ‘버핏 효과’의 의미 \n\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n얼마전 보이그룹 빅톤 출신 도한세는 팬들과의 소통 플랫폼인 버블을 통해 이렇게 말했다.\n“음방(음악 방송) 너무 좋지. 그런데 그거야말로 수지타산이 안 맞는다. 2세대 선배님들처럼 홍보 효과가 엄청난 것도 아니고 1주 돌면 1,000만 원이 든다. 거기다 컴백하려면 멋있어야 되니까 세트 짓고 이러면 플러스 알파다. 헤어 메이크업비, 스타일링비, 현장 스태프들 식비, 간식비, 음료비 하면 2,000만 원도 든다. 그런데 그렇게라도 홍보해야 되니까 하는 거다.”\n실제 기획사 사람들 반응도 비슷했다. 도한세의 지적대로 비용 문제를 힘들어했다. 특히 부담이 되는 것이 무대 의상 비용이라고 했다. “방송국마다 다른 의상을 입어야 해요. MBC에 입고 나간 옷을 SBS에도 입고 가면 PD들이 싫어하거든요.” \n한 벌에 수십에서 수백만 원이 드는 의상을 멤버당 4벌씩은 갖춰야 하니, 트와이스처럼 9인조로 활동하는 경우라면 만만히 볼 문제가 아니다. 그에 비해 받는 돈은 팀당 5~20만 원 수준으로, 20년째 고정이다. ‘거마비’라고도 불리는 교통비다.\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}사실 돈은 정작 큰 문제가 아니다. 가요 프로그램 출연을 망설이게 만드는 결정적 요인은 바로 시청률이다. KBS의 간판 음악 프로그램 〈뮤직뱅크〉의 평균 시청률은 1%를 넘지 못한 지 오래다. \n2024년 5월 24일 기준 〈뮤직뱅크〉의 시청률은 0.4%. 소위 애국가 시청률 수준이다. 2세대 걸그룹들이 활동하던 2007~2012년, 시청률이 20~30%를 넘나들었던 것과 비교하면 터무니없이 낮다.\n그럼에도 이들이 지상파 가요 프로그램을 끊을 수 없는 이유, 도한세가 “그런데 그렇게라도 홍보해야 되니까 하는 거다”라고 말한 이유는 분명 존재한다.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n그의 입에 한번 오르기만 하면 뜬다\n버핏 효과\n신문 경제 기사에 간간이 등장하는 ‘버핏 효과(Buffet Effect)’라는 용어가 있다. ‘오마하의 현인’으로 불리는 미국의 전설적인 투자가 워런 버핏이 투자 대상에 대해 낙관적인 발언을 하거나 투자했다는 사실이 알려지면 주식 가치가 급등하는 현상을 말한다.\n과거 애플도 버핏 효과로 기사회생한 적이 있다.\n.css-2sk6rv{font-size:19px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);white-space:pre-wrap;margin:24px 0;padding-left:20px;position:relative;}.css-2sk6rv::before{content:'';display:block;position:absolute;top:4px;left:0;width:2px;height:calc(100% - 4px * 2);padding:4px 0;background-color:var(--adaptiveGrey800);}\n“애플 주가는 지난달 중순 이후 19%나 떨어졌다. 아이폰 판매 부진으로 지난 분기 매출이 13년 만에 처음으로 감소한 데다 지난달 28일에는 ‘행동주의 투자자’ 칼 아이칸이 애플 주식을 모두 처분했다고 밝히는 등 악재가 많았다. 이런 가운데 워런 버핏의 주식 매입이라는 새로운 호재가 등장하면서 애플 주가는 증시 개장 직후부터 상승하기 시작했다. 애플은 16일(현지시간) 버핏 회장의 버크셔 해서웨이가 투자했다는 소식에 전날 대비 3.71% 오르며 93.88달러에 마감했다. 지난 3월 1일 이후 2개월 15일 만에 일일 최대 상승 폭을 기록했다.” \n–<중앙일보>, 2016년 5월 17일.css-7mseny>*{margin-left:0;margin-right:0;}.css-7mseny>:last-child{margin-bottom:0;}blockquote>.css-7mseny:first-child>:first-child{margin-top:0;}\n워런 버핏은 지난 2000년부터 심지어 자신과 함께 하는 점심식사를 경매에 붙이는 기막힌 짓을 했는데, 이게 또 히트를 쳤다. 경매 낙찰자는 미국 뉴욕에 있는 스테이크 하우스 ‘Smith& Wollensky’에서 버핏과 세 시간 동안 점심식사를 하는데, 이 자리에는 동반자를 7명까지 데려갈 수 있다.\n첫 해 2만 5,000달러로 시작한 이 점심은 매년 가격이 상승하더니 올해는 익명을 요구한 낙찰자가 267만 9,001달러(약 37억 원)를 내고 기회를 잡았다. 버핏은 이 수익금을 모두 홈리스 자선단체 글라이드파운데이션에 전달했는데, 지금까지 기부한 액수가 2,000만 달러 정도 된다고 한다.\n제아무리 물가가 높은 뉴욕이라지만 스테이크 가격은 기껏해야 100~200달러 수준일 테니 이 식사의 가격은 거품이 잔뜩 낀 셈이다. 그럼에도 사람들이 원래 가격의 수만 배를 지불하면서까지 버핏과 식사하려고 하는 데는 이유가 있다. 바로 이 식사를 통해 그 이상의 가치를 얻을 수 있기 때문이다.\n2008년 중국인 자오단양(趙丹陽)은 211만 달러를 내고 버핏과의 점심식사를 낙찰 받았다. 그는 버핏에게 자신의 슈퍼마켓 체인점 ‘우메이상업’에 대해 조언을 구하겠다고 공언했는데, 이 소식이 매스컴을 통해 투자자들에게 알려지면서 주가가 급등하기 시작했다. \n이후 2008년 말 자오단양은 우메이상업의 지분을 매각하고 1,600만 달러 가량의 이득을 얻었다. 버핏과 함께 이름이 오르내린 것만으로 1,400만 달러(약 193억 원) 차익을 거둔 셈이니 진정한 버핏 효과를 누린 셈이다.\n걸그룹들의 버핏, 지상파 가요 프로그램\n걸그룹들이 ‘울며 겨자먹기’로 지상파 가요 프로그램에 출연하는 이유도 사람들이 어떻게든 버핏과 밥 한 끼 먹으려는 상황과 다르지 않다. 무대에 오르고 순위에 들어 한번이라도 더 이름이 언급되는 데서 파생되는 경제적 효과가 크기 때문이다.\n케이블 TV와 인터넷이 제대로 보급되지 않았던 시절, 지상파 가요 프로그램 1위의 위력은 더 말할 나위 없이 강력했다. “1위에 오른 다음 날 음반사에서 대금을 회수해 가라는 전화를 받고 갔다가 1만 원이 가득 든 쌀자루를 트렁크에 담고 돌아왔다”라는 무용담이 회자될 정도였다.\n물론 그런 무용담은 더이상 먹히지 않지만, 지상파 가요 프로그램은 여전히 걸그룹들에게 ‘버핏’ 같은 존재다. 가요계 관계자에 따르면 가요 프로그램에 한 번 출연하는 것만으로도 행사 출연료가 3~4배씩 뛴단다. \n게다가 요즘에는 해외 팬들도 국내 가요 프로그램을 챙겨 보고, 그 순위를 인기를 가늠하는 척도로 삼으면서 버핏 효과는 더 커지고 있다.\n여기서 궁금한 점이 하나 생긴다. 가요 프로그램 1위와 ‘아는 형님’ 같은 예능 프로그램 출연 가운데 어느 쪽의 버핏 효과가 더 클까? \n기획사들은 열이면 열, “가요 프로그램 1위가 훨씬 힘이 세다”고 했다. 한 기획사의 이사는 “지상파에서 1위를 하면 행사비가 10배는 올라요”라며 가요 프로그램이 가진 파워를 수치로 말해주었다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n2021년 3월 데뷔 10년 만에 처음으로 SBS ‘인기가요’ 1위에 오른 브레이브걸스는 이후 광고를 스무 편 넘게 찍었다.\n지상파 가요 프로그램 1위라는 영예는 금전적 측면뿐 아니라 가수로서의 ‘존엄’이 더해지면서 이후 롱런에도 결정적인 도움이 된다고 한다. “아무리 예능에 많이 출연한다고 하더라도 가요 프로그램에서 순위가 좋지 않으면 한계가 있어서 오래 가지 못해요.”\n이 역시 브레이브걸스가 증명했다. 브레이브걸스는 2021년에 지상파 가요프로그램에서 9차례나 1위에 올랐다. ‘롤린’으로 6차례, ‘치맛바람’으로 3차례였다. 하지만 2022년부터는 다시 1위에 오르지 못했고, 광고도 역시 급감했다. 예능 프로그램에 여러 번 출연했지만 큰 도움이 되지 않았다.\n\n최근 무섭게 치고 올라온 걸그룹 QWER도 마찬가지다. QWER은 5월 4일 MBC ‘음악중심’에서 1위 후보에 올랐다. 이들이 방송 활동을 거의 하지 않는다는 점, 유튜버 김계란이 만든 ‘최애의 아이들’이라는 프로젝트로 만들어진 걸그룹이라는 점을 감안하면 대단한 성과다.\nQWER은 5월 대학 축제 섭외 1순위 걸그룹으로 떠올랐는데, 그럼에도 구글 트렌드에서 검색량이 최고치에 올랐던 것은 역시 5월 4일, 그러니까 MBC ‘음악중심’에서 1위 후보에 오른 날이다.\n가요 프로그램 시청률이 아무리 바닥을 기어도, 걸그룹들이 가요 프로그램 출연으로 파생되는 버핏 효과를 포기할 수 없는 이유다.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nData 바이브컴퍼니 김종민\nEdit 정경화 Graphic 조수희 함영범",
        "content": "가요 순위 프로그램과 버핏 효과",
        "contentSnippet": "가요 순위 프로그램과 버핏 효과",
        "guid": "https://blog.toss.im/article/girl-groups-economics-08",
        "isoDate": "2024-06-19T00:05:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]