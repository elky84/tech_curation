[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Taming the tail utilization of ads inference at Meta scale",
        "link": "https://engineering.fb.com/2024/07/10/production-engineering/tail-utilization-ads-inference-meta/",
        "pubDate": "Wed, 10 Jul 2024 20:30:26 +0000",
        "content:encodedSnippet": "Tail utilization is a significant system issue and a major factor in overload-related failures and low compute utilization.\nThe tail utilization optimizations at Meta have had a profound impact on model serving capacity footprint and reliability. \nFailure rates, which are mostly timeout errors, were reduced by two-thirds; the compute footprint delivered 35% more work for the same amount of resources; and p99 latency was cut in half.\nThe inference platforms that serve the sophisticated machine learning models used by Meta’s ads delivery system require significant infrastructure capacity across CPUs, GPUs, storage, networking, and databases. Improving tail utilization – the utilization level of the top 5% of the servers when ranked by utilization– within our infrastructure is imperative to operate our fleet efficiently and sustainably.\nWith the growing complexity and computational intensity of these models, as well as the strict latency and throughput requirements to deliver ads, we’ve implemented system optimizations and best practices to address tail utilization. The solutions we’ve implemented for our ads inference service have positively impacted compute utilization in our ads fleet in several ways, including increasing work output by 35 percent without additional resources, decreasing timeout error rates by two-thirds, and reducing tail latency at p99 by half.\nHow Meta’s ads model inference service works \nWhen placing an ad, client requests are routed to the inference service to get predictions. A single request from a client typically results in multiple model inferences being requested, depending on experiment setup, page type, and ad attributes. This is shown below in figure 1 as a request from the ads core services to the model inference service. The actual request flow is more complex but for the purpose of this post, the below schematic model should serve well.\nThe inference service leverages Meta infrastructure capabilities such as ServiceRouter for service discovery, load balancing, and other reliability features. The service is set up as a sharded service where each model is a shard and multiple models are hosted in a single host of a job that spans multiple hosts.\nThis is supported by Meta’s sharding service, Shard Manager, a universal infrastructure solution that facilitates efficient development and operation of reliable sharded applications. Meta’s advertising team leverages Shard Manager’sload balancing and shard scaling capabilities to effectively handle shards across heterogeneous hardware.\nFigure 1: The ads inference architecture.\nChallenges of load balancing\nThere are two approaches to load balancing: \nRouting load balancing – load balancing across replicas of a single model. We use ServiceRouter to enable routing based load balancing. \nPlacement load balancing – balancing load on hosts by moving replicas of a model across hosts.\nFundamental concepts like replica estimation, snapshot transition and multi-service deployments are key aspects of model productionisation that make load balancing in this environment a complex problem.\nReplica estimation\nWhen a new version of the model enters the system, the number of replicas needed for the new model version is estimated based on historical data of the replica usage of the model.\nSnapshot transition\nAds models are continuously updated to improve their performance. The ads inference system then transitions traffic from the older model to the new version. Updated and refreshed models get a new snapshot ID. Snapshot transition is the mechanism by which the refreshed model replaces the current model serving production traffic.\nMulti-service deployment\nModels are deployed to multiple service tiers to take advantage of hardware heterogeneity and elastic capacity.\nWhy is tail utilization a problem?\nTail utilization is a problem because as the number of requests increases, servers that contribute to high tail utilization become overloaded and fail, ultimately affecting our service level agreements (SLAs). Consequently, the extra headroom or buffer needed to handle increased traffic is directly determined by the tail utilization. \nThis is challenging because it leads to overallocation of capacity for the service. If demand increases, capacity headroom is necessary in constrained servers to maintain service levels when accommodating new demand. Since capacity is uniformly added to all servers in a cluster, generating headroom in constrained servers involves adding significantly more capacity than required for headroom.\nIn addition, tail utilization for most constrained servers grows faster than lower percentile utilization due to the non linear relationship between traffic increase and utilization. This is the reason why more capacity is needed even while the system is under utilized on average.\nMaking the utilization distribution tighter across the fleet unlocks capacity within servers running at low utilization, i.e. the fleet can support more requests and model launches while maintaining SLAs.\nFigure 2: Divergence in the tail utilization distribution across percentile ranges.\nHow we optimized tail utilization \nThe implemented solution comprises a class of technical optimizations that attempt to balance the objectives of improving utilization and reducing error rate and latency.\nThe improvements made the utilization distribution tighter. This created the ability to move work from crunched servers to low utilization servers and absorb increased demand. As a result, the system has been able to absorb up to 35% load increase with no additional capacity.\nFigure 3: Convergence of tail utilization distribution across percentiles.\nThe reliability also improved, reducing the timeout error rate by two-thirds and cutting latency by half.\nFigure 4: System reliability over time.\nThe solution involved two approaches: \nTuning load balancing mechanisms\nMaking system level changes in model productionisation. \nThe first approach is well understood in the industry. The second one required significant trial, testing, and nuanced execution.\nTuning load balancing mechanisms\nThe power of two choices\nThe service mesh, ServiceRouter, provides detailed instrumentation that allows a better understanding of the load balancing characteristics. Specifically relevant to tail utilization is suboptimal load balancing because of load staleness. To address this we leveraged the power of two choices in a randomized load balancing mechanism. This algorithm requires load data from the servers. This telemetry is collected either by polling – query server load before request dispatch; or by load-header –  piggyback on response. \nPolling provides fresh load, while it adds an additional hop, but on the other side, load-header results in reading stale load. Load staleness is a significant issue for large services with substantial clients. Any error here due to staleness would result in random load balancing. For polling, given the inference request is computationally expensive, the overhead was found to be negligible. Using polling improved tail utilization noticeably because heavily loaded hosts were actively avoided. This approach worked very well specifically for inference requests greater than 10s of milliseconds.\nServiceRouter provides various tuning load-balancing capabilities. We tested many of these techniques, including the number of choices for server selection (i.e., power of k instead of 2), backup request configuration, and hardware-specific routing weights. \nThese changes offered marginal improvements. CPU utilization as load-counter was especially insightful. While it is intuitive to balance based on CPU utilization, it turned out to be not useful because: CPU utilization is aggregated over some period of time versus the need for instant load information in this case; and outstanding active tasks waiting on I/O were not taken into account correctly.\nPlacement load balancing\nPlacement load balancing helped a lot. Given the diversity in model resource demand characteristics and machine resource supply, there is significant variance in server utilization. There is an opportunity to make the utilization distribution tighter by tuning the Shard Manager load balancing configurations, such as load bands, thresholds, and balancing frequency. The basic tuning above helped and provided big gains. It also exposed a deeper problem like spiky tail utilization, which was hidden behind the high tail utilization and was fixed once identified .\nSystem level changes\nThere wasn’t a single significant cause for the utilization variance and several intriguing issues emerged among them that offered valuable insights into the system characteristics. \nMemory bandwidth\nCPU spikes were observed when new replicas, placed on hosts already hosting other models, began serving traffic. Ideally, this should not happen because Shard Manager should only place a replica when the resource requirements are met. Upon examining the spike pattern, the team discovered that the stall cycles were increasing significantly. Using dynolog perf instrumentations, we determined that memory latency was increasing as well, which aligned with memory latency benchmarks.\nMemory latency starts to increase exponentially at around 65-70% utilization. It appears to be an increase in CPU utilization, but the actual issue was that the CPU was stalling. The solution involved considering memory bandwidth as a resource during replica placement in Shard Manager. \nServiceRouter and Shard Manager expectation mismatch\nThere is a service control plane component called ReplicaEstimator that performs replica count estimation for a model. When ReplicaEstimator performs this estimation, the expectation is that each replica roughly receives the same amount of traffic. Shard Manager also works under this assumption that replicas of the same model will roughly be equal in their resource usage on a host. Shard Manager load balancing also assumes this property. There are also cases where Shard Manager uses load information from other replicas if load fetch fails. So ReplicaEstimator and Shard Manager share the same expectation that each replica will end up doing roughly the same amount of work.\nServiceRouter employs the default load counter, which encompasses both active and queued outstanding requests on a host. In general, this works fine when there is only one replica per host and they are expected to receive the same amount of load. However, this assumption is broken due to multi-tenancy, resulting in each host potentially having different models and outstanding requests on a host cannot be used to compare load as it can vary greatly. For example, two hosts serving the same model could have completely different load metrics leading to significant CPU imbalance issues.\nThe imbalance of replica load created because of the host level consolidated load counter violates Shard Manager and ReplicaEstimator expectations. A simple and elegant solution to this problem is a per-model load counter. If each model were to expose a load counter based on its own load on the server, ServiceRouter will end up balancing load across model replicas, and Shard Manger will end up more accurately balancing hosts. Replica estimation also ends up being more accurate. All expectations are aligned. \nSupport for this was added to the prediction client by explicitly setting the load counter per model client and exposing appropriate per model load metric on the server side. The model replica load distribution as expected became much tighter with a per-model load counter and helps with the problems discussed above.\nBut this also presented some challenges. Enabling per-model load counter changes the load distribution instantaneously, causing spikes until Shard Manager catches up and rebalances. The team built a mechanism to make the transition smooth by gradually rolling out the load counter change to the client. Then there are models with low load that end up having per-model load counter values of ‘0’, making it essentially random. In the default load counter configuration, such models end up using the host level load as a good proxy to decide which server to send the request to.\n“Outstanding examples CPU” was the most promising load counter among many that were tested. It is the estimated total CPU time spent on active requests, and better represents the cost of outstanding work. The counter is normalized by the number of cores to account for machine heterogeneity.\nFigure 5: Throughput as measured by requests per second across hosts in a tier.\nSnapshot transition\nSome ads models are retrained more frequently than others. Discounting real-time updated models, the majority of the models involve transitioning traffic from a previous model snapshot to the new model snapshot. Snapshot transition is a major disruption to a balanced system, especially when the transitioning models have a large number of replicas.\nDuring peak traffic, snapshot transition can have a significant impact on utilization. Figure 6 below illustrates the issue. The snapshot transition of large models during a crunched time causes utilization to be very unbalanced until Shard Manager is able to bring it back in balance. This takes a few load balancing runs because the placement of the new model during peak traffic ends up violating CPU soft thresholds. The problem of load counters, as discussed earlier, further complicates Shard Manager’s ability to resolve issues.\nFigure 6: A utilization spike due to the snapshot transition.\nTo mitigate this issue, the team added the snapshot transition budget capability. This allows for snapshot transitions to occur only when resource utilization is below a configured threshold. The trade-off here is between snapshot staleness and failure rate. Fast scale down of old snapshots helped minimize the overhead of snapshot staleness while maintaining lower failure rates.\nCross-service load balancing\nAfter optimizing load balancing within a single service, the next step was to extend this to multiple services. Each regional model inference service is made up of multiple sub-services depending on hardware type and capacity pools – guaranteed and elastic pools. We changed the calculation to the compute capacity of the hosts instead of the host number. This helped with a more balanced load across tiers. \nCertain hardware types are more loaded than others. Given that clients maintain separate connections to these tiers, ServiceRouter load balancing, which performs balancing within tiers, did not help. Given the production setup, it was non-trivial to put all these tiers behind a single parent tier. Therefore, the team added a small utilization balancing feedback controller to adjust traffic routing percentages and achieve balance between these tiers. Figure 7 shows  an example of this being rolled out.\nFigure 7: Request per service.\nReplica estimation and predictive scaling \nShard Manager employs a reactive approach to load by scaling up replicas in response to a load increase. This meant increased error rates during the time replicas were scaled up and became ready. This is exacerbated by the fact that replicas with higher utilization are more prone to utilization spikes given the non-linear relationship between queries per second (QPS) and utilization. To add to this, when auto-scaling kicks in, it responds to a much larger CPU requirement and results in over-replication. We designed a simple predictive replica estimation system for the models that predicts future resource usage based on current and past usage patterns up to two hours in advance. This approach yielded significant improvements in failure rate during peak periods. \nNext steps \nThe next step in our journey is to adopt our learnings around tail utilization to new system architectures and platforms. For example, we’re actively working to apply the utilizations discussed here to IPnext, Meta’s next-generation unified platform for managing the entire lifecycle of machine learning model deployments, from publishing to serving. IPnext’s modular design enables us to support various model architectures (e.g., for ranking or GenAI applications) through a single platform spanning multiple data center regions. Optimizing tail utilization within IPnext thereby delivering these benefits to a broader range of expanding machine learning inference use cases at Meta.\nThe post Taming the tail utilization of ads inference at Meta scale appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Tail utilization is a significant system issue and a major factor in overload-related failures and low compute utilization. The tail utilization optimizations at Meta have had a profound impact on model serving capacity footprint and reliability.  Failure rates, which are mostly timeout errors, were reduced by two-thirds; the compute footprint delivered 35% more work for [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/07/10/production-engineering/tail-utilization-ads-inference-meta/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/07/10/production-engineering/tail-utilization-ads-inference-meta/\">Taming the tail utilization of ads inference at Meta scale</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Tail utilization is a significant system issue and a major factor in overload-related failures and low compute utilization. The tail utilization optimizations at Meta have had a profound impact on model serving capacity footprint and reliability.  Failure rates, which are mostly timeout errors, were reduced by two-thirds; the compute footprint delivered 35% more work for [...]\nRead More...\nThe post Taming the tail utilization of ads inference at Meta scale appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21421",
        "categories": [
          "ML Applications",
          "Networking & Traffic",
          "Production Engineering"
        ],
        "isoDate": "2024-07-10T20:30:26.000Z"
      },
      {
        "creator": "",
        "title": "Meta’s approach to machine learning prediction robustness",
        "link": "https://engineering.fb.com/2024/07/10/data-infrastructure/machine-learning-ml-prediction-robustness-meta/",
        "pubDate": "Wed, 10 Jul 2024 13:00:37 +0000",
        "content:encodedSnippet": "Meta’s advertising business leverages large-scale machine learning (ML) recommendation models that power millions of ads recommendations per second across Meta’s family of apps. Maintaining reliability of these ML systems helps ensure the highest level of service and uninterrupted benefit delivery to our users and advertisers. To minimize disruptions and ensure our ML systems are intrinsically resilient, we have built a comprehensive set of prediction robustness solutions that ensure stability without compromising performance or availability of our ML systems. \nWhy is machine learning robustness difficult?\nSolving for ML prediction stability has many unique characteristics, making it more complex than addressing stability challenges for traditional online services: \nML models are stochastic by nature. Prediction uncertainty is inherent, which makes it difficult to define, identify, diagnose, reproduce, and debug prediction quality issues. \n\nConstant and frequent refreshing of models and features. ML models and features are continuously updated to learn from and reflect people’s interests, which makes it challenging to locate prediction quality issues, contain their impact, and quickly resolve them\n\nBlurred line between reliability and performance. In traditional online services, reliability issues are easier to detect based on service metrics such as latency and availability. However, ML prediction stability implies a consistent prediction quality shift, which is harder to distinguish. For example, an “available” ML recommender system that reliably produces inaccurate predictions is actually “unreliable.”\n\nCumulative effect of small distribution shifts over time. Due to the stochastic nature of ML models, small regressions in prediction quality are hard to distinguish from the anticipated organic traffic-pattern changes. However, if undetected, such small prediction regressions could have a significant cumulative negative impact over time. \nLong chain of complex interactions. The final ML prediction result is derived from a complex chain of processing and propagation across multiple ML systems. Regression in prediction quality could be traced back to several hops upstream in the chain, making it hard to diagnose and locate stability improvements per specific ML system. \nSmall fluctuations can amplify to become big impacts. Even small changes in the input data (e.g., features, training data, and model hyperparameters) can have a significant and unpredictable impact on the final predictions. This poses a major challenge in containing prediction quality issues at particular ML artifacts (model, feature, label), and it requires end-to-end global protection. \nRising complexity with rapid modeling innovations. Meta’s ML technologies are evolving rapidly, with increasingly larger and more complex models and new system architectures. This requires prediction robustness solutions to evolve at the same fast pace. \nMeta’s approach and progress towards prediction robustness\nMeta has developed a systematic framework to build prediction robustness. This framework includes a set of prevention guardrails to build control from outside-in, fundamental understanding of the issues to gain ML insights, and a set of technical fortifications to establish intrinsic robustness. \nThese three approaches are exercised across models, features, training data, calibration, and interpretability to ensure all possible issues are covered throughout the ML ecosystem. With prediction robustness, Meta’s ML systems are robust by design, and any stability issues are actively monitored and resolved to ensure smooth ads delivery for our users and advertisers. \nFigure 1: A simplified view of Meta’s ads recommendation system shows the flow of complex interactions for producing the final predictions.\nOur prediction robustness solution systematically covers all areas of the recommender system – training data, features, models, calibration, and interpretability. \nModel robustness\nModel robustness challenges include model snapshot quality, model snapshot freshness, and inferencing availability. We use Snapshot Validator, an internal-only real-time, scalable, and low-latency model evaluation system, as the prevention guardrail on the quality of every single model snapshot, before it ever serves production traffic. \nSnapshot Validator runs evaluations with holdout datasets on newly-published model snapshots in real-time, and it determines whether the new snapshot can serve production traffic. Snapshot Validator has reduced model snapshot corruption by 74% in the past two years. It has protected >90% of Meta ads ranking models in production without prolonging Meta’s real-time model refresh. \nIn addition, Meta engineers built new ML techniques to improve the intrinsic robustness of models, such as pruning less-useful modules inside models, better model generalization against overfitting, more effective quantization algorithms, and ensuring model resilience in performance even with a small amount of input data anomalies. Together these techniques have improved the ads ML model stability, making the models resilient against overfitting, loss divergence, and more.  \nFeature robustness\nFeature robustness focuses on guaranteeing the quality of ML features across coverage, data distribution, freshness, and training-inference consistency. As prevention guardrails, robust feature monitoring systems were in production to continuously detect anomalies on ML features. As the ML-feature-value distributions can change widely with non-deterministics sways on model performance, the anomaly detection systems have turned to accommodate the particular traffic and ML prediction patterns for accuracy. \nUpon detection, automated preventive measures will kick in to ensure abnormal features are not used in production. Furthermore, a real-time feature importance evaluation system is built to provide fundamental understanding of the correlation between feature quality and model prediction quality. \nAll these solutions have effectively contained ML feature issues on coverage drop, data corruption, and inconsistency in Meta. \nTraining data robustness\nThe wide spectrum of Meta ads products requires distinct labeling logics for model training, which significantly increases the complexity of labeling. In addition, the data sources for label calculation could be unstable, due to the complicated logging infrastructure and the organic traffic drifts. Dedicated training-data-quality systems were built as the prevention guardrails to detect label drifts over time with high accuracy, and swiftly and automatically mitigate the abnormal data changes and prevent models from learning the affected training data. \nAdditionally, fundamental understanding of training data label consistency has resulted in optimizations in training data generation for better model learning. \nCalibration robustness\nCalibration robustness builds real-time monitoring and auto-mitigation toolsets to guarantee that the final prediction is well calibrated, which is vital for advertiser experiences. The calibration mechanism is technically unique because it is unjoined-data real-time model training, and it is more sensitive to traffic distribution shifts than the joined-data mechanism. \nTo improve the stability and accuracy of calibration Meta has built prevention guardrails that consist of high-precision alert systems to minimize problem-detection time, as well as high-rigor, automatically orchestrated mitigations to minimize problem-mitigation time.\nML interpretability\nML interpretability focuses on identifying the root causes of all ML instability issues. Hawkeye, our internal AI debugging toolkit, allows engineers at Meta to root-cause tricky ML prediction problems. Hawkeye is an end-to-end and streamlined diagnostic experience covering all ML artifacts at Meta, and it has covered >80% of ads ML artifacts. It is now one of the most widely used tools in the Meta ML engineering community. \nBeyond debugging, ML interpretability invests heavily in model internal state understanding – one of the most complex and technically challenging areas in the realm of ML stability. There are no standardized solutions to this challenge, but Meta uses model graph tracing, which uses model internal states on model activations and neuron importance, to accurately explain why models get corrupted. \nAltogether, advancements in ML Interpretability have reduced the time to root-cause ML prediction issues by 50%, and have significantly boosted the fundamental understanding of model behaviors. \nImproving ranking and productivity with prediction robustness\nGoing forward, we’ll be extending our prediction robustness solutions to improve ML ranking performance, and boost engineering productivity by accelerating ML developments.\nPrediction robustness techniques can boost ML performance by making models more robust intrinsically, with more stable training, less normalized entropy explosion or loss divergence, more resilience to data shift, and stronger generalizability. We’ve seen performance gains from applying robustness techniques like gradient clipping and more robust quantization algorithms. And we will continue to identify more systematic improvement opportunities with model understanding techniques.\nIn addition, model performance will be improved with less staleness and stronger consistency between serving and training environments across labels, features, inference platform, and more. We plan to continue upgrading Meta’s ads ML services with stronger guarantees of training-serving consistency and more aggressive staleness SLAs. \nRegarding ML development productivity, prediction robustness techniques can facilitate model development, and improve daily operations by reducing the time needed to address ML prediction stability issues. We’re currently building an intelligent ML diagnostic platform that will leverage the latest ML technologies, in the context of prediction robustness, to help even engineers with little ML knowledge locate the root cause of ML stability issues within minutes. \nThe platform will also evaluate reliability risk continuously across the development lifecycle, minimizing delays in ML development due to reliability regressions. It will embed reliability into every ML development stage, from idea exploration all the way to online experimentation and final launches. \nAcknowledgements\nWe would like to thank all the team members and the leadership that contributed to make the Prediction Robustness effort successful in Meta. Special thanks to Adwait Tumbde, Alex Gong, Animesh Dalakoti, Ashish Singh, Ashish Srivastava, Ben Dummitt, Booker Gong, David Serfass, David Thompson, Evan Poon, Girish Vaitheeswaran, Govind Kabra, Haibo Lin, Haoyan Yuan, Igor Lytvynenko, Jie Zheng, Jin Zhu, Jing Chen, Junye Wang, Kapil Gupta, Kestutis Patiejunas, Konark Gill, Lachlan Hillman, Lanlan Liu, Lu Zheng, Maggie Ma, Marios Kokkodis, Namit Gupta, Ngoc Lan Nguyen, Partha Kanuparthy, Pedro Perez de Tejada, Pratibha Udmalpet, Qiming Guo, Ram Vishnampet, Roopa Iyer, Rohit Iyer, Sam Elshamy, Sagar Chordia, Sheng Luo, Shuo Chang, Shupin Mao, Subash Sundaresan, Velavan Trichy, Weifeng Cui, Ximing Chen, Xin Zhao, Yalan Xing, Yiye Lin, Yongjun Xie, Yubin He, Yue Wang, Zewei Jiang, Santanu Kolay, Prabhakar Goyal, Neeraj Bhatia, Sandeep Pandey, Uladzimir Pashkevich, and Matt Steiner. \nThe post Meta’s approach to machine learning prediction robustness appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Meta’s advertising business leverages large-scale machine learning (ML) recommendation models that power millions of ads recommendations per second across Meta’s family of apps. Maintaining reliability of these ML systems helps ensure the highest level of service and uninterrupted benefit delivery to our users and advertisers. To minimize disruptions and ensure our ML systems are intrinsically [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/07/10/data-infrastructure/machine-learning-ml-prediction-robustness-meta/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/07/10/data-infrastructure/machine-learning-ml-prediction-robustness-meta/\">Meta’s approach to machine learning prediction robustness</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Meta’s advertising business leverages large-scale machine learning (ML) recommendation models that power millions of ads recommendations per second across Meta’s family of apps. Maintaining reliability of these ML systems helps ensure the highest level of service and uninterrupted benefit delivery to our users and advertisers. To minimize disruptions and ensure our ML systems are intrinsically [...]\nRead More...\nThe post Meta’s approach to machine learning prediction robustness appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21437",
        "categories": [
          "Data Infrastructure",
          "ML Applications"
        ],
        "isoDate": "2024-07-10T13:00:37.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "eBay News Team",
        "title": "eBay Advertising Unveils New Dashboard, Personalized Insights, and Intuitive Campaign Tools",
        "link": "https://innovation.ebayinc.com/tech/features/ebay-advertising-helps-sellers-grow-their-business-with-introduction-of-new-dashboard-personalized-insights-and-intuitive-campaign-tools/",
        "pubDate": "Mon, 08 Jul 2024 00:00:00 -0700",
        "dc:creator": "eBay News Team",
        "content": "<div style=\"margin-bottom: 10px;\"><img src=\"https://static.ebayinc.com/static/assets/Uploads/Blog/Posts/_resampled/FitWzIwMCwxMTld/eBay-Ads-Experience2.jpg\" width=\"200\" height=\"119\" alt=\"eBay Advertising Unveils New Dashboard, Personalized Insights, and Intuitive Campaign Tools\" /></div><div>Introducing a reimagined, redesigned advertising experience to help sellers grow their business.</div>",
        "contentSnippet": "Introducing a reimagined, redesigned advertising experience to help sellers grow their business.",
        "guid": "https://innovation.ebayinc.com/tech/features/ebay-advertising-helps-sellers-grow-their-business-with-introduction-of-new-dashboard-personalized-insights-and-intuitive-campaign-tools/",
        "categories": [
          "article"
        ],
        "isoDate": "2024-07-08T07:00:00.000Z"
      },
      {
        "creator": "eBay News Team",
        "title": "eBay’s Magical Listing Tool Wins AI Breakthrough Award for ‘Best Overall Generative AI Solution’ ",
        "link": "https://innovation.ebayinc.com/tech/features/ebays-magical-listing-tool-wins-ai-breakthrough-award-for-best-overall-generative-ai-solution/",
        "pubDate": "Mon, 08 Jul 2024 00:00:00 -0700",
        "dc:creator": "eBay News Team",
        "content": "<div style=\"margin-bottom: 10px;\"><img src=\"https://static.ebayinc.com/static/assets/Uploads/Blog/Posts/_resampled/FitWzIwMCwxMTNd/240626-Magical-Listing-v1-1600x900.jpg\" width=\"200\" height=\"113\" alt=\"eBay’s Magical Listing Tool Wins AI Breakthrough Award for ‘Best Overall Generative AI Solution’ \" /></div><div>eBay’s magical listing experience uses generative AI to save sellers time and effort.</div>",
        "contentSnippet": "eBay’s magical listing experience uses generative AI to save sellers time and effort.",
        "guid": "https://innovation.ebayinc.com/tech/features/ebays-magical-listing-tool-wins-ai-breakthrough-award-for-best-overall-generative-ai-solution/",
        "categories": [
          "article"
        ],
        "isoDate": "2024-07-08T07:00:00.000Z"
      }
    ]
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Maria Kosukhina",
        "title": "IntelliJ IDEA 2024.2 Beta Is Out! ",
        "link": "https://blog.jetbrains.com/idea/2024/07/intellij-idea-2024-2-beta/",
        "pubDate": "Thu, 11 Jul 2024 22:17:51 +0000",
        "content:encodedSnippet": "We’ve just released the Beta version of IntelliJ IDEA 2024.2. This milestone brings us closer to the big release date, and you still have time to try out the new features through the Early Access Program.\n\n\n\n\nThe Beta build includes all of the new functionality detailed in our IntelliJ IDEA 2024.2 EAP blog posts. Here’s a recap of what’s coming in the new version of the IDE:\nFaster time to code \nImproved Kotlin K2 mode \nEnhanced AI Assistant code сompletion\nBetter log management for Java and Kotlin \nSupport for math syntax in Markdown \nImproved experience with Gradle build scripts\nMultiple improvements for version control systems \nString variable visualizers for JSON, XML, and other formats in the debugger\nEnhanced Spring Data JPA support\nImproved cron expression support\nGraalJS as the execution engine for the HTTP Client\nAutocompletion for Micronaut and Quarkus beans\nAnd much more\n\n\n\n\nDownload IntelliJ IDEA 2024.2 Beta\nWhile the team is currently polishing these features, we still have a few updates that haven’t been covered yet. Let’s take a look!\nKotlin \nEnhanced Gradle build script support\nIn IntelliJ IDEA 2024.2, we’ve significantly improved Gradle.kts support. This includes enabling scripting support for K2 mode, introducing support for TOML files, adding project module navigation, and providing type-safe dependency project accessors.\n\n\n\n\n\n\n\n\nCode coverage \nTest coverage for changes in the current feature branch\nIntelliJ IDEA 2024.2 further improves the ability to quickly check and improve test coverage locally without invoking a slow CI/CD pipeline.\nBy default, the Coverage tool window now shows only the classes that were changed in your current feature branch. This allows you to check the test coverage for your recent changes without browsing the entire project status.\nIf you’re interested in the entire project’s test coverage, you can disable the Show Only Modified Classes option to view all classes.\n\n\n\n\nFrameworks and technologies \nKtor development mode support in run configurations\nIntelliJ IDEA 2024.2 provides an easy way to enable Ktor’s development mode in run configurations. This mode is now set by default when creating a new run configuration and can be managed in the updated Run/Debug Configurations dialog. In addition, we’ve reworked this dialog so that now it features a cleaner and more user-friendly UI for Ktor users.\n\n\n\n\nThat’s it for now! For the full list of changes implemented in this build, refer to the release notes.\nAs we put the finishing touches on the major release, you still have a couple of weeks to test out the new features and help us ensure the final version runs smoothly. For this, we’d love to know what you think about the latest additions, so please share your opinions in the comments section below or on X (formerly Twitter). If you encounter any bugs, submit a report to our issue tracker. \nHappy developing!",
        "dc:creator": "Maria Kosukhina",
        "content": "We’ve just released the Beta version of IntelliJ IDEA 2024.2. This milestone brings us closer to the big release date, and you still have time to try out the new features through the Early Access Program. The Beta build includes all of the new functionality detailed in our IntelliJ IDEA 2024.2 EAP blog posts. Here&#8217;s [&#8230;]",
        "contentSnippet": "We’ve just released the Beta version of IntelliJ IDEA 2024.2. This milestone brings us closer to the big release date, and you still have time to try out the new features through the Early Access Program. The Beta build includes all of the new functionality detailed in our IntelliJ IDEA 2024.2 EAP blog posts. Here’s […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=492460",
        "categories": [
          "eap",
          "2024-2-eap",
          "intellij-idea-2024-2",
          "intellij-idea-2024-2-eap"
        ],
        "isoDate": "2024-07-11T22:17:51.000Z"
      },
      {
        "creator": "Khalid Abuhakmeh",
        "title": "Snapshot Testing in .NET with Verify",
        "link": "https://blog.jetbrains.com/dotnet/2024/07/11/snapshot-testing-in-net-with-verify/",
        "pubDate": "Thu, 11 Jul 2024 14:06:26 +0000",
        "content:encodedSnippet": "When writing tests, the ultimate goal should always be to deliver “value”. This value is not just about the number of tests written but about the quality and relevance of the tests. We aim to write, execute, and maintain valuable tests that instill confidence in our application’s ability to withstand the rigors of user production use. Throughout the history of software testing, several techniques have contributed their unique value proposition to the testing mythos. \nFor example, Unit tests help us focus on writing small and faster tests around the logical aspects of our application. Integration tests take several units and dependencies and attempt to see the outcome of their interactions. Manual tests take the unpredictability of a human user and help us see if our applications can handle the unexpected. \nEach testing approach can have a distinct style. Today, we’ll delve into snapshot testing, a practical technique you can apply to code-driven tests. It combines a few previously mentioned approaches, offering a uniquely practical test. By the end of this post, you’ll have a comprehensive understanding of snapshot testing with Verify, how to integrate it into your test suites seamlessly, and why we believe it’s a valuable addition to your testing toolkit.\nDownload Verify plugin for Rider\n                                                    \nWhat is snapshot testing?\nLogically, you typically center tests around asserting the state before and after a particular action occurs. If you’re familiar with unit testing, you’ve likely heard the phrase: “Arrange, Act, and Assert”. In terms of code, let’s look at a simple example to illustrate this construct.\n[Test]\npublic void Assert_apple_is_not_null()\n{\n    // arrange\n    Apple apple;\n\n    // act\n    apple = new Apple(\"Honey Crisp\", \"Yellow & Red\");\n\n    // assert\n    Assert.That(apple, Is.Not.Null);\n}\n\n\n\n\nIf we look at this code, it sets out to accomplish the test’s intent: asserting that the target is not null. But as you look closer, you realize some data points are unused in this test, mainly the name and color of the apple.\nSnapshot testing is different from a traditional test as it focuses on the result of an action and expects you, the test author, to verify the accuracy of the result. In the case of our apple example, we would run our test and verify that the entire apple is “correctly” created.\nLet’s look at an example of a snapshot test and what steps you would take to get a passing.\nThe first step is to write a test similar to the one above.\n[Test]\npublic Task Verify_apple_is_granny_smith()\n{\n    // arrange\n    var service = new AppleService();\n\n    // act \n    var apple = service.GetApple();\n \n    // verify    \n    return Verify(apple);\n}\n\n\n\n\nNote that the call to Verify takes the entire instance and has no assertions. The method call will produce a binary snapshot of the instance and write it to non-volatile storage, such as the file system.\n{\n  Name: Granny Smith,\n  Color: Green\n}\nFrom here, the first test run of a newly created test will always fail. As the author, you will look at this serialized result and verify that it meets your success requirements. If it does, you accept the results, and the test now passes. We’ll get into how you verify results later, as this can vary depending on the serialization method of the snapshot. In future test runs, if our code produces a different result, then the test will fail and require reverifying the snapshot or investigating why the change occurred in the first place.\nSnapshot testing is straightforward in concept yet a powerful approach to building valuable test suites. In the next section, we’ll see how to start with Verify, a .NET library focused on producing and maintaining snapshots.\nGetting started with Verify\nBefore updating your test projects, we highly recommend installing the excellent Verify Plug-in, developed by .NET Developer Advocate Matthias Koch (check out the livestream below). The plug-in adds Verify support for both JetBrains Rider and ReSharper for Visual Studio. Great, let’s start adding Verify to your test project.\n\n\n\n\n\n\nVerify supports most major unit testing libraries, including NUnit, xUnit, MSTest, and Expecto. You’ll need to install the matching Verify package in a test project of your choice. In my case, I’ll be using NUnit and will install Verify.NUnit.\nFor the sake of this demo, I’ll be testing an AppleService class.\npublic class AppleService\n{\n    public Apple GetApple() \n        => new Apple(\"Granny Smith\", \"Green\");\n}\n\npublic record Apple(string Name, string Color);\nNext, I’ll create a static method to set up some global settings for Verify. This step is optional but allows you to define some of the library’s many features. In my case, I’m putting snapshot artifacts under a snapshots directory.\npublic class Tests\n{\n    private static readonly VerifySettings Settings;\n    \n    static Tests()\n    {\n        Settings = new VerifySettings();\n        Settings.UseDirectory(\"snapshots\");\n    }\n}\n\n\n\n\nNext, let’s add our tests.\nnamespace SnapshotTests;\n\npublic class Tests\n{\n    private static readonly VerifySettings Settings;\n    \n    static Tests()\n    {\n        Settings = new VerifySettings();\n        Settings.UseDirectory(\"snapshots\");\n    }\n    \n    private readonly AppleService sut = new();\n\n    [Test]\n    public void Assert_apple_is_granny_smith()\n    {\n        var apple = sut.GetApple();\n        Assert.That(apple.Name, Is.EquivalentTo(\"Granny Smith\"));\n    }\n\n    [Test]\n    public Task Verify_apple_is_granny_smith()\n    {\n        // arrange\n        var service = new AppleService();\n        // act \n        var apple = service.GetApple(); \n        // verify    \n        return Verify(apple, Settings);\n    }\n}\n\n\n\n\nNote that we have a mixture of traditional unit tests and snapshot tests. These two methodologies are compatible, and we encourage you to think critically about which approach suits your goals.\nRunning our test, you’ll see that it immediately fails with a VerifyException.\n\n\n\n\nThis result is as expected. Let’s use the Verify plug-in to see the received result compared with the verified result. In the test window, right-click the failed test and use the menu to find Compare Received/Verified.\n\n\n\n\nOnce you’ve chosen Compare Received/Verified, your IDE’s comparison tool will launch, allowing you to see the variations between the received and verified results.\n\n\n\n\nIf it looks good to you, remember you’re the verifier of the snapshot, then you can right-click the failed test and choose Accept Received.\n\n\n\n\nRerunning the tests will lead to a passing test.\n\n\n\n\nCongratulations. You’ve successfully written your first snapshot test. Now, let’s talk about some frequently asked questions and answer them.\nCommon questions about snapshot testing\nWhen adopting snapshot tests, there are a few questions many developers commonly ask. We’ve gathered some of them here and will try to answer them.\nIs this “really” better than other styles of testing?\nSnapshot testing provides a different approach and, as mentioned earlier, is compatible with all testing approaches. Snapshots can offer more value over fewer tests and catch unintended changes you may miss when writing assertion-based tests. Like all things in life, snapshot testing has advantages and disadvantages.\nDo I have to check in the snapshots to source control?\nYes. Snapshots are binary artifacts necessary to fulfill the verification test you’ve written. Without these files, your test has nothing to assert against and will fail.\nWon’t that make my source control huge?\nThese snapshot files should not change so frequently that they cause significant binary changes in your source control. Text-based serialization is typically the default for Verify, so these files are compressed and efficiently stored.\nCan I fine-tune the verification process?\nAs you’ve seen in the above example, a VerifySettings class allows you to configure how verification occurs. Settings changes could include where snapshot files are stored, what fields are part of verification, and how binary serialization occurs.\nCan I verify more than just JSON objects?\nYes! Serializing anything is another strength of snapshot testing. The comparison can be between any two binary files, including PDFs, images, videos, or whatever your code can produce. Simon Cropp created an entire library of extensions for that purpose.\nCan I set Verify settings globally?\nYes, but you’ll need to use the ModuleInitializer attribute, which allows you to execute code once the code runtime has loaded an assembly.\npublic class StaticSettings\n{\n    [Fact]\n    public Task Test() =>\n        Verify(\"String to verify\");\n}\n\npublic static class StaticSettingsUsage\n{\n    [ModuleInitializer]\n    public static void Initialize() =>\n        VerifierSettings.AddScrubber(_ => _.Replace(\"String to verify\", \"new value\"));\n}\n\n\n\n\nConclusion\nVerify by Simon Cropp is a fantastic library for folks looking to enhance the value of their test suites. Also, remember to install the plug-in written by Matthias Koch for both ReSharper and JetBrains Rider for an improved verification workflow. We also love that all major testing libraries are supported with a massive library of extensions to verify a variety of test artifacts. We highly recommend you take a look.\nWe hope you learned something about snapshot testing. Please let us know in the comments below if you try it in your solutions.\nimage credit: Alexander Wende",
        "dc:creator": "Khalid Abuhakmeh",
        "content": "When writing tests, the ultimate goal should always be to deliver “value”. This value is not just about the number of tests written but about the quality and relevance of the tests. We aim to write, execute, and maintain valuable tests that instill confidence in our application&#8217;s ability to withstand the rigors of user production [&#8230;]",
        "contentSnippet": "When writing tests, the ultimate goal should always be to deliver “value”. This value is not just about the number of tests written but about the quality and relevance of the tests. We aim to write, execute, and maintain valuable tests that instill confidence in our application’s ability to withstand the rigors of user production […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=477058",
        "categories": [
          "net-tools",
          "c",
          "integration-testing",
          "resharper",
          "rider",
          "unit-testing"
        ],
        "isoDate": "2024-07-11T14:06:26.000Z"
      },
      {
        "creator": "Alena Guzharina",
        "title": "5 Emerging Data Job Trends in 2024",
        "link": "https://blog.jetbrains.com/datalore/2024/07/11/5-emerging-data-job-trends-in-2024/",
        "pubDate": "Thu, 11 Jul 2024 09:54:11 +0000",
        "content:encodedSnippet": "This is a guest blog post by Thu Vu. \nThe long-term outlook for data jobs – like data scientists, statisticians, and market research analysts – predicts explosive growth, much faster than most other fields. But here’s the catch: Despite the promising stats, data professionals are struggling to find jobs. AI is also shaking things up with capable LLMs, coding assistants, and loads of smart tools for data analytics.\n\n\n\n\nData source  \nSo, what does this mean for you as a data professional? What exactly has changed in the past one to two years? To try and find out, I spent 24 hours researching the data job market. \nIn this article, I’m going to share five key trends I’ve noticed in the market right now and detail what I would do to adapt to these changes. To view all the graphs in one place, click the link below: \n      \n      Open Datalore report\n    \n\n\n\n\n1. Data job postings are getting competitive but remain stable\nFirst up, let’s talk about the job market. You might be thinking – with all the tech layoffs we’ve been hearing about, surely data jobs must be taking a hit, right? Well, you might be surprised.\nSince the end of 2022, the number of jobs for data scientists, data analysts, and data engineers has decreased by about 15% but has remained quite stable since the beginning of this year. \nData source\nThis is pretty interesting, especially when you consider that the tech industry has experienced two big waves of layoffs since the COVID-19 pandemic – one at the beginning of 2023 and another at the beginning of 2024.\nData source\nBut if we lay this trend next to the tech layoffs, we can see that the data job posts didn’t seem to be affected much by the tech layoff trends.\nThis trend can also be observed per job title.\nData source\nCompared to the last two years, the job market is certainly more competitive, with companies being more selective. The uncertain economic growth and high interest rates are making companies tighten their budgets and seek skills that focus on efficiency and cost reduction. This might explain why it feels harder to land a job today.\nDon’t let that discourage you, though! It just means we need to be smarter about how we position ourselves in the market. Which brings me to my next point…\n2. Technical skills\nIf you’re in the data field, you’ve probably noticed that certain programming languages are becoming more dominant. Technical skills are consolidating. And the data backs this up.\nA whopping 86% of data scientists said that Python is the main language they use for current projects. Another 10% said they use it as a secondary language.\nData source\nAnd Python is being used for everything from data analysis to machine learning and web development.\n\nData source\nA few years ago, if you asked me whether you should learn R or Python, I would’ve said it doesn’t matter which language you start with. But today, I’d definitely say Python.\nBut Python isn’t the only player in town. Looking at job postings data over the past two years, SQL consistently appears in up to 60% of all job posts, right alongside Python, month after month. This shows that Python and SQL are and will remain the dominant languages for the foreseeable future.\nData source\nSo, if you’re trying to become a data scientist from scratch and are wondering what programming language to learn, I’d say it’s smart to focus on mastering Python and SQL first.\nIn fact, you might be surprised to hear this, but Wes McKinney, the creator of the pandas package, was recently asked to give advice for data scientists. His shocking response? “Learn SQL.”\nHe said, “Learning SQL is actually a really good skill. It’s not just learning SQL, the language, but learning the concepts of relational algebra and how to think about data sets, designing schemas, and organizing data.”\nAs much as I love Python, I must agree on this. I once worked on a machine learning project at a large bank for anti-money laundering. We used PySpark SQL to query bank transaction data, think billions of rows. I remember at the beginning it’d take me up to 10 minutes to even run a command to check the number of rows in the dataset. Only afterward, I learned about concepts such as partitioning and load balancing to help me optimize my code.\nSo, if you’re looking to level up your skills, don’t overlook SQL. It’s more than just a query language – it’s a way of thinking about data that can make you a better data professional overall.\n      \n      Try SQL features in Datalore\n    \n\n\n\n\n3. Emergence of AI engineering\nNow, here’s where things get really exciting. While data scientists and data analyst roles are always in demand, there’s a new kid on the block: AI engineers.\nThese roles have emerged with the rapid development of large language models in the past two years. And here’s the interesting part – they don’t require a PhD. Rather, they require an in-depth knowledge of LLMs, prompt engineering, and AI agent workflow engineering.\nThis role is still very new, and there are different opinions about what the job exactly entails.\nBut in general, you can think of it this way: If we put data science research on one end of the spectrum and AI applications on the other, AI engineers lean towards the product and user end. They build applications that use pre-trained AI models, or foundation models, to solve a specialized business problem. You can perhaps think of AI engineers as software engineers specializing in AI products.\nData source\nFor example, let’s say a company wants to develop an AI application like a specialized customer chatbot using LLMs. AI Engineers will be the ones who put the AI model in place, do some prompt engineering, fine-tuning the model if necessary, tailoring the workflow to the use case, and also evaluating the application to make sure it works as it should.\nAndrej Karpathy, a big name in the AI world, predicts that:\n“In numbers, there’s probably going to be significantly more AI engineers than there are ML engineers/LLM engineers. One can be quite successful in this role without ever training anything.” – Andrej Karpathy\nAnd the job post data backs this up. In the past two years, AI engineer jobs have been growing much faster than ML engineer jobs, with the former actually surpassing the latter in May 2023, according to Hacker News Hiring trends.\nData source\nYou might be asking what’s the key difference between AI engineers and ML engineers: Well, it’s quite simple, creating LLM applications rely heavily on prompt engineering, which of course doesn’t exist in a traditional machine learning model. Evaluating LLM applications also requires a very different approach to using precision and recall metrics or mean squared error like in machine learning models.\nRecently, PwC, one of the big four companies, landed a deal with OpenAI to become its first resale partner. This partnership helps PwC scale AI capabilities across businesses to help drive accelerated impact for clients. What this basically means is more and more businesses will be able to build and incorporate AI into their solutions. And who will implement this? AI engineers, that’s who.\nSo, if you have a data science background, how do you become an AI engineer?\nI’m certainly not an expert in this field. But a popular post on Hacker News suggested focusing on these areas:\nMathematical foundations\nBasic statistics\nPython programming\nCourses such as:\n\nML specialization and deep learning specialization by Andrew Ng on Coursera\nfast.ai deep learning courses\nAnd then you can choose a specific area of AI to focus on, for example:\n\nNatural language processing (NLP)\nComputer vision (CV)\nReinforcement learning (RL)\nOther specializations\nThere are other emerging new roles being talked about, such as quality assurance business analyst (or QA analyst for short), who investigate LLM outputs, design A/B tests, and build dashboards to monitor the overall performance of AI products. This role is relatively business-focused.\nThis is yet to be seen in the data for the number of new vacancies being posted. But, this role does not require significant qualifications, and I think anyone with an analytical mind and data science skills can adapt themselves to this new role.\n4. Freelancing trends\nNow, let’s talk about another interesting trend: the rise of freelancing in the data world.\nIn 2024, there seems to have been a significant increase in the number of job posts looking for contractors and freelancers. This is exciting news for those of you who might be interested in a part-time or flexible job.\nData source\nBecoming a freelancer is a great way to learn new skills fast and build a diverse portfolio because you’ll get to work on real business problems with clients, sometimes in completely new domain areas, with different types of data and analytics tools.\nIn the US, most freelancers find their work through previous clients, friends and family, social media, and professional contacts.\nData source\nThe question is, if you don’t have a previous client already, how do you find your first client?\nHere’s my advice: Start small and utilize your own network. Post about your relevant projects on LinkedIn, showcase your skills, and mention that you’re looking for freelance work in this and that area. I used to be scared to post stuff on Linkedin, but a little bit of fear is a good sign that you’re getting out of your comfort zone.\nEven better, you can approach your neighbors, friends, and family members directly. Small business owners around the corner might need your help, and friends and relatives might have interesting work for you.\nOnce you have 2–3 projects like this (even for free or at very small commissions), you can start collecting reviews, building your process, and refining your services to offer them at a larger scale. You can even start going on online job boards like Upwork and Fiverr to find more jobs.\n5. Automation – The rise of low-code and no-code tools\nLast but definitely not least, let’s talk about a trend that’s changing the game: low-code and no-code tools. It’s not an exaggeration to say that, in the future, anyone could become a data analyst without specialized training. And I’m talking about doing much more than just creating pivot tables in Excel.\nLow-code and no-code development platforms, enabled by AI, are becoming increasingly popular. The low-code market is forecast to grow at an annual average rate of 22.9% from 2023 to 2030.\nData source\nThese tools are making data analytics more accessible to people who might not have traditional coding skills. They provide simplified interfaces that let anyone plug in their data and do tasks like data preparation, statistical analysis, visualization, and even build machine learning models without significant coding effort.\nNow, I know what some of you might be thinking. This sounds too good to be true, right? Well, you’re not entirely wrong: AI’s smart, but it still needs human expertise to guide it in complex tasks. And at the end of the day, someone needs to make sense of the results, evaluate them, and make a decision.\nSo, it’s all about finding that sweet spot where tech and expertise work together.\nAs low-code platforms improve to automate a lot of entry-level data analysis tasks, data jobs will likely become more specialized in the future. So instead of just looking for “data analyst” or “data scientist” job titles, you might consider a wider range of titles such as marketing analyst, sales analyst, risk analyst, psychometrician, quality assurance analyst, data governor, or perhaps even data cleaning ninja.\n      \n      Check out Datalore AI\n    \n\n\n\n\nConclusions\nNo matter what your next career move will be, the market will always be in constant flux. The key is to stay adaptable, keep learning, and make valuable connections with people. \nIf you want to dive deeper into the data behind this video, you can find the full report in a Datalore notebook on the JetBrains Datalore website.\n      \n      Open Datalore report",
        "dc:creator": "Alena Guzharina",
        "content": "This is a guest blog post by Thu Vu.&#160; The long-term outlook for data jobs – like data scientists, statisticians, and market research analysts – predicts explosive growth, much faster than most other fields. But here’s the catch: Despite the promising stats, data professionals are struggling to find jobs. AI is also shaking things up [&#8230;]",
        "contentSnippet": "This is a guest blog post by Thu Vu.  The long-term outlook for data jobs – like data scientists, statisticians, and market research analysts – predicts explosive growth, much faster than most other fields. But here’s the catch: Despite the promising stats, data professionals are struggling to find jobs. AI is also shaking things up […]",
        "guid": "https://blog.jetbrains.com/?post_type=datalore&p=492542",
        "isoDate": "2024-07-11T09:54:11.000Z"
      },
      {
        "creator": "Vaclav Pech",
        "title": "The MPS 2024.1 Release Candidate Is Out",
        "link": "https://blog.jetbrains.com/mps/2024/07/the-mps-2023-3-release-candidate-is-out-2/",
        "pubDate": "Thu, 11 Jul 2024 08:58:50 +0000",
        "content:encodedSnippet": "The Release Candidate for MPS 2024.1 is now available for download. Grab it and experience the new functionality before the final 2024.1 release.\nDOWNLOAD MPS 2024.1 RC\nYou can learn about the new features in more detail in this blog post.\nThe full list of fixed issues can be found here.\nYour JetBrains MPS team",
        "dc:creator": "Vaclav Pech",
        "content": "The Release Candidate for MPS 2024.1 is now available for download. Grab it and experience the new functionality before the final 2024.1 release. DOWNLOAD MPS 2024.1 RC You can learn about the new features in more detail in this blog post. The full list of fixed issues can be found here. Your JetBrains MPS team",
        "contentSnippet": "The Release Candidate for MPS 2024.1 is now available for download. Grab it and experience the new functionality before the final 2024.1 release. DOWNLOAD MPS 2024.1 RC You can learn about the new features in more detail in this blog post. The full list of fixed issues can be found here. Your JetBrains MPS team",
        "guid": "https://blog.jetbrains.com/?post_type=mps&p=487916",
        "categories": [
          "releases",
          "release"
        ],
        "isoDate": "2024-07-11T08:58:50.000Z"
      },
      {
        "creator": "Khalid Abuhakmeh",
        "title": "Try Full Line Code Completion in JetBrains Rider 2024.1.4",
        "link": "https://blog.jetbrains.com/dotnet/2024/07/10/full-line-code-completion-in-jetbrains-rider/",
        "pubDate": "Wed, 10 Jul 2024 13:49:11 +0000",
        "content:encodedSnippet": "We recently released the 2024.1 version of all our IDE products, including the dotUltimate family of products: ReSharper, Rider, dotMemory, dotTrace, dotCover, and dotPeek. Full Line Code Completion (FLCC), a local and fast AI model fine-tuned for product-specific programming languages, is one feature you may have heard of in this release. FLCC was released with support for many other languages, but we still feel there’s more work to be done regarding the .NET ecosystem, and that’s where your expertise and feedback are crucial. \nDownload\n                                \nJetBrains Rider 2024.1.4\nIn this post, we’d like to introduce you to FLCC, explain what it is and what it isn’t, and invite you to join our group of early adopters to try it out and provide feedback because you, as valued community members, complete us. Let’s get into it.\nWhat is Full Line Code Completion?\nFull Line Code Completion is an IntelliJ-platform plugin designed to predict the following line of code in the current scope. Predictions use a fine-tuned model for each language to suggest syntactically correct lines. Syntactic accuracy means there’s no chance that FLCC will suggest anything that will be a compilation error in the current scope of your code. Focusing on correctness means more valuable suggestions and less noise in the editor, keeping you in the coding flow.\nIn addition to correctness, FLCC is entirely local, which means all suggestions are processed and presented in the privacy of your development environment. Local also enables offline scenarios for those famous coding sessions on trains, planes, and automobiles. The locality of the models also means suggestions are “blink and you’ll miss it” fast. FLCC speed is another way we help you stay in the flow.\nFinally, the best part of FLCC is that it’s included at no additional cost to current JetBrains IDE subscription holders. Yes, that’s right; it’s part of the core JetBrains IDE experience. \nCheck out our YouTube announcement for a visual summary of FLCC. Developer advocate Paul Everitt explains FLCC in his usual charming way.\n\n\n\n\n\n\nI’d also recommend reading the IntelliJ Full Line Code Completion announcement, as it provides further details for those more curious about the plugin’s inner workings.\nThis sounds great, but what about the JetBrains Rider user community? When do we get access to FLCC? Well… right now!\nTrying out Full Line Code Completion\nWith the 2024.1.4 release of JetBrains Rider, the plugin can be found under the Staff Picks category of the Plugins section or by searching for “Full Line Completion” in the marketplace tab. Install the plugin as you would any other plugin from our JetBrains Marketplace.\n\n\n\n\nYou can verify that the plugin is available and enabled by navigating to “Settings | Editor” and finding the “Code Completion” section. \nIn this section, you’ll see a “Machine Learning-Assisted Completion” group, where you can pre-emptively download the models for each supported language in JetBrains Rider: C#, CSS-like, and JavaScript/TypeScript. Before F# folks ask, we are also researching F# support. C++ support for game developers is also coming soon.\n\n\n\n\nYou can choose which FLCC suggestions are available or disable the feature by checking the appropriate box. For folks on a strict bandwidth budget, you can also change the Download Models setting to ask before downloading any model. Downloading the models you use in your everyday workflow is a breeze. Considering they’re only 100 MB, you can download one or all. Remember, they’re fine-tuned, so they’re small and efficient. \nExamples of Full Line Code Completion\nFLCC works based on the current file and the position of your current cursor, attempting to predict the following line. You don’t have to do anything differently regarding your current workflow and developer habits other than look for suggestions and pick the ones that work best for you.\nAs a usability hint, the more code in the file, the more suggestions will meet your expectations. Here’s an example in a unit testing suite. Each new Assert is predicted by using similarly-scoped tests.\n\n\n\n\nFLCC can use existing patterns in your code to predict what you will do next. The context supercharges FLCC’s predictive powers, especially in opinionated codebases. A framework like ASP.NET Core MVC follows a predictable pattern and is an excellent place for predictive models to help you get to solutions faster.\n\n\n\n\nAs you may have noticed in the previous screenshot, the code completion key is fully customizable to your needs. Hover over the completion and select which key combination you want to use when picking a suggestion. Options include Tab, Right, Enter, Shift + Right, or a custom key combination of your choice.\n\n\n\n\nWhere You Can Help\nAs we mentioned at the beginning of this post, these models continue to undergo fine-tuning to serve our ultimate goal: providing JetBrains Rider users with the best experience possible. Your feedback is not just important; it’s crucial. While these models can feel like magic, they ultimately work on your feedback and insights. You can download newer iterations as these models improve, boosting your productivity.\nDownload\n                                \nJetBrains Rider 2024.1.4\nThe next step for the adventurous and curious is to download the latest version of JetBrains Rider along with the relevant models and try it for yourself. While doing so, tell us what you like and what we could do better. In the section below, let us know if you have any questions or comments.",
        "dc:creator": "Khalid Abuhakmeh",
        "content": "We recently released the 2024.1 version of all our IDE products, including the dotUltimate family of products: ReSharper, Rider, dotMemory, dotTrace, dotCover, and dotPeek. Full Line Code Completion (FLCC), a local and fast AI model fine-tuned for product-specific programming languages, is one feature you may have heard of in this release. FLCC was released with [&#8230;]",
        "contentSnippet": "We recently released the 2024.1 version of all our IDE products, including the dotUltimate family of products: ReSharper, Rider, dotMemory, dotTrace, dotCover, and dotPeek. Full Line Code Completion (FLCC), a local and fast AI model fine-tuned for product-specific programming languages, is one feature you may have heard of in this release. FLCC was released with […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=468903",
        "categories": [
          "net-tools",
          "ai",
          "c",
          "rider"
        ],
        "isoDate": "2024-07-10T13:49:11.000Z"
      },
      {
        "creator": "Elena Kerpeleva",
        "title": "Busy Plugin Developers Newsletter – Q2 2024",
        "link": "https://blog.jetbrains.com/platform/2024/07/busy-plugin-developers-newsletter-q2-2024/",
        "pubDate": "Tue, 09 Jul 2024 15:32:54 +0000",
        "content:encodedSnippet": "⭐️ Marketplace updates\nFlexible trial periods for paid plugins\nYou can now customize trial periods for your paid plugins. Instead of the default 30-day trial, you can set a shorter trial period or even none at all. Just select the preferred trial period while uploading your plugin to the Marketplace or, if your plugin is already on the Marketplace, go to the settings and edit the trial period length.\nNote: This feature is available in the IDE starting from the 2024.1.1 release. Anyone using an older version will see outdated trial period information.\nLearn more about this feature in our recent blog post.\nImportant update on plugin download statistics\nAs a plugin author, you might have noticed a recent decrease in your download numbers. This is due to a miscalculation identified by JetBrains Marketplace – no actual decrease occurred. \nIn March 2024, an error started causing inflated download numbers by mistakenly counting certain requests as downloads. We have now adjusted the algorithm to ensure data accuracy. We apologize for any inconvenience this may have caused. \nIf you have any questions or concerns, please reach out to our support team at marketplace@jetbrains.com.\nThe Writerside IDE is now on JetBrains Marketplace\nWriterside, a documentation authoring and building environment aimed at professional technical writers and software developers, is now available on JetBrains Marketplace. It lets you author, preview, build, test, and publish technical documentation for your plugins directly within your favorite IDE. \n\n\n\n\n⭐️ Plugin development tooling updates\nIntelliJ Platform Plugin Template 1.14.1\nThe IntelliJ Platform Plugin Template is a repository that streamlines the initial stages of plugin development for IntelliJ-based IDEs. Key changes in the recent update involve upgrading dependencies, as well as upgrading the platformVersion to 2023.2.7 and Gradle Wrapper to 8.8. Get more insights from the release notes.\nIntelliJ Plugin Verifier 1.367 \nPlugin Verifier Version 1.367 introduces a CLI switch to mute specific plugin problems, distinguishes errors in outputs, shows structure warnings with solution hints, fixes several issues when checking against Platform 2024.2, and adds a YouTrack App plugin structure parser.\nCheck out the changelog for more details.\nIntelliJ Platform Gradle Plugin 2.0 (Beta)\nThe IntelliJ Platform Gradle Plugin is a plugin for the Gradle build system to help configure your environment for building, testing, verifying, and publishing plugins for IntelliJ-based IDEs. The plugin is now 2.0.0-beta8 and available for general use. Users can report bugs or problems via GitHub issues.\nFind all of the details here.\n⭐️ Useful resources\nPlugin Internationalization\nTwo new articles cover plugin internationalization possibilities. The Internationalization page describes how to enable national language support (NLS) in IntelliJ-based IDEs and plugins, implement message bundles, and organize translations. \nThe Providing Translations article explains how to provide translations for IntelliJ Platform products and plugins through language packs and bundled translations, detailing the structure, implementation, and prioritization of translation files.\nCode Formatter\nA reworked Code Formatter page describes how to implement custom language formatters in the IntelliJ Platform, including the structure of formatting blocks, implementation steps, and specific formatting properties like indent, spacing, wrap, and alignment.\nIndexing and PSI Stubs: DumbAware API﻿\nA new addition to the Indexing and PSI Stubs article covers the implementation and testing of the DumbAware API, which enables certain extension points and actions to function during Dumb Mode in the IntelliJ Platform.\n⭐️ Community highlights\nTop plugin picks by JetBrains product teams\nRecently, we introduced an application process for plugin authors, providing a chance to be featured in JetBrains Marketplace’s Staff Picks.\nAll applications were carefully reviewed, and our product teams selected a handful of plugins based on their utility and impact. You can check out this blog post for some of the selected plugins or see the full list here.\nThe Staff Picks list is updated with each IDE release cycle. Releases take place in April, July, and November. Feel free to apply to have your own plugin featured.\nNew People Behind Plugins video\nWatch our latest interview with Yuna Morgenstern, author of the GitHub Workflow plugin. Yuna shares how she came up with the idea for the plugin and what inspires her to be an active member of the community. Learn about her journey, contributions to open-source, and how she manages her own pet projects and teaches kids to code.\nWould you like to nominate someone, or do you have a story to share? Email us at marketplace@jetbrains.com.",
        "dc:creator": "Elena Kerpeleva",
        "content": "⭐️ Marketplace updates Flexible trial periods for paid plugins You can now customize trial periods for your paid plugins. Instead of the default 30-day trial, you can set a shorter trial period or even none at all. Just select the preferred trial period while uploading your plugin to the Marketplace or, if your plugin is [&#8230;]",
        "contentSnippet": "⭐️ Marketplace updates Flexible trial periods for paid plugins You can now customize trial periods for your paid plugins. Instead of the default 30-day trial, you can set a shorter trial period or even none at all. Just select the preferred trial period while uploading your plugin to the Marketplace or, if your plugin is […]",
        "guid": "https://blog.jetbrains.com/?post_type=platform&p=491644",
        "categories": [
          "marketplace",
          "news",
          "busy-plugin-developers"
        ],
        "isoDate": "2024-07-09T15:32:54.000Z"
      },
      {
        "creator": "Garth Gilmour",
        "title": "Enhanced Column Selection DSL in Kotlin DataFrame",
        "link": "https://blog.jetbrains.com/kotlin/2024/07/enhanced-column-selection-dsl-in-kotlin-dataframe/",
        "pubDate": "Tue, 09 Jul 2024 15:26:52 +0000",
        "content:encodedSnippet": "Introduction\nThe Kotlin DataFrame library makes extracting values from structured data an easy task. As discussed in our documentation, there are four separate APIs that can be used for this purpose, with the optimal choice depending on your individual situation and requirements. \nTo demonstrate, let’s read in a JSON document containing information about users:\nval rawUserData = DataFrame.read(\"https://dummyjson.com/users\")\n   .getFrameColumn(\"users\")\n   .first()\n\nrawUserData.select { cols(0..2) }.head(3)\nThe final line selects the first three columns from the first three rows (for illustration purposes only):\n\n\n\n\nDon’t worry about how the final line works just yet – we’ll get to that later.\nHaving obtained our sample data, let’s now extract some values. In the example below, you:\nTake the last five users as strongly typed DataRow objects, using the tail operation.\nCapture each user’s name four times, using a different API each time.\nPrint the captured values, so you can be sure that they’re identical.\ndata class Person(val firstName: String)\n\nrawUserData.tail().forEach {\n   val name1 = firstName               // Extension Properties API\n   val name2 = \"firstName\"<String>()   // String API\n   val firstName by column<String>()   // Column Accessors API\n   val nameRef = Person::firstName     // KProperties API\n  \n   println(\"$name1 $name2 ${firstName()} ${this[nameRef]}\")\nThis should be the resultant output:\nEvelyn Evelyn Evelyn Evelyn\nDaniel Daniel Daniel Daniel\nLily Lily Lily Lily\nHenry Henry Henry Henry\nAddison Addison Addison Addison\nImpressive as this is, selecting individual values is not enough for real world scenarios. When using functions like select, remove, or update, you will typically need to select values from multiple columns. \nThese columns might all be at the top level, but when dealing with hierarchical data (like JSON), you’ll need to select columns from within nested column groups. This functionality is provided by the Columns Selection DSL.\nThe DataFrame library has always had a DSL for selecting multiple (potentially nested) columns, but in this release, we’ve added new functions and improved the overall syntax and readability. \nAn initial example of selection\nIn the example below, you:\nSelect the firstName column.\nUse the and operator to combine this column with further selections.\nAccess the nested data within the address column.\nUse the cols function to select multiple columns from the nested data.\nOnly keep the final five records via tail.\nrawUserData.select {\n   firstName and address.cols(\"city\", \"state\")\n}.tail()\nAs you can see from the results, you can use the and operator to select multiple columns individually, and the cols function to select multiple columns in one go.\n\n\n\n\nSelecting by index\nColumns can also be selected by index, with the first column having an index of zero. The code below would give you the same result:\nrawUserData.select {\n   firstName and address.cols(1, 2)\n}.tail()\nIf you were to include the column with index zero, then the results would include the street number and name. You could list the three indexes individually, but a range is more convenient:\nrawUserData.select {\n   firstName and address.cols(0..2)\n}.tail()\nThese would be the results:\n\n\n\n\nSelecting based on a predicate\nThe value passed to cols can also be a lambda. This allows you to select columns based on an arbitrary predicate – typically involving their name or content. Let’s look at two examples.\nThis first example selects all columns whose name ends with “Name”:\nrawUserData.select {\n   cols { it.name.contains(\".+Name\".toRegex()) }\n}.tail()\nAs you can see, this gives us three results:\n\n\n\n\nThe second example selects all columns whose values contain either the word “Lee” or the number 31.\nrawUserData.select {\n   cols { \"Lee\" in it.values() } and\n   cols { 31 in it.values() }\n}.tail()\nAs is visible below, this gives us two columns:\n\n\n\n\nHandling nested data\nWhat if you want to search within nested data? The function isValueColumn returns true if a column contains regular data. Otherwise the column is a column group or a frame column.\nThis test can be repeated recursively to descend the hierarchy. That sounds like a lot of work, but fortunately the library provides a colsAtAnyDepth function that handles the recursion for you. Let’s look at some examples.\nIn the code below, you select columns from anywhere in the column group hierarchy that contain regular data and have a name of length six:\nrawUserData.select {\n   colsAtAnyDepth {\n       it.name.length == 6 && it.isValueColumn()\n   }\n}.tail()\nThese are the results:\n\n\n\n\nUnfortunately, this code contains a bug. You cannot have multiple columns with the same name in the results. For example let’s say you search for columns of length four:\nrawUserData.select {\n   colsAtAnyDepth {\n       it.name.length == 4 && it.isValueColumn()\n   }\n}.tail()\nThe results will include two columns called “city” – one from the column group describing the user’s address, and the other from the column group describing the address of the company the user works for. This duplication will cause an exception to be raised:\nDuplicate column names: [city]\n\nAll column names: [type, city, iban, name, city, coin, role]\norg.jetbrains.kotlinx.dataframe.exceptions.DuplicateColumnNamesException: Duplicate column names: [city]\nThe solution is to create a new version of the data, where the column names encode the full path down the hierarchy:\nval renamedUserData = rawUserData.rename {\n   colsAtAnyDepth()\n}.into { it.path.joinToString(\".\") }\nYou can query this new data to see how the column names have changed:\nrenamedUserData.select {\n   colsAtAnyDepth()\n}.columnNames().forEach(::println)\nFor example, these are the columns relating to the address of the user:\naddress\naddress.address\naddress.city\naddress.state\naddress.stateCode\naddress.postalCode\naddress.coordinates\naddress.coordinates.lat\naddress.coordinates.lng\naddress.country\nIf you now select columns you will need to split up the column name:\nrenamedUserData.select {\n   colsAtAnyDepth {\n       val isLength6 = it.name.split(\".\").last().length == 6\n       isLength6 && it.isValueColumn()\n   }\n}.tail()\n\n\n\n\nThe benefit is that searching by length 4 no longer produces an exception:\nrenamedUserData.select {\n   colsAtAnyDepth {\n       val isLength4 = it.name.split(\".\").last().length == 4\n       isLength4 && it.isValueColumn()\n   }\n}.tail()\n\n\n\n\nNote that colsAtAnyDepth replaces the dfs and recursively functions, which have now been deprecated and removed.\nProcessing data by column order\nMost of the specificities of Column Selection DSL will be intuitive to folks who have experience with SQL. However, there is one area that might catch them off guard. Unlike in relational database theory (RDT), the order of the columns in a DataFrame is significant, and can be used in queries.\nWe already saw this with the example of indexing, but ordering can be used in many ways. Let’s try to find all of the top-level columns whose name begins with the letter “i”:\nrawUserData.select {\n   cols {\n       it.name.startsWith(\"i\")\n   }\n}.tail()\nYou can see that there are three such columns:\n\n\n\n\nUnlike in SQL, it’s meaningful to ask which column comes first:\nrawUserData.select {\n   first {\n       it.name.startsWith(\"i\")\n   }\n}.tail()\n\n\n\n\nBy that logic, it’s also meaningful to ask which column comes last:\nrawUserData.select {\n   last {\n       it.name.startsWith(\"i\")\n   }\n}.tail()\n\n\n\n\nYou can even traverse across the columns, selecting all columns until a specified one is reached or a condition is met. In the example below you select all columns until you encounter the first one whose name starts with “e”:\nrawUserData.select {\n   allUpTo {\n       first {\n           it.name.startsWith(\"e\")\n       }\n   }\n}.tail()\nIn our sample data, this is the column named “email”:\n\n\n\n\nAdditional helper functions\nThere are a number of helper functions you can explore, which simplify common scenarios. Let’s explore three examples.\nThe valueCols function \nThis function only selects value columns. That means we can take this earlier example:\nrawUserData.select {\n   cols {\n       it.name.length == 6 && it.isValueColumn()\n   }\n}.tail()\nAnd simplify it into:\nrawUserData.select {\n   valueCols {\n       it.name.length == 6\n   }\n}.tail()\nBoth will produce the following results:\n\n\n\n\nIf you did not exclude nested data, then the users cryptocurrency information will be included as well:\nrawUserData.select {\n   cols {\n       it.name.length == 6\n   }\n}.tail()\n\n\n\n\nThe colsOfKind function\nThis function lets you select any combination of group, frame, and value columns. If you only wanted to find the names of the group columns you could do this:\nrawUserData.select {\n   colsOfKind(ColumnKind.Group)\n}.first().run {\n   columnNames().forEach(::println)\n}\nIn which case, the results are:\nhair\naddress\nbank\ncompany\ncrypto\nAlternatively, you could select group and value columns like this:\nrawUserData.select {\n   colsOfKind(ColumnKind.Group, ColumnKind.Value)\n}.first().run {\n   columnNames().forEach(::println)\n}\nBecause the scope of the query is wider, more results will be selected:\naddress\nmacAddress\nuniversity\nbank\ncompany\nein\nssn\nuserAgent\ncrypto\nrole\nThe colsOf function\nIn the DataFrame library every column created infers its type based on the data inside. This being the case, you can select columns based on the type of data they contain:\nrawUserData.select {\n   colsOf<Int>()\n}.tail()\nIn this example, the top level data contains two columns holding integer values:\n\n\n\n\nThe colsOf function is polymorphic, meaning that it will select columns whose data type is a subtype of the type you specify. For example, if you specify Number as the type, then columns containing both integer and floating-point values will be selected. \nrawUserData.select {\n   colsOf<Number>()\n}.tail()\nIn this case, that gives us an additional two columns:\n\n\n\n\nIf you wanted, you could create a new version of the data, where all numeric values were doubles. This could be achieved as follows:\nval convertedUserData = rawUserData.convert {\n   colsAtAnyDepth().colsOf<Number>()\n}.toDouble()\nNow, selecting the integer columns would give us no results, whereas selecting all the doubles would give us four:\nconvertedUserData.select {\n   colsOf<Double>()\n}.tail()\n\n\n\n\nOperators and subtracting columns\nThe square brackets operator can be used as a shortcut for the cols function. Consider the following example:\nrawUserData.select {\n   bank.cols {\n       it.name.startsWith(\"card\")\n   }\n}.tail()\nThis selects the nested data within the “bank” column, specifically all those columns whose name starts with “card”:\n\n\n\n\nYou can achieve the same result using the operator as follows:\nrawUserData.select {\n   bank[{ it.name.startsWith(\"card\") }]\n}.tail()\nWhich syntax you prefer is a matter of personal preference, but consistency is recommended to avoid confusing your code’s maintainers.\nIt’s also possible to select columns by subtraction, rather than addition. To show this, let’s create a simpler data set:\nval employeeData = rawUserData.mapToFrame {\n   \"name\" from { \"$firstName $lastName\" }\n   university into \"education\"\n   \"employment\" from { \"${company.title} at ${company.name}\" }\n   +birthDate\n   +email\n}.tail()\nThis gives us the following values:\n\n\n\n\nYou already know how to specify which columns you want:\nemployeeData.select {\n   cols(name, employment, birthDate)\n}\nBut it’s also possible to obtain the same result by specifying which columns you wish to leave out:\nemployeeData.select {\n   allExcept(email, education)\n}.tail()\nBoth of these examples give the following result:\n\n\n\n\nSubtraction can be used when working with nested data. In the example below, you return to the original data set and select the user’s first name and all elements of their address with three exceptions:\nrawUserData.select {\n   firstName and\n   address.allColsExcept {\n       cols(coordinates, stateCode, postalCode)\n   }\n}.tail()\n\n\n\n\nInteractive grammars\nAs you can see, there’s a huge amount of functionality within the Column Selection DSL. When you first encounter the library, it’s easy to be confused by both the number of operations and the different ways in which they can be combined. \nTo assist with this, we now provide grammars for each function in the associated KDocs. You might have encountered these grammars on the website already, but in KDocs, they’re fully interactive!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConclusions\nHopefully this blog has given you some insight into the power and versatility of the Column Selection DSL. This latest (0.13.1) update brings a more organized and consistent way to select columns with detailed and interactive documentation. All examples from this article are available as a Kotlin Notebook on GitHub. \nAs always, we’re keen to receive feedback on our products, and what areas could be extended or improved. You can find more information about column selectors on this page of our Kotlin DataFrame documentation site. Each function is introduced with examples and explanations, which is a great way to get an overview of what’s possible. Happy coding!",
        "dc:creator": "Garth Gilmour",
        "content": "Introduction The Kotlin DataFrame library makes extracting values from structured data an easy task. As discussed in our documentation, there are four separate APIs that can be used for this purpose, with the optimal choice depending on your individual situation and requirements.&#160; To demonstrate, let’s read in a JSON document containing information about users: The [&#8230;]",
        "contentSnippet": "Introduction The Kotlin DataFrame library makes extracting values from structured data an easy task. As discussed in our documentation, there are four separate APIs that can be used for this purpose, with the optimal choice depending on your individual situation and requirements.  To demonstrate, let’s read in a JSON document containing information about users: The […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=487668",
        "categories": [
          "ecosystem",
          "data-analysis",
          "dataframe",
          "notebooks"
        ],
        "isoDate": "2024-07-09T15:26:52.000Z"
      },
      {
        "creator": "Dmitry Romanov",
        "title": "DataGrip User Experience Survey",
        "link": "https://blog.jetbrains.com/datagrip/2024/07/09/datagrip-user-experience-survey/",
        "pubDate": "Tue, 09 Jul 2024 13:58:48 +0000",
        "content:encodedSnippet": "Hello, DataGrip community!\nAt JetBrains, delivering an excellent user experience is always a top priority. Today, we’re launching a survey to gather your feedback and explore how we can make DataGrip even better. \nPlease take a few minutes to complete the DataGrip User Experience Survey. Your input will help us prioritize future improvements. \nAs a thank you for your time, you’ll have a chance to win one of five $100 Amazon Gift Cards or a one-year All Products Pack subscription. We’ll randomly pick the winners from among the questionnaires that are filled out completely with meaningful answers. Remember to enter your contact details to be eligible for the raffle.\nTake the DataGrip UX survey\nThank you for your time and effort!\nThe DataGrip team",
        "dc:creator": "Dmitry Romanov",
        "content": "Hello, DataGrip community! At JetBrains, delivering an excellent user experience is always a top priority. Today, we&#8217;re launching a survey to gather your feedback and explore how we can make DataGrip even better. Please take a few minutes to complete the DataGrip User Experience Survey. Your input will help us prioritize future improvements. As a [&#8230;]",
        "contentSnippet": "Hello, DataGrip community! At JetBrains, delivering an excellent user experience is always a top priority. Today, we’re launching a survey to gather your feedback and explore how we can make DataGrip even better. Please take a few minutes to complete the DataGrip User Experience Survey. Your input will help us prioritize future improvements. As a […]",
        "guid": "https://blog.jetbrains.com/?post_type=datagrip&p=491646",
        "categories": [
          "survey",
          "datagrip",
          "ux"
        ],
        "isoDate": "2024-07-09T13:58:48.000Z"
      },
      {
        "creator": "Regina Muradova",
        "title": "JetBrains Academy: New in July",
        "link": "https://blog.jetbrains.com/education/2024/07/09/jetbrains-academy-new-in-july/",
        "pubDate": "Tue, 09 Jul 2024 12:15:07 +0000",
        "content:encodedSnippet": "This July, we’ve made some improvements to our courses to better serve your learning needs, added certificates for two more courses, and introduced new learning topics. \nLet’s take a closer look at these updates.\nUpdated courses\nOur courses have been restructured to align with the latest job requirements. We’ve incorporated real interview questions and regularly revise our content to help you stay up to date with constantly evolving technologies.\nData Analyst\nData analysts play a crucial role in today’s data-driven world, helping companies make informed decisions and optimize performance. If you are eager to use large amounts of data to reveal meaningful insights, this career path might be right for you. \nIn this course you’ll gain data analysis skills, which are essential for solving complex problems in a data analyst role, with a focus on data handling and decision-making. \nThe Data Analyst course gives you a better understanding of how to work with data and strengthens your SQL skills so you can feel more confident in an interview.\nData Scientist\nIn this course, we’ll give you the foundational knowledge that every data scientist needs. We will show you the world of classic machine learning with models like linear and logistic regression, decision trees, model compositions, and much more, while also familiarizing you with more modern methods based on neural networks. Additionally, you will strengthen your data manipulation skills with advanced SQL queries.\nDevOps Engineer with AI\nThis course offers hands-on training to become a proficient DevOps engineer. You’ll learn critical DevOps principles, CI/CD processes, configuration management, and the integration of AI technologies. This training equips you to manage and automate the entire software lifecycle.\nNLP Engineer\nDeepen your understanding of natural language processing (NLP) with our advanced course. You’ll gain a solid understanding of fields like machine translation, chatbot systems, automatic question answering, and sentiment analysis. \nNew certificates available\nWe are excited to announce certificates for two courses: Introduction to Go and SQL for Data Analysis. Earn your certificate upon completing these courses and showcase your expertise to potential employers.\n\n\n\n\nNew learning topics\nData Science: Overview of Streamlit\nJavaScript: Testing frameworks introduction\nPython: Integer arithmetic: special operations\nGenerative AI: Combining prompting techniques, Self-evaluation and refine prompting\nWe hope that you find these updates valuable and that they enhance your learning experience. Your feedback and suggestions are welcome, so please don’t hesitate to get in touch with us at academy@jetbrains.com or share your thoughts with us on LinkedIn, X (formerly Twitter), or Facebook.\nHappy learning!\nYour JetBrains Academy team",
        "dc:creator": "Regina Muradova",
        "content": "This July, we&#8217;ve made some improvements to our courses to better serve your learning needs, added certificates for two more courses, and introduced new learning topics.  Let’s take a closer look at these updates. Updated courses Our courses have been restructured to align with the latest job requirements. We&#8217;ve incorporated real interview questions and regularly [&#8230;]",
        "contentSnippet": "This July, we’ve made some improvements to our courses to better serve your learning needs, added certificates for two more courses, and introduced new learning topics.  Let’s take a closer look at these updates. Updated courses Our courses have been restructured to align with the latest job requirements. We’ve incorporated real interview questions and regularly […]",
        "guid": "https://blog.jetbrains.com/?post_type=education&p=491699",
        "categories": [
          "jetbrains-academy",
          "learning-courses",
          "project-based-learning",
          "data-analysis",
          "data-science",
          "devops",
          "online-learning"
        ],
        "isoDate": "2024-07-09T12:15:07.000Z"
      },
      {
        "creator": "Maxim Kartashev",
        "title": "Wayland Support Preview In 2024.2",
        "link": "https://blog.jetbrains.com/platform/2024/07/wayland-support-preview-in-2024-2/",
        "pubDate": "Mon, 08 Jul 2024 15:05:17 +0000",
        "content:encodedSnippet": "We are delighted to announce that, starting with the 2024.2 Early Access Program (EAP), IntelliJ-based IDEs will offer preliminary support for the Wayland display server protocol on Linux, including Windows Subsystem for Linux a.k.a. WSLg.\nHow To Opt In\nOn Linux, IntelliJ-based IDEs were using exclusively the X11 protocol and an X server to show their user interface (UI), even if you were running a Wayland-based desktop. All Wayland servers include an X server implementation (XWayland) for backward compatibility with applications that aren’t ready to work with Wayland directly.\nStarting with the 2024.2 EAP, however, users can run IntelliJ-based IDEs on Wayland natively by adding:\n-Dawt.toolkit.name=WLToolkit\nto their VM options (Help | Edit Custom VM Options…). This will completely bypass the XWayland compatibility layer and provide all the benefits that Wayland has to offer.\nThis initial support aims to provide the foundational functionality necessary for operating an IDE on Wayland. While we have made significant progress, it’s important to note that there are features still in development and known bugs yet to be fixed.\nX11 or Wayland?\nIt’s not always possible to tell visually whether your IntelliJ-based IDE is running through X11 or natively on Wayland. One way to be sure is by using the About dialog (`Help | About`) to obtain full system information. Just click on the Copy and Close button. Towards the top of the copied text the toolkit’s name will be listed as follows:\nToolkit: sun.awt.wl.WLToolkit\nWLToolkit means that the IDE is talking directly to the Wayland server, while XToolkit – as the name would imply – means that the X11 protocol is used.\nThe same information is also available in idea.log; for example:\nINFO - #c.i.p.i.b.AppStarter - toolkit: sun.awt.wl.WLToolkit\nWhat’s Included\nIt goes without saying that this release includes the essential features that make a graphic user interface functional like showing the UI, typing text, moving the mouse pointer around, etc. Some features are worthy of mention.\nSharp Picture\nThe top complaint about running IntelliJ-based IDEs on modern Wayland desktops was the blurry picture you’d get when you scaled your desktop to a fractional value, not an integer multiple of 100%, e.g. 150% or 215%. While this wasn’t an inherent problem with X11, Wayland addresses fractional scale in a more robust way, and our new graphical subsystem supports any desktop scale, including fractional.\nThis area of Wayland is still under development, with improvements being made both on the protocol side and in implementations (such as KWin, Mutter, etc). We follow this work closely and will make the necessary updates to our graphical subsystem as the situation evolves.\nWSLg\nOn the WSLg side, switching to Wayland will mean no more unsightly window decorations imposed by the X server (something many people complained about), since the X server will no longer be involved in any stage of the operations.\nResponsive UI\nThe current implementation delivers a decent frames-per-second performance, which is mainly visible upon scrolling or resizing, as that’s when the window needs to be updated dozens or even hundreds of times per second. At the same time, when things are quiet and only the cursor is blinking, the graphical subsystem will not drain your battery by refreshing the entire screen at 60 FPS. Wayland allows both high-performance screen updates and slow pace periods to coexist in one application, and our graphical subsystem takes full advantage of that.\nThe work in this area is far from over, and utilization of Vulkan is expected to bring even better performance.\nBetter Multi-Monitor Support\nWayland generally handles window placement so that the application doesn’t have to. This is a paradigm change for many graphical applications, IntelliJ-based IDEs included. Among the positive effects of this change is better handling of popups and other utility windows that should now appear on the correct monitor and not cross the monitor boundary regardless of how complex your setup is. This used to be a somewhat weak point with modern systems that allowed different scales to be specified for each monitor and that used to cause a lot of confusion when running through the XWayland compatibility layer.\nWork in Progress\nDespite the advancements, full parity with X11 features has yet to be achieved. There are several areas listed below that we focus on in the near term.\nInput Methods\nInput methods are essential for developers who work with multiple languages and scripts. They provide a standardized way to enter characters that aren’t readily available on a standard keyboard.\nIn 2024.2 EAPs, no input methods are supported on Wayland. Since there is no working around this limitation, this particular feature is at the very top of our priorities list.\nNote, however, that Wayland already supports languages that don’t quite require the sophistication of input methods.\nNative Window Decorations\nThere are still a few utility windows in IntelliJ-based IDEs that are decorated by the OS, such as, for example, the About dialog or the differences window. For the moment, when running on Wayland those decorations (by which we essentially mean the window’s title bar and its buttons) are painted by the JetBrains Runtime and do not adhere to the desktop’s theme.\nAt a later date, we plan to implement native decoration support, similar to what is available currently with X11. In the meantime, the decorations will follow the overall desktop’s dark/light style, for those desktop environments where such notifications are available.\nDrag And Drop\nIn the 2024.2 release cycle, drag and drop within the IDE or between the IDE and other applications will not be supported on Wayland. In many cases, you’ll be able to just copy and paste as a work-around.\nStability\nAs with any major platform shift, there are bound to be some rough edges. We review and prioritize incoming issues on a daily basis so that the most important issues can be addressed as quickly as possible.\nFeedback\nWe deeply appreciate our users’ patience and enthusiasm. Many have already shared their feedback about IntelliJ-based IDEs on Wayland, and this has been instrumental in delivering a robust preview with many “paper cuts” having already been dealt with.\nYour insights and experiences are invaluable to us. By reporting issues and suggesting improvements, you can directly influence the development journey and help us refine Wayland integration in IntelliJ-based IDEs. We encourage you to create new issues on YouTrack and/or upvote the existing ones.\nGet started with the 2024.2 EAP today and join us in shaping the future of IntelliJ-based IDEs on Wayland!\nStay tuned for more updates and improvements in our upcoming releases.",
        "dc:creator": "Maxim Kartashev",
        "content": "We are delighted to announce that, starting with the 2024.2 Early Access Program (EAP), IntelliJ-based IDEs will offer preliminary support for the Wayland display server protocol on Linux, including Windows Subsystem for Linux a.k.a. WSLg. How To Opt In On Linux, IntelliJ-based IDEs were using exclusively the X11 protocol and an X server to show [&#8230;]",
        "contentSnippet": "We are delighted to announce that, starting with the 2024.2 Early Access Program (EAP), IntelliJ-based IDEs will offer preliminary support for the Wayland display server protocol on Linux, including Windows Subsystem for Linux a.k.a. WSLg. How To Opt In On Linux, IntelliJ-based IDEs were using exclusively the X11 protocol and an X server to show […]",
        "guid": "https://blog.jetbrains.com/?post_type=platform&p=491458",
        "categories": [
          "intellij",
          "idea",
          "jetbrains-runtime",
          "intellij-idea",
          "jbr",
          "linux",
          "wayland"
        ],
        "isoDate": "2024-07-08T15:05:17.000Z"
      },
      {
        "creator": "Alina Mishina",
        "title": "The New UI Becomes the Default in 2024.2",
        "link": "https://blog.jetbrains.com/blog/2024/07/08/the-new-ui-becomes-the-default-in-2024-2/",
        "pubDate": "Mon, 08 Jul 2024 14:57:25 +0000",
        "content:encodedSnippet": "We are happy to announce that we will enable the new UI for all JetBrains IDE users in the upcoming 2024.2 version. We designed the new UI to reduce visual clutter, ensuring easy access to essential features while gradually revealing more advanced functionality as needed. The new UI is clean and modern, providing bigger, easier-to-use controls, a consistent color palette, light and legible icons, increased contrast, and better accents.\n\n\n\n\nWork on the new UI began in 2021. We analyzed the issues with the old UI, carefully worked on solutions, released preview and Beta versions, gathered feedback, and conducted over 10 UX studies.\nThere was a lot of positive feedback from our users:\nThe new IntelliJ UI is so good. Minimalistic, modern, and still powerful, good job @jetbrains!\nWow, @WebStormIDE @jetbrains New UI is AWESOME, it looks very fresh.\nI’ve been using it for a few weeks and I absolutely love it. The tiny interface elements in the old UI really felt out of place in modern desktop environments.\nI’ve been using it for several weeks now with IntelliJ Ultimate, and I absolutely love it. I was afraid it was too minimal when I first started using it (I even went back to the “old look” for a little while), but after a few days, I realized everything I needed was still right where I needed it (and when I needed it), and all I’ve lost is the distractions. Everything works, and the look and feel is fresh, responsive and (ok, I’ll say it) modern.\nOf course, there was also negative feedback, and it greatly helped us make the new UI better – we fixed more than 2,000 bugs and made numerous improvements. For example, we added a compact mode, removed the bright blue Run button from the toolbar, added the ability to easily customize the main toolbar, added an option to enable tool window names, and polished color themes.\nFor more information about the main changes in the new UI, see the documentation. For known issues and future plans, see the Knowledge Base.\nCurrently, 87% of our users have adopted the new UI, despite it not being the default option for existing users.\nHow long will we continue to support the old UI?\nThe classic UI is available as a plugin in JetBrains Marketplace. Starting with the 2024.2 version, you will see a popup with the link to the plugin, or you can find the plugin in Settings | Plugins.\nWe plan to support the plugin for at least one year, which means that we will test and release it with every major IDE release. We will evaluate the new UI adoption rate and feedback, and based on this information, we will decide how long we will continue to support the classic UI.\nUnfortunately, the Classic UI plugin won’t work correctly with Gateway and when running the IDEs remotely.\nResources\nWe published the Int UI Kit and Icons pack for the new UI. Currently, we are updating the UI Guidelines to refer to the new UI.",
        "dc:creator": "Alina Mishina",
        "content": "We are happy to announce that we will enable the new UI for all JetBrains IDE users in the upcoming 2024.2 version. We designed the new UI to reduce visual clutter, ensuring easy access to essential features while gradually revealing more advanced functionality as needed. The new UI is clean and modern, providing bigger, easier-to-use [&#8230;]",
        "contentSnippet": "We are happy to announce that we will enable the new UI for all JetBrains IDE users in the upcoming 2024.2 version. We designed the new UI to reduce visual clutter, ensuring easy access to essential features while gradually revealing more advanced functionality as needed. The new UI is clean and modern, providing bigger, easier-to-use […]",
        "guid": "https://blog.jetbrains.com/?post_type=blog&p=491431",
        "categories": [
          "news",
          "releases",
          "new-ui",
          "user-interface"
        ],
        "isoDate": "2024-07-08T14:57:25.000Z"
      },
      {
        "creator": "Andrey Gushchin",
        "title": "CLion 2024.2 EAP 5: Zephyr West Support and Full Line Code Completion for C++",
        "link": "https://blog.jetbrains.com/clion/2024/07/2024-2-eap-5-zephyr-west-support-full-line-code-completion/",
        "pubDate": "Mon, 08 Jul 2024 13:05:38 +0000",
        "content:encodedSnippet": "The CLion 2024.2 EAP 5 build (242.19890.26) is now out! It’s available from our website, via the Toolbox App, or as a snap package.\nDOWNLOAD CLION 2024.2 EAP\nZephyr West support\nIn this EAP build, we introduce a new project model supported by CLion – it’s called the West project model. As we previously mentioned in our roadmap for this release, a West project makes it much easier to set up, open, and build a project that uses Zephyr RTOS.\nFor existing projects that have installed Zephyr, West, and the Zephyr SDK, CLion detects Zephyr usage and automatically sets up the project to provide code insight features, such as code competition, code navigation, and others.\nIn addition, the new bundled CLion Integration for Zephyr® Project plugin provides the following features:\nAutomatic creation of a Python interpreter and setting it as the current interpreter if there is a directory with a Python virtual environment next to the .west directory in the Zephyr workspace.\nBuilding a project using the west build command.\nAutomatic creation of a run/debug configuration that flashes the built binary to a board using the west flash command (please note that you may need to install Flash Host Tools, like OpenOCD, to flash your binary).\nDevice tree integration uses the same board that is configured for the project.\nAn optional Change Project Root suggestion to set the project’s root to the root of Zephyr’s workspace. By default, the Project view shows all the project’s source roots, which may sometimes be inconvenient.\n\nTo change the path to the West executable, board name, and build directory, go to Settings/Preferences | Build, Execution, Deployment | Embedded Development | West.\n\nA Zephyr project opened previously as a CMake project can be re-opened as a West project using the Convert to West Project action. And vice-versa, a West project can be converted back to a CMake project with the Convert to CMake Project action.\n\nAdditional options for the west flash command can be set in the settings of the West run/debug configuration.\n\nZephyr support is a work in progress, and we’d like to hear your feedback! Let us know your thoughts by commenting below or in our issue tracker.\nFull line code completion for C++\nPreviously introduced for Java, Kotlin, Python, JavaScript, TypeScript, CSS, PHP, Go, and Ruby, full line code completion becomes available for C++ with this build.\n\nThe full line code completion feature suggests entire lines of code using a locally run deep learning model. It works completely locally and doesn’t send any data outside your IDE. Also note that it’s included with your active JetBrains IDE subscription at no additional cost.\n❗️Full line code completion works only with the new ReSharper C++ language engine (also known as CLion Nova). Go to Settings/Preferences | Advanced Settings | CLion | Use the ReSharper C++ language engine (CLion Nova) to enable it.\nTo tweak the feature or download models for languages other than C++, go to Settings/Preferences | Editor | General | Inline Completion.\n\nThe full release notes are available here. Your feedback matters to us! Share your ideas in the comments section below or submit them to our issue tracker.\nDOWNLOAD CLION 2024.2 EAP\nYour CLion team\nJetBrains\nThe Drive to Develop",
        "dc:creator": "Andrey Gushchin",
        "content": "The CLion 2024.2 EAP 5 build (242.19890.26) is now out! It’s available from our website, via the Toolbox App, or as a snap package. DOWNLOAD CLION 2024.2 EAP Zephyr West support In this EAP build, we introduce a new project model supported by CLion – it’s called the West project model. As we previously mentioned [&#8230;]",
        "contentSnippet": "The CLion 2024.2 EAP 5 build (242.19890.26) is now out! It’s available from our website, via the Toolbox App, or as a snap package. DOWNLOAD CLION 2024.2 EAP Zephyr West support In this EAP build, we introduce a new project model supported by CLion – it’s called the West project model. As we previously mentioned […]",
        "guid": "https://blog.jetbrains.com/?post_type=clion&p=491289",
        "categories": [
          "eap",
          "news",
          "zephyr-west"
        ],
        "isoDate": "2024-07-08T13:05:38.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "article New updates to Planner comment notifications and settings in Planner Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Jessie Houghton",
        "title": "Demystify history with GitHub Copilot commit explanations",
        "link": "https://devblogs.microsoft.com/visualstudio/demystify-history-with-github-copilot-commit-explanations/",
        "pubDate": "Mon, 08 Jul 2024 07:00:53 +0000",
        "content:encodedSnippet": "Have you ever struggled to understand what a commit was doing or why it was made? Do you wish you had more clarity and context when reviewing or collaborating on code changes? If you answered yes, then you’ll love what GitHub Copilot can do for you: generate commit explanations. GitHub Copilot can analyze your code differences and produce concise summaries that highlight the key points. No more guessing or wasting time on deciphering your Git history. You can focus on coding and collaborating with ease. And the best part is, you can also improve your communication and teamwork by having better documentation and transparency of your code changes.\n\nDownload Visual Studio\n\nUnravel your commit history with GitHub Copilot\nGit history can be daunting to shuffle through, but it’s often the best way to learn about a code base or help identify the origin of a bug. We’ve added a GitHub Copilot powered explain feature to the Commit Details window to make it easier to understand the contents of each commit. You’ll get a summary of the changes side by side with the code, highlighting the key differences and the rationale behind them. Since GitHub Copilot needs to look at all the changes, this may take some time for large changesets or pull requests.\nDouble click on any commit to open the Commit Details pane in the Git Repository window. Then, select Explain button above the commit message to get a summary of the changes. Pro tip: use the expand option and the summary view to get a better view of the code changes with the description.\n\nPlease share your thoughts!\nMore folks are finding this option useful, so we wanted to highlight it here and share it broadly. We’d love to hear your thoughts for how to make commit explanations better and any other ideas to superpower Version Control with GitHub Copilot, especially with Git history.\nTake the Survey\n\nWe appreciate the time you’ve spent reporting issues/suggestions and hope you continue to give us feedback when using Visual Studio on what you like and what we can improve. Your feedback is critical to help us make Visual Studio the best tool it can be! You can share feedback with us via Developer Community: report any bugs or issues via report a problem and share your suggestions for new features or improvements to existing ones.\nStay connected with the Visual Studio team by following us on YouTube, Twitter, LinkedIn, Twitch and on Microsoft Learn.\nThe post Demystify history with GitHub Copilot commit explanations appeared first on Visual Studio Blog.",
        "dc:creator": "Jessie Houghton",
        "content": "<p>Have you ever struggled to understand what a commit was doing or why it was made? Do you wish you had more clarity and context when reviewing or collaborating on code changes? If you answered yes, then you&#8217;ll love what GitHub Copilot can do for you: generate commit explanations.</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/demystify-history-with-github-copilot-commit-explanations/\">Demystify history with GitHub Copilot commit explanations</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Have you ever struggled to understand what a commit was doing or why it was made? Do you wish you had more clarity and context when reviewing or collaborating on code changes? If you answered yes, then you’ll love what GitHub Copilot can do for you: generate commit explanations.\nThe post Demystify history with GitHub Copilot commit explanations appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=249632",
        "categories": [
          "Visual Studio"
        ],
        "isoDate": "2024-07-08T07:00:53.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "\r\n                            Binoy Dash,Bradley Crossen,Eric Cunningham,Royce Ausburn,Tejas Patel\r\n            \t\t\t",
        "title": "Bringing AI-powered answers and summaries to file previews on the web",
        "link": "https://dropbox.tech/machine-learning/bringing-ai-powered-answers-and-summaries-to-file-previews-on-the-web",
        "pubDate": "Thu, 11 Jul 2024 07:00:00 -0700",
        "content:encodedSnippet": "Dropbox offers a handful of features that use machine learning to understand content much like a human would. For example, Dropbox can generate summaries and answer questions about files when those files are previewed on the web. Instead of asking a coworker for the gist of last week’s all-hands meetings, Dropbox can provide a summary of the video and a user can ask questions about its contents—all from the file preview. We recently expanded AI-powered summarization and Q&A to handle multiple files simultaneously, too. \n(As part of our commitment to responsibly using AI, Dropbox abides by a set of AI principles; you can visit our Help Center to learn more. These features are still in early access, and not yet available to all users. These features are also optional, and can be turned on or off for you or your team.)\nBoth our summarization and Q&A features leverage large language models (LLMs) to find, compare, and consolidate the content of the file. An LLM works by ingesting content as text, transforming the ideas contained within it into a numerical representation, and comparing those numerical representations against both the input query and an internal corpus of knowledge to answer the question. This effectively enables a computer to consume and compare information semantically, rather than lexically.\nFor knowledge workers suffering from information overload, we can use machine learning to get them the answers they need—without them having to remember exactly how a piece of information was worded, or where it might be contained within a file. This is what we’ve done with file previews on the web.\n\r\n\r\n    \n Extracting text and embeddings with Riviera\n\r\n\r\n\n\nThe first part of this process is, of course, retrieving the text. Luckily, we already have a framework for transforming basically any file type to text.\nDropbox is capable of turning complex file types like CAD drawings into formats that are easily consumable by web browsers, such as PDF. Historically we have used this system for file previews, but we also use it to power features like transcription and Dropbox Replay. Internally, we call this system Riviera. \nAt a high level, Riviera consists of a frontend which routes requests through one or more plugins that convert a file from one type to another. Each plugin runs in a jail, which is a container designed to run third party code and tools safely and in an isolated manner. The framework maintains a graph of possible conversions, and is capable of chaining together multiple plugins into a multi-step pipeline to perform even more complex transformations. We currently support conversions between about 300 file types, and the system crunches through about 2.5 billion requests—totalling nearly an exabyte, or one billion gigabytes of data—per day.\nIn order to apply machine learning to file previews, the conversions we are interested are those that convert any file type to raw text. In the case of video, text extraction might looks something like:\n\r\n\r\n\r\n\r\n\r\n\n\r\n\r\n\r\n    \r\n        Copy\r\n    \r\n    \nVideo (.mp4) -> Audio (.aac) -> Transcript (.txt)\n\r\n\r\n\r\n\r\n\n\r\n\n\nSome of the conversions in Riviera can be quite expensive to compute on-the-fly, so it also includes a sophisticated caching layer that allows us to reuse conversions between plugins. Each state of the pipeline is cached, so intermediate states can be reused.\nIn the world of LLMs, the mathematical representation of the semantic meaning of text is called the embedding. Riviera treats embeddings like any other file conversion, so in the pipeline above, we can append:\n\r\n\r\n\r\n\r\n\r\n\n\r\n\r\n\r\n    \r\n        Copy\r\n    \r\n    \nVideo (.mp4) -> Audio (.aac) -> Transcript (.txt) -> AIEmbedding\n\r\n\r\n\r\n\r\n\n\r\n\n\nBy separating the embedding generation from the actual summary generation we can reuse the cache features built into Riviera. If a user wants to summarize a video, then ask some follow-up questions, we only have to generate the transcript and embeddings once.\n\r\n\r\n\r\n\r\n\r\n\n\r\n\r\n\r\n    \r\n        Copy\r\n    \r\n    \nVideo (.mp4) -> Audio (.aac) -> Transcript (.txt) -> AIEmbedding --> Summary\r\n                                                                 |\r\n                                                                 --> Q&A \n\r\n\r\n\r\n\r\n\n\r\n\n\nThe input for the embeddings plugin typically consists of text data extracted from various file types such as documents, videos, or audio files. In the case of video content, for example, the plugin may receive the transcript generated from the audio track of the video.\nThe process of converting text into embeddings involves using advanced language models that take the text input and produce a vector representing that text. In our implementation, we split the text into paragraph-sized chunks and calculate an embedding for each chunk. By doing this, we effectively increase the granularity of the information stored within a file. Instead of having just a single embedding for an entire file, we have multiple embeddings for different sections of the text. This higher granularity, or bit depth, allows us to capture more detailed and nuanced information. We apply the same chunking and embedding method for both summaries and Q&A, ensuring they share the same embedding cache within Riviera.\nWhile the actual LLM processing happens inside the summary and Q&A plugins, treating embeddings, summaries, and queries as file conversions inside Riviera allows us to operate these features at Dropbox scale.\n\r\n\r\n    \r\n        \r\n            \r\n    \r\n\r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n\r\n        \r\n        <!-- <img data-sly-test.highRes=\"\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-riviera_2x.png 2x, /cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-riviera_2x.png.transform/half-res/img.png 1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-riviera_2x.png\"\r\n             aria-hidden=\"\"\r\n             alt=\"\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"720\"\r\n             data-sly-attribute.height=\"673\"\r\n             data-aem-asset-id=\"46057bbc-1606-440d-85d8-9f203ed86c1d:aifilepreviews-diagram-riviera_2x.png\"\r\n             data-trackable=\"true\" />\r\n        <img data-sly-test.highRes=\"true\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-riviera_2x.png 2x, /cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-riviera_2x.png.transform/half-res/img.png 1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-riviera_2x.png\"\r\n             aria-hidden=\"\"\r\n             alt=\"\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"720\"\r\n             data-sly-attribute.height=\"673\"\r\n             data-aem-asset-id=\"46057bbc-1606-440d-85d8-9f203ed86c1d:aifilepreviews-diagram-riviera_2x.png\"\r\n             data-trackable=\"true\" /> -->\r\n\r\n        \r\n         \r\n        \r\n    \r\n\r\n            \nThe high level architecture of our file previews surface, with new machine learning components highlighted\n\r\n        \r\n    \r\n\n\r\n\r\n    \n The summarization plugin\n\r\n\r\n\n\nA common use case for LLMs is to concisely summarize large amounts of text. When negotiating a contract, for example, a person might copy the text from a contract PDF, paste it into an LLM-powered chat prompt, and ask the LLM to summarize it in understandable terms. While adding this feature into Dropbox may have been useful as-is, we decided that we didn’t want to stop there. Dropbox users store long documents, videos, and other rich media files in Dropbox, and a summarization feature only gets more useful as the length of the file increases. We wanted to unlock this feature for all of our users' files, no matter the format or length.\nFirst, we needed to define the qualities of a good summary. A contract to purchase a home might include many different concepts. There might be a long description of payment terms, wire instructions, good-faith deposits, and escrow accounts. It also might have a long description of contingencies and when they can be triggered. A good summary might simply say “this document is an agreement to purchase a home for X amount, and it has finance and inspection contingencies.” In other words, we defined a good summary as one that can identify all the different ideas or concepts in a document and give the reader the gist of each.\nLanguage models enable this to be implemented algorithmically using embeddings, which allow passages to be compared semantically. King and Queen might be relatively close together (they are both regal), King and Dog might be somewhere in the middle (they are both living beings, perhaps), while King and Toaster have very little in common. Language model embeddings allow us to compare passages on thousands of dimensions that are all learned through a long training process. These embeddings in turn enable efficient summarization of large files of essentially unlimited length. \nOur summarization plugin takes the chunks and associated embeddings from the embeddings plugin and uses k-means clustering to group the text chunks from the file into clusters in this multi-dimensional embedding space. With this method, we can organize data into distinct groups, or clusters, based on their characteristics, so that chunks with similar content are placed in the same cluster. We then identify major clusters (the main ideas of the file) and concatenate a representative chunk from the corresponding text from each cluster into one blob—the context. Finally, we generate a summary of that context via an LLM.\nWe found k-means clustering was better than alternatives such as a summary-of-summaries approach in a couple of ways:\nHigher diversity of topics. Many individual summaries before reaching the final summary of summaries often repeat similar information. Combining these summaries results in a significant loss of overall file content. Using k-means clustering, we discovered that the summaries covered a broader range of topics—approximately 50% more than with map-reduce, since we search for chunks that are semantically dissimilar to one another.\nLower chance of hallucinations. When the LLM receives the entire file in one go, its likelihood of hallucinating decreases significantly. Conversely, each call made to the LLM presents a chance for hallucination, making the problem exponentially worse when summarizing summaries. The map-reduce approach lacks the context provided by other chunks, compounding the issue. Using the k-means technique, pinpointing errors in the final output—especially when comparing between LLMs or models—becomes much easier because there is just a single LLM call to evaluate.\n\r\n\r\n    \n The Q&A plugin\n\r\n\r\n\n\nOur Q&A plugin works in a similar manner to the summarization plugin, but in a somewhat opposite way. The Q&A plugin takes in the embeddings and text chunks from the embedding plugin and generates a new embedding for the user question. Then for each chunk of file text it computes the distance to the query text embedding. By calculating the closeness of each chunk to the query in vector space, the most relevant chunks are selected.\nIn the summarization plugin the text chunks were selected for dissimilarity, while in the Q&A plugin they were selected for similarity to the query text. These text chunks, along with the query, are sent to the language model for generating the answer. \nA language model uses the context to generate answers by analyzing the provided text chunks and the query to understand their meaning and relationships. When a query is received, the model first interprets the question and identifies key elements and intents. It then examines the text chunks, which serve as additional context, to extract relevant information. The model employs sophisticated algorithms to detect patterns, correlations, and nuances within the text, allowing it to discern how different pieces of information fit together. By integrating the context from the text chunks with the specifics of the query, the language model can produce a coherent and accurate response that is tailored to the query's requirements. This process involves leveraging large-scale language patterns learned during training, enabling the model to generate answers that are both contextually appropriate and informative.\nThe relevant chunk locations are then returned to the user as sources, allowing them to reference the specific parts of the file that contributed to the answer.\nAs an add on feature to both the summarization and Q&A plugins, we also request context-relevant follow-up questions from the LLM. In testing we found that follow-up questions allow the user to more naturally learn about a file and the topic they are interested in. To gather these follow-up questions, we utilize function calling and structured outputs to request follow-up questions from the LLM at the same time we request the summary or an answer to the initial question. \n\r\n\r\n    \n Expanding to multiple files\n\r\n\r\n\n\nThe first iteration of intelligent summaries and Q&A was limited to one file at a time—but we knew we could do better for our customers. We wanted to make LLM-powered understanding possible across collections of files, and not just individual documents.\nExpanding our understanding capabilities to multiple files within Dropbox involved a significant evolution of our capabilities, infrastructure, UI, and algorithms. Building on our existing file processing pipeline, we expanded Riviera’s capabilities to handle multiple files simultaneously inside of a single plugin. The embeddings plugin would still be separate for every file, but the final summarization or Q&A plugin call would need to take in multiple files. The question was: which subset of files selected by the user would we extract the relevant information from?\nWhen testing this feature, we found that some questions were quite direct (“What is Dropbox?”) while some were quite broad (“Can you explain this contract like I’m 5?”). For best results we found that we needed to tailor our response accordingly. Direct questions can often be answered in a single sentence, while the answers to broader questions are typically longer and potentially sourced from a wider context. The challenge was determining which type of answer was required. Put another way: How should we determine the number of relevant chunks or files to use when answering a request or query?\nWe eventually came to the conclusion that this was a trick question. You cannot determine if a question is direct or broad based just on the question itself. You also need the context the answer is pulled from. The question “What is Dropbox?” could both direct if asked about a list of tech companies, but also broad if asked about the Dropbox Wikipedia page.\nTo solve this question, we took advantage of power law dynamics to determine the number of relevant chunks to send to the LLM.\n\r\n\r\n    \r\n        \r\n            \r\n    \r\n\r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n\r\n        \r\n        <!-- <img data-sly-test.highRes=\"\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-ordering-by-relevance_2x.png 2x, /cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-ordering-by-relevance_2x.png.transform/half-res/img.png 1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-ordering-by-relevance_2x.png\"\r\n             aria-hidden=\"\"\r\n             alt=\"\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"720\"\r\n             data-sly-attribute.height=\"435\"\r\n             data-aem-asset-id=\"2790a713-cf18-4ba3-b2b5-8ca42d9642f9:aifilepreviews-diagram-ordering-by-relevance_2x.png\"\r\n             data-trackable=\"true\" />\r\n        <img data-sly-test.highRes=\"true\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-ordering-by-relevance_2x.png 2x, /cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-ordering-by-relevance_2x.png.transform/half-res/img.png 1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2024/07/ai-file-previews/aifilepreviews-diagram-ordering-by-relevance_2x.png\"\r\n             aria-hidden=\"\"\r\n             alt=\"\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"720\"\r\n             data-sly-attribute.height=\"435\"\r\n             data-aem-asset-id=\"2790a713-cf18-4ba3-b2b5-8ca42d9642f9:aifilepreviews-diagram-ordering-by-relevance_2x.png\"\r\n             data-trackable=\"true\" /> -->\r\n\r\n        \r\n         \r\n        \r\n    \r\n\r\n            \nLine A is a direct question, while line B is a broad question\n\r\n        \r\n    \r\n\nOur solutions takes the max and min relevance scores from the top 50 text chunks related to the user query, as calculated through the embeddings, and cuts off the bottom 20% of that spread. This works well because, as shown in the diagram above, direct questions have a steeper power law curve than broad questions. \nFor Example A above, lets say that the most relevant chunk has a score of 0.9 and the least is 0.2. In this case, everything below a 0.34 score is discarded (the 20th percentile score). Since the slope is steep, over half of the chunks will be discarded, leaving about 15 left. For Example B—a more broad question—let’s say that the most relevant chunk has a score of 0.5, and the least is 0.2. In this case, everything below a 0.26 would be discarded, leaving about 40 left. Since the slope is flatter, more chunks are chosen to send to the LLM.\nAnother example could be a quarterly earnings report. For the question “what were the financial results?” a lot of the chunks would have medium relevance, resulting in something similar to the B curve above, since it is a broad question. For a question like “how much was spent on real estate?” there would be some very relevant chunks and a lot of non-relevant chunks—like the A curve above, since it is a more direct question. The first question would require more chunks to answer the question fully versus the second question.\nThis algorithm allowed us to strategically determine which files and chunks within those files were relevant, and thus, which context to send to the LLM. Direct questions get less but more relevant context, while broad questions are given more context to expand on the topic.\n\r\n\r\n    \n What we learned\n\r\n\r\n\n\nBuilding the machine learning capabilities for file understanding within Dropbox involved a series of strategic decisions, technical challenges, and optimizations to ensure efficient and accurate performance and a scalable cost model. These include: \nReal-time processing. We had to decide between calculating embeddings and AI responses ahead of time or in real time. Computing these transformations ahead of time allows for lower latency, but we settled on computing responses in real time because of one main factor: it allows the user to choose which files to share with the LLM—and only those files. Privacy and security is a top priority at Dropbox, so this was an easy choice to go with. As a side benefit, computing these requests in real-time would also save us the cost of pre-computing requests that a user might never make.\nSegmentation and clustering. We also found numerous benefits to the segmentation and clustering of requests, versus sending full file text to the LLM. By only sending the most relevant parts of a file to the LLM in a single request, we could return summaries and answers with lower latency and lower cost. Allowing the LLM to focus on the context that matters most to the user’s request also yielded better quality results; we quickly learned through testing that sending garbage into the LLM means garbage out from the LLM.\nChunk priority calculation. To optimize token usage and ensure the most relevant information is included in the summary or answer, we calculate a priority tier for each chunk. The first two chunks chronologically are given top priority, followed by k-means clustering to select semantically dissimilar chunks for summary, or semantically similar chunks to a question. This approach maximizes the breadth of topics covered in the summary and enhances the quality and relevancy of the answer.\nEmbracing embeddings. This was a crucial decision. Embeddings enabled us to compare passages efficiently in a multi-dimensional space, allowing for more accurate summarization and question answering. For multi-file actions, it also meant that we could pick and choose which files were most relevant for a query out of a list of multiple files. Even though there is a cost in latency and compute to gather these embeddings for each file, they enable a much higher quality response from the LLM.\nCached embeddings. In our initial version, embeddings were not cached, resulting in multiple calls to the LLM for the same document. In the subsequent version, embeddings are cached, reducing the number of API calls and improving performance. This optimization also allows summaries and Q&A to use the same chunks and embeddings, further enhancing efficiency.\nAll of this work has yielded significant improvements in terms of cost and latency since the start of the project. Cost-per-summary dropped by 93%, and cost-per-query dropped by 64%. The p75 latency of summaries decreased from 115 seconds to 4 seconds, and the p75 latency for queries decreased from 25 seconds to 5 seconds. These optimizations have not only made summarization and Q&A more affordable for Dropbox, but more responsive for our users.\nFile previews with AI-powered summaries and Q&A are available in early access on select Dropbox plans. Visit our Help Center to learn more.\n~ ~ ~\nIf building innovative products, experiences, and infrastructure excites you, come build the future with us! Visit dropbox.com/jobs to see our open roles, and follow @LifeInsideDropbox on Instagram and Facebook to see what it's like to create a more enlightened way of working.",
        "dc:creator": "\r\n                            Binoy Dash,Bradley Crossen,Eric Cunningham,Royce Ausburn,Tejas Patel\r\n            \t\t\t",
        "content": "null",
        "contentSnippet": "null",
        "guid": "https://dropbox.tech/machine-learning/bringing-ai-powered-answers-and-summaries-to-file-previews-on-the-web",
        "categories": [
          "Machine Learning",
          "AI",
          "summarization",
          "LLM",
          "file previews",
          "Q&A",
          "Riviera"
        ],
        "isoDate": "2024-07-11T14:00:00.000Z"
      }
    ]
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": [
      {
        "creator": "sunyzero",
        "title": "M.2 NVMe Enclosure - USB4 외장 인클로저 Maiwo K1625",
        "link": "http://sunyzero.tistory.com/299",
        "pubDate": "Sun, 7 Jul 2024 20:26:18 +0900",
        "author": "sunyzero",
        "comments": "http://sunyzero.tistory.com/299#entry299comment",
        "content": "<p data-ke-size=\"size16\">알리에서 M.2 NVMe enclosure 중에 USB4 40Gbps 제품 중에 <span style=\"background-color: #f3c000;\">ASM2464PD</span> 칩셋을 사용한 제품이 있길래 테스트 해봤다. 기존의 USB4(혹은 썬더볼트3/썬더볼트4 = 이하 TB3, TB4) 제품은 썬더볼트인 경우에는 40Gbps로 작동하지만, USB3.x로 연결하면 대개 10Gbps 혹은 5Gbps로 작동한다. 하지만 ASM2464PD 칩셋은 USB 3.2 Gen2x2 20Gbps로도 작동이 되는 특성이 있어서 구매 후 이리저리 테스트 해봤다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">1. Maiwo k1625 제품의 스펙, 특징</h2>\n<p data-ke-size=\"size16\">Maiwo K1625는 Asmedia의 ASM2464PD 칩셋을 사용한 것이 특징이다. 기존의 썬더볼트나 USB4는 모두 인텔사의 칩셋을 사용하는데, 2023년에 드디어 asmedia도 USB4 (썬더볼트 호환) 칩셋을 내놓은 것이다.</p>\n<p data-ke-size=\"size16\">보통 NVMe 외장 케이스(enclosuer)의 속도는 USB3 계열로는 5Gbps, 10Gbps, 20Gbps 제품이 있고, TB3, TB4나 USB4의 40Gbps 제품이 있다. 보통 USB3 계열은 하위 호환이 잘되지만 썬더볼트는 USB와의 하위 호환은 별도의 칩셋으로 해결했었다. 주로 JMicron의 JMS582 칩셋을 추가로 사용했는데, Asmedia의 ASM2464PD 제품은 USB4 40Gbps 및 USB3.2의 20Gbps/10Gbps/5Gbps를 모두 지원하는 특징이 있다. 한 마디로 하나의 칩셋에 USB의 현재 기능을 다 넣었다고 보면 된다.</p>\n<p data-ke-size=\"size16\">참고로 <span style=\"background-color: #f6e199;\">해당 제품의 실제 탐색기의 전송속도는 평균 1.6~1.8 GB/s 정도 나온다고 보면 된다</span>. 물론 몇 기가바이트 이내로 작은 경우 캐시 효과로 잠깐동안 2GB/s 이상의 속도가 나오기도 한다. 보통 10Gbps USB 3.2 Gen2 제품이 900MB/s 정도 나오므로 대략 2배 정도의 속도라고 보면 된다. (10Gbps와 40Gbps지만 실제 속도는 4배가 아니다. TB3/TB4나 USB4의 40Gbps는 수치상 최대일뿐 실제 데이터 통신 대역폭으로는 22Gbps이기 때문에 생기는 오해이다.)</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"1_MAIWO_k1625_usb4_asm2464pd.jpg\" data-origin-width=\"847\" data-origin-height=\"845\"><span data-url=\"https://blog.kakaocdn.net/dn/bczP04/btsIrhdjkNq/L2FCMkv0bwBsgHqfIlnz51/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bczP04/btsIrhdjkNq/L2FCMkv0bwBsgHqfIlnz51/img.jpg\" data-alt=\"MAIWO K1625 USB4 SSD Enclosure 40Gbps 20Gbps 10Gbps 5Gbps\"><img src=\"https://blog.kakaocdn.net/dn/bczP04/btsIrhdjkNq/L2FCMkv0bwBsgHqfIlnz51/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbczP04%2FbtsIrhdjkNq%2FL2FCMkv0bwBsgHqfIlnz51%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"1_MAIWO_k1625_usb4_asm2464pd.jpg\" data-origin-width=\"847\" data-origin-height=\"845\"/></span><figcaption>MAIWO K1625 USB4 SSD Enclosure 40Gbps 20Gbps 10Gbps 5Gbps</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">참고로 USB4는 썬더볼트의 기술을 사용해서 만들었기 때문에 실질적으로는 TB3 및 TB4의 기술이다. 이에 관해서는 일전에 써둔 글이 있으니 이를 참고하기 바란다.</p>\n<p data-ke-size=\"size16\"><span style=\"background-color: #f6e199;\">썬더볼트와 USB4, 전송속도 및 호환성</span> <a href=\"https://sunyzero.tistory.com/291\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://sunyzero.tistory.com/291</a></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">2. 구성 및 외관</h2>\n<p data-ke-size=\"size16\"><br />제품 박스에는 본품과 약 15cm 정도의 USB4케이블, 써멀패드, 고무패킹이 있다. 본품을 열때는 딱히 툴이 필요없고, 스프링의 힘으로 고정되는 걸쇠가 2가 있는데, 생각보다 짱짱해서 스스로 풀릴 위험은 없다.&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"resize_2_20231124_171755 오픈.jpg\" data-origin-width=\"768\" data-origin-height=\"1024\"><span data-url=\"https://blog.kakaocdn.net/dn/bYEYCq/btsIqTRidpY/p7CRmcQZjLAHD1rjz3Wne0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bYEYCq/btsIqTRidpY/p7CRmcQZjLAHD1rjz3Wne0/img.jpg\" data-alt=\"MAIWO K1625\"><img src=\"https://blog.kakaocdn.net/dn/bYEYCq/btsIqTRidpY/p7CRmcQZjLAHD1rjz3Wne0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbYEYCq%2FbtsIqTRidpY%2Fp7CRmcQZjLAHD1rjz3Wne0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"resize_2_20231124_171755 오픈.jpg\" data-origin-width=\"768\" data-origin-height=\"1024\"/></span><figcaption>MAIWO K1625</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">내부에는 별것이 없고 보이는 면의 기판은 별다른 것이 없다. 나사를 4개 풀면 들어낼 수 있다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"resize_3_20231124_171932 분해.jpg\" data-origin-width=\"768\" data-origin-height=\"1024\"><span data-url=\"https://blog.kakaocdn.net/dn/bxiQ2Z/btsIrsyVfzO/0BPpopdqs5NKmKWoFVIxa1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bxiQ2Z/btsIrsyVfzO/0BPpopdqs5NKmKWoFVIxa1/img.jpg\" data-alt=\"MAIWO K1625 and asm2464pd chipset\"><img src=\"https://blog.kakaocdn.net/dn/bxiQ2Z/btsIrsyVfzO/0BPpopdqs5NKmKWoFVIxa1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbxiQ2Z%2FbtsIrsyVfzO%2F0BPpopdqs5NKmKWoFVIxa1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"resize_3_20231124_171932 분해.jpg\" data-origin-width=\"768\" data-origin-height=\"1024\"/></span><figcaption>MAIWO K1625 and asm2464pd chipset</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">뒷면에는 각종 부속품들이 보이고, 위 그립 상단 왼쪽에 가장 큰 칩셋이 ASM2464PD 칩셋이다. 해당 칩셋을 약간 근접샷으로 찍어보면 정확하게 칩셋 이름이 보인다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"resize_4_20231124_172016 asm2464pd zoom in.jpg\" data-origin-width=\"768\" data-origin-height=\"1024\"><span data-url=\"https://blog.kakaocdn.net/dn/bnm3aL/btsIpJIWn4b/OjhO3LRyONXTDuvhTeLNk0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bnm3aL/btsIpJIWn4b/OjhO3LRyONXTDuvhTeLNk0/img.jpg\" data-alt=\"MAIWO K1625, asm2464pd\"><img src=\"https://blog.kakaocdn.net/dn/bnm3aL/btsIpJIWn4b/OjhO3LRyONXTDuvhTeLNk0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbnm3aL%2FbtsIpJIWn4b%2FOjhO3LRyONXTDuvhTeLNk0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"resize_4_20231124_172016 asm2464pd zoom in.jpg\" data-origin-width=\"768\" data-origin-height=\"1024\"/></span><figcaption>MAIWO K1625, asm2464pd</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">ASM2464PD 칩셋은 위와 같이 생겼다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">3. 속도 측정</h2>\n<p data-ke-size=\"size16\">속도 측정은 벤치마크 프로그램과 실제 탐색기의 속도를 비교해봤다. NVMe SSD는 디램리스 제품인 SN550 1TB와 디램탑재된 제품인 SN850X 및 PM9A1으로 테스트해보았다.</p>\n<p data-ke-size=\"size16\">참고로 간혹 잘못 연결되어서 썬더볼트나 USB4가 아닌 USB 3.2로 인식되면 윈도우에서는 경고 메시지로 느린 속도로 연결되었다고 나온다. 혹은 크리스탈디스크인포에 보면 전송 방식이 <span style=\"background-color: #9feec3;\">PCIe</span> 로 표시되면 썬더볼트나 USB4로 인식된 것이고, <span style=\"background-color: #ffc9af;\">UASP</span>로 나오면 USB 3.2로 인식된 것이다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"5_CrystalDiskMark_20231126143011_TB4enclosure_MAIWO_sn550_nocache_win11.png\" data-origin-width=\"602\" data-origin-height=\"441\"><span data-url=\"https://blog.kakaocdn.net/dn/vU01L/btsIpHqQnyB/FRV75X7CntS5uxguDURM4k/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/vU01L/btsIpHqQnyB/FRV75X7CntS5uxguDURM4k/img.png\" data-alt=\"Maiwo K1625 and SN550 1TB\"><img src=\"https://blog.kakaocdn.net/dn/vU01L/btsIpHqQnyB/FRV75X7CntS5uxguDURM4k/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FvU01L%2FbtsIpHqQnyB%2FFRV75X7CntS5uxguDURM4k%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"5_CrystalDiskMark_20231126143011_TB4enclosure_MAIWO_sn550_nocache_win11.png\" data-origin-width=\"602\" data-origin-height=\"441\"/></span><figcaption>Maiwo K1625 and SN550 1TB</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">디램리스 제품인 SN550으로는 읽기 2450MB/s, 쓰기 2021MB/s 정도로 trim 후 몇번을 테스트를 해봐도 비슷한 수치가 나온다.&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"5_CrystalDiskMark_20231126233935_TB4enclosure_MAIWO_sn850x_cacheenabled.png\" data-origin-width=\"602\" data-origin-height=\"441\"><span data-url=\"https://blog.kakaocdn.net/dn/boIhRa/btsIpWnIyCY/N2YK1kkISiCFkimKXBOnMk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/boIhRa/btsIpWnIyCY/N2YK1kkISiCFkimKXBOnMk/img.png\" data-alt=\"Maiwo K1625 and SN850x 2TB SSD\"><img src=\"https://blog.kakaocdn.net/dn/boIhRa/btsIpWnIyCY/N2YK1kkISiCFkimKXBOnMk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FboIhRa%2FbtsIpWnIyCY%2FN2YK1kkISiCFkimKXBOnMk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"5_CrystalDiskMark_20231126233935_TB4enclosure_MAIWO_sn850x_cacheenabled.png\" data-origin-width=\"602\" data-origin-height=\"441\"/></span><figcaption>Maiwo K1625 and SN850x 2TB SSD</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">디램 탑제 제품인 SN850x로는 읽기/쓰기가 3080MB/s, 2811MB/s 정도가 나오는데, 이보다 더큰 차이는 랜덤 4k쪽의 차이가 컸다. 하지만 실사용에서는 큰 차이가 없었다. PM9A1도 SN850x와 속도가 거의 비슷하게 나왔다.</p>\n<p data-ke-size=\"size16\">하지만 벤치마크와 달리 실제 사용시에는 위와 같은 속도는 나오지 않는다. 실제 탐색기에서 20GB 정도크기의 파일을 복사해보면 아래와 같은 속도가 나온다. (원본 파일은 SN850x로 PCIe 4에 장착된 SSD에 있었고, Maiwo k1625에는 PM9A1을 넣고 테스트했다.) 아래 캡쳐했을때는 캡쳐 프로그램이 작동하면서 잠깐 속도가 떨어진 상태이고, 실제로는 평균은 1.5~1.8GB/s이고, 최대로는 2.1GB/s 정도로 나왔다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"k1625_explorer_copy.png\" data-origin-width=\"613\" data-origin-height=\"324\"><span data-url=\"https://blog.kakaocdn.net/dn/bt7Pr5/btsIrO9z8W6/5b44mVXJj20uzX3kGwxsV0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bt7Pr5/btsIrO9z8W6/5b44mVXJj20uzX3kGwxsV0/img.png\" data-alt=\"Maiwo K1625의 탐색기 실제 복사 속도 (USB4 40Gbps 연결시)\"><img src=\"https://blog.kakaocdn.net/dn/bt7Pr5/btsIrO9z8W6/5b44mVXJj20uzX3kGwxsV0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbt7Pr5%2FbtsIrO9z8W6%2F5b44mVXJj20uzX3kGwxsV0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"k1625_explorer_copy.png\" data-origin-width=\"613\" data-origin-height=\"324\"/></span><figcaption>Maiwo K1625의 탐색기 실제 복사 속도 (USB4 40Gbps 연결시)</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">USB3.2 Gen2 10Gbps에 연결한 경우 평균 700~800MB/s의 속도밖에 안나온다. 이는 다른 10Gbps 외장 케이스와 차이가 없는 수치이다.[2]</p>\n<p data-ke-size=\"size16\">간혹 PC를 다른곳에 연결하면 속도가 떨어지는 경우도 있는데, 이건 윈도11에서 외장 디스크는 캐시를 쓰지 않도록 되어있어서 그렇다. 아래와 같이 캐시를 사용하도록 해주면 해결된다. (장치관리자에서 디스크 드라이브에서 해당 목록을 선택하면 된다.)</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"dev_manager_disk_cache.png\" data-origin-width=\"693\" data-origin-height=\"658\"><span data-url=\"https://blog.kakaocdn.net/dn/bDFDsn/btsIqPOTBy5/mbkHr1hPk0LJ4QnsjKLns0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bDFDsn/btsIqPOTBy5/mbkHr1hPk0LJ4QnsjKLns0/img.png\" data-alt=\"장치관리자 디스크 드라이브의 정책 설정\"><img src=\"https://blog.kakaocdn.net/dn/bDFDsn/btsIqPOTBy5/mbkHr1hPk0LJ4QnsjKLns0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbDFDsn%2FbtsIqPOTBy5%2FmbkHr1hPk0LJ4QnsjKLns0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"dev_manager_disk_cache.png\" data-origin-width=\"693\" data-origin-height=\"658\"/></span><figcaption>장치관리자 디스크 드라이브의 정책 설정</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">중요한 점은 이와 같이 사용하다가 디스크를 뺄 때는 하드웨어 안전하게 제거를 선택하는 것이 좋다. 아니면 다른 글에서 쓴 것처럼 sync 기능을 사용해서 캐시 버퍼를 디스크에 기록하도록 명령하고 빼면 된다.</p>\n<p data-ke-size=\"size16\"><span style=\"background-color: #f6e199;\">윈10 디스크 rescan, flush(sync) 기능 : 안전 제거</span>&nbsp;<a href=\"https://sunyzero.tistory.com/275\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://sunyzero.tistory.com/275</a></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">4. 발열 측정</h2>\n<p data-ke-size=\"size16\">기본적으로 썬더볼트 외장 디스크는 발열이 꽤 높다. 평상시에도 섭씨 50도를 넘는다. 크리스탈 디스크 인포로 확인해보면 보통 55도 정도를 유지하고, 열화상 카메라로 찍어봐도 50도 정도로 보인다. 심지어 저 사진은 아무것도 안할 때 찍은 것이다. 실제로 벤치마크나 쓰기를 시작하면 55~58도 정도로 올라간다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"resize_열화상카메라 - 윗판 닫은 상태.jpg\" data-origin-width=\"1024\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/QPp1I/btsIpvqGuJ3/HLBMngTifhI12EuUfJA10K/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/QPp1I/btsIpvqGuJ3/HLBMngTifhI12EuUfJA10K/img.jpg\" data-alt=\"MAIWO K1625, temperature\"><img src=\"https://blog.kakaocdn.net/dn/QPp1I/btsIpvqGuJ3/HLBMngTifhI12EuUfJA10K/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FQPp1I%2FbtsIpvqGuJ3%2FHLBMngTifhI12EuUfJA10K%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"resize_열화상카메라 - 윗판 닫은 상태.jpg\" data-origin-width=\"1024\" data-origin-height=\"768\"/></span><figcaption>MAIWO K1625, temperature</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">Maiwo K1625의 윗 뚜껑을 따고 내부를 확인해보면 확실히 더 뜨겁다. (아무것도 안하는 idle 상태의 온도다)</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"resize_열화상카메라 - 윗판 개봉시.jpg\" data-origin-width=\"1024\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/zPLj7/btsIp7icbDd/5z6l4KAv6El0nwFVADNmg0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/zPLj7/btsIp7icbDd/5z6l4KAv6El0nwFVADNmg0/img.jpg\" data-alt=\"MAIWO K1625, temperature\"><img src=\"https://blog.kakaocdn.net/dn/zPLj7/btsIp7icbDd/5z6l4KAv6El0nwFVADNmg0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FzPLj7%2FbtsIp7icbDd%2F5z6l4KAv6El0nwFVADNmg0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"resize_열화상카메라 - 윗판 개봉시.jpg\" data-origin-width=\"1024\" data-origin-height=\"768\"/></span><figcaption>MAIWO K1625, temperature</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">완전히 탈거해서 아랫쪽에 있는 ASM2464PD 칩셋을 보면 컨트롤러의 온도는 80도에 유박한다. 손으로 만지면 그냥 화상을 입을 것이다. 신기한 것은 ASM2464PD 칩셋외에는 온도가 높은 칩셋이 없었다. (아무것도 하지 않는 상태의 온도다)</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"resize_열화상카메라 - 뒷면 컨트롤러.jpg\" data-origin-width=\"1024\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/pgPpK/btsIphTFy9J/L7kt1HLj4OMkQEjsrS7pH1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/pgPpK/btsIphTFy9J/L7kt1HLj4OMkQEjsrS7pH1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/pgPpK/btsIphTFy9J/L7kt1HLj4OMkQEjsrS7pH1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FpgPpK%2FbtsIphTFy9J%2FL7kt1HLj4OMkQEjsrS7pH1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"resize_열화상카메라 - 뒷면 컨트롤러.jpg\" data-origin-width=\"1024\" data-origin-height=\"768\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">어떤 분은 PCIe의 절전 기능인 ASPM(Active State Power Management)를 켜면 발열이 줄어든다고 했다. 그래서 BIOS에서 해당 기능을 찾아서 켜주고, 윈도우 제어판에서 PCIe 절전 기능을 켰다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"win11 PCIe ASPM powersave.png\" data-origin-width=\"1432\" data-origin-height=\"692\"><span data-url=\"https://blog.kakaocdn.net/dn/ybu39/btsIqPg4K6i/Z3cKskHR57jVoMXGdCWUK0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ybu39/btsIqPg4K6i/Z3cKskHR57jVoMXGdCWUK0/img.png\" data-alt=\"Win11 - control panel - power option - PCIe link state power management - powersave\"><img src=\"https://blog.kakaocdn.net/dn/ybu39/btsIqPg4K6i/Z3cKskHR57jVoMXGdCWUK0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fybu39%2FbtsIqPg4K6i%2FZ3cKskHR57jVoMXGdCWUK0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"win11 PCIe ASPM powersave.png\" data-origin-width=\"1432\" data-origin-height=\"692\"/></span><figcaption>Win11 - control panel - power option - PCIe link state power management - powersave</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">ASPM을 설정하니까 평균적으로 섭씨 3~4도 정도는 떨어졌다. 그럼에도 불구하고 여전히 뜨겁긴 하다. 전원 관리 정책(power management policy)으로 Maiwo k1625의 발열을 획기적으로 낮추는 것은 불가능해 보인다. <span style=\"color: #ee2323;\">게다가 최대 절전으로 해두면 이상하게 연결이 끊어지고 다시 붙지 않는 경우가 종종 발생했다. 이는 윈도우11의 문제인 것 같다. 리눅스에서는 해당 문제가 발생하지 않았다.</span></p>\n<p data-ke-size=\"size16\">하지만 신기하게도 USB 연결로 작동할 때는 절전 기능이 매우 잘 작동해서 빠르게 열을 낮춘다. 조금이라도 사용하지 않으면 즉시 1W의 전력을 소비하면서 온도가 착해지는 장점이 있었다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">5. 펌웨어 및 장치 상태</h2>\n<p data-ke-size=\"size16\">MPtool로 펌웨어 버전을 확인하면 다음과 같이 231005850000 이다. 이 제품의 구입이 올 초였으니까 이후에 구입한 사람은 펌웨어 버전이 더 높을 가능성이 있다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"asm2464PD_maiwo k1695 firmware statu.png\" data-origin-width=\"1856\" data-origin-height=\"701\"><span data-url=\"https://blog.kakaocdn.net/dn/365ja/btsIqalHnMP/iadItU2UQN4VXqDTpRdCG0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/365ja/btsIqalHnMP/iadItU2UQN4VXqDTpRdCG0/img.png\" data-alt=\"asmedia MPtool - Maiwo K1625 asm2464PD firmware\"><img src=\"https://blog.kakaocdn.net/dn/365ja/btsIqalHnMP/iadItU2UQN4VXqDTpRdCG0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F365ja%2FbtsIqalHnMP%2FiadItU2UQN4VXqDTpRdCG0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"asm2464PD_maiwo k1695 firmware statu.png\" data-origin-width=\"1856\" data-origin-height=\"701\"/></span><figcaption>asmedia MPtool - Maiwo K1625 asm2464PD firmware</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">HWinfo 툴로 확인해보면 다음과 같이 보인다. 현재 상태는 ASPM을 켜놓아서 L1 entry가 활성화 되어있음을 볼 수 있다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"HWinfo_asm2564pd.png\" data-origin-width=\"2067\" data-origin-height=\"1432\"><span data-url=\"https://blog.kakaocdn.net/dn/cqlsxJ/btsIpG6zAjM/SiprMpGsEVkJNMwyIkKgZK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cqlsxJ/btsIpG6zAjM/SiprMpGsEVkJNMwyIkKgZK/img.png\" data-alt=\"MAIWO K1625 , asm2464pd\"><img src=\"https://blog.kakaocdn.net/dn/cqlsxJ/btsIpG6zAjM/SiprMpGsEVkJNMwyIkKgZK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcqlsxJ%2FbtsIpG6zAjM%2FSiprMpGsEVkJNMwyIkKgZK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"HWinfo_asm2564pd.png\" data-origin-width=\"2067\" data-origin-height=\"1432\"/></span><figcaption>MAIWO K1625 , asm2464pd</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">6. 총평</h2>\n<p data-ke-size=\"size16\">인텔 칩셋을 사용한 썬더볼트3 인클로저에 비해서 딱히 강점이라는 것은 없어 보인다. 인텝칩을 사용한 제품들에 비해 USB3.2 Gen2x2 20Gbps를 지원하는 장점이 있긴 하지만 20Gbps USB는 사장되는 분위기라 사용하는 시스템이 많지 않고, 앞으로 점점 USB4로 옮겨가는 것에 비하면 계륵같은 존재다.</p>\n<p data-ke-size=\"size16\">그래도 장점으로는 USB4 (혹은 TB3, TB4 연결시) 복사 성능이 10Gbps USB 3.2 제품보다 거의 2배의 수준이라 한 번에 수백기가씩 옮기는 경우에는 확실히 이점이 있다. 하지만 이것도 발열이라는 복병으로 인해서 급격하게 성능이 꺽일 수 있다.</p>\n<p data-ke-size=\"size16\">따라서 가장 큰 약점은 발열이다. 발열이 심해도 너무 심한데, 위에 본 것처럼 컨트롤러 칩셋은 아무것도 안해도 80도 가까운 온도를 보여준다. 한번에 100기가가 넘는 파일을 옮겨보면 더 심하게 온도가 발생해서 외부 온도도 60도를 넘어서 손으로 잡기 힘들 정도였다. 나중에 보니까 Maiwo k1625에 팬이 달린 모델이 나왔는데, 쓰기를 많이 한다면 진짜 팬이 있는 모델을 써야 할 것 같다. 썬더볼트 외장을 구매한다면 팬 달린 제품을 권장하는데, 이게 또 소음이 있을 수 있다는 단점이 있다. 아니면 아래 사진처럼 알리에서 파는 공유기용 USB 팬을 구입해서 그 위에 두는 것도 괜찮을 것이다.(과거 ASUS 공유기가 발열로 죽는 경우가 있어서 사둔 팬에 올려두니 너무 잘 작동하였다. 보통 알리에서 라우터쿨러로 검색하면 된다.)</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"852\" data-origin-height=\"845\"><span data-url=\"https://blog.kakaocdn.net/dn/pNDRD/btsItFTZXWR/gf6lNMvMDO09nzgJqVEKh0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/pNDRD/btsItFTZXWR/gf6lNMvMDO09nzgJqVEKh0/img.png\" data-alt=\"라우터 쿨러 (router cooler)\"><img src=\"https://blog.kakaocdn.net/dn/pNDRD/btsItFTZXWR/gf6lNMvMDO09nzgJqVEKh0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FpNDRD%2FbtsItFTZXWR%2Fgf6lNMvMDO09nzgJqVEKh0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"852\" data-origin-height=\"845\"/></span><figcaption>라우터 쿨러 (router cooler)</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">레퍼런스</h2>\n<p data-ke-size=\"size16\">[1] List of SSD enclosure chipset,&nbsp;<a href=\"https://dancharblog.wordpress.com/2024/01/01/list-of-ssd-enclosure-chipsets-2022/#thundebrolt-5-enclosuresusb4-asm2464pd-ssd-enclosures\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://dancharblog.wordpress.com/2024/01/01/list-of-ssd-enclosure-chipsets-2022/#thundebrolt-5-enclosuresusb4-asm2464pd-ssd-enclosures</a></p>\n<p data-ke-size=\"size16\">[2]&nbsp;M.2 NVMe SSD 외장 인클로저 (유그린,오리코,제위), <a href=\"https://sunyzero.tistory.com/280\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://sunyzero.tistory.com/280</a></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">히스토리</h2>\n<p data-ke-size=\"size16\">2024.07.10 라우터 쿨러 내용 추가</p>\n<p data-ke-size=\"size16\">2024.07.07 초고</p>",
        "contentSnippet": "알리에서 M.2 NVMe enclosure 중에 USB4 40Gbps 제품 중에 ASM2464PD 칩셋을 사용한 제품이 있길래 테스트 해봤다. 기존의 USB4(혹은 썬더볼트3/썬더볼트4 = 이하 TB3, TB4) 제품은 썬더볼트인 경우에는 40Gbps로 작동하지만, USB3.x로 연결하면 대개 10Gbps 혹은 5Gbps로 작동한다. 하지만 ASM2464PD 칩셋은 USB 3.2 Gen2x2 20Gbps로도 작동이 되는 특성이 있어서 구매 후 이리저리 테스트 해봤다.\n \n1. Maiwo k1625 제품의 스펙, 특징\nMaiwo K1625는 Asmedia의 ASM2464PD 칩셋을 사용한 것이 특징이다. 기존의 썬더볼트나 USB4는 모두 인텔사의 칩셋을 사용하는데, 2023년에 드디어 asmedia도 USB4 (썬더볼트 호환) 칩셋을 내놓은 것이다.\n보통 NVMe 외장 케이스(enclosuer)의 속도는 USB3 계열로는 5Gbps, 10Gbps, 20Gbps 제품이 있고, TB3, TB4나 USB4의 40Gbps 제품이 있다. 보통 USB3 계열은 하위 호환이 잘되지만 썬더볼트는 USB와의 하위 호환은 별도의 칩셋으로 해결했었다. 주로 JMicron의 JMS582 칩셋을 추가로 사용했는데, Asmedia의 ASM2464PD 제품은 USB4 40Gbps 및 USB3.2의 20Gbps/10Gbps/5Gbps를 모두 지원하는 특징이 있다. 한 마디로 하나의 칩셋에 USB의 현재 기능을 다 넣었다고 보면 된다.\n참고로 해당 제품의 실제 탐색기의 전송속도는 평균 1.6~1.8 GB/s 정도 나온다고 보면 된다. 물론 몇 기가바이트 이내로 작은 경우 캐시 효과로 잠깐동안 2GB/s 이상의 속도가 나오기도 한다. 보통 10Gbps USB 3.2 Gen2 제품이 900MB/s 정도 나오므로 대략 2배 정도의 속도라고 보면 된다. (10Gbps와 40Gbps지만 실제 속도는 4배가 아니다. TB3/TB4나 USB4의 40Gbps는 수치상 최대일뿐 실제 데이터 통신 대역폭으로는 22Gbps이기 때문에 생기는 오해이다.)\nMAIWO K1625 USB4 SSD Enclosure 40Gbps 20Gbps 10Gbps 5Gbps\n\n\n참고로 USB4는 썬더볼트의 기술을 사용해서 만들었기 때문에 실질적으로는 TB3 및 TB4의 기술이다. 이에 관해서는 일전에 써둔 글이 있으니 이를 참고하기 바란다.\n썬더볼트와 USB4, 전송속도 및 호환성 https://sunyzero.tistory.com/291\n \n2. 구성 및 외관\n제품 박스에는 본품과 약 15cm 정도의 USB4케이블, 써멀패드, 고무패킹이 있다. 본품을 열때는 딱히 툴이 필요없고, 스프링의 힘으로 고정되는 걸쇠가 2가 있는데, 생각보다 짱짱해서 스스로 풀릴 위험은 없다. \nMAIWO K1625\n\n\n내부에는 별것이 없고 보이는 면의 기판은 별다른 것이 없다. 나사를 4개 풀면 들어낼 수 있다.\nMAIWO K1625 and asm2464pd chipset\n\n\n뒷면에는 각종 부속품들이 보이고, 위 그립 상단 왼쪽에 가장 큰 칩셋이 ASM2464PD 칩셋이다. 해당 칩셋을 약간 근접샷으로 찍어보면 정확하게 칩셋 이름이 보인다.\nMAIWO K1625, asm2464pd\n\n\nASM2464PD 칩셋은 위와 같이 생겼다.\n \n3. 속도 측정\n속도 측정은 벤치마크 프로그램과 실제 탐색기의 속도를 비교해봤다. NVMe SSD는 디램리스 제품인 SN550 1TB와 디램탑재된 제품인 SN850X 및 PM9A1으로 테스트해보았다.\n참고로 간혹 잘못 연결되어서 썬더볼트나 USB4가 아닌 USB 3.2로 인식되면 윈도우에서는 경고 메시지로 느린 속도로 연결되었다고 나온다. 혹은 크리스탈디스크인포에 보면 전송 방식이 PCIe 로 표시되면 썬더볼트나 USB4로 인식된 것이고, UASP로 나오면 USB 3.2로 인식된 것이다.\nMaiwo K1625 and SN550 1TB\n\n\n디램리스 제품인 SN550으로는 읽기 2450MB/s, 쓰기 2021MB/s 정도로 trim 후 몇번을 테스트를 해봐도 비슷한 수치가 나온다. \nMaiwo K1625 and SN850x 2TB SSD\n\n\n디램 탑제 제품인 SN850x로는 읽기/쓰기가 3080MB/s, 2811MB/s 정도가 나오는데, 이보다 더큰 차이는 랜덤 4k쪽의 차이가 컸다. 하지만 실사용에서는 큰 차이가 없었다. PM9A1도 SN850x와 속도가 거의 비슷하게 나왔다.\n하지만 벤치마크와 달리 실제 사용시에는 위와 같은 속도는 나오지 않는다. 실제 탐색기에서 20GB 정도크기의 파일을 복사해보면 아래와 같은 속도가 나온다. (원본 파일은 SN850x로 PCIe 4에 장착된 SSD에 있었고, Maiwo k1625에는 PM9A1을 넣고 테스트했다.) 아래 캡쳐했을때는 캡쳐 프로그램이 작동하면서 잠깐 속도가 떨어진 상태이고, 실제로는 평균은 1.5~1.8GB/s이고, 최대로는 2.1GB/s 정도로 나왔다.\nMaiwo K1625의 탐색기 실제 복사 속도 (USB4 40Gbps 연결시)\n\n\n \nUSB3.2 Gen2 10Gbps에 연결한 경우 평균 700~800MB/s의 속도밖에 안나온다. 이는 다른 10Gbps 외장 케이스와 차이가 없는 수치이다.[2]\n간혹 PC를 다른곳에 연결하면 속도가 떨어지는 경우도 있는데, 이건 윈도11에서 외장 디스크는 캐시를 쓰지 않도록 되어있어서 그렇다. 아래와 같이 캐시를 사용하도록 해주면 해결된다. (장치관리자에서 디스크 드라이브에서 해당 목록을 선택하면 된다.)\n장치관리자 디스크 드라이브의 정책 설정\n\n\n중요한 점은 이와 같이 사용하다가 디스크를 뺄 때는 하드웨어 안전하게 제거를 선택하는 것이 좋다. 아니면 다른 글에서 쓴 것처럼 sync 기능을 사용해서 캐시 버퍼를 디스크에 기록하도록 명령하고 빼면 된다.\n윈10 디스크 rescan, flush(sync) 기능 : 안전 제거 https://sunyzero.tistory.com/275\n \n4. 발열 측정\n기본적으로 썬더볼트 외장 디스크는 발열이 꽤 높다. 평상시에도 섭씨 50도를 넘는다. 크리스탈 디스크 인포로 확인해보면 보통 55도 정도를 유지하고, 열화상 카메라로 찍어봐도 50도 정도로 보인다. 심지어 저 사진은 아무것도 안할 때 찍은 것이다. 실제로 벤치마크나 쓰기를 시작하면 55~58도 정도로 올라간다.\nMAIWO K1625, temperature\n\n\n \nMaiwo K1625의 윗 뚜껑을 따고 내부를 확인해보면 확실히 더 뜨겁다. (아무것도 안하는 idle 상태의 온도다)\nMAIWO K1625, temperature\n\n\n완전히 탈거해서 아랫쪽에 있는 ASM2464PD 칩셋을 보면 컨트롤러의 온도는 80도에 유박한다. 손으로 만지면 그냥 화상을 입을 것이다. 신기한 것은 ASM2464PD 칩셋외에는 온도가 높은 칩셋이 없었다. (아무것도 하지 않는 상태의 온도다)\n\n\n어떤 분은 PCIe의 절전 기능인 ASPM(Active State Power Management)를 켜면 발열이 줄어든다고 했다. 그래서 BIOS에서 해당 기능을 찾아서 켜주고, 윈도우 제어판에서 PCIe 절전 기능을 켰다.\nWin11 - control panel - power option - PCIe link state power management - powersave\n\n\nASPM을 설정하니까 평균적으로 섭씨 3~4도 정도는 떨어졌다. 그럼에도 불구하고 여전히 뜨겁긴 하다. 전원 관리 정책(power management policy)으로 Maiwo k1625의 발열을 획기적으로 낮추는 것은 불가능해 보인다. 게다가 최대 절전으로 해두면 이상하게 연결이 끊어지고 다시 붙지 않는 경우가 종종 발생했다. 이는 윈도우11의 문제인 것 같다. 리눅스에서는 해당 문제가 발생하지 않았다.\n하지만 신기하게도 USB 연결로 작동할 때는 절전 기능이 매우 잘 작동해서 빠르게 열을 낮춘다. 조금이라도 사용하지 않으면 즉시 1W의 전력을 소비하면서 온도가 착해지는 장점이 있었다.\n \n5. 펌웨어 및 장치 상태\nMPtool로 펌웨어 버전을 확인하면 다음과 같이 231005850000 이다. 이 제품의 구입이 올 초였으니까 이후에 구입한 사람은 펌웨어 버전이 더 높을 가능성이 있다.\nasmedia MPtool - Maiwo K1625 asm2464PD firmware\n\n\nHWinfo 툴로 확인해보면 다음과 같이 보인다. 현재 상태는 ASPM을 켜놓아서 L1 entry가 활성화 되어있음을 볼 수 있다.\nMAIWO K1625 , asm2464pd\n\n\n \n6. 총평\n인텔 칩셋을 사용한 썬더볼트3 인클로저에 비해서 딱히 강점이라는 것은 없어 보인다. 인텝칩을 사용한 제품들에 비해 USB3.2 Gen2x2 20Gbps를 지원하는 장점이 있긴 하지만 20Gbps USB는 사장되는 분위기라 사용하는 시스템이 많지 않고, 앞으로 점점 USB4로 옮겨가는 것에 비하면 계륵같은 존재다.\n그래도 장점으로는 USB4 (혹은 TB3, TB4 연결시) 복사 성능이 10Gbps USB 3.2 제품보다 거의 2배의 수준이라 한 번에 수백기가씩 옮기는 경우에는 확실히 이점이 있다. 하지만 이것도 발열이라는 복병으로 인해서 급격하게 성능이 꺽일 수 있다.\n따라서 가장 큰 약점은 발열이다. 발열이 심해도 너무 심한데, 위에 본 것처럼 컨트롤러 칩셋은 아무것도 안해도 80도 가까운 온도를 보여준다. 한번에 100기가가 넘는 파일을 옮겨보면 더 심하게 온도가 발생해서 외부 온도도 60도를 넘어서 손으로 잡기 힘들 정도였다. 나중에 보니까 Maiwo k1625에 팬이 달린 모델이 나왔는데, 쓰기를 많이 한다면 진짜 팬이 있는 모델을 써야 할 것 같다. 썬더볼트 외장을 구매한다면 팬 달린 제품을 권장하는데, 이게 또 소음이 있을 수 있다는 단점이 있다. 아니면 아래 사진처럼 알리에서 파는 공유기용 USB 팬을 구입해서 그 위에 두는 것도 괜찮을 것이다.(과거 ASUS 공유기가 발열로 죽는 경우가 있어서 사둔 팬에 올려두니 너무 잘 작동하였다. 보통 알리에서 라우터쿨러로 검색하면 된다.)\n라우터 쿨러 (router cooler)\n\n\n \n레퍼런스\n[1] List of SSD enclosure chipset, https://dancharblog.wordpress.com/2024/01/01/list-of-ssd-enclosure-chipsets-2022/#thundebrolt-5-enclosuresusb4-asm2464pd-ssd-enclosures\n[2] M.2 NVMe SSD 외장 인클로저 (유그린,오리코,제위), https://sunyzero.tistory.com/280\n \n히스토리\n2024.07.10 라우터 쿨러 내용 추가\n2024.07.07 초고",
        "guid": "http://sunyzero.tistory.com/299",
        "categories": [
          "컴퓨터 관련/기타 등등",
          "m.2 nvme enclosure",
          "maiwo k1625",
          "usb4 asm2464pd",
          "usb4 외장 디스크",
          "썬더볼트 외장 디스크"
        ],
        "isoDate": "2024-07-07T11:26:18.000Z"
      }
    ]
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": [
      {
        "title": "pandas AI 이용한 표 형식 데이터 생성AI로 처리해 보기",
        "link": "http://daddynkidsmakers.blogspot.com/2024/07/pandas-ai-ai.html",
        "pubDate": "2024-07-12T11:33:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">이 글은&nbsp;pandas AI 이용한 표 형식 데이터 생성AI로 처리해 보는 방법을 간략히 정리한다.<br /></div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEgVkwuvFaQen-42SQch-oPTBRAwnnvJfFjHCS11Woi-n1K_ZsrhYpkGHKsESYSNJzqAMXChHXcWOtHjxNJGAQntDIG8Hmw2Evxa07mpLLPQy-CwaT0o-JJDh4XeCRBCsUr8HiG2Qv3mDh5X5NT-JjX9CFkgZOFEVG4xi6Rl08K0cEDiVtfwyO7iWXAzAd1f\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"500\" data-original-width=\"800\" height=\"250\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgVkwuvFaQen-42SQch-oPTBRAwnnvJfFjHCS11Woi-n1K_ZsrhYpkGHKsESYSNJzqAMXChHXcWOtHjxNJGAQntDIG8Hmw2Evxa07mpLLPQy-CwaT0o-JJDh4XeCRBCsUr8HiG2Qv3mDh5X5NT-JjX9CFkgZOFEVG4xi6Rl08K0cEDiVtfwyO7iWXAzAd1f=w400-h250\" width=\"400\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEhKvj69LoCWf3yRZmk_ciCj1oentwi__YYU8trQ81SiC0ZzgGjYbtcqD4Cu1SUc5CytZupZLl6EwWFiWuCi61IV4cE1QU8CDNnMeQcFKK9yrTQJUNLB2BLucyYgdlNHmLq0q1U1236GBThJaT9qnPsLyCiskUw2t5q2kbsFjkCbYE85hNL86aqZPud_OrzN\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"146\" data-original-width=\"500\" height=\"116\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhKvj69LoCWf3yRZmk_ciCj1oentwi__YYU8trQ81SiC0ZzgGjYbtcqD4Cu1SUc5CytZupZLl6EwWFiWuCi61IV4cE1QU8CDNnMeQcFKK9yrTQJUNLB2BLucyYgdlNHmLq0q1U1236GBThJaT9qnPsLyCiskUw2t5q2kbsFjkCbYE85hNL86aqZPud_OrzN=w400-h116\" width=\"400\" /></a></div><br /></div></div><b>레퍼런스</b><br /><ul style=\"text-align: left;\"><li><a href=\"https://github.com/Sinaptik-AI/pandas-ai\">pandas-ai: Chat with your database (SQL, CSV, pandas, polars, mongodb, noSQL, etc). PandasAI makes data analysis conversational using LLMs (GPT 3.5 / 4, Anthropic, VertexAI) and RAG</a></li></ul></div>",
        "contentSnippet": "이 글은 pandas AI 이용한 표 형식 데이터 생성AI로 처리해 보는 방법을 간략히 정리한다.\n\n\n\n\n\n\n레퍼런스\n\npandas-ai: Chat with your database (SQL, CSV, pandas, polars, mongodb, noSQL, etc). PandasAI makes data analysis conversational using LLMs (GPT 3.5 / 4, Anthropic, VertexAI) and RAG",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-8890276364037553078",
        "isoDate": "2024-07-12T11:33:00.000Z"
      }
    ]
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권영재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김병환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김상훈",
    "category": "개인",
    "posts": [
      {
        "creator": "김상훈",
        "title": "비 대신, 가뭄을 주는 구름(cloud)",
        "link": "https://interpiler.com/2024/07/12/%eb%b9%84-%eb%8c%80%ec%8b%a0-%ea%b0%80%eb%ad%84%ec%9d%84-%ec%a3%bc%eb%8a%94-%ea%b5%ac%eb%a6%84cloud/",
        "pubDate": "Fri, 12 Jul 2024 08:58:45 +0000",
        "content:encodedSnippet": "하늘의 구름이 아니라, 클라우드 컴퓨팅의 그 구름(cloud) 얘기다.\n인공지능(AI) 열풍 때문에 데이터센터 건설 붐이 일었고, 데이터센터가 잡아먹는 전기가 어마어마해서 지역 정전까지 걱정할 상황이란 얘기가 계속 나온다. 갑자기 소형원자로 산업이 주목을 받질 않나, 소형원자로 조차도 도입을 결정해서 가동할 때까지 최소 5년 이상 걸리니 그 사이를 채우기 위해 태양광발전만이 대안이라질 않나, 전기 관련한 얘기는 끝이 없다.\n하지만 물은 전기 만큼의 관심을 받지 못한다.\n데이터센터의 전기는 반도체를 돌릴 때에도 필요하지만, 열심히 계산을 하느라 열을 잔뜩 뿜어낸 반도체를 식힐 때도 사용된다. 에어컨을 돌려 더워진 반도체를 식히는 방식이다. 비효율적이니 사람들은 더 효율적인 방법을 고민했다. 데이터센터를 추운 곳에 짓는다거나, 심지어 바다속에 짓겠다는 아이디어가 이래서 나왔다. 이 과정에서 찾아낸 현재의 가장 비용효율적인 냉각 방식이 냉각수를 사용하는 방식이다. 대개의 원리는 이렇다.\n에어컨을 수냉식으로 돌린다. 공기를 직접 냉매로 식히는 대신, 찬 물을 만들어 공기를 식히는 방식이다.\n우선 데이터센터 전역을 휘감는 냉각코일을 설치한 뒤 중앙냉각기에서 물을 냉각해, 차가워진 물을 코일로 보낸다. \n찬 물은 센터를 휘돌며 공기를 식히고, 열을 머금는다. 이렇게 더워진 물은 센터 외부의 냉각탑으로 보내진다.\n냉각탑은 외부 기온으로도 냉각수 온도를 낮추지만, 더 빨리 더 많이 온도를 낮추기 위해 일부 물을 증발시킨다. 기화열을 빼앗기도록 해 전기는 아끼지만, 당연히 이만큼의 물은 하늘로 증발된다.\n구글의 데이터센터는 (단 한 곳 기준으로도) 이런 냉각수로만 하루 210만리터의 물을 사용한다. 올림픽 경기를 여는 국제규격 수영장 하나를 가득 채우고도 남는 양이다.\n추운 지역은 건조한 날이 상대적으로 많게 마련이다. 가습에도 물이 사용된다. 건조한 환경은 정전기 발생 가능성을 높이고, 데이터센터의 민감한 부품들을 망가뜨린다. 냉각수보다는 적지만 상당한 물이 이렇게 습도를 높이는데 사용된다.\n물 사용을 줄이려면 물을 재활용하면 되지 않느냐 물을 수 있지만, 결론부터 말하자면 어렵다. 일부 증발도 거치고, 긴 코일 사이를 흐르기도 하면서 냉각수에는 조금씩 미네랄이 쌓여간다. 즉, 물의 농도가 점점 짙어진다. 어느 순간에는 미네랄이 코일을 막을 수도 있고, 전기가 너무 잘 통하게 된 물이 다른 문제를 일으킬 수도 있다. 한두번 재활용은 할 수 있어도 몇 번 돌리면 버려야 한다는 얘기다. 게다가 재활용까지 할 수준의 물은 깨끗한 물이어야하는데, 그게 어지간한 데이터센터가 식용수를 냉각수로 사용하는 이유다. 물은 그 자체로도 귀하지만, 마실 수 있는 물은 훨씬 더 귀하다.\n이런 식의 계산도 가능하다. 예를 들어 2030년까지 유럽인은 1인당 하루 평균 3리터의 물을 소비할 계획이다. 현실에서 마시는 물 얘기가 아니다. 유럽인이 사용하는 인터넷 사용량을 데이터센터 용량으로 역산해 냉각수에 사용되는 물의 양을 계산했을 때 나오는 수치다. 즉, 우리는 조만간 마시는 물보다 더 많은 물을 반도체를 식히는데 쓰게 될 예정이다.\n지금까지 우리가 혐오시설이라 생각했던 시설들은 화석연료를 태우는 엔진들이 연기를 뿜어내는 제조공장이나, 유독한 화학물질을 다루는 화학공장, 먼지가 휘날리는 광산 등이었다. 데이터센터는 다르다. 겉으로 보기엔 깨끗하다. 가끔 피어오르는 연기도 수증기에 불과하다. 하지만 그 수증기가 인근의 물을 빨아들이고, 지역에 가뭄을 불러온다.\n데이터센터의 평균 수명은 10-20년 정도. 기술 발전의 속도와 효율성의 경제논리 때문에 이 정도 시간이 지나면 데이터센터는 다시 리노베이션되거나 버려지게 된다. 즉, 10-20년 비트(bit)를 채굴하는 광산을 건설하고 자원을 뽑아쓸만큼 뽑아쓰면 버려버리는 셈이다. 데이터센터 건설에 열을 올리는 빅테크 기업들은 나무를 더 많이 심고, 숲을 조성하겠다고 한다. 그리고, 동시에 그 나무에 줘야 하는 물을 말려버리고 있다.",
        "dc:creator": "김상훈",
        "comments": "https://interpiler.com/2024/07/12/%eb%b9%84-%eb%8c%80%ec%8b%a0-%ea%b0%80%eb%ad%84%ec%9d%84-%ec%a3%bc%eb%8a%94-%ea%b5%ac%eb%a6%84cloud/#respond",
        "content": "하늘의 구름이 아니라, 클라우드 컴퓨팅의 그 구름(cloud) 얘기다. 인공지능(AI) 열풍 때문에 데이터센터 건설 붐이 일었고, 데이터센터가 잡아먹는 전기가 어마어마해서 지역 정전까지 걱정할 상황이란 얘기가 계속 나온다. 갑자기 소형원자로 산업이 주목을 받질 않나, 소형원자로 조차도 도입을 결정해서 가동할 때까지 최소 5년 이상 걸리니 그 사이를 채우기 위해 태양광발전만이 대안이라질 않나, 전기 관련한 얘기는 끝이 없다. 하지만 &#8230; <a href=\"https://interpiler.com/2024/07/12/%eb%b9%84-%eb%8c%80%ec%8b%a0-%ea%b0%80%eb%ad%84%ec%9d%84-%ec%a3%bc%eb%8a%94-%ea%b5%ac%eb%a6%84cloud/\" class=\"more-link\">계속 읽기 <span class=\"screen-reader-text\">비 대신, 가뭄을 주는&#160;구름(cloud)</span> <span class=\"meta-nav\">\t</span></a>",
        "contentSnippet": "하늘의 구름이 아니라, 클라우드 컴퓨팅의 그 구름(cloud) 얘기다. 인공지능(AI) 열풍 때문에 데이터센터 건설 붐이 일었고, 데이터센터가 잡아먹는 전기가 어마어마해서 지역 정전까지 걱정할 상황이란 얘기가 계속 나온다. 갑자기 소형원자로 산업이 주목을 받질 않나, 소형원자로 조차도 도입을 결정해서 가동할 때까지 최소 5년 이상 걸리니 그 사이를 채우기 위해 태양광발전만이 대안이라질 않나, 전기 관련한 얘기는 끝이 없다. 하지만 … 계속 읽기 비 대신, 가뭄을 주는 구름(cloud)",
        "guid": "http://interpiler.com/?p=1482",
        "categories": [
          "That's IT",
          "AI",
          "냉각수",
          "데이터센터",
          "클라우드",
          "인공지능"
        ],
        "isoDate": "2024-07-12T08:58:45.000Z"
      }
    ]
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "for loop test",
        "link": "https://kangmyounghun.blogspot.com/2024/07/pipe-redirection.html",
        "pubDate": "2024-07-07T08:36:00.004Z",
        "author": "강명훈",
        "content": "<div>확장자 추출.</div>\n<div><pre><code class=\"java\">root@MHKANG:~# echo -e \"a.txt\\nb.php\"|grep -oP \"[^.]+$\"\ntxt\nphp</code></pre></div>\n<div><br /></div><div>윈도우는 파이프를 이용한 리다이렉션이 안 된다.</div>\n<div><pre><code>D:\\&gt;echo a.txt &amp; echo.b.php\na.txt\nb.php\n\nD:\\&gt;echo a.txt &amp; echo.b.php | findstr php\na.txt\nb.php</code></pre></div>\n<div><br /></div><div><span><a name='more'></a></span>파일 저장 후 테스트. 흉내는 내는데 매칭 결과만 출력해주는 기능은 없음.</div>\n<div><pre><code><div>D:\\&gt;echo a.txt &gt; test.txt &amp; echo.b.php &gt;&gt; test.txt</div><div><br /></div><div>D:\\&gt;type test.txt</div><div>a.txt</div><div>b.php</div><div><br /></div><div>D:\\&gt;findstr php test.txt</div><div>b.php</div><div><br /></div><div>D:\\&gt;findstr /r \"[^.]+$\" test.txt</div><div><br /></div><div>D:\\&gt;findstr /r \"[^.]*$\" test.txt</div><div>a.txt</div><div>b.php</div></code></pre></div>\n<div><br /></div><div>정규표현식 제한도 좀 있고.</div>\n<div><pre><code><div>D:\\&gt;findstr /?</div><div>파일에서 문자열을 찾습니다.</div><div><br /></div><div>FINDSTR [/B] [/E] [/L] [/R] [/S] [/I] [/X] [/V] [/N] [/M] [/O] [/P]</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;[/F:파일][/C:문자열] [/G:파일] [/D:디렉터리 목록] [/A:색 속성] [/OFF[LINE]]</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;문자열 [[드라이브:][경로]파일이름[ ...]]</div><div><br /></div><div>&nbsp; /B&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;패턴이 행의 첫 부분에 있는지를 비교합니다.</div><div>&nbsp; /E&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;패턴이 행의 끝부분에 있는지를 비교합니다.</div><div>&nbsp; /L&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;찾는 문자열을 글자 그대로 사용합니다.</div><div>&nbsp; /R&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;찾는 문자열을 정규식으로 사용합니다.</div><div>&nbsp; /S&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;현재 디렉터리와 모든 하위 디렉터리에서 일치하는 파일을 찾습니다.</div><div>&nbsp; /I&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;찾을 때 대/소문자를 구별하지 않습니다.</div><div>&nbsp; /X&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;정확히 일치하는 줄만 보여줍니다.</div><div>&nbsp; /V&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;일치하는 텍스트가 없는 줄만 보여줍니다.</div><div>&nbsp; /N&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;일치하는 각 줄 앞에 줄 번호를 보여줍니다.</div><div>&nbsp; /M&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;파일에 일치하는 텍스트가 있으면 파일 이름만 보여줍니다.</div><div>&nbsp; /O&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;일치하는 각 줄 앞에 문자 오프셋을 보여줍니다.</div><div>&nbsp; /P&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;인쇄할 수 없는 텍스트가 포함된 파일은 건너뜁니다.</div><div>&nbsp; /OFF[LINE] 오프라인 속성 세트 파일을 건너뛰지 않습니다.</div><div>&nbsp; /A:속성&nbsp; &nbsp; 색 속성을 두 자리 16진수로 지정합니다. \"color /?\"를 참조하십시오.</div><div>&nbsp; /F:파일&nbsp; &nbsp; 지정된 파일에서 파일 목록을 읽습니다('/'는 콘솔에 해당됩니다).</div><div>&nbsp; /C:문자열&nbsp; 지정된 텍스트를 글자 그대로 찾는 문자열로 사용합니다.</div><div>&nbsp; /G:파일&nbsp; &nbsp; 지정된 파일로부터 찾는 텍스트를 받습니다('/'는 콘솔에 해당됩니다).</div><div>&nbsp; /D:디렉터리&nbsp; &nbsp; 디렉터리 목록을 구분하는 세미콜론(;)를 찾습니다.</div><div>&nbsp; 문자열&nbsp; &nbsp; &nbsp;찾을 텍스트.</div><div>&nbsp; [드라이브:][경로]파일이름</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;찾을 파일을 지정합니다.</div><div><br /></div><div>/C 옵션을 사용한 경우가 아니면, 찾는 문자열을 여러 개 지정할 때</div><div>공백으로 분리하십시오. 예를 들면, 'FINDSTR \"hello there\" x.y' 명령을</div><div>입력하면 파일 x.y에서 \"hello\"나 \"there\"을 찾습니다.</div><div>반면에 'FINDSTR /C:\"hello there\" x.y' 명령을 입력하면 파일 x.y에서</div><div>\"hello there\"을 찾습니다.</div><div><br /></div><div>정규식에 대한 참고 사항:</div><div>&nbsp; .&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;와일드카드: 모든 문자</div><div>&nbsp; *&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;반복: 문자나 클래스에 대하여 0번 이상 반복</div><div>&nbsp; ^&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;행 위치: 행의 앞부분</div><div>&nbsp; $&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;행 위치: 행의 끝부분</div><div>&nbsp; [클래스]&nbsp; 문자 클래스: 세트에 있는 문자</div><div>&nbsp; [^클래스] 역 클래스: 세트에 없는 문자</div><div>&nbsp; [x-y]&nbsp; &nbsp; &nbsp;범위: 특정 범위에 있는 문자</div><div>&nbsp; \\x&nbsp; &nbsp; &nbsp; &nbsp; 이스케이프: 메타 문자 x를 문자 그대로 사용</div><div>&nbsp; \\&lt;xyz&nbsp; &nbsp; &nbsp;단어 위치: 단어의 앞부분</div><div>&nbsp; xyz\\&gt;&nbsp; &nbsp; &nbsp;단어 위치: 단어의 끝부분</div><div><br /></div><div>Findstr에서 사용 가능한 정규식은 온라인 명령을 참조하십시오.</div></code></pre></div>\n<div><br /></div>\n<div>파일을 지정한 for 반복문.</div>\n<div><pre><code>D:\\&gt;for /f %i in (test.txt) do @echo %i\na.txt\nb.php\n\nD:\\&gt;for /f \"delims=. tokens=2\" %i in (test.txt) do @echo %i\ntxt\nphp</code></pre><div><br /></div>\n  <div><div>문자열을 지정한 for 반복문.</div></div>\n  <pre><code><div>D:\\&gt;for /f \"tokens=2 delims=.\" %i in (\"a.txt\") do @echo %i</div><div>txt</div></code></pre>\n  <div><br /></div>\n  <div>명령어를 지정한 for 반복문.</div>\n  <pre><code><div>D:\\&gt;for /f \"tokens=2 delims=.\" %i in ('echo a.txt') do @echo %i</div><div>txt</div></code></pre></div><div><br /></div><div>안 되는 거 되게 많네.&nbsp;<strike><span style=\"font-size: x-small;\">리눅스 만세</span></strike></div><div><div><b><br /></b></div><div><b>관련 글</b></div><div><ul><li><a href=\"https://kangmyounghun.blogspot.com/2019/12/blog-post_15.html\" target=\"_blank\">파일명 일괄 변경</a></li></ul></div></div>",
        "contentSnippet": "확장자 추출.\nroot@MHKANG:~# echo -e \"a.txt\\nb.php\"|grep -oP \"[^.]+$\"\ntxt\nphp\n\n\n\n윈도우는 파이프를 이용한 리다이렉션이 안 된다.\nD:\\>echo a.txt & echo.b.php\na.txt\nb.php\n\nD:\\>echo a.txt & echo.b.php | findstr php\na.txt\nb.php\n\n\n\n파일 저장 후 테스트. 흉내는 내는데 매칭 결과만 출력해주는 기능은 없음.\n\nD:\\>echo a.txt > test.txt & echo.b.php >> test.txt\n\n\nD:\\>type test.txt\na.txt\nb.php\n\n\nD:\\>findstr php test.txt\nb.php\n\n\nD:\\>findstr /r \"[^.]+$\" test.txt\n\n\nD:\\>findstr /r \"[^.]*$\" test.txt\na.txt\nb.php\n\n\n\n\n정규표현식 제한도 좀 있고.\n\nD:\\>findstr /?\n파일에서 문자열을 찾습니다.\n\n\nFINDSTR [/B] [/E] [/L] [/R] [/S] [/I] [/X] [/V] [/N] [/M] [/O] [/P]\n         [/F:파일][/C:문자열] [/G:파일] [/D:디렉터리 목록] [/A:색 속성] [/OFF[LINE]]\n         문자열 [[드라이브:][경로]파일이름[ ...]]\n\n\n  /B         패턴이 행의 첫 부분에 있는지를 비교합니다.\n  /E         패턴이 행의 끝부분에 있는지를 비교합니다.\n  /L         찾는 문자열을 글자 그대로 사용합니다.\n  /R         찾는 문자열을 정규식으로 사용합니다.\n  /S         현재 디렉터리와 모든 하위 디렉터리에서 일치하는 파일을 찾습니다.\n  /I         찾을 때 대/소문자를 구별하지 않습니다.\n  /X         정확히 일치하는 줄만 보여줍니다.\n  /V         일치하는 텍스트가 없는 줄만 보여줍니다.\n  /N         일치하는 각 줄 앞에 줄 번호를 보여줍니다.\n  /M         파일에 일치하는 텍스트가 있으면 파일 이름만 보여줍니다.\n  /O         일치하는 각 줄 앞에 문자 오프셋을 보여줍니다.\n  /P         인쇄할 수 없는 텍스트가 포함된 파일은 건너뜁니다.\n  /OFF[LINE] 오프라인 속성 세트 파일을 건너뛰지 않습니다.\n  /A:속성    색 속성을 두 자리 16진수로 지정합니다. \"color /?\"를 참조하십시오.\n  /F:파일    지정된 파일에서 파일 목록을 읽습니다('/'는 콘솔에 해당됩니다).\n  /C:문자열  지정된 텍스트를 글자 그대로 찾는 문자열로 사용합니다.\n  /G:파일    지정된 파일로부터 찾는 텍스트를 받습니다('/'는 콘솔에 해당됩니다).\n  /D:디렉터리    디렉터리 목록을 구분하는 세미콜론(;)를 찾습니다.\n  문자열     찾을 텍스트.\n  [드라이브:][경로]파일이름\n             찾을 파일을 지정합니다.\n\n\n/C 옵션을 사용한 경우가 아니면, 찾는 문자열을 여러 개 지정할 때\n공백으로 분리하십시오. 예를 들면, 'FINDSTR \"hello there\" x.y' 명령을\n입력하면 파일 x.y에서 \"hello\"나 \"there\"을 찾습니다.\n반면에 'FINDSTR /C:\"hello there\" x.y' 명령을 입력하면 파일 x.y에서\n\"hello there\"을 찾습니다.\n\n\n정규식에 대한 참고 사항:\n  .         와일드카드: 모든 문자\n  *         반복: 문자나 클래스에 대하여 0번 이상 반복\n  ^         행 위치: 행의 앞부분\n  $         행 위치: 행의 끝부분\n  [클래스]  문자 클래스: 세트에 있는 문자\n  [^클래스] 역 클래스: 세트에 없는 문자\n  [x-y]     범위: 특정 범위에 있는 문자\n  \\x        이스케이프: 메타 문자 x를 문자 그대로 사용\n  \\<xyz     단어 위치: 단어의 앞부분\n  xyz\\>     단어 위치: 단어의 끝부분\n\n\nFindstr에서 사용 가능한 정규식은 온라인 명령을 참조하십시오.\n\n\n\n\n파일을 지정한 for 반복문.\nD:\\>for /f %i in (test.txt) do @echo %i\na.txt\nb.php\n\nD:\\>for /f \"delims=. tokens=2\" %i in (test.txt) do @echo %i\ntxt\nphp\n\n\n  \n문자열을 지정한 for 반복문.\n\n  \n\nD:\\>for /f \"tokens=2 delims=.\" %i in (\"a.txt\") do @echo %i\ntxt\n\n\n명령어를 지정한 for 반복문.\n\nD:\\>for /f \"tokens=2 delims=.\" %i in ('echo a.txt') do @echo %i\ntxt\n\n\n\n안 되는 거 되게 많네. 리눅스 만세\n\n\n\n관련 글\n\n파일명 일괄 변경",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-701081710191582402",
        "isoDate": "2024-07-07T08:36:00.004Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕홍",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김놀부",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "스마트한 검색창 윈디로 편하게 사는법",
        "link": "http://muzbox.tistory.com/483449",
        "pubDate": "Fri, 12 Jul 2024 09:19:42 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483449#entry483449comment",
        "content": "<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp; 윈디는&nbsp;윈도우&nbsp;사용자들을&nbsp;위한&nbsp;스마트한&nbsp;검색&nbsp;프로그램입니다.&nbsp;빠른&nbsp;파일/폴더&nbsp;검색,&nbsp;웹&nbsp;검색,&nbsp;날씨&nbsp;검색&nbsp;등&nbsp;다양한&nbsp;기능을&nbsp;제공하여&nbsp;작업&nbsp;효율을&nbsp;극대화합니다.&nbsp; </p>\n<table style=\"border-collapse: collapse; width: 95.6979%; height: 248px;\" border=\"1\" data-ke-align=\"alignLeft\">\n<tbody>\n<tr style=\"height: 62px;\"><!-- 첫 번째 열에 배경색을 노란색으로 설정 -->\n<td style=\"width: 13.1835%; height: 62px; text-align: center; background-color: #555555;\"><span style=\"color: #ffffff;\"><b>분류</b></span></td>\n<td style=\"width: 22.4483%; height: 62px; text-align: center;\">유틸리티/파일관리</td>\n<td style=\"width: 64.3682%; height: 248px; text-align: center;\" rowspan=\"4\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"윈디1.png\" data-origin-width=\"551\" data-origin-height=\"367\"><span data-url=\"https://blog.kakaocdn.net/dn/48Wd4/btsIwdCIkx0/bqedPQoZqIKXNPhcKgbvX1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/48Wd4/btsIwdCIkx0/bqedPQoZqIKXNPhcKgbvX1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/48Wd4/btsIwdCIkx0/bqedPQoZqIKXNPhcKgbvX1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F48Wd4%2FbtsIwdCIkx0%2FbqedPQoZqIKXNPhcKgbvX1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"윈디1.png\" data-origin-width=\"551\" data-origin-height=\"367\"/></span></figure>\n</td>\n</tr>\n<tr style=\"height: 62px;\"><!-- 첫 번째 열에 배경색을 노란색으로 설정 -->\n<td style=\"width: 13.1835%; height: 62px; text-align: center; background-color: #555555;\"><span style=\"color: #ffffff;\"><b>사용범위</b></span></td>\n<td style=\"width: 22.4483%; height: 62px; text-align: center;\">무료(개인/기)</td>\n</tr>\n<tr style=\"height: 62px;\"><!-- 첫 번째 열에 배경색을 노란색으로 설정 -->\n<td style=\"width: 13.1835%; height: 62px; text-align: center; background-color: #555555;\"><span style=\"color: #ffffff;\"><b>사용환경</b></span></td>\n<td style=\"width: 22.4483%; height: 62px; text-align: center;\">Windows</td>\n</tr>\n<tr style=\"height: 62px;\"><!-- 첫 번째 열에 배경색을 노란색으로 설정 -->\n<td style=\"width: 13.1835%; height: 62px; text-align: center; background-color: #555555;\"><span style=\"color: #ffffff;\"><b>제작사</b></span></td>\n<td style=\"width: 22.4483%; height: 62px; text-align: center;\"><u><span style=\"color: #006dd7;\"><a style=\"color: #006dd7;\" href=\"https://sfsoftware.co.kr/\" target=\"_blank\" rel=\"noopener\">소셜프렌즈</a></span></u></td>\n</tr>\n</tbody>\n</table>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b> 프로그램 소개</b></h2>\n<p data-ke-size=\"size18\">&nbsp; 윈디는&nbsp;윈도우&nbsp;사용자들에게&nbsp;클릭&nbsp;없이도&nbsp;파일/폴더&nbsp;검색,&nbsp;웹&nbsp;검색,&nbsp;날씨&nbsp;검색&nbsp;등을&nbsp;손쉽게&nbsp;할&nbsp;수&nbsp;있는&nbsp;스마트한&nbsp;검색&nbsp;프로그램입니다.&nbsp;간편한&nbsp;키보드&nbsp;조작만으로&nbsp;다양한&nbsp;검색과&nbsp;시스템&nbsp;명령을&nbsp;수행할&nbsp;수&nbsp;있어,&nbsp;사용자의&nbsp;작업&nbsp;효율을&nbsp;크게&nbsp;높여줍니다.&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">이&nbsp;글에서는&nbsp;윈디의&nbsp;주요&nbsp;기능과&nbsp;장점,&nbsp;단점&nbsp;등을&nbsp;살펴보겠습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"스마트한 검색 창 윈디.png\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/5mExc/btsIvi5NQKa/S9ywJ3IkUdJN6Hi9X6TFKk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/5mExc/btsIvi5NQKa/S9ywJ3IkUdJN6Hi9X6TFKk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/5mExc/btsIvi5NQKa/S9ywJ3IkUdJN6Hi9X6TFKk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F5mExc%2FbtsIvi5NQKa%2FS9ywJ3IkUdJN6Hi9X6TFKk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"스마트한 검색창 윈디로 편하게 사는법\" data-filename=\"스마트한 검색 창 윈디.png\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b> 주요 특징</b></h2>\n<p data-ke-size=\"size18\"><b>1. 빠른 파일/폴더 검색</b> <br />윈디는&nbsp;윈도우&nbsp;탐색기보다&nbsp;더&nbsp;빠르게&nbsp;파일,&nbsp;폴더,&nbsp;애플리케이션을&nbsp;검색할&nbsp;수&nbsp;있습니다.&nbsp;키보드&nbsp;방향키와&nbsp;엔터&nbsp;키만으로&nbsp;세부&nbsp;검색과&nbsp;실행을&nbsp;간편하게&nbsp;할&nbsp;수&nbsp;있어&nbsp;마우스를&nbsp;사용할&nbsp;필요가&nbsp;없습니다. <br /><br /><b>2. 기본 플러그인 바로 실행</b> <br />윈디는 기본 플러그인으로 계산기와 날씨 검색 기능을 제공합니다. 별도의 프로그램 실행 없이도 윈디 창에서 바로 계산과 날씨 검색을 할 수 있어 매우 편리합니다. 향후 추가될 플러그인 업데이트도 기대해 볼 만합니다.&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"윈디 플러그인.png\" data-origin-width=\"507\" data-origin-height=\"373\"><span data-url=\"https://blog.kakaocdn.net/dn/b5R2aB/btsIxKziD61/z2Jx4VyNyThUWWQxOtAwdK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/b5R2aB/btsIxKziD61/z2Jx4VyNyThUWWQxOtAwdK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/b5R2aB/btsIxKziD61/z2Jx4VyNyThUWWQxOtAwdK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb5R2aB%2FbtsIxKziD61%2Fz2Jx4VyNyThUWWQxOtAwdK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"윈디 플러그인.png\" data-origin-width=\"507\" data-origin-height=\"373\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\"><br /><br /><b>3. 웹사이트 검색</b> <br />웹&nbsp;브라우저를&nbsp;열지&nbsp;않고도&nbsp;구글,&nbsp;네이버,&nbsp;유튜브&nbsp;등에서&nbsp;검색을&nbsp;수행할&nbsp;수&nbsp;있는&nbsp;스마트한&nbsp;기능을&nbsp;제공합니다.&nbsp;액션키와&nbsp;검색어를&nbsp;입력하면&nbsp;검색&nbsp;결과를&nbsp;바로&nbsp;확인할&nbsp;수&nbsp;있어,&nbsp;검색&nbsp;단계를&nbsp;최소화할&nbsp;수&nbsp;있습니다. <br /><br /><b>4. 테마 설정</b> <br />윈디는&nbsp;사용자의&nbsp;취향에&nbsp;맞게&nbsp;다양한&nbsp;검색창&nbsp;테마를&nbsp;제공합니다.&nbsp;다크&nbsp;모드와&nbsp;라이트&nbsp;모드&nbsp;등&nbsp;여러&nbsp;테마를&nbsp;선택하여&nbsp;더욱&nbsp;트렌디하게&nbsp;사용할&nbsp;수&nbsp;있습니다. <br /><br /><b>5. 컴퓨터 시스템 명령</b> <br />화면&nbsp;잠금,&nbsp;시스템&nbsp;종료,&nbsp;제어판&nbsp;열기&nbsp;등&nbsp;자주&nbsp;사용하는&nbsp;시스템&nbsp;명령을&nbsp;윈디를&nbsp;통해&nbsp;빠르게&nbsp;실행할&nbsp;수&nbsp;있습니다.&nbsp;검색창에&nbsp;명령어를&nbsp;입력하면&nbsp;바로&nbsp;실행됩니다. </p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b>  프로그램 장단점</b></h2>\n<h4 data-ke-size=\"size20\"><b> 장점</b></h4>\n<blockquote data-ke-style=\"style3\">1. 신속함: 윈디는 빠른 파일/폴더 검색 및 웹 검색에 최적화되어 있어 효율적인 작업이 가능합니다. <br />2. 간편함: 단축키(Alt+Space)를 사용해 마우스 없이도 키보드만으로 간편하게 조작할 수 있습니다. <br />3. 심플함: 직관적이고 심플한 UI로 다크, 라이트 등 다양한 테마 설정이 가능합니다. 사용자가 원하는 대로 인터페이스를 조정할 수 있습니다.</blockquote>\n<h4 data-ke-size=\"size20\"><b> 단점</b></h4>\n<blockquote data-ke-style=\"style3\">1. 플러그인 제한: 현재 제공되는 기본 플러그인이 제한적이어서 사용자 요구에 따라 추가 플러그인 업데이트가 필요합니다. <br />2. 학습 곡선: 새로운 인터페이스와 단축키 사용에 익숙해지기까지 다소 시간이 필요할 수 있습니다. <br />3. 시스템 자원 사용: 백그라운드에서 실행되는 프로그램이므로 시스템 자원을 다소 사용합니다.</blockquote>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b>  간단 활용법</b></h2>\n<p data-ke-size=\"size18\"><b>윈디 설치 및 실행</b> <br />1.&nbsp;윈디&nbsp;다운로드&nbsp;및&nbsp;설치:&nbsp;윈디&nbsp;공식&nbsp;웹사이트에서&nbsp;프로그램을&nbsp;다운로드하고&nbsp;설치합니다. <br />2.&nbsp;프로그램&nbsp;실행:&nbsp;단축키&nbsp;`Alt+Enter`를&nbsp;눌러&nbsp;윈디를&nbsp;실행합니다. <br /><br /><b>기본 검색 기능 사용</b> <br />1. 파일/폴더 검색: 검색창에 찾고자 하는 파일이나 폴더 이름을 입력하고 `Enter` 키를 누릅니다. ▼</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"윈디1.png\" data-origin-width=\"551\" data-origin-height=\"367\"><span data-url=\"https://blog.kakaocdn.net/dn/Mvv0u/btsIwgGcRNt/Yu7pwbW2ifk8yYq6OUskTK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Mvv0u/btsIwgGcRNt/Yu7pwbW2ifk8yYq6OUskTK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/Mvv0u/btsIwgGcRNt/Yu7pwbW2ifk8yYq6OUskTK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FMvv0u%2FbtsIwgGcRNt%2FYu7pwbW2ifk8yYq6OUskTK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"윈디1.png\" data-origin-width=\"551\" data-origin-height=\"367\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\"><br />2. 웹 검색: 액션키(`g` for 구글, `n` for 네이버 등)와 검색어를 함께 입력하고 `Enter`를 눌러 검색 결과를 확인합니다. ▼</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"윈디 웹검색.png\" data-origin-width=\"545\" data-origin-height=\"363\"><span data-url=\"https://blog.kakaocdn.net/dn/bfM9lC/btsIweIn22P/yrF2tFpzPUO1gqDlMPT2b0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bfM9lC/btsIweIn22P/yrF2tFpzPUO1gqDlMPT2b0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bfM9lC/btsIweIn22P/yrF2tFpzPUO1gqDlMPT2b0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbfM9lC%2FbtsIweIn22P%2FyrF2tFpzPUO1gqDlMPT2b0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"윈디 웹검색.png\" data-origin-width=\"545\" data-origin-height=\"363\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\"><br /><br /><b>추가 기능 활용</b> <br />1. 계산기: 검색창에 수식을 입력하면 자동으로 계산 결과를 제공합니다. ▼</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"윈디 계산기.png\" data-origin-width=\"545\" data-origin-height=\"361\"><span data-url=\"https://blog.kakaocdn.net/dn/tDXgk/btsIwZjpf5G/WDZh2j8CPKxUS4x1F0yHwK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/tDXgk/btsIwZjpf5G/WDZh2j8CPKxUS4x1F0yHwK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/tDXgk/btsIwZjpf5G/WDZh2j8CPKxUS4x1F0yHwK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FtDXgk%2FbtsIwZjpf5G%2FWDZh2j8CPKxUS4x1F0yHwK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"윈디 계산기.png\" data-origin-width=\"545\" data-origin-height=\"361\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\"><br />2.&nbsp;날씨&nbsp;검색:&nbsp;`날씨&nbsp;+&nbsp;지역`을&nbsp;입력하여&nbsp;해당&nbsp;지역의&nbsp;날씨&nbsp;정보를&nbsp;확인할&nbsp;수&nbsp;있습니다. ▼</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"윈디 날씨.png\" data-origin-width=\"545\" data-origin-height=\"363\"><span data-url=\"https://blog.kakaocdn.net/dn/lWemq/btsIwnrCM64/j5DbNZYrHTC10rdEcB6R11/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/lWemq/btsIwnrCM64/j5DbNZYrHTC10rdEcB6R11/img.png\"><img src=\"https://blog.kakaocdn.net/dn/lWemq/btsIwnrCM64/j5DbNZYrHTC10rdEcB6R11/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FlWemq%2FbtsIwnrCM64%2Fj5DbNZYrHTC10rdEcB6R11%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"윈디 날씨.png\" data-origin-width=\"545\" data-origin-height=\"363\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\"><br />3. 시스템 명령: `lock`, `shutdown`, `control panel` 등의 명령어를 입력하여 시스템 명령을 실행합니다. ▼</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"윈디 시스템.png\" data-origin-width=\"545\" data-origin-height=\"361\"><span data-url=\"https://blog.kakaocdn.net/dn/chW217/btsIwX0ceM9/cWaMqEjKC3D53wnWgrxD60/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/chW217/btsIwX0ceM9/cWaMqEjKC3D53wnWgrxD60/img.png\"><img src=\"https://blog.kakaocdn.net/dn/chW217/btsIwX0ceM9/cWaMqEjKC3D53wnWgrxD60/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FchW217%2FbtsIwX0ceM9%2FcWaMqEjKC3D53wnWgrxD60%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"윈디 시스템.png\" data-origin-width=\"545\" data-origin-height=\"361\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\"><br /><br /><b>테마 설정</b> <br />1. 테마 변경: 설정 메뉴에서 다크 모드, 라이트 모드 등 원하는 테마를 선택하여 검색창의 테마를 변경할 수 있습니다. ▼</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"윈디 테마.png\" data-origin-width=\"509\" data-origin-height=\"375\"><span data-url=\"https://blog.kakaocdn.net/dn/3ANze/btsIxK68dpV/elOMP8xYG2qrmNKaD0E2zK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/3ANze/btsIxK68dpV/elOMP8xYG2qrmNKaD0E2zK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/3ANze/btsIxK68dpV/elOMP8xYG2qrmNKaD0E2zK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F3ANze%2FbtsIxK68dpV%2FelOMP8xYG2qrmNKaD0E2zK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"윈디 테마.png\" data-origin-width=\"509\" data-origin-height=\"375\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 style=\"color: #000000; text-align: start;\" data-ke-size=\"size26\"><b>  라이센스 정책</b></h2>\n<p data-ke-size=\"size18\">&nbsp;윈디는 개인 및 상업적 용도로 모두 무료로 제공되는 프리웨어입니다. 사용자는 소프트웨어를 자유롭게 다운로드하여 설치하고 사용할 수 있으며, 추가 비용 없이 모든 기능을 이용할 수 있습니다.&nbsp;</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b>⬇️ 프로그램 다운로드</b></h2>\n\n<p data-ke-size=\"size16\">&nbsp;</p>\n<figure id=\"og_1720743289899\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Social Freinds (소셜프렌즈) &ndash; 윈도우 메모장 프로그램 위메모, 윈도우 스팟라이트 윈디\" data-og-description=\"직관적이며 심플한 UI 다크, 라이트 등 테마 설정이 가능합니다\" data-og-host=\"sfsoftware.co.kr\" data-og-source-url=\"https://sfsoftware.co.kr/\" data-og-url=\"https://sfsoftware.co.kr/\" data-og-image=\"https://scrap.kakaocdn.net/dn/b4GlVk/hyWvKtGNpE/Y2tEJUAOxqHmQT0CgLoUaK/img.png?width=1024&amp;height=843&amp;face=0_0_1024_843,https://scrap.kakaocdn.net/dn/bMqkCt/hyWvUb0X9F/YCm8FJxBo2y7hVkm0yHeck/img.png?width=1024&amp;height=843&amp;face=0_0_1024_843,https://scrap.kakaocdn.net/dn/bJFdgU/hyWzEyzZnb/T8W0ZAAerv7KRdAvihJn40/img.png?width=1024&amp;height=796&amp;face=0_0_1024_796\"><a href=\"https://sfsoftware.co.kr/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://sfsoftware.co.kr/\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/b4GlVk/hyWvKtGNpE/Y2tEJUAOxqHmQT0CgLoUaK/img.png?width=1024&amp;height=843&amp;face=0_0_1024_843,https://scrap.kakaocdn.net/dn/bMqkCt/hyWvUb0X9F/YCm8FJxBo2y7hVkm0yHeck/img.png?width=1024&amp;height=843&amp;face=0_0_1024_843,https://scrap.kakaocdn.net/dn/bJFdgU/hyWzEyzZnb/T8W0ZAAerv7KRdAvihJn40/img.png?width=1024&amp;height=796&amp;face=0_0_1024_796');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Social Freinds (소셜프렌즈) &ndash; 윈도우 메모장 프로그램 위메모, 윈도우 스팟라이트 윈디</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">직관적이며 심플한 UI 다크, 라이트 등 테마 설정이 가능합니다</p>\n<p class=\"og-host\" data-ke-size=\"size16\">sfsoftware.co.kr</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "윈디는 윈도우 사용자들을 위한 스마트한 검색 프로그램입니다. 빠른 파일/폴더 검색, 웹 검색, 날씨 검색 등 다양한 기능을 제공하여 작업 효율을 극대화합니다.  \n\n분류\n유틸리티/파일관리\n\n\n\n\n사용범위\n무료(개인/기)\n\n\n사용환경\nWindows\n\n\n제작사\n소셜프렌즈\n\n\n\n \n 프로그램 소개\n  윈디는 윈도우 사용자들에게 클릭 없이도 파일/폴더 검색, 웹 검색, 날씨 검색 등을 손쉽게 할 수 있는 스마트한 검색 프로그램입니다. 간편한 키보드 조작만으로 다양한 검색과 시스템 명령을 수행할 수 있어, 사용자의 작업 효율을 크게 높여줍니다. \n \n이 글에서는 윈디의 주요 기능과 장점, 단점 등을 살펴보겠습니다.\n\n\n \n 주요 특징\n1. 빠른 파일/폴더 검색 \n윈디는 윈도우 탐색기보다 더 빠르게 파일, 폴더, 애플리케이션을 검색할 수 있습니다. 키보드 방향키와 엔터 키만으로 세부 검색과 실행을 간편하게 할 수 있어 마우스를 사용할 필요가 없습니다. \n2. 기본 플러그인 바로 실행 \n윈디는 기본 플러그인으로 계산기와 날씨 검색 기능을 제공합니다. 별도의 프로그램 실행 없이도 윈디 창에서 바로 계산과 날씨 검색을 할 수 있어 매우 편리합니다. 향후 추가될 플러그인 업데이트도 기대해 볼 만합니다. \n\n\n\n3. 웹사이트 검색 \n웹 브라우저를 열지 않고도 구글, 네이버, 유튜브 등에서 검색을 수행할 수 있는 스마트한 기능을 제공합니다. 액션키와 검색어를 입력하면 검색 결과를 바로 확인할 수 있어, 검색 단계를 최소화할 수 있습니다. \n4. 테마 설정 \n윈디는 사용자의 취향에 맞게 다양한 검색창 테마를 제공합니다. 다크 모드와 라이트 모드 등 여러 테마를 선택하여 더욱 트렌디하게 사용할 수 있습니다. \n5. 컴퓨터 시스템 명령 \n화면 잠금, 시스템 종료, 제어판 열기 등 자주 사용하는 시스템 명령을 윈디를 통해 빠르게 실행할 수 있습니다. 검색창에 명령어를 입력하면 바로 실행됩니다. \n \n \n  프로그램 장단점\n 장점\n1. 신속함: 윈디는 빠른 파일/폴더 검색 및 웹 검색에 최적화되어 있어 효율적인 작업이 가능합니다. \n2. 간편함: 단축키(Alt+Space)를 사용해 마우스 없이도 키보드만으로 간편하게 조작할 수 있습니다. \n3. 심플함: 직관적이고 심플한 UI로 다크, 라이트 등 다양한 테마 설정이 가능합니다. 사용자가 원하는 대로 인터페이스를 조정할 수 있습니다.\n 단점\n1. 플러그인 제한: 현재 제공되는 기본 플러그인이 제한적이어서 사용자 요구에 따라 추가 플러그인 업데이트가 필요합니다. \n2. 학습 곡선: 새로운 인터페이스와 단축키 사용에 익숙해지기까지 다소 시간이 필요할 수 있습니다. \n3. 시스템 자원 사용: 백그라운드에서 실행되는 프로그램이므로 시스템 자원을 다소 사용합니다.\n \n \n  간단 활용법\n윈디 설치 및 실행 \n1. 윈디 다운로드 및 설치: 윈디 공식 웹사이트에서 프로그램을 다운로드하고 설치합니다. \n2. 프로그램 실행: 단축키 `Alt+Enter`를 눌러 윈디를 실행합니다. \n기본 검색 기능 사용 \n1. 파일/폴더 검색: 검색창에 찾고자 하는 파일이나 폴더 이름을 입력하고 `Enter` 키를 누릅니다. ▼\n\n\n \n2. 웹 검색: 액션키(`g` for 구글, `n` for 네이버 등)와 검색어를 함께 입력하고 `Enter`를 눌러 검색 결과를 확인합니다. ▼\n\n\n\n추가 기능 활용 \n1. 계산기: 검색창에 수식을 입력하면 자동으로 계산 결과를 제공합니다. ▼\n\n\n \n2. 날씨 검색: `날씨 + 지역`을 입력하여 해당 지역의 날씨 정보를 확인할 수 있습니다. ▼\n\n\n \n3. 시스템 명령: `lock`, `shutdown`, `control panel` 등의 명령어를 입력하여 시스템 명령을 실행합니다. ▼\n\n\n\n테마 설정 \n1. 테마 변경: 설정 메뉴에서 다크 모드, 라이트 모드 등 원하는 테마를 선택하여 검색창의 테마를 변경할 수 있습니다. ▼\n\n\n \n  라이센스 정책\n 윈디는 개인 및 상업적 용도로 모두 무료로 제공되는 프리웨어입니다. 사용자는 소프트웨어를 자유롭게 다운로드하여 설치하고 사용할 수 있으며, 추가 비용 없이 모든 기능을 이용할 수 있습니다. \n \n⬇️ 프로그램 다운로드\n \n\n \nSocial Freinds (소셜프렌즈) – 윈도우 메모장 프로그램 위메모, 윈도우 스팟라이트 윈디\n직관적이며 심플한 UI 다크, 라이트 등 테마 설정이 가능합니다\nsfsoftware.co.kr",
        "guid": "http://muzbox.tistory.com/483449",
        "categories": [
          "추천 프리웨어/시스템관리,보안",
          "It",
          "공개자료실",
          "스마트 검색 프로그램",
          "웹 검색 플러그인",
          "윈도우 검색 도구",
          "윈도우 유틸리티",
          "윈디",
          "키보드 검색 도구",
          "파일 검색 프로그램",
          "프리웨어"
        ],
        "isoDate": "2024-07-12T00:19:42.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "윈도우용 추천 프리웨어 (2024.7.8) 앱자동설치방지,재미있는효과적요,사진편집,오디오편집,게임용웹브라우저,PC정보확인",
        "link": "http://muzbox.tistory.com/483448",
        "pubDate": "Mon, 8 Jul 2024 09:36:43 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483448#entry483448comment",
        "content": "<p style=\"text-align: left;\" data-ke-size=\"size18\"><span style=\"background-color: #ffffff; color: #0d0d0d; text-align: start;\">&nbsp;네이버 소프트웨어와 같은 프로그램 소개 사이트가 종료된 후, 윈도우 운영체제를 사용하는 이용자들을 위해 공개 프리웨어 및 오픈소스 프로그램을 소개합니다. 유용한 무료 소프트웨어를 찾고자 하는 사용자들에게 정기적으로 알찬 정보를 제공합니다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"프리웨어.png\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/df1GRa/btsIps1WtEG/HuOyTS9XtVDQ5XdV9gBzVK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/df1GRa/btsIps1WtEG/HuOyTS9XtVDQ5XdV9gBzVK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/df1GRa/btsIps1WtEG/HuOyTS9XtVDQ5XdV9gBzVK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fdf1GRa%2FbtsIps1WtEG%2FHuOyTS9XtVDQ5XdV9gBzVK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"윈도우용 추천 프리웨어 (2024.7.8) 앱자동설치방지,재미있는효과적요,사진편집,오디오편집,게임용웹브라우저,PC정보확인\" data-filename=\"프리웨어.png\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\">&nbsp;</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\"><span style=\"color: #333333; text-align: left;\">&nbsp;윈도우용 응용프로그램 (Application)은 수없이 많은 종류가 많은 개발자들에 의해 하루에도 수백,수천개가 새로 출시되고 그보다 더 많은 수의 프로그램들이 업데이트 됩니다. 이들 응용프로그램 (Application)은 비율을 지불해야하는<span>&nbsp;</span></span><b><span style=\"color: #009a87;\">상용프로그램</span></b><span style=\"color: #333333; text-align: left;\">과 정품 구매를 확대하기 위해 공급하는 일종의 샘플 개념의<span>&nbsp;</span></span><span style=\"color: #ee2323;\"><b>쉐어웨어</b></span><span style=\"color: #333333; text-align: left;\">, 무료로 사용할 수 있는<span>&nbsp;</span></span><b><span style=\"color: #ef6f53;\">프리웨어</span></b>등으로 크게 3가지로 나뉘게 되는데요.</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\"><br />&nbsp;물론 프리웨어에도 개인만 사용할 있다던가, 기업이나 관공서에서도 사용이 가능하다던가, 소스까지 같이 공개하여 맘대로 수정과 배포가 가능한 완전 무료등의 추가 분류가 필요합니다. 하지만, 개발자가 공개하는 무료배포의 의미가 정확하지 않는 프로그램도 많고, 저작권의 정의도 각양각색이라 본 블로그에서 소개하는 프리웨어도 <span style=\"color: #006dd7;\"><b>최대한 확인이 가능한 범위에서 개인 또는 기업에서 사용가능한지를 구분하여 소개</b></span>하고 있습니다.</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\">&nbsp;</p>\n<p style=\"text-align: left;\" data-ke-size=\"size18\">&nbsp;</p>\n<p style=\"text-align: center;\" data-ke-size=\"size18\">'어떤오후의 프리웨어 이야기'에서 추천하는<br /><span style=\"color: #409d00;\">&nbsp;<b>2024년 7월 8일자 공개자료실 윈도우용 추천 프리웨어</b></span>입니다.</p>\n<p id=\"no_1\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>1. Unchecky (소프트웨어 설치 시 타사 프로그램의 자동 설치 방지)<br /></b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp; 소프트웨어 설치 중 원치 않는 타사 제안을 자동으로 거부하는 배경 프로세스 도구입니다. 이 프로그램은 설치 과정을 모니터링하고 관련 없는 제안을 감지하면 자동으로 체크를 해제합니다. OpenCandy, AVG 등 여러 인기 있는 인스톨러와 잘 작동하지만, 모든 종류의 타사 제안에 대해 완벽하게 작동하지는 않습니다. 리소스 사용량이 적고 원치 않는 도구 모음이나 애플리케이션 설치를 방지하는 데 유용한 도구입니다. 자주 실수로 타사 제안을 수락하는 사용자에게 특히 유용할 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Unchecky.jpg\" data-origin-width=\"899\" data-origin-height=\"802\"><span data-url=\"https://blog.kakaocdn.net/dn/bj9UFq/btsIpuFrdYz/Q3eARqKZvFyaKWhFkTRgSk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bj9UFq/btsIpuFrdYz/Q3eARqKZvFyaKWhFkTRgSk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bj9UFq/btsIpuFrdYz/Q3eARqKZvFyaKWhFkTRgSk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbj9UFq%2FbtsIpuFrdYz%2FQ3eARqKZvFyaKWhFkTRgSk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"Unchecky (소프트웨어 설치 시 타사 프로그램의 자동 설치 방지)\" data-filename=\"Unchecky.jpg\" data-origin-width=\"899\" data-origin-height=\"802\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인</p>\n<p data-ke-size=\"size18\">▶ Windows 10/11</p>\n<p data-ke-size=\"size18\">▶무료 다운로드◀</p>\n<figure id=\"og_1720398653392\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Unchecky - Keeps your checkboxes clear\" data-og-description=\"Unchecky aims to keep potentially unwanted programs out of your computer.\" data-og-host=\"unchecky.com\" data-og-source-url=\"https://unchecky.com/\" data-og-url=\"https://unchecky.com/\" data-og-image=\"https://scrap.kakaocdn.net/dn/DgPO0/hyWvKfyIhi/kLCdidQmSEkle2kelBxnW1/img.png?width=256&amp;height=256&amp;face=0_0_256_256,https://scrap.kakaocdn.net/dn/nUAvA/hyWzsYCbog/pCLOk9gt7dIqRtikww77K0/img.jpg?width=1100&amp;height=715&amp;face=0_0_1100_715\"><a href=\"https://unchecky.com/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://unchecky.com/\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/DgPO0/hyWvKfyIhi/kLCdidQmSEkle2kelBxnW1/img.png?width=256&amp;height=256&amp;face=0_0_256_256,https://scrap.kakaocdn.net/dn/nUAvA/hyWzsYCbog/pCLOk9gt7dIqRtikww77K0/img.jpg?width=1100&amp;height=715&amp;face=0_0_1100_715');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Unchecky - Keeps your checkboxes clear</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Unchecky aims to keep potentially unwanted programs out of your computer.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">unchecky.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"no_2\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>2. Funny&nbsp;Photo&nbsp;Maker&nbsp;(재미있는&nbsp;효과&nbsp;적용하는&nbsp;&nbsp;무료&nbsp;사진&nbsp;편집&nbsp;프로그램)</b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp; Windows용&nbsp;무료&nbsp;사진&nbsp;편집&nbsp;프로그램으로,&nbsp;디지털&nbsp;사진에&nbsp;재미있는&nbsp;효과를&nbsp;쉽고&nbsp;빠르게&nbsp;추가할&nbsp;수&nbsp;있습니다.&nbsp;이&nbsp;프로그램은&nbsp;200개&nbsp;이상의&nbsp;표준&nbsp;효과를&nbsp;제공하며,&nbsp;이는&nbsp;Photo&nbsp;Frame,&nbsp;Face&nbsp;Fun,&nbsp;Photo&nbsp;Effects의&nbsp;세&nbsp;가지&nbsp;카테고리로&nbsp;분류됩니다.&nbsp;사용자는&nbsp;사진을&nbsp;프레임에&nbsp;삽입하거나,&nbsp;얼굴을&nbsp;다른&nbsp;이미지로&nbsp;변환하거나,&nbsp;예술적&nbsp;효과를&nbsp;적용할&nbsp;수&nbsp;있습니다.&nbsp;Funny&nbsp;Photo&nbsp;Maker를&nbsp;통해&nbsp;편집된&nbsp;사진은&nbsp;PC에&nbsp;저장하거나&nbsp;소셜&nbsp;미디어를&nbsp;통해&nbsp;공유할&nbsp;수&nbsp;있으며,&nbsp;BMP,&nbsp;JPG,&nbsp;PNG&nbsp;이미지&nbsp;또는&nbsp;GIF&nbsp;애니메이션으로&nbsp;저장할&nbsp;수&nbsp;있습니다.&nbsp;이&nbsp;프로그램은&nbsp;Microsoft&nbsp;Windows에서만&nbsp;사용&nbsp;가능합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Funny Photo Maker.jpg\" data-origin-width=\"650\" data-origin-height=\"406\"><span data-url=\"https://blog.kakaocdn.net/dn/chOlGZ/btsIreHQHOF/UcxAivhpq7TKG3b9fgAfX0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/chOlGZ/btsIreHQHOF/UcxAivhpq7TKG3b9fgAfX0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/chOlGZ/btsIreHQHOF/UcxAivhpq7TKG3b9fgAfX0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FchOlGZ%2FbtsIreHQHOF%2FUcxAivhpq7TKG3b9fgAfX0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"Funny Photo Maker (재미있는 효과 적용하는 무료 사진 편집 프로그램)\" data-filename=\"Funny Photo Maker.jpg\" data-origin-width=\"650\" data-origin-height=\"406\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인</p>\n<p data-ke-size=\"size18\">▶Windows 10/11</p>\n<p data-ke-size=\"size18\">▶무료 다운로드 ◀</p>\n<figure id=\"og_1720398783272\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Funny Photo Maker - Edit Funny Photos with photo frames and effects For Free\" data-og-description=\"It's Easy! Confused on the countless buttons in PhotoShop? Now you have an easier solution! Funny Photo Maker has a user-friendly interface that enables you to fast comprehend and use the powerful program. The whole editing process is a piece of cake for a\" data-og-host=\"www.funny-photo-maker.com\" data-og-source-url=\"https://www.funny-photo-maker.com/\" data-og-url=\"https://www.funny-photo-maker.com/\" data-og-image=\"https://scrap.kakaocdn.net/dn/v42xQ/hyWvPA8ElG/LDKzIROYKqmeGAaes7FZ4k/img.jpg?width=490&amp;height=400&amp;face=215_283_289_334\"><a href=\"https://www.funny-photo-maker.com/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.funny-photo-maker.com/\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/v42xQ/hyWvPA8ElG/LDKzIROYKqmeGAaes7FZ4k/img.jpg?width=490&amp;height=400&amp;face=215_283_289_334');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Funny Photo Maker - Edit Funny Photos with photo frames and effects For Free</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">It's Easy! Confused on the countless buttons in PhotoShop? Now you have an easier solution! Funny Photo Maker has a user-friendly interface that enables you to fast comprehend and use the powerful program. The whole editing process is a piece of cake for a</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.funny-photo-maker.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"no_3\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>3. Ocenaudio&nbsp;(무료&nbsp;디지털&nbsp;사운드&nbsp;편집&nbsp;프로그램)</b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp;무료&nbsp;디지털&nbsp;사운드&nbsp;편집&nbsp;프로그램입니다.&nbsp;이&nbsp;프로그램은&nbsp;Ocean&nbsp;프레임워크를&nbsp;기반으로&nbsp;하며,&nbsp;VST&nbsp;플러그인을&nbsp;지원하여&nbsp;다양한&nbsp;효과를&nbsp;적용할&nbsp;수&nbsp;있습니다.&nbsp;Ocenaudio는&nbsp;실시간&nbsp;미리보기&nbsp;기능과&nbsp;다중&nbsp;선택&nbsp;시스템을&nbsp;제공하여&nbsp;복잡한&nbsp;오디오&nbsp;편집&nbsp;작업을&nbsp;효율적으로&nbsp;수행할&nbsp;수&nbsp;있게&nbsp;해줍니다.&nbsp;이&nbsp;소프트웨어는&nbsp;파일&nbsp;길이나&nbsp;수량에&nbsp;제한이&nbsp;없으며,&nbsp;실시간&nbsp;스펙트로그램&nbsp;디스플레이를&nbsp;제공합니다.&nbsp;Ocenaudio는&nbsp;초보자부터&nbsp;경험&nbsp;있는&nbsp;사용자까지&nbsp;모두에게&nbsp;적합한&nbsp;기능을&nbsp;갖춘&nbsp;종합적인&nbsp;오디오&nbsp;및&nbsp;음악&nbsp;편집&nbsp;도구입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Ocenaudio.jpg\" data-origin-width=\"799\" data-origin-height=\"525\"><span data-url=\"https://blog.kakaocdn.net/dn/db1w4A/btsIrJ1GA2U/GcEJ5N6KRBYpmbvS3htpXK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/db1w4A/btsIrJ1GA2U/GcEJ5N6KRBYpmbvS3htpXK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/db1w4A/btsIrJ1GA2U/GcEJ5N6KRBYpmbvS3htpXK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fdb1w4A%2FbtsIrJ1GA2U%2FGcEJ5N6KRBYpmbvS3htpXK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"Ocenaudio (무료 디지털 사운드 편집 프로그램)\" data-filename=\"Ocenaudio.jpg\" data-origin-width=\"799\" data-origin-height=\"525\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인</p>\n<p data-ke-size=\"size18\">▶Windows 10/11&nbsp;</p>\n<p data-ke-size=\"size18\">▶무료 다운로드 ◀<a href=\"https://www.ocenaudio.com/\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.ocenaudio.com/</a></p>\n<figure id=\"og_1720398816093\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"ocenaudio\" data-og-description=\"Easy, fast and powerful audio editor\" data-og-host=\"www.ocenaudio.com\" data-og-source-url=\"https://www.ocenaudio.com/\" data-og-url=\"https://www.ocenaudio.com/\" data-og-image=\"\"><a href=\"https://www.ocenaudio.com/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.ocenaudio.com/\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">ocenaudio</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Easy, fast and powerful audio editor</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.ocenaudio.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"no_4\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>4. Opera&nbsp;GX&nbsp;(게이머를&nbsp;위한&nbsp;특별한&nbsp;브라우저) <br /></b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp;게이머를 위한 특별한 브라우저입니다. CPU, RAM, 네트워크 사용량을 제한하고, 사이드바에서 디스코드와 트위치를 사용하며, Flow 기능을 사용하여 모바일과 데스크탑 브라우저를 연결할 수 있습니다. <br /><br />Opera&nbsp;GX와&nbsp;기존&nbsp;Opera&nbsp;브라우저의&nbsp;주요&nbsp;차이점은&nbsp;게이머&nbsp;맞춤&nbsp;기능,&nbsp;성능,&nbsp;리소스&nbsp;사용,&nbsp;사용자&nbsp;정의,&nbsp;가용&nbsp;플랫폼입니다.&nbsp;Opera&nbsp;GX는&nbsp;게이머에게&nbsp;더&nbsp;나은&nbsp;경험을&nbsp;제공하기&nbsp;위해&nbsp;특화되어&nbsp;있으며,&nbsp;기존&nbsp;Opera&nbsp;브라우저는&nbsp;더&nbsp;다양한&nbsp;기능과&nbsp;플랫폼을&nbsp;지원합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Opera GX.jpg\" data-origin-width=\"1083\" data-origin-height=\"672\"><span data-url=\"https://blog.kakaocdn.net/dn/mtCow/btsIpKOLu0e/jlmHgrq6HbMICXRhqgXoUK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/mtCow/btsIpKOLu0e/jlmHgrq6HbMICXRhqgXoUK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/mtCow/btsIpKOLu0e/jlmHgrq6HbMICXRhqgXoUK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FmtCow%2FbtsIpKOLu0e%2FjlmHgrq6HbMICXRhqgXoUK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"Opera GX (게이머를 위한 특별한 브라우저)\" data-filename=\"Opera GX.jpg\" data-origin-width=\"1083\" data-origin-height=\"672\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인/기업&nbsp;(오픈소스)</p>\n<p data-ke-size=\"size18\">▶Windows 10/11</p>\n<p data-ke-size=\"size18\">▶무료 다운로드 ◀</p>\n<figure id=\"og_1720398839002\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Opera GX | 게이밍 브라우저 | Opera\" data-og-description=\"Opera GX는 특별히 게이머를 위해 만든 브라우저입니다. 강력하고 혁신적 브라우저에 포함된 비교할 수 없는 게이밍 및 브라우징 기능을 이용하세요.\" data-og-host=\"www.opera.com\" data-og-source-url=\"https://www.opera.com/ko/gx\" data-og-url=\"https://www.opera.com/ko/gx\" data-og-image=\"https://scrap.kakaocdn.net/dn/eUWy0/hyWzsqMjUg/7kUMI76aY0sG73Gk7RpJ51/img.png?width=1180&amp;height=682&amp;face=0_0_1180_682\"><a href=\"https://www.opera.com/ko/gx\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.opera.com/ko/gx\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/eUWy0/hyWzsqMjUg/7kUMI76aY0sG73Gk7RpJ51/img.png?width=1180&amp;height=682&amp;face=0_0_1180_682');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Opera GX | 게이밍 브라우저 | Opera</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Opera GX는 특별히 게이머를 위해 만든 브라우저입니다. 강력하고 혁신적 브라우저에 포함된 비교할 수 없는 게이밍 및 브라우징 기능을 이용하세요.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.opera.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"no_5\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><i><b>5. Speccy&nbsp;(PC의&nbsp;사양과&nbsp;구성&nbsp;요소를&nbsp;파악)</b></i></span></h2>\n<p data-ke-size=\"size18\">&nbsp; 사용자&nbsp;친화적인&nbsp;무료&nbsp;프로그램으로,&nbsp;PC의&nbsp;사양과&nbsp;구성&nbsp;요소를&nbsp;파악하는&nbsp;데&nbsp;도움을&nbsp;줍니다.&nbsp;운영&nbsp;체제,&nbsp;CPU,&nbsp;RAM,&nbsp;스토리지,&nbsp;그래픽&nbsp;카드,&nbsp;사운드&nbsp;카드,&nbsp;온도,&nbsp;드라이버&nbsp;등을&nbsp;포함한&nbsp;하드웨어&nbsp;및&nbsp;소프트웨어에&nbsp;대한&nbsp;자세한&nbsp;보고서를&nbsp;제공합니다.&nbsp;Speccy는&nbsp;시스템&nbsp;문제&nbsp;진단,&nbsp;구성&nbsp;요소&nbsp;온도&nbsp;모니터링,&nbsp;업데이트&nbsp;확인,&nbsp;설치된&nbsp;드라이버&nbsp;분석,&nbsp;기술&nbsp;보고서&nbsp;작성&nbsp;등에&nbsp;유용합니다.&nbsp;가볍고&nbsp;사용하기&nbsp;쉬운&nbsp;Speccy는&nbsp;PC에&nbsp;대해&nbsp;더&nbsp;알고&nbsp;싶은&nbsp;모든&nbsp;사람들에게&nbsp;훌륭한&nbsp;도구입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"speccy.jpg\" data-origin-width=\"676\" data-origin-height=\"270\"><span data-url=\"https://blog.kakaocdn.net/dn/bhT4y2/btsIrhR5YmI/wsQzHlfxkRxa6K37vpleeK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bhT4y2/btsIrhR5YmI/wsQzHlfxkRxa6K37vpleeK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bhT4y2/btsIrhR5YmI/wsQzHlfxkRxa6K37vpleeK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbhT4y2%2FbtsIrhR5YmI%2FwsQzHlfxkRxa6K37vpleeK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"Speccy (PC의 사양과 구성 요소를 파악)\" data-filename=\"speccy.jpg\" data-origin-width=\"676\" data-origin-height=\"270\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">▶프리웨어 - 개인</p>\n<p data-ke-size=\"size18\">▶Windows 10/11</p>\n<p data-ke-size=\"size18\">▶무료 다운로드 ◀</p>\n<figure id=\"og_1720398856529\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Speccy 다운로드 | 컴퓨터 사양을 무료로 확인하세요!\" data-og-description=\"Speccy&reg; 빠르고 가벼운 PC용 고급 시스템 정보 도구입니다. 컴퓨터에 무엇이 있는지 알고 싶으신가요? Speccy에 필요한 모든 정보가 있습니다! 참고: 다양한 스크린 리더를 사용하여 CCleaner를 테스트\" data-og-host=\"www.ccleaner.com\" data-og-source-url=\"https://www.ccleaner.com/ko-kr/speccy\" data-og-url=\"https://www.ccleaner.com/ko-kr/speccy\" data-og-image=\"https://scrap.kakaocdn.net/dn/uJWvl/hyWvVVHeLO/99mH8ZVFEj774p005EqKFK/img.png?width=676&amp;height=270&amp;face=0_0_676_270\"><a href=\"https://www.ccleaner.com/ko-kr/speccy\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.ccleaner.com/ko-kr/speccy\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/uJWvl/hyWvVVHeLO/99mH8ZVFEj774p005EqKFK/img.png?width=676&amp;height=270&amp;face=0_0_676_270');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Speccy 다운로드 | 컴퓨터 사양을 무료로 확인하세요!</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">Speccy&reg; 빠르고 가벼운 PC용 고급 시스템 정보 도구입니다. 컴퓨터에 무엇이 있는지 알고 싶으신가요? Speccy에 필요한 모든 정보가 있습니다! 참고: 다양한 스크린 리더를 사용하여 CCleaner를 테스트</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.ccleaner.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "네이버 소프트웨어와 같은 프로그램 소개 사이트가 종료된 후, 윈도우 운영체제를 사용하는 이용자들을 위해 공개 프리웨어 및 오픈소스 프로그램을 소개합니다. 유용한 무료 소프트웨어를 찾고자 하는 사용자들에게 정기적으로 알찬 정보를 제공합니다.\n\n\n \n 윈도우용 응용프로그램 (Application)은 수없이 많은 종류가 많은 개발자들에 의해 하루에도 수백,수천개가 새로 출시되고 그보다 더 많은 수의 프로그램들이 업데이트 됩니다. 이들 응용프로그램 (Application)은 비율을 지불해야하는 상용프로그램과 정품 구매를 확대하기 위해 공급하는 일종의 샘플 개념의 쉐어웨어, 무료로 사용할 수 있는 프리웨어등으로 크게 3가지로 나뉘게 되는데요.\n 물론 프리웨어에도 개인만 사용할 있다던가, 기업이나 관공서에서도 사용이 가능하다던가, 소스까지 같이 공개하여 맘대로 수정과 배포가 가능한 완전 무료등의 추가 분류가 필요합니다. 하지만, 개발자가 공개하는 무료배포의 의미가 정확하지 않는 프로그램도 많고, 저작권의 정의도 각양각색이라 본 블로그에서 소개하는 프리웨어도 최대한 확인이 가능한 범위에서 개인 또는 기업에서 사용가능한지를 구분하여 소개하고 있습니다.\n \n \n'어떤오후의 프리웨어 이야기'에서 추천하는\n 2024년 7월 8일자 공개자료실 윈도우용 추천 프리웨어입니다.\n \n1. Unchecky (소프트웨어 설치 시 타사 프로그램의 자동 설치 방지)\n\n  소프트웨어 설치 중 원치 않는 타사 제안을 자동으로 거부하는 배경 프로세스 도구입니다. 이 프로그램은 설치 과정을 모니터링하고 관련 없는 제안을 감지하면 자동으로 체크를 해제합니다. OpenCandy, AVG 등 여러 인기 있는 인스톨러와 잘 작동하지만, 모든 종류의 타사 제안에 대해 완벽하게 작동하지는 않습니다. 리소스 사용량이 적고 원치 않는 도구 모음이나 애플리케이션 설치를 방지하는 데 유용한 도구입니다. 자주 실수로 타사 제안을 수락하는 사용자에게 특히 유용할 수 있습니다.\n\n\n▶프리웨어 - 개인\n▶ Windows 10/11\n▶무료 다운로드◀\n\n \nUnchecky - Keeps your checkboxes clear\nUnchecky aims to keep potentially unwanted programs out of your computer.\nunchecky.com\n\n \n \n \n \n2. Funny Photo Maker (재미있는 효과 적용하는  무료 사진 편집 프로그램)\n  Windows용 무료 사진 편집 프로그램으로, 디지털 사진에 재미있는 효과를 쉽고 빠르게 추가할 수 있습니다. 이 프로그램은 200개 이상의 표준 효과를 제공하며, 이는 Photo Frame, Face Fun, Photo Effects의 세 가지 카테고리로 분류됩니다. 사용자는 사진을 프레임에 삽입하거나, 얼굴을 다른 이미지로 변환하거나, 예술적 효과를 적용할 수 있습니다. Funny Photo Maker를 통해 편집된 사진은 PC에 저장하거나 소셜 미디어를 통해 공유할 수 있으며, BMP, JPG, PNG 이미지 또는 GIF 애니메이션으로 저장할 수 있습니다. 이 프로그램은 Microsoft Windows에서만 사용 가능합니다.\n\n\n▶프리웨어 - 개인\n▶Windows 10/11\n▶무료 다운로드 ◀\n\n \nFunny Photo Maker - Edit Funny Photos with photo frames and effects For Free\nIt's Easy! Confused on the countless buttons in PhotoShop? Now you have an easier solution! Funny Photo Maker has a user-friendly interface that enables you to fast comprehend and use the powerful program. The whole editing process is a piece of cake for a\nwww.funny-photo-maker.com\n\n \n \n \n \n3. Ocenaudio (무료 디지털 사운드 편집 프로그램)\n 무료 디지털 사운드 편집 프로그램입니다. 이 프로그램은 Ocean 프레임워크를 기반으로 하며, VST 플러그인을 지원하여 다양한 효과를 적용할 수 있습니다. Ocenaudio는 실시간 미리보기 기능과 다중 선택 시스템을 제공하여 복잡한 오디오 편집 작업을 효율적으로 수행할 수 있게 해줍니다. 이 소프트웨어는 파일 길이나 수량에 제한이 없으며, 실시간 스펙트로그램 디스플레이를 제공합니다. Ocenaudio는 초보자부터 경험 있는 사용자까지 모두에게 적합한 기능을 갖춘 종합적인 오디오 및 음악 편집 도구입니다.\n\n\n▶프리웨어 - 개인\n▶Windows 10/11 \n▶무료 다운로드 ◀https://www.ocenaudio.com/\n\n \nocenaudio\nEasy, fast and powerful audio editor\nwww.ocenaudio.com\n\n \n \n \n \n4. Opera GX (게이머를 위한 특별한 브라우저) \n\n 게이머를 위한 특별한 브라우저입니다. CPU, RAM, 네트워크 사용량을 제한하고, 사이드바에서 디스코드와 트위치를 사용하며, Flow 기능을 사용하여 모바일과 데스크탑 브라우저를 연결할 수 있습니다. \nOpera GX와 기존 Opera 브라우저의 주요 차이점은 게이머 맞춤 기능, 성능, 리소스 사용, 사용자 정의, 가용 플랫폼입니다. Opera GX는 게이머에게 더 나은 경험을 제공하기 위해 특화되어 있으며, 기존 Opera 브라우저는 더 다양한 기능과 플랫폼을 지원합니다.\n\n\n▶프리웨어 - 개인/기업 (오픈소스)\n▶Windows 10/11\n▶무료 다운로드 ◀\n\n \nOpera GX | 게이밍 브라우저 | Opera\nOpera GX는 특별히 게이머를 위해 만든 브라우저입니다. 강력하고 혁신적 브라우저에 포함된 비교할 수 없는 게이밍 및 브라우징 기능을 이용하세요.\nwww.opera.com\n\n \n \n \n \n5. Speccy (PC의 사양과 구성 요소를 파악)\n  사용자 친화적인 무료 프로그램으로, PC의 사양과 구성 요소를 파악하는 데 도움을 줍니다. 운영 체제, CPU, RAM, 스토리지, 그래픽 카드, 사운드 카드, 온도, 드라이버 등을 포함한 하드웨어 및 소프트웨어에 대한 자세한 보고서를 제공합니다. Speccy는 시스템 문제 진단, 구성 요소 온도 모니터링, 업데이트 확인, 설치된 드라이버 분석, 기술 보고서 작성 등에 유용합니다. 가볍고 사용하기 쉬운 Speccy는 PC에 대해 더 알고 싶은 모든 사람들에게 훌륭한 도구입니다.\n\n\n▶프리웨어 - 개인\n▶Windows 10/11\n▶무료 다운로드 ◀\n\n \nSpeccy 다운로드 | 컴퓨터 사양을 무료로 확인하세요!\nSpeccy® 빠르고 가벼운 PC용 고급 시스템 정보 도구입니다. 컴퓨터에 무엇이 있는지 알고 싶으신가요? Speccy에 필요한 모든 정보가 있습니다! 참고: 다양한 스크린 리더를 사용하여 CCleaner를 테스트\nwww.ccleaner.com",
        "guid": "http://muzbox.tistory.com/483448",
        "categories": [
          "NEWS/프리웨어 뉴스",
          "It",
          "opera gx",
          "pc정보확인",
          "Speccy",
          "게임용웹브라우저",
          "사진편집",
          "앱자동설치방지",
          "오디오편집",
          "재미있는효과적요",
          "추천프로그램"
        ],
        "isoDate": "2024-07-08T00:36:43.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": [
      {
        "creator": "늑돌이",
        "title": "1등 10만달러! 글로벌 webOS 해커톤 여는 LG전자",
        "link": "http://lazion.com/2513714",
        "pubDate": "Wed, 10 Jul 2024 13:36:54 +0900",
        "author": "늑돌이",
        "comments": "http://lazion.com/2513714#entry2513714comment",
        "content": "<h3 data-ke-size=\"size23\">LG전자가 자사의 스마트TV 플랫폼인 <b>webOS</b>에 탑재할 게임과 라이프스타일, 인공지능(AI) 활용 콘텐츠를 모집하는 <b>글로벌 해커톤(Hackathon)을 개최</b>합니다.</h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"001 - 56870_web.jpg\" data-origin-width=\"856\" data-origin-height=\"542\"><span data-url=\"https://blog.kakaocdn.net/dn/cSgu6m/btsItHwW5V9/giFnMNdOkTKq6oWPYNTYz0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cSgu6m/btsItHwW5V9/giFnMNdOkTKq6oWPYNTYz0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cSgu6m/btsItHwW5V9/giFnMNdOkTKq6oWPYNTYz0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcSgu6m%2FbtsItHwW5V9%2FgiFnMNdOkTKq6oWPYNTYz0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"001 - 56870_web.jpg\" data-origin-width=\"856\" data-origin-height=\"542\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\"><a href=\"https://weboshackathon.lge.com/\" target=\"_blank\" rel=\"noopener\">북미이노베이션센터(LG NOVA) 홈페이지를 통해 발표</a>된 이번 글로벌 해커톤 행사는 webOS 콘텐츠의 경쟁력을 향상시켜 webOS의 TV 플랫폼 사업을 확대하는 개방형 혁신 활동의 일환으로 진행됩니다.</p>\n<p data-ke-size=\"size16\">이미 LG전자는 TV 사업의 지향점을 미디어&amp;엔터테인먼트 플랫폼 기업으로 삼고 올해 webOS 플랫폼 사업을 조(兆) 단위 매출 규모로 키우겠다고 밝힌 바 있습니다.<br />&nbsp;</p>\n<p data-ke-size=\"size16\">현재 webOS에는 엔터테인먼트, 홈피트니스, 교육, 원격의료 등 약 3,500여개 앱 콘텐츠가 준비되어 있으며 글로벌 기준으로 webOS로 즐길 수 있는 게임은 500여개의 앱이 있습니다. 만약 지포스 나우(GeForce NOW), 아마존 루나(Amazon Luna) 등 클라우드 게이밍 서비스 내 게임을 합친다면 3,000여개까지 가능합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;<br />해커톤 참가를 원하는 글로벌 개발자들은 7월 26일까지 <span style=\"color: #0593d3;\"><a href=\"https://weboshackathon.lge.com/\" target=\"_blank\" rel=\"noopener\">공식 홈페이지(https://weboshackathon.lge.com/)</a></span>로 지원서를 제출해야 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"002 - 56869_web.jpg\" data-origin-width=\"856\" data-origin-height=\"563\"><span data-url=\"https://blog.kakaocdn.net/dn/bEq2wq/btsIuSxwP5k/ETz6d4y89LqNRVs4uR3xgk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bEq2wq/btsIuSxwP5k/ETz6d4y89LqNRVs4uR3xgk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bEq2wq/btsIuSxwP5k/ETz6d4y89LqNRVs4uR3xgk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbEq2wq%2FbtsIuSxwP5k%2FETz6d4y89LqNRVs4uR3xgk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"002 - 56869_web.jpg\" data-origin-width=\"856\" data-origin-height=\"563\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">선정된 수상자에게는 <b>1등은 10만달러(약 1억3천9백만원)</b>, 2등은 8만달러, 3등은 5만달러 등의 상금과 함께 개발한 콘텐츠를 webOS를 탑재한 2억대 넘는 스마트TV를 대상으로 사업화할 수 있는 하는 기회도 주어집니다. 참고로 콘텐츠 개발 과정에서 LG전자 전문가들로부터 기술 지원도 받을 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: right;\" data-ke-size=\"size16\">(출처 : <a href=\"https://www.lge.co.kr/\" target=\"_blank\" rel=\"noopener\">LG전자</a>)</p>",
        "contentSnippet": "LG전자가 자사의 스마트TV 플랫폼인 webOS에 탑재할 게임과 라이프스타일, 인공지능(AI) 활용 콘텐츠를 모집하는 글로벌 해커톤(Hackathon)을 개최합니다.\n\n\n북미이노베이션센터(LG NOVA) 홈페이지를 통해 발표된 이번 글로벌 해커톤 행사는 webOS 콘텐츠의 경쟁력을 향상시켜 webOS의 TV 플랫폼 사업을 확대하는 개방형 혁신 활동의 일환으로 진행됩니다.\n이미 LG전자는 TV 사업의 지향점을 미디어&엔터테인먼트 플랫폼 기업으로 삼고 올해 webOS 플랫폼 사업을 조(兆) 단위 매출 규모로 키우겠다고 밝힌 바 있습니다.\n \n현재 webOS에는 엔터테인먼트, 홈피트니스, 교육, 원격의료 등 약 3,500여개 앱 콘텐츠가 준비되어 있으며 글로벌 기준으로 webOS로 즐길 수 있는 게임은 500여개의 앱이 있습니다. 만약 지포스 나우(GeForce NOW), 아마존 루나(Amazon Luna) 등 클라우드 게이밍 서비스 내 게임을 합친다면 3,000여개까지 가능합니다.\n \n해커톤 참가를 원하는 글로벌 개발자들은 7월 26일까지 공식 홈페이지(https://weboshackathon.lge.com/)로 지원서를 제출해야 합니다.\n \n\n\n \n선정된 수상자에게는 1등은 10만달러(약 1억3천9백만원), 2등은 8만달러, 3등은 5만달러 등의 상금과 함께 개발한 콘텐츠를 webOS를 탑재한 2억대 넘는 스마트TV를 대상으로 사업화할 수 있는 하는 기회도 주어집니다. 참고로 콘텐츠 개발 과정에서 LG전자 전문가들로부터 기술 지원도 받을 수 있습니다.\n \n(출처 : LG전자)",
        "guid": "http://lazion.com/2513714",
        "categories": [
          "#소프트웨어#앱#서비스",
          "Hackathon",
          "LG",
          "LGE",
          "News",
          "SmartTV",
          "Software",
          "TV",
          "WEBOS"
        ],
        "isoDate": "2024-07-10T04:36:54.000Z"
      }
    ]
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "｜RULIWEB｜",
        "title": "[게임툰] 탐정이 사신쨩을 숨김, 초탐정사건부 레인코드",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2235",
        "pubDate": "Thu, 11 Jul 2024 16:41:54 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i1.ruliweb.com/thumb/24/07/11/190a0953b8e51ad6b.png\">",
        "contentSnippet": "",
        "categories": [
          "게임툰"
        ],
        "isoDate": "2024-07-11T07:41:54.000Z"
      },
      {
        "creator": "［RULIWEB］",
        "title": "[MULTI] 두 개의 DNA가 만든 기초와 후반 집중 그라인딩, 퍼스트 디센던트",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2234",
        "pubDate": "Tue, 09 Jul 2024 13:48:10 +0900",
        "author": "［RULIWEB］",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/24/07/09/19095d14db05104c1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2024-07-09T04:48:10.000Z"
      },
      {
        "creator": "｜RULIWEB｜",
        "title": "[게임툰] 나만의 본격적인 댄스 레슨, 마이 댄스 스튜디오",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2233",
        "pubDate": "Mon, 08 Jul 2024 18:59:28 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/24/07/08/19091c56dd951ad6b.png\">",
        "contentSnippet": "",
        "categories": [
          "게임툰"
        ],
        "isoDate": "2024-07-08T09:59:28.000Z"
      },
      {
        "creator": "｜RULIWEB｜",
        "title": "[게임툰] 색다른 형태로 즐기는 수렵, 몬스터헌터 스토리즈",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2232",
        "pubDate": "Sat, 06 Jul 2024 20:17:01 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i1.ruliweb.com/thumb/24/07/06/19087bf43cb51ad6b.jpg\">",
        "contentSnippet": "",
        "categories": [
          "게임툰"
        ],
        "isoDate": "2024-07-06T11:17:01.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "khris'log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": [
      {
        "title": "Visual C++ - 리팩터링 도구",
        "link": "https://jacking75.github.io/VS_20240712/",
        "pubDate": "Fri, 12 Jul 2024 00:00:00 +0900",
        "content": "<iframe width=\"1024\" height=\"1024\" src=\"https://docs.google.com/document/d/e/2PACX-1vQ3mKCaWpwuh-q2xhHR49Wlz90iBQuHaVVU0W90Vs785x7kbgL7-t4-zYUU7XlgguXATi6_M73dXs8n/pub?embedded=true\"></iframe>\n\n",
        "contentSnippet": "",
        "guid": "https://jacking75.github.io/VS_20240712/",
        "isoDate": "2024-07-11T15:00:00.000Z"
      },
      {
        "title": "GitHub Copilot 명령어",
        "link": "https://jacking75.github.io/tech-ai_20240711/",
        "pubDate": "Thu, 11 Jul 2024 00:00:00 +0900",
        "content": "<iframe width=\"1024\" height=\"1024\" src=\"https://docs.google.com/document/d/e/2PACX-1vTmSSv2NBS-inJxrJkfNuAsRVCTnXAZkv8-ZEevtY-53JhJeaHuM2Xw8_ezOjH6inK7jmi5zTwZFcMz/pub?embedded=true\"></iframe>\n\n",
        "contentSnippet": "",
        "guid": "https://jacking75.github.io/tech-ai_20240711/",
        "isoDate": "2024-07-10T15:00:00.000Z"
      }
    ]
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": [
      {
        "title": "루비 온 레일즈 소식지",
        "link": "https://jeho.page/essay/2024/07/09/rails-news-letter.html",
        "pubDate": "2024-07-09T04:15:00.000Z",
        "author": "김재호",
        "content": "<p>루비 온 레일즈의 따끈따끈한 소식을 전달해 주는 한국어 소식지가 생겼습니다.</p>\n\n<p>소식지를 쓰는 사람은 이전 회사의 동료입니다.<br />\n10년 전에 카카오에서 레일즈로 서버 개발을 하던 당시에, 자리에 찾아와서 레일즈 배포 방법 같은 걸 귀찮게 물어보던 클라이언트 개발자가 있었습니다.<br />\n귀찮았지만(ㅋㅋ) 열심히 가르쳐 줬던 것 같습니다.<br />\n그러다가 시간이 흘러 카톡 서버팀으로 와서 함께 일하게 됐고… 큰 힘이 됐던 동료입니다.</p>\n\n<p><img src=\"/assets/img/rails_news.png\" alt=\"레일즈 소식지\" /><br />\n<em>레일즈를 좋아하는 사람들에게는 단비 같은 뉴스</em></p>\n\n<p>오늘 <a href=\"https://maily.so/rubyonrails/posts/3a2526c1\">두 번째 소식</a>을 받아봤는데 <a href=\"https://maily.so/rubyonrails/posts/8399b690\">첫 번째 소식지</a> 만큼이나 만족스럽습니다.<br />\n딱 이 정도 퀄리티로 꾸준하게 받아볼 수 있다면 제게 가장 기다려지는 소식지가 될 것 같습니다.</p>\n\n<p>레일즈에 관심 있는 사람들이 많이 구독하고 피드백하면서 계속 발전해나가면 좋겠습니다.\n<br />\n<br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2021/12/17/ruby-on-rails-7.html\">루비 온 레일즈 7</a></li>\n  <li><a href=\"/essay/2023/01/04/dont-say-ruby-is-slow.html\">루비가 느리다고?</a></li>\n</ul>",
        "contentSnippet": "루비 온 레일즈의 따끈따끈한 소식을 전달해 주는 한국어 소식지가 생겼습니다.\n소식지를 쓰는 사람은 이전 회사의 동료입니다.\n\n레일즈를 좋아하는 사람들에게는 단비 같은 뉴스\n오늘 두 번째 소식을 받아봤는데 첫 번째 소식지 만큼이나 만족스럽습니다.\n레일즈에 관심 있는 사람들이 많이 구독하고 피드백하면서 계속 발전해나가면 좋겠습니다.\n\n\n함께 읽으면 좋은 글:\n루비 온 레일즈 7\n루비가 느리다고?",
        "summary": "루비 온 레일즈의 따끈따끈한 소식을 전달해 주는 한국어 소식지가 생겼습니다.",
        "id": "https://jeho.page/essay/2024/07/09/rails-news-letter",
        "isoDate": "2024-07-09T04:15:00.000Z"
      },
      {
        "title": "꾸준한 블로깅",
        "link": "https://jeho.page/essay/2024/07/08/steady-blogging.html",
        "pubDate": "2024-07-07T16:28:00.000Z",
        "author": "김재호",
        "content": "<p><a href=\"https://github.com/BenjaminKim/awesome-blogs/blob/master/config/feeds.yml\">개발자 블로그를 큐레이션 한지</a> 8년째.</p>\n\n<p>5년 이상 꾸준하게 글을 쓰는 사람이 거의 없습니다.<br />\n반짝거리는 신인이 등장했다가도 몇 년 글을 쓰다가 사라져버립니다.<br />\n몇 년 동안 새로운 글이 올라오지 않아 블로그를 빼버릴 땐 잠시 슬퍼집니다.<br />\n글 올라오기를 손꼽아 기다리던 블로그라면 더욱더.</p>\n\n<p>열정을 잃어서.<br />\n취업을 해버려서.<br />\n다른 곳에 흥미가 생겨서.<br />\n결혼하고 육아하다 보니까.<br />\n사람들에게 악플 공세를 받고.<br />\n유명해질수록 점점 압박이 커져서.</p>\n\n<p>그만둘 이유는 많습니다.<br />\n열정을 오랫동안 유지하기란 이렇게 어려운 것.</p>\n\n<p>그래서 오래 꾸준한 블로그를 보면 좋은 영감을 받게 됩니다.<br />\n저도 제 개발자 이야기를 완결 짓는 날까지 꾸준히 써보고 싶습니다.\n<br />\n<br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2021/12/14/steady.html\">꾸준히 한다는 것</a></li>\n  <li><a href=\"/essay/2023/10/25/firebase.html\">개발자 블로그 모음</a></li>\n  <li><a href=\"/essay/2022/01/05/daily-coding.html\">매일매일 코딩하기</a></li>\n</ul>",
        "contentSnippet": "개발자 블로그를 큐레이션 한지 8년째.\n5년 이상 꾸준하게 글을 쓰는 사람이 거의 없습니다.\n열정을 잃어서.\n그만둘 이유는 많습니다.\n그래서 오래 꾸준한 블로그를 보면 좋은 영감을 받게 됩니다.\n함께 읽으면 좋은 글:\n꾸준히 한다는 것\n개발자 블로그 모음\n매일매일 코딩하기",
        "summary": "개발자 블로그를 큐레이션 한지 8년째.",
        "id": "https://jeho.page/essay/2024/07/08/steady-blogging",
        "isoDate": "2024-07-07T16:28:00.000Z"
      }
    ]
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "SPY -&gt; SPMO  / SDHD -&gt; DGRW 종목교체권장",
        "link": "http://serverdown.tistory.com/782",
        "pubDate": "Mon, 8 Jul 2024 00:21:38 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/782#entry782comment",
        "content": "<div style=\"background-color: #000000; color: #000000; text-align: left;\">\n<div style=\"background-color: #000000; color: #000000;\" data-ved=\"2ahUKEwiC-IvijpWHAxUHhlYBHYIIILkQlcAGegQIDxAA\" data-hveid=\"CA8QAA\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">&nbsp;</div>\n</div>\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\" data-ias=\"false\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">8-9월엔 장이 보통 안좋습니다.</div>\n<div style=\"background-color: #000000; color: #000000;\">9월이 정치적 이슈가 크기 때문이죠</div>\n<div style=\"background-color: #000000; color: #000000;\">높을땐 좀 줄이고 다시 사는걸 고려해야합니다.</div>\n<div style=\"background-color: #000000; color: #000000;\">&nbsp;</div>\n<div style=\"background-color: #000000; color: #000000;\">그래서 종목교체 추천</div>\n<div style=\"background-color: #000000; color: #000000;\">&nbsp;</div>\n<div style=\"background-color: #000000; color: #000000;\">&nbsp;</div>\n<div style=\"background-color: #000000; color: #000000;\">&nbsp;</div>\n<div style=\"background-color: #000000; color: #000000;\">SPMO&nbsp; - Invesco S&amp;P 500 Momentum ETF</div>\n<div style=\"background-color: #000000; color: #000000;\">&nbsp;</div>\n<div style=\"background-color: #000000; color: #000000;\">S&amp;P500 보다 더 가고 하락시엔 덜 하락하는 모먼템 투자 ETF 입니다.</div>\n<div style=\"background-color: #000000; color: #000000;\">&nbsp;</div>\n<div style=\"background-color: #000000; color: #000000;\">한국에선 소개된 영상이 없군요&nbsp;</div>\n<div style=\"background-color: #000000; color: #000000;\">&nbsp;</div>\n<div style=\"background-color: #000000; color: #000000;\">&nbsp;</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<div style=\"background-color: #000000; color: #000000; text-align: left;\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div id=\"JTPWx\" style=\"background-color: #000000; color: #000000;\" data-hveid=\"CBIQAA\">&nbsp;</div>\n</div>\n</div>\n<p data-ke-size=\"size16\">SCHD - 배당주 ETF 로 인기있었던건데 이것도&nbsp;</p>\n<p data-ke-size=\"size16\">모멘텀 방식의 ETF 가 나왔습니다. DGRW&nbsp;</p>\n<p data-ke-size=\"size16\">참고영상:</p>\n<p data-ke-size=\"size16\"><a href=\"https://www.youtube.com/watch?v=F3kdp5HyGwU\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=F3kdp5HyGwU</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=F3kdp5HyGwU\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/psknD/hyWzFjjsPF/zB4420AhrDwboKRLMKNK71/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"미국 1등 월 배당 ETF / DGRW ETF / 배당성장 ETF 끝판왕!\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/F3kdp5HyGwU\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "8-9월엔 장이 보통 안좋습니다.\n9월이 정치적 이슈가 크기 때문이죠\n높을땐 좀 줄이고 다시 사는걸 고려해야합니다.\n \n그래서 종목교체 추천\n \n \n \nSPMO  - Invesco S&P 500 Momentum ETF\n \nS&P500 보다 더 가고 하락시엔 덜 하락하는 모먼템 투자 ETF 입니다.\n \n한국에선 소개된 영상이 없군요 \n \n \n \n \nSCHD - 배당주 ETF 로 인기있었던건데 이것도 \n모멘텀 방식의 ETF 가 나왔습니다. DGRW \n참고영상:\nhttps://www.youtube.com/watch?v=F3kdp5HyGwU",
        "guid": "http://serverdown.tistory.com/782",
        "categories": [
          "투자",
          "DGRW",
          "SCHD",
          "spmo",
          "Spy"
        ],
        "isoDate": "2024-07-07T15:21:38.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Hybrid's Notes",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": []
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "한상곤 - Sigmadream",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": []
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "이한",
    "category": "개인",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": [
      {
        "title": "지식, 진실, 그리고 거짓말",
        "link": "https://velog.io/@ahngj96/%EC%A7%80%EC%8B%9D-%EC%A7%84%EC%8B%A4-%EA%B7%B8%EB%A6%AC%EA%B3%A0-%EA%B1%B0%EC%A7%93%EB%A7%90",
        "pubDate": "Thu, 11 Jul 2024 18:12:39 GMT",
        "content": "<p>분산 시스템에서 우리는 동작(시스템 모델)에 관해 정한 가정을 명시하고, 이런 가정을 만족시키는 방식으로 실제 시스템을 설계할 수 있다. 어떤 시스템 모델 내에서 알고리즘이 올바르게 동작하는지 증명할 수 있다. 기반 시스템 모델이 매우 적은 보장만 제공하더라도 신뢰성 있는 동작을 달성할 수 있다는 뜻이다.</p>\n<h1 id=\"진실은-다수결로-결정된다\">진실은 다수결로 결정된다</h1>\n<p>노드가 상황에 대한 자신의 판단은 반드시 믿을 수 있는 것이 아니다. 분산 시스템은 한 노드에만 의존할 수는 없다. 노드에 언제든 장애가 나서 잠재적으로 시스템이 멈추고 복구할 수 없게 될 수도 있기 때문이다. 대신 여러 분산 알고리즘은 정족수, 즉 노드들 사이의 투표에 의존한다. 특정한 노드 하나에 대한 의존을 줄이기 위해 결정을 하려면 여러 노드로부터 어떤 최소 개수의 투표를 받아야 한다.</p>\n<p>노드의 과반수 이상을 정족수로 삼는 게 가장 흔하다. 과반수 정족수를 사용하면 개별 노드들에 장애가 나더라도 시스템은 계속 동작할 수 있다(노드가 3대면 1대 장애 ok, 노드가 5대면 2대 장애 ok).</p>\n<h2 id=\"리더와-잠금\">리더와 잠금</h2>\n<p>시스템이 오직 하나의 뭔가가 필요할 때가 자주 있다.</p>\n<ul>\n<li>스플릿 브레인(리더가 하나뿐인 시스템에서 서로 자신이 리더인줄 알고 있는 상황) 방지</li>\n<li>객체에 쓰거나 수정할때 객체 잠금 획득</li>\n<li>유니크 사용자 명</li>\n</ul>\n<p>분산 시스템에서 이를 구현하려면 주의해야 한다. 어떤 노드가 스스로를 <code>선택된 자</code>라고 믿을지라도 노드의 정족수도 반드시 동의한다는 뜻은 아니다! 어떤 노드가 이전에 리더였더라도 시간이 흐른 사이에 다른 노드들이 그 노드가 죽었다고 선언하면 그 노드는 강등되고 다른 리더가 이미 선출됐을지도 모른다.</p>\n<p><img src=\"https://velog.velcdn.com/images/ahngj96/post/d4f4503e-8692-436b-858d-1fd64b4588d0/image.png\" alt=\"\">\n<a href=\"https://azderica.github.io/til/docs/data/designing-data-intensive-applications/ch8/\">이미지 출처</a></p>\n<p>위 그림과 같이 만료된 권한인지 모르고 권한 있는 상태(<code>선택된 자</code>)라 생각하고 데이터를 기록하게되면 저장소에 있는 데이터를 오염시키게 된다.</p>\n<h2 id=\"펜싱-토큰\">펜싱 토큰</h2>\n<p>자신이 <code>선택된 자</code>라고 잘못 믿고 있는 노드가 나머지 시스템을 방해할 수 없도록 보장해야 한다. 이 목적을 달성하는 상당히 단순한 기법을 펜싱(fencing)이 있다.</p>\n<p><img src=\"https://velog.velcdn.com/images/ahngj96/post/4bf9f1b5-d700-4d89-9456-6dc9298dbd7a/image.png\" alt=\"\">\n<a href=\"https://azderica.github.io/til/docs/data/designing-data-intensive-applications/ch8/\">이미지 출처</a></p>\n<p>잠금 서버가 잠금이나 임차권을 승인할 때마다 펜싱 토큰(fencing token)도 반환한다고 가정한다. 그리고 펜싱 토큰은 잠금이 승인될 때마다 증가하는 숫자라 가정한다. 그러면 클라이언트가 쓰기 요청을 저장소 서비스로 보낼 때마다 자신의 현재 펜싱 토큰을 포함하도록 요구할 수 있다. 그러면 위 그림과 같이 오래된 토큰의 요청은 거부할 수 있다.</p>\n<p>서버 측에서 토큰을 확인하는 것은 결점으로 보이지만 결점이 아니다. 뜻하지 않게 폭력적인 클라이언트로부터 보호하려는 서비스는 서버 측에서 토큰을 확인하는 게 좋다.</p>\n<h2 id=\"비잔틴-결함\">비잔틴 결함</h2>\n<p>펜싱 토큰은 아직 자신이 <code>선택된 자</code>라고 생각하는 오류에 빠진 노드를 감지하고 차단할 수 있다. 그러나 노드가 고의로 시스템의 보장을 무너뜨리려한다면 가짜 펜싱 토큰을 포함한 메시지를 보내기만 하면 된다.</p>\n<p>지금까지는 노드들이 신뢰성은 없지만 응답한다면 <code>진실</code>만 말한다고 가정했다. 그러나 분산 시스템 문제는 노드가 <code>거짓말</code>을 할지도 모른다는 위험이 있다면 훨씬 더 어려워진다. 이런 동작을 비잔틴 결함(Byzantine fault)이라고 하며 이렇게 신뢰할 수 없는 환경에서 합의에 도달하는 문제를 <a href=\"https://m.upbitcare.com/academy/education/blockchain/296\">비잔틴 장군 문제(Byzantine Generals Problem)</a>라고 한다.</p>\n<p>일부 노드가 오작동하고 프로토콜을 준수하지 않고나 악의적인 공격자가 네트워크를 방해하더라도 시스템이 계속 올바르게 동작한다면 이 시스템은 비잔틴 내결함성(Byzantine fault tolerant)을 지닌다. 이런 관심사는 특정 환경에서 유의미하다. (예를 들어, 방사선 노출이 큰 항공우주 산업이나 비트코인 같은 분야)</p>\n<p>그러나 우리가 살펴보는 시스템의 종류는 보통 비잔틴 결함이 없다고 가정할 수 있다. 그리고 대부분의 서버 측 데이터 시스템에서 비잔틴 내결함성 솔류션을 배치하는 것은 비용이 커서 실용적이지 않다. 대신 보통 중앙 권한을 가지고 최종 사용자의 입력을 확인(input validation)하고 살균(sanitization, 잠재적으로 위험할 수 있는 입력값을 유효한 값으로 치환)하고 출력 이스케이핑(output escaping) 등으로 SQL injection이나 크로스 사이트 스크립팅 등의 공격을 막는다.</p>\n<h2 id=\"약한-형태의-거짓말\">약한 형태의 거짓말</h2>\n<p>하드웨어 문제, 소프트웨어 버그, 잘못된 설정으로 인한 유효하지 않은 메시지 등 의도치 않은 약한 형태의 <code>거짓말</code>로부터 보호해주느느 메커니즘을 추가하는 것은 가치가 있다.</p>\n<ul>\n<li>TCP 내장 체크섬만 믿지 말고 체크섬을 직접 애플리케이션에 넣기</li>\n<li>사용자 입력 살균하기</li>\n<li>NTP 여러 서버 주소 설정하기</li>\n</ul>\n<h1 id=\"시스템-모델과-현실\">시스템 모델과 현실</h1>\n<p>알고리즘은 그들이 실행되는 하드웨어와 소프트웨어 설정의 세부 사항에 너무 심하게 의존하지 않는 방식으로 작성해야 한다. 그러려면 시스템에서 발생할 것으로 예상되는 결함의 종류를 어떻게든 정형화해야 한다. 시스템 모델을 정의해서 정형화하는데, 시스템 모델은 알고리즘이 가정하는 것을 기술한 추상화다.</p>\n<blockquote>\n<p>타이밍 가정에 대한 흔히 사용하는 세 가지 시스템 모델</p>\n<ul>\n<li>동기식 모델: 네트워크 지연, 프로세스 중단 등 모두 제한이 있다고 가정</li>\n<li>부분 동기식 모델: 대부분의 시간에는 동기식 시스템처럼 동작하지만 때때로 네트워크 지연 등 한계치를 초과한다고 가정. 많은 시스템에서 현실적인 모델</li>\n<li>비동기식 모델: 이 모델에서 알고리즘은 타이밍에 대한 어떤 가정도 할 수 없다.</li>\n</ul>\n</blockquote>\n<blockquote>\n<p>노드 장애를 고려하는 세가지 시스템 모델</p>\n<ul>\n<li>죽으면 중단(crash-stop)하는 결함</li>\n<li>죽으면 복구하는(carsh-recovery) 결함</li>\n<li>비잔틴 결함</li>\n</ul>\n</blockquote>\n<p>현실 시스템을 모델링하는데는 죽으면 복구하는 결함을 지닌 부분 동기식 모델이 일반적으로 가장 유용한 모델이다.</p>\n<h2 id=\"알고리즘의-안정성과-활동성\">알고리즘의 안정성과 활동성</h2>\n<p>상황을 분명히 하기 위해 두 가지 다른 종류의 속성, 안정성(safety)과 활동성(liveness)을 구별할 필요가 있다.</p>\n<p>안정성은 흔히 비공식적으로 나쁜 일은 일어나지 않는다라고, 활동성은 좋은 일은 결국 일어난다라고 정의한다. 안전성 속성이 위반되면 그 속성이 깨진 특정 시점을 가리킬 수 있다. 안전성 속성이 위반된 후에는 그 위반을 취소할 수 없다. 활동성 속성은 어떤 시점을 정하지 못할 수 있지만, 항상 미래에 그 속성을 만족시킬 수 있다는 희망이 있다.</p>\n<p>분산 알고리즘은 시스템 모델의 모든 상황에서 안정성 속성이 항상 만족되기를 요구하는 게 일반적이다. 즉 모든 노드가 죽거나 네트워크 전체에 장애가 생기더라도 알고리즘은 잘못된 결과를 반환하지 않는다고 보장해야 한다.</p>\n<p>그러나 활동성 속성에 대해서는 경고를 하는 게 허용된다. 예를 들어 노드의 다수가 죽지 않고 네트워크가 중단으로부터 결국 복구됐을 때만 요청이 응답을 받아야 한다고 말할 수 있다.</p>\n<h2 id=\"시스템-모델을-현실-세계에-대응시키기\">시스템 모델을 현실 세계에 대응시키기</h2>\n<p>현업에서 알고리즘을 구현할 때 현실의 지저분한 사실들이 시스템 모델은 현실의 단순화된 추상화라는 게 명백해진다.</p>\n<p>알고리즘을 이론적으로 설명할 때는 그냥 어떤 일이 일어나지 않는다고 가정할 수 있다. 그러나 실제 구현에는 여전히 불가능하다고 가정했던 일이 발생하는 경우를 처리하는 코드를 포함시켜야 할 수도 있다.</p>\n<p>이론적인 추상 시스템 모델은 현실 시스템의 복잡함에서 우리가 추론할 수 있는 관리 가능한 결함의 집합을 뽑아내서, 문제를 이해하고 체계적으로 해결하려고 노력할 수 있게 하는 데 도움이 된다.</p>\n<p>알고리즘이 올바르다고 증명됐더라도 반드시 현실 시스템에서의 구현도 언제나 올바르게 동작한다는 뜻은 아니다. 그렇지만 알고리즘의 증명은 아주 좋은 첫걸음이다.</p>\n<h1 id=\"reference\">Reference</h1>\n<p>데이터 중심 애플리케이션 설계 8장</p>\n",
        "contentSnippet": "분산 시스템에서 우리는 동작(시스템 모델)에 관해 정한 가정을 명시하고, 이런 가정을 만족시키는 방식으로 실제 시스템을 설계할 수 있다. 어떤 시스템 모델 내에서 알고리즘이 올바르게 동작하는지 증명할 수 있다. 기반 시스템 모델이 매우 적은 보장만 제공하더라도 신뢰성 있는 동작을 달성할 수 있다는 뜻이다.\n진실은 다수결로 결정된다\n노드가 상황에 대한 자신의 판단은 반드시 믿을 수 있는 것이 아니다. 분산 시스템은 한 노드에만 의존할 수는 없다. 노드에 언제든 장애가 나서 잠재적으로 시스템이 멈추고 복구할 수 없게 될 수도 있기 때문이다. 대신 여러 분산 알고리즘은 정족수, 즉 노드들 사이의 투표에 의존한다. 특정한 노드 하나에 대한 의존을 줄이기 위해 결정을 하려면 여러 노드로부터 어떤 최소 개수의 투표를 받아야 한다.\n노드의 과반수 이상을 정족수로 삼는 게 가장 흔하다. 과반수 정족수를 사용하면 개별 노드들에 장애가 나더라도 시스템은 계속 동작할 수 있다(노드가 3대면 1대 장애 ok, 노드가 5대면 2대 장애 ok).\n리더와 잠금\n시스템이 오직 하나의 뭔가가 필요할 때가 자주 있다.\n스플릿 브레인(리더가 하나뿐인 시스템에서 서로 자신이 리더인줄 알고 있는 상황) 방지\n객체에 쓰거나 수정할때 객체 잠금 획득\n유니크 사용자 명\n분산 시스템에서 이를 구현하려면 주의해야 한다. 어떤 노드가 스스로를 선택된 자라고 믿을지라도 노드의 정족수도 반드시 동의한다는 뜻은 아니다! 어떤 노드가 이전에 리더였더라도 시간이 흐른 사이에 다른 노드들이 그 노드가 죽었다고 선언하면 그 노드는 강등되고 다른 리더가 이미 선출됐을지도 모른다.\n\n이미지 출처\n위 그림과 같이 만료된 권한인지 모르고 권한 있는 상태(선택된 자)라 생각하고 데이터를 기록하게되면 저장소에 있는 데이터를 오염시키게 된다.\n펜싱 토큰\n자신이 선택된 자라고 잘못 믿고 있는 노드가 나머지 시스템을 방해할 수 없도록 보장해야 한다. 이 목적을 달성하는 상당히 단순한 기법을 펜싱(fencing)이 있다.\n\n이미지 출처\n잠금 서버가 잠금이나 임차권을 승인할 때마다 펜싱 토큰(fencing token)도 반환한다고 가정한다. 그리고 펜싱 토큰은 잠금이 승인될 때마다 증가하는 숫자라 가정한다. 그러면 클라이언트가 쓰기 요청을 저장소 서비스로 보낼 때마다 자신의 현재 펜싱 토큰을 포함하도록 요구할 수 있다. 그러면 위 그림과 같이 오래된 토큰의 요청은 거부할 수 있다.\n서버 측에서 토큰을 확인하는 것은 결점으로 보이지만 결점이 아니다. 뜻하지 않게 폭력적인 클라이언트로부터 보호하려는 서비스는 서버 측에서 토큰을 확인하는 게 좋다.\n비잔틴 결함\n펜싱 토큰은 아직 자신이 선택된 자라고 생각하는 오류에 빠진 노드를 감지하고 차단할 수 있다. 그러나 노드가 고의로 시스템의 보장을 무너뜨리려한다면 가짜 펜싱 토큰을 포함한 메시지를 보내기만 하면 된다.\n지금까지는 노드들이 신뢰성은 없지만 응답한다면 진실만 말한다고 가정했다. 그러나 분산 시스템 문제는 노드가 거짓말을 할지도 모른다는 위험이 있다면 훨씬 더 어려워진다. 이런 동작을 비잔틴 결함(Byzantine fault)이라고 하며 이렇게 신뢰할 수 없는 환경에서 합의에 도달하는 문제를 비잔틴 장군 문제(Byzantine Generals Problem)라고 한다.\n일부 노드가 오작동하고 프로토콜을 준수하지 않고나 악의적인 공격자가 네트워크를 방해하더라도 시스템이 계속 올바르게 동작한다면 이 시스템은 비잔틴 내결함성(Byzantine fault tolerant)을 지닌다. 이런 관심사는 특정 환경에서 유의미하다. (예를 들어, 방사선 노출이 큰 항공우주 산업이나 비트코인 같은 분야)\n그러나 우리가 살펴보는 시스템의 종류는 보통 비잔틴 결함이 없다고 가정할 수 있다. 그리고 대부분의 서버 측 데이터 시스템에서 비잔틴 내결함성 솔류션을 배치하는 것은 비용이 커서 실용적이지 않다. 대신 보통 중앙 권한을 가지고 최종 사용자의 입력을 확인(input validation)하고 살균(sanitization, 잠재적으로 위험할 수 있는 입력값을 유효한 값으로 치환)하고 출력 이스케이핑(output escaping) 등으로 SQL injection이나 크로스 사이트 스크립팅 등의 공격을 막는다.\n약한 형태의 거짓말\n하드웨어 문제, 소프트웨어 버그, 잘못된 설정으로 인한 유효하지 않은 메시지 등 의도치 않은 약한 형태의 거짓말로부터 보호해주느느 메커니즘을 추가하는 것은 가치가 있다.\nTCP 내장 체크섬만 믿지 말고 체크섬을 직접 애플리케이션에 넣기\n사용자 입력 살균하기\nNTP 여러 서버 주소 설정하기\n시스템 모델과 현실\n알고리즘은 그들이 실행되는 하드웨어와 소프트웨어 설정의 세부 사항에 너무 심하게 의존하지 않는 방식으로 작성해야 한다. 그러려면 시스템에서 발생할 것으로 예상되는 결함의 종류를 어떻게든 정형화해야 한다. 시스템 모델을 정의해서 정형화하는데, 시스템 모델은 알고리즘이 가정하는 것을 기술한 추상화다.\n타이밍 가정에 대한 흔히 사용하는 세 가지 시스템 모델\n동기식 모델: 네트워크 지연, 프로세스 중단 등 모두 제한이 있다고 가정\n부분 동기식 모델: 대부분의 시간에는 동기식 시스템처럼 동작하지만 때때로 네트워크 지연 등 한계치를 초과한다고 가정. 많은 시스템에서 현실적인 모델\n비동기식 모델: 이 모델에서 알고리즘은 타이밍에 대한 어떤 가정도 할 수 없다.\n노드 장애를 고려하는 세가지 시스템 모델\n죽으면 중단(crash-stop)하는 결함\n죽으면 복구하는(carsh-recovery) 결함\n비잔틴 결함\n현실 시스템을 모델링하는데는 죽으면 복구하는 결함을 지닌 부분 동기식 모델이 일반적으로 가장 유용한 모델이다.\n알고리즘의 안정성과 활동성\n상황을 분명히 하기 위해 두 가지 다른 종류의 속성, 안정성(safety)과 활동성(liveness)을 구별할 필요가 있다.\n안정성은 흔히 비공식적으로 나쁜 일은 일어나지 않는다라고, 활동성은 좋은 일은 결국 일어난다라고 정의한다. 안전성 속성이 위반되면 그 속성이 깨진 특정 시점을 가리킬 수 있다. 안전성 속성이 위반된 후에는 그 위반을 취소할 수 없다. 활동성 속성은 어떤 시점을 정하지 못할 수 있지만, 항상 미래에 그 속성을 만족시킬 수 있다는 희망이 있다.\n분산 알고리즘은 시스템 모델의 모든 상황에서 안정성 속성이 항상 만족되기를 요구하는 게 일반적이다. 즉 모든 노드가 죽거나 네트워크 전체에 장애가 생기더라도 알고리즘은 잘못된 결과를 반환하지 않는다고 보장해야 한다.\n그러나 활동성 속성에 대해서는 경고를 하는 게 허용된다. 예를 들어 노드의 다수가 죽지 않고 네트워크가 중단으로부터 결국 복구됐을 때만 요청이 응답을 받아야 한다고 말할 수 있다.\n시스템 모델을 현실 세계에 대응시키기\n현업에서 알고리즘을 구현할 때 현실의 지저분한 사실들이 시스템 모델은 현실의 단순화된 추상화라는 게 명백해진다.\n알고리즘을 이론적으로 설명할 때는 그냥 어떤 일이 일어나지 않는다고 가정할 수 있다. 그러나 실제 구현에는 여전히 불가능하다고 가정했던 일이 발생하는 경우를 처리하는 코드를 포함시켜야 할 수도 있다.\n이론적인 추상 시스템 모델은 현실 시스템의 복잡함에서 우리가 추론할 수 있는 관리 가능한 결함의 집합을 뽑아내서, 문제를 이해하고 체계적으로 해결하려고 노력할 수 있게 하는 데 도움이 된다.\n알고리즘이 올바르다고 증명됐더라도 반드시 현실 시스템에서의 구현도 언제나 올바르게 동작한다는 뜻은 아니다. 그렇지만 알고리즘의 증명은 아주 좋은 첫걸음이다.\nReference\n데이터 중심 애플리케이션 설계 8장",
        "guid": "https://velog.io/@ahngj96/%EC%A7%80%EC%8B%9D-%EC%A7%84%EC%8B%A4-%EA%B7%B8%EB%A6%AC%EA%B3%A0-%EA%B1%B0%EC%A7%93%EB%A7%90",
        "isoDate": "2024-07-11T18:12:39.000Z"
      },
      {
        "title": "신뢰성 없는 시계",
        "link": "https://velog.io/@ahngj96/%EC%8B%A0%EB%A2%B0%EC%84%B1-%EC%97%86%EB%8A%94-%EC%8B%9C%EA%B3%84-2",
        "pubDate": "Thu, 11 Jul 2024 15:44:45 GMT",
        "content": "<p>시계와 시간은 중요하다. 애플리케이션은 다양한 방식으로 시계에 의존하는데 대표적으로 <strong>지속 시간 측정</strong>과 <strong>특정 시점 기술</strong>에 의존한다. 분산 시스템에서는 통신이 즉각적이지 않으므로 시간은 다루기 까다롭다. 네트워크 지연의 변동성 때문에 어떤 일이 발생한 순서를 알아내기 어렵다. 게다가 네트워크에 있는 개별 장비는 자신의 시계(보통 수정 발진기, quartz crystal oscillator)를 가지고 있다. 각자 가지고 있는 시계는 완벽하지 않아서 다른 장비보다 약간 빠를 수도 느릴 수도 있다. 시간을 어느정도 동기화 할 수 있는데 NTP(Network Time Protocol)를 사용하는 것이다.</p>\n<h1 id=\"단조-시계-대-일-기준-시계\">단조 시계 대 일 기준 시계</h1>\n<p>각각 일 기준 시계와 단조 시계는 Java 의 <a href=\"https://www.baeldung.com/java-system-currenttimemillis-vs-system-nanotime\"><code>System.currentTimeMillis()</code>와 <code>System.nanoTime()</code></a>로 설명할 수 있다. 간단히 차이를 보자면 <strong>일 기준 시계는 시스템 시각이며 NTP와 동기화</strong>되어 만약 로컬 시계가 NTP 시계보다 빠르다면 동기화되면서 시간이 거꾸로 흐르는 것처럼 착각할 수 있다. <strong>단조 시계는 이름에서 알 수 있듯 항상 시간이 앞으로만 흐른다.</strong></p>\n<p>NTP는 컴퓨터의 로컬 시계가 NTP 서버보다 빠르거나 느리다는 것을 발견하면 <strong>단조 시계가 진행하는 진도수를 조정</strong>할 수도 있다(시계를 돌린다(slewing)고 한다). 기본적으로 NTP는 시계 속도를 0.05%까지 올리거나 내리는 것을 허용하지만 단조 시계가 앞이나 뒤로 뛰게 할 수는 없다.</p>\n<p>분산 시스템에서 경과 시간을 재는 데 단조 시계를 쓰는 것은 일반적으로 괜찮다. 다른 노드의 시계 사이에 동기화가 돼야 한다는 가정이 없고 측정이 약간 부정확해도 민감하지 않기 때문이다.</p>\n<h1 id=\"시계-동기화와-정확도\">시계 동기화와 정확도</h1>\n<p>단조 시계는 동기화가 필요 없지만 일 기준 시계는 NTP 서버나 다른 외부 시간 출처에 맞춰 설정돼야 유용하다. 유감스럽게도 시계가 정확한 시간을 알려주게 하는 방법은 기대만큼 신회성이 있거나 정확하지 않다. 하드웨어 시계와 NTP는 변덕스러운 짐승이 될 수 있다.</p>\n<ul>\n<li>컴퓨터의 수정 시계는 드리프트 현상(더 빠르거나 느리게 실행)으로 인하여 정확하지 않다. 시계 드리프트는 장비의 온도에 따라 변한다.</li>\n<li>컴퓨터 시계가 NTP 서버와 너무 많은 차이가 나면 동기화가 거부되거나 로컬 시계가 강제로 리셋될 수 있다. 리셋 전후로 시간을 관찰한 애플리케이션은 시간이 건너뛰어지는 상황을 보게 된다.</li>\n<li>방화벽으로 인하여 잘못된 설정이 알려지지 않을 수 있다.</li>\n<li>NTP 동기화도 네트워크 지연으로 인한 정확도에 한계가 있다.</li>\n<li>어떤 NTP 서버들은 잘못된 시간을 가지고 있기도 하는데, NTP 클라이언트는 여러 서버에 질의를 보내고 다른 것과 큰 차이가 나는 값을 무시하기에 상당히 견고하다. 그럼에도 다소 걱정스럽다.</li>\n<li>윤초가 발생하면 1분의 길이가 59초나 61초가 되어 윤초를 고려하지 않고 설계된 시스템에서는 시간에 관한 가정이 엉망이 돼 버린다. 윤초를 처리하는 최선의 방법은 윤초 조정을 하루에 걸쳐서 서서히 수행함으로써 NTP 서버가 거짓맣을 하게 하는 것일 수도 있다.(문지름(smearing)이라고 부른다)</li>\n<li>가상 장비에서 하드웨어 시계는 가상화돼서 정확한 시간 엄수가 필요한 애플리케이션에게 추가적인 어려움이 생긴다. CPU 코어가 가상 장비 사이에 공유될 때 각 VM은 다른 VM이 실행되는 동안 수십 밀리초 동안 멈춘다. 애플리케이션 관점에서 이 중단은 시계가 갑자기 앞으로 뛰는 문제로 나타난다.</li>\n<li>완전히 제어할 수 없는 장치에서 소프트웨어를 실행하면 그 장치의 하드웨어 시계를 전혀 믿을 수 없을 것이다.</li>\n</ul>\n<p>시계 정확도를 높이기 위해 많은 자원을 투입할 수 있다면 시계 정확도를 매우 높이는 것도 가능하다. GPS 수신기, 정밀 시간 프로토콜과 세심한 배포 및 모니터링으로 다성할 수 있다. 다만 상당한 노력과 전문 기술이 필요하다.</p>\n<h1 id=\"동기화된-시계에-의존하기\">동기화된 시계에 의존하기</h1>\n<p>시계는 간단하고 사용하기 쉬워 보이지만 함정이 있다는 것이 문제다. 하루는 정확히 86,400초가 아닐 수도 있고, 일 기준 시계의 시간이 거꾸로 갈 수도 있으며, 노드의 시간이 다른 노드의 시간과 차이가 많이 날 수도 있다. 대부분의 시간에 아주 잘 동작하지만 견고한 소프트웨어는 잘못된 시계에 대비할 필요가 있다.</p>\n<p>한 가지 문제는 시계가 잘못된다는 것을 눈치채지 못하기 쉽다는 것이다. 장비의 수정 시계에 결함이 있거나 NTP 클라이언트가 잘못 설정됐다면 시계는 드리프트가 생겨서 점점 실제 시간으로부터 멀어져 가지만 대부분이 잘 동작하는 것처럼 보인다. 따라서 동기화된 시계가 필요한 소프트웨어를 사용한다면 필수적으로 모든 장비 사이의 시계 차이를 조심스럽게 모니터링해야 한다. <strong>다른 노드와 시계가 너무 차이나는 노드는 죽은 것으로 선언되고 클러스터에서 제거</strong>돼야 한다. 이런 모니터링을 하면 너무 큰 피해를 입기 전에 고장 난 시계를 알아채도록 보장할 수 있다.</p>\n<h2 id=\"이벤트-순서화용-타임스탬프\">이벤트 순서화용 타임스탬프</h2>\n<p>시계에 의존하고 싶은 유혹이 들지만 위험한 특정 상황 하나를 고려해 보자. 여러 노드에 걸친 이벤트들의 순서를 정하는 문제다. 예를 들어 두 클라이언트가 분산 데이터베이스에 쓰면 누가 먼저 쓰게 될까? 누가 쓴 게 더 최근 것이 될까?</p>\n<p><img src=\"https://velog.velcdn.com/images/ahngj96/post/57d8e5ac-8d03-4db1-90d7-03dadf4d7faa/image.png\" alt=\"\">\n<a href=\"https://azderica.github.io/til/docs/data/designing-data-intensive-applications/ch8/\">이미지 출처</a></p>\n<p>다중 리더 복제 시스템에서 A가 실제로 더 먼저 작성하고 나중에 B가 작성했음에도 최종 쓰기 승리(last write wins, LWW)를 A가 가져가는 상황이 발생할 수 있다. LWW는 근본적으로 순차적인 쓰기가 빠른 시간 내에 연속으로 실행되는 것과 진짜 동시에 쓰기가 실행되는 것을 구별할 수 없다. 인과성 위반을 막으려면 <a href=\"https://en.wikipedia.org/wiki/Version_vector\">버전 벡터</a>와 같은 부가적인 인과성 추적 매커니즘이 필요하다.</p>\n<p>따라서 가장 최근 값을 유지하고 다른 것들을 버림으로써 충돌을 해소하고 싶은 유혹이 들더라도 <strong>최근의 정의는 로컬 일 기준 시계에 의존하며 그 시계는 틀릴 수도 있다</strong>는 것을 아는 게 중요하다.</p>\n<p>논리적 시계는 증가하는 카운터를 기반으로 하며 이벤트 순서화의 안전한 대안이다. 논리적 시계는 일 기준 시간이나 경과한 초 수를 측정하지 않고 이벤트의 상대적인 순서만 측정한다. 반대로 일 기준 시계와 단조 시계는 실제 경과 시간을 측정하며 물리적 시계라고도 한다.</p>\n<h2 id=\"시계-읽기는-신뢰-구간이-있다\">시계 읽기는 신뢰 구간이 있다</h2>\n<p>시계 읽기를 어떤 시점으로 생각하는 것은 옳지 않다. 어떤 신뢰 구간에 속하는 시간의 범위로 읽는 게 나을 것이다. 예를 들어, 스패너에 있는 구글 트루타임 API는 로컬 시계의 신뢰 구간을 명시적으로 보고한다. 이 API에 현재 시간을 요청하면 가능한 타임스탬프 범위 중 가장 이른 것과 가장 늦은 것을 가리키는 두 개의 값을 받는다. 시계는 불확실성 계산을 기반으로 실제 현재 시간이 그 구간 안의 어딘가에 있다는 것을 안다.</p>\n<h2 id=\"전역-스냅숏용-동기화된-시계\">전역 스냅숏용 동기화된 시계</h2>\n<p>DB에서 스냅숏 격리를 달성하기 위해서는 가장 흔한 방법은 단조 증가하는 트랜잭션 아이디이다. 그러나 분산 환경에서는 전역 단조 증가 트랜잭션 아이디를 생성하기 힘들다. 트랜잭션 아이디는 인과성을 반영해야 한다. 트랜잭션 A가 쓴 값을 트랜잭션 B가 읽는다면 B가 A보다 높은 높은 트랜잭션 아이디를 가져야 한다. 그렇지 않으면 스냅숏이 일관성을 지니지 못한다.</p>\n<p>동기화된 일 기준 시계의 타임스탬프를 트랜잭션 아이디로 쓸 수 있을까? 스패너의 경우 타임스탬프를 가지고 여러 데이터센터에 걸쳐서 스냅숏 격리를 구현한다. 스패너의 스냅숏 구현은 트루타입 API가 보고한 시계 신뢰 구간을 사용하여 다음과 같은 관찰을 기반으로 한다.</p>\n<blockquote>\n</blockquote>\n<ul>\n<li>A: [ early-A, last-A ]</li>\n<li>B: [ early-B, last-B ]</li>\n</ul>\n<p>위 와같은 두 개의 신회 구간이 있을 때,</p>\n<blockquote>\n<p>early-A -&gt; last-A -&gt; early-B -&gt;  last-B</p>\n</blockquote>\n<p>이렇게 두 구간이 겹치지 않는다면 분명히 B가 A보다 나중에 실행됐다. 구간이 겹칠 때만 A와 B가 어떤 순서로 실행됐는지 확신할 수 없다.</p>\n<p>분산 트랜잭션 시맨틱용으로 시계 동기화를 쓰는 것은 흥미롭지만 구글 이외에는 주류 데이터베이스에서 구현한 사례가 없다.</p>\n<h1 id=\"프로세스-중단\">프로세스 중단</h1>\n<p>분산 시스템에서 시계를 위험하게 사용하는 경우가 두 가지있다.</p>\n<ol>\n<li>어떤 권한의 만료 체크를 동기화된 시계에 의존하는 것이다. 동기화된 시계의 동기화가 깨진다면 의도하지 않은 동작을 하게 될 수 있다.</li>\n<li>어떤 권한의 만료를 체크한 이후에 스레드가 오랜 시간 멈춘 것이다. 재시작됐을 때는 이미 만료된 권한이지만 만료된지 모르고 안전하지 않은 동작을 할 수 있다.</li>\n</ol>\n<p>스레드가 아주 오랫동안 멈추는 경우는 다음과 같다.</p>\n<ul>\n<li>JVM 등의 GC로 인한 stop-the-world</li>\n<li>가상 환경에서 가상 장비를 멈췄다 재실행</li>\n<li>노트북 덮개를 닫는 경우</li>\n<li>운영체제가 다른 스레드로 컨텍스트 스위치하거나 하이퍼바이저가 다른 가상 장비로 스위치되는 것. 가상 장비의 경우 다른 가상 장비에서 소비된 CPU 시간을 스틸 타임(steal time)이라고 한다.</li>\n<li>애플리케이션이 동기식으로 디스크에 접근하면 스레드가 느린 디스크 I/O 연산을 완료되기를 기다리느라 중단. 예를 들어 자바 클래스로더는 클래스 파일이 처음 사용될 때 지연로딩하는데, 이는 프로그램 실행 중 언제라도 일어날 수 있다.</li>\n<li>운영 체제의 디스크로 스왑(페이징) 설정. 극단적인 환경에서는 운영체제가 페이지를 메모리 안팎으로 스와핑하느라 대부분의 시간을 쓰고 실제 작업은 거의 못할 수도 있다. 이를 스래싱(thrashing)이라고 한다.</li>\n<li>유닉스에서 <code>SIGSTOP</code> 시그널. <code>ctrl + z</code>를 눌러 신호를 보낼 수 있다. 이 신호는 프로세스가 <code>SIGCONT</code> 신호로 재개되어 중단됐던 지점에서 다시 실행될 때까지 CPU 사이클을 더 이상 할당받지 못하게 한다.</li>\n</ul>\n<p>단일 장비에서 다중 스레드 코드를 작성할 때 그 코드를 thread-safe 하게 만들 수 있는 좋은 도구들이 있다. 뮤텍스, 세마포어, atomic, lock-free 자료구조, blocking queue 등이다. 불행하게도 이런 도구들은 분산 시스템용으로 바로 변형할 수 없다. 분산 시스템은 공유 메모리가 없고 단지 신뢰성 없는 네트워크를 통해 메시지를 보낼 수만 있기 때문이다.</p>\n<p>분산 시스템의 노드는 어느 시점에 실행이 상당한 시간 동안 멈출 수 있다고 가정해야 한다. 심지어 함수 중간에서 멈출 수도 있다. 그렇게 멈춰 있는 동안 외부 세계는 계속 움직이며 멈춘 노드가 응답하지 않아서 죽었다고 선언할 수도 있다. 결국 멈춘 노드는 다시 실행되겠지만 얼마 후 시계를 확인할 때까지 잠들었다는 것을 알아채지 못한다.</p>\n<h2 id=\"응답-시간-보장\">응답 시간 보장</h2>\n<p>많은 프로그래밍 언어와 운영체제에서 스레드와 프로세스는 기약 없는 시간동안 중단될 수 있다. 충분히 열심히 노력하면 중단의 원인을 제거할 수 있다.</p>\n<p>어떤 소프트웨어는 명시된 시간 안에 응답하는 데 실패하면 심각한 손상을 유발할 수 있는 환경에서 실행된다. 항공기, 로켓, 로봇, 자동차, 그리고 다른 물리적 물체를 제어하는 컴퓨터는 그들의 센서 입력에 빠르고 예측 가능하게 응답해야 한다. 이런 시스템에서는 소프트웨어가 응답해야 하는 데드라인이 명시된다. 데드라인을 만족시키지 못하면 전체 시스템의 장애를 유발할 수 있다. 이를 엄격한 실시간 시스템(hard real-time)이라고 한다.</p>\n<p>대부분의 서버측 데이터 처리 시스템에게 실시간 보장은 전혀 경제적이지도, 적절하지도 않다. 결과적으로 이런 시스템들은 비실시간 환경에서 운영될 때 발생하는 중단과 시계 불안적으로부터 고통받을 수밖에 없다.</p>\n<h2 id=\"가비지-컬렉션의-영향을-제한하기\">가비지 컬렉션의 영향을 제한하기</h2>\n<p>몇 가지 아이디어들이 있다.</p>\n<ul>\n<li>GC 중단을 노드가 잠시 동안 계획적으로 중단되는 것으로 간주하고 노드가 가비지 컬렉션을 하는 동안 클라이언트로부터의 요청을 다른 노드들이 처리하게 하는 것이다.</li>\n<li>수명이 짧은 객체만 GC를 사용하고 수명이 긴 객체의 전체 GC가 필요할 만큼 객체가 쌓이기 전에 주기적으로 프로세스를 재시작하는 것이다. 한 번에 노드 하나씩 재시작하도록 하고 순회식 업그레이드를 할 때 처럼 계획된 재시작을 하기 전에 트래픽을 다른 노드로 옮길 수 있다.</li>\n</ul>\n<p>이런 조치가 GC 중단을 완전히 막을 수는 없지만 애플리케이션에 미치는 영향은 유용하게 줄일 수 있다.</p>\n<h1 id=\"reference\">Reference</h1>\n<p>데이터 중심 애플리케이션 설계 8장</p>\n",
        "contentSnippet": "시계와 시간은 중요하다. 애플리케이션은 다양한 방식으로 시계에 의존하는데 대표적으로 지속 시간 측정과 특정 시점 기술에 의존한다. 분산 시스템에서는 통신이 즉각적이지 않으므로 시간은 다루기 까다롭다. 네트워크 지연의 변동성 때문에 어떤 일이 발생한 순서를 알아내기 어렵다. 게다가 네트워크에 있는 개별 장비는 자신의 시계(보통 수정 발진기, quartz crystal oscillator)를 가지고 있다. 각자 가지고 있는 시계는 완벽하지 않아서 다른 장비보다 약간 빠를 수도 느릴 수도 있다. 시간을 어느정도 동기화 할 수 있는데 NTP(Network Time Protocol)를 사용하는 것이다.\n단조 시계 대 일 기준 시계\n각각 일 기준 시계와 단조 시계는 Java 의 System.currentTimeMillis()와 System.nanoTime()로 설명할 수 있다. 간단히 차이를 보자면 일 기준 시계는 시스템 시각이며 NTP와 동기화되어 만약 로컬 시계가 NTP 시계보다 빠르다면 동기화되면서 시간이 거꾸로 흐르는 것처럼 착각할 수 있다. 단조 시계는 이름에서 알 수 있듯 항상 시간이 앞으로만 흐른다.\nNTP는 컴퓨터의 로컬 시계가 NTP 서버보다 빠르거나 느리다는 것을 발견하면 단조 시계가 진행하는 진도수를 조정할 수도 있다(시계를 돌린다(slewing)고 한다). 기본적으로 NTP는 시계 속도를 0.05%까지 올리거나 내리는 것을 허용하지만 단조 시계가 앞이나 뒤로 뛰게 할 수는 없다.\n분산 시스템에서 경과 시간을 재는 데 단조 시계를 쓰는 것은 일반적으로 괜찮다. 다른 노드의 시계 사이에 동기화가 돼야 한다는 가정이 없고 측정이 약간 부정확해도 민감하지 않기 때문이다.\n시계 동기화와 정확도\n단조 시계는 동기화가 필요 없지만 일 기준 시계는 NTP 서버나 다른 외부 시간 출처에 맞춰 설정돼야 유용하다. 유감스럽게도 시계가 정확한 시간을 알려주게 하는 방법은 기대만큼 신회성이 있거나 정확하지 않다. 하드웨어 시계와 NTP는 변덕스러운 짐승이 될 수 있다.\n컴퓨터의 수정 시계는 드리프트 현상(더 빠르거나 느리게 실행)으로 인하여 정확하지 않다. 시계 드리프트는 장비의 온도에 따라 변한다.\n컴퓨터 시계가 NTP 서버와 너무 많은 차이가 나면 동기화가 거부되거나 로컬 시계가 강제로 리셋될 수 있다. 리셋 전후로 시간을 관찰한 애플리케이션은 시간이 건너뛰어지는 상황을 보게 된다.\n방화벽으로 인하여 잘못된 설정이 알려지지 않을 수 있다.\nNTP 동기화도 네트워크 지연으로 인한 정확도에 한계가 있다.\n어떤 NTP 서버들은 잘못된 시간을 가지고 있기도 하는데, NTP 클라이언트는 여러 서버에 질의를 보내고 다른 것과 큰 차이가 나는 값을 무시하기에 상당히 견고하다. 그럼에도 다소 걱정스럽다.\n윤초가 발생하면 1분의 길이가 59초나 61초가 되어 윤초를 고려하지 않고 설계된 시스템에서는 시간에 관한 가정이 엉망이 돼 버린다. 윤초를 처리하는 최선의 방법은 윤초 조정을 하루에 걸쳐서 서서히 수행함으로써 NTP 서버가 거짓맣을 하게 하는 것일 수도 있다.(문지름(smearing)이라고 부른다)\n가상 장비에서 하드웨어 시계는 가상화돼서 정확한 시간 엄수가 필요한 애플리케이션에게 추가적인 어려움이 생긴다. CPU 코어가 가상 장비 사이에 공유될 때 각 VM은 다른 VM이 실행되는 동안 수십 밀리초 동안 멈춘다. 애플리케이션 관점에서 이 중단은 시계가 갑자기 앞으로 뛰는 문제로 나타난다.\n완전히 제어할 수 없는 장치에서 소프트웨어를 실행하면 그 장치의 하드웨어 시계를 전혀 믿을 수 없을 것이다.\n시계 정확도를 높이기 위해 많은 자원을 투입할 수 있다면 시계 정확도를 매우 높이는 것도 가능하다. GPS 수신기, 정밀 시간 프로토콜과 세심한 배포 및 모니터링으로 다성할 수 있다. 다만 상당한 노력과 전문 기술이 필요하다.\n동기화된 시계에 의존하기\n시계는 간단하고 사용하기 쉬워 보이지만 함정이 있다는 것이 문제다. 하루는 정확히 86,400초가 아닐 수도 있고, 일 기준 시계의 시간이 거꾸로 갈 수도 있으며, 노드의 시간이 다른 노드의 시간과 차이가 많이 날 수도 있다. 대부분의 시간에 아주 잘 동작하지만 견고한 소프트웨어는 잘못된 시계에 대비할 필요가 있다.\n한 가지 문제는 시계가 잘못된다는 것을 눈치채지 못하기 쉽다는 것이다. 장비의 수정 시계에 결함이 있거나 NTP 클라이언트가 잘못 설정됐다면 시계는 드리프트가 생겨서 점점 실제 시간으로부터 멀어져 가지만 대부분이 잘 동작하는 것처럼 보인다. 따라서 동기화된 시계가 필요한 소프트웨어를 사용한다면 필수적으로 모든 장비 사이의 시계 차이를 조심스럽게 모니터링해야 한다. 다른 노드와 시계가 너무 차이나는 노드는 죽은 것으로 선언되고 클러스터에서 제거돼야 한다. 이런 모니터링을 하면 너무 큰 피해를 입기 전에 고장 난 시계를 알아채도록 보장할 수 있다.\n이벤트 순서화용 타임스탬프\n시계에 의존하고 싶은 유혹이 들지만 위험한 특정 상황 하나를 고려해 보자. 여러 노드에 걸친 이벤트들의 순서를 정하는 문제다. 예를 들어 두 클라이언트가 분산 데이터베이스에 쓰면 누가 먼저 쓰게 될까? 누가 쓴 게 더 최근 것이 될까?\n\n이미지 출처\n다중 리더 복제 시스템에서 A가 실제로 더 먼저 작성하고 나중에 B가 작성했음에도 최종 쓰기 승리(last write wins, LWW)를 A가 가져가는 상황이 발생할 수 있다. LWW는 근본적으로 순차적인 쓰기가 빠른 시간 내에 연속으로 실행되는 것과 진짜 동시에 쓰기가 실행되는 것을 구별할 수 없다. 인과성 위반을 막으려면 버전 벡터와 같은 부가적인 인과성 추적 매커니즘이 필요하다.\n따라서 가장 최근 값을 유지하고 다른 것들을 버림으로써 충돌을 해소하고 싶은 유혹이 들더라도 최근의 정의는 로컬 일 기준 시계에 의존하며 그 시계는 틀릴 수도 있다는 것을 아는 게 중요하다.\n논리적 시계는 증가하는 카운터를 기반으로 하며 이벤트 순서화의 안전한 대안이다. 논리적 시계는 일 기준 시간이나 경과한 초 수를 측정하지 않고 이벤트의 상대적인 순서만 측정한다. 반대로 일 기준 시계와 단조 시계는 실제 경과 시간을 측정하며 물리적 시계라고도 한다.\n시계 읽기는 신뢰 구간이 있다\n시계 읽기를 어떤 시점으로 생각하는 것은 옳지 않다. 어떤 신뢰 구간에 속하는 시간의 범위로 읽는 게 나을 것이다. 예를 들어, 스패너에 있는 구글 트루타임 API는 로컬 시계의 신뢰 구간을 명시적으로 보고한다. 이 API에 현재 시간을 요청하면 가능한 타임스탬프 범위 중 가장 이른 것과 가장 늦은 것을 가리키는 두 개의 값을 받는다. 시계는 불확실성 계산을 기반으로 실제 현재 시간이 그 구간 안의 어딘가에 있다는 것을 안다.\n전역 스냅숏용 동기화된 시계\nDB에서 스냅숏 격리를 달성하기 위해서는 가장 흔한 방법은 단조 증가하는 트랜잭션 아이디이다. 그러나 분산 환경에서는 전역 단조 증가 트랜잭션 아이디를 생성하기 힘들다. 트랜잭션 아이디는 인과성을 반영해야 한다. 트랜잭션 A가 쓴 값을 트랜잭션 B가 읽는다면 B가 A보다 높은 높은 트랜잭션 아이디를 가져야 한다. 그렇지 않으면 스냅숏이 일관성을 지니지 못한다.\n동기화된 일 기준 시계의 타임스탬프를 트랜잭션 아이디로 쓸 수 있을까? 스패너의 경우 타임스탬프를 가지고 여러 데이터센터에 걸쳐서 스냅숏 격리를 구현한다. 스패너의 스냅숏 구현은 트루타입 API가 보고한 시계 신뢰 구간을 사용하여 다음과 같은 관찰을 기반으로 한다.\nA: [ early-A, last-A ]\nB: [ early-B, last-B ]\n위 와같은 두 개의 신회 구간이 있을 때,\nearly-A -> last-A -> early-B ->  last-B\n이렇게 두 구간이 겹치지 않는다면 분명히 B가 A보다 나중에 실행됐다. 구간이 겹칠 때만 A와 B가 어떤 순서로 실행됐는지 확신할 수 없다.\n분산 트랜잭션 시맨틱용으로 시계 동기화를 쓰는 것은 흥미롭지만 구글 이외에는 주류 데이터베이스에서 구현한 사례가 없다.\n프로세스 중단\n분산 시스템에서 시계를 위험하게 사용하는 경우가 두 가지있다.\n어떤 권한의 만료 체크를 동기화된 시계에 의존하는 것이다. 동기화된 시계의 동기화가 깨진다면 의도하지 않은 동작을 하게 될 수 있다.\n어떤 권한의 만료를 체크한 이후에 스레드가 오랜 시간 멈춘 것이다. 재시작됐을 때는 이미 만료된 권한이지만 만료된지 모르고 안전하지 않은 동작을 할 수 있다.\n스레드가 아주 오랫동안 멈추는 경우는 다음과 같다.\nJVM 등의 GC로 인한 stop-the-world\n가상 환경에서 가상 장비를 멈췄다 재실행\n노트북 덮개를 닫는 경우\n운영체제가 다른 스레드로 컨텍스트 스위치하거나 하이퍼바이저가 다른 가상 장비로 스위치되는 것. 가상 장비의 경우 다른 가상 장비에서 소비된 CPU 시간을 스틸 타임(steal time)이라고 한다.\n애플리케이션이 동기식으로 디스크에 접근하면 스레드가 느린 디스크 I/O 연산을 완료되기를 기다리느라 중단. 예를 들어 자바 클래스로더는 클래스 파일이 처음 사용될 때 지연로딩하는데, 이는 프로그램 실행 중 언제라도 일어날 수 있다.\n운영 체제의 디스크로 스왑(페이징) 설정. 극단적인 환경에서는 운영체제가 페이지를 메모리 안팎으로 스와핑하느라 대부분의 시간을 쓰고 실제 작업은 거의 못할 수도 있다. 이를 스래싱(thrashing)이라고 한다.\n유닉스에서 SIGSTOP 시그널. ctrl + z를 눌러 신호를 보낼 수 있다. 이 신호는 프로세스가 SIGCONT 신호로 재개되어 중단됐던 지점에서 다시 실행될 때까지 CPU 사이클을 더 이상 할당받지 못하게 한다.\n단일 장비에서 다중 스레드 코드를 작성할 때 그 코드를 thread-safe 하게 만들 수 있는 좋은 도구들이 있다. 뮤텍스, 세마포어, atomic, lock-free 자료구조, blocking queue 등이다. 불행하게도 이런 도구들은 분산 시스템용으로 바로 변형할 수 없다. 분산 시스템은 공유 메모리가 없고 단지 신뢰성 없는 네트워크를 통해 메시지를 보낼 수만 있기 때문이다.\n분산 시스템의 노드는 어느 시점에 실행이 상당한 시간 동안 멈출 수 있다고 가정해야 한다. 심지어 함수 중간에서 멈출 수도 있다. 그렇게 멈춰 있는 동안 외부 세계는 계속 움직이며 멈춘 노드가 응답하지 않아서 죽었다고 선언할 수도 있다. 결국 멈춘 노드는 다시 실행되겠지만 얼마 후 시계를 확인할 때까지 잠들었다는 것을 알아채지 못한다.\n응답 시간 보장\n많은 프로그래밍 언어와 운영체제에서 스레드와 프로세스는 기약 없는 시간동안 중단될 수 있다. 충분히 열심히 노력하면 중단의 원인을 제거할 수 있다.\n어떤 소프트웨어는 명시된 시간 안에 응답하는 데 실패하면 심각한 손상을 유발할 수 있는 환경에서 실행된다. 항공기, 로켓, 로봇, 자동차, 그리고 다른 물리적 물체를 제어하는 컴퓨터는 그들의 센서 입력에 빠르고 예측 가능하게 응답해야 한다. 이런 시스템에서는 소프트웨어가 응답해야 하는 데드라인이 명시된다. 데드라인을 만족시키지 못하면 전체 시스템의 장애를 유발할 수 있다. 이를 엄격한 실시간 시스템(hard real-time)이라고 한다.\n대부분의 서버측 데이터 처리 시스템에게 실시간 보장은 전혀 경제적이지도, 적절하지도 않다. 결과적으로 이런 시스템들은 비실시간 환경에서 운영될 때 발생하는 중단과 시계 불안적으로부터 고통받을 수밖에 없다.\n가비지 컬렉션의 영향을 제한하기\n몇 가지 아이디어들이 있다.\nGC 중단을 노드가 잠시 동안 계획적으로 중단되는 것으로 간주하고 노드가 가비지 컬렉션을 하는 동안 클라이언트로부터의 요청을 다른 노드들이 처리하게 하는 것이다.\n수명이 짧은 객체만 GC를 사용하고 수명이 긴 객체의 전체 GC가 필요할 만큼 객체가 쌓이기 전에 주기적으로 프로세스를 재시작하는 것이다. 한 번에 노드 하나씩 재시작하도록 하고 순회식 업그레이드를 할 때 처럼 계획된 재시작을 하기 전에 트래픽을 다른 노드로 옮길 수 있다.\n이런 조치가 GC 중단을 완전히 막을 수는 없지만 애플리케이션에 미치는 영향은 유용하게 줄일 수 있다.\nReference\n데이터 중심 애플리케이션 설계 8장",
        "guid": "https://velog.io/@ahngj96/%EC%8B%A0%EB%A2%B0%EC%84%B1-%EC%97%86%EB%8A%94-%EC%8B%9C%EA%B3%84-2",
        "isoDate": "2024-07-11T15:44:45.000Z"
      },
      {
        "title": "AIX 환경에서 동작하는 상태 수집기가 필요해요",
        "link": "https://velog.io/@ahngj96/AIX-%ED%99%98%EA%B2%BD%EC%97%90%EC%84%9C-%EB%8F%99%EC%9E%91%ED%95%98%EB%8A%94-%EC%88%98%EC%A7%91%EA%B8%B0%EA%B0%80-%ED%95%84%EC%9A%94%ED%95%B4%EC%9A%94",
        "pubDate": "Sat, 06 Jul 2024 17:09:18 GMT",
        "content": "<h1 id=\"aix-환경에서-동작하는-상태-수집기가-필요해요\">AIX 환경에서 동작하는 상태 수집기가 필요해요</h1>\n<p>Tibero를 모니터링하는 제품인 만큼 기존 Tibero가 배포된 머신에 수집기 바이너리를 배포하여 실행시키고 있었다. 지금까지 AIX 환경에 바이너리를 배포한 경험이 없어서 단지 Unix 계열이라는 점만 믿고, C++ 빌드 다 되겠지라는 안일한 생각으로 빌드를 시도하였는데 생각보다 빌드가 번거로웠다(<a href=\"https://www.ibm.com/docs/en/xl-c-and-cpp-aix/16.1?topic=migration-comparison-between-xl-based-clang-based-front-ends\">AIX 7.1에서 xlc 16.1 버전이 c++11를 부분지원해서 xlclang++로 빌드 시도</a>). 빌드는 어찌저찌 겨우겨우 해냈지만 결국 실행을 실패하였다.</p>\n<ul>\n<li>C++11</li>\n<li>Boost 1.78</li>\n<li>Avro 1.11.0</li>\n</ul>\n<p>위 C++11 스펙에서 Boost와 Avro 라이브러리를 빌드하여 수집기 바이너리에 링킹하여 빌드하고 실행하면 되는 것이었는데, 어떻게 어떻게 빌드는 성공하였다. 그런데 <strong>실행을 하면 바로 죽는 것 아니겠는가.</strong> <code>dbx</code> 명령어로 확인해보니 첫 <code>main</code> 함수 들어가기도 전에 Boost 1.78 asio 라이브러리를 로드하다 죽는 것이었다. Boost 1.78 코드를 보고 고치자니 여기서부터는 더이상 유지보수가 불가능한 수준일 수 있겠다는 생각이 들어 AIX 환경 전용으로 아예 새로 개발하는 것이 좋을 것같다고 보고하였다.</p>\n<h1 id=\"새로-만드는-것-ok-어떤-언어로\">새로 만드는 것 OK, 어떤 언어로?</h1>\n<p>결과적으로 새로 수집기를 <strong>동일한 로직 &amp; 다른 언어</strong>로 구현하는 것으로는 협의가 되었다. 물론 그전에 다른 분들의 검증은 거쳤다. 더욱 실력 좋은 분들이 빌드 및 실행을 시도하였으나 쉽게 빌드하고 실행하는 것은 힘들 것같다고 개발하고 유지보수해야하는 담당자인 내가 새로 구현해서 대응하자는 의견을 존중해주셨다.</p>\n<p>그래서 바로 생각나는 세 가지 언어(Java, Rust, Golang)를 검토하고 결국 <strong><code>Java</code></strong>를 선택하게 되었다.</p>\n<p>선택을 위해 오래 고민하지 않았다. 아주 현실적인 문제가 있었기 때문이다. 선택한 이유는 다음과 같다.</p>\n<ul>\n<li>새로 만드는 것으로 협의를 하기까지 너무 오랜 시간이 걸려 실제 구현하고 테스트하는데 시간이 2달 밖에 안남아서 모르는 언어를 시도할 수가 없었다(이게 가장 큰 문제.. 그래서 kotlin으로도 못했다).</li>\n<li>Golang, Rust는 결국 네이티브 바이너리를 만들어내는데, 계속 늘어나는 다양한 OS 환경별로 바이너리 만드는 것이 너무 머리아프다.</li>\n<li>C++에 비해 성능 느릴 수 있지만 그래도 Java JIT를 믿었다.</li>\n</ul>\n<p>Java 8을 선택하였는데 가장 많은 환경에서 쉽게 사용할 수 있는 것이 Java 8 이라 생각해서였다. 다양한 환경에 배포되는 바이너리인 만큼 최대한 많은 환경에서 동작하는게 맞을 것같아 일단 Java 8로 선택하였다. (나중에 알고보니 32bit 지원이 마지막이라는 것을 듣고 일단 Java 8로 하는 것이 다양한 환경에 배포되는 수집기로써 호환성 측면에서는 나은 선택일 수도 있었겠다 생각했다.)</p>\n<h1 id=\"구현하고보니-보이는-장단점\">구현하고보니 보이는 장단점</h1>\n<p>Java 8, Spring Boot, Netty, JNI 를 사용하여 구현하였다. 구현을 하고 보니 보이는 장단점들이 있었다.</p>\n<p>JNI가 필요한 이유는 관제 DB인 Tibero 데이터 수집하기 위해서 TIbero에서 제공해주는 C 라이브러리 함수를 사용해야하기 때문이다. 제공된 C 라이브러리를 통해서 조회한 데이터는 바로 Java 객체로 담아서 return하는 식이다.</p>\n<h2 id=\"장점\">장점</h2>\n<p>Java를 선택하게된 결정적인 이유가 구현 전보다 구현 후에 더 큰 장점으로 느껴졌다. 직접 구현하고 <strong>서로 다른 환경에서 서로 다른 JVM 위에서 같은 애플리케이션을 실행시켜보니 호환성과 편리함을 여실히 실감</strong>하게 되었다.</p>\n<p>그리고 다양한 라이브러리를 중앙 저장소인 <code>maven</code> 으로부터 쉽게 로드하여 사용할 수 있다는 것이 엄청난 장점이라는 것을 다시 한번 느꼈다. 유저가 많은 언어라는 것 자체가 확실히 장점으로 다가왔고, 그만큼 <strong>탄탄한 라이브러리들을 기반으로 편리하게 구현</strong>을 진행할 수 있었다.</p>\n<h2 id=\"단점\">단점</h2>\n<p>이렇게 쉽게 선택하고 구현을 마치고 보니 즉각적인 단점이 눈앞에 보였다.</p>\n<blockquote>\n<p><strong>Realtime 수집기인데 GC로 인해서 수집 주기가 지켜지지 못하고 뜰쑥날쑥한 현상이 간헐적으로 발생한 것이다</strong></p>\n</blockquote>\n<p>물론 현재는 1초가 최소 수집 주기이기에 실제 화면에서는 실시간이 기존 것과 큰 차이가 없다. 1초 안에는 대부분 데이터 수집하고 메시지를 만들어 serialize하고 TCP로 보내기는 하는 것이다.</p>\n<p>그래도 확실히 C++에 비해 Java가 느리고 <strong>GC로 인해 불안한 수집 주기</strong>를 가지게 된다는 것을 느끼게 되었다.</p>\n<h3 id=\"그래서-gc를-최대한-하지-않도록-코드-개선-진행중\">그래서 GC를 최대한 하지 않도록 코드 개선 진행중</h3>\n<p>GC가 최대한 발생하지 않도록 개선을 진행하고 있다.</p>\n<p>코드 레벨에서는 GC가 최대한 발생하지 않도록 새로 만드는 인스턴스들이 정말로 필요한지, 재사용할 수는 없는지 테스트하고 개선하는 중이다.</p>\n<p>JVM 메모리 설정으로도 GC를 덜 할 수 있도록 할 수 있을 것처럼 보인다. 다만 JVM 메모리 설정은 각 배포된 환경이 천차만별이기에 그 환경에 맞게 진행하는 것이 맞을 것으로 보인다.</p>\n",
        "contentSnippet": "AIX 환경에서 동작하는 상태 수집기가 필요해요\nTibero를 모니터링하는 제품인 만큼 기존 Tibero가 배포된 머신에 수집기 바이너리를 배포하여 실행시키고 있었다. 지금까지 AIX 환경에 바이너리를 배포한 경험이 없어서 단지 Unix 계열이라는 점만 믿고, C++ 빌드 다 되겠지라는 안일한 생각으로 빌드를 시도하였는데 생각보다 빌드가 번거로웠다(AIX 7.1에서 xlc 16.1 버전이 c++11를 부분지원해서 xlclang++로 빌드 시도). 빌드는 어찌저찌 겨우겨우 해냈지만 결국 실행을 실패하였다.\nC++11\nBoost 1.78\nAvro 1.11.0\n위 C++11 스펙에서 Boost와 Avro 라이브러리를 빌드하여 수집기 바이너리에 링킹하여 빌드하고 실행하면 되는 것이었는데, 어떻게 어떻게 빌드는 성공하였다. 그런데 실행을 하면 바로 죽는 것 아니겠는가. dbx 명령어로 확인해보니 첫 main 함수 들어가기도 전에 Boost 1.78 asio 라이브러리를 로드하다 죽는 것이었다. Boost 1.78 코드를 보고 고치자니 여기서부터는 더이상 유지보수가 불가능한 수준일 수 있겠다는 생각이 들어 AIX 환경 전용으로 아예 새로 개발하는 것이 좋을 것같다고 보고하였다.\n새로 만드는 것 OK, 어떤 언어로?\n결과적으로 새로 수집기를 동일한 로직 & 다른 언어로 구현하는 것으로는 협의가 되었다. 물론 그전에 다른 분들의 검증은 거쳤다. 더욱 실력 좋은 분들이 빌드 및 실행을 시도하였으나 쉽게 빌드하고 실행하는 것은 힘들 것같다고 개발하고 유지보수해야하는 담당자인 내가 새로 구현해서 대응하자는 의견을 존중해주셨다.\n그래서 바로 생각나는 세 가지 언어(Java, Rust, Golang)를 검토하고 결국 Java를 선택하게 되었다.\n선택을 위해 오래 고민하지 않았다. 아주 현실적인 문제가 있었기 때문이다. 선택한 이유는 다음과 같다.\n새로 만드는 것으로 협의를 하기까지 너무 오랜 시간이 걸려 실제 구현하고 테스트하는데 시간이 2달 밖에 안남아서 모르는 언어를 시도할 수가 없었다(이게 가장 큰 문제.. 그래서 kotlin으로도 못했다).\nGolang, Rust는 결국 네이티브 바이너리를 만들어내는데, 계속 늘어나는 다양한 OS 환경별로 바이너리 만드는 것이 너무 머리아프다.\nC++에 비해 성능 느릴 수 있지만 그래도 Java JIT를 믿었다.\nJava 8을 선택하였는데 가장 많은 환경에서 쉽게 사용할 수 있는 것이 Java 8 이라 생각해서였다. 다양한 환경에 배포되는 바이너리인 만큼 최대한 많은 환경에서 동작하는게 맞을 것같아 일단 Java 8로 선택하였다. (나중에 알고보니 32bit 지원이 마지막이라는 것을 듣고 일단 Java 8로 하는 것이 다양한 환경에 배포되는 수집기로써 호환성 측면에서는 나은 선택일 수도 있었겠다 생각했다.)\n구현하고보니 보이는 장단점\nJava 8, Spring Boot, Netty, JNI 를 사용하여 구현하였다. 구현을 하고 보니 보이는 장단점들이 있었다.\nJNI가 필요한 이유는 관제 DB인 Tibero 데이터 수집하기 위해서 TIbero에서 제공해주는 C 라이브러리 함수를 사용해야하기 때문이다. 제공된 C 라이브러리를 통해서 조회한 데이터는 바로 Java 객체로 담아서 return하는 식이다.\n장점\nJava를 선택하게된 결정적인 이유가 구현 전보다 구현 후에 더 큰 장점으로 느껴졌다. 직접 구현하고 서로 다른 환경에서 서로 다른 JVM 위에서 같은 애플리케이션을 실행시켜보니 호환성과 편리함을 여실히 실감하게 되었다.\n그리고 다양한 라이브러리를 중앙 저장소인 maven 으로부터 쉽게 로드하여 사용할 수 있다는 것이 엄청난 장점이라는 것을 다시 한번 느꼈다. 유저가 많은 언어라는 것 자체가 확실히 장점으로 다가왔고, 그만큼 탄탄한 라이브러리들을 기반으로 편리하게 구현을 진행할 수 있었다.\n단점\n이렇게 쉽게 선택하고 구현을 마치고 보니 즉각적인 단점이 눈앞에 보였다.\nRealtime 수집기인데 GC로 인해서 수집 주기가 지켜지지 못하고 뜰쑥날쑥한 현상이 간헐적으로 발생한 것이다\n물론 현재는 1초가 최소 수집 주기이기에 실제 화면에서는 실시간이 기존 것과 큰 차이가 없다. 1초 안에는 대부분 데이터 수집하고 메시지를 만들어 serialize하고 TCP로 보내기는 하는 것이다.\n그래도 확실히 C++에 비해 Java가 느리고 GC로 인해 불안한 수집 주기를 가지게 된다는 것을 느끼게 되었다.\n그래서 GC를 최대한 하지 않도록 코드 개선 진행중\nGC가 최대한 발생하지 않도록 개선을 진행하고 있다.\n코드 레벨에서는 GC가 최대한 발생하지 않도록 새로 만드는 인스턴스들이 정말로 필요한지, 재사용할 수는 없는지 테스트하고 개선하는 중이다.\nJVM 메모리 설정으로도 GC를 덜 할 수 있도록 할 수 있을 것처럼 보인다. 다만 JVM 메모리 설정은 각 배포된 환경이 천차만별이기에 그 환경에 맞게 진행하는 것이 맞을 것으로 보인다.",
        "guid": "https://velog.io/@ahngj96/AIX-%ED%99%98%EA%B2%BD%EC%97%90%EC%84%9C-%EB%8F%99%EC%9E%91%ED%95%98%EB%8A%94-%EC%88%98%EC%A7%91%EA%B8%B0%EA%B0%80-%ED%95%84%EC%9A%94%ED%95%B4%EC%9A%94",
        "isoDate": "2024-07-06T17:09:18.000Z"
      }
    ]
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "지속 가능한 사업",
        "link": "https://www.thestartupbible.com/2024/07/on-being-ready-to-be-a-sustainable-business.html",
        "pubDate": "Wed, 10 Jul 2024 21:34:00 +0000",
        "content:encodedSnippet": "한때는 테슬라보다 더 혁신적인 전기 자동차 회사로 추앙받던 Fisker가 얼마 전에 파산 신청을 했다. 실은, 10년 전에 이미 회사를 한 번 말아먹었고, 이번이 두 번째 파산이라고도 할 수 있는데, 관련 기사를 읽어보면 피스커의 파산 원인은 여러 가지 복합적이지만, 결국엔 지속 가능한 사업 자체를 만들 준비가 안 됐기 때문인 것 같다.\nTechCrunch의 기사 제목을 보면 피스커의 실패 원인이 “it wasn’t ready to be a car company” 라고 하는데, 내가 봤을 때 이 말의 뜻은 피스커가 멋진 컨셉의 전기자동차를 디자인하고 만드는 회사가 되긴 했지만, 이 자동차를 대량으로 생산하고, 판매하고, 결국엔 안정적으로 돈을 버는 비즈니스를 만들고 운영하는 데 실패했다는 것 같다. 피스커의 창업자는 Henrik Fisker라는 걸출한 자동차 디자이너인데, 이분은 멋진 자동차를 디자인하는 데는 천부적인 소질이 있었지만, 그 재능은 딱 거기까지인 것 같다. 비즈니스를 하는 사업가로 변신하는 데는 실패했고, 아마도 자신의 그런 한계를 잘 몰랐던 것 같다.\n우리가 투자했거나, 검토했던 꽤 많은 회사도 이런 비슷한 문제를 경험한다.\n창업가가 특정 문제를 해결하기 위해서 회사를 만들고, 열심히 제품을 만든다. 출시 일정을 정하고, 여기에 맞춰서 몇 개월, 또는 몇 년을 밤새워서 만들고, 운 좋으면 원래 계획했던 대로 제품이 완성돼서 시장에 출시된다. 실은, 대부분의 회사가 여기까지도 못 간다. 거창하게 세웠던 계획대로 되는 일은 하나도 없고, 모든 게 엉망진창으로 진행되면서 돈은 예상보다 빨리 쓰고, 제품은 나오지 않거나, 나오더라도 계획했던 게 아닌, 아주 허접한 제품이 출시되면서 그냥 소리 소문 없이 회사는 문을 닫거나, 다른 제품으로 피봇한다.\n하지만, 아주 운이 좋은 회사들은 시장에서 꽤 열광하는 좋은 제품을 만들어서 출시한다. 그리고, 초기 얼리 어댑터들 사이에서 입소문이 나고 어느 정도의 바이럴 요소가 감지된다.\n오랜 시간 동안 고생해서 초기 반응이 좋은 제품을 만들어서 출시한 건, 이것 자체가 대단하고 스스로 자랑스러워야 하는 큰 마일스톤 달성이지만, 많은 대표들은 이게 사업의 종착점이자 성공이라고 착각한다. 실은, 제품 출시한 후부터가 진정한 사업의 시작점이고, 여기서 어떻게 하는가에 따라서 이 사업이 정말로 지속 가능한 사업이 될 수 있을지 결정된다.\n어떤 분들은 만들어서 출시하면, 그냥 알아서 팔릴 것이고, 이렇게 팔리다 보면 곧 유니콘이 되는 걸로 착각하는데, 경험이 좀 있는 분들은 절대로 이렇게 안 된다는 걸 잘 알고 있을 것이다. 좋은 제품을 만들 때까진, 장인의 정신으로 정말로 쓸모 있는 제품을 만들어야 한다. 하지만, 이후부턴 이 제품을 어떻게 시장의 요구에 맞춰서 최적화하고, 어떻게 영업과 마케팅을 하고, 어떻게 더 좋은 사람을 채용하고, 어떻게 더 비용을 절감하면서 사업을 운영해서, 오랫동안 지속 가능한 회사다운 회사를 만들지에 대한, 사업가의 마인드와 실행력이 필요하다.\n어떤 분들은 이런 걸 0에서 1은 엄청나게 잘 하지만, 1에서 10까진 못 하는 딜레마라고도 한다. 결국엔 돈을 벌고 사업을 만드는 건 1에서 10 사이 어딘가에 존재하고, 단순히 만드는 회사가 아닌 사업하는 회사가 되기 위해선 1에서 10 사이 어딘가에 있어야 한다.\n결국엔 피스커도 멋지고 시장에서 WoW 하는 제품을 만들어서 출시했지만(0->1), 회사가 돈을 벌면서 이 멋진 자동차를 대량생산해서 판매할 방법에 대한 생각과 고민이 깊지 않았고, 결국 지속 가능한 사업(1->10)을 만드는 데 실패했다고 생각한다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/07/on-being-ready-to-be-a-sustainable-business.html#respond",
        "content": "한때는 테슬라보다 더 혁신적인 전기 자동차 회사로 추앙받던 Fisker가 얼마 전에 파산 신청을 했다. 실은, 10년 전에 이미 회사를 한 번 말아먹었고, 이번이 두 번째 파산이라고도 할 수 있는데, 관련 기사를 읽어보면 피스커의 파산 원인은 여러 가지 복합적이지만, 결국엔 지속 가능한 사업 자체를 만들 준비가 안 됐기 때문인 것 같다. TechCrunch의 기사 제목을 보면 피스커의(...)",
        "contentSnippet": "한때는 테슬라보다 더 혁신적인 전기 자동차 회사로 추앙받던 Fisker가 얼마 전에 파산 신청을 했다. 실은, 10년 전에 이미 회사를 한 번 말아먹었고, 이번이 두 번째 파산이라고도 할 수 있는데, 관련 기사를 읽어보면 피스커의 파산 원인은 여러 가지 복합적이지만, 결국엔 지속 가능한 사업 자체를 만들 준비가 안 됐기 때문인 것 같다. TechCrunch의 기사 제목을 보면 피스커의(...)",
        "guid": "https://www.thestartupbible.com/?p=9152",
        "categories": [
          "Uncategorized",
          "failure",
          "FoundersAtWork",
          "hardware",
          "mobility",
          "strategy",
          "Strong",
          "스타트업 바이블 QA"
        ],
        "isoDate": "2024-07-10T21:34:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "가장 중요한 점수",
        "link": "https://www.thestartupbible.com/2024/07/the-most-important-point-is-the-point-you-are-playing-right-now.html",
        "pubDate": "Sun, 07 Jul 2024 21:32:00 +0000",
        "content:encodedSnippet": "창업가들의 가장 큰 장점이자, 동시에 가장 큰 단점이 될 수 있는 것 중 하나가 너무 멀리, 그리고 너무 넓게 보는 능력이다.\n너무 멀리 본다는 건, 좋게 말하면 장기적인 비전이 있고, 큰 그림을 그릴 수 있고, 이 그림을 완성하기 위한 계획성이 있다는 것이지만, 나쁘게 말하면 작은 것도 못 하는데 너무 큰 것만 생각하는 공상가/망상가라는 의미다. 이제 막 시작한 창업가가 월 매출 10만 원도 못 하면서 월 매출 100억 원을 하기 위한 구체적인 계획을 세울 때, 어떤 투자자들은 대단한 비저너리라고 좋아하지만, 어떤 투자자들은 꿈만 꾸는 사람이라고 비난한다.\n너무 넓게 본다는 건, 좋게 말하면 한 번에 다양한 분야로 확장해서 큰 시장을 먹을 수 있다는 의미지만, 나쁘게 말하면 하나에도 제대로 집중하지 못하고 일만 벌이는 스타일이라는 의미일 수도 있다. 하나의 기능도 제대로 못 만들고 있는데, 계속 슈퍼 앱을 만들겠다는 창업가들이 대표적인 사례이다.\n이제 시작하는 창업가들이 나한테 지금까지 봤던 회사 중 잘 된 회사들의 공통점을 자주 물어본다. 회사마다 다르고, 창업가마다 다르기 때문에, 딱 하나의 공통점은 없지만, 오랫동안 사업을 하기로 결심한 분들에겐 작은 것들이 차곡차곡 쌓이면, 복리의 힘으로 인해서 나중에 폭발적인 성장이 만들어진다는 걸 믿으라고 한다. 간단하게 말하면, 성공하는 회사들의 공통점은 작은 것들의 힘과 복리의 힘을 믿는다는 점이다. 이걸 믿지 않으면 창업과 사업이라는 외로운 싸움을 오래 할 수가 없다.\n그럼 작은 것엔 어떻게 집중할 수 있을까? 지금 하는 일, 지금 만들고 있는 기능, 지금 쓰고 있는 이메일, 이게 내가 이 세상에서 하는 마지막 일이라고 생각하면 된다. 그러면 여기에 100% 집중하고, 아무리 작은 일이라도 완벽하게 하려고 노력한다. 매사에 이런 자세로 임하면, 결국엔 작은 것들이 완벽하게 만들어지고, 이렇게 완벽하고 작은 것들이 차곡차곡 쌓이다 보면 아주 크고 아주 완벽한 것으로 성장한다. 폭발적으로 성장한다.\n역사상 가장 완벽한 테니스 선수였던 로저 페더러가 얼마 전에 다트머스 대학교 졸업식 축사에서 이런 명언을 했다. “테니스 경기에서 가장 중요한 건 바로 지금 치고 있는 포인트다. 이게 세상에서 가장 중요하다. 이기기 위해서 최선을 다해야 한다. 하지만, 이기든 지든, 이 포인트가 끝났다면, 이젠 잊어버리고 다음 포인트에 집중해야 한다…지금 이 시점에 모든 걸 집중해야 한다.”\n창업가들도 이런 마인드로 사업을 해야 한다. 이 세상에서 가장 어려운 경기는 지금, 현재 내가 하고 있는 경기다. 이 경기에서 가장 어렵고 중요한 건 바로 지금 치고 있는 포인트다. 그다음으로 중요하고 어려운 건 바로 다음 포인트고, 다음 경기다.\n점수를 하나씩 이기다 보면, 게임에 이기고, 세트를 이기고, 시합에 이긴다. 이 순서대로 인생은 흘러가지, 그 반대로 흘러가지 않는다.\n이제 사업을 막 시작한 어떤 창업가가 본인은 몇백억짜리 회사를 만들 계획이었으면 그냥 대기업에 취직했지, 창업하지 않았을 거라고 했다. 처음부터 본인은 유니콘이 목표라고 하면서. 참고로 이 분은 내가 보기엔 아직 30억짜리 회사도 못 만들었다. 위에서 말한 이유로 나는 이런 창업가들이 싫다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/07/the-most-important-point-is-the-point-you-are-playing-right-now.html#comments",
        "content": "창업가들의 가장 큰 장점이자, 동시에 가장 큰 단점이 될 수 있는 것 중 하나가 너무 멀리, 그리고 너무 넓게 보는 능력이다. 너무 멀리 본다는 건, 좋게 말하면 장기적인 비전이 있고, 큰 그림을 그릴 수 있고, 이 그림을 완성하기 위한 계획성이 있다는 것이지만, 나쁘게 말하면 작은 것도 못 하는데 너무 큰 것만 생각하는 공상가/망상가라는 의미다. 이제(...)",
        "contentSnippet": "창업가들의 가장 큰 장점이자, 동시에 가장 큰 단점이 될 수 있는 것 중 하나가 너무 멀리, 그리고 너무 넓게 보는 능력이다. 너무 멀리 본다는 건, 좋게 말하면 장기적인 비전이 있고, 큰 그림을 그릴 수 있고, 이 그림을 완성하기 위한 계획성이 있다는 것이지만, 나쁘게 말하면 작은 것도 못 하는데 너무 큰 것만 생각하는 공상가/망상가라는 의미다. 이제(...)",
        "guid": "https://www.thestartupbible.com/?p=9149",
        "categories": [
          "Uncategorized",
          "buffett",
          "FoundersAtWork",
          "general",
          "sports",
          "vc"
        ],
        "isoDate": "2024-07-07T21:32:00.000Z"
      }
    ]
  },
  {
    "name": "Build a Great Product",
    "category": "개인",
    "posts": []
  },
  {
    "name": "지금 써보러 갑니다",
    "category": "개인",
    "posts": []
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": [
      {
        "creator": "지마켓 기술블로그",
        "title": "Redis Stream 적용기",
        "link": "https://dev.gmarket.com/113",
        "pubDate": "Thu, 11 Jul 2024 15:55:03 +0900",
        "author": "지마켓 기술블로그",
        "comments": "https://dev.gmarket.com/113#entry113comment",
        "content": "<div id=\"SE-2c9b3139-ac56-4d2d-850c-9c900a9815a4\" data-compid=\"SE-2c9b3139-ac56-4d2d-850c-9c900a9815a4\" data-a11y-title=\"본문\">\n<div data-unitid=\"\" data-compid=\"SE-2c9b3139-ac56-4d2d-850c-9c900a9815a4\" data-direction=\"top\">\n<div id=\"SE-741470b1-f120-49c5-87ee-5590a6ea400a\">\n<p id=\"SE-357ed5d0-792c-4e3b-8e49-ae1c6930c179\" style=\"text-align: justify;\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">안녕하세요 Data Product 팀 박상우입니다.</span></p>\n<p id=\"SE-21a56774-3805-4eb6-a441-8b03225e0767\" style=\"text-align: justify;\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-ca8cdf9c-9bec-49fe-8444-8b20e8ef3c1f\" style=\"text-align: justify;\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">이번에 제가 소개해드릴 내용은 팀 내 session Info data 적재 및 API 서비스 구축에 적용한 Redis Stream에 대한 이야기입니다.</span></p>\n<p id=\"SE-2edf5846-d99e-4b1d-942a-824a88ef7faa\" style=\"text-align: justify;\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-6d909383-ff9b-4d35-aae4-be5d72b77c65\" style=\"text-align: justify;\" data-ke-size=\"size16\">저희 팀에서는 User의 행동 정보를 수집하는 프레임워크 중 하나인 montelena receiver를 통해 수집한 데이터 (view, event, impression 등)를 post Processor라는 데이터 파이프라인 application을 통해 적재, 가공해서 각종 지표 트래킹 및 분석에 활용할 수 있도록 제공하고 있습니다.</p>\n<p id=\"SE-02e93e82-be43-4a45-a3f1-db95b554df20\" style=\"text-align: justify;\" data-ke-size=\"size16\">&nbsp;</p>\n</div>\n</div>\n</div>\n<div id=\"SE-468d39bb-314c-46ca-83cd-0af12095f990\" data-compid=\"SE-468d39bb-314c-46ca-83cd-0af12095f990\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-468d39bb-314c-46ca-83cd-0af12095f990\" data-direction=\"top\">\n<div id=\"SE-468d39bb-314c-46ca-83cd-0af12095f990\">\n<div data-unitid=\"SE-468d39bb-314c-46ca-83cd-0af12095f990\" data-compid=\"\" data-direction=\"top\"><figure class=\"imageblock alignLeft\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"936\" data-origin-height=\"353\"><span data-url=\"https://blog.kakaocdn.net/dn/SBPOd/btsIwoKfyaN/2JJfk81k3oxKCKPy1Dezy1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/SBPOd/btsIwoKfyaN/2JJfk81k3oxKCKPy1Dezy1/img.png\" data-alt=\"Post Processor Data Pipeline\"><img src=\"https://blog.kakaocdn.net/dn/SBPOd/btsIwoKfyaN/2JJfk81k3oxKCKPy1Dezy1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FSBPOd%2FbtsIwoKfyaN%2F2JJfk81k3oxKCKPy1Dezy1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"936\" data-origin-height=\"353\"/></span><figcaption>Post Processor Data Pipeline</figcaption>\n</figure>\n</div>\n</div>\n<div id=\"SE-5a4bd3d0-0d12-4aad-bf3a-3c3dcce13a6f\">\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-e075356b-38e3-41eb-a3a2-b7858c9beba2\" data-ke-size=\"size16\"><span style=\"color: #000000; letter-spacing: 0px; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">그중 유니크한 active user를 식별하기 위해 session_id를 발급하고, 그 히스토리를 남겨 광고에 활용하고 있는데,</span></p>\n</div>\n</div>\n</div>\n<div id=\"SE-0b48a89c-f2df-44d8-8d78-7edc34e87c1d\" data-compid=\"SE-0b48a89c-f2df-44d8-8d78-7edc34e87c1d\" data-a11y-title=\"본문\">\n<div data-unitid=\"\" data-compid=\"SE-0b48a89c-f2df-44d8-8d78-7edc34e87c1d\" data-direction=\"top\">\n<div id=\"SE-0493ecca-7da0-42b9-87b5-31418a7ef390\">\n<p id=\"SE-c7fb2763-0ab4-4ee5-b9aa-fa5fdbc41797\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">'Big Smile Day' (지마켓 최고의 연례행사인 빅스마일데이, 이하 BDS)</span></p>\n<p id=\"SE-55b4456d-f930-4b5a-b8cb-4254427f8342\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">'User Targeting Content' (이하 UTC) Push 발송 등 유저의 유입이 급증해서 트래픽이 대폭 증가할 경우 데이터 처리가 지연되는 현상이 발생하게 되었습니다.</span></p>\n<p id=\"SE-a3dd4089-12f6-48d5-a70f-211da8bc84dc\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-6168f497-1f4a-40e0-adb6-8600e573040e\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">이 문제를 해결하기 위해서는 부하를 발생시키는 로직을 분리해서 별도로 처리하도록 하는<span>&nbsp;</span><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif; color: #000000; text-align: start;\">application</span>의 개발이 요구되는 상황이었고,</span></p>\n<p id=\"SE-411d4691-6532-4300-9a58-0e1b4db2dbcd\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">이에 Redis stream을 사용해서 session_id 히스토리 적재 로직을 수행하는 신규 consumer를 개발했던 과정을 간단하게나마 공유해보고자 합니다.</span></p>\n<p id=\"SE-9aebcf12-3a31-4257-aa78-23b2b573f787\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-412c07c7-1fbf-45e3-bc6e-655cf98e9f72\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-b2f0ee19-e189-4a18-bcb3-58df216da2f7\" data-ke-size=\"size16\">&nbsp;</p>\n</div>\n</div>\n</div>\n<div id=\"SE-8c1cf4fc-bedd-4308-ba8a-d7746f88e176\" data-compid=\"SE-8c1cf4fc-bedd-4308-ba8a-d7746f88e176\" data-a11y-title=\"소제목\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-8c1cf4fc-bedd-4308-ba8a-d7746f88e176\" data-direction=\"top\">\n<div>\n<div id=\"SE-0b356118-4562-40a6-970c-366cf868c876\">\n<h2 id=\"SE-5b922977-36c3-495c-87b4-f690741f3b32\" style=\"color: #000000;\" data-ke-size=\"size26\"><b><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Redis Stream의 특징과 장점</span></b></h2>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p style=\"text-align: justify;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: justify;\" data-ke-size=\"size16\"><span style=\"color: #000000; letter-spacing: 0px; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">2018년 10월 17일, Redis 5.0 버전이 출시되었습니다.</span></p>\n<div id=\"SE-19dc2e32-9404-454a-b69c-0eaa465d7b9a\" data-compid=\"SE-19dc2e32-9404-454a-b69c-0eaa465d7b9a\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-19dc2e32-9404-454a-b69c-0eaa465d7b9a\" data-direction=\"top\">\n<div id=\"SE-9291e0a4-c0af-46d2-b6b9-77ebb077ab5f\">\n<p data-ke-size=\"size16\">&nbsp;</p>\n<div id=\"SE-19dc2e32-9404-454a-b69c-0eaa465d7b9a\" data-compid=\"SE-19dc2e32-9404-454a-b69c-0eaa465d7b9a\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-19dc2e32-9404-454a-b69c-0eaa465d7b9a\" data-direction=\"top\">\n<div id=\"SE-19dc2e32-9404-454a-b69c-0eaa465d7b9a\">\n<div>&nbsp;</div>\n<div data-unitid=\"SE-19dc2e32-9404-454a-b69c-0eaa465d7b9a\" data-compid=\"\" data-direction=\"top\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"727\" data-origin-height=\"471\"><span data-url=\"https://blog.kakaocdn.net/dn/bJtN2h/btsIv8Vbi5J/y3xzOpcLp6Yw69kOCkbDU0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bJtN2h/btsIv8Vbi5J/y3xzOpcLp6Yw69kOCkbDU0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bJtN2h/btsIv8Vbi5J/y3xzOpcLp6Yw69kOCkbDU0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbJtN2h%2FbtsIv8Vbi5J%2Fy3xzOpcLp6Yw69kOCkbDU0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"500\" data-origin-width=\"727\" data-origin-height=\"471\"/></span></figure>\n</div>\n<span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\"></span></div>\n<div>&nbsp;</div>\n<div>&nbsp;</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p style=\"text-align: justify;\" data-ke-size=\"size16\">이전&nbsp;버전에서&nbsp;많은&nbsp;부분이&nbsp;개선되었지만&nbsp;그중&nbsp;가장&nbsp;중요한&nbsp;기능&nbsp;추가&nbsp;중&nbsp;하나가&nbsp;바로&nbsp;Redis&nbsp;stream&nbsp;이였는데요.<br />고가용성&nbsp;데이터&nbsp;스트리밍&nbsp;처리가&nbsp;도입되면서,&nbsp;데이터의&nbsp;일관성과&nbsp;안정성을&nbsp;보장하면서&nbsp;대용량&nbsp;데이터&nbsp;스트림을&nbsp;실시간으로&nbsp;처리할 수&nbsp;있게&nbsp;되었습니다.<br />동시에 inmemory 기반으로 동작하는 key value 기반의 캐시를 사용하기 때문에 속도가 빠르다는 장점으로 사내에서도 저장소로&nbsp;널리&nbsp;사용되고 있죠.</p>\n<p style=\"text-align: justify;\" data-ke-size=\"size16\">&nbsp;</p>\n<div id=\"SE-401d2a2f-1385-43dc-95ac-240605a5cff7\" data-compid=\"SE-401d2a2f-1385-43dc-95ac-240605a5cff7\" data-a11y-title=\"본문\">\n<div data-unitid=\"\" data-compid=\"SE-401d2a2f-1385-43dc-95ac-240605a5cff7\" data-direction=\"top\">\n<div id=\"SE-27f964f0-3e80-4fbe-b415-5335fd52026c\">\n<p id=\"SE-476d05cb-8a69-4e82-980c-9d7baca9f1d0\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 id=\"SE-d9e7b0e4-6c6a-4932-be60-96638bca8718\" style=\"color: #000000;\" data-ke-size=\"size26\"><b><span style=\"color: #000000; letter-spacing: 0px; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">왜 Redis Stream을 선택했는가?</span></b></h2>\n</div>\n</div>\n</div>\n<div id=\"SE-662bd44e-9cac-4554-b87a-9572250e9bc2\" data-compid=\"SE-662bd44e-9cac-4554-b87a-9572250e9bc2\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-662bd44e-9cac-4554-b87a-9572250e9bc2\" data-direction=\"top\">\n<div>\n<div id=\"SE-1132e013-65d2-4ece-808b-f2633ffe9d50\">\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-270a3284-7ae1-4297-8f36-ab7624d57043\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">처음에는 메시지 큐로 kafka나 MQ를 생각했었는데, 새로운 플랫폼을 적용해야 하다 보니 개발 공수도 늘어나고 리소스도 많이 소모될 거라는 결론을 내렸습니다.</span></p>\n<p id=\"SE-a2903419-78c8-42eb-9aed-0d5f54ca6b90\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">거기다 BSD가 얼마 남지 않은 시점이라 그전에 개발을 완료해야 된다는 시간적인 제한도 허들이었습니다.</span></p>\n<p id=\"SE-d4b227e2-63f1-4f92-b04d-9d26a05c9b5a\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">이미 session_id 저장소로 redis를 사용하고 있었고, 최대한 기존 로직을 건드리지 않으면서, 빠르게 히스토리를 적재할 수 있는 방법을 찾던 중,</span></p>\n<p id=\"SE-ce036b84-2517-4774-84e0-23908edcd43f\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">kafka와 유사한 기능들을 제공하면서 사내 openshift 환경의 여러 개 pod에서 구동해도 데이터 중복이나 유실 없이 처리가 가능한 Redis stream을 선택하게 되었습니다.</span></p>\n<p id=\"SE-9c0b7bfc-2769-4411-a8bd-8a73884e7abc\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-8d5fb2d8-06ac-47a2-9fb9-449b0eff6d50\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-6ae2d4c0-877b-4b62-8629-b4015e0ec3f0\" data-ke-size=\"size16\">&nbsp;</p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-b28477fc-4501-4d0b-919a-48011b3b7d95\" data-compid=\"SE-b28477fc-4501-4d0b-919a-48011b3b7d95\" data-a11y-title=\"소제목\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-b28477fc-4501-4d0b-919a-48011b3b7d95\" data-direction=\"top\">\n<div>\n<div id=\"SE-edc77a9b-6756-4678-91c4-e7f6fa5a5040\">\n<h2 id=\"SE-1eedcb1a-3744-4dc2-b8f0-66f9dc8cb113\" style=\"color: #000000;\" data-ke-size=\"size26\"><b><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Redis Pub/Sub과 Redis Stream?</span></b></h2>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-b2bfe4c8-3516-4379-8f5a-0d3343890166\" data-compid=\"SE-b2bfe4c8-3516-4379-8f5a-0d3343890166\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-b2bfe4c8-3516-4379-8f5a-0d3343890166\" data-direction=\"top\">\n<div>\n<div id=\"SE-2b73999d-9408-4f92-adfd-337b6364c533\">\n<p id=\"SE-e11ef9e3-5704-4fe1-a45d-aa93b4dc4061\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-3e062e88-28c2-41be-a19b-d0f1ca15cf58\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">일반적으로 Redis를 이용해 메시지를 Broadcasting 할 때는 pub/sub을 많이 사용합니다.</span></p>\n<p id=\"SE-afd4ed17-640d-417e-ac6e-a48c5896ea5d\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">하지만 이 방식은 publisher가 메시지를 발행했을 때 subscriber가 존재하지 않거나 애플리케이션에 이슈가 발생하면 수신 여부에 관계없이 메시지가 휘발되는 단점이 있습니다.</span></p>\n<p id=\"SE-9ae4edb6-538a-47e2-9e74-226c6df845d1\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">또한, 여러 개의 subscriber를 구동하면 모두에게 동일한 메시지를 발행해 데이터가 중복되는 이슈가 발생합니다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-8deef978-4efa-41b3-83e6-09075a0ff7d8\" data-compid=\"SE-8deef978-4efa-41b3-83e6-09075a0ff7d8\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-8deef978-4efa-41b3-83e6-09075a0ff7d8\" data-direction=\"top\">\n<div id=\"SE-8deef978-4efa-41b3-83e6-09075a0ff7d8\">\n<div id=\"SE-8deef978-4efa-41b3-83e6-09075a0ff7d8\" data-compid=\"SE-8deef978-4efa-41b3-83e6-09075a0ff7d8\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-8deef978-4efa-41b3-83e6-09075a0ff7d8\" data-direction=\"top\">\n<div id=\"SE-8deef978-4efa-41b3-83e6-09075a0ff7d8\">\n<div data-unitid=\"SE-8deef978-4efa-41b3-83e6-09075a0ff7d8\" data-compid=\"\" data-direction=\"top\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"764\" data-origin-height=\"271\"><span data-url=\"https://blog.kakaocdn.net/dn/djuNL5/btsIvc44dSR/nwOBrr8w29oi21zVE3rBw1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/djuNL5/btsIvc44dSR/nwOBrr8w29oi21zVE3rBw1/img.png\" data-alt=\"Redis Pub / Sub\"><img src=\"https://blog.kakaocdn.net/dn/djuNL5/btsIvc44dSR/nwOBrr8w29oi21zVE3rBw1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdjuNL5%2FbtsIvc44dSR%2FnwOBrr8w29oi21zVE3rBw1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"500\" data-origin-width=\"764\" data-origin-height=\"271\"/></span><figcaption>Redis Pub / Sub</figcaption>\n</figure>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-d8914789-fae5-40df-b819-d93e5536cc54\" data-compid=\"SE-d8914789-fae5-40df-b819-d93e5536cc54\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-d8914789-fae5-40df-b819-d93e5536cc54\" data-direction=\"top\">\n<div>\n<div id=\"SE-b1a053cd-7310-4f7d-ba53-b9259578498e\">\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-afc6e0ac-5e90-4898-900a-5375c334b416\" data-ke-size=\"size16\"><span style=\"background-color: #ffffff; color: #202124; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">반면, Redis Stream은 휘발성이 아니라 Kafka의 offset 개념처럼 마지막으로 수신한 record id를 저장하고 XADD, XREADGROUP, XACK, XPENDING, XCLAIM으로 이어지는 처리 프로세스를 통해 메시지를 컨트롤할 수 있는 다양한 방법을 제공합니다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-9e58f812-3103-4700-8642-45867dc03830\" data-compid=\"SE-9e58f812-3103-4700-8642-45867dc03830\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-9e58f812-3103-4700-8642-45867dc03830\" data-direction=\"top\">\n<div id=\"SE-38ffbcef-62f9-4b87-a300-74b1c2961990\">\n<div id=\"SE-9e58f812-3103-4700-8642-45867dc03830\" data-compid=\"SE-9e58f812-3103-4700-8642-45867dc03830\" data-a11y-title=\"사진\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-9e58f812-3103-4700-8642-45867dc03830\" data-direction=\"top\">\n<div>\n<div id=\"SE-9e58f812-3103-4700-8642-45867dc03830\">\n<div data-unitid=\"SE-9e58f812-3103-4700-8642-45867dc03830\" data-compid=\"\" data-direction=\"top\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"936\" data-origin-height=\"454\"><span data-url=\"https://blog.kakaocdn.net/dn/5VRLC/btsIuJbk6De/jgDkLxka0URSNnkpQGfjKK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/5VRLC/btsIuJbk6De/jgDkLxka0URSNnkpQGfjKK/img.png\" data-alt=\"Redis Stream\"><img src=\"https://blog.kakaocdn.net/dn/5VRLC/btsIuJbk6De/jgDkLxka0URSNnkpQGfjKK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F5VRLC%2FbtsIuJbk6De%2FjgDkLxka0URSNnkpQGfjKK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"700\" height=\"340\" data-origin-width=\"936\" data-origin-height=\"454\"/></span><figcaption>Redis Stream</figcaption>\n</figure>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-1685d92e-3fd6-4e11-ae8e-7f7010b4f3d0\" data-compid=\"SE-1685d92e-3fd6-4e11-ae8e-7f7010b4f3d0\" data-a11y-title=\"본문\">\n<div data-unitid=\"\" data-compid=\"SE-1685d92e-3fd6-4e11-ae8e-7f7010b4f3d0\" data-direction=\"top\">\n<div id=\"SE-6c282846-05f4-450b-b3f8-299d639bd94c\">\n<p id=\"SE-a1ce989c-92e9-434c-a046-4009660c5ae8\" style=\"text-align: center;\" data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\"><span style=\"color: #000000;\">출처 :<span>&nbsp;</span></span><span style=\"color: #000000;\" data-href=\"https://jybaek.tistory.com/935\"><a href=\"https://jybaek.tistory.com/935\">https://jybaek.tistory.com/935</a></span></span></p>\n<p id=\"SE-ab0cbd7c-2853-41b6-9179-101ca31033ec\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-d054cfc8-c06c-429e-960a-fad4ad846a75\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-b4aeaa0a-5405-4c79-9c69-9afaa5447348\" data-ke-size=\"size16\"><span style=\"background-color: #ffffff; color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">또한, Redis Stream은 consumer group을 지원하기 때문에 producer가 발행한 메시지를 여러 개의 consumer가 하나의 그룹을 형성해서 중복 없이 순차적으로 병렬 처리할 수 있습니다.</span></p>\n<p id=\"SE-c899530e-7b99-4159-b0dc-d2c6ddba796e\" data-ke-size=\"size16\"><span style=\"background-color: #ffffff; color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">그리고 XACK 명령어를 사용해 메시지 처리 여부를 확인할 수 있으며, 일정 시간 동안 처리되지 못한 메시지들도 Pending Entries List를 이용해서 재처리할 수 있는 방법을 제공합니다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">&nbsp;</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<div id=\"SE-e16ffa64-c312-4d25-9143-50cf67592c37\" data-compid=\"SE-e16ffa64-c312-4d25-9143-50cf67592c37\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-e16ffa64-c312-4d25-9143-50cf67592c37\" data-direction=\"top\">\n<div id=\"SE-e16ffa64-c312-4d25-9143-50cf67592c37\">\n<div>&nbsp;</div>\n<div data-unitid=\"SE-e16ffa64-c312-4d25-9143-50cf67592c37\" data-compid=\"\" data-direction=\"top\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"936\" data-origin-height=\"384\"><span data-url=\"https://blog.kakaocdn.net/dn/dcWlQp/btsIvuj7Zcb/EubKOQ3WOv7XN1Bnj0H2gK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dcWlQp/btsIvuj7Zcb/EubKOQ3WOv7XN1Bnj0H2gK/img.png\" data-alt=\"Redis Stream\"><img src=\"https://blog.kakaocdn.net/dn/dcWlQp/btsIvuj7Zcb/EubKOQ3WOv7XN1Bnj0H2gK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdcWlQp%2FbtsIvuj7Zcb%2FEubKOQ3WOv7XN1Bnj0H2gK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"500\" data-origin-width=\"936\" data-origin-height=\"384\"/></span><figcaption>Redis Stream</figcaption>\n</figure>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-288e280d-6a52-41e8-8499-823d02f251b6\" data-compid=\"SE-288e280d-6a52-41e8-8499-823d02f251b6\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-288e280d-6a52-41e8-8499-823d02f251b6\" data-direction=\"top\">\n<div>\n<div id=\"SE-fb3932b5-b95d-4b11-8b07-5ceaf287aefb\">\n<p id=\"SE-9e6367df-0387-4fba-a980-1fc1075b9da8\" style=\"text-align: center;\" data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\"><span style=\"color: #000000;\">출처 :<span>&nbsp;</span></span><span style=\"color: #000000;\" data-href=\"https://jybaek.tistory.com/935\"><a href=\"https://jybaek.tistory.com/935\">https://jybaek.tistory.com/935</a></span></span></p>\n<p id=\"SE-a1d3405d-9bf0-44fc-8335-d72f94d05895\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-f7885cbb-4667-4e34-a91e-a6b61bc7ba9d\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 id=\"SE-c2091a53-27c5-4981-819b-8363f55aedce\" style=\"color: #000000;\" data-ke-size=\"size26\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\"><b>Redis stream Development</b></span></h2>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-707de02d-f65b-48a9-b6f0-3b9a443cc77b\" data-compid=\"SE-707de02d-f65b-48a9-b6f0-3b9a443cc77b\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-707de02d-f65b-48a9-b6f0-3b9a443cc77b\" data-direction=\"top\">\n<div>\n<div id=\"SE-b9beb496-17c7-4639-8501-98cfa7c601c5\">\n<p id=\"SE-848be57f-56e6-4915-9825-93836706a052\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-eb31c105-8a1b-48fe-bce2-91a3d4629279\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">이제 실제로 코드를 보며 Redis stream으로 어떻게 개발을 진행했는지 간단히 알아보도록 하겠습니다.</span></p>\n<p id=\"SE-4c006b2e-08de-451c-a726-2c5558f7b92a\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">프로세스는 심플한 구조로 아래 flow chart를 참고해 주시면 되겠습니다.</span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p style=\"text-align: justify;\" data-ke-size=\"size16\">&nbsp;</p>\n<div id=\"SE-4bb6012c-751a-4442-8b38-e7bfa5169dfc\" data-compid=\"SE-4bb6012c-751a-4442-8b38-e7bfa5169dfc\" data-a11y-title=\"사진\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-4bb6012c-751a-4442-8b38-e7bfa5169dfc\" data-direction=\"top\">\n<div>&nbsp;</div>\n</div>\n</div>\n</div>\n<div id=\"SE-b8fbb9b6-067f-4fd3-82b2-513c47cfb988\" data-compid=\"SE-b8fbb9b6-067f-4fd3-82b2-513c47cfb988\" data-a11y-title=\"소제목\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-b8fbb9b6-067f-4fd3-82b2-513c47cfb988\" data-direction=\"top\">\n<div>\n<div id=\"SE-7bf1eb01-c5e9-4567-affa-b6a9ad6384de\">\n<p data-ke-size=\"size16\">&nbsp;</p>\n<div id=\"SE-4bb6012c-751a-4442-8b38-e7bfa5169dfc\" data-compid=\"SE-4bb6012c-751a-4442-8b38-e7bfa5169dfc\" data-a11y-title=\"사진\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-4bb6012c-751a-4442-8b38-e7bfa5169dfc\" data-direction=\"top\">\n<div>\n<div id=\"SE-4bb6012c-751a-4442-8b38-e7bfa5169dfc\">\n<div>&nbsp;</div>\n<div data-unitid=\"SE-4bb6012c-751a-4442-8b38-e7bfa5169dfc\" data-compid=\"\" data-direction=\"top\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"808\" data-origin-height=\"327\"><span data-url=\"https://blog.kakaocdn.net/dn/cADQ90/btsIv7IKSSA/ZAki0Xm51oKpkSICbkZZ6k/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cADQ90/btsIv7IKSSA/ZAki0Xm51oKpkSICbkZZ6k/img.png\" data-alt=\"Redis Stream flow\"><img src=\"https://blog.kakaocdn.net/dn/cADQ90/btsIv7IKSSA/ZAki0Xm51oKpkSICbkZZ6k/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcADQ90%2FbtsIv7IKSSA%2FZAki0Xm51oKpkSICbkZZ6k%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"808\" height=\"327\" data-origin-width=\"808\" data-origin-height=\"327\"/></span><figcaption>Redis Stream flow</figcaption>\n</figure>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-32a10410-a65a-4dbd-9633-7a1305807528\" data-compid=\"SE-32a10410-a65a-4dbd-9633-7a1305807528\" data-a11y-title=\"소제목\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-32a10410-a65a-4dbd-9633-7a1305807528\" data-direction=\"top\">\n<div>\n<div id=\"SE-32848fa8-69dd-4c86-b11f-7450c4f671c7\">\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-84113c7f-be28-4bb0-a7c5-40373116ca6b\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\"><b>&lt;Publisher&gt;</b></span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-edac2506-b47b-4324-ad33-123a418238b6\" data-compid=\"SE-edac2506-b47b-4324-ad33-123a418238b6\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-edac2506-b47b-4324-ad33-123a418238b6\" data-direction=\"top\">\n<div>\n<div id=\"SE-b23e679d-2030-4156-af61-4fa1da515d1f\">\n<p id=\"SE-61ccbf26-4173-4f6e-a7c1-c285af9f72d2\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">먼저 Post Processor에서 트래픽 데이터를 가공/처리한 후, app에서 정의한 streamKey를 통해서 생성한 session 객체를 캡슐화해서 Redis Stream 메시지로 발행합니다.</span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-77887dee-5a6a-4f32-86cb-ac6c538be831\" data-compid=\"SE-77887dee-5a6a-4f32-86cb-ac6c538be831\" data-a11y-title=\"코드\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-77887dee-5a6a-4f32-86cb-ac6c538be831\" data-direction=\"top\">\n<div>\n<div>\n<div>\n<pre class=\"reasonml\" style=\"background-color: #f8f8f8; color: #383a42;\" data-ke-language=\"java\"><code>ObjectRecord&lt;String, String&gt; record = StreamRecords.newRecord()\n\t\t\t\t.ofObject(GsonUtil.gson().toJson(session))\n\t\t\t\t.withStreamKey(streamKey);\n\nRecordId recordId = gmktRedisTemplate.opsForStream().add(record);\nif (Objects.isNull(recordId)) {\n    // Redis Stream record 처리에 실패했을 경우 로직 추가\n}</code></pre>\n</div>\n<div>&nbsp;</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-cfc7fcb3-d839-45cd-b87e-f298b5026795\" data-compid=\"SE-cfc7fcb3-d839-45cd-b87e-f298b5026795\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-cfc7fcb3-d839-45cd-b87e-f298b5026795\" data-direction=\"top\">\n<div>\n<div id=\"SE-2e782fc2-0ab5-4abf-914b-08864a729e76\">\n<p id=\"SE-ee92c833-7004-4aff-88a3-56d74510ede1\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">opsForStream().add() 메서드를 통해서 메시지를 발행하면 recordId를 리턴하는데, 이 값은 각각의 메시지가 스트림에 추가될 때 Redis가 생성해 주는 고유의 id 값으로 보시면 됩니다.</span></p>\n<p id=\"SE-1c7c2ef7-8c54-49ad-a8c7-2f2b3c4ae6a9\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">저는 stream key / value 형태의 ObjectRecord 객체를 사용해서 개발했지만,</span></p>\n<p id=\"SE-c5453b6a-83fb-4f14-bffb-455d21798805\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">이외에도 value 값으로 Map&lt;K, V&gt; 형태로 데이터를 저장하고 읽을 수 있는 MapRecord라는 메서드도 지원하고 있습니다.</span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-9fc73dac-0da6-4c26-8cb9-86d12ca9d6f1\" data-compid=\"SE-9fc73dac-0da6-4c26-8cb9-86d12ca9d6f1\" data-a11y-title=\"코드\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-9fc73dac-0da6-4c26-8cb9-86d12ca9d6f1\" data-direction=\"top\">\n<div>\n<div>\n<div>\n<pre class=\"reasonml\" style=\"background-color: #f8f8f8; color: #383a42;\"><code>public interface MapRecord&lt;S, K, V&gt; extends Record&lt;S, Map&lt;K, V&gt;&gt;, Iterable&lt;Map.Entry&lt;K, V&gt;&gt; {\n\n\tstatic &lt;S, K, V&gt; MapRecord&lt;S, K, V&gt; create(S stream, Map&lt;K, V&gt; map) {\n\n\t\tAssert.notNull(stream, \"Stream must not be null\");\n\t\tAssert.notNull(map, \"Map must not be null\");\n\n\t\treturn new MapBackedRecord&lt;&gt;(stream, RecordId.autoGenerate(), map);\n\t}\n}</code></pre>\n</div>\n<div>&nbsp;</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-98145847-a32a-42c0-8da6-7a148159ce2b\" data-compid=\"SE-98145847-a32a-42c0-8da6-7a148159ce2b\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-98145847-a32a-42c0-8da6-7a148159ce2b\" data-direction=\"top\">\n<div>\n<div id=\"SE-5360de94-3060-40bc-bd73-ed580458aa65\">\n<p id=\"SE-185d8051-2d3f-4daf-9a0f-55cf30e9408c\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-1a9ed55e-cb22-4642-95bb-0d9530ccefa9\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\"><b>&lt;Consumer&gt;</b></span></p>\n<p id=\"SE-454f8cb7-0b4f-4483-acfb-02371449862b\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">다음은 발행된 메시지를 컨슈밍 하고 처리하는 코드를 보여드리겠습니다.</span></p>\n<p id=\"SE-d1e0074a-b694-45b6-9d8b-bc0d867cb4b3\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">먼저 Spring boot 프로젝트에서 'spring-boot-starter-data-redis' 의존성을 추가하고 Redis 서버 설정을 완료합니다.</span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-45b12fc3-7f7a-4a11-80aa-18f4bb1a4dd7\" data-compid=\"SE-45b12fc3-7f7a-4a11-80aa-18f4bb1a4dd7\" data-a11y-title=\"코드\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-45b12fc3-7f7a-4a11-80aa-18f4bb1a4dd7\" data-direction=\"top\">\n<div>\n<div>\n<div>\n<pre class=\"xml\" style=\"background-color: #f8f8f8; color: #383a42;\"><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;\n&lt;/dependency&gt;</code></pre>\n</div>\n<div>&nbsp;</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-2be1ad25-43fa-4716-992e-de27eeb244f1\" data-compid=\"SE-2be1ad25-43fa-4716-992e-de27eeb244f1\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-2be1ad25-43fa-4716-992e-de27eeb244f1\" data-direction=\"top\">\n<div>\n<div id=\"SE-1fa8afaa-6160-4826-b530-b3a37368dd9b\">\n<p id=\"SE-2a544bfe-68be-43bc-a2d1-b56886883422\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">그다음 'StreamListener' 인터페이스를 구현하고, afterPropertiesSet() 메서드를 @Orverride 해서 Redis Stream 메시지를 소비하는 consumer Group과 Listener Container를 설정하고 초기화합니다.</span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-ef18516e-30ed-4bb5-a556-a87a00b1826f\" data-compid=\"SE-ef18516e-30ed-4bb5-a556-a87a00b1826f\" data-a11y-title=\"코드\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-ef18516e-30ed-4bb5-a556-a87a00b1826f\" data-direction=\"top\">\n<div>\n<div>\n<div>\n<pre class=\"reasonml\" style=\"background-color: #f8f8f8; color: #383a42;\"><code>@Override\npublic void afterPropertiesSet() throws Exception {\n    // Consumer Group 설정\n    createStreamConsumerGroup(streamKey, consumerGroupName);\n\n    // StreamMessageListenerContainer 설정\n    this.listenerContainer = StreamMessageListenerContainer.create(\n\t\t\t\tredisTemplate.getConnectionFactory(),\n\t\t\t\tStreamMessageListenerContainer.StreamMessageListenerContainerOptions.builder()\n\t\t\t\t.targetType(String.class)\n\t\t\t\t.pollTimeout(Duration.ofSeconds(2))\n\t\t\t\t.build()\n\t\t);\n\n    // Subscription 설정\n    this.subscription = this.listenerContainer.receive(\n            Consumer.from(this.consumerGroupName, consumerName),\n            StreamOffset.create(streamKey, ReadOffset.lastConsumed()),\n            this\n    );\n\n    // Redis listen 시작\n    this.listenerContainer.start();\n}\n\npublic void createStreamConsumerGroup(String streamKey, String consumerGroupName){\n\tif (!redisTemplate.hasKey(streamKey)){\n\t\tRedisClusterAsyncCommands commands = (RedisClusterAsyncCommands) this.redisTemplate\n\t\t\t\t.getConnectionFactory()\n\t\t\t\t.getClusterConnection()\n\t\t\t\t.getNativeConnection();\n\t\t\n        CommandArgs&lt;String, String&gt; args = new CommandArgs&lt;&gt;(StringCodec.UTF8)\n\t\t\t\t.add(CommandKeyword.CREATE)\n\t\t\t\t.add(streamKey)\n\t\t\t\t.add(consumerGroupName)\n\t\t\t\t.add(\"0\")\n\t\t\t\t.add(\"MKSTREAM\");\n\n\t\tcommands.dispatch(CommandType.XGROUP, new StatusOutput(StringCodec.UTF8), args);\n\t}\n\telse{\n\t\tif(!isStreamConsumerGroupExist(streamKey, consumerGroupName)){\n\t\t\tthis.redisTemplate.opsForStream().createGroup(streamKey, ReadOffset.from(\"0\"), consumerGroupName);\n\t\t}\n\t}\n}</code></pre>\n</div>\n<div>&nbsp;</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-c5eab8de-6a72-4a4f-8e32-4af6a44dacff\" data-compid=\"SE-c5eab8de-6a72-4a4f-8e32-4af6a44dacff\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-c5eab8de-6a72-4a4f-8e32-4af6a44dacff\" data-direction=\"top\">\n<div>\n<div id=\"SE-6d43d598-d620-4aca-bba0-c3cb7590ae47\">\n<p id=\"SE-2e564dd0-5c7c-4245-95d3-6c566ea24e15\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Publisher에서 설정한 StreamKey와 Consumer Name을 세팅해서 Consumer Group을 생성합니다.</span></p>\n<p id=\"SE-f1cfaf02-4aa6-4f2a-9580-6b70e6f42e99\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">그리고 Consumer 객체를 생성, Offset 설정, Subscriber 옵션 등 세부적인 설정을 완료한 뒤, Listener Container를 시작하면 Redis Stream 메시지를 비동기적으로 Listner에게 전달하게 됩니다.</span></p>\n<p id=\"SE-c7bafcff-d90c-412c-a794-02cf3171546a\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">이 과정을 통해서 여러 개의 Consumer Group을 사용해서 하나의 Redis Stream을 병렬로 처리할 수 있습니다.</span></p>\n<p id=\"SE-ecc68fbd-e19e-432f-b6a1-d69aa5666fdb\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-094e67ba-5494-4454-af2b-94dc1d8a9cc4\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">이렇게 전달되는 메시지들은 마찬가지로 'StreamListener' 인터페이스가 제공하는 onMessage 메서드를 구현해서 처리하게 됩니다.</span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-3a982061-e5b4-4038-ae19-04ba484914aa\" data-compid=\"SE-3a982061-e5b4-4038-ae19-04ba484914aa\" data-a11y-title=\"코드\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-3a982061-e5b4-4038-ae19-04ba484914aa\" data-direction=\"top\">\n<div>\n<div>\n<div>\n<pre class=\"reasonml\" style=\"background-color: #f8f8f8; color: #383a42;\"><code>@Override\npublic void onMessage(ObjectRecord&lt;String, String&gt; message) {\n    \n    String stream = message.getStream();\n    String recordId = message.getId().getValue();\n    \n    try {\n        // 처리할 로직 구현\n        if (StringUtils.isNotEmpty(message.getValue())) {\n            // To-Do\n        }\n        // 이후, ack stream\n        this.redisTemplate.opsForStream().acknowledge(streamKey, consumerGroupName, recordId);\n        \n    } catch (Exception e) {\n        // TODO: handle exception\n        e.printStackTrace();\n        this.redisOperator.delete(stream, recordId);\n    }\n}</code></pre>\n</div>\n<div>&nbsp;</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-a27a1193-0356-49c7-b518-59125a518ed4\" data-compid=\"SE-a27a1193-0356-49c7-b518-59125a518ed4\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-a27a1193-0356-49c7-b518-59125a518ed4\" data-direction=\"top\">\n<div>\n<div id=\"SE-77401bbc-f306-4983-8687-2811adf476f6\">\n<p id=\"SE-b9079962-3214-42fa-b68b-dbab64b1f572\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">메시지를 처리하고 나면 'ackStream' 메소드를 호출해서 Redis Stream 메시지가 성공적으로 처리되었음을 알리고, 해당 메시지를 대기열에서 제거합니다.</span></p>\n<p id=\"SE-86d29336-8939-4552-b232-12fbb8d88559\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Exception 이 발생할 경우 recordId를 통해 메시지를 삭제 처리할 수도 있고, 다양한 시나리오로 처리가 가능하니 용도에 맞게 사용하시면 되겠습니다.</span></p>\n<p id=\"SE-b526e745-0b93-41e8-aca0-da6e37a27e6f\" data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-54f0a52c-4c94-4a55-b41e-e5d4511a6e19\" data-ke-size=\"size16\">&nbsp;</p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-e30ea8ea-4591-4bea-aa95-20d8826a6409\" data-compid=\"SE-e30ea8ea-4591-4bea-aa95-20d8826a6409\" data-a11y-title=\"소제목\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-e30ea8ea-4591-4bea-aa95-20d8826a6409\" data-direction=\"top\">\n<div>\n<div id=\"SE-03626274-fc83-43bf-9233-551862ac372c\">\n<h2 id=\"SE-a27eef85-6824-4d86-b7d4-b2b29d03ebeb\" style=\"color: #000000;\" data-ke-size=\"size26\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\"><b>Redis stream 적용 시 고려할 점들</b></span></h2>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-87337d3c-5368-4f1e-9f65-b37a21afde18\" data-compid=\"SE-87337d3c-5368-4f1e-9f65-b37a21afde18\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-87337d3c-5368-4f1e-9f65-b37a21afde18\" data-direction=\"top\">\n<div>\n<div id=\"SE-a4e50485-301a-4a9e-9d0b-6663d0d4c93c\">\n<p id=\"SE-64809c52-18b2-4908-b60a-2a8c36fed53a\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-70df0afc-f520-4bb5-b4b7-3d8a0de56a52\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Redis Stream은 파티션 개념이 없기 때문에 하나의 stream을 여러 개의 consumer가 병렬 처리하는 구조로 동작합니다.</span></p>\n<p id=\"SE-862d46d6-c66f-472d-a7cd-05838df12568\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">그래서 Redis cluster 구조에서 sharding 되어 있는 node에 메시지를 고르게 보내려면 추가적으로 N개의 stream을 각각의 node에 할당하도록 추가 개발이 필요합니다.</span></p>\n<p id=\"SE-70c5363c-6600-405c-9acd-098e8440ce5f\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">이러한 특징 때문에 produce 된 순서대로 메시지를 처리한다는 보장이 없어지는데, 이는 실서비스에 적용할 때 반드시 고려해야 할 점입니다.</span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-e29805df-493d-4a32-8789-5a611b6e7ad0\" data-compid=\"SE-e29805df-493d-4a32-8789-5a611b6e7ad0\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-e29805df-493d-4a32-8789-5a611b6e7ad0\" data-direction=\"top\">\n<div id=\"SE-e29805df-493d-4a32-8789-5a611b6e7ad0\">\n<div id=\"SE-e29805df-493d-4a32-8789-5a611b6e7ad0\" data-compid=\"SE-e29805df-493d-4a32-8789-5a611b6e7ad0\" data-a11y-title=\"사진\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-e29805df-493d-4a32-8789-5a611b6e7ad0\" data-direction=\"top\">\n<div>\n<div id=\"SE-e29805df-493d-4a32-8789-5a611b6e7ad0\">\n<div data-unitid=\"SE-e29805df-493d-4a32-8789-5a611b6e7ad0\" data-compid=\"\" data-direction=\"top\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"519\" data-origin-height=\"215\"><span data-url=\"https://blog.kakaocdn.net/dn/bSL4Sg/btsIvO3JfJn/csBbQKFXKKAG9EE5OCjOKK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bSL4Sg/btsIvO3JfJn/csBbQKFXKKAG9EE5OCjOKK/img.jpg\" data-alt=\"Partition을 지원하는 Kafka cousumer group의 구조\"><img src=\"https://blog.kakaocdn.net/dn/bSL4Sg/btsIvO3JfJn/csBbQKFXKKAG9EE5OCjOKK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbSL4Sg%2FbtsIvO3JfJn%2FcsBbQKFXKKAG9EE5OCjOKK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"600\" height=\"249\" data-origin-width=\"519\" data-origin-height=\"215\"/></span><figcaption>Partition을 지원하는 Kafka cousumer group의 구조</figcaption>\n</figure>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-608c567f-3e1e-4174-ad08-3ccd114e6363\" data-compid=\"SE-608c567f-3e1e-4174-ad08-3ccd114e6363\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-608c567f-3e1e-4174-ad08-3ccd114e6363\" data-direction=\"top\">\n<div id=\"SE-608c567f-3e1e-4174-ad08-3ccd114e6363\">\n<div id=\"SE-608c567f-3e1e-4174-ad08-3ccd114e6363\" data-compid=\"SE-608c567f-3e1e-4174-ad08-3ccd114e6363\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-608c567f-3e1e-4174-ad08-3ccd114e6363\" data-direction=\"top\">\n<div id=\"SE-608c567f-3e1e-4174-ad08-3ccd114e6363\">\n<div data-unitid=\"SE-608c567f-3e1e-4174-ad08-3ccd114e6363\" data-compid=\"\" data-direction=\"top\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"621\" data-origin-height=\"197\"><span data-url=\"https://blog.kakaocdn.net/dn/npYh8/btsIu22KWqw/RkzpHbeirIf34M98HJ1QPk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/npYh8/btsIu22KWqw/RkzpHbeirIf34M98HJ1QPk/img.jpg\" data-alt=\"단일 Stream Redis stream cousumer group의 구조\"><img src=\"https://blog.kakaocdn.net/dn/npYh8/btsIu22KWqw/RkzpHbeirIf34M98HJ1QPk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FnpYh8%2FbtsIu22KWqw%2FRkzpHbeirIf34M98HJ1QPk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"600\" height=\"190\" data-origin-width=\"621\" data-origin-height=\"197\"/></span><figcaption>단일 Stream Redis stream cousumer group의 구조</figcaption>\n</figure>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-e9465d19-1241-4b4f-95c5-50a2277c372b\" data-compid=\"SE-e9465d19-1241-4b4f-95c5-50a2277c372b\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-e9465d19-1241-4b4f-95c5-50a2277c372b\" data-direction=\"top\">\n<div>\n<div id=\"SE-65d6d43d-9c7f-4a33-add0-3e989e0afe0a\">\n<p id=\"SE-2c787147-9cc6-4a3e-b992-addc26e3ae16\" style=\"text-align: center;\" data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\"><span style=\"color: #000000;\">출처 :<span>&nbsp;</span></span><span style=\"color: #000000;\" data-href=\"https://mattwestcott.org/blog/redis-streams-vs-kafka\"><a href=\"https://mattwestcott.org/blog/redis-streams-vs-kafka\">https://mattwestcott.org/blog/redis-streams-vs-kafka</a></span></span></p>\n<p id=\"SE-bbe73690-fbfd-49d0-b88d-a389de44d439\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-d7e416de-66bf-4f23-becc-cfc8c0e1abb0\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-a4680370-73c5-4265-aeb4-8c3c8cca5851\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">그리고 또 한 가지.</span></p>\n<p id=\"SE-24b0340e-ccac-4dfa-a27a-6f2b4b3c5c75\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">in-memory 기반의 저장소이기 때문에 memory 관리에 신경을 많이 써야 합니다.</span></p>\n<p id=\"SE-b3a1c6b3-6467-41ec-ac68-ee4aba251ae9\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">예를 들어, XACK를 받지 못한 pending 메시지를 다시 처리하지 않으면, 그 메시지들은 점점 쌓여가면서 Redis cluster의 memory를 위태롭게 만들 것입니다.</span></p>\n<p id=\"SE-bdf5cc9a-642c-4ce3-b23b-140131123daa\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">그래서 저도 1분마다 스케줄을 돌며 pending 메시지를 처리하는 로직을 추가해 memory full 이슈를 방지하고 있습니다.</span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-c0fd154c-f351-44b0-842a-3321011e41e6\" data-compid=\"SE-c0fd154c-f351-44b0-842a-3321011e41e6\" data-a11y-title=\"코드\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-c0fd154c-f351-44b0-842a-3321011e41e6\" data-direction=\"top\">\n<div>\n<div>\n<div>\n<pre class=\"kotlin\" style=\"background-color: #f8f8f8; color: #383a42;\"><code>@Scheduled(fixedRate = 60000)\npublic void PendingMessagesSummaryScheduler() {\n    PendingMessagesSummary pendingSummary = this.redisOperator.pendingSummary(streamKey, consumerGroupName);\n\n    // 로그 출력\n    pendingSummary.getPendingMessagesPerConsumer().forEach((consumer, count) -&gt; {\n        log.info(\"Consumer: \" + consumer + \", Pending Messages: \" + count);\n    });\n\n    // pendingSummary와 TotalPendingMessages 체크 및 메시지 처리\n    if (pendingSummary != null &amp;&amp; pendingSummary.getTotalPendingMessages() &gt; 0) {\n        PendingMessages pendingMessages = this.redisOperator.pending(streamKey, consumerGroupName);\n        pendingMessages.toList().stream()\n            .filter(pendingMessage -&gt; !ObjectUtils.isEmpty(pendingMessage))\n            .forEach(pendingMessage -&gt; {\n                List&lt;ObjectRecord&lt;String, String&gt;&gt; messages = this.redisOperator.read(streamKey, consumerGroupName, consumerName, pendingMessage.getIdAsString());\n                messages.stream()\n                    .filter(recordMessage -&gt; !ObjectUtils.isEmpty(recordMessage))\n                    .forEach(recordMessage -&gt; {\n                        // 메시지 처리 로직\n\n                    });\n                // 메시지 ACK\n                this.redisTemplate.opsForStream().acknowledge(streamKey, consumerGroupName, pendingMessage.getIdAsString());\n            });\n    }\n}</code></pre>\n</div>\n<div>&nbsp;</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-42274b60-2da6-44b5-ad35-b53dacb09eb2\" data-compid=\"SE-42274b60-2da6-44b5-ad35-b53dacb09eb2\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-42274b60-2da6-44b5-ad35-b53dacb09eb2\" data-direction=\"top\">\n<div>\n<div id=\"SE-c7cb55f7-fe1f-4819-bfc7-802c1132f4ae\">\n<p id=\"SE-693159ae-8306-4082-a9ec-3c18d5f8f95d\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-47cb3487-82b5-4ae5-9341-c0c88e5a4946\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-b83569b2-1c27-42da-8743-44d9dc71ad3f\" data-ke-size=\"size16\">&nbsp;</p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-10c8da58-aef9-4e4e-96a5-5ff41f728b27\" data-compid=\"SE-10c8da58-aef9-4e4e-96a5-5ff41f728b27\" data-a11y-title=\"소제목\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-10c8da58-aef9-4e4e-96a5-5ff41f728b27\" data-direction=\"top\">\n<div>\n<div id=\"SE-b594a902-f03d-4223-b683-2e9c5487e358\">\n<h2 id=\"SE-71dc92dd-b306-42bd-bbdd-9dc5b4d5ddeb\" style=\"color: #000000;\" data-ke-size=\"size26\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\"><b>마치며</b></span></h2>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p style=\"text-align: justify;\" data-ke-size=\"size16\">&nbsp;</p>\n<div id=\"SE-f2b009b7-1f8d-4ff8-a0e7-505550c6290a\" data-compid=\"SE-f2b009b7-1f8d-4ff8-a0e7-505550c6290a\" data-a11y-title=\"사진\">\n<div data-unitid=\"\" data-compid=\"SE-f2b009b7-1f8d-4ff8-a0e7-505550c6290a\" data-direction=\"top\">\n<div id=\"SE-ca80826c-94e0-4ff5-9146-d700c00e5dbb\">\n<div id=\"SE-f2b009b7-1f8d-4ff8-a0e7-505550c6290a\" data-compid=\"SE-f2b009b7-1f8d-4ff8-a0e7-505550c6290a\" data-a11y-title=\"사진\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-f2b009b7-1f8d-4ff8-a0e7-505550c6290a\" data-direction=\"top\">\n<div>\n<div id=\"SE-f2b009b7-1f8d-4ff8-a0e7-505550c6290a\">\n<div data-unitid=\"SE-f2b009b7-1f8d-4ff8-a0e7-505550c6290a\" data-compid=\"\" data-direction=\"top\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"768\" data-origin-height=\"267\"><span data-url=\"https://blog.kakaocdn.net/dn/blcKht/btsIv8t7Obt/B9tykHX6n0BhZ1UzhNlbSK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/blcKht/btsIv8t7Obt/B9tykHX6n0BhZ1UzhNlbSK/img.png\" data-alt=\"Redis Stream 적용 전\"><img src=\"https://blog.kakaocdn.net/dn/blcKht/btsIv8t7Obt/B9tykHX6n0BhZ1UzhNlbSK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FblcKht%2FbtsIv8t7Obt%2FB9tykHX6n0BhZ1UzhNlbSK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"768\" height=\"267\" data-origin-width=\"768\" data-origin-height=\"267\"/></span><figcaption>Redis Stream 적용 전</figcaption>\n</figure>\n</div>\n<div id=\"SE-5a48b168-41af-4e85-a534-1895384ac2c7\" data-compid=\"SE-5a48b168-41af-4e85-a534-1895384ac2c7\" data-a11y-title=\"사진\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-5a48b168-41af-4e85-a534-1895384ac2c7\" data-direction=\"top\">\n<div>\n<div id=\"SE-5a48b168-41af-4e85-a534-1895384ac2c7\">\n<div>&nbsp;</div>\n<div data-unitid=\"SE-5a48b168-41af-4e85-a534-1895384ac2c7\" data-compid=\"\" data-direction=\"top\"><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"765\" data-origin-height=\"268\"><span data-url=\"https://blog.kakaocdn.net/dn/UKiVE/btsIwTCYMz8/zxfAyKBSfE97ad8RswKHSk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/UKiVE/btsIwTCYMz8/zxfAyKBSfE97ad8RswKHSk/img.png\" data-alt=\"Redis Stream 적용 후\"><img src=\"https://blog.kakaocdn.net/dn/UKiVE/btsIwTCYMz8/zxfAyKBSfE97ad8RswKHSk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FUKiVE%2FbtsIwTCYMz8%2FzxfAyKBSfE97ad8RswKHSk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" width=\"765\" height=\"268\" data-origin-width=\"765\" data-origin-height=\"268\"/></span><figcaption>Redis Stream 적용 후</figcaption>\n</figure>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"SE-7ee1f2b0-a714-4669-9e65-8b30e4d5826f\" data-compid=\"SE-7ee1f2b0-a714-4669-9e65-8b30e4d5826f\" data-a11y-title=\"본문\">\n<div>\n<div data-unitid=\"\" data-compid=\"SE-7ee1f2b0-a714-4669-9e65-8b30e4d5826f\" data-direction=\"top\">\n<div>\n<div id=\"SE-02edf51b-92e7-4e2f-bcb8-c6a57e6e9e2d\">\n<p id=\"SE-bf6bfcd0-4542-4cca-970d-19af03efff87\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">데이터 파이프라인 applicaion에 Redis Stream을 적용 후,</span></p>\n<p id=\"SE-2db906b3-8936-4cbe-a53e-8800aa493289\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">UTS Push 발송 시 지연되던 트래픽 처리가 완전하게 해소되어, BDS 행사기간에도 원활하게 서비스가 가능하게 되었습니다.</span></p>\n<p id=\"SE-6cd6cb97-2cab-4575-8841-e6b0855fee35\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Redis stream은 분산 처리 환경에서 쉽고 빠르게 실시간 데이터 처리를 가능하게 만들어주는 아주 효율적인 도구입니다.</span></p>\n<p id=\"SE-38a26d28-e877-4047-813d-9546cac74fc1\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">이 포스팅을 통해서 Redis Stream의 개념과 동작 방식에 대해서 간단하게나마 파악하고, 추후 Redis Stream을 이용한 애플리케이션을 구축하는데 작은 도움이 되었으면 하는 바람입니다.</span></p>\n<p id=\"SE-86da73f1-502d-4546-a181-08e1b1fcbe7e\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-a64c4b1e-fe02-424f-a7ee-df4d8150007e\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-c3dc5a9e-a343-44ac-9683-70e65485d380\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-d007608b-6eaf-49e9-993b-dd36f1741769\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-3d107c9b-9460-42e7-8b3e-b431203876e4\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-1d5667f3-9023-4457-aa24-aecad03020d0\" data-ke-size=\"size16\">&nbsp;</p>\n<p id=\"SE-589e507f-4171-4d24-b177-f44a9b0c8033\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">&lt;참고문서&gt;</span></p>\n<p id=\"SE-e467964e-8d0c-4f7d-ad03-deea9d4649f1\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\" data-href=\"https://nimasrn.medium.com/introduction-to-redis-streams-1d6a95ab141\"><a href=\"https://nimasrn.medium.com/introduction-to-redis-streams-1d6a95ab141\">https://nimasrn.medium.com/introduction-to-redis-streams-1d6a95ab141</a></span></p>\n<p id=\"SE-8c5f199d-1b03-40e3-b2fd-a17fc3134293\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\" data-href=\"https://redis.io/docs/latest/develop/data-types/streams/\"><a href=\"https://redis.io/docs/latest/develop/data-types/streams/\">https://redis.io/docs/latest/develop/data-types/streams/</a></span></p>\n<p id=\"SE-e042d8ec-bd31-4584-9faa-9ccdc721abbb\" data-ke-size=\"size16\"><span style=\"color: #000000; font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\" data-href=\"https://jybaek.tistory.com/935\"><a href=\"https://jybaek.tistory.com/935\">https://jybaek.tistory.com/935</a></span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p style=\"text-align: justify;\" data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "안녕하세요 Data Product 팀 박상우입니다.\n \n이번에 제가 소개해드릴 내용은 팀 내 session Info data 적재 및 API 서비스 구축에 적용한 Redis Stream에 대한 이야기입니다.\n \n저희 팀에서는 User의 행동 정보를 수집하는 프레임워크 중 하나인 montelena receiver를 통해 수집한 데이터 (view, event, impression 등)를 post Processor라는 데이터 파이프라인 application을 통해 적재, 가공해서 각종 지표 트래킹 및 분석에 활용할 수 있도록 제공하고 있습니다.\n \nPost Processor Data Pipeline\n\n\n\n\n \n그중 유니크한 active user를 식별하기 위해 session_id를 발급하고, 그 히스토리를 남겨 광고에 활용하고 있는데,\n'Big Smile Day' (지마켓 최고의 연례행사인 빅스마일데이, 이하 BDS)\n'User Targeting Content' (이하 UTC) Push 발송 등 유저의 유입이 급증해서 트래픽이 대폭 증가할 경우 데이터 처리가 지연되는 현상이 발생하게 되었습니다.\n \n이 문제를 해결하기 위해서는 부하를 발생시키는 로직을 분리해서 별도로 처리하도록 하는 application의 개발이 요구되는 상황이었고,\n이에 Redis stream을 사용해서 session_id 히스토리 적재 로직을 수행하는 신규 consumer를 개발했던 과정을 간단하게나마 공유해보고자 합니다.\n \n \n \nRedis Stream의 특징과 장점\n \n2018년 10월 17일, Redis 5.0 버전이 출시되었습니다.\n \n \n\n\n\n \n \n이전 버전에서 많은 부분이 개선되었지만 그중 가장 중요한 기능 추가 중 하나가 바로 Redis stream 이였는데요.\n고가용성 데이터 스트리밍 처리가 도입되면서, 데이터의 일관성과 안정성을 보장하면서 대용량 데이터 스트림을 실시간으로 처리할 수 있게 되었습니다.\n동시에 inmemory 기반으로 동작하는 key value 기반의 캐시를 사용하기 때문에 속도가 빠르다는 장점으로 사내에서도 저장소로 널리 사용되고 있죠.\n \n \n왜 Redis Stream을 선택했는가?\n \n처음에는 메시지 큐로 kafka나 MQ를 생각했었는데, 새로운 플랫폼을 적용해야 하다 보니 개발 공수도 늘어나고 리소스도 많이 소모될 거라는 결론을 내렸습니다.\n거기다 BSD가 얼마 남지 않은 시점이라 그전에 개발을 완료해야 된다는 시간적인 제한도 허들이었습니다.\n이미 session_id 저장소로 redis를 사용하고 있었고, 최대한 기존 로직을 건드리지 않으면서, 빠르게 히스토리를 적재할 수 있는 방법을 찾던 중,\nkafka와 유사한 기능들을 제공하면서 사내 openshift 환경의 여러 개 pod에서 구동해도 데이터 중복이나 유실 없이 처리가 가능한 Redis stream을 선택하게 되었습니다.\n \n \n \nRedis Pub/Sub과 Redis Stream?\n \n일반적으로 Redis를 이용해 메시지를 Broadcasting 할 때는 pub/sub을 많이 사용합니다.\n하지만 이 방식은 publisher가 메시지를 발행했을 때 subscriber가 존재하지 않거나 애플리케이션에 이슈가 발생하면 수신 여부에 관계없이 메시지가 휘발되는 단점이 있습니다.\n또한, 여러 개의 subscriber를 구동하면 모두에게 동일한 메시지를 발행해 데이터가 중복되는 이슈가 발생합니다.\n \nRedis Pub / Sub\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n반면, Redis Stream은 휘발성이 아니라 Kafka의 offset 개념처럼 마지막으로 수신한 record id를 저장하고 XADD, XREADGROUP, XACK, XPENDING, XCLAIM으로 이어지는 처리 프로세스를 통해 메시지를 컨트롤할 수 있는 다양한 방법을 제공합니다.\n \nRedis Stream\n\n\n\n\n\n\n\n\n\n\n\n\n\n출처 : https://jybaek.tistory.com/935\n \n \n또한, Redis Stream은 consumer group을 지원하기 때문에 producer가 발행한 메시지를 여러 개의 consumer가 하나의 그룹을 형성해서 중복 없이 순차적으로 병렬 처리할 수 있습니다.\n그리고 XACK 명령어를 사용해 메시지 처리 여부를 확인할 수 있으며, 일정 시간 동안 처리되지 못한 메시지들도 Pending Entries List를 이용해서 재처리할 수 있는 방법을 제공합니다.\n \n \n \nRedis Stream\n\n\n\n\n\n\n\n\n\n\n\n\n\n출처 : https://jybaek.tistory.com/935\n \n \nRedis stream Development\n \n이제 실제로 코드를 보며 Redis stream으로 어떻게 개발을 진행했는지 간단히 알아보도록 하겠습니다.\n프로세스는 심플한 구조로 아래 flow chart를 참고해 주시면 되겠습니다.\n \n \n \n \nRedis Stream flow\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n<Publisher>\n먼저 Post Processor에서 트래픽 데이터를 가공/처리한 후, app에서 정의한 streamKey를 통해서 생성한 session 객체를 캡슐화해서 Redis Stream 메시지로 발행합니다.\nObjectRecord<String, String> record = StreamRecords.newRecord()\n\t\t\t\t.ofObject(GsonUtil.gson().toJson(session))\n\t\t\t\t.withStreamKey(streamKey);\n\nRecordId recordId = gmktRedisTemplate.opsForStream().add(record);\nif (Objects.isNull(recordId)) {\n    // Redis Stream record 처리에 실패했을 경우 로직 추가\n}\n \nopsForStream().add() 메서드를 통해서 메시지를 발행하면 recordId를 리턴하는데, 이 값은 각각의 메시지가 스트림에 추가될 때 Redis가 생성해 주는 고유의 id 값으로 보시면 됩니다.\n저는 stream key / value 형태의 ObjectRecord 객체를 사용해서 개발했지만,\n이외에도 value 값으로 Map<K, V> 형태로 데이터를 저장하고 읽을 수 있는 MapRecord라는 메서드도 지원하고 있습니다.\npublic interface MapRecord<S, K, V> extends Record<S, Map<K, V>>, Iterable<Map.Entry<K, V>> {\n\n\tstatic <S, K, V> MapRecord<S, K, V> create(S stream, Map<K, V> map) {\n\n\t\tAssert.notNull(stream, \"Stream must not be null\");\n\t\tAssert.notNull(map, \"Map must not be null\");\n\n\t\treturn new MapBackedRecord<>(stream, RecordId.autoGenerate(), map);\n\t}\n}\n \n \n<Consumer>\n다음은 발행된 메시지를 컨슈밍 하고 처리하는 코드를 보여드리겠습니다.\n먼저 Spring boot 프로젝트에서 'spring-boot-starter-data-redis' 의존성을 추가하고 Redis 서버 설정을 완료합니다.\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-data-redis</artifactId>\n</dependency>\n \n그다음 'StreamListener' 인터페이스를 구현하고, afterPropertiesSet() 메서드를 @Orverride 해서 Redis Stream 메시지를 소비하는 consumer Group과 Listener Container를 설정하고 초기화합니다.\n@Override\npublic void afterPropertiesSet() throws Exception {\n    // Consumer Group 설정\n    createStreamConsumerGroup(streamKey, consumerGroupName);\n\n    // StreamMessageListenerContainer 설정\n    this.listenerContainer = StreamMessageListenerContainer.create(\n\t\t\t\tredisTemplate.getConnectionFactory(),\n\t\t\t\tStreamMessageListenerContainer.StreamMessageListenerContainerOptions.builder()\n\t\t\t\t.targetType(String.class)\n\t\t\t\t.pollTimeout(Duration.ofSeconds(2))\n\t\t\t\t.build()\n\t\t);\n\n    // Subscription 설정\n    this.subscription = this.listenerContainer.receive(\n            Consumer.from(this.consumerGroupName, consumerName),\n            StreamOffset.create(streamKey, ReadOffset.lastConsumed()),\n            this\n    );\n\n    // Redis listen 시작\n    this.listenerContainer.start();\n}\n\npublic void createStreamConsumerGroup(String streamKey, String consumerGroupName){\n\tif (!redisTemplate.hasKey(streamKey)){\n\t\tRedisClusterAsyncCommands commands = (RedisClusterAsyncCommands) this.redisTemplate\n\t\t\t\t.getConnectionFactory()\n\t\t\t\t.getClusterConnection()\n\t\t\t\t.getNativeConnection();\n\t\t\n        CommandArgs<String, String> args = new CommandArgs<>(StringCodec.UTF8)\n\t\t\t\t.add(CommandKeyword.CREATE)\n\t\t\t\t.add(streamKey)\n\t\t\t\t.add(consumerGroupName)\n\t\t\t\t.add(\"0\")\n\t\t\t\t.add(\"MKSTREAM\");\n\n\t\tcommands.dispatch(CommandType.XGROUP, new StatusOutput(StringCodec.UTF8), args);\n\t}\n\telse{\n\t\tif(!isStreamConsumerGroupExist(streamKey, consumerGroupName)){\n\t\t\tthis.redisTemplate.opsForStream().createGroup(streamKey, ReadOffset.from(\"0\"), consumerGroupName);\n\t\t}\n\t}\n}\n \nPublisher에서 설정한 StreamKey와 Consumer Name을 세팅해서 Consumer Group을 생성합니다.\n그리고 Consumer 객체를 생성, Offset 설정, Subscriber 옵션 등 세부적인 설정을 완료한 뒤, Listener Container를 시작하면 Redis Stream 메시지를 비동기적으로 Listner에게 전달하게 됩니다.\n이 과정을 통해서 여러 개의 Consumer Group을 사용해서 하나의 Redis Stream을 병렬로 처리할 수 있습니다.\n \n이렇게 전달되는 메시지들은 마찬가지로 'StreamListener' 인터페이스가 제공하는 onMessage 메서드를 구현해서 처리하게 됩니다.\n@Override\npublic void onMessage(ObjectRecord<String, String> message) {\n    \n    String stream = message.getStream();\n    String recordId = message.getId().getValue();\n    \n    try {\n        // 처리할 로직 구현\n        if (StringUtils.isNotEmpty(message.getValue())) {\n            // To-Do\n        }\n        // 이후, ack stream\n        this.redisTemplate.opsForStream().acknowledge(streamKey, consumerGroupName, recordId);\n        \n    } catch (Exception e) {\n        // TODO: handle exception\n        e.printStackTrace();\n        this.redisOperator.delete(stream, recordId);\n    }\n}\n \n메시지를 처리하고 나면 'ackStream' 메소드를 호출해서 Redis Stream 메시지가 성공적으로 처리되었음을 알리고, 해당 메시지를 대기열에서 제거합니다.\nException 이 발생할 경우 recordId를 통해 메시지를 삭제 처리할 수도 있고, 다양한 시나리오로 처리가 가능하니 용도에 맞게 사용하시면 되겠습니다.\n \n \n \nRedis stream 적용 시 고려할 점들\n \nRedis Stream은 파티션 개념이 없기 때문에 하나의 stream을 여러 개의 consumer가 병렬 처리하는 구조로 동작합니다.\n그래서 Redis cluster 구조에서 sharding 되어 있는 node에 메시지를 고르게 보내려면 추가적으로 N개의 stream을 각각의 node에 할당하도록 추가 개발이 필요합니다.\n이러한 특징 때문에 produce 된 순서대로 메시지를 처리한다는 보장이 없어지는데, 이는 실서비스에 적용할 때 반드시 고려해야 할 점입니다.\nPartition을 지원하는 Kafka cousumer group의 구조\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n단일 Stream Redis stream cousumer group의 구조\n\n\n\n\n\n\n\n\n\n\n\n\n\n출처 : https://mattwestcott.org/blog/redis-streams-vs-kafka\n \n \n그리고 또 한 가지.\nin-memory 기반의 저장소이기 때문에 memory 관리에 신경을 많이 써야 합니다.\n예를 들어, XACK를 받지 못한 pending 메시지를 다시 처리하지 않으면, 그 메시지들은 점점 쌓여가면서 Redis cluster의 memory를 위태롭게 만들 것입니다.\n그래서 저도 1분마다 스케줄을 돌며 pending 메시지를 처리하는 로직을 추가해 memory full 이슈를 방지하고 있습니다.\n@Scheduled(fixedRate = 60000)\npublic void PendingMessagesSummaryScheduler() {\n    PendingMessagesSummary pendingSummary = this.redisOperator.pendingSummary(streamKey, consumerGroupName);\n\n    // 로그 출력\n    pendingSummary.getPendingMessagesPerConsumer().forEach((consumer, count) -> {\n        log.info(\"Consumer: \" + consumer + \", Pending Messages: \" + count);\n    });\n\n    // pendingSummary와 TotalPendingMessages 체크 및 메시지 처리\n    if (pendingSummary != null && pendingSummary.getTotalPendingMessages() > 0) {\n        PendingMessages pendingMessages = this.redisOperator.pending(streamKey, consumerGroupName);\n        pendingMessages.toList().stream()\n            .filter(pendingMessage -> !ObjectUtils.isEmpty(pendingMessage))\n            .forEach(pendingMessage -> {\n                List<ObjectRecord<String, String>> messages = this.redisOperator.read(streamKey, consumerGroupName, consumerName, pendingMessage.getIdAsString());\n                messages.stream()\n                    .filter(recordMessage -> !ObjectUtils.isEmpty(recordMessage))\n                    .forEach(recordMessage -> {\n                        // 메시지 처리 로직\n\n                    });\n                // 메시지 ACK\n                this.redisTemplate.opsForStream().acknowledge(streamKey, consumerGroupName, pendingMessage.getIdAsString());\n            });\n    }\n}\n \n \n \n \n마치며\n \nRedis Stream 적용 전\n\n\n\n\n\n\n\n \nRedis Stream 적용 후\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n데이터 파이프라인 applicaion에 Redis Stream을 적용 후,\nUTS Push 발송 시 지연되던 트래픽 처리가 완전하게 해소되어, BDS 행사기간에도 원활하게 서비스가 가능하게 되었습니다.\nRedis stream은 분산 처리 환경에서 쉽고 빠르게 실시간 데이터 처리를 가능하게 만들어주는 아주 효율적인 도구입니다.\n이 포스팅을 통해서 Redis Stream의 개념과 동작 방식에 대해서 간단하게나마 파악하고, 추후 Redis Stream을 이용한 애플리케이션을 구축하는데 작은 도움이 되었으면 하는 바람입니다.\n \n \n \n \n \n \n<참고문서>\nhttps://nimasrn.medium.com/introduction-to-redis-streams-1d6a95ab141\nhttps://redis.io/docs/latest/develop/data-types/streams/\nhttps://jybaek.tistory.com/935",
        "guid": "https://dev.gmarket.com/113",
        "categories": [
          "Infra"
        ],
        "isoDate": "2024-07-11T06:55:03.000Z"
      }
    ]
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": [
      {
        "title": "Bulkhead 패턴을 사용한 장애 격리",
        "link": "https://hudi.blog/bulkhead-pattern/",
        "pubDate": "Sun, 07 Jul 2024 02:30:00 GMT",
        "content:encodedSnippet": "배경\n최근 특정 데이터를 Apache POI를 사용해서 엑셀 파일로 만들어서 유저에게 서빙하는 기능을 개발했었다. 유즈 케이스를 조금 찾아보았는데, Apache POI로 규모가 큰 데이터를 다룰 때 Out of Memory 가 쉽게 발생한다는 사실을 알게 되었다. 다른 중요한 기능도 수행하고 있는 서버인데, 엑셀 파일을 만들다가 Out of Memory가 발생하면 서버 자체가 죽어버리므로, 발생해서는 안되는 문제였다. 따라서 해당 기능을 동시에 요청할 수 있는 최대 수를 제어할 필요가 있었다. 그렇게 Bulkhead 패턴을 공부하게 되었다.\n💭 사실 가장 좋은 방법은 해당 기능을 수행하는 별개의 서비스를 만들어서 물리적으로 장애를 격리하는 방법이겠지만, 실무를 하다보면 항상 일정, 운영비용과 완성도 사이를 저울질하게 되는 것 같다. 나는 별개 서비스를 만드는 것은 오버 엔지니어링이라고 판단하였고, 기존 서비스에 해당 기능을 붙이되 Bulkhead 패턴을 사용해서 요청량을 제어하는 것이 합리적이라고 판단했다.\n💡 POI의 엑셀 파일 접근을 위한 구현체는 HSSF, XSSF, SXSSF 3개가 있는데, 이 중 SXSSF는 스트리밍 방식을 사용하여 메모리를 과도하게 점유하는 문제를 해결한 구현체이다. 실제로 운영에서는 SXSSF를 사용하여, 눈에 띄게 메모리 사용량이 늘지 않았다.\n\nBulkhead Pattern\n\n    \n      \n    \n  \n  \n    \n    출처: https://en.wikipedia.org/wiki/Bulkhead_(partition)\n  \nBulkhead는 한국어로 격벽을 의미한다. 격벽이란 선박의 공간을 여러 구획으로 나누기 위해 사용되는 벽을 의미한다. 선박의 공간을 격벽으로 구획을 나누면, 어느 한 곳에 물이 차더라도 다른 구획은 이에 영향 받지 않기 때문에, 선박은 안전하게 항해할 수 있다.\nBulkhead 패턴은 선박의 격벽으로부터 영감을 얻어 만들어진 패턴으로, 리소스를 격리하여, 일부 컴포넌트에 문제가 발생하더라도, 그것이 시스템 전체로의 장애로 전파되지 않게끔 만들어주는 패턴이다.\n\nwithout bulkhead vs with bulkhead\n\n    \n      \n    \n  \n  \n    \n    Bulkhead 를 사용하지 않은 케이스와 사용한 케이스\n  \n예를 들어보자. MSA 환경에서 서비스 A, B, C가 존재한다. 서비스 A의 B API 는 서비스 B를 호출해 응답을 만들고, C API 는 서비스 C를 호출해 응답을 만들어낸다고 가정해보자.\n그런데 서비스 B에 장애가 발생하여, 응답을 매우 느리게 주는 상황이라면? 이런 상황에서 서비스 A의 B API 호출이 발생한다면, 서비스 B의 응답을 기다리느라 계속 쓰레드를 점유할 것이고, 장애가 길어짐에 따라 서비스 A의 톰캣 쓰레드 풀이 고갈될 것이다. 그렇다면 C API 는 서비스 B에 의존하지 않지만, 톰캣 쓰레드를 할당 받지 못해 덩달아 장애의 영향을 받게 된다.\n여기에 Bulkhead 패턴을 사용하여, 두 쓰레드 풀을 격리하면 어떻게 될까? 여전히 서비스 B에 의존적인 B API 의 요청을 처리하는 쓰레드 풀은 고갈 상태가 유지되겠지만, 서비스 C에 의존적인 C API 의 요청을 처리하는 쓰레드 풀은 고갈 상태가 아니므로 서비스 B 장애 여부와 무관하게 요청을 잘 처리할 것이다.\n즉, Bulkhead 패턴의 핵심 아이디어는 ‘리소스 격리를 통한 장애 격리’ 이다. 예시에서는 쓰레드 풀을 예로 들었지만, 커넥션 풀과 같은 다른 자원에도 적용해볼 수 있다. 또한 꼭 리소스 풀을 물리적으로 분리하지 않고, 세마포어1 등의 상호배제 메커니즘 등을 사용하여 Bulkhead 를 구현할 수도 있다.\n\n장애 전파 재현 및 Bulkhead 구현\n코틀린 코드로 아주 간단하게 리소스 고갈로 인한 장애 전파를 재현해보고, 이를 격벽으로 나누어 장애 전파를 차단하는 Bulkhead 패턴을 구현해보자.\n\n리소스 고갈로 인한 장애 전파 재현\nfun main() {\n    val tomcatThreadPool = Executors.newFixedThreadPool(4)\n\n    val startTime = System.currentTimeMillis()\n\n    for (i in (1..4)) {\n        tomcatThreadPool.execute { callBService(startTime) }\n    }\n\n    for (i in (1..4)) {\n        tomcatThreadPool.execute { callCService(startTime) }\n    }\n}\n\nfun callBService(callTime: Long) = println(\"* 서비스 B 호출 완료 | 소요 시간: ${System.currentTimeMillis() - callTime}ms\")\nfun callCService(callTime: Long) = println(\"* 서비스 C 호출 완료 | 소요 시간: ${System.currentTimeMillis() - callTime}ms\")\n\n이해를 돕기 위해 아래와 같이 가정한다.\nmain 함수 = 서비스 A 애플리케이션\ntomcatThreadPool = 서비스 A의 톰캣 쓰레드 풀 (사이즈 4)\ntomcatThreadPool.execute() = 서비스 A로 들어온 HTTP 요청\ncallBService() , callCService() = 서비스 B, C의 API를 호출하는 함수\n위 코드를 실행하면, tomcatThreadPool 의 쓰레드들은 서비스 B를 호출하기 위해 모두 할당된 후, 작업을 잘 마치고 난 뒤 서비스 C를 호출하기 위해 할당될 것이다. 그럼 아래와 같이 정상적으로 작업이 완료될 것이다.\n* 서비스 B 호출 완료 | 소요 시간: 1ms\n* 서비스 B 호출 완료 | 소요 시간: 1ms\n* 서비스 B 호출 완료 | 소요 시간: 1ms\n* 서비스 B 호출 완료 | 소요 시간: 1ms\n* 서비스 C 호출 완료 | 소요 시간: 6ms\n* 서비스 C 호출 완료 | 소요 시간: 6ms\n* 서비스 C 호출 완료 | 소요 시간: 6ms\n* 서비스 C 호출 완료 | 소요 시간: 6ms\n\n그런데 서비스 B의 데이터베이스에 장애가 발생해서, 서비스 B가 굉장히 느리게 응답을 하기 시작했다. 이를 아래와 같이 Thread.sleep() 을 사용하여 표현한다.\nfun callBService(callTime: Long) {\n    Thread.sleep(20_000) // 데이터베이스 장애 발생으로, 굉장히 느리게 응답한다고 가정한다.\n    println(\"* 서비스 B 호출 완료 | 소요 시간: ${System.currentTimeMillis() - callTime}ms\")\n}\n\n이렇게 서비스 B에 장애가 발생한 상황에서는, 서비스 B를 호출하기 위한 쓰레드를 비정상적으로 오래 점유한다. 그렇게 되면 서비스 C만 필요한 요청이 톰캣 쓰레드를 할당받지 못하고, 아래와 장애가 전파된다.\n* 서비스 B 호출 완료 | 소요 시간: 20008ms\n* 서비스 C 호출 완료 | 소요 시간: 20026ms\n* 서비스 C 호출 완료 | 소요 시간: 20027ms\n* 서비스 C 호출 완료 | 소요 시간: 20027ms\n* 서비스 C 호출 완료 | 소요 시간: 20027ms\n* 서비스 B 호출 완료 | 소요 시간: 20008ms\n* 서비스 B 호출 완료 | 소요 시간: 20007ms\n* 서비스 B 호출 완료 | 소요 시간: 20007ms\n\n서비스 C를 호출하는 함수는 호출 즉시 결과를 반환할 수 있었으나, 서비스 B 호출로 인해 쓰레드 풀이 밀려 정상적으로 쓰레드를 할당받지 못하게 되었고, 그 결과 서비스 C를 호출하는 함수의 응답까지 덩달아 굉장히 느려졌다. 장애가 전파된 것이다. 실제 스프링 애플리케이션이었다면, 타임아웃이 발생하여 아예 응답을 주지 못하고 예외가 발생했을수도 있다.\n\nBulkhead 적용\n그럼 이제 tomcatThreadPool 을 격벽으로 분리해보자. 이를 bulkheadForB 쓰레드 풀과 bulkheadForC 쓰레드 풀을 만들고, 서비스 B와 서비스 C를 호출하는 메소드를 각각의 쓰레드 풀로 격리할 것이다.\nfun main() {\n    val bulkheadForB = Executors.newFixedThreadPool(4)\n    val bulkheadForC = Executors.newFixedThreadPool(4)\n\n    val startTime = System.currentTimeMillis()\n\n    for (i in (1..4)) {\n        // 서비스 B를 호출하는 함수는, bulkheadForB 쓰레드 풀에서 실행\n        bulkheadForB.execute { callBService(startTime) }\n    }\n\n    for (i in (1..4)) {\n        // 서비스 C를 호출하는 함수는, bulkheadForC 쓰레드 풀에서 실행\n        bulkheadForC.execute { callCService(startTime) }\n    }\n}\n\n그럼 결과는 아래와 같을 것이다. 서비스 C를 호출하는 메서드는 더이상 서비스 B의 장애에 영향을 받지 않는다.\n* 서비스 C 호출 완료 | 소요 시간: 2ms\n* 서비스 C 호출 완료 | 소요 시간: 2ms\n* 서비스 C 호출 완료 | 소요 시간: 2ms\n* 서비스 C 호출 완료 | 소요 시간: 2ms\n* 서비스 B 호출 완료 | 소요 시간: 20010ms\n* 서비스 B 호출 완료 | 소요 시간: 20009ms\n* 서비스 B 호출 완료 | 소요 시간: 20008ms\n* 서비스 B 호출 완료 | 소요 시간: 20009ms\n\n\nResilience4j의 Bulkhead\n실제 업무에서는 위와 같이 직접 Bulkhead 를 구현할 필요 없이 라이브러리를 사용하면 간단하게 Bulkhead 를 구현할 수 있다. 나는 이미 팀에서 Resilience4j 를 사용중이었으므로, 이 라이브러리가 제공하는 Bulkhead 기능을 사용하였다.\nResilience4j의 Bulkhead 는 쓰레드 풀 또는 세마포어를 사용하여 동시 호출 수를 제어하며, 이에 따라 특정 작업으로 인해 과도한 리소스를 차지하지 않도록 리소스를 격리할 수 있도록한다.\n공식 가이드는 여기에 접속해서 읽어보면 되고, 이 글에서는 간단히 적용만 해보겠다. 아래와 같이 resilience4j 의존성부터 추가한다.\nimplementation(\"io.github.resilience4j:resilience4j-spring-boot2:2.2.0\")\n\n그리고 application.properties 에 아래와 같이 추가한다.\nresilience4j.bulkhead.instances.backendA.maxConcurrentCalls=4\nresilience4j.bulkhead.instances.backendA.maxWaitDuration=0\n\nmaxConcurrentCalls 는 허용할 최대 동시 호출 수, maxWaitDuration 은 최대 동시 호출 수에 도달했을 때 추가 요청이 들어온 경우 얼마나 기다려줄 것인지를 나타낸다. 지금과 같은 설정은 최대 4개의 동시 요청을 허용하며, 5번째 요청부터는 즉시 실패하도록 한다. backendA 는 벌크헤드의 이름이다.\n@RestController\nclass BulkheadController {\n\n    @Bulkhead(name = \"backendA\", type = Bulkhead.Type.SEMAPHORE)\n    @GetMapping(\"/bulkhead\")\n    fun bulkhead(): String {\n        Thread.sleep(10_000)\n        return \"DONE\"\n    }\n}\n\n위와 같이 간단하게 컨트롤러를 작성했다. type 은 Bulkhead.Type.SEMAPHORE 와 Bulkhead.Type.THREADPOOL 두가지가 있으며, 생략하면 기본값은 세마포어이다. 해당 엔트포인트로 4개를 초과한 동시 요청을 넣게 되면, 아래와 같이 BulkheadFullException 이 발생하는 것을 볼 수 있다.\n\n    \n      \n    \n  \n  \n    \n    BulkheadFullException 발생\n  \nhttps://hudi.blog/race-condition-critical-section-mutual-exclusion/#세마포어-semaphore",
        "content": "배경 최근 특정 데이터를 Apache POI를 사용해서 엑셀 파일로 만들어서 유저에게 서빙하는 기능을 개발했었다. 유즈 케이스를 조금 찾아보았는데, Apache POI로 규모가 큰 데이터를 다룰 때 Out of Memory…",
        "contentSnippet": "배경 최근 특정 데이터를 Apache POI를 사용해서 엑셀 파일로 만들어서 유저에게 서빙하는 기능을 개발했었다. 유즈 케이스를 조금 찾아보았는데, Apache POI로 규모가 큰 데이터를 다룰 때 Out of Memory…",
        "guid": "https://hudi.blog/bulkhead-pattern/",
        "isoDate": "2024-07-07T02:30:00.000Z"
      },
      {
        "title": "MySQL는 Order By가 없다면 정렬을 보장하지 않는다",
        "link": "https://hudi.blog/mysql-no-order-by-no-sorting-guarantee/",
        "pubDate": "Sat, 06 Jul 2024 20:30:00 GMT",
        "content:encodedSnippet": "MySQL이 알아서 PK로 정렬해줄 것이라는 오해\n흔히 SELECT 쿼리를 실행하면 Primary Key 기준으로 오름차순 정렬이 되는 것을 보고, MySQL의 기본 정렬은 PK 기준이라고 생각할 수도 있다.\nCREATE TABLE user\n(\n    id           BIGINT AUTO_INCREMENT PRIMARY KEY,\n    address      VARCHAR(255) NULL,\n    age          INT NOT NULL,\n    created_at   DATETIME(6) NULL,\n    email        VARCHAR(255) NULL,\n    first_name   VARCHAR(255) NULL,\n    last_name    VARCHAR(255) NULL,\n    phone_number VARCHAR(255) NULL\n);\n\n이를 확인해보기 위해서 위와 같이 user 테이블을 만들고, 실제와 비슷한 환경을 만들기 위해 10만개의 더미 데이터를 추가해두었다. 먼저, user 테이블에 대해서 아무런 조건 없는 단순한 SELECT 쿼리를 실행해보자.\nmysql> SELECT * FROM user;\n+--------+---------------+-----+----------------------------+-----------------------------------+------------+-----------+--------------+\n| id     | address       | age | created_at                 | email                             | first_name | last_name | phone_number |\n+--------+---------------+-----+----------------------------+-----------------------------------+------------+-----------+--------------+\n|      1 | 802 Main St   |  77 | 2022-10-09 12:32:10.119311 | grace.jones1@test.com             | Grace      | Jones     | 555-8533     |\n|      2 | 209 Maple St  |  39 | 2022-01-24 12:32:10.119335 | bob.miller2@dummy.com             | Bob        | Miller    | 555-4287     |\n|      3 | 592 Birch St  |  53 | 2024-06-17 12:32:10.119348 | john.miller3@test.com             | John       | Miller    | 555-4130     |\n|      4 | 914 Spruce St |  46 | 2021-09-06 12:32:10.119356 | grace.jones4@dummy.com            | Grace      | Jones     | 555-7132     |\n|      5 | 507 Oak St    |  60 | 2023-02-11 12:32:10.119363 | alice.jones5@example.com          | Alice      | Jones     | 555-8964     |\n|      6 | 710 Birch St  |  74 | 2022-03-28 12:32:10.119369 | alice.williams6@dummy.com         | Alice      | Williams  | 555-7837     |\n|      7 | 198 Oak St    |  44 | 2022-08-07 12:32:10.119376 | john.miller7@example.com          | John       | Miller    | 555-6914     |\n|      8 | 802 Oak St    |  44 | 2021-04-29 12:32:10.119382 | john.doe8@example.com             | John       | Doe       | 555-6634     |\n|      9 | 420 Birch St  |  71 | 2024-02-11 12:32:10.119388 | bob.brown9@example.com            | Bob        | Brown     | 555-7305     |\n|     10 | 732 Willow St |  54 | 2023-10-27 12:32:10.119395 | john.smith10@test.com             | John       | Smith     | 555-4544     |\n\n결과는 예상처럼 PK인 id 컬럼 기준으로 오름차순 정렬되어 보인다. 그렇다면 이번에는 좀 더 복잡한 조건을 만들어보고, 조회 쿼리에도 여러 조건을 추가해보자.\nmysql> create index user_age_email_index on user (age desc, email desc);\n\n우선 위와 같이 인덱스를 추가해보자. 그리고 아래와 같이 쿼리한다.\nmysql> SELECT * FROM user WHERE age > 25 AND email LIKE '%@test.com' LIMIT 10;\n+-------+---------------+-----+----------------------------+-----------------------------+------------+-----------+--------------+\n| id    | address       | age | created_at                 | email                       | first_name | last_name | phone_number |\n+-------+---------------+-----+----------------------------+-----------------------------+------------+-----------+--------------+\n| 56753 | 104 Ash St    |  80 | 2024-02-29 12:32:10.413366 | john.williams56753@test.com | John       | Williams  | 555-3182     |\n| 16364 | 951 Maple St  |  80 | 2021-01-21 12:32:10.205319 | john.williams16364@test.com | John       | Williams  | 555-2859     |\n|  9196 | 175 Birch St  |  80 | 2021-09-12 12:32:10.168647 | john.smith9196@test.com     | John       | Smith     | 555-2383     |\n|  6681 | 801 Pine St   |  80 | 2020-02-01 12:32:10.155685 | john.smith6681@test.com     | John       | Smith     | 555-8990     |\n| 11058 | 217 Birch St  |  80 | 2023-11-21 12:32:10.178208 | john.smith11058@test.com    | John       | Smith     | 555-9641     |\n| 97566 | 916 Birch St  |  80 | 2023-04-08 12:32:10.626287 | john.miller97566@test.com   | John       | Miller    | 555-2294     |\n| 53274 | 375 Birch St  |  80 | 2022-04-09 12:32:10.395543 | john.miller53274@test.com   | John       | Miller    | 555-6957     |\n| 47688 | 256 Birch St  |  80 | 2020-03-19 12:32:10.366987 | john.miller47688@test.com   | John       | Miller    | 555-7895     |\n| 15841 | 379 Spruce St |  80 | 2022-05-06 12:32:10.202662 | john.miller15841@test.com   | John       | Miller    | 555-3964     |\n|  9954 | 155 Birch St  |  80 | 2023-06-02 12:32:10.172515 | john.martinez9954@test.com  | John       | Martinez  | 555-6591     |\n+-------+---------------+-----+----------------------------+-----------------------------+------------+-----------+--------------+\n10 rows in set (0.02 sec)\n\n예상과 다르게 id 컬럼의 정렬이 뒤죽박죽 불규칙적이다. 왜 이런일이 발생할까?\n\n사실, MySQL은 정렬을 보장하지 않는다\n방금 전 알아본것 처럼 MySQL은 정렬 순서를 보장해주지 않는다.\nMySQL은 자신이 판단했을 때 가장 효율적으로 데이터를 탐색할 수 있는 순서대로 우리에게 데이터를 보여준다 (정확히는 그냥 DBMS가 데이터를 읽는 순서대로 우리에게 보여준다). 즉 쿼리, 인덱스, 실행 계획, 쿼리 옵티마이저의 동작, 데이터 스토리지 엔진, 물리적인 데이터의 위치 등 여러 조건들에 따라서 정렬 순서는 달라지고, 이는 예측 불가능하다.\n그렇다면 첫번째 SELECT * FROM user 쿼리는 왜 PK 기준으로 정렬되는 것 처럼 보였던 것일까? 이것은 그저 Clustered Index1에서 데이터가 PK 기준으로 물리적인 정렬이 되어 있어 가장 빠르게 탐색할 수 있는 방법이었기 때문이다.\n\n정렬을 보장해야한다면, Order By를 반드시 명세하자\n물론 데이터 조회 순서에 영향을 주는 모든 요소를 파악하고 동작을 예측해서, 데이터 정렬 순서를 예상해보는게 가능이야 하겠다만… 그런 수고를 들이느니 간단하게 SELECT 쿼리 마지막에 ORDER BY 를 추가하는게 훨씬 더 경제적이다.\nmysql> SELECT * FROM user WHERE age > 25 AND email LIKE '%@test.com' ORDER BY id  LIMIT 10;\n+----+---------------+-----+----------------------------+--------------------------+------------+-----------+--------------+\n| id | address       | age | created_at                 | email                    | first_name | last_name | phone_number |\n+----+---------------+-----+----------------------------+--------------------------+------------+-----------+--------------+\n|  1 | 802 Main St   |  77 | 2022-10-09 12:32:10.119311 | grace.jones1@test.com    | Grace      | Jones     | 555-8533     |\n|  3 | 592 Birch St  |  53 | 2024-06-17 12:32:10.119348 | john.miller3@test.com    | John       | Miller    | 555-4130     |\n| 10 | 732 Willow St |  54 | 2023-10-27 12:32:10.119395 | john.smith10@test.com    | John       | Smith     | 555-4544     |\n| 14 | 824 Maple St  |  37 | 2021-02-11 12:32:10.119419 | david.smith14@test.com   | David      | Smith     | 555-3876     |\n| 16 | 616 Birch St  |  31 | 2021-02-10 12:32:10.119432 | alice.johnson16@test.com | Alice      | Johnson   | 555-2375     |\n| 17 | 404 Birch St  |  56 | 2021-11-25 12:32:10.119438 | charlie.doe17@test.com   | Charlie    | Doe       | 555-9786     |\n| 19 | 201 Birch St  |  75 | 2023-08-13 12:32:10.119450 | hank.jones19@test.com    | Hank       | Jones     | 555-9836     |\n| 24 | 808 Maple St  |  45 | 2024-05-23 12:32:10.119480 | david.jones24@test.com   | David      | Jones     | 555-7736     |\n| 28 | 274 Main St   |  35 | 2022-05-16 12:32:10.119504 | bob.davis28@test.com     | Bob        | Davis     | 555-4227     |\n| 31 | 640 Cedar St  |  40 | 2019-11-08 12:32:10.119522 | jane.doe31@test.com      | Jane       | Doe       | 555-8499     |\n+----+---------------+-----+----------------------------+--------------------------+------------+-----------+--------------+\n10 rows in set (0.02 sec)\n\nORDER BY 를 추가하고 나서야, (당연하게도) id 기준으로 정렬되어 결과를 보여주는 것을 볼 수 있다.\n\nSQL-92 명세\n사실 SQL의 이런 동작 방식은 SQL-92 이라는 SQL 표준 명세2를 보아도 알 수 있다.\n\n    \n      \n    \n  \n  \n    \n    SQL-92 내용 발췌\n  \nIf an <order by clause> is not specified, then the ordering of the rows of Q is implementation-dependent.\nSQL-92 문서를 읽어보면 중후반부에 ‘만일 order by 절이 명세되지 않았다면, Q(쿼리)의 정렬은 구현에 의존한다.’ 라는 내용이 명확히 존재하는 것을 알 수 있다.\n따라서 예시를 MySQL로 들었지만, 이런 특징은 비단 MySQL 뿐 아니라 Oracle, SQL Server 와 같은 다른 벤더의 DBMS 도 마찬가지이다3.\n\nDBMS는 굳이 PK 기준 정렬을 해줄 의무가 없다\n그럼 MySQL을 포함한 여러 DBMS 들은 배려심이 없어서 이렇게 개발자를 당황하게 만드는 걸까?\n이건 내 개인적인 생각이지만, 잘 생각해보면 MySQL은 굳이 ORDER BY 가 없는 질의에 대해서 PK 기준으로 정렬을 해줄 의무가 없다. 대부분의 경우 PK를 auto_increment 로 사용하지만, UUID 처럼 sequential 하지 않은 값을 사용하는 경우도 충분히 존재한다. 이런 경우 애써 MySQL이 정렬을 해준다고 한들, 그 순서는 별 의미가 없을 것이다.\n\n흔한 실수: 커서 기반 페이지네이션\n관련하여 나의 실수를 하나 공유해본다. 매일 새벽에 해당 일자에 발생한 어떠한 데이터를 집계하는 배치 잡을 작성하던 때였다. 아무래도 배치이기 때문에 많은 양의 데이터를 다루게 되는데, 이때 다량의 데이터를 제한 없이 모두 읽어오게 되면, OOM이 발생하게 되어 배치 잡 프로세스가 죽을수도 있다.\n따라서 이런 경우 페이지네이션을 사용해야 안전하다. 페이지네이션은 크게 오프셋 기반과 커서 기반 방식으로 나뉘게 되는데, 커서 기반의 페이지네이션 방식이 오프셋 기반 방식에 비해 여러 이점이 있어 (이건 별개 포스팅으로 다뤄보겠다), 커서 기반 페이지네이션을 선택했다.\n커서 기반 페이지네이션은 커서 기준으로 삼을 sequential 한 컬럼이 하나 필요한데, 위 예제와 비슷하게 당시 테이블도 PK인 id 컬럼이 sequential 했으므로 이 컬럼을 기준으로 잡고 로직을 작성했다. 위 예제를 예로 들자면, 아래와 같이 JPA Repository 메소드를 작성한것이다.\ninterface UserRepository : JpaRepository<User, Long> {\n    fun findByIdGreaterThanAndAgeGreaterThanAndEmailEndsWith(\n        id: Long,\n        age: Int,\n        email: String,\n        pageable: Pageable,\n    ): List<User>\n}\n\n그리고 여러분의 예상처럼, 배치는 어떤 데이터는 중복으로 집계되고, 어떤 데이터는 누락되면서 난리가 났고, 나는 새벽 한밤중에 부랴부랴 대응하느라 정신이 없었다. 하필 다음날 오전에 출국하는 비행기가 있었는데, 잠을 늦게 자서 비행기를 놓칠뻔했다.\n그러니까, 커서기반 페이지네이션 할 때 꼭 ORDER BY 를 넣어서 정렬을 보장하자. MySQL은 여기까지 배려해주지 않는다.\n\n참고\nhttps://dba.stackexchange.com/questions/6051/what-is-the-default-order-of-records-for-a-select-statement-in-mysql\nhttps://stackoverflow.com/questions/8746519/sql-what-is-the-default-order-by-of-queries\nhttps://stackoverflow.com/questions/49815703/what-is-the-default-order-by-for-a-mysql-innodb-query-that-omits-the-order-by\nhttps://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt\nhttps://hudi.blog/db-clustered-and-non-clustered-index/\nhttps://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt\nhttps://learn.microsoft.com/en-us/archive/blogs/conor_cunningham_msft/no-seatbelt-expecting-order-without-order-by",
        "content": "MySQL이 알아서 PK로 정렬해줄 것이라는 오해 흔히  쿼리를 실행하면 Primary Key 기준으로 오름차순 정렬이 되는 것을 보고, MySQL의 기본 정렬은 PK…",
        "contentSnippet": "MySQL이 알아서 PK로 정렬해줄 것이라는 오해 흔히  쿼리를 실행하면 Primary Key 기준으로 오름차순 정렬이 되는 것을 보고, MySQL의 기본 정렬은 PK…",
        "guid": "https://hudi.blog/mysql-no-order-by-no-sorting-guarantee/",
        "isoDate": "2024-07-06T20:30:00.000Z"
      }
    ]
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "2024 하반기 달라지는 정책: 금융·경제·복지 제도 13가지",
        "link": "https://blog.toss.im/article/money-policies-17",
        "pubDate": "Fri, 12 Jul 2024 02:50:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}2024 하반기를 맞아 새롭게 시행되는 금융, 경제, 복지 분야의 다양한 정책들을 정리했습니다. 부모와 청년을 위한 혜택부터 더 안전하고 간편한 금융생활을 위한 정책까지 많은 변화가 기다리고 있어요.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}부모를 위한 혜택\n1.모든 초등학교에서 늘봄학교를 운영해요\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}2024년 2학기부터 전국 모든 초등학교 약 6,100개에서 1학년을 대상으로 늘봄학교를 확대 운영합니다. 늘봄학교를 이용하는 아이들은 다양한 맞춤형 프로그램을 연간 매일 2시간씩 무료로 제공받게 됩니다.\n2.육아로 근로시간 단축 시, 소득을 더 보전받아요\n육아를 이유로 근로시간을 단축할 경우, 통상임금 100%를 지급하는 기간이 늘어납니다. 7월 1일부터 통상임금 100%(월 상한액 200만 원) 지원범위를 주 최초 5시간에서 주 최초 10시간까지 확대합니다.\n육아기 근로시간 단축을 30일 이상 허용(주당 10시간 이상)하고, 업무분담 근로자를 지정하여 금전적 지원을 한 경우, 정부가 사업주에게 월 최대 20만 원을 지원합니다.\n3.출산과 양육에 어려움을 겪는 임산부를 지원해요\n7월 19일부터 위기임산부는 상담전화(1308)을 통해 경제적 지원, 법률적 지원, 출산 전후 주거·돌봄 및 산후조리 지원 등을 연계 받을 수 있습니다. 또한 신원을 밝히기 어려운 임산부는 의료기관에서 가명으로 진료·출산할 수 있고,  태어난 아동은 출생등록 및 보호조치를 받을 수 있어요.\n청년을 위한 혜택\n4.취업 후 상환 학자금 대출 지원 대상 및 이자 면제 확대\n7월 1일부터 학자금 지원 1~5구간인 기준 중위소득 이하 가구의 대학생*이라면 대출 시점부터 졸업 후 2년 범위 안에서 의무상환 개시 전까지 이자를 면제받을 수 있습니다.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*기준 중위소득 100%이하(4인가구 기준 월 572만 9913원)\n상환유예 사유에 재난 피해(재난사태 선포 또는 특별재난지역 거주)를 추가하고, 유예기간 동안 발생한 이자도 면제합니다. 취업 후 상환 등록금대출을 받을 수 있는 대학생 또한 기존 학자금지원 8구간에서 9구간까지 확대되었습니다.\n5.청년 제대군인을 위한 혜택이 늘어요\n만 34세 이하의 제대군인 또는 전역 후 3년 이내의 제대군인이라면 ‘히어로즈 카드'를 이용해 보세요. 학원·도서 구입·어학시험 등 자기 계발비나 교통·통신 등 생활편의에 5~20%의 할인 혜택을 받을 수 있어요. IBK기업은행, KB국민카드, NH농협카드 등 3개 금융사를 통해 7월 16일부터 발급할 수 있습니다.\n여가생활을 위한 혜택\n6. 여권 발급 비용이 저렴해져요\n7월 1일 부터 여권발급비용이 3,000원 저렴해집니다. 유효기간이 10년인 58면짜리 여권은 기존 5만 3,000원에서 5만 원으로, 페이지 수가 적은 26면짜리 여권은 기존 5만 원에서 4만 7,000원으로 발급비용이 줄었어요.\n또한 여권을 재발급 할 때에는 민간 앱을 이용할 수 있어요. 전자여권을 한 번이라도 발급받은 적이 있는 18세 이상 국민은 KB스타뱅킹을 통해 재발급 신청을 하면 돼요.\n7. 해외여행 갈 때 내던 세금이 줄어요\n해외여행 갈 때 내던 출국납부금이 1만 원에서 7,000원으로 인하됐습니다. 출국납부금 면제 기준 연령도 12세 미만 어린이로 확대됩니다.\n더 안전하고 편리한 금융생활을 위해\n8. 보이스피싱 피해, 더 빠르게 구제받을 수 있어요\n8월 말 부터 .css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}통장협박 피해자도 피해금 편취 의도가 없음을 소명하는 협박문자와 같은 객관적인 자료를 가지고 금융회사에 이의제기를 신청하면 피해금과 관련이 없는 부분에 대한 신속한 지급정지 해제가 가능하게 됩니다.\n계좌 추적이 어려운 보이스피싱에 대해, 금융회사와 전자금융업자 간 계좌정보 공유를 의무화해 신속한 지급정지 및 피해금 환급이 가능하게 됩니다.\n9. 불법추심 피해 입은 가족·지인도 무료 법률 상담받을 수 있어요\n채무당사자뿐만 아니라 ① 채무자와 동거하거나 생계를 같이 하는 자 ②채무자의 친족 ③채무자가 근무하는 장소에 함께 근무하는 직장동료도 무료로 법률지원을 받을 수 있습니다.\n금융감독원 누리집 불법금융 신고센터 내 ‘채무자대리인 및 소송변호사 무료지원 신청’에서 온라인 신청하거나, 금융감독원 불법사금융신고센터(1332)를 통해 신청할 수 있어요.\n10.주택임대차 신고, 모바일로도 할 수 있어요\n8월부터 계약을 체결한 자리에서 집주인과 세입자가 모바일로 .css-1ly3pih{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey800);background-color:#3fd59936;-webkit-text-decoration:underline!important;text-decoration:underline!important;}주택임대차 신고를 할 수 있습니다. 주민센터에 직접 방문 또는 PC를 통해서만 신고가 가능했지만, 8월부터는 모바일로도 신고가 가능합니다.\n11.오피스텔·빌라도 주택담보대출 갈아탈 수 있어요\n9월부터는 주거용 오피스텔·빌라 담보대출도 주택담보대출 갈아타기 서비스 이용대상에 포함됩니다. 현재는 신용대출, 아파트 주택담보대출, 전세대출만 온라인 대환대출 인프라를 통해 갈아탈 수 있는데요. 9월부터 KB시세 등 실시간 시세 조회가 가능한 빌라(연립·다세대) 및 주거용 오피스텔 담보대출도 갈아탈 수 있게 됩니다.\n12.주민등록증, 휴대폰에 넣고 다녀요\n12월 27일부터 17세 이상 국민 누구나 모바일 주민등록증을 발급받을 수 있습니다. 실물 주민등록증을 들고 다닐 필요 없이 휴대폰에 주민등록증을 저장해 편리하게 사용할 수 있어요. 모바일 주민등록증은 읍·면·동 주민센터를 방문해 본인 확인을 거친 뒤 무료로 발급받을 수 있습니다.\n13.인감증명서, 정부24에서 편하게 발급해요\n그동안 주민센터를 방문해야만 발급받을 수 있던 인감증명서를 9월 30일(예정)부터 정부24에서 무료로 발급받을 수 있습니다.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 이지영 Graphic 조수희",
        "content": "내 삶에 도움이 되는 혜택을 찾아보세요.",
        "contentSnippet": "내 삶에 도움이 되는 혜택을 찾아보세요.",
        "guid": "https://blog.toss.im/article/money-policies-17",
        "isoDate": "2024-07-12T02:50:00.000Z"
      },
      {
        "title": "자꾸 디폴트옵션 설정하라고 알림이 와요",
        "link": "https://blog.toss.im/article/retirement-plans-04",
        "pubDate": "Fri, 12 Jul 2024 00:14:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}이 글에서 알 수 있는 것들\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1kxrhf3{white-space:pre-wrap;}DC형 퇴직연금과 IRP 가입자에게 필수 사항인 디폴트옵션의 개념 \n디폴트옵션의 종류와 성향에 따라 잘 고르는 방법\n\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n무심코 선택한 디폴트옵션에서 다섯 배 이상 수익률 차이가 난다고요?!\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n고용노동부가 발표한 2024년도 1분기 퇴직연금 디폴트옵션 주요 현황 공시에 따르면 한국투자증권의 '디폴트옵션고위험BF1'은 1년 수익률이 22.87%로 전 사업자의 전체 상품 수익률 중 1위를 기록했다. 1년에 22%가 넘는 수익률이라니, 디폴트옵션의 취지가 ‘너무 낮은 퇴직연금 수익률 개선하기’였던 점을 생각하면 이런 성과는 그저 놀라울 뿐이다.\n디폴트옵션은 DC형 퇴직연금이나 IRP 계좌를 만들고 나서 첫 번째로 만나는 단계이다. 2023년 7월 이후 둘 중 하나의 계좌라도 가지고 있었다면 디폴트옵션에 대해 들어봤거나 직접 선택한 경험이 있을 것이다. 만약 당신이 이제 막 취업에 성공한 사회초년생이라면 가입 과정에서 디폴트옵션에 가입해야 한다는 설명을 들었을 수도 있다.\n그럼에도 많은 사람들은 이렇게 생각한다. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}‘대체 디폴트옵션이 뭐야? 퇴직연금도 아직 잘 이해하지 못했는데 왜 자꾸 디폴트옵션을 선택하라고 하는 거지?’ 그러고는 설명을 읽어봐도 뭐가 뭔지 잘 모르겠어서 대충 원리금이 보장된다는 저위험 상품을 골라두기도 한다. 하지만 디폴트옵션을 어떻게 선택하느냐에 따라 원리금 보장형이 예금을 통해 연 3~4% 수익률을 내는 동안 22%가 넘는 수익률을 올리는 상품도 있다. 무조건 고위험을 고르자는 뜻은 아니다. 이제부터 잘 이해하고 골라야겠다는 마음, 그 마음의 준비가 필요하다.\n1. 이게 다 우리를 위해 만들어졌다니까요? 디폴트옵션의 탄생\n‘디폴트옵션(default option, 사전지정운용제도)’은 쉽게 말하면 퇴직연금 계좌에 들어있는 돈을 가입자가 사전에 정한 방법으로 돈을 운용하는 제도이다. 퇴직연금에 넣은 돈은 활발히 투자해 노후 연금 형태로 쓸 수 있도록 불려야 하는데, 가입자가 주기적으로 돈을 어떻게 운용할지 지시하지 않는 경우가 많다. 그러면 결국 가입자의 손해로 이어지므로, 퇴직연금이 투자한 상품이 만기가 됐는데도 일정 기간 가입자가 별도의 운용 지시를 하지 않으면 사전에 지정해둔 방법으로 운용해주는 것이다.\n퇴직연금 운용에 대한 경험이 풍부한 미국, 영국, 호주 등 연금 선진국에서는 가입자가 적절한 시기에 적절한 선택을 하도록 유도하여 노후 소득 보장을 강화하도록 돕는 것이 정부의 사회적 책무라는 인식이 퍼져 있다. 그래서 이미 오래전부터 이 디폴트옵션을 도입하고 운영해 왔으며, 연평균 6%에서 8%대의 안정적인 수익률 성과를 내고 있다.\n국내에서 디폴트옵션은 2022년 7월 도입되었고, 1년간의 사전 준비 등 유예기간을 거쳐 2023년 7월 12일부터 본격적으로 시행되었다. 시행 목적은 물론 매우 저조한 수익률을 거두고 있는 퇴직연금 적립금을 활용해 운용 성과를 높이기 위한 것이다. 2021년 기준 5년간 퇴직연금 수익률은 2.4%에 불과했고 직전 해까지 기준으로는 1%대였다. 적극적으로 투자하지 않고 원리금 보장형으로 운용되거나 아예 현금 그대로 방치하는 경우도 많았기 때문이다. 연 1~2%의 수익률은 물가상승률도 따라가지 못하는 숫자인데, 그렇다는 건 돈을 그대로 방치하는 바람에 실질적으로는 마이너스 수익률을 거두는 것이다. 이렇게 노후를 위해 마련하는 퇴직연금을 몇십 년 방치하면 어떤 일이 벌어질까? 안타깝게도 빈곤한 연금 잔액이 기다리게 된다. 그래서 잠자고 있는 퇴직연금을 투자하게 만드는 데에 국가가 발벗고 나선 것이다.\n2. 누가 디폴트옵션을 지정해야 할까?\n개인이 운용 책임을 지는  DC형 퇴직연금과 IRP 계좌를 가진 사람들에게는 모두 해당한다. 만약 디폴트옵션을 끝내 지정하지 않으면 퇴직연금 운용 수익이 발생하지 않을 수 있다는 점을 꼭 기억하자.\nDB형 퇴직연금은 회사가 운용 책임을 가지기 때문에 DB형 가입자들은 디폴트옵션을 직접 선택하지 않는다.\n3. 지정해두면 언제 디폴트옵션으로 운용될까?\n디폴트옵션은 가입자가 퇴직연금 계좌에 있는 적립금을 일정기간 동안 어떻게 운용할지 지시하지 않을 때 작동한다. 이 시기에는 2가지 경우가 해당한다. 첫째, DC형 퇴직연금이나 IRP에 가입 후 적립금이 이체되고 나서 2주 동안 운용 지시를 내리지 않으면 디폴트옵션이 작동한다.\n둘째, 적립금이 들어가 있던 금융상품이 만기 되고 4주가 지났는데도 운용 지시를 별도로 하지 않으면 퇴직연금사업자로부터 2주 안에 운용 지시를 해야 한다는 안내를 받게 된다. 이때도 운용 지시를 하지 않아 총 6주 동안 방치하면 디폴트옵션으로 운용된다. 디폴트옵션 미지정 시 기존 상품의 만기가 도래했는데 가입자가 별도로 운용 지시를 하지 않으면 현금성 자산으로 남아 낮은 금리로 운용된다.\n4. 디폴트옵션에는 어떤 상품이 있을까?\n디폴트옵션을 설정하러 들어가면 보통 네 가지 중에 고르라는 문항을 만나게 된다. 바로 초저위험, 저위험, 중위험, 고위험이다. 초저위험은 말 그대로 위험이 매우 낮아 원리금을 잃을 가능성이 없는 원리금 보장형 상품으로 구성된다. 따라서 은행의 예금, 보험사의 GIC(이율보증형 보험계약)* 등이 주를 이룬다. 최근 1~2년 동안 금리 상승 효과로 초저위험 디폴트옵션의 수익률이 3% 이상으로 올라가면서 주목을 받기도 했다.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*은행의 정기예금과 유사한 금융상품으로 보험사가 판매하는 원리금보장 보험계약(특별계정, 예금자보호 대상)이다.\n저위험부터는 원리금 보장형인 정기예금부터 투자 성향이 들어가는 TDF, BF펀드까지 상품군이 다양해진다. 물론 저위험의 성향에 맞게 원리금 보장형의 배분이 더 높고 투자형 상품의 배분은 더 낮은 편이다. 중위험으로 갈수록 투자형 상품의 배분이 더 높아진다. 그렇다면 디폴트옵션에 많이 포함되어 있는 TDF나 BF펀드는 무엇일까?\n먼저 TDF는 타깃 데이트 펀드(Target Date Fund)의 줄임말로 은퇴 시점을 기준으로 운용되는 은퇴 상품이다. TDF는 투자자의 은퇴 시점에 맞춰 은퇴까지 많은 시간이 남아 있을 때는 주식 비중이 높고 은퇴에 가까워질수록 안전자산인 채권의 비중이 높아지도록 배분을 조정한다. 즉 은퇴 시점에 맞춰 펀드 안에 있는 자산의 편입 비중을 자동으로 조정해준다는 특징이 있다.\n만약 디폴트옵션에서 TDF를 선택하고 싶다면 목표 시점을 확인해야 한다. TDF 상품 이름에 들어간 네 자리 숫자가 목표 시점을 나타낸다. 2030, 2040 등이 붙은 상품 이름은 해당 시점 무렵에 은퇴할 예정인 투자자를 위한 상품이다. 네 자리 숫자를 빈티지(vintage)라고 부른다.\n디폴트옵션 안에는 BF펀드(Balance Fund, 밸런스펀드)도 들어 있다. 이는 투자위험이 다른 다양한 자산에 분산투자하고, 금융시장 상황과 가치 변동 등에 맞춰 주기적으로 자산 비중을 조절하는 펀드다. TDF와 BF펀드는 모두 주식과 채권 등 다양한 자산에 분산 투자하는 자산배분펀드라는 점에서는 같지만, BF펀드는 자산배분 비중이 일정하게 유지된다. 시간의 흐름에 따라 주식과 채권의 비중이 달라지는 TDF와 가장 큰 차이점이라고 할 수 있다. 따라서 현재 주식과 같은 위험자산에 최대 얼마나 투자할지 등을 체크해야 한다. 만약 위험비중을 조정하고 싶다면 투자자가 직접 상품을 변경하는 등의 개입이 있어야 한다.\n5. 그럼 나는 어디에 투자하는 게 좋을까?\n실제로 승인받은 퇴직연금사업자가 지금까지 300개가 넘는 디폴트옵션 상품을 내놓았다. 그렇다면 어떤 기준을 가지고 선택해야 할까? 이 역시 투자자의 위험 감수 성향과 은퇴까지 남은 시간 등을 고려해야 한다. 우선 네 가지 분류에 대해서는 아래의 질문을 따라가면서 나에게 맞는 카테고리를 골라보자.\n우선 가장 첫 번째 기준은 내가 받고 싶은 수익률이다. 만약 정기예금 금리 수준의 수익에 만족하며 원금 손실을 원하지 않는다면 초저위험을 선택하면 된다. 정기예금 금리보다는 높은 수준을 원한다면 다음 질문을 살펴보자. 원금 손실을 최소화하고 싶다면 저위험으로, 정기예금보다 높은 수익을 추구하며 그에 따르는 위험성을 충분히 알고 있다면 다음 단계로 넘어갈 수 있다. 마지막 질문은 어느 정도의 위험을 감당할 수 있는가에 달려 있다. 너무 높은 위험을 피하고 싶다면 중위험으로, 위험을 감수하더라도 높은 수익을 추구한다면 고위험으로 선택할 수 있다.\n\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n\n그런데 2024년 2월에 금융감독원이 발표한 자료에 따르면 디폴트옵션 전체 적립금 가운데 84%가 은행권에 몰려 있다. 적립금 상위 10개 기관을 살펴보면 상위 5위까지를 모두 은행이 차지하고 있다는 것을 알 수 있다. 근로복지공단과 미래에셋증권을 제외하면 8개가 모두 은행권이다.\n\n\n\n또한 최근 5월에 발표된 금융감독원 자료를 살펴보면 얼마나 많은 비중이 원리금 보장형으로 몰려 있는지도 알 수 있다. 은행의 적립금 비중을 살펴보면 원리금 보장형 90.1%, 실적배당형 9.9%이다. 90%가 원리금 보장형으로 운용되고 있음을 알 수 있다.\n\n\n\n운용 성과를 높이기 위해 도입한 디폴트옵션의 취지에 무색하게 대다수가 원리금 보장형을 선택하는 상황이다. 1년 22%의 수익률을 기록한 디폴트옵션 상품도 있으나 실제로 80%가 넘는 적립금이 초저위험으로 몰려 있는 것을 보면 가입자들의 이해도나 기대치와 디폴트옵션의 취지 사이에는 갭이 있다는 것을 알 수 있다. 아직도 퇴직연금이 가야 할 길은 멀다.\n6. 분기별로 수익률을 체크하자\n300개가 넘는 디폴트옵션 상품은 그 숫자만큼 다양한 수익률을 보여준다. 따라서 정확하게 수익률을 확인하는 일도 중요하다. 금융감독원이 2023년 7월에 발표한 보도자료를 보면 실적배당형의 수익률은 13.25%이고, 원리금 보장형은 4.08%으로 세 배 이상의 수익률 차이를 보인다. 그렇기 때문에 직접 내 적립금이 들어가 있는 상품의 수익률과 다른 선택지들의 수익률을 비교해보거나, 글라이드 등 수많은 상품별 수익률 정보를 리포트해주는 곳을 활용해 주기적으로 수익률을 체크하고 다시 지정할 필요가 있다.\n7. 상품 만기가 끝났다면 언제든 운용 지시도 가능! 옵트인과 옵트아웃을 적극적으로 활용하자\n가입자가 디폴트옵션이 발동하기 전에 적극적으로 디폴트옵션 상품으로 적립금을 운용하고 싶다면 대기 기간 없이 상품을 선택할 수 있다. 이를 옵트인(opt-in, 직접 운용)이라고 한다. 퇴직연금사업자가 제공하는 디폴트옵션 상품으로 퇴직연금 계좌의 돈을 직접 운용할 수 있다는 뜻이다. 동일한 유형의 일반 퇴직연금 상품과 비교했을 때 디폴트옵션 상품은 금리가 조금 더 높거나 수수료가 조금 더 싼 편이다. 따라서 이를 적극적으로 이용한다면 수익률에 도움을 받을 수 있다. 다만 옵트인으로는 디폴트옵션 상품 하나만 가입이 가능하다는 점을 잊지 말아야 한다.\n또 반대로 디폴트옵션이 적용된 뒤에도 가입자가 희망하면 언제든지 다른 금융 상품으로 갈아탈 수 있다. 이것을 옵트아웃(opt-out)이라고 부른다.\n지금까지 글을 따라오면서 자신이 어떤 디폴트옵션을 선택했는지 기억났는가? 만약 제대로 따져보고 고르지 않았다면, 어떤 상품을 골랐는지조차 잘 기억나지 않을 수 있다. 그렇다면 지금까지 정리한 정보를 통해서 다시 한 번 골라보면 어떨까?\n가입자는 퇴직연금사업자(은행, 보험, 증권사)가 제시하는 디폴트옵션 상품 가운데 하나만을 선택할 수 있다. 만약 이미 퇴직연금 적립금을 디폴트옵션 상품에 투자하고 있다면 다른 디폴트옵션 상품에 적립금을 투자할 수는 없다. 하지만 다른 상품으로 갈아타기를 희망해 다시 지정하면 기존에 운용하고 있는 디폴트옵션 상품은 그대로 유지되고, 이후에 새롭게 납부된 금액부터 새롭게 지정한 디폴트옵션 상품으로 운용된다.\n만약 이 개념이 헷갈린다면 직접 고르고 변경해보면서 알아가도 좋다. 중요한 점은 한번 골랐다고 그대로 방치하지 말아야 한다는 사실이다. 분기별 수익률도 점검해보고, 위험을 감수하더라도 조금 더 나은 수익률을 얻고 싶다면 다시 한번 비교하고 고르는 수고로움도 반드시 감수해야 한다. 이번 글을 읽은 투자자들은 반드시 자신이 가입한 디폴트옵션 상품이 무엇인지, 수익률을 얼마나 되는지 꼭 점검하길 바란다.\n다음 편에서는 사람들이 가장 쉽게 접근할 수 있는 은퇴상품 TDF를 어떻게 고르고 포트폴리오를 구성해야 하는지 실제 투자 노하우를 알아보자.\n*디폴트옵션 상품 구성에 대한 더 자세한 정보는 .css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}글라이드의 포스트 혹은 카카오톡 채널을 통해 확인하실 수 있습니다.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 주소은, 김현미(아이랩)\nGraphic 조수희, 이서영",
        "content": "디폴트옵션(사전지정운용제도)의 모든 것",
        "contentSnippet": "디폴트옵션(사전지정운용제도)의 모든 것",
        "guid": "https://blog.toss.im/article/retirement-plans-04",
        "isoDate": "2024-07-12T00:14:00.000Z"
      },
      {
        "title": "킹달러 현상 지속, 지금은 여러가지 이유가 복잡하게 얽혀있어요",
        "link": "https://blog.toss.im/article/economic-terms-21-kingdollar",
        "pubDate": "Thu, 11 Jul 2024 02:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-8atqhb{width:100%;}.css-1c1qox8{font-size:30px;letter-spacing:0em;line-height:1.55;font-weight:bold;color:var(--adaptiveGrey900);margin:40px 0 4px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-p4abj2{display:contents;line-height:1.55;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}🔖 이번 주 경제 용어\n킹달러\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}이번 주 경제 용어는 글로벌 경제를 파악하기 위해 필요한 정보예요.\n\n.css-1pgssrp{max-width:100%;border-radius:16px;}\n달러가 강세인 상황으로, 달러의 힘이 세지는 것을 말해요.\n\n\n올해 들어 달러화 가치가 상승하면서 원·달러 환율이 고공행진 중입니다. 지난 4월 원·달러 환율이 1,400원에 육박할 정도로 가파르게 상승한 뒤, 외환 당국의 시장 개입으로 1,300원대 중후반대로 내려오면서 안정을 찾는 듯 싶었는데요. 최근 달러 값이 다시 상승하면서 현재(2024.7.11.기준)는 1달러를 구매하기 위해 약 1,390원이 필요한 상황입니다.\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}원·달러 환율이 1,350원을 넘는 것은 경제적으로 위험한 수준으로 여겨집니다. 1997년 아시아 금융 위기, 2008년 글로벌 금융 위기 때 원화가 크게 평가절하되면서 원·달러 환율이 급등한 적이 있기 때문인데요. 당시 환율 수준이 1,300원~1,400원 사이였고 특히 2008년 금융 위기 때엔 1,400원 대까지 폭등했습니다. 이 때의 경험으로 1,350원이 넘으면 경제적으로 위험한 수준이라 인지하게 되는 것이죠.\n원·달러 환율이 1,400원에 육박하다 조금 잠잠해지나 싶었는데, 다시 두 달 만에 1,400원을 위협하는 수준까지 상승했습니다. 이는 수출입 뿐만 아니라, 소비·투자·여행 등 다방면에 상당히 큰 영향을 미칠 수 있는 상황이에요.\n대체 왜 달러가 오르는 걸까요?\n4월에 달러가 강세였던 이유는 미국 연방준비제도(연준, Fed)의 기준금리 인하 시점이 늦어질 수도 있다는 전망 때문이었습니다. 생각보다 미국의 물가가 끈적거리며 3% 대에 달라붙어 내려오지 않았고, 고용 시장도 활발해지고 뜨거워졌기 때문에 연준의 금리 인하 시점은 9월 이후로 늦춰질 가능성이 높아졌습니다.\n심지어 일부 분석에서는 연준이 올해 추가 인상 없이 금리를 유지할 수 있다는 전망도 제시되고 있습니다. 기준금리가 내려가야 시중에 통화가 풀리면서 통화 가치가 하락할 수 있는데요. 이 기대감이 하락하며 당시 달러 가치가 상승했습니다.\n그런데, 지금 원·달러 환율이 오르는 이유는 4월보다 좀 더 복잡합니다. 여러 나라가 각자의 이유로 금리를 관리하고 있는데 달러 가치가 오를 수 밖에 없는 상황으로 가고 있어요.\n1. 주요국 중앙은행의 기준금리 인하\n최근 캐나다·유럽연합(EU)·스위스·스웨덴 중앙은행이 미국보다 먼저 기준금리를 인하했습니다. 이는 자국 경기가 침체될 우려에 대응하기 위한 조치였는데요.\n통화 가치 하락은 각오해야 했습니다. 주요 6개 통화(유로, 일본 엔, 영국 파운드, 캐나다 달러, 스웨덴 크로나, 스위스 프랑)에 대한 달러화 가치를 반영하는 달러 인덱스 값은 상승해서 105*를 넘겼어요.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}* 통상적으로 달러 인덱스 값이 100을 초과하면 강달러, 100보다 낮으면 약달러라고 부릅니다.\n2. 일본 엔화 약세 가속\n일본은 지난 3월, 17년 만에 첫 금리 인상을 단행했습니다. 하지만 .css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}엔화 약세는 지속되고 있는데요. 일본 은행이 미국 연준(Fed)의 기준금리 인하 소식만 기다리며, 적극적으로 금리 추가 인상을 하지 않고 있기 때문입니다.\n국가 부채가 많은 일본의 경우 금리가 오르면 이자가 늘어나기 때문에 부담이 커요. 금리를 올리는 데에 한계가 있습니다. 그렇다고 일본이 보유하고 있는 미국 국채를 팔면? 다시 채권 금리가 올라 달러 강세가 심화될 수 있다는 우려가 있어요. 이러지도 저러지도 못하고 있는 실정이죠. 이에 따라 당분간 엔저 현상이 쉽게 해소되지 않을 것이라는 전망이 높습니다.\n3. 동아시아 지정학적 불안\n달러·위안화 환율은 지난 해부터 중국 당국이 심리적 마지노선으로 여기는 '달러당 7위안'을 넘긴 상태입니다. 중국의 위안화 환율이 달러당 7위안 이상으로 오르는 것을 포치(破七) 상태라 하는데요. 한동안 포치 상태로 머무를 가능성이 높아보입니다. 중국 경기가 살아나지 못한다면 위안화 가치 회복이 어려울 것으로 예상되기 때문이에요.\n그리고 러시아는 아직 우크라이나와 전쟁 중이고, 러시아 푸틴 대통령은 북한을 방문하기도 했기에 국제 정세에 긴장감이 더해지고 있습니다.\n\n\n.css-2yhypk{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);font-style:italic;-webkit-text-decoration:underline!important;text-decoration:underline!important;}7월도 킹달러 여진 지속…고환율 수혜주 담아라\n(이데일리 2024.7.2)\n화장품과 반도체 관련주가 강세를 보인 것은 고환율 기조 전망 속 수출 확대에 따른 수혜가 예상되기 때문으로 풀이된다. 고환율 국면에서 수출 비중이 높은 업체의 경우 달러 강세에 따른 매출 증가와 환차익을 누릴 수 있는데, 최근 환율이 상승 기조를 보이면서 수출주에 대한 매수세가 확대했다는 판단이다.\n서울외국환중개에 따르면 이날 오후 3시30분 기준 원·달러 환율은 전 거래일 대비 2.6원 오른 1379.3원을 기록했다. 이는 지난달 중순 1370원 초반대 수준을 기록한 것과 비교하면 점진적으로 상승하는 흐름이다.\n증권가에선 고환율 기조가 이달에도 지속할 가능성이 크다고 점친다. 엔화와 유로화 약세가 당분간 이어지며 달러 강세를 지속 부추길 것이란 이유에서다. 엔화 약세는 일본은행(BOJ)의 추가 긴축 조치가 지연되고 있는 데다, 기시다 후미오 총리의 퇴진 위기가 가시화한 게 주요한 영향을 미치고 있다는 분석이다.\n유럽에선 기대를 밑도는 경기 회복 흐름과 조기 초선을 치르는 프랑스와 영국에서 극우 세력 돌풍에 따른 정치 불안 우려가 유로화 약세의 동인이 되고 있다. 박상현 하이투자증권 연구원은 “엔화와 유로화의 추가 약세 시 원·달러 환율의 1400원대 진입을 배제할 수 없으며, 일시적으로 금융시장 변동성이 확대될 것”이라고 전망했다. (중략)\n\n\n달러와 원화의 관계를 간략히 정리하면 아래와 같습니다.\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n달러 강세 = 원화 약세 = 원·달러 환율 상승\n달러 약세 = 원화 강세 = 원·달러 환율 하락\n\n원·달러 환율이 1,250원에서 1,400원으로 상승했다는 것은 1달러를 구매하는 데 더 많은 한국 원화가 필요하게 되었음을 의미합니다. 이전에는 1달러를 1,250원에 구매할 수 있었지만 지금은 1,400원을 지불해야 하는 거죠. 반대로 미국에서 1달러를 벌어와서 국내에서 환전했을 때, 예전에는 1,250원만 받았지만 지금은 1,400원을 받게 됩니다.\n즉, 환율 상승은 수출 기업에는 유리할 수 있지만 수입 기업에는 불리하며 물가 상승을 불러올 수 있어요.\n환율 상승은 외국인 투자자들의 국내 투자 감소로 이어질 가능성이 높습니다. 외국인 투자자들은 국내 투자로 얻는 수익이 원화로 지급되는데, 환율이 상승하면 외화로 환전했을 때 받는 금액이 줄어들기 때문에 투자를 회수할 우려가 높아요.\n그나마 수출 중심 기업은 달러를 벌어와서 높은 가격으로 환전할 수 있으니까 실적이 좋아질 수 있는데요. 이런 주식에는 외국인 투자자도 투자를 할 수 있습니다.\n기사 내용처럼 최근 화장품과 반도체 관련 주식이 강세를 보이는 이유는 고환율 기조 전망 속에서 수출이 늘어나면 그에 따른 수혜가 예상되기 때문이에요. 고환율은 수출 중심 기업의 경쟁력을 높여주고, 환차익도 얻을 수 있으니까요.\n그러니까 당분간 달러가 대세 상승기에 접어든다면 화장품, K-식품, 반도체, 자동차 같은 수출 중심 기업의 주식에 관심을 가지는 것도 좋겠습니다.\n\n\n환율 방어: 외환시장에서 급격한 변동으로 인해 자국 통화 가치가 하락하는 것을 막기 위해 중앙은행이나 정부가 시장에 개입하여 인위적으로 환율을 안정시키는 것. 구두 개입은 말로 외환 시장 불안이 지속되면 조치를 취하겠다고 경고를 주는 것이고, 직접 개입은 외환당국이 외환 시장에서 달러를 팔거나 사들이는 것이에요. 사실 외환시장에 직접 개입하는 건 환율조작국으로 지정될 수 있기 때문에 공식적으로 발표하지 않습니다.\n통화 스와프(Swap): 두 국가가 서로 다른 통화를 교환하고, 일정 기간 후에 다시 원래의 통화로 교환하는 거래. 외환시장의 안정성을 유지하고, 국제무역의 원활한 거래를 지원하는 것이 목적이에요.\n외환당국: 외환시장의 안정을 유지하기 위한 역할을 하는 기관. 우리나라에선 기획재정부와 한국은행이 그 역할을 해요.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 금혜원 Graphic 조수희 이동건",
        "content": "올해 들어 원·달러 환율이 고공행진 중입니다. 킹달러 현상이 지속되는 이유, 자세히 알아볼게요.",
        "contentSnippet": "올해 들어 원·달러 환율이 고공행진 중입니다. 킹달러 현상이 지속되는 이유, 자세히 알아볼게요.",
        "guid": "https://blog.toss.im/article/economic-terms-21-kingdollar",
        "isoDate": "2024-07-11T02:00:00.000Z"
      },
      {
        "title": "토스, CU멤버십 연동 고객 110만 명 돌파",
        "link": "https://blog.toss.im/article/toss-cu-membership",
        "pubDate": "Wed, 10 Jul 2024 04:52:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}‘내 멤버십 모아보기’에서 CU멤버십 포인트 적립 내역 확인 가능\n사후 적립 기능도 구현... 론칭 한 달 만에 80만 건 적립\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n토스 앱 내 ‘내 멤버십 모아보기’ 서비스에 ‘CU멤버십’을 연동한 고객이 110만 명을 돌파했다.\n내 멤버십 모아보기는 토스 앱으로 다양한 멤버십 포인트를 확인할 수 있는 서비스다. 현재 CU멤버십을 포함, 총 7개의 멤버십 포인트 조회가 가능하다. 멤버십별로 결제일과 결제처, 그에 따른 포인트 적립 내역을 확인할 수 있는 것이 특징이다.\n토스는 CU멤버십에 한하여 사후 적립 기능도 추가로 구현했다. 해당 기능을 통해 CU 편의점에서 결제 시 포인트를 적립하지 않았더라도, 나중에 토스 앱을 통해 적립이 가능해졌다. 현재 토스에 CU멤버십을 연동한 고객 수는 110만 명을 돌파했다.\n사후 적립 기능을 사용하기 위해서는 내 멤버십 모아보기 메뉴에 CU멤버십 연결이 필요하다. 결제 시 CU멤버십 회원이 아니었더라도 이후 CU멤버십 가입 후 연동을 진행하면 포인트 적립이 가능하다. 적립 대상 내역은 토스 앱 내 '내 소비' 내역(계좌 및 유스카드 결제 제외)을 기준으로 한다. 총 14일 전부터 1일 전까지의 결제 내역에 대해 적립 가능한 CU포인트가 있는 경우, [내 멤버십 모아보기 - CU - 받을 포인트]에서 확인할 수 있다.\n토스 관계자는 “CU포인트 사후 적립 기능은 빠르고 간편한 결제 경험을 위해 결제 시 멤버십 적립 과정을 생략할 수 있도록 설계한 것”이라며 “해당 기능 론칭 한 달여 만에 사후 적립 건수는 80만 건을 돌파할 정도로 긍정적인 반응이 이어지고 있다”라고 전했다.",
        "content": "사후 적립 기능 구현 한 달 만에 적립 건수는 80만 건을 넘었어요.",
        "contentSnippet": "사후 적립 기능 구현 한 달 만에 적립 건수는 80만 건을 넘었어요.",
        "guid": "https://blog.toss.im/article/toss-cu-membership",
        "isoDate": "2024-07-10T04:52:00.000Z"
      },
      {
        "title": "토스씨엑스, 굿네이버스에 1천만원 후원…후원자 대상 교육기부도",
        "link": "https://blog.toss.im/article/tosscx_goodneighbors",
        "pubDate": "Tue, 09 Jul 2024 00:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}후원금은 생리대 지원 사업 및 국내외 아동 후원에 사용\n후원 문화 활성화 위해 토스씨엑스 임직원이 교육기부도\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n비바리퍼블리카(이하 ‘토스’)의 비대면 금융 상담 전문 계열사 토스씨엑스(대표 강희진)가 글로벌 아동권리 전문 NGO 굿네이버스에 후원금 1천만원을 전달했다고 9일 밝혔다.\n지난 6일 굿네이버스 회관에서 열린 후원금 전달식에는 토스씨엑스 강희진 대표와 굿네이버스 현대중 대외협력실장 등이 참석했다. 전달된 후원금은 국내 취약 계층 여성 청소년을 위한 생리대 지원사업과 국내외 아동 후원에 사용될 예정이다.\n이날 토스씨엑스 직원들은 후원 문화 활성화를 위한 재능기부 행사도 마련했다. 굿네이버스를 통해 해외 아동과 결연을 맺은 초등학교 저학년 후원자 및 보호자 60여 명을 초청해 경제교육을 열고, 토스씨엑스 직원들이 직접 강사로 나섰다.\n그간 쌓아온 금융 상담 노하우를 바탕으로 초등학교 저학년 눈높이에 맞춘 교육 프로그램을 선보였다. 특히 체험 활동을 통해 예적금과 이자 개념, 소비 관리 방법을 배우는 프로그램이 참석자들에게 큰 호응을 얻었다.\n토스씨엑스 강희진 대표는 “후원금 전달과 더불어 토스씨엑스 구성원들이 가진 역량으로 후원 문화에 일조할 수 있는 뜻깊은 시간이었다”며 “고객이 마주한 어려움을 가장 신속하고 완벽하게 해결한다는 토스씨엑스의 미션처럼 지원이 필요한 사회 곳곳에 도움이 될 수 있는 방법을 계속 고민하겠다”고 말했다.",
        "content": "후원금은 생리대 지원 사업 및 국내외 아동 후원에 사용했어요.",
        "contentSnippet": "후원금은 생리대 지원 사업 및 국내외 아동 후원에 사용했어요.",
        "guid": "https://blog.toss.im/article/tosscx_goodneighbors",
        "isoDate": "2024-07-09T00:00:00.000Z"
      },
      {
        "title": "토스피드 누적 조회수 5천만 돌파",
        "link": "https://blog.toss.im/article/tossfeed-50-million",
        "pubDate": "Sun, 07 Jul 2024 23:17:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}토스피드 출범 6년 만의 성과… 성장 속도 더욱 빨라져\n누적 조회수 5천만 돌파 기념 설문에 독자 2천여 명 참여\n설문 결과, 매일 방문 비율 63.7%에 달해\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n토스의 콘텐츠 플랫폼 ‘토스피드’가 누적 조회수 5천만을 돌파했다. \n토스피드는 2018년 5월 토스의 공식 블로그로 출발했다. 초반에는 토스 서비스와 기업에 대한 소식을 전하는 채널이었으나 이후 금융⋅경제와 관련된 주제를 전방위적으로 다루며 종합 금융⋅경제 콘텐츠 플랫폼으로 성장했다. \n그 결과, 출범 6년 만인 올해 5월 기준 누적 조회수 5천만을 돌파했다. 이는 지난해 6월 누적 조회수 3천만을 기록한 이후 약 11개월 만의 성과로, 성장 속도는 더욱 빨라진 것을 확인할 수 있다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n토스는 누적 조회수 5천만 돌파를 기념하며 독자 대상 설문조사를 진행했다. 지난 5월 27일부터 6월 5일까지 열흘간 진행한 설문조사에는 2천여 명의 독자가 참여해 다양한 의견을 전했다. 방문 빈도를 묻는 질문에 매일 접속한다고 답한 비중은 63.7%에 달했다. \n토스피드에서 어떤 콘텐츠를 주로 확인하는지에 대한 질문에는 ‘금융・경제에 관한 정보나 지식’이 60.1%로 가장 높은 답변 비중을 차지했으며, ‘최신 금융・경제 관련 뉴스’가 45%로 뒤를 이었다.\n‘가장 좋아하는 콘텐츠와 이유’를 묻는 질문에는 '월간 토스픽', '에브리데이 경제학' 등의 라이프스타일 콘텐츠가 인상적이라는 답변이 많았다. 여기에 금융과 일상이 맞닿은 지점을 발굴해 '금융은 어렵다'라는 인식을 허물어준다는 긍정적인 피드백이 따랐다. \n다양한 연령대에서 자신의 상황에 맞는 콘텐츠를 찾아보고 있다는 답변 또한 많은 독자들이 공통적으로 보내왔다. ‘앞으로 토스피드에서 보고 싶은 콘텐츠’에 대해서는 부동산(내 집 마련, 분양 등), 노후 준비(연금 등), 세계 경제, 가상화폐 등 구체적인 답변이 이어졌다.\n토스는 최근 모바일로 보는 토스피드 화면을 개편하는 작업도 단행했다. 모바일로 토스피드 콘텐츠를 소비하는 독자 비중이 점점 높아진다는 점에 주목한 결과다. \nPC로 접속하면 보이는 화면과 달리, 모바일 토스피드의 홈 화면은 ‘이 주의 콘텐츠’와 ‘이번 주 많이 본 콘텐츠’ 순위를 먼저 보여준다. ‘오늘의 금전운' 등 재미 요소도 더했다. \n또한 댓글이나 좋아요 기능을 추가해 독자들이 반응을 보내고 소통할 수 있는 창구도 확대했다.\n토스 관계자는 “토스피드는 회사의 소식을 전하는 미디어를 넘어 금융・경제와 일상의 접점을 만드는 콘텐츠 플랫폼으로 자리 잡았다는 사실을 설문을 통해 또 한 번 확인했다”라며 “월평균 조회 수가 150만에 이르는 등 금융・경제 분야의 대표 콘텐츠 플랫폼으로 자리매김한 만큼, 앞으로도 독자들과의 소통을 강화하며 더욱 양질의 콘텐츠를 제공하기 위해 노력할 것”이라고 전했다.",
        "content": "출범 6년 만의 성과예요. 성장 속도는 더욱 빨라졌어요.",
        "contentSnippet": "출범 6년 만의 성과예요. 성장 속도는 더욱 빨라졌어요.",
        "guid": "https://blog.toss.im/article/tossfeed-50-million",
        "isoDate": "2024-07-07T23:17:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]