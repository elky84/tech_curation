[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Carson Radtke",
        "title": "Announcing Guidelines Support Library v4.2.0",
        "link": "https://devblogs.microsoft.com/cppblog/announcing-guidelines-support-library-v4-2-0/",
        "pubDate": "Thu, 06 Mar 2025 09:36:54 +0000",
        "content:encodedSnippet": "GSL is an implementation of the Guidelines Support Library specified by the\nC++ Core Guidelines.\nIt provides types and functions that help C++ developers write safer, more maintainable\ncode while following modern C++ best practices.\nWe are excited to announce the release of GSL v4.2.0! This release brings significant\nperformance improvements, new features, and important updates that align GSL with modern\nC++ standards.\nPerformance Boost for Span Iterator\nOne of the most notable changes in this release is the significant performance\nimprovements of span_iterator when using the Clang compiler. Previously, gsl::span\niterators could be up to 20 times slower than std::span under various workloads\n(range-for, <algorithm>, etc.). Through reorganization of the code and moving\naccess-checks out of the hot path, we have achieved performance parity for most\nworkloads (see #1168). This\nABI-preserving improvement makes gsl::span a more practical choice for code that is\nboth safe and fast.\nNew Features and Improvements\nAs the C++ Core Guidelines evolve with modern C++ practices, GSL continues to adapt and\ngrow. Working closely with the community, we’ve implemented key enhancements that make\nGSL more robust and easier to use in modern C++ codebases. These updates focus on type\nsafety, modern idioms, and better template support — areas crucial for production\ncode. Here are some of the key improvements since version 4.1.0:\nGSL Swap Support: Introduced gsl::swap specifically designed for safely swapping\ngsl::not_null pointers\nEnhanced Type Traits: Added element_type to gsl::not_null<T> for better type\ntrait consistency\nImproved Smart Pointer Support: Added support for strict_not_null with\nunique_ptr\nBetter SFINAE: Improved template substitution behavior throughout the library\nAlignment with C++ Standards\nAs part of our commitment to keeping GSL aligned with modern C++ development, we are\ndeprecating features that have been adopted into the C++ standard library. We recommend\nusing the C++ standard library equivalents for these features when possible. Here are\nthe features that have been deprecated in this release:\ngsl::unique_ptr\ngsl::shared_ptr\ngsl::byte (for C++17 and later)\nAdditionally, we have removed the long-deprecated string_span feature, encouraging\nusers to migrate to std::string_view.\nNote: We continue to recommend using gsl::span as a safer alternative to\nstd::span.\nCompatibility Updates\nWe want to make sure GSL runs well on the latest compilers and modern operating systems.\nTo that end, we have modernized our build infrastructure to validate that GSL is\nsupported by the latest development environments:\nUpdated compiler support to include Clang 16 to 18 and GCC 12 to 14\nUpgraded to Ubuntu 24.04 in our CI pipeline\nMore information about our supported platforms can be found in our\nREADME.\nBug Fixes and Standards Compliance\nSeveral important bugs have been fixed in this release:\nResolved a GCC-specific issue with list initialization of const references\nFixed SFINAE implementation in gsl::owner\nImproved include directive handling to prevent conflicts with standard library headers\nUpdated include paths to comply with C++ Core Guidelines\nTry It Out\nTo start using GSL v4.2.0, you can either:\nInstall via vcpkg: vcpkg install ms-gsl\nDownload from GitHub:\nmicrosoft/GSL\nFor detailed release notes and migration guidance, please visit our\nGitHub repository.\nContributing to GSL\nThis release would not have been possible without our community contributors. Special\nthanks to the following individuals for their valuable contributions:\n@ajtruckle\n@apenn-msft\n@asartori86\n@beinhaerter\n@daltairwalter\n@DanielJump\n@HenryHu\n@lord-pando\n@mhthies\n@paparodeo\n@tiagomacarios\nIf you wish to contribute to GSL, please refer to our open issues and pull requests in\nthe Microsoft/GSL repository on GitHub. We welcome\nyour feedback and contributions!\nPlease remember to follow our\nCode of Conduct when contributing to\nGSL.\nFeedback\nIn addition to contributing, we would love to hear your thoughts on the latest updates\nto GSL! Please share your feedback and suggestions in the comments below.\nThe post Announcing Guidelines Support Library v4.2.0 appeared first on C++ Team Blog.",
        "dc:creator": "Carson Radtke",
        "comments": "https://devblogs.microsoft.com/cppblog/announcing-guidelines-support-library-v4-2-0/#respond",
        "content": "<p>Version 4.2.0 of Microsoft's Guidelines Support Library brings performance improvements, safety features, modern compiler support.</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/announcing-guidelines-support-library-v4-2-0/\">Announcing Guidelines Support Library v4.2.0</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "Version 4.2.0 of Microsoft's Guidelines Support Library brings performance improvements, safety features, modern compiler support.\nThe post Announcing Guidelines Support Library v4.2.0 appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=35183",
        "categories": [
          "Announcement",
          "C++"
        ],
        "isoDate": "2025-03-06T09:36:54.000Z"
      }
    ]
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Building multimodal AI for Ray-Ban Meta glasses",
        "link": "https://engineering.fb.com/2025/03/04/virtual-reality/building-multimodal-ai-for-ray-ban-meta-glasses/",
        "pubDate": "Tue, 04 Mar 2025 21:24:18 +0000",
        "content:encodedSnippet": "Multimodal AI – models capable of processing multiple different types of inputs like speech, text, and images – have been transforming user experiences in the wearables space.\nWith our Ray-Ban Meta glasses, multimodal AI helps the glasses see what the wearer is seeing. This means anyone wearing Ray-Ban Meta glasses can ask them questions about what they’re looking at. The glasses can provide information about a landmark, translate text you’re looking at, and many other features.\nBut what does it take to bring AI into a wearable device?\nOn this episode of the Meta Tech Podcast, meet Shane, a research scientist at Meta who has spent the last seven years focusing on computer vision and multimodal AI for wearables. Shane and his team have been behind cutting edge AI research like AnyMAL, a unified language model that can reason over an array of input signals including text, audio, video, and even IMU motion sensor data.\nShane sits down with Pascal Hartig to share how his team is building foundational models for the Ray-Ban Meta glasses. They talk about the unique challenges of AI glasses and pushing the boundaries of AI-driven wearable technology.\nWhether you’re an engineer, a tech enthusiast, or simply curious, this episode has something for everyone!\nDownload or listen to the episode below:\n\nSpotify\nApple Podcasts\nPocket Casts\nOvercast\nThe Meta Tech Podcast is a podcast, brought to you by Meta, where we highlight the work Meta’s engineers are doing at every level – from low-level frameworks to end-user features.\nSend us feedback on Instagram, Threads, or X.\nAnd if you’re interested in learning more about career opportunities at Meta visit the Meta Careers page.\nLinks\nAnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model\nInside The Be My Eyes-Meta Collaboration\nCachelib\nMeta Open Source on Threads\nMeta’s AI-Powered Ray-Bans Are Life-Enhancing for the Blind\nTimestamps\nIntro 0:06\nOSS News 0:56\nIntroduction Shane 1:30\nThe role of research scientist over time 3:03\nWhat’s Multi-Modal AI? 5:45\nApplying Multi-Modal AI in Meta’s products 7:21\nAcoustic modalities beyond speech 9:17\nAnyMAL 12:23\nEncoder zoos 13:53\n0-shot performance 16:25\nIterating on models 17:28\nLLM parameter size 19:29\nHow do we process a request from the glasses? 21:53\nProcessing moving images 23:44\nScaling to billions of users 26:01\nWhere lies the optimization potential? 28:12\nIncorporating feedback 29:08\nOpen-source influence 31:30\nBe My Eyes Program 33:57\nWorking with industry experts at Meta 36:18\nOutro 38:55\nThe post Building multimodal AI for Ray-Ban Meta glasses appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Multimodal AI – models capable of processing multiple different types of inputs like speech, text, and images – have been transforming user experiences in the wearables space. With our Ray-Ban Meta glasses, multimodal AI helps the glasses see what the wearer is seeing. This means anyone wearing Ray-Ban Meta glasses can ask them questions about [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/03/04/virtual-reality/building-multimodal-ai-for-ray-ban-meta-glasses/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/03/04/virtual-reality/building-multimodal-ai-for-ray-ban-meta-glasses/\">Building multimodal AI for Ray-Ban Meta glasses</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Multimodal AI – models capable of processing multiple different types of inputs like speech, text, and images – have been transforming user experiences in the wearables space. With our Ray-Ban Meta glasses, multimodal AI helps the glasses see what the wearer is seeing. This means anyone wearing Ray-Ban Meta glasses can ask them questions about [...]\nRead More...\nThe post Building multimodal AI for Ray-Ban Meta glasses appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=22308",
        "categories": [
          "AI Research",
          "ML Applications",
          "Virtual Reality",
          "Meta Tech Podcast"
        ],
        "isoDate": "2025-03-04T21:24:18.000Z"
      },
      {
        "creator": "",
        "title": "A case for QLC SSDs in the data center",
        "link": "https://engineering.fb.com/2025/03/04/data-center-engineering/a-case-for-qlc-ssds-in-the-data-center/",
        "pubDate": "Tue, 04 Mar 2025 17:00:26 +0000",
        "content:encodedSnippet": "The growth of data and need for increased power efficiency are leading to innovative storage solutions.\nHDDs have been growing in density, but not performance, and TLC flash remains at a price point that is restrictive for scaling. \nQLC technology addresses these challenges by forming a middle tier between HDDs and TLC SSDs.   QLC provides higher density, improved power efficiency, and better cost than existing TLC SSDs. \nToday, HDDs are the go-to storage solution for most data centers because of their lower cost and power footprint compared to other solutions like TLC flash. But while HDDs are growing in size, they haven’t been growing in I/O performance. In other words, the bandwidth per TB for HDDs has been dropping. This has been forcing data center engineers to meet their storage performance needs by shifting hot (frequently accessed) data to a TLC flash tier or by overprovisioning storage.\nQLC flash as a technology has been around since 2009. Adoption has been slow because it has historically operated at lower drive capacity points – less than 32TB. As well, high cost and limited write endurance didn’t make it an attractive alternative to TLC in the datacenter. \nIn the meantime, HDD densities have been growing without any significant increase in the throughput. As more data is stored on a given drive the need for I/O goes up proportionally. The continued densification of HDD capacity has led to a consistent decline in BW/TB. This has negatively affected a portion of hot workloads and forced bytes to get stranded on HDDs.\n\nQLC flash occupies a unique space in the performance spectrum in between HDDs and SSDs for servicing workloads that still depend upon performance at 10 MB/s/TB range i.e., where we had 16-20TB HDDs. Additionally there are workloads doing large batch IOs which do not need very high performance but still are in the 15-20 MB/s/TB range and use TLC flash today.\nQLC flash introduced as a tier above HDDs can meet write performance requirements with sufficient headroom in endurance specifications. The workloads being targeted are read-bandwidth-intensive with infrequent as well as comparatively low write bandwidth requirements. Since the bulk of power consumption in any NAND flash media comes from writes, we expect our workloads to consume lower power with QLC SSDs. \nThe advent of the 2Tb QLC NAND die along with 32-die stack becoming mainstream illustrates just how rapidly the density scaling of QLC flash is growing at a NAND package level as well as at drive level.\nWe expect QLC SSD density will scale much higher than TLC SSD density in the near-term and long-term. This will bring meaningful impact to server and rack level bytes densification as well as help lower per-TB acquisition and power costs at both the drive and server level. \n\nQLC at Meta\nMeta’s storage teams have started working closely with partners like Pure Storage, utilizing their DirectFlash Module (DFM) and DirectFlash software solution to bring reliable QLC storage to Meta. We are also working with other NAND vendors to integrate standard NVMe QLC SSDs into our data centers. \nWhile today QLC is lower in cost than TLC, it is not yet price competitive enough for a broader deployment. Still, the gains in power consumption efficiency are material and the above mentioned use cases are expected to greatly benefit from that. Given that HDDs are continuing to get colder as their density increases (decreasing BW/TB), and that NAND cost structures are improving with technology advancements, we believe that adding a QLC tier is the right path forward.\nHardware considerations for adopting QLC\nWhile E1.S as a form factor has been great for our TLC deployments, it’s not an ideal form factor to scale our QLC roadmap because its size limits the number of NAND packages per drive.\nThe Industry standard U.2-15mm is still a prevalent form factor across SSD suppliers and it enables us to potentially scale to 512TB capacity. E3 doesn’t bring additional value over U.2 at the moment and the market adoption split between the 4 variants of E3 makes it less attractive. Pure Storage’s DFMs can allow scaling up to 600TB with the same NAND package technology. Designing a server to support DFMs allows the drive slot to also accept U.2 drives. This strategy enables us to reap the most benefits in cost competition, schedule acceleration, power efficiency, and vendor diversity.  \nThe primary benefit of QLC drives is byte density at the drive and server level and the associated power efficiency. Within Meta, the byte density target of the QLC-based server is 6x the densest TLC-based server we ship today. Even though the BW/TB expected of QLC is lower than TLC, the QLC server bytes density requires a more performant CPU, faster memory and network subsystem to take advantage of the media capabilities.  \nAdapting our storage software for QLC \nAdopting Meta’s existing storage software to QLC has presented some interesting challenges. As discussed above, our QLC systems are very high in density. And we are targeting QLC SSDs as a higher performance media compared to HDDs. This raises throughput expectations beyond any single server throughput we ever had. \nScaling such high throughput across CPU cores and sockets requires careful placement of data and compute to process that I/O. We need to make sure we minimize data touchpoints and can separate the I/O by type. The software stack in Pure Storage’s solutions uses Linux userspace block device driver (ublk) devices over io_uring to both expose the storage as a regular block device and enable zero copy for data copy elimination – as well as talk to their userspace FTL (DirectFlash software) in the background. \nFor other vendors, the stack uses io_uring to directly interact with the NVMe block device.\nFurther, QLC SSDs have a significant delta between read and write throughput. Read throughput in the case of QLC can be as high as 4x or more than write throughput. What’s more, typical use cases around reads are latency sensitive so we need to make sure that the I/O delivering this massive read BW is not getting serialized behind the writes. This requires building, and carefully tuning, rate controllers and I/O schedulers.\nLooking forward\nMeta recognizes QLC flash’s potential as a viable and promising optimization opportunity for storage cost, performance, and power for data center workloads. As flash suppliers continue to invest in advanced fab processes and package designs and increase the QLC flash production output, we anticipate substantial cost improvements, making QLC flash progressively more attractive for a broader range of data center workloads. We are excited about driving innovation, fostering collaboration, and promoting ecosystem alignment in this evolving storage space.\nThe post A case for QLC SSDs in the data center appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>The growth of data and need for increased power efficiency are leading to innovative storage solutions. HDDs have been growing in density, but not performance, and TLC flash remains at a price point that is restrictive for scaling.  QLC technology addresses these challenges by forming a middle tier between HDDs and TLC SSDs.   QLC [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/03/04/data-center-engineering/a-case-for-qlc-ssds-in-the-data-center/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/03/04/data-center-engineering/a-case-for-qlc-ssds-in-the-data-center/\">A case for QLC SSDs in the data center</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "The growth of data and need for increased power efficiency are leading to innovative storage solutions. HDDs have been growing in density, but not performance, and TLC flash remains at a price point that is restrictive for scaling.  QLC technology addresses these challenges by forming a middle tier between HDDs and TLC SSDs.   QLC [...]\nRead More...\nThe post A case for QLC SSDs in the data center appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=22312",
        "categories": [
          "Data Center Engineering"
        ],
        "isoDate": "2025-03-04T17:00:26.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": [
      {
        "creator": "Netflix Technology Blog",
        "title": "Title Launch Observability at Netflix Scale",
        "link": "https://netflixtechblog.com/title-launch-observability-at-netflix-scale-8efe69ebd653?source=rss----2615bd06b42e---4",
        "pubDate": "Wed, 05 Mar 2025 01:24:53 GMT",
        "content:encodedSnippet": "Part 3: System Strategies and Architecture\nBy: Varun Khaitan\nWith special thanks to my stunning colleagues: Mallika Rao, Esmir Mesic, Hugo Marques\nThis blog post is a continuation of Part 2, where we cleared the ambiguity around title launch observability at Netflix. In this installment, we will explore the strategies, tools, and methodologies that were employed to achieve comprehensive title observability at scale.\nDefining the observability endpoint\nTo create a comprehensive solution, we decided to introduce observability endpoints first. Each microservice involved in our Personalization stack that integrated with our observability solution had to introduce a new “Title Health” endpoint. Our goal was for each new endpoint to adhere to a few principles:\n\nAccurate reflection of production behavior\nStandardization across all endpoints\nAnswering the Insight Triad: “Healthy” or not, why not and how to fix it.\n\nAccurately Reflecting Production Behavior\nA key part of our solution is insights into production behavior, which necessitates our requests to the endpoint result in traffic to the real service functions that mimics the same pathways the traffic would take if it came from the usual callers.\nIn order to allow for this mimicking, many systems implement an “event” handling, where they convert our request into a call to the real service with properties enabled to log when titles are filtered out of their response and why. Building services that adhere to software best practices, such as Object-Oriented Programming (OOP), the SOLID principles, and modularization, is crucial to have success at this stage. Without these practices, service endpoints may become tightly coupled to business logic, making it challenging and costly to add a new endpoint that seamlessly integrates with the observability solution while following the same production logic.\nA service with modular business logic facilitates the seamless addition of an observability endpoint.\nStandardization\nTo standardize communication between our observability service and the personalization stack’s observability endpoints, we’ve developed a stable proto request/response format. This centralized format, defined and maintained by our team, ensures all endpoints adhere to a consistent protocol. As a result, requests are uniformly handled, and responses are processed cohesively. This standardization enhances adoption within the personalization stack, simplifies the system, and improves understanding and debuggability for engineers.\nThe request schema for the observability endpoint.\nThe Insight Triad API\nTo efficiently understand the health of a title and triage issues quickly, all implementations of the observability endpoint must answer: is the title eligible for this phase of promotion, if not — why is it not eligible, and what can be done to fix any problems.\nThe end-users of this observability system are Launch Managers, whose job it is to ensure smooth title launches. As such, they must be able to quickly see whether there is a problem, what the problem is, and how to solve it. Teams implementing the endpoint must provide as much information as possible so that a non-engineer (Launch Manager) can understand the root cause of the issue and fix any title setup issues as they arise. They must also provide enough information for partner engineers to identify the problem with the underlying service in cases of system-level issues.\nThese requirements are captured in the following protobuf object that defines the endpoint response.\nThe response schema for the observability endpoint.\nHigh level architecture\nWe’ve distilled our comprehensive solution into the following key steps, capturing the essence of our approach:\n\nEstablish observability endpoints across all services within our Personalization and Discovery Stack.\nImplement proactive monitoring for each of these endpoints.\nTrack real-time title impressions from the Netflix UI.\nStore the data in an optimized, highly distributed datastore.\nOffer easy-to-integrate APIs for our dashboard, enabling stakeholders to track specific titles effectively.\n“Time Travel” to validate ahead of time.\nObservability stack high level architecture diagram\nIn the following sections, we will explore each of these concepts and components as illustrated in the diagram above.\nKey Features\nProactive monitoring through scheduled collectors jobs\nOur Title Health microservice runs a scheduled collector job every 30 minutes for most of our personalization stack.\nFor each Netflix row we support (such as Trending Now, Coming Soon, etc.), there is a dedicated collector. These collectors retrieve the relevant list of titles from our catalog that qualify for a specific row by interfacing with our catalog services. These services are informed about the expected subset of titles for each row, for which we are assessing title health.\nOnce a collector retrieves its list of candidate titles, it orchestrates batched calls to assigned row services using the above standardized schema to retrieve all the relevant health information of the titles. Additionally, some collectors will instead poll our kafka queue for impressions data.\nReal-time Title Impressions and Kafka Queue\nIn addition to evaluating title health via our personalization stack services, we also keep an eye on how our recommendation algorithms treat titles by reviewing impressions data. It’s essential that our algorithms treat all titles equitably, for each one has limitless potential.\nThis data is processed from a real-time impressions stream into a Kafka queue, which our title health system regularly polls. Specialized collectors access the Kafka queue every two minutes to retrieve impressions data. This data is then aggregated in minute(s) intervals, calculating the number of impressions titles receive in near-real-time, and presented as an additional health status indicator for stakeholders.\nData storage and distribution through Hollow Feeds\nNetflix Hollow is an Open Source java library and toolset for disseminating in-memory datasets from a single producer to many consumers for high performance read-only access. Given the shape of our data, hollow feeds are an excellent strategy to distribute the data across our service boxes.\nOnce collectors gather health data from partner services in the personalization stack or from our impressions stream, this data is stored in a dedicated Hollow feed for each collector. Hollow offers numerous features that help us monitor the overall health of a Netflix row, including ensuring there are no large-scale issues across a feed publish. It also allows us to track the history of each title by maintaining a per-title data history, calculate differences between previous and current data versions, and roll back to earlier versions if a problematic data change is detected.\nObservability Dashboard using Health Check Engine\nWe maintain several dashboards that utilize our title health service to present the status of titles to stakeholders. These user interfaces access an endpoint in our service, enabling them to request the current status of a title across all supported rows. This endpoint efficiently reads from all available Hollow Feeds to obtain the current status, thanks to Hollow’s in-memory capabilities. The results are returned in a standardized format, ensuring easy support for future UIs.\nAdditionally, we have other endpoints that can summarize the health of a title across subsets of sections to highlight specific member experiences.\nMessage depicting a dashboard request.\nTime Traveling: Catching before launch\n\nTitles launching at Netflix go through several phases of pre-promotion before ultimately launching on our platform. For each of these phases, the first several hours of promotion are critical for the reach and effective personalization of a title, especially once the title has launched. Thus, to prevent issues as titles go through the launch lifecycle, our observability system needs to be capable of simulating traffic ahead of time so that relevant teams can catch and fix issues before they impact members. We call this capability “Time Travel”.\nMany of the metadata and assets involved in title setup have specific timelines for when they become available to members. To determine if a title will be viewable at the start of an experience, we must simulate a request to a partner service as if it were from a future time when those specific metadata or assets are available. This is achieved by including a future timestamp in our request to the observability endpoint, corresponding to when the title is expected to appear for a given experience. The endpoint then communicates with any further downstream services using the context of that future timestamp.\nAn example request with a future timestamp.\nConclusion\nThroughout this series, we’ve explored the journey of enhancing title launch observability at Netflix. In Part 1, we identified the challenges of managing vast content launches and the need for scalable solutions to ensure each title’s success. Part 2 highlighted the strategic approach to navigating ambiguity, introducing “Title Health” as a framework to align teams and prioritize core issues. In this final part, we detailed the sophisticated system strategies and architecture, including observability endpoints, proactive monitoring, and “Time Travel” capabilities; all designed to ensure a thrilling viewing experience.\nBy investing in these innovative solutions, we enhance the discoverability and success of each title, fostering trust with content creators and partners. This journey not only bolsters our operational capabilities but also lays the groundwork for future innovations, ensuring that every story reaches its intended audience and that every member enjoys their favorite titles on Netflix.\nThank you for joining us on this exploration, and stay tuned for more insights and innovations as we continue to entertain the world.\n\nTitle Launch Observability at Netflix Scale was originally published in Netflix TechBlog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Netflix Technology Blog",
        "guid": "https://medium.com/p/8efe69ebd653",
        "categories": [
          "system-design-concepts",
          "netflix",
          "software-engineering",
          "observability"
        ],
        "isoDate": "2025-03-05T01:24:53.000Z"
      }
    ]
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Matthias Koch",
        "title": "Webinar – OSS Power-Ups: EntityFramework.Exceptions",
        "link": "https://blog.jetbrains.com/dotnet/2025/03/07/webinar-oss-power-ups-entityframework-exceptions/",
        "pubDate": "Fri, 07 Mar 2025 14:42:16 +0000",
        "content:encodedSnippet": "Join us Tuesday, March 18, 2025, 14:00 – 15:30 UTC (check other timezones) for our free live webinar, OSS PowerUps – EntityFramework.Exceptions, with Giorgi Dalakishvili. This is the fourtheenth episode of our series of OSS Power-Ups, where we put a spotlight on open-source .NET projects.\nRegister now and get a reminder, or join on YouTube\nWhen using Entity Framework Core for data access, all database exceptions are wrapped in DbUpdateException. If you need to know whether the exception was caused by a unique constraint, the value being too long, or the value missing for a required column, you need to dig into the concrete DbException subclass instance and check the error number to determine the exact cause. In this episode, learn how EntityFramework.Exceptions handles all the database-specific details and allows you to use typed exceptions for Entity Framework Core when your query violates database constraints.\n\n\n\n\nYou can attend Giorgi Dalakishvili’s webinar on YouTube, or register here to get a reminder closer to the webinar.\nAbout the presenter:\nGiorgi Dalakishvili\nGiorgi is a software developer with more than a decade of experience. He works mainly with C#, ASP.NET Core, REST, MAUI, Xamarin, Entity Framework Core, AWS, and SQL Server. He has also worked with many other frameworks and systems such as GraphQL, ASP.NET MVC, ASP.NET Web API, WCF, Avalonia, WinForms, Oracle, and others.\nGiorgi is an open-source author and contributor on GitHub, and a member of the .NET Foundation.\nYou can follow Giorgi on Twitter, BlueSky, LinkedIn, and GitHub.",
        "dc:creator": "Matthias Koch",
        "content": "Join us Tuesday, March 18, 2025, 14:00 – 15:30 UTC (check other timezones) for our free live webinar, OSS PowerUps – EntityFramework.Exceptions, with Giorgi Dalakishvili. This is the fourtheenth episode of our series of OSS Power-Ups, where we put a spotlight on open-source .NET projects. Register now and get a reminder, or join on YouTube [&#8230;]",
        "contentSnippet": "Join us Tuesday, March 18, 2025, 14:00 – 15:30 UTC (check other timezones) for our free live webinar, OSS PowerUps – EntityFramework.Exceptions, with Giorgi Dalakishvili. This is the fourtheenth episode of our series of OSS Power-Ups, where we put a spotlight on open-source .NET projects. Register now and get a reminder, or join on YouTube […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=545527",
        "categories": [
          "net-tools",
          "livestreams",
          "entity-framework-core",
          "oss",
          "power-up"
        ],
        "isoDate": "2025-03-07T14:42:16.000Z"
      },
      {
        "creator": "Dmitrii Korovin",
        "title": "TeamCity 2024.12.3 Bug Fix Is Out!",
        "link": "https://blog.jetbrains.com/teamcity/2025/03/teamcity-2024-12-3-bug-fix/",
        "pubDate": "Fri, 07 Mar 2025 09:54:08 +0000",
        "content:encodedSnippet": "The TeamCity On-Premises 2024.12.3 bug-fix update is out and ready to be installed on your servers! This update resolves over 10 issues and, as always, includes essential security and performance fixes. We highly recommend upgrading to keep your system secure and optimized. The list of resolved issues includes:\nS3 cleanup fails to remove artifacts;\nGitHub App timeouts when loading repositories;\nInability to mute Unit5 TestFactory-generated tests.\nSee TeamCity 2024.12.3 Upgrade Notes for the complete list.\nWhy update?\nStaying up to date with minor releases ensures your TeamCity instance benefits from the following:\nPerformance improvements.\nBetter compatibility with integrations.\nFaster, more stable builds.\nEnhanced security for your workflows.\nCompatibility\nTeamCity 2024.12.3 shares the same data format as all 2024.12.x releases. You can upgrade or downgrade within this series without the need for backup and restoration.\nHow to upgrade\nUse the automatic update feature in your current TeamCity version.\nDownload the latest version directly from the JetBrains website.\nPull the updated TeamCity Docker image.\nNeed help?\nThank you for reporting issues and providing feedback! If you have questions or run into any problems, please let us know via the TeamCity Forum or Issue Tracker.\nHappy building!",
        "dc:creator": "Dmitrii Korovin",
        "content": "The TeamCity On-Premises 2024.12.3 bug-fix update is out and ready to be installed on your servers! This update resolves over 10 issues and, as always, includes essential security and performance fixes. We highly recommend upgrading to keep your system secure and optimized. The list of resolved issues includes: See TeamCity 2024.12.3 Upgrade Notes for the [&#8230;]",
        "contentSnippet": "The TeamCity On-Premises 2024.12.3 bug-fix update is out and ready to be installed on your servers! This update resolves over 10 issues and, as always, includes essential security and performance fixes. We highly recommend upgrading to keep your system secure and optimized. The list of resolved issues includes: See TeamCity 2024.12.3 Upgrade Notes for the […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=551676",
        "categories": [
          "bug-fix"
        ],
        "isoDate": "2025-03-07T09:54:08.000Z"
      },
      {
        "creator": "Kerry Beetge",
        "title": "What Are OWASP Top 10 Checks and How Can Your Team Benchmark Security?",
        "link": "https://blog.jetbrains.com/qodana/2025/03/owasp-top-10/",
        "pubDate": "Fri, 07 Mar 2025 09:42:40 +0000",
        "content:encodedSnippet": "Businesses of different sizes have various motives for prioritizing code security. For an enterprise client, it might have to do with compliance. For a business that handles user data, there could be very imminent risk to customers and staff alike. \nAny development team could fall prey to the rise of cybercrime and attacks as detailed in the CyberCrime Report and many other sources. This is one reason why it’s so important to secure your codebase against both seemingly simple and more sophisticated and malicious activity. \nThen again, it’s easy to say that developer teams need to prioritize security, but this is sometimes difficult to put into practice. What frameworks are most helpful? Can they be applied to teams of any size and industry? And which standards do developers trust to help them achieve a level of foundational security and safety?\nTable of Contents\n\nWhat is OWASP?\nCommon OWASP Top 10 checks\nSQL Injection\nPrevention is better than cure\nBroken Authentication\nSensitive data exposure\nXML External Entities (XXE)\nBroken Access Control\nSecurity Misconfiguration\nCross-Site Scripting (XSS)\nInsecure deserialization\n\nOWASP guidance in a nutshell\n\nWhat is OWASP?\nThe Open Web Application Security Project (OWASP) is an organization dedicated to improving software security. One of its primary contributions is the OWASP Top 10, which outlines the most critical security risks to web applications and provides the checks that organizations should consider when enhancing application security. While OWASP hasn’t officially released the list for 2025, we’re taking a closer list of some common contenders today. Let’s dive in: \nCommon OWASP Top 10 checks\nSQL Injection\nSQL Injection (SQLi) is a type of injection attack where an attacker can execute arbitrary SQL code on a database by manipulating the SQL queries made by an application.\nHow it happens:\nSQLi typically happens when user inputs are directly included in SQL statements without proper validation or escaping. For example:\nSELECT * FROM users WHERE username = ‘user_input’;\nIf user_input is not sanitized, an attacker could input something like admin’ –, which might change the original query’s logic.\nPrevention is better than cure\nTo prevent this, you could use prepared statements with parameterized queries to separate SQL logic from user input. Stored procedures are precompiled SQL statements that can accept parameters. Always validate and sanitize user inputs. \nEnsure that only expected values are accepted (e.g., alphanumeric validation) and avoid displaying detailed error messages to users, which could give attackers insights into the database structure. The database account used by the application should have no more privileges than necessary, that way one can at least reduce the impact if an SQL injection is successful.\nYou also get Command Injections, which the attacker manages to execute arbitrary commands on the host operating system via a vulnerable application. For example, an attacker might input ; rm -rf / to execute unauthorized commands. To prevent these you should avoid executing system commands, use safe, language-specific APIs that don’t invoke command shells, and if user inputs have to be included in a command shell, make sure that inputs are properly escaped. \nQodana’s Taint Analysis helps prevent security vulnerabilities like SQL injections, cross-site scripting (XSS), command injections, and path traversal and is supported in IntelliJ IDEA as well as in Qodana for Php and JVM. \nBroken Authentication\nCheck for Broken Authentication aims to address vulnerabilities in user authentication processes and session management that can lead to a range of security risks.\nYou can address this by implementing Multi-Factor Authentication (MFA) and making sure sessions are securely managed. MFA is a security mechanism that requires users to use two or more independent credentials to verify their identity. \nInstead of just relying on a username and a password, which can be stolen, guessed, or brute-forced, MFA adds extra layers of security that make authentication more secure with biometric, device, or knowledge entries. If you use this in conjunction with secure session management, you have a good starting point for better and more secure authentication. \nPrevention measures\nIt matters how applications handle user sessions over the duration of their interactions with the system. When users log in an application, the application creates a session (or token) to keep track of their authenticated status. The identifiers for these have to be unique and transmitted securely using HTTPS to encrypt data between the client and the server. \nSensitive data exposure\nSensitive data can include personal information (PII), payment information, healthcare records, authentication credentials, and any other data that could be harmful if exposed.\nTo combat this, developers need to encrypt data in transit over networks and “at rest”, i.e. stored on servers and databases. \nYou can do this by generating cryptographic keys that use secure, random sources and only allow authorized people and applications to access them. Never hard-code keys in the application or configuration files. You can also implement a key rotation policy. \nAlso keep in mind that Hardcoded secrets are related to several items in the OWASP Top 10, particularly “Sensitive Data Exposure” and “Broken Authentication.” Detecting hardcoded passkeys helps to mitigate risks associated with these vulnerabilities. \n\n\n\n\n\n\nXML External Entities (XXE)\nXML External Entities (XXE) is a vulnerability that happens when an XML parser doesn’t process external entity references properly. Attackers can exploit this vulnerability for:\nData exfiltration: Attackers can manipulate an XML input to read sensitive files from the server or sensitive information from other places.\nDenial of Service (DoS): By including a large number of entities in the XML file, an attacker can cause the application to consume excessive resources, leading to service outages.\nServer Side Request Forgery (SSRF): Attackers can access internal services and resources which are not directly accessible from the outside world.\nThe best way to mitigate XXE vulnerabilities is to entirely disable the external entities being processed. This can usually be configured in the XML parsing libraries that your application is using. \nFor example, if you’re using Java with DOM or SAX parsers, you can configure them to disable DTD processing and external entities:\nDocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance();\ndbf.setValidating(false);\ndbf.setFeature(“http://xml.org/sax/features/external-general-entities”, false);\ndbf.setFeature(“http://xml.org/sax/features/external-parameter-entities”, false);\ndbf.setFeature(“http://apache.org/xml/features/disallow-doctype-decl”, true);\nYou can also implement strict validation and schema checks for XML inputs. This process ensures that the XML data adheres to a predefined structure and is what your application expects.\nBroken Access Control\nRole-Based Access Control (RBAC) is a widely used method for restricting system access to authorized users. In RBAC, permissions are assigned based on roles rather than individual users, which helps streamline the management of user access. However, without proper implementation and regular testing, systems can become vulnerable. \nGet ahead of access issues\nClearly define roles based on job responsibilities and least privilege principles. Ensure roles align closely with user needs and limit permissions to what is strictly necessary. Some organizations may need to define hierarchical roles. For instance, a manager could inherit the permissions of their subordinates, but without additional privileges that they do not require.\nConduct periodic reviews of roles and permissions to ensure they remain relevant and appropriate. Consider any role changes in personnel or shifts in organizational processes. Implement temporary or context-sensitive roles for particular tasks or projects. This way, users can gain additional permissions as needed without permanently extending their permissions.\nMaintain detailed logs of access attempts and regularly monitor these logs for any suspicious activity. This can help you spot any causes for concern like unwanted access. \nControl testing is another important tactic to help identify potential vulnerabilities like horizontal (same level access) and vertical (higher-level access) privileges.You can use automated security testing tools that can simulate various attack vectors to check for access control weaknesses. Tools can be used to check access control lists (ACLs) and role permissions programmatically.\nSecurity Misconfiguration\nImproper security configurations are one of OWASP’s major checks because default settings can create security risks. \nTo prevent this, change any default passwords right after installing new systems. Those default passwords are often widely known and can be a goldmine for attackers. \nAlso, many applications and operating systems come with unnecessary services turned on by default, so go through and turn off those unused features to decrease vulnerabilities. Also make sure that default roles and access permissions aren’t giving users more access than they really need.\nAlso, apply security hardening guidelines for servers, databases, and applications to eliminate unnecessary features and reduce attack surfaces.\nAnd keep in mind that before deploying patches to production systems, it’s important to test them in a staging environment to identify any potential compatibility issues or bugs that could arise from the update.\nCross-Site Scripting (XSS)\nCross-Site Scripting (XSS) is a type of security vulnerability that allows an attacker to inject malicious scripts into content delivered to users’ web browsers. When a user visits a page that contains XSS, the malicious script can execute within the context of that user’s session, leading to various risks, including data theft, session hijacking, or defacement of web applications.\nMitigating cross-site scripting risk\nMitigate this issue with output encoding to ensure that user inputs are properly encoded before they’re visible and only show up as plain text. You could do this by converting characters into their HTML equivalents, encoding characters that are specific to HTML attributes like “ and in JavaScript properly escaping a user input so that it won’t execute the script. You could also implement a content security policy to mitigate the risk of XSS attacks. \nIf you’re using IntelliJ IDEA, you can use the Qodana plugin to find and address cross-site scripting. Find it under the Problems tab in the Security Analysis section. \n\n\n\n\nInsecure deserialization\nInsecure deserialization occurs when an application accepts data from untrusted sources and interprets it as a serialized object without proper validation. This opens the door for attackers to manipulate the serialized data, potentially leading to remote code execution, data tampering, or denial-of-service attacks. \nMitigate these risks\nAvoid deserializing untrusted data altogether. If deserialization is necessary, developers should implement stringent checks to validate the integrity and format of the incoming data. Using safe serialization formats, which don’t allow for arbitrary code execution, can hugely reduce the risks associated with processing untrusted data.\nIntegrity checks also play a big role in securing serialized data. Digital signatures or cryptographic hashes allow an application to verify that the serialized object has not been altered in any way it’s not supposed to be. \nBy signing serialized data with a private key, the application can later check the signature against the expected outcome using a public key, helping to ensure the data’s authenticity. Also, using hashes enables the application to confirm that the data remains unchanged. However, even with integrity checks, deserializing data from untrusted sources should be minimized or avoided.\nOWASP guidance in a nutshell\nSecure your application development and deployment more thoroughly by using these checks as a security benchmark. Regular security testing, code reviews, and security training for developers play a crucial role in minimizing risks associated with these vulnerabilities. \nIf you are implementing OWASP standards, consider using resources like the OWASP Cheat Sheets, OWASP Testing Guide, and OWASP Best Practices for secure coding. You can also use Qodana to look for issues and run select security checks in your CI/CD pipeline.",
        "dc:creator": "Kerry Beetge",
        "content": "Businesses of different sizes have various motives for prioritizing code security. For an enterprise client, it might have to do with compliance. For a business that handles user data, there could be very imminent risk to customers and staff alike.  Any development team could fall prey to the rise of cybercrime and attacks as detailed [&#8230;]",
        "contentSnippet": "Businesses of different sizes have various motives for prioritizing code security. For an enterprise client, it might have to do with compliance. For a business that handles user data, there could be very imminent risk to customers and staff alike.  Any development team could fall prey to the rise of cybercrime and attacks as detailed […]",
        "guid": "https://blog.jetbrains.com/?post_type=qodana&p=551778",
        "categories": [
          "qodana",
          "security",
          "free-learning",
          "security-checks",
          "taint-analysis"
        ],
        "isoDate": "2025-03-07T09:42:40.000Z"
      },
      {
        "creator": "Jan-Niklas Wortmann",
        "title": "The Angular Language Server: Understanding IDE Integration Approaches",
        "link": "https://blog.jetbrains.com/webstorm/2025/03/the-angular-language-server-understanding-ide-integration-approaches/",
        "pubDate": "Thu, 06 Mar 2025 18:26:00 +0000",
        "content:encodedSnippet": "The Language Server Protocol (LSP) has been a fundamental part of the code editor landscape for years, providing a consistent development experience across different editors. The Angular Language Server leverages this protocol to provide Angular-specific features to compatible editors. However, not all IDEs take the same approach to delivering these capabilities. Let’s look at the major differences between VS Code, NeoVim, and WebStorm and finally answer the age-old question, “Why does WebStorm not just use the Angular Language Server?!”\nWhat is a language server, and how does the LSP work?\nModern code editors need to understand your code to provide features like autocompletion, go to definition, or error detection. Traditionally, each editor needed to implement this understanding for every programming language, leading to duplicated effort and inconsistent experiences across editors.\nThe Language Server Protocol (LSP) solves this by standardizing how editors communicate with language-specific analysis tools. Here’s how it works:\nYour editor (the client) sends information about your code (typically the file that is currently open in your editor) to a language server.\nThe language server analyzes the code and responds with insights.\nYour editor displays these insights as squiggly error lines, autocompletion popups, or other UI elements.\n\n\n\n\n\n// When you type this in your editor\n@Component({\n  template: `\n    <div *ngFor=\"let item of items\">\n      {{ item.property }}\n    </div>\n  `\n})\nclass MyComponent { }\nYour editor sends the file content to the language server. The server analyzes it and might respond with:\n{\n  \"diagnostics\": [{\n    \"message\": \"Property 'property' does not exist on type 'any'\",\n    \"range\": {\n      \"start\": {\"line\": 3, \"character\": 12},\n      \"end\": {\"line\": 3, \"character\": 20}\n    }\n  }]\n}\n// Your editor then shows the error underline\nThis standardization means that:\nDevelopers of editors and IDEs can add support for new languages just by implementing the LSP client once.\nLanguage tool developers can support all LSP-compatible editors with a single server and very small client implementations (JetBrains IDE plugin or VS Code plugin).\nDevelopers get consistent features across different editors.\nThe Angular Language Server specifically provides Angular-aware code analysis, offering features like template type checking, component property completion, and Angular-specific refactorings to any editor that supports LSP.\nBenefits of the Language Server Protocol\nThe LSP has established itself as the standard for providing editor intelligence across different development environments. It enables consistent features like type checking, code completion, and navigation across any LSP-compatible editor:\n@Component({\n  template: `\n    <div *ngFor=\"let item of items\">\n      {{ item?.deeply?.nested?.property }}\n    </div>\n  `\n})\nclass WhyTypeCheckingMatters { }\nWhile the Angular compiler would catch these template errors during build time, the language server provides immediate feedback in your editor. This means you can spot and fix type errors as you write your code, without waiting for the compilation step.\nVS Code: LSP’s golden child\nVS Code’s integration with the Angular Language Server is seamless and intuitive. Here are some of the features that you’ll be able to use after installing the necessary plugin:\nTemplate type checking: Because nobody likes finding out about undefined properties in production.\nGo To Definition: Jump straight to your TypeScript references.\nAutocompletion: For when you can’t remember the syntax of *ngFor or @switch.\nReal-time error detection: Catch those typos before they catch you out.\nThe best part? It’s all standardized. The same language server that powers VS Code can power any editor that speaks LSP.\nNeovim: for when Vim users want nice things, too\nRemember when Vim users had to type out every import statement manually? Pepperidge Farm remembers. Now, thanks to LSP, you get:\n-- Neovim config that actually gives you IDE features\nrequire'lspconfig'.angularls.setup{\n  -- Look ma, real autocomplete!\n}\nNeovim users now enjoy the same powerful features as VS Code users while keeping their beloved modal editing. It’s the best of both worlds – modern IDE features with an outstanding editing experience.\nThe caveats of language servers\nLanguage servers are great – they provide a consistent developer experience and guarantee correctness. However, the fact that language servers adhere to a standardized protocol means that they do have some limitations. For instance, even though most languages and frameworks have some kind of test support, the LSP is not aware of this concept, and, therefore, tests must be configured manually within the editor. This is also the case when working with debuggers, too.\nAdditionally, language servers generally look at the codebase on a “file by file” basis, and, more specifically, at the current cursor position. Generally speaking, this works great until it doesn’t… Implementing a multi-file refactoring, for instance, can be difficult (though not impossible). For this reason, extracting some HTML code into a new Angular component is not as straightforward as it might first sound. On top of that, language servers can usually only process one language at a time; therefore, refactoring a CSS class across languages can quickly become very cumbersome in a language server implementation. The Angular Language Server has a very clever trick for handling HTML and TypeScript, but more on that in the next section. CSS, on the other hand, doesn’t enjoy the same level of support. \nWhat’s more, adding further support for parts that don’t have dedicated compiler functionality is difficult to accomplish. One such example would be IntelliSense for the host property of the component decorator.\nWebStorm: a slightly different approach\nNow, here’s where things get interesting. WebStorm and other JetBrains IDEs take a different approach, and it’s not just about being contrarian. For the last few years, the Angular plugin has been pre-installed with WebStorm. As of now, this plugin does not utilize the Angular Language Server, but a custom-type engine. As part of our new Service-powered type engine (more about this in the future), we made some major changes to our Angular integration. Instead of using the entire Angular Language Server, WebStorm adopted Angular’s TCB (type-check block) engine, an integral part of the Angular Language Server. For more details, you can check out this talk at NG DE, but in short, the Angular Language Server converts the HTML code into TypeScript code and uses the generated TypeScript code to map errors and IntelliSense features back to the cursor position in the original HTML file. The screenshot below visualizes this concept.\n\n\n\n\nSee how this.counter is used in the template, which gets converted to the function _tcb1 on the right side, but isn’t properly declared in TestComponent. \nYou might now be asking, why doesn’t WebStorm just use the Angular Language Server? Well, it turns out template type checking is just one piece of the IDE puzzle. WebStorm’s architecture already handles most of what the Angular Language Server provides:\nNavigation\nCode completion\nQuick-fixes\nFurthermore, it offers parts of functionality that our users appreciate and that are not offered by the language server:\nUnit and E2E test integration for Jasmine, Jest, Vitest, Cypress, and Playwright.\nDebugging integration.\nSemantic highlighting of signals (fun fact: the Angular LSP does not provide syntax highlighting, which is part of the VS Code plugin).\nSpecial refactoring and quick-fix capabilities (e.g. extract Angular Component, create a signal ‘property’, etc.).\nIntelliSense without compiler support, like the host property mentioned above.\nEnhanced search capabilities (e.g. Find Usages for components).\nThe real-world implications\nSo what does this mean for you, the developer, just trying to get work done?\nVS Code and Neovim users\nStandardized experience across editors\nRegular updates with Angular releases\nBuilt-in type correctness\nWebStorm users\nBuilt-in integration of broader IDE tools (debugger, test runner, run configurations, etc.)\nDirect TCB integration for template type checking\nAdditional navigation, refactoring features, and consistent development experiences across different languages (HTML, CSS, and TypeScript)\nLooking forward\nThe Angular Language Server continues to evolve, making developers’ lives easier. Meanwhile, WebStorm’s specialized approach shows that there’s more than one way to achieve excellent Angular support.",
        "dc:creator": "Jan-Niklas Wortmann",
        "content": "The Language Server Protocol (LSP) has been a fundamental part of the code editor landscape for years, providing a consistent development experience across different editors. The Angular Language Server leverages this protocol to provide Angular-specific features to compatible editors. However, not all IDEs take the same approach to delivering these capabilities. Let’s look at the [&#8230;]",
        "contentSnippet": "The Language Server Protocol (LSP) has been a fundamental part of the code editor landscape for years, providing a consistent development experience across different editors. The Angular Language Server leverages this protocol to provide Angular-specific features to compatible editors. However, not all IDEs take the same approach to delivering these capabilities. Let’s look at the […]",
        "guid": "https://blog.jetbrains.com/?post_type=webstorm&p=551237",
        "categories": [
          "all-things-web",
          "web-development",
          "webstorm"
        ],
        "isoDate": "2025-03-06T18:26:00.000Z"
      },
      {
        "creator": "Irina Mariasova",
        "title": "Java Annotated Monthly – March 2025",
        "link": "https://blog.jetbrains.com/idea/2025/03/java-annotated-monthly-march-2025/",
        "pubDate": "Thu, 06 Mar 2025 12:17:04 +0000",
        "content:encodedSnippet": "Welcome to this month’s Java Annotated Monthly! As always, we bring you the most interesting tutorials on Java, Kotlin, and other technologies, along with the latest news you don’t want to miss.\nWe’re also excited to introduce a brand-new AI section, which we reserve for the most fascinating content on the topic. And this month, we’re honored to feature Angie Jones as the author for our Featured Content section – so you know it’s going to be a great read!\nA lot of exciting things are happening, so without further ado, let’s go! \nFeatured Content\n\nAngie Jones is the Global Vice President of Developer Relations at Block, Inc.\nAn award-winning educator and international keynote speaker, Angie shares her extensive knowledge with software companies and conference audiences worldwide.A master inventor, Angie is recognized for her innovative, out-of-the-box thinking, which has led to 27 patented inventions in virtual worlds, collaboration software, social networking, smarter planet initiatives, and software development processes.\n\nAs a Java Champion, I make it a point to stay up to date on what’s happening in the JVM ecosystem and, more importantly, share it with my fellow Java developers. To my delight, we’re seeing the Java ecosystem embrace AI integration more than ever, thanks to the Model Context Protocol (MCP). MCP offers a standardized way to connect AI models with various tools and data sources, which means we can now employ AI agents like Goose within our local environments.\nJetBrains MCP Server\nI was pleased to see that JetBrains created an MCP Server plugin that integrates with MCP-enabled AI agents like Goose and Claude Desktop. This combination allows developers to enhance their JetBrains IDEs with AI capabilities, enabling tasks like code analysis and automated refactoring directly within the development environment. For example, I used Goose within IntelliJ IDEA. and right from the IDE’s terminal, I asked it to upgrade my project from Java 14 to Java 21 and modernize my codebase using the latest Java features:\n“Hey Goose, using the JetBrains extension, upgrade this project to use the latest Java LTS version and refactor the codebase to use newer Java features where beneficial.”\nWithin two minutes, I had a fully upgraded project with shiny new features such as string templates, pattern matching for switch and instanceof, sealed classes, records, text blocks, and switch expressions!\nThis alone blew me away, but I also loved that I could see how these new features worked within my own project, making them much easier to learn and apply.\nOfficial MCP Java SDK\nMCP is an open ecosystem. This means anyone can create an MCP server or even their own AI agent. There were already MCP SDKs for Kotlin, TypeScript, and Python, and as of mid-February (Valentine’s Day, to be exact ❤️), there’s now an official MCP Java SDK! There are more than 1,300 MCP servers that provide access to tons of APIs, but if there’s an API that you want to add to the ecosystem, you can now build it yourself with the MCP Java SDK.\nSpring AI with MCP\nFor those utilizing the Spring framework, you simply must check out Spring AI’s integration with MCP. Spring AI is incorporating MCP to make it easier for Spring Boot applications to interact with AI agents and external tools. For a visual demonstration of how MCP simplifies AI integration, check out this cool video by my dear friend and Spring expert, Josh Long.\nMore to explore!\nI have to tell you, I’m having an absolute blast incorporating AI into my workflows. I’m feeling more productive, efficient, and creative than ever! I have my eye on two other MCP servers I want to try:\nJavaFX MCP Server – allows you to create drawings using a JavaFX canvas directly from your AI agent. Whether it’s automating UI prototyping or generating visualizations, this opens up some exciting possibilities.\n\n\n\n\nJDBC MCP Server – a database connector that allows AI agents to interact with any JDBC-compatible database, including MySQL, PostgreSQL, Oracle, SQL Server, SQLite, and more. This enables natural language querying, inserting, updating, and deleting data.\nIf you haven’t played around with MCP and AI agents yet, now’s the perfect time. \nJava News\nJava News Roundup 1, 2, 3, 4 – Get the latest news from the Java community. \nJoin the Celebration of 30 Years of Java – Join a virtual event on March 13, hosted by Azul, to celebrate 30 years of Java. \nJDK 24 and JDK 25: What We Know So Far – Michael Redlich summarizes the new features in JDK 24 and hints at what’s coming in JDK 25.\nJava Resists Quantum Attacks – Inside Java Newscast #85 – Explore how Java is preparing for the future of cryptography with new APIs and algorithms to defend against quantum computing threats.\nJava 24: What’s New? – Get an overview of the features and improvements in Java 24, including updates to garbage collection, object headers, and security enhancements.\nJava Language Evolution in 2025 – Inside Java Newscast #84 – Discover how Project Amber plans to enhance the Java language in 2025.\nKeep an eye on some expected deprecations:\nQuality Outreach Heads-up – JDK 24: Remote Debugging with jstat and jhsdb Is Deprecated for Removal \nQuality Outreach Heads-up – JDK 25: Proposal to Deprecate for Removal -UseCompressedClassPointers\nJava Tutorials and Tips\nModern Java Deep Dive – In this talk recorded at Devoxx Belgium 2024, Nicolai Parlog explores the new features and improvements in Java 22 and 23, covering language updates, API enhancements, and changes to runtime.\nIntelliJ 101 — Part 1: Save Time with Regex Search & Replace – Aicha Laafia explains how to use regular expressions in IntelliJ IDEA to find and replace text quickly and make data reformatting easier.\nGarbage Collection in Java – The progress since JDK 8 – Since JDK 8, the GC performance has improved significantly, removing much of the overhead usually associated with automatic memory management. Learn more about its evolution from this talk by Stefan Johansson. \nAssert but Verify – Donald Raab discusses how relying solely on inheritance for convenience in Java can lead to problems and emphasizes the importance of verifying assumptions in code.\nThese IntelliJ IDEA Features Will SAVE YOUR BACON – Trisha Gee shares her top five IntelliJ IDEA features that could save you from harmful mistakes, while also giving you a visual tutorial on how to apply those features.\nProject Loom: Structured Concurrency – Java – Learn how Project Loom’s structured concurrency simplifies handling multiple tasks in Java by organizing them in a clear and predictable way.\nIntroducing the Model Context Java SDK – The MCP Java SDK provides a comprehensive foundation for integrating AI models with external tools and data sources. Find out which key features are included in the SDK. \nProject Loom and Virtual Threads: Next Phases – Alan Bateman discusses how to use virtual threads effectively in Java, addresses common issues like “pinning” with object monitors, and demonstrates how structured concurrency can manage related tasks as a single unit.\nTeaching Java is Getting Simpler – If you’re currently teaching Java, now would be a good time to consider how you can introduce some of the features described in the article to your students.\nKotlin Corner\nOpenAI vs. DeepSeek: Which AI Understands Kotlin Better? – JetBrains Research evaluated several AI models to see which better understands Kotlin. Dive into this article to discover the results! \nKtor 3.1.0 is out – Check out the latest updates: a command-line tool for creating projects, better server-sent events support, WebAssembly compatibility, and initial steps toward gRPC integration. \nKotlin for Server-Side Content Creators – Learn more about an initiative to highlight and promote high-quality content created by developers using Kotlin for server-side development.\nKotlin Multiplatform Scalability Challenges on a Large Project – In this article, Andrei Beriukhov shares his experience addressing scalability challenges when implementing Kotlin Multiplatform in a large project.\nShould you use Kotlin Sequences for Performance? – Chris Banes explains when using Kotlin’s Sequence is helpful and when it might slow things down, showing that it’s not always the best choice for performance.\nWhat are all of those Kotlin function types for? – Kotlin’s got a surprising number of function types, but what are they all used for? In this video, Dave Leeds looks at the range of different function types – from regular function types to KCallable, KFunction, KProperty, the Function interface, and more – and outlines use cases for each one.\nAI\nJetBrains AI Coding Agent Junie Provides Tight Integration with JetBrains IDEs – Learn more about Junie, a new AI coding agent by JetBrains that can perform coding tasks within your project and understand its context within the IDE. \nHow Do LLMs Benefit Developer Productivity? – In this article, Cheuk Ting Ho explains how large language models (LLMs) enhance developer productivity and demonstrates her findings in JetBrains AI Assistant.\nEvolution of Java Ecosystem for Integrating AI – Poonam Parhar describes how the Java ecosystem is evolving to help developers add AI features to their applications, highlighting tools like LangChain4j, Spring AI, and Oracle’s Generative AI service.\nA Generative AI Agent with a real declarative workflow – Guillaume Laforge shows how to make an AI agent that writes stories and creates images using a step-by-step workflow instead of regular coding.\nDoc-Powered AI Assistant – JetBrains AI Assistant can access the IDE’s own documentation. This article provides more details.\nWhy and How JetBrains Built Mellum – the LLM Designed for Code Completion – JetBrains’ AI-powered code completion is driven by its own model, Mellum – learn why it was built in this blog post.\nPrompt Injection for Large Language Models – Georg Dresler explains how attackers can exploit prompt injection vulnerabilities in large language models to steal confidential data and suggests ways to prevent such attacks.\nChecking out Junie, a coding agent by JetBrains – In this article, Igor Kulakov explores his experience using JetBrains’ new AI coding agent, Junie.\nPrompt Engineering: Is it a New Programming Language? – Hien Luu debates if prompt engineering is a programming language in itself, arguing the case for both sides and exploring how this may impact learning and skill acquisition for software developers.\nAI Assistant expands with cutting-edge models – JetBrains AI Assistant now supports LLMs from Anthropic and OpenAI, as well as local models via LM Studio, offering developers more flexibility.\nEpisode 106. Spring AI and Ollama – This is a great episode that explores how to run large language models (LLMs) on personal computers and interact with them using Java. So, if you ever wanted to start experimenting with LLMs, but didn’t know where to begin, this episode is a fantastic place to start!\nHow I Use AI: Meet My Promptly Hired Model Intern – Armin Ronacher shares his thoughts on the current state of AI, its limitations, and how developers can approach using it effectively.\nHow Do LLMs Benefit Developer Productivity? – In this article, Cheuk Ting Ho explains how large language models (LLMs) enhance developer productivity and demonstrates her findings in JetBrains AI Assistant. \nBuilding local LLM AI-Powered Applications with Quarkus, Ollama and Testcontainers – Find out how to create AI-powered apps that run on your computer using Quarkus, Ollama for AI models, and Testcontainers for easy testing.\nLanguages, Frameworks, Libraries, and Technologies\nThis week in Spring 1, 2, 3, 4 – The freshest news from the Spring ecosystem. \nRemote Development made simple with DevPod – Nicolas Fränkel explains how DevPod makes it easy to set up the same development environment for everyone on a team.\nA Bootiful Podcast: ‘Just Use Postgres!’ author Denis Magda – Josh Long talks with Denis Magda about his new book, Just Use Postgres!, which examines how to use Postgres for a variety of use cases that an application developer should know.\nPresentation: Zero Waste, Radical Magic, and Italian Graft – Quarkus Efficiency Secrets \n– Holly Cummins discusses some of the technical underpinnings of Quarkus’s efficiency, providing advice for those using or considering Quarkus.\nFive ways to speed up your Maven builds – In this post, Brian Demers demonstrates low-effort strategies for accelerating your Maven builds. He demonstrates a real-life example that brings a 1.5-minute build down to 7.5 seconds.\nMySQL Performance Tuning with Releem – Vlad Mihalcea introduces Releem, a tool that helps improve MySQL performance by analyzing your database and providing optimization suggestions.\nUsing LangChain4j to analyze PDF documents – Emil Lefkof explains how to use LangChain4j and Google Gemini AI to automatically extract structured metadata from PDF lease documents, streamlining the review process.\nA Bootiful Podcast: HTMX creator Carson Gross – In this podcast, Josh Long hosts a talk with Carson Gross, the creator of HTMX, about simplifying web development by reducing client-side complexity.\nConferences and Events\nCheck out our selection of tech events for March:\nDevnexus 2025 – Atlanta, USA, March 4–6. The IntelliJ IDEA team will be at the JetBrains booth. Come say hello!\nGatherers: The API Your Stream Was Missing – Online, March 13\nDuke Turns 30 Java Celebrations – Online, March 13\nJavaOne – Redwood Shores, USA, March 18–20\nVoxxed Days Zurich – Zurich, Switzerland, March 25\nVoxxed Days Bucharest – Bucharest, Romania, March 26–27\nHarnessing the Power of AI in IntelliJ IDEA – Zurich, Switzerland, March 27\nCulture and Community\nProductivity is Messing Around and Having Fun – Join the QCon London for a talk by Holly Cummins and Trisha Gee in which they will discuss how having fun and taking breaks can boost developer productivity and satisfaction and why it’s important to make time for enjoyment at work.\nThe Efficiency Paradox and How to Save Yourself and the World – Here is another talk by Holly Cummins about how inefficiency harms both the planet and our well-being and offers strategies to reduce software waste and climate impact.\nContext-switching is the main productivity killer for developers – Dr. Milan Milanović discusses how frequent task-switching disrupts developers’ focus, leading to reduced productivity and increased errors.\nFoojay Podcast #67: Writing a book. Does it make you rich and famous? – Frank Delporte discusses the realities of writing a book, sharing personal experiences and insights from guests Trisha Gee, Len Epp, Wim Deblauwe, and Marián Varga.\nMy Twenty-one Year Journey to Write and Publish My First Book – Coincidence or not, Donald Raab shares his 21-year journey of writing and publishing his first book, offering insights into the challenges and triumphs he experienced along the way.\nOrganizational Skills Beat Algorithmic Wizardry – James Hague argues that managing complexity and organizing code are more crucial in programming than mastering complex algorithms. Do you agree?\nAnd Finally…\nTop Java Conferences and Events in 2025 – If you haven’t planned your networking and educational trips for the year, our article can help you with that. \nDatabase Migrations in the Real World – In this article, Siva Katamreddy discusses the challenges of managing database migrations in large-scale applications and offers best practices to ensure smooth and efficient schema changes.\nJava 24: Build Games, Prototypes, Utilities, and More – With Less Boilerplate – Mala Gupta shows how Java 24’s new features help developers create games, prototypes, and utilities with less repetitive code.\nJITWatch4i: Analyzing IntelliJ IDEA’s Startup – JITWatch4i, a plugin for IntelliJ IDEA that helps developers analyze and visualize Java’s Just-In-Time (JIT) compilation processes within the IDE. Learn more in this article.\nThat’s it for today! We’re always collecting ideas for the next Java Annotated Monthly – send us your suggestions via email or X by March 20. Don’t forget to check out our archive of past JAM issues for any articles you might have missed!",
        "dc:creator": "Irina Mariasova",
        "content": "Welcome to this month’s Java Annotated Monthly! As always, we bring you the most interesting tutorials on Java, Kotlin, and other technologies, along with the latest news you don’t want to miss. We’re also excited to introduce a brand-new AI section, which we reserve for the most fascinating content on the topic. And this month, [&#8230;]",
        "contentSnippet": "Welcome to this month’s Java Annotated Monthly! As always, we bring you the most interesting tutorials on Java, Kotlin, and other technologies, along with the latest news you don’t want to miss. We’re also excited to introduce a brand-new AI section, which we reserve for the most fascinating content on the topic. And this month, […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=551543",
        "categories": [
          "news",
          "java-annotated",
          "java-annotated-monthly"
        ],
        "isoDate": "2025-03-06T12:17:04.000Z"
      },
      {
        "creator": "Ivan Kuzmin",
        "title": "Try The New Toolbox App 2.6 EAP With Remote Development Support",
        "link": "https://blog.jetbrains.com/toolbox-app/2025/03/try-the-new-toolbox-app-2-6-eap-with-remote-development-support/",
        "pubDate": "Thu, 06 Mar 2025 10:45:29 +0000",
        "content:encodedSnippet": "With the latest update, the Toolbox App now supports remote development, allowing you to manage your JetBrains tools and projects both locally and on remote servers. This allows you to connect to cross-platform hosts, including Windows, macOS, and Linux, and use integrated OpenSSH for secure and customizable SSH connections. You can download the latest Toolbox EAP from the JetBrains website or update it from the Toolbox EAP channel in the Toolbox App Settings → Appearance and Behavior → Update quality: EAP. \nCross-platform hosts: Connect to Linux, Windows, and macOS\nWith the Toolbox App, remote development with JetBrains IDEs is now possible on Linux, Windows, and MacOS hosts. This allows you to manage your development environments both locally and across all remote hosts using major operating systems.\nRemote JetBrains IDE tools management\nBuilding upon its local tool management capabilities, the Toolbox App has extended its functionality to remote environments. This means you can install, access, update, and monitor your JetBrains IDEs on remote hosts just as easily as you do locally, ensuring a consistent and efficient workflow across all of your development environments.\nSecure and full-featured SSH support \nSSH support in the Toolbox App is backed by OpenSSH, bringing enterprise-level security and flexibility to remote development. Instead of relying on a limited, custom SSH implementation, the Toolbox App uses the standard OpenSSH executable, which integrates smoothly with the SSH configurations you already rely on. Just import them to the Toolbox App and start working.\nThis also means you can leverage the full range of OpenSSH capabilities, including ProxyJump, multi-factor authentication (MFA), reverse proxy setups, custom IdentityFile configurations, and askpass integration. Even advanced enterprise use cases, such as replacing the SSH binary entirely, are fully supported. \nThe Toolbox App uses the same trusted OpenSSH tools you already know, making setting up remote connections easier, more secure, and fully customizable to fit your workflow.\nTry it out \nGetting started with remote development in the Toolbox App is simple. First, download or update to the latest Toolbox App EAP release. Once installed, switch to the SSH context to see your available remote connections.\n\n\n\n\nNext, connect to your remote host by copying the SSH command you usually use in the terminal or by entering your username and host details, such as those from the EC2 console. As a general rule, if the connection works in the terminal, it should work in the Toolbox App as well.\n\n\n\n\nOnce connected, install your preferred JetBrains IDE, and you’re ready to go. For the best experience, we recommend trying the latest 2025.1 EAP versions, which include the latest remote development updates. To get the latest EAP version, select the EAP update channel in the tool settings.\n\n\n\n\nIf you already have your SSH connections set up in your SSH config or JetBrains Gateway, you don’t need to start from scratch. The Toolbox App allows you to import your existing configurations, so you can pick up right where you left off. Just bring in your saved connections, and you’ll be ready to connect and work without any extra setup.\n\n\n\n\nThe Toolbox App doesn’t stop at SSH, either. If you’re using an orchestration solution, whether in-house or commercial, there’s support for that too. With the available Plugin API, the Toolbox App can be extended to fit your specific needs. Several plugins for popular orchestrators are already in development, so stay tuned for updates. If you’re looking to migrate your in-house orchestration solution to Toolbox, feel free to reach out to us for guides and documentation.\nWe’d love for you to try these new features. Your feedback helps us improve, so please let us know your thoughts in the comments or through our issue tracker.\nThe JetBrains Toolbox team",
        "dc:creator": "Ivan Kuzmin",
        "content": "With the latest update, the Toolbox App now supports remote development, allowing you to manage your JetBrains tools and projects both locally and on remote servers. This allows you to connect to cross-platform hosts, including Windows, macOS, and Linux, and use integrated OpenSSH for secure and customizable SSH connections. You can download the latest Toolbox [&#8230;]",
        "contentSnippet": "With the latest update, the Toolbox App now supports remote development, allowing you to manage your JetBrains tools and projects both locally and on remote servers. This allows you to connect to cross-platform hosts, including Windows, macOS, and Linux, and use integrated OpenSSH for secure and customizable SSH connections. You can download the latest Toolbox […]",
        "guid": "https://blog.jetbrains.com/?post_type=toolbox-app&p=551253",
        "categories": [
          "jetbrains-toolbox",
          "toolbox-app"
        ],
        "isoDate": "2025-03-06T10:45:29.000Z"
      },
      {
        "creator": "Maria Kosukhina",
        "title": "IntelliJ IDEA 2025.1 Beta Is Out! ",
        "link": "https://blog.jetbrains.com/idea/2025/03/intellij-idea-2025-1-beta/",
        "pubDate": "Wed, 05 Mar 2025 17:16:21 +0000",
        "content:encodedSnippet": "IntelliJ IDEA 2025.1 Beta is now available! This means we’re in the final stretch before the major release, and you can try out all the new features and improvements right now.\nYou can download this version from our website, update directly from within the IDE, use the free Toolbox App, or install it via snap packages for Ubuntu.\nDownload IntelliJ IDEA 2025.1 Beta\nThere are still several updates and enhancements that haven’t been covered in the 2025.1 EAP blog posts, some of which are highlighted below.\nUser experience \nNative OS file dialogs on Windows \nIntelliJ IDEA now defaults to using native Windows file dialogs instead of the custom implementation. This gives you a more familiar experience when opening or saving files. If you prefer the previous behavior, you can restore it in Advanced Settings | User Interface. \n\n\n\n\nVersion control systems \nCommit details in the diff view\nYou can now see commit details directly in the diff view. The diff dialog now displays the commit message, author, date and time, and full commit hash, giving you a clearer view of a file’s history and helping you understand modifications faster.\n\n\n\n\nOption to run tools for pre-commit checks \nYou can now launch any tool to perform a pre-commit check alongside inspections and formatting. Custom checks can be configured as run configurations in the Run Configuration dialog. This helps you catch potential issues early and ensures your code meets project standards before it’s committed.\n\n\n\n\nAutomatic fetch when adding or modifying a Git remote\nIntelliJ IDEA now automatically fetches changes when you add or update a Git remote, ensuring you always have the latest branch list and commit history without needing to fetch them manually. Newly fetched branches will immediately appear in the Git branch tree. You’ll be able to start working with them right away, and your repository will always be up to date.\n\n\n\n\nOption to disable running Git commit hooks\nA new option allows you to instruct the IDE not to run Git commit hooks. Previously, Git hooks would execute automatically during commit operations, which might not have been desirable in all situations. With this update, you can now configure the IDE to skip these hooks, giving you more control over your commit process.\n\n\n\n\nDiscontinuation of the modal commit interface\nThe modal commit interface has been deactivated in IntelliJ IDEA. A few key reasons are behind this change: \nPerformance and overall experience – The modal commit option introduces lag and performance issues, adding to our technical debt in ways we can’t effectively address.\nRemote development – The current implementation of modal commits limits our ability to focus on a seamless remote development experience, which is becoming essential.\nNon-modal commit – We introduced a non-modal commit interface a few years ago, and it’s now the default for the vast majority of users. We know it’s not perfect, but we’re continually improving it. With the existing customization options, we believe it can be a solid option.\nWhile the non-modal commit workflow will now be the only built-in option, the modal commit experience will still be available through a separate plugin. The plugin won’t be actively maintained long-term, but we’ll review community pull requests to support it if there’s continued interest. If you’re looking to customize your commit workflow to make it similar to the modal commit one, we’ve gathered and documented several useful configuration options available in the IDE.\n\n\n\n\nFrameworks and technologies \nGit-ready Ubuntu image for easier Dev Container setup\nSetting up Dev Containers is now more seamless. When you clone a repository without a Dev Container configuration, the IDE now offers a wizard with an optimized Ubuntu-based container that has Git pre-installed. This update eliminates common issues like Git being missing, reducing setup time so you can focus on coding.\n\n\n\n\nEnhanced user experience with generated HTTP requests \nIntelliJ IDEA now opens HTTP requests generated from code in the right editor split, which means you no longer need to review them in a separate tab that was automatically opened.\n\n\n\n\nThat’s it for now. Stay tuned for more updates coming soon! For a complete list of changes in this build, check out the release notes.\nNow is the perfect time to explore the new features and share your feedback before the final release. Try out the IntelliJ IDEA 2025.1 Beta and let us know your thoughts in the comments or on X. If you run into any issues, please report them in our issue tracker.\nHappy developing!",
        "dc:creator": "Maria Kosukhina",
        "content": "IntelliJ IDEA 2025.1 Beta is now available! This means we’re in the final stretch before the major release, and you can try out all the new features and improvements right now. You can download this version from our website, update directly from within the IDE, use the free Toolbox App, or install it via snap [&#8230;]",
        "contentSnippet": "IntelliJ IDEA 2025.1 Beta is now available! This means we’re in the final stretch before the major release, and you can try out all the new features and improvements right now. You can download this version from our website, update directly from within the IDE, use the free Toolbox App, or install it via snap […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=551057",
        "categories": [
          "eap",
          "2025-1-eap",
          "intellij-idea-2025-1",
          "intellij-idea-2025-1-eap"
        ],
        "isoDate": "2025-03-05T17:16:21.000Z"
      },
      {
        "creator": "Rachel Appel",
        "title": "dotInsights | March 2025",
        "link": "https://blog.jetbrains.com/dotnet/2025/03/05/dotinsights-march-2025/",
        "pubDate": "Wed, 05 Mar 2025 13:45:36 +0000",
        "content:encodedSnippet": "Did you know? The [InternalsVisibleTo] attribute in .NET is a powerful feature that allows an assembly to expose its internal members (normally only accessible within the same assembly) to another specified assembly. This is typically used in scenarios like unit testing or multi-assembly projects where tight integration between assemblies is needed.\n\n\n\n\nWelcome to dotInsights by JetBrains! This newsletter is the home for recent .NET and software development related information.\n🔗 Links\nHere’s the latest from the developer community.\nGetting a Development team Onboard with Technical Coaching – Emily Bache\nSplash Screen in .NET MAUI – Leomaris Reyes\nMassTransit with Azure Service Bus – Error management – Irina Scurtu\n2code ^ !2code [S2025E01] Incremental Source Generators – FlashOWare with Stefan Pölz & Merely Eva\nHow to harmonize Agile sprints with product roadmaps – Amanda Rueda\nDon’t Use WhenAll in .NET! Use WaitAny Instead | Code Cop #027 – Nick Chapsas\n5 Mistakes That Make Your Code Unmaintainable – CodeOpinion by Derek Comartin\nHow to Protect Your API Resources – Gui Ferreira\nHandling MassTransit errors with the Particular Service Platform – Chris Patterson\nTailwind v4 with Blazor – It just got easier – Steven Giesel\nMigrate from MSTest to xUnit using a Roslyn analyzer – Gérald Barré\nNumeric sorting in .NET– Anthony Simmon\nHybrid Caching in ASP.NET Core – Bozo Spoljaric\nBoost Your .NET Projects: Unleashing the Power of Spargine’s InMemoryCache – David McCarter\nC# Dictionary: How to Create One and Best Practices – Stackify Team\nSoftware development is… – Jessica Kerr\nBuild an AI-Powered Smart Appointment Booking App Using WinUI Scheduler – Jeyasri Murugan\nKill the Bloat: The Controversial Clash Between SPAs, Server-Side Rendering, and the Power of Simplicity – Chris Woodruff\nBlazor Basics: Lazy Load Assemblies to Boost the Performance of Blazor WebAssembly – Claudio Bernasconi\nStrongly-Typed Markdown for ASP.NET Core Content Apps – Khalid Abuhakmeh\nEngineering Culture, Trust, and Accountability – Emily Dresner\nWhat are Custom Integrations in .NET Aspire? – Kalle Marjokorpi\nWhy is gRPC so much faster than a JSON-based REST API? – Benjamin Cane\nImplement Phone verification, 2FA using ASP.NET Core Identity – Damien Bowden\nExploring the Forwarded Headers Middleware in ASP.NET Core – Tore Nestenius\n🔦 From our .NET Guide\nEach month we feature tutorials or tips from our .NET Guide.\n\n\n\n            \n.NET Localization\nIn this short series, we’ll explore localization in .NET. For those unfamiliar with the concept, localization is the process of matching an application’s language and visuals to a specific culture. We’ll see just how easy it is to take an existing .NET application and localize it. \nby Khalid Abuhakmeh\n.NET Localization\n                                                    \n☕ Coffee Break\nTake a break to catch some fun social posts.\n\nhttps://youtube.com/shorts/qvlVXamSpQQ?si=hyE01li3ii_4DyOn\n\n\n\n\n🗞️ JetBrains News\nWhat’s going on at JetBrains? Check it out here:\nAnother Set of Bug-Fix Updates for ReSharper and Rider 2024.3 Is Here\nRider 2025.1 EAP 5: Roslyn Syntax Tree Visualizer, Unity Profiler Integration, and More\nWebinar – Uno Platform & Hot Design for Rider\n\n\n\n\n✉️ Comments? Questions? Send us an  email. \nSubscribe to dotInsights",
        "dc:creator": "Rachel Appel",
        "content": "Did you know?&#160;The [InternalsVisibleTo] attribute in .NET is a powerful feature that allows an assembly to expose its internal members (normally only accessible within the same assembly) to another specified assembly. This is typically used in scenarios like unit testing or multi-assembly projects where tight integration between assemblies is needed. Welcome to dotInsights by JetBrains! [&#8230;]",
        "contentSnippet": "Did you know? The [InternalsVisibleTo] attribute in .NET is a powerful feature that allows an assembly to expose its internal members (normally only accessible within the same assembly) to another specified assembly. This is typically used in scenarios like unit testing or multi-assembly projects where tight integration between assemblies is needed. Welcome to dotInsights by JetBrains! […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=550837",
        "categories": [
          "net-tools",
          "dotinsights"
        ],
        "isoDate": "2025-03-05T13:45:36.000Z"
      },
      {
        "creator": "Kerry Beetge",
        "title": "On the Horizon: Top Three Updates Coming Soon From Qodana",
        "link": "https://blog.jetbrains.com/qodana/2025/03/qodana-roadmap-2025-q1/",
        "pubDate": "Tue, 04 Mar 2025 14:05:56 +0000",
        "content:encodedSnippet": "As we head deeper into Q1 of 2025, some exciting new developments are underway. From expanding Qodana’s integrations with new IDEs to consolidating organizational data, many more promising new projects are in the works to help increase code quality in your team. Let’s take a look at the top three!\nAn organization-wide dashboard\nInsights into all your development projects\nWe’ll introduce a new insights dashboard to Qodana, offering a high-level overview of your organization’s code quality. It’s perfect for team leads and project managers to track trends and spot vulnerabilities and will help you get a sense of your organization’s overall code health. \n✓ View behavioral trends and usage patterns.\n✓ Identify projects that need extra work.\n✓ Spot critical issues and vulnerabilities.\nThis new multiproject dashboard will enable your team to filter by the total number of problems, critical problems, and code coverage level. It will also give you an indication of where Qodana is not set up for checks or has been inactive over time. You’ll also be able to check the state of third-party licenses and much more. \nBook Dashboard Demo\nLightweight, self-hosted solution\nData control, compliance, and autonomy\nWe’re about to release Qodana Self-Hosted Lite, which offers teams like yours a secure, lightweight solution for implementing static code analysis and other code quality and security checks. This works well for most software development teams, especially in regulated industries, that want control over their data while they work toward technical excellence. \n✓ Maintain control of your organization’s data.\n✓ Scale up codebase checks easily. \n✓ Configure Qodana to catch issues you deem most important.\nKeep an eye on our social media for details, or reach out to Kai Schmithusen if you’re interested in a demo. \nGet Demo\nNew Visual Studio software quality plugin\nJetBrains code quality for everyone on the team\nYou will soon be able to download the Qodana Code Quality Plugin for Visual Studio via your ReSharper installer to bring Qodana Cloud or self-hosted Qodana projects into Visual Studio. Identify code issues, detect bugs and vulnerabilities, run the analyses directly in your pipeline, and then view issues in the IDE where you work for better contextual updates and learning. You also have the option to download the solution as a standalone plugin. \nWant to have a say in what Qodana focuses on?\nWe’re building Qodana with a user-first approach, and while we’ve already got a lot in the pipeline, we want to give you the opportunity to have your say! Vote on issues in Qodana’s YouTrack, and you could impact what goes into development as we go. You can also reach out to our team with specific requests. \nWhat to do next\nSubscribe to Qodana news and Qodana roadmap updates (on the right).\nJoin our communities on X, LinkedIn, GitHub, and Reddit. \nFind out more about Qodana’s top features. \nGet Qodana",
        "dc:creator": "Kerry Beetge",
        "content": "As we head deeper into Q1 of 2025, some exciting new developments are underway. From expanding Qodana’s integrations with new IDEs to consolidating organizational data, many more promising new projects are in the works to help increase code quality in your team. Let’s take a look at the top three! An organization-wide dashboard Insights into [&#8230;]",
        "contentSnippet": "As we head deeper into Q1 of 2025, some exciting new developments are underway. From expanding Qodana’s integrations with new IDEs to consolidating organizational data, many more promising new projects are in the works to help increase code quality in your team. Let’s take a look at the top three! An organization-wide dashboard Insights into […]",
        "guid": "https://blog.jetbrains.com/?post_type=qodana&p=550980",
        "categories": [
          "qodana",
          "code-quality-dashboard",
          "roadmap",
          "roadmap2025",
          "visual-studio-plugin"
        ],
        "isoDate": "2025-03-04T14:05:56.000Z"
      },
      {
        "creator": "Vaclav Pech",
        "title": "MPS 2024.1.2 Is Now Available",
        "link": "https://blog.jetbrains.com/mps/2025/03/mps-2024-1-2-is-out/",
        "pubDate": "Tue, 04 Mar 2025 07:38:22 +0000",
        "content:encodedSnippet": "We’ve just released an update to MPS 2024.1, which corrects several problems, mainly in the UI, indexing, and migrations.\nDOWNLOAD MPS 2024.1.2\nSee the full list of fixed issues here.\nhere.\nYour JetBrains MPS team",
        "dc:creator": "Vaclav Pech",
        "content": "We’ve just released an update to MPS 2024.1, which corrects several problems, mainly in the UI, indexing, and migrations. DOWNLOAD MPS 2024.1.2 See the full list of fixed issues here. Download this latest version here. Your JetBrains MPS team",
        "contentSnippet": "We’ve just released an update to MPS 2024.1, which corrects several problems, mainly in the UI, indexing, and migrations. DOWNLOAD MPS 2024.1.2 See the full list of fixed issues here. Download this latest version here. Your JetBrains MPS team",
        "guid": "https://blog.jetbrains.com/?post_type=mps&p=550470",
        "categories": [
          "releases",
          "release"
        ],
        "isoDate": "2025-03-04T07:38:22.000Z"
      },
      {
        "creator": "Anna Rovinskaia",
        "title": "New Livestream – Gatherers: The API Your Stream Was Missing",
        "link": "https://blog.jetbrains.com/idea/2025/03/new-livestream-gatherers-the-api-your-stream-was-missing/",
        "pubDate": "Mon, 03 Mar 2025 08:55:48 +0000",
        "content:encodedSnippet": "Join us for a new IntelliJ IDEA Livestream episode with José Paumard, where we’ll explore the Stream Gatherer API in JDK 24 and how to use it effectively in your applications. \nDate: March 13, 2025\nTime: 3:00–4:00 pm UTC\nREGISTER FOR THE LIVESTREAM\n\n\n\n\nSession abstract\nJDK 24 is bringing a new enhancement to the Stream API, called the Stream Gatherer API. Stream Gatherers are a great addition to the Stream API, bringing new possibilities and helping to solve complex problems. This presentation shows you how Gatherers work on live examples, how you can create them, and what use cases they are most suitable for. Understanding Gatherers requires a good understanding of the Stream API. At the end of this presentation, you will be able to create your own Gatherers and understand when you should use them in your application.\n\n\n\n\nAsking questions\nJosé will try to answer all of your questions during the session. If we run out of time, we’ll publish answers to any remaining questions in a follow-up blog post.\nYour speaker and host\nSpeaker\nJosé Paumard\nJosé works as Java Developer Advocate at Oracle and is a Java Champion alumni member and JavaOne Rockstar. He has a PhD in applied mathematics and computer science and was an assistant professor at the University Sorbonne Paris Nord for 25 years. A member of the Paris Java User Group, he has been a co-organizer of the Devoxx France conference and is a disorganizer of JChateau – an unconference held in the Châteaux of the Loire Valley. Paumard works on the dev.java documentation website, hosts the monthly YouTube video podcast JEP Café, and is a Pluralsight author in the Java space.\nHost\nMala Gupta\n\nA Java Champion and JUG leader, Mala has authored multiple books with Manning, Packt, and O’Reilly Publications. She has more than two decades of experience in the software industry and is a regular speaker at industry conferences around the world. She is a vocal supporter of Java certification as a path to career advancement.\n\nHappy developing!",
        "dc:creator": "Anna Rovinskaia",
        "content": "Join us for a new IntelliJ IDEA Livestream episode with José Paumard, where we’ll explore the Stream Gatherer API in JDK 24 and how to use it effectively in your applications. Date: March 13, 2025 Time: 3:00–4:00 pm UTC REGISTER FOR THE LIVESTREAM Session abstract JDK 24 is bringing a new enhancement to the Stream [&#8230;]",
        "contentSnippet": "Join us for a new IntelliJ IDEA Livestream episode with José Paumard, where we’ll explore the Stream Gatherer API in JDK 24 and how to use it effectively in your applications. Date: March 13, 2025 Time: 3:00–4:00 pm UTC REGISTER FOR THE LIVESTREAM Session abstract JDK 24 is bringing a new enhancement to the Stream […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=548958",
        "categories": [
          "livestreams",
          "intellij-idea",
          "intellijidealivestream",
          "livestream",
          "webinars"
        ],
        "isoDate": "2025-03-03T08:55:48.000Z"
      },
      {
        "creator": "Alena Gupaisova",
        "title": "Admission for the Computer Science and AI BSc Is Open",
        "link": "https://blog.jetbrains.com/education/2025/03/03/admission-for-the-computer-science-and-ai-bsc-is-open/",
        "pubDate": "Mon, 03 Mar 2025 08:17:10 +0000",
        "content:encodedSnippet": "Admission to the Computer Science and Artificial Intelligence bachelor’s program at Neapolis University Pafos is open! \n\n\n\n\nThe JetBrains Foundation supports this bachelor’s program and offers 15 fully funded scholarships for the most talented applicants. The scholarships cover tuition, accommodation, medical insurance, visa fees, and spending money (€300 per month).\nMany students who graduate from bachelor’s and master’s programs developed in collaboration with the JetBrains Foundation work at top IT companies like Meta, Google, and JetBrains, so don’t miss your chance to join the team!\nFind out more about the program here. \n2025 key admission dates\nFirst admission round:\nApplication deadline – April 23\nEntrance test – April 27\n\n\n\n\nSecond admission round:\nApplication deadline – June 11\nEntrance test – June 15\nUpcoming events\nJoin our next livestream with the program team on March 11, 2025. In it, our experts will share details about the curriculum and admission process. \nRegister for Livestream\n                                                    \n\n\n\n\nIf you’re in Cyprus, attend our Open Day on March 15 to meet the program’s professors, speak with current students, and tour the campus. \nMarch 15, 12:00 – 03:00 pm\nWhere: Neapolis University Pafos, 2 Danais Avenue, Paphos 8042\nLearn more about the Open Day here.\nRegister for Open Day\n                                                    \nContact us\nDo you have any questions? Drop us a line via Telegram chat or nup@jetbrains.com.\nDon’t miss this opportunity to launch your career in one of today’s most dynamic and in-demand fields. Apply now and take the first step toward your future in Computer Science and AI!",
        "dc:creator": "Alena Gupaisova",
        "content": "Admission to the Computer Science and Artificial Intelligence bachelor&#8217;s program at Neapolis University Pafos is open!&#160; The JetBrains Foundation supports this bachelor&#8217;s program and offers 15 fully funded scholarships for the most talented applicants. The scholarships cover tuition, accommodation, medical insurance, visa fees, and spending money (€300 per month). Many students who graduate from bachelor’s [&#8230;]",
        "contentSnippet": "Admission to the Computer Science and Artificial Intelligence bachelor’s program at Neapolis University Pafos is open!  The JetBrains Foundation supports this bachelor’s program and offers 15 fully funded scholarships for the most talented applicants. The scholarships cover tuition, accommodation, medical insurance, visa fees, and spending money (€300 per month). Many students who graduate from bachelor’s […]",
        "guid": "https://blog.jetbrains.com/?post_type=education&p=550218",
        "categories": [
          "offline-programs",
          "csai"
        ],
        "isoDate": "2025-03-03T08:17:10.000Z"
      }
    ]
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Harshada Hole",
        "title": "New Debugging and Profiling Features in Visual Studio (v17.13)",
        "link": "https://devblogs.microsoft.com/visualstudio/new-debugging-and-profiling-features-in-visual-studio-v17-13/",
        "pubDate": "Wed, 05 Mar 2025 15:39:27 +0000",
        "content:encodedSnippet": "The latest Visual Studio update (v17.13) brings a strong set of debugging and profiling features designed to speed up troubleshooting, making it more efficient. With AI-driven features in this release, variable analysis and data inspection are smarter and more intuitive, and problems are easier to identify and debug. Profiling tool improvements also deliver better support and visualization for multi-process execution, native code, and async workflows, with clearer insights into performance bottlenecks. For a full list of debugger and diagnostics features in this release, check out the release notes.\nDownload Visual Studio 2022 v17.13\n\nGitHub Copilot Assited Debugging Features\nSmarter exception and variable analysis\nGitHub Copilot Exception Analysis and Variable Analysis now use your project context intelligently to find and bring to your attention the most relevant code to errors.\nWith sharper, actionable insights and smarter, context-aware solutions, these capabilities can guide you to the root cause of issues more quickly, make your debugging workflow more streamlined, and provide greater overall accuracy in debugging errors.\n\nAI-Powered Parallel Stacks window\nAuto-Summarize in Parallel Stacks gives you AI-generated summaries so you can get a quick idea of what each thread is doing. Copilot Chat Integration with App Summarization goes a step further, identifying probable problems, recommending solutions, and enabling you to ask questions, get them explained, and get AI-powered suggestions—all in the context of your debugging session.\nCombined, these tools simplify parallel debugging so you can diagnose and repair threading problems more quickly and confidently.\n\nEnhanced Editable Expressions in IEnumerable Visualizer\nThe IEnumerable Visualizer now features GitHub Copilot Inline Chat, allowing you to refine editable expressions using natural language. Open a prompt with the Copilot sparkle button, tell it what you would like to change, and receive AI-generated LINQ queries for customized filtering your data. Including syntax highlighting to make it easier to read.\n\nProfiling Features\nTargeted Instrumentation for native code\nThe Instrumentation tool in the Visual Studio now has targeted instrumentation for native code, allowing you to choose functions and classes to inspect thoroughly.\nThis improves performance monitoring and makes it easier for you to spot issues, streamlining your debugging experience.\n\nDisplay unified async stacks in profiler\nThe Visual Studio profiler now improves debugging of .NET applications by showing stitched async stacks in the summary and detail call tree windows.\nThis feature gives a more cohesive, clearer picture of asynchronous operations, making it easier for developers to follow the entire execution path, including asynchronous method calls, in a single, unified stack trace.\n\nMultiprocess Analysis with Color-Coded Swimlanes in CPU Usage\nCPU Usage tool in the Visual Studio profiler now supports multiprocess analysis, with performance graphs displayed as separate color coding for each process in swim lanes.\nThe graphs are displayed as stacked area charts. You can also filter processes by a dropdown at the top left, to enable focused analysis.\nThis enhancement enables you to profile and isolate CPU usage by process with ease in one session. Providing better visualization of resource usage, it optimizes profiling performance and simplifies multiprocess application performance tuning.\n\nThank you!\nWe aim to make your debugging and profiling experience as smooth and productive as it can be. We really appreciate the feedback and suggestions you provide, as that is what determines the direction of the tools you use daily. Never stop providing us with feedback, as we can keep making Visual Studio an excellent and user-friendly tool for developers like you.\nHappy coding!\nThe post New Debugging and Profiling Features in Visual Studio (v17.13) appeared first on Visual Studio Blog.",
        "dc:creator": "Harshada Hole",
        "content": "<p>The latest Visual Studio update (v17.13) brings a strong set of debugging and profiling features designed to speed up troubleshooting, making it more efficient. With AI-driven features in this release, variable analysis and data inspection are smarter and more intuitive, and problems are easier to identify and debug. Profiling tool improvements also deliver better support [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/new-debugging-and-profiling-features-in-visual-studio-v17-13/\">New Debugging and Profiling Features in Visual Studio (v17.13)</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "The latest Visual Studio update (v17.13) brings a strong set of debugging and profiling features designed to speed up troubleshooting, making it more efficient. With AI-driven features in this release, variable analysis and data inspection are smarter and more intuitive, and problems are easier to identify and debug. Profiling tool improvements also deliver better support […]\nThe post New Debugging and Profiling Features in Visual Studio (v17.13) appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=252584",
        "categories": [
          "Copilot",
          "Debug",
          "GitHub Copilot",
          "Visual Studio",
          "Debugging and Diagnostics",
          "Profiling"
        ],
        "isoDate": "2025-03-05T15:39:27.000Z"
      },
      {
        "creator": "Mads Kristensen",
        "title": "Great new productivity features in Visual Studio",
        "link": "https://devblogs.microsoft.com/visualstudio/great-new-productivity-features-in-visual-studio/",
        "pubDate": "Mon, 03 Mar 2025 16:28:28 +0000",
        "content:encodedSnippet": "Sometimes it’s the little things in life that matter the most. In the latest version of Visual Studio, we’ve added some features and tweaks that aim to put a smile on your face and make you more productive. Here is a list of some of these, and if you want the full list, make sure to check out the release notes.\nCustomize file encoding\nDevelopers working in cross-platform environments often need files to be saved with specific file encodings. Changing these encodings can lead to various issues.\nVisual Studio now allows you to set the default file encoding for saving files. This feature ensures that your preferred encoding is used whenever possible.\nTo set the default encoding, navigate to Tools → Options → Environment → Documents. There, you will find an option titled Save files with a specific encoding. If this option is unchecked, Visual Studio will manage file encoding using its default behavior. If checked, Visual Studio will use the encoding specified in the adjacent combo box whenever a file is saved.\n\nIf Visual Studio cannot save with the specified encoding (e.g., requesting ASCII encoding for a file containing Unicode characters), it will display a dialog informing you of the issue.\nChoose whether to indent word wrap\nWe are excited to introduce a new feature that allows you to control whether wrapped lines are indented in the editor. This enhancement provides greater flexibility and customization for your coding environment, ensuring that your code appears exactly as you prefer.\n\nTo change this option, follow these steps:\nGo to Tools → Options → Text Editor → General.\nLook for the option called Automatically indent when word wrap is enabled.\nBy default, this option is enabled, meaning that wrapped lines will be indented. If you prefer your wrapped lines not to be indented, simply uncheck this option. This setting can help improve readability and maintain the desired formatting of your code, especially in projects where indentation style is crucial.\nPreserve font preferences across themes\nWe understand that the fonts developers select when coding is a personal choice, influenced by preferences for readability, accessibility, or aesthetics. Visual Studio themes primarily focus on presentation colors and are independent of your preferred fonts.\nWith this update, we’ve introduced functionality to retain your font face and size choices when switching themes. You can now set your font preferences once and switch themes in Visual Studio without needing to reconfigure your font settings every time. Note that the colors of your fonts remain linked to the theme, as that is the purpose of themes, but your font selections will be preserved.\n\nThis feature will be enabled by default for all users. If you prefer the previous behavior, go to Tools > Manage Preview Features and find the option Separate font settings from color theme selection. If this option is checked, your font preferences will be maintained regardless of theme changes. Uncheck the box to reinstate the previous behavior which ties font choices to theme.\nReimagine the horizontal scrollbar\nThe editor tray in Visual Studio is a valuable space for a wealth of information. You can control your zoom, check the health of your document, see what line you’re on, and access a variety of additional information.\nUnfortunately, sometimes all of that information can crowd out the horizontal scrollbar, making it difficult to scroll through your window. This is particularly true in a side-by-side view where the system tray isn’t very wide.\nWith this latest update, these struggles are a thing of the past. If the scrollbar drops below a usable width, it will reposition itself above the system tray to ensure it’s always accessible. By default, it will return to the editor tray as soon as there’s enough room for it again.\n\nWhile we believe this behavior will be ideal for most users, if you encounter any issues, you can control the behavior in Tools → Options. The option is located under Text Editor → Advanced and is labeled Editor horizontal scrollbar location. This setting allows you to choose whether the scrollbar adjusts its position according to the available space, stays in the editor tray, or always appears above the editor tray.\n\nThank you!\nWe are dedicated to continuously improving your development experience, and many of these advancements are driven by your invaluable feedback and suggestions. Your input plays a vital role in shaping the future of Visual Studio, and we encourage you to keep sharing your ideas with us.\nHappy coding!\nThe post Great new productivity features in Visual Studio appeared first on Visual Studio Blog.",
        "dc:creator": "Mads Kristensen",
        "content": "<p>Sometimes it’s the little things in life that matter the most. In the latest version of Visual Studio, we’ve added some features and tweaks that aim to put a smile on your face and make you more productive. Here is a list of some of these, and if you want the full list, make sure [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/great-new-productivity-features-in-visual-studio/\">Great new productivity features in Visual Studio</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Sometimes it’s the little things in life that matter the most. In the latest version of Visual Studio, we’ve added some features and tweaks that aim to put a smile on your face and make you more productive. Here is a list of some of these, and if you want the full list, make sure […]\nThe post Great new productivity features in Visual Studio appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=252558",
        "categories": [
          "Accessibility",
          "Productivity",
          "Visual Studio",
          "Developer Productivity"
        ],
        "isoDate": "2025-03-03T16:28:28.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": [
      {
        "creator": "권창현",
        "title": "2015년 여름",
        "link": "https://thoughts.chkwon.net/2015-summer/",
        "pubDate": "Mon, 03 Mar 2025 23:28:10 +0000",
        "content:encodedSnippet": "이 여름에는 많은 일이 일어났다. 버팔로에서 탬파로 이사가고 이직하던 시기이다. 베를린에서 열렸던 TSL Workshop에서는 장영재 교수님을 처음으로 만나 카이스트 산업및시스템공학과와 연결고리가 생기기도 했다.\n버팔로에서 많은 추억을 함께 쌓은 김진수 선생님의 초청으로 인천국제고와 인천과학고에서 세미나도 했다. 산업공학을 소개하고 고등학생들에게 도움될만한 여러가지 이야기를 하러 다녀왔다. 학생들 똘망똘망 질문도 잘하고 진로에 대한 고민을 털어놓기도 하더라.\n인천과학고 학생 하나가 있었다. 이 학생은 2학년이었는데 대학에서 어떤 전공을 할지 고민이 많았더랬다. 현재 고등학교에서 하는 활동은 기계공학에 모두 초점이 맞춰져있었고 가족들도 선생님들도 기계공학을 권하고 있었는데, 정작 본인은 산업공학에 끌리고 있었더랬다. 때마침 찾아온 세미나 연사가 기계공학을 학부에서 공부하고 대학원에서는 산업공학을 공부했단다. 질문을 했다. 나도 그렇게 전공 바꿔서 공부하려고 하는데 괜찮을까요? 학부에서는 기계공학을 대학원에서는 산업공학을.\n2023년에 카이스트 부임해서 가르쳤던 대학원 과목에서 눈에 띄는 학생 하나가 있었다. 수업시간에 질문도 열심히 하고 내 질문에 대답도 열심히 하던 성실하고 똑똑한 학생 하나가 있었다. 석사과정에 입학해서 열심히 연구하고 있다고 했다. 나는 같이 연구할 좋은 학생들을 찾고 있던터라 지도교수님이 이미 있어서 아쉬운 마음이 들기도 했다.\n일년이 지나서 2024년 가을에 연락이 왔다. 지도교수님께서 다른 학교로 이직하게 되면서 새로 지도교수를 찾고 있다고 했다. 인터뷰에서 여러가지 이야기 해 본 다음 박사과정에 진학하게 되는 시점 부터 내가 지도 하기로 했다. 이번 학기가 그 첫 학기다.\n최근에 이 학생이랑 여러가지 이야기 나누다가 이 학생이 그 인천과학고 학생이라는 사실을 알게 되었다. 서로 기억이 희미했지만 그 당시 인천과학고에서 산업공학으로 진학한 학생은 자기 동기들 중에선 본인 밖에 없을 정도로 매우 드물었으며, 그 해 여름에 기계공학에서 산업공학으로 전공을 바꾼 연사가 나 말고 또 누가 왔을 것이며, 나도 비슷한 질문에 대답을 했던 것이 기억이 나는 걸로 보아 이 학생이 질문을 던졌던 세미나 연사가 나였을 확률이 매우 높은 것으로 결론을 지었다.\n그 때 그 질문에 돌아온 대답은 어차피 돌아올거면 지금 왜 당장 하지 않느냐, 그냥 지금 하고 싶은거 해도 된다였단다. 이 대답이 너무 간결해서 마음이 편안해졌고 같은식으로 가족도 설득할 수 있었단다. 그래서 대학에서 원하는 전공 공부하면서 즐겁게 보낼 수 있었단다. 내가 그 이야기해줘서 고마웠다고 했다.\n아마 이 학생은 그 때 이미 마음을 먹은 상태였고 누가 등 떠밀어주기를 바라고 있었던 것 같다. 그게 마침 나였고.\n인연이라는게 참 신기하다. 이렇게 다시 만나는구나. 세상 좁다 또 한 번 느낀다. 고등학생들 만나서 이야기 하고 내 생각 전하던 활동이 이렇게 내게 다시 돌아와, 산업공학 박사과정 학생과 지도교수로 만났다.\n결자해지의 시간인가.",
        "dc:creator": "권창현",
        "comments": "https://thoughts.chkwon.net/2015-summer/#respond",
        "content": "이 여름에는 많은 일이 일어났다. 버팔로에서 탬파로 이사가고 이직하던 시기이다. 베를린에서 열렸던 TSL Workshop에서는 장영재 교수님을 처음으로 만나 카이스트 산업및시스템공학과와 연결고리가 생기기도 했다. 버팔로에서 많은 추억을 함께 쌓은 김진수 선생님의 초청으로 인천국제고와 인천과학고에서 세미나도&#46;&#46;&#46;",
        "contentSnippet": "이 여름에는 많은 일이 일어났다. 버팔로에서 탬파로 이사가고 이직하던 시기이다. 베를린에서 열렸던 TSL Workshop에서는 장영재 교수님을 처음으로 만나 카이스트 산업및시스템공학과와 연결고리가 생기기도 했다. 버팔로에서 많은 추억을 함께 쌓은 김진수 선생님의 초청으로 인천국제고와 인천과학고에서 세미나도...",
        "guid": "https://thoughts.chkwon.net/?p=997",
        "categories": [
          "잡생각"
        ],
        "isoDate": "2025-03-03T23:28:10.000Z"
      }
    ]
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김상훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "엘라스틱의 합집합 집계",
        "link": "https://kangmyounghun.blogspot.com/2025/03/blog-post.html",
        "pubDate": "2025-03-06T09:34:00.000Z",
        "author": "강명훈",
        "content": "<div>특정 프로세스 발생 통계.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjznljyTEsXEOHKc0kEbiprFURpPJUVuUONg9NeaQWIWlhJkMIYER2C-eHTYzFVJE1op_sO11uQVLdajP3KS_xARLjm9-GiR65xfiOR2PSGP0HX7r0t4ckCGDTUZk1J_FflXoJ88IXhazDURnXHXovO-fnIUqejg5RXVneLe0TskyNEBZhVQUyuhAcGLhKP/s1280/stat_union.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"669\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjznljyTEsXEOHKc0kEbiprFURpPJUVuUONg9NeaQWIWlhJkMIYER2C-eHTYzFVJE1op_sO11uQVLdajP3KS_xARLjm9-GiR65xfiOR2PSGP0HX7r0t4ckCGDTUZk1J_FflXoJ88IXhazDURnXHXovO-fnIUqejg5RXVneLe0TskyNEBZhVQUyuhAcGLhKP/s16000/stat_union.png\" /></a></div><div><br /></div><div><span><a name='more'></a></span>집계 분할 기준에 제작사 정보를 추가하면 집계 실패. 제작사 정보가 없으니까.</div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjUtd_QbHF6M2DouVpRXcF6Ne80yYiU24AJ_vHzFGPiCi2ZTL3FxwIwQc6kCk9EQHSyIKvEk5KYccZl5_4uA5nG2RtY5EXiGPZPdK0OWvqwjD7qigwF6aqPjQwIthlPctDI_drrQiT2ApsnKf2omikUdtzFDYWjHqkSOLcc0CsD470Zmc7rTdYCV1EJlW3Z/s1210/stat_union2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1210\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjUtd_QbHF6M2DouVpRXcF6Ne80yYiU24AJ_vHzFGPiCi2ZTL3FxwIwQc6kCk9EQHSyIKvEk5KYccZl5_4uA5nG2RtY5EXiGPZPdK0OWvqwjD7qigwF6aqPjQwIthlPctDI_drrQiT2ApsnKf2omikUdtzFDYWjHqkSOLcc0CsD470Zmc7rTdYCV1EJlW3Z/s16000/stat_union2.png\" /></a></div><div><br /></div><div>이때 null값 추가 옵션을 사용하면 합집합 집계 가능.</div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiF_4rNL9p4sOHHu0Mvu9NIQUT1qMnL73tZmtYj2cLsOq8Xn3GXM7GHY1p6FttQrcFLZVvRTSiO6MNt4HKrZCwCGMIMN9hFVfUdeZoa60ch7qjfY4F1guzhliDIP3VqeyDijckhWF16_bQB1Y9bbFXaoFLAz6KiPESoVw4R7Q_ZAOYMw89Km3JDPtpRNLcz/s1356/stat_union3.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"1125\" data-original-width=\"1356\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiF_4rNL9p4sOHHu0Mvu9NIQUT1qMnL73tZmtYj2cLsOq8Xn3GXM7GHY1p6FttQrcFLZVvRTSiO6MNt4HKrZCwCGMIMN9hFVfUdeZoa60ch7qjfY4F1guzhliDIP3VqeyDijckhWF16_bQB1Y9bbFXaoFLAz6KiPESoVw4R7Q_ZAOYMw89Km3JDPtpRNLcz/s16000/stat_union3.png\" /></a></div><br /><div>엘라스틱이 열심히 밀어주는 Lens에서는 이렇게.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiN6yJityh7lZpwTHrATkprZefMlagjzcx8tm1XdFjHnm1CVteJxJFDWyDsQENak7WNk4N8cm96xlZ6ZIExFtFc3JVRD_brEuhkdPMq0W_pyDDPvYS_PSDufZmGdpUh6KlQyKJA6cEbOdcxu3Ra9Okrf0dOVWmj3eEmzEafCtIstNQOIgj7x7lPtPEM23WO/s1508/stat_union4.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"1125\" data-original-width=\"1508\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiN6yJityh7lZpwTHrATkprZefMlagjzcx8tm1XdFjHnm1CVteJxJFDWyDsQENak7WNk4N8cm96xlZ6ZIExFtFc3JVRD_brEuhkdPMq0W_pyDDPvYS_PSDufZmGdpUh6KlQyKJA6cEbOdcxu3Ra9Okrf0dOVWmj3eEmzEafCtIstNQOIgj7x7lPtPEM23WO/s16000/stat_union4.png\" /></a></div><br /><div><b>관련 글</b></div><div><ul><li><a href=\"https://kangmyounghun.blogspot.com/2020/09/blog-post.html\" target=\"\">데이터 시인성</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2023/09/splunk-fillnull.html\">Splunk의 fillnull</a></li></ul></div>",
        "contentSnippet": "특정 프로세스 발생 통계.\n\n\n\n\n\n집계 분할 기준에 제작사 정보를 추가하면 집계 실패. 제작사 정보가 없으니까.\n\n\n\n\n이때 null값 추가 옵션을 사용하면 합집합 집계 가능.\n\n\n\n엘라스틱이 열심히 밀어주는 Lens에서는 이렇게.\n\n\n\n\n관련 글\n\n데이터 시인성\nSplunk의 fillnull",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-2919730457054908590",
        "isoDate": "2025-03-06T09:34:00.000Z"
      },
      {
        "title": "엘라스틱 Runtime field - 10th",
        "link": "https://kangmyounghun.blogspot.com/2025/03/runtime-field-10th.html",
        "pubDate": "2025-03-03T12:27:00.002Z",
        "author": "강명훈",
        "content": "<div>beat 기본 인덱스 템플릿을 사용하면 1,500여 개 필드로 구성된 인덱스가 생성된다.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiy8CR8Pm_CZ6JGMq7P4g0MdNlb0HAtChFNtwZ9oLnSgmnjaX4n6VWHcEg6I0pzaAYSVUxxYCqzavH6CM5VkD2MpUx8TYQfdKzAvFmUGh2HR8M_F6rb6WtbdZ8C8Ic2XQDYzUxXozjevvfjwDHqKIau1COQa8u-3G9LXyU_idQ5yxCNvsy8oe9D4uybD8ml/s1280/winlogbeat_basic_template.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"664\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiy8CR8Pm_CZ6JGMq7P4g0MdNlb0HAtChFNtwZ9oLnSgmnjaX4n6VWHcEg6I0pzaAYSVUxxYCqzavH6CM5VkD2MpUx8TYQfdKzAvFmUGh2HR8M_F6rb6WtbdZ8C8Ic2XQDYzUxXozjevvfjwDHqKIau1COQa8u-3G9LXyU_idQ5yxCNvsy8oe9D4uybD8ml/s16000/winlogbeat_basic_template.png\" /></a></div><br /><div><span><a name='more'></a></span>이게 싫으면 별도 템플릿을 사용하면 됨.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhGsQoYvN8bwVnNZSyqWiLsF-gm6Ds2PXwpqrMpMWxYIOWO5OOA-B7Tw0XtaHSatmF-C_pjZeCxTs8kYgfwLO443pkirlW7wwmXVlAgWmf8LefVRWWWkq9NRyrUuJjxnjuC1alNLtggp8KLQGnTrOuxkQf6n-1ykK0w8FZu9dCNrknkYkXm6cj1fxAZypsf/s1280/winlogbeat_custom_template.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"617\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhGsQoYvN8bwVnNZSyqWiLsF-gm6Ds2PXwpqrMpMWxYIOWO5OOA-B7Tw0XtaHSatmF-C_pjZeCxTs8kYgfwLO443pkirlW7wwmXVlAgWmf8LefVRWWWkq9NRyrUuJjxnjuC1alNLtggp8KLQGnTrOuxkQf6n-1ykK0w8FZu9dCNrknkYkXm6cj1fxAZypsf/s16000/winlogbeat_custom_template.png\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjiLRXLnXOGhxQR_QYwc03ue9WFeh1bALR7vI0-F4MF9Q4W5xeIP_99_7sxmY2Y93QUFWgJOamTdLKk2pcpXXpRPJJVmG_eVNA465j5YZ6WhBFyDGuyAig0mPCyaav-1p-VavUslyYaRPzOLL_iXt7BCweV94_T4Sy3Vp7JklYC13y3_NypSYLmOAqFrH-j/s1280/winlogbeat_custom_template2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"621\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjiLRXLnXOGhxQR_QYwc03ue9WFeh1bALR7vI0-F4MF9Q4W5xeIP_99_7sxmY2Y93QUFWgJOamTdLKk2pcpXXpRPJJVmG_eVNA465j5YZ6WhBFyDGuyAig0mPCyaav-1p-VavUslyYaRPzOLL_iXt7BCweV94_T4Sy3Vp7JklYC13y3_NypSYLmOAqFrH-j/s16000/winlogbeat_custom_template2.png\" /></a></div><br /><div>그런데 갑자기 geo_point 타입 필드가 필요하면?</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg8NileS2sFLvkS_TX8-CkA8QkgQ8CSZiAlT0OyTB5dGKK0Hb28YSL7VPCK0AK2JLXlhM5wQaTFybWsWLuhJJTxywSkVajuklLf5-QXWMD9MKzLQdw5paBQiJMpdIJQumhfkm_vFLZ2R03TQOufgY7hOjHpVzVWczG_Ed_w6ctcSiyQE9VOb5aYMLy2Ty7T/s1280/win_event_22.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"609\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg8NileS2sFLvkS_TX8-CkA8QkgQ8CSZiAlT0OyTB5dGKK0Hb28YSL7VPCK0AK2JLXlhM5wQaTFybWsWLuhJJTxywSkVajuklLf5-QXWMD9MKzLQdw5paBQiJMpdIJQumhfkm_vFLZ2R03TQOufgY7hOjHpVzVWczG_Ed_w6ctcSiyQE9VOb5aYMLy2Ty7T/s16000/win_event_22.png\" /></a></div><br /><div>미리 계획된 템플릿을 준비하지 못했더라도 rest api로 간단히 원하는 필드 추가 가능.</div>\n<div><pre><code><div>PUT winevent-2025/_mapping</div><div>{</div><div>&nbsp; &nbsp; \"properties\": {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; \"geoip\": {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"properties\": {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"location\": {</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \"type\": \"geo_point\"</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }</div><div>&nbsp; &nbsp; &nbsp; &nbsp; }</div><div>&nbsp; &nbsp; }</div><div>}</div></code></pre></div>\n<div><br /></div>\n<div>이게 번거로우면 런타임 필드 기능을 써도 된다. geo_point 타입 빈 필드 생성.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEinzjcpDQiTHonYn-eShtCmDX36ZLFeOIBd28wVFZmeJ4FdeSaSQkZJw7hMY7ARHZS4aE35HiROoJfLlZ2y7LEUOp4z07jP9KJctDX36pgKdrj-j-kTVMMZBizjWTy2ZsOfVJa0YFfrA95DDn7Sx_XY5Bp52HRG2CbWjP2pB9pJdn2uprLZgKQknR7UnK-s/s1080/runtime_field.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1080\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEinzjcpDQiTHonYn-eShtCmDX36ZLFeOIBd28wVFZmeJ4FdeSaSQkZJw7hMY7ARHZS4aE35HiROoJfLlZ2y7LEUOp4z07jP9KJctDX36pgKdrj-j-kTVMMZBizjWTy2ZsOfVJa0YFfrA95DDn7Sx_XY5Bp52HRG2CbWjP2pB9pJdn2uprLZgKQknR7UnK-s/s16000/runtime_field.png\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiaNwvOgQjsbI5ov-wU9AOsjFpaEVZR2rfnhNvQeWWwIVhoSIj1MR-KEGpTKNhP5dQECgGOQLkD_TNFkFTtw5jEMCwzgsPSJNpGp6kEEqZtF3yMAiWFmaEUpzgbHM7_1R_glfBNmtOuRYIBvgdiOD4ZLcsil2EUuIoVQ6IE1gqiAvMYyLCuHjNVNpT-sPy0/s1280/win_event_22_2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"609\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiaNwvOgQjsbI5ov-wU9AOsjFpaEVZR2rfnhNvQeWWwIVhoSIj1MR-KEGpTKNhP5dQECgGOQLkD_TNFkFTtw5jEMCwzgsPSJNpGp6kEEqZtF3yMAiWFmaEUpzgbHM7_1R_glfBNmtOuRYIBvgdiOD4ZLcsil2EUuIoVQ6IE1gqiAvMYyLCuHjNVNpT-sPy0/s16000/win_event_22_2.png\" /></a></div><div><br /></div>set value 옵션으로 새로운 값 만들 때만 썼는데 이렇게도 활용할 수 있구나.<br /><div><br /></div><div><div><b>관련 글</b></div><div><ul><li><a href=\"https://kangmyounghun.blogspot.com/2024/05/runtime-field-9th.html\">엘라스틱 Runtime field - 9th</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2021/03/712.html\" target=\"\">엘라스틱 Runtime field</a></li><li><a href=\"http://kangmyounghun.blogspot.com/2018/07/elasticsearch-scripted-field.html\" target=\"\">Elasticsearch 활용(scripted field)</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2021/09/2nd.html\" target=\"\">정규표현식 몰라도 된다 - 2nd</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2023/09/convert-ip-to-decimal.html\">convert ip to decimal</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2024/02/winlogbeat-812.html\">Winlogbeat 8.12의 변화</a></li></ul></div></div>",
        "contentSnippet": "beat 기본 인덱스 템플릿을 사용하면 1,500여 개 필드로 구성된 인덱스가 생성된다.\n\n\n\n\n이게 싫으면 별도 템플릿을 사용하면 됨.\n\n\n\n\n\n그런데 갑자기 geo_point 타입 필드가 필요하면?\n\n\n\n\n미리 계획된 템플릿을 준비하지 못했더라도 rest api로 간단히 원하는 필드 추가 가능.\n\nPUT winevent-2025/_mapping\n{\n    \"properties\": {\n        \"geoip\": {\n            \"properties\": {\n                \"location\": {\n                    \"type\": \"geo_point\"\n                }\n            }\n        }\n    }\n}\n\n\n\n\n이게 번거로우면 런타임 필드 기능을 써도 된다. geo_point 타입 빈 필드 생성.\n\n\n\n\n\nset value 옵션으로 새로운 값 만들 때만 썼는데 이렇게도 활용할 수 있구나.\n\n\n관련 글\n\n엘라스틱 Runtime field - 9th\n엘라스틱 Runtime field\nElasticsearch 활용(scripted field)\n정규표현식 몰라도 된다 - 2nd\nconvert ip to decimal\nWinlogbeat 8.12의 변화",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-3627236663677945228",
        "isoDate": "2025-03-03T12:27:00.002Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": [
      {
        "creator": "minieetea",
        "title": "인생을 0.5배속으로 살아가기",
        "link": "https://minieetea.com/20250304-0-5x-speed-for-life/",
        "pubDate": "Tue, 04 Mar 2025 12:38:51 GMT",
        "content:encodedSnippet": "올해가 카운트다운이 된 지 벌써 60일이 훌쩍 지났습니다. 아직도 저는 날짜를 입력할 때 2024로 쓰고 지우길 반복하는데 말이죠. 3월 초에도 눈은 내리지만, 겨울은 다 끝나가고 이제 봄이 온다는 것을 쇼핑몰이 봄옷으로 바뀌는 것을 보면서 비로소 눈치를 챕니다.\n얼마 전에 바뀐 나이 체계가 아니었다면 올해는 30대의 마지막입니다. 앞자리가 바뀌는 것이 싫긴 하지만, 저는 나이가 들면 시간이 빨리 간다는 말이 더 싫습니다. 새해를 맞아 휘몰아치는 업무에 시간이 훌쩍 지나가 버리고 나니 차마 할 말이 없습니다. 결국 올해도 이렇게 보내고 말겠구나!' 했어요. 예전 같았으면 체념했을 것 같아요. 올해는 망했다- 하면서 말이죠. 하지만 '이렇게 보내지 않으려면 어떻게 해야 하지?'라는 질문의 끝에 저는 이렇게 자리에 앉았습니다. 연말 휴가 때 써둔 글을 몰아서 발행한 후로는 글을 쓰지 못했으니, 사실상 올해의 첫 글이기도 합니다.\n나이가 들면 시간이 빨리 간다는 말은 과학적으로도 근거가 있는 말입니다. 반복적이고 단조로운 일상이 지속되면 시간이 빠르게 지나가는 것처럼 느껴질 수 있습니다.​ 반대로, 일상에서 특별하거나 새로운 경험이 많을수록 시간이 더 천천히 흐르는 것처럼 느낍니다. 이는 뇌가 새로운 정보를 처리하고 저장하는 과정에서 더 많은 자원을 사용하거든요.\n저는 저의 시간을 늘리는 몇 가지 방법이 있습니다. 독서와 글쓰기인데요. 단순히 시간을 보내기 위한 것이 아니라 내면의 경험을 깊이 있게 기록하고 반추하는 과정이기 때문입니다. 아마도 이런 활동을 할 때의 뇌는 평범한 일상의 순간보다 훨씬 풍부하고 세밀한 정보를 저장하게 되고, 그 결과 주관적으로 \"시간이 천천히 간다\"는 느낌을 받는 것이죠. 특히나 글쓰기의 경우 새로 받아들이는 정보와 과거의 기억, 명시적이지 않은 모호한 경험을 뚜렷하고 뾰족하게 만드는 과정에서 머리를 굉장히 많이 쓴다고 느낍니다. 도파민이 쏟아진다고나 해야 할까요?\n이런 경험을 주는 활동 하나를 더한다면 코칭도 마찬가지인 것 같습니다. 코칭은 저의 에너지 박스와 같아요. 어떤 사연이 있을지 모르는 상자를 열어보는 설렘, 당혹스러움과 안도감, 안쓰러움과 설렘 등 다양한 감정을 순식간에 느껴보기도 하고요. 나의 과거로부터의 성찰이 앞에 있는 내담자에게 전달되어 작은 변화라도 한 방울 떨어트리는 순간은 놀랍게도 며칠, 몇 달의 시간이 지나도 뚜렷하게 생각이 납니다. 15분에서 30분, 길게는 1시간의 짧은 대화만으로도 우리의 에너지가 채워지는 기분을 느끼면 이루 말할 수 없는 보람을 느끼는 것 같아요.\n만약 제가 일에 치여 오랫동안 글을 쓰지 않는다면, 다시 돌아오는 데까지 오래 걸릴까 봐 오늘은 사설을 좀 늘어놔 봤어요. 여러분의 '삶의 플레이 속도 조절 버튼'은 무엇인지 궁금해요.",
        "dc:creator": "minieetea",
        "content": "<p>&#xC62C;&#xD574;&#xAC00; &#xCE74;&#xC6B4;&#xD2B8;&#xB2E4;&#xC6B4;&#xC774; &#xB41C; &#xC9C0; &#xBC8C;&#xC368; 60&#xC77C;&#xC774; &#xD6CC;&#xCA4D; &#xC9C0;&#xB0AC;&#xC2B5;&#xB2C8;&#xB2E4;. &#xC544;&#xC9C1;&#xB3C4; &#xC800;&#xB294; &#xB0A0;&#xC9DC;&#xB97C; &#xC785;&#xB825;&#xD560; &#xB54C; 2024&#xB85C; &#xC4F0;&#xACE0; &#xC9C0;&#xC6B0;&#xAE38; &#xBC18;&#xBCF5;&#xD558;&#xB294;&#xB370; &#xB9D0;&#xC774;&#xC8E0;</p>",
        "contentSnippet": "올해가 카운트다운이 된 지 벌써 60일이 훌쩍 지났습니다. 아직도 저는 날짜를 입력할 때 2024로 쓰고 지우길 반복하는데 말이죠",
        "guid": "677d567b933924000135f0b0",
        "isoDate": "2025-03-04T12:38:51.000Z"
      }
    ]
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김놀부",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "생산성 UP! Claude, ChatGPT, Notion AI를 함께 활용하는 방법",
        "link": "http://muzbox.tistory.com/483550",
        "pubDate": "Fri, 7 Mar 2025 09:12:38 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483550#entry483550comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"blob\" data-origin-width=\"1792\" data-origin-height=\"1024\"><span data-url=\"https://blog.kakaocdn.net/dn/yPMOp/btsMEbs9nJp/7OhaIcv3laWWZYrZs3UBI1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/yPMOp/btsMEbs9nJp/7OhaIcv3laWWZYrZs3UBI1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/yPMOp/btsMEbs9nJp/7OhaIcv3laWWZYrZs3UBI1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FyPMOp%2FbtsMEbs9nJp%2F7OhaIcv3laWWZYrZs3UBI1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"생산성 UP! Claude, ChatGPT, Notion AI를 함께 활용하는 방법\" loading=\"lazy\" width=\"1792\" height=\"1024\" data-filename=\"blob\" data-origin-width=\"1792\" data-origin-height=\"1024\"/></span></figure>\n</p>\n<div>\n<style>\n:root {\n  --fashion-1: #593C47;\n  --fashion-2: #F2E63D;\n  --fashion-3: #F2C53D;\n  --fashion-4: #F25C05;\n  --fashion-5: #F24405;\n  --text-dark: #334155;\n  --text-section: #1e40af;\n  --text-subtitle: #475569;\n}\n\n* {\n  box-sizing: border-box;\n  margin: 0;\n  padding: 0;\n}\n\n.container {\n  width: 100%;\n  max-width: 1200px;\n  margin: 0 auto;\n  padding: 20px;\n  /* 블로그 기본 폰트 사용 - font-family 제거 */\n  color: var(--text-dark);\n  background-color: #f9f9f9;\n  position: relative;\n  overflow: hidden;\n}\n\n.container::before {\n  content: \"\";\n  position: absolute;\n  top: 0;\n  left: 0;\n  width: 100%;\n  height: 100%;\n  background: url(\"data:image/svg+xml,%3Csvg width='100' height='100' viewBox='0 0 100 100' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='M11 18c3.866 0 7-3.134 7-7s-3.134-7-7-7-7 3.134-7 7 3.134 7 7 7zm48 25c3.866 0 7-3.134 7-7s-3.134-7-7-7-7 3.134-7 7 3.134 7 7 7zm-43-7c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm63 31c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zM34 90c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm56-76c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zM12 86c2.21 0 4-1.79 4-4s-1.79-4-4-4-4 1.79-4 4 1.79 4 4 4zm28-65c2.21 0 4-1.79 4-4s-1.79-4-4-4-4 1.79-4 4 1.79 4 4 4zm23-11c2.76 0 5-2.24 5-5s-2.24-5-5-5-5 2.24-5 5 2.24 5 5 5zm-6 60c2.21 0 4-1.79 4-4s-1.79-4-4-4-4 1.79-4 4 1.79 4 4 4zm29 22c2.76 0 5-2.24 5-5s-2.24-5-5-5-5 2.24-5 5 2.24 5 5 5zM32 63c2.76 0 5-2.24 5-5s-2.24-5-5-5-5 2.24-5 5 2.24 5 5 5zm57-13c2.76 0 5-2.24 5-5s-2.24-5-5-5-5 2.24-5 5 2.24 5 5 5zm-9-21c1.105 0 2-.895 2-2s-.895-2-2-2-2 .895-2 2 .895 2 2 2zM60 91c1.105 0 2-.895 2-2s-.895-2-2-2-2 .895-2 2 .895 2 2 2zM35 41c1.105 0 2-.895 2-2s-.895-2-2-2-2 .895-2 2 .895 2 2 2zM12 60c1.105 0 2-.895 2-2s-.895-2-2-2-2 .895-2 2 .895 2 2 2z' fill='%23593c47' fill-opacity='0.05' fill-rule='evenodd'/%3E%3C/svg%3E\");\n  z-index: -1;\n}\n\n.header {\n  display: flex;\n  justify-content: space-between;\n  align-items: center;\n  margin-bottom: 30px;\n  border-bottom: 2px dashed var(--fashion-1);\n  padding-bottom: 15px;\n}\n\n.title {\n  font-size: 32px;\n  font-weight: bold;\n  /* font-family 제거하여 블로그 기본 폰트 사용 */\n  background: linear-gradient(to right, var(--fashion-1), var(--fashion-5));\n  -webkit-background-clip: text;\n  -webkit-text-fill-color: transparent;\n  position: relative;\n  display: inline-block;\n}\n\n.title::after {\n  content: \"\";\n  position: absolute;\n  bottom: -5px;\n  left: 0;\n  width: 100%;\n  height: 3px;\n  background: linear-gradient(to right, var(--fashion-3), var(--fashion-4));\n  border-radius: 2px;\n}\n\n.date {\n  font-size: 14px;\n  color: var(--text-subtitle);\n}\n\n.intro {\n  position: relative;\n  padding: 20px;\n  margin-bottom: 30px;\n  background-color: #ffffffd0;\n  border-radius: 12px;\n  box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n  backdrop-filter: blur(10px);\n}\n\n.intro::before {\n  content: \"✨\";\n  position: absolute;\n  top: -15px;\n  left: 20px;\n  font-size: 24px;\n}\n\n.intro-text {\n  font-size: 16px;\n  line-height: 1.6;\n}\n\n.grid-container {\n  display: grid;\n  grid-template-columns: repeat(3, 1fr);\n  gap: 20px;\n  margin-bottom: 30px;\n}\n\n.card {\n  position: relative;\n  background-color: white;\n  border-radius: 12px;\n  padding: 20px;\n  box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n  transition: transform 0.3s ease, box-shadow 0.3s ease;\n  overflow: hidden;\n}\n\n.card:hover {\n  transform: translateY(-5px);\n  box-shadow: 0 10px 20px rgba(0, 0, 0, 0.15);\n}\n\n.card::before {\n  content: \"\";\n  position: absolute;\n  top: 0;\n  left: 0;\n  width: 5px;\n  height: 100%;\n  background: linear-gradient(to bottom, var(--fashion-2), var(--fashion-4));\n  border-radius: 4px 0 0 4px;\n}\n\n.section-title {\n  display: flex;\n  align-items: center;\n  font-size: 18px;\n  font-weight: bold;\n  color: var(--text-section);\n  margin-bottom: 15px;\n  padding-bottom: 8px;\n  border-bottom: 2px dashed #e2e8f0;\n}\n\n.section-title i {\n  margin-right: 8px;\n  font-size: 20px;\n  background: var(--fashion-3);\n  color: white;\n  width: 30px;\n  height: 30px;\n  display: flex;\n  align-items: center;\n  justify-content: center;\n  border-radius: 50%;\n}\n\n.section-content {\n  font-size: 14px;\n  line-height: 1.4;\n}\n\n.highlight {\n  position: relative;\n  display: inline-block;\n  padding: 0 2px;\n  z-index: 1;\n}\n\n.highlight::before {\n  content: \"\";\n  position: absolute;\n  bottom: 0;\n  left: 0;\n  width: 100%;\n  height: 7px;\n  background-color: var(--fashion-2);\n  z-index: -1;\n  opacity: 0.7;\n}\n\n.tool-icon {\n  display: inline-flex;\n  align-items: center;\n  justify-content: center;\n  width: 24px;\n  height: 24px;\n  background-color: var(--fashion-1);\n  color: white;\n  border-radius: 50%;\n  margin-right: 5px;\n  font-size: 12px;\n}\n\n.feature-list {\n  margin: 15px 0;\n  padding-left: 20px;\n  list-style-type: none;\n}\n\n.feature-list li {\n  position: relative;\n  margin-bottom: 8px;\n  padding-left: 20px;\n}\n\n.feature-list li::before {\n  content: \"✓\";\n  position: absolute;\n  left: 0;\n  color: var(--fashion-4);\n  font-weight: bold;\n}\n\n.prompt-example {\n  background-color: #f1f5f9;\n  border-left: 3px solid var(--fashion-3);\n  padding: 10px;\n  margin: 10px 0;\n  /* font-family 제거하여 블로그 기본 폰트 사용 */\n  font-size: 16px;\n  color: #334155;\n  position: relative;\n}\n\n.prompt-example::before {\n  content: \" \";\n  position: absolute;\n  top: -10px;\n  right: 10px;\n  font-size: 20px;\n}\n\n.arrow {\n  position: absolute;\n  width: 40px;\n  height: 20px;\n}\n\n.arrow.right {\n  transform: rotate(-30deg);\n  right: -20px;\n  top: 50%;\n}\n\n.arrow.down {\n  transform: rotate(90deg);\n  bottom: -20px;\n  left: 50%;\n}\n\n.qa-section {\n  background-color: white;\n  border-radius: 12px;\n  padding: 20px;\n  margin-top: 30px;\n  box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n}\n\n.qa-title {\n  font-size: 18px;\n  font-weight: bold;\n  color: var(--text-section);\n  margin-bottom: 15px;\n  padding-bottom: 8px;\n  border-bottom: 2px dashed #e2e8f0;\n  display: flex;\n  align-items: center;\n}\n\n.qa-title::before {\n  content: \" \";\n  margin-right: 10px;\n}\n\n.qa-item {\n  margin-bottom: 15px;\n}\n\n.question {\n  font-weight: bold;\n  margin-bottom: 5px;\n  color: var(--fashion-5);\n}\n\n.answer {\n  padding-left: 20px;\n}\n\n.footer {\n  text-align: center;\n  margin-top: 30px;\n  padding-top: 15px;\n  border-top: 2px dashed var(--fashion-1);\n  font-size: 12px;\n  color: var(--text-subtitle);\n}\n\n@media (max-width: 768px) {\n  .grid-container {\n    grid-template-columns: 1fr;\n  }\n}\n\n.hand-drawn {\n  position: relative;\n  color: var(--fashion-1);\n  font-weight: bold;\n}\n\n.hand-drawn::after {\n  content: \"\";\n  position: absolute;\n  bottom: -2px;\n  left: 0;\n  width: 100%;\n  height: 2px;\n  background: repeating-linear-gradient(to right, var(--fashion-4), var(--fashion-4) 2px, transparent 2px, transparent 4px);\n}\n\n.connection-line {\n  position: absolute;\n  border: 2px dashed var(--fashion-3);\n  z-index: -1;\n}\n\n.emoji-bullet {\n  display: inline-block;\n  width: 20px;\n  text-align: center;\n  margin-right: 5px;\n}\n</style>\n</div>\n<div class=\"container\">\n<div class=\"header\">\n<h1 class=\"title\"><b>AI 도구를 활용한 생산성 극대화</b></h1>\n<p class=\"date\" data-ke-size=\"size16\">2025년 3월</p>\n</div>\n<div class=\"intro\">\n<p class=\"intro-text\" data-ke-size=\"size16\">AI 도구를 함께 사용하면 업무 생산성이 극대화됩니다. <span class=\"highlight\">Claude, ChatGPT, Notion AI</span> 등을 조합해 콘텐츠 제작을 더 효율적으로 하는 방법을 알아보세요.</p>\n</div>\n<div class=\"intro\" style=\"margin-top: 20px;\">\n<p class=\"intro-text\" data-ke-size=\"size16\"><span style=\"font-weight: bold;\">AI 도구를 활용한 생산성 극대화, 어떻게 하면 좋을까요?</span></p>\n<p class=\"intro-text\" data-ke-size=\"size16\">요즘 AI를 활용한 업무 방식이 점점 정교해지고 있어요. 단일 도구를 사용하는 것도 좋지만, 여러 개의 AI 툴을 조합하면 훨씬 강력한 결과를 얻을 수 있죠. 저도 여행 블로그 콘텐츠를 제작하면서 다양한 AI를 조합해 사용하고 있는데요. 어떤 방식으로 활용하면 효율을 극대화할 수 있는지 소개해 드릴게요.</p>\n</div>\n<div class=\"grid-container\"><!-- 카드 1: 아이디어 브레인스토밍 -->\n<div class=\"card\">\n<h2 class=\"section-title\" data-ke-size=\"size26\"><i> </i> 아이디어 브레인스토밍</h2>\n<div class=\"section-content\">\n<p data-ke-size=\"size16\">글을 쓰기 전, 가장 먼저 해야 할 일은 <span class=\"highlight\">'무엇을 쓸 것인가'</span>에 대한 고민이죠. Claude와 ChatGPT를 활용해 아이디어를 얻어요.</p>\n<div class=\"prompt-example\">\"도시 여행 가이드를 작성하려고 해. 독특한 문화 체험과 숨겨진 명소를 포함하는 색다른 주제를 추천해 줄 수 있어?\"</div>\n<p data-ke-size=\"size16\">Claude는 다양한 제목과 주제를 추천해 주고, 이를 토대로 글의 주요 섹션을 정리할 수 있어요. 이 과정에서 <span class=\"hand-drawn\">Perplexity</span>를 활용해 트렌드를 조사하면 더욱 유용합니다.</p>\n</div>\n</div>\n<!-- 카드 2: 리서치 정리 -->\n<div class=\"card\">\n<h2 class=\"section-title\" data-ke-size=\"size26\"><i>✍️</i> 리서치 정리</h2>\n<div class=\"section-content\">\n<p data-ke-size=\"size16\">리서치를 하다 보면 자료가 너무 많아져서 정리가 어려울 때가 있어요. 이럴 때 Notion AI의 <span class=\"highlight\">\"Summarize this page\"</span> 기능을 활용하면 핵심 내용만 추려볼 수 있습니다.</p>\n<p data-ke-size=\"size16\">예를 들어, Claude에서 받은 아이디어를 정리한 후 Notion AI에 요약을 맡기면 한눈에 보기 편한 포인트들만 남길 수 있어요. 특히 Notion을 자주 사용하신다면 AI 기능을 적극 활용해 보세요.</p>\n</div>\n</div>\n<!-- 카드 3: 글의 구조 잡기 -->\n<div class=\"card\">\n<h2 class=\"section-title\" data-ke-size=\"size26\"><i> ️</i> 글의 구조 잡기</h2>\n<div class=\"section-content\">\n<p data-ke-size=\"size16\">이제 글을 본격적으로 작성할 차례입니다. ChatGPT는 글의 구조를 잡는 데 유용한 도구예요. 예를 들어, <span class=\"highlight\">\"유럽에서 저렴하게 여행하는 법\"</span>을 쓴다고 가정하면, ChatGPT에 이런 프롬프트를 입력할 수 있어요.</p>\n<div class=\"prompt-example\">\"예산이 적은 여행자를 위한 유럽 여행 가이드를 작성하려고 해. 교통비 절약, 저렴한 숙소 찾기, 무료 명소 추천 등 실용적인 정보를 포함한 개요를 만들어 줄래?\"</div>\n<p data-ke-size=\"size16\">이렇게 하면 ChatGPT가 섹션별 추천 내용을 제공하는데, 이를 참고하여 내 경험과 결합해 더욱 풍부한 콘텐츠를 만들 수 있어요.</p>\n</div>\n</div>\n<!-- 카드 4: 이미지 편집 -->\n<div class=\"card\">\n<h2 class=\"section-title\" data-ke-size=\"size26\"><i> ️</i> 이미지 편집</h2>\n<div class=\"section-content\">\n<p data-ke-size=\"size16\">사진 작업을 할 때 AI를 활용하면 시간을 크게 절약할 수 있습니다. 특히 어두운 사진의 노이즈를 제거하는 <span class=\"highlight\">Lightroom의 Denoise AI</span> 기능을 추천해요.</p>\n<ul class=\"feature-list\" style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><span class=\"emoji-bullet\"> </span> <b>Denoise</b>: 저조도 사진에서 노이즈 제거</li>\n<li><span class=\"emoji-bullet\"> </span> <b>자동 피사체 선택</b>: 특정 부분만 조정 가능</li>\n<li><span class=\"emoji-bullet\">✨</span> <b>Auto Enhance</b>: 색감 및 밝기 자동 보정</li>\n</ul>\n<p data-ke-size=\"size16\">하지만 AI 보정을 너무 과하게 하면 부자연스러워질 수 있으니, 적절한 수치를 조정하는 것이 중요합니다.</p>\n</div>\n</div>\n<!-- 카드 5: 문장 교정 -->\n<div class=\"card\">\n<h2 class=\"section-title\" data-ke-size=\"size26\"><i>✨</i> 문장 교정</h2>\n<div class=\"section-content\">\n<p data-ke-size=\"size16\">블로그 글을 작성한 후에는 반드시 문법 검토를 해야 합니다. 저는 ChatGPT를 활용해 오타와 문법 오류를 잡아요.</p>\n<ul class=\"feature-list\" style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>글을 작성한 후 ChatGPT 등에서 검토</li>\n<li>맞춤법과 문법 수정</li>\n<li><b>프롬프트 요청으로 </b>문장을 더 간결하게 다듬기</li>\n</ul>\n<p data-ke-size=\"size16\">이렇게 하면 가독성이 향상되고, 독자들이 글을 읽기 더 편해집니다.</p>\n</div>\n</div>\n<!-- 카드 6: SNS 콘텐츠 제작 -->\n<div class=\"card\">\n<h2 class=\"section-title\" data-ke-size=\"size26\"><i> </i> SNS 콘텐츠 제작</h2>\n<div class=\"section-content\">\n<p data-ke-size=\"size16\">블로그 글을 작성한 후에는 SNS에서 홍보하는 것도 중요하죠. 저는 <span class=\"highlight\">ChatGPT</span>를 활용해 Pinterest용 포스트 초안을 만들고, Tailwind로 예약 발행합니다.</p>\n<div class=\"prompt-example\">\"유럽 저가 여행 블로그를 위한 Instagram 게시글 3개를 작성해 줘. '한 달 동안 100만 원으로 유럽 여행하기'라는 글을 홍보할 거야. 유익하면서도 흥미로운 내용을 포함해 줘.\"</div>\n<p data-ke-size=\"size16\">이렇게 생성된 초안을 검토한 후, 직접 수정을 거쳐 Tailwind로 예약하면 SNS 관리가 훨씬 쉬워집니다.</p>\n</div>\n</div>\n</div>\n<!-- 마무리 섹션 -->\n<div class=\"intro\">\n<h2 class=\"section-title\" data-ke-size=\"size26\"><i> </i> 마무리</h2>\n<p class=\"intro-text\" data-ke-size=\"size16\">AI는 개별 도구를 단독으로 사용하는 것보다, <span class=\"highlight\">여러 개를 조합할 때</span> 더 큰 효과를 발휘합니다. 저는 Claude, ChatGPT, Notion AI, Lightroom, Tailwind 등을 조합해 콘텐츠 제작을 최적화하고 있어요.</p>\n<p class=\"intro-text\" data-ke-size=\"size16\">  여러분도 AI 도구들을 조합해서 더 스마트한 워크플로우를 만들어 보세요! 사용해 본 AI 툴이 있다면 댓글로 공유해 주세요.  </p>\n</div>\n<!-- Q&A 섹션 -->\n<div class=\"qa-section\">\n<h2 class=\"qa-title\" data-ke-size=\"size26\">자주 묻는 질문 (Q&amp;A)</h2>\n<div class=\"qa-item\">\n<p class=\"question\" data-ke-size=\"size16\">Q1. AI 도구를 조합하면 어떤 장점이 있나요?</p>\n<p class=\"answer\" data-ke-size=\"size16\">A. 시간 절약, 콘텐츠 품질 향상, 일관된 스타일 유지 등의 장점이 있습니다.</p>\n</div>\n<div class=\"qa-item\">\n<p class=\"question\" data-ke-size=\"size16\">Q2. ChatGPT로 글을 대신 작성하는 것이 좋은가요?</p>\n<p class=\"answer\" data-ke-size=\"size16\">A. 기본 아웃라인을 만들거나 아이디어를 얻는 용도로 활용하는 것이 좋습니다. 최종 글은 직접 수정하는 것이 자연스럽습니다.</p>\n</div>\n<div class=\"qa-item\">\n<p class=\"question\" data-ke-size=\"size16\">Q3. Notion AI의 무료 사용량은 어느 정도인가요?</p>\n<p class=\"answer\" data-ke-size=\"size16\">A. 워크스페이스당 50회의 무료 AI 응답이 제공됩니다.</p>\n</div>\n<div class=\"qa-item\">\n<p class=\"question\" data-ke-size=\"size16\">Q4. AI가 편집한 사진은 자연스러울까요?</p>\n<p class=\"answer\" data-ke-size=\"size16\">A. Lightroom AI 같은 툴을 적절히 활용하면 자연스럽게 보정할 수 있지만, 과도하게 사용할 경우 인공적인 느낌이 날 수 있습니다.</p>\n</div>\n</div>\n<div class=\"footer\">\n<p data-ke-size=\"size16\">&copy; 2025 AI 생산성 극대화 가이드 | 어떤오후의 프리웨어 이야기</p>\n</div>\n</div>\n<script type=\"application/ld+json\">\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"AI 도구를 조합하면 어떤 장점이 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"시간 절약, 콘텐츠 품질 향상, 일관된 스타일 유지 등의 장점이 있습니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"ChatGPT로 글을 대신 작성하는 것이 좋은가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"기본 아웃라인을 만들거나 아이디어를 얻는 용도로 활용하는 것이 좋습니다. 최종 글은 직접 수정하는 것이 자연스럽습니다.\"\n      }\n    },\n   {\n      \"@type\": \"Question\",\n      \"name\": \"Notion AI의 무료 사용량은 어느 정도인가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"워크스페이스당 50회의 무료 AI 응답이 제공됩니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"AI가 편집한 사진은 자연스러울까요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"Lightroom AI 같은 툴을 적절히 활용하면 자연스럽게 보정할 수 있지만, 과도하게 사용할 경우 인공적인 느낌이 날 수 있습니다.\"\n      }\n    }\n  ]\n}\n</script>",
        "contentSnippet": ":root {\n  --fashion-1: #593C47;\n  --fashion-2: #F2E63D;\n  --fashion-3: #F2C53D;\n  --fashion-4: #F25C05;\n  --fashion-5: #F24405;\n  --text-dark: #334155;\n  --text-section: #1e40af;\n  --text-subtitle: #475569;\n}\n\n* {\n  box-sizing: border-box;\n  margin: 0;\n  padding: 0;\n}\n\n.container {\n  width: 100%;\n  max-width: 1200px;\n  margin: 0 auto;\n  padding: 20px;\n  /* 블로그 기본 폰트 사용 - font-family 제거 */\n  color: var(--text-dark);\n  background-color: #f9f9f9;\n  position: relative;\n  overflow: hidden;\n}\n\n.container::before {\n  content: \"\";\n  position: absolute;\n  top: 0;\n  left: 0;\n  width: 100%;\n  height: 100%;\n  background: url(\"data:image/svg+xml,%3Csvg width='100' height='100' viewBox='0 0 100 100' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='M11 18c3.866 0 7-3.134 7-7s-3.134-7-7-7-7 3.134-7 7 3.134 7 7 7zm48 25c3.866 0 7-3.134 7-7s-3.134-7-7-7-7 3.134-7 7 3.134 7 7 7zm-43-7c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm63 31c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zM34 90c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm56-76c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zM12 86c2.21 0 4-1.79 4-4s-1.79-4-4-4-4 1.79-4 4 1.79 4 4 4zm28-65c2.21 0 4-1.79 4-4s-1.79-4-4-4-4 1.79-4 4 1.79 4 4 4zm23-11c2.76 0 5-2.24 5-5s-2.24-5-5-5-5 2.24-5 5 2.24 5 5 5zm-6 60c2.21 0 4-1.79 4-4s-1.79-4-4-4-4 1.79-4 4 1.79 4 4 4zm29 22c2.76 0 5-2.24 5-5s-2.24-5-5-5-5 2.24-5 5 2.24 5 5 5zM32 63c2.76 0 5-2.24 5-5s-2.24-5-5-5-5 2.24-5 5 2.24 5 5 5zm57-13c2.76 0 5-2.24 5-5s-2.24-5-5-5-5 2.24-5 5 2.24 5 5 5zm-9-21c1.105 0 2-.895 2-2s-.895-2-2-2-2 .895-2 2 .895 2 2 2zM60 91c1.105 0 2-.895 2-2s-.895-2-2-2-2 .895-2 2 .895 2 2 2zM35 41c1.105 0 2-.895 2-2s-.895-2-2-2-2 .895-2 2 .895 2 2 2zM12 60c1.105 0 2-.895 2-2s-.895-2-2-2-2 .895-2 2 .895 2 2 2z' fill='%23593c47' fill-opacity='0.05' fill-rule='evenodd'/%3E%3C/svg%3E\");\n  z-index: -1;\n}\n\n.header {\n  display: flex;\n  justify-content: space-between;\n  align-items: center;\n  margin-bottom: 30px;\n  border-bottom: 2px dashed var(--fashion-1);\n  padding-bottom: 15px;\n}\n\n.title {\n  font-size: 32px;\n  font-weight: bold;\n  /* font-family 제거하여 블로그 기본 폰트 사용 */\n  background: linear-gradient(to right, var(--fashion-1), var(--fashion-5));\n  -webkit-background-clip: text;\n  -webkit-text-fill-color: transparent;\n  position: relative;\n  display: inline-block;\n}\n\n.title::after {\n  content: \"\";\n  position: absolute;\n  bottom: -5px;\n  left: 0;\n  width: 100%;\n  height: 3px;\n  background: linear-gradient(to right, var(--fashion-3), var(--fashion-4));\n  border-radius: 2px;\n}\n\n.date {\n  font-size: 14px;\n  color: var(--text-subtitle);\n}\n\n.intro {\n  position: relative;\n  padding: 20px;\n  margin-bottom: 30px;\n  background-color: #ffffffd0;\n  border-radius: 12px;\n  box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n  backdrop-filter: blur(10px);\n}\n\n.intro::before {\n  content: \"✨\";\n  position: absolute;\n  top: -15px;\n  left: 20px;\n  font-size: 24px;\n}\n\n.intro-text {\n  font-size: 16px;\n  line-height: 1.6;\n}\n\n.grid-container {\n  display: grid;\n  grid-template-columns: repeat(3, 1fr);\n  gap: 20px;\n  margin-bottom: 30px;\n}\n\n.card {\n  position: relative;\n  background-color: white;\n  border-radius: 12px;\n  padding: 20px;\n  box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n  transition: transform 0.3s ease, box-shadow 0.3s ease;\n  overflow: hidden;\n}\n\n.card:hover {\n  transform: translateY(-5px);\n  box-shadow: 0 10px 20px rgba(0, 0, 0, 0.15);\n}\n\n.card::before {\n  content: \"\";\n  position: absolute;\n  top: 0;\n  left: 0;\n  width: 5px;\n  height: 100%;\n  background: linear-gradient(to bottom, var(--fashion-2), var(--fashion-4));\n  border-radius: 4px 0 0 4px;\n}\n\n.section-title {\n  display: flex;\n  align-items: center;\n  font-size: 18px;\n  font-weight: bold;\n  color: var(--text-section);\n  margin-bottom: 15px;\n  padding-bottom: 8px;\n  border-bottom: 2px dashed #e2e8f0;\n}\n\n.section-title i {\n  margin-right: 8px;\n  font-size: 20px;\n  background: var(--fashion-3);\n  color: white;\n  width: 30px;\n  height: 30px;\n  display: flex;\n  align-items: center;\n  justify-content: center;\n  border-radius: 50%;\n}\n\n.section-content {\n  font-size: 14px;\n  line-height: 1.4;\n}\n\n.highlight {\n  position: relative;\n  display: inline-block;\n  padding: 0 2px;\n  z-index: 1;\n}\n\n.highlight::before {\n  content: \"\";\n  position: absolute;\n  bottom: 0;\n  left: 0;\n  width: 100%;\n  height: 7px;\n  background-color: var(--fashion-2);\n  z-index: -1;\n  opacity: 0.7;\n}\n\n.tool-icon {\n  display: inline-flex;\n  align-items: center;\n  justify-content: center;\n  width: 24px;\n  height: 24px;\n  background-color: var(--fashion-1);\n  color: white;\n  border-radius: 50%;\n  margin-right: 5px;\n  font-size: 12px;\n}\n\n.feature-list {\n  margin: 15px 0;\n  padding-left: 20px;\n  list-style-type: none;\n}\n\n.feature-list li {\n  position: relative;\n  margin-bottom: 8px;\n  padding-left: 20px;\n}\n\n.feature-list li::before {\n  content: \"✓\";\n  position: absolute;\n  left: 0;\n  color: var(--fashion-4);\n  font-weight: bold;\n}\n\n.prompt-example {\n  background-color: #f1f5f9;\n  border-left: 3px solid var(--fashion-3);\n  padding: 10px;\n  margin: 10px 0;\n  /* font-family 제거하여 블로그 기본 폰트 사용 */\n  font-size: 16px;\n  color: #334155;\n  position: relative;\n}\n\n.prompt-example::before {\n  content: \" \";\n  position: absolute;\n  top: -10px;\n  right: 10px;\n  font-size: 20px;\n}\n\n.arrow {\n  position: absolute;\n  width: 40px;\n  height: 20px;\n}\n\n.arrow.right {\n  transform: rotate(-30deg);\n  right: -20px;\n  top: 50%;\n}\n\n.arrow.down {\n  transform: rotate(90deg);\n  bottom: -20px;\n  left: 50%;\n}\n\n.qa-section {\n  background-color: white;\n  border-radius: 12px;\n  padding: 20px;\n  margin-top: 30px;\n  box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n}\n\n.qa-title {\n  font-size: 18px;\n  font-weight: bold;\n  color: var(--text-section);\n  margin-bottom: 15px;\n  padding-bottom: 8px;\n  border-bottom: 2px dashed #e2e8f0;\n  display: flex;\n  align-items: center;\n}\n\n.qa-title::before {\n  content: \" \";\n  margin-right: 10px;\n}\n\n.qa-item {\n  margin-bottom: 15px;\n}\n\n.question {\n  font-weight: bold;\n  margin-bottom: 5px;\n  color: var(--fashion-5);\n}\n\n.answer {\n  padding-left: 20px;\n}\n\n.footer {\n  text-align: center;\n  margin-top: 30px;\n  padding-top: 15px;\n  border-top: 2px dashed var(--fashion-1);\n  font-size: 12px;\n  color: var(--text-subtitle);\n}\n\n@media (max-width: 768px) {\n  .grid-container {\n    grid-template-columns: 1fr;\n  }\n}\n\n.hand-drawn {\n  position: relative;\n  color: var(--fashion-1);\n  font-weight: bold;\n}\n\n.hand-drawn::after {\n  content: \"\";\n  position: absolute;\n  bottom: -2px;\n  left: 0;\n  width: 100%;\n  height: 2px;\n  background: repeating-linear-gradient(to right, var(--fashion-4), var(--fashion-4) 2px, transparent 2px, transparent 4px);\n}\n\n.connection-line {\n  position: absolute;\n  border: 2px dashed var(--fashion-3);\n  z-index: -1;\n}\n\n.emoji-bullet {\n  display: inline-block;\n  width: 20px;\n  text-align: center;\n  margin-right: 5px;\n}\n\n\n\n\nAI 도구를 활용한 생산성 극대화\n2025년 3월\nAI 도구를 함께 사용하면 업무 생산성이 극대화됩니다. Claude, ChatGPT, Notion AI 등을 조합해 콘텐츠 제작을 더 효율적으로 하는 방법을 알아보세요.\nAI 도구를 활용한 생산성 극대화, 어떻게 하면 좋을까요?\n요즘 AI를 활용한 업무 방식이 점점 정교해지고 있어요. 단일 도구를 사용하는 것도 좋지만, 여러 개의 AI 툴을 조합하면 훨씬 강력한 결과를 얻을 수 있죠. 저도 여행 블로그 콘텐츠를 제작하면서 다양한 AI를 조합해 사용하고 있는데요. 어떤 방식으로 활용하면 효율을 극대화할 수 있는지 소개해 드릴게요.\n\n\n  아이디어 브레인스토밍\n글을 쓰기 전, 가장 먼저 해야 할 일은 '무엇을 쓸 것인가'에 대한 고민이죠. Claude와 ChatGPT를 활용해 아이디어를 얻어요.\n\"도시 여행 가이드를 작성하려고 해. 독특한 문화 체험과 숨겨진 명소를 포함하는 색다른 주제를 추천해 줄 수 있어?\"\nClaude는 다양한 제목과 주제를 추천해 주고, 이를 토대로 글의 주요 섹션을 정리할 수 있어요. 이 과정에서 Perplexity를 활용해 트렌드를 조사하면 더욱 유용합니다.\n✍️ 리서치 정리\n리서치를 하다 보면 자료가 너무 많아져서 정리가 어려울 때가 있어요. 이럴 때 Notion AI의 \"Summarize this page\" 기능을 활용하면 핵심 내용만 추려볼 수 있습니다.\n예를 들어, Claude에서 받은 아이디어를 정리한 후 Notion AI에 요약을 맡기면 한눈에 보기 편한 포인트들만 남길 수 있어요. 특히 Notion을 자주 사용하신다면 AI 기능을 적극 활용해 보세요.\n ️ 글의 구조 잡기\n이제 글을 본격적으로 작성할 차례입니다. ChatGPT는 글의 구조를 잡는 데 유용한 도구예요. 예를 들어, \"유럽에서 저렴하게 여행하는 법\"을 쓴다고 가정하면, ChatGPT에 이런 프롬프트를 입력할 수 있어요.\n\"예산이 적은 여행자를 위한 유럽 여행 가이드를 작성하려고 해. 교통비 절약, 저렴한 숙소 찾기, 무료 명소 추천 등 실용적인 정보를 포함한 개요를 만들어 줄래?\"\n이렇게 하면 ChatGPT가 섹션별 추천 내용을 제공하는데, 이를 참고하여 내 경험과 결합해 더욱 풍부한 콘텐츠를 만들 수 있어요.\n ️ 이미지 편집\n사진 작업을 할 때 AI를 활용하면 시간을 크게 절약할 수 있습니다. 특히 어두운 사진의 노이즈를 제거하는 Lightroom의 Denoise AI 기능을 추천해요.\n  Denoise: 저조도 사진에서 노이즈 제거\n  자동 피사체 선택: 특정 부분만 조정 가능\n✨ Auto Enhance: 색감 및 밝기 자동 보정\n하지만 AI 보정을 너무 과하게 하면 부자연스러워질 수 있으니, 적절한 수치를 조정하는 것이 중요합니다.\n✨ 문장 교정\n블로그 글을 작성한 후에는 반드시 문법 검토를 해야 합니다. 저는 ChatGPT를 활용해 오타와 문법 오류를 잡아요.\n글을 작성한 후 ChatGPT 등에서 검토\n맞춤법과 문법 수정\n프롬프트 요청으로 문장을 더 간결하게 다듬기\n이렇게 하면 가독성이 향상되고, 독자들이 글을 읽기 더 편해집니다.\n  SNS 콘텐츠 제작\n블로그 글을 작성한 후에는 SNS에서 홍보하는 것도 중요하죠. 저는 ChatGPT를 활용해 Pinterest용 포스트 초안을 만들고, Tailwind로 예약 발행합니다.\n\"유럽 저가 여행 블로그를 위한 Instagram 게시글 3개를 작성해 줘. '한 달 동안 100만 원으로 유럽 여행하기'라는 글을 홍보할 거야. 유익하면서도 흥미로운 내용을 포함해 줘.\"\n이렇게 생성된 초안을 검토한 후, 직접 수정을 거쳐 Tailwind로 예약하면 SNS 관리가 훨씬 쉬워집니다.\n  마무리\nAI는 개별 도구를 단독으로 사용하는 것보다, 여러 개를 조합할 때 더 큰 효과를 발휘합니다. 저는 Claude, ChatGPT, Notion AI, Lightroom, Tailwind 등을 조합해 콘텐츠 제작을 최적화하고 있어요.\n  여러분도 AI 도구들을 조합해서 더 스마트한 워크플로우를 만들어 보세요! 사용해 본 AI 툴이 있다면 댓글로 공유해 주세요.  \n자주 묻는 질문 (Q&A)\nQ1. AI 도구를 조합하면 어떤 장점이 있나요?\nA. 시간 절약, 콘텐츠 품질 향상, 일관된 스타일 유지 등의 장점이 있습니다.\nQ2. ChatGPT로 글을 대신 작성하는 것이 좋은가요?\nA. 기본 아웃라인을 만들거나 아이디어를 얻는 용도로 활용하는 것이 좋습니다. 최종 글은 직접 수정하는 것이 자연스럽습니다.\nQ3. Notion AI의 무료 사용량은 어느 정도인가요?\nA. 워크스페이스당 50회의 무료 AI 응답이 제공됩니다.\nQ4. AI가 편집한 사진은 자연스러울까요?\nA. Lightroom AI 같은 툴을 적절히 활용하면 자연스럽게 보정할 수 있지만, 과도하게 사용할 경우 인공적인 느낌이 날 수 있습니다.\n© 2025 AI 생산성 극대화 가이드 | 어떤오후의 프리웨어 이야기\n\n\n\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"AI 도구를 조합하면 어떤 장점이 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"시간 절약, 콘텐츠 품질 향상, 일관된 스타일 유지 등의 장점이 있습니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"ChatGPT로 글을 대신 작성하는 것이 좋은가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"기본 아웃라인을 만들거나 아이디어를 얻는 용도로 활용하는 것이 좋습니다. 최종 글은 직접 수정하는 것이 자연스럽습니다.\"\n      }\n    },\n   {\n      \"@type\": \"Question\",\n      \"name\": \"Notion AI의 무료 사용량은 어느 정도인가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"워크스페이스당 50회의 무료 AI 응답이 제공됩니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"AI가 편집한 사진은 자연스러울까요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"Lightroom AI 같은 툴을 적절히 활용하면 자연스럽게 보정할 수 있지만, 과도하게 사용할 경우 인공적인 느낌이 날 수 있습니다.\"\n      }\n    }\n  ]\n}",
        "guid": "http://muzbox.tistory.com/483550",
        "categories": [
          "AI, 미래기술",
          "ai 도구 조합",
          "ai 브레인스토밍",
          "ChatGPT 활용법",
          "grammarly 문법 교정",
          "lightroom ai 사진 편집",
          "notion ai 요약",
          "sns 마케팅",
          "tailwind 예약 발행",
          "생산성 향상",
          "콘텐츠 제작"
        ],
        "isoDate": "2025-03-07T00:12:38.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "YouTube 추천 알고리즘, 내 입맛대로 조정하는 법",
        "link": "http://muzbox.tistory.com/483549",
        "pubDate": "Wed, 5 Mar 2025 11:20:33 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483549#entry483549comment",
        "content": "<p data-ke-size=\"size16\">YouTube 추천 알고리즘이 원하는 대로 작동하지 않나요? 엉뚱한 영상이 계속 뜨는 이유는 시청 기록과 검색 기록 때문일 수도 있어요. 피드를 최적화하고 원하는 콘텐츠만 추천받는 방법을 알려드릴게요!</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"edited_YouTube 추천 알고리즘, 내 입맛대로 조정하는 법.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/b1euyG/btsMBE3IzHc/XFqQDjXWQklvIzRKBie9p1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/b1euyG/btsMBE3IzHc/XFqQDjXWQklvIzRKBie9p1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/b1euyG/btsMBE3IzHc/XFqQDjXWQklvIzRKBie9p1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb1euyG%2FbtsMBE3IzHc%2FXFqQDjXWQklvIzRKBie9p1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"edited_YouTube 추천 알고리즘, 내 입맛대로 조정하는 법.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">YouTube를 사용하다 보면 원치 않는 영상이 추천 피드를 도배하는 경우가 많아요. 한 번 실수로 클릭한 영상 때문에 이후의 추천이 엉망이 되기도 하고요. \"내가 좋아하는 콘텐츠만 보고 싶은데, 방법이 없을까?\"라는 고민, 한 번쯤 해보셨을 거예요. 다행히 YouTube 추천 알고리즘은 우리가 조작할 수 있는 요소가 많아요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">오늘은 <b>YouTube 추천 피드를 깔끔하게 정리하고, 나에게 꼭 맞는 영상을 추천받는 방법</b>을 알려드릴게요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>  YouTube 추천 알고리즘을 최적화하는 5가지 방법</b></span></h2>\n<p data-ke-size=\"size16\">YouTube의 추천 시스템은 <b>시청 기록, 검색 기록, 좋아요, 싫어요, 구독 채널, 피드백(&lsquo;관심 없음&rsquo; 또는 &lsquo;이 채널 추천 안 함&rsquo;)</b> 등을 분석해 사용자의 관심사에 맞는 영상을 제공합니다. 하지만 한 번의 잘못된 클릭이 계속된 추천 오류를 유발할 수도 있어요. 이 문제를 해결하는 5가지 방법을 소개할게요.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">1️⃣ 시청 기록을 삭제해 새로운 추천 받기</span></h3>\n<p data-ke-size=\"size16\">YouTube 추천이 엉망이 된 가장 큰 이유는 <b>기존의 시청 기록 때문</b>입니다. 내가 한 번이라도 본 영상이 추천 알고리즘에 반영되기 때문에, 관심이 없던 영상이 자꾸 등장하는 거죠.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"유튜브 시청기록 지우기.jpg\" data-origin-width=\"958\" data-origin-height=\"481\"><span data-url=\"https://blog.kakaocdn.net/dn/paSqp/btsMBANRJZW/CwzIKJfqcBV5IxzY3RZgi1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/paSqp/btsMBANRJZW/CwzIKJfqcBV5IxzY3RZgi1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/paSqp/btsMBANRJZW/CwzIKJfqcBV5IxzY3RZgi1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FpaSqp%2FbtsMBANRJZW%2FCwzIKJfqcBV5IxzY3RZgi1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"958\" height=\"481\" data-filename=\"유튜브 시청기록 지우기.jpg\" data-origin-width=\"958\" data-origin-height=\"481\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">✔ <b>해결 방법:</b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>YouTube 왼쪽 메뉴에서 <b>&lsquo;기록&rsquo;</b> 클릭</li>\n<li>오른쪽에서 <b>&lsquo;모든 시청 기록 삭제&rsquo;</b> 선택</li>\n<li>앞으로 볼 콘텐츠만 추천받고 싶다면 <b>시청 기록을 아예 끄는 것도 가능!</b></li>\n</ul>\n<p data-ke-size=\"size16\">  <b>팁:</b><br />시청 기록을 삭제하기 전에 중요한 영상은 &lsquo;나중에 보기&rsquo; 목록이나 플레이리스트에 저장해 두세요!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">2️⃣ 관심 있는 주제의 영상만 시청하기</span></h3>\n<p data-ke-size=\"size16\">시청 기록을 삭제한 후에는 <b>현재 관심 있는 콘텐츠만 시청</b>해야 합니다. YouTube 알고리즘은 사용자가 본 영상의 주제를 기반으로 다음 추천 영상을 결정하니까요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">❌ <b>주의할 점:</b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>호기심에 클릭 금지!</b> 관심 없는 영상은 클릭하지 마세요.</li>\n<li>실수로 클릭한 영상은 &lsquo;기록&rsquo;에서 바로 삭제할 것!</li>\n</ul>\n<p data-ke-size=\"size16\">✔ <b>시청 기록을 보호하는 방법:</b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>특정 콘텐츠를 검색해야 할 때는 <b>&lsquo;시청 기록 일시 중지&rsquo;</b> 기능 사용\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>방법: YouTube &lsquo;기록&rsquo; &rarr; &lsquo;시청 기록 일시 중지&rsquo;</li>\n<li>&nbsp;</li>\n</ul>\n</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">3️⃣ 좋아요는 신중하게, 싫어요도 적극 활용</span></h3>\n<p data-ke-size=\"size16\">&lsquo;좋아요&rsquo;를 누르는 것도 YouTube 추천 알고리즘에 큰 영향을 줍니다. 하지만 <b>무조건 좋아요를 누르면 오히려 추천 피드가 혼란스러워질 수 있어요.</b></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">✔ <b>좋아요 활용법:</b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>**보고 싶은 영상에만<b> &lsquo;좋아요&rsquo;</b>를 누르세요.</li>\n<li>예전에는 좋아했지만 지금은 관심 없는 영상은 <b>&lsquo;좋아요 취소&rsquo;</b>!</li>\n</ul>\n<p data-ke-size=\"size16\">❌ <b>싫어요 활용법:</b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>특정 유형의 콘텐츠를 추천받고 싶지 않다면 <b>&lsquo;싫어요&rsquo;</b> 버튼 클릭</li>\n<li>더 강력한 차단을 원하면 <b>&lsquo;이 채널 추천 안 함&rsquo;</b> 옵션 활용</li>\n</ul>\n<p data-ke-size=\"size16\">  <b>&lsquo;좋아요&rsquo;와 &lsquo;싫어요&rsquo;를 전략적으로 사용하면 원하는 영상만 추천받을 수 있어요!</b></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">4️⃣ 검색 기록도 관리해야 한다</span></h3>\n<p data-ke-size=\"size16\">YouTube는 시청 기록뿐만 아니라 <b>검색 기록도 추천 알고리즘에 반영</b>합니다. 내가 검색한 주제와 관련된 영상이 피드에 나타나는 이유죠.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"유튜브 검색기록 해제.jpg\" data-origin-width=\"847\" data-origin-height=\"489\"><span data-url=\"https://blog.kakaocdn.net/dn/caKmfS/btsMBhnuWNm/Cp6pW0Hwd2qswI6ht8sH51/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/caKmfS/btsMBhnuWNm/Cp6pW0Hwd2qswI6ht8sH51/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/caKmfS/btsMBhnuWNm/Cp6pW0Hwd2qswI6ht8sH51/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcaKmfS%2FbtsMBhnuWNm%2FCp6pW0Hwd2qswI6ht8sH51%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"847\" height=\"489\" data-filename=\"유튜브 검색기록 해제.jpg\" data-origin-width=\"847\" data-origin-height=\"489\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">✔ <b>검색 기록 정리 방법:</b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>프로필 아이콘 클릭 &rarr; <b>&lsquo;YouTube 데이터&rsquo;</b> 선택</li>\n<li><b>&lsquo;YouTube 검색 기록 포함&rsquo;</b> 옵션 체크 해제</li>\n<li>필요하면 <b>&lsquo;검색 기록 삭제&rsquo;</b></li>\n</ul>\n<p data-ke-size=\"size16\">  검색 기록을 삭제하면 특정 키워드 검색이 이후 추천에 영향을 주지 않아요!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">5️⃣ 추천 주제 필터를 활용해 원하는 영상만 보기</span></h3>\n<p data-ke-size=\"size16\">YouTube 홈 화면 상단에는 내가 관심 있는 주제를 기반으로 한 필터가 표시됩니다.<br />이 기능을 적극 활용하면 원하는 주제의 영상만 추천받을 수 있어요!</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"유튜브 관심없음.jpg\" data-origin-width=\"893\" data-origin-height=\"531\"><span data-url=\"https://blog.kakaocdn.net/dn/daEhg3/btsMAZN44YB/EyTT8vm4650sC0SQsqkLZ0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/daEhg3/btsMAZN44YB/EyTT8vm4650sC0SQsqkLZ0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/daEhg3/btsMAZN44YB/EyTT8vm4650sC0SQsqkLZ0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdaEhg3%2FbtsMAZN44YB%2FEyTT8vm4650sC0SQsqkLZ0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"893\" height=\"531\" data-filename=\"유튜브 관심없음.jpg\" data-origin-width=\"893\" data-origin-height=\"531\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">✔ <b>활용법:</b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>상단의 주제 필터를 클릭하면 관련된 영상만 피드에 표시됨</li>\n<li>원하는 주제가 계속 나오도록 <b>비슷한 주제의 영상을 여러 개 시청</b></li>\n</ul>\n<p data-ke-size=\"size16\">  <b>관심 없는 주제가 계속 추천된다면?</b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>&lsquo;관심 없음&rsquo;</b> 또는 <b>&lsquo;이 채널 추천 안 함&rsquo;</b>을 선택하세요!</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b><span style=\"color: #009a87;\">  YouTube 추천 피드를 정리하는 마무리 꿀팁</span></b></h2>\n<p data-ke-size=\"size16\">✅ <b>시청 기록을 삭제하고 새로운 추천을 받는다</b><br />✅ <b>현재 관심 있는 영상만 시청한다</b><br />✅ <b>좋아요, 싫어요를 신중하게 활용한다</b><br />✅ <b>검색 기록을 관리해 추천 피드에 영향을 주지 않는다</b><br />✅ <b>주제 필터를 활용해 원하는 영상만 추천받는다</b></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 방법들을 실천하면 YouTube가 <b>내가 원하는 영상만 추천하는 최적의 플랫폼</b>으로 변할 거예요.<br />불필요한 콘텐츠에 시간 낭비하지 말고, 원하는 정보만 골라서 시청해 보세요!  </p>\n<hr data-ke-style=\"style1\" />\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>  Q&amp;A (자주 묻는 질문)</b></span></h2>\n<p data-ke-size=\"size16\"><b>1. YouTube 추천 피드를 완전히 초기화할 수 있나요?</b></p>\n<p data-ke-size=\"size16\">네! <b>&lsquo;시청 기록 삭제&rsquo; + &lsquo;검색 기록 삭제&rsquo;</b>를 하면 추천 피드가 초기화됩니다. 하지만 완전히 새롭게 만들려면 이후의 시청 습관도 신경 써야 해요.</p>\n<p data-ke-size=\"size16\"><b>2. 검색 기록을 남기지 않고 영상을 볼 수 있나요?</b></p>\n<p data-ke-size=\"size16\">네! <b>&lsquo;시청 기록 일시 중지&rsquo; 기능</b>을 사용하면 검색해도 기록이 남지 않아요.</p>\n<p data-ke-size=\"size16\"><b>3. 특정 채널의 영상이 추천되지 않도록 하는 방법은?</b></p>\n<p data-ke-size=\"size16\"><span style=\"letter-spacing: 0px;\">영상에서</span><b> &lsquo;이 채널 추천 안 함&rsquo;</b><span style=\"letter-spacing: 0px;\">을 선택하면 해당 채널의 영상이 더 이상 추천되지 않습니다.</span></p>\n<p data-ke-size=\"size16\"><b>4. YouTube 알고리즘이 내 관심사를 파악하는 기준은?</b></p>\n<p data-ke-size=\"size16\">YouTube는 <b>시청 기록, 검색 기록, 좋아요, 싫어요, 구독 정보, 피드백(&lsquo;관심 없음&rsquo; 선택 등)</b>을 종합적으로 분석해서 추천을 만듭니다.</p>\n<p data-ke-size=\"size16\"><b>5. 주제별 추천 필터는 어떻게 활용하면 좋나요?</b></p>\n<p data-ke-size=\"size16\">홈 화면 상단의 주제 필터를 클릭하면 특정 주제의 영상만 볼 수 있습니다. 관심 있는 주제를 여러 개 클릭하면 추천 피드가 더욱 최적화됩니다.</p>\n<script type=\"application/ld+json\">\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"YouTube 추천 피드를 완전히 초기화할 수 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"네! ‘시청 기록 삭제’와 ‘검색 기록 삭제’를 하면 추천 피드가 초기화됩니다. 하지만 이후의 시청 습관도 신경 써야 원하는 영상만 추천받을 수 있습니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"검색 기록을 남기지 않고 영상을 볼 수 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"네! ‘시청 기록 일시 중지’ 기능을 사용하면 검색해도 기록이 남지 않으며, 추천 피드에 영향을 주지 않습니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"특정 채널의 영상이 추천되지 않도록 하는 방법은?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"영상에서 ‘이 채널 추천 안 함’을 선택하면 해당 채널의 영상이 더 이상 추천되지 않습니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"YouTube 알고리즘이 내 관심사를 파악하는 기준은?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"YouTube는 시청 기록, 검색 기록, 좋아요, 싫어요, 구독 정보, 피드백(‘관심 없음’ 선택 등)을 종합적으로 분석해서 추천을 생성합니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"주제별 추천 필터는 어떻게 활용하면 좋나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"홈 화면 상단의 주제 필터를 클릭하면 특정 주제의 영상만 볼 수 있습니다. 관심 있는 주제를 여러 개 클릭하면 추천 피드가 더욱 최적화됩니다.\"\n      }\n    }\n  ]\n}\n</script>\n<div id=\"gtx-trans\" style=\"position: absolute; left: -188px; top: 4883.69px;\">\n<div class=\"gtx-trans-icon\">&nbsp;</div>\n</div>",
        "contentSnippet": "YouTube 추천 알고리즘이 원하는 대로 작동하지 않나요? 엉뚱한 영상이 계속 뜨는 이유는 시청 기록과 검색 기록 때문일 수도 있어요. 피드를 최적화하고 원하는 콘텐츠만 추천받는 방법을 알려드릴게요!\n\n\n \nYouTube를 사용하다 보면 원치 않는 영상이 추천 피드를 도배하는 경우가 많아요. 한 번 실수로 클릭한 영상 때문에 이후의 추천이 엉망이 되기도 하고요. \"내가 좋아하는 콘텐츠만 보고 싶은데, 방법이 없을까?\"라는 고민, 한 번쯤 해보셨을 거예요. 다행히 YouTube 추천 알고리즘은 우리가 조작할 수 있는 요소가 많아요.\n \n오늘은 YouTube 추천 피드를 깔끔하게 정리하고, 나에게 꼭 맞는 영상을 추천받는 방법을 알려드릴게요.\n \n \n  YouTube 추천 알고리즘을 최적화하는 5가지 방법\nYouTube의 추천 시스템은 시청 기록, 검색 기록, 좋아요, 싫어요, 구독 채널, 피드백(‘관심 없음’ 또는 ‘이 채널 추천 안 함’) 등을 분석해 사용자의 관심사에 맞는 영상을 제공합니다. 하지만 한 번의 잘못된 클릭이 계속된 추천 오류를 유발할 수도 있어요. 이 문제를 해결하는 5가지 방법을 소개할게요.\n1️⃣ 시청 기록을 삭제해 새로운 추천 받기\nYouTube 추천이 엉망이 된 가장 큰 이유는 기존의 시청 기록 때문입니다. 내가 한 번이라도 본 영상이 추천 알고리즘에 반영되기 때문에, 관심이 없던 영상이 자꾸 등장하는 거죠.\n\n\n \n✔ 해결 방법:\nYouTube 왼쪽 메뉴에서 ‘기록’ 클릭\n오른쪽에서 ‘모든 시청 기록 삭제’ 선택\n앞으로 볼 콘텐츠만 추천받고 싶다면 시청 기록을 아예 끄는 것도 가능!\n  팁:\n시청 기록을 삭제하기 전에 중요한 영상은 ‘나중에 보기’ 목록이나 플레이리스트에 저장해 두세요!\n \n2️⃣ 관심 있는 주제의 영상만 시청하기\n시청 기록을 삭제한 후에는 현재 관심 있는 콘텐츠만 시청해야 합니다. YouTube 알고리즘은 사용자가 본 영상의 주제를 기반으로 다음 추천 영상을 결정하니까요.\n \n❌ 주의할 점:\n호기심에 클릭 금지! 관심 없는 영상은 클릭하지 마세요.\n실수로 클릭한 영상은 ‘기록’에서 바로 삭제할 것!\n✔ 시청 기록을 보호하는 방법:\n특정 콘텐츠를 검색해야 할 때는 ‘시청 기록 일시 중지’ 기능 사용\n\n방법: YouTube ‘기록’ → ‘시청 기록 일시 중지’\n \n3️⃣ 좋아요는 신중하게, 싫어요도 적극 활용\n‘좋아요’를 누르는 것도 YouTube 추천 알고리즘에 큰 영향을 줍니다. 하지만 무조건 좋아요를 누르면 오히려 추천 피드가 혼란스러워질 수 있어요.\n \n✔ 좋아요 활용법:\n**보고 싶은 영상에만 ‘좋아요’를 누르세요.\n예전에는 좋아했지만 지금은 관심 없는 영상은 ‘좋아요 취소’!\n❌ 싫어요 활용법:\n특정 유형의 콘텐츠를 추천받고 싶지 않다면 ‘싫어요’ 버튼 클릭\n더 강력한 차단을 원하면 ‘이 채널 추천 안 함’ 옵션 활용\n  ‘좋아요’와 ‘싫어요’를 전략적으로 사용하면 원하는 영상만 추천받을 수 있어요!\n \n4️⃣ 검색 기록도 관리해야 한다\nYouTube는 시청 기록뿐만 아니라 검색 기록도 추천 알고리즘에 반영합니다. 내가 검색한 주제와 관련된 영상이 피드에 나타나는 이유죠.\n\n\n \n✔ 검색 기록 정리 방법:\n프로필 아이콘 클릭 → ‘YouTube 데이터’ 선택\n‘YouTube 검색 기록 포함’ 옵션 체크 해제\n필요하면 ‘검색 기록 삭제’\n  검색 기록을 삭제하면 특정 키워드 검색이 이후 추천에 영향을 주지 않아요!\n \n5️⃣ 추천 주제 필터를 활용해 원하는 영상만 보기\nYouTube 홈 화면 상단에는 내가 관심 있는 주제를 기반으로 한 필터가 표시됩니다.\n이 기능을 적극 활용하면 원하는 주제의 영상만 추천받을 수 있어요!\n\n\n \n✔ 활용법:\n상단의 주제 필터를 클릭하면 관련된 영상만 피드에 표시됨\n원하는 주제가 계속 나오도록 비슷한 주제의 영상을 여러 개 시청\n  관심 없는 주제가 계속 추천된다면?\n‘관심 없음’ 또는 ‘이 채널 추천 안 함’을 선택하세요!\n \n  YouTube 추천 피드를 정리하는 마무리 꿀팁\n✅ 시청 기록을 삭제하고 새로운 추천을 받는다\n✅ 현재 관심 있는 영상만 시청한다\n✅ 좋아요, 싫어요를 신중하게 활용한다\n✅ 검색 기록을 관리해 추천 피드에 영향을 주지 않는다\n✅ 주제 필터를 활용해 원하는 영상만 추천받는다\n \n이 방법들을 실천하면 YouTube가 내가 원하는 영상만 추천하는 최적의 플랫폼으로 변할 거예요.\n불필요한 콘텐츠에 시간 낭비하지 말고, 원하는 정보만 골라서 시청해 보세요!  \n  Q&A (자주 묻는 질문)\n1. YouTube 추천 피드를 완전히 초기화할 수 있나요?\n네! ‘시청 기록 삭제’ + ‘검색 기록 삭제’를 하면 추천 피드가 초기화됩니다. 하지만 완전히 새롭게 만들려면 이후의 시청 습관도 신경 써야 해요.\n2. 검색 기록을 남기지 않고 영상을 볼 수 있나요?\n네! ‘시청 기록 일시 중지’ 기능을 사용하면 검색해도 기록이 남지 않아요.\n3. 특정 채널의 영상이 추천되지 않도록 하는 방법은?\n영상에서 ‘이 채널 추천 안 함’을 선택하면 해당 채널의 영상이 더 이상 추천되지 않습니다.\n4. YouTube 알고리즘이 내 관심사를 파악하는 기준은?\nYouTube는 시청 기록, 검색 기록, 좋아요, 싫어요, 구독 정보, 피드백(‘관심 없음’ 선택 등)을 종합적으로 분석해서 추천을 만듭니다.\n5. 주제별 추천 필터는 어떻게 활용하면 좋나요?\n홈 화면 상단의 주제 필터를 클릭하면 특정 주제의 영상만 볼 수 있습니다. 관심 있는 주제를 여러 개 클릭하면 추천 피드가 더욱 최적화됩니다.",
        "guid": "http://muzbox.tistory.com/483549",
        "categories": [
          "유튜브,넷플릭스 사용법/유튜브(YOUTUBE) 사용법",
          "youtube 추천 알고리즘",
          "youtube 피드 정리",
          "검색 기록 관리",
          "관심 없는 영상 차단",
          "시청 기록 삭제",
          "유튜브 설정 변경",
          "유튜브 주제 필터",
          "유튜브 추천 초기화",
          "유튜브 추천 최적화",
          "좋아요 싫어요 활용"
        ],
        "isoDate": "2025-03-05T02:20:33.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "ChatGPT는 정말 공정할까? 편향된 답변 피하는 5가지 방법",
        "link": "http://muzbox.tistory.com/483548",
        "pubDate": "Tue, 4 Mar 2025 18:49:06 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483548#entry483548comment",
        "content": "<p data-ke-size=\"size16\">ChatGPT의 편향성을 최소화하는 방법이 궁금하신가요? 특정 역할을 부여하거나, 다양한 의견을 요청하는 등 균형 잡힌 답변을 얻는 방법을 알려드립니다. AI의 한계를 극복하는 스마트한 활용법을 지금 확인하세요!</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"blob\" data-origin-width=\"1280\" data-origin-height=\"722\"><span data-url=\"https://blog.kakaocdn.net/dn/bfgVFd/btsMB1qskrT/iQMascsKYLB8B0OyvCKVL1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bfgVFd/btsMB1qskrT/iQMascsKYLB8B0OyvCKVL1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bfgVFd/btsMB1qskrT/iQMascsKYLB8B0OyvCKVL1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbfgVFd%2FbtsMB1qskrT%2FiQMascsKYLB8B0OyvCKVL1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"ChatGPT는 정말 공정할까? 편향된 답변 피하는 5가지 방법\" loading=\"lazy\" width=\"1280\" height=\"722\" data-filename=\"blob\" data-origin-width=\"1280\" data-origin-height=\"722\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;AI 챗봇을 사용하다 보면 \"이거 너무 한쪽으로 치우친 답변 아닌가?\"라는 생각이 들 때가 있죠. 저도 처음엔 ChatGPT가 공정하고 객관적인 답변을 줄 거라고 믿었어요. 하지만 쓰면 쓸수록 미묘하게 편향된 답변을 주는 경우가 많다는 걸 알게 됐어요. 특히 정치, 사회 이슈나 윤리적 논란이 있는 주제에서는 더욱 그렇죠. 그렇다면 어떻게 하면 ChatGPT가 보다 균형 잡힌 답변을 하도록 유도할 수 있을까요?</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>1. ChatGPT에게 &lsquo;역할&rsquo;을 부여하기</b></span></h2>\n<blockquote data-ke-style=\"style1\"><span style=\"font-family: 'Noto Serif KR';\">  &ldquo;이제부터 너는 중립적인 컨설턴트야.&rdquo;</span></blockquote>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">가장 효과적인 방법 중 하나는 ChatGPT에게 특정한 역할을 부여하는 거예요. 예를 들면, \"너는 공정한 저널리스트야\" 혹은 \"너는 객관적인 연구 분석가야\"라고 요청하는 거죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"color: #ee2323;\"><b>  예제:</b></span><br /><b>&ldquo;너는 정치적으로 중립적인 전문가야. 특정한 이념이나 정당을 지지하지 않고, 팩트에 기반해서만 설명해줘.&rdquo;</b></p>\n<p data-ke-size=\"size16\">이렇게 역할을 정해주면 ChatGPT가 특정한 관점을 지양하고 좀 더 균형 잡힌 정보를 제공하려고 해요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>2. 더 구체적인 프롬프트 사용하기</b></span></h2>\n<p data-ke-size=\"size16\">✅ <b>\"XX에 대한 객관적인 분석을 해줘.\"</b><br />✅ <b>\"찬반 의견을 모두 포함해서 정리해줘.\"</b><br />✅ <b>\"팩트 기반의 근거를 제시해줘.\"</b></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">처음엔 저도 단순하게 \"이 주제에 대해 설명해줘\"라고만 요청했어요. 그런데 그럴 경우 ChatGPT가 제한된 정보만 제공하는 경향이 있더라고요. 그래서 더 구체적으로 요청하는 방식으로 바꿨어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"color: #ee2323;\"><b>  예제</b></span><br />❌ <b>\"기후 변화에 대해 설명해줘.\"</b><br />✔ <b>\"기후 변화에 대한 주요 과학적 연구 결과를 중립적으로 정리해줘.\"</b></p>\n<p data-ke-size=\"size16\">이렇게 하면 ChatGPT가 다양한 관점을 반영해서 답변을 구성할 가능성이 커져요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>3. 다양한 의견을 요청하기</b></span></h2>\n<blockquote data-ke-style=\"style1\"><span style=\"font-family: 'Noto Serif KR';\">\"한 가지 답변만 주지 말고, 여러 가지 시각에서 분석해줘.\"</span></blockquote>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">ChatGPT는 기본적으로 사용자가 원하는 대답을 해주려고 해요. 그렇다 보니 질문 방식이 편향되면 답변도 그에 맞춰지는 경우가 많죠. 그래서 저는 \"다른 시각에서 보면 어떨까?\"라는 질문을 자주 던져요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"color: #ee2323;\"><b>  예제:</b></span><br /><b>&ldquo;이 주제에 대한 서로 다른 학파의 입장을 3가지 이상 정리해줘.&rdquo;</b><br /><b>&ldquo;반대 의견을 가진 사람들이 어떤 근거로 주장하는지 설명해줘.&rdquo;</b></p>\n<p data-ke-size=\"size16\">이런 식으로 요청하면 ChatGPT가 한쪽으로 치우치지 않고 다양한 의견을 제공할 가능성이 높아져요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>4. \"동의하냐\"고 묻지 않기</b></span></h2>\n<blockquote data-ke-style=\"style1\"><span style=\"font-family: 'Noto Serif KR';\">\"너도 이 의견에 동의하지?\"</span></blockquote>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">라고 묻는 순간, ChatGPT는 동의하는 방향으로 답변을 만들어낼 가능성이 커요. 이건 심리학적으로도 자연스러운 반응이에요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"color: #ee2323;\"><b>  잘못된 질문</b></span><br /><b>&ldquo;이 이론이 맞다고 생각해?&rdquo;</b><br />  동의하는 방향으로 답변을 생성할 확률이 높음</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"color: #ee2323;\"><b>✅ 올바른 질문</b></span><br /><b>&ldquo;이 이론을 반대하는 학자들의 근거는 무엇이야?&rdquo;</b><br />  반대 의견까지 포함된 균형 잡힌 답변을 받을 확률이 높음</p>\n<p data-ke-size=\"size16\">이처럼 질문하는 방식만 바꿔도 답변의 질이 확 달라져요!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>5. ChatGPT 설정을 커스터마이징하기</b></span></h2>\n<p data-ke-size=\"size16\">ChatGPT를 사용할 때, 프로필 아이콘을 클릭하면 <b>\"Customize ChatGPT\"</b> 옵션이 있어요. 여기에서 답변 스타일을 조정할 수 있어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">✔ <b>\"정치적으로 중립적인 답변을 원합니다.\"</b><br />✔ <b>\"객관적이고 공정한 분석을 제공해 주세요.\"</b></p>\n<p data-ke-size=\"size16\">이런 식으로 설정을 조정하면 AI가 좀 더 균형 잡힌 답변을 하도록 유도할 수 있어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b><span style=\"color: #009a87;\">결론: AI는 도구일 뿐, 우리가 스마트하게 활용해야 한다</span></b></h2>\n<p data-ke-size=\"size16\">ChatGPT는 완벽한 도구가 아니에요. 여전히 편향된 데이터로 학습될 수도 있고, 사용자 질문 방식에 따라 답변이 왜곡될 수도 있어요. 하지만 위의 방법들을 활용하면 보다 객관적이고 균형 잡힌 답변을 얻을 수 있어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">✔ ChatGPT에게 역할을 부여하기<br />✔ 더 구체적인 질문하기<br />✔ 다양한 시각을 요청하기<br />✔ \"동의하냐?\"는 질문을 피하기<br />✔ 설정을 커스터마이징하기</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 다섯 가지만 기억해도 훨씬 더 좋은 답변을 얻을 수 있을 거예요! 여러분은 AI를 사용할 때 어떤 방법을 활용하시나요? 댓글로 경험을 공유해 주세요  </p>\n<hr data-ke-style=\"style1\" />\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>  Q&amp;A</b></span></h2>\n<p data-ke-size=\"size16\"><b>1. ChatGPT는 왜 편향된 답변을 할까요?</b></p>\n<p data-ke-size=\"size16\">ChatGPT는 인터넷의 방대한 데이터를 학습했기 때문에 원천 데이터가 편향적이라면 답변도 영향을 받을 수 있어요. 또한, 사용자의 질문 방식에 따라 특정한 방향으로 답변이 조정될 수도 있어요.</p>\n<p data-ke-size=\"size16\"><b>2. ChatGPT의 답변이 공정한지 확인하는 방법은?</b></p>\n<p data-ke-size=\"size16\">하나의 답변만 믿지 말고, 같은 질문을 다르게 표현해서 여러 번 요청해보세요. 또한, 다른 정보 출처와 비교하는 것도 중요해요.</p>\n<p data-ke-size=\"size16\"><b>3. AI의 편향성을 최소화하는 가장 효과적인 방법은?</b></p>\n<p data-ke-size=\"size16\">AI에게 특정한 역할을 부여하거나, 반대 의견을 요청하는 방식이 가장 효과적이에요.</p>\n<p data-ke-size=\"size16\"><b>4. ChatGPT를 설정에서 중립적으로 만들 수 있나요?</b></p>\n<p data-ke-size=\"size16\">네! \"Customize ChatGPT\" 기능을 활용하면 원하는 답변 스타일을 설정할 수 있어요.</p>\n<p data-ke-size=\"size16\"><b>5. ChatGPT가 제공하는 정보를 100% 신뢰해도 될까요?</b></p>\n<p data-ke-size=\"size16\">아니요! AI는 참고용으로만 사용하고, 중요한 결정은 반드시 다른 신뢰할 만한 정보와 함께 고려해야 해요.</p>\n<script type=\"application/ld+json\">\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"ChatGPT는 왜 편향된 답변을 할까요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"ChatGPT는 인터넷의 방대한 데이터를 학습했기 때문에 원천 데이터가 편향적이라면 답변도 영향을 받을 수 있어요. 또한, 사용자의 질문 방식에 따라 특정한 방향으로 답변이 조정될 수도 있어요.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"ChatGPT의 답변이 공정한지 확인하는 방법은?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"하나의 답변만 믿지 말고, 같은 질문을 다르게 표현해서 여러 번 요청해보세요. 또한, 다른 정보 출처와 비교하는 것도 중요해요.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"AI의 편향성을 최소화하는 가장 효과적인 방법은?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"AI에게 특정한 역할을 부여하거나, 반대 의견을 요청하는 방식이 가장 효과적이에요.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"ChatGPT를 설정에서 중립적으로 만들 수 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"네! 'Customize ChatGPT' 기능을 활용하면 원하는 답변 스타일을 설정할 수 있어요.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"ChatGPT가 제공하는 정보를 100% 신뢰해도 될까요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"아니요! AI는 참고용으로만 사용하고, 중요한 결정은 반드시 다른 신뢰할 만한 정보와 함께 고려해야 해요.\"\n      }\n    }\n  ]\n}\n</script>",
        "contentSnippet": "ChatGPT의 편향성을 최소화하는 방법이 궁금하신가요? 특정 역할을 부여하거나, 다양한 의견을 요청하는 등 균형 잡힌 답변을 얻는 방법을 알려드립니다. AI의 한계를 극복하는 스마트한 활용법을 지금 확인하세요!\n\n\n \n AI 챗봇을 사용하다 보면 \"이거 너무 한쪽으로 치우친 답변 아닌가?\"라는 생각이 들 때가 있죠. 저도 처음엔 ChatGPT가 공정하고 객관적인 답변을 줄 거라고 믿었어요. 하지만 쓰면 쓸수록 미묘하게 편향된 답변을 주는 경우가 많다는 걸 알게 됐어요. 특히 정치, 사회 이슈나 윤리적 논란이 있는 주제에서는 더욱 그렇죠. 그렇다면 어떻게 하면 ChatGPT가 보다 균형 잡힌 답변을 하도록 유도할 수 있을까요?\n \n \n1. ChatGPT에게 ‘역할’을 부여하기\n  “이제부터 너는 중립적인 컨설턴트야.”\n \n가장 효과적인 방법 중 하나는 ChatGPT에게 특정한 역할을 부여하는 거예요. 예를 들면, \"너는 공정한 저널리스트야\" 혹은 \"너는 객관적인 연구 분석가야\"라고 요청하는 거죠.\n \n  예제:\n“너는 정치적으로 중립적인 전문가야. 특정한 이념이나 정당을 지지하지 않고, 팩트에 기반해서만 설명해줘.”\n이렇게 역할을 정해주면 ChatGPT가 특정한 관점을 지양하고 좀 더 균형 잡힌 정보를 제공하려고 해요.\n \n \n \n2. 더 구체적인 프롬프트 사용하기\n✅ \"XX에 대한 객관적인 분석을 해줘.\"\n✅ \"찬반 의견을 모두 포함해서 정리해줘.\"\n✅ \"팩트 기반의 근거를 제시해줘.\"\n \n처음엔 저도 단순하게 \"이 주제에 대해 설명해줘\"라고만 요청했어요. 그런데 그럴 경우 ChatGPT가 제한된 정보만 제공하는 경향이 있더라고요. 그래서 더 구체적으로 요청하는 방식으로 바꿨어요.\n \n  예제\n❌ \"기후 변화에 대해 설명해줘.\"\n✔ \"기후 변화에 대한 주요 과학적 연구 결과를 중립적으로 정리해줘.\"\n이렇게 하면 ChatGPT가 다양한 관점을 반영해서 답변을 구성할 가능성이 커져요.\n \n \n \n3. 다양한 의견을 요청하기\n\"한 가지 답변만 주지 말고, 여러 가지 시각에서 분석해줘.\"\n \nChatGPT는 기본적으로 사용자가 원하는 대답을 해주려고 해요. 그렇다 보니 질문 방식이 편향되면 답변도 그에 맞춰지는 경우가 많죠. 그래서 저는 \"다른 시각에서 보면 어떨까?\"라는 질문을 자주 던져요.\n \n  예제:\n“이 주제에 대한 서로 다른 학파의 입장을 3가지 이상 정리해줘.”\n“반대 의견을 가진 사람들이 어떤 근거로 주장하는지 설명해줘.”\n이런 식으로 요청하면 ChatGPT가 한쪽으로 치우치지 않고 다양한 의견을 제공할 가능성이 높아져요.\n \n \n \n4. \"동의하냐\"고 묻지 않기\n\"너도 이 의견에 동의하지?\"\n \n라고 묻는 순간, ChatGPT는 동의하는 방향으로 답변을 만들어낼 가능성이 커요. 이건 심리학적으로도 자연스러운 반응이에요.\n \n  잘못된 질문\n“이 이론이 맞다고 생각해?”\n  동의하는 방향으로 답변을 생성할 확률이 높음\n \n✅ 올바른 질문\n“이 이론을 반대하는 학자들의 근거는 무엇이야?”\n  반대 의견까지 포함된 균형 잡힌 답변을 받을 확률이 높음\n이처럼 질문하는 방식만 바꿔도 답변의 질이 확 달라져요!\n \n \n \n5. ChatGPT 설정을 커스터마이징하기\nChatGPT를 사용할 때, 프로필 아이콘을 클릭하면 \"Customize ChatGPT\" 옵션이 있어요. 여기에서 답변 스타일을 조정할 수 있어요.\n \n✔ \"정치적으로 중립적인 답변을 원합니다.\"\n✔ \"객관적이고 공정한 분석을 제공해 주세요.\"\n이런 식으로 설정을 조정하면 AI가 좀 더 균형 잡힌 답변을 하도록 유도할 수 있어요.\n \n \n결론: AI는 도구일 뿐, 우리가 스마트하게 활용해야 한다\nChatGPT는 완벽한 도구가 아니에요. 여전히 편향된 데이터로 학습될 수도 있고, 사용자 질문 방식에 따라 답변이 왜곡될 수도 있어요. 하지만 위의 방법들을 활용하면 보다 객관적이고 균형 잡힌 답변을 얻을 수 있어요.\n \n✔ ChatGPT에게 역할을 부여하기\n✔ 더 구체적인 질문하기\n✔ 다양한 시각을 요청하기\n✔ \"동의하냐?\"는 질문을 피하기\n✔ 설정을 커스터마이징하기\n \n이 다섯 가지만 기억해도 훨씬 더 좋은 답변을 얻을 수 있을 거예요! 여러분은 AI를 사용할 때 어떤 방법을 활용하시나요? 댓글로 경험을 공유해 주세요  \n  Q&A\n1. ChatGPT는 왜 편향된 답변을 할까요?\nChatGPT는 인터넷의 방대한 데이터를 학습했기 때문에 원천 데이터가 편향적이라면 답변도 영향을 받을 수 있어요. 또한, 사용자의 질문 방식에 따라 특정한 방향으로 답변이 조정될 수도 있어요.\n2. ChatGPT의 답변이 공정한지 확인하는 방법은?\n하나의 답변만 믿지 말고, 같은 질문을 다르게 표현해서 여러 번 요청해보세요. 또한, 다른 정보 출처와 비교하는 것도 중요해요.\n3. AI의 편향성을 최소화하는 가장 효과적인 방법은?\nAI에게 특정한 역할을 부여하거나, 반대 의견을 요청하는 방식이 가장 효과적이에요.\n4. ChatGPT를 설정에서 중립적으로 만들 수 있나요?\n네! \"Customize ChatGPT\" 기능을 활용하면 원하는 답변 스타일을 설정할 수 있어요.\n5. ChatGPT가 제공하는 정보를 100% 신뢰해도 될까요?\n아니요! AI는 참고용으로만 사용하고, 중요한 결정은 반드시 다른 신뢰할 만한 정보와 함께 고려해야 해요.\n\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"ChatGPT는 왜 편향된 답변을 할까요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"ChatGPT는 인터넷의 방대한 데이터를 학습했기 때문에 원천 데이터가 편향적이라면 답변도 영향을 받을 수 있어요. 또한, 사용자의 질문 방식에 따라 특정한 방향으로 답변이 조정될 수도 있어요.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"ChatGPT의 답변이 공정한지 확인하는 방법은?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"하나의 답변만 믿지 말고, 같은 질문을 다르게 표현해서 여러 번 요청해보세요. 또한, 다른 정보 출처와 비교하는 것도 중요해요.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"AI의 편향성을 최소화하는 가장 효과적인 방법은?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"AI에게 특정한 역할을 부여하거나, 반대 의견을 요청하는 방식이 가장 효과적이에요.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"ChatGPT를 설정에서 중립적으로 만들 수 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"네! 'Customize ChatGPT' 기능을 활용하면 원하는 답변 스타일을 설정할 수 있어요.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"ChatGPT가 제공하는 정보를 100% 신뢰해도 될까요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"아니요! AI는 참고용으로만 사용하고, 중요한 결정은 반드시 다른 신뢰할 만한 정보와 함께 고려해야 해요.\"\n      }\n    }\n  ]\n}",
        "guid": "http://muzbox.tistory.com/483548",
        "categories": [
          "AI, 미래기술/채팅",
          "ai 답변 조정",
          "ai 신뢰성",
          "AI 편향성",
          "ai 프롬프트",
          "AI 활용법",
          "ai와 정보 검증",
          "chatgpt 설정",
          "hatgpt",
          "공정한 답변",
          "중립적 ai"
        ],
        "isoDate": "2025-03-04T09:49:06.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "｜RULIWEB｜",
        "title": "무쌍영걸들로 명토를 휩쓸어라! 무쌍:어비스",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2290",
        "pubDate": "Thu, 06 Mar 2025 23:18:24 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i1.ruliweb.com/thumb/25/03/06/1956bd0743851ad6b.jpg\">",
        "contentSnippet": "",
        "categories": [
          "게임툰"
        ],
        "isoDate": "2025-03-06T14:18:24.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": [
      {
        "title": "Visual Studio 17.12의 디버거 및 진단 업데이트",
        "link": "https://jacking75.github.io/VS_20250309/",
        "pubDate": "Sun, 09 Mar 2025 00:00:00 +0900",
        "content": "<iframe width=\"1024\" height=\"1024\" src=\"https://docs.google.com/document/d/e/2PACX-1vS2IR5s6JtRpV--n0Qn6eGHM293HtF40_iURlk1U-kBk6J0omhtVyrtw-QDs56747C4XRwDXUGcDsaS/pub?embedded=true\"></iframe>\n\n",
        "contentSnippet": "",
        "guid": "https://jacking75.github.io/VS_20250309/",
        "isoDate": "2025-03-08T15:00:00.000Z"
      },
      {
        "title": "Visual Studio v17.12 로 생산성을 높이기",
        "link": "https://jacking75.github.io/VS_20250307/",
        "pubDate": "Fri, 07 Mar 2025 00:00:00 +0900",
        "content": "<iframe width=\"1024\" height=\"1024\" src=\"https://docs.google.com/document/d/e/2PACX-1vSd0AKAZlpycgmuQNdjInFQTuFAjEky61Wvw4o4tAWy1YKOBPSuXJ-ggvYr6mghE8VOQcXg8vVNotji/pub?embedded=true\"></iframe>\n\n",
        "contentSnippet": "",
        "guid": "https://jacking75.github.io/VS_20250307/",
        "isoDate": "2025-03-06T15:00:00.000Z"
      },
      {
        "title": "NotebookLM을 이용한 AI 활용 - 기술 자료 분석",
        "link": "https://jacking75.github.io/tech-ai_20250304/",
        "pubDate": "Tue, 04 Mar 2025 00:00:00 +0900",
        "content": "<iframe width=\"1024\" height=\"1024\" src=\"https://docs.google.com/document/d/e/2PACX-1vQX9B27qcuEN-EoU4AMLJso1YazqPvmvFMZzyXFnEb3X7FUYvYAzPtDANR7Y6ajdg6byfunqRYfFps7/pub?embedded=true\"></iframe>\n\n",
        "contentSnippet": "",
        "guid": "https://jacking75.github.io/tech-ai_20250304/",
        "isoDate": "2025-03-03T15:00:00.000Z"
      }
    ]
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": [
      {
        "title": "지각하지 않던 사람들",
        "link": "https://jeho.page/essay/2025/03/06/time-to-work.html",
        "pubDate": "2025-03-06T02:54:00.000Z",
        "author": "김재호",
        "content": "<p>딸을 학교에 보내고 돌아오며 저의 학창 시절이 떠올랐습니다.<br />\n일어나기 싫어서 이불 속에서 버티다가 결국에 후루룩 씻고 교복을 입고 눈뜬 지 10분 만에 튀어나가던 아침의 일상. 항상 아슬아슬하게 시간에 쫓겨 다녔고 지각을 하는 날도 많았습니다.<br />\n이런 습관은 회사에 가서도 똑같이 이어졌습니다.</p>\n\n<p>인생을 더 살면서 사소해 보이는 작은 약속을 잘 지키는 것이 얼마나 중요한지 깨닫게 되었습니다.<br />\n아내가 세상에서 제일 멋져 보였던 순간은 동네 미용실에 데려다주던 어느 날이었습니다.<br />\n1~2분 정도 늦을 것 같아 미용실에 전화를 하는 아내를 보며 뭐 저런 걸로 전화를 하나 생각했습니다.<br />\n심지어 미용실에서도 놀라는 눈치였습니다. 1~2분 늦는다고 이렇게 미안해하며 전화를 주다니. 흔한 노쇼 전화일꺼라 생각했을지도요.</p>\n\n<p>어쩌면 아내의 이런 모습들이 저에게 좋은 영향을 끼친 것 아닐까?<br />\n이후로 저도 약속 시간을 잘 지키기 위해 노력했습니다.<br />\n친구들 모임에 갈 때도, 음식점 예약 시간에 맞출 때도, 동네 미용실에 갈 때도.</p>\n\n<p>그럼에도 불구하고 최근 몇 년 간 약속 시간에 늦은 적이 몇 번 있음을 고백합니다.<br />\n저희 집 앞 커피숍에서 만나기로 한 손님을 잠자느라 완전히 바람 맞춘 충격적인 날도 있었습니다. ㅠㅠ<br />\n(다음 날 제가 찾아가서 석고대죄하고 즐거운 이야기를 나눴습니다. 이후로 다시는 아침 일찍 약속을 잡지 않습니다. ㅋㅋ)</p>\n\n<p>다시 회사에 간다면 걱정되는 한 가지는 바로 이 출근 시간입니다.<br />\n내가 이제는 과연 출근 시간을 잘 지킬 수 있을 것인가?<br />\n회사로 돌아갈 생각을 안 하는 건 이 출근 시간 탓도 큰 것 같습니다. 도저히 자신이 없어서.</p>\n\n<p>한 편으로 몇 년 동안 한 번도 지각하지 않던 동료들도 떠오릅니다.<br />\n어떤 회사는 지각을 엄격하게 체크하여 상벌을 줬고 어떤 회사는 전혀 그렇지 않았습니다.<br />\n상벌이 있던 회사에서 개근을 하던 사람들도 물론 대단합니다만, 모두가 근태 개판이던(카카오 초창기 시절) 회사에서 홀로 자리를 지키던 사람들이 특히나 떠오릅니다.<br />\n남들이야 어찌하든 나는 나와의 약속을 지킨다라는 것이었을까요? 정말 멋지고 존경스럽습니다.</p>\n\n<p><br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2022/09/02/the-happiest-way-to-work.html\">가장 행복했던 출근길</a></li>\n  <li><a href=\"/essay/2021/10/03/출근길의-강제-독서.html\">출근길의 강제 독서</a></li>\n</ul>",
        "contentSnippet": "딸을 학교에 보내고 돌아오며 저의 학창 시절이 떠올랐습니다.\n인생을 더 살면서 사소해 보이는 작은 약속을 잘 지키는 것이 얼마나 중요한지 깨닫게 되었습니다.\n어쩌면 아내의 이런 모습들이 저에게 좋은 영향을 끼친 것 아닐까?\n그럼에도 불구하고 최근 몇 년 간 약속 시간에 늦은 적이 몇 번 있음을 고백합니다.\n다시 회사에 간다면 걱정되는 한 가지는 바로 이 출근 시간입니다.\n한 편으로 몇 년 동안 한 번도 지각하지 않던 동료들도 떠오릅니다.\n\n함께 읽으면 좋은 글:\n가장 행복했던 출근길\n출근길의 강제 독서",
        "summary": "딸을 학교에 보내고 돌아오며 저의 학창 시절이 떠올랐습니다. 일어나기 싫어서 이불 속에서 버티다가 결국에 후루룩 씻고 교복을 입고 눈뜬 지 10분 만에 튀어나가던 아침의 일상. 항상 아슬아슬하게 시간에 쫓겨 다녔고 지각을 하는 날도 많았습니다. 이런 습관은 회사에 가서도 똑같이 이어졌습니다.",
        "id": "https://jeho.page/essay/2025/03/06/time-to-work",
        "isoDate": "2025-03-06T02:54:00.000Z"
      }
    ]
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "BGM - #Electronic || Pers&eacute;phone - Retro Funky (SUNDANCE Remix)",
        "link": "http://serverdown.tistory.com/1177",
        "pubDate": "Sun, 9 Mar 2025 18:40:27 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1177#entry1177comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=0-c7kXpRVIQ\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=0-c7kXpRVIQ</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=0-c7kXpRVIQ\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bcQ0VS/hyYm0nGiUp/mPnbB7BAkqGPKDIzuKhLk0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/blaWry/hyYm7mN0nP/5AX95aZWRtvg9Szpq0nKcK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"#Electronic || Pers&eacute;phone - Retro Funky (SUNDANCE Remix)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/0-c7kXpRVIQ\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">신나네요</p>\n<p data-ke-size=\"size16\">저작권이 없는건 아니라 짧게 부분적으로 쓰는거 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상1 : <a href=\"https://www.youtube.com/watch?v=IUX4b5SJEl0&amp;lc=UgysBKrwVxP1SwOfMkZ4AaABAg.AFRZzf60md0AFRjy5KKLY1\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=IUX4b5SJEl0&amp;lc=UgysBKrwVxP1SwOfMkZ4AaABAg.AFRZzf60md0AFRjy5KKLY1</a></p>\n<p data-ke-size=\"size16\">초반에 엄청 짧게 사용되네요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=0-c7kXpRVIQ\n\n\n\n신나네요\n저작권이 없는건 아니라 짧게 부분적으로 쓰는거 같습니다.\n \n영상1 : https://www.youtube.com/watch?v=IUX4b5SJEl0&lc=UgysBKrwVxP1SwOfMkZ4AaABAg.AFRZzf60md0AFRjy5KKLY1\n초반에 엄청 짧게 사용되네요",
        "guid": "http://serverdown.tistory.com/1177",
        "isoDate": "2025-03-09T09:40:27.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "죄도 병으로 만들면 된다. / 도벽증 / 둔주 해리성 기억장애",
        "link": "http://serverdown.tistory.com/1176",
        "pubDate": "Sun, 9 Mar 2025 14:29:26 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1176#entry1176comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=dmVYhc_w_ew\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=dmVYhc_w_ew</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=dmVYhc_w_ew\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/wjKpu/hyYm5oVRoW/8ovuXrjk89iHKRcpVhTH30/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/bLthxs/hyYm7NOrdn/FmGwqFhpNpgpAQT2Z0ZnKK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"19세기 돈 많은 여자들의 은밀한 취미생활｜시대가 만든 유행병\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/dmVYhc_w_ew\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">어느시대엔 죄가 되고 어느 시대엔 죄가 안되고</p>\n<p data-ke-size=\"size16\">미국도 한때 천달라 이하의 절도는 죄가 안되는 벙이 있었고</p>\n<p data-ke-size=\"size16\">한국은 군대에 가지 않기 위해 장애 판정을 받기도 했습니다.</p>\n<p data-ke-size=\"size16\">돈이 있는 사람에게는 죄도 죄가 아니게 할 수 있었던 적도 있었습니다.</p>\n<p data-ke-size=\"size16\">시대의 흐름을 안보고 관념에 사로잡혀있으면 안된다는 것을 말하고 싶었습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=dmVYhc_w_ew\n\n\n\n어느시대엔 죄가 되고 어느 시대엔 죄가 안되고\n미국도 한때 천달라 이하의 절도는 죄가 안되는 벙이 있었고\n한국은 군대에 가지 않기 위해 장애 판정을 받기도 했습니다.\n돈이 있는 사람에게는 죄도 죄가 아니게 할 수 있었던 적도 있었습니다.\n시대의 흐름을 안보고 관념에 사로잡혀있으면 안된다는 것을 말하고 싶었습니다.",
        "guid": "http://serverdown.tistory.com/1176",
        "categories": [
          "시대"
        ],
        "isoDate": "2025-03-09T05:29:26.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "들리는데로 적어본다. / 몬더그린 현상",
        "link": "http://serverdown.tistory.com/1175",
        "pubDate": "Sat, 8 Mar 2025 14:31:07 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1175#entry1175comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=tcBLqdJbXBA\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=tcBLqdJbXBA</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=tcBLqdJbXBA\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/dWABYY/hyYm9xWbkK/igfBVic6ch6kxoGZBnZqN0/img.jpg?width=480&amp;height=360&amp;face=233_132_259_160,https://scrap.kakaocdn.net/dn/Vw21A/hyYmQLWmXo/TkG9pTCNxTQwPD18bnzCJ0/img.jpg?width=480&amp;height=360&amp;face=233_132_259_160\" data-video-width=\"480\" data-video-height=\"360\" data-video-origin-width=\"480\" data-video-origin-height=\"360\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"엌ㅋㅋㅋㅋ 절묘하게 한국어처럼 들리는 영화 속 외국 대사들 ㅋㅋㅋㅋㅋㅋㅋㅋㅋ\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/tcBLqdJbXBA\" width=\"480\" height=\"360\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">다 연결되어있다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=tcBLqdJbXBA\n\n\n\n다 연결되어있다.",
        "guid": "http://serverdown.tistory.com/1175",
        "categories": [
          "유튜브",
          "영화"
        ],
        "isoDate": "2025-03-08T05:31:07.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "지나보고 알게되는 팔란티어가 하는일 /PLTR",
        "link": "http://serverdown.tistory.com/1174",
        "pubDate": "Fri, 7 Mar 2025 23:39:45 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1174#entry1174comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=w2c1XclG4U0\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=w2c1XclG4U0</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=w2c1XclG4U0\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bwxPeY/hyYm9xRaVv/zKpKgcsQSRzuiLlaI1MgHK/img.jpg?width=1280&amp;height=720&amp;face=304_62_534_312,https://scrap.kakaocdn.net/dn/itx6g/hyYm5IWJ3E/ykRMudW951wgAGs54zZkRk/img.jpg?width=1280&amp;height=720&amp;face=304_62_534_312\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"팔란티어가 본 미래는? AI 방산 기업의 위험한 질주 / 오그랲 / 비디오머그\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/w2c1XclG4U0\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">AI 의 발전사항과 시대흐름&nbsp;</p>\n<p data-ke-size=\"size16\">팔란티어가 한일을 잘 알려줍니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=w2c1XclG4U0\n\n\n\nAI 의 발전사항과 시대흐름 \n팔란티어가 한일을 잘 알려줍니다.",
        "guid": "http://serverdown.tistory.com/1174",
        "categories": [
          "투자",
          "PLTR",
          "팔란티어"
        ],
        "isoDate": "2025-03-07T14:39:45.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "방향이 바겼다. 미국 주식은 안된다. / 중국 유럽 주식 / 미국 채권 / 2025-03-07",
        "link": "http://serverdown.tistory.com/1173",
        "pubDate": "Fri, 7 Mar 2025 17:56:24 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1173#entry1173comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=vsSWm_-PnqM\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=vsSWm_-PnqM</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=vsSWm_-PnqM\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/ciL4fa/hyYqbnoqiA/9G2wY1qOlT61sOsjoG9G20/img.jpg?width=1280&amp;height=720&amp;face=240_208_1016_362,https://scrap.kakaocdn.net/dn/bWWfZK/hyYncuwSOK/gNY4b9YgHGQ3XkxrJ6hZkk/img.jpg?width=1280&amp;height=720&amp;face=240_208_1016_362\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"[마켓진단] 불안한 美 증시, 韓∙中∙EU 주목할 때  /김유성 유니스토리자산운용 전무 / 김치형 앵\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/vsSWm_-PnqM\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">18분에 나오는 스샷</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"923\" data-origin-height=\"572\"><span data-url=\"https://blog.kakaocdn.net/dn/Bma5q/btsMEEvLSwC/iCS1kAB82gBnCc8MUGSWc1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Bma5q/btsMEEvLSwC/iCS1kAB82gBnCc8MUGSWc1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/Bma5q/btsMEEvLSwC/iCS1kAB82gBnCc8MUGSWc1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FBma5q%2FbtsMEEvLSwC%2FiCS1kAB82gBnCc8MUGSWc1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"923\" height=\"572\" data-origin-width=\"923\" data-origin-height=\"572\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">요약</p>\n<p data-ke-size=\"size16\">미국 주식도 안좋고 달러도 안좋습니다.&nbsp;</p>\n<p data-ke-size=\"size16\">금 / 유럼 + 중국 주식 / 미국 채권은 좋습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">TIGER&nbsp;차이나항셍테크</p>\n<p data-ke-size=\"size16\">KIWOOM&nbsp;차이나내수소비TOP&nbsp;CSI</p>\n<p data-ke-size=\"size16\">에셋플러스&nbsp;차이나일등기업포커스10액티브</p>\n<p data-ke-size=\"size16\">Kodex&nbsp;미국30년국채액티브(H)</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=vsSWm_-PnqM\n\n\n\n18분에 나오는 스샷\n\n\n \n요약\n미국 주식도 안좋고 달러도 안좋습니다. \n금 / 유럼 + 중국 주식 / 미국 채권은 좋습니다.\n \nTIGER 차이나항셍테크\nKIWOOM 차이나내수소비TOP CSI\n에셋플러스 차이나일등기업포커스10액티브\nKodex 미국30년국채액티브(H)",
        "guid": "http://serverdown.tistory.com/1173",
        "categories": [
          "투자"
        ],
        "isoDate": "2025-03-07T08:56:24.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "유니티 6 캔버스 셰이더 깜박이기 / Unity 6 Canvas Shader",
        "link": "http://serverdown.tistory.com/1172",
        "pubDate": "Fri, 7 Mar 2025 15:32:30 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1172#entry1172comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"canvas_blink.gif\" data-origin-width=\"328\" data-origin-height=\"240\"><span data-url=\"https://blog.kakaocdn.net/dn/bu5V7d/btsMEpL4qZx/mYDUUfnyHdhSDdeCPoNrfk/img.gif\" data-phocus=\"https://blog.kakaocdn.net/dn/bu5V7d/btsMEpL4qZx/mYDUUfnyHdhSDdeCPoNrfk/img.gif\"><img src=\"https://blog.kakaocdn.net/dn/bu5V7d/btsMEpL4qZx/mYDUUfnyHdhSDdeCPoNrfk/img.gif\" srcset=\"https://blog.kakaocdn.net/dn/bu5V7d/btsMEpL4qZx/mYDUUfnyHdhSDdeCPoNrfk/img.gif\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"328\" height=\"240\" data-filename=\"canvas_blink.gif\" data-origin-width=\"328\" data-origin-height=\"240\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">빨간 사격형이 깜박이는 작업이다.</p>\n<p data-ke-size=\"size16\">셰이더작업은 메뉴가 버전마다 달라서 어디는지 찾다보니 기록을 남겨둔다.</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=VuibGcamE5E&amp;t=45s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=VuibGcamE5E&amp;t=45s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=VuibGcamE5E\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bvsGZ3/hyYmZu9iUB/d2bKjArACroI4gtup0d8H1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/TSnRX/hyYm9xMhtK/NFCy2GMGMG0PdxZiXg1s1K/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"유니티 공식 UI 셰이더: UGUI 캔버스 셰이더\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/VuibGcamE5E\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">이분 영상은 유니티 2023 버전이였다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">1. UI -&gt; Canvas 로 캔버스 만듭니다.</p>\n<p data-ke-size=\"size16\">2. UI -&gt; Image 로 사각형 만듭니다.</p>\n<p data-ke-size=\"size16\">3. 파일쪽에서 우클릭 create -&gt; Shader Graph -&gt; Spirte Unlit ~~ 셰이더 그래프 만듭니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1091\" data-origin-height=\"565\"><span data-url=\"https://blog.kakaocdn.net/dn/dH450U/btsMER87KDO/7Ek7viFh1LgIGq6kNNRsf1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dH450U/btsMER87KDO/7Ek7viFh1LgIGq6kNNRsf1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dH450U/btsMER87KDO/7Ek7viFh1LgIGq6kNNRsf1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdH450U%2FbtsMER87KDO%2F7Ek7viFh1LgIGq6kNNRsf1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1091\" height=\"565\" data-origin-width=\"1091\" data-origin-height=\"565\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">멀리도 있다.</p>\n<p data-ke-size=\"size16\">4. 더블클릭해서 Shader Graph 엽니다.</p>\n<p data-ke-size=\"size16\">5.Fragment 클릭</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"344\" data-origin-height=\"302\"><span data-url=\"https://blog.kakaocdn.net/dn/bTIVXi/btsMD2Kitp3/EbCQVwkeku6Ks4fsYOGPAk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bTIVXi/btsMD2Kitp3/EbCQVwkeku6Ks4fsYOGPAk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bTIVXi/btsMD2Kitp3/EbCQVwkeku6Ks4fsYOGPAk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbTIVXi%2FbtsMD2Kitp3%2FEbCQVwkeku6Ks4fsYOGPAk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"344\" height=\"302\" data-origin-width=\"344\" data-origin-height=\"302\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">6. 우측 상단에 떠있는 UI 인데 그림따라 가서 Canvas 로 바꾼다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"443\" data-origin-height=\"454\"><span data-url=\"https://blog.kakaocdn.net/dn/Cuvjg/btsMES71NbU/CW9ENF4UhuZRkS7HSL2A0K/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Cuvjg/btsMES71NbU/CW9ENF4UhuZRkS7HSL2A0K/img.png\"><img src=\"https://blog.kakaocdn.net/dn/Cuvjg/btsMES71NbU/CW9ENF4UhuZRkS7HSL2A0K/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FCuvjg%2FbtsMES71NbU%2FCW9ENF4UhuZRkS7HSL2A0K%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"443\" height=\"454\" data-origin-width=\"443\" data-origin-height=\"454\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">여기까지해야 alpha 가 정상적으로 먹히는 캔버스 셰이더가 동작합니다.</p>\n<p data-ke-size=\"size16\">7. 셰이더 그래프 만들기</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"599\" data-origin-height=\"411\"><span data-url=\"https://blog.kakaocdn.net/dn/KwwcW/btsMDQQSo8m/X7yOPVCJ3kDkuZ4Gobw45K/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/KwwcW/btsMDQQSo8m/X7yOPVCJ3kDkuZ4Gobw45K/img.png\"><img src=\"https://blog.kakaocdn.net/dn/KwwcW/btsMDQQSo8m/X7yOPVCJ3kDkuZ4Gobw45K/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FKwwcW%2FbtsMDQQSo8m%2FX7yOPVCJ3kDkuZ4Gobw45K%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"599\" height=\"411\" data-origin-width=\"599\" data-origin-height=\"411\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">Color 는 빨간색 그대로 박아넣었고</p>\n<p data-ke-size=\"size16\">Alpha 는 Time&nbsp; 의 sine time 을 이용해 1 ~ -1 왔다갔다 하는 값을 넣었다.&nbsp;<br />0 ~ -1 부분은 다 0 이 되기 때문에 안보이는 시간이 좀 길더라 Absolute 를 넣으면 1 ~ 0 값으로 바꿔준다.<br />(영상에선 그걸 사용함)</p>\n<p data-ke-size=\"size16\">좌측 상단에 디스켓 아이콘을 눌러 저장한다.<br />(요즘 사람은 디스켓이 뭔지 모른다더라.)</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"213\" data-origin-height=\"181\"><span data-url=\"https://blog.kakaocdn.net/dn/7wi4j/btsMDPdk37Q/iRTtbjHeBoc2dblNxpm8b0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/7wi4j/btsMDPdk37Q/iRTtbjHeBoc2dblNxpm8b0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/7wi4j/btsMDPdk37Q/iRTtbjHeBoc2dblNxpm8b0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F7wi4j%2FbtsMDPdk37Q%2FiRTtbjHeBoc2dblNxpm8b0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"213\" height=\"181\" data-origin-width=\"213\" data-origin-height=\"181\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">이렇게 생긴 아이콘이 디스켓 이다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">8. 캔버스의 이미지에 셰이더를 박는다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"913\" data-origin-height=\"514\"><span data-url=\"https://blog.kakaocdn.net/dn/lBrAl/btsMECLbAax/balcNFidBgaXn9T9jBv3hk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/lBrAl/btsMECLbAax/balcNFidBgaXn9T9jBv3hk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/lBrAl/btsMECLbAax/balcNFidBgaXn9T9jBv3hk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FlBrAl%2FbtsMECLbAax%2FbalcNFidBgaXn9T9jBv3hk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"913\" height=\"514\" data-origin-width=\"913\" data-origin-height=\"514\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">내 프로젝트 기준으로 스샷을 찍은거니 각자 알아서 잘 찾아 넣는다.</p>\n<p data-ke-size=\"size16\">Material 부분에 Shader 를 넣어도 되니 편리했다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">셰이더는 어려운 분야라서 UI 에 익숙해지는게 좋을것 같아 일부러 스샷을 많이 남겼다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">추가작업</h2>\n<p data-ke-size=\"size16\">FS_Blink_shader.zip 파일 링크 : <a href=\"https://drive.google.com/file/d/1aEqv4z_f76fntUDX60DnCDY057BDLWfV/view?usp=drive_link\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://drive.google.com/file/d/1aEqv4z_f76fntUDX60DnCDY057BDLWfV/view?usp=drive_link</a></p>\n<p data-ke-size=\"size16\">위에서 만든 셰이더는 색깔이 깜박거리는 것이라 쓸모가 없습니다.</p>\n<p data-ke-size=\"size16\">이 셰이더는 텍스처를 포함한 UI 를 깜박히게 합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"tex_blink.gif\" data-origin-width=\"544\" data-origin-height=\"306\"><span data-url=\"https://blog.kakaocdn.net/dn/cU8l3K/btsMD5NXCKo/HaCdORsBavFJSuV8vGLcr1/img.gif\" data-phocus=\"https://blog.kakaocdn.net/dn/cU8l3K/btsMD5NXCKo/HaCdORsBavFJSuV8vGLcr1/img.gif\"><img src=\"https://blog.kakaocdn.net/dn/cU8l3K/btsMD5NXCKo/HaCdORsBavFJSuV8vGLcr1/img.gif\" srcset=\"https://blog.kakaocdn.net/dn/cU8l3K/btsMD5NXCKo/HaCdORsBavFJSuV8vGLcr1/img.gif\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"544\" height=\"306\" data-filename=\"tex_blink.gif\" data-origin-width=\"544\" data-origin-height=\"306\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">예시 화면</p>\n<p data-ke-size=\"size16\">셰이더가&nbsp; UI 의 scrite 를 받아드리려면 입력 텍스쳐의 이름을 고쳐주어야합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"311\" data-origin-height=\"269\"><span data-url=\"https://blog.kakaocdn.net/dn/bgKjbA/btsMDIFO9oc/6yfKL7qPFDuSH1BZGNCIP0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bgKjbA/btsMDIFO9oc/6yfKL7qPFDuSH1BZGNCIP0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bgKjbA/btsMDIFO9oc/6yfKL7qPFDuSH1BZGNCIP0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbgKjbA%2FbtsMDIFO9oc%2F6yfKL7qPFDuSH1BZGNCIP0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"311\" height=\"269\" data-origin-width=\"311\" data-origin-height=\"269\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">_MainTex &lt;-- 이런식의 이름을 써야 UI 에 설정한 그림을 받아 드릴 수 있으니 주의</p>\n<p data-ke-size=\"size16\">관련 설명:&nbsp;</p>\n<p data-ke-size=\"size16\">Some&nbsp;common&nbsp;texture&nbsp;names&nbsp;in&nbsp;Unity&nbsp;shaders&nbsp;include:&nbsp;</p>\n<p data-ke-size=\"size16\"><br />_MainTex:&nbsp;The&nbsp;main&nbsp;diffuse&nbsp;texture <br />_BumpMap:&nbsp;The&nbsp;normal&nbsp;map <br />_Cube:&nbsp;The&nbsp;reflection&nbsp;cubemap</p>\n<p data-ke-size=\"size16\"><br />You&nbsp;can&nbsp;use&nbsp;the&nbsp;Material.GetTexture&nbsp;method&nbsp;to&nbsp;get&nbsp;a&nbsp;named&nbsp;texture.&nbsp;If&nbsp;the&nbsp;texture&nbsp;is&nbsp;not&nbsp;found,&nbsp;the&nbsp;method&nbsp;will&nbsp;write&nbsp;an&nbsp;error&nbsp;message&nbsp;to&nbsp;the&nbsp;console&nbsp;and&nbsp;return&nbsp;null.&nbsp;</p>",
        "contentSnippet": "빨간 사격형이 깜박이는 작업이다.\n셰이더작업은 메뉴가 버전마다 달라서 어디는지 찾다보니 기록을 남겨둔다.\n영상: https://www.youtube.com/watch?v=VuibGcamE5E&t=45s\n\n\n\n이분 영상은 유니티 2023 버전이였다.\n \n1. UI -> Canvas 로 캔버스 만듭니다.\n2. UI -> Image 로 사각형 만듭니다.\n3. 파일쪽에서 우클릭 create -> Shader Graph -> Spirte Unlit ~~ 셰이더 그래프 만듭니다.\n\n\n멀리도 있다.\n4. 더블클릭해서 Shader Graph 엽니다.\n5.Fragment 클릭\n\n\n6. 우측 상단에 떠있는 UI 인데 그림따라 가서 Canvas 로 바꾼다.\n\n\n여기까지해야 alpha 가 정상적으로 먹히는 캔버스 셰이더가 동작합니다.\n7. 셰이더 그래프 만들기\n\n\nColor 는 빨간색 그대로 박아넣었고\nAlpha 는 Time  의 sine time 을 이용해 1 ~ -1 왔다갔다 하는 값을 넣었다. \n0 ~ -1 부분은 다 0 이 되기 때문에 안보이는 시간이 좀 길더라 Absolute 를 넣으면 1 ~ 0 값으로 바꿔준다.\n(영상에선 그걸 사용함)\n좌측 상단에 디스켓 아이콘을 눌러 저장한다.\n(요즘 사람은 디스켓이 뭔지 모른다더라.)\n\n\n이렇게 생긴 아이콘이 디스켓 이다.\n \n8. 캔버스의 이미지에 셰이더를 박는다.\n\n\n내 프로젝트 기준으로 스샷을 찍은거니 각자 알아서 잘 찾아 넣는다.\nMaterial 부분에 Shader 를 넣어도 되니 편리했다.\n \n셰이더는 어려운 분야라서 UI 에 익숙해지는게 좋을것 같아 일부러 스샷을 많이 남겼다.\n \n추가작업\nFS_Blink_shader.zip 파일 링크 : https://drive.google.com/file/d/1aEqv4z_f76fntUDX60DnCDY057BDLWfV/view?usp=drive_link\n위에서 만든 셰이더는 색깔이 깜박거리는 것이라 쓸모가 없습니다.\n이 셰이더는 텍스처를 포함한 UI 를 깜박히게 합니다.\n\n\n예시 화면\n셰이더가  UI 의 scrite 를 받아드리려면 입력 텍스쳐의 이름을 고쳐주어야합니다.\n\n\n_MainTex <-- 이런식의 이름을 써야 UI 에 설정한 그림을 받아 드릴 수 있으니 주의\n관련 설명: \nSome common texture names in Unity shaders include: \n_MainTex: The main diffuse texture \n_BumpMap: The normal map \n_Cube: The reflection cubemap\nYou can use the Material.GetTexture method to get a named texture. If the texture is not found, the method will write an error message to the console and return null.",
        "guid": "http://serverdown.tistory.com/1172",
        "categories": [
          "프로그래밍/개발메모"
        ],
        "isoDate": "2025-03-07T06:32:30.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "2025 로켓랩 RKLB 집중",
        "link": "http://serverdown.tistory.com/1171",
        "pubDate": "Fri, 7 Mar 2025 13:47:45 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1171#entry1171comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=Kk-4WdF8GEE&amp;t=846s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=Kk-4WdF8GEE&amp;t=846s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=Kk-4WdF8GEE\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/KiGyv/hyYmVl2Ait/MaaZw0wA3qUKG4Ai1h1vi0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/GJ43U/hyYmJy7Y6e/GLX5XUSwpKH7mONEe0SumK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"로켓랩 기업분석 : 트럼프 2.0, 이젠 우주를 향해  \" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/Kk-4WdF8GEE\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">25년 1월 영상인데</p>\n<p data-ke-size=\"size16\">잘 나가다 고꾸라 졌습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"818\" data-origin-height=\"326\"><span data-url=\"https://blog.kakaocdn.net/dn/d67rWN/btsMDfJ6wu7/anVmkKaGyqIJIxPbWKWMaK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/d67rWN/btsMDfJ6wu7/anVmkKaGyqIJIxPbWKWMaK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/d67rWN/btsMDfJ6wu7/anVmkKaGyqIJIxPbWKWMaK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fd67rWN%2FbtsMDfJ6wu7%2FanVmkKaGyqIJIxPbWKWMaK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"818\" height=\"326\" data-origin-width=\"818\" data-origin-height=\"326\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">1년치 차트인데요 32 갔다가 현재 18 입니다.</p>\n<p data-ke-size=\"size16\">연말엔 스페이스액스 상장도 하고</p>\n<p data-ke-size=\"size16\">로켓랩에서도 커다란 로켓을 쏠 예정이라고 합니다.</p>\n<p data-ke-size=\"size16\">이번 하락의 바닥에서 잡아볼 예정입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=Kk-4WdF8GEE&t=846s\n\n\n\n25년 1월 영상인데\n잘 나가다 고꾸라 졌습니다.\n \n\n\n1년치 차트인데요 32 갔다가 현재 18 입니다.\n연말엔 스페이스액스 상장도 하고\n로켓랩에서도 커다란 로켓을 쏠 예정이라고 합니다.\n이번 하락의 바닥에서 잡아볼 예정입니다.",
        "guid": "http://serverdown.tistory.com/1171",
        "categories": [
          "미국주식"
        ],
        "isoDate": "2025-03-07T04:47:45.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "유니티 U / 인디게임 개발은 돈이 안된다.",
        "link": "http://serverdown.tistory.com/1170",
        "pubDate": "Fri, 7 Mar 2025 10:04:04 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1170#entry1170comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://youtu.be/uteONf6Fs8I?t=192\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://youtu.be/uteONf6Fs8I?t=192</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=uteONf6Fs8I\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/lBLdX/hyYm1sUcFc/g4fSpXDxkMCwPDtu5nA6jK/img.jpg?width=1280&amp;height=720&amp;face=78_26_1102_388,https://scrap.kakaocdn.net/dn/bssN0o/hyYmYJHN0U/qaSEc7IHvdgKWUNVIudBck/img.jpg?width=1280&amp;height=720&amp;face=78_26_1102_388\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"&quot;언리얼에 고도까지..&quot; 유니티 반등의 필수 조건은?\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/uteONf6Fs8I\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">유니티 를 소개하면서 나오는 내용입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">인디게임은 매년 1만개가 출시되며</p>\n<p data-ke-size=\"size16\">50%는 4천달러를 벌지 못한다.</p>\n<p data-ke-size=\"size16\">그래서 유니티는 돈을 벌 수 없다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">인디 개발자는 쉽지 않다는 것을 의미합니다.</p>",
        "contentSnippet": "영상: https://youtu.be/uteONf6Fs8I?t=192\n\n\n\n유니티 를 소개하면서 나오는 내용입니다.\n \n인디게임은 매년 1만개가 출시되며\n50%는 4천달러를 벌지 못한다.\n그래서 유니티는 돈을 벌 수 없다.\n \n인디 개발자는 쉽지 않다는 것을 의미합니다.",
        "guid": "http://serverdown.tistory.com/1170",
        "categories": [
          "유튜브",
          "이디게임"
        ],
        "isoDate": "2025-03-07T01:04:04.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "레이 달리오 그는 훌륭하지도 투자자도 아니였다.",
        "link": "http://serverdown.tistory.com/1169",
        "pubDate": "Fri, 7 Mar 2025 09:51:38 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1169#entry1169comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=3H9IzYweqAA&amp;list=WL\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=3H9IzYweqAA&amp;list=WL</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=3H9IzYweqAA\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cB0nyZ/hyYncVuMnj/KTqM7BDVj8cLkK6z2p7Ku1/img.jpg?width=1280&amp;height=720&amp;face=364_78_580_314,https://scrap.kakaocdn.net/dn/cFxX5z/hyYqYaiFPh/5kcEtnyAxTfSIz7FFeYbmK/img.jpg?width=1280&amp;height=720&amp;face=364_78_580_314\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"⛪ 레이 달리오를 숭배하는 종교와 같았던 브리지워터와 원칙의 실체!\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/3H9IzYweqAA\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">그는 엄청나게 고평가된 사람이며</p>\n<p data-ke-size=\"size16\">위기가 올때까지 7년을 위기라고 밀고 나간 사람이다.</p>\n<p data-ke-size=\"size16\">회사의 운영방식은 너무 이상했고</p>\n<p data-ke-size=\"size16\">돈을 번게 아니라 위기때 마다 인기를 얻어 투자금이 들어오면서 성공한것 처럼 보였다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=3H9IzYweqAA&list=WL\n\n\n\n그는 엄청나게 고평가된 사람이며\n위기가 올때까지 7년을 위기라고 밀고 나간 사람이다.\n회사의 운영방식은 너무 이상했고\n돈을 번게 아니라 위기때 마다 인기를 얻어 투자금이 들어오면서 성공한것 처럼 보였다.",
        "guid": "http://serverdown.tistory.com/1169",
        "categories": [
          "투자"
        ],
        "isoDate": "2025-03-07T00:51:38.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "Google Play 앱 출시 오류 / 계정 세부정보 업데이트 / 대한민국에 거주하는 모든 개발자는 대한민국 법규를 준수하기 위해 Google Play에 추가 정보를 제공해야 합니다.",
        "link": "http://serverdown.tistory.com/1168",
        "pubDate": "Thu, 6 Mar 2025 17:57:22 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1168#entry1168comment",
        "content": "<p data-ke-size=\"size16\">저는 남의 계정에 앱 올려주다 발생했습니다.</p>\n<p data-ke-size=\"size16\">비공개 테스트 까지 올리려고 하는데 발생했구요</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"894\" data-origin-height=\"478\"><span data-url=\"https://blog.kakaocdn.net/dn/0hN9n/btsMDJDAzpO/ubjwQUUju6JT7MfL3EGmh0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/0hN9n/btsMDJDAzpO/ubjwQUUju6JT7MfL3EGmh0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/0hN9n/btsMDJDAzpO/ubjwQUUju6JT7MfL3EGmh0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F0hN9n%2FbtsMDJDAzpO%2FubjwQUUju6JT7MfL3EGmh0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"894\" height=\"478\" data-origin-width=\"894\" data-origin-height=\"478\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">우측에 문제 보기 누르시면</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"background-color: #000000; color: #000000; font-size: 1.62em; letter-spacing: -1px;\">발견된 문제 1개</span></p>\n<div style=\"background-color: #000000; color: #000000; text-align: start;\">\n<div style=\"background-color: #000000; color: #000000;\"><i>close</i></div>\n<div id=\"a9ADCBC82-7189-409E-860D-B40BA40EEA8F--695\" style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">검토를 위해 앱을 전송하는 것을 막는 몇 가지 일반적인 문제가 발견되었습니다. 검토를 위해 변경사항을 전송하기 전에 이러한 문제를 해결해야 합니다.</div>\n</div>\n</div>\n</div>\n</div>\n<div style=\"background-color: #000000; color: #000000; text-align: start;\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\"><span style=\"background-color: #000000; color: #000000;\">계정 세부정보 업데이트</span></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"a9ADCBC82-7189-409E-860D-B40BA40EEA8F--696\" style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">\n<div style=\"background-color: #000000; color: #000000;\">\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\">대한민국에 거주하는 모든 개발자는 대한민국 법규를 준수하기 위해 Google Play에 추가 정보를 제공해야 합니다.</p>\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\">이런 내용이구요</p>\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\">출시국가랑은 관련 없습니다. 올리는 사람이 한국 사람이면 이걸 증명하라는 뜻입니다.</p>\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\">&nbsp;</p>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"908\" data-origin-height=\"324\"><span data-url=\"https://blog.kakaocdn.net/dn/bqIsoZ/btsMBVFvTKI/NPiJidr6CVLmSy91UCO7k0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bqIsoZ/btsMBVFvTKI/NPiJidr6CVLmSy91UCO7k0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bqIsoZ/btsMBVFvTKI/NPiJidr6CVLmSy91UCO7k0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbqIsoZ%2FbtsMBVFvTKI%2FNPiJidr6CVLmSy91UCO7k0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"908\" height=\"324\" data-origin-width=\"908\" data-origin-height=\"324\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">버튼 누르시면 개발자 정보 메뉴로 넘어갑니다.</p>\n<p data-ke-size=\"size16\">아래쪽에 보시면 사업자 등록증 번호를 요구 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"882\" data-origin-height=\"368\"><span data-url=\"https://blog.kakaocdn.net/dn/wxgqH/btsMBSB8cRV/N7u4syJHjLkPno4K5upHsk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/wxgqH/btsMBSB8cRV/N7u4syJHjLkPno4K5upHsk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/wxgqH/btsMBSB8cRV/N7u4syJHjLkPno4K5upHsk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FwxgqH%2FbtsMBSB8cRV%2FN7u4syJHjLkPno4K5upHsk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"882\" height=\"368\" data-origin-width=\"882\" data-origin-height=\"368\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">이후 필요한 내용은&nbsp;</p>\n<p data-ke-size=\"size16\">앱을 출시하려면 사업자등록번호</p>\n<p data-ke-size=\"size16\">인앱을 판매하려면 통신판매업 번호 및 통신판매업 등록 구청 이름 <br />(통신판매업자 문서 받아보시면 거기 나옵니다.)</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">제가 등록했던 방법 글 링크: <a href=\"https://serverdown.tistory.com/815\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://serverdown.tistory.com/815</a></p>\n<figure id=\"og_1741251402681\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"1인개발자 개인사업자 등록에서 앱스토어 런칭까지 01 / 사람 안만나고 인터넷로만 진행가능\" data-og-description=\"순서1부 - 이글 입니다. 사업자 등록 같은 서류 준비 부분입니다.2부 - Googla play 스토어에 입력해야할 것 (작성중)&nbsp;&nbsp;사전지식앱스토어에서 인앱을 팔려면 통신판매업자를 등록해야 합니다.통신 \" data-og-host=\"serverdown.tistory.com\" data-og-source-url=\"https://serverdown.tistory.com/815\" data-og-url=\"https://serverdown.tistory.com/815\" data-og-image=\"https://scrap.kakaocdn.net/dn/n1njN/hyYmNnTchI/V5HIezJK2dgEeR1rzIUDTK/img.png?width=434&amp;height=601&amp;face=0_0_434_601,https://scrap.kakaocdn.net/dn/CgrHN/hyYm8SYsDo/ukmpxt7GZV4Y5r0JEhm9aK/img.png?width=434&amp;height=601&amp;face=0_0_434_601,https://scrap.kakaocdn.net/dn/capky4/hyYm8SYsGm/jerDRiByujQcwekGBF8TRK/img.png?width=983&amp;height=494&amp;face=0_0_983_494\"><a href=\"https://serverdown.tistory.com/815\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://serverdown.tistory.com/815\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/n1njN/hyYmNnTchI/V5HIezJK2dgEeR1rzIUDTK/img.png?width=434&amp;height=601&amp;face=0_0_434_601,https://scrap.kakaocdn.net/dn/CgrHN/hyYm8SYsDo/ukmpxt7GZV4Y5r0JEhm9aK/img.png?width=434&amp;height=601&amp;face=0_0_434_601,https://scrap.kakaocdn.net/dn/capky4/hyYm8SYsGm/jerDRiByujQcwekGBF8TRK/img.png?width=983&amp;height=494&amp;face=0_0_983_494');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">1인개발자 개인사업자 등록에서 앱스토어 런칭까지 01 / 사람 안만나고 인터넷로만 진행가능</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">순서1부 - 이글 입니다. 사업자 등록 같은 서류 준비 부분입니다.2부 - Googla play 스토어에 입력해야할 것 (작성중)&nbsp;&nbsp;사전지식앱스토어에서 인앱을 팔려면 통신판매업자를 등록해야 합니다.통신</p>\n<p class=\"og-host\" data-ke-size=\"size16\">serverdown.tistory.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">수익나면 매달 국세청에 올리라고 했던거 같은데 수익이 안나서 그걸 못해봤군요 ㅠㅠ</p>",
        "contentSnippet": "저는 남의 계정에 앱 올려주다 발생했습니다.\n비공개 테스트 까지 올리려고 하는데 발생했구요\n\n\n우측에 문제 보기 누르시면\n \n발견된 문제 1개\nclose\n검토를 위해 앱을 전송하는 것을 막는 몇 가지 일반적인 문제가 발견되었습니다. 검토를 위해 변경사항을 전송하기 전에 이러한 문제를 해결해야 합니다.\n계정 세부정보 업데이트\n대한민국에 거주하는 모든 개발자는 대한민국 법규를 준수하기 위해 Google Play에 추가 정보를 제공해야 합니다.\n이런 내용이구요\n출시국가랑은 관련 없습니다. 올리는 사람이 한국 사람이면 이걸 증명하라는 뜻입니다.\n \n\n\n버튼 누르시면 개발자 정보 메뉴로 넘어갑니다.\n아래쪽에 보시면 사업자 등록증 번호를 요구 합니다.\n \n\n\n이후 필요한 내용은 \n앱을 출시하려면 사업자등록번호\n인앱을 판매하려면 통신판매업 번호 및 통신판매업 등록 구청 이름 \n(통신판매업자 문서 받아보시면 거기 나옵니다.)\n \n제가 등록했던 방법 글 링크: https://serverdown.tistory.com/815\n\n \n1인개발자 개인사업자 등록에서 앱스토어 런칭까지 01 / 사람 안만나고 인터넷로만 진행가능\n순서1부 - 이글 입니다. 사업자 등록 같은 서류 준비 부분입니다.2부 - Googla play 스토어에 입력해야할 것 (작성중)  사전지식앱스토어에서 인앱을 팔려면 통신판매업자를 등록해야 합니다.통신\nserverdown.tistory.com\n\n \n수익나면 매달 국세청에 올리라고 했던거 같은데 수익이 안나서 그걸 못해봤군요 ㅠㅠ",
        "guid": "http://serverdown.tistory.com/1168",
        "categories": [
          "프로그래밍/개발메모",
          "앱개발"
        ],
        "isoDate": "2025-03-06T08:57:22.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": [
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "조금은 덜 최적화된 환경",
        "link": "http://jojoldu.tistory.com/820",
        "pubDate": "Tue, 4 Mar 2025 09:22:28 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "http://jojoldu.tistory.com/820#entry820comment",
        "content": "<p>최근 <a href=\"https://series.naver.com/novel/detail.series?productNo=10311211\">배드 본 블러드</a>라는 판타지 웹 소설을 완독했다.  </p>\n<p>지구가 망하고 행성 이주를 해서 살아가는 디스토피아를 그리고 있는데, 사람과 삶에 대해 되게 많은 생각을 하게 해준다.  </p>\n<p>소설에서는 3개의 국가가 배경이 되는데, 주인공이 태어난 국가는 상층과 하층으로 나뉠정도로 <strong>계급화가 되어있으며 기계국가로서 계급이 올라갈수록 신체를 좋은 기계 신체로 교체</strong>한다.<br>그래서 좋은 기계 신체로 교체된 사람일수록 고위직임을 의미한다.  </p>\n<p>환경에 관계 없이 좋은 퍼포먼스를, 신체를 건강하게 하기 위해 했던 기존의 낭비적인 활동 (생리욕구, 음식 섭취, 오염된 환경에서의 적응등) 들을 모두 할 필요가 없는 최적의 신체가 되는 것이 국가적으로 최고의 목표인 것이다.  </p>\n<p>아이러니한 것은 이렇게 모든 신체를 기계로 바꾼 고위층들이 몰래 저지르는 범되이다.<br>돈, 성, 마약 등에 대한 범죄 보다 더 극단적으로 취하고 있는 범죄가 바로 <strong>일반 신체에 대한 욕구</strong>이다.   </p>\n<p><strong>생살, 피, 뼈에 대한 집착</strong>으로 기계신체를 갖지 못한 하위층 시민들을 납치해 생살을 찢고, 피를 뽑고, 뼈를 부수는 등 기계 신체가 아닌 인간의 신체에 대한 고문을 한다.  </p>\n<p>그렇게 효율적으로, 효과적으로 살기 위해 기계신체로 변경하고나서 보니 예전의 비효율적인 신체가 여러 감정들을 느끼게 해주는 장치들이였던 것이다.<br>다시 돌아가지 못하는 것을 알기에 남의 신체에 고통을 주면서 상실감을 채운다.  </p>\n<hr>\n<p>최근 데브옵스 파트와 데일리 스크럼 시간에 잡담으로 1시간을 보냈다.<br>원래 했어야할 스크럼 내용은 하나도 하지 못하고 당시 있었던 전사 주간 프리뷰 이야기, 중간 리더에 대한 이야기, 프로덕트 파트에 대한 이야기 등등을 나눴다.<br>특히 <strong>효율, 비효율에 관한 이야기</strong>를 나눌때 팀원들과 다양하게 의견을 교류할 수 있었다.  </p>\n<p>데브옵스 파트가 해야하는 일이 결국 팀의 업무환경을 효율적으로 개선하는 것인데 이 <strong>조직의 효율화 개선이 가장 중요한 목표가 되면 우리가 놓치는 것들이 있지 않겠냐</strong>는 주제의 대화였다.  </p>\n<p>대화 중 &quot;회사에서 이런 인문학적인 이야기를 할 수 있어서 되게 좋은 것 같다&quot; 라는 이야기가 팀원에게서 나왔다.<br>다른 팀원들도 동의하면서 같은 파트로서 일하는 &quot;<strong>우리가 서로 가치관이 어느 방향을 향하는지 알 수 있었다</strong>&quot;는 말에서 다시 한번 이 시간이 소중했다는 생각을 했다.<br>각자가 어떻게 생각하는지 이야기를 나누고 데일리 스크럼 시간이 끝나버렸다.  </p>\n<p>빠르게 데일리 스크럼을 마치고 각자 자기 할 일을 하는게 회사 내 업무 시간을 가장 효율적으로 보내는 것이다.<br>다만 그렇게 효율만 추구하는게 오히려 더 비효율을 추구할 수 있다.<br><strong>효율화, 최적화를 하면 할수록 눈엔 보이지 않지만 조직에 가장 중요한 것들인 유대감, 동질감, 전우애 등이 사라진다</strong>.  </p>\n<p>물론 시간을 낭비해야한다는 건 아니다.<br>다만, <strong>불순물이 하나도 없는 완전히 최적화된 환경을 지향할수록 부작용이 더 클 것</strong>이라는 이야기다.<br><strong>내가 버릴려고 했던 마지막 0.01%의 불순물은 실제로는 불순물이 아닌 다른 큰 사이드 이펙트를 막기 위한 방지턱</strong>일 수도 있다.  </p>",
        "contentSnippet": "최근 배드 본 블러드라는 판타지 웹 소설을 완독했다.  \n지구가 망하고 행성 이주를 해서 살아가는 디스토피아를 그리고 있는데, 사람과 삶에 대해 되게 많은 생각을 하게 해준다.  \n소설에서는 3개의 국가가 배경이 되는데, 주인공이 태어난 국가는 상층과 하층으로 나뉠정도로 계급화가 되어있으며 기계국가로서 계급이 올라갈수록 신체를 좋은 기계 신체로 교체한다.\n그래서 좋은 기계 신체로 교체된 사람일수록 고위직임을 의미한다.  \n환경에 관계 없이 좋은 퍼포먼스를, 신체를 건강하게 하기 위해 했던 기존의 낭비적인 활동 (생리욕구, 음식 섭취, 오염된 환경에서의 적응등) 들을 모두 할 필요가 없는 최적의 신체가 되는 것이 국가적으로 최고의 목표인 것이다.  \n아이러니한 것은 이렇게 모든 신체를 기계로 바꾼 고위층들이 몰래 저지르는 범되이다.\n돈, 성, 마약 등에 대한 범죄 보다 더 극단적으로 취하고 있는 범죄가 바로 일반 신체에 대한 욕구이다.   \n생살, 피, 뼈에 대한 집착으로 기계신체를 갖지 못한 하위층 시민들을 납치해 생살을 찢고, 피를 뽑고, 뼈를 부수는 등 기계 신체가 아닌 인간의 신체에 대한 고문을 한다.  \n그렇게 효율적으로, 효과적으로 살기 위해 기계신체로 변경하고나서 보니 예전의 비효율적인 신체가 여러 감정들을 느끼게 해주는 장치들이였던 것이다.\n다시 돌아가지 못하는 것을 알기에 남의 신체에 고통을 주면서 상실감을 채운다.  \n최근 데브옵스 파트와 데일리 스크럼 시간에 잡담으로 1시간을 보냈다.\n원래 했어야할 스크럼 내용은 하나도 하지 못하고 당시 있었던 전사 주간 프리뷰 이야기, 중간 리더에 대한 이야기, 프로덕트 파트에 대한 이야기 등등을 나눴다.\n특히 효율, 비효율에 관한 이야기를 나눌때 팀원들과 다양하게 의견을 교류할 수 있었다.  \n데브옵스 파트가 해야하는 일이 결국 팀의 업무환경을 효율적으로 개선하는 것인데 이 조직의 효율화 개선이 가장 중요한 목표가 되면 우리가 놓치는 것들이 있지 않겠냐는 주제의 대화였다.  \n대화 중 \"회사에서 이런 인문학적인 이야기를 할 수 있어서 되게 좋은 것 같다\" 라는 이야기가 팀원에게서 나왔다.\n다른 팀원들도 동의하면서 같은 파트로서 일하는 \"우리가 서로 가치관이 어느 방향을 향하는지 알 수 있었다\"는 말에서 다시 한번 이 시간이 소중했다는 생각을 했다.\n각자가 어떻게 생각하는지 이야기를 나누고 데일리 스크럼 시간이 끝나버렸다.  \n빠르게 데일리 스크럼을 마치고 각자 자기 할 일을 하는게 회사 내 업무 시간을 가장 효율적으로 보내는 것이다.\n다만 그렇게 효율만 추구하는게 오히려 더 비효율을 추구할 수 있다.\n효율화, 최적화를 하면 할수록 눈엔 보이지 않지만 조직에 가장 중요한 것들인 유대감, 동질감, 전우애 등이 사라진다.  \n물론 시간을 낭비해야한다는 건 아니다.\n다만, 불순물이 하나도 없는 완전히 최적화된 환경을 지향할수록 부작용이 더 클 것이라는 이야기다.\n내가 버릴려고 했던 마지막 0.01%의 불순물은 실제로는 불순물이 아닌 다른 큰 사이드 이펙트를 막기 위한 방지턱일 수도 있다.",
        "guid": "http://jojoldu.tistory.com/820",
        "categories": [
          "생각정리",
          "DevOps",
          "데브옵스",
          "배드 본 블러드",
          "생산성",
          "최적화"
        ],
        "isoDate": "2025-03-04T00:22:28.000Z"
      }
    ]
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "한상곤 - Sigmadream",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "한국어 몰라요 - 글로벌 협업의 4가지 패턴",
        "link": "https://techblog.lycorp.co.jp/ko/4-patterns-of-global-collaboration",
        "pubDate": "Fri, 07 Mar 2025 04:00:00 GMT",
        "content": "요즘 우리나라는 어느 회사든 글로벌 진출을 염두에 두고 있습니다. 대부분의 분야에서 우리나라 시장은 가파른 속도로 축소될 전망이므로 해외 진출은 하고 싶은 것이 아닌 할 수밖에 없...",
        "contentSnippet": "요즘 우리나라는 어느 회사든 글로벌 진출을 염두에 두고 있습니다. 대부분의 분야에서 우리나라 시장은 가파른 속도로 축소될 전망이므로 해외 진출은 하고 싶은 것이 아닌 할 수밖에 없...",
        "guid": "https://techblog.lycorp.co.jp/ko/4-patterns-of-global-collaboration",
        "isoDate": "2025-03-07T04:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": [
      {
        "title": "Trino로 타임아웃 개선하기",
        "link": "https://meetup.nhncloud.com/posts/391",
        "pubDate": "Tue, 04 Mar 2025 02:22:40 GMT",
        "content": "![NHN Cloud_meetup banner_trino_202502-01_900.png](https://image.toast.com/aaaadh/real/2025/techblog/NHN%20Cloudmeetup%20bannertrino20250201900.png)\r\r\n\r\r\n# 들어가며\r\r\n안녕하세요. NHN Cloud의 클라우드AI팀 이태형입니다.\r\r\n로그 데이터가 쌓일수록 조회 속도가 느려지는 문제, 한 번쯤 겪어 보셨을 텐데요. 이 글에서는 이러한 문제를 해결하기 위해 저희 팀에서 Trino를 도입하여 성능을 개선한 과정을 공유해 보려 합니다. 재미있게 읽어 주세요! \r\r\n\r\r\n# 개요: NHN AppGuard\r\r\n[NHN AppGuard](https://www.nhncloud.com/kr/service/security/nhn-appguard) 서비스에 Trino를 적용한 이야기를 드릴 예정이라서 먼저 해당 서비스를 소개하겠습니다.\r\r\n\r\r\nNHN AppGuard는 모바일 애플리케이션을 보호하기 위해 사용자의 이상 행위를 탐지하거나 차단하는 모바일 앱 보안 솔루션입니다. NHN AppGuard의 서버는 탐지/차단 로그를 안전하게 저장하고, 각종 조건 검색과 대시보드를 제공합니다.\r\r\n\r\r\n![Trino_1.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino1.png)\r\r\n\r\r\n## NHN AppGuard 로그\r\r\n\r\r\nNHN AppGuard는 평균 600만개/일 가량의 로그를 수집하고 있습니다. 이러한 로그는 NHN AppGuard 로그 워크플로에 따라 DB에 적재됩니다.\r\r\n\r\r\n![Trino_2_900.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino2900.png)\r\r\n\r\r\n## 이슈 발생\r\r\n\r\r\n대부분의 쿼리가 월 단위 집계 성격을 띠는 이유로 질의 대상 row 가 1억 건이 넘는 경우가 많아 이슈가 발생했습니다.\r\r\n발생한 이슈는 아래와 같습니다.\r\r\n\r\r\n1. 검색 조건 변경 시 대시보드 화면에서 타임아웃 발생\r\r\n![Trino_3.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino3.png)\r\r\n2. 집계 쿼리가 수행되는 새벽 시간대에 slow query 발생\r\r\n![Trino_4.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino4.png)\r\r\n\r\r\n## 일반적인 해결 방안\r\r\n\r\r\n위 이슈들은 결국 쿼리의 성능이 원인이기 때문에 먼저 쿼리 최적화를 수행했습니다.\r\r\n\r\r\n1. index 문제\r\r\n    1. 쿼리 검수를 통해 index의 순서를 변경하고\r\r\n    2. 의도한 index가 적용되도록 쿼리에 index hint를 추가했습니다.\r\r\n2. 쿼리의 문제\r\r\n    1. 한 달 기간 전체 데이터를 스캔하는 쿼리를 당일 증가분만 조회하도록 수정하고\r\r\n    2. 대시보드를 매번 조회하지 않고 일 배치 작업으로 미리 계산해 둔 데이터를 조회하고\r\r\n    3. 조회 가능한 기간을 제한했습니다.\r\r\n\r\r\n이러한 최적화를 통해 일시적으로 이슈가 해소되었습니다.\r\r\n하지만 NHN AppGuard의 로그는 점차 늘어나고, 집계할 데이터의 종류도 증가했으며, 조회 기간 감소에 대한 불만이 발생하여 다른 접근이 필요했습니다.\r\r\n\r\r\n## 로그 저장소 검토\r\r\n\r\r\nMySQL을 대신해 로그를 저장하기에 적절한 로그 저장소를 검토했습니다.\r\r\n\r\r\n1. Elasticsearch (LNCS)\r\r\n    1. 검색에 좋은 성능\r\r\n    2. 상품 스펙상 최대 120일 저장 제한\r\r\n2. Trino (DataQuery)\r\r\n    1. 복잡한 집계 쿼리에 좋은 성능\r\r\n    2. 여러 데이터 소스 간 federation 지원\r\r\n    3. 저장 기간 제한 없음\r\r\n\r\r\nNHN AppGuard는 로그의 저장 기간을 기존 90일에서 늘리는 것을 계획하고 있었고, 무엇보다 대부분의 쿼리가 집계 성격을 많이 띠어 Trino가 적절하다고 판단했습니다.\r\r\n\r\r\n# Trino와 DataQuery\r\r\n\r\r\n## Trino란\r\r\n\r\r\n[Trino 공식 홈페이지](https://trino.io)를 보면 아래와 같은 문구를 찾을 수 있습니다.\r\r\n\r\r\n> Trino, a query engine that runs at ludicrous speed\r\r\n> Fast distributed SQL query engine for big data analytics that helps you explore your data universe.\r\r\n\r\r\n키워드를 뽑아 보면 아래와 같습니다.\r\r\n\r\r\n1. Fast - 빠르다\r\r\n2. Distributed - 분산 처리한다\r\r\n3. analytics - 분석에 적절하다\r\r\n\r\r\n## Trino 특징\r\r\n\r\r\n마찬가지로 [Trino 공식 홈페이지](https://trino.io)에서는 아래와 같은 특징을 소개합니다.\r\r\n![Trino_5.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino5.png)\r\r\n\r\r\n여기서도 키워드를 뽑아보면 아래와 같습니다.\r\r\n\r\r\n1. distributed: 분산 처리로 빠르고\r\r\n2. ANSI SQL: 표준 SQL 을 호환하여 현재 쿼리문을 수정할 필요가 없고\r\r\n3. S3: OBS에 저장하여 스토리지 비용을 줄일 수 있고\r\r\n4. Query Federation: OBS의 데이터와 MySQL 데이터를 하나의 쿼리로 join할 수 있다.\r\r\n\r\r\n## Trino 동작 원리\r\r\n\r\r\nTrino의 동작 원리는 [Presto: SQL on Everything](https://trino.io/Presto_SQL_on_Everything.pdf)라는 논문에 자세히 소개하고 있습니다.\r\r\n해당 논문의 일부를 가볍게 살펴보겠습니다.\r\r\n\r\r\n### 구조도\r\r\n![Trino_6.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino6.png)\r\r\n\r\r\nTrino는 하나의 Coordinator 노드와 여러 개의 Worker 노드로 구성됩니다. Coordinator 노드는 쿼리의 인입 지점으로 admit, parsing, planning, optimizing, orchestration 등을 수행하고, worker node는 query processing을 담당합니다.\r\r\n\r\r\n### 요청 처리 순서\r\r\n\r\r\nCoordinator 노드가 분산 처리를 계획하면 worker node가 병렬로 처리해서 복잡한 쿼리가 더 빠르게 실행되는 원리입니다.\r\r\n\r\r\n1. client → coordinator: http request (SQL stmt)\r\r\n2. coordinator: evaluate request(parsing, analyzing, **optimizing distributed execution plan**)\r\r\n3. coordinator: plan to worker\r\r\n    1. task 생성\r\r\n    2. **splits** 생성(addressable chunk in external storage)\r\r\n    3. splits을 task에 할당\r\r\n4. worker: run task\r\r\n    1. fetching splits\r\r\n    2. 다른 worker에서 생성한 intermediate data 처리\r\r\n        1. worker 간에는 intermediate data를 memory에 저장하여 공유\r\r\n        2. **shuffle**이 발생할 수 있음\r\r\n             \\*shuffle = node 간 데이터 재분배\r\r\n    3. query의 shape에 따라 모든 데이터를 처리하지 않고 반환\r\r\n\r\r\n## Trino 쿼리 실행 예시\r\r\n\r\r\n### 그림으로 살펴보기\r\r\n* 쿼리문\r\r\n![Trino_7.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino7.png)\r\r\n\r\r\n* logical plan\r\r\n![Trino_8.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino8.png)\r\r\n\r\r\n* distributed plan (stage)\r\r\n![Trino_9.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino9.png)\r\r\n\r\r\n* optimized plan (pipeline, parallelism)\r\r\n![Trino_10.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino10.png)\r\r\n\r\r\n\r\r\n### 실행 순서\r\r\n\r\r\n1. Planner: SQL → SQL syntax tree → Logical Planning (IR 생성)\r\r\n    * IR = Intermediate Representation\r\r\n2. Optimizer: Logical Plan → evaluate transformation rules → **optimize** → Physical Structure\r\r\n    * transformation rules = sub-tree query plan + transformation\r\r\n    * 사용되는 optimizing 기법 = predicate and limit pushdown, column pruning, decorrelation, table and column statistics 기반 cost-based 최적화\r\r\n        * Data Layouts = Connector Data Layout API로 얻어내는 위치, 파티션, 정렬, 그룹화, 인덱스\r\r\n        * Predicate Pushdown = connector에 따른 filtering 최적화\r\r\n            * \\*pushdown : 읽어야 하는 데이터를 줄이는 것\r\r\n            * \\***Predicate Pushdown** : 조회 조건에 맞는 데이터만 읽는 것\r\r\n        * **Inter**-node Parallelism = stage 단위의 병렬 실행\r\r\n        * **Intra**-node Parallelism = stage 내에서 single node의 thread에 걸친 병렬 실행\r\r\n3. Scheduler: Stage Scheduling → Task Scheduling → Split Scheduling\r\r\n    * Task Scheduling = Leaf Stage / Intermediate Stage 분리하여 배치\r\r\n4. Query Execution = Local Data Flow → Shuffles → Writes\r\r\n\r\r\n## DataQuery\r\r\n\r\r\n[NHN Cloud의 DataQuery](https://www.nhncloud.com/kr/service/data-analytics/dataquery?lang=ko) 서비스는 위에서 소개한 Trino를 기반으로 대규모 데이터에 대해 쿼리를 실행할 수 있는 서비스입니다.\r\r\n이를 통해 원하는 클러스터 스펙을 지정하고 연결할 데이터 소스만 작성하면 Trino의 복잡한 설치와 설정 과정 없이 사용이 가능합니다.\r\r\n\r\r\n# Trino 적용 - 개념\r\r\nTrino를 적용하기 위해 알아야 할 개념을 소개합니다.\r\r\n\r\r\n## 데이터 소스 선정\r\r\nTrino는 여러 종류의 데이터 소스를 지원합니다.\r\r\n\r\r\nNHN AppGuard는 로그 저장 기간 증가를 계획하고 있어 저장 비용을 절약하기 위해 OBS를 데이터 소스로 선정하였습니다.\r\r\nOBS 데이터 소스를 사용하는 경우 데이터의 타입도 Parquet, JSON, ORC, CSV, Text 중에 선택해 주어야 해서, 위와 동일한 이유로 Parquet 파일 포맷을 선택하였습니다.\r\r\n\r\r\n### Apache Parquet\r\r\n\r\r\n[Apache Parquet 홈페이지](https://parquet.apache.org)에는 Parquet를 아래와 같이 설명합니다.\r\r\n\r\r\n> Apache Parquet is an open source, column-oriented data file format designed for efficient data storage and retrieval. It provides efficient data compression and encoding schemes with enhanced performance to handle complex data in bulk. Parquet is available in multiple languages including Java, C++, Python, etc...\r\r\n\r\r\n여기서도 키워드를 뽑아보면 아래와 같습니다.\r\r\n\r\r\n* column-oriented data\r\r\n* efficient data storage and retrieval\r\r\n* efficient data compression\r\r\n* encoding schema\r\r\n* handle complex data in bulk\r\r\n\r\r\ncolumn-oriented data의 설명은 아래의 그림을 보시면 이해가 쉽습니다.\r\r\n![Trino_11.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino11.png)\r\r\n<center>(Source: [https://devidea.tistory.com/92](https://devidea.tistory.com/92))</center>\r\r\n<br>\r\r\n동일한 타입의 데이터가 나열되기 때문에 압축 효율이 높아지는 효과가 있습니다.\r\r\n또한 footer에 데이터에 대한 메타데이터를 저장해 두어 reader에게 데이터에 대한 힌트를 주어 조회 성능을 높입니다.\r\r\n\r\r\n![Trino_12.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino12.png)\r\r\n<center>(source: [https://parquet.apache.org/docs/file-format/](https://parquet.apache.org/docs/file-format/))</center>\r\r\n<br>\r\r\n## 구상안\r\r\n\r\r\nparquet는 columnar한 형식이기 때문에 row 단위로 데이터를 append하는 것은 비효율적입니다. 그러므로 데이터를 모아서 parquet 형식으로 파일을 생성하는 것이 효율적입니다. 이를 위해 NHN AppGuard에서는 3가지 구성 방법을 고려했고 3번째 안을 선택했습니다.\r\r\n\r\r\n1. micro batch\r\r\n    1. kafka → log-batch → create parquet / 1 minute → save obs → obs\r\r\n    2. trino는 OBS를 사용하는 경우 파일 기반으로 동작하기 때문에 파일의 개수가 많아지면 비효율적입니다.\r\r\n    3. 1분 단위로 파일을 쓸 경우 작은 파일이 많아져 조회 성능이 현저히 떨어지기 때문에 선택하지 않았습니다.\r\r\n2. hourly batch\r\r\n    1. kafka → log-batch → create parquet / 1 hour (save data in memory or redis) → save obs → obs\r\r\n    2. 메모리에 저장하는 경우 데이터 유실의 리스크가 걱정되었고\r\r\n    3. NHN AppGuard는 redis를 사용하고 있지 않아 trino와 redis 두 컴포넌트의 추가로 인한 운영 복잡도 증가가 부담되어 선택하지 않았습니다.\r\r\n3. **중간 DB 사용 - MySQL**\r\r\n    1. kafka → log-batch → save to mysql → mysql → tier down in daily-batch → save obs → obs\r\r\n    2. 기존에 사용하던 MySQL 구성을 변경하지 않아 수정 소요가 적었고\r\r\n    3. MySQL을 통해 실시간 데이터 또한 조회할 수 있어 실시간 데이터 조회가 쉬워 선택하였습니다.\r\r\n\r\r\n### 구성도\r\r\n\r\r\n* AS-IS\r\r\n![Trino_13_900.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino13900.png)\r\r\n\r\r\n* TO-BE\r\r\n![Trino_14_900.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino14900.png)\r\r\n\r\r\n\r\r\n### tier down 개념\r\r\n\r\r\nElasticSearch는 데이터의 역할 또는 접근 빈도에 따라 노드를 분배하는 기법으로 Data Tiering 을 사용합니다.\r\r\n\r\r\n![Trino_15.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino15.png)\r\r\n<center>(source: [https://www.linkedin.com/pulse/navigating-data-tiers-optimizing-costs-reducing-risk-boosting-lim-yfeyc](https://www.linkedin.com/pulse/navigating-data-tiers-optimizing-costs-reducing-risk-boosting-lim-yfeyc))</center>\r\r\n<br>\r\r\n이렇게 tier를 적용한 데이터를 높은 티어에서 낮은 티어로 낮추는 것을 tier down이라고 부릅니다. hot tier는 일반적으로 성능이 좋고 반응이 빠르지만 비용이 비싸고, cold tier는 반응은 조금 느리지만 비용이 저렴한 저장소를 사용합니다.\r\r\n\r\r\nNHN AppGuard에서는 MySQL을 hot tier, Trino를 cold tier로 정의하고 daily-batch에서 MySQL 데이터를 Parquet로 변환해 Trino에 삽입시키는 작업을 tier down으로 정의했습니다.\r\r\n\r\r\n### Parquet 파일 생성 방법\r\r\n\r\r\nParquet는 원래 HDFS에 쓰는 용도로 고안되어서 Parquet 파일을 직접 쓰려면 `org.apache.hadoop:hadoop-common:3.3.6`과 같은 hdfs writer에 세그먼트 관리, 열 압축 등의 기능을 구현해야 합니다. 이러한 작업을 피하기 위해 일반적으로 Spark 등의 외부 컴포넌트를 쓰거나 avro 포맷의 파일을 거쳤다가 parquet로 변환하는 방법을 사용합니다.\r\r\n\r\r\n[Apache Avro](https://avro.apache.org)는 data를 serialize하기에 좋은 포맷으로 스키마를 갖습니다.\r\r\nParquetFileWriter를 지원하기 때문에 손쉽게 변환이 가능합니다.\r\r\n\r\r\n> Apache Avro™ is the leading serialization format for record data, and first choice for streaming data pipelines. It offers excellent schema evolution, and has implementations for the JVM (Java, Kotlin, Scala, …), Python, C/C++/C#, PHP, Ruby, Rust, JavaScript, and even Perl.\r\r\n\r\r\n# Trino 적용 - 구현\r\r\n\r\r\n## tier down 구현\r\r\n\r\r\n### 논리 구조\r\r\n![Trino_16_900.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino16900.png)\r\r\n\r\r\n\r\r\n### Trino 테이블 생성\r\r\n\r\r\nTrino 데이터 소스로 OBS를 사용하는 경우 Hive를 사용하기 때문에 HQL을 사용해야 합니다. HQL 또한 SQL 표준을 따르기 때문에 거의 유사하지만 묵시적 형 변환과 같은 편의 기능을 지원하지 않고, with 문의 external location, partitioned_by 등의 옵션이 추가됩니다.\r\r\n\r\r\n```sql\r\r\nCREATE TABLE log\r\r\n (\r\r\n    seq              bigint, \r\r\n    log_time         timestamp,\r\r\n    // 생략 \r\r\n    log_date         date,\r\r\n    appkey           varchar(64),\r\r\n ) \r\r\n WITH ( \r\r\n    format = 'Parquet',\r\r\n    external_location = 's3a://data-query/log',\r\r\n    partitioned_by = ARRAY['appkey','date']\r\r\n);\r\r\n```\r\r\n\r\r\n### avro schema 작성\r\r\n\r\r\n```javascript\r\r\n{\r\r\n  \"type\" : \"record\",\r\r\n  \"name\" : \"log\",\r\r\n  \"namespace\" : \"avro\",\r\r\n  \"fields\" : [\r\r\n    { \"name\" : \"seq\", \"type\" : \"long\" },\r\r\n    { \"name\" : \"log_time\", \"type\" : [ \"null\", \"string\" ], \"default\" : null },\r\r\n    // 생략\r\r\n  ]\r\r\n}\r\r\n```\r\r\n\r\r\n### tier down process\r\r\n![Trino_17.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino17.png)\r\r\n데이터를 메모리에 올려서 변환하기 때문에 장비와 데이터에 따라 적절한 페이징을 적용해야 합니다.\r\r\n\r\r\n### convert to parquet\r\r\n![Trino_18.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino18.png)\r\r\navro 변환은 apache avro 모듈의 schema.from 함수로 쉽게 변환이 가능합니다. parquet는 apache parquet 모듈의 PositionOutputStream 객체의 writer를 구현하여 변환할 수 있습니다.\r\r\n\r\r\n### 다른 방법은 없을까?\r\r\nCTAS(Create Table As Select)가 가장 쉬운 방법입니다. 수행 시간은 위 방법과 비슷하게 소요되지만 용량이 30% 정도 더 효율적인 것으로 확인하였습니다. 하지만 DataQuery에서 사내 DB를 아직 데이터 소스로 지원하지 않아 현재는 사용이 어렵습니다.\r\r\n여기에서는 방법만 소개하겠습니다.\r\r\n\r\r\n```sql\r\r\nCREATE TABLE obs.test.log_ctas\r\r\n    WITH (\r\r\n        format = 'Parquet',\r\r\n        external_location = 's3a://ctas-test/log-ctas',\r\r\n        partitioned_by = ARRAY['log_date', 'appkey']\r\r\n        )\r\r\nAS\r\r\nselect seq,\r\r\n// 생략\r\r\n       cast(log_time as date) as log_date,\r\r\n       appkey\r\r\nfrom \"mysql\".log\r\r\nwhere log_time >= date '2024-11-01'\r\r\n  and log_time < date '2024-11-02';\r\r\n```\r\r\n\r\r\n## 실시간 데이터 union 구현\r\r\n\r\r\n### 논리 구성도\r\r\n![Trino_19_900.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino19900.png)\r\r\n1. cold data에 마지막으로 저장된 시간을 조회하고\r\r\n2. cold data와 hot data를 조회해\r\r\n3. join / union 하여 응답합니다.\r\r\n\r\r\n### Data 조회\r\r\n\r\r\nCold - max cold data 기준 왼쪽을 조회합니다.\r\r\n![Trino_20.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino20.png)\r\r\n\r\r\nHot - max cold data 기준 오른쪽을 조회합니다.\r\r\n![Trino_21.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino21.png)\r\r\n\r\r\n### Data Join / Union\r\r\n\r\r\n집계의 경우 toMap과 id 값을 이용해 Join 합니다.\r\r\n![Trino_22.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino22.png)\r\r\n\r\r\n단순 조회의 경우 stream.concat으로 Union 합니다.\r\r\n![Trino_23.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino23.png)\r\r\n\r\r\n# 성능 테스트\r\r\n\r\r\n## 환경\r\r\n\r\r\n* DataQuery 스펙: c2m8 * 3\r\r\n* DataQuery 데이터는(log_date, appKey) 파티셔닝 되어 있고\r\r\n    * 참고 \\*partition = RDBMS의 index 와 유사. parquet 가 저장된 경로를 의미\r\r\n        ![Trino_24.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino24.png)\r\r\n* MySQL 데이터는 일 단위로 파티셔닝되어 있습니다.\r\r\n* MySQL 데이터는 log\\_time, appkey 각각의 인덱스와 (log\\_time, appkey) 복합 index 가 적용되어 있습니다.\r\r\n\r\r\n## 데이터 조회\r\r\n\r\r\n이슈 대응 등의 이유로 개발자가 쿼리 엔진에 자주 질의하는 **일반 쿼리**와 서비스에서 사용하는 **서비스 쿼리**로 구분하여 테스트했습니다.\r\r\n\r\r\n### 일반 쿼리\r\r\n\r\r\n단순한 select \\* 조회는 mysql이 7배가량 빠르고, count 등의 집계 함수가 포함된 쿼리는 DataQuery가 적게는 4배에서 6배가량 빠른 양상을 보였습니다.\r\r\nTrino + Parquet 조합은 열 기반 데이터 포맷으로 인한 행 조회의 비효율성, Trino의 쿼리 플래닝과 file fetch에서의 오버헤드로 인해 단순한 행 조회가 느리기 때문입니다.\r\r\n\r\r\n| 쿼리 | dataquery | mysql |\r\r\n| --- | --------- | ----- |\r\r\n| **단순** 조회 (select \\* limit 500) | <span style=\"color:#e11d21;\">1 s 151 ms</span> | <span style=\"color:#0052cc;\">148 ms</span> |\r\r\n| **count** 조회 (select count(\\*) 한 달 | <span style=\"color:#0052cc;\">8 s 957 ms</span> | <span style=\"color:#e11d21;\">30.987 s</span> |\r\r\n| filter - appkey \\& log\\_time **행 조회** | <span style=\"color:#e11d21;\">1 s 323 ms</span> | <span style=\"color:#0052cc;\">393 ms</span> |\r\r\n| filter - appkey \\& log\\_time **count** | <span style=\"color:#0052cc;\">349 ms</span> | <span style=\"color:#e11d21;\">14.662 s</span> |\r\r\n| group by - appkey 하루 | <span style=\"color:#0052cc;\">814 ms</span> | <span style=\"color:#e11d21;\">2.385 s</span> |\r\r\n| group by - appkey 한 달 | <span style=\"color:#0052cc;\">18 s 530 ms</span> | <span style=\"color:#e11d21;\">2m 15s 538ms</span> |\r\r\n\r\r\n### NHN AppGuard 서비스 쿼리\r\r\n\r\r\nDataQuery가 전반적으로 10배 정도 빨랐습니다.\r\r\n이상 행위 탐지 현황의 한 달치 데이터는 MySQL에서 30분 이상 소요되어 조회할 수 없었지만 DataQuery는 36초만에 조회하였습니다.\r\r\n\r\r\n| 쿼리 | dataquery | mysql |\r\r\n| --- | --------- | ----- |\r\r\n| 이상행위 탐지현황 - limit 50 하루 | <span style=\"color:#0052cc;\">1 s 696 ms</span> | <span style=\"color:#e11d21;\">9.676s</span> |\r\r\n| 이상행위 탐지현황 - limit 50 한 달 | <span style=\"color:#0052cc;\">6 s 468 ms</span> | <span style=\"color:#e11d21;\">6m 19s 459ms</span> |\r\r\n| 이상행위 탐지현황 report - 하루 | <span style=\"color:#0052cc;\">7.06s</span> | <span style=\"color:#e11d21;\">21s 890ms</span> |\r\r\n| 이상행위 탐지현황 report - 한 달 | <span style=\"color:#0052cc;\">36.81s</span> | <span style=\"color:#e11d21;\">**조회 불가(30분 이상)**</span> |\r\r\n| 로그 조회 - 하루 | <span style=\"color:#0052cc;\">1 s 531 ms</span> | <span style=\"color:#e11d21;\">7s 264ms</span> |\r\r\n| 로그 조회 - 한 달 | <span style=\"color:#0052cc;\">5 s 728 ms</span> | <span style=\"color:#e11d21;\">5m 58s 381ms</span> |\r\r\n\r\r\n### Parquet 크기별 비교\r\r\n\r\r\nappkey로 파티션 되기 때문에 appkey별 로그 양이 달라 로그 개수에 따른 성능 차이를 비교해 보았습니다. 로그 수 기준 중위의 appkey까지도 MySQL이 더 빠른 양상을 보였습니다. 2-300ms가량의 차이를 보이는 만큼 로그가 적은 사용자 입장에서는 데이터가 없는데 굼뜨다는 느낌을 받을 수 있습니다. 이에 반해 로그 수가 평균을 넘어가면 MySQL은 30초가 넘어가는 응답을 보여 콘솔에서 서비스하기에 어려운 반응 속도를 보입니다.\r\r\n\r\r\n| 대시보드 조회 쿼리 | DataQuery | MySQL |\r\r\n| ---------- | --------- | ----- |\r\r\n| 데이터 없음 | <span style=\"color:#e11d21;\">267 ms</span> | <span style=\"color:#0052cc;\">102 ms</span> |\r\r\n| 최소 | <span style=\"color:#e11d21;\">365 ms</span> | <span style=\"color:#0052cc;\">100 ms</span> |\r\r\n| 중위 | <span style=\"color:#e11d21;\">610 ms</span> | <span style=\"color:#0052cc;\">168 ms</span> |\r\r\n| 평균 | <span style=\"color:#0052cc;\">505 ms</span> | <span style=\"color:#e11d21;\">34 s 24 ms</span> |\r\r\n| 최대 | <span style=\"color:#0052cc;\">15s 85 ms</span> | <span style=\"color:#e11d21;\">10 m 23 s 982 ms</span> |\r\r\n\r\r\n## 성능 테스트 결론\r\r\n\r\r\n1. 행 전체 조회, 데이터가 적은 경우는 MySQL이 빠르다.\r\r\n    1. 100ms VS 500ms의 차이 → **참을만하다.**\r\r\n2. 집계 조회, 데이터가 많은 경우에는 DataQuery가 빠르다.\r\r\n    1. 수십 초 VS 수 분 차이 → **참을 수 없다.**\r\r\n\r\r\n# 결과\r\r\n\r\r\n## 좋아졌나요?\r\r\n\r\r\n1. 이상 행위 탐지 현황의 30일치 데이터를 조회하지 못하던 고객이 이제 조회할 수 있게 되었습니다.\r\r\n2. 2024년 초 공개한 NHN AppGuard public api는 MySQL로는 30분 이상 소요되어 개발이 어려웠는데, DataQuery를 통해 7초 이내로 조회하여 개발할 수 있었습니다.\r\r\n3. 내부 집계 시간이 38m36s → 22m16s로 약 43% 개선했습니다.\r\r\n4. mysql에서의 집계로 인한 slow query가 제거되어 일 배치로 인한 서비스의 영향성이 없어졌습니다.\r\r\n5. 집계 연산이 빨라져서 집계 데이터의 종류를 늘리는 것에 부담이 없어졌습니다.\r\r\n6. 스토리지 비용 감소로 데이터 저장 기간을 60일에서 1년으로 늘렸습니다.\r\r\n\r\r\n## 나쁜 점은 없나요?\r\r\n\r\r\n1. 대시보드의 기본 응답 속도가 300ms 정도 느려졌습니다.\r\r\n2. tier down 실패 시 집계, 미터링 등에 영향을 주기 때문에 모니터링 요소가 늘어났습니다.\r\r\n3. DataQuery와 OBS 비용이 추가되었습니다. (대략 100만 원/월)\r\r\n\r\r\n## 앞으로 해야 할 것이 있을까요?\r\r\n\r\r\n1. 일 단위 tier down을 시간 단위로 변경하는 것을 고민하고 있습니다.\r\r\n2. 고객 로그 수에 따라 적절한 쿼리 엔진을 사용하도록 최적화하는 부분에 대해 고민하고 있습니다.\r\r\n\r\r\n\r\r\n\r\r\n이상 NHN AppGuard에 Trino를 적용해 본 과정과 결과에 대해 정리하였습니다. 도움이 되셨길 바라며, 긴 글을 읽어 주셔서 감사합니다. \r\r\n\r\r\n[![NHN Cloud_meetup banner_footer_gray_202408_900.png](https://image.toast.com/aaaadh/real/2025/techblog/NHN%20Cloudmeetup%20bannerfootergray202408900.png)](https://www.nhncloud.com/kr)",
        "contentSnippet": "![NHN Cloud_meetup banner_trino_202502-01_900.png](https://image.toast.com/aaaadh/real/2025/techblog/NHN%20Cloudmeetup%20bannertrino20250201900.png)\r\r\n\r\r\n# 들어가며\r\r\n안녕하세요. NHN Cloud의 클라우드AI팀 이태형입니다.\r\r\n로그 데이터가 쌓일수록 조회 속도가 느려지는 문제, 한 번쯤 겪어 보셨을 텐데요. 이 글에서는 이러한 문제를 해결하기 위해 저희 팀에서 Trino를 도입하여 성능을 개선한 과정을 공유해 보려 합니다. 재미있게 읽어 주세요! \r\r\n\r\r\n# 개요: NHN AppGuard\r\r\n[NHN AppGuard](https://www.nhncloud.com/kr/service/security/nhn-appguard) 서비스에 Trino를 적용한 이야기를 드릴 예정이라서 먼저 해당 서비스를 소개하겠습니다.\r\r\n\r\r\nNHN AppGuard는 모바일 애플리케이션을 보호하기 위해 사용자의 이상 행위를 탐지하거나 차단하는 모바일 앱 보안 솔루션입니다. NHN AppGuard의 서버는 탐지/차단 로그를 안전하게 저장하고, 각종 조건 검색과 대시보드를 제공합니다.\r\r\n\r\r\n![Trino_1.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino1.png)\r\r\n\r\r\n## NHN AppGuard 로그\r\r\n\r\r\nNHN AppGuard는 평균 600만개/일 가량의 로그를 수집하고 있습니다. 이러한 로그는 NHN AppGuard 로그 워크플로에 따라 DB에 적재됩니다.\r\r\n\r\r\n![Trino_2_900.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino2900.png)\r\r\n\r\r\n## 이슈 발생\r\r\n\r\r\n대부분의 쿼리가 월 단위 집계 성격을 띠는 이유로 질의 대상 row 가 1억 건이 넘는 경우가 많아 이슈가 발생했습니다.\r\r\n발생한 이슈는 아래와 같습니다.\r\r\n\r\r\n1. 검색 조건 변경 시 대시보드 화면에서 타임아웃 발생\r\r\n![Trino_3.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino3.png)\r\r\n2. 집계 쿼리가 수행되는 새벽 시간대에 slow query 발생\r\r\n![Trino_4.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino4.png)\r\r\n\r\r\n## 일반적인 해결 방안\r\r\n\r\r\n위 이슈들은 결국 쿼리의 성능이 원인이기 때문에 먼저 쿼리 최적화를 수행했습니다.\r\r\n\r\r\n1. index 문제\r\r\n    1. 쿼리 검수를 통해 index의 순서를 변경하고\r\r\n    2. 의도한 index가 적용되도록 쿼리에 index hint를 추가했습니다.\r\r\n2. 쿼리의 문제\r\r\n    1. 한 달 기간 전체 데이터를 스캔하는 쿼리를 당일 증가분만 조회하도록 수정하고\r\r\n    2. 대시보드를 매번 조회하지 않고 일 배치 작업으로 미리 계산해 둔 데이터를 조회하고\r\r\n    3. 조회 가능한 기간을 제한했습니다.\r\r\n\r\r\n이러한 최적화를 통해 일시적으로 이슈가 해소되었습니다.\r\r\n하지만 NHN AppGuard의 로그는 점차 늘어나고, 집계할 데이터의 종류도 증가했으며, 조회 기간 감소에 대한 불만이 발생하여 다른 접근이 필요했습니다.\r\r\n\r\r\n## 로그 저장소 검토\r\r\n\r\r\nMySQL을 대신해 로그를 저장하기에 적절한 로그 저장소를 검토했습니다.\r\r\n\r\r\n1. Elasticsearch (LNCS)\r\r\n    1. 검색에 좋은 성능\r\r\n    2. 상품 스펙상 최대 120일 저장 제한\r\r\n2. Trino (DataQuery)\r\r\n    1. 복잡한 집계 쿼리에 좋은 성능\r\r\n    2. 여러 데이터 소스 간 federation 지원\r\r\n    3. 저장 기간 제한 없음\r\r\n\r\r\nNHN AppGuard는 로그의 저장 기간을 기존 90일에서 늘리는 것을 계획하고 있었고, 무엇보다 대부분의 쿼리가 집계 성격을 많이 띠어 Trino가 적절하다고 판단했습니다.\r\r\n\r\r\n# Trino와 DataQuery\r\r\n\r\r\n## Trino란\r\r\n\r\r\n[Trino 공식 홈페이지](https://trino.io)를 보면 아래와 같은 문구를 찾을 수 있습니다.\r\r\n\r\r\n> Trino, a query engine that runs at ludicrous speed\r\r\n> Fast distributed SQL query engine for big data analytics that helps you explore your data universe.\r\r\n\r\r\n키워드를 뽑아 보면 아래와 같습니다.\r\r\n\r\r\n1. Fast - 빠르다\r\r\n2. Distributed - 분산 처리한다\r\r\n3. analytics - 분석에 적절하다\r\r\n\r\r\n## Trino 특징\r\r\n\r\r\n마찬가지로 [Trino 공식 홈페이지](https://trino.io)에서는 아래와 같은 특징을 소개합니다.\r\r\n![Trino_5.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino5.png)\r\r\n\r\r\n여기서도 키워드를 뽑아보면 아래와 같습니다.\r\r\n\r\r\n1. distributed: 분산 처리로 빠르고\r\r\n2. ANSI SQL: 표준 SQL 을 호환하여 현재 쿼리문을 수정할 필요가 없고\r\r\n3. S3: OBS에 저장하여 스토리지 비용을 줄일 수 있고\r\r\n4. Query Federation: OBS의 데이터와 MySQL 데이터를 하나의 쿼리로 join할 수 있다.\r\r\n\r\r\n## Trino 동작 원리\r\r\n\r\r\nTrino의 동작 원리는 [Presto: SQL on Everything](https://trino.io/Presto_SQL_on_Everything.pdf)라는 논문에 자세히 소개하고 있습니다.\r\r\n해당 논문의 일부를 가볍게 살펴보겠습니다.\r\r\n\r\r\n### 구조도\r\r\n![Trino_6.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino6.png)\r\r\n\r\r\nTrino는 하나의 Coordinator 노드와 여러 개의 Worker 노드로 구성됩니다. Coordinator 노드는 쿼리의 인입 지점으로 admit, parsing, planning, optimizing, orchestration 등을 수행하고, worker node는 query processing을 담당합니다.\r\r\n\r\r\n### 요청 처리 순서\r\r\n\r\r\nCoordinator 노드가 분산 처리를 계획하면 worker node가 병렬로 처리해서 복잡한 쿼리가 더 빠르게 실행되는 원리입니다.\r\r\n\r\r\n1. client → coordinator: http request (SQL stmt)\r\r\n2. coordinator: evaluate request(parsing, analyzing, **optimizing distributed execution plan**)\r\r\n3. coordinator: plan to worker\r\r\n    1. task 생성\r\r\n    2. **splits** 생성(addressable chunk in external storage)\r\r\n    3. splits을 task에 할당\r\r\n4. worker: run task\r\r\n    1. fetching splits\r\r\n    2. 다른 worker에서 생성한 intermediate data 처리\r\r\n        1. worker 간에는 intermediate data를 memory에 저장하여 공유\r\r\n        2. **shuffle**이 발생할 수 있음\r\r\n             \\*shuffle = node 간 데이터 재분배\r\r\n    3. query의 shape에 따라 모든 데이터를 처리하지 않고 반환\r\r\n\r\r\n## Trino 쿼리 실행 예시\r\r\n\r\r\n### 그림으로 살펴보기\r\r\n* 쿼리문\r\r\n![Trino_7.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino7.png)\r\r\n\r\r\n* logical plan\r\r\n![Trino_8.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino8.png)\r\r\n\r\r\n* distributed plan (stage)\r\r\n![Trino_9.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino9.png)\r\r\n\r\r\n* optimized plan (pipeline, parallelism)\r\r\n![Trino_10.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino10.png)\r\r\n\r\r\n\r\r\n### 실행 순서\r\r\n\r\r\n1. Planner: SQL → SQL syntax tree → Logical Planning (IR 생성)\r\r\n    * IR = Intermediate Representation\r\r\n2. Optimizer: Logical Plan → evaluate transformation rules → **optimize** → Physical Structure\r\r\n    * transformation rules = sub-tree query plan + transformation\r\r\n    * 사용되는 optimizing 기법 = predicate and limit pushdown, column pruning, decorrelation, table and column statistics 기반 cost-based 최적화\r\r\n        * Data Layouts = Connector Data Layout API로 얻어내는 위치, 파티션, 정렬, 그룹화, 인덱스\r\r\n        * Predicate Pushdown = connector에 따른 filtering 최적화\r\r\n            * \\*pushdown : 읽어야 하는 데이터를 줄이는 것\r\r\n            * \\***Predicate Pushdown** : 조회 조건에 맞는 데이터만 읽는 것\r\r\n        * **Inter**-node Parallelism = stage 단위의 병렬 실행\r\r\n        * **Intra**-node Parallelism = stage 내에서 single node의 thread에 걸친 병렬 실행\r\r\n3. Scheduler: Stage Scheduling → Task Scheduling → Split Scheduling\r\r\n    * Task Scheduling = Leaf Stage / Intermediate Stage 분리하여 배치\r\r\n4. Query Execution = Local Data Flow → Shuffles → Writes\r\r\n\r\r\n## DataQuery\r\r\n\r\r\n[NHN Cloud의 DataQuery](https://www.nhncloud.com/kr/service/data-analytics/dataquery?lang=ko) 서비스는 위에서 소개한 Trino를 기반으로 대규모 데이터에 대해 쿼리를 실행할 수 있는 서비스입니다.\r\r\n이를 통해 원하는 클러스터 스펙을 지정하고 연결할 데이터 소스만 작성하면 Trino의 복잡한 설치와 설정 과정 없이 사용이 가능합니다.\r\r\n\r\r\n# Trino 적용 - 개념\r\r\nTrino를 적용하기 위해 알아야 할 개념을 소개합니다.\r\r\n\r\r\n## 데이터 소스 선정\r\r\nTrino는 여러 종류의 데이터 소스를 지원합니다.\r\r\n\r\r\nNHN AppGuard는 로그 저장 기간 증가를 계획하고 있어 저장 비용을 절약하기 위해 OBS를 데이터 소스로 선정하였습니다.\r\r\nOBS 데이터 소스를 사용하는 경우 데이터의 타입도 Parquet, JSON, ORC, CSV, Text 중에 선택해 주어야 해서, 위와 동일한 이유로 Parquet 파일 포맷을 선택하였습니다.\r\r\n\r\r\n### Apache Parquet\r\r\n\r\r\n[Apache Parquet 홈페이지](https://parquet.apache.org)에는 Parquet를 아래와 같이 설명합니다.\r\r\n\r\r\n> Apache Parquet is an open source, column-oriented data file format designed for efficient data storage and retrieval. It provides efficient data compression and encoding schemes with enhanced performance to handle complex data in bulk. Parquet is available in multiple languages including Java, C++, Python, etc...\r\r\n\r\r\n여기서도 키워드를 뽑아보면 아래와 같습니다.\r\r\n\r\r\n* column-oriented data\r\r\n* efficient data storage and retrieval\r\r\n* efficient data compression\r\r\n* encoding schema\r\r\n* handle complex data in bulk\r\r\n\r\r\ncolumn-oriented data의 설명은 아래의 그림을 보시면 이해가 쉽습니다.\r\r\n![Trino_11.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino11.png)\r\r\n(Source: [https://devidea.tistory.com/92](https://devidea.tistory.com/92))\r\r\n\r\r\n동일한 타입의 데이터가 나열되기 때문에 압축 효율이 높아지는 효과가 있습니다.\r\r\n또한 footer에 데이터에 대한 메타데이터를 저장해 두어 reader에게 데이터에 대한 힌트를 주어 조회 성능을 높입니다.\r\r\n\r\r\n![Trino_12.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino12.png)\r\r\n(source: [https://parquet.apache.org/docs/file-format/](https://parquet.apache.org/docs/file-format/))\r\r\n\r\r\n## 구상안\r\r\n\r\r\nparquet는 columnar한 형식이기 때문에 row 단위로 데이터를 append하는 것은 비효율적입니다. 그러므로 데이터를 모아서 parquet 형식으로 파일을 생성하는 것이 효율적입니다. 이를 위해 NHN AppGuard에서는 3가지 구성 방법을 고려했고 3번째 안을 선택했습니다.\r\r\n\r\r\n1. micro batch\r\r\n    1. kafka → log-batch → create parquet / 1 minute → save obs → obs\r\r\n    2. trino는 OBS를 사용하는 경우 파일 기반으로 동작하기 때문에 파일의 개수가 많아지면 비효율적입니다.\r\r\n    3. 1분 단위로 파일을 쓸 경우 작은 파일이 많아져 조회 성능이 현저히 떨어지기 때문에 선택하지 않았습니다.\r\r\n2. hourly batch\r\r\n    1. kafka → log-batch → create parquet / 1 hour (save data in memory or redis) → save obs → obs\r\r\n    2. 메모리에 저장하는 경우 데이터 유실의 리스크가 걱정되었고\r\r\n    3. NHN AppGuard는 redis를 사용하고 있지 않아 trino와 redis 두 컴포넌트의 추가로 인한 운영 복잡도 증가가 부담되어 선택하지 않았습니다.\r\r\n3. **중간 DB 사용 - MySQL**\r\r\n    1. kafka → log-batch → save to mysql → mysql → tier down in daily-batch → save obs → obs\r\r\n    2. 기존에 사용하던 MySQL 구성을 변경하지 않아 수정 소요가 적었고\r\r\n    3. MySQL을 통해 실시간 데이터 또한 조회할 수 있어 실시간 데이터 조회가 쉬워 선택하였습니다.\r\r\n\r\r\n### 구성도\r\r\n\r\r\n* AS-IS\r\r\n![Trino_13_900.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino13900.png)\r\r\n\r\r\n* TO-BE\r\r\n![Trino_14_900.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino14900.png)\r\r\n\r\r\n\r\r\n### tier down 개념\r\r\n\r\r\nElasticSearch는 데이터의 역할 또는 접근 빈도에 따라 노드를 분배하는 기법으로 Data Tiering 을 사용합니다.\r\r\n\r\r\n![Trino_15.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino15.png)\r\r\n(source: [https://www.linkedin.com/pulse/navigating-data-tiers-optimizing-costs-reducing-risk-boosting-lim-yfeyc](https://www.linkedin.com/pulse/navigating-data-tiers-optimizing-costs-reducing-risk-boosting-lim-yfeyc))\r\r\n\r\r\n이렇게 tier를 적용한 데이터를 높은 티어에서 낮은 티어로 낮추는 것을 tier down이라고 부릅니다. hot tier는 일반적으로 성능이 좋고 반응이 빠르지만 비용이 비싸고, cold tier는 반응은 조금 느리지만 비용이 저렴한 저장소를 사용합니다.\r\r\n\r\r\nNHN AppGuard에서는 MySQL을 hot tier, Trino를 cold tier로 정의하고 daily-batch에서 MySQL 데이터를 Parquet로 변환해 Trino에 삽입시키는 작업을 tier down으로 정의했습니다.\r\r\n\r\r\n### Parquet 파일 생성 방법\r\r\n\r\r\nParquet는 원래 HDFS에 쓰는 용도로 고안되어서 Parquet 파일을 직접 쓰려면 `org.apache.hadoop:hadoop-common:3.3.6`과 같은 hdfs writer에 세그먼트 관리, 열 압축 등의 기능을 구현해야 합니다. 이러한 작업을 피하기 위해 일반적으로 Spark 등의 외부 컴포넌트를 쓰거나 avro 포맷의 파일을 거쳤다가 parquet로 변환하는 방법을 사용합니다.\r\r\n\r\r\n[Apache Avro](https://avro.apache.org)는 data를 serialize하기에 좋은 포맷으로 스키마를 갖습니다.\r\r\nParquetFileWriter를 지원하기 때문에 손쉽게 변환이 가능합니다.\r\r\n\r\r\n> Apache Avro™ is the leading serialization format for record data, and first choice for streaming data pipelines. It offers excellent schema evolution, and has implementations for the JVM (Java, Kotlin, Scala, …), Python, C/C++/C#, PHP, Ruby, Rust, JavaScript, and even Perl.\r\r\n\r\r\n# Trino 적용 - 구현\r\r\n\r\r\n## tier down 구현\r\r\n\r\r\n### 논리 구조\r\r\n![Trino_16_900.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino16900.png)\r\r\n\r\r\n\r\r\n### Trino 테이블 생성\r\r\n\r\r\nTrino 데이터 소스로 OBS를 사용하는 경우 Hive를 사용하기 때문에 HQL을 사용해야 합니다. HQL 또한 SQL 표준을 따르기 때문에 거의 유사하지만 묵시적 형 변환과 같은 편의 기능을 지원하지 않고, with 문의 external location, partitioned_by 등의 옵션이 추가됩니다.\r\r\n\r\r\n```sql\r\r\nCREATE TABLE log\r\r\n (\r\r\n    seq              bigint, \r\r\n    log_time         timestamp,\r\r\n    // 생략 \r\r\n    log_date         date,\r\r\n    appkey           varchar(64),\r\r\n ) \r\r\n WITH ( \r\r\n    format = 'Parquet',\r\r\n    external_location = 's3a://data-query/log',\r\r\n    partitioned_by = ARRAY['appkey','date']\r\r\n);\r\r\n```\r\r\n\r\r\n### avro schema 작성\r\r\n\r\r\n```javascript\r\r\n{\r\r\n  \"type\" : \"record\",\r\r\n  \"name\" : \"log\",\r\r\n  \"namespace\" : \"avro\",\r\r\n  \"fields\" : [\r\r\n    { \"name\" : \"seq\", \"type\" : \"long\" },\r\r\n    { \"name\" : \"log_time\", \"type\" : [ \"null\", \"string\" ], \"default\" : null },\r\r\n    // 생략\r\r\n  ]\r\r\n}\r\r\n```\r\r\n\r\r\n### tier down process\r\r\n![Trino_17.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino17.png)\r\r\n데이터를 메모리에 올려서 변환하기 때문에 장비와 데이터에 따라 적절한 페이징을 적용해야 합니다.\r\r\n\r\r\n### convert to parquet\r\r\n![Trino_18.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino18.png)\r\r\navro 변환은 apache avro 모듈의 schema.from 함수로 쉽게 변환이 가능합니다. parquet는 apache parquet 모듈의 PositionOutputStream 객체의 writer를 구현하여 변환할 수 있습니다.\r\r\n\r\r\n### 다른 방법은 없을까?\r\r\nCTAS(Create Table As Select)가 가장 쉬운 방법입니다. 수행 시간은 위 방법과 비슷하게 소요되지만 용량이 30% 정도 더 효율적인 것으로 확인하였습니다. 하지만 DataQuery에서 사내 DB를 아직 데이터 소스로 지원하지 않아 현재는 사용이 어렵습니다.\r\r\n여기에서는 방법만 소개하겠습니다.\r\r\n\r\r\n```sql\r\r\nCREATE TABLE obs.test.log_ctas\r\r\n    WITH (\r\r\n        format = 'Parquet',\r\r\n        external_location = 's3a://ctas-test/log-ctas',\r\r\n        partitioned_by = ARRAY['log_date', 'appkey']\r\r\n        )\r\r\nAS\r\r\nselect seq,\r\r\n// 생략\r\r\n       cast(log_time as date) as log_date,\r\r\n       appkey\r\r\nfrom \"mysql\".log\r\r\nwhere log_time >= date '2024-11-01'\r\r\n  and log_time < date '2024-11-02';\r\r\n```\r\r\n\r\r\n## 실시간 데이터 union 구현\r\r\n\r\r\n### 논리 구성도\r\r\n![Trino_19_900.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino19900.png)\r\r\n1. cold data에 마지막으로 저장된 시간을 조회하고\r\r\n2. cold data와 hot data를 조회해\r\r\n3. join / union 하여 응답합니다.\r\r\n\r\r\n### Data 조회\r\r\n\r\r\nCold - max cold data 기준 왼쪽을 조회합니다.\r\r\n![Trino_20.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino20.png)\r\r\n\r\r\nHot - max cold data 기준 오른쪽을 조회합니다.\r\r\n![Trino_21.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino21.png)\r\r\n\r\r\n### Data Join / Union\r\r\n\r\r\n집계의 경우 toMap과 id 값을 이용해 Join 합니다.\r\r\n![Trino_22.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino22.png)\r\r\n\r\r\n단순 조회의 경우 stream.concat으로 Union 합니다.\r\r\n![Trino_23.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino23.png)\r\r\n\r\r\n# 성능 테스트\r\r\n\r\r\n## 환경\r\r\n\r\r\n* DataQuery 스펙: c2m8 * 3\r\r\n* DataQuery 데이터는(log_date, appKey) 파티셔닝 되어 있고\r\r\n    * 참고 \\*partition = RDBMS의 index 와 유사. parquet 가 저장된 경로를 의미\r\r\n        ![Trino_24.png](https://image.toast.com/aaaadh/real/2025/techblog/Trino24.png)\r\r\n* MySQL 데이터는 일 단위로 파티셔닝되어 있습니다.\r\r\n* MySQL 데이터는 log\\_time, appkey 각각의 인덱스와 (log\\_time, appkey) 복합 index 가 적용되어 있습니다.\r\r\n\r\r\n## 데이터 조회\r\r\n\r\r\n이슈 대응 등의 이유로 개발자가 쿼리 엔진에 자주 질의하는 **일반 쿼리**와 서비스에서 사용하는 **서비스 쿼리**로 구분하여 테스트했습니다.\r\r\n\r\r\n### 일반 쿼리\r\r\n\r\r\n단순한 select \\* 조회는 mysql이 7배가량 빠르고, count 등의 집계 함수가 포함된 쿼리는 DataQuery가 적게는 4배에서 6배가량 빠른 양상을 보였습니다.\r\r\nTrino + Parquet 조합은 열 기반 데이터 포맷으로 인한 행 조회의 비효율성, Trino의 쿼리 플래닝과 file fetch에서의 오버헤드로 인해 단순한 행 조회가 느리기 때문입니다.\r\r\n\r\r\n| 쿼리 | dataquery | mysql |\r\r\n| --- | --------- | ----- |\r\r\n| **단순** 조회 (select \\* limit 500) | 1 s 151 ms | 148 ms |\r\r\n| **count** 조회 (select count(\\*) 한 달 | 8 s 957 ms | 30.987 s |\r\r\n| filter - appkey \\& log\\_time **행 조회** | 1 s 323 ms | 393 ms |\r\r\n| filter - appkey \\& log\\_time **count** | 349 ms | 14.662 s |\r\r\n| group by - appkey 하루 | 814 ms | 2.385 s |\r\r\n| group by - appkey 한 달 | 18 s 530 ms | 2m 15s 538ms |\r\r\n\r\r\n### NHN AppGuard 서비스 쿼리\r\r\n\r\r\nDataQuery가 전반적으로 10배 정도 빨랐습니다.\r\r\n이상 행위 탐지 현황의 한 달치 데이터는 MySQL에서 30분 이상 소요되어 조회할 수 없었지만 DataQuery는 36초만에 조회하였습니다.\r\r\n\r\r\n| 쿼리 | dataquery | mysql |\r\r\n| --- | --------- | ----- |\r\r\n| 이상행위 탐지현황 - limit 50 하루 | 1 s 696 ms | 9.676s |\r\r\n| 이상행위 탐지현황 - limit 50 한 달 | 6 s 468 ms | 6m 19s 459ms |\r\r\n| 이상행위 탐지현황 report - 하루 | 7.06s | 21s 890ms |\r\r\n| 이상행위 탐지현황 report - 한 달 | 36.81s | **조회 불가(30분 이상)** |\r\r\n| 로그 조회 - 하루 | 1 s 531 ms | 7s 264ms |\r\r\n| 로그 조회 - 한 달 | 5 s 728 ms | 5m 58s 381ms |\r\r\n\r\r\n### Parquet 크기별 비교\r\r\n\r\r\nappkey로 파티션 되기 때문에 appkey별 로그 양이 달라 로그 개수에 따른 성능 차이를 비교해 보았습니다. 로그 수 기준 중위의 appkey까지도 MySQL이 더 빠른 양상을 보였습니다. 2-300ms가량의 차이를 보이는 만큼 로그가 적은 사용자 입장에서는 데이터가 없는데 굼뜨다는 느낌을 받을 수 있습니다. 이에 반해 로그 수가 평균을 넘어가면 MySQL은 30초가 넘어가는 응답을 보여 콘솔에서 서비스하기에 어려운 반응 속도를 보입니다.\r\r\n\r\r\n| 대시보드 조회 쿼리 | DataQuery | MySQL |\r\r\n| ---------- | --------- | ----- |\r\r\n| 데이터 없음 | 267 ms | 102 ms |\r\r\n| 최소 | 365 ms | 100 ms |\r\r\n| 중위 | 610 ms | 168 ms |\r\r\n| 평균 | 505 ms | 34 s 24 ms |\r\r\n| 최대 | 15s 85 ms | 10 m 23 s 982 ms |\r\r\n\r\r\n## 성능 테스트 결론\r\r\n\r\r\n1. 행 전체 조회, 데이터가 적은 경우는 MySQL이 빠르다.\r\r\n    1. 100ms VS 500ms의 차이 → **참을만하다.**\r\r\n2. 집계 조회, 데이터가 많은 경우에는 DataQuery가 빠르다.\r\r\n    1. 수십 초 VS 수 분 차이 → **참을 수 없다.**\r\r\n\r\r\n# 결과\r\r\n\r\r\n## 좋아졌나요?\r\r\n\r\r\n1. 이상 행위 탐지 현황의 30일치 데이터를 조회하지 못하던 고객이 이제 조회할 수 있게 되었습니다.\r\r\n2. 2024년 초 공개한 NHN AppGuard public api는 MySQL로는 30분 이상 소요되어 개발이 어려웠는데, DataQuery를 통해 7초 이내로 조회하여 개발할 수 있었습니다.\r\r\n3. 내부 집계 시간이 38m36s → 22m16s로 약 43% 개선했습니다.\r\r\n4. mysql에서의 집계로 인한 slow query가 제거되어 일 배치로 인한 서비스의 영향성이 없어졌습니다.\r\r\n5. 집계 연산이 빨라져서 집계 데이터의 종류를 늘리는 것에 부담이 없어졌습니다.\r\r\n6. 스토리지 비용 감소로 데이터 저장 기간을 60일에서 1년으로 늘렸습니다.\r\r\n\r\r\n## 나쁜 점은 없나요?\r\r\n\r\r\n1. 대시보드의 기본 응답 속도가 300ms 정도 느려졌습니다.\r\r\n2. tier down 실패 시 집계, 미터링 등에 영향을 주기 때문에 모니터링 요소가 늘어났습니다.\r\r\n3. DataQuery와 OBS 비용이 추가되었습니다. (대략 100만 원/월)\r\r\n\r\r\n## 앞으로 해야 할 것이 있을까요?\r\r\n\r\r\n1. 일 단위 tier down을 시간 단위로 변경하는 것을 고민하고 있습니다.\r\r\n2. 고객 로그 수에 따라 적절한 쿼리 엔진을 사용하도록 최적화하는 부분에 대해 고민하고 있습니다.\r\r\n\r\r\n\r\r\n\r\r\n이상 NHN AppGuard에 Trino를 적용해 본 과정과 결과에 대해 정리하였습니다. 도움이 되셨길 바라며, 긴 글을 읽어 주셔서 감사합니다. \r\r\n\r\r\n[![NHN Cloud_meetup banner_footer_gray_202408_900.png](https://image.toast.com/aaaadh/real/2025/techblog/NHN%20Cloudmeetup%20bannerfootergray202408900.png)](https://www.nhncloud.com/kr)",
        "isoDate": "2025-03-04T02:22:40.000Z"
      }
    ]
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": [
      {
        "title": "식자재 품목 검색을 더 쉽게! 검색 엔진 도입과 개선",
        "link": "https://spoqa.github.io/2025/03/04/es-dev.html",
        "pubDate": "2025-03-04T00:00:00.000Z",
        "author": "이지민",
        "content": "<p>안녕하세요. 스포카 백엔드팀 프로그래머 이지민입니다.</p>\n\n<p>스포카에서는 식당 점주분들이 식자재 주문을 더 편리하게 하기 위한 많은 노력들을 하고 있습니다.\n그중에서도, 주문하려는 품목을 검색하여 원하는 품목을 빠르게 찾을 수 있도록 품목 검색 기능을 제공하고 있는데요.</p>\n\n<p>검색 엔진 도입부터 지금의 검색이 되기까지의 과정들을 이야기해보려고 합니다.</p>\n\n<p>도입 초기에는 검색 엔진에 대한 이해가 깊지 않아, 논리적인 의사결정보다는 다양한 테스트를 통해 더 나은 결과를 찾는 방식으로 기능을 결정, 구현하였습니다.\n이 점을 고려해 읽어주시길 바라며, 이 글은 검색 엔진의 점진적인 발전 과정을 다루는 이야기이니, 순차적으로 읽어보시면 개선 과정이 더욱 잘 이해되실 것 같습니다!</p>\n\n<h1 id=\"검색-엔진-도입-배경\">검색 엔진 도입 배경</h1>\n<p>품목 검색 기능 초기에는 Database의 LIKE 질의를 통한 검색만 제공되었습니다. 이로 인해 품목명에 띄어쓰기가 다르거나 맞춤법이 정확히 일치하지 않는 경우, 사용자가 원하는 결과를 찾기가 어려웠습니다.</p>\n\n<p>예를 들어, <code class=\"language-plaintext highlighter-rouge\">깐마늘</code>을 검색했을 때 <code class=\"language-plaintext highlighter-rouge\">마늘/깐</code> 이라고 저장되어 있는 유통사 품목은 검색되지 않아 점주들은 깐마늘을 유통사가 취급하지 않는다고 오해하는 상황이 발생하곤 했습니다.</p>\n\n<p>이와 같은 문제와 사용하는 점주의 수가 증가하고 품목의 종류가 다양해짐에 따라, DB 검색 기능의 한계가 더 드러나게 되었고 이를 해결하기 위해 검색 엔진 도입의 필요성이 대두되었습니다.</p>\n\n<p>이번 검색 엔진 도입이 스포카에서 최초 도입은 아닌데요.(하지만 제가 처음이에요.) (구)도도카트 서비스 운영 당시 많은 명세표 품목을 검색하는데 Elasticsearch 검색 엔진을 활용했었습니다.\n우선 별도의 검색 품질에 대한 기준이 마련되어 있지 않았기 때문에 (구)도도카트 서비스의 검색 엔진 설정을 참고해 Elasticsearch(이하 ES)를 POC 해보기로 했습니다.</p>\n\n<p><img src=\"/images/es-dev/es0-1.jpg\" alt=\"background\" /></p>\n\n<h2 id=\"db-like-검색과-es-검색-비교-poc\">DB LIKE 검색과 ES 검색 비교 POC</h2>\n<p>품목 데이터는 <code class=\"language-plaintext highlighter-rouge\">product</code> 라는 인덱스에 다음과 같은 setting 으로 구성했습니다.</p>\n\n<div class=\"language-json highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"p\">{</span><span class=\"w\">\n  </span><span class=\"nl\">\"product\"</span><span class=\"p\">:{</span><span class=\"w\">\n    </span><span class=\"nl\">\"mappings\"</span><span class=\"p\">:{</span><span class=\"w\">\n      </span><span class=\"nl\">\"properties\"</span><span class=\"p\">:{</span><span class=\"w\">\n        </span><span class=\"err\">//</span><span class=\"w\"> </span><span class=\"err\">..</span><span class=\"w\"> </span><span class=\"err\">생략</span><span class=\"w\">\n        </span><span class=\"nl\">\"name\"</span><span class=\"p\">:{</span><span class=\"w\">\n          </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"text\"</span><span class=\"p\">,</span><span class=\"w\">\n          </span><span class=\"nl\">\"analyzer\"</span><span class=\"p\">:</span><span class=\"s2\">\"korean\"</span><span class=\"p\">,</span><span class=\"w\">\n          </span><span class=\"nl\">\"fields\"</span><span class=\"p\">:{</span><span class=\"w\">\n            </span><span class=\"nl\">\"ngram\"</span><span class=\"p\">:{</span><span class=\"w\">\n              </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"text\"</span><span class=\"p\">,</span><span class=\"w\">\n              </span><span class=\"nl\">\"analyzer\"</span><span class=\"p\">:</span><span class=\"s2\">\"korean_ngram\"</span><span class=\"w\">\n            </span><span class=\"p\">}</span><span class=\"w\">\n          </span><span class=\"p\">}</span><span class=\"w\">\n        </span><span class=\"p\">}</span><span class=\"w\">\n      </span><span class=\"p\">}</span><span class=\"w\">\n    </span><span class=\"p\">},</span><span class=\"w\">\n    </span><span class=\"nl\">\"settings\"</span><span class=\"p\">:{</span><span class=\"w\">\n      </span><span class=\"nl\">\"index\"</span><span class=\"p\">:{</span><span class=\"w\">\n        </span><span class=\"nl\">\"analysis\"</span><span class=\"p\">:{</span><span class=\"w\">\n          </span><span class=\"nl\">\"filter\"</span><span class=\"p\">:{</span><span class=\"w\">\n            </span><span class=\"nl\">\"edge_ngram_back\"</span><span class=\"p\">:{</span><span class=\"w\">\n              </span><span class=\"nl\">\"min_gram\"</span><span class=\"p\">:</span><span class=\"s2\">\"1\"</span><span class=\"p\">,</span><span class=\"w\">\n              </span><span class=\"nl\">\"side\"</span><span class=\"p\">:</span><span class=\"s2\">\"back\"</span><span class=\"p\">,</span><span class=\"w\">\n              </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"edge_ngram\"</span><span class=\"p\">,</span><span class=\"w\">\n              </span><span class=\"nl\">\"max_gram\"</span><span class=\"p\">:</span><span class=\"s2\">\"5\"</span><span class=\"w\">\n            </span><span class=\"p\">},</span><span class=\"w\">\n            </span><span class=\"nl\">\"edge_ngram_front\"</span><span class=\"p\">:{</span><span class=\"w\">\n              </span><span class=\"nl\">\"min_gram\"</span><span class=\"p\">:</span><span class=\"s2\">\"1\"</span><span class=\"p\">,</span><span class=\"w\">\n              </span><span class=\"nl\">\"side\"</span><span class=\"p\">:</span><span class=\"s2\">\"front\"</span><span class=\"p\">,</span><span class=\"w\">\n              </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"edge_ngram\"</span><span class=\"p\">,</span><span class=\"w\">\n              </span><span class=\"nl\">\"max_gram\"</span><span class=\"p\">:</span><span class=\"s2\">\"5\"</span><span class=\"w\">\n            </span><span class=\"p\">}</span><span class=\"w\">\n          </span><span class=\"p\">},</span><span class=\"w\">\n          </span><span class=\"nl\">\"analyzer\"</span><span class=\"p\">:{</span><span class=\"w\">\n            </span><span class=\"nl\">\"korean\"</span><span class=\"p\">:{</span><span class=\"w\">\n              </span><span class=\"nl\">\"filter\"</span><span class=\"p\">:[</span><span class=\"w\">\n                </span><span class=\"s2\">\"lowercase\"</span><span class=\"p\">,</span><span class=\"w\">\n                </span><span class=\"s2\">\"trim\"</span><span class=\"w\">\n              </span><span class=\"p\">],</span><span class=\"w\">\n              </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"custom\"</span><span class=\"p\">,</span><span class=\"w\">\n              </span><span class=\"nl\">\"tokenizer\"</span><span class=\"p\">:</span><span class=\"s2\">\"nori_mixed\"</span><span class=\"w\">\n            </span><span class=\"p\">},</span><span class=\"w\">\n            </span><span class=\"nl\">\"korean_ngram\"</span><span class=\"p\">:{</span><span class=\"w\">\n              </span><span class=\"nl\">\"filter\"</span><span class=\"p\">:[</span><span class=\"w\">\n                </span><span class=\"s2\">\"lowercase\"</span><span class=\"p\">,</span><span class=\"w\">\n                </span><span class=\"s2\">\"edge_ngram_front\"</span><span class=\"p\">,</span><span class=\"w\">\n                </span><span class=\"s2\">\"edge_ngram_back\"</span><span class=\"p\">,</span><span class=\"w\">\n                </span><span class=\"s2\">\"trim\"</span><span class=\"w\">\n              </span><span class=\"p\">],</span><span class=\"w\">\n              </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"custom\"</span><span class=\"p\">,</span><span class=\"w\">\n              </span><span class=\"nl\">\"tokenizer\"</span><span class=\"p\">:</span><span class=\"s2\">\"nori_mixed\"</span><span class=\"w\">\n            </span><span class=\"p\">}</span><span class=\"w\">\n          </span><span class=\"p\">},</span><span class=\"w\">\n          </span><span class=\"nl\">\"tokenizer\"</span><span class=\"p\">:{</span><span class=\"w\">\n            </span><span class=\"nl\">\"nori_mixed\"</span><span class=\"p\">:{</span><span class=\"w\">\n              </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"nori_tokenizer\"</span><span class=\"p\">,</span><span class=\"w\">\n              </span><span class=\"nl\">\"decompound_mode\"</span><span class=\"p\">:</span><span class=\"s2\">\"mixed\"</span><span class=\"w\">\n            </span><span class=\"p\">}</span><span class=\"w\">\n          </span><span class=\"p\">}</span><span class=\"w\">\n        </span><span class=\"p\">}</span><span class=\"w\">\n      </span><span class=\"p\">}</span><span class=\"w\">\n    </span><span class=\"p\">}</span><span class=\"w\">\n  </span><span class=\"p\">}</span><span class=\"w\">\n</span><span class=\"p\">}</span><span class=\"w\">\n</span></code></pre></div></div>\n<ul>\n  <li>품목명을 저장할 <code class=\"language-plaintext highlighter-rouge\">name</code> field, <code class=\"language-plaintext highlighter-rouge\">name.ngram</code> field 구현</li>\n  <li>한글 검색의 정확성과 유연성을 높이기 위해 <a href=\"https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis-nori-tokenizer.html\">Nori Tokenizer</a>와 <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-edgengram-tokenfilter.html\">Edge N-gram</a> 필터를 활용해 띄어쓰기나 일부 단어만으로도 검색이 가능하도록 설정</li>\n</ul>\n\n<p>또한, LIKE 질의를 사용하는 기존 DB 검색과 ES 검색의 결과를 비교한 POC 결과는 다음과 같습니다.\n<img src=\"/images/es-dev/es0-2.png\" alt=\"es-start\" /></p>\n\n<p>결과를 통해 볼 수 있듯이, 정확하지 않은 키워드로 검색했을 때도 기존 DB의 LIKE 질의보다 ES 검색이 훨씬 더 나은 결과를 제공하는 것을 확인할 수 있었습니다.</p>\n\n<p>비용 증가와 관리 포인트가 늘어남에도 불구하고 앞서 언급한 문제들이 해소되었고 검색 품질을 크게 항상시킬 수 있을거 같아 검색 엔진 도입을 최종적으로 결정하게 되었습니다!</p>\n\n<p>다만, 이번 테스트는 전체 검색어가 아닌 일부 검색어를 대상으로 진행된 POC 였기 때문에, 실제 사용자의 피드백을 바탕으로 지속적인 수정과 개선이 필요할 것으로 예상하고 있었습니다.\n이러한 부분을 미리 인지하고 마음의 준비(?)와 공부를 하고 있었죠.</p>\n\n<h1 id=\"개선-작업\">개선 작업</h1>\n<h2 id=\"1-가중치-조절-및-n-gram-조정\">1) 가중치 조절 및 N-gram 조정</h2>\n<h3 id=\"이슈-및-원인-분석\">이슈 및 원인 분석</h3>\n<p>검색 엔진을 적용한 후에 아래와 같은 피드백이 들어왔습니다.\n<img src=\"/images/es-dev/es1-1.png\" alt=\"es-bacon-result\" /></p>\n\n<p>주문하려고 했던 품목은 <code class=\"language-plaintext highlighter-rouge\">통베이컨(에스푸드)</code>였지만, <code class=\"language-plaintext highlighter-rouge\">통베</code>, <code class=\"language-plaintext highlighter-rouge\">통베이</code> 키워드로 검색했을 때 상위에 노출되지 않는다는 이슈였습니다.\n이 문제를 해결하기 위해, 우선 <code class=\"language-plaintext highlighter-rouge\">통베</code>라는 검색어를 중심으로 원인을 분석해보았습니다.</p>\n\n<p>문제 원인 파악을 위해 <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-analyze.html\">_analyze</a> API를 활용하여 name 필드에 적용된 분석기(analyzer)가 검색어를 어떻게 토큰화하는지 살펴보았습니다.</p>\n\n<div class=\"language-json highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"err\">GET</span><span class=\"w\"> </span><span class=\"err\">product/_analyze</span><span class=\"w\">\n</span><span class=\"p\">{</span><span class=\"w\">\n  </span><span class=\"nl\">\"field\"</span><span class=\"w\"> </span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"name\"</span><span class=\"p\">,</span><span class=\"w\">\n  </span><span class=\"nl\">\"text\"</span><span class=\"w\"> </span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"통베이컨(에스푸드)\"</span><span class=\"w\">\n</span><span class=\"p\">}</span><span class=\"w\">\n\n</span><span class=\"err\">Response</span><span class=\"w\">\n</span><span class=\"p\">{</span><span class=\"w\">\n  </span><span class=\"nl\">\"response\"</span><span class=\"p\">:{</span><span class=\"w\">\n    </span><span class=\"nl\">\"tokens\"</span><span class=\"p\">:[</span><span class=\"w\">\n      </span><span class=\"p\">{</span><span class=\"w\">\n        </span><span class=\"nl\">\"token\"</span><span class=\"p\">:</span><span class=\"s2\">\"통\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"start_offset\"</span><span class=\"p\">:</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"end_offset\"</span><span class=\"p\">:</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"word\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"position\"</span><span class=\"p\">:</span><span class=\"mi\">0</span><span class=\"w\">\n      </span><span class=\"p\">},</span><span class=\"w\">\n      </span><span class=\"p\">{</span><span class=\"w\">\n        </span><span class=\"nl\">\"token\"</span><span class=\"p\">:</span><span class=\"s2\">\"베이컨\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"start_offset\"</span><span class=\"p\">:</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"end_offset\"</span><span class=\"p\">:</span><span class=\"mi\">4</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"word\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"position\"</span><span class=\"p\">:</span><span class=\"mi\">1</span><span class=\"w\">\n      </span><span class=\"p\">},</span><span class=\"w\">\n      </span><span class=\"p\">{</span><span class=\"w\">\n        </span><span class=\"nl\">\"token\"</span><span class=\"p\">:</span><span class=\"s2\">\"에스\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"start_offset\"</span><span class=\"p\">:</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"end_offset\"</span><span class=\"p\">:</span><span class=\"mi\">7</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"word\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"position\"</span><span class=\"p\">:</span><span class=\"mi\">2</span><span class=\"w\">\n      </span><span class=\"p\">},</span><span class=\"w\">\n      </span><span class=\"p\">{</span><span class=\"w\">\n        </span><span class=\"nl\">\"token\"</span><span class=\"p\">:</span><span class=\"s2\">\"푸드\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"start_offset\"</span><span class=\"p\">:</span><span class=\"mi\">7</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"end_offset\"</span><span class=\"p\">:</span><span class=\"mi\">9</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"word\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"position\"</span><span class=\"p\">:</span><span class=\"mi\">3</span><span class=\"w\">\n      </span><span class=\"p\">}</span><span class=\"w\">\n    </span><span class=\"p\">]</span><span class=\"w\">\n  </span><span class=\"p\">}</span><span class=\"w\">\n</span><span class=\"p\">}</span><span class=\"w\">\n</span></code></pre></div></div>\n\n<p>결과는 [<code class=\"language-plaintext highlighter-rouge\">통</code>, <code class=\"language-plaintext highlighter-rouge\">베이컨</code>, <code class=\"language-plaintext highlighter-rouge\">에스</code>, <code class=\"language-plaintext highlighter-rouge\">푸드</code>] 로 예측 가능하게 나오네요.</p>\n\n<p>그러나 문제의 검색어인 통베는 다음과 같이 토큰화되었습니다:\n[<code class=\"language-plaintext highlighter-rouge\">통</code>, <code class=\"language-plaintext highlighter-rouge\">베</code>, <code class=\"language-plaintext highlighter-rouge\">베</code>, <code class=\"language-plaintext highlighter-rouge\">어</code>]</p>\n\n<p>잠깐 <code class=\"language-plaintext highlighter-rouge\">어</code> 는 뭐지? 라고 생각하실 수 있는데요. <code class=\"language-plaintext highlighter-rouge\">통베</code>라는 단어 어디에도 <code class=\"language-plaintext highlighter-rouge\">어</code> 라는 단어는 찾아볼 수 없기 때문이죠.</p>\n\n<p>이는 ES의 Nori Tokenizer 가 한국어 문장에서 어미를 추출하는 방식을 따라 토큰화하기 때문입니다.\n예를 들어, “강아지가 밥을 먹습니다”라는 문장은 [<code class=\"language-plaintext highlighter-rouge\">강아지</code>, <code class=\"language-plaintext highlighter-rouge\">가</code>, <code class=\"language-plaintext highlighter-rouge\">밥</code>, <code class=\"language-plaintext highlighter-rouge\">을</code>, <code class=\"language-plaintext highlighter-rouge\">먹</code>, <code class=\"language-plaintext highlighter-rouge\">습니다</code>]로 명사와 어미를 구분하여 토큰화됩니다.\n따라서 정확히 알기는 어렵지만 <code class=\"language-plaintext highlighter-rouge\">어</code>는 Nori Tokenizer 가 <code class=\"language-plaintext highlighter-rouge\">베</code>에서 어미로 분리한 결과로 예상하고 있어요.</p>\n\n<p>이런 토큰화 방식을 보고 Nori Tokenizer 의 토큰화는 단어별로 검색하는 패턴이 많은 저희 서비스에서 예측 불가능할 수 있겠다라는 깨달음을 얻었어요.\n하지만 Nori를 아예 제거하기엔 Nori 가 해주는 명사 추출의 이점이 있을 수 있어 조심스러웠습니다.\n결론적으로, Nori 기능을 완전히 제거하는 대신, 다른 접근을 시도하기로 했습니다.</p>\n\n<h3 id=\"쿼리-가중치-조절-poc\">쿼리 가중치 조절 POC</h3>\n<p>문제 해결을 위해 쿼리의 가중치를 조절해보기로 했습니다.\n기존엔 쿼리 가중치를 순수 Nori Tokenizer 가 적용된 <code class=\"language-plaintext highlighter-rouge\">name</code> 필드와 Nori Tokenizer 와 N-gram filter 가 적용된 <code class=\"language-plaintext highlighter-rouge\">name.ngram</code> 필드에 각각 10과 5 를 주고 있었는데요.\n따라서 N-gram 에 의해 검색된 품목보다 순수 Nori 에 의해 검색된 품목의 유사도가 높아져 상위에 올라가게 됩니다.</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">통베</code> 라고 검색했을때 <code class=\"language-plaintext highlighter-rouge\">통베이컨(에스푸드)</code> 품목이 올라오기 위한 가중치 조절과 N-gram Filter 조정이 필요해보였습니다.\n<img src=\"/images/es-dev/es1-2.jpeg\" alt=\"sapjil\" />\n최적의 가중치와 N-gram Filter 설정을 찾기 위해 통베이컨 품목을 기준으로 <del>삽질을</del> 테스트를 아래와 같이 해보았는데요.</p>\n\n<p><img src=\"/images/es-dev/es1-3.png\" alt=\"es-ngram\" />\n<img src=\"/images/es-dev/es1-4.png\" alt=\"es-ngram\" /></p>\n\n<p>Nori Tokenizer 에만 의존하기에는 무리가 있을거 같아 ES 기본 Tokenizer 인 <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-standard-tokenizer.html\">Standard Tokenizer</a> 도 추가해서 테스트 해봤습니다. \n가중치의 경우, 순수 Nori 인 <code class=\"language-plaintext highlighter-rouge\">nori</code> 와 N-gram 을 적용한 <code class=\"language-plaintext highlighter-rouge\">ngram</code>, <code class=\"language-plaintext highlighter-rouge\">standard</code> 필드의 가중치를 조정해보며 각각 2.0, 3.0, 2.0 일 때 <code class=\"language-plaintext highlighter-rouge\">통베이컨(에스푸드)</code>와 <code class=\"language-plaintext highlighter-rouge\">세척당근</code>이 가장 잘 검색되는 것을 확인 했습니다.</p>\n\n<p>여기에서 Edge N-gram 에 대해서 간단히 설명드리자면요.</p>\n<div class=\"language-json highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"p\">{</span><span class=\"w\">\n  </span><span class=\"nl\">\"min_gram\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"1\"</span><span class=\"p\">,</span><span class=\"w\">\n  </span><span class=\"nl\">\"max_gram\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"3\"</span><span class=\"p\">,</span><span class=\"w\">\n  </span><span class=\"nl\">\"side\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"front\"</span><span class=\"p\">,</span><span class=\"w\">\n  </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"edge_ngram\"</span><span class=\"w\">\n</span><span class=\"p\">}</span><span class=\"w\">\n</span></code></pre></div></div>\n<ul>\n  <li>min_gram : 최소 토큰 길이</li>\n  <li>max_gram : 최대 토큰 길이</li>\n  <li>side : 단어의 어느 부분부터 토큰화 할지 설정(front/back)</li>\n</ul>\n\n<p>side 가 front 인 위 예시로 <code class=\"language-plaintext highlighter-rouge\">안녕하세요</code>를 토큰화해보면 [<code class=\"language-plaintext highlighter-rouge\">안</code>, <code class=\"language-plaintext highlighter-rouge\">안녕</code>, <code class=\"language-plaintext highlighter-rouge\">안녕하</code>]로 토큰화되고 side 가 back 일 경우엔 [<code class=\"language-plaintext highlighter-rouge\">요</code>, <code class=\"language-plaintext highlighter-rouge\">세요</code>, <code class=\"language-plaintext highlighter-rouge\">하세요</code>]로 토큰화 됩니다.\n때문에 front 의 경우 주로 첫 글자부터 검색하는 자동완성과 같은 곳에서 사용하고 back 은 주로 뒷글자부터 검색하는 경우, 예를들면 영어로 ion 을 검색했을 때 action, station, evolution 같은 것들을 검색할 때 유용하게 사용할 수 있을거예요.</p>\n\n<p>저희는 식자재 검색라는 특성이 있어 <code class=\"language-plaintext highlighter-rouge\">통베</code>, <code class=\"language-plaintext highlighter-rouge\">세척당</code>과 같이 앞글자부터 검색하는 경우가 많기 때문에 back 은 제거하고 front 만 남기기로 했습니다. max_gram 도 기존엔 5로 토큰화가 많이 되어 오히려 정확성을 떨어트리는 것을 발견했고 적절해보이는 3으로 조정했습니다.</p>\n\n<h3 id=\"결론\">결론</h3>\n<p>결론적으로 아래 조정 작업으로 문제가 되었던 품목이 검색 상위에 안정적으로 노출되도록 검색 품질을 향상시켰습니다.</p>\n<ul>\n  <li>N-gram 조정: <code class=\"language-plaintext highlighter-rouge\">max_gram</code> 값을 5 -&gt; 3으로 하향 조정하고 <code class=\"language-plaintext highlighter-rouge\">side: front</code> 만 사용</li>\n  <li>가중치 조정: Nori, N-gram, Standard 분석기의 가중치를 적절히 분배</li>\n</ul>\n\n<h2 id=\"2-wildcard-검색\">2) Wildcard 검색</h2>\n<h3 id=\"이슈-및-원인-분석-1\">이슈 및 원인 분석</h3>\n<p>위 작업을 배포하고 내부에서 아래와 같은 피드백을 받았습니다.\n<img src=\"/images/es-dev/es2-1.png\" alt=\"es2\" /></p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">칠성사이다/355ml*24캔</code>라는 품목이 있는데도 불구하고 <code class=\"language-plaintext highlighter-rouge\">사이다</code> 라고 검색했을때 검색이 되지 않는 이슈였는데요.\n각 분석기에서 <code class=\"language-plaintext highlighter-rouge\">칠성사이다/355ml*24캔</code>이 토큰화된 결과는 다음과 같았습니다.</p>\n\n<div class=\"language-text highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Nori: 칠성사, 칠, 성사, 이, 다, 355, ml, 24, 캔\n\nN-gram: 칠, 칠성, 칠성사, 칠, 성, 성사, 이, 다, 3, 35, 355, m, ml, 2, 24, 캔\n\nStandard: 칠성사이다, 355ml, 24캔\n</code></pre></div></div>\n<p>결과에서 확인할 수 있듯이, <code class=\"language-plaintext highlighter-rouge\">사이다</code>라는 토큰이 생성되지 않아 검색 결과에서 제외된 것입니다.</p>\n\n<p>위에서 가중치와 N-gram 을 조정했는데도 불구하고 왜 사이다로 토큰화되지 않았을까요?\n이는 N-gram 은 Filter 이기 때문에 Nori 분석기에서 생성된 토큰을 기반으로 토큰을 더 잘게 나누는 필터링을 수행하기 때문이에요.\n즉, Nori 분석기가 사이다를 하나의 단어로 인식하지 못하고 어미(이, 다)로 나누어버렸기 때문에, 사이다라는 토큰 자체가 존재하지 않았던 것이죠,,</p>\n\n<p>만약 칠성고구마였다면 어떻게 되었을까요?</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>nori: [칠성, 고구마, 355, ml, 24, 캔]\n\nngram: [칠, 칠성, 고, 고구, 고구마, 3, 35, 355, m, ml, 2, 24, 캔]\n\nstandard: [칠성고구마, 355ml, 24캔]\n</code></pre></div></div>\n\n<p><img src=\"/images/es-dev/es2-2.jpeg\" alt=\"huguma\" width=\"300\" /></p>\n\n<p>이처럼 명사 단위로 토큰화하기 때문에 <a href=\"https://bitbucket.org/eunjeon/mecab-ko-dic/src/master/\">Nori 명사 사전</a>에 명사 존재 여부에 따라 토큰화가 다르게 됩니다. 명사 사전에 존재하는 품목의 경우, 고구마처럼 검색이 훨씬 매끄러울 수 있을거예요.\n사이다도 명사 사전에 등록되어 있었다면 <code class=\"language-plaintext highlighter-rouge\">칠성사이다</code>도 [<code class=\"language-plaintext highlighter-rouge\">칠성</code>, <code class=\"language-plaintext highlighter-rouge\">사이다</code>] 로 토큰할 수 있었겠죠.</p>\n\n<h3 id=\"user-dictionary\">User Dictionary</h3>\n<p>따라서, <a href=\"https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis-nori-tokenizer.html\">사용자 사전(user_dictionary)</a> 도입을 고려했었는데요. Nori Tokenizer 에게 <code class=\"language-plaintext highlighter-rouge\">사이다</code>는 명사야, 혹은 <code class=\"language-plaintext highlighter-rouge\">칠성사이다</code>는 [<code class=\"language-plaintext highlighter-rouge\">칠성</code>, <code class=\"language-plaintext highlighter-rouge\">사이다</code>] 라고 토큰화 해! 라고 인식할 수 있는 기준을 마련해줄수있는 방법이에요.</p>\n\n<p>하지만 몇가지 한계가 있었어요.</p>\n\n<ul>\n  <li>관리 포인트 증가\n    <ul>\n      <li>관리해야 할 품목의 종류가 너무 많아 어려움이 발생</li>\n      <li>농산물, 곡류, 축산물, 수산물 등 수백에서 수천 가지 품목을 주기적으로 업데이트하기 어려운 환경</li>\n    </ul>\n  </li>\n  <li>표준화되지 않은 품목명\n    <ul>\n      <li>유통사마다 다른 표기 방식으로 인해 같은 품목도 명칭이 다름</li>\n      <li>예: “무”와 “무우”, “샐러드”와 “셀러드” 등 비표준어와 잘못된 외래어 표기</li>\n      <li>이러한 다양한 표기법을 모두 관리하기엔 부담이 큼</li>\n    </ul>\n  </li>\n</ul>\n\n<p>이러한 이유로 사용자 사전을 유지 관리하는 것이 현실적으로 어렵다고 판단하여 다른 접근 방식을 찾기로 했습니다.</p>\n\n<h3 id=\"wildcard-field\">Wildcard Field</h3>\n<p>문제를 다시 분석한 결과, 검색어 자체가 포함된 품목을 반환하는 것이 핵심이라는 점을 확인했습니다.\n이는 마치 DB의 LIKE 쿼리처럼 검색어가 포함된 품목을 반환하는 것이죠.\nES에서는 이러한 기능을 제공하는 <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/7.17/keyword.html#wildcard-field-type\">Wildcard</a> 필드를 활용할 수 있었습니다.</p>\n\n<p>Wildcard 필드를 추가하는 방법은 간단합니다.</p>\n\n<div class=\"language-json highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"p\">{</span><span class=\"w\">\n  </span><span class=\"nl\">\"mappings\"</span><span class=\"p\">:{</span><span class=\"w\">\n    </span><span class=\"nl\">\"properties\"</span><span class=\"p\">:{</span><span class=\"w\">\n      </span><span class=\"nl\">\"name\"</span><span class=\"p\">:{</span><span class=\"w\">\n        </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"text\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"analyzer\"</span><span class=\"p\">:</span><span class=\"s2\">\"korean\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"fields\"</span><span class=\"p\">:{</span><span class=\"w\">\n          </span><span class=\"err\">//</span><span class=\"w\"> </span><span class=\"err\">..</span><span class=\"w\"> </span><span class=\"err\">생략</span><span class=\"w\">\n          </span><span class=\"nl\">\"wildcard\"</span><span class=\"p\">:{</span><span class=\"w\">\n            </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"wildcard\"</span><span class=\"w\">\n          </span><span class=\"p\">}</span><span class=\"w\">\n        </span><span class=\"p\">}</span><span class=\"w\">\n      </span><span class=\"p\">}</span><span class=\"w\">\n      </span><span class=\"err\">//..</span><span class=\"w\"> </span><span class=\"err\">생략</span><span class=\"w\">\n    </span><span class=\"p\">}</span><span class=\"w\">\n  </span><span class=\"p\">}</span><span class=\"w\">\n</span><span class=\"p\">}</span><span class=\"w\">\n</span></code></pre></div></div>\n\n<p>Wildcard 필드는 역색인 구조가 아닌 패턴 매칭 방식을 사용하기 때문에 성능 문제가 발생할 수 있어서 신중히 사용해야 합니다. 모든 토큰을 검사해야 하기 때문에 데이터가 많아질수록 메모리 사용량이 많아지고 성능이 떨어질 수 있습니다.\n따라서 Wildcard 필드 대신 정교한 N-gram 을 사용하거나 Query-String 쿼리를 권장합니다.</p>\n\n<p>하지만 저희는 데이터량이 많지 않고, 필터를 통해 조회되는 데이터 수를 제한할 수 있었기 때문에 성능 부담이 아직까진 크지 않아 Wildcard 필드를 사용하기로 결정했습니다.</p>\n\n<p>Wildcard 필드를 활용한 쿼리는 다음과 같이 구성했습니다:</p>\n<div class=\"language-json highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"p\">{</span><span class=\"w\">\n  </span><span class=\"nl\">\"query\"</span><span class=\"p\">:{</span><span class=\"w\">\n    </span><span class=\"nl\">\"bool\"</span><span class=\"p\">:{</span><span class=\"w\">\n      </span><span class=\"nl\">\"must\"</span><span class=\"p\">:[</span><span class=\"w\">\n        </span><span class=\"p\">{</span><span class=\"w\">\n          </span><span class=\"nl\">\"bool\"</span><span class=\"p\">:{</span><span class=\"w\">\n            </span><span class=\"nl\">\"should\"</span><span class=\"p\">:[</span><span class=\"w\">\n              </span><span class=\"p\">{</span><span class=\"w\">\n                </span><span class=\"nl\">\"wildcard\"</span><span class=\"p\">:{</span><span class=\"w\">\n                  </span><span class=\"nl\">\"name.wildcard\"</span><span class=\"p\">:{</span><span class=\"w\">\n                    </span><span class=\"nl\">\"boost\"</span><span class=\"p\">:</span><span class=\"mf\">100.0</span><span class=\"p\">,</span><span class=\"w\">\n                    </span><span class=\"nl\">\"wildcard\"</span><span class=\"p\">:</span><span class=\"s2\">\"*사이다*\"</span><span class=\"w\">\n                  </span><span class=\"p\">}</span><span class=\"w\">\n                </span><span class=\"p\">}</span><span class=\"w\">\n              </span><span class=\"p\">},</span><span class=\"w\">\n              </span><span class=\"p\">{</span><span class=\"w\">\n                </span><span class=\"nl\">\"multi_match\"</span><span class=\"p\">:{</span><span class=\"w\">\n                  </span><span class=\"nl\">\"fields\"</span><span class=\"p\">:[</span><span class=\"w\">\n                    </span><span class=\"s2\">\"name^3.0\"</span><span class=\"p\">,</span><span class=\"w\">\n                    </span><span class=\"s2\">\"name.ngram^4.0\"</span><span class=\"p\">,</span><span class=\"w\">\n                    </span><span class=\"s2\">\"name.standard^3.0\"</span><span class=\"w\">\n                  </span><span class=\"p\">],</span><span class=\"w\">\n                  </span><span class=\"nl\">\"query\"</span><span class=\"p\">:</span><span class=\"s2\">\"사이다\"</span><span class=\"w\">\n                </span><span class=\"p\">}</span><span class=\"w\">\n              </span><span class=\"p\">}</span><span class=\"w\">\n            </span><span class=\"p\">]</span><span class=\"w\">\n          </span><span class=\"p\">}</span><span class=\"w\">\n        </span><span class=\"p\">}</span><span class=\"w\">\n      </span><span class=\"p\">]</span><span class=\"w\">\n    </span><span class=\"p\">}</span><span class=\"w\">\n  </span><span class=\"p\">}</span><span class=\"w\">\n</span><span class=\"p\">}</span><span class=\"w\">\n</span></code></pre></div></div>\n<p>검색어가 포함된 결과는 상단으로 올리되, 포함된 결과 내에서도 유사도에 맞게 정렬되도록 쿼리를 수정했습니다. 위처럼 할 경우 사이다가 포함된 단어는 100 점을 추가로 받고 match 되는 필드에 따라 점수를 추가로 더해지게 됩니다.</p>\n\n<p>예를들어 <code class=\"language-plaintext highlighter-rouge\">칠성사이다</code> , <code class=\"language-plaintext highlighter-rouge\">칠십성사이다</code> , <code class=\"language-plaintext highlighter-rouge\">칠성사이</code> 라는 품목이 있을때, <code class=\"language-plaintext highlighter-rouge\">사이다</code> 라고 검색하면 wildcard 에 의해 <code class=\"language-plaintext highlighter-rouge\">칠성사이다</code>, <code class=\"language-plaintext highlighter-rouge\">칠십성사이다</code> 가 가장 상단으로 나오게 될테고, 품목의 이름이 더 짧아 유사도가 더 높은 <code class=\"language-plaintext highlighter-rouge\">칠성사이다</code> 가 최상단으로 나오게 될거예요.\n기존의 가중치는 유지하되 검색어가 포함된 결과만 올리기 위한 쿼리입니다.</p>\n\n<h3 id=\"결론-1\">결론</h3>\n<ul>\n  <li>User Dictionary 도입을 고려했으나 유지보수에 대한 한계로 제외</li>\n  <li>Wildcard 필드와 쿼리로 검색어가 포함된 품목의 점수를 높임</li>\n</ul>\n\n<h2 id=\"3-초성-검색-feat-icu\">3) 초성 검색 feat. ICU</h2>\n<p>Wildcard 검색까지 구현하고 나니 검색 되지 않는 품목 없이 꽤 안정화된 검색 결과를 제공할 수 있었는데요. 더 편리한 검색을 위한 초성 검색 니즈가 들어 왔습니다.</p>\n\n<h3 id=\"어떤-extension-을-사용할-것인가\">어떤 extension 을 사용할 것인가</h3>\n<p>초성검색을 위해 지금 시스템에 도입할 수 있고, 적당한 레퍼런스가 있는 두가지 extension으로 POC 를 진행해봤어요.</p>\n<ol>\n  <li><a href=\"https://github.com/netcrazy/elasticsearch-jaso-analyzer\">elasticsearch-jaso-analyzer</a>(이하 JASO)</li>\n  <li><a href=\"https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis-icu.html\">analysis-icu</a>(이하 ICU)</li>\n</ol>\n\n<p>결론적으로 ICU 를 선택했는데요, JASO 에 대한 설명이 너무 길어질거 같아 자세한 설정 방법과 설명은 위 주소에서 참고주시길 바랍니다.\n두 분석기를 비교한 결과는 아래 표로 정리되었습니다.</p>\n\n<p><img src=\"/images/es-dev/es3-1.png\" alt=\"jaso-icu-analyzer\" /></p>\n<ol>\n  <li>개발 난이도\n    <ul>\n      <li>JASO: <code class=\"language-plaintext highlighter-rouge\">\"chosung\"</code> 옵션만 추가하면 간단히 초성 검색이 가능</li>\n      <li>ICU: 직접 초성 필터를 구현해야 하는 추가 작업 필요</li>\n    </ul>\n  </li>\n  <li>유지보수 및 확장성\n    <ul>\n      <li>JASO: 커스텀 확장(extension)으로 기본 제공되지 않기 때문에, 사용하는 ES 버전과 플랜에 따라 제약이 있을 수 있음</li>\n      <li>ICU: 기본 확장(extension)으로 계속 지원되며, 다른 기능으로의 확장이 자유로움</li>\n    </ul>\n  </li>\n  <li>버전 지원\n    <ul>\n      <li>JASO: Elasticsearch 8.6.2까지만 지원. 이후 버전은 직접 설정 필요</li>\n      <li>ICU: 최신 버전까지 지원</li>\n    </ul>\n  </li>\n  <li>토큰 생성 방식\n    <ul>\n      <li>JASO: 영어 오타 교정, 쌍자음 분리 등 추가 기능 지원</li>\n      <li>ICU: 필요에 따라 초성 검색뿐만 아니라 다양한 확장 가능</li>\n    </ul>\n  </li>\n</ol>\n\n<p>JASO 가 더 많은 옵션을 제공한다는 이점이 있지만 불필요한 토큰이 생성되고 큰 <code class=\"language-plaintext highlighter-rouge\">max_gram</code>을 주어 토큰을 많이 생성해야 된다는 점,\n유지보수를 직접 해야된다는 점에서 ICU extension 을 직접 확장하여 사용하기로 하였습니다.</p>\n\n<h3 id=\"icu-analyzer\">ICU Analyzer</h3>\n<p>그럼, ICU analyzer 의 설정을 좀더 자세히 살펴보겠습니다.</p>\n\n<div class=\"language-json highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"p\">{</span><span class=\"w\">\n    </span><span class=\"nl\">\"orderable_vendor_product_v4\"</span><span class=\"p\">:{</span><span class=\"w\">\n        </span><span class=\"nl\">\"aliases\"</span><span class=\"p\">:{</span><span class=\"w\">\n            </span><span class=\"nl\">\"orderable_vendor_product\"</span><span class=\"p\">:{}</span><span class=\"w\">\n        </span><span class=\"p\">},</span><span class=\"w\">\n        </span><span class=\"nl\">\"mappings\"</span><span class=\"p\">:{</span><span class=\"w\">\n            </span><span class=\"nl\">\"properties\"</span><span class=\"p\">:{</span><span class=\"w\">\n                </span><span class=\"err\">//</span><span class=\"w\"> </span><span class=\"err\">..</span><span class=\"w\"> </span><span class=\"err\">생략</span><span class=\"w\">\n                </span><span class=\"nl\">\"name\"</span><span class=\"p\">:{</span><span class=\"w\">\n                    </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"text\"</span><span class=\"p\">,</span><span class=\"w\">\n                    </span><span class=\"nl\">\"fields\"</span><span class=\"p\">:{</span><span class=\"w\">\n                        </span><span class=\"nl\">\"icu\"</span><span class=\"p\">:{</span><span class=\"w\">\n                            </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"text\"</span><span class=\"p\">,</span><span class=\"w\">\n                            </span><span class=\"nl\">\"analyzer\"</span><span class=\"p\">:</span><span class=\"s2\">\"icu_analyzer\"</span><span class=\"p\">,</span><span class=\"w\">\n                            </span><span class=\"nl\">\"search_analyzer\"</span><span class=\"p\">:</span><span class=\"s2\">\"icu_search_analyzer\"</span><span class=\"p\">,</span><span class=\"w\">\n                            </span><span class=\"nl\">\"similarity\"</span><span class=\"p\">:</span><span class=\"s2\">\"scripted_no_idf\"</span><span class=\"w\">\n                        </span><span class=\"p\">}</span><span class=\"w\">\n                    </span><span class=\"p\">}</span><span class=\"w\">\n                </span><span class=\"p\">}</span><span class=\"w\">\n            </span><span class=\"p\">}</span><span class=\"w\">\n        </span><span class=\"p\">}</span><span class=\"w\">\n    </span><span class=\"p\">},</span><span class=\"w\">\n    </span><span class=\"nl\">\"template\"</span><span class=\"p\">:{</span><span class=\"w\">\n        </span><span class=\"nl\">\"settings\"</span><span class=\"p\">:{</span><span class=\"w\">\n            </span><span class=\"nl\">\"index\"</span><span class=\"p\">:{</span><span class=\"w\">\n                </span><span class=\"nl\">\"analysis\"</span><span class=\"p\">:{</span><span class=\"w\">\n                    </span><span class=\"nl\">\"filter\"</span><span class=\"p\">:{</span><span class=\"w\">\n                        </span><span class=\"err\">//</span><span class=\"w\"> </span><span class=\"err\">..</span><span class=\"w\"> </span><span class=\"err\">생략</span><span class=\"w\">\n                        </span><span class=\"nl\">\"ngram_filter\"</span><span class=\"p\">:{</span><span class=\"w\">\n                            </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"ngram\"</span><span class=\"p\">,</span><span class=\"w\">\n                            </span><span class=\"nl\">\"min_gram\"</span><span class=\"p\">:</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"w\">\n                            </span><span class=\"nl\">\"max_gram\"</span><span class=\"p\">:</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"w\">\n                            </span><span class=\"nl\">\"token_chars\"</span><span class=\"p\">:[</span><span class=\"w\">\n                                </span><span class=\"s2\">\"letter\"</span><span class=\"p\">,</span><span class=\"w\">\n                                </span><span class=\"s2\">\"digit\"</span><span class=\"w\">\n                            </span><span class=\"p\">]</span><span class=\"w\">\n                        </span><span class=\"p\">}</span><span class=\"w\">\n                    </span><span class=\"p\">},</span><span class=\"w\">\n                    </span><span class=\"nl\">\"analyzer\"</span><span class=\"p\">:{</span><span class=\"w\">\n                        </span><span class=\"err\">//</span><span class=\"w\"> </span><span class=\"err\">..</span><span class=\"w\"> </span><span class=\"err\">생략</span><span class=\"w\">\n                        </span><span class=\"nl\">\"icu_analyzer\"</span><span class=\"p\">:{</span><span class=\"w\">\n                            </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"custom\"</span><span class=\"p\">,</span><span class=\"w\">\n                            </span><span class=\"nl\">\"filter\"</span><span class=\"p\">:[</span><span class=\"w\">\n                                </span><span class=\"s2\">\"lowercase\"</span><span class=\"p\">,</span><span class=\"w\">\n                                </span><span class=\"s2\">\"ngram_filter\"</span><span class=\"w\">\n                            </span><span class=\"p\">],</span><span class=\"w\">\n                            </span><span class=\"nl\">\"char_filter\"</span><span class=\"p\">:[</span><span class=\"w\">\n                                </span><span class=\"s2\">\"nfd_normalizer\"</span><span class=\"p\">,</span><span class=\"w\">\n                                </span><span class=\"s2\">\"make_chosung_filter\"</span><span class=\"w\">\n                            </span><span class=\"p\">],</span><span class=\"w\">\n                            </span><span class=\"nl\">\"tokenizer\"</span><span class=\"p\">:</span><span class=\"s2\">\"icu_tokenizer\"</span><span class=\"w\">\n                        </span><span class=\"p\">},</span><span class=\"w\">\n                        </span><span class=\"nl\">\"icu_search_analyzer\"</span><span class=\"p\">:{</span><span class=\"w\">\n                            </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"custom\"</span><span class=\"p\">,</span><span class=\"w\">\n                            </span><span class=\"nl\">\"filter\"</span><span class=\"p\">:[</span><span class=\"w\">\n                                </span><span class=\"s2\">\"lowercase\"</span><span class=\"p\">,</span><span class=\"w\">\n                                </span><span class=\"s2\">\"ngram_filter\"</span><span class=\"w\">\n                            </span><span class=\"p\">],</span><span class=\"w\">\n                            </span><span class=\"nl\">\"char_filter\"</span><span class=\"p\">:[</span><span class=\"w\">\n                                </span><span class=\"s2\">\"chosung_only_filter\"</span><span class=\"p\">,</span><span class=\"w\">\n                                </span><span class=\"s2\">\"nfd_normalizer\"</span><span class=\"w\">\n                            </span><span class=\"p\">],</span><span class=\"w\">\n                            </span><span class=\"nl\">\"tokenizer\"</span><span class=\"p\">:</span><span class=\"s2\">\"icu_tokenizer\"</span><span class=\"w\">\n                        </span><span class=\"p\">}</span><span class=\"w\">\n                    </span><span class=\"p\">},</span><span class=\"w\">\n                    </span><span class=\"nl\">\"char_filter\"</span><span class=\"p\">:{</span><span class=\"w\">\n                        </span><span class=\"nl\">\"nfd_normalizer\"</span><span class=\"p\">:{</span><span class=\"w\">\n                            </span><span class=\"nl\">\"mode\"</span><span class=\"p\">:</span><span class=\"s2\">\"decompose\"</span><span class=\"p\">,</span><span class=\"w\">\n                            </span><span class=\"nl\">\"name\"</span><span class=\"p\">:</span><span class=\"s2\">\"nfkc\"</span><span class=\"p\">,</span><span class=\"w\">\n                            </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"icu_normalizer\"</span><span class=\"w\">\n                        </span><span class=\"p\">},</span><span class=\"w\">\n                        </span><span class=\"nl\">\"make_chosung_filter\"</span><span class=\"p\">:{</span><span class=\"w\">\n                            </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"pattern_replace\"</span><span class=\"p\">,</span><span class=\"w\">\n                            </span><span class=\"nl\">\"pattern\"</span><span class=\"p\">:</span><span class=\"s2\">\"[^</span><span class=\"se\">\\u</span><span class=\"s2\">1100-</span><span class=\"se\">\\u</span><span class=\"s2\">1112^0-9a-zA-Z가-힣ㄱ-ㅎ ㅏ-ㅑ]\"</span><span class=\"p\">,</span><span class=\"w\">\n                            </span><span class=\"nl\">\"replacement\"</span><span class=\"p\">:</span><span class=\"s2\">\"\"</span><span class=\"w\">\n                        </span><span class=\"p\">},</span><span class=\"w\">\n                        </span><span class=\"nl\">\"chosung_only_filter\"</span><span class=\"p\">:{</span><span class=\"w\">\n                            </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"pattern_replace\"</span><span class=\"p\">,</span><span class=\"w\">\n                            </span><span class=\"nl\">\"pattern\"</span><span class=\"p\">:</span><span class=\"s2\">\"[^ㄱ-ㅎa-zA-Z0-9]\"</span><span class=\"p\">,</span><span class=\"w\">\n                            </span><span class=\"nl\">\"replacement\"</span><span class=\"p\">:</span><span class=\"s2\">\"\"</span><span class=\"w\">\n                        </span><span class=\"p\">}</span><span class=\"w\">\n                    </span><span class=\"p\">}</span><span class=\"w\">\n                    </span><span class=\"err\">//..</span><span class=\"w\"> </span><span class=\"err\">생략</span><span class=\"w\"> </span><span class=\"err\">Tokenizer</span><span class=\"w\">\n                </span><span class=\"p\">}</span><span class=\"w\">\n            </span><span class=\"p\">}</span><span class=\"w\">\n        </span><span class=\"p\">}</span><span class=\"w\">\n    </span><span class=\"p\">}</span><span class=\"w\">\n</span><span class=\"p\">}</span><span class=\"w\">\n</span></code></pre></div></div>\n\n<p>위 analzyer 를 그림으로 나타내면 아래와 같습니다.</p>\n\n<p><img src=\"/images/es-dev/es3-2.png\" alt=\"icu-analzyer\" /></p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">icu</code> field 를 보시면 <code class=\"language-plaintext highlighter-rouge\">analyzer</code> 와 <code class=\"language-plaintext highlighter-rouge\">search_analyzer</code> 를 구분해서 설정해준걸 보실 수 있는데요.</p>\n<ul>\n  <li>Analyzer : 저장되는 document 에 대해서 토큰화하여 그림과 같이 역색인화 구조로 저장합니다.</li>\n  <li>Search Analyzer : 검색어에 대해서 토큰화를 수행해서 저장되어 있는 토큰을 검색해서 결과를 내는 역할을 합니다.</li>\n</ul>\n\n<p>기존엔 Analyzer 와 Search Analyzer 를 구분해서 지정해줄 필요가 없었지만 초성 검색의 경우엔 초성으로 검색 했을 때만 초성 검색이 되길 바랬었는데요.\n예를 들어 초성이 아닌 <code class=\"language-plaintext highlighter-rouge\">통베이컨</code>을 Analyzer 로 검색했을 경우, <code class=\"language-plaintext highlighter-rouge\">ㅌㅂㅇㅋ</code> 으로 초성화 될 것이고 사용자가 초성 검색을 하지 않았는데도 초성을 포함하는 품목이 많이 나오게 될 것 입니다. \n그래서 최대한 기존의 쿼리 score 에는 영향이 가지 않고 초성 검색을 했을때만 초성으로 품목을 찾기 위해서 초성을 제외한 글자는 모두 제거하는 필터를 넣는 Search Analyzer 를 따로 지정해주었습니다.\n즉, <code class=\"language-plaintext highlighter-rouge\">통베이컨</code>이 Search Analyzer 를 거치게 되면 아무 토큰도 생성되지 않게 되어 초성 검색에 대해서는 수행이 되지 않게 되는거죠.</p>\n\n<p><a href=\"https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis-icu-normalization-charfilter.html\">ICU_Normalizer</a> 에 대한 설정은 문서를 보시면 더 자세히 볼 수 있을거예요.\n요약하자면 유니코드의 정규화(Normalization)를 수행하는 역할을 합니다.</p>\n\n<p>저희는 <code class=\"language-plaintext highlighter-rouge\">decompose</code> 옵션을 사용하여 <code class=\"language-plaintext highlighter-rouge\">통</code>이라는 글자를 <code class=\"language-plaintext highlighter-rouge\">ㅌㅗㅇ</code> 으로 문자를 분해할 수 있도록 했고, <code class=\"language-plaintext highlighter-rouge\">NFKC(Normalization Form Compatibility Composition)</code> 옵션을 사용하여 호환가능한 문자를 호환시키고, 조합 가능한 문자는 조합하도록 설정하였습니다.\n즉, <code class=\"language-plaintext highlighter-rouge\">통베이컨™①é</code>를 정규화하면 <code class=\"language-plaintext highlighter-rouge\">ㅌㅗㅇㅂㅔㅇㅣㅋㅓㄴTM1é</code>로 정규화 됩니다. \n초성검색 구현을 위해선 정규화 방식보다는 초성 분리를 위한 mode 를 잘 설정하는게 더 핵심이라고 할 수 있을거예요.</p>\n\n<p>요약하면 품목을 ICU Normalizer 를 활용하여 초성 토큰 형태로 저장하고, 초성 검색어에 대해서만 초성 검색을 수행할 수 있도록 Search Analyzer 를 구분하여 구현해주었습니다.</p>\n\n<p>ICU 는 JASO와 비교했을 때 초기 구현은 다소 복잡했지만, 유지보수와 추후 확장성 측면에서 더 적합한 선택이었으면 합니다!! (Extension 교체 작업만은 다시 하고 싶지 않아요..)</p>\n\n<h3 id=\"idf-제외\">IDF 제외</h3>\n<p>이제 마지막 개선 작업이네요.\n잘 운영하고 있던 중 아래와 같은 의견이 들어왔습니다.</p>\n\n<h3 id=\"이슈-및-원인-분석-2\">이슈 및 원인 분석</h3>\n<p><img src=\"/images/es-dev/es4-1.png\" alt=\"es-sweetcorn\" /></p>\n\n<p>사용자가 스위트콘을 검색하려 했으나 스위트곤으로 오타가 발생한 경우, 기대했던 스위트콘이 아닌 곤약이 상위에 노출되는 문제가 있었습니다.\n일반적으로 사용자가 기대하는 결과와는 다른 결과였죠.</p>\n\n<p>다행히도 로컬 테스트 환경에서 원인 분석을 해볼 수 있었는데요, 그런데 조금 충격적이게도 로컬에선 스위트콘이 더 상위노출 되었습니다. 이럴수가..</p>\n\n<p>그렇다는 것은 로컬 테스트코드와 실제 환경의 검색 결과가 다르다는 것이고, 지금까지의 테스트가 유효한게 맞을까.. 하는 생각이 들었는데요.\n<img src=\"/images/es-dev/es4-2.jpeg\" alt=\"es5\" /></p>\n\n<p>더 자세한 원인을 파악하기 위해 ES의 <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/search-explain.html\">explain</a> API를 사용해 점수 산출 과정을 분석했습니다.</p>\n\n<p>결과를 요약하자면 아래와 같은데요.</p>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">#곤약/면곤약</code>\n    <ul>\n      <li>N-gram Boost : 8.8</li>\n      <li><strong>IDF: 6.05</strong></li>\n      <li>TF: 0.78</li>\n      <li>8.8 * 6.05 * 0.78 = <strong>41.66</strong></li>\n    </ul>\n  </li>\n  <li><code class=\"language-plaintext highlighter-rouge\">스위트콘/리치스/2.95kg</code>\n    <ul>\n      <li>N-gram Boost : 8.8</li>\n      <li><strong>IDF : 3.14</strong></li>\n      <li>TF : 0.81696963</li>\n      <li>8.8 * 3.14 * 0.81696963 = <strong>22.568493</strong></li>\n    </ul>\n  </li>\n</ul>\n\n<p>ES 에서 Boost * IDF * TF 계산 로직을 통해 score 를 산출하고 있었습니다. 곤약이 상위로 올라온 이유는 숫자를 보면 알수있듯 두배 가까이 차이나는 IDF 때문인 것을 파악할 수 있었는데요.</p>\n\n<p>우선 처음 보는 개념인 IDF 와 TF 가 무엇인지 알아보았습니다.</p>\n\n<ul>\n  <li>IDF(Inverse Document Frequency): 특정 단어가 <strong>전체 문서</strong>에서 얼마나 드물게 나타나는지</li>\n  <li>TF(Term Frequency): 특정 단어가 문서 내에서 얼마나 자주 나타나는지</li>\n</ul>\n\n<p>IDF 는 전체 문서를 기준으로 계산되기 때문에 테스트코드와 실제 환경의 결과가 다른 이유가 여기에 있었습니다.\n테스트코드의 테스트를 위해 생성해놓은 문서는 상대적으로 너무나도 적은 양의 데이터이기 때문에 IDF 의 값이 대부분 동일하고 TF 값으로 대부분 유사도가 정해질거예요.\n반면, 테스트코드에 비해 방대한 품목 데이터가 있는 실제 환경에선 곤약과 스위트콘처럼 IDF 의 차이가 클 수 있습니다.</p>\n\n<p>IDF 가 유의미한 결과를 내주기 위해서는 전체 문서가 모두 한 유통사의 품목으로, 품목명의 구조나 맥락이 동일해야 할 것 같은데요.\n하지만 유통사마다 품목명이 모두 제각각인데도 IDF가 모든 유통사의 데이터를 포함한 전체 품목 데이터를 기준으로 계산되면서 오히려 유사도 계산에 역효과를 내고 있었습니다.\n또한, 실제환경과 로컬 환경에서의 테스트 결과가 보장되지 않아 문제 재현 및 원인 파악이 어려워보였습니다.</p>\n\n<p>따라서, <strong>IDF 를 제외</strong>하고 score 계산하는 방법을 알아봤습니다.</p>\n\n<p>IDF를 제외한 점수 계산을 위해 크게 세 가지 방법을 검토해봤습니다.</p>\n\n<h3 id=\"1-점수-고정-constant-score\">1. 점수 고정 (Constant Score)</h3>\n\n<p>첫번째 방법은 아래와 같이 쿼리에 <code class=\"language-plaintext highlighter-rouge\">boost</code> 값을 명시하여 점수를 고정 시키는 <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-constant-score-query.html\">Constant Score Query</a> 를 활용한 방법입니다.</p>\n\n<div class=\"language-json highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"p\">{</span><span class=\"w\">\n  </span><span class=\"nl\">\"query\"</span><span class=\"p\">:{</span><span class=\"w\">\n    </span><span class=\"nl\">\"bool\"</span><span class=\"p\">:{</span><span class=\"w\">\n      </span><span class=\"nl\">\"must\"</span><span class=\"p\">:[</span><span class=\"w\">\n        </span><span class=\"p\">{</span><span class=\"w\">\n          </span><span class=\"nl\">\"bool\"</span><span class=\"p\">:{</span><span class=\"w\">\n            </span><span class=\"nl\">\"should\"</span><span class=\"p\">:[</span><span class=\"w\">\n              </span><span class=\"p\">{</span><span class=\"w\">\n                </span><span class=\"nl\">\"constant_score\"</span><span class=\"p\">:{</span><span class=\"w\">\n                  </span><span class=\"nl\">\"filter\"</span><span class=\"p\">:{</span><span class=\"w\">\n                    </span><span class=\"nl\">\"wildcard\"</span><span class=\"p\">:{</span><span class=\"w\">\n                      </span><span class=\"nl\">\"name.wildcard\"</span><span class=\"p\">:{</span><span class=\"w\">\n                        </span><span class=\"nl\">\"wildcard\"</span><span class=\"p\">:</span><span class=\"s2\">\"*스위트곤*\"</span><span class=\"w\">\n                      </span><span class=\"p\">}</span><span class=\"w\">\n                    </span><span class=\"p\">}</span><span class=\"w\">\n                  </span><span class=\"p\">},</span><span class=\"w\">\n                  </span><span class=\"nl\">\"boost\"</span><span class=\"p\">:</span><span class=\"mf\">100.0</span><span class=\"w\">\n                </span><span class=\"p\">}</span><span class=\"w\">\n              </span><span class=\"p\">},</span><span class=\"w\">\n              </span><span class=\"p\">{</span><span class=\"w\">\n                </span><span class=\"nl\">\"constant_score\"</span><span class=\"p\">:{</span><span class=\"w\">\n                  </span><span class=\"nl\">\"filter\"</span><span class=\"p\">:{</span><span class=\"w\">\n                    </span><span class=\"nl\">\"match\"</span><span class=\"p\">:{</span><span class=\"w\">\n                      </span><span class=\"nl\">\"name\"</span><span class=\"p\">:</span><span class=\"s2\">\"스위트곤\"</span><span class=\"w\">\n                    </span><span class=\"p\">}</span><span class=\"w\">\n                  </span><span class=\"p\">},</span><span class=\"w\">\n                  </span><span class=\"nl\">\"boost\"</span><span class=\"p\">:</span><span class=\"mf\">3.0</span><span class=\"w\">\n                </span><span class=\"p\">}</span><span class=\"w\">\n              </span><span class=\"p\">},</span><span class=\"w\">\n              </span><span class=\"p\">{</span><span class=\"w\">\n                </span><span class=\"nl\">\"constant_score\"</span><span class=\"p\">:{</span><span class=\"w\">\n                  </span><span class=\"nl\">\"filter\"</span><span class=\"p\">:{</span><span class=\"w\">\n                    </span><span class=\"nl\">\"match\"</span><span class=\"p\">:{</span><span class=\"w\">\n                      </span><span class=\"nl\">\"name.ngram\"</span><span class=\"p\">:</span><span class=\"s2\">\"스위트곤\"</span><span class=\"w\">\n                    </span><span class=\"p\">}</span><span class=\"w\">\n                  </span><span class=\"p\">},</span><span class=\"w\">\n                  </span><span class=\"nl\">\"boost\"</span><span class=\"p\">:</span><span class=\"mf\">4.0</span><span class=\"w\">\n                </span><span class=\"p\">}</span><span class=\"w\">\n              </span><span class=\"p\">}</span><span class=\"w\">\n              </span><span class=\"err\">//</span><span class=\"w\"> </span><span class=\"err\">..</span><span class=\"w\"> </span><span class=\"err\">생략</span><span class=\"w\">\n            </span><span class=\"p\">]</span><span class=\"w\">\n          </span><span class=\"p\">}</span><span class=\"w\">\n        </span><span class=\"p\">}</span><span class=\"w\">\n      </span><span class=\"p\">]</span><span class=\"w\">\n    </span><span class=\"p\">}</span><span class=\"w\">\n  </span><span class=\"p\">}</span><span class=\"w\">\n</span><span class=\"p\">}</span><span class=\"w\">\n</span></code></pre></div></div>\n<p>결과를 봤을 때, Boost 만으로 Scoring 되기 때문에 같은 필드에서 검색된 품목은 동일한 점수를 가지는 것을 확인했습니다. \n예를 들어 <code class=\"language-plaintext highlighter-rouge\">name.ngram</code> 로 검색된 품목들은 모두 Boost 4 인 동일한 점수로 정렬이 제대로 되지 않았습니다.</p>\n\n<p>결론적으로, 이 방식은 유사도 기반 정렬이 필요한 우리의 요구사항에 적합하지 않았습니다.</p>\n\n<h3 id=\"2-유사도-모델-변경\">2. 유사도 모델 변경</h3>\n<p>기본적으로 ES는 <code class=\"language-plaintext highlighter-rouge\">Boost * IDF * TF</code> 식을 사용하는 <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-similarity.html#bm25\">BM25(Best Matching 25)</a> 모델을 사용합니다. 이를 대신해 <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-similarity.html#dfr\">DFR(Deviation From Randomness)</a> 모델을 사용해 보았습니다.\nDFR 은 현 document에 얼마나 드물게 등장하는지, 문서 길이에 따라 통계적 랜덤성 기반으로 검색됩니다. type 뿐만 아니라 아래처럼 옵션에 가중치나 옵션을 설정해줄수있습니다.\n아래는 DFR 모델 설정 예시입니다.</p>\n<div class=\"language-json highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"p\">{</span><span class=\"w\">\n  </span><span class=\"nl\">\"settings\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\">\n    </span><span class=\"nl\">\"similarity\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\">\n      </span><span class=\"nl\">\"custom_similarity\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\">\n        </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"DFR\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"basic_model\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"g\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"err\">//</span><span class=\"w\"> </span><span class=\"err\">문서</span><span class=\"w\"> </span><span class=\"err\">내에</span><span class=\"w\"> </span><span class=\"err\">특정</span><span class=\"w\"> </span><span class=\"err\">용어가</span><span class=\"w\"> </span><span class=\"err\">얼마나</span><span class=\"w\"> </span><span class=\"err\">드물게</span><span class=\"w\"> </span><span class=\"err\">발생하는지</span><span class=\"w\">\n        </span><span class=\"nl\">\"after_effect\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"b\"</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"err\">//</span><span class=\"w\"> </span><span class=\"err\">검색어가</span><span class=\"w\"> </span><span class=\"err\">얼마나</span><span class=\"w\"> </span><span class=\"err\">여러번</span><span class=\"w\"> </span><span class=\"err\">등장하는지</span><span class=\"w\">\n        </span><span class=\"nl\">\"normalization\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"h2\"</span><span class=\"w\"> </span><span class=\"err\">//</span><span class=\"w\"> </span><span class=\"err\">문서</span><span class=\"w\"> </span><span class=\"err\">길이에</span><span class=\"w\"> </span><span class=\"err\">따라</span><span class=\"w\"> </span><span class=\"err\">빈도</span><span class=\"w\"> </span><span class=\"err\">설정</span><span class=\"w\">\n      </span><span class=\"p\">}</span><span class=\"w\">\n    </span><span class=\"p\">}</span><span class=\"w\">\n  </span><span class=\"p\">}</span><span class=\"w\">\n</span><span class=\"p\">}</span><span class=\"w\">\n</span></code></pre></div></div>\n\n<p>보시다시피 DFR 모델에 대한 지식이 없으면 유지보수가 무척 어려워보입니다.\n문제가 생기거나 개선의 여지가 생겼을 때 더 복잡한 계산식을 사용하는 모델이기 때문에 쉽게 커스텀하기가 힘들어보이고, 모델의 대한 이해뿐만 아니라 옵션에 대한 각 알고리즘도 알아야하기 때문에 유지보수가 정말 쉽지 않을거라 생각이 들었죠.</p>\n\n<p>우리 팀에 검색 엔진에 대한 전문적인 지식을 가진 분이 없었기 때문에 더 복잡한 모델로 변경하는건 과감하게 제외했습니다.</p>\n\n<h3 id=\"3-scripted-similarity-사용\">3. Scripted Similarity 사용</h3>\n\n<p>IDF를 제외하고 직접 계산식을 정의하는 방법입니다. 아래는 Scripted Similarity 설정 예시입니다.</p>\n\n<div class=\"language-json highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"p\">{</span><span class=\"w\">\n  </span><span class=\"nl\">\"setting\"</span><span class=\"p\">:{</span><span class=\"w\">\n    </span><span class=\"nl\">\"similarity\"</span><span class=\"p\">:{</span><span class=\"w\">\n      </span><span class=\"nl\">\"scripted_no_idf\"</span><span class=\"p\">:{</span><span class=\"w\">\n        </span><span class=\"nl\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"scripted\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"script\"</span><span class=\"p\">:{</span><span class=\"w\">\n          </span><span class=\"nl\">\"source\"</span><span class=\"p\">:</span><span class=\"s2\">\"double tf = Math.sqrt(doc.freq); return query.boost * tf;\"</span><span class=\"w\">\n        </span><span class=\"p\">}</span><span class=\"w\">\n      </span><span class=\"p\">}</span><span class=\"w\">\n    </span><span class=\"p\">}</span><span class=\"w\">\n  </span><span class=\"p\">}</span><span class=\"w\">\n</span><span class=\"p\">}</span><span class=\"w\">\n</span></code></pre></div></div>\n\n<p>위처럼 setting 을 변경하고 쿼리의 explain 을 해보면 script 에 있는 식이 아래와 같이 <code class=\"language-plaintext highlighter-rouge\">idOrCode</code>에 들어가 scoring 되는것을 볼 수 있어요.</p>\n\n<div class=\"language-json highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"err\">Explain</span><span class=\"w\"> </span><span class=\"err\">결과</span><span class=\"w\">\n</span><span class=\"p\">{</span><span class=\"w\">   \n    </span><span class=\"err\">//</span><span class=\"w\"> </span><span class=\"err\">..</span><span class=\"w\"> </span><span class=\"err\">생략</span><span class=\"w\">\n    </span><span class=\"nl\">\"description\"</span><span class=\"p\">:</span><span class=\"s2\">\"sum of:\"</span><span class=\"p\">,</span><span class=\"w\">\n    </span><span class=\"nl\">\"details\"</span><span class=\"p\">:[</span><span class=\"w\">\n        </span><span class=\"p\">{</span><span class=\"w\">\n            </span><span class=\"nl\">\"details\"</span><span class=\"p\">:[</span><span class=\"w\">\n                </span><span class=\"p\">{</span><span class=\"w\">\n                    </span><span class=\"nl\">\"description\"</span><span class=\"p\">:</span><span class=\"s2\">\"score from ScriptedSimilarity(weightScript=[null], script=[Script{type=inline, lang='painless', idOrCode='double tf = Math.sqrt(doc.freq); return query.boost * tf;', options={}, params={}}]) computed from:\"</span><span class=\"p\">,</span><span class=\"w\">\n                    </span><span class=\"nl\">\"details\"</span><span class=\"p\">:[</span><span class=\"w\">\n                        </span><span class=\"err\">//</span><span class=\"w\"> </span><span class=\"err\">..</span><span class=\"w\"> </span><span class=\"err\">생략</span><span class=\"w\">\n                    </span><span class=\"p\">],</span><span class=\"w\">\n                    </span><span class=\"nl\">\"value\"</span><span class=\"p\">:</span><span class=\"mi\">8</span><span class=\"w\">\n                </span><span class=\"p\">}</span><span class=\"w\">\n            </span><span class=\"p\">]</span><span class=\"w\">\n        </span><span class=\"p\">}</span><span class=\"w\">\n        </span><span class=\"err\">//</span><span class=\"w\"> </span><span class=\"err\">..</span><span class=\"w\"> </span><span class=\"err\">생략</span><span class=\"w\">\n    </span><span class=\"p\">]</span><span class=\"w\">\n</span><span class=\"p\">}</span><span class=\"w\">\n\n</span></code></pre></div></div>\n\n<p>위 세가지 방법 중 가장 마지막 방법인 Scripted Similarity 로 계산식을 넣기로 했어요. Scripted Similarity 를 선택한 이유는 다음과 같습니다.</p>\n\n<ol>\n  <li>유연한 계산식 사용\n    <ul>\n      <li>계산식을 직접 조정 가능</li>\n      <li>기존 BM25 모델에서 IDF만 제거할 수 있는 계산식을 직접 부여 가능</li>\n    </ul>\n  </li>\n  <li>유지보수 용이성\n    <ul>\n      <li>계산식이 명확히 노출되어 있어 비교적 수정이 간단</li>\n    </ul>\n  </li>\n  <li>쿼리와 독립적\n    <ul>\n      <li>점수 계산이 쿼리와 독립적으로 이루어져 다른 쿼리 추가 시에도 영향을 받지 않음</li>\n    </ul>\n  </li>\n</ol>\n\n<h3 id=\"scripted-similarity-계산식-결정\">Scripted Similarity 계산식 결정</h3>\n\n<p>그후에는 Scripted Similarity 에 적용할 계산식 결정이 필요했습니다.</p>\n\n<p><strong>후보 1. 단순한 TF 계산식</strong></p>\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">double</span> <span class=\"n\">tf</span> <span class=\"p\">=</span> <span class=\"nc\">Math</span><span class=\"p\">.</span><span class=\"nf\">sqrt</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"p\">.</span><span class=\"n\">freq</span><span class=\"p\">);</span>\n<span class=\"k\">return</span> <span class=\"n\">query</span><span class=\"p\">.</span><span class=\"n\">boost</span> <span class=\"p\">*</span> <span class=\"n\">tf</span><span class=\"p\">;</span>\n\n<span class=\"cm\">/* freq : 문서 내의 토큰 등장 수 */</span>\n</code></pre></div></div>\n\n<p><strong>후보 2. BM 모델과 동일한 TF 계산식</strong></p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">double</span> <span class=\"n\">freq</span> <span class=\"p\">=</span> <span class=\"n\">doc</span><span class=\"p\">.</span><span class=\"n\">freq</span><span class=\"p\">;</span>\n<span class=\"n\">double</span> <span class=\"n\">k1</span> <span class=\"p\">=</span> <span class=\"mf\">1.2</span><span class=\"p\">;</span>\n<span class=\"n\">double</span> <span class=\"n\">b</span> <span class=\"p\">=</span> <span class=\"mf\">0.75</span><span class=\"p\">;</span>\n<span class=\"n\">double</span> <span class=\"n\">dl</span> <span class=\"p\">=</span> <span class=\"n\">doc</span><span class=\"p\">.</span><span class=\"n\">length</span><span class=\"p\">;</span>\n<span class=\"n\">double</span> <span class=\"n\">avgdl</span> <span class=\"p\">=</span> <span class=\"mi\">7</span><span class=\"p\">;</span>\n<span class=\"n\">double</span> <span class=\"n\">tf</span> <span class=\"p\">=</span> <span class=\"n\">freq</span> <span class=\"p\">/</span> <span class=\"p\">(</span><span class=\"n\">freq</span> <span class=\"p\">+</span> <span class=\"n\">k1</span> <span class=\"p\">*</span> <span class=\"p\">(</span><span class=\"mi\">1</span> <span class=\"p\">-</span> <span class=\"n\">b</span> <span class=\"p\">+</span> <span class=\"n\">b</span> <span class=\"p\">*</span> <span class=\"n\">dl</span> <span class=\"p\">/</span> <span class=\"n\">avgdl</span><span class=\"p\">));</span>\n<span class=\"k\">return</span> <span class=\"n\">query</span><span class=\"p\">.</span><span class=\"n\">boost</span> <span class=\"p\">*</span> <span class=\"n\">tf</span><span class=\"p\">;</span>\n\n<span class=\"cm\">/*\n    freq : 문서 내의 토큰 등장 수\n    k1: TF 영향도 가중치\n    b : 문서 길이 보정 파라미터\n    dl : 문서 길이\n    avgdl : 전체 문서의 문서 길이 평균값\n */</span>\n</code></pre></div></div>\n\n<p><img src=\"/images/es-dev/es4-3.png\" alt=\"idf\" />\n<img src=\"/images/es-dev/es4-4.png\" alt=\"idf\" />\n결과만 보았을 때 확실히 IDF 를 포함했을 때보다 IDF 를 제외했을 때 결과가 개선되긴 했지만, 여전히 단순 TF 계산식, BM 모델 계산식의 결과는 크게 차이가 없었습니다.</p>\n\n<p>하지만 위 결과의 정렬은 비슷한듯 하지만 실제 점수는 다릅니다. 단순 TF 의 경우 문서 내의 토큰 등장 수로만 TF 를 계산하기 때문에 동일한 점수를 가진 결과가 다수 나타나 매번 정렬이 달라질 수 있습니다.\n<code class=\"language-plaintext highlighter-rouge\">국산쌀</code>와 <code class=\"language-plaintext highlighter-rouge\">찰떡(쌀 국산)</code>는 단순 TF 계산식에 의하면 둘은 동일한 점수를 반환하게 됩니다.\n반면 BM 모델과 동일한 TF 계산식의 경우, 문서 내 토큰 등장 수와 문서 길이를 함께 고려하기 때문에 저희가 흔히 생각한대로 <code class=\"language-plaintext highlighter-rouge\">국산쌀</code>의 유사도가 더 높은 결과로 나오게 됩니다.</p>\n\n<p>따라서, BM 모델에서 IDF 만 제거한, 후보2 계산식을 사용하기로 결정하였습니다.</p>\n\n<p>다만, <code class=\"language-plaintext highlighter-rouge\">avgdl</code> 를 현재의 기준으로 7로 고정시켜 가중치를 조정했지만 이후 문서의 평균 길이가 변경될 경우엔 유지보수가 필요한 부분이 있을 수 있습니다.\n하지만 <code class=\"language-plaintext highlighter-rouge\">avgdl</code> 가 크게 변하지 않을 것이라는 가정과 점수 계산에 크게 영향을 주지 않는다고 생각해 고정된 계산식으로 가게 되었습니다.</p>\n\n<p>그럼에도 이후에 유지보수가 필요하거나 변경이 필요할 수 있습니다. 꽤 해석이 필요한 계산식을 가지고 있기 때문에\n어떤 계기로 IDF를 제거하게 되었는지, Scripted Similarity 를 왜 적용하게 되었는지, 계산식은 어떻게 결정되었고 어떤 의미인지를 자세히 문서화하도록 노력하였습니다.</p>\n\n<h2 id=\"결과\">결과</h2>\n<p>결과적으로, 아래와 같은 구조를 갖게 되었습니다.</p>\n\n<p><img src=\"/images/es-dev/es5-1.png\" alt=\"final\" /></p>\n\n<p>이러한 구조를 통해 현재 검색 정확도는 어떨까요?</p>\n\n<p>아래는 매장 사이드 관련 데이터입니다.</p>\n<ul>\n  <li>2025년 1월 기준\n    <ul>\n      <li>검색 결과 성공률: 검색 시 하나 이상의 품목이 결과에 노출되는 경우 → <strong>98.6%</strong></li>\n      <li>검색 목적 달성률: 검색한 품목을 선택한 후, 실제 액션(주문 등)을 수행하는 경우 → <strong>73.6%</strong></li>\n    </ul>\n  </li>\n</ul>\n\n<p>이를 통해 상당히 높은 검색 정확도와 달성률을 기록하고 있음을 확인할 수 있습니다.</p>\n\n<p>또한, 아래는 유통사에서 매장의 주문서를 생성할 때, ES 검색이 매우 편리했다는 피드백을 받은 메시지입니다.\n키친보드의 검색 기능이 타 ERP와 달리 오타가 있어도 품목을 정확하게 검색할 수 있어 큰 편리함을 느꼈다고 합니다!</p>\n\n<p><img src=\"/images/es-dev/es5-2.png\" alt=\"final\" />\n<img src=\"/images/es-dev/es5-3.png\" alt=\"final\" /></p>\n\n<p>개발 과정에서 어려움이 있었지만 결국 사용자한테 좋은 영향을 주는 기능을 개발한거 같아 아주 뿌듯하네요!</p>\n\n<h1 id=\"소소한-tip\">소소한 Tip</h1>\n<h2 id=\"중단-시간을-줄인-reindexing\">중단 시간을 줄인 Reindexing</h2>\n<p>ES 의 비용을 최소화하기 위해서 최소한의 리소스로 구동하고 있습니다. 그러다보니 인덱스에 새로운 필드가 추가되거나 설정이 변경되는 개선이 될때마다 인덱스를 새롭게 동기화해야하기 때문에 중단이 불가피했는데요.\n하지만 주문에서의 검색은 점주들이 꼭 해야만하는 중요한 기능이기 때문에 중단을 최소화하고 싶었습니다.</p>\n\n<p>알아보던 중 찾아낸 것은 별칭(Alias)를 이용한 배포입니다.</p>\n\n<p><img src=\"/images/es-dev/es6-1.png\" alt=\"final\" /></p>\n\n<ol>\n  <li><code class=\"language-plaintext highlighter-rouge\">Old Index Template</code> 을 템플릿으로 하여 생성된 <code class=\"language-plaintext highlighter-rouge\">Old Index</code>(별칭: <code class=\"language-plaintext highlighter-rouge\">Product</code>) 가 존재한다.</li>\n  <li>새로운 매핑 정보가 있는 <code class=\"language-plaintext highlighter-rouge\">New Index Template</code> 을 생성한다.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">New Index Template</code> 을 템플릿으로 하여 <code class=\"language-plaintext highlighter-rouge\">New Index</code> 를 생성한다.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">Old Index</code> 의 문서를 <code class=\"language-plaintext highlighter-rouge\">New Index</code> 로 <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-reindex.html\">reindex</a> 한다.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">Old Index</code> 를 삭제한다.</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">New Index</code> 에 <code class=\"language-plaintext highlighter-rouge\">Product</code> alias 를 부여 한다.</li>\n  <li>서버에서 alias 기준으로 쿼리한다.</li>\n</ol>\n\n<p>이렇게 되면 5번과 6번 사이, <code class=\"language-plaintext highlighter-rouge\">Product</code> 를 가진 인덱스가 존재하지 않을 시에만 검색 중단이 발생하게 됩니다.\n이 방법이 가장 좋은 방법이라고 표현하기는 어렵지만 기존 20만개의 품목을 마이그레이션 하느라 10분이 넘는 중단 시간을 3초 정도의 중단 시간으로 낮출 수 있는 방법이었습니다.</p>\n\n<h2 id=\"대량-데이터-조회\">대량 데이터 조회</h2>\n<p>DB 의 품목 데이터와 ES 인덱스 동기화를 위해 하루에 한번씩 스케줄러가 실행됩니다.</p>\n\n<p>DB 품목 데이터가 삭제될 때 ES 데이터도 삭제되어야 하는데 어떠한 이유로 삭제되지 않는 경우가 있었습니다. 즉, 품목이 DB 데이터엔 없지만 ES 데이터에는 있는 경우죠.<br />\n스케줄러에서 전체 ES 인덱스 문서를 조회하고 DB 에 없으면 문서를 삭제해서 동기화해주려고 해요.</p>\n\n<p>다만 전체 문서를 조회하는 과정의 부하가 많이 걱정되긴 했는데요. 그래서 처음엔 페이징을 활용했습니다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code> <span class=\"k\">fun</span> <span class=\"nf\">deleteOrphanDocuments</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">pageSize</span> <span class=\"p\">=</span> <span class=\"mi\">1000</span>\n\n    <span class=\"kd\">var</span> <span class=\"py\">pageable</span> <span class=\"p\">=</span> <span class=\"nc\">PageRequest</span><span class=\"p\">.</span><span class=\"nf\">of</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">pageSize</span><span class=\"p\">,</span> <span class=\"nc\">Sort</span><span class=\"p\">.</span><span class=\"k\">by</span><span class=\"p\">(</span><span class=\"nc\">Sort</span><span class=\"p\">.</span><span class=\"nc\">Order</span><span class=\"p\">.</span><span class=\"nf\">asc</span><span class=\"p\">(</span><span class=\"s\">\"id.keyword\"</span><span class=\"p\">)))</span>\n\n    <span class=\"k\">do</span> <span class=\"p\">{</span>\n        <span class=\"kd\">val</span> <span class=\"py\">indexPage</span> <span class=\"p\">=</span> <span class=\"n\">productIndexRepository</span><span class=\"p\">.</span><span class=\"nf\">findAll</span><span class=\"p\">(</span><span class=\"n\">pageable</span><span class=\"p\">)</span>\n        <span class=\"kd\">val</span> <span class=\"py\">documentProductIds</span> <span class=\"p\">=</span> <span class=\"n\">indexPage</span><span class=\"p\">.</span><span class=\"n\">content</span><span class=\"p\">.</span><span class=\"nf\">map</span> <span class=\"p\">{</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">id</span> <span class=\"p\">}</span>\n\n        <span class=\"kd\">val</span> <span class=\"py\">dbProductIds</span> <span class=\"p\">=</span> <span class=\"n\">productRepository</span><span class=\"p\">.</span><span class=\"nf\">findAllById</span><span class=\"p\">(</span><span class=\"n\">documentProductIds</span><span class=\"p\">).</span><span class=\"nf\">map</span> <span class=\"p\">{</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">id</span> <span class=\"p\">}</span>\n\n        <span class=\"kd\">val</span> <span class=\"py\">documentIdsNotInDB</span> <span class=\"p\">=</span> <span class=\"n\">documentProductIds</span> <span class=\"p\">-</span> <span class=\"n\">dbProductIds</span>\n        <span class=\"n\">productIndexRepository</span><span class=\"p\">.</span><span class=\"nf\">deleteAllById</span><span class=\"p\">(</span><span class=\"n\">documentIdsNotInDB</span><span class=\"p\">)</span>\n\n        <span class=\"n\">pageable</span> <span class=\"p\">=</span> <span class=\"n\">pageable</span><span class=\"p\">.</span><span class=\"nf\">next</span><span class=\"p\">()</span>\n    <span class=\"p\">}</span> <span class=\"k\">while</span> <span class=\"p\">(</span><span class=\"n\">indexPage</span><span class=\"p\">.</span><span class=\"nf\">hasNext</span><span class=\"p\">())</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n<p><img src=\"/images/es-dev/es6-2.png\" alt=\"page-query\" /></p>\n\n<p>ES야.. 죽지마.. 테스트서버에서 확인해보니 동기화 할 때마다 자꾸 ES 서버가 다운되더라고요..\n페이징보다 <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/scroll-api.html\">Scroll</a> API 를 이용하는 것이 훨씬 성능상 좋다고 하여서 Scroll API 를 적용해봤습니다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">fun</span> <span class=\"nf\">deleteOrphanDocuments</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">toDeleteProductIds</span> <span class=\"p\">=</span> <span class=\"n\">mutableListOf</span><span class=\"p\">&lt;</span><span class=\"nc\">UUID</span><span class=\"p\">&gt;()</span>\n\n    <span class=\"kd\">val</span> <span class=\"py\">batchSize</span> <span class=\"p\">=</span> <span class=\"mi\">1000</span>\n\n    <span class=\"kd\">var</span> <span class=\"py\">documentIdsWithScroll</span> <span class=\"p\">=</span> <span class=\"n\">productIndexRepository</span><span class=\"p\">.</span><span class=\"nf\">findAllIdWithScroll</span><span class=\"p\">(</span><span class=\"n\">size</span> <span class=\"p\">=</span> <span class=\"n\">batchSize</span><span class=\"p\">)</span>\n\n    <span class=\"k\">while</span> <span class=\"p\">(</span><span class=\"n\">documentIdsWithScroll</span><span class=\"p\">.</span><span class=\"n\">productDocumentIds</span><span class=\"p\">.</span><span class=\"nf\">isNotEmpty</span><span class=\"p\">())</span> <span class=\"p\">{</span>\n        <span class=\"kd\">val</span> <span class=\"py\">documentIds</span> <span class=\"p\">=</span> <span class=\"n\">documentIdsWithScroll</span><span class=\"p\">.</span><span class=\"n\">productDocumentIds</span>\n        <span class=\"kd\">val</span> <span class=\"py\">dbProductIds</span> <span class=\"p\">=</span> <span class=\"n\">productRepository</span><span class=\"p\">.</span><span class=\"nf\">findAllById</span><span class=\"p\">(</span><span class=\"n\">documentIds</span><span class=\"p\">).</span><span class=\"nf\">map</span> <span class=\"p\">{</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">id</span> <span class=\"p\">}</span>\n\n        <span class=\"n\">toDeleteProductIds</span><span class=\"p\">.</span><span class=\"nf\">addAll</span><span class=\"p\">(</span><span class=\"n\">documentIds</span> <span class=\"p\">-</span> <span class=\"n\">dbProductIds</span><span class=\"p\">)</span>\n\n        <span class=\"n\">documentIdsWithScroll</span> <span class=\"p\">=</span>\n            <span class=\"n\">productIndexRepository</span><span class=\"p\">.</span><span class=\"nf\">findAllIdByScrollId</span><span class=\"p\">(</span>\n                <span class=\"n\">scrollId</span> <span class=\"p\">=</span> <span class=\"n\">documentIdsWithScroll</span><span class=\"p\">.</span><span class=\"n\">nextScrollId</span><span class=\"p\">,</span>\n            <span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"n\">productIndexRepository</span><span class=\"p\">.</span><span class=\"nf\">clearScroll</span><span class=\"p\">(</span><span class=\"n\">documentIdsWithScroll</span><span class=\"p\">.</span><span class=\"n\">nextScrollId</span><span class=\"p\">)</span>\n\n    <span class=\"n\">productIndexRepository</span><span class=\"p\">.</span><span class=\"nf\">deleteAllById</span><span class=\"p\">(</span><span class=\"n\">toDeleteProductIds</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>ES 에서 Scroll 을 생성할 때 설정한 시간만큼 Scroll 정보를 저장하고 있고 해당 Scroll ID 를 가지고 다음 데이터를 처리단위만큼 반환해줍니다. \n받은 데이터엔 또 다음 Scroll 조회를 위한 Scroll ID 를 반환하는 형식입니다.</p>\n\n<p>장점은 페이징 조회보다 계산과 조회가 빠르고 부하가 적은 것인데요. 다만, Scroll 정보를 저장하고 있어야한다는 단점이 있습니다.</p>\n\n<p>조회 후 <code class=\"language-plaintext highlighter-rouge\">clearScroll</code> 해주고 만료 시간을 적게 설정하면 큰 문제가 되지 않을거예요.</p>\n\n<p>변경 후엔 ES가 건강해졌습니다. 대량 조회가 필요할 땐 Scroll API 를 사용하는걸 추천드립니다.</p>\n\n<h2 id=\"검색-품질-유지하기\">검색 품질 유지하기</h2>\n<p>추가적으로 쿼리나 스코어링 방식을 변경하다보면 현재의 요구사항에는 만족했지만 이전의 요구사항에 반할 때가 생길 수 있습니다.\n그래서 테스트코드에 이전 요구사항에 관련된 테스트케이스를 꼭 남겨두고 현재 만족할 수 있는 테스트케이스를 더해서\n이전과 현재 요구사항을 모두 만족할 수 있도록 구현하는걸 목표로 했습니다.</p>\n\n<p>특정 케이스에 모두 만족하는지 일일이 확인하는 것은 현실적으로 어려울 수 있으니 테스트를 든든하게! 잘 짜두는 것이 많은 도움이 될 겁니다!</p>\n\n<h2 id=\"이후엔-어떤-것을-할-것인가\">이후엔 어떤 것을 할 것인가</h2>\n<p>Wildcard 검색, 초성 검색, IDF 제거 등 여러 개선들을 해왔는데요.\n요구사항에 맞게, 문제상황에 맞게 조치하는 형식으로 개선해나가다보니 조금은 불필요한 옵션들로 검색을 무겁게 만든 부분들이 분명 있을 수 있을것 같아요.\n또한 검색 엔진에 대한 전문적인 지식 없이 점차 학습하여 개발하다보니 초반과 후반에 대한 지식의 차이가 커서 초반에 했던 방법들이 논리보단 여러 검색어 테스트 POC 로 적용한 것들이 많아요.\n그래서 조금 뚱뚱해진 ES 의 다이어트가 필요해보입니다.</p>\n\n<p>일단 생각나는 것은 부하를 줄 수 있는 Wildcard 를 없애는 것인데요. N-gram 과 Tokenizer 의 적절한 조합으로 Wildcard 없이 포함된 단어가 잘 조회될 수 있도록 방법을 찾아봐야할 것 같아요.</p>\n\n<p>그리고 이젠 품목 데이터가 많이 쌓여서 한국 식자재의 대부분 데이터가 존재할 것인데요. 이 데이터로 사용자 사전을 만들어서 검색의 정확도를 높이는 작업을 해볼 수 있을 겁니다.\n추가되는 데이터에 맞춰 사전이 관리되어야 하기 때문에 개발자뿐만 아니라 타부서 팀원분들도 쉽게 관리하기 위한 시스템을 마련해야 할 것 같습니다.</p>\n\n<p>외래어를 포함하는 새로운 식자재를 등록하는 것도 중요하지만 “셀러드”처럼 식자재이지만 표기를 잘못한 경우도 있어서 이런 경우엔 품목명 자체의 수정이 필요합니다.\nERP에 등록된 품목명과 키친보드의 등록된 품목명의 강한 결합성을 끊을 수 있도록, 검색 엔진의 설정뿐만 아니라 키친보드 품목명의 데이터 클렌징이 필요할거예요.</p>\n\n<h1 id=\"마무리\">마무리</h1>\n<p>끝으로, 저희의 지금 검색 엔진은 완성이 아닙니다. 지금도 많이 부족할 수 있지만 사용자의 보이스를 들으며 꾸준히 발전하고 있습니다.\n키친보드를 사용하는 점주 모두가 검색이 너무 편해요! 라고 할때까지, 대충 검색해도 마음속으로 생각했던 품목이 결과에 나오는 그날까지, 발전은 계속 됩니다!</p>\n\n<p>ES 도입과 설정에 도움주시고 자기 일처럼 고민해주신 백엔드 개발자분들과 개선을 위한 데이터를 제공해주신 데이터팀분들, 검색 개선을 위해 피드백 주신 사업팀분들 모두 감사합니다!</p>\n\n<p><img src=\"/images/es-dev/chillguy.png\" alt=\"chillguy\" width=\"300\" /></p>\n",
        "contentSnippet": "안녕하세요. 스포카 백엔드팀 프로그래머 이지민입니다.\n스포카에서는 식당 점주분들이 식자재 주문을 더 편리하게 하기 위한 많은 노력들을 하고 있습니다.\n그중에서도, 주문하려는 품목을 검색하여 원하는 품목을 빠르게 찾을 수 있도록 품목 검색 기능을 제공하고 있는데요.\n검색 엔진 도입부터 지금의 검색이 되기까지의 과정들을 이야기해보려고 합니다.\n도입 초기에는 검색 엔진에 대한 이해가 깊지 않아, 논리적인 의사결정보다는 다양한 테스트를 통해 더 나은 결과를 찾는 방식으로 기능을 결정, 구현하였습니다.\n이 점을 고려해 읽어주시길 바라며, 이 글은 검색 엔진의 점진적인 발전 과정을 다루는 이야기이니, 순차적으로 읽어보시면 개선 과정이 더욱 잘 이해되실 것 같습니다!\n검색 엔진 도입 배경\n품목 검색 기능 초기에는 Database의 LIKE 질의를 통한 검색만 제공되었습니다. 이로 인해 품목명에 띄어쓰기가 다르거나 맞춤법이 정확히 일치하지 않는 경우, 사용자가 원하는 결과를 찾기가 어려웠습니다.\n예를 들어, 깐마늘을 검색했을 때 마늘/깐 이라고 저장되어 있는 유통사 품목은 검색되지 않아 점주들은 깐마늘을 유통사가 취급하지 않는다고 오해하는 상황이 발생하곤 했습니다.\n이와 같은 문제와 사용하는 점주의 수가 증가하고 품목의 종류가 다양해짐에 따라, DB 검색 기능의 한계가 더 드러나게 되었고 이를 해결하기 위해 검색 엔진 도입의 필요성이 대두되었습니다.\n이번 검색 엔진 도입이 스포카에서 최초 도입은 아닌데요.(하지만 제가 처음이에요.) (구)도도카트 서비스 운영 당시 많은 명세표 품목을 검색하는데 Elasticsearch 검색 엔진을 활용했었습니다.\n우선 별도의 검색 품질에 대한 기준이 마련되어 있지 않았기 때문에 (구)도도카트 서비스의 검색 엔진 설정을 참고해 Elasticsearch(이하 ES)를 POC 해보기로 했습니다.\n\nDB LIKE 검색과 ES 검색 비교 POC\n품목 데이터는 product 라는 인덱스에 다음과 같은 setting 으로 구성했습니다.\n\n{\n  \"product\":{\n    \"mappings\":{\n      \"properties\":{\n        // .. 생략\n        \"name\":{\n          \"type\":\"text\",\n          \"analyzer\":\"korean\",\n          \"fields\":{\n            \"ngram\":{\n              \"type\":\"text\",\n              \"analyzer\":\"korean_ngram\"\n            }\n          }\n        }\n      }\n    },\n    \"settings\":{\n      \"index\":{\n        \"analysis\":{\n          \"filter\":{\n            \"edge_ngram_back\":{\n              \"min_gram\":\"1\",\n              \"side\":\"back\",\n              \"type\":\"edge_ngram\",\n              \"max_gram\":\"5\"\n            },\n            \"edge_ngram_front\":{\n              \"min_gram\":\"1\",\n              \"side\":\"front\",\n              \"type\":\"edge_ngram\",\n              \"max_gram\":\"5\"\n            }\n          },\n          \"analyzer\":{\n            \"korean\":{\n              \"filter\":[\n                \"lowercase\",\n                \"trim\"\n              ],\n              \"type\":\"custom\",\n              \"tokenizer\":\"nori_mixed\"\n            },\n            \"korean_ngram\":{\n              \"filter\":[\n                \"lowercase\",\n                \"edge_ngram_front\",\n                \"edge_ngram_back\",\n                \"trim\"\n              ],\n              \"type\":\"custom\",\n              \"tokenizer\":\"nori_mixed\"\n            }\n          },\n          \"tokenizer\":{\n            \"nori_mixed\":{\n              \"type\":\"nori_tokenizer\",\n              \"decompound_mode\":\"mixed\"\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n\n품목명을 저장할 name field, name.ngram field 구현\n한글 검색의 정확성과 유연성을 높이기 위해 Nori Tokenizer와 Edge N-gram 필터를 활용해 띄어쓰기나 일부 단어만으로도 검색이 가능하도록 설정\n또한, LIKE 질의를 사용하는 기존 DB 검색과 ES 검색의 결과를 비교한 POC 결과는 다음과 같습니다.\n\n결과를 통해 볼 수 있듯이, 정확하지 않은 키워드로 검색했을 때도 기존 DB의 LIKE 질의보다 ES 검색이 훨씬 더 나은 결과를 제공하는 것을 확인할 수 있었습니다.\n비용 증가와 관리 포인트가 늘어남에도 불구하고 앞서 언급한 문제들이 해소되었고 검색 품질을 크게 항상시킬 수 있을거 같아 검색 엔진 도입을 최종적으로 결정하게 되었습니다!\n다만, 이번 테스트는 전체 검색어가 아닌 일부 검색어를 대상으로 진행된 POC 였기 때문에, 실제 사용자의 피드백을 바탕으로 지속적인 수정과 개선이 필요할 것으로 예상하고 있었습니다.\n이러한 부분을 미리 인지하고 마음의 준비(?)와 공부를 하고 있었죠.\n개선 작업\n1) 가중치 조절 및 N-gram 조정\n이슈 및 원인 분석\n검색 엔진을 적용한 후에 아래와 같은 피드백이 들어왔습니다.\n\n주문하려고 했던 품목은 통베이컨(에스푸드)였지만, 통베, 통베이 키워드로 검색했을 때 상위에 노출되지 않는다는 이슈였습니다.\n이 문제를 해결하기 위해, 우선 통베라는 검색어를 중심으로 원인을 분석해보았습니다.\n문제 원인 파악을 위해 _analyze API를 활용하여 name 필드에 적용된 분석기(analyzer)가 검색어를 어떻게 토큰화하는지 살펴보았습니다.\n\nGET product/_analyze\n{\n  \"field\" : \"name\",\n  \"text\" : \"통베이컨(에스푸드)\"\n}\n\nResponse\n{\n  \"response\":{\n    \"tokens\":[\n      {\n        \"token\":\"통\",\n        \"start_offset\":0,\n        \"end_offset\":1,\n        \"type\":\"word\",\n        \"position\":0\n      },\n      {\n        \"token\":\"베이컨\",\n        \"start_offset\":1,\n        \"end_offset\":4,\n        \"type\":\"word\",\n        \"position\":1\n      },\n      {\n        \"token\":\"에스\",\n        \"start_offset\":5,\n        \"end_offset\":7,\n        \"type\":\"word\",\n        \"position\":2\n      },\n      {\n        \"token\":\"푸드\",\n        \"start_offset\":7,\n        \"end_offset\":9,\n        \"type\":\"word\",\n        \"position\":3\n      }\n    ]\n  }\n}\n\n\n결과는 [통, 베이컨, 에스, 푸드] 로 예측 가능하게 나오네요.\n그러나 문제의 검색어인 통베는 다음과 같이 토큰화되었습니다:\n[통, 베, 베, 어]\n잠깐 어 는 뭐지? 라고 생각하실 수 있는데요. 통베라는 단어 어디에도 어 라는 단어는 찾아볼 수 없기 때문이죠.\n이는 ES의 Nori Tokenizer 가 한국어 문장에서 어미를 추출하는 방식을 따라 토큰화하기 때문입니다.\n예를 들어, “강아지가 밥을 먹습니다”라는 문장은 [강아지, 가, 밥, 을, 먹, 습니다]로 명사와 어미를 구분하여 토큰화됩니다.\n따라서 정확히 알기는 어렵지만 어는 Nori Tokenizer 가 베에서 어미로 분리한 결과로 예상하고 있어요.\n이런 토큰화 방식을 보고 Nori Tokenizer 의 토큰화는 단어별로 검색하는 패턴이 많은 저희 서비스에서 예측 불가능할 수 있겠다라는 깨달음을 얻었어요.\n하지만 Nori를 아예 제거하기엔 Nori 가 해주는 명사 추출의 이점이 있을 수 있어 조심스러웠습니다.\n결론적으로, Nori 기능을 완전히 제거하는 대신, 다른 접근을 시도하기로 했습니다.\n쿼리 가중치 조절 POC\n문제 해결을 위해 쿼리의 가중치를 조절해보기로 했습니다.\n기존엔 쿼리 가중치를 순수 Nori Tokenizer 가 적용된 name 필드와 Nori Tokenizer 와 N-gram filter 가 적용된 name.ngram 필드에 각각 10과 5 를 주고 있었는데요.\n따라서 N-gram 에 의해 검색된 품목보다 순수 Nori 에 의해 검색된 품목의 유사도가 높아져 상위에 올라가게 됩니다.\n통베 라고 검색했을때 통베이컨(에스푸드) 품목이 올라오기 위한 가중치 조절과 N-gram Filter 조정이 필요해보였습니다.\n\n최적의 가중치와 N-gram Filter 설정을 찾기 위해 통베이컨 품목을 기준으로 삽질을 테스트를 아래와 같이 해보았는데요.\n\n\nNori Tokenizer 에만 의존하기에는 무리가 있을거 같아 ES 기본 Tokenizer 인 Standard Tokenizer 도 추가해서 테스트 해봤습니다. \n가중치의 경우, 순수 Nori 인 nori 와 N-gram 을 적용한 ngram, standard 필드의 가중치를 조정해보며 각각 2.0, 3.0, 2.0 일 때 통베이컨(에스푸드)와 세척당근이 가장 잘 검색되는 것을 확인 했습니다.\n여기에서 Edge N-gram 에 대해서 간단히 설명드리자면요.\n\n{\n  \"min_gram\": \"1\",\n  \"max_gram\": \"3\",\n  \"side\": \"front\",\n  \"type\": \"edge_ngram\"\n}\n\n\nmin_gram : 최소 토큰 길이\nmax_gram : 최대 토큰 길이\nside : 단어의 어느 부분부터 토큰화 할지 설정(front/back)\nside 가 front 인 위 예시로 안녕하세요를 토큰화해보면 [안, 안녕, 안녕하]로 토큰화되고 side 가 back 일 경우엔 [요, 세요, 하세요]로 토큰화 됩니다.\n때문에 front 의 경우 주로 첫 글자부터 검색하는 자동완성과 같은 곳에서 사용하고 back 은 주로 뒷글자부터 검색하는 경우, 예를들면 영어로 ion 을 검색했을 때 action, station, evolution 같은 것들을 검색할 때 유용하게 사용할 수 있을거예요.\n저희는 식자재 검색라는 특성이 있어 통베, 세척당과 같이 앞글자부터 검색하는 경우가 많기 때문에 back 은 제거하고 front 만 남기기로 했습니다. max_gram 도 기존엔 5로 토큰화가 많이 되어 오히려 정확성을 떨어트리는 것을 발견했고 적절해보이는 3으로 조정했습니다.\n결론\n결론적으로 아래 조정 작업으로 문제가 되었던 품목이 검색 상위에 안정적으로 노출되도록 검색 품질을 향상시켰습니다.\nN-gram 조정: max_gram 값을 5 -> 3으로 하향 조정하고 side: front 만 사용\n가중치 조정: Nori, N-gram, Standard 분석기의 가중치를 적절히 분배\n2) Wildcard 검색\n이슈 및 원인 분석\n위 작업을 배포하고 내부에서 아래와 같은 피드백을 받았습니다.\n\n칠성사이다/355ml*24캔라는 품목이 있는데도 불구하고 사이다 라고 검색했을때 검색이 되지 않는 이슈였는데요.\n각 분석기에서 칠성사이다/355ml*24캔이 토큰화된 결과는 다음과 같았습니다.\n\nNori: 칠성사, 칠, 성사, 이, 다, 355, ml, 24, 캔\n\nN-gram: 칠, 칠성, 칠성사, 칠, 성, 성사, 이, 다, 3, 35, 355, m, ml, 2, 24, 캔\n\nStandard: 칠성사이다, 355ml, 24캔\n\n\n결과에서 확인할 수 있듯이, 사이다라는 토큰이 생성되지 않아 검색 결과에서 제외된 것입니다.\n위에서 가중치와 N-gram 을 조정했는데도 불구하고 왜 사이다로 토큰화되지 않았을까요?\n이는 N-gram 은 Filter 이기 때문에 Nori 분석기에서 생성된 토큰을 기반으로 토큰을 더 잘게 나누는 필터링을 수행하기 때문이에요.\n즉, Nori 분석기가 사이다를 하나의 단어로 인식하지 못하고 어미(이, 다)로 나누어버렸기 때문에, 사이다라는 토큰 자체가 존재하지 않았던 것이죠,,\n만약 칠성고구마였다면 어떻게 되었을까요?\n\nnori: [칠성, 고구마, 355, ml, 24, 캔]\n\nngram: [칠, 칠성, 고, 고구, 고구마, 3, 35, 355, m, ml, 2, 24, 캔]\n\nstandard: [칠성고구마, 355ml, 24캔]\n\n\n\n이처럼 명사 단위로 토큰화하기 때문에 Nori 명사 사전에 명사 존재 여부에 따라 토큰화가 다르게 됩니다. 명사 사전에 존재하는 품목의 경우, 고구마처럼 검색이 훨씬 매끄러울 수 있을거예요.\n사이다도 명사 사전에 등록되어 있었다면 칠성사이다도 [칠성, 사이다] 로 토큰할 수 있었겠죠.\nUser Dictionary\n따라서, 사용자 사전(user_dictionary) 도입을 고려했었는데요. Nori Tokenizer 에게 사이다는 명사야, 혹은 칠성사이다는 [칠성, 사이다] 라고 토큰화 해! 라고 인식할 수 있는 기준을 마련해줄수있는 방법이에요.\n하지만 몇가지 한계가 있었어요.\n관리 포인트 증가\n    \n관리해야 할 품목의 종류가 너무 많아 어려움이 발생\n농산물, 곡류, 축산물, 수산물 등 수백에서 수천 가지 품목을 주기적으로 업데이트하기 어려운 환경\n표준화되지 않은 품목명\n    \n유통사마다 다른 표기 방식으로 인해 같은 품목도 명칭이 다름\n예: “무”와 “무우”, “샐러드”와 “셀러드” 등 비표준어와 잘못된 외래어 표기\n이러한 다양한 표기법을 모두 관리하기엔 부담이 큼\n이러한 이유로 사용자 사전을 유지 관리하는 것이 현실적으로 어렵다고 판단하여 다른 접근 방식을 찾기로 했습니다.\nWildcard Field\n문제를 다시 분석한 결과, 검색어 자체가 포함된 품목을 반환하는 것이 핵심이라는 점을 확인했습니다.\n이는 마치 DB의 LIKE 쿼리처럼 검색어가 포함된 품목을 반환하는 것이죠.\nES에서는 이러한 기능을 제공하는 Wildcard 필드를 활용할 수 있었습니다.\nWildcard 필드를 추가하는 방법은 간단합니다.\n\n{\n  \"mappings\":{\n    \"properties\":{\n      \"name\":{\n        \"type\":\"text\",\n        \"analyzer\":\"korean\",\n        \"fields\":{\n          // .. 생략\n          \"wildcard\":{\n            \"type\":\"wildcard\"\n          }\n        }\n      }\n      //.. 생략\n    }\n  }\n}\n\n\nWildcard 필드는 역색인 구조가 아닌 패턴 매칭 방식을 사용하기 때문에 성능 문제가 발생할 수 있어서 신중히 사용해야 합니다. 모든 토큰을 검사해야 하기 때문에 데이터가 많아질수록 메모리 사용량이 많아지고 성능이 떨어질 수 있습니다.\n따라서 Wildcard 필드 대신 정교한 N-gram 을 사용하거나 Query-String 쿼리를 권장합니다.\n하지만 저희는 데이터량이 많지 않고, 필터를 통해 조회되는 데이터 수를 제한할 수 있었기 때문에 성능 부담이 아직까진 크지 않아 Wildcard 필드를 사용하기로 결정했습니다.\nWildcard 필드를 활용한 쿼리는 다음과 같이 구성했습니다:\n\n{\n  \"query\":{\n    \"bool\":{\n      \"must\":[\n        {\n          \"bool\":{\n            \"should\":[\n              {\n                \"wildcard\":{\n                  \"name.wildcard\":{\n                    \"boost\":100.0,\n                    \"wildcard\":\"*사이다*\"\n                  }\n                }\n              },\n              {\n                \"multi_match\":{\n                  \"fields\":[\n                    \"name^3.0\",\n                    \"name.ngram^4.0\",\n                    \"name.standard^3.0\"\n                  ],\n                  \"query\":\"사이다\"\n                }\n              }\n            ]\n          }\n        }\n      ]\n    }\n  }\n}\n\n\n검색어가 포함된 결과는 상단으로 올리되, 포함된 결과 내에서도 유사도에 맞게 정렬되도록 쿼리를 수정했습니다. 위처럼 할 경우 사이다가 포함된 단어는 100 점을 추가로 받고 match 되는 필드에 따라 점수를 추가로 더해지게 됩니다.\n예를들어 칠성사이다 , 칠십성사이다 , 칠성사이 라는 품목이 있을때, 사이다 라고 검색하면 wildcard 에 의해 칠성사이다, 칠십성사이다 가 가장 상단으로 나오게 될테고, 품목의 이름이 더 짧아 유사도가 더 높은 칠성사이다 가 최상단으로 나오게 될거예요.\n기존의 가중치는 유지하되 검색어가 포함된 결과만 올리기 위한 쿼리입니다.\n결론\nUser Dictionary 도입을 고려했으나 유지보수에 대한 한계로 제외\nWildcard 필드와 쿼리로 검색어가 포함된 품목의 점수를 높임\n3) 초성 검색 feat. ICU\nWildcard 검색까지 구현하고 나니 검색 되지 않는 품목 없이 꽤 안정화된 검색 결과를 제공할 수 있었는데요. 더 편리한 검색을 위한 초성 검색 니즈가 들어 왔습니다.\n어떤 extension 을 사용할 것인가\n초성검색을 위해 지금 시스템에 도입할 수 있고, 적당한 레퍼런스가 있는 두가지 extension으로 POC 를 진행해봤어요.\nelasticsearch-jaso-analyzer(이하 JASO)\nanalysis-icu(이하 ICU)\n결론적으로 ICU 를 선택했는데요, JASO 에 대한 설명이 너무 길어질거 같아 자세한 설정 방법과 설명은 위 주소에서 참고주시길 바랍니다.\n두 분석기를 비교한 결과는 아래 표로 정리되었습니다.\n\n개발 난이도\n    \nJASO: \"chosung\" 옵션만 추가하면 간단히 초성 검색이 가능\nICU: 직접 초성 필터를 구현해야 하는 추가 작업 필요\n유지보수 및 확장성\n    \nJASO: 커스텀 확장(extension)으로 기본 제공되지 않기 때문에, 사용하는 ES 버전과 플랜에 따라 제약이 있을 수 있음\nICU: 기본 확장(extension)으로 계속 지원되며, 다른 기능으로의 확장이 자유로움\n버전 지원\n    \nJASO: Elasticsearch 8.6.2까지만 지원. 이후 버전은 직접 설정 필요\nICU: 최신 버전까지 지원\n토큰 생성 방식\n    \nJASO: 영어 오타 교정, 쌍자음 분리 등 추가 기능 지원\nICU: 필요에 따라 초성 검색뿐만 아니라 다양한 확장 가능\nJASO 가 더 많은 옵션을 제공한다는 이점이 있지만 불필요한 토큰이 생성되고 큰 max_gram을 주어 토큰을 많이 생성해야 된다는 점,\n유지보수를 직접 해야된다는 점에서 ICU extension 을 직접 확장하여 사용하기로 하였습니다.\nICU Analyzer\n그럼, ICU analyzer 의 설정을 좀더 자세히 살펴보겠습니다.\n\n{\n    \"orderable_vendor_product_v4\":{\n        \"aliases\":{\n            \"orderable_vendor_product\":{}\n        },\n        \"mappings\":{\n            \"properties\":{\n                // .. 생략\n                \"name\":{\n                    \"type\":\"text\",\n                    \"fields\":{\n                        \"icu\":{\n                            \"type\":\"text\",\n                            \"analyzer\":\"icu_analyzer\",\n                            \"search_analyzer\":\"icu_search_analyzer\",\n                            \"similarity\":\"scripted_no_idf\"\n                        }\n                    }\n                }\n            }\n        }\n    },\n    \"template\":{\n        \"settings\":{\n            \"index\":{\n                \"analysis\":{\n                    \"filter\":{\n                        // .. 생략\n                        \"ngram_filter\":{\n                            \"type\":\"ngram\",\n                            \"min_gram\":1,\n                            \"max_gram\":2,\n                            \"token_chars\":[\n                                \"letter\",\n                                \"digit\"\n                            ]\n                        }\n                    },\n                    \"analyzer\":{\n                        // .. 생략\n                        \"icu_analyzer\":{\n                            \"type\":\"custom\",\n                            \"filter\":[\n                                \"lowercase\",\n                                \"ngram_filter\"\n                            ],\n                            \"char_filter\":[\n                                \"nfd_normalizer\",\n                                \"make_chosung_filter\"\n                            ],\n                            \"tokenizer\":\"icu_tokenizer\"\n                        },\n                        \"icu_search_analyzer\":{\n                            \"type\":\"custom\",\n                            \"filter\":[\n                                \"lowercase\",\n                                \"ngram_filter\"\n                            ],\n                            \"char_filter\":[\n                                \"chosung_only_filter\",\n                                \"nfd_normalizer\"\n                            ],\n                            \"tokenizer\":\"icu_tokenizer\"\n                        }\n                    },\n                    \"char_filter\":{\n                        \"nfd_normalizer\":{\n                            \"mode\":\"decompose\",\n                            \"name\":\"nfkc\",\n                            \"type\":\"icu_normalizer\"\n                        },\n                        \"make_chosung_filter\":{\n                            \"type\":\"pattern_replace\",\n                            \"pattern\":\"[^\\u1100-\\u1112^0-9a-zA-Z가-힣ㄱ-ㅎ ㅏ-ㅑ]\",\n                            \"replacement\":\"\"\n                        },\n                        \"chosung_only_filter\":{\n                            \"type\":\"pattern_replace\",\n                            \"pattern\":\"[^ㄱ-ㅎa-zA-Z0-9]\",\n                            \"replacement\":\"\"\n                        }\n                    }\n                    //.. 생략 Tokenizer\n                }\n            }\n        }\n    }\n}\n\n\n위 analzyer 를 그림으로 나타내면 아래와 같습니다.\n\nicu field 를 보시면 analyzer 와 search_analyzer 를 구분해서 설정해준걸 보실 수 있는데요.\nAnalyzer : 저장되는 document 에 대해서 토큰화하여 그림과 같이 역색인화 구조로 저장합니다.\nSearch Analyzer : 검색어에 대해서 토큰화를 수행해서 저장되어 있는 토큰을 검색해서 결과를 내는 역할을 합니다.\n기존엔 Analyzer 와 Search Analyzer 를 구분해서 지정해줄 필요가 없었지만 초성 검색의 경우엔 초성으로 검색 했을 때만 초성 검색이 되길 바랬었는데요.\n예를 들어 초성이 아닌 통베이컨을 Analyzer 로 검색했을 경우, ㅌㅂㅇㅋ 으로 초성화 될 것이고 사용자가 초성 검색을 하지 않았는데도 초성을 포함하는 품목이 많이 나오게 될 것 입니다. \n그래서 최대한 기존의 쿼리 score 에는 영향이 가지 않고 초성 검색을 했을때만 초성으로 품목을 찾기 위해서 초성을 제외한 글자는 모두 제거하는 필터를 넣는 Search Analyzer 를 따로 지정해주었습니다.\n즉, 통베이컨이 Search Analyzer 를 거치게 되면 아무 토큰도 생성되지 않게 되어 초성 검색에 대해서는 수행이 되지 않게 되는거죠.\nICU_Normalizer 에 대한 설정은 문서를 보시면 더 자세히 볼 수 있을거예요.\n요약하자면 유니코드의 정규화(Normalization)를 수행하는 역할을 합니다.\n저희는 decompose 옵션을 사용하여 통이라는 글자를 ㅌㅗㅇ 으로 문자를 분해할 수 있도록 했고, NFKC(Normalization Form Compatibility Composition) 옵션을 사용하여 호환가능한 문자를 호환시키고, 조합 가능한 문자는 조합하도록 설정하였습니다.\n즉, 통베이컨™①é를 정규화하면 ㅌㅗㅇㅂㅔㅇㅣㅋㅓㄴTM1é로 정규화 됩니다. \n초성검색 구현을 위해선 정규화 방식보다는 초성 분리를 위한 mode 를 잘 설정하는게 더 핵심이라고 할 수 있을거예요.\n요약하면 품목을 ICU Normalizer 를 활용하여 초성 토큰 형태로 저장하고, 초성 검색어에 대해서만 초성 검색을 수행할 수 있도록 Search Analyzer 를 구분하여 구현해주었습니다.\nICU 는 JASO와 비교했을 때 초기 구현은 다소 복잡했지만, 유지보수와 추후 확장성 측면에서 더 적합한 선택이었으면 합니다!! (Extension 교체 작업만은 다시 하고 싶지 않아요..)\nIDF 제외\n이제 마지막 개선 작업이네요.\n잘 운영하고 있던 중 아래와 같은 의견이 들어왔습니다.\n이슈 및 원인 분석\n\n사용자가 스위트콘을 검색하려 했으나 스위트곤으로 오타가 발생한 경우, 기대했던 스위트콘이 아닌 곤약이 상위에 노출되는 문제가 있었습니다.\n일반적으로 사용자가 기대하는 결과와는 다른 결과였죠.\n다행히도 로컬 테스트 환경에서 원인 분석을 해볼 수 있었는데요, 그런데 조금 충격적이게도 로컬에선 스위트콘이 더 상위노출 되었습니다. 이럴수가..\n그렇다는 것은 로컬 테스트코드와 실제 환경의 검색 결과가 다르다는 것이고, 지금까지의 테스트가 유효한게 맞을까.. 하는 생각이 들었는데요.\n\n더 자세한 원인을 파악하기 위해 ES의 explain API를 사용해 점수 산출 과정을 분석했습니다.\n결과를 요약하자면 아래와 같은데요.\n#곤약/면곤약\n    \nN-gram Boost : 8.8\nIDF: 6.05\nTF: 0.78\n8.8 * 6.05 * 0.78 = 41.66\n스위트콘/리치스/2.95kg\n    \nN-gram Boost : 8.8\nIDF : 3.14\nTF : 0.81696963\n8.8 * 3.14 * 0.81696963 = 22.568493\nES 에서 Boost * IDF * TF 계산 로직을 통해 score 를 산출하고 있었습니다. 곤약이 상위로 올라온 이유는 숫자를 보면 알수있듯 두배 가까이 차이나는 IDF 때문인 것을 파악할 수 있었는데요.\n우선 처음 보는 개념인 IDF 와 TF 가 무엇인지 알아보았습니다.\nIDF(Inverse Document Frequency): 특정 단어가 전체 문서에서 얼마나 드물게 나타나는지\nTF(Term Frequency): 특정 단어가 문서 내에서 얼마나 자주 나타나는지\nIDF 는 전체 문서를 기준으로 계산되기 때문에 테스트코드와 실제 환경의 결과가 다른 이유가 여기에 있었습니다.\n테스트코드의 테스트를 위해 생성해놓은 문서는 상대적으로 너무나도 적은 양의 데이터이기 때문에 IDF 의 값이 대부분 동일하고 TF 값으로 대부분 유사도가 정해질거예요.\n반면, 테스트코드에 비해 방대한 품목 데이터가 있는 실제 환경에선 곤약과 스위트콘처럼 IDF 의 차이가 클 수 있습니다.\nIDF 가 유의미한 결과를 내주기 위해서는 전체 문서가 모두 한 유통사의 품목으로, 품목명의 구조나 맥락이 동일해야 할 것 같은데요.\n하지만 유통사마다 품목명이 모두 제각각인데도 IDF가 모든 유통사의 데이터를 포함한 전체 품목 데이터를 기준으로 계산되면서 오히려 유사도 계산에 역효과를 내고 있었습니다.\n또한, 실제환경과 로컬 환경에서의 테스트 결과가 보장되지 않아 문제 재현 및 원인 파악이 어려워보였습니다.\n따라서, IDF 를 제외하고 score 계산하는 방법을 알아봤습니다.\nIDF를 제외한 점수 계산을 위해 크게 세 가지 방법을 검토해봤습니다.\n1. 점수 고정 (Constant Score)\n첫번째 방법은 아래와 같이 쿼리에 boost 값을 명시하여 점수를 고정 시키는 Constant Score Query 를 활용한 방법입니다.\n\n{\n  \"query\":{\n    \"bool\":{\n      \"must\":[\n        {\n          \"bool\":{\n            \"should\":[\n              {\n                \"constant_score\":{\n                  \"filter\":{\n                    \"wildcard\":{\n                      \"name.wildcard\":{\n                        \"wildcard\":\"*스위트곤*\"\n                      }\n                    }\n                  },\n                  \"boost\":100.0\n                }\n              },\n              {\n                \"constant_score\":{\n                  \"filter\":{\n                    \"match\":{\n                      \"name\":\"스위트곤\"\n                    }\n                  },\n                  \"boost\":3.0\n                }\n              },\n              {\n                \"constant_score\":{\n                  \"filter\":{\n                    \"match\":{\n                      \"name.ngram\":\"스위트곤\"\n                    }\n                  },\n                  \"boost\":4.0\n                }\n              }\n              // .. 생략\n            ]\n          }\n        }\n      ]\n    }\n  }\n}\n\n\n결과를 봤을 때, Boost 만으로 Scoring 되기 때문에 같은 필드에서 검색된 품목은 동일한 점수를 가지는 것을 확인했습니다. \n예를 들어 name.ngram 로 검색된 품목들은 모두 Boost 4 인 동일한 점수로 정렬이 제대로 되지 않았습니다.\n결론적으로, 이 방식은 유사도 기반 정렬이 필요한 우리의 요구사항에 적합하지 않았습니다.\n2. 유사도 모델 변경\n기본적으로 ES는 Boost * IDF * TF 식을 사용하는 BM25(Best Matching 25) 모델을 사용합니다. 이를 대신해 DFR(Deviation From Randomness) 모델을 사용해 보았습니다.\nDFR 은 현 document에 얼마나 드물게 등장하는지, 문서 길이에 따라 통계적 랜덤성 기반으로 검색됩니다. type 뿐만 아니라 아래처럼 옵션에 가중치나 옵션을 설정해줄수있습니다.\n아래는 DFR 모델 설정 예시입니다.\n\n{\n  \"settings\": {\n    \"similarity\": {\n      \"custom_similarity\": {\n        \"type\": \"DFR\",\n        \"basic_model\": \"g\", // 문서 내에 특정 용어가 얼마나 드물게 발생하는지\n        \"after_effect\": \"b\", // 검색어가 얼마나 여러번 등장하는지\n        \"normalization\": \"h2\" // 문서 길이에 따라 빈도 설정\n      }\n    }\n  }\n}\n\n\n보시다시피 DFR 모델에 대한 지식이 없으면 유지보수가 무척 어려워보입니다.\n문제가 생기거나 개선의 여지가 생겼을 때 더 복잡한 계산식을 사용하는 모델이기 때문에 쉽게 커스텀하기가 힘들어보이고, 모델의 대한 이해뿐만 아니라 옵션에 대한 각 알고리즘도 알아야하기 때문에 유지보수가 정말 쉽지 않을거라 생각이 들었죠.\n우리 팀에 검색 엔진에 대한 전문적인 지식을 가진 분이 없었기 때문에 더 복잡한 모델로 변경하는건 과감하게 제외했습니다.\n3. Scripted Similarity 사용\nIDF를 제외하고 직접 계산식을 정의하는 방법입니다. 아래는 Scripted Similarity 설정 예시입니다.\n\n{\n  \"setting\":{\n    \"similarity\":{\n      \"scripted_no_idf\":{\n        \"type\":\"scripted\",\n        \"script\":{\n          \"source\":\"double tf = Math.sqrt(doc.freq); return query.boost * tf;\"\n        }\n      }\n    }\n  }\n}\n\n\n위처럼 setting 을 변경하고 쿼리의 explain 을 해보면 script 에 있는 식이 아래와 같이 idOrCode에 들어가 scoring 되는것을 볼 수 있어요.\n\nExplain 결과\n{   \n    // .. 생략\n    \"description\":\"sum of:\",\n    \"details\":[\n        {\n            \"details\":[\n                {\n                    \"description\":\"score from ScriptedSimilarity(weightScript=[null], script=[Script{type=inline, lang='painless', idOrCode='double tf = Math.sqrt(doc.freq); return query.boost * tf;', options={}, params={}}]) computed from:\",\n                    \"details\":[\n                        // .. 생략\n                    ],\n                    \"value\":8\n                }\n            ]\n        }\n        // .. 생략\n    ]\n}\n\n\n\n위 세가지 방법 중 가장 마지막 방법인 Scripted Similarity 로 계산식을 넣기로 했어요. Scripted Similarity 를 선택한 이유는 다음과 같습니다.\n유연한 계산식 사용\n    \n계산식을 직접 조정 가능\n기존 BM25 모델에서 IDF만 제거할 수 있는 계산식을 직접 부여 가능\n유지보수 용이성\n    \n계산식이 명확히 노출되어 있어 비교적 수정이 간단\n쿼리와 독립적\n    \n점수 계산이 쿼리와 독립적으로 이루어져 다른 쿼리 추가 시에도 영향을 받지 않음\nScripted Similarity 계산식 결정\n그후에는 Scripted Similarity 에 적용할 계산식 결정이 필요했습니다.\n후보 1. 단순한 TF 계산식\n\ndouble tf = Math.sqrt(doc.freq);\nreturn query.boost * tf;\n\n/* freq : 문서 내의 토큰 등장 수 */\n\n\n후보 2. BM 모델과 동일한 TF 계산식\n\ndouble freq = doc.freq;\ndouble k1 = 1.2;\ndouble b = 0.75;\ndouble dl = doc.length;\ndouble avgdl = 7;\ndouble tf = freq / (freq + k1 * (1 - b + b * dl / avgdl));\nreturn query.boost * tf;\n\n/*\n    freq : 문서 내의 토큰 등장 수\n    k1: TF 영향도 가중치\n    b : 문서 길이 보정 파라미터\n    dl : 문서 길이\n    avgdl : 전체 문서의 문서 길이 평균값\n */\n\n\n\n\n결과만 보았을 때 확실히 IDF 를 포함했을 때보다 IDF 를 제외했을 때 결과가 개선되긴 했지만, 여전히 단순 TF 계산식, BM 모델 계산식의 결과는 크게 차이가 없었습니다.\n하지만 위 결과의 정렬은 비슷한듯 하지만 실제 점수는 다릅니다. 단순 TF 의 경우 문서 내의 토큰 등장 수로만 TF 를 계산하기 때문에 동일한 점수를 가진 결과가 다수 나타나 매번 정렬이 달라질 수 있습니다.\n국산쌀와 찰떡(쌀 국산)는 단순 TF 계산식에 의하면 둘은 동일한 점수를 반환하게 됩니다.\n반면 BM 모델과 동일한 TF 계산식의 경우, 문서 내 토큰 등장 수와 문서 길이를 함께 고려하기 때문에 저희가 흔히 생각한대로 국산쌀의 유사도가 더 높은 결과로 나오게 됩니다.\n따라서, BM 모델에서 IDF 만 제거한, 후보2 계산식을 사용하기로 결정하였습니다.\n다만, avgdl 를 현재의 기준으로 7로 고정시켜 가중치를 조정했지만 이후 문서의 평균 길이가 변경될 경우엔 유지보수가 필요한 부분이 있을 수 있습니다.\n하지만 avgdl 가 크게 변하지 않을 것이라는 가정과 점수 계산에 크게 영향을 주지 않는다고 생각해 고정된 계산식으로 가게 되었습니다.\n그럼에도 이후에 유지보수가 필요하거나 변경이 필요할 수 있습니다. 꽤 해석이 필요한 계산식을 가지고 있기 때문에\n어떤 계기로 IDF를 제거하게 되었는지, Scripted Similarity 를 왜 적용하게 되었는지, 계산식은 어떻게 결정되었고 어떤 의미인지를 자세히 문서화하도록 노력하였습니다.\n결과\n결과적으로, 아래와 같은 구조를 갖게 되었습니다.\n\n이러한 구조를 통해 현재 검색 정확도는 어떨까요?\n아래는 매장 사이드 관련 데이터입니다.\n2025년 1월 기준\n    \n검색 결과 성공률: 검색 시 하나 이상의 품목이 결과에 노출되는 경우 → 98.6%\n검색 목적 달성률: 검색한 품목을 선택한 후, 실제 액션(주문 등)을 수행하는 경우 → 73.6%\n이를 통해 상당히 높은 검색 정확도와 달성률을 기록하고 있음을 확인할 수 있습니다.\n또한, 아래는 유통사에서 매장의 주문서를 생성할 때, ES 검색이 매우 편리했다는 피드백을 받은 메시지입니다.\n키친보드의 검색 기능이 타 ERP와 달리 오타가 있어도 품목을 정확하게 검색할 수 있어 큰 편리함을 느꼈다고 합니다!\n\n\n개발 과정에서 어려움이 있었지만 결국 사용자한테 좋은 영향을 주는 기능을 개발한거 같아 아주 뿌듯하네요!\n소소한 Tip\n중단 시간을 줄인 Reindexing\nES 의 비용을 최소화하기 위해서 최소한의 리소스로 구동하고 있습니다. 그러다보니 인덱스에 새로운 필드가 추가되거나 설정이 변경되는 개선이 될때마다 인덱스를 새롭게 동기화해야하기 때문에 중단이 불가피했는데요.\n하지만 주문에서의 검색은 점주들이 꼭 해야만하는 중요한 기능이기 때문에 중단을 최소화하고 싶었습니다.\n알아보던 중 찾아낸 것은 별칭(Alias)를 이용한 배포입니다.\n\nOld Index Template 을 템플릿으로 하여 생성된 Old Index(별칭: Product) 가 존재한다.\n새로운 매핑 정보가 있는 New Index Template 을 생성한다.\nNew Index Template 을 템플릿으로 하여 New Index 를 생성한다.\nOld Index 의 문서를 New Index 로 reindex 한다.\nOld Index 를 삭제한다.\nNew Index 에 Product alias 를 부여 한다.\n서버에서 alias 기준으로 쿼리한다.\n이렇게 되면 5번과 6번 사이, Product 를 가진 인덱스가 존재하지 않을 시에만 검색 중단이 발생하게 됩니다.\n이 방법이 가장 좋은 방법이라고 표현하기는 어렵지만 기존 20만개의 품목을 마이그레이션 하느라 10분이 넘는 중단 시간을 3초 정도의 중단 시간으로 낮출 수 있는 방법이었습니다.\n대량 데이터 조회\nDB 의 품목 데이터와 ES 인덱스 동기화를 위해 하루에 한번씩 스케줄러가 실행됩니다.\nDB 품목 데이터가 삭제될 때 ES 데이터도 삭제되어야 하는데 어떠한 이유로 삭제되지 않는 경우가 있었습니다. 즉, 품목이 DB 데이터엔 없지만 ES 데이터에는 있는 경우죠.\n다만 전체 문서를 조회하는 과정의 부하가 많이 걱정되긴 했는데요. 그래서 처음엔 페이징을 활용했습니다.\n\n fun deleteOrphanDocuments() {\n    val pageSize = 1000\n\n    var pageable = PageRequest.of(0, pageSize, Sort.by(Sort.Order.asc(\"id.keyword\")))\n\n    do {\n        val indexPage = productIndexRepository.findAll(pageable)\n        val documentProductIds = indexPage.content.map { it.id }\n\n        val dbProductIds = productRepository.findAllById(documentProductIds).map { it.id }\n\n        val documentIdsNotInDB = documentProductIds - dbProductIds\n        productIndexRepository.deleteAllById(documentIdsNotInDB)\n\n        pageable = pageable.next()\n    } while (indexPage.hasNext())\n}\n\n\n\nES야.. 죽지마.. 테스트서버에서 확인해보니 동기화 할 때마다 자꾸 ES 서버가 다운되더라고요..\n페이징보다 Scroll API 를 이용하는 것이 훨씬 성능상 좋다고 하여서 Scroll API 를 적용해봤습니다.\n\nfun deleteOrphanDocuments() {\n    val toDeleteProductIds = mutableListOf<UUID>()\n\n    val batchSize = 1000\n\n    var documentIdsWithScroll = productIndexRepository.findAllIdWithScroll(size = batchSize)\n\n    while (documentIdsWithScroll.productDocumentIds.isNotEmpty()) {\n        val documentIds = documentIdsWithScroll.productDocumentIds\n        val dbProductIds = productRepository.findAllById(documentIds).map { it.id }\n\n        toDeleteProductIds.addAll(documentIds - dbProductIds)\n\n        documentIdsWithScroll =\n            productIndexRepository.findAllIdByScrollId(\n                scrollId = documentIdsWithScroll.nextScrollId,\n            )\n    }\n\n    productIndexRepository.clearScroll(documentIdsWithScroll.nextScrollId)\n\n    productIndexRepository.deleteAllById(toDeleteProductIds)\n}\n\n\nES 에서 Scroll 을 생성할 때 설정한 시간만큼 Scroll 정보를 저장하고 있고 해당 Scroll ID 를 가지고 다음 데이터를 처리단위만큼 반환해줍니다. \n받은 데이터엔 또 다음 Scroll 조회를 위한 Scroll ID 를 반환하는 형식입니다.\n장점은 페이징 조회보다 계산과 조회가 빠르고 부하가 적은 것인데요. 다만, Scroll 정보를 저장하고 있어야한다는 단점이 있습니다.\n조회 후 clearScroll 해주고 만료 시간을 적게 설정하면 큰 문제가 되지 않을거예요.\n변경 후엔 ES가 건강해졌습니다. 대량 조회가 필요할 땐 Scroll API 를 사용하는걸 추천드립니다.\n검색 품질 유지하기\n추가적으로 쿼리나 스코어링 방식을 변경하다보면 현재의 요구사항에는 만족했지만 이전의 요구사항에 반할 때가 생길 수 있습니다.\n그래서 테스트코드에 이전 요구사항에 관련된 테스트케이스를 꼭 남겨두고 현재 만족할 수 있는 테스트케이스를 더해서\n이전과 현재 요구사항을 모두 만족할 수 있도록 구현하는걸 목표로 했습니다.\n특정 케이스에 모두 만족하는지 일일이 확인하는 것은 현실적으로 어려울 수 있으니 테스트를 든든하게! 잘 짜두는 것이 많은 도움이 될 겁니다!\n이후엔 어떤 것을 할 것인가\nWildcard 검색, 초성 검색, IDF 제거 등 여러 개선들을 해왔는데요.\n요구사항에 맞게, 문제상황에 맞게 조치하는 형식으로 개선해나가다보니 조금은 불필요한 옵션들로 검색을 무겁게 만든 부분들이 분명 있을 수 있을것 같아요.\n또한 검색 엔진에 대한 전문적인 지식 없이 점차 학습하여 개발하다보니 초반과 후반에 대한 지식의 차이가 커서 초반에 했던 방법들이 논리보단 여러 검색어 테스트 POC 로 적용한 것들이 많아요.\n그래서 조금 뚱뚱해진 ES 의 다이어트가 필요해보입니다.\n일단 생각나는 것은 부하를 줄 수 있는 Wildcard 를 없애는 것인데요. N-gram 과 Tokenizer 의 적절한 조합으로 Wildcard 없이 포함된 단어가 잘 조회될 수 있도록 방법을 찾아봐야할 것 같아요.\n그리고 이젠 품목 데이터가 많이 쌓여서 한국 식자재의 대부분 데이터가 존재할 것인데요. 이 데이터로 사용자 사전을 만들어서 검색의 정확도를 높이는 작업을 해볼 수 있을 겁니다.\n추가되는 데이터에 맞춰 사전이 관리되어야 하기 때문에 개발자뿐만 아니라 타부서 팀원분들도 쉽게 관리하기 위한 시스템을 마련해야 할 것 같습니다.\n외래어를 포함하는 새로운 식자재를 등록하는 것도 중요하지만 “셀러드”처럼 식자재이지만 표기를 잘못한 경우도 있어서 이런 경우엔 품목명 자체의 수정이 필요합니다.\nERP에 등록된 품목명과 키친보드의 등록된 품목명의 강한 결합성을 끊을 수 있도록, 검색 엔진의 설정뿐만 아니라 키친보드 품목명의 데이터 클렌징이 필요할거예요.\n마무리\n끝으로, 저희의 지금 검색 엔진은 완성이 아닙니다. 지금도 많이 부족할 수 있지만 사용자의 보이스를 들으며 꾸준히 발전하고 있습니다.\n키친보드를 사용하는 점주 모두가 검색이 너무 편해요! 라고 할때까지, 대충 검색해도 마음속으로 생각했던 품목이 결과에 나오는 그날까지, 발전은 계속 됩니다!\nES 도입과 설정에 도움주시고 자기 일처럼 고민해주신 백엔드 개발자분들과 개선을 위한 데이터를 제공해주신 데이터팀분들, 검색 개선을 위해 피드백 주신 사업팀분들 모두 감사합니다!",
        "id": "https://spoqa.github.io/2025/03/04/es-dev.html",
        "isoDate": "2025-03-04T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": [
      {
        "title": "분산락 적용하기 (실전)",
        "link": "https://velog.io/@sweet_sumin/%EB%B6%84%EC%82%B0%EB%9D%BD-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0-%EC%8B%A4%EC%A0%84",
        "pubDate": "Wed, 05 Mar 2025 22:44:11 GMT",
        "content": "<p>이전까지는 왜 분산락을 적용했고, 해당 코드가 어떤지에 대해서 이야기해보았다. \n이번에는 적용한 코드가 우리가 원하는 동시성에 대한 대책이 제대로 되었는지에 대한 이야기를 해볼것이다. </p>\n<h3 id=\"📌-조건은\">📌 조건은?</h3>\n<p>우선, 난 Jmeter를 활용해서 하나의 락을 거는 @DistributedLock과 여러 락을 동시에 거는@MultiDistributedLock에 대한 동시성 테스트를 진행했다. \n조건은 둘다 똑같이 설정했다.\n<img src=\"https://velog.velcdn.com/images/sweet_sumin/post/849b4964-99df-4eea-a519-a322e784e4b6/image.png\" alt=\"\">\n조건을 해석해보자면, </p>\n<ul>\n<li>50개의 스레드 (동시 사용자 50명)</li>\n<li>Ramp-up 시간 50초 (1초마다 1개의 스레드가 추가됨)</li>\n<li>Loop Count: 10 (각 스레드가 10번 반복 요청)</li>\n</ul>\n<p>→ 즉, 최대 500개의 요청이 순차적으로 발생</p>\n<blockquote>\n<p>추가적으로 설명하자면, \nRamp-up Period는 <strong>모든 스레드(사용자)를 얼마나 걸쳐서 실행할지를 결정하는 값</strong>이다.\n즉, JMeter는 총 N개의 스레드를 Ramp-up Period 동안 균등하게 분배하여 시작한다.</p>\n</blockquote>\n<p>이걸 공식으로 정리하자면,\n🔹 스레드 시작 간격 (초) = Ramp-up Period / 총 스레드 개수</p>\n<blockquote>\n</blockquote>\n<p>내가 설정한 조건에 의하면, Ramp-up Period를 50초, 스레드 개수를 50으로 설정하게 되고\n50초/50쓰레드 가 되니 1초마다 1개의 스레드가 추가되는 구조가 된다. </p>\n<blockquote>\n</blockquote>\n<p>정리하자면, 50초 동안 50개의 스레드가 점진적으로 늘어나며, 매 초마다 1개의 스레드가 실행된다. 50초가 지나면 모든 스레드가 동시에 실행된 상태에서 반복(Loop Count: 10번)하면서 요청을 보내게 되는 조건이다.</p>\n<h3 id=\"📌-테스트-해볼까\">📌 테스트 해볼까?</h3>\n<p>이제 본격적으로 테스트를 해보자. </p>\n<h4 id=\"distributedlock-테스트\">@DistributedLock 테스트</h4>\n<pre><code>{\n  &quot;id&quot;: &quot;row:2&quot;\n}</code></pre><p>하나의 키를 동시에 여러번 테스트하는 것인데 한 키만을 걸었기 때문일까</p>\n<p><img src=\"https://velog.velcdn.com/images/sweet_sumin/post/d23e7a00-16c5-4c70-b5d9-921d352a8301/image.png\" alt=\"\">\n모든 요청이 동시에 보냈음에도 불구하고 성공률이 100%였다 ㅋㅋㅋ \n<img src=\"https://velog.velcdn.com/images/sweet_sumin/post/aee8b3f3-7fa2-4e83-b5b2-f5dcdb045270/image.png\" alt=\"\">\n하나하나 뜯어보자면, </p>\n<ul>\n<li>Samples: 500 → 총 500개의 요청이 전송됨</li>\n<li>Average: 5006 ms → 모든 요청의 평균 응답 시간이 5006ms (5.006초)</li>\n<li>Median: 5006 ms → 응답 시간을 작은 순서대로 정렬했을 때 중간 값이 5006ms</li>\n<li>90% Line:    5010 ms    → 응답 시간이 5010ms 이하인 요청이 전체의 90%</li>\n<li>95% Line:    5012 ms    → 응답 시간이 5012ms 이하인 요청이 전체의 95%</li>\n<li>99% Line:    5015 ms    → 응답 시간이 5015ms 이하인 요청이 전체의 99%</li>\n<li>Min: 5001 ms → 가장 빠른 응답 시간이 5001ms</li>\n<li>Max: 5028 ms → 가장 느린 응답 시간이 5028ms</li>\n<li>Error %: 0.0% → 오류 없이 100% 성공</li>\n<li>Throughput: 5.0/sec → 초당 평균 5개의 요청을 처리</li>\n<li>Received KB/sec: 0.86 KB/s → 서버에서 초당 0.86KB 데이터를 받아옴</li>\n<li>Sent KB/sec: 1.03 KB/s → 서버로 초당 1.03KB 데이터를 보냄</li>\n</ul>\n<p>평균 응답시간 (Throughput)이 5초인게 아마 코드 상  Thread.sleep(5000) 영향인 듯 싶다. \n사실 어떻게 100% 성공일 수 있지? 설마 락이 안걸리나 싶어서 \n<img src=\"https://velog.velcdn.com/images/sweet_sumin/post/0912875b-5fa1-4058-85bb-03112f3f1c90/image.png\" alt=\"\">\nlog를 걸어서 봤는데 락이 잘 걸려있는 것을 확인할 수 있었다. \n그렇다면 멀티로 락을 걸었을때는 어떨까?</p>\n<h4 id=\"multidistributedlock-테스트\">@MultiDistributedLock 테스트</h4>\n<p>@DistributedLock과 같은 조건으로 진행하였다. \n사실 처음에 테스트 할때는 이것도 성공률이 100%일줄 알았다. \n<img src=\"https://velog.velcdn.com/images/sweet_sumin/post/ad959716-4791-4047-93df-a2d511e200a1/image.png\" alt=\"\"></p>\n<p>뭐야? 이건 왜 간간히 성공해?? 왜 실패한건 500에러야?\n<img src=\"https://velog.velcdn.com/images/sweet_sumin/post/9fa1e95b-a09a-492f-9628-92adfdd3195c/image.png\" alt=\"\">\n에러 메세지를 확인해보니, 락 거는데 에러가 뜬거였다. </p>\n<h5 id=\"single-락과-multi-락-왜-같은-조건인데-결과가-다를까\">Single 락과 Multi 락 왜 같은 조건인데 결과가 다를까??</h5>\n<p>✔️ @DistributedLock (Single)\n<img src=\"https://velog.velcdn.com/images/sweet_sumin/post/ccb73d20-3996-413d-8907-5390f226833d/image.png\" alt=\"\"></p>\n<ul>\n<li>요청마다 <strong>하나의 키(row:2 같은 단일 값)</strong>만 사용</li>\n<li>waitTime = 15이므로 락을 못 잡으면 최대 15초까지 대기 + 쓰레드 sleep 5초</li>\n<li>하나의 키만 처리하므로 충돌 가능성이 낮음</li>\n<li>결과적으로 스레드 간 충돌 없이 요청이 순차적으로 처리됨 → 실패율 낮음</li>\n</ul>\n<p>✔️ @MultiDistributedLock (Multi)\n<img src=\"https://velog.velcdn.com/images/sweet_sumin/post/3ed86a1b-dad1-4e10-a9b7-b59bd2a56aa5/image.png\" alt=\"\"></p>\n<ul>\n<li>여러 개의 키([&quot;row:2&quot;,&quot;row:1&quot;,&quot;row:3&quot;])를 락으로 사용</li>\n<li>만약 다른 스레드가 row:1을 선점했다면, row:2와 row:3이 잠겨 있어도 락을 얻지 못함</li>\n<li>락을 얻지 못하면 실패 (대기 시간이 지나도 모든 키를 얻지 못하면 실패)</li>\n<li>일부 키만 사용 가능해도 전체가 실패하는 구조 → 충돌 가능성이 급증</li>\n</ul>\n<p>따라서 싱글락과 달리 멀티락에서 에러가 뜨는 것은 동시성 테스트에서 잘 방어를 하고 있다는 뜻이었다. </p>\n<p>참고) 나의 github 코드 : <a href=\"https://github.com/sue4869/lockPractice\">https://github.com/sue4869/lockPractice</a></p>\n",
        "contentSnippet": "이전까지는 왜 분산락을 적용했고, 해당 코드가 어떤지에 대해서 이야기해보았다. \n이번에는 적용한 코드가 우리가 원하는 동시성에 대한 대책이 제대로 되었는지에 대한 이야기를 해볼것이다. \n📌 조건은?\n우선, 난 Jmeter를 활용해서 하나의 락을 거는 @DistributedLock과 여러 락을 동시에 거는@MultiDistributedLock에 대한 동시성 테스트를 진행했다. \n조건은 둘다 똑같이 설정했다.\n\n조건을 해석해보자면, \n50개의 스레드 (동시 사용자 50명)\nRamp-up 시간 50초 (1초마다 1개의 스레드가 추가됨)\nLoop Count: 10 (각 스레드가 10번 반복 요청)\n→ 즉, 최대 500개의 요청이 순차적으로 발생\n추가적으로 설명하자면, \nRamp-up Period는 모든 스레드(사용자)를 얼마나 걸쳐서 실행할지를 결정하는 값이다.\n즉, JMeter는 총 N개의 스레드를 Ramp-up Period 동안 균등하게 분배하여 시작한다.\n이걸 공식으로 정리하자면,\n🔹 스레드 시작 간격 (초) = Ramp-up Period / 총 스레드 개수\n내가 설정한 조건에 의하면, Ramp-up Period를 50초, 스레드 개수를 50으로 설정하게 되고\n50초/50쓰레드 가 되니 1초마다 1개의 스레드가 추가되는 구조가 된다. \n정리하자면, 50초 동안 50개의 스레드가 점진적으로 늘어나며, 매 초마다 1개의 스레드가 실행된다. 50초가 지나면 모든 스레드가 동시에 실행된 상태에서 반복(Loop Count: 10번)하면서 요청을 보내게 되는 조건이다.\n📌 테스트 해볼까?\n이제 본격적으로 테스트를 해보자. \n@DistributedLock 테스트\n{\n  \"id\": \"row:2\"\n}\n하나의 키를 동시에 여러번 테스트하는 것인데 한 키만을 걸었기 때문일까\n\n모든 요청이 동시에 보냈음에도 불구하고 성공률이 100%였다 ㅋㅋㅋ \n\n하나하나 뜯어보자면, \nSamples: 500 → 총 500개의 요청이 전송됨\nAverage: 5006 ms → 모든 요청의 평균 응답 시간이 5006ms (5.006초)\nMedian: 5006 ms → 응답 시간을 작은 순서대로 정렬했을 때 중간 값이 5006ms\n90% Line:    5010 ms    → 응답 시간이 5010ms 이하인 요청이 전체의 90%\n95% Line:    5012 ms    → 응답 시간이 5012ms 이하인 요청이 전체의 95%\n99% Line:    5015 ms    → 응답 시간이 5015ms 이하인 요청이 전체의 99%\nMin: 5001 ms → 가장 빠른 응답 시간이 5001ms\nMax: 5028 ms → 가장 느린 응답 시간이 5028ms\nError %: 0.0% → 오류 없이 100% 성공\nThroughput: 5.0/sec → 초당 평균 5개의 요청을 처리\nReceived KB/sec: 0.86 KB/s → 서버에서 초당 0.86KB 데이터를 받아옴\nSent KB/sec: 1.03 KB/s → 서버로 초당 1.03KB 데이터를 보냄\n평균 응답시간 (Throughput)이 5초인게 아마 코드 상  Thread.sleep(5000) 영향인 듯 싶다. \n사실 어떻게 100% 성공일 수 있지? 설마 락이 안걸리나 싶어서 \n\nlog를 걸어서 봤는데 락이 잘 걸려있는 것을 확인할 수 있었다. \n그렇다면 멀티로 락을 걸었을때는 어떨까?\n@MultiDistributedLock 테스트\n@DistributedLock과 같은 조건으로 진행하였다. \n사실 처음에 테스트 할때는 이것도 성공률이 100%일줄 알았다. \n\n뭐야? 이건 왜 간간히 성공해?? 왜 실패한건 500에러야?\n\n에러 메세지를 확인해보니, 락 거는데 에러가 뜬거였다. \nSingle 락과 Multi 락 왜 같은 조건인데 결과가 다를까??\n✔️ @DistributedLock (Single)\n\n요청마다 하나의 키(row:2 같은 단일 값)만 사용\nwaitTime = 15이므로 락을 못 잡으면 최대 15초까지 대기 + 쓰레드 sleep 5초\n하나의 키만 처리하므로 충돌 가능성이 낮음\n결과적으로 스레드 간 충돌 없이 요청이 순차적으로 처리됨 → 실패율 낮음\n✔️ @MultiDistributedLock (Multi)\n\n여러 개의 키([\"row:2\",\"row:1\",\"row:3\"])를 락으로 사용\n만약 다른 스레드가 row:1을 선점했다면, row:2와 row:3이 잠겨 있어도 락을 얻지 못함\n락을 얻지 못하면 실패 (대기 시간이 지나도 모든 키를 얻지 못하면 실패)\n일부 키만 사용 가능해도 전체가 실패하는 구조 → 충돌 가능성이 급증\n따라서 싱글락과 달리 멀티락에서 에러가 뜨는 것은 동시성 테스트에서 잘 방어를 하고 있다는 뜻이었다. \n참고) 나의 github 코드 : https://github.com/sue4869/lockPractice",
        "guid": "https://velog.io/@sweet_sumin/%EB%B6%84%EC%82%B0%EB%9D%BD-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0-%EC%8B%A4%EC%A0%84",
        "isoDate": "2025-03-05T22:44:11.000Z"
      },
      {
        "title": "분산락 적용하기 (개념)",
        "link": "https://velog.io/@sweet_sumin/%EB%B6%84%EC%82%B0%EB%9D%BD-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0-%EA%B0%9C%EB%85%90",
        "pubDate": "Wed, 05 Mar 2025 22:42:55 GMT",
        "content": "<h2 id=\"📌-적용-배경\">📌 적용 배경</h2>\n<p>이번에 회사에서 하는 프로젝트는 &#39;오더 상태 관리&#39;이다. &#39;오더서밋, 오더취소, 배송, 오 더컨펌&#39; 까지의 다양한 오더 상태에 대한 관리를 적용하는 프로젝트이다. </p>\n<p>우리 회사는 공급사 상품들의 묶음 단위인 딜을 이용해 주문을 한다. 상품이 있으니까 재고가 있겠지? 즉, 각 오더 상태의 역할별로 재고가 차감되거나 복원된다. </p>\n<ul>\n<li>오더 서밋시 : 재고 차감</li>\n<li>오더 취소시 : 재고 복원</li>\n<li>오더 컨펌시 : 재고 차감 / 재고 복원\n이러한 상태가 변경될때 각 딜에는 항상 중복되는 상품이 존재하기 때문에 동시성 문제가 발생하게 된다. 여기서 추가로 딜에는 여러 상품들이 있기 때문에 여러 상품을 동시에 락을 걸어야 하는 상황이다. </li>\n</ul>\n<h2 id=\"📌-동시성-문제를-해결하는-방법\">📌 동시성 문제를 해결하는 방법</h2>\n<p>여러가지 방법이 있는데 비관적락, 낙관적락, 분산락, 네임드락 등이 있다. 각각의 특징을 간단히 알아보자면,</p>\n<p>1) 비관적락(DB락)</p>\n<ul>\n<li>DB에서 직접 락을 걸어 다른 트랜잭션 차단</li>\n<li>장점 : 데이터 정합성 강하게 보장, 실시간 동시 수정 방지 가능</li>\n<li>단점 : 성능 저하(트랜잭션이 길어질수록 락 유지시간 증가), 데드락</li>\n<li>적용 예시) 은행 계좌 잔고 업데이트</li>\n</ul>\n<p>2) 낙관적락(버전 필드)</p>\n<ul>\n<li>충돌 감지 후 재시도 (rollback &amp; retry)</li>\n<li>장점 : 락을 안걸어서 성능이 좋음</li>\n<li>단점 : 충돌이 빈번할 경우 계속 재시도하여 성능 저하를 일으킴. 정합성이 다소 낮음</li>\n</ul>\n<p>3) 분산락(Redis, Zookeeper)</p>\n<ul>\n<li>여러 서버에서 동일한 리소스를 동시에 수정하지 못하도록 제어</li>\n<li>장점 : 분산 시스템에도 동기화 가능</li>\n<li>단점 : 락 관리(해제, TTL 설정 등) 신경 써야 함, 분산 환경에서 네트워크 이슈로 인해 지연 가능</li>\n</ul>\n<p>우리 회사의 경우, 멀티 인스턴스 환경에서 오더상태 변경을 해야하고 재고관리에 있어서 강한 정합성을 요구하기 때문에 분산락을 적용하기로 결정하였다.</p>\n<h2 id=\"📌-분산락\">📌 분산락</h2>\n<p>분산락이란 무엇일까?\n앞서 언급했듯이 분산락은 여러 서버에서 동일한 리소스를 동시에 접근하지 못하도록 제어하는 것을 의미한다.(비관적 락이나 낙관적 락은 하나의 DB에서만 동작하는 락) 좀 더 기술적 용어를 사용해서 설명하자면, </p>\n<blockquote>\n<p>💡 분산락\n락을 획득한 프로세스 혹은 스레드만이 공유 자원 혹은 Critical Section 에 접근할 수 있도록 하는 것</p>\n</blockquote>\n<p><strong>키(락)를 가진 사람(프로세스/스레드)만 보물이 있는 공간(공유자원)의 문을 열 수 있는 것이다</strong> 🗝</p>\n<p>분산락을 적용하는 방법은 여러가지가 있다. Redis, Zookeeper, MySql 등등.. 결론적으로 말하자면, 우린 Redis를 사용하였다.\n우선 Redis는 그동안 캐시용도로 이미 구성해놓은 반면에 Zookeeper는 추가적인 인프라 구성이 필요하기 때문에 제외하게 되었다. 그리고 알다시피 Redis는 싱글스레드로 작동하기 때문에 동시성 문제도 현저히 작다. 아 물론 Mysql도 있긴 한데, 락을 사용하기 위해 별도의 커넥션 풀을 관리해야 하고 락에 관련된 부하를 RDS에서 받으니 Redis를 사용하는 것이 더 효율적이다.</p>\n<h3 id=\"redisson을-사용한-이유는\">Redisson을 사용한 이유는?</h3>\n<p>Redis는 인메모리 데이터 저장소로 사용되지만 , 캐시 역할을 넘어서 다양한 분산 시스템 기능을 지원하는 구현제(라이브러리, 프레임워크)들이 존재한다. 그 중 난 분산락을 위한 구현체에 대해 간단히 알아보자면,</p>\n<ul>\n<li>Jedis -&gt; Lettuce가 성능이 더 좋아서 Lettuce로 대체됨</li>\n<li>Lettuce</li>\n<li>Redisson</li>\n</ul>\n<p>1) Lettuce</p>\n<ul>\n<li>Spring Data Redis에서 기본적으로 사용하는 Redis 클라이언트</li>\n<li>setnx를 활용한 스핀락 : 반복적으로 락 획득 시도 -&gt; 레디스에 많은 부하 발생. CPU를 계속 사용하면서 재시도하는 방식</li>\n<li>락 획득 방식\n(1) SET NX 명령어로 락 획득을 시도\n(2) 락이 없으면 성공 → 작업 진행 후 DEL로 락 해제\n(3) 이미 락이 있으면 실패 → 일정 시간 대기 후 재시도 (스핀락 방식)\n(4) TTL(EX)을 설정하여 데드락 방지</li>\n</ul>\n<p>2) Redisson</p>\n<ul>\n<li><p>별도의 Lock interface를 지원 : RedLock, RLock(단일 인스턴스 락) 지원</p>\n<blockquote>\n<p>💡 RedLock</p>\n<ul>\n<li>Redis 기반의 분산 락을 더 안전하게 보장하기 위한 알고리즘</li>\n<li>멀티 Redis 노드 환경에서 장애 복구가 중요한 경우</li>\n<li>데이터 정합성이 중요한 글로벌 시스템</li>\n<li>Redis 장애가 발생해도 락을 유지해야 하는 경우</li>\n<li>RedLock은 과반수 이상의 Redis 노드에서 락을 획득해야 성공</li>\n</ul>\n</blockquote>\n</li>\n<li><p>Pub/Sub 방식을 이용하기에 락이 해제되면 락을 subscribe 하는 클라이언트는 락이 해제되었다는 신호를 받고 락 획득을 시도</p>\n</li>\n<li><p>Redisson은 락 대기 및 해제 처리를 최적화하여 불필요한 CPU 낭비 없이 안정적으로 락을 관리</p>\n</li>\n<li><p>락이 만료되기 전에 자동으로 TTL을 연장하여, 장시간 작업에서도 안정적인 락 유지가 가능\n( Lettuce는 TTL이 지나면 락이 풀릴 수 있어 작업 중 충돌 위험이 존재 )</p>\n</li>\n</ul>\n<p>결론적으로, Lettuce보다 안정적인 분산 락이 필요했고, CPU 사용을 줄이면서 TTL 자동 연장과 다양한 락 기능을 활용하기 위해 Redisson을 선택하게 된것이다. 그럼 이제, RedLock을 이용할지, RLock을 이용해서 구현할지에 대한 고민이 생긴다.</p>\n<h3 id=\"redlock-rlock--어떤-것을-이용할까\">RedLock, RLock ? 어떤 것을 이용할까</h3>\n<p>❌ RedLock이 과할 수 있는 경우\n싱글 Redis 노드 환경이거나, 락을 걸어야 하는 트랜잭션이 짧다면 RedLock은 오버헤드가 될 수도 있다</p>\n<ul>\n<li>단일 Redis 인스턴스 환경에서는 RedLock을 사용할 필요 없음</li>\n<li>과반수 노드가 죽으면 락 획득이 불가능해질 수도 있음</li>\n</ul>\n<p>현재 우리의 레디스 환경은 하나의 레디스 인스턴스에서 모든 데이터와 락을 관리하는 싱글 노드 형태이기 때문에 RedLock보다는 RLock을 선택하는 것이 낫다는 판단이 되었다.</p>\n<h3 id=\"코드내에서-주목해야-할점\">코드내에서 주목해야 할점</h3>\n<p>코드 내에서 주목해야 할 점을 난 2가지를 뽑았다. </p>\n<p>1) RLock의 내부 코드 파헤치기\n2) 트랜잭션 분리</p>\n<h4 id=\"🤔-rlock의-내부-코드-파헤치기\">🤔 RLock의 내부 코드 파헤치기</h4>\n<p>Redission을 이용한 분산락 코드는 사실 인터넷을 조금은 서칭하면 거의 비슷하게 나온다. 그런데 정작 내부의 RLock의 코드를 파헤친 기록은 없더이다. 퇴근하고 남는게 시간인데 놀면 뭐하나,, 내부 코드 뒤적거리면서 시간이나 보내야지 ⏳\n적용한 코드를 크게 보면 간단하다</p>\n<blockquote>\n<p>락 객체 생성(열쇠 가져오기) → 락 걸기(열쇠로 잠그기) → 락 해제(열쇠로 잠금 풀기) </p>\n</blockquote>\n<p>1) 락 객체 생성(열쇠 가져오기)</p>\n<p>자.. 락 객체 생성부터 알아볼까?\n<img src=\"https://velog.velcdn.com/images/sweet_sumin/post/c0c778c4-6249-4dd9-b28e-272717b5ae1b/image.png\" alt=\"\">\n처음 시작은 getLock부터 시작한다. 이 코드를 따라가다보면, 최종적으로 RedissonLock 클래스의 생성자로 연결된다. \n<img src=\"https://velog.velcdn.com/images/sweet_sumin/post/f3c40997-5bd3-4697-b199-ff112467f38f/image.png\" alt=\"\">\n첫번째 코드 줄을 통해, RedissonLock은 RedissonBaseLock을 상속받고, 기본적인 락 이름(name)과 명령 실행기(commandExecutor)가 초기화함을 알 수 있다. \n명령 실행기(commandExecutor)라는 것은 <strong>🎁 비동기 Redis 명령어 실행기</strong>를 의미한다. 음 Redis에 직접 명령을 보내는 역할인거다. 예를 들어 tryLock()을 호출하면, 내부적으로 SET NX PX 명령이 Redis에 전송되는 것이다. 그래서 명령 실행기를 초기화한다는 것은 commandExecutor를 통해 Redis와 통신할 준비를 한다는 거라고 생각하면 된다. </p>\n<p>internalLockLeaseTime는 자동 락 해제 시간 설정하는 것이다. 여기서 우리가 주목해야 할것은 🎁 <strong>락 워치독 (Watchdog)</strong> 기능이다. 쉽게 말하면, 자동 연장 기능이다. </p>\n<blockquote>\n<p>📌 락 워치독(Watchdog)은 왜 필요할까?\n보통 Redis에서 락을 설정할 때 TTL(만료 시간)을 지정하는데, 작업이 TTL 안에 끝나지 않으면 락이 자동으로 해제되는 문제가 있다. </p>\n<p>예를 들어 TTL이 5초인데 작업이 6초걸린다고 치자. 5초 후 락이 만료되고 자동으로 해제되면?\n다른 프로세스가 같은 락을 획득할 수 있다 → 데이터 일관성 깨짐 😨\n그래서 락을 획득한 스레드가 살아 있는 동안 TTL이 자동으로 연장된다는 기능이다. TTL을 직접 설정하지 않으면 기본 30초 동안 유지된다고 한다. </p>\n</blockquote>\n<p>마지막 줄인 pubSub은 <strong>🎁 Pub/Sub 기능</strong>을 활용하여 락 해제 이벤트를 감지하는 역할이다. \nRedis에서 분산 락을 사용할 때, 다른 클라이언트가 락을 대기하는 방식에는 2가지 방식이 있다. </p>\n<ul>\n<li>폴링(Polling) 방식: 주기적으로 Redis를 조회해서 락이 해제되었는지 확인함.</li>\n<li>이벤트 기반 방식: 락이 해제될 때 Redis가 직접 알림(Pub/Sub)을 보내서 대기 중인 클라이언트가 즉시 실행됨.</li>\n</ul>\n<p>만약 폴링 방식이라면? 락을 얻으려는 클라이언트가 주기적으로 Redis에 요청을 보내 락이 해제되었는지 확인해야한다. 듣기만 해도, 불필요한 Redis 부하가 발생하고 클라이언트가 지속적으로 Redis에 요청을 보내므로 트래픽이 많아질 거라는 단점이 느껴지지?\n그래서 Redisson에서는 락이 해제될 때 이벤트를 발생시켜 다른 클라이언트가 즉시 실행될 수 있도록 처리한다. <strong>언제? RLock.unlock() 이 호출될때!</strong></p>\n<p>2) 락 걸기(열쇠로 잠그기)\n이제 락을 어떻게 거는지 알아보자. 코드를 따라가다보면 Redission 클래스에서 tryLock()의 구현체를 확인할 수 있다. \n코드에 대한 내용을 간단하게 정리하자면, \n주어진 대기 시간(waitTime) 내에 락을 획득하려 시도하며, 락을 획득하면 지정된 임대 시간(leaseTime) 동안 락을 유지한다. 락을 즉시 획득하지 못한 경우, 다른 클라이언트의 락 해제 이벤트를 대기하기 위해 Pub/Sub 메커니즘을 활용하고, 대기 시간 내에 락을 획득하지 못하면 false를 반환하는 매커니즘을 확인할 수 있다. \n<img src=\"https://velog.velcdn.com/images/sweet_sumin/post/942080f9-4adb-40d5-b537-e2ee4f3e0251/image.png\" alt=\"\"></p>\n<p>3) 락 해제(열쇠로 잠금 풀기)</p>\n<p>비동기적으로 락을 해제하는 모습을 볼 수 있다. 앞서 언급했듯이  Redisson에서는 락이 해제될 때 이벤트를 발생시켜 다른 클라이언트가 즉시 실행될 수 있도록 처리한다 -&gt; 이부분을 찾기 위해 코드를 엄청 뒤졌는데 사실 해당 역할을 하는 코드를 찾을 수가 없어서 좀 아쉽다..ㅠ\n<img src=\"https://velog.velcdn.com/images/sweet_sumin/post/8aa9b100-ef12-4199-b10c-efb8cad433b0/image.png\" alt=\"\"></p>\n<h4 id=\"🤔-트랜잭션-분리\">🤔 트랜잭션 분리</h4>\n<p>코드를 살펴보면 락을 걸고 나서 트랜잭션을 분리해서 비즈니스 로직을 실행하는 역할을 하는 것을 볼 수 있다. </p>\n<p><img src=\"https://velog.velcdn.com/images/sweet_sumin/post/55536ec0-d5e8-4f62-964e-08458dbc23c2/image.png\" alt=\"\">\n음..쉽게 말하면 DistributedLock 어노테이션이 선언된 메서드를 <strong>별도의 트랜잭션으로</strong> 실행하게 만든 코드인 것이다. \n<img src=\"https://velog.velcdn.com/images/sweet_sumin/post/13dbe77e-56f1-40fc-ad98-d20acca68ccf/image.png\" alt=\"\"></p>\n<p>Propagation.REQUIRES_NEW 옵션을 지정해 부모 트랜잭션의 유무에 관계없이 별도의 트랜잭션으로 동작하게끔 설정하고 반드시 트랜잭션 커밋 이후 락이 해제되게끔 처리하고 있다. 왜 이렇게 분리를 했을까?\n해당 내용은 <a href=\"https://helloworld.kurly.com/blog/distributed-redisson-lock/\">컬리의 블로그</a>에 너무 자세히 써져있다. 내가 진행한 프로젝트도 재고를 위한 분산락인데 여기서도 재고를 예시로 들어서 너무나 적절하게 써져있으니 해당 링크 참고하길 바란다. 결론을 말하자면 데이터 정합성을 위한 방법으로 트랜잭션 커밋 이후 락이 해제되게끔 처리 해놓았다. </p>\n<h2 id=\"📌-추가된-요구사항\">📌 추가된 요구사항</h2>\n<p>실전으로 넘어가기 전에, 추가할 요구사항이 있다. 앞선 요구사항은 하나의 key 즉, 하나의 row만 락을 거는 형식으로 구현되어 있다. 하지만 우리 회사 특성상 주문시 여러 상품을 동시에 상태 변경하기 때문에 한번에 여러 상품의 재고를 변경해야한다. 따라서 하나의 row가 아닌 여러 row에 락을 걸어야 한다. </p>\n<p>그렇다면 기존에 받는 키도 하나에서 여러개를 받게 되고 락도 동시에 여러개를 건다는 말이겠지? 정리하자면, 여러 개의 락을 동시에 걸고, 하나라도 실패하면 전체 실패하도록 하고 싶다는 것이다. 이때 난 RedissonMultiLock이라는 것을 사용했다. </p>\n<p><img src=\"https://velog.velcdn.com/images/sweet_sumin/post/daf79e99-4aee-49a1-ab06-aae8528faa82/image.png\" alt=\"\"></p>\n<p>즉, 하나의 트랜잭션처럼 모든 락이 성공해야만 실행되도록 할때 사용된다. 그렇다는 말은 락을 해제할때도 한꺼번에 해제한다는 말과 동일하다. </p>\n<p>이제 추가된 요구까지 알아보았으니 본격적으로 테스트를 해볼까? 해당 내용은 다음편에 있다. </p>\n<p>참고) </p>\n<ul>\n<li><a href=\"https://velog.io/@a01021039107/%EB%B6%84%EC%82%B0%EB%9D%BD%EC%9C%BC%EB%A1%9C-%ED%95%B4%EA%B2%B0%ED%95%98%EB%8A%94-%EB%8F%99%EC%8B%9C%EC%84%B1-%EB%AC%B8%EC%A0%9C%EC%9D%B4%EB%A1%A0%ED%8E%B8\">https://velog.io/@a01021039107/%EB%B6%84%EC%82%B0%EB%9D%BD%EC%9C%BC%EB%A1%9C-%ED%95%B4%EA%B2%B0%ED%95%98%EB%8A%94-%EB%8F%99%EC%8B%9C%EC%84%B1-%EB%AC%B8%EC%A0%9C%EC%9D%B4%EB%A1%A0%ED%8E%B8</a></li>\n<li><a href=\"https://helloworld.kurly.com/blog/distributed-redisson-lock/\">https://helloworld.kurly.com/blog/distributed-redisson-lock/</a></li>\n<li><a href=\"https://techblog.woowahan.com/17416/\">https://techblog.woowahan.com/17416/</a></li>\n<li><a href=\"https://velog.io/@jinony/Spring-Boot-Apache-JMeter%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EB%B6%80%ED%95%98-%ED%85%8C%EC%8A%A4%ED%8A%B8\">https://velog.io/@jinony/Spring-Boot-Apache-JMeter%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EB%B6%80%ED%95%98-%ED%85%8C%EC%8A%A4%ED%8A%B8</a></li>\n</ul>\n",
        "contentSnippet": "📌 적용 배경\n이번에 회사에서 하는 프로젝트는 '오더 상태 관리'이다. '오더서밋, 오더취소, 배송, 오 더컨펌' 까지의 다양한 오더 상태에 대한 관리를 적용하는 프로젝트이다. \n우리 회사는 공급사 상품들의 묶음 단위인 딜을 이용해 주문을 한다. 상품이 있으니까 재고가 있겠지? 즉, 각 오더 상태의 역할별로 재고가 차감되거나 복원된다. \n오더 서밋시 : 재고 차감\n오더 취소시 : 재고 복원\n오더 컨펌시 : 재고 차감 / 재고 복원\n이러한 상태가 변경될때 각 딜에는 항상 중복되는 상품이 존재하기 때문에 동시성 문제가 발생하게 된다. 여기서 추가로 딜에는 여러 상품들이 있기 때문에 여러 상품을 동시에 락을 걸어야 하는 상황이다. \n📌 동시성 문제를 해결하는 방법\n여러가지 방법이 있는데 비관적락, 낙관적락, 분산락, 네임드락 등이 있다. 각각의 특징을 간단히 알아보자면,\n1) 비관적락(DB락)\nDB에서 직접 락을 걸어 다른 트랜잭션 차단\n장점 : 데이터 정합성 강하게 보장, 실시간 동시 수정 방지 가능\n단점 : 성능 저하(트랜잭션이 길어질수록 락 유지시간 증가), 데드락\n적용 예시) 은행 계좌 잔고 업데이트\n2) 낙관적락(버전 필드)\n충돌 감지 후 재시도 (rollback & retry)\n장점 : 락을 안걸어서 성능이 좋음\n단점 : 충돌이 빈번할 경우 계속 재시도하여 성능 저하를 일으킴. 정합성이 다소 낮음\n3) 분산락(Redis, Zookeeper)\n여러 서버에서 동일한 리소스를 동시에 수정하지 못하도록 제어\n장점 : 분산 시스템에도 동기화 가능\n단점 : 락 관리(해제, TTL 설정 등) 신경 써야 함, 분산 환경에서 네트워크 이슈로 인해 지연 가능\n우리 회사의 경우, 멀티 인스턴스 환경에서 오더상태 변경을 해야하고 재고관리에 있어서 강한 정합성을 요구하기 때문에 분산락을 적용하기로 결정하였다.\n📌 분산락\n분산락이란 무엇일까?\n앞서 언급했듯이 분산락은 여러 서버에서 동일한 리소스를 동시에 접근하지 못하도록 제어하는 것을 의미한다.(비관적 락이나 낙관적 락은 하나의 DB에서만 동작하는 락) 좀 더 기술적 용어를 사용해서 설명하자면, \n💡 분산락\n락을 획득한 프로세스 혹은 스레드만이 공유 자원 혹은 Critical Section 에 접근할 수 있도록 하는 것\n키(락)를 가진 사람(프로세스/스레드)만 보물이 있는 공간(공유자원)의 문을 열 수 있는 것이다 🗝\n분산락을 적용하는 방법은 여러가지가 있다. Redis, Zookeeper, MySql 등등.. 결론적으로 말하자면, 우린 Redis를 사용하였다.\n우선 Redis는 그동안 캐시용도로 이미 구성해놓은 반면에 Zookeeper는 추가적인 인프라 구성이 필요하기 때문에 제외하게 되었다. 그리고 알다시피 Redis는 싱글스레드로 작동하기 때문에 동시성 문제도 현저히 작다. 아 물론 Mysql도 있긴 한데, 락을 사용하기 위해 별도의 커넥션 풀을 관리해야 하고 락에 관련된 부하를 RDS에서 받으니 Redis를 사용하는 것이 더 효율적이다.\nRedisson을 사용한 이유는?\nRedis는 인메모리 데이터 저장소로 사용되지만 , 캐시 역할을 넘어서 다양한 분산 시스템 기능을 지원하는 구현제(라이브러리, 프레임워크)들이 존재한다. 그 중 난 분산락을 위한 구현체에 대해 간단히 알아보자면,\nJedis -> Lettuce가 성능이 더 좋아서 Lettuce로 대체됨\nLettuce\nRedisson\n1) Lettuce\nSpring Data Redis에서 기본적으로 사용하는 Redis 클라이언트\nsetnx를 활용한 스핀락 : 반복적으로 락 획득 시도 -> 레디스에 많은 부하 발생. CPU를 계속 사용하면서 재시도하는 방식\n락 획득 방식\n(1) SET NX 명령어로 락 획득을 시도\n(2) 락이 없으면 성공 → 작업 진행 후 DEL로 락 해제\n(3) 이미 락이 있으면 실패 → 일정 시간 대기 후 재시도 (스핀락 방식)\n(4) TTL(EX)을 설정하여 데드락 방지\n2) Redisson\n별도의 Lock interface를 지원 : RedLock, RLock(단일 인스턴스 락) 지원\n💡 RedLock\nRedis 기반의 분산 락을 더 안전하게 보장하기 위한 알고리즘\n멀티 Redis 노드 환경에서 장애 복구가 중요한 경우\n데이터 정합성이 중요한 글로벌 시스템\nRedis 장애가 발생해도 락을 유지해야 하는 경우\nRedLock은 과반수 이상의 Redis 노드에서 락을 획득해야 성공\nPub/Sub 방식을 이용하기에 락이 해제되면 락을 subscribe 하는 클라이언트는 락이 해제되었다는 신호를 받고 락 획득을 시도\nRedisson은 락 대기 및 해제 처리를 최적화하여 불필요한 CPU 낭비 없이 안정적으로 락을 관리\n락이 만료되기 전에 자동으로 TTL을 연장하여, 장시간 작업에서도 안정적인 락 유지가 가능\n( Lettuce는 TTL이 지나면 락이 풀릴 수 있어 작업 중 충돌 위험이 존재 )\n결론적으로, Lettuce보다 안정적인 분산 락이 필요했고, CPU 사용을 줄이면서 TTL 자동 연장과 다양한 락 기능을 활용하기 위해 Redisson을 선택하게 된것이다. 그럼 이제, RedLock을 이용할지, RLock을 이용해서 구현할지에 대한 고민이 생긴다.\nRedLock, RLock ? 어떤 것을 이용할까\n❌ RedLock이 과할 수 있는 경우\n싱글 Redis 노드 환경이거나, 락을 걸어야 하는 트랜잭션이 짧다면 RedLock은 오버헤드가 될 수도 있다\n단일 Redis 인스턴스 환경에서는 RedLock을 사용할 필요 없음\n과반수 노드가 죽으면 락 획득이 불가능해질 수도 있음\n현재 우리의 레디스 환경은 하나의 레디스 인스턴스에서 모든 데이터와 락을 관리하는 싱글 노드 형태이기 때문에 RedLock보다는 RLock을 선택하는 것이 낫다는 판단이 되었다.\n코드내에서 주목해야 할점\n코드 내에서 주목해야 할 점을 난 2가지를 뽑았다. \n1) RLock의 내부 코드 파헤치기\n2) 트랜잭션 분리\n🤔 RLock의 내부 코드 파헤치기\nRedission을 이용한 분산락 코드는 사실 인터넷을 조금은 서칭하면 거의 비슷하게 나온다. 그런데 정작 내부의 RLock의 코드를 파헤친 기록은 없더이다. 퇴근하고 남는게 시간인데 놀면 뭐하나,, 내부 코드 뒤적거리면서 시간이나 보내야지 ⏳\n적용한 코드를 크게 보면 간단하다\n락 객체 생성(열쇠 가져오기) → 락 걸기(열쇠로 잠그기) → 락 해제(열쇠로 잠금 풀기) \n1) 락 객체 생성(열쇠 가져오기)\n자.. 락 객체 생성부터 알아볼까?\n\n처음 시작은 getLock부터 시작한다. 이 코드를 따라가다보면, 최종적으로 RedissonLock 클래스의 생성자로 연결된다. \n\n첫번째 코드 줄을 통해, RedissonLock은 RedissonBaseLock을 상속받고, 기본적인 락 이름(name)과 명령 실행기(commandExecutor)가 초기화함을 알 수 있다. \n명령 실행기(commandExecutor)라는 것은 🎁 비동기 Redis 명령어 실행기를 의미한다. 음 Redis에 직접 명령을 보내는 역할인거다. 예를 들어 tryLock()을 호출하면, 내부적으로 SET NX PX 명령이 Redis에 전송되는 것이다. 그래서 명령 실행기를 초기화한다는 것은 commandExecutor를 통해 Redis와 통신할 준비를 한다는 거라고 생각하면 된다. \ninternalLockLeaseTime는 자동 락 해제 시간 설정하는 것이다. 여기서 우리가 주목해야 할것은 🎁 락 워치독 (Watchdog) 기능이다. 쉽게 말하면, 자동 연장 기능이다. \n📌 락 워치독(Watchdog)은 왜 필요할까?\n보통 Redis에서 락을 설정할 때 TTL(만료 시간)을 지정하는데, 작업이 TTL 안에 끝나지 않으면 락이 자동으로 해제되는 문제가 있다. \n예를 들어 TTL이 5초인데 작업이 6초걸린다고 치자. 5초 후 락이 만료되고 자동으로 해제되면?\n다른 프로세스가 같은 락을 획득할 수 있다 → 데이터 일관성 깨짐 😨\n그래서 락을 획득한 스레드가 살아 있는 동안 TTL이 자동으로 연장된다는 기능이다. TTL을 직접 설정하지 않으면 기본 30초 동안 유지된다고 한다. \n마지막 줄인 pubSub은 🎁 Pub/Sub 기능을 활용하여 락 해제 이벤트를 감지하는 역할이다. \nRedis에서 분산 락을 사용할 때, 다른 클라이언트가 락을 대기하는 방식에는 2가지 방식이 있다. \n폴링(Polling) 방식: 주기적으로 Redis를 조회해서 락이 해제되었는지 확인함.\n이벤트 기반 방식: 락이 해제될 때 Redis가 직접 알림(Pub/Sub)을 보내서 대기 중인 클라이언트가 즉시 실행됨.\n만약 폴링 방식이라면? 락을 얻으려는 클라이언트가 주기적으로 Redis에 요청을 보내 락이 해제되었는지 확인해야한다. 듣기만 해도, 불필요한 Redis 부하가 발생하고 클라이언트가 지속적으로 Redis에 요청을 보내므로 트래픽이 많아질 거라는 단점이 느껴지지?\n그래서 Redisson에서는 락이 해제될 때 이벤트를 발생시켜 다른 클라이언트가 즉시 실행될 수 있도록 처리한다. 언제? RLock.unlock() 이 호출될때!\n2) 락 걸기(열쇠로 잠그기)\n이제 락을 어떻게 거는지 알아보자. 코드를 따라가다보면 Redission 클래스에서 tryLock()의 구현체를 확인할 수 있다. \n코드에 대한 내용을 간단하게 정리하자면, \n주어진 대기 시간(waitTime) 내에 락을 획득하려 시도하며, 락을 획득하면 지정된 임대 시간(leaseTime) 동안 락을 유지한다. 락을 즉시 획득하지 못한 경우, 다른 클라이언트의 락 해제 이벤트를 대기하기 위해 Pub/Sub 메커니즘을 활용하고, 대기 시간 내에 락을 획득하지 못하면 false를 반환하는 매커니즘을 확인할 수 있다. \n\n3) 락 해제(열쇠로 잠금 풀기)\n비동기적으로 락을 해제하는 모습을 볼 수 있다. 앞서 언급했듯이  Redisson에서는 락이 해제될 때 이벤트를 발생시켜 다른 클라이언트가 즉시 실행될 수 있도록 처리한다 -> 이부분을 찾기 위해 코드를 엄청 뒤졌는데 사실 해당 역할을 하는 코드를 찾을 수가 없어서 좀 아쉽다..ㅠ\n\n🤔 트랜잭션 분리\n코드를 살펴보면 락을 걸고 나서 트랜잭션을 분리해서 비즈니스 로직을 실행하는 역할을 하는 것을 볼 수 있다. \n\n음..쉽게 말하면 DistributedLock 어노테이션이 선언된 메서드를 별도의 트랜잭션으로 실행하게 만든 코드인 것이다. \n\nPropagation.REQUIRES_NEW 옵션을 지정해 부모 트랜잭션의 유무에 관계없이 별도의 트랜잭션으로 동작하게끔 설정하고 반드시 트랜잭션 커밋 이후 락이 해제되게끔 처리하고 있다. 왜 이렇게 분리를 했을까?\n해당 내용은 컬리의 블로그에 너무 자세히 써져있다. 내가 진행한 프로젝트도 재고를 위한 분산락인데 여기서도 재고를 예시로 들어서 너무나 적절하게 써져있으니 해당 링크 참고하길 바란다. 결론을 말하자면 데이터 정합성을 위한 방법으로 트랜잭션 커밋 이후 락이 해제되게끔 처리 해놓았다. \n📌 추가된 요구사항\n실전으로 넘어가기 전에, 추가할 요구사항이 있다. 앞선 요구사항은 하나의 key 즉, 하나의 row만 락을 거는 형식으로 구현되어 있다. 하지만 우리 회사 특성상 주문시 여러 상품을 동시에 상태 변경하기 때문에 한번에 여러 상품의 재고를 변경해야한다. 따라서 하나의 row가 아닌 여러 row에 락을 걸어야 한다. \n그렇다면 기존에 받는 키도 하나에서 여러개를 받게 되고 락도 동시에 여러개를 건다는 말이겠지? 정리하자면, 여러 개의 락을 동시에 걸고, 하나라도 실패하면 전체 실패하도록 하고 싶다는 것이다. 이때 난 RedissonMultiLock이라는 것을 사용했다. \n\n즉, 하나의 트랜잭션처럼 모든 락이 성공해야만 실행되도록 할때 사용된다. 그렇다는 말은 락을 해제할때도 한꺼번에 해제한다는 말과 동일하다. \n이제 추가된 요구까지 알아보았으니 본격적으로 테스트를 해볼까? 해당 내용은 다음편에 있다. \n참고) \nhttps://velog.io/@a01021039107/%EB%B6%84%EC%82%B0%EB%9D%BD%EC%9C%BC%EB%A1%9C-%ED%95%B4%EA%B2%B0%ED%95%98%EB%8A%94-%EB%8F%99%EC%8B%9C%EC%84%B1-%EB%AC%B8%EC%A0%9C%EC%9D%B4%EB%A1%A0%ED%8E%B8\nhttps://helloworld.kurly.com/blog/distributed-redisson-lock/\nhttps://techblog.woowahan.com/17416/\nhttps://velog.io/@jinony/Spring-Boot-Apache-JMeter%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EB%B6%80%ED%95%98-%ED%85%8C%EC%8A%A4%ED%8A%B8",
        "guid": "https://velog.io/@sweet_sumin/%EB%B6%84%EC%82%B0%EB%9D%BD-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0-%EA%B0%9C%EB%85%90",
        "isoDate": "2025-03-05T22:42:55.000Z"
      }
    ]
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "내 제품의 첫번째 고객은 나",
        "link": "https://www.thestartupbible.com/2025/03/eat-your-own-dogfood-and-finish-it.html",
        "pubDate": "Sun, 09 Mar 2025 21:38:00 +0000",
        "content:encodedSnippet": "이 블로그에서 ‘개밥 먹기’에 대해서는 지난 18년 동안 셀 수 없을 정도로 많은 글을 썼는데, 그만큼 제품을 만드는 창업가들에겐 본인이 만든 제품을 1부터 100까지 직접 다 사용해 보는 게 중요하다는 말이다. 내가 만든 제품을 출시하기 전에 내가 하나씩 사용해 보고, 혹시 이상한 건 없는지, 치명적인 버그는 없는지, 이런 점들을 남이 발견하기 전에 먼저 발견하고, 매일 우리 제품을 사용하면서 조금씩 개선하는 작업은 창업가들이 절대로 소홀히 하면 안 되는 필수 작업이다.\n사업을 하다 보면 챙겨야 할 것들이 한두 개가 아니다. 특히, 요새 같이 어려운 시기엔 회사에 피 같은 자금이 고갈되지 않게 대표이사는 합법적으로 할 수 있는 모든 일을 해서 직원들 월급이 밀리지 않게 해야 하고, 직원들의 사기가 떨어지지 않게 여러 가지 동기 부여 방법에 대해서도 고민해야 한다. 이 외에도 신경 써야 할 것이 너무 많아서 돌아버릴 지경이지만, 아무리 바빠도 대표를 비롯한 전 직원이 절대로 하루도 멈추면 안 되는 게 우리 제품 사용하기, 즉, 우리 개밥 먹기다. 하루도 빠지지 않고, 우리가 고객을 위해서 만들고 있는 제품을 매일 실행하고, 매일 사용해야 한다. 혹시나 기능이 잘 못 되지 않았을까, 숨은 버그가 있지 않을까, 서버가 다운되지 않았을까 등, 하루 종일 우리 제품을 사용하면서 모니터링 해야 한다.\n어떻게 보면 이 개밥 먹기는 너무나 당연한 스타트업의 첫 번째 법칙인데, 또 이만큼 잘 안 지켜지는 원칙도 없는 것 같다. 실은, 스트롱의 포트폴리오들도 이 비난을 피해 가기가 어렵다. 얼마나 본인들이 만드는 제품을 안 쓰면, 아주 심각한 에러가 발생한 것도 모르다가 나 같은 투자자가 그 제품을 사용하면서 한참 후에 발견한 오류를 제보해 주면, 그제야 “아, 그런가요?” 하면서 원인 파악을 시작해 본다. 새로운 기능이 출시됐다고 언론에 PR까지 때리면서, 막상 대표에게 그 기능에 대해서 자세히 물어보면 본인도 잘 사용 안 해봤다면서 PM과 나를 연결해 준 경우도 있다.\n소프트웨어 회사에서는 마이크로소프트가 ‘개밥 먹기’라는 용어를 처음 쓰기 시작했는데, 내가 마이크로소프트 다녔던 짧은 기간 동안 가장 인상 깊었던 건, 오피스 제품을 담당하는 글로벌 부사장이 오피스 제품의 기능을 하나씩 데모하면서 청중의 질문에 모두 답변했던 기억이다. 그만큼 이분은 본인이 몸담고 있던 회사에서 만든 제품을 구석구석 다 사용하면서 개밥을 열심히 먹었다는 의미다. 실은 한 조각도 남기지 않고 샅샅이 다 핥아먹었는데, 그때 정말 인상 깊었던 기억이 난다.\n우리 제품을 제대로 사용하지 않는 대표와 그 회사의 모든 직원은 깊이 반성해야 한다. 그 어떤 작가라도, 본인 책의 첫 번째 독자는 작가 그 자신이다. 작가가 쓴 책을 스스로 읽었는데 본인이 그 책이 맘에 안 든다면, 다른 독자는 말할 것도 없다. 이와 마찬가지로, 우리가 만드는 제품의 첫 번째 고객은 이 제품을 만드는 우리 회사의 임직원들이다. 우리가 만든 제품을 우리도 사용해 보지 않았는데, 이걸 어떻게 자랑스럽게 고객에게 보여주고 심지어 돈을 받고 판매할 수 있겠는가?\n우리가 만든 제품을 구석구석 꼼꼼히 사용해 보면, 분명히 만족스럽지 못한 것들이 있을 것이고, 수많은 버그를 발견할 것이다. 내가 만든 제품의 첫 번째 고객인 내가 수많은 버그를 발견한다면, 이 제품을 제대로 사용하지 못할 것이다. 그리고 우리가 만든 제품의 첫 번째 고객인 우리 회사 사람들도 우리 제품을 제대로 사용하지 못하면, 우리조차 우리 제품을 사랑할 수가 없다.\n이런 개 허접한 제품을 우린 어떻게 시장에 출시하고, 어떻게 주위 사람들에게 사라고 강요하겠는가? 절대로 이렇게 해선 안 되는데, 실은 너무나 많은 스타트업이 이런 말도 안 되는 짓을 매일 한다. 너무 많은 스타트업이 본인들도 제대로 사용해 보지 않은 거지 같은 제품을 출시한다. 그러면서 모두 다 대박 나는 유니콘을 꿈꾼다. 모두 다 꿈 깨시길.\n에어비앤비의 공동창업가 Brian Chesky 대표가 요샌 어떻게 사는지 잘 모르겠지만, 그는 2022년까지 집 없이, 에어비앤비에서 여기저기 숙소를 예약하면서 1년 내내 살았다. 이 세상 모든 집을 살 수 있을 정도의 재산이 그에겐 있지만, 사장은 회사가 만드는 제품을 눈감고도 외울 수 있어야 한다는 그의 철학 때문이다. 그가 항상 농담처럼 하던 말이 “저는 말 그대로 아직도 우리 사이트에서 살고 있습니다(I still live on the site).” 였는데, 에어비앤비 사장이 집이 없고 회사 웹사이트에서 살고 있다는 건 정말 시사하는 바가 크다고 생각한다. 이보다 훨씬 더 작은 대부분의 한국 스타트업의 대표와 임직원들은 눈 감고도 본인들의 제품이 어떻게 작동하는지, 어떤 UI와 UX를 거쳐서 어떤 결과가 나오는지, 줄줄 외워야 한다. \n내가 만든 개밥의 첫 번째 고객은 나 자신이다. 내가 만든 개밥을 내가 맛없어서 못 먹는다면, 그 누구도 이걸 맛있게 먹을 수 없을 것이다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/03/eat-your-own-dogfood-and-finish-it.html#respond",
        "content": "이 블로그에서 ‘개밥 먹기’에 대해서는 지난 18년 동안 셀 수 없을 정도로 많은 글을 썼는데, 그만큼 제품을 만드는 창업가들에겐 본인이 만든 제품을 1부터 100까지 직접 다 사용해 보는 게 중요하다는 말이다. 내가 만든 제품을 출시하기 전에 내가 하나씩 사용해 보고, 혹시 이상한 건 없는지, 치명적인 버그는 없는지, 이런 점들을 남이 발견하기 전에 먼저 발견하고, 매일(...)",
        "contentSnippet": "이 블로그에서 ‘개밥 먹기’에 대해서는 지난 18년 동안 셀 수 없을 정도로 많은 글을 썼는데, 그만큼 제품을 만드는 창업가들에겐 본인이 만든 제품을 1부터 100까지 직접 다 사용해 보는 게 중요하다는 말이다. 내가 만든 제품을 출시하기 전에 내가 하나씩 사용해 보고, 혹시 이상한 건 없는지, 치명적인 버그는 없는지, 이런 점들을 남이 발견하기 전에 먼저 발견하고, 매일(...)",
        "guid": "https://www.thestartupbible.com/?p=9388",
        "categories": [
          "Uncategorized",
          "general",
          "microsoft",
          "product"
        ],
        "isoDate": "2025-03-09T21:38:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "디지털 결제의 부상",
        "link": "https://www.thestartupbible.com/2025/03/rise-of-digital-payment.html",
        "pubDate": "Wed, 05 Mar 2025 21:38:00 +0000",
        "content:encodedSnippet": "10년마다 오는 큰 tech 물결을 잘 예측하고, 기회의 파도의 고점을 잘 타이밍 하면, 엄청나게 큰 사업을 만들 수 있다는 것을, 과거를 보면 잘 알 수 있다. 1960년대에 반도체의 미래를 보고 인텔이라는 회사가 만들어졌고, 이 반도체를 어떻게 활용할지 고민하면서 1970년대에 애플, 마이크로소프트, 오라클과 같은 회사들이 personal computer 시장을 만들면서 엄청난 기업으로 성장했다. 그 이후에 10년마다 아주 큰 기술의 물결이 출렁거렸는데, 1980년대 인터넷의 탄생, 1990년대 메인스트림 인터넷 서비스의 등장(구글, 아마존 등), 그리고 데스크탑에서 모바일로의 패러다임 변화 등이 이런 큰 물결이다. 중간 중간에 다양한 회사들이 등장했고, 이 중 성공한 곳들이 많지만, 정말 대박급으로 성공한 회사들은 모두 다 “앞으로 10년 동안 어떤 기술의 물결이 올까?”를 예측하고 여기에 베팅한 곳들이라고 난 생각한다.\n앞으로 10년은 어떤 테마가 거대한 유니콘들을 탄생시킬까? 이미 이 테마는 AI로 정해진 것 같다. 이렇게 많은 돈이 짧은 시간 동안 한 테마에 투입되는 걸 우리가 과거에 본 적이 없을 정도로 요새 AI 분야에 큰 투자와 관심이 집중되어 있다. 분명히 AI 분야에서 엄청난 혁신이 일어날 것이고, 이 혁신을 적극적으로 수용하는 회사들이 앞으로 미래를 이끌어 갈 것이다.\n여기에 나는 디지털 결제라는 테마를 하나 더 추가하고 싶다. 과거 10년 동안 세상의 모든 기술이 비약적으로 발전했다. 사람을 닮은 로봇이 등장하고, 사람 없이 스스로 운전하는 자율주행 자동차가 하늘을 날기도 하는데, 이런 변화 속에서 유독 돈이 움직이는 방법과 기술엔 큰 발전이 없었다. 아니, 디지털 결제는 오히려 여러 가지 면에서 후퇴하고 있는 것 같다. 특히, 돈이 국경을 넘어가는 과정과 이를 가능케 하는 기술을 보면, 우린 삶의 구석구석에 internet of everything을 적극적으로 도입하지만, 유독 internet of money는 구현되지 않는 것 같다.\n내가 합법적으로 열심히 번 돈을 사용하거나, 투자하거나, 또는 다른 사람에게 보낼 때, 우린 기술이 덜 발달했고, 인터넷이 없던 시절과 크게 다르지 않은 규제를 극복해야 하고, 오히려 그때보다 더 복잡한 인증 절차를 거쳐야 한다. 기술의 발전으로 우리 생활에서 많은 규제가 완화되고, 불필요한 비용을 발생시키는 중개인들이 줄었는데, 오히려 돈이 움직이는 프로세스를 보면 규제는 더 많아졌고, 아직도 불필요한 중개인들이 하는 것도 없이 수수료를 챙기고 있다. 돈세탁 방지와 고객확인제도는 디지털화가 아니라 오히려 더 아날로그화되어 가고 있다.\n이걸 내가 전혀 이해 못 하는 건 아니다. 돈은 정말 중요하고, 이 중요한 돈이 이동하면 – 특히, 국경을 넘으면 – 여러 가지를 신경 써야 한다. 통화는 나라마다 다르고, 그 통화를 지배하는 법과 규제는 가는 곳마다 다르므로, 범죄가 발생할 수 있는 구멍이 가장 많은 게 금융 쪽이다. 금융 범죄자들은 더 똑똑해지고, 악랄해지고, 대범해져서, 우리가 지금까지 경험하지 못했던 금융 범죄가 계속 등장하고, 이런 범죄를 막아야 하는 인공지능 기술이 오히려 더 많은 범죄를, 더 지능적으로 만드는데 악용되고 있기도 하다. 그러면, 정부 당국은 새로운 범죄를 차단하고 예방하기 위해서 더욱더 빡빡하고 엄격한 법과 규제를 만들 것이고, 이 과정을 거치면서 디지털 결제는 더욱더 아날로그화되면서 기술로부터 멀어질 것이다.\n나는 이 문제를 해결할 수 있는 건 블록체인 기술과 디지털 자산이라고 확신한다. 지난 10년 동안 internet of money와 digital network of money를 만들기 위해 이 분야의 다양한 이해관계자들이 노력을 많이 했는데, 솔직히 매번 규제에 부딪히거나, 인간의 탐욕에 스스로 굴복했다. 하지만, 10년 동안의 시행착오를 거치면서, 기술은 발전했고, 이 시장을 바라보는 시각도 많이 변했다는 걸 요샌 체감한다. 특히, 이번에 다 바뀐, 미국 SEC에서 디지털 자산을 담당하는 공무원들이 시장의 의견을 적극 수용해서 현실적으로 적용 가능한 법과 규제를 잘 만들면, 이게 한국을 포함한 전 세계의 표준이 되지 않을까,,,개인적으로 은근히 기대하고 있다.\n물론, 아직도 사기꾼들은 많고, 이 분야에서 일어나면 안 될 사기가 너무 많이 발생한다. 그래서, 내가 이런 이야기를 하면, 잘 모르는 분들은 코인 생각을 할 것인데 절대로 내가 밈코인이나 잡코인을 옹호하는 건 아니다. 나는 오히려 이젠 변동성의 리스크가 어느 정도 제거된 스테이블코인과 이 자산의 움직임과 투명성을 더 강화할 수 있는 기술을 연구하면서 좋은 디지털 결제 제품을 개발하는 창업가들이 앞으로 10년 동안 엄청난 사업을 만들 수 있을거라고 생각한다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/03/rise-of-digital-payment.html#comments",
        "content": "10년마다 오는 큰 tech 물결을 잘 예측하고, 기회의 파도의 고점을 잘 타이밍 하면, 엄청나게 큰 사업을 만들 수 있다는 것을, 과거를 보면 잘 알 수 있다. 1960년대에 반도체의 미래를 보고 인텔이라는 회사가 만들어졌고, 이 반도체를 어떻게 활용할지 고민하면서 1970년대에 애플, 마이크로소프트, 오라클과 같은 회사들이 personal computer 시장을 만들면서 엄청난 기업으로 성장했다. 그 이후에 10년마다 아주(...)",
        "contentSnippet": "10년마다 오는 큰 tech 물결을 잘 예측하고, 기회의 파도의 고점을 잘 타이밍 하면, 엄청나게 큰 사업을 만들 수 있다는 것을, 과거를 보면 잘 알 수 있다. 1960년대에 반도체의 미래를 보고 인텔이라는 회사가 만들어졌고, 이 반도체를 어떻게 활용할지 고민하면서 1970년대에 애플, 마이크로소프트, 오라클과 같은 회사들이 personal computer 시장을 만들면서 엄청난 기업으로 성장했다. 그 이후에 10년마다 아주(...)",
        "guid": "https://www.thestartupbible.com/?p=9385",
        "categories": [
          "비트코인",
          "bitcoin",
          "crypto curreny",
          "internet",
          "technology",
          "unicorn"
        ],
        "isoDate": "2025-03-05T21:38:00.000Z"
      }
    ]
  },
  {
    "name": "지금 써보러 갑니다",
    "category": "개인",
    "posts": []
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "대출 이자 줄이는 3가지 방법",
        "link": "https://blog.toss.im/article/loan-101-interest-rate",
        "pubDate": "Fri, 07 Mar 2025 01:03:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}이미 받은 대출은 계약한 대로 고스란히 이자를 내야 할까요? 매달 대출금 갚는 부담을 조금이라도 덜고 싶은 분들을 위해, 대출 이자 줄이는 3가지 방법을 알려드릴게요.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}1️⃣ 대출 금리 낮춰달라고 요구하기\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}신용점수가 오르는 등 여건이 좋아졌다면 은행에 금리를 낮춰달라고 요구할 수 있어요. 이 권리를 ‘금리인하요구권’이라고 부릅니다. 신용대출은 물론 자동차 할부 같은 할부금융 및 리스에도 신청할 수 있고, 담보대출도 일부 가능해요.\n은행에 직접 방문하거나 인터넷, 모바일뱅킹으로 신청합니다. 재직증명서, 원천징수영수증 등 바뀐 상황을 증명할 수 있는 서류를 제출하면 돼요 신청하면 10영업일 안에 결과를 안내받을 수 있어요.\n2️⃣ 중간에 대출 원금 갚기\n매달 내는 대출 이자는 원금, 이자율, 대출 기간에 따라 결정돼요. 당연히 원금을 갚는 만큼 이자도 줄어듭니다.\n특히 대출을 받은 지 3년이 지난 뒤부터는 중도상환수수료가 없어서 더 유리하죠. 은행 입장에서는 대출을 중간에 미리 갚으면 이자 수익이 기대보다 작아지므로, 통상 대출일로부터 3년까지는 중도상환수수료를 부과합니다.\n3️⃣ 금리 낮은 대출로 갈아타기\n금리가 낮은 다른 대출 상품으로 갈아타는 것을 ‘대환대출’이라고 부릅니다. 대출을 받은 이후 시장의 대출 금리가 낮아졌거나 신용점수가 좋아졌다면 더 효과가 커요. 이자 납입 방식, 상환 기간, 만기일 등 조건도 바꿀 수 있어요. 대상은 신용대출과 주택담보대출이에요.\n단, 기존 대출을 갚고 새로운 대출을 받는 개념이기 때문에 중도상환수수료가 발생할 수 있고, 인지세도 내야 해요. 인지세는 대출금에 따라 최대 35만 원이며, 은행과 반씩 나눠 내게 되고 대출금 5,000만 원까지는 면제됩니다.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}✱준법감시인 심의완료(2025-00109호)\n.css-1lvcgm8{padding:22px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;border-radius:20px;}\n.css-13ko30i{width:375px;}토스에서 신용대출 갈아타기\n토스에서 주택담보대출 갈아타기",
        "content": "금리인하요구권부터 대환대출까지 개념 정리",
        "contentSnippet": "금리인하요구권부터 대환대출까지 개념 정리",
        "guid": "https://blog.toss.im/article/loan-101-interest-rate",
        "isoDate": "2025-03-07T01:03:00.000Z"
      },
      {
        "title": "종합소득세 안 내면 어떻게 될까?",
        "link": "https://blog.toss.im/article/tossmoment-2",
        "pubDate": "Thu, 06 Mar 2025 08:16:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}5월이 되면 종합소득세 신고 시즌이 찾아옵니다. 사업을 하거나 프리랜서로 활동하는 사람, 금융상품으로 소득을 얻은 투자자라면 반드시 이때 신고해야 하는데요. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}이미 낸 세금이 신고를 통해 계산된 금액보다 많다면 환급을 받을 수 있지만, 신고를 하지 않거나 잘못하면 가산세 등 불이익이 생길 수 있어요.\n‘종합소득세 신고 어려운데... 이 정도 금액은 신고 안 해도 괜찮지 않을까?’라는 생각은 금물! 정교한 국세청 시스템 안에서 숨길 수 있는 소득은 거의 없을뿐더러, 대한민국 국민이라면 납세의 의무가 있기 때문에 몰라서 지나치는 것도 가산세 대상이 될 수 있어요.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}종합소득세, 가산세를 조심하세요\n종합소득세는 기한 내에 신고하고 납부하는 것이 중요합니다. 신고를 아예 하지 않거나, 신고는 했지만 세금을 납부하지 않았다면 가산세가 부과될 수 있어요. 또한, 사실과 다르게 신고해 환급을 많이 받았거나, 납부해야 할 세금을 줄였을 경우에도 가산세가 붙습니다. 미루다 보면 부담이 커질 수 있으니, 기한을 놓치지 않도록 주의하세요!\n➀ 무신고가산세: 신고를 안 한 경우\n종합소득세 신고를 하지 않으면 ‘무신고가산세’가 부과돼요. 일반적으로 납부세액의 20%가 추가되지만, 복식부기 의무자는 납부세액의 20% 또는 수입금액의 0.07% 중 더 큰 금액이 적용됩니다. 소득을 고의로 누락한 경우에는 ‘부정 무신고’로 간주되어 가산세는 40%로 올라가고, 복식부기 의무자는 납부세액의 40% 또는 수입금액의 0.14% 중 더 큰 금액이 부과되죠. 국제거래가 포함된 경우에는 가산세율이 최대 60%까지 올라갈 수 있어요.\n➁ 납부지연가산세*: 신고는 했지만 세금을 제때 내지 않은 경우\n신고를 했더라도 정해진 기한 내에 세금을 내지 않으면, 납부가 지연되는 만큼 하루하루 가산세가 쌓여요. 가산세는 미납기간 1일당 미납된 세액에서 0.022%가 추가되어 적용됩니다. 당연히 시간이 지날수록 부담은 커지겠죠.\n➂ 초과환급가산세*: 실제 받아야 할 금액보다 많이 환급받은 경우\n종합소득세 신고 과정에서 잘못 기재하여 실제보다 많은 금액을 환급 받았다면 그 차액에 대한 가산세가 부과됩니다. 단순착오로 초과 환급을 받았다고 하더라도 이에 대한 책임은 신고 당사자인 납세자에게 있어요. 초과환급가산세는 환급받은 날부터 경과일수에 따라 0.022%씩 부과되니, 실수로라도 더 많은 환급액을 받았다면 얼른 정정해야 해요.\n➃ 과소신고가산세: 신고를 잘못해서 세금을 덜 낸 경우\n신고한 세금이 실제보다 적을 경우 일반적으로 부족한 세액의 10%가 가산됩니다. 하지만 소득을 고의로 누락했거나 허위로 신고했다면 가산세율은 40%로 늘어나요. 복식부기 의무자는 납부세액의 40% 또는 수입금액의 0.14% 중 더 큰 금액이 적용되며, 국제거래가 있을 경우 60% 또는 수입금액의 0.14% 중 더 큰 금액으로 가산세가 적용됩니다.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*납부지연가산세의 경과일수는 납부기한 다음날부터 자진납부일 또는 납부고지일까지, 초과환급가산세의 경과일수는 환급 받은 다음날부터 자진납부일 또는 납부고지일까지를 말해요. 가산세에 대한 더 자세한 정보는 .css-114ityv{white-space:pre-wrap;cursor:pointer;-webkit-text-decoration:underline!important;text-decoration:underline!important;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}국세청 사이트에서 확인할 수 있어요.\n신고 기한을 놓쳤다면, 지금이라도 해야 해요\n종합소득세 신고는 매년 5월 1일부터 5월 31일까지 진행됩니다. 부득이한 이유로 5월을 놓쳤다면 ‘늦었다고 생각할 때가 가장 빠른 때다’라는 말을 기억하세요. 기한이 지났어도 ’기한 후 신고’를 통해 신고할 수 있거든요. 이 경우 가산세는 부과되지만, 신고 지연 기간에 따라 일정 비율의 세금은 감면받을 수 있고, 경과 기간이 짧을수록 감면율도 높아져요.\n\n국세청은 다 알고 있어요\n나 하나쯤 신고하지 않아도 국세청이 모르지 않을까 생각했다면 큰 오산입니다. 소득 발생 시점에서 세금이 신고되기 때문에 국세청이 모를 수 없거든요. 종합소득세 신고를 하지 않으면 몇 년이 지나더라도 과세자료 해명 안내문이 날아올 수 있습니다.\n반대로, 그동안 성실하게 소득을 신고해왔다면 오히려 환급받을 세금이 있을 가능성도 있어요! 종합소득세는 5년까지 ‘기한 후 신고’가 가능하니, 예전에 공제 받을 항목을 빠뜨린 건 아닐까하는 생각이 든다면 지금이라도 확인해보는 것이 좋아요.\n토스에서는 내가 놓쳤던 세금이 있는지 쉽고 빠르게 확인할 수 있어요. 영영 못 찾을 뻔한 환급액을 찾을 수도 있으니, 미루지 말고 지금 바로 아래 버튼을 눌러 체크해보세요!\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 윤동해 Graphic 조수희 이제현",
        "content": "안 냈다가는 세금 폭탄 맞을 수 있어요",
        "contentSnippet": "안 냈다가는 세금 폭탄 맞을 수 있어요",
        "guid": "https://blog.toss.im/article/tossmoment-2",
        "isoDate": "2025-03-06T08:16:00.000Z"
      },
      {
        "title": "토스, ‘미키 17’ 개봉 캠페인 성료…534만 회 참여",
        "link": "https://blog.toss.im/article/MICKEY17",
        "pubDate": "Thu, 06 Mar 2025 01:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}봉준호 감독 영화 ‘미키 17’ 광고 채널로 토스 광고 서비스 ‘토스애즈(Toss Ads)’ 선택\n토스 유저 534만 회 참여…공식 예고편 조회수 보다 높은 참여율 기록\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n\n토스(운영사 비바리퍼블리카, 대표 이승건)가 영화 ‘미키 17’과 함께한 개봉 캠페인을 성료했다고 6일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n‘미키 17’은 ‘기생충’을 통해 칸영화제 그랑프리와 아카데미상을 석권한 봉준호 감독의 차기작으로, 국내외 영화 팬들의 기대를 모아왔다. 토스 만보기 화면에서 진행한 ‘미키 17’ 관람권 응모에 534만 회 참여를 기록하며, 봉 감독 신작에 대한 높은 관심을 증명했다. 이는 같은 시기에 세계 최대 동영상 플랫폼에 공개된 2차 공식 예고편 조회수(346만, 3월 5일 기준)를 웃도는 수치다.\n이번 캠페인은 ‘미키 17’만을 위해 특별 제작된 아이콘 커스터마이징, OX 퀴즈 참여를 통한 영화 관람권 응모, 만보기 복권 긁기 등 크게 세 가지 방식으로 진행됐다. 특히, 아이콘 커스터마이징은 매스 타겟팅을 목표로 한 새로운 광고 형식으로, 광고주가 원하는 대로 아이콘을 설정하고 클릭 시 노출되는 화면까지 토스애즈가 광고주의 니즈에 맞게 최적화된 방식으로 제공하는 것이 특징이다. 이번에는 영화를 연상하는 팝콘 모양과 ‘미키 17’ 영화 티켓을 조합해 대표 아이콘으로 만들어 만보기 화면에 노출하였고, 클릭하면 OX 퀴즈를 참여하여 영화 관람권에 응모할 수 있도록 설계했다.\n‘미키 17’ 캠페인은 평소에 만보기를 사용하는 유저 중 약 60%가 커스터마이징 아이콘을 눌러 OX 퀴즈 화면에 진입했으며, 이 중 80% 이상이 퀴즈를 풀어 영화 관람권 응모에 참여했다. 특히 눈에 띄는 점은, 보통은 캠페인 첫날 참여율이 가장 높고 이후 점차 감소하는 경향이 있지만, 이번에는 이벤트 기간 7일 내내 꾸준히 40%의 높은 참여율을 유지했다.\n높은 참여율을 유지할 수 있었던 이유는 토스의 높은 MAU(1900만 명)뿐만 아니라, 만보기 주 이용자층이 미디어 콘텐츠 소비층과 유사하기 때문이다. 또한 만보기는 광범위하게 브랜드를 노출할 수 있어 유저 유입을 효과적으로 유도할 수 있다는 것이 차별점으로 작용했다.\n토스 내 광고 사업을 담당하는 토스애즈 관계자는 “토스 광고를 통해 ‘미키 17’의 홍보 뿐만 아니라 실제 모객까지 이루어져 의미 있는 캠페인이었다고 생각한다”며 “앞으로 더 다양한 산업의 광고주와 함께 고민하고 유저에게는 재미있는 경험을 선사할 수 있는 광고 상품 개발을 위해 지속적으로 노력할 것”이라고 밝혔다.",
        "content": "이제 영화 광고도 토스로",
        "contentSnippet": "이제 영화 광고도 토스로",
        "guid": "https://blog.toss.im/article/MICKEY17",
        "isoDate": "2025-03-06T01:00:00.000Z"
      },
      {
        "title": "토스페이 3월 할인 이벤트와 쿠폰 혜택 총정리",
        "link": "https://blog.toss.im/article/tosspay-2025-03",
        "pubDate": "Wed, 05 Mar 2025 01:11:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}완연한 봄이 시작되는 3월, 계절이 바뀌면서 필요한 것들이 많아지는 시기죠. 환절기 필수품인 .css-q3ktjb{white-space:pre-wrap;font-weight:bold;}뷰티 & 건강 케어, 가벼운 봄 패션, 새로운 시작을 위한 IT & 도서 쇼핑까지, 토스페이 할인 이벤트를 똑똑하게 이용하면 더 알뜰한 3월을 누릴 수 있어요.\n토스페이 3월 한정 혜택, 놓치지 않도록 필요한 것만 쏙쏙 정리해서 알려드립니다.\n.css-1c1qox8{font-size:30px;letter-spacing:0em;line-height:1.55;font-weight:bold;color:var(--adaptiveGrey900);margin:40px 0 4px;}\n.css-p4abj2{display:contents;line-height:1.55;}토스페이 3월 주요 할인 이벤트 모아보기\n.css-2sk6rv{font-size:19px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);white-space:pre-wrap;margin:24px 0;padding-left:20px;position:relative;}.css-2sk6rv::before{content:'';display:block;position:absolute;top:4px;left:0;width:2px;height:calc(100% - 4px * 2);padding:4px 0;background-color:var(--adaptiveGrey800);}\n.css-mlvj3o{white-space:pre-wrap;color:#4593fc;font-weight:bold;}토스페이로 결제하고 자동 할인받기\n아래 혜택들은 결제 시 토스페이를 선택하면 자동으로 할인이 적용돼요..css-7mseny>*{margin-left:0;margin-right:0;}.css-7mseny>:last-child{margin-bottom:0;}blockquote>.css-7mseny:first-child>:first-child{margin-top:0;}\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n🛫 해외직구 | 특가로 직구할 기회\n원래 저렴한 알리에서 더 저렴하게! 생활용품을 비롯해 모든 카테고리의 상품을 알뜰하게 직구할 기회 놓치지 마세요.\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n✅ 알리 익스프레스\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n$100이상 구매 시 $12 할인 \n이벤트 기간: 25.03.17.~25.03.26.\n\n.css-1lvcgm8{padding:22px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;border-radius:20px;}\n.css-13ko30i{width:375px;}알리익스프레스 바로 가기\n👗 패션 | 봄이 오면 옷장도 새롭게\n봄에는 가볍고 산뜻한 패션으로 변신해보는 건 어떨까요? ‘봄 직잭팟’ 프로모션 시즌에 토스페이로 결제하고 가성비 좋은 패션 쇼핑을 즐겨보세요.\n\n✅ 지그재그\n\n12만원 이상 구매 시 5천원 할인 \n이벤트 기간: 25.03.24.~25.04.07.\n\n\n지그재그 바로 가기\n💻 전자기기 | 새학기 & 업무 효율 UP!\n노트북부터 태블릿, 모니터, 다양한 부품까지 각종 컴퓨터 관련 제품을 할인된 가격으로 구매할 수 있어요.\n\n✅ 컴퓨존\n\n20만원 이상 결제 시 5% 할인(최대 5만원)\n기간: 25.03.11.~25.03.31.\n\n\n컴퓨존 바로 가기\n🏠 가전 | 효율적인 생활 가전으로 집 꾸미기\n필수 디지털 가전제품을 더 합리적인 가격으로 마련하세요.\n\n✅ 롯데온\n\n제품별 최대 10% 할인\n기간: 25.03.01.~25.03.31.\n\n\n롯데온 바로 가기\n📚 도서 | 봄날의 감성을 채울 책 쇼핑\n지식과 감성을 충전할 시간, 날씨가 풀리면 책 한 권 들고 여유로운 봄날을 즐겨야 해요. 나를 위한 생산적인 소비를 합리적인 비용에 할 수 있도록 도서 프로모션을 모아왔어요!\n\n✅ 알라딘\n\n3만원 이상 결제 시 2천원 할인\n기간: 25.02.28.~25.03.19.\n\n\n알라딘 바로 가기\n\n✅ 교보문고\n\n4만원 이상 결제 시 2천원 할인\n기간: 25.03.01.~25.03.15.\n\n\n교보문고 바로 가기\n\n✅ 예스24\n\n5만원 이상 결제 시 3천원 할인\n기간: 25.03.15.~25.03.16.\n\n\n예스24 바로 가기\n\n할인 쿠폰 발급받기\n아래 혜택들은 토스 앱에서 쿠폰을 발급받고, 해당 브랜드 앱에서 토스페이로 결제하면 자동으로 적용돼요.\n💄 뷰티&헬스케어 | 봄철 피부 관리, 건강 지키기 \n환절기로 건조한 날씨, 피부 & 건강 관리가 필요할 때, 봄맞이 수분을 채워줄 뷰티, 스킨케어 아이템과 면역력 강화를 위한 건강기능식품을 특별 혜택으로 만나보세요.\n\n✅ CNP - 스킨케어 제품 추천\n\n신규 고객 20%, 모든 고객 15% 할인 쿠폰\n기간: 25.03.01.~25.03.31.\n\n\n✅ 종근당건강몰 - 락토핏 추천\n.css-hokoge{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;counter-reset:numberedList;}.css-hokoge ul,.css-hokoge ol{margin:16px 0 0;}.css-hokoge>li{counter-increment:numberedList;margin-bottom:16px;padding-left:24px;}.css-hokoge>li:last-of-type{margin-bottom:0;}.css-hokoge>li>span{position:relative;}.css-hokoge>li>span>:first-child::before{content:counter(numberedList) '.';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n최대 22% 할인 쿠폰\n\n기간: 25.03.25.~25.03.27.(3일 동안은 22% 할인)\n\n\n12% 할인 쿠폰\n\n기간: 25.03.01.~25.03.31.\n\n\n\n👗 패션 | 봄이 오면 옷장도 새롭게\n운동복부터 편안한 데일리룩까지 편안함에 스타일도 잡는 안다르, 3가지 카테고리별로 쿠폰을 각각 다운로드받아 적용할 수 있어요. 카테고리별 혜택이 다르므로 최대 혜택을 받을 수 있는 쿠폰을 확인해보세요! \n\n기간: 25.03.01.~25.03.31.\n\n✅ 안다르 여성\n\n신규 고객 12% / 모든 고객 7% 할인 쿠폰\n\n✅ 안다르 언더웨어\n\n10% 할인 쿠폰\n\n✅ 안다르 맨즈웨어\n\n12% 할인 쿠폰\n\n\n🏬 백화점 | 프리미엄 쇼핑 \n비싸게 느껴지는 백화점 쇼핑도 더 합리적으로! 롯데백화점몰에서 패션, 뷰티, 리빙까지 모든 카테고리에 할인 쿠폰을 적용해 보세요.\n\n✅ 롯데백화점몰\n\n3.5% 할인 쿠폰 + a \n10일부터 16일 롯백위크 기간에는 쿠폰과 롯데백화점 자체 혜택을 중복해서 받을 수 있어요!\n기간: 25.03.01.~25.03.31.\n\n\n토스 앱에서 쿠폰 확인하기\n3월 토스 소식 \n🏪 편의점 최대 할인 이벤트 \n\n✅ GS25 \n\n3,000원 이상 토스페이 결제 시 1,500원 할인\n햄버거/샌드위치 토스페이 결제 시 50% 토스포인트 적립\n\n\n🔖 우리 동네 복권 받기\n\n✅ 최대 100만 토스포인트 복권 우리 동네에서 찾아보세요!\n\n지도에 표시된 동네 가게 방문하면 꽝없는 토스포인트 당첨!\n가게에 있는 행운 쿼카를 눌러 방문 인증만 하면 복권을 받을 수 있어요.\n최대 당첨금은 100만 토스포인트 💫\n기간: 25.03.06. ~ 25.03.23.\n\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n필요했는데 미뤄둔 것이 있다면 이번 기회에 나를 위한 작은 선물을 해보는 것은 어떨까요? .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}3월에만 누릴 수 있는 특별한 할인 혜택을 알차게 활용해 보세요. 다음 달에도 더 합리적인 선택을 할 수 있도록 가장 필요한 혜택만 골라서 돌아올게요!",
        "content": "지그재그, GS25, 알리익스프레스 할인·적립 쿠폰까지, 토스페이 2025년 3월 혜택 확인하기",
        "contentSnippet": "지그재그, GS25, 알리익스프레스 할인·적립 쿠폰까지, 토스페이 2025년 3월 혜택 확인하기",
        "guid": "https://blog.toss.im/article/tosspay-2025-03",
        "isoDate": "2025-03-05T01:11:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]