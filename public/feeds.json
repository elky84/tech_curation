[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Sinem Akinci",
        "title": "Fix C++ warnings and errors with Copilot: Introducing AI-Assisted Code Fixes in Visual Studio",
        "link": "https://devblogs.microsoft.com/cppblog/fix-c-warnings-and-errors-with-copilot-introducing-ai-assisted-code-fixes-in-visual-studio/",
        "pubDate": "Wed, 11 Sep 2024 10:00:41 +0000",
        "content:encodedSnippet": "Stuck on an unfamiliar build error? Want to resolve your code errors quickly? Copilot is now integrated into Visual Studio error workflows to assist you with understanding and resolving C++ errors and warnings.\nTo access this new feature, you will need an active Copilot subscription and the latest 17.11 GA version of Visual Studio.\nHow does it work?\nThere are two different entry points to accommodate where you are at in your error workflow:\nThe Quick Action lightbulb proposes a fix of a given error inline in your code window.\nThe Error List Integration invokes Copilot in the chat window to explain the error code and showcase a proposed fix.\nSemantically relevant code snippets from your active file and related files are automatically included as context to increase the relevant of the proposed fix.\nFix with Copilot in the Quick Action Lightbulb\nCopilot is integrated into the Quick Action lightbulb in your code editor, so that you can invoke Copilot and view proposed fixes inline with a few simple clicks. Just hover over the diagnostic squiggle or double-click on a diagnostic message in your Error List to access Fix with Copilot via Quick Action Lightbulb.\nFrom here, Copilot will invoke the /fix command with semantically relevant C++ code snippets to propose a fix for your code.\n\nYou can edit the proposed code, accept any changes inline, or ask any follow-up questions in the inline Copilot Chat pane, without having to navigate away from the code editor.\nExplain and Fix with Copilot in the Error List\nIf you want to learn more about the error itself, Copilot is integrated in the Error List to invoke by selecting the Copilot icon to the left of a code warning or error to provide an explanation alongside a proposed fix through the Chat pane. This can be beneficial for more complex fixes, as it can provide multiple code snippets across several files and a deeper understanding of the error itself.\n\nGiven the same relevant C++ context, it will help you more deeply understand the error code and propose a fix for the code. You also can ask follow-up questions or add any additional details via the Chat pane to probe further.\n\nWhat do you think?\nPlease let us know anything you’d like to see added to this feature or your experiences with this fixing experience. We have a survey available for any feedback here: https://www.surveymonkey.com/r/RKG68YN. You’ll need an active GitHub Copilot subscription. Download the latest version of Visual Studio and give it a try.\nIn addition, our team is working hard on improving C++ integrations with Copilot Chat, so please let us know any other enhancements you’d like to see to your C++ workflows and content you’d like to see.\nWe welcome all types of feedback on your experience with the product. Comment below, or you can find us via email at visualcpp@microsoft.com or via X at @VisualC.\nThe post Fix C++ warnings and errors with Copilot: Introducing AI-Assisted Code Fixes in Visual Studio appeared first on C++ Team Blog.",
        "dc:creator": "Sinem Akinci",
        "comments": "https://devblogs.microsoft.com/cppblog/fix-c-warnings-and-errors-with-copilot-introducing-ai-assisted-code-fixes-in-visual-studio/#comments",
        "content": "<p>Stuck on an unfamiliar build error? Want to resolve your code errors quickly? Copilot is now integrated into Visual Studio error workflows to assist you with understanding and resolving C++ errors and warnings. To access this new feature, you will need an active Copilot subscription and the latest 17.11 GA version of Visual Studio. How [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/fix-c-warnings-and-errors-with-copilot-introducing-ai-assisted-code-fixes-in-visual-studio/\">Fix C++ warnings and errors with Copilot: Introducing AI-Assisted Code Fixes in Visual Studio</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "Stuck on an unfamiliar build error? Want to resolve your code errors quickly? Copilot is now integrated into Visual Studio error workflows to assist you with understanding and resolving C++ errors and warnings. To access this new feature, you will need an active Copilot subscription and the latest 17.11 GA version of Visual Studio. How […]\nThe post Fix C++ warnings and errors with Copilot: Introducing AI-Assisted Code Fixes in Visual Studio appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34627",
        "categories": [
          "C++",
          "Copilot"
        ],
        "isoDate": "2024-09-11T10:00:41.000Z"
      },
      {
        "creator": "Augustin Popa",
        "title": "Askia, an Ipsos company, achieved faster, reproducible builds with vcpkg",
        "link": "https://devblogs.microsoft.com/cppblog/askia-an-ipsos-company-achieved-faster-reproducible-builds-with-vcpkg/",
        "pubDate": "Mon, 09 Sep 2024 19:09:56 +0000",
        "content:encodedSnippet": "vcpkg is a free and open-source C/C++ package manager maintained by Microsoft and the C++ community that runs on Windows, macOS, and Linux. Over the years we have heard from companies using vcpkg to manage dependencies at enterprise-scale. In this interview, I spoke to Dimitri Rochette, a lead developer at Askia, an Ipsos company, about vcpkg’s impact on their team.\n\nAfter switching to vcpkg and CMake, Askia was able to reduce build times for their dependencies by using the vcpkg binary caching feature and reduce their code size by about 300,000 lines by eliminating project files, scripts, and copied dependencies. Switching to vcpkg also allowed them to ensure consistent and reproducible builds across multiple platforms, access a vast array of libraries, streamline their onboarding process as their development team grew, and standardize the use of microservices in a multi-repository environment.\nQ: Can you tell us about your company and team?\nAskia, a software company with two decades of experience, specializes in the development of tools for survey creation, response collection, and data analysis. In 2020, Ipsos, a global leader in market research, acquired Askia with the aim of collaboratively developing a platform that aligns with their ambitious goals. At the time of acquisition, Askia was a team of 30. However, with substantial investment from Ipsos, the team expanded rapidly to 90 members within just two years.\nQ: Can you tell us about your C++ development environment?\nAll our teams utilize the latest Visual Studio 2022. For C++ development, we employ two compilers: MSVC and GCC13. Our projects are all built with CMake and vcpkg. We’ve also implemented additional setup scripts in PowerShell 7 (PWSH) to ensure portability between Windows and Linux. These scripts handle the setup of developer and CI machines, GitHub tokens, NuGet caching, the initial cloning of vcpkg, and database creation for clusters or unit tests. We’re quite satisfied with CMake, despite the initial setup being challenging. The integration with Visual Studio continues to improve, and maintaining a single project for two platforms has been a significant advantage.\nWithin our project scope, the majority of our code is written in C++. We initially started with C++17 and have now transitioned to C++23. We strive to stay updated with the latest stable compilers for MSVC and GCC. Occasionally, we face challenges waiting for implementations to be available on both compilers. C++ code is on our critical path, and we aim to minimize latency as much as possible. We also have numerous services in C#.Net8, which is the most commonly used language company wise. We have a significant amount of T-SQL code as we heavily rely on SQL Server for our C++ services. For the frontend, we took a chance on Svelte before its 1.0 release, and we are extremely satisfied with the outcome today.\nOur development environment is based on Windows, while our production target is Ubuntu 22.04, housed within Docker containers. Despite this, all our code is compatible with Windows and is compiled using MSVC. This allows us to exchange services between both platforms.\nOur Docker container is structured in four layers, all built on Ubuntu 22.04:\nBase Image: This includes additional apt repositories, security measures, and an ODBC driver.\n\nDev: This layer is equipped with all the necessary tools for developers. It’s used as a workspace by developers and by the continuous integration (CI) system to execute unit tests.\n\nStatic Analysis: This layer is used by the CI system for static analysis and includes SonarCloud and its prerequisites.\nProduction: This is the image that runs the release version. It’s used by the CI system to install binaries of the Dev build on a clean image and is then uploaded for Kubernetes consumption.\nWe utilize the same images for both developers and CI, leveraging vcpkg binary caching (with GitHub serving as a NuGet server). This means that each build by a developer or CI either downloads or builds and uploads the result to the shared cache. We have 274 packages, with the main ones being downloaded 300 times per month. The ability to save even a single compilation of packages like OpenSSL or Python is greatly appreciated by the team and reduces our CI build times and costs.\nOur current codebase is relatively compact, comprising approximately 40,000 lines of C++ code, which are divided across various repositories for services and components. Our legacy codebase is significantly larger, containing more than 2 million lines of C++ code. The introduction of CMake and vcpkg to our main repository resulted in a reduction of about 10% (or 300,000 lines), which included project files, scripts, and copied dependencies.\nWe utilize GitHub as our continuous integration system. Given that we have scripts to configure developer tools and machines, as well as standard Docker images, we leverage these in our CI environment. The same image used by developers for their work is also used in GitHub CI. Additionally, on GitHub, we employ the other layers of our Docker container for building our release version and executing unit tests.\nQ: What kinds of C++ libraries do you consume?\nFor first-party private/internal libraries, we have established a vcpkg registry with our shared library. Those packages are allowed to use any other library provided by vcpkg. This includes a wrapper for asynchronous messaging (librabbitmq), a wrapper for logging (spdlog), a configuration file with an override system (nlohmann-json), our HTTP server (boost-beast), plugins for our HTTP server (boost asio, curl, fmt), a JWT token checker (jwt-cpp, cppcodec, OpenSSL), and Python scripts (boost-python, python3). The most crucial package for us is our CMake scripts, which define all output folders, all parameters per platform (compiler, C++ version, debug/release, Windows SDK, UNICODE, _UNICODE, NOMINMAX, etc.), our CMake function for tagging versions with git hash and version files, branch name, scripts to create zip or NuGet as output of build, and scripts to copy dependency DLLs.\nAs for open-source dependencies, we directly utilize boost, fmt, gtest, magic-enum, nanodbc, nlohmann-json, spdlog, pybind11, librabbitmq, openssl, and libcurl.\nWe also have a significant amount of MFC and some third-party controls in our legacy codebase. In our new codebase, LaunchDarkly is used by C# projects, so it may be used in C++ in the future.\nQ: How were you managing C++ dependencies before vcpkg?\nIn our legacy stack, which is based on the Windows GUI in MFC, we had a variety of methods for managing dependencies. These included:\nIncluding them as source\nIncluding them as source with modifications\nUsing public NuGet packages with MSBuild projects\nIncluding them as pre-compiled binaries\nThe system was functional, but it was challenging to keep track of what was used and in which version. The ABI break before 2015 served as a useful reminder to consider upgrading our NuGet packages. Our initial inventory of repository candidates for the CMake/vcpkg migration took some time, but all the standard ones were relatively easy to identify.\nQ: When did your team move to vcpkg and why did you ultimately choose it?\nI had previously used vcpkg at another company to develop a Windows/Linux Qt tool. The use of CMake/vcpkg was a lifesaver, eliminating the need to manage both Visual Studio and Xcode projects. When I joined the company in 2019, I found the build process to be quite cumbersome. We were heavily reliant on Jenkins, with numerous scripts and file copies pre/post-build. Many projects required relative builds of other projects. My first proof of concept was converting some projects to CMake, which involved converting NuGet dependencies to vcpkg. The integration of cmakeconfig.json into Visual Studio 2019 facilitated user acceptance. We maintained both sln + CMake in the repository for about a year in case we encountered any issues.\nThe acquisition by Ipsos brought significant changes. The need for scalability necessitated major modifications. We had to develop new microservices, and as the team became more familiar with the advantages of CMake/vcpkg, we made vcpkg mandatory for all new projects. The primary goal at this stage was to expedite the onboarding of new developers. We aimed to minimize the steps required to launch and debug a unit test as much as possible. We have iteratively improved this process, and today, the steps take less than half a day.\nThe steps include:\nInstalling Visual Studio with C++\nInstalling ODBCDriver\nCloning vcpkg\nCreating a GitHub token for binary caching\nWith these steps, all our C++ projects could be cloned, compiled, and debugged in unit tests. If you install Docker and create the reference image, you can target both Windows and Linux.\nSo, yes, vcpkg has been instrumental in our onboarding process. We have tripled the team size in a few years. Standardizing the tools helps developers working on one repository to easily transition to another.\nQ: What is your overall impression of vcpkg?\nvcpkg has been a game-changer in my 25 years of working with C++. It has revolutionized the way we manage dependencies by ensuring consistent and reproducible builds across multiple platforms. With a vast array of libraries at our disposal, we have the flexibility to create or extend libraries as needed. The caching feature significantly speeds up our build process. Moreover, vcpkg has streamlined our onboarding process and standardized the use of microservices in a multi-repository environment.\nLearn More About vcpkg\nIf you want to learn more about vcpkg, check out our website at vcpkg.io and read the vcpkg overview in our documentation.\nIf you have a story you would like to share with us about your experiences with vcpkg, feel free to contact us at vcpkg@microsoft.com. You can submit bug reports in our GitHub issue tracker or make feature requests in our discussion forum.\nThe post Askia, an Ipsos company, achieved faster, reproducible builds with vcpkg appeared first on C++ Team Blog.",
        "dc:creator": "Augustin Popa",
        "comments": "https://devblogs.microsoft.com/cppblog/askia-an-ipsos-company-achieved-faster-reproducible-builds-with-vcpkg/#respond",
        "content": "<p>vcpkg is a free and open-source C/C++ package manager maintained by Microsoft and the C++ community that runs on Windows, macOS, and Linux. Over the years we have heard from companies using vcpkg to manage dependencies at enterprise-scale. In this interview, I spoke to Dimitri Rochette, a lead developer at Askia, an Ipsos company, about [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/askia-an-ipsos-company-achieved-faster-reproducible-builds-with-vcpkg/\">Askia, an Ipsos company, achieved faster, reproducible builds with vcpkg</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "vcpkg is a free and open-source C/C++ package manager maintained by Microsoft and the C++ community that runs on Windows, macOS, and Linux. Over the years we have heard from companies using vcpkg to manage dependencies at enterprise-scale. In this interview, I spoke to Dimitri Rochette, a lead developer at Askia, an Ipsos company, about […]\nThe post Askia, an Ipsos company, achieved faster, reproducible builds with vcpkg appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34577",
        "categories": [
          "C++",
          "Vcpkg",
          "vcpkg"
        ],
        "isoDate": "2024-09-09T19:09:56.000Z"
      },
      {
        "creator": "Augustin Popa",
        "title": "What’s New in vcpkg (August 2024)",
        "link": "https://devblogs.microsoft.com/cppblog/whats-new-in-vcpkg-august-2024/",
        "pubDate": "Thu, 05 Sep 2024 22:06:11 +0000",
        "content:encodedSnippet": "This blog post summarizes changes to the vcpkg package manager as part of the 2024.08.23 release, 2024-08-01 tool release, as well as changes to vcpkg documentation throughout August. This month’s release includes several notable changes as well as bug fixes and documentation improvements. The most notable changes were:\nThe shell function used to run vcpkg artifacts commands has been renamed to vcpkg-shell. Artifacts users will need to update their commands to use this new identifier.\nA triplet variable called VCPKG_POST_PORTFILE_INCLUDES was added to allow users to specify a list of CMake files to include after the execution of portfile.cmake.\nDocumentation articles were added for using vcpkg to target Windows with MSVC as well as Universal Windows Platform (UWP).\nSome stats for this period:\nThere are now 2,475 total ports available in the vcpkg public registry. A port is a versioned recipe for building a package from source, such as a C or C++ library.\n20 new ports were added to the open-source registry.\n267 updates were made to existing ports. As always, we validate each change to a port by building all other ports that depend on or are depended by the library that is being updated for our 13 main triplets.\n30 people contributed to this release.\nThe main vcpkg repo has over 6,300 forks and 22,700 stars on GitHub.\nLastly, it’s CppCon season, and I am giving a talk on 10 Problems Large Companies Have with Managing C++ Dependencies and How to Solve Them on Tuesday, September 17, 2024, from 16:45-17:45 MDT. If you are coming to the conference, check it out! If you are unable to make it, the talk should go up on YouTube sometime after the event.\nvcpkg changelog (2024.08.23 release)\nThe following notable changes were made in this release:\nThe shell function used to run vcpkg artifacts commands has been renamed from vcpkg to vcpkg-shell. This addresses some issues when running vcpkg from a Visual Studio Developer Command Prompt. If you are an artifacts user, you will need to update your commands. For example: vcpkg activate should be changed to vcpkg-shell activate. Note: most vcpkg commands do not use the shell script, and you should still be able to run them as before (PR: Microsoft/vcpkg-tool#1442).\nAdded VCPKG_POST_PORTFILE_INCLUDES triplet variable. Allows users to optionally specify a list of CMake files to include after the execution of portfile.cmake (PR: Microsoft/vcpkg-tool#1417, thanks @Neumann-A!).\nBug fixes:\n\nFixed a crash if \"platform\": \"mips64\" is used (PR: Microsoft/vcpkg-tool#1454, thanks @autoantwort!).\nAdded error checking for http binary caching when some incorrect URL formats are specified (PR: Microsoft/vcpkg-tool#1459, thanks @autoantwort!).\nFixed several typos in console output (PR: Microsoft/vcpkg-tool#1461).\nFixed JSON configuration schemas for vcpkg manifest files not correctly supporting ports with wildcards (PR: Microsoft/vcpkg-tool#1429).\nFixed filesystem registry schema not including a \"baseline\" property (PR: Microsoft/vcpkg-tool#1463).\nDocumentation changes\nUpdated the vcpkg Maintainer Guide to elaborate on port naming guidelines and add a guideline about downloading patch files (PR: Microsoft/vcpkg-docs#371).\nAdded vcpkg_msbuild_install maintainer function to Table of Contents (PR: Microsoft/vcpkg-docs#378, thanks @HNegus!).\nAdded articles for using vcpkg to target Windows with MSVC and Universal Windows Platform (PR: Microsoft/vcpkg-docs#77, thanks @walbourn!).\nDocumented triplet naming requirements and usage of VCPKG_CXX_FLAGS, along with some additional typo fixes and clarifications (PR: Microsoft/vcpkg-docs#384, thanks @Thomas1664!).\nFormatting improvements to several deprecation warnings in documentation (PR: Microsoft/vcpkg-docs#380, thanks @Thomas1664!).\nOther typo, formatting, and bug fixes (thanks @Thomas1664, @HNegus!).\nIf you have any suggestions for our documentation, please submit an issue in our GitHub repo or see the box at the bottom of a particular article.\n\nTotal ports available for tested triplets\ntriplet\nports available\n\n\nx64-windows\n2,337\n\n\nx86-windows\n2,239\n\n\nx64-windows-static\n2,214\n\n\nx64-windows-static-md\n2,249\n\n\narm64-windows\n1,929\n\n\nx64-uwp\n1,293\n\n\narm64-uwp\n1,263\n\n\nx64-linux\n2,306\n\n\nx64-osx\n2,185\n\n\narm64-osx\n2,105\n\n\narm-neon-android\n1,608\n\n\nx64-android\n1,683\n\n\narm64-android\n1,657\n\n\n\nWhile vcpkg supports a much larger variety of target platforms and architectures (as community triplets), the list above is validated exhaustively to ensure updated ports don’t break other ports in the catalog.\nThank you to our contributors\nvcpkg couldn’t be where it is today without contributions from our open-source community. Thank you for your continued support! The following people contributed to the vcpkg, vcpkg-tool, or vcpkg-docs repos in this release (listed alphabetically by GitHub username):\nADKaster\nagl-alexglopez\nautoantwort\nbenjamin-hodgson\nBertalanD\ncrhowell3\nderekcyruschow-catapult\nGwaldron\nhermet\nHNegus\nLandryNorris\nmatthieugleg\nmedns\nmutptr\nNeumann-A\noboukli\nplekakis\nRobbiE-Envista\nromanpauk\nrudchenkos\nsgoth\ntchaikov\ntimkpaine\nThomas1664\nTomieAi\ntrflynn89\nvadi2\nwalbourn\nwestlicht\nxb284524239\nz4kn4fein\nLearn more\nYou can find the full 2024.08.23 release notes on GitHub for the main repo. Recent updates to the vcpkg tool can be viewed on the vcpkg-tool Releases page. To contribute to vcpkg documentation, visit the vcpkg-docs repo. If you’re new to vcpkg or curious about how a package manager can make your life easier as a C/C++ developer, check out the vcpkg website – vcpkg.io.\nIf you would like to contribute to vcpkg and its library catalog, or want to give us feedback on anything, check out our GitHub repo. Please report bugs or request updates to ports in our issue tracker or join more general discussion in our discussion forum.\n \nThe post What’s New in vcpkg (August 2024) appeared first on C++ Team Blog.",
        "dc:creator": "Augustin Popa",
        "comments": "https://devblogs.microsoft.com/cppblog/whats-new-in-vcpkg-august-2024/#respond",
        "content": "<p>This blog post summarizes changes to the vcpkg package manager as part of the 2024.08.23 release, 2024-08-01 tool release, as well as changes to vcpkg documentation throughout August. This month’s release includes several notable changes as well as bug fixes and documentation improvements. The most notable changes were: The shell function used to run vcpkg [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/whats-new-in-vcpkg-august-2024/\">What’s New in vcpkg (August 2024)</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "This blog post summarizes changes to the vcpkg package manager as part of the 2024.08.23 release, 2024-08-01 tool release, as well as changes to vcpkg documentation throughout August. This month’s release includes several notable changes as well as bug fixes and documentation improvements. The most notable changes were: The shell function used to run vcpkg […]\nThe post What’s New in vcpkg (August 2024) appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34589",
        "categories": [
          "C++",
          "Vcpkg",
          "vcpkg"
        ],
        "isoDate": "2024-09-05T22:06:11.000Z"
      }
    ]
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Simulator-based reinforcement learning for data center cooling optimization",
        "link": "https://engineering.fb.com/2024/09/10/data-center-engineering/simulator-based-reinforcement-learning-for-data-center-cooling-optimization/",
        "pubDate": "Tue, 10 Sep 2024 16:00:31 +0000",
        "content:encodedSnippet": "We’re sharing more about the role that reinforcement learning plays in helping us optimize our data centers’ environmental controls.\nOur reinforcement learning-based approach has helped us reduce energy consumption and water usage across various weather conditions in our data centers.  \nMeta is revamping its new data center design to optimize for artificial intelligence and the same methodology will be applicable for future data center optimizations as well.\nEfficiency is one of the key components of Meta’s approach to designing, building, and operating sustainable data centers. Besides the IT load, cooling is the primary consumer of energy and water in the data center environment. Improving the cooling efficiency helps reduce our energy use, water use, and greenhouse gas (GHG) emissions and also helps address one of the greatest challenges of all – climate change.\nMost of Meta’s existing data centers use outdoor air and evaporative cooling systems to maintain environmental conditions within the envelope of temperature between 65°F and 85°F (18°C and 30°C) and relative humidity between 13 and 80%. As water and energy are consumed in the conditioning of this air, optimizing the amount of supply airflow that has to be conditioned is a high priority in terms of improving operational efficiency. \nSince 2021, we have been leveraging AI to optimize the amount of airflow supply into data centers for cooling purposes. Using simulator-based reinforcement learning, we have, on average, reduced the supply fan energy consumption at one of the pilot regions by 20% and water usage by 4% across various weather conditions.\nPreviously, we shared how a physics-based thermal simulator helps us optimize our data centers’ environmental controls. Now, we will shed more light on the role of reinforcement learning in the solution. As Meta is revamping its new data center design to optimize for artificial intelligence, the same methodology will be applicable for future data center optimizations as well to improve operational efficiency.\nHow cooling works at Meta’s data centers \nCurrently, Meta’s data centers adopt a two-tiered penthouse design that utilizes 100% outside air for cooling. As shown in Figure 1, the air enters the facility through louvers on the second-floor “penthouse,” with modulating dampers regulating the volume of outside air. The air passes through a mixing room, where outdoor air, if too cold, can be mixed with heat from server exhaust when needed to regulate the temperature. \nThe air then passes through a series of air filters and a misting chamber where the evaporative cooling and humidification (ECH) system is used to further control the temperature and humidity. The air continues through a fan wall that pushes the air through openings in the floor that serve as an air shaft leading into the server area on the first floor. The hot air coming out from the server exhaust will be contained in the hot aisle, through exhaust shafts, and eventually released out of the building with the help of relief fans. \nWater is mainly used in two ways: evaporative cooling and humidification. The evaporative cooling system converts water into vapor to lower the temperature when the outside air is too hot, while the humidification process maintains the humidity level if the air is too dry. As a result of this design, we believe Meta’s data centers are among the most advanced, energy and water efficient data centers in the world.\nFigure 1: The penthouse cooling system within Meta’s data centers.\nIn order to supply air within the defined operating envelope, the penthouse relies on the building management system (BMS) to monitor and control different components of the mechanical system. This system performs the task of conditioning the intake air from outside by mixing, humidifying/dehumidifying, evaporative cooling, or a combination of these operations. \nThere are three major control loops responsible for adjusting setpoints for supply air: temperature, humidity, and airflow. The airflow setpoint is typically calculated based on a small set of input variables like current IT load, cold aisle temperature, and differential pressure between the cold aisle and hot aisle. The logic is often very simple at a linear scale, but becomes very difficult to accurately model as these values at different locations in the data center are coupled to one another and highly dependent on complex local boundary conditions. However, the amount of airflow will largely dictate the energy used by the supply fan arrays and water consumption when cooling or humidification is required. Therefore, optimizing the airflow setpoint would have the greatest impact in regards to further improving the cooling efficiency given the fact that the temperature and humidity boundary of the operating envelope is fixed.\nA reinforcement learning approach to data center cooling\nReinforcement learning (RL) is good at modeling control systems as sequential state machines. It functions as a software agent that determines what action to take at each state based on some transition model – which leads to a different state – and constantly gets feedback from the environment in terms of reward. In the end, the agent learns the best policy model (typically parameterized by a deep neural network) to achieve the optimal accumulated reward. The data center cooling control can be naturally modeled under this paradigm.\nAt any given time, the state of a data center can be represented by a set of environmental variables monitored by many different sensors for outside air, supply air, cold aisle and hot aisle, plus IT load (i.e., power consumption by servers), etc. The action is to control setpoints – for example, the supply airflow setpoint that determines how fast the supply fans run to meet the demand. The policy is the function mapping from the state space to action space (i.e., determining the appropriate airflow setpoint based on current state conditions). Now the task is to leverage historical data we have collected from thousands of sensors in our data centers – augmented with simulated data of potential, but not yet experienced conditions – and train a better policy model that gives us better reward in terms of energy or water usage efficiency. \nThe idea of using AI for data center cooling optimization is not new. There are also various RL approaches reported such as, transforming cooling optimization via deep reinforcement learning and data center cooling using model-predictive control. \nHowever, applying the control policy determined by an online RL model may result in various risks including breaches of service requirements and even thermal unsafety. To address this challenge, we adopted an offline simulator based RL approach. As illustrated in Figure 2, our RL agent operates in a simulated environment by starting from real-life historical observations, S. It then explores the action space, feeding into the simulator to predict the anticipated new state S’ and reward, R, given each sampled action, A. From there it collects the pairs (S, A) that have the best reward to form a new training data set to update the parameterized policy model.\nFigure 2: Our simulated-based offline RL approach.\nOur simulator is a physics-based model of building energy use that takes as inputs time series such as weather data, IT load, and setpoint schedules. The model is built with data center building parameters, including geometry, construction materials, HVAC, system configurations, component efficiencies, and control strategies. It uses differential equations to output the dynamic system response, such as the thermal load and resulting energy use, along with related metrics like cold aisle temperature and differential pressure profiles. \nThe simulator plays a very important role here since our goal is to optimize energy and water usage while keeping the data center condition under specs so hardware performance isn’t affected. More specifically, we want to keep the rise in cold aisle temperature below a certain threshold, or a positive pressurization from cold aisle to hot aisle, to minimize the parasitic heat caused by recirculation. \nAdditionally, the physics-based simulator enables us to train the RL model with all possible scenarios, not only those present in the historical data. This increases reliability during outlier events and allows for rapid deployment in newly commissioned data centers.\nResults of our RL approach\nIn 2021, we started a pilot at one of Meta’s data center regions – having the RL model directly controlling the supply airflow setpoint. Figure 3 shows a comparison of the new setpoint, in the unit of cubic feet per minute (CFM) as the red line to the original BMS setpoint (as the dotted blue line) over one week’s duration for illustration purposes.\nFigure 3: A comparison of the RL model versus the original BMS setpoint.\nThe fluctuation is mainly determined by the supply air temperature and server load cycles at different times of day. More importantly, as shown in Figure 4, the data center temperature conditions never went out of spec, with reduced airflow supply with respect to both cold aisle average and maximum temperature compared against the supply air temperature.\nFigure 4: A data center temperature profile under RL model control.\nIt is noticeable that the CFM savings vary under different supply air temperatures as the univariate chart in Figure 5 shows. The CFM savings can easily be converted to energy savings used by the supply fans. Under hot and dry conditions, when evaporative cooling or humidification is required, using less air will result in less water usage as well. Over the past couple years of the pilot, on average, we were able to reduce the supply fan energy consumption by 20% and water usage by 4% across various weather conditions.  \nFigure 5. A breakdown of airflow savings at different supply air temperatures.\nFuture work for AI in data center optimization\nThis effort has opened the door to transform how our data centers operate. By introducing automated predictions and continuous optimizations for tuning environment conditions in our data centers we can bend the cost curve and reduce effort on labor intensive tasks.\n\nMeta is breaking ground on new types of data centers that are designed to optimize for artificial intelligence. We plan to apply the same methodology presented here to our future data centers at the design phase to help ensure they’re optimized for sustainability from day one of their operations.\nWe’re also currently rolling out our RL approach to data center cooling to our existing data centers. Over the couple of years we expect to achieve significant energy and water usage savings to contribute to Meta’s long- term sustainability goals. \nAcknowledgements\nWe would like to thank our partners in IDC Facility Operations (Butch Howard, Randy Ridgway, James Monahan, Jose Montes, Larame Cummings, Gerson Arteaga Ramirez, John Fabian, and many others) for their support.\nThe post Simulator-based reinforcement learning for data center cooling optimization appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>We’re sharing more about the role that reinforcement learning plays in helping us optimize our data centers’ environmental controls. Our reinforcement learning-based approach has helped us reduce energy consumption and water usage across various weather conditions in our data centers.   Meta is revamping its new data center design to optimize for artificial intelligence and the [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/09/10/data-center-engineering/simulator-based-reinforcement-learning-for-data-center-cooling-optimization/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/09/10/data-center-engineering/simulator-based-reinforcement-learning-for-data-center-cooling-optimization/\">Simulator-based reinforcement learning for data center cooling optimization</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "We’re sharing more about the role that reinforcement learning plays in helping us optimize our data centers’ environmental controls. Our reinforcement learning-based approach has helped us reduce energy consumption and water usage across various weather conditions in our data centers.   Meta is revamping its new data center design to optimize for artificial intelligence and the [...]\nRead More...\nThe post Simulator-based reinforcement learning for data center cooling optimization appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21675",
        "categories": [
          "Data Center Engineering",
          "ML Applications"
        ],
        "isoDate": "2024-09-10T16:00:31.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": [
      {
        "creator": "Netflix Technology Blog",
        "title": "Pushy to the Limit: Evolving Netflix’s WebSocket proxy for the future",
        "link": "https://netflixtechblog.com/pushy-to-the-limit-evolving-netflixs-websocket-proxy-for-the-future-b468bc0ff658?source=rss----2615bd06b42e---4",
        "pubDate": "Tue, 10 Sep 2024 19:15:34 GMT",
        "content:encodedSnippet": "By Karthik Yagna, Baskar Odayarkoil, and Alex Ellis\nPushy is Netflix’s WebSocket server that maintains persistent WebSocket connections with devices running the Netflix application. This allows data to be sent to the device from backend services on demand, without the need for continually polling requests from the device. Over the last few years, Pushy has seen tremendous growth, evolving from its role as a best-effort message delivery service to be an integral part of the Netflix ecosystem. This post describes how we’ve grown and scaled Pushy to meet its new and future needs, as it handles hundreds of millions of concurrent WebSocket connections, delivers hundreds of thousands of messages per second, and maintains a steady 99.999% message delivery reliability rate.\nHistory & motivation\nThere were two main motivating use cases that drove Pushy’s initial development and usage. The first was voice control, where you can play a title or search using your virtual assistant with a voice command like “Show me Stranger Things on Netflix.” (See How to use voice controls with Netflix if you want to do this yourself!).\nIf we consider the Alexa use case, we can see how this partnership with Amazon enabled this to work. Once they receive the voice command, we allow them to make an authenticated call through apiproxy, our streaming edge proxy, to our internal voice service. This call includes metadata, such as the user’s information and details about the command, such as the specific show to play. The voice service then constructs a message for the device and places it on the message queue, which is then processed and sent to Pushy to deliver to the device. Finally, the device receives the message, and the action, such as “Show me Stranger Things on Netflix”, is performed. This initial functionality was built out for FireTVs and was expanded from there.\nSample system diagram for an Alexa voice command. Where aws ends and the internet begins is an exercise left to the reader.\nThe other main use case was RENO, the Rapid Event Notification System mentioned above. Before the integration with Pushy, the TV UI would continuously poll a backend service to see if there were any row updates to get the latest information. These requests would happen every few seconds, which ended up creating extraneous requests to the backend and were costly for devices, which are frequently resource constrained. The integration with WebSockets and Pushy alleviated both of these points, allowing the origin service to send row updates as they were ready, resulting in lower request rates and cost savings.\nFor more background on Pushy, you can see this InfoQ talk by Susheel Aroskar. Since that presentation, Pushy has grown in both size and scope, and this article will be discussing the investments we’ve made to evolve Pushy for the next generation of features.\nClient Reach\nThis integration was initially rolled out for Fire TVs, PS4s, Samsung TVs, and LG TVs, leading to a reach of about 30 million candidate devices. With these clear benefits, we continued to build out this functionality for more devices, enabling the same efficiency wins. As of today, we’ve expanded our list of candidate devices even further to nearly a billion devices, including mobile devices running the Netflix app and the website experience. We’ve even extended support to older devices that lack modern capabilities, like support for TLS and HTTPS requests. For those, we’ve enabled secure communication from client to Pushy via an encryption/decryption layer on each, allowing for confidential messages to flow between the device and server.\nScaling to handle that growth (and more)\nGrowth\nWith that extended reach, Pushy has gotten busier. Over the last five years, Pushy has gone from tens of millions of concurrent connections to hundreds of millions of concurrent connections, and it regularly reaches 300,000 messages sent per second. To support this growth, we’ve revisited Pushy’s past assumptions and design decisions with an eye towards both Pushy’s future role and future stability. Pushy had been relatively hands-free operationally over the last few years, and as we updated Pushy to fit its evolving role, our goal was also to get it into a stable state for the next few years. This is particularly important as we build out new functionality that relies on Pushy; a strong, stable infrastructure foundation allows our partners to continue to build on top of Pushy with confidence.\nThroughout this evolution, we’ve been able to maintain high availability and a consistent message delivery rate, with Pushy successfully maintaining 99.999% reliability for message delivery over the last few months. When our partners want to deliver a message to a device, it’s our job to make sure they can do so.\nHere are a few of the ways we’ve evolved Pushy to handle its growing scale.\nA few of the related services in Pushy’s immediate ecosystem and the changes we’ve made for them.\nMessage processor\nOne aspect that we invested in was the evolution of the asynchronous message processor. The previous version of the message processor was a Mantis stream-processing job that processed messages from the message queue. It was very efficient, but it had a set job size, requiring manual intervention if we wanted to horizontally scale it, and it required manual intervention when rolling out a new version.\nIt served Pushy’s needs well for many years. As the scale of the messages being processed increased and we were making more code changes in the message processor, we found ourselves looking for something more flexible. In particular, we were looking for some of the features we enjoy with our other services: automatic horizontal scaling, canaries, automated red/black rollouts, and more observability. With this in mind, we rewrote the message processor as a standalone Spring Boot service using Netflix paved-path components. Its job is the same, but it does so with easy rollouts, canary configuration that lets us roll changes safely, and autoscaling policies we’ve defined to let it handle varying volumes.\nRewriting always comes with a risk, and it’s never the first solution we reach for, particularly when working with a system that’s in place and working well. In this case, we found that the burden from maintaining and improving the custom stream processing job was increasing, and we made the judgment call to do the rewrite. Part of the reason we did so was the clear role that the message processor played — we weren’t rewriting a huge monolithic service, but instead a well-scoped component that had explicit goals, well-defined success criteria, and a clear path towards improvement. Since the rewrite was completed in mid-2023, the message processor component has been completely zero touch, happily automated and running reliably on its own.\nPush Registry\nFor most of its life, Pushy has used Dynomite for keeping track of device connection metadata in its Push Registry. Dynomite is a Netflix open source wrapper around Redis that provides a few additional features like auto-sharding and cross-region replication, and it provided Pushy with low latency and easy record expiry, both of which are critical for Pushy’s workload.\nAs Pushy’s portfolio grew, we experienced some pain points with Dynomite. Dynomite had great performance, but it required manual scaling as the system grew. The folks on the Cloud Data Engineering (CDE) team, the ones building the paved path for internal data at Netflix, graciously helped us scale it up and make adjustments, but it ended up being an involved process as we kept growing.\nThese pain points coincided with the introduction of KeyValue, which was a new offering from the CDE team that is roughly “HashMap as a service” for Netflix developers. KeyValue is an abstraction over the storage engine itself, which allows us to choose the best storage engine that meets our SLO needs. In our case, we value low latency — the faster we can read from KeyValue, the faster these messages can get delivered. With CDE’s help, we migrated our Push Registry to use KV instead, and we have been extremely satisfied with the result. After tuning our store for Pushy’s needs, it has been on autopilot since, appropriately scaling and serving our requests with very low latency.\nScaling Pushy horizontally and vertically\nMost of the other services our team runs, like apiproxy, the streaming edge proxy, are CPU bound, and we have autoscaling policies that scale them horizontally when we see an increase in CPU usage. This maps well to their workload — more HTTP requests means more CPU used, and we can scale up and down accordingly.\nPushy has slightly different performance characteristics, with each node maintaining many connections and delivering messages on demand. In Pushy’s case, CPU usage is consistently low, since most of the connections are parked and waiting for an occasional message. Instead of relying on CPU, we scale Pushy on the number of connections, with exponential scaling to scale faster after higher thresholds are reached. We load balance the initial HTTP requests to establish the connections and rely on a reconnect protocol where devices will reconnect every 30 minutes or so, with some staggering, that gives us a steady stream of reconnecting devices to balance connections across all available instances.\nFor a few years, our scaling policy had been that we would add new instances when the average number of connections reached 60,000 connections per instance. For a couple hundred million devices, this meant that we were regularly running thousands of Pushy instances. We can horizontally scale Pushy to our heart’s content, but we would be less content with our bill and would have to shard Pushy further to get around NLB connection limits. This evolution effort aligned well with an internal focus on cost efficiency, and we used this as an opportunity to revisit these earlier assumptions with an eye towards efficiency.\nBoth of these would be helped by increasing the number of connections that each Pushy node could handle, reducing the total number of Pushy instances and running more efficiently with the right balance between instance type, instance cost, and maximum concurrent connections. It would also allow us to have more breathing room with the NLB limits, reducing the toil of additional sharding as we continue to grow. That being said, increasing the number of connections per node is not without its own drawbacks. When a Pushy instance goes down, the devices that were connected to it will immediately try to reconnect. By increasing the number of connections per instance, it means that we would be increasing the number of devices that would be immediately trying to reconnect. We could have a million connections per instance, but a down node would lead to a thundering herd of a million devices reconnecting at the same time.\nThis delicate balance led to us doing a deep evaluation of many instance types and performance tuning options. Striking that balance, we ended up with instances that handle an average of 200,000 connections per node, with breathing room to go up to 400,000 connections if we had to. This makes for a nice balance between CPU usage, memory usage, and the thundering herd when a device connects. We’ve also enhanced our autoscaling policies to scale exponentially; the farther we are past our target average connection count, the more instances we’ll add. These improvements have enabled Pushy to be almost entirely hands off operationally, giving us plenty of flexibility as more devices come online in different patterns.\nReliability & building a stable foundation\nAlongside these efforts to scale Pushy for the future, we also took a close look at our reliability after finding some connectivity edge cases during recent feature development. We found a few areas for improvement around the connection between Pushy and the device, with failures due to Pushy attempting to send messages on a connection that had failed without notifying Pushy. Ideally something like a silent failure wouldn’t happen, but we frequently see odd client behavior, particularly on older devices.\nIn collaboration with the client teams, we were able to make some improvements. On the client side, better connection handling and improvements around the reconnect flow meant that they were more likely to reconnect appropriately. In Pushy, we added additional heartbeats, idle connection cleanup, and better connection tracking, which meant that we were keeping around fewer and fewer stale connections.\nWhile these improvements were mostly around those edge cases for the feature development, they had the side benefit of bumping our message delivery rates up even further. We already had a good message delivery rate, but this additional bump has enabled Pushy to regularly average 5 9s of message delivery reliability.\nPush message delivery success rate over a recent 2-week period.\nRecent developments\nWith this stable foundation and all of these connections, what can we now do with them? This question has been the driving force behind nearly all of the recent features built on top of Pushy, and it’s an exciting question to ask, particularly as an infrastructure team.\nShift towards direct push\nThe first change from Pushy’s traditional role is what we call direct push; instead of a backend service dropping the message on the asynchronous message queue, it can instead leverage the Push library to skip the asynchronous queue entirely. When called to deliver a message in the direct path, the Push library will look up the Pushy connected to the target device in the Push Registry, then send the message directly to that Pushy. Pushy will respond with a status code reflecting whether it was able to successfully deliver the message or it encountered an error, and the Push library will bubble that up to the calling code in the service.\nThe system diagram for the direct and indirect push paths.\nSusheel, the original author of Pushy, added this functionality as an optional path, but for years, nearly all backend services relied on the indirect path with its “best-effort” being good enough for their use cases. In recent years, we’ve seen usage of this direct path really take off as the needs of backend services have grown. In particular, rather than being just best effort, these direct messages allow the calling service to have immediate feedback about the delivery, letting them retry if a device they’re targeting has gone offline.\nThese days, messages sent via direct push make up the majority of messages sent through Pushy. For example, for a recent 24 hour period, direct messages averaged around 160,000 messages per second and indirect averaged at around 50,000 messages per second..\nGraph of direct vs indirect messages per second.\nDevice to device messaging\nAs we’ve thought through this evolving use case, our concept of a message sender has also evolved. What if we wanted to move past Pushy’s pattern of delivering server-side messages? What if we wanted to have a device send a message to a backend service, or maybe even to another device? Our messages had traditionally been unidirectional as we send messages from the server to the device, but we now leverage these bidirectional connections and direct device messaging to enable what we call device to device messaging. This device to device messaging supported early phone-to-TV communication in support of games like Triviaverse, and it’s the messaging foundation for our Companion Mode as TVs and phones communicate back and forth.\nA screenshot of one of the authors playing Triviaquest with a mobile device as the controller.\nThis requires higher level knowledge of the system, where we need to know not just information about a single device, but more broader information, like what devices are connected for an account that the phone can pair with. This also enables things like subscribing to device events to know when another device comes online and when they’re available to pair or send a message to. This has been built out with an additional service that receives device connection information from Pushy. These events, sent over a Kafka topic, let the service keep track of the device list for a given account. Devices can subscribe to these events, allowing them to receive a message from the service when another device for the same account comes online.\nPushy and its relationship with the Device List Service for discovering other devices.\nThis device list enables the discoverability aspect of these device to device messages. Once the devices have this knowledge of the other devices connected for the same account, they’re able to choose a target device from this list that they can then send messages to.\nOnce a device has that list, it can send a message to Pushy over its WebSocket connection with that device as the target in what we call a device to device message (1 in the diagram below). Pushy looks up the target device’s metadata in the Push registry (2) and sends the message to the second Pushy that the target device is connected to (3), as if it was the backend service in the direct push pattern above. That Pushy delivers the message to the target device (4), and the original Pushy will receive a status code in response, which it can pass back to the source device (5).\nA basic order of events for a device to device message.\nThe messaging protocol\nWe’ve defined a basic JSON-based message protocol for device to device messaging that lets these messages be passed from the source device to the target device. As a networking team, we naturally lean towards abstracting the communication layer with encapsulation wherever possible. This generalized message means that device teams are able to define their own protocols on top of these messages — Pushy would just be the transport layer, happily forwarding messages back and forth.\nThe client app protocol, built on top of the device to device protocol, built on top of Pushy.\nThis generalization paid off in terms of investment and operational support. We built the majority of this functionality in October 2022, and we’ve only needed small tweaks since then. We needed nearly no modifications as client teams built out the functionality on top of this layer, defining the higher level application-specific protocols that powered the features they were building. We really do enjoy working with our partner teams, but if we’re able to give them the freedom to build on top of our infrastructure layer without us getting involved, then we’re able to increase their velocity, make their lives easier, and play our infrastructure roles as message platform providers.\nWith early features in experimentation, Pushy sees an average of 1000 device to device messages per second, a number that will only continue to grow.\nGraph of device to device messages per second.\nThe Netty-gritty details\nIn Pushy, we handle incoming WebSocket messages in our PushClientProtocolHandler (code pointer to class in Zuul that we extend), which extends Netty’s ChannelInboundHandlerAdapter and is added to the Netty pipeline for each client connection. We listen for incoming WebSocket messages from the connected device in its channelRead method and parse the incoming message. If it’s a device to device message, we pass the message, the ChannelHandlerContext, and the PushUserAuth information about the connection’s identity to our DeviceToDeviceManager.\nA rough overview of the internal organization for these components.\nThe DeviceToDeviceManager is responsible for validating the message, doing some bookkeeping, and kicking off an async call that validates that the device is an authorized target, looks up the Pushy for the target device in the local cache (or makes a call to the data store if it’s not found), and forwards on the message. We run this asynchronously to avoid any event loop blocking due to these calls. The DeviceToDeviceManager is also responsible for observability, with metrics around cache hits, calls to the data store, message delivery rates, and latency percentile measurements. We’ve relied heavily on these metrics for alerts and optimizations — Pushy really is a metrics service that occasionally will deliver a message or two!\nSecurity\nAs the edge of the Netflix cloud, security considerations are always top of mind. With every connection over HTTPS, we’ve limited these messages to just authenticated WebSocket connections, added rate limiting, and added authorization checks to ensure that a device is able to target another device — you may have the best intentions in mind, but I’d strongly prefer it if you weren’t able to send arbitrary data to my personal TV from yours (and vice versa, I’m sure!).\nLatency and other considerations\nOne main consideration with the products built on top of this is latency, particularly when this feature is used for anything interactive within the Netflix app.\nWe’ve added caching to Pushy to reduce the number of lookups in the hotpath for things that are unlikely to change frequently, like a device’s allowed list of targets and the Pushy instance the target device is connected to. We have to do some lookups on the initial messages to know where to send them, but it enables us to send subsequent messages faster without any KeyValue lookups. For these requests where caching removed KeyValue from the hot path, we were able to greatly speed things up. From the incoming message arriving at Pushy to the response being sent back to the device, we reduced median latency to less than a millisecond, with the 99th percentile of latency at less than 4ms.\nOur KeyValue latency is usually very low, but we have seen brief periods of elevated read latencies due to underlying issues in our KeyValue datastore. Overall latencies increased for other parts of Pushy, like client registration, but we saw very little increase in device to device latency with this caching in place.\nCultural aspects that enable this work\nPushy’s scale and system design considerations make the work technically interesting, but we also deliberately focus on non-technical aspects that have helped to drive Pushy’s growth. We focus on iterative development that solves the hardest problem first, with projects frequently starting with quick hacks or prototypes to prove out a feature. As we do this initial version, we do our best to keep an eye towards the future, allowing us to move quickly from supporting a single, focused use case to a broad, generalized solution. For example, for our cross-device messaging, we were able to solve hard problems in the early work for Triviaverse that we later leveraged for the generic device to device solution.\nAs one can immediately see in the system diagrams above, Pushy does not exist in a vacuum, with projects frequently involving at least half a dozen teams. Trust, experience, communication, and strong relationships all enable this to work. Our team wouldn’t exist without our platform users, and we certainly wouldn’t be here writing this post without all of the work our product and client teams do. This has also emphasized the importance of building and sharing — if we’re able to get a prototype together with a device team, we’re able to then show it off to seed ideas from other teams. It’s one thing to mention that you can send these messages, but it’s another to show off the TV responding to the first click of the phone controller button!\nThe future of Pushy\nIf there’s anything certain in this world, it’s that Pushy will continue to grow and evolve. We have many new features in the works, like WebSocket message proxying, WebSocket message tracing, a global broadcast mechanism, and subscription functionality in support of Games and Live. With all of this investment, Pushy is a stable, reinforced foundation, ready for this next generation of features.\nWe’ll be writing about those new features as well — stay tuned for future posts.\nSpecial thanks to our stunning colleagues Jeremy Kelly and Justin Guerra who have both been invaluable to Pushy’s growth and the WebSocket ecosystem at large. We would also like to thank our larger teams and our numerous partners for their great work; it truly takes a village!\n\nPushy to the Limit: Evolving Netflix’s WebSocket proxy for the future was originally published in Netflix TechBlog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Netflix Technology Blog",
        "guid": "https://medium.com/p/b468bc0ff658",
        "isoDate": "2024-09-10T19:15:34.000Z"
      },
      {
        "creator": "Netflix Technology Blog",
        "title": "Noisy Neighbor Detection with eBPF",
        "link": "https://netflixtechblog.com/noisy-neighbor-detection-with-ebpf-64b1f4b3bbdd?source=rss----2615bd06b42e---4",
        "pubDate": "Tue, 10 Sep 2024 18:00:21 GMT",
        "content:encodedSnippet": "By Jose Fernandez, Sebastien Dabdoub, Jason Koch, Artem Tkachuk\nThe Compute and Performance Engineering teams at Netflix regularly investigate performance issues in our multi-tenant environment. The first step is determining whether the problem originates from the application or the underlying infrastructure. One issue that often complicates this process is the \"noisy neighbor\" problem. On Titus, our multi-tenant compute platform, a \"noisy neighbor\" refers to a container or system service that heavily utilizes the server's resources, causing performance degradation in adjacent containers. We usually focus on CPU utilization because it is our workloads’ most frequent source of noisy neighbor issues.\nDetecting the effects of noisy neighbors is complex. Traditional performance analysis tools such as perf can introduce significant overhead, risking further performance degradation. Additionally, these tools are typically deployed after the fact, which is too late for effective investigation. Another challenge is that debugging noisy neighbor issues requires significant low-level expertise and specialized tooling. In this blog post, we'll reveal how we leveraged eBPF to achieve continuous, low-overhead instrumentation of the Linux scheduler, enabling effective self-serve monitoring of noisy neighbor issues. You’ll learn how Linux kernel instrumentation can improve your infrastructure observability with deeper insights and enhanced monitoring.\nContinuous Instrumentation of the Linux Scheduler\nTo ensure the reliability of our workloads that depend on low latency responses, we instrumented the run queue latency for each container, which measures the time processes spend in the scheduling queue before being dispatched to the CPU. Extended waiting in this queue can be a telltale of performance issues, especially when containers are not utilizing their total CPU allocation. Continuous instrumentation is critical to catching such matters as they emerge, and eBPF, with its hooks into the Linux scheduler with minimal overhead, enabled us to monitor run queue latency efficiently.\nTo emit a run queue latency metric, we leveraged three eBPF hooks: sched_wakeup, sched_wakeup_new, and sched_switch.\nDiagram of how run queue latency is measured and instrumented\nThe sched_wakeup and sched_wakeup_new hooks are invoked when a process changes state from 'sleeping' to 'runnable.' They let us identify when a process is ready to run and is waiting for CPU time. During this event, we generate a timestamp and store it in an eBPF hash map using the process ID as the key.\nstruct {\n    __uint(type, BPF_MAP_TYPE_HASH);\n    __uint(max_entries, MAX_TASK_ENTRIES);\n    __uint(key_size, sizeof(u32));\n    __uint(value_size, sizeof(u64));\n} runq_enqueued SEC(\".maps\");\nSEC(\"tp_btf/sched_wakeup\")\nint tp_sched_wakeup(u64 *ctx)\n{    struct task_struct *task = (void *)ctx[0];\n    u32 pid = task->pid;\n    u64 ts = bpf_ktime_get_ns();\n    bpf_map_update_elem(&runq_enqueued, &pid, &ts, BPF_NOEXIST);\n    return 0;\n}\nConversely, the sched_switch hook is triggered when the CPU switches between processes. This hook provides pointers to the process currently utilizing the CPU and the process about to take over. We use the upcoming task's process ID (PID) to fetch the timestamp from the eBPF map. This timestamp represents when the process entered the queue, which we had previously stored. We then calculate the run queue latency by simply subtracting the timestamps.\nSEC(\"tp_btf/sched_switch\")\nint tp_sched_switch(u64 *ctx)\n{    struct task_struct *prev = (struct task_struct *)ctx[1];\n    struct task_struct *next = (struct task_struct *)ctx[2];\n    u32 prev_pid = prev->pid;\n    u32 next_pid = next->pid;\n     // fetch timestamp of when the next task was enqueued\n    u64 *tsp = bpf_map_lookup_elem(&runq_enqueued, &next_pid);\n    if (tsp == NULL) {\n        return 0; // missed enqueue\n    }\n    // calculate runq latency before deleting the stored timestamp\n    u64 now = bpf_ktime_get_ns();\n    u64 runq_lat = now - *tsp;\n    // delete pid from enqueued map\n    bpf_map_delete_elem(&runq_enqueued, &next_pid);\n    ....\nOne of the advantages of eBPF is its ability to provide pointers to the actual kernel data structures representing processes or threads, also known as tasks in kernel terminology. This feature enables access to a wealth of information stored about a process. We required the process's cgroup ID to associate it with a container for our specific use case. However, the cgroup information in the process struct is safeguarded by an RCU (Read Copy Update) lock.\nTo safely access this RCU-protected information, we can leverage kfuncs in eBPF. kfuncs are kernel functions that can be called from eBPF programs. There are kfuncs available to lock and unlock RCU read-side critical sections. These functions ensure that our eBPF program remains safe and efficient while retrieving the cgroup ID from the task struct.\nvoid bpf_rcu_read_lock(void) __ksym;\nvoid bpf_rcu_read_unlock(void) __ksym;\nu64 get_task_cgroup_id(struct task_struct *task)\n{    struct css_set *cgroups;\n    u64 cgroup_id;\n    bpf_rcu_read_lock();\n    cgroups = task->cgroups;\n    cgroup_id = cgroups->dfl_cgrp->kn->id;\n    bpf_rcu_read_unlock();\n    return cgroup_id;\n}\nOnce the data is ready, we must package it and send it to userspace. For this purpose, we chose the eBPF ring buffer. It is efficient, high-performing, and user-friendly. It can handle variable-length data records and allows data reading without necessitating extra memory copying or syscalls. However, the sheer number of data points was causing the userspace program to use too much CPU, so we implemented a rate limiter in eBPF to sample the data.\nstruct {\n    __uint(type, BPF_MAP_TYPE_RINGBUF);\n    __uint(max_entries, RINGBUF_SIZE_BYTES);\n} events SEC(\".maps\");\nstruct {\n    __uint(type, BPF_MAP_TYPE_PERCPU_HASH);\n    __uint(max_entries, MAX_TASK_ENTRIES);\n    __uint(key_size, sizeof(u64));\n    __uint(value_size, sizeof(u64));\n} cgroup_id_to_last_event_ts SEC(\".maps\");\nstruct runq_event {\n    u64 prev_cgroup_id;\n    u64 cgroup_id;\n    u64 runq_lat;\n    u64 ts;\n};\nSEC(\"tp_btf/sched_switch\")\nint tp_sched_switch(u64 *ctx)\n{    // ....\n    // The previous code\n    // ....\n     u64 prev_cgroup_id = get_task_cgroup_id(prev);\n    u64 cgroup_id = get_task_cgroup_id(next);\n     // per-cgroup-id-per-CPU rate-limiting \n    // to balance observability with performance overhead\n    u64 *last_ts = \n        bpf_map_lookup_elem(&cgroup_id_to_last_event_ts, &cgroup_id);\n    u64 last_ts_val = last_ts == NULL ? 0 : *last_ts;\n    // check the rate limit for the cgroup_id in consideration\n    // before doing more work\n    if (now - last_ts_val < RATE_LIMIT_NS) {\n        // Rate limit exceeded, drop the event\n        return 0;\n    }\n    struct runq_event *event;\n    event = bpf_ringbuf_reserve(&events, sizeof(*event), 0);\n  \n    if (event) {\n        event->prev_cgroup_id = prev_cgroup_id;\n        event->cgroup_id = cgroup_id;\n        event->runq_lat = runq_lat;\n        event->ts = now;\n        bpf_ringbuf_submit(event, 0);\n        // Update the last event timestamp for the current cgroup_id\n        bpf_map_update_elem(&cgroup_id_to_last_event_ts, &cgroup_id,\n            &now, BPF_ANY);\n    }\n    return 0;\n}\nOur userspace application, developed in Go, processes events from the ring buffer to emit metrics to our metrics backend, Atlas. Each event includes a run queue latency sample with a cgroup ID, which we associate with containers running on the host. We categorize it as a system service if no such association is found. When a cgroup ID is associated with a container, we emit a percentile timer Atlas metric (runq.latency) for that container. We also increment a counter metric (sched.switch.out) to monitor preemptions occurring for the container's processes. Access to the prev_cgroup_id of the preempted process allows us to tag the metric with the cause of the preemption, whether it's due to a process within the same container (or cgroup), a process in another container, or a system service.\nIt's important to highlight that both the runq.latency metric and the sched.switch.out metrics are needed to determine if a container is affected by noisy neighbors, which is the goal we aim to achieve — relying solely on the runq.latency metric can lead to misconceptions. For example, if a container is at or over its cgroup CPU limit, the scheduler will throttle it, resulting in an apparent spike in run queue latency due to delays in the queue. If we were only to consider this metric, we might incorrectly attribute the performance degradation to noisy neighbors when it's actually because the container is hitting its CPU quota. However, simultaneous spikes in both metrics, mainly when the cause is a different container or system process, clearly indicate a noisy neighbor issue.\nA Noisy Neighbor Story\nBelow is the runq.latency metric for a server running a single container with ample CPU capacity. The 99th percentile averages 83.4µs (microseconds), serving as our baseline. Although there are some spikes reaching 400µs, the latency remains within acceptable parameters.\ncontainer1’s 99th percentile runq.latency averages 83µs (microseconds), with spikes up to 400µs, without adjacent containers. This serves as our baseline for a container not contending for CPU on a host.\nAt 10:35, launching container2, which fully utilized all CPUs on the host, caused a significant 131-millisecond spike (131,000 microseconds) in container1's P99 run queue latency. This spike would be noticeable in the userspace application if it were serving HTTP traffic. If userspace app owners reported an unexplained latency spike, we could quickly identify the noisy neighbor issue through run queue latency metrics.\nLaunching container2 at 10:35, which maxes out all CPUs on the host, caused a 131-millisecond spike in container1’s P99 run queue latency due to increased preemptions by system processes. This indicates a noisy neighbor issue, where system services compete for CPU time with containers.\nThe sched.switch.out metric indicates that the spike was due to increased preemptions by system processes, highlighting a noisy neighbor issue where system services compete with containers for CPU time. Our metrics show that the noisy neighbors were actually system processes, likely triggered by container2 consuming all available CPU capacity.\nOptimizing eBPF Code\nWe developed an open-source eBPF process monitoring tool called bpftop to measure the overhead of eBPF code in this kernel hot path. Our profiling with bpftop shows that the instrumentation adds less than 600 nanoseconds to each sched_* hook. We conducted a performance analysis on a Java service running in a container, and the instrumentation did not introduce significant overhead. The performance variance with the run queue profiling code active versus inactive was not measurable in milliseconds.\nDuring our research on how eBPF statistics are measured in the kernel, we identified an opportunity to improve the calculation. We submitted this patch, which was included in the Linux kernel 6.10 release.\n\nThrough trial and error and using bpftop, we identified several optimizations that helped maintain low overhead for our eBPF code:\n\nWe found that BPF_MAP_TYPE_HASH was the most performant for storing enqueued timestamps. Using BPF_MAP_TYPE_TASK_STORAGE resulted in nearly a twofold performance decline. BPF_MAP_TYPE_PERCPU_HASH was slightly less performant than BPF_MAP_TYPE_HASH, which was unexpected and requires further investigation.\nBPF_MAP_TYPE_LRU_HASH maps are 40–50 nanoseconds slower per operation than regular hash maps. Due to space concerns from PID churn, we initially used them for enqueued timestamps. Ultimately, we settled on BPF_MAP_TYPE_HASH with an increased size to mitigate this risk.\nThe BPF_CORE_READ helper adds 20–30 nanoseconds per invocation. In the case of raw tracepoints, specifically those that are \"BTF-enabled\" (tp_btf/*), it is safe and more efficient to access the task struct members directly. Andrii Nakryiko recommends this approach in this blog post.\nThe sched_switch, sched_wakeup, and sched_wakeup_new are all triggered for kernel tasks, which are identifiable by their PID of 0. We found monitoring these tasks unnecessary, so we implemented several early exit conditions and conditional logic to prevent executing costly operations, such as accessing BPF maps, when dealing with a kernel task. Notably, kernel tasks operate through the scheduler queue like any regular process.\n\nConclusion\nOur findings highlight the value of low-overhead continuous instrumentation of the Linux kernel with eBPF. We have integrated these metrics into customer dashboards, enabling actionable insights and guiding multitenancy performance discussions. We can also now use these metrics to refine CPU isolation strategies to minimize the impact of noisy neighbors. Additionally, thanks to these metrics, we've gained deeper insights into the Linux scheduler.\nThis work has also deepened our understanding of eBPF technology and underscored the importance of tools like bpftop for optimizing eBPF code. As eBPF adoption increases, we foresee more infrastructure observability and business logic shifting to it. One promising project in this space is sched_ext, which has the potential to revolutionize how scheduling decisions are made and tailored to specific workload needs.\n\nNoisy Neighbor Detection with eBPF was originally published in Netflix TechBlog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Netflix Technology Blog",
        "guid": "https://medium.com/p/64b1f4b3bbdd",
        "categories": [
          "observability",
          "linux",
          "ebpf",
          "performance",
          "containers"
        ],
        "isoDate": "2024-09-10T18:00:21.000Z"
      }
    ]
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "David Watson",
        "title": "What’s Next: The WebStorm 2024.3 Roadmap",
        "link": "https://blog.jetbrains.com/webstorm/2024/09/what-s-next-the-webstorm-2024-3-roadmap/",
        "pubDate": "Wed, 11 Sep 2024 13:30:20 +0000",
        "content:encodedSnippet": "In August of this year, we released WebStorm 2024.2, our second major update for 2024. Thank you to everyone who is already using it and providing feedback. \nWith August now behind us, we’d like to announce what we’ve got planned for the next release of WebStorm, which is scheduled for the middle of November, with our usual disclaimer: these plans are subject to change. \nAlso, as usual, we’ll be releasing EAP builds in the run-up to this release. We encourage you to try these builds, provide feedback on the features, and report any issues you discover. At this stage, you can significantly impact the product’s development.\nOur primary focus with this release is on improving the stability and quality of WebStorm and some of its subsystems. Here are our most significant plans for WebStorm 2024.3:\nWebStorm@next TypeScript engine – We’ve been working on delivering our TypeScript engine for the last year. We’re excited to announce significant performance improvements in WebStorm@next, with minimal functionality regression. If it meets our strict quality criteria by the end of the 2024.3 Early Access Program (EAP), it will be enabled by default in the release. Initially, WebStorm@next will focus on TypeScript, React, and Angular, with Vue potentially included if optimizations are completed. \nDatabase plugin – We’re going to reconsider how the current Database Tools and SQL plugin license model works with WebStorm subscriptions, and try to find a more suitable solution. This plugin provides you with database tools to query, create, and manage databases and full SQL language support.\nTailwind CSS color preview – We’re enhancing our Tailwind integration by adding color previews, making it easier to quickly identify the colors that are applied to elements. (WEB-47817).\nNew functionality during indexing – To improve the startup experience and reduce waiting times, certain dumb functionality (WEB-64105, WEB-64106, and WEB-64107) will now be accessible during indexing.\nImproved test framework support – Certain limitations of the current test framework support can cause test files to be misidentified. We’ll be making significant internal changes and general test framework support improvements to fix this issue (WEB-64971 and WEB-67720).\nEnhanced Show Component Usages – We’re updating how WebStorm handles components. Template usages will now be recognized as part of the file, improving both the Show Component Usages action for Vue, Svelte, and Astro, as well as the Rename feature (WEB-65061).\nDisable SvelteKit a11y warnings option – We’ll add a new option to disable accessibility (a11y) warnings from the Svelte Language Service (WEB-62537).\nMonorepo project improvements – We’ll make searches in monorepo projects more focused and manageable by excluding search results from node_modules in the Find in Files directory tab by default (WEB-25601).\nEnhanced monorepo imports – We’ll improve the handling of imports in monorepos to reduce the number of incorrect imports from libraries or subprojects. This will address common issues related to auto-generated output folders like dist (WEB-68309) and problems associated with the partial support for the exports field in package.json (WEB-68290).\nSupport for exports in CSS – We’re adding support for the exports field in package.json for CSS files (WEB-55017).\n.idea directory displayed by default – Historically, the .idea folder has been hidden by default. Moving forward, we’ve decided to display all files in the projects to enhance transparency (WEB-68009).\nImproved JSX attribute experience  – We’ll no longer include the equal sign (=) for boolean JSX attributes (WEB-62632).\nAngular template usages displayed with class usages – We’re making Angular usage tracking more intuitive. When you invoke Show Usages on an Angular class, WebStorm will now display usages from templates as well (WEB-68183).\nUnused import inspections for Angular – We plan to introduce unused import inspections for Angular NgModule and standalone components, allowing you to reduce the number of unnecessary dependencies by identifying and removing unused imports (WEB-38266). This will also be added to version 2024.2.\nBundled Vue, Svelte, and Astro language servers – We plan to bundle the primary language services to enhance product reliability, prevent issues with language-server loading on WSL, and address security concerns associated with downloading language servers from the internet.\n\n\n\n\nThat’s all for now! Check out the 2024.3 Early Access Program to test these features as they become available!\nThe WebStorm team",
        "dc:creator": "David Watson",
        "content": "In August of this year, we released WebStorm 2024.2, our second major update for 2024. Thank you to everyone who is already using it and providing feedback.&#160; With August now behind us, we’d like to announce what we’ve got planned for the next release of WebStorm, which is scheduled for the middle of November, with [&#8230;]",
        "contentSnippet": "In August of this year, we released WebStorm 2024.2, our second major update for 2024. Thank you to everyone who is already using it and providing feedback.  With August now behind us, we’d like to announce what we’ve got planned for the next release of WebStorm, which is scheduled for the middle of November, with […]",
        "guid": "https://blog.jetbrains.com/?post_type=webstorm&p=509199",
        "isoDate": "2024-09-11T13:30:20.000Z"
      },
      {
        "creator": "Oleg Zinovyev",
        "title": "What’s Next for CLion: The 2024.3 Roadmap",
        "link": "https://blog.jetbrains.com/clion/2024/09/2024-3-roadmap/",
        "pubDate": "Wed, 11 Sep 2024 07:11:41 +0000",
        "content:encodedSnippet": "The second major release of CLion this year, 2024.2, introduced many improvements and advanced features. These include full line code completion for С++ that runs locally, Zephyr West support, and updates to the new CLion Nova language engine. If you still haven’t tried CLion 2024.2, download and try it today.\nDOWNLOAD CLION 2024.2\nWe’ve begun our work on the next release, 2024.3, and are prioritizing improvements in the following areas:\n🚀 CLion Nova functionality and stability\n🤖 Embedded development\n🏗️ Project formats and build tools\nRead on to learn more about the planned updates.\nThe following is a preliminary plan and not a promise or commitment. Tasks might be changed or rescheduled for various reasons. We can’t guarantee that all the issues listed below will be addressed in CLion 2024.3.\nCLion Nova\nCLion Nova is a new language engine that improves the IDE’s performance and accuracy. Since v2024.2, it has become the default language engine for new CLion users. For the 2024.3 release, we are working on some of the most requested features and improvements in CLion Nova related to project navigation, remote development, code style, and more.\nNew features\nHere are the features we plan to add to CLion Nova:\nCall hierarchy displays a function’s callers and callees (CPP-22675). This is one of the most anticipated features missing from CLion Nova compared to CLion Classic.\nMISRA C++:2023 is the latest edition of MISRA C++, which provides guidelines for using C++17 in safety-critical systems. We’ll add support for MISRA C++:2023 checks in the new release; the full list will be announced later. The MISRA C++:2023 checks will complement the currently supported MISRA C 2012 and MISRA C++ 2008 checks.\nFrontend-based typing assistance for remote development\nThe remote development mode in CLion Nova is still in beta. However, we are constantly improving its performance, stability, and functionality to make it production-ready sooner. In v2024.3, we plan to improve the responsiveness of the typing assistant. It is responsible for auto-inserting pair parentheses, brackets, and quotes, as well as smart indentation when pressing Enter, and other important actions.\nCLion now performs typing assistance on the server side, not the client side. The network round-trip time adds a noticeable delay between typing and the assistance results. To solve this problem, we move the typing assistance to the client side.\nThis solution is part of our broader project to move the typing assistance from CLion’s backend to the frontend. First, we will implement this optimization only for the local development scenario. The overall goal is to improve both remote and local development, eventually making typing assistance in the remote mode just as fast as it is in the local mode.\nSettings-related improvements\nThere are several important settings that CLion Nova still lacks. In v2024.3, we will add support for some of them, including those related to code styles:\nPredefined code styles, such as Google, LLVM, and GNU (CPP-36365).\nHeader Guard Style, which helps keep header naming according to your pattern (CPP-36933).\nWe will also be working on various settings-related issues to improve the user experience.\nProject formats\nWe plan to fix the problem where newly added .cpp and .h files are treated as not belonging to any project target, which causes code analysis to fail (CPP-37734, CPP-38040).\nEmbedded development\nOur ongoing efforts are focused on expanding CLion’s functionality and tailoring it to meet the needs of embedded developers across all their use cases. We already support different types of hardware and toolchains. In v2024.3, we will add a new feature for managing debugging servers more easily. This feature simplifies the configuration and execution of specific run/debug configurations for selected projects, such as OpenOCD, Zephyr, or J-Link. Roughly speaking, the feature will instruct CLion how and where to run a configuration. You can configure a debugger type, environment variables, connection, and other settings for each specific project.\nAnother helpful feature that we plan to include in this update is predefined debug targets (a tentative title), which are like preconfigured templates and will help speed up the configuration of debugging servers.\nProject formats and build tools\nCLion 2024.2 introduced Zephyr West support for creating and building Zephyr RTOS-based projects. We are gathering your feedback and continuing to improve Zephyr West support accordingly. One of the major features we plan to add in v2024.3 is the ability to run the native west debug command to make debugging more convenient (CPP-39392).\nWe would appreciate your participation in our user interviews, designed to help us improve Zephyr West support in CLion. You will be rewarded for your time and meaningful feedback.\nThere is also a lot of work related to Bazel support. One of the key features we plan to add is basic support for the MSVC compiler for Windows users.\nDebugger\nWe are working on a new debugger feature that will make it easier to develop OpenCV-based applications and will be helpful in computer vision, machine learning, and game development (CPP-3659). This feature allows you to view bitmap image data temporarily stored in memory while the program is running. It provides a watch window for viewing bitmaps during debugging. The first version of this feature will support OpenCV image types like cv::Mat.\nCall for feedback\nYour feedback is important to us, as your experiences and insights are essential to our mission to continuously improve CLion. Please share your ideas in the comments section below or submit them to our issue tracker. \nThe free Early Access Program is just around the corner. In the meantime, upgrade to CLion 2024.2 if you haven’t already done so, and let us know what you think.\nDOWNLOAD CLION 2024.2\nYour CLion team\nJetBrains\nThe Drive to Develop",
        "dc:creator": "Oleg Zinovyev",
        "content": "The second major release of CLion this year, 2024.2, introduced many improvements and advanced features. These include full line code completion for С++ that runs locally, Zephyr West support, and updates to the new CLion Nova language engine. If you still haven’t tried CLion 2024.2, download and try it today. DOWNLOAD CLION 2024.2 We’ve begun [&#8230;]",
        "contentSnippet": "The second major release of CLion this year, 2024.2, introduced many improvements and advanced features. These include full line code completion for С++ that runs locally, Zephyr West support, and updates to the new CLion Nova language engine. If you still haven’t tried CLion 2024.2, download and try it today. DOWNLOAD CLION 2024.2 We’ve begun […]",
        "guid": "https://blog.jetbrains.com/?post_type=clion&p=509003",
        "categories": [
          "news",
          "roadmap",
          "2024-3",
          "clionnova",
          "debugger",
          "embedded",
          "zephyr-west"
        ],
        "isoDate": "2024-09-11T07:11:41.000Z"
      },
      {
        "creator": "Stanislav Garkusha",
        "title": "How to Use Jupyter Notebooks in PyCharm",
        "link": "https://blog.jetbrains.com/pycharm/2024/09/how-to-use-jupyter-notebooks-in-pycharm/",
        "pubDate": "Mon, 09 Sep 2024 13:45:37 +0000",
        "content:encodedSnippet": "PyCharm is one of the most well-known data science tools, offering excellent out-of-the-box support for Python, SQL, and other languages. PyCharm also provides integrations for Databricks, Hugging Face and many other important tools. All these features allow you to write good code and work with your data and projects faster. \nPyCharm Professional’s support for Jupyter notebooks combines the interactive nature of Jupyter notebooks with PyCharm’s superior code quality and data-related features. This blog post will explore how PyCharm’s Jupyter support can significantly boost your productivity.\n\n\n\n\nWatch this video to get a comprehensive overview of using Jupyter notebooks in PyCharm and learn how you can speed up your data workflows. \n\n\n\n\n\n\nSpeed up data analysis\nGet acquainted with your data\nWhen you start working on your project, it is extremely important to understand what data you have, including information about the size of your dataset, any problems with it, and its  patterns. For this purpose, your pandas and Polars DataFrames can be rendered in Jupyter outputs in Excel-like tables. The tables are fully interactive, so you can easily sort one or multiple columns and browse and view your data, you can choose how many rows will be shown in a table and perform many other operations.\n\n\n\n\nThe table also provides some important information for example:\nYou can find the the size of a table in its header. \n\n\n\n\n\n You can find the data type symbols in the column headers.\n\n\n\n\n\nYou can also use JetBrains AI Assistant to get information about your DataFrame by clicking on the  icon.\n\n\n\n\nEasily spot issues with the data\nAfter getting acquainted with your data, you need to clean it. This an important step, but it is also extremely time consuming because there are all sorts of problems you could find, including missing values, outliers, inconsistencies in data types, and so on. Indeed, according to the State of Developer Ecosystem 2023 report, nearly 50% of Data Professionals dedicate 30% of their time or more to data preparation. Fortunately, PyCharm offers a variety of features that streamline the data-cleaning process.\nSome insights are already available in the column headers. \nFirst, we can easily spot the amount of missing data for each column because it is highlighted in red. Also, we may be able to see at a glance whether some of our columns have outliers. For example, in the bath column, the maximum value is significantly higher than the ninety-fifth percentile. Therefore, we can expect that this column has at least one outlier and requires our attention.\n\n\n\n\nAdditionally, you might suspect there’s an issue with the data if the data type does not match the expected one. For example, the header of the total_sqft column below is marked with the  symbol, which in PyCharm indicates that the column contains the Object data type. The most appropriate data type for a column like total_sqft would likely be float or integer, however, so we may expect there to be inconsistencies in the data types within the column, which could affect data processing and analysis. After sorting, we notice one possible reason for the discrepancy: the use of text in data and ranges instead of numerical values.\n\n\n\n\nSo, our suspicion that the column had data-type inconsistencies was proven correct. As this example shows, small details in the table header can provide important information about your data and alert you to issues that need to be addressed, so it’s always worth checking.You can also use no-code visualizations to gather information about whether your data needs to be cleaned. Simply click on the  icon in the top-left corner of the table. There are many available visualization options, including histograms, that can be used to see where the peaks of the distribution are, whether the distribution is skewed or symmetrical, and whether there are any outliers.\n\n\n\n\nOf course, you can use code to gather information about your dataset and fix any problems you’ve identified. However, the mentioned low-code features often provide valuable insights about your data and can help you work with it much faster.\nCode faster \nCode completion and quick documentation\nA significant portion of a data professional’s job involves writing code. Fortunately, PyCharm is well known for its features that allow you to write code significantly faster. For example, local ML-powered full line code completion can provide suggestions for entire lines of code.\n\n\n\n\nAnother useful feature is quick documentation, which appears when you hover the cursor over your code. This allows you to gather information about functions and other code elements without having to leave the IDE.\n\n\n\n\nRefactorings\nOf course, working with code and data is an interactive process, and you may often decide to make some changes in your code – for example, to rename a variable. Going through the whole file or, in some cases, the entire project, would be cumbersome and time consuming. We can use PyCharm’s refactoring capabilities to rename a variable, introduce a constant, and make many other changes in your code. For example, in this case, I want to rename the DataFrame to make it shorter. I simply use the the Rename refactoring to make the necessary changes.\n\n\n\n\nPyCharm offers a vast number of different refactoring options. To dive deeper into this functionality, watch this video.\nFix problems\nIt is practically impossible to write code without there being any mistakes or typos. PyCharm has a vast array of features that allow you to spot and address issues faster. You will notice the Inspection widget in the top-right corner if it finds any problems.  \n\nFor example, I forgot to import a library in my project and made several typos in the doc so let’s take a look how PyCharm can help here. \nFirst of all, the problem with the library import:\n\n\n\n\nAdditionally, with Jupyter traceback, you can see the line where the error occurred and get a link to the code. This makes the bug-fixing process much easier. Here, I have a typo in line 3. I can easily navigate to it by clicking on the blue text.\n\n\n\n\nAdditionally if you would like to get more information and suggestion how to fix the problem, you can use JetBrains AI Assistant by clicking on Explain with AI. \n\n\n\n\nOf course, that is just the tip of the iceberg. We recommend reading the documentation to better understand all the features PyCharm offers to help you maintain code quality.\nNavigate easily\nFor the majority of cases, data science work involves a lot of experimentation, with the journey from start to finish rarely resembling a straight line.\nDuring this experimentation process, you have to go back and forth between different parts of your project and between cells in order to find the best solution for a given problem. Therefore, it is essential for you to be able to navigate smoothly through your project and files. Let’s take a look at how PyCharm can help in this respect.\nFirst of all, you can use the classic CMD+F (Mac) or CTRL+F (Windows) shortcut for searching in your notebook. This basic search functionality offers some additional filters like Match Case or Regex.\n\n\n\n\nYou can use Markdown cells to structure the document and navigate it easily.\n\n\n\n\nIf you would like to highlight some cells so you can come back to them later, you can mark them with #TODO or #FIXME, and they will be made available for you to dissect in a dedicated window.\n\n\n\n\nOr you can use tags to highlight some cells so you’ll be able to spot them more easily.\n\n\n\n\nIn some cases, you may need to see the most recently executed cell; in this case, you can simply use the Go To option. \n\n\n\n\nSave your work\nBecause teamwork is essential for data professionals, you need tooling that makes sharing the results of your work easy. One popular solution is Git, which PyCharm supports with features like notebook versioning and version comparison using the Diff view. You can find an in-depth overview of the functionality in this tutorial.\nAnother useful feature is Local History, which automatically saves your progress and allows you to revert to previous steps with just a few clicks.\n\n\n\n\nUse the full power of AI Assistant\nJetBrains AI Assistant helps you automate repetitive tasks, optimize your code, and enhance your productivity. In Jupyter notebooks, it also offers several unique features in addition to those that are available in any JetBrains tool. \nClick the  icon to get insights regarding your data. You can also ask additional questions regarding the dataset or ask AI Assistant to do something – for example, “write some code that solves the missing data problem”.\n\n\n\n\nAI data visualization\nPressing the icon  will suggest some useful visualizations for your data. AI Assistant will generate the proper code in the chat section for your data.\n\n\n\n\nAI cell\nAI Assistant can create a cell based on a prompt. You can simply ask it to create a visualization or do something else with your code or data, and it will generate the code that you requested. \n\n\n\n\nDebugger\nPyCharm offers advanced debugging capabilities to enhance your experience in Jupyter notebooks. The integrated Jupyter debugger allows you to set breakpoints, inspect variables, and evaluate expressions directly within your notebooks. This powerful tool helps you step through your code cell by cell, making it easier to identify and fix issues as they arise. Read our blog post on how you can debug a Jupyter notebook in PyCharm for a real-life example.\n\n\n\n\nGet started with PyCharm Professional\nPyCharm’s Jupyter support enhances your data science workflows by combining the interactive aspects of Jupyter notebooks with advanced IDE features. It accelerates data analysis with interactive tables and AI assistance, improves coding efficiency with code completion and refactoring, and simplifies error detection and navigation. PyCharm’s seamless Git integration and powerful debugging tools further boost productivity, making it essential for data professionals.\nDownload PyCharm Professional to try it out for yourself! Get an extended trial today and experience the difference PyCharm Professional can make in your data science endeavors.Use the promo code “PyCharmNotebooks” at checkout to activate your free 60-day subscription to PyCharm Professional. The free subscription is available for individual users only.\nActivate your 60-day trial\n                                                    \nExplore our official documentation to fully unlock PyCharm’s potential for your projects.",
        "dc:creator": "Stanislav Garkusha",
        "content": "PyCharm is one of the most well-known data science tools, offering excellent out-of-the-box support for Python, SQL, and other languages. PyCharm also provides integrations for Databricks, Hugging Face and many other important tools. All these features allow you to write good code and work with your data and projects faster.&#160; PyCharm Professional’s support for Jupyter [&#8230;]",
        "contentSnippet": "PyCharm is one of the most well-known data science tools, offering excellent out-of-the-box support for Python, SQL, and other languages. PyCharm also provides integrations for Databricks, Hugging Face and many other important tools. All these features allow you to write good code and work with your data and projects faster.  PyCharm Professional’s support for Jupyter […]",
        "guid": "https://blog.jetbrains.com/?post_type=pycharm&p=508361",
        "categories": [
          "data-science",
          "how-tos",
          "jupyter",
          "jupyter-notebooks"
        ],
        "isoDate": "2024-09-09T13:45:37.000Z"
      },
      {
        "creator": "Sergey Kozlovskiy",
        "title": "Celebrate Tester’s Day With JetBrains Aqua – 50% OFF!",
        "link": "https://blog.jetbrains.com/qa/2024/09/celebrate-tester-s-day-with-jetbrains-aqua-50-off/",
        "pubDate": "Mon, 09 Sep 2024 11:00:58 +0000",
        "content:encodedSnippet": "JetBrains Aqua is proud to join the global tech community in celebrating International Tester’s Day on September 9. This day recognizes the crucial contributions of QA professionals, who ensure that the software we rely on functions flawlessly and delivers a superior user experience.\n      \n        Buy Aqua – 50% OFF\n    \n\n\n\n\nWhy testers are our everyday heroes\nIn today’s fast-paced, ever-evolving software industry, quality is not just an option – it’s a necessity. Testers are quality gatekeepers, often working behind the scenes to detect bugs and find vulnerabilities. Testers ensure our products are reliable, secure, and ready for the real world. Their attention to detail and dedication to finding issues before they reach users make them a crucial part of every development team.\nHow JetBrains Aqua empowers testers\nAqua is the first IDE created specifically for test automation. Aqua supports Selenium, Cypress, and Playwright. It’s a polyglot IDE that understands Java, Python, JavaScript, TypeScript, Kotlin, and SQL. With Aqua, you can get straight to testing without having to install and configure lots of plugins.\nYour work deserves the best tools, and Aqua is designed to help you perform your job more efficiently and maintain high-quality standards.\nA special thank you\nIn honor of International Tester’s Day, we’re offering a 50% discount on JetBrains Aqua commercial subscriptions. This is the perfect opportunity to equip yourself with a tool designed to elevate your testing game.\nClaim your discount and take your test automation to the next level. This offer is available from September 9 until October 9, so don’t miss out!\nCelebrate with us!\nLet’s use this day to celebrate the testing profession and acknowledge its continuous dedication to quality. Share your favorite testing moments, tips, and bug-finding stories with the community using the hashtag #TestersDay. And don’t forget to tag us @JetBrainsAqua so we can celebrate together!\nThank you for making software better and more reliable every day. We’re excited to support you on your journey! Happy Tester’s Day! 🎉\nYour JetBrains Aqua team",
        "dc:creator": "Sergey Kozlovskiy",
        "content": "JetBrains Aqua is proud to join the global tech community in celebrating International Tester’s Day on September 9. This day recognizes the crucial contributions of QA professionals, who ensure that the software we rely on functions flawlessly and delivers a superior user experience. Buy Aqua – 50% OFF Why testers are our everyday heroes In [&#8230;]",
        "contentSnippet": "JetBrains Aqua is proud to join the global tech community in celebrating International Tester’s Day on September 9. This day recognizes the crucial contributions of QA professionals, who ensure that the software we rely on functions flawlessly and delivers a superior user experience. Buy Aqua – 50% OFF Why testers are our everyday heroes In […]",
        "guid": "https://blog.jetbrains.com/?post_type=qa&p=508140",
        "isoDate": "2024-09-09T11:00:58.000Z"
      },
      {
        "creator": "Daniela Bentrup",
        "title": "Fleet 1.40 Is Here With Compose Preview for Android, Inlay Hints for Generating Documentation for PHP and Groovy, and Other Improvements",
        "link": "https://blog.jetbrains.com/fleet/2024/09/fleet-1-40-is-here-with-compose-preview-for-android-inlay-hints-for-generating-documentation-for-php-and-groovy-and-other-improvements/",
        "pubDate": "Mon, 09 Sep 2024 07:38:22 +0000",
        "content:encodedSnippet": "Fleet 1.40 is now available! In this release, we’ve introduced some new features while also focusing on many important bug fixes. Your feedback is vital to making Fleet even better. Please report any problems you encounter to our issue tracker, or add a vote to an existing issue to express your support.\nYou can update to this version using the Toolbox App. Let’s take a closer look at the highlights.\nDownload Fleet 1.40\nNew features\nFleet 1.40 introduces Compose Preview for Android. Since previewing an app’s UI in the IDE is one of the most critical scenarios for every mobile developer, this feature significantly improves the multiplatform development experience for Android developers. You can now leverage powerful preview customization tools from Android Studio in Android sources such as multi-preview, parameter providers, and annotation options.\n\n\n\n\n\nBut there’s more! Along with previews for Android code, we’ve also added the option to render Android previews from common code. For projects with both Android and regular JVM targets, you can now choose which platform to render against (Android or Desktop).\nWe’ve added inlay hints for generating documentation for PHP and Groovy. Fleet already supported this feature for Java, Kotlin, and JavaScript. Just type /** and press Enter to bring up the Generate Documentation option, and then press ⌥↵ / Alt+Enter to show the tooltip.\nImprovements\nFleet 1.40 introduces a new shortcut for the Build & Refresh action when running Android Preview. ⌥⇧⌘R on macOS or Ctrl+Shift+F5 on Windows.\nThe Generate Code template is now hidden  when you are logged out.\nWhen you generate code with AI Assistant, the editor now scrolls along with the generated content.\n\n\n\nBug fixes\nWe’ve also fixed several bugs:\nUndoing the renaming of a file no longer deletes the file [FL-27850].\nSoft wraps now work correctly in the diff viewer [FL-19723].\nGradle run configurations are executed successfully, even when passing parameters with spaces [FL-28619].\nThe Git Push action is now available after you create a new branch with a new commit [FL-27285].\nUsing Page Up and Page Down quickly scrolls as expected [FL-23471].\nSee the full release notes for more details about Fleet 1.40.\nStay tuned for further exciting announcements.\nJoin the JetBrains Tech Insights Lab to participate in surveys, interviews, and UX studies, and help us make JetBrains Fleet better!",
        "dc:creator": "Daniela Bentrup",
        "content": "Fleet 1.40 is now available! In this release, we’ve introduced some new features while also focusing on many important bug fixes. Your feedback is vital to making Fleet even better. Please report any problems you encounter to our issue tracker, or add a vote to an existing issue to express your support. You can update [&#8230;]",
        "contentSnippet": "Fleet 1.40 is now available! In this release, we’ve introduced some new features while also focusing on many important bug fixes. Your feedback is vital to making Fleet even better. Please report any problems you encounter to our issue tracker, or add a vote to an existing issue to express your support. You can update […]",
        "guid": "https://blog.jetbrains.com/?post_type=fleet&p=507729",
        "categories": [
          "news",
          "releases"
        ],
        "isoDate": "2024-09-09T07:38:22.000Z"
      },
      {
        "creator": "Roman Pronskiy",
        "title": "PHP Annotated – September 2024",
        "link": "https://blog.jetbrains.com/phpstorm/2024/09/php-annotated-september-2024/",
        "pubDate": "Mon, 09 Sep 2024 03:57:21 +0000",
        "content:encodedSnippet": "Welcome to the September edition of PHP Annotated! After a brief summer break, we’re back with all things PHP. This recap is carefully handcrafted and brings you the most interesting developments in the PHP community over the past couple of months, so you don’t have to sift through the noise—we’ve done it for you.\n@media (min-width: 769px) { main .article-section .content ul:not([class]):not([id]) li ul:not([class]):not([id]) { margin-top: 0; margin-bottom: 24px; } } main .article-section .content ul:not([class]):not([id]) li, main .article-section .content ul:not([class]):not([id]) > li {padding-bottom: 18px;}  main .article-section .content ul:not([class]):not([id]) li ul:not([class]):not([id]) li {padding-bottom: 0;} img.alignico {margin-right: 10px;margin-top: 5px;float: left;}  summary {display: list-item;cursor: pointer;font-style: italic; } section.article-section a {color: #7755f3} code {color: red;} #roman-pronskiy,.copy-heading:has(#roman-pronskiy){margin-top: 0;} main li a[href^=\"https://github.com\"]:before {background: no-repeat 2px center url(data:image/svg+xml;utf8;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNCIgaGVpZ2h0PSIxNCIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDMyIDMyIj48cGF0aCBmaWxsPSIjMjQyOTJFIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0xNiAwYTE2IDE2IDAgMCAwLTUgMzEuMmMuNy4xIDEtLjQgMS0uOHYtM2MtNCAuOC01LTEtNS40LTEuOC0uMS0uNS0xLTItMS42LTIuMy0uNi0uMy0xLjQtMSAwLTEgMS4yIDAgMi4xIDEuMSAyLjQgMS42IDEuNSAyLjQgMy44IDEuNyA0LjcgMS4zLjEtMSAuNi0xLjcgMS0yLjEtMy41LS40LTcuMy0xLjgtNy4zLTggMC0xLjcuNy0zLjEgMS43LTQuMi0uMi0uNC0uNy0yIC4xLTQuMyAwIDAgMS40LS40IDQuNCAxLjdhMTQuOCAxNC44IDAgMCAxIDggMGMzLjEtMi4xIDQuNC0xLjcgNC40LTEuNyAxIDIuMi40IDMuOS4yIDQuM2E2IDYgMCAwIDEgMS42IDQuM2MwIDYuMS0zLjcgNy41LTcuMyA3LjkuNi41IDEuMSAxLjQgMS4xIDN2NC4zYzAgLjQuMyAxIDEuMS44QTE2IDE2IDAgMCAwIDE2IDBaIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiLz48L3N2Zz4=);content: \"\";padding-left: 20px;} main li a[href^=\"https://www.youtube.com\"]:before {background: no-repeat 0px center url(\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' height='100%25' version='1.1' viewBox='0 0 68 48' width='100%25'%3E%3Cpath class='ytp-large-play-button-bg' d='m .66,37.62 c 0,0 .66,4.70 2.70,6.77 2.58,2.71 5.98,2.63 7.49,2.91 5.43,.52 23.10,.68 23.12,.68 .00,-1.3e-5 14.29,-0.02 23.81,-0.71 1.32,-0.15 4.22,-0.17 6.81,-2.89 2.03,-2.07 2.70,-6.77 2.70,-6.77 0,0 .67,-5.52 .67,-11.04 l 0,-5.17 c 0,-5.52 -0.67,-11.04 -0.67,-11.04 0,0 -0.66,-4.70 -2.70,-6.77 C 62.03,.86 59.13,.84 57.80,.69 48.28,0 34.00,0 34.00,0 33.97,0 19.69,0 10.18,.69 8.85,.84 5.95,.86 3.36,3.58 1.32,5.65 .66,10.35 .66,10.35 c 0,0 -0.55,4.50 -0.66,9.45 l 0,8.36 c .10,4.94 .66,9.45 .66,9.45 z' fill='%23FF0000' fill-opacity='0.81'%3E%3C/path%3E%3Cpath d='m 26.96,13.67 18.37,9.62 -18.37,9.55 -0.00,-19.17 z' fill='%23fff'%3E%3C/path%3E%3Cpath d='M 45.02,23.46 45.32,23.28 26.96,13.67 43.32,24.34 45.02,23.46 z' fill='%23ccc'%3E%3C/path%3E%3C/svg%3E\"); content: \"\";padding-left: 18px;background-size: 16px;}\nHighlights\nLaravel raises a $57 million Series A from Accel\nRight after the Laracon US, Taylor Otwell posted a tweet announcing a $57M investment from Accel, a renowned venture capital firm.\nCongratulations to Taylor and the team!\nCheck out this video interview to learn more:\n\n        \nPHP 8.4.0 Beta 4 is available for testing\nUpdates for PHP 8.4 are released every two weeks, following the timeline. The final release is expected on November 21.\nThe feature freeze took effect on August 13, meaning the set of new features is now locked in, and any major changes will be postponed to the next PHP version.\nSome of the most notable changes in PHP 8.4 include:\nProperty hooks\nAsymmetric Visibility\nnew MyClass()->method() without parentheses\nLazy Objects\nNew HTML5 Support\nNew functions for working with arrays: array_find(), array_find_key(), array_any(), and array_all().\nFor a detailed list of what’s coming in PHP 8.4 see php.watch, stitcher.io, or Ash Allen posts.\n        Try PHP 8.4:\nOn Mac, you can install it using Homebrew through the Nightly channel via shivammathur/homebrew-php.\nFor other platforms, Docker images are probably the easiest way to try it out with no hassle.\nFor a quick local test, PHP 8.4 is also available on Herd.\nState of Generics and Collections 💜\nArnaud Le Blanc, Derick Rethans, and Larry Garfield have published a comprehensive research article on the current state of generics in PHP. The article covers all possible implementations with the pros and cons of each.\nYou can join the ongoing discussion on the mailing list and Reddit.\nIn the meantime, you can start leveraging of generics with PHPDoc blocks.\nShutting down Packagist.org support for Composer 1.x\n        With over 95% of Composer updates now using v2, Composer v1 will be officially shut down on August 1, 2025.\n    \nPhpStorm 2024.2 is out\n        Highlights include: \nLog files support\nCompletion in the new terminal\nEditing from a floating toolbar\nPER Coding Style\nNew UI Becomes the Default\nFundraiser by Joe Watkins : A big ask from a big community\nJoe Watkins (@krakjoe), a pillar of the PHP community, needs help. Joe is one of the creators of The PHP Foundation and author of several PHP tools you’ve likely used in your work, including pcov, phpthreads, and parallel.\nAfter battling severe health issues, he’s facing homelessness & loss of life-saving meds. Please donate if you can and help reshare ❤️‍🩹\n\"PHP is beautiful and powerful\"\n        \n    \nPHP Core\n✅ RFC: Asymmetric Visibility v2 💜\n        Thanks to Ilija Tovilo’s and Larry Garfield’s proposal, PHP 8.4 will have asymmetric visibility, i.e. possibility to make properties public for reading (get) and private for changing (set). The syntax was inspired by Swift.\n    \n✅ RFC: Lazy Objects 💜\n        Lazy objects are standard objects except that their initialization is deferred until one of their properties is accessed (including non-existing ones). This can be useful\nVery likely, the lazy objects won’t be used directly by most PHP users, but package and framework authors will benefit from it a lot as it allows them to remove a lot of boilerplate code. Here is for example how symfony/var-exporter will be simplified:\n        \n    \n✅ RFC: Transform exit() from a language construct into a standard function 💜\nGina Peter Banyard proposed to make exit() a proper function with the following signature: function exit(string|int $status = 0): never {}\nThe benefit is that it will properly validate the arguments passed and throw a TypeError if you pass something irrelevant, such as an array or resource.\n📣 RFC: Improve language coherence for the behaviour of offsets and containers 💜\nPHP supports offset accesses using brackets [] with the following notation $container[$offset]. However, the behavior of such accesses depends not only on the container type and offset, but also on the operation that is performed when accessing the offset. The existing behavior is highly inconsistent and difficult to predict.\nGina Peter Banyard proposes to improve language consistency for offsets and containers.\n📣 RFC: Function Autoloading v4\n        Robert Landers proposes to add the ability to autoload functions by adding a 4th parameter to spl_autoload_register(…). Then with a simple PSR-4-like autoloader for functions, the code example could look like this:\nspl_autoload_register(function ($function_name) {...}, false, false, SPL_AUTOLOAD_FUNCTION);   \n\nThere is an alternative more comprehensive proposal from Gina P. Banyard: RFC: New core autoloading mechanism with support for function autoloading.\n📣 RFC: Default expression\n        Paul Morris proposes to introduce the default expression in argument-passing contexts to use the default value of the function or method.\nfunction greetingEveryone($greeting = 'Hello', $subject = 'World') {  \n    return sprintf('%s, %s!', $greeting, $subject);  \n}  \n\necho greetingEveryone(default, ‘Earth’)); // Hello, Earth!  \n\n        A similar proposal has been declined in the past, and it seems the problem has already been solved with the named arguments\n    \nTools\narokettu/composer-license-manager – The plugin for Composer that allows specifying license policies, e.g. list of allowed licenses for a project and avoid proprietary packages, packages with non-permissive licenses such as GPL, or no license at all. 🔗\n    \nphp-tui/php-tui – A framework for creating console applications in PHP with pseudo graphical UI. terminal user interfaces (TUIs)\ncomposer/pcre – PCRE wrapping library that offers type-safe preg_* replacements.\n    \nclementtalleu/php-redis-om – A PHP object mapper for Redis. Check out the intro article for more details.\n    \nSammyjo20/ssh-php – The ridiculously simple starting point for building PHP SSH apps.\n    \nServBay – A local dev environment, alternative to Laravel Herd.\n    \nHiEventsDev/Hi.Events – Open-source event management and ticket selling platform.\n    \nfreescout-help-desk/freescout – Free self-hosted help desk & shared mailbox (Zendesk / Help Scout alternative).\n    \nsavinmikhail/Comments-Density – Analyze the comment density and quality in PHP files to maintain and improve code documentation quality.\n    \nprasathmani/tinyfilemanager – Single-file PHP file manager, browser and manage your files efficiently and easily with tinyfilemanager.\n    \nTicketSwap/phpstan-error-formatter – A minimalistic error formatter for PHPStan.\n    \n\n    \nAI\nTransformersPHP\nIt’s a PHP package that lets you run pretrained models from HuggingFace directly in PHP – no API, no extra server required.\nThe package is designed to be functionally equivalent to the popular Python Transformers library. So it’s easy to start using if you’re familiar with ML.\nHere are some use-cases:\nBuilding a Background Removal Tool with Laravel and TransformersPHP.\nHow to translate content programmatically using AI and TransformersPHP.\nHow to auto-generate the image Alt-Text using AI and Transformers PHP.\nMachine Learning with PHP.\nUnder the hood, it uses ONNX Runtime and Math libray Rindow via FFI. And the cool part is that it handles everything for you, even downloading all the libs according to your OS with a small Composer plugin: CodeWithKyrian/transformers-libsloader.\nllm-agents-php/agents – LLM Agents abstraction.\nThis package is a framework for creating, managing, and deploying AI agents within PHP environments. The library aims to simplify using Retrieval-Augmented Generation (RAG) techniques into PHP projects.\nCheck out a sample-app and a video showcase: Building a Blog with LLM Agents.\nSymfony\nFunctional Tests with Symfony and Webhook component by Pierre Emmanuel Capel.\nBundling Your Symfony UX Twig Components by Yonel Ceruto.\nzenstruck/console-extra – A modular set of features to reduce configuration boilerplate for your Symfony commands.\nSymfony 7.1 curated new features\nLaravel\nLaracon US 2024\nLast week, the flagship Laravel conference happened in Dallas, TX. Some big announcements were made, including:\nLaravel Cloud\nPest 3\nInvertia.js v2\nLaravel VS Code extension\nA few cool features for Laravel 11\nThe State of Laravel Survey 2024\nThe results of the annual survey are now published and have some interesting insights.\nCheck Brent’s overview of the results on YouTube.\nBuilt with Laravel – Nice inspo catalog.\nLaravel Config Problem: Is It Time for a Revolution?.\nLearn to master Query Scopes in Laravel by Ashley Allen.\nHow to test all routes in your Laravel app by writing just a single Pest test by Freek Van der Herten.\nAdding real-time chat in 14 lines of code with Laravel Reverb and Livewire by Simon Hamp.\nBuilding Desktop Applications using Native PHP with Simon Hamp by Laravel News.\nI challenged myself to run Laravel with rryqszq4/ngx-php, and ended up benchmarking other runtimes along the way:\n        \n    \nOther Frameworks\nPhalcon + Swoole in High Load Micro Service – A case study on using Swoole to turn PHP into a high-performance powerhouse!\nUsing Laminas Continuous Integration by Julian Somesan.\nCurrent Maintenance Status of Laminas & Mezzio Packages by Julian Somesan.\nMisc\nSlowly introducing static analysis without changing everything by Joel Clermont.\nArray Shapes For Preg Match Matches by Markus Staab.\nContainer Efficiency in Modular Monoliths: Symfony vs. Laravel by Kamil Ruczyński.\nTo double quote or not, that’s the question! by Florian Engelhardt.\nScope and Downgrade your PHP Tools for Everyone to Use by Tomas Votruba.\nThe #[\\Override] Attribute in PHP by Ashley Allen.\nStore Code Discussions in Git using Git Notes by Wouter de Jong – This is how Symfony stores GitHub Discussions in Git.\nChoosing a PHP Library based on Performance by Benjamin Eberlei.\nHow to use PHP-VCR to record and replay API calls in PHP – by Imen Ezzine.\nInheritance in modern programming languages is different… by Brent.\nHow to build a game engine in a CMS, in PHP by Jack Wilkinson.\nHow Craft CMS built Craft Cloud – A case study from Bref, the serverless PHP tool.\nConferences\nThese PHP events are all worth a visit, and some are still accepting presentation proposals:\nAPI Platfrom Conference – Lille, France, September 19-20.\nCascadiaPHP 2024 – Portland, OR, USA, October 24-26.\nPHPCon Poland 2024 – Wisła, Poland, October 25–26.\nLaracon AU – Brisbane, Australia, November 7–8.\nInternational PHP Conference – Munich, Germany, November 11‒15.\nSymfonyCon 2024 – Vienna, Austria, December 5–6.\nLaracon EU 2025 – Amsterdam, The Netherlands, February 3-4. CFP 🆕\nPHP UK Conference 2025 – London, UK, February 19. CFP 🆕\nphp[tek] 2025 – Chicago, IL, USA, May 20-22. CFP 🆕\nTo find a PHP meetup happening near you, check out the calendar on php.net.\nFun\nJavaScript Bloat in 2024 by Niki Tonsky – “Gitlab needs 13 MB of JS code just to display a static landing page.”\n\n\n    \nIf you have any interesting or useful links to share via PHP Annotated, please leave a comment on this post or let us know on X/Twitter.\nSubscribe to PHP Annotated\nRoman Pronskiy\nDeveloper Advocate at @PhpStorm, Operations Manager at @The PHP Foundation.\nTwitter | GitHub",
        "dc:creator": "Roman Pronskiy",
        "content": "Welcome to the September edition of PHP Annotated! After a brief summer break, we’re back with all things PHP. This recap is carefully handcrafted and brings you the most interesting developments in the PHP community over the past couple of months, so you don’t have to sift through the noise—we’ve done it for you. Highlights [&#8230;]",
        "contentSnippet": "Welcome to the September edition of PHP Annotated! After a brief summer break, we’re back with all things PHP. This recap is carefully handcrafted and brings you the most interesting developments in the PHP community over the past couple of months, so you don’t have to sift through the noise—we’ve done it for you. Highlights […]",
        "guid": "https://blog.jetbrains.com/?post_type=phpstorm&p=508283",
        "categories": [
          "news",
          "laravel",
          "php",
          "php-8-3",
          "php-8-4",
          "php-annotated-monthly",
          "rfc",
          "symfony"
        ],
        "isoDate": "2024-09-09T03:57:21.000Z"
      },
      {
        "creator": "Irina Mariasova",
        "title": "Top 12 Podcasts for Java Developers in 2024",
        "link": "https://blog.jetbrains.com/idea/2024/09/top-12-podcasts-for-java-developers-in-2024/",
        "pubDate": "Fri, 06 Sep 2024 08:03:29 +0000",
        "content:encodedSnippet": "In 2024, learning new things as a Java developer has never been easier or more fun! How about kicking off your morning with a cup of coffee while some of the biggest names in the industry chat directly into your ear? Or, imagine being stuck in traffic on your way to work, but instead of just waiting, you’re getting inspired by great stories from fellow developers – all thanks to podcasts!\nWe’ve teamed up with our in-house Java advocates and developers to bring you a list of the most helpful, inspiring, and engaging podcasts that cover everything Java. Whether you’re looking to learn new tricks, share a laugh with fellow devs, or just stay updated, these podcasts have something for you. Plus, we’ve even included recommendations on the best episodes to start with. Let’s go!\nDuke’s Corner Podcast\n\n\n\n\nHost: Jim Grisanzio, Oracle. \nTopics: This podcast dives deep into the Java ecosystem, covering everything from the latest updates and best practices to real-world use cases and developer experiences. Duke’s Corner features interviews with leading Java experts, discussions on new releases, and tips for unlocking Java’s full potential.\nFormat: Episodes are 25–45 minutes long, released regularly about once a month.\nEpisode to start with: Marit van Dijk: The Java Community is Awesome!\nIn this episode, Marit van Dijk, a Java Champion and Developer Advocate at JetBrains, talks about how she blends social science with coding and why the Java community is so powerful. It’s one of the most popular episodes, giving you a lively insider’s view of what unites Java developers and why this community is so special.\nInteresting Fact: Duke’s Corner takes its name from Duke, the iconic Java mascot. Imagine Duke in the corner at a conference or café, conducting interviews – like in a special, unique club.\nThe podcast focuses on the Java community. Jim discusses Java, but always with an emphasis on the people involved. Each episode features a guest and rounds out their profile, highlighting their contributions and personal journey.\nUltimately, the podcast helps you learn Java while empowering you to make a positive impact in the world. Without the community, there would be no Java.\nHave you tuned in to Duke’s Corner yet? What’s your favorite episode?\nA Bootiful Podcast \n\n\n\n\nHost: Josh Long, the Spring Developer Advocate at VMware.\nTopics: This podcast covers a wide range of topics related to Spring, Java, and software development in general. Each episode features interviews with industry experts, thought leaders, and fellow developers who share their experiences, tips, and tricks. \nWhat’s your favorite Spring feature that you’ve learned about from this podcast?\nFormat: Episodes are 30–60 minutes long, released generally once a week.\nEpisode to Start With: Tagir Valeev, Fellow Java Champion and IntelliJ IDEA Java Legend\nJosh Long chats with Tagir Valeev, a Java Champion and the mastermind behind many of IntelliJ IDEA’s coolest features. They dive into the world of Java, sharing tips, tricks, and even a few developer jokes along the way. \nInteresting Fact: Josh Long’s enthusiasm and deep knowledge of the Spring framework have made this podcast one of the most popular in the field. What began as a simple way for Josh to share his passion for Java, Spring, and cloud computing with developers has now evolved into a hub for deep technical discussions, engaging personal stories, and industry trends.\nFoojay Podcast \n\n\n\n\nHost: Mainly hosted by Frank Delporte.\nTopics: The Foojay Podcast explores everything from deep technical topics to broader industry trends, offering something for Java developers at all levels.\nFormat: Episodes are 30–60 minutes long, released every couple of weeks.\nEpisode to Start With: Artificial Intelligence and Machine Learning with Java\nIn this episode, Frank Delporte hosts Lize Raes, an AI and data specialist with experience applying machine learning techniques within the Java ecosystem, and Lutske de Leeuw, a software engineer focused on bringing AI into enterprise Java solutions. They offer practical advice for developers looking to incorporate AI into their Java projects. \nHow do you personally integrate AI into your Java projects? Share in the comments below. \nInteresting Fact: This podcast is just part of a larger ecosystem; Foojay.io is a vibrant community where Java developers can also read articles and connect with others who share their passion for Java. \nThe Stack Overflow Podcast\n\n\n\n\nHost: Ryan Donovan, Ben Popper, and Eira May\nTopics: Discussing topics ranging from the latest languages to industry buzz, the hosts keep it lively with expert guests and unexpected tech tales. If you’re a developer who wants to stay sharp and entertained, this podcast is a must-listen.\nFormat: Episodes are 30–45 minutes long, released regularly but not strictly scheduled.\nEpisode to Start With: Unpacking the 2024 Developer Survey results\nThe hosts chat about the hottest trends, the challenges developers are up against, and what the future might have in store for tech pros. Packed with data and sprinkled with some fun banter, this episode is your go-to for staying in the know about the developer world. \nInteresting Fact: The Stack Overflow Podcast isn’t just about tech – it’s about the human side of coding. Whether they’re talking about imposter syndrome, developer burnout, or celebrating a big win, the hosts keep it real and relatable.\nJava Off-Heap\n\n\n\n\nHost: A group of passionate Java developers, including Freddy Guime, Bob Paulin, Michael Minella, and Josh Juneau. \nTopics: Java Off-Heap is the podcast for Java developers who want more than just tech updates. The hosts explore Java, JVM internals, and software architecture while also chatting about industry news with a touch of humor. It’s a fun and informative mix.\nFormat: Episodes are 45–60 minutes long, with no fixed release schedule. \nEpisode to Start With: Episode 85: The Economic Future of Open Source\nIn this episode, Freddy Guime, Bob Paulin, and Michael Minella talk about how economic trends are shaking up the open-source world and what this means for developers. It’s a fun, eye-opening chat that combines tech and economics!\nInteresting Fact: The hosts don’t just talk code – they also share their experiences, frustrations, and successes in the tech world.\nHappy Path Programming\n\n\n\n\nHosts: Bruce Eckel and James Ward.\nTopics: This podcast offers straightforward, no-frills conversations between Bruce and James, where they discuss what programming is and what it should be. They strip away the jargon to focus on the real, practical, and sometimes even philosophical aspects of coding. If you’re looking for honest, thoughtful discussions that cut to the heart of programming, this podcast delivers. \nFormat: Episodes are 30–60 minutes long, with no fixed release schedule. \nEpisode to Start With: Gathering Nerds and Java Gatherers with Venkat Subramaniam\nThis episode features a conversation with Venkat Subramaniam, a well-known figure in the Java community. He talks about his upcoming dev2next conference and the Stream Gatherers API (preview in JDK 22).\nInteresting Fact: The podcast doesn’t just cover technical topics – it also delves into the philosophical aspects of programming. Bruce and James often reflect on what it means to be a programmer, how to find joy in coding, and how to navigate the challenges of the tech industry.\nSpring Office Hours \n\n\n\n\nHosts: Dan Vega and DaShaun Carter.\nTopics: This podcast features the newest developments in the Spring ecosystem along with demos of exciting Spring-related projects. The hosts and guests also answer questions from the community.\nFormat: Episodes are 30–60 minutes long, depending on how much time it takes to answer questions during the live session, and they are released 3–4 times per month. \nEpisode to Start With: Spring Office Hours: Episode 48 – How to learn Spring\nIn this episode, the hosts talk to Ken Kousen, a Java Champion and teacher, to explore the best ways to get up to speed with the Spring Framework and related projects. \nInteresting Fact: What makes Spring Office Hours special is its interactive format. The hosts don’t just share their deep knowledge of Spring, they also engage directly with the audience, making it a great way to get your Spring-related questions answered in real time.\nairhacks.fm \n\n\n\n\nHost: Adam Bien, a seasoned Java Champion and consultant.\nTopics: This podcast cuts straight to the core of enterprise software, cloud technologies, and Java. What makes it stand out? It’s all about the real-world experience – no fluff, just actionable insights and expert advice.\nFormat: Episodes are 45–60 minutes long, released every few weeks. \nEpisode to Start With: The Long Road to Java and Kotlin\nIn this airhacks.fm episode, Adam Bien and Anton Arhipov talk about Anton’s fascinating tech journey, from programming ship simulations in Java to working on JRebel and his role at JetBrains. Along the way, they reminisce about destroying joysticks during intense gaming sessions and the evolution of development tools like NetBeans, Eclipse, and IntelliJ IDEA. If you enjoy hearing about the intersection of tech and some good old geek nostalgia, this episode is a must-listen!\nInteresting Fact: Adam Bien is not just a podcaster; he’s an active consultant and trainer who brings his real-world experience to the conversations on airhacks.fm. \nJava Pub House \n\n\n\n\nHost: Freddy Guime and Bob Paulin, passionate Java developers.\nTopics: This laid-back yet informative podcast is for Java developers who want to stay up to date. It covers everything from making Java safer with fewer null errors to boosting performance through benchmarking. The hosts explore new tech like GraalVM, break down real-world coding challenges, and discuss complex topics like reactive programming.\nFormat: Episodes are 30–45 minutes long with no strict release schedule, but new episodes generally come out every few weeks. \nEpisode to Start With: Episode 105. Neurons, AI, and LLMs\nThis episode explores the world of AI, with the hosts covering neural networks and vector databases while trying to find answers about why they’re crucial. The field is vast, fascinating, and here to stay. So tune in and familiarize yourself with this powerful tool shaping our future!\nInteresting Fact: The hosts and their guests are mostly active developers who bring their day-to-day experiences and challenges into the discussion. Just like a pub where friends can chat over drinks, the Java Pub House podcast gives developers a relaxed space to talk about technical topics, share their experiences, and learn from each other.\nCoding Blocks \n\n\n\n\nHosts: Michael Outlaw, Allen Underwood, and Joe Zack – professional developers with many years of experience in the industry. \nTopics: Coding Blocks covers various software development topics (not only Java-related) from core programming concepts, design patterns, algorithms, and software architecture to career advice for developers. \nEpisode to Start With: Intro to Apache Kafka\nThe hosts break down what Kafka is all about, covering key concepts like topics and partitions, but they keep it light with some fun along the way. The episode is focused on how Kafka can be used in various scenarios, the challenges of managing Kafka clusters, and why it has become a crucial tool in modern data architecture. \nFormat: Episodes are 60–90 minutes long, released every few weeks with no fixed schedule. \nInteresting Fact: Each episode comes with a brief summary, handy tips of the week, and a list of recommended resources. The content is presented in a concise format, making it easy to skim through and decide if you’d like to listen.\nCodeNewbie \n\n\n\n\nHost: Saron Yitbarek, a software developer and entrepreneur who used to work in marketing and communications but later transitioned into tech after teaching herself how to code.\nTopics: This podcast is part of the CodeNewbie community, which is dedicated to supporting people new to coding. Each episode features interviews with developers, engineers, and tech professionals who share their stories, challenges, and tips for success. The podcast is mostly about career advice, personal stories of career transitions, and insights into the tech industry. It’s a supportive and encouraging resource for anyone who’s learning to code or considering a career in tech.\nEpisode to Start With: The Journey from Sound Engineer to Software Engineer\nThis is the inspiring story of Alejandro Aspinwall, who is now a software developer at Amazon. He talks about how he used his old skills in a new way and made a successful leap into tech. If you’re curious about career changes or how different experiences can help in coding, give this one a listen.\nThere are so many inspiring stories here! What’s your favorite?\nFormat: Episodes are 30–45 minutes long, typically released every Monday. \nInteresting Fact: This podcast is part of a vast community that includes a forum, chats on X, and events all designed to help new coders connect, learn, and grow together. Saron Yitbarek’s friendly style makes every CodeNewbie episode feel like a relaxed chat with a buddy. She mixes tech tips with a supportive, comforting vibe.\nDeveloper Tea\n\n\n\n\nHost: Jonathan Cutrell, a seasoned developer and Director of Engineering at PBS.\nTopics: Get ready for quick, insightful episodes that cover a wide range of development topics as well as productivity hacks and personal growth. Jonathan’s goal is to provide developers with the tools and inspiration they need to navigate the challenges of the tech industry, all in the time it takes to enjoy a cup of tea.\nEpisode to Start With: Talking To Yourself for Better One-On-Ones\nIn this episode, Jonathan shares his thoughts on how to prepare for your next one-on-one. Do your homework – take a moment to reflect on what you want to say.\nFormat: Episodes are 10–20 minutes long, released multiple times a week.\nInteresting Fact: Jonathan Cutrell’s Developer Tea podcast mixes deep tech insights with practical advice and a bit of philosophy. This combo makes the show stand out by offering more than just coding tips. It gives listeners thoughtful advice on how to grow both as developers and as individuals.\nConclusion \nIn 2024, podcasts are more than just background noise – they’re a powerful tool for learning and growing as a Java developer. No matter whether you are searching for technical topics, want to be aware of the latest industry trends, or just enjoy engaging conversation, these podcasts have you covered. Tune in, explore the episodes we’ve highlighted, and don’t forget to share your favorites in the comments below. Happy listening!",
        "dc:creator": "Irina Mariasova",
        "content": "In 2024, learning new things as a Java developer has never been easier or more fun! How about kicking off your morning with a cup of coffee while some of the biggest names in the industry chat directly into your ear? Or, imagine being stuck in traffic on your way to work, but instead of [&#8230;]",
        "contentSnippet": "In 2024, learning new things as a Java developer has never been easier or more fun! How about kicking off your morning with a cup of coffee while some of the biggest names in the industry chat directly into your ear? Or, imagine being stuck in traffic on your way to work, but instead of […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=508043",
        "categories": [
          "podcast",
          "tutorials",
          "developers",
          "duke",
          "java",
          "java-podcasts",
          "podcasts",
          "spring"
        ],
        "isoDate": "2024-09-06T08:03:29.000Z"
      },
      {
        "creator": "Tatiana Parshutkina",
        "title": "Pricing and Licensing Changes in RustRover and the Rust Plugin",
        "link": "https://blog.jetbrains.com/rust/2024/09/05/pricing-and-licensing-changes-in-rustrover-and-the-rust-plugin/",
        "pubDate": "Thu, 05 Sep 2024 15:47:11 +0000",
        "content:encodedSnippet": "RustRover was initially released without support for web frontend technologies and databases. This decision was primarily based on EAP usage statistics and early research. It also allowed us to price RustRover more competitively.\nHowever, after the release, we received a large number of requests from our community asking us to support these technologies. Another piece of feedback we received was that the single subscription model (commercial), as opposed to our existing one for all our other products (for individual use and for organizations), made it difficult for many to choose the right subscription for their needs.\nIn response to this feedback, we’re making some changes as of v2024.2. In particular:\nSupport for web frontend and databases will now be included.\nWe’re reintroducing two commercial subscription options, for individual use and organizations, to align with our existing subscription for other products.\n\n\n\n\nThis means you will be able to choose from one of the following price models:\nRustRover Non-Commercial – Free\nRustRover Commercial For Individual Use – $69/year (New❗)\nRustRover Commercial For Organizations – $229/year\nGet RustRover\n                                                    \nWe’ve also revised the price of the Rust plugin for CLion, lowering it for both personal and organizational subscriptions:\nRust Plugin Commercial Subscription For Individual Use – USD 29/year\nRust Plugin Commercial Subscription For Organizations – USD 99/year\nHow does this affect you as a customer?\nOur Sales teams will contact you to properly reflect any changes in your subscription based on your usage of the commercial license. If you have any questions, they’ll be happy to answer them.\nWe want to thank our users and our community for their support. We understand that sometimes we may not get things quite right, but your feedback helps us correct the course. \nIn addition to the subscription changes, this release includes many technical improvements. Make sure you check them out!",
        "dc:creator": "Tatiana Parshutkina",
        "content": "RustRover was initially released without support for web frontend technologies and databases. This decision was primarily based on EAP usage statistics and early research. It also allowed us to price RustRover more competitively. However, after the release, we received a large number of requests from our community asking us to support these technologies. Another piece [&#8230;]",
        "contentSnippet": "RustRover was initially released without support for web frontend technologies and databases. This decision was primarily based on EAP usage statistics and early research. It also allowed us to price RustRover more competitively. However, after the release, we received a large number of requests from our community asking us to support these technologies. Another piece […]",
        "guid": "https://blog.jetbrains.com/?post_type=rust&p=507617",
        "categories": [
          "news",
          "rustrover"
        ],
        "isoDate": "2024-09-05T15:47:11.000Z"
      },
      {
        "creator": "Tania Goral",
        "title": "Laravel Trends 2024: The Latest Market Insights",
        "link": "https://blog.jetbrains.com/phpstorm/2024/09/laravel-trends-2024-the-latest-market-insights/",
        "pubDate": "Thu, 05 Sep 2024 14:16:13 +0000",
        "content:encodedSnippet": "As we move through 2024, Laravel continues to solidify its position as one of the most popular PHP frameworks, powering a multitude of web applications across the globe. In this blog post, we’ll analyze the recently published State of Laravel 2024 survey results, highlighting key takeaways and what they mean for developers, companies, and the broader PHP community. \nThis year’s survey saw participation from 4,090 respondents across all continents (excluding Antarctica), with the majority hailing from Europe and Asia (49.8% and 20.15%, respectively). Notably, most respondents are experienced developers with 10–20 years of overall experience and 5–10 years of experience with Laravel.\n\n\n\n\nThe growing popularity of Laravel\nLaravel’s appeal has only grown over the years, as evidenced by the recent JetBrains Developer Ecosystem Survey. According to this survey, Laravel remains the most popular PHP framework, with a significant number of developers reporting they use it regularly in their projects. \n\nTop primary code editors\nA notable result of the State of Laravel survey pertains to the preferred primary code editors among Laravel developers. PhpStorm has been the most popular choice for ages, and in this iteration of the survey it was favored by 54.01% of respondents. This IDE, enhanced by the Laravel Idea plugin, offers a comprehensive feature set specifically tailored for Laravel development.\nFollowing PhpStorm, Visual Studio Code (VS Code) is the editor of choice for 40.24% of respondents, while Sublime Text ranks third with 2.18% of responses.\n\n\n\n\nLaravel versions and use cases\nOne key trend in the results is the widespread adoption of newer Laravel versions. With the recent release of Laravel 11, many developers are eager to upgrade their projects to leverage the latest improvements and features. However, the results also indicate that a significant number of projects are still running on Laravel 9 and 10. This suggests that while the community is enthusiastic about new versions, the migration process can be challenging, particularly for larger or more complex applications.\n\n\n\n\nThe results also provide valuable insights into the application contexts where Laravel is most commonly used. Almost all respondents (95.40%) reported using Laravel for business applications, while 57.90% use it for hobby projects.\nPHP version preferences\nFrom the survey results, it is evident that there is a strong preference among Laravel developers for using the latest PHP version. This trend is not surprising given the new features introduced in PHP 8.3, such as readonly clones, the #[Override] attribute, and the json_validate function.\n\n\n\n\n\n\nDebugging approaches\nIt is also interesting to look at the approaches developers take to debugging within Laravel. According to the survey results, most developers (89.63%) rely heavily on traditional debugging techniques such as using the dd() and dump() functions. \n\n\n\n\n\n\n“It’s interesting that the majority of PHP and Laravel developers still prefer var_dump equivalents over a debugger. My experience, and that of many developers, is that there’s still too much friction in setting up and toggling Xdebug on a day-by-day basis. I hope PhpStorm will be able to remove some, if not all, of that friction in the near future, as we’re working on improved Xdebug support.”\n\n            \nBrent Roose\n                                                                JetBrains Developer Advocate\n                                    \nCheck out Brent’s reflections on the 2024 State of Laravel results in his latest video stream:\n\n\n\n\n\n\nIntegrations and the expanding Laravel ecosystem\nLaravel’s ability to integrate seamlessly with other technologies is another reason for its growing popularity. The survey results show that many Laravel projects are built with a wide range of integrations, from APIs and third-party services to complex database architectures.\nIn particular, Laravel’s own tools for the ecosystem like Laravel Forge (for server management), Laravel Vapor (for serverless deployment on AWS), and Laravel Nova (an administration panel for Laravel applications) are gaining traction. These tools simplify many aspects of development, deployment, and maintenance, allowing developers to focus more on coding and less on infrastructure management.\n\n\n\n\nThe future of Laravel\nLooking ahead, the survey results indicate a promising future for Laravel. The framework’s maintainers consistently deliver regular updates and introduce new features to keep Laravel at the cutting edge of PHP development. For the latest on these updates, including new features and improvements, you can explore the detailed Laravel Release Notes.\nThe Laravel community is also incredibly active, with numerous online courses, YouTube videos, and vibrant forums, as well as a wealth of resources tailored to various learning preferences. For a comprehensive compilation of resources and tutorials to support your journey, check out Laracasts, a platform offering high-quality video tutorials and courses on Laravel and other web development topics, designed to help developers of all skill levels enhance their knowledge and skills.\nConclusion\nThe State of Laravel survey results offer a comprehensive snapshot of the current trends and challenges within the Laravel ecosystem. For developers and companies working with Laravel, it is essential to stay informed about these trends and adapt accordingly. By leveraging the insights from this survey and staying active in the Laravel community, you can ensure that your projects remain at the forefront of web development in 2024 and beyond.",
        "dc:creator": "Tania Goral",
        "content": "As we move through 2024, Laravel continues to solidify its position as one of the most popular PHP frameworks, powering a multitude of web applications across the globe. In this blog post, we’ll analyze the recently published State of Laravel 2024 survey results, highlighting key takeaways and what they mean for developers, companies, and the [&#8230;]",
        "contentSnippet": "As we move through 2024, Laravel continues to solidify its position as one of the most popular PHP frameworks, powering a multitude of web applications across the globe. In this blog post, we’ll analyze the recently published State of Laravel 2024 survey results, highlighting key takeaways and what they mean for developers, companies, and the […]",
        "guid": "https://blog.jetbrains.com/?post_type=phpstorm&p=507731",
        "categories": [
          "news",
          "laravel"
        ],
        "isoDate": "2024-09-05T14:16:13.000Z"
      },
      {
        "creator": "Irina Mariasova",
        "title": "Java Annotated Monthly – September 2024",
        "link": "https://blog.jetbrains.com/idea/2024/09/java-annotated-monthly-september-2024/",
        "pubDate": "Thu, 05 Sep 2024 07:16:04 +0000",
        "content:encodedSnippet": "Welcome to the latest edition of Java Annotated Monthly! This edition is packed with the latest news on Java, Kotlin, and other influential technologies in the IT world. Don’t miss out on exploring IntelliJ IDEA 2024.2, staying up to date with Java 23, grabbing your tickets for KotlinConf 2025, and learning about the newest developments in Spring and AI. Stay informed and ahead of the curve with everything happening in the Java ecosystem and beyond!\nLet’s start!\nJava News\nJava News Roundup 1, 2, 3, 4 – Make sure you haven’t missed any important updates. \nJava in 2024 – #JVMLS keynote – Check out all the major announcements, trends, and innovations expected to shape the Java landscape in 2024.\nJDK 23 and JDK 24: What We Know So Far – Have an in-depth look at Java 23 so far, including new features, improvements, and community reactions.\nBest of Java Performance – Inside Java Newscast #75 – This episode summarizes the key takeaways from the JVM Language Summit 2024 and includes unreleased video footage.\nConsequences of DORA on Java and OpenJDK with Azul – This article explores the impact of DevOps Research and Assessment (DORA) on Java and OpenJDK, particularly focusing on how it shapes performance metrics and development practices within the community.\nJava Tutorials and Tips\nMoving Java Forward Together by Sharat Chander – In this session, Sharat Chander discusses how you can help keep Java the leading choice for building tomorrow’s applications.\nHow to Read a JDK Enhancement Proposal – Inside Java Newscast #74 – Nicolai Parlog talks about how to effectively read and understand JDK Enhancement Proposals (JEPs). While they’re often easy enough to read, the devil is in the details. Together with Nicolai, you’ll go through those details: states and their changes, the JEP header, the evolution and reliability of the text, and more.\nLeveraging JDK Tools and Updates to Help Safeguard Java Applications – This article reviews several built-in JDK tools and features that administrators can use to strengthen the security of their Java applications. It offers general advice for maintaining application safety rather than addressing specific vulnerabilities, with additional resources for further learning.\nTrash Pandas Love Enterprise Java Garbage Code – Erik Costlow talks about the importance of identifying and removing clutter code to improve system efficiency and developer productivity.\nEpisode 105. Neurons, AI, and LLMs – Learn more about AI, neural networks, and large language models (LLMs), including their core principles, refinements, and the role of vector databases in AI development.\nProject Babylon – Code Reflection #JVMLS – Paul Sandoz presents the recent advancements in Java’s code reflection, focusing on improvements to runtime introspection and metaprogramming.\nInterview with a Java Champion: Reflections on a Storied Career and Insights for the Next Generation – In this interview by A N M Bazlur Rahman, Java Champion Ben Evans reflects on his extensive career, discussing the evolution of the Java ecosystem and offering advice to both experienced developers and newcomers. \nAre Critical Vulnerabilities Lurking in Your Java Ecosystem? – Check out how to avoid hidden security vulnerabilities in the Java ecosystem, particularly from third-party libraries. \nNetflix Adopts Virtual Threads: A Case Study on Performance and Pitfalls – The case study reveals issues with deadlocks and thread handling in Netflix’s microservices, emphasizing the need for careful integration of virtual threads in production environments.\nFour Easy Ways to Analyze your Java and Kotlin Code for Security Problems – Brian Vermeer explains how to use Snyk tools to identify and fix security issues in Java and Kotlin code through CLI, IDE, Git, and CI/CD integrations.\nKotlin Corner\nKotlinConf 2025 Tickets Are Now on Sale! – Tickets for KotlinConf 2025, the largest Kotlin event, are now available to buy.\nKotlin Roundup: Ktor in Focus – Check out the latest updates and developments in the Ktor framework for building asynchronous servers and clients in connected systems.\nApplying the Decorator Pattern in Kotlin by Dave Leeds – The decorator pattern lets you enhance an object’s behavior without its awareness. In this video, Dave Leeds starts with code that could benefit from this pattern, applies it using the classic method from the Gang of Four book, and then updates it with Kotlin’s modern features.\nApplying the Strategy Pattern in Kotlin by Dave Leeds – Another helpful video from Dave Leeds explains why the strategy pattern is so useful, implement it in Kotlin, and then use Kotlin’s language features to give it a modern twist.\nRe-Implementing kotlinx.coroutines by Sebastian Sellmair – In this video, Sebastian Sellmair shows how to re-implement the basics of kotlinx.coroutines.\nCoroutines: Concurrency in Kotlin by Dave Leeds – In this presentation, Dave Leeds covers the essentials of coroutines in Kotlin, including how they enable concurrency and parallelism, and how structured concurrency ensures proper cleanup in cases of cancellations and exceptions.\nThe Kotlinx DateTime API for Compose Multiplatform by Philipp Lackner – Join Philipp Lackner to get an introduction to using the Kotlinx DateTime API in Compose Multiplatform.\nRefactoring to Functional Kotlin by Duncan McGregor – This video gives you a good overview of a really important topic – actions and calculations or impure and pure functions.\nLanguages, Frameworks, Libraries, and Technologies\nThis Week in Spring 1, 2, 3, 4 – Find all the latest Spring news here. \nSpring: Internals of @ComponentScan – Mahendra Rao explains how the @ComponentScan annotation in Spring works to automatically detect and register components in an application.\nSpring Tips: HTMX – Find out how to integrate HTMX with Spring Boot and Thymeleaf and get insights into how HTMX simplifies the process of creating dynamic web applications.\nA Bootiful Podcast: Observability legend Jonatan Ivanov on the latest and greatest in Micrometer – Josh Long and Jonatan Ivanov, an expert in observability, discuss the latest advancements in the Micrometer library, which is widely used within and beyond the Spring ecosystem.\nLeveraging Hibernate Search capabilities in a Quarkus application without a database – Marko Bekhta demonstrates how to use Hibernate Search in Quarkus without a database with the help of the Hibernate Search Standalone mapper.\nGet Started With Allocation Profiling – Igor Kulakov provides a guide on how to use allocation profiling to troubleshoot memory issues in Java applications. He shows how to identify memory leaks by analyzing memory allocations and interpreting profiler data and offers practical steps to optimize your code.\nPodcast: InfoQ AI, ML, and Data Engineering Trends in 2024 – This podcast is about the latest trends in AI, machine learning, and data engineering for 2024. It highlights innovations like the rise of open-source models, the importance of retrieval-augmented generation (RAG) for scalable AI applications, and the growing role of AI-powered hardware.\nHow to integrate Jakarta Data with Spring and Hibernate – In his article, Vlad Mihalcea explains how to integrate Jakarta Data with Spring and Hibernate, providing insights and examples for the usage of these technologies.\nSelf-profiling IntelliJ IDEA – Did you know IntelliJ IDEA can profile itself? If you’re developing an IntelliJ IDEA plugin or troubleshooting performance issues in other projects, this profiling strategy can help identify and address bottlenecks across various tools and scenarios.\nA Bootiful Podcast: Vaadin developer advocacy legend Marcus Hellberg – This is the podcast with Marcus Hellberg, a well-known figure in Vaadin developer advocacy, where he talks about the latest trends and developments in the Spring ecosystem.\nDebugging Kubernetes: Troubleshooting Guide – Shai Almog presents a comprehensive guide to troubleshooting common issues in Kubernetes that can help developers navigate and resolve errors effectively. \nConferences and Events\nHere is a list of Java events taking place both online and offline in September:\nJavaZone – Oslo, Norway, September 4–5\nJava Forum Nord – Hannover, Germany, September 10\nIntroduction to Workspaces in IntelliJ IDEA – Online, September 12\nJConf.dev – Dallas, USA, September 24–26\nJUG Saxony Day – Radebeul, Germany, September 26–27\nJC Conference Taiwan – Taipei, Taiwan, September 27\nJax London – London, United Kingdom, September 30 – October 2\nDev2Next – Denver, USA, September 30 – October 3\nGOTO Copenhagen – Copenhagen, Denmark, September 30 – October 4\nCulture and Community\nInstead of restricting AI and algorithms, make them explainable – Martin Fowler suggests that rather than limiting algorithms and AI, we should focus on making them explainable to ensure transparency and fairness. How would you feel if you could clearly understand the decisions made by AI systems?\nLet LLM suggest Instagram hashtags for your pictures – Guillaume Laforge explores how LLMs can assist in generating creative Instagram hashtags by using AI tools like Gemini. He demonstrates a method to enhance hashtag generation, balancing creativity against structured output.\nA manifesto for small teams doing important work – Check out practical guidelines for small teams to effectively manage time, communication, and responsibilities to achieve meaningful results.\nThe Road to Membership and Baeldung Pro – Find out what Baeldung Pro is and how you can get a membership.\nAnd Finally…\nIntelliJ IDEA 2024.2 Is Out! – The newest version of IntelliJ IDEA is here! This release enhances Spring Data JPA support, simplifies cron expression management, and upgrades the HTTP Client with the GraalJS engine. Startup efficiency is improved, allowing you to dive into coding faster. Additionally, the new version integrates K2 mode (Beta) to boost the IDE’s performance and stability for Kotlin. Read this blog post for more, or watch the embedded video.\nMeet Renovated Kotlin Support – K2 Mode: What You Need to Know – K2 mode is a new way of supporting Kotlin in IntelliJ IDEA, making the IDE more stable and ready for future language features. If you haven’t tried it yet and want to know how it works, this article is for you.\nWorkspaces in IntelliJ IDEA – The new Workspaces feature in IntelliJ IDEA allows developers to manage multiple projects simultaneously within the IDE. Read more about it in this article by Andrey Belyaev and Aleksey Stukalov. \nHacking a JVM Application With IntelliJ IDEA’s Debugger – Have a look at this fun exercise in debugging IntelliJ IDEA with its own debugger.\nThe New Terminal (Beta): Updates for JetBrains IDEs v2024.2 – Check out the new terminal (Beta) features in JetBrains IDEs v2024.2. \nVideos and livestreams \nBefore the arrival of Java 23, we prepared a series of talks about the upcoming updates. Mala Gupta is hosting these sessions with experts including Brian Goetz, Ken Fogel, Dr. Venkat Subramaniam, and Rafael Winterhalter:\nJEP Explained. JEP 455: Primitive Types in Patterns, instanceof, and switch\nJEP Explained. JEP 477: Implicitly Declared Classes and Instance Main Methods\nJEP Explained. JEP 482: Flexible Constructor Bodies\nJEP Explained. JEP 466: Class-File API\nMastering IntelliJ IDEA With DevoxxGenie: Harnessing Local and Cloud-Based LLMs – Join Stephan Janssen as he explores DevoxxGenie’s local LLM integration.\nIntelliJ IDEA Pro Tips: Find Action – Learn more about the Find Action feature, which helps you to quickly locate any action.\nThat’s all for today!\nWe’re gathering ideas for the next Java Annotated Monthly. To contribute, share your suggestions via email or X by September 20. And don’t forget to explore our archive of past JAM issues to catch up on any posts or articles you might have missed.",
        "dc:creator": "Irina Mariasova",
        "content": "Welcome to the latest edition of Java Annotated Monthly! This edition is packed with the latest news on Java, Kotlin, and other influential technologies in the IT world. Don’t miss out on exploring IntelliJ IDEA 2024.2, staying up to date with Java 23, grabbing your tickets for KotlinConf 2025, and learning about the newest developments [&#8230;]",
        "contentSnippet": "Welcome to the latest edition of Java Annotated Monthly! This edition is packed with the latest news on Java, Kotlin, and other influential technologies in the IT world. Don’t miss out on exploring IntelliJ IDEA 2024.2, staying up to date with Java 23, grabbing your tickets for KotlinConf 2025, and learning about the newest developments […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=507639",
        "categories": [
          "news",
          "tutorials",
          "ai",
          "java",
          "java-annotated",
          "kotlin",
          "spring"
        ],
        "isoDate": "2024-09-05T07:16:04.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": [
      {
        "creator": "Xiangmin Liang",
        "title": "Riverbed Data Hydration — Part 1",
        "link": "https://medium.com/airbnb-engineering/riverbed-data-hydration-part-1-e7011d62d946?source=rss----53c7c27702d5---4",
        "pubDate": "Tue, 10 Sep 2024 16:01:29 GMT",
        "content:encodedSnippet": "Riverbed Data Hydration — Part 1\nby: Xiangmin Liang, Sivakumar Bhavanari, Amre Shakim\n\nA deep dive into the streaming aspect of the Lambda architecture framework that optimizes how data is consumed from system-of-record data stores and updates secondary read-optimized stores at Airbnb.\nOverview\nIn our previous blog post we introduced the motivation and high-level architecture of Riverbed. As a recap, Riverbed is a part of Airbnb’s tech stack designed to streamline and optimize how data is consumed from system-of-record data stores and update secondary read-optimized stores. The framework is built around the concept of ‘materialized views’ — denormalized representations of data that can be queried in a predictable, efficient manner. The primary goal of Riverbed is to improve scalability, enable more efficient data fetching patterns, and provide enhanced filtering and search capabilities for a better user experience. It achieves this by keeping the read-optimized store up-to-date with the system-of-record data stores, and by making it easier for developers to build and manage pipelines that stitch together data from various data sources.\nIn this blog post, we will delve deeper into the streaming aspect of the Lambda architecture framework. We’ll discuss step by step its critical components and explain how it constructs and sinks the materialized view from the Change Data Capture (CDC) events of various online data sources. Specifically, we’ll take a closer look at the join transformation within the Notification Pipeline, illustrating how we designed a DAG-like data structure to efficiently join different data sources together in a memory-efficient manner.\nTo make the framework and its components easier to understand, let’s begin with a simplified example of a Riverbed pipeline definition:\n{\n  Review {\n    id @documentId\n    review\n    User {\n      id\n      firstName\n      lastName\n    }\n  }\n}\nRiverbed provides a declarative schema-based interface for customers to define Riverbed pipelines. From the sample definition above, a Riverbed pipeline is configured to integrate data sources from the Review and User entities, generating Riverbed sink documents with the review ID as the materialized view document ID.\nBased on this definition, Riverbed generates two types of streaming pipelines:\n\nSource Pipelines: Two pipelines consume CDC events from the Review and User tables respectively and publish Apache Kafka® events known as notification events, indicating which documents need to be refreshed.\nNotification Pipeline: This pipeline consumes the notification events published by the source pipelines and constructs materialized view documents to be written into sink stores.\n\nNow, let us delve deeper into these two types of pipelines.\nSource Pipeline\nPicture 1. High-level system diagram of Riverbed\nPicture 1 shows the Source Pipeline as the first component in Riverbed. It is an auto-generated pipeline that listens to changes in system-of-record data sources. When changes occur, the Source Pipeline constructs NotificationEvents and emits them onto the Notification Kafka® topic to notify the Notification Pipeline on which documents should be refreshed. In the event-driven architecture of Riverbed, the Source Pipeline acts as the initial trigger for real-time updates in the read-optimized store. It not only ensures that the mutations in the underlying data sources are appropriately captured and communicated to the Notification Pipeline for subsequent processing, but also is the key solution for the concurrency and versioning issues in the framework.\nWhile the emphasis of this blog post is the Notification Pipeline, a detailed exploration of the Source Pipeline — especially its critical role in maintaining real-time data consistency and its interaction with Notification Pipelines — will be discussed in the next blog post of this series.\nNotification Pipeline\nPicture 2. Notification Pipeline components\nThe Notification Pipeline is the core component of the Riverbed framework. It consumes Notification events, then queries dependent data sources and stitches together “documents” that are written into a read-optimized sink to support a materialized view. A notification event is processed by the following operations:\n\nIngestion: For every change to a data source that the Read-Optimized Store is dependent on, we must re-index all affected documents to ensure freshness of data. In this step, Notification Pipeline consumes Notification events from Kafka® and deserializes them into objects that simply contain the document ID and primary source ID.\nJoin: Based on these deserialized objects, Notification Pipeline queries various data stores to fetch all data sources that are necessary for building the materialized view.\nStitch: This step models the join results from various data sources into a comprehensive Java Pojo called StitchModel, so that engineers can perform further customized data processing on it.\nOperate: In this step, a chain of various operators including filter, map, flatMap, etc, containing product-specific business logic can be applied to the StitchModel to convert it into the final document structure that will be stored in the index.\nSink: As the last step, documents can be drained into various data sinks to refresh the materialized views.\n\nAmong these operations, Join, Stitch and Sink are the most important as well as the most complicated ones. In the following sections, we will dive deeper into their design.\nData Source Join\nOne of the most crucial and intricate operations in Riverbed’s Notification Pipeline is the Join operation. A Join operation starts from the primary source ID and then fetches data for all data sources associated with the materialized view based on their relationship.\nJoinConditionsDag\nIn Riverbed, we use JoinConditionsDag, a Directed Acyclic Graph, to store the relationship metadata among data sources, where each node represents one unique data source and each edge represents the join condition between two data sources. In the Notification Pipelines, JoinConditionsDag’s root node is always a metadata node for the notification event which contains the document ID and the primary source ID. The join condition connecting to the notification event node reflects the join condition to query the primary source. Below is a sample JoinConditionsDag defining the join relationship between the primary source Listing and some of its related data sources:\nPicture 3: JoinConditionsDag Sample\nGiven notification events are used to indicate which document needs to be refreshed and does not contain any source data, Notification Pipeline joins data sources starting from the primary source ID provided by the Notification event. Guided by the JoinConditionsDag, when the Notification Pipeline processes a Notification event containing the primarySourceId, it queries the Listing table to fetch Listing data where the id matches primarySourceId. Subsequently, leveraging this Listing data, it queries the ListingDescription and Room tables to retrieve listing descriptions and rooms data, respectively, where the listingId equals id of Listing. In a similar manner, RoomAmenity data is obtained with roomId matching the id of the Room data.\nJoinResultsDag\nNow, we have the JoinConditionsDag guiding the Notification Pipeline to fetch all data sources. However, the question arises: how can we efficiently store the query results? One straightforward option is to flatten all the joined results into a table-like structure. Yet, this approach can consume a significant amount of memory, especially when performing joins with high cardinality. To optimize memory usage, we designed another DAG-like data structure named JoinResultsDag.\nPicture 4: JoinResultsDag Structure\nThere are two major components in a JoinResultsDag. Cell is the atomic container for a data record. Each cell maintains its own successor relationships by mapping successor data source aliases to the CellGroups. CellGroup is the container to store the joined records from one data source. Each data source table record is stored in each Cell.\nAs mentioned above, the biggest difference and the advantage of using a DAG-based data structure instead of using the traditional flat join table is that it can efficiently store a large amount of join result data especially when there is a 1:M or M:N join relationship between data sources. For example, we have one pipeline to create materialized views for Airbnb Listings with information about all their Listing rooms, which also have lots of room amenities. If we use the traditional flat join table, it will look like the following table.\n\nObviously, storing joined results using a flat table structure demands extensive resources for both storage and processing. In contrast, JoinResultsDag effectively mitigates data duplication by allowing multiple successor nodes to refer back to the same ancestor nodes.\nPicture 5: JoinResultsDag Example\nNow with JoinConditionsDag representing the relationship among all data sources and JoinResultsDag storing all the results, joins can be performed in Riverbed roughly as follows:\nStarting from the NotificationEvent, Riverbed first initializes a JoinResultsDag with the deserialized Notification event as root. Then guided by the JoinConditionsDag and following a depth-first-search traverse, it visits the data store of each source, queries data based on the join conditions defined on the JoinConditionsDag edges, encapsulates the query results rows inside each Cell and then continues fetching the data of its dependencies until finished visiting all data sources.\nStitching of Data\nWith the joined results now stored in JoinResultsDag, an additional operation is necessary to transform these varied data pieces into a more usable and functional model. This enables engineers to apply their custom operators, mapping the data onto their specifically designed Sink Document. We refer to this process as the Stitch Operation, resulting in what is known as the StitchModel.\nThe StitchModel, a Java POJO derived from the custom pipeline definition, serves as the intermediate data model that not only contains the actual data but also contains useful metadata about the event such as document ID, version, mutation source, etc.\nAfter the StitchModel metadata is generated, with the help of the JoinResultsDag, the Stitch operation is more straightforward. It maps the JoinResultsDag into a JSON model with the same structure and then converts the JSON model into the custom defined Java POJO utilizing the GSON library.\nSink data\nThe final stage in Riverbed’s Notification Pipeline is to write documents into data sinks. In Riverbed, sinks define where the processed data, now in the form of documents, will be ingested after the preceding operations are completed. Riverbed allows for multiple sinks, including Apache Hive(™) and Kafka®, so the same data can be ingested into multiple storage locations if required. This flexibility is a key advantage of the Notification Pipeline, enabling it to cater to a wide variety of use cases.\nRiverbed writes documents into data sinks via their write APIs. For the best performance, it encapsulates a collection of documents into the API request and then makes use of the batched write API of each data sink to update multiple documents efficiently.\nSummary\nIn conclusion, we’ve navigated the critical steps of Riverbed’s streaming system within the Lambda architecture framework, focusing on the construction of materialized views from CDC events. Our highlight on the join transformation within the Notification Pipeline showcased a DAG-like structure for efficient and memory-conscious data joining. This discussion has shed light on the architectural approach to constructing materialized views in streaming and introduced innovative data structure designs for optimizing streaming data joins. Looking ahead, we will delve deeper into the Source Pipeline of the streaming system and explore the batch system of Riverbed, continuing our journey through advanced data architecture solutions.\nIf this kind of work sounds appealing to you, check out our open roles — we’re hiring!\n\nRiverbed Data Hydration — Part 1 was originally published in The Airbnb Tech Blog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Xiangmin Liang",
        "guid": "https://medium.com/p/e7011d62d946",
        "categories": [
          "data",
          "infrastructure",
          "data-science",
          "engineering",
          "architecture"
        ],
        "isoDate": "2024-09-10T16:01:29.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "article New updates to Planner comment notifications and settings in Planner Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Leah Tran",
        "title": "Search scoping helps you find what you’re looking for",
        "link": "https://devblogs.microsoft.com/visualstudio/search-scoping-helps-you-find-what-youre-looking-for/",
        "pubDate": "Wed, 11 Sep 2024 10:00:38 +0000",
        "content:encodedSnippet": "If you’re working on a large and complex solution, you might find yourself overwhelmed by the number of results when you use code search in Visual Studio. You might be looking for a specific class, method, or variable, but end up scrolling through pages of irrelevant matches. Wouldn’t it be nice if you could narrow down your search scope to only the parts of the solution that you care about?\nIn the latest update of Visual Studio, you can now use the new scoping options in code search to filter your results by the entire solution, the current project, or the current document. You can also toggle the inclusion of external files in your search.\nThis way, you can quickly and easily find what you need without getting lost in the noise.\n\nHow to Use Scoping in Code Search\nTo access the new scoping options, open the Code Search window by pressing Ctrl+T or clicking on the Search button (magnifying glass icon) at the top of the IDE. You’ll see a drop-down menu at the far right of the search box that lets you choose between different scopes.\nYou can select one of the following options:\nEntire solution\nCurrent project\nCurrent document\n\nYou can also click on the checkbox next to Search in external items to toggle the inclusion of code files that are not part of your solution.\nYou can set different scopes for different filters, and your selections will be remembered across sessions. For example, you can set the default filter to search through the entire solution, and the member filter to search through the current document. This way, you can switch between various levels of granularity depending on what you’re looking for.\nHere’s an example of how code search scoping can help you find what you need faster. Suppose you want to find a method called GetProducts in your solution. If you use the default filter and scope, you might get hundreds of results from various projects. But if you use the member filter and scope it to the current project, you will get a narrower set of results that are relevant to your current context.\nWe Hope You Enjoy This Feature\nWe hope that code search scoping will make your coding experience more productive and enjoyable. We’d love to hear your feedback on this feature and any other suggestions you have for improving code search in Visual Studio 2022. You can leave a comment below, use the Report a Problem tool in Visual Studio, or head over to the Developer Community website.\nThank you for your continuous feedback and support, which helps us make Visual Studio better every day.\nThe post Search scoping helps you find what you’re looking for appeared first on Visual Studio Blog.",
        "dc:creator": "Leah Tran",
        "content": "<p>If you&#8217;re working on a large and complex solution, you might find yourself overwhelmed by the number of results when you use code search in Visual Studio. You might be looking for a specific class, method, or variable, but end up scrolling through pages of irrelevant matches. Wouldn&#8217;t it be nice if you could narrow [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/search-scoping-helps-you-find-what-youre-looking-for/\">Search scoping helps you find what you’re looking for</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "If you’re working on a large and complex solution, you might find yourself overwhelmed by the number of results when you use code search in Visual Studio. You might be looking for a specific class, method, or variable, but end up scrolling through pages of irrelevant matches. Wouldn’t it be nice if you could narrow […]\nThe post Search scoping helps you find what you’re looking for appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=250542",
        "categories": [
          "Productivity",
          "Visual Studio",
          "code search",
          "Search"
        ],
        "isoDate": "2024-09-11T10:00:38.000Z"
      },
      {
        "creator": "Anders Sundheim",
        "title": "Break for Async User-Unhandled exceptions in the Visual Studio Debugger",
        "link": "https://devblogs.microsoft.com/visualstudio/break-for-async-user-unhandled-exceptions-in-the-visual-studio-debugger/",
        "pubDate": "Tue, 10 Sep 2024 10:00:16 +0000",
        "content:encodedSnippet": "Before .NET 9, the debugger was unable to track exceptions thrown from user-code async methods into non-user code framework methods, such as ASP.NET middleware. We are pleased to announce that you will now start seeing the debugger stop for these user-unhandled exceptions in your ASP.NET applications, as well as anywhere else this might happen!\n\nSummary\nDebugging asynchronous code, especially in frameworks like ASP.NET Core, can be tricky due to the potential for exceptions to be thrown across asynchronous boundaries.\nNow, the Visual Studio Debugger will automatically break when an async Task method throws an exception back to framework code. This will allow you to easily identify and diagnose issues in your ASP.NET applications, leading to faster debugging cycles and improved productivity. Read below for more details about how user-unhandled exceptions work and how the debugger handles async methods.\nPlease note that this is for .NET 9 and newer projects only.\nDetails\nThe Visual Studio Debugger will enter a break state when exceptions are thrown under three different conditions:\nFirst chance exceptions, where exception settings indicate that the debugger should break whenever exceptions of the specified type are thrown.\nUnhandled exceptions, where the exception is unhandled and no catch handler is found.\nUser-unhandled exceptions, where Just My Code is enabled, and an exception was found to have traveled through user code before a catch handler was found in non-user code.\nUser-unhandled exceptions are the target of the change to account for async user-unhandled scenarios.\nAll async Task<T> functions in C# compile to a state machine with an implicit catch handler that catches all exceptions thrown in the Task, sets IsFaulted, and adds the Exception to the AggregateException in Task.Exception.\nWhen a Task is “unwrapped”, typically either via the preferred await or .Result, the stored exception is rethrown to the caller as would happen in a synchronous method and the implicit catch handling is not typically important or observed.\nTo a debugger, on the other hand, this looks like exceptions are being handled! An exception was thrown, it was caught in “user code” (the compiled result of async Task<T> DoSomethingAsync(...)), and any non-user code awaiting that Task will throw the exception again from non-user code. It is important to note that when Just My Code is enabled, the runtime will avoid sending the debugger events for exceptions that were not thrown in user code, significantly improving performance.\nNow consider this behavior in a typical ASP.NET MVC Controller, when Just My Code is enabled:\n[HttpPost]\npublic async Task<ActionResult<TodoItem>> PostTodoItem(TodoItem todoItem)\n{\n_context.TodoItems.Add(todoItem);\nawait _context.SaveChangesAsync(); // imagine this throws some Exception\nreturn CreatedAtAction(nameof(GetTodoItem), new { id = todoItem.Id }, todoItem);\n}\nIf SaveChangesAsync() throws an unhandled Exception, it will:\n1. Immediately catch it and fault the Task. The debugger is notified, but its user code throwing and catching, so the process continues.\n2. async Task<ActionResult<TodoItem>> PostTodoItem will unwrap the faulted Task, rethrow the Exception, and catch it again. Again, the debugger is notified, but nothing is amiss here (and there might be user code that might eventually await it to catch the exception, we cannot see into the future!)\n3. Whatever non-user library/framework middleware that is awaiting PostTodoItem will unwrap that Task and rethrow the exception, but since Just My Code is enabled, the debugger is oblivious – that exception was not thrown from user code and caught in non-user code, it was thrown from non-user code.\nThus, changes were required in the runtime to allow the debugger to indicate that we’d like to keep an eye on a particular exception object, so that if the compiled catch handler of a user-code async Task<T> method catches an exception, we continue to be notified about that exception object in case it is rethrown in non-user code. That way, if an exception is thrown through an ASP.NET MVC Controller, the debugger can break for user-unhandled.\nLimitations\nThere are some limitations with this approach, notably the fact that the debugger is not actually stopped on the PostTodoItem frame in the example above, it is stopped at the frame below it, where the exception was rethrown and caught in non-user code:\nApp!MyMVCApp.DbContextOptions<TodoContext>.SaveChangesAsync() Line 10\nApp!MyMVCApp.TodoController.PostTodoItem(TodoItem todoItem) Line 5\n[External Code] <- The debugger will stop here\nThis means the frames the exception was thrown from have been unwound past and are not necessarily valid to do variable evaluations on. A GC (Garbage Collection) may have occurred, variables may have been changed, and so on. The debugger will create fake [Exception] frames to represent the context in which the exception was originally thrown, and will attempt to save information from the async state machine to evaluate variables as best as it can, but certain things get nulled out by the compiler as part of async Task exception handling, notably:\nLocal reference type variables\nLocal value types with reference fields, or value types that reference other value types with reference fields.\nParameters and class fields/properties will stay intact, as will the exception itself.\nFor more information, see the original feature request in the public dotnet runtime repository here: https://github.com/dotnet/runtime/issues/12488.\nTo disable entering break state for async user-unhandled, you can run (in the associated Visual Studio Developer Command Prompt)\nvsregedit set local hklm Debugger\\EngineSwitches DisableBreakForAsyncUserUnhandled dword 1\nor otherwise set the indicated key for the target installation of Visual Studio.\nLibrary authors who do not want the debugger to stop on expected exceptions thrown into their functions can use the [DebuggerDisableUserUnhandledExceptions] attribute introduced in .NET 9 Preview 7, and either rethrow the exception or call the new Debugger.BreakForUserUnhandledException(Exception e) function when the exception is unexpected. You can find the API proposal and discussion for this pair of APIs here: https://github.com/dotnet/runtime/issues/103105.\nThank you!\nWe appreciate the time you’ve spent reporting issues/suggestions and hope you continue to give us feedback when using Visual Studio on what you like and what we can improve. Your feedback is critical to help us make Visual Studio the best tool it can be! You can share feedback with us via Developer Community: report any bugs or issues via report a problem and share your suggestions for new features or improvements to existing ones.\nStay connected with the Visual Studio team by following us on YouTube, Twitter, LinkedIn, Twitch and on Microsoft Learn.\nThe post Break for Async User-Unhandled exceptions in the Visual Studio Debugger appeared first on Visual Studio Blog.",
        "dc:creator": "Anders Sundheim",
        "content": "<p>Before .NET 9, the debugger was unable to track exceptions thrown from user-code async methods into non-user code framework methods, such as ASP.NET middleware. We are pleased to announce that you will now start seeing the debugger stop for these user-unhandled exceptions in your ASP.NET applications, as well as anywhere else this might happen! Summary [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/break-for-async-user-unhandled-exceptions-in-the-visual-studio-debugger/\">Break for Async User-Unhandled exceptions in the Visual Studio Debugger</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Before .NET 9, the debugger was unable to track exceptions thrown from user-code async methods into non-user code framework methods, such as ASP.NET middleware. We are pleased to announce that you will now start seeing the debugger stop for these user-unhandled exceptions in your ASP.NET applications, as well as anywhere else this might happen! Summary […]\nThe post Break for Async User-Unhandled exceptions in the Visual Studio Debugger appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=250536",
        "categories": [
          "Debug",
          "Productivity",
          "Visual Studio",
          "Debugger"
        ],
        "isoDate": "2024-09-10T10:00:16.000Z"
      },
      {
        "creator": "Harshada Hole",
        "title": "Supercharge C++ Debugging with AI-Generated breakpoint expressions",
        "link": "https://devblogs.microsoft.com/visualstudio/supercharge-c-debugging-with-ai-generated-breakpoint-expressions/",
        "pubDate": "Mon, 09 Sep 2024 13:39:25 +0000",
        "content:encodedSnippet": "Have you ever spent hours debugging your C++ code, struggling to set up the right conditional breakpoint or tracepoint? Or wished for a smarter way to obtain detailed runtime information without manually crafting complex expressions? You’re in luck! With Visual Studio 2022, the latest GitHub Copilot feature now offers AI-generated expressions for both conditional breakpoints and tracepoints, available from C# 17.10 and now extended to C++. With these AI-generated conditional breakpoints and tracepoints, you can now automate the creation of intelligent expressions tailored to your specific debugging needs, significantly speeding up the process and enhancing your ability to diagnose and resolve issues.\n\nWhat are conditional breakpoints and tracepoints?\nConditional breakpoints and tracepoints are powerful debugging tools that enhance your ability to control and monitor code execution. A conditional breakpoint pauses execution only when a specified condition is true, making it ideal for targeting specific scenarios. For example, you can halt code only when a variable exceeds a certain value or a function is called with particular parameters, while a Tracepoints enable logging of messages to the output window or a file without interrupting code execution and replaces traditional ‘printf’ statements, offering detailed runtime insights without the need for code recompilation.\nThese tools are invaluable for identifying bugs, testing various scenarios, and tracking variables and expression values without manually stepping through each line of code. However, crafting the correct expressions for conditional breakpoints or tracepoints can be challenging and time-consuming, especially when remembering the correct syntax in complex codebases.\nFortunately, with GitHub Copilot you have the flexibility to choose from predefined conditions that suit your needs or to define custom conditions for precise and efficient debugging.\nHow can AI-generated expressions help you debug faster?\nVisual Studio 2022 integrates with GitHub Copilot, AI-powered code completion tool that suggests lines of code or entire functions, effectively acting as a pair programmer that enhances coding efficiency. When you position the cursor in the textbox for a conditional breakpoint or tracepoint, GitHub Copilot promptly provides three AI-generated expression suggestions based on your codebase. You can choose the most suitable condition or create your own custom conditions as needed.\nWith AI-generated expressions, you can save time and effort by letting GitHub Copilot do the hard work for you. You can also discover new ways of writing expressions that you might not have thought of before. AI-generated expressions can help you debug your code faster and more effectively and learn from the suggestions along the way.\nHow to use AI-generated expressions in Visual Studio 2022?\nTo use AI-generated expressions for conditional breakpoints and tracepoints in Visual Studio 2022, you need to have a GitHub account and sign in with GitHub in Visual Studio. You also need to make sure Tools > Options > Debugging > enable AI suggestions for breakpoint expressions” is enabled.\nOnce you have enabled GitHub Copilot, you can start using AI-generated expressions for conditional breakpoints and tracepoints in your C++ code.\n\nYou can also use keyboard shortcuts to navigate and select the suggestions. Use Ctrl+Space to invoke the suggestion list, use the up and down arrow keys to move through the list, and use Enter to select a suggestion.\nTry it and let us know what you think\nWe hope you enjoy using AI-generated expressions for conditional breakpoints and tracepoints in Visual Studio 2022. This feature aims to make debugging your C++ code faster and easier. We’d love your feedback and suggestions for improvement. Please leave a comment below or use the Send Feedback button in Visual Studio.\nLearn more about other Copilot assisted features in Visual Studio by checking out additional resources Debug with GitHub Copilot – Visual Studio (Windows) | Microsoft Learn\nStay connected with the Visual Studio team by following us on Twitter @VS_Debugger, Twitter @VisualStudio, Twitter @VisualC YouTube, and LinkedIn.\nDownload Visual Studio 17.11\n\nThe post Supercharge C++ Debugging with AI-Generated breakpoint expressions appeared first on Visual Studio Blog.",
        "dc:creator": "Harshada Hole",
        "content": "<p>Have you ever spent hours debugging your C++ code, struggling to set up the right conditional breakpoint or tracepoint? Or wished for a smarter way to obtain detailed runtime information without manually crafting complex expressions? You&#8217;re in luck! With Visual Studio 2022, the latest GitHub Copilot feature now offers AI-generated expressions for both conditional breakpoints [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/supercharge-c-debugging-with-ai-generated-breakpoint-expressions/\">Supercharge C++ Debugging with AI-Generated breakpoint expressions</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Have you ever spent hours debugging your C++ code, struggling to set up the right conditional breakpoint or tracepoint? Or wished for a smarter way to obtain detailed runtime information without manually crafting complex expressions? You’re in luck! With Visual Studio 2022, the latest GitHub Copilot feature now offers AI-generated expressions for both conditional breakpoints […]\nThe post Supercharge C++ Debugging with AI-Generated breakpoint expressions appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=250522",
        "categories": [
          "Debug",
          "Productivity",
          "Team and Development",
          "Visual Studio",
          "Breakpoints",
          "Debugging and Diagnostics"
        ],
        "isoDate": "2024-09-09T13:39:25.000Z"
      },
      {
        "creator": "Mads Kristensen",
        "title": "Easily dock and float tool windows",
        "link": "https://devblogs.microsoft.com/visualstudio/easily-dock-and-float-tool-windows/",
        "pubDate": "Thu, 05 Sep 2024 10:00:26 +0000",
        "content:encodedSnippet": "You’re in the middle of a debugging session, attempting to chase down that one issue that is causing you trouble. In the heat of the moment, you grab a tool window and drag it out of its docked position – purely by accident. You didn’t mean to drag it, but sometimes when you move the mouse around, things like that happen. Your full attention now shifts from debugging to trying to get the tool window back to where it was.\nSounds familiar? Here’s something that will help.\n\nThere is a little-known feature that will move a tool window between its last known docked location and last known floating location. Holding the Ctrl key while double-clicking the tool window header toggles the location back and forth.\n\nThis is useful for more than just accidental dragging, and I find that it comes in handy on a weekly basis myself.\nI hope this will both lessen some frustration and make you more productive.\nHappy coding!\nThe post Easily dock and float tool windows appeared first on Visual Studio Blog.",
        "dc:creator": "Mads Kristensen",
        "content": "<p>You’re in the middle of a debugging session, attempting to chase down that one issue that is causing you trouble. In the heat of the moment, you grab a tool window and drag it out of its docked position – purely by accident. You didn’t mean to drag it, but sometimes when you move the [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/easily-dock-and-float-tool-windows/\">Easily dock and float tool windows</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "You’re in the middle of a debugging session, attempting to chase down that one issue that is causing you trouble. In the heat of the moment, you grab a tool window and drag it out of its docked position – purely by accident. You didn’t mean to drag it, but sometimes when you move the […]\nThe post Easily dock and float tool windows appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=250474",
        "categories": [
          "Debug",
          "Debugging and Diagnostics",
          "Keyboard Shortcuts",
          "Visual Studio 2022"
        ],
        "isoDate": "2024-09-05T10:00:26.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권영재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김병환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김상훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "내가 처음이 아니다",
        "link": "https://kangmyounghun.blogspot.com/2024/09/blog-post.html",
        "pubDate": "2024-09-11T04:18:00.002Z",
        "author": "강명훈",
        "content": "<div>하나의 <a href=\"https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html\" target=\"_blank\">로그스태시 파이프라인</a>에서 서로 다른 데이터를 수집, 서로 다른 인덱스에 저장하는 구성에 대한 질문을 받았다. 방법은 input 구간에서 출처별로 수집 플러그인을 분리한 후, output 구간에서 조건에 따라 저장명을 달리하는 것.</div><div>\n<pre><code><div>input {</div><div>&nbsp;file {</div><div>&nbsp; path =&gt; \"a.log\"</div><div>&nbsp;}</div><div><br /></div><div><div>&nbsp;file {</div><div>&nbsp; path =&gt; \"b.log\"</div><div>&nbsp;}</div></div><div>}</div><div><br /></div><div><span><a name='more'></a></span>output {</div><div>&nbsp;if [path] == \"a.log\" {</div><div>&nbsp; elasticsearch {</div><div>&nbsp; &nbsp;index =&gt; \"index_a\"</div><div>&nbsp; }</div><div>&nbsp;} else {</div><div><div>&nbsp; elasticsearch {</div><div>&nbsp; &nbsp;index =&gt; \"index_b\"</div><div>&nbsp; }</div></div><div>&nbsp;}</div><div>}</div></code></pre>\n<div><br /></div><div>데이터 전처리를 잘 하면 분석이 쉬워진다가 강의 주제인지라&nbsp;<a href=\"https://www.elastic.co/guide/en/logstash/current/filter-plugins.html\" target=\"_blank\">filter 구간</a>&nbsp;활용에 집중한다. 자연스럽게 input이나 output 멀티 구성에 대한 필요성을 느낀 적이 없음. 개인의 경험은 한계가 있다. 그래서 타인의 경험이 공유될 때 강의가 재밌어진다.</div><div><br /></div><div>당연히 질문에 대한 답을 처음부터 알지 못했다. 하지만 답을 찾는 게 어렵진 않았다. 모르면 물어보면 되니까.</div><div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwf2tckxDTqxGtOLyhirUiEgQWsZUp5eocJAi1JTrOpsXJw-njHpZu2E2j-hhtf7r7kgfr6j28-maw2jYWOt__b2GdDuKq1Mz6aJzk8QH7gmjkyw-J4kiwnCEiaNHoczAqwlw3dIp2_aaEPiVNzM73drEVCnuRmDrYKXYVrzx1-wjqzWLK6sruJKBCXxvv/s1280/u_r_not_first.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"704\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwf2tckxDTqxGtOLyhirUiEgQWsZUp5eocJAi1JTrOpsXJw-njHpZu2E2j-hhtf7r7kgfr6j28-maw2jYWOt__b2GdDuKq1Mz6aJzk8QH7gmjkyw-J4kiwnCEiaNHoczAqwlw3dIp2_aaEPiVNzM73drEVCnuRmDrYKXYVrzx1-wjqzWLK6sruJKBCXxvv/s520/u_r_not_first.png\" width=\"520\" /></a></div><div><br /></div></div><div>엘라스틱이 나온 지 10년이 넘었고, 그동안 수백만 이상의 사용자들이 엘라스틱을 사용했다. 그중에 나와 같은 목적을 가진 사람이 한 명도 없다면 정말 이상하지 않을까? 하늘 아래 새로운 거 없고, 사람 생각하는 거 크게 다르지 않다.</div><div><br /></div><div>나와 같은 문제로 고민하는 사람이 수 만은 될 것이고, 그중엔 반드시 문제를 해결한 사람이, 그리고 그 해결책을 공유하는 사람이 존재한다. 검색만 잘 하면 된다는 얘기. 이때 원하는 검색 결과를 얻기 위한 조건은 단 하나.</div><div><br /></div><div><b><span style=\"font-size: x-large;\">질문이 뚜렷해야 한다</span></b></div><div><br /></div><div>질문을 명확히 정의할 수 있어야 한다는 얘기. 그게 가능하려면 결국 내가 하고 싶은 게 구체적이어야 한다. 하고 싶은 게 뚜렷하지 않은 상태에서는 뭘 질문해야 할지 알 수도 없고, 설령 질문을 한들 누구도 답을 주기 어렵다. 뭘 원하는지 알기 힘든 질문이니까.</div><div><blockquote style=\"text-align: center;\"><i>목적이 뚜렷하다면 아무리 새롭고 어려운 기술이라도 즐겁게 배움에 임할 수 있으며, 좋은 질문을 할 수 있고, 좋은 답을 구할 수 있다. 설령 좋은 답을 얻지 못하더라도 최소한 그 답에 가까워질 수 있다</i> - <span style=\"font-size: x-small;\">Elasticsearch로 알아보는 이상징후 분석 (249p)</span></blockquote><span style=\"font-size: x-small;\"></span></div><div><br /></div><div>물론 그저 엘라스틱 박사가 되고 싶은 거라면 공식 문서를 모조리 외워버리는 방법도 있다. 하지만 그게 가능하다면 같은 노력을 했을 때 인생이 더 풍요로워지는 다른 분야가 있지 않을까? 결국 툴을 잘 쓰려면 명확한 사용처가 있어야 한다.</div><div><br /></div><div>하고 싶은 게 뚜렷하다면 엘라스틱이나 스플렁크는 배우기 쉽다. 제품 인기도 만큼 커뮤니티가 활발하고, 같은 목적을 위한 삽질 끝에 나보다 먼저 문제를 해결한 선배들이 많기 때문. 그래서 팁이라면 그냥 구글 검색보다 커뮤니티 우선 검색이 구체적인 사례 수집에 유리하다.</div><div><br /></div>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj4K7J0uWByZGBRVH6N_rl4smTJVc9l24kYKty2wqZJ4jzc4z28LwOn6uqFGY6HmpYOyAcO9qqvBeeuoLBKOcIOUHEx3LnqhJG9ZMWHDL5ULsDVzZj9bEVcKqjpMKTOmZFIlTr4mKCJc7jNyc36AfzPinxzVbbwlsdpGdWCub38MuETnhCHcjCzvsmRtswB/s1280/u_r_not_first2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"704\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj4K7J0uWByZGBRVH6N_rl4smTJVc9l24kYKty2wqZJ4jzc4z28LwOn6uqFGY6HmpYOyAcO9qqvBeeuoLBKOcIOUHEx3LnqhJG9ZMWHDL5ULsDVzZj9bEVcKqjpMKTOmZFIlTr4mKCJc7jNyc36AfzPinxzVbbwlsdpGdWCub38MuETnhCHcjCzvsmRtswB/s520/u_r_not_first2.png\" width=\"520\" /></a></div>\n<div><br /></div><div>기억하자. 내가 뭔가 하고 싶은 게 있다면, 나만 하고 싶어 하는 게 아니다. 반드시 먼저 시도한 이들이 있다.</div><div><br /></div><div><b>관련 글</b><br /><ul><li><a href=\"https://kangmyounghun.blogspot.com/2022/01/2nd.html\" target=\"\">엘라스틱이 쉬웠던 이유 - 2nd</a></li></ul></div></div>",
        "contentSnippet": "하나의 로그스태시 파이프라인에서 서로 다른 데이터를 수집, 서로 다른 인덱스에 저장하는 구성에 대한 질문을 받았다. 방법은 input 구간에서 출처별로 수집 플러그인을 분리한 후, output 구간에서 조건에 따라 저장명을 달리하는 것.\n\n\ninput {\n file {\n  path => \"a.log\"\n }\n\n\n file {\n  path => \"b.log\"\n }\n\n}\n\noutput {\n if [path] == \"a.log\" {\n  elasticsearch {\n   index => \"index_a\"\n  }\n } else {\n\n  elasticsearch {\n   index => \"index_b\"\n  }\n\n }\n}\n\n\n데이터 전처리를 잘 하면 분석이 쉬워진다가 강의 주제인지라 filter 구간 활용에 집중한다. 자연스럽게 input이나 output 멀티 구성에 대한 필요성을 느낀 적이 없음. 개인의 경험은 한계가 있다. 그래서 타인의 경험이 공유될 때 강의가 재밌어진다.\n\n\n당연히 질문에 대한 답을 처음부터 알지 못했다. 하지만 답을 찾는 게 어렵진 않았다. 모르면 물어보면 되니까.\n\n\n\n\n\n엘라스틱이 나온 지 10년이 넘었고, 그동안 수백만 이상의 사용자들이 엘라스틱을 사용했다. 그중에 나와 같은 목적을 가진 사람이 한 명도 없다면 정말 이상하지 않을까? 하늘 아래 새로운 거 없고, 사람 생각하는 거 크게 다르지 않다.\n\n\n나와 같은 문제로 고민하는 사람이 수 만은 될 것이고, 그중엔 반드시 문제를 해결한 사람이, 그리고 그 해결책을 공유하는 사람이 존재한다. 검색만 잘 하면 된다는 얘기. 이때 원하는 검색 결과를 얻기 위한 조건은 단 하나.\n\n\n질문이 뚜렷해야 한다\n\n\n질문을 명확히 정의할 수 있어야 한다는 얘기. 그게 가능하려면 결국 내가 하고 싶은 게 구체적이어야 한다. 하고 싶은 게 뚜렷하지 않은 상태에서는 뭘 질문해야 할지 알 수도 없고, 설령 질문을 한들 누구도 답을 주기 어렵다. 뭘 원하는지 알기 힘든 질문이니까.\n\n목적이 뚜렷하다면 아무리 새롭고 어려운 기술이라도 즐겁게 배움에 임할 수 있으며, 좋은 질문을 할 수 있고, 좋은 답을 구할 수 있다. 설령 좋은 답을 얻지 못하더라도 최소한 그 답에 가까워질 수 있다 - Elasticsearch로 알아보는 이상징후 분석 (249p)\n\n\n\n물론 그저 엘라스틱 박사가 되고 싶은 거라면 공식 문서를 모조리 외워버리는 방법도 있다. 하지만 그게 가능하다면 같은 노력을 했을 때 인생이 더 풍요로워지는 다른 분야가 있지 않을까? 결국 툴을 잘 쓰려면 명확한 사용처가 있어야 한다.\n\n\n하고 싶은 게 뚜렷하다면 엘라스틱이나 스플렁크는 배우기 쉽다. 제품 인기도 만큼 커뮤니티가 활발하고, 같은 목적을 위한 삽질 끝에 나보다 먼저 문제를 해결한 선배들이 많기 때문. 그래서 팁이라면 그냥 구글 검색보다 커뮤니티 우선 검색이 구체적인 사례 수집에 유리하다.\n\n\n\n\n기억하자. 내가 뭔가 하고 싶은 게 있다면, 나만 하고 싶어 하는 게 아니다. 반드시 먼저 시도한 이들이 있다.\n\n\n관련 글\n\n엘라스틱이 쉬웠던 이유 - 2nd",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-1623305934797223552",
        "isoDate": "2024-09-11T04:18:00.002Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕홍",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": [
      {
        "creator": "베누시안",
        "title": "한림 웹폰트",
        "link": "http://martian36.tistory.com/1636",
        "pubDate": "Sun, 8 Sep 2024 15:00:16 +0900",
        "author": "베누시안",
        "comments": "http://martian36.tistory.com/1636#entry1636comment",
        "content": "<p data-ke-size=\"size16\">한림대학교의료원에서 제작한 폰트를 기반으로 웹폰트를 만들었습니다. 본래 눈누에 웹폰트가 있으나 레귤러만 있어서 필요에 따라 모든 서체를 웹폰트로 만들었습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"fileblock\" data-ke-align=\"alignCenter\"><a href=\"https://blog.kakaocdn.net/dn/biTlKA/btsJueuoRWS/lvbn6p1dPNt1kJ1KrpXYUk/Hallym2350.zip?attach=1&amp;knm=tfile.zip\" class=\"\">\n    <div class=\"image\"></div>\n    <div class=\"desc\"><div class=\"filename\"><span class=\"name\">Hallym2350.zip</span></div>\n<div class=\"size\">2.27MB</div>\n</div>\n  </a></figure>\n<figure class=\"fileblock\" data-ke-align=\"alignCenter\"><a href=\"https://blog.kakaocdn.net/dn/070Ky/btsJvwgiyAn/inwuYY6c5kWpbnjaFFcVe1/Hallym-All.zip?attach=1&amp;knm=tfile.zip\" class=\"\">\n    <div class=\"image\"></div>\n    <div class=\"desc\"><div class=\"filename\"><span class=\"name\">Hallym-All.zip</span></div>\n<div class=\"size\">4.33MB</div>\n</div>\n  </a></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">Hallym2350은 많이 쓰이는 한글을 2350개만 추가한 것이고 All은 모든 글꼴을 포함했습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">Hallym2350의 파일을 압축해제하고 Html 파일을 열면 아래처럼 글자를 볼 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"009.jpg\" data-origin-width=\"983\" data-origin-height=\"1294\"><span data-url=\"https://blog.kakaocdn.net/dn/cF8ao8/btsJvpOUqyS/jFvRqpSmCJVNepQ2Xzk83k/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cF8ao8/btsJvpOUqyS/jFvRqpSmCJVNepQ2Xzk83k/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cF8ao8/btsJvpOUqyS/jFvRqpSmCJVNepQ2Xzk83k/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcF8ao8%2FbtsJvpOUqyS%2FjFvRqpSmCJVNepQ2Xzk83k%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"009.jpg\" data-origin-width=\"983\" data-origin-height=\"1294\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">All은 아래처러 각종 기호도 포함돼있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"010.jpg\" data-origin-width=\"976\" data-origin-height=\"1289\"><span data-url=\"https://blog.kakaocdn.net/dn/p1l8F/btsJuHXcD2P/J61exvOszVGRHklSkhbkEk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/p1l8F/btsJuHXcD2P/J61exvOszVGRHklSkhbkEk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/p1l8F/btsJuHXcD2P/J61exvOszVGRHklSkhbkEk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fp1l8F%2FbtsJuHXcD2P%2FJ61exvOszVGRHklSkhbkEk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"010.jpg\" data-origin-width=\"976\" data-origin-height=\"1289\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">웹폰트 사용법은 css 파일과 woff 파일 등을 폴더에 넣고 아래처럼 임포트를 해주면 됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">@import&nbsp;url(\"assets/hallym/stylesheet.css\");</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">폰트 굵기에 따라서 아래처럼 폰트 패밀리 이름을 정해주면 됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">.home-top&nbsp;h3&nbsp;{ <br />font-family: 'hallym_mjoregular' !important;<br />font-size:&nbsp;26px; <br />}</p>",
        "contentSnippet": "한림대학교의료원에서 제작한 폰트를 기반으로 웹폰트를 만들었습니다. 본래 눈누에 웹폰트가 있으나 레귤러만 있어서 필요에 따라 모든 서체를 웹폰트로 만들었습니다.\n \n\n    \n\n    \nHallym2350.zip\n2.27MB\n\n\n    \n\n    \nHallym-All.zip\n4.33MB\n\n\n \nHallym2350은 많이 쓰이는 한글을 2350개만 추가한 것이고 All은 모든 글꼴을 포함했습니다.\n \nHallym2350의 파일을 압축해제하고 Html 파일을 열면 아래처럼 글자를 볼 수 있습니다.\n \n\n\n \nAll은 아래처러 각종 기호도 포함돼있습니다.\n \n\n\n \n웹폰트 사용법은 css 파일과 woff 파일 등을 폴더에 넣고 아래처럼 임포트를 해주면 됩니다.\n \n@import url(\"assets/hallym/stylesheet.css\");\n \n폰트 굵기에 따라서 아래처럼 폰트 패밀리 이름을 정해주면 됩니다.\n \n.home-top h3 { \nfont-family: 'hallym_mjoregular' !important;\nfont-size: 26px; \n}",
        "guid": "http://martian36.tistory.com/1636",
        "categories": [
          "폰트/한글폰트"
        ],
        "isoDate": "2024-09-08T06:00:16.000Z"
      },
      {
        "creator": "베누시안",
        "title": "워드프레스에서 갑작스러운 문제 발생의 원인은 플러그인 충돌",
        "link": "http://martian36.tistory.com/1635",
        "pubDate": "Sun, 8 Sep 2024 11:14:11 +0900",
        "author": "베누시안",
        "comments": "http://martian36.tistory.com/1635#entry1635comment",
        "content": "<p data-ke-size=\"size16\">우커머스 쇼핑몰을 개발하다보면 제일 먼저 하는 것이 테마와 모든 플러그인을 설치하고 결제까지 진행해서 테스트 결제를 완료합니다. 그 이후로는 원하는 기능과 디자인을 진행합니다. 기능개선을 위해 별도의 플러그인을 설치하기도 하죠. 이러다보면 기존에 잘 작동하던 기능도 갑자기 안되기도 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"001.jpg\" data-origin-width=\"1527\" data-origin-height=\"978\"><span data-url=\"https://blog.kakaocdn.net/dn/cpJy7Q/btsJu8zNAlc/U5C8kDNqQVqBc9JoVEsDjK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cpJy7Q/btsJu8zNAlc/U5C8kDNqQVqBc9JoVEsDjK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cpJy7Q/btsJu8zNAlc/U5C8kDNqQVqBc9JoVEsDjK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcpJy7Q%2FbtsJu8zNAlc%2FU5C8kDNqQVqBc9JoVEsDjK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"001.jpg\" data-origin-width=\"1527\" data-origin-height=\"978\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">장바구니에 들어가니 위처럼 숏코드가 나타납니다. 원래대로라면 아래처럼 나타나야 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"002.jpg\" data-origin-width=\"1528\" data-origin-height=\"980\"><span data-url=\"https://blog.kakaocdn.net/dn/VeTet/btsJuAjhUwZ/mZLijISfkqAiM5Kxy8R86K/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/VeTet/btsJuAjhUwZ/mZLijISfkqAiM5Kxy8R86K/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/VeTet/btsJuAjhUwZ/mZLijISfkqAiM5Kxy8R86K/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FVeTet%2FbtsJuAjhUwZ%2FmZLijISfkqAiM5Kxy8R86K%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"002.jpg\" data-origin-width=\"1528\" data-origin-height=\"980\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">우커머스 숏코드가 작동하지 않는 것이죠. 다른 숏코드로 그런가 해서 결제페이지로 가도 마찬가지로 작동하지 않습니다. 그래서 아래의 화면으로 가서 각 페이지들이 연결이 잘 돼있나 확인해봅니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"003.jpg\" data-origin-width=\"1112\" data-origin-height=\"746\"><span data-url=\"https://blog.kakaocdn.net/dn/U6mlA/btsJusTmAKK/I8hF0vzNgzG5maUgUt84a0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/U6mlA/btsJusTmAKK/I8hF0vzNgzG5maUgUt84a0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/U6mlA/btsJusTmAKK/I8hF0vzNgzG5maUgUt84a0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FU6mlA%2FbtsJusTmAKK%2FI8hF0vzNgzG5maUgUt84a0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"003.jpg\" data-origin-width=\"1112\" data-origin-height=\"746\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">원래 대로 제대로 돼있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">뭐가 문제일까.. 이런 경우는 처음입니다. 플러그인이 문제일 것이다라고 생각하고 테마를 기본 테마로 변경하고 플러그인을 다섯 개씩 비활성화 해봅니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"004.jpg\" data-origin-width=\"833\" data-origin-height=\"501\"><span data-url=\"https://blog.kakaocdn.net/dn/bhVjwk/btsJv7G2rQP/Avy7SYhAqXcJP4nk9zmrH0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bhVjwk/btsJv7G2rQP/Avy7SYhAqXcJP4nk9zmrH0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bhVjwk/btsJv7G2rQP/Avy7SYhAqXcJP4nk9zmrH0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbhVjwk%2FbtsJv7G2rQP%2FAvy7SYhAqXcJP4nk9zmrH0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"004.jpg\" data-origin-width=\"833\" data-origin-height=\"501\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">문제의 플러그인을 찾았습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>Disable Elements for WPBakery Page Builder</b></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">위 플러그인의 기능은 페이지빌더에 나타나는 각종 엘리먼트(요소)들을 비활성화해서 편집화면을 간단하게 보이도록 할 수 있는 아주 유용한 플러그인입니다. 이것을 사용하지 않으면 아래처럼 엄청나게 많은 요소들이 나타납니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"005.jpg\" data-origin-width=\"2637\" data-origin-height=\"1089\"><span data-url=\"https://blog.kakaocdn.net/dn/c2UOgP/btsJvvn3YA6/TuExidEL3hiNxQILJXna51/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/c2UOgP/btsJvvn3YA6/TuExidEL3hiNxQILJXna51/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/c2UOgP/btsJvvn3YA6/TuExidEL3hiNxQILJXna51/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc2UOgP%2FbtsJvvn3YA6%2FTuExidEL3hiNxQILJXna51%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"005.jpg\" data-origin-width=\"2637\" data-origin-height=\"1089\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">원하는 요소를 찾기도 어렵죠. 자주 사용하거나 필수 요소만 나타나도록 한다면 좋겠죠? 이를 사용하면 아래처럼 간단하게 보입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"006.jpg\" data-origin-width=\"2659\" data-origin-height=\"489\"><span data-url=\"https://blog.kakaocdn.net/dn/Gu5d1/btsJvbDkhbH/F4zfgKJIpSbmKi0SibmNn1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/Gu5d1/btsJvbDkhbH/F4zfgKJIpSbmKi0SibmNn1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/Gu5d1/btsJvbDkhbH/F4zfgKJIpSbmKi0SibmNn1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FGu5d1%2FbtsJvbDkhbH%2FF4zfgKJIpSbmKi0SibmNn1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"006.jpg\" data-origin-width=\"2659\" data-origin-height=\"489\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">원하는 요소를 바로 찾을 수 있죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">뭐가 문제였을까 생각해보니 우커머스 관련 페이지를 만드는 숏코드가 있는 요소가 포함돼지 않았기 때문입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"007.jpg\" data-origin-width=\"1042\" data-origin-height=\"1000\"><span data-url=\"https://blog.kakaocdn.net/dn/b16NEI/btsJuUaMsvo/zhGZtudfmQNH4wwjGKekT1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/b16NEI/btsJuUaMsvo/zhGZtudfmQNH4wwjGKekT1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/b16NEI/btsJuUaMsvo/zhGZtudfmQNH4wwjGKekT1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb16NEI%2FbtsJuUaMsvo%2FzhGZtudfmQNH4wwjGKekT1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"007.jpg\" data-origin-width=\"1042\" data-origin-height=\"1000\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 플러그인의 설정화면으로 가서 해당 숏코드가 있는 요소를 활성화 하니 이제 제대로 보입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"008.jpg\" data-origin-width=\"1506\" data-origin-height=\"1020\"><span data-url=\"https://blog.kakaocdn.net/dn/evWUqO/btsJt0JTos0/TiwKqkfTAt0pivMFdwrUbk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/evWUqO/btsJt0JTos0/TiwKqkfTAt0pivMFdwrUbk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/evWUqO/btsJt0JTos0/TiwKqkfTAt0pivMFdwrUbk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FevWUqO%2FbtsJt0JTos0%2FTiwKqkfTAt0pivMFdwrUbk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"008.jpg\" data-origin-width=\"1506\" data-origin-height=\"1020\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">수많은 사이트를 만들어봤는데도 처음 보는 문제를 접하게 되면 상당히 당황스럽습니다. 설마하던 플러그인에서 문제가 발생할줄이야 꿈에도 생각지 못했지만 항상 그렇듯이 기본은 우선 플러그인을 비활성화 해보는 것이 좋습니다.</p>",
        "contentSnippet": "우커머스 쇼핑몰을 개발하다보면 제일 먼저 하는 것이 테마와 모든 플러그인을 설치하고 결제까지 진행해서 테스트 결제를 완료합니다. 그 이후로는 원하는 기능과 디자인을 진행합니다. 기능개선을 위해 별도의 플러그인을 설치하기도 하죠. 이러다보면 기존에 잘 작동하던 기능도 갑자기 안되기도 합니다.\n \n\n\n \n장바구니에 들어가니 위처럼 숏코드가 나타납니다. 원래대로라면 아래처럼 나타나야 합니다.\n \n\n\n \n우커머스 숏코드가 작동하지 않는 것이죠. 다른 숏코드로 그런가 해서 결제페이지로 가도 마찬가지로 작동하지 않습니다. 그래서 아래의 화면으로 가서 각 페이지들이 연결이 잘 돼있나 확인해봅니다.\n \n\n\n \n원래 대로 제대로 돼있습니다.\n \n뭐가 문제일까.. 이런 경우는 처음입니다. 플러그인이 문제일 것이다라고 생각하고 테마를 기본 테마로 변경하고 플러그인을 다섯 개씩 비활성화 해봅니다.\n \n\n\n \n문제의 플러그인을 찾았습니다.\n \nDisable Elements for WPBakery Page Builder\n \n위 플러그인의 기능은 페이지빌더에 나타나는 각종 엘리먼트(요소)들을 비활성화해서 편집화면을 간단하게 보이도록 할 수 있는 아주 유용한 플러그인입니다. 이것을 사용하지 않으면 아래처럼 엄청나게 많은 요소들이 나타납니다.\n \n\n\n \n원하는 요소를 찾기도 어렵죠. 자주 사용하거나 필수 요소만 나타나도록 한다면 좋겠죠? 이를 사용하면 아래처럼 간단하게 보입니다.\n \n\n\n \n원하는 요소를 바로 찾을 수 있죠.\n \n뭐가 문제였을까 생각해보니 우커머스 관련 페이지를 만드는 숏코드가 있는 요소가 포함돼지 않았기 때문입니다.\n \n\n\n \n이 플러그인의 설정화면으로 가서 해당 숏코드가 있는 요소를 활성화 하니 이제 제대로 보입니다.\n \n\n\n \n수많은 사이트를 만들어봤는데도 처음 보는 문제를 접하게 되면 상당히 당황스럽습니다. 설마하던 플러그인에서 문제가 발생할줄이야 꿈에도 생각지 못했지만 항상 그렇듯이 기본은 우선 플러그인을 비활성화 해보는 것이 좋습니다.",
        "guid": "http://martian36.tistory.com/1635",
        "categories": [
          "워드프레스/플러그인"
        ],
        "isoDate": "2024-09-08T02:14:11.000Z"
      }
    ]
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김놀부",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "가성비부터 프리미엄까지, 2024년 최고의 무선 이어폰",
        "link": "http://muzbox.tistory.com/483468",
        "pubDate": "Wed, 11 Sep 2024 08:30:01 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483468#entry483468comment",
        "content": "<p data-ke-size=\"size16\">2024년 최고의 무선 이어폰을 소개합니다. Apple AirPods Pro의 뛰어난 소프트웨어 커스터마이징, Bose QC Ultra의 자연스러운 노이즈 캔슬링, Soundcore Liberty 4 NC의 합리적인 가격과 긴 배터리 수명을 비교하여 최적의 선택을 도와드립니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"1231231.png\" data-origin-width=\"2000\" data-origin-height=\"1125\"><span data-url=\"https://blog.kakaocdn.net/dn/3WxRg/btsJxjIJ4kh/16sKPwGqZKaSEDpvzugbA1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/3WxRg/btsJxjIJ4kh/16sKPwGqZKaSEDpvzugbA1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/3WxRg/btsJxjIJ4kh/16sKPwGqZKaSEDpvzugbA1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F3WxRg%2FbtsJxjIJ4kh%2F16sKPwGqZKaSEDpvzugbA1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"가성비부터 프리미엄까지, 2024년 최고의 무선 이어폰\" data-filename=\"1231231.png\" data-origin-width=\"2000\" data-origin-height=\"1125\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">무선 이어폰 시장은 최근 몇 년 사이에 급격한 발전을 이루었습니다. Apple이 iPhone과 함께 제공되던 EarPods의 케이블을 없애면서 무선 이어폰 시장에 큰 변화를 일으켰고, 이후 수많은 브랜드들이 뒤따라 나오기 시작했습니다. 하지만 이렇게 많은 선택지 속에서 자신에게 가장 적합한 무선 이어폰을 찾는 일은 쉽지 않습니다. 이번 기사에서는 다양한 상황에서 최고의 성능을 발휘하는 무선 이어폰들을 추천하며, 각 제품의 장단점을 상세히 분석해보겠습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>1. Apple AirPods Pro: 최고의 소프트웨어와 놀라운 음질</b></span></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"1a.jpg\" data-origin-width=\"492\" data-origin-height=\"492\"><span data-url=\"https://blog.kakaocdn.net/dn/cnQhOC/btsJwSdX673/PUXuOVyBLAghfDkiynUrWk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cnQhOC/btsJwSdX673/PUXuOVyBLAghfDkiynUrWk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cnQhOC/btsJwSdX673/PUXuOVyBLAghfDkiynUrWk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcnQhOC%2FbtsJwSdX673%2FPUXuOVyBLAghfDkiynUrWk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"1a.jpg\" data-origin-width=\"492\" data-origin-height=\"492\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">Apple AirPods Pro는 여전히 무선 이어폰 시장에서 최고의 선택 중 하나로 꼽힙니다. 특히 Apple 사용자뿐만 아니라 모든 무선 이어폰 사용자에게 적합한 기능을 제공합니다. 이 이어폰의 주요 장점은 뛰어난 소프트웨어 커스터마이징, 탁월한 공간 오디오 기능, 그리고 효과적인 노이즈 캔슬링 기능입니다. Apple은 오디오 연구에 엄청난 투자를 하여 탁월한 적응형 노이즈 캔슬링 기능을 제공하며, 이는 시끄러운 커피숍에서의 잡음이나 HVAC 시스템의 소음을 완벽하게 차단해줍니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">AirPods Pro의 음질도 매우 인상적입니다. Apple의 새로운 Adaptive 및 Spatial Audio 기능 덕분에 주변 환경과 귀 모양에 맞춰 소리를 조정하며, 모든 음악 장르에 적합한 고품질 사운드를 제공합니다. 다만, 배터리 사용 시간은 광고된 30시간보다 약간 짧은 20~25시간 정도로 측정되었습니다. 이는 실제 사용 환경에 따라 다를 수 있지만, 여전히 인상적인 성능입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"1b.jpg\" data-origin-width=\"902\" data-origin-height=\"1125\"><span data-url=\"https://blog.kakaocdn.net/dn/O5oiP/btsJytw66nD/aXenNFeZ9ojCZYkA5kWnv1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/O5oiP/btsJytw66nD/aXenNFeZ9ojCZYkA5kWnv1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/O5oiP/btsJytw66nD/aXenNFeZ9ojCZYkA5kWnv1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FO5oiP%2FbtsJytw66nD%2FaXenNFeZ9ojCZYkA5kWnv1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"1b.jpg\" data-origin-width=\"902\" data-origin-height=\"1125\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b><i>장점:</i></b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>뛰어난 노이즈 캔슬링</li>\n<li>인상적인 적응형 오디오 기능</li>\n<li>견고한 디자인과 마감</li>\n</ul>\n<p data-ke-size=\"size16\"><b><i>단점:</i></b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>배터리 수명이 광고보다 짧음</li>\n<li>높은 가격대</li>\n</ul>\n<div class=\"product-details-button-wrapper\">\n    <style>\n        .product-details-button-wrapper .button-container {\n            display: flex;\n            justify-content: center;\n            align-items: center;\n            padding: 20px 0;\n        }\n        .product-details-button-wrapper .product-details-button {\n            width: 600px;\n            height: 100px;\n            font-family: '맑은 고딕', 'Malgun Gothic', sans-serif;\n            font-weight: bold;\n            font-size: 24px;\n            color: white;\n            background: linear-gradient(145deg, #3498db, #2980b9);\n            border: 4px solid #1f618d;\n            border-radius: 15px;\n            cursor: pointer;\n            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);\n            transition: all 0.3s ease;\n            overflow: hidden;\n            position: relative;\n        }\n        .product-details-button-wrapper .product-details-button:hover {\n            transform: translateY(-3px);\n            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);\n        }\n        .product-details-button-wrapper .button-text {\n            position: relative;\n            z-index: 1;\n            animation: sparkle 1.5s infinite;\n        }\n        @keyframes sparkle {\n            0%, 100% { opacity: 1; }\n            50% { opacity: 0.7; }\n        }\n    </style>\n    <div class=\"button-container\">\n        <button class=\"product-details-button\">\n            <span class=\"button-text\">제품 상세 정보는 여기를 클릭하세요</span>\n        </button>\n    </div>\n    <script>\n        (function() {\n            var wrapper = document.currentScript.closest('.product-details-button-wrapper');\n            var button = wrapper.querySelector('.product-details-button');\n            // URL을 여기에 삽입하세요\n            var productDetailsUrl = \"https://link.coupang.com/a/bRC9ov\";\n            button.addEventListener(\"click\", function() {\n                window.open(productDetailsUrl, '_blank');\n            });\n        })();\n    </script>\n    <p style=\"text-align: center;\" data-ke-size=\"size14\"><span style=\"background-color: #ffffff; color: #0f0f0f; text-align: start;\">&lt;이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.&gt;</span></p>\n</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>2. Bose QC Ultra Earbuds: 자연스러운 노이즈 캔슬링과 맞춤형 사운드</b></span></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"2a.png\" data-origin-width=\"492\" data-origin-height=\"492\"><span data-url=\"https://blog.kakaocdn.net/dn/7PjMk/btsJyGpruSk/OGIk6kd6sAY8eKkE2nUkXK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/7PjMk/btsJyGpruSk/OGIk6kd6sAY8eKkE2nUkXK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/7PjMk/btsJyGpruSk/OGIk6kd6sAY8eKkE2nUkXK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F7PjMk%2FbtsJyGpruSk%2FOGIk6kd6sAY8eKkE2nUkXK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"2a.png\" data-origin-width=\"492\" data-origin-height=\"492\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">Bose QC Ultra 이어버드는 Bose의 특유의 자연스럽고 효과적인 노이즈 캔슬링 기능으로 주목받습니다. 이 이어폰은 특히 기차역, 시끄러운 거리, 그리고 야간 사용 등 다양한 상황에서 사용해도 음악의 질을 유지하면서 주변 소음을 잘 차단해줍니다. Bose Music 앱을 통해 소리를 사용자 취향에 맞게 조정할 수 있는 기능도 제공합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">다만, 배터리 수명은 이어버드 자체로는 약 6시간, 케이스를 사용할 경우 추가 10~12시간 정도로 다소 제한적입니다. 하지만 저렴한 가격과 인상적인 사운드 품질 덕분에 여전히 많은 소비자들에게 매력적인 선택지입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"2b.jpg\" data-origin-width=\"737\" data-origin-height=\"856\"><span data-url=\"https://blog.kakaocdn.net/dn/szUC0/btsJwPheSp8/JtKgjKNIxL926zZxXCBVMK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/szUC0/btsJwPheSp8/JtKgjKNIxL926zZxXCBVMK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/szUC0/btsJwPheSp8/JtKgjKNIxL926zZxXCBVMK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FszUC0%2FbtsJwPheSp8%2FJtKgjKNIxL926zZxXCBVMK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"2b.jpg\" data-origin-width=\"737\" data-origin-height=\"856\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b><i>장점:</i></b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>탁월하고 자연스러운 노이즈 캔슬링</li>\n<li>견고한 소리 품질과 맞춤화 가능</li>\n<li>아름다운 디자인과 착용감</li>\n</ul>\n<p data-ke-size=\"size16\"><b><i>단점:</i></b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>케이스와 함께 사용 시 배터리 수명이 제한적</li>\n<li>블루투스 연결 문제 발생 가능성</li>\n</ul>\n<div class=\"product-details-button-wrapper\">\n    <style>\n        .product-details-button-wrapper .button-container {\n            display: flex;\n            justify-content: center;\n            align-items: center;\n            padding: 20px 0;\n        }\n        .product-details-button-wrapper .product-details-button {\n            width: 600px;\n            height: 100px;\n            font-family: '맑은 고딕', 'Malgun Gothic', sans-serif;\n            font-weight: bold;\n            font-size: 24px;\n            color: white;\n            background: linear-gradient(145deg, #3498db, #2980b9);\n            border: 4px solid #1f618d;\n            border-radius: 15px;\n            cursor: pointer;\n            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);\n            transition: all 0.3s ease;\n            overflow: hidden;\n            position: relative;\n        }\n        .product-details-button-wrapper .product-details-button:hover {\n            transform: translateY(-3px);\n            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);\n        }\n        .product-details-button-wrapper .button-text {\n            position: relative;\n            z-index: 1;\n            animation: sparkle 1.5s infinite;\n        }\n        @keyframes sparkle {\n            0%, 100% { opacity: 1; }\n            50% { opacity: 0.7; }\n        }\n    </style>\n    <div class=\"button-container\">\n        <button class=\"product-details-button\">\n            <span class=\"button-text\">제품 상세 정보는 여기를 클릭하세요</span>\n        </button>\n    </div>\n    <script>\n        (function() {\n            var wrapper = document.currentScript.closest('.product-details-button-wrapper');\n            var button = wrapper.querySelector('.product-details-button');\n            // URL을 여기에 삽입하세요\n            var productDetailsUrl = \"https://link.coupang.com/a/bRC9K8\";\n            button.addEventListener(\"click\", function() {\n                window.open(productDetailsUrl, '_blank');\n            });\n        })();\n    </script>\n    <p style=\"text-align: center;\" data-ke-size=\"size14\"><span style=\"background-color: #ffffff; color: #0f0f0f; text-align: start;\">&lt;이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.&gt;</span></p>\n</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>3. Soundcore Liberty 4 NC: 가격 대비 높은 성능과 긴 배터리 수명</b></span></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"3a.jpg\" data-origin-width=\"492\" data-origin-height=\"492\"><span data-url=\"https://blog.kakaocdn.net/dn/3UqPZ/btsJxw829MQ/K9EQuIcnTwtj3Ah956OWqK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/3UqPZ/btsJxw829MQ/K9EQuIcnTwtj3Ah956OWqK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/3UqPZ/btsJxw829MQ/K9EQuIcnTwtj3Ah956OWqK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F3UqPZ%2FbtsJxw829MQ%2FK9EQuIcnTwtj3Ah956OWqK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"3a.jpg\" data-origin-width=\"492\" data-origin-height=\"492\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">Soundcore Liberty 4 NC는 합리적인 가격에 고성능의 무선 이어폰을 제공하여 가성비를 중요시하는 소비자들에게 좋은 선택입니다. 이 제품은 최대 50시간의 배터리 수명을 제공하며, 한번 충전으로 최대 10시간 사용이 가능합니다. 디자인도 독특하여 이어폰을 꺼내고 넣는 동작이 편리하게 설계되어 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">사운드 품질 측면에서는 가격 대비 매우 우수하지만, Apple이나 Bose의 고급 제품보다는 약간 부족할 수 있습니다. 플라스틱 소재를 사용하여 무게를 줄인 점은 장점이지만, 프리미엄 느낌이 부족할 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"3b.jpg\" data-origin-width=\"772\" data-origin-height=\"771\"><span data-url=\"https://blog.kakaocdn.net/dn/c08lkR/btsJwSkIvAR/doKHe0E1elbk1tIXindrF0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/c08lkR/btsJwSkIvAR/doKHe0E1elbk1tIXindrF0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/c08lkR/btsJwSkIvAR/doKHe0E1elbk1tIXindrF0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc08lkR%2FbtsJwSkIvAR%2FdoKHe0E1elbk1tIXindrF0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"3b.jpg\" data-origin-width=\"772\" data-origin-height=\"771\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b><i>장점:</i></b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>뛰어난 가성비</li>\n<li>긴 배터리 수명</li>\n<li>재미있는 디자인과 다양한 색상</li>\n</ul>\n<p data-ke-size=\"size16\"><b><i>단점:</i></b></p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>음질이 Apple이나 Bose 제품보다 다소 떨어짐</li>\n<li>플라스틱 소재 사용으로 프리미엄 느낌이 부족</li>\n</ul>\n<div class=\"product-details-button-wrapper\">\n    <style>\n        .product-details-button-wrapper .button-container {\n            display: flex;\n            justify-content: center;\n            align-items: center;\n            padding: 20px 0;\n        }\n        .product-details-button-wrapper .product-details-button {\n            width: 600px;\n            height: 100px;\n            font-family: '맑은 고딕', 'Malgun Gothic', sans-serif;\n            font-weight: bold;\n            font-size: 24px;\n            color: white;\n            background: linear-gradient(145deg, #3498db, #2980b9);\n            border: 4px solid #1f618d;\n            border-radius: 15px;\n            cursor: pointer;\n            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);\n            transition: all 0.3s ease;\n            overflow: hidden;\n            position: relative;\n        }\n        .product-details-button-wrapper .product-details-button:hover {\n            transform: translateY(-3px);\n            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);\n        }\n        .product-details-button-wrapper .button-text {\n            position: relative;\n            z-index: 1;\n            animation: sparkle 1.5s infinite;\n        }\n        @keyframes sparkle {\n            0%, 100% { opacity: 1; }\n            50% { opacity: 0.7; }\n        }\n    </style>\n    <div class=\"button-container\">\n        <button class=\"product-details-button\">\n            <span class=\"button-text\">제품 상세 정보는 여기를 클릭하세요</span>\n        </button>\n    </div>\n    <script>\n        (function() {\n            var wrapper = document.currentScript.closest('.product-details-button-wrapper');\n            var button = wrapper.querySelector('.product-details-button');\n            // URL을 여기에 삽입하세요\n            var productDetailsUrl = \"https://link.coupang.com/a/bRC9YC\";\n            button.addEventListener(\"click\", function() {\n                window.open(productDetailsUrl, '_blank');\n            });\n        })();\n    </script>\n    <p style=\"text-align: center;\" data-ke-size=\"size14\"><span style=\"background-color: #ffffff; color: #0f0f0f; text-align: start;\">&lt;이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.&gt;</span></p>\n</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>결론</b></span></h2>\n<p data-ke-size=\"size16\">무선 이어폰을 선택할 때는 사용자의 필요와 예산에 맞춰 다양한 옵션을 고려해야 합니다. Apple AirPods Pro는 최고급 성능과 기능을 자랑하며, Bose QC Ultra Earbuds는 자연스러운 노이즈 캔슬링과 뛰어난 사운드 품질을 제공합니다. Soundcore Liberty 4 NC는 가성비를 중시하는 소비자에게 적합한 제품입니다. 각 제품의 장단점을 잘 비교해보시고, 자신에게 가장 잘 맞는 무선 이어폰을 선택하시기 바랍니다.</p>\n<div id=\"gtx-trans\" style=\"position: absolute; left: -64px; top: 6781.2px;\">\n<div class=\"gtx-trans-icon\">&nbsp;</div>\n</div>",
        "contentSnippet": "2024년 최고의 무선 이어폰을 소개합니다. Apple AirPods Pro의 뛰어난 소프트웨어 커스터마이징, Bose QC Ultra의 자연스러운 노이즈 캔슬링, Soundcore Liberty 4 NC의 합리적인 가격과 긴 배터리 수명을 비교하여 최적의 선택을 도와드립니다.\n\n\n \n무선 이어폰 시장은 최근 몇 년 사이에 급격한 발전을 이루었습니다. Apple이 iPhone과 함께 제공되던 EarPods의 케이블을 없애면서 무선 이어폰 시장에 큰 변화를 일으켰고, 이후 수많은 브랜드들이 뒤따라 나오기 시작했습니다. 하지만 이렇게 많은 선택지 속에서 자신에게 가장 적합한 무선 이어폰을 찾는 일은 쉽지 않습니다. 이번 기사에서는 다양한 상황에서 최고의 성능을 발휘하는 무선 이어폰들을 추천하며, 각 제품의 장단점을 상세히 분석해보겠습니다.\n \n \n1. Apple AirPods Pro: 최고의 소프트웨어와 놀라운 음질\n\n\nApple AirPods Pro는 여전히 무선 이어폰 시장에서 최고의 선택 중 하나로 꼽힙니다. 특히 Apple 사용자뿐만 아니라 모든 무선 이어폰 사용자에게 적합한 기능을 제공합니다. 이 이어폰의 주요 장점은 뛰어난 소프트웨어 커스터마이징, 탁월한 공간 오디오 기능, 그리고 효과적인 노이즈 캔슬링 기능입니다. Apple은 오디오 연구에 엄청난 투자를 하여 탁월한 적응형 노이즈 캔슬링 기능을 제공하며, 이는 시끄러운 커피숍에서의 잡음이나 HVAC 시스템의 소음을 완벽하게 차단해줍니다.\n \nAirPods Pro의 음질도 매우 인상적입니다. Apple의 새로운 Adaptive 및 Spatial Audio 기능 덕분에 주변 환경과 귀 모양에 맞춰 소리를 조정하며, 모든 음악 장르에 적합한 고품질 사운드를 제공합니다. 다만, 배터리 사용 시간은 광고된 30시간보다 약간 짧은 20~25시간 정도로 측정되었습니다. 이는 실제 사용 환경에 따라 다를 수 있지만, 여전히 인상적인 성능입니다.\n\n\n \n장점:\n뛰어난 노이즈 캔슬링\n인상적인 적응형 오디오 기능\n견고한 디자인과 마감\n단점:\n배터리 수명이 광고보다 짧음\n높은 가격대\n제품 상세 정보는 여기를 클릭하세요\n        \n    \n<이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.>\n \n \n2. Bose QC Ultra Earbuds: 자연스러운 노이즈 캔슬링과 맞춤형 사운드\n\n\nBose QC Ultra 이어버드는 Bose의 특유의 자연스럽고 효과적인 노이즈 캔슬링 기능으로 주목받습니다. 이 이어폰은 특히 기차역, 시끄러운 거리, 그리고 야간 사용 등 다양한 상황에서 사용해도 음악의 질을 유지하면서 주변 소음을 잘 차단해줍니다. Bose Music 앱을 통해 소리를 사용자 취향에 맞게 조정할 수 있는 기능도 제공합니다.\n \n다만, 배터리 수명은 이어버드 자체로는 약 6시간, 케이스를 사용할 경우 추가 10~12시간 정도로 다소 제한적입니다. 하지만 저렴한 가격과 인상적인 사운드 품질 덕분에 여전히 많은 소비자들에게 매력적인 선택지입니다.\n\n\n \n장점:\n탁월하고 자연스러운 노이즈 캔슬링\n견고한 소리 품질과 맞춤화 가능\n아름다운 디자인과 착용감\n단점:\n케이스와 함께 사용 시 배터리 수명이 제한적\n블루투스 연결 문제 발생 가능성\n제품 상세 정보는 여기를 클릭하세요\n        \n    \n<이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.>\n \n \n3. Soundcore Liberty 4 NC: 가격 대비 높은 성능과 긴 배터리 수명\n\n\nSoundcore Liberty 4 NC는 합리적인 가격에 고성능의 무선 이어폰을 제공하여 가성비를 중요시하는 소비자들에게 좋은 선택입니다. 이 제품은 최대 50시간의 배터리 수명을 제공하며, 한번 충전으로 최대 10시간 사용이 가능합니다. 디자인도 독특하여 이어폰을 꺼내고 넣는 동작이 편리하게 설계되어 있습니다.\n \n사운드 품질 측면에서는 가격 대비 매우 우수하지만, Apple이나 Bose의 고급 제품보다는 약간 부족할 수 있습니다. 플라스틱 소재를 사용하여 무게를 줄인 점은 장점이지만, 프리미엄 느낌이 부족할 수 있습니다.\n\n\n \n장점:\n뛰어난 가성비\n긴 배터리 수명\n재미있는 디자인과 다양한 색상\n단점:\n음질이 Apple이나 Bose 제품보다 다소 떨어짐\n플라스틱 소재 사용으로 프리미엄 느낌이 부족\n제품 상세 정보는 여기를 클릭하세요\n        \n    \n<이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.>\n \n \n결론\n무선 이어폰을 선택할 때는 사용자의 필요와 예산에 맞춰 다양한 옵션을 고려해야 합니다. Apple AirPods Pro는 최고급 성능과 기능을 자랑하며, Bose QC Ultra Earbuds는 자연스러운 노이즈 캔슬링과 뛰어난 사운드 품질을 제공합니다. Soundcore Liberty 4 NC는 가성비를 중시하는 소비자에게 적합한 제품입니다. 각 제품의 장단점을 잘 비교해보시고, 자신에게 가장 잘 맞는 무선 이어폰을 선택하시기 바랍니다.",
        "guid": "http://muzbox.tistory.com/483468",
        "categories": [
          "신제품 리뷰/주변기기",
          "2024 최고의 이어폰",
          "Apple AirPods Pro",
          "bose qc ultra",
          "soundcore liberty 4 nc",
          "가성비 좋은 이어폰",
          "고품질 음향 기기",
          "노이즈 캔슬링 이어폰",
          "무선 이어폰",
          "블루투스 이어폰"
        ],
        "isoDate": "2024-09-10T23:30:01.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "인텔 코어 i5 vs AMD 라이젠 5, 어떤 CPU가 더 나을까?",
        "link": "http://muzbox.tistory.com/483467",
        "pubDate": "Mon, 9 Sep 2024 09:12:09 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483467#entry483467comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;AMD의 라이젠 5와 인텔의 코어 i5는 오늘날 가장 인기 있는 미드레인지 CPU입니다. 이 두 제품 중 어떤 것을 선택해야 할지 고민되시나요? 각 프로세서의 성능, 아키텍처, 전력 소비량, 가격 등의 요소를 비교하여 어느 제품이 더 나은 선택인지 알아보세요.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"cpu compare.jpg\" data-origin-width=\"747\" data-origin-height=\"747\"><span data-url=\"https://blog.kakaocdn.net/dn/bFQLkn/btsJvoWYkZM/ljTqlxUWFagdzteKbSXXWK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bFQLkn/btsJvoWYkZM/ljTqlxUWFagdzteKbSXXWK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bFQLkn/btsJvoWYkZM/ljTqlxUWFagdzteKbSXXWK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbFQLkn%2FbtsJvoWYkZM%2FljTqlxUWFagdzteKbSXXWK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"인텔 코어 i5 vs AMD 라이젠 5, 어떤 CPU가 더 나을까?\" width=\"500\" height=\"500\" data-filename=\"cpu compare.jpg\" data-origin-width=\"747\" data-origin-height=\"747\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;CPU는 컴퓨터 성능의 핵심 요소 중 하나로, 올바른 선택은 사용자 경험에 큰 영향을 미칩니다. 미드레인지 CPU의 대표적인 두 경쟁자인 인텔 코어 i5와 AMD 라이젠 5는 모두 게이머와 전문가들에게 매우 인기 있는 옵션입니다. 그러나 이 두 제품 간의 차이점과 각 프로세서가 제공하는 가치를 명확히 이해해야 합니다. 이 블로그에서는 인텔 코어 i5와 AMD 라이젠 5를 다양한 측면에서 비교하여 어떤 CPU가 여러분에게 더 적합한지에 대해 알아봅니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>인텔 코어 i5와 AMD 라이젠 5의 기본 비교</b></span></h2>\n<p data-ke-size=\"size16\"><span style=\"color: #ee2323;\"><b>인텔 코어 i5의 특장점</b></span><br />인텔 코어 i5는 2009년에 처음 출시되었으며, 성능과 효율성 사이에서 뛰어난 균형을 제공합니다. 이 CPU는 하이브리드 아키텍처를 사용하여 성능 지향적인 코어(P-코어)와 에너지 효율이 높은 코어(E-코어)를 결합하여 리소스 사용을 최적화합니다. 코어 i5는 싱글 코어 성능에서 AMD 라이젠 5보다 약간 앞서지만, 멀티코어 성능에서는 라이젠 5에 뒤처지는 경향이 있습니다. 이 프로세서는 하이퍼스레딩을 지원하여 각 물리적 코어가 두 개의 스레드를 동시에 처리할 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"color: #ee2323;\"><b>AMD 라이젠 5의 특장점</b></span><br />AMD 라이젠 5는 2017년에 출시된 이후 뛰어난 멀티스레딩 성능과 경쟁력 있는 가격으로 주목받고 있습니다. Zen 아키텍처를 기반으로 하는 이 프로세서는 보통 인텔보다 더 많은 코어 수와 빠른 클럭 속도를 제공합니다. 최신 Zen 5 아키텍처는 16%의 성능 향상과 전력 소비의 큰 감소를 가져왔습니다. 그러나 인텔 코어 i5와 달리, 라이젠 5는 통합 그래픽이 없기 때문에 별도의 GPU가 필요합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b><span style=\"color: #006dd7;\">인텔 코어 i5 vs AMD 라이젠 5: 성능 비교</span></b></h2>\n<p data-ke-size=\"size16\"><span style=\"color: #ee2323;\"><b>입문형: 코어 i5-12600K vs 라이젠 5 5600X</b></span><br />이 두 CPU는 예산에 민감한 빌드를 위해 적합하며 일상적인 작업과 가벼운 게임을 처리할 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"코어 i5-12600K vs 라이젠 5 5600X.png\" data-origin-width=\"844\" data-origin-height=\"639\"><span data-url=\"https://blog.kakaocdn.net/dn/bjWa1b/btsJwaYjxpT/H2ZedVipUbc1PqknEjj2k1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bjWa1b/btsJwaYjxpT/H2ZedVipUbc1PqknEjj2k1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bjWa1b/btsJwaYjxpT/H2ZedVipUbc1PqknEjj2k1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbjWa1b%2FbtsJwaYjxpT%2FH2ZedVipUbc1PqknEjj2k1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"코어 i5-12600K vs 라이젠 5 5600X.png\" data-origin-width=\"844\" data-origin-height=\"639\"/></span></figure>\n</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>아키텍처 및 코어 수</b>: 코어 i5-12600K는 6개의 성능 코어와 4개의 효율 코어로 구성된 10개의 코어와 16개의 스레드를 제공합니다. 반면에 AMD 라이젠 5 5600X는 6개의 코어와 12개의 스레드를 가지고 있습니다.</li>\n<li><b>클럭 속도</b>: 코어 i5-12600K는 최대 4.9GHz까지 부스트가 가능하며, 라이젠 5 5600X는 최대 4.6GHz입니다.</li>\n<li><b>캐시 및 메모리 타입</b>: 코어 i5-12600K는 20MB의 스마트 캐시를 제공하는 반면, 라이젠 5 5600X는 32MB의 L3 캐시를 갖추고 있습니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"color: #ee2323;\"><b>중급형: 코어 i5-13600K vs 라이젠 5 7600X</b></span><br />중급형 프로세서로, 고사양 게임이나 비디오 편집과 같은 보다 높은 요구 사항을 처리할 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"코어 i5-13600K vs 라이젠 5 7600X.png\" data-origin-width=\"843\" data-origin-height=\"640\"><span data-url=\"https://blog.kakaocdn.net/dn/cluU5t/btsJwcPhwux/ZiHdPJPGJU4xd7bePOVvM0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cluU5t/btsJwcPhwux/ZiHdPJPGJU4xd7bePOVvM0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cluU5t/btsJwcPhwux/ZiHdPJPGJU4xd7bePOVvM0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcluU5t%2FbtsJwcPhwux%2FZiHdPJPGJU4xd7bePOVvM0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"코어 i5-13600K vs 라이젠 5 7600X.png\" data-origin-width=\"843\" data-origin-height=\"640\"/></span></figure>\n</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>아키텍처 및 코어 수</b>: 코어 i5-13600K는 14개의 코어(6개의 성능 + 8개의 효율 코어)와 20개의 스레드를 제공하며, 라이젠 5 7600X는 6개의 코어와 12개의 스레드를 가지고 있습니다.</li>\n<li><b>전력 소비</b>: 라이젠 5 7600X는 105W의 낮은 전력 소비를 자랑하며, 코어 i5-13600K는 125W입니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"color: #ee2323;\"><b>고급형: 코어 i5-14600K vs 라이젠 5 9600X</b></span><br />이 프로세서들은 고사양 작업을 처리하기에 적합합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"코어 i5-14600K vs 라이젠 5 9600X.png\" data-origin-width=\"842\" data-origin-height=\"642\"><span data-url=\"https://blog.kakaocdn.net/dn/outBD/btsJvRR86VD/NkdXejqJVWlnjTOoZoUk11/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/outBD/btsJvRR86VD/NkdXejqJVWlnjTOoZoUk11/img.png\"><img src=\"https://blog.kakaocdn.net/dn/outBD/btsJvRR86VD/NkdXejqJVWlnjTOoZoUk11/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FoutBD%2FbtsJvRR86VD%2FNkdXejqJVWlnjTOoZoUk11%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"코어 i5-14600K vs 라이젠 5 9600X.png\" data-origin-width=\"842\" data-origin-height=\"642\"/></span></figure>\n</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>아키텍처 및 코어 수</b>: 라이젠 5 9600X는 6개의 코어와 12개의 스레드를 제공하며, 코어 i5-14600K는 14개의 코어(6개의 성능 코어와 8개의 효율 코어)와 20개의 스레드를 갖추고 있습니다.</li>\n<li><b>성능 및 가격 비교</b>: 코어 i5-14600K는 $350의 가격으로 라이젠 5 9600X의 $279보다 비싸지만, 더 나은 종합 성능을 제공합니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>결론: 어떤 CPU를 선택해야 할까요?</b></span></h2>\n<p data-ke-size=\"size16\">결국, 인텔 코어 i5와 AMD 라이젠 5는 각각 다른 시장을 겨냥하고 있습니다. 라이젠 5는 높은 클럭 속도와 더 낮은 TDP를 제공하며, 코어 i5는 전반적인 성능에서 더 높은 점수를 받습니다. 게이머와 콘텐츠 제작자는 싱글 코어 성능이 뛰어난 코어 i5를 선호할 수 있으며, 멀티태스킹과 에너지 효율성을 중요시하는 사용자는 라이젠 5를 선택할 가능성이 큽니다. 최종 선택은 예산과 용도에 따라 달라집니다.</p>",
        "contentSnippet": "AMD의 라이젠 5와 인텔의 코어 i5는 오늘날 가장 인기 있는 미드레인지 CPU입니다. 이 두 제품 중 어떤 것을 선택해야 할지 고민되시나요? 각 프로세서의 성능, 아키텍처, 전력 소비량, 가격 등의 요소를 비교하여 어느 제품이 더 나은 선택인지 알아보세요.\n\n\n \n CPU는 컴퓨터 성능의 핵심 요소 중 하나로, 올바른 선택은 사용자 경험에 큰 영향을 미칩니다. 미드레인지 CPU의 대표적인 두 경쟁자인 인텔 코어 i5와 AMD 라이젠 5는 모두 게이머와 전문가들에게 매우 인기 있는 옵션입니다. 그러나 이 두 제품 간의 차이점과 각 프로세서가 제공하는 가치를 명확히 이해해야 합니다. 이 블로그에서는 인텔 코어 i5와 AMD 라이젠 5를 다양한 측면에서 비교하여 어떤 CPU가 여러분에게 더 적합한지에 대해 알아봅니다.\n \n \n \n인텔 코어 i5와 AMD 라이젠 5의 기본 비교\n인텔 코어 i5의 특장점\n인텔 코어 i5는 2009년에 처음 출시되었으며, 성능과 효율성 사이에서 뛰어난 균형을 제공합니다. 이 CPU는 하이브리드 아키텍처를 사용하여 성능 지향적인 코어(P-코어)와 에너지 효율이 높은 코어(E-코어)를 결합하여 리소스 사용을 최적화합니다. 코어 i5는 싱글 코어 성능에서 AMD 라이젠 5보다 약간 앞서지만, 멀티코어 성능에서는 라이젠 5에 뒤처지는 경향이 있습니다. 이 프로세서는 하이퍼스레딩을 지원하여 각 물리적 코어가 두 개의 스레드를 동시에 처리할 수 있습니다.\n \nAMD 라이젠 5의 특장점\nAMD 라이젠 5는 2017년에 출시된 이후 뛰어난 멀티스레딩 성능과 경쟁력 있는 가격으로 주목받고 있습니다. Zen 아키텍처를 기반으로 하는 이 프로세서는 보통 인텔보다 더 많은 코어 수와 빠른 클럭 속도를 제공합니다. 최신 Zen 5 아키텍처는 16%의 성능 향상과 전력 소비의 큰 감소를 가져왔습니다. 그러나 인텔 코어 i5와 달리, 라이젠 5는 통합 그래픽이 없기 때문에 별도의 GPU가 필요합니다.\n \n \n인텔 코어 i5 vs AMD 라이젠 5: 성능 비교\n입문형: 코어 i5-12600K vs 라이젠 5 5600X\n이 두 CPU는 예산에 민감한 빌드를 위해 적합하며 일상적인 작업과 가벼운 게임을 처리할 수 있습니다.\n\n\n\n아키텍처 및 코어 수: 코어 i5-12600K는 6개의 성능 코어와 4개의 효율 코어로 구성된 10개의 코어와 16개의 스레드를 제공합니다. 반면에 AMD 라이젠 5 5600X는 6개의 코어와 12개의 스레드를 가지고 있습니다.\n클럭 속도: 코어 i5-12600K는 최대 4.9GHz까지 부스트가 가능하며, 라이젠 5 5600X는 최대 4.6GHz입니다.\n캐시 및 메모리 타입: 코어 i5-12600K는 20MB의 스마트 캐시를 제공하는 반면, 라이젠 5 5600X는 32MB의 L3 캐시를 갖추고 있습니다.\n \n중급형: 코어 i5-13600K vs 라이젠 5 7600X\n중급형 프로세서로, 고사양 게임이나 비디오 편집과 같은 보다 높은 요구 사항을 처리할 수 있습니다.\n\n\n\n아키텍처 및 코어 수: 코어 i5-13600K는 14개의 코어(6개의 성능 + 8개의 효율 코어)와 20개의 스레드를 제공하며, 라이젠 5 7600X는 6개의 코어와 12개의 스레드를 가지고 있습니다.\n전력 소비: 라이젠 5 7600X는 105W의 낮은 전력 소비를 자랑하며, 코어 i5-13600K는 125W입니다.\n \n고급형: 코어 i5-14600K vs 라이젠 5 9600X\n이 프로세서들은 고사양 작업을 처리하기에 적합합니다.\n\n\n\n아키텍처 및 코어 수: 라이젠 5 9600X는 6개의 코어와 12개의 스레드를 제공하며, 코어 i5-14600K는 14개의 코어(6개의 성능 코어와 8개의 효율 코어)와 20개의 스레드를 갖추고 있습니다.\n성능 및 가격 비교: 코어 i5-14600K는 $350의 가격으로 라이젠 5 9600X의 $279보다 비싸지만, 더 나은 종합 성능을 제공합니다.\n \n결론: 어떤 CPU를 선택해야 할까요?\n결국, 인텔 코어 i5와 AMD 라이젠 5는 각각 다른 시장을 겨냥하고 있습니다. 라이젠 5는 높은 클럭 속도와 더 낮은 TDP를 제공하며, 코어 i5는 전반적인 성능에서 더 높은 점수를 받습니다. 게이머와 콘텐츠 제작자는 싱글 코어 성능이 뛰어난 코어 i5를 선호할 수 있으며, 멀티태스킹과 에너지 효율성을 중요시하는 사용자는 라이젠 5를 선택할 가능성이 큽니다. 최종 선택은 예산과 용도에 따라 달라집니다.",
        "guid": "http://muzbox.tistory.com/483467",
        "categories": [
          "윈도우 사용팁/하드웨어",
          "amd 라이젠 5",
          "cpu추천",
          "게이밍 cpu",
          "멀티스레딩 성능",
          "미드레인지 cpu 비교",
          "싱글 코어 성능",
          "인텔 코어 i5",
          "전력 소비 비교",
          "프로세서 성능",
          "하이브리드 아키텍처"
        ],
        "isoDate": "2024-09-09T00:12:09.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": [
      {
        "creator": "늑돌이",
        "title": "갤럭시 S24/S23/Z폴드5∙플립5/탭S9에 갤럭시 AI 신기능 업데이트 실시",
        "link": "https://lazion.com/2513723",
        "pubDate": "Fri, 6 Sep 2024 11:29:10 +0900",
        "author": "늑돌이",
        "comments": "https://lazion.com/2513723#entry2513723comment",
        "content": "<h3 data-ke-size=\"size23\">삼성전자가 갤럭시 S24 시리즈와 작년에 출시한 갤럭시 S23/Z폴드5∙플립5/탭S9 등 주요 모델에 갤럭시 AI 신기능 업데이트를 실시합니다.</h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>갤럭시 AI 신기능 업데이트 대상 모델</b></span></h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이번 업데이트의 대상 모델은 다음과 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">- 갤럭시 S24 시리즈 : S24∙S24+∙S24 울트라</p>\n<p data-ke-size=\"size16\">- 갤럭시 S23 시리즈 : S23∙S23+∙S23 울트라∙S23 FE</p>\n<p data-ke-size=\"size16\">- 갤럭시 Z 폴드5∙Z 플립5</p>\n<p data-ke-size=\"size16\">- 갤럭시 탭 S9 시리즈 : S9∙S9+∙S9 울트라</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>갤럭시 AI 새로운 기능</b></span></h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"삼성전자-모바일-갤럭시-AI-S24-업데이트-S23-Z폴드6스케치-변환_web.jpg\" data-origin-width=\"1000\" data-origin-height=\"666\"><span data-url=\"https://blog.kakaocdn.net/dn/UvFIF/btsJtHIBDX9/G2FLGsP5u3g0terQk2Q2E0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/UvFIF/btsJtHIBDX9/G2FLGsP5u3g0terQk2Q2E0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/UvFIF/btsJtHIBDX9/G2FLGsP5u3g0terQk2Q2E0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FUvFIF%2FbtsJtHIBDX9%2FG2FLGsP5u3g0terQk2Q2E0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"삼성전자-모바일-갤럭시-AI-S24-업데이트-S23-Z폴드6스케치-변환_web.jpg\" data-origin-width=\"1000\" data-origin-height=\"666\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">기존 갤럭시 이용 고객 가운데 해당 모델 보유자는 이번 업데이트를 통해 갤럭시 Z 폴드6∙플립6에 탑재된 One UI 6.1.1이 지원하는 고도화된 새로운 갤럭시 AI 기능을 사용할 수 있습니다. 다만 모델 별로 지원되는 세부 기능은 다를 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">- 통역(Interpreter) 듣기 모드 : 현장에서 듣는 외국인의 말을 실시간으로 번역해 텍스트로 보여준다</p>\n<p data-ke-size=\"size16\">- 글쓰기(Composer) : 간단한 키워드만 입력해도 사용자의 어조와 스타일이 반영된 이메일과 소셜네트워크 게시글을 제안한다.</p>\n<p data-ke-size=\"size16\">- 답장 추천(Suggested replies) : 최근 상대방과 주고받은 메시지를 분석해 맞춤형 답장을 제안한다.</p>\n<p data-ke-size=\"size16\">- 노트 어시스트(Note Assist)의 음성 녹음 텍스트 변환과 PDF 오버레이(PDF Overlay) 번역</p>\n<p data-ke-size=\"size16\">- 스케치 변환(Sketch to image) : 간단한 스케치를 정교한 AI 이미지로 변환한다.</p>\n<p data-ke-size=\"size16\">- 서클 투 서치(Circle to Search) : 수학 문제 풀이와 음악 찾기 기능을 제공하는 한층 진화했다.</p>\n<p data-ke-size=\"size16\">- 인물 사진 스튜디오(Portrait Studio) : 인물사진을 3D 캐릭터, 수채화 등 다양한 스타일로 변환한다.</p>\n<p data-ke-size=\"size16\">- 인스턴트 슬로우 모션(Instant Slow-mo) : 슬로우 모션 영상을 간단하고 빠르게 제작할 수 있다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><b><span style=\"color: #006dd7;\">갤럭시 AI 신기능 업데이트는 언제부터?</span></b></h3>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이번 갤럭시 AI 신기능 업데이트는 어제(9월 5일)부터 순차적으로 진행 중입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"text-align: right;\" data-ke-size=\"size16\">(출처 : 삼성전자)</p>",
        "contentSnippet": "삼성전자가 갤럭시 S24 시리즈와 작년에 출시한 갤럭시 S23/Z폴드5∙플립5/탭S9 등 주요 모델에 갤럭시 AI 신기능 업데이트를 실시합니다.\n \n갤럭시 AI 신기능 업데이트 대상 모델\n \n이번 업데이트의 대상 모델은 다음과 같습니다.\n \n- 갤럭시 S24 시리즈 : S24∙S24+∙S24 울트라\n- 갤럭시 S23 시리즈 : S23∙S23+∙S23 울트라∙S23 FE\n- 갤럭시 Z 폴드5∙Z 플립5\n- 갤럭시 탭 S9 시리즈 : S9∙S9+∙S9 울트라\n \n \n갤럭시 AI 새로운 기능\n \n\n\n \n기존 갤럭시 이용 고객 가운데 해당 모델 보유자는 이번 업데이트를 통해 갤럭시 Z 폴드6∙플립6에 탑재된 One UI 6.1.1이 지원하는 고도화된 새로운 갤럭시 AI 기능을 사용할 수 있습니다. 다만 모델 별로 지원되는 세부 기능은 다를 수 있습니다.\n \n- 통역(Interpreter) 듣기 모드 : 현장에서 듣는 외국인의 말을 실시간으로 번역해 텍스트로 보여준다\n- 글쓰기(Composer) : 간단한 키워드만 입력해도 사용자의 어조와 스타일이 반영된 이메일과 소셜네트워크 게시글을 제안한다.\n- 답장 추천(Suggested replies) : 최근 상대방과 주고받은 메시지를 분석해 맞춤형 답장을 제안한다.\n- 노트 어시스트(Note Assist)의 음성 녹음 텍스트 변환과 PDF 오버레이(PDF Overlay) 번역\n- 스케치 변환(Sketch to image) : 간단한 스케치를 정교한 AI 이미지로 변환한다.\n- 서클 투 서치(Circle to Search) : 수학 문제 풀이와 음악 찾기 기능을 제공하는 한층 진화했다.\n- 인물 사진 스튜디오(Portrait Studio) : 인물사진을 3D 캐릭터, 수채화 등 다양한 스타일로 변환한다.\n- 인스턴트 슬로우 모션(Instant Slow-mo) : 슬로우 모션 영상을 간단하고 빠르게 제작할 수 있다.\n \n \n갤럭시 AI 신기능 업데이트는 언제부터?\n \n이번 갤럭시 AI 신기능 업데이트는 어제(9월 5일)부터 순차적으로 진행 중입니다.\n \n(출처 : 삼성전자)",
        "guid": "https://lazion.com/2513723",
        "categories": [
          "#더작은모바일/#스마트폰#PDA#PMP",
          "Galaxy",
          "Galaxy AI",
          "News",
          "Samsung",
          "SEC",
          "smartphone",
          "Tablet",
          "Update"
        ],
        "isoDate": "2024-09-06T02:29:10.000Z"
      }
    ]
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "(RULIWEB`Д')/",
        "title": "[MULTI] 건프라란… 자유다! 건담 브레이커 4",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2249",
        "pubDate": "Wed, 11 Sep 2024 19:40:29 +0900",
        "author": "(RULIWEB`Д')/",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/24/09/11/191e0a995d14c329e.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2024-09-11T10:40:29.000Z"
      },
      {
        "creator": "［RULIWEB］",
        "title": "[MULTI] 풍선 근육 오픈 월드, 스타워즈 아웃로",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2248",
        "pubDate": "Tue, 10 Sep 2024 15:05:44 +0900",
        "author": "［RULIWEB］",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/24/09/10/191da89412a5104c1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2024-09-10T06:05:44.000Z"
      },
      {
        "creator": "｜RULIWEB｜",
        "title": "[게임툰] 냥만 넘치는 해적 RPG, 캣 퀘스트 3",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2247",
        "pubDate": "Fri, 06 Sep 2024 13:54:26 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/24/09/06/191c5ae96d451ad6b.png\">",
        "contentSnippet": "",
        "categories": [
          "게임툰"
        ],
        "isoDate": "2024-09-06T04:54:26.000Z"
      },
      {
        "creator": "［RULIWEB］",
        "title": "[PS] 더 커지고 넓어지고 즐거워졌다, 아스트로 봇",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2246",
        "pubDate": "Thu, 05 Sep 2024 21:26:31 +0900",
        "author": "［RULIWEB］",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/24/09/05/191c22624375104c1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2024-09-05T12:26:31.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "khris'log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": [
      {
        "title": "Excel상에서 WebAssembly판 Python을 실행 가능하게 하는 애드온 Anaconda Code",
        "link": "https://jacking75.github.io/tech_20240911/",
        "pubDate": "Wed, 11 Sep 2024 00:00:00 +0900",
        "content": "<iframe width=\"1024\" height=\"1024\" src=\"https://docs.google.com/document/d/1c7CbAi55VlnfiMQ6JQZDQn6AidbJW6RknQSpe58qTBo/pub?embedded=true\"></iframe>\n\n",
        "contentSnippet": "",
        "guid": "https://jacking75.github.io/tech_20240911/",
        "isoDate": "2024-09-10T15:00:00.000Z"
      },
      {
        "title": "golang - Go 1.22  버전의 math/rand/v2",
        "link": "https://jacking75.github.io/go_20240906/",
        "pubDate": "Fri, 06 Sep 2024 00:00:00 +0900",
        "content": "<iframe width=\"1024\" height=\"1024\" src=\"https://docs.google.com/document/d/e/2PACX-1vR3PWN26Eq-FdbW-paq90HGaCehR8hD25MrFvWRg9DxEkUUrs3XzhDleT7VZb_Sey5F5QLzQVVimaAb/pub?embedded=true\"></iframe>\n\n",
        "contentSnippet": "",
        "guid": "https://jacking75.github.io/go_20240906/",
        "isoDate": "2024-09-05T15:00:00.000Z"
      }
    ]
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "정부 창업지원금 관련 내용",
        "link": "http://serverdown.tistory.com/798",
        "pubDate": "Mon, 9 Sep 2024 22:41:39 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/798#entry798comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=VdAZmGlEV20\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=VdAZmGlEV20</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=VdAZmGlEV20\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/FGkXD/hyW2SWZsKx/xokg4Y8gT789J9VTRRxwdK/img.jpg?width=1280&amp;height=720&amp;face=790_130_1028_390\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"(대출아님) 정부창업지원금으로 무자본 창업했어요 (2천만원~1억원 받기 | 예비창업패키지)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/VdAZmGlEV20\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">정부지원금 받는 내용인데 보통인물은 아닌듯</p>\n<p data-ke-size=\"size16\">대충 이런식으로 진행되서 받는다는건데</p>\n<p data-ke-size=\"size16\">한번에 되는 사람도 있고 몇년을 해도 안되는 사람도 있으니&nbsp;</p>\n<p data-ke-size=\"size16\">능력안된다 싶으면 도망을 추천</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">---------</p>\n<p data-ke-size=\"size16\">게임 개발 앱개발 지원급음&nbsp;</p>\n<p data-ke-size=\"size16\">년초에 코카? koca 에서 지원금 공고가 뜨면 지원하는거라고 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">-------</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=Ckv3nhDdM5Y\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=Ckv3nhDdM5Y</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=Ckv3nhDdM5Y\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/oydI5/hyW24b4DUV/Ro3Hl81eURyKhfb8Iviutk/img.jpg?width=640&amp;height=480&amp;face=0_0_640_480\" data-video-width=\"640\" data-video-height=\"480\" data-video-origin-width=\"640\" data-video-origin-height=\"480\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"2022년 상반기, 총 지원금 1억5천만원을 품에 안은 영광의 게임은? [제 16회 경기게임오디션] 스케\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/Ckv3nhDdM5Y\" width=\"640\" height=\"480\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">지역마다 따로 뭔가 진행중이기 아이디어는 미리 준비해야할듯</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">내용 찾는대로 추가해야할듯 방법은 많네</p>\n<p data-ke-size=\"size16\">통과 못할 뿐이지</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=VdAZmGlEV20\n\n\n\n \n정부지원금 받는 내용인데 보통인물은 아닌듯\n대충 이런식으로 진행되서 받는다는건데\n한번에 되는 사람도 있고 몇년을 해도 안되는 사람도 있으니 \n능력안된다 싶으면 도망을 추천\n \n---------\n게임 개발 앱개발 지원급음 \n년초에 코카? koca 에서 지원금 공고가 뜨면 지원하는거라고 합니다.\n \n \n \n-------\n영상: https://www.youtube.com/watch?v=Ckv3nhDdM5Y\n\n\n\n지역마다 따로 뭔가 진행중이기 아이디어는 미리 준비해야할듯\n \n \n내용 찾는대로 추가해야할듯 방법은 많네\n통과 못할 뿐이지",
        "guid": "http://serverdown.tistory.com/798",
        "categories": [
          "유튜브"
        ],
        "isoDate": "2024-09-09T13:41:39.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "AI 검색에대한 설명",
        "link": "http://serverdown.tistory.com/797",
        "pubDate": "Fri, 6 Sep 2024 09:09:16 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/797#entry797comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://youtu.be/aMtvJoE_EJQ?t=1536\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://youtu.be/aMtvJoE_EJQ?t=1536</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=aMtvJoE_EJQ\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/0xwgv/hyWZaEcLtv/HCGtdKgdITgJroBKpm2HAK/img.jpg?width=1280&amp;height=720&amp;face=530_114_644_238\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"(1부) 구글 검색의 시대 끝날 것 같습니다 (솔트룩스 이경일 대표)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/aMtvJoE_EJQ\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">전체는 ai 검색에대ㅏ설명이구요</p>\n<p data-ke-size=\"size16\">제가 따온 부분은</p>\n<p data-ke-size=\"size16\">언어를 벡터화 했다는 부분입니다.</p>\n<p data-ke-size=\"size16\">1000 ~ 2000 차원까지 늘리면 언어를 벡터로 만들 수 있다고 합니다.</p>\n<p data-ke-size=\"size16\">그러면 언어끼리 서버 비교도 가능하고 연산도 가능해지기 때문에&nbsp;</p>\n<p data-ke-size=\"size16\">컴퓨터가 처리할 수 있게 된거 같군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상2: <a href=\"https://youtu.be/aMtvJoE_EJQ?t=2320\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://youtu.be/aMtvJoE_EJQ?t=2320</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=aMtvJoE_EJQ\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/ccsCa4/hyWZivs4fm/xBBhmbmdylNW2ePtwIgG50/img.jpg?width=1280&amp;height=720&amp;face=530_114_644_238\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"(1부) 구글 검색의 시대 끝날 것 같습니다 (솔트룩스 이경일 대표)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/aMtvJoE_EJQ\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">같은 영상이구요&nbsp;</p>\n<p data-ke-size=\"size16\">이제 ai 가 언어검색이 잘되고나면</p>\n<p data-ke-size=\"size16\">회사내에서 이걸 활용할 수 있게됩니다.</p>\n<p data-ke-size=\"size16\">회사내에서도 정보가 너무 많아서 개인들이 통합할 수 없는 수준이되면</p>\n<p data-ke-size=\"size16\">그걸 ai 가 요약하게 되고 자기 회사의 지식을 제대로 활용할 수 있게 됩니다.</p>\n<p data-ke-size=\"size16\">그리고 회사용&nbsp; ai 시스템은 회사내부에 둬야겠지요 유출되면 안되니</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://youtu.be/aMtvJoE_EJQ?t=1536\n\n\n\n \n전체는 ai 검색에대ㅏ설명이구요\n제가 따온 부분은\n언어를 벡터화 했다는 부분입니다.\n1000 ~ 2000 차원까지 늘리면 언어를 벡터로 만들 수 있다고 합니다.\n그러면 언어끼리 서버 비교도 가능하고 연산도 가능해지기 때문에 \n컴퓨터가 처리할 수 있게 된거 같군요\n \n \n \n영상2: https://youtu.be/aMtvJoE_EJQ?t=2320\n\n\n\n \n같은 영상이구요 \n이제 ai 가 언어검색이 잘되고나면\n회사내에서 이걸 활용할 수 있게됩니다.\n회사내에서도 정보가 너무 많아서 개인들이 통합할 수 없는 수준이되면\n그걸 ai 가 요약하게 되고 자기 회사의 지식을 제대로 활용할 수 있게 됩니다.\n그리고 회사용  ai 시스템은 회사내부에 둬야겠지요 유출되면 안되니",
        "guid": "http://serverdown.tistory.com/797",
        "categories": [
          "유튜브"
        ],
        "isoDate": "2024-09-06T00:09:16.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Hybrid's Notes",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": []
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": [
      {
        "title": "WebP의 품질과 파일 크기",
        "link": "https://hyeonseok.com/blog/918",
        "pubDate": "Sat, 07 Sep 2024 22:50:43 GMT",
        "content": "<p>웹피(WebP)를 저장 할 때 품질을 얼마로 정해야 품질과 파일 크기 사이에서 적당한 지점을 찾을 수 있을지 실험을 좀 해봤다. 먼저 웹피에 대해서 알아보려면 <a href=\"https://kr.bandisoft.com/honeycam/webp/what-is-webp/\">반디소프트</a>나 <a href=\"https://developers.google.com/speed/webp?hl=ko\">구글</a>, <a href=\"https://blog.tinify.com/pros-and-cons-webp-images/\">타이니파이</a>의 글을 참고하면 좋다. 간단히 말하면 구글에서 만든 무손실과 손실, 알파채널, 애니메이션까지 지원하면서 기존 포맷 보다 작은 파일 크기를 유지하는 최근에 가장 각광 받고 있는 이미지 포맷이다. <a href=\"https://caniuse.com/?search=webp\">대부분의 브라우저에서 지원</a>한다.</p>\r\n\r\n<p>무손실로 저장을 해도 PNG에 비해 26%가 작다니 사용하지 않을 이유가 없다. 다만 손실의 경우에는 파일 크기는 획기적으로 줄어들지만 그만큼 품질도 희생되기 때문에 JPG 사용하는 기분으로 쓰면 된다. 품질은 0에서 100까지 지정할 수 있는데 생각보다 유실되는 디테일이 많아서 품질을 많이 낮춰서 사용하기는 힘들다.</p>\r\n\r\n<table style=\"width: 20em\">\r\n  <caption>WebP 품질에 따른 파일 크기 변화</caption>\r\n  <thead>\r\n    <tr>\r\n      <th>Quality</th>\r\n      <th>Size (KB)</th>\r\n    </tr>\r\n  </thead>\r\n  <tbody>\r\n    <tr>\r\n      <th>10</th>\r\n      <td>42</td>\r\n    </tr>\r\n    <tr>\r\n      <th>20</th>\r\n      <td>50</td>\r\n    </tr>\r\n    <tr>\r\n      <th>30</th>\r\n      <td>58</td>\r\n    </tr>\r\n    <tr>\r\n      <th>40</th>\r\n      <td>66</td>\r\n    </tr>\r\n    <tr>\r\n      <th>50</th>\r\n      <td>72</td>\r\n    </tr>\r\n    <tr>\r\n      <th>60</th>\r\n      <td>77</td>\r\n    </tr>\r\n    <tr>\r\n      <th>70</th>\r\n      <td>84</td>\r\n    </tr>\r\n    <tr>\r\n      <th>80</th>\r\n      <td>99</td>\r\n    </tr>\r\n    <tr>\r\n      <th>90</th>\r\n      <td>131</td>\r\n    </tr>\r\n    <tr>\r\n      <th>100</th>\r\n      <td>344</td>\r\n    </tr>\r\n  </tbody>\r\n</table>\r\n\r\n<p><img src=\"/static/blog/webp-quality-and-size.png\" class=\"major\" alt=\"WebP의 품질이 80까지는 크기가 급격히 줄다가 그 이하에서는 선형적으로 줄어들고 있다.\" /> 90정도의 품질을 선택해도 크기가 반이하로 줄고 80아래부터는 품질 저하에 비해 크기가 많이 줄지 않기 때문에 90이나 80정도를 사용하면 충분할 것 같다. 내 경우는 품질이 크게 중요하지 않아서 일단 50으로 잡기는 했다. 하지만 품질이 떨어짐에 따라 손실되는 이미지 디테일이 매우 심하기 때문에 이미지 손상에 대해서 어느정도 감수는 해야 한다.</p>\r\n\r\n<p><img src=\"/static/blog/bandisoft-webp-quality.png\" class=\"major\" alt=\"반디소프트의 정적 이미지와 애니메이션 이미지의 품질별 크기 비교, 유사한 경향성을 보여주고 있다.\" /> <a href=\"https://kr.bandisoft.com/honeycam/webp/webp-quality/\">반디소프트 글 중에서 품질을 다룬 것</a>이 있는데 그래프로 그려보면 거의 비슷한 경향성을 가지고 있어서 웹피의 품질 설정이 어느정도 예측 가능한 일관성을 가지고 있는 것으로 생각된다. 아직은 내가 쓰는 툴이 무손실 웹피를 편하게 지원하지 않아서 바로 바꾸지는 못했는데 웹피의 흥행은 앞으로 시간 문제로 생각된다. 이미 많이 사용되고 있다.</p>",
        "contentSnippet": "웹피(WebP)를 저장 할 때 품질을 얼마로 정해야 품질과 파일 크기 사이에서 적당한 지점을 찾을 수 있을지 실험을 좀 해봤다. 먼저 웹피에 대해서 알아보려면 반디소프트나 구글, 타이니파이의 글을 참고하면 좋다. 간단히 말하면 구글에서 만든 무손실과 손실, 알파채널, 애니메이션까지 지원하면서 기존 포맷 보다 작은 파일 크기를 유지하는 최근에 가장 각광 받고 있는 이미지 포맷이다. 대부분의 브라우저에서 지원한다.\n\r\n\r\n무손실로 저장을 해도 PNG에 비해 26%가 작다니 사용하지 않을 이유가 없다. 다만 손실의 경우에는 파일 크기는 획기적으로 줄어들지만 그만큼 품질도 희생되기 때문에 JPG 사용하는 기분으로 쓰면 된다. 품질은 0에서 100까지 지정할 수 있는데 생각보다 유실되는 디테일이 많아서 품질을 많이 낮춰서 사용하기는 힘들다.\n\r\n\r\n\r\n  WebP 품질에 따른 파일 크기 변화\r\n  \r\n    \n\r\n      Quality\r\n      Size (KB)\r\n    \n\r\n  \r\n  \r\n    \n\r\n      10\r\n      42\r\n    \n\r\n    \n\r\n      20\r\n      50\r\n    \n\r\n    \n\r\n      30\r\n      58\r\n    \n\r\n    \n\r\n      40\r\n      66\r\n    \n\r\n    \n\r\n      50\r\n      72\r\n    \n\r\n    \n\r\n      60\r\n      77\r\n    \n\r\n    \n\r\n      70\r\n      84\r\n    \n\r\n    \n\r\n      80\r\n      99\r\n    \n\r\n    \n\r\n      90\r\n      131\r\n    \n\r\n    \n\r\n      100\r\n      344\r\n    \n\r\n  \r\n\r\n\r\n 90정도의 품질을 선택해도 크기가 반이하로 줄고 80아래부터는 품질 저하에 비해 크기가 많이 줄지 않기 때문에 90이나 80정도를 사용하면 충분할 것 같다. 내 경우는 품질이 크게 중요하지 않아서 일단 50으로 잡기는 했다. 하지만 품질이 떨어짐에 따라 손실되는 이미지 디테일이 매우 심하기 때문에 이미지 손상에 대해서 어느정도 감수는 해야 한다.\n\r\n\r\n 반디소프트 글 중에서 품질을 다룬 것이 있는데 그래프로 그려보면 거의 비슷한 경향성을 가지고 있어서 웹피의 품질 설정이 어느정도 예측 가능한 일관성을 가지고 있는 것으로 생각된다. 아직은 내가 쓰는 툴이 무손실 웹피를 편하게 지원하지 않아서 바로 바꾸지는 못했는데 웹피의 흥행은 앞으로 시간 문제로 생각된다. 이미 많이 사용되고 있다.",
        "guid": "https://hyeonseok.com/blog/918",
        "isoDate": "2024-09-07T22:50:43.000Z"
      }
    ]
  },
  {
    "name": "한상곤 - Sigmadream",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "Flutter Web을 활용해 제품 개발 환경 개선하기",
        "link": "https://techblog.lycorp.co.jp/ko/improve-development-experience-with-flutter-web",
        "pubDate": "Fri, 06 Sep 2024 02:00:00 GMT",
        "content": "안녕하세요. ABC Studio에서 Demaecan(出前館, 이하 데마에칸) 앱을 개발하고 있는 김종식입니다. 데마에칸은 2000년부터 서비스를 시작한 일본 최대 규모의 음식 배달...",
        "contentSnippet": "안녕하세요. ABC Studio에서 Demaecan(出前館, 이하 데마에칸) 앱을 개발하고 있는 김종식입니다. 데마에칸은 2000년부터 서비스를 시작한 일본 최대 규모의 음식 배달...",
        "guid": "https://techblog.lycorp.co.jp/ko/improve-development-experience-with-flutter-web",
        "isoDate": "2024-09-06T02:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": [
      {
        "title": "API 가이드 vs. API 스펙, 뭐가 다른거야?",
        "link": "https://meetup.nhncloud.com/posts/386",
        "pubDate": "Wed, 11 Sep 2024 00:44:35 GMT",
        "content": "![final_섬네일민트2.png](https://image.toast.com/aaaadh/real/2024/techblog/finaluC12CuB124uC77CuBBFCuD2B82.png)\r\r\n\r\r\n## 들어가며\r\r\n\r\r\nAPI(application programming interface)는 우리가 인지하지 못하는 동안에도 일상생활의 곳곳에 밀접하게 연관되어 있습니다. 날씨 정보 조회에서부터 소셜 미디어 로그인까지 우리가 의식하지 않는 순간에도 API를 호출하고 데이터를 주고받고 있는데요. 작년 TESLA가 서드 파티 애플리케이션을 지원하기 위한 공식 API와 [API 문서](https://developer.tesla.com/docs/fleet-api/getting-started/what-is-fleet-api)를 공개하면서 이제 API가 전 산업분야에서 활발히 사용 중인 걸 알 수 있었습니다. 아카마이 테크놀로지가 발표한 [조사](https://www.akamai.com/newsroom/press-release/state-of-the-internet-security-retail-attacks-and-api-traffic)에 따르면 API 호출로 인한 웹 트래픽이 전체 웹 트래픽의 83퍼센트를 차지한다고 합니다. 이렇게 API가 마치 물처럼 없어선 안 될 요소가 되면서 동시에 API 문서의 중요성도 함께 커지고 있습니다.\r\r\n\r\r\n여러 서비스들의 기술 문서를 보다 보면 API 가이드 또는 API 명세, API 레퍼런스 같은 용어들을 자주 마주칠 수 있는데요. 과연 이 용어들이 같은 의미를 가지고 있을까요?\r\r\n\r\r\n사실 API 문서와 API 스펙은 비슷해 보이지만 다른 의미를 가지고 있습니다.\r\r\nAPI 스펙(API specification)이란 무엇일까요? API 문서(API documentation)를 의미하는 것일까요?\r\r\n\r\r\n## API 문서? API 스펙?\r\r\n\r\r\nAPI 가이드, API 레퍼런스는 모두 API 문서(API documentation)입니다. API 문서는 API 사용 방법을 주로 다룹니다. 독자는 개발자 또는 API를 사용하는 일반 사용자입니다. API 호출 시 필요한 파라미터와 반환되는 응답, 오류 메시지, JavaScript, Python과 같이 자주 사용되는 개발 언어로 작성된 샘플 코드 등을 제공해 독자가 읽고 쉽게 이해할 수 있도록 돕는 문서입니다. 따라서 잘 작성된 API 가이드는 API를 즉시 테스트해 볼 수 있도록 빠른 시작 가이드, 튜토리얼, 오류 처리 방법 등 다양한 정보를 담고있습니다.\r\r\n\r\r\n그렇다면 ‘API 스펙’은 무엇을 의미할까요?\r\r\n\r\r\n만약 나만의 API를 개발했다고 합시다. 이 API로 사업을 계획하고 있다면, 이를 사용할 고객, 거래처, 팀원에게 API를 명확하게 설명하는 것이 매우 중요할 것입니다. 반복적이지만 군더더기 없이 간결하게 API를 설명하는 것이 API를 활용한 비즈니스를 성공적으로 이끄는 데 매우 중요할 텐데요. 이를 가능케 하는 것이 바로 `API 스펙`입니다.\r\r\n\r\r\nAPI 스펙이란 `단순하고 명확한 언어로 작성된 API의 청사진 혹은 API 설계도면`(또는 설계 규격)을 뜻합니다. 다시 말해 특정 API에 대한 모든 정보를 항목화한 명세입니다. 잘 작성된 API 스펙은 해당 애플리케이션을 구석구석 살펴보지 않아도, 즉시 이해할 수 있습니다.\r\r\n\r\r\nAPI 스펙은 API가 어떻게 동작하고 다른 API와 어떻게 상호작용하는지를 다룹니다. API 문서는 API를 사용하고 싶은 개발자를 위한 것이라면 API 스펙은 API를 빌드하고자하는 개발자를 위해 작성된 것입니다. API 스펙은 API가 가진 각각의 동작에 대해 더 상세하게 기재되어 있습니다. API에 포함된 오브젝트, 값, 파라미터는 물론이고 해당 API가 사용하는 데이터 모델에 대한 정보를 담고 있습니다. 즉 API 스펙은 해당 API의 동작 방식과 다른 API와 상호 작용에 대해 상세하게 기술한 문서입니다.\r\r\n\r\r\n![화면 캡처 2024-09-04 154738.png](https://image.toast.com/aaaadh/real/2024/techblog/uD654uBA74%20uCEA1uCC98%2020240904%20154738.png)\r\r\n\r\r\n\r\r\nAPI 스펙은 API를 맨 처음 개발할 때부터 API를 기술하는 API 문서를 제작하는 데 있어 가장 필수적인 도구입니다. API 스펙이 아주 잘 정립되어 있다면 생소한 코드를 분석하는 골치 아픈 일을 건너뛰고 API를 훨씬 더 일관되고 안정적으로 구현할 수 있습니다. 사실 ‘API 스펙’이란 개념이 등장하기 전엔, API 개발하는 과정은 팀마다 회사마다 제각각이고 질서가 없었는데요. 그 결과, 완성된 힘들게 개발한 API를 연동하는 것이 무척 어렵고 복잡하고 비효율적이었습니다. 이는 곧 서비스의 매력도를 크게 떨어뜨리는 결과를 가져오게 되죠.\r\r\n\r\r\n![비교_new1.png](https://image.toast.com/aaaadh/real/2024/techblog/uBE44uAD50new1.png)\r\r\n\r\r\n## OpenAPI의 등장\r\r\n\r\r\n‘API 스펙’이란 개념이 주목받기 시작한 때는 2010년 지금은 너무나 잘 알려진 Swagger가 등장하면서부터입니다. Swagger는 API를 문서화하고, 정의하고 인터랙션 하기 위해 필요한 모든 것을 제공하는 `오픈소스 소프트웨어 프레임워크`인데요. 풀어서 설명하면, Swagger는 RESTful API(웹에서 사용되는 자원을 효율적이고 안정적으로 사용할 수 있게 하는 REST 원칙을 잘 따르는 API)를 설계하고, 빌드하고, 이에 대한 문서도 작성할 수 있도록 하는 도구입니다. 여기에 더해 빌드한 API를 호출해 볼수도 있습니다.\r\r\n\r\r\nAPI를 작성할 수 있다는 점에는 Swagger는 API 정의 언어라고도 하는데요. 다음에 나올 내용에서 계속 등장하니 기억해 주시기 바랍니다.\r\r\nSwagger로 작성한 API 스펙인 Swagger Specification이 API 스펙의 표준으로 널리 사용되었는데, 이후 2015년 Swagger 개발사인 SmartBear가 Swagger Specification을 리눅스 재단 산하의 **오픈API 이니셔티브**에 기부하면서 Swagger Specification은 <strong>OpenAPI Specification(OAS)</strong>라는 공식 명칭을 가지게 되었고 OAS는 표준 API 스펙으로 자리잡게되었습니다. 오픈 API 이니셔티브는 API 기술하는 방식을 표준화하자는 목표 아래 현재도 활발하게 API 생태계 발전에 기여하고있습니다. 2024년 9월 기준, OAS는 버전 [3.1.0](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.1.0.md) 까지 업데이트되었습니다.\r\r\n\r\r\n다시 말하자면 OpenAPI는 Swagger와 마찬가지로 API 정의 언어(API description language)이며, OpenAPI로 작성한 API 스펙을 OAS(OpenAPI Specification)라고 합니다.\r\r\n\r\r\nOAS는 이제 API 스펙의 표준으로 인식되며 현재 가장 많이 사용되는 API 스펙입니다. OAS를 활용하면 기계가 인식할 수 있는 형태로 API를 설계할 수 있고, 더 나아가 API 문서와 클라이언트 SDK 등을 생성하고 인증과 오류 처리 방법, 보안과 같은 디테일한 정보도 기술할 수 있습니다.\r\r\n\r\r\n## TypeSpec의 등장\r\r\n\r\r\n이렇게 OAS가 API 스펙의 표준으로 굳건하게 입지를 다지는 중에 최근 Microsoft가 새로운 API 정의 언어인 TypeSpec을 출시했습니다.\r\r\n<span style=\"\">TypeSpec은 Microsoft Graph 개발팀이 마치 코드를 작성하는 것처럼 유연하고 편리하게 API 스펙을 작성하고 싶다는 생각에서 탄생했습니다.</span>\r\r\n\r\r\nAPI 콘퍼런스인 [Nordic APIs](https://www.youtube.com/watch?v=yfCYrKaojDo&t=731s)에서 Microsoft Azure SDK 팀리더는 무수히 많은 문서와 라이브러리를 일관되고 용이하게 관리하기 위해 API 정의 언어로 TypeSpec을 활용한다고 합니다. 내부에서 API와 SDK 문서를 일관되게 관리하기 위한 API 작성 가이드라인이 있지만, Azure 서비스가 급속하게 성장하다 보니 각기 다른 언어로 작성된 API 문서를 효율적으로 관리하기가 어려워졌고 이런 상황에서 TypeSpec으로 API를 정의하면 API 스펙을 크게 간소화할 수 있고, API 가이드라인을 재사용 가능한 코드로 만들면 신규인력도 이를 빠르고 쉽게 적용하여 API 문서를 작성할 수 있다고 하는데요.\r\r\n\r\r\n마치 코드를 작성하는 것과 같이 API 스펙을 작성해서 Design-First 접근법(API 설계 시 API 스펙을 먼저 작성하는 접근법)을 실현하기 위해 TypeSpec을 활발히 사용 중이라고 밝혔습니다.\r\r\n\r\r\n반복해서 나오는 API 정의 언어와 API 스펙의 개념을 구분하면 아래와 같습니다.\r\r\n\r\r\n![자산 2.png](https://image.toast.com/aaaadh/real/2024/techblog/uC790uC0B0%202.png)\r\r\n\r\r\n그렇다면 OpenAPI와 TypeSpec으로 작성한 API 스펙이 어떻게 다른지 한번 살펴보겠습니다.\r\r\n예로 아래와 같이 동작하는 API가 있습니다.\r\r\n\r\r\n### 사용자 관리 API\r\r\n\r\r\n* 사용자 목록 조회(List)\r\r\n* ID로 사용자 단일 조회(Read)\r\r\n* 신규 사용자 생성(Create)\r\r\n* 사용자 정보 수정(Update)\r\r\n* 사용자 삭제(Delete)\r\r\n\r\r\n## OpenAPI vs TypeSpec\r\r\n\r\r\nTypeSpec과 OpenAPI로 각각 사용자 관리 API 스펙을 작성하면 아래와 같습니다\r\r\n\r\r\n![codereview_.png](https://image.toast.com/aaaadh/real/2024/techblog/codereview.png)\r\r\n\r\r\n이 두 API 정의 언어의 장점과 단점은 분명한데요. TypeSpec은 코드를 작성하는 것과 유사하게 API 스펙을 작성할 수 있고, OpenAPI 대비 좀 더 경량화된 언어인 반면, 아직 OpenAPI보다 지원하는 서드파티 툴이 적다는 단점이 있습니다. 또한 OpenAPI는 호환 가능한 툴이 매우 다양하고 관련 생태계가 활성화되어있지만 API의 규모가 커질수록 길이가 너무 길어지고 복잡해지는 단점을 가지고 있습니다.\r\r\n\r\r\nTypeSpec은 OpenAPI를 완벽히 대체하기는 어려울 것이라는 의견도 있습니다만, 그보다 TypeSpec을 활용해 코드를 작성하는 것처럼 재사용 가능하고 확장 가능한 API 스펙을 만들 수 있고, OpenAPI 툴 체인과 쉽게 연동이 가능하여 이는 결국 API 생태계를 더욱 풍성하게 만들 것이란 의견이 많습니다.\r\r\n\r\r\nTypeSpec과 OpenAPI와 같은 API 정의 언어로 API 스펙을 작성할 때 누릴 수 있는 이점을 정리해 보면 아래와 같습니다.\r\r\n\r\r\n* 일관성\r\r\n    * API 스펙, 즉 API 규격이 잘 정립되어 있다면, 신규 API가 출시되었을 때, API 스펙에 부합하는지를 검증할 수 있습니다. 이로써 API의 작동 방식을 더욱 빠르고 쉽게 이해할 수 있습니다.\r\r\n    * API들이 일관된 규격에 맞게 설계되므로, 이는 백엔드 개발자와 프론트엔드 개발자 간 커뮤니케이션을 매끄럽게 만들어줍니다.\r\r\n* 문서 자동화\r\r\n    * Swagger 같은 API 문서 자동화 툴과 호환할 수 있어, API 문서에 포함된 API 엔드포인트를 즉시 테스트해 볼 수 있습니다.\r\r\n* 쉬운 유지 보수와 테스트\r\r\n    * 일관된 규격에 맞게 설계된 API는 물론 그렇지 않은 API보다 이해하기가 더 쉬우므로, API 업데이트 혹은 버전업을 더 빠르게 수행할 수 있습니다.\r\r\n\r\r\n## 나가며\r\r\n\r\r\nAPI 가이드와 API 스펙은 평소 자주 혼용되어 그 개념을 정확히 알고자 이렇게 기술 공유 글을 작성하게 되었는데요, 이번 계기로 API 스펙이 API 문서와 어떻게 다른지 알 수 있었습니다.\r\r\n비즈니스 관점에서 잘 작성된 API 스펙과 API 가이드는 API가 약속한 대로 작동할 것이라는 계약서와 같은 역할을 하고 이는 신뢰성과도 직결되는데요, 더 나아가 완성도 있는 애플리케이션 구축의 토대가 된다는 점을 고려하면 앞으로 API 스펙의 중요성은 커질 것입니다. 긴 글 읽어주셔서 감사합니다.\r\r\n\r\r\n## 참고자료\r\r\n\r\r\n* [https://nordicapis.com/what-is-an-api-definition/](https://nordicapis.com/what-is-an-api-definition/)\r\r\n* [https://swagger.io/resources/articles/difference-between-api-documentation-specification/](https://swagger.io/resources/articles/difference-between-api-documentation-specification/)\r\r\n* [https://github.com/OAI/OpenAPI-Specification/blob/main/examples/v2.0/json/petstore-expanded.json](https://github.com/OAI/OpenAPI-Specification/blob/main/examples/v2.0/json/petstore-expanded.json)\r\r\n* [https://medium.com/another-integration-blog/your-api-specification-is-not-your-api-documentation-4dcc33d23823](https://medium.com/another-integration-blog/your-api-specification-is-not-your-api-documentation-4dcc33d23823)\r\r\n* [https://www.moesif.com/blog/technical/api-design/Benefits-of-using-the-OpenAPI-Swagger-specification-for-your-API/](https://www.moesif.com/blog/technical/api-design/Benefits-of-using-the-OpenAPI-Swagger-specification-for-your-API/)\r\r\n* [https://blog.postman.com/openapi-vs-swagger/](https://blog.postman.com/openapi-vs-swagger/)\r\r\n* [https://www.youtube.com/watch?v=yfCYrKaojDo&t=731s](https://www.youtube.com/watch?v=yfCYrKaojDo&t=731s)\r\r\n\r\r\n![footer.png](https://image.toast.com/aaaadh/real/2024/techblog/footer.png)",
        "contentSnippet": "![final_섬네일민트2.png](https://image.toast.com/aaaadh/real/2024/techblog/finaluC12CuB124uC77CuBBFCuD2B82.png)\r\r\n\r\r\n## 들어가며\r\r\n\r\r\nAPI(application programming interface)는 우리가 인지하지 못하는 동안에도 일상생활의 곳곳에 밀접하게 연관되어 있습니다. 날씨 정보 조회에서부터 소셜 미디어 로그인까지 우리가 의식하지 않는 순간에도 API를 호출하고 데이터를 주고받고 있는데요. 작년 TESLA가 서드 파티 애플리케이션을 지원하기 위한 공식 API와 [API 문서](https://developer.tesla.com/docs/fleet-api/getting-started/what-is-fleet-api)를 공개하면서 이제 API가 전 산업분야에서 활발히 사용 중인 걸 알 수 있었습니다. 아카마이 테크놀로지가 발표한 [조사](https://www.akamai.com/newsroom/press-release/state-of-the-internet-security-retail-attacks-and-api-traffic)에 따르면 API 호출로 인한 웹 트래픽이 전체 웹 트래픽의 83퍼센트를 차지한다고 합니다. 이렇게 API가 마치 물처럼 없어선 안 될 요소가 되면서 동시에 API 문서의 중요성도 함께 커지고 있습니다.\r\r\n\r\r\n여러 서비스들의 기술 문서를 보다 보면 API 가이드 또는 API 명세, API 레퍼런스 같은 용어들을 자주 마주칠 수 있는데요. 과연 이 용어들이 같은 의미를 가지고 있을까요?\r\r\n\r\r\n사실 API 문서와 API 스펙은 비슷해 보이지만 다른 의미를 가지고 있습니다.\r\r\nAPI 스펙(API specification)이란 무엇일까요? API 문서(API documentation)를 의미하는 것일까요?\r\r\n\r\r\n## API 문서? API 스펙?\r\r\n\r\r\nAPI 가이드, API 레퍼런스는 모두 API 문서(API documentation)입니다. API 문서는 API 사용 방법을 주로 다룹니다. 독자는 개발자 또는 API를 사용하는 일반 사용자입니다. API 호출 시 필요한 파라미터와 반환되는 응답, 오류 메시지, JavaScript, Python과 같이 자주 사용되는 개발 언어로 작성된 샘플 코드 등을 제공해 독자가 읽고 쉽게 이해할 수 있도록 돕는 문서입니다. 따라서 잘 작성된 API 가이드는 API를 즉시 테스트해 볼 수 있도록 빠른 시작 가이드, 튜토리얼, 오류 처리 방법 등 다양한 정보를 담고있습니다.\r\r\n\r\r\n그렇다면 ‘API 스펙’은 무엇을 의미할까요?\r\r\n\r\r\n만약 나만의 API를 개발했다고 합시다. 이 API로 사업을 계획하고 있다면, 이를 사용할 고객, 거래처, 팀원에게 API를 명확하게 설명하는 것이 매우 중요할 것입니다. 반복적이지만 군더더기 없이 간결하게 API를 설명하는 것이 API를 활용한 비즈니스를 성공적으로 이끄는 데 매우 중요할 텐데요. 이를 가능케 하는 것이 바로 `API 스펙`입니다.\r\r\n\r\r\nAPI 스펙이란 `단순하고 명확한 언어로 작성된 API의 청사진 혹은 API 설계도면`(또는 설계 규격)을 뜻합니다. 다시 말해 특정 API에 대한 모든 정보를 항목화한 명세입니다. 잘 작성된 API 스펙은 해당 애플리케이션을 구석구석 살펴보지 않아도, 즉시 이해할 수 있습니다.\r\r\n\r\r\nAPI 스펙은 API가 어떻게 동작하고 다른 API와 어떻게 상호작용하는지를 다룹니다. API 문서는 API를 사용하고 싶은 개발자를 위한 것이라면 API 스펙은 API를 빌드하고자하는 개발자를 위해 작성된 것입니다. API 스펙은 API가 가진 각각의 동작에 대해 더 상세하게 기재되어 있습니다. API에 포함된 오브젝트, 값, 파라미터는 물론이고 해당 API가 사용하는 데이터 모델에 대한 정보를 담고 있습니다. 즉 API 스펙은 해당 API의 동작 방식과 다른 API와 상호 작용에 대해 상세하게 기술한 문서입니다.\r\r\n\r\r\n![화면 캡처 2024-09-04 154738.png](https://image.toast.com/aaaadh/real/2024/techblog/uD654uBA74%20uCEA1uCC98%2020240904%20154738.png)\r\r\n\r\r\n\r\r\nAPI 스펙은 API를 맨 처음 개발할 때부터 API를 기술하는 API 문서를 제작하는 데 있어 가장 필수적인 도구입니다. API 스펙이 아주 잘 정립되어 있다면 생소한 코드를 분석하는 골치 아픈 일을 건너뛰고 API를 훨씬 더 일관되고 안정적으로 구현할 수 있습니다. 사실 ‘API 스펙’이란 개념이 등장하기 전엔, API 개발하는 과정은 팀마다 회사마다 제각각이고 질서가 없었는데요. 그 결과, 완성된 힘들게 개발한 API를 연동하는 것이 무척 어렵고 복잡하고 비효율적이었습니다. 이는 곧 서비스의 매력도를 크게 떨어뜨리는 결과를 가져오게 되죠.\r\r\n\r\r\n![비교_new1.png](https://image.toast.com/aaaadh/real/2024/techblog/uBE44uAD50new1.png)\r\r\n\r\r\n## OpenAPI의 등장\r\r\n\r\r\n‘API 스펙’이란 개념이 주목받기 시작한 때는 2010년 지금은 너무나 잘 알려진 Swagger가 등장하면서부터입니다. Swagger는 API를 문서화하고, 정의하고 인터랙션 하기 위해 필요한 모든 것을 제공하는 `오픈소스 소프트웨어 프레임워크`인데요. 풀어서 설명하면, Swagger는 RESTful API(웹에서 사용되는 자원을 효율적이고 안정적으로 사용할 수 있게 하는 REST 원칙을 잘 따르는 API)를 설계하고, 빌드하고, 이에 대한 문서도 작성할 수 있도록 하는 도구입니다. 여기에 더해 빌드한 API를 호출해 볼수도 있습니다.\r\r\n\r\r\nAPI를 작성할 수 있다는 점에는 Swagger는 API 정의 언어라고도 하는데요. 다음에 나올 내용에서 계속 등장하니 기억해 주시기 바랍니다.\r\r\nSwagger로 작성한 API 스펙인 Swagger Specification이 API 스펙의 표준으로 널리 사용되었는데, 이후 2015년 Swagger 개발사인 SmartBear가 Swagger Specification을 리눅스 재단 산하의 **오픈API 이니셔티브**에 기부하면서 Swagger Specification은 OpenAPI Specification(OAS)라는 공식 명칭을 가지게 되었고 OAS는 표준 API 스펙으로 자리잡게되었습니다. 오픈 API 이니셔티브는 API 기술하는 방식을 표준화하자는 목표 아래 현재도 활발하게 API 생태계 발전에 기여하고있습니다. 2024년 9월 기준, OAS는 버전 [3.1.0](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.1.0.md) 까지 업데이트되었습니다.\r\r\n\r\r\n다시 말하자면 OpenAPI는 Swagger와 마찬가지로 API 정의 언어(API description language)이며, OpenAPI로 작성한 API 스펙을 OAS(OpenAPI Specification)라고 합니다.\r\r\n\r\r\nOAS는 이제 API 스펙의 표준으로 인식되며 현재 가장 많이 사용되는 API 스펙입니다. OAS를 활용하면 기계가 인식할 수 있는 형태로 API를 설계할 수 있고, 더 나아가 API 문서와 클라이언트 SDK 등을 생성하고 인증과 오류 처리 방법, 보안과 같은 디테일한 정보도 기술할 수 있습니다.\r\r\n\r\r\n## TypeSpec의 등장\r\r\n\r\r\n이렇게 OAS가 API 스펙의 표준으로 굳건하게 입지를 다지는 중에 최근 Microsoft가 새로운 API 정의 언어인 TypeSpec을 출시했습니다.\r\r\nTypeSpec은 Microsoft Graph 개발팀이 마치 코드를 작성하는 것처럼 유연하고 편리하게 API 스펙을 작성하고 싶다는 생각에서 탄생했습니다.\r\r\n\r\r\nAPI 콘퍼런스인 [Nordic APIs](https://www.youtube.com/watch?v=yfCYrKaojDo&t=731s)에서 Microsoft Azure SDK 팀리더는 무수히 많은 문서와 라이브러리를 일관되고 용이하게 관리하기 위해 API 정의 언어로 TypeSpec을 활용한다고 합니다. 내부에서 API와 SDK 문서를 일관되게 관리하기 위한 API 작성 가이드라인이 있지만, Azure 서비스가 급속하게 성장하다 보니 각기 다른 언어로 작성된 API 문서를 효율적으로 관리하기가 어려워졌고 이런 상황에서 TypeSpec으로 API를 정의하면 API 스펙을 크게 간소화할 수 있고, API 가이드라인을 재사용 가능한 코드로 만들면 신규인력도 이를 빠르고 쉽게 적용하여 API 문서를 작성할 수 있다고 하는데요.\r\r\n\r\r\n마치 코드를 작성하는 것과 같이 API 스펙을 작성해서 Design-First 접근법(API 설계 시 API 스펙을 먼저 작성하는 접근법)을 실현하기 위해 TypeSpec을 활발히 사용 중이라고 밝혔습니다.\r\r\n\r\r\n반복해서 나오는 API 정의 언어와 API 스펙의 개념을 구분하면 아래와 같습니다.\r\r\n\r\r\n![자산 2.png](https://image.toast.com/aaaadh/real/2024/techblog/uC790uC0B0%202.png)\r\r\n\r\r\n그렇다면 OpenAPI와 TypeSpec으로 작성한 API 스펙이 어떻게 다른지 한번 살펴보겠습니다.\r\r\n예로 아래와 같이 동작하는 API가 있습니다.\r\r\n\r\r\n### 사용자 관리 API\r\r\n\r\r\n* 사용자 목록 조회(List)\r\r\n* ID로 사용자 단일 조회(Read)\r\r\n* 신규 사용자 생성(Create)\r\r\n* 사용자 정보 수정(Update)\r\r\n* 사용자 삭제(Delete)\r\r\n\r\r\n## OpenAPI vs TypeSpec\r\r\n\r\r\nTypeSpec과 OpenAPI로 각각 사용자 관리 API 스펙을 작성하면 아래와 같습니다\r\r\n\r\r\n![codereview_.png](https://image.toast.com/aaaadh/real/2024/techblog/codereview.png)\r\r\n\r\r\n이 두 API 정의 언어의 장점과 단점은 분명한데요. TypeSpec은 코드를 작성하는 것과 유사하게 API 스펙을 작성할 수 있고, OpenAPI 대비 좀 더 경량화된 언어인 반면, 아직 OpenAPI보다 지원하는 서드파티 툴이 적다는 단점이 있습니다. 또한 OpenAPI는 호환 가능한 툴이 매우 다양하고 관련 생태계가 활성화되어있지만 API의 규모가 커질수록 길이가 너무 길어지고 복잡해지는 단점을 가지고 있습니다.\r\r\n\r\r\nTypeSpec은 OpenAPI를 완벽히 대체하기는 어려울 것이라는 의견도 있습니다만, 그보다 TypeSpec을 활용해 코드를 작성하는 것처럼 재사용 가능하고 확장 가능한 API 스펙을 만들 수 있고, OpenAPI 툴 체인과 쉽게 연동이 가능하여 이는 결국 API 생태계를 더욱 풍성하게 만들 것이란 의견이 많습니다.\r\r\n\r\r\nTypeSpec과 OpenAPI와 같은 API 정의 언어로 API 스펙을 작성할 때 누릴 수 있는 이점을 정리해 보면 아래와 같습니다.\r\r\n\r\r\n* 일관성\r\r\n    * API 스펙, 즉 API 규격이 잘 정립되어 있다면, 신규 API가 출시되었을 때, API 스펙에 부합하는지를 검증할 수 있습니다. 이로써 API의 작동 방식을 더욱 빠르고 쉽게 이해할 수 있습니다.\r\r\n    * API들이 일관된 규격에 맞게 설계되므로, 이는 백엔드 개발자와 프론트엔드 개발자 간 커뮤니케이션을 매끄럽게 만들어줍니다.\r\r\n* 문서 자동화\r\r\n    * Swagger 같은 API 문서 자동화 툴과 호환할 수 있어, API 문서에 포함된 API 엔드포인트를 즉시 테스트해 볼 수 있습니다.\r\r\n* 쉬운 유지 보수와 테스트\r\r\n    * 일관된 규격에 맞게 설계된 API는 물론 그렇지 않은 API보다 이해하기가 더 쉬우므로, API 업데이트 혹은 버전업을 더 빠르게 수행할 수 있습니다.\r\r\n\r\r\n## 나가며\r\r\n\r\r\nAPI 가이드와 API 스펙은 평소 자주 혼용되어 그 개념을 정확히 알고자 이렇게 기술 공유 글을 작성하게 되었는데요, 이번 계기로 API 스펙이 API 문서와 어떻게 다른지 알 수 있었습니다.\r\r\n비즈니스 관점에서 잘 작성된 API 스펙과 API 가이드는 API가 약속한 대로 작동할 것이라는 계약서와 같은 역할을 하고 이는 신뢰성과도 직결되는데요, 더 나아가 완성도 있는 애플리케이션 구축의 토대가 된다는 점을 고려하면 앞으로 API 스펙의 중요성은 커질 것입니다. 긴 글 읽어주셔서 감사합니다.\r\r\n\r\r\n## 참고자료\r\r\n\r\r\n* [https://nordicapis.com/what-is-an-api-definition/](https://nordicapis.com/what-is-an-api-definition/)\r\r\n* [https://swagger.io/resources/articles/difference-between-api-documentation-specification/](https://swagger.io/resources/articles/difference-between-api-documentation-specification/)\r\r\n* [https://github.com/OAI/OpenAPI-Specification/blob/main/examples/v2.0/json/petstore-expanded.json](https://github.com/OAI/OpenAPI-Specification/blob/main/examples/v2.0/json/petstore-expanded.json)\r\r\n* [https://medium.com/another-integration-blog/your-api-specification-is-not-your-api-documentation-4dcc33d23823](https://medium.com/another-integration-blog/your-api-specification-is-not-your-api-documentation-4dcc33d23823)\r\r\n* [https://www.moesif.com/blog/technical/api-design/Benefits-of-using-the-OpenAPI-Swagger-specification-for-your-API/](https://www.moesif.com/blog/technical/api-design/Benefits-of-using-the-OpenAPI-Swagger-specification-for-your-API/)\r\r\n* [https://blog.postman.com/openapi-vs-swagger/](https://blog.postman.com/openapi-vs-swagger/)\r\r\n* [https://www.youtube.com/watch?v=yfCYrKaojDo&t=731s](https://www.youtube.com/watch?v=yfCYrKaojDo&t=731s)\r\r\n\r\r\n![footer.png](https://image.toast.com/aaaadh/real/2024/techblog/footer.png)",
        "isoDate": "2024-09-11T00:44:35.000Z"
      }
    ]
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "이한",
    "category": "개인",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "분위기",
        "link": "https://www.thestartupbible.com/2024/09/the-vibe.html",
        "pubDate": "Wed, 11 Sep 2024 19:00:00 +0000",
        "content:encodedSnippet": "우린 매주 화요일 오전에 전체 주간 미팅을 하고, 이때 현재 투자 검토하고 있는 회사들에 대한 이야기를 하고 결정하는 투자심의위원회(투심위) 미팅도 같이한다. 다양한 경로를 통해서 알게 된 회사들에 대해서 각자의 의견을 들어보고, 투자할지 말지 결정하는데, 모든 사업이 다르고, 비슷한 사업이라도 창업자가 다르기 때문에, 결정의 결과는 항상 다르다.\n내가 얼마 전에 어떤 회사에 대해서, “비즈니스모델은 괜찮은 것 같은데, 그 창업가의 분위기가 좀 별로였다.”라는 굉장히 애매모호하고, 주관적이고, 비과학적인 발언을 했는데, 참 신기하게도 이 말에 동의하는 분이 몇 명 있었다. 어쨌든, 꼬집어서 그 이유를 정확하게 말할 순 없었지만, 뭔가 느낌이 좋지 않았던 그런 미팅이었다. 결국 우린 이 회사를 더 이상 검토하지 않았는데, 이 전에도 우린 분위기가 이상하거나, 이보다 더 애매모호하게 “느낌이 쎄해서” 그냥 겉으로 보면 괜찮은 사업 같은데 한 번의 미팅 이후에 더 이상 검토를 하지 않은 곳들이 꽤 있었다.\n한 사람과 이야기를 해보면, 이 사람이 지금까지 살아온 인생이 다양한 방식으로 표출된다. 어떤 사람은 이게 인상에서 어느 정도 보이고, 어떤 사람은 말투에서 이분이 어떤 성향의 사람이고 지금까지 어떤 인생을 살아왔는지 대략 느껴진다. 그리고 조금 더 미팅하면서 더 다양한 말을 섞어보면, 옷차림, 인상, 눈빛, 몸짓, 목소리, 단어 하나하나 등을 통해서 이 사람의 에너지와 분위기가 느껴진다. 우린 온갖 종류의 창업가들을 매일 다양하게 많이 만나는데, 더 많은 사람을 만날수록 이분들의 성공 가능성을 예측할 수 있는 정확도가 향상되진 않는다. 이렇게 되면 너무 좋겠지만, 사람은 정말 복잡한 생명체라서 어디로 튈지 모르기 때문에 솔직히 말해서 우리의 판단이 틀리는 경우가 더 많다. 하지만, 그 사람의 분위기가 좋은지 안 좋은진 정확하게 판단할 수 있다고 믿고 있다.\n창업가들과 10분 정도만 이야기해 봐도 이분들이 정말로 본인이 하는 사업에 확신이 있는지, 모든 사람들이 반대해도 계속 이 사업을 할 의지가 있는지, 그리고 정말로 투자를 받고 싶은 의지가 있는지 꽤 정확하게 파악할 수 있다. 위에서 내가 말 한 그런 다양한 외부의 시그널이 이 창업가의 내면의 의지를 꽤 정확하게 반영하는데, 이런 걸 통틀어서 종합한 게 이 글에서 말하고자 하는 그 분위기이다. 내가 전에 우린 창업가들의 거창한 것보단, 매우 작은 것들을 관찰한다고 했는데, 이 작은 것들도 분위기랑 밀접한 연관이 있다.\n나도 투자자들을 만날 땐, 평소보다 이 내면의 에너지에 신경을 많이 쓴다. 우리가 창업가들과 10분만 이야기해도, 분위기를 금방 느낄 수 있듯이, 우리 같은 펀드에 출자하는 LP들도 나랑 10분만 이야기해 보면, 내가 긍정적인 에너지를 분출하는 바이브를 형성하는 사람인지 아닌지 금방 파악 가능할 것이고, 실은 거기서 우리에게 돈을 줄지 안 줄지 바로 결정이 나는 것이다. 참고로 에너지 레벨이 높다는 게, 동작이 과격하고 목소리가 큰 게 아니다. 조용하고 차분해도 긍정적인 분위기는 그대로 상대방에게 다양한 방식을 통해서 전달된다.\n그래서 나는 모든 중요한 일을 할 때, 내가 기분이 좋아야 하고, 내 내면의 분위기가 긍정적이어야 하고, 내 에너지 레벨이 높아야 한다고 생각한다. 가장 좋은 방법은 루틴을 반복하는 것이다. 잘 자고, 잘 운동하고, 잘 먹어야 한다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/09/the-vibe.html#respond",
        "content": "우린 매주 화요일 오전에 전체 주간 미팅을 하고, 이때 현재 투자 검토하고 있는 회사들에 대한 이야기를 하고 결정하는 투자심의위원회(투심위) 미팅도 같이한다. 다양한 경로를 통해서 알게 된 회사들에 대해서 각자의 의견을 들어보고, 투자할지 말지 결정하는데, 모든 사업이 다르고, 비슷한 사업이라도 창업자가 다르기 때문에, 결정의 결과는 항상 다르다. 내가 얼마 전에 어떤 회사에 대해서, “비즈니스모델은 괜찮은 것(...)",
        "contentSnippet": "우린 매주 화요일 오전에 전체 주간 미팅을 하고, 이때 현재 투자 검토하고 있는 회사들에 대한 이야기를 하고 결정하는 투자심의위원회(투심위) 미팅도 같이한다. 다양한 경로를 통해서 알게 된 회사들에 대해서 각자의 의견을 들어보고, 투자할지 말지 결정하는데, 모든 사업이 다르고, 비슷한 사업이라도 창업자가 다르기 때문에, 결정의 결과는 항상 다르다. 내가 얼마 전에 어떤 회사에 대해서, “비즈니스모델은 괜찮은 것(...)",
        "guid": "https://www.thestartupbible.com/?p=9214",
        "categories": [
          "Uncategorized",
          "fundraising",
          "general",
          "people",
          "Strong",
          "vc"
        ],
        "isoDate": "2024-09-11T19:00:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "노가다에 대해서",
        "link": "https://www.thestartupbible.com/2024/09/not-scalable-until-scalable.html",
        "pubDate": "Sun, 08 Sep 2024 19:03:02 +0000",
        "content:encodedSnippet": "투자자나 창업가나 스케일에 대한 이야기를 자주 한다. 우리가 자주 하는 질문은 과연 특정 사업이 얼마나 빠르게, 그리고 얼마나 효율적으로 성장이 가능할까인데 영어로 이 질문을 하면 “이 비즈니스가 얼마나 scalable 할까?” 정도가 되지 않을까 싶다.\n대부분의 유니콘 회사가 아주 빠르게 성장을 했고, 스케일이라는 말을 스타트업 분야에서 워낙 많이 사용하기 때문에, 많은 창업가들이 이 단어에 집착한다고 난 생각한다. 아주 효율적으로, 아주 빠르게 성장하는 건 당연히 좋고, 투자자로서 나도 스케일이 가능한 사업을 발견하면 좋아하지만, 솔직히 말해서 쉽게, 그리고 빠르게 성장할 수 있는 비즈니스는 요새 정말 찾기 힘들다. 나는 오히려 이런 비즈니스가 있다고 하면 약간 의심하고, 너무 많은 창업가들이 필요 이상으로 스케일이라는 말에 집착하는 것 같다.\n최근에 워낙 경기가 안 좋다 보니, 많은 창업가들이 성장보단 생존에 집중하고 있는데, 계속 성장을 하고 싶어 하는 창업가들은 이런 상황이 죽고 싶어질 정도로 답답할 것이다. 우리 투자사 대표 몇 분은 이런 답답함과 짜증 남에 대해서 우리랑 편안하게 자주 이야기하는 편인데, 최근에 했던 이런 대화가 기억난다. B2B 제품을 만들고 있는데 영업 속도가 느리고 매출 성장이 너무 더뎌서 매우 초조해하고 스트레스 받고 있는 분과의 미팅이었다.\n일단, 기업에 판매할 B2B 제품은 소비자에게 직접 판매하는 B2C 제품보단 주로 시간과 노력이 많이 들어간다. 우리가 투자한 어떤 B2B SaaS 회사들은 제품만 만드는 데 1년이 걸리는 경우도 있다. 이렇게 힘들게 제품을 만들었는데, 이 제품을 기업 고객에게 판매하는 건, 더 힘들고 시간이 많이 필요하다. 첫 번째 B2B 고객을 확보하기 위해서 한 달 이상 영업하는 경우도 자주 보는데, 이렇게 해서 확보한 고객에게 발생하는 매출은 기대 이하이다. 이분은 이런 식으로 하면, 일 년 열심히 영업해도 유료 고객이 15개도 안 될 것이고, 이들로부터 나오는 매출도 크지 않아서, 과연 내가 맞는 방법으로 사업을 하고 있는지, 이렇게 고객 한 명 한 명씩 영업하는 방법이 맞는 건지 스스로에 대한 불신이 있었다. 그리고 주위에서 ‘미친 성장’을 하는 다른 스타트업같이 아주 효율적으로 노가다 없이 스케일 할 수 있는 방법에 대해 깊은 고민을 하고 있었다.\n나는 개인적으로 이 회사는 아주 잘될 것이라고 믿는다. 내 솔직한 의견은, B2C 제품이나, B2B 제품이나, 노가다 없이 스케일 할 수 있는 방법은 없다. 언론에서는 마치 쉽게 사업을 확장하고, 스케일이라는 말을 모든 스타트업이 가져야 할 필수 덕목같이 포장하는데, 나는 큰 스케일은 수많은 작은 노가다가 축적될 때 나올 수 있다고 생각한다. 요샌 웬만한 사람들이 다 사용하는 드롭박스 같은 제품도 사업 초반에는 창업자가 직접 지인들 사무실을 방문해서 이들의 PC에 제품을 설치해 주고, 사용법을 가르쳐주면서 성장했고, 에어비앤비도 창업자들이 직접 호스트의 숙소를 방문해서 사진을 찍어서 대신 올려주면서 성장했다. 우리 투자사 당근도 판교에서 아주 작게 시작했는데, 창업자들이 직접 물건을 하나씩 올려서 판매하면서 시작했다.\n동네 가게를 위한 B2B 제품을 만들고 있다면, 우리가 만든 제품을 어떻게 하면 최소한의 노력으로 가장 많은 동네 가게 사장님들에게 한 방에 크게 노출할 수 있는지 고민할 시간에, 그냥 하루 종일 동네 가게 문 두드리고 찾아가서 영업하는 게 맞는 방법이라고 생각한다. 이렇게 하루 종일 뚜벅뚜벅 걸어 다니면서 고객의 목소리를 직접 듣고, 이들에게 직접 제품을 설치해 주다 보면, 진짜 사업에 대해서 배울 수 있고, 세상이 정확히 어떻게 돌아가는지 몸으로 배우게 된다. 그러면서도 이렇게 고객 한 명씩 상대하면서 노가다 작업을 하는 게 맞는 방법인지 계속 스스로 의심하겠지만, 고객 한 명이 두 명이 되고, 두 명이 다섯 명이 되고, 다섯 명이 50명이 되면서, 그때부터 사업엔 스케일이 생길 것이다. 하지만, 스케일이 생기기 전 까진 그냥 옛날 방식대로 하나씩 해야 한다. 소위 말하는 노가다를 뛰어야 한다.\n스케일은 가만히 책상에 앉아서 손가락으로 만들어지지 않는다. 직접 발로 뛰어야 하고, 이런 노가다를 계속하다 보면 어느 순간 큰 스케일이 만들어진다. 대신, 멈추지 말고 계속 해야 한다. 내가 이전 포스팅에서도 말했지만, 세상의 모든 큰 일은 아주 작은 일을 계속하는 것에서 시작된다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/09/not-scalable-until-scalable.html#comments",
        "content": "투자자나 창업가나 스케일에 대한 이야기를 자주 한다. 우리가 자주 하는 질문은 과연 특정 사업이 얼마나 빠르게, 그리고 얼마나 효율적으로 성장이 가능할까인데 영어로 이 질문을 하면 “이 비즈니스가 얼마나 scalable 할까?” 정도가 되지 않을까 싶다. 대부분의 유니콘 회사가 아주 빠르게 성장을 했고, 스케일이라는 말을 스타트업 분야에서 워낙 많이 사용하기 때문에, 많은 창업가들이 이 단어에 집착한다고 난(...)",
        "contentSnippet": "투자자나 창업가나 스케일에 대한 이야기를 자주 한다. 우리가 자주 하는 질문은 과연 특정 사업이 얼마나 빠르게, 그리고 얼마나 효율적으로 성장이 가능할까인데 영어로 이 질문을 하면 “이 비즈니스가 얼마나 scalable 할까?” 정도가 되지 않을까 싶다. 대부분의 유니콘 회사가 아주 빠르게 성장을 했고, 스케일이라는 말을 스타트업 분야에서 워낙 많이 사용하기 때문에, 많은 창업가들이 이 단어에 집착한다고 난(...)",
        "guid": "https://www.thestartupbible.com/?p=9206",
        "categories": [
          "Uncategorized",
          "B2B",
          "FoundersAtWork",
          "hustle",
          "inspiring",
          "unicorn",
          "스타트업 바이블 1",
          "스타트업 바이블 2",
          "스타트업 바이블 QA"
        ],
        "isoDate": "2024-09-08T19:03:02.000Z"
      }
    ]
  },
  {
    "name": "Build a Great Product",
    "category": "개인",
    "posts": []
  },
  {
    "name": "지금 써보러 갑니다",
    "category": "개인",
    "posts": []
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "왜 은행마다 이자율이 조금씩 다른 걸까?",
        "link": "https://blog.toss.im/article/everyday-economics-18-bank-interest-rate",
        "pubDate": "Wed, 11 Sep 2024 12:23:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-94on8q{white-space:pre-wrap;color:#c770e4;font-weight:bold;}에디터 G (이하 G):.css-1kxrhf3{white-space:pre-wrap;} 교수님, 얼마 전 대출을 알아보려고 토스앱을 켰는데요. 여러 은행의 대출 상품이 리스트로 쭉 뜨는데, 은행마다 이자율이 조금씩 다르더라고요. 같은 금액의 대출금을 빌리더라도, A 은행에서는 3.5%의 이자율인 반면 B 은행에서는 4.2%의 이자율을 보여주는 거예요. 왜 같은 돈을 빌리더라도 은행마다 이렇게 이자율에 차이가 나는 걸까요?\n.css-12p6bv8{white-space:pre-wrap;color:#15c47e;font-weight:bold;}교수 K (이하 K): 요즘은 은행에 직접 방문하지 않고도 모바일로 간편하게 여러 대출을 비교할 수 있게 되면서, 은행마다 대출 금리가 다르다는 것을 더 잘 파악할 수 있게 된 것 같아요.\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}은행마다 이자율이 다른 이유에 대해 가장 먼저 생각해 볼 수 있는 것은, 리스크(risk: 위험) 관점인데요. 각 은행들의 리스크를 관리하는 방법이 다르기 때문입니다.\n은행은 다양한 리스크에 노출되어 있습니다. 예를 들면, 금리, 환율, 주가 변동 등 금융 시장의 변화로 인해 손실이 발생할 수 있는 시장 리스크(market risk)가 있고요. 은행 내부의 프로세스, 시스템 오류, 직원의 실수 등으로 인해 손실이 발생할 수 있는 운영 리스크(operational risk)도 있습니다. 또한 자금을 적시에 조달하지 못해 지불 의무를 이행하지 못하게 되는 유동성 리스크(liquidity risk)도 있고요.\nG: 엄청나게 다양한 리스크가 있군요. 은행 입장에서 가장 중요하게 생각하는 리스크는 어떤 것이려나요?\nK: 앞서 언급한 리스크 이외에 또다른 리스크가 있는데요. 은행이 가장 신경 쓰는 리스크는 바로, .css-1swx3yz{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;font-weight:bold;}신용 리스크(credit risk)입니다.\n신용 리스크는 대출을 받아간 고객이 원리금(원금+이자)을 상환하지 못할 가능성을 의미하는데요. 이는 은행의 재무 건전성과 직결됩니다. 신용 리스크가 현실화되면 은행은 대출 손실을 입게 되어 자산 건전성이 악화되기 때문이죠.\nG: 그렇겠네요. 그래서 은행에서 돈을 빌릴 때, 제가 대출을 잘 갚을 수 있는 사람인지 확인하는 절차가 꽤 복잡한 이유가 있는 거고요. 하지만 빌려준 돈을 못 갚을 가능성은 언제나 있으니, 은행 입장에선 항상 신용 리스크가 존재한다고 볼 수 있겠군요. 그렇다면 이러한 신용 리스크가 발생하는 이유에 대해서도 자세히 설명해주실 수 있을까요?\nK: 그럼요. 저희 시리즈의 취지에 맞게 경제학 관점에서 좀더 자세하게 설명해 드릴게요. 먼저 신용 리스크가 발생하는 원인으로는 ‘정보의 비대칭성(asymmetric information)’과 ‘역선택(adverse selection)’을 들 수 있습니다.\n정보의 비대칭성이란 거래 당사자 간의 정보가 균등하게 공유되지 않는 상황을 의미합니다.\n예를 들어, 은행에 투자 자금 1천만 원을 빌리러 온 김안정 씨와 이모험 씨가 있다고 가정해 볼게요. 김안정 씨는 안정적인 투자를 선호하는 사람이기 때문에, 5% 수익이 확실히 보장되는 사업에 투자를 하려고 합니다. 평소 조금씩 모아둔 비상금도 있어서 1천만 원을 빌려도 나중에 상환하는 데에 큰 문제가 없어요.\n반면, 이모험 씨는 모험적인 투자를 선호합니다. 성공 확률은 매우 낮지만, 만약 성공하게 되면 1,000%의 수익을 얻을 수 있는 사업에 투자하려고 합니다. 그러나 얼마 전에 지인으로부터 이미 많은 돈을 빌린 터라, 이번에 은행에서 1천만 원을 빌리면 나중에 상환할 수 있을지 불확실한 상황입니다.\n만약, 은행이 김안정 씨와 이모험 씨의 상황에 대한 정보를 완전하게 알고 있다면 어떤 결과가 나올까요?\nG: 음… 안정적인 투자를 선호하면서 모아둔 비상금도 있는 김안정 씨에게는 돈을 빌려줄 가능성이 높지만, 모험적인 투자를 선호하면서 지인에게 빌린 돈까지 있는 이모험 씨에게는 돈을 안 빌려줄 가능성이 높을 것 같아요.\nK: 그렇죠. 상식적으로 그들의 상황을 모두 안다면 에디터 님이 말씀하신 결과가 나올 겁니다. 하지만 은행은 김안정 씨와 이모험 씨의 이런 투자 성향과 상환 능력의 차이에 대해 전혀 모를 수도 있어요. 즉, ‘정보의 비대칭성’은 이처럼 돈을 빌리는 사람이 가진 정보와 은행이 가진 정보 사이에 차이가 나는 경우를 말합니다.\n정보의 비대칭성이 존재하는 상황을 좀 더 살펴보도록 하죠. 김안정 씨는 보수적인 투자자이기 때문에 기대 수익률 5%와 비교해서 대출 이자율이 더 높다면, 아마 대출 신청을 하지 않을 것입니다. 반면, 한탕을 노리는 이모험 씨는 높은 이자를 지불하더라도 은행으로부터 적극적으로 돈을 빌리려 할 것이고요.\n결과적으로, 은행은 이모험 씨처럼 위험이 높은 사람들에게만 대출을 해주는 상황이 발생할 수 있습니다. 이와 같이 정보의 비대칭성으로 인해 발생하는 문제를 ‘역선택’이라 해요.\nG: 오, 그렇군요. 당연히 김안정 씨에게 돈을 빌려줄 가능성이 높을 거라 생각했는데, 김안정 씨는 애초에 대출을 신청하지 않을 가능성이 높고 이모험 씨는 대출을 신청할 가능성이 높으니 예상과 반대되는 결과가 펼쳐지는 거네요. 아무래도 현실에서는 은행 입장에서 돈을 빌리고자 하는 사람들의 모든 상황을 파악하기가 어려우니 이런 결과가 나올 수밖에 없겠어요.\nK: 맞습니다. 그래서 은행은 정보의 비대칭성과 역선택 문제에 다양한 방식으로 대응하고 있어요. 대표적인 예가 바로 신용 점수, 재정 상태, 소득 수준 등의 정보를 이용해 고객의 신용도를 평가하는 것인데요. 이 때 은행마다 사용하는 신용 평가 모델이 다를 수 있습니다. 어떤 은행은 외부 신용 평가 기관의 점수를 주로 사용하는 반면, 다른 은행은 자체적으로 개발한 모델을 사용하여 신용 위험을 평가할 수 있죠.\n또한 각 은행마다 신용 평가 시 고려하는 요소가 다를 수 있습니다. 예를 들어, 소득 수준, 부채 비율, 직업 안정성, 금융 거래 내역 등을 평가할 때 각 요소의 비중을 다르게 설정할 수 있는 것이죠. 신용 평가에 사용하는 데이터도 서로 다를 수 있습니다. 대형 은행들은 고객의 기존 거래 내역, 예금 계좌 정보 등을 포함해 더 많은 내부 데이터를 활용할 수 있을 거고요.\n또한 은행마다 리스크를 허용하는 정도도 다르기 때문에, 같은 신용도를 가진 고객이라도 평가 결과가 서로 다르게 나올 수 있답니다. 리스크를 더 잘 수용할 수 있는 은행은 높은 점수를 부여하고, 보수적인 은행은 낮은 점수를 줄 수 있는 것이죠.\nG: 아하, 은행마다 고객의 신용도를 측정하는 방식이 다르기 때문에, 대출 금리와 이자율에도 차이가 발생하게 되는 것이군요.\nK: 맞아요. 이제 시각을 좀더 넓혀서 더 다양한 종류의 금융기관들의 이자율이 서로 다른 이유도 한번 살펴볼까요? 이번 기회에 우리나라에 존재하는 금융기관의 종류를 겸사겸사 정리해볼 겸 말이죠.\n현재 우리나라의 금융기관이 제공하는 금융 서비스는 유형에 따라 아래 표와 같이 구분할 수 있습니다. 은행, 비은행 예금취급기관, 보험회사, 금융투자업자, 기타 금융기관, 그리고 공적금융기관 등으로 나눌 수 있어요.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}은행\n\n먼저, 은행은 일반은행과 특수은행으로 나뉩니다. 일반은행은 시중은행, 지방은행, 외국은행 국내지점 등으로 구성되는데요. 주로 예금, 대출, 지급결제 등의 업무를 수행하고 있습니다.\n참고로, 현재 우리나라의 시중은행에는 신한은행, 우리은행, 하나은행, 한국씨티은행, iM뱅크(구 대구은행), KB국민은행, SC제일은행(가나다 순)과 토스뱅크를 비롯한 인터넷전문은행들이 포함된답니다.\n한편, 특수은행은 특정 목적을 위해 설립된 은행이에요. KDB산업은행, 한국수출입은행, IBK기업은행, NH농협은행, Sh수협은행 등이 있습니다.\n\n\n비은행 예금취급기관\n\n말 그대로 은행은 아니지만 예금 업무를 수행하는 기관인데요. 상호저축은행, 신용협동기구, 우체국예금, 종합금융회사 등으로 구성됩니다.\n상호저축은행은 특정한 지역의 서민 및 소규모 기업을 대상으로 대출을 제공하고 있어요. 조합원들을 대상으로 금융 서비스를 제공하며 공동 이익을 추구하는 신용협동기구에는 신협, 새마을금고, 농협, 수협 등이 포함됩니다. 우체국예금은 전국에 분포된 우체국을 통해 민간금융이 취약한 지역을 지원하는 국영 금융을 말하고요.\n\n\n보험회사\n\n크게 생명보험회사, 손해보험회사, 우체국보험, 공제기관생명 등으로 나뉩니다.\n생명보험회사는 사망, 질병, 노후 등에 대비한 보험과 관련된 업무를 하는 금융회사이고요. 손해보험회사는 화재, 자동차 및 해상사고 등과 같이 재산 및 사고 손실에 대비한 보험을 고유업무로 하는데요. 재보험회사와 보증보험회사도 손해보험회사에 포함됩니다. 우체국보험은 국가기관이 취급하는 국영보험이며, 공제기관의 경우 유사보험을 취급한답니다.\n\n\n금융투자회사\n\n투자매매·중개업자, 집합투자업자, 투자자문·일임업자, 신탁업자 등으로 분류됩니다.\n이 가운데 우리가 잘 알고 있는 증권회사는 투자매매·중개업자에 속하는데요. 주로 증권 및 채권과 관련된 위탁매매, 발행 및 인수 업무를 수행합니다. 은행의 경우 예금을 받아 기업에게 대출을 해주는 반면, 증권회사는 증권을 매개로 기업과 투자자를 직접 연결시킨다는 점에서 차이를 보인답니다.\n\n\n기타 금융기관\n\n금융지주회사, 여신전문금융회사, 벤처캐피탈회사, 증권금융회사, 대부업자 등이 있어요.\n이 중 여신전문금융회사는 고객으로부터 자금을 예치받는 수신(deposit) 기능 없이, 돈을 빌려주는 여신(lending) 업무만 취급하는 금융기관을 말합니다. 여신전문금융회사의 예로는 신용카드회사, 리스회사, 할부금융회사, 신기술사업금융회사 등이 있습니다.\n\n\n공적금융기관\n\n특정한 정책적 목적을 위해 설립된 기관으로, 한국무역보험공사, 한국주택금융공사, 한국자산관리공사, 한국투자공사, 서민금융진흥원 등이 포함돼요.\n\n\nG: 엄청나게 다양한 종류의 금융기관이 있군요! 서로 어떻게 다른지 잘 알아볼 수 있었어요. 글을 저장해 두고 다음에 다시 살펴봐야 겠어요.\nK: 좋습니다. 앞서 설명드린 금융기관들은 자금 조달 방식에 있어 서로 차이를 보이는데요. 이를 통해 각 금융기관들마다 다른 이자율을 제시하는 이유를 설명할 수 있답니다.\n예를 들어, 은행의 경우 주로 개인 및 기업 예금을 통해 자금을 조달해요. 또한, 채권 발행과 중앙은행에서의 차입, 다른 금융기관과의 대출 거래도 활용합니다. 이를 통해 은행은 비교적 안정적이고 대규모의 자금 조달이 가능하기 때문에, 예금 금리가 상대적으로 낮고 대출 금리도 경쟁력 있는 수준으로 제공할 수 있습니다.\n반면, 저축은행은 은행보다 금리를 높게 설정한 개인 예금을 통해 자금을 조달합니다. 또한 고위험 대출에 집중하기 때문에 리스크를 보상하기 위한 목적으로 대출 금리가 상대적으로 높답니다. 이는 저축은행이 은행보다 작은 규모로 운영되며, 고객 기반도 다르기 때문이에요.\n보험사의 경우, 고객이 납부하는 보험료가 주요 자금 조달원입니다. 이 보험료를 주식, 채권, 부동산 등 다양한 투자처에 투자하여 수익을 창출해요.\n생명보험회사는 장기적인 투자 수익을 목표로 하므로, 안정적인 수익을 제공할 수 있는 자산에 주로 투자합니다. 반면, 손해보험회사는 상대적으로 단기 계약이 많고 다양한 리스크를 보장하기 때문에, 주로 유동성이 높은 자산에 투자하는 경향이 강합니다.\n이렇게 확보된 자금을 바탕으로, 보험사들은 보험계약자들이 가입한 보험 상품의 해지환급금을 담보로 대출을 해주는 약관대출뿐만 아니라 신용대출과 부동산담보대출도 취급하고 있습니다.\n보험사의 대출 금리는 중앙은행의 기준 금리와 더불어 계약자의 신용도, 자산운용의 기대 수익률, 시장 금리, 담보 가액 등을 고려하여 결정되는데요. 제2금융권에 속하는 보험사는 일반적으로 제1금융권의 시중은행보다 금리가 높은 편입니다.\n그런데 금융당국이 가계부채 관리를 위해 제1금융권에 대한 규제를 강화하면서 시중은행들이 금리를 지속적으로 올린 결과, 얼마 전 보험사의 금리가 시중은행의 금리보다 낮아지는 금리 역전 현상이 발생하기도 했습니다.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}* 출처: .css-114ityv{white-space:pre-wrap;cursor:pointer;-webkit-text-decoration:underline!important;text-decoration:underline!important;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}[단독] 초유의 주담대 ‘금리 역전’… 보험사, 은행보다 낮아졌다 (한국경제) \n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n🏦 제1금융권, 제2금융권 금리도 차이가 꽤 나는데 왜 그런가요?\n\n제1금융권은 은행(일반은행, 특수은행)을 말합니다. 제2금융권은 앞에서 살펴본 금융기관들 중 은행을 제외한 금융기관들을 통칭하는 용어라고 생각하시면 됩니다.\n제2금융권 대출은, 대출 자격이 까다로운 제1금융권에서 대출을 받지 못하거나 신용등급이 낮은 고객을 대상으로 하는 경우가 상대적으로 많아요. 그래서 신용 리스크가 높아지고요. 이를 보상하기 위해 제1금융권보다 더 높은 금리를 부과하는 경향이 강하답니다.\n또한 제2금융권은 제1금융권에 비해 예금 유치가 적고 자금 시장에서의 차입 비용이 더 높기 때문에, 대출 금리도 제1금융권보다 올라가게 되는 것이지요.\n\n한편 증권사는 중개 기능을 주업무로 수행하고 있기 때문에, 자금 조달 방식이 은행이나 타금융기관과 차이를 보입니다.\n증권사의 자금조달원은 크게 두 가지인데요. 첫 번째는 투자자들의 증권 계좌에 들어있는 예수금(예수부채)이고요. 두 번째는 주가연계증권(ELS)과 같은 파생결합증권, 회사채, 기업어음(CP), 환매조건부채권(RP), 발행어음 등을 통해 자금을 차입하는 것(차입부채)입니다.\n증권사에서도 돈을 빌려주는데요. 고객이 주식을 사기 위해 필요한 자금이 부족할 때, 증권 계좌에 있는 주식을 담보로 빌려줍니다. 이를 신용거래 대출(마진 론)이라고 불러요. 증권사는 시장 금리, 고객의 신용도, 담보로 제공된 주식의 가치 변동성 등을 고려하여 대출 금리를 설정하게 됩니다.\nG: 은행, 저축은행, 보험회사, 증권회사… 모두 각자가 가지고 있는 고유한 비즈니스 모델에 따라 서로 다른 방법으로 자금을 조달하고 있군요. 자금 조달 비용이 서로 달라지기 때문에 각 금융기관들마다 이자율이 달라지는 거겠네요.\nK: 정확히 이해하셨어요. 각 금융기관에 대해 하나하나 설명드려서 조금 어려우셨을 수 있는데요. 결국 금융기관들마다 이자율이 달라지는 이유는 각자의 비즈니스 모델과 자금 조달 방법, 그리고 그 비용이 서로 다르기 때문입니다. 이 점을 이해하시면 금리가 차이 나는 이유도 금방 이해하실 수 있을 거예요.\nG: 각 금융기관의 이자율, 금리에 영향을 미치는 또다른 요인도 있을까요?\nK: 이외에도 특정 지역이나 고객층을 대상으로 한 경쟁 상황이 이자율에 영향을 미치기도 하고요. 운영 비용이 높은 금융기관은 이를 보상하기 위해 이자율을 높게 설정할 수도 있습니다. 또한 정부의 규제와 중앙은행의 통화 정책에 의해서도 이자율은 영향을 받기 마련이고요.\n오늘은 은행들마다 왜 이자율에 차이가 나는지와 더불어, 우리나라에 존재하는 금융기관들의 종류와 각 금융기관별로 이자율이 다른 이유까지 살펴 봤습니다. 혹시 앞으로 금융기관과 금리에 대한 뉴스를 보게 된다면, 오늘 내용을 한번 떠올려보면 좋을 것 같네요.\n.css-13d8cj1{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;margin:24px 0 8px;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:var(--adaptiveGrey700);}\n.css-1dzrkjz{width:16px;margin-right:8px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}\n.svg-icon-wrapper{position:relative;display:inline-block;width:24px;height:24px;}.svg-icon-wrapper >.svg-icon:empty+.svg-icon-fallback{visibility:visible;z-index:inherit;}.svg-icon{color:var(--adaptiveGrey900);display:inline-block;width:24px;height:24px;display:block;width:100%;height:100%;}.svg-icon svg,.svg-icon img{display:block;width:100%;height:100%;}.svg-icon--hide{display:none;}.svg-icon-fallback{position:absolute;left:0;right:0;top:0;z-index:z-index(hidden);visibility:hidden;display:block;width:100%;height:100%;}.svg-icon-fallback--show{visibility:visible;z-index:inherit;}\n참고자료\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 금혜원 Graphic 조수희 이제현",
        "content": "각 은행이 리스크(위험)를 관리하는 방법이 다르기 때문이에요.",
        "contentSnippet": "각 은행이 리스크(위험)를 관리하는 방법이 다르기 때문이에요.",
        "guid": "https://blog.toss.im/article/everyday-economics-18-bank-interest-rate",
        "isoDate": "2024-09-11T12:23:00.000Z"
      },
      {
        "title": "누구나 팬이 필요하다 ",
        "link": "https://blog.toss.im/article/fandustry-01",
        "pubDate": "Mon, 09 Sep 2024 23:36:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}2016년의 일이다. 평소에 갈 일 없던 모임, 그러니까 주로 대기업 임원들이나 스타트업 대표들의 네트워킹 모임에 초대받은 적이 있다. 그런 곳에서는 다들 어느 기업에서 무슨 업무를 맡고 있다는 식으로 자기 소개를 하기 때문에 당시 회사도 없고 직무도 없던 나로서는 괜히 자기소개에 자신이 없어지기도 했다. ‘00전자에서 웨어러블 사업을 총괄하고 있습니다’라는 중후한 소개 말에 이어 ‘저는 음악평론 하는데, 아니, 클래식은 아니고요, 대중음악인데, 아니 케이팝만 하는 건 아니고 인디 음악도 하는데, 아니, 평론이란 게 별점 매기는 건 또 아니지만서도, 네 뭐 서비스 기획도 했고, 콘텐츠도 만들고 에 또…’ 하는 게 얼마나 뻘쭘했을지 상상해보라. \n어휴 괜히 왔네, 후회하던 찰나 뒷줄의 나이 지긋한 여성분이 자기 소개를 하는데 ‘00기업에서 마케팅만 30년을 맡고 있습니다’ 하더니 조금 부끄러운 듯 한 마디를 보탰다. “그리고… 저는 아미입니다.”\n그 한마디에 주변 여성들의 호응하는 목소리가 커졌다. ‘저도 아미에요!’ ‘상무님, 멋있으세요!’ 남성들도 관심을 보였다. ‘아미가 뭐에요?’ ‘에이 BTS 그거요…’ 그 한 마디에 대체로 근엄하고 지루했던 자리에 활기가 넘치기 시작했다. ‘어이쿠, 나도 그냥 샤이니 팬이라고 소개할 걸!’ 하는 후회는 안했다. (나도 소셜 포지션이 있답니다~) 대신, ‘이제는 덕질이 커리어와 같은 레벨이 되었구나’라는 생각이 떠올랐다.\n그리고 8년이 지났다. 지금 ‘아미’는 팬덤의 대명사이자 케이팝의 글로벌 영향력을 상징하는 단어가 되었다. 또한 팬덤은 일종의 개념으로도 자리잡고 있다. 2016년엔 대기업 상무님의 ‘덕밍아웃’이 쿨하게 여겨졌다면, 2024년엔 신입 마케터 채용 조건에 ‘덕질’을 언급할 만큼 일반화되었다. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}이제 팬덤은 사업적으로도, 산업적으로도 중요한 요소가 되었다.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}음악 산업에서 팬덤이 중요해진 이유\n2024년 현재, 스포티파이 기준 하루에 업로드되는 음악은 12만 곡 정도다. 오타가 아니다. 12만 곡이다. 1곡 당 최소 3분으로 잡으면(음악의 길이는 점점 짧아져서 이젠 3분 30초가 보통이다) 총 6천 시간, 250일이 된다. 하루에 업로드되는 음악을 듣는 데에만 거의 1년의 시간이 필요하다. 그런데 음악만 이럴까? 유튜브는 더하다. 2018년 기준으로 유튜브에는 1분마다 약 500시간 분량의 콘텐츠가 업로드되는데, 이걸 다 보려면 82년이 걸린다.\n그러니까 콘텐츠의 생산 수준은 이미 상식을 벗어났다는 얘기다. 그래도 생산 속도가 좀 느리진 않을까? 천만에. 생성형 AI가 가세하면서 그 속도는 상상 이상으로 빨라지고 있다. 1년만 지나도 영상과 음악 콘텐츠는 지금의 몇 배는 늘어날 수 있다. 우리는 인류 역사상 한 번도 경험하지 못한 콘텐츠 무한공급의 시대를 살고 있다. 그리고 이 시대야말로 문화예술을 사랑하는 사람들이 상상하던 바로 그 ‘문화 예술이 일상이 된 시대’다. 어서오세요, 문화 예술 콘텐츠가 흘러넘치는 디스토피아에.\n생산자로서는 노출이 중요해질 수밖에 없다. 세상 어딜 둘러봐도 ‘마케팅’이 문제고, 곳곳에서 마케터가 자주 눈에 띄는 이유다. 그런데 마케팅의 역할은 애초에 광고 집행이 아니라 효율적인 시장을 개발하는 것이다. 시장이 있어야 광고도 쓸모 있으니까. 그런데 지금은 미디어가 많아도 너무 많다. 기껏해야 텔레비전, 신문, 잡지, 라디오가 전부였던 ‘매스 미디어’ 시대에는 몇 개의 광고만으로도 큰 관심을 얻을 수 있었다. 우리 제품을 사주세요! 우리 음악을 들어주세요! 우리 영화 보러 극장에 오세요!\n하지만 지금은 무수히 많은 콘텐츠 채널과 앱 서비스가 알아서 돌아가는 시대다. 스마트폰 사용자는 전세계 55억명을 돌파했고, 이들은 스마트폰을 개인용 TV, 극장, 오디오, 게임기로 쓰고 있다. 55억개의 미디어가 존재하는 셈이다. 있는 줄도 몰랐던 유튜브 채널의 구독자가 5만, 10만, 20만이라는 걸 알게 되었을 때 얼마나 당황스러웠는지 떠올려보자. 2024년은 콘텐츠도 많은데 그걸 안내하고 유통하는 채널도 무수히 많은 시대다.\n그래서 팬덤이 중요해졌다. 팬덤의 부상은 미디어 분화의 결과다. 팬덤은 명확한 타깃의 총합이다. 홍보 효과가 큰 반면, 마케팅 비용은 적게 든다. 전환율도 높다. 팬은 기능이나 가격이 아니라 스토리와 드라마에 끌리는 사람들이다. 그래서 공감이 중요하다. 소비자들은 천천히 마음을 열다가  마침내 시간과 애정이라는 고귀한 ‘자원’을 쓰는 팬이 된다. 한국의 케이팝 팬들은 이들을 ‘덕후’라고 부른다. 다른 업계에서는 ‘찐팬’이라고 부른다. 해외에서는? ‘슈퍼 팬’이라고 부른다.\n슈퍼 팬은 왜 중요할까? \n음악 업계에서 ‘슈퍼 팬’이란 말이 유행한 것은 최근의 일이다. 음악, 영화, TV에 대한 방대한 데이터를 분석하는 회사 루미네이트(1990년에 빌보드 차트의 현대적 솔루션을 만든 회사다)는 2023년 7월에 50페이지 분량의 상반기 음악시장 보고서를 발표했는데, 여기서 ‘슈퍼 팬’이라는 개념이 본격적으로 등장했다.\n음악 산업에서 슈퍼 팬은 스트리밍 청취, 뮤직비디오 시청, 음반 구매*, 공연 참여, 굿즈 구매 등 최소 5가지 이상의 방법으로 한 아티스트의 콘텐츠를 소비하고 관계를 맺는 사람들로 정의한다. 미국의 슈퍼 팬은 일반 리스너와 비교해서 매달 음악에 80% 이상의 돈을 쓰는데 루미네이트는 이러한 슈퍼 팬이 미국 음악 시장 전체에서 최소한 15%를 차지한다고 분석했다. 특히 밀레니얼 세대(22% 이상), Z세대(13% 이상)가 주요 그룹이다.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*일단 피지컬(실물) 앨범을 구매한다면 슈퍼 팬이 될 가능성이 2배 이상 높다.\n우리는 이 슈퍼 팬이 대부분 케이팝 팬일 거라고 예상하지만 놀랍게도 아니다. 압도적으로 높은 것은 아프로-팝(블랙뮤직)의 팬들이고, 그 다음이 케이팝, 그 다음에 EDM이다. 다만 케이팝 팬들은 다른 장르 팬들에 비해 음반과 굿즈를 더 많이 구매한다. 그래서 미국 음악 업계는 요즘 케이팝에 관심이 많다. 대체 무슨 요술을 부리길래 저렇게 많은 팬들이 저렇게 많은 CD와 굿즈를 사는 걸까? 2024년인데! 딱 이런 궁금증이 케이팝에 대한 관심과 호감을 키운다. 유니버설뮤직그룹(UMG)이 하이브와 계약을 맺고, 워너뮤직그룹(WMG)이 위버스와 비슷한 .css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}팬덤 플랫폼을 만들겠다고 하는 것도 같은 이유다.\n사실 음악 산업의 비즈니스 모델은 슈퍼 팬을 찾는 방법에서부터 시작된다. 이때 팬을 찾는 방법론은 기존의 마케팅 방법론과는 다를 수밖에 없다. 팬은 소비자가 아니다. 팬은 부가 가치도 아니다. 팬은 수익 그 자체를 만드는 존재이면서 동시에 산업을 지탱하는 기반이기도 하다. 콘텐츠 비즈니스에서 슈퍼 팬은 비즈니스 모델의 처음이자 끝이다. 그런데 또한, 팬은 비즈니스 관점으로만 설명할 수 없는 존재다. 수익율과 전환율 같은 이런저런 지표를 관통하면서 팬은 마침내 문화를 만든다. 그래서 중요하다. 팬을 찾고 싶다면 결국 팬을 관찰하고 팬 문화를 경험할 수밖에 없다. 그걸 통해 팬을 어떻게 정의하고, 팬과 어떤 관계를 맺으며, 팬과 무엇을 함께 할 것인지 발견할 수밖에 없다. 그게 바로 팬덤 비즈니스다.\n팬덤 비즈니스를 하고 싶다면\n음악 산업의 슈퍼 팬을 이해해야 한다\n사실, 음악계 뿐 아니라 누구든 팬을 원하는 시대다. 여기서 ‘누구나’란 말이 질소로 빵빵한 과자 포장지 같을지 모르겠지만, 사실은 사실이다. 정말로 누구나 팬을 원한다.\n2021년부터 ‘팬덤 경영’을 강조한 LG는 지금도 팬을 만들기 위해 다양한 전략을 구사하고 있다. 애플은 말할 것도 없고, 짝퉁으로 놀림받던 샤오미와 다이소도 이제는 팬덤을 기반으로 사업을 확장한다. [어벤저스4: 엔드 게임] 이후 지지부진하던 마블은 어떤가? 얼마 전 공개한 [어벤져스5: 둠스데이]의 메인 빌런 ‘닥터 둠’으로 로버트 다우니 주니어를 섭외했다. 그가 연기한 슈퍼히어로이자 팬층이 두터웠던 ‘아이언 맨’은 전작에서 사망해 MCU에서 영영 사라졌는데, 신작에서 갑자기 우주 최강 빌런으로 부활한 것이다. 마블은 이제 꽤 복잡한 퍼즐을 맞춰야겠지만, 팬들은 일단 열광했다.\nF&B 업계에서도 팬은 중요하다. 올해 4월, ‘한식의 글로벌'이라는 주제로 [난로 인사이트 2024]라는 컨퍼런스가 열렸다. 행사에는 월드 챔피언 레스토랑으로 꼽히는 스페인의 센트럴(Central)과 디스푸르타르(Disfrutar)의 셰프들, 미국에서 한식 푸드트럭의 신화를 쓴 컵밥(CUPBOP)의 송정훈 대표, 유럽에서 한식 프랜차이즈를 개척 중인 요리(YORI)의 김종순 대표와 같은 사업가들이 참여했는데, 그곳에서 나는 케이팝과 뉴진스, 팬덤 비즈니스에 대해 발표했다. 행사가 끝나고도 여러 셰프들과 자리를 옮기며 글로벌, 브랜딩, 팬덤에 대해 동이 틀 때까지 대화를 나눴다.\n유튜브가 매년 발행하는 ‘컬쳐 & 트렌드 리포트’의 2024년 주제*도 '팬덤'이었다. 유튜버만큼 팬들이 중요하다는 얘기였다. 그야말로, 지금은 팬의 시대다. 그래서 아티스트나 크리에이터들 뿐 아니라 브랜드 마케터, 콘텐츠 기획자들은 팬을 관찰하고, 팬 문화를 더 많이 경험할 필요가 있다. \n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n📝 유튜브의 컬쳐 & 트렌드 리포트 2024에서는 \n\n팬이 콘텐츠 소비자가 아니라 적극적인 창작자로 진화하고 있다는 점을 짚었다. 숏폼 동영상 제작 툴과 생성형 AI 등 기술 발전으로 팬 참여가 급진적으로 쉬워지면서 캐주얼 팬이 적극적으로 돈을 지불하는 빅 팬이 되거나, 팬심으로 수익까지 창출하는 프로 팬으로 변화하고 있다는 것이다. \n특히 미국의 Z세대 65%가 자신을 ‘크리에이터'로 인식하고, 그 중 8%가 프로 팬으로서 수익을 창출한다는 부분이 흥미로웠다. 20세기의 팬들이 대상을 동경하면서 추종했다면, 21세기 팬들은 대상을 가지고 놀면서 수평적인 관계를 만든다.\n\n앞서 언급한 루미네이트의 보고서에는 음악의 슈퍼 팬이 왜 중요할 수밖에 없는지에 대한 이유가 등장한다. 음악의 슈퍼 팬은 스포츠 팬*에 비해 브랜드 파트너십에 매우 호의적이다. 쉽게 말해 아티스트가 어떤 브랜드의 광고 모델이 된다고 해도 거부감이 거의 없다. 음악이 브랜드 광고에 쓰여도 그러려니 한다. 오히려 자연스럽게 브랜드 구매로 이어지거나, 다른 사람들에게 적극적으로 그 브랜드를 알리기도 한다. 심지어 음악 팬들은 스포츠 팬에 비해 온라인 쇼핑이나 화장품, 배달 음식에 대해서도 더 호의적이다. \n*미국 사회에서 팬은, 한국과 달리 여전히 서브컬쳐에 머무는 존재다. 할리우드 청춘 영화나 드라마에서 사회성 부족한 인물이 ‘덕후’나 ‘너드’ 캐릭터로 등장하는 것도 그런 이유다. 그나마 ‘의미있는 집단’으로서의 슈퍼 팬은 스포츠에 국한되는데, 보통 미식축구, 농구, 야구 팬들을 대상으로 한 연구가 많았다. 음악의 슈퍼 팬에 대한 연구는 이제 시작 단계다. 그래서 종종 스포츠의 팬들과 비교된다. \n쉽게 말해, 음악 팬들은 일반 소비자보다 자신이 좋아하는 것에 더 많은 돈과 시간을 쓴다. 우리 비즈니스의 팬덤을 음악의 슈퍼 팬처럼 만들 수 있다면 얼마나 좋을까? 이게 바로 화장품 회사든 대기업이든, 음악 팬들을 이해하고 음악 산업을 살펴야봐야 할 이유다. \n\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 송수아 Graphic 이은호",
        "content": "비즈니스를 한다면, 음악 산업의 팬덤에 주목해야 하는 이유 ",
        "contentSnippet": "비즈니스를 한다면, 음악 산업의 팬덤에 주목해야 하는 이유",
        "guid": "https://blog.toss.im/article/fandustry-01",
        "isoDate": "2024-09-09T23:36:00.000Z"
      },
      {
        "title": "조선 시대 제사상 비용은 얼마였을까?",
        "link": "https://blog.toss.im/article/behindthemoney-7",
        "pubDate": "Mon, 09 Sep 2024 08:12:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}우리나라를 포함한 동아시아에는 오래된 믿음이 있다. ‘조상신이 가족을 돌보고 복을 준다.’ 사람을 돕는 신은 오직 죽은 자들, 그것도 가족 단위로 조상들만이 후손들을 돕는다고 믿었다. 물론 동아시아에도 옥황상제, 산신, 용왕 등 다양한 신들이 있지만 이런 자연신들은 자신들의 영역을 관장할 뿐 인간계에는 개입하지 않는다.\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}조상이 후손을 돕는다는 믿음은 유교 문화에 흡수되었고, 이러한 믿음에 따라 동아시아 제사 문화의 기본 단위는 ‘가족'이 되었다. 지금까지 가족 단위로 제사를 지내는 것은 수천 년에 걸쳐 내려온 오래된 동아시아 사람들의 믿음과 전통 때문인 것이다.\n하지만 오래된 전통이라도 시대에 따라 형태와 모양은 변하기 마련이다. 온라인에 보이는 요즘 제사 풍경은 그야말로 각양각색. 할머니, 할아버지가 생전에 좋아하시던 음식을 제사상에 올리기도 하고, 피자나 치킨이 제사상의 주인이 되기도 한다. 그렇다면, 옛날 제사상에는 어떤 음식이 올랐을까?\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}800년 전 제사상 엿보기\n시대별로 제사상에 오른 음식에 대해 명확히 설명하기는 어렵다. 제사 음식에 대한 구체적인 기록이 많지 않기도 하다. 수백 년 전통을 자랑하는 종갓집 제사상도 대부분 조선 후기의 문화를 반영하기 때문에 우리가 상상하는 제사상과 큰 차이가 없다.\n그럼에도 과거 기록은 몇 가지 흥미로운 사실을 알려준다. 고려 시대 의학서 ‘향약구급방'을 보면 연근, 도라지, 토란, 아욱, 상치, 무, 배추, 우엉 같은 채소를 제사상에 올렸다. 국가의 큰 제사에는 미나리, 죽순, 무청 등을 올렸다.\n시대에 따라 다양한 채소와 과일이 제사상에 올랐지만, 복숭아만큼은 제사상에 오르지 못했다. 공자의 제자들은 복숭아가 과일 중에 가장 하등품이고, 조상님들께 바치기에는 천박한 과일이라고 보았다. 반면,\n떡은 제사상에나 올리는 귀한 음식이었다. 전통사회에서는 쌀이 귀했기 때문에 떡을 만드는 것은 사치스러운 문화였고 제사상 혹은 잔칫상에서나 볼 수 있는 음식이었다.\n예나 지금이나 부담스러웠던 제사 비용\n2023년 추석 차례상 평균 비용은 30만 3,002원이었다.* 해마다 물가가 오르고 제사 비용에 대한 부담이 커지니 명절이 되면 제사상을 간소화하자는 기사가 쏟아진다. ‘옛날 제사상은 화려하지 않았다', ‘명문가일수록 제사상이 단출했다'는 식의 기사를 한 번쯤 보았을 것이다. 하지만 옛날 제사상이 간소했다는 주장은 1970년대 이후 정부 정책 영향의 결과이지 역사적 사실은 아니다.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*한국농수산식품유통공사 조사 결과\n오늘날에는 명절 차례와 가족 제사를 지내는 정도지만 과거에는 국가에서 제례를 지내고, 마을에서는 동제를 지내고, 절기마다 제사를 지냈다. 제사는 삶의 일부였다. 더구나 제사는 공동체의 축제였기 때문에 최대한 성대하게 치러졌다.\n조선시대에도 제사상을 차리는 데는 비용이 많이 들었다. 제사 비용을 충당하기 위해 ‘위토(位土)’라는 제도가 따로 있을 정도였다. 위토는 제사를 위한 토지로써 문중에서 공동으로 소유했던 땅이다. 위토에서 나오는 곡식을 팔아 제사 비용을 마련하거나 위토에 소작을 주어서 돈을 마련하기도 했다. 조선 시대에는 가문에 재산이 많고 크게 번성하면 문중을 중심으로 성대한 제사를 지냈다. 명절 때 차례는 물론이고 4대조에 이르는 조상의 기일에 맞추어서 일년 내내 제사를 지냈다.\n일반 평민들 역시 형편에 맞추어 제사를 지냈다. 형편이 어려워서 제사상이 단출할 수는 있어도 제사를 지내지 않는 경우를 상상하기는 어렵다. 물 한 사발이라도 올려놓고 치성을 드려야 하는 것이 법도인바, 최초로 제사를 거부하여 진산사건(1791)*을 일으킨 윤지충은 정조의 명에 따라 목숨을 잃고 가문이 풍비박산되었다.\n*1791년, 전라도 진산(珍山)의 윤지충, 권상연 두 선비가 부모의 제사를 거부하고 위패를 불태운 사건. 두 사람은 천주교 신자였으며 교리에 따라 조상의 제사를 거부했다.\n1934년, 일제강점기에는 제사 비용을 마련하지 못해서 음독자살 했던 어느 부부의 이야기가 신문에 보도된 적이 있었다. 제사 비용에 대한 부담뿐만 아니라 식민지 시절 가난한 백성의 고달픈 살림살이에 대한 애환을 담고 있는 기사이다.\n.css-2sk6rv{font-size:19px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);white-space:pre-wrap;margin:24px 0;padding-left:20px;position:relative;}.css-2sk6rv::before{content:'';display:block;position:absolute;top:4px;left:0;width:2px;height:calc(100% - 4px * 2);padding:4px 0;background-color:var(--adaptiveGrey800);}\n.css-1odxvuk{white-space:pre-wrap;font-style:italic;}“부부간 싸움 끝에 양재물을 먹고 자살하였는데.. 모친의 제사 지낼 비용을 십원만 부조해달라는 편지를 받고... 가난한 생활을 견딜 수 없어.. 비관자살을 하였다.\"\n- 1934. 2. 19. 조선일보.css-7mseny>*{margin-left:0;margin-right:0;}.css-7mseny>:last-child{margin-bottom:0;}blockquote>.css-7mseny:first-child>:first-child{margin-top:0;}\n갈비찜 대신 사태찜, 식혜 대신 화채 \n나라에서 정해주는 제사상 가이드\n6.25전쟁 이후 산업화가 진행되면서 사람들은 농촌을 떠나 도시에 정착했고, 경제성장에 버금가는 물가상승 덕분에 제사상 비용은 점차 사회 문제가 되었다.\n한정된 월급에서, 날로 물가는 오르고 따라서 필수의 씀씀이가 자꾸 늘어가는데 반비례하여 제사비용으로 돌아가는 예산은 축소될 수밖에 없다. 종가라고 해서 모든 것을 우리에게만 전담시킬 것이 아니라 세 집에서 분담하는 것이 바람직한 일이다. 분노를 삭이듯 침통하게 눈을 감고 계시던 숙부가 천천히 고개를 들었다. \n\n“일언이 폐지하고 이런 문제에 네가 나설 일이 아니야. 네 남편이 있잖아. 네 남편이, 네가 살림을 맡고서부터 젯상은 날로 형편이 없어졌어. 두고보자 보자 했더니 이건 한술 더 떠서 뭔시 어쩌고 어째? 아니 그래 갑자기 이 집이 망하기라도 했다는게냐 엉? 항창 그렇다 치자. 네 남편을 통해 얘기하는거야.”\n- 1973. 1. 4. 동아일보\n위의 내용은 ‘제삿날’이라는 1970년대 동아일보 기사의 일부이다. 치솟는 물가와 부담스러운 제사 비용 때문에 장손의 며느리가 제사 비용을 분담하자고 했다가 숙부들의 분노와 반발을 샀다는 내용이다. 숙부들은 ‘너가 며느리로 들어온 후 제사상이 형편없어졌다.’, ‘할 얘기 있으면 너가 아니라 네 남편이 해야 한다’ 등 모욕적인 말도 서슴치 않았다.\n1960년대 이후 한국 사회는 과도한 제사 비용을 해소하기 위해 머리를 맞대기 시작한다. 정부에서는 전통적인 관혼상제의 허례허식을 줄이고, 절차의 간소화를 위한 ‘가정의례준칙’을 만들어 검소한 제사상을 강제했다. 가족끼리 제사와 차례 비용을 분담하는 방식 역시 이때부터 나온 이야기다.\n첫째, 제사를 꼭 맏아들이 주관할 필요는 없다. 둘째, 형식보다는 내면이기 때문에 고인이 평소 좋아하던 음식으로 제사상을 차리거나 고인의 유품 같은 것을 놓을 것을 권장한다. 셋째, 축문은 한문이 아닌 한글로 써서 조상과 자손 간의 유대 관계를 강화한다. 1970년대 유신 시절 정부는 한바탕 제사상과의 전쟁을 치렀는데 그럼에도 불구하고 제사 자체를 폐지하는 데는 이르지 못했다.\n1980년대가 되면 더욱 구체적인 제사상 가이드가 등장한다. ‘다섯 명 기준으로 2~3만 원 정도’를 적정 제사 비용으로 보았고 이를 실천하기 위해 소고기가 아닌 돼지고기나 닭고기 사용을 권장했고 갈비찜보다는 사태찜, 버섯은 송이버섯보다는 표고버섯이나 느타리버섯, 식혜보다는 화채를 사용하면 비용을 낮출 수 있다는 것이다. 유신 체제 때 강제하던 가정의례준칙은 1999년 폐지되었지만, 90년대 초반까지 보다 실용적인 해법을 도모하며 제사 비용을 아끼려는 노력은 계속 이어졌다.\n하마터면 사라질 뻔했던 추석\n사실 제사 비용보다 문제가 되었던 것은 추석을 비롯한 명절 자체를 없애버리려는 시도였다. 1927년 조선을 점령한 일본은 공휴일제도를 법제화했다. 원시제(양력 1월 3일), 신무천황제(양력 4월 3일), 신상제(양력 10월 17일), 명치절(양력 11월 3일) 등 새롭게 마련된 절기는 철저하게 일본의 문화를 바탕으로 했다.\n그중 신상제는 천황이 신에게 햇곡식을 바치는 제도로써 추석을 대체하는 제도였다. 우리 민족의 명절은 음력을 따라 계산되었는데 일제는 서구화를 도모하면서 양력 공휴일제를 강요한 것이다. 심지어 명절을 맞이해 단체 삭발을 강요하기도 했다. 소위 '스포츠 머리'로 깨끗하고 단정하게 머리를 밀어버리라는 근본없는 문화가 생기기도 했다.\n해방이 되고나니 미국의 영향을 받아 추석을 ‘추석감사일’, 즉 추수감사절과 같은 날로 만들고자 했으니 이 또한 웃지 못할 해프닝이었다. 우여곡절을 거치며 1989년이 되어서야 지금과 같이 음력을 바탕으로 한 설·추석 3일 연휴제가 만들어졌다.\n놀라운 것은 이 기간에도 명절 문화는 유지가 되었다는 점이다. 공휴일이 아니더라도, 일제가 억압을 하고, 정부가 못하게 하더라도 사람들은 명절이 되면 모였고, 세시 풍속을 즐겼고, 덕담을 나누었다. 따져보니 추석은 100년 만에 부활한 셈이다. 앞으로 명절 풍경은 어떻게 변하게 될까? 시대에 어울리는 풍요롭고, 스트레스 없는 추석 명절 문화가 만들어지길 기대해본다.\n.css-13d8cj1{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;margin:24px 0 8px;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:var(--adaptiveGrey700);}\n.css-1dzrkjz{width:16px;margin-right:8px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}\n.svg-icon-wrapper{position:relative;display:inline-block;width:24px;height:24px;}.svg-icon-wrapper >.svg-icon:empty+.svg-icon-fallback{visibility:visible;z-index:inherit;}.svg-icon{color:var(--adaptiveGrey900);display:inline-block;width:24px;height:24px;display:block;width:100%;height:100%;}.svg-icon svg,.svg-icon img{display:block;width:100%;height:100%;}.svg-icon--hide{display:none;}.svg-icon-fallback{position:absolute;left:0;right:0;top:0;z-index:z-index(hidden);visibility:hidden;display:block;width:100%;height:100%;}.svg-icon-fallback--show{visibility:visible;z-index:inherit;}\n참고자료\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 이지영 Graphic 이은호",
        "content": "옛날 제사상이 간소했다는 주장, 역사적 사실은 아니다.",
        "contentSnippet": "옛날 제사상이 간소했다는 주장, 역사적 사실은 아니다.",
        "guid": "https://blog.toss.im/article/behindthemoney-7",
        "isoDate": "2024-09-09T08:12:00.000Z"
      },
      {
        "title": "‘김영란법’ 식사비 한도가 5만 원으로 올랐어요",
        "link": "https://blog.toss.im/article/money-policies-25",
        "pubDate": "Fri, 06 Sep 2024 01:43:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}‘김영란법'으로 불리는 ‘부정청탁 및 금품 등 수수의 금지에 관한 법률(이하 청탁금지법)’상\n식사비 한도가 기존 3만 원에서 5만 원으로 올랐어요. .css-1kxrhf3{white-space:pre-wrap;}2016년 청탁금지법이 시행된 지 8년\n만의 첫 인상이에요.\n\n그동안 청탁금지법상 공직자·언론인·사립학교 교직원 등은 원활한 직무수행, 사교·의례 등의\n목적으로 제공되는 3만 원 이하의 음식물, 5만 원 이하의 선물만 받을 수 있었는데요.\n\n음식물(식사비)의 경우 2003년 마련된 기준이 20년간 유지되면서 제도의 실효성 저하를\n우려하는 목소리가 제기되어 왔어요. 또 고물가와 경기침체, 소비위축 등으로 어려움을 겪는\n소상공인, 자영업자 지원 등을 위해 식사비 기준 한도를 높여달라는 의견도 꾸준했어요.\n\n한편 청탁금지법상 공직자 등에게 예외적으로 허용되는 농수산물·농수산가공품 선물의 가액\n한도는 평상시 15만 원, 추석·설날 명절 30만 원으로 기존과 같이 유지돼요. 청탁금지법상\n설날·추석 선물 기간은 명절 당일 전 24일부터 당일 후 5일이에요. 올해 추석 기간에는 8월\n24일부터 9월 22일까지 농수산물과 농수산가공품 선물 가액 한도가 평상시의 두 배인 30만\n원으로 상향 적용돼요.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}Edit 이지영 Graphic 조수희",
        "content": "청탁금지법 시행 8년 만에 첫 인상이에요.",
        "contentSnippet": "청탁금지법 시행 8년 만에 첫 인상이에요.",
        "guid": "https://blog.toss.im/article/money-policies-25",
        "isoDate": "2024-09-06T01:43:00.000Z"
      },
      {
        "title": "토스 투자자들이 토스에 묻는 것들 ",
        "link": "https://blog.toss.im/article/toss-ir-story",
        "pubDate": "Thu, 05 Sep 2024 09:10:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}최근 토스의 .css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}2024년 상반기 실적이 공개되면서 토스의 재무적 성장세가 시장의 많은 관심을 받고 있어요. 올해 상반기 매출이 9,141억원(연결 기준)으로 작년 같은 기간보다 40% 증가하며 역대 최대치를 기록했고요. 2분기로 좁혀 보면 영업이익이 처음으로 흑자 전환했기 때문이에요.\n토스는 그동안 알토스벤처스, 굿워터캐피탈, 싱가포르투자청, KDB산업은행 등 국내외 유수의 기관으로부터 누적 1조 6,000억원 넘는 투자를 유치했습니다. 이 투자자들은 토스가 보여주는 성과에 놀라워하는 한편, 앞으로의 성장 잠재력을 더욱 궁금하게 여깁니다.\n그럴 때 토스팀이 내놓는 답은 무엇일까요? 전세계 투자자들에게 토스의 매력을 알리는 역할을 맡고 있는 Investor Relations Team 리더 .css-q3ktjb{white-space:pre-wrap;font-weight:bold;}김민우 님으로부터 토스의 IR 스토리*를 들어봤습니다.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*스타트업이 투자를 유치하기 위해, 지금까지 달성한 회사의 성과와 앞으로 달성하고자 하는 목표 및 그 계획을 하나의 이야기로 꿰어 전달하는 것을 말해요.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n투자자들이 보는 세 가지\n바다, 배, 선장\n스타트업은 ‘자유항해’를 꿈꿉니다. 더이상 외부 자금을 투자받지 않고도, 스스로 충분한 매출과 이익을 만들어 내며 나아갈 수 있는 상황을 의미해요. 토스도 마찬가지입니다.\n투자자들도 이 목표를 이룰 수 있을 것으로 판단되는 기업에 투자하기 마련이에요. 그렇다면 어떤 기업이 자유 항해에 성공할까요? 투자자들은 크게 세 가지 측면을 살핍니다.\n.css-hokoge{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;counter-reset:numberedList;}.css-hokoge ul,.css-hokoge ol{margin:16px 0 0;}.css-hokoge>li{counter-increment:numberedList;margin-bottom:16px;padding-left:24px;}.css-hokoge>li:last-of-type{margin-bottom:0;}.css-hokoge>li>span{position:relative;}.css-hokoge>li>span>:first-child::before{content:counter(numberedList) '.';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n바다(Ocean): .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}기업이 경쟁하고 있는 시장을 의미합니다. 이 기업이 항해하고 있는 바다가 충분히 거대하며 성장하고 있는 산업인지를 보는 거예요. 지금 토스의 바다는 한국의 금융 산업, 그 중에서도 디지털화 할 수 있는 시장이라고 할 수 있지요. 이 시장에 대한 규제 환경 변화 등 어떤 순풍 혹은 역풍이 불고 있는지도 중요한 판단 요소입니다.\n배(Boat): 기업이 그 시장에서 뚜렷한 경쟁 우위를 갖는 분명한 리더인지를 봅니다. 토스가 한 척의 배라면 얼마나 멀리까지, 빠르게 갈 수 있을지 증명해야 하죠. 토스 코어를 포함해, 토스증권, 토스뱅크, 토스인슈어런스, 토스페이먼츠, 토스플레이스 등 토스 커뮤니티의 비즈니스 모델이 서로 잘 결합돼 있으며, 앞으로 수십년간 성장의 가능성과 속도를 명확히 설명하는 것이 중요해요.\n선장(Captain): 기업의 리더십과 전략을 말해요. 경영진이 얼마나 훌륭한 비전을 제시하고 있으며, 전략을 실행할 수 있는 역량을 갖췄는지 살펴보는 거예요.\n\n토스가 항해하고 있는 바다, 그리고 토스라는 배와 그 위의 선장이 투자자들로부터 어떤 평가를 받고 있는지 살펴볼게요.\n토스가 항해하는 드넓은 대양,\n50조원에 이르는 디지털 금융 산업\n현재 토스가 경쟁하는 시장은 한국의 디지털 금융 산업입니다. 결제, 증권 투자, 금융상품 광고, 중개(Marketplace) 등 수익성이 높은 사업 영역이 포진돼 있어요. 토스는 이 시장을 현재 연 매출 50조원(2023년 기준) 규모에 달하는 것으로 추정하고 있어요.\n그런데 이 50조원 규모의 시장에서 토스가 현재 차지한 비중은 약 3%에 불과합니다. 갈 길이 멀지요. 반대로 토스의 매출 창출 여력이 크다고 해석할 수도 있습니다. 향후 5년간 각 영역에서 빠르게 토스의 비중을 늘려가는 것을 목표로 삼고 있어요.\n다시 말해 “토스가 항해하는 바다는 굉장히 넓은 대양이고, 앞으로 토스가 가야 할 길은 멀다. 이 시장은 앞으로 더 클 텐데, 토스는 그보다 더 빠른 속도로 크겠다”라는 것이 토스팀의 비전이자 방향성입니다.\n토스라는 튼튼한 배,\n원앱 전략과 압도적인 인게이지먼트\n그 목표를 어떻게 달성할 거냐고요? 토스의 원앱(One App) 전략이 그 기반이 되어줍니다. 투자, 뱅킹, 보험, 결제 등의 영역에 따라 별도의 앱을 만드는 대신, 하나의 토스 앱에서 모든 영역의 서비스를 제공하는 것을 말해요. \n토스증권, 토스뱅크가 토스 앱 안에서 순차적으로 런칭한 2021년 이후, 토스는 사용자들에게 ‘금융의 슈퍼앱’으로 자리 잡았습니다.\n투자자들은 세 가지 지표를 보고 금융 슈퍼앱 토스가 한국 디지털 금융 시장에서 독보적인 1위라는 사실에 고개를 끄덕입니다.\n첫 번째는 1,900만(2023년 말, 와이즈앱 기준)에 이르는 MAU입니다. 우리나라 인구 3명 중 1명 이상이 토스를 매달 한 번 이상 사용한다는 의미이지요. 두 번째, 무려 600조원을 초과하는 토스 플랫폼의 연간 금융 거래액입니다.\n마지막으로 투자자들이 제일 중요하게 여기는 지표는 ‘인게이지먼트(Engagement)’ 수준입니다. 고객 참여도 또는 앱 활성도라고도 표현하는데요. ‘사용자 수가 많은 것은 알겠는데, 그들이 토스 앱을 얼마나 자주, 유용하게 쓰고 있느냐’고 묻는 것입니다. \n토스팀은 “월간 활성 사용자 중에서도 ‘매일 토스 앱을 쓰는 사용자(DAU)’의 비중이 50% 이상”이라는 답을 내놓습니다.\n여기서 많은 투자자들이 놀랍니다. 소셜 네트워크 서비스나 채팅 앱에서나 가능한 숫자이기 때문이에요. 전 세계에서 가장 많이 쓰는 채팅 앱 왓츠앱의 DAU/MAU가 50% 초반이라고 하니, 토스는 이미 핀테크의 영역을 넘어섰습니다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n\n특히 토스 사용자들이 하루 평균 9번 토스 앱을 켠다는 데이터에 해외 투자자들은 감탄합니다. 스스로 ‘슈퍼 앱’이라고 주장하는 앱이 많지만, 토스처럼 ‘슈퍼 앱’ 전략이 제대로 작동해 압도적인 인게이지먼트를 만들어 내는 앱은 전세계적으로 찾아보기 힘들기 때문이에요. \n앞으로의 성장 전략,\n시간이 갈수록 늘어나는 ARPU\n토스는 현재 70가지 넘는 서비스를 11개 카테고리로 구분하는데, 2024년 3월 기준 사용자들은 평균 4.1개 카테고리의 서비스를 넘나들며 토스 앱을 적극적으로 이용하고 있습니다. 또 이렇게 4개 이상 카테고리를 이용하는 사용자의 월간 리텐션은 90%에 달해요. 다음 달에도 토스 앱을 이용하고 있을 확률이 90%라는 뜻입니다.\n토스 앱을 자주 켜고 다양한 서비스를 이용하는 사용자의 행위는 곧 토스의 매출 성장 잠재력으로 이어집니다. 아래 표에서 보는 것처럼 토스의 각 서비스는 ‘전략적인 목표’를 가지고 있는데요.\n\n\n\n송금이나 금융 대시보드, 혜택 등은 토스가 돈을 버는 구조의 서비스는 아니지만, 사용자들이 토스에 가입하고 계속 쓰는 유인이 됩니다. 이후 토스 앱에 모인 사용자들이 간편결제, 금융상품 가입, 주식투자, 뱅킹 등 토스가 매출을 창출해 낼 수 있는 서비스까지 이용하기 시작합니다.\n커머스, 광고, 세금환급 등 새로운 서비스를 론칭했을 때에도, 사용자들은 여전히 토스 앱 안에서 쉽게 접근하고 탐색합니다. 투자자들에게는 “사용자를 획득하고 리텐션 시키는 비용을 최소화하면서 사용자 1인당 매출은 극대화하는 전략”으로 받아들여집니다.\n사용자 1명이 발생시키는 매출을 ARPU(Average Revenue Per User)라고 부르는데요. 사용자가 이용하는 서비스 개수가 늘어날수록 ARPU도 늘어납니다. 토스팀은 특히 사용자의 가입 시점에 따른 서비스 이용 개수와 ARPU의 변화를 유의해서 지켜보고 있어요.\n지난 2018년 토스에 가입한 사용자들은 1개 이하의 서비스만 쓰다가 6년이 지난 지금 평균 4개 이상의 서비스를 이용하는데요. 최근 가입한 사용자들은 처음부터 평균 2.4가지 서비스를 사용하고, 빠르게 4개 이상에 도달하는 추이를 보입니다.\n그만큼 토스의 사용자 대상 서비스 ARPU 역시 빠른 속도로 증가하고 있어요. 2022년 연 22.6달러였던 ARPU는 2023년 26.7달러, 2024년 1분기에는 연환산 기준 34달러로 늘었습니다. 반면 사용자 획득 비용과 서비스 운영 비용은 안정화되며 토스 전체의 수익성은 개선되고 있지요.\n토스의 내일을 기대하는 까닭 \n토스는 사용자 인게이지먼트가 높은 플랫폼 서비스가 더 많은 ARPU를 창출하며 수익성을 확보할 수 있다는 가설을 매순간 증명해 내고 있습니다.\n2024년 2분기에는 처음으로 영업이익(연결 기준)이 흑자로 전환하는 성과를 거뒀어요. 상반기 매출은 작년 같은 기간 대비 40% 가까이 늘어났습니다. 토스증권 등 계열사의 실적도 뛰어났지만, 이번에는 간편결제와 광고, 세무 서비스 등 토스 코어의 사용자 대상 서비스가 크게 성장했던 것도 한 몫 했습니다.\n연 매출 1조원 넘는 기업이 매년 이처럼 큰 폭의 성장세를 기록하는 사례는 굉장히 드뭅니다. 전 세계의 핀테크 회사들을 지켜보는 투자자들이 ‘토스는 아직 더 클 여지가 있구나’ 흥분을 불러 일으키는 대목이자, 토스의 다음 분기, 반기, 내년을 기대하는 까닭입니다.\n\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nWords 김민우 Edit 정경화 Graphic 조수희・이서영",
        "content": "IR 스토리로 보는 토스의 성장 잠재력",
        "contentSnippet": "IR 스토리로 보는 토스의 성장 잠재력",
        "guid": "https://blog.toss.im/article/toss-ir-story",
        "isoDate": "2024-09-05T09:10:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]