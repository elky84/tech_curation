[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Strobelight: A profiling service built on open source technology",
        "link": "https://engineering.fb.com/2025/01/21/production-engineering/strobelight-a-profiling-service-built-on-open-source-technology/",
        "pubDate": "Tue, 21 Jan 2025 17:00:54 +0000",
        "content:encodedSnippet": "We’re sharing details about Strobelight, Meta’s profiling orchestrator.\nStrobelight combines several technologies, many open source, into a single service that helps engineers at Meta improve efficiency and utilization across our fleet.\nUsing Strobelight, we’ve seen significant efficiency wins, including one that has resulted in an estimated 15,000 servers’ worth of annual capacity savings.\nStrobelight, Meta’s profiling orchestrator, is not really one technology. It’s several (many open source) combined to make something that unlocks truly amazing efficiency wins. Strobelight is also not a single profiler but an orchestrator of many different profilers (even ad-hoc ones) that runs on all production hosts at Meta, collecting detailed information about CPU usage, memory allocations, and other performance metrics from running processes. Engineers and developers can use this information to identify performance and resource bottlenecks, optimize their code, and improve utilization.\nWhen you combine talented engineers with rich performance data you can get efficiency wins by both creating tooling to identify issues before they reach production and finding opportunities in already running code. Let’s say an engineer makes a code change that introduces an unintended copy of some large object on a service’s critical path. Meta’s existing tools can identify the issue and query Strobelight data to estimate the impact on compute cost. Then Meta’s code review tool can notify the engineer that they’re about to waste, say, 20,000 servers.\nOf course, static analysis tools can pick up on these sorts of issues, but they are unaware of global compute cost and oftentimes these inefficiencies aren’t a problem until they’re gradually serving millions of requests per minute. The frog can boil slowly.\nWhy do we use profilers?\nProfilers operate by sampling data to perform statistical analysis. For example, a profiler takes a sample every N events (or milliseconds in the case of time profilers) to understand where that event occurs or what is happening at the moment of that event. With a CPU-cycles event, for example, the profile will be CPU time spent in functions or function call stacks executing on the CPU. This can give an engineer a high-level understanding of the code execution of a service or binary.\nChoosing your own adventure with Strobelight\nThere are other daemons at Meta that collect observability metrics, but Strobelight’s wheelhouse is software profiling. It connects resource usage to source code (what developers understand best). Strobelight’s profilers are often, but not exclusively, built using eBPF, which is a Linux kernel technology. eBPF allows the safe injection of custom code into the kernel, which enables very low overhead collection of different types of data and unlocks so many possibilities in the observability space that it’s hard to imagine how Strobelight would work without it.\nAs of the time of writing this, Strobelight has 42 different profilers, including:\nMemory profilers powered by jemalloc.\nFunction call count profilers.\nEvent-based profilers for both native and non-native languages (e.g., Python, Java, and Erlang).\nAI/GPU profilers.\nProfilers that track off-CPU time.\nProfilers that track service request latency.\nEngineers can utilize any one of these to collect data from servers on demand via Strobelight’s command line tool or web UI.\nThe Strobelight web UI.\nUsers also have the ability to set up continuous or “triggered” profiling for any of these profilers by updating a configuration file in Meta’s Configerator, allowing them to target their entire service or, for example, only hosts that run in certain regions. Users can specify how often these profilers should run, the run duration, the symbolization strategy, the process they want to target, and a lot more.\nHere is an example of a simple configuration for one of these profilers:\nadd_continuous_override_for_offcpu_data(\r\n    \"my_awesome_team\", // the team that owns this service\r\n    Type.SERVICE_ID,\r\n    \"my_awseome_service\",\r\n    30_000, // desired samples per hour\r\n)\r\n\nWhy does Strobelight have so many profilers? Because there are so many different things happening in these systems powered by so many different technologies.\nThis is also why Strobelight provides ad-hoc profilers. Since the kind of data that can be gathered from a binary is so varied, engineers often need something that Strobelight doesn’t provide out of the box. Adding a new profiler from scratch to Strobelight involves several code changes and could take several weeks to get reviewed and rolled out.\nHowever, engineers can write a single bpftrace script (a simple language/tool that allows you to easily write eBPF programs) and tell Strobelight to run it like it would any other profiler. An engineer that really cares about the latency of a particular C++ function, for example, could write up a little bpftrace script, commit it, and have Strobelight run it on any number of hosts throughout Meta’s fleet – all within a matter of hours, if needed.\nIf all of this sounds powerfully dangerous, that’s because it is. However, Strobelight has several safeguards in place to prevent users from causing performance degradation for the targeted workloads and retention issues for the databases Strobelight writes to. Strobelight also has enough awareness to ensure that different profilers don’t conflict with each other. For example, if a profiler is tracking CPU cycles, Strobelight ensures another profiler can’t use another PMU counter at the same time (as there are other services that also use them).\nStrobelight also has concurrency rules and a profiler queuing system. Of course, service owners still have the flexibility to really hammer their machines if they want to extract a lot of data to debug.\nDefault data for everyone\nSince its inception, one of Strobelight’s core principles has been to provide automatic, regularly-collected profiling data for all of Meta’s services. It’s like a flight recorder – something that doesn’t have to be thought about until it’s needed. What’s worse than waking up to an alert that a service is unhealthy and there is no data as to why?\nFor that reason, Strobelight has a handful of curated profilers that are configured to run automatically on every Meta host. They’re not running all the time; that would be “bad” and not really “profiling.” Instead, they have custom run intervals and sampling rates specific to the workloads running on the host. This provides just the right amount of data without impacting the profiled services or overburdening the systems that store Strobelight data.\nHere is an example:\nA service, named Soft Server, runs on 1,000 hosts and let’s say we want profiler A to gather 40,000 CPU-cycles samples per hour for this service (remember the config above). Strobelight, knowing how many hosts Soft Server runs on, but not how CPU intensive it is, will start with a conservative run probability, which is a sampling mechanism to prevent bias (e.g., profiling these hosts at noon every day would hide traffic patterns).\nThe next day Strobelight will look at how many samples it was able to gather for this service and then automatically tune the run probability (with some very simple math) to try to hit 40,000 samples per hour. We call this dynamic sampling and Strobelight does this readjustment every day for every service at Meta.\nAnd if there is more than one service running on the host (excluding daemons like systemd or Strobelight) then Strobelight will default to using the configuration that will yield more samples for both.\nHang on, hang on. If the run probability or sampling rate is different depending on the host for a service, then how can the data be aggregated or compared across the hosts? And how can profiling data for multiple services be compared?\nSince Strobelight is aware of all these different knobs for profile tuning, it adjusts the “weight” of a profile sample when it’s logged. A sample’s weight is used to normalize the data and prevent bias when analyzing or viewing this data in aggregate. So even if Strobelight is profiling Soft Server less often on one host than on another, the samples can be accurately compared and grouped. This also works for comparing two different services since Strobelight is used both by service owners looking at their specific service as well as efficiency experts who look for “horizontal” wins across the fleet in shared libraries.\nHow Strobelight saves capacity\nThere are two default continuous profilers that should be called out because of how much they end up saving in capacity.\nThe last branch record (LBR) profiler \nThe LBR profiler, true to its name, is used to sample last branch records (a hardware feature that started on Intel). The data from this profiler doesn’t get visualized but instead is fed into Meta’s feedback directed optimization (FDO) pipeline. This data is used to create FDO profiles that are consumed at compile time (CSSPGO) and post-compile time (BOLT) to speed up binaries through the added knowledge of runtime behavior. Meta’s top 200 largest services all have FDO profiles from the LBR data gathered continuously across the fleet. Some of these services see up to 20% reduction in CPU cycles, which equates to a 10-20% reduction in the number of servers needed to run these services at Meta.\nThe event profiler\nThe second profiler is Strobelight’s event profiler. This is Strobelight’s version of the Linux perf tool. Its primary job is to collect user and kernel stack traces from multiple performance (perf) events e.g., CPU-cycles, L3 cache misses, instructions, etc. Not only is this data looked at by individual engineers to understand what the hottest functions and call paths are, but this data is also fed into monitoring and testing tools to identify regressions; ideally before they hit production.\nDid someone say Meta…data?\nLooking at function call stacks with flame graphs is great, nothing against it. But a service owner looking at call stacks from their service, which imports many libraries and utilizes Meta’s software frameworks, will see a lot of “foreign” functions. Also, what about finding just the stacks for p99 latency requests? Or how about all the places where a service is making an unintended string copy?\nStack schemas\nStrobelight has multiple mechanisms for enhancing the data it produces according to the needs of its users. One such mechanism is called Stack Schemas (inspired by Microsoft’s stack tags), which is a small DSL that operates on call stacks and can be used to add tags (strings) to entire call stacks or individual frames/functions. These tags can then be utilized in our visualization tool. Stack Schemas can also remove functions users don’t care about with regex matching. Any number of schemas can be applied on a per-service or even per-profile basis to customize the data.\nThere are even folks who create dashboards from this metadata to help other engineers identify expensive copying, use of inefficient or inappropriate C++ containers, overuse of smart pointers, and much more. Static analysis tools that can do this have been around for a long time, but they can’t pinpoint the really painful or computationally expensive instances of these issues across a large fleet of machines.\nStrobemeta\nStrobemeta is another mechanism, which utilizes thread local storage, to attach bits of dynamic metadata at runtime to call stacks that we gather in the event profiler (and others). This is one of the biggest advantages of building profilers using eBPF: complex and customized actions taken at sample time. Collected Strobemeta is used to attribute call stacks to specific service endpoints, or request latency metrics, or request identifiers. Again, this allows engineers and tools to do more complex filtering to focus the vast amounts of data that Strobelight profilers produce.\nSymbolization\nNow is a good time to talk about symbolization: taking the virtual address of an instruction, converting it into an actual symbol (function) name, and, depending on the symbolization strategy, also getting the function’s source file, line number, and type information.\nMost of the time getting the whole enchilada means using a binary’s DWARF debug info. But this can be many megabytes (or even gigabytes) in size because DWARF debug data contains much more than the symbol information.\nThis data needs to be downloaded then parsed. But attempting this while profiling, or even afterwards on the same host where the profile is gathered, is far too computationally expensive. Even with optimal caching strategies it can cause memory issues for the host’s workloads.\nStrobelight gets around this problem via a symbolization service that utilizes several open source technologies including DWARF, ELF, gsym, and blazesym. At the end of a profile Strobelight sends stacks of binary addresses to a service that sends back symbolized stacks with file, line, type info, and even inline information.\nIt can do this because it has already done all the heavy lifting of downloading and parsing the DWARF data for each of Meta’s binaries (specifically, production binaries) and stores what it needs in a database. Then it can serve multiple symbolization requests coming from different instances of Strobelight running throughout the fleet.\nTo add to that enchilada (hungry yet?), Strobelight also delays symbolization until after profiling and stores raw data to disk to prevent memory thrash on the host. This has the added benefit of not letting the consumer impact the producer – meaning if Strobelight’s user space code can’t handle the speed at which the eBPF kernel code is producing samples (because it’s spending time symbolizing or doing some other processing) it results in dropped samples.\nAll of this is made possible with the inclusion of frame pointers in all of Meta’s user space binaries, otherwise we couldn’t walk the stack to get all these addresses (or we’d have to do some other complicated/expensive thing which wouldn’t be as efficient). \nA simplified Strobelight service graph.\nShow me the data (and make it nice)!\nThe primary tool Strobelight customers use is Scuba – a query language (like SQL), database, and UI. The Scuba UI has a large suite of visualizations for the queries people construct (e.g., flame graphs, pie charts, time series graphs, distributions, etc).\nStrobelight, for the most part, produces Scuba data and, generally, it’s a happy marriage. If someone runs an on-demand profile, it’s just a few seconds before they can visualize this data in the Scuba UI (and send people links to it). Even tools like Perfetto expose the ability to query the underlying data because they know it’s impossible to try to come up with enough dropdowns and buttons that can express everything you want to do in a query language – though the Scuba UI comes close.\nAn example flamegraph/icicle of function call stacks of the CPU cycles event for the mononoke service for one hour.\nThe other tool is a trace visualization tool used at Meta named Tracery. We use this tool when we want to combine correlated but different streams of profile data on one screen. This data is also a natural fit for viewing on a timeline. Tracery allows users to make custom visualizations and curated workspaces to share with other engineers to pinpoint the important parts of that data. It’s also powered by a client-side columnar database (written in JavaScript!), which makes it very fast when it comes to zooming and filtering. Strobelight’s Crochet profiler combines service request spans, CPU-cycles stacks, and off-CPU data to give users a detailed snapshot of their service.\nAn example trace in Tracery.\nThe Biggest Ampersand\nStrobelight has helped engineers at Meta realize countless efficiency and latency wins, ranging from increases in the number of requests served, to large reductions in heap allocations, to regressions caught in pre-prod analysis tools.\nBut one of the most significant wins is one we call, “The Biggest Ampersand.”\nA seasoned performance engineer was looking through Strobelight data and discovered that by filtering on a particular std::vector function call (using the symbolized file and line number) he could identify computationally expensive array copies that happen unintentionally with the ‘auto’ keyword in C++.\nThe engineer turned a few knobs, adjusted his Scuba query, and happened to notice one of these copies in a particularly hot call path in one of Meta’s largest ads services. He then cracked open his code editor to investigate whether this particular vector copy was intentional… it wasn’t.\nIt was a simple mistake that any engineer working in C++ has made a hundred times.\nSo, the engineer typed an “&” in front of the auto keyword to indicate we want a reference instead of a copy. It was a one-character commit, which, after it was shipped to production, equated to an estimated 15,000 servers in capacity savings per year!\nGo back and re-read that sentence. One ampersand! \nAn open ending\nThis only scratches the surface of everything Strobelight can do. The Strobelight team works closely with Meta’s performance engineers on new features that can better analyze code to help pinpoint where things are slow, computationally expensive, and why.\nWe’re currently working on open-sourcing Strobelight’s profilers and libraries, which will no doubt make them more robust and useful. Most of the technologies Strobelight uses are already public or open source, so please use and contribute to them!\nAcknowledgements\nSpecial thanks to Wenlei He, Andrii Nakryiko, Giuseppe Ottaviano, Mark Santaniello, Nathan Slingerland, Anita Zhang, and the Profilers Team at Meta. \nThe post Strobelight: A profiling service built on open source technology appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>We’re sharing details about Strobelight, Meta’s profiling orchestrator. Strobelight combines several technologies, many open source, into a single service that helps engineers at Meta improve efficiency and utilization across our fleet. Using Strobelight, we’ve seen significant efficiency wins, including one that has resulted in an estimated 15,000 servers’ worth of annual capacity savings. Strobelight, Meta’s [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/01/21/production-engineering/strobelight-a-profiling-service-built-on-open-source-technology/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/01/21/production-engineering/strobelight-a-profiling-service-built-on-open-source-technology/\">Strobelight: A profiling service built on open source technology</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "We’re sharing details about Strobelight, Meta’s profiling orchestrator. Strobelight combines several technologies, many open source, into a single service that helps engineers at Meta improve efficiency and utilization across our fleet. Using Strobelight, we’ve seen significant efficiency wins, including one that has resulted in an estimated 15,000 servers’ worth of annual capacity savings. Strobelight, Meta’s [...]\nRead More...\nThe post Strobelight: A profiling service built on open source technology appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=22157",
        "categories": [
          "Open Source",
          "Production Engineering"
        ],
        "isoDate": "2025-01-21T17:00:54.000Z"
      },
      {
        "creator": "",
        "title": "Measuring productivity impact with Diff Authoring Time",
        "link": "https://engineering.fb.com/2025/01/16/developer-tools/measuring-productivity-impact-with-diff-authoring-time/",
        "pubDate": "Thu, 16 Jan 2025 17:00:00 +0000",
        "content:encodedSnippet": "Do types actually make developers more productive? Or is it just more typing on the keyboard? To answer that question we’re revisiting Diff Authoring Time (DAT) – how Meta measures how long it takes to submit changes to a codebase.\nDAT is just one of the ways e measure developer productivity and this latest episode of the Meta Tech Podcast takes a look at two concrete use cases for DAT, including a type-safe mocking framework in Hack.\nTune in to learn how we leverage metrics to run experiments on productivity in our internal codebase at Meta.\nDownload or listen to the podcast episode below:\n\nSpotify\nApple Podcasts\nPocket Casts\nOvercast\nThe Meta Tech Podcast is a podcast, brought to you by Meta, where we highlight the work Meta’s engineers are doing at every level – from low-level frameworks to end-user features.\nSend us feedback on Instagram, Threads, or X.\nAnd if you’re interested in learning more about career opportunities at Meta visit the Meta Careers page.\nThe post Measuring productivity impact with Diff Authoring Time appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Do types actually make developers more productive? Or is it just more typing on the keyboard? To answer that question we’re revisiting Diff Authoring Time (DAT) – how Meta measures how long it takes to submit changes to a codebase. DAT is just one of the ways e measure developer productivity and this latest episode [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/01/16/developer-tools/measuring-productivity-impact-with-diff-authoring-time/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/01/16/developer-tools/measuring-productivity-impact-with-diff-authoring-time/\">Measuring productivity impact with Diff Authoring Time</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Do types actually make developers more productive? Or is it just more typing on the keyboard? To answer that question we’re revisiting Diff Authoring Time (DAT) – how Meta measures how long it takes to submit changes to a codebase. DAT is just one of the ways e measure developer productivity and this latest episode [...]\nRead More...\nThe post Measuring productivity impact with Diff Authoring Time appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=22150",
        "categories": [
          "Culture",
          "DevInfra",
          "Meta Tech Podcast"
        ],
        "isoDate": "2025-01-16T17:00:00.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Christian Herold and Shahram Khadivi",
        "title": "Scaling Large Language Models for e-Commerce: The Development of a Llama-Based Customized LLM",
        "link": "https://innovation.ebayinc.com/tech/features/scaling-large-language-models-for-e-commerce-the-development-of-a-llama-based-customized-llm-for-e-commerce/",
        "pubDate": "Fri, 17 Jan 2025 00:00:00 -0800",
        "dc:creator": "Christian Herold and Shahram Khadivi",
        "content": "<div style=\"margin-bottom: 10px;\"><img src=\"https://static.ebayinc.com/static/assets/Uploads/Blog/Posts/_resampled/FitWzIwMCwxMTZd/Llama-Graphic.jpg?fs=238f37447da3cf46\" width=\"200\" height=\"116\" alt=\"Scaling Large Language Models for e-Commerce: The Development of a Llama-Based Customized LLM\" /></div><div>Third-party LLMs like Llama 3.1 allow us to adapt powerful tools for the e-commerce domain with a mix of eBay and general data to enable our magical AI experiences. </div>",
        "contentSnippet": "Third-party LLMs like Llama 3.1 allow us to adapt powerful tools for the e-commerce domain with a mix of eBay and general data to enable our magical AI experiences.",
        "guid": "https://innovation.ebayinc.com/tech/features/scaling-large-language-models-for-e-commerce-the-development-of-a-llama-based-customized-llm-for-e-commerce/",
        "categories": [
          "article"
        ],
        "isoDate": "2025-01-17T08:00:00.000Z"
      },
      {
        "creator": "eBay News Team",
        "title": "eBay Design Team Reflects On a Transformative 2024",
        "link": "https://innovation.ebayinc.com/tech/features/ebay-design-2024/",
        "pubDate": "Thu, 16 Jan 2025 00:00:00 -0800",
        "dc:creator": "eBay News Team",
        "content": "<div style=\"margin-bottom: 10px;\"><img src=\"https://static.ebayinc.com/static/assets/Uploads/Blog/Posts/_resampled/FitWzIwMCwxMTJd/2024-Lookback-Article-Thumbnail.jpg?fs=fecdec16f242078b\" width=\"200\" height=\"112\" alt=\"eBay Design Team Reflects On a Transformative 2024\" /></div><div>Check out a roundup of eBay Design’s favorite moments from 2024.</div>",
        "contentSnippet": "Check out a roundup of eBay Design’s favorite moments from 2024.",
        "guid": "https://innovation.ebayinc.com/tech/features/ebay-design-2024/",
        "categories": [
          "article"
        ],
        "isoDate": "2025-01-16T08:00:00.000Z"
      }
    ]
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Elena Kerpeleva",
        "title": "Introducing  Perpetual Licenses on JetBrains Marketplace",
        "link": "https://blog.jetbrains.com/platform/2025/01/introducing-perpetual-licenses-on-jetbrains-marketplace/",
        "pubDate": "Tue, 21 Jan 2025 18:11:47 +0000",
        "content:encodedSnippet": "JetBrains Marketplace provides various licensing models for paid plugins to suit different user preferences. Now, we are introducing a new option that may change how your users purchase your plugins – perpetual licensing.\nLicensing options on JetBrains Marketplace\nThe current licensing schemes available on JetBrains Marketplace include:\nAnnual/monthly subscription without a fallback license: Users can access your plugin only with an active subscription. This model is ideal for ensuring continuous revenue as users need to maintain their subscriptions to keep using the plugin.\nAnnual/monthly subscription with a fallback license: Users receive lifetime access to a specific version of your plugin. Updates and new features are only available with an active subscription. This model strikes a balance between providing long-term value to users and encouraging them to renew their subscriptions.\nThe licensing type (with or without fallback) and billing period (annual/monthly) can be selected under the Sales tab, in the Sales Info section of the plugin page.\nIn addition to the options described above, we are now introducing a perpetual license option. This new license type allows users to make a one-time payment for lifetime access to your plugin, including all future updates. It can be an appealing choice for users who prefer a single upfront payment rather than recurring charges.\n\n\n\n\nHow to implement perpetual licenses\nNow that you can opt for perpetual licensing for your new plugin, the perpetual license will be available as an option when you publish a new plugin on JetBrains Marketplace. \nAlternatively, if you prefer to switch your existing plugin to a perpetual licensing model, you can do so by contacting the JetBrains Marketplace team at marketplace@jetbrains.com. In this scenario, all current customers will automatically receive the perpetual license for free, while new customers will need to purchase it.\nNote that a plugin can currently have only one paid license option: either recurring or perpetual.\nChoosing the best licensing model for your plugin\nThe introduction of the perpetual license gives you more flexibility in how you monetize your plugin. However, it’s essential to consider the implications carefully.\nRevenue stability: While a one-time payment model may attract more users initially, it can lead to less predictable revenue in the long run compared to a subscription model.\nUser satisfaction: Perpetual licenses can increase customer satisfaction, as users appreciate the simplicity and long-term value of a single payment.\nIf you have any questions or need guidance on transitioning to the perpetual license model, feel free to reach out to the Marketplace Support team at marketplace@jetbrains.com.",
        "dc:creator": "Elena Kerpeleva",
        "content": "JetBrains Marketplace provides various licensing models for paid plugins to suit different user preferences. Now, we are introducing a new option that may change how your users purchase your plugins – perpetual licensing. Licensing options on JetBrains Marketplace The current licensing schemes available on JetBrains Marketplace include: The licensing type (with or without fallback) and [&#8230;]",
        "contentSnippet": "JetBrains Marketplace provides various licensing models for paid plugins to suit different user preferences. Now, we are introducing a new option that may change how your users purchase your plugins – perpetual licensing. Licensing options on JetBrains Marketplace The current licensing schemes available on JetBrains Marketplace include: The licensing type (with or without fallback) and […]",
        "guid": "https://blog.jetbrains.com/?post_type=platform&p=538720",
        "categories": [
          "marketplace",
          "plugin-development"
        ],
        "isoDate": "2025-01-21T18:11:47.000Z"
      },
      {
        "creator": "Vaclav Pech",
        "title": "MPS 2024.3 Is Out!",
        "link": "https://blog.jetbrains.com/mps/2025/01/mps-2024-3-is-out/",
        "pubDate": "Tue, 21 Jan 2025 17:01:08 +0000",
        "content:encodedSnippet": "In this release, you’ll find improvements to the UI, reworked internals for various components, and a binary-enabled textgen. MPS 2024.3 also brings enhanced support for icons, an applicability condition for quick-fixes, and numerous platform updates.\nDOWNLOAD MPS 2024.3\nWhat’s new\nLet’s check out the new features we’ve prepared for you in this release.\nTop-level folder for transient and checkpoint models\nThe ProjectView tool now provides three top-level folders to keep the structure of the project better organized:\nProject Name\nModules Pool\nCheckpoints and Transient Models\nThe Checkpoints and Transient Models folder is always displayed below the Modules Pool, and is empty unless any transient or checkpoint models are available. These models are displayed under this folder, and not at the top level as they used to be.\nCheckpoints and Transient Models folder allows the ProjectView to remember the expanded and collapsed subtrees of the project structure across MPS restarts.\n\nEnable preview tag option\nThe following options to enable/disable the Preview Tab provided by the IntelliJ Platform are now respected by MPS and guarantee the same behavior of the editor as in other JetBrains tools:\nSettings | Editor | General | Editor Tabs | Opening Policy | Enable preview tab\nLogical View | Behavior | Enable Preview Tab\n\nApplicability condition for a quick-fix\nA new section named applicable has been added to Quick-Fix definitions to let you control the applicability of a quick-fix. The default value <always> guarantees unrestricted applicability.\n\nIcon handling\nIcons and images that use a path relative to the module are no longer copied during generation next to the places of their individual usage. Instead, they are copied to the distribution module once as image files and are available for use at this single location. This has two immediate benefits: avoiding the duplication of image files to save disk space and the ability to access the images both from the distribution and from the source module.\nConstant icons\nIn addition to the existing TextIcon and FileIcon concepts, a new ConstantFieldIcon concept is now available. It allows an icon to be specified by reference to a concrete static field declaration holding an instance of javax.swing.Icon.\n\nTextGen binary outcome\nInspired by the need for better handling of icon files, we’ve added a new mechanism to produce binary output during the TextGen process, instead of text. The new API consists of a write operation that directly manipulates data as instances of byte[].\nTool windows migrated away from ProjectComponent\nAll tool windows, such as Inspector, HierarchyView, and Usages, have been reworked to no longer follow the long-deprecated mechanism of the IntelliJ Platform’s project components (ProjectComponent). The changes to the API have been minimal, but for some tool windows, there is a change in how they are obtained from code:\nThe Project.getComponent() method no longer returns any of the tool windows.\nTools that are implemented as an MPS tool concept can be obtained using com.intellij.openapi.project.Project.tool<ToolConcept>.\nTools that are frequently used from Java provide a static getInstance() method:\n\nUsagesViewTool.getInstance()\nInspectorTool.getInstance()\nThe Inspector tool is traditionally also available from EditorContext.inspectorTool().\nIntelliJ Platform components and services\nIn addition to tool windows, most of the MPS core functionality has been reworked not to use IntelliJ IDEA’s ApplicationComponent and ProjectComponent.\nMPS used to rely heavily on the IntelliJ Platform facilities to compose the complete application. Now, most of the legacy components have been refactored to use contemporary MPS or IntelliJ IDEA APIs (like IntelliJ IDEA’s application/project services and extension points, MPS’ CoreComponents and extensions, etc.). There are still a few components left, which the MPS team plans to get rid of completely in the next release.\nMost users probably won’t notice any difference, with the exception of reduced startup times.\nPlease consult the Migration Guide if your code fails to locate any of the platform components because it uses an obsolete retrieval mechanism.\nSwitched to the new UI\nMPS now uses the new UI. The old version of the UI can be enabled by installing the Classic UI plugin.\nMore new features…\nCheck out the What’s New page to learn all about the new features.\nYou can find a full list of fixed issues here.\nYour JetBrains MPS team",
        "dc:creator": "Vaclav Pech",
        "content": "In this release, you’ll find improvements to the UI, reworked internals for various components, and a binary-enabled textgen. MPS 2024.3 also brings enhanced support for icons, an applicability condition for quick-fixes, and numerous platform updates. DOWNLOAD MPS 2024.3 What’s new Let’s check out the new features we’ve prepared for you in this release. Top-level folder [&#8230;]",
        "contentSnippet": "In this release, you’ll find improvements to the UI, reworked internals for various components, and a binary-enabled textgen. MPS 2024.3 also brings enhanced support for icons, an applicability condition for quick-fixes, and numerous platform updates. DOWNLOAD MPS 2024.3 What’s new Let’s check out the new features we’ve prepared for you in this release. Top-level folder […]",
        "guid": "https://blog.jetbrains.com/?post_type=mps&p=533562",
        "categories": [
          "releases",
          "release"
        ],
        "isoDate": "2025-01-21T17:01:08.000Z"
      },
      {
        "creator": "Irina Mariasova",
        "title": "Maximize Code Security in JetBrains IDEs and Qodana With Mend.io",
        "link": "https://blog.jetbrains.com/idea/2025/01/maximize-code-security-in-jetbrains-ides-and-qodana-with-mend-io/",
        "pubDate": "Tue, 21 Jan 2025 09:35:46 +0000",
        "content:encodedSnippet": "JetBrains has partnered with Mend.io, a trusted name in application security. This collaboration will help us continue providing the tools you need to develop secure applications with ease and confidence in our IDEs and Qodana. For the best user experience, make sure to use the latest stable version 2024.3.2. \nWhy Mend?\nTrusted by industry giants like Google and Comcast, Mend.io offers a reliable application security platform. It helps organizations build mature AppSec programs, shifting from reactive vulnerability management to proactive risk mitigation. With Mend’s expertise, our users gain access to a robust solution that simplifies security and boosts code quality.\nWhat’s new?\nOur Package Checker plugin has long been a reliable tool for identifying vulnerabilities in third-party dependencies and suggesting safe updates. By switching to Mend.io as our software composition analysis (SCA) provider, we’re ensuring that these capabilities remain effective and up to date.\nMalicious package detection\nThanks to this partnership, you can now identify malicious packages – those specifically designed to harm systems. Mend strongly advises removing such packages immediately to protect your code and systems.\nPowered by Mend.io, the Malicious Dependency inspection helps you:\nDetect harmful npm and PyPI packages.\n\n\n\n\n\nPrevent commits with malicious dependencies, protecting your repositories.\n\n\n\n\nMalicious package detection is also available in Qodana.\n\n\n\n\nVulnerability detection \nThe popular Vulnerable Path functionality, which helps pinpoint the exact source of a vulnerability, will return with the upcoming 2025.1 version of JetBrains IDEs, giving you added precision when managing your code dependencies. \nBasic functionality remains \nThe bundled Package Checker plugin will continue to provide a reliable way to keep your code secure with the help of the following basic features:\nDependency scanning. Helps identify vulnerabilities and threats in third-party dependencies.\nSafe updates. Suggests secure versions of dependencies, allowing you to fix vulnerabilities easily.\nSmooth IDE integration. Highlights issues directly in the editor and provides details in the Problems | Vulnerable Dependencies tab or via Analyze | Vulnerable Dependencies.\n\n\n\n\nLooking ahead\nThis update brings incremental, yet valuable, improvements to the security features in JetBrains IDEs and Qodana. We’re committed to enhancing these capabilities further and providing you with the tools needed to build secure applications.\nBe sure to update your tools and try the new features once they are available!",
        "dc:creator": "Irina Mariasova",
        "content": "JetBrains has partnered with Mend.io, a trusted name in application security. This collaboration will help us continue providing the tools you need to develop secure applications with ease and confidence in our IDEs and Qodana. For the best user experience, make sure to use the latest stable version 2024.3.2. Why Mend? Trusted by industry giants [&#8230;]",
        "contentSnippet": "JetBrains has partnered with Mend.io, a trusted name in application security. This collaboration will help us continue providing the tools you need to develop secure applications with ease and confidence in our IDEs and Qodana. For the best user experience, make sure to use the latest stable version 2024.3.2. Why Mend? Trusted by industry giants […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=538928",
        "categories": [
          "news",
          "intellij-idea",
          "news-company",
          "package-checker",
          "security"
        ],
        "isoDate": "2025-01-21T09:35:46.000Z"
      },
      {
        "creator": "Olga Bedrina",
        "title": "TeamCity 2024.12.1 Bug Fix Is Now Available",
        "link": "https://blog.jetbrains.com/teamcity/2025/01/teamcity-2024-12-1-bug-fix/",
        "pubDate": "Mon, 20 Jan 2025 12:49:48 +0000",
        "content:encodedSnippet": "We’re excited to announce the release of TeamCity On-Premises 2024.12.1, a bug fix update that resolves over 80 issues reported by users. This version includes crucial fixes across multiple areas, ensuring enhanced performance, stability, and security for your CI/CD pipelines.\nSome highlights of this release include:\nResolved truncated build tags, addressing an issue that impacted tag visibility.\nEnhanced VCS checkout, ensuring revision computation considers all VCS root variations.\nFixed possible agent hang-ups during artifact publishing.\nSupport for MySQL 8.4 by adding allowPublicKeyRetrieval to the database connection URL (TW-91529).\nFixed SSH agent build feature issues on Windows (TW-85769).\nWe recommend upgrading to apply the latest improvements and security fixes to your TeamCity server.\nWhy update?\nStaying up to date with minor releases ensures your TeamCity instance benefits from:\nPerformance improvements.\nBetter compatibility with integrations.\nFaster, more stable builds.\nEnhanced security for your workflows.\nCompatibility\nTeamCity 2024.12.1 shares the same data format as all 2024.12.x releases. You can upgrade or downgrade within this series without the need for backup and restoration.\nHow to upgrade\nUse the automatic update feature in your current TeamCity version.\nDownload the latest version directly from the JetBrains website.\nPull the updated TeamCity Docker image.\nNeed help?\nThank you for reporting issues and providing feedback! If you have questions or run into any problems, please let us know via the TeamCity Forum or Issue Tracker.\nHappy building!",
        "dc:creator": "Olga Bedrina",
        "content": "We’re excited to announce the release of TeamCity On-Premises 2024.12.1, a bug fix update that resolves over 80 issues reported by users. This version includes crucial fixes across multiple areas, ensuring enhanced performance, stability, and security for your CI/CD pipelines. Some highlights of this release include: We recommend upgrading to apply the latest improvements and [&#8230;]",
        "contentSnippet": "We’re excited to announce the release of TeamCity On-Premises 2024.12.1, a bug fix update that resolves over 80 issues reported by users. This version includes crucial fixes across multiple areas, ensuring enhanced performance, stability, and security for your CI/CD pipelines. Some highlights of this release include: We recommend upgrading to apply the latest improvements and […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=539240",
        "categories": [
          "bug-fix"
        ],
        "isoDate": "2025-01-20T12:49:48.000Z"
      },
      {
        "creator": "Kerry Beetge",
        "title": "Fixing Unreal Engine Project Issues With Qodana",
        "link": "https://blog.jetbrains.com/qodana/2025/01/unreal-engine-project-qodana/",
        "pubDate": "Mon, 20 Jan 2025 11:00:47 +0000",
        "content:encodedSnippet": "If you saw our blog post about using Qodana in Unity and .NET projects, you know that we’ve been striving to explore Qodana’s potential for game development. What’s our next stop on this mission? Seeing our code quality platform in action with Unreal Engine, one of the most popular engines for different types of projects – from virtual reality prototypes to triple-A games. \nIn this post, we’ll demonstrate how we used our static analysis tool Qodana on Lyra Starter Game, a widely known sample project from Epic Games. We chose this project for its large codebase, which provides a wider range of potential issues to identify, analyze, and fix. \nThe analysis and the resolution of issues were carried out by a junior developer. Our goal was to check how someone still building their game development knowledge can use Qodana to improve code and product quality. \nTable of Contents\n\nRunning Qodana from the IDE\nSetting up the CI/CD pipeline\nFixing problems\nQodana’s Unreal Engine analysis summarized\nSwitch to Qodana for code analysis and get 25% off\n\nRunning Qodana from the IDE\nWe started by running Qodana from an IDE (Rider) to see the initial results and set up filtering. As Qodana is integrated with the most popular JetBrains IDEs, it can be easily launched directly from the Tools menu. For a better team experience, we also recommend using the JetBrains CI/CD solution, TeamCity. After setting up we will switch that on as well to set up a seamless process and quality gate.\n Running Qodana in the IDE\n\n\n\nYou can run Qodana in your IDE without a token, but we wanted our results to be accessible from Qodana Cloud, a cloud-based tool for Qodana reports. To upload a report to the cloud, you need a license token, which you can get from the Qodana Cloud project. We will also use the token to integrate our analysis into the CI/CD pipeline.\nThe qodana.yaml file is created automatically and shown in the popup below. \nThe qodana.yaml popup\n\n\n\nYou can modify this file directly in the popup window if you need to, and you can run inspections with the qodana.starter profile to check if there are any critical errors. Once you run it, the file will be saved in the project root. We wanted to use a custom profile, so we modified this file to reference the custom profile.yaml.\nIn the qodana.yaml file, we left a link to the profile. QDNET is a linter based on the Rider distribution and designed to work with Unreal Engine projects.\nversion: \"1.0\"\n\n#Specify IDE code to run analysis without container (Applied in CI/CD pipeline)\nide: QDNET\n\n#Specify inspection profile for code analysis\nprofile:\n  path: profile.yaml\nqodana.yaml\nIn the profile.yaml file, we changed the profile to the more extensive qodana.recommended and identified scope to be excluded from the analysis. We wanted to analyze only the project codebase, without Unreal Engine or plugin sources.\nbaseProfile: \"qodana.recommended\"\nname: \"UnrealEngine\"\n\ninspections:\n  - group: ALL\n    ignore:\n      - \"scope#!file:Source/LyraGame//*\"\nprofile.yaml\nThese changes provided a relatively comprehensive analysis report.\n\n We then linked our project to Qodana Cloud. \n Linking the project to Qodana Cloud\n\n\n\nThis will allow us to access future reports withinin the IDE and view problems locally.\nThe report in the IDE\n\n\n\nSetting up the CI/CD pipeline\nWe already had a CI/CD pipeline in TeamCity, which we used to build the project every time we pushed changes to the main branch. There are several ways to complete the build. One such method is with the Unreal Engine plugin for TeamCity which can be downloaded from JetBrains Marketplace. You don’t have to run the build before running Qodana, but it is convenient to put it in the same pipeline. This allows TeamCity to mark the build as Failed if Qodana finds any issues.\nTo run the Qodana analysis, we added a PowerShell step that loaded and ran our Qodana CLI tool. We opted for the latest AMD64-compatible version and assets for our agents. If you are working with a different operating system and architecture, you will have to choose the assets designed for them. \nBefore implementing this in any project, you should discuss the security implications with the people responsible for this in your organization. Downloading a third-party binary without checking its integrity and checksum can be risky. You may need to save a fixed version of the binary yourself or verify the checksum of the downloaded distribution. \nInvoke-WebRequest -Uri \"https://github.com/JetBrains/qodana-cli/releases/download/%VERSION%/qodana_windows_x86_64.exe\" -OutFile \"qodana_windows_x86_64.exe\" \n\n./qodana_windows_x86_64.exe scan --ide QDNET\nPowerShell build step\nThe linter requires a Qodana token, a value from the project page on Qodana Cloud. To pass the token through the pipeline, we added the QODANA_TOKEN environment variable with the Password value type to ensure the token remains secure.\nThen, in the same way, we added the desired version of Qodana CLI as a configuration parameter.\n\n\n\n\nFixing problems\nFor this Unreal Engine project, we were particularly interested in issues specific to projects created with the game engine. We used filters on Qodana Сloud to show only these problems.\nUnreal Engine problems\n\n\n\nQodana’s sunburst diagram provides a convenient visualization of the detected issues, as well as an easy way to navigate to them. In our case, we could see there were seven types of problems, some of which could be resolved using context actions:\nBlueprintCallable function can be made const\nBlueprintCallable function can be made static\nUse of a class that has not been declared previously\nTo quickly navigate to these issues in the IDE, we can click on the Open file in Rider button.\nPlease note: to get this functionality to work you have to install JetBrains Toolbox on your computer. \nExample of a problem in Qodana Cloud\n\n\n\nAfter opening the file in the IDE, we resolved this problem using the relevant quick-fix with a context action.\nExample of a problem in the IDE\n\n\n\nYou can also navigate by opening a report locally in the IDE and going through the list of problems grouped there by type, fixing them one by one. As you fix problems in the IDE, the number of issues detected will decrease.\n\n\n\n\nWe decided not to fix problems like BlueprintCallable function is never used in Blueprint or C++ code, as the Lyra project is considered learning material, and it’s actively maintained. The project contains methods that are not currently being used but may be in the future. \nAdditionally, we decided not to fix inconsistent Unreal Engine naming problems because the project uses a different naming convention, where upper case is used for all abbreviations.\nExample of a naming problem in the IDE\n\n\n\nTo deactivate these inspections, we added their inspection IDs to profile.yaml and set the enabled property to false, ensuring these types of problems will no longer be shown in reports. The problem ID can be found in the qodana.sarif.json file.\nNext, we moved to C++ problems. We decided to only fix the problems that were categorized as higher than moderate severity, as most low-level issues could be fixed with quick-fixes. We excluded the non-critical issues by changing the profile.yaml file.\nbaseProfile: \"qodana.recommended\"\nname: \"UnrealEngine\"\n\ninspections:\n - group: ALL\n   ignore:\n     - \"scope#!file:Source/LyraGame//*\"\n - group: \"severity:TYPO\"\n   enabled: false\n - inspection: \"CppUE4CodingStandardNamingViolationWarning\"\n   enabled: false\n - inspection: \"CppUEBlueprintCallableFunctionUnused\"\n   enabled: false\nprofile.yaml\nThis produced a report with less than a thousand problems. To experiment with different filtering strategies, we used separate branches for each YAML file. This allowed us to divide the problems into groups based on type, tackling each type in a separate branch with different settings and then merging the branches.\nLow-severity C++ problems excluded\n\n\n\nEven without the low-level results, we saw many types of problems that were not in the Unreal Engine category. \nIn total, our team fixed 822 of 937 problems from the categories we examined next.\nAs you can see below, the most common problems fell into the Common Practices and Code Improvements category and included issues like variables that could be made const or static. We resolved most of them with quick-fixes. We left problems like Function is not implemented, as they could be fixed in future development. We decided not to fix some of the problems, as the changes required to mitigate them would make the project uncompilable and in need of further refactoring.\nProblems classified as Common Practices and Code Improvements\n\n\n\nAs a result, we were left with only 26 problems in the Common Practices and Code Improvements category, which we could deal with later. \nRemaining problems classified as Common Practices and Code Improvements\n\n\n\nUp next were potential code quality issues. From this category, we fixed problems where we needed to remove unused declarators or directives. We then moved to redundancies in code, most of which were resolved easily with a quick-fix. We did not address any problems where developers left comments with their plans or TODOs because we assumed that these problems would be fixed with future changes.\nExample of a TODO\n\n\n\nLast but not least, the Syntax Style category contained only two types of problems, both of which concerned the use of virtual and override specifiers when overriding functions. We fixed all of them by adding the missing specifiers.\nSyntax Style problems\n\n\n\nWe were left with 123 unresolved problems, either due to ongoing development or the lack of a feasible solution. We moved these issues to the baseline. To apply the baseline, we downloaded the baseline file and stored it in the repository.\nSelecting problems\n\n\n\nDownloading the baseline file\n\n\n\nThen, by adding the –baseline parameter and path to the file, we adjusted the pipeline to include the baseline in future analyses.\nInvoke-WebRequest -Uri \"https://github.com/JetBrains/qodana-cli/releases/download/%VERSION%/qodana_windows_x86_64.exe\" -OutFile \"qodana_windows_x86_64.exe\" \n./qodana_windows_x86_64.exe scan --ide QDNET --baseline qodana.sarif.json\nPowerShell build step\nAnd finally, we had a flawless report.\n\n\n\n\nIf our team decided to continue working on this project, we could fix new problems as they appeared or we could focus on eliminating problems from the baseline, depending on our priorities.\nWe set up a quality gate to enforce the standards we had achieved with these efforts, and we added a several failureConditions section to qodana.yaml to configure additional quality gates for the total number of problems, as well as the numbers of critical and high-severity issues. Going forward, if any of these limits are exceeded, the build will fail.\nfailureConditions:\n  severityThresholds:\n    any: 10 # Total problems\n    critical: 0 # Critical and other severities\n    high: 5\n\n\n\n\nAdded qodana.yaml configuration\nWe also adjusted the execution of qodana-cli to consider exit code, failing the build if the result fails the quality gates. By failing builds that don’t meet our quality criteria, we can identify and address issues immediately.\nInvoke-WebRequest -Uri \"https://github.com/JetBrains/qodana-cli/releases/download/%VERSION%/qodana_windows_x86_64.exe\" -OutFile \"qodana_windows_x86_64.exe\" \n./qodana_windows_x86_64.exe scan --ide QDNET \n\n# Capture the exit code of the command\n$exitCode = $LASTEXITCODE\n\n# Print the exit code\nWrite-Output \"Exit code: $exitCode\"\n\n# Exit the script with the same exit code\nexit $exitCode\nPowerShell build step\nA failed build in TeamCity\n\n\n\nQodana’s Unreal Engine analysis summarized\nWe successfully analyzed the Lyra project, got a detailed report, and fixed more than 800 problems. While conducting professional reviews will likely require a deeper understanding of Unreal Engine, Qodana’s analysis still helped a single junior developer clean up the code and make it more concise. \nFor large-scale projects like Lyra, Qodana can effectively highlight and prioritize critical code issues that may be overlooked in manual reviews.\nSince Lyra is a private repo, we can’t share the outcome, but we hope we’ve shown you how this process could work for your team and what kind of results it can deliver.\nIf you’d like more information, visit our website, view Qodana’s features, or try it in your next game development project. \nSwitch to Qodana for code analysis and get 25% off\nQodana gets better with every release and provides a cost-effective way for teams to build confidence in code quality. \nWith this in mind, we’re offering you 25% off your first year of Qodana if you switch from a comparable commercial solution. Click on the button below to speak to our team. \nSwitch To Qodana\nThank you to Software Developer Ekaterina Trukhan for her contribution to this analysis.",
        "dc:creator": "Kerry Beetge",
        "content": "If you saw our blog post about using Qodana in Unity and .NET projects, you know that we’ve been striving to explore Qodana’s potential for game development. What’s our next stop on this mission? Seeing our code quality platform in action with Unreal Engine, one of the most popular engines for different types of projects [&#8230;]",
        "contentSnippet": "If you saw our blog post about using Qodana in Unity and .NET projects, you know that we’ve been striving to explore Qodana’s potential for game development. What’s our next stop on this mission? Seeing our code quality platform in action with Unreal Engine, one of the most popular engines for different types of projects […]",
        "guid": "https://blog.jetbrains.com/?post_type=qodana&p=537855",
        "categories": [
          "tutorials",
          "game-development",
          "qodana",
          "teamcity",
          "unreal-engine"
        ],
        "isoDate": "2025-01-20T11:00:47.000Z"
      },
      {
        "creator": "Sasha Ivanova",
        "title": "The Early Access Program for ReSharper and the .NET Tools 2025.1 Is Here!",
        "link": "https://blog.jetbrains.com/dotnet/2025/01/17/resharper-2025-1-eap-1/",
        "pubDate": "Fri, 17 Jan 2025 12:46:31 +0000",
        "content:encodedSnippet": "We are excited to announce the launch of the Early Access Program (EAP) for the next major release of ReSharper and the .NET Tools! This initial EAP build is now available for download and offers a preview of the upcoming features and enhancements. Your feedback is crucial in helping us refine these updates, so we encourage you to try out the new build and share your thoughts.\nDownload ReSharper 2025.1 EAP 1\n                                                    \nIf you’re new to the Early Access Program, we encourage you to read this blog post where we outline what the program is all about and the benefits you can expect from participating in it.\nNow let’s take a look at the feature highlights of the first preview build!\ndotMemory\ndotMemory is now fully integrated with Visual Studio\nWith the 2025.1 update we’re elevating dotMemory from a standalone companion application to a fully integrated part of your Visual Studio workflow. The integration brings dotMemory’s complete feature set right into your development environment, accessible through the familiar ReSharper | Profile menu.\n\n\n\n\nHere’s how it works\nYou can now start profiling your application, capture memory snapshots, and analyze memory usage patterns without leaving Visual Studio. The dedicated dotMemory tool window gives you instant access to the collected profiling data. The profiling data is shown in the corresponding document tabs.\n\n\n\n\nThe dotMemory workspace inside Visual Studio\nA flashing memory profiling icon appears in the bottom-right corner of the Visual Studio window whenever a profiling session is running. Right-clicking this status bar icon allows you to:\nQuickly stop the current profiling session.\nOpen the dotMemory tool window if it’s not already visible.\n\n\n\n\nThis status bar menu also offers a faster way to access dotMemory than navigating through the main menu (Extensions | ReSharper | Profile | Show dotMemory Profiler), ensuring you can manage profiling sessions with ease. \n\n\n\n\nYou can also find your way to the dotMemory tool window by looking it up using the Search Everywhere action. \nGetting started\nFollow these steps to get started with dotMemory inside Visual Studio:\nInstall the ReSharper 2025.1 EAP 1 build\nGo to Extensions | ReSharper | Profile in the main menu\nChoose your target process or start a new profiling session\nConfigure your profiling parameters and start the profiling session.\nInvestigate the memory usage patterns in the dedicated Analysis tabs in the document window inside Visual Studio.  \nThe integration requires Visual Studio 2019 or later, and all your existing dotMemory workspaces will work seamlessly with the integrated version.\ndotMemory is part of the dotUltimate suite of tools, so if you already have a dotUltimate license, you can start using it right away!\nShould you encounter any issues with using the integrated version of dotMemory, please report them to this issue.\nReSharper C++\nThe 2025.1 EAP 1 build for ReSharper C++ comes with the following improvements:\nCross-platform code enhancements\nImproved support for conditionals with omitted operands. [RSCPP-35483]\nAdded support for the GNU #import directive. [RSCPP-35415]\nAdded support for _Float16, __bf16, and __float128 types. [RSCPP-35004, RSCPP-35814]\nCode editing and navigation\nIf no file with a matching name exists, the Switch header/source feature now suggests files containing symbols from the current file. [RSCPP-36341]\nThe __declspec(property) feature now parses get and put arguments and also supports Rename refactoring for them. [RSCPP-14090]\nCode analysis and formatting\nImproved handling of the Indent class member from access specifier formatter setting in typing assistance for a smoother editing experience. [RSCPP-31862]\nAn inspection has been added to detect redundant forward declarations within a single file. [RSCPP-35102]\nFor the full list of changes included in this build please see our issue tracker.\n[Download the EAP 1 build]\nWe encourage you to download the latest build and explore these new features. Your feedback is invaluable as we continue to refine and improve ReSharper for the upcoming release. Please share your thoughts and suggestions in the comments below or via our issue tracker.",
        "dc:creator": "Sasha Ivanova",
        "content": "We are excited to announce the launch of the Early Access Program (EAP) for the next major release of ReSharper and the .NET Tools! This initial EAP build is now available for download and offers a preview of the upcoming features and enhancements. Your feedback is crucial in helping us refine these updates, so we [&#8230;]",
        "contentSnippet": "We are excited to announce the launch of the Early Access Program (EAP) for the next major release of ReSharper and the .NET Tools! This initial EAP build is now available for download and offers a preview of the upcoming features and enhancements. Your feedback is crucial in helping us refine these updates, so we […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=538158",
        "categories": [
          "net-tools",
          "dotmemory",
          "resharpercplusplus",
          "resharper",
          "resharper-c"
        ],
        "isoDate": "2025-01-17T12:46:31.000Z"
      },
      {
        "creator": "Sasha Ivanova",
        "title": "The Early Access Program for Rider 2025.1 Is Now Open!",
        "link": "https://blog.jetbrains.com/dotnet/2025/01/17/rider-2025-1-eap-1/",
        "pubDate": "Fri, 17 Jan 2025 12:46:08 +0000",
        "content:encodedSnippet": "The Early Access Program for Rider 2025.1 has just begun. This is your chance to preview the new features and enhancements we’ve been working on and share your feedback to help us shape the future of JetBrains Rider. \nThere are several ways for you to get your hands on the first preview build:\nDownload and install them from our website.\nUse the Toolbox App.\nInstall this snap package from the SnapCraft store if you’re using a compatible Linux distribution.\n\n\n\n\nTo see the big picture of what’s coming, don’t miss our Rider 2025.1 Roadmap blog post. You may also want to check out this blog post, where we outline how the EAP program works and the benefits from using it.\nWithout further ado, here’s a quick overview of the first EAP build:\nRepository-wide visibility in the Solution Explorer\nYou can now navigate your entire codebase with Rider’s new Files view. This redesigned view complements the existing Solution view and displays your complete repository structure from the root, making it easier to work with full-stack projects, configuration files, and other modern development environment components.\n\n\n\n\nTo enable the Files tab by default, go to Settings/Preferences | Advanced Settings | Project View and select Enable Repository view in Explorer tool window.\nPlease note that there may be some performance issues when using the Files view with large solutions, which will be resolved in the upcoming builds.\nMore about this feature here. \nAutomatic child processes attachment for the .NET debugger\nRider now offers automatic attachment to child and grandchild processes during .NET application debugging. When enabled in the Run/Debug configurations, the IDE tracks and attaches to all .NET processes spawned within the application’s process tree.\nEnable this feature using the new Attach to child .NET processes checkbox.\nEnhanced .NET exception breakpoint configuration\nDebugging with exceptions gets smoother with Rider 2025.1! We’ve redesigned how you manage exception breakpoints, making it easier to focus on the exceptions that matter while keeping the noise at bay.\nThe new UI brings new filtering capabilities to your debugging workflow. When debugging your application, you now have precise control over which exceptions trigger breakpoints. Rider lets you filter exceptions based on both their origin (whether they come from your application code or external libraries) and how they’re handled in the code (if they’re caught by exception handlers or left unhandled). \n\n\n\n\n\nWe’ve expanded the exception popup’s capabilities to include unhandled exceptions management. While you could already mute handled exceptions from the popup window, now you can do the same for unhandled exceptions too with a single click of the Mute and Resume button.\n\n\n\n\nIf you’re migrating from a previous version of JetBrains Rider, your existing exception settings will automatically transfer to the new system, ensuring a smooth transition to the improved interface.\nSeparate color settings for C++ keywords\nWe’re ve introduced distinct color settings for built-in type keywords, control flow keywords, and control transfer keywords in C++, similar to the existing settings for C#. \n\n\n\n\n____________________________________________________________________________\nFor the full list of changes included in this build please see our issue tracker.\nWe encourage you to download the EAP build, give these new features a try, and share your feedback. The Early Access Program is a collaborative effort, and your input plays a vital role in making Rider the best it can be.\nDownload Rider 2025.1 EAP 1\n                                                    \nThank you for being part of our EAP community, and we look forward to hearing what you think!",
        "dc:creator": "Sasha Ivanova",
        "content": "The Early Access Program for Rider 2025.1 has just begun. This is your chance to preview the new features and enhancements we’ve been working on and share your feedback to help us shape the future of JetBrains Rider.  There are several ways for you to get your hands on the first preview build: To see [&#8230;]",
        "contentSnippet": "The Early Access Program for Rider 2025.1 has just begun. This is your chance to preview the new features and enhancements we’ve been working on and share your feedback to help us shape the future of JetBrains Rider.  There are several ways for you to get your hands on the first preview build: To see […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=538188",
        "categories": [
          "net-tools",
          "rider",
          "eap"
        ],
        "isoDate": "2025-01-17T12:46:08.000Z"
      },
      {
        "creator": "Sasha Ivanova",
        "title": "New Files View in Solution Explorer",
        "link": "https://blog.jetbrains.com/dotnet/2025/01/17/new-files-view-in-solution-explorer/",
        "pubDate": "Fri, 17 Jan 2025 12:45:43 +0000",
        "content:encodedSnippet": "In modern development, repositories are much more than just .NET solutions. From TypeScript end-to-end tests and Docker compose files to global.json and Playwright configs – your codebase contains numerous essential files that live outside of your C# projects.While these files are fully supported in Rider, they can be hard to find when viewing your solution structure.\nThis is why we’re introducing an enhanced Files view in the EAP 1 release for Rider 2025.1. \nDownload Rider 2025.1 EAP 1\n                                                    \nWhat’s new?\nThe reimagined Files view brings three key improvements:\nFirst, we’ve elevated the Files tab to be a true companion to the Solution view. You’ll find them side-by-side in one tool window, making it easier to switch contexts. Need to check your e2e tests in the tests folder? Looking for that CI configuration in .github? The Files view puts everything at your fingertips.\nSecond, we’ve shifted the view’s starting point to your repository root instead of the directory that contains the current solution file. This can be especially valuable for full-stack projects, where you might have:\nA backend folder with multiple .NET solutions\nA frontend directory containing your React, Angular, or Vue code\nDocker configurations and Kubernetes manifests\nDatabase migrations and scripts\nAPI documentation and Swagger files\n\n\n\n\nFinally, we’ve added intelligent folder highlighting to speed up navigation:\nDevelopment folders like src and tests stand out for quick access.\nSystem folders like .git fade into the background.\nSpecial directories like .github get distinct styling.\n\n\n\n\nHow to try it \nTo make sure the Files tab is displayed by default, go to Rider’s Settings/Preferences | Advanced Settings | Project View and check the Enable Repository view in Explorer toolwindow box.\n\n\n\n\nThen restart Rider, and you’ll see your full-stack repository in a whole new light!\nHelp us shape this feature\nThis is an early implementation, and your experience matters. We’d love to hear how the new Files view fits into your workflow. Share your thoughts in the comments below – what works, what doesn’t, and what you’d like to see next.\nDownload Rider 2025.1 EAP 1",
        "dc:creator": "Sasha Ivanova",
        "content": "In modern development, repositories are much more than just .NET solutions. From TypeScript end-to-end tests and Docker compose files to global.json and Playwright configs – your codebase contains numerous essential files that live outside of your C# projects.While these files are fully supported in Rider, they can be hard to find when viewing your solution [&#8230;]",
        "contentSnippet": "In modern development, repositories are much more than just .NET solutions. From TypeScript end-to-end tests and Docker compose files to global.json and Playwright configs – your codebase contains numerous essential files that live outside of your C# projects.While these files are fully supported in Rider, they can be hard to find when viewing your solution […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=537683",
        "categories": [
          "net-tools",
          "rider",
          "full-stack-development",
          "solution-explorer"
        ],
        "isoDate": "2025-01-17T12:45:43.000Z"
      },
      {
        "creator": "Anna Zykova",
        "title": "The RubyMine 2025.1 Early Access Program Is Open!",
        "link": "https://blog.jetbrains.com/ruby/2025/01/the-rubymine-2025-1-early-access-program-is-open/",
        "pubDate": "Fri, 17 Jan 2025 10:46:15 +0000",
        "content:encodedSnippet": "Hello everyone!\nWe’re starting this year off with the opening of the RubyMine 2025.1 Early Access Program. In this blog post, you’ll find details about the new features and improvements we’ve been working on.\n\n\n\n\nWhat’s coming in RubyMine 2025.1?\nAI Assistant\nThe 2024.3 release introduced enhanced cloud-based completion for Ruby code. The upcoming release will expand that support to related technologies like RBS and ERB, offering faster, more context-sensitive completion and enhanced quality, as well as support for multiline completion.\nWe’re also implementing inline AI prompt functionality for those same technologies. This means you’ll be able to submit natural language requests to AI Assistant and get instant code changes in your RBS and ERB files.\nDebugger\nWe’re working hard to improve our debugging tools and fix existing problems. In version 2025.1, you’ll find fixes for multi-module projects, an improved experience when attaching to running processes, and a more straightforward installation and downloading of RubyMine debugger gems. With these changes we aim to provide a smoother and more reliable debugging experience overall, along with various bug fixes and performance optimizations.\nRemote development experience\nBuilding on our previous release, we’re continuing to enhance remote development in RubyMine. We’re now working to introduce more responsive typing and editing for Ruby code when you’re working remotely with JetBrains Gateway, and we’re extending these improvements to RBS and ERB. Our goal is to reduce delays, resulting in a faster and more fluid coding experience.\nSupport for Ruby 3.4\nIn RubyMine 2025.1, we’re introducing more changes and improvements to accommodate Ruby 3.4 features. Stay tuned for updates about better code insight and improved inspections.\nMinor releases for RubyMine 2024.3 will include select Ruby 3.4 updates as well.\nQodana for Ruby\nWe’re integrating Ruby inspections into Qodana, a smart code quality platform by JetBrains. Qodana offers customizable inspection profiles and detailed reports highlighting issues with solutions, and it facilitates code review optimization, standard enforcement, and team collaboration via cloud storage.\nWith the Qodana plugin in RubyMine, you will be able to run Qodana locally and then forward inspection reports to Qodana Cloud for storage and analysis.\nJoin the Early Access Program\nYou can download the latest EAP build from our website or via the Toolbox App. The full list of closed tickets for this build is available in the release notes. \nWe encourage you to share your thoughts in the comments below and to create and vote for new feature requests in the issue tracker.\nHappy developing!\nThe RubyMine team",
        "dc:creator": "Anna Zykova",
        "content": "Hello everyone! We’re starting this year off with the opening of the RubyMine 2025.1 Early Access Program. In this blog post, you’ll find details about the new features and improvements we’ve been working on. What’s coming in RubyMine 2025.1? AI Assistant The 2024.3 release introduced enhanced cloud-based completion for Ruby code. The upcoming release will [&#8230;]",
        "contentSnippet": "Hello everyone! We’re starting this year off with the opening of the RubyMine 2025.1 Early Access Program. In this blog post, you’ll find details about the new features and improvements we’ve been working on. What’s coming in RubyMine 2025.1? AI Assistant The 2024.3 release introduced enhanced cloud-based completion for Ruby code. The upcoming release will […]",
        "guid": "https://blog.jetbrains.com/?post_type=ruby&p=538561",
        "categories": [
          "eap",
          "rubymine",
          "rubymine-2025-1",
          "rubymine-eap"
        ],
        "isoDate": "2025-01-17T10:46:15.000Z"
      },
      {
        "creator": "Julia Shashkova",
        "title": "IntelliJ IDEA 2024.3.2 Is Out",
        "link": "https://blog.jetbrains.com/idea/2025/01/intellij-idea-2024-3-2/",
        "pubDate": "Thu, 16 Jan 2025 23:03:31 +0000",
        "content:encodedSnippet": "We’ve just released the next minor update for IntelliJ IDEA 2024.3 – v2024.3.2.\nYou can update to this version from inside the IDE, via the Toolbox App, or by using snaps for Ubuntu. You can also download it from our website.\nThis release includes the following improvements:\nUsing certain third-party plugins no longer causes the font settings to reset to default. [IJPL-157487]\nIt’s again possible to compile Java 7 projects with Javac version 7. [IDEA-361854]\nWhen establishing an SSH connection with a specified deployment path, the IDE no longer mistakenly sets the working directory to the host’s root directory. [IJPL-171619]\nThe IDE no longer incorrectly reports valid JPQL syntax as errors. [IDEA-360902, IDEA-364513, IDEA-244155]\nJPA Buddy’s New Association Attribute dialog option for @OneToMany once again works as expected. [IDEA-359970]\nWhen the IDE window size is maximized on macOS Sequoia, it stays maximized upon IDE reopening. [IJPL-164502]\nThe IDE correctly displays the GitHub pull request timeline with mannequins and deleted participants. [IJPL-79734]\nThe Collection Presentation window properly displays nested collections in the debugger. [IDEA-363360]\nEach JetBrains IDE binary on macOS is now assigned a specific UUID, ensuring that different applications are no longer treated as single entities in the system settings. This helps prevent issues such as JetBrains Gateway being unable to connect to remote hosts. [IJPL-172978, IJPL-173908]\n\n\n\n\nTo find out more about the resolved issues, please refer to the release notes. \nIf you encounter any issues or would like to make a suggestion or a feature request, please submit them to our issue tracker.\nHappy developing!",
        "dc:creator": "Julia Shashkova",
        "content": "We’ve just released the next minor update for IntelliJ IDEA 2024.3 – v2024.3.2. You can update to this version from inside the IDE, via the Toolbox App, or by using snaps for Ubuntu. You can also download it from our website. This release includes the following improvements: To find out more about the resolved issues, [&#8230;]",
        "contentSnippet": "We’ve just released the next minor update for IntelliJ IDEA 2024.3 – v2024.3.2. You can update to this version from inside the IDE, via the Toolbox App, or by using snaps for Ubuntu. You can also download it from our website. This release includes the following improvements: To find out more about the resolved issues, […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=535818",
        "categories": [
          "releases",
          "2024-3",
          "bug-fix-update",
          "intellij-idea-2024-3",
          "intellij-idea-2024-3-2"
        ],
        "isoDate": "2025-01-16T23:03:31.000Z"
      },
      {
        "creator": "Tania Goral",
        "title": "Support for .env Files: Now Built into PhpStorm",
        "link": "https://blog.jetbrains.com/phpstorm/2025/01/support-for-env-files/",
        "pubDate": "Thu, 16 Jan 2025 20:14:13 +0000",
        "content:encodedSnippet": ".env files are widely used to configure applications by storing configuration settings, environment variables, and sensitive information. This eliminates the need to hardcode these values into the application code.\nPreviously, developers using PhpStorm had to manually install the .env Files Support plugin, originally created by Adel Faizrakhmanov, to unlock dedicated features for working with these files.\n\nWanting to ensure that PhpStorm users have everything they need for web development already built into the IDE, we reached out to Adel about transferring ownership of his .env Files Support plugin to JetBrains for bundling – and he graciously supported this idea. Starting with PhpStorm 2024.3.2, this plugin is included out of the box, with JetBrains taking over its development while keeping it open source. \nDownload PhpStorm\n“I’m pleased that it has been bundled with the IDE. I hope JetBrains implements some features I didn’t have time to, like nested variables.”\n\n            \nAdel Faizrakhmanov\n                                                                Software Developer\n                                    \nWhat’s inside?\nСode completion for the environment variable keys defined in the .env file, Dockerfile, or docker-compose.yml file.\n\nSyntax highlighting and validation inspections in .env files.\n\nNavigation between environment variable declarations and usages.\n\nYou may also like\nAdel is widely known for the Laravel Idea plugin, which offers extensive support for Laravel development, including Laravel code generation, Eloquent completion, Laravel navigation, as well as autocompletion for Laravel routes, request fields, and validation rules.\n“.env Files Support was the first plugin I developed. Its sudden popularity inspired me to pay more attention to IntelliJ Platform plugin development, and now I’m working full time on Laravel Idea and other plugins.”\n\n            \nAdel Faizrakhmanov\n                                                                Software Developer\n                                    \n\nIf you’re a Laravel developer and haven’t tried this plugin yet, give it a shot!\nConclusion\nPhpStorm continues to refine and expand its features to support PHP developers better. By bundling .env file support into the core IDE, JetBrains has removed yet another barrier to productivity.\nIf you haven’t updated PhpStorm yet, now’s the time to do it! \nDownload PhpStorm",
        "dc:creator": "Tania Goral",
        "content": ".env files are widely used to configure applications by storing configuration settings, environment variables, and sensitive information. This eliminates the need to hardcode these values into the application code. Previously, developers using PhpStorm had to manually install the .env Files Support plugin, originally created by Adel Faizrakhmanov, to unlock dedicated features for working with these [&#8230;]",
        "contentSnippet": ".env files are widely used to configure applications by storing configuration settings, environment variables, and sensitive information. This eliminates the need to hardcode these values into the application code. Previously, developers using PhpStorm had to manually install the .env Files Support plugin, originally created by Adel Faizrakhmanov, to unlock dedicated features for working with these […]",
        "guid": "https://blog.jetbrains.com/?post_type=phpstorm&p=537237",
        "categories": [
          "news",
          "releases",
          "env-files",
          "2024-3"
        ],
        "isoDate": "2025-01-16T20:14:13.000Z"
      },
      {
        "creator": "Sergey Kozlovskiy",
        "title": "JetBrains Named a Customers’ Choice Again for Integrated Development Environment Software",
        "link": "https://blog.jetbrains.com/blog/2025/01/16/gartner-peer-insights-customers-choice/",
        "pubDate": "Thu, 16 Jan 2025 14:45:53 +0000",
        "content:encodedSnippet": "JetBrains is honored to be recognized as a Customers’ Choice in the 2024 Gartner® Peer Insights™ Voice of the Customer for Integrated Development Environment (IDE) Software – a distinction we are proud to receive for the second consecutive year. \n      \n        Read the Report\n    \n\n\n\n\n\n\n\n\nA trusted vendor\nWe believe JetBrains’ consistent innovation and developer-first approach have earned us this recognition. With flagship IDEs like IntelliJ IDEA, PyCharm, PhpStorm, Rider, WebStorm, and others, JetBrains empowers developers to write better code and be more productive.\n\nWe are honored to be recognized as a Customers’ Choice in the IDE category for the second consecutive year. We believe this recognition underscores our ongoing commitment to investing in IDEs that provide an exceptional developer experience. Trusted by over 300,000 organizations, including 90% of Fortune Global Top 100 companies, JetBrains remains dedicated to creating best-in-class tools covering the entire development lifecycle.\nMikhail Vink, Head of Business Development\n\n\n\n\nWhat makes JetBrains stand out?\nJetBrains IDEs are known for their cutting-edge features, intuitive interfaces, and unwavering focus on enhancing developer productivity. Here’s what real users had to say:\n“IntelliJ IDEA provides smart code completion, deep static analysis and intelligent refactoring. This has helped team accelerate code completion and review. We have seen 20% increase in code merges with the reduction in code rollbacks.” (Link to the review)\n“PyCharm has been an absolute game-changer for my Python development workflow. Its intuitive interface and powerful code analysis tools have significantly boosted my productivity.” (Link to the review)\nWebStorm: “The ultimate IDE for a frontend developer with cutting edge features.” (Link to the review) \nThese reviews highlight JetBrains’ commitment to delivering an exceptional development experience across programming languages and ecosystems. See it for yourself! Explore JetBrains reviews on Gartner Peer Insights.\n\n\n\n\nCelebrate with us\nRead the full Gartner Peer Insights Voice of the Customer report.\n      \n        Read the Report\n    \n\n\n\n\n\n\n\n\nGartner, Voice of the Customer for Integrated Development Environment Software. By Peer Contributors, 28 November 2024\nGARTNER is a registered trademark and service mark of Gartner, Inc. and/or its affiliates in the U.S. and internationally, PEER INSIGHTS is a registered trademark, and The GARTNER PEER INSIGHTS CUSTOMERS’ CHOICE badge is a trademark and service mark of Gartner, Inc. and/or its affiliates and is used herein with permission. All rights reserved.\nGartner® Peer Insights™ content consists of the opinions of individual end users based on their own experiences with the vendors listed on the platform, should not be construed as statements of fact, nor do they represent the views of Gartner® or its affiliates. Gartner® does not endorse any vendor, product or service depicted in this content nor makes any warranties, expressed or implied, with respect to this content, about its accuracy or completeness, including any warranties of merchantability or fitness for a particular purpose.\nThis graphic was published by Gartner, Inc. as part of a larger research document and should be evaluated in the context of the entire document. The Gartner document is available upon request from JetBrains.",
        "dc:creator": "Sergey Kozlovskiy",
        "content": "JetBrains is honored to be recognized as a Customers’ Choice in the 2024 Gartner® Peer Insights™ Voice of the Customer for Integrated Development Environment (IDE) Software – a distinction we are proud to receive for the second consecutive year.&#160; Read the Report A trusted vendor We believe JetBrains’ consistent innovation and developer-first approach have earned [&#8230;]",
        "contentSnippet": "JetBrains is honored to be recognized as a Customers’ Choice in the 2024 Gartner® Peer Insights™ Voice of the Customer for Integrated Development Environment (IDE) Software – a distinction we are proud to receive for the second consecutive year.  Read the Report A trusted vendor We believe JetBrains’ consistent innovation and developer-first approach have earned […]",
        "guid": "https://blog.jetbrains.com/?post_type=blog&p=538225",
        "categories": [
          "news"
        ],
        "isoDate": "2025-01-16T14:45:53.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": []
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Jason Chlus",
        "title": "Our Favorite NEW Visual Studio Features of 2024",
        "link": "https://devblogs.microsoft.com/visualstudio/our-favorite-new-visual-studio-features-of-2024/",
        "pubDate": "Thu, 16 Jan 2025 17:01:56 +0000",
        "content:encodedSnippet": "Last year, the Visual Studio team delivered many new developer-focused improvements and AI integrations, many of which came directly from your feedback on Developer Community. In this post, we highlight the team’s favorite features from 2024 that boost productivity, streamline workflows, and enhance your coding experience. Let’s dive in!\nDownload Visual Studio 2022\n\n\nImage Hover Preview: See your images instantly! (Mads Kristensen 00:30)\nStruggling to visualize referenced images in your code? Visual Studio’s Image Hover Preview solves this by showing a quick preview of any image, complete with dimensions and file size, when you hover over its reference. It’s a small addition with a big impact on productivity.\n\nI love this feature!\nError Copying Improvements: Copy only what you need (Mads Kristensen 00:55)\nHistorically, copying error messages might have included detailed data that weren’t necessary to you. With this update, you can copy (Ctrl+C) just the error description, making it easier to search for solutions online.\n\nBefore:\nSeverity Code Description Project File Line Suppression State\nError (active) CS0103 The name ‘Test’ does not exist in the current context ConsoleApp1 C:\\Users\\jamont\\source\\repos\\ConsoleApp1\\ConsoleApp1\\Program.cs 7\nAfter:\nThe name ‘Test’ does not exist in the current context\nDrag/Drop across multiple instances of Visual Studio (Mads Kristensen 1:45)\nYou can now copy/paste or drag/drop files between Visual Studio instances seamlessly. This feature works across most project types and enhances workflow efficiency.\n\nRename Suggestions: Smarter names for cleaner code (Dalia Ado Sheasha 2:48)\nTired of unclear variable or method names? The Rename Suggestions feature analyzes your code to offer context-aware naming options. It’s a lifesaver when working on legacy or inherited projects.\nI hate naming things; this means I don’t have to!\nCopilot for Commits: Automated and personalized messages (Jessie Houghton 4:23)\nCommit messages just got easier. GitHub Copilot now generates customized commit messages, ensuring they align with your preferences and cover every change.\n\nMemory Layout Viewer: Optimize memory usage (Sy Brand 5:25)\nVisual Studio now lets you visualize memory layout, identify gaps, and optimize memory usage. This is particularly beneficial for projects requiring efficient memory management.\n\nAsync Debugging made easy (Andy Sterland 6:23)\nDebugging async/await code is notoriously tricky. The new Async Debugger in Visual Studio provides clearer insights into async calls, making it easier to identify issues and debug effectively.\nNew .NET MAUI templates: Start projects with ease (Rachel Kang 8:08)\nWith this update to .NET MAUI templates, you can now include sample content to jump-start your project. These templates integrate popular toolkits for a smoother development experience.\n\nEverything Copilot (Bruno Capuano 9:50)\nYou can now ask domain specific questions in Copilot Chat. Which, in combination with Copilot Edits, provides targeted code suggestions that you can add in session. If you want to change up the suggestions, you now can choose between different models in Copilot Chat.\nNew Extension Manager and Extension Hot Loading (Maia Kelner 11:11)\nInstalling extensions no longer interrupts your flow. With extension hot loading, you can install and use extensions without restarting Visual Studio.\n\nCheck out the new Bright Xaml Extension!\nUnreal Engine integration: Game development streamlined (David Li 12:55)\nGame developers rejoice! Open Unreal Engine projects directly in Visual Studio, configure targets, and leverage the new Unreal Engine toolbar for efficient workflows.\n\nCode Search (Sandy Armstrong 14:13)\nUse Ctrl + T to launch search. You can now search for specific scopes (current document, entire solution, etc)\n\nYou can dock the feature search window!\n.NET Aspire integrations (James Montemagno 15:09)\nYou can now easily orchestrate your existing .NET applications and services with a single click. Visual Studio will automatically create the .NET Aspire `AppHost` and `ServiceDefault` projects and configure everything for you! From the same context menu in Visual Studio you can easily add .NET Aspire integrations to your project by bringing up a filtered NuGet search. Check it out!\n\nWe love your feedback!\nThese innovations and improvements are a direct result of your input. The Visual Studio team thrives on feedback, and your suggestions continue to make it better. Keep sharing your thoughts and ideas on Developer Community. We’re building the future of development together!\nThe post Our Favorite NEW Visual Studio Features of 2024 appeared first on Visual Studio Blog.",
        "dc:creator": "Jason Chlus",
        "content": "<p>Last year, the Visual Studio team delivered many new developer-focused improvements and AI integrations, many of which came directly from your feedback on Developer Community. In this post, we highlight the team’s favorite features from 2024 that boost productivity, streamline workflows, and enhance your coding experience. Let’s dive in! Image Hover Preview: See your images [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/our-favorite-new-visual-studio-features-of-2024/\">Our Favorite NEW Visual Studio Features of 2024</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Last year, the Visual Studio team delivered many new developer-focused improvements and AI integrations, many of which came directly from your feedback on Developer Community. In this post, we highlight the team’s favorite features from 2024 that boost productivity, streamline workflows, and enhance your coding experience. Let’s dive in! Image Hover Preview: See your images […]\nThe post Our Favorite NEW Visual Studio Features of 2024 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=252076",
        "categories": [
          "Artificial Intelligence",
          "Data and Analytics",
          "Debug",
          "Git",
          "GitHub Copilot",
          "performance",
          "Productivity",
          "Visual Studio",
          ".NET MAUI",
          "Aspire",
          "code search",
          "Copilot",
          "Debugging",
          "Extensions",
          "Unreal Engine"
        ],
        "isoDate": "2025-01-16T17:01:56.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "\r\n                            Dmitry Kopytkov,Deepak Gupta\r\n            \t\t\t",
        "title": "Evolving our infrastructure through the messaging system model in Dropbox",
        "link": "https://dropbox.tech/infrastructure/infrastructure-messaging-system-model-async-platform-evolution",
        "pubDate": "Tue, 21 Jan 2025 09:00:00 -0800",
        "content:encodedSnippet": "The asynchronous platform at Dropbox integrates a suite of services that enable tasks and workflows to function independently without having to wait on one another. This is pretty important to our work as developers: It empowers any service within Dropbox to initiate and schedule tasks, seamlessly supporting over 400 product use cases—including Dropbox Dash and our other AI innovations—and efficiently routing more than 30 million tasks every minute. It also handles change data capture (CDC) use cases, where changes in our underlying storage system, including the FileSystem, are relayed to various product lambdas and processes. In short, it helps us ensure impactful and efficient business operations.\nThis implementation was essential to our growth from where we were a couple of years ago. Back then, the asynchronous platform struggled with scalability and reliability, frequently falling short of the demands of our expanding product portfolio. For product engineers, the platform posed additional hurdles due to limited developer productivity tools, making it cumbersome to build and iterate on asynchronous workflows. Today’s transformation into a robust and scalable system marks a dramatic shift from those early challenges—it enables innovation at a desired pace.\nIn this blog, we’ll introduce an open messaging system model (MSM), which played a key role in evolving our platform. It helped us build a unified event-driven system capable of orchestrating a wide range of asynchronous tasks and meeting future needs, especially as we focus on AI. Inspired by the Open Systems Interconnection (OSI) model, the MSM divides our platform into five logical layers. This standardization simplifies layers such as frontend interfaces, lambda functions, event schedulers, and event routers, allowing them to work across various use cases with different delivery guarantees and data sources, including those related to CDC.\nLet’s get into it.\n\r\n\r\n    \nChallenges and limitations in our asynchronous infrastructure\n\r\n\r\n\n\nBeginning in 2021, our infrastructure comprised multiple asynchronous systems, each tailored to specific product or process requirements. These systems facilitated diverse functions—such as streaming events for Dropbox file uploads and edits—as well as supporting domains like security, abuse prevention, machine learning, and search indexing. Additionally, Dropbox integrated CDC functionality, enabling any modification within the underlying storage systems to generate an event, subsequently activating the async infrastructure. Despite occasional functional overlaps, these systems were developed, operated, and maintained separately, leading to inconsistencies in development speed, reliability, and operational ease.\nKey issues and limitations with these systems were as follows:\nDeveloper efficiency\nThe complexity of the current systems required product engineers to undertake a steep learning curve and assume responsibility for operational tasks such as capacity planning, release processes, and support, leading to reduced development speed and productivity.\nReliability\nThese systems had varied service-level objectives (SLOs) for availability, latency, processing, and recovery, which resulted in inconsistent and unreliable performance. Additionally, systems were not multi-homed, and this created significant reliability risk for multiple business use cases in the event of data center failure.\nOperability\nThe variety of systems led to higher operational costs due to their complexity, requiring additional development effort for maintenance and support. The asynchronous components in our technology stack relied on a mix of external queuing solutions, such as Kafka, Redis, and Amazon SQS, creating an infrastructure that was challenging to manage and operate.\nSystem scalability\nAt the beginning of 2021, our system was processing over 30 billion requests daily to dispatch jobs to lambda functions. (Lambda is a serverless cloud service that runs your code automatically in response to events, without requiring you to manage any servers.) However, meeting the defined SLOs became increasingly challenging. Certain critical components, such as the delayed event scheduler, had already maxed out their throughput capacity. Consequently, we had to implement rigorous screening protocols for each new use case before onboarding in order to ensure it adhered to the system's capacity limitations and wouldn't jeopardize its performance.\nLambda infrastructure\nThe lambda-based architecture utilized on the consumer side was complex and diverged from the Dropbox service-oriented architecture (SOA) guidelines and established best practices. Consequently, diagnosing and investigating issues on the consumption side became highly challenging, as it didn't integrate seamlessly with the Dropbox infrastructure and recommended methodologies. This lack of alignment resulted in several adverse effects, notably:\nRelease consistency: The release procedures across these systems lacked uniformity and robust safety measures, introducing deployment and update risks.\nCompute efficiency: The compute clusters supporting these systems operated below peak efficiency, resulting in suboptimal resource utilization.\nNo autoscaling: The absence of autoscaling for lambda infrastructure, stemming from its deviation from the Dropbox SOA guidelines, resulted in poor integration with our autoscaling infrastructure. As a result, there was a reliance on customer or platform-owner intervention to manually augment capacity when the base capacity proved inadequate to manage the workload.\nExtensibility\nExtensibility posed a significant challenge for these systems, characterized by a deficiency in flexibility and scalability to adapt to emerging product demands. The current solutions were ill-equipped to seamlessly integrate new workflows, and any attempts to expand them would introduce unnecessary complexities in implementation. With the introduction of Cypress, our new filesystem architecture, the existing system faced limitations in expanding our CDC pipeline to distribute Cypress events to multiple subscribers within Dropbox.\nIn all, these challenges underscored the need for a more unified and consistent approach to our asynchronous infrastructure, emphasizing the importance of addressing developer velocity, reliability, operability, efficiency, and extensibility to better support the company's evolving product landscape.\n\r\n\r\n    \nRethinking our approach\n\r\n\r\n\n\nThe existing async systems already supported over 400 business use cases. The large number of existing use cases meant we didn’t have the flexibility to construct an entirely new system from scratch, as the migration would have been very time consuming. Instead, we decided to adopt a phased approach, with incremental steps to rebuild existing systems that mitigate risks associated with migrating existing production flows to a new infrastructure. Returning to the drawing board, we outlined three primary goals for the new platform, envisioning a gradual and incremental build-up of capabilities:\nDevelopment velocity\nSimplify the asynchronous interface to streamline platform adoption for product engineers. This allows them to focus on creating innovative product features rather than investing time in understanding the complex asynchronous landscape and determining the most suitable system for their use case.\nDecrease the operational burden on product engineers by implementing release practices that identify code regressions during deployment and automatically initiate rollbacks if a new release breaches predefined thresholds.\nEnable automatic compute scaling when a lambda function encounters a backlog of events to process, ensuring that the current base capacity is augmented if deemed insufficient.\nRobust and extensible async foundation\nUnify common elements and patterns across existing async systems within Dropbox and simplify the interface.\nSupport new use cases with minimal modifications and avoid the need to build entire new systems by providing extensible components and flexible APIs.\nCost and operational efficiency\nStreamline the foundational infrastructure by phasing out redundant systems (where applicable) and cut down on operational costs.\nTransition lambda infrastructure to the Dropbox SOA stack to increase compute efficiency and enable functionalities such as autoscaling, multihoming, and improved out-of-the-box monitoring capabilities.\nThe overarching key performance indicator (KPI) that we aimed to improve over time was the \"time to launch\" for product engineers to deploy a new use case into production. As platform owners, our primary KPI of interest was the \"oncall time\" expended on a weekly basis.\n\r\n\r\n    \n The five layers of the messaging system model\n\r\n\r\n\n\nThe initial step in the refinement of the async system involved deconstructing it into its fundamental layers. We undertook this process to achieve the aforementioned objectives. Subsequently, a systematic approach was devised, beginning with the dissection of the async system into its core elements, followed by the formulation of a bottom-up strategy for its progressive enhancement.\nFrom a macroscopic standpoint, the asynchronous system can be mapped to an MSM consisting of three primary layers, analogous to the seven layers of the OSI model in network transmission frameworks. These three primary layers are:\nCustomer layer: This component, also known as the “frontend layer,” encompasses the various pathways through which users interact and interface with the async system. It encapsulates the mechanisms by which users communicate with and integrate into the async environment.\nOrchestration layer: This layer is intrinsic to the async system and encompasses the entirety of the tasks required for the scheduling and transmission of async operations to the compute layer (also known as the “execution layer”). It serves as the intermediary stage between the customer layer and the compute layer, and it’s responsible for ensuring that various components and services interact seamlessly to fulfill complex workflows and business logic requirements.\nCompute layer: This layer is the execution hub of the async system, where the actual processing and execution of async tasks take place. It is responsible for the seamless execution of asynchronous operations, thereby ensuring the efficient functioning of the system as a whole.\n\r\n\r\n    \r\n        \r\n            \r\n    \r\n\r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n\r\n        \r\n        <!-- <img data-sly-test.highRes=\"false\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2025/async-platform-evolution/diagrams/0125-Infrastructure-Async-Evolution.png 2x,  1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2025/async-platform-evolution/diagrams/0125-Infrastructure-Async-Evolution.png\"\r\n             aria-hidden=\"\"\r\n             alt=\"\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"1440\"\r\n             data-sly-attribute.height=\"1130\"\r\n             data-aem-asset-id=\"46222c44-8ece-4a89-9fe7-810b610c626c:0125-Infrastructure-Async-Evolution.png\"\r\n             data-trackable=\"true\" />\r\n        <img data-sly-test.highRes=\"false\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2025/async-platform-evolution/diagrams/0125-Infrastructure-Async-Evolution.png 2x,  1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2025/async-platform-evolution/diagrams/0125-Infrastructure-Async-Evolution.png\"\r\n             aria-hidden=\"\"\r\n             alt=\"\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"1440\"\r\n             data-sly-attribute.height=\"1130\"\r\n             data-aem-asset-id=\"46222c44-8ece-4a89-9fe7-810b610c626c:0125-Infrastructure-Async-Evolution.png\"\r\n             data-trackable=\"true\" /> -->\r\n\r\n        \r\n         \r\n        \r\n    \r\n\r\n            \nA 10,000-foot view of the async system\n\r\n        \r\n    \r\n\nThe three layers mentioned above can then be further broken down into five, more specific layers—frontend, scheduler, flow control, delivery, and execution—with each new layer serving an important role within the above three buckets. (Some overlap occurs between the customer and orchestration layers). These five layers of the MSM are illustrated in the diagram below.\n\r\n\r\n    \r\n        \r\n            \r\n    \r\n\r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n        \r\n\r\n        \r\n        \r\n\r\n        \r\n        <!-- <img data-sly-test.highRes=\"false\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2025/async-platform-evolution/diagrams/0125-Infrastructure-Async-Evolution-2.png 2x,  1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2025/async-platform-evolution/diagrams/0125-Infrastructure-Async-Evolution-2.png\"\r\n             aria-hidden=\"\"\r\n             alt=\"\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"1440\"\r\n             data-sly-attribute.height=\"2540\"\r\n             data-aem-asset-id=\"3ad24655-f395-485c-aa0c-f0f19d55d0f1:0125-Infrastructure-Async-Evolution-2.png\"\r\n             data-trackable=\"true\" />\r\n        <img data-sly-test.highRes=\"false\"\r\n             srcset=\"/cms/content/dam/dropbox/tech-blog/en-us/2025/async-platform-evolution/diagrams/0125-Infrastructure-Async-Evolution-2.png 2x,  1x\"\r\n             src=\"/cms/content/dam/dropbox/tech-blog/en-us/2025/async-platform-evolution/diagrams/0125-Infrastructure-Async-Evolution-2.png\"\r\n             aria-hidden=\"\"\r\n             alt=\"\"\r\n             class=\"\"\r\n             data-sly-attribute.width=\"1440\"\r\n             data-sly-attribute.height=\"2540\"\r\n             data-aem-asset-id=\"3ad24655-f395-485c-aa0c-f0f19d55d0f1:0125-Infrastructure-Async-Evolution-2.png\"\r\n             data-trackable=\"true\" /> -->\r\n\r\n        \r\n         \r\n        \r\n    \r\n\r\n            \nAn illustration of the five components of the Messaging System Model (MSM)\n\r\n        \r\n    \r\n\nNow, let's take a closer look at each of these five layers.\nFrontend\nIn the architecture of an asynchronous system, the frontend layer assumes the critical role of serving as the primary interface for user interaction with the system. It represents the user-facing aspect of the asynchronous environment, orchestrating seamless communication and integration with the system's core functionalities. Users are categorized into two distinct groups: first, there are the regular product engineers who utilize programmatic methods to invoke a publish remote procedure call (RPC) and enqueue events, destined to be consumed by one or more subscribers. The second category encompasses systems such as databases or event sources, which necessitate the enqueuing of changes to diverse objects, entities, or files, thereby propelling both internal and external business workflows forward.\nA pivotal responsibility of the frontend layer is the management of the schema registry and the rigorous validation of every event schema traversing the system. This stringent schema validation process ensures that published events conform to the predefined contract established with subscribers. Additionally, the frontend layer is tasked with the intricate conversion of disparate message formats, including JSON, Proto, and Avro, among others, into a standardized message format—typically protocol buffers—compatible with the internal asynchronous implementation.\nFurthermore, the frontend component is entrusted with guaranteeing the durability of all events published to the asynchronous system, thereby safeguarding the integrity and reliability of the system's data flow. \nScheduler\nThe scheduler is the core engine within an async system and plays a crucial role in coordinating and dispatching disparate events for various consumers that subscribe to these events. This layer plays various roles. For example, for a CDC use case, this will call external data source APIs to get relevant range for the payloads that will be delivered to the subscribers. For a use case where events need delayed execution, the scheduler would store these events separately so they can be trigger at desired timestamp with a process keeping tabs on these events and publishing them to subscribers at those desired scheduled timestamps. \nScheduler also has the responsibility to maintain the order of execution of the events and ensures task delivery to subscribers based on this order.\nFlow control\nFlow control plays a pivotal role in the orchestration layer, managing the distribution of tasks to subscribers based on several factors, such as subscriber availability, task priority, and potential throttling events. For instance, in a CDC scenario, the orchestration layer dynamically adjusts the rate of queries dispatched to subscribers. This adaptation occurs when the orchestration layer detects that a subscriber is unable to handle the job throughput effectively or when the source, backing CDC, signals the scheduler client to reduce the pace.\nState management, another function of this layer, encompasses the maintenance of data structures responsible for tracking ongoing events and their respective statuses (such as pending, running, or complete). Additionally, it incorporates mechanisms to retry tasks in case of transient failures, ensuring robustness and reliability in task execution.\nDelivery\nThe execution layer of the messaging system model can be broken down into two main parts. The first is the delivery layer, which is the process of directing the event to the right place or service. The second, the event execution, we’ll get to in a bit.\nRouting is the final layer in an asynchronous system, responsible for directing the message out of the system and into the domain where a designated process or lambda function will handle the event. This process or lambda function may be hosted within the same virtual private cloud (VPC) as the messaging infrastructure or may be a part of public clouds like AWS, Azure, etc. In a push-based model, the routing layer is one of the most critical components, similar to the “last mile delivery” in an e-commerce delivery system.\nRouting enables many critical functions, including:\nMessage filtering based on subscriber preferences\nDelivery retries for transient failures\nContinuously monitoring the health of a subscriber’s event execution hosts, and then routing events only to those that are healthy\nDispatching event execution status to the orchestration layer for state machine management\nEvent delivery concurrency management\nExecution\nThe event execution is the second layer of the primary compute bucket. It’s when the actual task happens, and it’s usually done by a lambda function (i.e., serverless code), or a remote process—potentially even another system or service—that handles the event. In short, the compute layer involves first routing the event and then actually processing it.\nLambda infrastructure refers to the underlying framework responsible for executing events. When an event is triggered, a process is initiated within this infrastructure, which subsequently returns either a success or retriable failure status post-execution. If no status is returned, or if an error occurs, the default assumption is a retriable failure. In this interaction, the router acts as the client, operating under a push model.\nIdeally, the executing process operates across multiple cloud environments to enhance reliability. The router has the capability to push events to various clouds based on the locality preference configured by the lambda/process owner. For example, some users may opt to configure their processes to be active in specific clouds to ensure proximity to backend storage dependencies, thereby minimizing cross-data center latency.\nLambda infrastructure should also include autoscaling as part of its features. At Dropbox, our lambda infrastructure is backed by Atlas, which offers autoscaling capabilities. Additionally, Atlas supports release-time hooks, enabling validation and rollback of code changes if they would potentially degrade service uptime or impact any features negatively.\n\r\n\r\n    \nConclusion\n\r\n\r\n\n\nEngaging with customers and understanding their requirements and pain points is vital when evolving or reconstructing a major platform component. This approach was instrumental in shaping the blueprint for MSM. By applying first principles, we deconstructed the problem into its smallest components and envisioned a system that delivers the flexibility and extensibility required for the platform. This solid foundation enabled us to rebuild from the ground up with clarity and purpose, ensuring the platform meets current demands while remaining adaptable to future challenges.\nThis blog has only scratched the surface of the asynchronous platform we’ve built over the past few years, and we’re constantly looking for new ways to improve our infrastructure. We’re excited to, in the future, dive deeper into other critical design decisions that help us build a more efficient and useful Dropbox!\n \n~ ~ ~\n \nIf building innovative products, experiences, and infrastructure excites you, come build the future with us! Visit dropbox.com/jobs to see our open roles, and follow @LifeInsideDropbox on Instagram and Facebook to see what it's like to create a more enlightened way of working.",
        "dc:creator": "\r\n                            Dmitry Kopytkov,Deepak Gupta\r\n            \t\t\t",
        "content": "null",
        "contentSnippet": "null",
        "guid": "https://dropbox.tech/infrastructure/infrastructure-messaging-system-model-async-platform-evolution",
        "categories": [
          "models",
          "Developer",
          "AI",
          "Lambda",
          "Dash",
          "Infrastructure"
        ],
        "isoDate": "2025-01-21T17:00:00.000Z"
      }
    ]
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": [
      {
        "creator": "sunyzero",
        "title": "gnome-tweaks로 리눅스 데스크탑 환경의 미세 조정",
        "link": "http://sunyzero.tistory.com/311",
        "pubDate": "Sun, 19 Jan 2025 23:48:43 +0900",
        "author": "sunyzero",
        "comments": "http://sunyzero.tistory.com/311#entry311comment",
        "content": "<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">리눅스 GNOME 데스크탑 환경을 사용하다보면 뭔가 약간 불편함이 있을 수 있는데, 이를 미세하게 조정해주면 편리해진다. 이를 위해 사용되는 프로그램이 gnome-tweaks 이다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">1. 설치</span></h2>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">dnf install gnome-tweaks 로 간단하게 설치할 수 있다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">2. 실행 및 설정</span></h2>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">애플리케이션 목록에서 실행해도되고, 터미널에서 gnome-tweaks로 실행해도 된다. 사용하는 유저로 로그인한 상태에서 실행하면 된다. root로 실행하지는 말자.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1032\" data-origin-height=\"630\"><span data-url=\"https://blog.kakaocdn.net/dn/M3UKs/btsLRhig95a/tNmcAciyh63SfNH13kykA0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/M3UKs/btsLRhig95a/tNmcAciyh63SfNH13kykA0/img.png\" data-alt=\"gnome-tweaks - Windows\"><img src=\"https://blog.kakaocdn.net/dn/M3UKs/btsLRhig95a/tNmcAciyh63SfNH13kykA0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FM3UKs%2FbtsLRhig95a%2FtNmcAciyh63SfNH13kykA0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1032\" height=\"630\" data-origin-width=\"1032\" data-origin-height=\"630\"/></span><figcaption>gnome-tweaks - Windows</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">Windows에서 설정할 수 있는 주요 기능은 다음과 같다. 특히 \"두번째 누름 동작에 크기 조절\"은 매우 유용한 기능이다.</span></p>\n<div>\n<table style=\"border-collapse: collapse; width: 100%;\" border=\"1\" data-ke-align=\"alignLeft\">\n<tbody>\n<tr>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">두번 누름</span></span></td>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">Minimize를 설정해두면 편리하게 사용할 수 있다. <br />(창 타이틀 부분을 두번 클리하면 즉시 최소화 해준다)</span></span></td>\n</tr>\n<tr>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">제목 표시줄 단추=최대화/최소화</span></span></td>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">최대화, 최소화 기능을 켜면 창 우측 or 좌측 상단에 최소/최대화 기능이 생긴다.</span></span></td>\n</tr>\n<tr>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">모달 대화 상자 붙여두기</span></span></td>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">모달 대화 상자와 상위 창이 같이 이동하면 직관적이고 잘못 입력하거나 오해할 가능성이 적어진다.</span></span></td>\n</tr>\n<tr>\n<td><span style=\"background-color: #f6e199; font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">두번째 누름 동작에 크기 조절</span></span></td>\n<td><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">Super키를 누른 상태에서 휠 버튼으로 크기 조절하던 것을 마우스 오른 버튼으로 대체하여 편리해진다. 이 기능은 적극적으로 추천한다.</span></span><br /><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><span style=\"color: #000000;\">(두번째 누름 동작 = Mouse 2번째 버튼 클릭 동작)</span></span></td>\n</tr>\n</tbody>\n</table>\n<span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\"><b><br /></b> </span></div>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">Keyboard에서는&nbsp;Capslock&nbsp;동작에&nbsp;대해서&nbsp;커스터마이징을&nbsp;하는&nbsp;편이다.&nbsp;Linux에서는&nbsp;보통&nbsp;&lt;Ctrl-C&gt;나&nbsp;&lt;Ctrl-Z&gt;,&nbsp;&lt;Ctrl-W&gt;를&nbsp;많이&nbsp;사용한다.&nbsp;각각&nbsp;취소,&nbsp;SIGTSTP&nbsp;시그널&nbsp;전달,&nbsp;GUI&nbsp;프로그램의&nbsp;탭&nbsp;닫기&nbsp;기능으로&nbsp;사용된다.&nbsp;이&nbsp;기능을&nbsp;누를때&nbsp;Capslock키를&nbsp;&lt;Ctrl&gt;로&nbsp;대체하면&nbsp;편리해진다.&nbsp;대신에&nbsp;Capslock&nbsp;기능은&nbsp;양쪽&nbsp;Shift를&nbsp;동시에&nbsp;눌러서&nbsp;토글하는&nbsp;방식으로&nbsp;변경한다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"528\" data-origin-height=\"566\"><span data-url=\"https://blog.kakaocdn.net/dn/Cfmkw/btsLSxYObiO/7CMBqnOXGC6RpJb0N2tZDK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Cfmkw/btsLSxYObiO/7CMBqnOXGC6RpJb0N2tZDK/img.png\" data-alt=\"gnome-tweaks - keyboard - caps lock\"><img src=\"https://blog.kakaocdn.net/dn/Cfmkw/btsLSxYObiO/7CMBqnOXGC6RpJb0N2tZDK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FCfmkw%2FbtsLSxYObiO%2F7CMBqnOXGC6RpJb0N2tZDK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"528\" height=\"566\" data-origin-width=\"528\" data-origin-height=\"566\"/></span><figcaption>gnome-tweaks - keyboard - caps lock</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">앞서 언급한대로 caps lock을 control키로 사용하는 경우에는 양쪽 shift로 caps lock을 대신하면 된다. 이 설정은 호환성 옵션 부분에 있다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"528\" data-origin-height=\"566\"><span data-url=\"https://blog.kakaocdn.net/dn/cOxQq0/btsLScU6XY8/MvmmPeaSLsUdf6SDi6t941/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cOxQq0/btsLScU6XY8/MvmmPeaSLsUdf6SDi6t941/img.png\" data-alt=\"gnome-tweaks - keyboard - compatibility\"><img src=\"https://blog.kakaocdn.net/dn/cOxQq0/btsLScU6XY8/MvmmPeaSLsUdf6SDi6t941/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcOxQq0%2FbtsLScU6XY8%2FMvmmPeaSLsUdf6SDi6t941%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"528\" height=\"566\" data-origin-width=\"528\" data-origin-height=\"566\"/></span><figcaption>gnome-tweaks - keyboard - compatibility</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">이외에 기본 Font나 appearance에서 이것저것 수정이 가능하므로 한번씩 살펴보면 좋을 듯 하다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">히스토리</span></h2>\n<p data-ke-size=\"size16\"><span style=\"font-family: 'Noto Sans Demilight', 'Noto Sans KR';\">2025-01-19 작성</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "리눅스 GNOME 데스크탑 환경을 사용하다보면 뭔가 약간 불편함이 있을 수 있는데, 이를 미세하게 조정해주면 편리해진다. 이를 위해 사용되는 프로그램이 gnome-tweaks 이다.\n \n1. 설치\ndnf install gnome-tweaks 로 간단하게 설치할 수 있다.\n \n2. 실행 및 설정\n애플리케이션 목록에서 실행해도되고, 터미널에서 gnome-tweaks로 실행해도 된다. 사용하는 유저로 로그인한 상태에서 실행하면 된다. root로 실행하지는 말자.\ngnome-tweaks - Windows\n\n\nWindows에서 설정할 수 있는 주요 기능은 다음과 같다. 특히 \"두번째 누름 동작에 크기 조절\"은 매우 유용한 기능이다.\n두번 누름\nMinimize를 설정해두면 편리하게 사용할 수 있다. \n(창 타이틀 부분을 두번 클리하면 즉시 최소화 해준다)\n\n\n제목 표시줄 단추=최대화/최소화\n최대화, 최소화 기능을 켜면 창 우측 or 좌측 상단에 최소/최대화 기능이 생긴다.\n\n\n모달 대화 상자 붙여두기\n모달 대화 상자와 상위 창이 같이 이동하면 직관적이고 잘못 입력하거나 오해할 가능성이 적어진다.\n\n\n두번째 누름 동작에 크기 조절\nSuper키를 누른 상태에서 휠 버튼으로 크기 조절하던 것을 마우스 오른 버튼으로 대체하여 편리해진다. 이 기능은 적극적으로 추천한다.\n(두번째 누름 동작 = Mouse 2번째 버튼 클릭 동작)\n\n\n\n\n \nKeyboard에서는 Capslock 동작에 대해서 커스터마이징을 하는 편이다. Linux에서는 보통 <Ctrl-C>나 <Ctrl-Z>, <Ctrl-W>를 많이 사용한다. 각각 취소, SIGTSTP 시그널 전달, GUI 프로그램의 탭 닫기 기능으로 사용된다. 이 기능을 누를때 Capslock키를 <Ctrl>로 대체하면 편리해진다. 대신에 Capslock 기능은 양쪽 Shift를 동시에 눌러서 토글하는 방식으로 변경한다.\ngnome-tweaks - keyboard - caps lock\n\n\n앞서 언급한대로 caps lock을 control키로 사용하는 경우에는 양쪽 shift로 caps lock을 대신하면 된다. 이 설정은 호환성 옵션 부분에 있다.\ngnome-tweaks - keyboard - compatibility\n\n\n \n이외에 기본 Font나 appearance에서 이것저것 수정이 가능하므로 한번씩 살펴보면 좋을 듯 하다.\n \n히스토리\n2025-01-19 작성",
        "guid": "http://sunyzero.tistory.com/311",
        "categories": [
          "컴퓨터 관련/리눅스 데스크탑",
          "gnome",
          "gnome-tweaks",
          "linux",
          "그놈 데스크탑",
          "리눅스",
          "캡스락"
        ],
        "isoDate": "2025-01-19T14:48:43.000Z"
      }
    ]
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권영재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": [
      {
        "title": "Spring Data MongoDB에서의 Update 전략과 경험",
        "link": "https://cheese10yun.github.io/spring-data-mongo-update-guide-1/",
        "pubDate": "2025-01-18T14:24:07.000Z",
        "content": "<p>Spring Data MongoDB를 활용한 애플리케이션 개발 과정에서, 데이터를 업데이트하는 방법은 프로젝트의 설계와 성능에 큰 영향을 미칩니다. 특히, <code>mongoRepository.save</code>, <code>mongoTemplate.save</code>, 그리고 <code>mongoTemplate.updateFirst</code>와 같은 메서드들은 각각의 특성과 적합한 상황이 다릅니다. 이 글에서는 Spring Data MongoDB에서 <strong>업데이트 전략</strong>을 중심으로 개발 경험에서 얻은 인사이트를 공유하며, 각 메서드의 동작 방식과 적절한 사용 방법에 대해 논의합니다.</p><h2><span id=\"update-메서드-비교\">Update 메서드 비교</span></h2><p>Spring Data MongoDB에서 사용되는 주요 업데이트 메서드들은 아래와 같이 동작 방식과 적합한 시나리오에서 차이가 있습니다:</p><table><thead><tr><th><strong>특징</strong></th><th><strong>mongoRepository.save</strong></th><th><strong>mongoTemplate.save</strong></th><th><strong>mongoTemplate.updateFirst</strong></th></tr></thead><tbody><tr><td><strong>작업 대상</strong></td><td>단일 문서</td><td>단일 문서</td><td>단일 문서</td></tr><tr><td><strong>저장 방식</strong></td><td>변경된 필드만 업데이트</td><td>전체 문서 교체</td><td>변경된 필드만 업데이트</td></tr><tr><td><strong>문서가 없을 경우</strong></td><td>새로 삽입</td><td>새로 삽입</td><td>기본적으로 아무 작업도 수행하지 않음</td></tr><tr><td><strong>업데이트 범위</strong></td><td>필드 단위</td><td>전체 문서</td><td>필드 단위</td></tr><tr><td><strong>조건 지정</strong></td><td><code>_id</code> 기준</td><td><code>_id</code> 기준</td><td>사용자 정의 쿼리</td></tr><tr><td><strong>Spring Data 통합</strong></td><td>페이징, 정렬 등 지원</td><td>미지원</td><td>미지원</td></tr><tr><td><strong>적합한 상황</strong></td><td>간단한 CRUD 작업</td><td>전체 문서 교체 또는 삽입</td><td>조건에 맞는 단일 문서 필드 수정</td></tr></tbody></table><h3><span id=\"mongotemplatesave\">mongoTemplate.save</span></h3><p>문서 전체 교체(Replace)를 수행합니다.</p><h4><span id=\"동작-방식\">동작 방식</span></h4><ul><li><code>_id</code> 필드를 기준으로 MongoDB에서 문서를 검색.</li><li>문서가 존재하면 <strong>전체 문서를 교체</strong>합니다.</li><li>문서가 존재하지 않으면 새로 삽입합니다.</li><li>저장 객체에 없는 필드는 기존 문서에서 삭제됩니다.</li></ul><h4><span id=\"예제\">예제</span></h4><figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">val</span> user = User(id = <span class=\"string\">\"123\"</span>, name = <span class=\"string\">\"John Doe\"</span>, age = <span class=\"number\">30</span>)</span><br><span class=\"line\">mongoTemplate.save(user)</span><br></pre></td></tr></table></figure><h4><span id=\"결과\">결과</span></h4><ul><li>기존 문서: <code>{ &quot;_id&quot;: &quot;123&quot;, &quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 25, &quot;email&quot;: &quot;alice@example.com&quot; }</code></li><li>업데이트 후: <code>{ &quot;_id&quot;: &quot;123&quot;, &quot;name&quot;: &quot;John Doe&quot;, &quot;age&quot;: 30 }</code></li><li>변경 사항: <code>email</code> 필드가 삭제됨.</li></ul><h3><span id=\"mongorepositorysave\">mongoRepository.save</span></h3><p>문서의 일부 필드만 업데이트(Partial Update)를 수행합니다.</p><h4><span id=\"동작-방식\">동작 방식</span></h4><ul><li><code>_id</code> 필드를 기준으로 MongoDB에서 문서를 검색.</li><li>문서가 존재하면 <strong>변경된 필드만 업데이트</strong>하고, 나머지 필드는 유지됩니다.</li><li>문서가 존재하지 않으면 새로 삽입합니다.</li></ul><h4><span id=\"예제\">예제</span></h4><figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">val</span> user = User(id = <span class=\"string\">\"123\"</span>, name = <span class=\"string\">\"John Doe\"</span>)</span><br><span class=\"line\">userRepository.save(user)</span><br></pre></td></tr></table></figure><h4><span id=\"결과\">결과</span></h4><ul><li>기존 문서: <code>{ &quot;_id&quot;: &quot;123&quot;, &quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 25, &quot;email&quot;: &quot;alice@example.com&quot; }</code></li><li>업데이트 후: <code>{ &quot;_id&quot;: &quot;123&quot;, &quot;name&quot;: &quot;John Doe&quot;, &quot;age&quot;: 25, &quot;email&quot;: &quot;alice@example.com&quot; }</code></li><li>변경 사항: <code>name</code> 필드만 업데이트, 나머지 필드는 유지됨.</li></ul><h3><span id=\"mongotemplateupdatefirst\">mongoTemplate.updateFirst</span></h3><p>MongoDB의 <strong><code>updateFirst</code></strong> 명령어를 실행하여 <strong>단일 문서를 부분 업데이트</strong>합니다.</p><h4><span id=\"동작-방식\">동작 방식</span></h4><ul><li>조건을 지정하여 MongoDB에서 문서를 검색.</li><li>첫 번째로 매칭된 문서의 <strong>일부 필드만 업데이트</strong>합니다.</li><li>문서가 존재하지 않으면 기본적으로 아무 작업도 수행하지 않습니다(삽입하지 않음).</li><li><code>$set</code>과 같은 MongoDB 연산자를 사용하여 지정된 필드만 업데이트합니다.</li></ul><h4><span id=\"예제\">예제</span></h4><figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">val</span> query = Query(Criteria.where(<span class=\"string\">\"name\"</span>).`<span class=\"keyword\">is</span>`(<span class=\"string\">\"Alice\"</span>))</span><br><span class=\"line\"><span class=\"keyword\">val</span> update = Update().<span class=\"keyword\">set</span>(<span class=\"string\">\"age\"</span>, <span class=\"number\">30</span>)</span><br><span class=\"line\">mongoTemplate.updateFirst(query, update, User::<span class=\"class\"><span class=\"keyword\">class</span>.<span class=\"title\">java</span>)</span></span><br></pre></td></tr></table></figure><h4><span id=\"결과\">결과</span></h4><ul><li>기존 문서: <code>{ &quot;_id&quot;: &quot;123&quot;, &quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 25, &quot;email&quot;: &quot;alice@example.com&quot; }</code></li><li>업데이트 후: <code>{ &quot;_id&quot;: &quot;123&quot;, &quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 30, &quot;email&quot;: &quot;alice@example.com&quot; }</code></li><li>변경 사항: <code>age</code> 필드만 업데이트, 나머지 필드는 유지됨.</li></ul><h2><span id=\"효율적인-mongodb-업데이트-전략\">효율적인 MongoDB 업데이트 전략</span></h2><p><code>mongoTemplate.save</code>는 문서 전체를 교체하기 때문에 일반적인 경우에는 거의 사용되지 않습니다. 반면, <code>mongoRepository.save</code>는 더 직관적이며, 특히 Spring Data JPA 경험이 있는 개발자에게는 익숙하고 이해하기 쉬운 방식입니다. 그럼에도 불구하고, 저는 업데이트 작업에 <code>mongoTemplate</code>기반의 업데이트만을 사용하고 있습니다. 그 이유는 다음과 같습니다.</p><h3><span id=\"대량-처리에서의-성능-차이\">대량 처리에서의 성능 차이</span></h3><p><a href=\"https://cheese10yun.github.io/spring-data-mongodb-update-performance/\">MongoDB Update 성능 측정 및 분석</a>에서 업데이트 성능을 측정한 결과를 참고할 수 있습니다.</p><p><img src=\"https://raw.githubusercontent.com/cheese10yun/blog-sample/5fc6127a0800ca9bce5de5a6c73931b2025b0791/mongo-study/images/performance-update.png\" alt=\"\"></p><table><thead><tr><th><strong>Rows</strong></th><th><strong>saveAll</strong></th><th><strong>updateFirst</strong></th><th><strong>bulkOps (UNORDERED)</strong></th><th><strong>bulkOps (ORDERED)</strong></th></tr></thead><tbody><tr><td>100</td><td>1,052 ms</td><td>1,176 ms</td><td>46 ms</td><td>79 ms</td></tr><tr><td>200</td><td>2,304 ms</td><td>2,196 ms</td><td>103 ms</td><td>124 ms</td></tr><tr><td>500</td><td>5,658 ms</td><td>5,250 ms</td><td>309 ms</td><td>257 ms</td></tr><tr><td>1,000</td><td>11,106 ms</td><td>10,846 ms</td><td>418 ms</td><td>412 ms</td></tr><tr><td>2,000</td><td>22,592 ms</td><td>21,427 ms</td><td>1,060 ms</td><td>1,004 ms</td></tr><tr><td>5,000</td><td>54,407 ms</td><td>52,075 ms</td><td>2,663 ms</td><td>2,292 ms</td></tr><tr><td>10,000</td><td>107,651 ms</td><td>110,884 ms</td><td>4,514 ms</td><td>4,496 ms</td></tr></tbody></table><p>대량 처리를 할 경우 <code>saveAll</code> 방식은 내부적으로 반복문을 돌면서 <code>save</code>를 호출하는 방식으로 동작합니다. 이는 데이터베이스 요청을 문서별로 각각 보내기 때문에, 대량 처리 시 성능이 크게 저하됩니다. <code>saveAll</code>과 <code>updateFirst</code>는 모두 문서 단위로 데이터베이스 요청을 반복 호출하기 때문에 처리 성능이 거의 비슷하지만, 요청 수가 많아질수록 응답 시간이 급격히 증가하는 문제가 발생합니다.</p><p>반면, <code>bulkOps</code>는 여러 업데이트 작업을 한 번의 연산으로 묶어서 실행하므로 대량 처리에서 훨씬 효율적입니다. 이를 통해 처리 시간을 크게 단축할 수 있지만, <code>save</code>와 <code>saveAll</code> 방식으로는 <code>bulkOps</code>를 활용할 수 없다는 한계가 있습니다. 이러한 이유로 저는 대량 처리 작업에서 <code>updateFirst</code>와 함께 <code>bulkOps</code>를 활용하는 방식을 선호합니다.</p><p>또한, 대량 데이터를 업데이트할 때 <strong><code>where in</code> 절</strong>을 활용하면 효과적입니다. 이 경우, <code>mongoTemplate.updateMulti</code>를 사용하면 <code>bulkOps</code> 방식과 유사한 성능을 얻을 수 있습니다. <code>saveAll</code>을 사용하면 성능이 급격히 저하되므로, 대량 데이터를 업데이트할 때는 반드시 <code>mongoTemplate</code>을 사용하는 것이 좋습니다. 이러한 접근 방식은 대량 처리의 효율성과 성능 최적화를 보장하며, 대량 데이터를 다루는 애플리케이션에서 더욱 유용합니다.</p><h3><span id=\"명확한-변경-사항-추적\">명확한 변경 사항 추적</span></h3><p><code>mongoRepository.save</code>를 사용하여 데이터를 업데이트할 경우, 정확히 어떤 필드가 변경되었는지 추적하기 어렵습니다. MongoDB는 비정형 데이터베이스로, 다양한 필드와 그 필드들이 다루는 컨텍스트가 매우 다양합니다. 이런 상황에서 <code>mongoRepository.save</code>를 통해 업데이트가 이루어지면, 어떤 필드가 어떤 조건에서 업데이트되었는지 명확히 파악하기 어렵기 때문에 데이터 변경 사항을 추적하고 관리하는 데 어려움이 발생할 수 있습니다.</p><p>반면, <code>mongoTemplate</code>을 기반으로 업데이트 쿼리를 작성하면 특정 필드에 대해 명확히 정의된 업데이트를 수행할 수 있습니다. 각 업데이트가 어디에서 이루어졌는지, 어떤 필드가 변경되었는지를 코드 레벨에서 명확히 확인할 수 있어 추적이 용이합니다. 특히 프로젝트가 복잡해지거나 엄격한 변경 관리가 요구될수록, 이러한 명확성은 유지보수와 협업 측면에서 큰 장점으로 작용합니다. 이를 통해 데이터 업데이트의 불확실성을 줄이고, 코드의 가독성과 신뢰성을 높일 수 있습니다.</p><h2><span id=\"실제-사용-예시\">실제 사용 예시</span></h2><h3><span id=\"document-정의\">Document 정의</span></h3><figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Document(collection = <span class=\"meta-string\">\"members\"</span>)</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Member</span></span>(</span><br><span class=\"line\">    <span class=\"meta\">@Field(name = <span class=\"meta-string\">\"name\"</span>)</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> name: String,</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Field(name = <span class=\"meta-string\">\"address\"</span>)</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> address: Address,</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Field(name = <span class=\"meta-string\">\"member_id\"</span>)</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> memberId: String,</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Field(name = <span class=\"meta-string\">\"email\"</span>)</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> email: String,</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Field(name = <span class=\"meta-string\">\"status\"</span>)</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> status: MemberStatus</span><br><span class=\"line\">) : Auditable()</span><br></pre></td></tr></table></figure><p>위 예시와 같이 <code>Member</code> 도큐먼트가 정의되어 있다고 가정하겠습니다. 이 도큐먼트는 <code>MongoRepository</code>를 사용하여 업데이트하지 않기 때문에, 필드들이 <code>val</code>로 지정되어 있습니다. 필드를 <code>val</code>로 지정하면 도큐먼트의 특정 필드를 변경하기 위해 객체를 직접 수정한 뒤 <code>save</code>를 호출하는 방식이 불가능합니다. 이렇게 필드를 <code>val</code>로 지정하면 도큐먼트의 불변성을 보장하며, 특정 필드의 변경을 엄격히 관리할 수 있습니다.</p><h3><span id=\"repository-정의\">Repository 정의</span></h3><figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">MemberRepository</span> : <span class=\"type\">MongoRepository</span>&lt;<span class=\"type\">Member, ObjectId</span>&gt;, <span class=\"type\">MemberCustomRepository</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">MemberCustomRepository</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">fun</span> <span class=\"title\">updateName</span><span class=\"params\">(targets: <span class=\"type\">List</span>&lt;<span class=\"type\">MemberQueryForm</span>.<span class=\"type\">UpdateName</span>&gt;)</span></span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MemberCustomRepositoryImpl</span></span>(mongoTemplate: MongoTemplate) : MemberCustomRepository, MongoCustomRepositorySupport&lt;Member&gt;(Member::<span class=\"class\"><span class=\"keyword\">class</span>.<span class=\"title\">java</span>, <span class=\"type\">mongoTemplate) &#123;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">override</span> <span class=\"function\"><span class=\"keyword\">fun</span> <span class=\"title\">updateName</span><span class=\"params\">(targets: <span class=\"type\">List</span>&lt;<span class=\"type\">MemberQueryForm</span>.<span class=\"type\">UpdateName</span>&gt;)</span></span> &#123;</span><br><span class=\"line\">        bulkUpdate(</span><br><span class=\"line\">            targets.map &#123;</span><br><span class=\"line\">                Pair(</span><br><span class=\"line\">                    &#123; Query(Criteria.where(<span class=\"string\">\"id\"</span>).`<span class=\"keyword\">is</span>`(it.id)) &#125;,</span><br><span class=\"line\">                    &#123; Update().<span class=\"keyword\">set</span>(<span class=\"string\">\"name\"</span>, it.name) &#125;</span><br><span class=\"line\">                )</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        )</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><p><code>MongoCustomRepositorySupport</code>를 상속받아 <code>bulkUpdate</code> 메서드를 통해 <code>bulkOps</code>를 사용한 대량 업데이트를 수행합니다. 이를 활용하면 대량 데이터를 효율적으로 처리할 수 있으며, 단일 업데이트만 필요한 경우 <code>updateFirst</code>를 사용하여 업데이트를 수행할 수도 있습니다. 그러나 특별한 이유가 없다면 <code>MongoCustomRepositorySupport</code> 기반으로 대량 업데이트를 지원하는 <code>bulkUpdate</code>를 사용하는 것을 권장합니다.</p><p>이 방식에 대한 자세한 구현 방법은 이전 포스팅 <a href=\"https://cheese10yun.github.io/spring-data-mongodb-update-performance/\">MongoDB Update 성능 측정 및 분석 - MongoCustomRepositorySupport을 통한 bulkOps 기능 제공</a>에서 확인할 수 있습니다.</p><h3><span id=\"업데이트-쿼리에-사용할-객체-정의\">업데이트 쿼리에 사용할 객체 정의</span></h3><figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">object</span> MemberQueryForm &#123;</span><br><span class=\"line\">    <span class=\"keyword\">data</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">UpdateName</span></span>(</span><br><span class=\"line\">        <span class=\"keyword\">val</span> id: ObjectId,</span><br><span class=\"line\">        <span class=\"keyword\">val</span> name: String</span><br><span class=\"line\">    )</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><p><code>MemberQueryForm</code> 객체를 정의하여 쿼리에 필요한 필드와 데이터를 명확하게 관리합니다. 이를 통해 업데이트 작업에서 어떤 필드가 업데이트되는지 명확히 파악할 수 있습니다. 만약 <code>MemberQueryForm</code>에 정의되지 않은 필드가 있다면, 해당 필드는 현재 업데이트 대상이 아니거나 정책적으로 업데이트되지 않는 필드라고 간주할 수 있습니다.</p><h3><span id=\"테스트-코드-예시\">테스트 코드 예시</span></h3><figure class=\"highlight kotlin\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@MongoTestSupport</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MemberRepositoryTest</span></span>(</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">val</span> memberRepository: MemberRepository</span><br><span class=\"line\">) : MongoStudyApplicationTests() &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Test</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">fun</span> `updateName test`<span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// given</span></span><br><span class=\"line\">        <span class=\"keyword\">val</span> members = (<span class=\"number\">1.</span><span class=\"number\">.20</span>).map &#123;</span><br><span class=\"line\">            Member(</span><br><span class=\"line\">                name = <span class=\"string\">\"name\"</span>,</span><br><span class=\"line\">                ...</span><br><span class=\"line\">            )</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">val</span> targets = mongoTemplate</span><br><span class=\"line\">            .insertAll(members).map &#123;</span><br><span class=\"line\">                MemberQueryForm.UpdateName(</span><br><span class=\"line\">                    id = it.id!!,</span><br><span class=\"line\">                    name = <span class=\"string\">\"newName\"</span></span><br><span class=\"line\">                )</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// when</span></span><br><span class=\"line\">        memberRepository.updateName(targets)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// then</span></span><br><span class=\"line\">        <span class=\"keyword\">val</span> results = mongoTemplate.findAll&lt;Member&gt;()</span><br><span class=\"line\"></span><br><span class=\"line\">        then(results).hasSize(<span class=\"number\">20</span>)</span><br><span class=\"line\">        then(results).allSatisfy &#123;</span><br><span class=\"line\">            then(it.name).isEqualTo(<span class=\"string\">\"newName\"</span>)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><p>해당 테스트 코드는 <code>MemberRepository</code>의 <code>updateName</code> 메서드를 검증합니다.</p><ol><li>먼저 <code>Member</code> 객체를 생성하고 MongoDB에 저장한 뒤, 저장된 데이터를 조회하여 <code>UpdateName</code> 객체를 생성합니다.</li><li>이후 <code>updateName</code> 메서드를 호출하여 업데이트를 수행합니다.</li><li>마지막으로 MongoDB에서 데이터를 다시 조회해, 업데이트가 성공적으로 이루어졌는지 확인합니다.</li></ol><p>이처럼 <code>MemberQueryForm</code> 객체를 사용해 업데이트 대상 필드를 명확히 정의함으로써, 변경 작업의 범위를 명확히 관리하고 추적할 수 있습니다. 테스트 코드 역시 이러한 명확성을 기반으로 업데이트 로직을 확인하도록 작성되었습니다.</p><h2><span id=\"정리\">정리</span></h2><p>제가 담당하는 도메인은 특정 필드마다 업데이트 권한이 다르게 설정되어 있어, 업데이트 필드를 보다 명확하고 엄격하게 관리해야 하는 상황입니다. 또한, 대량의 데이터를 처리해야 하며, 빠른 처리를 보장해야 하는 요구사항도 있습니다. 이러한 이유로, 위에서 설명한 방식의 업데이트 전략을 선택했습니다. 각자의 상황과 요구사항에 맞는 적절한 방법을 선택하는 것이 가장 중요합니다.</p>",
        "contentSnippet": "Spring Data MongoDB를 활용한 애플리케이션 개발 과정에서, 데이터를 업데이트하는 방법은 프로젝트의 설계와 성능에 큰 영향을 미칩니다. 특히, mongoRepository.save, mongoTemplate.save, 그리고 mongoTemplate.updateFirst와 같은 메서드들은 각각의 특성과 적합한 상황이 다릅니다. 이 글에서는 Spring Data MongoDB에서 업데이트 전략을 중심으로 개발 경험에서 얻은 인사이트를 공유하며, 각 메서드의 동작 방식과 적절한 사용 방법에 대해 논의합니다.\nUpdate 메서드 비교\nSpring Data MongoDB에서 사용되는 주요 업데이트 메서드들은 아래와 같이 동작 방식과 적합한 시나리오에서 차이가 있습니다:\n\n특징mongoRepository.savemongoTemplate.savemongoTemplate.updateFirst\n\n작업 대상단일 문서단일 문서단일 문서\n저장 방식변경된 필드만 업데이트전체 문서 교체변경된 필드만 업데이트\n문서가 없을 경우새로 삽입새로 삽입기본적으로 아무 작업도 수행하지 않음\n업데이트 범위필드 단위전체 문서필드 단위\n조건 지정_id 기준_id 기준사용자 정의 쿼리\nSpring Data 통합페이징, 정렬 등 지원미지원미지원\n적합한 상황간단한 CRUD 작업전체 문서 교체 또는 삽입조건에 맞는 단일 문서 필드 수정\n\nmongoTemplate.save\n문서 전체 교체(Replace)를 수행합니다.\n동작 방식\n\n_id 필드를 기준으로 MongoDB에서 문서를 검색.\n문서가 존재하면 전체 문서를 교체합니다.\n문서가 존재하지 않으면 새로 삽입합니다.\n저장 객체에 없는 필드는 기존 문서에서 삭제됩니다.\n\n예제\n\n\n1\n2\n\nval user = User(id = \"123\", name = \"John Doe\", age = 30)\nmongoTemplate.save(user)\n\n\n결과\n\n기존 문서: { \"_id\": \"123\", \"name\": \"Alice\", \"age\": 25, \"email\": \"alice@example.com\" }\n업데이트 후: { \"_id\": \"123\", \"name\": \"John Doe\", \"age\": 30 }\n변경 사항: email 필드가 삭제됨.\n\nmongoRepository.save\n문서의 일부 필드만 업데이트(Partial Update)를 수행합니다.\n동작 방식\n\n_id 필드를 기준으로 MongoDB에서 문서를 검색.\n문서가 존재하면 변경된 필드만 업데이트하고, 나머지 필드는 유지됩니다.\n문서가 존재하지 않으면 새로 삽입합니다.\n\n예제\n\n\n1\n2\n\nval user = User(id = \"123\", name = \"John Doe\")\nuserRepository.save(user)\n\n\n결과\n\n기존 문서: { \"_id\": \"123\", \"name\": \"Alice\", \"age\": 25, \"email\": \"alice@example.com\" }\n업데이트 후: { \"_id\": \"123\", \"name\": \"John Doe\", \"age\": 25, \"email\": \"alice@example.com\" }\n변경 사항: name 필드만 업데이트, 나머지 필드는 유지됨.\n\nmongoTemplate.updateFirst\nMongoDB의 updateFirst 명령어를 실행하여 단일 문서를 부분 업데이트합니다.\n동작 방식\n\n조건을 지정하여 MongoDB에서 문서를 검색.\n첫 번째로 매칭된 문서의 일부 필드만 업데이트합니다.\n문서가 존재하지 않으면 기본적으로 아무 작업도 수행하지 않습니다(삽입하지 않음).\n$set과 같은 MongoDB 연산자를 사용하여 지정된 필드만 업데이트합니다.\n\n예제\n\n\n1\n2\n3\n\nval query = Query(Criteria.where(\"name\").`is`(\"Alice\"))\nval update = Update().set(\"age\", 30)\nmongoTemplate.updateFirst(query, update, User::class.java)\n\n\n결과\n\n기존 문서: { \"_id\": \"123\", \"name\": \"Alice\", \"age\": 25, \"email\": \"alice@example.com\" }\n업데이트 후: { \"_id\": \"123\", \"name\": \"Alice\", \"age\": 30, \"email\": \"alice@example.com\" }\n변경 사항: age 필드만 업데이트, 나머지 필드는 유지됨.\n\n효율적인 MongoDB 업데이트 전략\nmongoTemplate.save는 문서 전체를 교체하기 때문에 일반적인 경우에는 거의 사용되지 않습니다. 반면, mongoRepository.save는 더 직관적이며, 특히 Spring Data JPA 경험이 있는 개발자에게는 익숙하고 이해하기 쉬운 방식입니다. 그럼에도 불구하고, 저는 업데이트 작업에 mongoTemplate기반의 업데이트만을 사용하고 있습니다. 그 이유는 다음과 같습니다.\n대량 처리에서의 성능 차이\nMongoDB Update 성능 측정 및 분석에서 업데이트 성능을 측정한 결과를 참고할 수 있습니다.\n\n\nRowssaveAllupdateFirstbulkOps (UNORDERED)bulkOps (ORDERED)\n\n1001,052 ms1,176 ms46 ms79 ms\n2002,304 ms2,196 ms103 ms124 ms\n5005,658 ms5,250 ms309 ms257 ms\n1,00011,106 ms10,846 ms418 ms412 ms\n2,00022,592 ms21,427 ms1,060 ms1,004 ms\n5,00054,407 ms52,075 ms2,663 ms2,292 ms\n10,000107,651 ms110,884 ms4,514 ms4,496 ms\n\n대량 처리를 할 경우 saveAll 방식은 내부적으로 반복문을 돌면서 save를 호출하는 방식으로 동작합니다. 이는 데이터베이스 요청을 문서별로 각각 보내기 때문에, 대량 처리 시 성능이 크게 저하됩니다. saveAll과 updateFirst는 모두 문서 단위로 데이터베이스 요청을 반복 호출하기 때문에 처리 성능이 거의 비슷하지만, 요청 수가 많아질수록 응답 시간이 급격히 증가하는 문제가 발생합니다.\n반면, bulkOps는 여러 업데이트 작업을 한 번의 연산으로 묶어서 실행하므로 대량 처리에서 훨씬 효율적입니다. 이를 통해 처리 시간을 크게 단축할 수 있지만, save와 saveAll 방식으로는 bulkOps를 활용할 수 없다는 한계가 있습니다. 이러한 이유로 저는 대량 처리 작업에서 updateFirst와 함께 bulkOps를 활용하는 방식을 선호합니다.\n또한, 대량 데이터를 업데이트할 때 where in 절을 활용하면 효과적입니다. 이 경우, mongoTemplate.updateMulti를 사용하면 bulkOps 방식과 유사한 성능을 얻을 수 있습니다. saveAll을 사용하면 성능이 급격히 저하되므로, 대량 데이터를 업데이트할 때는 반드시 mongoTemplate을 사용하는 것이 좋습니다. 이러한 접근 방식은 대량 처리의 효율성과 성능 최적화를 보장하며, 대량 데이터를 다루는 애플리케이션에서 더욱 유용합니다.\n명확한 변경 사항 추적\nmongoRepository.save를 사용하여 데이터를 업데이트할 경우, 정확히 어떤 필드가 변경되었는지 추적하기 어렵습니다. MongoDB는 비정형 데이터베이스로, 다양한 필드와 그 필드들이 다루는 컨텍스트가 매우 다양합니다. 이런 상황에서 mongoRepository.save를 통해 업데이트가 이루어지면, 어떤 필드가 어떤 조건에서 업데이트되었는지 명확히 파악하기 어렵기 때문에 데이터 변경 사항을 추적하고 관리하는 데 어려움이 발생할 수 있습니다.\n반면, mongoTemplate을 기반으로 업데이트 쿼리를 작성하면 특정 필드에 대해 명확히 정의된 업데이트를 수행할 수 있습니다. 각 업데이트가 어디에서 이루어졌는지, 어떤 필드가 변경되었는지를 코드 레벨에서 명확히 확인할 수 있어 추적이 용이합니다. 특히 프로젝트가 복잡해지거나 엄격한 변경 관리가 요구될수록, 이러한 명확성은 유지보수와 협업 측면에서 큰 장점으로 작용합니다. 이를 통해 데이터 업데이트의 불확실성을 줄이고, 코드의 가독성과 신뢰성을 높일 수 있습니다.\n실제 사용 예시\nDocument 정의\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n@Document(collection = \"members\")\nclass Member(\n    @Field(name = \"name\")\n    val name: String,\n\n    @Field(name = \"address\")\n    val address: Address,\n\n    @Field(name = \"member_id\")\n    val memberId: String,\n\n    @Field(name = \"email\")\n    val email: String,\n\n    @Field(name = \"status\")\n    val status: MemberStatus\n) : Auditable()\n\n\n위 예시와 같이 Member 도큐먼트가 정의되어 있다고 가정하겠습니다. 이 도큐먼트는 MongoRepository를 사용하여 업데이트하지 않기 때문에, 필드들이 val로 지정되어 있습니다. 필드를 val로 지정하면 도큐먼트의 특정 필드를 변경하기 위해 객체를 직접 수정한 뒤 save를 호출하는 방식이 불가능합니다. 이렇게 필드를 val로 지정하면 도큐먼트의 불변성을 보장하며, 특정 필드의 변경을 엄격히 관리할 수 있습니다.\nRepository 정의\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\ninterface MemberRepository : MongoRepository<Member, ObjectId>, MemberCustomRepository\n\ninterface MemberCustomRepository {\n    fun updateName(targets: List<MemberQueryForm.UpdateName>)\n}\n\nclass MemberCustomRepositoryImpl(mongoTemplate: MongoTemplate) : MemberCustomRepository, MongoCustomRepositorySupport<Member>(Member::class.java, mongoTemplate) {\n\n    override fun updateName(targets: List<MemberQueryForm.UpdateName>) {\n        bulkUpdate(\n            targets.map {\n                Pair(\n                    { Query(Criteria.where(\"id\").`is`(it.id)) },\n                    { Update().set(\"name\", it.name) }\n                )\n            }\n        )\n    }\n}\n\n\nMongoCustomRepositorySupport를 상속받아 bulkUpdate 메서드를 통해 bulkOps를 사용한 대량 업데이트를 수행합니다. 이를 활용하면 대량 데이터를 효율적으로 처리할 수 있으며, 단일 업데이트만 필요한 경우 updateFirst를 사용하여 업데이트를 수행할 수도 있습니다. 그러나 특별한 이유가 없다면 MongoCustomRepositorySupport 기반으로 대량 업데이트를 지원하는 bulkUpdate를 사용하는 것을 권장합니다.\n이 방식에 대한 자세한 구현 방법은 이전 포스팅 MongoDB Update 성능 측정 및 분석 - MongoCustomRepositorySupport을 통한 bulkOps 기능 제공에서 확인할 수 있습니다.\n업데이트 쿼리에 사용할 객체 정의\n\n\n1\n2\n3\n4\n5\n6\n\nobject MemberQueryForm {\n    data class UpdateName(\n        val id: ObjectId,\n        val name: String\n    )\n}\n\n\nMemberQueryForm 객체를 정의하여 쿼리에 필요한 필드와 데이터를 명확하게 관리합니다. 이를 통해 업데이트 작업에서 어떤 필드가 업데이트되는지 명확히 파악할 수 있습니다. 만약 MemberQueryForm에 정의되지 않은 필드가 있다면, 해당 필드는 현재 업데이트 대상이 아니거나 정책적으로 업데이트되지 않는 필드라고 간주할 수 있습니다.\n테스트 코드 예시\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n@MongoTestSupport\nclass MemberRepositoryTest(\n    private val memberRepository: MemberRepository\n) : MongoStudyApplicationTests() {\n\n    @Test\n    fun `updateName test`() {\n        // given\n        val members = (1..20).map {\n            Member(\n                name = \"name\",\n                ...\n            )\n        }\n\n        val targets = mongoTemplate\n            .insertAll(members).map {\n                MemberQueryForm.UpdateName(\n                    id = it.id!!,\n                    name = \"newName\"\n                )\n            }\n\n        // when\n        memberRepository.updateName(targets)\n\n        // then\n        val results = mongoTemplate.findAll<Member>()\n\n        then(results).hasSize(20)\n        then(results).allSatisfy {\n            then(it.name).isEqualTo(\"newName\")\n        }\n    }\n}\n\n\n해당 테스트 코드는 MemberRepository의 updateName 메서드를 검증합니다.\n\n먼저 Member 객체를 생성하고 MongoDB에 저장한 뒤, 저장된 데이터를 조회하여 UpdateName 객체를 생성합니다.\n이후 updateName 메서드를 호출하여 업데이트를 수행합니다.\n마지막으로 MongoDB에서 데이터를 다시 조회해, 업데이트가 성공적으로 이루어졌는지 확인합니다.\n\n이처럼 MemberQueryForm 객체를 사용해 업데이트 대상 필드를 명확히 정의함으로써, 변경 작업의 범위를 명확히 관리하고 추적할 수 있습니다. 테스트 코드 역시 이러한 명확성을 기반으로 업데이트 로직을 확인하도록 작성되었습니다.\n정리\n제가 담당하는 도메인은 특정 필드마다 업데이트 권한이 다르게 설정되어 있어, 업데이트 필드를 보다 명확하고 엄격하게 관리해야 하는 상황입니다. 또한, 대량의 데이터를 처리해야 하며, 빠른 처리를 보장해야 하는 요구사항도 있습니다. 이러한 이유로, 위에서 설명한 방식의 업데이트 전략을 선택했습니다. 각자의 상황과 요구사항에 맞는 적절한 방법을 선택하는 것이 가장 중요합니다.",
        "summary": "\n    \n      \n      \n        <p>Spring Data MongoDB를 활용한 애플리케이션 개발 과정에서, 데이터를 업데이트하는 방법은 프로젝트의 설계와 성능에 큰 영향을 미칩니다. 특히, <code>mongoRepository.save</code>, <code>mongoTemp\n      \n    \n    ",
        "id": "https://cheese10yun.github.io/spring-data-mongo-update-guide-1/",
        "isoDate": "2025-01-18T14:24:07.000Z"
      }
    ]
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": [
      {
        "creator": "강철 벼룩",
        "title": "ARM 템플릿을 사용한 인프라 배포 시 만날 수 있는 오류",
        "link": "http://www.dokyun.pe.kr/352",
        "pubDate": "Sun, 19 Jan 2025 00:24:40 +0900",
        "author": "강철 벼룩",
        "comments": "http://www.dokyun.pe.kr/352#entry352comment",
        "content": "<h3 data-ke-size=\"size23\">Errors&nbsp;you&nbsp;may&nbsp;encounter&nbsp;when&nbsp;deploying&nbsp;infrastructure&nbsp;with&nbsp;ARM&nbsp;templates</h3>\n<p data-ke-size=\"size18\">기존 가상 네트워크를 업데이트하는 update-vnet.json 이라는 ARM 템플릿을 작성했다.</p>\n<p data-ke-size=\"size18\">다음의 Azure Cli 스크립트를 통해 이 템플릿을 적용했다.</p>\n<pre id=\"code_1737212932841\" class=\"bash\" data-ke-language=\"bash\" data-ke-type=\"codeblock\"><code>az deployment group create --resource-group $rgName --name UpdateVNet --template-file .\\update-vnet.json</code></pre>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">이 스크립트 실행 중에 다음과 같은 오류를 만났다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"876\" data-origin-height=\"231\"><span data-url=\"https://blog.kakaocdn.net/dn/Ccycb/btsLTGNKVJ8/qAMKIg1ETkf2is9WBxss6k/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Ccycb/btsLTGNKVJ8/qAMKIg1ETkf2is9WBxss6k/img.png\"><img src=\"https://blog.kakaocdn.net/dn/Ccycb/btsLTGNKVJ8/qAMKIg1ETkf2is9WBxss6k/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FCcycb%2FbtsLTGNKVJ8%2FqAMKIg1ETkf2is9WBxss6k%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"876\" height=\"231\" data-origin-width=\"876\" data-origin-height=\"231\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">이 오류에서 사각형 박스 내의 문구가 문제를 해결하는 단서다.</p>\n<p data-ke-size=\"size18\">현재 구독과 리소스 그룹에서 진행 중인 배포는 없었으며, 진행 완료된 기존 배포는 성공 상태로 종료한 것으로 확인했다. 혹시나 해서 구독과 리소스 그룹의 배포 섹션에 나열된 모든 배포를 제거하고 다시 시도해보아도 동일한 문제가 발생했다.</p>\n<p data-ke-size=\"size18\">잠깐 생각을 하다가 떠오른 부분은 현재 배포하는 ARM 템플릿의 배포 이름의 고유성으로 인한 문제인가 싶었다. 그래서 <b><span style=\"color: #006dd7;\"><u>다음 그림의 사각형 박스를&nbsp; 기존의 평이한 배포 이름인 \"UpdateVnet\"을 고유한 이름으로 변경하고 다시 템플릿을 적용했을 때 비로소 문제가 해결 되었다.</u></span></b></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"994\" data-origin-height=\"580\"><span data-url=\"https://blog.kakaocdn.net/dn/cn7Dah/btsLSdM4Mwx/KmjeWkczrwagT3GXtrj0u1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cn7Dah/btsLSdM4Mwx/KmjeWkczrwagT3GXtrj0u1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cn7Dah/btsLSdM4Mwx/KmjeWkczrwagT3GXtrj0u1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fcn7Dah%2FbtsLSdM4Mwx%2FKmjeWkczrwagT3GXtrj0u1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"994\" height=\"580\" data-origin-width=\"994\" data-origin-height=\"580\"/></span></figure>\n</p>\n<p data-ke-size=\"size18\">&nbsp;</p>\n<p data-ke-size=\"size18\">이 외에도 내 구독이나 리소스 그룹에서 실제 배포중인 상태라면&nbsp; 배포 완료나 실패를 기다리거나, 진행 중인 다른 배포를 취소하고 다시 배포를 시도할 수 있다.</p>",
        "contentSnippet": "Errors you may encounter when deploying infrastructure with ARM templates\n기존 가상 네트워크를 업데이트하는 update-vnet.json 이라는 ARM 템플릿을 작성했다.\n다음의 Azure Cli 스크립트를 통해 이 템플릿을 적용했다.\naz deployment group create --resource-group $rgName --name UpdateVNet --template-file .\\update-vnet.json\n \n이 스크립트 실행 중에 다음과 같은 오류를 만났다.\n\n\n \n이 오류에서 사각형 박스 내의 문구가 문제를 해결하는 단서다.\n현재 구독과 리소스 그룹에서 진행 중인 배포는 없었으며, 진행 완료된 기존 배포는 성공 상태로 종료한 것으로 확인했다. 혹시나 해서 구독과 리소스 그룹의 배포 섹션에 나열된 모든 배포를 제거하고 다시 시도해보아도 동일한 문제가 발생했다.\n잠깐 생각을 하다가 떠오른 부분은 현재 배포하는 ARM 템플릿의 배포 이름의 고유성으로 인한 문제인가 싶었다. 그래서 다음 그림의 사각형 박스를  기존의 평이한 배포 이름인 \"UpdateVnet\"을 고유한 이름으로 변경하고 다시 템플릿을 적용했을 때 비로소 문제가 해결 되었다.\n\n\n \n이 외에도 내 구독이나 리소스 그룹에서 실제 배포중인 상태라면  배포 완료나 실패를 기다리거나, 진행 중인 다른 배포를 취소하고 다시 배포를 시도할 수 있다.",
        "guid": "http://www.dokyun.pe.kr/352",
        "categories": [
          "Azure &amp; Windows/Azure",
          "ARM",
          "azure",
          "IAC"
        ],
        "isoDate": "2025-01-18T15:24:40.000Z"
      }
    ]
  },
  {
    "name": "김상훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": [
      {
        "title": "리눅스 컴플렉스",
        "link": "https://elky84.github.io/2025/01/19/linux_complex/",
        "pubDate": "Sun, 19 Jan 2025 00:00:00 +0000",
        "content": "<h1 id=\"개요\">개요</h1>\n<p>나는 게임 클라이언트 프로그래머 지망생이었다.</p>\n\n<p>그리고 첫 취업을 한 2005년 당시에는 당연하게도 윈도우를 썼고, 윈도우용 게임을 개발해야 했으며, 클라이언트다 보니 당시 서버가 (당시엔 당연한 줄 알았지만 보기 드문)리눅스용 소켓서버였음에도 나는 윈도우만 썼다.</p>\n\n<p>그리고 그게 전혀 이상하지 않았다.</p>\n\n<p>나에게 리눅스란 먼 존재였다.</p>\n\n<p>내가 직접 게임 서버를 개발한 시기에는 리눅스 서버가 아닌 윈도우 게임 서버를 썼기에, 리눅스를 잘 써야 할 상황은 없었다.</p>\n\n<p>2014년까지의 나에게 리눅스는 먼 존재였고, 책에서 읽으면 리눅스에 대한 호기심이 생기긴 했지만, 업무에서 쓸 확률이 낮은 OS를 가볍게 쓰는 것 이외에는 하기 어려웠고, 파고들기엔 다른 중요한 것들이 너무나 많았다.</p>\n\n<h1 id=\"컴플렉스\">컴플렉스</h1>\n\n<p>나는 게임에서도 관심가는 게임이라면 찍먹이라도 해봐야 하는 성향이다.</p>\n\n<p>현실적 이슈로 못할 지언정, 성향적으로 그렇다보니 리눅스에 대해 분명히 관심이 생겼는데 이를 해소하지 못한 불편함이 마음 한켠에 존재했다.</p>\n\n<p>특히 IT 관련 서적을 읽을 때 마다, 해킹 관련 서적은 물론이고, 다양한 기술 서적의 실습에서도 제약이 따르는 기분을 지울 수가 없었다.</p>\n\n<p>또한 리눅스와 유닉스의 그 문화를 공감하지 못한다는 것이 더욱 큰 아쉬움이자 불편한 마음을 만들었다.</p>\n\n<h1 id=\"해소\">해소</h1>\n\n<p>2015년 즈음 나는 루비 온 레일즈로 리눅스 환경에서 서비스를 배포하고, 처음으로 웹 서버로 게임을 서비스하게 됐다. 물론 게임 서버로써였고, API 서버에 가까웠으며, 나의 많은 업무 시간은 유니티 클라이언트 개발도 하다보니 리눅스 이해도가 높아지진 않았따.</p>\n\n<p>2년여가 더 지낫 결국 여러가지 이유가 복합적이었지만 나는 플랫폼 개발자로 전향해보기로 했고, 마침 그 회사가 당시 트래픽이 많던 넷마블이었고, 심지어 그 부서가 Private Cloud를 개발하는 부서라서 인프라를 제공하는 과정에서 다양한 팀의 리눅스 환경 구성을 돕게 됐고, 이로 인해 나 역시 자연스레 리눅스 이해도가 극적으로 높아졌다.</p>\n\n<p>메인 데스크탑은 여전히 윈도우였지만, 적어도 리눅스 서버에서 하게 되는 수 많은 작업이 나에게 리눅스 이해도를 높여줬다.</p>\n\n<p>특히 당시만 해도 Docker가 활성화되기 전이라, daemonize와 배포 및 가동에 골치를 썩었는데 이러한 과정 역시 나에게 리눅스 이해도를 높여주게 됐다.</p>\n\n<p>이 시기 쯤해서 홈 서버를 리눅스로 바꾸기 시작했다.</p>\n\n<p>중간에 라즈베리 파이로 홈서버를 쓰기도 했으나 너무 저성능이라 결국 미니 PC로 바꾸긴 했지만, 라즈베리 파이 역시 리눅스를 깔아서 썼다.</p>\n\n<p>여러 이슈를 겪으면서 막연한 두려움은 사라지고 훨씬 더 익숙해져서 나에게 서버는 리눅스가 더 익숙해지기까지 했는데, 이 과정으로 오는 과정에 리눅스 데스크탑 강제로 써보기, 맥만 쓰기 운동 등을 통해서 익숙하지 않은 환경을 강제화 하는 것도 크게 도움이 됐다.</p>\n\n<h1 id=\"마치며\">마치며</h1>\n\n<p>리눅스는 나에게 있어 컴플렉스가 아니게 됐는데, 아마도 그렇게 된 시점이 내가 순혈 게임 개발자로 남는 길 보다, 다재다능한 제너럴 리스트가 되기로 마음 먹고, 노력하는 과정에서 극복 된 것 같다.</p>\n\n<p>이미 익숙하고, 많은 경험을 쌓은 환경을 선호하는 것은 나 역시 마찬가지 였고, 배우는 것 까지는 좋아하는 개발자가 많지만, 익숙하지 않은 환경에서 낮은 퍼포먼스가 날 때의 저항감을 이겨내는 것이 쉽지 않은데, 나는 이 과정을 전향과, 집에서의 Dev Toy와 학습, 회사에서도 가능한 상황에선 강제로 OS를 바꿔서 사용해보며 극복하고자 했었다.</p>\n\n<p>순혈 게임 서버 개발자는 평생 윈도우 게임 서버만으로 서비스 할 수도 있는데, 그러한 개발자가 어떻게 리눅스와 리눅스 서버에 익숙해졌는지 가볍게 이야기 해보고 싶었다.</p>\n",
        "contentSnippet": "개요\n나는 게임 클라이언트 프로그래머 지망생이었다.\n그리고 첫 취업을 한 2005년 당시에는 당연하게도 윈도우를 썼고, 윈도우용 게임을 개발해야 했으며, 클라이언트다 보니 당시 서버가 (당시엔 당연한 줄 알았지만 보기 드문)리눅스용 소켓서버였음에도 나는 윈도우만 썼다.\n그리고 그게 전혀 이상하지 않았다.\n나에게 리눅스란 먼 존재였다.\n내가 직접 게임 서버를 개발한 시기에는 리눅스 서버가 아닌 윈도우 게임 서버를 썼기에, 리눅스를 잘 써야 할 상황은 없었다.\n2014년까지의 나에게 리눅스는 먼 존재였고, 책에서 읽으면 리눅스에 대한 호기심이 생기긴 했지만, 업무에서 쓸 확률이 낮은 OS를 가볍게 쓰는 것 이외에는 하기 어려웠고, 파고들기엔 다른 중요한 것들이 너무나 많았다.\n컴플렉스\n나는 게임에서도 관심가는 게임이라면 찍먹이라도 해봐야 하는 성향이다.\n현실적 이슈로 못할 지언정, 성향적으로 그렇다보니 리눅스에 대해 분명히 관심이 생겼는데 이를 해소하지 못한 불편함이 마음 한켠에 존재했다.\n특히 IT 관련 서적을 읽을 때 마다, 해킹 관련 서적은 물론이고, 다양한 기술 서적의 실습에서도 제약이 따르는 기분을 지울 수가 없었다.\n또한 리눅스와 유닉스의 그 문화를 공감하지 못한다는 것이 더욱 큰 아쉬움이자 불편한 마음을 만들었다.\n해소\n2015년 즈음 나는 루비 온 레일즈로 리눅스 환경에서 서비스를 배포하고, 처음으로 웹 서버로 게임을 서비스하게 됐다. 물론 게임 서버로써였고, API 서버에 가까웠으며, 나의 많은 업무 시간은 유니티 클라이언트 개발도 하다보니 리눅스 이해도가 높아지진 않았따.\n2년여가 더 지낫 결국 여러가지 이유가 복합적이었지만 나는 플랫폼 개발자로 전향해보기로 했고, 마침 그 회사가 당시 트래픽이 많던 넷마블이었고, 심지어 그 부서가 Private Cloud를 개발하는 부서라서 인프라를 제공하는 과정에서 다양한 팀의 리눅스 환경 구성을 돕게 됐고, 이로 인해 나 역시 자연스레 리눅스 이해도가 극적으로 높아졌다.\n메인 데스크탑은 여전히 윈도우였지만, 적어도 리눅스 서버에서 하게 되는 수 많은 작업이 나에게 리눅스 이해도를 높여줬다.\n특히 당시만 해도 Docker가 활성화되기 전이라, daemonize와 배포 및 가동에 골치를 썩었는데 이러한 과정 역시 나에게 리눅스 이해도를 높여주게 됐다.\n이 시기 쯤해서 홈 서버를 리눅스로 바꾸기 시작했다.\n중간에 라즈베리 파이로 홈서버를 쓰기도 했으나 너무 저성능이라 결국 미니 PC로 바꾸긴 했지만, 라즈베리 파이 역시 리눅스를 깔아서 썼다.\n여러 이슈를 겪으면서 막연한 두려움은 사라지고 훨씬 더 익숙해져서 나에게 서버는 리눅스가 더 익숙해지기까지 했는데, 이 과정으로 오는 과정에 리눅스 데스크탑 강제로 써보기, 맥만 쓰기 운동 등을 통해서 익숙하지 않은 환경을 강제화 하는 것도 크게 도움이 됐다.\n마치며\n리눅스는 나에게 있어 컴플렉스가 아니게 됐는데, 아마도 그렇게 된 시점이 내가 순혈 게임 개발자로 남는 길 보다, 다재다능한 제너럴 리스트가 되기로 마음 먹고, 노력하는 과정에서 극복 된 것 같다.\n이미 익숙하고, 많은 경험을 쌓은 환경을 선호하는 것은 나 역시 마찬가지 였고, 배우는 것 까지는 좋아하는 개발자가 많지만, 익숙하지 않은 환경에서 낮은 퍼포먼스가 날 때의 저항감을 이겨내는 것이 쉽지 않은데, 나는 이 과정을 전향과, 집에서의 Dev Toy와 학습, 회사에서도 가능한 상황에선 강제로 OS를 바꿔서 사용해보며 극복하고자 했었다.\n순혈 게임 서버 개발자는 평생 윈도우 게임 서버만으로 서비스 할 수도 있는데, 그러한 개발자가 어떻게 리눅스와 리눅스 서버에 익숙해졌는지 가볍게 이야기 해보고 싶었다.",
        "guid": "https://elky84.github.io/2025/01/19/linux_complex/",
        "categories": [
          "Windows",
          "Linux",
          "OS",
          "OS"
        ],
        "isoDate": "2025-01-19T00:00:00.000Z"
      },
      {
        "title": "윈도우도 훌륭한 개발머신이라구",
        "link": "https://elky84.github.io/2025/01/18/good_dev_os_windows/",
        "pubDate": "Sat, 18 Jan 2025 00:00:00 +0000",
        "content": "<h1 id=\"개요\">개요</h1>\n\n<p>한국에서 많은 웹이나 앱 개발자의 많은 수가 맥을 선택하고 있다.</p>\n\n<p>나 역시 2018년 이후 맥을 병행해서 쓰고 있고, 특정한 시기에는 온리 맥도 썼던 입장에서 맥의 장점도 이해하고 공감하는 부분이 있다.</p>\n\n<p>특히 인텔 맥 때의 애매함을 이겨낸 애플 실리콘 칩 이후의 맥은 ARM 데스크탑의 시대를 열었고 그 만족도는 나 역시 체감하고 있다.</p>\n\n<p>M1 맥북 에어는 교체의 필요성을 못느낄 만큼 만족하고 있고, 특히 여행이나 집 안에서 가벼운 코딩이나, 타이핑에서 아주 잘 쓰고 있다.</p>\n\n<p>개인적으로 오래 써오던 리눅스 미니 데스크탑도 맥미니로 교체하고 싶을 정도니 말이다.</p>\n\n<p>나는 게임 개발자로써 살아온 커리어도 길고, 게이머로써의 아이덴티티도 강하다 보니 윈도우가 좋은 측면이 있다.</p>\n\n<p>하지만 개발에서 아쉬움이 있었다면 윈도우를 메인 데스크탑으로 쓸 이유가 없는 상황이다.</p>\n\n<p>이미 맥북만 써서 개발했던 기간도 5년이었고, 맥과 윈도우 (+WSL), 리눅스 데스크탑 OS (노트북으로) 사용한지도 8년이 넘었는데, 사실 어떤 OS를 써도 크게 이질감이 들지 않게 적응한 상황이기 때문이다.</p>\n\n<p>이렇게 다 사용해본 입장에서 종종 나오는 논란에 대해서 이야기해보고자 한다.</p>\n\n<h1 id=\"논란\">논란</h1>\n\n<h2 id=\"맥은-리눅스가-아니다\">맥은 리눅스가 아니다</h2>\n<p>종종 리눅스 서버 개발에 친화적이라는 이야기를 하는 사람을 자주 본다.</p>\n\n<p>맥은 Darwin 커널 기반의 별개의 OS지 리눅스가 아니다.</p>\n\n<p>리눅스 개발 환경과 유사한 점은 유닉스 라이크라고 보는 것이 맞고, 이로 인해 꽤 많은 차이가 나서 동일한 동작을 보장하지 않는다.</p>\n\n<h2 id=\"wsl2\">WSL2</h2>\n\n<p><strong>WSL(Windows Subsystem for Linux)</strong> 은 리눅스 호환률이 macOS보다 더 높은 편이다.</p>\n\n<p>이는 WSL의 구조와 설계 방식이 리눅스와 직접적인데, WSL2는 리눅스 커널을 실제로 실행한다.</p>\n\n<p>WSL1은 에뮬레이션 방식 이었지만, WSL2는 커널이다 커널.</p>\n\n<p>당연히 훨씬 더 높은 호환성을 보여준다.</p>\n<h2 id=\"리눅스-데스크탑은-어때\">리눅스 데스크탑은 어때?</h2>\n\n<p>리눅스 데스크탑을 쓰면 여러가지 지식이 늘어난다.</p>\n\n<p>각종 오류 (…) 발생 시 커맨드 라인 명령어를 써서 해결 해야 되는 상황들, 그리고 부족한 레퍼런스, 정식으로 지원되지 않은 수많은 앱 (다수의 앱이 윈도우나 맥 온리 또는 윈도우와 맥을 지원한다)이 개발자로써의 나를 강하게 성장시켜준다. (강해지고 싶다면 오라)</p>\n\n<h1 id=\"마치며\">마치며</h1>\n\n<p>조만간 리눅스 이야기를 좀 더 하게 되겠지만, 개인적으로 리눅스에 익숙해진 뒤에도 여전히 윈도우를 쓰는 이유에 게임이 무관하지 않다.</p>\n\n<p>다만 콘솔 켜듯이 충분히 윈도우도 스위칭해서 쓸 수 있음에도 개발 머신으로도 쓰는 것은, 철저히 윈도우가 개발 머신으로 훌륭하기 때문이다.</p>\n\n<p>특히 많은 사람들이 불편을 말하는 포인트 대다수가 WSL2+VS Code를 연동하면 해결되는 이슈이기도하고, 윈도우를 사용하면서 발생되는 문제도 과거에 비하면 매우 줄어들기도 했다.</p>\n\n<p>사실 개인적으로는 지금은 많이 해소 됐지만 m1 맥북 넘어오면서 아키텍쳐 변경으로 인한 호환성 이슈가 꽤 길기도 했고, 그러한 문제 이외에도 나는 리눅스 서버 개발에 더 편한 경험을 못했는데, 감안할만한 수준이라는 점은 나 역시 공감한다.</p>\n\n<p>또한 프론트엔드 개발자라면 맥 OS를 쓰면서 겪는 이슈나 문제가 없을 가능성도 높고 맥의 장점 위주로 체감할 확률이 높다는 것 역시 인정하한다.</p>\n\n<p>다만 맥을 써야만 개발이 편하다는 편견 대신 윈도우가 개발 머신으로 부족하거나 문제가 있는게 아니고 충분한 선택지이며, 리눅스 데스크탑도 쓸만하다는 이야기를 하고 싶었다.</p>\n\n",
        "contentSnippet": "개요\n한국에서 많은 웹이나 앱 개발자의 많은 수가 맥을 선택하고 있다.\n나 역시 2018년 이후 맥을 병행해서 쓰고 있고, 특정한 시기에는 온리 맥도 썼던 입장에서 맥의 장점도 이해하고 공감하는 부분이 있다.\n특히 인텔 맥 때의 애매함을 이겨낸 애플 실리콘 칩 이후의 맥은 ARM 데스크탑의 시대를 열었고 그 만족도는 나 역시 체감하고 있다.\nM1 맥북 에어는 교체의 필요성을 못느낄 만큼 만족하고 있고, 특히 여행이나 집 안에서 가벼운 코딩이나, 타이핑에서 아주 잘 쓰고 있다.\n개인적으로 오래 써오던 리눅스 미니 데스크탑도 맥미니로 교체하고 싶을 정도니 말이다.\n나는 게임 개발자로써 살아온 커리어도 길고, 게이머로써의 아이덴티티도 강하다 보니 윈도우가 좋은 측면이 있다.\n하지만 개발에서 아쉬움이 있었다면 윈도우를 메인 데스크탑으로 쓸 이유가 없는 상황이다.\n이미 맥북만 써서 개발했던 기간도 5년이었고, 맥과 윈도우 (+WSL), 리눅스 데스크탑 OS (노트북으로) 사용한지도 8년이 넘었는데, 사실 어떤 OS를 써도 크게 이질감이 들지 않게 적응한 상황이기 때문이다.\n이렇게 다 사용해본 입장에서 종종 나오는 논란에 대해서 이야기해보고자 한다.\n논란\n맥은 리눅스가 아니다\n종종 리눅스 서버 개발에 친화적이라는 이야기를 하는 사람을 자주 본다.\n맥은 Darwin 커널 기반의 별개의 OS지 리눅스가 아니다.\n리눅스 개발 환경과 유사한 점은 유닉스 라이크라고 보는 것이 맞고, 이로 인해 꽤 많은 차이가 나서 동일한 동작을 보장하지 않는다.\nWSL2\nWSL(Windows Subsystem for Linux) 은 리눅스 호환률이 macOS보다 더 높은 편이다.\n이는 WSL의 구조와 설계 방식이 리눅스와 직접적인데, WSL2는 리눅스 커널을 실제로 실행한다.\nWSL1은 에뮬레이션 방식 이었지만, WSL2는 커널이다 커널.\n당연히 훨씬 더 높은 호환성을 보여준다.\n리눅스 데스크탑은 어때?\n리눅스 데스크탑을 쓰면 여러가지 지식이 늘어난다.\n각종 오류 (…) 발생 시 커맨드 라인 명령어를 써서 해결 해야 되는 상황들, 그리고 부족한 레퍼런스, 정식으로 지원되지 않은 수많은 앱 (다수의 앱이 윈도우나 맥 온리 또는 윈도우와 맥을 지원한다)이 개발자로써의 나를 강하게 성장시켜준다. (강해지고 싶다면 오라)\n마치며\n조만간 리눅스 이야기를 좀 더 하게 되겠지만, 개인적으로 리눅스에 익숙해진 뒤에도 여전히 윈도우를 쓰는 이유에 게임이 무관하지 않다.\n다만 콘솔 켜듯이 충분히 윈도우도 스위칭해서 쓸 수 있음에도 개발 머신으로도 쓰는 것은, 철저히 윈도우가 개발 머신으로 훌륭하기 때문이다.\n특히 많은 사람들이 불편을 말하는 포인트 대다수가 WSL2+VS Code를 연동하면 해결되는 이슈이기도하고, 윈도우를 사용하면서 발생되는 문제도 과거에 비하면 매우 줄어들기도 했다.\n사실 개인적으로는 지금은 많이 해소 됐지만 m1 맥북 넘어오면서 아키텍쳐 변경으로 인한 호환성 이슈가 꽤 길기도 했고, 그러한 문제 이외에도 나는 리눅스 서버 개발에 더 편한 경험을 못했는데, 감안할만한 수준이라는 점은 나 역시 공감한다.\n또한 프론트엔드 개발자라면 맥 OS를 쓰면서 겪는 이슈나 문제가 없을 가능성도 높고 맥의 장점 위주로 체감할 확률이 높다는 것 역시 인정하한다.\n다만 맥을 써야만 개발이 편하다는 편견 대신 윈도우가 개발 머신으로 부족하거나 문제가 있는게 아니고 충분한 선택지이며, 리눅스 데스크탑도 쓸만하다는 이야기를 하고 싶었다.",
        "guid": "https://elky84.github.io/2025/01/18/good_dev_os_windows/",
        "categories": [
          "Windows",
          "Mac",
          "Linux",
          "OS",
          "OS"
        ],
        "isoDate": "2025-01-18T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "Logstash 필터 ruby - 6th",
        "link": "https://kangmyounghun.blogspot.com/2025/01/logstash-ruby-6th.html",
        "pubDate": "2025-01-18T11:49:00.003Z",
        "author": "강명훈",
        "content": "<div>캡쳐그룹 순서번호는 1부터 시작한다.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhGl-5aMV8phuQR0YOOViJkCOnonbpTk6NzLnrtM_5H-P1k-9IxU-w1atWtv20yMfM1L2FjEX0kFuBFaM9R_PlFvpYDnBlV2xe24avBHbE65D_4iizpQQTPEDsVz7ewR2f_XtRi-t6J7I7sAASiWydMfrl7vpO-BsQco4oPrAHoeQxcQbyIc_W_yoUvuvaH/s2027/captures.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"988\" data-original-width=\"2027\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhGl-5aMV8phuQR0YOOViJkCOnonbpTk6NzLnrtM_5H-P1k-9IxU-w1atWtv20yMfM1L2FjEX0kFuBFaM9R_PlFvpYDnBlV2xe24avBHbE65D_4iizpQQTPEDsVz7ewR2f_XtRi-t6J7I7sAASiWydMfrl7vpO-BsQco4oPrAHoeQxcQbyIc_W_yoUvuvaH/s16000/captures.png\" /></a></div><br /><div><span><a name='more'></a></span>첫 번째 순서번호 캡쳐를 위한 ruby 필터</div>\n<div><pre><code><div>ruby {</div><div><span style=\"white-space: normal;\">&nbsp;code =&gt; \"</span></div><div><span style=\"white-space: normal;\">&nbsp; event.set('result', event.get('message').match(/(.).../).captures[1])<span style=\"white-space: pre;\">\t</span></span></div><div><span style=\"white-space: normal;\">&nbsp;\"</span></div><div><span style=\"white-space: normal;\">}</span></div></code></pre></div><div><br /></div>\n<div>캡쳐 실패.</div>\n<div><pre><code><div>[2025-01-18T20:37:14,434][INFO ][logstash.agent&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;] Pipelines running {:count=&gt;1, :running_pipelines=&gt;[:main], :non_running_pipelines=&gt;[]}</div><div>{</div><div>&nbsp; &nbsp; \"message\" =&gt; \"abcd\\r\",</div><div>&nbsp; &nbsp; &nbsp;\"result\" =&gt; nil</div><div>}</div></code></pre></div>\n<div><br /></div>\n<div>왜 안 되지? 전체 문자를 개별 캡쳐해봤다.</div>\n<div><pre><code><div>ruby {</div><div><span style=\"white-space: normal;\">&nbsp;code =&gt; \"</span></div><div><span style=\"white-space: normal;\">&nbsp; event.set('result', event.get('message').match(/(.)(.)(.)(.)/).captures[1])<span style=\"white-space: pre;\">\t</span></span></div><div><span style=\"white-space: normal;\">&nbsp;\"</span></div><div><span style=\"white-space: normal;\">}</span></div></code></pre></div>\n<div><br /></div>\n<div>두 번째 순서번호를 가져오네?</div>\n<div><pre><code><div>[2025-01-18T20:32:47,467][INFO ][logstash.agent&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;] Pipelines running {:count=&gt;1, :running_pipelines=&gt;[:main], :non_running_pipelines=&gt;[]}</div><div>{</div><div>&nbsp; &nbsp; \"message\" =&gt; \"abcd\\r\",</div><div>&nbsp; &nbsp; &nbsp;\"result\" =&gt; \"b\"</div><div>}</div></code></pre></div>\n<div><br /></div>\n<div>순서번호를 빼봤다.</div>\n<div><pre><code><div>ruby {</div><div><span style=\"white-space: normal;\">&nbsp;code =&gt; \"</span></div><div><span style=\"white-space: normal;\">&nbsp; event.set('result', event.get('message').match(/(.)(.)(.)(.)/).captures)<span style=\"white-space: pre;\">\t</span></span></div><div><span style=\"white-space: normal;\">&nbsp;\"</span></div><div><span style=\"white-space: normal;\">}</span></div></code></pre></div>\n<div><pre><code><div>[2025-01-18T20:33:35,432][INFO ][logstash.agent&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;] Pipelines running {:count=&gt;1, :running_pipelines=&gt;[:main], :non_running_pipelines=&gt;[]}</div><div>{</div><div>&nbsp; &nbsp; \"message\" =&gt; \"abcd\\r\",</div><div>&nbsp; &nbsp; &nbsp;\"result\" =&gt; [</div><div>&nbsp; &nbsp; &nbsp; &nbsp; [0] \"a\",</div><div>&nbsp; &nbsp; &nbsp; &nbsp; [1] \"b\",</div><div>&nbsp; &nbsp; &nbsp; &nbsp; [2] \"c\",</div><div>&nbsp; &nbsp; &nbsp; &nbsp; [3] \"d\"</div><div>&nbsp; &nbsp; ]</div><div>}</div></code></pre></div>\n<div><br /></div><div>순서번호가 0부터 시작<span style=\"font-size: x-small;\">(..)</span></div><div><br /></div><div><b style=\"font-family: inherit;\">관련&nbsp;글</b><br /><ul><li><a href=\"https://kangmyounghun.blogspot.com/2025/01/logstash-ruby-5th.html\">Logstash 필터 ruby - 5th</a></li><li><span style=\"font-family: inherit;\"><a href=\"http://kangmyounghun.blogspot.kr/2017/10/logstash-ruby.html\" target=\"\">Logstash 필터 ruby</a></span></li><li><span style=\"font-family: inherit;\"><a href=\"http://kangmyounghun.blogspot.com/2017/06/elasticsearch-grok.html\" target=\"_blank\">Logstash 필터 grok</a></span></li><li><span style=\"font-family: inherit;\"><a href=\"http://kangmyounghun.blogspot.com/2017/07/logstash-mutate.html\" target=\"_blank\">Logstash 필터 mutate</a></span></li><li><span style=\"font-family: inherit;\"><a href=\"http://kangmyounghun.blogspot.kr/2018/02/logstash-geoip.html\" target=\"_blank\">Logstash 필터&nbsp;geoip</a></span></li><li><span style=\"font-family: inherit;\"><a href=\"http://kangmyounghun.blogspot.kr/2018/04/logstash-dissect.html\" target=\"_blank\">Logstash 필터 dissect</a></span></li><li><a href=\"http://kangmyounghun.blogspot.com/2018/09/logstash-kv.html\" target=\"_blank\">Logstash 필터&nbsp;kv</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2019/01/logstash-date.html\" target=\"_blank\">Logstash 필터 date</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2019/02/logstash-translate.html\" target=\"_blank\">Logstash 필터 translate</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2019/08/logstash-drop.html\" target=\"_blank\">Logstash 필터 drop</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2019/11/logstash-useragent.html\" target=\"_blank\">Logstash 필터 useragent</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2020/02/logstash-elapsed.html\" target=\"_blank\">Logstash 필터 elapsed</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2020/04/logstash-fingerprint.html\" target=\"_blank\">Logstash 필터 fingerprint</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2022/12/logstash-csv.html\" target=\"_blank\">Logstash 필터 csv</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2023/11/logstash-dns.html\">Logstash 필터 dns</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2025/01/logstash-split.html\">Logstash 필터 split</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2020/02/logstash-codec-multiline.html\" target=\"_blank\">Logstash codec 플러그인 multiline</a></li></ul></div>",
        "contentSnippet": "캡쳐그룹 순서번호는 1부터 시작한다.\n\n\n\n\n첫 번째 순서번호 캡쳐를 위한 ruby 필터\n\nruby {\n code => \"\n  event.set('result', event.get('message').match(/(.).../).captures[1])\t\n \"\n}\n\n\n\n캡쳐 실패.\n\n[2025-01-18T20:37:14,434][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}\n{\n    \"message\" => \"abcd\\r\",\n     \"result\" => nil\n}\n\n\n\n\n왜 안 되지? 전체 문자를 개별 캡쳐해봤다.\n\nruby {\n code => \"\n  event.set('result', event.get('message').match(/(.)(.)(.)(.)/).captures[1])\t\n \"\n}\n\n\n\n\n두 번째 순서번호를 가져오네?\n\n[2025-01-18T20:32:47,467][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}\n{\n    \"message\" => \"abcd\\r\",\n     \"result\" => \"b\"\n}\n\n\n\n\n순서번호를 빼봤다.\n\nruby {\n code => \"\n  event.set('result', event.get('message').match(/(.)(.)(.)(.)/).captures)\t\n \"\n}\n\n\n\n\n[2025-01-18T20:33:35,432][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}\n{\n    \"message\" => \"abcd\\r\",\n     \"result\" => [\n        [0] \"a\",\n        [1] \"b\",\n        [2] \"c\",\n        [3] \"d\"\n    ]\n}\n\n\n\n\n순서번호가 0부터 시작(..)\n\n\n관련 글\n\nLogstash 필터 ruby - 5th\nLogstash 필터 ruby\nLogstash 필터 grok\nLogstash 필터 mutate\nLogstash 필터 geoip\nLogstash 필터 dissect\nLogstash 필터 kv\nLogstash 필터 date\nLogstash 필터 translate\nLogstash 필터 drop\nLogstash 필터 useragent\nLogstash 필터 elapsed\nLogstash 필터 fingerprint\nLogstash 필터 csv\nLogstash 필터 dns\nLogstash 필터 split\nLogstash codec 플러그인 multiline",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-1406692707397421592",
        "isoDate": "2025-01-18T11:49:00.003Z"
      },
      {
        "title": "Logstash 필터 ruby - 5th",
        "link": "https://kangmyounghun.blogspot.com/2025/01/logstash-ruby-5th.html",
        "pubDate": "2025-01-18T06:28:00.002Z",
        "author": "강명훈",
        "content": "<div>ruby 필터는 <span style=\"font-family: courier;\">==</span> 등의 비교 연산자를 지원하지 않는다. 다음은 include 메소드를 이용한 <span style=\"font-family: courier;\">?</span> 검사.</div>\n<div><pre><code><span style=\"font-family: courier;\"><div>ruby {</div><div><span style=\"white-space: normal;\">&nbsp;code =&gt; \"</span></div><div><span style=\"white-space: normal;\">&nbsp; if event.get('message').include?('?')</span></div><div><span style=\"white-space: normal;\">&nbsp; &nbsp;event.set('result', 'TRUE')</span></div><div><span style=\"white-space: normal;\">&nbsp; else</span></div><div><span style=\"white-space: normal;\">&nbsp; &nbsp;event.set('result', 'FALSE')</span></div><div><span style=\"white-space: normal;\">&nbsp; end<span style=\"white-space: pre;\">\t</span></span></div><div><span style=\"white-space: normal;\">&nbsp;\"</span></div><div><span style=\"white-space: normal;\">}</span></div></span></code></pre></div>\n<span><a name='more'></a></span><div><pre><code><span style=\"font-family: courier;\"><div>[2025-01-18T14:56:19,606][INFO ][logstash.agent&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;] Pipelines running {:count=&gt;1, :running_pipelines=&gt;[:main], :non_running_pipelines=&gt;[]}</div><div>{</div><div>&nbsp; &nbsp; \"message\" =&gt; \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.php?board_id=kor%5Fmedia&amp;gul_no=1106&amp;idx=17&amp;m=4&amp;upage=25&amp;tpage=&amp;PAGE=4 HTTP/1.1\\\" 200 37727\\r\",</div><div>&nbsp; &nbsp; &nbsp;\"result\" =&gt; \"TRUE\"</div><div>}</div><div>{</div><div>&nbsp; &nbsp; \"message\" =&gt; \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.html HTTP/1.1\\\" 200 37727\\r\",</div><div>&nbsp; &nbsp; &nbsp;\"result\" =&gt; \"FALSE\"</div><div>}</div></span></code></pre></div>\n<div><br /></div>\n<div>정규표현식 검사는 match 메소드로 가능.</div>\n<div><pre><code><span style=\"font-family: courier;\"><div>ruby {</div><div>&nbsp;code =&gt; \"</div><div>&nbsp; if event.get('message').match('\\?')</div><div>&nbsp; &nbsp;event.set('result', 'TRUE')</div><div>&nbsp; else</div><div>&nbsp; &nbsp;event.set('result', 'FALSE')</div><div>&nbsp; end<span style=\"white-space: pre;\">\t</span></div><div>&nbsp;\"</div><div>}</div></span></code></pre></div><div><br /></div>\n<div>그런데 code 표현식 구분기호를 <span style=\"font-family: courier;\">'</span>로 바꾸면서 충돌 방지를 위해 표현식내에 사용된 <span style=\"font-family: courier;\">'</span>를 <span style=\"font-family: courier;\">\"</span>로 바꾸니 에러 발생. 순수문자&nbsp;<span style=\"font-family: courier;\">?</span><span style=\"font-size: x-small;\">(\\?)</span>를 수량자로 인식한다.</div>\n<div><pre><code><span style=\"font-family: courier;\"><div>ruby {</div><div><span style=\"white-space: normal;\">&nbsp;code =&gt; '</span></div><div><span style=\"white-space: normal;\">&nbsp; if event.get(\"message\").match(\"\\?\")</span></div><div><span style=\"white-space: normal;\">&nbsp; &nbsp;event.set(\"result\", \"TRUE\")</span></div><div><span style=\"white-space: normal;\">&nbsp; else</span></div><div><span style=\"white-space: normal;\">&nbsp; &nbsp;event.set(\"result\", \"FALSE\")</span></div><div><span style=\"white-space: normal;\">&nbsp; end<span style=\"white-space: pre;\">\t</span></span></div><div><span style=\"white-space: normal;\">&nbsp;'</span></div><div><span style=\"white-space: normal;\">}</span></div></span></code></pre></div>\n<div><pre><code><span style=\"font-family: courier;\"><div>[2025-01-18T15:02:16,612][INFO ][logstash.agent&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;] Pipelines running {:count=&gt;1, :running_pipelines=&gt;[:main], :non_running_pipelines=&gt;[]}</div><div>[2025-01-18T15:02:16,740][ERROR][logstash.filters.ruby&nbsp; &nbsp; ][main][62b3883710cf5e6539519c02d2e859b71543aa213032326fbf070fa80051a3f3] Ruby exception occurred: target of repeat operator is not specified: /?/ {:class=&gt;\"RegexpError\", :backtrace=&gt;[\"org/jruby/RubyString.java:1754:in `match'\", \"(ruby filter code):3:in `block in register'\", \"D:/ELK/logstash-8.17.0/vendor/bundle/jruby/3.1.0/gems/logstash-filter-ruby-3.1.8/lib/logstash/filters/ruby.rb:96:in `inline_script'\", \"D:/ELK/logstash-8.17.0/vendor/bundle/jruby/3.1.0/gems/logstash-filter-ruby-3.1.8/lib/logstash/filters/ruby.rb:89:in `filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:158:in `do_filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:176:in `block in multi_filter'\", \"org/jruby/RubyArray.java:1981:in `each'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:173:in `multi_filter'\", \"org/logstash/config/ir/compiler/AbstractFilterDelegatorExt.java:133:in `multi_filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/java_pipeline.rb:308:in `block in start_workers'\"]}</div><div>[2025-01-18T15:02:16,742][ERROR][logstash.filters.ruby&nbsp; &nbsp; ][main][62b3883710cf5e6539519c02d2e859b71543aa213032326fbf070fa80051a3f3] Ruby exception occurred: target of repeat operator is not specified: /?/ {:class=&gt;\"RegexpError\", :backtrace=&gt;[\"org/jruby/RubyString.java:1754:in `match'\", \"(ruby filter code):3:in `block in register'\", \"D:/ELK/logstash-8.17.0/vendor/bundle/jruby/3.1.0/gems/logstash-filter-ruby-3.1.8/lib/logstash/filters/ruby.rb:96:in `inline_script'\", \"D:/ELK/logstash-8.17.0/vendor/bundle/jruby/3.1.0/gems/logstash-filter-ruby-3.1.8/lib/logstash/filters/ruby.rb:89:in `filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:158:in `do_filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:176:in `block in multi_filter'\", \"org/jruby/RubyArray.java:1981:in `each'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:173:in `multi_filter'\", \"org/logstash/config/ir/compiler/AbstractFilterDelegatorExt.java:133:in `multi_filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/java_pipeline.rb:308:in `block in start_workers'\"]}</div><div>{</div><div>&nbsp; &nbsp; \"message\" =&gt; \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.php?board_id=kor%5Fmedia&amp;gul_no=1106&amp;idx=17&amp;m=4&amp;upage=25&amp;tpage=&amp;PAGE=4 HTTP/1.1\\\" 200 37727\\r\",</div><div>&nbsp; &nbsp; &nbsp; &nbsp;\"tags\" =&gt; [</div><div>&nbsp; &nbsp; &nbsp; &nbsp; [0] \"_rubyexception\"</div><div>&nbsp; &nbsp; ]</div><div>}</div><div>{</div><div>&nbsp; &nbsp; \"message\" =&gt; \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.html HTTP/1.1\\\" 200 37727\\r\",</div><div>&nbsp; &nbsp; &nbsp; &nbsp;\"tags\" =&gt; [</div><div>&nbsp; &nbsp; &nbsp; &nbsp; [0] \"_rubyexception\"</div><div>&nbsp; &nbsp; ]</div><div>}</div></span></code></pre></div>\n<div><br /></div>\n<div><span style=\"font-family: courier;\">\\</span>를 하나 더 추가해줘야 예외처리가 됨. 인용부호 종류에 따라 동작 방식이 바뀌다니 신기하네<span style=\"font-size: x-small;\">(..)</span></div>\n<div><pre><code><span style=\"font-family: courier;\"><div>ruby {</div><div>&nbsp;code =&gt; '</div><div>&nbsp; if event.get(\"message\").match(\"\\\\?\")</div><div>&nbsp; &nbsp;event.set(\"result\", \"TRUE\")</div><div>&nbsp; else</div><div>&nbsp; &nbsp;event.set(\"result\", \"FALSE\")</div><div>&nbsp; end<span style=\"white-space: pre;\">\t</span></div><div>&nbsp;'</div><div>}</div></span></code></pre></div>\n<div><pre><code><span style=\"font-family: courier;\"><div>[2025-01-18T15:02:55,821][INFO ][logstash.agent&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;] Pipelines running {:count=&gt;1, :running_pipelines=&gt;[:main], :non_running_pipelines=&gt;[]}</div><div>[2025-01-18T15:02:55,823][INFO ][filewatch.observingtail&nbsp; ][main][925210a49f665e5510840791e908400bcb21ff21428156584c5f572f276da2fe] START, creating Discoverer, Watch with file and sincedb collections</div><div>{</div><div>&nbsp; &nbsp; \"message\" =&gt; \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.html HTTP/1.1\\\" 200 37727\\r\",</div><div>&nbsp; &nbsp; &nbsp;\"result\" =&gt; \"FALSE\"</div><div>}</div><div>{</div><div>&nbsp; &nbsp; \"message\" =&gt; \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.php?board_id=kor%5Fmedia&amp;gul_no=1106&amp;idx=17&amp;m=4&amp;upage=25&amp;tpage=&amp;PAGE=4 HTTP/1.1\\\" 200 37727\\r\",</div><div>&nbsp; &nbsp; &nbsp;\"result\" =&gt; \"TRUE\"</div><div>}</div></span></code></pre></div>\n<div><br /></div>\n<div>정규표현식 구분기호는 <span style=\"font-family: courier;\">/</span>만 써야겠다.</div>\n<div><pre><code><span style=\"font-family: courier;\"><div>ruby {</div><div>&nbsp;code =&gt; '</div><div>&nbsp; if event.get(\"message\").match(/\\?/)</div><div>&nbsp; &nbsp;event.set(\"result\", \"TRUE\")</div><div>&nbsp; else</div><div>&nbsp; &nbsp;event.set(\"result\", \"FALSE\")</div><div>&nbsp; end<span style=\"white-space: pre;\">\t</span></div><div>&nbsp;'</div><div>}</div></span></code></pre></div>\n<div><br /></div>\n<div><b style=\"font-family: inherit;\">관련&nbsp;글</b><br /><ul><li><a href=\"https://kangmyounghun.blogspot.com/2025/01/logstash-ruby-6th.html\">Logstash 필터 ruby - 6th</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2020/02/logstash-ruby-4th.html\" target=\"\">Logstash 필터 ruby - 4th</a></li></ul></div>",
        "contentSnippet": "ruby 필터는 == 등의 비교 연산자를 지원하지 않는다. 다음은 include 메소드를 이용한 ? 검사.\n\nruby {\n code => \"\n  if event.get('message').include?('?')\n   event.set('result', 'TRUE')\n  else\n   event.set('result', 'FALSE')\n  end\t\n \"\n}\n\n\n\n\n[2025-01-18T14:56:19,606][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}\n{\n    \"message\" => \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.php?board_id=kor%5Fmedia&gul_no=1106&idx=17&m=4&upage=25&tpage=&PAGE=4 HTTP/1.1\\\" 200 37727\\r\",\n     \"result\" => \"TRUE\"\n}\n{\n    \"message\" => \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.html HTTP/1.1\\\" 200 37727\\r\",\n     \"result\" => \"FALSE\"\n}\n\n\n\n\n정규표현식 검사는 match 메소드로 가능.\n\nruby {\n code => \"\n  if event.get('message').match('\\?')\n   event.set('result', 'TRUE')\n  else\n   event.set('result', 'FALSE')\n  end\t\n \"\n}\n\n\n\n그런데 code 표현식 구분기호를 '로 바꾸면서 충돌 방지를 위해 표현식내에 사용된 '를 \"로 바꾸니 에러 발생. 순수문자 ?(\\?)를 수량자로 인식한다.\n\nruby {\n code => '\n  if event.get(\"message\").match(\"\\?\")\n   event.set(\"result\", \"TRUE\")\n  else\n   event.set(\"result\", \"FALSE\")\n  end\t\n '\n}\n\n\n\n\n[2025-01-18T15:02:16,612][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}\n[2025-01-18T15:02:16,740][ERROR][logstash.filters.ruby    ][main][62b3883710cf5e6539519c02d2e859b71543aa213032326fbf070fa80051a3f3] Ruby exception occurred: target of repeat operator is not specified: /?/ {:class=>\"RegexpError\", :backtrace=>[\"org/jruby/RubyString.java:1754:in `match'\", \"(ruby filter code):3:in `block in register'\", \"D:/ELK/logstash-8.17.0/vendor/bundle/jruby/3.1.0/gems/logstash-filter-ruby-3.1.8/lib/logstash/filters/ruby.rb:96:in `inline_script'\", \"D:/ELK/logstash-8.17.0/vendor/bundle/jruby/3.1.0/gems/logstash-filter-ruby-3.1.8/lib/logstash/filters/ruby.rb:89:in `filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:158:in `do_filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:176:in `block in multi_filter'\", \"org/jruby/RubyArray.java:1981:in `each'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:173:in `multi_filter'\", \"org/logstash/config/ir/compiler/AbstractFilterDelegatorExt.java:133:in `multi_filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/java_pipeline.rb:308:in `block in start_workers'\"]}\n[2025-01-18T15:02:16,742][ERROR][logstash.filters.ruby    ][main][62b3883710cf5e6539519c02d2e859b71543aa213032326fbf070fa80051a3f3] Ruby exception occurred: target of repeat operator is not specified: /?/ {:class=>\"RegexpError\", :backtrace=>[\"org/jruby/RubyString.java:1754:in `match'\", \"(ruby filter code):3:in `block in register'\", \"D:/ELK/logstash-8.17.0/vendor/bundle/jruby/3.1.0/gems/logstash-filter-ruby-3.1.8/lib/logstash/filters/ruby.rb:96:in `inline_script'\", \"D:/ELK/logstash-8.17.0/vendor/bundle/jruby/3.1.0/gems/logstash-filter-ruby-3.1.8/lib/logstash/filters/ruby.rb:89:in `filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:158:in `do_filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:176:in `block in multi_filter'\", \"org/jruby/RubyArray.java:1981:in `each'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/filters/base.rb:173:in `multi_filter'\", \"org/logstash/config/ir/compiler/AbstractFilterDelegatorExt.java:133:in `multi_filter'\", \"D:/ELK/logstash-8.17.0/logstash-core/lib/logstash/java_pipeline.rb:308:in `block in start_workers'\"]}\n{\n    \"message\" => \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.php?board_id=kor%5Fmedia&gul_no=1106&idx=17&m=4&upage=25&tpage=&PAGE=4 HTTP/1.1\\\" 200 37727\\r\",\n       \"tags\" => [\n        [0] \"_rubyexception\"\n    ]\n}\n{\n    \"message\" => \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.html HTTP/1.1\\\" 200 37727\\r\",\n       \"tags\" => [\n        [0] \"_rubyexception\"\n    ]\n}\n\n\n\n\n\\를 하나 더 추가해줘야 예외처리가 됨. 인용부호 종류에 따라 동작 방식이 바뀌다니 신기하네(..)\n\nruby {\n code => '\n  if event.get(\"message\").match(\"\\\\?\")\n   event.set(\"result\", \"TRUE\")\n  else\n   event.set(\"result\", \"FALSE\")\n  end\t\n '\n}\n\n\n\n\n[2025-01-18T15:02:55,821][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}\n[2025-01-18T15:02:55,823][INFO ][filewatch.observingtail  ][main][925210a49f665e5510840791e908400bcb21ff21428156584c5f572f276da2fe] START, creating Discoverer, Watch with file and sincedb collections\n{\n    \"message\" => \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.html HTTP/1.1\\\" 200 37727\\r\",\n     \"result\" => \"FALSE\"\n}\n{\n    \"message\" => \"192.168.71.168 - - [12/Oct/2015:02:42:00 +0900] \\\"GET /bbs/view.php?board_id=kor%5Fmedia&gul_no=1106&idx=17&m=4&upage=25&tpage=&PAGE=4 HTTP/1.1\\\" 200 37727\\r\",\n     \"result\" => \"TRUE\"\n}\n\n\n\n\n정규표현식 구분기호는 /만 써야겠다.\n\nruby {\n code => '\n  if event.get(\"message\").match(/\\?/)\n   event.set(\"result\", \"TRUE\")\n  else\n   event.set(\"result\", \"FALSE\")\n  end\t\n '\n}\n\n\n\n\n관련 글\n\nLogstash 필터 ruby - 6th\nLogstash 필터 ruby - 4th",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-6643708857228007068",
        "isoDate": "2025-01-18T06:28:00.002Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕홍",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": [
      {
        "creator": "고명환",
        "title": "희망리턴패키지 사업계획서 작성 방법 및 사례 1 - 소상공인",
        "link": "https://brunch.co.kr/@@LOc/260",
        "pubDate": "Tue, 21 Jan 2025 04:41:12 GMT",
        "author": "고명환",
        "content": "희망리턴패키지 사업은 소상공인의 재창업 및 경영개선을 위한 사업으로 소상공인과 관련된 정부지원사업 중 가장 많은 사업화 자금이 지원됩니다. 소상공인 분들이 평소에 사업계획서를 작성할 일이 없어서 신청에 애로사항이 있기 때문에 이를 조금이나마 도움을 드리고자 사례를 들여서 작성 방법을 설명드리겠습니다.   https://www.sbiz.or.kr/sup/ma<img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FhLzDtxsW_25jtWNdD20tnwJ8AOA.jpg\" width=\"500\" />",
        "contentSnippet": "희망리턴패키지 사업은 소상공인의 재창업 및 경영개선을 위한 사업으로 소상공인과 관련된 정부지원사업 중 가장 많은 사업화 자금이 지원됩니다. 소상공인 분들이 평소에 사업계획서를 작성할 일이 없어서 신청에 애로사항이 있기 때문에 이를 조금이나마 도움을 드리고자 사례를 들여서 작성 방법을 설명드리겠습니다.   https://www.sbiz.or.kr/sup/ma",
        "guid": "https://brunch.co.kr/@@LOc/260",
        "isoDate": "2025-01-21T04:41:12.000Z"
      },
      {
        "creator": "고명환",
        "title": "스타트업의 R&amp;D 과제 수행 시 자주하는 실수 5가지 - 스타트업",
        "link": "https://brunch.co.kr/@@LOc/259",
        "pubDate": "Mon, 20 Jan 2025 01:48:48 GMT",
        "author": "고명환",
        "content": "스타트업이 R&amp;D 지원사업에 처음 도전할 때, 많은 시행착오를 겪는 경우가 많습니다. 특히, 예비창업패키지, 청년창업사관학교와 같은 사업과 혼돈해 R&amp;D 지원사업을 진행하는 경우가 많은 데 성격이 매우 다른 사업인만큼 과제를 성공적으로 수행하기 위해서는 주요 실수를 미리 파악하고 방지하는 것이 중요합니다.   1. 목표 설정의 불명확성  1) 실수  많은 <img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FI-s08aVvuHE4UdXIoQRfZftRAIc.jpg\" width=\"500\" />",
        "contentSnippet": "스타트업이 R&D 지원사업에 처음 도전할 때, 많은 시행착오를 겪는 경우가 많습니다. 특히, 예비창업패키지, 청년창업사관학교와 같은 사업과 혼돈해 R&D 지원사업을 진행하는 경우가 많은 데 성격이 매우 다른 사업인만큼 과제를 성공적으로 수행하기 위해서는 주요 실수를 미리 파악하고 방지하는 것이 중요합니다.   1. 목표 설정의 불명확성  1) 실수  많은",
        "guid": "https://brunch.co.kr/@@LOc/259",
        "isoDate": "2025-01-20T01:48:48.000Z"
      },
      {
        "creator": "고명환",
        "title": "R&amp;D 성능지표 선정 시 주의할 점 및 참고 웹사이트 - 스타트",
        "link": "https://brunch.co.kr/@@LOc/258",
        "pubDate": "Fri, 17 Jan 2025 02:00:06 GMT",
        "author": "고명환",
        "content": "R&amp;D 지원사업에서 '성능지표'는 과제의 성공 가능성을 평가하는 중요한 기준입니다. 성능지표를 잘 선정하면 사업계획서 평가에서 긍정적인 영향을 줄 뿐 아니라, 과제 종료 후 성과를 명확히 입증할 수 있습니다. 아래는 성능지표 선정 시 주의할 점과 참고할만한 웹사이트를 정리하였습니다   1. 성능지표 선정 시 주의할 점  가. 구체적이고 측정 가능해야 함(S<img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FqsgCb0yPb3Am8ZuXSfVlR2DoHf0.jpg\" width=\"500\" />",
        "contentSnippet": "R&D 지원사업에서 '성능지표'는 과제의 성공 가능성을 평가하는 중요한 기준입니다. 성능지표를 잘 선정하면 사업계획서 평가에서 긍정적인 영향을 줄 뿐 아니라, 과제 종료 후 성과를 명확히 입증할 수 있습니다. 아래는 성능지표 선정 시 주의할 점과 참고할만한 웹사이트를 정리하였습니다   1. 성능지표 선정 시 주의할 점  가. 구체적이고 측정 가능해야 함(S",
        "guid": "https://brunch.co.kr/@@LOc/258",
        "isoDate": "2025-01-17T02:00:06.000Z"
      },
      {
        "creator": "고명환",
        "title": "R&amp;D 지원사업 신청 시 파트너 선정 방법 - 스타트",
        "link": "https://brunch.co.kr/@@LOc/257",
        "pubDate": "Wed, 15 Jan 2025 10:50:46 GMT",
        "author": "고명환",
        "content": "R&amp;D 지원사업을 처음하는 스타트업의 경우 파트너와의 협력은 성공적인 과제 수행과 사업화의 핵심 요소입니다. 다음은 파트너 선정 시 유의해야 할 점을 체계적으로 정리하였습니다.   1. 파트너의 역량과 전문성  기술적 보완성 : 스타트업이 부족한 기술이나 역량을 보완할 수 있는 파트너인 지 확인하세요. 예를 들어, 기계적 설계를 주로 하는 기업이라면 소프트<img src= \"https://img1.daumcdn.net/thumb/R1280x0/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FeIj9tzIUkrFSdRXW_ZV0H0deuJw.jpg\" width=\"500\" />",
        "contentSnippet": "R&D 지원사업을 처음하는 스타트업의 경우 파트너와의 협력은 성공적인 과제 수행과 사업화의 핵심 요소입니다. 다음은 파트너 선정 시 유의해야 할 점을 체계적으로 정리하였습니다.   1. 파트너의 역량과 전문성  기술적 보완성 : 스타트업이 부족한 기술이나 역량을 보완할 수 있는 파트너인 지 확인하세요. 예를 들어, 기계적 설계를 주로 하는 기업이라면 소프트",
        "guid": "https://brunch.co.kr/@@LOc/257",
        "isoDate": "2025-01-15T10:50:46.000Z"
      }
    ]
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김놀부",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "챗GPT 블로그 제목 생성 무료 GPTS, 이슈성 키워드를 롱런시키는 전략",
        "link": "http://muzbox.tistory.com/483528",
        "pubDate": "Mon, 20 Jan 2025 09:25:33 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483528#entry483528comment",
        "content": "<p data-ke-size=\"size16\">이슈성 키워드를 오랫동안 유지할 수 있는 블로그 제목을 만드는 방법과 SEO 최적화 전략을 해결한 무료 GPTS를 공개합니다. 연말정산이나 폭설 같은 키워드를 활용해서 꾸준한 트래픽을 유지하는 방법, 같이 알아봐요!</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"블로그 제목 생성.png\" data-origin-width=\"900\" data-origin-height=\"514\"><span data-url=\"https://blog.kakaocdn.net/dn/cGt6gX/btsLSO0ecsE/du7A79MqpndE6lhOKAvki1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cGt6gX/btsLSO0ecsE/du7A79MqpndE6lhOKAvki1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cGt6gX/btsLSO0ecsE/du7A79MqpndE6lhOKAvki1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcGt6gX%2FbtsLSO0ecsE%2Fdu7A79MqpndE6lhOKAvki1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"챗GPT 블로그 제목 생성 무료 GPTS, 이슈성 키워드를 롱런시키는 전략\" loading=\"lazy\" width=\"700\" height=\"400\" data-filename=\"블로그 제목 생성.png\" data-origin-width=\"900\" data-origin-height=\"514\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;블로그를 운영하다 보면 특정 키워드가 갑자기 인기를 끌다가 얼마 지나지 않아 관심이 뚝 떨어지는 경우가 많죠. 저도 블로그에서 \"연말정산\"이나 \"폭설\" 같은 키워드를 써보면서 이런 경험을 했는데요. 처음엔 방문자가 몰렸다가 시즌이 끝나면 트래픽이 확 줄더라고요. 그렇다고 포기할 수는 없잖아요? 어떻게 하면 이런 키워드를 오랫동안 관심받게 만들 수 있을지, 오늘 같이 고민해볼게요!&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이러한 과정을 통해 챗GPT를 이용하여 바로 적절한 제목을 만들어 주는 GPTS 를 무료로 공개합니다.!!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>  이슈성 키워드를 꾸준히 유지하는 방법</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">  \"관심과 감정이 연결된 대상\" 찾기</span></h3>\n<p data-ke-size=\"size16\">사람들은 자기와 관련된 내용에 훨씬 더 오래 관심을 가져요. 그냥 \"폭설 대비 방법\"보다는 \"우리 가족을 위한 폭설 대비 체크리스트\"처럼 개인적인 느낌을 담으면 효과가 좋아요.</p>\n<h4 data-ke-size=\"size20\"><b>  실행 방안</b></h4>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>개인적인 관점 추가하기:</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>단순 키워드 ❌ &rarr; 감성적인 연결 ✔️</li>\n<li>예: \"폭설\" ❌ &rarr; \"우리 집 자동차를 위한 폭설 대비 완벽 가이드\" ✔️</li>\n<li>예: \"연말정산\" ❌ &rarr; \"2024 직장인을 위한 연말정산 절세 꿀팁\" ✔️</li>\n</ul>\n</li>\n<li><b>사회적 관심 반영하기:</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>트렌드와 연관된 주제로 풀어보기</li>\n<li>예: \"폭설 대비 정책 변화, 우리 생활에 미치는 영향\"</li>\n</ul>\n</li>\n<li><b>검색 의도를 고려한 키워드 조합:</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>왜 필요할까? &rarr; 폭설의 원인 분석</li>\n<li>누구에게 도움될까? &rarr; 직장인, 자영업자 등</li>\n</ul>\n</li>\n</ol>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">  검색 패턴을 활용한 키워드 전략</span></h3>\n<p data-ke-size=\"size16\">검색을 해보면 사람들이 두 가지 방식으로 키워드를 찾더라고요. 바로 <b>즉각적인 검색</b>과 <b>장기적인 검색</b>이에요.</p>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>즉각적인 검색:</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>\"2024 연말정산 마감일 언제까지?\"</li>\n<li>\"서울 폭설 현재 상황 실시간 보기\"</li>\n</ul>\n</li>\n<li><b>장기적인 검색:</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>\"연말정산 공제 항목 완벽 정리\"</li>\n<li>\"겨울철 차량 관리법, 폭설 대비 팁\"</li>\n</ul>\n</li>\n</ol>\n<h4 data-ke-size=\"size20\"><b>  키워드 전략 적용</b></h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>즉각적인 검색:</b> 마감일, 실시간, 빠른 해결</li>\n<li><b>장기적인 검색:</b> 팁, 가이드, 준비법</li>\n</ul>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">  키워드를 지속 가능하게 만드는 법</span></h3>\n<h4 data-ke-size=\"size20\">1) 트렌드 활용하기</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>연말정산: \"2025 연말정산 준비, 미리 챙겨야 할 것들\"</li>\n<li>폭설: \"기후 변화로 폭설이 많아진다, 우리가 대비할 방법은?\"</li>\n</ul>\n<h4 data-ke-size=\"size20\">2) 깊이 있는 정보 제공</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>연말정산: \"초보 직장인을 위한 연말정산 공제 완벽 정리\"</li>\n<li>폭설: \"지역별 폭설 대처법, 이렇게 하면 안전해요\"</li>\n</ul>\n<h4 data-ke-size=\"size20\">3) 키워드 확장</h4>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>연말정산 &rarr; \"소득공제, 세액공제 뭐가 다를까?\"</li>\n<li>폭설 &rarr; \"겨울철 자동차 관리, 이것만은 꼭!\"</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>  [연말정산] 및 [폭설] 키워드 적용 예시</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">즉각적인 호기심 유발</span></h3>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>\"2024 연말정산, 이번에 놓치면 안 되는 절세 포인트!\"</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>핵심 키워드: 연말정산 팁, 절세 전략</li>\n<li>SEO 전략: '놓치면 안 되는', '필수 항목' 키워드 활용</li>\n</ul>\n</li>\n<li><b>\"올 겨울 폭설 대비, 필수 체크리스트 대공개!\"</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>핵심 키워드: 폭설 대비, 차량 준비</li>\n<li>SEO 전략: '필수', '체크리스트', '준비법' 키워드 강조</li>\n</ul>\n</li>\n</ol>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">구체적인 문제 해결</span></h3>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>\"연말정산 소득공제와 세액공제, 뭐가 다를까?\"</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>핵심 키워드: 소득공제, 세액공제</li>\n<li>SEO 전략: '차이점', '비교', '절세 방법' 강조</li>\n</ul>\n</li>\n<li><b>\"폭설 대비 차량 점검, 이것만 기억하세요!\"</b>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>핵심 키워드: 겨울철 차량 관리, 폭설 대비</li>\n<li>SEO 전략: '필수 확인', '고장 예방' 키워드 삽입</li>\n</ul>\n</li>\n</ol>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>마무리하며</b></span></h2>\n<p data-ke-size=\"size16\">이슈성 키워드를 꾸준히 유지하려면, <b>검색 패턴을 이해하고, 개인적인 스토리와 사회적 이슈를 적절히 섞는 게 중요해요.</b> 이렇게 하면 독자들이 꾸준히 관심을 가질 수 있답니다.</p>\n<p data-ke-size=\"size16\">이제 여러분도 연말정산이나 폭설 같은 키워드로 꾸준한 검색 유입을 만들어 보세요!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000; text-align: start;\" data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b> </b></span><span style=\"color: #009a87;\"><b><span>&nbsp;</span>GPTS 무료배포</b></span></h2>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\">&nbsp;약간의 지식과 시간만 투자하면 누구나 직접 제작하고 활용할 수 있는 유용한 GPTs가 이미 많이 존재합니다. 그러나 여전히 AI 기술에 대한 낯선 접근을 두려워하거나 IT 초보자, 또는 시간적 여유가 없거나 수익화에 대한 절실함 때문에 올바른 정보를 얻지 못하는 사람들이 많습니다. 이러한 심리를 악용해 과도한 가격으로 유료 강의를 판매하며 불필요한 부담을 주는 사례들이 늘어나고 있습니다.<span>&nbsp;</span><span style=\"color: #ee2323;\"><b>이에 본 블로그에서는 모든 사람이 AI의 혜택을 공정하고 자유롭게 누릴 수 있도록 GPTs를 무료로 배포하며, 불합리한 강의 판매 행위를 단호히 배척하고자 합니다.</b></span></p>\n<script async src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8195497734535830\"\n     crossorigin=\"anonymous\"></script>\n<ins class=\"adsbygoogle\"\n     style=\"display:block; text-align:center;\"\n     data-ad-layout=\"in-article\"\n     data-ad-format=\"fluid\"\n     data-ad-client=\"ca-pub-8195497734535830\"\n     data-ad-slot=\"7411138078\"></ins>\n<script>\n     (adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<figure id=\"og_1737332149856\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"ChatGPT - 챗GPT 블로그 제목 생성기\" data-og-description=\"사용자가 [키워드]를 입력하면 키워드를 지속적으로 유지하기 위한 블로그 제목을 제안합니다.\" data-og-host=\"chatgpt.com\" data-og-source-url=\"https://chatgpt.com/g/g-678d84eed64c819190a55fb6178767fc-caesgpt-beulrogeu-jemog-saengseonggi\" data-og-url=\"https://chatgpt.com/g/g-678d84eed64c819190a55fb6178767fc-caesgpt-beulrogeu-jemog-saengseonggi\" data-og-image=\"\"><a href=\"https://chatgpt.com/g/g-678d84eed64c819190a55fb6178767fc-caesgpt-beulrogeu-jemog-saengseonggi\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://chatgpt.com/g/g-678d84eed64c819190a55fb6178767fc-caesgpt-beulrogeu-jemog-saengseonggi\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">ChatGPT - 챗GPT 블로그 제목 생성기</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">사용자가 [키워드]를 입력하면 키워드를 지속적으로 유지하기 위한 블로그 제목을 제안합니다.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">chatgpt.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\">&nbsp;</p>\n<hr data-ke-style=\"style1\" />\n<h2 data-ke-size=\"size26\"><span style=\"color: #ee2323;\"><b>❓ 자주 묻는 질문(Q&amp;A)</b></span></h2>\n<p data-ke-size=\"size16\"><b>1. 연말정산 키워드를 롱런하려면 어떻게 해야 하나요?</b> <br />절세&nbsp;관련&nbsp;정보나&nbsp;연중&nbsp;세테크&nbsp;팁을&nbsp;제공하세요.<br /><br /><b>2. 폭설 키워드는 시즌 외에 어떻게 유지할 수 있을까요?</b> <br />사계절&nbsp;차량&nbsp;관리법을&nbsp;포함해&nbsp;지속적인&nbsp;관심을&nbsp;유도하세요.<br /><br /><b>3. 블로그 제목을 효과적으로 작성하려면?</b> <br />키워드를&nbsp;제목&nbsp;앞쪽에&nbsp;배치하고,&nbsp;'꿀팁',&nbsp;'필수&nbsp;체크리스트'&nbsp;같은&nbsp;단어를&nbsp;활용하세요.<br /><br /><b>4. SEO 최적화를 위해 어떤 전략이 필요할까요?</b> <br />검색&nbsp;의도를&nbsp;파악하고,&nbsp;관련&nbsp;키워드를&nbsp;자연스럽게&nbsp;삽입하는&nbsp;것이&nbsp;중요합니다.<br /><br /><b>5. 이슈성 키워드 외에도 블로그 트래픽을 유지할 방법이 있을까요?</b> <br />꾸준한 콘텐츠 업데이트와 관련 주제 확장을 통해 지속적인 관심을 유도하세요.</p>\n<p><textarea style=\"display: none;\">&lt;script type=\"application/ld+json\"&gt;\n{\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n        {\n            \"@type\": \"Question\",\n            \"name\": \"연말정산 키워드를 롱런하려면 어떻게 해야 하나요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"절세 관련 정보나 연중 세테크 팁을 제공하세요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"폭설 키워드는 시즌 외에 어떻게 유지할 수 있을까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"사계절 차량 관리법을 포함해 지속적인 관심을 유도하세요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"블로그 제목을 효과적으로 작성하려면?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"키워드를 제목 앞쪽에 배치하고, '꿀팁', '필수 체크리스트' 같은 단어를 활용하세요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"SEO 최적화를 위해 어떤 전략이 필요할까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"검색 의도를 파악하고, 관련 키워드를 자연스럽게 삽입하는 것이 중요합니다.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"이슈성 키워드 외에도 블로그 트래픽을 유지할 방법이 있을까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"꾸준한 콘텐츠 업데이트와 관련 주제 확장을 통해 지속적인 관심을 유도하세요.\"\n            }\n        }\n    ]\n}\n&lt;/script&gt;\n</textarea></p>",
        "contentSnippet": "이슈성 키워드를 오랫동안 유지할 수 있는 블로그 제목을 만드는 방법과 SEO 최적화 전략을 해결한 무료 GPTS를 공개합니다. 연말정산이나 폭설 같은 키워드를 활용해서 꾸준한 트래픽을 유지하는 방법, 같이 알아봐요!\n\n\n \n 블로그를 운영하다 보면 특정 키워드가 갑자기 인기를 끌다가 얼마 지나지 않아 관심이 뚝 떨어지는 경우가 많죠. 저도 블로그에서 \"연말정산\"이나 \"폭설\" 같은 키워드를 써보면서 이런 경험을 했는데요. 처음엔 방문자가 몰렸다가 시즌이 끝나면 트래픽이 확 줄더라고요. 그렇다고 포기할 수는 없잖아요? 어떻게 하면 이런 키워드를 오랫동안 관심받게 만들 수 있을지, 오늘 같이 고민해볼게요! \n \n이러한 과정을 통해 챗GPT를 이용하여 바로 적절한 제목을 만들어 주는 GPTS 를 무료로 공개합니다.!!\n \n  이슈성 키워드를 꾸준히 유지하는 방법\n  \"관심과 감정이 연결된 대상\" 찾기\n사람들은 자기와 관련된 내용에 훨씬 더 오래 관심을 가져요. 그냥 \"폭설 대비 방법\"보다는 \"우리 가족을 위한 폭설 대비 체크리스트\"처럼 개인적인 느낌을 담으면 효과가 좋아요.\n  실행 방안\n개인적인 관점 추가하기:\n\n단순 키워드 ❌ → 감성적인 연결 ✔️\n예: \"폭설\" ❌ → \"우리 집 자동차를 위한 폭설 대비 완벽 가이드\" ✔️\n예: \"연말정산\" ❌ → \"2024 직장인을 위한 연말정산 절세 꿀팁\" ✔️\n사회적 관심 반영하기:\n\n트렌드와 연관된 주제로 풀어보기\n예: \"폭설 대비 정책 변화, 우리 생활에 미치는 영향\"\n검색 의도를 고려한 키워드 조합:\n\n왜 필요할까? → 폭설의 원인 분석\n누구에게 도움될까? → 직장인, 자영업자 등\n  검색 패턴을 활용한 키워드 전략\n검색을 해보면 사람들이 두 가지 방식으로 키워드를 찾더라고요. 바로 즉각적인 검색과 장기적인 검색이에요.\n즉각적인 검색:\n\n\"2024 연말정산 마감일 언제까지?\"\n\"서울 폭설 현재 상황 실시간 보기\"\n장기적인 검색:\n\n\"연말정산 공제 항목 완벽 정리\"\n\"겨울철 차량 관리법, 폭설 대비 팁\"\n  키워드 전략 적용\n즉각적인 검색: 마감일, 실시간, 빠른 해결\n장기적인 검색: 팁, 가이드, 준비법\n  키워드를 지속 가능하게 만드는 법\n1) 트렌드 활용하기\n연말정산: \"2025 연말정산 준비, 미리 챙겨야 할 것들\"\n폭설: \"기후 변화로 폭설이 많아진다, 우리가 대비할 방법은?\"\n2) 깊이 있는 정보 제공\n연말정산: \"초보 직장인을 위한 연말정산 공제 완벽 정리\"\n폭설: \"지역별 폭설 대처법, 이렇게 하면 안전해요\"\n3) 키워드 확장\n연말정산 → \"소득공제, 세액공제 뭐가 다를까?\"\n폭설 → \"겨울철 자동차 관리, 이것만은 꼭!\"\n \n  [연말정산] 및 [폭설] 키워드 적용 예시\n즉각적인 호기심 유발\n\"2024 연말정산, 이번에 놓치면 안 되는 절세 포인트!\"\n\n핵심 키워드: 연말정산 팁, 절세 전략\nSEO 전략: '놓치면 안 되는', '필수 항목' 키워드 활용\n\"올 겨울 폭설 대비, 필수 체크리스트 대공개!\"\n\n핵심 키워드: 폭설 대비, 차량 준비\nSEO 전략: '필수', '체크리스트', '준비법' 키워드 강조\n구체적인 문제 해결\n\"연말정산 소득공제와 세액공제, 뭐가 다를까?\"\n\n핵심 키워드: 소득공제, 세액공제\nSEO 전략: '차이점', '비교', '절세 방법' 강조\n\"폭설 대비 차량 점검, 이것만 기억하세요!\"\n\n핵심 키워드: 겨울철 차량 관리, 폭설 대비\nSEO 전략: '필수 확인', '고장 예방' 키워드 삽입\n \n마무리하며\n이슈성 키워드를 꾸준히 유지하려면, 검색 패턴을 이해하고, 개인적인 스토리와 사회적 이슈를 적절히 섞는 게 중요해요. 이렇게 하면 독자들이 꾸준히 관심을 가질 수 있답니다.\n이제 여러분도 연말정산이나 폭설 같은 키워드로 꾸준한 검색 유입을 만들어 보세요!\n \n \n  GPTS 무료배포\n 약간의 지식과 시간만 투자하면 누구나 직접 제작하고 활용할 수 있는 유용한 GPTs가 이미 많이 존재합니다. 그러나 여전히 AI 기술에 대한 낯선 접근을 두려워하거나 IT 초보자, 또는 시간적 여유가 없거나 수익화에 대한 절실함 때문에 올바른 정보를 얻지 못하는 사람들이 많습니다. 이러한 심리를 악용해 과도한 가격으로 유료 강의를 판매하며 불필요한 부담을 주는 사례들이 늘어나고 있습니다. 이에 본 블로그에서는 모든 사람이 AI의 혜택을 공정하고 자유롭게 누릴 수 있도록 GPTs를 무료로 배포하며, 불합리한 강의 판매 행위를 단호히 배척하고자 합니다.\n\n\n\n     (adsbygoogle = window.adsbygoogle || []).push({});\n\n\n \nChatGPT - 챗GPT 블로그 제목 생성기\n사용자가 [키워드]를 입력하면 키워드를 지속적으로 유지하기 위한 블로그 제목을 제안합니다.\nchatgpt.com\n\n \n \n❓ 자주 묻는 질문(Q&A)\n1. 연말정산 키워드를 롱런하려면 어떻게 해야 하나요? \n절세 관련 정보나 연중 세테크 팁을 제공하세요.\n2. 폭설 키워드는 시즌 외에 어떻게 유지할 수 있을까요? \n사계절 차량 관리법을 포함해 지속적인 관심을 유도하세요.\n3. 블로그 제목을 효과적으로 작성하려면? \n키워드를 제목 앞쪽에 배치하고, '꿀팁', '필수 체크리스트' 같은 단어를 활용하세요.\n4. SEO 최적화를 위해 어떤 전략이 필요할까요? \n검색 의도를 파악하고, 관련 키워드를 자연스럽게 삽입하는 것이 중요합니다.\n5. 이슈성 키워드 외에도 블로그 트래픽을 유지할 방법이 있을까요? \n꾸준한 콘텐츠 업데이트와 관련 주제 확장을 통해 지속적인 관심을 유도하세요.\n<script type=\"application/ld+json\">\n{\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n        {\n            \"@type\": \"Question\",\n            \"name\": \"연말정산 키워드를 롱런하려면 어떻게 해야 하나요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"절세 관련 정보나 연중 세테크 팁을 제공하세요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"폭설 키워드는 시즌 외에 어떻게 유지할 수 있을까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"사계절 차량 관리법을 포함해 지속적인 관심을 유도하세요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"블로그 제목을 효과적으로 작성하려면?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"키워드를 제목 앞쪽에 배치하고, '꿀팁', '필수 체크리스트' 같은 단어를 활용하세요.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"SEO 최적화를 위해 어떤 전략이 필요할까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"검색 의도를 파악하고, 관련 키워드를 자연스럽게 삽입하는 것이 중요합니다.\"\n            }\n        },\n        {\n            \"@type\": \"Question\",\n            \"name\": \"이슈성 키워드 외에도 블로그 트래픽을 유지할 방법이 있을까요?\",\n            \"acceptedAnswer\": {\n                \"@type\": \"Answer\",\n                \"text\": \"꾸준한 콘텐츠 업데이트와 관련 주제 확장을 통해 지속적인 관심을 유도하세요.\"\n            }\n        }\n    ]\n}\n</script>",
        "guid": "http://muzbox.tistory.com/483528",
        "categories": [
          "AI, 미래기술/MY GPT 공개",
          "SEO 최적화",
          "롱런 키워드 전략",
          "무료 gpts",
          "무료챗봇",
          "블로그 제목 생성기",
          "블로그 콘텐츠 기획",
          "이슈성 키워드",
          "지속 가능한 트래픽",
          "챗GPT",
          "키워드 지속 유지법"
        ],
        "isoDate": "2025-01-20T00:25:33.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "AI 노트북 고민 끝!: 에이서 스위프트 16 AI",
        "link": "http://muzbox.tistory.com/483527",
        "pubDate": "Fri, 17 Jan 2025 09:54:33 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483527#entry483527comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;요즘 AI 기술이 빠르게 발전하면서 관련 작업에 적합한 노트북을 찾는 일이 점점 더 중요해지고 있어요.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"에이서 스위프트 16 AI 노트북 리뷰.jpg\" data-origin-width=\"775\" data-origin-height=\"460\"><span data-url=\"https://blog.kakaocdn.net/dn/bzu9UO/btsLQi1GVls/ad4Uf2qqMXKq5EYMVfb0X0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bzu9UO/btsLQi1GVls/ad4Uf2qqMXKq5EYMVfb0X0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bzu9UO/btsLQi1GVls/ad4Uf2qqMXKq5EYMVfb0X0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbzu9UO%2FbtsLQi1GVls%2Fad4Uf2qqMXKq5EYMVfb0X0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"AI 노트북 고민 끝!: 에이서 스위프트 16 AI\" loading=\"lazy\" width=\"700\" height=\"415\" data-filename=\"에이서 스위프트 16 AI 노트북 리뷰.jpg\" data-origin-width=\"775\" data-origin-height=\"460\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;저도 비슷한 고민을 하던 중에 우연히 <b>에이서 스위프트 16 AI</b>를 발견하게 되었는데요. 단순히 \"AI 기술에 적합하다\"를 넘어서, <b>성능, 디자인, 휴대성, 배터리 지속 시간</b>까지 어느 하나 빠지지 않는 제품이더라고요. 그래서 오늘은 이 노트북의 각 특징을 구체적으로 살펴보며, 여러분께 추천드리고자 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">1️⃣ <b>최신 인텔 코어 울트라 7로 AI 작업에 최적화된 퍼포먼스</b></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"773\" data-origin-height=\"614\"><span data-url=\"https://blog.kakaocdn.net/dn/bP9iqF/btsLPQEv2Xr/HmVQ0mgk7sqqFVnxURYoDK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bP9iqF/btsLPQEv2Xr/HmVQ0mgk7sqqFVnxURYoDK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bP9iqF/btsLPQEv2Xr/HmVQ0mgk7sqqFVnxURYoDK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbP9iqF%2FbtsLPQEv2Xr%2FHmVQ0mgk7sqqFVnxURYoDK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"에이서 스위프트 16 AI CPU\" loading=\"lazy\" width=\"773\" height=\"614\" data-origin-width=\"773\" data-origin-height=\"614\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>에이서 스위프트 16 AI</b>가 특별히 주목받는 이유 중 하나는 최신형 <b>인텔 코어 울트라 7 258V 프로세서</b> 덕분이에요. 이 CPU는 일반적인 프로세서 성능 개선을 넘어, <b>AI 작업에 특화된 전용 하드웨어</b>를 탑재하고 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">우선, 이 프로세서의 가장 큰 특징은 <b>NPU(신경망 처리 장치)</b>예요. 기존 CPU는 모든 작업을 동일한 프로세서 코어에서 처리했지만, 이 제품은 AI 연산을 NPU가 전담합니다. 예를 들어, 머신러닝 모델을 훈련시키거나 데이터 분석 작업을 수행할 때, NPU가 따로 일을 처리하기 때문에 작업 속도가 기존 프로세서 대비 월등히 빠르고 효율적이에요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">또한, <b>47TOPS(초당 연산 트릴리언 회수)</b>라는 AI 연산 성능은 복잡한 딥러닝 연산이나 대규모 시뮬레이션을 부드럽게 처리할 수 있는 수준입니다. 이 정도 성능은 데이터 과학자, AI 연구원, 개발자들이 주로 사용하는 고성능 워크스테이션과도 견줄 만하다고 할 수 있어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">여기에 더해, 이 CPU는 전력 효율성이 뛰어나서 배터리 소모를 줄이면서도 고성능을 유지할 수 있습니다. 예를 들어, AI 기반 앱을 장시간 실행하더라도 발열과 배터리 문제가 크게 줄어든다는 점은 정말 매력적이에요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">2️⃣ <b>Intel Arc 140V 그래픽으로 AI와 비주얼 작업을 한 번에</b></h2>\n<p data-ke-size=\"size16\">AI 작업은 그래픽 성능과도 밀접한 연관이 있죠. 특히 데이터 시각화, 영상 편집, 3D 모델링 같은 고사양 작업은 CPU와 GPU의 조화가 중요합니다. 에이서 스위프트 16 AI는 <b>Intel Arc 140V 그래픽 카드</b>를 탑재해 이 두 가지를 완벽히 충족시켜 줍니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 그래픽 카드는 머신러닝 모델의 시각화 작업이나 대규모 데이터 처리 시 병렬 연산 성능을 극대화해줍니다. 예를 들어, 딥러닝 모델의 훈련 과정을 시각적으로 확인하거나 복잡한 데이터 분석 결과를 시뮬레이션할 때, 기존 대비 훨씬 빠르고 정확하게 결과를 얻을 수 있어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">그래픽 성능이 뛰어난 덕분에, 영상 편집자나 디자이너처럼 고사양 작업이 잦은 분들에게도 큰 도움이 됩니다. <b>최대 1.5배 향상된 그래픽 처리 능력</b>은 4K 이상의 고해상도 영상 작업이나 3D 렌더링 프로젝트를 더욱 빠르게 처리할 수 있게 해줍니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">또한, 이 제품은 게이머들에게도 매력적입니다. 고사양 게임에서 요구하는 그래픽 처리량을 안정적으로 처리할 수 있어서, 업무와 오락 모두를 만족시킬 수 있는 만능형 노트북이에요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<div class=\"product-details-button-wrapper\">\n    <style>\n        .product-details-button-wrapper .button-container {\n            display: flex;\n            justify-content: center;\n            align-items: center;\n            padding: 20px 0;\n        }\n        .product-details-button-wrapper .product-details-button {\n            width: 600px;\n            height: 80px; /* 높이를 줄임 */\n            font-family: '맑은 고딕', 'Malgun Gothic', sans-serif;\n            font-weight: bold;\n            font-size: 28px; /* 글자 크기를 키움 */\n            color: white;\n            background: linear-gradient(145deg, #ff6b6b, #ee5253);\n            border: 4px solid #c0392b;\n            border-radius: 15px;\n            cursor: pointer;\n            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);\n            transition: all 0.3s ease;\n            overflow: hidden;\n            position: relative;\n            display: flex; /* 추가 */\n            justify-content: center; /* 추가 */\n            align-items: center; /* 추가 */\n        }\n        .product-details-button-wrapper .product-details-button:hover {\n            transform: scale(1.05);\n            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);\n        }\n        .product-details-button-wrapper .button-text {\n            position: relative;\n            z-index: 1;\n            animation: sparkle 1.5s infinite;\n        }\n        @keyframes sparkle {\n            0%, 100% { opacity: 1; }\n            50% { opacity: 0.7; }\n        }\n    </style>\n    <div class=\"button-container\">\n        <button class=\"product-details-button\">\n            <span class=\"button-text\">제품 상세 정보는 여기를 클릭하세요</span>\n        </button>\n    </div>\n    <script>\n        (function() {\n            var wrapper = document.currentScript.closest('.product-details-button-wrapper');\n            var button = wrapper.querySelector('.product-details-button');\n            // URL을 여기에 삽입하세요\n            var productDetailsUrl = \"https://link.coupang.com/a/cafzqG\";\n            button.addEventListener(\"click\", function() {\n                window.open(productDetailsUrl, '_self');\n            });\n        })();\n    </script>\n    <p style=\"text-align: center;\" data-ke-size=\"size14\"><span style=\"background-color: #ffffff; color: #0f0f0f; text-align: start;\">&lt;이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.&gt;</span></p>\n</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">3️⃣ <b>초경량 디자인으로 휴대성과 편리함을 모두 잡다</b></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"774\" data-origin-height=\"616\"><span data-url=\"https://blog.kakaocdn.net/dn/oznVM/btsLO8TfwWM/Q6Sk17gauKQJU2ONeW9cik/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/oznVM/btsLO8TfwWM/Q6Sk17gauKQJU2ONeW9cik/img.png\"><img src=\"https://blog.kakaocdn.net/dn/oznVM/btsLO8TfwWM/Q6Sk17gauKQJU2ONeW9cik/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FoznVM%2FbtsLO8TfwWM%2FQ6Sk17gauKQJU2ONeW9cik%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"에이서 스위프트 16 AI 디자인\" loading=\"lazy\" width=\"774\" height=\"616\" data-origin-width=\"774\" data-origin-height=\"616\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">노트북을 선택할 때 휴대성이 중요한 분들이 많으실 텐데요. 특히 매일같이 들고 다니는 직장인이나 학생들에게 <b>가벼운 무게와 슬림한 디자인</b>은 필수 조건이죠. 에이서 스위프트 16 AI는 <b>1.46kg</b>의 초경량 무게와 <b>15.95mm의 얇은 두께</b>로 휴대성을 극대화했어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">가방에 넣고 다녀도 부담스럽지 않은 무게와 디자인 덕분에, 외근이 잦은 직장인이나 이동 중 작업이 많은 프리랜서들에게 특히 유용합니다. 더불어, <b>180도 힌지</b>가 적용되어 회의 중 다른 사람과 화면을 쉽게 공유하거나, 여러 각도로 화면을 조정하며 편리하게 작업할 수 있어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">여기에 넓은 터치패드는 세밀한 작업이 필요할 때 큰 도움을 줍니다. 터치패드의 감도와 크기는 사용자의 편의성을 크게 좌우하는데, 이 제품은 그런 점에서도 아주 잘 설계되었어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">4️⃣ <b>생산성을 높이는 16인치 WQXGA+ 디스플레이</b></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"775\" data-origin-height=\"767\"><span data-url=\"https://blog.kakaocdn.net/dn/bbM2Ec/btsLQPYYSgC/4cjtK5e4D8mC0YknzNG8P1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bbM2Ec/btsLQPYYSgC/4cjtK5e4D8mC0YknzNG8P1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bbM2Ec/btsLQPYYSgC/4cjtK5e4D8mC0YknzNG8P1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbbM2Ec%2FbtsLQPYYSgC%2F4cjtK5e4D8mC0YknzNG8P1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"에이서 스위프트 16 AI 디스플레이\" loading=\"lazy\" width=\"775\" height=\"767\" data-origin-width=\"775\" data-origin-height=\"767\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">노트북 화면은 단순히 크기만 중요한 게 아니라, 해상도와 화면 비율도 생산성에 큰 영향을 미쳐요. <b>에이서 스위프트 16 AI</b>의 <b>16인치 WQXGA+ 디스플레이</b>는 그런 면에서 최고의 선택이에요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>2880x1800 해상도</b>는 텍스트, 이미지, 영상 모두를 선명하게 표현해주며, 세부적인 작업에서도 왜곡 없이 명확한 화면을 제공합니다. 특히, 해상도가 높으면 영상 편집이나 그래픽 작업에서 작은 디테일까지 확인할 수 있어 작업 효율이 크게 높아집니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">또한, <b>16:10 화면 비율</b>은 기존 16:9 비율보다 더 넓은 작업 공간을 제공해 여러 창을 띄워도 답답하지 않아요. 이 비율은 멀티태스킹 작업에 최적화되어 있어, 영상 편집자나 코딩 작업을 하는 분들에게 특히 유용합니다.</p>\n<p data-ke-size=\"size16\"><b>120Hz 주사율</b>은 화면 전환이 빠르고 부드러워 눈의 피로를 줄여줍니다. 특히, 그래픽 디자인이나 사진 보정 작업 중 미세한 화면 움직임이 필요할 때 이 기능이 크게 도움됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">5️⃣ <b>강력한 배터리로 하루 종일 충전 걱정 없이</b></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"772\" data-origin-height=\"652\"><span data-url=\"https://blog.kakaocdn.net/dn/bqu3mm/btsLP4CBYQY/7GKn2GczR3lAKqaRpkiNJ0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bqu3mm/btsLP4CBYQY/7GKn2GczR3lAKqaRpkiNJ0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bqu3mm/btsLP4CBYQY/7GKn2GczR3lAKqaRpkiNJ0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbqu3mm%2FbtsLP4CBYQY%2F7GKn2GczR3lAKqaRpkiNJ0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"에이서 스위프트 16 AI 배터리\" loading=\"lazy\" width=\"772\" height=\"652\" data-origin-width=\"772\" data-origin-height=\"652\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">긴 배터리 지속 시간은 외부에서 장시간 작업해야 하는 사용자들에게 필수 조건이죠. 에이서 스위프트 16 AI는 <b>70Wh 배터리</b>를 탑재해 하루 종일 충전 걱정 없이 사용할 수 있어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">비디오 재생 기준으로 <b>최대 20시간</b>, 일반 작업 기준으로 <b>17.5시간</b>, 웹 브라우징 기준으로 <b>13.5시간</b>까지 사용 가능합니다. 충전기를 따로 들고 다니지 않아도, 배터리가 오래 지속되니 가벼운 마음으로 이동할 수 있어요.</p>\n<p data-ke-size=\"size16\">특히, 출장이나 야외 촬영이 많은 분들에게 이 배터리 성능은 큰 장점으로 다가올 거예요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<div class=\"product-details-button-wrapper\">\n    <style>\n        .product-details-button-wrapper .button-container {\n            display: flex;\n            justify-content: center;\n            align-items: center;\n            padding: 20px 0;\n        }\n        .product-details-button-wrapper .product-details-button {\n            width: 600px;\n            height: 80px; /* 높이를 줄임 */\n            font-family: '맑은 고딕', 'Malgun Gothic', sans-serif;\n            font-weight: bold;\n            font-size: 28px; /* 글자 크기를 키움 */\n            color: white;\n            background: linear-gradient(145deg, #ff6b6b, #ee5253);\n            border: 4px solid #c0392b;\n            border-radius: 15px;\n            cursor: pointer;\n            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);\n            transition: all 0.3s ease;\n            overflow: hidden;\n            position: relative;\n            display: flex; /* 추가 */\n            justify-content: center; /* 추가 */\n            align-items: center; /* 추가 */\n        }\n        .product-details-button-wrapper .product-details-button:hover {\n            transform: scale(1.05);\n            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);\n        }\n        .product-details-button-wrapper .button-text {\n            position: relative;\n            z-index: 1;\n            animation: sparkle 1.5s infinite;\n        }\n        @keyframes sparkle {\n            0%, 100% { opacity: 1; }\n            50% { opacity: 0.7; }\n        }\n    </style>\n    <div class=\"button-container\">\n        <button class=\"product-details-button\">\n            <span class=\"button-text\">제품 상세 정보는 여기를 클릭하세요</span>\n        </button>\n    </div>\n    <script>\n        (function() {\n            var wrapper = document.currentScript.closest('.product-details-button-wrapper');\n            var button = wrapper.querySelector('.product-details-button');\n            // URL을 여기에 삽입하세요\n            var productDetailsUrl = \"https://link.coupang.com/a/cafzqG\";\n            button.addEventListener(\"click\", function() {\n                window.open(productDetailsUrl, '_self');\n            });\n        })();\n    </script>\n    <p style=\"text-align: center;\" data-ke-size=\"size14\"><span style=\"background-color: #ffffff; color: #0f0f0f; text-align: start;\">&lt;이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.&gt;</span></p>\n</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">6️⃣ <b>Windows 11과 Copilot으로 AI 활용을 극대화</b></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"757\" data-origin-height=\"703\"><span data-url=\"https://blog.kakaocdn.net/dn/bLNDWm/btsLRpMaSEW/PHaTwgUzuZmNKCmVYu0Hg1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bLNDWm/btsLRpMaSEW/PHaTwgUzuZmNKCmVYu0Hg1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bLNDWm/btsLRpMaSEW/PHaTwgUzuZmNKCmVYu0Hg1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbLNDWm%2FbtsLRpMaSEW%2FPHaTwgUzuZmNKCmVYu0Hg1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"에이서 스위프트 16 AI 코파일럿\" loading=\"lazy\" width=\"757\" height=\"703\" data-origin-width=\"757\" data-origin-height=\"703\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;AI 소프트웨어를 제대로 활용하려면 운영 체제와의 조화가 중요한데요, 에이서 스위프트 16 AI는 최신 <b>Windows 11</b>에 포함된 <b>Copilot</b> 기능을 탑재해 작업 효율을 극대화합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">Copilot은 번역, 문서 분석, PDF 요약, 웹 검색 같은 다양한 작업을 AI 기반으로 더 빠르고 정확하게 처리할 수 있게 도와줍니다. 여기에 <b>AcerSense</b>가 추가돼 시스템 최적화와 성능 관리까지 자동으로 이루어지니, 사용자 입장에서는 더 편리하죠.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"784\" data-origin-height=\"602\"><span data-url=\"https://blog.kakaocdn.net/dn/GsI8g/btsLQt9S2u4/ydyzhKseBDe6hI4HZJRMuk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/GsI8g/btsLQt9S2u4/ydyzhKseBDe6hI4HZJRMuk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/GsI8g/btsLQt9S2u4/ydyzhKseBDe6hI4HZJRMuk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FGsI8g%2FbtsLQt9S2u4%2FydyzhKseBDe6hI4HZJRMuk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"에이서 스위프트 16 AI 카메라\" loading=\"lazy\" width=\"784\" height=\"602\" data-origin-width=\"784\" data-origin-height=\"602\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;또한, <b>1440p QHD 카메라</b>와 <b>AI 기반 Windows Studio Effects</b> 기능이 더해져 화상회의나 온라인 학습에서도 탁월한 품질을 제공합니다. 배경 흐림, 자동 프레이밍, 아이컨택 같은 기능은 화상 통화 중 더 자연스럽고 편리한 경험을 선사합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">7️⃣ <b>튼튼한 내구성과 다양한 연결 옵션으로 완벽한 호환성 제공</b></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"769\" data-origin-height=\"649\"><span data-url=\"https://blog.kakaocdn.net/dn/cRyruq/btsLP7zekvo/NQyMLvkKkE6uYRZ4uCUk8k/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cRyruq/btsLP7zekvo/NQyMLvkKkE6uYRZ4uCUk8k/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cRyruq/btsLP7zekvo/NQyMLvkKkE6uYRZ4uCUk8k/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcRyruq%2FbtsLP7zekvo%2FNQyMLvkKkE6uYRZ4uCUk8k%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"에이서 스위프트 16 AI 내구성\" loading=\"lazy\" width=\"769\" height=\"649\" data-origin-width=\"769\" data-origin-height=\"649\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">노트북의 내구성은 장기적인 사용을 보장하는 중요한 요소인데요, 이 제품은 <b>MIL-STD-810G 인증</b>을 받아 다양한 환경에서도 안정적으로 사용할 수 있어요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">포트 구성도 완벽합니다. <b>Thunderbolt&trade; 4</b>, <b>USB 3.2 Gen1</b>, <b>HDMI 2.1</b> 등의 포트를 지원해 다양한 외부 장치와 연결이 가능합니다. 이 정도 연결 옵션이면 업무 환경이 훨씬 더 유연해질 거예요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><b>결론: AI 노트북의 새로운 기준, 지금 바로 선택하세요!</b></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"775\" data-origin-height=\"588\"><span data-url=\"https://blog.kakaocdn.net/dn/B8nOH/btsLRFOSUhk/xtsnbs1aczMioyiKeosvO0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/B8nOH/btsLRFOSUhk/xtsnbs1aczMioyiKeosvO0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/B8nOH/btsLRFOSUhk/xtsnbs1aczMioyiKeosvO0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FB8nOH%2FbtsLRFOSUhk%2Fxtsnbs1aczMioyiKeosvO0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"에이서 스위프트 16 AI 제원\" loading=\"lazy\" width=\"775\" height=\"588\" data-origin-width=\"775\" data-origin-height=\"588\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><b>&nbsp;에이서 스위프트 16 AI</b>는 AI 기술을 제대로 활용하면서도, <b>성능, 디스플레이, 휴대성, 배터리</b>까지 완벽한 균형을 갖춘 제품이에요. 특히, 가격대비 뛰어난 성능 덕분에 가성비를 중시하는 사용자들에게 정말 좋은 선택이 될 거예요.<br /><br /></p>\n<p data-ke-size=\"size16\">최신 AI 기술을 활용해 생산성과 창의성을 높이고 싶으시다면, 더 이상 고민할 필요 없이 이 제품을 선택해 보세요.  ✨</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<div class=\"product-details-button-wrapper\">\n    <style>\n        .product-details-button-wrapper .button-container {\n            display: flex;\n            justify-content: center;\n            align-items: center;\n            padding: 20px 0;\n        }\n        .product-details-button-wrapper .product-details-button {\n            width: 600px;\n            height: 80px; /* 높이를 줄임 */\n            font-family: '맑은 고딕', 'Malgun Gothic', sans-serif;\n            font-weight: bold;\n            font-size: 28px; /* 글자 크기를 키움 */\n            color: white;\n            background: linear-gradient(145deg, #ff6b6b, #ee5253);\n            border: 4px solid #c0392b;\n            border-radius: 15px;\n            cursor: pointer;\n            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);\n            transition: all 0.3s ease;\n            overflow: hidden;\n            position: relative;\n            display: flex; /* 추가 */\n            justify-content: center; /* 추가 */\n            align-items: center; /* 추가 */\n        }\n        .product-details-button-wrapper .product-details-button:hover {\n            transform: scale(1.05);\n            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);\n        }\n        .product-details-button-wrapper .button-text {\n            position: relative;\n            z-index: 1;\n            animation: sparkle 1.5s infinite;\n        }\n        @keyframes sparkle {\n            0%, 100% { opacity: 1; }\n            50% { opacity: 0.7; }\n        }\n    </style>\n    <div class=\"button-container\">\n        <button class=\"product-details-button\">\n            <span class=\"button-text\">제품 상세 정보는 여기를 클릭하세요</span>\n        </button>\n    </div>\n    <script>\n        (function() {\n            var wrapper = document.currentScript.closest('.product-details-button-wrapper');\n            var button = wrapper.querySelector('.product-details-button');\n            // URL을 여기에 삽입하세요\n            var productDetailsUrl = \"https://link.coupang.com/a/cafzqG\";\n            button.addEventListener(\"click\", function() {\n                window.open(productDetailsUrl, '_self');\n            });\n        })();\n    </script>\n    <p style=\"text-align: center;\" data-ke-size=\"size14\"><span style=\"background-color: #ffffff; color: #0f0f0f; text-align: start;\">&lt;이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.&gt;</span></p>\n</div>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"kakaotv\" data-video-url=\"https://tv.kakao.com/v/452396312\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cEcAWC/hyX4nobXQb/BDmOOzuWlZXNdDr55YWw61/img.jpg?width=776&amp;height=442&amp;face=156_72_358_292,https://scrap.kakaocdn.net/dn/bj53RV/hyX0v9fYkz/yPQayThp8U0KkfXVUR2CG1/img.jpg?width=776&amp;height=442&amp;face=156_72_358_292\" data-video-width=\"776\" data-video-height=\"442\" data-video-origin-width=\"776\" data-video-origin-height=\"442\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"'어떤오후의 프리웨..'에서 업로드한 동영상\" data-video-play-service=\"daum_tistory\" data-original-url=\"\"><iframe src=\"https://play-tv.kakao.com/embed/player/cliplink/452396312?service=daum_tistory\" width=\"776\" height=\"442\" frameborder=\"0\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "요즘 AI 기술이 빠르게 발전하면서 관련 작업에 적합한 노트북을 찾는 일이 점점 더 중요해지고 있어요.\n\n\n \n 저도 비슷한 고민을 하던 중에 우연히 에이서 스위프트 16 AI를 발견하게 되었는데요. 단순히 \"AI 기술에 적합하다\"를 넘어서, 성능, 디자인, 휴대성, 배터리 지속 시간까지 어느 하나 빠지지 않는 제품이더라고요. 그래서 오늘은 이 노트북의 각 특징을 구체적으로 살펴보며, 여러분께 추천드리고자 합니다.\n \n \n1️⃣ 최신 인텔 코어 울트라 7로 AI 작업에 최적화된 퍼포먼스\n\n\n \n에이서 스위프트 16 AI가 특별히 주목받는 이유 중 하나는 최신형 인텔 코어 울트라 7 258V 프로세서 덕분이에요. 이 CPU는 일반적인 프로세서 성능 개선을 넘어, AI 작업에 특화된 전용 하드웨어를 탑재하고 있습니다.\n \n우선, 이 프로세서의 가장 큰 특징은 NPU(신경망 처리 장치)예요. 기존 CPU는 모든 작업을 동일한 프로세서 코어에서 처리했지만, 이 제품은 AI 연산을 NPU가 전담합니다. 예를 들어, 머신러닝 모델을 훈련시키거나 데이터 분석 작업을 수행할 때, NPU가 따로 일을 처리하기 때문에 작업 속도가 기존 프로세서 대비 월등히 빠르고 효율적이에요.\n \n또한, 47TOPS(초당 연산 트릴리언 회수)라는 AI 연산 성능은 복잡한 딥러닝 연산이나 대규모 시뮬레이션을 부드럽게 처리할 수 있는 수준입니다. 이 정도 성능은 데이터 과학자, AI 연구원, 개발자들이 주로 사용하는 고성능 워크스테이션과도 견줄 만하다고 할 수 있어요.\n \n여기에 더해, 이 CPU는 전력 효율성이 뛰어나서 배터리 소모를 줄이면서도 고성능을 유지할 수 있습니다. 예를 들어, AI 기반 앱을 장시간 실행하더라도 발열과 배터리 문제가 크게 줄어든다는 점은 정말 매력적이에요.\n \n \n2️⃣ Intel Arc 140V 그래픽으로 AI와 비주얼 작업을 한 번에\nAI 작업은 그래픽 성능과도 밀접한 연관이 있죠. 특히 데이터 시각화, 영상 편집, 3D 모델링 같은 고사양 작업은 CPU와 GPU의 조화가 중요합니다. 에이서 스위프트 16 AI는 Intel Arc 140V 그래픽 카드를 탑재해 이 두 가지를 완벽히 충족시켜 줍니다.\n \n이 그래픽 카드는 머신러닝 모델의 시각화 작업이나 대규모 데이터 처리 시 병렬 연산 성능을 극대화해줍니다. 예를 들어, 딥러닝 모델의 훈련 과정을 시각적으로 확인하거나 복잡한 데이터 분석 결과를 시뮬레이션할 때, 기존 대비 훨씬 빠르고 정확하게 결과를 얻을 수 있어요.\n \n그래픽 성능이 뛰어난 덕분에, 영상 편집자나 디자이너처럼 고사양 작업이 잦은 분들에게도 큰 도움이 됩니다. 최대 1.5배 향상된 그래픽 처리 능력은 4K 이상의 고해상도 영상 작업이나 3D 렌더링 프로젝트를 더욱 빠르게 처리할 수 있게 해줍니다.\n \n또한, 이 제품은 게이머들에게도 매력적입니다. 고사양 게임에서 요구하는 그래픽 처리량을 안정적으로 처리할 수 있어서, 업무와 오락 모두를 만족시킬 수 있는 만능형 노트북이에요.\n \n제품 상세 정보는 여기를 클릭하세요\n        \n    \n<이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.>\n \n3️⃣ 초경량 디자인으로 휴대성과 편리함을 모두 잡다\n\n\n노트북을 선택할 때 휴대성이 중요한 분들이 많으실 텐데요. 특히 매일같이 들고 다니는 직장인이나 학생들에게 가벼운 무게와 슬림한 디자인은 필수 조건이죠. 에이서 스위프트 16 AI는 1.46kg의 초경량 무게와 15.95mm의 얇은 두께로 휴대성을 극대화했어요.\n \n가방에 넣고 다녀도 부담스럽지 않은 무게와 디자인 덕분에, 외근이 잦은 직장인이나 이동 중 작업이 많은 프리랜서들에게 특히 유용합니다. 더불어, 180도 힌지가 적용되어 회의 중 다른 사람과 화면을 쉽게 공유하거나, 여러 각도로 화면을 조정하며 편리하게 작업할 수 있어요.\n \n여기에 넓은 터치패드는 세밀한 작업이 필요할 때 큰 도움을 줍니다. 터치패드의 감도와 크기는 사용자의 편의성을 크게 좌우하는데, 이 제품은 그런 점에서도 아주 잘 설계되었어요.\n \n \n4️⃣ 생산성을 높이는 16인치 WQXGA+ 디스플레이\n\n\n \n노트북 화면은 단순히 크기만 중요한 게 아니라, 해상도와 화면 비율도 생산성에 큰 영향을 미쳐요. 에이서 스위프트 16 AI의 16인치 WQXGA+ 디스플레이는 그런 면에서 최고의 선택이에요.\n \n2880x1800 해상도는 텍스트, 이미지, 영상 모두를 선명하게 표현해주며, 세부적인 작업에서도 왜곡 없이 명확한 화면을 제공합니다. 특히, 해상도가 높으면 영상 편집이나 그래픽 작업에서 작은 디테일까지 확인할 수 있어 작업 효율이 크게 높아집니다.\n \n또한, 16:10 화면 비율은 기존 16:9 비율보다 더 넓은 작업 공간을 제공해 여러 창을 띄워도 답답하지 않아요. 이 비율은 멀티태스킹 작업에 최적화되어 있어, 영상 편집자나 코딩 작업을 하는 분들에게 특히 유용합니다.\n120Hz 주사율은 화면 전환이 빠르고 부드러워 눈의 피로를 줄여줍니다. 특히, 그래픽 디자인이나 사진 보정 작업 중 미세한 화면 움직임이 필요할 때 이 기능이 크게 도움됩니다.\n \n \n5️⃣ 강력한 배터리로 하루 종일 충전 걱정 없이\n\n\n \n긴 배터리 지속 시간은 외부에서 장시간 작업해야 하는 사용자들에게 필수 조건이죠. 에이서 스위프트 16 AI는 70Wh 배터리를 탑재해 하루 종일 충전 걱정 없이 사용할 수 있어요.\n \n비디오 재생 기준으로 최대 20시간, 일반 작업 기준으로 17.5시간, 웹 브라우징 기준으로 13.5시간까지 사용 가능합니다. 충전기를 따로 들고 다니지 않아도, 배터리가 오래 지속되니 가벼운 마음으로 이동할 수 있어요.\n특히, 출장이나 야외 촬영이 많은 분들에게 이 배터리 성능은 큰 장점으로 다가올 거예요.\n \n제품 상세 정보는 여기를 클릭하세요\n        \n    \n<이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.>\n \n6️⃣ Windows 11과 Copilot으로 AI 활용을 극대화\n\n\n \n AI 소프트웨어를 제대로 활용하려면 운영 체제와의 조화가 중요한데요, 에이서 스위프트 16 AI는 최신 Windows 11에 포함된 Copilot 기능을 탑재해 작업 효율을 극대화합니다.\n \nCopilot은 번역, 문서 분석, PDF 요약, 웹 검색 같은 다양한 작업을 AI 기반으로 더 빠르고 정확하게 처리할 수 있게 도와줍니다. 여기에 AcerSense가 추가돼 시스템 최적화와 성능 관리까지 자동으로 이루어지니, 사용자 입장에서는 더 편리하죠.\n\n\n \n 또한, 1440p QHD 카메라와 AI 기반 Windows Studio Effects 기능이 더해져 화상회의나 온라인 학습에서도 탁월한 품질을 제공합니다. 배경 흐림, 자동 프레이밍, 아이컨택 같은 기능은 화상 통화 중 더 자연스럽고 편리한 경험을 선사합니다.\n \n \n7️⃣ 튼튼한 내구성과 다양한 연결 옵션으로 완벽한 호환성 제공\n\n\n노트북의 내구성은 장기적인 사용을 보장하는 중요한 요소인데요, 이 제품은 MIL-STD-810G 인증을 받아 다양한 환경에서도 안정적으로 사용할 수 있어요.\n \n포트 구성도 완벽합니다. Thunderbolt™ 4, USB 3.2 Gen1, HDMI 2.1 등의 포트를 지원해 다양한 외부 장치와 연결이 가능합니다. 이 정도 연결 옵션이면 업무 환경이 훨씬 더 유연해질 거예요.\n \n \n결론: AI 노트북의 새로운 기준, 지금 바로 선택하세요!\n\n\n \n 에이서 스위프트 16 AI는 AI 기술을 제대로 활용하면서도, 성능, 디스플레이, 휴대성, 배터리까지 완벽한 균형을 갖춘 제품이에요. 특히, 가격대비 뛰어난 성능 덕분에 가성비를 중시하는 사용자들에게 정말 좋은 선택이 될 거예요.\n\n최신 AI 기술을 활용해 생산성과 창의성을 높이고 싶으시다면, 더 이상 고민할 필요 없이 이 제품을 선택해 보세요.  ✨\n \n제품 상세 정보는 여기를 클릭하세요\n        \n    \n<이 기사는 쿠팡 파트너스 활동의 일환으로 일정액의 수수료를 제공받습니다.>",
        "guid": "http://muzbox.tistory.com/483527",
        "categories": [
          "신제품 리뷰/컴퓨터",
          "ai노트북추천",
          "가성비노트북",
          "노트북추천",
          "에이서 스위프트 16 ai",
          "에이서노트북",
          "인공지능 노트북"
        ],
        "isoDate": "2025-01-17T00:54:33.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "AI 가 만든 글에 사람의 향기를, 무료 GTPS - 인간냄새",
        "link": "http://muzbox.tistory.com/483526",
        "pubDate": "Wed, 15 Jan 2025 10:38:55 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483526#entry483526comment",
        "content": "<p data-ke-size=\"size16\">사람 냄새 나는 AI 글쓰기, 어떻게 가능할까요? 제가 만든 챗봇, GPTS가 바로 그 답입니다! 자연스럽고 공감 가는 글을 만드는 비법을 지금 확인해 보세요.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"인간냄새.jpg\" data-origin-width=\"800\" data-origin-height=\"457\"><span data-url=\"https://blog.kakaocdn.net/dn/ef9h1S/btsLOKW8fqL/lCuHjHMQXJGU5PwCPtisS0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/ef9h1S/btsLOKW8fqL/lCuHjHMQXJGU5PwCPtisS0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/ef9h1S/btsLOKW8fqL/lCuHjHMQXJGU5PwCPtisS0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fef9h1S%2FbtsLOKW8fqL%2FlCuHjHMQXJGU5PwCPtisS0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"700\" height=\"400\" data-filename=\"인간냄새.jpg\" data-origin-width=\"800\" data-origin-height=\"457\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">여러분, AI가 만든 글을 읽을 때 느낌이 어떠셨나요? 잘 쓰긴 했지만 뭔가 기계적인 냄새가 나는 것 같지 않으셨나요? 사실 저도 처음엔 AI 글을 보며 \"이걸 사람처럼 자연스럽게 바꾸려면 시간이 얼마나 걸릴까?\" 고민하곤 했어요. 하지만 그 고민을 해결하기 위해 직접 <b>'인간냄새' GPTS를 </b>만들게 되었습니다. 이 챗봇은 단순한 AI 텍스트 생성기를 넘어, 글에 진정성과 감정을 담아주는 역할을 해요. 오늘은 제가 만든 이 챗봇의 비밀을 여러분께 소개하려고 합니다.  </p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>왜 GPTS를 만들었나요?</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">  AI 글쓰기의 한계</span></h3>\n<p data-ke-size=\"size16\">제가 처음 AI가 작성한 글을 접했을 때, 놀라운 기술력에 감탄했지만, 뭔가 부족하다는 느낌이 들었어요. 정확히 말하면, 글에 <b>사람 냄새</b>가 없었어요. 우리가 글을 읽을 때 느끼는 따뜻함, 공감, 그리고 이야기를 듣는 듯한 편안함이 빠져 있었죠.</p>\n<p data-ke-size=\"size16\">예를 들어, AI는 \"이 도시는 아름답다\"라고 쓸 수 있지만, \"이 도시의 해변에서 바라본 석양은 마치 황금빛 물결 같았어요\"라는 식의 감성적인 묘사는 잘 하지 못하더라고요. 그래서 이런 문제를 해결하기 위해 독자의 마음을 움직이고, 진짜 대화를 나누는 것 같은 글을 만들어주는 GPTS를 개발하게 되었습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>GPTS 챗봇의 주요 기능</b></span></h2>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"> ️ 1. 사람처럼 말하기</span></h3>\n<p data-ke-size=\"size16\">GPTS의 가장 큰 특징은 대화하듯이 글을 쓸 수 있다는 점이에요. 예를 들어, \"운동은 건강에 좋습니다\"라는 딱딱한 문장을 \"제가 매일 아침 스트레칭을 10분씩 하고 있는데요, 덕분에 하루가 훨씬 가볍게 시작되더라고요!\"처럼 바꿀 수 있답니다. 이렇게 대화체로 전환하면 글이 훨씬 더 따뜻하고 친근하게 느껴져요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">  2. 감각적인 묘사 추가</span></h3>\n<p data-ke-size=\"size16\">사람 냄새 나는 글을 만들기 위해 가장 중요한 건 <b>감각적인 묘사</b>예요. 예를 들어, \"맛있는 음식\"이라는 단어 대신, \"버터의 고소한 향이 퍼지고, 갓 구운 빵에서 올라오는 따뜻한 김이 느껴지더라고요\"라는 식으로 글에 생동감을 더하는 거죠. GPTS는 이런 디테일한 표현을 자동으로 만들어줘요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">✍️ 3. 개인화된 스토리텔링</span></h3>\n<p data-ke-size=\"size16\">사람들은 경험담에 더 관심을 가지죠. GPTS는 이 점을 활용해 글에 자연스럽게 이야기를 녹여줍니다. 예를 들어, \"효율적인 시간 관리 방법\"이라는 주제를 \"제가 시간 관리가 너무 어려워서 고민하다가 시작한 방법인데요...\"처럼 개인화된 경험으로 풀어낼 수 있게 도와줘요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>GPTS의 작동 원리</b></span></h2>\n<p data-ke-size=\"size16\">GPTS는 단순한 AI 텍스트 생성기가 아니에요. 몇 가지 특별한 알고리즘과 전략이 더해져서 사람처럼 자연스러운 글을 만들어냅니다.</p>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li><b>스토리텔링 기반</b>: 독자가 공감할 수 있는 개인적인 경험과 상황을 중심으로 글을 작성합니다.</li>\n<li><b>대화형 어투 적용</b>: 마치 친구와 이야기하는 듯한 톤으로 글을 작성합니다.</li>\n<li><b>구체적인 디테일 추가</b>: 시각, 청각, 촉각 등을 자극하는 세밀한 묘사를 포함합니다.</li>\n</ol>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>GPTS로 글을 재구성하는 방법</b></span></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1792\" data-origin-height=\"1024\"><span data-url=\"https://blog.kakaocdn.net/dn/davJyg/btsLNBtoZ1f/JNkXQCuEPiMvkWR4UfyBY1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/davJyg/btsLNBtoZ1f/JNkXQCuEPiMvkWR4UfyBY1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/davJyg/btsLNBtoZ1f/JNkXQCuEPiMvkWR4UfyBY1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdavJyg%2FbtsLNBtoZ1f%2FJNkXQCuEPiMvkWR4UfyBY1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"GPTS로 글을 재구성하는 방법\" loading=\"lazy\" width=\"700\" height=\"400\" data-origin-width=\"1792\" data-origin-height=\"1024\"/></span></figure>\n</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">  1. 기존 글을 대화체로 변환</span></h3>\n<p data-ke-size=\"size16\">어떤 글이든 GPTS에 입력하면 대화하듯 자연스럽게 변환할 수 있어요. 예를 들어, \"운동은 건강에 좋습니다\"라는 문장이 \"저는 매일 아침 운동을 시작하면서 몸도 가벼워지고 기분도 좋아졌어요!\"로 바뀌는 거죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\"> ️ 2. 디테일 추가</span></h3>\n<p data-ke-size=\"size16\">GPTS는 글에 생동감을 더하기 위해 \"왜?\", \"어떻게?\"라는 질문을 던져서 더 구체적인 내용을 만들어내요. 예를 들어, \"차를 마셨다\" 대신 \"따뜻한 머그잔을 두 손으로 감싸고, 향긋한 녹차 향기를 맡으며 마음을 진정시켰다\"로 표현할 수 있게 돕습니다.</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #ee2323;\">  3. 독자와 소통하는 글쓰기</span></h3>\n<p data-ke-size=\"size16\">마치 독자와 대화를 나누는 것처럼, 질문을 던지거나 응원을 전하는 글을 작성할 수 있어요. \"여러분도 이런 경험 있으신가요?\" 같은 문장이 대표적이죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000; text-align: start;\" data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>GPTS로 검증</b></span></h2>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\">그림과 같이 '아보카도의 건간지방 구성과 특성'에 관련된 GPTS가 작성한 블로그 기사를 \"인간냄새\"로 재구성하였습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"인간냄새 적용전후.jpg\" data-origin-width=\"1115\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/dfgVdw/btsLN4V726m/zFKTpv7wZ9ssJjrbV91TkK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/dfgVdw/btsLN4V726m/zFKTpv7wZ9ssJjrbV91TkK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/dfgVdw/btsLN4V726m/zFKTpv7wZ9ssJjrbV91TkK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdfgVdw%2FbtsLN4V726m%2FzFKTpv7wZ9ssJjrbV91TkK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1115\" height=\"768\" data-filename=\"인간냄새 적용전후.jpg\" data-origin-width=\"1115\" data-origin-height=\"768\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">그런다음 한국형 AI 탐지기로 유명한 <a href=\"https://isgen.ai/ko\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://isgen.ai/ko</a> 에 확인한 결과는 아래와 같이 인간이 100% 작성했다고 나오는 군요. ㅎㅎ (물론 내용 따라 결과는 달라지니 참고하세요)&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"인간냄새 2.png\" data-origin-width=\"1163\" data-origin-height=\"794\"><span data-url=\"https://blog.kakaocdn.net/dn/9Vtbt/btsLM7F6DSp/KCz00gQ7QEtAHEwSx1GOSk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/9Vtbt/btsLM7F6DSp/KCz00gQ7QEtAHEwSx1GOSk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/9Vtbt/btsLM7F6DSp/KCz00gQ7QEtAHEwSx1GOSk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F9Vtbt%2FbtsLM7F6DSp%2FKCz00gQ7QEtAHEwSx1GOSk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"1163\" height=\"794\" data-filename=\"인간냄새 2.png\" data-origin-width=\"1163\" data-origin-height=\"794\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<blockquote data-ke-style=\"style1\"><i><span style=\"font-family: 'Noto Serif KR';\">인간냄새는 URL을 입력하면 해당 사이트의 내용도, PDF 를 입력하면 문서의 내용도 인간의 향기를 불어넣어 재구성 하니 참고하세요</span></i></blockquote>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>마치며</b></span></h2>\n<p data-ke-size=\"size16\">제가 만든 GPTS 챗봇은 단순히 글을 만드는 도구가 아니라, 글을 통해 독자와 진정한 연결을 만들어주는 도구예요. 여러분도 GPTS를 사용해 AI 글을 사람 냄새 나는 따뜻한 글로 바꿔보세요. 이 기술은 제가 상상했던 것보다 훨씬 더 많은 가능성을 열어줬고, 앞으로도 더 많은 사람들에게 도움을 줄 수 있기를 기대하고 있어요. 여러분의 글쓰기 여정에도 새로운 바람이 불길 바라며, 오늘 소개를 마칩니다. ✨</p>\n<hr data-ke-style=\"style1\" />\n<h2 data-ke-size=\"size26\">Q&amp;A</h2>\n<p data-ke-size=\"size16\"><b>❓ GPTS는 어떤 원리로 작동하나요?</b></p>\n<p data-ke-size=\"size16\">스토리텔링, 대화체, 감각적 묘사를 통해 글을 자연스럽게 바꿉니다.<br /><br /></p>\n<p data-ke-size=\"size16\"><b>❓ GPTS를 사용하면 누구에게 유리한가요?</b></p>\n<p data-ke-size=\"size16\">블로거, 콘텐츠 마케터, 작가 등 글을 작성하는 모든 사람에게 유용합니다.<br /><br /></p>\n<p data-ke-size=\"size16\"><b>❓ 직접 사용해보려면 어떻게 하나요?</b></p>\n<p data-ke-size=\"size16\">웹사이트에서 데모를 사용해 보거나, 정식 라이선스를 통해 GPTS를 경험해 보세요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"color: #000000; text-align: start;\" data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b> </b></span><span style=\"color: #009a87;\"><b><span>&nbsp;</span>GPTS 무료배포</b></span></h2>\n<p style=\"color: #333333; text-align: start;\" data-ke-size=\"size16\">&nbsp;약간의 지식과 시간만 투자하면 누구나 직접 제작하고 활용할 수 있는 유용한 GPTs가 이미 많이 존재합니다. 그러나 여전히 AI 기술에 대한 낯선 접근을 두려워하거나 IT 초보자, 또는 시간적 여유가 없거나 수익화에 대한 절실함 때문에 올바른 정보를 얻지 못하는 사람들이 많습니다. 이러한 심리를 악용해 과도한 가격으로 유료 강의를 판매하며 불필요한 부담을 주는 사례들이 늘어나고 있습니다.<span>&nbsp;</span><span style=\"color: #ee2323;\"><b>이에 본 블로그에서는 모든 사람이 AI의 혜택을 공정하고 자유롭게 누릴 수 있도록 GPTs를 무료로 배포하며, 불합리한 강의 판매 행위를 단호히 배척하고자 합니다.</b></span></p>\n<script async src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8195497734535830\"\n     crossorigin=\"anonymous\"></script>\n<ins class=\"adsbygoogle\"\n     style=\"display:block; text-align:center;\"\n     data-ad-layout=\"in-article\"\n     data-ad-format=\"fluid\"\n     data-ad-client=\"ca-pub-8195497734535830\"\n     data-ad-slot=\"1494233468\"></ins>\n<script>\n     (adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n<figure id=\"og_1736904319885\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"ChatGPT - 인간 냄새\" data-og-description=\"AI로 생성한 모든 글을 사람이 쓴 글로 재구성합니다.\" data-og-host=\"chatgpt.com\" data-og-source-url=\"https://chatgpt.com/g/g-6786ffee60c48191a207fb7e1dd4a2e3-ingan-naemsae\" data-og-url=\"https://chatgpt.com/g/g-6786ffee60c48191a207fb7e1dd4a2e3-ingan-naemsae\" data-og-image=\"\"><a href=\"https://chatgpt.com/g/g-6786ffee60c48191a207fb7e1dd4a2e3-ingan-naemsae\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://chatgpt.com/g/g-6786ffee60c48191a207fb7e1dd4a2e3-ingan-naemsae\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">ChatGPT - 인간 냄새</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">AI로 생성한 모든 글을 사람이 쓴 글로 재구성합니다.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">chatgpt.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<div id=\"gtx-trans\" style=\"position: absolute; left: -61px; top: 4787.97px;\">\n<div class=\"gtx-trans-icon\">&nbsp;</div>\n</div>\n<script type=\"application/ld+json\">\n  {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n      {\n        \"@type\": \"Question\",\n        \"name\": \"GPTS는 어떤 원리로 작동하나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"GPTS는 자연어 처리 기술을 기반으로 작동하며, 스토리텔링, 대화체, 감각적 묘사를 통해 글을 자연스럽고 매력적으로 변환합니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"GPTS를 사용하면 누구에게 유리한가요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"GPTS는 블로거, 콘텐츠 마케터, 작가 등 글을 작성하거나 편집하는 모든 사람들에게 유용합니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"직접 사용해보려면 어떻게 하나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"GPTS를 직접 경험하려면 공식 웹사이트에서 데모를 사용해 보거나, 정식 라이선스를 통해 이용해 보실 수 있습니다.\"\n        }\n      }\n    ]\n  }\n</script>",
        "contentSnippet": "사람 냄새 나는 AI 글쓰기, 어떻게 가능할까요? 제가 만든 챗봇, GPTS가 바로 그 답입니다! 자연스럽고 공감 가는 글을 만드는 비법을 지금 확인해 보세요.\n\n\n \n여러분, AI가 만든 글을 읽을 때 느낌이 어떠셨나요? 잘 쓰긴 했지만 뭔가 기계적인 냄새가 나는 것 같지 않으셨나요? 사실 저도 처음엔 AI 글을 보며 \"이걸 사람처럼 자연스럽게 바꾸려면 시간이 얼마나 걸릴까?\" 고민하곤 했어요. 하지만 그 고민을 해결하기 위해 직접 '인간냄새' GPTS를 만들게 되었습니다. 이 챗봇은 단순한 AI 텍스트 생성기를 넘어, 글에 진정성과 감정을 담아주는 역할을 해요. 오늘은 제가 만든 이 챗봇의 비밀을 여러분께 소개하려고 합니다.  \n \n왜 GPTS를 만들었나요?\n  AI 글쓰기의 한계\n제가 처음 AI가 작성한 글을 접했을 때, 놀라운 기술력에 감탄했지만, 뭔가 부족하다는 느낌이 들었어요. 정확히 말하면, 글에 사람 냄새가 없었어요. 우리가 글을 읽을 때 느끼는 따뜻함, 공감, 그리고 이야기를 듣는 듯한 편안함이 빠져 있었죠.\n예를 들어, AI는 \"이 도시는 아름답다\"라고 쓸 수 있지만, \"이 도시의 해변에서 바라본 석양은 마치 황금빛 물결 같았어요\"라는 식의 감성적인 묘사는 잘 하지 못하더라고요. 그래서 이런 문제를 해결하기 위해 독자의 마음을 움직이고, 진짜 대화를 나누는 것 같은 글을 만들어주는 GPTS를 개발하게 되었습니다.\n \n \nGPTS 챗봇의 주요 기능\n ️ 1. 사람처럼 말하기\nGPTS의 가장 큰 특징은 대화하듯이 글을 쓸 수 있다는 점이에요. 예를 들어, \"운동은 건강에 좋습니다\"라는 딱딱한 문장을 \"제가 매일 아침 스트레칭을 10분씩 하고 있는데요, 덕분에 하루가 훨씬 가볍게 시작되더라고요!\"처럼 바꿀 수 있답니다. 이렇게 대화체로 전환하면 글이 훨씬 더 따뜻하고 친근하게 느껴져요.\n \n  2. 감각적인 묘사 추가\n사람 냄새 나는 글을 만들기 위해 가장 중요한 건 감각적인 묘사예요. 예를 들어, \"맛있는 음식\"이라는 단어 대신, \"버터의 고소한 향이 퍼지고, 갓 구운 빵에서 올라오는 따뜻한 김이 느껴지더라고요\"라는 식으로 글에 생동감을 더하는 거죠. GPTS는 이런 디테일한 표현을 자동으로 만들어줘요.\n \n✍️ 3. 개인화된 스토리텔링\n사람들은 경험담에 더 관심을 가지죠. GPTS는 이 점을 활용해 글에 자연스럽게 이야기를 녹여줍니다. 예를 들어, \"효율적인 시간 관리 방법\"이라는 주제를 \"제가 시간 관리가 너무 어려워서 고민하다가 시작한 방법인데요...\"처럼 개인화된 경험으로 풀어낼 수 있게 도와줘요.\n \nGPTS의 작동 원리\nGPTS는 단순한 AI 텍스트 생성기가 아니에요. 몇 가지 특별한 알고리즘과 전략이 더해져서 사람처럼 자연스러운 글을 만들어냅니다.\n스토리텔링 기반: 독자가 공감할 수 있는 개인적인 경험과 상황을 중심으로 글을 작성합니다.\n대화형 어투 적용: 마치 친구와 이야기하는 듯한 톤으로 글을 작성합니다.\n구체적인 디테일 추가: 시각, 청각, 촉각 등을 자극하는 세밀한 묘사를 포함합니다.\n \nGPTS로 글을 재구성하는 방법\n\n\n  1. 기존 글을 대화체로 변환\n어떤 글이든 GPTS에 입력하면 대화하듯 자연스럽게 변환할 수 있어요. 예를 들어, \"운동은 건강에 좋습니다\"라는 문장이 \"저는 매일 아침 운동을 시작하면서 몸도 가벼워지고 기분도 좋아졌어요!\"로 바뀌는 거죠.\n \n ️ 2. 디테일 추가\nGPTS는 글에 생동감을 더하기 위해 \"왜?\", \"어떻게?\"라는 질문을 던져서 더 구체적인 내용을 만들어내요. 예를 들어, \"차를 마셨다\" 대신 \"따뜻한 머그잔을 두 손으로 감싸고, 향긋한 녹차 향기를 맡으며 마음을 진정시켰다\"로 표현할 수 있게 돕습니다.\n  3. 독자와 소통하는 글쓰기\n마치 독자와 대화를 나누는 것처럼, 질문을 던지거나 응원을 전하는 글을 작성할 수 있어요. \"여러분도 이런 경험 있으신가요?\" 같은 문장이 대표적이죠.\n \n \nGPTS로 검증\n그림과 같이 '아보카도의 건간지방 구성과 특성'에 관련된 GPTS가 작성한 블로그 기사를 \"인간냄새\"로 재구성하였습니다.\n\n\n \n그런다음 한국형 AI 탐지기로 유명한 https://isgen.ai/ko 에 확인한 결과는 아래와 같이 인간이 100% 작성했다고 나오는 군요. ㅎㅎ (물론 내용 따라 결과는 달라지니 참고하세요) \n\n\n \n \n인간냄새는 URL을 입력하면 해당 사이트의 내용도, PDF 를 입력하면 문서의 내용도 인간의 향기를 불어넣어 재구성 하니 참고하세요\n \n마치며\n제가 만든 GPTS 챗봇은 단순히 글을 만드는 도구가 아니라, 글을 통해 독자와 진정한 연결을 만들어주는 도구예요. 여러분도 GPTS를 사용해 AI 글을 사람 냄새 나는 따뜻한 글로 바꿔보세요. 이 기술은 제가 상상했던 것보다 훨씬 더 많은 가능성을 열어줬고, 앞으로도 더 많은 사람들에게 도움을 줄 수 있기를 기대하고 있어요. 여러분의 글쓰기 여정에도 새로운 바람이 불길 바라며, 오늘 소개를 마칩니다. ✨\nQ&A\n❓ GPTS는 어떤 원리로 작동하나요?\n스토리텔링, 대화체, 감각적 묘사를 통해 글을 자연스럽게 바꿉니다.\n\n❓ GPTS를 사용하면 누구에게 유리한가요?\n블로거, 콘텐츠 마케터, 작가 등 글을 작성하는 모든 사람에게 유용합니다.\n\n❓ 직접 사용해보려면 어떻게 하나요?\n웹사이트에서 데모를 사용해 보거나, 정식 라이선스를 통해 GPTS를 경험해 보세요.\n \n \n  GPTS 무료배포\n 약간의 지식과 시간만 투자하면 누구나 직접 제작하고 활용할 수 있는 유용한 GPTs가 이미 많이 존재합니다. 그러나 여전히 AI 기술에 대한 낯선 접근을 두려워하거나 IT 초보자, 또는 시간적 여유가 없거나 수익화에 대한 절실함 때문에 올바른 정보를 얻지 못하는 사람들이 많습니다. 이러한 심리를 악용해 과도한 가격으로 유료 강의를 판매하며 불필요한 부담을 주는 사례들이 늘어나고 있습니다. 이에 본 블로그에서는 모든 사람이 AI의 혜택을 공정하고 자유롭게 누릴 수 있도록 GPTs를 무료로 배포하며, 불합리한 강의 판매 행위를 단호히 배척하고자 합니다.\n\n\n\n     (adsbygoogle = window.adsbygoogle || []).push({});\n\n\n \nChatGPT - 인간 냄새\nAI로 생성한 모든 글을 사람이 쓴 글로 재구성합니다.\nchatgpt.com\n\n \n \n\n\n  {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n      {\n        \"@type\": \"Question\",\n        \"name\": \"GPTS는 어떤 원리로 작동하나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"GPTS는 자연어 처리 기술을 기반으로 작동하며, 스토리텔링, 대화체, 감각적 묘사를 통해 글을 자연스럽고 매력적으로 변환합니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"GPTS를 사용하면 누구에게 유리한가요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"GPTS는 블로거, 콘텐츠 마케터, 작가 등 글을 작성하거나 편집하는 모든 사람들에게 유용합니다.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"직접 사용해보려면 어떻게 하나요?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"GPTS를 직접 경험하려면 공식 웹사이트에서 데모를 사용해 보거나, 정식 라이선스를 통해 이용해 보실 수 있습니다.\"\n        }\n      }\n    ]\n  }",
        "guid": "http://muzbox.tistory.com/483526",
        "categories": [
          "AI, 미래기술/MY GPT 공개",
          "AI글쓰기",
          "ai텍스트편집",
          "AI활용법",
          "gpts챗봇",
          "감성글쓰기",
          "글쓰기도구",
          "대화형글쓰기",
          "사람냄새글쓰기",
          "스토리텔링ai",
          "자연스러운글쓰기"
        ],
        "isoDate": "2025-01-15T01:38:55.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "［RULIWEB］",
        "title": "[MULTI] 시리즈의 미래를 밝힐 긍정적 변화, 진 · 삼국무쌍 ORIGINS",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2280",
        "pubDate": "Thu, 16 Jan 2025 15:24:47 +0900",
        "author": "［RULIWEB］",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/25/01/16/1946dc8b4c75104c1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2025-01-16T06:24:47.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": [
      {
        "title": "인터넷을 처음 하던 날",
        "link": "https://jeho.page/essay/2025/01/21/internet-day1.html",
        "pubDate": "2025-01-21T09:55:00.000Z",
        "author": "김재호",
        "content": "<p>인터넷을 처음 접한 건 2000년 1월 1일이었습니다.<br />\n저 스스로도 놀라운 날짜입니다. 2000년 1월 1일이라니. 이런 우연이 다 있나..?<br />\n1990년대 내내 컴퓨터 앞에서 살았고, 1996년부터는 PC 통신도 많이 했습니다만, <strong>인터넷</strong>이라고 불리는 것은 한 번도 써보질 않았던 것입니다.</p>\n\n<p>1999년 말에는 2000년이 되면 밀레니엄 버그 때문에 난리가 날 거라고 떠들썩 했는데 막상 2000년 1월 1일이 되자 별다른 일은 일어나지 않았습니다.\n이 일이 어쩌면 영향이 있었던 건가? 처음으로 인터넷 익스플로러를 켜서 여기저기 사이트를 돌아다녔던 것 같습니다.</p>\n\n<p>와레즈라는 사이트를 그때 처음 알았습니다. 아니, 이런 세계가 있었단 말이야?<br />\nFIFA 2000을 다운로드하면서 잠이 들었었는데 50MB 쯤 되는 파일을 밤새도록 받았습니다.<br />\n(밤 10시부터 아침 9시까진가 통신 정액제가 있었던 것 같네요)</p>\n\n<p>다음 날 눈을 뜨자마자 반쯤 의심하며 실행해 봤는데 프로그램이 열리고 <a href=\"https://www.youtube.com/watch?v=ecrph82o6FU\">노래가 흘러나올 때</a> 두근거리고 기쁘던 감정을 아직 기억합니다.</p>\n\n<h1 id=\"인터넷과--pc--통신의-차이\">인터넷과  PC  통신의 차이</h1>\n<p>사실 저는 아직도 PC 통신과 인터넷의 차이를 잘 구분하지 못합니다만, 궁금해진 김에 챗지피티를 통해서 알아봤습니다.</p>\n\n<p>PC 통신은 TCP/IP로 연결했던 것이 아니라 시리얼 통신으로 연결했던 것 같습니다.<br />\n즉, 시리얼 포트에 모뎀을 꼽고 ‘01410’ 이란 번호로 전화 걸기 명령을 보내서 전화 연결을 하고, 서버에서는 역시 전화선을 통해 텍스트로 메뉴 구성을 알려줍니다.</p>\n\n<p>그 시절 PC 통신을 하기 위한 프로그램이었던 <code class=\"language-plaintext highlighter-rouge\">이야기</code>나 <code class=\"language-plaintext highlighter-rouge\">새롬데이터맨</code>은 다음처럼 짰을 것 같습니다.</p>\n\n<div class=\"language-c++ highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">HANDLE</span> <span class=\"n\">hCom</span> <span class=\"o\">=</span> <span class=\"n\">CreateFile</span><span class=\"p\">(</span>\n    <span class=\"s\">L\"COM1\"</span><span class=\"p\">,</span> <span class=\"c1\">// 모뎀이 꼽혀 있는 시리얼 포트</span>\n    <span class=\"n\">GENERIC_READ</span> <span class=\"o\">|</span> <span class=\"n\">GENERIC_WRITE</span><span class=\"p\">,</span>\n    <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"nb\">NULL</span><span class=\"p\">,</span>\n    <span class=\"n\">OPEN_EXISTING</span><span class=\"p\">,</span>\n    <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"nb\">NULL</span>\n<span class=\"p\">);</span>\n\n<span class=\"c1\">// 모뎀으로 전화 걸기 명령 전송 (하이텔의 전화번호 01410)</span>\n<span class=\"n\">WriteFile</span><span class=\"p\">(</span><span class=\"n\">hCom</span><span class=\"p\">,</span> <span class=\"s\">\"ATD01410</span><span class=\"se\">\\r\\n</span><span class=\"s\">\"</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">DWORD</span><span class=\"p\">)</span><span class=\"n\">strlen</span><span class=\"p\">(</span><span class=\"n\">atCmd</span><span class=\"p\">),</span> <span class=\"o\">&amp;</span><span class=\"n\">bytesWritten</span><span class=\"p\">,</span> <span class=\"nb\">NULL</span><span class=\"p\">);</span>\n\n<span class=\"c1\">// 서버로부터 ASCII 코드로 하이텔 대문을 받아와서 뿌려줌</span>\n\n<span class=\"c1\">// 메뉴 구성 보여주기</span>\n<span class=\"c1\">// (1) 게시판, (2) 자료실, (3) 채팅방</span>\n</code></pre></div></div>\n\n<p><code class=\"language-plaintext highlighter-rouge\">1</code>, <code class=\"language-plaintext highlighter-rouge\">2</code> 같은 메뉴의 번호를 별다른 프로토콜도 없이 raw string 에 가깝게 서버와 주고받았던 것 같네요.<br />\n채팅방 내에서 이상한 문자열을 입력해서 채팅방을 강제로 파괴하던 사람들이 있었는데, 이제야 어떻게 했는지 알 것 같습니다.</p>\n\n<p>지금 보면 참 조잡하지만, 이때 코딩하던 개발자들은 정말 신기하고 재밌었을 것 같습니다.<br />\n아마 새로운 세상을 창조해낸 기분 아니었을까?<br />\nPC 통신이 처음 시작되던 시절에 그런 기쁨을 함께 느껴보지 못했다는 게 아쉽습니다.</p>\n\n<p><img src=\"/assets/img/kitel.jpg\" alt=\"PC통신의 역사\" /><br />\n<em>넥슨컴퓨터 박물관, 2022년</em></p>\n\n<p><br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2022/11/05/old-memories-of-computers.html\">허큘리스 카드와 사운드 블라스터 그리고 PC통신</a></li>\n  <li><a href=\"https://brunch.co.kr/@buildingking/107\">넥슨 컴퓨터 박물관에 가는 날</a></li>\n</ul>",
        "contentSnippet": "인터넷을 처음 접한 건 2000년 1월 1일이었습니다.\n인터넷이라고 불리는 것은 한 번도 써보질 않았던 것입니다.\n1999년 말에는 2000년이 되면 밀레니엄 버그 때문에 난리가 날 거라고 떠들썩 했는데 막상 2000년 1월 1일이 되자 별다른 일은 일어나지 않았습니다.\n이 일이 어쩌면 영향이 있었던 건가? 처음으로 인터넷 익스플로러를 켜서 여기저기 사이트를 돌아다녔던 것 같습니다.\n와레즈라는 사이트를 그때 처음 알았습니다. 아니, 이런 세계가 있었단 말이야?\n다음 날 눈을 뜨자마자 반쯤 의심하며 실행해 봤는데 프로그램이 열리고 노래가 흘러나올 때 두근거리고 기쁘던 감정을 아직 기억합니다.\n인터넷과  PC  통신의 차이\n사실 저는 아직도 PC 통신과 인터넷의 차이를 잘 구분하지 못합니다만, 궁금해진 김에 챗지피티를 통해서 알아봤습니다.\nPC 통신은 TCP/IP로 연결했던 것이 아니라 시리얼 통신으로 연결했던 것 같습니다.\n그 시절 PC 통신을 하기 위한 프로그램이었던 이야기나 새롬데이터맨은 다음처럼 짰을 것 같습니다.\n\nHANDLE hCom = CreateFile(\n    L\"COM1\", // 모뎀이 꼽혀 있는 시리얼 포트\n    GENERIC_READ | GENERIC_WRITE,\n    0,\n    NULL,\n    OPEN_EXISTING,\n    0,\n    NULL\n);\n\n// 모뎀으로 전화 걸기 명령 전송 (하이텔의 전화번호 01410)\nWriteFile(hCom, \"ATD01410\\r\\n\", (DWORD)strlen(atCmd), &bytesWritten, NULL);\n\n// 서버로부터 ASCII 코드로 하이텔 대문을 받아와서 뿌려줌\n\n// 메뉴 구성 보여주기\n// (1) 게시판, (2) 자료실, (3) 채팅방\n\n\n1, 2 같은 메뉴의 번호를 별다른 프로토콜도 없이 raw string 에 가깝게 서버와 주고받았던 것 같네요.\n지금 보면 참 조잡하지만, 이때 코딩하던 개발자들은 정말 신기하고 재밌었을 것 같습니다.\n\n넥슨컴퓨터 박물관, 2022년\n\n함께 읽으면 좋은 글:\n허큘리스 카드와 사운드 블라스터 그리고 PC통신\n넥슨 컴퓨터 박물관에 가는 날",
        "summary": "인터넷을 처음 접한 건 2000년 1월 1일이었습니다. 저 스스로도 놀라운 날짜입니다. 2000년 1월 1일이라니. 이런 우연이 다 있나..? 1990년대 내내 컴퓨터 앞에서 살았고, 1996년부터는 PC 통신도 많이 했습니다만, 인터넷이라고 불리는 것은 한 번도 써보질 않았던 것입니다.",
        "id": "https://jeho.page/essay/2025/01/21/internet-day1",
        "isoDate": "2025-01-21T09:55:00.000Z"
      },
      {
        "title": "팀장님의 칭찬",
        "link": "https://jeho.page/essay/2025/01/20/praise-from-roy.html",
        "pubDate": "2025-01-20T08:54:00.000Z",
        "author": "김재호",
        "content": "<p>오랜만에 예전 팀 사람들과 점심을 함께했습니다.<br />\n거의 10년 가까이 못 본 친구들도 있었고, 우리 모두에게 존경받던 팀장님도 함께했습니다.</p>\n\n<p>다들 존경하고 우러러보던 팀장님의 그 시절 한 마디는 힘이 셌습니다.<br />\n팀장님이 뭔가 질문을 하면 다들 뜨끔할 정도로.</p>\n\n<p>중요한 뭔가를 놓치고 있거나, 흐리멍텅하게 일하고 있을 때.<br />\n긴장이 풀려있을 때면 어김없이 팀장님의 질문이 날아왔습니다.</p>\n\n<p>“벤자민, 이런 이런 부분도 고려하고 있는거니?”</p>\n\n<p>말이 질문이지, 사실은 정신 똑바로 차리고 일하라는 가르침이었습니다.</p>\n\n<p>다들 사고를 많이 쳐서 혼나기 일쑤였습니다만, 가끔 팀장이 칭찬을 해주실 때도 있었습니다.<br />\n누군가 칭찬을 받으면 팀원 모두가 부러워했습니다. 우와 팀장님한테 칭찬을 다 들었네.</p>\n\n<p>오늘 점심을 먹으면서 팀장님에게 칭찬을 들었습니다.<br />\n블로그 잘 읽고 있는데, 생각이 탄탄해서 좋다고.<br />\n팀장님도 미처 생각해보지 못한 이야기들이 있다고.<br />\n10년 전에 알던 저와는 많이 달라졌다고.</p>\n\n<p>우와, 이거 최고의 칭찬인 걸.<br />\n팀장님께 생각이 탄탄하단 소리를 듣다니.<br />\n같이 있던 동료들이 부러운 눈으로 쳐다봤습니다. 마치 10년 전 우리들처럼.</p>\n\n<p>저도 입이 찢어졌습니다.<br />\n회사 그만두고 혼자 지내면서 성장이 멈췄다고 생각했는데 그렇지 않았구나.<br />\n어쩌면 혼자 지내면서 더 많이 성장하게 된 건 아닐까?</p>\n\n<p>아무리 생각해도 기분이 좋아서 헤어지고 나서도 종일 헤벌쭉 해있는 걸 보니 저는 아직도 어린애입니다.(웃음)</p>\n\n<p><br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2021/09/10/왜-막내들은-항상-바깥쪽-자리에-앉아야-하나요.html\">왜 막내들은 항상 바깥쪽 자리에 앉아야 하나요?</a></li>\n  <li><a href=\"/essay/2021/11/02/윗사람과-아랫사람.html\">윗사람과 아랫사람</a></li>\n</ul>",
        "contentSnippet": "오랜만에 예전 팀 사람들과 점심을 함께했습니다.\n다들 존경하고 우러러보던 팀장님의 그 시절 한 마디는 힘이 셌습니다.\n중요한 뭔가를 놓치고 있거나, 흐리멍텅하게 일하고 있을 때.\n“벤자민, 이런 이런 부분도 고려하고 있는거니?”\n말이 질문이지, 사실은 정신 똑바로 차리고 일하라는 가르침이었습니다.\n다들 사고를 많이 쳐서 혼나기 일쑤였습니다만, 가끔 팀장이 칭찬을 해주실 때도 있었습니다.\n오늘 점심을 먹으면서 팀장님에게 칭찬을 들었습니다.\n우와, 이거 최고의 칭찬인 걸.\n저도 입이 찢어졌습니다.\n아무리 생각해도 기분이 좋아서 헤어지고 나서도 종일 헤벌쭉 해있는 걸 보니 저는 아직도 어린애입니다.(웃음)\n\n함께 읽으면 좋은 글:\n왜 막내들은 항상 바깥쪽 자리에 앉아야 하나요?\n윗사람과 아랫사람",
        "summary": "오랜만에 예전 팀 사람들과 점심을 함께했습니다. 거의 10년 가까이 못 본 친구들도 있었고, 우리 모두에게 존경받던 팀장님도 함께했습니다.",
        "id": "https://jeho.page/essay/2025/01/20/praise-from-roy",
        "isoDate": "2025-01-20T08:54:00.000Z"
      },
      {
        "title": "홈택스 칭찬",
        "link": "https://jeho.page/essay/2025/01/16/cheer-up-hometax.html",
        "pubDate": "2025-01-16T04:25:00.000Z",
        "author": "김재호",
        "content": "<p>부가세 신고를 하면서 홈택스에 구글의 인앱 결제 매출이 집계되기 시작했다는 걸 알았습니다.<br />\n구글에서 국세청으로 드디어 매출을 건네주기 시작한 것 같습니다.</p>\n\n<p>그동안은 매출을 건네주지 않고 있었냐? 그렇습니다.<br />\n구글이나 애플이 우리나라에 세금을 제대로 안 내고 있다는 말은 워낙 많았으니까요.</p>\n\n<p>구글이나 애플뿐만이 아니라 앱 개발자들도 매출을 누락시켜 신고하거나, 신고조차 하지 않는 사람들이 있었을 걸로 추측합니다.<br />\n어차피 국세청에서 모를 테니까. 이제 그런 탈세는 하지 못하게 되었습니다. 잘된 일입니다.<br />\n(굳이 강조하자면 <a href=\"https://withcoffee.app/\">커피한잔</a>은 돈을 거의 못 벌 때조차 항상 정직하게 매출을 신고했습니다.)</p>\n\n<p>저는 구글과 애플의 오랜 주주이고 이들이 세상 사람들의 돈을 다 긁어 모으는 것이 좋으면서도… <br />\n우리나라에 세금을 제대로 안 내는 부분은 영 못 마땅한 이중적인 입장에 있었습니다.<br />\n이제 드디어 구글이 세금을 제대로 내려는 의지를 보여줬으니 기쁘게 생각합니다. 애플도 얼른 매출 데이터를 보내주면 좋겠습니다.</p>\n\n<p>국세청에 대한 칭찬도 하고 싶습니다. 홈택스는 볼 때마다 편리한 기능이 추가되고 감탄하게 됩니다.<br />\n정부 사이트들 중 이렇게 서비스에 열심인 곳이 또 있을까?<br />\n돈 걷어야 해서 더 열심히 하는 것이겠지만 (ㅋㅋ) 그래도 괜찮습니다.<br />\n(거지같이 만들어 놓고 돈 걷는다 생각하면 얼마나 열받겠습니까?)</p>\n\n<p>홈택스는 <a href=\"https://www.sejungilbo.com/news/articleView.html?idxno=44309\">세무사들의 반발</a>때문에 혁신하기가 쉽지 않은 서비스이기도 합니다.<br />\n너무 잘 만들어버리면 영세한 세무사무실들은 문을 닫아야 할 테니.<br />\n그럼에도 불구하고 혁신의 의지가 느껴지는 유일한 정부 사이트 아닌가 생각합니다. 응원하고 있습니다.</p>\n\n<p>반면에 정부 사이트들 중 가장 한숨이 나오는 사이트는 법원 사이트입니다. 인터넷 등기소, 전자 소송.<br />\n2025년에도 https 조차되어있지 않고 밤늦은 시간이 되면 문을 닫는(?) 믿기 힘든 사이트.</p>\n\n<p>하지만 이런 법원 사이트도 며칠 후 개편될 예정입니다.<br />\n이제 정말 막바지 작업을 하고 있는 것 같습니다.</p>\n\n<p><img src=\"/assets/img/scourt.png\" alt=\"법원 사이트 개편\" /></p>\n\n<p>공지사항을 읽어보니 약간 걱정이 들기도 합니다.\n세상 어떤 사이트가 개편을 위한 작업 중단을 6일씩이나 하는 걸까? 아마 책임자는 큰 개편이니 충분히 시간을 확보하고 싶었을 것 같습니다.<br />\n하지만 사용자들 생각은 너무 뒷전인거 아닌가…?</p>\n\n<p>카톡, 당근, 쿠팡 같은 서비스가 5분이라도 멈췄을 때 서비스를 복구하기 위해 얼마나 애쓰는지 상상해 보면…<br />\n정부 관리자의 사용자를 배려하는 마음은 달라도 너무 다른 것 같습니다.<br />\n이런 감독하에 만들어진 사이트가 얼마나 좋아졌을지 염려가 되는 것도 사실입니다.</p>\n\n<p>제 염려가 무색할 만큼 좋은 사이트가 출시되길 기대합니다.</p>\n\n<p><br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2024/10/21/government-sponsored.html\">정부의 창업 지원 (비대면 바우처)</a></li>\n  <li><a href=\"/essay/2024/10/18/business-registration.html\">개인 사업자와 법인 사업자</a></li>\n</ul>",
        "contentSnippet": "부가세 신고를 하면서 홈택스에 구글의 인앱 결제 매출이 집계되기 시작했다는 걸 알았습니다.\n그동안은 매출을 건네주지 않고 있었냐? 그렇습니다.\n구글이나 애플뿐만이 아니라 앱 개발자들도 매출을 누락시켜 신고하거나, 신고조차 하지 않는 사람들이 있었을 걸로 추측합니다.\n커피한잔은 돈을 거의 못 벌 때조차 항상 정직하게 매출을 신고했습니다.)\n저는 구글과 애플의 오랜 주주이고 이들이 세상 사람들의 돈을 다 긁어 모으는 것이 좋으면서도… \n국세청에 대한 칭찬도 하고 싶습니다. 홈택스는 볼 때마다 편리한 기능이 추가되고 감탄하게 됩니다.\n홈택스는 세무사들의 반발때문에 혁신하기가 쉽지 않은 서비스이기도 합니다.\n반면에 정부 사이트들 중 가장 한숨이 나오는 사이트는 법원 사이트입니다. 인터넷 등기소, 전자 소송.\n하지만 이런 법원 사이트도 며칠 후 개편될 예정입니다.\n\n공지사항을 읽어보니 약간 걱정이 들기도 합니다.\n세상 어떤 사이트가 개편을 위한 작업 중단을 6일씩이나 하는 걸까? 아마 책임자는 큰 개편이니 충분히 시간을 확보하고 싶었을 것 같습니다.\n카톡, 당근, 쿠팡 같은 서비스가 5분이라도 멈췄을 때 서비스를 복구하기 위해 얼마나 애쓰는지 상상해 보면…\n제 염려가 무색할 만큼 좋은 사이트가 출시되길 기대합니다.\n\n함께 읽으면 좋은 글:\n정부의 창업 지원 (비대면 바우처)\n개인 사업자와 법인 사업자",
        "summary": "부가세 신고를 하면서 홈택스에 구글의 인앱 결제 매출이 집계되기 시작했다는 걸 알았습니다. 구글에서 국세청으로 드디어 매출을 건네주기 시작한 것 같습니다.",
        "id": "https://jeho.page/essay/2025/01/16/cheer-up-hometax",
        "isoDate": "2025-01-16T04:25:00.000Z"
      }
    ]
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": [
      {
        "title": "dbt 사용법과 기본 개념",
        "link": "https://zzsza.github.io/data-engineering/2025/01/16/dbt-core/",
        "pubDate": "Thu, 16 Jan 2025 00:00:00 +0000",
        "content": "<ul>\n  <li>이 글은 dbt 사용법(Data Build Tool)을 작성한 글입니다</li>\n  <li>예상 독자\n    <ul>\n      <li>dbt가 궁금하신 분</li>\n      <li>마트 모델링을 해야 하는 데이터 분석가, 데이터 엔지니어</li>\n    </ul>\n  </li>\n  <li>키워드 : dbt 사용법, dbt(data build tool), dbt 사용법, dbt 설치, dbt core</li>\n</ul>\n\n<hr />\n\n<h1 id=\"dbt란\">dbt란?</h1>\n<h2 id=\"dbt가-나오게-된-배경\">dbt가 나오게 된 배경</h2>\n<ul>\n  <li>과거엔 데이터 처리를 ETL 방식으로 진행(Extract - Trasnform - Load)\n    <ul>\n      <li>예 : 원본 데이터를 추출하고 Apache Spark를 사용해 바로 데이터를 변환해서 변환한 결과를 저장함</li>\n      <li>이 당시의 데이터 저장소 비용은 지금에 비하면 상대적으로 높았고, 컴퓨팅 파워도 제한적이였음</li>\n      <li>이렇게 처리할 때 원본 데이터를 그대로 저장하는 것은 비용 이슈 때문에 고민이 되던 시기</li>\n    </ul>\n  </li>\n  <li>클라우드 발전\n    <ul>\n      <li>클라우드가 발전하면서 클라우드 베이스의 데이터 웨어하우스가 등장했음(BigQuery, Snowflake, Redshift 등)\n        <ul>\n          <li>데이터 웨어하우스에서 저장 / 컴퓨팅을 분리하기 시작</li>\n        </ul>\n      </li>\n      <li>데이터 저장소 비용이 점점 저렴해짐(S3, GCS 비용)</li>\n      <li>위 발전 덕분에 ETL 방식에서 ELT 방식이 업계에서 알려지고, 채택되는 케이스가 많아짐</li>\n    </ul>\n  </li>\n  <li>ELT\n    <ul>\n      <li>Extract - Load - Transform</li>\n      <li>S3, DB 등에서 데이터를 추출하고, 추출한 데이터를 바로 데이터 웨어하우스에 불러옴(Load) 그 후에 불러온 데이터를 데이터 웨어하우스에서 목적에 맞게 Transform을 해서 저장함</li>\n      <li>데이터 웨어하우스에서 Transform을 할 때는 주로 SQL을 사용함. 과거엔 Apache Spark로 전처리를 하는 것이 필수였으나(물론 Spark도 SQL 방식이 요즘은 더 많이 사용되고 있으나, 과거엔 RDD 기반을 주로 사용하던 시기가 있었음) 이젠 더 쉽게 진행할 수 있게 됨</li>\n      <li>일단 데이터를 모두 가져오기 때문에 모든 데이터를 목적에 맞게 활용할 수 있음\n        <ul>\n          <li>Transform을 다시 실행할 때, 원본 데이터가 데이터 웨어하우스에 있어서 바로 다시 Transform을 실행하면 됨</li>\n          <li>같은 데이터여도 목적에 따라 다르게 전처리가 필요할 때도 유용함</li>\n        </ul>\n      </li>\n      <li>그러나 데이터를 모두 저장하는 것은 장점이기도 하지만, 사용되지 않는 데이터도 일단 다 저장해서 단점도 존재함(저장 비용의 증가)</li>\n      <li>사람들이 더 쉽게 데이터를 사용할 수 있게 되면서, 같은 지표인데 다르게 뽑는 경우가 생김. 예를 들어 DAU를 뽑아야 하는데, 부서마다 Active의 정의를 다르게 해서 CEO에게 보고함. CEO 입장에선 데이터가 달라서 의문을 제기하고, 데이터 조직에게 데이터를 확인해보라고 함\n        <ul>\n          <li>그래서 확인해보면, 조직 간 지표 정의가 달랐기 때문을 발견함</li>\n        </ul>\n      </li>\n      <li>위 문제를 해결하기 위해 데이터 조직에서 표준화 작업을 시작함. 이 때는 데이터 분석가가 하는 조직도 있고, 데이터 엔지니어가 하는 조직도 있음. 조직 상황에 따라 할 수 있는 사람들이 하기 시작함\n        <ul>\n          <li>처음엔 단순하게 Transform을 Spark나 Airflow 등으로 만들면서 관리함</li>\n          <li>그러나 이 방식은 코드나 쿼리가 길어서 가독성이 떨어져, 유지보수를 할 수 있는 사람이 적어지게 됨(만든 사람만 이해함)</li>\n          <li>또한 모델 정의가 다를 땐 전체적으로 다시 실행하는 과정이 필요해짐</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n  <li>이런 맥락에서 dbt가 등장함\n    <ul>\n      <li>데이터 웨어하우스에서 Transform 작업을 체계적으로 관리할 수 있게 해주는 도구</li>\n      <li>버전 관리나 테스팅도 지원하며, 문서도 만들 수 있어 많은 회사들에서 채택함(실리콘밸리에서 많이 채택했으며, 한국에서는 최근 1~2년부터 도입하는 중)</li>\n    </ul>\n  </li>\n</ul>\n\n<p><br /><br /></p>\n\n<h2 id=\"dbt-설명\">dbt 설명</h2>\n<ul>\n  <li>dbt : data build tool</li>\n  <li>dbt는 데이터 변환(transformation)에 특화된 도구. 데이터 엔지니어링에서 T 레이어에서 사용된다고 표현함</li>\n  <li>오픈소스인 dbt core와 클라우드 버전인 dbt cloud가 존재함\n    <ul>\n      <li>보통 회사에선 dbt core를 사용하고, Airflow나 dbt Web 화면을 직접 만들어서 쓰는 경우가 많음</li>\n    </ul>\n  </li>\n  <li>특징\n    <ul>\n      <li>모델을 구조화해서 관리할 수 있음\n        <ul>\n          <li>데이터 모델 : 데이터를 어떻게 정의할 것인지를 나타내는 것. 머신러닝이나 AI 모델과 다른 개념</li>\n          <li>SQL 쿼리를 복사 붙여넣기하는 것이 아닌 dbt에서 모델을 만들어서 그 결과 테이블을 사용할 수 있음</li>\n          <li>모델링하는 과정에서 복잡한 비즈니스 로직을 추가할 수 있음</li>\n        </ul>\n      </li>\n      <li>데이터 리니지 제공\n        <ul>\n          <li>집계된 데이터에서 어떤 데이터를 참고하는지를 알려주는 기능이 있는데, 이 기능이 리니지(lineage), 계보 기능</li>\n        </ul>\n      </li>\n      <li>Incremental 지원\n        <ul>\n          <li>회사에서 전체 데이터를 매일 가지고 오는 것은 DB에도 부담이 되고, 시간도 오래 걸림. 이럴 때 Incremental하게 증분 데이터만 가지고 오는 것이 필요. 이 부분을 지원하는 것도 장점</li>\n        </ul>\n      </li>\n      <li>데이터 퀄리티 테스트\n        <ul>\n          <li>데이터의 품질 테스트를 지원. 어떤 값이 있는지, 최소/최대값 등</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n</ul>\n\n<p><br /><br /></p>\n\n<h2 id=\"dbt-도입을-고려하면-좋은-조직\">dbt 도입을 고려하면 좋은 조직</h2>\n<ul>\n  <li>(1) 데이터 분석가, 데이터 엔지니어가 함께 일하는 조직\n    <ul>\n      <li>dbt는 SQL 사용해서 데이터 분석가도 모델을 만들 때 기여할 수 있음</li>\n      <li>그러나 데이터 분석가가 SQL을 못하는 경우도 존재함. Pandas 등을 사용해서 전처리를 하는 경우엔 SQL에 익숙해진 후에 도입하는 것을 추천함</li>\n    </ul>\n  </li>\n  <li>(2) 클라우드 데이터 웨어하우스를 사용하고 있는 조직\n    <ul>\n      <li>클라우드 기반 데이터 웨어하우스를 사용할 때 특히 더 좋음\n        <ul>\n          <li>이런 데이터 웨어하우스는 SQL로 데이터 처리를 할 수 있고, 보통 UDF 기능을 지원함</li>\n          <li>클라우드 데이터 웨어하우스의 인프라를 관리할 필요가 없기 때문에 클러스터 관리 등을 하지 않아도 괜찮음</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n  <li>(3) 데이터를 잘 활용하는 조직\n    <ul>\n      <li>데이터를 잘 활용하지 못하는 경우에 dbt를 도입하는 것은 비추천</li>\n      <li>데이터 성숙도 관점에서 모델링의 복잡성과 규모가 존재할 때 도입하는 것이 좋음</li>\n      <li>여러 소스의 데이터와 결합할 때 좋고, 단순하게 집계만 하려고 한다면 굳이 dbt를 사용하지 않아도 괜찮음</li>\n    </ul>\n  </li>\n  <li>데이터 파이프라인 관점\n    <ul>\n      <li>데이터 파이프라인이 복잡할 때, 리니지 기능이 빛을 낼 수 있기 때문에 복잡한 조직에서 추천함. 간단하다면 그냥 문서에 정리해도 괜찮을 수 있음</li>\n      <li>dbt cloud를 사용하지 않으면 Airflow나 dbt Web UI를 구성하는 것이 필요할 수 있음. 추가적으로 리소스가 든다는 것을 인지해야 함\n        <ul>\n          <li>구현해야 하는 기능\n            <ul>\n              <li>스케줄링 : Airflow에서 dbt run, test</li>\n              <li>알림/모니터링 : Slack 메시지 전송</li>\n              <li>대시보드 : Superset 등을 사용해 모델 지표 관리</li>\n              <li>CI/CD : Github Action 등을 사용해 배포</li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n</ul>\n\n<p><br /><br /></p>\n\n<h1 id=\"dbt-사용법\">dbt 사용법</h1>\n<h2 id=\"dbt-설치\">dbt 설치</h2>\n<ul>\n  <li>글 작성 기준 최신 버전 명시</li>\n</ul>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>pip3 install dbt-core==1.9.1\n</code></pre></div></div>\n\n<h2 id=\"1-프로젝트-생성\">(1) 프로젝트 생성</h2>\n<ul>\n  <li>CLI에서 아래 명령어 실행\n    <ul>\n      <li>jaffle_shop이란 프로젝트를 init</li>\n      <li>이미 프로젝트가 있다면 이 작업은 생략 가능</li>\n    </ul>\n  </li>\n</ul>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>dbt init jaffle_shop\n</code></pre></div></div>\n\n<p><br /></p>\n\n<h2 id=\"2-프로젝트-폴더-구조\">(2) 프로젝트 폴더 구조</h2>\n<ul>\n  <li>dbt init을 하면 기본적으로 폴더가 생성됨</li>\n  <li>\n    <p>dbt init 할 때 생기는 폴더</p>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  ├── README.md\n  ├── analyses\n  ├── dbt_project.yml\n  ├── macros\n  ├── models\n  │   └── example\n  │       ├── my_first_dbt_model.sql\n  │       ├── my_second_dbt_model.sql\n  │       └── schema.yml : 모델 정의\n  ├── seeds\n  ├── snapshots\n  └── tests\n</code></pre></div>    </div>\n\n    <ul>\n      <li>dbt_project.yml : dbt 프로젝트 설정</li>\n      <li>analyses/ : 임시 또는 일회성 분석을 위한 쿼리를 저장하는 폴더. dbt run을 해도 실행되지 않음</li>\n      <li>macros/ : 재사용 가능한 매크로를 저장</li>\n      <li>models/ : SQL 모델 파일들을 저장\n        <ul>\n          <li>보통 staging, intermediate, mart와 같이 하위 폴더로 구분</li>\n          <li>schema.yml : 모델에 대한 정의. model name, description, columns, data_tests 등이 존재</li>\n        </ul>\n      </li>\n      <li>seeds/ : CSV 파일 형태의 변하지 않는 데이터를 저장</li>\n      <li>snapshots/ : 데이터의 스냅샷을 찍기 위한 SQL 파일을 저장\n        <ul>\n          <li>dbt snapshot 명령어로 실행</li>\n        </ul>\n      </li>\n      <li>tests/ : 데이터 품질 테스트 정의</li>\n    </ul>\n  </li>\n</ul>\n\n<p><br /></p>\n\n<h2 id=\"3-모델-작성하기\">(3) 모델 작성하기</h2>\n<ul>\n  <li>모델 : 하나의 SQL 쿼리</li>\n  <li>쿼리의 결과가 데이터 웨어하우스의 테이블, VIEW로 저장됨</li>\n  <li>모델은 .sql 파일로 작성됨</li>\n  <li>‘참조(ref)’ 기능\n    <ul>\n      <li>특정 모델에서 다른 모델을 참조할 때, 테이블 이름을 직접 쓰는 대신 <code class=\"language-plaintext highlighter-rouge\">ref('model_name')</code> 함수를 사용함</li>\n      <li>이 기능을 사용해 모델 간의 의존성을 자동으로 추적함</li>\n    </ul>\n  </li>\n  <li>models/staging/stg_orders.sql 예시</li>\n</ul>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>\n-- models/staging/stg_orders.sql\n{{ config(materialized='table') }}\n\nSELECT\n    order_id,\n    customer_id,\n    order_date,\n    status,\n    amount\nFROM raw_data.orders\nWHERE status IS NOT NULL\n\n</code></pre></div></div>\n\n<ul>\n  <li>위 테이블을 사용해서 일별 주문 집계를 구하고 싶다면</li>\n</ul>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>\n-- models/intermediate/int_daily_orders.sql\n{{ config(materialized='table') }}\n\nSELECT \n    DATE_TRUNC('day', order_date) as date,\n    COUNT(DISTINCT order_id) as order_count,\n    COUNT(DISTINCT customer_id) as customer_count,\n    SUM(amount) as total_amount\nFROM {{ ref('stg_orders') }}\nGROUP BY date\n\n</code></pre></div></div>\n\n<ul>\n  <li>고객별 구매 이력을 만들 때는</li>\n</ul>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>\n\n-- models/marts/mart_customer_orders.sql\n{{ config(materialized='table') }}\n\nWITH customer_orders AS (\n    SELECT \n        customer_id,\n        COUNT(*) as total_orders,\n        SUM(amount) as total_spent,\n        MIN(order_date) as first_order_date,\n        MAX(order_date) as last_order_date\n    FROM {{ ref('stg_orders') }}\n    GROUP BY customer_id\n)\n\nSELECT \n    *,\n    DATEDIFF('day', first_order_date, last_order_date) as customer_lifetime_days\nFROM customer_orders\n\n</code></pre></div></div>\n\n<ul>\n  <li>config의 materialization은 SQL 쿼리의 결과를 데이터 웨어하우스에서 어떻게 저장할지를 의미함\n    <ul>\n      <li><strong>table</strong> : 실제 테이블로 저장. 데이터가 자주 변경되지 않고, 쿼리 성능이 중요할 경우 사용</li>\n      <li><strong>view</strong> : 쿼리를 뷰로 저장. 저장 공간을 절약할 수 있지만, 쿼리 성능이 떨어질 수 있음. 다만 원본 데이터가 바뀌면 바로 볼 수 있음(최신 데이터 확인 가능)</li>\n      <li><strong>incremental</strong> : 테이블에 새로운, 변경된 데이터만 추가함</li>\n      <li><strong>emphemeral</strong> : 실제로 물리화되지 않고, 다른 모델에서 참조될 때 서브 쿼리로 사용</li>\n    </ul>\n  </li>\n</ul>\n\n<p><br /></p>\n\n<h3 id=\"incremental-materilization\">Incremental Materilization</h3>\n<ul>\n  <li>자주 사용하는 패턴. 데이터를 증분만 처리</li>\n</ul>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>\n\n-- models/mart/web_analytics/daily_pageviews.sql\n{{ config(\n    materialized='incremental',\n    unique_key='page_date_key'\n) }}\n\nSELECT \n    date_trunc('day', timestamp) as visit_date,\n    page_url,\n    count(*) as pageviews,\n    count(distinct user_id) as unique_visitors,\n    concat(date_trunc('day', timestamp), '-', page_url) as page_date_key\nFROM {{ ref('stg_page_visits') }}\n{% if is_incremental() %}\n    WHERE timestamp &gt;= (SELECT max(visit_date) FROM ]{{ this }})\n{% endif %}\nGROUP BY 1, 2, 5\n\n</code></pre></div></div>\n\n<ul>\n  <li>config에서 incremental을 명시하고, unique_key를 추가함\n    <ul>\n      <li>증분 업데이트를 할 때 사용할 id를 의미함</li>\n      <li>unique_key는 고유한 값이어야 하며, 여러 컬럼을 조합해서 사용할 수도 있음</li>\n      <li>NULL이 있으면 안됨</li>\n    </ul>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    \n\n  {{ config(\n      materialized='incremental',\n      unique_key=['date_key', 'product_id', 'store_id'] \n  ) }}\n    \n</code></pre></div>    </div>\n  </li>\n  <li>아래 if is_incremental()은 증분이 있는지 확인하는 것\n    <ul>\n      <li>이미 처리된 테이블이 있는 경우 실행하며, this는 현재 모델의 테이블을 의미</li>\n      <li>timestamp 기준으로 현재 테이블에 저장된 최근 값(max(visit_date))보다 이후 데이터만 가져옴</li>\n    </ul>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    \n\n  {% if is_incremental() %}\n      -- 이미 처리된 테이블이 있는 경우에만 실행\n      WHERE timestamp &gt;= (SELECT max(visit_date) FROM {{ this }})\n      -- {{ this }}는 현재 생성되는 테이블을 참조\n  {% endif %}\n    \n</code></pre></div>    </div>\n  </li>\n  <li>\n    <p>insert, update를 모두 고려하고 싶다면 아래와 같이 작성</p>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    \n\n  {% if is_incremental() %}\n      WHERE created_at &gt;= (SELECT max(created_at) FROM {{ this }})\n      OR updated_at &gt;= (SELECT max(updated_at) FROM {{ this }})\n  {% endif %}\n    \n</code></pre></div>    </div>\n  </li>\n</ul>\n\n<p><br /></p>\n\n<h2 id=\"4-모델을-저장하는-방식\">(4) 모델을 저장하는 방식</h2>\n<ul>\n  <li>models 하위 폴더 구조를 고민하는 것이 필요함\n    <ul>\n      <li>dbt는 여러 직무에서 같이 협업하며 사용할 수 있기 때문에 협업에 최적화된 패턴을 고려해야 함</li>\n      <li>일관되고 이해하기 쉬운 구조를 만들어야 하며, 정답이 있는 것보단 조직 상황에 따라 다름</li>\n    </ul>\n  </li>\n  <li>다양한 방식이 있지만, 대표적인 2가지 공유</li>\n</ul>\n\n<p><br /></p>\n\n<h3 id=\"대표적인-방식--비즈니스-도메인-맞춤\">대표적인 방식 : 비즈니스 도메인 맞춤</h3>\n<ul>\n  <li>dbt에서 가이드로 주고 있는 형태\n    <ul>\n      <li>staging : 초기 정제</li>\n      <li>intermediate : 중간 집계나 조인</li>\n      <li>mart : 최종 분석용 테이블\n        <ul>\n          <li>비즈니스 도메인 별로 구분</li>\n        </ul>\n      </li>\n      <li>이런 구성을 사용하면 파일 이름만 봐도 흐름이 명확해짐</li>\n    </ul>\n  </li>\n</ul>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>models/\n├── staging/\n│   ├── stg_orders.sql\n│   └── stg_customers.sql\n├── intermediate/\n│   ├── int_order_payments.sql\n│   └── int_customer_orders.sql\n└── mart/\n    ├── finance/\n    │   ├── daily_revenue.sql\n    │   └── monthly_profit.sql\n    ├── marketing/\n    │   ├── customer_segments.sql\n    │   └── campaign_performance.sql\n    └── product/\n        ├── product_metrics.sql\n        └── inventory_analysis.sql\n</code></pre></div></div>\n\n<p><br /></p>\n\n<h3 id=\"다른-방식--fact--dimension\">다른 방식 : Fact / Dimension</h3>\n<ul>\n  <li>Kimball의 차원 모델링 방식\n    <ul>\n      <li>Facts / Dimension 관점으로 처리</li>\n      <li>staging, intermediate는 동일</li>\n    </ul>\n  </li>\n  <li>Fact(팩트) 테이블\n    <ul>\n      <li>비즈니스 프로세스의 측정값/메트릭을 저장</li>\n      <li>주로 숫자형 데이터(금액, 수량 등)</li>\n      <li>매우 자주 업데이트되고 크기가 계속 증가</li>\n    </ul>\n  </li>\n  <li>Dimension(디멘전, 차원) 테이블\n    <ul>\n      <li>비즈니스 엔티티의 속성 정보를 저장</li>\n      <li>주로 텍스트/카테고리형 데이터</li>\n      <li>상대적으로 천천히 변함</li>\n    </ul>\n  </li>\n  <li>이 방식의 장점\n    <ul>\n      <li>명확한 분리 : 팩트, 디멘전을 나눠서 각각의 업데이트 주기와 처리 방식을 나눔</li>\n      <li>쿼리 최적화 : 차원 테이블은 작고 자주 JOIN되어서 캐싱, 팩트 테이블은 필요한 컬럼만 포함해 효율적</li>\n      <li>유지보수 : 속성 변경은 차원 테이블에서만 관리함. 새로운 값은 팩트 테이블에만 추가</li>\n    </ul>\n  </li>\n</ul>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>models/\n├── staging/      # 원본 데이터 정제\n├── intermediate/ # 중간 처리\n└── marts/\n    ├── facts/    # 측정값이 있는 팩트 테이블\n    │   ├── fct_orders.sql\n    │   └── fct_page_views.sql\n    └── dimensions/  # 차원 테이블\n        ├── dim_customers.sql\n        └── dim_products.sql\n</code></pre></div></div>\n\n<ul>\n  <li>\n    <p>Fact, Dimension 결과를 사용하는 예시 쿼리</p>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    \n  SELECT \n      d.customer_segment,\n      d.country,\n      COUNT(DISTINCT f.order_id) as total_orders,\n      SUM(f.total_amount) as total_revenue\n  FROM {{ ref('fct_orders') }} f\n  JOIN {{ ref('dim_customers') }} d\n      ON f.customer_id = d.customer_id\n  GROUP BY 1, 2\n    \n</code></pre></div>    </div>\n  </li>\n</ul>\n\n<p><br /></p>\n\n<h2 id=\"5-모델-실행--test\">(5) 모델 실행 &amp; Test</h2>\n<ul>\n  <li>모델 파일을 작성한 후, 실행 및 테스트를 진행해야 함</li>\n  <li>dbt run 명령어로 실행할  수 있음\n    <ul>\n      <li>+을 붙이면 의존된 모델을 실행함</li>\n      <li>앞에 붙이면 상위 의존성, 뒤에 붙이면 하위 의존성</li>\n      <li>추가적인 내용은 <a href=\"https://docs.getdbt.com/reference/node-selection/graph-operators\">dbt Graph Operator Docs</a></li>\n    </ul>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  # 특정 모델 실행\n  dbt run --select my_model \n    \n  # 하위 의존성 모델 포함해 실행\n  dbt run --select my_model+\n     \n  # 상위 의존성 모델 포함\n  dbt run --select +my_model  \n    \n  # 상위와 하위 의존성 모델 모두 포함\n  dbt run --select +my_model+\n</code></pre></div>    </div>\n  </li>\n  <li>dbt run 관련 문법은 <a href=\"https://docs.getdbt.com/reference/node-selection/syntax\">Doc</a> 참고\n    <ul>\n      <li>Argument는 <code class=\"language-plaintext highlighter-rouge\">--select</code>, <code class=\"language-plaintext highlighter-rouge\">--exclue</code>, <code class=\"language-plaintext highlighter-rouge\">--selector</code>, <code class=\"language-plaintext highlighter-rouge\">--defer</code>가 있음</li>\n      <li>특정 모델, 그룹만 실행하고 싶을 땐 –select 를 사용하면 됨</li>\n    </ul>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  dbt run --select \"my_dbt_project_name\"  # 프로젝트의 모든 모델\n  dbt run --select \"my_dbt_model\"         # 특정 모델만\n  dbt run --select \"path/to/my/models\"    # 특정 디렉토리의 모든 모델\n  dbt run --select \"tag:nightly\"          # \"nightly\" 태그가 있는 모델들\n</code></pre></div>    </div>\n  </li>\n  <li>만약 문법 검사를 하고 싶다면 dbt compile로 확인할 수 있음\n    <ul>\n      <li>모델 참조 확인, SQL 문법 등</li>\n    </ul>\n  </li>\n</ul>\n\n<p><br /></p>\n\n<h3 id=\"증분-모델-전체-재실행\">증분 모델 전체 재실행</h3>\n<ul>\n  <li>일반적인 증분 모델도 동일하게 dbt run으로 실행함</li>\n  <li>그러나 처음부터 다시 실행해야 할 경우엔 –full-refresh 인자와 실행\n    <ul>\n      <li>Incremental 모델의 스키마가 변경되어 다시 만들어야 하는 경우</li>\n      <li>새로운 논리가 추가되어 모델 전체를 다시 처리</li>\n      <li>내부적으로 기존 테이븡를 DROP하고 모든 데이터를 새로 계산해 적재함(탐색하는 범위에 비용을 부과하는 데이터 웨어하우스에선 비용이 많이 드는 행위일 수 있음)</li>\n    </ul>\n  </li>\n</ul>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>db run --full-refresh --select my_model\n</code></pre></div></div>\n\n<p><br /></p>\n\n<h3 id=\"dbt-test\">dbt Test</h3>\n<ul>\n  <li>dbt test는 2가지로 구성됨\n    <ul>\n      <li>generic\n        <ul>\n          <li><code class=\"language-plaintext highlighter-rouge\">models/{모델_파일}</code>이 있는 폴더에 저장된 <code class=\"language-plaintext highlighter-rouge\">schema.yml</code>에 저장함</li>\n          <li>특정 컬럼이 Unique인가? Not Null인가?</li>\n          <li>relationship : 특정 테이블의 컬럼에 존재하는 값인지</li>\n          <li>accepted_values : 지정된 값만 있는지</li>\n          <li>dbt_expectations(추가 패키지 설치 필요) : <a href=\"https://hub.getdbt.com/calogica/dbt_expectations/latest/\">dbt hub</a> 참고. 여러 Test가 존재함</li>\n        </ul>\n      </li>\n    </ul>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  # models/intermediate/schema.yml\n  version: 2\n  models:\n    - name: int_daily_sales\n      columns:\n        - name: date\n          tests:\n            - not_null\n            - unique:\n                combination_of: [date, product_id]\n        - name: daily_sales\n          tests:\n            - not_null\n            - positive_value\n</code></pre></div>    </div>\n\n    <ul>\n      <li>singular\n        <ul>\n          <li><code class=\"language-plaintext highlighter-rouge\">tests</code> 폴더에 .sql 파일로 정의함</li>\n          <li>복잡한 비즈니스 로직을 주로 저장함</li>\n          <li>실패 케이스를 반환하는 SQL 쿼리 작성\n            <ul>\n              <li>아래 쿼리는 결과 row가 0건이면 성공, 1건 이상이면 실패를 의미</li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n    </ul>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    \n\n  -- tests/assert_total_payment_amount_is_positive.sql\n  SELECT\n      order_id,\n      total_amount\n  FROM {{ ref('orders') }}\n  WHERE total_amount &lt; 0\n    \n</code></pre></div>    </div>\n\n    <ul>\n      <li>매출 합계와 일별 매출의 합이 같은지 확인하고 싶은 경우</li>\n    </ul>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    \n\n  -- 매출 합계가 일별 매출의 합과 같은지 확인\n  SELECT \n      CASE \n          WHEN total_revenue != daily_sum THEN '정합성 확인 필요'\n      END as check_result\n  FROM (\n      SELECT \n          SUM(revenue) as total_revenue\n      FROM {{ ref('revenue') }}\n  ) t1\n  CROSS JOIN (\n      SELECT \n          SUM(daily_revenue) as daily_sum\n      FROM {{ ref('daily_revenue') }}\n  ) t2\n  WHERE total_revenue != daily_sum\n    \n</code></pre></div>    </div>\n  </li>\n  <li>dbt test 명령어로 실행</li>\n</ul>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>dbt test # 모든 테스트\ndbt test --select my_model  # 특정 모델의 테스트만\ndbt test --select test_type:generic # generic 테스트만\ndbt test --select test_type:singular # singular 테스트만\ndbt test --select result:fail #실패한 테스트만 재실행\n\n</code></pre></div></div>\n\n<p><br /></p>\n\n<h2 id=\"6-dbt-build\">(6) dbt build</h2>\n<ul>\n  <li>build = run + test + snapshot + seed 모두 한번에 실행</li>\n  <li>실행 순서\n    <ul>\n      <li>Seedfile Load</li>\n      <li>Model Run</li>\n      <li>Snapshot Run</li>\n      <li>Test run</li>\n      <li>모델을 만들고, 테스트를 실행하는 과정</li>\n    </ul>\n  </li>\n</ul>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>dbt build --select my_model\n</code></pre></div></div>\n\n<p><br /></p>\n\n<h3 id=\"언제-build를-하는가\">언제 build를 하는가?</h3>\n<ul>\n  <li>모델 개발, 테스트 작성할 때는 run, test를 각각 하는 것이 효율적</li>\n  <li>build는 Airflow에서 주기적으로 실행하곤 함\n    <ul>\n      <li>하지만 조직에 따라선 build를 안하고 dbt run만 하는 경우도 존재함(Test까지 하는 것이 이상적이나 현실적으로 Test를 많이 챙기려면 시간이 더 들기 때문에)</li>\n    </ul>\n  </li>\n  <li>빌드 시간을 줄이기 위해 수정된 것만 빌드하는 인자도 존재</li>\n</ul>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>dbt build --select state:modified+ --defer --state path/to/prod/artifacts\n</code></pre></div></div>\n\n<ul>\n  <li>state:modified+ : 변경된 모델과 의존된 다운스트림만 실행\n    <ul>\n      <li>state path: 프로덕션 환경의 상태와 비교해 어떤 모델이 변경되었나 확인</li>\n    </ul>\n  </li>\n  <li>defer : 변경되지 않은 모델은 프로덕션 데이터 참조</li>\n</ul>\n\n<p><br /></p>\n\n<h1 id=\"추가로-고려할-것들\">추가로 고려할 것들</h1>\n<ul>\n  <li>기존에 SQL 기반으로 마트를 만들었다면 마이그레이션이 필요함\n    <ul>\n      <li><a href=\"https://learn.getdbt.com/courses/refactoring-sql-for-modularity\">Refactoring SQL for Modularity Course</a> 추천</li>\n    </ul>\n  </li>\n  <li>dbt docs 배포\n    <ul>\n      <li>dbt model에 대한 내용을 문서로 배포해, 사내 구성원들이 볼 수 있게 해야 함</li>\n      <li><a href=\"https://medium.com/iotrustlab/dbt-docs-site-hosting-guide-24c2d08e277f\">김진석님의 dbt Docs 사내 공유 방법 feat. 사이트 호스팅 가이드</a> 추천</li>\n    </ul>\n  </li>\n  <li>대시보드와 통합하기 : <a href=\"https://github.com/lightdash/lightdash\">lightdash</a> 추천\n    <ul>\n      <li><a href=\"https://aibunny.medium.com/hands-on-guide-to-data-modeling-with-dbt-and-visualization-with-lightdash-f6bf3c0a2b36\">Hands-on Guide to Data Modeling with dbt and Visualization with Lightdash</a></li>\n    </ul>\n  </li>\n  <li>dbt + Airflow(스케줄링 도구)\n    <ul>\n      <li>주기적으로 실행하기 위해 Airflow 같은 도구와 통합 필요</li>\n      <li>또는 GitHub Action에서 실행할 수도 있음</li>\n    </ul>\n  </li>\n  <li>dbt metrics을 활용해 지표 집계\n    <ul>\n      <li><a href=\"https://docs.getdbt.com/docs/build/build-metrics-intro\">Build your metrics</a></li>\n      <li><a href=\"https://docs.getdbt.com/docs/use-dbt-semantic-layer/dbt-sl\">dbt Semantic Layer</a></li>\n    </ul>\n  </li>\n  <li>dbt utils 확인하기\n    <ul>\n      <li><a href=\"https://github.com/dbt-labs/dbt-utils\">dbt utils</a>에 유용한 함수들이 많이 존재함</li>\n    </ul>\n  </li>\n  <li>dbt + 데이터 웨어하우스\n    <ul>\n      <li>이번 글은 dbt에 대한 전반적인 소개를 목적으로 한 글이라 이 내용을 포함하진 않았으나, 다음 글은 dbt + 데이터 웨어하우스 글을 작성할 예정</li>\n    </ul>\n  </li>\n  <li>dbt와 유사한 역할을 하는 도구는 dbt 외에도 <a href=\"https://sqlmesh.com/\">SQLMesh</a>라는 것도 존재함. dbt가 초반 러닝커브가 높은데(Jinja 템플릿을 활용) 이 부분\n    <ul>\n      <li>궁금하다면 <a href=\"https://kestra.io/blogs/2024-02-28-dbt-or-sqlmesh\">Is It Time To Move From dbt to SQLMesh?</a> 추천. SQLMesh가 더 좋은 부분도 있으나 dbt가 생태계가 더 큼. 마치 Airflow가 배치 스케줄링에서 제일 점유율이 높고, Prefect나 다른 도구들이 계속 발전하는 것과 유사한 느낌\n        <ul>\n          <li>그러나 아직 dbt를 도입하지 않았다면 SQLMesh를 도입하는 것도 괜찮다고 생각. dbt를 쓰다가 옮기는 것은 고민됨</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n</ul>\n\n<p><br /></p>\n\n<h1 id=\"추천-자료\">추천 자료</h1>\n<ul>\n  <li><a href=\"https://www.meetup.com/ko-KR/seoul-dbt-meetup/\">Seoul dbt Meetup</a> : dbt 행사를 종종 여시는데, dbt 사용자라면 참석 추천</li>\n  <li><a href=\"https://tech.socarcorp.kr/data/2022/07/25/analytics-engineering-with-dbt.html\">(쏘카) 데이터에 신뢰성과 재사용성까지, Analytics Engineering with dbt</a></li>\n  <li><a href=\"https://medium.com/daangn/dbt%EC%99%80-airflow-%EB%8F%84%EC%9E%85%ED%95%98%EB%A9%B0-%EB%A7%88%EC%A3%BC%ED%95%9C-7%EA%B0%80%EC%A7%80-%EB%AC%B8%EC%A0%9C%EB%93%A4-61250a9904ab\">(당근) DBT와 Airflow 도입하며 마주한 7가지 문제들</a>\n    <ul>\n      <li><a href=\"https://youtu.be/m9lGtlxRJC4?si=7Y231BJQlIkpU9nW\">Do you know DBT?</a></li>\n    </ul>\n  </li>\n  <li><a href=\"https://medium.com/iotrustlab/data-warehouse-with-dbt-b65be67750e9\">dbt를 통한 데이터 웨어하우스 개발 후기</a></li>\n  <li><a href=\"https://blog.doctor-cha.com/building-autopedia-data-warehouse\">오토피디아 데이터 웨어하우스 구축하기</a></li>\n</ul>\n\n<p><br /><br /></p>\n\n<ul>\n  <li>글 작성하는데 걸린 시간 : 3시간 33분\n    <ul>\n      <li>하고자 하는 이야기, 개요 정리 : 13분</li>\n      <li>초안 글 작성 : 2시간 50분</li>\n      <li>클로드와 셀프 글 피드백 : 30분</li>\n    </ul>\n  </li>\n  <li>간단 회고\n    <ul>\n      <li>dbt + BigQuery까지 쓰려니까 내용이 너무 많아져서 두번째 글을 작성할 예정</li>\n    </ul>\n  </li>\n</ul>\n",
        "contentSnippet": "이 글은 dbt 사용법(Data Build Tool)을 작성한 글입니다\n예상 독자\n    \ndbt가 궁금하신 분\n마트 모델링을 해야 하는 데이터 분석가, 데이터 엔지니어\n키워드 : dbt 사용법, dbt(data build tool), dbt 사용법, dbt 설치, dbt core\ndbt란?\ndbt가 나오게 된 배경\n과거엔 데이터 처리를 ETL 방식으로 진행(Extract - Trasnform - Load)\n    \n예 : 원본 데이터를 추출하고 Apache Spark를 사용해 바로 데이터를 변환해서 변환한 결과를 저장함\n이 당시의 데이터 저장소 비용은 지금에 비하면 상대적으로 높았고, 컴퓨팅 파워도 제한적이였음\n이렇게 처리할 때 원본 데이터를 그대로 저장하는 것은 비용 이슈 때문에 고민이 되던 시기\n클라우드 발전\n    \n클라우드가 발전하면서 클라우드 베이스의 데이터 웨어하우스가 등장했음(BigQuery, Snowflake, Redshift 등)\n        \n데이터 웨어하우스에서 저장 / 컴퓨팅을 분리하기 시작\n데이터 저장소 비용이 점점 저렴해짐(S3, GCS 비용)\n위 발전 덕분에 ETL 방식에서 ELT 방식이 업계에서 알려지고, 채택되는 케이스가 많아짐\nELT\n    \nExtract - Load - Transform\nS3, DB 등에서 데이터를 추출하고, 추출한 데이터를 바로 데이터 웨어하우스에 불러옴(Load) 그 후에 불러온 데이터를 데이터 웨어하우스에서 목적에 맞게 Transform을 해서 저장함\n데이터 웨어하우스에서 Transform을 할 때는 주로 SQL을 사용함. 과거엔 Apache Spark로 전처리를 하는 것이 필수였으나(물론 Spark도 SQL 방식이 요즘은 더 많이 사용되고 있으나, 과거엔 RDD 기반을 주로 사용하던 시기가 있었음) 이젠 더 쉽게 진행할 수 있게 됨\n일단 데이터를 모두 가져오기 때문에 모든 데이터를 목적에 맞게 활용할 수 있음\n        \nTransform을 다시 실행할 때, 원본 데이터가 데이터 웨어하우스에 있어서 바로 다시 Transform을 실행하면 됨\n같은 데이터여도 목적에 따라 다르게 전처리가 필요할 때도 유용함\n그러나 데이터를 모두 저장하는 것은 장점이기도 하지만, 사용되지 않는 데이터도 일단 다 저장해서 단점도 존재함(저장 비용의 증가)\n사람들이 더 쉽게 데이터를 사용할 수 있게 되면서, 같은 지표인데 다르게 뽑는 경우가 생김. 예를 들어 DAU를 뽑아야 하는데, 부서마다 Active의 정의를 다르게 해서 CEO에게 보고함. CEO 입장에선 데이터가 달라서 의문을 제기하고, 데이터 조직에게 데이터를 확인해보라고 함\n        \n그래서 확인해보면, 조직 간 지표 정의가 달랐기 때문을 발견함\n위 문제를 해결하기 위해 데이터 조직에서 표준화 작업을 시작함. 이 때는 데이터 분석가가 하는 조직도 있고, 데이터 엔지니어가 하는 조직도 있음. 조직 상황에 따라 할 수 있는 사람들이 하기 시작함\n        \n처음엔 단순하게 Transform을 Spark나 Airflow 등으로 만들면서 관리함\n그러나 이 방식은 코드나 쿼리가 길어서 가독성이 떨어져, 유지보수를 할 수 있는 사람이 적어지게 됨(만든 사람만 이해함)\n또한 모델 정의가 다를 땐 전체적으로 다시 실행하는 과정이 필요해짐\n이런 맥락에서 dbt가 등장함\n    \n데이터 웨어하우스에서 Transform 작업을 체계적으로 관리할 수 있게 해주는 도구\n버전 관리나 테스팅도 지원하며, 문서도 만들 수 있어 많은 회사들에서 채택함(실리콘밸리에서 많이 채택했으며, 한국에서는 최근 1~2년부터 도입하는 중)\n\n\n\ndbt 설명\ndbt : data build tool\ndbt는 데이터 변환(transformation)에 특화된 도구. 데이터 엔지니어링에서 T 레이어에서 사용된다고 표현함\n오픈소스인 dbt core와 클라우드 버전인 dbt cloud가 존재함\n    \n보통 회사에선 dbt core를 사용하고, Airflow나 dbt Web 화면을 직접 만들어서 쓰는 경우가 많음\n특징\n    \n모델을 구조화해서 관리할 수 있음\n        \n데이터 모델 : 데이터를 어떻게 정의할 것인지를 나타내는 것. 머신러닝이나 AI 모델과 다른 개념\nSQL 쿼리를 복사 붙여넣기하는 것이 아닌 dbt에서 모델을 만들어서 그 결과 테이블을 사용할 수 있음\n모델링하는 과정에서 복잡한 비즈니스 로직을 추가할 수 있음\n데이터 리니지 제공\n        \n집계된 데이터에서 어떤 데이터를 참고하는지를 알려주는 기능이 있는데, 이 기능이 리니지(lineage), 계보 기능\nIncremental 지원\n        \n회사에서 전체 데이터를 매일 가지고 오는 것은 DB에도 부담이 되고, 시간도 오래 걸림. 이럴 때 Incremental하게 증분 데이터만 가지고 오는 것이 필요. 이 부분을 지원하는 것도 장점\n데이터 퀄리티 테스트\n        \n데이터의 품질 테스트를 지원. 어떤 값이 있는지, 최소/최대값 등\n\n\n\ndbt 도입을 고려하면 좋은 조직\n(1) 데이터 분석가, 데이터 엔지니어가 함께 일하는 조직\n    \ndbt는 SQL 사용해서 데이터 분석가도 모델을 만들 때 기여할 수 있음\n그러나 데이터 분석가가 SQL을 못하는 경우도 존재함. Pandas 등을 사용해서 전처리를 하는 경우엔 SQL에 익숙해진 후에 도입하는 것을 추천함\n(2) 클라우드 데이터 웨어하우스를 사용하고 있는 조직\n    \n클라우드 기반 데이터 웨어하우스를 사용할 때 특히 더 좋음\n        \n이런 데이터 웨어하우스는 SQL로 데이터 처리를 할 수 있고, 보통 UDF 기능을 지원함\n클라우드 데이터 웨어하우스의 인프라를 관리할 필요가 없기 때문에 클러스터 관리 등을 하지 않아도 괜찮음\n(3) 데이터를 잘 활용하는 조직\n    \n데이터를 잘 활용하지 못하는 경우에 dbt를 도입하는 것은 비추천\n데이터 성숙도 관점에서 모델링의 복잡성과 규모가 존재할 때 도입하는 것이 좋음\n여러 소스의 데이터와 결합할 때 좋고, 단순하게 집계만 하려고 한다면 굳이 dbt를 사용하지 않아도 괜찮음\n데이터 파이프라인 관점\n    \n데이터 파이프라인이 복잡할 때, 리니지 기능이 빛을 낼 수 있기 때문에 복잡한 조직에서 추천함. 간단하다면 그냥 문서에 정리해도 괜찮을 수 있음\ndbt cloud를 사용하지 않으면 Airflow나 dbt Web UI를 구성하는 것이 필요할 수 있음. 추가적으로 리소스가 든다는 것을 인지해야 함\n        \n구현해야 하는 기능\n            \n스케줄링 : Airflow에서 dbt run, test\n알림/모니터링 : Slack 메시지 전송\n대시보드 : Superset 등을 사용해 모델 지표 관리\nCI/CD : Github Action 등을 사용해 배포\n\n\n\ndbt 사용법\ndbt 설치\n글 작성 기준 최신 버전 명시\n\npip3 install dbt-core==1.9.1\n\n\n(1) 프로젝트 생성\nCLI에서 아래 명령어 실행\n    \njaffle_shop이란 프로젝트를 init\n이미 프로젝트가 있다면 이 작업은 생략 가능\n\ndbt init jaffle_shop\n\n\n\n(2) 프로젝트 폴더 구조\ndbt init을 하면 기본적으로 폴더가 생성됨\ndbt init 할 때 생기는 폴더\n\n  ├── README.md\n  ├── analyses\n  ├── dbt_project.yml\n  ├── macros\n  ├── models\n  │   └── example\n  │       ├── my_first_dbt_model.sql\n  │       ├── my_second_dbt_model.sql\n  │       └── schema.yml : 모델 정의\n  ├── seeds\n  ├── snapshots\n  └── tests\n\n    \ndbt_project.yml : dbt 프로젝트 설정\nanalyses/ : 임시 또는 일회성 분석을 위한 쿼리를 저장하는 폴더. dbt run을 해도 실행되지 않음\nmacros/ : 재사용 가능한 매크로를 저장\nmodels/ : SQL 모델 파일들을 저장\n        \n보통 staging, intermediate, mart와 같이 하위 폴더로 구분\nschema.yml : 모델에 대한 정의. model name, description, columns, data_tests 등이 존재\nseeds/ : CSV 파일 형태의 변하지 않는 데이터를 저장\nsnapshots/ : 데이터의 스냅샷을 찍기 위한 SQL 파일을 저장\n        \ndbt snapshot 명령어로 실행\ntests/ : 데이터 품질 테스트 정의\n\n(3) 모델 작성하기\n모델 : 하나의 SQL 쿼리\n쿼리의 결과가 데이터 웨어하우스의 테이블, VIEW로 저장됨\n모델은 .sql 파일로 작성됨\n‘참조(ref)’ 기능\n    \n특정 모델에서 다른 모델을 참조할 때, 테이블 이름을 직접 쓰는 대신 ref('model_name') 함수를 사용함\n이 기능을 사용해 모델 간의 의존성을 자동으로 추적함\nmodels/staging/stg_orders.sql 예시\n\n\n-- models/staging/stg_orders.sql\n{{ config(materialized='table') }}\n\nSELECT\n    order_id,\n    customer_id,\n    order_date,\n    status,\n    amount\nFROM raw_data.orders\nWHERE status IS NOT NULL\n\n\n\n위 테이블을 사용해서 일별 주문 집계를 구하고 싶다면\n\n\n-- models/intermediate/int_daily_orders.sql\n{{ config(materialized='table') }}\n\nSELECT \n    DATE_TRUNC('day', order_date) as date,\n    COUNT(DISTINCT order_id) as order_count,\n    COUNT(DISTINCT customer_id) as customer_count,\n    SUM(amount) as total_amount\nFROM {{ ref('stg_orders') }}\nGROUP BY date\n\n\n\n고객별 구매 이력을 만들 때는\n\n\n\n-- models/marts/mart_customer_orders.sql\n{{ config(materialized='table') }}\n\nWITH customer_orders AS (\n    SELECT \n        customer_id,\n        COUNT(*) as total_orders,\n        SUM(amount) as total_spent,\n        MIN(order_date) as first_order_date,\n        MAX(order_date) as last_order_date\n    FROM {{ ref('stg_orders') }}\n    GROUP BY customer_id\n)\n\nSELECT \n    *,\n    DATEDIFF('day', first_order_date, last_order_date) as customer_lifetime_days\nFROM customer_orders\n\n\n\nconfig의 materialization은 SQL 쿼리의 결과를 데이터 웨어하우스에서 어떻게 저장할지를 의미함\n    \ntable : 실제 테이블로 저장. 데이터가 자주 변경되지 않고, 쿼리 성능이 중요할 경우 사용\nview : 쿼리를 뷰로 저장. 저장 공간을 절약할 수 있지만, 쿼리 성능이 떨어질 수 있음. 다만 원본 데이터가 바뀌면 바로 볼 수 있음(최신 데이터 확인 가능)\nincremental : 테이블에 새로운, 변경된 데이터만 추가함\nemphemeral : 실제로 물리화되지 않고, 다른 모델에서 참조될 때 서브 쿼리로 사용\n\nIncremental Materilization\n자주 사용하는 패턴. 데이터를 증분만 처리\n\n\n\n-- models/mart/web_analytics/daily_pageviews.sql\n{{ config(\n    materialized='incremental',\n    unique_key='page_date_key'\n) }}\n\nSELECT \n    date_trunc('day', timestamp) as visit_date,\n    page_url,\n    count(*) as pageviews,\n    count(distinct user_id) as unique_visitors,\n    concat(date_trunc('day', timestamp), '-', page_url) as page_date_key\nFROM {{ ref('stg_page_visits') }}\n{% if is_incremental() %}\n    WHERE timestamp >= (SELECT max(visit_date) FROM ]{{ this }})\n{% endif %}\nGROUP BY 1, 2, 5\n\n\n\nconfig에서 incremental을 명시하고, unique_key를 추가함\n    \n증분 업데이트를 할 때 사용할 id를 의미함\nunique_key는 고유한 값이어야 하며, 여러 컬럼을 조합해서 사용할 수도 있음\nNULL이 있으면 안됨\n\n    \n\n  {{ config(\n      materialized='incremental',\n      unique_key=['date_key', 'product_id', 'store_id'] \n  ) }}\n    \n\n    \n아래 if is_incremental()은 증분이 있는지 확인하는 것\n    \n이미 처리된 테이블이 있는 경우 실행하며, this는 현재 모델의 테이블을 의미\ntimestamp 기준으로 현재 테이블에 저장된 최근 값(max(visit_date))보다 이후 데이터만 가져옴\n\n    \n\n  {% if is_incremental() %}\n      -- 이미 처리된 테이블이 있는 경우에만 실행\n      WHERE timestamp >= (SELECT max(visit_date) FROM {{ this }})\n      -- {{ this }}는 현재 생성되는 테이블을 참조\n  {% endif %}\n    \n\n    \ninsert, update를 모두 고려하고 싶다면 아래와 같이 작성\n\n    \n\n  {% if is_incremental() %}\n      WHERE created_at >= (SELECT max(created_at) FROM {{ this }})\n      OR updated_at >= (SELECT max(updated_at) FROM {{ this }})\n  {% endif %}\n    \n\n    \n\n(4) 모델을 저장하는 방식\nmodels 하위 폴더 구조를 고민하는 것이 필요함\n    \ndbt는 여러 직무에서 같이 협업하며 사용할 수 있기 때문에 협업에 최적화된 패턴을 고려해야 함\n일관되고 이해하기 쉬운 구조를 만들어야 하며, 정답이 있는 것보단 조직 상황에 따라 다름\n다양한 방식이 있지만, 대표적인 2가지 공유\n\n대표적인 방식 : 비즈니스 도메인 맞춤\ndbt에서 가이드로 주고 있는 형태\n    \nstaging : 초기 정제\nintermediate : 중간 집계나 조인\nmart : 최종 분석용 테이블\n        \n비즈니스 도메인 별로 구분\n이런 구성을 사용하면 파일 이름만 봐도 흐름이 명확해짐\n\nmodels/\n├── staging/\n│   ├── stg_orders.sql\n│   └── stg_customers.sql\n├── intermediate/\n│   ├── int_order_payments.sql\n│   └── int_customer_orders.sql\n└── mart/\n    ├── finance/\n    │   ├── daily_revenue.sql\n    │   └── monthly_profit.sql\n    ├── marketing/\n    │   ├── customer_segments.sql\n    │   └── campaign_performance.sql\n    └── product/\n        ├── product_metrics.sql\n        └── inventory_analysis.sql\n\n\n\n다른 방식 : Fact / Dimension\nKimball의 차원 모델링 방식\n    \nFacts / Dimension 관점으로 처리\nstaging, intermediate는 동일\nFact(팩트) 테이블\n    \n비즈니스 프로세스의 측정값/메트릭을 저장\n주로 숫자형 데이터(금액, 수량 등)\n매우 자주 업데이트되고 크기가 계속 증가\nDimension(디멘전, 차원) 테이블\n    \n비즈니스 엔티티의 속성 정보를 저장\n주로 텍스트/카테고리형 데이터\n상대적으로 천천히 변함\n이 방식의 장점\n    \n명확한 분리 : 팩트, 디멘전을 나눠서 각각의 업데이트 주기와 처리 방식을 나눔\n쿼리 최적화 : 차원 테이블은 작고 자주 JOIN되어서 캐싱, 팩트 테이블은 필요한 컬럼만 포함해 효율적\n유지보수 : 속성 변경은 차원 테이블에서만 관리함. 새로운 값은 팩트 테이블에만 추가\n\nmodels/\n├── staging/      # 원본 데이터 정제\n├── intermediate/ # 중간 처리\n└── marts/\n    ├── facts/    # 측정값이 있는 팩트 테이블\n    │   ├── fct_orders.sql\n    │   └── fct_page_views.sql\n    └── dimensions/  # 차원 테이블\n        ├── dim_customers.sql\n        └── dim_products.sql\n\n\nFact, Dimension 결과를 사용하는 예시 쿼리\n\n    \n  SELECT \n      d.customer_segment,\n      d.country,\n      COUNT(DISTINCT f.order_id) as total_orders,\n      SUM(f.total_amount) as total_revenue\n  FROM {{ ref('fct_orders') }} f\n  JOIN {{ ref('dim_customers') }} d\n      ON f.customer_id = d.customer_id\n  GROUP BY 1, 2\n    \n\n    \n\n(5) 모델 실행 & Test\n모델 파일을 작성한 후, 실행 및 테스트를 진행해야 함\ndbt run 명령어로 실행할  수 있음\n    \n+을 붙이면 의존된 모델을 실행함\n앞에 붙이면 상위 의존성, 뒤에 붙이면 하위 의존성\n추가적인 내용은 dbt Graph Operator Docs\n\n  # 특정 모델 실행\n  dbt run --select my_model \n    \n  # 하위 의존성 모델 포함해 실행\n  dbt run --select my_model+\n     \n  # 상위 의존성 모델 포함\n  dbt run --select +my_model  \n    \n  # 상위와 하위 의존성 모델 모두 포함\n  dbt run --select +my_model+\n\n    \ndbt run 관련 문법은 Doc 참고\n    \nArgument는 --select, --exclue, --selector, --defer가 있음\n특정 모델, 그룹만 실행하고 싶을 땐 –select 를 사용하면 됨\n\n  dbt run --select \"my_dbt_project_name\"  # 프로젝트의 모든 모델\n  dbt run --select \"my_dbt_model\"         # 특정 모델만\n  dbt run --select \"path/to/my/models\"    # 특정 디렉토리의 모든 모델\n  dbt run --select \"tag:nightly\"          # \"nightly\" 태그가 있는 모델들\n\n    \n만약 문법 검사를 하고 싶다면 dbt compile로 확인할 수 있음\n    \n모델 참조 확인, SQL 문법 등\n\n증분 모델 전체 재실행\n일반적인 증분 모델도 동일하게 dbt run으로 실행함\n그러나 처음부터 다시 실행해야 할 경우엔 –full-refresh 인자와 실행\n    \nIncremental 모델의 스키마가 변경되어 다시 만들어야 하는 경우\n새로운 논리가 추가되어 모델 전체를 다시 처리\n내부적으로 기존 테이븡를 DROP하고 모든 데이터를 새로 계산해 적재함(탐색하는 범위에 비용을 부과하는 데이터 웨어하우스에선 비용이 많이 드는 행위일 수 있음)\n\ndb run --full-refresh --select my_model\n\n\n\ndbt Test\ndbt test는 2가지로 구성됨\n    \ngeneric\n        \nmodels/{모델_파일}이 있는 폴더에 저장된 schema.yml에 저장함\n특정 컬럼이 Unique인가? Not Null인가?\nrelationship : 특정 테이블의 컬럼에 존재하는 값인지\naccepted_values : 지정된 값만 있는지\ndbt_expectations(추가 패키지 설치 필요) : dbt hub 참고. 여러 Test가 존재함\n\n  # models/intermediate/schema.yml\n  version: 2\n  models:\n    - name: int_daily_sales\n      columns:\n        - name: date\n          tests:\n            - not_null\n            - unique:\n                combination_of: [date, product_id]\n        - name: daily_sales\n          tests:\n            - not_null\n            - positive_value\n\n    \nsingular\n        \ntests 폴더에 .sql 파일로 정의함\n복잡한 비즈니스 로직을 주로 저장함\n실패 케이스를 반환하는 SQL 쿼리 작성\n            \n아래 쿼리는 결과 row가 0건이면 성공, 1건 이상이면 실패를 의미\n\n    \n\n  -- tests/assert_total_payment_amount_is_positive.sql\n  SELECT\n      order_id,\n      total_amount\n  FROM {{ ref('orders') }}\n  WHERE total_amount < 0\n    \n\n    \n매출 합계와 일별 매출의 합이 같은지 확인하고 싶은 경우\n\n    \n\n  -- 매출 합계가 일별 매출의 합과 같은지 확인\n  SELECT \n      CASE \n          WHEN total_revenue != daily_sum THEN '정합성 확인 필요'\n      END as check_result\n  FROM (\n      SELECT \n          SUM(revenue) as total_revenue\n      FROM {{ ref('revenue') }}\n  ) t1\n  CROSS JOIN (\n      SELECT \n          SUM(daily_revenue) as daily_sum\n      FROM {{ ref('daily_revenue') }}\n  ) t2\n  WHERE total_revenue != daily_sum\n    \n\n    \ndbt test 명령어로 실행\n\ndbt test # 모든 테스트\ndbt test --select my_model  # 특정 모델의 테스트만\ndbt test --select test_type:generic # generic 테스트만\ndbt test --select test_type:singular # singular 테스트만\ndbt test --select result:fail #실패한 테스트만 재실행\n\n\n\n\n(6) dbt build\nbuild = run + test + snapshot + seed 모두 한번에 실행\n실행 순서\n    \nSeedfile Load\nModel Run\nSnapshot Run\nTest run\n모델을 만들고, 테스트를 실행하는 과정\n\ndbt build --select my_model\n\n\n\n언제 build를 하는가?\n모델 개발, 테스트 작성할 때는 run, test를 각각 하는 것이 효율적\nbuild는 Airflow에서 주기적으로 실행하곤 함\n    \n하지만 조직에 따라선 build를 안하고 dbt run만 하는 경우도 존재함(Test까지 하는 것이 이상적이나 현실적으로 Test를 많이 챙기려면 시간이 더 들기 때문에)\n빌드 시간을 줄이기 위해 수정된 것만 빌드하는 인자도 존재\n\ndbt build --select state:modified+ --defer --state path/to/prod/artifacts\n\n\nstate:modified+ : 변경된 모델과 의존된 다운스트림만 실행\n    \nstate path: 프로덕션 환경의 상태와 비교해 어떤 모델이 변경되었나 확인\ndefer : 변경되지 않은 모델은 프로덕션 데이터 참조\n\n추가로 고려할 것들\n기존에 SQL 기반으로 마트를 만들었다면 마이그레이션이 필요함\n    \nRefactoring SQL for Modularity Course 추천\ndbt docs 배포\n    \ndbt model에 대한 내용을 문서로 배포해, 사내 구성원들이 볼 수 있게 해야 함\n김진석님의 dbt Docs 사내 공유 방법 feat. 사이트 호스팅 가이드 추천\n대시보드와 통합하기 : lightdash 추천\n    \nHands-on Guide to Data Modeling with dbt and Visualization with Lightdash\ndbt + Airflow(스케줄링 도구)\n    \n주기적으로 실행하기 위해 Airflow 같은 도구와 통합 필요\n또는 GitHub Action에서 실행할 수도 있음\ndbt metrics을 활용해 지표 집계\n    \nBuild your metrics\ndbt Semantic Layer\ndbt utils 확인하기\n    \ndbt utils에 유용한 함수들이 많이 존재함\ndbt + 데이터 웨어하우스\n    \n이번 글은 dbt에 대한 전반적인 소개를 목적으로 한 글이라 이 내용을 포함하진 않았으나, 다음 글은 dbt + 데이터 웨어하우스 글을 작성할 예정\ndbt와 유사한 역할을 하는 도구는 dbt 외에도 SQLMesh라는 것도 존재함. dbt가 초반 러닝커브가 높은데(Jinja 템플릿을 활용) 이 부분\n    \n궁금하다면 Is It Time To Move From dbt to SQLMesh? 추천. SQLMesh가 더 좋은 부분도 있으나 dbt가 생태계가 더 큼. 마치 Airflow가 배치 스케줄링에서 제일 점유율이 높고, Prefect나 다른 도구들이 계속 발전하는 것과 유사한 느낌\n        \n그러나 아직 dbt를 도입하지 않았다면 SQLMesh를 도입하는 것도 괜찮다고 생각. dbt를 쓰다가 옮기는 것은 고민됨\n\n추천 자료\nSeoul dbt Meetup : dbt 행사를 종종 여시는데, dbt 사용자라면 참석 추천\n(쏘카) 데이터에 신뢰성과 재사용성까지, Analytics Engineering with dbt\n(당근) DBT와 Airflow 도입하며 마주한 7가지 문제들\n    \nDo you know DBT?\ndbt를 통한 데이터 웨어하우스 개발 후기\n오토피디아 데이터 웨어하우스 구축하기\n\n\n\n\n  \n글 작성하는데 걸린 시간 : 3시간 33분\n    \n하고자 하는 이야기, 개요 정리 : 13분\n초안 글 작성 : 2시간 50분\n클로드와 셀프 글 피드백 : 30분\n간단 회고\n    \ndbt + BigQuery까지 쓰려니까 내용이 너무 많아져서 두번째 글을 작성할 예정",
        "guid": "https://zzsza.github.io/data-engineering/2025/01/16/dbt-core/",
        "categories": [
          "dbt",
          "data-engineering"
        ],
        "isoDate": "2025-01-16T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "코인 하락장이 오면 이렇게 됩니다.",
        "link": "http://serverdown.tistory.com/1115",
        "pubDate": "Mon, 20 Jan 2025 21:29:24 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1115#entry1115comment",
        "content": "<p data-ke-size=\"size16\">저는 2025년 3월까지만 코인할 생각인데요</p>\n<p data-ke-size=\"size16\">결국 어느날 하락장이 올것입니다.</p>\n<p data-ke-size=\"size16\">그때가 되면 어떻게 되는지 알아두는 것은 매우 중요한 일입니다.</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/shorts/jmRU026r7YQ\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/shorts/jmRU026r7YQ</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/shorts/jmRU026r7YQ\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/b1e8UQ/hyX4tvI6m0/1EqwWe1aK2bsuMtNik8Kgk/img.jpg?width=405&amp;height=720&amp;face=38_115_310_391,https://scrap.kakaocdn.net/dn/3eMts/hyX4kMjOcQ/lIKmKjtqSNPGDDZMSPhGG1/img.jpg?width=405&amp;height=720&amp;face=38_115_310_391\" data-video-width=\"405\" data-video-height=\"720\" data-video-origin-width=\"405\" data-video-origin-height=\"720\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"불장에 졸업못한 사람 특  #shorts #비트코인\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/jmRU026r7YQ\" width=\"405\" height=\"720\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "저는 2025년 3월까지만 코인할 생각인데요\n결국 어느날 하락장이 올것입니다.\n그때가 되면 어떻게 되는지 알아두는 것은 매우 중요한 일입니다.\n영상: https://www.youtube.com/shorts/jmRU026r7YQ",
        "guid": "http://serverdown.tistory.com/1115",
        "categories": [
          "코인",
          "코인"
        ],
        "isoDate": "2025-01-20T12:29:24.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "일본의 초밥 자판기 / 곱창 자판기 (망함)",
        "link": "http://serverdown.tistory.com/1114",
        "pubDate": "Sun, 19 Jan 2025 23:37:28 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1114#entry1114comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=RZkb9Aptv9g\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=RZkb9Aptv9g</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=RZkb9Aptv9g\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cmGaGY/hyX4unEISc/ILuJpmQEBWHyi9TDDPzIy0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/0KWYl/hyX0lTqUYj/zQdMzxbGUkm0UZsgwkKqr0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"일본 동네 초밥 자판기에서 초밥을 사보았다\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/RZkb9Aptv9g\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">어떻게 파나 싶어서 봤는데</p>\n<p data-ke-size=\"size16\">냉동이라고 합니다.</p>\n<p data-ke-size=\"size16\">뜨거운물을 밑에 채워두고 30분 기다리면 먹을만하게 녹는다고 합니다.</p>\n<p data-ke-size=\"size16\">유통기한은 6개월 정도</p>\n<p data-ke-size=\"size16\">가격은 13,000 엔</p>\n<p data-ke-size=\"size16\">기술 좋네요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">곱창 자판기: <a href=\"https://www.youtube.com/watch?v=-nQA1meAVc8\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=-nQA1meAVc8</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=-nQA1meAVc8\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/fO2fa/hyX4xq9rlC/76fBFwCeLz3qtgA6AsK0c0/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360,https://scrap.kakaocdn.net/dn/REN6a/hyX0uCRjRs/BwVHKSEpEbU1353ZWsCp40/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360\" data-video-width=\"480\" data-video-height=\"360\" data-video-origin-width=\"480\" data-video-origin-height=\"360\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"일본 동네에 있는 곱창 자판기 이용해보기 [+혼술 먹방]\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/-nQA1meAVc8\" width=\"480\" height=\"360\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">는 망했다고 합니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=RZkb9Aptv9g\n\n\n\n어떻게 파나 싶어서 봤는데\n냉동이라고 합니다.\n뜨거운물을 밑에 채워두고 30분 기다리면 먹을만하게 녹는다고 합니다.\n유통기한은 6개월 정도\n가격은 13,000 엔\n기술 좋네요\n \n곱창 자판기: https://www.youtube.com/watch?v=-nQA1meAVc8\n\n\n\n는 망했다고 합니다.",
        "guid": "http://serverdown.tistory.com/1114",
        "categories": [
          "유튜브",
          "여행",
          "일본"
        ],
        "isoDate": "2025-01-19T14:37:28.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "깡통 7번 차고 배운점 / 투자 실패 스토리",
        "link": "http://serverdown.tistory.com/1113",
        "pubDate": "Sun, 19 Jan 2025 23:25:08 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1113#entry1113comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=w4tmHlvSidA\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=w4tmHlvSidA</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=w4tmHlvSidA\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bbkumQ/hyX4Ag7cDD/vIrmoPWQoFBjc2sSVTmBmk/img.jpg?width=1280&amp;height=720&amp;face=410_134_992_500,https://scrap.kakaocdn.net/dn/qnCHg/hyX4mQGrYw/OqQtSEbryKdZQenChGwv3K/img.jpg?width=1280&amp;height=720&amp;face=410_134_992_500\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"깡통 7번 차고 죽을 만큼 힘들었어요! &quot;실패에서 배운 성공 투자 기법&quot; / 무조건 피해야 할 1가지 (\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/w4tmHlvSidA\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">들어볼만합니다.</p>\n<p data-ke-size=\"size16\">하다보면 잘 될때가 있습니다.</p>\n<p data-ke-size=\"size16\">꼭 그럴때 욕심을 잘 조절해야합니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=w4tmHlvSidA\n\n\n\n들어볼만합니다.\n하다보면 잘 될때가 있습니다.\n꼭 그럴때 욕심을 잘 조절해야합니다.",
        "guid": "http://serverdown.tistory.com/1113",
        "categories": [
          "투자",
          "주식",
          "투자"
        ],
        "isoDate": "2025-01-19T14:25:08.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "미국 강의 - 자유가 무엇인지 설명하기위해 &quot;바이든 멍청이&quot; 를 시켜봅니다.",
        "link": "http://serverdown.tistory.com/1112",
        "pubDate": "Fri, 17 Jan 2025 15:45:37 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1112#entry1112comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=1OfJGkltN_M\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=1OfJGkltN_M</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=1OfJGkltN_M\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/b8p1fr/hyX4otUrDw/YOqcBapLDK3LD74AKQRkn0/img.jpg?width=1280&amp;height=720&amp;face=128_254_654_424,https://scrap.kakaocdn.net/dn/dO6FbY/hyX0rFLG0a/N2wKJEkNajt90CLyUoGl01/img.jpg?width=1280&amp;height=720&amp;face=128_254_654_424\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"하버드 교수의 일침에 중국 찬양하던 중국 유학생이 1초만에 입 다문 이유\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/1OfJGkltN_M\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">사우디 와 중국 항생에게 이야기를 시키면서</p>\n<p data-ke-size=\"size16\">미국 학생에게 \"바이든 멍청이\" (현직 대통령) 이라고 말해보라고 시킵니다.<br />미국 항생은 당연히 말했지요.</p>\n<p data-ke-size=\"size16\">자유라는게 무엇인지 아주 간단하게 보여주는 강의 였습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">자율라는건 이미 누리고 있다면 알 방법이 없습니다.</p>\n<p data-ke-size=\"size16\">공기 같은 것이죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=1OfJGkltN_M\n\n\n\n사우디 와 중국 항생에게 이야기를 시키면서\n미국 학생에게 \"바이든 멍청이\" (현직 대통령) 이라고 말해보라고 시킵니다.\n미국 항생은 당연히 말했지요.\n자유라는게 무엇인지 아주 간단하게 보여주는 강의 였습니다.\n \n자율라는건 이미 누리고 있다면 알 방법이 없습니다.\n공기 같은 것이죠.",
        "guid": "http://serverdown.tistory.com/1112",
        "categories": [
          "유튜브",
          "미국"
        ],
        "isoDate": "2025-01-17T06:45:37.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "2차전지 중국의 폐베터리는 재홀용할 방법이 없다.",
        "link": "http://serverdown.tistory.com/1111",
        "pubDate": "Fri, 17 Jan 2025 15:31:21 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1111#entry1111comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://youtu.be/1YlJg3y_8wQ?t=274\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://youtu.be/1YlJg3y_8wQ?t=274</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=1YlJg3y_8wQ\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/y5ycB/hyX4spxakF/OPlt3RiXfVLf024vLFbUS0/img.jpg?width=1280&amp;height=720&amp;face=882_264_1104_506,https://scrap.kakaocdn.net/dn/c9XFXF/hyX4rEaSar/nSOhj36XXAIzu8I7UikEO0/img.jpg?width=1280&amp;height=720&amp;face=882_264_1104_506\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"【중국인사이트】 2025년, 중국 경제의 추락? 숨겨진 진실 공개! (진태산 보도)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/1YlJg3y_8wQ\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">4분 30초에 나옵니다.</p>\n<p data-ke-size=\"size16\">유럽에 많이 수출했지만 베터리를 교체하기위해 베터리를 중국에 다시 보낼텐데</p>\n<p data-ke-size=\"size16\">이 폐베터리는 환경에 문제 없이 폐기나 재활용할 방법이 중국에는 없습니다.</p>\n<p data-ke-size=\"size16\">왜냐하면 당연히 그런걸 고려안하고 만든 가격이 지금 가격이기 때문입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이런 베터리는 싸다고 많이 사용해봐야 환경문제를 일으키게 됩니다.</p>\n<p data-ke-size=\"size16\">비싼비용으로 재활용 하느니 땅에 뭍어버리는게 낫을 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">그렇습니다. 중국의 베터리 가격은 뒷일을 생각하지 않은 그냥 원가 인것입니다.</p>\n<p data-ke-size=\"size16\">물론 유럽은 이 베터리를 자국에서 어떻게 하지 않고 중국으로 보내버릴 것입니다.</p>",
        "contentSnippet": "영상: https://youtu.be/1YlJg3y_8wQ?t=274\n\n\n\n4분 30초에 나옵니다.\n유럽에 많이 수출했지만 베터리를 교체하기위해 베터리를 중국에 다시 보낼텐데\n이 폐베터리는 환경에 문제 없이 폐기나 재활용할 방법이 중국에는 없습니다.\n왜냐하면 당연히 그런걸 고려안하고 만든 가격이 지금 가격이기 때문입니다.\n \n이런 베터리는 싸다고 많이 사용해봐야 환경문제를 일으키게 됩니다.\n비싼비용으로 재활용 하느니 땅에 뭍어버리는게 낫을 것입니다.\n \n그렇습니다. 중국의 베터리 가격은 뒷일을 생각하지 않은 그냥 원가 인것입니다.\n물론 유럽은 이 베터리를 자국에서 어떻게 하지 않고 중국으로 보내버릴 것입니다.",
        "guid": "http://serverdown.tistory.com/1111",
        "categories": [
          "투자",
          "2차전지",
          "중국",
          "폐베터리"
        ],
        "isoDate": "2025-01-17T06:31:21.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": []
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "한상곤 - Sigmadream",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "3단계로 완성하는 유연한 디자인 시스템",
        "link": "https://techblog.lycorp.co.jp/ko/a-flexible-design-system-using-3-tier-tokens",
        "pubDate": "Mon, 20 Jan 2025 03:00:00 GMT",
        "content": "안녕하세요. LINE Plus ABC Studio에서 일본 음식 배달 서비스 Demaecan(出前館, 이하 데마에칸)의 디자인을 담당하고 있고, 사용자의 다양한 목소리를 담을 수 ...",
        "contentSnippet": "안녕하세요. LINE Plus ABC Studio에서 일본 음식 배달 서비스 Demaecan(出前館, 이하 데마에칸)의 디자인을 담당하고 있고, 사용자의 다양한 목소리를 담을 수 ...",
        "guid": "https://techblog.lycorp.co.jp/ko/a-flexible-design-system-using-3-tier-tokens",
        "isoDate": "2025-01-20T03:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "희망의 실종",
        "link": "https://www.thestartupbible.com/2025/01/will-there-be-hope-in-2025.html",
        "pubDate": "Sun, 19 Jan 2025 21:34:00 +0000",
        "content:encodedSnippet": "2022년 하반기에 많은 분들이 나에게 앞으로 경기는 어떻게 될 것이고, 언제쯤, 이 불경기가 회복될지 물어봤다. 물론, 나는 경제학자도 아니고 미래학자도 아니라서 잘 모른다고 했지만, 속으론 2024년 상반기면 괜찮아질 것으로 생각했다. 그래서 계속 개인적인 생각을 물어보면, 그냥 2024년 상반기엔 좋아지지 않겠나,,,라고 이야기했다. 그런데 2023년 상반기가 되자, 여러 가지 분위기와 정성적인 지표는 – 예, 해외 투자자들과의 이야기와 느낌 – 2024년 경기도 매우 안 좋은 방향으로 향하고 있는 게 너무나 명확했다. 그래서 내가 했던 말을 번복하고, 2025년이 돼야 시장의 상황이 더 좋아질 것 같다고 했다.\n작년 사사분기에, 이런 내 생각에 한 번의 전환이 더 있었고, 내 말을 한 번 더 번복했다. 2025년은 어쩌면 우리가 스타트업을 하면서 경험할 수 있는 최악의 경기가 될지도 모르겠다. 특히나 한국은 그동안 국제적인 이미지가 너무 좋았고, 전반적인 분위기가 나쁘지 않았는데, 말도 안 되는 정치적인 사건으로 인해서 국가의 이미지가 실추되면서 그 누구도 상상하지 못했던 엄청난 경제적인 손실이 발생하고 있다.\n그동안 내가 외국인들에게 항상 자랑스럽게 주장했던 게 두 가지가 있었다.\n하나는, 한국은 그나마 다른 아시아 국가 중 정치적으로 안정된 국가라는 점이었고, 둘째는, 한국은 그나마 다른 아시아 국가보다 USD에 대한 환율이 강한 국가라는 점이었다.\n모두 잘 아시다시피, 내가 완전히 양치기 소년이 됐다. 어쨌든, 이 좋지 않은 세계 경제 상황에서 정치적, 경제적으로 일시적으로 최악의 상황에 놓인 한국은 힘든 한 해를 보낼 것이고, 한국에서 사업을 하는 스타트업, 그리고 우리 같은 투자자 모두 아주 힘든 한 해를 경험할 것이다.\n2025년에는 사라지는 회사들이 정말 많을 것이다. 우리 투자사들도 너무 다 힘들고, 이미 폐업 준비하는 대표들이 내 주변에도 너무 많아지고 있다. 가장 먼저 문 닫을 회사들은 원래 2024년도에 폐업을 해야 했는데, 2025년은 더 좋아질 것이라는 희망을 갖고, 오로지 이 희망 하나로 작년 한 해를 버틴 회사들이다. 이들의 희망과는 달리 2025년도 크게 좋아지지 않을 것이기 때문에, 매출은 작고, 돈은 없고, 직원들은 하나둘씩 해고되거나 나갈 회사들은 문을 닫아야 할 것이다. 이들에게 더 이상 희망으로 버틸 수 있는 체력과 돈은 없다.\n펀딩 시리즈 스펙트럼의 다른 극에 있는 유니콘 회사들도 많이 망하거나, 아니면 유니콘 왕관을 스스로 내려놔야 할 것이다. 돈도 못 벌고, 마이너스만 만들고 있는 유니콘들이 꽤 많은데, 이들이 작년 한 해 유니콘 밸류에이션을 유지할 수 있었던 이유는 두 가지다. 하나는 이들도 2025년은 시장이 더 좋아져서 다시 한번 유니콘 밸류에 투자를 받을 수 있을 것이라는 희망으로 힘든 2024년을 버텼을 것이다. 또 다른 이유는 이 회사에 마지막으로 투자한 VC들이 어떻게든 기업 가치를 유지해서 본인들 투자에 손실이 발생하지 않기 위해서 이 회사들을 하드캐리 했는데, 더 이상 이걸 할 순 없을 것이다. 실은, 이 VC들도 2025년에 대한 희망을 품고 힘든 2024년을 보냈는데, 더 이상 이런 희망으로 버틸 순 없을 것이다.\n2025년에는 스타트업만 돈이 없는 게 아니라, 이들에게 투자하는 VC들도 돈이 없어서 활발한 투자를 보긴 힘들 것이다. VC들도 누군가에게 돈을 받아서 투자해야 하는데, 이들에게 돈을 주는 LP들이 매우 보수적인 자세를 취하고 있어서, 펀드를 만드는 게 우리 같은 투자자들에겐 큰 도전이자 과제다. 돈이 나올 수 있는 구멍이 여러 면에서 막혀 있는 게 VC나 스타트업의 2025년도 현실이다.\n단도직입적으로 말하자면, 근대 벤처업계 역사상 최악의 한 해가 될 것이다. 인생 최고 공포의 롤러코스터 라이드가 될 것이니까, 안전띠 꽉 조이고, 허리띠는 더 꽉 조여야 할 것이다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/01/will-there-be-hope-in-2025.html#respond",
        "content": "2022년 하반기에 많은 분들이 나에게 앞으로 경기는 어떻게 될 것이고, 언제쯤, 이 불경기가 회복될지 물어봤다. 물론, 나는 경제학자도 아니고 미래학자도 아니라서 잘 모른다고 했지만, 속으론 2024년 상반기면 괜찮아질 것으로 생각했다. 그래서 계속 개인적인 생각을 물어보면, 그냥 2024년 상반기엔 좋아지지 않겠나,,,라고 이야기했다. 그런데 2023년 상반기가 되자, 여러 가지 분위기와 정성적인 지표는 – 예, 해외 투자자들과의 이야기와(...)",
        "contentSnippet": "2022년 하반기에 많은 분들이 나에게 앞으로 경기는 어떻게 될 것이고, 언제쯤, 이 불경기가 회복될지 물어봤다. 물론, 나는 경제학자도 아니고 미래학자도 아니라서 잘 모른다고 했지만, 속으론 2024년 상반기면 괜찮아질 것으로 생각했다. 그래서 계속 개인적인 생각을 물어보면, 그냥 2024년 상반기엔 좋아지지 않겠나,,,라고 이야기했다. 그런데 2023년 상반기가 되자, 여러 가지 분위기와 정성적인 지표는 – 예, 해외 투자자들과의 이야기와(...)",
        "guid": "https://www.thestartupbible.com/?p=9352",
        "categories": [
          "Uncategorized",
          "failure",
          "FoundersAtWork",
          "fundraising",
          "korea",
          "unicorn",
          "vc"
        ],
        "isoDate": "2025-01-19T21:34:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "강렬함",
        "link": "https://www.thestartupbible.com/2025/01/the-land-of-intensity.html",
        "pubDate": "Wed, 15 Jan 2025 21:31:00 +0000",
        "content:encodedSnippet": "대한항공을 자주 타는 사람들이라면, 좌석마다 배치된 기내지 Morning Calm을 보거나, 읽어봤을 것이다. 이 잡지의 이름의 유래는 한국을 영어로 Land of Morning Calm이라고 설명해서인데, 이 설명은 ‘조선’을 영어로 풀어 해석한 것이다. 여기에다가 조금 더 해석을 붙여보자면, 한국은 경치가 좋고, 아름다운 산과 강이 많아서, 아침에 보면 이 풍경이 아주 고요하고 평화로워서 Morning Calm이라는 설명이 한국의 이미지와 잘 어울린다는 것이다. 지금까지는.\n나는 이제 이 Morning Calm은 한국을 제대로 설명할 수 있는 좋은 명사가 아니라고 생각한다. 조용하다고 하기에 한국은 이제 너무 역동적이고 강렬한 나라가 되어가고 있기 때문이다. 최근 2년 동안 우리는 상당히 많은 외국 투자자를 한국에서 만났고, 미국, 동남아, 일본, 유럽 등의 나라에서도 수많은 외국인과 이야기할 수 있었는데, 내가 전에 포스팅했듯이 한국이라는 나라의 이미지와 위상이 너무 좋아졌다는 걸 매번 느낄 수 있었다.\n이들과 이야기해 보면, 대부분의 외국인들이 한국에 대해 갖고 있는 이미지는 가지각색이지만, 대화 중에 항상 한두 번 튀어나오는 단어가 있었는데, 그 단어가 바로 “intense”와 “intensity”였다. 외국인들이 본 한국은 아주 강렬한 나라인 것 같다.\n일단 한국의 관문인 공항에 내려서 숙소로 오는 길에서 경험하는 한국의 교통체증은 정말 강렬하다. 그 교통체증의 한가운데에서 길에 있는 다른 차를 보는데, 좋은 차들 또한 너무 많다. 단위 면적 당 비싼 차들이 가장 많은 나라 중 하나가 한국일 것이다. 우리 외국 투자자 한 분이 서울에 삼일 있었는데, 평생 70년 동안 전 세계에서 봤던 벤츠 마이바흐 숫자보다 더 많은 마이바흐를 사흘 동안 서울에서 봤다면서 정말 강렬한(=뭔가 미친) 도시라고 했던 기억이 난다.\n한국 음식에 대한 인상도 비슷하다. 김치나 찌개와 같은 음식은 양념이 세고 자극적이라서 강렬하고, 갈비나 불고기 같은 고기류는 맛 있어서 강렬하다. 특히 깨알 같은 반찬에 감탄하지 않는 사람들이 없다. 한국인들과 술을 한 번이라도 먹어본 외국인들은 한국의 술 문화를 완전 증오하거나, 완전히 사랑하게 된다. 다양한 술과 이 술을 먹는 다양한 방법, 여기에 매우 강렬한 인상은 받은 외국인들이 상당히 많다.\n케이팝과 케이드라마를 자주 접하는 외국인들도 다양한 의견을 우리와 공유하는데, 한 단어로 이들의 느낌을 요약하면, 한국의 콘텐츠가 매우 강렬하다고 할 수 있다. 특히, 오징어게임과 기생충을 봤던 평론가들의 평을 보면, 이들이 강렬하다는 표현을 자주 사용하는 걸 볼 수 있다.\n한국 사람들과 일을 해 본 외국인들도 이 “intense”라는 말을 자주 사용하는데, 주로 좋은 의미로 사용된다고 나는 생각한다. 일단 전반적으로 한국인들은 정말 일을 잘하고, 일머리가 있고, 그리고 (아직까진) 대부분 정말 열심히 일한다는 피드백이 지배적이다. 일을 잘하는데, 일을 열심히 까지 하면, 이건 굉장히 강렬하게 일을 하는 것이다. 작년에 유럽에서 가는 곳마다 한국 사람들이 너무 늦게까지 일해서, 본인들이 페이스 맞춰서 같이 일하는 게 너무 힘들다는 불평 아닌 불평을 자주 들었는데, 역시 이분들도 한국인들은 정말 강렬하게 일한다고 했다. 뭐, 워낙 게으른 유럽 사람들이라서 한국이 너무 열심히 일한다고 했을 수도 있다.\n추운 겨울에도 이렇게 많은 한국인들이 아이스 아메리카노를 시켜서 춥다면서 그 차가운 커피를 벌컥벌컥 먹는 게 매우 인상적이었다는 이야기도 최근에 들었다. 아주 강렬한 인상을 남겼다는 이야기를 하면서. 그리고 성형수술을 하고 퉁퉁 부은 얼굴에 붕대를 칭칭 감고 시내를 아무렇지도 않게 돌아다니는 사람들도 매우 강렬했고, 그런 사람을 보고도 아무렇지도 않은 듯이 걸어 다니는 한국인들에 대한 인상도 참으로 강렬했다는 이야기도 들었다. 어쨌든 이런 한국의 강렬함에 대한 에피소드는 끊임없이 많다.\n왜 한국의 모든 게 이렇게 강렬할까? 나에게 개인적으로 물어본다면, 이 모든 걸 만들고, 이 모든 걸 가능케 하는 한국인들 자체가 강렬한 민족이기 때문이다. 우린 뭘 하나 하면, 정말 끝을 보는 성격을 가진 사람들이고, 한 번 하려고 마음먹은 건 정말 잘 한다.(시작하고 끝을 못 보는 것들도 많긴 하지만).\n나는 이런 한국의 강렬함은 계속 우리가 유지하고, 이어 나가야 하는 좋은 습관이자 특징이라고 생각한다. 이걸 나쁘게 이야기하면, 우린 너무 바쁘게 살고 있고, 앞뒤 가리지 않는 냄비근성이고, 스스로 자제하지 못하는 민족이라고 할 수도 있지만, 나는 오히려 이런 DNA를 우리가 계속 잘 다듬고, 좋은 쪽으로 계속 발전시켜야 한다고 생각한다. \nKorea, the Land of Intensity.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/01/the-land-of-intensity.html#respond",
        "content": "대한항공을 자주 타는 사람들이라면, 좌석마다 배치된 기내지 Morning Calm을 보거나, 읽어봤을 것이다. 이 잡지의 이름의 유래는 한국을 영어로 Land of Morning Calm이라고 설명해서인데, 이 설명은 ‘조선’을 영어로 풀어 해석한 것이다. 여기에다가 조금 더 해석을 붙여보자면, 한국은 경치가 좋고, 아름다운 산과 강이 많아서, 아침에 보면 이 풍경이 아주 고요하고 평화로워서 Morning Calm이라는 설명이 한국의 이미지와 잘(...)",
        "contentSnippet": "대한항공을 자주 타는 사람들이라면, 좌석마다 배치된 기내지 Morning Calm을 보거나, 읽어봤을 것이다. 이 잡지의 이름의 유래는 한국을 영어로 Land of Morning Calm이라고 설명해서인데, 이 설명은 ‘조선’을 영어로 풀어 해석한 것이다. 여기에다가 조금 더 해석을 붙여보자면, 한국은 경치가 좋고, 아름다운 산과 강이 많아서, 아침에 보면 이 풍경이 아주 고요하고 평화로워서 Morning Calm이라는 설명이 한국의 이미지와 잘(...)",
        "guid": "https://www.thestartupbible.com/?p=9348",
        "categories": [
          "Uncategorized",
          "inspiring",
          "korea",
          "people"
        ],
        "isoDate": "2025-01-15T21:31:00.000Z"
      }
    ]
  },
  {
    "name": "Build a Great Product",
    "category": "개인",
    "posts": []
  },
  {
    "name": "지금 써보러 갑니다",
    "category": "개인",
    "posts": []
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": []
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]