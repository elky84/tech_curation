[
  {
    "name": "ㅍㅍㅅㅅ",
    "category": "큐레이팅",
    "posts": []
  },
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Mryam Girmay",
        "title": "Prevent Critical Bugs with MSVC Code Analysis",
        "link": "https://devblogs.microsoft.com/cppblog/prevent-critical-bugs-with-msvc-code-analysis/",
        "pubDate": "Thu, 22 Aug 2024 18:12:24 +0000",
        "content:encodedSnippet": "Imagine this: You’re deep into a complex C++ project, and everything seems to be running smoothly. But then, out of nowhere, a critical bug surfaces— one that requires a bit more foresight. We’ve all been there, right? This is where code analysis steps in as your silent guardian. \nCode analysis is a great tool for catching those elusive bugs and ensuring your code adheres to the best programming practices. It identifies defects that are difficult to discover through testing by searching for specific code patterns known to cause problems.  \n The analysis results are displayed in the Visual Studio Error List window and as squiggles in the editor. This feature checks for problematic code patterns, such as buffer overruns caused by converting an element count into a byte count and null pointer dereferences, even if the code  looks correct. In this blog, we will focus on MSVC Code Analysis, which is one of the different types of code analysis available in Visual Studio for C++. \nWhere MSVC Code Analysis Shines \nIn 2014, the tech world was shaken by the discovery of the Heartbleed bug in OpenSSL. This critical vulnerability, caused by a missing bounds check, allowed attackers to exploit the TLS heartbeat extension and read sensitive data from server memory, including private keys, usernames, and passwords. The fallout was massive, affecting millions of users and causing widespread panic. \nNow, picture yourself as a C++ developer working on a high-stakes project. You know that even a small mistake can lead to significant security vulnerabilities, just like Heartbleed. This is where MSVC Code Analysis becomes your best ally. \nMSVC Code Analysis is a static analysis tool that checks your code for errors, potential improvements, and adherence to coding best practices when using the Microsoft Visual C++ (MSVC) compiler. For example, failing to initialize a pointer (e.g., int* uninitializedPtr;) in your project can result in unpredictable behavior, crashes, and security vulnerabilities. Consider the following scenario: You declare a pointer and initialize it to nullptr (int* imageData = nullptr;). Later, you attempt to allocate memory for the pointer based on uninitialized width and height variables (imageData = new int[width * height];). This can lead to undefined behavior because width and height are not initialized before use. If the pointer is used before being properly assigned, it can lead to accessing uninitialized memory, which Rule C6001 identifies, helping you catch these issues before they become critical problems. The following sample generates ‘Using uninitialized memory’ warning: \n#include <iostream> \r\n\r\n#include <stdexcept> \r\n\r\n class ImageProcessor { \r\n\r\npublic: \r\n\r\n    void processImage() { \r\n\r\n        int width, height; \r\n\r\n        int* imageData = nullptr; \r\n\r\n        try { \r\n\r\n            // Attempt to allocate memory based on width and height \r\n\r\n            imageData = new int[width * height]; // Uninitialized width and height \r\n\r\n            // Process the image data (this will cause undefined behavior) \r\n\r\n            for (int i = 0; i < width * height; ++i) { \r\n\r\n                imageData[i] = i; // Potentially accessing uninitialized memory \r\n\r\n            } \r\n\r\n            // Simulate further processing \r\n\r\n            std::cout << \"Image processed successfully.\" << std::endl; \r\n\r\n        } \r\n\r\n        catch (const std::bad_alloc& e) { \r\n\r\n            std::cerr << \"Memory allocation failed: \" << e.what() << std::endl; \r\n\r\n        } \r\n\r\n        // Clean up allocated memory \r\n\r\n        delete[] imageData; \r\n\r\n    } \r\n\r\n}; \nNow, let’s use this example to understand the different ways to invoke code analysis in Visual Studio.\nBackground Code Analysis  \nThis integral feature of Visual Studio functions as a real-time code analysis tool. This tool is particularly beneficial for you because it: \nProvides immediate feedback on potential issues, aiding in early problem resolution. \nFocuses on the files that are currently open in the editor, streamlining analysis during active development.  \nBackground code analysis will automatically run after you open or save the file. The warning for uninitialized memory will be enabled by default, displaying a green squiggle in the editor and appearing in the error list, as demonstrated in the example below. \n\nThis feature is enabled by default; however, you can double check the setting by navigating to Tools > Options > Text Editor > C/C++ > Advanced > Code Analysis > Disable Background Code Analysis: False.\nManually Running Code Analysis \nIn addition to background code analysis, you can also manually run code analysis as needed. You can start by clearing all warnings in the current file you’re working on, then invoke Code Analysis for the current project. Periodically, run Code Analysis for the entire solution to maintain overall code quality. You can also manually run code analysis for individual files. There are several ways to manually run a code analysis. Following any of these steps will display the ‘Using uninitialized memory’ warning in the error list window for our example. \n1. Menu-bar: \nOpen the project.\nFrom the menu-bar, select Build -> Run Code Analysis on [Solution | Project Name | File] \nFrom the menu-bar, select Analyze -> Run Code Analysis -> [On Solution | Run Code Analysis on ‘project name’ | Run Code Analysis on File]\n\n2. Keyboard Shortcut: \nFor a single file: Ctrl + Shift + Alt + F7 \nLearn more about the different ways to run code analysis manually in Run code analysis. \nEnable Code Analysis on Build \nThis setup ensures that code analysis runs automatically every time you build your project or compile a single file. Think of code analysis as an inspector who checks your project. While this inspector might take more time to examine everything, catching potential issues early provides peace of mind. This additional time you invest   is necessary to ensure your code is secure. To enable it: \n Open Project Properties in Visual Studio.\nNavigate to Configuration Properties > Code Analysis > General. \nSelect the Yes option for Enable Code Analysis on Build. Note that this option is disabled by default, whereas Microsoft Code Analysis is enabled by default.\n\nTo view all default selected rules, including the rule for detecting uninitialized memory, navigate to Configuration Properties > Code Analysis > Microsoft, and then click Configure.   \n\nAfter enabling code analysis on build, building the example code will cause Visual Studio to generate a warning for the lines imageData = new int[width * height];, indicating that width and height are uninitialized. Background code analysis focuses on the files you’re actively working on, while build-time analysis ensures all project files are checked, catching any missed issues that aren’t in the current file. This warning will appear in the Error List window. \n\nKey Events in Microsoft C++ Code Analysis help you quickly identify and fix defects by providing detailed information in selected warnings from the Error List. They trace code flow to pinpoint root causes, making it easier to understand issues like variable initialization or branching. For example, double-clicking the C6001 ‘Using uninitialized memory: width’ warning in the Error List opens a new window showing the Key Events. For further insights, please refer to the Microsoft C++ Code Analysis Warnings with Key Events blog. \n\nCode Analysis Rules and Rulesets  \nRulesets in Visual Studio for C++ are collections of code analysis rules that ensure code quality and adherence to standards. For example, enabling the MSVC rule C26440, ‘Function can be declared ‘noexcept’,’ suggests marking functions with ‘noexcept’ if they do not throw exceptions. This can improve both performance and reliability. \nTo create a new custom rule set with the “Function can be declared ‘noexcept’” rule added, follow these steps: \nOpen Project Properties in Visual Studio \nNavigate to Configuration Properties > Code Analysis > Microsoft. \nIn the Active rules section, click “Configure”  \nSelect the check box for the rule that you want to include in the ruleset. The Action will automatically change from ‘None’ to ‘Warning’. You can change the severity of this rule based on your needs, with options like Error, Info, Hidden, None, or <Inherit>.  \nSave the rule set with a new file name. The custom rule set is now automatically assigned to the project. \n\nTo learn more about using rule sets in depth, refer to the Use Rule Sets to Specify the C++ Rules to Run article.  \nAdditional Tools and Techniques\nVisual Studio offers several features that can enhance code quality and prevent issues like the Heartbleed bug. Here are some tools you might find useful: \nClang-Tidy Code Analysis \nClang-Tidy, a tool used with the LLVM/clang-cl compiler, is designed to modernize your code, ensure adherence to standards, perform static analysis, and automatically format your code. When using an MSVC toolset, you can configure Clang-Tidy to complement or replace the conventional Code Analysis process. This helps catch different types of issues and improves overall code quality. You can find more details in Using Clang-Tidy in Visual Studio article. \nSuppress Specific Warnings \nSuppressing specific warnings in C++ involves configuring your project settings to ignore certain compiler warnings for a single line, section of code, file, or entire project. This can be done at the project level or for individual files using Visual Studio’s project properties or ‘#pragma warning’ directives. By suppressing less relevant warnings, you can focus on the most critical issues, making the build output cleaner and easier to read, which simplifies identifying and addressing significant problems. To dive deeper into this topic, check out the Suppress compiler warnings article. \nIt’s important to note that Code Analysis tools may occasionally generate false positives. If you encounter a false positive, please report it through the Visual Studio Developer Community channel with detailed repro code and information. This helps us to improve the accuracy of Code Analysis tools and ensures a smoother development experience. \nLearn More \nTo learn more about securing your C++ programs, visit the Build Reliable and Secure C++ programs blog. For the latest updates to the MSVC backend, check out the MSVC Backend Updates in Visual Studio 2022 version 17.10 blog.  \nYour feedback is invaluable in helping us enhance the MSVC Code Analysis experience. Please share your suggestions in the comments below or through the Developer Community. You can also reach us via email at visualcpp@microsoft.com or via X at @VisualC. \nThe post Prevent Critical Bugs with MSVC Code Analysis appeared first on C++ Team Blog.",
        "dc:creator": "Mryam Girmay",
        "comments": "https://devblogs.microsoft.com/cppblog/prevent-critical-bugs-with-msvc-code-analysis/#comments",
        "content": "<p>Imagine this: You’re deep into a complex C++ project, and everything seems to be running smoothly. But then, out of nowhere, a critical bug surfaces— one that requires a bit more foresight. We’ve all been there, right? This is where code analysis steps in as your silent guardian. </p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/prevent-critical-bugs-with-msvc-code-analysis/\">Prevent Critical Bugs with MSVC Code Analysis</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "Imagine this: You’re deep into a complex C++ project, and everything seems to be running smoothly. But then, out of nowhere, a critical bug surfaces— one that requires a bit more foresight. We’ve all been there, right? This is where code analysis steps in as your silent guardian. \nThe post Prevent Critical Bugs with MSVC Code Analysis appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=34525",
        "categories": [
          "C++"
        ],
        "isoDate": "2024-08-22T18:12:24.000Z"
      }
    ]
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "How PyTorch powers AI training and inference",
        "link": "https://engineering.fb.com/2024/08/23/ml-applications/pytorch-ai-training-inference/",
        "pubDate": "Fri, 23 Aug 2024 16:00:54 +0000",
        "content:encodedSnippet": "Learn about new PyTorch advancements for LLMs and how PyTorch is enhancing every aspect of the LLM lifecycle.\nIn this talk from AI Infra @ Scale 2024, software engineers Wanchao Liang and Evan Smothers are joined by Meta research scientist Kimish Patel to discuss our newest features and tools that enable large-scale training, memory efficient fine-tuning, and on-device LLM capabilities.\nFirst, they cover the importance of memory-efficient fine-tuning and a few common architectural and algorithmic techniques to enable fine-tuning on consumer-grade hardware. Then they discuss the challenges of deploying large models for on-device deployment and how techniques such as quantization make these deployments possible.\n\nThe post How PyTorch powers AI training and inference appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Learn about new PyTorch advancements for LLMs and how PyTorch is enhancing every aspect of the LLM lifecycle. In this talk from AI Infra @ Scale 2024, software engineers Wanchao Liang and Evan Smothers are joined by Meta research scientist Kimish Patel to discuss our newest features and tools that enable large-scale training, memory efficient [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/08/23/ml-applications/pytorch-ai-training-inference/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/08/23/ml-applications/pytorch-ai-training-inference/\">How PyTorch powers AI training and inference</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Learn about new PyTorch advancements for LLMs and how PyTorch is enhancing every aspect of the LLM lifecycle. In this talk from AI Infra @ Scale 2024, software engineers Wanchao Liang and Evan Smothers are joined by Meta research scientist Kimish Patel to discuss our newest features and tools that enable large-scale training, memory efficient [...]\nRead More...\nThe post How PyTorch powers AI training and inference appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21568",
        "categories": [
          "AI Research",
          "ML Applications",
          "Open Source",
          "AI Infra @ Scale"
        ],
        "isoDate": "2024-08-23T16:00:54.000Z"
      },
      {
        "creator": "",
        "title": "Inside the hardware and co-design of MTIA",
        "link": "https://engineering.fb.com/2024/08/22/ml-applications/meta-mtia-hardware-co-design/",
        "pubDate": "Thu, 22 Aug 2024 16:00:34 +0000",
        "content:encodedSnippet": "In this talk from AI Infra @ Scale 2024, Joel Colburn, a software engineer at Meta, technical lead Junqiang Lan, and software engineer Jack Montgomery discuss the second generation of MTIA, Meta’s in-house training and inference accelerator.\nThey cover the co-design process behind building the second generation of Meta’s first-ever custom silicon for AI workloads, including the PyTorch software ecosystem, and the model architectures for Meta’s key applications. They demonstrate how MTIA achieves the performance, efficiency, and developer experience to successfully launch models into production. They also highlight several co-design examples where special silicon features are utilized to accelerate Meta’s models.\n\nThe post Inside the hardware and co-design of MTIA appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>In this talk from AI Infra @ Scale 2024, Joel Colburn, a software engineer at Meta, technical lead Junqiang Lan, and software engineer Jack Montgomery discuss the second generation of MTIA, Meta’s in-house training and inference accelerator. They cover the co-design process behind building the second generation of Meta’s first-ever custom silicon for AI workloads, [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/08/22/ml-applications/meta-mtia-hardware-co-design/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/08/22/ml-applications/meta-mtia-hardware-co-design/\">Inside the hardware and co-design of MTIA</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "In this talk from AI Infra @ Scale 2024, Joel Colburn, a software engineer at Meta, technical lead Junqiang Lan, and software engineer Jack Montgomery discuss the second generation of MTIA, Meta’s in-house training and inference accelerator. They cover the co-design process behind building the second generation of Meta’s first-ever custom silicon for AI workloads, [...]\nRead More...\nThe post Inside the hardware and co-design of MTIA appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21571",
        "categories": [
          "AI Research",
          "ML Applications",
          "AI Infra @ Scale"
        ],
        "isoDate": "2024-08-22T16:00:34.000Z"
      },
      {
        "creator": "",
        "title": "Bringing Llama 3 to life",
        "link": "https://engineering.fb.com/2024/08/21/production-engineering/bringing-llama-3-to-life/",
        "pubDate": "Wed, 21 Aug 2024 16:00:49 +0000",
        "content:encodedSnippet": "Llama 3 is Meta’s most capable openly-available LLM to date and the recently-released Llama 3.1 will enable new workflows, such as synthetic data generation and model distillation with unmatched flexibility, control, and state-of-the-art capabilities that rival the best closed source models. \nAt AI Infra @ Scale 2024, Meta engineers discussed every step of how we built and brought Llama 3 to life, from data and training to inference. \nJoe Spisak, Product Director and Head of Generative AI Open Source at Meta, talks about the history of Llama and Meta’s overarching vision for open source AI.\nHe’s joined by Delia David, a software engineer at Meta, to discuss all things data-related for GenAI. David covers the diversity, volume, and freshness of data needed for GenAI and how different data types should be extracted and prepared.\nKaushik Veeraraghavan, a software engineer at Meta, discusses how Meta trains Llama at scale and delves into the data center, networking, and software investments that have enabled the development of Meta’s Llama 3 models.\nFinally, Ye (Charlotte) Qia, a production engineer at Meta, discusses how Meta handles inference for Llama. Optimizing and scaling LLM inference is important for enabling large-scale product applications. Qia introduces key parallelism techniques that help scale model sizes and context windows, which in turn influence inference system designs. She also discusses practical challenges associated with deploying these complex serving paradigms throughout Meta’s internal cloud to our data center of heterogeneous hardware.\n\nThe post Bringing Llama 3 to life appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Llama 3 is Meta’s most capable openly-available LLM to date and the recently-released Llama 3.1 will enable new workflows, such as synthetic data generation and model distillation with unmatched flexibility, control, and state-of-the-art capabilities that rival the best closed source models.  At AI Infra @ Scale 2024, Meta engineers discussed every step of how we [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/08/21/production-engineering/bringing-llama-3-to-life/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/08/21/production-engineering/bringing-llama-3-to-life/\">Bringing Llama 3 to life</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Llama 3 is Meta’s most capable openly-available LLM to date and the recently-released Llama 3.1 will enable new workflows, such as synthetic data generation and model distillation with unmatched flexibility, control, and state-of-the-art capabilities that rival the best closed source models.  At AI Infra @ Scale 2024, Meta engineers discussed every step of how we [...]\nRead More...\nThe post Bringing Llama 3 to life appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21564",
        "categories": [
          "AI Research",
          "Culture",
          "ML Applications",
          "Open Source",
          "Production Engineering",
          "AI Infra @ Scale"
        ],
        "isoDate": "2024-08-21T16:00:49.000Z"
      },
      {
        "creator": "",
        "title": "Aparna Ramani discusses the future of AI infrastructure",
        "link": "https://engineering.fb.com/2024/08/20/data-infrastructure/aparna-ramani-future-of-ai-infrastructure-meta/",
        "pubDate": "Tue, 20 Aug 2024 16:00:26 +0000",
        "content:encodedSnippet": "Delivering new AI technologies at scale also means rethinking every layer of our infrastructure – from silicon and software systems and even our data center designs.\nFor the second year in a row, Meta’s engineering and infrastructure teams returned for the AI Infra @ Scale conference, where they discussed the challenges of scaling up an infrastructure for AI as well as work being done on our large-scale GPU clusters, open hardware designs for next-generation data center hardware, and how Meta is building custom silicon like the Meta Training and Inference Accelerator (MTIA) to handle some of our AI training workloads.\nAparna Ramani, VP of Engineering at Meta, responsible for AI infrastructure, data infrastructure and developer infrastructure, delivered the opening keynote at AI Infra @Scale 2024 and discussed the AI landscape up to today, the technical challenges, and how solutions like open models and hardware can push AI to new frontiers.\nWatch the full keynote presentation below:\n\nThe post Aparna Ramani discusses the future of AI infrastructure appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Delivering new AI technologies at scale also means rethinking every layer of our infrastructure – from silicon and software systems and even our data center designs. For the second year in a row, Meta’s engineering and infrastructure teams returned for the AI Infra @ Scale conference, where they discussed the challenges of scaling up an [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2024/08/20/data-infrastructure/aparna-ramani-future-of-ai-infrastructure-meta/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2024/08/20/data-infrastructure/aparna-ramani-future-of-ai-infrastructure-meta/\">Aparna Ramani discusses the future of AI infrastructure</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Delivering new AI technologies at scale also means rethinking every layer of our infrastructure – from silicon and software systems and even our data center designs. For the second year in a row, Meta’s engineering and infrastructure teams returned for the AI Infra @ Scale conference, where they discussed the challenges of scaling up an [...]\nRead More...\nThe post Aparna Ramani discusses the future of AI infrastructure appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=21559",
        "categories": [
          "AI Research",
          "Data Center Engineering",
          "Data Infrastructure",
          "ML Applications",
          "AI Infra @ Scale"
        ],
        "isoDate": "2024-08-20T16:00:26.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Olga Bedrina",
        "title": "The Fail-Fast Strategy: What Is It and How Does TeamCity Support It?",
        "link": "https://blog.jetbrains.com/teamcity/2024/08/fail-fast-strategy-teamcity/",
        "pubDate": "Fri, 23 Aug 2024 09:57:01 +0000",
        "content:encodedSnippet": "This is a guest post from Cameron Pavey, draft.dev.\nSoftware development teams are always looking for ways to move faster and deliver more value in less time. However, one common pitfall for many teams is spending far too much time and effort building something, only to encounter major issues late in the project’s lifecycle.\nThe fail-fast strategy addresses this problem by “shifting left” on potential points of failure and embracing them as part of a virtuous feedback loop. Whether in project management or software development, a failure is often just a signal that something needs to change. The earlier you can detect this signal, the sooner you can adjust for it, thus mitigating the risk of wasted work.\nTo properly implement a fail-fast strategy, you need a tool that supports this way of working. TeamCity is a CI/CD solution that complements the fail-fast strategy and has several features to help you implement it.\nIn this guide, you’ll learn more about the fail fast strategy and how you can leverage TeamCity to adopt this strategy for yourself.\nWhat is the fail-fast strategy?\nIn software development, the fail-fast strategy emphasizes iterative discovery over strict planning. Key principles include:\nRapid feedback loops: Short cycles allow for frequent releases and early feedback, helping teams move quickly and efficiently.\n\n\n\n\nProactive risk management: Early identification of risks allows for timely mitigation or pivoting, reducing wasted effort.\n\n\n\n\nIterative experimentation: Frequent experimentation helps quickly identify dead ends and promising solutions, optimizing the use of resources.\n\n\n\n\nTransparency: Promotes a culture of continuous improvement, where teams share and learn openly.\nThis strategy operates on multiple levels:\nProject management: Focuses on direction, ideation, and finding product-market fit.\nSoftware development: Applies the same principles to concrete practices like continuous integration (CI).\nPairing the fail-fast mentality with a CI service like TeamCity helps shorten feedback cycles and improve outcomes by rapidly identifying and addressing issues.\nMajor advantages of the fail-fast strategy\nCompared to traditional methods like the waterfall strategy, the fail-fast strategy offers significant benefits:\nShorter feedback loop: Submit small, incremental changes for automated checks, catching faults early and fixing them quickly.\nIdentifying pitfalls early on: Incremental builds help identify technical issues early, allowing for timely adjustments and de-risking your approach upfront.\nPotential drawbacks of the fail-fast strategy\nWhile the fail-fast strategy offers many benefits, there are potential drawbacks:\nMindset shift: Teams used to traditional methods may resist the concept of “failure”, impacting morale and causing frustration.\nEmbracing failure: Understanding that failure, discovery, and pivoting are key elements is crucial for the strategy’s success.\nTooling requirements: Effective implementation requires robust tools, particularly a CI/CD tool like TeamCity.\nHow does TeamCity support the fail-fast strategy?\nAs the central goal of the fail-fast strategy is shorter feedback cycles, you need a tool that provides this feedback for you in a timely manner. Continuous integration tools, such as TeamCity, are designed for this purpose. They can run builds, tests, and other scripted workflows in response to code changes.\nReal-time reporting\nLarge software projects can have long, slow-running builds. This makes it especially frustrating when you wait a long time for a build to run, only to discover that it failed. Whether it’s a blocking build issue that stops subsequent steps or an early test failure that makes the rest of the run redundant – the sooner you discover these issues, the better.\nTeamCity mitigates this issue for you by providing real-time reporting. You can view in-progress builds, inspect their current state, and build logs to identify problems as they occur rather than waiting until the end of a CI run.\nBy seeing the live status of running builds, developers can identify and fix problems without waiting for the build to finish. When the build fails, you can see what went wrong, fix it, and run another build. Compared to other CI systems where you need to wait for the build to complete, this workflow offers a shorter feedback cycle that works well with the fail-fast strategy.\n\n\n\n\nThis approach is particularly effective if quick-running build steps provide high-value feedback, like static analysis and other code quality checks. You can view the progress of these live to determine if you need to make any alterations to your code, and once these pass, you can leave the rest of the build to run.\nBuild configurations\nYour build process will likely be nontrivial when dealing with complex software systems. You’ll need to do any number of steps, including:\nBuilding Docker images\nCompiling source code\nDownloading dependencies\nRunning various kinds of tests (with varying degrees of cost)\nAs your build grows over time, it could become too large to reasonably manage. At this point, you may want to find a way to split the build into smaller steps.\nTeamCity solves this through build configurations. Build configurations allow you to split your build into discrete steps. When you do this, each step has a clearly defined responsibility, limiting the potential for complexity to leak between steps as your system grows.\nBuild chains\nAnother helpful feature of TeamCity that can be used to implement the fail-fast strategy is build chains. This feature allows you to declare build configurations as dependent on one another. In practice, this means you can run all your quality gates before the deployment step, allowing you to skip the deployment if there are quality issues that prevent it from being a release candidate.\nExample of a build chain in TeamCity\n\n\n\nFailures in the earlier steps in the chain will stop subsequent build configurations from running. This can save time and resources and help shorten the feedback loop even more by avoiding the effort spent on faulty builds.\nTest reports\nFailing tests are a fact of life for software developers. The key factor that separates frustrating failures from helpful failures is how much information you have when trying to fix them. Ideally, you want to know:\n– What failed: Was it a unit test, an integration test, etc.?\n– When it failed: Is it a new failure? Is this the first time it has happened? Is it a recurring flaky test?\n– Why it failed: Is it a legitimate functional failure or a flaky test?\nThis information helps you narrow down the cause and promptly fix the issue. You could run the test on your development machine and see it fail for yourself, but you’ll likely miss out on a lot of context (for example, information about in which commit this failure first arose). \nTeamCity test reports solve this problem. Every time your CI workflow runs, test data is captured for a wide range of testing frameworks. This data is then presented to you in relation to the CI runs that have experienced test failures, as well as a few other views like Current Problems and Flaky Tests.\nExample of a test report in TeamCity\n\n\n\nThese reports provide immediate insights into what problems your build is facing and the nature of the problems, such as flaky tests, newly introduced issues, or long-standing failures. \nHigh-quality test reports are a must for projects that require heavy use of automated testing at any level, but they’re especially helpful if you have broad coverage from unit tests and integration tests.\nThis way, at a glance, you have a comprehensive snapshot of the state of your code base each time CI runs.\nNotifications\nFail fast is only good if you know about the failure, and detailed build information is only helpful if people know it’s there. Developers would typically prefer to work on things themselves rather than sit and watch something being built by CI.\nThanks to highly configurable notifications, there’s no need to babysit builds. In TeamCity, you can configure rules to determine what you would like to be notified about and where you’d like those notifications to go. From email and browser notifications to Slack and even in-IDE notifications, there are several channels to choose from.\nNotification options in TeamCity\n\n\n\nNotifications are a key requirement in a system that’s intended to help you work more proactively, and the more configuration options you have at your disposal, the more use cases you will be able to satisfy.\nFor a fail-fast workflow, you might want to configure notifications for any failed build to which you’ve contributed. Then, relying on the VCS integration, you can get rapid feedback on your changes directly in your IDE as you make small, atomic changes.\nTeamCity notifications can be configured to only notify you of Builds containing my changes or when The first build error occurs. These settings are great for fine-tuning the notifications you see. Rather than seeing every failing build, you might only want to see failures on builds that include your changes or when the first error happens for a build.\nIf you set up continuous development through TeamCity, you can also enable notifications to inform you whenever a deployment or infrastructure change (through infrastructure as code tools like Terraform or Kubernetes deployments) occurs. In this case, you’d likely want to be notified in case of success as well as failure.\nArtifacts\nIssues often arise in CI that you cannot replicate locally. This can lead to a lot of misdirected time as you try to determine which is different between the CI run and your local application. Using artifacts can help address this problem.\nIn TeamCity, artifacts are typically anything produced by your build, such as binaries, logs, recordings, screenshots, etc. You can treat pretty much anything as an artifact, which gives you great flexibility in how you use this feature. Artifacts are then captured by TeamCity and are available for download through the UI after the build.\nThis can greatly streamline the analysis and debugging process that you go through when trying to rectify a failing build. For example, if you have end-to-end (E2E) tests that only seem to fail in your CI runs, there’s a good chance that your E2E tool has the ability to produce screenshots and screen recordings when failures occur. Being able to capture these as artifacts gives you a trove of data to help with debugging.\nArtifacts can also be used for any other use case where you want to capture the output of a build. Perhaps your project produces binary executables. In that case, you could capture the built binary for each CI run, allowing you to test any build for any commit that runs through your CI workflow.\nWrapping up\nThis guide introduced the fail-fast strategy, including its benefits, such as proactive risk management, transparency, and adaptability. TeamCity supports fail-fast through various powerful features, including real-time reporting, flexible notifications, and detailed test reports.\nWhen utilized properly, the fail-fast strategy can be a powerful tool. It can help you move faster and deliver value without the constraints of slower, more traditional ways of working. However, the process needs to be supported by suitably powerful and flexible tools. If you’re looking for a CI/CD server that fits the bill, consider taking TeamCity for a spin today.",
        "dc:creator": "Olga Bedrina",
        "content": "This is a guest post from Cameron Pavey, draft.dev. Software development teams are always looking for ways to move faster and deliver more value in less time. However, one common pitfall for many teams is spending far too much time and effort building something, only to encounter major issues late in the project&#8217;s lifecycle. The [&#8230;]",
        "contentSnippet": "This is a guest post from Cameron Pavey, draft.dev. Software development teams are always looking for ways to move faster and deliver more value in less time. However, one common pitfall for many teams is spending far too much time and effort building something, only to encounter major issues late in the project’s lifecycle. The […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=505010",
        "categories": [
          "news"
        ],
        "isoDate": "2024-08-23T09:57:01.000Z"
      },
      {
        "creator": "Sarah Haggarty",
        "title": "Kotlin 2.0.20 Released",
        "link": "https://blog.jetbrains.com/kotlin/2024/08/kotlin-2-0-20-released/",
        "pubDate": "Thu, 22 Aug 2024 14:51:13 +0000",
        "content:encodedSnippet": "The Kotlin 2.0.20 release is out! This version includes performance improvements and bug fixes for Kotlin 2.0.0, where we announced the Kotlin K2 compiler as Stable. Here are some additional highlights from this release:\nThe data class copy function will have the same visibility as the constructor\nStatic accessors for source sets from the default target hierarchy are now available in multiplatform projects\nConcurrent marking for Kotlin/Native has been made possible in the garbage collector\nThe @ExperimentalWasmDsl annotation in Kotlin/Wasm has a new location\nSupport has been added for Gradle versions 8.6–8.8\nA new option allows sharing JVM artifacts between Gradle projects as class files\nThe Compose compiler has been updated\nSupport for UUIDs has been added to the common Kotlin standard library\n\n\n\n\nFor the complete list of changes, refer to What’s new in Kotlin 2.0.20 or the release notes on GitHub.\nHow to install Kotlin 2.0.20\nStarting from IntelliJ IDEA 2023.3 and Android Studio Iguana (2023.2.1) Canary 15, the Kotlin plugin is distributed as a bundled plugin included in your IDE. This means that you can’t install the plugin from JetBrains Marketplace anymore.\nTo update to the new Kotlin version, change the Kotlin version to 2.0.20 in your build scripts.\nIf you need the command-line compiler, download it from the GitHub release page.\nIf you run into any problems\nFind help on Slack (get an invite).\nReport issues to our issue tracker, YouTrack.\n\n\n\n\n\nStay up to date with the latest Kotlin features! Subscribe to receive Kotlin updates by filling out the form at the bottom of this post. ⬇️\nSpecial thanks to our EAP Champions 🥇👏\nZac Sweers\nRick Clephas\nFlorian Schreiber\nSechaba Mofokeng\nYang\nŁukasz Wasylkowski\nDavid Lopez\nBernd Prünster\nAlexander Nozik\nBenoit ‘BoD’ Lubek\nSterling Albury\nKacper Wojciechowski\nMohamed Rejeb\nJake Wharton\nJohannes Svensson\nArtyom Shendrik\n\n\n\n\nWhat else to read and watch\nWhat’s new in Kotlin 2.0.20 documentation\nK2 compiler migration guide\nK2 Compiler Performance Benchmarks and How to Measure Them on Your Projects\nMeet Renovated Kotlin Support – K2 Mode: What You Need to Know\nJetpack Compose compiler moving to the Kotlin repository\nKotlin EAP Champions",
        "dc:creator": "Sarah Haggarty",
        "content": "The Kotlin 2.0.20 release is out! This version includes performance improvements and bug fixes for Kotlin 2.0.0, where we announced the Kotlin K2 compiler as Stable. Here are some additional highlights from this release: For the complete list of changes, refer to What&#8217;s new in Kotlin 2.0.20 or the release notes on GitHub. How to [&#8230;]",
        "contentSnippet": "The Kotlin 2.0.20 release is out! This version includes performance improvements and bug fixes for Kotlin 2.0.0, where we announced the Kotlin K2 compiler as Stable. Here are some additional highlights from this release: For the complete list of changes, refer to What’s new in Kotlin 2.0.20 or the release notes on GitHub. How to […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=503938",
        "categories": [
          "releases"
        ],
        "isoDate": "2024-08-22T14:51:13.000Z"
      },
      {
        "creator": "Alena Guzharina",
        "title": "What’s New in Datalore 2024.4: Limit 500 Toggle, Easier Folder Import, Polars DataFrames Support, and More",
        "link": "https://blog.jetbrains.com/datalore/2024/08/22/what-s-new-in-datalore-2024-4-limit-500-toggle-easier-folder-import-polars-dataframes-support-and-more/",
        "pubDate": "Thu, 22 Aug 2024 10:07:56 +0000",
        "content:encodedSnippet": "Datalore 2024.4 introduces quality-of-life improvements for SQL cells, a revamped folder import workflow, support for Polars DataFrames, and more. Datalore Cloud customers have already received the new update automatically, and Datalore On-Premises customers can upgrade by following these instructions.\nLimit 500 toggle for SQL cells\nTo help you prototype SQL queries faster, we’ve introduced a new Limit 500 feature inside SQL cells in Datalore notebooks. There is now a toggle visible in the SQL cell next to the Browse schema action. This setting will persist after a kernel restart, ensuring a seamless workflow.\n\n\n\n\nRevamped import folder workflow\nIt is now easier to import your previous work into Datalore. We’ve enhanced the folder import experience with a new, streamlined dialog that appears when you click Import | Upload folder. You can now easily select which notebooks and files to import, with the option to import notebooks as files. Hidden files and folders are fully supported and can be imported if selected. \n\n\n\n\nUpdates to the notebook UI\nWe’ve made several updates to the notebook UI to enhance your editing experience. Unfocused code cells now have borders, improving cell visibility and making it easier to target the insert cell buttons. Interactive controls and metric cells now have their options merged with the cell toolbar, no longer occupying the full width of the notebook. Additionally, cell type-specific actions, such as selecting a datasource or target variable, are now positioned to the right of the execution time for easier access. Cells now also feature a Run button, which can be gray or blue depending on whether the cell was changed after execution – offering a clearer indication of a cell’s status.\n\n\n\n\nDrop-down cell improvements\nFor large lists, you can now use a search string within the drop-down to quickly find your desired option. Additionally, multiselect drop-downs now include Select all and Clear all options.\n\n\n\n\nQuick notebook access from the editor\nYou can now quickly search for and open notebooks in a separate tab directly from the Notebooks view. Enjoy easier navigation without extra context switching.\n\n\n\n\nSupport for Polars DataFrames\nDatalore now supports rich table outputs for Polars DataFrames. To get an interactive table output, specify the DataFrame name at the end of the cell without a print statement.\n\n\n\n\nOther updates and bug fixes\nDuplicate file names are no longer permitted inside Datalore’s file system, with existing duplicates renamed with (#N) prefixes to make files easier to find and minimize naming confusion. \nPython `input()` commands are now supported for interactive reports. \nGit repositories with submodules are now cloned correctly. \nTables are no longer cropped when printing to PDF. \nWe’ve resolved the issue where pages would not load when Datalore was set up with an HTTP proxy on a non-standard port. \nWe’ve fixed the issue where refreshing the schema in the Edit database connection dialog would not work for users logged in via OAuth.\nIt is now possible to copy data from the cell outputs to the clipboard via the output’s context menut. This feature is supported for most cell output types. \nThe workspace owner is now indicated in the left-hand sidebar of the home page.\nDatalore Cloud customers have already received these updates automatically. \nFor Datalore On-Premises customers, it is highly important to ensure the database that stores all the Datalore content is backed up before upgrading to the 2024.4 version.\n      \n      Upgrade to 2024.4\n    \n\n\n\n\nKind regards,\nThe Datalore team",
        "dc:creator": "Alena Guzharina",
        "content": "Datalore 2024.4 introduces quality-of-life improvements for SQL cells, a revamped folder import workflow, support for Polars DataFrames, and more. Datalore Cloud customers have already received the new update automatically, and Datalore On-Premises customers can upgrade by following these instructions. Limit 500 toggle for SQL cells To help you prototype SQL queries faster, we&#8217;ve introduced a [&#8230;]",
        "contentSnippet": "Datalore 2024.4 introduces quality-of-life improvements for SQL cells, a revamped folder import workflow, support for Polars DataFrames, and more. Datalore Cloud customers have already received the new update automatically, and Datalore On-Premises customers can upgrade by following these instructions. Limit 500 toggle for SQL cells To help you prototype SQL queries faster, we’ve introduced a […]",
        "guid": "https://blog.jetbrains.com/?post_type=datalore&p=504871",
        "categories": [
          "releases"
        ],
        "isoDate": "2024-08-22T10:07:56.000Z"
      },
      {
        "creator": "Khalid Abuhakmeh",
        "title": "ReSharper Tips & Tricks with Matt Ellis – Livestream",
        "link": "https://blog.jetbrains.com/dotnet/2024/08/21/resharper-tips-tricks-with-matt-ellis-livestream/",
        "pubDate": "Wed, 21 Aug 2024 13:58:37 +0000",
        "content:encodedSnippet": "Join us on September 12, 2024, at 2:00 PM UTC for another JetBrains livestream event. You can register for the event using the link below or subscribe to our YouTube channel, JetBrainsTV, to get a notification closer to the event.\nRegister\n                                \nfor the livestream\n\n\n\n\nWith over 20 years of ReSharper setting the standard for the .NET development experience, it’s time for .NET developers, new and accomplished, to see what the #1 productivity extension for Visual Studio has to offer. In this livestream, we’ll be joined by JetBrains Developer Advocate Matt Ellis, who will highlight some of his best tips and tricks to get the most productivity gains in your .NET workflows. Discover what you’ve been missing with ReSharper.\nMatt Ellis – Developer Advocate Game Development, JetBrains\nMatt Ellis is a developer advocate at JetBrains, working with lots of different IDEs and technologies such as the Unity and Unreal Engine game development tools in Rider, Code With Me for collaborative editing and remote development with JetBrains Gateway. He has spent (well) over 20 years shipping software in various industries, and thoroughly enjoys working with IDEs and development tools, having fun with syntax trees and source code analysis. He also helps build the Unity support in Rider, and contributes to the popular IdeaVim plugin.",
        "dc:creator": "Khalid Abuhakmeh",
        "content": "Join us on September 12, 2024, at 2:00 PM UTC for another JetBrains livestream event. You can register for the event using the link below or subscribe to our YouTube channel, JetBrainsTV, to get a notification closer to the event. With over 20 years of ReSharper setting the standard for the .NET development experience, it&#8217;s [&#8230;]",
        "contentSnippet": "Join us on September 12, 2024, at 2:00 PM UTC for another JetBrains livestream event. You can register for the event using the link below or subscribe to our YouTube channel, JetBrainsTV, to get a notification closer to the event. With over 20 years of ReSharper setting the standard for the .NET development experience, it’s […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=503092",
        "categories": [
          "net-tools",
          "c",
          "resharper",
          "visual-studio"
        ],
        "isoDate": "2024-08-21T13:58:37.000Z"
      },
      {
        "creator": "Evgenia Verbina",
        "title": "How to Build Chatbots With LangChain",
        "link": "https://blog.jetbrains.com/pycharm/2024/08/how-to-build-chatbots-with-langchain/",
        "pubDate": "Wed, 21 Aug 2024 10:06:08 +0000",
        "content:encodedSnippet": "This is a guest post from Dido Grigorov, a deep learning engineer and Python programmer with 17 years of experience in the field.\n\n\n\n\nChatbots have evolved far beyond simple question-and-answer tools. With the power of large language models (LLMs), they can understand the context of conversations and generate human-like responses, making them invaluable for customer support applications and other types of virtual assistance. \nLangChain, an open-source framework, streamlines the process of building these conversational chatbots by providing tools for seamless model integration, context management, and prompt engineering.\nIn this blog post, we’ll explore how LangChain works and how chatbots interact with LLMs. We’ll also guide you step by step through building a context-aware chatbot that delivers accurate, relevant responses using LangChain and GPT-3.\n\n\n\n\nWhat are the chatbots in the realm of LLMs?\nChatbots in the field of LLMs are cutting-edge software that simulate human-like conversations with users through text or voice interfaces. These chatbots exploit the advanced capabilities of LLMs, which are neural networks trained on huge amounts of text data which allows them to produce human-like responses to a wide range of input prompts.\nOne among all other matters is that LLM-based chatbots can take a conversation’s context into account when generating a response. This means they can keep coherence across several exchanges and can process complex queries to produce outputs that are in line with the users’ intentions. Additionally, these chatbots assess the emotional tone of a user’s input and adjust their responses to match the user’s sentiments.\nChatbots are highly adaptable and personalized. They learn from how users interact with them thus improving on their responses by adjusting them according to individual preferences and needs. \nWhat is LangChain?\nLangChain is a framework that’s open-source developed for creating apps that use large language models (LLMs). It comes with tools and abstractions to better personalize the information produced from these models while maintaining accuracy and relevance. \nOne common term you can see when you read about LLMs is “prompt chains”. A prompt chain refers to a sequence of prompts or instructions used in the context of artificial intelligence and machine learning, with the purpose to guide the AI model through a multi-step process to generate more accurate, detailed, or refined outputs. This method can be employed for various tasks, such as writing, problem-solving, or generating code. \nDevelopers can create new prompt chains using LangChain, which is one of the strongest sides of the framework. They can even modify existing prompt templates without needing to train the model again when using new datasets.\nHow does LangChain work?\nLangChain is a framework designed to simplify the development of applications that utilize language models. It offers a suite of tools that help developers efficiently build and manage applications that involve natural language processing (NLP) and Large Language Models. By defining the steps needed to achieve the desired outcome (this might be a chatbot, task automation, virtual assistant, customer support, and even more), developers can adapt language models flexibly to specific business contexts using LangChain. \nHere’s a high-level overview of how LangChain works.\nModel integration\nLangChain supports various Language models including those from OpenAI, Hugging Face, Cohere, Anyscale, Azure Models, Databricks, Ollama, Llama, GPT4All, Spacy, Pinecone, AWS Bedrock, MistralAI, among others. Developers can easily switch between different models or use multiple models in one application. They can build custom-developed model integration solutions, which allow developers to take advantage of specific capabilities tailored to their specific applications.\nChains\nThe core concept of LangChain is chains, which bring together different AI components for context-aware responses. A chain represents a set of automated actions between a user prompt and the final model output. There are two types of chains provided by LangChain:\nSequential chains: These chains enable the output of a model or function to be used as an input for another one. This is particularly helpful in making multi-step processes that depend on each other.\nParallel chains: It allows for simultaneous running of multiple tasks, with their outputs merged at the end. This makes it perfect for doing tasks that can be divided into subtasks that are completely independent.\nMemory\nLangChain facilitates the storage and retrieval of information across various interactions. This is essential where there is need for persistence of context such as with chat-bots or interactive agents. There are also two types of memory provided:\nShort-term memory – Helps keep track of recent sessions.\nLong-term memory – Allows retention of information from previous sessions enhancing system recall capability on past chats and user preferences.\nTools and utilities\nLangChain provides many tools, but the most used ones are Prompt Engineering, Data Loaders and Evaluators.  When it comes to Prompt Engineering, LangChain contains utilities to develop good prompts, which are very important in getting the best responses from language models.\nIf you want to load up files like csv, pdf or other format, Data Loaders are here to help you to load and pre-process different types of data hence making them usable in model interactions.\nEvaluation is an essential part of working with machine learning models and large language models. That’s why LangChain provides Evaluators – tools used for testing language models and chains so that generated results meet the required criteria, which might include:\nDatasets criteria:\nManually curated examples: Start with high-quality, diverse inputs.\nHistorical logs: Use real user data and feedback.\nSynthetic data: Generate examples based on initial data.\nTypes of evaluations:\nHuman: Manual scoring and feedback.\nHeuristic: Rule-based functions, both reference-free and reference-based.\nLLM-as-judge: LLMs score outputs based on encoded criteria.\nPairwise: Compare two outputs to pick the better one.\nApplication evaluations:\nUnit tests: Quick, heuristic-based checks.\nRegression testing: Measure performance changes over time.\nBack-testing: Re-run production data on new versions.\nOnline evaluation: Evaluate in real-time, often for guardrails and classifications.\nAgents\nLangChain agents are essentially autonomous entities that leverage LLMs to interact with users, perform tasks, and make decisions based on natural language inputs.\nAction-driven agents use language models to decide on optimal actions for predefined tasks. On the other side interactive agents or interactive applications such as chatbots make use of these agents, which also take into account user input and stored memory when responding to queries.\nHow do chatbots work with LLMs?\nLLMs underlying chatbots use Natural Language Understanding (NLU) and Natural Language Generation (NLG), which are made possible through pre-training of models on vast textual data.\nNatural Language Understanding (NLU)\nContext awareness: LLMs can understand the subtlety and allusions in a conversation, and they can keep track of the conversation from one turn to the next. This makes it possible for the chatbots to generate logical and contextually appropriate responses to the clients.\nIntent recognition: These models should be capable of understanding the user’s intent from their queries, whether the language is very specific or quite general. They can discern what the user wants to achieve and determine the best way to help them reach that goal.\nSentiment analysis: Chatbots can determine the emotion of the user through the tone of language used and adapt to the user’s emotional state, which increases the engagement of the user.\nNatural Language Generation (NLG)\nResponse generation: When LLMs are asked questions, the responses they provide are correct both in terms of grammar and the context. This is because the responses that are produced by these models mimic human communication, due to the training of the models on vast amounts of natural language textual data.\nCreativity and flexibility: Apart from simple answers, LLM-based chatbots can tell a story, create a poem, or provide a detailed description of a specific technical issue and, therefore, can be considered to be very flexible in terms of the provided material.\nPersonalization and adaptability\nLearning from interactions: Chatbots make the interaction personalized because they have the ability to learn from the users’ behavior, as well as from their choices. It can be said that it is constantly learning, thereby making the chatbot more effective and precise in answering questions.\nAdaptation to different domains: The LLMs can be tuned to particular areas or specialties that allow the chatbots to perform as subject matter experts in customer relations, technical support, or the healthcare domain.\nLLMs are capable of understanding and generating text in multiple languages, making them suitable for applications in diverse linguistic contexts.\nBuilding your own chatbot with LangChain in five steps\nThis project aims to build a chatbot that leverages GPT-3 to search for answers within documents. First, we scrape content from online articles, split them into small chunks, compute their embeddings, and store them in Deep Lake. Then, we use a user query to retrieve the most relevant chunks from Deep Lake, which are incorporated into a prompt for generating the final answer with the LLM.\nIt’s important to note that using LLMs carries a risk of generating hallucinations or false information. While this may be unacceptable for many customer support scenarios, the chatbot can still be valuable for assisting operators in drafting answers that they can verify before sending to users.\nNext, we’ll explore how to manage conversations with GPT-3 and provide examples to demonstrate the effectiveness of this workflow\nStep 1: Project creation, prerequisites, and required library installation\nFirst create your PyCharm project for the chatbot. Open up Pycharm and click on “new project”. Then give a name of your project.\n\n\n\n\nOnce ready with the project set up, generate your `OPENAI_API_KEY` on the OpenAI API Platform Website, once you are logged in (or sign up on the OpenAI website for that purpose). To do that go to the “API Keys” section on the left navigation menu and then click on the button “+Create new secret key”. Don’t forget to copy your key.\nAfter that get your `ACTIVELOOP_TOKEN` by signing up on the Activeloop website. Once logged in, just click on the button “Create API Token” and you’ll be navigated to the token creation page. Copy this token as well.\nOnce you have both the token and the key, open your configuration settings in PyCharm, by clicking on the 3 dots button next to the run and debug buttons, and choose “Edit”. You should see the following window:\n\n\n\n\nNow locate the field “Environment variables” and find the icon on the right side of the field. Then click there – you’ll see the following window:\n\n\n\n\nAnd now by clicking the + button start adding your environmental variables and be careful with their names. They should be the same as mentioned above: `OPENAI_API_KEY` and `ACTIVELOOP_TOKEN`. When ready just click OK on the first window and then “Apply” and “OK” on the second one.\nThat’s a very big advantage of PyCharm and I very much love it, because it handles the environment variables for us automatically without the requirement for additional calls to them, allowing us to think more about the creative part of the code.\nNote: ActiveLoop is a technology company that focuses on developing data infrastructure and tools for machine learning and artificial intelligence. The company aims to streamline the process of managing, storing, and processing large-scale datasets, particularly for deep learning and other AI applications.\nDeepLake is an ActiveLoop’s flagship product. It provides efficient data storage, management, and access capabilities, optimized for large-scale datasets often used in AI.\nInstall the required libraries\nWe’ll use the `SeleniumURLLoader` class from LangChain, which relies on the `unstructured` and `selenium` Python libraries. Install these using pip.  It is recommended to install the latest version, although the code has been specifically tested with version 0.7.7. \nTo do that use the following command in your PyCharm terminal:\npip install unstructured selenium\n\n\n\n\nNow we need to install langchain, deeplake and openai. To do that just use this command in your terminal (same window you used for Selenium) and wait a bit until everything is successfully installed:\npip install langchain==0.0.208 deeplake openai==0.27.8 psutil tiktoken\nTo make sure all libraries are properly installed, just add the following lines needed for our chatbot app and click on the Run button:\nfrom langchain.embeddings.openai import OpenAIEmbeddings\n\nfrom langchain.vectorstores import DeepLake\n\nfrom langchain.text_splitter import CharacterTextSplitter\n\nfrom langchain import OpenAI\n\nfrom langchain.document_loaders import SeleniumURLLoader\n\nfrom langchain import PromptTemplate\nAnother way to install your libraries is through the settings of PyCharm. Open them and go to the section Project -> Project Interpreter. Then locate the + button, search for your package and hit the button “Install Package”. Once ready, close it, and on the next window click “Apply” and then “OK”.\n\n\n\n\nStep 2: Splitting content into chunks and computing their embeddings\nAs previously mentioned, our chatbot will “communicate” with content coming out of online articles, that’s why I picked Digitaltrends.com as my source of data and selected 8 articles to start. All of them are organized into a Python list and assigned to a variable called “articles”.\narticles = ['https://www.digitaltrends.com/computing/claude-sonnet-vs-gpt-4o-comparison/',\n           'https://www.digitaltrends.com/computing/apple-intelligence-proves-that-macbooks-need-something-more/',\n           'https://www.digitaltrends.com/computing/how-to-use-openai-chatgpt-text-generation-chatbot/',\n           'https://www.digitaltrends.com/computing/character-ai-how-to-use/',\n           'https://www.digitaltrends.com/computing/how-to-upload-pdf-to-chatgpt/']\nWe load the documents from the provided URLs and split them into chunks using the `CharacterTextSplitter` with a chunk size of 1000 and no overlap:\n# Use the selenium to load the documents\nloader = SeleniumURLLoader(urls=articles)\ndocs_not_splitted = loader.load()\n\n# Split the documents into smaller chunks\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ndocs = text_splitter.split_documents(docs_not_splitted)\nIf you run the code till now you should receive the following output, if everything works well:\n[Document(page_content=\"techcrunch\\n\\ntechcrunch\\n\\nWe, TechCrunch, are part of the Yahoo family of brandsThe sites and apps that we own and operate, including Yahoo and AOL, and our digital advertising service, Yahoo Advertising.Yahoo family of brands.\\n\\n    When you use our sites and apps, we use \\n\\nCookiesCookies (including similar technologies such as web storage) allow the operators of websites and apps to store and read information from your device. Learn more in our cookie policy.cookies to:\\n\\nprovide our sites and apps to you\\n\\nauthenticate users, apply security measures, and prevent spam and abuse, and\\n\\nmeasure your use of our sites and apps\\n\\n    If you click '\", metadata={'source': ……………]\nNext, we generate the embeddings using OpenAIEmbeddings and save them in a DeepLake vector store hosted in the cloud. Ideally, in a production environment, we could upload an entire website or course lesson to a DeepLake dataset, enabling searches across thousands or even millions of documents. \nBy leveraging a serverless Deep Lake dataset in the cloud, applications from various locations can seamlessly access a centralized dataset without the necessity of setting up a vector store on a dedicated machine.\nWhy do we need embeddings and documents in chunks?\nWhen building chatbots with Langchain, embeddings and chunking documents are essential for several reasons that relate to the efficiency, accuracy, and performance of the chatbot.\nEmbeddings are vector representations of text (words, sentences, paragraphs, or documents) that capture semantic meaning. They encapsulate the context and meaning of words in a numerical form. This allows the chatbot to understand and generate responses that are contextually appropriate by capturing nuances, synonyms, and relationships between words.\nThanks to the embeddings, the chatbot can also quickly identify and retrieve the most relevant responses or information from a knowledge base, because they allow matching user queries with the most semantically relevant chunks of information, even if the wording differs.\nChunking, on the other side, involves dividing large documents into smaller, manageable pieces or chunks. Smaller chunks are faster to process and analyze compared to large, monolithic documents. This results in quicker response times from the chatbot.\nDocument chunking helps also with the relevancy of the output, because when a user asks a question, it is often only in a specific part of a document. Chunking allows the system to pinpoint and retrieve just the relevant sections and the chatbot can provide more precise and accurate answers.\nNow let’s get back to our application and let’s update the following code by including your Activeloop organization ID. Keep in mind that, by default, your organization ID is the same as your username.\n# TODO: use your organization id here. (by default, org id is your username)\nmy_activeloop_org_id = \"didogrigorov\"\nmy_activeloop_dataset_name = \"jetbrains_article_dataset\"\ndataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\ndb = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n\n\n# add documents to our Deep Lake dataset\ndb.add_documents(docs)\nAnother great feature of PyCharm I love is the option TODO notes to be added directly in Python comments. Once you type TODO with capital letters, all notes go to a section of PyCharm where you can see them all:\n# TODO: use your organization id here. (by default, org id is your username)\nYou can click on them and PyCharm directly shows you where they are in your code. I find it very convenient for developers and use it all the time:\n\n\n\n\nIf you execute the code till now you should see the following output, if everything works normal:\n\n\n\n\nTo find the most similar chunks to a given query, we can utilize the similarity_search method provided by the Deep Lake vector store:\n# Check the top relevant documents to a specific query\nquery = \"how to check disk usage in linux?\"\ndocs = db.similarity_search(query)\nprint(docs[0].page_content)\nStep 3: Let’s build the prompt for GPT-3\nWe will design a prompt template that integrates role-prompting, pertinent Knowledge Base data, and the user’s inquiry. This template establishes the chatbot’s persona as an outstanding customer support agent. It accepts two input variables: chunks_formatted, containing the pre-formatted excerpts from articles, and query, representing the customer’s question. The goal is to produce a precise response solely based on the given chunks, avoiding any fabricated or incorrect information.\nStep 4: Building the chatbot functionality\nTo generate a response, we begin by retrieving the top-k (e.g., top-3) chunks that are most similar to the user’s query. These chunks are then formatted into a prompt, which is sent to the GPT-3 model with a temperature setting of 0.\n# user question\nquery = \"How to check disk usage in linux?\"\n\n# retrieve relevant chunks\ndocs = db.similarity_search(query)\nretrieved_chunks = [doc.page_content for doc in docs]\n\n# format the prompt\nchunks_formatted = \"\\n\\n\".join(retrieved_chunks)\nprompt_formatted = prompt.format(chunks_formatted=chunks_formatted, query=query)\n\n# generate answer\nllm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\nanswer = llm(prompt_formatted)\nprint(answer)\nIf everything works fine, your output should be:\nTo upload a PDF to ChatGPT, first log into the website and click the paperclip icon next to the text input field. Then, select the PDF from your local hard drive, Google Drive, or Microsoft OneDrive. Once attached, type your query or question into the prompt field and click the upload button. Give the system time to analyze the PDF and provide you with a response.\nStep 5: Build conversational history\n# Create conversational memory\nmemory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"input\")\n\n# Define a prompt template that includes memory\ntemplate = \"\"\"You are an exceptional customer support chatbot that gently answers questions.\n\n{chat_history}\n\nYou know the following context information.\n\n{chunks_formatted}\n\nAnswer the following question from a customer. Use only information from the previous context information. Do not invent stuff.\n\nQuestion: {input}\n\nAnswer:\"\"\"\n\nprompt = PromptTemplate(\n    input_variables=[\"chat_history\", \"chunks_formatted\", \"input\"],\n    template=template,\n)\n\n# Initialize the OpenAI model\nllm = OpenAI(openai_api_key=\"YOUR API KEY\", model=\"gpt-3.5-turbo-instruct\", temperature=0)\n\n# Create the LLMChain with memory\nchain = LLMChain(\n    llm=llm,\n    prompt=prompt,\n    memory=memory\n)\n\n# User query\nquery = \"What was the 5th point about on the question how to remove spotify account?\"\n\n# Retrieve relevant chunks\ndocs = db.similarity_search(query)\nretrieved_chunks = [doc.page_content for doc in docs]\n\n# Format the chunks for the prompt\nchunks_formatted = \"\\n\\n\".join(retrieved_chunks)\n\n# Prepare the input for the chain\ninput_data = {\n    \"input\": query,\n    \"chunks_formatted\": chunks_formatted,\n    \"chat_history\": memory.buffer\n}\n\n# Simulate a conversation\nresponse = chain.predict(**input_data)\n\nprint(response)\nLet’s walk through the code in a more conversational manner.\nTo start with, we set up a conversational memory using `ConversationBufferMemory`. This allows our chatbot to remember the ongoing chat history, using `input_key=”input”` to manage the incoming user inputs.\nNext, we design a prompt template. This template is like a script for the chatbot, including sections for chat history, the chunks of information we’ve gathered, and the current user question (input). This structure helps the chatbot know exactly what context it has and what question it needs to answer.\nThen, we move on to initializing our language model chain, or `LLMChain`. Think of this as assembling the components: we take our prompt template, the language model, and the memory we set up earlier, and combine them into a single workflow.\nWhen it’s time to handle a user query, we prepare the input. This involves creating a dictionary that includes the user’s question (`input`) and the relevant information chunks (`chunks_formatted`). This setup ensures that the chatbot has all the details it needs to craft a well-informed response.\nFinally, we generate a response. We call the `chain.predict` method, passing in our prepared input data. The method processes this input through the workflow we’ve built, and out comes the chatbot’s answer, which we then display.\nThis approach allows our chatbot to maintain a smooth, informed conversation, remembering past interactions and providing relevant answers based on the context.\nAnother favorite trick with PyCharm that helped me a lot to build this functionality was the opportunity to put my cursor over a method, to hit the key “CTRL” and click on it.\nIn conclusion\nGPT-3 excels at creating conversational chatbots capable of answering specific questions based on contextual information provided in the prompt. However, ensuring the model generates answers solely based on this context can be challenging, as it often tends to hallucinate (i.e., generate new, potentially false information). The impact of such false information varies depending on the use case.\nIn summary, we developed a context-aware question-answering system using LangChain, following the provided code and strategies. The process included splitting documents into chunks, computing their embeddings, implementing a retriever to find similar chunks, crafting a prompt for GPT-3, and using the GPT-3 model for text generation. This approach showcases the potential of leveraging GPT-3 to create powerful and contextually accurate chatbots while also emphasizing the importance of being vigilant about the risk of generating false information.\nAbout the author\nDido Grigorov\nDido is a seasoned Deep Learning Engineer and Python programmer with an impressive 17 years of experience in the field. He is currently pursuing advanced studies at the prestigious Stanford University, where he is enrolled in a cutting-edge AI program, led by renowned experts such as Andrew Ng, Christopher Manning, Fei-Fei Li and Chelsea Finn, providing Dido with unparalleled insights and mentorship.\nDido’s passion for Artificial Intelligence is evident in his dedication to both work and experimentation. Over the years, he has developed a deep expertise in designing, implementing, and optimizing machine learning models. His proficiency in Python has enabled him to tackle complex problems and contribute to innovative AI solutions across various domains.",
        "dc:creator": "Evgenia Verbina",
        "content": "This is a guest post from Dido Grigorov, a deep learning engineer and Python programmer with 17 years of experience in the field. Chatbots have evolved far beyond simple question-and-answer tools. With the power of large language models (LLMs), they can understand the context of conversations and generate human-like responses, making them invaluable for customer [&#8230;]",
        "contentSnippet": "This is a guest post from Dido Grigorov, a deep learning engineer and Python programmer with 17 years of experience in the field. Chatbots have evolved far beyond simple question-and-answer tools. With the power of large language models (LLMs), they can understand the context of conversations and generate human-like responses, making them invaluable for customer […]",
        "guid": "https://blog.jetbrains.com/?post_type=pycharm&p=503887",
        "categories": [
          "data-science",
          "how-tos",
          "chatbots",
          "langchain",
          "llms"
        ],
        "isoDate": "2024-08-21T10:06:08.000Z"
      },
      {
        "creator": "Daniela Bentrup",
        "title": "Fleet 1.39 Is Out With Smart Mode for Single Files, the Ability to Compare Files, the Structure Tool Window, Automatic Language Detection for Untitled Files, and Other Enhancements",
        "link": "https://blog.jetbrains.com/fleet/2024/08/fleet-1-39-is-out-with-smart-mode-for-single-files-the-ability-to-compare-files-the-structure-tool-window-automatic-language-detection-for-untitled-files-and-other-enhancements/",
        "pubDate": "Tue, 20 Aug 2024 14:59:18 +0000",
        "content:encodedSnippet": "Fleet 1.39 is now available! Explore our latest release, which introduces many new features designed to improve your development experience. You can update to this version using the Toolbox App.\nLet’s take a closer look at the highlights.\nDownload Fleet 1.39\nNew features\nYou can now open a file and use Smart Mode without having to open a folder. This feature is currently supported for most languages that use the IntelliJ backend, including but not limited to Java, Kotlin, TypeScript, JavaScript, PHP, Python, and Go. It is also available for C+⁠⁠⁠+.\nIn version 1.39, we’ve implemented a file comparison feature. Go to Git | Current File and select Compare with Branch or Compare with Commit to review differences between files and directories.\nThe new Structure tool window offers a dedicated interface for viewing and navigating the structure of a file, which can be more convenient than using the Structure popup when working with large files. To open it, go to View | Symbols or use the Actions shortcut (⇧⌘K / Ctrl+Shift+K) and select Jump to Symbols Tool.\n\n\n\n\n\nWe’ve added an inlay hint for generating documentation. Just type /** and press Enter to bring up the Generate Documentation option, and then press ⌥↵ / Alt+Enter to show the tooltip. Inlay hints are currently supported for Java, Kotlin, and JavaScript. This feature will also be made available for PHP, Groovy, and Swift in later versions.\n\n\n\n\n\nFleet 1.39 offers automatic language detection for untitled files. Just add your code to a scratch file, and Fleet will detect the language you are coding in. Untitled files won’t be saved automatically.\n\n\n\n\n\nWe’ve added highlighting to the gray-text code completion. This feature can be enabled or disabled by going to Settings | Code and clicking the Enable AI code completion and Enable syntax highlighting in AI code completion checkboxes.\n\n\n\n\n\nFleet 1.39 offers faster, more accurate code completion suggestions for Kotlin, Python, and Java.\nYou can now pipe standard output (stdout) into Fleet by using the | fleet - syntax, for example: \ndir | fleet - \n./test_script.sh | fleet - \nGet-Process | Select-Object -First 5 | fleet -  \nFleet will then open a new scratch file with an automatically generated file name.\nA highly requested feature in Fleet 1.39 enhances its usability as a quick and effective ad hoc editor. In the terminal, you can now use Fleet by calling fleet --wait, which keeps the command line active until the edited file is closed. It also returns a non-zero exit code if file opening or editing fails. This feature brings Fleet one step closer to supporting the EDITOR environment variable in the terminal, expanding its versatility and functionality in various workflows, including as a Git commit editor.\n\n\n\n\n\n\nWe’ve added two ways of specifying a file with environment variables. Each config in run.json can now specify the environmentFile. Furthermore, on each settings level, it’s possible to specify the run.environmentFile. If such a file is given, the variables are loaded from it and passed to the run config(s).\nBeginning with version 1.38.89, Fleet supports custom theme plugins. Now you can control the appearance of built-in UI elements and publish your own theme plugins to JetBrains Marketplace. The customization options include the ability to change the colors of UI controls and provide custom editor schemes. Learn more about how to create your own themes in this tutorial.\nImprovements\nWith Fleet 1.39, config files and themes are no longer stored in the home directory.\nThe plugin documentation has received a major update, including a detailed tutorial about building a theme plugin in Fleet.\nYou can now open files directly in other applications. Just right-click on the file and click on Open In.\n\n\n\nBug fixes\nWe’ve also fixed several bugs:\nImages are now shown in their original size in the editor [FL-11201].\nClicking Configure Docker now navigates you to the Docker section in the settings when a workspace settings tab is open [FL-19807].\nThe value of the counter in the Search tab no longer changes after you click on a file [FL-25443].\nSee the full release notes for more details about Fleet 1.39\nPlease report any problems you encounter to our issue tracker, and stay tuned for further exciting announcements.\nSupport for plugins and plugin APIs is a work in progress, but the list of bundled plugins is now available and visible to everyone. To view it, select Plugins from the Actions menu. \nJoin the JetBrains Tech Insights Lab to participate in surveys, interviews, and UX studies, and help us make JetBrains Fleet better!",
        "dc:creator": "Daniela Bentrup",
        "content": "Fleet 1.39 is now available! Explore our latest release, which introduces many new features designed to improve your development experience. You can update to this version using the Toolbox App. Let’s take a closer look at the highlights. Download Fleet 1.39 New features Improvements Bug fixes We&#8217;ve also fixed several bugs: See the full release [&#8230;]",
        "contentSnippet": "Fleet 1.39 is now available! Explore our latest release, which introduces many new features designed to improve your development experience. You can update to this version using the Toolbox App. Let’s take a closer look at the highlights. Download Fleet 1.39 New features Improvements Bug fixes We’ve also fixed several bugs: See the full release […]",
        "guid": "https://blog.jetbrains.com/?post_type=fleet&p=503559",
        "categories": [
          "news",
          "releases"
        ],
        "isoDate": "2024-08-20T14:59:18.000Z"
      },
      {
        "creator": "Alena Guzharina",
        "title": "New Datalore Cloud Plans – What You Need to Know",
        "link": "https://blog.jetbrains.com/datalore/2024/08/20/new-datalore-cloud-plans-what-you-need-to-know/",
        "pubDate": "Tue, 20 Aug 2024 13:10:45 +0000",
        "content:encodedSnippet": "As Datalore has evolved over the years, we’ve added more and more pricing tiers to cater to different users in the cloud. The variety of tiers sometimes made choosing a plan complicated. Now, we’ve decided to revamp our subscription plans to simplify the process of finding the option that best fits your needs. You no longer have to worry about juggling between Team, Professional, and Community plans; we now present a unified and powerful solution for all cloud users: Datalore Cloud.\nRead on to learn more, and check out the new pricing plan comparison table below. \n      \n      Explore the new plans\n    \n\n\n\n\nDatalore Cloud: One plan for all\nWhether you’re an individual data scientist, a small startup, or a large corporation, Datalore Cloud is designed to cater to your needs. This comprehensive plan includes robust team management functionalities, ensuring seamless collaboration and efficiency. If you need a limited set of features, you can still enjoy Datalore on the Cloud Free tier. \n\n\n\n\nNew features for Datalore Cloud users\nIn line with many requests from our customers, Datalore Cloud offers a powerful CPU L machine, featuring 4 virtual CPUs (vCPUs) and 16 GB RAM. This machine is optimized to handle most of your daily tasks with ease and is included in your subscription.\nMoreover, we’ve updated our computation options to include the latest and most powerful machines. You can explore detailed specifications and pricing in our documentation.\nTransition details for existing users\nFor Team plan users:\nYour team will now enjoy the upgraded CPU L machines, and you’ll receive six Datalore credits per month for each member.\nThe transition to the Cloud plan has happened automatically, so no action is needed from your side. Rest assured, the price remains the same!\n\n\n\n\nFor Professional plan users:\nYou can continue with your existing plan under the same terms and conditions.\nHowever, you have the option to upgrade to the new Cloud plan, which includes the powerful CPU L machines and team-management features.\n\n\n\n\nPlease note that the Professional plan has been archived and is no longer available for new users.\nFor Community plan users:\nUpon your next login, your Community plan will be upgraded to a 14-day Cloud trial at no additional cost.\nAfter the trial, if you choose not to subscribe to the Cloud plan, you will transition to Cloud Free, our new free plan offering similar functionality to the old Community plan.\n\n\n\n\nFor Enterprise plan users:\nDatalore Enterprise has been renamed to Datalore On-Premises. Other changes outlined above do not affect you.\n\n\n\n\nIf you have any questions or require assistance, please don’t hesitate to contact Datalore Support.\nBest regards,\nThe Datalore team",
        "dc:creator": "Alena Guzharina",
        "content": "As Datalore has evolved over the years, we’ve added more and more pricing tiers to cater to different users in the cloud. The variety of tiers sometimes made choosing a plan complicated. Now, we&#8217;ve decided to revamp our subscription plans to simplify the process of finding the option that best fits your needs. You no [&#8230;]",
        "contentSnippet": "As Datalore has evolved over the years, we’ve added more and more pricing tiers to cater to different users in the cloud. The variety of tiers sometimes made choosing a plan complicated. Now, we’ve decided to revamp our subscription plans to simplify the process of finding the option that best fits your needs. You no […]",
        "guid": "https://blog.jetbrains.com/?post_type=datalore&p=504334",
        "categories": [
          "news"
        ],
        "isoDate": "2024-08-20T13:10:45.000Z"
      },
      {
        "creator": "Olga Bedrina",
        "title": "What We Learned From the Perforce 2024 State of Game Technology Report",
        "link": "https://blog.jetbrains.com/teamcity/2024/08/perforce-2024-game-tech-report/",
        "pubDate": "Tue, 20 Aug 2024 11:44:43 +0000",
        "content:encodedSnippet": "The gaming industry has long been a hotbed of innovation, with developers consistently pushing the boundaries of what’s possible. But as we progress into 2024, it’s clear that game technology’s sphere of influence is expanding far beyond the realm of gaming. \nTechnological advancements coming out of the game industry are quickly adopted by various other industries, from automotive to healthcare to education, as identified by Perforce’s 2024 State of Game Technology.\nIn this blog post, we’ll take a closer look at the report’s key findings and the trends that are shaping the future of game technology. We’ll also highlight some of the findings we found the most interesting. \nYou can download the full report via the link below to get more information on the challenges the game industry is facing, the latest AI trends, the current state of the job market, and predictions for the future of the industry.\nDownload your report copy here\nKey findings and trends\nWidespread adoption across industries sphere\nThe most striking trend in this year’s report is the widespread adoption of game technology across multiple sectors. Traditionally confined to gaming, tools like game engines are now being embraced by industries including media, automotive, and healthcare. \nThe report reveals that 50% of respondents are now using game engines outside of gaming, marking a significant shift in how these tools are perceived and utilized.\nThe main reason behind this trend is the growing complexity of projects. Projects are becoming more complex as the demand for high-quality, immersive experiences grows.\nEconomic uncertainty has added to this challenge, forcing teams to handle changing consumer demands, higher costs, and the pressure to deliver realistic visuals. The report highlights just how difficult it is to manage such large projects, especially with limited resources and teams distributed across different locations.\nCollaboration challenges\nDespite promising technological advancements in technology, collaboration remains a significant hurdle. The report identifies moving large files as the main barrier to effective teamwork, a challenge exacerbated by the growing size of digital assets.\nSource: Perforce 2024 State of Game Technology Report\n\n\n\nWhile issues surrounding remote work have become more manageable, other collaboration issues, such as inefficient communication and feedback loops, continue to impede progress.\nUnsurprisingly, smaller studios and AAA studios face different challenges. Large and AAA studios primarily struggle with collaboration issues and finding time dedicated to innovation. On the other hand, small studios find funding to be their biggest hurdle, far outweighing other concerns.\nSource: Perforce 2024 State of Game Technology Report\nConsolidation of toolsets\nEfficiency is becoming more critical as organizations look to streamline their processes. Instead of adopting a wide array of tools, teams are focusing on consolidating their technology stacks. Game engines are particularly valued for their versatility, with applications ranging from digital twins in manufacturing to immersive educational tools.\nCross-industry trends in game development\nThe cross-industry trends regarding game technology, as highlighted in the report, include several key insights.\nAdoption of game engines \nUnreal Engine is by far the most utilized game engine industry-wide, with 63% of respondents using it. The engine is especially favored in media and entertainment due to its robust tools for creating 3D worlds and its flexibility in various production roles​.\nJust as AAA and indie studios face different challenges, they also prefer using different game engines. Thus, AAA developers often use proprietary game engines but predominantly rely on Unreal Engine, which is nearly twice as popular as Unity. \nIn contrast, indie studios use Unreal Engine and Unity at more similar rates, with Godot gaining popularity as an alternative.\nSource: Perforce 2024 State of Game Technology Report\nUsage of Perforce Helix Core\nThe report revealed that a significant majority of respondents (54%) incorporate Git-based version control tools like GitHub, GitLab, BitBucket, or Azure DevOps into their workflows. Similarly, over half of the respondents reported using Perforce Helix Core as part of their version control processes.\nOther tools used widely in the industry\nIn addition to game engines and version control systems, game developers continue to rely on other technologies and tools to help them create top-notch experiences for their users.\nIDEs\nAs revealed by the report, the majority of respondents use Microsoft Visual Studio within their development process. However, more than a third of respondents (34% among AAA studios and 46% among indie studios) also reported using JetBrains Rider as their IDE of choice. This could be attributed to Rider’s seamless integration with game engines (Unreal Engine, Unity, and Godot).\nCI/CD tools\nThe report revealed a great variety of CI/CD tools used by AAA studios and indie studios alike. Among AAA studios, Jenkins (41%) and TeamCity (23%) stand out as the most widely used CI/CD tools.\nSource: Perforce 2024 State of Game Technology Report\nTeamCity is a powerful CI/CD tool that seamlessly integrates with Unreal Engine, Unity, and Perforce and is widely used by AAA and indie game studios. If you’d like to learn more about TeamCity, feel free to schedule a call with our solutions engineer.\nConclusion\nThe 2024 State of Game Technology Report paints a vivid picture of an industry at a crossroads. As game technology continues to break into new sectors, the challenges of complexity, collaboration, and innovation must be addressed to fully realize its potential. \nThe key for organizations across all industries will be to harness the right tools and strategies to stay competitive in an increasingly dynamic landscape.",
        "dc:creator": "Olga Bedrina",
        "content": "The gaming industry has long been a hotbed of innovation, with developers consistently pushing the boundaries of what’s possible. But as we progress into 2024, it’s clear that game technology’s sphere of influence is expanding far beyond the realm of gaming.&#160; Technological advancements coming out of the game industry are quickly adopted by various other [&#8230;]",
        "contentSnippet": "The gaming industry has long been a hotbed of innovation, with developers consistently pushing the boundaries of what’s possible. But as we progress into 2024, it’s clear that game technology’s sphere of influence is expanding far beyond the realm of gaming.  Technological advancements coming out of the game industry are quickly adopted by various other […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=504369",
        "categories": [
          "news"
        ],
        "isoDate": "2024-08-20T11:44:43.000Z"
      },
      {
        "creator": "Yaroslav Golubev",
        "title": "Long Code Arena: How Well Can AI Models Understand Your Entire Project?",
        "link": "https://blog.jetbrains.com/ai/2024/08/long-code-arena-how-well-can-ai-models-understand-your-entire-project/",
        "pubDate": "Mon, 19 Aug 2024 11:45:50 +0000",
        "content:encodedSnippet": "In the last couple of years, AI has found its way into virtually all aspects of software development. We know that AI models are getting smarter, and we can clearly see how they have become better at seemingly everything, but why is this happening? One factor that is changing is context size, which is how much information models are able to receive as input. Basically, as the models become capable of processing larger amounts of data, they can provide better outputs.\nIn software engineering specifically, the most recent models have context sizes that allow them to take entire projects – tens or even hundreds of files! – as input, and this impacts a variety of software development tasks. However, with the rapid advancements in the field, the benchmarks are lagging behind. Most researchers still evaluate the newest code models at the scale of files or often even just individual functions. \nBut no more!\nRecently, JetBrains Research introduced Long Code Arena – a set of six benchmarks that require the models to take an entire project as input. All the tasks in the suite contain high-quality reference solutions, manually collected and verified. In this blog post, we will share with you what these benchmarks are and how they will help researchers all over the world to train the next generation of smart AI models for code. If you’d like to learn about Long Code Arena in more detail, check out this preprint of the formal paper, which has received a lot of positive feedback.\nLibrary-based code generation\nCode generation is one of the most common uses of AI for coding. However, one aspect of this use case that can be difficult to control is the exact kind of code the model will generate for you. If you just ask it to complete a task, it might introduce new dependencies that will make your project harder to maintain or it may awkwardly use built-in solutions when more convenient libraries exist. \nOur first benchmark tests a smarter way to approach this scenario. As usual, the model receives a task that it must complete, but it also receives the contents of a given library, and it must complete the task while making heavy use of the library’s APIs. This tests the model’s ability to process a full library – both code and documentation – and provide results that rely on what you want. We found that GPT-4 performs the best, but even it only uses 37% of the APIs found in the reference solutions, leaving huge room for further improvement.\nCI builds repair\nNext up, we test the models on their ability to fix a failing CI build. We give the model an entire repository at the moment of failure and the logs of the failed run, and the model has to generate a patch. For this task, we developed an interactive evaluation system! The patch that the model generates gets applied, and then the fixed version of the build is run live in GitHub Actions. This represents an evaluation pipeline that’s as close to real-world conditions as possible.\n\n\n\n\nThe results show that even the best model – GPT-3.5 in this case – can only fix 17% of failing builds, indicating just how much work yet needs to be done for AI to be practically useful in this context.\nProject-level code completion\nTogether with code generation, code completion is among the most popular uses of AI for coding, and so of course we want to evaluate it. The model receives the full project and the contents of the file, and it then has to generate the next line in this file. The model needs to use the entire project because some of the lines that need to be completed contain functions or classes from other files in the repository. To test this exhaustively, our benchmark includes a detailed categorization of lines by the different functions and classes that they contain, and thus in a way, by difficulty.\nUnsurprisingly, our results show that it is harder for the models to correctly generate a line that contains functions from other parts of the project. However, we tested a way to compose context using files that are closest in the file tree to the completion file, and this resulted in a noticeable improvement. \nCommit message generation\nThe generation of commit messages is an established task in software engineering research, and it is highly useful in practice. Models take in the code diff and outputs a description of it in natural language. While this does not require the full project, existing benchmarks still only evaluate the models on highly filtered, pristine diffs and commit messages, whereas reality can be much more complicated. To test a more complex case, we collected a dataset of large commits, ones with hundreds of lines of code and thousands of symbols. \nAgain, unsurprisingly, the models perform worse on such data than on smaller, more atomic commits. If we want our future models to be able to handle even larger amounts of data, our dataset will come in handy. For instance, we released sources of all repositories appearing in our dataset, allowing future researchers to explore whether the context of the entire project might be beneficial for this task as well.\nBug localization\nBug localization tests the ability of models to understand a repository, with all its nuances and complexities. Given the full repository and an issue that contains a bug description, the model must point out which files need to be fixed to solve the issue. Here, too, GPT-4 performed better than the other models.\nModule summarization\nFinally, the last task evaluates the ability of the model to understand the full project even more explicitly. Summarization is another key way AI models work with code. However, it also is usually tested by writing comments or docstrings for individual functions, while modern models can do so much more. In our benchmark, we give the model a full module or repository and a short instruction about what type of documentation is needed, for example, a README. The model then has to process and summarize it all.\nThis task also features a novel metric. While there are a lot of metrics for comparing texts, they were developed for short strings and might not work on entire pages of documents. For that reason, we employ AI models to evaluate other AI models: We give an LLM the relevant code and two versions of documentation – the reference and the generated one – and ask it to identify which version better matches the input code. We do this several times with the order randomized to account for potential biases.\n\n\n\n\nTesting different models on different context sizes, we can see that GPT-4 beats other models here as well, demonstrating a 45–57% probability of being better than the reference.\nLooking forward\nLong Code Arena represents an important step towards better code models, and it is the first dataset with large contexts in the field. We hope that it will be useful for the research community. We already plan to use it to improve the models in JetBrains tools, and with it we will continue to move the field forward!",
        "dc:creator": "Yaroslav Golubev",
        "content": "In the last couple of years, AI has found its way into virtually all aspects of software development. We know that AI models are getting smarter, and we can clearly see how they have become better at seemingly everything, but why is this happening? One factor that is changing is context size, which is how [&#8230;]",
        "contentSnippet": "In the last couple of years, AI has found its way into virtually all aspects of software development. We know that AI models are getting smarter, and we can clearly see how they have become better at seemingly everything, but why is this happening? One factor that is changing is context size, which is how […]",
        "guid": "https://blog.jetbrains.com/?post_type=ai&p=503829",
        "categories": [
          "jetbrains-ai"
        ],
        "isoDate": "2024-08-19T11:45:50.000Z"
      },
      {
        "creator": "Stanislav Garkusha",
        "title": "Introducing the PyCharm Databricks Integration",
        "link": "https://blog.jetbrains.com/pycharm/2024/08/introducing-the-pycharm-databricks-integration/",
        "pubDate": "Mon, 19 Aug 2024 08:47:34 +0000",
        "content:encodedSnippet": "We’re introducing the Databricks integration with PyCharm Professional to make it easier for you to process, store, and analyze your data! \nThe integration allows you to build your data and AI apps on the Databricks Data Intelligence Platform directly within PyCharm Professional, enhancing the data analytics platform with the powerful Python IDE by JetBrains. It enables you to write code quickly and easily and run it in the cloud without extra configurations, and it offers additional benefits for working with data. \nRead this blog post to learn more about the integration, who it will be useful for, and what benefits it offers.\n\n\n\n    \nInstall the Databricks plugin\n                                                    \nWatch the plugin in action\n\n\n\n\n\n\nWhat is Databricks?\nThe Databricks Data Intelligence Platform allows your entire organization to use data and AI. It’s built on a lakehouse to provide an open, unified foundation for all data and governance, and is powered by a Data Intelligence Engine that understands the uniqueness of your data.\nWhat is PyCharm Professional?\nPyCharm Professional is a leading IDE for Python and other programming languages. It allows you to write high-quality and efficient code using superior code completion, refactoring capabilities, code inspections, seamless code and project navigation, a debugger, and a wide range of integrations, including Jupyter notebooks, testing frameworks, Git, CI/CD solutions, and more – all available in one place right out of the box.\nWho will the integration be useful for? \nOrganizations and data professionals using data lakehouses, data lakes, and data warehouses via Databricks will benefit from this integration.\nWhat benefits does the integration bring?\nThe integration combines the most powerful capabilities of each platform, allowing you to easily build all of your data and AI applications at scale within PyCharm: \nUse PyCharm to implement software development best practices, which are essential for large codebases, such as source code control, modular code layouts, testing, and more. \nDatabricks enables the use of powerful clusters, allowing you to work on projects too large for a local machine and helping you orchestrate data processing efficiently. \nYou can write the code for your pipelines and jobs in PyCharm, then deploy, test, and run it in real time on your Databricks cluster without any additional configurations. \nLet’s dive into more details about what the PyCharm Databricks integration provides.\nConnect to your cluster via PyCharm\nYou can connect directly to the Databricks cluster via PyCharm and monitor the process within the IDE. This allows you to check if the cluster is running, see the results of the current session’s runs, and view process outcomes along with additional details.\n\n\n\n\nRun Python scripts on a remote cluster\nIn addition, you can run Python scripts on a remote cluster, which is particularly useful for working with big data, and view the results in the IDE.\n\n\n\n\nRun Jupyter notebooks or Python scripts as workflows\nAdditionally, you can run your notebook or Python scripts as a Databricks workflow and see the output in the console. \n\n\n\n\nYou can see the results of the runs on the Databricks platform, including the runs initiated from PyCharm.\n\n\n\n\nSynchronize project files to the Databricks workspace\nThe synchronization of project files with the Databricks workspace allows you to access and work with the same files in both PyCharm and Databricks workspaces. You can also schedule your notebooks and scripts and utilize other platform features for projects completed in PyCharm. \n\n\n\n\nHow to get started\nMake sure you have the following ready to go:\nPyCharm Professional 2024.2 and further editions\nBig Data Tools Core plugin \nDatabricks account\nYou can install the Databricks plugin either from JetBrains Marketplace or directly from within the PyCharm IDE.\nInstall the Databricks plugin\n                                                    \nHead over to the documentation to get step-by-step instructions on how to get started and use the plugin.\nWhat do you think about this integration? Share your thoughts in the comments below.",
        "dc:creator": "Stanislav Garkusha",
        "content": "We&#8217;re introducing the Databricks integration with PyCharm Professional to make it easier for you to process, store, and analyze your data!&#160; The integration allows you to build your data and AI apps on the Databricks Data Intelligence Platform directly within PyCharm Professional, enhancing the data analytics platform with the powerful Python IDE by JetBrains. It [&#8230;]",
        "contentSnippet": "We’re introducing the Databricks integration with PyCharm Professional to make it easier for you to process, store, and analyze your data!  The integration allows you to build your data and AI apps on the Databricks Data Intelligence Platform directly within PyCharm Professional, enhancing the data analytics platform with the powerful Python IDE by JetBrains. It […]",
        "guid": "https://blog.jetbrains.com/?post_type=pycharm&p=501836",
        "categories": [
          "news",
          "databricks"
        ],
        "isoDate": "2024-08-19T08:47:34.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": [
      {
        "creator": "Sam Kim",
        "title": "Personal Data Classification",
        "link": "https://medium.com/airbnb-engineering/personal-data-classification-2d816d8ea516?source=rss----53c7c27702d5---4",
        "pubDate": "Mon, 19 Aug 2024 16:43:29 GMT",
        "content:encodedSnippet": "An Important Foundation For Security, Privacy, and Compliance at Airbnb\n\nBy: Sam Kim, Alex Klimov, Woody Zhou, Sylvia Tomiyama, Aniket Arondekar, Ansuman Acharya\nIntroduction\nAirbnb is built on trust. One key way we maintain trust with our community is by ensuring that personal data is handled with care, in a manner that meets security, privacy, and compliance requirements. Understanding where and what personal data exists is foundational to this.\nOver the past several years, we’ve built our own data classification system that adapts to the needs of our data ecosystem, to streamline our processes, and further unlock our ability to protect the data entrusted to Airbnb. This was made possible by many teams working closely to achieve this overarching, shared objective. Information Security, Privacy, Data Governance, Legal, and Engineering collaborated to tackle this problem holistically to produce a unified data identification and classification strategy across all data stores.\nIn this blog, we will shed light on the complexities of how data classification works at Airbnb, what measurements we set to assess the quality, performance, and accuracy of the systems involved, and the important considerations when building a data classification system. We hope to share insights for others that are facing similar challenges and to provide a framework for how data classification systems can be built at scale.\nThe Complexities of Data Classification at Airbnb\nData classification is the process of identifying where data exists and then organizing, detecting, and annotating that data based on a taxonomy. At Airbnb, we have established a Personal Data Taxonomy Council to define the taxonomy for personal data and to refine it over time. This taxonomy breaks down personal data into various data elements that are relevant for our ecosystem such as email address, physical address, and guest names. Once data is annotated with its applicable personal data element(s), various enforcement systems use these annotations to ensure personal data is handled according to our Security and Privacy policies. In this blog post, we will focus primarily on the data classification workflow and not each type of enforcement use case.\nThe workflow can be classified into three pillars:\n\nCatalog: What data do we have?\nDetection: What data do we suspect is personal data?\nReconciliation: Which classification do we choose?\nPersonal Data Classification Flow\nLet’s dig deeper into how each of these form the backbone of data classification.\nCatalog\nCataloging involves building a dynamic, accurate, and scalable system to first identify where data exists and then organize the whole inventory. Cataloging is akin to mapping the data landscape or organizing a library. It involves dynamically discovering new data, enriching it with metadata from various sources, and manually inputting information. This process is crucial for enforcing data policies, accurately classifying data, and assigning it to the correct owners.\n\nAutomated and Dynamic Discovery: Automation makes the cataloging process scalable and efficient. For the variety of data stores that Airbnb uses, such as production and analytical databases, object stores, and cloud storage, our catalogs connect to them and dynamically fetch the full inventory of data. Either through stream or batch processing, they dynamically update to reflect new and changed data. This ensures the catalog is a reliable and accurate source of truth.\nComplexity and Diversity in Data Sources: The challenge of cataloging stems from the variety and complexity of data sources, including different formats and locations. Our cataloging systems fetch metadata in several ways: through direct API calls or by crawling schemas in formats like thrift, JSON, yaml, or config files, accommodating the diverse nature of modern data storage.\n\nFor search and discovery, many of our data entities are surfaced in the data management platform, Metis. This helps the data owners quickly answer questions such as which data contains personal data, who owns the data, and which controls are in place.\nCatalog UI\nDetection\nFor personal data detection, we use the in-house automated detection service in our Data Protection Platform which was built to protect data in compliance with global regulations and security requirements. As our own taxonomy grows, we have expanded our capabilities and made the service easily extensible to detect all other types of personal data elements and personal Airbnb IDs.\nDetection engine\nFor each data entity stored in the catalogs, scanning jobs are scheduled through a message queue, which then samples data and runs through our list of classifiers. Recognizing the need for periodic classifier updates, the detection engine was designed for simplicity and flexibility. Since its inception, our detection engine has upgraded to include additional steps and adopted the approach of configuration-driven development. The majority of the logic of the detection engine has been rewritten as simpler configurations to increase the speed of iterating on existing classifiers, improve testing, and enable quick development of new features.\nThe detection engine can be seen as a pipeline, which involves the scanner, validator, and thresholding.\nDetection Engine\nScanner: The scanner classifies personal data using metadata and content, employing methods like regex for emails and keyword lists for cities, and advanced machine learning models for complex data types requiring contextual understanding.\nValidator: Sampled data matching a scanner undergoes a customizable validation step to enhance classifier accuracy, verifying details like latitude/longitude ranges or custom ciphertexts from encryption services.\nThresholding: To reduce noise, thresholding is applied before storing results, varying by data structure type (e.g., matched rows vs. findings in a document) and set based on historical data frequency and criticality.\nWith the revamped pipeline, this has resulted in a significant decrease in false positive findings and reduced the burden on data owners to verify every result, which has historically impeded their productivity.\nReconciliation\nNot every detection surfaced may be correct or, in other cases, more context may be required. Therefore, we employ a human-in-the-loop strategy: where data owners confirm the classifications. This step is critical in ensuring these classifications are correct before any data policies are automatically enforced to protect our data.\nAutomated Notifications\nFor compliance, we have an automated notification system that issues tickets whenever personal data is detected. These get surfaced to the appropriate data or service owners with strict SLAs.\nFor data entities that have schemas defined in code, such as transactional tables from production services (online), Amazon S3 buckets, or tables that are exported to our data warehouse, we assist the developers by automatically creating code changes that update their table schemas with the detected personal data elements.\nEnforcing resolution\nTo enforce resolution on these tickets, tables are automatically access controlled in the data warehouse when the tickets are not resolved within SLA. Additionally reviews are conducted to ensure our classifications are correct for data where its handling requirements apply.\nTracking actions taken on these tickets for when personal data is detected has been important to assess the quality of our data classification flow and to keep an audit trail of past detections. It also highlights points of friction developers face when resolving these tickets. The investments we have made in this area have continued to improve the process and reduce the time needed to resolve tickets each year.\nAssessing Quality of a Data Classification System\nBecause of the complexity of the system and its sub-components, this presented a unique challenge as we strive to define what quality means for the entire system. To build with the long-term in mind, we evaluated how well our entire data classification system functions as a whole.\nWe’ve set up measurements to assess quality of our data classification in three categories:\nRecall: This measures our coverage and ability to not miss where personal data may exist, crucial for protecting the stored personal data. We assess recall through:\n\nNumber of data entities integrated in the data classification system\nVolume of personal data that exists from all different sources\nTypes of personal data being annotated and automatically detected against our taxonomy\n\nPrecision: This evaluates the accuracy of our data classifications, vital for data owners tagging their data. High precision minimizes tagging friction. Precision is measured by:\n\nTracking false positive rates of classifiers for each type of personal data\nTracking ticket resolutions made by data owners, which also aids in understanding nuanced classification cases\n\nSpeed: This gauges the efficiency of identifying and classifying personal data, aiming to minimize compliance risks. Speed is measured by:\n\nTime it takes for the detection engine for scanning new data entities\nTime it takes for data owners to reconcile classifications and resolve tickets\nThe frequency of data tagging at creation by data owners\n\nThese measurements ensure our data classification system is effective, accurate, and efficient, safeguarding our personal data.\nConsiderations for Building a Data Classification System\nIt is important to be aware of issues that may be present with the outlined approach in general. Below are some challenges that we’ve considered when building a data classification system:\n\nPost-Processing Classification: The outlined approach mostly relies on post-processing classification, which means that schema information is added after data has been collected and stored. In a modern data world where data and metadata are constantly changing, post-processing cannot catch up with data evolution.\nInconsistent Classifications: Data generally flows from online to offline through ETL (extract, transform, and load) processes, and then reverse ETLing back to the online world. However, data classification that is performed independently in both worlds can lead to inconsistent classifications.\nWaste of Process Cost: Duplicate annotations can be made for the same data in the online and offline domains, which might result in increased costs for data classification processes.\n\nTo address these challenges, we describe the process of “shifting left” with data classification and how we started to push developers to annotate their data at the beginning of the data lifecycle.\nShifting Left\nInstead of thinking about governance and data classification as an activity that happens post-hoc, we’ve started to embed the annotation process directly into data schemas as they are being created and updated. This enables us to:\n\nShift Classification from Data to Schema: The schema annotation process takes place earlier in the data lifecycle at the point of data collection. This keeps annotations updated as data evolves and ensures data is annotated before collection and consumption, allowing for immediate policy enforcement.\nShift Classification from Offline to Online: Traditionally done offline, data classification is now integrated into production services, ensuring data is structured and formatted correctly from the start. Leveraging data lineage information enables automated annotation, reducing the need for manual effort and lowering process costs.\nShift from Data Steward to Data Owner: Oftentimes, stewardship, or the responsible management and oversight, of the data is conducted by people who are downstream of data creation, such as data consumers or governance professionals. This change shifts stewardship to the data producers, merging the roles of data steward and data owner. This empowers the team that owns the data to manage it more effectively and scale operations.\n\nSchema Annotation Enforcement\nFocusing on our most crucial online data, we have started executing on shifting left by directly integrating with our internal schema definition language that is known for its annotation capabilities. We now mandate that developers include personal data annotations at the source when creating new data models, providing guidance on accurate tagging. This requirement is enforced through checks that run in our CI/CD pipelines which:\n\nAutomatically suggest data elements: Based on the schema’s metadata, we automatically detect the data elements for all fields defined in the schema with our detection service.\nValidate data elements: Annotations are validated against our own taxonomy and schemas are enforced and all fields are annotated, even when it is not considered personal.\nWarn about downstream impact: We notify data owners when annotations can impact downstream services such as offline data pipelines and direct them to the proper resources for handling.\nSchema Annotation Enforcement\nWhile shifting left has significantly helped to push classifying data earlier and increase coverage of schema annotations, this does not discount the importance of the rest of the classification process. Classifications that happen post-process are necessary for instance in cases where data storages that do not include well-defined schemas. Therefore, continued investments are still needed in detection and reconciliation to cover areas that cannot be shifted left and to verify annotations that may have already been made by owners as a second layer of protection.\nConclusion/Lessons Learned\nThe Airbnb data classification framework has been successful in advancing data management, security, and privacy. Reflecting on the journey, it has offered invaluable insights that have shaped our methodologies. Key takeaways include:\n\nAdopting a unified strategy for classifying online and offline personal data to streamline processes\nImplementing a ‘Shift Left’ approach to engage with data owners early in the development cycle\nAddressing classification uncertainties through clear guidelines and decision-making\nEnhancing education and training initiatives for data owners and consumers\n\nAs the data landscape continues to rapidly change, these lessons will guide future data classification efforts and ensure continued trust and protection of customer data.\nAcknowledgements\nOur data classification strategy has evolved over many years and we’ve been able to quickly adapt and iterate thanks to our decision to build an in-house solution. Security, privacy, and compliance are of utmost importance at Airbnb, and this work would not be possible without the contribution of many of our cross-functional partners and leaders.\nThis includes, but are not limited to: Bill Meng, Aravind Selvan, Juan Tamayo, Xiao Chen, Pinyao Guo, Wendy Jin, Liam McInerney, Pat Moynahan, Gabriel Gejman, Marc Blanchou, Brendon Lynch, and many others.\nIf this type of work interests you, check out some of our related positions at Careers at Airbnb or check out more resources in the Airbnb Tech Blog!\nAll product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.\n\nPersonal Data Classification was originally published in The Airbnb Tech Blog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Sam Kim",
        "guid": "https://medium.com/p/2d816d8ea516",
        "categories": [
          "privacy",
          "data",
          "engineering",
          "security",
          "technology"
        ],
        "isoDate": "2024-08-19T16:43:29.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "article New updates to Planner comment notifications and settings in Planner Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Rhea Patel",
        "title": "Enhancing Code Comprehension: GitHub Copilot’s Features in Visual Studio 2022 17.11",
        "link": "https://devblogs.microsoft.com/visualstudio/enhancing-code-comprehension-github-copilots-features-in-visual-studio-2022-17-11/",
        "pubDate": "Thu, 22 Aug 2024 10:00:28 +0000",
        "content:encodedSnippet": "GitHub Copilot in Visual Studio 2022 17.11 now offers an improved experience you to refer to their methods, classes, functions, and entire solution directly within the chat. By using the # symbol followed by the name of a method, class, or function, or by referring to your solution with @workspace, you can provide specific context that helps GitHub Copilot better understand their code and the problem at hand.\nRefer to your solution\nGitHub Copilot Chat now allows you to refer to your entire solution. This feature helps provide an even deeper understanding of your solution to get the best results. To refer to your solution, simply use the @workspace and Copilot will answer high level questions about your solution, files and how they work together.\n\nTry asking GitHub Copilot Chat questions like:\n@workspace What project can I run in my solution?\n@workspace In my workspace, where is #methodname referenced?\n@workspace Where does serialization occur in my solution?\n \nReference your methods, classes, functions\nGitHub Copilot Chat now allows you to refer to your methods, classes, and functions inline. By referring to methods, classes, and functions directly within the chat, you can provide specific context that helps GitHub Copilot better comprehend your code and the problem at hand. This feature empowers you to provide richer context to GitHub Copilot, enabling it to deliver more precise responses by gaining a deeper understanding of your codebase.\n\nTry asking GitHub Copilot Chat questions like:\nI have a test method named #methodName. How can I ensure that it’s being executed correctly?\nWhat are some optimizations that could be applied to #methodName?\nHow does #methodName1 use #methodName2 and what issues should I look out for?\n/explain #methodName\n \nSearch the web in Copilot Chat\nGitHub Copilot now includes context from your entire repository & can search the web.\nGitHub Copilot Enterprise subscribers in Visual Studio can now use GitHub Copilot Chat to get answers enriched with context from their entire repository and Bing search results.\n\nGet answers from across your entire codebase\nGitHub Copilot Chat can now answer questions with understanding of your full repository, not just the tabs you have open. Index your repository on GitHub.com, and then ask a question mentioning @github. You can ask questions like @github where is rate limiting implemented?\nSearch with the context of the web\nGitHub Copilot chat can also search Bing to find information outside of its general knowledge or your codebase. When you mention @github, GitHub Copilot will intelligently decide when to use Bing. You can ask questions like @github what is the latest LTS version of .NET?\nBing search is only available if enabled by an administrator – for more details, see Enabling GitHub Copilot Enterprise features or read the docs.\nTry it out today!\nWe hope you enjoy this new feature in GitHub Copilot for Visual Studio! Your feedback is important to us, so please share your thoughts using the thumbs up or down in the Chat, or by visiting the Developer Community. We look forward to hearing from you!\n\nHappy coding!\nWe appreciate the time you’ve spent reporting issues/suggestions and hope you continue to give us feedback when using GitHub Copilot in Visual Studio on what you like and what we can improve. Your feedback is critical to help us make GitHub Copilot  the best tool it can be! You can share feedback with us via Developer Community: report any bugs or issues via report a problem and share your suggestions for new features or improvements to existing ones.\nStay connected with the Visual Studio team by following us on YouTube, Twitter, LinkedIn, Twitch and on Microsoft Learn.\n\nThe post Enhancing Code Comprehension: GitHub Copilot’s Features in Visual Studio 2022 17.11 appeared first on Visual Studio Blog.",
        "dc:creator": "Rhea Patel",
        "content": "<p>GitHub Copilot in Visual Studio 2022 17.11 now offers an improved experience you to refer to their methods, classes, functions, and entire solution directly within the chat. By using the # symbol followed by the name of a method, class, or function,</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/enhancing-code-comprehension-github-copilots-features-in-visual-studio-2022-17-11/\">Enhancing Code Comprehension: GitHub Copilot’s Features in Visual Studio 2022 17.11</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "GitHub Copilot in Visual Studio 2022 17.11 now offers an improved experience you to refer to their methods, classes, functions, and entire solution directly within the chat. By using the # symbol followed by the name of a method, class, or function,\nThe post Enhancing Code Comprehension: GitHub Copilot’s Features in Visual Studio 2022 17.11 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=249711",
        "categories": [
          "Copilot",
          "Visual Studio",
          "Context",
          "GitHub Copilot"
        ],
        "isoDate": "2024-08-22T10:00:28.000Z"
      },
      {
        "creator": "Sy Brand",
        "title": "New C++ features in Visual Studio v17.11",
        "link": "https://devblogs.microsoft.com/visualstudio/new-c-features-in-visual-studio-v17-11/",
        "pubDate": "Wed, 21 Aug 2024 10:00:31 +0000",
        "content:encodedSnippet": "Visual Studio 2022 version 17.11 is here and comes with a host of new features for C++ developers. We’ve made improvements across our toolchain, Unreal Engine support, Build Insights, CMake debugger, and more. This post gives a quick overview of what’s available; for all the details, see What’s New for C++ Developers in Visual Studio 2022 17.11 on the C++ blog.\nStandard Library\nThe three main areas of improvement in this release are in formatted output, vectorization, and diagnostics. For formatted output, we’ve implemented parts of Formatting Ranges and all of Printing Blank Lines with println. Our vectorization improvements hit over a dozen of the standard algorithms, and we’ve improved the diagnostics of common misuses of std::ranges::to and std::get(std::tuple). See the STL changelog for all the details.\nCMake Debugger\nWe have added support for the CMake debugger in CMake projects targeting Linux via WSL or SSH. The CMake debugger allows you to debug your CMake scripts and CMakeLists.txt files through the Visual Studio debugger.\nTo start a CMake debugging session, set a breakpoint in your CMakeLists.txt file and then navigate to Project > Configure Cache with CMake Debugging.\n\nUnreal Engine Support\nWe’ve added several new features for Unreal Engine developers:\nAn Unreal Engine toolbar that provides quick access to Unreal Engine actions such as attaching to UE processes and accessing the UE log\nAn Add Class dialog for adding common UE class templates to your project\nAn Add Module dialog for adding UE modules to your project\n\nBuild Insights\nIn this update, we added quality of life changes to C++ Build Insights integration. You can now filter your Build Insights trace results by project. For results in each row, you will now see the relative path and file name instead of the full path. We have also improved the grouping of results in the Included Files view.\n\nBreakpoint Performance\nWe have significantly enhanced the performance of conditional breakpoints in C++ through a reworked implementation.\nBeginning with version 17.11, our initial assessment finds that execution time is almost four times as fast, reducing execution time from 80 seconds to 21 seconds over 80,000 iterations.\nSummary\nWe hope this has given you a taste of what’s new. For all the details, see What’s New for C++ Developers in Visual Studio 2022 17.11 on the C++ blog.\nWe are very much interested in your feedback. The comments below are open. Feedback can also be shared through Visual Studio Developer Community. You can also reach us on Twitter (@VisualC), or via email at visualcpp@microsoft.com.\nThe post New C++ features in Visual Studio v17.11 appeared first on Visual Studio Blog.",
        "dc:creator": "Sy Brand",
        "content": "<p>Visual Studio 2022 version 17.11 is here and comes with a host of new features for C++ developers. We’ve made improvements across our toolchain, Unreal Engine support, Build Insights, CMake debugger, and more. This post gives a quick overview of what’s available;</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/new-c-features-in-visual-studio-v17-11/\">New C++ features in Visual Studio v17.11</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Visual Studio 2022 version 17.11 is here and comes with a host of new features for C++ developers. We’ve made improvements across our toolchain, Unreal Engine support, Build Insights, CMake debugger, and more. This post gives a quick overview of what’s available;\nThe post New C++ features in Visual Studio v17.11 appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=250237",
        "categories": [
          "Cross-Platform",
          "Gaming",
          "Visual Studio",
          "C++",
          "Visual Studio 2022"
        ],
        "isoDate": "2024-08-21T10:00:31.000Z"
      },
      {
        "creator": "Harshada Hole",
        "title": "New debugging and diagnostic features",
        "link": "https://devblogs.microsoft.com/visualstudio/new-debugging-and-diagnostic-features/",
        "pubDate": "Tue, 20 Aug 2024 10:00:11 +0000",
        "content:encodedSnippet": "Debugging and diagnostics are vital skills for any developer, but they can also be difficult and time-consuming to get proficient . That’s why we’ve added some fantastic new features and enhancements to Visual Studio 2022 v17.11 that will help you find and resolve bugs faster and easier than ever before. Here are some of the highlights. Download this update and see the release notes for all the details.\n\nDebugging\nBreak on async method exceptions\nDebugging asynchronous code, especially in frameworks like ASP.NET, can be tricky due to the potential for exceptions to be thrown across asynchronous boundaries.\nNow, with Visual Studio Debugger it automatically breaks when an async Task method throws an exception back to framework code.\nAI-generated breakpoint expressions\nAI-generated expressions for conditional breakpoints and tracepoints are now supported in C++. GitHub Copilot analyzes your code and offers insightful breakpoint expressions, streamlining your debugging process.\nDebug AnyCPU applications manifested to run as arm64\nVisual Studio natively supports building and debugging Arm64 apps on Arm-based processors. Unfortunately, applications built with the AnyCPU setting running on an Arm64 machine will default to using x64 emulation. While the capabilities of the x64 emulator have expanded, the most efficient Arm CPU scenarios are supported when applications are running natively.\nTo better support the intended native behavior the Windows 24H2 update introduces a new <supportedArchitectures> setting for your App manifest files. .NET developers can include a list of supported architectures (amd64 or arm64), explicitly signaling that an application built with the AnyCPU setting should run natively using the Arm64 CLR on Arm64 devices.\nBlazor WebAssembly debugging\nThis release features a preview of the improved debugging experience for Blazor WebAssembly apps targeting .NET 9 or later.\nOrganize your breakpoints with default breakpoint groups\nBreakpoint groups allow you to customize and toggle breakpoints for faster and more effective debugging.\nYou can now mark the selected breakpoint group as the default, ensuring all newly added breakpoints are automatically included in that group.\nEdit and visualize LINQ expressions in the IEnumerable visualizer\nThe Visual Studio debugger now offers an editable expression feature in the IEnumerable visualizer, a powerful enhancement for developers working with collections.\nImproved performance of conditional breakpoints in C++\nWe have significantly enhanced the performance of conditional breakpoints in C++ through a reworked implementation.\nOur initial assessment shows a performance improvement of at least 35% in version 17.10 and 70% in version 17.11, reducing execution time from 80 seconds to 21 seconds over 80,000 iterations.\nProfiling\nKeep your target selection in the instrumentation tool between runs\nThe instrumentation tool now persists the target selection between runs offering a significant benefit by enhancing the continuity of profiling sessions.\nWith this improvement, you can maintain your specified target across multiple instrumentation runs, removing the need for repetitive selection tasks.\nDecompile .NET assemblies\nVisual Studio profiler now offers auto-decompilation for .NET libraries in scenarios where source code is unavailable. By automatically decompiling code during source lookup, even without loaded symbols or exact file locations, you can gain insights into the code’s structure and performance issues.\nWith this new feature, while visualizing a collection or dataset, you can directly edit the expressions textbox on the top of the dialog with your desired LINQ expressions. The visualizer updates in real-time, reflecting the data change resulting from your query.\nWe hope you enjoy this update to Visual Studio, and we look forward to hearing what you think. You can share feedback with us via Developer Community, by reporting issues via report a problem and share your suggestions for new features or improvements to existing ones.\nStay connected with the Visual Studio team by following us on Twitter @VS_Debugger, Twitter @VisualStudio, YouTube, and LinkedIn and on Microsoft Learn.\nThank you for using Visual Studio and happy coding!\nThe post New debugging and diagnostic features appeared first on Visual Studio Blog.",
        "dc:creator": "Harshada Hole",
        "content": "<p>Debugging and diagnostics are vital skills for any developer, but they can also be difficult and time-consuming to get proficient . That&#8217;s why we&#8217;ve added some fantastic new features and enhancements to Visual Studio 2022 v17.11 that will help you find and resolve bugs faster and easier than ever before.</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/new-debugging-and-diagnostic-features/\">New debugging and diagnostic features</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Debugging and diagnostics are vital skills for any developer, but they can also be difficult and time-consuming to get proficient . That’s why we’ve added some fantastic new features and enhancements to Visual Studio 2022 v17.11 that will help you find and resolve bugs faster and easier than ever before.\nThe post New debugging and diagnostic features appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=250236",
        "categories": [
          "Debug",
          "Visual Studio",
          "Debugger",
          "Debugging",
          "Debugging and Diagnostics",
          "Visual Studio 2022"
        ],
        "isoDate": "2024-08-20T10:00:11.000Z"
      },
      {
        "creator": "Jessie Houghton",
        "title": "New git tooling features",
        "link": "https://devblogs.microsoft.com/visualstudio/new-git-tooling-features/",
        "pubDate": "Mon, 19 Aug 2024 10:00:33 +0000",
        "content:encodedSnippet": "Visual Studio 2022 v17.11 includes fantastic updates to everyone working with Git. They bring the richness of both GitHub and Azure DevOps into Visual Studio and part of your natural workflow. This greatly simplifies your inner loop, making you even more productive than before. Download this update and see the release notes for all the details.\n\nMore meaningful code reviews\nWe’ve made it easier to view your GitHub and Azure DevOps pull request comments directly in your working file in Visual Studio. You can now stay in your context, make necessary code changes, and interact with your colleagues’ suggestions without switching contexts to the browser.\nFix for CodeLens timeline\nCodeLens timeline now respects the configuration of your timeline to show the correct information. This fix addresses an issue where the timeline was not honoring the months set in the file changes hover preview.\nUpdates to pull request creation\nWe’ve improved on the create a pull request experience with target branch selection, commit counts, and other stabilization fixes. Additionally, we now automatically create links to work items that have been mentioned in commits that are part of the pull request. We also draft pull requests which was one of the top requests.\nWe hope you enjoy this update to Visual Studio, and we look forward to hearing what you think. You can share feedback with us via Developer Community, by reporting issues via report a problem and share your suggestions for new features or improvements to existing ones.\nStay connected with the Visual Studio team by following us on Twitter @VS_Debugger, Twitter @VisualStudio, YouTube, and LinkedIn and on Microsoft Learn.\nThank you for using Visual Studio and happy coding!\nDownload Visual Studio 17.11\n\nThe post New git tooling features appeared first on Visual Studio Blog.",
        "dc:creator": "Jessie Houghton",
        "content": "<p>Visual Studio 2022 v17.11 includes fantastic updates to everyone working with Git. They bring the richness of both GitHub and Azure DevOps into Visual Studio and part of your natural workflow. This greatly simplifies your inner loop, making you even more productive than before.</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/new-git-tooling-features/\">New git tooling features</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Visual Studio 2022 v17.11 includes fantastic updates to everyone working with Git. They bring the richness of both GitHub and Azure DevOps into Visual Studio and part of your natural workflow. This greatly simplifies your inner loop, making you even more productive than before.\nThe post New git tooling features appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=250212",
        "categories": [
          "Git",
          "Visual Studio",
          "Visual Studio 2022"
        ],
        "isoDate": "2024-08-19T10:00:33.000Z"
      }
    ]
  },
  {
    "name": "Instagram Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Dropbox Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": [
      {
        "creator": "sunyzero",
        "title": "개발자용 고정폭 글꼴(mono font) 추천 - nerd font",
        "link": "http://sunyzero.tistory.com/301",
        "pubDate": "Tue, 20 Aug 2024 22:04:40 +0900",
        "author": "sunyzero",
        "comments": "http://sunyzero.tistory.com/301#entry301comment",
        "content": "<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">개발자라면 필수로 <span style=\"background-color: #f6e199;\">고정폭 글꼴</span>(fixed width font, mono font)을 사용한다. 여기서 mono font란 monospace font를 의미한다. 개발자가 고정폭을 좋아하는 이유는 코드를 볼때 간격이 일정해서 가독성이 좋기 때문이다. 반대로 가변폭 글꼴을 사용하면 탭이나 기호가 들어간 코드를 볼때 매우 불편해진다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">글꼴은 취향의 영역이라서 어느 것이 최고라고 말할 수는 없다. 다만 여기서는 많이 사용되는 <span style=\"background-color: #f3c000;\">Nerd font</span>를 기준으로 하겠다. 너드 폰트는 다운로드를 자동화하는 스크립트도 있지만, 시스템 전역으로 쓸때는 그냥 수동으로 /usr/share/fonts/ 밑에 디렉터리를 만들고 설치하는게 좋다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">0. 글꼴 선택 기준</span></h2>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">본인은 글꼴을 선택할 때 우선적으로 2가지를 살펴본다. </span></p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">첫번째로 숫자 0 (zero)의 안쪽이 빗금인지 점인지를 확인한다. 개인적으로 빗금 스타일을 더 선호한다. 아래 그림을 보면 좌측은 빗금 스타일 0(slashed zero number)을 사용하고, 우측은 점을 찍은 것이다. 어느 스타일을 선호하는지 본인이 여기서 보고 정하면 된다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"font-zero_slash_vs_dot.jpg\" data-origin-width=\"1249\" data-origin-height=\"151\"><span data-url=\"https://blog.kakaocdn.net/dn/chsZDQ/btsJaCHs6Fr/A253tuHn1OhG76Q7K2MKu0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/chsZDQ/btsJaCHs6Fr/A253tuHn1OhG76Q7K2MKu0/img.jpg\" data-alt=\"Mono font - Slashed zero vs Doted zero\"><img src=\"https://blog.kakaocdn.net/dn/chsZDQ/btsJaCHs6Fr/A253tuHn1OhG76Q7K2MKu0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FchsZDQ%2FbtsJaCHs6Fr%2FA253tuHn1OhG76Q7K2MKu0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"font-zero_slash_vs_dot.jpg\" data-origin-width=\"1249\" data-origin-height=\"151\"/></span><figcaption>Mono font - Slashed zero vs Doted zero</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">두번째로는 폭을 본다. 글꼴의 폭이 넓으면 눈이 덜 피로하지만 한 화면에 많이 표시하지 못한다. 대표적으로 폭이 넓은 형태로는 Roboto가 있고, 좁은 형태로는 Iosevka가 있다. 둘을 비교하기 위해 아래 그림을 보면 된다. 위가 Roboto이고 아래가 Iosevka이다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"font-narrow-Roboto_vs_Iosevka.png\" data-origin-width=\"590\" data-origin-height=\"270\"><span data-url=\"https://blog.kakaocdn.net/dn/WdxYi/btsI9eOMy9l/hJr9xAf16xDlGb8bqLiBCk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/WdxYi/btsI9eOMy9l/hJr9xAf16xDlGb8bqLiBCk/img.png\" data-alt=\"Roboto (top) vs Iosevka (bottom)\"><img src=\"https://blog.kakaocdn.net/dn/WdxYi/btsI9eOMy9l/hJr9xAf16xDlGb8bqLiBCk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FWdxYi%2FbtsI9eOMy9l%2FhJr9xAf16xDlGb8bqLiBCk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"font-narrow-Roboto_vs_Iosevka.png\" data-origin-width=\"590\" data-origin-height=\"270\"/></span><figcaption>Roboto (top) vs Iosevka (bottom)</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">폭이 좁으면 화면에 많은 글을 표시할 수 있어서 log를 보거나 code를 분석할 때는 용이한 측면이 있다. 다만 문서 자료를 작성할 때는 정신이 사나울 수도 있다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">1. Nerd font란?</span></h2>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Nerd font는 개발자들이 주로 사용하는 폰트에 각종 기호(git이나 vim 에디터에서 사용하는 기호)를 추가한 버전이다. 기존 폰트에 기호 이미지를 추가하는 패치된 폰트이므로 어떤 폰트든지 패치해서 만들 수 있다. 다만 패치 스크립트를 직접 사용하면 작업 시간이 좀 오래 걸리는 편이라서 미리 패치된 글꼴을 제공한다. 아래에서 볼 수 있다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Nerd Font Downloads -&nbsp;<b><span style=\"color: #1155cc;\"></span><a href=\"https://www.nerdfonts.com/font-downloads\">https://www.nerdfonts.com/font-downloads</a></b></span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">2. 추천하는 폰트</span></h2>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">개인적으로 추천하는 Nerd font는 다음과 같다.&nbsp;</span></p>\n<table style=\"border-collapse: collapse; width: 100%;\" border=\"1\" data-ke-align=\"alignLeft\">\n<tbody>\n<tr>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif; background-color: #f6e199;\">CodeNewRoman</span></td>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">넓은 폭을 가진 글꼴이다.</span><br /><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">가독성이 좋아서 터미널용으로 많이 사용된다.</span></td>\n</tr>\n<tr>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif; background-color: #9feec3;\">D2coding</span></td>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">네이버에서 제작한 글꼴이다.&nbsp;</span><br /><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">폭이 좁은 편이라 한 화면에 많은 글자를 표시할 수 있다.</span></td>\n</tr>\n<tr>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">EnvyCodeR</span></td>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">좁은 폭과 귀엽게 둥근 글꼴이다.</span></td>\n</tr>\n<tr>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Iosevka</span></td>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">좁은 폭을 가진 글꼴이다.</span><br /><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">자매품으로 Zed가 있다.</span></td>\n</tr>\n<tr>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif; background-color: #f6e199;\">Mononoki</span></td>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">중간 폭을 가진 글꼴이다.<br />동글동글해서 귀여운 글꼴이다.</span></td>\n</tr>\n<tr>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Roboto Mono</span></td>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">넓은 폭을 가진 글꼴이다.</span></td>\n</tr>\n<tr>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif; background-color: #99cefa;\">ZedMono</span></td>\n<td style=\"width: 50%;\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">좁은 폭을 가진 글꼴이다.</span><br /><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Iosevka를 약간 둥글게 수정한 글꼴이다. 개인적으로 추천.</span></td>\n</tr>\n</tbody>\n</table>\n<p data-ke-size=\"size16\"><span>위 글꼴 외에 FiraCode, IBM Plex나 Noto Nerd, Source code pro 도 많이 쓰이므로 한번 위의 Nerd Font 링크에서 확인해보기 바란다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif; color: #333333; text-align: start;\">그러면 위에서 언급한 글꼴을 순서대로 그림으로 살펴보면 다음과 같다. 참고로 Gnome builder의 설정 화면에서 캡쳐했다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">2.1. CodeNewRoman Nerd Font</span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"font-CodeNewRoman-nerdfont.png\" data-origin-width=\"780\" data-origin-height=\"773\"><span data-url=\"https://blog.kakaocdn.net/dn/oH2kn/btsJaCAHLxB/aZM24SYmooDsSJz8RKKQ2K/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/oH2kn/btsJaCAHLxB/aZM24SYmooDsSJz8RKKQ2K/img.png\" data-alt=\"CodeNewRoman\"><img src=\"https://blog.kakaocdn.net/dn/oH2kn/btsJaCAHLxB/aZM24SYmooDsSJz8RKKQ2K/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FoH2kn%2FbtsJaCAHLxB%2FaZM24SYmooDsSJz8RKKQ2K%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"font-CodeNewRoman-nerdfont.png\" data-origin-width=\"780\" data-origin-height=\"773\"/></span><figcaption>CodeNewRoman</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">CodeNewRoman은 터미널인 gnome-terminal에서 설정해도 좋은 글꼴이다. 아래 그림은 gnome-terminal에 설정한 모습이다.</span></p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"font-codenewroman_gnome-terminal.png\" data-origin-width=\"952\" data-origin-height=\"651\"><span data-url=\"https://blog.kakaocdn.net/dn/1wkJs/btsJaIHHepO/0gBiK8Uysu9iA3BnGnEg5k/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/1wkJs/btsJaIHHepO/0gBiK8Uysu9iA3BnGnEg5k/img.png\" data-alt=\"gnome-terminal profile\"><img src=\"https://blog.kakaocdn.net/dn/1wkJs/btsJaIHHepO/0gBiK8Uysu9iA3BnGnEg5k/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F1wkJs%2FbtsJaIHHepO%2F0gBiK8Uysu9iA3BnGnEg5k%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"font-codenewroman_gnome-terminal.png\" data-origin-width=\"952\" data-origin-height=\"651\"/></span><figcaption>gnome-terminal profile</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">2.2. D2coding Nerd Font</span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"font-D2coding-nerdfont.png\" data-origin-width=\"789\" data-origin-height=\"774\"><span data-url=\"https://blog.kakaocdn.net/dn/cgnKSX/btsI9xAAvPv/lN54ebkfXTxrxv8mA2XZM0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cgnKSX/btsI9xAAvPv/lN54ebkfXTxrxv8mA2XZM0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cgnKSX/btsI9xAAvPv/lN54ebkfXTxrxv8mA2XZM0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcgnKSX%2FbtsI9xAAvPv%2FlN54ebkfXTxrxv8mA2XZM0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"font-D2coding-nerdfont.png\" data-origin-width=\"789\" data-origin-height=\"774\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">D2coding은 터미널 용으로 써도 좋은 편이다. 그리고 한글이 지원된다는 강점이 있다. 본인은 D2coding 공식 사이트에서 받은 TTC 파일 1개로 버전을 nerdfont 패치 프로그램으로 직접 패치해서 사용하는데, d2coding은 재배포가 가능하므로 나중에 파일 링크를 올리도록 하겠다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">2.3. EnvyCodeR Nerd Font Mono</span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"font-EnvyCodeR-nerdfont-mono.png\" data-origin-width=\"788\" data-origin-height=\"766\"><span data-url=\"https://blog.kakaocdn.net/dn/nGYJw/btsI9EM4WZi/KwJVF3IwSYriRdbfqRorm0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/nGYJw/btsI9EM4WZi/KwJVF3IwSYriRdbfqRorm0/img.png\" data-alt=\"EnvyCodeR\"><img src=\"https://blog.kakaocdn.net/dn/nGYJw/btsI9EM4WZi/KwJVF3IwSYriRdbfqRorm0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FnGYJw%2FbtsI9EM4WZi%2FKwJVF3IwSYriRdbfqRorm0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"font-EnvyCodeR-nerdfont-mono.png\" data-origin-width=\"788\" data-origin-height=\"766\"/></span><figcaption>EnvyCodeR</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">EnvyCodeR도 좁은 편에 둥글둥글한 스타일인데, 문서 읽을때 오히려 더 좋은 것 같다는 생각이 든다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">2.4. Iosevka Nerd Font Medium</span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"font-Iosevka-nerdfont-medium.png\" data-origin-width=\"785\" data-origin-height=\"772\"><span data-url=\"https://blog.kakaocdn.net/dn/vntCe/btsI9EGjS3Y/yirQyBMt7LALKbvFQi7G31/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/vntCe/btsI9EGjS3Y/yirQyBMt7LALKbvFQi7G31/img.png\" data-alt=\"Iosevka\"><img src=\"https://blog.kakaocdn.net/dn/vntCe/btsI9EGjS3Y/yirQyBMt7LALKbvFQi7G31/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FvntCe%2FbtsI9EGjS3Y%2FyirQyBMt7LALKbvFQi7G31%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"font-Iosevka-nerdfont-medium.png\" data-origin-width=\"785\" data-origin-height=\"772\"/></span><figcaption>Iosevka</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">Iosevka는 기본적으로 가늘어서 가독성을 높이려면 Medium 정도의 레벨을 사용하는 것을 추천한다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\">2.5. Mononoki Nerd Font Propo</h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"font-Mononoki-nerdfont-propo.png\" data-origin-width=\"785\" data-origin-height=\"776\"><span data-url=\"https://blog.kakaocdn.net/dn/bem4WE/btsJapn51Sl/a3ZvWAHH8v9pH0Fxhcfw61/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bem4WE/btsJapn51Sl/a3ZvWAHH8v9pH0Fxhcfw61/img.png\" data-alt=\"Mononoki Nerd Font propo\"><img src=\"https://blog.kakaocdn.net/dn/bem4WE/btsJapn51Sl/a3ZvWAHH8v9pH0Fxhcfw61/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbem4WE%2FbtsJapn51Sl%2Fa3ZvWAHH8v9pH0Fxhcfw61%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"font-Mononoki-nerdfont-propo.png\" data-origin-width=\"785\" data-origin-height=\"776\"/></span><figcaption>Mononoki Nerd Font propo</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">동글동글해서 보기 좋은 글꼴이다. 터미널용으로도 괜찮은 글꼴이다. 개인적으로 추천하는 글꼴 중에 하나이다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">2.6. Roboto Nerd Font</span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"font-Roboto-mono-nerdfont.png\" data-origin-width=\"781\" data-origin-height=\"772\"><span data-url=\"https://blog.kakaocdn.net/dn/rn1Jd/btsI94xWXNr/hmLwxkWc7iih3warCPUnx0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/rn1Jd/btsI94xWXNr/hmLwxkWc7iih3warCPUnx0/img.png\" data-alt=\"Roboto Nerd Font\"><img src=\"https://blog.kakaocdn.net/dn/rn1Jd/btsI94xWXNr/hmLwxkWc7iih3warCPUnx0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Frn1Jd%2FbtsI94xWXNr%2FhmLwxkWc7iih3warCPUnx0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"font-Roboto-mono-nerdfont.png\" data-origin-width=\"781\" data-origin-height=\"772\"/></span><figcaption>Roboto Nerd Font</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">2.7. ZedMono Nerd Font Mono Medium</span></h3>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"font-ZedMono-nerdfont-mono-medium.png\" data-origin-width=\"789\" data-origin-height=\"771\"><span data-url=\"https://blog.kakaocdn.net/dn/lbUEi/btsI93Mxh6C/NcYshFilh72ectosyik1Ek/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/lbUEi/btsI93Mxh6C/NcYshFilh72ectosyik1Ek/img.png\" data-alt=\"ZedMono Nerd Font Mono Medium\"><img src=\"https://blog.kakaocdn.net/dn/lbUEi/btsI93Mxh6C/NcYshFilh72ectosyik1Ek/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FlbUEi%2FbtsI93Mxh6C%2FNcYshFilh72ectosyik1Ek%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"font-ZedMono-nerdfont-mono-medium.png\" data-origin-width=\"789\" data-origin-height=\"771\"/></span><figcaption>ZedMono Nerd Font Mono Medium</figcaption>\n</figure>\n</p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">ZedMono는 Iosevka를 다음은 글꼴이다.&nbsp;</span><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">개인적으로 좁은 폰트 중에 제일 좋아하는 폰트이다. 특히 Medium 레벨의 굵기로 표시하면 가독성도 좋다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">3. 폰트 설치 방법</span></h2>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">리눅스에서는 개인 홈디렉터리에 폰트를 설치하는 방법과 시스템에 설치하는 방법이 있는데, 되도록이면 시스템에 설치하는 것을 추천한다. 시스템에 폰트를 설치하는 방법은 매우 간단하다. Nerd Font 사이트에서 받은 폰트는 zip 파일로 되어있는데, 이를 풀면 디렉터리가 나온다. 그리고 해당 디렉터리를 통째로 /usr/share/fonts/ 로 복사하면 된다. (복사는 당연히 root 권한으로 작업해야만 한다)</span></p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">만일 폰트 파일만 있는 경우, 예를 들어 ttc 파일 1개라면 /usr/share/fonts/ 밑에 적당한 이름의 디렉터리를 만들고 그 안에 넣어주면 된다. 예를 들어 mynerdfont.ttc 파일이라면 /usr/share/fonts/mynerdfont 라고 디렉터리를 만들고 그 안에 파일을 넣어주면 된다. ttf같이 여러개의 파일이 있는 경우라도 방법은 같다.</span></p>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">보통 글꼴을 /usr/share/fonts 밑에 복사하면 아무 작업을 안해도 자동으로 인식된다. 그렇지만 간혹 인식이 안된 경우도 생길 수 있는데, 그럴 경우에는 font cache를 재설정하기 위해 fc-cache -f 명령을 내리면 된다. 그래도 안된다면 재부팅하도록 하자.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">히스토리</span></h3>\n<p data-ke-size=\"size16\"><span style=\"font-family: AppleSDGothicNeo-Regular, 'Malgun Gothic', '맑은 고딕', dotum, 돋움, sans-serif;\">2024-08-20 초고</span></p>",
        "contentSnippet": "개발자라면 필수로 고정폭 글꼴(fixed width font, mono font)을 사용한다. 여기서 mono font란 monospace font를 의미한다. 개발자가 고정폭을 좋아하는 이유는 코드를 볼때 간격이 일정해서 가독성이 좋기 때문이다. 반대로 가변폭 글꼴을 사용하면 탭이나 기호가 들어간 코드를 볼때 매우 불편해진다.\n글꼴은 취향의 영역이라서 어느 것이 최고라고 말할 수는 없다. 다만 여기서는 많이 사용되는 Nerd font를 기준으로 하겠다. 너드 폰트는 다운로드를 자동화하는 스크립트도 있지만, 시스템 전역으로 쓸때는 그냥 수동으로 /usr/share/fonts/ 밑에 디렉터리를 만들고 설치하는게 좋다.\n \n0. 글꼴 선택 기준\n본인은 글꼴을 선택할 때 우선적으로 2가지를 살펴본다. \n첫번째로 숫자 0 (zero)의 안쪽이 빗금인지 점인지를 확인한다. 개인적으로 빗금 스타일을 더 선호한다. 아래 그림을 보면 좌측은 빗금 스타일 0(slashed zero number)을 사용하고, 우측은 점을 찍은 것이다. 어느 스타일을 선호하는지 본인이 여기서 보고 정하면 된다.\nMono font - Slashed zero vs Doted zero\n\n\n두번째로는 폭을 본다. 글꼴의 폭이 넓으면 눈이 덜 피로하지만 한 화면에 많이 표시하지 못한다. 대표적으로 폭이 넓은 형태로는 Roboto가 있고, 좁은 형태로는 Iosevka가 있다. 둘을 비교하기 위해 아래 그림을 보면 된다. 위가 Roboto이고 아래가 Iosevka이다.\nRoboto (top) vs Iosevka (bottom)\n\n\n폭이 좁으면 화면에 많은 글을 표시할 수 있어서 log를 보거나 code를 분석할 때는 용이한 측면이 있다. 다만 문서 자료를 작성할 때는 정신이 사나울 수도 있다.\n \n \n1. Nerd font란?\nNerd font는 개발자들이 주로 사용하는 폰트에 각종 기호(git이나 vim 에디터에서 사용하는 기호)를 추가한 버전이다. 기존 폰트에 기호 이미지를 추가하는 패치된 폰트이므로 어떤 폰트든지 패치해서 만들 수 있다. 다만 패치 스크립트를 직접 사용하면 작업 시간이 좀 오래 걸리는 편이라서 미리 패치된 글꼴을 제공한다. 아래에서 볼 수 있다.\nNerd Font Downloads - https://www.nerdfonts.com/font-downloads\n \n2. 추천하는 폰트\n개인적으로 추천하는 Nerd font는 다음과 같다. \nCodeNewRoman\n넓은 폭을 가진 글꼴이다.\n가독성이 좋아서 터미널용으로 많이 사용된다.\n\n\nD2coding\n네이버에서 제작한 글꼴이다. \n폭이 좁은 편이라 한 화면에 많은 글자를 표시할 수 있다.\n\n\nEnvyCodeR\n좁은 폭과 귀엽게 둥근 글꼴이다.\n\n\nIosevka\n좁은 폭을 가진 글꼴이다.\n자매품으로 Zed가 있다.\n\n\nMononoki\n중간 폭을 가진 글꼴이다.\n동글동글해서 귀여운 글꼴이다.\n\n\nRoboto Mono\n넓은 폭을 가진 글꼴이다.\n\n\nZedMono\n좁은 폭을 가진 글꼴이다.\nIosevka를 약간 둥글게 수정한 글꼴이다. 개인적으로 추천.\n\n\n\n위 글꼴 외에 FiraCode, IBM Plex나 Noto Nerd, Source code pro 도 많이 쓰이므로 한번 위의 Nerd Font 링크에서 확인해보기 바란다.\n그러면 위에서 언급한 글꼴을 순서대로 그림으로 살펴보면 다음과 같다. 참고로 Gnome builder의 설정 화면에서 캡쳐했다.\n \n2.1. CodeNewRoman Nerd Font\nCodeNewRoman\n\n\nCodeNewRoman은 터미널인 gnome-terminal에서 설정해도 좋은 글꼴이다. 아래 그림은 gnome-terminal에 설정한 모습이다.\ngnome-terminal profile\n\n\n \n2.2. D2coding Nerd Font\n\n\nD2coding은 터미널 용으로 써도 좋은 편이다. 그리고 한글이 지원된다는 강점이 있다. 본인은 D2coding 공식 사이트에서 받은 TTC 파일 1개로 버전을 nerdfont 패치 프로그램으로 직접 패치해서 사용하는데, d2coding은 재배포가 가능하므로 나중에 파일 링크를 올리도록 하겠다.\n \n2.3. EnvyCodeR Nerd Font Mono\nEnvyCodeR\n\n\nEnvyCodeR도 좁은 편에 둥글둥글한 스타일인데, 문서 읽을때 오히려 더 좋은 것 같다는 생각이 든다.\n \n2.4. Iosevka Nerd Font Medium\nIosevka\n\n\nIosevka는 기본적으로 가늘어서 가독성을 높이려면 Medium 정도의 레벨을 사용하는 것을 추천한다.\n \n2.5. Mononoki Nerd Font Propo\nMononoki Nerd Font propo\n\n\n동글동글해서 보기 좋은 글꼴이다. 터미널용으로도 괜찮은 글꼴이다. 개인적으로 추천하는 글꼴 중에 하나이다.\n \n2.6. Roboto Nerd Font\nRoboto Nerd Font\n\n\n \n \n2.7. ZedMono Nerd Font Mono Medium\nZedMono Nerd Font Mono Medium\n\n\nZedMono는 Iosevka를 다음은 글꼴이다. 개인적으로 좁은 폰트 중에 제일 좋아하는 폰트이다. 특히 Medium 레벨의 굵기로 표시하면 가독성도 좋다.\n \n \n3. 폰트 설치 방법\n리눅스에서는 개인 홈디렉터리에 폰트를 설치하는 방법과 시스템에 설치하는 방법이 있는데, 되도록이면 시스템에 설치하는 것을 추천한다. 시스템에 폰트를 설치하는 방법은 매우 간단하다. Nerd Font 사이트에서 받은 폰트는 zip 파일로 되어있는데, 이를 풀면 디렉터리가 나온다. 그리고 해당 디렉터리를 통째로 /usr/share/fonts/ 로 복사하면 된다. (복사는 당연히 root 권한으로 작업해야만 한다)\n만일 폰트 파일만 있는 경우, 예를 들어 ttc 파일 1개라면 /usr/share/fonts/ 밑에 적당한 이름의 디렉터리를 만들고 그 안에 넣어주면 된다. 예를 들어 mynerdfont.ttc 파일이라면 /usr/share/fonts/mynerdfont 라고 디렉터리를 만들고 그 안에 파일을 넣어주면 된다. ttf같이 여러개의 파일이 있는 경우라도 방법은 같다.\n보통 글꼴을 /usr/share/fonts 밑에 복사하면 아무 작업을 안해도 자동으로 인식된다. 그렇지만 간혹 인식이 안된 경우도 생길 수 있는데, 그럴 경우에는 font cache를 재설정하기 위해 fc-cache -f 명령을 내리면 된다. 그래도 안된다면 재부팅하도록 하자.\n \n히스토리\n2024-08-20 초고",
        "guid": "http://sunyzero.tistory.com/301",
        "categories": [
          "컴퓨터 관련",
          "codenewroman",
          "D2Coding",
          "envycoder",
          "fc-cache",
          "ibm plex",
          "iosevka",
          "mono font",
          "nerdfont",
          "고정폭글꼴",
          "리눅스 글꼴"
        ],
        "isoDate": "2024-08-20T13:04:40.000Z"
      }
    ]
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": [
      {
        "title": "AI 과학자 Sakana.AI 사용법",
        "link": "http://daddynkidsmakers.blogspot.com/2024/08/ai-sakanaai.html",
        "pubDate": "2024-08-19T23:38:00.000Z",
        "author": "Daddy Maker",
        "content": "<div style=\"text-align: left;\">이 글은&nbsp;AI 과학자 Sakana.AI 사용법을 간략히 소개한다.&nbsp;</div><div style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEg0oV5UFCusqRic36rTUWUt9wFR_5bCl4C2hpOdQCcmPjsgDzi1EGwXHU7kRGyGMe7aLfUJUoKzYI9gq504kavl6SDh44f_jfxGjAQu2uzHXJhTvodH8WvCz9a2lLMjAQCw9vU1FxbkWnySpEUU5RdlAYP5yOXVjxq8GWVEkv-hm-eM0XMn6P7tycNve798\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"2048\" data-original-width=\"2048\" height=\"240\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEg0oV5UFCusqRic36rTUWUt9wFR_5bCl4C2hpOdQCcmPjsgDzi1EGwXHU7kRGyGMe7aLfUJUoKzYI9gq504kavl6SDh44f_jfxGjAQu2uzHXJhTvodH8WvCz9a2lLMjAQCw9vU1FxbkWnySpEUU5RdlAYP5yOXVjxq8GWVEkv-hm-eM0XMn6P7tycNve798\" width=\"240\" /></a></div><br />이 프로그램은 과학적 논문을 AI가 스스로 작성할 수 있다.</div><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><a href=\"https://github.com/SakanaAI\">Sakana AI (github.com)</a></li><li><a href=\"https://cosine.sh/register\">Get started with Cosine - Human Reasoning Lab</a></li></ul><div><br /></div><div><br /></div></div>",
        "contentSnippet": "이 글은 AI 과학자 Sakana.AI 사용법을 간략히 소개한다. \n\n\n이 프로그램은 과학적 논문을 AI가 스스로 작성할 수 있다.\n\nSakana AI (github.com)\nGet started with Cosine - Human Reasoning Lab",
        "id": "tag:blogger.com,1999:blog-5201956450461596914.post-2205216419439612546",
        "isoDate": "2024-08-19T23:38:00.000Z"
      }
    ]
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권영재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김병환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": [
      {
        "creator": "고종범",
        "title": "하루 하나의 운동으로 보낸 휴가",
        "link": "https://brunch.co.kr/@@24SO/44",
        "pubDate": "Sun, 18 Aug 2024 10:56:01 GMT",
        "author": "고종범",
        "content": "여유가 생긴 시간 올해는 초반부터 조금 힘들게 시작했다. 불확실성이 높은 프로젝트를 맡아서 하느라 신경을 많이 쓰기도 했고 중간에 목표가 바뀌어서 프로젝트를 재구성하기도 했다. 고생을 했지만 지금은 정리가 되어 프로젝트는 순조롭게 진행되고 잠깐의 여유를 즐기는 시간이 되고 있다. 무엇보다 이슈가 없어서 프로젝트 회의를 하지 않아도 된다는 것이 더욱 여유를",
        "contentSnippet": "여유가 생긴 시간 올해는 초반부터 조금 힘들게 시작했다. 불확실성이 높은 프로젝트를 맡아서 하느라 신경을 많이 쓰기도 했고 중간에 목표가 바뀌어서 프로젝트를 재구성하기도 했다. 고생을 했지만 지금은 정리가 되어 프로젝트는 순조롭게 진행되고 잠깐의 여유를 즐기는 시간이 되고 있다. 무엇보다 이슈가 없어서 프로젝트 회의를 하지 않아도 된다는 것이 더욱 여유를",
        "guid": "https://brunch.co.kr/@@24SO/44",
        "isoDate": "2024-08-18T10:56:01.000Z"
      }
    ]
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김상훈",
    "category": "개인",
    "posts": [
      {
        "creator": "김상훈",
        "title": "Threads on week 33",
        "link": "https://interpiler.com/2024/08/20/threads-on-week-33/",
        "pubDate": "Tue, 20 Aug 2024 03:17:25 +0000",
        "content:encodedSnippet": "sanghoon_k08/17/2024\n“지난해 환경미화원 사상자는 ‘6439명’이다. 전국 환경미화원은 약 4만 명으로 집계되는데 연간 6명 중 1명이 산재를 당하는 셈이다.”\n“이웃인 우리의 반성도 필요하다. 종량제 봉투를 넘치게 채워 무겁게 만들고, 깨진 접시 같은 날카로운 물건을 아무렇게나 봉투에 담는 등 사소한 습관이 환경미화원을 크게 다치게 만든다고 한다. 환경미화원 연간 사상자 ‘6439명’. 이 숫자야말로 우리 사회의 진짜 안전 성적표란 생각이 든다.”\n[횡설수설/우경임]환경미화원 死傷 연 6000명\n\n\n\n\nsanghoon_k08/16/2024\n와이어드에서 조사한 팔로어 숫자에 따른 인플루언서 그래프. 빨간색은 공화당 쪽, 파란색은 민주당 쪽.팔로어 수로만 보면 약 2억 명에 가까운 팔로어를 확보한 일론 머스크가 모두를 과다대표하는 탓에 공화당이 인터넷을 지배하는 것처럼 보임. 실제로 머스크가 X를 이용해 사업과 정치를 넘나드는 모습을 보면 영향력이 대단한 것은 알 수 있지만, 플랫폼 문제도 있음.공화당 쪽 상위 인플루언서들은 X 또는 유튜브에서 활동, 하지만 민주당 쪽 상위 유튜버는 대부분 틱톡이 메인 플랫폼. 어찌보면 인터넷을 지배하는 것 같은 카말라 해리스 쪽 민주당 진영이 10대-20대 파티장인 틱톡만의 태풍 같기도 하고, 그냥 보수주의자들의 막말 대잔치 플랫폼 같은 X의 영향력이 실제 이상으로 대표되는 것 같기도 함. 복잡한 미디어 지형.\n\n\n\n\n\nsanghoon_k4d4 d08/16/2024\n세계 최고령 혹등고래 올드타이머(Old Timer) 이야기….가 아니고, 실제로는 세계 최고령 혹등고래의 나이를 추정하게 된 방법에 대한 기사.혹등고래는 꼬리 지느러미 사진으로 개체를 구분. 사람의 지문이나 얼굴처럼 개체별로 생김새가 다르기 때문. 과거에는 특정 혹등고래를 찾아내기 위해 연구자들이 직접 고래를 촬영하고 눈으로 비교했음.인터넷과 AI의 시대인 21세기에는 모든 게 달라짐. Happywhale이라는 사이트는 일반인으로부터 고래 사진을 제출받아 AI로 분석. 이렇게 사진을 올려준 사람들에겐 자신이 올린 사진과 동일 개체의 사진이 올라오면 그 내용을 계속 업데이트 해 줌. 고래가 언제 나타나 어디를 돌아다니며 어떻게 살아가는지 이해할 방법이 늘어난 것.꼬리지느러미를 분석하는데 쓰이는 알고리듬은 한국 개발자 박진모 님이 개발. 전 세계의 고래연구자들이 널리 쓰는 기술.\nHow the World’s Oldest Humpback Whale Has Survived Is a Mystery\n박진모님 인터뷰 blog.estsoft.co.kr/727, 해피웨일 사이트 happywhale.com\n혹등고래 등밖에 못 봤는데 꼬리지느러미라도 보는 게 쉬운 일이 아니었던 듯. 해피웨일 사이트에선 고래에게 위협을 가하지 않도록 적절한 단계를 지키는 여행사를 찾도록 권장. 세계고래연맹(WCA) 회원사를 추천한다고. 한국 인근에서는 오키나와의 혹등고래 관광이 유명한데, 불행히도 오키나와에는 WCA 회원사가 없는 듯.\n\nsanghoon_k6d6 days ago\n튜비(Tubi)라는 무료 스트리밍 서비스가 미국에서 폭발적인 인기. 넷플릭스가 지배하는 이 업계에서 처음엔 “내 컴퓨터에 바이러스가 깔리는 것 아닌가?”, “정말 무료 맞아?” 같은 의심을 들었지만 지금은 당당히 메이저 서비스가 됐음.- 유튜브, 넷플릭스, 아마존, 훌루 다음의 5위 서비스. 디즈니플러스, 애플티비 같은 서비스들이 모두 튜비보다 시청시간이 적음. – 수익성은 아직 물음표. 수익모델은 당연히 광고. – 낮은 비용이 핵심. 저예산 독립영화, 흘러간 옛 영화, 유명배우가 없는 영화 등이 주요 콘텐츠. – 오리지널 콘텐츠도 제작하는데 철저히 소수의 마니아층을 노리는 콘텐츠.점점 스트리밍 서비스들의 값이 올라가면서 조만간 데드크로스(스트리밍 신규가입자보다 해지가입자가 더 많은 상황)가 생길 가능성도 얘기되는 중. 튜비의 성장은 어찌 보면 당연. 생각해보면 왓챠도 10년째 버티며 아니메, 독립영화 등으로 틈새를 잡은 회사. 한국의 튜비가 될 수 있을까 궁금.\nThe Little Streamer That Could\n\nsanghoon_k08/13/2024\n인공지능이 길가메시 서사시의 번역을 돕기 시작. 수천개의 석판에 새겨진 설형문자가 해석되지 않은 상태로 남겨져 있었는데, 이 석판들을 디지털화한 다음 인공지능에게 번역하도록 시켜서 디테일을 빠르게 보강하는 중. 뿐만 아니라 비슷한 지역과 시기의 유물이 새로 발굴됐을 때 빠르게 해당 유물의 내용을 판단하고 다른 작품들과의 연관성을 파악하는데도 도움을 주고 있음.문과생들도 인공지능 정도는 다룰 줄 알아야 문학 공부를 제대로 해볼 수 있는 세상.\nPiecing Together an Ancient Epic Was Slow Work. Until A.I. Got Involved.\n\nsanghoon_k08/12/2024\n뉴욕타임즈가 메달 수 분석을 여러가지로 했는데, 읽다가 재미있는 부분이 있어서 거기만 발췌. 무기를 사용한 시합에서 한국의 성적을 보세요. 양궁과 사격, 펜싱 덕분. 이렇게 쪼개놓고 봐도 미국이 대부분 1등이지만 2020 도쿄올림픽 대비로 봐도 한국이 3위. 1위야 개최국 효과가 있는 프랑스고, 2위는 미국인데, 한국도 전 올림픽 대비 금메달 7개가 많고 전체 매달수도 12개가 많은 나라. 개인적으로도 가깝고 시차도 없었던 도쿄올림픽보다도 중계를 더 많이 봤던 듯.",
        "dc:creator": "김상훈",
        "comments": "https://interpiler.com/2024/08/20/threads-on-week-33/#respond",
        "content": "sanghoon_k08/17/2024 “지난해 환경미화원 사상자는 ‘6439명’이다. 전국 환경미화원은 약 4만 명으로 집계되는데 연간 6명 중 1명이 산재를 당하는 셈이다.” “이웃인 우리의 반성도 필요하다. 종량제 봉투를 넘치게 채워 무겁게 만들고, 깨진 접시 같은 날카로운 물건을 아무렇게나 봉투에 담는 등 사소한 습관이 환경미화원을 크게 다치게 만든다고 한다. 환경미화원 연간 사상자 ‘6439명’. 이 숫자야말로 우리 사회의 진짜 안전 성적표란 &#8230; <a href=\"https://interpiler.com/2024/08/20/threads-on-week-33/\" class=\"more-link\">계속 읽기 <span class=\"screen-reader-text\">Threads on week&#160;33</span> <span class=\"meta-nav\">\t</span></a>",
        "contentSnippet": "sanghoon_k08/17/2024 “지난해 환경미화원 사상자는 ‘6439명’이다. 전국 환경미화원은 약 4만 명으로 집계되는데 연간 6명 중 1명이 산재를 당하는 셈이다.” “이웃인 우리의 반성도 필요하다. 종량제 봉투를 넘치게 채워 무겁게 만들고, 깨진 접시 같은 날카로운 물건을 아무렇게나 봉투에 담는 등 사소한 습관이 환경미화원을 크게 다치게 만든다고 한다. 환경미화원 연간 사상자 ‘6439명’. 이 숫자야말로 우리 사회의 진짜 안전 성적표란 … 계속 읽기 Threads on week 33",
        "guid": "http://interpiler.com/?p=1504",
        "categories": [
          "That's IT"
        ],
        "isoDate": "2024-08-20T03:17:25.000Z"
      }
    ]
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "비율 계산",
        "link": "https://kangmyounghun.blogspot.com/2024/08/blog-post_22.html",
        "pubDate": "2024-08-22T08:58:00.000Z",
        "author": "강명훈",
        "content": "<div>프로세스 단위별 합산 구하고,</div><div><br /></div>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgOhXs36W9US2RiekjU5y8DAa8GsEORl5sxBBmgaw5HWBInPzfuQetcjYRWg7SV6rpPWzMjOqxAxGT0xFogcUkWYGgc4HD5Oibw80V1Huyo7K3Vc4aGbWBCaV9WJy65dPmsqWoAgaNgTWkkGTcOHHAaFN7amC7fywBDesHcp5u1StPRUtUAP128JSkh0feq/s1240/percent.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1240\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgOhXs36W9US2RiekjU5y8DAa8GsEORl5sxBBmgaw5HWBInPzfuQetcjYRWg7SV6rpPWzMjOqxAxGT0xFogcUkWYGgc4HD5Oibw80V1Huyo7K3Vc4aGbWBCaV9WJy65dPmsqWoAgaNgTWkkGTcOHHAaFN7amC7fywBDesHcp5u1StPRUtUAP128JSkh0feq/s520/percent.png\" width=\"520\" /></a></div><div><br /></div><div><span><a name='more'></a></span>총합 <a href=\"https://docs.splunk.com/Documentation/Splunk/9.3.0/SearchReference/Appendcols\" target=\"_blank\">필드 추가</a> 후,</div><br />\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEimln5NpC3Fdsuv5daWi5vziXQDbwY46Nvz3Zh_kgNQyg6o_Q4jLmahA_DvVO6YdsXWjCjOPk3Qf1h3YUuH-3N3Z7iPCNIG8QlNAD0HZhXpJnAzkSCY03YXRMLs1EmZAjfGSqa2XIojFMjuyZ1s9p_Mpdmc6d7zc1Q2iBTWVLKcncpPbhZzJDEKmCNpXXzv/s1240/percent2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1240\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEimln5NpC3Fdsuv5daWi5vziXQDbwY46Nvz3Zh_kgNQyg6o_Q4jLmahA_DvVO6YdsXWjCjOPk3Qf1h3YUuH-3N3Z7iPCNIG8QlNAD0HZhXpJnAzkSCY03YXRMLs1EmZAjfGSqa2XIojFMjuyZ1s9p_Mpdmc6d7zc1Q2iBTWVLKcncpPbhZzJDEKmCNpXXzv/s520/percent2.png\" width=\"520\" /></a></div><br />\n<div>비율 계산.</div><div><br /></div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh4dpHdY-hZJxGnhlSoMHPWA6c0CK6WBgxavdAbIBWIiUFaA_vaFZuvXT6VDNr8WFILy6PByRHI6wSC1s-YI6Bo7PbulvuXoMwEDS4MqrwBB1jSF-nwmm2jl3JktWxINodvUqtb1fLocQwMjp6bBzpIiueU0QKCnScM7pdNuO5whFicWfCxcS1sHCH4XJsw/s1240/percent3.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1240\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh4dpHdY-hZJxGnhlSoMHPWA6c0CK6WBgxavdAbIBWIiUFaA_vaFZuvXT6VDNr8WFILy6PByRHI6wSC1s-YI6Bo7PbulvuXoMwEDS4MqrwBB1jSF-nwmm2jl3JktWxINodvUqtb1fLocQwMjp6bBzpIiueU0QKCnScM7pdNuO5whFicWfCxcS1sHCH4XJsw/s520/percent3.png\" width=\"520\" /></a></div><div><br /></div><div>아니면 이벤트 단위로 총합, 단위별 합산 추가 후, 계산.</div></div><div><br /></div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjkrY1Cl8fh7lL04rj0SgMxiiaV8xXoTDk6VhMoI0lv27mzptIPny21eod4yLhZnrQHzEZfeKKdWzw_dXPoVUmaIJ5WtT_nCYndvk6ecNisXTtRXY9mVM7Yx3eTRden5ejxJVHEw2PERBKQ10LmbVTKfliPgnzNvUlHLaSwiVLkjQnijIscvdmHHxYdkxWJ/s1280/percent4.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"666\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjkrY1Cl8fh7lL04rj0SgMxiiaV8xXoTDk6VhMoI0lv27mzptIPny21eod4yLhZnrQHzEZfeKKdWzw_dXPoVUmaIJ5WtT_nCYndvk6ecNisXTtRXY9mVM7Yx3eTRden5ejxJVHEw2PERBKQ10LmbVTKfliPgnzNvUlHLaSwiVLkjQnijIscvdmHHxYdkxWJ/s520/percent4.png\" width=\"520\" /></a></div><div><br /></div><div>그냥 <a href=\"https://docs.splunk.com/Documentation/Splunk/9.3.0/SearchReference/Top\" target=\"_blank\">top</a> 쓰자.</div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgN-n-UihLnfQ5CN9jamjwW55gQsHGen9R34TVjvnRmApkAp-FoKQPybxnUTfCRAph0GwlCC2Wx-Q_uwJ6mYVSDf211B6_FX0_7vt4_oawkkIHsL_ea9iXkKVuNVGOrLSsrr_mowxmwCU4e4nwdCHq4WwssJTWOahGXe0y4Fi8VEZ-q0MNJkzRoo9Q_6_I-/s1280/percent5.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"554\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgN-n-UihLnfQ5CN9jamjwW55gQsHGen9R34TVjvnRmApkAp-FoKQPybxnUTfCRAph0GwlCC2Wx-Q_uwJ6mYVSDf211B6_FX0_7vt4_oawkkIHsL_ea9iXkKVuNVGOrLSsrr_mowxmwCU4e4nwdCHq4WwssJTWOahGXe0y4Fi8VEZ-q0MNJkzRoo9Q_6_I-/s520/percent5.png\" width=\"520\" /></a></div><div><br /></div></div><div><div><b>관련 글</b></div><div><ul><li><a href=\"https://kangmyounghun.blogspot.com/2021/08/splunk-eval-rex.html\">Splunk의 eval과 rex</a></li></ul></div></div>",
        "contentSnippet": "프로세스 단위별 합산 구하고,\n\n\n\n\n\n총합 필드 추가 후,\n\n\n\n비율 계산.\n\n\n\n\n\n아니면 이벤트 단위로 총합, 단위별 합산 추가 후, 계산.\n\n\n\n\n\n\n그냥 top 쓰자.\n\n\n\n\n\n관련 글\n\nSplunk의 eval과 rex",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-2918153940603938022",
        "isoDate": "2024-08-22T08:58:00.000Z"
      },
      {
        "title": "데이터 시인성 - 8th",
        "link": "https://kangmyounghun.blogspot.com/2024/08/8th.html",
        "pubDate": "2024-08-18T10:24:00.001Z",
        "author": "강명훈",
        "content": "<div>해시 변화를 보여주는 차트.</div><div><br /></div>\n<div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg76x0GGNdvmDKz7yBqwqHXDUiqCB1rvypjadLtapGWpU2506VcLXU58If8loNKP_S93FFMHF2NardvIJGjnFcRdqiy93rF6sB-Dk-W3NhHN2DtvNSAU3GzkE8Wu12GpKu7cI5SJRtHwgQoQ9x1Rao1I7J2MMqU83rVlfNXtH3aY6TkvjDir5tXPopyxSPu/s1274/elastic_timechart.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1274\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg76x0GGNdvmDKz7yBqwqHXDUiqCB1rvypjadLtapGWpU2506VcLXU58If8loNKP_S93FFMHF2NardvIJGjnFcRdqiy93rF6sB-Dk-W3NhHN2DtvNSAU3GzkE8Wu12GpKu7cI5SJRtHwgQoQ9x1Rao1I7J2MMqU83rVlfNXtH3aY6TkvjDir5tXPopyxSPu/s520/elastic_timechart.png\" width=\"520\" /></a></div><div><br /></div></div>\n<div><span><a name='more'></a></span>숫자가 무량대수급으로 커지면 스플렁크는 좀 헤메는 것 같다.&nbsp;버그?&nbsp;측정은 했는데 차트가 안 보임.</div><div><br /></div>\n<div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjIEA6GkY51bmkTyQYyKlzN4fPNIrT_51UgFk9TV2emzo8cAUVprAyArPWjP2XknFYNIoUUfsv1GQpSiZcV9otZV3xqn2y4i3zMjEMY2ZAScwI_7yJByStG1h4y_0GvCDtgON7iMKJBDJ3zv33OSF3yK4wni6S3r1aEk8GHtoPwQ7r8ag7V3aEGVzaBfzpK/s1549/splunk_timechart.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"1125\" data-original-width=\"1549\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjIEA6GkY51bmkTyQYyKlzN4fPNIrT_51UgFk9TV2emzo8cAUVprAyArPWjP2XknFYNIoUUfsv1GQpSiZcV9otZV3xqn2y4i3zMjEMY2ZAScwI_7yJByStG1h4y_0GvCDtgON7iMKJBDJ3zv33OSF3yK4wni6S3r1aEk8GHtoPwQ7r8ag7V3aEGVzaBfzpK/s520/splunk_timechart.png\" width=\"520\" /></a></div><div><br /></div></div>\n<div>그럴 땐 Y축 기준점을 바꾸던가,</div><div><br /></div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhXjHJ5dVHXwi5IKcwApe5qvCgiOTaJ10b9K9dTMmXkCU4ZuGS6ZHT9B-mADq-YMseTXeiqzso5xLw1DG0Qh6YcD3FeZU7rvyIQe0gd5szv4Y6k89R6R-3ML-nRGqBBwyFf36Asel3FrJVWcgj9C3JqYaCOK7ZOmpFErUbN3P5KvE53uEbJrADU6nSFtAcm/s1924/splunk_timechart2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"1125\" data-original-width=\"1924\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhXjHJ5dVHXwi5IKcwApe5qvCgiOTaJ10b9K9dTMmXkCU4ZuGS6ZHT9B-mADq-YMseTXeiqzso5xLw1DG0Qh6YcD3FeZU7rvyIQe0gd5szv4Y6k89R6R-3ML-nRGqBBwyFf36Asel3FrJVWcgj9C3JqYaCOK7ZOmpFErUbN3P5KvE53uEbJrADU6nSFtAcm/s520/splunk_timechart2.png\" width=\"520\" /></a></div><br /><div>차트 유형을 바꾸던가.</div><div><br /></div></div>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgcCE-KgASVJBE9Ve77EtVgAHBTe-XleEUABZ_UdigbliBvt5iM1ChwlZexf8wzn03Tz7crOi3QCDZEHhon_Ya3sT9hIW1nD9HIzpg20adgJtvalf_QhNg2uMeQzB8r4fMXovCBqAkETdNIP-9aSkrlD0eZP0gcANl8yoSJSpJxXHz2mwquKHLvUUKnalQ5/s1924/splunk_timechart3.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"1125\" data-original-width=\"1924\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgcCE-KgASVJBE9Ve77EtVgAHBTe-XleEUABZ_UdigbliBvt5iM1ChwlZexf8wzn03Tz7crOi3QCDZEHhon_Ya3sT9hIW1nD9HIzpg20adgJtvalf_QhNg2uMeQzB8r4fMXovCBqAkETdNIP-9aSkrlD0eZP0gcANl8yoSJSpJxXHz2mwquKHLvUUKnalQ5/s520/splunk_timechart3.png\" width=\"520\" /></a></div><div><br /></div><div><div><b>관련 글</b></div><div><ul><li><a href=\"https://kangmyounghun.blogspot.com/2024/06/7th.html\">데이터 시인성 - 7th</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2020/09/blog-post.html\" target=\"\">데이터 시인성</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2022/09/having-query.html\">having query</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2022/05/splunk.html\" target=\"\">Splunk의 해시 변환</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2021/11/blog-post.html\">네트워크 관계망 그리기</a></li></ul></div></div>",
        "contentSnippet": "해시 변화를 보여주는 차트.\n\n\n\n\n\n\n숫자가 무량대수급으로 커지면 스플렁크는 좀 헤메는 것 같다. 버그? 측정은 했는데 차트가 안 보임.\n\n\n\n\n\n\n그럴 땐 Y축 기준점을 바꾸던가,\n\n\n\n\n차트 유형을 바꾸던가.\n\n\n\n\n\n관련 글\n\n데이터 시인성 - 7th\n데이터 시인성\nhaving query\nSplunk의 해시 변환\n네트워크 관계망 그리기",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-2683829468208235580",
        "isoDate": "2024-08-18T10:24:00.001Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕홍",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김놀부",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "스마트폰으로 DSLR 부럽지 않은 사진 찍는 4가지 방법",
        "link": "http://muzbox.tistory.com/483461",
        "pubDate": "Fri, 23 Aug 2024 17:50:43 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483461#entry483461comment",
        "content": "<p data-ke-size=\"size16\">스마트폰으로 DSLR 못지않은 사진을 찍고 싶으신가요? 이 글에서 소개하는 간단한 비법들을 통해, DSLR 없이도 스마트폰만으로 멋진 사진을 촬영하는 방법을 알아보세요.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"0000.png\" data-origin-width=\"1234\" data-origin-height=\"694\"><span data-url=\"https://blog.kakaocdn.net/dn/dgYX4o/btsJcJnZHOm/sHaXaT6CAXv3XpQ5iSCWG0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dgYX4o/btsJcJnZHOm/sHaXaT6CAXv3XpQ5iSCWG0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dgYX4o/btsJcJnZHOm/sHaXaT6CAXv3XpQ5iSCWG0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdgYX4o%2FbtsJcJnZHOm%2FsHaXaT6CAXv3XpQ5iSCWG0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"스마트폰으로 DSLR 부럽지 않은 사진 찍는 4가지 방법\" data-filename=\"0000.png\" data-origin-width=\"1234\" data-origin-height=\"694\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">스마트폰이 우리 일상에서 없어서는 안 될 필수 아이템이 된 지도 오래입니다. 특히, 최근 몇 년간 스마트폰 카메라 기술이 비약적으로 발전하면서, 이제는 DSLR 없이도 훌륭한 사진을 촬영할 수 있게 되었습니다. 하지만 좋은 장비만으로는 뛰어난 사진을 찍을 수 없다는 사실, 알고 계셨나요? 이번 글에서는 별도의 DSLR 없이도 스마트폰으로 멋진 사진을 찍을 수 있는 몇 가지 비법을 소개하고자 합니다. 이제 언제 어디서나 스마트폰을 꺼내들어 전문가처럼 사진을 찍어보세요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>1. 카메라 설정 최적화하기</b></span></h2>\n<p data-ke-size=\"size16\">스마트폰의 기본 카메라 앱은 많은 설정을 자동으로 처리해줍니다. 하지만 설정을 조금만 손봐도 사진의 퀄리티를 크게 향상시킬 수 있습니다. 예를 들어, HDR(High Dynamic Range) 기능을 활성화하면 밝고 어두운 영역이 고르게 노출되어 더 자연스럽고 선명한 사진을 얻을 수 있습니다. 또한, 촬영 전에 초점을 수동으로 맞추고, 노출을 조정하는 것 역시 중요합니다. 빛이 너무 많거나 적으면 사진이 흐릿해지거나, 디테일이 사라질 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"a.png\" data-origin-width=\"1234\" data-origin-height=\"694\"><span data-url=\"https://blog.kakaocdn.net/dn/eXksWk/btsJcQHmAMR/qlHktJNK87wm2pUXyqECgk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/eXksWk/btsJcQHmAMR/qlHktJNK87wm2pUXyqECgk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/eXksWk/btsJcQHmAMR/qlHktJNK87wm2pUXyqECgk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FeXksWk%2FbtsJcQHmAMR%2FqlHktJNK87wm2pUXyqECgk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"카메라 설정 최적화하기\" data-filename=\"a.png\" data-origin-width=\"1234\" data-origin-height=\"694\"/></span></figure>\n</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>HDR 기능 사용:</b> 강한 대비가 있는 장면에서 더 디테일한 사진을 촬영할 수 있습니다.</li>\n<li><b>초점 수동 조절:</b> 사진의 주제가 명확하게 보이도록 초점을 맞추세요.</li>\n<li><b>노출 조정:</b> 밝기를 조절하여 디테일을 더 살릴 수 있습니다.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>2. 자연광을 활용하라</b></span></h2>\n<p data-ke-size=\"size16\">빛은 사진의 품질을 좌우하는 중요한 요소입니다. 스마트폰 카메라 센서의 크기는 DSLR보다 작기 때문에, 충분한 조명이 없다면 사진이 흐릿하게 나오기 쉽습니다. 자연광을 잘 활용하면 이런 문제를 해결할 수 있습니다. 예를 들어, 창가에서 들어오는 자연광을 활용하거나, 해가 질 무렵의 부드러운 빛을 이용해 촬영해 보세요. 실내 촬영 시에는 인공 조명보다는 자연광을 최대한 활용하는 것이 좋습니다. 단, 역광을 피하고 피사체가 빛을 충분히 받도록 각도를 조절해야 합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"b.png\" data-origin-width=\"1234\" data-origin-height=\"694\"><span data-url=\"https://blog.kakaocdn.net/dn/ba9KfT/btsJdmThLeR/r6rk4BWLkFmtlBfZVDOu60/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ba9KfT/btsJdmThLeR/r6rk4BWLkFmtlBfZVDOu60/img.png\"><img src=\"https://blog.kakaocdn.net/dn/ba9KfT/btsJdmThLeR/r6rk4BWLkFmtlBfZVDOu60/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fba9KfT%2FbtsJdmThLeR%2Fr6rk4BWLkFmtlBfZVDOu60%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"자연광을 활용하라\" data-filename=\"b.png\" data-origin-width=\"1234\" data-origin-height=\"694\"/></span></figure>\n</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>황금 시간대 촬영:</b> 일출이나 일몰 시의 부드러운 빛을 활용해보세요.</li>\n<li><b>역광 피하기:</b> 피사체가 어두워지지 않도록 주의하세요.</li>\n<li><b>반사된 빛 활용:</b> 직사광선이 강할 때는 반사된 빛을 이용하세요.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>3. 구도와 각도에 신경 쓰기</b></span></h2>\n<p data-ke-size=\"size16\">좋은 사진은 구도에서 시작된다고 해도 과언이 아닙니다. 촬영할 때 단순히 피사체를 중앙에 두기보다는 3분할 구도를 활용하거나, 다양한 각도에서 찍어보는 것이 좋습니다. 예를 들어, 낮은 각도에서 촬영하면 피사체가 더 돋보이게 되며, 높은 각도에서는 넓은 배경을 효과적으로 담을 수 있습니다. 또한, 수평을 맞추는 것 역시 중요합니다. 스마트폰의 그리드 라인을 활용하면 수평을 쉽게 맞출 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"c.png\" data-origin-width=\"1234\" data-origin-height=\"694\"><span data-url=\"https://blog.kakaocdn.net/dn/QXn8G/btsJeAvZqmg/3DJuAfVCyf3jb2r1qEqH50/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/QXn8G/btsJeAvZqmg/3DJuAfVCyf3jb2r1qEqH50/img.png\"><img src=\"https://blog.kakaocdn.net/dn/QXn8G/btsJeAvZqmg/3DJuAfVCyf3jb2r1qEqH50/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FQXn8G%2FbtsJeAvZqmg%2F3DJuAfVCyf3jb2r1qEqH50%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"구도와 각도에 신경 쓰기\" data-filename=\"c.png\" data-origin-width=\"1234\" data-origin-height=\"694\"/></span></figure>\n</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>3분할 구도:</b> 사진의 중심을 3등분하여 구성하세요.</li>\n<li><b>다양한 각도 실험:</b> 여러 각도에서 촬영하여 가장 인상적인 장면을 찾아보세요.</li>\n<li><b>수평 맞추기:</b> 그리드 라인을 사용하여 수평을 정확히 맞추세요.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>4. 간단한 후반 작업으로 완성도 높이기</b></span></h2>\n<p data-ke-size=\"size16\">사진을 찍고 난 후에도 스마트폰에서 바로 간단한 편집 작업을 통해 완성도를 높일 수 있습니다. 예를 들어, 밝기와 대비를 조정하거나, 색온도를 맞추는 것만으로도 사진의 분위기가 완전히 달라질 수 있습니다. 요즘 스마트폰에는 다양한 편집 앱이 있어서 전문가처럼 색상 보정, 노이즈 제거, 크롭 등을 손쉽게 할 수 있습니다. 하지만 과도한 편집은 오히려 사진의 자연스러움을 해칠 수 있으므로, 적절한 선에서 작업을 마무리하는 것이 좋습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"d.png\" data-origin-width=\"1234\" data-origin-height=\"694\"><span data-url=\"https://blog.kakaocdn.net/dn/bHSy0O/btsJekmEDnB/IqyGjmZRrUxZx8mgErOMqK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bHSy0O/btsJekmEDnB/IqyGjmZRrUxZx8mgErOMqK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bHSy0O/btsJekmEDnB/IqyGjmZRrUxZx8mgErOMqK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbHSy0O%2FbtsJekmEDnB%2FIqyGjmZRrUxZx8mgErOMqK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"d.png\" data-origin-width=\"1234\" data-origin-height=\"694\"/></span></figure>\n</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><b>밝기 및 대비 조절:</b> 간단한 조정만으로도 사진이 선명해질 수 있습니다.</li>\n<li><b>색온도 맞추기:</b> 사진의 분위기를 원하는 대로 조정하세요.</li>\n<li><b>과한 편집 피하기:</b> 자연스러움을 잃지 않도록 주의하세요.</li>\n</ul>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #006dd7;\"><b>결론</b></span></h2>\n<p data-ke-size=\"size16\">스마트폰 카메라는 이제 우리 삶의 필수품이 되었으며, DSLR에 뒤지지 않는 성능을 자랑합니다. 하지만 그만큼 사용자의 노력도 중요합니다. 이번에 소개한 간단한 팁들을 활용하면, 언제 어디서나 스마트폰으로 전문가 못지않은 사진을 촬영할 수 있을 것입니다. 중요한 것은 장비가 아닌, 그 장비를 어떻게 활용하느냐입니다. 다음번에 사진을 찍을 때는 이 비법들을 꼭 기억하고 적용해 보세요.</p>",
        "contentSnippet": "스마트폰으로 DSLR 못지않은 사진을 찍고 싶으신가요? 이 글에서 소개하는 간단한 비법들을 통해, DSLR 없이도 스마트폰만으로 멋진 사진을 촬영하는 방법을 알아보세요.\n\n\n \n스마트폰이 우리 일상에서 없어서는 안 될 필수 아이템이 된 지도 오래입니다. 특히, 최근 몇 년간 스마트폰 카메라 기술이 비약적으로 발전하면서, 이제는 DSLR 없이도 훌륭한 사진을 촬영할 수 있게 되었습니다. 하지만 좋은 장비만으로는 뛰어난 사진을 찍을 수 없다는 사실, 알고 계셨나요? 이번 글에서는 별도의 DSLR 없이도 스마트폰으로 멋진 사진을 찍을 수 있는 몇 가지 비법을 소개하고자 합니다. 이제 언제 어디서나 스마트폰을 꺼내들어 전문가처럼 사진을 찍어보세요.\n \n \n1. 카메라 설정 최적화하기\n스마트폰의 기본 카메라 앱은 많은 설정을 자동으로 처리해줍니다. 하지만 설정을 조금만 손봐도 사진의 퀄리티를 크게 향상시킬 수 있습니다. 예를 들어, HDR(High Dynamic Range) 기능을 활성화하면 밝고 어두운 영역이 고르게 노출되어 더 자연스럽고 선명한 사진을 얻을 수 있습니다. 또한, 촬영 전에 초점을 수동으로 맞추고, 노출을 조정하는 것 역시 중요합니다. 빛이 너무 많거나 적으면 사진이 흐릿해지거나, 디테일이 사라질 수 있습니다.\n\n\n\nHDR 기능 사용: 강한 대비가 있는 장면에서 더 디테일한 사진을 촬영할 수 있습니다.\n초점 수동 조절: 사진의 주제가 명확하게 보이도록 초점을 맞추세요.\n노출 조정: 밝기를 조절하여 디테일을 더 살릴 수 있습니다.\n \n \n2. 자연광을 활용하라\n빛은 사진의 품질을 좌우하는 중요한 요소입니다. 스마트폰 카메라 센서의 크기는 DSLR보다 작기 때문에, 충분한 조명이 없다면 사진이 흐릿하게 나오기 쉽습니다. 자연광을 잘 활용하면 이런 문제를 해결할 수 있습니다. 예를 들어, 창가에서 들어오는 자연광을 활용하거나, 해가 질 무렵의 부드러운 빛을 이용해 촬영해 보세요. 실내 촬영 시에는 인공 조명보다는 자연광을 최대한 활용하는 것이 좋습니다. 단, 역광을 피하고 피사체가 빛을 충분히 받도록 각도를 조절해야 합니다.\n\n\n\n황금 시간대 촬영: 일출이나 일몰 시의 부드러운 빛을 활용해보세요.\n역광 피하기: 피사체가 어두워지지 않도록 주의하세요.\n반사된 빛 활용: 직사광선이 강할 때는 반사된 빛을 이용하세요.\n \n \n3. 구도와 각도에 신경 쓰기\n좋은 사진은 구도에서 시작된다고 해도 과언이 아닙니다. 촬영할 때 단순히 피사체를 중앙에 두기보다는 3분할 구도를 활용하거나, 다양한 각도에서 찍어보는 것이 좋습니다. 예를 들어, 낮은 각도에서 촬영하면 피사체가 더 돋보이게 되며, 높은 각도에서는 넓은 배경을 효과적으로 담을 수 있습니다. 또한, 수평을 맞추는 것 역시 중요합니다. 스마트폰의 그리드 라인을 활용하면 수평을 쉽게 맞출 수 있습니다.\n\n\n\n3분할 구도: 사진의 중심을 3등분하여 구성하세요.\n다양한 각도 실험: 여러 각도에서 촬영하여 가장 인상적인 장면을 찾아보세요.\n수평 맞추기: 그리드 라인을 사용하여 수평을 정확히 맞추세요.\n \n \n4. 간단한 후반 작업으로 완성도 높이기\n사진을 찍고 난 후에도 스마트폰에서 바로 간단한 편집 작업을 통해 완성도를 높일 수 있습니다. 예를 들어, 밝기와 대비를 조정하거나, 색온도를 맞추는 것만으로도 사진의 분위기가 완전히 달라질 수 있습니다. 요즘 스마트폰에는 다양한 편집 앱이 있어서 전문가처럼 색상 보정, 노이즈 제거, 크롭 등을 손쉽게 할 수 있습니다. 하지만 과도한 편집은 오히려 사진의 자연스러움을 해칠 수 있으므로, 적절한 선에서 작업을 마무리하는 것이 좋습니다.\n\n\n\n밝기 및 대비 조절: 간단한 조정만으로도 사진이 선명해질 수 있습니다.\n색온도 맞추기: 사진의 분위기를 원하는 대로 조정하세요.\n과한 편집 피하기: 자연스러움을 잃지 않도록 주의하세요.\n \n \n결론\n스마트폰 카메라는 이제 우리 삶의 필수품이 되었으며, DSLR에 뒤지지 않는 성능을 자랑합니다. 하지만 그만큼 사용자의 노력도 중요합니다. 이번에 소개한 간단한 팁들을 활용하면, 언제 어디서나 스마트폰으로 전문가 못지않은 사진을 촬영할 수 있을 것입니다. 중요한 것은 장비가 아닌, 그 장비를 어떻게 활용하느냐입니다. 다음번에 사진을 찍을 때는 이 비법들을 꼭 기억하고 적용해 보세요.",
        "guid": "http://muzbox.tistory.com/483461",
        "categories": [
          "ANDROID &amp; 모바일/안드로이드 꿀팁",
          "dslr 없이 사진",
          "hdr 기능",
          "사진 구도",
          "사진 편집",
          "스마트폰 사진 비법",
          "스마트폰 사진 촬영",
          "스마트폰 카메라 설정",
          "자연광 활용"
        ],
        "isoDate": "2024-08-23T08:50:43.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "이미지 품질 향상 AIarty, 무료 1년 라이센스 받는 방법",
        "link": "http://muzbox.tistory.com/483460",
        "pubDate": "Thu, 22 Aug 2024 09:24:29 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483460#entry483460comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;AIarty 이미지 향상 프로그램으로 사진을 놀랍도록 향상시키세요. 무료 1년 라이선스를 통해 Windows와 Mac에서 고해상도 이미지를 손쉽게 제작할 수 있습니다. 지금 한정된 시간 동안 무료로 제공되는 이 기회를 놓치지 마세요!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1280\" data-origin-height=\"720\"><span data-url=\"https://blog.kakaocdn.net/dn/XdCYQ/btsJbtj4Hgg/ZKza8SqAkQgpbhyUvGpE10/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/XdCYQ/btsJbtj4Hgg/ZKza8SqAkQgpbhyUvGpE10/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/XdCYQ/btsJbtj4Hgg/ZKza8SqAkQgpbhyUvGpE10/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FXdCYQ%2FbtsJbtj4Hgg%2FZKza8SqAkQgpbhyUvGpE10%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"이미지 품질 향상 AIarty, 무료 1년 라이센스 받는 방법\" data-origin-width=\"1280\" data-origin-height=\"720\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;이미지의 품질은 높을수록 시각적 경험이 향상되며, 이는 개인 프로젝트든 비즈니스 마케팅이든 매우 중요한 요소로 작용합니다. 그러나 때로는 저해상도 이미지나 노이즈가 많은 사진 때문에 원하는 결과를 얻지 못할 때가 있습니다. 이런 문제를 해결하기 위해 AIarty 이미지 향상 소프트웨어가 등장했습니다. AIarty는 최신 딥러닝 기술을 활용하여 이미지를 향상시키고, 저해상도 이미지를 고해상도로 변환하며, 노이즈 제거와 블러 현상을 개선하는 강력한 기능을 제공합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"color: #ee2323;\"><i>&nbsp;특히, 이 소프트웨어의 일반적인 1년 라이선스는 85달러이지만, 현재 무료로 제공되고 있어 누구나 손쉽게 이 강력한 도구를 활용할 수 있습니다.</i></span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>AIarty 소개</b></span></h2>\n<p data-ke-size=\"size16\">AIarty 이미지 향상 프로그램은 Mac과 Windows에서 모두 사용할 수 있는 친환경 데스크탑 프로그램으로, 혁신적인 딥러닝 기술을 사용하여 이미지의 품질을 향상시키고 업스케일링하며, 세부 정보를 생성하는 데 최적화되어 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1092\" data-origin-height=\"724\"><span data-url=\"https://blog.kakaocdn.net/dn/cL5hCO/btsJaAxsUyE/VygUOy55ShYubfj04aIzqK/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/cL5hCO/btsJaAxsUyE/VygUOy55ShYubfj04aIzqK/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/cL5hCO/btsJaAxsUyE/VygUOy55ShYubfj04aIzqK/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcL5hCO%2FbtsJaAxsUyE%2FVygUOy55ShYubfj04aIzqK%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"AIarty\" data-origin-width=\"1092\" data-origin-height=\"724\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 소프트웨어는 최대 32K(Windows) 또는 16K(Mac) 해상도로 이미지를 업스케일링할 수 있으며, 이를 통해 저해상도 이미지를 200%, 400%, 800%로 확대해도 고품질로 인쇄할 수 있습니다. 뿐만 아니라 2K, 4K, 8K의 고해상도 이미지를 제공하여 노이즈와 블러를 제거하고, 압축된 JPEG를 복원하는 기능도 포함되어 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 소프트웨어는 이미지 품질을 크게 개선하여 잡음과 결함이 없는 선명한 이미지를 제공합니다. 특히 AIarty의 기술은 저품질, 저해상도 이미지나 AI가 생성한 이미지를 고화질의 예술 작품으로 변환하는 데 탁월한 성능을 발휘합니다. 사용자는 1K, 2K, 4K, 8K 해상도를 선택할 수 있으며, 최대 32K 이미지 품질을 제공하는 업스케일 기능도 포함되어 있어 큰 포맷의 출력물을 손쉽게 제작할 수 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"AIarty 01.png\" data-origin-width=\"1392\" data-origin-height=\"745\"><span data-url=\"https://blog.kakaocdn.net/dn/bgYWwC/btsJbKeOf5C/Kc8ni1oTzcLj4yM6PCjda1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bgYWwC/btsJbKeOf5C/Kc8ni1oTzcLj4yM6PCjda1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bgYWwC/btsJbKeOf5C/Kc8ni1oTzcLj4yM6PCjda1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbgYWwC%2FbtsJbKeOf5C%2FKc8ni1oTzcLj4yM6PCjda1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"AIarty\" data-filename=\"AIarty 01.png\" data-origin-width=\"1392\" data-origin-height=\"745\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;또한 이 프로그램은 이미지의 모서리를 선명하게 만들어주는 디블러 기능과, 노이즈를 제거하고 이미지를 재구성하여 더욱 깨끗한 결과물을 제공하는 디노이즈 기능을 제공합니다. AIarty는 세 가지 AI 모델을 사용하여 사진을 개선합니다. 첫 번째 모델은 이미지의 세부 정보를 더욱 뚜렷하게 하고, 두 번째 모델은 사진을 부드럽게 처리하여 결함을 제거하며, 세 번째 모델은 실제와 같은 세부 정보를 추가하여 이미지를 더 생동감 있게 만듭니다.</p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=Y3QdLNFWP0I\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/eghvGt/hyWSchXMkT/NcWPFazPRFoZB0H0Pw7yBk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"Aiarty Image Enhancer Quick Start Guide | From Pixelated to Perfect\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/Y3QdLNFWP0I\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>AIarty 무료 1년 라이선스 취득 방법</b></span></h2>\n<p data-ke-size=\"size16\">AIarty 이미지 향상 소프트웨어의 1년 무료 라이선스를 얻는 방법은 매우 간단합니다. 아래 단계를 따라 무료 라이선스를 취득해 보세요:</p>\n<ol style=\"list-style-type: decimal;\" data-ke-list-type=\"decimal\">\n<li>공식 웹사이트 방문: 먼저 <b><span style=\"color: #006dd7;\"><u>[</u> <a href=\"https://www.aiarty.com\" target=\"_blank\" rel=\"noopener\">AIarty 공식 웹사이트</a> ]</span></b>를 방문합니다. 웹사이트에서 해당 프로그램의 무료 1년 라이선스를 제공하는 페이지로 이동하세요.</li>\n<li>다운로드 및 설치: 사용 중인 운영 체제에 맞는 설치 파일을 다운로드합니다. Windows 사용자는 <span style=\"color: #006dd7;\"><b>[</b> <a href=\"https://www.aiarty.com/release/aiarty-image-enhancer.exe\" target=\"_blank\" rel=\"noopener\">여기</a> <b>]</b></span>에서, Mac 사용자는<b><u><span style=\"color: #006dd7;\">[ <a href=\"https://www.aiarty.com/release/aiarty-image-enhancer.dmg\" target=\"_blank\" rel=\"noopener\">여기</a> ]</span></u></b>에서 설치 파일을 다운로드할 수 있습니다. 다운로드가 완료되면 파일을 실행하여 프로그램을 설치합니다.</li>\n<li>라이선스 코드 입력: 프로그램 설치 및 실행 후, 이메일 주소와 함께 제공된 라이선스 코드를 입력합니다. Windows와 Mac 사용자에게 각각 다른 라이선스 코드가 제공되며, 이를 통해 프로그램을 활성화할 수 있습니다.\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>Windows 라이선스 코드:\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>FAN3I-ZJE5W-A4QRQ-JWEBH</li>\n<li>FA5OU-OQKNW-QPHTC-4VMGZ</li>\n<li>FAMU5-MJFVU-T3KAY-664VF</li>\n</ul>\n</li>\n<li>Mac 라이선스 코드:\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li>FBOIZ-JJRUD-6IEFN-KGZCR</li>\n<li>FBR6N-A75VN-PVIEO-CCSSU</li>\n<li>FB2HF-24TT5-U7YEB-5562Z</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>프로그램 활성화: 라이선스 코드를 입력하고 \"Activate\" 버튼을 클릭하면 프로그램이 활성화됩니다. 이제 1년 동안 AIarty 이미지 향상 소프트웨어의 모든 기능을 무료로 이용할 수 있습니다.<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"847\" data-origin-height=\"850\"><span data-url=\"https://blog.kakaocdn.net/dn/cseRwY/btsJag7hTya/qHw4JpK2MqJAy61SyhmphK/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/cseRwY/btsJag7hTya/qHw4JpK2MqJAy61SyhmphK/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/cseRwY/btsJag7hTya/qHw4JpK2MqJAy61SyhmphK/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcseRwY%2FbtsJag7hTya%2FqHw4JpK2MqJAy61SyhmphK%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"AIarty\" data-origin-width=\"847\" data-origin-height=\"850\"/></span></figure>\n</li>\n</ol>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>마치며</b></span></h2>\n<p data-ke-size=\"size16\">AIarty 이미지 향상 소프트웨어는 매우 강력하면서도 사용하기 쉬운 사진 향상 도구로, 이미지 품질을 한 단계 끌어올리려는 모든 사용자에게 추천할 만한 프로그램입니다. 이 소프트웨어는 업스케일링, 노이즈 제거, 블러 개선뿐만 아니라 세부 정보를 추가하는 등 다양한 기능을 제공하여 이미지를 더욱 선명하고 생생하게 만듭니다. 지금 바로 무료 1년 라이선스를 통해 AIarty를 경험해 보세요.&nbsp;</p>",
        "contentSnippet": "AIarty 이미지 향상 프로그램으로 사진을 놀랍도록 향상시키세요. 무료 1년 라이선스를 통해 Windows와 Mac에서 고해상도 이미지를 손쉽게 제작할 수 있습니다. 지금 한정된 시간 동안 무료로 제공되는 이 기회를 놓치지 마세요!\n \n\n\n \n 이미지의 품질은 높을수록 시각적 경험이 향상되며, 이는 개인 프로젝트든 비즈니스 마케팅이든 매우 중요한 요소로 작용합니다. 그러나 때로는 저해상도 이미지나 노이즈가 많은 사진 때문에 원하는 결과를 얻지 못할 때가 있습니다. 이런 문제를 해결하기 위해 AIarty 이미지 향상 소프트웨어가 등장했습니다. AIarty는 최신 딥러닝 기술을 활용하여 이미지를 향상시키고, 저해상도 이미지를 고해상도로 변환하며, 노이즈 제거와 블러 현상을 개선하는 강력한 기능을 제공합니다.\n \n 특히, 이 소프트웨어의 일반적인 1년 라이선스는 85달러이지만, 현재 무료로 제공되고 있어 누구나 손쉽게 이 강력한 도구를 활용할 수 있습니다.\n \n \nAIarty 소개\nAIarty 이미지 향상 프로그램은 Mac과 Windows에서 모두 사용할 수 있는 친환경 데스크탑 프로그램으로, 혁신적인 딥러닝 기술을 사용하여 이미지의 품질을 향상시키고 업스케일링하며, 세부 정보를 생성하는 데 최적화되어 있습니다.\n\n\n \n이 소프트웨어는 최대 32K(Windows) 또는 16K(Mac) 해상도로 이미지를 업스케일링할 수 있으며, 이를 통해 저해상도 이미지를 200%, 400%, 800%로 확대해도 고품질로 인쇄할 수 있습니다. 뿐만 아니라 2K, 4K, 8K의 고해상도 이미지를 제공하여 노이즈와 블러를 제거하고, 압축된 JPEG를 복원하는 기능도 포함되어 있습니다.\n \n이 소프트웨어는 이미지 품질을 크게 개선하여 잡음과 결함이 없는 선명한 이미지를 제공합니다. 특히 AIarty의 기술은 저품질, 저해상도 이미지나 AI가 생성한 이미지를 고화질의 예술 작품으로 변환하는 데 탁월한 성능을 발휘합니다. 사용자는 1K, 2K, 4K, 8K 해상도를 선택할 수 있으며, 최대 32K 이미지 품질을 제공하는 업스케일 기능도 포함되어 있어 큰 포맷의 출력물을 손쉽게 제작할 수 있습니다.\n\n\n \n 또한 이 프로그램은 이미지의 모서리를 선명하게 만들어주는 디블러 기능과, 노이즈를 제거하고 이미지를 재구성하여 더욱 깨끗한 결과물을 제공하는 디노이즈 기능을 제공합니다. AIarty는 세 가지 AI 모델을 사용하여 사진을 개선합니다. 첫 번째 모델은 이미지의 세부 정보를 더욱 뚜렷하게 하고, 두 번째 모델은 사진을 부드럽게 처리하여 결함을 제거하며, 세 번째 모델은 실제와 같은 세부 정보를 추가하여 이미지를 더 생동감 있게 만듭니다.\n\n\n\n \n \n \nAIarty 무료 1년 라이선스 취득 방법\nAIarty 이미지 향상 소프트웨어의 1년 무료 라이선스를 얻는 방법은 매우 간단합니다. 아래 단계를 따라 무료 라이선스를 취득해 보세요:\n공식 웹사이트 방문: 먼저 [ AIarty 공식 웹사이트 ]를 방문합니다. 웹사이트에서 해당 프로그램의 무료 1년 라이선스를 제공하는 페이지로 이동하세요.\n다운로드 및 설치: 사용 중인 운영 체제에 맞는 설치 파일을 다운로드합니다. Windows 사용자는 [ 여기 ]에서, Mac 사용자는[ 여기 ]에서 설치 파일을 다운로드할 수 있습니다. 다운로드가 완료되면 파일을 실행하여 프로그램을 설치합니다.\n라이선스 코드 입력: 프로그램 설치 및 실행 후, 이메일 주소와 함께 제공된 라이선스 코드를 입력합니다. Windows와 Mac 사용자에게 각각 다른 라이선스 코드가 제공되며, 이를 통해 프로그램을 활성화할 수 있습니다.\n\nWindows 라이선스 코드:\n\nFAN3I-ZJE5W-A4QRQ-JWEBH\nFA5OU-OQKNW-QPHTC-4VMGZ\nFAMU5-MJFVU-T3KAY-664VF\nMac 라이선스 코드:\n\nFBOIZ-JJRUD-6IEFN-KGZCR\nFBR6N-A75VN-PVIEO-CCSSU\nFB2HF-24TT5-U7YEB-5562Z\n프로그램 활성화: 라이선스 코드를 입력하고 \"Activate\" 버튼을 클릭하면 프로그램이 활성화됩니다. 이제 1년 동안 AIarty 이미지 향상 소프트웨어의 모든 기능을 무료로 이용할 수 있습니다.\n\n\n \n \n마치며\nAIarty 이미지 향상 소프트웨어는 매우 강력하면서도 사용하기 쉬운 사진 향상 도구로, 이미지 품질을 한 단계 끌어올리려는 모든 사용자에게 추천할 만한 프로그램입니다. 이 소프트웨어는 업스케일링, 노이즈 제거, 블러 개선뿐만 아니라 세부 정보를 추가하는 등 다양한 기능을 제공하여 이미지를 더욱 선명하고 생생하게 만듭니다. 지금 바로 무료 1년 라이선스를 통해 AIarty를 경험해 보세요.",
        "guid": "http://muzbox.tistory.com/483460",
        "categories": [
          "NEWS/윈도우10 한시적 무료앱",
          "ai 이미지 향상",
          "고해상도 업스케일링",
          "노이즈 제거",
          "딥러닝 이미지",
          "무료 라이선스",
          "무료 소프트웨어",
          "블러 제거",
          "사진 품질 개선"
        ],
        "isoDate": "2024-08-22T00:24:29.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "Google 계정으로 다른 사이트 가입을 하지 말아야 하는 이유",
        "link": "http://muzbox.tistory.com/483459",
        "pubDate": "Wed, 21 Aug 2024 08:36:38 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483459#entry483459comment",
        "content": "<p data-ke-size=\"size16\">Google 또는 Facebook을 통해 온라인 계정을 만드는 것이 편리할 수 있지만, 이는 보안과 프라이버시에 심각한 위험을 초래할 수 있습니다. 이 기사에서는 이러한 방법을 피해야 하는 이유와 대안을 제시합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"google.png\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/dhfTAd/btsI9cXQZx1/hoGlkBNLcCGD4Z8ui1g6PK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dhfTAd/btsI9cXQZx1/hoGlkBNLcCGD4Z8ui1g6PK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dhfTAd/btsI9cXQZx1/hoGlkBNLcCGD4Z8ui1g6PK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdhfTAd%2FbtsI9cXQZx1%2FhoGlkBNLcCGD4Z8ui1g6PK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"Google 계정으로 다른 사이트 가입을 하지 말아야 하는 이유\" data-filename=\"google.png\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;온라인 서비스를 사용할 때, Google 또는 Facebook 계정을 사용해 쉽게 로그인을 할 수 있는 옵션을 자주 보게 됩니다. 처음에는 이러한 기능이 시간을 절약하고 사용이 편리하게 느껴질 수 있지만, 그 이면에는 우리가 간과하기 쉬운 심각한 위험 요소가 숨어 있습니다. 특히, 보안과 프라이버시 측면에서 이 방법이 가지는 문제점을 이해하는 것이 중요합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b>SSO란 무엇인가?</b></h2>\n<p data-ke-size=\"size16\">SSO(싱글 사인온)는 한 번의 로그인으로 여러 서비스에 접근할 수 있게 해주는 기술입니다. 이 기술을 사용하면 Google 또는 Facebook 계정을 통해 다른 서비스에 가입할 때마다 별도의 로그인 정보를 입력할 필요 없이 자동으로 인증이 이루어집니다. 이는 매우 편리하게 보일 수 있습니다. 하지만 이 편리함은 커다란 대가를 요구합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b>SSO를 사용하지 말아야 하는 이유</b></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"로그인.png\" data-origin-width=\"1080\" data-origin-height=\"1080\"><span data-url=\"https://blog.kakaocdn.net/dn/c1VUDg/btsJaUnGYWa/2G67loBvtaFriGiHH5JBtk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/c1VUDg/btsJaUnGYWa/2G67loBvtaFriGiHH5JBtk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/c1VUDg/btsJaUnGYWa/2G67loBvtaFriGiHH5JBtk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc1VUDg%2FbtsJaUnGYWa%2F2G67loBvtaFriGiHH5JBtk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"SSO를 사용하지 말아야 하는 이유\" width=\"500\" height=\"500\" data-filename=\"로그인.png\" data-origin-width=\"1080\" data-origin-height=\"1080\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;SSO의 가장 큰 문제는 보안의 단일 실패 지점(single point of failure)을 만든다는 점입니다. 즉, 하나의 계정이 해킹당하면, 해당 계정을 통해 접속한 모든 서비스가 위험에 처할 수 있습니다. 예를 들어, Google 계정이 해킹되면 Google을 통해 로그인한 모든 계정에 대한 접근 권한이 해커에게 넘어갑니다. 이는 보안 측면에서 큰 위험 요소입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">또한, SSO를 사용하면 Google이나 Facebook 같은 거대 기술 기업에 당신의 계정 통제권을 넘기는 셈이 됩니다. 만약 Google이나 Facebook 계정이 잠기거나 문제가 발생하면, 다른 계정들에도 접근할 수 없게 되는 문제가 발생할 수 있습니다. 이는 단순한 불편을 넘어, 디지털 자산에 대한 심각한 손실을 초래할 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b>프라이버시 측면에서의 위험성</b></h2>\n<p data-ke-size=\"size16\">&nbsp;SSO를 사용하면 개인의 인터넷 활동을 거대 기술 기업들이 추적하고 관리할 수 있는 기회를 제공하게 됩니다. Google이나 Facebook은 이미 사용자 데이터를 광고 목적으로 수집하고 있으며, SSO를 통해 그들이 접근할 수 있는 데이터 범위는 더욱 확대됩니다. 이러한 이유로, 개인정보 보호에 민감한 사용자라면 SSO 사용을 재고해볼 필요가 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b>대안: 비밀번호 관리자 사용</b></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1024\" data-origin-height=\"1024\"><span data-url=\"https://blog.kakaocdn.net/dn/cXVqL6/btsI8Y6FyQa/q8PIsenyNwTrSmH2Ssnqo1/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/cXVqL6/btsI8Y6FyQa/q8PIsenyNwTrSmH2Ssnqo1/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/cXVqL6/btsI8Y6FyQa/q8PIsenyNwTrSmH2Ssnqo1/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcXVqL6%2FbtsI8Y6FyQa%2Fq8PIsenyNwTrSmH2Ssnqo1%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"비밀번호 관리자 사용\" width=\"500\" height=\"500\" data-origin-width=\"1024\" data-origin-height=\"1024\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;SSO의 편리함을 포기하기 어려운 사용자라면, 비밀번호 관리자를 사용하는 것이 좋은 대안이 될 수 있습니다. 비밀번호 관리자는 각 서비스마다 별도의 비밀번호를 안전하게 저장하고 자동으로 입력해주는 프로그램입니다. 이를 통해 SSO의 편리함을 그대로 유지하면서도 보안과 프라이버시 문제를 해결할 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b>결론</b></h2>\n<p data-ke-size=\"size16\">Google 또는 Facebook 계정으로 간편하게 로그인을 하는 것은 처음에는 매력적으로 보일 수 있습니다. 그러나 보안과 프라이버시의 측면에서 보면, 이는 커다란 위험을 동반합니다. 안전한 온라인 생활을 위해서는 비밀번호 관리자를 사용하는 것이 더 나은 선택일 수 있습니다.</p>",
        "contentSnippet": "Google 또는 Facebook을 통해 온라인 계정을 만드는 것이 편리할 수 있지만, 이는 보안과 프라이버시에 심각한 위험을 초래할 수 있습니다. 이 기사에서는 이러한 방법을 피해야 하는 이유와 대안을 제시합니다.\n\n\n \n 온라인 서비스를 사용할 때, Google 또는 Facebook 계정을 사용해 쉽게 로그인을 할 수 있는 옵션을 자주 보게 됩니다. 처음에는 이러한 기능이 시간을 절약하고 사용이 편리하게 느껴질 수 있지만, 그 이면에는 우리가 간과하기 쉬운 심각한 위험 요소가 숨어 있습니다. 특히, 보안과 프라이버시 측면에서 이 방법이 가지는 문제점을 이해하는 것이 중요합니다.\n \nSSO란 무엇인가?\nSSO(싱글 사인온)는 한 번의 로그인으로 여러 서비스에 접근할 수 있게 해주는 기술입니다. 이 기술을 사용하면 Google 또는 Facebook 계정을 통해 다른 서비스에 가입할 때마다 별도의 로그인 정보를 입력할 필요 없이 자동으로 인증이 이루어집니다. 이는 매우 편리하게 보일 수 있습니다. 하지만 이 편리함은 커다란 대가를 요구합니다.\n \n \nSSO를 사용하지 말아야 하는 이유\n\n\n \n SSO의 가장 큰 문제는 보안의 단일 실패 지점(single point of failure)을 만든다는 점입니다. 즉, 하나의 계정이 해킹당하면, 해당 계정을 통해 접속한 모든 서비스가 위험에 처할 수 있습니다. 예를 들어, Google 계정이 해킹되면 Google을 통해 로그인한 모든 계정에 대한 접근 권한이 해커에게 넘어갑니다. 이는 보안 측면에서 큰 위험 요소입니다.\n \n또한, SSO를 사용하면 Google이나 Facebook 같은 거대 기술 기업에 당신의 계정 통제권을 넘기는 셈이 됩니다. 만약 Google이나 Facebook 계정이 잠기거나 문제가 발생하면, 다른 계정들에도 접근할 수 없게 되는 문제가 발생할 수 있습니다. 이는 단순한 불편을 넘어, 디지털 자산에 대한 심각한 손실을 초래할 수 있습니다.\n \n \n \n프라이버시 측면에서의 위험성\n SSO를 사용하면 개인의 인터넷 활동을 거대 기술 기업들이 추적하고 관리할 수 있는 기회를 제공하게 됩니다. Google이나 Facebook은 이미 사용자 데이터를 광고 목적으로 수집하고 있으며, SSO를 통해 그들이 접근할 수 있는 데이터 범위는 더욱 확대됩니다. 이러한 이유로, 개인정보 보호에 민감한 사용자라면 SSO 사용을 재고해볼 필요가 있습니다.\n \n \n대안: 비밀번호 관리자 사용\n\n\n \n SSO의 편리함을 포기하기 어려운 사용자라면, 비밀번호 관리자를 사용하는 것이 좋은 대안이 될 수 있습니다. 비밀번호 관리자는 각 서비스마다 별도의 비밀번호를 안전하게 저장하고 자동으로 입력해주는 프로그램입니다. 이를 통해 SSO의 편리함을 그대로 유지하면서도 보안과 프라이버시 문제를 해결할 수 있습니다.\n \n \n결론\nGoogle 또는 Facebook 계정으로 간편하게 로그인을 하는 것은 처음에는 매력적으로 보일 수 있습니다. 그러나 보안과 프라이버시의 측면에서 보면, 이는 커다란 위험을 동반합니다. 안전한 온라인 생활을 위해서는 비밀번호 관리자를 사용하는 것이 더 나은 선택일 수 있습니다.",
        "guid": "http://muzbox.tistory.com/483459",
        "categories": [
          "Google 이야기/구글 뉴스",
          "facebook 로그인",
          "google 로그인",
          "SSO",
          "계정 해킹",
          "데이터 추적",
          "비밀번호 관리자",
          "온라인 보안",
          "프라이버시 보호"
        ],
        "isoDate": "2024-08-20T23:36:38.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "안드로이드 추천 앱, 추천 어플 (24.8.19) 뉴스, 채팅앱, ai캐릭터, 캐릭터만들기,수학 학습 앱, 고프로, 사진동영상편집",
        "link": "http://muzbox.tistory.com/483458",
        "pubDate": "Mon, 19 Aug 2024 10:31:38 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483458#entry483458comment",
        "content": "<p data-ke-size=\"size16\">구글플레이 스토어에 등록된 유용한 앱 5개를 소개합니다. 새로운 기능, 사용자 경험 향상을 위한 앱들을 발견하고, 일상생활을 더욱 편리하게 만들어 줄 최고의 앱들을 찾아보세요.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"안드로이드추천앱.png\" data-origin-width=\"500\" data-origin-height=\"500\"><span data-url=\"https://blog.kakaocdn.net/dn/S9Iad/btsI7Gqizln/lDW7Yi1KwngL8X1jTuTzh0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/S9Iad/btsI7Gqizln/lDW7Yi1KwngL8X1jTuTzh0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/S9Iad/btsI7Gqizln/lDW7Yi1KwngL8X1jTuTzh0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FS9Iad%2FbtsI7Gqizln%2FlDW7Yi1KwngL8X1jTuTzh0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"안드로이드 추천 앱, 추천 어플\" data-filename=\"안드로이드추천앱.png\" data-origin-width=\"500\" data-origin-height=\"500\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h1><b>안드로이드 앱 추천 배경</b></h1>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;안드로이드 앱스토어인 구글 플레이 스토어에는 <span style=\"color: #ee2323;\"><b>하루에도 엄청난 수의 앱과 게임이 신규로 등록</b></span>됩니다. 이 모든앱들을 사용자가 확인하고 양질의 앱을 선택하는 것이 사실상 불가능 하다는 얘기죠.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">또한, 최근들어 강화되었다 하지만 여전히 구글 플레이스토어에는 <span style=\"color: #ee2323;\"><b>유해한 앱들이 사라지지 않고 이들 앱으로 피해</b></span>를 보는 사용자도 많습니다. 본 블로그에서는 일주일에 한 번정도 <b><span style=\"color: #006dd7;\">운영자가 직접 유용하고 편리한 앱을 엄선하여 소개</span></b>합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<blockquote data-ke-style=\"style1\">\n<p data-ke-size=\"size16\"><b>'어떤오후의 프리웨어 이야기'에서 추천하는 2024년 8월 19일자 '안드로이드 추천 앱'입니다.<br /></b></p>\n</blockquote>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>1. 금일 뉴스</b></span></h2>\n<p data-ke-size=\"size16\">다양한 주제에 대한 최신 뉴스를 제공하는 종합적인 뉴스 플랫폼입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 앱은 사용자 친화적인 인터페이스를 통해 전 세계의 신뢰할 수 있는 소스에서 선별된 기사에 쉽게 접근할 수 있게 해줍니다.주요 기능으로는 실시간 로컬 뉴스 업데이트, 국제 뉴스, 날씨 알림 등이 있으며, 사용자의 위치를 기반으로 한 맞춤형 정보를 제공합니다. 뉴스 투데이는 개인화 기능을 통해 사용자가 선호하는 카테고리, 주제, 소스를 선택하여 맞춤형 뉴스 피드를 구성할 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">또한 빠른 알림 시스템을 통해 급속한 뉴스에 대한 실시간 알림을 받을 수 있어, 최신 정보를 놓치지 않고 받아볼 수 있습니다. 이 앱은 사용자 친화적인 인터페이스와 개인화된 기능으로 뉴스 애호가와 일반 독자 모두에게 적합한 필수적인 뉴스 플랫폼입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"금일 뉴스.jpg\" data-origin-width=\"981\" data-origin-height=\"1737\"><span data-url=\"https://blog.kakaocdn.net/dn/b9rRhN/btsI8mLxC56/v0iXF0amrHYkJLSGYLOpz0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/b9rRhN/btsI8mLxC56/v0iXF0amrHYkJLSGYLOpz0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/b9rRhN/btsI8mLxC56/v0iXF0amrHYkJLSGYLOpz0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb9rRhN%2FbtsI8mLxC56%2Fv0iXF0amrHYkJLSGYLOpz0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"안드로이드 추천앱 금일 뉴스\" width=\"760\" height=\"1346\" data-filename=\"금일 뉴스.jpg\" data-origin-width=\"981\" data-origin-height=\"1737\"/></span></figure>\n</p>\n<figure id=\"og_1724030790913\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"금일 뉴스 - Google Play 앱\" data-og-description=\"뉴스 투데이에서 맞춤형 일일, 지역 및 급속한 뉴스 업데이트를 받아보고 정보를 유지하세요.\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.newsvison.android.newstoday\" data-og-url=\"https://play.google.com/store/apps/details?id=com.newsvison.android.newstoday&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/ozQY9/hyWSoorM65/eef8fGWxBegKDlDLBrQwm0/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/Mxiem/hyWOdhSuoc/7oAR8UL5XVftqwTcMgKnJK/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/dLlP9B/hyWOeueMVT/DrXzjUKCSLscKBYoiMdCxK/img.png?width=240&amp;height=240&amp;face=0_0_240_240\"><a href=\"https://play.google.com/store/apps/details?id=com.newsvison.android.newstoday\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.newsvison.android.newstoday\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/ozQY9/hyWSoorM65/eef8fGWxBegKDlDLBrQwm0/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/Mxiem/hyWOdhSuoc/7oAR8UL5XVftqwTcMgKnJK/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/dLlP9B/hyWOeueMVT/DrXzjUKCSLscKBYoiMdCxK/img.png?width=240&amp;height=240&amp;face=0_0_240_240');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">금일 뉴스 - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">뉴스 투데이에서 맞춤형 일일, 지역 및 급속한 뉴스 업데이트를 받아보고 정보를 유지하세요.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>2. Threads</b></span></h2>\n<p data-ke-size=\"size16\">&nbsp;Instagram의 텍스트 기반 대화 앱으로, 다양한 주제에 대해 의견을 나누고 소통할 수 있는 플랫폼입니다.<br />사용자는 Instagram 계정으로 로그인하여 기존 팔로워를 유지하고 새로운 계정을 탐색할 수 있습니다.</p>\n<p data-ke-size=\"size16\">앱의 주요 기능으로는 새로운 스레드 작성, 토론 참여, 아이디어 발견, 실시간 이벤트 및 트렌드 확인 등이 있습니다.</p>\n<p data-ke-size=\"size16\"><br />Threads는 사용자가 관심사를 공유하는 사람들과 소통하고, 다양한 주제에 대한 인사이트를 얻을 수 있는 공간을 제공합니다. 앱은 개인화된 설정과 관리 기능을 통해 사용자가 원하는 대로 대화를 조절할 수 있게 해줍니다.</p>\n<p data-ke-size=\"size16\"><br />Threads는 Instagram의 커뮤니티 가이드라인을 따르며, 안전하고 진정성 있는 교류를 위한 환경을 제공합니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Threads.jpg\" data-origin-width=\"981\" data-origin-height=\"1737\"><span data-url=\"https://blog.kakaocdn.net/dn/byS1Ay/btsI6SLS7Q4/f78IgSlJ1bXoTAfjuHqHOK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/byS1Ay/btsI6SLS7Q4/f78IgSlJ1bXoTAfjuHqHOK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/byS1Ay/btsI6SLS7Q4/f78IgSlJ1bXoTAfjuHqHOK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbyS1Ay%2FbtsI6SLS7Q4%2Ff78IgSlJ1bXoTAfjuHqHOK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"안드로이드 추천앱 Threads\" width=\"760\" height=\"1346\" data-filename=\"Threads.jpg\" data-origin-width=\"981\" data-origin-height=\"1737\"/></span></figure>\n</p>\n<figure id=\"og_1724030813717\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Threads - Google Play 앱\" data-og-description=\"텍스트로 아이디어와 트렌드를 공유하세요\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.instagram.barcelona\" data-og-url=\"https://play.google.com/store/apps/details?id=com.instagram.barcelona&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/oxqwt/hyWSmqCH2v/IJVdAQjo1bs9fqYHyBRpm1/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/g06BK/hyWSeMT9Kc/kxiNqL820we6nR4OEwlxpk/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/eSqwCu/hyWShCRwgO/j7V6a0ZsuOSKkIdsnqu9Sk/img.png?width=240&amp;height=240&amp;face=0_0_240_240\"><a href=\"https://play.google.com/store/apps/details?id=com.instagram.barcelona\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.instagram.barcelona\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/oxqwt/hyWSmqCH2v/IJVdAQjo1bs9fqYHyBRpm1/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/g06BK/hyWSeMT9Kc/kxiNqL820we6nR4OEwlxpk/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/eSqwCu/hyWShCRwgO/j7V6a0ZsuOSKkIdsnqu9Sk/img.png?width=240&amp;height=240&amp;face=0_0_240_240');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Threads - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">텍스트로 아이디어와 트렌드를 공유하세요</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>3. Character AI: Chat, Talk, Text</b></span></h2>\n<p data-ke-size=\"size16\">&nbsp;매우&nbsp;지능적이고&nbsp;실제와&nbsp;같은&nbsp;채팅&nbsp;봇&nbsp;캐릭터와&nbsp;대화할&nbsp;수&nbsp;있는&nbsp;플랫폼입니다.</p>\n<p data-ke-size=\"size16\"><br />이 앱은 수백만 개의 사용자 생성 캐릭터와 음성 라이브러리를 제공하며, 사용자는 자신만의 캐릭터와 음성을 만들 수도 있습니다. AI Chat은 통화나 문자 메시지를 통해 인간과 유사한 상호작용을 제공하며, 사용자의 필요에 맞는 맞춤형 지원을 제공합니다.이&nbsp;플랫폼은&nbsp;학습&nbsp;지원부터&nbsp;창의적인&nbsp;작업,&nbsp;엔터테인먼트까지&nbsp;다양한&nbsp;용도로&nbsp;활용될&nbsp;수&nbsp;있습니다.</p>\n<p data-ke-size=\"size16\"><br />AI Chat은 무료로 제공되며, 광고 없이 무제한 메시지와 통화를 즐길 수 있습니다.이&nbsp;혁신적인&nbsp;기술은&nbsp;사용자의&nbsp;상상력을&nbsp;유일한&nbsp;한계로&nbsp;두고&nbsp;있으며,&nbsp;Character.AI&nbsp;커뮤니티를&nbsp;통해&nbsp;다양한&nbsp;작품을&nbsp;공유할&nbsp;수&nbsp;있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Character AI.jpg\" data-origin-width=\"981\" data-origin-height=\"1737\"><span data-url=\"https://blog.kakaocdn.net/dn/lDlj3/btsI8obqXB6/ZAdlb3SpgiW5KGKERs42sK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/lDlj3/btsI8obqXB6/ZAdlb3SpgiW5KGKERs42sK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/lDlj3/btsI8obqXB6/ZAdlb3SpgiW5KGKERs42sK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FlDlj3%2FbtsI8obqXB6%2FZAdlb3SpgiW5KGKERs42sK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"안드로이드 추천앱 Character AI: Chat, Talk, Text\" width=\"760\" height=\"1346\" data-filename=\"Character AI.jpg\" data-origin-width=\"981\" data-origin-height=\"1737\"/></span></figure>\n</p>\n<figure id=\"og_1724030825205\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Character AI: Chat, Talk, Text - Google Play 앱\" data-og-description=\"당신의 말을 듣고, 이해하고, 기억하는 초지능 AI 채팅봇.\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=ai.character.app\" data-og-url=\"https://play.google.com/store/apps/details?id=ai.character.app&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/coiCDZ/hyWSesA80O/zEMyC6eKAQieXq9jOfC1F1/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/Gsbg3/hyWSiIw3ZR/Xsg7ycXSeY1juUSziyrMY1/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/bmnWGP/hyWR9Y8ok7/AJ4Yzynj4oJ8uUtGHy8Lf0/img.png?width=240&amp;height=240&amp;face=0_0_240_240\"><a href=\"https://play.google.com/store/apps/details?id=ai.character.app\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=ai.character.app\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/coiCDZ/hyWSesA80O/zEMyC6eKAQieXq9jOfC1F1/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/Gsbg3/hyWSiIw3ZR/Xsg7ycXSeY1juUSziyrMY1/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/bmnWGP/hyWR9Y8ok7/AJ4Yzynj4oJ8uUtGHy8Lf0/img.png?width=240&amp;height=240&amp;face=0_0_240_240');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Character AI: Chat, Talk, Text - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">당신의 말을 듣고, 이해하고, 기억하는 초지능 AI 채팅봇.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><b><span style=\"color: #009a87;\">4. Microsoft&nbsp;Math&nbsp;Solver</span></b></h2>\n<p data-ke-size=\"size16\">&nbsp;Microsoft에서&nbsp;제공하는&nbsp;100%&nbsp;무료&nbsp;수학&nbsp;학습&nbsp;앱으로,&nbsp;모든&nbsp;연령과&nbsp;능력&nbsp;수준의&nbsp;사용자를&nbsp;위해&nbsp;설계되었습니다. <br />이&nbsp;앱은&nbsp;카메라&nbsp;스캔,&nbsp;손글씨&nbsp;입력,&nbsp;계산기&nbsp;기능&nbsp;등&nbsp;다양한&nbsp;방식으로&nbsp;수학&nbsp;문제를&nbsp;입력할&nbsp;수&nbsp;있게&nbsp;해줍니다.</p>\n<p data-ke-size=\"size16\"><br />Math&nbsp;Solver는&nbsp;단계별&nbsp;설명,&nbsp;대화형&nbsp;그래프,&nbsp;유사&nbsp;문제&nbsp;제공&nbsp;등을&nbsp;통해&nbsp;즉각적인&nbsp;문제&nbsp;해결&nbsp;지원을&nbsp;제공합니다. <br />기초&nbsp;산술부터&nbsp;고급&nbsp;대수,&nbsp;미적분까지&nbsp;광범위한&nbsp;수학&nbsp;주제를&nbsp;다루며,&nbsp;다양한&nbsp;언어로&nbsp;제공됩니다.</p>\n<p data-ke-size=\"size16\"><br />앱은&nbsp;또한&nbsp;일일&nbsp;퀴즈,&nbsp;게임,&nbsp;비디오&nbsp;강의&nbsp;등&nbsp;추가적인&nbsp;학습&nbsp;자료를&nbsp;제공하여&nbsp;사용자의&nbsp;지속적인&nbsp;학습을&nbsp;돕습니다. <br />Math&nbsp;Solver는&nbsp;사용자&nbsp;친화적인&nbsp;인터페이스와&nbsp;다양한&nbsp;기능을&nbsp;통해&nbsp;수학&nbsp;학습을&nbsp;쉽고&nbsp;재미있게&nbsp;만들어주는&nbsp;종합적인&nbsp;수학&nbsp;도구입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"Microsoft Math Solver.jpg\" data-origin-width=\"981\" data-origin-height=\"1737\"><span data-url=\"https://blog.kakaocdn.net/dn/cIZW7C/btsI7Nv30S6/Mi3ijcNHBwlpC1dDuaW2r0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cIZW7C/btsI7Nv30S6/Mi3ijcNHBwlpC1dDuaW2r0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cIZW7C/btsI7Nv30S6/Mi3ijcNHBwlpC1dDuaW2r0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcIZW7C%2FbtsI7Nv30S6%2FMi3ijcNHBwlpC1dDuaW2r0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"안드로이드 추천앱 Microsoft Math Solver\" width=\"760\" height=\"1346\" data-filename=\"Microsoft Math Solver.jpg\" data-origin-width=\"981\" data-origin-height=\"1737\"/></span></figure>\n</p>\n<figure id=\"og_1724030832979\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"Microsoft Math Solver - Google Play 앱\" data-og-description=\"수학 문제를 작성하거나 스캔하여 자세한 단계별 설명과 그래프를 확인하세요.\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.microsoft.math\" data-og-url=\"https://play.google.com/store/apps/details?id=com.microsoft.math&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/diQAUL/hyWR9x2JEJ/H0cQl8iyeQ0dA7Y0BGkZj1/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/bJnzfh/hyWShQo2q7/3GLBlQ9dX7C20PVlUCkNZ1/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/bHXmyk/hyWOkBdst6/jFdmG76kFO3ATkynKgOrVK/img.png?width=240&amp;height=240&amp;face=0_0_240_240\"><a href=\"https://play.google.com/store/apps/details?id=com.microsoft.math\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.microsoft.math\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/diQAUL/hyWR9x2JEJ/H0cQl8iyeQ0dA7Y0BGkZj1/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/bJnzfh/hyWShQo2q7/3GLBlQ9dX7C20PVlUCkNZ1/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/bHXmyk/hyWOkBdst6/jFdmG76kFO3ATkynKgOrVK/img.png?width=240&amp;height=240&amp;face=0_0_240_240');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">Microsoft Math Solver - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">수학 문제를 작성하거나 스캔하여 자세한 단계별 설명과 그래프를 확인하세요.</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\"><span style=\"color: #009a87;\"><b>5. GoPro&nbsp;Quik&nbsp;:&nbsp;사진편집&nbsp;+&nbsp;동영상&nbsp;편집</b></span></h2>\n<p data-ke-size=\"size16\">&nbsp;GoPro에서 제공하는 다기능 동영상 편집 및 관리 앱입니다.주요 기능으로는 자동 편집, 하이라이트 동영상 자동 전송, 무제한 클라우드 백업 등이 있습니다.</p>\n<p data-ke-size=\"size16\"><br />앱은&nbsp;사용자의&nbsp;모든&nbsp;사진과&nbsp;동영상을&nbsp;한&nbsp;곳에&nbsp;모아주는&nbsp;'Mural'&nbsp;기능을&nbsp;제공하며,&nbsp;강력한&nbsp;편집&nbsp;도구를&nbsp;통해&nbsp;사용자&nbsp;맞춤형&nbsp;동영상&nbsp;제작이&nbsp;가능합니다.</p>\n<p data-ke-size=\"size16\"><br />GoPro&nbsp;카메라&nbsp;사용자를&nbsp;위해&nbsp;원격&nbsp;제어,&nbsp;라이브&nbsp;스트리밍,&nbsp;펌웨어&nbsp;업데이트&nbsp;등의&nbsp;추가&nbsp;기능을&nbsp;제공합니다. <br />Quik은&nbsp;구독&nbsp;서비스를&nbsp;통해&nbsp;더&nbsp;많은&nbsp;기능을&nbsp;제공하며,&nbsp;Wi-Fi&nbsp;연결이&nbsp;필요한&nbsp;기능들이&nbsp;있습니다. <br />앱은&nbsp;소셜&nbsp;미디어&nbsp;공유&nbsp;기능을&nbsp;제공하여&nbsp;편집한&nbsp;콘텐츠를&nbsp;쉽게&nbsp;공유할&nbsp;수&nbsp;있게&nbsp;해줍니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"GoPro Quik.jpg\" data-origin-width=\"981\" data-origin-height=\"1737\"><span data-url=\"https://blog.kakaocdn.net/dn/dO0BqS/btsI8hcy2qW/rwKzX7i6ZZhDZBA7Yk4MeK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/dO0BqS/btsI8hcy2qW/rwKzX7i6ZZhDZBA7Yk4MeK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/dO0BqS/btsI8hcy2qW/rwKzX7i6ZZhDZBA7Yk4MeK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdO0BqS%2FbtsI8hcy2qW%2FrwKzX7i6ZZhDZBA7Yk4MeK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"안드로이드 추천앱 GoPro Quik : 사진편집 + 동영상 편집\" width=\"760\" height=\"1346\" data-filename=\"GoPro Quik.jpg\" data-origin-width=\"981\" data-origin-height=\"1737\"/></span></figure>\n</p>\n<figure id=\"og_1724030842002\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"GoPro Quik : 사진편집 + 동영상 편집 - Google Play 앱\" data-og-description=\"GoPro,영상 편집,영상,스톱모션,비디오,편집기,동영상편집,video editor,video,동영상 배속,gopro app,비디오편집,편집어플\" data-og-host=\"play.google.com\" data-og-source-url=\"https://play.google.com/store/apps/details?id=com.gopro.smarty\" data-og-url=\"https://play.google.com/store/apps/details?id=com.gopro.smarty&amp;hl=ko\" data-og-image=\"https://scrap.kakaocdn.net/dn/Drbok/hyWSj8uXls/sCMjNKpo1zmemMSWN8mVq1/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/1izCw/hyWSkGmfu5/2Jix8MmkkKiPak2PVxVgx1/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/c6YIv7/hyWOe8RQuC/9yqvQHCiOzo7PRbak9NNSk/img.png?width=240&amp;height=240&amp;face=0_0_240_240\"><a href=\"https://play.google.com/store/apps/details?id=com.gopro.smarty\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://play.google.com/store/apps/details?id=com.gopro.smarty\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/Drbok/hyWSj8uXls/sCMjNKpo1zmemMSWN8mVq1/img.png?width=512&amp;height=512&amp;face=0_0_512_512,https://scrap.kakaocdn.net/dn/1izCw/hyWSkGmfu5/2Jix8MmkkKiPak2PVxVgx1/img.png?width=600&amp;height=300&amp;face=0_0_600_300,https://scrap.kakaocdn.net/dn/c6YIv7/hyWOe8RQuC/9yqvQHCiOzo7PRbak9NNSk/img.png?width=240&amp;height=240&amp;face=0_0_240_240');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">GoPro Quik : 사진편집 + 동영상 편집 - Google Play 앱</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">GoPro,영상 편집,영상,스톱모션,비디오,편집기,동영상편집,video editor,video,동영상 배속,gopro app,비디오편집,편집어플</p>\n<p class=\"og-host\" data-ke-size=\"size16\">play.google.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h3 data-ke-size=\"size23\"><span style=\"color: #006dd7;\"><b>마치며</b></span></h3>\n<p data-ke-size=\"size16\">&nbsp;이번 주 안드로이드 추천 앱들을 살펴보았습니다. 뉴스, 소셜 미디어, AI 채팅, 교육, 그리고 멀티미디어 편집까지 다양한 분야의 앱들이 소개되었습니다. 이 앱들은 각자의 분야에서 뛰어난 기능과 사용자 경험을 제공하며, 우리의 일상을 더욱 풍요롭고 효율적으로 만들어줄 것입니다. 여러분의 필요와 관심사에 맞는 앱을 선택하여 스마트폰 활용도를 한층 높여보시기 바랍니다. 다음에도 새롭고 유용한 앱들로 찾아뵙겠습니다. &lt;어떤오후&gt;</p>",
        "contentSnippet": "구글플레이 스토어에 등록된 유용한 앱 5개를 소개합니다. 새로운 기능, 사용자 경험 향상을 위한 앱들을 발견하고, 일상생활을 더욱 편리하게 만들어 줄 최고의 앱들을 찾아보세요.\n \n\n\n \n안드로이드 앱 추천 배경\n \n 안드로이드 앱스토어인 구글 플레이 스토어에는 하루에도 엄청난 수의 앱과 게임이 신규로 등록됩니다. 이 모든앱들을 사용자가 확인하고 양질의 앱을 선택하는 것이 사실상 불가능 하다는 얘기죠.\n \n또한, 최근들어 강화되었다 하지만 여전히 구글 플레이스토어에는 유해한 앱들이 사라지지 않고 이들 앱으로 피해를 보는 사용자도 많습니다. 본 블로그에서는 일주일에 한 번정도 운영자가 직접 유용하고 편리한 앱을 엄선하여 소개합니다.\n \n'어떤오후의 프리웨어 이야기'에서 추천하는 2024년 8월 19일자 '안드로이드 추천 앱'입니다.\n\n \n \n1. 금일 뉴스\n다양한 주제에 대한 최신 뉴스를 제공하는 종합적인 뉴스 플랫폼입니다.\n \n이 앱은 사용자 친화적인 인터페이스를 통해 전 세계의 신뢰할 수 있는 소스에서 선별된 기사에 쉽게 접근할 수 있게 해줍니다.주요 기능으로는 실시간 로컬 뉴스 업데이트, 국제 뉴스, 날씨 알림 등이 있으며, 사용자의 위치를 기반으로 한 맞춤형 정보를 제공합니다. 뉴스 투데이는 개인화 기능을 통해 사용자가 선호하는 카테고리, 주제, 소스를 선택하여 맞춤형 뉴스 피드를 구성할 수 있습니다.\n \n또한 빠른 알림 시스템을 통해 급속한 뉴스에 대한 실시간 알림을 받을 수 있어, 최신 정보를 놓치지 않고 받아볼 수 있습니다. 이 앱은 사용자 친화적인 인터페이스와 개인화된 기능으로 뉴스 애호가와 일반 독자 모두에게 적합한 필수적인 뉴스 플랫폼입니다.\n\n\n\n \n금일 뉴스 - Google Play 앱\n뉴스 투데이에서 맞춤형 일일, 지역 및 급속한 뉴스 업데이트를 받아보고 정보를 유지하세요.\nplay.google.com\n\n \n \n \n2. Threads\n Instagram의 텍스트 기반 대화 앱으로, 다양한 주제에 대해 의견을 나누고 소통할 수 있는 플랫폼입니다.\n사용자는 Instagram 계정으로 로그인하여 기존 팔로워를 유지하고 새로운 계정을 탐색할 수 있습니다.\n앱의 주요 기능으로는 새로운 스레드 작성, 토론 참여, 아이디어 발견, 실시간 이벤트 및 트렌드 확인 등이 있습니다.\nThreads는 사용자가 관심사를 공유하는 사람들과 소통하고, 다양한 주제에 대한 인사이트를 얻을 수 있는 공간을 제공합니다. 앱은 개인화된 설정과 관리 기능을 통해 사용자가 원하는 대로 대화를 조절할 수 있게 해줍니다.\nThreads는 Instagram의 커뮤니티 가이드라인을 따르며, 안전하고 진정성 있는 교류를 위한 환경을 제공합니다.\n\n\n\n \nThreads - Google Play 앱\n텍스트로 아이디어와 트렌드를 공유하세요\nplay.google.com\n\n \n \n \n3. Character AI: Chat, Talk, Text\n 매우 지능적이고 실제와 같은 채팅 봇 캐릭터와 대화할 수 있는 플랫폼입니다.\n이 앱은 수백만 개의 사용자 생성 캐릭터와 음성 라이브러리를 제공하며, 사용자는 자신만의 캐릭터와 음성을 만들 수도 있습니다. AI Chat은 통화나 문자 메시지를 통해 인간과 유사한 상호작용을 제공하며, 사용자의 필요에 맞는 맞춤형 지원을 제공합니다.이 플랫폼은 학습 지원부터 창의적인 작업, 엔터테인먼트까지 다양한 용도로 활용될 수 있습니다.\nAI Chat은 무료로 제공되며, 광고 없이 무제한 메시지와 통화를 즐길 수 있습니다.이 혁신적인 기술은 사용자의 상상력을 유일한 한계로 두고 있으며, Character.AI 커뮤니티를 통해 다양한 작품을 공유할 수 있습니다.\n\n\n\n \nCharacter AI: Chat, Talk, Text - Google Play 앱\n당신의 말을 듣고, 이해하고, 기억하는 초지능 AI 채팅봇.\nplay.google.com\n\n \n \n \n4. Microsoft Math Solver\n Microsoft에서 제공하는 100% 무료 수학 학습 앱으로, 모든 연령과 능력 수준의 사용자를 위해 설계되었습니다. \n이 앱은 카메라 스캔, 손글씨 입력, 계산기 기능 등 다양한 방식으로 수학 문제를 입력할 수 있게 해줍니다.\nMath Solver는 단계별 설명, 대화형 그래프, 유사 문제 제공 등을 통해 즉각적인 문제 해결 지원을 제공합니다. \n기초 산술부터 고급 대수, 미적분까지 광범위한 수학 주제를 다루며, 다양한 언어로 제공됩니다.\n앱은 또한 일일 퀴즈, 게임, 비디오 강의 등 추가적인 학습 자료를 제공하여 사용자의 지속적인 학습을 돕습니다. \nMath Solver는 사용자 친화적인 인터페이스와 다양한 기능을 통해 수학 학습을 쉽고 재미있게 만들어주는 종합적인 수학 도구입니다.\n\n\n\n \nMicrosoft Math Solver - Google Play 앱\n수학 문제를 작성하거나 스캔하여 자세한 단계별 설명과 그래프를 확인하세요.\nplay.google.com\n\n \n \n \n5. GoPro Quik : 사진편집 + 동영상 편집\n GoPro에서 제공하는 다기능 동영상 편집 및 관리 앱입니다.주요 기능으로는 자동 편집, 하이라이트 동영상 자동 전송, 무제한 클라우드 백업 등이 있습니다.\n앱은 사용자의 모든 사진과 동영상을 한 곳에 모아주는 'Mural' 기능을 제공하며, 강력한 편집 도구를 통해 사용자 맞춤형 동영상 제작이 가능합니다.\nGoPro 카메라 사용자를 위해 원격 제어, 라이브 스트리밍, 펌웨어 업데이트 등의 추가 기능을 제공합니다. \nQuik은 구독 서비스를 통해 더 많은 기능을 제공하며, Wi-Fi 연결이 필요한 기능들이 있습니다. \n앱은 소셜 미디어 공유 기능을 제공하여 편집한 콘텐츠를 쉽게 공유할 수 있게 해줍니다.\n\n\n\n \nGoPro Quik : 사진편집 + 동영상 편집 - Google Play 앱\nGoPro,영상 편집,영상,스톱모션,비디오,편집기,동영상편집,video editor,video,동영상 배속,gopro app,비디오편집,편집어플\nplay.google.com\n\n \n \n \n마치며\n 이번 주 안드로이드 추천 앱들을 살펴보았습니다. 뉴스, 소셜 미디어, AI 채팅, 교육, 그리고 멀티미디어 편집까지 다양한 분야의 앱들이 소개되었습니다. 이 앱들은 각자의 분야에서 뛰어난 기능과 사용자 경험을 제공하며, 우리의 일상을 더욱 풍요롭고 효율적으로 만들어줄 것입니다. 여러분의 필요와 관심사에 맞는 앱을 선택하여 스마트폰 활용도를 한층 높여보시기 바랍니다. 다음에도 새롭고 유용한 앱들로 찾아뵙겠습니다. <어떤오후>",
        "guid": "http://muzbox.tistory.com/483458",
        "categories": [
          "ANDROID &amp; 모바일/추천 무료 앱",
          "AI캐릭터",
          "고프로",
          "뉴스",
          "무료앱",
          "사진동영상편집",
          "수학 학습 앱",
          "안드로이드추천앱",
          "채팅앱",
          "추천앱",
          "캐릭터만들기"
        ],
        "isoDate": "2024-08-19T01:31:38.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "｜RULIWEB｜",
        "title": "[게임툰] 아키하바라 물담배 액션, 후카 헤이즈",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2241",
        "pubDate": "Mon, 19 Aug 2024 15:57:50 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i1.ruliweb.com/thumb/24/08/19/191696d499851ad6b.png\">",
        "contentSnippet": "",
        "categories": [
          "게임툰"
        ],
        "isoDate": "2024-08-19T06:57:50.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "khris'log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": [
      {
        "title": "GitHub Copilot 통합으로 향상된 \"Visual Studio 2022 버전 17.10\"의 Git 도구 기능",
        "link": "https://jacking75.github.io/tech-ai_20240822/",
        "pubDate": "Thu, 22 Aug 2024 00:00:00 +0900",
        "content": "<iframe width=\"1024\" height=\"1024\" src=\"https://docs.google.com/document/d/e/2PACX-1vQxAH2MgY6UHmBNwjep5Q4AAf82MNhrFR_3yI-ShVy_mtsrpMMXd25YLuobBWV52JNbZopoo_wpGy76/pub?embedded=true\"></iframe>\n\n",
        "contentSnippet": "",
        "guid": "https://jacking75.github.io/tech-ai_20240822/",
        "isoDate": "2024-08-21T15:00:00.000Z"
      }
    ]
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": [
      {
        "title": "데이터 분석가 로드맵(프로덕트 분석가)을 만들며 했던 생각들",
        "link": "https://zzsza.github.io/diary/2024/08/21/product-analyst-roadmap/",
        "pubDate": "Wed, 21 Aug 2024 00:00:00 +0000",
        "content": "<ul>\n  <li>와 올해 블로그에 쓴 글이 0개였다니.. 충격적이네요. 의식하면서 글을 써보도록 할게요</li>\n  <li>이번 글은 인프런에 프로덕트 분석가 로드맵을 작성한 내용에 대해 공유해볼게요</li>\n  <li>강의 만드는 과정의 노하우 공유는 예전에 작성한 <a href=\"https://zzsza.github.io/diary/2023/07/13/how-to-make-a-lecture/\">인프런에서 강의 만들기</a> 글에 있어요</li>\n</ul>\n\n<hr />\n\n<h1 id=\"프로덕트-분석가-로드맵-제작\">프로덕트 분석가 로드맵 제작</h1>\n<ul>\n  <li><a href=\"https://www.inflearn.com/roadmaps/4639\">인프런 로드맵</a>을 만들었어요. 제가 퇴사하고 만든 강의들을 모아둔 내용입니다</li>\n</ul>\n\n<p><img src=\"https://capture.dropbox.com/37KrIVW1YEPIkOzd?raw=1\" /></p>\n\n<h2 id=\"왜-프로덕트-분석가인가\">왜 프로덕트 분석가인가?</h2>\n<ul>\n  <li>데이터 직무로 처음 일했던 회사에서 했던 일을 돌이켜보면 앱 로그 데이터 분석을 많이 진행했어요. Firebase의 데이터를 다루면서 앱 데이터가 어떻게 생겼는지, 로그 설계는 어떻게 해야하는지 등을 경험했어요</li>\n  <li>그 당시엔 프로덕트 분석가라는 이름이 따로 있진 않았지만, 시간이 지나고 보니 이런 이름으로 불리게 되더라구요</li>\n  <li>이직한 후에도 GA, Firebase 데이터를 어떻게 다룰지에 대해 생각해보고, 앱 로그 데이터에 대한 마트를 제작하기도 했어요. 그래서 이 부분에 대해서는 많은 시행착오를 겪었어요</li>\n  <li>Amplitude, Mixpanel에 대한 것도 개인적으로 경험해보면서, 로그 데이터가 어떻게 구성되고 어떤 관점으로 바라볼지에 대해 알게 되었어요</li>\n  <li>그리고 비즈니스나 머신러닝 알고리즘 관점에서 AB Test를 해보고, 해석의 모호함이 생길 땐 어떻게 해결해야 할지, 통계적 유의성이 이슈가 있으면 어떻게 해야할지 등에 대해 경험했어요</li>\n  <li>돌이켜보면, 저는 여러 직무를 경험했지만 B2C 앱 데이터를 많이 다루곤 했어요. 그래서 프로덕트 데이터 분석가 로드맵을 만들기로 했어요(제일 많이 경험하고 시행 착오가 존재하는)</li>\n</ul>\n\n<p><br /><br /></p>\n\n<h2 id=\"나는-왜-교육을-하는가\">나는 왜 교육을 하는가?</h2>\n<ul>\n  <li>프로덕트 분석가라는 이름이 있지 않던 시절 이 분야를 공부할 때 참 어려웠어요. 회사 개발자분께서 DB를 배우는 것이 필요하다고 해서 <a href=\"https://www.yes24.com/Product/Goods/1820583\">새로쓴 대용량 데이터베이스 솔루션</a>을 공부하기도 했어요. DB를 이해하는데 도움이 되긴 했지만, 내용이 너무 어려웠던 기억이 나네요(요즘 학습하면 LLM의 도움을 받아 더 쉽게 가능하겠지만)</li>\n  <li>교육을 해야겠다고 다짐할 때, <strong>과거의 저처럼 회사에서 업무를 진행하다가 어려움을 겪는 분들이 조금이나마 더 나은 길을 가길 바랬어요</strong></li>\n  <li>어떻게 보면 <strong>과거의 저에게 보내는 강의</strong>라고 볼 수 있어요\n    <ul>\n      <li>이 내용을 미리 알았다면 참 좋았을텐데, 실제로 해보면 이런 부분을 깊게 생각하면 좋은 것 등</li>\n      <li>그래서 PM을 위한 데이터 리터러시 강의에는 “카일 스토리”라는 것이 나옵니다. 원래 강의 인트로에 연기하려고 했다가, 어설프게 하려니 이상해서 그냥 덤덤한 방식으로 전개했어요</li>\n    </ul>\n  </li>\n  <li><strong>저를 경험한 분들이 더 좋은 삶을 살길 바라고 있어요. 그냥 각자가 더 좋은 삶(사람마다 정의하기 나름이지만)을 살길 바라고 있어요</strong>\n    <ul>\n      <li>여러 관점이 있지만, 인프런에 올리는 내용은 대부분 업무를 하다가 겪는 내용들을 다루곤 해요. 어떻게 해야 일을 더 잘할 수 있고, 회사에서 인정 받을 수 있을까?를 주로 다룹니다</li>\n      <li>유튜브에는 커리어에서 생각할 수 있는 고민들을 주로 다루고, 로드맵이나 제 생각을 공유하곤 해요. 이런 내용을 통해 영감을 받길 바라고 있어요(꼭 그대로 하는 것이 아닌 자신만의 방법을 찾는 것)</li>\n    </ul>\n  </li>\n  <li>어떤 형태의 강의를 하고 싶었는지 생각해보면, 고등학생 때 들었던 신승범 선생님처럼 수업하고 싶었던 것 같네요. 강의 자체도 하지만, 인생에 대한 내용이나 어떻게 삶을 살아갈지, 동기부여 등도 같이 진행하고 싶었어요\n    <ul>\n      <li>요즘 수학은 정승제 선생님 강의를 듣던데, 이 맥락과 비슷한 것 같네요</li>\n      <li>강의에 저도 이런 동기 부여에 대한 내용도 추가하려고 생각하고 있어요</li>\n    </ul>\n  </li>\n</ul>\n\n<p><br /><br /></p>\n\n<h2 id=\"어떤-것이-중요하다고-생각했는가\">어떤 것이 중요하다고 생각했는가?</h2>\n<ul>\n  <li>강의는 총 3개로 구성되어 있고, 나머지는 유튜브 영상이에요.</li>\n  <li><a href=\"https://inf.run/jfWT\">PM을 위한 데이터 리터러시</a>\n    <ul>\n      <li>문제 정의, 구조적인 사고, 로그 설계, 실험 설계, 의사 결정, 데이터 문화 등 데이터를 다루다가 생기는 다양한 일을 모두 담았어요</li>\n      <li>제 강의 중에 처음 어떤 강의를 들을까? 생각하면 이 강의가 제일 좋다고 생각합니다. 회사에서 어떤 방식으로 일을 하는지 알아보면서 데이터 분석을 어떻게 해야할지에 대해 알 수 있어요</li>\n      <li>제가 익힌 여러 암묵지를 모두 담은 강의라, 다시 이런 종류의 강의를 만들라고 하면 어떤 내용을 더 넣어야 할지 고민될 것 같네요. 물론 더 추가할 부분이 있긴 합니다</li>\n      <li>PM 직무에 계신 분들도 보기 좋고, 디자이너, 데이터 분석가 모두 보면 좋을 내용으로 구성되어 있어요</li>\n    </ul>\n  </li>\n  <li><a href=\"https://inf.run/p121d\">초보자를 위한 BigQuery(SQL)</a>\n    <ul>\n      <li>데이터를 다루기 위해 SQL을 알아야 합니다.</li>\n      <li>회사에서 SQL을 처음 배우는 분들이 어디서 어려움을 겪는지, 어떤 것을 알면 좋을지 고민하며 만들었어요</li>\n      <li>강의에서 특히 힘을 준 부분은 <strong>“데이터 검증”</strong>, <strong>“쿼리를 작성하는 흐름”</strong>. 이 부분은 암묵지에 해당될 수 있는 내용인데, 회사에서 참 중요하다 생각했어요</li>\n      <li>지표를 잘못 뽑고, 지표를 보는 분에게 잘못 뽑았다고 말하는 경우 종종 있을 수 있는데, 데이터 검증을 어떻게 해야할지에 대해 모르거나 쿼리의 실수로 발생하곤 합니다. 간단하게 특정 user_id를 선정해서 미리 확인해보는 과정으로 해결할 수 있는데, 이런 내용에 대해 알지 못하는 경우가 있었어요</li>\n      <li>쿼리를 작성하는 흐름은 처음에 이런 큰 그림을 이해하면 더 잘 작성할 수 있다고 판단했어요</li>\n      <li>쿼리를 작성할 때 참고할 수 있는 데이터 템플릿도 공유드리고, 이걸 자동화할 수 있는 도구도 알려드렸어요. <a href=\"https://espanso.org/\">Espanso</a>라는 도구인데, 무료고 오픈소스라 많은 분들이 아시면 좋을거에요</li>\n      <li>시간 데이터를 다룰 일이 많은데, 서버의 데이터는 UTC로 저장되어 있는 경우가 많아요. 이 때 타임존에 대한 내용을 모를 수 있는데, SQL에서 이 부분을 학습하면 좋겠다고 생각했어요</li>\n    </ul>\n  </li>\n  <li><a href=\"https://inf.run/QVgPf\">BigQuery 활용편</a>\n    <ul>\n      <li>이 강의는 입문편에서 다루진 않은 부분 중 유용한 함수인 윈도우 함수를 주로 다룹니다</li>\n      <li>Firebase 데이터의 특징으로 배열 데이터를 다뤄야 하는데, 배열 데이터를 다루는 방법에 대해서도 학습합니다</li>\n      <li>단순히 문법만 배우는 것이 아니라 퍼널 분석, 리텐션 분석을 어떻게 접근하면 좋은지 공유합니다</li>\n      <li>PM을 위한 데이터 리터러시 강의랑 연결되는 부분인데, 제품에 대해 생각하고, 그 부분에서 리텐션 개선 아이디어를 생각하도록 강의를 구성했어요. 이렇게 말을 해도 실제로 데이터를 보면 데이터만 보게 되는 경우가 종종 있어서, 강의에서 계속 제품에 대해 고민할 수 있도록 생각을 공유했어요</li>\n      <li>Google Sheets로 자동화를 할 수 있는 부분이 꽤 있는데, 이 부분도 알아가시면 좋을 것 같다 싶어 이 부분도 추가했어요</li>\n    </ul>\n  </li>\n</ul>\n\n<p><br /><br /></p>\n\n<h2 id=\"데이터를-활용하고-싶은-분들이-어떻게-학습하면-좋을까\">데이터를 활용하고 싶은 분들이 어떻게 학습하면 좋을까</h2>\n<ul>\n  <li>이 부분은 최근에 <a href=\"https://www.threads.net/@data.scientist/post/C-c48E7zEM_\">쓰레드</a>에 길게 남겼는데, 블로그에도 공유해보아요. 존댓말을 쓰지 않고 자유롭게 남긴 내용입니다</li>\n  <li>하드 스킬에 대한 내용은 줄인 버전이고, 머신러닝이나 데이터 시각화 등에 대한 지식은 언제든 해도 괜찮다고 생각</li>\n  <li>보통 데이터를 활용한다라고 하면 파이썬, SQL, 통계 같은 기술적인 것부터 생각한다. 그렇기 때문에 이걸 해야 데이터를 활용할 수 있다고 생각\n    <ul>\n      <li>데이터를 활용한다는 것은 데이터 기반 의사결정을 한다는 것이고, 이것은 문제를 해결하는 과정에서 지표를 정의해서 지표에 따른 의사 결정을 하는 것</li>\n      <li>제일 중요한 것은 문제를 정의하고, 문제를 인식하는 것. 대부분 이 부분을 그냥 넘어가지만, 문제 정의를 잘 진행하는 것이 제일 중요하다. 정의가 잘 된다면 지표는 자연스럽게 나오고, 지표는 사용할 수 있는 도구(엑셀, 파이썬, SQL 등 사용 가능한 것)로 추출하면 된다</li>\n      <li>논리적 사고는 “로지컬 씽킹” 책을 추천. 맥킨지식 논리적 사고로 유명하고, MECE / So What? Why So를 매번 생각한다</li>\n      <li>사실 이 역량은 모든 직무에게 필요하다</li>\n    </ul>\n  </li>\n  <li>논리적 사고에 대해 어느정도 파악을 했다면, 그 후엔 무엇을 해야할까?\n    <ul>\n      <li>그 후엔 데이터를 어떤 관점으로 바라볼지에 대해 감을 잡으면 좋다. 신입 시절에 데이터를 어떻게 바라볼지에 대한 관점이 없이 일단 데이터를 뽑고 해석을 하려고 했는데, 데이터를 바라보는 관점이 없어서 어려웠다.</li>\n      <li>데이터를 바라보는 과정에선 1) 그래프 기반, 2) 호기심 기반, 3) 상급자 기반 등이 있는데 3가지 방법보단 “목적 기반”으로 보는 것이 핵심. 어떤 목적을 가지고 어떤 지표를 볼지, 그리고 어떤 것을 해야할까?에 대해 생각해보는 것이 필요하다. 목적이 없으면 기준이나 판단이 어렵다.</li>\n      <li>이런 관점에 대해 잘 나온 책은 “빅데이터 시대, 성과를 이끌어 내는 데이터 문해력” 이 책이 나왔을 때 처음 읽고 완전 감동받은 책. 논리적 사고랑 연결되는 부분이 있다</li>\n    </ul>\n  </li>\n  <li>(3) 논리적 사고, 데이터 목적에 대한 학습. 그 후엔?\n    <ul>\n      <li>앞선 것들을 잘 진행하기 위해, 회사의 비즈니스 모델을 잘 이해하면 좋다. 비즈니스 모델이란 것은 회사에서 매출이 언제 발생하고, 어떤 흐름으로 돈이 돌아다니는지를 의미한다. 데이터 분석을 한다는 것은 목적이 있을텐데, 회사의 서비스를 성장하기 위해 무엇을 해야할까?, 매출을 증가시키기 위해 무엇을 해야할까?, 비용을 줄이기 위해 무엇을 해야할까? 등을 생각한다. 이 때 비즈니스 모델을 이해하면 더 수월하게 생각할 수 있었다.</li>\n      <li>관련해서는 “한 장으로 끝내는 비즈니스 모델 100” 책을 추천. 도식화로 정리가 되어있어서 도움이 된다. 그러면서 사용하고 있는 앱이나 서비스의 비즈니스 모델을 분석해보는 것도 추천</li>\n      <li>강의를 들은 분들 중 면접을 잘 보고 싶다고 하는 분들에겐 “지원하는 회사의 비즈니스 모델”을 스스로 분석해보고, 도식화해서 그 내용 기반으로 무엇을 할지 생각해보라고 권한다. 이런 것을 하는 사람이 적다.</li>\n    </ul>\n  </li>\n  <li>(4) 논리적 사고, 데이터 목적, 비즈니스 모델. 그 후엔?\n    <ul>\n      <li>그 후에 간단한 통계학 공부를 하면 좋은데, 통계학을 어려워하는 사람이 있기에 처음엔 쉽게 접근하는 것을 추천한다.\n  “데이터 분석가의 숫자유감”이란 책이 있는데, 만화로 구성되어 있다. 통계를 활용하는 핵심적인 부분이 나와있어서 이 책을 보면 대략적으로 어떻게 활용해야 할지에 대해 감이 온다.</li>\n      <li>그 후에 추천하는 책은 “숫자에 약한 사람들을 위한 통계학 수업”. 이 책도 핵심적인 통계학 개념을 쭉 훑고, 실용적인 관점에서 사례가 많이 나온다. 수학을 극도로 배제해서 눈높이를 낮추어서 많은 분들이 읽을 수 있다.</li>\n      <li>그 후에 본격적인 통계를 공부하고 싶다면 “An Introduction to Statistical Learning”를 추천. 줄여서 ISLR라고도 하는데, 많은 분들이 이 책을 기본서 같이 생각한다. 한국어 번역이 있다고 들었지만, 원서를 추천. 구글에 책 제목을 검색하면 원서가 나온다(파이썬 버전도 있음)</li>\n    </ul>\n  </li>\n  <li>(5) 통계학 그 후엔 무엇을 해야할까, 이 시기엔 상황에 따라 다를듯. 우선 회사에 다니고 계신 분들 대상으로 먼저 이야기\n회사에 다니고 있다면, 어떤 문제를 해결해야 할 것. 진행하고 있는 업무가 문제와 관련되어 있을 것이다. 이 문제를 해결하기 위해 어떤 것을 해야할까? 어떤 지표를 봐야할까? 생각하기\n    <ul>\n      <li>이 과정에서 지표 정의에 대해서 알면 좋은데, 지표가 어렵다면 “문제가 해결되면 어떤 모습이 되는가? 그 모습을 숫자로 표시한다면?” 질문을 통해 정의. 요즘은 LLM이 잘 발전되어 있어서 어떤 문제를 해결하고 싶은지를 클로드 등에 물어보면 잘 추천해준다. 그러면 그 지표들을 모두 모아서 어떤 것을 사용할지 결정한다.</li>\n      <li>그리고 해당 지표를 개발자나 데이터 분석가분들에게 부탁해서 받아보고, 그것 기반으로 “Action Item”을 생각해본다. 뭘 해야 그 지표를 올릴 수 있을까? 그리고 그것을 실행하고 기능 개발 -&gt; 의사 결정. 바로 문제를 푸는 방법</li>\n    </ul>\n  </li>\n  <li>(6) 회사에 다니지 않는 취준생이라면\n    <ul>\n      <li>이런 경우 참 어렵다. 취준생 입장에서 데이터를 어떻게 구할까?라는 고민에 빠진다. 이를 해결하기 위해 캐글이란 플랫폼이 나왔지만, 캐글은 문제 정의가 된 후에 데이터를 제공한 후 모델링에 집중한다.</li>\n      <li>데이터를 활용한다는 것은 문제에서 데이터를 해석하고, 의사결정하는 것이라고 볼 수 있다. 그리고 데이터가 쌓인 후 목적에 맞으면 예측 모델링을 진행한다.\n취준생이라면 내가 데이터 분석을 집중하고 싶은지, 모델링을 하고 싶은지 고민해야 한다. 많은 교육 과정에서 모델링 위주로 교육해서 혼란스러운 경우가 있는데, 나눠서 생각해보는 것을 추천.</li>\n      <li>어떤 직무를 하던, 이 쯔음에 SQL/파이썬 등을 학습한다. 요즘은 대부분의 책이 잘 나와서 서점에서 고르는 것도 추천</li>\n    </ul>\n  </li>\n</ul>\n\n<p><br /><br /></p>\n\n<h1 id=\"데이터-분석가-로드맵에-더-추가되면-좋은-것은\">데이터 분석가 로드맵에 더 추가되면 좋은 것은?</h1>\n<ul>\n  <li>어떤 내용이 더 필요할까 생각해봤는데, 다음 내용을 추가하면 좋을 것 같다</li>\n  <li><strong>데이터 전처리에 대한 학습</strong> : 데이터를 어떻게 처리할지에 대해 방법론이 다양한데 각 방법론의 장단점과 어떻게 활용하면 좋을지에 대해 학습</li>\n  <li><strong>설득하기, 협상하기</strong> : 대화를 할 일이 참 많은 직무다. 설득하기, 협상하기는 어떤 직무여도 있으면 좋겠지만 데이터 분석가분들이 더 들어보면 좋겠다. 사내 컨설턴트가 된다는 생각도 같이 하면서</li>\n  <li>그 후엔 자신이 자신 있는 <strong>도메인 영역</strong>을 정해보면 좋겠다. 산업이여도 괜찮고, 비즈니스나 프러덕트 등으로 생각해도 좋다. 하나의 도메인에서 해결할 수 있는 문제를 거시적으로도 파악하고, 미시적으로도 파악해보면 좋겠다</li>\n  <li><strong>경영진의 사고 과정</strong> : 경영진에 계신 분들이 어떤 생각을 주로 하고, 어떻게 생각하는지 알아두면 좋다. 이런 생각을 할 수 있게 된다면, 내가 지금 어떤 일을 해야할지를 더 잘 생각할 수 있다. 상황에 따라 유연한 접근이 필요한데, 대표님이 지금 무슨 생각을 할까?라는 생각을 하면서 업무를 하곤 했다</li>\n  <li>물론 위에 말한 내용은 일반적인 데이터 분석가 로드맵에서 나오는 내용도 있지만, 아닌 내용도 있다. 회사에서 일을 잘 진행하기 위해 필요했던 내용인데 나만의 경험일 수도 있을 것 같고, 아닐수도 있다</li>\n  <li>데이터 사이언티스트가 되고 싶다면, 데이터 분석도 해보고 전략, 데이터 엔지니어링 등을 모두 경험해보는 것을 추천한다. 다만 요즘 데이터 사이언티스트도 회사마다 다르다. 주로 추천 알고리즘을 만들고 데이터 분석을 할 때 데이터 사이언티스트라고 불리는 것 같다</li>\n</ul>\n\n<p><br /><br /></p>\n\n<h1 id=\"앞으로-할-것들\">앞으로 할 것들</h1>\n<ul>\n  <li>데이터 분석 관련 강의는 잠시 쉬고, 원래 만들고 싶었던 내용을 만들려고 합니다</li>\n  <li>어떻게 해야 데이터 엔지니어링을 쉽게 할 수 있을지에 대한 내용. 그리고 데이터 분석가가 이정도는 알면 좋은 개발 지식. 이렇게 선언해두면, 언젠가 하려고 시도할거라 생각해서 선언해두어요</li>\n  <li>일단 개발자 블로그 글쓰기 강의는 빠르게 만들 수 있어서, 이것부터 하고 전체적인  강의에 대해 설계할 예정</li>\n  <li>강의 만드는 것도 시행착오가 있어서, 여러 방법으로 시도하고 있어요. 이제는 어떻게 해야 속도를 낼 수 있을지 감을 잡아서 계속 시도해볼 예정이에요.</li>\n  <li>그 후엔 다시 회사로 돌아가지 않을까 싶어요. 다만 그 사이에 최선을 다해 강의를 만들려고 해요. 회사에 들어가서 온보딩 자료로 활용할 수 있는 수준으로 강의를 만들려고 합니다. 정해진 것은 아무것도 없지만, 일단 이정도로 생각하고 있어요</li>\n  <li>최근 데이터 리터러시에 대한 니즈를 많이 느끼고 있어요. 강의 판매도 늘어나고 있고, 기업 강의도 요청받고 있어요. 많은 분들이 데이터를 더 잘 활용하고, 쉽게 접근할 수 있도록 계속 하나씩 만들어 볼게요\n    <ul>\n      <li>회사에서 데이터를 어떻게 활용해야 하는지 가이드를 주고, 더 잘 진행할 수 있도록 돕는 직무도 점점 필요해지는 것 같아요. 단순히 데이터 프러덕트를 만들고 끝이 아니고 여러 조직에 있는 사람들의 상황을 파악하고 해결할 수 있는 방법 도출</li>\n    </ul>\n  </li>\n  <li>저는 데이터 분석가분들이 점점 데이터 엔지니어링을 할 수 있어야 하고, 데이터 엔지니어도 데이터나 비즈니스에 대한 큰 그림을 이해하면 좋다고 생각해요. 회사 상황에 따라 다를 수도 있지만, 데이터 관련 큰 그림을 잘 이해할 수 있는 사람들이 더 필요한 시기라고 생각해요</li>\n  <li>대학생분들을 어떻게 도울 수 있을까 고민하고 있어요. 대학원을 가지 않은 제가 교수를 하긴 어려워서, 지금 진행하고 있는 일들을 집중하려고 해요. 부스트캠프 AI Tech와 유튜브 등. 학생분들이 도움을 구하면 가능하면 최대한 시도해보려고 하고 있어요</li>\n  <li>데이터 직무가 아닌 분들이 어떻게 데이터를 잘 활용할 수 있을까? 이 부분에 대해 활용 지침 위주로 내용을 정리해볼까 생각하고 있어요</li>\n</ul>\n\n<p><br /><br /></p>\n\n<h1 id=\"마무리\">마무리</h1>\n<ul>\n  <li>인프런에 올린 <a href=\"https://www.inflearn.com/roadmaps/4639\">로드맵</a>에 관심이 있다면 한번 봐주셔요. 유튜브 영상도 추가해두었어요\n    <ul>\n      <li>2주 동안 로드맵 화면에서 쿠폰을 발급 받을 수 있어요. 필요하시다면 활용하셔도 좋을 것 같아요.</li>\n    </ul>\n  </li>\n  <li>앞으로 제가 어떤 일을 할지, 어떤 커리어를 밟을지 잘 모르지만 지금 상황에 진심을 다해 하나씩 해볼 예정이에요. 지금의 시간이 참 소중하기에.</li>\n  <li>제게 궁금한 내용이 있다면 무엇이든 말씀해주셔요. 이 글에 대한 피드백도 좋아요. 제가 답이라는 것은 아니고, 제 생각을 공유했으니 여러 이야기를 나누며 합쳐보고 싶네요.</li>\n</ul>\n\n<p><br /><br /></p>\n\n<ul>\n  <li>글 작성하는데 걸린 시간 : 약 40분</li>\n</ul>\n\n",
        "contentSnippet": "와 올해 블로그에 쓴 글이 0개였다니.. 충격적이네요. 의식하면서 글을 써보도록 할게요\n이번 글은 인프런에 프로덕트 분석가 로드맵을 작성한 내용에 대해 공유해볼게요\n강의 만드는 과정의 노하우 공유는 예전에 작성한 인프런에서 강의 만들기 글에 있어요\n프로덕트 분석가 로드맵 제작\n인프런 로드맵을 만들었어요. 제가 퇴사하고 만든 강의들을 모아둔 내용입니다\n\n왜 프로덕트 분석가인가?\n데이터 직무로 처음 일했던 회사에서 했던 일을 돌이켜보면 앱 로그 데이터 분석을 많이 진행했어요. Firebase의 데이터를 다루면서 앱 데이터가 어떻게 생겼는지, 로그 설계는 어떻게 해야하는지 등을 경험했어요\n그 당시엔 프로덕트 분석가라는 이름이 따로 있진 않았지만, 시간이 지나고 보니 이런 이름으로 불리게 되더라구요\n이직한 후에도 GA, Firebase 데이터를 어떻게 다룰지에 대해 생각해보고, 앱 로그 데이터에 대한 마트를 제작하기도 했어요. 그래서 이 부분에 대해서는 많은 시행착오를 겪었어요\nAmplitude, Mixpanel에 대한 것도 개인적으로 경험해보면서, 로그 데이터가 어떻게 구성되고 어떤 관점으로 바라볼지에 대해 알게 되었어요\n그리고 비즈니스나 머신러닝 알고리즘 관점에서 AB Test를 해보고, 해석의 모호함이 생길 땐 어떻게 해결해야 할지, 통계적 유의성이 이슈가 있으면 어떻게 해야할지 등에 대해 경험했어요\n돌이켜보면, 저는 여러 직무를 경험했지만 B2C 앱 데이터를 많이 다루곤 했어요. 그래서 프로덕트 데이터 분석가 로드맵을 만들기로 했어요(제일 많이 경험하고 시행 착오가 존재하는)\n\n\n\n나는 왜 교육을 하는가?\n프로덕트 분석가라는 이름이 있지 않던 시절 이 분야를 공부할 때 참 어려웠어요. 회사 개발자분께서 DB를 배우는 것이 필요하다고 해서 새로쓴 대용량 데이터베이스 솔루션을 공부하기도 했어요. DB를 이해하는데 도움이 되긴 했지만, 내용이 너무 어려웠던 기억이 나네요(요즘 학습하면 LLM의 도움을 받아 더 쉽게 가능하겠지만)\n교육을 해야겠다고 다짐할 때, 과거의 저처럼 회사에서 업무를 진행하다가 어려움을 겪는 분들이 조금이나마 더 나은 길을 가길 바랬어요\n어떻게 보면 과거의 저에게 보내는 강의라고 볼 수 있어요\n    \n이 내용을 미리 알았다면 참 좋았을텐데, 실제로 해보면 이런 부분을 깊게 생각하면 좋은 것 등\n그래서 PM을 위한 데이터 리터러시 강의에는 “카일 스토리”라는 것이 나옵니다. 원래 강의 인트로에 연기하려고 했다가, 어설프게 하려니 이상해서 그냥 덤덤한 방식으로 전개했어요\n저를 경험한 분들이 더 좋은 삶을 살길 바라고 있어요. 그냥 각자가 더 좋은 삶(사람마다 정의하기 나름이지만)을 살길 바라고 있어요\n    \n여러 관점이 있지만, 인프런에 올리는 내용은 대부분 업무를 하다가 겪는 내용들을 다루곤 해요. 어떻게 해야 일을 더 잘할 수 있고, 회사에서 인정 받을 수 있을까?를 주로 다룹니다\n유튜브에는 커리어에서 생각할 수 있는 고민들을 주로 다루고, 로드맵이나 제 생각을 공유하곤 해요. 이런 내용을 통해 영감을 받길 바라고 있어요(꼭 그대로 하는 것이 아닌 자신만의 방법을 찾는 것)\n어떤 형태의 강의를 하고 싶었는지 생각해보면, 고등학생 때 들었던 신승범 선생님처럼 수업하고 싶었던 것 같네요. 강의 자체도 하지만, 인생에 대한 내용이나 어떻게 삶을 살아갈지, 동기부여 등도 같이 진행하고 싶었어요\n    \n요즘 수학은 정승제 선생님 강의를 듣던데, 이 맥락과 비슷한 것 같네요\n강의에 저도 이런 동기 부여에 대한 내용도 추가하려고 생각하고 있어요\n\n\n\n어떤 것이 중요하다고 생각했는가?\n강의는 총 3개로 구성되어 있고, 나머지는 유튜브 영상이에요.\nPM을 위한 데이터 리터러시\n    \n문제 정의, 구조적인 사고, 로그 설계, 실험 설계, 의사 결정, 데이터 문화 등 데이터를 다루다가 생기는 다양한 일을 모두 담았어요\n제 강의 중에 처음 어떤 강의를 들을까? 생각하면 이 강의가 제일 좋다고 생각합니다. 회사에서 어떤 방식으로 일을 하는지 알아보면서 데이터 분석을 어떻게 해야할지에 대해 알 수 있어요\n제가 익힌 여러 암묵지를 모두 담은 강의라, 다시 이런 종류의 강의를 만들라고 하면 어떤 내용을 더 넣어야 할지 고민될 것 같네요. 물론 더 추가할 부분이 있긴 합니다\nPM 직무에 계신 분들도 보기 좋고, 디자이너, 데이터 분석가 모두 보면 좋을 내용으로 구성되어 있어요\n초보자를 위한 BigQuery(SQL)\n    \n데이터를 다루기 위해 SQL을 알아야 합니다.\n회사에서 SQL을 처음 배우는 분들이 어디서 어려움을 겪는지, 어떤 것을 알면 좋을지 고민하며 만들었어요\n강의에서 특히 힘을 준 부분은 “데이터 검증”, “쿼리를 작성하는 흐름”. 이 부분은 암묵지에 해당될 수 있는 내용인데, 회사에서 참 중요하다 생각했어요\n지표를 잘못 뽑고, 지표를 보는 분에게 잘못 뽑았다고 말하는 경우 종종 있을 수 있는데, 데이터 검증을 어떻게 해야할지에 대해 모르거나 쿼리의 실수로 발생하곤 합니다. 간단하게 특정 user_id를 선정해서 미리 확인해보는 과정으로 해결할 수 있는데, 이런 내용에 대해 알지 못하는 경우가 있었어요\n쿼리를 작성하는 흐름은 처음에 이런 큰 그림을 이해하면 더 잘 작성할 수 있다고 판단했어요\n쿼리를 작성할 때 참고할 수 있는 데이터 템플릿도 공유드리고, 이걸 자동화할 수 있는 도구도 알려드렸어요. Espanso라는 도구인데, 무료고 오픈소스라 많은 분들이 아시면 좋을거에요\n시간 데이터를 다룰 일이 많은데, 서버의 데이터는 UTC로 저장되어 있는 경우가 많아요. 이 때 타임존에 대한 내용을 모를 수 있는데, SQL에서 이 부분을 학습하면 좋겠다고 생각했어요\nBigQuery 활용편\n    \n이 강의는 입문편에서 다루진 않은 부분 중 유용한 함수인 윈도우 함수를 주로 다룹니다\nFirebase 데이터의 특징으로 배열 데이터를 다뤄야 하는데, 배열 데이터를 다루는 방법에 대해서도 학습합니다\n단순히 문법만 배우는 것이 아니라 퍼널 분석, 리텐션 분석을 어떻게 접근하면 좋은지 공유합니다\nPM을 위한 데이터 리터러시 강의랑 연결되는 부분인데, 제품에 대해 생각하고, 그 부분에서 리텐션 개선 아이디어를 생각하도록 강의를 구성했어요. 이렇게 말을 해도 실제로 데이터를 보면 데이터만 보게 되는 경우가 종종 있어서, 강의에서 계속 제품에 대해 고민할 수 있도록 생각을 공유했어요\nGoogle Sheets로 자동화를 할 수 있는 부분이 꽤 있는데, 이 부분도 알아가시면 좋을 것 같다 싶어 이 부분도 추가했어요\n\n\n\n데이터를 활용하고 싶은 분들이 어떻게 학습하면 좋을까\n이 부분은 최근에 쓰레드에 길게 남겼는데, 블로그에도 공유해보아요. 존댓말을 쓰지 않고 자유롭게 남긴 내용입니다\n하드 스킬에 대한 내용은 줄인 버전이고, 머신러닝이나 데이터 시각화 등에 대한 지식은 언제든 해도 괜찮다고 생각\n보통 데이터를 활용한다라고 하면 파이썬, SQL, 통계 같은 기술적인 것부터 생각한다. 그렇기 때문에 이걸 해야 데이터를 활용할 수 있다고 생각\n    \n데이터를 활용한다는 것은 데이터 기반 의사결정을 한다는 것이고, 이것은 문제를 해결하는 과정에서 지표를 정의해서 지표에 따른 의사 결정을 하는 것\n제일 중요한 것은 문제를 정의하고, 문제를 인식하는 것. 대부분 이 부분을 그냥 넘어가지만, 문제 정의를 잘 진행하는 것이 제일 중요하다. 정의가 잘 된다면 지표는 자연스럽게 나오고, 지표는 사용할 수 있는 도구(엑셀, 파이썬, SQL 등 사용 가능한 것)로 추출하면 된다\n논리적 사고는 “로지컬 씽킹” 책을 추천. 맥킨지식 논리적 사고로 유명하고, MECE / So What? Why So를 매번 생각한다\n사실 이 역량은 모든 직무에게 필요하다\n논리적 사고에 대해 어느정도 파악을 했다면, 그 후엔 무엇을 해야할까?\n    \n그 후엔 데이터를 어떤 관점으로 바라볼지에 대해 감을 잡으면 좋다. 신입 시절에 데이터를 어떻게 바라볼지에 대한 관점이 없이 일단 데이터를 뽑고 해석을 하려고 했는데, 데이터를 바라보는 관점이 없어서 어려웠다.\n데이터를 바라보는 과정에선 1) 그래프 기반, 2) 호기심 기반, 3) 상급자 기반 등이 있는데 3가지 방법보단 “목적 기반”으로 보는 것이 핵심. 어떤 목적을 가지고 어떤 지표를 볼지, 그리고 어떤 것을 해야할까?에 대해 생각해보는 것이 필요하다. 목적이 없으면 기준이나 판단이 어렵다.\n이런 관점에 대해 잘 나온 책은 “빅데이터 시대, 성과를 이끌어 내는 데이터 문해력” 이 책이 나왔을 때 처음 읽고 완전 감동받은 책. 논리적 사고랑 연결되는 부분이 있다\n(3) 논리적 사고, 데이터 목적에 대한 학습. 그 후엔?\n    \n앞선 것들을 잘 진행하기 위해, 회사의 비즈니스 모델을 잘 이해하면 좋다. 비즈니스 모델이란 것은 회사에서 매출이 언제 발생하고, 어떤 흐름으로 돈이 돌아다니는지를 의미한다. 데이터 분석을 한다는 것은 목적이 있을텐데, 회사의 서비스를 성장하기 위해 무엇을 해야할까?, 매출을 증가시키기 위해 무엇을 해야할까?, 비용을 줄이기 위해 무엇을 해야할까? 등을 생각한다. 이 때 비즈니스 모델을 이해하면 더 수월하게 생각할 수 있었다.\n관련해서는 “한 장으로 끝내는 비즈니스 모델 100” 책을 추천. 도식화로 정리가 되어있어서 도움이 된다. 그러면서 사용하고 있는 앱이나 서비스의 비즈니스 모델을 분석해보는 것도 추천\n강의를 들은 분들 중 면접을 잘 보고 싶다고 하는 분들에겐 “지원하는 회사의 비즈니스 모델”을 스스로 분석해보고, 도식화해서 그 내용 기반으로 무엇을 할지 생각해보라고 권한다. 이런 것을 하는 사람이 적다.\n(4) 논리적 사고, 데이터 목적, 비즈니스 모델. 그 후엔?\n    \n그 후에 간단한 통계학 공부를 하면 좋은데, 통계학을 어려워하는 사람이 있기에 처음엔 쉽게 접근하는 것을 추천한다.\n  “데이터 분석가의 숫자유감”이란 책이 있는데, 만화로 구성되어 있다. 통계를 활용하는 핵심적인 부분이 나와있어서 이 책을 보면 대략적으로 어떻게 활용해야 할지에 대해 감이 온다.\n그 후에 추천하는 책은 “숫자에 약한 사람들을 위한 통계학 수업”. 이 책도 핵심적인 통계학 개념을 쭉 훑고, 실용적인 관점에서 사례가 많이 나온다. 수학을 극도로 배제해서 눈높이를 낮추어서 많은 분들이 읽을 수 있다.\n그 후에 본격적인 통계를 공부하고 싶다면 “An Introduction to Statistical Learning”를 추천. 줄여서 ISLR라고도 하는데, 많은 분들이 이 책을 기본서 같이 생각한다. 한국어 번역이 있다고 들었지만, 원서를 추천. 구글에 책 제목을 검색하면 원서가 나온다(파이썬 버전도 있음)\n(5) 통계학 그 후엔 무엇을 해야할까, 이 시기엔 상황에 따라 다를듯. 우선 회사에 다니고 계신 분들 대상으로 먼저 이야기\n회사에 다니고 있다면, 어떤 문제를 해결해야 할 것. 진행하고 있는 업무가 문제와 관련되어 있을 것이다. 이 문제를 해결하기 위해 어떤 것을 해야할까? 어떤 지표를 봐야할까? 생각하기\n    \n이 과정에서 지표 정의에 대해서 알면 좋은데, 지표가 어렵다면 “문제가 해결되면 어떤 모습이 되는가? 그 모습을 숫자로 표시한다면?” 질문을 통해 정의. 요즘은 LLM이 잘 발전되어 있어서 어떤 문제를 해결하고 싶은지를 클로드 등에 물어보면 잘 추천해준다. 그러면 그 지표들을 모두 모아서 어떤 것을 사용할지 결정한다.\n그리고 해당 지표를 개발자나 데이터 분석가분들에게 부탁해서 받아보고, 그것 기반으로 “Action Item”을 생각해본다. 뭘 해야 그 지표를 올릴 수 있을까? 그리고 그것을 실행하고 기능 개발 -> 의사 결정. 바로 문제를 푸는 방법\n(6) 회사에 다니지 않는 취준생이라면\n    \n이런 경우 참 어렵다. 취준생 입장에서 데이터를 어떻게 구할까?라는 고민에 빠진다. 이를 해결하기 위해 캐글이란 플랫폼이 나왔지만, 캐글은 문제 정의가 된 후에 데이터를 제공한 후 모델링에 집중한다.\n데이터를 활용한다는 것은 문제에서 데이터를 해석하고, 의사결정하는 것이라고 볼 수 있다. 그리고 데이터가 쌓인 후 목적에 맞으면 예측 모델링을 진행한다.\n취준생이라면 내가 데이터 분석을 집중하고 싶은지, 모델링을 하고 싶은지 고민해야 한다. 많은 교육 과정에서 모델링 위주로 교육해서 혼란스러운 경우가 있는데, 나눠서 생각해보는 것을 추천.\n어떤 직무를 하던, 이 쯔음에 SQL/파이썬 등을 학습한다. 요즘은 대부분의 책이 잘 나와서 서점에서 고르는 것도 추천\n\n\n\n데이터 분석가 로드맵에 더 추가되면 좋은 것은?\n어떤 내용이 더 필요할까 생각해봤는데, 다음 내용을 추가하면 좋을 것 같다\n데이터 전처리에 대한 학습 : 데이터를 어떻게 처리할지에 대해 방법론이 다양한데 각 방법론의 장단점과 어떻게 활용하면 좋을지에 대해 학습\n설득하기, 협상하기 : 대화를 할 일이 참 많은 직무다. 설득하기, 협상하기는 어떤 직무여도 있으면 좋겠지만 데이터 분석가분들이 더 들어보면 좋겠다. 사내 컨설턴트가 된다는 생각도 같이 하면서\n그 후엔 자신이 자신 있는 도메인 영역을 정해보면 좋겠다. 산업이여도 괜찮고, 비즈니스나 프러덕트 등으로 생각해도 좋다. 하나의 도메인에서 해결할 수 있는 문제를 거시적으로도 파악하고, 미시적으로도 파악해보면 좋겠다\n경영진의 사고 과정 : 경영진에 계신 분들이 어떤 생각을 주로 하고, 어떻게 생각하는지 알아두면 좋다. 이런 생각을 할 수 있게 된다면, 내가 지금 어떤 일을 해야할지를 더 잘 생각할 수 있다. 상황에 따라 유연한 접근이 필요한데, 대표님이 지금 무슨 생각을 할까?라는 생각을 하면서 업무를 하곤 했다\n물론 위에 말한 내용은 일반적인 데이터 분석가 로드맵에서 나오는 내용도 있지만, 아닌 내용도 있다. 회사에서 일을 잘 진행하기 위해 필요했던 내용인데 나만의 경험일 수도 있을 것 같고, 아닐수도 있다\n데이터 사이언티스트가 되고 싶다면, 데이터 분석도 해보고 전략, 데이터 엔지니어링 등을 모두 경험해보는 것을 추천한다. 다만 요즘 데이터 사이언티스트도 회사마다 다르다. 주로 추천 알고리즘을 만들고 데이터 분석을 할 때 데이터 사이언티스트라고 불리는 것 같다\n\n\n\n앞으로 할 것들\n데이터 분석 관련 강의는 잠시 쉬고, 원래 만들고 싶었던 내용을 만들려고 합니다\n어떻게 해야 데이터 엔지니어링을 쉽게 할 수 있을지에 대한 내용. 그리고 데이터 분석가가 이정도는 알면 좋은 개발 지식. 이렇게 선언해두면, 언젠가 하려고 시도할거라 생각해서 선언해두어요\n일단 개발자 블로그 글쓰기 강의는 빠르게 만들 수 있어서, 이것부터 하고 전체적인  강의에 대해 설계할 예정\n강의 만드는 것도 시행착오가 있어서, 여러 방법으로 시도하고 있어요. 이제는 어떻게 해야 속도를 낼 수 있을지 감을 잡아서 계속 시도해볼 예정이에요.\n그 후엔 다시 회사로 돌아가지 않을까 싶어요. 다만 그 사이에 최선을 다해 강의를 만들려고 해요. 회사에 들어가서 온보딩 자료로 활용할 수 있는 수준으로 강의를 만들려고 합니다. 정해진 것은 아무것도 없지만, 일단 이정도로 생각하고 있어요\n최근 데이터 리터러시에 대한 니즈를 많이 느끼고 있어요. 강의 판매도 늘어나고 있고, 기업 강의도 요청받고 있어요. 많은 분들이 데이터를 더 잘 활용하고, 쉽게 접근할 수 있도록 계속 하나씩 만들어 볼게요\n    \n회사에서 데이터를 어떻게 활용해야 하는지 가이드를 주고, 더 잘 진행할 수 있도록 돕는 직무도 점점 필요해지는 것 같아요. 단순히 데이터 프러덕트를 만들고 끝이 아니고 여러 조직에 있는 사람들의 상황을 파악하고 해결할 수 있는 방법 도출\n저는 데이터 분석가분들이 점점 데이터 엔지니어링을 할 수 있어야 하고, 데이터 엔지니어도 데이터나 비즈니스에 대한 큰 그림을 이해하면 좋다고 생각해요. 회사 상황에 따라 다를 수도 있지만, 데이터 관련 큰 그림을 잘 이해할 수 있는 사람들이 더 필요한 시기라고 생각해요\n대학생분들을 어떻게 도울 수 있을까 고민하고 있어요. 대학원을 가지 않은 제가 교수를 하긴 어려워서, 지금 진행하고 있는 일들을 집중하려고 해요. 부스트캠프 AI Tech와 유튜브 등. 학생분들이 도움을 구하면 가능하면 최대한 시도해보려고 하고 있어요\n데이터 직무가 아닌 분들이 어떻게 데이터를 잘 활용할 수 있을까? 이 부분에 대해 활용 지침 위주로 내용을 정리해볼까 생각하고 있어요\n\n\n\n마무리\n인프런에 올린 로드맵에 관심이 있다면 한번 봐주셔요. 유튜브 영상도 추가해두었어요\n    \n2주 동안 로드맵 화면에서 쿠폰을 발급 받을 수 있어요. 필요하시다면 활용하셔도 좋을 것 같아요.\n앞으로 제가 어떤 일을 할지, 어떤 커리어를 밟을지 잘 모르지만 지금 상황에 진심을 다해 하나씩 해볼 예정이에요. 지금의 시간이 참 소중하기에.\n제게 궁금한 내용이 있다면 무엇이든 말씀해주셔요. 이 글에 대한 피드백도 좋아요. 제가 답이라는 것은 아니고, 제 생각을 공유했으니 여러 이야기를 나누며 합쳐보고 싶네요.\n\n\n\n\n  \n글 작성하는데 걸린 시간 : 약 40분",
        "guid": "https://zzsza.github.io/diary/2024/08/21/product-analyst-roadmap/",
        "categories": [
          "diary",
          "diary"
        ],
        "isoDate": "2024-08-21T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "Firebase 세금 - 간이결제 일반결제 - 바꾸는 ui 어딧을까?",
        "link": "http://serverdown.tistory.com/793",
        "pubDate": "Wed, 21 Aug 2024 01:44:17 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/793#entry793comment",
        "content": "<p data-ke-size=\"size16\">법인은 일반과세를 해야한다고합니다.</p>\n<p data-ke-size=\"size16\">간이는 어디 쓰는지 모르겠는데 싸보여서 했다가 고쳐야할일이 생겨서 ui 열심히 찾았습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">간이과세 일반과세 부분을 바꾸려면 간단하게는 안되고</p>\n<p data-ke-size=\"size16\">1. Firebase 에서 무료 오금제로 변경합니다.</p>\n<p data-ke-size=\"size16\">Blaze -&gt; Spark 로 바꾸라는 이야기</p>\n<p data-ke-size=\"size16\">좌측 하단에 수정 버튼이 있습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"355\" data-origin-height=\"304\"><span data-url=\"https://blog.kakaocdn.net/dn/P8ZZG/btsJaS6oPcC/EqySgA5Yhuf8ubXJKnkbL0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/P8ZZG/btsJaS6oPcC/EqySgA5Yhuf8ubXJKnkbL0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/P8ZZG/btsJaS6oPcC/EqySgA5Yhuf8ubXJKnkbL0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FP8ZZG%2FbtsJaS6oPcC%2FEqySgA5Yhuf8ubXJKnkbL0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"355\" data-origin-height=\"304\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">2. 무료로 다운그레이드하시고 다시 Blaze 요금제를 선택할때 결제 프로필을 고르라고 합니다.</p>\n<p data-ke-size=\"size16\">이때 프로필 새로 만들기를 하면</p>\n<p data-ke-size=\"size16\">예전 데이터가 입력되어있으니 여기서 과세 부분만 바꿔서 다시 진행 하시면 됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">==== 아래는 과세 정보 보는 UI 위치에 대한 설명입니다. ===</p>\n<p data-ke-size=\"size16\">과세 유형 바꿀수 있는지 알고 적상했는데</p>\n<p data-ke-size=\"size16\">변경이 안되는군요 UI 위치 참고용으로 남겨둡니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">1. Firebase 콘솔 에서 프로젝트 고릅니다.</p>\n<p data-ke-size=\"size16\">2.&nbsp; 우측 메뉴에서 [프로젝트 개요] -&gt; [톱니바퀴] -&gt; [사용량 및 결제] 로 갑니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"476\" data-origin-height=\"255\"><span data-url=\"https://blog.kakaocdn.net/dn/dIEpre/btsI9OoBgTz/aDRD8DYB3ybQXHiKZl4t4K/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/dIEpre/btsI9OoBgTz/aDRD8DYB3ybQXHiKZl4t4K/img.png\"><img src=\"https://blog.kakaocdn.net/dn/dIEpre/btsI9OoBgTz/aDRD8DYB3ybQXHiKZl4t4K/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdIEpre%2FbtsI9OoBgTz%2FaDRD8DYB3ybQXHiKZl4t4K%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"476\" data-origin-height=\"255\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">3. [계정보기] 들어갑니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"699\" data-origin-height=\"668\"><span data-url=\"https://blog.kakaocdn.net/dn/bIucWz/btsI81CcStp/vXs6ZSn4lnk7xvm2Vk4ck0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bIucWz/btsI81CcStp/vXs6ZSn4lnk7xvm2Vk4ck0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bIucWz/btsI81CcStp/vXs6ZSn4lnk7xvm2Vk4ck0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbIucWz%2FbtsI81CcStp%2FvXs6ZSn4lnk7xvm2Vk4ck0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"699\" data-origin-height=\"668\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">4.&nbsp; Google Cloud 로 왔네요 우측 하단에 [결제 설정] 누릅니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"341\" data-origin-height=\"632\"><span data-url=\"https://blog.kakaocdn.net/dn/try4n/btsI9bEBjWb/psdk649aFE5TDmjxCWccg0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/try4n/btsI9bEBjWb/psdk649aFE5TDmjxCWccg0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/try4n/btsI9bEBjWb/psdk649aFE5TDmjxCWccg0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Ftry4n%2FbtsI9bEBjWb%2Fpsdk649aFE5TDmjxCWccg0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"341\" data-origin-height=\"632\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">5. 간이과세 골랐던 부분이 있습니다. ctrl-f 눌러서 검색하셔도 되구요 잘찾아보세요</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"307\" data-origin-height=\"126\"><span data-url=\"https://blog.kakaocdn.net/dn/bqmjko/btsI8QAYamq/V3ebNfO1gx8Va8sTdwuG0K/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bqmjko/btsI8QAYamq/V3ebNfO1gx8Va8sTdwuG0K/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bqmjko/btsI8QAYamq/V3ebNfO1gx8Va8sTdwuG0K/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbqmjko%2FbtsI8QAYamq%2FV3ebNfO1gx8Va8sTdwuG0K%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-origin-width=\"307\" data-origin-height=\"126\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">이상입니다.</p>\n<p data-ke-size=\"size16\">변경은 실패하더군요 보는 용도로만 ..</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "법인은 일반과세를 해야한다고합니다.\n간이는 어디 쓰는지 모르겠는데 싸보여서 했다가 고쳐야할일이 생겨서 ui 열심히 찾았습니다.\n \n간이과세 일반과세 부분을 바꾸려면 간단하게는 안되고\n1. Firebase 에서 무료 오금제로 변경합니다.\nBlaze -> Spark 로 바꾸라는 이야기\n좌측 하단에 수정 버튼이 있습니다.\n\n\n \n2. 무료로 다운그레이드하시고 다시 Blaze 요금제를 선택할때 결제 프로필을 고르라고 합니다.\n이때 프로필 새로 만들기를 하면\n예전 데이터가 입력되어있으니 여기서 과세 부분만 바꿔서 다시 진행 하시면 됩니다.\n \n \n==== 아래는 과세 정보 보는 UI 위치에 대한 설명입니다. ===\n과세 유형 바꿀수 있는지 알고 적상했는데\n변경이 안되는군요 UI 위치 참고용으로 남겨둡니다.\n \n1. Firebase 콘솔 에서 프로젝트 고릅니다.\n2.  우측 메뉴에서 [프로젝트 개요] -> [톱니바퀴] -> [사용량 및 결제] 로 갑니다.\n\n\n3. [계정보기] 들어갑니다.\n\n\n4.  Google Cloud 로 왔네요 우측 하단에 [결제 설정] 누릅니다.\n\n\n5. 간이과세 골랐던 부분이 있습니다. ctrl-f 눌러서 검색하셔도 되구요 잘찾아보세요\n\n\n이상입니다.\n변경은 실패하더군요 보는 용도로만 ..",
        "guid": "http://serverdown.tistory.com/793",
        "categories": [
          "프로그래밍/개발메모",
          "Firebase"
        ],
        "isoDate": "2024-08-20T16:44:17.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "코카콜라가 비트코인을 사야할지도 ...",
        "link": "http://serverdown.tistory.com/792",
        "pubDate": "Mon, 19 Aug 2024 19:58:26 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/792#entry792comment",
        "content": "<p data-ke-size=\"size16\">영상: <a href=\"https://youtu.be/IzRy_tYMIk8?t=1389\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://youtu.be/IzRy_tYMIk8?t=1389</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=IzRy_tYMIk8\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cou261/hyWOlG0daZ/XrkJ80AEUjhalEdCcIWk80/img.jpg?width=1280&amp;height=720&amp;face=552_132_684_276\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"코카콜라 세금 폭탄, 미국 국세청이 화난 이유 (언더스탠딩 김상훈 기자)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/IzRy_tYMIk8\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상 요약</p>\n<p data-ke-size=\"size16\">코카콜라는 수익금이 많이 쌓여있습니다.</p>\n<p data-ke-size=\"size16\">가끔 이벤트가 있을때 마다 돈을 미국으로 송금해서 세금을 내는데</p>\n<p data-ke-size=\"size16\">너무 적게 들고 오니 내는 세금도 적다고 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">미국 국세청이 그래서 명령을 통해 더많은 세금을 징수하려고 하는데</p>\n<p data-ke-size=\"size16\">이 부분에서 수익금이 많이 쌓인게 문제이니</p>\n<p data-ke-size=\"size16\">비트코인 같은걸 사버리면 수익금이 줄게 되겠지요</p>\n<p data-ke-size=\"size16\">그걸 우연히 이야기하는데 아이디어 좋아서 남겨둡니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">큰돈을 안정적으로 받아둘 만한 곳이 잘 업다고합니다.</p>\n<p data-ke-size=\"size16\">빅테크는 너무 올랐고</p>\n<p data-ke-size=\"size16\">미국채는 여차하면 많이 풀어버릴꺼라 불안하고</p>\n<p data-ke-size=\"size16\">금도 있지만</p>\n<p data-ke-size=\"size16\">비트도 있다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">정도의 느낌</p>",
        "contentSnippet": "영상: https://youtu.be/IzRy_tYMIk8?t=1389\n\n\n\n \n \n영상 요약\n코카콜라는 수익금이 많이 쌓여있습니다.\n가끔 이벤트가 있을때 마다 돈을 미국으로 송금해서 세금을 내는데\n너무 적게 들고 오니 내는 세금도 적다고 합니다.\n \n미국 국세청이 그래서 명령을 통해 더많은 세금을 징수하려고 하는데\n이 부분에서 수익금이 많이 쌓인게 문제이니\n비트코인 같은걸 사버리면 수익금이 줄게 되겠지요\n그걸 우연히 이야기하는데 아이디어 좋아서 남겨둡니다.\n \n큰돈을 안정적으로 받아둘 만한 곳이 잘 업다고합니다.\n빅테크는 너무 올랐고\n미국채는 여차하면 많이 풀어버릴꺼라 불안하고\n금도 있지만\n비트도 있다.\n \n정도의 느낌",
        "guid": "http://serverdown.tistory.com/792",
        "categories": [
          "투자",
          "비트코인"
        ],
        "isoDate": "2024-08-19T10:58:26.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Hybrid's Notes",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": [
      {
        "creator": "향로 (기억보단 기록을)",
        "title": "IntelliJ 등에서 메모리 점유율이 계속 높아질 때 (feat. vanilla JBR)",
        "link": "https://jojoldu.tistory.com/800",
        "pubDate": "Mon, 19 Aug 2024 23:40:27 +0900",
        "author": "향로 (기억보단 기록을)",
        "comments": "https://jojoldu.tistory.com/800#entry800comment",
        "content": "<p data-ke-size=\"size16\">silicon M1 맥북을 사용하고나서 IntelliJ를 계속 켜놓고 있으면 끝도 없이 메모리가 올라가는 이슈가 발생했다.</p>\n<p data-ke-size=\"size16\">현재 내 IntelliJ VM Option 에서 메모리 설정은 다음과 같다.</p>\n<p data-ke-size=\"size16\">(PC는 M1 Pro 16GB)</p>\n<pre class=\"diff\"><code>-Xms1024m\n-Xmx4096m</code></pre>\n<p data-ke-size=\"size16\">위와 같이 설정하고 IntelliJ를 켜두고 오랜 시간이 지나면 IntelliJ의 자체 Memory 분석 도구에서는 여전히 아래와 같이 정상적인 사용량이 노출되는 반면,</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"memory1.png\" data-origin-width=\"732\" data-origin-height=\"370\"><span data-url=\"https://blog.kakaocdn.net/dn/Egq6X/btsI7MrmJD3/kJCgClGLvIxOsP766Kitd1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/Egq6X/btsI7MrmJD3/kJCgClGLvIxOsP766Kitd1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/Egq6X/btsI7MrmJD3/kJCgClGLvIxOsP766Kitd1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FEgq6X%2FbtsI7MrmJD3%2FkJCgClGLvIxOsP766Kitd1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"memory1.png\" data-origin-width=\"732\" data-origin-height=\"370\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">실제 IntellIJ의 메모리 사용량은 다음과 같이 <b>설정한 VM Option을 크게 초과해서 사용하는 것</b>을 확인할 수 있다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"memory2.png\" data-origin-width=\"1919\" data-origin-height=\"814\"><span data-url=\"https://blog.kakaocdn.net/dn/bdItHM/btsI7XzBkfa/AUNKw95YgPxX3JTWyM9hek/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bdItHM/btsI7XzBkfa/AUNKw95YgPxX3JTWyM9hek/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bdItHM/btsI7XzBkfa/AUNKw95YgPxX3JTWyM9hek/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbdItHM%2FbtsI7XzBkfa%2FAUNKw95YgPxX3JTWyM9hek%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"memory2.png\" data-origin-width=\"1919\" data-origin-height=\"814\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">16GB RAM을 가진 PC에서 14GB에 가까운 메모리를 사용중인데, 이건 <b>더 높은 메모리 사양을 가진 맥북을 사용하면 더 크게 메모리를 점유한다</b>.<br />(테스트 결과 36GB 메모리 PC에서는 20GB를 사용한다.)</p>\n<p data-ke-size=\"size16\">즉, <b>아무리 사양이 좋은 맥북을 사용하더라도 메모리로 인한 성능 저하 문제를 피할 수가 없다</b>.</p>\n<p data-ke-size=\"size16\">이 이슈를 해결하기 위해 여러 설정들을 테스트 해봤다.</p>\n<h2 data-ke-size=\"size26\">해결 방법</h2>\n<p data-ke-size=\"size16\"><a href=\"https://youtrack.jetbrains.com/\">YouTrack</a> 이슈들을 확인 해보니, 이 이슈가 3년전부터 있었던 이슈였다.</p>\n<ul style=\"list-style-type: disc;\" data-ke-list-type=\"disc\">\n<li><a href=\"https://youtrack.jetbrains.com/issue/JBR-3631\">Intellij high memory usage on apple silicon M1, 7-8GB of RAM</a></li>\n</ul>\n<p data-ke-size=\"size16\">댓글에서 여러가지 방법들이 이야기 되었지만, 실제 효과가 있었던 방법은 하나였다.<br />바로 <a href=\"https://www.jetbrains.com/help/webstorm/switching-boot-jdk.html\">\"IDE의 Java Runtime을 바꾸는 것\"</a>이다.</p>\n<p data-ke-size=\"size16\">IntelliJ 역시 Java로 만들어진 애플리케이션이며, 이를 구동시키는데는 Java Runtime 환경 (JRE)이 필요하다.<br />기본적으로 JetBrains IDE들은 IDE에 포함된 JetBrains Runtime(OpenJDK의 Fork 버전)을 사용한다.<br />JetBrains Runtime은 알려진 다양한 OpenJDK 및 Oracle JDK 버그를 수정하고 더 나은 성능과 안정성을 제공하지만, 이번 경우와 같이 문제가 될 경우 변경할 수 있는 설정을 지원한다.</p>\n<p data-ke-size=\"size16\">우리가 변경할 버전은 <a href=\"https://youtrack.jetbrains.com/issue/JBR-3631/Intellij-high-memory-usage-on-apple-silicon-M1-7-8GB-of-RAM#focus=Comments-27-8283737.0-0\">JBR Vanilla</a>이다.</p>\n<p data-ke-size=\"size16\">변경 하는 방법은 다음과 같다.<br /><code>CMD + Shift A</code> 로 Actions 검색 화면에서 <code>choose boot java</code> 를 검색하여 <code>Choose Boot Java Runtime for the IDE...</code> 를 선택한다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"memory3.png\" data-origin-width=\"1900\" data-origin-height=\"396\"><span data-url=\"https://blog.kakaocdn.net/dn/ciFheL/btsI9iCyxAZ/36uxFzbnENZk5A6hrOC7Y1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ciFheL/btsI9iCyxAZ/36uxFzbnENZk5A6hrOC7Y1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/ciFheL/btsI9iCyxAZ/36uxFzbnENZk5A6hrOC7Y1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FciFheL%2FbtsI9iCyxAZ%2F36uxFzbnENZk5A6hrOC7Y1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"memory3.png\" data-origin-width=\"1900\" data-origin-height=\"396\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">현재 사용중인 버전을 확인해보면 <code>21.0.3+13-509.4-jcef</code> 인 것을 확인할 수 있다.<br />(이건 개인 PC마다 다름)</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"memory4.png\" data-origin-width=\"1660\" data-origin-height=\"778\"><span data-url=\"https://blog.kakaocdn.net/dn/ltbt4/btsI7OilLBO/3s54pRWLQKLE9z9U8usAB0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ltbt4/btsI7OilLBO/3s54pRWLQKLE9z9U8usAB0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/ltbt4/btsI7OilLBO/3s54pRWLQKLE9z9U8usAB0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fltbt4%2FbtsI7OilLBO%2F3s54pRWLQKLE9z9U8usAB0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"memory4.png\" data-origin-width=\"1660\" data-origin-height=\"778\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">여기서 <code>jcef</code> 가 아니라 동일 버전의 <code>vanilla</code> JBR을 선택하면 된다.<br />나 같은 경우 <code>21.0.3b509.11 (vanilla)</code> 를 선택했다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"memory5.png\" data-origin-width=\"1650\" data-origin-height=\"748\"><span data-url=\"https://blog.kakaocdn.net/dn/496gc/btsI9ubHw8P/rTK9P4kMQrD3JyJ3Q3K9xk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/496gc/btsI9ubHw8P/rTK9P4kMQrD3JyJ3Q3K9xk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/496gc/btsI9ubHw8P/rTK9P4kMQrD3JyJ3Q3K9xk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F496gc%2FbtsI9ubHw8P%2FrTK9P4kMQrD3JyJ3Q3K9xk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"memory5.png\" data-origin-width=\"1650\" data-origin-height=\"748\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">여기까지하면 설정은 끝났다.<br />OK를 누르고 IntelliJ를 완전히 종료 후, 재실행 해본다.</p>\n<p data-ke-size=\"size16\">그리고나서 사용해보면 <b>몇시간이 지나도 IntelliJ에서 안정적으로 메모리를 사용</b>하는 것을 확인할 수 있다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"memory6.png\" data-origin-width=\"1478\" data-origin-height=\"422\"><span data-url=\"https://blog.kakaocdn.net/dn/bcnd7k/btsI9f6RGD2/TVym4iaMZWiHMaHmP6DwPK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bcnd7k/btsI9f6RGD2/TVym4iaMZWiHMaHmP6DwPK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bcnd7k/btsI9f6RGD2/TVym4iaMZWiHMaHmP6DwPK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbcnd7k%2FbtsI9f6RGD2%2FTVym4iaMZWiHMaHmP6DwPK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"memory6.png\" data-origin-width=\"1478\" data-origin-height=\"422\"/></span></figure>\n</p>\n<blockquote data-ke-style=\"style2\">\n<p data-ke-size=\"size16\">당연히 이 설정은 이후 IntelliJ가 메모리 이슈를 해소하고 나면 다시 Default Runtime을 선택할 수 있음을 염두해 둔다.</p>\n</blockquote>",
        "contentSnippet": "silicon M1 맥북을 사용하고나서 IntelliJ를 계속 켜놓고 있으면 끝도 없이 메모리가 올라가는 이슈가 발생했다.\n현재 내 IntelliJ VM Option 에서 메모리 설정은 다음과 같다.\n(PC는 M1 Pro 16GB)\n-Xms1024m\n-Xmx4096m\n위와 같이 설정하고 IntelliJ를 켜두고 오랜 시간이 지나면 IntelliJ의 자체 Memory 분석 도구에서는 여전히 아래와 같이 정상적인 사용량이 노출되는 반면,\n\n\n실제 IntellIJ의 메모리 사용량은 다음과 같이 설정한 VM Option을 크게 초과해서 사용하는 것을 확인할 수 있다.\n\n\n16GB RAM을 가진 PC에서 14GB에 가까운 메모리를 사용중인데, 이건 더 높은 메모리 사양을 가진 맥북을 사용하면 더 크게 메모리를 점유한다.\n(테스트 결과 36GB 메모리 PC에서는 20GB를 사용한다.)\n즉, 아무리 사양이 좋은 맥북을 사용하더라도 메모리로 인한 성능 저하 문제를 피할 수가 없다.\n이 이슈를 해결하기 위해 여러 설정들을 테스트 해봤다.\n해결 방법\nYouTrack 이슈들을 확인 해보니, 이 이슈가 3년전부터 있었던 이슈였다.\nIntellij high memory usage on apple silicon M1, 7-8GB of RAM\n댓글에서 여러가지 방법들이 이야기 되었지만, 실제 효과가 있었던 방법은 하나였다.\n바로 \"IDE의 Java Runtime을 바꾸는 것\"이다.\nIntelliJ 역시 Java로 만들어진 애플리케이션이며, 이를 구동시키는데는 Java Runtime 환경 (JRE)이 필요하다.\n기본적으로 JetBrains IDE들은 IDE에 포함된 JetBrains Runtime(OpenJDK의 Fork 버전)을 사용한다.\nJetBrains Runtime은 알려진 다양한 OpenJDK 및 Oracle JDK 버그를 수정하고 더 나은 성능과 안정성을 제공하지만, 이번 경우와 같이 문제가 될 경우 변경할 수 있는 설정을 지원한다.\n우리가 변경할 버전은 JBR Vanilla이다.\n변경 하는 방법은 다음과 같다.\nCMD + Shift A 로 Actions 검색 화면에서 choose boot java 를 검색하여 Choose Boot Java Runtime for the IDE... 를 선택한다.\n\n\n현재 사용중인 버전을 확인해보면 21.0.3+13-509.4-jcef 인 것을 확인할 수 있다.\n(이건 개인 PC마다 다름)\n\n\n여기서 jcef 가 아니라 동일 버전의 vanilla JBR을 선택하면 된다.\n나 같은 경우 21.0.3b509.11 (vanilla) 를 선택했다.\n\n\n여기까지하면 설정은 끝났다.\nOK를 누르고 IntelliJ를 완전히 종료 후, 재실행 해본다.\n그리고나서 사용해보면 몇시간이 지나도 IntelliJ에서 안정적으로 메모리를 사용하는 것을 확인할 수 있다.\n\n\n\n당연히 이 설정은 이후 IntelliJ가 메모리 이슈를 해소하고 나면 다시 Default Runtime을 선택할 수 있음을 염두해 둔다.",
        "guid": "https://jojoldu.tistory.com/800",
        "categories": [
          "IDE",
          "high memory usage intellij on m1",
          "IntelliJ",
          "jetbrains",
          "webstorm",
          "메모리 누수",
          "웹스톰",
          "인텔리제이"
        ],
        "isoDate": "2024-08-19T14:40:27.000Z"
      }
    ]
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": [
      {
        "creator": "megayuchi",
        "title": "LightMap 구현전략",
        "link": "https://megayuchi.com/2024/08/22/lightmap-%ea%b5%ac%ed%98%84%ec%a0%84%eb%9e%b5/",
        "pubDate": "Thu, 22 Aug 2024 14:10:10 +0000",
        "content:encodedSnippet": "2024년 8월 22일 방송분입니다.",
        "dc:creator": "megayuchi",
        "comments": "https://megayuchi.com/2024/08/22/lightmap-%ea%b5%ac%ed%98%84%ec%a0%84%eb%9e%b5/#respond",
        "content": "2024년 8월 22일 방송분입니다.",
        "contentSnippet": "2024년 8월 22일 방송분입니다.",
        "guid": "http://megayuchi.com/?p=7047",
        "categories": [
          "Development",
          "Game Engine Development",
          "GPU"
        ],
        "isoDate": "2024-08-22T14:10:10.000Z"
      }
    ]
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "한상곤 - Sigmadream",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": []
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": [
      {
        "title": "이걸 진짜 만든다고요? 세상에 없던 게임, 샐러드게임 | 1편. BX",
        "link": "https://blog.banksalad.com/tech/banksalad-saladgame-1/",
        "pubDate": "Fri, 23 Aug 2024 00:00:00 GMT",
        "content": "“이걸 진짜 만든다고요? 🤯 ” 샐러드게임 탄생 배경 202…",
        "contentSnippet": "“이걸 진짜 만든다고요? 🤯 ” 샐러드게임 탄생 배경 202…",
        "guid": "https://blog.banksalad.com/tech/banksalad-saladgame-1/",
        "isoDate": "2024-08-23T00:00:00.000Z"
      },
      {
        "title": "이걸 진짜 만든다고요? 세상에 없던 게임, 샐러드게임 | 2편. UX",
        "link": "https://blog.banksalad.com/tech/banksalad-saladgame-2/",
        "pubDate": "Fri, 23 Aug 2024 00:00:00 GMT",
        "content": "…",
        "contentSnippet": "…",
        "guid": "https://blog.banksalad.com/tech/banksalad-saladgame-2/",
        "isoDate": "2024-08-23T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": [
      {
        "title": "AI를 활용한 주문서 생성 자동화: 카카오톡 주문을 키친보드 주문으로",
        "link": "https://spoqa.github.io/2024/08/19/ai-order-sheet.html",
        "pubDate": "2024-08-19T00:00:00.000Z",
        "author": "남경호",
        "content": "<p>안녕하세요. 스포카 백엔드팀 프로그래머 남경호입니다.</p>\n\n<p>최근 <a href=\"https://chatgpt.com/\" target=\"\\_blank\">ChatGPT</a>를 비롯한 생성형 AI가 주목받으면서 저희 스포카에서도 AI 스터디를 진행했습니다. AI에 대해 들어본 적은 있었지만, 실제로 접해본 적은 없어서 스터디를 통해 <a href=\"https://en.wikipedia.org/wiki/Prompt_engineering\" target=\"\\_blank\">프롬프트 엔지니어링</a>, <a href=\"https://en.wikipedia.org/wiki/Retrieval-augmented_generation\" target=\"\\_blank\">RAG</a>, <a href=\"https://www.langchain.com/\" target=\"\\_blank\">랭체인</a> 등의 개념을 배우고 이를 어떻게 활용할 수 있는지에 대한 기초를 익힐 수 있었습니다.</p>\n\n<p>이번 글에서는 저희가 AI를 어떻게 제품에 활용했는지 소개해 드리고자 합니다. RAG를 사용하거나 복잡한 기술을 도입한 것은 아니지만, AI 초보 개발자도 사용자의 편의를 위해 제품에 AI를 효과적으로 활용할 수 있다는 점에서 의미가 있다고 생각합니다.</p>\n\n<p>모쪼록 재미있게 봐주시길 바랍니다.</p>\n\n<h1 id=\"도입배경\">도입배경</h1>\n\n<p>키친보드를 사용하기 전, 매장의 점주님들은 유통사로 식자재를 주문할 때 주로 문자나 카카오톡을 이용했습니다.</p>\n\n<p><img src=\"/images/ai-order-sheet/kakao-order.png\" alt=\"kakao-order\" /></p>\n\n<p>이 방식에는 여러 가지 불편함이 있습니다.</p>\n\n<ul>\n  <li>유통사에서 매장의 주문 내용을 취합하고 정리하기가 어렵습니다.</li>\n  <li>매장에서 과거 주문 내역을 확인하기 어렵습니다.</li>\n  <li>유통사가 다수의 매장 주문을 취합하면서 누락되거나 잘못 정리되는 경우가 많습니다.</li>\n  <li>이로 인해 매장은 주문한 품목을 원하는 시간에 정확히 받지 못할 수 있습니다.</li>\n</ul>\n\n<p>저희 키친보드는 이러한 불편을 해소하기 위해 주문톡 서비스를 운영하고 있습니다.</p>\n\n<p><br /></p>\n\n<p>하지만 여전히 일부 매장은 카카오톡으로 유통사에 식자재를 주문하고 있습니다. 유통사는 키친보드의 편리함을 느끼고 이를 적극적으로 사용하지만, 몇몇 매장은 기존의 카카오톡 주문 방식을 고수하고 있는 것입니다.</p>\n\n<p>매장에서는 <code class=\"language-plaintext highlighter-rouge\">피망 6개, 양파 2망, 올리브오일 2개 주세요</code>와 같이 간단히 주문하는 것이 편리할 수 있습니다. 유통사가 알아서 품목을 해석하고 적절한 제품을 보내주기 때문입니다. 하지만 유통사는 매장의 주문을 해석하고 취합하는 데 많은 시간을 소모하게 됩니다. 더욱이 이러한 지식은 오랜 경험을 바탕으로 작업자들이 처리해 왔기 때문에, 작업자가 바뀌면 배송 실수가 발생할 가능성이 큽니다.</p>\n\n<p><br /></p>\n\n<p>그래서 저희 키친보드는 오래전부터 카카오톡으로 받은 주문을 어떻게 하면 손쉽게 주문톡의 주문서로 변환할 수 있을지 고민해 왔습니다. 주문톡 서비스를 처음 만들 때도 카카오톡 주문을 주문서로 생성하려는 시도도 물론 있었습니다. 일정한 패턴만 정의할 수 있다면 카카오톡 주문을 해석하고, 이를 기반으로 주문서를 생성하는 것이 가능할 것으로 생각했기 때문입니다.</p>\n\n<p>하지만 저희는 아래와 같이 매장에서 주문하는 다양한 패턴에 좌절하고 맙니다.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>피망 6개, 양파 2망, 올리브오일 2개 주세요\n</code></pre></div></div>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>다진김치1  콩나물2개 깻잎2개 계란5판 청양고추1 깐마늘1 다진마늘1 쌈무4개 날치알3개 떡사리1개 모짜치즈1개 버섯1 만두2개 맛소금1 마요네즈1개\n다진김치는 중국산으로 주세요 3kg\n</code></pre></div></div>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>맛살-2\n치즈떡-3\n연근-3\n메추리알-3\n고구마떡-2\n비엔나-3봉지\n</code></pre></div></div>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>콩나물4개 깻잎4개 날치알4개 튀김고구마1개 만두4개 슬라이스치즈1개 오이 3숙주나물 0,5 청양고추1 스위트곤1개 다진마늘1참맛기름1개 설탕1개 계란5 쌈장1개 쌈무6개 당면1개 마요네즈1개 떡사리1개 모짜치즈2개 고추맛기름1 김가루1개 김2개 짜파게티5개입 2 사세바팔로윙스틱1개 미풍1개 물엿1 마카로니1개 감자튀김 1\n레몬 4\n</code></pre></div></div>\n\n<p>어떤 매장은 품목명과 개수를 띄어쓰기도 하고, 어떤 매장은 품목명과 개수 사이에 <code class=\"language-plaintext highlighter-rouge\">-</code>를 넣기도 합니다. 또 어떤 매장은 <code class=\"language-plaintext highlighter-rouge\">00개</code>라고 표기하거나, 같은 내용의 주문에서도 다른 표기법을 사용하기도 합니다.</p>\n\n<p>결국, 저희는 다양한 주문 패턴을 단순히 조건 처리로 해결하기에는 무리가 있다고 판단했고, 카카오톡 주문을 주문톡으로 자동 변환하는 과제를 이후로 미루기로 했습니다.</p>\n\n<h1 id=\"ai-활용\">AI 활용</h1>\n\n<p>AI 스터디를 진행하면서 저희는 과거에 좌절했던 카카오톡 주문 해석 문제를 AI로 해결할 수 있다고 생각했습니다. AI를 활용하면 다양한 패턴의 문자 내용을 우리가 원하는 포맷으로 변환할 수 있고, 이를 바탕으로 주문서를 생성할 수 있을 것으로 생각했기 때문입니다.</p>\n\n<p>그래서 저희는 아래와 같이 몇 가지 사례를 기반으로 테스트를 진행했습니다.</p>\n\n<h3 id=\"사례1\">사례1</h3>\n\n<ul>\n  <li>Prompt\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Convert the given 'text' into JSON format with 'name' and 'count' as keys. Where 'name' is of type String and 'count' is of type integer.\n\ntext:\n다진김치1  콩나물2개 깻잎2개 계란5판 청양고추1 깐마늘1 다진마늘1 쌈무4개 날치알3개 떡사리1개 모짜치즈1개 버섯1 만두2개 맛소금1 마요네즈1개\n다진김치는 중국산으로 주세요 3kg\n</code></pre></div>    </div>\n  </li>\n  <li>Output\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>[\n  { \"name\": \"다진김치\", \"count\": 1 },\n  { \"name\": \"콩나물\", \"count\": 2 },\n  { \"name\": \"깻잎\", \"count\": 2 },\n  { \"name\": \"계란\", \"count\": 5 },\n  { \"name\": \"청양고추\", \"count\": 1 },\n  { \"name\": \"깐마늘\", \"count\": 1 },\n  { \"name\": \"다진마늘\", \"count\": 1 },\n  { \"name\": \"쌈무\", \"count\": 4 },\n  { \"name\": \"날치알\", \"count\": 3 },\n  { \"name\": \"떡사리\", \"count\": 1 },\n  { \"name\": \"모짜치즈\", \"count\": 1 },\n  { \"name\": \"버섯\", \"count\": 1 },\n  { \"name\": \"만두\", \"count\": 2 },\n  { \"name\": \"맛소금\", \"count\": 1 },\n  { \"name\": \"마요네즈\", \"count\": 1 }\n]\n</code></pre></div>    </div>\n  </li>\n</ul>\n\n<h3 id=\"사례2\">사례2</h3>\n\n<ul>\n  <li>Prompt\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Convert the given 'text' into JSON format with 'name' and 'count' as keys. Where 'name' is of type String and 'count' is of type integer.\n\ntext:\n콩나물 8\n깻잎 3\n청양고추 2\n깐마늘 2\n다진마늘 2\n홍고추 1\n양배추 1\n날치알 3\n만두 2\n갖다주세요\n당면 3개추가좀 해주세요 ㅠ\n</code></pre></div>    </div>\n  </li>\n  <li>Output\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>[\n  { \"name\": \"콩나물\", \"count\": 8 },\n  { \"name\": \"깻잎\", \"count\": 3 },\n  { \"name\": \"청양고추\", \"count\": 2 },\n  { \"name\": \"깐마늘\", \"count\": 2 },\n  { \"name\": \"다진마늘\", \"count\": 2 },\n  { \"name\": \"홍고추\", \"count\": 1 },\n  { \"name\": \"양배추\", \"count\": 1 },\n  { \"name\": \"날치알\", \"count\": 3 },\n  { \"name\": \"만두\", \"count\": 2 },\n  { \"name\": \"갖다주세요\", \"count\": 0 },\n  { \"name\": \"당면\", \"count\": 3 },\n  { \"name\": \"개추가좀 해주세요 ㅠ\", \"count\": 0 }\n]\n</code></pre></div>    </div>\n  </li>\n</ul>\n\n<h3 id=\"사례3\">사례3</h3>\n\n<ul>\n  <li>Prompt\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Convert the given 'text' into JSON format with 'name' and 'count' as keys. Where 'name' is of type String and 'count' is of type integer.\n\ntext:\n야채 유통사에 넣어주세요.\n새송이-1박스\n숙주나물 -1박스\n깐마늘-2봉지\n팽이버섯-1박스\n대파-1단\n치즈떡-1봉지\n메추리알-1봉지\n불고기햄-1봉지\n맛소금-1봉지\n토마토 케첩-봉지에 들은걸로 2.5킬로?? 그걸로 ?? 9봉지\n</code></pre></div>    </div>\n  </li>\n  <li>Output\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>[\n  { \"name\": \"새송이\", \"count\": 1 },\n  { \"name\": \"숙주나물\", \"count\": 1 },\n  { \"name\": \"깐마늘\", \"count\": 2 },\n  { \"name\": \"팽이버섯\", \"count\": 1 },\n  { \"name\": \"대파\", \"count\": 1 },\n  { \"name\": \"치즈떡\", \"count\": 1 },\n  { \"name\": \"메추리알\", \"count\": 1 },\n  { \"name\": \"불고기햄\", \"count\": 1 },\n  { \"name\": \"맛소금\", \"count\": 1 },\n  { \"name\": \"토마토 케첩\", \"count\": 9 }\n]\n</code></pre></div>    </div>\n  </li>\n</ul>\n\n<p><code class=\"language-plaintext highlighter-rouge\">개추가좀 해주세요 ㅠ</code>, <code class=\"language-plaintext highlighter-rouge\">갖다주세요</code> 와 같이 몇 가지 잘못 해석하는 부분은 있었지만 <code class=\"language-plaintext highlighter-rouge\">토마토 케첩-봉지에 들은걸로 2.5킬로?? 그걸로 ?? 9봉지</code>를 <code class=\"language-plaintext highlighter-rouge\">{\"name\"=\"토마토 케첩\", \"count\"=9}</code>로 인식한다든지 패턴이 일정하지 않더라도 품목명과 주문수를 원하는 대로 구분해 주는 것들을 보면 AI를 통해 충분히 카카오톡 주문 내용을 해석하여 원하는 패턴으로 변환할 수 있을 것으로 생각했습니다.</p>\n\n<h1 id=\"주문서-품목-선택\">주문서 품목 선택</h1>\n\n<p>앞에서 저희는 AI를 통해 <code class=\"language-plaintext highlighter-rouge\">품목명</code>, <code class=\"language-plaintext highlighter-rouge\">주문 건수</code>와 같이 일관된 양식으로 변환할 수 있다는 것을 알게 되었습니다. 하지만 이번에는 해석된 품목명을 키친보드에 입력된 유통사의 품목으로 변환하는 데 문제가 있었는데요.</p>\n\n<p>키친보드에서 다루는 유통사의 주문 품목은 품목명만 있는 것이 아닌 규격과 단위가 존재합니다. 예를 들어 같은 <code class=\"language-plaintext highlighter-rouge\">계란</code>이라는 품목이 있더라도 규격은 <code class=\"language-plaintext highlighter-rouge\">대란</code>, <code class=\"language-plaintext highlighter-rouge\">중란</code>, <code class=\"language-plaintext highlighter-rouge\">특란</code>과 같이 나눠질 수 있고 단위도 <code class=\"language-plaintext highlighter-rouge\">6개입</code>, <code class=\"language-plaintext highlighter-rouge\">개</code>, <code class=\"language-plaintext highlighter-rouge\">판</code>과 같이 나누어질 수 있습니다. 그래서 아래와 같이 <code class=\"language-plaintext highlighter-rouge\">계란</code>을 주문하려고 하면 다수의 품목이 검색되어 어떤 품목을 주문해야 할지 시스템이 판단하기 어렵다는 문제가 있습니다.</p>\n\n<p><img src=\"/images/ai-order-sheet/eggs.png\" alt=\"eggs\" /></p>\n\n<p>또 다른 사례로, 매장에서는 유통사가 입력해 둔 정확한 품목명을 기억하고 주문하지 않는 경우가 많습니다. 예를 들어 <code class=\"language-plaintext highlighter-rouge\">깐마늘</code>을 생각해 보겠습니다. 유통사는 <code class=\"language-plaintext highlighter-rouge\">깐마늘</code>을 그대로 저장하지 않고, <code class=\"language-plaintext highlighter-rouge\">마늘/깐(대)</code>와 같이 유통사의 규칙에 따라 품목명을 저장해두고 주문을 받고 있습니다.</p>\n\n<p>이 때문에 키친보드에서는 주문톡을 사용하는 매장이 <code class=\"language-plaintext highlighter-rouge\">깐마늘</code>이라고 검색하더라도, 유통사에서 저장한 <code class=\"language-plaintext highlighter-rouge\">마늘/깐(대)</code> 품목을 조회할 수 있도록 유사도 검색 기능을 지원하고 있습니다. (다만 유사도 검색에는 원치 않는 품목이 함께 조회될 가능성이 있다는 단점도 존재합니다)</p>\n\n<p>예를 들어 <code class=\"language-plaintext highlighter-rouge\">깐마늘</code>을 검색했을 때, 아래처럼 다양한 품목들이 조회되는 것을 볼 수 있습니다.</p>\n\n<p><img src=\"/images/ai-order-sheet/search-products.png\" alt=\"search-products\" /></p>\n\n<p>그래서 저희는 주문할 품목 선택을 시스템이 자동으로 하기보다는 사용자에게 위임하기로 했습니다. 잘못된 품목으로 주문서가 생성되는 위험보다는 매장에서 원하는 품목을 한 번 더 확인하도록 하는 것이 낫다는 판단에서입니다.</p>\n\n<p>다만, 사용자 편의를 위해 입력한 품목명과 가장 유사한 품목을 자동으로 선택하고, 최근에 주문했던 품목을 우선 선택하도록 하여 최대한 편리하게 주문서를 생성할 수 있도록 했습니다.</p>\n\n<h1 id=\"ai-주문서-생성-순서\">AI 주문서 생성 순서</h1>\n\n<p>위에서 말씀드린 내용을 기반으로 사용자가 AI 주문서를 생성하는 순서를 그려보면 아래와 같습니다.</p>\n\n<p><img src=\"/images/ai-order-sheet/ai-order-flow.png\" alt=\"ai-order-flow\" /></p>\n\n<h3 id=\"주문서-초안-생성\">주문서 초안 생성</h3>\n\n<p>먼저 사용자는 카카오톡 주문 내용을 복사해서 주문서 초안을 생성합니다.</p>\n\n<p><img src=\"/images/ai-order-sheet/create-draft.png\" alt=\"create-draft\" /></p>\n\n<h3 id=\"주문-품목-선택\">주문 품목 선택</h3>\n\n<p>앞서 “주문서 품목 선택 이슈”에서 말씀드린 바와 같이 주어진 품목명이 원하는 주문서 품목과 일치하는지 정확히 알기 힘들기 때문에 생성된 주문서 초안에서 원하는 품목을 선택합니다. 다만, 가장 많이 주문하는 품목이 먼저 선택되어 있도록 함으로써 사용자가 품목을 선택하는 행위를 최소화하였습니다.</p>\n\n<p><img src=\"/images/ai-order-sheet/select-product.png\" alt=\"select-product\" /></p>\n\n<h3 id=\"주문서-확인-및-주문\">주문서 확인 및 주문</h3>\n\n<p>사용자는 최종적으로 생성될 주문서를 확인하고 주문서를 생성할 수 있습니다. 이때 원치 않는 품목을 제거하거나 추가하여 AI가 생성해 준 품목을 토대로 기대한 주문서를 생성할 수 있게 됩니다.</p>\n\n<p><img src=\"/images/ai-order-sheet/check-order-sheet.png\" alt=\"check-order-sheet\" /></p>\n\n<h1 id=\"구현\">구현</h1>\n\n<p>이제 기술적인 측면을 살펴보겠습니다. 사실 AI를 활용한 주문서 생성 기능은 기존의 주문서 생성 기능을 크게 변경하지 않았습니다. 앞서 설명해 드린 AI 주문서 생성 순서에서, 초안을 생성하는 부분만 추가되었을 뿐이죠.</p>\n\n<p><img src=\"/images/ai-order-sheet/ai-order-flow-for-dev.png\" alt=\"ai-order-flow-for-dev\" /></p>\n\n<p>그래서 주문서 초안을 생성하는 흐름도를 조금 더 자세히 그려보면 아래와 같이 그릴 수 있습니다. 조금 더 자세한 내용은 아래에서 다루어볼게요.</p>\n\n<p><img src=\"/images/ai-order-sheet/create-draft-diagram.png\" alt=\"create-draft-diagram\" /></p>\n\n<h3 id=\"spring-ai\">Spring AI</h3>\n\n<p>AI 스터디를 진행하면서 읽었던 책은 <a href=\"https://product.kyobobook.co.kr/detail/S000212568407\" target=\"\\_blank\">랭체인으로 LLM 기반의 AI 서비스 개발하기</a>였습니다. 이 책은 LLM 기반의 AI 서비스를 예제로 쉽게 따라 할 수 있도록 가이드해 주어, AI 초보자인 저도 손쉽게 학습할 수 있었습니다. (광고 아닙니다!)</p>\n\n<p>처음 학습할 때 랭체인으로 시작했기 때문에, AI 모델에게 주문 내용을 해석해 주는 기능을 별도의 Python 서버로 구현하는 방안을 고민하기도 했습니다. 그러나 팀 정책상, 관리 포인트를 불필요하게 늘리지 않기 위해 키친보드 서비스의 서버에서 최대한 해결하는 것이 좋겠다고 판단했습니다. 그러던 중 발견한 프레임워크가 바로 Spring AI였습니다.</p>\n\n<p><a href=\"https://spring.io/projects/spring-ai\" target=\"\\_blank\">Spring AI</a>는 AI 엔지니어링에 특화된 프레임워크로, 랭체인만큼 다양한 기능을 제공하지는 않지만, 저희가 구현하고자 했던 카카오톡 주문 내용을 원하는 형식으로 변환하는 데는 부족함이 없었습니다. 또한, 스프링과 쉽게 통합할 수 있었기에 더할 나위 없는 선택지였습니다. (자세한 사용법은 <a href=\"https://docs.spring.io/spring-ai/reference/getting-started.html\" target=\"\\_blank\">공식 문서</a>를 참고해 주세요!)</p>\n\n<h3 id=\"주문서-초안-생성-로직\">주문서 초안 생성 로직</h3>\n\n<p>추문서 초안 생성을 위한 로직을 보면 아래와 같습니다.</p>\n\n<p><img src=\"/images/ai-order-sheet/create-draft-data-flow.png\" alt=\"create-draft-data-flow\" /></p>\n\n<p>주문 내용을 해석해 줄 <code class=\"language-plaintext highlighter-rouge\">MessageInterpreter</code>가 AI 서비스에 해석요청을 보내고 그 결과를 바탕으로 유통사의 품목을 조회해 초안을 생성해 준다는 것을 알 수 있습니다.</p>\n\n<p>저희는 <code class=\"language-plaintext highlighter-rouge\">MessageInterpreter</code>의 구현 클래스에서 Spring AI를 활용하였습니다. 구현 클래스인 <code class=\"language-plaintext highlighter-rouge\">AIMessageInterpreter</code>를 보면 상당히 단순한 것을 볼 수 있습니다. Spring AI는 <code class=\"language-plaintext highlighter-rouge\">ChatClient</code>를 통해 AI 서비스와의 Prompt 통신을 단순화한 것을 볼 수 있습니다. 또한, <code class=\"language-plaintext highlighter-rouge\">responseEntity</code> 함수와 같이 응답 결과를 원하는 데이터 구조로 손쉽게 변환할 수 있도록 해주기 때문에 AI 채팅의 결과를 원하는 데이터 객체로 변환하기 위한 복잡하고 번거로운 코드를 작성하지 않아도 된다는 장점도 있습니다.</p>\n\n<p>Java가 아닌 Kotlin으로 Spring AI를 사용하시는 분들께 드리는 한가지 팁은 <code class=\"language-plaintext highlighter-rouge\">responseEntity</code>의 반환 타입인 <code class=\"language-plaintext highlighter-rouge\">OrderProduct</code>를 정의할 때 <code class=\"language-plaintext highlighter-rouge\">@JvmRecord</code>를 선언해 주지 않으면 오류가 발생하니 이 부분은 기억해 두시면 좋겠습니다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kd\">interface</span> <span class=\"nc\">MessageInterpreter</span> <span class=\"p\">{</span>\n    <span class=\"k\">fun</span> <span class=\"nf\">interpretOrderMessage</span><span class=\"p\">(</span><span class=\"n\">message</span><span class=\"p\">:</span> <span class=\"nc\">String</span><span class=\"p\">):</span> <span class=\"nc\">List</span><span class=\"p\">&lt;</span><span class=\"nc\">OrderProduct</span><span class=\"p\">&gt;</span>\n<span class=\"p\">}</span>\n\n<span class=\"nd\">@Component</span>\n<span class=\"kd\">class</span> <span class=\"nc\">AIMessageInterpreter</span><span class=\"p\">(</span>\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">openAiChatClient</span><span class=\"p\">:</span> <span class=\"nc\">ChatClient</span><span class=\"p\">,</span>\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">aiChatHistoryRepository</span><span class=\"p\">:</span> <span class=\"nc\">AIChatHistoryRepository</span><span class=\"p\">,</span>\n<span class=\"p\">)</span> <span class=\"p\">:</span> <span class=\"nc\">MessageInterpreter</span> <span class=\"p\">{</span>\n    <span class=\"k\">override</span> <span class=\"k\">fun</span> <span class=\"nf\">interpretOrderMessage</span><span class=\"p\">(</span><span class=\"n\">message</span><span class=\"p\">:</span> <span class=\"nc\">String</span><span class=\"p\">):</span> <span class=\"nc\">List</span><span class=\"p\">&lt;</span><span class=\"nc\">OrderProduct</span><span class=\"p\">&gt;</span> <span class=\"p\">{</span>\n        <span class=\"kd\">val</span> <span class=\"py\">promptMessage</span> <span class=\"p\">=</span>\n            <span class=\"s\">\"\"\"\n            |Convert the given 'text' into JSON format with 'name' and 'count' as keys. Where 'name' is of type String and 'count' is of type integer.\n\n            |text:\n            |$message\n            \"\"\"</span><span class=\"p\">.</span><span class=\"nf\">trimMargin</span><span class=\"p\">()</span>\n\n        <span class=\"kd\">val</span> <span class=\"py\">response</span> <span class=\"p\">=</span>\n            <span class=\"n\">openAiChatClient</span>\n                <span class=\"p\">.</span><span class=\"nf\">prompt</span><span class=\"p\">()</span>\n                <span class=\"p\">.</span><span class=\"nf\">user</span><span class=\"p\">(</span><span class=\"n\">promptMessage</span><span class=\"p\">)</span>\n                <span class=\"p\">.</span><span class=\"nf\">call</span><span class=\"p\">()</span>\n                <span class=\"p\">.</span><span class=\"nf\">responseEntity</span><span class=\"p\">(</span><span class=\"n\">parameterizedTypeRef</span><span class=\"p\">&lt;</span><span class=\"nc\">List</span><span class=\"p\">&lt;</span><span class=\"nc\">OrderProduct</span><span class=\"p\">&gt;&gt;())</span>\n\n        <span class=\"nf\">saveHistory</span><span class=\"p\">(</span><span class=\"n\">message</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">)</span>\n\n        <span class=\"k\">return</span> <span class=\"n\">response</span><span class=\"p\">.</span><span class=\"n\">entity</span>\n    <span class=\"p\">}</span>\n    \n    <span class=\"c1\">// 생략...</span>\n<span class=\"p\">}</span>\n\n<span class=\"nd\">@JvmRecord</span>\n<span class=\"kd\">data class</span> <span class=\"nc\">OrderProduct</span><span class=\"p\">(</span>\n    <span class=\"kd\">val</span> <span class=\"py\">name</span><span class=\"p\">:</span> <span class=\"nc\">String</span><span class=\"p\">,</span>\n    <span class=\"kd\">val</span> <span class=\"py\">count</span><span class=\"p\">:</span> <span class=\"nc\">Float</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n</code></pre></div></div>\n\n<h3 id=\"주문-품목-병렬-조회\">주문 품목 병렬 조회</h3>\n\n<p>위에서 보여드린 예시처럼, 매장에서는 한 번에 여러 품목을 주문하는 경우가 많습니다. 예를 들어, 주문서 품목을 조회하는 데 1초가 걸린다고 가정하면, 30개의 품목을 조회하는 로직을 아래와 같이 구현했을 때, 주문서 초안을 생성하는 데 최소 30초가 소요될 것입니다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">fun</span> <span class=\"nf\">getOrderSheetDraftProducts</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">:</span> <span class=\"nc\">OrderSheetDraftProductsSearchData</span><span class=\"p\">):</span> <span class=\"nc\">List</span><span class=\"p\">&lt;</span><span class=\"nc\">OrderSheetDraftProduct</span><span class=\"p\">&gt;</span> <span class=\"p\">{</span>\n    <span class=\"kd\">val</span> <span class=\"py\">orderProducts</span> <span class=\"p\">=</span> <span class=\"n\">aiMessageInterpreter</span><span class=\"p\">.</span><span class=\"nf\">interpretOrderMessage</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">.</span><span class=\"n\">text</span><span class=\"p\">)</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">orderProducts</span><span class=\"p\">.</span><span class=\"nf\">map</span> <span class=\"p\">{</span>\n        <span class=\"kd\">val</span> <span class=\"py\">products</span> <span class=\"p\">=</span> <span class=\"nf\">searchOrderableProducts</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">name</span><span class=\"p\">)</span>\n\n        <span class=\"nc\">OrderSheetDraftProduct</span><span class=\"p\">(</span>\n            <span class=\"n\">name</span> <span class=\"p\">=</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">name</span><span class=\"p\">,</span>\n            <span class=\"n\">count</span> <span class=\"p\">=</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">count</span><span class=\"p\">,</span>\n            <span class=\"n\">foundProducts</span> <span class=\"p\">=</span> <span class=\"n\">products</span><span class=\"p\">,</span>\n        <span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>당연한 이야기겠지만, 주문서 초안을 생성하는 데 시간이 오래 걸리면 사용자는 불편함을 느껴 AI 주문서 기능을 더 이상 적극적으로 사용하지 않게 될 수 있습니다. 이를 방지하기 위해 저희는 병렬 처리 방식을 도입하여 주문서를 조회하고 초안을 생성함으로써, 최대한 짧은 시간 안에 사용자의 요청을 처리할 수 있도록 했습니다.</p>\n\n<p>아래와 같이 코드를 작성하면 다수의 품목을 조회하더라도 약 1초 만에 전체 품목의 조회 결과를 반환할 수 있습니다.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">fun</span> <span class=\"nf\">getOrderSheetDraftProducts</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">:</span> <span class=\"nc\">OrderSheetDraftProductsSearchData</span><span class=\"p\">):</span> <span class=\"nc\">List</span><span class=\"p\">&lt;</span><span class=\"nc\">OrderSheetDraftProduct</span><span class=\"p\">&gt;</span> <span class=\"p\">=</span>\n    <span class=\"nf\">runBlocking</span> <span class=\"p\">{</span>\n        <span class=\"kd\">val</span> <span class=\"py\">orderProducts</span> <span class=\"p\">=</span> <span class=\"n\">aiMessageInterpreter</span><span class=\"p\">.</span><span class=\"nf\">interpretOrderMessage</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">.</span><span class=\"n\">text</span><span class=\"p\">)</span>\n\n        <span class=\"n\">orderProducts</span><span class=\"p\">.</span><span class=\"nf\">map</span> <span class=\"p\">{</span>\n            <span class=\"nf\">async</span> <span class=\"p\">{</span>\n                <span class=\"kd\">val</span> <span class=\"py\">products</span> <span class=\"p\">=</span> <span class=\"nf\">searchOrderableProducts</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">name</span><span class=\"p\">)</span>\n\n                <span class=\"nc\">OrderSheetDraftProduct</span><span class=\"p\">(</span>\n                    <span class=\"n\">name</span> <span class=\"p\">=</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">name</span><span class=\"p\">,</span>\n                    <span class=\"n\">count</span> <span class=\"p\">=</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"n\">count</span><span class=\"p\">,</span>\n                    <span class=\"n\">foundProducts</span> <span class=\"p\">=</span> <span class=\"n\">products</span><span class=\"p\">,</span>\n                <span class=\"p\">)</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}.</span><span class=\"nf\">awaitAll</span><span class=\"p\">()</span>\n    <span class=\"p\">}</span>\n</code></pre></div></div>\n\n<h1 id=\"마무리\">마무리</h1>\n\n<p>지금까지 Spring AI를 활용하여 카카오톡 주문을 키친보드 주문서로 자동 생성하는 기능을 구현한 사례를 소개해 드렸습니다. 비록 이번 구현이 단순한 수준이어서 AI 도입 사례로 소개하기에 다소 민망할 수 있지만, 이 과정에서 저희가 가진 문제를 어떻게 해결할지 고민한 점과, AI 도입이 생각만큼 복잡하거나 어려운 일이 아니라는 점을 봐주시면 좋겠습니다.</p>\n\n<p>최근 OpenAI에서 <a href=\"https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/\" target=\"\\_blank\">GPT-4o-mini 모델이 출시</a>되어, 저희가 구현한 것처럼 경량 모델이 필요한 경우에는 GPT-3.5 Turbo 모델보다 비용 효율적이고 다양한 기능을 사용할 수 있게 되었습니다. 그래서 앞으로 이미지 기반 주문서 생성 기능도 도입할 계획입니다. 이를 통해, 유통사에서 화이트보드나 손 글씨로 작성해 카카오톡으로 보내던 주문 요청을 키친보드로 쉽게 전환할 수 있도록 할 예정입니다. (생각보다 변환 결과가 괜찮았습니다!)</p>\n\n<p>또한, 아직 경험이 부족하여 키친보드의 데이터를 사전 학습시켜 주문서를 생성하는 RAG 방식을 도입하지는 못했지만, 더 나은 기능을 제공할 아이디어가 떠 오른다면, 조금 더 학습하여 RAG 방식을 도입해 AI를 조금 더 풍부하게 활용해 보고 싶습니다.</p>\n\n<p>또 다른 사용 사례가 생기면, 다음에 더 유익한 글로 찾아뵙겠습니다.</p>\n\n<p>긴 글 읽어주셔서 감사합니다.</p>\n",
        "contentSnippet": "안녕하세요. 스포카 백엔드팀 프로그래머 남경호입니다.\n최근 ChatGPT를 비롯한 생성형 AI가 주목받으면서 저희 스포카에서도 AI 스터디를 진행했습니다. AI에 대해 들어본 적은 있었지만, 실제로 접해본 적은 없어서 스터디를 통해 프롬프트 엔지니어링, RAG, 랭체인 등의 개념을 배우고 이를 어떻게 활용할 수 있는지에 대한 기초를 익힐 수 있었습니다.\n이번 글에서는 저희가 AI를 어떻게 제품에 활용했는지 소개해 드리고자 합니다. RAG를 사용하거나 복잡한 기술을 도입한 것은 아니지만, AI 초보 개발자도 사용자의 편의를 위해 제품에 AI를 효과적으로 활용할 수 있다는 점에서 의미가 있다고 생각합니다.\n모쪼록 재미있게 봐주시길 바랍니다.\n도입배경\n키친보드를 사용하기 전, 매장의 점주님들은 유통사로 식자재를 주문할 때 주로 문자나 카카오톡을 이용했습니다.\n\n이 방식에는 여러 가지 불편함이 있습니다.\n유통사에서 매장의 주문 내용을 취합하고 정리하기가 어렵습니다.\n매장에서 과거 주문 내역을 확인하기 어렵습니다.\n유통사가 다수의 매장 주문을 취합하면서 누락되거나 잘못 정리되는 경우가 많습니다.\n이로 인해 매장은 주문한 품목을 원하는 시간에 정확히 받지 못할 수 있습니다.\n저희 키친보드는 이러한 불편을 해소하기 위해 주문톡 서비스를 운영하고 있습니다.\n\n하지만 여전히 일부 매장은 카카오톡으로 유통사에 식자재를 주문하고 있습니다. 유통사는 키친보드의 편리함을 느끼고 이를 적극적으로 사용하지만, 몇몇 매장은 기존의 카카오톡 주문 방식을 고수하고 있는 것입니다.\n매장에서는 피망 6개, 양파 2망, 올리브오일 2개 주세요와 같이 간단히 주문하는 것이 편리할 수 있습니다. 유통사가 알아서 품목을 해석하고 적절한 제품을 보내주기 때문입니다. 하지만 유통사는 매장의 주문을 해석하고 취합하는 데 많은 시간을 소모하게 됩니다. 더욱이 이러한 지식은 오랜 경험을 바탕으로 작업자들이 처리해 왔기 때문에, 작업자가 바뀌면 배송 실수가 발생할 가능성이 큽니다.\n\n그래서 저희 키친보드는 오래전부터 카카오톡으로 받은 주문을 어떻게 하면 손쉽게 주문톡의 주문서로 변환할 수 있을지 고민해 왔습니다. 주문톡 서비스를 처음 만들 때도 카카오톡 주문을 주문서로 생성하려는 시도도 물론 있었습니다. 일정한 패턴만 정의할 수 있다면 카카오톡 주문을 해석하고, 이를 기반으로 주문서를 생성하는 것이 가능할 것으로 생각했기 때문입니다.\n하지만 저희는 아래와 같이 매장에서 주문하는 다양한 패턴에 좌절하고 맙니다.\n\n피망 6개, 양파 2망, 올리브오일 2개 주세요\n\n\n\n다진김치1  콩나물2개 깻잎2개 계란5판 청양고추1 깐마늘1 다진마늘1 쌈무4개 날치알3개 떡사리1개 모짜치즈1개 버섯1 만두2개 맛소금1 마요네즈1개\n다진김치는 중국산으로 주세요 3kg\n\n\n\n맛살-2\n치즈떡-3\n연근-3\n메추리알-3\n고구마떡-2\n비엔나-3봉지\n\n\n\n콩나물4개 깻잎4개 날치알4개 튀김고구마1개 만두4개 슬라이스치즈1개 오이 3숙주나물 0,5 청양고추1 스위트곤1개 다진마늘1참맛기름1개 설탕1개 계란5 쌈장1개 쌈무6개 당면1개 마요네즈1개 떡사리1개 모짜치즈2개 고추맛기름1 김가루1개 김2개 짜파게티5개입 2 사세바팔로윙스틱1개 미풍1개 물엿1 마카로니1개 감자튀김 1\n레몬 4\n\n\n어떤 매장은 품목명과 개수를 띄어쓰기도 하고, 어떤 매장은 품목명과 개수 사이에 -를 넣기도 합니다. 또 어떤 매장은 00개라고 표기하거나, 같은 내용의 주문에서도 다른 표기법을 사용하기도 합니다.\n결국, 저희는 다양한 주문 패턴을 단순히 조건 처리로 해결하기에는 무리가 있다고 판단했고, 카카오톡 주문을 주문톡으로 자동 변환하는 과제를 이후로 미루기로 했습니다.\nAI 활용\nAI 스터디를 진행하면서 저희는 과거에 좌절했던 카카오톡 주문 해석 문제를 AI로 해결할 수 있다고 생각했습니다. AI를 활용하면 다양한 패턴의 문자 내용을 우리가 원하는 포맷으로 변환할 수 있고, 이를 바탕으로 주문서를 생성할 수 있을 것으로 생각했기 때문입니다.\n그래서 저희는 아래와 같이 몇 가지 사례를 기반으로 테스트를 진행했습니다.\n사례1\nPrompt\n    \n\nConvert the given 'text' into JSON format with 'name' and 'count' as keys. Where 'name' is of type String and 'count' is of type integer.\n\ntext:\n다진김치1  콩나물2개 깻잎2개 계란5판 청양고추1 깐마늘1 다진마늘1 쌈무4개 날치알3개 떡사리1개 모짜치즈1개 버섯1 만두2개 맛소금1 마요네즈1개\n다진김치는 중국산으로 주세요 3kg\n\n    \nOutput\n    \n\n[\n  { \"name\": \"다진김치\", \"count\": 1 },\n  { \"name\": \"콩나물\", \"count\": 2 },\n  { \"name\": \"깻잎\", \"count\": 2 },\n  { \"name\": \"계란\", \"count\": 5 },\n  { \"name\": \"청양고추\", \"count\": 1 },\n  { \"name\": \"깐마늘\", \"count\": 1 },\n  { \"name\": \"다진마늘\", \"count\": 1 },\n  { \"name\": \"쌈무\", \"count\": 4 },\n  { \"name\": \"날치알\", \"count\": 3 },\n  { \"name\": \"떡사리\", \"count\": 1 },\n  { \"name\": \"모짜치즈\", \"count\": 1 },\n  { \"name\": \"버섯\", \"count\": 1 },\n  { \"name\": \"만두\", \"count\": 2 },\n  { \"name\": \"맛소금\", \"count\": 1 },\n  { \"name\": \"마요네즈\", \"count\": 1 }\n]\n\n    \n사례2\nPrompt\n    \n\nConvert the given 'text' into JSON format with 'name' and 'count' as keys. Where 'name' is of type String and 'count' is of type integer.\n\ntext:\n콩나물 8\n깻잎 3\n청양고추 2\n깐마늘 2\n다진마늘 2\n홍고추 1\n양배추 1\n날치알 3\n만두 2\n갖다주세요\n당면 3개추가좀 해주세요 ㅠ\n\n    \nOutput\n    \n\n[\n  { \"name\": \"콩나물\", \"count\": 8 },\n  { \"name\": \"깻잎\", \"count\": 3 },\n  { \"name\": \"청양고추\", \"count\": 2 },\n  { \"name\": \"깐마늘\", \"count\": 2 },\n  { \"name\": \"다진마늘\", \"count\": 2 },\n  { \"name\": \"홍고추\", \"count\": 1 },\n  { \"name\": \"양배추\", \"count\": 1 },\n  { \"name\": \"날치알\", \"count\": 3 },\n  { \"name\": \"만두\", \"count\": 2 },\n  { \"name\": \"갖다주세요\", \"count\": 0 },\n  { \"name\": \"당면\", \"count\": 3 },\n  { \"name\": \"개추가좀 해주세요 ㅠ\", \"count\": 0 }\n]\n\n    \n사례3\nPrompt\n    \n\nConvert the given 'text' into JSON format with 'name' and 'count' as keys. Where 'name' is of type String and 'count' is of type integer.\n\ntext:\n야채 유통사에 넣어주세요.\n새송이-1박스\n숙주나물 -1박스\n깐마늘-2봉지\n팽이버섯-1박스\n대파-1단\n치즈떡-1봉지\n메추리알-1봉지\n불고기햄-1봉지\n맛소금-1봉지\n토마토 케첩-봉지에 들은걸로 2.5킬로?? 그걸로 ?? 9봉지\n\n    \nOutput\n    \n\n[\n  { \"name\": \"새송이\", \"count\": 1 },\n  { \"name\": \"숙주나물\", \"count\": 1 },\n  { \"name\": \"깐마늘\", \"count\": 2 },\n  { \"name\": \"팽이버섯\", \"count\": 1 },\n  { \"name\": \"대파\", \"count\": 1 },\n  { \"name\": \"치즈떡\", \"count\": 1 },\n  { \"name\": \"메추리알\", \"count\": 1 },\n  { \"name\": \"불고기햄\", \"count\": 1 },\n  { \"name\": \"맛소금\", \"count\": 1 },\n  { \"name\": \"토마토 케첩\", \"count\": 9 }\n]\n\n    \n개추가좀 해주세요 ㅠ, 갖다주세요 와 같이 몇 가지 잘못 해석하는 부분은 있었지만 토마토 케첩-봉지에 들은걸로 2.5킬로?? 그걸로 ?? 9봉지를 {\"name\"=\"토마토 케첩\", \"count\"=9}로 인식한다든지 패턴이 일정하지 않더라도 품목명과 주문수를 원하는 대로 구분해 주는 것들을 보면 AI를 통해 충분히 카카오톡 주문 내용을 해석하여 원하는 패턴으로 변환할 수 있을 것으로 생각했습니다.\n주문서 품목 선택\n앞에서 저희는 AI를 통해 품목명, 주문 건수와 같이 일관된 양식으로 변환할 수 있다는 것을 알게 되었습니다. 하지만 이번에는 해석된 품목명을 키친보드에 입력된 유통사의 품목으로 변환하는 데 문제가 있었는데요.\n키친보드에서 다루는 유통사의 주문 품목은 품목명만 있는 것이 아닌 규격과 단위가 존재합니다. 예를 들어 같은 계란이라는 품목이 있더라도 규격은 대란, 중란, 특란과 같이 나눠질 수 있고 단위도 6개입, 개, 판과 같이 나누어질 수 있습니다. 그래서 아래와 같이 계란을 주문하려고 하면 다수의 품목이 검색되어 어떤 품목을 주문해야 할지 시스템이 판단하기 어렵다는 문제가 있습니다.\n\n또 다른 사례로, 매장에서는 유통사가 입력해 둔 정확한 품목명을 기억하고 주문하지 않는 경우가 많습니다. 예를 들어 깐마늘을 생각해 보겠습니다. 유통사는 깐마늘을 그대로 저장하지 않고, 마늘/깐(대)와 같이 유통사의 규칙에 따라 품목명을 저장해두고 주문을 받고 있습니다.\n이 때문에 키친보드에서는 주문톡을 사용하는 매장이 깐마늘이라고 검색하더라도, 유통사에서 저장한 마늘/깐(대) 품목을 조회할 수 있도록 유사도 검색 기능을 지원하고 있습니다. (다만 유사도 검색에는 원치 않는 품목이 함께 조회될 가능성이 있다는 단점도 존재합니다)\n예를 들어 깐마늘을 검색했을 때, 아래처럼 다양한 품목들이 조회되는 것을 볼 수 있습니다.\n\n그래서 저희는 주문할 품목 선택을 시스템이 자동으로 하기보다는 사용자에게 위임하기로 했습니다. 잘못된 품목으로 주문서가 생성되는 위험보다는 매장에서 원하는 품목을 한 번 더 확인하도록 하는 것이 낫다는 판단에서입니다.\n다만, 사용자 편의를 위해 입력한 품목명과 가장 유사한 품목을 자동으로 선택하고, 최근에 주문했던 품목을 우선 선택하도록 하여 최대한 편리하게 주문서를 생성할 수 있도록 했습니다.\nAI 주문서 생성 순서\n위에서 말씀드린 내용을 기반으로 사용자가 AI 주문서를 생성하는 순서를 그려보면 아래와 같습니다.\n\n주문서 초안 생성\n먼저 사용자는 카카오톡 주문 내용을 복사해서 주문서 초안을 생성합니다.\n\n주문 품목 선택\n앞서 “주문서 품목 선택 이슈”에서 말씀드린 바와 같이 주어진 품목명이 원하는 주문서 품목과 일치하는지 정확히 알기 힘들기 때문에 생성된 주문서 초안에서 원하는 품목을 선택합니다. 다만, 가장 많이 주문하는 품목이 먼저 선택되어 있도록 함으로써 사용자가 품목을 선택하는 행위를 최소화하였습니다.\n\n주문서 확인 및 주문\n사용자는 최종적으로 생성될 주문서를 확인하고 주문서를 생성할 수 있습니다. 이때 원치 않는 품목을 제거하거나 추가하여 AI가 생성해 준 품목을 토대로 기대한 주문서를 생성할 수 있게 됩니다.\n\n구현\n이제 기술적인 측면을 살펴보겠습니다. 사실 AI를 활용한 주문서 생성 기능은 기존의 주문서 생성 기능을 크게 변경하지 않았습니다. 앞서 설명해 드린 AI 주문서 생성 순서에서, 초안을 생성하는 부분만 추가되었을 뿐이죠.\n\n그래서 주문서 초안을 생성하는 흐름도를 조금 더 자세히 그려보면 아래와 같이 그릴 수 있습니다. 조금 더 자세한 내용은 아래에서 다루어볼게요.\n\nSpring AI\nAI 스터디를 진행하면서 읽었던 책은 랭체인으로 LLM 기반의 AI 서비스 개발하기였습니다. 이 책은 LLM 기반의 AI 서비스를 예제로 쉽게 따라 할 수 있도록 가이드해 주어, AI 초보자인 저도 손쉽게 학습할 수 있었습니다. (광고 아닙니다!)\n처음 학습할 때 랭체인으로 시작했기 때문에, AI 모델에게 주문 내용을 해석해 주는 기능을 별도의 Python 서버로 구현하는 방안을 고민하기도 했습니다. 그러나 팀 정책상, 관리 포인트를 불필요하게 늘리지 않기 위해 키친보드 서비스의 서버에서 최대한 해결하는 것이 좋겠다고 판단했습니다. 그러던 중 발견한 프레임워크가 바로 Spring AI였습니다.\nSpring AI는 AI 엔지니어링에 특화된 프레임워크로, 랭체인만큼 다양한 기능을 제공하지는 않지만, 저희가 구현하고자 했던 카카오톡 주문 내용을 원하는 형식으로 변환하는 데는 부족함이 없었습니다. 또한, 스프링과 쉽게 통합할 수 있었기에 더할 나위 없는 선택지였습니다. (자세한 사용법은 공식 문서를 참고해 주세요!)\n주문서 초안 생성 로직\n추문서 초안 생성을 위한 로직을 보면 아래와 같습니다.\n\n주문 내용을 해석해 줄 MessageInterpreter가 AI 서비스에 해석요청을 보내고 그 결과를 바탕으로 유통사의 품목을 조회해 초안을 생성해 준다는 것을 알 수 있습니다.\n저희는 MessageInterpreter의 구현 클래스에서 Spring AI를 활용하였습니다. 구현 클래스인 AIMessageInterpreter를 보면 상당히 단순한 것을 볼 수 있습니다. Spring AI는 ChatClient를 통해 AI 서비스와의 Prompt 통신을 단순화한 것을 볼 수 있습니다. 또한, responseEntity 함수와 같이 응답 결과를 원하는 데이터 구조로 손쉽게 변환할 수 있도록 해주기 때문에 AI 채팅의 결과를 원하는 데이터 객체로 변환하기 위한 복잡하고 번거로운 코드를 작성하지 않아도 된다는 장점도 있습니다.\nJava가 아닌 Kotlin으로 Spring AI를 사용하시는 분들께 드리는 한가지 팁은 responseEntity의 반환 타입인 OrderProduct를 정의할 때 @JvmRecord를 선언해 주지 않으면 오류가 발생하니 이 부분은 기억해 두시면 좋겠습니다.\n\ninterface MessageInterpreter {\n    fun interpretOrderMessage(message: String): List<OrderProduct>\n}\n\n@Component\nclass AIMessageInterpreter(\n    private val openAiChatClient: ChatClient,\n    private val aiChatHistoryRepository: AIChatHistoryRepository,\n) : MessageInterpreter {\n    override fun interpretOrderMessage(message: String): List<OrderProduct> {\n        val promptMessage =\n            \"\"\"\n            |Convert the given 'text' into JSON format with 'name' and 'count' as keys. Where 'name' is of type String and 'count' is of type integer.\n\n            |text:\n            |$message\n            \"\"\".trimMargin()\n\n        val response =\n            openAiChatClient\n                .prompt()\n                .user(promptMessage)\n                .call()\n                .responseEntity(parameterizedTypeRef<List<OrderProduct>>())\n\n        saveHistory(message, response)\n\n        return response.entity\n    }\n    \n    // 생략...\n}\n\n@JvmRecord\ndata class OrderProduct(\n    val name: String,\n    val count: Float,\n)\n\n\n주문 품목 병렬 조회\n위에서 보여드린 예시처럼, 매장에서는 한 번에 여러 품목을 주문하는 경우가 많습니다. 예를 들어, 주문서 품목을 조회하는 데 1초가 걸린다고 가정하면, 30개의 품목을 조회하는 로직을 아래와 같이 구현했을 때, 주문서 초안을 생성하는 데 최소 30초가 소요될 것입니다.\n\nfun getOrderSheetDraftProducts(data: OrderSheetDraftProductsSearchData): List<OrderSheetDraftProduct> {\n    val orderProducts = aiMessageInterpreter.interpretOrderMessage(data.text)\n\n    return orderProducts.map {\n        val products = searchOrderableProducts(data, it.name)\n\n        OrderSheetDraftProduct(\n            name = it.name,\n            count = it.count,\n            foundProducts = products,\n        )\n    }\n}\n\n\n당연한 이야기겠지만, 주문서 초안을 생성하는 데 시간이 오래 걸리면 사용자는 불편함을 느껴 AI 주문서 기능을 더 이상 적극적으로 사용하지 않게 될 수 있습니다. 이를 방지하기 위해 저희는 병렬 처리 방식을 도입하여 주문서를 조회하고 초안을 생성함으로써, 최대한 짧은 시간 안에 사용자의 요청을 처리할 수 있도록 했습니다.\n아래와 같이 코드를 작성하면 다수의 품목을 조회하더라도 약 1초 만에 전체 품목의 조회 결과를 반환할 수 있습니다.\n\nfun getOrderSheetDraftProducts(data: OrderSheetDraftProductsSearchData): List<OrderSheetDraftProduct> =\n    runBlocking {\n        val orderProducts = aiMessageInterpreter.interpretOrderMessage(data.text)\n\n        orderProducts.map {\n            async {\n                val products = searchOrderableProducts(data, it.name)\n\n                OrderSheetDraftProduct(\n                    name = it.name,\n                    count = it.count,\n                    foundProducts = products,\n                )\n            }\n        }.awaitAll()\n    }\n\n\n마무리\n지금까지 Spring AI를 활용하여 카카오톡 주문을 키친보드 주문서로 자동 생성하는 기능을 구현한 사례를 소개해 드렸습니다. 비록 이번 구현이 단순한 수준이어서 AI 도입 사례로 소개하기에 다소 민망할 수 있지만, 이 과정에서 저희가 가진 문제를 어떻게 해결할지 고민한 점과, AI 도입이 생각만큼 복잡하거나 어려운 일이 아니라는 점을 봐주시면 좋겠습니다.\n최근 OpenAI에서 GPT-4o-mini 모델이 출시되어, 저희가 구현한 것처럼 경량 모델이 필요한 경우에는 GPT-3.5 Turbo 모델보다 비용 효율적이고 다양한 기능을 사용할 수 있게 되었습니다. 그래서 앞으로 이미지 기반 주문서 생성 기능도 도입할 계획입니다. 이를 통해, 유통사에서 화이트보드나 손 글씨로 작성해 카카오톡으로 보내던 주문 요청을 키친보드로 쉽게 전환할 수 있도록 할 예정입니다. (생각보다 변환 결과가 괜찮았습니다!)\n또한, 아직 경험이 부족하여 키친보드의 데이터를 사전 학습시켜 주문서를 생성하는 RAG 방식을 도입하지는 못했지만, 더 나은 기능을 제공할 아이디어가 떠 오른다면, 조금 더 학습하여 RAG 방식을 도입해 AI를 조금 더 풍부하게 활용해 보고 싶습니다.\n또 다른 사용 사례가 생기면, 다음에 더 유익한 글로 찾아뵙겠습니다.\n긴 글 읽어주셔서 감사합니다.",
        "id": "https://spoqa.github.io/2024/08/19/ai-order-sheet.html",
        "isoDate": "2024-08-19T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "이한",
    "category": "개인",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": [
      {
        "creator": "호돌맨",
        "title": "결혼",
        "link": "https://hodolman.com/62",
        "pubDate": "Sun, 18 Aug 2024 16:27:26 +0900",
        "author": "호돌맨",
        "comments": "https://hodolman.com/62#entry62comment",
        "content": "<p><figure class=\"imageblock widthContent\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"DALL&amp;middot;E 2024-08-18 16.29.35 - A symbolic image representing the themes of development, progress, and collaboration. The image features two intertwined paths, one representing softw.webp\" data-origin-width=\"1024\" data-origin-height=\"1024\"><span data-url=\"https://blog.kakaocdn.net/dn/boYn6Y/btsI7nElwKw/XxNItlbE5vxUIK3O1jUKck/img.webp\" data-phocus=\"https://blog.kakaocdn.net/dn/boYn6Y/btsI7nElwKw/XxNItlbE5vxUIK3O1jUKck/img.webp\"><img src=\"https://blog.kakaocdn.net/dn/boYn6Y/btsI7nElwKw/XxNItlbE5vxUIK3O1jUKck/img.webp\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FboYn6Y%2FbtsI7nElwKw%2FXxNItlbE5vxUIK3O1jUKck%2Fimg.webp\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" data-filename=\"DALL&middot;E 2024-08-18 16.29.35 - A symbolic image representing the themes of development, progress, and collaboration. The image features two intertwined paths, one representing softw.webp\" data-origin-width=\"1024\" data-origin-height=\"1024\"/></span></figure>\n</p>\n<h3 style=\"text-align: left;\" data-ke-size=\"size23\"><b>제목: 결혼</b></h3>\n<p style=\"text-align: left;\" data-ke-size=\"size14\">지은이: 호돌맨</p>\n<p style=\"text-align: left;\" data-ke-size=\"size16\">우선배포를 하자<br />아무런 걱정 없이 배포를 하자</p>\n<p style=\"text-align: left;\" data-ke-size=\"size16\">오래 계산하지 말고<br />자주 실패하는 우리가 되자</p>\n<p style=\"text-align: left;\" data-ke-size=\"size16\">두려운 생각에 완벽해지고 싶어도<br />멀리 꿈꾸고 작은 것부터 시작하자</p>\n<p style=\"text-align: left;\" data-ke-size=\"size16\">욕심을 줄이고<br />욕망을 같이 꿈꾸는 사이<br />그래<br />적게 상처받고 빠르게 익숙해질 수 있는<br />우선배포를 하자</p>",
        "contentSnippet": "제목: 결혼\n지은이: 호돌맨\n우선배포를 하자\n아무런 걱정 없이 배포를 하자\n오래 계산하지 말고\n자주 실패하는 우리가 되자\n두려운 생각에 완벽해지고 싶어도\n멀리 꿈꾸고 작은 것부터 시작하자\n욕심을 줄이고\n욕망을 같이 꿈꾸는 사이\n그래\n적게 상처받고 빠르게 익숙해질 수 있는\n우선배포를 하자",
        "guid": "https://hodolman.com/62",
        "categories": [
          "개발/우당탕탕 대모험",
          "결혼"
        ],
        "isoDate": "2024-08-18T07:27:26.000Z"
      }
    ]
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "제품도 없는데 수익은 어떻게?",
        "link": "https://www.thestartupbible.com/2024/08/how-do-you-make-a-profit-when-you-dont-have-a-product.html",
        "pubDate": "Wed, 21 Aug 2024 21:24:00 +0000",
        "content:encodedSnippet": "얼마 전에 TechCrunch에서 배양육 산업 관련 기사를 읽었다. 우리도 국내 최초의 배양육 스타트업 셀미트에 투자했기 때문에, 관심을 갖고 기사를 정독했다. 기사의 제목은 “Even after $1.6B in VC money, the lab-grown meat industry is facing ‘massive’ issues” 였고, 내용은 암울했다.\n내용을 요약하자면, 너도나도 대체 단백질과 배양육 시장에 투자하기 바쁠 땐, 거의 묻지마 투자 수준으로 많은 돈이 이 시장에 투입됐지만, 연구개발에 생각보다 많은 돈과 시간이 필요하고, 이후에 관계 정부 부서의 승인 받는 것도 어렵다는 걸 이제 많은 사람들이 깨닫고 있다. 하지만, 가장 어려운 현실은, 연구개발을 하고 승인을 받아도, 결국 돈을 벌기 위해선 배양육 제품을 팔아야 하는데, 시장에서 수용할 수 있는 가격대에 대량 생산하기 위해서는 상상 이상의 돈이 설비와 공장에 투입돼야 하므로 투자자들이 이젠 이 분야를 등한시하고 있다는 내용이다.\n실은, 순수 소프트웨어 사업이 아닌, 사람의 개입이 필요한 operation이 필수인 사업도 비슷한 문제에 항상 직면해 있긴 하다. 멀리 볼 필요도 없고 가까운 스트롱 포트폴리오 네트워크에만 보더라도 이런 회사들이 수두룩하다. 대표적인 예가 모바일 세탁소 세탁특공대인데, 앱으로 세탁을 맡길 수 있지만, 결국엔 회사에서 세탁물을 수거해서 본인들이 직접 운영하는 세탁공장으로 운반하고, 여기서 세탁한 후에 다시 고객들에게 배송해야 한다. 분명 소프트웨어 비즈니스이지만, 사업의 절반 이상이 전통적인 물류와 공장 운영이다. 굉장히 돈이 많이 필요하고, 상상 이상의 돈이 설비와 공장에 투입되어야 한다는 점은 위에서 언급한 배양육 회사와 크게 다르지 않다.\n하지만, 한 가지 다른 점이 있다면, 세탁이라는 업은 첫 매출을 만들기 위한 R&D는 필요 없다. 사업을 개선해서 더 많은 매출을 만들기 위한 R&D는 있지만, 이게 없어도 세탁업은 시작할 수 있고, 매출을 만들 수 있다. 이렇게 만든 매출과 다른 의미 있는 수치를 기반으로 계속 적당한 밸류에이션에 투자 받으면서 사업을 키울 수 있다.\n하지만, 배양육 사업은 오랜 기간 동안 아주 무거운 R&D 과정을 거치지 않으면, 제품 자체가 만들어지지 않기 때문에, 실제로 돈을 버는 건 시작도 못 한다. 사업을 시작하지 못하고, 돈을 아예 못 벌면, 투자받는 게 쉽지 않다. 경기가 아주 좋을 땐, 기술력을 평가하고 미래의 수익성을 기반으로 좋은 조건에 큰 투자를 하는 투자자들이 꽤 있다. 실은 우리 투자사 셀미트를 비롯한 이 분야의 많은 회사들이 몇 년 전만 해도 이런 식으로 투자를 잘 받았다. 하지만, 요새 같은 불경기에 투자자들이 회사를 판단하는 가장 중요한 기준은 매출이다. 투자자들은 매출을 선호하고, 더 나아가서 수익을 선호한다. 이 상황에서 팔 제품 자체가 없는 스타트업은 어떻게 수익을 만들고, 어떻게 투자를 받을 수 있을까?\n아마도 이런 상황에 놓인 창업가들이 꽤 있을 것 같고, 최근에 이런 고민을 하는 분과 잠깐 이야기를 했는데, 이분이 나한테 열변을 토했다. “아니, 아직 제품도 없는데 어떻게 매출을 만드나요? 어떻게 우리 같은 회사의 밸류에이션을 매출을 기반으로 산정합니까? 그러면 우린 밸류에이션이 0인 회사인데요.”\n이분은 시드 투자를 받아서 한 2년 동안 열심히 R&D를 해고, 연구 결과도 좋고 방향도 좋아서 실제 제품을 만들고 매출을 발생시키기 위해 추가 투자를 받아야 하는데, 만나는 대부분의 투자자들이 매출이 없어서 거절하거나, 관심 있는 투자자는 매출이 없어서 (본인이 생각하기엔) 터무니없이 낮은 기업 가치를 제시하는 좋지 않은 상황에 부닥쳐있다.\n솔직히 나도 이분에게 특별히 해 줄 말이 없었다. 경기가 좋고 시장에 돈이 넘쳐흐를 땐, 제품도 없고 매출이 없어도 기술 그 자체나 시장의 가능성에 투자하는 VC들이 많았지만, 이젠 대부분의 VC들이 매출이 발생하는 회사를 선호하고, 어떤 VC는 매출로도 부족하고 손익분기를 해서 이익이 발생하는 회사에만 투자하고 있기 때문에 위에서 말한 창업가가 투자받는 건 정말 힘들기 때문이다. 만약에 이런 상황에 처한 창업가가 있다면, 그냥 최대한 많은 투자자를 만나서 제품과 매출이 없는 회사에도 투자하는 곳을 찾는 수밖에 없다. 만약에 운 좋게 이런 곳을 찾더라도, 회사의 밸류에이션과 투자 조건을 결정하는 건 전적으로 투자자의 특권이 될 수밖에 없다. 이 말을 쉽게 해석해 보면, 투자받는 것도 mission impossible이고, 운 좋게 우리 회사에 관심 갖는 투자자를 찾더라도 좋지 않은 조건에 투자받아야 한다는 의미다.\n입장 바꿔서 이야기를 한번 해보고 싶다. 즉, 이런 회사들을 자주 만나는 VC의 입장에서,,,실은 지금 이런 상황에 부닥친 회사에 투자하면, 정말 매력적인 조건에 투자할 수 있다. 이 회사에 살아 남아서 정말로 좋은 기술로 좋은 제품을 만들 수 있다면, 시간은 오래 걸리지만, 매출이 발생하기 시작하면 확실한 해자를 만들면서 성장하기 때문에 멈출 수 없을 정도로 매출이 잘 나올 것이다. 특히나, 이런 기술을 잘 이해하고, 이 시장을 잘 이해하고 있는 대기업의 전략적 투자 부서가 이런 플레이를 스마트하게 하면, 그 대기업의 미래 먹거리를 생각보다 쉽게 확보할 수도 있다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/08/how-do-you-make-a-profit-when-you-dont-have-a-product.html#respond",
        "content": "얼마 전에 TechCrunch에서 배양육 산업 관련 기사를 읽었다. 우리도 국내 최초의 배양육 스타트업 셀미트에 투자했기 때문에, 관심을 갖고 기사를 정독했다. 기사의 제목은 “Even after $1.6B in VC money, the lab-grown meat industry is facing ‘massive’ issues” 였고, 내용은 암울했다. 내용을 요약하자면, 너도나도 대체 단백질과 배양육 시장에 투자하기 바쁠 땐, 거의 묻지마 투자 수준으로 많은 돈이(...)",
        "contentSnippet": "얼마 전에 TechCrunch에서 배양육 산업 관련 기사를 읽었다. 우리도 국내 최초의 배양육 스타트업 셀미트에 투자했기 때문에, 관심을 갖고 기사를 정독했다. 기사의 제목은 “Even after $1.6B in VC money, the lab-grown meat industry is facing ‘massive’ issues” 였고, 내용은 암울했다. 내용을 요약하자면, 너도나도 대체 단백질과 배양육 시장에 투자하기 바쁠 땐, 거의 묻지마 투자 수준으로 많은 돈이(...)",
        "guid": "https://www.thestartupbible.com/?p=9185",
        "categories": [
          "Uncategorized",
          "FoundersAtWork",
          "fundraising",
          "technology",
          "vc"
        ],
        "isoDate": "2024-08-21T21:24:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "노력의 부족으로 실패하지 말자",
        "link": "https://www.thestartupbible.com/2024/08/if-you-fail-make-sure-its-not-because-of-a-lack-of-effort.html",
        "pubDate": "Sun, 18 Aug 2024 21:18:00 +0000",
        "content:encodedSnippet": "역대 최악의 성적이 예상됐지만, 반대로 한국이 역대 최고의 성적을 거둔 파리 올림픽이 지난주에 잘 마무리됐다. 나는 대부분의 올림픽 종목을 별로 안 좋아하지만, 국가 대표들이 열심히 경쟁하는 경기라서 그런지 매일 저녁 한국이 참여하는 대부분의 종목을 와이프랑 정말 재미있게 봤던 즐거운 2주였다. 한국은 금 13개, 총 32개의 메달을 따면서 8위로 끝났는데 너무 잘했고, 모두 너무 자랑스럽다. 안세영 선수의 발언과 더불어 그동안 변화를 수용하지 못한 여러 협회에 대한 불미스러운 일들도 있었지만, 나는 이런 과정이 체육협회와 선수들이 모두 다 한 단계 더 성장하는 계기가 되길 바란다.\n스포츠를 각본 없는 드라마라고 하는데, 이번 파리 올림픽에서도 다양한 이변이 많았고, 메달이 당연시됐던 선수들이 형편없는 성적으로 예선 탈락했고, 전혀 기대되지 않았던 선수들이 선전해서 메달을 따기도 했다. 우리나라 태권도 김유진 선수가 그중 하나였던 것 같은데, 세계 랭킹 12위가 세계랭킹 1위와 2위를 모두 이기고 금메달을 획득한 건, 태권도 전문가들의 말에 의하면 이변 중 대이변이었다.\n이 선수 외에도 랭킹이 한참 아래였거나, 거의 무명의 선수들이 메달을 획득한 사례가 다른 나라에도 몇 개 있었는데, 이 중 몇 명의 경기 후 인터뷰를 보면, 다들 하는 말이 거의 비슷했다. 다른 사람들은 이 선수들의 외부 랭킹만 보고 승패를 예측하지만, 정작 본인들은 스스로가 얼마나 열심히 연습하고 훈련했는지 알기 때문에, 충분히 우승할 수 있다고 믿고 있었고, 이런 땀과 노력은 절대로 배신하지 않는다는 걸 알기 때문에 남들은 이변이라고 하는 결과가 본인에겐 전혀 놀랍지 않다는 내용이었다. 어떤 선수는 이런 말을 했는데 이 말이 굉장히 인상적이었다. “내 연습량을 내가 잘 알고 있고, 훈련의 양에 있어서는 그 어떤 선수도 나를 능가할 수 없다는 걸 내가 잘 알고 있다. 그래서 나는 이 메달이 전혀 신기하지도, 놀랍지도 않다. 당연히 올림픽이라는 큰 무대에서 질 수도 있다. 하지만, 패배의 원인이 노력의 부족이면 절대로 안 된다. 노력의 부족 때문이 아닌 다른 이유로 진다면, 아쉽겠지만 절대로 후회는 안 한다.”\n실은 내가 우리 창업가분들과 자주 하는 말과 너무 비슷해서 나에겐 더욱더 인상 깊었던 말이었던 것 같다. 우린 모두가 항상 최선을 다해야한다는 말을 밥 먹듯이 하지만, 또 한 편으론 내가 봤을 때 최선을 다하지 않는 분들도 종종 본다. 물론, 이건 굉장히 주관적인 입장이고 최선의 개념은 모두에게 다르다. 어쨌든, 정말로 사업과 본인의 미션에 헌신(=commitment)을 보이면서 최선의 노력을 다하는 건 매우 중요하다고 생각한다.\n사업도 올림픽 경기와 같이, 아무리 열심히 하고 죽기 살기로 노력해도 잘 안될 수도 있다. 아니, 성공의 확률이 낮기 때문에 잘 안되는 게 오히려 어쩌면 정상적이다. 그래서 사업은 실패할 수도 있고, 실패한 사업가들이 욕을 먹는 건 가혹하다고 생각하지만, 그 실패의 원인이 노력의 부족이라면, 비난을 받아도 할 말이 없다고 생각한다.\n나는 우리 포트폴리오 회사들이 더는 버티기 힘들어서 폐업을 결정하면, 이런 대화를 많이 한다. “최선을 다했나요? 대표님만큼 치열하고 열심히 노력한 사업가가 주위에 없을 정도로 열심히 했나요? 그랬다면 잘했습니다. 실패의 원인이 노력의 부족이 아니었다면 편안하게 사업 접고 좀 쉬세요.”\n실패의 원인이 노력의 부족이 되지 않게 모두 다 치열하게 헌신하는 하루, 일주, 그리고 일 년이 되길.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2024/08/if-you-fail-make-sure-its-not-because-of-a-lack-of-effort.html#comments",
        "content": "역대 최악의 성적이 예상됐지만, 반대로 한국이 역대 최고의 성적을 거둔 파리 올림픽이 지난주에 잘 마무리됐다. 나는 대부분의 올림픽 종목을 별로 안 좋아하지만, 국가 대표들이 열심히 경쟁하는 경기라서 그런지 매일 저녁 한국이 참여하는 대부분의 종목을 와이프랑 정말 재미있게 봤던 즐거운 2주였다. 한국은 금 13개, 총 32개의 메달을 따면서 8위로 끝났는데 너무 잘했고, 모두 너무 자랑스럽다. 안세영(...)",
        "contentSnippet": "역대 최악의 성적이 예상됐지만, 반대로 한국이 역대 최고의 성적을 거둔 파리 올림픽이 지난주에 잘 마무리됐다. 나는 대부분의 올림픽 종목을 별로 안 좋아하지만, 국가 대표들이 열심히 경쟁하는 경기라서 그런지 매일 저녁 한국이 참여하는 대부분의 종목을 와이프랑 정말 재미있게 봤던 즐거운 2주였다. 한국은 금 13개, 총 32개의 메달을 따면서 8위로 끝났는데 너무 잘했고, 모두 너무 자랑스럽다. 안세영(...)",
        "guid": "https://www.thestartupbible.com/?p=9183",
        "categories": [
          "Uncategorized",
          "failure",
          "FoundersAtWork",
          "hustle",
          "inspiring",
          "korea",
          "sports",
          "Strong"
        ],
        "isoDate": "2024-08-18T21:18:00.000Z"
      }
    ]
  },
  {
    "name": "Build a Great Product",
    "category": "개인",
    "posts": []
  },
  {
    "name": "지금 써보러 갑니다",
    "category": "개인",
    "posts": []
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "TDF, 우리 모두의 은퇴 준비 필수품",
        "link": "https://blog.toss.im/article/retirement-plans-05",
        "pubDate": "Fri, 23 Aug 2024 06:20:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}이 글에서 알 수 있는 것들\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1kxrhf3{white-space:pre-wrap;}퇴직연금에서 중요한 비중을 차지하는 TDF 개념 이해하기\n내가 계획하는 은퇴시점에 따라 TDF 고르는 기준 알아보기\n\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n은퇴 준비를 위한 자산 배분 이해하기\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n은퇴 준비를 하겠다고 마음 먹었을 때 가장 중요한 첫 번째는 적은 금액이라도 퇴직연금 계좌에 꾸준하게 모으는 것, 두 번째는 자산 배분이다. 만약 이미 은퇴에 가까운 나이라면 힘들게 모은 자산을 안전하게 관리하면서 가져가야 한다. 위험자산보다는 안전자산의 비중을 높여 너무 무리하지 않는 선에서 투자와 관리를 지속하는 것이다. 시장 분위기가 좋을 때 높은 수익을 가져다주는 위험자산은 언제나 유혹적이지만, 최근처럼 한국 주식이 급락해버리면 열심히 모아온 은퇴 자금이 위태로워지고 만다.\n반대로 아직 은퇴까지 20~30년의 시간이 있다면 위험자산을 이용해 적극적인 투자가 가능하다. 물론 자신이 얼마나 위험을 감수할 수 있는 성향인지 이해하고 이를 바탕으로 위험자산의 비중을 조정해야 하지만, 일반적으로 20대와 30대일 때는 전체 자산에서 위험자산의 비중이 중년기보다 많아도 된다고 말한다. 일시적으로 시장이 급락할지라도 은퇴 시점까지 회복할 시간이 충분히 있기 때문이다.\n모두에게 공평하게 적용되는 한 가지는 바로 시간이다. 시간이 흘러 나이를 먹으면서 모두가 점차 은퇴 시점에 가까워진다. .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}그렇게 은퇴 시점에 가까워지면 자산 배분도 그에 맞게 변경되어야 한다. 30대의 주식과 채권 배분 비율과 50대의 비율은 당연히 다를 수밖에 없다. 시기에 따라 적절히 주식과 채권 상품을 사고 팔며 비율을 조정해야 한다는 뜻이다. 여기까지 이야기하면 대부분의 사람들이 이런 반응을 보인다.\n“먹고 살기도 바쁜데 어떻게 매번 그걸 체크하고 바꾸나요?”\n“배분 비율을 어떻게 바꿔야 하죠? 기준이 있나요?”\n투자에 관심이 많고 늘 시간을 들일 수 있는 사람이라면 충분히 가능한 일이다. 하지만 대다수의 사람들에게 ‘주기적으로 리밸런싱하고, 위험자산과 안전자산의 비율을 조정하라'는 건 사실 지속 가능하지 않은 방법이다. 그래서 등장한 은퇴용 투자상품이 바로 TDF(Target Date Fund)이다.\n은퇴를 위해 태어났어요, TDF\nTDF는 은퇴 시점을 정하고 투자하면 펀드를 운용하는 회사가 해당 시점에 맞춰 자산 배분을 알아서 관리해주는 상품이다. 따라서 보통 TDF 상품에는 숫자가 들어 있는데, 이 숫자가 바로 은퇴 연도를 뜻한다. 예를 들어 내가 은퇴하고자 하는 시점이 2040년이라면 상품명에 2040이 들어간 TDF를 고르면 된다.(이 숫자를 빈티지(vintage)라고 부른다.) 보통 TDF에 들어 있는 숫자는 2030, 2035, 2040처럼 5년 단위로 설정된다. 따라서 자신의 은퇴 희망 시점과 가장 가까운 숫자를 선택하면 된다.\n문제는 많은 사람들이 TDF에 대한 이해가 부족한 채 무분별하게 투자하고 있다는 데 있다. 실제로 IRP 계좌를 보유한 한 30대를 인터뷰해보니 TDF2035 상품과 TDF2050 상품을 모두 보유하고 있었다. 자신의 은퇴 희망 시점을 고려한 것이 아니라 상품을 권유한 판매자의 말대로 여러 TDF를 구매한 탓이었다. TDF가 만들어진 취지와 맞지 않을 뿐더러, 투자자가 투자 상품에 대해 이해하지 못한 채 돈을 넣어버린 잘못된 투자였다.\n한국 시장에서 TDF 상품이 수면 위로 떠오른 이유는 바로 디폴트옵션(사전지정운용제도) 때문이다. 4화 ‘.css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}자꾸 디폴트옵션 설정하라고 알림이 와요’에서 말했듯이 오랫동안 저조했던 퇴직연금의 수익률을 개선하기 위해 등장한 디폴트옵션에는 TDF 상품이 매우 많이 포진되어 있다. 심지어 주식 배분이 80% 가까이 올라가도 TDF는 안전자산으로 분류되는 특징이 있다. 시간 흐름에 따라 은퇴 시점에 가까워질수록 안전자산 비중이 높아지면서 변화하기 때문이다. 은퇴 준비를 효과적으로 하기 위해서는 이러한 특징을 가진 TDF 상품을 적절하게 활용할 줄 알아야 한다.\nTDF의 핵심은 바로 글라이드 패스\n시간 흐름에 따라 알아서 자산을 배분해주는 TDF의 특징을 글라이드 패스(glide path)로 설명하곤 한다. 글라이드 패스는 비행기가 착륙할 때 그리는 경로를 뜻하는 말로, 하늘에서 땅으로 부드러운 곡선을 그리며 착륙하는 모습이 은퇴까지 아직 많은 시간이 남은 사회 초년기에는 주식 비중이 크고, 은퇴 시기에 가까워질수록 주식 비중이 줄어드는 흐름과 매우 닮아 있다. 따라서 TDF에서의 글라이드 패스를 쉽게 설명하자면, 가입 시점부터 은퇴 시점까지 시간 흐름에 따라 주식과 채권의 배분을 조정하는 방법이다. 시기에 따른 배분율은 사전에 정해져 있으며, 그 비율에 따라 은퇴 시점이 가까워지면 TDF는 포트폴리오의 주식 보유량을 줄이고 채권 보유량을 늘려준다. 이유는 간단하다. 채권이 주식에 비해 위험이 적다고 판단하기 때문이다.\n다음 그래프는 미국의 자산운용사 블랙록(Black Rock)의 2040 TDF 자산 배분 현황이다. 가로축에서 0은 은퇴 시점이고 5는 은퇴 시점 5년 전, 10은 10년 전을 나타낸다. 해당 포트폴리오의 2023년 상태, 즉 약 8년 정도 남은 상태를 보면 주식 비중은 약 55%이고, 은퇴 시점에는 40%로 줄어든 것을 확인할 수 있다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}은퇴를 기점으로 달라지는 블랙록의 2040 TDF 자산 배분 현황\n그래프처럼 주식 배분이 점점 줄어드는 스케줄이 바로 글라이드 패스다. 글라이드 패스의 높낮이는 TDF를 만드는 회사마다 다르다. 어떤 방식의 글라이드 패스가 정답이라고 말할 수는 없지만, 모든 글라이드 패스를 만들 때 공통적으로 고려하는 몇 가지가 있다.\n첫째, 은퇴 시점이 가까워질수록 주식보다 채권의 비중이 높아진다.\n둘째, 은퇴 시점이 가까워질수록 해외주식보다 자국 주식의 비중이 높아진다. 은퇴에 가까울수록 외환 위험에 노출되지 않도록 자국 주식의 비중을 높이는 방식이 미국에서는 정석으로 통용된다. (그런데 이것은 한국 주식시장의 저조한 실적을 고려하면 한국 TDF에도 맞다고 단언할 수는 없는 부분이다.)\n셋째, 은퇴 시점이 가까워질수록 수익률이 높고 만기가 긴 채권의 비중이 줄고 수익률이 좀 낮더라도 만기가 짧은 채권의 비중이 높아진다.\n넷째, 은퇴 시점부터는 물가연동채권(미국에서는 TIPS), 원자재, 부동산 등의 자산이 많이 포함된다.\n이처럼 글라이드 패스는 주식과 채권의 분배 비율을 담고 있기 때문에 TDF의 수익률을 좌우하는 매우 중요한 요소이다. TDF 상품을 이해하는 데 가장 중요한 정보이지만 아직까지는 어려운 용어로 가득한 투자상품 설명서를 읽어야 파악할 수 있게 되어 있어서 투자자에게 제일 전달되지 않는 정보이기도 하다.\n배분 비율에 따른 수익률 차이는?\nTDF 상품별로 얼마나 주식에 투자되고, 채권에 투자되는지에 따라 매년 수익률이 달라진다. 예를 들어 2024년 1월 1일부터 7월 31일까지의 수익률을 살펴보자. 물론 장기간 투자를 위해 만들어진 상품을 이렇게 단기간 수익률로 분석하는 방법은 상품의 본래 취지에 어긋날 순 있지만, 투자자들이 수익률 차이를 이해하는 데 있어서 중요한 부분이라고 생각한다.\n\n출처=.css-114ityv{white-space:pre-wrap;cursor:pointer;-webkit-text-decoration:underline!important;text-decoration:underline!important;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}아이랩 글라이드\n2040 빈티지인 TDF 상품들의 2024년 동안의 수익률을 보면 가장 좋은 수익률을 기록한 것은 ‘한국투자TDF알아서ETF포커스’로 7개월 수익률이 13.19%이다. 수익률이 가장 낮은 상품과 비교하면 무려 8% 넘게 차이가 난다. 2040년을 은퇴 시점으로 타깃하는 경우에는 주식 배분율 차이가 최대 77%에서 최소 57%로 다양하기 때문에 상당한 차이가 날 수밖에 없다. 이런 점을 이해한다면 같은 빈티지 안에서도 왜 이렇게 수익률이 다른지 이해할 수 있고, TDF를 고를 때 내가 주식에 더 많이 투자하고 싶다면 주식 배분율을 기준으로 상품을 고르는 방법도 가능하다.(하위 개념인 어떤 종목을 보유했느냐 또한 중요한 요소이지만, 수익률 차이를 가르는 데는 상위 개념인 어떤 자산을 얼마나 보유했느냐가 더 결정적인 역할을 한다.)\nTDF를 고르는 6가지 기준\n만약 내가 은퇴자금을 공격적으로 투자하고 싶다면 상품별로 주식-채권 배분율을 확인해보고, 주식 배분율이 높은 TDF를 고르면 된다. 이 배분율 차이는 곧 수익률, 변동성과 직결된다는 점, 그리고 위에서 살펴본 수익률 순위는 2024년 상반기 한정이며, 투자 기간 전체의 수익률이 아니라는 것도 잊지 않아야 한다.\n\n출처=아이랩 글라이드\n또한 나에게 맞는 TDF를 고르기 위해서는 조금 더 고려해야 할 사항들이 있다. 아래 6가지 기준을 소개한다.\n첫째가 앞서 말한 나의 은퇴 시점, 둘째가 주식 배분의 정도이다. 예를 들어 2045년 은퇴를 목표로 한다면 TDF 2045 빈티지 안에서 주식 배분율을 최소 57%에서 최대 79%까지 고를 수 있다.\n셋째는 미국 주식에 어느 정도 투자하고 싶은가다. 한국 TDF 상품은 미국 주식에 많이 투자하는데 역시 배분율이 조금씩 다르다. 만약 미국 주식에 많이 투자하고 싶다면 최대치를 선택할 수 있다.\n넷째, 수수료 차이를 고려해 패시브 펀드와 액티브 펀드 중 원하는 것을 선택한다. 지수를 따라가는 패시브 펀드는 액티브 펀드보다 수수료가 저렴하다. 또한 패시브 펀드로 구성된 TDF는 펀드 매니저가 종목을 골라 넣는 방식이 아니기 때문에 시장 환경에 따른 수익률 예측이 가능하다.\n다섯째, 위험도 선택이다. 상품설명서를 보면 펀드운용자가 정한 위험등급을 볼 수 있다. 이는 매우 높은 위험의 1부터 매우 낮은 위험의 6까지 구분된다. 자신이 얼마나 위험을 감수할 수 있을지를 고려한다.\n여섯째, 은퇴 시점의 주식 배분율을 고른다. 같은 빈티지 안에서도 은퇴 시점에 주식 배분이 조금 더 높은 상품이 있고 낮은 상품이 있다. 은퇴가 다가왔을 때 예상치 못한 시장 상황에 의한 갑작스러운 손실을 낮추고 싶다면 더 낮은 상품을 고르면 된다.\n위와 같은 질문을 통해 자신의 계획에 맞는 TDF 상품을 찾아갈 수 있다. 단순히 수익률만으로 상품을 고르기보다는 나의 성향에 맞춰 고르는 심층적인 방법이다.\n과거 수익률은 판단하기 위한 최소한의 단서\n상품을 고르는 데 있어서 과거 수익률은 중요한 정보다. 과거의 수익률이 미래 수익률을 보장하지는 않지만 그동안 얼마나 잘해왔는지를 살펴볼 수 있는 중요한 척도이므로, 광고만 보고 고르는 것보다는 낫다. 수익률을 잘 비교하기 위해서는 내 펀드의 수익률만 살펴보는 것이 아니라, 같은 빈티지의 다른 상품이 동일한 기간에 얼마나 수익을 올렸는지 살필 것을 권한다. 앞서 살펴본 것처럼 똑같은 2040 타깃의 TDF여도 최소 5%에서 최대 13%로 차이가 있기 때문이다. 만기를 채우지 않은 채 수시로 상품을 갈아타는 것을 추천할 수는 없지만, 만약 꾸준히 더 좋은 수익률을 내고 나에게 잘 맞는 상품이 있다면 당연히 바꾸어야 하지 않을까?\nTDF는 한국 금융시장에서 은퇴 준비에 있어서 점점 더 큰 부분을 차지하고 있는 상품이므로, 이번 시간을 통해 TDF에 대해 제대로 이해하는 투자자들이 많아지길 기대한다. 그리하여 나에게 맞는 TDF를 골라서 투자하고 다음 단계로 나아가기를 바란다. 퇴직연금 계좌에는 보통 다른 계좌보다 제약이 있기는 하지만 ETF, 자산 배분 펀드 등 다양한 상품이 존재한다. 이를 이용해서 장기투자와 단기투자를 섞거나, 투자에 더 익숙한 투자자라면 ETF를 이용해 자신만의 포트폴리오를 잘 구성해볼 수 있다. 다음 화에서는 퇴직연금으로 투자하는 ETF에 대해 다루어 보도록 하겠다.\n*<노후 준비 액션플랜> 시리즈는 국내 159개 대표 운용펀드의 TDF 글라이드 패스와 수익률을 한눈에 보기 쉽도록 전달하는 .css-1vsqqzg{white-space:pre-wrap;cursor:pointer;-webkit-text-decoration:underline!important;text-decoration:underline!important;font-weight:bold;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}아이랩 글라이드와 함께 만듭니다.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 주소은, 김현미(아이랩) Graphic 조수희, 윤여진",
        "content": "퇴직연금을 운용하는 지속 가능한 방법",
        "contentSnippet": "퇴직연금을 운용하는 지속 가능한 방법",
        "guid": "https://blog.toss.im/article/retirement-plans-05",
        "isoDate": "2024-08-23T06:20:00.000Z"
      },
      {
        "title": "건강검진 지원부터 빈 용기 보증금 제도까지, 우리의 건강과 환경을 지키는 돈 되는 정책",
        "link": "https://blog.toss.im/article/money-policies-23",
        "pubDate": "Fri, 23 Aug 2024 01:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}우리의 건강과 환경, 안전을 지키는 정책과 제도를 살펴봅니다.  \n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n건강이 최우선 \n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}⓵ 생애주기별 국가건강검진제도\n일반건강검진부터 연령에 따른 암 검진, 영유아와 청소년까지 필수적인 검사를 지원합니다.\n.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}일반건강검진은 보통 2년 주기로 받아요. 비만, 시청각 이상, 고혈압, 폐결핵, 신장질환, 빈혈, 당뇨병 여부 등을 공통으로 검사하고요. 연령에 따라 이상지질혈증, B형간염, 골밀도, 인지기능장애, 우울증 등의 검사를 추가로 받을 수 있어요.\n자세한 내용은 국민건강보험공단(www.nhis.or.kr)에서 확인할 수 있습니다.\n⓶ 암 환자 의료비 지원\n암 환자가 있는 가정의 경제적 부담을 덜어드리고 힘든 치료 과정을 잘 견뎌낼 수 있도록 의료비를 지원해요.\n성인 환자 기준, 의료급여 수급자나 차상위 본인 부담 경감대상자인 경우, 최대 3년간 연속으로 연간 최대 300만원을 지원합니다. 주소지 관할 보건소에서 신청할 수 있어요.\n⓷ 찾아가는 금연지원 서비스\n담배를 끊고자 하는 금연 의지가 있지만 프로그램에 참가하기 어려운 상황이라면, 직접 찾아가 관리해드립니다. 위기 청소년, 여성, 장애인, 소규모 사업장 근로자 등이 지원 대상이에요.\n전국 17개 지역금연지원센터를 통해 신청하면 6개월간 9회 이상 지속적인 금연 상담을 받을 수 있고요, 니코틴 보조제나 금연치료제를 지원 받을 수 있어요. 한국건강증진개발원(02-3781-2220)에 더 자세한 내용을 문의해보세요.\n안전을 체감할 수 있는 사회 \n⓸ 여성 긴급전화 1366\n가정폭력, 성폭력, 성매매, 스토킹, 교제폭력 등 폭력 피해자에게 상담 서비스를 지원합니다. 365일 24시간 운영되니 도움이 필요할 때 언제든 전화하면 됩니다. \n초기 상담부터 관련 지원 기관으로의 연계, 피해자와 동반가족이 최대 7일까지 머무를 수 있는 긴급 피난처까지 제공합니다. \n⓹ 안심 상속 원스톱 서비스\n사망자가 남긴 재산과 채무를 한번에 조회하는 서비스입니다. 예금, 대출, 보험, 증권 등 금융거래 내역부터 연금 가입 유무까지 확인할 수 있어요.\n사망일이 속한 달의 말일부터 1년 이내에 상속인(또는 후견인)이 신청할 수 있어요. 가까운 행정복지센터에 방문해도 되고, 정부24 홈페이지에서 온라인 신청도 가능합니다.\n환경을 지키는 돈 되는 정책 \n⓺ 폐가전 무상방문수거\n온라인이나 전화로 폐가전 처리 신청하면, 수거 전담반이 찾아가 무상 수거해 갑니다. 집에서 사용하지 않는 TV나 냉장고, 세탁기, 에어컨 등 부피가 크고 무거운 폐가전 제품을 배출할 때 꼭 확인해보세요. 소형 가전은 5개 이상인 경우 수거 가능합니다.\n폐가전제품 배출예약시스템(www.15990903.or.kr)이나 전화(1599-0903)로 신청할 수 있어요.\n⓻ 빈 용기 보증금 제도\n재사용 표시가 있는 병을 가까운 슈퍼나 대형마트에 반환하면 보증금을 돌려 받을 수 있어요. 돌려받을 수 있는 금액은 병의 용량에 따라 70원~350원으로 달라요.\n예를 들면 소주병은 1병당 100원인데, 제사 지낼 때 많이 쓰는 대형 청주 병은 개당 350원이랍니다. 제품 라벨에 금액이 표시돼 있어요.\n\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 정경화 Graphic 조수희",
        "content": "지키고 살피는 건강, 안전, 환경 서비스",
        "contentSnippet": "지키고 살피는 건강, 안전, 환경 서비스",
        "guid": "https://blog.toss.im/article/money-policies-23",
        "isoDate": "2024-08-23T01:00:00.000Z"
      },
      {
        "title": "대출 받을 때 알아야 할 3가지: 2024년 LTV, DTI, DSR",
        "link": "https://blog.toss.im/article/ltv-dti-dsr",
        "pubDate": "Tue, 20 Aug 2024 03:05:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}계속 바뀌는 대출 정책에 ‘내가 돈을 빌릴 수 있다는 건지, 없다는 건지' 헷갈릴 때가 많을 텐데요. 자주 등장하는 LTV, DTI, DSR 뜻만 제대로 알아도 얼마나 대출 받을 수 있는지 예상하기 편해질 거예요.\n.css-1c1qox8{font-size:30px;letter-spacing:0em;line-height:1.55;font-weight:bold;color:var(--adaptiveGrey900);margin:40px 0 4px;}\n.css-p4abj2{display:contents;line-height:1.55;}LTV\n집을 사기 위해서는 ‘주택담보대출'을 많이 받아요. 내가 살 집을 담보로 금융기관에서 돈을 빌리는 건데 이때 .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}집값 대비 얼마까지 빌릴 수 있는지를 LTV(주택담보대출비율)라고 불러요. \n만약 5억원짜리 집을 사기 위해 집을 담보로 4억원을 빌렸다면, LTV는 80%가 되는 거예요.\nDTI\n소득에 비해 빚을 갚을 능력이 얼마나 되는지 알아보는 지표예요. 1년간 갚아야 할 주택대출의 원금+이자를 연소득으로 나눈 후 100을 곱해 구해요. 일반적으로 DTI가 낮을 때 빚을 갚을 능력이 높다고 여겨져요. \nDSR\n내가 가지고 있는 모든 빚을 기준으로 빌릴 수 있는 돈의 상한선을 정하는 거예요. \n이 때에는 주택담보대출뿐만 아니라 학자금대출, 마이너스대출*, 자동차할부, 카드론 등 모든 대출의 원리금을 합한 것을 기준으로 연소득 대비 일정 비율(%)까지 대출해줘요.\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}*마이너스대출은 빌린 금액이 아닌 한도금액, 즉 사용할 수 있는 마이너스대출 한도 전체를 더해요. \n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}DTI, DSR 비슷해보이는데 다른 건가요?\n네, 달라요! DTI는 주택담보대출의 원리금만 더하지만 DSR은 한 사람이 가진 거의 모든 빚을 더해 빌려줄 수 있는 돈을 정한다는 점에서 더 강력한 대출 규제라고 할 수 있어요. \n\n2024년부터는 \n스트레스 DSR이 적용돼요 \n스트레스 DSR이란 미래의 금리 인상 위험을 반영한 일정 수준의 ‘가산(스트레스) 금리’를 적용하는 거예요. 미래에 금리가 오를 경우 늘어날 원리금 상환 부담까지 반영하기 때문에 대출한도가 기존보다 줄어들 예정이에요. \n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}.css-wgpbp3{display:block;margin-top:6px;}스트레스 DSR 시행 단계\n스트레스 DSR은 총 3단계로 진행돼요. \n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n1단계는 2024년 2월 26일부터 8월 31일까지 적용돼요. 이때 적용되는 스트레스 금리는 0.38%*로 계산된 스트레스 금리(1.5%)의 25%만 반영했어요. 이에 따라 2024년 상반기 차주별 주택담보대출 한도가 2~4% 줄어들 것으로 예상돼요. \n*매년 2회(상, 하반기)에 걸쳐 주기적으로 변경돼요. 추후 결정되는 스트레스 금리는 .css-114ityv{white-space:pre-wrap;cursor:pointer;-webkit-text-decoration:underline!important;text-decoration:underline!important;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}은행연합회 홈페이지(kfb.or.kr)에서 확인할 수 있어요.\n2024년 9월부터는 2단계 스트레스 DSR을 시행해요. 기본 스트레스 금리의 50%인 0.75%p로 가산금리를 올리고, 은행권 신용대출과 2금융권 주택담보대출까지 포함해요. 여기에 은행권의 수도권 주택담보대출에 대해서는 스트레스 금리를 0.75%p 대신 1.2%p로 상향 적용해요. \n\n신용대출 받으려면\nDSR을 알아야 해요 \n나의 총 대출 금액이 1억원을 넘으면, DSR 40%까지만 대출받을 수 있기 때문이에요. 1년간 갚는 원리금이 연소득의 40%(비은행 50%)를 넘어가게 대출 받을 수 없다는 이야기예요 (전세대출, 중도금대출, 소액 신용대출 등은 제외). \n연봉까지만 빌릴 수 있던 신용대출을 연봉의 2~3배까지 빌릴 수 있도록 허용해주었지만, 사실상 필요한 돈이 1억원 이상이라면 DSR 40%내에서만 빌릴 수 있는 거예요. 상대적으로 연소득이 적은 청년층에 영향이 클 수밖에 없고요.\n\n한도 높이기 위해서는: 연소득이 높아지거나, 매년 내는 원리금 부담을 줄이면 되는데요. 최근 나온 .css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}10년 만기 신용대출 등을 이용해 매년 내는 원리금 부담을 줄이면 일시적으로 한도를 높일 수 있어요.\n\n\n주택담보대출 받으려면\n3가지 모두 알아야 해요\n부동산은 크게 규제지역과 비규제지역으로 나누어지는데요. 2023년 1월 5일부터 강남, 서초, 송파, 용산 등 서울 4개구를 제외하고는 모두 규제지역(투기과열지구, 조정대상지역)에서 해제됐어요. \n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n1. 규제지역과 비규제지역의 LTV가 달라요 \n\n무주택자, 1주택자는 비규제지역에서는 70%, 규제지역에서는 50%의 LTV가 적용돼요. \n부부합산 연소득이 9,000만 원 이하이고, 규제지역의 주택가격 9억 원 이하, 무주택세대주의 요건을 모두 충족하면 6억 원 한도 내에서 LTV 70%까지 적용받을 수 있어요. \n생애 최초 구입이라면 규제지역 여부와 상관없이 집값의 80%까지 대출받을 수 있어요. 주택 소재 지역이나 주택 가격, 소득과 관계없이 최대 6억 원까지 대출받을 수 있어요. \n\n2. 다주택자도 규제지역에서 주택담보대출을 받을 수 있어요\n그동안 다주택자는 규제지역 내에서 주택담보대출을 받을 수 없었는데요. 2023년부터 규제지역에서도 집값의 최대 30%까지 대출받을 수 있게 됐어요 (LTV 0 → 30%). 비규제지역은 이전과 동일하게 LTV 60%가 적용돼요. \n3. DTI는 지역에 따라 달라요\n\n투기지역, 투기과열지구는 40% 적용해요. (서울 강남, 송파, 서초, 용산) \n조정대상지역은 50% 적용하고, 그 외에서는 60%가 적용돼요. \n생애 최초 구입자와 서민 등 실수요자는 투기지역 여부 관계없이 60%로 완화돼요.\n\n4. DSR도 적용돼요 \nLTV, DTI 규제가 완화됐지만 1억 원 넘게 대출받을 때 DSR 40% 규제는 유지돼요. 2024년부터는 위에서 설명한 스트레스 DSR도 추가되기 때문에, 내가 받는 대출이 해당하는지 살펴봐야 해요. \n\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 송수아 Graphic 이은호 이서영\n\n- 이 콘텐츠는 2022년 12월 19일 작성됐고, 2024년 8월 20일 업데이트됐어요.",
        "content": "주택담보대출에 LTV, DTI, DSR을 모두 적용하면 얼마까지 빌릴 수 있을까?",
        "contentSnippet": "주택담보대출에 LTV, DTI, DSR을 모두 적용하면 얼마까지 빌릴 수 있을까?",
        "guid": "https://blog.toss.im/article/ltv-dti-dsr",
        "isoDate": "2024-08-20T03:05:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]