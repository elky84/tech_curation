[
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Sinem Akinci",
        "title": "C++ code editing tools for GitHub Copilot: now in Public Preview",
        "link": "https://devblogs.microsoft.com/cppblog/c-code-editing-tools-for-github-copilot-now-in-public-preview/",
        "pubDate": "Tue, 16 Dec 2025 18:25:48 +0000",
        "content:encodedSnippet": "In November, we introduced C++ code editing tools for GitHub Copilot as a Private Preview, focusing on partnering with customers to tackle one of the common, taxing challenges for C++ development: refactoring at scale. Since then, we’ve listened to feedback and refined our tooling to make wide-sweeping C++ edits easier.\n“With C++ code editing tools for GitHub Copilot in Visual Studio, we’ve seen noticeably better overall results, with fewer errors and faster processing on large projects.” – Software engineer (from our Private Preview)\n\nWe’re excited to announce that C++ code editing tools for GitHub Copilot are now available to all C++ users in the latest version of Visual Studio 2026 Insiders.\nC++ code editing tools for GitHub Copilot\nRefactoring at scale is a time-consuming and error-prone process for C++ developers. Traditionally, developers relied on manual searches and incremental edits across multiple files to accomplish these tasks.\nWith these C++ code editing tools, Copilot goes beyond file searches and unlocks greater context-aware refactoring that enables changes across multiple files and sections.\nThe C++ code editing tools provide rich context for any symbol in your project, allowing Copilot agent mode to:\nView all references across your codebase\nUnderstand metadata such as type, declaration, and scope\nVisualize class inheritance hierarchies\nTrace function call chains\n\nThis helps Copilot accomplish complex editing tasks, reducing the traditionally manual effort required to perform refactoring tasks by improving the accuracy and speed of these operations.\nGetting started\nTo get started with these tools\nOpen your C++ project and ensure you have IntelliSense enabled\nNavigate to Tools > Options and turn on the visibility of the tools via GitHub > Copilot settings. You may need to close and re-open your solution for the tools to populate after this step.\n\nEnable any or all tools via the “Tools” icon in Copilot Chat\n\n\n\n\n\nNote: Tool names and UI may evolve during the Public Preview and are subject to change.\nExample scenarios\nAll examples below were showcased using bullet3, an open-source C++ physics simulation engine.\n1. Add additional functionality to existing functions\nAs applications evolve, you often need to enhance existing functions without breaking current behavior. This can include adding logging or performance metrics.\nThese tools help the agent quickly identify all relevant references, ensuring complete and accurate updates for feature additions.\n\n2. Improve memory management\nInefficient memory handling leads to performance bottlenecks, excessive copies, and unclear ownership semantics. When making these updates, these tools can help identify all relevant references and ensure all type changes are updated to verify code compiles without errors.\n3. Visualizing unfamiliar code\nC++ code can often have intricate structures and dependency mapping. In a large, unfamiliar codebase, onboarding to a task can often be very time-consuming.\nThe C++ tools can help identify all relevant class structures and symbol information to produce a visualization of a given set of C++ symbols in a library or file, easing your onboarding process.\nBest practices\nChoose the right model for the job: Models that are optimized for tool-calling will perform best with our tools. To learn more about the models available, please visit these docs: AI model comparison – GitHub Docs\nBe specific with prompts: Being specific with prompts and breaking vague tasks into clear intent and context will improve the tool calling and performance. Specify symbols explicitly when possible.\nShare your feedback\nWe’d love to hear feedback on how we can improve the C++ tooling experience. Please report problems or suggest improvements through the Visual Studio feedback icon.\n\nWhat’s next\nWe’re looking to evolve our integration with Visual Studio tools and expand this support to other Copilot surfaces, like Visual Studio Code, to further empower agent-driven edits for C++. Stay tuned for updates!\nThe post C++ code editing tools for GitHub Copilot: now in Public Preview appeared first on C++ Team Blog.",
        "dc:creator": "Sinem Akinci",
        "comments": "https://devblogs.microsoft.com/cppblog/c-code-editing-tools-for-github-copilot-now-in-public-preview/#comments",
        "content": "<p>In November, we introduced C++ code editing tools for GitHub Copilot as a Private Preview, focusing on partnering with customers to tackle one of the common, taxing challenges for C++ development: refactoring at scale. Since then, we&#8217;ve listened to feedback and refined our tooling to make wide-sweeping C++ edits easier. &#8220;With C++ code editing tools [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/cppblog/c-code-editing-tools-for-github-copilot-now-in-public-preview/\">C++ code editing tools for GitHub Copilot: now in Public Preview</a> appeared first on <a href=\"https://devblogs.microsoft.com/cppblog\">C++ Team Blog</a>.</p>\n",
        "contentSnippet": "In November, we introduced C++ code editing tools for GitHub Copilot as a Private Preview, focusing on partnering with customers to tackle one of the common, taxing challenges for C++ development: refactoring at scale. Since then, we’ve listened to feedback and refined our tooling to make wide-sweeping C++ edits easier. “With C++ code editing tools […]\nThe post C++ code editing tools for GitHub Copilot: now in Public Preview appeared first on C++ Team Blog.",
        "guid": "https://devblogs.microsoft.com/cppblog/?p=36161",
        "categories": [
          "C++",
          "Copilot",
          "New Feature",
          "Visual Studio"
        ],
        "isoDate": "2025-12-16T18:25:48.000Z"
      }
    ]
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "DrP: Meta’s Root Cause Analysis Platform at Scale",
        "link": "https://engineering.fb.com/2025/12/19/data-infrastructure/drp-metas-root-cause-analysis-platform-at-scale/",
        "pubDate": "Fri, 19 Dec 2025 17:35:13 +0000",
        "content:encodedSnippet": "Incident investigation can be a daunting task in today’s digital landscape, where large-scale systems comprise numerous interconnected components and dependencies\nDrP is a root cause analysis (RCA) platform, designed by Meta, to programmatically automate the investigation process, significantly reducing the mean time to resolve (MTTR) for incidents and alleviating on-call toil\nToday, DrP is used by over 300 teams at Meta, running 50,000 analyses daily, and has been effective in reducing MTTR by 20-80% \nBy understanding DrP and its capabilities, we can unlock new possibilities for efficient incident resolution and improved system reliability.\nWhat It Is\nDrP is an end-to-end platform that automates the investigation process for large-scale systems. It addresses the inefficiencies of manual investigations, which often rely on outdated playbooks and ad-hoc scripts. These traditional methods can lead to prolonged downtimes and increased on-call toil as engineers spend countless hours triaging and debugging incidents.\nDrP offers a comprehensive solution by providing an expressive and flexible SDK to author investigation playbooks, known as analyzers. These analyzers are executed by a scalable backend system, which integrates seamlessly with mainstream workflows such as alerts and incident management tools. Additionally, DrP includes a post-processing system to automate actions based on investigation results, such as mitigation steps.\n\nDrP’s key components include: \nExpressive SDK: The DrP SDK allows engineers to codify investigation workflows into analyzers. It provides a rich set of helper libraries and machine learning (ML) algorithms for data access and problem isolation analysis, such as anomaly detection, event isolation, time series correlation and dimension analysis.\nScalable backend: The backend system executes the analyzers, providing both multi-tenant and isolated execution environments. It ensures that analyzers can be run at scale, handling thousands of automated analyses per day.\nIntegration with workflows: DrP integrates with alerting and incident management tools, allowing for the auto-triggering of analyzers on incidents. This integration ensures that investigation results are immediately available to on-call engineers.\nPost-processing system: After an investigation, the post-processing system can take automated actions based on the analysis results. For example, it can create tasks or pull requests to mitigate issues identified during the investigation.\nHow It Works \nAuthoring Workflow\n\nThe process of creating automated playbooks, or analyzers, begins with the DrP SDK. Engineers enumerate the investigation steps, listing inputs and potential paths to isolate problem areas. The SDK provides APIs and libraries to codify these workflows, allowing engineers to capture all required input parameters and context in a type-safe manner.\nEnumerate investigation steps: Engineers start by listing the steps required to investigate an incident, including inputs and potential paths to isolate the problem.\nBootstrap code: The DrP SDK provides bootstrap code to create a template analyzer with pre-populated boilerplate code. Engineers extend this code to capture all necessary input parameters and context.\nData access and analysis: The SDK includes libraries for data access and analysis, such as dimension analysis and time series correlation. Engineers use these libraries to code the main investigation decision tree into the analyzer.\nAnalyzer chaining: For dependent service analysis, the SDK’s APIs allow for seamless chaining of analyzers, passing context and obtaining outputs.\nOutput and post-processing: The output method captures findings from the analysis, using special data structures for both text and machine-readable formats. Post-processing methods automate actions based on analyzer findings.\nOnce created, analyzers are tested and sent for code review. DrP offers automated backtesting integrated into code review tools, ensuring high-quality analyzers before deployment.\nConsumption Workflow\nIn production, analyzers integrate with tools like UI, CLI, alerts, and incident management systems. Analyzers can automatically trigger upon alert activation, providing immediate results to on-call engineers and improving response times. The DrP backend manages a queue for requests and a worker pool for secure execution, with results returning asynchronously.\nIntegration with alerts: DrP is integrated with alerting systems, allowing analyzers to trigger automatically when an alert is activated. This provides immediate analysis results to on-call engineers.\nExecution and monitoring: The backend system manages a queue for analyzer requests and a worker pool for execution. It monitors execution, ensuring that analyzers run securely and efficiently.\nPost-processing and insights: A separate post-processing system handles analysis results, annotating alerts with findings. The DrP Insights system periodically analyzes outputs to identify and rank top alert causes, aiding teams in prioritizing reliability improvements.\nWhy It Matters\nReducing MTTR\nDrP has demonstrated significant improvements in reducing MTTR across various teams and use cases. By automating manual investigations, DrP enables faster triage and mitigation of incidents, leading to quicker system recovery and improved availability.\nEfficiency: Automated investigations reduce the time engineers spend on manual triage, allowing them to focus on more complex tasks. This efficiency translates to faster incident resolution and reduced downtime.\nConsistency: By codifying investigation workflows into analyzers, DrP ensures consistent and repeatable investigations. This consistency reduces the likelihood of errors and improves the reliability of incident resolution.\nScalability: DrP can handle thousands of automated analyses per day, making it suitable for large-scale systems with complex dependencies. Its scalability ensures that it can support the needs of growing organizations.\nEnhancing On-Call Productivity\nThe automation provided by DrP reduces the on-call effort during investigations, saving engineering hours and reducing on-call fatigue. By automating repetitive and time-consuming steps, DrP allows engineers to focus on more complex tasks, improving overall productivity.\nScalability and Adoption\nDrP has been successfully deployed at scale at Meta, covering over 300 teams and 2000 analyzers, executing 50,000 automated analyses per day. Its integration into mainstream workflows, such as alerting systems, has facilitated widespread adoption and demonstrated its value in real-world scenarios.\nWidespread adoption: DrP has been adopted by hundreds of teams across various domains, demonstrating its versatility and effectiveness in addressing diverse investigation needs.\nProven impact: DrP has been in production for over five years, with proven results in reducing MTTR and improving on-call productivity. Its impact is evident in the positive feedback received from users and the significant improvements in incident resolution times.\nContinuous improvement: DrP is continuously evolving, with ongoing enhancements to its ML algorithms, SDK, backend system, and integrations. This commitment to continuous improvement ensures that DrP remains a cutting-edge solution for incident investigations, while its growing adoption across teams enables existing workflows and analyzers to be reused by others, compounding the shared knowledge base and making it increasingly valuable across the organization.\nWhat’s Next\nLooking ahead, DrP aims to evolve into an AI-native platform, playing a central role in advancing Meta’s broader AI4Ops vision, enabling more powerful and automated investigations. This transformation will enhance analysis by delivering more accurate and insightful results, while also simplifying the user experience through streamlined ML algorithms, SDKs, UI, and integrations facilitating effortless authoring and execution of analyzers.\nRead the Paper\nDrP: Meta’s Efficient Investigations Platform at Scale\nAcknowledgements\nWe wish to thank contributors to this effort across many teams throughout Meta\nTeam –  Eduardo Hernandez, Jimmy Wang, Akash Jothi, Kshitiz Bhattarai, Shreya Shah, Neeru Sharma, Alex He, Juan-Pablo E, Oswaldo R, Vamsi Kunchaparthi, Daniel An, Rakesh Vanga, Ankit Agarwal, Narayanan Sankaran, Vlad Tsvang, Khushbu Thakur, Srikanth Kamath, Chris Davis, Rohit JV, Ohad Yahalom, Bao Nguyen, Viraaj Navelkar, Arturo Lira, Nikolay Laptev, Sean Lee, Yulin Chen\nLeadership – Sanjay Sundarajan, John Ehrhardt, Ruben Badaro, Nitin Gupta, Victoria Dudin, Benjamin Renard, Gautam Shanbhag, Barak Yagour, Aparna Ramani\nThe post DrP: Meta’s Root Cause Analysis Platform at Scale appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Incident investigation can be a daunting task in today’s digital landscape, where large-scale systems comprise numerous interconnected components and dependencies DrP is a root cause analysis (RCA) platform, designed by Meta, to programmatically automate the investigation process, significantly reducing the mean time to resolve (MTTR) for incidents and alleviating on-call toil Today, DrP is used [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/12/19/data-infrastructure/drp-metas-root-cause-analysis-platform-at-scale/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/12/19/data-infrastructure/drp-metas-root-cause-analysis-platform-at-scale/\">DrP: Meta&#8217;s Root Cause Analysis Platform at Scale</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Incident investigation can be a daunting task in today’s digital landscape, where large-scale systems comprise numerous interconnected components and dependencies DrP is a root cause analysis (RCA) platform, designed by Meta, to programmatically automate the investigation process, significantly reducing the mean time to resolve (MTTR) for incidents and alleviating on-call toil Today, DrP is used [...]\nRead More...\nThe post DrP: Meta’s Root Cause Analysis Platform at Scale appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=23496",
        "categories": [
          "Data Infrastructure",
          "ML Applications"
        ],
        "isoDate": "2025-12-19T17:35:13.000Z"
      },
      {
        "creator": "",
        "title": "How We Built Meta Ray-Ban Display: From Zero to Polish",
        "link": "https://engineering.fb.com/2025/12/17/virtual-reality/meta-ray-ban-display-from-zero-to-polish/",
        "pubDate": "Wed, 17 Dec 2025 14:00:17 +0000",
        "content:encodedSnippet": "We’re going behind the scenes of the Meta Ray-Ban Display, Meta’s most advanced AI glasses yet. In a previous episode we met the team behind the Meta Neural Band, the EMG wristband packaged with the Ray-Ban Display. Now we’re delving into the glasses themselves.\nKenan and Emanuel, from Meta’s Wearables org, join Pascal Hartig on the Meta Tech Podcast to talk about all the unique challenges of designing game-changing wearable technology, from the unique display technology to emerging UI patterns for display glasses.\nYou’ll also learn what particle physics and hardware design have in common and how to celebrate even the incremental wins in a fast-moving culture.\nDownload or listen to the episode below:\n\nYou can also find the episode wherever you get your podcasts, including:\nSpotify\nApple Podcasts\nPocket Casts\nThe Meta Tech Podcast is a podcast, brought to you by Meta, where we highlight the work Meta’s engineers are doing at every level – from low-level frameworks to end-user features.\nSend us feedback on Instagram, Threads, or X.\nAnd if you’re interested in learning more about career opportunities at Meta visit the Meta Careers page.\nThe post How We Built Meta Ray-Ban Display: From Zero to Polish appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>We’re going behind the scenes of the Meta Ray-Ban Display, Meta’s most advanced AI glasses yet. In a previous episode we met the team behind the Meta Neural Band, the EMG wristband packaged with the Ray-Ban Display. Now we’re delving into the glasses themselves. Kenan and Emanuel, from Meta’s Wearables org, join Pascal Hartig on [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/12/17/virtual-reality/meta-ray-ban-display-from-zero-to-polish/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/12/17/virtual-reality/meta-ray-ban-display-from-zero-to-polish/\">How We Built Meta Ray-Ban Display: From Zero to Polish</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "We’re going behind the scenes of the Meta Ray-Ban Display, Meta’s most advanced AI glasses yet. In a previous episode we met the team behind the Meta Neural Band, the EMG wristband packaged with the Ray-Ban Display. Now we’re delving into the glasses themselves. Kenan and Emanuel, from Meta’s Wearables org, join Pascal Hartig on [...]\nRead More...\nThe post How We Built Meta Ray-Ban Display: From Zero to Polish appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=23477",
        "categories": [
          "Culture",
          "Virtual Reality",
          "Meta Tech Podcast"
        ],
        "isoDate": "2025-12-17T14:00:17.000Z"
      },
      {
        "creator": "",
        "title": "How AI Is Transforming the Adoption of Secure-by-Default Mobile Frameworks",
        "link": "https://engineering.fb.com/2025/12/15/android/how-ai-transforming-secure-by-default-mobile-frameworks-adoption/",
        "pubDate": "Mon, 15 Dec 2025 17:00:25 +0000",
        "content:encodedSnippet": "Meta’s secure-by-default frameworks wrap potentially unsafe OS and third-party functions, making security the default while preserving developer speed and usability.\nThese frameworks are designed to closely mirror existing APIs, rely on public and stable interfaces, and maximize developer adoption by minimizing friction and complexity.\nGenerative AI and automation accelerate the adoption of secure frameworks at scale, enabling consistent security enforcement and efficient migration across Meta’s vast codebase.\nSometimes functions within operating systems or provided by third parties come with a risk of misuse that could compromise security. To mitigate this, we wrap or replace these functions using our own secure-by-default frameworks. These frameworks play an important role in helping our security and software engineers maintain and improve the security of our codebases while maintaining developer speed.\nBut implementing these frameworks comes with practical challenges, like design tradeoffs. Building a secure framework on top of Android APIs, for example, requires a thoughtful balance between security, usability, and maintainability.\nWith the emergence of AI-driven tools and automation we can scale the adoption of these frameworks across Meta’s large codebase. AI can assist in identifying insecure usage patterns, suggesting or automatically applying secure framework replacements and continuously monitoring compliance. This not only accelerates migration but also ensures consistent security enforcement at scale.\nTogether, these strategies empower our development teams to ship well-secured software efficiently, safeguarding user data and trust while maintaining high developer productivity across Meta’s vast ecosystem.\nHow We Design Secure-by-Default Frameworks at Meta\nDesigning secure-by-default frameworks for use by a large number of developers shipping vastly different features across multiple apps is an interesting challenge. There are a lot of competing concerns such as discoverability, usability, maintainability, performance, and security benefits. \nPractically speaking, developers only have a finite amount of time to code each day. The goal of our frameworks is to improve product security while being largely invisible and friction-free to avoid slowing developers down unnecessarily. This means that we have to correctly balance all those competing concerns discussed above. If we strike the wrong balance, some developers could avoid using our frameworks, which could reduce our ability to prevent security vulnerabilities. \nFor example, if we design a framework that improves product security in one area but introduces three new concepts and requires developers to provide five additional pieces of information per call site, some app developers may try to find a way around using them. Conversely, if we provide these same frameworks that are trivially easy to use, but they consume noticeable amounts of CPU and RAM, some app developers may, again, seek ways around using them, albeit for different reasons.\nThese examples might seem a bit obvious, but they are taken from real experiences over the last 10+ years developing ~15 secure-by-default frameworks targeting Android and iOS. Over that time, we’ve established some best practices for designing and implementing these new frameworks.\nTo the maximum extent possible, an effective framework should embody the following principles: \nThe secure framework API should resemble the existing API. This reduces the cognitive burden on framework users, forces security framework developers to minimize the complexity of the changes, and makes it easier to perform automated code conversion from the insecure to secure API usage.\nThe framework should itself be built on public and stable APIs. APIs from OS vendors and third parties change all the time, especially the non-public ones. Even if access to those APIs is technically allowed in some cases, building on top of private APIs is a recipe for constant fire drills (best case) and dead-end investment in frameworks that simply can’t work with newer versions of operating systems and libraries (worst case).\nThe framework should cover the maximum number of application users, not security use cases. There shouldn’t be one security framework that covers all security issues, and not every security issue is general enough to deserve its own framework. However, each security framework should be usable across all apps and OS versions for a particular platform. Small libraries are faster to build and deploy, and easier to maintain and explain to app developers.\nNow that we’ve looked at the design philosophy behind our frameworks, let’s look at one of our most widely used Android security frameworks, SecureLinkLauncher.\nSecureLinkLauncher: Preventing Android Intent Hijacking\nSecureLinkLauncher (SLL) is one of our widely-used secure frameworks. SLL is designed to prevent sensitive data from spilling through the Android intents system. It exemplifies our approach to secure-by-default frameworks by wrapping native Android intent launching methods with scope verification and security checks, preventing common vulnerabilities such as intent hijacking without sacrificing developer velocity or familiarity.\nThe system consists of intent senders and intent receivers. SLL is targeted to intent senders.\nSLL offers a semantic API that closely mirrors the familiar Android Context API for launching intents, including methods like startActivity() and startActivityForResult(). Instead of invoking the potentially insecure Android API directly, such as context.startActivity(intent);, developers use SecureLinkLauncher with a similar method call pattern, for example, SecureLinkLauncher.launchInternalActivity(intent, context);. Internally, SecureLinkLauncher delegates to the stable Android startActivity() API, ensuring that all intent launches are securely verified and protected by the framework.\npublic void launchInternalActivity(Intent intent, Context context) {\r\n   // Verify that the target activity is internal (same package)\r\n   if (!isInternalActivity(intent, context)) {\r\n       throw new SecurityException(\"Target activity is not internal\");\r\n   }\r\n   // Delegate to Android's startActivity to launch the intent\r\n   context.startActivity(intent);\r\n}\r\n\nSimilarly, instead of calling context.startActivityForResult(intent, code); directly, developers use SecureLinkLauncher.launchInternalActivityForResult(intent, code, context);. SecureLinkLauncher (SLL) wraps Android’s startActivity() and related methods, enforcing scope verification before delegating to the native Android API. This approach provides security by default while preserving the familiar Android intent launching semantics.\nOne of the most common ways that data is spilled through intents is due to incorrect targeting of the intent. As an example, following intent isn’t targeting a specific package. This means it can be received by any app with a matching <intent-filter>. While the intention of the developer might be that their Intent ends up in the Facebook app based on the URL, the reality is that any app, including a malicious application, could add an <intent-filter> that handles that URL and receive the intent. \nIntent intent = new Intent(FBLinks.PREFIX + \"profile\");\r\nintent.setExtra(SECRET_INFO, user_id);\r\nstartActivity(intent); \r\n// startActivity can’t ensure who the receiver of the intent would be\nIn the example below, SLL ensures that the intent is directed to one of the family apps, as specified by the developer’s scope for implicit intents. Without SLL, these intents can resolve to both family and non-family apps,potentially exposing SECRET_INFO to third-party or malicious apps on the user’s device. By enforcing this scope, SLL can prevent such information leaks.\nSecureLinkLauncher.launchFamilyActivity(intent, context); \r\n// launchFamilyActivity would make sure intent goes to the meta family apps\nIn a typical Android environment, two scopes – internal and external – might seem sufficient for handling intents within the same app and between different apps. However, Meta’s ecosystem is unique, comprising multiple apps such as Facebook, Instagram, Messenger, WhatsApp, and their variants (e.g., WhatsApp Business). The complexity of inter-process communication between these apps demands more nuanced control over intent scoping. To address this need, SLL provides a more fine-grained approach to intent scoping, offering scopes that cater to specific use cases:\nFamily scope: Enables secure communication between Meta-owned apps, ensuring that intents are only sent from one Meta app to another.\nSame-key scope: Restricts intent sending to Meta apps signed with the same key (not all Meta apps are signed by the same key), providing an additional layer of security and trust.\nInternal scope: Restricts intent sending within the app itself.\nThird-party scope: Allows intents to be sent to third-party apps, while preventing them from being handled by Meta’s own apps.\nBy leveraging these scopes, developers can ensure that sensitive data is shared securely and intentionally within the Meta ecosystem, while also protecting against unintended or malicious access. SLL’s fine-grained intent scoping capabilities, which are built upon the secure-by-default framework principles discussed above, empower developers to build more robust and secure applications that meet the unique demands of Meta’s complex ecosystem.\nLeveraging Generative AI To Deploy Secure-by-Default Frameworks at Scale\nAdopting these frameworks in a large codebase is non-trivial. The main complexity is choosing the correct scope, as that choice relies on information that is not readily available at existing call sites. While one could imagine a deterministic analysis attempting to infer the scope based on dataflows, that would be a large undertaking. Furthermore, it would likely have some precision-scalability trade-off. \nInstead, we explored using Generative AI for this case. AI can read the surrounding code and attempt to infer the scope based on variable names and comments surrounding the call site. While this approach isn’t always perfect, it doesn’t need to be. It just needs to provide good enough guesses, such that code owners can one-click accept suggested patches. \nIf the patches are correct in most cases, this is a big timesaver that enables efficient adoption of the framework. This complements our recent work on AutoPatchBench, a benchmark designed to evaluate AI-powered patch generators that leverage large language models (LLMs) to automatically recommend and apply security patches. Secure-by-default frameworks are a great example of the kinds of code modifications that an automatic patching system can apply to improve the security of a code base.\nWe’ve built a framework leveraging Llama as the core technology, which takes locations in the codebase that we want to migrate and suggests patches for code owners to accept:\n\nPrompt Creation\nThe AI workflow starts with a call site we want to migrate including its file path and line number. The location is used to extract a code snippet from the code base. This means opening the file where the call site is present, copying 10-20 lines before and after the call site location, and pasting this into the prompt template that gives general instructions as to how to perform the migration. This description is very similar to what would be written as an onboarding guide to the framework for human engineers.\nGenerative AI\nThe prompt is then provided to a Llama model (llama4-maverick-17b-128e-instruct). The model is asked to output two things: the modified code snippet, where the call site has been migrated; and, optionally, some actions (like adding an import to the top of a file). The main purpose of actions is to work around the limitations of this approach where all code changes are not local and limited to the code snippet. Actions enable the model fix to reach outside the snippet for some limited, deterministic changes. This is useful for adding imports or dependencies, which are rarely local to the code snippet, but are necessary for the code to compile. The code snippet is then inserted back to the code base and any actions are applied. \nValidation\nFinally, we perform a series of validations on the code base. We run all of these with and without the AI changes and only report the difference:\nLints: We run the linters again to confirm the lint issue was fixed and no new lint errors were introduced by the changes.\nCompiling: We compile and run tests covering the targeted file. This is not intended to catch all bugs (we rely on continuous integration for that), but give the AI some early feedback on its changes (such as compile errors). \nFormatting: The code is formatted to avoid formatting issues. We do not feed the formatting errors back to the AI.\nIf any errors arise during the validation, their error messages are included in the prompt (along with the “fixed” code snippet) and the AI is asked to try again. We repeat this loop five times and give up if no successful fix is created. If the validation succeeds, we submit a patch for human review.\nThoughtful Framework Design Meets Intelligent Automation\nBy adhering to core design principles such as providing an API that closely resembles existing OS patterns, relying solely on public and stable OS APIs, and designing frameworks that cover broad user bases rather than niche use cases, developers can create robust, secure-by-default features that integrate seamlessly into existing codebases.\n\nThese same design principles help us leverage AI for smoothly adopting frameworks at scale. While there are still challenges around the accuracy of generated code – for example, the AI choosing the incorrect scope, using incorrect syntax, etc., the internal feedback loop design allows the LLM to automatically move past easily solvable problems without human intervention, increasing scalability and reducing developer frustration.\nInternally, this project helped prove that AI could be impactful for adopting security frameworks across a diverse codebase in a way that is minimally disruptive to our developers. There are now a variety of projects tackling similar problems across a variety of codebases and languages – including C/++ – using diverse models and validation techniques. We expect this trend to continue and accelerate in 2026 as developers become more comfortable with state of the art AI tools and the quality of code that they are capable of producing.\nAs our codebase grows and security threats become more sophisticated, the combination of thoughtful framework design and intelligent automation will be essential to protecting user data and maintaining trust at scale.\nThe post How AI Is Transforming the Adoption of Secure-by-Default Mobile Frameworks appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Meta’s secure-by-default frameworks wrap potentially unsafe OS and third-party functions, making security the default while preserving developer speed and usability. These frameworks are designed to closely mirror existing APIs, rely on public and stable interfaces, and maximize developer adoption by minimizing friction and complexity. Generative AI and automation accelerate the adoption of secure frameworks at [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/12/15/android/how-ai-transforming-secure-by-default-mobile-frameworks-adoption/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/12/15/android/how-ai-transforming-secure-by-default-mobile-frameworks-adoption/\">How AI Is Transforming the Adoption of Secure-by-Default Mobile Frameworks</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Meta’s secure-by-default frameworks wrap potentially unsafe OS and third-party functions, making security the default while preserving developer speed and usability. These frameworks are designed to closely mirror existing APIs, rely on public and stable interfaces, and maximize developer adoption by minimizing friction and complexity. Generative AI and automation accelerate the adoption of secure frameworks at [...]\nRead More...\nThe post How AI Is Transforming the Adoption of Secure-by-Default Mobile Frameworks appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=23460",
        "categories": [
          "Android",
          "iOS",
          "ML Applications",
          "Security & Privacy"
        ],
        "isoDate": "2025-12-15T17:00:25.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Netflix TechBlog",
    "category": "기업",
    "posts": [
      {
        "creator": "Netflix Technology Blog",
        "title": "How Temporal Powers Reliable Cloud Operations at Netflix",
        "link": "https://netflixtechblog.com/how-temporal-powers-reliable-cloud-operations-at-netflix-73c69ccb5953?source=rss----2615bd06b42e---4",
        "pubDate": "Mon, 15 Dec 2025 23:51:59 GMT",
        "content:encodedSnippet": "By Jacob Meyers and Rob Zienert\nTemporal is a Durable Execution platform which allows you to write code “as if failures don’t exist”. It’s become increasingly critical to Netflix since its initial adoption in 2021, with users ranging from the operators of our Open Connect global CDN to our Live reliability teams now depending on Temporal to operate their business-critical services. In this post, I’ll give a high-level overview of what Temporal offers users, the problems we were experiencing operating Spinnaker that motivated its initial adoption at Netflix, and how Temporal helped us reduce the number of transient deployment failures at Netflix from 4% to 0.0001%.\nA Crash Course on (some of) Spinnaker\nSpinnaker is a multi-cloud continuous delivery platform that powers the vast majority of Netflix’s software deployments. It’s composed of several (mostly nautical themed) microservices. Let’s double-click on two in particular to understand the problems we were facing that led us to adopting Temporal.\nIn case you’re completely new to Spinnaker, Spinnaker’s fundamental tool for deployments is the Pipeline. A Pipeline is composed of a sequence of steps called Stages, which themselves can be decomposed into one or more Tasks, or other Stages. An example deployment pipeline for a production service may consist of these stages: Find Image -> Run Smoke Tests -> Run Canary -> Deploy to us-east-2 -> Wait -> Deploy to us-east-1.\nAn example Spinnaker Pipeline for a Netflix service\nPipeline configuration is extremely flexible. You can have Stages run completely serially, one after another, or you can have a mix of concurrent and serial Stages. Stages can also be executed conditionally based on the result of previous stages. This brings us to our first Spinnaker service: Orca. Orca is the orca-stration engine of Spinnaker. It’s responsible for managing the execution of the Stages and Tasks that a Pipeline unrolls into and coordinating with other Spinnaker services to actually execute them.\nOne of those collaborating services is called Clouddriver. In the example Pipeline above, some of the Stages will require interfacing with cloud infrastructure. For example, the canary deployment involves creating ephemeral hosts to run an experiment, and a full deployment of a new version of the service may involve spinning up new servers and then tearing down the old ones. We call these sorts of operations that mutate cloud infrastructure Cloud Operations. Clouddriver’s job is to decompose and execute Cloud Operations sent to it by Orca as part of a deployment. Cloud Operations sent from Orca to Clouddriver are relatively high level (for example: createServerGroup), so Clouddriver understands how to translate these into lower-level cloud provider API calls.\nPain points in the interaction between Orca and Clouddriver and the implementation details of Cloud Operation execution in Clouddriver are what led us to look for new solutions and ultimately migrate to Temporal, so we’ll next look at the anatomy of a Cloud Operation. Cloud Operations in the OSS version of Spinnaker still work as described below, so motivated readers can follow along in source code, however our migration to Temporal is entirely closed-source following a fork from OSS in 2020 to allow Netflix to make larger pivots to the product such as this one.\nThe Original Cloud Operation Flow\nA Cloud Operation’s execution goes something like this:\n\nOrca, in orchestrating a Pipeline execution, decides a particular Cloud Operation needs to be performed. It sends a POST request to Clouddriver’s /ops endpoint with an untyped bag-of-fields.\nClouddriver attempts to resolve the operation Orca sent into a set of AtomicOperation s— internal operations that only Clouddriver understands.\nIf the payload was valid and Clouddriver successfully resolved the operation, it will immediately return a Task ID to Orca.\nOrca will immediately begin polling Clouddriver’s GET /task/<id> endpoint to keep track of the status of the Cloud Operation.\nAsynchronously, Clouddriver begins executing AtomicOperations using its own internal orchestration engine. Ultimately, the AtomicOperations resolve into cloud provider API calls. As the Cloud Operation progresses, Clouddriver updates an internal state store to surface progress to Orca.\nEventually, if all went well, Clouddriver will mark the Cloud Operation complete, which eventually surfaces to Orca in its polling. Orca considers the Cloud Operation finished, and the deployment can progress.\nA sequence diagram of a Cloud Operation execution\nThis works well enough on the happy path, but veer off the happy path and dragons begin to emerge:\n\nClouddriver has its own internal orchestration system independent of Orca to allow Orca to query the progress of Cloud Operation. This is largely undifferentiated lifting relative to Clouddriver’s goal of actuating cloud infrastructure changes, and ultimately adds complexity and surface area for bugs to the application. Additionally, Orca is tightly coupled to Clouddriver’s orchestration system — it must understand how to poll Clouddriver, interpret the status, and handle errors returned by Clouddriver.\nDistributed systems are messy — networks and external services are unreliable. While executing a Cloud Operation, Clouddriver could experience transient network issues, or the cloud provider it’s attempting to call into may be having an outage, or any number of issues in between. Despite all of this, Clouddriver must be as reliable as reasonably possible as a core platform service. To deal with this shape of issue, Clouddriver internally evolved complex retry logic, further adding cognitive complexity to the system.\nRemember how a Cloud Operation gets decomposed by Clouddriver into AtomicOperations? Sometimes, if there’s a failure in the middle of a Cloud Operation, we need to be able to roll back what was done in AtomicOperations prior to the failure. This led to a homegrown Saga framework being implemented inside Clouddriver. While this did result in a big step forward in reliability of Cloud Operations facing transient failures because the Saga framework also allowed replaying partially-failed Cloud Operations, it added yet more undifferentiated lifting inside the service.\nThe task state kept by Clouddriver was instance-local. In other words, if the Clouddriver instance carrying out a Cloud Operation crashed, that Cloud Operation state was lost, and Orca would eventually time out polling for the task status. The Saga implementation mentioned above mitigated this for certain operations, but was not widely adopted across all cloud providers supported by Spinnaker.\n\nWe introduced a lot of incidental complexity into Clouddriver in an effort to keep Cloud Operation execution reliable, and despite all this deployments still failed around 4% of the time due to transient Cloud Operation failures.\nNow, I can already hear you saying: “So what? Can’t people re-try their deployments if they fail?” While true, some pipelines take days to complete for complex deployments, and a failed Cloud Operation mid-way through requires re-running the whole thing. This was detrimental to engineering productivity at Netflix in a non-trivial way. Rather than continue trying to build a faster horse, we began to look elsewhere for our reliable orchestration requirements, which is where Temporal comes in.\nTemporal: Basic Concepts\nTemporal is an open source product that offers a durable execution platform for your applications. Durable execution means that the platform will ensure your programs run to completion despite adverse conditions. With Temporal, you organize your business logic into Workflows, which are a deterministic series of steps. The steps inside of Workflows are called Activities, which is where you encapsulate all your non-deterministic logic that needs to happen in the course of executing your Workflows. As your Workflows execute in processes called Workers, the Temporal server durably stores their execution state so that in the event of failures your Workflows can be retried or even migrated to a different Worker. This makes Workflows incredibly resilient to the sorts of transient failures Clouddriver was susceptible to. Here’s a simple example Workflow in Java that runs an Activity to send an email once every 30 days:\n@WorkflowInterface\npublic interface SleepForDaysWorkflow {\n    @WorkflowMethod\n    void run();\n}\npublic class SleepForDaysWorkflowImpl implements SleepForDaysWorkflow {\n    private final SendEmailActivities emailActivities =\n            Workflow.newActivityStub(\n                    SendEmailActivities.class,\n                    ActivityOptions.newBuilder()\n                            .setStartToCloseTimeout(Duration.ofSeconds(10))\n                            .build());\n    @Override\n    public void run() {\n        while (true) {\n            // Activities already carry retries/timeouts via options.\n            emailActivities.sendEmail();\n            // Pause the workflow for 30 days before sending the next email.\n            Workflow.sleep(Duration.ofDays(30));\n        }\n    }\n}\n@ActivityInterface\npublic interface SendEmailActivities {\n    void sendEmail();\n}\nThere’s some interesting things to note about this Workflow:\n\nWorkflows and Activities are just code, so you can test them using the same techniques and processes as the rest of your codebase.\nActivities are automatically retried by Temporal with configurable exponential backoff.\nTemporal manages all the execution state of the Workflow, including timers (like the one used by Workflow.sleep). If the Worker executing this workflow were to have its power cable unplugged, Temporal would ensure another Worker continues to execute it (even during the 30 day sleep).\nWorkflow sleeps are not compute-intensive, and they don’t tie up the process.\n\nYou might already begin to see how Temporal solves a lot of the problems we had with Clouddriver. Ultimately, we decided to pull the trigger on migrating Cloud Operation execution to Temporal.\nCloud Operations with Temporal\nToday, we execute Cloud Operations as Temporal workflows. Here’s what that looks like.\n\nOrca, using a Temporal client, sends a request to Temporal to execute an UntypedCloudOperationRunner Workflow. The contract of the Workflow looks something like this:\n\n@WorkflowInterface\ninterface UntypedCloudOperationRunner {\n  /**\n   * Runs a cloud operation given an untyped payload.\n   *\n   * WorkflowResult is a thin wrapper around OutputType providing a standard contract for\n   * clients to determine if the CloudOperation was successful and fetching any errors.\n   */\n  @WorkflowMethod\n  fun <OutputType : CloudOperationOutput> run(stageContext: Map<String, Any?>, operationType: String): WorkflowResult<OutputType>\n}\n2. The Clouddriver Temporal worker is constantly polling Temporal for work. A worker will eventually see a task for an UntypedCloudOperationRunner Workflow and start executing it.\n3. Similar to before with resolution into AtomicOperations, Clouddriver does some pre-processing of the bag-of-fields in stageContext and resolves it to a strongly typed implementation of the CloudOperation Workflow interface based on the operationType input and the stageContext:\ninterface CloudOperation<I : CloudOperationInput, O : CloudOperationOutput> {\n  @WorkflowMethod\n  fun operate(input: I, credentials: AccountCredentials<out Any>): O\n}\n4. Clouddriver starts a Child Workflow execution of the CloudOperation implementation it resolved. The child workflow will execute Activities which handle the actual cloud provider API calls to mutate infrastructure.\n5. Orca uses its Temporal Client to await completion of the UntypedCloudOperationRunner Workflow. Once it’s complete, Temporal notifies the client and sends the result and Orca can continue progressing the deployment.\nSequence diagram of a Cloud Operation execution with Temporal\nResults and Lessons Learned from the Migration\nA shiny new architecture is great, but equally important is the non-glamorous work of refactoring legacy systems to fit the new architecture. How did we integrate Temporal into critical dependencies of all Netflix engineers transparently?\nThe answer, of course, is a combination of abstraction and dynamic configuration. We built a CloudOperationRunner interface in Orca to encapsulate whether the Cloud Operation was being executed via the legacy path or Temporal. At runtime, Fast Properties (Netflix’s dynamic configuration system) determined which path a stage that needed to execute a Cloud Operation would take. We could set these properties quite granularly — by Stage type, cloud provider account, Spinnaker application, Cloud Operation type (createServerGroup), and cloud provider (either AWS or Titus in our case). The Spinnaker services themselves were the first to be deployed using Temporal, and within two quarters, all applications at Netflix were onboarded.\nImpact\nWhat did we have to show for it all? With Temporal as the orchestration engine for Cloud Operations, the percentage of deployments that failed due to transient Cloud Operation failures dropped from 4% to 0.0001%. For those keeping track at home, that’s a four and a half order of magnitude reduction. Virtually eliminating this failure mode for deployments was a huge win for developer productivity, especially for teams with long and complex deployment pipelines.\nBeyond the improvement in deployment success metrics, we saw a number of other benefits:\n\nOrca no longer needs to directly communicate with Clouddriver to start Cloud Operations or poll their status with Temporal as the intermediary. The services are less coupled, which is a win for maintainability.\nSpeaking of maintainability, with Temporal doing the heavy lifting of orchestration and retries inside of Clouddriver, we got to remove a lot of the homegrown logic we’d built up over the years for the same purpose.\nSince Temporal manages execution state, Clouddriver instances became stateless and Cloud Operation execution can bounce between instances with impunity. We can treat Clouddriver instances more like cattle and enable things like Chaos Monkey for the service which we were previously prevented from doing.\nMigrating Cloud Operation steps into Activities was a forcing function to re-write the logic to be idempotent. Since Temporal retries activities by default, it’s generally recommended they be idempotent. This alone fixed a number of issues that existed previously when operations were retried in Clouddriver.\nWe set the retry timeout for Activities in Clouddriver to be two hours by default. This gives us a long leash to fix-forward or rollback Clouddriver if we introduce a regression before customer deployments fail — to them, it might just look like a deployment is taking longer than usual.\nCloud Operations are much easier to introspect than before. Temporal ships with a great UI to help visualize Workflow and Activity executions, which is a huge boon for debugging live Workflows executing in production. The Temporal SDKs and server also emit a lot of useful metrics.\nExecution of a resizeServerGroup Cloud Operation as seen from the Temporal UI. This operation executes 3 Activities: DescribeAutoScalingGroup, GetHookConfigurations, and ResizeServerGroup\nLessons Learned\nWith the benefit of hindsight, there are also some lessons we can share from this migration:\n1. Avoid unnecessary Child Workflows: Structuring Cloud Operations as an UntypedCloudOperationRunner Workflow that starts Child Workflows to actually execute the Cloud Operation’s logic was unnecessary and the indirection made troubleshooting more difficult. There are situations where Child Workflows are appropriate, but in this case we were using them as a tool for code organization, which is generally unnecessary. We could’ve achieved the same effect with class composition in the top-level parent Workflow.\n2. Use single argument objects: At first, we structured Workflow and Activity functions with variable arguments, much as you’d write normal functions. This can be problematic for Temporal because of Temporal’s determinism constraints. Adding or removing an argument from a function signature is not a backward-compatible change, and doing so can break long-running workflows — and it’s not immediately obvious in code review your change is problematic. The preferred pattern is to use a single serializable class to host all your arguments for Workflows and Activities — these can be more freely changed without breaking determinism.\n3. Separate business failures from workflow failures: We like the pattern of the WorkflowResult type that UntypedCloudOperationRunner returns in the interface above. It allows us to communicate business process failures without failing the Workflow itself and have more overall nuance in error handling. This is a pattern we’ve carried over to other Workflows we’ve implemented since.\nTemporal at Netflix Today\nTemporal adoption has skyrocketed at Netflix since its initial introduction for Spinnaker. Today, we have hundreds of use cases, and we’ve seen adoption double in the last year with no signs of slowing down.\nOne major difference between initial adoption and today is that Netflix migrated from an on-prem Temporal deployment to using Temporal Cloud, which is Temporal’s SaaS offering of the Temporal server. This has let us scale Temporal adoption while running a lean team. We’ve also built up a robust internal platform around Temporal Cloud to integrate with Netflix’s internal ecosystem and make onboarding for our developers as easy as possible. Stay tuned for a future post digging into more specifics of our Netflix Temporal platform.\nAcknowledgement\nWe all stand on the shoulders of giants in software. I want to call out that I’m retelling the work of my two stunning colleagues Chris Smalley and Rob Zienert in this post, who were the two aforementioned engineers who introduced Temporal and carried out the migration.\n\nHow Temporal Powers Reliable Cloud Operations at Netflix was originally published in Netflix TechBlog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Netflix Technology Blog",
        "guid": "https://medium.com/p/73c69ccb5953",
        "isoDate": "2025-12-15T23:51:59.000Z"
      },
      {
        "creator": "Netflix Technology Blog",
        "title": "Netflix Live Origin",
        "link": "https://netflixtechblog.com/netflix-live-origin-41f1b0ad5371?source=rss----2615bd06b42e---4",
        "pubDate": "Mon, 15 Dec 2025 17:38:16 GMT",
        "content:encodedSnippet": "Xiaomei Liu, Joseph Lynch, Chris Newton\nIntroduction\nBehind the Streams: Building a Reliable Cloud Live Streaming Pipeline for Netflix introduced the architecture of the streaming pipeline. This blog post looks at the custom Origin Server we built for Live — the Netflix Live Origin. It sits at the demarcation point between the cloud live streaming pipelines on its upstream side and the distribution system, Open Connect, Netflix’s in-house Content Delivery Network (CDN), on its downstream side, and acts as a broker managing what content makes it out to Open Connect and ultimately to the client devices.\nLive Streaming Distribution and Origin Architecture\nNetflix Live Origin is a multi-tenant microservice operating on EC2 instances within the AWS cloud. We lean on standard HTTP protocol features to communicate with the Live Origin. The Packager pushes segments to it using PUT requests, which place a file into storage at the particular location named in the URL. The storage location corresponds to the URL that is used when the Open Connect side issues the corresponding GET request.\nLive Origin architecture is influenced by key technical decisions of the live streaming architecture. First, resilience is achieved through redundant regional live streaming pipelines, with failover orchestrated at the server-side to reduce client complexity. The implementation of epoch locking at the cloud encoder enables the origin to select a segment from either encoding pipeline. Second, Netflix adopted a manifest design with segment templates and constant segment duration to avoid frequent manifest refresh. The constant duration templates enable Origin to predict the segment publishing schedule.\nMulti-pipeline and multi-region aware origin\nLive streams inevitably contain defects due to the non-deterministic nature of live contribution feeds and strict real-time segment publishing timelines. Common defects include:\n\nShort segments: Missing video frames and audio samples.\nMissing segments: Entire segments are absent.\nSegment timing discontinuity: Issues with the Track Fragment Decode Time.\n\nCommunicating segment discontinuity from the server to the client via a segment template-based manifest is impractical, and these defective segments can disrupt client streaming.\nThe redundant cloud streaming pipelines operate independently, encompassing distinct cloud regions, contribution feeds, encoder, and packager deployments. This independence substantially mitigates the probability of simultaneous defective segments across the dual pipelines. Owing to its strategic placement within the distribution path, the live origin naturally emerges as a component capable of intelligent candidate selection.\nThe Netflix Live Origin features multi-pipeline and multi-region awareness. When a segment is requested, the live origin checks candidates from each pipeline in a deterministic order, selecting the first valid one. Segment defects are detected via lightweight media inspection at the packager. This defect information is provided as metadata when the segment is published to the live origin. In the rare case of concurrent defects at the dual pipeline, the segment defects can be communicated downstream for intelligent client-side error concealment.\nOpen Connect streaming optimization\nWhen the Live project started, Open Connect had become highly optimised for VOD content delivery — nginx had been chosen many years ago as the Web Server since it is highly capable in this role, and a number of enhancements had been added to it and to the underlying operating system (BSD). Unlike traditional CDNs, Open Connect is more of a distributed origin server — VOD assets are pre-positioned onto carefully selected server machines (OCAs, or Open Connect Appliances) rather than being filled on demand.\nAlongside the VOD delivery, an on-demand fill system has been used for non-VOD assets — this includes artwork and the downloadable portions of the clients, etc. These are also served out of the same nginx workers, albeit under a distinct server block, using a distinct set of hostnames.\nLive didn’t fit neatly into this ‘small object delivery’ model, so we extended the proxy-caching functionality of nginx to address Live-specific needs. We will touch on some of these here related to optimized interactions with the Origin Server. Look for a future blog post that will go into more details on the Open Connect side.\nThe segment templates provided to clients are also provided to the OCAs as part of the Live Event Configuration data. Using the Availability Start Time and Initial Segment number, the OCA is able to determine the legitimate range of segments for each event at any point in time — requests for objects outside this range can be rejected, preventing unnecessary requests going up through the fill hierarchy to the origin. If a request makes it through to the origin, and the segment isn’t available yet, the origin server will return a 404 Status Code (indicating File Not Found) with the expiration policy of that error so that it can be cached within Open Connect until just before that segment is expected to be published.\nIf the Live Origin knows when segments are being pushed to it, and knows what the live edge is — when a request is received for the immediately next object, rather than handing back another 404 error (which would go all the way back through Open Connect to the client), the Live Origin can ‘hold open’ the request, and service it once the segment has been published to it. By doing this, the degree of chatter within the network handling requests that arrive early has been significantly reduced. As part of this, millisecond grain caching was added to nginx to enhance the standard HTTP Cache Control, which only works at second granularity, a long time when segments are generated every 2 seconds.\nStreaming metadata enhancement\nThe HTTP standard allows for the addition of request and response headers that can be used to provide additional information as files move between clients and servers. The HTTP headers provide notifications of events within the stream in a highly scalable way that is independently conveyed to client devices, regardless of their playback position within the stream.\nThese notifications are provided to the origin by the live streaming pipeline and are inserted by the origin in the form of headers, appearing on the segments generated at that point in time (and persist to future segments — they are cumulative). Whenever a segment is received at an OCA, this notification information is extracted from the response headers and used to update an in-memory data structure, keyed by event ID; and whenever a segment is served from the OCA, the latest such notification data is attached to the response. This means that, given any flow of segments into an OCA, it will always have the most recent notification data, even if all clients requesting it are behind the live edge. In fact, the notification information can be conveyed on any response, not just those supplying new segments.\nCache invalidation and origin mask\nAn invalidation system has been available since the early days of the project. It can be used to “flush” all content associated with an event by altering the key used when looking up objects in cache — this is done by incorporating a version number into the cache key that can then be bumped on demand. This is used during pre-event testing so that the network can be returned to a pristine state for the test with minimal fuss.\nEach segment published by the Live Origin conveys the encoding pipeline it was generated by, as well as the region it was requested from. Any issues that are found after segments make their way into the network can be remedied by an enhanced invalidation system that takes such variants into account. It is possible to invalidate (that is, cause to be considered expired) segments in a range of segment numbers, but only if they were sourced from encoder A, or from Encoder A, but only if retrieved from region X.\nIn combination with Open Connect’s enhanced cache invalidation, the Netflix Live Origin allows selective encoding pipeline masking to exclude a range of segments from a particular pipeline when serving segments to Open Connect. The enhanced cache invalidation and origin masking enable live streaming operations to hide known problematic segments (e.g., segments causing client playback errors) from streaming clients once the bad segments are detected, protecting millions of streaming clients during the DVR playback window.\nOrigin storage architecture\nOur original storage architecture for the Live Origin was simple: just use AWS S3 like we do for SVOD. This served us well initially for our low-traffic events, but as we scaled up we discovered that Live streaming has unique latency and workload requirements that differ significantly from on-demand where we have significant time ahead-of-time to pre-position content. While S3 met its stated uptime guarantees, our strict 2-second retry budget inherent to Live events (where every write is critical) led us to explore optimizations specifically tailored for real-time delivery at scale. AWS S3 is an amazing object store, but our Live streaming requirements were closer to those of a global low-latency highly-available database. So, we went back to the drawing board and started from the requirements. The Origin required:\n\n[HA Writes] Extremely high write availability, ideally as close to full write availability within a single AWS region, with low second replication delay to other regions. Any failed write operation within 500ms is considered a bug that must be triaged and prevented from re-occurring.\n[Throughput] High write throughput, with hundreds of MiB replicating across regions\n[Large Partitions] Efficiently support O(MiB) writes that accumulate to O(10k) keys per partition with O(GiB) total size per event.\n[Strong Consistency] Within the same region, we needed read-your-write semantics to hit our <1s read delay requirements (must be able to read published segments)\n[Origin Storm] During worst-case load involving Open Connect edge cases, we may need to handle O(GiB) of read throughput without affecting writes.\n\nFortunately, Netflix had previously invested in building a KeyValue Storage Abstraction that cleverly leveraged Apache Cassandra to provide chunked storage of MiB or even GiB values. This abstraction was initially built to support cloud saves of Game state. The Live use case would push the boundaries of this solution, however, in terms of availability for writes (#1), cumulative partition size (#3), and read throughput during Origin Storm (#5).\nHigh Availability for Writes of Large Payloads\nThe KeyValue Payload Chunking and Compression Algorithm breaks O(MiB) work down so each part can be idempotently retried and hedged to maintain strict latency service level objectives, as well as spreading the data across the full cluster. When we combine this algorithm with Apache Cassandra’s local-quorum consistency model, which allows write availability even with an entire Availability Zone outage, plus a write-optimized Log-Structured Merge Tree (LSM) storage engine, we could meet the first four requirements. After iterating on the performance and availability of this solution, we were not only able to achieve the write availability required, but did so with a P99 tail latency that was similar to the status quo’s P50 average latency while also handling cross-region replication behind the scenes for the Origin. This new solution was significantly more expensive (as expected, databases backed by SSD cost more), but minimizing cost was not a key objective and low latency with high availability was:\nStorage System Write Performance\nHigh Availability Reads at Gbps Throughputs\nNow that we solved the write reliability problem, we had to handle the Origin Storm failure case, where potentially dozens of Open Connect top-tier caches could be requesting multiple O(MiB) video segments at once. Our back-of-the-envelope calculations showed worst-case read throughput in the O(100Gbps) range, which would normally be extremely expensive for a strongly-consistent storage engine like Apache Cassandra. With careful tuning of chunk access, we were able to respond to reads at network line rate (100Gbps) from Apache Cassandra, but we observed unacceptable performance and availability degradation on concurrent writes. To resolve this issue, we introduced write-through caching of chunks using our distributed caching system EVCache, which is based on Memcached. This allows almost all reads to be served from a highly scalable cache, allowing us to easily hit 200Gbps and beyond without affecting the write path, achieving read-write separation.\nFinal Storage Architecture\nIn the final storage architecture, the Live Origin writes and reads to KeyValue, which manages a write-through cache to EVCache (memcached) and implements a safe chunking protocol that spreads large values and partitions them out across the storage cluster (Apache Cassandra). This allows almost all read load to be handled from cache, with only misses hitting the storage. This combination of cache and highly available storage has met the demanding needs of our Live Origin for over a year now.\nStorage System High Level Architecture\nDelivering this consistent low latency for large writes with cross-region replication and consistent write-through caching to a distributed cache required solving numerous hard problems with novel techniques, which we plan to share in detail during a future post.\nScalability and scalable architecture\nNetflix’s live streaming platform must handle a high volume of diverse stream renditions for each live event. This complexity stems from supporting various video encoding formats (each with multiple encoder ladders), numerous audio options (across languages, formats, and bitrates), and different content versions (e.g., with or without advertisements). The combination of these elements, alongside concurrent event support, leads to a significant number of unique stream renditions per live event. This, in turn, necessitates a high Requests Per Second (RPS) capacity from the multi-tenant live origin service to ensure publishing-side scalability.\nIn addition, Netflix’s global reach presents distinct challenges to the live origin on the retrieval side. During the Tyson vs. Paul fight event in 2024, a historic peak of 65 million concurrent streams was observed. Consequently, a scalable architecture for live origin is essential for the success of large-scale live streaming.\nScaling architecture\nWe chose to build a highly scalable origin instead of relying on the traditional origin shields approach for better end-to-end cache consistency control and simpler system architecture. The live origin in this architecture directly connects with top-tier Open Connect nodes, which are geographically distributed across several sites. To minimize the load on the origin, only designated nodes per stream rendition at each site are permitted to directly fill from the origin.\nNetflix Live Origin Scalability Architecture\nWhile the origin service can autoscale horizontally using EC2 instances, there are other system resources that are not autoscalable, such as storage platform capacity and AWS to Open Connect backbone bandwidth capacity. Since in live streaming, not all requests to the live origin are of the same importance, the origin is designed to prioritize more critical requests over less critical requests when system resources are limited. The table below outlines the request categories, their identification, and protection methods.\n\nPublishing isolation\nPublishing traffic, unlike potentially surging CDN retrieval traffic, is predictable, making path isolation a highly effective solution. As shown in the scalability architecture diagram, the origin utilizes separate EC2 publishing and CDN stacks to protect the latency and failure-sensitive origin writes. In addition, the storage abstraction layer features distinct clusters for key-value (KV) read and KV write operations. Finally, the storage layer itself separates read (EVCache) and write (Cassandra) paths. This comprehensive path isolation facilitates independent cloud scaling of publishing and retrieval, and also prevents CDN-facing traffic surges from impacting the performance and reliability of origin publishing.\nPriority rate limiting\nGiven Netflix’s scale, managing incoming requests during a traffic storm is challenging, especially considering non-autoscalable system resources. The Netflix Live Origin implemented priority-based rate limiting when the underlying system is under stress. This approach ensures that requests with greater user impact are prioritized to succeed, while requests with lower user impact are allowed to fail during times of stress in order to protect the streaming infrastructure and are permitted to retry later to succeed.\nLeveraging Netflix’s microservice platform priority rate limiting feature, the origin prioritizes live edge traffic over DVR traffic during periods of high load on the storage platform. The live edge vs. DVR traffic detection is based on the predictable segment template. The template is further cached in memory on the origin node to enable priority rate limiting without access to the datastore, which is valuable especially during periods of high datastore stress.\nTo mitigate traffic surges, TTL cache control is used alongside priority rate limiting. When the low-priority traffic is impacted, the origin instructs Open Connect to slow down and cache identical requests for 5 seconds by setting a max-age = 5s and returns an HTTP 503 error code. This strategy effectively dampens traffic surges by preventing repeated requests to the origin within that 5-second window.\nThe following diagrams illustrate origin priority rate limiting with simulated traffic. The nliveorigin_mp41 traffic is the low-priority traffic and is mixed with other high-priority traffic. In the first row: the 1st diagram shows the request RPS, the 2nd diagram shows the percentage of request failure. In the second row, the 1st diagram shows datastore resource utilization, and the 2nd diagram shows the origin retrieval P99 latency. The results clearly show that only the low-priority traffic (nliveorigin_mp41) is impacted at datastore high utilization, and the origin request latency is under control.\nOrigin Priority Rate Limiting\n404 storm and cache optimization\nPublishing isolation and priority rate limiting successfully protect the live origin from DVR traffic storms. However, the traffic storm generated by requests for non-existent segments presents further challenges and opportunities for optimization.\nThe live origin structures metadata hierarchically as event > stream rendition > segment, and the segment publishing template is maintained at the stream rendition level. This hierarchical organization allows the origin to preemptively reject requests with an HTTP 404(not found)/410(Gone) error, leveraging highly cacheable event and stream rendition level metadata, avoiding unnecessary queries to the segment level metadata:\n\nIf the event is unknown, reject the request with 404\nIf the event is known, but the segment request timing does not match the expected publishing timing, reject the request with 404 and cache control TTL matching the expected publishing time\nIf the event is known, the requested segment is never generated or misses the retry deadline, reject the request with a 410 error, preventing the client from repeatedly requesting\n\nAt the storage layer, metadata is stored separately from media data in the control plane datastore. Unlike the media datastore, the control plane datastore does not use a distributed cache to avoid cache inconsistency. Event and rendition level metadata benefits from a high cache hit ratio when in-memory caching is utilized at the live origin instance. During traffic storms involving non-existent segments, the cache hit ratio for control plane access easily exceeds 90%.\nThe use of in-memory caching for metadata effectively handles 404 storms at the live origin without causing datastore stress. This metadata caching complements the storage system’s distributed media cache, providing a complete solution for traffic surge protection.\nSummary\nThe Netflix Live Origin, built upon an optimized storage platform, is specifically designed for live streaming. It incorporates advanced media and segment publishing scheduling awareness and leverages enhanced intelligence to improve streaming quality, optimize scalability, and improve Open Connect live streaming operations.\nAcknowledgement\nMany teams and stunning colleagues contributed to the Netflix live origin. Special thanks to Flavio Ribeiro for advocacy and sponsorship of the live origin project; to Raj Ummadisetty, Prudhviraj Karumanchi for the storage platform; to Rosanna Lee, Hunter Ford, and Thiago Pontes for storage lifecycle management; to Ameya Vasani for e2e test framework; Thomas Symborski for orchestrator integration; to James Schek for Open Connect integration; to Kevin Wang for platform priority rate limit; to Di Li, Nathan Hubbard for origin scalability testing.\n\nNetflix Live Origin was originally published in Netflix TechBlog on Medium, where people are continuing the conversation by highlighting and responding to this story.",
        "dc:creator": "Netflix Technology Blog",
        "guid": "https://medium.com/p/41f1b0ad5371",
        "categories": [
          "live-origin",
          "live-streaming",
          "content-delivery-network",
          "cloud-storage"
        ],
        "isoDate": "2025-12-15T17:38:16.000Z"
      }
    ]
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Ksenia Shneyveys",
        "title": "How Mobile Development Teams Use Kotlin in 2025: Insights From a Certified Trainer",
        "link": "https://blog.jetbrains.com/kotlin/2025/12/how-mobile-development-teams-use-kotlin-in-2025/",
        "pubDate": "Fri, 19 Dec 2025 14:44:34 +0000",
        "content:encodedSnippet": "This is the second guest post in a two-part series from José Luis González. José Luis has a PhD in software development and is a JetBrains-certified Kotlin Trainer, who works with developers and engineering teams to deepen their Kotlin skills and apply the language effectively in real projects. At Hyperskill, he runs Kotlin instructor-led training for teams at Hyperskill that focus on advanced topics and practical problem-solving rather than theory.\nFirst post in the series: How Backend Development Teams Use Kotlin in 2025: Insights from a Certified Trainer\nI’d probably have to say swallowing CancellationException in general catch blocks (including runCatching). It looks harmless, but it disables cooperative cancellation, so timeouts, parent scopes, and lifecycles keep running “mysteriously.” In recent talks, linters, and guides, you still see this called out as a real-world production bug. Official docs stress that cancellation must propagate, detekt ships a rule warning if you don’t rethrow, and the coroutines library provides mechanisms that avoid catching CancellationException in generic catch-alls.\nUse the following pattern instead to always rethrow cancellations (or choose a helper that preserves them):\nsuspend fun <T> safeCall(block: suspend () -> T, fallback: () -> T): T = try {\n    block()\n} catch (e: CancellationException) {\n    throw e // never swallow cancellation\n}\n// catch other specific exceptions\n} catch (e: Exception) {\n    logger.error(\"call failed\", e)\n    fallback()\n}\nIf you like Result-style API, mirror the kotlinx approach as follows:\nsuspend inline fun <T> runSuspendCatching(block: () -> T): Result<T> =\n    try { Result.success(block()) }\n    catch (e: CancellationException) { throw e }\n    catch (e: Throwable) { Result.failure(e) }\nThis tiny rethrow keeps structured concurrency intact and matches the guidance you’ll hear in the latest coroutine discussions.\n2. If a team has only two hours to set up monitoring for their mobile Kotlin app, which specific dashboards should they prioritize?\nBegin with metrics that indicate whether users can successfully use the app. Crash-free users and ANR rate by version and device model tell you whether a release is safe to ship.\nFirebase Crashlytics handles this out of the box – just tag builds for quick filtering:\nFirebaseCrashlytics.getInstance().setCustomKeys {\n    key(\"version\", BuildConfig.VERSION_NAME)\n    key(\"commit\", BuildConfig.GIT_SHA)\n}\nAs for UI issues, use JankStats to log when and where frames drop, so you know which screens stutter:\nval jankStats = JankStats.create(window) { frame ->\n    if (frame.isJank) Log.d(\"Jank\",\n        \"Jank on ${currentScreen()} – ${(frame.frameDurationUiNanos / 1_000_000)}ms\")\n}\njankStats.isTrackingEnabled = true\nAnother main concern is performance, of course. With Sentry, you get end-to-end insights into what is actually slowing down your app: startup, navigation, network calls, etc. It correlates frontend and backend timing so you can spot bottlenecks and regressions fast.\nHere is a standard setup with tracing and profiling:\nSentryAndroid.init(this) { options ->\n    options.dsn = \"<dsn>\"\n    options.tracesSampleRate = 0.1\n    options.profilesSampleRate = 0.05\n    options.release = \"${BuildConfig.VERSION_NAME} (${BuildConfig.VERSION_CODE})\"\n    options.environment = BuildConfig.BUILD_TYPE\n}\nNow, let’s add some custom transactions for key flows:\nval tx = Sentry.startTransaction(\"screen:${currentScreen()}\", \"ui.load\")\nSentry.configureScope { it.setTransaction(tx) }\n\nval net = tx.startChild(\"http.client\", \"GET /api/items\")\ntry { /* network call */ } finally { net.finish() }\n\nval db = tx.startChild(\"db.query\", \"SELECT items\")\ntry { /* read */ } finally { db.finish() }\n\ntx.finish()\nAnd auto-tracing for network calls (OkHttp and Ktor):\nOkHttp:\nval client = OkHttpClient.Builder()\n    .addInterceptor(SentryOkHttpInterceptor())\n    .build()\nKtor:\nval client = HttpClient(CIO) {\n    install(Sentry) {\n        tracesSampleRate = 0.1\n        profilesSampleRate = 0.05\n    }\n}\nSentry Mobile Insights provides a prebuilt dashboard for this. It groups slow transactions and crash-free rate by release and device model, so you can see exactly where users struggle the most without the need for a custom setup.\nHere’s how a real trace looks in Sentry: You can see a cold start (app.start.cold), API calls, and rendering time, all visualized in one timeline, for a detailed breakdown of how much time the app spends on various tasks.\n\n\n\n\nCheck these dashboards in Sentry:\nPerformance / Transactions: p95 duration for app.start.cold, ui.load, and checkout.\nTraces / Slow spans to find lags in HTTP, database, or main-thread work.\nReleases / Crash-free and ANR: Correlate stability with performance.\nSentry (or Crashlytics) combined with JankStats will give you the full picture. Can users open the app, interact smoothly, and exit without crashes or leaks? Sentry covers both performance and crash tracking, so you can often use it alone, while Crashlytics remains a lightweight alternative many teams already have in place.\n3. When a mobile Kotlin application is running slowly in production, what are your top three profiling techniques, and what tools do you use for each?\nI wouldn’t say there’s anything groundbreaking here. I usually start with the same baseline we talked about earlier: Crashlytics, JankStats, and Sentry traces. They will provide a comprehensive overview of what’s going on. From there, my top three profiling techniques are pretty straightforward but extremely effective.\nHonestly, the standalone Android Studio profiler is still the most powerful and underrated tool out there. I spend most of my time in its CPU and memory profilers, checking which methods block the main thread or which allocations spike during transitions. I always check the Sample Call Stack view, as it’s the fastest way to see where time is actually spent per frame, instead of guessing from logs.\nIt sounds basic, but it often reveals that a single RecyclerView binding or JSON parser allocates thousands of tiny objects per frame.\nAlso, I would typically do network profiling. Using the Network Inspector or Sentry’s tracing, I check which requests block rendering or input. If scrolling freezes when images load, you can immediately tell whether it’s an uncompressed call or a missing cache layer without guessing. If you’ve already enabled Sentry Performance in the Monitoring section of the settings menu, it doubles as lightweight production profiling. You can literally see slow transactions by endpoint.\nFrame-time profiling is something that comes in handy as well. I like using JankStats or even adb shell dumpsys gfxinfo to see which screens consistently drop frames. Then I pair that with LeakCanary to catch activities or bitmaps that stay alive longer than they should. Together, that tells me exactly what’s slowing the UI down.\nIn short, you don’t really need fancy tools. CPU, memory, network, and frame-time profiling, all within Android Studio, cover about 90% of the real issues. These profiling tools help identify what’s making the app feel slow, so you can easily fix the underlying problems. \n4. When teams ask about Kotlin Multiplatform, what’s the smallest project they should start with to prove the concept?\nI usually remind teams that they’re probably using Kotlin Multiplatform already. Libraries like kotlinx.coroutines or kotlinx.serialization are basically multiplatform under the hood. You’re just using them from Android today, but they work the same on iOS, too.\nThe smallest realistic project to actually prove Kotlin Multiplatform in your environment is a shared data or utility layer – something both applications can call without touching the UI. A great first step is to share one simple function, like returning the current time or a version string:\n// commonMain\nexpect fun currentTime(): Long\n\n// androidMain / iosMain\nactual fun currentTime() = System.currentTimeMillis() // or NSDate().timeIntervalSince1970\nHere’s how to connect the Kotlin framework generated from the Kotlin Multiplatform project to your Xcode project:\nThe embedAndSignAppleFrameworkForXcode task only registers if the binaries.framework configuration option is declared. In your Kotlin Multiplatform project, check the iOS target declaration in the build.gradle.kts file.\nkotlin {\n    ios() // or iosArm64(), iosX64(), iosSimulatorArm64()\n    binaries {\n        framework {\n            baseName = \"Shared\"\n        }\n    }\n}\nTo automatically build a shared module in Xcode, you need to add a script. In the Build Phases tab, add a run script with the following code:\ncd \"$SRCROOT/..\"\n./gradlew :shared:embedAndSignAppleFrameworkForXcode\n\n\n\n\nUsing the specified script, access the Gradle task to create and embed the library into the native iOS application.\nThen you should move the Run Script phase higher, placing it before the Compile Sources phase.\n\n\n\n\nAfter running the build on the iOS app side or iosApp configuration from the Kotlin Multiplatform project, the compiled xcode-frameworks will appear in the build folder of the shared module.\nThis will generate the framework at:\n\n\n\n\nThen import it into Swift:\nimport Shared\n\nlet t = currentTime() // works directly from the shared Kotlin code\nIf that builds and runs cleanly, you’ve already proven that Kotlin code can compile and interop on both sides. From there, you can expand to something slightly more useful. For example, a shared module that fetches and parses a list of items using Ktor and kotlinx.serialization.\nJosé Luis González\nJosé Luis González, PhD, is a JetBrains-certified Kotlin Trainer who teaches Kotlin and advanced techniques to development teams. If your team has more questions about Kotlin anti-patterns, idiomatic design, or wants to learn how to write more maintainable Kotlin code, explore his instructor-led Kotlin workshops at Hyperskill.",
        "dc:creator": "Ksenia Shneyveys",
        "content": "This is the second guest post in a two-part series from José Luis González. José Luis has a PhD in software development and is a JetBrains-certified Kotlin Trainer, who works with developers and engineering teams to deepen their Kotlin skills and apply the language effectively in real projects. At Hyperskill, he runs&#160;Kotlin instructor-led training for [&#8230;]",
        "contentSnippet": "This is the second guest post in a two-part series from José Luis González. José Luis has a PhD in software development and is a JetBrains-certified Kotlin Trainer, who works with developers and engineering teams to deepen their Kotlin skills and apply the language effectively in real projects. At Hyperskill, he runs Kotlin instructor-led training for […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=670271",
        "categories": [
          "news"
        ],
        "isoDate": "2025-12-19T14:44:34.000Z"
      },
      {
        "creator": "Kerry Beetge",
        "title": "Top 3 Qodana 2025.3 Release Highlights ",
        "link": "https://blog.jetbrains.com/qodana/2025/12/top-3-qodana-2025-3-release-highlights/",
        "pubDate": "Fri, 19 Dec 2025 14:34:25 +0000",
        "content:encodedSnippet": "Qodana 2025.3 delivers important new capabilities that help teams standardize their development practices, improve compliance, make audits easier, and simplify large-scale code analysis. \nFrom introducing Global Project Configuration, a major step toward scalable, centralized policy management, to expanding license auditing for .NET and enhancing monorepository support for Java and Kotlin, Qodana 2025.3 makes it easier to maintain code quality and security across teams, languages, and repositories. Let’s take a closer look at what’s new.\nGlobal Project Configuration\nWe released support for Global Project Configuration, which brings Qodana users the ability to control all linter’s configurations in a single place for an entire organization or a team. You can also use it to enforce best practices, company-wide, without compromising  the needs of a specific project.  \nPreviously, adjusting or appending a rule (like permitting a new license or providing a specific pattern for hardcoded passwords) required manually updating profiles in all repositories. \nNow, with Global Project Configuration we’ve introduced a way to simultaneously apply specific configurations to the analyses for the projects you choose, and we’ve made applying these settings very easy.\nHow does it work?\nGlobal Project Configuration uses a dedicated repository where the organization can store all configurations needed for analysis. These configurations can be organized logically and can reference each other for reuse.\nFor instance, in the example below, the organization defined a “Base” profile that contains universal organization coding standards. After that “Team A” decided to enforce these standards using Lombok in their Java code, while other teams kept it optional. \nSo “Team A” created their own configuration by inheriting “Base” and assigned it to their projects. Meanwhile “Team B” decided that issues of their legacy project will not be handled, so they inherited “Base” and disabled all rules except security.\nQodana Global Project Configuration\n\n\n\nOnce a project is linked to a global configuration, Qodana automatically applies it on the next run. Configurations and the projects they are applied to can be easily viewed and managed through our UI. \nFor detailed instructions on setting up a repository, syncing it with Qodana Cloud, and linking projects, see Qodana Cloud → Settings → Global Configurations or view our documentation. \nLicense Audit for .NET\nThe license detection engine for NuGet packages has been improved in this release, and now supports packages which follow the Semantic Versioning 2.0.0 specification. This means that Qodana will be able to detect licenses on a broader range of dependencies, and provide more accurate license auditing for .NET projects.\nQodana License Audit for .NET\n\n\n\nView License Audit Docs\nImproved monorepositories support for Java/Kotlin projects\nBy default, Qodana works with a project file defined at the root level of the repository. We’ve improved this behavior to support monorepositories consisting of loosely coupled projects not aggregated in a single project file.\nIf Qodana doesn’t detect a project file at root level it will recursively collect projects from subdirectories and import them for analysis.\nIt is possible to override automatic detection in qodana.yaml using the new rootJavaProjects property, which allows you to specify which projects should be included in the analysis. For example:\nrootJavaProjects:\n - \"./gradleProject\"\n - \"./mavenModule/pom.xml\"\nMonorepository Support\nWhat to do next\nThose are the key updates for this release. If you’re using the latest release tag, you don’t need to do anything to enjoy the benefits of our new Qodana 2025.3 release. \nOtherwise, please switch from 2025.2 to 2025.3 to update. Users of GitHub Actions, Azure DevOps, and Circle CI can find the latest version of the extension here.\nFor more information, including detailed setup instructions for each feature, please refer to our official documentation. Click on the button below to speak to our team, and join our community on X for updates between releases. \nSwitch To Qodana",
        "dc:creator": "Kerry Beetge",
        "content": "Qodana 2025.3 delivers important new capabilities that help teams standardize their development practices, improve compliance, make audits easier, and simplify large-scale code analysis.&#160; From introducing Global Project Configuration, a major step toward scalable, centralized policy management, to expanding license auditing for .NET and enhancing monorepository support for Java and Kotlin, Qodana 2025.3 makes it easier [&#8230;]",
        "contentSnippet": "Qodana 2025.3 delivers important new capabilities that help teams standardize their development practices, improve compliance, make audits easier, and simplify large-scale code analysis.  From introducing Global Project Configuration, a major step toward scalable, centralized policy management, to expanding license auditing for .NET and enhancing monorepository support for Java and Kotlin, Qodana 2025.3 makes it easier […]",
        "guid": "https://blog.jetbrains.com/?post_type=qodana&p=667444",
        "categories": [
          "releases",
          "code-quality",
          "maven",
          "qodana"
        ],
        "isoDate": "2025-12-19T14:34:25.000Z"
      },
      {
        "creator": "Dmitrii Korovin",
        "title": "First-Class Docker Support: Building and Deploying Containers With TeamCity",
        "link": "https://blog.jetbrains.com/teamcity/2025/12/first-class-docker-support/",
        "pubDate": "Fri, 19 Dec 2025 12:53:54 +0000",
        "content:encodedSnippet": "This article was brought to you by Kumar Harsh, draft.dev.\nDocker has changed the way we build and ship software. Instead of wrestling with “it works on my machine” issues, developers can now package applications and all their dependencies into a neat, portable container that runs anywhere. No wonder Docker has become the de facto standard for modern DevOps workflows.\nHowever, building and deploying containers at scale isn’t as simple as running docker build. You need a reliable CI/CD system that can consistently build, test, and push images to your registries while keeping the process fast, repeatable, and secure.\nIn this article, we’ll explore how to set up a complete Docker-based build and deployment pipeline with TeamCity’s first-class Docker support. You’ll see how features like built-in runners, native registry integration, and Kotlin DSL support make container pipelines smoother and more maintainable compared to the plugin-heavy, script-driven approach in Jenkins.\nBy the end, you’ll know exactly how to create and run a Docker pipeline in TeamCity, from building images to pushing them to your registry and even deploying them to staging.\nThe Docker pipeline setup experience in Jenkins vs. TeamCity\nIf you’ve ever tried to set up a Docker pipeline in Jenkins, you know the drill: Find and install the right plugins, configure them to match your environment, and then hold your breath hoping they don’t break when Jenkins upgrades. \nEven the official Docker plugin, while powerful, requires manual setup, custom scripting, and constant upkeep to stay compatible.\nFor many teams, this quickly turns into a maintenance burden, especially as pipelines grow more complex.\nTeamCity takes a very different approach. Docker support isn’t added on via third-party plugins; it’s baked into the product. Right out of the box, you get dedicated Docker build runners, registry integration, and full support for defining Docker steps in both the UI and the Kotlin DSL. That means no hunting down plugins, no brittle scripts, and far fewer surprises during upgrades.\nAnother difference lies in configuration. Jenkins pipelines often rely on long Groovy scripts or scattered YAML files, which can be challenging to maintain over time. TeamCity, on the other hand, offers a clean UI-driven configuration for quick setup, with the option to switch over to the Kotlin DSL for version-controlled, production-grade pipelines. This dual approach makes it easy to start simple and then scale your configuration as your projects demand.\nHow TeamCity handles Docker better\nHere’s what TeamCity’s native Docker support looks like in practice:\nDocker build runners: Instead of writing ad hoc scripts, you can add dedicated Docker build steps directly in your pipeline. Whether you’re building images, running containers, or cleaning up afterward, it’s all handled through first-class runners.\nBuilt-in registry support: Authenticating and pushing images to Docker Hub, GitHub Container Registry, or a private registry is straightforward. TeamCity provides registry connections out of the box, so you don’t have to wire up custom credentials every time.\nKotlin DSL integration: If you prefer pipelines as code, you can declare Docker build and push steps in the Kotlin DSL with just a few lines. This makes it easy to track changes in version control and keep your pipelines reproducible.\nBundled Docker plugin: Perhaps the best part about all this is that there’s no separate plugin to install. The Docker integration is bundled with TeamCity, maintained alongside the product itself. That means fewer moving parts and no surprises during upgrades.\nCreating a Docker build and push pipeline in TeamCity\nLet’s now see TeamCity’s Docker support in action by setting up a simple build-and-push pipeline. The goal here is to take a standard Dockerfile, build an image from it, and push that image to a container registry like Docker Hub or GitHub Container Registry.\nStep 1: Set up your Dockerfile\nStart with a project that has a valid Dockerfile at its root. (You can use this one if you don’t have your own. Make sure to fork it to your GitHub account.)\nHere’s what the Dockerfile in this project looks like:\n# Use official Node.js LTS image\n\nFROM node:24-alpine\n\n# Set working directory\n\nWORKDIR /usr/src/app\n\n# Copy package files and install dependencies\n\nCOPY package*.json ./\n\nRUN npm install --production\n\n# Copy app source\n\nCOPY index.js ./\n\n# Expose the port the app runs on\n\nEXPOSE 3000\n\n# Start the app\n\nCMD [\"node\", \"index.js\"]\nIt’s a pretty barebones Dockerfile for setting up the environment for a Node.js app, copying source code files, and running the app.\nStep 2: Add a Docker build step\nIn TeamCity, set up a new project for your pipeline.\nNote: If you’re creating a new TeamCity project with a Dockerfile, TeamCity will most likely autodetect the right build steps for you to get started quickly. You can select the right steps for your workflow and click Use selected to set up the pipeline right away!\n\n\n\n\nTo learn how to add a Docker build step by yourself, read along.\nIn your TeamCity project, create a new build configuration if you don’t have one prepared already. In the build configuration settings page, go to Build Steps and add a new build step to build the Docker image.\nChoose Docker as the runner for the build step:\n\n\n\n\nOn the next page, you can configure what happens in this new build step. TeamCity’s Docker build runner makes this process straightforward. You don’t have to write ad hoc shell scripts for every operation – just pick the command you want (build, push, or other) and fill in the additional parameters as you need.\nFor example, in the build step, you need to configure the path to your Dockerfile, the platform your built images should target, and the name and tag for it. You can also supply additional arguments to add to the docker build command as follows, should you need to:\n\n\n\n\nThanks to TeamCity’s registry connections, you don’t need to embed credentials in scripts. TeamCity logs in before the build and automatically logs out afterward.\n💡 Pro tip: You can set environment variables in TeamCity (like commit SHA or build number) and use them in your image tags for traceability.\nHere’s the equivalent Kotlin DSL snippet:\nsteps {\n\n    dockerCommand {\n\n        name = \"Build\"\n\n        id = \"Build\"\n\n        commandType = build {\n\n            source = file {\n\n                path = \"Dockerfile\"\n\n            }\n\n            platform = DockerCommandStep.ImagePlatform.Linux\n\n            namesAndTags = \"krharsh17/hello-node:latest\"\n\n            commandArgs = \"--pull\"\n\n        }\n\n    }\n\n}\nStep 3: Add a Docker push step\nNext, add a Docker push build step. Select Docker once again as the build runner, and select push as the Docker command this time. Provide an image name and tag to use when pushing the image to your Docker registry:\n\n\n\n\nHere’s what the build step looks like as a Kotlin DSL snippet:\nsteps {\n    dockerCommand {\n        name = \"Push\"\n        id = \"Push\"\n        commandType = push {\n            namesAndTags = \"krharsh17/hello-node:latest\"\n        }\n    }\n}\nSave the build step.\nStep 4: Configure Docker registry connection\nAll that’s left now is to provide the TeamCity project with instructions on how to access your container registry account. You’ll need to do two things:\nCreate a new connection in your project.\nConfigure your build-and-push build configuration to use the Docker Registry Connections build feature to access the connection you just created.\n\n\n\n\nTo create the new connection, head over to Admin | Your Project | Connections | New Connection.\nChoose Docker Registry as the connection type, and provide your registry address and a username and password pair if needed:\n\n\n\n\nTest the connection and save it.\nTo use this connection through the Docker Registry Connections build feature, head over to your build configuration’s settings page and click the Build Features tab. Click the + Add Build Feature button here. In the dialog that opens, select Docker Registry Connections as the build feature to add.\nNext, you need to choose which connection to link here. Click on the + Add registry connection button, and select the new connection you just created:\n\n\n\n\nClick Save to add the feature.\nIf you prefer Kotlin DSL, here’s what the new build feature would look like:\nfeatures {\n    dockerRegistryConnections {\n        loginToRegistry = on {\n            dockerRegistryId = \"PROJECT_EXT_3\"\n        }\n    }\n}\nPROJECT_EXT_3 is the connection ID. You can get this value from the Connections page on your TeamCity project.\nStep 5: Testing the pipeline\nYou’re all set! It’s time to test the pipeline now.\nTry triggering a build. You should see a new image tag get pushed to your Docker registry as soon as the build completes:\n\n\n\n\nThis means that your Docker-native pipeline is ready.\nYou can also go further by adding steps to run containerized tests or deploy to a staging environment. For instance, spin up the freshly built container with docker run as part of your CI/CD workflow, then run integration tests against it.\nIntegrated security and caching features\nWhen building and pushing containers, you need to ensure functionality, security, and efficiency. TeamCity’s native Docker support includes features that help you protect sensitive data and speed up pipelines without extra work:\nSecure registry authentication: TeamCity’s Docker Registry Connections build feature automatically logs in to container registries (like Docker Hub or private registries) before each build and logs out afterward. You don’t need to embed credentials in scripts. TeamCity manages them securely for you.\nImage cleanup: When enabled, the Docker Registry Connections feature can automatically clean up pushed images after builds are cleaned up on the server. This keeps registry storage tidy and maintains good hygiene for build artifacts.\nLayer caching for speed: Rebuilding from scratch every time slows down development. With TeamCity’s Build Cache feature, key files and dependencies (like node_modules/ or .m2/) can be cached and reused across builds, significantly accelerating repeat runs.\nOptimized for iterative workflows: With secure, credential-managed builds and reusable cache artifacts, teams can iterate quickly on Docker pipelines. Small updates don’t mean starting over from scratch, and the process stays secure by default.\nConclusion\nIf you’ve ever grappled with Docker pipelines in Jenkins, you know how fragile things can feel: chasing down plugin updates, maintaining brittle scripts, and dealing with configs that never quite stay consistent. It works, but it often feels like you’re spending more time nursing your CI/CD than actually delivering software.\nTeamCity treats Docker as a first-class citizen. Native runners, registry integrations, caching, secrets management, and the Kotlin DSL replace Jenkins’s patchwork setup with a workflow you can actually rely on. Instead of simply trying to get builds to pass, you have a system you can trust to scale with you.\nIf you’re already running Docker pipelines in Jenkins, the migration path is straightforward and liberating. You’ll spend less time firefighting pipeline issues and more time shipping the features your users are waiting for.\nIf you’re ready to modernize your container pipelines, it’s worth seeing TeamCity in action. Head over to the TeamCity Docker documentation, or try TeamCity yourself and experience how first-class Docker support can simplify your CI/CD pipeline.",
        "dc:creator": "Dmitrii Korovin",
        "content": "This article was brought to you by Kumar Harsh, draft.dev. Docker has changed the way we build and ship software. Instead of wrestling with &#8220;it works on my machine&#8221; issues, developers can now package applications and all their dependencies into a neat, portable container that runs anywhere. No wonder Docker has become the de facto [&#8230;]",
        "contentSnippet": "This article was brought to you by Kumar Harsh, draft.dev. Docker has changed the way we build and ship software. Instead of wrestling with “it works on my machine” issues, developers can now package applications and all their dependencies into a neat, portable container that runs anywhere. No wonder Docker has become the de facto […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=669189",
        "categories": [
          "best-practices",
          "teamcity-2",
          "testing",
          "devopspains",
          "docker"
        ],
        "isoDate": "2025-12-19T12:53:54.000Z"
      },
      {
        "creator": "Sasha Ivanova",
        "title": "ReSharper and Rider 2025.3.1 Released: Next Edit Suggestions and Other Important Updates",
        "link": "https://blog.jetbrains.com/dotnet/2025/12/18/resharper-and-rider-2025-3-1/",
        "pubDate": "Thu, 18 Dec 2025 17:47:54 +0000",
        "content:encodedSnippet": "Since the 2025.3 release, we’ve published several rapid-response updates (2025.3.0.1–2025.3.0.4) for ReSharper and Rider to address the most urgent issues as quickly as possible. The 2025.3.1 update brings all of those fixes together and includes additional improvements that required more time to implement. \nFor Rider, it also delivers the data-sharing functionality we announced earlier this year, now refined based on the feedback we’ve received, along with Next Edit Suggestions – a significant step forward in how JetBrains AI supports your everyday coding by anticipating follow-up changes and keeping your code consistent as you work.\nLet’s take a look at these updates. \nRider 2025.3.1\nNext edit suggestions (NES) come to JetBrains Rider\nThe 2025.3.1 update to Rider introduces the long awaited new feature from JetBrains AI Assistant – next edit suggestions (NES). Next edit suggestions offer intelligent recommendations for edits across your entire file – not just the next line of code. \nNext edit suggestions work a lot like code completion – they appear as you type. But while completion focuses on your next token or line, NES reacts to the meaning of your edit, analyzing the change you just made and proposing follow-up updates elsewhere in your file. It also has more trigger points than completion, making it appear earlier and more frequently when it detects an opportunity to help.\nIn .NET projects, it might look like this: as you begin shaping a LINQ expression, NES picks up on the intent behind your edits and prepares related updates that may be needed in the rest of the method. It doesn’t replace code completion, but works alongside it, stepping in only when the changes you’ve made start to matter to the logic.\n\n\n\n\nYou will see NES suggestions highlighted in light purple. If they’re near your cursor, they appear instantly. If the suggestions touch other parts of the file, you’ll get a prompt to review and apply them.\nIn this example from an Unreal Engine gameplay code, as you start typing a new if condition inside TakeDamage(), NES immediately picks up on the intent behind the change, namely that you’re adding new death-related logic after the character’s health has been reduced. \n\n\n\n\nHow to enable the feature\nTo start using the feature, update JetBrains AI Assistant to the latest version and check the Enable next edit suggestions box in the settings (Settings | Tools | AI Assistant). You will also have the option to enable IDE-powered Code Insight actions.\n\n\n\n\nThe new feature is available as part of all AI Pro and AI Ultimate plans – with unlimited usage and zero impact on your cloud quota.\nWe’d love to hear what you think! You can share feedback directly inside the IDE – a prompt will appear after you begin using the feature. You’re also welcome to leave your thoughts in the comment section below this blog post.\nYou can find the documentation on this feature here.\nData sharing for better AI in JetBrains IDEs\nWith this update, we’re delivering the data-sharing functionality we previewed earlier. Our goal remains the same: to improve the quality and reliability of the AI features in our IDEs by learning from real-world usage, while ensuring that sharing data is always a choice and never a requirement.\nNothing changes unless you explicitly agree to participate. Organizations continue to control data-sharing at the admin level, and individual users can adjust their preferences at any time. For non-commercial users, detailed data sharing is enabled by default, but no information is collected until after you see the in-IDE notice and you may disable it immediately. All shared data is processed responsibly and protected under strict safeguards. \nYou can find the most detailed information on our data collection and usage here.\nNotable fixes\nNormal operation of the Suggested Plugins dialog has been restored. [IJPL-207992]\nMCP-related tool calls now return correct data for project dependencies, modules, and problems instead of empty or generic results. [RIDER-128984] \nThe Show in Find Results shortcut now works correctly when viewing implementing methods.  [RIDER-116221]\nRiderLink now compiles successfully with Unreal Engine 5.7 on Linux using v26 / clang-201.8.[RIDER-133226]\nFor the complete list of issues resolved, please see our issue tracker. \nDownload Rider 2025.3.1\n                                                    \n\n\n\n\nReSharper 2025.3.1\nThese are the most notable fixes included in this update:\ndotTrace Viewer no longer fails to open snapshots [DTRC-31858]\nThe Submit Feedback dialog now shows all expected categories and options again, instead of limiting reports to performance issues only. [RSRP-502160]\nThe Code Cleanup window now renders correctly in Out-of-Process mode. [RSRP-502174]\nAI Assistant now stays activated after restarting Visual Studio. [RSRP-501759]\nIcons in the Options dialog now correctly follow the selected color scheme instead of appearing flat or uncolored. [RSRP-502170]\nResolved a TypeLoadException when running InspectCode with Microsoft.CodeAnalysis.CodeStyle.Fixes 4.14.0, restoring full analyzer execution. [RSRP-502233]  \nFor the full list of resolved issues included in this build, please refer to our issue tracker.\nDownload ReSharper 2025.3.1\n                                                    \nResolved vulnerabilities\nA couple of security vulnerabilities –  [CVE-2025-64456] and [CVE-2025-64457] – have been resolved.\nThese vulnerabilities have been resolved in all Rider, ReSharper, and the .NET tools updates starting with 2024.3.9, including versions 2025.1.8, 2025.2.5, and the latest 2025.3.1.\nYou can download the latest builds from our website (Rider, ReSharper) or via the Toolbox App. You can also update Rider as a snap.\nThis is our last update of the year, and we want to close with a simple message: thank you. From the .NET team at JetBrains, we wish you a happy, warm, and safe holiday season. We’ll see you in the new year!",
        "dc:creator": "Sasha Ivanova",
        "content": "Since the 2025.3 release, we’ve published several rapid-response updates (2025.3.0.1–2025.3.0.4) for ReSharper and Rider to address the most urgent issues as quickly as possible. The 2025.3.1 update brings all of those fixes together and includes additional improvements that required more time to implement.&#160; For Rider, it also delivers the data-sharing functionality we announced earlier this [&#8230;]",
        "contentSnippet": "Since the 2025.3 release, we’ve published several rapid-response updates (2025.3.0.1–2025.3.0.4) for ReSharper and Rider to address the most urgent issues as quickly as possible. The 2025.3.1 update brings all of those fixes together and includes additional improvements that required more time to implement.  For Rider, it also delivers the data-sharing functionality we announced earlier this […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=669532",
        "categories": [
          "net-tools",
          "jetbrains-ai",
          "resharper",
          "rider",
          "next-edit-suggestion"
        ],
        "isoDate": "2025-12-18T17:47:54.000Z"
      },
      {
        "creator": "Anton Semenkin",
        "title": "Next Edit Suggestions: Now Generally Available",
        "link": "https://blog.jetbrains.com/ai/2025/12/next-edit-suggestions-now-generally-available/",
        "pubDate": "Thu, 18 Dec 2025 16:10:39 +0000",
        "content:encodedSnippet": "The next edit suggestions feature is now enabled in all JetBrains IDEs for JetBrains AI Pro, AI Ultimate, and AI Enterprise subscribers.\nYes, you read that right! JetBrains-native diff suggestions are available right in your editor. Global support for optimized latency. Out-of-the-box IDE actions for reliability. And the best part? It doesn’t consume your AI quota.\nWhat are next edit suggestions?\nLike the suggestions provided by AI code completion, next edit suggestions (NES) appear as you type. The difference is that NES can be proposed beyond the immediate vicinity of your caret, and they can modify existing code instead of exclusively adding new code. This feature is a natural extension of code completion, and together they comprise the in-flow Tab-Tab experience. \n\n\n\n\n\n\n\n\nThe NES feature runs silently in the background, generating suggestions as you modify your code. It then gives you the option to review and decide whether to accept them in a small in-editor diff view (the NES UI). The feature adapts how it presents the suggestions, showing them to you in the least intrusive way to avoid interfering with your work. Large changes appear in a dedicated diff view, while smaller suggestions are shown in a larger popup.\n\n\n\n\nOverall, NES provide a smart code editing experience. Let’s agree to share responsibilities as follows: you can simply type and continue development as you used to, and we suggest small digestible diffs that help you do your job faster. Deal?\nWho can use NES? \nWith the latest AI Assistant update, next edit suggestions are enabled by default for all users with AI Pro, AI Ultimate, or AI Enterprise subscriptions. Unlike AI code completion, the next edit suggestions feature is currently unavailable for AI Free license holders. Stay tuned, though – we are actively working on bringing it to a wider audience!\nYou can always learn more about which AI features are available in different pricing tiers on our official page.\nHow do NES work?\nTrust us, there is a lot we could say about the internals, but we’ll try to keep things simple here.\nLong story short, next edit suggestions are where AI meets 🤝 the intelligence of JetBrains IDEs. Under the hood, the feature calls our cloud-based custom AI model and leverages deterministic IDE actions where possible. \nAI model\nCurrently, at their core, NES rely mostly on suggestions provided by a model fine-tuned specifically for this task. \nMuch like Mellum, the model is a small language model (SLM) that leverages cloud GPU infrastructure to provide the best possible latency all around the world. Unlike Mellum, however, the underlying model is bigger and leverages a different type of context: the history of your recent changes as opposed to the current file and RAG.\nBigger does not always mean slower! Our inference pipelines differ for code completion and next edit suggestions generation. NES employ several inference tricks that keep latency under 200 ms for the majority of requests, even at the busiest times of the day 💪. If you ever thought that completion in JetBrains IDEs was slow, it’s time to reconsider!\nIDE actions (code insights)\nDevelopers love our IDEs because of their reliability, and next edit suggestions put that aspect at your fingertips.\nAs part of their pipeline, when invoked, NES look for available code insights provided by the IDE and show them in the NES UI if they are appropriate. One of the easiest ways to see this interaction at work would be to look at a suggestion that renames an identifier in a file. The next edit suggestion will activate the IDE’s Rename refactoring, and usages will be conveniently updated. This even works with multi-file search!\n\n\n\n\nThe integration between next edit suggestions and IDE code insights is not yet fully complete. Because even frontier models struggle with out-of-distribution tools, or even just having a large number of tools in general, we are intentionally adding new IDE actions to NES slowly. We are prioritizing the ones that are useful the most often, as well as the ones the models can use most effectively. Let us know in the comments which IDE actions you would find useful in NES!\nSummary\nNext edit suggestions don’t replace the existing forms of code completion, but complement them, ensuring the best speed and relevance. Where code completion provides suggestions for new material, the next edit suggetions model works in the field of, well, edits. It is optimised to propose changes to existing code, but sometimes the best edit is simply to add something new. In those cases, the suggestions will look like completions because they are presented the same way – as inline gray text. \nThe simple scheme below explains which suggestion provider can be handled by which UI.\n\n\n\n\nSettings panel update\nIn addition to enabling this new feature, we are redesigning the settings for AI code completion and next edit suggestions. Shortly after the start of the new year, the settings for these features will be simplified. Instead of having to navigate multiple views, you will be able to view everything on a single screen, with all the most important options available.\nHere’s a sneak peek of the new design:\n\n\n\n\nAs you can see, the settings for local completion, cloud-based completion, and next edit suggestions are all combined on a single page where you can decide what you want and what you don’t. \n\n\n\n\nAI code completion and NES cheat sheet\nDeciding which types of suggestions to enable may feel a bit overwhelming, so we’ve put together a short cheat sheet to help clarify which settings to enable in the new settings panel, depending on your preferred workflow.\nCase 1: You don’t want AI in your editor\nSimply turn off inline completion and next edit suggestions on this panel. We’ll make sure you don’t see any results of matrix multiplications.\nCase 2: You don’t want cloud-based suggestions\nJust turn on inline completion with local models. Those models are already bundled into your IDE and work without an internet connection. Good ol’ full line code completion will have your back.\nIf you want your own local solution, you can plug any open-source model into the IDE via LM Studio or Ollama. This option is available on the AI Assistant | Models settings page. Note that, currently, this option only works for code completion. We will closely monitor the level of quality that is possible with local inference for NES, with the aim of eventually including it as well.\nCase 3: You like completion but NES seem off\nIn this case, the best solution is to turn on inline completion with the Cloud and local models option and make sure that next edit suggestions are turned off. You will get the best from the Mellum model, and the IDE will automatically fall back to local models if your internet connection is unstable. \nCase 4: You like full-blown in-editor AI assistance\nTurn on both cloud models for inline completion and next edit suggestions to get code snippet suggestions as you modify your source code.\nWhat’s next for NES?\nHere is a quick look at some of the improvements we’re already working on:\nSmarter and more precise suggestions\nMore IDE actions for NES to use\nLonger tab sequences\nMany other developments are on our radar, and we’ll keep you updated as they come closer to fruition.\nThank-you note\nWhile you update your AI Assistant and GPUs go brrr, we would like to thank everyone who participated in the open Beta test for the next edit suggestions feature this fall.\nOver the last few months, the feature has been available to JetBrains AI subscribers who were willing to try it and share anonymous usage statistics. With your help, we were able to make sure the feature was ready and properly prepare the cloud infrastructure for a full-scale release. Thank you so much! ❤️\nTab–Tab,\nYour AI completion team",
        "dc:creator": "Anton Semenkin",
        "content": "The next edit suggestions feature is now enabled in all JetBrains IDEs for JetBrains AI Pro, AI Ultimate, and AI Enterprise subscribers. Yes, you read that right! JetBrains-native diff suggestions are available right in your editor. Global support for optimized latency. Out-of-the-box IDE actions for reliability. And the best part? It doesn’t consume your AI [&#8230;]",
        "contentSnippet": "The next edit suggestions feature is now enabled in all JetBrains IDEs for JetBrains AI Pro, AI Ultimate, and AI Enterprise subscribers. Yes, you read that right! JetBrains-native diff suggestions are available right in your editor. Global support for optimized latency. Out-of-the-box IDE actions for reliability. And the best part? It doesn’t consume your AI […]",
        "guid": "https://blog.jetbrains.com/?post_type=ai&p=669678",
        "categories": [
          "news",
          "ai-assistant",
          "ai-in-ides"
        ],
        "isoDate": "2025-12-18T16:10:39.000Z"
      },
      {
        "creator": "Ekaterina Zharova",
        "title": "Bring Your Own Key (BYOK) Is Now Live in JetBrains IDEs",
        "link": "https://blog.jetbrains.com/ai/2025/12/bring-your-own-key-byok-is-now-live-in-jetbrains-ides/",
        "pubDate": "Thu, 18 Dec 2025 15:59:56 +0000",
        "content:encodedSnippet": "Bring Your Own Key (BYOK) is now available in the AI chat inside JetBrains IDEs as well as for AI agents, including JetBrains’ Junie and Claude Agent. Whether you’re looking to use cutting-edge frontier models, cost-efficient small models, locally hosted private models, or experimental research previews, BYOK makes it easy to bring them all directly into your JetBrains IDE – with no JetBrains AI subscription required.\n\n\n\n\n\n\nFreedom to choose your provider and models\nThe feature is now officially live, allowing you to connect your own API keys from Anthropic, OpenAI, and other OpenAI API-compatible providers. You will also be able to use both Junie and Claude Agent, as long as your chosen provider offers the models the agents require. \nNo vendor lock-in means you’re now free to choose your preferred AI provider or model. You get full transparency over costs on your selected platform – with no hidden quotas or unexpected interruptions – and enhanced privacy and security. Your API keys are stored and managed locally on your machine and never shared with JetBrains.\nGetting started with BYOK\nGetting started is simple: Install the JetBrains AI Assistant plugin in your IDE and select Bring Your Own API Key on the AI chat start screen. Choose a provider, enter your API key, and the available models will automatically appear in your model picker, ready to use in the chat.\n\n\n\n\nIf you’re already using AI Assistant and have it installed, whether on a paid plan or the free tier, you can configure BYOK at any time via Settings | Tools | AI Assistant | Models.\nGet the best experience by pairing BYOK with JetBrains AI\nPlease note that not all AI features are guaranteed to work with third-party provider models. For cloud code completion and other editor-integrated AI features, we recommend activating JetBrains AI (no paid subscription required). To enable your JetBrains AI subscription, go to Settings | Tools | AI Assistant | Models and click Activate JetBrains AI in the JetBrains AI section.\n\n\n\n\nThis setup enables your own key and JetBrains AI to work together, giving you full feature coverage and the best possible experience. Your key will be prioritized wherever possible, and the built-in model picker allows you to select your desired provider right from the AI chat.\nWhat’s next for BYOK\nThis is just the beginning! We’re continuing to add more providers, including Google Gemini, Azure, and Amazon Bedrock, while also refining BYOK to make it more convenient and user-friendly.\nAs always, we’d love to hear your thoughts, feedback, and any feature requests you’d like us to prioritize!",
        "dc:creator": "Ekaterina Zharova",
        "content": "Bring Your Own Key (BYOK) is now available in the AI chat inside JetBrains IDEs as well as for AI agents, including JetBrains’ Junie and Claude Agent. Whether you’re looking to use cutting-edge frontier models, cost-efficient small models, locally hosted private models, or experimental research previews, BYOK makes it easy to bring them all directly [&#8230;]",
        "contentSnippet": "Bring Your Own Key (BYOK) is now available in the AI chat inside JetBrains IDEs as well as for AI agents, including JetBrains’ Junie and Claude Agent. Whether you’re looking to use cutting-edge frontier models, cost-efficient small models, locally hosted private models, or experimental research previews, BYOK makes it easy to bring them all directly […]",
        "guid": "https://blog.jetbrains.com/?post_type=ai&p=669669",
        "categories": [
          "news",
          "ai-in-ides"
        ],
        "isoDate": "2025-12-18T15:59:56.000Z"
      },
      {
        "creator": "Maria Kosukhina",
        "title": "IntelliJ IDEA 2025.3.1 Is Out!",
        "link": "https://blog.jetbrains.com/idea/2025/12/intellij-idea-2025-3-1/",
        "pubDate": "Thu, 18 Dec 2025 15:47:09 +0000",
        "content:encodedSnippet": "IntelliJ IDEA 2025.3.1 is out with a number of useful fixes.\nYou can update to this version from inside the IDE, using the Toolbox App, or using snaps if you are a Ubuntu user. You can also download it from our website.\nThe latest update brings the following improvements:\nThe IDE once again shows the Resume Build From button in the Run tool window for Maven projects. [IDEA-376908]\nIn the Version Control section of Advanced Settings, there’s now an option to disable the warning dialog on force-pushing. [IDEA-285542]\nQuery result tabs now follow the corresponding active editor tabs as expected. [IJPL-222217]\nSeveral issues that appeared when running or debugging in WSL using Gradle have been resolved. [IDEA-357963], [IDEA-285542], [IDEA-363930], [IDEA-352779]\nThe IDE no longer shifts mouse text selection in the terminal one character to the left of the cursor position. [IJPL-190533]\nThe IDE once again correctly loads the list of suggested plugins invoked by the Configure Plugins action. [IJPL-207992]\nThe IDE no longer displays a stray = character in the terminal when working with Fish shell versions 4.0.0–4.0.9 in Docker or when opening a terminal tab via a new SSH session. [IJPL-166234]\nFor a comprehensive overview of the fixes, see the release notes. If you spot any issues, let us know via the issue tracker.\nHappy developing!",
        "dc:creator": "Maria Kosukhina",
        "content": "IntelliJ IDEA 2025.3.1 is out with a number of useful fixes. You can update to this version from inside the IDE, using the Toolbox App, or using snaps if you are a Ubuntu user. You can also download it from our website. The latest update brings the following improvements: For a comprehensive overview of the [&#8230;]",
        "contentSnippet": "IntelliJ IDEA 2025.3.1 is out with a number of useful fixes. You can update to this version from inside the IDE, using the Toolbox App, or using snaps if you are a Ubuntu user. You can also download it from our website. The latest update brings the following improvements: For a comprehensive overview of the […]",
        "guid": "https://blog.jetbrains.com/?post_type=idea&p=669868",
        "categories": [
          "releases",
          "bug-fix-update",
          "intellij-idea-2025-3"
        ],
        "isoDate": "2025-12-18T15:47:09.000Z"
      },
      {
        "creator": "Dmitry Romanov",
        "title": "Query Consoles Are Coming Back ",
        "link": "https://blog.jetbrains.com/datagrip/2025/12/18/query-consoles-are-coming-back/",
        "pubDate": "Thu, 18 Dec 2025 15:35:20 +0000",
        "content:encodedSnippet": "Hi DataGrip and Database Tools community,\nShortly after the 2025.3 release, your feedback made it clear that the redesigned workflow for query files and query consoles introduced issues in several important scenarios, especially when working with global data sources.\nAfter reviewing the impact, we’ve decided that the best course of action is to revert this change in both DataGrip and the Database Tools plugin for JetBrains IDEs, rather than attempt incremental fixes while more users continue to update and encounter problems. \nThe rollback will be included in the upcoming 2025.3.1 release arriving later this week.\nThis affects only those who updated to 2025.3. If you haven’t updated yet, your workflow remains unchanged. If you have, we recommend updating to 2025.3.1 as soon as it becomes available to minimize the gap between the previous and restored behavior.\nWhat’s changing:\nQuery consoles return as the default workflow, working exactly as they did before 2025.3.\nQuery consoles saved before the migration will appear in the same locations as before.\nQuery files created during or after the migration will remain available. You can handle them in several ways:\n\nDelete query files you don’t need. In DataGrip, their default location is the /queries folder in the Files tool window. In other IDEs, their default location is the /.idea/queries mvb directory in the Project tool window.\nConvert query files you want to keep into query consoles. To do so, move them to the appropriate data source node under Scratches and Consoles | Database Consoles (in the Files tool window in DataGrip or in the Project tool window in other IDEs).\nKeep your query files for now. We plan to bring back an improved query file workflow early next year so it can work alongside query consoles in a more intuitive and flexible way.\nA note from the team\nWe apologize for the inconvenience and disruption caused by this change. We hold ourselves to a zero-regression standard, and this release did not meet it. That responsibility is on us, and our focus now is on minimizing the impact and restoring your workflow as quickly as possible. Your trust means a lot, and we’ll continue doing our best to earn it.\nAlthough we are reverting this change for now, our long-term goal remains unchanged: to improve this core workflow and make it more intuitive for both new and experienced users. We will move forward more carefully, and future updates will be more flexible and less disruptive, even if that requires more time and effort on our side.\nIf you have any comments or encounter any issues, please contact us through our issue tracker or support channels.\nBest regards,\nThe DataGrip team",
        "dc:creator": "Dmitry Romanov",
        "content": "Hi DataGrip and Database Tools community, Shortly after the 2025.3 release, your feedback made it clear that the redesigned workflow for query files and query consoles introduced issues in several important scenarios, especially when working with global data sources. After reviewing the impact, we’ve decided that the best course of action is to revert this [&#8230;]",
        "contentSnippet": "Hi DataGrip and Database Tools community, Shortly after the 2025.3 release, your feedback made it clear that the redesigned workflow for query files and query consoles introduced issues in several important scenarios, especially when working with global data sources. After reviewing the impact, we’ve decided that the best course of action is to revert this […]",
        "guid": "https://blog.jetbrains.com/?post_type=datagrip&p=669418",
        "isoDate": "2025-12-18T15:35:20.000Z"
      },
      {
        "creator": "Alyona Chernyaeva",
        "title": "The Ultimate Guide to Successfully Adopting Kotlin in a Java-Dominated Environment",
        "link": "https://blog.jetbrains.com/kotlin/2025/12/the-ultimate-guide-to-successfully-adopting-kotlin-in-a-java-dominated-environment/",
        "pubDate": "Thu, 18 Dec 2025 15:04:44 +0000",
        "content:encodedSnippet": "Adopting Kotlin in a Java-centric company  is not about flipping a switch or rewriting everything “the right way”. It’s about people, timing, risk, and trust.\nOver the last four weeks, we’ve published a series of blog posts by Urs Peter, covering all of these aspects of migrating to Kotlin. In this post, we’ll tie the series together and give you one file you can hand to any engineer, tech lead, or manager to help them make the change.\nDownload the Kotlin Adoption Guide (PDF)\n                                                    \nUse this post as a map, and when you spot a topic that resonates, check out the PDF for detailed instructions, side‑by‑side code examples, and concrete migration patterns.\nThe journey in five parts\nKotlin adoption starts with a spark: one or two engineers who feel that Kotlin could make their code a bit clearer, safer, or easier to work with in the long run.\nThe guide walks you through a five-stage process to make this happen.\n Part 1: Getting Started With Kotlin for Java Developers\nWe’re starting small. And for good reason: You want to introduce Kotlin in a way that can’t possibly hurt production – by using your test suite.\nThis part shows you how to:\nWire Kotlin into an existing Java project.\nUse tools like Kotest and MockK.\nUse Kotlin’s null safety and collections in code you run every day.\nThe goal here is not to become an expert, but to answer a simple question: “Does working with this language feel better?”\nLearn More\n                                                    \nPart 2: Evaluating Kotlin in Real Projects \nOnce tests feel comfortable, you’ll inevitably start asking yourself, “Can we trust this in production?”\nPart 2 explores two paths:\nStarting a new service in Kotlin (often with Spring Boot).\nAdding Kotlin modules to an existing Java system.\nYou’ll see how to avoid the “Java in Kotlin syntax” trap, teaching you how to use extension functions instead of static helpers, nullable types instead of Optional, and data classes and immutability instead of boilerplate models and builders.\nLearn More\n                                                    \nPart 3: Growing Kotlin Adoption in Your Company \nPart 3 looks at the human side: how to get your colleagues on board with Kotlin by piquing their interest rather than pushing it on them.\nThis part will give you practical ways to:\nProvide small, focused examples of Java and Kotlin that respect people’s existing code.\nShare a starter repository with Kotlin, linting, tests, and CI already set up.\nHold short clinics, pairing sessions, and chats to give your colleagues a chance to ask you questions.\nBuild an in‑house Kotlin community that doesn’t depend on a single proponent.\nThe aim is simple: make it easy for others to say, “Let me try this on my next task.”\nLearn More\n                                                    \nPart 4: Helping Decision‑Makers Say Yes to Kotlin \nPersuading your tech-savvy employees is one thing – but what about your colleagues who ask, “How does Kotlin benefit us as a business?”\nPart 4 helps you explain the benefits of Kotlin in terms of business value:\nLess code to read and maintain.\nFewer defects thanks to null safety and safer defaults.\nNo re-writing required, as Kotlin has full Java interop and existing frameworks still work.\nDeveloper happiness and hiring – people want to work with thoughtful, cutting-edge tools.\nPredictable costs for training, gradual migration, and knowledge‑sharing.\n\n\n\n\n\nThis part is written to help you have honest conversations with managers and architects who are accountable for risk, not just syntax.\nLearn More\n                                                    \nPart 5: Scaling Kotlin Adoption Across Your Organization\nOkay – let’s say you’ve managed to bring managers on board and teams are enjoying coding in Kotlin. Now to address the final question: “We have a lot of Java. How do we migrate without breaking things or burning people out?”\nPart 5 focuses on strategy at scale. It suggests:\nTreating systems differently based on lifecycle:\n\nLeave end‑of‑life apps as they are.\nDefault new builds to Kotlin.\nMigrate active systems step by step, not as big‑bang rewrites.\nUsing the right tools for the job:\n\nIDE conversion.\nNull‑safety annotations like JSpecify’s.\nAI‑assisted refactoring where tests are strong.\nRule‑based automation for large codebases.\nCapturing everything in a Kotlin “house playbook” so teams don’t have to re-learn it all from scratch.\nLearn More\n                                                    \nWho this guide is for\nThe guide is written for people who currently work in Java codebases and care about moving them forward responsibly:\nJava developers who want safer, more expressive tools without throwing away their experience.\nBackend and platform engineers running Spring Boot or similar stacks who need a clear, low‑risk path.\nTech leads and architects who are responsible for consistency across many services and teams.\nEngineering managers and decision‑makers who need a transparent view of costs, benefits, and risks.\nDownload the complete series as a PDF\nThe PDF version brings everything together:\nAll five parts of the journey.\nSide‑by‑side Java and Kotlin examples.\nMigration patterns, pitfalls to avoid, and success factors at scale.\nDownload the Kotlin Adoption Guide (PDF)\n                                                    \nTake a look and let us know what you think in the comments. We can’t wait to hear about how you use it.",
        "dc:creator": "Alyona Chernyaeva",
        "content": "Adopting Kotlin in a Java-centric company&#160; is not about flipping a switch or rewriting everything “the right way”. It’s about people, timing, risk, and trust. Over the last four weeks, we’ve published a series of blog posts by Urs Peter, covering all of these aspects of migrating to Kotlin. In this post, we’ll tie the [&#8230;]",
        "contentSnippet": "Adopting Kotlin in a Java-centric company  is not about flipping a switch or rewriting everything “the right way”. It’s about people, timing, risk, and trust. Over the last four weeks, we’ve published a series of blog posts by Urs Peter, covering all of these aspects of migrating to Kotlin. In this post, we’ll tie the […]",
        "guid": "https://blog.jetbrains.com/?post_type=kotlin&p=669909",
        "isoDate": "2025-12-18T15:04:44.000Z"
      },
      {
        "creator": "Regina Muradova",
        "title": "Best Programming Courses in 2025: New and Favorite Picks on JetBrains Academy",
        "link": "https://blog.jetbrains.com/education/2025/12/18/best-programming-courses-in-2025-new-and-favorite-picks-on-jetbrains-academy/",
        "pubDate": "Thu, 18 Dec 2025 11:54:30 +0000",
        "content:encodedSnippet": "“It’s tiiiiiiiiiiiime!”, and not just for Mariah Carey on the playlist. Here’s our annual roundup of JetBrains Academy courses – the favorites you loved this year and the new courses launched in 2025.\nIf you’re trying to figure out where to start, what to learn next, or how to invest in your future skills, this overview will help you navigate the best options and find a path that fits your goals.\nTop in-IDE courses\nOur in-IDE courses are built directly inside the tools developers use every day, so you learn by doing – writing real code, solving real tasks, and building skills that are sought after by employers. All in-IDE courses are free of charge, and as a student, you can apply for the JetBrains Student Pack and get a free licence for JetBrains IDEs. \nLet’s take a look at the courses learners loved most this year.\n❤️ 100 Days of Code – The Complete Python Pro Bootcamp\nBest for: motivated learners who want to build projects every day.\nAngela Yu’s bestselling course comes to life inside PyCharm. You’ll build 100 real projects in 100 days, from data dashboards and simple games to full web apps, APIs, and automation tools. You’ll be learning Python, the most popular programming language, and a great place to  start your developer career. Join over a million learners who’ve completed the course and created a beautiful portfolio of 100 Python projects ready to show to future employers.\n❤️ Introduction to Python\nBest for: absolute beginners who want to get started.\nWith Python being the most popular language among developers in 2025, it’s no surprise that another Python course has been a hit among learners. This fan-favorite helps complete beginners write real code from day one. You’ll learn essentials like variables, loops, functions, and data structures while using the same professional developer tools you’d use on the job. After finishing, you’ll be ready to continue learning, and our structured Python learning roadmap can help you choose what to explore next.\n\n\n\n\n❤️ AtomicKotlin\nBest for: beginners to intermediate Kotlin learners.\nDesigned for both beginners and experienced programmers, this course contains exercises that accompany the Atomic Kotlin book. Start from scratch and progress atom by atom – write real code, test your understanding, and learn with instant IDE feedback and guided hints. \n❤️ 100 Exercises to Learn Rust\nBest for: learners who want a hands-on path into Rust.\nRust is rapidly growing in popularity. The 2025 JetBrains Developer Ecosystem Survey results show that it’s among the top languages developers plan to adopt next, with 10% of respondents saying they want to learn it. It’s no surprise then that this course, which is based on Luca Palmieri’s 100 Exercises to Learn Rust, was so popular this year. Each lesson begins with a failing test, and your task is to write the code that makes it pass. By the end, you’ll have completed 100 carefully selected challenges and gained confidence writing clean, idiomatic Rust in a real development environment.\n\n\n\n\n❤️ Introduction to JavaScript Programming\nBest for: beginners interested in web development.\nJavaScript isn’t just popular – it’s at the center of what most developers actually build. Three out of four developers work on websites or business software, where JavaScript is the industry standard. \nThis course is a perfect starting point for learning JavaScript from scratch. You’ll pick up all of the core concepts needed to understand how modern websites work and start writing interactive code inside a real IDE. By the end, you’ll have the foundation to move confidently into frontend or full-stack development.  If you want to keep going, our Full-Stack JavaScript course is the ideal next step.\nNew courses in 2025\nThis year, we focused on giving learners even more ways to explore programming. Alongside new IDE-based courses, we launched partnerships, expanded to new platforms, and introduced completely new skill paths. Here’s a look at what arrived in 2025 and what’s coming next.\n⭐ Skill Paths from JetBrains Academy and AWS\nIn October, we released our first joint Skill Paths with AWS – free to complete using the AWS Free Tier. These skill paths give you practical, real-world experience. You’ll write Python microservices, containerize them with Docker, deploy on AWS ECS or EC2, and even build and launch a full chat app using React and Flask.\nLearners have already earned more than 40 certificates co-branded by JetBrains Academy and AWS. Get yours by completing the course – a strong addition to your LinkedIn profile or portfolio.\n\n\n\n    \nEarly next year, we’ll also introduce new AI and LLM Skill Paths that dive into machine learning, reinforcement learning, and building applications with LLMs. You’ll learn how to train models with SageMaker, create Bedrock-powered assistants, and work with LangChain in real projects. At the end, you’ll have a working app or LLM endpoint, along with a verified certificate from JetBrains Academy and AWS. Save your spot on the waiting list!\n⭐ AI-Assisted Programming With JetBrains Academy and Nebius\nOver 65% of developers anticipate that AI proficiency will become a job requirement. AI tools are reshaping how we write and test code, but using them effectively isn’t always obvious. That’s why we teamed up with Nebius, an AI cloud platform, to create a new course series that helps developers move beyond the hype and learn how to work with AI in practical, meaningful ways. \nYou’ll write and debug Python code with AI support, use AI for QA and bug detection, automate routine steps with AI agents, explore common AI development tools, and build and test projects with Junie, the AI coding agent by JetBrains, directly inside the IDE.\nIf you’re wondering whether learning to code still matters in an AI-driven world, we’ve covered this in our recent blog series, from why it’s still worth learning to code and exploring the psychology of beginner programmers to whether you should use AI at all.\n⭐ JetBrains Academy Courses on Coursera\nThis year, JetBrains Academy expanded to Coursera, bringing our IDE-based learning experience to one of the world’s largest education platforms. Two courses already support full IDE integration, so you can complete all coding tasks directly in PyCharm – Python from Scratch: Learn by Coding and AI-Assisted Programming. \nThis gives you a full IDE setup while you study – the same tools developers use, tightly connected to your Coursera coursework. In 2026, we’ll add even more JetBrains Academy courses to Coursera. Stay tuned for more!\n⭐ Java Foundations Professional Certificate\nJava may not be the newest language, but it remains one of the most in-demand. If you’re considering a career as a developer, Java is a solid place to begin.\nThat’s why JetBrains has partnered with LinkedIn to offer the Java Foundations Professional Certificate, exclusively on LinkedIn Learning. By completing this learning path, you’ll enhance your LinkedIn profile, validate your Java skills, and get real-world experience. You’ll work in IntelliJ IDEA, the industry’s leading IDE for Java development, gaining practical knowledge essential for your career. By the end of the series, you’ll have acquired the skills to apply for junior developer positions directly on LinkedIn.\n\n\n\n\nThanks for joining us on this tour of the courses that shaped 2025! If you’d like to explore even more learning courses, you can always browse the full JetBrains Academy catalog, with more than 120 courses designed to help strengthen your CV, build a standout portfolio, and ace IT interviews. \nHappy learning!\nThe JetBrains Academy team",
        "dc:creator": "Regina Muradova",
        "content": "“It’s tiiiiiiiiiiiime!”, and not just for Mariah Carey on the playlist. Here’s our annual roundup of JetBrains Academy courses – the favorites you loved this year and the new courses launched in 2025. If you’re trying to figure out where to start, what to learn next, or how to invest in your future skills, this [&#8230;]",
        "contentSnippet": "“It’s tiiiiiiiiiiiime!”, and not just for Mariah Carey on the playlist. Here’s our annual roundup of JetBrains Academy courses – the favorites you loved this year and the new courses launched in 2025. If you’re trying to figure out where to start, what to learn next, or how to invest in your future skills, this […]",
        "guid": "https://blog.jetbrains.com/?post_type=education&p=669435",
        "categories": [
          "jetbrains-academy",
          "learning-courses",
          "beginner",
          "best-courses",
          "jetbrainsacademy-2",
          "learn-to-code",
          "online-learning",
          "python",
          "rust"
        ],
        "isoDate": "2025-12-18T11:54:30.000Z"
      },
      {
        "creator": "Kris Kang",
        "title": "When AI Amplifies Your Bad (and Good) Habits",
        "link": "https://blog.jetbrains.com/ai/2025/12/when-ai-amplifies-your-bad-and-good-habits/",
        "pubDate": "Wed, 17 Dec 2025 14:36:12 +0000",
        "content:encodedSnippet": "AI is more like a megaphone than a magic wand. It amplifies what is already there. Whatever habits you bring to your workflow, good or bad, AI will turn up the volume. \nEvery untested component, undocumented design, and ill-specified feature, to name a few, becomes louder when AI enters the mix.\nTeams with a clear intent about what they are building upfront, with the right best practices in place to preserve that intent, will find leverage with AI. But for those who rely on improvisation or unspoken rules, confusion multiplies. \nThe data tells the same story. A 2025 study by MIT and the U.S. Census Bureau found that firms with disciplined management practices mitigated short-term decline and boosted long-term returns when adopting AI.\nThis is how AI mirrors habits, not intentions, and reflects the culture that creates it.\nCulture in, culture out\nAI learns from what surrounds it. The more structure and clarity you give AI, the less noise you’ll get back. It’s not simply a garbage-in, garbage-out (GIGO) problem. \nEven a well-written PRD can still lead to faulty code, which is why you need downstream safeguards like reliable unit tests to preserve the intent of the original input.\nThis helps explain why inaccuracy emerged as one of the top two risks for organizations in McKinsey’s 2025 global survey on the state of AI.\nThink of AI like an intern who learns by imitation and is guardrailed by good practices. When your codebase is well-patterned, commit messages are readable, and architectural intent is documented, AI can better navigate and contribute to your codebase intelligently. Without this structure, AI tools are left to guess intent and design, and are likely to leave a mess.\nDiscipline as leverage\nDiscipline is not optional in the age of AI. Setting and conforming to standards, and documenting decisions aren’t bureaucratic chores. They’re the signals AI uses to understand your world. They turn your practices into a map that both humans and machines can follow.\nIf your team already values practices like clean code, test-driven development (TDD), good documentation, and legible code reviews, AI will amplify these good habits by handling repetitive tasks following these good habits. \nThe aforementioned McKinsey study on the state of AI confirmed this: organizations with the highest returns from AI followed a range of best practices. However, without structure and processes, AI magnifies weakness, spreading it across every line of code.\nDiscipline doesn’t have to slow you down. There is a durable saying that can be applied here: go slow to go fast.\nSystems that scale\nAI extends your existing system. Continuous integration, automated checks, and code reviews create the safety nets that make scaling possible. When these systems are strong, AI integrates into them seamlessly. \nBut when those systems are missing, AI doesn’t fix the gap. It introduces errors faster than your feedback loops can correct them.\nLook at AI like a high-performance engine. It makes your car faster. But if you fail to tune your brakes and steering, you’ll just crash sooner. The 2025 State of AI Code Quality report by Qodo validates this, as teams using AI for code review saw quality improvements surge to 81%, compared to 55% for those without review.\nAI scales whatever exists. The question is whether what exists deserves scaling.\nDesign for delegation\nDelegating to AI without design is guesswork. You wouldn’t hand off a feature to a new developer without explaining its scope, dependencies, and success criteria. \nThe same logic applies to AI. When you define tasks precisely, AI amplifies precision. When you delegate vaguely, AI amplifies confusion.\nBreak tasks into clear, verifiable steps. Define what “good enough” looks like. Specify what the model should handle and where human judgment still matters. \nYour ability to define boundaries becomes the control knob for how AI reflects your team’s habits. The more intentional your delegation, the more reliable your automation.\nAs the technology evolves, those boundaries will shift. But clarity multiplies efficiency.\nWhat the mirror reveals\nAI is not a fixer of culture. It’s not a patch for weak processes or an escape hatch from discipline. It’s a mirror that reflects your practices in high definition. It will take whatever you already do and turn the volume up. \nIf your workflows are healthy, AI will reinforce that health. If your culture cuts corners, AI will cut them faster.\nThe promise of AI isn’t that it will make bad teams good. It’s that it will long-lever already good teams with good habits. Every improvement in your engineering culture makes your AI more effective. Every bad habit you ignore becomes louder.\nSo, before asking what AI can do for you, ask what your habits will cause it to spotlight next. AI doesn’t change who you are. It just amplifies what’s already there.",
        "dc:creator": "Kris Kang",
        "content": "AI is more like a megaphone than a magic wand. It amplifies what is already there. Whatever habits you bring to your workflow, good or bad, AI will turn up the volume.&#160; Every untested component, undocumented design, and ill-specified feature, to name a few, becomes louder when AI enters the mix. Teams with a clear [&#8230;]",
        "contentSnippet": "AI is more like a megaphone than a magic wand. It amplifies what is already there. Whatever habits you bring to your workflow, good or bad, AI will turn up the volume.  Every untested component, undocumented design, and ill-specified feature, to name a few, becomes louder when AI enters the mix. Teams with a clear […]",
        "guid": "https://blog.jetbrains.com/?post_type=ai&p=666258",
        "categories": [
          "ai",
          "best-practices",
          "collaboration",
          "industry-trends"
        ],
        "isoDate": "2025-12-17T14:36:12.000Z"
      },
      {
        "creator": "Vaclav Pech",
        "title": "MPS 2025.3 Has Been Released!",
        "link": "https://blog.jetbrains.com/mps/2025/12/mps-2025-3-is-out/",
        "pubDate": "Wed, 17 Dec 2025 11:47:53 +0000",
        "content:encodedSnippet": "MPS 2025.3 introduces a major overhaul of the JavaDoc language, significant changes to generator plans, and a major update to the reflective editor. It also enables keyboard actions in the Logical view and allows TextIcon to offer visually distinct variants for light and dark themes.\nDOWNLOAD MPS 2025.3\nWhat’s new\nCheck out all the available updates.\nJavaDoc language overhaul\nThe JavaDoc language has been completely migrated to use the jetbrains.mps.lang.text language for text representation and editing. This change is expected to have minimal impact on the overall user experience. However, it fixes numerous problems:\nThe editing experience is now consistent with other MPS languages that use jetbrains.mps.lang.text, such as BaseLanguage comments or structure language documentation. For more information on editing text, refer to the documentation facet page.\nText can be copied and pasted between JavaDoc, BaseLanguage comments, language documentation comments, and other places where jetbrains.mps.lang.text is used. You can also copy and paste plain text.\nText can now include styling, such as bold or italics. This styling is generated as HTML tags in the resulting Java source files.\nAlong the way, several problems associated with the JavaDoc language have been resolved:\nThe description for block tags was changed to use jetbrains.mps.lang.text instead of string properties, so the same edit/copy/paste/style functionality is available inside block tags.\nBlock tags now support multiple lines of description.\nBoth block tags and inline tags are now correctly parsed from Java sources.\nA new {@literal …} inline tag was added as mandated by the Java language specification.\nCode inside CodeSnippet correctly resolves local variables.\nNodeWrapper correctly textgens the contained nodes.\n\nPaste as JavaDoc action available in BaseLanguage\nIn addition to the existing Paste as Java Statement and Paste as Class Content actions, the redesigned JavaDoc language supports a new action that enables easy pasting of textual JavaDoc code into BaseLanguage. Most importantly, this new action ensures that your JavaDoc code is properly parsed into JavaDoc text lines, block tags, and inline tags, including potential reference resolutions (e.g. for the @param or {@link } tags).\n\nThis new Paste as JavaDoc action parses the text from the clipboard and pastes it into a JavaDoc comment at the current position of the cursor. If the cursor is not positioned within an existing JavaDoc comment, the action attaches the parsed JavaDoc elements to the following field/method/class definition’s JavaDoc, creating a new JavaDoc file for them, if needed.\n\nContributions to generator plans\nWe’ve made some major improvements to generator plans, enhancing the user’s experience with complex model transformations. A new notion of PlanContribution supersedes and completely replaces the experimental fork as functionality that we introduced back in 2024.1.\ntargetFacet (see jetbrains.mps.generator.extensions.common model), which tells <mps.make> which GenerationTargetFacet/ModuleFacet to consult when determining an appropriate output location for a model.\n\nConditional forks with generator plans\nBoth the fork step and a PlanContribution in a generator plan support conditional activation. It’s now possible to activate certain branches of a plan only when certain criteria are met. At the moment, MPS comes with a conditional statement that checks the values of specified plan parameters. We intend to eventually extend statements to support logical operations (and/or), as well as other potential operations, while maintaining a strict interpretation of generator plans (i.e. no BaseLanguage code in plans).\nParameterDeclaration classes. Values for these parameters can be contributed using a PlanParameterContributor extension point. MPS comes with a few predefined parameters that are usable straight out of the box – see the jetbrains.mps.generator.extensions.common model for full details of these.\n\nLight and dark TextIcon options\nTextIcon’s layers can now be configured to apply to the Light, Dark, or both color themes. Additionally, the color literals in TextIcon’s definition can provide different values for the light and dark color themes.\n\nReflective editor overhaul\nThe reflective (default) editor has a new look and feel. The read-only default editor has been merged with the reflective editor, so there’s no longer confusion between the two.\n\nMore new features…\nCheck out the What’s New page to learn all about the new features.\nhere.\nTry the new features and let us know what you think.",
        "dc:creator": "Vaclav Pech",
        "content": "MPS 2025.3 introduces a major overhaul of the JavaDoc language, significant changes to generator plans, and a major update to the reflective editor. It also enables keyboard actions in the Logical view and allows TextIcon to offer visually distinct variants for light and dark themes. DOWNLOAD MPS 2025.3 What’s new Check out all the available [&#8230;]",
        "contentSnippet": "MPS 2025.3 introduces a major overhaul of the JavaDoc language, significant changes to generator plans, and a major update to the reflective editor. It also enables keyboard actions in the Logical view and allows TextIcon to offer visually distinct variants for light and dark themes. DOWNLOAD MPS 2025.3 What’s new Check out all the available […]",
        "guid": "https://blog.jetbrains.com/?post_type=mps&p=666016",
        "categories": [
          "releases",
          "release"
        ],
        "isoDate": "2025-12-17T11:47:53.000Z"
      }
    ]
  },
  {
    "name": "Airbnb Engineering & Data Science",
    "category": "기업",
    "posts": []
  },
  {
    "name": "PayPal Engineering",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": [
      {
        "creator": "Harshada Hole",
        "title": "Debugging, but Without the Drama (A Visual Studio 2026 Story)",
        "link": "https://devblogs.microsoft.com/visualstudio/visual-studio-2026-debugging-with-copilot/",
        "pubDate": "Tue, 16 Dec 2025 15:00:12 +0000",
        "content:encodedSnippet": "It starts the way these things always start. \nA red build.\nA failing test.\nAnd that quiet, sinking feeling of “This worked yesterday.” \nMeet Sam. Sam’s not a junior, not a rockstar, just a solid developer who’s shipped enough code to know that bugs don’t care how confident you feel on Monday morning. \nThat test failure does not offer much help at all. There are no clear steps to reproduce the issue. The exception message seems familiar in a vague way. But it does not prove useful right then. Out of habit Sam hits F5. He notices something small yet pretty important about it. \nThe debugger launches faster than before. No long pause, no breaking his flow. Sam gets straight into debugging, and that small improvement already feels like a win. \nThe Exception Knows More Than It Used To \nThe app crashes. Sam opens the exception details. Normally, he’d read the error message, scroll through the stack trace, which shows the chain of function calls that led to the crash and start guessing what went wrong. \nThis time, things feel different. Exception Assistance ‘s Copilot analysis looked at the whole repository, not just the file in front of Sam. It checks past bugs, old pull requests, and even fixes from months ago. It notices a similar error that happened after a validation tweak, flags the code paths that might have been hit, and points to places where that odd value could have slipped in. \nIf Sam wants a different angle, he can pick any model in Copilot Chat to analyze the exception the way that fits the problem. And for trickier, nested, or chained errors, Copilot may decide it needs more context and offer to dig deeper.  Sam can continue with the deeper analysis to get a more context-driven, accurate understanding of what went wrong, without losing control of the investigation \nWhat used to take hours now feels like a conversation with a teammate who knows the history of your code and points you exactly where you need to look. \nWant to see this in action?\n\n\nInline Values: When If-Statements Stop Lying and Values Appear Where You Need Them \nSam steps through the code and lands on a conditional that should be true but is now showing false. \nNormally, you’d hover over every variable, checking them one by one but now? The result is right there. Inline in editor. The condition shows how it was evaluated.\nSam hovers and chooses Analyze with Copilot. Instead of just seeing “false,” Copilot breaks the condition apart sub-expression by sub expression showing exactly which part failed and how it affected the outcome. No stepping. No breakpoint. Just reasoning where the decision happened.  \nAs Sam moves on, he notices something else that clicks: \nMethod parameters? Inline. \nLoop variables? Inline. \nReturn values? Inline, where they’re used, not buried inside a function call.\nOne way keeps returning a value that feels wrong. Sam doesn’t step into it. Doesn’t add watches. He just hovers, asks Copilot to analyze the value, and instantly sees an explanation grounded in runtime behavior and the surrounding code. \nIt doesn’t replace DataTips or visualizers; they’re still there when Sam needs to dig deeper. But most of the time, the answer he’s looking for is already right in front of him. \nWant to see this in action?\n\nWhen a Test Fails, and You Don’t Debug Alone \nLater that day, another test failed. Different feature. Same frustration. Sam right-clicks the test and selects Debug with Copilot. \nThe Debugger Agent takes over. It looks at the test, its code, and recent changes. Then it makes a guess, applies a fix, runs the test, adjusts, and tries again. Sam watches. Not hands-off, but without the usual busy work. When it’s done, there’s a clear summary of what has changed and why. Sam reviews it, nods, and commits. \nThis isn’t giving up control.\nIt’s cutting out the repetitive stuff so Sam can focus on the important decisions. \nWant to see this in action?\n\nThe Calm at the End of Debugging \nBy the end of the day, Sam notices something important. \nThe bugs weren’t easy.\nThe code wasn’t simple.\nBut understand them? That came faster. \nVisual Studio 2026 doesn’t make debugging magic. It makes it feel like a conversation between Sam, his code, his history, and tools that get the context. By the end of the day, Sam closes the debugger feeling focused, not worn down.  \nThese improvements in Visual Studio 2026 are the first steps toward a smoother, calmer, more intuitive debugging experience, less time guessing, and more time understanding.  There’s a lot more coming, and your feedback is crucial. Tell us what works, what doesn’t, and where debugging still trips you up. \nHappy Debugging.  \nThe post Debugging, but Without the Drama (A Visual Studio 2026 Story) appeared first on Visual Studio Blog.",
        "dc:creator": "Harshada Hole",
        "comments": "https://devblogs.microsoft.com/visualstudio/visual-studio-2026-debugging-with-copilot/#comments",
        "content": "<p>It starts the way these things always start.  A red build. A failing test. And that quiet, sinking feeling of “This worked yesterday.”  Meet Sam. Sam’s not a junior, not a rockstar, just a solid developer who’s shipped enough code to know that bugs don’t care how confident you feel on Monday morning.  That test failure does not offer much help [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/visual-studio-2026-debugging-with-copilot/\">Debugging, but Without the Drama (A Visual Studio 2026 Story)</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "It starts the way these things always start.  A red build. A failing test. And that quiet, sinking feeling of “This worked yesterday.”  Meet Sam. Sam’s not a junior, not a rockstar, just a solid developer who’s shipped enough code to know that bugs don’t care how confident you feel on Monday morning.  That test failure does not offer much help […]\nThe post Debugging, but Without the Drama (A Visual Studio 2026 Story) appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=255172",
        "categories": [
          "Visual Studio",
          "Debugging and Diagnostics",
          "Developer Productivity",
          "Performance",
          "Visual Studio 2026"
        ],
        "isoDate": "2025-12-16T15:00:12.000Z"
      },
      {
        "creator": "Mads Kristensen",
        "title": "Behind the scenes of the Visual Studio feedback system",
        "link": "https://devblogs.microsoft.com/visualstudio/behind-the-scenes-of-the-visual-studio-feedback-system/",
        "pubDate": "Mon, 15 Dec 2025 15:00:33 +0000",
        "content:encodedSnippet": "Here on the Visual Studio team, our top priority is making your coding experience smoother and more enjoyable. And that begins with truly listening to your feedback. We understand that sometimes sharing your thoughts can feel like tossing bug reports and suggestions into a black hole. It doesn’t feel good, and we get it.\nBut here’s the good news: over the past year, we’ve resolved more bugs reported by users and delivered more requested features than at any other time in Visual Studio’s history. We believe in being open about what happens to your feedback, so in this post, we’ll pull back the curtain and show you exactly how your input is processed and how it directly influences our work.\nSo, grab your favorite warm drink, settle in, and join us for a behind-the-scenes look at how your feedback truly shapes the future of Visual Studio.\nEvery bug report or feature request you submit on developercommunity.visualstudio.com becomes a ticket in our system. We mirror that ticket in our internal Azure DevOps setup and assign it to the right team.\nFigure 1: The public ticket on Developer Community on the left, and the internal ticket in Azure DevOps on the right\nWe treat your feedback with the same priority as our internal tasks, triaging and prioritizing it to align with our goals and direction. In other words, who created the issue doesn’t matter. If the issue is important and impactful, we consider it.\nFigure 2: Internal and external tickets are triaged together in the same view in Azure DevOps\nSo, what makes a feedback ticket important and impactful? Your engagement on the Developer Community directly influences what we work on next. We assign an internal Score to every ticket based on community traction, impact, and severity. Each vote increases the ticket’s Score and highlights issues or ideas the community cares about. It’s important that you upvote existing tickets and add more context rather than submitting a new ticket for the same issue. Comments add context and boost the Score, helping us understand the issue or feature request’s importance. Comment on existing tickets to add more context to the issue or feature request. It all helps.\nFigure 3: A bug ticket with votes and comments\nAs a ticket’s Score rises, it can automatically escalate in priority – low, medium, or high. Medium and high-priority bugs come with Service Level Agreements (SLAs). High-priority tickets are targeted for investigation within a week, while medium-priority tickets have a longer but defined timeline.\nPriority isn’t just about votes and comments, though. Our teams weigh the Score against factors like technical complexity and alignment with goals, such as performance, reliability, and accessibility. A high Score doesn’t guarantee top priority, but it’s a major factor.\nThis system ensures that feedback from our users shapes the IDE, and that we catch bugs as early as possible. Some bugs require immediate attention, especially regressions and issues affecting key tenets like performance or accessibility.\nFigure 4: The option to rollback to a previous version in the Installer\nRegressions – cases where something that used to work breaks – are typically high priority because they disrupt your workflow. If you ever need to rollback to a prior release due to a regression or critical issue, it’s crucial to let us know. After you complete the rollback, Visual Studio asks you to submit feedback describing what led you to revert and the specific problem you encountered.\nYour input is invaluable for helping us identify, prioritize, and resolve regressions quickly so we can prevent similar disruptions in future updates. Bugs affecting core tenets like performance or accessibility also get quick attention. A slowdown in the IDE or an accessibility issue that limits usability? We prioritize those to keep Visual Studio smooth and inclusive.\nTo help us address your feedback as quickly and effectively as possible, here are some tips for writing a ticket that stands out and speeds up resolution.\nUse descriptive title: Use a title that is easy for others to find so they can vote, comment, and add more information.\nInclude clear reproduction steps: Describe exactly what you did leading up to the issue. List each step in order so we can follow your process and reliably see the problem on our end.\nAdd screenshots: Visuals make it easier to understand what’s happening. If possible, attach screenshots that highlight the issue or error message.\nUse the recording function: Consider using the built-in recording feature to capture your workflow and the issue in real time. This gives us a direct view of the problem as it occurs.\nShare a minimal reproducible project: If you can, create a simple project that demonstrates the issue. Zip up the project files and include them with your ticket submission. This helps us isolate the bug and find a solution faster.\nSometimes, we still can’t figure out what’s going on. The team can’t reproduce the issue, or the error logs just don’t give us enough to go on. When that happens, we usually reach out to you and the rest of the community for more details. We’re not trying to be a hassle; we really do want to fix the problem, but we just need a little more info to get there. Anyone can add more info to any ticket, and we encourage you to jump in if you can help.\n \nSpeaking of feedback, love that Visual Studio fixed the build status after I reported the misleading output and many of you upvoted it. The next text is much better. Your feedback matters!\n \nWhat happens if you want to open a bug on the bug reporting system itself? This is one of the feedback team’s most frequently asked questions. The answer is that you report it the exact same way as any other Visual Studio bug. Go to Help > Send Feedback > Report a Problem… and fill in the ticket.\nIn conclusion…\nThe bug is there whether you tell us or not. But when you take the time to let us know about it, you’re really doing all of us – our team and other users – a huge favor. We know reporting bugs isn’t much fun, but we do our best to make it a good experience.\nIt may not always seem like it, but things are getting better. We’re fixing more bugs and adding more features now than ever before in our nearly 30 years of history. And that’s all because of you. Thank you for all your feedback over the years. It’s made a bigger difference than you can possibly imagine.\nKeep sharing your thoughts on developercommunity.visualstudio.com and in the comments below.\nThe post Behind the scenes of the Visual Studio feedback system appeared first on Visual Studio Blog.",
        "dc:creator": "Mads Kristensen",
        "comments": "https://devblogs.microsoft.com/visualstudio/behind-the-scenes-of-the-visual-studio-feedback-system/#comments",
        "content": "<p>Here on the Visual Studio team, our top priority is making your coding experience smoother and more enjoyable. And that begins with truly listening to your feedback. We understand that sometimes sharing your thoughts can feel like tossing bug reports and suggestions into a black hole. It doesn’t feel good, and we get it. But [&#8230;]</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/visualstudio/behind-the-scenes-of-the-visual-studio-feedback-system/\">Behind the scenes of the Visual Studio feedback system</a> appeared first on <a href=\"https://devblogs.microsoft.com/visualstudio\">Visual Studio Blog</a>.</p>\n",
        "contentSnippet": "Here on the Visual Studio team, our top priority is making your coding experience smoother and more enjoyable. And that begins with truly listening to your feedback. We understand that sometimes sharing your thoughts can feel like tossing bug reports and suggestions into a black hole. It doesn’t feel good, and we get it. But […]\nThe post Behind the scenes of the Visual Studio feedback system appeared first on Visual Studio Blog.",
        "guid": "https://devblogs.microsoft.com/visualstudio/?p=255216",
        "categories": [
          "Visual Studio",
          "Feedback"
        ],
        "isoDate": "2025-12-15T15:00:33.000Z"
      }
    ]
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김범진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권혁우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김준형",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강성훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": [
      {
        "creator": "고명환",
        "title": "스타트업 IPO 완전 정리 - 공모가부터 청약, 성장까지 한 번에 이해하기",
        "link": "https://brunch.co.kr/@@LOc/319",
        "pubDate": "Fri, 19 Dec 2025 03:35:58 GMT",
        "author": "고명환",
        "content": "최근 우리나라 스타트업 시장을 보면 IPO(기업공개)를 선택하는 기업들이 눈에 띄게 늘어나고 있습니다. 과거에는 IPO가 일부 대기업이나 중견기업의 전유물처럼 여겨졌다면, 이제는 기술력과 성장성을 갖춘 스타트업이라면 충분히 도전할 수 있는 선택지가 되었습니다. 실제로 IT, 플랫폼, 바이오, 콘텐츠 기업을 중심으로 코스탁 성장이 꾸준히 증가하고 있습니다. <img src= \"https://img1.daumcdn.net/thumb/R1280x0.fjpg/?fname=http%3A%2F%2Ft1.daumcdn.net%2Fbrunch%2Fservice%2Fuser%2FLOc%2Fimage%2FLU9aOVwdL3AX6Jwy1hOgqChJIj8\" width=\"500\" />",
        "contentSnippet": "최근 우리나라 스타트업 시장을 보면 IPO(기업공개)를 선택하는 기업들이 눈에 띄게 늘어나고 있습니다. 과거에는 IPO가 일부 대기업이나 중견기업의 전유물처럼 여겨졌다면, 이제는 기술력과 성장성을 갖춘 스타트업이라면 충분히 도전할 수 있는 선택지가 되었습니다. 실제로 IT, 플랫폼, 바이오, 콘텐츠 기업을 중심으로 코스탁 성장이 꾸준히 증가하고 있습니다.",
        "guid": "https://brunch.co.kr/@@LOc/319",
        "isoDate": "2025-12-19T03:35:58.000Z"
      }
    ]
  },
  {
    "name": "강성희",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "기획부터 썸네일까지 AI 원스톱! 유튜브 플레이리스트 제작 치트키 공개",
        "link": "https://muzbox.tistory.com/483694",
        "pubDate": "Sun, 21 Dec 2025 09:26:57 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "https://muzbox.tistory.com/483694#entry483694comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #3c4043;\">\n<div style=\"background-color: #e8f4fd; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">유튜브 플레이리스트 채널, 영상을 직접 편집해야 한다는 부담감 때문에 시작도 못 해보셨나요? 더 이상 그런 고민은 필요 없습니다. 기획부터 음악, 썸네일, 그리고 전문가급 오디오 스펙트럼 영상 제작까지 AI가 원스톱으로 해결해주는 신세계를 경험해보세요. 클릭 몇 번으로 누구나 쉽게 유튜브 수익화를 달성할 수 있는 궁극의 치트키를 지금 바로 공개합니다.</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">요즘 유튜브에서 잔잔한 음악과 함께 멋진 배경 영상이 흘러나오는 플레이리스트 채널이 큰 인기를 끌고 있죠. 로파이걸(Lofi Girl) 같은 채널은 이런 플레이리스트 영상만으로도 어마어마한 조회수와 함께 상당한 광고 수익을 올리고 있다고 알려져 있습니다. 많은 분들이 '나도 한번 해볼<span style=\"color: #3c4043; text-align: start;\">까?' 생각하시지만, 막상 시작하려니 막막한 부분이 한두 가지가 아니었을 겁니다.</span></p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/kPly7/dJMcabJyRwl/NK51hkLChaKno3ktc2TDA0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/kPly7/dJMcabJyRwl/NK51hkLChaKno3ktc2TDA0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/kPly7/dJMcabJyRwl/NK51hkLChaKno3ktc2TDA0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FkPly7%2FdJMcabJyRwl%2FNK51hkLChaKno3ktc2TDA0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"기획부터 썸네일까지 AI 원스톱! 유튜브 플레이리스트 제작 치트키 공개\" loading=\"lazy\" width=\"500\" height=\"500\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">과연 내가 어떤 컨셉으로 채널을 만들지, 저작권 걱정 없는 음원은 어디서 구해야 할지, 게다가 프리미어나 파이널컷 같은 복잡한 편집 프로그램을 다뤄야 한다는 압박감까지&hellip; 정말이지 시작도 전에 지쳐버리기 일쑤였죠. 썸네일 디자인도 빼놓을 수 없고요. 이 모든 과정을 하나하나 배우려면 솔직히 시간과 노력이 정말 많이 들었습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">그런데 말입니다. 이 모든 고민을 단숨에 날려버릴 놀라운 AI 솔루션이 등장했습니다. 이제 클릭 몇 번만으로 이 모든 과정을 해결하고 여러분만의 플레이리스트 채널을 운영하며 수익을 창출할 수 있게 되었어요. 자, 저와 함께 이 혁신적인 방법을 자세히 알아보시죠!</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  플레이리스트 채널, 왜 그렇게 어려웠을까요?</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">먼저, 기존의 플레이리스트 채널 제작 방식이 왜 그렇게 만만치 않았는지 그 어려움을 짚어보겠습니다. 크게 세 단계로 나눌 수 있는데, 이 과정 하나하나가 결코 쉽지 않았어요.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; font-weight: 600;\" data-ke-size=\"size23\"><b>1. 컨셉 설정과 음원 수급의 딜레마</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">단순히 '좋은 노래 모음'으로는 경쟁력을 갖기 어려웠죠. '비 오는 밤 성수동 카페', '새벽 3시 집중력을 높이는 로파이'처럼 구체적인 상황과 감성을 담은 컨셉을 잡아야 하는데, 여기서부터 많은 분들이 막막함을 느꼈을 거예요. 게다가 저작권 걱정 없이 좋은 음원을 확보하는 건 또 다른 큰 산이었습니다. 유튜브 오디오 보관함이나 NCS 같은 무료 음원도 있지만, 너무 많은 사람들이 사용해서 차별화가 어렵다는 단점이 있었죠.</p>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>AI 음원의 등장:</b> 요즘은 수노(Suno AI)나 유디오(Udio) 같은 AI로 직접 음원을 만드는 추세예요. 하지만 이것도 처음에는 '프롬프트'를 어떻게 작성해야 원하는 결과물을 얻을 수 있을지 정말 어렵게 느껴질 수 있습니다.</div>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; font-weight: 600;\" data-ke-size=\"size23\"><b>2. 시각 자료 제작의 복잡성</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">음악만 계속 틀어놓으면 시청자들이 금세 지루함을 느낄 수 있죠. 그래서 배경 영상이나 이미지가 필수인데, 미드저니(Midjourney)나 캔바(Canva) 같은 도구를 배우는 것도 일이었어요. 거기서 끝이 아니죠! 정적인 이미지에 오디오 스펙트럼 같은 움직임을 더해서 시청자의 시선을 사로잡아야 했습니다. 그런데 이런 효과를 넣으려면 프리미어 프로나 캡컷(CapCut) 같은 전문 영상 편집 프로그램을 배워야 하니, 이 단계에서 좌절하는 분들이 많았을 겁니다.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; font-weight: 600;\" data-ke-size=\"size23\"><b>3. 긴 영상 편집과 렌더링의 고통</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">배경 영상 위에 음원을 배치하고, 화면 하단에 곡 제목을 표시하고, 여러 영상 효과를 반영하는 것 자체가 어려운 작업입니다. 특히 플레이리스트 영상처럼 1시간 이상의 긴 영상을 원활하게 편집하고 렌더링하려면 앞서 언급한 전문 영상 편집 프로그램은 거의 필수적이죠. 배우는 것도 어렵지만, 저사양 컴퓨터로는 렌더링에만 반나절이 걸리는 경우도 허다해서 '대체 언제 다 만들지?' 하는 생각이 절로 들었습니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/bt6AyQ/dJMcadAx0mC/AIOZ8KbMvkeKsVij2KKkwK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bt6AyQ/dJMcadAx0mC/AIOZ8KbMvkeKsVij2KKkwK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bt6AyQ/dJMcadAx0mC/AIOZ8KbMvkeKsVij2KKkwK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbt6AyQ%2FdJMcadAx0mC%2FAIOZ8KbMvkeKsVij2KKkwK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"복잡한 영상 편집 및 음원 작업으로 인해 스트레스받는 유튜버의 모습\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; font-weight: 600;\" data-ke-size=\"size23\"><b>4. 시간 소모와 초기 노출의 한계</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 모든 과정을 숙련자가 해도 영상 하나 만드는 데 최소 3시간에서 5시간은 족히 걸렸습니다. 기획/선곡 1~2시간, 시각 자료 제작 30분~1시간, 편집/렌더링 1~2시간, 유튜브 업로드/SEO 30분&hellip; 매일 이렇게 작업하려면 정말 힘들었겠죠? 게다가 이미 로파이걸 같은 거대 채널들이 시장을 장악하고 있어서 신규 채널이 알고리즘의 선택을 받기까지는 최소 3~6개월 이상의 꾸준한 노력이 필요했습니다. 매번 새로운 무드를 찾아내고 수십 곡의 리스트를 짜는 작업은 창의적인 에너지를 엄청나게 소모하며 소재 고갈에 빠지기 쉬웠고요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">하지만 오늘 제가 소개해드릴 방법은 이 모든 과정을 획기적으로 단축시켜줍니다. 특히 AI 도구를 활용하면 저작권 문제에서 훨씬 자유롭고, 제작 시간도 놀랍도록 줄일 수 있으니, 정말 솔깃하지 않나요? 이제 본격적으로 강력한 두 가지 앱을 소개해드릴게요!</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  AI 플레이리스트 제작, 시작 전 준비물!</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">자, 그럼 이 놀라운 AI 도구들을 사용하기 전에 몇 가지 준비할 것이 있습니다. 생각보다 간단하니 걱정 마세요!</p>\n<ul style=\"list-style-type: disc; margin-left: 20px; margin-bottom: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px;\"><b>구글 아이디 및 API 발급:</b> 구글의 최신 AI 모델인 제미나이를 기반으로 작동하는 'AI 플레이리스트 크리에이터'를 사용하려면 구글 AI 스튜디오 사용을 위한 구글 아이디와 API 발급이 필요해요. API 발급 방법은 제가 다른 영상에서 상세히 다뤘으니, 본문이나 댓글에 있는 링크를 참고하셔서 먼저 발급받아주세요.</li>\n<li style=\"margin-bottom: 10px;\"><b>Suno AI 가입:</b> 음악 생성을 위해 suno.com에 접속하셔서 간단하게 가입해주셔야 합니다.</li>\n</ul>\n<div style=\"background-color: #fce8e6; border-left: 4px solid #d93025; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">⚠️ <b>중요! Suno AI 유료 플랜:</b> Suno AI에서 생성한 음원을 유튜브 수익 창출이나 음원 발매 등 상업적으로 활용하려면 반드시 <b>유료 플랜에 가입</b>해야 합니다. 이 점 꼭 기억해 주세요!</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 두 가지 준비물이 갖춰졌다면, 이제 본격적으로 AI와 함께 플레이리스트 채널을 만드는 여정을 시작해볼까요?</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  AI 플레이리스트 크리에이터: 기획부터 썸네일까지 원스톱!</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 앱은 구글의 최신 AI 모델인 제미나이를 기반으로 작동하는데요. 단순히 아이디어만 툭 던져주는 수준이 아닙니다. 실제 음악 생성에 필요한 전문적인 프롬프트부터 채널 운영에 필수적인 모든 요소를 그야말로 원스톱으로 제공해줘요. 제가 직접 써보니, 정말이지 '이게 되네?' 싶을 정도로 놀라웠습니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"AI 플레이리스트 크리에이터- 메인화면.png\" data-origin-width=\"1775\" data-origin-height=\"904\"><span data-url=\"https://blog.kakaocdn.net/dn/mDZrH/dJMcadHkqKN/o4FeJyPoKn4YeB7PGcVIk0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/mDZrH/dJMcadHkqKN/o4FeJyPoKn4YeB7PGcVIk0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/mDZrH/dJMcadHkqKN/o4FeJyPoKn4YeB7PGcVIk0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FmDZrH%2FdJMcadHkqKN%2Fo4FeJyPoKn4YeB7PGcVIk0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"AI 플레이리스트 크리에이터 메인화면\" loading=\"lazy\" width=\"1775\" height=\"904\" data-filename=\"AI 플레이리스트 크리에이터- 메인화면.png\" data-origin-width=\"1775\" data-origin-height=\"904\"/></span></figure>\n\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; font-weight: 600;\" data-ke-size=\"size23\"><b>✨ AI 플레이리스트 크리에이터의 핵심 기능 4가지</b></h3>\n<ul style=\"list-style-type: disc; margin-left: 20px; margin-bottom: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px;\"><b>클릭을 부르는 감성적인 제목 생성:</b> '재즈 음악'처럼 평범한 제목이 아닌, 이모지와 감성적인 문구, 그리고 검색 키워드까지 고려한 매력적인 제목을 뽑아줍니다. 예를 들어, ' ️ 비 오는 밤, 따뜻한 커피와 함께 듣는 감성 재즈'처럼요.</li>\n<li style=\"margin-bottom: 10px;\"><b>Suno 5.0에 최적화된 프롬프트 생성:</b> 단순히 '재즈 만들어줘'가 아닙니다. 악기 구성, 공간감, 연주 스타일까지 아주 디테일하게 작성된 전문적인 프롬프트를 생성해줘요. 여러분은 그저 복사해서 Suno AI에 붙여넣기만 하면 끝입니다!</li>\n<li style=\"margin-bottom: 10px;\"><b>맞춤형 가사 생성:</b> 인트로, 벌스, 코러스 같은 곡 구조를 설정해서 가사를 뽑을 수 있고요. 가사가 없는 연주곡 모드도 지원하니, 다양한 컨셉을 시도해볼 수 있습니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>가장 중요한, 고퀄리티 썸네일 자동 생성:</b> 배경에 'PLAYLIST'라는 문구가 자연스럽게 들어간 고퀄리티 이미지를 생성하고, 그 위에 원하는 감성 폰트로 제목까지 합성해줍니다. 포토샵 같은 전문 프로그램은 전혀 필요 없어요. 정말 정말 편리하죠!</li>\n</ul>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; font-weight: 600;\" data-ke-size=\"size23\"><b> ️ AI 플레이리스트 크리에이터 사용법 (단계별 가이드)</b></h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">사용 편의성을 위해 화면을 양쪽으로 나누어 'AI 플레이리스트 크리에이터'와 'Suno AI'를 함께 실행하는 것을 추천해요. 그러면 작업 효율이 훨씬 높아집니다.</p>\n<ol style=\"list-style-type: decimal; margin-left: 20px; margin-bottom: 20px;\" data-ke-list-type=\"decimal\">\n<li style=\"margin-bottom: 10px;\"><b>장르 선택:</b> 앱 첫 화면에서 플레이리스트 채널에서 가장 인기 있는 장르를 선택합니다. 만약 원하는 장르가 없다면 직접 입력할 수도 있어요. (예시: 로파이(Lo-Fi) 장르 선택)</li>\n<li style=\"margin-bottom: 10px;\"><b>제목 선택:</b> 선택한 장르에 적합한 제목 리스트가 생성되면, 그중 마음에 드는 감성적인 제목을 고릅니다. (예시: '비오는 날 창밖 보며 멍 때리기 좋은 감성' 선택)</li>\n<li style=\"margin-bottom: 10px;\"><b>프롬프트 및 가사 설정:</b> 화면이 바뀌면 왼쪽에 Suno AI용 프롬프트가 나타나요. 오른쪽에서는 생성할 가사의 언어와 곡 수를 선택하고, 곡의 구성을 설정합니다. 앱이 사용자가 선택한 내용에 적합한 곡 구성을 미리 추천해 주니 정말 편리하죠. 그 다음 가사에 적용할 비유와 은유의 정도를 선택하고, 인트로/아웃트로에도 가사를 포함할지 결정한 후 가사를 생성합니다. 연주곡을 원한다면 '가사 없음'을 선택하면 됩니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>SEO 정보 생성 및 저장:</b> 빠른 유튜브 SEO 작업을 위해 영상 제목, 설명, 해시태그, 키워드를 생성하는 기능이 있어요. 이걸 메모장에 미리 복사해두면 나중에 정말 유용하게 쓸 수 있습니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>Suno AI로 음악 생성:</b> AI 플레이리스트 크리에이터에서 생성된 Suno AI용 프롬프트를 복사하여 Suno AI의 스타일 칸에 붙여넣습니다. 가사가 생성되면 제목과 가사를 각각 복사한 후 Suno AI에 붙여넣기 하고 'Create' 버튼을 클릭하여 곡을 생성합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>썸네일 생성 및 다운로드:</b> 곡이 생성되는 동안 유튜브 썸네일 탭으로 이동하여 스타일과 폰트를 선택한 후 '생성' 버튼을 클릭합니다. 플레이리스트 제목이 멋지게 적용된 썸네일이 생성되는데, 수정사항이 있다면 입력하여 이미지의 일관성을 유지한 채 원하는 내용만 수정할 수 있습니다. 마음에 드는 썸네일은 바로 다운로드하세요!</li>\n<li style=\"margin-bottom: 10px;\"><b>곡 다운로드:</b> Suno AI에서 생성된 로파이 음악을 들어보고, 만족스럽다면 가사만큼 같은 작업을 반복하여 곡을 생성한 후 모두 다운로드합니다.</li>\n</ol>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  스펙트럼 스튜디오: 영상 편집 없이 전문가급 영상 만들기!</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이제 Suno AI로 만든 음악 파일을 가지고 '스펙트럼 스튜디오'를 활용해 실제 플레이리스트 영상을 만들어 볼 차례입니다. 이 도구는 정말이지 혁신적이라고 생각해요. 복잡한 영상 편집 프로그램 없이도 브라우저에서 바로 유튜브 플레이리스트 영상을 만들 수 있는 웹 기반 도구거든요!</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"스펙트럼 스튜디오 편집스튜디오.png\" data-origin-width=\"1626\" data-origin-height=\"915\"><span data-url=\"https://blog.kakaocdn.net/dn/bzA4WY/dJMcachnTo4/b2O1JwwEWxc7GymXtVuFg1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bzA4WY/dJMcachnTo4/b2O1JwwEWxc7GymXtVuFg1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bzA4WY/dJMcachnTo4/b2O1JwwEWxc7GymXtVuFg1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbzA4WY%2FdJMcachnTo4%2Fb2O1JwwEWxc7GymXtVuFg1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"스펙트럼 스튜디오 작업화면\" loading=\"lazy\" width=\"1626\" height=\"915\" data-filename=\"스펙트럼 스튜디오 편집스튜디오.png\" data-origin-width=\"1626\" data-origin-height=\"915\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><br />프리미어 프로나 파이널컷 같은 전문 편집 프로그램을 따로 배우지 않아도 되고, 프로그램을 설치할 필요도 없이 인터넷 브라우저만 있으면 어디서든 사용할 수 있다는 점이 정말 매력적입니다. 게다가, 앞서 소개한 AI 플레이리스트 크리에이터와 달리 AI 기능을 사용하지 않기 때문에 API 발급도 필요 없고, 가입만 하면 바로 사용할 수 있어요. 접근성이 정말 좋죠?</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; font-weight: 600;\" data-ke-size=\"size23\"><b>  스펙트럼 스튜디오의 독보적인 강점 5가지</b></h3>\n<ul style=\"list-style-type: disc; margin-left: 20px; margin-bottom: 20px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px;\"><b>환상적인 오디오 스펙트럼 기능:</b> 음악에 반응해서 실시간으로 움직이는 시각화 효과를 만들어줍니다. 막대형, 원형, 파형 등 다양한 스타일을 선택할 수 있고, 색상부터 반응 민감도까지 세밀하게 조정해서 나만의 감성을 표현할 수 있어요.</li>\n<li style=\"margin-bottom: 10px;\"><b>로고 배경 자동 제거:</b> 포토샵 없이도 클릭 한 번으로 로고 배경을 깔끔하게 제거하여 영상에 자연스럽게 합성할 수 있습니다. 채널의 브랜딩을 강화하는 데 아주 유용하죠.</li>\n<li style=\"margin-bottom: 10px;\"><b>감성적인 특수 효과와 필터:</b> 물방울, 반짝이는 입자, 빈티지 필터 등을 추가하여 영상을 훨씬 풍성하고 감성적으로 만들 수 있습니다. 시청자들의 눈을 즐겁게 해줄 거예요.</li>\n<li style=\"margin-bottom: 10px;\"><b>타임라인 자동 복사 기능:</b> 버튼 한 번으로 유튜브 설명란에 들어갈 곡 제목과 시간 정보가 자동으로 복사됩니다. 일일이 시간을 적을 필요가 없으니 정말이지 시간을 엄청나게 아낄 수 있습니다!</li>\n<li style=\"margin-bottom: 10px;\"><b>빠르고 안전한 로컬 렌더링 방식:</b> 여러분의 파일을 서버로 보내지 않고 PC에서 바로 처리하기 때문에 개인정보 유출 걱정이 없고, 렌더링 속도도 빠르며 안전합니다.</li>\n</ul>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 모든 강점 덕분에 2시간짜리 플레이리스트 영상을 편집부터 렌더링 완료까지 40분에서 50분이면 충분하다고 합니다. 기존 방식으로는 몇 시간씩 걸리던 작업을 1시간 안에 끝낼 수 있다니, 정말 놀랍지 않나요?</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px; font-weight: 600;\" data-ke-size=\"size23\"><b>⚙️ 스펙트럼 스튜디오 사용법 (단계별 가이드)</b></h3>\n<ol style=\"list-style-type: decimal; margin-left: 20px; margin-bottom: 20px;\" data-ke-list-type=\"decimal\">\n<li style=\"margin-bottom: 10px;\"><b>음악 파일 업로드:</b> Suno AI에서 작업한 음악 파일을 스펙트럼 스튜디오에 업로드합니다. 업로드한 파일의 재생 순서도 변경할 수 있으니 참고하세요.</li>\n<li style=\"margin-bottom: 10px;\"><b>타임라인 복사:</b> 상단에 있는 타임라인 복사 버튼을 클릭하면, 해당 곡으로 바로 이동할 수 있는 타임라인이 자동으로 생성됩니다. 이것도 메모장에 복사해 두면 유튜브 업로드 시 매우 유용해요.</li>\n<li style=\"margin-bottom: 10px;\"><b>이미지 및 로고 등록:</b> 앞서 AI 플레이리스트 크리에이터에서 만들어둔 썸네일 이미지를 등록합니다. 채널 로고가 있다면 함께 업로드할 수 있어요.</li>\n<li style=\"margin-bottom: 10px;\"><b>재생 설정:</b> 전체 음악을 몇 번 반복할지 재생 횟수를 선택하고 오디오 품질도 선택한 후 편집 스튜디오로 넘어갑니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>편집 스튜디오 설정:</b>\n<ul style=\"list-style-type: circle; margin-left: 20px; margin-top: 5px; margin-bottom: 10px;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px;\"><b>오디오 스펙트럼:</b> 왼쪽에서 막대형, 미니막대형, 원형, 파형 등 다양한 스타일을 선택하고, 오른쪽 아래에서 스펙트럼의 위치, 크기, 스타일 등 세부 속성을 변경합니다.</li>\n<li style=\"margin-bottom: 5px;\"><b>로고 조정:</b> 오른쪽 위에서 업로드한 로고 이미지의 크기와 위치를 조절하고, 배경 제거 기능을 활용하여 깔끔하게 적용할 수 있습니다.</li>\n<li style=\"margin-bottom: 5px;\"><b>배경 효과:</b> 왼쪽 아래에서는 배경 이미지에 다양한 필터와 비네팅 효과를 줄 수 있습니다.</li>\n<li style=\"margin-bottom: 5px;\"><b>특수 효과:</b> 바로 아래에는 배경 이미지 위에 움직이는 물방울과 반짝임 특수효과를 적용하고, 이 효과들의 속성을 제어하는 특별한 기능이 있습니다.</li>\n</ul>\n</li>\n<li style=\"margin-bottom: 10px;\"><b>비디오 내보내기:</b> 모든 설정이 완료되면 우측 상단의 '비디오 내보내기'를 클릭하고, 다음 화면에서 'MP4 렌더링 시작'을 클릭합니다. 저장할 파일명 설정 후 바로 렌더링이 시작되며, 짧은 시간 안에 고품질 영상이 완성됩니다.</li>\n</ol>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✅ 완성된 플레이리스트 영상, 유튜브에 업로드하기!</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이제 대망의 마지막 단계입니다! AI의 도움으로 완성된 플레이리스트 영상을 유튜브에 등록하는 방법을 알려드릴게요. 이 과정도 생각보다 어렵지 않으니 잘 따라와 주세요.</p>\n<ol style=\"list-style-type: decimal; margin-left: 20px; margin-bottom: 20px;\" data-ke-list-type=\"decimal\">\n<li style=\"margin-bottom: 10px;\"><b>영상 업로드:</b> 유튜브 우측 상단의 '만들기'에서 '동영상 업로드'를 클릭하고, 스펙트럼 스튜디오에서 렌더링한 영상을 등록합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>정보 입력:</b> AI 플레이리스트 크리에이터에서 미리 복사해 둔 영상 제목을 붙여넣고, 영상 설명란에도 미리 준비한 설명, 해시태그, 타임라인을 붙여넣습니다. 썸네일도 등록하시고요.</li>\n<li style=\"margin-bottom: 10px;\"><b>세부 설정:</b> 몇 가지 옵션 사항에 체크하고, 키워드까지 붙여넣기 한 후 동영상 언어를 한국어로 변경합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>공개 설정:</b> 하단의 '다음'을 클릭하면 공개 설정 화면이 나옵니다. 유튜브가 업로드하고 화질 처리를 완료할 때까지는 일단 '비공개'로 설정해 두는 것이 좋습니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>영어 자막 추가 (선택 사항):</b> 왼쪽 메뉴에서 '자막'을 선택하고 '언어 추가' 버튼 클릭 후 '영어'를 선택합니다. 그 다음 영어 우측의 '제목 및 설명 수정' 모드로 들어가서 제목, 영상 설명, 해시태그를 영어로 번역하여 붙여넣습니다. 이렇게 하면 영어권 국가에서 접속하는 시청자들에게 영상 제목과 설명이 영어로 보이게 되어 글로벌 시청자 유입에 유리합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>최종 공개:</b> 모든 설정이 완료되고 영상 처리가 끝나면, 비공개 영상을 '공개'로 변경하시면 됩니다.</li>\n</ol>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">어때요, 정말 간단하죠? 이 과정들을 거치면 여러분의 플레이리스트 채널이 멋지게 세상에 공개될 것입니다.</p>\n<div style=\"background-color: #f8f9fa; border: 1px solid #dadce0; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); padding: 25px; margin: 40px 0;\">\n<div style=\"font-size: 26px; color: #1a73e8; font-weight: bold; margin-bottom: 15px; padding-bottom: 10px; border-bottom: 2px solid #1a73e8;\">  <b>핵심 요약</b></div>\n<div style=\"font-size: 17px; line-height: 1.8;\">\n<p style=\"margin-bottom: 10px;\" data-ke-size=\"size16\">1. <b>AI 플레이리스트 크리에이터</b>로 기획, 음악 프롬프트, 가사, 썸네일을 원스톱으로 생성해요.</p>\n<p style=\"margin-bottom: 10px;\" data-ke-size=\"size16\">2. <b>Suno AI 유료 플랜</b>으로 상업적 이용 가능한 고품질 저작권 프리 음원을 만들 수 있어요.</p>\n<p style=\"margin-bottom: 10px;\" data-ke-size=\"size16\">3. <b>스펙트럼 스튜디오</b>로 복잡한 편집 없이 오디오 스펙트럼 영상을 초고속으로 만들어요.</p>\n<p style=\"margin-bottom: 0;\" data-ke-size=\"size16\">4. <b>SEO 최적화된 업로드</b>와 영어 자막 추가로 글로벌 시청자를 사로잡아요.</p>\n</div>\n<div style=\"font-size: 14px; color: #5f6368; margin-top: 25px; padding-top: 15px; border-top: 1px solid #e8eaed;\"><i>AI 기술을 활용하면 누구나 쉽고 빠르게 유튜브 플레이리스트 채널 운영이 가능해집니다.</i></div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q1: AI 플레이리스트 채널이 왜 인기가 많나요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A1: 영상 편집이나 저작권 걱정 없이 AI 도구로 고품질의 플레이리스트 영상을 쉽고 빠르게 제작할 수 있기 때문입니다. 초기 진입 장벽이 낮아 누구나 쉽게 시작하여 수익을 창출할 수 있다는 점이 큰 장점이에요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q2: Suno AI 유료 플랜은 왜 필요한가요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A2: Suno AI의 무료 플랜으로 생성한 음악은 상업적으로 이용할 수 없습니다. 유튜브 수익 창출이나 음원 발매 등 상업적 활용을 위해서는 반드시 유료 플랜에 가입해야 저작권 문제없이 안전하게 활동할 수 있어요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q3: AI 플레이리스트 크리에이터와 스펙트럼 스튜디오의 주요 차이점은 무엇인가요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A3: AI 플레이리스트 크리에이터는 플레이리스트 기획, 음악 프롬프트, 가사, 썸네일 등 '콘텐츠 아이디어와 생성'에 중점을 둔 AI 기반 도구입니다. 반면 스펙트럼 스튜디오는 음악 파일과 배경 이미지를 활용하여 오디오 스펙트럼이 포함된 '실제 영상 제작'에 특화된 웹 기반 편집 도구이며, AI 기능을 사용하지 않아 API가 필요 없습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q4: 로컬 렌더링 방식의 장점은 무엇인가요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A4: 로컬 렌더링은 개인의 컴퓨터에서 직접 영상 파일을 처리하기 때문에 서버로 파일을 전송할 필요가 없어 개인 정보 유출에 대한 걱정이 없습니다. 또한, 빠르고 안정적으로 고품질의 영상을 생성할 수 있다는 장점이 있습니다.</p>\n<script type=\"application/ld+json\">\n    {\n      \"@context\": \"https://schema.org\",\n      \"@type\": \"FAQPage\",\n      \"mainEntity\": [\n        {\n          \"@type\": \"Question\",\n          \"name\": \"AI 플레이리스트 채널이 왜 인기가 많나요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"영상 편집이나 저작권 걱정 없이 AI 도구로 고품질의 플레이리스트 영상을 쉽고 빠르게 제작할 수 있기 때문입니다. 초기 진입 장벽이 낮아 누구나 쉽게 시작하여 수익을 창출할 수 있다는 점이 큰 장점이에요.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"Suno AI 유료 플랜은 왜 필요한가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"Suno AI의 무료 플랜으로 생성한 음악은 상업적으로 이용할 수 없습니다. 유튜브 수익 창출이나 음원 발매 등 상업적 활용을 위해서는 반드시 유료 플랜에 가입해야 저작권 문제없이 안전하게 활동할 수 있어요.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"AI 플레이리스트 크리에이터와 스펙트럼 스튜디오의 주요 차이점은 무엇인가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"AI 플레이리스트 크리에이터는 플레이리스트 기획, 음악 프롬프트, 가사, 썸네일 등 '콘텐츠 아이디어와 생성'에 중점을 둔 AI 기반 도구입니다. 반면 스펙트럼 스튜디오는 음악 파일과 배경 이미지를 활용하여 오디오 스펙트럼이 포함된 '실제 영상 제작'에 특화된 웹 기반 편집 도구이며, AI 기능을 사용하지 않아 API가 필요 없습니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"로컬 렌더링 방식의 장점은 무엇인가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"로컬 렌더링은 개인의 컴퓨터에서 직접 영상 파일을 처리하기 때문에 서버로 파일을 전송할 필요가 없어 개인 정보 유출에 대한 걱정이 없습니다. 또한, 빠르고 안정적으로 고품질의 영상을 생성할 수 있다는 장점이 있습니다.\"\n          }\n        }\n      ]\n    }\n  </script>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">자, 이것으로 기획부터 썸네일, 그리고 전문가급 영상 제작까지 AI로 원스톱으로 끝내는 유튜브 플레이리스트 채널 만들기 강의를 모두 마쳤습니다. 제가 직접 경험해보니, 이 두 가지 도구를 활용하면 과거에는 초보자들이 도전조차 하지 못했던 플레이리스트 영상을 정말 쉽고 빠르게 만들 수 있다는 것을 확신했습니다. 여러분도 이제 더 이상 어렵게 생각하지 마세요! AI가 여러분의 크리에이티브한 잠재력을 활짝 열어줄 것입니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">특히 오늘 소개해드린 'AI 플레이리스트 크리에이터' 앱은 영상 설명란 링크를 통해 무료로 배포할 예정이니 많은 관심 부탁드립니다. 또한, 어려운 영상 편집기 없이 몇 번의 클릭만으로 플레이리스트 영상을 만들 수 있는 '스펙트럼 스튜디오'는 채널 멤버십 여러분께만 게시물을 통해 공개하도록 하겠습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이 강의가 여러분의 성공적인 유튜브 플레이리스트 채널 운영에 큰 도움이 되었기를 진심으로 바랍니다. 여러분의 구독과 좋아요, 그리고 알림 설정은 제가 더 좋은 콘텐츠를 만드는 데 큰 힘이 됩니다. 감사합니다!</p>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  무료 앱 사용하</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><span style=\"background-color: #ffffff; color: #3c4043; text-align: start;\">1. 'AI 플레이리스트 크리에이터' 는 아래 링크에서 무료로 사용하세요. (단, 여러분의 api 키 발급을 해야 합니다.)</span></p>\n<figure id=\"og_1766276619481\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"AI Playlist Creator\" data-og-description=\"\" data-og-host=\"ai-playlist-creator-bice.vercel.app\" data-og-source-url=\"https://ai-playlist-creator-bice.vercel.app/\" data-og-url=\"https://ai-playlist-creator-bice.vercel.app/\" data-og-image=\"\"><a href=\"https://ai-playlist-creator-bice.vercel.app/\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://ai-playlist-creator-bice.vercel.app/\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">AI Playlist Creator</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">&nbsp;</p>\n<p class=\"og-host\" data-ke-size=\"size16\">ai-playlist-creator-bice.vercel.app</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">2. ' <span style=\"background-color: #ffffff; color: #3c4043; text-align: start;\">스펙트럼 스튜디오'는 GPT PARK 유튜브 채널 멤버십 가입후 게시물에서 제공하는 링크에서 무료 사용이 가능합니다.</span></p>\n<figure id=\"og_1766276789271\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"profile\" data-og-title=\"GPT PARK의 AI팩트\" data-og-description=\"가장 빠르고 알찬 AI 정보를 공개합니다. 유용한 AI 인사이트 : https://muzbox.tistory.com/category/AI%2C%20미래기술 블로그 수익화 인사이트 : https://smart-it-life.tistory.com/category/블로그%20수익화 유용한 자료 \" data-og-host=\"www.youtube.com\" data-og-source-url=\"https://www.youtube.com/channel/UCAAj5mFm22pV99ucbcTZx-Q/join\" data-og-url=\"https://www.youtube.com/channel/UCAAj5mFm22pV99ucbcTZx-Q\" data-og-image=\"https://scrap.kakaocdn.net/dn/bUHvmP/hyZOC0aZkY/ycYWJS4ATkvBn02qIxWV3k/img.jpg?width=900&amp;height=900&amp;face=0_0_900_900,https://scrap.kakaocdn.net/dn/rVvEX/hyZOKw8tjr/rJFKQ9vxlSgnsykdvjNtBk/img.jpg?width=900&amp;height=900&amp;face=0_0_900_900\"><a href=\"https://www.youtube.com/channel/UCAAj5mFm22pV99ucbcTZx-Q/join\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://www.youtube.com/channel/UCAAj5mFm22pV99ucbcTZx-Q/join\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/bUHvmP/hyZOC0aZkY/ycYWJS4ATkvBn02qIxWV3k/img.jpg?width=900&amp;height=900&amp;face=0_0_900_900,https://scrap.kakaocdn.net/dn/rVvEX/hyZOKw8tjr/rJFKQ9vxlSgnsykdvjNtBk/img.jpg?width=900&amp;height=900&amp;face=0_0_900_900');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">GPT PARK의 AI팩트</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">가장 빠르고 알찬 AI 정보를 공개합니다. 유용한 AI 인사이트 : https://muzbox.tistory.com/category/AI%2C%20미래기술 블로그 수익화 인사이트 : https://smart-it-life.tistory.com/category/블로그%20수익화 유용한 자료</p>\n<p class=\"og-host\" data-ke-size=\"size16\">www.youtube.com</p>\n</div>\n</a></figure>\n<iframe \n  src=\"https://www.youtube.com/embed/LUcx7W_YIWs\" \n  title=\"영상 하나 만드는데 5시간? AI 툴을 쓰면 40분 컷! 플레이리스트 채널 자동화 가이드\" \n  frameborder=\"0\" \n  allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" \n  referrerpolicy=\"strict-origin-when-cross-origin\" \n  allowfullscreen\n  style=\"width: 100%; height: auto; aspect-ratio: 16 / 9;\">\n</iframe>",
        "contentSnippet": "유튜브 플레이리스트 채널, 영상을 직접 편집해야 한다는 부담감 때문에 시작도 못 해보셨나요? 더 이상 그런 고민은 필요 없습니다. 기획부터 음악, 썸네일, 그리고 전문가급 오디오 스펙트럼 영상 제작까지 AI가 원스톱으로 해결해주는 신세계를 경험해보세요. 클릭 몇 번으로 누구나 쉽게 유튜브 수익화를 달성할 수 있는 궁극의 치트키를 지금 바로 공개합니다.\n요즘 유튜브에서 잔잔한 음악과 함께 멋진 배경 영상이 흘러나오는 플레이리스트 채널이 큰 인기를 끌고 있죠. 로파이걸(Lofi Girl) 같은 채널은 이런 플레이리스트 영상만으로도 어마어마한 조회수와 함께 상당한 광고 수익을 올리고 있다고 알려져 있습니다. 많은 분들이 '나도 한번 해볼까?' 생각하시지만, 막상 시작하려니 막막한 부분이 한두 가지가 아니었을 겁니다.\n\n\n \n과연 내가 어떤 컨셉으로 채널을 만들지, 저작권 걱정 없는 음원은 어디서 구해야 할지, 게다가 프리미어나 파이널컷 같은 복잡한 편집 프로그램을 다뤄야 한다는 압박감까지… 정말이지 시작도 전에 지쳐버리기 일쑤였죠. 썸네일 디자인도 빼놓을 수 없고요. 이 모든 과정을 하나하나 배우려면 솔직히 시간과 노력이 정말 많이 들었습니다.\n그런데 말입니다. 이 모든 고민을 단숨에 날려버릴 놀라운 AI 솔루션이 등장했습니다. 이제 클릭 몇 번만으로 이 모든 과정을 해결하고 여러분만의 플레이리스트 채널을 운영하며 수익을 창출할 수 있게 되었어요. 자, 저와 함께 이 혁신적인 방법을 자세히 알아보시죠!\n  플레이리스트 채널, 왜 그렇게 어려웠을까요?\n먼저, 기존의 플레이리스트 채널 제작 방식이 왜 그렇게 만만치 않았는지 그 어려움을 짚어보겠습니다. 크게 세 단계로 나눌 수 있는데, 이 과정 하나하나가 결코 쉽지 않았어요.\n1. 컨셉 설정과 음원 수급의 딜레마\n단순히 '좋은 노래 모음'으로는 경쟁력을 갖기 어려웠죠. '비 오는 밤 성수동 카페', '새벽 3시 집중력을 높이는 로파이'처럼 구체적인 상황과 감성을 담은 컨셉을 잡아야 하는데, 여기서부터 많은 분들이 막막함을 느꼈을 거예요. 게다가 저작권 걱정 없이 좋은 음원을 확보하는 건 또 다른 큰 산이었습니다. 유튜브 오디오 보관함이나 NCS 같은 무료 음원도 있지만, 너무 많은 사람들이 사용해서 차별화가 어렵다는 단점이 있었죠.\n  AI 음원의 등장: 요즘은 수노(Suno AI)나 유디오(Udio) 같은 AI로 직접 음원을 만드는 추세예요. 하지만 이것도 처음에는 '프롬프트'를 어떻게 작성해야 원하는 결과물을 얻을 수 있을지 정말 어렵게 느껴질 수 있습니다.\n2. 시각 자료 제작의 복잡성\n음악만 계속 틀어놓으면 시청자들이 금세 지루함을 느낄 수 있죠. 그래서 배경 영상이나 이미지가 필수인데, 미드저니(Midjourney)나 캔바(Canva) 같은 도구를 배우는 것도 일이었어요. 거기서 끝이 아니죠! 정적인 이미지에 오디오 스펙트럼 같은 움직임을 더해서 시청자의 시선을 사로잡아야 했습니다. 그런데 이런 효과를 넣으려면 프리미어 프로나 캡컷(CapCut) 같은 전문 영상 편집 프로그램을 배워야 하니, 이 단계에서 좌절하는 분들이 많았을 겁니다.\n3. 긴 영상 편집과 렌더링의 고통\n배경 영상 위에 음원을 배치하고, 화면 하단에 곡 제목을 표시하고, 여러 영상 효과를 반영하는 것 자체가 어려운 작업입니다. 특히 플레이리스트 영상처럼 1시간 이상의 긴 영상을 원활하게 편집하고 렌더링하려면 앞서 언급한 전문 영상 편집 프로그램은 거의 필수적이죠. 배우는 것도 어렵지만, 저사양 컴퓨터로는 렌더링에만 반나절이 걸리는 경우도 허다해서 '대체 언제 다 만들지?' 하는 생각이 절로 들었습니다.\n\n\n4. 시간 소모와 초기 노출의 한계\n이 모든 과정을 숙련자가 해도 영상 하나 만드는 데 최소 3시간에서 5시간은 족히 걸렸습니다. 기획/선곡 1~2시간, 시각 자료 제작 30분~1시간, 편집/렌더링 1~2시간, 유튜브 업로드/SEO 30분… 매일 이렇게 작업하려면 정말 힘들었겠죠? 게다가 이미 로파이걸 같은 거대 채널들이 시장을 장악하고 있어서 신규 채널이 알고리즘의 선택을 받기까지는 최소 3~6개월 이상의 꾸준한 노력이 필요했습니다. 매번 새로운 무드를 찾아내고 수십 곡의 리스트를 짜는 작업은 창의적인 에너지를 엄청나게 소모하며 소재 고갈에 빠지기 쉬웠고요.\n하지만 오늘 제가 소개해드릴 방법은 이 모든 과정을 획기적으로 단축시켜줍니다. 특히 AI 도구를 활용하면 저작권 문제에서 훨씬 자유롭고, 제작 시간도 놀랍도록 줄일 수 있으니, 정말 솔깃하지 않나요? 이제 본격적으로 강력한 두 가지 앱을 소개해드릴게요!\n  AI 플레이리스트 제작, 시작 전 준비물!\n자, 그럼 이 놀라운 AI 도구들을 사용하기 전에 몇 가지 준비할 것이 있습니다. 생각보다 간단하니 걱정 마세요!\n구글 아이디 및 API 발급: 구글의 최신 AI 모델인 제미나이를 기반으로 작동하는 'AI 플레이리스트 크리에이터'를 사용하려면 구글 AI 스튜디오 사용을 위한 구글 아이디와 API 발급이 필요해요. API 발급 방법은 제가 다른 영상에서 상세히 다뤘으니, 본문이나 댓글에 있는 링크를 참고하셔서 먼저 발급받아주세요.\nSuno AI 가입: 음악 생성을 위해 suno.com에 접속하셔서 간단하게 가입해주셔야 합니다.\n⚠️ 중요! Suno AI 유료 플랜: Suno AI에서 생성한 음원을 유튜브 수익 창출이나 음원 발매 등 상업적으로 활용하려면 반드시 유료 플랜에 가입해야 합니다. 이 점 꼭 기억해 주세요!\n이 두 가지 준비물이 갖춰졌다면, 이제 본격적으로 AI와 함께 플레이리스트 채널을 만드는 여정을 시작해볼까요?\n  AI 플레이리스트 크리에이터: 기획부터 썸네일까지 원스톱!\n이 앱은 구글의 최신 AI 모델인 제미나이를 기반으로 작동하는데요. 단순히 아이디어만 툭 던져주는 수준이 아닙니다. 실제 음악 생성에 필요한 전문적인 프롬프트부터 채널 운영에 필수적인 모든 요소를 그야말로 원스톱으로 제공해줘요. 제가 직접 써보니, 정말이지 '이게 되네?' 싶을 정도로 놀라웠습니다.\n\n\n✨ AI 플레이리스트 크리에이터의 핵심 기능 4가지\n클릭을 부르는 감성적인 제목 생성: '재즈 음악'처럼 평범한 제목이 아닌, 이모지와 감성적인 문구, 그리고 검색 키워드까지 고려한 매력적인 제목을 뽑아줍니다. 예를 들어, ' ️ 비 오는 밤, 따뜻한 커피와 함께 듣는 감성 재즈'처럼요.\nSuno 5.0에 최적화된 프롬프트 생성: 단순히 '재즈 만들어줘'가 아닙니다. 악기 구성, 공간감, 연주 스타일까지 아주 디테일하게 작성된 전문적인 프롬프트를 생성해줘요. 여러분은 그저 복사해서 Suno AI에 붙여넣기만 하면 끝입니다!\n맞춤형 가사 생성: 인트로, 벌스, 코러스 같은 곡 구조를 설정해서 가사를 뽑을 수 있고요. 가사가 없는 연주곡 모드도 지원하니, 다양한 컨셉을 시도해볼 수 있습니다.\n가장 중요한, 고퀄리티 썸네일 자동 생성: 배경에 'PLAYLIST'라는 문구가 자연스럽게 들어간 고퀄리티 이미지를 생성하고, 그 위에 원하는 감성 폰트로 제목까지 합성해줍니다. 포토샵 같은 전문 프로그램은 전혀 필요 없어요. 정말 정말 편리하죠!\n ️ AI 플레이리스트 크리에이터 사용법 (단계별 가이드)\n사용 편의성을 위해 화면을 양쪽으로 나누어 'AI 플레이리스트 크리에이터'와 'Suno AI'를 함께 실행하는 것을 추천해요. 그러면 작업 효율이 훨씬 높아집니다.\n장르 선택: 앱 첫 화면에서 플레이리스트 채널에서 가장 인기 있는 장르를 선택합니다. 만약 원하는 장르가 없다면 직접 입력할 수도 있어요. (예시: 로파이(Lo-Fi) 장르 선택)\n제목 선택: 선택한 장르에 적합한 제목 리스트가 생성되면, 그중 마음에 드는 감성적인 제목을 고릅니다. (예시: '비오는 날 창밖 보며 멍 때리기 좋은 감성' 선택)\n프롬프트 및 가사 설정: 화면이 바뀌면 왼쪽에 Suno AI용 프롬프트가 나타나요. 오른쪽에서는 생성할 가사의 언어와 곡 수를 선택하고, 곡의 구성을 설정합니다. 앱이 사용자가 선택한 내용에 적합한 곡 구성을 미리 추천해 주니 정말 편리하죠. 그 다음 가사에 적용할 비유와 은유의 정도를 선택하고, 인트로/아웃트로에도 가사를 포함할지 결정한 후 가사를 생성합니다. 연주곡을 원한다면 '가사 없음'을 선택하면 됩니다.\nSEO 정보 생성 및 저장: 빠른 유튜브 SEO 작업을 위해 영상 제목, 설명, 해시태그, 키워드를 생성하는 기능이 있어요. 이걸 메모장에 미리 복사해두면 나중에 정말 유용하게 쓸 수 있습니다.\nSuno AI로 음악 생성: AI 플레이리스트 크리에이터에서 생성된 Suno AI용 프롬프트를 복사하여 Suno AI의 스타일 칸에 붙여넣습니다. 가사가 생성되면 제목과 가사를 각각 복사한 후 Suno AI에 붙여넣기 하고 'Create' 버튼을 클릭하여 곡을 생성합니다.\n썸네일 생성 및 다운로드: 곡이 생성되는 동안 유튜브 썸네일 탭으로 이동하여 스타일과 폰트를 선택한 후 '생성' 버튼을 클릭합니다. 플레이리스트 제목이 멋지게 적용된 썸네일이 생성되는데, 수정사항이 있다면 입력하여 이미지의 일관성을 유지한 채 원하는 내용만 수정할 수 있습니다. 마음에 드는 썸네일은 바로 다운로드하세요!\n곡 다운로드: Suno AI에서 생성된 로파이 음악을 들어보고, 만족스럽다면 가사만큼 같은 작업을 반복하여 곡을 생성한 후 모두 다운로드합니다.\n  스펙트럼 스튜디오: 영상 편집 없이 전문가급 영상 만들기!\n이제 Suno AI로 만든 음악 파일을 가지고 '스펙트럼 스튜디오'를 활용해 실제 플레이리스트 영상을 만들어 볼 차례입니다. 이 도구는 정말이지 혁신적이라고 생각해요. 복잡한 영상 편집 프로그램 없이도 브라우저에서 바로 유튜브 플레이리스트 영상을 만들 수 있는 웹 기반 도구거든요!\n\n\n\n프리미어 프로나 파이널컷 같은 전문 편집 프로그램을 따로 배우지 않아도 되고, 프로그램을 설치할 필요도 없이 인터넷 브라우저만 있으면 어디서든 사용할 수 있다는 점이 정말 매력적입니다. 게다가, 앞서 소개한 AI 플레이리스트 크리에이터와 달리 AI 기능을 사용하지 않기 때문에 API 발급도 필요 없고, 가입만 하면 바로 사용할 수 있어요. 접근성이 정말 좋죠?\n  스펙트럼 스튜디오의 독보적인 강점 5가지\n환상적인 오디오 스펙트럼 기능: 음악에 반응해서 실시간으로 움직이는 시각화 효과를 만들어줍니다. 막대형, 원형, 파형 등 다양한 스타일을 선택할 수 있고, 색상부터 반응 민감도까지 세밀하게 조정해서 나만의 감성을 표현할 수 있어요.\n로고 배경 자동 제거: 포토샵 없이도 클릭 한 번으로 로고 배경을 깔끔하게 제거하여 영상에 자연스럽게 합성할 수 있습니다. 채널의 브랜딩을 강화하는 데 아주 유용하죠.\n감성적인 특수 효과와 필터: 물방울, 반짝이는 입자, 빈티지 필터 등을 추가하여 영상을 훨씬 풍성하고 감성적으로 만들 수 있습니다. 시청자들의 눈을 즐겁게 해줄 거예요.\n타임라인 자동 복사 기능: 버튼 한 번으로 유튜브 설명란에 들어갈 곡 제목과 시간 정보가 자동으로 복사됩니다. 일일이 시간을 적을 필요가 없으니 정말이지 시간을 엄청나게 아낄 수 있습니다!\n빠르고 안전한 로컬 렌더링 방식: 여러분의 파일을 서버로 보내지 않고 PC에서 바로 처리하기 때문에 개인정보 유출 걱정이 없고, 렌더링 속도도 빠르며 안전합니다.\n이 모든 강점 덕분에 2시간짜리 플레이리스트 영상을 편집부터 렌더링 완료까지 40분에서 50분이면 충분하다고 합니다. 기존 방식으로는 몇 시간씩 걸리던 작업을 1시간 안에 끝낼 수 있다니, 정말 놀랍지 않나요?\n⚙️ 스펙트럼 스튜디오 사용법 (단계별 가이드)\n음악 파일 업로드: Suno AI에서 작업한 음악 파일을 스펙트럼 스튜디오에 업로드합니다. 업로드한 파일의 재생 순서도 변경할 수 있으니 참고하세요.\n타임라인 복사: 상단에 있는 타임라인 복사 버튼을 클릭하면, 해당 곡으로 바로 이동할 수 있는 타임라인이 자동으로 생성됩니다. 이것도 메모장에 복사해 두면 유튜브 업로드 시 매우 유용해요.\n이미지 및 로고 등록: 앞서 AI 플레이리스트 크리에이터에서 만들어둔 썸네일 이미지를 등록합니다. 채널 로고가 있다면 함께 업로드할 수 있어요.\n재생 설정: 전체 음악을 몇 번 반복할지 재생 횟수를 선택하고 오디오 품질도 선택한 후 편집 스튜디오로 넘어갑니다.\n편집 스튜디오 설정:\n\n오디오 스펙트럼: 왼쪽에서 막대형, 미니막대형, 원형, 파형 등 다양한 스타일을 선택하고, 오른쪽 아래에서 스펙트럼의 위치, 크기, 스타일 등 세부 속성을 변경합니다.\n로고 조정: 오른쪽 위에서 업로드한 로고 이미지의 크기와 위치를 조절하고, 배경 제거 기능을 활용하여 깔끔하게 적용할 수 있습니다.\n배경 효과: 왼쪽 아래에서는 배경 이미지에 다양한 필터와 비네팅 효과를 줄 수 있습니다.\n특수 효과: 바로 아래에는 배경 이미지 위에 움직이는 물방울과 반짝임 특수효과를 적용하고, 이 효과들의 속성을 제어하는 특별한 기능이 있습니다.\n비디오 내보내기: 모든 설정이 완료되면 우측 상단의 '비디오 내보내기'를 클릭하고, 다음 화면에서 'MP4 렌더링 시작'을 클릭합니다. 저장할 파일명 설정 후 바로 렌더링이 시작되며, 짧은 시간 안에 고품질 영상이 완성됩니다.\n✅ 완성된 플레이리스트 영상, 유튜브에 업로드하기!\n이제 대망의 마지막 단계입니다! AI의 도움으로 완성된 플레이리스트 영상을 유튜브에 등록하는 방법을 알려드릴게요. 이 과정도 생각보다 어렵지 않으니 잘 따라와 주세요.\n영상 업로드: 유튜브 우측 상단의 '만들기'에서 '동영상 업로드'를 클릭하고, 스펙트럼 스튜디오에서 렌더링한 영상을 등록합니다.\n정보 입력: AI 플레이리스트 크리에이터에서 미리 복사해 둔 영상 제목을 붙여넣고, 영상 설명란에도 미리 준비한 설명, 해시태그, 타임라인을 붙여넣습니다. 썸네일도 등록하시고요.\n세부 설정: 몇 가지 옵션 사항에 체크하고, 키워드까지 붙여넣기 한 후 동영상 언어를 한국어로 변경합니다.\n공개 설정: 하단의 '다음'을 클릭하면 공개 설정 화면이 나옵니다. 유튜브가 업로드하고 화질 처리를 완료할 때까지는 일단 '비공개'로 설정해 두는 것이 좋습니다.\n영어 자막 추가 (선택 사항): 왼쪽 메뉴에서 '자막'을 선택하고 '언어 추가' 버튼 클릭 후 '영어'를 선택합니다. 그 다음 영어 우측의 '제목 및 설명 수정' 모드로 들어가서 제목, 영상 설명, 해시태그를 영어로 번역하여 붙여넣습니다. 이렇게 하면 영어권 국가에서 접속하는 시청자들에게 영상 제목과 설명이 영어로 보이게 되어 글로벌 시청자 유입에 유리합니다.\n최종 공개: 모든 설정이 완료되고 영상 처리가 끝나면, 비공개 영상을 '공개'로 변경하시면 됩니다.\n어때요, 정말 간단하죠? 이 과정들을 거치면 여러분의 플레이리스트 채널이 멋지게 세상에 공개될 것입니다.\n  핵심 요약\n1. AI 플레이리스트 크리에이터로 기획, 음악 프롬프트, 가사, 썸네일을 원스톱으로 생성해요.\n2. Suno AI 유료 플랜으로 상업적 이용 가능한 고품질 저작권 프리 음원을 만들 수 있어요.\n3. 스펙트럼 스튜디오로 복잡한 편집 없이 오디오 스펙트럼 영상을 초고속으로 만들어요.\n4. SEO 최적화된 업로드와 영어 자막 추가로 글로벌 시청자를 사로잡아요.\nAI 기술을 활용하면 누구나 쉽고 빠르게 유튜브 플레이리스트 채널 운영이 가능해집니다.\n❓ 자주 묻는 질문 (FAQ)\nQ1: AI 플레이리스트 채널이 왜 인기가 많나요?\nA1: 영상 편집이나 저작권 걱정 없이 AI 도구로 고품질의 플레이리스트 영상을 쉽고 빠르게 제작할 수 있기 때문입니다. 초기 진입 장벽이 낮아 누구나 쉽게 시작하여 수익을 창출할 수 있다는 점이 큰 장점이에요.\nQ2: Suno AI 유료 플랜은 왜 필요한가요?\nA2: Suno AI의 무료 플랜으로 생성한 음악은 상업적으로 이용할 수 없습니다. 유튜브 수익 창출이나 음원 발매 등 상업적 활용을 위해서는 반드시 유료 플랜에 가입해야 저작권 문제없이 안전하게 활동할 수 있어요.\nQ3: AI 플레이리스트 크리에이터와 스펙트럼 스튜디오의 주요 차이점은 무엇인가요?\nA3: AI 플레이리스트 크리에이터는 플레이리스트 기획, 음악 프롬프트, 가사, 썸네일 등 '콘텐츠 아이디어와 생성'에 중점을 둔 AI 기반 도구입니다. 반면 스펙트럼 스튜디오는 음악 파일과 배경 이미지를 활용하여 오디오 스펙트럼이 포함된 '실제 영상 제작'에 특화된 웹 기반 편집 도구이며, AI 기능을 사용하지 않아 API가 필요 없습니다.\nQ4: 로컬 렌더링 방식의 장점은 무엇인가요?\nA4: 로컬 렌더링은 개인의 컴퓨터에서 직접 영상 파일을 처리하기 때문에 서버로 파일을 전송할 필요가 없어 개인 정보 유출에 대한 걱정이 없습니다. 또한, 빠르고 안정적으로 고품질의 영상을 생성할 수 있다는 장점이 있습니다.\n자, 이것으로 기획부터 썸네일, 그리고 전문가급 영상 제작까지 AI로 원스톱으로 끝내는 유튜브 플레이리스트 채널 만들기 강의를 모두 마쳤습니다. 제가 직접 경험해보니, 이 두 가지 도구를 활용하면 과거에는 초보자들이 도전조차 하지 못했던 플레이리스트 영상을 정말 쉽고 빠르게 만들 수 있다는 것을 확신했습니다. 여러분도 이제 더 이상 어렵게 생각하지 마세요! AI가 여러분의 크리에이티브한 잠재력을 활짝 열어줄 것입니다.\n특히 오늘 소개해드린 'AI 플레이리스트 크리에이터' 앱은 영상 설명란 링크를 통해 무료로 배포할 예정이니 많은 관심 부탁드립니다. 또한, 어려운 영상 편집기 없이 몇 번의 클릭만으로 플레이리스트 영상을 만들 수 있는 '스펙트럼 스튜디오'는 채널 멤버십 여러분께만 게시물을 통해 공개하도록 하겠습니다.\n이 강의가 여러분의 성공적인 유튜브 플레이리스트 채널 운영에 큰 도움이 되었기를 진심으로 바랍니다. 여러분의 구독과 좋아요, 그리고 알림 설정은 제가 더 좋은 콘텐츠를 만드는 데 큰 힘이 됩니다. 감사합니다!\n  무료 앱 사용하\n1. 'AI 플레이리스트 크리에이터' 는 아래 링크에서 무료로 사용하세요. (단, 여러분의 api 키 발급을 해야 합니다.)\n\n \nAI Playlist Creator\n \nai-playlist-creator-bice.vercel.app\n\n \n2. ' 스펙트럼 스튜디오'는 GPT PARK 유튜브 채널 멤버십 가입후 게시물에서 제공하는 링크에서 무료 사용이 가능합니다.\n\n \nGPT PARK의 AI팩트\n가장 빠르고 알찬 AI 정보를 공개합니다. 유용한 AI 인사이트 : https://muzbox.tistory.com/category/AI%2C%20미래기술 블로그 수익화 인사이트 : https://smart-it-life.tistory.com/category/블로그%20수익화 유용한 자료\nwww.youtube.com",
        "guid": "https://muzbox.tistory.com/483694",
        "categories": [
          "AI, 미래기술/AI 챗봇 및 지침 무료 배포",
          "ai 유튜브",
          "AI 플레이리스트 크리에이터",
          "suno ai",
          "스펙트럼 스튜디오",
          "영상 편집 없이",
          "오디오 스펙트럼",
          "유튜브 수익화",
          "유튜브 썸네일",
          "유튜브 플레이리스트",
          "플레이리스트 제작"
        ],
        "isoDate": "2025-12-21T00:26:57.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "Windows 앱은 왜 점점 무거워질까? 2025년, 사라진 '네이티브 앱'의 추억과 현실",
        "link": "https://muzbox.tistory.com/483693",
        "pubDate": "Wed, 17 Dec 2025 15:17:11 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "https://muzbox.tistory.com/483693#entry483693comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #333333;\">\n<div style=\"background-color: #e3f2fd; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">과거의 윈도우 앱들은 놀랍도록 가볍고 빠르게 작동하며 사용자들에게 쾌적한 경험을 선사했습니다. 하지만 현재, 우리는 점점 무거워지고 느려지는 앱들에 익숙해지고 있죠. 개발 편의성이라는 명분 뒤에 숨겨진 사용자 경험의 희생, 그리고 '네이티브 앱'이라는 단어가 잊혀져 가는 현실 속에서 과연 어떤 변화가 있었는지 함께 자세히 살펴보겠습니다.</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/XXYCc/dJMcafd5U65/zuB4SUihnMt7cnSUKyxWZK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/XXYCc/dJMcafd5U65/zuB4SUihnMt7cnSUKyxWZK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/XXYCc/dJMcafd5U65/zuB4SUihnMt7cnSUKyxWZK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FXXYCc%2FdJMcafd5U65%2FzuB4SUihnMt7cnSUKyxWZK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"옛날 윈도우 앱과 2025년의 무거운 웹 기반 앱을 대조하여 보여주는 이미지. 과거의 아이콘은 가볍고 빠르며, 현재의 아이콘은 복잡하고 시스템 자원을 많이 소비하는 듯한 모습이다.\" loading=\"lazy\" width=\"500\" height=\"500\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #0f4c81, #002f6c); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✨ 과거의 영광, '네이티브 앱'은 무엇이었을까?</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">윈도우에서 '네이티브 앱'이라고 하면, 그 운영체제 자체의 언어와 프레임워크를 기반으로 만들어진 애플리케이션을 의미했어요. Win32, MFC, .NET(WPF, WinForms) 같은 기술들, 그리고 좀 더 최근에는 UWP(Universal Windows Platform)나 WinUI 같은 것들이 대표적이죠. 이 앱들은 운영체제의 '모국어'를 구사하기 때문에 시스템 자원을 가장 효율적으로 사용하고, OS의 디자인 가이드라인이나 사용자 경험(UX)을 충실히 따랐습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">그래서 과거의 많은 윈도우 앱들은 정말이지 상상할 수 없을 정도로 빠르고 가벼웠습니다. Notepad++, Winamp, Paint.NET, foobar2000, Everything Search 같은 이름들을 들어보시면 아마 고개를 끄덕이실 거예요. 용량도 몇 MB에 불과한데, 실행은 눈 깜짝할 사이에 되고, RAM도 거의 사용하지 않았죠. 솔직히 저도 가끔 이런 앱들을 쓰면서 '아, 옛날 앱이 짱이지!' 하고 감탄할 때가 많아요. 구형 컴퓨터에서도 전혀 버벅거림 없이 잘 돌아가는 걸 보면, 정말이지 최적화의 극치를 보여줬다고 생각합니다.</p>\n<div style=\"background-color: #e3f2fd; border-left: 4px solid #0f4c81; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>네이티브 앱이란?</b> 운영체제 고유의 프레임워크를 사용하여 개발되어, OS의 기능과 자원을 가장 효율적으로 활용하는 애플리케이션을 의미합니다. 마치 그 운영체제만을 위해 태어난 것처럼, OS와 완벽하게 조화를 이루는 것이 특징이죠.</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #0f4c81, #002f6c); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  웹 기술 만능주의, 개발자들의 선택 'Electron'</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">그런데 어느 순간부터 '네이티브 앱'이라는 단어는 점점 희미해지기 시작했습니다. 그 자리를 채운 것은 다름 아닌 웹 기술을 기반으로 한 앱들이었죠. 특히 Electron이나 PWA(Progressive Web Apps) 같은 기술들이 대세로 떠오르면서, 개발자들은 윈도우, macOS, 리눅스 등 각기 다른 운영체제별로 앱을 따로 만들 필요가 없어졌습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이게 왜 그렇게 매력적이었냐면, 한 번 HTML, CSS, JavaScript로 웹 앱을 만들면 Electron이 이 웹 앱을 마치 데스크톱 애플리케이션처럼 실행시켜 주기 때문이에요. Electron은 Chromium 브라우저 엔진과 Node.js 런타임을 통째로 앱에 포함시키는 방식인데, 덕분에 개발자들은 하나의 코드베이스만 관리하면 됩니다. 개발팀에 웹 개발자만 있어도 모든 플랫폼용 앱을 만들 수 있게 된 거죠. 반복 작업도 줄어들고, UI 변경도 훨씬 쉽습니다. 기존에 수많은 웹 라이브러리가 있다는 것도 엄청난 장점이고요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이런 장점들 덕분에 Slack, Discord, Figma의 데스크톱 클라이언트, Obsidian, Notion, 그리고 최근의 WhatsApp까지, 수많은 유명 앱들이 Electron이나 유사한 웹 기술을 택했습니다. 개발자 입장에서는 더할 나위 없이 편리한 선택지였던 거죠. 제 생각엔 이 흐름을 거스를 수 없었을 것 같아요. 그런데 말입니다, 개발자의 이런 편리함이 과연 사용자에게도 좋은 방향이었을까요?</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/xzLDp/dJMcahQvCSH/91QeSVgMBxHhVbBW9lSH2K/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/xzLDp/dJMcahQvCSH/91QeSVgMBxHhVbBW9lSH2K/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/xzLDp/dJMcahQvCSH/91QeSVgMBxHhVbBW9lSH2K/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FxzLDp%2FdJMcahQvCSH%2F91QeSVgMBxHhVbBW9lSH2K%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"개발자의 효율적인 웹 기술 사용과 그로 인해 고통받는 사용자의 모습을 대비하여 보여주는 이미지.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #0f4c81, #002f6c); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  사용자가 지불하는 '성능 세금': 앱이 무거워지는 이유</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">아쉽게도, 개발자 편의성의 대가는 고스란히 사용자에게 '성능 세금'으로 부과되었습니다. Electron 앱은 기본적으로 자기만의 브라우저를 통째로 품고 있습니다. 여러 Electron 앱을 동시에 실행하면, 마치 여러 개의 크롬 브라우저를 띄워 놓은 것처럼 수많은 Chromium 인스턴스가 여러분의 PC 메모리를 점령하게 됩니다. 제가 겪어본 바로는, 한두 개만 켜도 RAM 사용량이 확 오르더라고요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">고성능 PC를 사용한다면 체감하기 어려울 수도 있지만, 보급형 노트북이나 오래된 컴퓨터에서는 그야말로 끔찍한 성능 저하를 경험하게 됩니다. 앱 실행 속도는 현저히 느려지고, UI 요소들이 네이티브 앱처럼 부드럽게 작동하지 않거나 시스템 테마와 동떨어지는 경우도 흔합니다. 키보드 단축키도 제멋대로인 경우가 있고요. 게다가 이렇게 여러 브라우저가 메모리에 상주하고 있으면 노트북 배터리 수명에도 치명적일 수밖에 없습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">물론 모든 Electron 앱이 나쁘다는 건 아닙니다. 대표적인 예시가 바로 Visual Studio Code(VS Code)죠. VS Code는 Electron 기반임에도 불구하고 뛰어난 성능과 놀라운 최적화를 보여주는, 최고의 코드 편집기 중 하나입니다. 이 사례를 보면 Electron 자체가 문제가 아니라, 개발 과정에서 <b>최적화에 대한 '관심'과 '노력'이 줄어들기 쉬운 환경이 조성되었다</b>는 점이 더 큰 문제라고 생각해요. 편리함 뒤에 숨겨진 책임감의 부재랄까요?</p>\n<div style=\"background-color: #ffebee; border-left: 4px solid #d32f2f; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">⚠️ <b>주의!</b> 저사양 PC나 오래된 노트북 사용자라면 웹 기반 앱의 성능 저하를 더욱 크게 체감할 수 있습니다. 수많은 백그라운드 프로세스가 시스템 리소스를 잠식하고, 이는 느려진 반응 속도와 급격한 배터리 소모로 이어질 수 있어요.</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #0f4c81, #002f6c); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  마이크로소프트도 이 변화를 부추기고 있나?</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이런 흐름에 마이크로소프트 역시 크게 제동을 걸지 않았다는 점도 주목할 만합니다. 아니, 어쩌면 마이크로소프트 자체가 이러한 변화를 은연중에 부추기고 있는지도 모릅니다. Edge 브라우저의 엔진을 앱에 내장할 수 있는 WebView2 같은 기술을 제공하고 있고, 마이크로소프트 스토어에는 이미 웹 기반 Electron 앱들이 차고 넘치죠. 심지어 마이크로소프트의 자체 제품인 Teams나 Office의 일부 요소들도 웹 기술에 크게 의존하고 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">엎친 데 덮친 격으로, 전통적인 윈도우 UI 프레임워크들은 시간이 갈수록 파편화되고 혼란스러워지고 있습니다. Win32, WPF, UWP, WinUI 3, 그리고 MAUI까지, 끊임없이 새로운 프레임워크가 등장하고 바뀌면서 소규모 개발자들이나 인디 개발자들이 윈도우 전용 코드베이스를 유지하는 것이 거의 불가능에 가까워졌어요. '내가 이미 React를 아는데, 굳이 XAML과 씨름할 필요가 있을까?' 하고 생각하는 게 어쩌면 당연한 일입니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">게다가 스토어에서 Electron 앱도 잘 받아주는데, 굳이 고생해서 네이티브 도구를 만들 이유가 없어지는 거죠. 과거 네이티브 윈도우 앱들은 셸 확장, 전역 단축키, 파일 연결, 드래그 앤 드롭, 알림 시스템, 심지어 작업 표시줄 통합 같은 시스템 기능들과 정말 유기적으로 연결되어 있었습니다. 이런 섬세한 통합성은 점점 더 획일화되는 웹 UI에서는 재현하기 어렵습니다. 잘 만들어진 네이티브 앱과 웹 기반 앱을 비교해 보면, 특히 저사양 하드웨어에서는 성능 차이가 극명하게 드러나는 걸 알 수 있어요.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/Yb7Lh/dJMcah32BUP/ufjHQcjmWYgcEKVsbzyIGk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/Yb7Lh/dJMcah32BUP/ufjHQcjmWYgcEKVsbzyIGk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/Yb7Lh/dJMcah32BUP/ufjHQcjmWYgcEKVsbzyIGk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FYb7Lh%2FdJMcah32BUP%2FufjHQcjmWYgcEKVsbzyIGk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"복잡하게 얽힌 윈도우 UI 프레임워크와 단순하고 깔끔한 웹 개발 스택을 대조하여 보여주는 시각적 은유.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #0f4c81, #002f6c); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  그럼에도 불구하고, '진정한' 네이티브 앱은 살아있다!</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">그럼에도 불구하고, 다행히도 여전히 훌륭한 네이티브 윈도우 앱들이 꾸준히 개발되고 유지되고 있습니다. Everything Search, ShareX, AutoHotKey, EarTrumpet 같은 도구들은 현대적인 네이티브 소프트웨어도 얼마든지 빠르고, 특정 기능에 집중하며, 운영체제에 완벽하게 통합될 수 있다는 살아있는 증거죠. 저도 이런 앱들을 써볼 때마다 '아, 이게 진짜 윈도우 앱이지!' 하고 무릎을 탁 치곤 합니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이런 앱들은 불필요한 기능 없이 핵심적인 역할에 충실하며, 시스템 리소스를 최소한으로 사용합니다. 덕분에 아무리 오래된 PC에서도 쾌적하게 작동하죠. 이들이 보여주는 성능과 완성도는 웹 기반 앱들이 쉽게 따라올 수 없는, 네이티브 앱만의 고유한 강점이라고 생각합니다. 여전히 이런 노력을 기울이는 개발자분들께 정말 감사드리고 싶어요.</p>\n<div style=\"background-color: #f0f4f8; border: 1px solid #b0bec5; border-radius: 8px; padding: 25px; margin: 30px 0; box-shadow: 0 4px 12px rgba(0,0,0,0.1);\">\n<div style=\"font-size: 26px; color: #0f4c81; font-weight: bold; margin-bottom: 15px; padding-bottom: 10px; border-bottom: 2px solid #0f4c81;\">  핵심 요약</div>\n<p style=\"font-size: 17px; margin-bottom: 15px;\" data-ke-size=\"size16\"><b>1. 과거의 네이티브 앱은 OS와 긴밀히 연동되어 놀라운 성능과 효율을 자랑했습니다.</b></p>\n<p style=\"font-size: 17px; margin-bottom: 15px;\" data-ke-size=\"size16\"><b>2. Electron 등 웹 기술은 개발자에게 막대한 편의성을 주었지만, 사용자는 무거운 앱으로 인한 성능 저하를 감수하게 되었습니다.</b></p>\n<p style=\"font-size: 17px; margin-bottom: 15px;\" data-ke-size=\"size16\"><b>3. 마이크로소프트의 정책과 파편화된 프레임워크 역시 웹 기반 앱 확산에 영향을 미쳤습니다.</b></p>\n<p style=\"font-size: 17px;\" data-ke-size=\"size16\"><b>4. 여전히 훌륭한 네이티브 앱들이 존재하며, 사용자 인식 변화와 개발자의 노력으로 네이티브 앱의 가치가 재조명될 수 있습니다.</b></p>\n<div style=\"font-size: 14px; color: #77aaff; margin-top: 20px; padding-top: 15px; border-top: 1px dashed #b0bec5;\"><i>결국, 기술 발전의 편리함과 사용자 경험 사이의 균형을 찾는 것이 중요합니다.</i></div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #0f4c81, #002f6c); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q: Electron 앱이 정말 그렇게 나쁜가요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A: Electron 자체는 개발 편의성을 제공하는 훌륭한 도구입니다. 하나의 코드베이스로 여러 플랫폼에 쉽게 배포할 수 있다는 점은 분명한 장점이죠. 하지만 개발자가 최적화에 덜 신경 쓰게 만들 수 있다는 점이 문제입니다. 잘 만들어진 Electron 앱은 훌륭한 성능을 보여주기도 합니다 (예: VS Code).</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q: 네이티브 앱 개발은 왜 점점 줄어드나요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A: 주로 개발 비용과 복잡성 때문입니다. 여러 플랫폼에 맞춰 코드를 따로 작성해야 하고, 윈도우 UI 프레임워크의 파편화도 한몫합니다. 웹 기술은 한 번의 개발로 여러 플랫폼에 대응할 수 있어 경제적인 선택지로 여겨지기 때문입니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q: 일반 사용자가 네이티브 앱과 웹 기반 앱을 어떻게 구분할 수 있나요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A: 일반적으로 네이티브 앱은 시스템 리소스를 적게 사용하고, 빠르게 실행되며, OS 테마나 동작 방식에 더 통합된 느낌을 줍니다. 작업 관리자에서 프로세스 이름을 확인하거나(Chromium 관련 프로세스가 많다면 웹 기반일 확률이 높습니다), 앱의 '정보'에서 사용된 프레임워크를 찾아보는 방법도 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q: 미래에 네이티브 앱이 다시 인기를 얻을 수 있을까요?</b></p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A: 사용자들의 성능과 통합성에 대한 요구가 커지고, 개발자들이 최적화와 OS 통합의 중요성을 다시 인식한다면 충분히 가능성이 있습니다. 마이크로소프트의 정책 변화와 새로운 네이티브 개발 도구의 등장이 큰 영향을 미칠 것입니다. 결국 균형점이 중요하다고 생각합니다.</p>\n</div>\n<script type=\"application/ld+json\">\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"Electron 앱이 정말 그렇게 나쁜가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"Electron 자체는 개발 편의성을 제공하는 훌륭한 도구입니다. 하나의 코드베이스로 여러 플랫폼에 쉽게 배포할 수 있다는 점은 분명한 장점이죠. 하지만 개발자가 최적화에 덜 신경 쓰게 만들 수 있다는 점이 문제입니다. 잘 만들어진 Electron 앱은 훌륭한 성능을 보여주기도 합니다 (예: VS Code).\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"네이티브 앱 개발은 왜 점점 줄어드나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"주로 개발 비용과 복잡성 때문입니다. 여러 플랫폼에 맞춰 코드를 따로 작성해야 하고, 윈도우 UI 프레임워크의 파편화도 한몫합니다. 웹 기술은 한 번의 개발로 여러 플랫폼에 대응할 수 있어 경제적인 선택지로 여겨지기 때문입니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"일반 사용자가 네이티브 앱과 웹 기반 앱을 어떻게 구분할 수 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"일반적으로 네이티브 앱은 시스템 리소스를 적게 사용하고, 빠르게 실행되며, OS 테마나 동작 방식에 더 통합된 느낌을 줍니다. 작업 관리자에서 프로세스 이름을 확인하거나(Chromium 관련 프로세스가 많다면 웹 기반일 확률이 높습니다), 앱의 '정보'에서 사용된 프레임워크를 찾아보는 방법도 있습니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"미래에 네이티브 앱이 다시 인기를 얻을 수 있을까요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"사용자들의 성능과 통합성에 대한 요구가 커지고, 개발자들이 최적화와 OS 통합의 중요성을 다시 인식한다면 충분히 가능성이 있습니다. 마이크로소프트의 정책 변화와 새로운 네이티브 개발 도구의 등장이 큰 영향을 미칠 것입니다. 결국 균형점이 중요하다고 생각합니다.\"\n      }\n    }\n  ]\n}\n</script>",
        "contentSnippet": "과거의 윈도우 앱들은 놀랍도록 가볍고 빠르게 작동하며 사용자들에게 쾌적한 경험을 선사했습니다. 하지만 현재, 우리는 점점 무거워지고 느려지는 앱들에 익숙해지고 있죠. 개발 편의성이라는 명분 뒤에 숨겨진 사용자 경험의 희생, 그리고 '네이티브 앱'이라는 단어가 잊혀져 가는 현실 속에서 과연 어떤 변화가 있었는지 함께 자세히 살펴보겠습니다.\n\n\n✨ 과거의 영광, '네이티브 앱'은 무엇이었을까?\n윈도우에서 '네이티브 앱'이라고 하면, 그 운영체제 자체의 언어와 프레임워크를 기반으로 만들어진 애플리케이션을 의미했어요. Win32, MFC, .NET(WPF, WinForms) 같은 기술들, 그리고 좀 더 최근에는 UWP(Universal Windows Platform)나 WinUI 같은 것들이 대표적이죠. 이 앱들은 운영체제의 '모국어'를 구사하기 때문에 시스템 자원을 가장 효율적으로 사용하고, OS의 디자인 가이드라인이나 사용자 경험(UX)을 충실히 따랐습니다.\n그래서 과거의 많은 윈도우 앱들은 정말이지 상상할 수 없을 정도로 빠르고 가벼웠습니다. Notepad++, Winamp, Paint.NET, foobar2000, Everything Search 같은 이름들을 들어보시면 아마 고개를 끄덕이실 거예요. 용량도 몇 MB에 불과한데, 실행은 눈 깜짝할 사이에 되고, RAM도 거의 사용하지 않았죠. 솔직히 저도 가끔 이런 앱들을 쓰면서 '아, 옛날 앱이 짱이지!' 하고 감탄할 때가 많아요. 구형 컴퓨터에서도 전혀 버벅거림 없이 잘 돌아가는 걸 보면, 정말이지 최적화의 극치를 보여줬다고 생각합니다.\n  네이티브 앱이란? 운영체제 고유의 프레임워크를 사용하여 개발되어, OS의 기능과 자원을 가장 효율적으로 활용하는 애플리케이션을 의미합니다. 마치 그 운영체제만을 위해 태어난 것처럼, OS와 완벽하게 조화를 이루는 것이 특징이죠.\n  웹 기술 만능주의, 개발자들의 선택 'Electron'\n그런데 어느 순간부터 '네이티브 앱'이라는 단어는 점점 희미해지기 시작했습니다. 그 자리를 채운 것은 다름 아닌 웹 기술을 기반으로 한 앱들이었죠. 특히 Electron이나 PWA(Progressive Web Apps) 같은 기술들이 대세로 떠오르면서, 개발자들은 윈도우, macOS, 리눅스 등 각기 다른 운영체제별로 앱을 따로 만들 필요가 없어졌습니다.\n이게 왜 그렇게 매력적이었냐면, 한 번 HTML, CSS, JavaScript로 웹 앱을 만들면 Electron이 이 웹 앱을 마치 데스크톱 애플리케이션처럼 실행시켜 주기 때문이에요. Electron은 Chromium 브라우저 엔진과 Node.js 런타임을 통째로 앱에 포함시키는 방식인데, 덕분에 개발자들은 하나의 코드베이스만 관리하면 됩니다. 개발팀에 웹 개발자만 있어도 모든 플랫폼용 앱을 만들 수 있게 된 거죠. 반복 작업도 줄어들고, UI 변경도 훨씬 쉽습니다. 기존에 수많은 웹 라이브러리가 있다는 것도 엄청난 장점이고요.\n이런 장점들 덕분에 Slack, Discord, Figma의 데스크톱 클라이언트, Obsidian, Notion, 그리고 최근의 WhatsApp까지, 수많은 유명 앱들이 Electron이나 유사한 웹 기술을 택했습니다. 개발자 입장에서는 더할 나위 없이 편리한 선택지였던 거죠. 제 생각엔 이 흐름을 거스를 수 없었을 것 같아요. 그런데 말입니다, 개발자의 이런 편리함이 과연 사용자에게도 좋은 방향이었을까요?\n\n\n  사용자가 지불하는 '성능 세금': 앱이 무거워지는 이유\n아쉽게도, 개발자 편의성의 대가는 고스란히 사용자에게 '성능 세금'으로 부과되었습니다. Electron 앱은 기본적으로 자기만의 브라우저를 통째로 품고 있습니다. 여러 Electron 앱을 동시에 실행하면, 마치 여러 개의 크롬 브라우저를 띄워 놓은 것처럼 수많은 Chromium 인스턴스가 여러분의 PC 메모리를 점령하게 됩니다. 제가 겪어본 바로는, 한두 개만 켜도 RAM 사용량이 확 오르더라고요.\n고성능 PC를 사용한다면 체감하기 어려울 수도 있지만, 보급형 노트북이나 오래된 컴퓨터에서는 그야말로 끔찍한 성능 저하를 경험하게 됩니다. 앱 실행 속도는 현저히 느려지고, UI 요소들이 네이티브 앱처럼 부드럽게 작동하지 않거나 시스템 테마와 동떨어지는 경우도 흔합니다. 키보드 단축키도 제멋대로인 경우가 있고요. 게다가 이렇게 여러 브라우저가 메모리에 상주하고 있으면 노트북 배터리 수명에도 치명적일 수밖에 없습니다.\n물론 모든 Electron 앱이 나쁘다는 건 아닙니다. 대표적인 예시가 바로 Visual Studio Code(VS Code)죠. VS Code는 Electron 기반임에도 불구하고 뛰어난 성능과 놀라운 최적화를 보여주는, 최고의 코드 편집기 중 하나입니다. 이 사례를 보면 Electron 자체가 문제가 아니라, 개발 과정에서 최적화에 대한 '관심'과 '노력'이 줄어들기 쉬운 환경이 조성되었다는 점이 더 큰 문제라고 생각해요. 편리함 뒤에 숨겨진 책임감의 부재랄까요?\n⚠️ 주의! 저사양 PC나 오래된 노트북 사용자라면 웹 기반 앱의 성능 저하를 더욱 크게 체감할 수 있습니다. 수많은 백그라운드 프로세스가 시스템 리소스를 잠식하고, 이는 느려진 반응 속도와 급격한 배터리 소모로 이어질 수 있어요.\n  마이크로소프트도 이 변화를 부추기고 있나?\n이런 흐름에 마이크로소프트 역시 크게 제동을 걸지 않았다는 점도 주목할 만합니다. 아니, 어쩌면 마이크로소프트 자체가 이러한 변화를 은연중에 부추기고 있는지도 모릅니다. Edge 브라우저의 엔진을 앱에 내장할 수 있는 WebView2 같은 기술을 제공하고 있고, 마이크로소프트 스토어에는 이미 웹 기반 Electron 앱들이 차고 넘치죠. 심지어 마이크로소프트의 자체 제품인 Teams나 Office의 일부 요소들도 웹 기술에 크게 의존하고 있습니다.\n엎친 데 덮친 격으로, 전통적인 윈도우 UI 프레임워크들은 시간이 갈수록 파편화되고 혼란스러워지고 있습니다. Win32, WPF, UWP, WinUI 3, 그리고 MAUI까지, 끊임없이 새로운 프레임워크가 등장하고 바뀌면서 소규모 개발자들이나 인디 개발자들이 윈도우 전용 코드베이스를 유지하는 것이 거의 불가능에 가까워졌어요. '내가 이미 React를 아는데, 굳이 XAML과 씨름할 필요가 있을까?' 하고 생각하는 게 어쩌면 당연한 일입니다.\n게다가 스토어에서 Electron 앱도 잘 받아주는데, 굳이 고생해서 네이티브 도구를 만들 이유가 없어지는 거죠. 과거 네이티브 윈도우 앱들은 셸 확장, 전역 단축키, 파일 연결, 드래그 앤 드롭, 알림 시스템, 심지어 작업 표시줄 통합 같은 시스템 기능들과 정말 유기적으로 연결되어 있었습니다. 이런 섬세한 통합성은 점점 더 획일화되는 웹 UI에서는 재현하기 어렵습니다. 잘 만들어진 네이티브 앱과 웹 기반 앱을 비교해 보면, 특히 저사양 하드웨어에서는 성능 차이가 극명하게 드러나는 걸 알 수 있어요.\n\n\n  그럼에도 불구하고, '진정한' 네이티브 앱은 살아있다!\n그럼에도 불구하고, 다행히도 여전히 훌륭한 네이티브 윈도우 앱들이 꾸준히 개발되고 유지되고 있습니다. Everything Search, ShareX, AutoHotKey, EarTrumpet 같은 도구들은 현대적인 네이티브 소프트웨어도 얼마든지 빠르고, 특정 기능에 집중하며, 운영체제에 완벽하게 통합될 수 있다는 살아있는 증거죠. 저도 이런 앱들을 써볼 때마다 '아, 이게 진짜 윈도우 앱이지!' 하고 무릎을 탁 치곤 합니다.\n이런 앱들은 불필요한 기능 없이 핵심적인 역할에 충실하며, 시스템 리소스를 최소한으로 사용합니다. 덕분에 아무리 오래된 PC에서도 쾌적하게 작동하죠. 이들이 보여주는 성능과 완성도는 웹 기반 앱들이 쉽게 따라올 수 없는, 네이티브 앱만의 고유한 강점이라고 생각합니다. 여전히 이런 노력을 기울이는 개발자분들께 정말 감사드리고 싶어요.\n  핵심 요약\n1. 과거의 네이티브 앱은 OS와 긴밀히 연동되어 놀라운 성능과 효율을 자랑했습니다.\n2. Electron 등 웹 기술은 개발자에게 막대한 편의성을 주었지만, 사용자는 무거운 앱으로 인한 성능 저하를 감수하게 되었습니다.\n3. 마이크로소프트의 정책과 파편화된 프레임워크 역시 웹 기반 앱 확산에 영향을 미쳤습니다.\n4. 여전히 훌륭한 네이티브 앱들이 존재하며, 사용자 인식 변화와 개발자의 노력으로 네이티브 앱의 가치가 재조명될 수 있습니다.\n결국, 기술 발전의 편리함과 사용자 경험 사이의 균형을 찾는 것이 중요합니다.\n❓ 자주 묻는 질문 (FAQ)\nQ: Electron 앱이 정말 그렇게 나쁜가요?\nA: Electron 자체는 개발 편의성을 제공하는 훌륭한 도구입니다. 하나의 코드베이스로 여러 플랫폼에 쉽게 배포할 수 있다는 점은 분명한 장점이죠. 하지만 개발자가 최적화에 덜 신경 쓰게 만들 수 있다는 점이 문제입니다. 잘 만들어진 Electron 앱은 훌륭한 성능을 보여주기도 합니다 (예: VS Code).\nQ: 네이티브 앱 개발은 왜 점점 줄어드나요?\nA: 주로 개발 비용과 복잡성 때문입니다. 여러 플랫폼에 맞춰 코드를 따로 작성해야 하고, 윈도우 UI 프레임워크의 파편화도 한몫합니다. 웹 기술은 한 번의 개발로 여러 플랫폼에 대응할 수 있어 경제적인 선택지로 여겨지기 때문입니다.\nQ: 일반 사용자가 네이티브 앱과 웹 기반 앱을 어떻게 구분할 수 있나요?\nA: 일반적으로 네이티브 앱은 시스템 리소스를 적게 사용하고, 빠르게 실행되며, OS 테마나 동작 방식에 더 통합된 느낌을 줍니다. 작업 관리자에서 프로세스 이름을 확인하거나(Chromium 관련 프로세스가 많다면 웹 기반일 확률이 높습니다), 앱의 '정보'에서 사용된 프레임워크를 찾아보는 방법도 있습니다.\nQ: 미래에 네이티브 앱이 다시 인기를 얻을 수 있을까요?\nA: 사용자들의 성능과 통합성에 대한 요구가 커지고, 개발자들이 최적화와 OS 통합의 중요성을 다시 인식한다면 충분히 가능성이 있습니다. 마이크로소프트의 정책 변화와 새로운 네이티브 개발 도구의 등장이 큰 영향을 미칠 것입니다. 결국 균형점이 중요하다고 생각합니다.\n\n\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"Electron 앱이 정말 그렇게 나쁜가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"Electron 자체는 개발 편의성을 제공하는 훌륭한 도구입니다. 하나의 코드베이스로 여러 플랫폼에 쉽게 배포할 수 있다는 점은 분명한 장점이죠. 하지만 개발자가 최적화에 덜 신경 쓰게 만들 수 있다는 점이 문제입니다. 잘 만들어진 Electron 앱은 훌륭한 성능을 보여주기도 합니다 (예: VS Code).\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"네이티브 앱 개발은 왜 점점 줄어드나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"주로 개발 비용과 복잡성 때문입니다. 여러 플랫폼에 맞춰 코드를 따로 작성해야 하고, 윈도우 UI 프레임워크의 파편화도 한몫합니다. 웹 기술은 한 번의 개발로 여러 플랫폼에 대응할 수 있어 경제적인 선택지로 여겨지기 때문입니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"일반 사용자가 네이티브 앱과 웹 기반 앱을 어떻게 구분할 수 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"일반적으로 네이티브 앱은 시스템 리소스를 적게 사용하고, 빠르게 실행되며, OS 테마나 동작 방식에 더 통합된 느낌을 줍니다. 작업 관리자에서 프로세스 이름을 확인하거나(Chromium 관련 프로세스가 많다면 웹 기반일 확률이 높습니다), 앱의 '정보'에서 사용된 프레임워크를 찾아보는 방법도 있습니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"미래에 네이티브 앱이 다시 인기를 얻을 수 있을까요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"사용자들의 성능과 통합성에 대한 요구가 커지고, 개발자들이 최적화와 OS 통합의 중요성을 다시 인식한다면 충분히 가능성이 있습니다. 마이크로소프트의 정책 변화와 새로운 네이티브 개발 도구의 등장이 큰 영향을 미칠 것입니다. 결국 균형점이 중요하다고 생각합니다.\"\n      }\n    }\n  ]\n}",
        "guid": "https://muzbox.tistory.com/483693",
        "categories": [
          "윈도우 사용팁/윈도우11 사용법",
          "electron",
          "pwa",
          "RAM 사용량",
          "UWP",
          "Win32",
          "네이티브 앱",
          "성능 저하",
          "앱 최적화",
          "웹 앱",
          "윈도우 앱"
        ],
        "isoDate": "2025-12-17T06:17:11.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "(RULIWEB`Д')/",
        "title": "[NS] 룰렛 위 우리네 인생사, 더 게임 오브 라이프 for NS",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2403",
        "pubDate": "Thu, 18 Dec 2025 00:00:00 +0900",
        "author": "(RULIWEB`Д')/",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/25/12/17/19b2caf8d4a4c329e.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2025-12-17T15:00:00.000Z"
      },
      {
        "creator": "｜RULIWEB｜",
        "title": "악역영애 4컷 만화 - 31화, 체육대회인데스와 ①",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2402",
        "pubDate": "Wed, 17 Dec 2025 20:17:54 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/25/12/17/19b2c077a1451ad6b.jpg\">",
        "contentSnippet": "",
        "categories": [
          "웹툰"
        ],
        "isoDate": "2025-12-17T11:17:54.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": [
      {
        "title": "Gemini CLI 사용법 - QnA 게시판 만들기(feat. SpecKit)",
        "link": "https://zzsza.github.io/ai/2025/12/21/gemini-cli-qna-board/",
        "pubDate": "Sun, 21 Dec 2025 00:00:00 +0000",
        "content": "<ul>\n  <li>안녕하세요. 이번 글은 Gemini CLI, SpecKit, Supabase, Vercel을 활용해 QnA 시스템을 구현하는 내용에 대해 작성한 글입니다.</li>\n  <li>Gemini CLI 설정부터 SpecKit을 사용하는 흐름, Supabase 설정 및 UI 개선하는 과정을 담았습니다.</li>\n  <li>키워드 : Gemini CLI 사용법, Gemini CLI with SpecKit, Supabase, Vercel, Gemini Code Assist</li>\n</ul>\n\n<p><br />\n<br /></p>\n\n<hr />\n\n<h1 id=\"gemini-cli\">Gemini CLI</h1>\n<h2 id=\"소개\">소개</h2>\n<ul>\n  <li>Gemini CLI는 Google의 AI 모델(Gemini)을 CLI 환경에서 사용할 수 있게 해주는 개발자 도구</li>\n  <li>최근 터미널 기반의 제품이 많이 나오는데, 직접 사용해보면 생산성이 많이 좋아지는 것을 느낄 수 있음</li>\n  <li>Gemini 모델의 장점 때문에 Gemini CLI를 쓰게 됨\n    <ul>\n      <li>(1) 긴 컨텍스트 : 컨텍스트를 많이 넣을 수 있기 때문에 복잡한 작업, 많은 컨텍스트가 필요할 때 유리</li>\n      <li>(2) 가격 : Gemini 모델의 가격은 다른 모델의 가격 대비 엄청 저렴함(특히 Gemini Flash Lite가 저렴해서 자주 사용함)</li>\n    </ul>\n  </li>\n  <li><a href=\"https://geminicli.com\">공식 문서</a>, <a href=\"https://geminicli.com/docs/\">Docs</a></li>\n</ul>\n\n<h2 id=\"gemini-cli-설치\">Gemini CLI 설치</h2>\n<ul>\n  <li>Gemini CLI는 Node.js 환경에서 동작하므로, 사전에 Node.js가 설치되어 있어야 함\n    <ul>\n      <li>만약 Node가 설치되어 있지 않다면 <a href=\"https://nodejs.org/ko/download\">Node.js</a> 페이지를 확인해서 Node 설치</li>\n    </ul>\n  </li>\n  <li>\n    <p>npm으로 글로벌하게 설치</p>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  npm install -g @google/gemini-cli\n</code></pre></div>    </div>\n  </li>\n</ul>\n\n<h2 id=\"gemini-cli-실행\">Gemini CLI 실행</h2>\n<ul>\n  <li>터미널에서 gemini 입력 후 엔터\n    <ul>\n      <li>만약 첫 실행이면 인증 방식을 선택하게 됨</li>\n      <li>구글 계정 로그인, API Key 방식, 구글 클라우드의 Vertex AI를 통해 인증할 수 있음</li>\n      <li>저는 Gemini를 구독하고 있어서 구글 로그인으로 선택함</li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/52tujotvhezfqfsxp6jcf/2025-12-20-7.06.24.png?rlkey=arf4dlr6oypdzqrnt2rw6l6io&amp;raw=1\" /></p>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">/model</code>을 입력하면 모델을 선택할 수 있음\n    <ul>\n      <li>Pro (gemini-3-pro-preview, gemini-2.5-pro)로 설정</li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/xch5gqp9p8s4p7xe8w62q/2025-12-20-7.17.24.png?rlkey=vwr0crnaefbgl0waixww49ihq&amp;raw=1\" /></p>\n\n<h2 id=\"gemini-cli-주요-명령어\">Gemini CLI 주요 명령어</h2>\n\n<table>\n  <thead>\n    <tr>\n      <th>명령어</th>\n      <th>설명</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td><code class=\"language-plaintext highlighter-rouge\">/help</code></td>\n      <td>사용 가능한 명령어 목록 확인</td>\n    </tr>\n    <tr>\n      <td><code class=\"language-plaintext highlighter-rouge\">/model</code></td>\n      <td>모델 선택 (gemini-3-pro 등)</td>\n    </tr>\n    <tr>\n      <td><code class=\"language-plaintext highlighter-rouge\">/memory show</code></td>\n      <td>현재 로드된 GEMINI.md 내용 확인</td>\n    </tr>\n    <tr>\n      <td><code class=\"language-plaintext highlighter-rouge\">/memory refresh</code></td>\n      <td>GEMINI.md 파일 다시 로드</td>\n    </tr>\n    <tr>\n      <td><code class=\"language-plaintext highlighter-rouge\">/memory add &lt;text&gt;</code></td>\n      <td>메모리에 텍스트 추가</td>\n    </tr>\n    <tr>\n      <td><code class=\"language-plaintext highlighter-rouge\">/chat</code></td>\n      <td>대화 저장/불러오기/공유</td>\n    </tr>\n    <tr>\n      <td><code class=\"language-plaintext highlighter-rouge\">/chat save &lt;tag&gt;</code></td>\n      <td>현재 대화를 태그로 저장</td>\n    </tr>\n    <tr>\n      <td><code class=\"language-plaintext highlighter-rouge\">/chat resume &lt;tag&gt;</code></td>\n      <td>저장된 대화 이어서 진행</td>\n    </tr>\n    <tr>\n      <td><code class=\"language-plaintext highlighter-rouge\">/mcp</code></td>\n      <td>MCP 서버 목록 및 상태 확인</td>\n    </tr>\n    <tr>\n      <td><code class=\"language-plaintext highlighter-rouge\">/tools</code></td>\n      <td>사용 가능한 도구 목록</td>\n    </tr>\n    <tr>\n      <td><code class=\"language-plaintext highlighter-rouge\">/stats</code></td>\n      <td>토큰 사용량, 세션 시간 등 통계</td>\n    </tr>\n    <tr>\n      <td><code class=\"language-plaintext highlighter-rouge\">/restore</code></td>\n      <td>체크포인트로 롤백 (파일 변경 전 상태)</td>\n    </tr>\n    <tr>\n      <td><code class=\"language-plaintext highlighter-rouge\">/clear</code></td>\n      <td>터미널 화면 초기화 (Ctrl+L)</td>\n    </tr>\n    <tr>\n      <td><code class=\"language-plaintext highlighter-rouge\">/compress</code></td>\n      <td>대화 컨텍스트를 요약해서 토큰 절약</td>\n    </tr>\n    <tr>\n      <td><code class=\"language-plaintext highlighter-rouge\">/copy</code></td>\n      <td>마지막 응답을 클립보드에 복사</td>\n    </tr>\n    <tr>\n      <td><code class=\"language-plaintext highlighter-rouge\">/settings</code></td>\n      <td>설정 편집기 열기</td>\n    </tr>\n  </tbody>\n</table>\n\n<ul>\n  <li>stats 입력시 아래와 같이 Session의 통계 정보를 제공함</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/pk6o3zgsr20ldeuzi4t4v/2025-12-21-10.17.18.png?rlkey=3f4bv8of0r7m9fxijj90xff5y&amp;raw=1\" /></p>\n\n<ul>\n  <li><a href=\"https://geminicli.com/extensions/\">Extensions</a>\n    <ul>\n      <li>다양한 Extensions이 존재하며, 설치하고 싶으면 아래와 같이 실행(나노바나나 Extension)</li>\n    </ul>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  gemini extensions install https://github.com/gemini-cli-extensions/nanobanana\n</code></pre></div>    </div>\n  </li>\n</ul>\n\n<h2 id=\"geminimd-설정\">GEMINI.md 설정</h2>\n<ul>\n  <li>GEMINI.md는 Gemini CLI에게 프로젝트 Context와 작업 규칙(Rules)을 알려주는 설정 파일\n    <ul>\n      <li>이 파일에 작성한 내용은 모든 대화에서 시스템 프롬프트처럼 적용됨</li>\n    </ul>\n  </li>\n  <li>Gemini CLI는 여러 위치의 GEMINI.md를 자동으로 찾아서 합쳐줌\n    <ul>\n      <li>아래 순서대로 로드되며, 모든 파일의 내용이 합쳐짐. 같은 항목에 대해 충돌이 있으면 하위 파일이 우선 적용됨(프로젝트가 글로벌보다 더 우선 적용)</li>\n    </ul>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  # 1) 글로벌(모든 프로젝트 공통) : 공통 규칙, 한국어 사용 등\n  ~/.gemini/GEMINI.md      \n\t\n  # 2) 프로젝트 루트 : 기술 스택, 구조 위주\n  /project-root/GEMINI.md \n\t\n  # 3) 하위 디렉토리(해당 폴더에서 작업할 경우)\n  /project-root/src/GEMINI.md\n</code></pre></div>    </div>\n  </li>\n  <li>현재 로드된 컨텍스트는 <code class=\"language-plaintext highlighter-rouge\">/memory show</code> 명령어로 확인할 수 있으며, CLI 하단에 로드된 파일 개수가 표시됨</li>\n  <li>GEMINI.md에 자주 들어가는 내용\n    <ul>\n      <li>기술 스택 : Python 3.13</li>\n      <li>코딩 컨벤션 : 네이밍 컨벤션</li>\n      <li>프로젝트 구조 : 폴더 설명</li>\n      <li>에러 처리 방식, API 호출 패턴</li>\n      <li>금지 사항 : 특정 라이브러리 사용 금지</li>\n      <li>참고 문서 : @로 외부 파일 import 가능</li>\n    </ul>\n  </li>\n  <li>\n    <p>다른 파일을 Import해서 불러오고 싶을 때는 @을 사용함. 프로젝트 문서나 스타일 가이드를 분리해서 관리할 때 유용함</p>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  # GEMINI.md \n\t\n  ## Project Context \n  @docs/architecture.md \n  @docs/api-spec.md \n</code></pre></div>    </div>\n  </li>\n  <li>GEMINI.md를 수정했으면 <code class=\"language-plaintext highlighter-rouge\">/memory refresh</code>로 반영해야 함</li>\n  <li>컨텍스트가 길다고 좋은 것은 아니므로 이 파일도 계속 관리해야 함</li>\n</ul>\n\n<p><br />\n<br /></p>\n\n<hr />\n\n<h1 id=\"speckit을-활용한-sdd-개발\">SpecKit을 활용한 SDD 개발</h1>\n<h2 id=\"소개-1\">소개</h2>\n<ul>\n  <li>SpecKit은 GitHub에서 만든 오픈소스로 SDD(Spec Driven Development) 도구\n    <ul>\n      <li>AI 코딩 에이전트(Gemini CLI, Claude Code 등)와 함께 사용하도록 설계됨</li>\n    </ul>\n  </li>\n  <li>만들어진 계기\n    <ul>\n      <li>AI에게 그냥 A 만들어줘라고 하면 의도와 다르게 나오거나 아키텍처가 엉망인 경우가 많음. 이 문제를 해결하기 위해 SpecKit은 코드 작성 전에 Spec을 정의하고 이를 기반으로 AI가 구현하도록 유도함</li>\n    </ul>\n  </li>\n  <li>이 Spec을 사람이 리뷰하면 되고, 리뷰하는 과정도 이 도구 사용법 안에 자연스레 존재함\n    <ul>\n      <li>코드보다 이 Spec을 더 잘 관리하고, 잘 작성하는 것이 중요하다는 의견이 있는데, 저도 동의함. 기본적인 문서 작성이 더 중요해지는 시기</li>\n    </ul>\n  </li>\n  <li>Workflow 흐름\n    <ul>\n      <li>크게 6단계로 설명할 수 있음</li>\n      <li>(1) Specify : 기능 요구사항 정의(기술 스택이 아닌 무엇을 만들지)</li>\n      <li>(2) Clarify : 애매한 부분, 의사결정이 필요한 부분을 질문하며 구체화</li>\n      <li>(3) Plan : 기술 스택, 아키텍처 등 계획을 세움</li>\n      <li>(4) Tasks : Plan을 기반으로 구현할 Task 생성</li>\n      <li>(5) Analyze : Spec과 Task의 일관성 검증</li>\n      <li>(6) Implement : Task 기반으로 코드 구현</li>\n    </ul>\n  </li>\n</ul>\n\n<h2 id=\"speckit-설치하기\">SpecKit 설치하기</h2>\n<ul>\n  <li>\n    <p>Python의 uv 설치</p>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre></div>    </div>\n  </li>\n  <li>\n    <p>SpecKit 글로벌 설치</p>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  uv tool install specify-cli --from git+https://github.com/github/spec-kit.git\n</code></pre></div>    </div>\n  </li>\n</ul>\n\n<h2 id=\"speckit-프로젝트-설정\">SpecKit 프로젝트 설정</h2>\n<ul>\n  <li>\n    <p>SpecKit 프로젝트 초기 설정</p>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  specify init ask-kyleschool --ai gemini\n</code></pre></div>    </div>\n  </li>\n  <li>\n    <p>만약 이미 폴더가 생성되어 있고, 현재 폴더에서 설정하고 싶은 경우</p>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  cd existing-project \n  specify init . --ai gemini\n</code></pre></div>    </div>\n  </li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/c4xmutjvqgird6x4ys9ni/2025-12-20-7.27.36.png?rlkey=u9hbbuz2hetsqomjmfcemwxp3&amp;raw=1\" /></p>\n\n<ul>\n  <li>이제 <code class=\"language-plaintext highlighter-rouge\">.gemini</code> 폴더와 <code class=\"language-plaintext highlighter-rouge\">.specify</code> 폴더를 보면 SpecKit 관련 파일들이 생성된 것을 볼 수 있음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/040uryl07axggaku168z2/2025-12-20-7.35.35.png?rlkey=ikshp4h92ooot8lwhonca930c&amp;raw=1\" /></p>\n\n<ul>\n  <li>Gemini CLI에서도 커맨드가 보임</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/1sme9m22545wqxxh1rbwd/2025-12-20-7.43.19.png?rlkey=b8sc1iwrq1dlzn3m3lp0uuk8w&amp;raw=1\" /></p>\n\n<h2 id=\"speckit을-활용한-개발\">SpecKit을 활용한 개발</h2>\n<ul>\n  <li>위에서 소개한 6단계를 실제로 진행</li>\n</ul>\n\n<table>\n  <thead>\n    <tr>\n      <th>단계</th>\n      <th>명령어</th>\n      <th>설명</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1. Specify</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">/speckit.specify</code></td>\n      <td>기능 요구사항 정의</td>\n    </tr>\n    <tr>\n      <td>2. Clarify</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">/speckit.clarify</code></td>\n      <td>애매한 부분 구체화</td>\n    </tr>\n    <tr>\n      <td>3. Plan</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">/speckit.plan</code></td>\n      <td>기술 스택, 아키텍처 계획</td>\n    </tr>\n    <tr>\n      <td>4. Tasks</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">/speckit.tasks</code></td>\n      <td>구현할 태스크 생성</td>\n    </tr>\n    <tr>\n      <td>5. Analyze</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">/speckit.analyze</code></td>\n      <td>Spec-Task 일관성 검증</td>\n    </tr>\n    <tr>\n      <td>6. Implement</td>\n      <td><code class=\"language-plaintext highlighter-rouge\">/speckit.implement</code></td>\n      <td>코드 구현</td>\n    </tr>\n  </tbody>\n</table>\n\n<h3 id=\"specify로-요구사항-구체화\">Specify로 요구사항 구체화</h3>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>/speckit.specify \"SQL 강의를 진행하는데, 학생들이 자유롭게 질문을 남기면 AI가 자동으로 답변을 남겨주는 플랫폼을  만들고 싶어.\"\n</code></pre></div></div>\n\n<ul>\n  <li>조금 시간이 지나면 Branch, Spec이 완성됨\n    <ul>\n      <li>여기서 디자인적 요소는 제외하고 기능 구현에 집중함</li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/bel28dmnth7a8lmxce7rj/2025-12-20-7.54.29.png?rlkey=evpd3nhysemy6ofm1vccsxg98&amp;raw=1\" /></p>\n\n<h3 id=\"clarify를-통해-구체화\">Clarify를 통해 구체화</h3>\n<ul>\n  <li>이제 clarify를 입력해서 애매한 부분에 대해 구체화를 진행</li>\n</ul>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>/speckit.clarify\n</code></pre></div></div>\n\n<ul>\n  <li>아래 화면처럼 질문들이 나타나고, 답변하면 됨</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/l6zm6a81t1j4bzdeo7vm9/2025-12-20-7.56.18.png?rlkey=ur1ej7l31b8pu6k5bvawu8xt2&amp;raw=1\" /></p>\n\n<ul>\n  <li>“Short. supabase를 사용하고 Social Login을 진행해”라고 답변함</li>\n  <li>이번엔 모델 질문</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/hb3abj0dxef3ixnppxg1x/2025-12-20-7.58.33.png?rlkey=hnle3b1mi4xty4cez7uc1pdgc&amp;raw=1\" /></p>\n\n<ul>\n  <li>Gemini 2.5 Flash Lite를 사용하라고 답하고, 다른 질문들도 답변하고 이제 모두 Clarify 됨</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/7lzdd6c5us5vnveogsimi/2025-12-20-8.03.14.png?rlkey=3derhohnhgyx7zgxswguuv4km&amp;raw=1\" /></p>\n\n<h3 id=\"plan--계획-생성\">Plan : 계획 생성</h3>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>/speckit.plan\n</code></pre></div></div>\n\n<ul>\n  <li>plan이 모두 세워짐</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/oth790axlu7pchc54tnlh/2025-12-20-8.06.02.png?rlkey=i8mnrbnv9n1im57delgf8687v&amp;raw=1\" /></p>\n\n<h3 id=\"tasks--task-생성\">Tasks : Task 생성</h3>\n<ul>\n  <li>이제 tasks 실행</li>\n</ul>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>/speckit.tasks\n</code></pre></div></div>\n\n<ul>\n  <li>이제 tasks 생성 완료</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/2dhtfh9fjssot4cengtmt/2025-12-20-8.08.38.png?rlkey=mocg9iiu6xmv7bgf0xsylmfp3&amp;raw=1\" /></p>\n\n<ul>\n  <li>생성된 tasks를 확인해보니 다음과 같음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/nd390vr77s8ffjepov00d/2025-12-20-8.09.23.png?rlkey=ah7l2pdovboq6dceu5ueraldg&amp;raw=1\" /></p>\n\n<h3 id=\"analyze--spec과-task의-일관성-검증\">Analyze : Spec과 Task의 일관성 검증</h3>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>/speckit.analyze\n</code></pre></div></div>\n\n<ul>\n  <li>SpecKit이 분석(analyze) 도중 Critical 이슈를 감지하면, 사용자에게 해결 방향을 물어봄</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/sekmscgfg0rvt1naygl2j/2025-12-20-8.13.43.png?rlkey=qzmij0vys3xso8dsz6ssu833b&amp;raw=1\" /></p>\n\n<ul>\n  <li>Critical 이슈를 해결하기 위해 Tasks.md 수정하라고 지시함\n    <ul>\n      <li>Constitution Alignment Issue</li>\n      <li>SpecKit 기본 원칙(constitution)에 “테스트 먼저 작성(Test-First)”이 필수로 되어 있음</li>\n      <li>근데 현재 tasks.md를 보니 테스트 작성 태스크가 없거나 너무 뒤에 있음 (T025/T026이 마지막 폴리싱 단계)</li>\n      <li>요약하면 테스트 먼저 써야 하는데 구현 태스크만 잔뜩 있어서 이슈 제시</li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/jlljrpogqbpcwtphhhav5/2025-12-20-8.14.40.png?rlkey=t83ep2gk646bef2a2hhp4t9np&amp;raw=1\" /></p>\n\n<ul>\n  <li>위와 같이 tasks.md를 수정함\n    <ul>\n      <li>Test tasks 추가 : Phase 3, 4, 5에 테스트 Task 추가 (Test-First 원칙 준수)</li>\n      <li>RLS task 명시 : “같은 강의의 질문만 보이게” 가시성 규칙 명확히 함 (FR-009)</li>\n      <li>Input Sanitization : 보안용 입력값 검증 Task 추가 (T012)</li>\n      <li>Dependencies 업데이트 : 테스트 도구 설치(T002)</li>\n    </ul>\n  </li>\n</ul>\n\n<h3 id=\"implement--코드-구현\">Implement : 코드 구현</h3>\n<ul>\n  <li>이제 코드 구현. 이 작업은 앞선 작업들보다 시간이 더 소요됨</li>\n</ul>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>/speckit.implement\n</code></pre></div></div>\n\n<ul>\n  <li>약 13분 정도 소요됨. 이 시간엔 위에서 작성된 Spec 문서를 다시 확인하거나 인프라 작업을 준비함(DB 등)</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/u8qf54208mpzpij8fraaj/2025-12-20-8.32.08.png?rlkey=6tbjdg0ownpo4k8rkf1dzw899&amp;raw=1\" /></p>\n\n<ul>\n  <li>코드 구현 후, 이제 어떻게 진행하면 좋을지 물어봄(=인프라 작업 등의 안내를 받기 위해)</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/tz7gh2wn6osdqj1den5r7/2025-12-20-8.41.49.png?rlkey=3p8x75g6w6x09tfhxmrpms8fq&amp;raw=1\" /></p>\n\n<p><br />\n<br /></p>\n\n<hr />\n\n<h1 id=\"환경-설정\">환경 설정</h1>\n<ul>\n  <li>앞서 구현한 코드를 실행하기 위해 Supabase 및 Gemini API 설정 진행</li>\n</ul>\n\n<h2 id=\"supabase-설정\">Supabase 설정</h2>\n<ul>\n  <li><a href=\"http://supabase.com/\">Supabase</a> 가입 후 새 프로젝트 생성</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/r0kxbjvptu1ee1ehrf8xq/2025-12-20-8.41.22.png?rlkey=2ftmmne0hel0mkjil1b44zaw7&amp;raw=1\" /></p>\n\n<ul>\n  <li>프로젝트 Settings - API Keys - Legacy anon, service_role API Keys를 누르면 anon_key를 확인할 수 있음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/zz77m60aeitq2k2unb557/2025-12-20-8.44.00.png?rlkey=f2g3n9dld2oifsmb8o2g3855k&amp;raw=1\" /></p>\n\n<ul>\n  <li>Supabase URL은 Settings - Data API - Project URL에서 확인할 수 있음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/02ctci1zz4zbpv69gsh8h/2025-12-20-8.46.51.png?rlkey=my0sob82rjsvmlnl02291f4jt&amp;raw=1\" /></p>\n\n<ul>\n  <li>위 두 키를 <code class=\"language-plaintext highlighter-rouge\">.env.local</code>에 저장함. 이 파일은 <code class=\"language-plaintext highlighter-rouge\">.gitignore</code>에 추가되어야 함(Push 방지)</li>\n</ul>\n\n<h2 id=\"gemini-api-설정\">Gemini API 설정</h2>\n<ul>\n  <li><a href=\"https://aistudio.google.com/\">AI Studio</a>에서 생성할 수 있음</li>\n  <li>홈페이지 접속 후 Get API Key - API 키 만들기 - 이름 설정하면 Key가 저장됨</li>\n  <li>Supabase와 마찬가지로 Gemini API Key를 <code class=\"language-plaintext highlighter-rouge\">.env.local</code>에 저장함</li>\n</ul>\n\n<h2 id=\"supabase---database-생성\">Supabase - Database 생성</h2>\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">supabase/migrations/20251220_init_schema.sql</code>의 내용을 Supabase SQL Editor에서 실행</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/1destdlac0r3ur38g8zco/2025-12-20-8.52.43.png?rlkey=4iwoo0mvpcm664eu73951kh94&amp;raw=1\" /></p>\n\n<ul>\n  <li>이제 필요한 Database가 생성됨</li>\n</ul>\n\n<h2 id=\"소셜-로그인-설정\">소셜 로그인 설정</h2>\n<ul>\n  <li>소셜 로그인 설정을 하기 위해서 구글 클라우드 계정이 필요함\n    <ul>\n      <li>만약 이 과정이 번거로우면 처음엔 소셜 로그인 설정을 추가하지 않아도 무방함. 하지만 서비스로 만들 땐 소셜 로그인을 지원하는 것이 필요함</li>\n    </ul>\n  </li>\n  <li>구글 클라우드 계정을 하나 생성한 후, <a href=\"https://console.cloud.google.com/auth/clients\">Auth</a> 페이지로 이동</li>\n  <li>만약 처음 생성했다면 아무것도 존재하지 않고, 시작하기 버튼을 클릭해야 함</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/sxr1qou6e37lvpww2pocj/2025-12-20-9.03.09.png?rlkey=nzxce8ghmqx204o0h3ptyf1n7&amp;raw=1\" /></p>\n\n<ul>\n  <li>앱 정보를 입력하고 나머지도 순차적으로 입력 후 저장\n    <ul>\n      <li>대상 : 외부</li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/km7spivwm3urynzch8l7n/2025-12-20-9.03.42.png?rlkey=2820bcila674qa069njgczpo3&amp;raw=1\" /></p>\n\n<ul>\n  <li>그 후, 클라이언트를 클릭한 후, 클라이언트 만들기 클릭</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/5prbbw734a1gfg5pio4ci/2025-12-20-9.05.13.png?rlkey=6nz7bjls46yfkewoo5m4u31j2&amp;raw=1\" /></p>\n\n<ul>\n  <li>클라이언트를 만들면 다음과 같이 설정이 저장됨. JSON 다운로드를 해두는 것을 추천(잃어버리지 않도록 주의. 다운로드 폴더에 그대로 두지 않기)</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/l7vmnnj9k0q7jwim7cv38/2025-12-20-9.08.16.png?rlkey=0q0f8wb9cgf0amlk4x6ul8o3a&amp;raw=1\" /></p>\n\n<ul>\n  <li>이제 Supabase로 돌아와서 Authentication - Sign In / Providers - Google을 선택</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/5xgbzgbk8x7is6mym7wp3/2025-12-20-9.10.20.png?rlkey=e7tqzfy2n07nuyl2votemk2lj&amp;raw=1\" /></p>\n\n<ul>\n  <li>Enable Sign in with Google을 설정하고 위에서 만든 클라이언트 id와 클라이언트 secret 값을 붙여넣기\n    <ul>\n      <li>하단에 있는 Callback URL 값은 이후에 사용할 예정이므로 복사 클릭</li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/1c1mka245c6230i0tsxz9/2025-12-20-9.11.15.png?rlkey=n0nnhsys2d9h0p3ouzk1yy1nt&amp;raw=1\" /></p>\n\n<ul>\n  <li>다시 구글 클라우드의 Client쪽에 다음과 같이 추가\n    <ul>\n      <li>승인된 JavaScript 원본 : 실행시킬 URL 입력. 지금은 배포하지 않고 제 로컬에서 실행할 예정이라 localhost:3000만 추가함\n        <ul>\n          <li>나중에 배포하면 배포한 URL 웹페이지를 입력하면 됨</li>\n        </ul>\n      </li>\n      <li>승인된 리디렉션 URI : 위에 Google 로그인에서 복사한 Callback URL 입력</li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/pcou1i9gsszbmqyr6yznq/2025-12-20-9.15.50.png?rlkey=ybxv19ve1manslitqeas2hhev&amp;raw=1\" /></p>\n\n<p><br />\n<br /></p>\n\n<hr />\n\n<h1 id=\"개발-결과-확인\">개발 결과 확인</h1>\n<ul>\n  <li>이제 인프라 설정이 완료되었으므로, 터미널에서 아래 명령어 실행해서 개발 결과 확인</li>\n</ul>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>npm run dev\n</code></pre></div></div>\n\n<ul>\n  <li>localhost:3000으로 접속하면 다음과 같이 뜸</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/6xcblzkudtx7l6p2n9igu/2025-12-20-9.21.07.png?rlkey=p4bennkf8z4a64vad4gf7w144&amp;raw=1\" /></p>\n\n<ul>\n  <li>구글로 로그인을 시도하니 정상적으로 로그인 완료</li>\n  <li>로그인 후 닉네임 설정을 하게 됨</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/aoaah32ddnr6pueebba9m/2025-12-20-9.22.53.png?rlkey=ys7a9xstk4sht2kgwpz7kq1t9&amp;raw=1\" /></p>\n\n<ul>\n  <li>강의 페이지로 이동</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/niwwzanhxh5zaitt2ahm2/2025-12-20-9.25.57.png?rlkey=lzfhx7ln6tpzkdke8ewxbrkrs&amp;raw=1\" /></p>\n\n<ul>\n  <li>‘BigQuery 쿼리를 실행하기 위한 기본적인 쿼리 구성 요소를 알려주세요’라고 질문함</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/wscdje73mfvhgfhqyztl8/2025-12-20-9.29.39.png?rlkey=dwtuv02ydu5xm4g0nm797bl7a&amp;raw=1\" /></p>\n\n<ul>\n  <li>그 결과 질문이 올라옴</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/x4cx9e3wtgy3bhe77o7bf/2025-12-20-9.31.09.png?rlkey=gqlplwzg7zm0cgiz3dfcepyle&amp;raw=1\" /></p>\n\n<ul>\n  <li>답변은 다음과 같이 달림. 단, 마크다운 설정이 필요할 것 같음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/7rdlig8g6fznefow72bvi/2025-12-20-9.39.20.png?rlkey=rmjo7rxye29ruioqn0wtrbmya&amp;raw=1\" /></p>\n\n<ul>\n  <li>만약 실행하는 과정에서 오류가 발생하면 Gemini CLI에게 오류를 보내고 수정하라고 가이드하면 됨. 만약 반복된다면 전체적으로 점검하라고 요청하는 것을 추천</li>\n</ul>\n\n<p><br />\n<br /></p>\n\n<hr />\n\n<h1 id=\"ui-개선\">UI 개선</h1>\n<h2 id=\"새로운-spec을-통해-디자인-개선하기\">새로운 Spec을 통해 디자인 개선하기</h2>\n<ul>\n  <li>기능 구현은 되었고, 디자인을 개선하기 위해 다시 Spec을 작성함</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/dtldzo376rh686m99eczf/2025-12-20-9.43.20.png?rlkey=t28psljx5k0xyhnvu9dvf6xo3&amp;raw=1\" /></p>\n\n<ul>\n  <li>위에서 진행한 것처럼 clarify, plan, tasks, analyze, implement를 실행한 후 기다림\n    <ul>\n      <li>이제 마크다운을 잘 표현하고, 디자인이 살짝 개선됨</li>\n    </ul>\n  </li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/zvqkd4v7kf3ov7yg2zwe1/2025-12-20-11.37.40.png?rlkey=8jub9qz1nhtluvxt3uvqx53c6&amp;raw=1\" /></p>\n\n<h2 id=\"더-자세한-지시를-통해-디자인-개선하기\">더 자세한 지시를 통해 디자인 개선하기</h2>\n<ul>\n  <li>만들어진 디자인이 마음에 들지 않아 어떻게 개선할지 고민하다가, Claude Code의 <a href=\"https://github.com/anthropics/skills/blob/main/skills/frontend-design/SKILL.md\">frontend-design 스킬</a>을 참고해서 개선하라고 지시함</li>\n  <li>\n    <p>GEMINI.md 파일에 아래 내용을 추가함</p>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>  ## Frontend Design\n  - Please refer to @frontend-design.md when implementing frontend designs\n</code></pre></div>    </div>\n  </li>\n  <li>GEMINI.md를 수정한 후, 해당 지시를 기반으로 디자인을 개선하라고 지시함</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/shpxew3apt53bkh75smed/2025-12-20-11.52.33.png?rlkey=44m6qdna8ym797sx3k3hkgvgy&amp;raw=1\" /></p>\n\n<ul>\n  <li>처음 버전보다 더 세련된 느낌. 만약 내가 원하는 방향성이 있다면 디자인 레퍼런스를 구체적으로 줄수록 만족스러운 결과가 나올 수 있음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/kf052kdxalafx9jmec8lt/2025-12-20-11.55.49.png?rlkey=tydo2iodwjqs75oc74zziq7c0&amp;raw=1\" /></p>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/9wv4gx7pi6ucaail86tch/2025-12-20-11.53.10.png?rlkey=1mfizxwmxlff84khx4cxbzo5e&amp;raw=1\" /></p>\n\n<h2 id=\"gemini-cli에게-아이디어-문의\">Gemini CLI에게 아이디어 문의</h2>\n<ul>\n  <li>이제 또 무엇을 하면 좋을지 아이디어를 물어봤더니, 좋은 아이디어를 줬음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/zawgk9gbxk8f95eeoqcpb/2025-12-21-1.00.27.png?rlkey=cg3sm6ey7aeyne28j6ol7fdvh&amp;raw=1\" /></p>\n\n<ul>\n  <li>위 내용을 모두 모아서 하나의 Spec으로 정의해서 구현해달라고 지시함\n    <ul>\n      <li>강의 클릭시 대기 시간에 system_log 형식으로 구현함</li>\n    </ul>\n  </li>\n</ul>\n\n<video width=\"100%\" autoplay=\"\" muted=\"\" playsinline=\"\" controls=\"\">\n  <source src=\"https://www.dropbox.com/scl/fi/qqlq47nc0sk7y1sn5cz52/2025-12-21-1.38.05.mp4?rlkey=xpg4wgixxozprrytzf18yvl47&amp;raw=1\" type=\"video/mp4\" />\n</video>\n\n<p><br />\n<br /></p>\n\n<hr />\n\n<h1 id=\"gemini-code-assist를-활용한-ai-코드-리뷰\">Gemini Code Assist를 활용한 AI 코드 리뷰</h1>\n<ul>\n  <li>이제 GitHub에 Push함. 처음 작업이라 main에 바로 Push했으나, 그 이후엔 브랜치를 새롭게 만들어서 확인하는 것을 추천함</li>\n  <li><a href=\"https://developers.google.com/gemini-code-assist/docs/review-github-code\">Gemini Code Assist</a>를 설치하면 GitHub에서 Pull Request가 발생할 때 코드를 Gemini가 리뷰해줌. 이 설정을 해두는 것을 추천</li>\n</ul>\n\n<h2 id=\"설정\">설정</h2>\n<ul>\n  <li><a href=\"https://github.com/apps/gemini-code-assist\">Gemini Code Assist GitHub App</a> 페이지 이동 -&gt; Configure 클릭</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/vob3uk3qgpnhyhdienpu9/2025-12-21-11.27.53.png?rlkey=jqztkxa4f9nktomzo2fv4piw9&amp;raw=1\" /></p>\n\n<ul>\n  <li>로그인을 완료한 후, 사용할 GitHub Repository를 추가</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/yhmio5ekue30b1u6h7ve4/2025-12-21-11.29.00.png?rlkey=0v4z48hsqfekp7acbla20i37w&amp;raw=1\" /></p>\n\n<h2 id=\"ai-코드-리뷰-결과\">AI 코드 리뷰 결과</h2>\n<ul>\n  <li>이렇게 설정한 후, Pull Request를 하면 아래와 같이 리뷰가 달림(아래 리뷰는 다른 Repo에서 Gemini Code Assist가 리뷰한 내용을 가져옴)</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/3xmvvzdgxr6fs2hnnlu6m/2025-12-21-11.30.24.png?rlkey=eo4jaw5ql1diqx6zg2bkeceyr&amp;raw=1\" /></p>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/g9jodue50blgxokf6o8tk/2025-12-21-11.31.11.png?rlkey=iar7ra5mqm89yapzsb6sg17qt&amp;raw=1\" /></p>\n\n<p><br />\n<br /></p>\n\n<hr />\n\n<h1 id=\"vercel-배포\">Vercel 배포</h1>\n<ul>\n  <li>Supabase와 Vercel이 잘 통합되어 있으므로, Vercel을 통해 배포하는 것을 추천</li>\n  <li>이 부분에 대해 글을 작성할 예정은 아니였지만, 간단하게라도 가이드를 남겨봄</li>\n  <li><a href=\"https://vercel.com/\">Vercel</a> - New Project를 누르면 GitHub에서 Import를 할 수 있음</li>\n</ul>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/pl3w60qrqwxukllanpsx5/2025-12-21-11.33.42.png?rlkey=86vsk4cnv5nkrqifw6sx2l3h7&amp;raw=1\" /></p>\n\n<p><img src=\"https://www.dropbox.com/scl/fi/oq8pndxw0h71i6lyb1cya/2025-12-21-11.34.47.png?rlkey=ancpt65u2yx8jksiayoj75tk2&amp;raw=1\" /></p>\n\n<ul>\n  <li>Supabase URL, Anon Key를 추가하면 어렵지 않게 배포할 수 있음</li>\n  <li>Vercel 배포가 완료되면 새로운 URL이 생성됨. 이 URL을 Google Cloud OAuth(위에 소셜 로그인 부분)에 가서 승인된 JavaScript 원본에 Vercel URL을 추가해야 함</li>\n  <li>그리고 Supabase에서도 URL 설정을 추가해야 함\n    <ul>\n      <li>Supabase &gt; Authentication &gt; URL Configuration에서 Site URL을 Vercel URL로 변경</li>\n    </ul>\n  </li>\n</ul>\n\n<p><br />\n<br /></p>\n\n<hr />\n\n<h1 id=\"후기\">후기</h1>\n<ul>\n  <li>Gemini CLI도 많이 사용하면서 도구에 적응하게 됨. 이런 도구들은 실제로 써보고, 피드백 루프를 돌리는 과정이 필요함</li>\n  <li>Gemini CLI의 <a href=\"https://geminicli.com/docs/changelogs/\">Release Notes</a>를 보면 새로운 기능들이 계속 생기고 있음. 앞으로 계속 더 발전할 것 같음</li>\n  <li>Claude Code와 Gemini CLI 둘 다 사용하게 되었는데, 필요에 맞게 사용할 수 있도록 계속 시도해볼 예정\n    <ul>\n      <li>Gemini CLI가 컨텍스트가 많기 때문에 핵심 AI 에이전트로 쓰고, Gemini CLI에서 Claude Code나 Codex를 실행하게 하는 것도 방법이고, 이미 이런 시도를 하는 분들이 계심</li>\n      <li>AI 에이전트 도구들의 설정을 동일하게 저장해서 (예를 들어 AGENT.md를 만들어서) 관리하는 것이 필요할 듯. 새로운 도구로 이사하는 것이 번거롭게 느껴질 수 있음</li>\n    </ul>\n  </li>\n</ul>\n\n<p><br />\n<br /></p>\n\n<hr />\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>이 글은 GDE 프로그램에서 진행한 AI Sprint에 참여하며 작성한 글입니다.\n\nGoogle Cloud credits are provided for this project. #AISprint\n</code></pre></div></div>\n",
        "contentSnippet": "안녕하세요. 이번 글은 Gemini CLI, SpecKit, Supabase, Vercel을 활용해 QnA 시스템을 구현하는 내용에 대해 작성한 글입니다.\nGemini CLI 설정부터 SpecKit을 사용하는 흐름, Supabase 설정 및 UI 개선하는 과정을 담았습니다.\n키워드 : Gemini CLI 사용법, Gemini CLI with SpecKit, Supabase, Vercel, Gemini Code Assist\n\n\nGemini CLI\n소개\nGemini CLI는 Google의 AI 모델(Gemini)을 CLI 환경에서 사용할 수 있게 해주는 개발자 도구\n최근 터미널 기반의 제품이 많이 나오는데, 직접 사용해보면 생산성이 많이 좋아지는 것을 느낄 수 있음\nGemini 모델의 장점 때문에 Gemini CLI를 쓰게 됨\n    \n(1) 긴 컨텍스트 : 컨텍스트를 많이 넣을 수 있기 때문에 복잡한 작업, 많은 컨텍스트가 필요할 때 유리\n(2) 가격 : Gemini 모델의 가격은 다른 모델의 가격 대비 엄청 저렴함(특히 Gemini Flash Lite가 저렴해서 자주 사용함)\n공식 문서, Docs\nGemini CLI 설치\nGemini CLI는 Node.js 환경에서 동작하므로, 사전에 Node.js가 설치되어 있어야 함\n    \n만약 Node가 설치되어 있지 않다면 Node.js 페이지를 확인해서 Node 설치\nnpm으로 글로벌하게 설치\n\n  npm install -g @google/gemini-cli\n\n    \nGemini CLI 실행\n터미널에서 gemini 입력 후 엔터\n    \n만약 첫 실행이면 인증 방식을 선택하게 됨\n구글 계정 로그인, API Key 방식, 구글 클라우드의 Vertex AI를 통해 인증할 수 있음\n저는 Gemini를 구독하고 있어서 구글 로그인으로 선택함\n\n/model을 입력하면 모델을 선택할 수 있음\n    \nPro (gemini-3-pro-preview, gemini-2.5-pro)로 설정\n\nGemini CLI 주요 명령어\n명령어\n      설명\n    \n/help\n      사용 가능한 명령어 목록 확인\n    \n/model\n      모델 선택 (gemini-3-pro 등)\n    \n/memory show\n      현재 로드된 GEMINI.md 내용 확인\n    \n/memory refresh\n      GEMINI.md 파일 다시 로드\n    \n/memory add <text>\n      메모리에 텍스트 추가\n    \n/chat\n      대화 저장/불러오기/공유\n    \n/chat save <tag>\n      현재 대화를 태그로 저장\n    \n/chat resume <tag>\n      저장된 대화 이어서 진행\n    \n/mcp\n      MCP 서버 목록 및 상태 확인\n    \n/tools\n      사용 가능한 도구 목록\n    \n/stats\n      토큰 사용량, 세션 시간 등 통계\n    \n/restore\n      체크포인트로 롤백 (파일 변경 전 상태)\n    \n/clear\n      터미널 화면 초기화 (Ctrl+L)\n    \n/compress\n      대화 컨텍스트를 요약해서 토큰 절약\n    \n/copy\n      마지막 응답을 클립보드에 복사\n    \n/settings\n      설정 편집기 열기\n    \nstats 입력시 아래와 같이 Session의 통계 정보를 제공함\n\nExtensions\n    \n다양한 Extensions이 존재하며, 설치하고 싶으면 아래와 같이 실행(나노바나나 Extension)\n\n  gemini extensions install https://github.com/gemini-cli-extensions/nanobanana\n\n    \nGEMINI.md 설정\nGEMINI.md는 Gemini CLI에게 프로젝트 Context와 작업 규칙(Rules)을 알려주는 설정 파일\n    \n이 파일에 작성한 내용은 모든 대화에서 시스템 프롬프트처럼 적용됨\nGemini CLI는 여러 위치의 GEMINI.md를 자동으로 찾아서 합쳐줌\n    \n아래 순서대로 로드되며, 모든 파일의 내용이 합쳐짐. 같은 항목에 대해 충돌이 있으면 하위 파일이 우선 적용됨(프로젝트가 글로벌보다 더 우선 적용)\n\n  # 1) 글로벌(모든 프로젝트 공통) : 공통 규칙, 한국어 사용 등\n  ~/.gemini/GEMINI.md      \n\t\n  # 2) 프로젝트 루트 : 기술 스택, 구조 위주\n  /project-root/GEMINI.md \n\t\n  # 3) 하위 디렉토리(해당 폴더에서 작업할 경우)\n  /project-root/src/GEMINI.md\n\n    \n현재 로드된 컨텍스트는 /memory show 명령어로 확인할 수 있으며, CLI 하단에 로드된 파일 개수가 표시됨\nGEMINI.md에 자주 들어가는 내용\n    \n기술 스택 : Python 3.13\n코딩 컨벤션 : 네이밍 컨벤션\n프로젝트 구조 : 폴더 설명\n에러 처리 방식, API 호출 패턴\n금지 사항 : 특정 라이브러리 사용 금지\n참고 문서 : @로 외부 파일 import 가능\n다른 파일을 Import해서 불러오고 싶을 때는 @을 사용함. 프로젝트 문서나 스타일 가이드를 분리해서 관리할 때 유용함\n\n  # GEMINI.md \n\t\n  ## Project Context \n  @docs/architecture.md \n  @docs/api-spec.md \n\n    \nGEMINI.md를 수정했으면 /memory refresh로 반영해야 함\n컨텍스트가 길다고 좋은 것은 아니므로 이 파일도 계속 관리해야 함\n\n\nSpecKit을 활용한 SDD 개발\n소개\nSpecKit은 GitHub에서 만든 오픈소스로 SDD(Spec Driven Development) 도구\n    \nAI 코딩 에이전트(Gemini CLI, Claude Code 등)와 함께 사용하도록 설계됨\n만들어진 계기\n    \nAI에게 그냥 A 만들어줘라고 하면 의도와 다르게 나오거나 아키텍처가 엉망인 경우가 많음. 이 문제를 해결하기 위해 SpecKit은 코드 작성 전에 Spec을 정의하고 이를 기반으로 AI가 구현하도록 유도함\n이 Spec을 사람이 리뷰하면 되고, 리뷰하는 과정도 이 도구 사용법 안에 자연스레 존재함\n    \n코드보다 이 Spec을 더 잘 관리하고, 잘 작성하는 것이 중요하다는 의견이 있는데, 저도 동의함. 기본적인 문서 작성이 더 중요해지는 시기\nWorkflow 흐름\n    \n크게 6단계로 설명할 수 있음\n(1) Specify : 기능 요구사항 정의(기술 스택이 아닌 무엇을 만들지)\n(2) Clarify : 애매한 부분, 의사결정이 필요한 부분을 질문하며 구체화\n(3) Plan : 기술 스택, 아키텍처 등 계획을 세움\n(4) Tasks : Plan을 기반으로 구현할 Task 생성\n(5) Analyze : Spec과 Task의 일관성 검증\n(6) Implement : Task 기반으로 코드 구현\nSpecKit 설치하기\nPython의 uv 설치\n\n  curl -LsSf https://astral.sh/uv/install.sh | sh\n\n    \nSpecKit 글로벌 설치\n\n  uv tool install specify-cli --from git+https://github.com/github/spec-kit.git\n\n    \nSpecKit 프로젝트 설정\nSpecKit 프로젝트 초기 설정\n\n  specify init ask-kyleschool --ai gemini\n\n    \n만약 이미 폴더가 생성되어 있고, 현재 폴더에서 설정하고 싶은 경우\n\n  cd existing-project \n  specify init . --ai gemini\n\n    \n\n이제 .gemini 폴더와 .specify 폴더를 보면 SpecKit 관련 파일들이 생성된 것을 볼 수 있음\n\nGemini CLI에서도 커맨드가 보임\n\nSpecKit을 활용한 개발\n위에서 소개한 6단계를 실제로 진행\n단계\n      명령어\n      설명\n    \n1. Specify\n      /speckit.specify\n      기능 요구사항 정의\n    \n2. Clarify\n      /speckit.clarify\n      애매한 부분 구체화\n    \n3. Plan\n      /speckit.plan\n      기술 스택, 아키텍처 계획\n    \n4. Tasks\n      /speckit.tasks\n      구현할 태스크 생성\n    \n5. Analyze\n      /speckit.analyze\n      Spec-Task 일관성 검증\n    \n6. Implement\n      /speckit.implement\n      코드 구현\n    \nSpecify로 요구사항 구체화\n\n/speckit.specify \"SQL 강의를 진행하는데, 학생들이 자유롭게 질문을 남기면 AI가 자동으로 답변을 남겨주는 플랫폼을  만들고 싶어.\"\n\n\n조금 시간이 지나면 Branch, Spec이 완성됨\n    \n여기서 디자인적 요소는 제외하고 기능 구현에 집중함\n\nClarify를 통해 구체화\n이제 clarify를 입력해서 애매한 부분에 대해 구체화를 진행\n\n/speckit.clarify\n\n\n아래 화면처럼 질문들이 나타나고, 답변하면 됨\n\n“Short. supabase를 사용하고 Social Login을 진행해”라고 답변함\n이번엔 모델 질문\n\nGemini 2.5 Flash Lite를 사용하라고 답하고, 다른 질문들도 답변하고 이제 모두 Clarify 됨\n\nPlan : 계획 생성\n\n/speckit.plan\n\n\nplan이 모두 세워짐\n\nTasks : Task 생성\n이제 tasks 실행\n\n/speckit.tasks\n\n\n이제 tasks 생성 완료\n\n생성된 tasks를 확인해보니 다음과 같음\n\nAnalyze : Spec과 Task의 일관성 검증\n\n/speckit.analyze\n\n\nSpecKit이 분석(analyze) 도중 Critical 이슈를 감지하면, 사용자에게 해결 방향을 물어봄\n\nCritical 이슈를 해결하기 위해 Tasks.md 수정하라고 지시함\n    \nConstitution Alignment Issue\nSpecKit 기본 원칙(constitution)에 “테스트 먼저 작성(Test-First)”이 필수로 되어 있음\n근데 현재 tasks.md를 보니 테스트 작성 태스크가 없거나 너무 뒤에 있음 (T025/T026이 마지막 폴리싱 단계)\n요약하면 테스트 먼저 써야 하는데 구현 태스크만 잔뜩 있어서 이슈 제시\n\n위와 같이 tasks.md를 수정함\n    \nTest tasks 추가 : Phase 3, 4, 5에 테스트 Task 추가 (Test-First 원칙 준수)\nRLS task 명시 : “같은 강의의 질문만 보이게” 가시성 규칙 명확히 함 (FR-009)\nInput Sanitization : 보안용 입력값 검증 Task 추가 (T012)\nDependencies 업데이트 : 테스트 도구 설치(T002)\nImplement : 코드 구현\n이제 코드 구현. 이 작업은 앞선 작업들보다 시간이 더 소요됨\n\n/speckit.implement\n\n\n약 13분 정도 소요됨. 이 시간엔 위에서 작성된 Spec 문서를 다시 확인하거나 인프라 작업을 준비함(DB 등)\n\n코드 구현 후, 이제 어떻게 진행하면 좋을지 물어봄(=인프라 작업 등의 안내를 받기 위해)\n\n\n\n환경 설정\n앞서 구현한 코드를 실행하기 위해 Supabase 및 Gemini API 설정 진행\nSupabase 설정\nSupabase 가입 후 새 프로젝트 생성\n\n프로젝트 Settings - API Keys - Legacy anon, service_role API Keys를 누르면 anon_key를 확인할 수 있음\n\nSupabase URL은 Settings - Data API - Project URL에서 확인할 수 있음\n\n위 두 키를 .env.local에 저장함. 이 파일은 .gitignore에 추가되어야 함(Push 방지)\nGemini API 설정\nAI Studio에서 생성할 수 있음\n홈페이지 접속 후 Get API Key - API 키 만들기 - 이름 설정하면 Key가 저장됨\nSupabase와 마찬가지로 Gemini API Key를 .env.local에 저장함\nSupabase - Database 생성\nsupabase/migrations/20251220_init_schema.sql의 내용을 Supabase SQL Editor에서 실행\n\n이제 필요한 Database가 생성됨\n소셜 로그인 설정\n소셜 로그인 설정을 하기 위해서 구글 클라우드 계정이 필요함\n    \n만약 이 과정이 번거로우면 처음엔 소셜 로그인 설정을 추가하지 않아도 무방함. 하지만 서비스로 만들 땐 소셜 로그인을 지원하는 것이 필요함\n구글 클라우드 계정을 하나 생성한 후, Auth 페이지로 이동\n만약 처음 생성했다면 아무것도 존재하지 않고, 시작하기 버튼을 클릭해야 함\n\n앱 정보를 입력하고 나머지도 순차적으로 입력 후 저장\n    \n대상 : 외부\n\n그 후, 클라이언트를 클릭한 후, 클라이언트 만들기 클릭\n\n클라이언트를 만들면 다음과 같이 설정이 저장됨. JSON 다운로드를 해두는 것을 추천(잃어버리지 않도록 주의. 다운로드 폴더에 그대로 두지 않기)\n\n이제 Supabase로 돌아와서 Authentication - Sign In / Providers - Google을 선택\n\nEnable Sign in with Google을 설정하고 위에서 만든 클라이언트 id와 클라이언트 secret 값을 붙여넣기\n    \n하단에 있는 Callback URL 값은 이후에 사용할 예정이므로 복사 클릭\n\n다시 구글 클라우드의 Client쪽에 다음과 같이 추가\n    \n승인된 JavaScript 원본 : 실행시킬 URL 입력. 지금은 배포하지 않고 제 로컬에서 실행할 예정이라 localhost:3000만 추가함\n        \n나중에 배포하면 배포한 URL 웹페이지를 입력하면 됨\n승인된 리디렉션 URI : 위에 Google 로그인에서 복사한 Callback URL 입력\n\n\n\n개발 결과 확인\n이제 인프라 설정이 완료되었으므로, 터미널에서 아래 명령어 실행해서 개발 결과 확인\n\nnpm run dev\n\n\nlocalhost:3000으로 접속하면 다음과 같이 뜸\n\n구글로 로그인을 시도하니 정상적으로 로그인 완료\n로그인 후 닉네임 설정을 하게 됨\n\n강의 페이지로 이동\n\n‘BigQuery 쿼리를 실행하기 위한 기본적인 쿼리 구성 요소를 알려주세요’라고 질문함\n\n그 결과 질문이 올라옴\n\n답변은 다음과 같이 달림. 단, 마크다운 설정이 필요할 것 같음\n\n만약 실행하는 과정에서 오류가 발생하면 Gemini CLI에게 오류를 보내고 수정하라고 가이드하면 됨. 만약 반복된다면 전체적으로 점검하라고 요청하는 것을 추천\n\n\nUI 개선\n새로운 Spec을 통해 디자인 개선하기\n기능 구현은 되었고, 디자인을 개선하기 위해 다시 Spec을 작성함\n\n위에서 진행한 것처럼 clarify, plan, tasks, analyze, implement를 실행한 후 기다림\n    \n이제 마크다운을 잘 표현하고, 디자인이 살짝 개선됨\n\n더 자세한 지시를 통해 디자인 개선하기\n만들어진 디자인이 마음에 들지 않아 어떻게 개선할지 고민하다가, Claude Code의 frontend-design 스킬을 참고해서 개선하라고 지시함\nGEMINI.md 파일에 아래 내용을 추가함\n\n  ## Frontend Design\n  - Please refer to @frontend-design.md when implementing frontend designs\n\n    \nGEMINI.md를 수정한 후, 해당 지시를 기반으로 디자인을 개선하라고 지시함\n\n처음 버전보다 더 세련된 느낌. 만약 내가 원하는 방향성이 있다면 디자인 레퍼런스를 구체적으로 줄수록 만족스러운 결과가 나올 수 있음\n\n\nGemini CLI에게 아이디어 문의\n이제 또 무엇을 하면 좋을지 아이디어를 물어봤더니, 좋은 아이디어를 줬음\n\n위 내용을 모두 모아서 하나의 Spec으로 정의해서 구현해달라고 지시함\n    \n강의 클릭시 대기 시간에 system_log 형식으로 구현함\n\n\nGemini Code Assist를 활용한 AI 코드 리뷰\n이제 GitHub에 Push함. 처음 작업이라 main에 바로 Push했으나, 그 이후엔 브랜치를 새롭게 만들어서 확인하는 것을 추천함\nGemini Code Assist를 설치하면 GitHub에서 Pull Request가 발생할 때 코드를 Gemini가 리뷰해줌. 이 설정을 해두는 것을 추천\n설정\nGemini Code Assist GitHub App 페이지 이동 -> Configure 클릭\n\n로그인을 완료한 후, 사용할 GitHub Repository를 추가\n\nAI 코드 리뷰 결과\n이렇게 설정한 후, Pull Request를 하면 아래와 같이 리뷰가 달림(아래 리뷰는 다른 Repo에서 Gemini Code Assist가 리뷰한 내용을 가져옴)\n\n\n\n\nVercel 배포\nSupabase와 Vercel이 잘 통합되어 있으므로, Vercel을 통해 배포하는 것을 추천\n이 부분에 대해 글을 작성할 예정은 아니였지만, 간단하게라도 가이드를 남겨봄\nVercel - New Project를 누르면 GitHub에서 Import를 할 수 있음\n\n\nSupabase URL, Anon Key를 추가하면 어렵지 않게 배포할 수 있음\nVercel 배포가 완료되면 새로운 URL이 생성됨. 이 URL을 Google Cloud OAuth(위에 소셜 로그인 부분)에 가서 승인된 JavaScript 원본에 Vercel URL을 추가해야 함\n그리고 Supabase에서도 URL 설정을 추가해야 함\n    \nSupabase > Authentication > URL Configuration에서 Site URL을 Vercel URL로 변경\n\n\n후기\nGemini CLI도 많이 사용하면서 도구에 적응하게 됨. 이런 도구들은 실제로 써보고, 피드백 루프를 돌리는 과정이 필요함\nGemini CLI의 Release Notes를 보면 새로운 기능들이 계속 생기고 있음. 앞으로 계속 더 발전할 것 같음\nClaude Code와 Gemini CLI 둘 다 사용하게 되었는데, 필요에 맞게 사용할 수 있도록 계속 시도해볼 예정\n    \nGemini CLI가 컨텍스트가 많기 때문에 핵심 AI 에이전트로 쓰고, Gemini CLI에서 Claude Code나 Codex를 실행하게 하는 것도 방법이고, 이미 이런 시도를 하는 분들이 계심\nAI 에이전트 도구들의 설정을 동일하게 저장해서 (예를 들어 AGENT.md를 만들어서) 관리하는 것이 필요할 듯. 새로운 도구로 이사하는 것이 번거롭게 느껴질 수 있음\n\n\n\n이 글은 GDE 프로그램에서 진행한 AI Sprint에 참여하며 작성한 글입니다.\n\nGoogle Cloud credits are provided for this project. #AISprint",
        "guid": "https://zzsza.github.io/ai/2025/12/21/gemini-cli-qna-board/",
        "categories": [
          "basic",
          "ai"
        ],
        "isoDate": "2025-12-21T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "유니티로 바이브 코딩 세팅 - 자동 리프레시 끄기는 사람에게는 안좋습니다.",
        "link": "https://serverdown.tistory.com/1550",
        "pubDate": "Thu, 18 Dec 2025 16:58:29 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1550#entry1550comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=fxbJpKBYUE8\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=fxbJpKBYUE8</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=fxbJpKBYUE8\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/obvkS/hyZOO7bWes/b3GTUAe0wOWcCn3zNZlmA1/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360,https://scrap.kakaocdn.net/dn/tOEbU/hyZP8pbOVO/YSlje5Y1sQpeG4UDVOqF4K/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360,https://scrap.kakaocdn.net/dn/cua6El/hyZPrKHHS9/LBwwEPJLwkKGeYockkObQ0/img.jpg?width=480&amp;height=360&amp;face=0_0_480_360\" data-video-width=\"480\" data-video-height=\"360\" data-video-origin-width=\"480\" data-video-origin-height=\"360\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"바이브코딩 게임개발 활용팁 ~ 유니티편\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/fxbJpKBYUE8\" width=\"480\" height=\"360\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">유영한 정보</h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"506\" data-origin-height=\"390\"><span data-url=\"https://blog.kakaocdn.net/dn/bVWlkN/dJMcagYm4Bj/TuPI1QKAmwPEJQoiKj9wJ0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bVWlkN/dJMcagYm4Bj/TuPI1QKAmwPEJQoiKj9wJ0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bVWlkN/dJMcagYm4Bj/TuPI1QKAmwPEJQoiKj9wJ0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbVWlkN%2FdJMcagYm4Bj%2FTuPI1QKAmwPEJQoiKj9wJ0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"506\" height=\"390\" data-origin-width=\"506\" data-origin-height=\"390\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이 영상에서는 바이브 코딩 때문에 자동 갱신을 끄고 있습니다.</p>\n<p data-ke-size=\"size16\">여기서 끄게 되면 다른 프로젝트도 동일한 셋팅으로 사용하게 됩니다.</p>\n<p data-ke-size=\"size16\">AI 야 매번 필요할때 수동으로 갱신 하겠지만</p>\n<p data-ke-size=\"size16\">사람은 까먹을 수 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">저도 이상태로 두고 다른 작업하다 잊어 먹었는데</p>\n<p data-ke-size=\"size16\">그후에 동작이 매우 이상해서 한참 보도 눈치 챘습니다.</p>\n<p data-ke-size=\"size16\">엄청난 시간낭비를 하고나니 알았습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">사람이 개발할꺼면 자동갱신 켜는게 맞겠구나</h2>\n<p data-ke-size=\"size16\">AI 와 사람은 공존할 수 없나봅니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=fxbJpKBYUE8\n\n\n\n \n \n유영한 정보\n\n\n \n이 영상에서는 바이브 코딩 때문에 자동 갱신을 끄고 있습니다.\n여기서 끄게 되면 다른 프로젝트도 동일한 셋팅으로 사용하게 됩니다.\nAI 야 매번 필요할때 수동으로 갱신 하겠지만\n사람은 까먹을 수 있습니다.\n \n저도 이상태로 두고 다른 작업하다 잊어 먹었는데\n그후에 동작이 매우 이상해서 한참 보도 눈치 챘습니다.\n엄청난 시간낭비를 하고나니 알았습니다.\n \n사람이 개발할꺼면 자동갱신 켜는게 맞겠구나\nAI 와 사람은 공존할 수 없나봅니다.",
        "guid": "https://serverdown.tistory.com/1550",
        "categories": [
          "프로그래밍/개발메모",
          "유니티"
        ],
        "isoDate": "2025-12-18T07:58:29.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "365일차 - 간단한게임만들기 12일차 / 개발일지",
        "link": "https://serverdown.tistory.com/1549",
        "pubDate": "Tue, 16 Dec 2025 20:35:29 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1549#entry1549comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"564\" data-origin-height=\"472\"><span data-url=\"https://blog.kakaocdn.net/dn/drx2Px/dJMcabQhMF4/Tv87nxwdPqC5yxsvwjPHx1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/drx2Px/dJMcabQhMF4/Tv87nxwdPqC5yxsvwjPHx1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/drx2Px/dJMcabQhMF4/Tv87nxwdPqC5yxsvwjPHx1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fdrx2Px%2FdJMcabQhMF4%2FTv87nxwdPqC5yxsvwjPHx1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"564\" height=\"472\" data-origin-width=\"564\" data-origin-height=\"472\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=uuRtpnwGimg\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=uuRtpnwGimg</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=uuRtpnwGimg\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/c7hD0C/hyZPybufjW/v9Vmu2K6NfMeD20lZlNLI0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/bNduKx/hyZPpMncsx/THXXb8yBCo0LIgYTvSJzK1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/G7Qdt/hyZPEohIz7/YX5K3idSeDWzlFbQjujNd0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"365일차 - 간단한게임만들기 12일차 - 서비스 기능 추가\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/uuRtpnwGimg\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\">이번에도 어렵게 만들었다고 생각했는데</p>\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\">더 어렵게 만들어야할꺼 같네요</p>\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\">1년을 축하하며</p>\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\">&nbsp;</p>\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size26\">플레이하러가기</h2>\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\">웹에서 플라이 가능합니다.</p>\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\">게임 링크:<span>&nbsp;</span><a href=\"https://play.unity.com/en/games/fb8df491-0bdd-417e-88b8-af692eb40f42/122-easy-v11\">https://play.unity.com/en/games/fb8df491-0bdd-417e-88b8-af692eb40f42/122-easy-v11</a></p>\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=uuRtpnwGimg\n\n\n\n \n \n이번에도 어렵게 만들었다고 생각했는데\n더 어렵게 만들어야할꺼 같네요\n1년을 축하하며\n \n \n플레이하러가기\n웹에서 플라이 가능합니다.\n게임 링크: https://play.unity.com/en/games/fb8df491-0bdd-417e-88b8-af692eb40f42/122-easy-v11",
        "guid": "https://serverdown.tistory.com/1549",
        "categories": [
          "프로그래밍/자작"
        ],
        "isoDate": "2025-12-16T11:35:29.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "40대 현실적인 이혼 이야기 영상",
        "link": "https://serverdown.tistory.com/1548",
        "pubDate": "Tue, 16 Dec 2025 13:49:39 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1548#entry1548comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"432\" data-origin-height=\"380\"><span data-url=\"https://blog.kakaocdn.net/dn/bciKmr/dJMcaihz23V/IDDTHg94THvikiPsZePZ20/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bciKmr/dJMcaihz23V/IDDTHg94THvikiPsZePZ20/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bciKmr/dJMcaihz23V/IDDTHg94THvikiPsZePZ20/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbciKmr%2FdJMcaihz23V%2FIDDTHg94THvikiPsZePZ20%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"432\" height=\"380\" data-origin-width=\"432\" data-origin-height=\"380\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=XNpRS6hHvas\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=XNpRS6hHvas</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=XNpRS6hHvas\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bjULYq/hyZOKcAiE8/sLGiJoHspXr5vlPrvcxTvK/img.jpg?width=1280&amp;height=720&amp;face=496_264_718_506,https://scrap.kakaocdn.net/dn/ihYIj/hyZPHkYAAP/T2jZ9IfVHMqmdFHIXtZD90/img.jpg?width=1280&amp;height=720&amp;face=496_264_718_506,https://scrap.kakaocdn.net/dn/jMj7i/hyZPwkiMa2/Xka2SQdouKKeisL7LGpK9K/img.jpg?width=1280&amp;height=720&amp;face=496_264_718_506\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"제 친구들이 결혼했다가 전부 돌아오고 있습니다..초현실인터뷰\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/XNpRS6hHvas\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">남자는 삼성다니고 맞벌이 부부였군요</p>\n<p data-ke-size=\"size16\">정확한 이유는 모르겠고 자주 이혼하자가고 여자가 이야기 했다는군요</p>\n<p data-ke-size=\"size16\">이혼 사유는 자세히 나오지는 않습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이혼 법정의 줄서기 상황</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">양육비</span></p>\n<p data-ke-size=\"size16\">캠핑,&nbsp;로보랏 이야기도 있군요</p>\n<p data-ke-size=\"size16\">그런 이야기 입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이혼 이야기 뿐만 아니라 다른것도 재밌는 이야기 였습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=XNpRS6hHvas\n\n\n\n \n남자는 삼성다니고 맞벌이 부부였군요\n정확한 이유는 모르겠고 자주 이혼하자가고 여자가 이야기 했다는군요\n이혼 사유는 자세히 나오지는 않습니다.\n \n이혼 법정의 줄서기 상황\n양육비\n캠핑, 로보랏 이야기도 있군요\n그런 이야기 입니다.\n \n이혼 이야기 뿐만 아니라 다른것도 재밌는 이야기 였습니다.",
        "guid": "https://serverdown.tistory.com/1548",
        "categories": [
          "유튜브",
          "라이프"
        ],
        "isoDate": "2025-12-16T04:49:39.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "미국에서 하체 미인이 인기가 된 역사에 대해 알아보자 / 밋돌세",
        "link": "https://serverdown.tistory.com/1547",
        "pubDate": "Tue, 16 Dec 2025 11:55:39 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1547#entry1547comment",
        "content": "<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"680\" data-origin-height=\"523\"><span data-url=\"https://blog.kakaocdn.net/dn/dpKNgS/dJMcafLU3G4/VbhMTzkOcxaCGu8ogiEkS1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/dpKNgS/dJMcafLU3G4/VbhMTzkOcxaCGu8ogiEkS1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/dpKNgS/dJMcafLU3G4/VbhMTzkOcxaCGu8ogiEkS1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdpKNgS%2FdJMcafLU3G4%2FVbhMTzkOcxaCGu8ogiEkS1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"680\" height=\"523\" data-origin-width=\"680\" data-origin-height=\"523\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">사진은 킴 카다시안 드레스 촬영</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=rEK_jqYR6vM&amp;t=464s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=rEK_jqYR6vM&amp;t=464s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=rEK_jqYR6vM\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/f1KuV/hyZPz87ciY/DaWYZIEEbgvB9LHeDyQzK0/img.jpg?width=1280&amp;height=720&amp;face=92_184_1202_390,https://scrap.kakaocdn.net/dn/kPjUK/hyZPwR4QcO/RKmFSana67ertrcJUhqgv0/img.jpg?width=1280&amp;height=720&amp;face=92_184_1202_390,https://scrap.kakaocdn.net/dn/dbOj5m/hyZPqYD9jq/hnqnkY0nsDmKoLHutLsZLk/img.jpg?width=1280&amp;height=720&amp;face=92_184_1202_390\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"미국인들은 왜 큰 엉덩이에 집착하게 되었을까?\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/rEK_jqYR6vM\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">많은 사람들의 성공과 함께 했군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 style=\"background-color: #000000; color: #000000; text-align: start;\" data-ke-size=\"size26\">Sir Mix-A-Lot - Baby Got Back - 1992년</h2>\n<p data-ke-size=\"size16\">언급되는 노래: <a href=\"https://www.youtube.com/watch?v=X53ZSxkQ3Ho&amp;list=RDX53ZSxkQ3Ho&amp;start_radio=1\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=X53ZSxkQ3Ho&amp;list=RDX53ZSxkQ3Ho&amp;start_radio=1</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=X53ZSxkQ3Ho&amp;list=RDX53ZSxkQ3Ho\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/9F4Zp/hyZPORWq0f/1eEa8npYWglXBQnKaWOEn1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/bxhqVT/hyZPNS2usN/IjfQKq1CTUTytjvcpcKpZk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"Sir Mix-A-Lot - Baby Got Back (Official Music Video)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/X53ZSxkQ3Ho\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">어디서 들어본 노래가 이런 뜻이였구나</p>\n<p data-ke-size=\"size16\">날짜로 보면 1992년 한참된 문화 입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">제니퍼 로패즈 - If You Had My Love - 1999</h2>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=lYfkl-HXfuU&amp;list=RDlYfkl-HXfuU&amp;start_radio=1\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=lYfkl-HXfuU&amp;list=RDlYfkl-HXfuU&amp;start_radio=1</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=lYfkl-HXfuU&amp;list=RDlYfkl-HXfuU\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/quI0Z/hyZPwLiVUZ/z6bqYrJ2MXXOSrWvnd9Ln1/img.jpg?width=1280&amp;height=720&amp;face=578_288_694_416,https://scrap.kakaocdn.net/dn/bDkUO4/hyZPomdH41/fpSQprIicyczYWgkKQZMVk/img.jpg?width=1280&amp;height=720&amp;face=578_288_694_416\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"Jennifer Lopez - If You Had My Love (Official Video)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/lYfkl-HXfuU\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">2년뒤에 데뷰 했군요 데뷰곡이라고 합니다.</p>\n<p data-ke-size=\"size16\">저는 모르는 노래군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">킴 카다시안 - <b>Keeping Up with the Kardashians (카다시안 가족 따라잡기 리얼리티 TV 쇼)</b>&nbsp; - 2007</h2>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=2Y6Of76juDU\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=2Y6Of76juDU</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=2Y6Of76juDU\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/biBjeB/hyZPsPGFiX/wZ8D2NSrg5UHJruvZMKy81/img.jpg?width=1280&amp;height=720&amp;face=100_136_1192_474,https://scrap.kakaocdn.net/dn/c0sd2E/hyZPvMpKOK/n8c7962bQpwcFKXKcUQdh1/img.jpg?width=1280&amp;height=720&amp;face=100_136_1192_474\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"&quot;Keeping Up With the Kardashians&quot; PILOT Episode Recap (S1, E1) | KUWTK | E!\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/2Y6Of76juDU\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">이게 첫편이라는데 모르는 사람이라 알 길이 없다.</p>\n<p data-ke-size=\"size16\">카다시안 가족은 모두가 유명인들이라고 한다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">문화의 변화는 중요하다</h2>\n<p data-ke-size=\"size16\">문화가 바뀌면 미디어가 급격하게 바껴야하기 때문에</p>\n<p data-ke-size=\"size16\">배우 광고 등이 먼저 반응합니다.&nbsp;</p>\n<p data-ke-size=\"size16\">그리고 새로운 스타가 탄생하게 되지요.</p>\n<p data-ke-size=\"size16\">문확의 변화가 중요합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">게임업계도 랜덤 뽑기 하지말라는 문화가 확산되면서 부터 몰락이 시작되었는데</p>\n<p data-ke-size=\"size16\">이걸 모르는 투자자들은 경쟁자가 줄었다며 각자 더많이 투자해셔 현재는 매달 하나씩 mmoprg 가 나오는 사태도 발생했습니다.</p>\n<p data-ke-size=\"size16\">이런 문화 알았으면 투자 안했겠지요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">아파트 재건축도 잘될때가 있었는데 지금은 아닙니다.</p>\n<p data-ke-size=\"size16\">하지만 아닌 이시기에 재건출 공사를 시작하는 건수는 더 늘어나고 있지요</p>\n<p data-ke-size=\"size16\">이럴때는 멀꼬 빠져야할 타이밍이지 들어갈 타이밍이 아닌데 말이죠</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">하체가 미의 기준이 되었는데 상체 운동하면 안되는 것 처럼</span></p>\n<p data-ke-size=\"size16\">문화가 변했다면 과거에 하던대로 해서 다시 성공하기란 불가능합니다.</p>\n<p data-ke-size=\"size16\">이 변화에는 민감하게 반응해야할 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "사진은 킴 카다시안 드레스 촬영\n \n영상: https://www.youtube.com/watch?v=rEK_jqYR6vM&t=464s\n\n\n\n많은 사람들의 성공과 함께 했군요\n \n \n \n \n \nSir Mix-A-Lot - Baby Got Back - 1992년\n언급되는 노래: https://www.youtube.com/watch?v=X53ZSxkQ3Ho&list=RDX53ZSxkQ3Ho&start_radio=1\n\n\n\n \n어디서 들어본 노래가 이런 뜻이였구나\n날짜로 보면 1992년 한참된 문화 입니다.\n \n \n제니퍼 로패즈 - If You Had My Love - 1999\n영상: https://www.youtube.com/watch?v=lYfkl-HXfuU&list=RDlYfkl-HXfuU&start_radio=1\n\n\n\n2년뒤에 데뷰 했군요 데뷰곡이라고 합니다.\n저는 모르는 노래군요\n \n \n킴 카다시안 - Keeping Up with the Kardashians (카다시안 가족 따라잡기 리얼리티 TV 쇼)  - 2007\n영상: https://www.youtube.com/watch?v=2Y6Of76juDU\n\n\n\n이게 첫편이라는데 모르는 사람이라 알 길이 없다.\n카다시안 가족은 모두가 유명인들이라고 한다.\n \n문화의 변화는 중요하다\n문화가 바뀌면 미디어가 급격하게 바껴야하기 때문에\n배우 광고 등이 먼저 반응합니다. \n그리고 새로운 스타가 탄생하게 되지요.\n문확의 변화가 중요합니다.\n \n게임업계도 랜덤 뽑기 하지말라는 문화가 확산되면서 부터 몰락이 시작되었는데\n이걸 모르는 투자자들은 경쟁자가 줄었다며 각자 더많이 투자해셔 현재는 매달 하나씩 mmoprg 가 나오는 사태도 발생했습니다.\n이런 문화 알았으면 투자 안했겠지요\n \n아파트 재건축도 잘될때가 있었는데 지금은 아닙니다.\n하지만 아닌 이시기에 재건출 공사를 시작하는 건수는 더 늘어나고 있지요\n이럴때는 멀꼬 빠져야할 타이밍이지 들어갈 타이밍이 아닌데 말이죠\n \n하체가 미의 기준이 되었는데 상체 운동하면 안되는 것 처럼\n문화가 변했다면 과거에 하던대로 해서 다시 성공하기란 불가능합니다.\n이 변화에는 민감하게 반응해야할 것입니다.",
        "guid": "https://serverdown.tistory.com/1547",
        "categories": [
          "유튜브",
          "문화",
          "미국"
        ],
        "isoDate": "2025-12-16T02:55:39.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "제품리뷰 - 스빙마스터 오토슬라이서 / 채 써는 주방기계",
        "link": "https://serverdown.tistory.com/1546",
        "pubDate": "Mon, 15 Dec 2025 15:50:07 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1546#entry1546comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"172\" data-origin-height=\"185\"><span data-url=\"https://blog.kakaocdn.net/dn/0tcdd/dJMcaiaNMvV/ikugBrXkOKLMUbxjmr59KK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/0tcdd/dJMcaiaNMvV/ikugBrXkOKLMUbxjmr59KK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/0tcdd/dJMcaiaNMvV/ikugBrXkOKLMUbxjmr59KK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F0tcdd%2FdJMcaiaNMvV%2FikugBrXkOKLMUbxjmr59KK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"172\" height=\"185\" data-origin-width=\"172\" data-origin-height=\"185\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"244\" data-origin-height=\"488\"><span data-url=\"https://blog.kakaocdn.net/dn/C4lA9/dJMcafE9oej/jWXxTcBp1xDAPHjpdv7zmk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/C4lA9/dJMcafE9oej/jWXxTcBp1xDAPHjpdv7zmk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/C4lA9/dJMcafE9oej/jWXxTcBp1xDAPHjpdv7zmk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FC4lA9%2FdJMcafE9oej%2FjWXxTcBp1xDAPHjpdv7zmk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"244\" height=\"488\" data-origin-width=\"244\" data-origin-height=\"488\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">18만원짜리 샀습니다.</h2>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">종류</h2>\n<p data-ke-size=\"size16\">스빙 제품은 3종류가 있습니다.</p>\n<h3 data-ke-size=\"size23\">스빙라이트 - 3 ~ 8 만원 정도구요</h3>\n<p data-ke-size=\"size16\">작아서 큰거는 잘라서 넣어줘야합니다.<br />힘도 약하나 작은게 장점일 수도 있습니다.<br />잘라주면 되서 칼을 한번 들어야하는게 단점입니다.</p>\n<p data-ke-size=\"size16\">마스터는 너무 커서 작은것도 괜찮지 않나 싶긴합니다.<br />힘이 얼마나 약한지 확인하기 어렵네요</p>\n<h3 data-ke-size=\"size23\">스빙 오토슬라이서 - 14만원 정도</h3>\n<p data-ke-size=\"size16\">1세대 제품입니다.<br />큐브컷(볶음밥용) 칼날이 없고 마스터보다는 작습니다.<br />투입구가 애매한 크기 입니다. 큰 무우는 잘라서 넣어주면 됩니다.</p>\n<h3 data-ke-size=\"size23\">스빙마스터 오토슬라이서 - 18.8만원</h3>\n<p data-ke-size=\"size16\">제일 마지막에 나온 제품이구요<br />투입구가 커졌습니다.<br />큐브컷 됩니다. 저는 이걸 샀습니다.</p>\n<p data-ke-size=\"size16\">큐브컷 아니라도 채썰어서 볶아도 되긴하구요<br />투입구 작으면 잘라서 넣어주면 되긴하고<br />크기가 큰게 단점이기도 합니다. 이게 키가 좀 커서 어디 두기가 좀 애매합니다.</p>\n<p data-ke-size=\"size16\">하지만 주방 용품은 싼거 사면 후회 하니 (믹서기 같은거)<br />최신으로 샀습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">주의점</h2>\n<p data-ke-size=\"size16\">대부분의 조립은 잘못 넣으면 결합이 안되도록 되어있어서 안심할 수 있습니다.</p>\n<p data-ke-size=\"size16\">1. 칼날 교체가 처음에 어려웠다.</p>\n<p data-ke-size=\"size16\">어느부분을 잡고 빼는지 잘 이해가 안될 수 있으니 영상 보시고 따라하세요<br />넣을때도 힘이 잘들어가는 위치를 잡아야하니 영상 참고 필수</p>\n<p data-ke-size=\"size16\">2. 칼날 보호용 스티커 제거해야 됩니다.</p>\n<p data-ke-size=\"size16\">왜 안썰리지 하는 경우가 있었는데</p>\n<p data-ke-size=\"size16\">발날 보호를 위해 몇개는 칼날 보호 스티커가 붙어 있습니다.</p>\n<p data-ke-size=\"size16\">출고할때 녹쓸지 말라고 붙인거 같군요 스티커 발려있으니 당연이 안썰리겠죠</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">사용법은 영상 보면시구요<br />여러 영상중에 이게 제일 도움 되었습니다.</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=OR8AJ-tpx_c&amp;t=302s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=OR8AJ-tpx_c&amp;t=302s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=OR8AJ-tpx_c\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/nYlV9/hyZPAUbix0/hbmP4KNWUZ6N6Uw0V7VLfK/img.jpg?width=1280&amp;height=720&amp;face=1018_288_1106_384,https://scrap.kakaocdn.net/dn/bz8ToZ/hyZPtgqNPC/4kQvQ9Oy037hoDrWhNbz4K/img.jpg?width=1280&amp;height=720&amp;face=1018_288_1106_384\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"편리하고 손 쉬운 재료 준비｜AGK 스빙마스터 오토슬라이서｜\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/OR8AJ-tpx_c\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">제품이 안전하도록 잘 설계되어있습니다.</p>\n<p data-ke-size=\"size16\">분해가 잘되서 무리해서 손넣을 만한 곳은 없습니다.</p>\n<p data-ke-size=\"size16\">가정용으로 좋아보입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">칼날 교체 쇼츠</h2>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/shorts/CfzR0eYrDqg\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/shorts/CfzR0eYrDqg</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/shorts/CfzR0eYrDqg\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/APX8l/hyZPqR43jD/9T0YSEV90foDBq3ZXbp5C0/img.jpg?width=405&amp;height=720&amp;face=0_0_405_720,https://scrap.kakaocdn.net/dn/Qm6x5/hyZPqdttrF/NbWnWiENFf1uuPjKCFSnn1/img.jpg?width=405&amp;height=720&amp;face=0_0_405_720,https://scrap.kakaocdn.net/dn/yG6JD/hyZPxjlLLr/uZChQODpQBy9gFUI0FWmj0/img.jpg?width=405&amp;height=720&amp;face=0_0_405_720\" data-video-width=\"405\" data-video-height=\"720\" data-video-origin-width=\"405\" data-video-origin-height=\"720\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"AGK스빙마스터 칼날교체영상\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/CfzR0eYrDqg\" width=\"405\" height=\"720\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">처음에 난감하신분을 위해</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">상업용 채써는 기계는 잘못다루면 위험해게 생긴게 꽤 있었습니다.</p>\n<p data-ke-size=\"size16\">이 제품은 크기가 너무 커서 손 넣다 다칠만한 구석은 없어 보입니다.</p>",
        "contentSnippet": "18만원짜리 샀습니다.\n \n종류\n스빙 제품은 3종류가 있습니다.\n스빙라이트 - 3 ~ 8 만원 정도구요\n작아서 큰거는 잘라서 넣어줘야합니다.\n힘도 약하나 작은게 장점일 수도 있습니다.\n잘라주면 되서 칼을 한번 들어야하는게 단점입니다.\n마스터는 너무 커서 작은것도 괜찮지 않나 싶긴합니다.\n힘이 얼마나 약한지 확인하기 어렵네요\n스빙 오토슬라이서 - 14만원 정도\n1세대 제품입니다.\n큐브컷(볶음밥용) 칼날이 없고 마스터보다는 작습니다.\n투입구가 애매한 크기 입니다. 큰 무우는 잘라서 넣어주면 됩니다.\n스빙마스터 오토슬라이서 - 18.8만원\n제일 마지막에 나온 제품이구요\n투입구가 커졌습니다.\n큐브컷 됩니다. 저는 이걸 샀습니다.\n큐브컷 아니라도 채썰어서 볶아도 되긴하구요\n투입구 작으면 잘라서 넣어주면 되긴하고\n크기가 큰게 단점이기도 합니다. 이게 키가 좀 커서 어디 두기가 좀 애매합니다.\n하지만 주방 용품은 싼거 사면 후회 하니 (믹서기 같은거)\n최신으로 샀습니다.\n \n주의점\n대부분의 조립은 잘못 넣으면 결합이 안되도록 되어있어서 안심할 수 있습니다.\n1. 칼날 교체가 처음에 어려웠다.\n어느부분을 잡고 빼는지 잘 이해가 안될 수 있으니 영상 보시고 따라하세요\n넣을때도 힘이 잘들어가는 위치를 잡아야하니 영상 참고 필수\n2. 칼날 보호용 스티커 제거해야 됩니다.\n왜 안썰리지 하는 경우가 있었는데\n발날 보호를 위해 몇개는 칼날 보호 스티커가 붙어 있습니다.\n출고할때 녹쓸지 말라고 붙인거 같군요 스티커 발려있으니 당연이 안썰리겠죠\n \n \n사용법은 영상 보면시구요\n여러 영상중에 이게 제일 도움 되었습니다.\n영상: https://www.youtube.com/watch?v=OR8AJ-tpx_c&t=302s\n\n\n\n제품이 안전하도록 잘 설계되어있습니다.\n분해가 잘되서 무리해서 손넣을 만한 곳은 없습니다.\n가정용으로 좋아보입니다.\n \n \n칼날 교체 쇼츠\n영상: https://www.youtube.com/shorts/CfzR0eYrDqg\n\n\n\n처음에 난감하신분을 위해\n \n \n상업용 채써는 기계는 잘못다루면 위험해게 생긴게 꽤 있었습니다.\n이 제품은 크기가 너무 커서 손 넣다 다칠만한 구석은 없어 보입니다.",
        "guid": "https://serverdown.tistory.com/1546",
        "categories": [
          "유튜브",
          "제품리뷰"
        ],
        "isoDate": "2025-12-15T06:50:07.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "제품리뷰 - 무선 마이크 마오노 PD200W",
        "link": "https://serverdown.tistory.com/1545",
        "pubDate": "Mon, 15 Dec 2025 15:32:17 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1545#entry1545comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"239\" data-origin-height=\"220\"><span data-url=\"https://blog.kakaocdn.net/dn/em87xV/dJMcaiIBaHn/L518PuHdk27ch8UDZdTOnk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/em87xV/dJMcaiIBaHn/L518PuHdk27ch8UDZdTOnk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/em87xV/dJMcaiIBaHn/L518PuHdk27ch8UDZdTOnk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fem87xV%2FdJMcaiIBaHn%2FL518PuHdk27ch8UDZdTOnk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"239\" height=\"220\" data-origin-width=\"239\" data-origin-height=\"220\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"259\" data-origin-height=\"410\"><span data-url=\"https://blog.kakaocdn.net/dn/cCW8Ry/dJMcadHh8wU/IgdqTiIDzgNwA87uxdl1g0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cCW8Ry/dJMcadHh8wU/IgdqTiIDzgNwA87uxdl1g0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cCW8Ry/dJMcadHh8wU/IgdqTiIDzgNwA87uxdl1g0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcCW8Ry%2FdJMcadHh8wU%2FIgdqTiIDzgNwA87uxdl1g0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"259\" height=\"410\" data-origin-width=\"259\" data-origin-height=\"410\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">15만원</p>\n<p data-ke-size=\"size16\">비싼 감이 있는데 싼거사서 노이즈 때문에 차차 올리다보면&nbsp;</p>\n<p data-ke-size=\"size16\">이가격 까지 옵니다. 한방에 지르는게 아끼는 걸 수 있습니다.</p>\n<p data-ke-size=\"size16\">성능에는 문제 없구요 (영상 보시면 됩니다.)</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">단점으로 보이는 것</h2>\n<p data-ke-size=\"size16\">1. 이거 툭쳐서 떨어질 수 있을꺼 같긴한데 ...<br />텀블러도 쏟는 사람이 있으니 이것도 가능한 시나리오 같습니다.</p>\n<p data-ke-size=\"size16\">2. 강의 녹음하려면 모니터를 본채로 말을 해야하는데<br />이게 눈앞에 있으면 모니터를 가릴꺼 같고<br />내 옆에 있으면 녹음이 잘 안될꺼 같긴한데 ...</p>\n<p data-ke-size=\"size16\">강의 용이 아니고 인터뷰 용인가 싶기도</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">하지만 저는 15,000원 짜리 핀마이크를 쓰고 있습니다.</p>\n<p data-ke-size=\"size16\">모니터 안가리는 제품있으면 정말 좋겠다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=HlXA3x88GQE\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=HlXA3x88GQE</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=HlXA3x88GQE\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/br9cfQ/hyZPA7HMIg/THaaU0Ci0tV81pP4PnWYf0/img.jpg?width=1280&amp;height=720&amp;face=286_108_704_370,https://scrap.kakaocdn.net/dn/byOsjU/hyZPngeDYk/umiDCNCVv8OuQ0Gy7Ce7Bk/img.jpg?width=1280&amp;height=720&amp;face=286_108_704_370,https://scrap.kakaocdn.net/dn/cLioZh/hyZPoTJ2mB/GWRtBzy3LdseIoeIqp5r81/img.jpg?width=1280&amp;height=720&amp;face=286_108_704_370\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"무선으로도 작동하는 하이브리드 방송용 마이크 마오노 PD200W 소개 #협찬\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/HlXA3x88GQE\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "15만원\n비싼 감이 있는데 싼거사서 노이즈 때문에 차차 올리다보면 \n이가격 까지 옵니다. 한방에 지르는게 아끼는 걸 수 있습니다.\n성능에는 문제 없구요 (영상 보시면 됩니다.)\n \n \n단점으로 보이는 것\n1. 이거 툭쳐서 떨어질 수 있을꺼 같긴한데 ...\n텀블러도 쏟는 사람이 있으니 이것도 가능한 시나리오 같습니다.\n2. 강의 녹음하려면 모니터를 본채로 말을 해야하는데\n이게 눈앞에 있으면 모니터를 가릴꺼 같고\n내 옆에 있으면 녹음이 잘 안될꺼 같긴한데 ...\n강의 용이 아니고 인터뷰 용인가 싶기도\n \n \n하지만 저는 15,000원 짜리 핀마이크를 쓰고 있습니다.\n모니터 안가리는 제품있으면 정말 좋겠다.\n \n영상: https://www.youtube.com/watch?v=HlXA3x88GQE",
        "guid": "https://serverdown.tistory.com/1545",
        "categories": [
          "제품리뷰"
        ],
        "isoDate": "2025-12-15T06:32:17.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "플스5 용 하드웨어를 컴퓨터로 개조해 팔고 있네요 / 가난한자의 컴퓨터",
        "link": "https://serverdown.tistory.com/1544",
        "pubDate": "Mon, 15 Dec 2025 12:35:33 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1544#entry1544comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"344\" data-origin-height=\"338\"><span data-url=\"https://blog.kakaocdn.net/dn/ceWgu6/dJMb99Stjm2/qamUzjoairxhxdzuBVMiDK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ceWgu6/dJMb99Stjm2/qamUzjoairxhxdzuBVMiDK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/ceWgu6/dJMb99Stjm2/qamUzjoairxhxdzuBVMiDK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FceWgu6%2FdJMb99Stjm2%2FqamUzjoairxhxdzuBVMiDK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"344\" height=\"338\" data-origin-width=\"344\" data-origin-height=\"338\"/></span></figure>\n</p>\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\"><span style=\"text-align: start;\">AMD GC-250 은 PS5 에 들어가는 CPU + GPU 입니다.</span></p>\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\"><span style=\"text-align: start;\">이게 남았는지 컴퓨터로 개조해 팔고 있네요</span></p>\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\"><span style=\"text-align: start;\">AMD 는 중국에서 대단한 일을 하고 있군요 ㄷㄷㄷ</span></p>\n<p style=\"background-color: #000000; color: #000000;\" data-ke-size=\"size16\">&nbsp;</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"656\" data-origin-height=\"268\"><span data-url=\"https://blog.kakaocdn.net/dn/EqRsy/dJMcadUOw4c/kOtRnSFkdrDqSUWlkSAyzK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/EqRsy/dJMcadUOw4c/kOtRnSFkdrDqSUWlkSAyzK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/EqRsy/dJMcadUOw4c/kOtRnSFkdrDqSUWlkSAyzK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FEqRsy%2FdJMcadUOw4c%2FkOtRnSFkdrDqSUWlkSAyzK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"656\" height=\"268\" data-origin-width=\"656\" data-origin-height=\"268\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">알리에서 팔고 있군요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=AY-23g6gNTw\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=AY-23g6gNTw</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=AY-23g6gNTw\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/XChI1/hyZOz9QZ0d/JqzkuIYCtPrMAxDOAdFo6k/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/bbtkMW/hyZPD3S2N8/PdhnoZVrZKjuYVDqrMkHjk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"채굴장에 끌려갔다온 플스5, BC250에 스팀덱OS 설치하기\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/AY-23g6gNTw\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">CPU 는 긱벤치로는 6천점 정도로</p>\n<p data-ke-size=\"size16\">라즈베리파이의 3배 정도 속도 나오네요</p>\n<p data-ke-size=\"size16\">3D 성능 좋구요</p>\n<p data-ke-size=\"size16\">리눅스에서만 정상동작합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">윈도우즈 설치기: <a href=\"https://www.youtube.com/watch?v=UZLbGMPZTJQ\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=UZLbGMPZTJQ</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=UZLbGMPZTJQ\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/BCj8g/hyZPsINFx4/wDCphf5EUUNrZPPWkcCbEK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/bq2vK1/hyZPAz3bRs/5wxLJobtHcjqi1aUeauTwk/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/5oxfD/hyZPx4pcKP/hYsEiB7kg58qlZW1bgF6c1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"bc250에 윈도우 설치하고 게임도 돌려봤습니다 (feat. 메이플스토리)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/UZLbGMPZTJQ\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">윈도우가 깔리긴하는데 ....</p>\n<p data-ke-size=\"size16\">상태가 안좋습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "AMD GC-250 은 PS5 에 들어가는 CPU + GPU 입니다.\n이게 남았는지 컴퓨터로 개조해 팔고 있네요\nAMD 는 중국에서 대단한 일을 하고 있군요 ㄷㄷㄷ\n \n\n\n알리에서 팔고 있군요\n \n영상: https://www.youtube.com/watch?v=AY-23g6gNTw\n\n\n\n \nCPU 는 긱벤치로는 6천점 정도로\n라즈베리파이의 3배 정도 속도 나오네요\n3D 성능 좋구요\n리눅스에서만 정상동작합니다.\n \n윈도우즈 설치기: https://www.youtube.com/watch?v=UZLbGMPZTJQ\n\n\n\n윈도우가 깔리긴하는데 ....\n상태가 안좋습니다.",
        "guid": "https://serverdown.tistory.com/1544",
        "categories": [
          "유튜브",
          "컴퓨터"
        ],
        "isoDate": "2025-12-15T03:35:33.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "내가 팔면 오르는 코인시장 / 누눙지",
        "link": "https://serverdown.tistory.com/1543",
        "pubDate": "Mon, 15 Dec 2025 12:22:51 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1543#entry1543comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"565\" data-origin-height=\"489\"><span data-url=\"https://blog.kakaocdn.net/dn/cm5KRE/dJMb9950uBc/U3OeZphTVqidQ8AvXLQwY1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/cm5KRE/dJMb9950uBc/U3OeZphTVqidQ8AvXLQwY1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/cm5KRE/dJMb9950uBc/U3OeZphTVqidQ8AvXLQwY1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fcm5KRE%2FdJMb9950uBc%2FU3OeZphTVqidQ8AvXLQwY1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"565\" height=\"489\" data-origin-width=\"565\" data-origin-height=\"489\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=w15xkTXOhuI\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=w15xkTXOhuI</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=w15xkTXOhuI\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cKVCuO/hyZPBlbpQ0/zrrt8Efi10tWjQ06knkn01/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/bZmAtU/hyZPCxDHi8/suBxPnYlTSAszkdJqbW2iK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/cAP9Rg/hyZOEwyL4Y/FBSQfzyBBbECZ1Y8Kf3a11/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"인생 여전\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/w15xkTXOhuI\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">간발의 차이 ㄷㄷㄷ</p>\n<p data-ke-size=\"size16\"><span style=\"text-align: start;\">그저 아깝다.</span></p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=w15xkTXOhuI\n\n\n\n \n간발의 차이 ㄷㄷㄷ\n그저 아깝다.",
        "guid": "https://serverdown.tistory.com/1543",
        "categories": [
          "유튜브",
          "유튜브"
        ],
        "isoDate": "2025-12-15T03:22:51.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "언리얼로 3개월 동안 게임 만들기 도전기 / NEXONTAG / 인디게임",
        "link": "https://serverdown.tistory.com/1542",
        "pubDate": "Mon, 15 Dec 2025 11:27:06 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1542#entry1542comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"424\" data-origin-height=\"327\"><span data-url=\"https://blog.kakaocdn.net/dn/b5m76r/dJMcafZrD5X/ny2uzT02nDKOvzSMdt23F0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/b5m76r/dJMcafZrD5X/ny2uzT02nDKOvzSMdt23F0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/b5m76r/dJMcafZrD5X/ny2uzT02nDKOvzSMdt23F0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb5m76r%2FdJMcafZrD5X%2Fny2uzT02nDKOvzSMdt23F0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"424\" height=\"327\" data-origin-width=\"424\" data-origin-height=\"327\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=bzJPslwwHCc\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=bzJPslwwHCc</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=bzJPslwwHCc\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/Y0lPM/hyZPByHTQ7/UmB5KpWKkSIhNKmgoKJp5K/img.jpg?width=1280&amp;height=720&amp;face=982_182_1062_270,https://scrap.kakaocdn.net/dn/Kx80l/hyZPnAraE7/6bOpqbUpMSrNk7YQRQUplk/img.jpg?width=1280&amp;height=720&amp;face=982_182_1062_270,https://scrap.kakaocdn.net/dn/ev2ute/hyZPt8vAUK/P1OaF3SQ8EVvPkCA1qyK5k/img.jpg?width=1280&amp;height=720&amp;face=982_182_1062_270\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"언리얼엔진 3개월 게임 개발 후기 #unrealengine\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/bzJPslwwHCc\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">여러가지 지식을 이야기 해줍니다.</p>\n<p data-ke-size=\"size16\">애셋문제</p>\n<p data-ke-size=\"size16\">용량문제</p>\n<p data-ke-size=\"size16\">배울점이 있었습니다.</p>\n<p data-ke-size=\"size16\">앞으로 기대되네요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=bzJPslwwHCc\n\n\n\n \n여러가지 지식을 이야기 해줍니다.\n애셋문제\n용량문제\n배울점이 있었습니다.\n앞으로 기대되네요",
        "guid": "https://serverdown.tistory.com/1542",
        "categories": [
          "유튜브",
          "유튜브",
          "인디게임"
        ],
        "isoDate": "2025-12-15T02:27:06.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "언리얼과 유니티의 파트너쉽 체결의 개발자 관점의 의미",
        "link": "https://serverdown.tistory.com/1541",
        "pubDate": "Mon, 15 Dec 2025 10:29:55 +0900",
        "author": "SIDNFT",
        "comments": "https://serverdown.tistory.com/1541#entry1541comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"922\" data-origin-height=\"741\"><span data-url=\"https://blog.kakaocdn.net/dn/syDBY/dJMcag478DO/g8cMiKfPgkrocc80Xoh94K/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/syDBY/dJMcag478DO/g8cMiKfPgkrocc80Xoh94K/img.png\"><img src=\"https://blog.kakaocdn.net/dn/syDBY/dJMcag478DO/g8cMiKfPgkrocc80Xoh94K/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FsyDBY%2FdJMcag478DO%2Fg8cMiKfPgkrocc80Xoh94K%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"922\" height=\"741\" data-origin-width=\"922\" data-origin-height=\"741\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">뉴스: <a href=\"https://n.news.naver.com/article/001/0015752259?sid=105\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://n.news.naver.com/article/001/0015752259?sid=105</a></p>\n<figure id=\"og_1765760109454\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"article\" data-og-title=\"게임엔진 '양대산맥' 에픽게임즈-유니티, 전격 파트너십\" data-og-description=\"유니티 게임 포트나이트에 선보이고 커머스 플랫폼 언리얼엔진 지원 전세계 상용 게임 엔진 시장을 양분하고 있는 에픽게임즈와 유니티가 전격 파트너십을 발표했다. 유니티는 19일 유니티 엔\" data-og-host=\"n.news.naver.com\" data-og-source-url=\"https://n.news.naver.com/article/001/0015752259?sid=105\" data-og-url=\"https://n.news.naver.com/article/001/0015752259\" data-og-image=\"https://scrap.kakaocdn.net/dn/BDi3Z/hyZPtHqjJX/D8EEGEgQGCJZzar1MPH12K/img.jpg?width=500&amp;height=281&amp;face=0_0_500_281,https://scrap.kakaocdn.net/dn/oznDe/hyZPoTDLVA/K6gtHo2HrZkfW8YMakCQm1/img.jpg?width=500&amp;height=281&amp;face=0_0_500_281\"><a href=\"https://n.news.naver.com/article/001/0015752259?sid=105\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://n.news.naver.com/article/001/0015752259?sid=105\">\n<div class=\"og-image\" style=\"background-image: url('https://scrap.kakaocdn.net/dn/BDi3Z/hyZPtHqjJX/D8EEGEgQGCJZzar1MPH12K/img.jpg?width=500&amp;height=281&amp;face=0_0_500_281,https://scrap.kakaocdn.net/dn/oznDe/hyZPoTDLVA/K6gtHo2HrZkfW8YMakCQm1/img.jpg?width=500&amp;height=281&amp;face=0_0_500_281');\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">게임엔진 '양대산맥' 에픽게임즈-유니티, 전격 파트너십</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">유니티 게임 포트나이트에 선보이고 커머스 플랫폼 언리얼엔진 지원 전세계 상용 게임 엔진 시장을 양분하고 있는 에픽게임즈와 유니티가 전격 파트너십을 발표했다. 유니티는 19일 유니티 엔</p>\n<p class=\"og-host\" data-ke-size=\"size16\">n.news.naver.com</p>\n</div>\n</a></figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">어차피 기자들은 개발과 상관 없기 때문에 와닿지 않는 의미로 해석한다.&nbsp;</p>\n<p data-ke-size=\"size16\">간략히 이야기 해보자</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">1. 커머스 통함</p>\n<p data-ke-size=\"size16\">유니티와 언리얼은 애셋 스토어가 있다.&nbsp;</p>\n<p data-ke-size=\"size16\">게임의 리소스들을 판매하는 곳으로 게임만들때 필요한 3D 모델, 애니메이션, 프로그램 코드 등을 판매한다.</p>\n<p data-ke-size=\"size16\">이중 3D 모델 과 애니메이션은 디자이너 영역으로 fbx 라는 통합 규격으로 동작한다&nbsp;</p>\n<p data-ke-size=\"size16\">그렇다 이미 통합되있다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">1. FBX 포멧</h2>\n<p data-ke-size=\"size16\">fbx 표준만 잘 맞춘다면 서로는 호환 될 수 있다.</p>\n<p data-ke-size=\"size16\">현재는 휴머노이드라고 해서 인간형태에 대한 표준은 있는데&nbsp;</p>\n<p data-ke-size=\"size16\">버튜버가 생겨나면서 얼굴 표정 까지 표사하는 단계에 이르렇다 이 표준 통합이 이뤄진다면&nbsp;</p>\n<p data-ke-size=\"size16\">얼굴 표정을 읽는 장비도 특정부분에 집중할 수 있을 것이고</p>\n<p data-ke-size=\"size16\">이런 표준은 표정을 연기하는 인간형 로봇에도 필요하다.</p>\n<p data-ke-size=\"size16\">(버튜버가 큰일 하고 있다.)</p>\n<p data-ke-size=\"size16\">현재 메터리얼(재질)은 호환이 안되느데 이부분도 되야할 것이다.<br />(누군가는 애니 케릭 좋아할 것이고 누군가는 리얼케릭 좋아할테니)</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">2. 광고 시장</h2>\n<p data-ke-size=\"size16\">네이버의 재페토는 앱 + 유니티를 통합해서 앱 실행시간이 유니티 실행시간과 동일하지 않다.</p>\n<p data-ke-size=\"size16\">앱 기능은 일반 커뮤니티 기능을 수행하고<br />유니티 부분은 방에 방문해서 3D 세상을 보는 형식의 앱이다.</p>\n<p data-ke-size=\"size16\">이런 식의 특이한 앱들이 늘어나면 통계가 왜곡 될수 있기 때문에 호환이 필요하다.</p>\n<p data-ke-size=\"size16\">유니티는 이미 앱내에서 유니티 엔진을 끄고 켜는게 가능하다.</p>\n<p data-ke-size=\"size16\">언리얼도 이기능을 지원한다면 앱 내에 유니티와 언리얼 엔진 둘다 들어가고</p>\n<p data-ke-size=\"size16\">상황에 따라 두 엔진이 (동시에는 어렵겠고) 번갈아 가며 표시할 수 도 있을 것이다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">물론 광고에서는 어느 엔진이 돌아갈때 무슨 상황인지 판단할 수 있어야하고</p>\n<p data-ke-size=\"size16\">그런 엔진 사용자는 어떤광고가 유리한지 판단할 수 있어야한다.</p>\n<p data-ke-size=\"size16\">그래야 제품을 살 고객에게 정확한 광고를 내보낼 수 있기 때문이다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">과거의 광고는 라면을 산 사람에게 라면을 광고하는 형식이지만 미래는 다를 것이라 믿는다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">3. 개발자 이익 집계</h2>\n<p data-ke-size=\"size16\">현재 유니티는 구글 애플 스토어의 이익을 집계하는 기능이 있는걸로 알고 있다.</p>\n<p data-ke-size=\"size16\">그래서 매출이 일정이상 오르면 사용료를 받을 수 있는데</p>\n<p data-ke-size=\"size16\">개발자는 이를 숨기기위해 특정이익 구간에서 귀찮은 짓을 해야한다.</p>\n<p data-ke-size=\"size16\">사업자를 여러개 낸다거나 해서 이익을 분산하는 방식이다.<br />(일정수준 넘어가면 의미없긴한데 사업 초기에는 고려할 수 있다.)</p>\n<p data-ke-size=\"size16\">언리얼도 이 통계에 같이 들어와버리면 수익 피하기 는 더 어려워질 것이다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">4. 메타버스 - 내 캐릭터의 호환성</h2>\n<p data-ke-size=\"size16\">현재는 언리얼에서 만든건 언리얼에서 돌아가고 유니티에서 만든건 유니티에서 돌아간다.<br />(당연하지)</p>\n<p data-ke-size=\"size16\">하지만 둘다 웹의 jpg 를 불러와 화면에 출력하는건 가능하다.</p>\n<p data-ke-size=\"size16\">점점더 확장된다면 3D 캐릭터를 호환시킬 수도 있게되고</p>\n<p data-ke-size=\"size16\">A 앱에서 내모습이&nbsp; B 앱에서도 동이하게 표시될 수 있게 될 것이다.</p>\n<p data-ke-size=\"size16\">이것은 나아가 내 케릭터에 더 많은 투자를 할 수 있게 된다는 뜻이다.<br />(잘보이기위해 이런 투자는 이미 명품시장에서 증명되었다.)</p>\n<p data-ke-size=\"size16\">허깅 페이스는 AI 모델을 웹에 올리고 서로 공유하고 있는 판국이고</p>\n<p data-ke-size=\"size16\">AI 는 언어를 번역하는 기술이 뛰어나다.</p>\n<p data-ke-size=\"size16\">결국 두엔진간의 리소스는 AI 번역을 통해 호환 될 것이다.<br />딴길 가지말고 미리 손잡고 호환시키는게 맞다.</p>\n<p data-ke-size=\"size16\">문제는 이러면 복제가 시워져서 기존 명풍 시장이라는 다른 방향으로 진화할 것이다.<br />(실문세계에서는 가방을 복제해서 내가 가지면 표가 난다 ㅋ)</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">나는 이런 의미로 해석했다.<br />메타버스에 한발 나아가고 있다고 본다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "뉴스: https://n.news.naver.com/article/001/0015752259?sid=105\n\n \n게임엔진 '양대산맥' 에픽게임즈-유니티, 전격 파트너십\n유니티 게임 포트나이트에 선보이고 커머스 플랫폼 언리얼엔진 지원 전세계 상용 게임 엔진 시장을 양분하고 있는 에픽게임즈와 유니티가 전격 파트너십을 발표했다. 유니티는 19일 유니티 엔\nn.news.naver.com\n\n \n \n어차피 기자들은 개발과 상관 없기 때문에 와닿지 않는 의미로 해석한다. \n간략히 이야기 해보자\n \n1. 커머스 통함\n유니티와 언리얼은 애셋 스토어가 있다. \n게임의 리소스들을 판매하는 곳으로 게임만들때 필요한 3D 모델, 애니메이션, 프로그램 코드 등을 판매한다.\n이중 3D 모델 과 애니메이션은 디자이너 영역으로 fbx 라는 통합 규격으로 동작한다 \n그렇다 이미 통합되있다.\n \n1. FBX 포멧\nfbx 표준만 잘 맞춘다면 서로는 호환 될 수 있다.\n현재는 휴머노이드라고 해서 인간형태에 대한 표준은 있는데 \n버튜버가 생겨나면서 얼굴 표정 까지 표사하는 단계에 이르렇다 이 표준 통합이 이뤄진다면 \n얼굴 표정을 읽는 장비도 특정부분에 집중할 수 있을 것이고\n이런 표준은 표정을 연기하는 인간형 로봇에도 필요하다.\n(버튜버가 큰일 하고 있다.)\n현재 메터리얼(재질)은 호환이 안되느데 이부분도 되야할 것이다.\n(누군가는 애니 케릭 좋아할 것이고 누군가는 리얼케릭 좋아할테니)\n \n \n2. 광고 시장\n네이버의 재페토는 앱 + 유니티를 통합해서 앱 실행시간이 유니티 실행시간과 동일하지 않다.\n앱 기능은 일반 커뮤니티 기능을 수행하고\n유니티 부분은 방에 방문해서 3D 세상을 보는 형식의 앱이다.\n이런 식의 특이한 앱들이 늘어나면 통계가 왜곡 될수 있기 때문에 호환이 필요하다.\n유니티는 이미 앱내에서 유니티 엔진을 끄고 켜는게 가능하다.\n언리얼도 이기능을 지원한다면 앱 내에 유니티와 언리얼 엔진 둘다 들어가고\n상황에 따라 두 엔진이 (동시에는 어렵겠고) 번갈아 가며 표시할 수 도 있을 것이다.\n \n물론 광고에서는 어느 엔진이 돌아갈때 무슨 상황인지 판단할 수 있어야하고\n그런 엔진 사용자는 어떤광고가 유리한지 판단할 수 있어야한다.\n그래야 제품을 살 고객에게 정확한 광고를 내보낼 수 있기 때문이다.\n \n과거의 광고는 라면을 산 사람에게 라면을 광고하는 형식이지만 미래는 다를 것이라 믿는다.\n \n3. 개발자 이익 집계\n현재 유니티는 구글 애플 스토어의 이익을 집계하는 기능이 있는걸로 알고 있다.\n그래서 매출이 일정이상 오르면 사용료를 받을 수 있는데\n개발자는 이를 숨기기위해 특정이익 구간에서 귀찮은 짓을 해야한다.\n사업자를 여러개 낸다거나 해서 이익을 분산하는 방식이다.\n(일정수준 넘어가면 의미없긴한데 사업 초기에는 고려할 수 있다.)\n언리얼도 이 통계에 같이 들어와버리면 수익 피하기 는 더 어려워질 것이다.\n \n4. 메타버스 - 내 캐릭터의 호환성\n현재는 언리얼에서 만든건 언리얼에서 돌아가고 유니티에서 만든건 유니티에서 돌아간다.\n(당연하지)\n하지만 둘다 웹의 jpg 를 불러와 화면에 출력하는건 가능하다.\n점점더 확장된다면 3D 캐릭터를 호환시킬 수도 있게되고\nA 앱에서 내모습이  B 앱에서도 동이하게 표시될 수 있게 될 것이다.\n이것은 나아가 내 케릭터에 더 많은 투자를 할 수 있게 된다는 뜻이다.\n(잘보이기위해 이런 투자는 이미 명품시장에서 증명되었다.)\n허깅 페이스는 AI 모델을 웹에 올리고 서로 공유하고 있는 판국이고\nAI 는 언어를 번역하는 기술이 뛰어나다.\n결국 두엔진간의 리소스는 AI 번역을 통해 호환 될 것이다.\n딴길 가지말고 미리 손잡고 호환시키는게 맞다.\n문제는 이러면 복제가 시워져서 기존 명풍 시장이라는 다른 방향으로 진화할 것이다.\n(실문세계에서는 가방을 복제해서 내가 가지면 표가 난다 ㅋ)\n \n나는 이런 의미로 해석했다.\n메타버스에 한발 나아가고 있다고 본다.",
        "guid": "https://serverdown.tistory.com/1541",
        "categories": [
          "프로그래밍/개발메모",
          "메타버스",
          "언리얼",
          "유니티"
        ],
        "isoDate": "2025-12-15T01:29:55.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": []
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "사내 AI 리터러시를 향상하기 위한 AI Campus Day를 개최했습니다",
        "link": "https://techblog.lycorp.co.jp/ko/ai-campus-day-for-enhancing-ai-literacy-of-employees",
        "pubDate": "Fri, 19 Dec 2025 02:00:00 GMT",
        "content": "LINE Plus의 오피스가 '캠퍼스'로 변신했습니다.회의실은 강의실이, LINER들은 학생이 되었습니다.위 모습은 지난 12월 2일에 열린 사내 행사 AI Campus Day의 ...",
        "contentSnippet": "LINE Plus의 오피스가 '캠퍼스'로 변신했습니다.회의실은 강의실이, LINER들은 학생이 되었습니다.위 모습은 지난 12월 2일에 열린 사내 행사 AI Campus Day의 ...",
        "guid": "https://techblog.lycorp.co.jp/ko/ai-campus-day-for-enhancing-ai-literacy-of-employees",
        "isoDate": "2025-12-19T02:00:00.000Z"
      },
      {
        "title": "안전은 기본, 비용 절감은 덤: AI 서비스에 별도 가드레일이 필요한 이유",
        "link": "https://techblog.lycorp.co.jp/ko/safety-and-cost-saving-why-separate-guardrails-are-necessary",
        "pubDate": "Wed, 17 Dec 2025 02:00:00 GMT",
        "content": "들어가며: 가드레일이 뭔가요?AI를 안전하게 사용하기 위한 여러 장치를 통틀어 보통 '가드레일(guardrails)'이라고 부릅니다. 자동차 주행 중 도로를 벗어나거나 옆 차선을 ...",
        "contentSnippet": "들어가며: 가드레일이 뭔가요?AI를 안전하게 사용하기 위한 여러 장치를 통틀어 보통 '가드레일(guardrails)'이라고 부릅니다. 자동차 주행 중 도로를 벗어나거나 옆 차선을 ...",
        "guid": "https://techblog.lycorp.co.jp/ko/safety-and-cost-saving-why-separate-guardrails-are-necessary",
        "isoDate": "2025-12-17T02:00:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황의윤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": []
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "쿠팡 엔지니어링",
    "category": "기업",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "리멤버 (드라마 앤 컴퍼니)",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "관중 1200만 시대, 한국 프로야구 인기의 비결",
        "link": "https://toss.im/tossfeed/article/moneyball-8",
        "pubDate": "Fri, 19 Dec 2025 08:58:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}2025 시즌 KBO 리그(한국 프로야구 리그)는 관중 1,201만 9,267명을 기록하며 역대 최고 흥행을 달성했습니다..css-1kxrhf3{white-space:pre-wrap;} 경기당 평균 관중도 1만 7,101명으로 그 어느 때보다 많은 분들이 야구장을 찾으셨죠. 전문가들은 야구장에서는 응원과 먹거리 등 경기 외에도 즐길 콘텐츠가 많다는 점에 주목합니다. 특유의 응원 문화와 가성비 좋은 야외 활동이라는 점이 MZ세대의 성향과 잘 맞아떨어졌다는 분석인 거죠.\n하지만 이런 분석만으로는 2025 시즌 가을야구 누적 시청자 2,700만 명이라는 숫자를 설명하기에 충분치 않습니다. 프로야구는 직관뿐 아니라 TV 시청에서도 여전히 한국에서 가장 강력한 스포츠인데요. 오랜 시간 동안 한국 스포츠의 중심을 지켜온 프로야구 인기의 비결은 무엇일까요?\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}관중으로 가득 찬 잠실 구장 / 사진: Kim Hong-Ji\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}지역과 도시를 상징하는\n프로야구의 탄생\n프로야구팀은 1982년 출범 때부터 지역 정체성을 상징하는 존재였습니다. 팬이 아니라면 프로축구나 프로농구는 팀 연고지를 잘 모르는 경우가 많지만, 프로야구는 달랐죠. 자이언츠, 타이거즈 같은 이름만 들어도 대부분의 한국인들은 이 팀의 연고 도시를 알고 있었으니까요.\n\n이런 지역성은 우연히 만들어진 것이 아닙니다. 1970년대 전성기를 누렸던 고교야구는 지역 명문고들의 각축장이었고, 고등학교를 졸업한 선수는 자연스럽게 같은 지역 프로팀에 입단했어요. 지역 팬들이 관심과 응원을 보낼 수밖에 없는 구조였죠. 이때 만들어진 '지역 연고 시스템'은 프로야구의 강력한 자산이 되었습니다.\n반면 프로축구는 초창기부터 홈·원정 체제 없이 전국을 돌며 경기를 했어요. 게다가 축구는 국가대표 중심의 팬덤 구조가 더 강했기 때문에 특정 지역과 깊은 유대가 생기기 어려웠습니다.\n높은 TV 시청률과\n어린이 회원 열풍\n프로야구 경기는 80년대 TV 최고 인기 프로그램 중 하나였습니다. 당시 TV 평균 시청률은 약 16%였는데, 프로야구 중계는 23%를 넘었어요. 특히 한국시리즈는 국민적 관심이 집중되는 콘텐츠였습니다. 1991년 해태 타이거즈와 빙그레 이글스가 맞붙은 한국시리즈 평균 시청률은 20%, 최고 시청률은 28%에 육박했죠. \n야구 인기에 힘입어 1980년대 초등학생들은 학교가 끝나면 공터에서 야구를 하고, 자연스럽게 야구팀 어린이 회원이 되었습니다. 어린 시절의 경험은 시간이 지나면서 가장 오래 남는 팬심이 되기 마련이죠. 프로야구는 미래의 팬층을 일찍 확보했고, 인기는 1990년대 중반까지 이어졌어요. \n박찬호와 월드컵 붐이 만든\nKBO 리그 침체기 \n1995년에 경기당 평균 관중 1만 명을 넘기며 500만 관중 시대를 열었던 프로야구는 1990년대 후반부터 암흑기에 들어섰어요. IMF 외환위기 상황에서 한국인들의 희망이었던 코리안 특급 박찬호의 전성 시대와 한일 월드컵 개최라는 두 가지 요인 때문이었죠.\n\n실의에 빠진 국민들에게 힘을 던져준 박찬호 / 사진: Str Old\n국민들은 더 이상 프로야구가 아닌 박찬호의 MLB 경기에 집중했습니다. 박찬호가 5일에 한 번씩 마운드에 오를 때 전 국민은 그의 투구를 지켜봤고 미디어에서는 그의 일거수 일투족을 다룬 수많은 기사와 리포트를 쏟아냈습니다. \n프로야구가 박찬호 신드롬으로 흔들리던 사이, 또 다른 거대한 파도도 몰려왔어요. 바로 월드컵이었죠. 2002 한일 월드컵 공동개최 확정 뉴스도 프로야구의 흥행을 위축시켰습니다. 1998년 프로야구는 관중 5,000명대에 머물렀지만, 프로축구 경기당 관중 수는 1만 4,000명으로 전년도에 비해 두 배나 늘어났습니다.\n\n올림픽 금메달과 롯데 열풍이\n불러온 반등의 시작\n침체되었던 프로야구 인기는 2007년부터 다시 상승세로 돌아섰습니다. 2006년부터 2009년까지 한국 야구가 유례없는 황금기를 맞았거든요. 한국 야구 국가대표팀은 2006년 WBC(월드베이스볼클래식) 4강을 시작으로, 2008년 베이징 올림픽 금메달과 2009년 WBC 준우승을 기록했죠.\n좋은 국제대회 성적 덕분에 한국 프로야구는 '명품 야구'라는 평가까지 받게 됐고, 특히 일본과의 경기에서 좋은 모습을 보이면서 야구 국가대표팀을 응원하는 '푸른 악마' 신드롬도 생겨났어요. 야구 국가대표팀 핵심 선수들이 대부분 한국 프로야구 무대에서 뛰고 있었다는 점도 큰 힘이 됐습니다. 이는 주요 선수들이 해외 리그에 진출한 축구 국가대표팀과는 다른 부분이었죠.\n국제대회 성적만큼 중요했던 것은 KBO의 구조적 변화였어요. 2011년부터 FA(자유계약선수) 제도*가 개선되면서 스타 선수들의 구단 이동이 활발해졌고, 팬들의 관심을 불러일으키는 계기가 됐습니다.\n* 일정 기간 이상 뛴 선수가 원하는 구단과 자유롭게 계약할 수 있는 제도\n\n2008 베이징 올림픽 우승을 차지한 한국 야구 국가대표팀 / 사진:Danny Moloshok\n전 경기 중계 시대 개막\n국제대회 성적만큼 중요한 변화는 2008년부터 프로야구 전 경기 중계가 이뤄졌다는 점이에요. 이전에는 각 방송사의 중계가 모든 경기를 커버하지 못했습니다. 그런데 2008년부터 Xports가 중계권을 얻으면서 케이블 4사(MBC ESPN, SBS Sports, KBS N Sports, Xports)가 4개 구장에서 열리는 8팀의 경기를 모두 중계할 수 있는 체제가 갖춰진 거죠.\n전 경기 중계 체제가 자리 잡으면서 프로야구는 미디어 콘텐츠로 다시 한번 진화하게 돼요. 팬들은 포털 사이트를 통해 무료로 모든 경기를 볼 수 있게 됐고, 다양한 경기 하이라이트 콘텐츠도 즐길 수 있었어요. 경기가 끝나자마자 방송사에서 모든 경기의 리뷰 프로그램을 제작할 수 있었고, 이를 통해 야구 전문 해설진들도 대중적 인지도를 얻게 됐습니다.\n이를 계기로 프로야구는 다시 500만 관중 시대를 열었습니다. 이때 2000년 이후 처음으로 가을야구에 진출한 '만년 하위팀' 롯데의 역할도 컸어요. 이때부터 프로야구는 코로나 팬데믹 기간을 제외하면 항상 평균 관중 1만 명 이상을 기록했죠.\n케이블 채널의 프로야구 중계 평균 시청률은 0.8~1.2%를 꾸준히 유지하고 있어요. 케이블 TV에서 인기 프로그램의 시청률이 1%대라는 점을 감안하면, 프로야구의 인기를 실감할 수 있습니다.\n\n뉴미디어 산업이 키운\n중계권 성장의 시대\n야구에 대한 전 국민적 관심 덕분에 2011년 프로야구 중계권 수입은 250억 원으로 상승했어요. 전년 대비 50% 늘어난 수치죠. 입장료 수입도 역대 최고인 551억 원을 넘겼고, 스폰서십 수입 역시 전년보다 40% 증가한 70억 원을 기록했습니다.\n1982년 2억 8,000만 원으로 출발했던 프로야구 중계권료는 2022년 기준 연간 760억 원까지 올랐어요. 이 중 뉴미디어 중계권료만 220억 원이었는데, 이 금액은 2022년 K리그(112억 원), 프로농구(30억 원), 프로배구(60억 원)의 중계권료를 모두 합친 것보다 더 많았죠.\n2024년 프로야구 미디어 시장은 또 한 번 도약을 이뤘습니다. 지상파와 스포츠 채널 방송사들은 경영 악화로 인해 2021년과 동일한 540억 원에 중계권 계약을 연장했지만, OTT 서비스 ‘티빙’을 운영하는 CJ ENM이 450억 원을 지불하면서 프로야구 뉴미디어 중계권 사업자가 됐어요.\n덕분에 2024년 방송사와 뉴미디어가 지불한 전체 중계권료는 990억 원까지 올랐어요. 이 금액은 10개 구단에 고르게 분배되기 때문에, 한 구단이 약 99억 원을 수입으로 가져가게 되죠. 이는 프로야구 톱클래스 선수 6~7명의 연봉을 합친 것과 비슷한 수준이에요. 프로야구 뉴미디어 중계권은 2026 시즌을 앞두고 다시 한 번 상승할 것으로 예상되고 있습니다.\n\n피크닉과 콘서트로 진화한\n관람 경험의 확장\n코로나 팬데믹은 야외 체험형 콘텐츠에 대한 관심을 크게 높였습니다. 프로야구는 이 변화의 가장 큰 수혜자였죠. 야구는 경기를 보면서 음식을 먹고 마시는 데 잘 어울리는 종목이에요. 여기에 프로야구 특유의 응원 문화가 더해지면서 매력이 커졌죠.\n이제 젊은 팬들은 야구장을 '야구만 보는 곳'으로 생각하지 않아요. 친구들과 야외에서 이야기하고, 응원가를 따라 부르고, 음식을 즐기는 피크닉과 콘서트가 결합된 다목적 공간에 가깝습니다. 즉, 팬들은 더 이상 ‘경기’를 소비하는 것이 아니라 '하루'를 소비하고 있는 셈입니다.\n젊은 팬들의 다양한 체험이 하나의 트렌드가 될 수 있었던 데에는 프로야구 경기장의 변화도 큰 역할을 했어요. 2010년부터 프로야구팀 홈구장 가운데 무려 5개가 신축됐고, 광주 기아 챔피언스 필드, 대구 삼성 라이온즈 파크, 대전 한화생명 볼파크 등은 지역의 랜드마크로 자리 잡았습니다.\n이런 변화 덕분에 젊은 세대는 야구장을 ‘한번쯤 가보고 싶은 공간’으로 인식하게 됐습니다. 게다가 신축 구장을 지은 구단들의 성적이 향상되면서 지역 팬들의 관람 욕구도 더 커졌어요. 프로야구 10개 구단의 총 입장 수입은 2022년 900억 원에서 2024년 1,594억 원으로 증가했고, 2025년에는 2,000억 원을 넘을 것으로 추정하고 있어요. \n\n2014년에 개장한 광주-기아 챔피언스 필드 / 사진: KIA 타이거즈\n유니폼을 포함한 구단 기념품 판매 수입도 크게 늘었습니다. 2024년 기아 타이거즈의 기념품 판매 수입은 전년 대비 무려 340% 증가했고, 이 가운데 팀의 인기 스타 김도영 선수 유니폼 판매액은 110억 원이나 됐어요.\n기념품 판매가 늘어난 데에는 프로야구의 폭발적 인기뿐 아니라, 아이돌 문화에 익숙한 MZ세대의 소비 패턴도 영향을 미쳤다는 분석이 많습니다. 무엇보다 중요한 점은 프로야구가 국내 다른 프로스포츠보다 여성 팬 비율이 훨씬 높다는 사실이에요. 2025년 프로야구 팬 가운데 여성 비율은 약 57.5%로 추산됩니다. 이 역시 기념품 판매 증가에 긍정적 영향을 미쳤죠.\n경기력 너머에서\n만들어진 팬덤의 힘\n일부 전문가들은 최근 한국 야구가 국제대회에서 저조한 성적을 기록했고, 프로야구 경기 퀄리티도 예전만 못하다는 점에서 우려를 표하고 있어요. 선수 수급 문제도 심각합니다. 고교야구가 쇠퇴하면서 유소년 야구 인구가 감소하고 있고, 주요 스타 선수들의 MLB 진출로 인한 공백도 우려되는 상황이죠. 경기 시간이 평균 3시간을 넘어서면서 짧은 콘텐츠에 익숙한 MZ세대의 집중력을 잃을 수 있다는 지적도 있습니다.\n그럼에도 프로야구의 인기는 당분간 이어질 가능성이 커요. 지금 야구장을 찾는 팬들은 경기 자체보다 경기장에서의 체험에 더 큰 관심을 기울이고 있기 때문이죠.\n2025년 KBO가 실시한 신규 관람자 조사에서도 이런 흐름이 확인됩니다. 신규 관람자들이 야구장을 찾은 가장 큰 이유는 응원 문화가 재미있을 것 같아서였고(33.8%), 그다음으로는 치맥 등 먹거리 문화를 경험해보고 싶어서였어요(19.9%). 다시 말해, 응원과 F&B 문화를 중심으로 한 야구장만의 체험 요소가 관람을 시작하게 만든 가장 큰 동기라고 볼 수 있어요.\n2025년 KBO가 공개한 포스트시즌 시청 데이터를 보면, 가을야구 누적 시청자 수는 2,687만 명을 넘었습니다. 산술적으로는 세대당 1명꼴로 올 시즌 가을야구를 시청한 셈이죠. 국내 어떤 프로 스포츠도 따라오기 어려운 이 엄청난 시청자 규모는, 프로야구가 젊은 세대를 넘어 중장년층까지 폭넓은 소구력을 갖고 있다는 뜻이기도 해요. \n프로야구 팬덤은 하루아침에 만들어진 것이 아닙니다. 40년 넘게 지역 정체성과 세대 경험, 그리고 진화하는 미디어 생태계가 만들어낸 구조적 성과죠. 1,200만 관중 시대의 비결은 바로 오랜 시간의 축적에 있습니다. 이렇게 쌓여온 문화가 앞으로 어떤 모습으로 진화할지 기대해봐도 좋겠습니다.\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 윤동해 Graphic 이은호 윤자영",
        "content": "지역, 세대, 미디어가 만든 K-스포츠 팬덤의 탄생",
        "contentSnippet": "지역, 세대, 미디어가 만든 K-스포츠 팬덤의 탄생",
        "guid": "https://toss.im/tossfeed/article/moneyball-8",
        "isoDate": "2025-12-19T08:58:00.000Z"
      },
      {
        "title": "요즘 사람들의 경제 매거진 〈더 머니이슈〉, 지금 읽어야 하는 이유",
        "link": "https://toss.im/tossfeed/article/the-money-issue-pick",
        "pubDate": "Fri, 19 Dec 2025 01:24:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}“토스 다니면 재테크도 잘하시겠네요?” \n종종 듣게 되는 이 질문 앞에 당당하게 끄덕일 팀원이 얼마나 되는지는 모르겠지만, 일단 저는 아닙니다. 통장 속살까지 보여드리기는 어려우나 앞으로도 꽤 오래 일해야 할 거 같다는 슬픔만 전해 드립니다. \n그럼에도 분명하게 말할 수 있는 것은, 토스에 입사해 여러 경제 전문가를 만나고 요즘 사람들에게 꼭 필요한 금융생활 정보와 지식을 전하는 동안 금융자산도 늘고 노후 대비라는 것도 시작하며 사람답게(?) 살 수 있게 되었다는 것이에요. \n‘돈 공부’를 제대로 못해 늘 뒤처진 기분을 느끼다 이제 좀 알 것 같은 상태가 된 (저를 비롯한) 팀원들, 그래서 독자님들의 팔을 붙잡고 .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}“지금 이것만은 꼭 아셔야 해요” “여기까지는 한번 해보시겠어요?”라는 마음으로 콘텐츠를 만들다 매거진까지 출간하게 된 팀원들이 모니터 뒤에 있습니다. 이들에게 〈더 머니이슈〉에서 꼭 읽어야 하는 아티클이 무엇인지 물었어요. \n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n인플루언서 따라 질러버린 새 옷은 정말 내 취향일까?\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}올해 인생 최대 소비를 달성한\n콘텐츠 매니저 동해’s pick\n최근에 지른 것들이 정말 내가 원해서 산 것이 맞는지 의심스러울 때가 있어요. 인플루언서들의 근사한 사진들로 뺵빽하게 채워진 피드를 보다가 나도 모르게 따라 산 건 아닐까 하는 생각이 들곤 하거든요. ‘나만의 취향’이 중요한 시대인데 남의 소비를 따르는 것도 결국 내 취향을 만들어줄까요? \n평생 돈과 떼려야 뗄 수 없는 관계로 살아가면서도 정작 돈이 나에게 어떤 의미인지, 최근 소비생활이 내 삶을 어디로 이끌고 있는지 돌아볼 기회는 없었던 것 같아요. 저처럼 돈에 관한 나만의 관점을 가지고 싶은 분들이라면 〈더 머니이슈〉를 읽으면서 분명 한층 깊어진 시야를 갖게 될 거예요!\n\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n\n돈 고민을 털어놓으면 전문가는 어떤 이야기를 해줄까?\n한번쯤 자산 관리 상담을 받아보고 싶은\n브랜드 디자이너 석원’s pick\n늘 다른 사람들은 돈 관리를 어떻게 하나 궁금해요. 이 글을 읽으면서 ‘내 씀씀이에 비해 벌이가 너무 적다’, 혹은 ‘벌이에 비해 저축이 턱없이 부족하다’ 등 사연 속에 구체적인 숫자와 공감 가는 상황들이 담겨 있어 내 상황과 대조해보는 재미가 있었어요. 여기에 전문가가 사연자의 돈 고민 뒤에 숨은 ’진짜 고민’을 짚어내며 건네는 현실적이고도 따뜻한 조언이 와닿았습니다. \n가진 돈이 한 줌이어도 자산 관리가 필요할까?\n돈 관리 늦게 시작한 만큼 잘해보고 싶은\n콘텐츠 매니저 소은’s pick \n’자산 관리’라고 하면 돈 많은 사람들의 일 같지만, 자산 관리를 시작해야 하는 건 바로 지금의 우리더라고요. 이 글은 어째서 지금 시작하라는 건지, 뭘 어떻게 하라는 건지 알려주며 무거운 엉덩이를 뗄 수 있도록 밀어주는 글이에요.\n얼마 전 에어로케이 비행기 안에서 〈더 머니이슈〉를 읽는 재밌는 이벤트를 진행했어요. 저는 침착한 척하면서 승객 분들이 매거진 읽는 모습을 힐끔힐끔 관찰했는데, 많은 분들이 이 글을 빨려들 듯 집중해서 보고 계셨어요. 필요했던 글이라는 걸 직감할 수 있었습니다.\n아직 잘 모른다는 이유로 '돈과 함께 잘 살아가고 있다는 감각'을 미뤄왔다면, 다른 사람들의 리얼한 돈 이야기와 팁을 읽으며 새해의 변화를 계획해 보시길 바라요.\n\n\n질 좋은 1인분의 삶, 원소윤은 어떻게 만들어가고 있을까?\n저축, 투자 얘기가 아직 두렵고 멀게 느껴지는\n그래픽 디자이너 수희’s pick \n스탠드업 코미디언 원소윤 님의 인터뷰를 읽으며 ‘돈이 되는 것’에 대해 더 넓게 생각해볼 수 있었어요. 특히 ‘퇴사’를 하나의 투자로 바라보고, 자신이 무엇을 좋아하는지 예리하게 알아차리는 감각을 기르는 것을 투자 개념으로 확장하는 관점이 인상 깊었습니다. 시간을 돈의 관점에서 다시 바라보니 내가 지금 ‘시간을 쓰는 방법’이 결국 나에게 어떤 ‘투자’로 돌아올지 더 멀리 상상해보게 되었어요. \n‘어떻게 모으고 투자할 것인가’라는 방법보다 먼저 ‘어떤 가치관으로 돈을 바라보고 살아갈 것인가’를 생각해볼 수 있는 지점들을 만들어준 글이라 추천합니다. \n나는 AI에 대체되지 않을 수 있을까?\n커리어를 쌓으며 ‘1인분’을 잘 해내고 싶은\n마케팅 어시스턴트 민지’s pick\n정보 검색부터 고민 상담까지 AI를 매일 쓰면서 매일 놀라다 보니 “AI가 일자리를 대체할 것이다”라는 말이 현실로 느껴져요. 그러던 중 이 인터뷰를 읽고 곧 나의 능력이 AI에 대체되는 건 아닌가? 하는 막연한 불안함이 좀 해소됐어요. AI를 경쟁자가 아닌 동료로 생각하는 마인드셋, AI를 잘 활용하는 법, 그럼에도 인간만이 할 수 있는 것은 무엇인지 생각하게 해준 글입니다.\n\n\n연봉 1억 원 찍으면 행복해질까?\n열심히 달리다 이제 일상을 돌볼 예정인\n콘텐츠 마케터 수지’s pick\n\"취업만 하면, 이직해서 연봉 오르면, 집만 사면…” \n나의 행복에도 자꾸 물질적 조건을 걸게 만드는 분위기 속에서 사실은 더 자주 행복할 방법이 있다고 알려주는 글을 만나서 숨통이 트이는 느낌이었어요. 결국 내가 행복해야 잘 벌고, 잘 쓰고, 잘 사는 거 아니겠어요!\n돈에 관한 관심은 결국 나답게, 좋은 삶을 살기 위한 관심과도 같다는 걸 더 많은 분들이 느낄 수 있기를 바라요. \n좋아하는 일로 N잡을 시작할 수 있을까?\n하고 싶은 건 많지만 뭘 실행할지 고민 중인\n콘텐츠 매니저 지영’s pick\n회사 다니면서 1천만 원으로 카페를 연 이야기부터, 인스타 덕질 계정으로 수익을 낸 경험, 고양이를 돌보며 커피값을 버는 방법까지. 직장인이라면 한 번쯤 상상해봤을 ‘부업’들을 실제로 실행해본 사람들의 생생한 경험이 담겨 있어요.\nN잡의 첫 삽을 뜨기까지 어떤 고민을 했는지, 어떤 선택이 어려웠는지, 그리고 현실의 벽에 부딪혀 어떤 좌절과 실패를 겪었는지까지. 현실적인 과정이 고스란히 드러나는 점이 특히 흥미로워요. \n우당탕탕 좌충우돌 'N잡' 경험기를 읽다 보면 내가 좋아하는 일은 뭘까? 나도 한번 해볼 수 있을까? 같은 생각과 용기가 은근슬쩍 떠올라요. 퇴근 후 침대에 누워 릴스를 무한 스크롤하던 제 삶에도 “나도 뭔가 해보고 싶다!”는 작은 불씨가 켜졌달까요.\n“인생에 정답은 없다지만, 내가 맞는 방향으로 가고 있는걸까?\" 싶은 사람들에게 〈더 머니이슈〉를 권하고 싶어요. 나의 걸음에 확신과 용기가 필요한 시기를 보내고 계셨다면, 여기서 작은 동력을 발견하실 거예요.\n\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}Words 권민지, 김수지, 윤동해, 이지영, 조수희, 황석원\nPhoto 이욱영",
        "content": "담당 에디터, 마케터, 디자이너의 원픽 아티클을 소개해요 ",
        "contentSnippet": "담당 에디터, 마케터, 디자이너의 원픽 아티클을 소개해요",
        "guid": "https://toss.im/tossfeed/article/the-money-issue-pick",
        "isoDate": "2025-12-19T01:24:00.000Z"
      },
      {
        "title": "결혼식 패키지 상품 가격, 이제 사전에 정확하게 알 수 있어요",
        "link": "https://toss.im/tossfeed/article/money-policies-56",
        "pubDate": "Tue, 16 Dec 2025 08:14:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}결혼식장 예약부터 사진 촬영, 이른바 ‘스드메(스튜디오·드레스·메이크업)’ 상품까지. 결혼식을 앞두고 알아봐야 할 것이 너무 많아 걱정이신가요? 예산 안에서 결혼식을 준비하며 생기는 고민들을 덜어주기 위해 .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}‘중요한 표시·광고사항 고시’ 개정안이 11월 12일부터 시행 중이에요.\n그동안 결혼 준비 과정에서 스드메 같은 패키지 상품 등은 세부 요금을 소비자가 사전에 정확하게 알기 어렵고 계약 체결 후 예상치 못한 다양한 옵션까지 추가되면서 ‘추가금 폭탄’을 맞는 사례가 꾸준히 생겼어요. 이번 조치는 이런 ‘깜깜이 계약’ 문제를 해결해 예비부부가 결혼 비용을 사전에 충분히 예측할 수 있도록 개선한 거예요.\n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n어떻게 달라지나요?\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n결혼서비스 사업자는 요금체계, 환급 기준, 보증보험 가입 여부 등을 사전에 공개해야 해요.\n예식장업 및 결혼준비대행업자는 기본 서비스 구성, 선택 옵션 항목별 요금, 계약 해지 시 위약금·환급 기준 등을 사업자 사이트 또는 .css-iynyr0{white-space:pre-wrap;cursor:pointer;color:var(--adaptiveGrey600);-webkit-text-decoration:underline!important;text-decoration:underline!important;}한국소비자원 ‘참가격’ 사이트 중 한 곳과 계약서에 반드시 표시해야 해요.\n계약서 앞면 표지부 서식을 마련해 스드메 등 기본 서비스와 담당자 지정, 드레스 도우미, 헤어피스 등 추가 옵션의 내용을 한눈에 확인할 수 있게 해야 해요.\n기본 서비스와 추가 옵션의 세부 가격은 스드메 서비스별 가격표에 표시하고 이용자에겐 상세히 설명해야 해요.\n사진파일(원본·수정본) 구입비, 드레스 피팅비, 메이크업 얼리스타트비(아침 시간 서비스 제공) 등 사실상 필수 서비스임에도 추가 옵션으로 구성됐던 항목은 이제 기본 서비스에 포함해야 해요.\n\n한편 결혼서비스업계도 이 같은 정보 제공 강화 취지에 동참해 ‘예식장 매칭 서비스’를 수도권에서 시범 운영하기로 했어요.\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}예식장 매칭 서비스란?\n\n잔여 예식홀을 보유한 예식장 정보를 예비부부에게 연결하는 서비스에요.\n자세한 내용은 한국예식업중앙회 사무국(02-3443-3788)을 통해 문의할 수 있어요.\n\n더불어 결혼 서비스 등 관련 불편사항에 대해 전화 상담(국번 없이 1372)을 통해 문의할 수 있어요. 그동안 제도적 사각지대에 놓였던 분야의 정보 제공이 강화되는 만큼 안심하고 행복한 결혼식을 준비해보세요!\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 권민지 이지영 Graphic 윤자영",
        "content": "추가금 걱정 없이 결혼식 비용 미리 확인해보세요",
        "contentSnippet": "추가금 걱정 없이 결혼식 비용 미리 확인해보세요",
        "guid": "https://toss.im/tossfeed/article/money-policies-56",
        "isoDate": "2025-12-16T08:14:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]