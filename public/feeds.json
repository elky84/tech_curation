[
  {
    "name": "C++ Team Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Facebook Engineering",
    "category": "기업",
    "posts": [
      {
        "creator": "",
        "title": "Disaggregated Scheduled Fabric: Scaling Meta’s AI Journey",
        "link": "https://engineering.fb.com/2025/10/20/data-center-engineering/disaggregated-scheduled-fabric-scaling-metas-ai-journey/",
        "pubDate": "Mon, 20 Oct 2025 16:00:37 +0000",
        "content:encodedSnippet": "Disaggregated Schedule Fabric (DSF) is Meta’s next-generation network fabric technology for AI training networks that addresses the challenges of existing Clos-based networks.\nWe’re sharing the challenges and innovations surrounding DSF and discussing future directions, including the creation of mega clusters through DSF and non-DSF region interconnectivity, as well as the exploration of alternative switching technologies.\nDisaggregated Schedule Fabric (DSF) is Meta’s next-generation network fabric. The GenAI boom has created a surge in demand for high-performance, low-latency, and lossless AI networks to support training AI models at a large scale. DSF helps us build scalable AI networks by breaking the physical limit of the traditional monolithic chassis-switch architecture. By disaggregating line cards and fabric cards into distinct, interconnected hardware devices, the DSF network creates a distributed system that offers scalability and performance for AI networks. \nDSF is a VOQ-based system powered by the open OCP-SAI standard and FBOSS with a modular architecture designed to optimize load balancing and congestion control, ensuring high performance for both intra and inter-cluster traffic. \nWith DSF we’ve already been able to build increasingly larger clusters that interconnect thousands of GPUs in a data center region. \n\nBackground: Our Challenges With Traditional IP Fabric\nWhile running training jobs over traditional IP fabric, we faced several challenges. These problems were specific to training applications that use remote direct memory access (RDMA) technology, which uses UDP protocol to exchange data. \nWe encountered these three types of problems:\nElephant flows: AI workloads tend to have long-duration, heavy-traffic flows that have the potential to congest the fabric links they hash onto and create head-of-the-line blocking. \nLow entropy: Depending on the number of GPUs involved in the collective operations, the number of IP flows could be lower, which results in inefficient hashing and, possibly, in congestion, despite the availability of adequate capacity in the fabric.\nSuboptimal fabric utilization: We have observed that, as a combined effect, there is a large skew in the bandwidth utilization of fabric links. This is important data because it impacts how much we should overprovision the fabric to support good pacing and  maintain steady performance in the event of failures.\nWe tried several solutions to handle these issues, but each presented challenges. For example, we created Border Gateway Protocol (BGP) policies such that when traffic is received from accelerators via leaf switches, it is pinned to a specific uplink, depending on its destination. This alleviated the problem of low entropy in steady state but didn’t handle failure scenarios where the fallback was equal-cost multipath (ECMP) routing.\nWe also tried load-aware ECMP schemes that could handle fat flows and low entropy, but they were difficult to tune and created out-of-order packets, which is detrimental to RDMA communication.\nWe also created a traffic-engineering solution that would pre-compute the flow pattern depending on the models used and configure the leaf switches before the job starts. This could handle fat flows and low entropy but grew too complex as network size increased. And due to its centralized nature, this set-up was slow to react to failures.\nA Primer on Disaggregated Scheduled Fabric \nThe idea behind DSF stems from the aforementioned characteristics of AI training workloads, particularly their tendency to generate “elephant flows” — extraordinarily large, continuous data streams — and “low entropy” traffic patterns that exhibit limited variation in flow and result in hash collisions and sub-optimal load distribution across network paths. The fundamental innovation of DSF lies in its two-domain architecture, which separates the network into the Ethernet domain, where servers and traditional networking protocols operate, and the “fabric” domain, where packets will be broken into cells, sprayed across the fabric, and subsequently reassembled at the hardware before being delivered back to the Ethernet domain.\nDSF is built on two components: interface nodes (INs), also referred to as rack disaggregated switches (RDSWs), and fabric nodes (FNs), known as fabric disaggregated switches (FDSWs). INs serve as the network-facing components that handle external connectivity and routing functions, and that interface with the broader data center infrastructure. FNs operate as internal switching elements dedicated to high-speed traffic distribution across the fabric without requiring Layer 3 routing capabilities. \nTo the external network infrastructure, this distributed collection of INs and FNs appears as a single, unified switch, with the total number of external ports equivalent to the aggregate of all external ports across all INs, effectively creating a virtual chassis switch that scales far beyond the physical limitations of traditional designs. The control plane that orchestrates this distributed system is built upon Meta’s FBOSS, an open-source network operating system that supports the multi-ASIC control requirements of disaggregated fabrics. Its communication with FBOSS State DataBase (FSBD) enables real-time state synchronization across nodes.\nDSF achieves traffic management by packet spraying and a credit-based, congestion control algorithm. Unlike conventional Ethernet fabrics that rely on hash-based approaches, DSF utilizes packet spraying that distributes traffic across all available paths through the fabric. Such a feature is enabled by the hardware’s ability to reassemble packet cells at the interface nodes within the fabric domain while ensuring in-order delivery to end hosts. \nThis packet-spraying capability is orchestrated through a credit-based allocation scheme where ingress INs dynamically request credit tokens from egress INs, allowing the system to make real-time decisions based on current path availability, congestion levels, and bandwidth utilization. Virtual output queuing (VOQ) helps with ensuring lossless delivery throughout this process, directing incoming packets to virtual output queues targeting specific destination ports and service classes, with each virtual output queue being scheduled independently for transmission, providing fine-grained traffic management that can accommodate the requirements of AI workloads and communication patterns.\nThis approach allows DSF to achieve near-optimal load balancing across all available network paths, effectively utilizing the full bandwidth capacity of the fabric. It provides the flexibility to handle mixed traffic patterns and adapt to dynamic network conditions without requiring manual reconfiguration or traffic engineering.\nDSF Fabric for GenAI Applications\nDSF Fabric (GenAI) \nUsing the DSF technology, we built a massive cluster that interconnects thousands of GPUs within a data center region. Figure 1 illustrates the network topology of a single AI zone that is a building block for the larger cluster.\nFigure 1: A building block of a single DSF L1 zone.\nAn AI zone contains multiple scaling units, shown in Figure 1 as “SUx.” A scaling unit is a grouping of GPU racks connected to RDSWs within the scaling unit. All the RDSWs within the AI zone are connected via a common layer of FDSWs. RDSWs are powered by deep-buffer Jerico3-AI chips, while FDSWs use Ramon3 chips. FBOSS is the network operating system for all the roles in this topology. We are using 2x400G FR4 optics between RDSW-FDSW connections.\nThe GPU to RDSW connections are rail optimized, which benefits hierarchical collectives like allreduce and allgather, both of which are latency sensitive.\nTo support high GPU scale in a single AI zone, two network planes that are identical to each other are created. This is called a DSF L1 zone and is a building block for larger GenAI clusters, as we will see in the next section.\nDSF Dual-Stage Fabric (GenAI)\nAs depicted in Figure 2 (below) we interconnected 4x DSF L1 zones through a second stage of spine DSF switches (SDSWs). SDSWs use the same hardware as FDSWs and aggregate DSF L1 zones, enabling them to act as a single DSF fabric. This is a non-blocking topology providing an interconnected GPU scale of 18K x 800G GPUs. \nFigure 2: A DSF L2 zone with a second stage of SDSW interconnecting four L1 zones.\nAll RDSWs in this topology maintain fully meshed FDSB sessions to exchange information such as IPv6 neighbor states. There is also an innovative feature — input-balanced mode — enabled over this fabric to smartly balance the reachability info across the layers such that, in case of failures, congestion is avoided over the fabric and spine layer. This feature will be explained in a separate section below. We call this topology the DSF L2 zone.\nDSF Region (GenAI)\nTo achieve a larger interconnected GPU scale, we connected 5x DSF L2 zones via the L3 super-spine layer. (See Figure 3 below.) We did this by using a special edge point of delivery (PoD) in each of the buildings. Edge PoDs consist of 40 FDSWs and 128 edge DSF switches (EDSWs). From a hardware point of view, EDSW is the same as RDSW but differs in its function of providing connectivity to the L3 super spine.\nEach EDSW connects to four superspine devices using 4x800G links provisioning a total of 2k x800G ports per edge PoD. \nThe way training models are sharded we don’t expect a lot of traffic transiting the L3 super-spine layer; hence, an oversubscription of 4.5:1 is sufficient.\nThis creates an L3 interconnect, which means we need to exchange the routing information. We created iBGP sessions with EDSW and all RDSWs within the building, with BGP add-path enabled such that RDSWs learn aggregates via all 2k next-hops.  \neBGP is used between EDSW and the L3 super spine, and only aggregates are exchanged over BGP peerings. \nFigure 3: An L3 super spine connecting five DSF L2 zones.\nGiven that L3 spine is used, some of the problems, including entropy and fat flow, tend to reappear; however, at this network tier where there’s much less traffic, those problems are less profound.\nInput Balanced Mode\nInput Balanced Mode is a critical feature that supports balanced traffic throughout the network in the face of remote link failures. The feature avoids severe congestion on the fabric and spine layer of the DSF network.\nMechanism\nThe purpose of Input Balanced Mode is to ensure any DSF devices have equal or less input BW compared to output BW. No oversubscription should occur in the network, even in the case of remote link failure. Devices experiencing link failure will propagate the reduced reachability information across the cluster, notifying other devices to send proportionally less traffic to the affected device. \nFigure 4: A mini-scale DSF network with two clusters connected by two SDSWs.\nNote: For clarity, in Figure 4, FDSW/SDSW are simplified to only show one virtual device. The above graph will be used to illustrate two different link failures and mechanisms.\nRDSW<->FDSW Link Failure\nIn the case of RDSW<->FDSW link failure, RDSW will lose connectivity to the FDSW, hence losing both input and output capacity on the link. FDSW also loses connectivity to the RDSW and then stops advertising the connectivity. In Figure 5 (below) FDSW1 in Cluster X loses connection to RDSW3, hence it stops advertising reachability to SDSW0 and SDSW1.\nFigure 5: Link failure in Cluster X and propagation towards SDSW.\nFrom SDSW0’s perspective, it receives no reachability to RDSW3 from FDSW1 in Cluster X, but still has reachability to RDSW3 through FDSW0. (See Figure 6.) Toward destination RDSW3 in Cluster X, the input capacity of 4 (FDSW0 and FDSW1 from Cluster X-1) is greater than the output capacity of 2 (FDSW0 in Cluster X). To avoid oversubscription, SDSW0 will pick two input links and stop advertising reachability toward RDSW3 in Cluster X. The same sequence will also take place in SDSW1.\nFigure 6: Input Balanced Mode kicks in and stops advertising reachability to FDSWs in Cluster X-1.\nThe link selection for balanced input mode should be randomized. As shown in Figure 7 (below), for simplicity’s sake, assume SDSW0 stops advertising reachability to FDSW0, and SDSW1 stops advertising reachability to FDSW1. Both FDSW0 and FDSW1 have an input capacity of 4 but an output capacity of 2, hence randomly selecting two links on each device to not advertise reachability.\nFigure 7: FDSWs in Cluster X-1 stop advertising reachability to RDSWs.\nAssume FDSW0 randomly selects links to RDSW0 and RDSW1, while FDSW1 randomly selects links to RDSW2 and RDSW3. This completes the propagation of link failure, resulting in RDSWs in Cluster X-1 having 50% capacity to forward traffic toward RDSW3 in Cluster X.\nFDSW<->SDSW Link Failure\nUpon FDSW<->SDSW link failure, there are two directions to propagate the reduced capacity:  1) on FDSW, reduce input capacity from RDSW, and 2) on SDSW, reduce input capacity from FDSWs in other clusters. (See Figure 8)\nFigure 8: Link Failure between SDSW1 and FDSW1 in Cluster X.\nFDSW Propagation\nConsider the traffic egressing out of Cluster X thru FDSW1 (see Figure 9): From FDSW1’s perspective, input capacity is 4 (from RDSW0-RDSW3) while output capacity is reduced to 3 due to link failure. \nTo balance input capacity, FDSW1 will randomly pick one FDSW<->RDSW link to stop advertising reachability to ALL destinations outside of the cluster.\nFigure 9: FDSW1 in Cluster X stops advertising reachability to RDSW2.\nAssume Cluster X FDSW1 randomly picks the link to RDSW2. It will stop advertising reachability to all RDSWs in Cluster X-1. Note that the same link can still be utilized for intra-cluster traffic, as it has full reachability to RDSWs in Cluster X.\nSDSW Propagation\nConsider traffic ingressing into Cluster X thru SDSW1 (see Figure 10): From SDSW1’s perspective, input capacity is 4 (from FDSW0 and FDSW1 in Cluster X-1), while due to link failure, output capacity is 3. SDSW1 will randomly pick one link towards Cluster X-1 and stop advertising reachability to all RDSWs in Cluster X.\nFigure 10: SDSW1 stops advertising reachability to FDSW0 in Cluster X-1.\nA similar calculation will take place on FDSW0 in Cluster X-1, resulting in Cluster X-1 FDSW0 randomly picking one link and stopping advertising reachability to all RDSWs in Cluster X. (See Figure 11 below) This completes the propagation, leading to RDSW1 in Cluster X-1 losing one link to forward traffic toward Cluster X.\nFigure 11: Input Balanced Mode propagation from FDSW0 to RDSW1 in Cluster X-1.\nFDSW<->SDSW and RDSW<->FDSW Link Failure\nFigure 12 illustrates another example of link failures occurring in between FDSW <-> SDSW, as well as RDSW <-> FDSW. The reduced reachability will propagate and then converge in both directions.\nFDSW<->SDSW link failure.\nRDSW<->FDSW link failure.\nFigure 12: Link failures in both FDSW<->RDSW and SDSW<->FDSW.\nFDSW Propagation for FDSW<->SDSW Link Failure \nSimilar to the above FDSW propagation, FDSW1 in cluster X will randomly pick one connecting RDSW and advertise no reachability to devices towards Cluster X-1. (See Figure 13 below) \nFigure 13: FDSW1 in Cluster X stops advertising reachability to RDSW2.\nSDSW propagation for FDSW<->SDSW Link Failure\nSimilar to the SDSW propagation above, SDSW1 will randomly pick one link towards cluster X-1 and propagate no reachability to Cluster X. Imagine SDSW1 picks one of the links connecting FDSW0 in cluster X-1.\nFigure 14: SDSW1 stops advertising reachability to FDSW0 in Cluster X-1.\nNote in Figure 14 that FDSW0 in Cluster X-1 already has one link failure connecting RDSW0. The input and output capacity towards Cluster X is already balanced on FDSW0, thus finishing propagation in this direction.\nFDSW Propagation for RDSW<->FDSW Link Failure \nAs FDSW0 in Cluster X-1 loses connectivity to RDSW0, it will stop advertising reachability to SDSW0 and SDSW1 on both of the links. (See Figure 15.)\nFigure 15: Link failure in Cluster X-1 and propagation towards SDSW.\nSDSW0 will randomly pick two links to stop advertising reachability to RDSW0 in Cluster X-1 (in the example in Figure 16 it picks one link in FDSW0 and one in FDSW1). On SDSW1, however, it already has one link failure connecting FDSW1 in Cluster X. Therefore, only one more link needs to be selected to propagate the reduced reachability (in the example it picks the other link towards FDSW1).  \nFigure 16: Input Balanced Mode kicks in and stops advertising reachability to FDSWs in Cluster X.\nFrom Cluster X FDSW1’s perspective, the output capacity towards RDSW0 in Cluster X-1 is 1 (two links with no reachability, and one link failure). Therefore, to balance input it should select three links to stop advertising reachability towards RDSW0 in Cluster X-1. Note that the link FDSW1<->RDSW2 already has no reachability towards Cluster X-1 due to 1.1 propagation above. Hence, it will pick two more links (RDSW0 and RDSW1 in Figure 17) to not advertise reachability.\nFor Cluster X FDSW0, it will randomly pick one downlink (RDSW0 in Figure 17) to not advertise reachability to RDSW0 in Cluster X-1. \nFigure 17: The composition effect of both link failures.\nFuture Work With DSF \nWe are interconnecting multiple regions to create mega clusters that will provide interconnectivity of GPUs with different regions that are tens of kilometers apart. \nThis will create an interesting challenge of addressing heterogeneity between different GPU types and fabric involving different regions.\nWe are also working on a new technology called Hyperports, which will combine multiple 800G ports at ASIC level to act as a single physical port. This will reduce the effect of fat flows on IP interconnects.\nIn addition, DSF is a smart fabric that inherently supports a wide range of GPUs/NICs. We are increasing our deployments to include an increasing variety of GPU/NIC models.\nThe post Disaggregated Scheduled Fabric: Scaling Meta’s AI Journey appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Disaggregated Schedule Fabric (DSF) is Meta’s next-generation network fabric technology for AI training networks that addresses the challenges of existing Clos-based networks. We’re sharing the challenges and innovations surrounding DSF and discussing future directions, including the creation of mega clusters through DSF and non-DSF region interconnectivity, as well as the exploration of alternative switching technologies. [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/10/20/data-center-engineering/disaggregated-scheduled-fabric-scaling-metas-ai-journey/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/10/20/data-center-engineering/disaggregated-scheduled-fabric-scaling-metas-ai-journey/\">Disaggregated Scheduled Fabric: Scaling Meta’s AI Journey</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Disaggregated Schedule Fabric (DSF) is Meta’s next-generation network fabric technology for AI training networks that addresses the challenges of existing Clos-based networks. We’re sharing the challenges and innovations surrounding DSF and discussing future directions, including the creation of mega clusters through DSF and non-DSF region interconnectivity, as well as the exploration of alternative switching technologies. [...]\nRead More...\nThe post Disaggregated Scheduled Fabric: Scaling Meta’s AI Journey appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=23150",
        "categories": [
          "Data Center Engineering",
          "Networking & Traffic"
        ],
        "isoDate": "2025-10-20T16:00:37.000Z"
      },
      {
        "creator": "",
        "title": "Scaling LLM Inference: Innovations in Tensor Parallelism, Context Parallelism, and Expert Parallelism",
        "link": "https://engineering.fb.com/2025/10/17/ai-research/scaling-llm-inference-innovations-tensor-parallelism-context-parallelism-expert-parallelism/",
        "pubDate": "Fri, 17 Oct 2025 16:00:50 +0000",
        "content:encodedSnippet": "At Meta, we are constantly pushing the boundaries of LLM inference systems to power applications such as the Meta AI App.\nWe’re sharing how we  developed and implemented advanced parallelism techniques to optimize key performance metrics related to resource efficiency, throughput, and latency.\nThe rapid evolution of large language models (LLMs) has ushered in a new era of AI-powered applications, from conversational agents to advanced content generation. However, deploying these massive models at scale for real-time inference presents significant challenges, particularly in achieving high throughput, low latency, and better resource efficiency. \nOur primary goal is to optimize key performance metrics:\nResource efficiency: Maximizing GPU utilization to improve operational efficiency.\nThroughput (queries/s): Serving more users by processing a higher volume of requests.\nLatency: Minimizing response times for a seamless user experience. This includes:\n\nTime-to-first-token (TTFT) for prefill: The time it takes for the first part of the response to appear, ideally under 350ms.\nTime-to-incremental-token (TTIT) for decoding: The latency between subsequent words, targeting less than 25ms.\nThese metrics highlight the distinct computational demands of LLM inference: Prefill is compute-intensive, while decoding is memory bandwidth-intensive. To address these challenges and enable the deployment of large models, we have developed and implemented advanced parallelism techniques.\n\nThe Two Stages of LLM Inference\nA typical LLM generative-inference task unfolds in two stages:\nPrefill stage: This stage processes the input prompt (which can be thousands of tokens long) to generate a key-value (KV) cache for each transformer layer of the LLM. Prefill is compute-bound, because the attention mechanism scales quadratically with sequence length.\nDecoding Stage: This stage utilizes and incrementally updates the KV cache to generate tokens (words) one by one. Decoding is memory-bound, as the I/O time of reading memory dominates attention time, with model weights and the KV cache occupying the majority of memory.\nAddressing Bottlenecks With Parallelism\nTo scale LLM inference effectively, especially for handling long contexts and massive models, we employ three main types of inference parallelism:\n1. Tensor parallelism (TP), which improves fitting large models across multiple GPUs and achieving high throughput that a single device cannot provide. It involves sharding individual layers of the model, such as attention blocks and multi-layer perceptron (MLP) layers, into smaller, independent blocks that can be executed on different devices.\nA challenge in tensor parallelism is the “allreduce” communication operation, which can contribute up to 30% of end-to-end latency. To mitigate this, we developed direct data access (DDA) algorithms:\nDDA flat algorithm: Improves small message-size allreduce latency by allowing each rank to directly load memory from other ranks and perform local reduce operations. This reduces latency from O(N) to O(1) by increasing the amount of data exchange from O(n) to O(n^2).\nDDA tree algorithm: Breaks the allreduce into two phases (reduce-scatter and all-gather) and uses direct data access in each step. This moves the same amount of data as the ring algorithm but reduces latency to a constant factor, making it suitable for slightly larger message sizes.\nOur DDA solutions demonstrate significant speedups against baselines such as NCCL (NVIDIA Collective Communications Library) and RCCL (ROCm Communication Collectives Library for AMD GPUs). For instance, with AMD MI300X, we achieved overall performance parity with Nvidia H100, with DDA outperforming RCCL baseline by 10-50% for decode (small message sizes) and yielding 10-30% speedup for prefill, resulting in approximately 10% reduction in TTIT.\n2. Context parallelism (CP), which facilitates managing and processing extremely long contexts, such as the 1M/10M token capabilities introduced with Llama 4. Long-context inference presents unique challenges:\nCompute: Dense attention FLOPs scale quadratically with context length, leading to attention-compute dominating.\nMemory: The KV cache grows linearly with context.\nCommunication: Communication latency increases when parallelizing across multiple hosts.\nWe have implemented two variants of context parallelism in the attention module, often referred to as “ring attention”:\nPass-KV: In this approach, input tokens are split across multiple CP ranks. Each rank calculates its portion of query, key, and value tensors. Then, key and value tensors are exchanged between ranks to enable attention interactions across the full context.\nPass-Q: Similar to Pass-KV, but query tensors are exchanged between ranks.\nOur context parallelism optimizations, combined with a fast-attention kernel, have enabled remarkable performance for long-context capabilities. We achieved less than one minute for one million tokens on a single H100 host and less than one minute for 10 million tokens using distributed inference across multiple H100 hosts (e.g., 32 H100 hosts). With Llama 3 405B, we demonstrated near-linear scaling, achieving 128K token prefill in 3.8 seconds with CP over 16 nodes, and 1M-token prefill in 77 seconds.\n3. Expert parallelism (EP), which helps with scaling mixture-of-experts (MoE) models, where a large number of “experts” (neural network modules) make it impossible to fit the entire model onto a single host. In EP-based inference, we utilize a two-shot, all-to-all communication pattern to exchange tokens between data parallelism and expert parallelism ranks based on routing.\nThe all-to-all communication can contribute 10-30% to end-to-end latency, especially for decode messages (100KB to 2MB). To optimize this, we are exploring solutions including:\nDynamic all-to-all: Sending sub-chunks of data to remote neighbors.\nPersistent all-to-all: Addressing slowdowns primarily caused by memory-handle exchange, network-load balancing, and CPU overhead.\nLooking Ahead: Disaggregated Inference and Future Challenges\nTo further optimize LLM inference, we are moving towards N-D parallelism (CP, PP, EP, TP across nodes, with separate DP) and disaggregating prefill and decoding tiers. This allows for better resource balancing and the potential to use heterogeneous hardware, where compute-heavy hardware is used for prefill and memory bandwidth-heavy hardware for decoding. This multi-dimensional parallelism can help unblock the serving and evaluation of colossal models.\nFuture challenges in this space include:\nCloud fabric design: Optimizing the underlying cloud infrastructure for LLM workloads.\nCommunication going to kernel (fused kernel): Integrating communication operations directly into computational kernels for greater efficiency.\nDevice-initiated kernel: Enabling devices to initiate operations directly, reducing CPU overhead.\nThese advancements in parallelization and system-level improvements have helped enable the next generation of AI applications and push the boundaries of what LLMs can achieve. We are committed to continuous innovation to ensure efficient and scalable LLM inference for millions of users worldwide.\nThe post Scaling LLM Inference: Innovations in Tensor Parallelism, Context Parallelism, and Expert Parallelism appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>At Meta, we are constantly pushing the boundaries of LLM inference systems to power applications such as the Meta AI App. We&#8217;re sharing how we developed and implemented advanced parallelism techniques to optimize key performance metrics related to resource efficiency, throughput, and latency. The rapid evolution of large language models (LLMs) has ushered in a [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/10/17/ai-research/scaling-llm-inference-innovations-tensor-parallelism-context-parallelism-expert-parallelism/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/10/17/ai-research/scaling-llm-inference-innovations-tensor-parallelism-context-parallelism-expert-parallelism/\">Scaling LLM Inference: Innovations in Tensor Parallelism, Context Parallelism, and Expert Parallelism</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "At Meta, we are constantly pushing the boundaries of LLM inference systems to power applications such as the Meta AI App. We’re sharing how we developed and implemented advanced parallelism techniques to optimize key performance metrics related to resource efficiency, throughput, and latency. The rapid evolution of large language models (LLMs) has ushered in a [...]\nRead More...\nThe post Scaling LLM Inference: Innovations in Tensor Parallelism, Context Parallelism, and Expert Parallelism appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=23019",
        "categories": [
          "AI Research"
        ],
        "isoDate": "2025-10-17T16:00:50.000Z"
      },
      {
        "creator": "",
        "title": "Branching in a Sapling Monorepo",
        "link": "https://engineering.fb.com/2025/10/16/developer-tools/branching-in-a-sapling-monorepo/",
        "pubDate": "Thu, 16 Oct 2025 17:10:43 +0000",
        "content:encodedSnippet": "Sapling is a scalable, user-friendly, and open-source source control system that powers Meta’s monorepo. As discussed at the GitMerge 2024 conference session on branching, designing and implementing branching workflows for large monorepos is a challenging problem with multiple tradeoffs between scalability and the developer experience.\nAfter the conference, we designed, implemented, and open sourced our monorepo branching solution in Sapling. While the code is already open source, in this article we share learnings on:\nHow we resolved scalability and developer experience tradeoffs in the design and implementation.\nWhat problems it solved.\nWhat feedback we received from other developers at Meta.\nThe key technical insight is that two workflows — non-mergeable full-repo branching and mergeable directory branching — solved all of the branching-related problems for a large and diverse set of products built at Meta.\nWe hope that the Sapling open source code and the learnings shared in this article will benefit the wider industry and open source communities.\nHow Source Control Is Handled at Meta \nAt Meta, our engineering teams work within a large monorepo with a single main branch. This approach enables unified dependency management, large-scale refactoring, easier collaboration, and code reuse across projects. However, this approach introduces challenges for teams that must manage multiple versions of their code.\nIn multi-repo setups, teams can rely on repository branches to manage different versions.  Source control gives them tools, like cherry-pick and merge, that let them manage the differences between the versions.\nIn the monorepo, however, repository branches do not work as well for this. Branches affect the whole repository, so creating a branch means unrelated projects and dependencies will remain frozen, and quickly become stale.\nIn this article we refer to whole repository branching as full-repo branching. What we learned is that for workflows that do not require merging back to the main branch (e.g., product releases where the branch ceases to exist after the release completes and the development moves back to the main branch) full-repo branching is a good solution. In Sapling, this workflow is well supported with the sl bookmark family of commands.\nHowever, for product development workflows where merging back to the main branch is required, we learned that full-repo branching is not a scalable approach. This is because full-repo merges create merge commits with multiple parents, making the commit graph wide (high branching factor) and non-linear. In large monorepos, this creates performance problems for operations like sl log and sl blame. Maintaining a linear commit graph,where most commits have a single parent, is crucial for keeping these operations fast for all monorepo users, not just those utilizing branches.\nThe core limitation is that full-repo branches are all-or-nothing. If you need to patch a legacy version, or maintain a custom variant for a particular project, you cannot create a branch for the part that you own. Branching forks everything.\nA common pattern when attempting to solve this problem was for teams to make multiple copies of their code. However, by doing this they lose a lot of the standard developer tools for managing their branches. This resulted in duplicated effort and error-prone copying of patches between directories.\nDirectory Branching: Sapling’s Monorepo Branching Solution\nTo solve these challenges, we have introduced a new set of source control tools in Sapling that can be used to implement a new kind of branching: directory branching. This bridges the gap between using multiple repository branches and maintaining copies of code as separate directories.\nWith these tools, you are able to treat directories in the monorepo much like traditional repository branches. You create branches by copying the code, maintain the code by cherry-picking, and merging changes between directories as if they were branches, and look at the history of each directory in the context of the copies and merges that were made.\nCrucially, while directory branches support merging between directories, at the level of the monorepo’s commit graph, they appear as linear commits. This resolves the scalability challenge with the repo-level merge commits and still provides merging workflows at the directory level.\nHow Directory Branching Is Implemented in Sapling \nDirectory branching in Sapling is implemented using a series of operations centered around the sl subtree command.\nTo branch a directory, you use the sl subtree copy command to copy a directory (or file), either at the current version or from any historical version, to a new location in the repository. Sapling records metadata in the commit that tracks the source directory, source revision, and copy relationship, which allows us to recover the complete history of all files in the new branch. If the code you want to branch is not in the monorepo yet, you can use sl subtree import to create a directory branch of an external repository branch.\nOnce you have a directory branch, you can use sl subtree graft and sl subtree merge to cherry-pick or merge changes between directory branches. These operations use the stored copy/merge metadata to reconstruct the relationship between directories, enabling Sapling to perform three-way merges between directory branches. The merge algorithm finds the common ancestor of the two directory branches (using the copy metadata) and performs a standard three-way merge, just as it would for regular repository merges, but scoped to the specific directory content.\nThe Build System and Wider Developer Tooling Integration\nAn advantage of this approach is that the latest versions of all directory branches are visible at the same time.  This means continuous integration (CI) can test against multiple branches with a single checkout, and you can be confident that there are no hidden old branches that are unexpectedly still in use.\nAt Meta we use Buck2 as our build system. When a component depends on another component that uses directory branching, we use Buck config modifiers (i.e., buck build with the -m flag) to allow us to select which branch is being used.\nOne downside of directory branching is that code searches can result in multiple hits for each of the branches. It is relevant that the searched-for code appears in multiple places, however it can be difficult to look through the results from multiple branches if they are mingled together. Code search systems capable of ranking results can resolve this issue.\nUser Feedback on Directory Branching\nThe introduction of directory branching has been a success, with a large and diverse set of engineering teams within Meta adopting it to manage multiple versions of code. Some teams have also found it useful to temporarily freeze the majority of the monorepo for development stability by remaining on an old commit and using directory branching to merge in changes for specific projects, effectively combining both full-repo branching and directory branching workflows.\nWe observed the following three common themes of valid reasons for adopting directory branching:\n1.)  When CI is prohibitively expensive or changes could cause major disruptions. Some teams at Meta used directory branches to effectively separate development and production versions of the code, giving them more control over when their code changes are deployed to production.\n2.) Experimental changes where a large number of developers are collaborating over several months, but the changes have the potential of disrupting the production version. At the same time, the collaboration scale is large enough that using a very large stack of diffs to simulate a branch is not practical.\n3.) Unblocking migrations from Git. Even if the ultimate goal is to have only one or a few versions in the Sapling monorepo, during the migrations we need an equivalent to Git branches so that the migration can complete and consolidation can take place within the monorepo. It is not always possible to consolidate all branches in Git before migrating to monorepo.\nIt is worth noting that having a single version of code remains the default assumption for the monorepo. However, if any of the three reasons above apply, directory branching can be used as a solution, providing branching workflows without sacrificing the benefits of a monorepo.\nFuture Work With Directory Branching\nWe are also planning to leverage directory branching for better integration of Git repositories into the Sapling monorepo. More specifically, we are developing a lightweight repository migration mechanism. Instead of making an irreversible decision of committing all of the Git repository commits into the monorepo history, we create a soft link to an external repository where Sapling can load the Git history on the fly when the user requests it. This lowers the barrier of entry of Git repositories into the monorepo and is useful for integrations before committing to migrating full history. This will be provided as an option to the sl subtree import command when working with external Git repositories. \nStay tuned—we will publish a separate article on this topic once we have enough learnings to share.\nTo learn more about Meta Open Source, visit our website, subscribe to our YouTube channel, or follow us on Facebook, Threads, X, Bluesky and LinkedIn.\nAcknowledgements\nMultiple people at Meta’s Source Control, Developer Experience and Open Source organisations contributed to the design and implementation of directory branching in Sapling. We would like to thank: Chris Cooper, George Giorgidze, Mark Juggurnauth-Thomas, Jon Janzen, Pingchuan Liu, Muir Manders, Mark Mendoza, Jun Wu, and Zhaolong Zhu.\nWe are also grateful to the Git, Mercurial, and Jujutsu open source communities for their branching-related discussions at the GitMerge 2024 conference in Berlin. We hope that the Sapling open source code and the learnings shared in this article will benefit all source control systems.\nThe post Branching in a Sapling Monorepo appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>Sapling is a scalable, user-friendly, and open-source source control system that powers Meta&#8217;s monorepo. As discussed at the GitMerge 2024 conference session on branching, designing and implementing branching workflows for large monorepos is a challenging problem with multiple tradeoffs between scalability and the developer experience. After the conference, we designed, implemented, and open sourced our [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/10/16/developer-tools/branching-in-a-sapling-monorepo/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/10/16/developer-tools/branching-in-a-sapling-monorepo/\">Branching in a Sapling Monorepo</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "Sapling is a scalable, user-friendly, and open-source source control system that powers Meta’s monorepo. As discussed at the GitMerge 2024 conference session on branching, designing and implementing branching workflows for large monorepos is a challenging problem with multiple tradeoffs between scalability and the developer experience. After the conference, we designed, implemented, and open sourced our [...]\nRead More...\nThe post Branching in a Sapling Monorepo appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=23178",
        "categories": [
          "DevInfra",
          "Open Source"
        ],
        "isoDate": "2025-10-16T17:10:43.000Z"
      },
      {
        "creator": "",
        "title": "10X Backbone: How Meta Is Scaling Backbone Connectivity for AI",
        "link": "https://engineering.fb.com/2025/10/16/data-center-engineering/10x-backbone-how-meta-is-scaling-backbone-connectivity-for-ai/",
        "pubDate": "Thu, 16 Oct 2025 16:30:02 +0000",
        "content:encodedSnippet": "We’re sharing details on our journey to scale Meta’s Backbone network to support the increasing demands of new and existing AI workloads.\nWe’ve developed new technologies and designs to address our 10x scaling needs and applying some of these same principles to help extend our AI clusters between multiple data centers.\n\nMeta’s Backbone network is composed of a set of interconnected routing platforms and provides WAN (wide area network) connectivity among network locations. Meta has architected Backbone in two different networks: Classic Backbone (CBB) and Express Backbone (EBB). They differ in some fundamental ways. \nCBB is used to achieve global reach from data centers (DCs) to our points of presence (POPs) where we connect with external carriers. CBB is flexible: It can shrink or grow to support a diverse set of geographies and accommodate a broad range of connectivity requirements. It uses traditional IP/MPLS-TE (Internet Protocol/Multiprotocol Label Switching/Traffic Engineering) technologies.\nEBB, in contrast, is built to provide scalable DC-to-DC interconnection. EBB is less flexible, having a sizable minimum installation. It runs a heavily customised stack of software, such as the Open/R routing protocol, and an in-house traffic-engineering stack with onbox agents and a centralized controller.\nWhile we see growth in both networks, it’s EBB that presents the most challenging scalability problems.\nIn the rest of this post, we will focus on EBB and describe how we actually addressed EBB’s growth and the resulting challenges.\nFigure 1: Traffic growth in Meta’s Backbone network\nEBB network first started serving traffic around 2015. Figure 1 represents the growth since then for EBB, DC-to-DC traffic flows versus CBB, and DC-to-POP traffic flows.\nPrior to 2015, CBB was used for both DC-to-DC and DC-to-POP traffic. Figure 2 represents some of the EBB adoption and technology milestones.\nFigure 2: EBB origins and growth\nA significant amount of fiber in terms of quantity and distance is required to interconnect DC locations at the necessary scale. The existing DCs continue to grow in footprint and capacity due to the addition of more powerful servers and, where possible, the addition of new buildings at existing locations.\nConnecting DCs reliably and repeatedly at high capacity to the rest of the network can be challenging, especially due to the speed at which new DCs are being built. While the network has some input into the site-selection process, there are many influencing factors beyond ease of connectivity that determine how new data center locations are chosen.\n10X Backbone\n10X Backbone is the evolution of EBB in terms of scale, topology, and technology. Below are the three techniques used to scale to 10X Backbone.\nDC Metro Architecture\nHistorically, building long-haul fibers to new DC locations has been painful, especially when these long-haul fibers need to extend hundreds of miles.\nOur first technique to scale up to 10X Backbone was to pre-build some of the components of DC metro architecture. By pre-building them, we could more quickly provide connectivity to new DCs.\nFirst, we built two rings of fiber to provide scalable capacity in the metro, and we connected long-haul fibers to the rings. Next, we built two POPs to provide connectivity toward remote sites. Last, we connected DCs to the rings, and therefore increased or enabled capacity between the DC and POPs. (See Figure 3.)\nDC metro architecture has several advantages:\nA simplified building of DC connectivity and WAN topology\nA standardized scalable physical design\nSeparate metro and long-haul networks \nFigure 3: DC metro architecture\nIP Platform Scaling\nThe second technique we use for 10X Backbone is IP platform scaling, which has two flavors: scaling up and scaling out.\nScaling up, as illustrated in Figure 4, relies heavily on vendor technology and has primarily two forms: \nLarger chassis: a 12-slot chassis provides 50% more capacity than an 8-slot chassis. However, a larger chassis introduces another set of important considerations:\n\nMore challenging mechanical and thermal designs\nHigher power and space requirements, and higher power density per rack\nHigher number of ASICs (application-specific integrated circuit) and the implications on control plane programming across them\nMore challenging infrastructure design with regard to higher interface and cabling count\nIncreased network operating system (NOS) complexity to support higher interface scale\nSimpler NPI (new product introduction) when keeping the same ASIC/line-card technology\nFaster interfaces. By leveraging modern ASICs and line cards, we can double the capacity when we move from 400G to 800G platforms. Important considerations arising from this technique:\n\nMore challenging thermal designs\nHigher power requirements and power density per rack\nComplex NPI introduced by a new ASIC and forwarding pipeline\nMore challenging infrastructure design with regard to higher interface and cabling count\nIncreased network OS complexity to support potentially higher interface scale\nSupport for 800G-ZR+ transceivers (a set of pluggables that support extended reach)\nFigure 4: EBB techniques to scale up\nIn contrast to the dependency on vendors/industry in scaling up, scaling out (illustrated in Figure 5) is more under our control and has historically taken two flavors in EBB:\nAdding more Backbone planes. Going from four to eight planes results in doubling capacity globally; however, this technique has the following considerations:\n\nImplementation is quite disruptive and requires a lot of planning, specifically when it comes to fiber restriping (this needs to be coordinated in many locations simultaneously)\nHigher power and space requirements globally, but power density per rack remains the same\nRouting support for planes with uneven capacity can be complex\nAdditional capacity on interconnects might be needed for compatibility with the final Backbone design\nDoesn’t require introducing new technology\nWe can add multiple devices per plane. This technique is more sophisticated and allows us to scale capacity only in a chosen location. Considerations include:\n\nImplementation is quite disruptive for the target site and requires a moderate amount of planning to execute\nHigher power and space requirements in the target location, but power density per rack remains the same\nInterconnect with other layers might be more challenging: full mesh needs to be extended to Nx devices\nIntroduces new failure modes: Device failure can impact some but not all of the of the Backbone in that plane/site\nNetwork operations can become more complex due to new failure modes and the handling of sets of devices (software upgrades, maintenance, etc.)\nDoesn’t require introducing new technology\nFigure 5: EBB techniques to scale out\nScaling up and scaling out are not mutually exclusive, and in our 10X Backbone journey we have used them both.\nIP and Optical Integration\nThe third technique to scale to 10X Backbone is IP and optical integration. By leveraging ZR technology, we are changing the power footprint per terabit in the network.\nPrior to ZR:\nWe had many transponders per router. Each of the transponders consumed up to 2kW for 4.8-6.4Tb of capacity.\nThere was a clear demarcation between IP and optical layers. This permitted work to occur at either layer with simple coordination.\nWith ZR: \nWe no longer need transponders; this functionality is now in the plugs in the router. By removing transponders, we recover large amounts of space and power.\nEach of the plugs consumes 10-15W of incremental power.\nAs a result of ZR plugs being installed in the routers, the split between IP and optical functions is not as clear as before.\nFigure 6: Network topology before and after ZR introduction\nIn summary, the use of ZR transceivers increases the power consumption in the router, which is offset by the considerable power savings from removing standalone transponders. In aggregate, we use 80 to 90% less power.\nUsing ZR technology has introduced important high-level changes:\nCost and power efficiency: \n\nThe same Backbone capacity can be deployed in a smaller S&P envelope\nRack allocation between optical and IP devices goes from 90/10 (prior to ZR) to 60/40 (with ZR)\nPrior to ZR, we could land 1x fiber pairs/rack; with ZR, since we don’t use standalone transponders, we can land 4x fiber pairs/rack\nSimplifies network deployments; installing a set of pluggables instead of standalone transponders makes network deployments easier and more predictable\nUses fewer active devices and therefore simplifies network operations\nEnables interoperability and vendor diversity\nOptical channel terminates in IP devices, and the demarcation of optical and IP is more complex than in non-ZR scenarios\nTelemetry and collections on the state of the optical channel is bound to IP devices, causing additional CPU consumption\nBy leveraging DC metro architecture, IP platform scaling, and IP/Optical integration, we transformed EBB from the experimental network of 2016 to a large-scale Backbone that supports all DC<>DC traffic at Meta. \nAI Backbone\nOver the last 18 months, we’ve seen an increasing interest in growing the megawatts footprint in support of building larger GPU clusters. The requirements have grown beyond what can fit in an existing data center campus, even considering undeveloped land or land adjacent to existing locations. Right now cluster performance is impacted by latency between endpoints, so we began to search for suitable expansion locations within bounded geographical proximity, expanding outwards until we achieve the target scale for a region. \nAs we identify sites of interest, we work with our fiber-sourcing team to determine the timing and feasibility to connect to existing locations at a very high scale as well as the most appropriate technology to utilize. In most cases, construction work is needed to place additional fiber in the ground, due to the significant quantities required.\nWe came up with three solutions based on the necessary reach:\nFR plugs: A solution that addresses buildings in the 3-kilometer range. (Note: We make some different assumptions about loss/connector count to permit this distance versus the standard specification, which states 2 kilometers.)\nLR plugs: Increasing the distance to a 10-kilometer range by using longer reach optics.\nZR plugs + Optical DWDM (dense wavelength division multiplexing) technology: To go beyond 10-kilometer range, we need active optical components to multiplex and amplify the signals to get the desired reach. Multiplexing reduces the fiber count by a factor of 64 versus FR/LR.\nFor longer reach connectivity, a more complex solution is required. We use a relatively tried-and-tested design incorporating optical-protection switching, albeit using the latest generation C+L-Band 800G ZR technology.\nToday’s requirements are at the lower end of the distance capabilities, and the initial deployments do not require any of the intermediate amplification sites that come into play when you go beyond 150 kilometers. This is fortunate, as these sites would be quite large given the amount of fiber pairs to be amplified (meaning additional lead times for construction, planning permits,etc.).\nProtection switching introduces some additional operational challenges to how we run the network, as we require external tooling/monitoring to determine if the underlying connectivity for an IP circuit is in a protected or unprotected state. The primary reason to use them is to reduce the number of ports that we consume on the IP platforms, versus providing protection at the IP layer with additional capacity.\nWith this design, each fiber pair can carry 64x 800G (51.2T). To achieve the overall capacity needed between a given site-pair, we just scale this horizontally.\n\nFigure 7: AI Backbone topology\nThe above diagram underscores the scale of these interconnects. Right now, a single AI Backbone site-pair is twice the size of the global backbone that we’ve been building for the last 10 years.\nThis presents many interesting challenges in how we deploy and provision this capacity. We’ll be putting a lot of time and effort into streamlining the sheer volume of this equipment and these connections as we complete the physical build-out of the fiber.\nWhat We Learned and What the Future Holds\nScaling EBB has been a wild journey over the last eight or nine years, and it is a story of unexpected acceleration, where our scalability plans had to be accelerated, from 2028 to 2024.\nThese are our key learnings:\n10x Backbone is possible because of the innovation in scaling up and scaling out.\nPre-building scalable metro designs enables a faster response to network growth.\nIP/optical integration reduces the number of active devices, space and power footprint, and allows further scaling.\nRe-using 10X Backbone technology enables the build of AI Backbone.\nMeta is planning to build city-size DCs, and our Backbone has to evolve and scale.\nWe see leaf-and-spine architecture as the next step to scale out our platforms. This architecture provides the needed scale with fewer disruptive scaling steps.\nWe will execute on the initial plan for AI Backbone, iterate as we go to more sites, and mature our operations. Throughout this process, we’ll come to understand AI intricacies as they develop through our optical network.\nThe post 10X Backbone: How Meta Is Scaling Backbone Connectivity for AI appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>We&#8217;re sharing details on our journey to scale Meta&#8217;s Backbone network to support the increasing demands of new and existing AI workloads. We&#8217;ve developed new technologies and designs to address our 10x scaling needs and applying some of these same principles to help extend our AI clusters between multiple data centers. Meta’s Backbone network is [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/10/16/data-center-engineering/10x-backbone-how-meta-is-scaling-backbone-connectivity-for-ai/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/10/16/data-center-engineering/10x-backbone-how-meta-is-scaling-backbone-connectivity-for-ai/\">10X Backbone: How Meta Is Scaling Backbone Connectivity for AI</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "We’re sharing details on our journey to scale Meta’s Backbone network to support the increasing demands of new and existing AI workloads. We’ve developed new technologies and designs to address our 10x scaling needs and applying some of these same principles to help extend our AI clusters between multiple data centers. Meta’s Backbone network is [...]\nRead More...\nThe post 10X Backbone: How Meta Is Scaling Backbone Connectivity for AI appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=23025",
        "categories": [
          "Data Center Engineering"
        ],
        "isoDate": "2025-10-16T16:30:02.000Z"
      },
      {
        "creator": "",
        "title": "Design for Sustainability: New Design Principles for Reducing IT Hardware Emissions",
        "link": "https://engineering.fb.com/2025/10/14/data-center-engineering/design-for-sustainability-new-design-principles-for-reducing-it-hardware-emissions/",
        "pubDate": "Tue, 14 Oct 2025 20:40:20 +0000",
        "content:encodedSnippet": "We’re presenting Design for Sustainability,  a set of technical design principles for new designs of IT hardware to reduce emissions and cost through reuse, extending useful life, and optimizing design.\nAt Meta, we’ve been able to significantly reduce the carbon footprint of our data centers by integrating several design strategies such as modularity, reuse, retrofitting, dematerialization, using greener materials, and extended hardware lifecycles, Meta can significantly reduce the carbon footprint of its data center infrastructure. \nWe’re inviting the wider industry to also adopt the strategies outlined here to help reach sustainability goals.\nThe data centers, server hardware, and global network infrastructure that underpin Meta’s operations are a critical focus to address the environmental impact of our operations. As we develop and deploy the compute capacity and storage racks used in data centers, we are focused on our goal to reach net zero emissions across our value chain in 2030. To do this, we prioritize interventions to reduce emissions associated with this hardware, including collaborating with hardware suppliers to reduce upstream emissions.\nWhat Is Design for Sustainability? \nDesign for Sustainability is a set of guidelines, developed and proposed by Meta, to aid hardware designers in reducing the environmental impact of IT racks. This considers various factors such as energy efficiency and the selection, reduction, circularity, and end-of-life disposal of materials used in hardware. Sustainable hardware design requires collaboration between hardware designers, engineers, and sustainability experts to create hardware that meets performance requirements while limiting environmental impact.\nIn this guide, we specifically focus on the design of racks that power our data centers and offer alternatives for various components (e.g., mechanicals, cooling, compute, storage and cabling) that can help rack designers make sustainable choices early in the product’s lifecycle. \nOur Focus on Scope 3 Emissions\nTo reach our net zero goal, we are primarily focused on reducing our Scope 3 (or value chain) emissions from physical sources like data center construction and our IT hardware (compute, storage and cooling equipment) and network fiber infrastructure.\nWhile the energy efficiency of the hardware itself deployed in our data centers helps reduce energy consumption, we have to also consider IT hardware emissions associated with the manufacturing and delivery of equipment to Meta, as well as the end-of-life disposal, recycling, or resale of this hardware.\nOur methods for controlling and reducing Scope 3 emissions generally involve optimizing material selection, choosing and developing lower carbon alternatives in design, and helping to reduce the upstream emissions of our suppliers.\nFor internal teams focused on hardware, this involves:\nOptimizing hardware design for the lowest possible emissions, extending the useful life of materials as much as possible with each system design, or using lower carbon materials.\nBeing more efficient by extending the useful life of IT racks to potentially skip new generations of equipment.\nHarvesting server components that are no longer available to be used as spares. When racks reach their end-of-life, some of the components still have service life left in them and can be harvested and reused in a variety of ways. Circularity programs harvest components such as dual In-line memory modules (DIMMs) from end-of-life racks and redeploy them in new builds.\nKnowing the emissions profiles of suppliers, components, and system designs. This in turn informs future roadmaps that will further reduce emissions.\nCollaborating with suppliers to electrify their manufacturing processes, to transition to renewable energy, and to leverage lower carbon materials and designs.\nThese actions to reduce Scope 3 emissions from our IT hardware also have the additional benefit of reducing the amount of electronic waste (e-waste) generated from our data centers.\nAn Overview of the Types of Racks We Deploy \nThere are many different rack designs deployed within Meta’s data centers to support different workloads and infrastructure needs, mainly:\nAI – AI training and inference workloads\nCompute – General compute needed for running Meta’s products and services\nStorage – Storing and maintaining data used by our products\nNetwork – Providing Low-latency interconnections between servers\nWhile there are differences in architecture across these different rack types, most of these racks apply general hardware design principles and contain active and passive components from a similar group of suppliers. As such, the same design principles for sustainability apply across these varied rack types.\nWithin each rack, there are five main categories of components that are targeted for emissions reductions: \nCompute (i.e., memory, HDD/SSD)\nStorage\nNetwork\nPower\nRack infrastructure (i.e., mechanical and thermals)\nThe emissions breakdown for a generic compute rack is shown below.\n\nOur Techniques for Reducing Emissions\nWe focus on four main categories to address emissions associated with these hardware components:\n\nWe will cover a few of the levers listed above in detail below.\nModular Rack Designs\nModular Design which allows older rack components to be re-used in newer racks. Open Rack designs (ORv2 & ORv3) form the bulk of high volume racks that exist in our data centers. \n\nHere are some key aspects of the ORv3 modular rack design:\nORv3 separates Power Supply Units (PSUs) and Battery Backup Units (BBUs) into their own shelves.\nThis allows for more reliable and flexible configurations, making repairs and replacements easier as each field replaceable unit (FRU) is toolless to replace.\nPower and flexibility \nThe ORv3 design includes a 48 V power output, which allows the power shelf to be placed anywhere in the rack. This is an improvement over the previous ORV2 design, which limited the power shelf to a specific power zone\nConfigurations \nThe rack can accommodate different configurations of PSU and BBU shelves to meet various platform and regional requirements. For example, North America uses a dual AC input per PSU shelf, while Europe and Asia use a single AC input. \nCommonization effort \nThere is an ongoing effort to design a “commonized” ORv3 rack frame that incorporates features from various rack variations into one standard frame. This aims to streamline the assembly process, reduce quality risks, and lower overall product costs \nORv3N \nA derivative of ORv3, known as ORv3N, is designed for network-specific applications. It includes in-rack PSU and BBU, offering efficiency and cost improvements over traditional in-row UPS systems \nThese design principles should continue to be followed in successive generations of racks. With the expansion of AI workloads, new specialized racks for compute, storage, power and cooling are being developed that are challenging  designers to adopt the most modular design principles. \nRe-Using/Retrofitting Existing Rack Designs\nRetrofitting existing rack designs for new uses/high density is a cost-effective and sustainable approach to meet evolving data center needs. This strategy can help reduce e-waste, lower costs, and accelerate deployment times. Benefits of re-use/retrofitting include:\nCost savings \nRetrofitting existing racks can be significantly cheaper compared to purchasing new racks.\nReduced e-waste \nReusing existing racks reduces the amount of e-waste generated by data centers.\nFaster deployment \nRetrofitting existing racks can be completed faster than deploying new racks, as it eliminates the need for procurement and manufacturing lead times.\nEnvironmental benefits \nReducing e-waste and reusing existing materials helps minimize the environmental impact of data centers.\nThere are several challenges when considering re-using or retrofitting racks:\nCompatibility issues\nEnsuring compatibility between old and new components can be challenging.\nPower and cooling requirements\nRetrofitting existing racks may require upgrades to power and cooling systems to support new equipment.\nScalability and flexibility \nRetrofitting existing racks may limit scalability and flexibility in terms of future upgrades or changes.\nTesting and validation\nThorough testing and validation are required to ensure that retrofitted racks meet performance and reliability standards.\nOverall, the benefits of retrofitting existing racks are substantial and should be examined in every new rack design.\nGreen Steel\nSteel is a significant portion of a rack and chassis and substituting traditional steel with green steel can reduce emissions. Green steel is typically produced using electric arc furnaces (EAF) instead of traditional basic oxygen furnaces (BOF), allowing for the use of clean and renewable electricity and a higher quantity of recycled content. This approach significantly reduces carbon emissions associated with steel production. Meta collaborates with suppliers who offer green steel produced with 100% clean and renewable energy.\nRecycled Steel, Aluminum, and Copper\nWhile steel is a significant component of rack and chassis, aluminum and copper are extensively used in heat sinks and wiring. Recycling steel, aluminum, and copper saves significant energy needed to produce hardware from raw materials. \nAs part of our commitment to sustainability, we now require all racks/chassis to contain a minimum of 20% recycled steel. Additionally, all heat sinks must be manufactured entirely from recycled aluminum or copper. These mandates are an important step in our ongoing sustainability journey.\nSeveral of our steel suppliers, such as Tata Steel, provide recycled steel. Product design teams may ask their original design manufacturer (ODM) partners to make sure that recycled steel is included in the steel vendor(s) selected by Meta’s ODM partners. Similarly, there are many vendors that are providing recycled aluminum and copper products.\nImproving Reliability to Extend Useful Life\nExtending the useful life of racks, servers, memory, and SSDs helps Meta reduce the number of hardware equipment that needs to be ordered. This has helped achieve significant reductions in both emissions and costs. \nA key requirement for extending useful life of hardware is the reliability of the hardware component or rack. Benchmarking reliability is an important element to determine whether hardware life extensions are feasible and for how long. Additional consideration needs to be given to the fact that spares and vendor support may have diminishing availability. Also, extending hardware life also comes with the risk of increased equipment failure, so a clear strategy to deal with the higher incidence of potential failure should be put in place.\nDematerialization\nDematerialization and removal of unnecessary hardware components can lead to a significant reduction in the use of raw materials, water, and/or energy. This entails reducing the use of raw materials such as steel on racks or removing unnecessary components on server motherboards while maintaining the design constraints established for the rack and its components. \nDematerialization also involves consolidating multiple racks into fewer, more efficient ones, reducing their overall physical footprint. \nExtra components on hardware boards are included for several reasons:\nFuture-proofing \nComponents might be added to a circuit board in anticipation of future upgrades or changes in the design. This allows manufacturers to easily modify the board without having to redesign it from scratch.\nFlexibility \nExtra components can provide flexibility in terms of configuration options. For example, a board might have multiple connectors or interfaces that can be used depending on the specific application.\nDebugging and testing\nAdditional components can be used for debugging and testing purposes. These components might include test points, debug headers, or other features that help engineers diagnose issues during development.\nRedundancy \nIn some cases, extra components are included to provide redundancy in case one component fails. This is particularly important in high-reliability applications where system failure could have significant consequences.\nModularity \nExtra components can make a board more modular, allowing users to customize or upgrade their system by adding or removing modules.\nRegulatory compliance\nSome components might be required for regulatory compliance, such as safety features or electromagnetic interference (EMI) filtering.\nIn addition, changes in requirements over time can also lead to extra components. While it is very difficult to modify systems in production, it is important to make sure that each hardware design optimizes for components that will be populated. \nExamples of extra components on hardware boards include:\nUnpopulated integrated circuit (IC) sockets or footprints\nUnused connectors or headers\nTest points or debug headers\nRedundant power supplies or capacitors\nOptional memory or storage components\nUnconnected or reserved pins on ICs\nIn addition to hardware boards, excess components may also be present in other parts of the rack. Removing excess components can lead to lowering the emissions footprint of a circuit board or rack. \nProductionizing New Technologies With Lower Emissions\nProductionizing new technologies can help Meta significantly reduce emissions. Memory and SSD/HDD are typically the single largest source of embodied carbon emissions in a server rack. New technologies can help Meta reduce emissions and costs while providing a substantially higher power-normalized performance. \nExamples of such technologies include:\nTransitioning to SSD from HDD can reduce emissions by requiring fewer drives, servers, racks, BBUs, and PSUs, as well as help reduce overall energy usage. \nDepending on local environmental conditions, and the data center’s workload, using liquid cooling in server racks can be up to 17% more carbon-efficient than traditional air cooling.\nSource: OCP Global Summit, Oct 15-17, 2024, San Jose, CA.\nTeams can explore additional approaches to reduce emissions associated with memory/SSD/HDD which include:\nAlternate technologies such as phase-change memory (PCM) or Magnetoresistive Random-Access Memory (MRAM) that have the same performance with low carbon.\nUse Low-Power Double Data Rates (LPDDRs ) for low power consumption and high bandwidth instead of DDR.\nRemoving/reusing unused memory modules to reduce energy usage or down-clocking them during idle periods.\nUsing fewer high capacity memory modules to reduce power and cooling needs. Use High Bandwidth Memory (HBM) which uses much less energy than the DDR memory.\nChoosing the Right Suppliers\nMeta engages with suppliers to reduce emissions through its net zero supplier engagement program. This program is designed to set GHG reduction targets with selected suppliers to help achieve our net zero target. Key aspects of the program include:\nProviding capacity building: Training suppliers on how to measure emissions, set science-aligned targets, build reduction roadmaps, procure renewable energy, and understand energy markets. \nScaling up: In 2021 the program started with 39 key suppliers; by 2024 it expanded to include 183 suppliers, who together account for over half of Meta’s supplier-related emissions. \nSetting target goals: Meta aims to have two-thirds of its suppliers set science-aligned greenhouse gas reduction targets by 2026 . As of end-2024, 48% (by emissions contribution) have done so. \nThe Clean Energy Procurement Academy (CEPA), launched in 2023 (with Meta and other corporations), helps suppliers — especially in the Asia-Pacific region — learn how to procure renewable energy via region-specific curricula. \nThe Road to Net Zero Emissions\nThe Design for Sustainability principles outlined in this guide represent an important step forward in Meta’s goal to achieve net zero emissions in 2030. By integrating innovative design strategies such as modularity, reuse, retrofitting, and dematerialization, alongside the adoption of greener materials and extended hardware lifecycles, Meta can significantly reduce the carbon footprint of its data center infrastructure. These approaches not only lower emissions but also drive cost savings, e-waste reductions, and operational efficiency, reinforcing sustainability as a core business value.\nCollaboration across hardware designers, engineers, suppliers, and sustainability experts is essential to realize these goals. The ongoing engagement with suppliers further amplifies the impact by addressing emissions across our entire value chain. As Meta continues to evolve its rack designs and operational frameworks, the focus on sustainability will remain paramount, ensuring that future infrastructure innovations support both environmental responsibility and business performance.\nUltimately, the success of these efforts will be measured by tangible emissions reductions, extended useful life of server hardware, and the widespread adoption of low carbon technologies and materials. \nThe post Design for Sustainability: New Design Principles for Reducing IT Hardware Emissions appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>We’re presenting Design for Sustainability,  a set of technical design principles for new designs of IT hardware to reduce emissions and cost through reuse, extending useful life, and optimizing design. At Meta, we’ve been able to significantly reduce the carbon footprint of our data centers by integrating several design strategies such as modularity, reuse, retrofitting, [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/10/14/data-center-engineering/design-for-sustainability-new-design-principles-for-reducing-it-hardware-emissions/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/10/14/data-center-engineering/design-for-sustainability-new-design-principles-for-reducing-it-hardware-emissions/\">Design for Sustainability: New Design Principles for Reducing IT Hardware Emissions</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "We’re presenting Design for Sustainability,  a set of technical design principles for new designs of IT hardware to reduce emissions and cost through reuse, extending useful life, and optimizing design. At Meta, we’ve been able to significantly reduce the carbon footprint of our data centers by integrating several design strategies such as modularity, reuse, retrofitting, [...]\nRead More...\nThe post Design for Sustainability: New Design Principles for Reducing IT Hardware Emissions appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=23111",
        "categories": [
          "Data Center Engineering"
        ],
        "isoDate": "2025-10-14T20:40:20.000Z"
      },
      {
        "creator": "",
        "title": "How Meta Is Leveraging AI To Improve the Quality of Scope 3 Emission Estimates for IT Hardware",
        "link": "https://engineering.fb.com/2025/10/14/data-center-engineering/how-meta-is-leveraging-ai-to-improve-the-quality-of-scope-3-emission-estimates-for-it-hardware/",
        "pubDate": "Tue, 14 Oct 2025 20:40:01 +0000",
        "content:encodedSnippet": "As we focus on our goal of achieving net zero emissions in 2030, we also aim to create a common taxonomy for the entire industry to measure carbon emissions.\nWe’re sharing details on a new methodology we presented at the 2025 OCP regional EMEA summit that leverages AI to improve our understanding of our IT hardware’s Scope 3 emissions.\nWe are collaborating with the OCP PCR workstream to open source this methodology for the wider industry. This collaboration will be introduced at the 2025 OCP Global Summit.\nAs Meta focuses on achieving net zero emissions in 2030, understanding the carbon footprint of server hardware is crucial for making informed decisions about sustainable sourcing and design. However, calculating the precise carbon footprint is challenging due to complex supply chains and limited data from suppliers. IT hardware used in our data centers is a significant source of emissions, and the embodied carbon associated with the manufacturing and transportation of this hardware is particularly challenging to quantify.\nTo address this, we developed a methodology to estimate and track the carbon emissions of hundreds of millions of components in our data centers. This approach involves a combination of cost-based estimates, modeled estimates, and component-specific product carbon footprints (PCFs) to provide a detailed understanding of embodied carbon emissions. These component-level estimates are ranked by the quality of data and aggregated at the server rack level.\nBy using this approach, we can analyze emissions at multiple levels of granularity, from individual screws to entire rack assemblies. This comprehensive framework allows us to identify high-impact areas for emissions reduction. \nOur ultimate goal is to drive the industry to adopt more sustainable manufacturing practices and produce components with reduced emissions. This initiative underscores the importance of high-quality data and collaboration with suppliers to enhance the accuracy of carbon footprint calculations to drive more sustainable practices.\nWe leveraged AI to help us improve this database and understand our Scope 3 emissions associated with IT hardware by:\nIdentifying similar components and applying existing PCFs to similar components that lack these carbon estimates.\nExtracting data from heterogeneous data sources to be used in parameterized models.\nUnderstanding the carbon footprint of IT racks and applying generative AI (GenAI) as a categorization algorithm to create a new and standard taxonomy. This taxonomy helps us understand the hierarchy and hotspots in our fleet and allows us to provide insights to the data center design team in their language. We hope to iterate on this taxonomy with the data center industry and agree on an industry-wide standard that allows us to compare IT hardware carbon footprints for different types and generations of hardware.\nWhy We Are Leveraging AI \nFor this work we used various AI methods to enhance the accuracy and coverage of Scope 3 emission estimates for our IT hardware. Our approach leverages the unique strengths of both  natural language processing (NLP) and large language models (LLMs). \nNLP For Identifying Similar Components\nIn our first use case (Identifying similar components with AI), we employed various NLP techniques such as Term Frequency-Inverse Document Frequency (TF-IDF) and Cosine similarity to identify patterns within a bounded, relatively small dataset. Specifically, we applied this method to determine the similarity between different components. This approach allowed us to develop a highly specialized model for this specific task.\nLLMs For Handling and Understanding Data\nLLMs are pre-trained on a large corpus of text data, enabling them to learn general patterns and relationships in language. They go through a post-training phase to adapt to specific use cases such as chatbots. We apply LLMs, specifically Llama 3.1, in the following three different scenarios:\nTo extract and process information from diverse data sources. The benefit of LLMs is that the model can recognize different representations of the same information, even if formatted or phrased differently. (see section: Extracting Data From Heterogeneous Data)\nTo understand potential groupings of components, aiding in the creation of a new taxonomy. (see section: A Component-Level Breakdown of IT Hardware Emissions Using AI)\nOnce categories are identified, we use an LLM to strictly classify components based on text strings. This method allows us to save significant training time compared to a traditional AI model, as LLMs can be quickly prompt-engineered to handle various tasks. (see section: A Component-Level Breakdown of IT Hardware Emissions Using AI)\nUnlike the first use case, where we needed a highly specialized model to detect similarities, we opted for LLM for these three use cases because it leverages general human language rules.  This includes handling different units for parameters, grouping synonyms into categories, and recognizing varied phrasing or terminology that conveys the same concept. This approach allows us to efficiently handle variability and complexity in language, which would have required significantly more time and effort to achieve using only traditional AI. \nIdentifying Similar Components With AI\nWhen analyzing inventory components, it’s common for multiple identifiers to represent the same parts or slight variations of them. This can occur due to differences in lifecycle stages, minor compositional variations, or new iterations of the part.\nPCFs following the GHG Protocol are the highest quality input data we can reference for each component, as they typically account for the Scope 3 emissions estimates throughout the entire lifecycle of the component. However, conducting a PCF is a time-consuming process that typically takes months. Therefore, when we receive PCF information, it is crucial to ensure that we map all the components correctly.\nPCFs are typically tied to a specific identifier, along with aggregated components. For instance, a PCF might be performed specifically for a particular board in a server, but there could be numerous variations of this specific component within an inventory. The complexity increases as the subcomponents of these items are often identical, meaning the potential impact of a PCF can be significantly multiplied across a fleet.\nTo maximize the utility of a PCF, it is essential to not only identify the primary component and its related subcomponents but also identify all similar parts that a PCF could be applied to. If these similar components are not identified their carbon footprint estimates will remain at a lower data quality. Therefore, identifying similar components is crucial to ensure that we:\nLeverage PCF information to ensure the highest data quality for all components.\nMaintain consistency within the dataset, ensuring that similar components have the same or closely aligned estimates.\nImprove traceability of each component’s carbon footprint estimate for reporting.\nTo achieve this, we employed a natural language processing (NLP) algorithm, specifically tailored to the language of this dataset, to identify possible proxy components by analyzing textual descriptions and filtering results by component category to ensure relevance.\nThe algorithm identifies proxy components in two distinct ways:\nLeveraging New PCFs: When a new PCF is received, the algorithm uses it as a reference point. It analyzes the description names of components within the same category to identify those with a high percentage of similarity. These similar components can be mapped to a representative proxy PCF, allowing us to use high-quality PCF data in similar components.\nImproving Low Data Quality Components: For components with low data quality scores, the algorithm operates in reverse with additional constraints. Starting with a list of low-data-quality components, the algorithm searches for estimates that have a data quality score greater than a certain threshold. These high-quality references can then be used to improve the data quality of the original low-scoring components.\nMeta’s Net Zero team reviews the proposed proxies and validates our ability to apply them in our estimates. This approach enhances the accuracy and consistency of component data, ensures that high-quality PCF data is effectively utilized across similar components, and enables us to design our systems to more effectively reduce emissions associated with server hardware.\nExtracting Data From Heterogeneous Data Sources\nWhen PCFs are not available, we aim to avoid using spend-to-carbon methods because they tie sustainability too closely to spending on hardware and can be less accurate due to the influence of factors like supply chain disruptions. \nInstead, we have developed a portfolio of methods to estimate the carbon footprint of these components, including through parameterized modeling. To adapt any model at scale, we require two essential elements: a deterministic model to scale the emissions, and a list of data input parameters. For example, we can scale the carbon footprint calculation for a component by knowing its constituent components’ carbon footprint.\nHowever, applying this methodology can be challenging due to inconsistent description data or locations where information is presented. For instance, information about cables may be stored in different tables, formats, or units, so we may be unable to apply models to some components due to difficulty in locating  input data.\nTo overcome this challenge, we have utilized large language models (LLMs) that extract information from heterogeneous sources and inject the extracted information into the parameterized model. This differs from how we apply NLP, as it focuses on extracting information from specific components. Scaling a common model ensures that the estimates provided for these parts are consistent with similar parts from the same family and can inform estimates for missing or misaligned parts.\nWe applied this approach to two specific categories: memory and cables. The LLM extracts relevant data (e.g., the capacity for memory estimates and length/type of cable for physics-based estimates) and scales the components’ emissions calculations according to the provided formulas. \nA Component-Level Breakdown of IT Hardware Emissions Using AI\nWe utilize our centralized component carbon footprint database not only for reporting emissions, but also to drive our ability to efficiently deploy emissions reduction interventions. Conducting a granular analysis of component-level emissions enables us to pinpoint specific areas for improvement and prioritize our efforts to achieve net zero emissions. For instance, if a particular component is found to have a disproportionately high carbon footprint, we can explore alternative materials or manufacturing processes to mitigate its environmental impact. We may also determine that we should reuse components and extend their useful life by testing or augmenting component reliability. By leveraging data-driven insights at the component level and driving proactive design interventions to reduce component emissions, we can more effectively prioritize sustainability when designing new servers.\nWe leverage a bill of materials (BOM) to list all of the components in a server rack in a tree structure, with “children” component nodes listed under “parent” nodes. However, each vendor can have a different BOM structure, so two identical racks may be represented differently. This, coupled with the heterogeneity of methods to estimate emissions, makes it challenging to easily identify actions to reduce component emissions.\nTo address this challenge, we have used AI to categorize the descriptive data of our racks into two hierarchical levels:\nDomain-level: A high-level breakdown of a rack into main functional groupings (e.g., compute, network, power, mechanical, and storage)\nComponent-level: A detailed breakdown that highlights the major components that are responsible for the bulk of Scope 3 emissions (e.g., CPU, GPU, DRAM, Flash, etc.)\nWe have developed two classification models: one for “domain” mapping, and another for “component” mapping. The difference between these mappings lies in the training data and the additional set of examples provided to each model. We then combine the two classifications to generate a mutually exclusive hierarchy.\nDuring the exploration phase of the new taxonomy generation, we allowed the GenAI model to operate freely to identify potential categories for grouping. After reviewing these potential groupings with our internal hardware experts, we established a fixed list of major components. Once this list was finalized, we switched to using a strict GenAI classifier model as follows:\nFor each rack, recursively identify the highest contributors, grouping smaller represented items together.\nRun a GenAI mutually exclusive classifier algorithm to group the components into the identified categories.\n \nThe emissions breakdown for a generic compute rack.\nThis methodology has been presented at the 2025 OCP regional EMEA summit with the goal to drive the industry toward a common taxonomy for carbon footprint emissions, and open source the methodology we used to create our taxonomy.\nThese groupings are specifically created to aid carbon footprint analysis, rather than for other purposes such as cost analysis. However, the methodology can be tailored for other purposes as necessary.\nComing Soon: Open Sourcing Our Taxonomies and Methodologies\nAs we work toward achieving net zero emissions across our value chain in 2030, this component-level breakdown methodology is necessary to help understand our emissions at the server component level. By using a combination of high-quality PCFs, spend-to-carbon data, and a portfolio of methods that leverage AI, we can enhance our data quality and coverage to more effectively deploy emissions reduction interventions. \nOur next steps include open sourcing:\nThe taxonomy and methodology for server rack emissions accounting.\nThe taxonomy builder using GenAI classifiers.\nThe aggregation methodology to improve facility reporting processes across the industry.\nWe are committed to sharing our learnings with the industry as we evolve this methodology, now as part of a collaborative effort with the OCP PCR group.\nThe post How Meta Is Leveraging AI To Improve the Quality of Scope 3 Emission Estimates for IT Hardware appeared first on Engineering at Meta.",
        "dc:creator": "",
        "content": "<p>As we focus on our goal of achieving net zero emissions in 2030, we also aim to create a common taxonomy for the entire industry to measure carbon emissions. We’re sharing details on a new methodology we presented at the 2025 OCP regional EMEA summit that leverages AI to improve our understanding of our IT [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/10/14/data-center-engineering/how-meta-is-leveraging-ai-to-improve-the-quality-of-scope-3-emission-estimates-for-it-hardware/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/10/14/data-center-engineering/how-meta-is-leveraging-ai-to-improve-the-quality-of-scope-3-emission-estimates-for-it-hardware/\">How Meta Is Leveraging AI To Improve the Quality of Scope 3 Emission Estimates for IT Hardware</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n",
        "contentSnippet": "As we focus on our goal of achieving net zero emissions in 2030, we also aim to create a common taxonomy for the entire industry to measure carbon emissions. We’re sharing details on a new methodology we presented at the 2025 OCP regional EMEA summit that leverages AI to improve our understanding of our IT [...]\nRead More...\nThe post How Meta Is Leveraging AI To Improve the Quality of Scope 3 Emission Estimates for IT Hardware appeared first on Engineering at Meta.",
        "guid": "https://engineering.fb.com/?p=23123",
        "categories": [
          "Data Center Engineering",
          "ML Applications"
        ],
        "isoDate": "2025-10-14T20:40:01.000Z"
      }
    ]
  },
  {
    "name": "eBay Tech Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Twitter Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "JetBrains: Developer Tools for Professionals and Teams – Company Blog | JetBrains",
    "category": "기업",
    "posts": [
      {
        "creator": "Sasha Ivanova",
        "title": "Coming to Rider 2025.3: ASP.NET and Database Issue Detection In The Monitoring Tool Window",
        "link": "https://blog.jetbrains.com/dotnet/2025/10/20/rider-2025-3-asp-dotnet-and-database-issue-monitoring/",
        "pubDate": "Mon, 20 Oct 2025 13:01:21 +0000",
        "content:encodedSnippet": "In Rider 2025.3, the Monitoring tool window has become even more powerful with the addition of database and ASP.NET issue detection. These new capabilities let you track slow queries, inefficient request handling, and other performance bottlenecks in real time – right alongside CPU, memory, and GC activity. \nYou can explore these new additions in the Rider 2025.3 EAP 6 build –  let’s take a closer look at what you can expect.\nTry it in Rider 2025.3 EAP 6\n                                                    \nA single home for performance insights\nThe Monitoring tool window now serves as a central hub for tracking your application’s runtime behavior – CPU usage, memory allocation, garbage collection, environment variables, and performance issues are all tracked within a single interface.\nWith the inclusion of Database and ASP.NET issue detection, the tool automatically highlights slow queries, excessive database connections, or long-running MVC actions and Razor handlers. These now appear alongside other runtime insights such as UI freezes, GC pressure, and performance hotspots.\n\n\n\n\nDetected issues appear directly beneath the live performance charts. You’ll see issue types like DB Command Time, DB Connections, and slow MVC actions.  If you have a dotUltimate subscription, these general issue types will be replaced with names of the specific methods responsible. A dotUltimate subscription will also let you investigate each entry further using the bundled dotTrace profiler, allowing you to explore call stacks, query details, and execution times with just a couple clicks.\nThere’s no need to wait until your session ends to see what’s going on. ASP.NET and database issues now appear and update in real time, so you can spot and understand performance bottlenecks as they happen.\nYou can configure thresholds and manage the inspections by going to Settings/Preferences | Build, Execution, Deployment | Monitoring | Inspections. \nCompatibility and availability\nASP.NET and database issue detection is available on Windows, Linux, and macOS. You can find additional information on supported OSs and application types in our documentation.\nIf you have a dotUltimate subscription, you can take your investigation even further with the bundled dotTrace profiler, which lets you jump straight to the problematic line in your source code.\n___________________________________________________________________________\nWith everything unified in the Monitoring tool window, you no longer need to juggle multiple tools or wonder where to look when performance issues arise. Database bottlenecks, ASP.NET inefficiencies, and runtime anomalies are now captured and visualized in one place, giving you the full picture of your application’s health at a glance.\nReady to try it out? Download Rider 2025.3 EAP 6, start running or debugging your application, and the Monitoring tool window will open automatically. \nTry it in Rider 2025.3 EAP 6\n                                                    \nYou’ll be able to troubleshoot performance issues more quickly and intuitively than ever. As always, we’d love to hear your feedback. Let us know what you think in the comments below!",
        "dc:creator": "Sasha Ivanova",
        "content": "In Rider 2025.3, the Monitoring tool window has become even more powerful with the addition of database and ASP.NET issue detection. These new capabilities let you track slow queries, inefficient request handling, and other performance bottlenecks in real time – right alongside CPU, memory, and GC activity.&#160; You can explore these new additions in the [&#8230;]",
        "contentSnippet": "In Rider 2025.3, the Monitoring tool window has become even more powerful with the addition of database and ASP.NET issue detection. These new capabilities let you track slow queries, inefficient request handling, and other performance bottlenecks in real time – right alongside CPU, memory, and GC activity.  You can explore these new additions in the […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=651200",
        "categories": [
          "net-tools",
          "rider",
          "dotrace",
          "dpa",
          "dynamic-program-analysis"
        ],
        "isoDate": "2025-10-20T13:01:21.000Z"
      },
      {
        "creator": "Katie Fraser",
        "title": "Computer Science Learning Curve: Insights from 18k Learners Worldwide",
        "link": "https://blog.jetbrains.com/research/2025/10/computer-science-learning-curve/",
        "pubDate": "Mon, 20 Oct 2025 06:52:48 +0000",
        "content:encodedSnippet": "The world of computer science (CS) education is changing rapidly. From AI-powered tools to new modes of online and blended learning, it has never been more dynamic – or more critical. Education research has looked into some aspects of how students learn computer science, but when we ask the big questions about who is learning computer science, how, and why, there are surprisingly few big-picture studies out there. \nOur Education Research team with our Strategic Research and Market Intelligence and JetBrains Academy teams addressed this gap by surveying a diverse audience on a wide range of topics. The collaboration combined their strengths: JetBrains Research brought expertise in conducting studies and writing research papers, while SRMI and JetBrains Academy brought experience with large-scale industry surveys. The dataset is available online, and we encourage you to explore it yourself!\nDownload the dataset\n                                    \nOur researchers will present insights from the study this October 23rd at ACM CompEd, a SIGCSE family conference. And in this blog post, we will tell you about the survey and the paper to be presented, including:\nWhy this kind of study is important\nHow the survey was set up\nWhat applications the results have in the real-world \nHow you can work with the data and collaborate with us\nThe importance of the big picture in computer science education\nWhile individual studies have examined specific aspects of CS learning, few have captured the global picture at scale. Studies are often limited in terms of sample demographics, for example, in types of education (both formal, like university, and informal, like self-paced courses or bootcamps), participant number or country. This limitation leaves educators and policymakers without the necessary insights into how people worldwide approach CS education today. Especially considering that many people learn online, we need more collaboration and broader studies revealing higher-level trends that might otherwise be missed.\nRecognizing this gap, our Education Research, our Strategic Research and Market Intelligence, and JetBrains Academy teams conducted a comprehensive survey of CS learners, representing 18,032 participants across 173 countries (paper, dataset). Our initial goal was to better understand how people learn to program today, in order to make our tools more supportive for learners. While working on the survey, we realized that the dataset has potential for other researchers; this realization led to the paper and making the dataset available on Zenodo.\nThe study has many advantages over similar work done previously. For one, it explicitly includes self-taught learners, which has been rare in previous studies. On top of that, it includes:\nA wide range of topics and questions\nA diverse set of learners to ensure broad representation\nThis post will describe the details of the study’s methodology and discuss both its key findings and potential applications.\nOur computer science education survey\nA primary goal of our study was to survey a broad sample size of CS learners about diverse topics. The results have been – and continue to be – useful here at JetBrains to improve our educational products. And the impact doesn’t have to end within our company or with our products: this dataset is available for anybody to explore!\nWith our comprehensive survey, we want to provide an example of collaboration between industry and academia. Industry resources can help academic researchers tap into a broader pool of participants or at a larger scale; and by agreeing on open data sharing, the data and results are available to the entire research community. These are just some ways  we can work together to learn about CS education and, ultimately, to help CS students.\nThe rest of this section will describe the methodology behind the dataset, including survey design, data collection, and data processing. The next section will discuss insights that have already been gained from the survey, plus further potential applications.\nData collection\nOur Strategic Research and Market Intelligence team prepared the survey and piloted it internally at JetBrains before a wider external release. The survey contained 87 questions (a mix of open and multiple-choice; all can be found here), organized into the following 10 topics:\nDemographics. Basic demographic identifiers: age, gender, geographical location, and language preferences.\nFormal Education. Educational level, institution types, and fields of study.\nCareer. Career trajectory, industry experience, professional development, and job-seeking behaviors.\nLearning Topics and Formats. Subject areas studied, self-assessed proficiency, educational platforms, and course preferences.\nCoding Experience. Technology adoption patterns and development practices.\nDevelopment Tools. IDE usage patterns and tool preferences.\nAI Integration. AI tool usage in learning contexts (for the state of things at data collection).\nLearning Challenges. Obstacles, reasons for quitting, and methods to overcome learning difficulties.\nStudy Habits. Learning routines, environments, productivity strategies, and device usage.\nMotivation. Drivers for CS education engagement.\nWith many topics, and many questions, there is both the opportunity to gain a better understanding of CS education and also see relationships between categories that might otherwise be missed.\nIn addition, our team:\nLocalized the survey questions into ten languages, namely:\n\nEnglish, Chinese, French, German, Japanese, Korean, Brazilian Portuguese, Russian, Spanish, and Turkish\nRecruited participants with:\n\nTargeted advertisements on social media platforms\nInvitations to a list of people who have already given consent to be contacted by JetBrains for research purposes\nExternal survey panels to ensure responses from underrepresented regions such as Japan and Ukraine\nCollected the data in the first half of 2024\nAfter collecting the initial data, our team did a sanity check, removing suspicious responses, similar to other large surveys’ methodologies (see Stack Overflow or DevEco). Examples of suspicious responses include low reported age in combination with high experience or unusually quick response times, i.e., less than five seconds per question. \nFollowing the sanity check, the dataset contained 18,032 responses from 173 countries. Note that 14,396 of these are full responses, meaning that these respondents completed all questions in the survey.\nData processing\nFor this survey, data processing comprised two main steps: (i) translating all responses into English and (ii) coding the responses into categories for analysis. The following table contains example responses and their labels for the open-ended question Do you have any methods of overcoming frustration and/or the feeling that you want to give up on your studies?\n\n\n\n\nFor both steps, our research team used GPT-4o. While coding the responses into categories, we had to manually review the LLM output. For example, we checked the number of clusters per question, the naming of clusters for each question, and how the responses were distributed across these clusters.This manual review was necessary because the LLM would group some of the inputs into an Other category even though they might actually belong to a category; in some cases, multiple responses marked as Other would form a new category.\nIn addition to data processing, our researchers were careful to address potential sampling bias (details can be found in the paper). They followed industry standards in weighing the data (see, for example, the detailed methodology for DevEco or the methodology for DeveloperNation’s Pulse Report), assigning a weight to each response so that underrepresented groups would have more influence in the analysis. The main feature of the weighting process was to divide the results into:\nExternal: collected from social network ads, together with responses from peer referrals\nInternal: collected from JetBrains social networks and the JetBrains email list \nOne goal of weighting external responses was to elevate responses from underrepresented countries. Based on previous internal research, our team determined what the expected distribution should look like and applied the post-stratification method to it.\nFor the internal responses, in addition to the country bias, potential biases include a higher proportion of JetBrains product users and a higher amount of experience in software engineering overall. In this case, the weighting technique, a type of calibration, involved using information from the external responses for the country bias, plus a series of calculations.\nBy applying the weighting methodology to both the internal and external responses, our team reduced potential biases. This ensured the study remained as unbiased as possible across the diverse global sample. \nThe full dataset, including categorization and data weighting, is available as supplementary material. The supplementary material, in particular the dataset, is intended to be accessible (and useful!) to researchers regardless of their technical background.\nReal-world applications\nIn the paper, our team presented the following example research directions and their corresponding results. We will go into more detail about them in the rest of this section.  which might inspire you for your own analysis based on the dataset:\nLearning challenges\nEmerging learning formats, including massive open online courses (MOOCs) and code schools\nIn-Integrated developer environment (–IDE) learning practices\nThese are just a sample of what could be explored. For example, you could look at the table from the previous section and pick out a topic to explore further,  like learning motivations. Or, you could look at how AI integrations look today compared to data collection. Or see if there is a relationship between students’ learning routines and frequency of quitting. What would your research idea be?\nLearning challenges\nFirst, we will look at what frustrations students identify when studying CS. Previous studies on this topic have looked specifically at why some students drop out of formal CS programs at universities, why some students persevere in the same type of program, and the challenges faced in different learning modes such as massive open online courses (MOOCs) and in-IDE learning. Our dataset builds on this body of work, complementing their results. Some of the relevant survey questions are listed below.\n\n\n\n\nThe first two of the above questions were multiple-choice, and only the third one was open-ended. For the multiple-choice questions, participants could pick more than one answer.\nFor the first question, the participants selected several challenges, both at the theoretical and practical levels. The top five choices and their percentages are shown in the following infographic.\n\n\n\n\nThere are some students who find learning CS so challenging that they decide to abandon their studies. The survey participants reported Unengaging content as a top reason for leaving, followed by Heavy workload and time constraints. These and the rest of the top five reasons are depicted below.\n\n\n\n\nDespite the challenges, many CS learners find ways to stay motivated and continue learning. Commonly reported methods of overcoming frustration are listed in the image below. Note that this question was the only open-ended one of the bunch, so the responses were categorized during data processing.\n\n\n\n\nThe students who answered this question reported a variety of methods, but one of the most common responses was that they are still looking for an effective way to overcome frustrations in CS learning. For educators and those creating CS courses, this is a valuable insight!\nIn summary, studying CS involves challenges like abstract concepts, heavy workloads, and unengaging content, which can lead to frustration and course dropout. To cope, students try to offset the frustration with physical activity and internal motivations, but many still need support in this. Our dataset can offer answers to questions about student behavior beyond what is reported here.\nLearning formats\nIn this subset of questions, we were interested in the most popular learning formats and what the participants’ experience with them was. Although we already know that it is possible to study CS with in-IDE courses or with MOOCs, we were interested in a more systematic view of learning formats and in including more formal education options like university. The relevant survey questions are listed below; all three were multiple-choice.\n\n\n\n\nFirst, we will look at the most common learning formats, depicted in the below infographic. The most popular format is to learn at university, college, or school at about 80%; the second most popular are self-paced online tutorials with two-thirds of the participants reporting this experience. Internships and paid online courses, for example, are less common, at about 30% for each.\n\n\n\n\nInterestingly, while formal CS studies are very popular, our survey participants rated this format as the worst. More positively rated learning formats include both the more common self-paced online tutorials, and the less common paid online courses and internships. Check out the ratings in the below image.\n\n\n\n\nAs far as which online courses are the most popular, we can see in the following image that Udemy is used by about 30% of respondents, followed by Coursera at 20% and JetBrains Academy at just above 15%.\n\n\n\n\nFrom this data, it is clear that students are exploring alternative learning formats, in addition to the traditional formal schooling path, and that they often rate the former better than the latter. As our dataset is available online, it can be used by any researcher to target more narrow topics or specific correlations not reported here – and we think there are many more patterns to explore!\nIn-IDE learning\nFinally, we will look at CS learners’ challenges with in-IDE learning, a format that can be found in a subset of online CS courses. In-IDE learning is new and is becoming more and more popular, as the student can learn to code inside of a professional IDE, i.e., with an industry tool. For this topic, our researchers identified a subset of survey respondents based on answers to the following questions.\n\n\n\n\nFor example, if a respondent indicated that they recently studied CS and currently use a MOOC such as JavaRush or JetBrains Academy, it is very likely that they are familiar with in-IDE learning. After identifying a subset, we then looked at their responses to the following question:\n\n\n\n\nThe top responses in this subset parallel what we saw above in the previous subsection about general CS learning challenges: as shown in the below figure, the most common reported challenge is Understanding abstract and complex concepts. \n\n\n\n\nWhere this subset differs from the broader dataset is in the subsequent categories: Hard to choose learning materials, courses, and platforms moved up to the top three, and categories like Getting stuck on a particular problem fell further down in importance. As in-IDE learning is quite new, it makes sense that getting oriented within the IDE presents a bigger challenge to students than completing specific tasks.\nAs this research direction concerns a very new learning format, it shows the most potential for future studies about CS learners. In addition, we reported this subset’s data as an example of how our dataset can be mined for information about particular groups, whether based on geographical location, area of study, or, as was done here, learning format subset.  \nWant to collaborate with us?\nOur CS education dataset contains both broad topics and a broad demographic. In this way, it is suitable for the quantitative analysis of many CS-learning-related topics. Researchers can focus on specific subsets of the data or examine interactions between multiple variables to uncover new insights about CS education effectiveness. \nThis project also shows the potential of industry-academia partnerships in educational research. The benefits of combining industry resources with academic rigor include the following:\nWe can conduct studies at scales previously impossible for individual institutions.\nWe can accelerate progress in understanding educational effectiveness and help institutions make evidence-based decisions about curriculum design, teaching methods, and student support services. \nThe commitment to open data sharing ensures that insights benefit the entire research community rather than remaining proprietary.\nThe Edu Research lab welcomes inquiries about dataset usage, research partnerships, and suggestions for future survey topics. Whether you’re investigating specific aspects of CS education or proposing new research directions, we’re eager to support studies that advance our understanding of effective computer science learning.\nTo discuss collaboration opportunities or share your research ideas for future global surveys:\nContact the Edu Research team\n                                    \nWant to learn more about research insights and take part in future JetBrains studies? Join our JetBrains Tech Insights Lab!",
        "dc:creator": "Katie Fraser",
        "content": "The world of computer science (CS) education is changing rapidly. From AI-powered tools to new modes of online and blended learning, it has never been more dynamic – or more critical. Education research has looked into some aspects of how students learn computer science, but when we ask the big questions about who is learning [&#8230;]",
        "contentSnippet": "The world of computer science (CS) education is changing rapidly. From AI-powered tools to new modes of online and blended learning, it has never been more dynamic – or more critical. Education research has looked into some aspects of how students learn computer science, but when we ask the big questions about who is learning […]",
        "guid": "https://blog.jetbrains.com/?post_type=research&p=648790",
        "categories": [
          "jetbrains-academy",
          "research",
          "education-research",
          "jetbrains-research",
          "market-research",
          "strategic-research-and-market-intelligence"
        ],
        "isoDate": "2025-10-20T06:52:48.000Z"
      },
      {
        "creator": "Daniela Bentrup",
        "title": "Koog 0.5.0 Is Out: Smarter Tools, Persistent Agents, and Simplified Strategy Design",
        "link": "https://blog.jetbrains.com/ai/2025/10/koog-0-5-0-is-out-smarter-tools-persistent-agents-and-simplified-strategy-design/",
        "pubDate": "Fri, 17 Oct 2025 07:19:48 +0000",
        "content:encodedSnippet": "We recently released Koog 0.5.0, introducing full Agent2Agent (A2A) protocol support, which makes it easier than ever to build systems of interconnected AI agents in Kotlin.\nBut A2A is just the beginning. Koog 0.5.0 brings a host of improvements that make agents more persistent, tools smarter, and strategy design more intuitive. Let’s dive into the highlights.\n💡 Non-graph API for strategies\nKoog 0.5.0 introduces a non-graph API for defining agent strategies. You can now create and modify agent strategies directly in Kotlin, without working with graphs. The new non-graph API keeps most of Koog’s core features, including state management and history compression, so you can prototype custom strategies faster. \nYou can now streamline your development cycle. Start simple with the out-of-the-box AIAgent using the default strategy. Then, experiment with the non-graph API to quickly test and find the best configuration for your task through straightforward code. Once you’re ready, scale it into a graph workflow to take full advantage of persistence for maximum reliability, as well as nested event tracing for deeper insights to build and test strategies more efficiently.\n🔁 Agent persistence and checkpointing improvements\nComplex AI workflows often depend on persistence – the ability to save and restore state without losing context or causing unintended side effects. Since we introduced persistence in Koog 0.4.0, we’ve continued to build on it to make agent state management much more reliable and flexible.\nThe new RollbackToolRegistry enables agents to undo side effects from tool calls when checkpointing, ensuring that rollbacks don’t leave your environment in an inconsistent state.\nYou can now also toggle between full state-machine persistence and message history persistence, giving you control over how much of the agent’s internal state to preserve.\n⚒️ Tool API enhancements\nTools are the backbone of Koog’s agent capabilities. This release refines the Tool API to make tool development and integration smoother.\nTool descriptors are now automatically generated for class-based tools across all platforms. With this update, defining tools on multiplatform works just as smoothly as on the JVM, removing redundant setup and keeping your Tool API definitions concise and consistent.\nWith improvements to subgraphWithTask and subgraphWithVerification, finishTools is no longer required, and neither is the SubgraphResult type. You can now specify any input type, output type (including primitive types), task, tools, and models, and everything works automatically. There’s no more boilerplate – Koog infers and generates it all for you.\n👋 Introducing AIAgentService\nManaging multiple agents is now easier with the new AIAgentService. It allows you to run and manage multiple AI agents as single-use, state-managed services.\n🧑‍⚖️ New components and smarter interactions\nKoog 0.5.0 also introduces new components that enhance reasoning and control in agent systems. \nLLM as a judge is a new component that uses large language models to evaluate outputs or guide decision-making processes.\nIn version 0.5.0, we’ve added a strategy for iterative tool calling with structured outputs. This makes it much easier to obtain typed results from any agent without having to write custom code. \nStreaming now supports tool calls, allowing the use of tools while receiving results from an LLM on the fly. With this update, front-end integrated agents can now stream partial outputs to the user interface while still invoking tools as needed.\nWrapping up\nKoog 0.5.0 isn’t just about connecting agents – it’s about empowering them to be smarter, more persistent, and easier to design. Whether you’re experimenting with lightweight strategies, managing long-lived agent sessions, or creating sophisticated toolchains, this release brings significant improvements across the board.\n✨ Try Koog 0.5.0\nIf you’re building agents that need to be more connected, persistent, and easier to design, Koog 0.5.0 is the right choice. Explore the docs, build systems of multiple AI agents, and experiment faster while still benefiting from Koog’s advanced features.\n🤝 Your contributions make a difference\nWe’d like to take this opportunity to extend a huge thank-you to the entire community! Your feedback, issue reports, and pull requests have been invaluable for the development of Koog!\nA special shoutout to this release’s top contributors:\nStan – refactored the streaming API to support tool calls.\nSiarhei Luskanau – added the iOS target and enabled web support for demo-compose-app.\nDidier Villevalois – added an option to dynamically adjust context window sizes for Ollama.\nRuben Cagnie – implemented support for the tool-calling strategy in structured output.",
        "dc:creator": "Daniela Bentrup",
        "content": "We recently released Koog 0.5.0, introducing full Agent2Agent (A2A) protocol support, which makes it easier than ever to build systems of interconnected AI agents in Kotlin. But A2A is just the beginning. Koog 0.5.0 brings a host of improvements that make agents more persistent, tools smarter, and strategy design more intuitive. Let’s dive into the [&#8230;]",
        "contentSnippet": "We recently released Koog 0.5.0, introducing full Agent2Agent (A2A) protocol support, which makes it easier than ever to build systems of interconnected AI agents in Kotlin. But A2A is just the beginning. Koog 0.5.0 brings a host of improvements that make agents more persistent, tools smarter, and strategy design more intuitive. Let’s dive into the […]",
        "guid": "https://blog.jetbrains.com/?post_type=ai&p=651225",
        "categories": [
          "news",
          "releases",
          "ai",
          "ai-agents"
        ],
        "isoDate": "2025-10-17T07:19:48.000Z"
      },
      {
        "creator": "Elena Kerpeleva",
        "title": "JetBrains Plugin Developer Conf 2025 Is Coming Up Soon!",
        "link": "https://blog.jetbrains.com/platform/2025/10/jetbrains-plugin-developer-conf-2025-is-coming-up-soon/",
        "pubDate": "Thu, 16 Oct 2025 21:38:13 +0000",
        "content:encodedSnippet": "Hey everyone! We’re excited to announce that JetBrains Plugin Developer Conf returns this November. Join us on Wednesday, November 5 for a full day of inspiring talks, live Q&A sessions, and deep dives into the latest in plugin development.\nRegister Now\n                                                    \nWhether you’re just getting started or already publishing on JetBrains Marketplace, you’ll find new ideas, practical techniques, and stories from plugin developers who’ve been there.\n\n\n\n\nThe talks on this year’s agenda include:\nKeynote by Ivan Chirkov, Jakub Chrzanowski, and Robert Novotny\nFrom Template to Marketplace: Creating Your First Plugin by Dmitrii Derepko\nDeveloping a Language Plugin: LSP Versus the Joy of Learning by Aleksandr Slepchenkov\nKotlin Notebook Meets IntelliJ Platform by Jakub Chrzanowski\nBuilding in Constrained Environments: Lessons From YouTrack Apps by Tommaso Gionfriddo\nAI-Powered Test Generation Straight From Your Debugger by Michael Solovev\nMaking an IntelliJ Plugin Remote Development-Friendly by Nikita Katkov\nHow to Investigate UI Freezes by Konstantin Nisht\nRegister Now\n                                                    \nYou can choose whether to attend just a few individual sessions or watch every one of them. We hope you enjoy the talks, and we encourage you to ask questions!\nWe’ll stream the presentations live on YouTube, and all the sessions will remain available after the event is over so you can catch up on any you missed.",
        "dc:creator": "Elena Kerpeleva",
        "content": "Hey everyone!&#160;We’re excited to announce that JetBrains Plugin Developer Conf returns this November. Join us on Wednesday, November 5 for a full day of inspiring talks, live Q&#38;A sessions, and deep dives into the latest in plugin development. Whether you’re just getting started or already publishing on JetBrains Marketplace, you’ll find new ideas, practical techniques, [&#8230;]",
        "contentSnippet": "Hey everyone! We’re excited to announce that JetBrains Plugin Developer Conf returns this November. Join us on Wednesday, November 5 for a full day of inspiring talks, live Q&A sessions, and deep dives into the latest in plugin development. Whether you’re just getting started or already publishing on JetBrains Marketplace, you’ll find new ideas, practical techniques, […]",
        "guid": "https://blog.jetbrains.com/?post_type=platform&p=651276",
        "categories": [
          "events",
          "livestream",
          "marketplace",
          "news",
          "plugins",
          "jetbrains-marketplace",
          "plugin-development"
        ],
        "isoDate": "2025-10-16T21:38:13.000Z"
      },
      {
        "creator": "Anna Protsenko",
        "title": "The “10x” Commandments of Highly Effective Go",
        "link": "https://blog.jetbrains.com/go/2025/10/16/the-10x-commandments-of-highly-effective-go/",
        "pubDate": "Thu, 16 Oct 2025 11:13:18 +0000",
        "content:encodedSnippet": "This is a guest post from John Arundel of Bitfield Consulting, a Go trainer and writer who runs a free newsletter for Go learners. His most recent book is The Deeper Love of Go.\nEver wondered if there’s a software engineer, somewhere, who actually knows what they’re doing? Well, I finally found the one serene, omnicompetent guru who writes perfect code. I can’t disclose the location of her mountain hermitage, but I can share her ten mantras of Go excellence. Let’s meditate on them together.\n1. Write packages, not programs\nThe standard library is great, but the universal library of free, open-source software is Go’s biggest asset. Return the favour by writing not just programs, but packages that others can use too.\nYour main function’s only job should be parsing flags and arguments, and handling errors and cleanup, while your imported “domain” package does the real work.\nFlexible packages return data instead of printing, and return errors rather than calling panic or os.Exit. Keep your module structure simple: ideally, one package.\nTip: Use Structure view (Cmd-F12) for a high-level picture of your module.\n\n\n\n\n2. Test everything\nWriting tests helps you dogfood your packages: awkward names and inconvenient APIs are obvious when you use them yourself.\nTest names should be sentences. Focus tests on small units of user-visible behaviour. Add integration tests for end-to-end checks. Test binaries with testscript.\nTip: Use GoLand’s “generate tests” feature to add tests for existing code. Run with coverage can identify untested code. Use the debugger to analyse test failures.\n\n\n\n\n3. Write code for reading\nAsk a co-worker to read your code line by line and tell you what it does. Their stumbles will show you where your speed-bumps are: flatten them out and reduce cognitive load by refactoring. Read other people’s code and notice where you stumble—why?\nUse consistent naming to maximise glanceability: err for errors, data for arbitrary []bytes, buf for buffers, file for *os.File pointers, path for pathnames, i for index values, req for requests, resp for responses, ctx for contexts, and so on.\nGood names make code read naturally. Design the architecture, name the components, document the details. Simplify wordy functions by moving low-level “paperwork” into smaller functions with informative names (createRequest, parseResponse).\nTip: In GoLand, use the Extract method refactoring to shorten long functions. Use Rename to rename an identifier everywhere.\n\n\n\n\n4. Be safe by default\nUse “always valid values” in your programs, and design types so that users can’t accidentally create values that won’t work. Make the zero value useful for literals, or write a validating constructor that guarantees a valid, usable object with default settings. Add configuration using WithX methods:\nwidget := NewWidget().WithTimeout(time.Second)\nUse named constants instead of magic values. http.StatusOK is self-explanatory; 200 isn’t. Define your own constants so IDEs like GoLand can auto-complete them, preventing typos. Use iota to auto-assign arbitrary values:\nconst (\n    Planet = iota // 0\n    Star          // 1\n    Comet         // 2\n    // ...\n)\nPrevent security holes by using os.Root instead of os.Open, eliminating path traversal attacks:\nroot, err := os.OpenRoot(\"/var/www/assets\")\nif err != nil {\n    return err\n}\ndefer root.Close()\nfile, err := root.Open(\"../../../etc/passwd\")\n// Error: 'openat ../../../etc/passwd: path escapes from parent'\n<code data-enlighter-language=\"generic\" class=\"EnlighterJSRAW\"></code>\nDon’t require your program to run as root or in setuid mode; let users configure the minimal permissions and capabilities they need.\nTip: Use Goland’s Generate constructor and Generate getter and setter functions to help you create always valid struct types.\n\n\n\n\n5. Wrap errors, don’t flatten\nDon’t type-assert errors or compare error values directly with ==, define named “sentinel” values that users can match errors against:\nvar ErrOutOfCheese = \"++?????++ Out of Cheese Error. Redo From Start.\"\nDon’t inspect the string values of errors to find out what they are; this is fragile. Instead, use errors.Is:\nif errors.Is(err, ErrOutOfCheese) {\nTo add run-time information or context to an error, don’t flatten it into a string. Use the %w verb with fmt.Errorf to create a wrapped error:\nreturn fmt.Errorf(\"GNU Terry Pratchett: %w\", ErrOutOfCheese)\nThis way, errors.Is can still match the wrapped error against your sentinel value, even though it contains extra information.\nTip: GoLand will warn you against comparing or type-asserting error values.\n\n\n\n\n6. Avoid mutable global state\nPackage-level variables can cause data races: reading a variable from one goroutine while writing it from another can crash your program. Instead, use a sync.Mutex to prevent concurrent access, or allow access to the data only in a single “guard” goroutine that takes read or write requests via a channel.\nDon’t use global objects like http.DefaultServeMux or DefaultClient;  packages you import might invisibly change these objects, maliciously or otherwise. Instead, create a new instance with http.NewServeMux (for example) and configure it how you want.\nTip: Use GoLand’s Run/Debug Configurations settings to enable the Go race detector for testing concurrent code.\n\n\n\n\n7. Use (structured) concurrency sparingly\nConcurrent programming is a minefield: it’s easy to trigger crashes or race conditions. Don’t introduce concurrency to a program unless it’s unavoidable. When you do use goroutines and channels, keep them strictly confined: once they escape the scope where they’re created, it’s hard to follow the flow of control. “Global” goroutines, like global variables, can lead to hard-to-find bugs.\nMake sure any goroutines you create will terminate before the enclosing function exits, using a context or waitgroup:\nvar wg sync.WaitGroup\nwg.Go(task1)\nwg.Go(task2)\nwg.Wait()\nThe Wait call ensures that both tasks have completed before we move on, making control flow easy to understand, and preventing resource leaks.\nUse errgroups to catch the first error from a number of parallel tasks, and terminate all the others:\nvar eg errgroup.Group\neg.Go(task1)\neg.Go(task2)\nerr := eg.Wait()\nif err != nil {\n\tfmt.Printf(\"error %v: all other tasks cancelled\", err)\n} else {\n\tfmt.Println(\"all tasks completed successfully\")\n}\nWhen you take a channel as the parameter to a function, take either its send or receive aspect, but not both. This prevents a common kind of deadlock where the function tries to send and receive on the same channel concurrently.\nfunc produce(ch chan<- Event) {\n\t// can send on `ch` but not receive\n}\n\nfunc consume(ch <-chan Event) {\n\t// can receive on `ch` but not send\n}\nTip: Use GoLand’s profiler and debugger to analyse the behaviour of your goroutines, eliminate leaks, and solve deadlocks.\n\n\n\n\n8. Decouple code from environment\nDon’t depend on OS or environment-specific details. Don’t use os.Getenv or os.Args deep in your package: only main should access environment variables or command-line arguments. Instead of taking choices away from users of your package, let them configure it however they want.\nSingle binaries are easier for users to install, update, and manage; don’t distribute config files. If necessary, create your config file at run time using defaults.\nUse go:embed to bundle static data, such as images or certificates, into your binary:\nimport _ \"embed\"\n\n//go:embed hello.txt\nvar s string\n\nfmt.Println(s) // `s` now has the contents of 'hello.txt'\nUse xdg instead of hard-coding paths. Don’t assume $HOME exists. Don’t assume any disk storage exists, or is writable.\nGo is popular in constrained environments, so be frugal with memory. Don’t read all your data at once; handle one chunk at a time, re-using the same buffer. This will keep your memory footprint small and reduce garbage collection cycles.\nTip: Use GoLand’s profiler to optimise your memory usage and eliminate leaks.\n\n\n\n\n9. Design for errors\nAlways check errors, and handle them if possible, retrying where appropriate. Report run-time errors to the user and exit gracefully, reserving panic for internal program errors. Don’t ignore errors using _: this leads to obscure bugs.\nShow usage hints for incorrect arguments, don’t crash. Rather than prompting users interactively, let them customise behaviour with flags or config.\nTip: GoLand will warn you about unchecked or ignored errors, and offer to generate the handling code for you.\n\n\n\n\n10. Log only actionable information\nLogorrhea is irritating, so don’t spam the user with trivia. If you log at all, log only actionable errors that someone needs to fix. Don’t use fancy loggers, just print to the console, and let users redirect that output where they need it. Never log secrets or personal data.\nUse slog to generate machine-readable JSON:\nlogger := slog.New(slog.NewJSONHandler(os.Stdout, nil))\nlogger.Error(\"oh no\", \"user\", os.Getenv(\"USER\"))\n// Output:\n// {\"time\":\"...\",\"level\":\"ERROR\",\"msg\":\"oh no\",\n// \"user\":\"bitfield\"}\nLogging is not for request-scoped troubleshooting: use tracing instead. Don’t log performance data or statistics: that’s what metrics are for.\nTip: Instead of logging, use GoLand’s debugger with non-suspending logging breakpoints to gather troubleshooting information.\n\n\n\n\nGuru meditation\nMy mountain-dwelling guru also says, “Make it work first, then make it right. Draft a quick walking skeleton, using shameless green, and try it out on real users. Solve their problems first, and only then focus on code quality.”\nSoftware takes more time to maintain than it does to write, so invest an extra 10% effort in refactoring, simplifying, and improving code while you still remember how it works. Making your programs better makes you a better programmer",
        "dc:creator": "Anna Protsenko",
        "content": "This is a guest post from John Arundel of Bitfield Consulting, a Go trainer and writer who runs a free newsletter for Go learners. His most recent book is The Deeper Love of Go. Ever wondered if there&#8217;s a software engineer, somewhere, who actually knows what they&#8217;re doing? Well, I finally found the one serene, [&#8230;]",
        "contentSnippet": "This is a guest post from John Arundel of Bitfield Consulting, a Go trainer and writer who runs a free newsletter for Go learners. His most recent book is The Deeper Love of Go. Ever wondered if there’s a software engineer, somewhere, who actually knows what they’re doing? Well, I finally found the one serene, […]",
        "guid": "https://blog.jetbrains.com/?post_type=go&p=648341",
        "categories": [
          "goland",
          "golang"
        ],
        "isoDate": "2025-10-16T11:13:18.000Z"
      },
      {
        "creator": "Elizaveta Zaytseva",
        "title": "JetBrains Is Sunsetting CodeCanvas",
        "link": "https://blog.jetbrains.com/codecanvas/2025/10/jetbrains-is-sunsetting-codecanvas/",
        "pubDate": "Thu, 16 Oct 2025 07:03:56 +0000",
        "content:encodedSnippet": "We started the development of CodeCanvas back in 2022, with the strong belief that cloud development environments (CDEs) would make development faster, smoother, and more efficient. \nWith this goal in mind, we launched CodeCanvas publicly in 2024 and started accumulating users. We dove into the issues they faced in their development workflows and how we could address them as a product.\nOver the last year, we have implemented many new features and fixes to make a product that would truly help developers. Today, we’re announcing that we have decided to discontinue the development of CodeCanvas in its current form.\nWhy we are making this decision\nThe rapid development of AI during the last several years has drastically changed the software development landscape. While CDEs make for a perfect environment to run AI agents in because of their isolated nature, we have concluded that the current CDE setup of CodeCanvas is too niche, if not obsolete, in the increasingly AI-enabled tech industry of today. \nUser and customer needs have changed and we cannot meet them with CodeCanvas the way it is right now, so we chose to drastically shift our focus and sunset CodeCanvas.\nWhat’s next\nHere’s what’s going to happen to CodeCanvas as a product:\nWe will no longer be providing new CodeCanvas licenses or subscription upgrades starting October 16, 2025.\nWe will continue providing support for our existing users until January 1, 2026. Before this deadline, our team will gladly consult our paid clients regarding migration options.\nOur existing users will be able to use CodeCanvas for six months, until March 31, 2026.\nAfter March 31, 2026, CodeCanvas public artifacts will no longer be available and your instance will stop working.\nIf you have any questions or require assistance, please reach out to us.\nClosing words\nAs a team, we have reflected on what professional developers need in the AI-enabled tech landscape of today. To meet those needs, we have decided to develop a new, more modern solution.\nWe are now creating an AI-first, cloud-native product that will help professional teams adopt AI and work with autonomous AI agents, and CDEs will play an important role in the final product design. Stay tuned for more updates!\nWe would like to extend our gratitude to every single user of CodeCanvas. Our goal in creating CodeCanvas was to make development more enjoyable for you as developers, and you gave us lots of useful information that will help us make our new product even better. Thank you for being part of our journey – we hope to see you again once our new solution is up and running!\nKindly,\nThe CodeCanvas team",
        "dc:creator": "Elizaveta Zaytseva",
        "content": "We started the development of CodeCanvas back in 2022, with the strong belief that cloud development environments (CDEs) would make development faster, smoother, and more efficient.  With this goal in mind, we launched CodeCanvas publicly in 2024 and started accumulating users. We dove into the issues they faced in their development workflows and how we [&#8230;]",
        "contentSnippet": "We started the development of CodeCanvas back in 2022, with the strong belief that cloud development environments (CDEs) would make development faster, smoother, and more efficient.  With this goal in mind, we launched CodeCanvas publicly in 2024 and started accumulating users. We dove into the issues they faced in their development workflows and how we […]",
        "guid": "https://blog.jetbrains.com/?post_type=codecanvas&p=647357",
        "categories": [
          "codecanvas"
        ],
        "isoDate": "2025-10-16T07:03:56.000Z"
      },
      {
        "creator": "Tania Goral",
        "title": "The State of PHP 2025",
        "link": "https://blog.jetbrains.com/phpstorm/2025/10/state-of-php-2025/",
        "pubDate": "Wed, 15 Oct 2025 14:00:04 +0000",
        "content:encodedSnippet": "The State of PHP 2025 examines how developers use, prefer, and rely on PHP, showing how this long-standing web language continues to modernize through new frameworks, improved tooling, and AI-assisted workflows.\nIn this report, we present findings from the Developer Ecosystem Survey 2025. Alongside the numbers, you’ll also hear commentary from Brent Roose, JetBrains Developer Advocate for PHP, and insights from other community experts explaining what’s shaping PHP today and where the ecosystem is heading.\nIf you’d like to see what the ecosystem looked like just a year ago, check out the State of PHP 2024.\nParticipants\nThis year, we collected responses from 1,720 developers who indicated PHP as their main programming language, with the largest populations living in Japan, the United States, Russia, China, and France.\n\n\n\n\n88% of PHP developers have more than three years of experience, with the largest single group falling in the six-to-ten-year range.\n\n\n\n\nTeam size and work environment\nMore than half of PHP developers (56%) work in small teams of two to seven people, while 12% work independently.\n\n\n\n\nLanguage adoption and usage\nThe majority of PHP developers (58%) do not plan to migrate to other languages in the next year. For those who do, Go and Python are the most attractive alternatives.\n\n\n\n\nThe share of newcomers is slowly growing: 4% have been using PHP for less than six months (up from 2% last year), and 6% for less than one year. Still, almost three-quarters (72%) of developers report over four years of PHP usage, underlining the ecosystem’s maturity.\n“Important to note is that these numbers aren’t talking about people leaving PHP – they are about adopting languages besides PHP. I think it’s great to see so many PHP developers who are adding other languages to their toolbelt. PHP has areas where it shines, but there are also problems that are better solved with languages like Go or Rust. Working together across those language barriers leads to great results.”\n\n            \nBrent Roose\n                                                                JetBrains Developer Advocate for PHP\n                                    \n\n\n\n    \n“It’s great to see more newcomers in PHP. It’s not surprising given the amount of positive buzz around PHP for the past couple of years, but it’s nice to see the numbers proving this trend as well.”\n\n            \nBrent Roose\n                                                                JetBrains Developer Advocate for PHP\n                                    \nThe trend toward modernization continues: PHP 8.x dominates with 89% usage, while PHP 7.x has dropped to 33%. Legacy versions (5.6 and earlier) are now down to 8%, though not entirely gone. Read Brent’s blog post for a more in-depth analysis of PHP versions’ usage.\n“I think the open-source community plays a vital role in pushing the PHP community forward to adopt more secure and performant versions. The best part is that by using tools like Rector, upgrading becomes almost trivial. I speak from experience: The yearly upgrade is so well worth it.”\n\n            \nBrent Roose\n                                                                JetBrains Developer Advocate for PHP\n                                    \n\n\n\n\nPHP frameworks and CMSs\nNo major shifts occurred in framework adoption: Laravel continues to lead with 64% usage, followed by WordPress (25%) and Symfony (23%). Other frameworks like CodeIgniter, Yii, and CakePHP hold smaller but stable shares.\n\n\n\n    \n“We’re thrilled to see Laravel adoption continuing to grow, driven by innovations like Laravel Cloud and AI integrations such as Laravel Boost and MCP. Laravel remains focused on providing a comprehensive, modern full-stack solution that makes PHP development more productive and accessible than ever.”\n\n            \nTaylor Otwell\n                                                                Creator of Laravel\n                                    \n“Symfony contributors continue to push the boundaries of what can be expressed through type annotations, creating a virtuous cycle where codebases, static analyzers, and IDEs continuously improve to enhance developer experience and verifiability. Informal communication channels between all stakeholders make this progress even smoother and more efficient.”\n\n            \nNicolas Grekas\n                                                                Core Developer at Symfony\n                                    \nPHP development environments\nMost used IDE or editor\nOne of the most striking changes is in tooling: The share of those using either PhpStorm or IntelliJ IDEA with the PHP plugin has gone up by 10 percentage points, to 68%. Visual Studio Code’s share has dropped to 23%, while new players like Cursor (6%) have also entered the scene.\n\n\n\n\nSatisfaction with coding tools\nWe also asked PHP developers how satisfied they are with their primary IDE. Among them, 53% of PhpStorm users gave their IDE the highest possible rating, compared to just 26% of VS Code users.\n\n\n\n\nIDE or editor of choice per framework\nPhpStorm dominates in Symfony (83%) and leads in Laravel (62%), while WordPress developers remain more split, with VS Code remaining a popular choice (37%).\n\n\n\n\nDid you know Laravel support is now free for all PhpStorm users? This blog post has the full story.\nDebugging and testing\nWhen it comes to debugging, most developers still rely on var_dump-style approaches (59%), though debugger adoption (e.g. Xdebug) has risen slightly to 39%.\n\n\n\n    \n“Xdebug’s usage seems to be pretty stable throughout the years and across several surveys: between 30% and 35%. While I definitely still do my fair share of “dd” or “log” debugging, there are times where having a debugger at hand and knowing how to use it saves so much time. It’s a skill that takes practicing and doesn’t come overnight – which is why I made this short video to help folks get started with Xdebug.”\n\n            \nBrent Roose\n                                                                JetBrains Developer Advocate for PHP\n                                    \nPHPUnit (50%) remains the standard, but Pest adoption has gained four percentage points to reach 17%, showing momentum toward modern, developer-friendly testing frameworks.\n“I’m super-happy to see more and more people choosing Pest as their go-to testing framework – the growth in this year’s survey really reflects the quality of our recent releases.\n\r\n\r\nSince the survey, we’ve actually released Pest 4, which introduces test sharding, profanity checking, and the revolutionary browser testing. Having proper browser testing in the PHP world is truly a game-changer, so I expect adoption to increase even more next year!”\n\n            \nNuno Maduro\n                                                                Creator of Pest\n                                    \n\n\n\n\nHowever, 32% of developers still don’t write tests at all, which highlights a persistent gap in testing culture.\nCode quality tools\nThe clear winner in 2025 is PHPStan, which jumped to 36% usage, up nine percentage points from last year. Tools like PHP CS Fixer (30%) and PHP_CodeSniffer (22%) remain widely used, while Rector (10%) continues its steady rise. Still, 42% of respondents don’t use any code quality tools regularly, leaving room for further improvement.\n\n\n\n\n\n\n💡Have you tried JetBrains Qodana? This static analysis and codebase auditing tool brings inspections from PhpStorm into your CI/CD pipeline, along with unique and custom code-quality and security checks. Use it to clean up and secure your team’s code before merging to the main branch.\n\n\n\n\n\nAdoption of AI\nAI has gone mainstream: 95% of developers have tried at least one AI tool, and 80% regularly use AI assistants or AI-powered editors.\n\n\n\n\nChatGPT leads daily use with 49%, though its share has dropped since 2024. GitHub Copilot (29%) and JetBrains AI Assistant (20%) follow, with the latter tripling its adoption since last year.\n\n\n\n    \n“AI is here to stay. It’s great to see the increased adoption of AI overall, and the drop in ChatGPT usage in favor of more specialized tooling. We can expect more of this moving forward, with new tools entering the scene, and the ones giving us the best boost earning their place in our daily stack.”\n\n            \nAshley Hindle\n                                                                AI Engineer at Laravel\n                                    \nLooking ahead, 72% of respondents are likely to try AI coding agents in the next year, while only 8% say it’s unlikely.\n\n\n\n\nTo support developers in this shift, earlier this year JetBrains introduced an AI coding agent called Junie. Unlike other coding assistants, Junie is built to work directly with your JetBrains IDE, project context, and team practices, delivering actionable and trustworthy support. With AI agents rapidly becoming part of everyday workflows, Junie brings the reliability, integration, and developer focus you expect from JetBrains to this new wave of tools.\n\n\n\n\n\n\nAt the same time, not every company is ready to embrace AI yet. 11% respondents report that their organization is unlikely to try AI coding agents in the next 12 months. Apart from the data privacy and security concerns (44%) and intellectual property questions (24%), many companies also struggle with a lack of knowledge about such tools (22%).\nEcosystem highlights 2025\nFrankenPHP\n“One of my personal highlights in PHP this year is FrankenPHP becoming a  project backed by the PHP Foundation. I think there’s a lot of potential for the project to become the de-facto standard runtime for PHP, which would be huge. FrankenPHP has a lot of performance optimizations that work out of the box for any PHP application, it’s portable across systems, and it has worker mode, which allows for asynchronous request handling in PHP, which can speed up applications by a factor of three compared to using PHP FPM.”\n\n            \nBrent Roose\n                                                                JetBrains Developer Advocate for PHP\n                                    \nLearn more about FrankenPHP from Kévin Dunglas on PHPverse 2025:\n\n\n\n\n\n\nPHPverse\nThis year also marked a special milestone – PHP turned 30 years old. We celebrated with JetBrains PHPverse, an online birthday event that drew more than 26,000 viewers worldwide. If you missed it, don’t worry – the recordings are available to watch on demand:\n\n\n\n\n\n\nCatch the next edition of PHPverse – sign up here to be the first to know when registration opens.\nGet event updates\n                                                    \nWhat this means for PHP\nThe 2025 results confirm that PHP remains a stable, professional, and evolving ecosystem. Its strong developer base, continued dominance of Laravel and WordPress, increasing adoption of modern tooling, and rapid embrace of AI-powered workflows show that PHP is far from being “legacy”.\nDisclaimer: Despite all the measures we’ve taken to secure a representative pool of respondents, these results might be slightly skewed toward users of JetBrains products, as they might have been more likely to take the survey. Read more about our methodology.",
        "dc:creator": "Tania Goral",
        "content": "The State of PHP 2025 examines how developers use, prefer, and rely on PHP, showing how this long-standing web language continues to modernize through new frameworks, improved tooling, and AI-assisted workflows. In this report, we present findings from the Developer Ecosystem Survey 2025. Alongside the numbers, you’ll also hear commentary from Brent Roose, JetBrains Developer [&#8230;]",
        "contentSnippet": "The State of PHP 2025 examines how developers use, prefer, and rely on PHP, showing how this long-standing web language continues to modernize through new frameworks, improved tooling, and AI-assisted workflows. In this report, we present findings from the Developer Ecosystem Survey 2025. Alongside the numbers, you’ll also hear commentary from Brent Roose, JetBrains Developer […]",
        "guid": "https://blog.jetbrains.com/?post_type=phpstorm&p=646639",
        "categories": [
          "news",
          "ai",
          "php"
        ],
        "isoDate": "2025-10-15T14:00:04.000Z"
      },
      {
        "creator": "Olga Bedrina",
        "title": "The State of Developer Ecosystem 2025: Coding in the Age of AI, New Productivity Metrics, and Changing Realities",
        "link": "https://blog.jetbrains.com/research/2025/10/state-of-developer-ecosystem-2025/",
        "pubDate": "Wed, 15 Oct 2025 13:01:04 +0000",
        "content:encodedSnippet": "Every year, the JetBrains Developer Ecosystem Survey takes a deep dive into the world of software development, looking at how developers work, what tools they use, and how the industry is changing. \nThe survey has been running since 2017 and has since grown into one of the most comprehensive studies of its kind.\nThe 2025 edition is based on responses from 24,534 developers across 194 countries, offering a truly global overview of the profession.\nLet’s explore what stood out the most in 2025.\nAI proficiency is becoming a core skill\nAI is becoming a standard in developers’ lives: 85% of developers regularly use AI tools for coding and development, and 62% rely on at least one AI coding assistant, agent, or code editor.\nStill, 15% of developers have not yet adopted AI tools in their daily work. Whether their hesitancy is due to skepticism, security concerns, or mere personal preference, this significant minority represents an interesting opposition to the mainstream trend.\nAI at the workplace\nFor the majority who have embraced AI, the benefits are tangible. Nearly nine out of ten developers save at least an hour every week, and one in five saves eight hours or more. That’s the equivalent of an entire workday!\n\n\n\n\nThere’s no wonder 68% expect employers to require proficiency in AI tools in the near future. AI work has already become as common as data processing (25% vs. 29%).\nLooking to the future\nWhen asked about the increasing role of AI in society, developers express a mix of optimism, curiosity, and anxiety.\n\n\n\n\nMost developers are happy to let AI handle repetitive tasks, such as generating boilerplate code, writing documentation, or summarizing changes, but they prefer to stay in charge of creative and complex tasks, like debugging or designing application logic.\nHere are the top five development activities that respondents are most likely to delegate to AI:\nWriting boilerplate, repetitive code\nSearching for development-related information on the internet\nConverting code to other languages\nWriting code comments or code documentation\nSummarizing recent code changes\nBiggest concerns around AI in coding and software development\nDespite the enthusiasm surrounding AI, many people still have reservations. Here are the top five concerns our respondents reported having about AI in software development:\nThe inconsistent quality of AI-generated code\nAI tools’ limited understanding of complex code and logic\nPrivacy and security risks\nThe potential negative impact on their own coding and development skills\nAI’s lack of context awareness\nLanguages and tools\nThe programming languages that developers choose reveal the state of the industry and which technologies are gaining traction now.\nTypeScript has seen the most dramatic rise in real-world usage over the past five years. Rust, Go, and Kotlin have also continued to steadily amass market share – although their gains have not been quite as impressive as TypeScript’s.\n\n\n\n\nMeanwhile, PHP, Ruby, and Objective-C continue to decline steadily, reflecting how developer preferences and project demands have shifted over time.\nThe JetBrains Language Promise Index ranks languages based on growth, stability, and developers’ willingness to adopt them. According to the index, in 2025, TypeScript, Rust, and Go boast the highest perceived growth potential, while JavaScript, PHP, and SQL appear to have reached their maturity plateau.\nThe top five languages that developers want to adopt next are:\nGo (11%)\nRust (10%)\nPython (7%)\nKotlin (6%)\nTypeScript (6%)\n\n\n\n\nSurprisingly, Scala leads among the top-paid developers with 38%, despite being used by only 2% of all developers as a primary language. Sometimes, it seems, niche expertise quite literally pays off. You can explore this phenomenon in more detail with our IT Salary Calculator.\nIn the world of cloud services, regional providers maintain a strong presence in their home countries, showing that developers often choose cloud providers based on where they work or what’s most available in their region.\n\n\n\n\nDeveloper productivity: Rethinking what it means to be productive\nLast year, companies focused almost exclusively on measuring technical performance – build time, velocity, and mean time to recovery.\nIn 2025, we have seen a major rebalancing. It’s no longer about DORA metrics – it’s developer productivity that now matters most.\nDevelopers themselves highlight both technical (51%) and non-technical (62%) factors as critical to their performance. Internal collaboration, communication, and clarity are now just as important as faster CI pipelines or better IDEs.\nWhile tech decision-makers dream of reducing technical debt and improving collaboration, developers want transparency, constructive feedback, and clarity of goals. Yet, 66% of developers don’t believe current metrics reflect their true contributions.\n\n\n\n\nThe data suggests it’s time to rethink how we measure success and to build work environments that reward not just results, but the way they’re achieved.\nFor more on how teams are reimagining productivity and developer experience, explore The State of Developer Experience and Productivity 2025 by JetBrains.\nDeveloper reality\nEvery developer’s work tells its own story, and the data highlights just how diverse those stories can be.\nGlobally, developers experience the job market in strikingly different ways: 57% describe it as “favorable” in Japan, while 66% find it “challenging” in Canada. The industry may be global, but opportunity still depends on where you are.\n61% of junior developers find the job market challenging, while 54% of senior developers share this concern.\nAs developers progress in their careers, they face entirely different types of challenges. The data shows a clear transformation from technical focus to coordination responsibilities, such as context switching, as experience increases. \nDespite all the challenges, developers love what they do: 52% of developers code for fun even after coding all day. 57% prefer to do it while listening to music, while 25% enjoy the quiet. \nAnd in one of the most delightful constants of this survey: Developers love cats just as much as dogs! 🐱 🐶\nMethodology\nThe survey ran from April to June 2025 and included 24,534 developers after data cleaning. We balanced our responses by geography, employment, programming languages, and JetBrains product use.\nWrapping up\nThe Developer Ecosystem Survey 2025 results reveal a field that’s changing fast, shaped by AI and growing self-awareness among developers. They’re using tools that make them more productive, while questioning how they define productivity in the changing landscape.\nExplore the full data and uncover your own insights using the Developer Ecosystem Data Playground. Check out the infographic for more insights about the current developer ecosystem.\nSee the infographic\n                                                    \nJoin the conversation\nWhat surprised or excited you most about the findings? Share your thoughts on X or other social media platforms, mentioning @jetbrains and using the hashtag #DevEcosystem25. Your feedback helps us make our reports even more informative and useful.\nBe part of the 2026 report\nWant to contribute to next year’s Developer Ecosystem Survey? Join our JetBrains Tech Insights Lab! As a participant, you’ll engage in surveys, interviews, and UX studies that not only improve JetBrains products but also provide invaluable insights for the developer community. Plus, you can enter various prize draws and earn valuable rewards.\nLet’s navigate the ever-changing tech landscape together. See you in the 2026 edition!",
        "dc:creator": "Olga Bedrina",
        "content": "Every year, the JetBrains Developer Ecosystem Survey takes a deep dive into the world of software development, looking at how developers work, what tools they use, and how the industry is changing.&#160; The survey has been running since 2017 and has since grown into one of the most comprehensive studies of its kind. The 2025 [&#8230;]",
        "contentSnippet": "Every year, the JetBrains Developer Ecosystem Survey takes a deep dive into the world of software development, looking at how developers work, what tools they use, and how the industry is changing.  The survey has been running since 2017 and has since grown into one of the most comprehensive studies of its kind. The 2025 […]",
        "guid": "https://blog.jetbrains.com/?post_type=research&p=648046",
        "categories": [
          "deveco",
          "news",
          "research",
          "jetbrains-deveco",
          "jetbrains-research",
          "market-research"
        ],
        "isoDate": "2025-10-15T13:01:04.000Z"
      },
      {
        "creator": "Olga Bedrina",
        "title": "[Livestream] Maximizing TeamCity: New Features in Action and a Look Ahead",
        "link": "https://blog.jetbrains.com/teamcity/2025/10/livestream-maximizing-teamcity-oct22-2025/",
        "pubDate": "Wed, 15 Oct 2025 11:01:50 +0000",
        "content:encodedSnippet": "Join us on October 22, 2025, for an essential TeamCity update livestream. \nIn a live session, TeamCity Solutions Engineers, Ricardo Leite and Daniel Gallo, will walk you through the powerful features introduced in the most recent release and give you an exclusive look at what’s next on our roadmap.\n\n\n\n\nWhether you’re looking to optimize your existing TeamCity setup or considering an upgrade, this webinar will give you the insights and practical knowledge you need to maximize your use of TeamCity.\nSave the date\n📆 October 22, 2025\n⏰ 4:00–5:00 pm (UTC)\nSign up for the livestream\n                                                    \nWhat you can expect from the session:\nHands-on demonstrations of the latest TeamCity features with real-world scenarios showing exactly when and how to use them.\nConfiguration walkthroughs to help you implement these features in your own pipelines.\nA roadmap preview so you can see what’s on the horizon.\nAn update on changes to our licensing model, including the removal of renewal discounts for new license purchases, and why acting now can help you save.\nSpeakers\nRicardo Leite\nRicardo is a Solutions Engineer on the TeamCity team at JetBrains. Throughout his career, he has helped numerous organizations integrate modern technologies to streamline CI/CD workflows and achieve faster and more reliable DevSecOps processes. Passionate about innovation, Ricardo thrives on solving complex technical challenges and coaching companies to adopt best practices that drive efficiency, security, and scalability.\nDaniel Gallo\nDaniel is a Solutions Engineer on the TeamCity team at JetBrains. With over 20 years of experience in the software development industry, he has held diverse roles, including Software Developer, Senior Systems Analyst, and Solutions Engineer. In his current role, Daniel works with customers worldwide, helping them understand TeamCity and optimize their CI/CD build pipelines.",
        "dc:creator": "Olga Bedrina",
        "content": "Join us on October 22, 2025, for an essential TeamCity update livestream.&#160; In a live session, TeamCity Solutions Engineers, Ricardo Leite and Daniel Gallo, will walk you through the powerful features introduced in the most recent release and give you an exclusive look at what’s next on our roadmap. Whether you’re looking to optimize your [&#8230;]",
        "contentSnippet": "Join us on October 22, 2025, for an essential TeamCity update livestream.  In a live session, TeamCity Solutions Engineers, Ricardo Leite and Daniel Gallo, will walk you through the powerful features introduced in the most recent release and give you an exclusive look at what’s next on our roadmap. Whether you’re looking to optimize your […]",
        "guid": "https://blog.jetbrains.com/?post_type=teamcity&p=648640",
        "categories": [
          "livestream",
          "demo",
          "live-stream",
          "teamcity",
          "webinar"
        ],
        "isoDate": "2025-10-15T11:01:50.000Z"
      },
      {
        "creator": "Vaclav Pech",
        "title": "New Bug-Fix Releases Are Available for MPS – 2025.2.1, 2025.1.1, 2024.3.4, and 2024.1.5",
        "link": "https://blog.jetbrains.com/mps/2025/10/new_bugfix_releases_mps-2025-2/",
        "pubDate": "Tue, 14 Oct 2025 15:21:16 +0000",
        "content:encodedSnippet": "We’ve released updates for multiple major MPS versions that fix several additional issues.\nThe two most notable improvements that these releases bring are:\nMPS-38681 – Invisible references can now be excluded from usage highlighting.\nMPS-36481 – The <generate> task in Ant now recognizes two additional project properties to configure the location of the log files:\n\nmps.log.config.file points to the JUL properties file, in which the location for the log files (both absolute and relative) can be specified.\nmps.log.dir specifies the directory for log files.\nDOWNLOAD MPS 2025.2.1\nCheck out all the updates in each particular version below:\nMPS 2025.2.1\nDownload MPS 2025.2.1 here.\nhere.\nMPS 2025.1.1\nDownload MPS 2025.1.1 here.\nhere.\nMPS 2024.3.4\nDownload MPS 2024.3.4 here.\nhere.\nMPS 2024.1.5\nThis release fixes a version-specific issue that caused occasional freezes after invalidating caches (MPS-37659).\nDownload MPS 2024.1.5 here.\nhere.\nYour JetBrains MPS team",
        "dc:creator": "Vaclav Pech",
        "content": "We’ve released updates for multiple major MPS versions that fix several additional issues. The two most notable improvements that these releases bring are: MPS-38681 – Invisible references can now be excluded from usage highlighting. MPS-36481 – The &#60;generate&#62; task in Ant now recognizes two additional project properties to configure the location of the log files: [&#8230;]",
        "contentSnippet": "We’ve released updates for multiple major MPS versions that fix several additional issues. The two most notable improvements that these releases bring are: MPS-38681 – Invisible references can now be excluded from usage highlighting. MPS-36481 – The <generate> task in Ant now recognizes two additional project properties to configure the location of the log files: […]",
        "guid": "https://blog.jetbrains.com/?post_type=mps&p=646577",
        "categories": [
          "releases",
          "release"
        ],
        "isoDate": "2025-10-14T15:21:16.000Z"
      },
      {
        "creator": "Alexander Kurakin",
        "title": "ReSharper Is Now on the Open VSX Registry",
        "link": "https://blog.jetbrains.com/dotnet/2025/10/14/resharper-open-vsx/",
        "pubDate": "Tue, 14 Oct 2025 14:26:54 +0000",
        "content:encodedSnippet": "ReSharper for Visual Studio Code has been available on the Microsoft Visual Studio Marketplace for some time now.\n\n\n\n\nHowever, ReSharper didn’t appear in many VS Code-compatible editors because these editors aren’t able to connect directly to the Visual Studio Code Marketplace. For this reason, users of such editors who wanted to install ReSharper had to download a platform-specific .vsix file and perform manual updates every time a new version was released. To make matters worse, a lack of update notifications meant that these users were often using outdated versions of the extension. This process was neither straightforward nor convenient. \nReSharper on the Open VSX Registry\nTo better serve our Cursor, Windsurf, and VSCodium users, we decided to publish our extension on the Open VSX Registry, which has become the default marketplace for VS Code-compatible editors.\nOn October 14, we published ReSharper to the Open VSX Registry. You can now easily install ReSharper in your VS Code-compatible code editor by simply typing ReSharper into the search field in the Extensions view. \n\n\n\n\nCursor users might have noticed that ReSharper was already searchable in the Extensions view before it was published to the Open VSX Registry. This is thanks to the Cursor team’s custom implementation, which enabled ReSharper to reach Cursor users ahead of the official release on Open VSX.\nIf your code editor does not use the Open VSX Registry as its default marketplace, you can manually download the extension from this web page.\n\n\n\n\nWe hope this will make accessing ReSharper code analysis in your code editor more convenient and improve your C# development experience.\nNew extension architecture\nWe intended to deliver ReSharper to the Open VSX Registry earlier, but we encountered a technical limitation – the registry requires that a published binary of an extension cannot exceed 256 MB in size. Unfortunately, the .vsix file for Windows ARM64 was 275 MB. While other platform-specific binaries were slightly below the limit, we anticipate that they will soon exceed the size restriction.\nTo address this issue, we decided to redesign the extension’s architecture and create a light core extension that will download larger components, such as the ReSharper language server and .NET runtime, directly from the JetBrains download server on first launch.\nUnfortunately, there are a couple of downsides to this architectural change: \nThe initial startup of the newly updated extension will take longer than before, as larger components will need to be downloaded and unzipped. However, this impact is minimal, and subsequent startups will not experience any delays.\n\n\n\n\n\nYou will need an active internet connection and unrestricted access to the https://download.jetbrains.com server when opening the first .NET solution with the updated ReSharper extension. Once the download is complete, the extension will remain fully functional even without an internet connection. If you do not meet these requirements, the ReSharper extension will notify you and provide a link to download a platform-specific .vsix file that contains all the necessary components for offline installation.\n\n\n\n\nIf you have any comments or questions regarding this architectural change, please reach out to us via our public issue tracker or the comments section of this blog post.",
        "dc:creator": "Alexander Kurakin",
        "content": "ReSharper for Visual Studio Code has been available on the Microsoft Visual Studio Marketplace for some time now. However, ReSharper didn’t appear in many VS Code-compatible editors because these editors aren’t able to connect directly to the Visual Studio Code Marketplace. For this reason, users of such editors who wanted to install ReSharper had to [&#8230;]",
        "contentSnippet": "ReSharper for Visual Studio Code has been available on the Microsoft Visual Studio Marketplace for some time now. However, ReSharper didn’t appear in many VS Code-compatible editors because these editors aren’t able to connect directly to the Visual Studio Code Marketplace. For this reason, users of such editors who wanted to install ReSharper had to […]",
        "guid": "https://blog.jetbrains.com/?post_type=dotnet&p=647882",
        "categories": [
          "net-tools",
          "cursor",
          "open-vsx",
          "resharper",
          "resharper-for-vs-code",
          "vs-code",
          "vsix"
        ],
        "isoDate": "2025-10-14T14:26:54.000Z"
      }
    ]
  },
  {
    "name": "Visual Studio Blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Joshua",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권재명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김석기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권진호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강대명",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권정혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "줌구",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수보",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김시은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "곽민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민서",
    "category": "개인",
    "posts": []
  },
  {
    "name": "I am not Okay",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권창현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권기호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강태욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권용진",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김승호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for boyism Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성준의 린스타트업과 디자인씽킹",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강동혁",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고종범",
    "category": "개인",
    "posts": []
  },
  {
    "name": "cheese10yun",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구자철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "FSS",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권동준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김용일",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도균",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김동우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권윤학",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김민준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김만수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "엘키",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김슬기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김광현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김영우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강명훈",
    "category": "개인",
    "posts": [
      {
        "title": "데이터 노가다 실수담 - 14th",
        "link": "https://kangmyounghun.blogspot.com/2025/10/14th.html",
        "pubDate": "2025-10-19T03:17:00.006Z",
        "author": "강명훈",
        "content": "<div>URL 인코딩 패턴 디코딩.</div><div><br /></div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi5srl4SIKUt8zs4gHhn3a3desDHk1IajQ3CUdgClDFE0mIx5yc-4VhaSEd2f_eFVN7EINvCn45yBBg6EY1j45qiGiwIKOokUiCpQVG8uscSGa2Ccqcl77qlUxHnGHT7JhrGMRQmVjtGFf2t01fXf4G3eOJnx3x0QSr3afneJdzyQkLnb1Kdow5_ZtFUl3A/s1280/urldecode.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"695\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi5srl4SIKUt8zs4gHhn3a3desDHk1IajQ3CUdgClDFE0mIx5yc-4VhaSEd2f_eFVN7EINvCn45yBBg6EY1j45qiGiwIKOokUiCpQVG8uscSGa2Ccqcl77qlUxHnGHT7JhrGMRQmVjtGFf2t01fXf4G3eOJnx3x0QSr3afneJdzyQkLnb1Kdow5_ZtFUl3A/s16000/urldecode.png\" /></a></div><br /><div><span><a name='more'></a></span>그런데 &gt;를 의미하는 %3E 패턴을 추가해서 script 태그를 완성하면 데이터가 사라짐.</div></div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhHjJYTv_-s04n5ZhRdWsIMspKR8Ce46BDlhI1BBCKOoZQOL2OUqxmcnC0L0GekU1HHFlqWwEcB9ifGM7ByRulcHBEYpdV3VVRZ7vgMa_ybJ1hsrznLwEHwtQVnsLgRQZ4t5oybz2pEn0SB_s6zARAKwpFcOiSW3_tlEVHsnDPw49PvfKl224EPI7BSqUUp/s1280/urldecode2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"696\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhHjJYTv_-s04n5ZhRdWsIMspKR8Ce46BDlhI1BBCKOoZQOL2OUqxmcnC0L0GekU1HHFlqWwEcB9ifGM7ByRulcHBEYpdV3VVRZ7vgMa_ybJ1hsrznLwEHwtQVnsLgRQZ4t5oybz2pEn0SB_s6zARAKwpFcOiSW3_tlEVHsnDPw49PvfKl224EPI7BSqUUp/s16000/urldecode2.png\" /></a></div><div><br /></div><div>혹시나 싶어 태그를 닫기 전에 \\를 추가해봤다.<br /></div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiPaI3bKaaffSNP-k8E1xNAURVXMvT3_uJrsh4WMSoiEBw97Cmt31nx2Onv1TF5BUADiRewu8_CJgiZ8MYYSOYbZ1ead08kWPenCPHEjgSgVjjdbJcLoXhjpcoIUGsUkKIhLpO0llLr41wg3LD70Mt3mcKi4TzEMvITKHHmyD3uX-YwjLy1xNHq4_HlZpZs/s1280/urldecode3.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"695\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiPaI3bKaaffSNP-k8E1xNAURVXMvT3_uJrsh4WMSoiEBw97Cmt31nx2Onv1TF5BUADiRewu8_CJgiZ8MYYSOYbZ1ead08kWPenCPHEjgSgVjjdbJcLoXhjpcoIUGsUkKIhLpO0llLr41wg3LD70Mt3mcKi4TzEMvITKHHmyD3uX-YwjLy1xNHq4_HlZpZs/s16000/urldecode3.png\" /></a></div><div><br /></div><div>잘 됨. 공백을 추가해도 마찬가지. %3E 패턴 전에 아무 문자나 하나 추가해주면 데이터가 유지된다.</div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgR8gK_IiFSCIPSiEtE3USaJTgY7NXIVkcFMkrYOusbf-Tt19Boqa48-T8nE1Vm7a-y-7uWq1BLZeOvBaindn2cg01k7RnPs3Szhg8fBKogjkZUJHE-xgqTS_uhqCo1tfM2JNy2e9YYFSAPq6BqvehFopDGtajnZOUr9YBWCwMJ2pB52qsgLRIsh3x7u5pb/s1280/urldecode4.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"696\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgR8gK_IiFSCIPSiEtE3USaJTgY7NXIVkcFMkrYOusbf-Tt19Boqa48-T8nE1Vm7a-y-7uWq1BLZeOvBaindn2cg01k7RnPs3Szhg8fBKogjkZUJHE-xgqTS_uhqCo1tfM2JNy2e9YYFSAPq6BqvehFopDGtajnZOUr9YBWCwMJ2pB52qsgLRIsh3x7u5pb/s16000/urldecode4.png\" /></a></div><div><br /></div><div>script 태그 방지 코드라도 적용돼 있는 거여 뭐여<span style=\"font-size: x-small;\">(..)</span></div><div><br /></div><div><div><b>관련 글</b></div><div><ul><li><a href=\"https://kangmyounghun.blogspot.com/2025/10/13th.html\">데이터 노가다 실수담 - 13th</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2019/01/blog-post_90.html\" target=\"\">데이터 노가다 실수담</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2023/06/blog-post.html\">평균의 함정</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2020/09/blog-post_27.html\" target=\"\">데이터 분석이 쉬워지는 비법</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2021/12/blog-post.html\" target=\"\">데이터 분석에 필요한 자질은 뭘까?</a></li></ul></div></div>",
        "contentSnippet": "URL 인코딩 패턴 디코딩.\n\n\n\n\n그런데 >를 의미하는 %3E 패턴을 추가해서 script 태그를 완성하면 데이터가 사라짐.\n\n\n\n\n\n혹시나 싶어 태그를 닫기 전에 \\를 추가해봤다.\n\n\n\n\n잘 됨. 공백을 추가해도 마찬가지. %3E 패턴 전에 아무 문자나 하나 추가해주면 데이터가 유지된다.\n\n\n\n\nscript 태그 방지 코드라도 적용돼 있는 거여 뭐여(..)\n\n\n관련 글\n\n데이터 노가다 실수담 - 13th\n데이터 노가다 실수담\n평균의 함정\n데이터 분석이 쉬워지는 비법\n데이터 분석에 필요한 자질은 뭘까?",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-6814952814111554238",
        "isoDate": "2025-10-19T03:17:00.006Z"
      },
      {
        "title": "데이터 노가다 실수담 - 13th",
        "link": "https://kangmyounghun.blogspot.com/2025/10/13th.html",
        "pubDate": "2025-10-17T08:04:00.008Z",
        "author": "강명훈",
        "content": "<div>3만 개에 육박하는 변수 발생 내역. 같은 변수라도 달라지는 값 때문에 복잡도가 증가한 결과.&nbsp;&nbsp;</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg-9opyhamXU3vh4r-YqJfv68b4epaAruddgiPS1qxVWiAmJyL4K_YqsUBOd6CNO5FPOJ-FmgGYfdIoEN8B09Ng0pn0l67tMEaxFAKxVukYgJDrnp2wUv2Z__F7OIdAYFinyjrtrjGAqOppZU5-NOMl6equ0psYP31nqdu6YMhP8oCMXKRSRbasl34JudLk/s1134/dimensiton.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1134\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg-9opyhamXU3vh4r-YqJfv68b4epaAruddgiPS1qxVWiAmJyL4K_YqsUBOd6CNO5FPOJ-FmgGYfdIoEN8B09Ng0pn0l67tMEaxFAKxVukYgJDrnp2wUv2Z__F7OIdAYFinyjrtrjGAqOppZU5-NOMl6equ0psYP31nqdu6YMhP8oCMXKRSRbasl34JudLk/s16000/dimensiton.png\" /></a></div><div><br /></div><div><span><a name='more'></a></span>변수값으로 사용된 숫자만 삭제해도 복잡도를 줄여 데이터 발생 범위를 좁힐 수 있다. 내가 알고 싶은 건 전체적인 변수 변화지, 세부적인 변수값 변화가 아니기 때문. 분석 목적에 영향을 주지 않는 요소를 제거하는 차원 축소 결과.&nbsp;</div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhMcGc9M505UtSj1FlRCbHAJIBGIU-1FR_MKPY6glfSVzzXckdkihwKPWF5vM7ck5D3LkJT1UnLaBr8FLbfxBu7z2tUwPzGIhU4r61yUsrOGledBoSjf7D2UQsNqsLVgmc6C14AqO8ePsFERZqi2Xgz_dt3yQiDm4F2fBNVRxaWJ9q5bnwhecLNBNEEh7xl/s1134/dimensiton2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1134\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhMcGc9M505UtSj1FlRCbHAJIBGIU-1FR_MKPY6glfSVzzXckdkihwKPWF5vM7ck5D3LkJT1UnLaBr8FLbfxBu7z2tUwPzGIhU4r61yUsrOGledBoSjf7D2UQsNqsLVgmc6C14AqO8ePsFERZqi2Xgz_dt3yQiDm4F2fBNVRxaWJ9q5bnwhecLNBNEEh7xl/s16000/dimensiton2.png\" /></a></div><br /><div>그런데 URL 인코딩 패턴 때문에 가독성이 떨어진다. 디코딩 시도.</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgF9fHuaEXaiUTFTUshSIVUaIT5Sw2YosR-lh70FKwURaBIK1mTWgSKX9gOhUZ9-wP-n64j1NROr9T1MfKlZqKnJMatnZuoNq9MDfYEo2lyf2Vxtq3ziFxbwMfyIRY6KFWTIhTjobeXrbL18bg6mwIKNq2_c_ei_uWNPPpYcUFzHQmsgtzj2zhaTd2gq4TP/s1114/dimensiton3.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"606\" data-original-width=\"1114\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgF9fHuaEXaiUTFTUshSIVUaIT5Sw2YosR-lh70FKwURaBIK1mTWgSKX9gOhUZ9-wP-n64j1NROr9T1MfKlZqKnJMatnZuoNq9MDfYEo2lyf2Vxtq3ziFxbwMfyIRY6KFWTIhTjobeXrbL18bg6mwIKNq2_c_ei_uWNPPpYcUFzHQmsgtzj2zhaTd2gq4TP/s16000/dimensiton3.png\" /></a></div><div><br /></div><div><b><span style=\"font-size: x-large;\">왜 디코딩이 안 되지?</span></b></div><div><br /></div><div>%2F는 /를 의미하는 16진수 2F를 URL 인코딩한 결과. 그런데 변수 내역을 보니 숫자가 없다. 삭제 과정에서 URL 인코딩 패턴의 숫자까지 삭제했구나<span style=\"font-size: x-small;\">(..)</span> 변수값으로 사용된 순수 숫자만을 삭제해야 한다.</div><div><br /></div>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjdC9tzYpgWvavOyQjBs03chQ2Ifk3cZ36KyOwb3K1RKXYglaSf_3EbGit2m3H2sDNG1I_b6uv_H4PbTU9igoJp6z1vkosnM-YaNFdxEc5hGitRKlIm_1-0qwyGpZv1lfYRDXu6dDvFqqbhddX9sT73QQ-4IIwS3DgEIJXhuDziyAqFLMMn2G6dsYoJE5bk/s1114/dimensiton4.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"671\" data-original-width=\"1114\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjdC9tzYpgWvavOyQjBs03chQ2Ifk3cZ36KyOwb3K1RKXYglaSf_3EbGit2m3H2sDNG1I_b6uv_H4PbTU9igoJp6z1vkosnM-YaNFdxEc5hGitRKlIm_1-0qwyGpZv1lfYRDXu6dDvFqqbhddX9sT73QQ-4IIwS3DgEIJXhuDziyAqFLMMn2G6dsYoJE5bk/s16000/dimensiton4.png\" /></a></div>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgd37uGIBtUtFFhoc8qdK8j7D7yopqwomNzw7VqDr6Uc_nGFtFgpLOQty9V6_H4DqdQoLWEoPznvxJbLxH9RQFrXA93BXOsfu4PBGgSOC3WOrzb54R8gULAHoTKjWucjL6tCGiG1giuFWHHEOutXtcbb4-YcIVG7Vxjj38iWqUTpt4qEeOdsISpFMaTVw16/s1262/regex.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"713\" data-original-width=\"1262\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgd37uGIBtUtFFhoc8qdK8j7D7yopqwomNzw7VqDr6Uc_nGFtFgpLOQty9V6_H4DqdQoLWEoPznvxJbLxH9RQFrXA93BXOsfu4PBGgSOC3WOrzb54R8gULAHoTKjWucjL6tCGiG1giuFWHHEOutXtcbb4-YcIVG7Vxjj38iWqUTpt4qEeOdsISpFMaTVw16/s16000/regex.png\" /></a></div>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEizD3X9aUu2rGlZWinTzxAjlJChSMJfBGT4KGo4LqJhvZjHimHtpbdiB46vHIeZHsdviSvv5-9GQIXDOvJg8G62_PHXD_BBRmUoeiNmc9_dd3d5r2ZAojMx7jKtEUjttuY8bfrEhqAfLNIAMa2qdF5dF1c2Vs6LpCZQipLEzdHVHECvT7uwkrgKSO1Uuojt/s1262/regex2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"713\" data-original-width=\"1262\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEizD3X9aUu2rGlZWinTzxAjlJChSMJfBGT4KGo4LqJhvZjHimHtpbdiB46vHIeZHsdviSvv5-9GQIXDOvJg8G62_PHXD_BBRmUoeiNmc9_dd3d5r2ZAojMx7jKtEUjttuY8bfrEhqAfLNIAMa2qdF5dF1c2Vs6LpCZQipLEzdHVHECvT7uwkrgKSO1Uuojt/s16000/regex2.png\" /></a></div>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhiTLq6_VV2bjpmixUkGtToVOm_UDFmGHUYf-Hm9U4UbjaT1YdnJv8NStI4Qw03ONWAHfkUfvpYQck_8ETmEw8L2f4feFHpjwl3Jo-r5Q4v3ApZjFn0GKWJJ7Gn1833udwyC7mOaDM6bBHzf1xMC3jlODaLUn90Ms4qOhsmKJulTfYWtFKyhuluL8fjHgqg/s1262/regex3.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"713\" data-original-width=\"1262\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhiTLq6_VV2bjpmixUkGtToVOm_UDFmGHUYf-Hm9U4UbjaT1YdnJv8NStI4Qw03ONWAHfkUfvpYQck_8ETmEw8L2f4feFHpjwl3Jo-r5Q4v3ApZjFn0GKWJJ7Gn1833udwyC7mOaDM6bBHzf1xMC3jlODaLUn90Ms4qOhsmKJulTfYWtFKyhuluL8fjHgqg/s16000/regex3.png\" /></a></div>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgg6YRLzK4liSBrM_x06l95ikYd8SYMh3gKd8qLDRJTwgMx4Sd26s3F-P4ffB7Aq7w59wMAExVhXaJymEYAaP36tWu-bOGfR4FgFoEH-7P2WYF7OeIpJc0nj6KzuJYVg5effNp6A9okakeOXnL6bHqtHctXo10uyRdCfldNGHFSU8eOlzMfwYJBtjIHPPpy/s1262/regex4.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"713\" data-original-width=\"1262\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgg6YRLzK4liSBrM_x06l95ikYd8SYMh3gKd8qLDRJTwgMx4Sd26s3F-P4ffB7Aq7w59wMAExVhXaJymEYAaP36tWu-bOGfR4FgFoEH-7P2WYF7OeIpJc0nj6KzuJYVg5effNp6A9okakeOXnL6bHqtHctXo10uyRdCfldNGHFSU8eOlzMfwYJBtjIHPPpy/s16000/regex4.png\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div>\n<div>데이터 처리 과정 전반에 관여하는 정규표현식에 대한 이해 없이는 그 좋다는 스플렁크를 제대로 사용하기 어렵다. 엑셀로 표만 그리는 수준에 머무르기 십상.</div><div><br /></div><div><div><b>관련 글</b></div><div><ul><li><a href=\"https://kangmyounghun.blogspot.com/2025/10/14th.html\">데이터 노가다 실수담 - 14th</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2025/07/12th.html\">데이터 노가다 실수담 - 12th</a></li><li><a href=\"https://kangmyounghun.blogspot.com/2023/06/vim-10th.html\">VIM 꼼수의 발견 - 10th</a></li></ul></div></div>",
        "contentSnippet": "3만 개에 육박하는 변수 발생 내역. 같은 변수라도 달라지는 값 때문에 복잡도가 증가한 결과.  \n\n\n\n\n\n변수값으로 사용된 숫자만 삭제해도 복잡도를 줄여 데이터 발생 범위를 좁힐 수 있다. 내가 알고 싶은 건 전체적인 변수 변화지, 세부적인 변수값 변화가 아니기 때문. 분석 목적에 영향을 주지 않는 요소를 제거하는 차원 축소 결과. \n\n\n\n그런데 URL 인코딩 패턴 때문에 가독성이 떨어진다. 디코딩 시도.\n\n\n\n\n\n왜 디코딩이 안 되지?\n\n\n%2F는 /를 의미하는 16진수 2F를 URL 인코딩한 결과. 그런데 변수 내역을 보니 숫자가 없다. 삭제 과정에서 URL 인코딩 패턴의 숫자까지 삭제했구나(..) 변수값으로 사용된 순수 숫자만을 삭제해야 한다.\n\n\n\n\n\n\n\n\n\n데이터 처리 과정 전반에 관여하는 정규표현식에 대한 이해 없이는 그 좋다는 스플렁크를 제대로 사용하기 어렵다. 엑셀로 표만 그리는 수준에 머무르기 십상.\n\n\n관련 글\n\n데이터 노가다 실수담 - 14th\n데이터 노가다 실수담 - 12th\nVIM 꼼수의 발견 - 10th",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-4895867124415270745",
        "isoDate": "2025-10-17T08:04:00.008Z"
      },
      {
        "title": "Splunk의 sourcetype 변경",
        "link": "https://kangmyounghun.blogspot.com/2025/10/splunk-sourcetype.html",
        "pubDate": "2025-10-14T11:43:00.004Z",
        "author": "강명훈",
        "content": "<div>다시 인덱싱을 하지 않는 한 저장된 인덱스의 소스타입은 바꿀 수 없다.</div><div><br /></div><div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjSCJkEaFTQr0Akc6Rige64aft0AgdsP1D8UXKj-LTZbqhevhiIc-jk9jWV8zxwYxJOeyxGyd0Qk41KsviibPyp_LLQZqQEn4g5OxQ0QheMWFMwAPYuQcr5fFVSIVSSvvkmR3OApLDOWhEFkJVZzon5-xc_m8TApNzux66Ol1_rLg2cu49NSIDl_SSmo3cO/s1280/sourcetype.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"715\" data-original-width=\"1280\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjSCJkEaFTQr0Akc6Rige64aft0AgdsP1D8UXKj-LTZbqhevhiIc-jk9jWV8zxwYxJOeyxGyd0Qk41KsviibPyp_LLQZqQEn4g5OxQ0QheMWFMwAPYuQcr5fFVSIVSSvvkmR3OApLDOWhEFkJVZzon5-xc_m8TApNzux66Ol1_rLg2cu49NSIDl_SSmo3cO/s16000/sourcetype.png\" /></a></div><br /><div><span><a name='more'></a></span>이때&nbsp;<a href=\"https://help.splunk.com/en/splunk-enterprise/search/spl-search-reference/9.4/search-commands/collect#id_6d5f670f_867e_4ddd_a25f_51b6a07d19dc__collect\" target=\"_blank\">collect</a>란 명령어를 사용해볼 수 있다. mysql의 <span style=\"font-family: courier;\">create target_table select * from source_table</span>과 유사. 인덱스는 당연히 미리 만들어 놔야 한다.</div></div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgNUxLCGAZzFd2dyCNbrZgk3gWVEusSOm_KDZqsOF3GT5yLGXRY6mtl9UOckQmhpxWmP-7JUyMEce8zC4w4VhuaUSvqcXOSdHsh1rg89oklQiwh73djKMO7Jmip_4_hyVzqA2hmrrFmpUS3BkopCWsV9uRK_bvy1Nz40pq16eG0SWjGYtP3vQfAU8m-7I1A/s1241/sourcetype2.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1241\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgNUxLCGAZzFd2dyCNbrZgk3gWVEusSOm_KDZqsOF3GT5yLGXRY6mtl9UOckQmhpxWmP-7JUyMEce8zC4w4VhuaUSvqcXOSdHsh1rg89oklQiwh73djKMO7Jmip_4_hyVzqA2hmrrFmpUS3BkopCWsV9uRK_bvy1Nz40pq16eG0SWjGYtP3vQfAU8m-7I1A/s16000/sourcetype2.png\" /></a></div><div><br /></div><div>검색 결과를 특정 경로에 임시 파일로 저장한 후, 새로운 인덱스에 저장해줌.&nbsp;&nbsp;</div><div><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi1S5IyGr37KDeDUqNaaDf04r4OJPl_FVOitECM8NkOmxGFQWGugrQSQWfiPx04rlNnyZBexj-EQmGQjrg9ZthizppFFZtkokeASDM1jh4vkWDox-I_un7zCtEnXGrbNaVxgkalSw3eOK5u1_qNYEPkfi20u7algaM4_JrFwoepPTOraudQx0NKisU2zZK_/s1212/sourcetype3.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1212\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi1S5IyGr37KDeDUqNaaDf04r4OJPl_FVOitECM8NkOmxGFQWGugrQSQWfiPx04rlNnyZBexj-EQmGQjrg9ZthizppFFZtkokeASDM1jh4vkWDox-I_un7zCtEnXGrbNaVxgkalSw3eOK5u1_qNYEPkfi20u7algaM4_JrFwoepPTOraudQx0NKisU2zZK_/s16000/sourcetype3.png\" /></a></div><div><br /></div><div>소스타입 변경도 가능.</div><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjyFakw9ceYNhIfls9NJXiZHgSwB4IxZn4qdKOju6e5yp288fBL8w06hZMuTX6dpSttzl75HTK2cNmbziQe5JT9UMFZYA4Fjy_UxeAS3fPmQmC6gfycNB0OTJGPPtnLL9QX740Lq7PS2XGVaiEolVjB5agnHwXVhbb8dUbVy0Sbe8snY6_rd_XBFoOnypEU/s1244/sourcetype4.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1244\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjyFakw9ceYNhIfls9NJXiZHgSwB4IxZn4qdKOju6e5yp288fBL8w06hZMuTX6dpSttzl75HTK2cNmbziQe5JT9UMFZYA4Fjy_UxeAS3fPmQmC6gfycNB0OTJGPPtnLL9QX740Lq7PS2XGVaiEolVjB5agnHwXVhbb8dUbVy0Sbe8snY6_rd_XBFoOnypEU/s16000/sourcetype4.png\" /></a></div>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhrBI6fiPt_-A1vqce43If9kz3cTqhW1ivyCu0_i7-UudB2e9zO6GOsfxvGf230sjlIzzSCyqU0xhJffMTvgoz-pPYPQKWzFwdwAh64Txrrt8TafkhzzBGQw17re-2oqQmLShqdyVoOOf78J4mHNdBBjKw8VmR0x3F98KSplR1pCGFGHCYFvBZC-Abh-Y7i/s1210/sourcetype5.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" data-original-height=\"720\" data-original-width=\"1210\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhrBI6fiPt_-A1vqce43If9kz3cTqhW1ivyCu0_i7-UudB2e9zO6GOsfxvGf230sjlIzzSCyqU0xhJffMTvgoz-pPYPQKWzFwdwAh64Txrrt8TafkhzzBGQw17re-2oqQmLShqdyVoOOf78J4mHNdBBjKw8VmR0x3F98KSplR1pCGFGHCYFvBZC-Abh-Y7i/s16000/sourcetype5.png\" /></a></div><br /><div><a href=\"https://help.splunk.com/en/splunk-enterprise/manage-knowledge-objects/knowledge-management-manual/10.0/use-data-summaries-to-accelerate-searches/use-summary-indexing-for-increased-search-efficiency\" target=\"_blank\">가공 결과를 별도 저장</a>하고 싶을 때 유용할 듯.</div><div><br /></div>",
        "contentSnippet": "다시 인덱싱을 하지 않는 한 저장된 인덱스의 소스타입은 바꿀 수 없다.\n\n\n\n\n이때 collect란 명령어를 사용해볼 수 있다. mysql의 create target_table select * from source_table과 유사. 인덱스는 당연히 미리 만들어 놔야 한다.\n\n\n\n\n\n검색 결과를 특정 경로에 임시 파일로 저장한 후, 새로운 인덱스에 저장해줌.  \n\n\n\n\n\n소스타입 변경도 가능.\n\n\n\n\n가공 결과를 별도 저장하고 싶을 때 유용할 듯.",
        "id": "tag:blogger.com,1999:blog-2597780270996323853.post-2970430929864022672",
        "isoDate": "2025-10-14T11:43:00.004Z"
      }
    ]
  },
  {
    "name": "김민장",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성중",
    "category": "개인",
    "posts": []
  },
  {
    "name": "구교준",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김덕기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "고명환",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강병수",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김봉현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강형석",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김수로",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강미경",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김성현",
    "category": "개인",
    "posts": []
  },
  {
    "name": "강진우",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권민재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "권태관",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김도곤",
    "category": "개인",
    "posts": []
  },
  {
    "name": "칡토스의 게임 개발",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김선철",
    "category": "개인",
    "posts": []
  },
  {
    "name": "프리웨어 이야기",
    "category": "개인",
    "posts": [
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "블로거 시간을 획기적으로 줄이는 올인원 앱, 무료 배포",
        "link": "http://muzbox.tistory.com/483670",
        "pubDate": "Sat, 18 Oct 2025 21:50:18 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483670#entry483670comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #333333;\">\n<div style=\"background-color: #e6f4ea; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">2025년, 블로거의 시간을 획기적으로 줄여줄 올인원 AI 블로깅 앱 <b>'GPT PARK 올인원 블로깅 프로'</b>를 소개합니다. 아이디어 발굴부터 SEO, 콘텐츠 생성, SNS 홍보까지 모든 과정을 한 번에 해결하여 블로그 운영의 효율을 극대화해보세요.</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"675\"><span data-url=\"https://blog.kakaocdn.net/dn/eIJNnk/dJMb9XqNzws/hjGBnkwZJBZVBFse9QcrCK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/eIJNnk/dJMb9XqNzws/hjGBnkwZJBZVBFse9QcrCK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/eIJNnk/dJMb9XqNzws/hjGBnkwZJBZVBFse9QcrCK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FeIJNnk%2FdJMb9XqNzws%2FhjGBnkwZJBZVBFse9QcrCK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"블로그 운영의 모든 과정을 AI가 효율적으로 지원하여 블로거의 시간을 절약하는 미래 지향적인 앱의 모습, AI 기반의 콘텐츠 생성 및 SEO 최적화 기능이 강조된 이미지.\" loading=\"lazy\" width=\"1200\" height=\"675\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"675\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><br />블로그 운영, 정말 쉽지 않죠? \"오늘 뭐 쓰지?\", \"이 키워드는 상위 노출될까?\", \"SEO는 어떻게 최적화하지?\", \"이미지는 어디서 구하지?\"&hellip; 아마 이런 고민들 때문에 지쳐본 경험, 다들 있으실 거예요. 매일 반복되는 콘텐츠 고민에 시달리다가 결국 포기하고 싶었던 순간도 적지 않을 거라 생각합니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">저도 20년차 블로거로서 비슷한 어려움을 수없이 겪어왔습니다. 기존에 제미나이(Gemini) 젬 지침을 활용한 블로그 글쓰기 방법도 소개했지만, 인용 코드, 글자 수 제한, 그리고 결정적으로 <b>블로그 이미지는 따로 생성해야 하는 번거로움</b>이 늘 아쉬웠죠. 이 문제를 해결하려면 더욱 구조화되고 자동화된 도구가 필요했고, 그 결과물이 바로 AI Studio 기반의 <b>'GPT PARK 올인원 블로깅 프로' 앱</b>입니다. 젬 지침이 손으로 쓴 레시피 메모라면, 이 앱은 모든 것이 자동화된 스마트 주방 시스템이라고 비유할 수 있겠네요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">오늘 제가 개발한 블로그 글쓰기의 끝판왕, <b>'GPT PARK 올인원 블로깅 프로'</b>를 자세히 소개해 드릴게요. 이 앱 하나면 아이디어 발굴부터 SEO 분석, 고품질 기사 작성, 그리고 소셜 미디어 홍보까지, 블로그 운영의 모든 것이 한 곳에서 가능해집니다. 그럼, 이 앱이 블로거의 시간을 어떻게 획기적으로 줄여주는지 함께 알아볼까요?</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #34a853, #1e8e3e); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  블로그 성장의 비밀 무기: 앱 핵심 기능 둘러보기</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">'GPT PARK 올인원 블로깅 프로'는 블로그 운영의 모든 과정을 세 가지 핵심 탭으로 통합하여 제공합니다. 각 탭은 유기적으로 연결되어, 글감 고민부터 최종 포스팅 발행까지 정말 자연스럽고 빠르게 진행할 수 있도록 설계되었어요.</p>\n<ul style=\"list-style-type: disc; margin-left: 25px; margin-bottom: 20px; color: #333333;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px;\"><b>1. 주제 아이디어 얻기:</b> 글감 부족 문제를 해결하는 첫걸음! AI가 다양한 관점에서 블로그에 딱 맞는 신선하고 경쟁력 있는 주제를 추천해줍니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>2. 키워드 파이터:</b> SEO 전문가처럼 키워드를 깊이 있게 분석하고, 경쟁 블로그를 뛰어넘을 전략을 수립하는 강력한 도구입니다. 분석 결과가 바로 포스팅 생성으로 연동되는 편리함이 돋보이죠.</li>\n<li style=\"margin-bottom: 10px;\"><b>3. 포스트 생성하기:</b> 앞서 정한 주제와 전략을 바탕으로 실제 블로그 글을 생성합니다. 고품질의 블로그 콘텐츠가 클릭 한 번으로 탄생하는 놀라운 경험을 선사합니다.</li>\n</ul>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #34a853, #1e8e3e); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  아이디어 고갈? 이젠 과거형! '주제 아이디어 얻기' 심층 분석</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">'주제 아이디어 얻기' 탭은 블로거의 가장 큰 고민 중 하나인 글감 고갈을 효과적으로 해결해줍니다. 여기서는 5가지 AI 분석 모델이 마치 여러 전문가처럼 다양한 관점에서 주제를 제안해요.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/bFnXzT/dJMb9N2RqrD/uEUBU5ZFklq0kHvsX4r6Mk/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bFnXzT/dJMb9N2RqrD/uEUBU5ZFklq0kHvsX4r6Mk/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bFnXzT/dJMb9N2RqrD/uEUBU5ZFklq0kHvsX4r6Mk/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbFnXzT%2FdJMb9N2RqrD%2FuEUBU5ZFklq0kHvsX4r6Mk%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"AI가 카테고리별, E-E-A-T, 에버그린, 롱테일, 메모/파일 기반으로 블로그 주제를 발굴하는 5가지 모델을 보여주는 이미지.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h3 style=\"font-size: 19px; color: #34a853; margin: 25px 0 10px; font-weight: bold;\" data-ke-size=\"size23\">다양한 AI 기반 주제 발굴 모델</h3>\n<ul style=\"list-style-type: disc; margin-left: 25px; margin-bottom: 20px; color: #333333;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px;\"><b>카테고리별 추천:</b> IT, 건강, 재테크 등 블로그 카테고리를 선택하면 AI가 최신 트렌드를 반영한 창의적인 주제를 제안합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>E-E-A-T 기반 주제 추천:</b> 구글 검색 상위 노출의 핵심인 E-E-A-T(경험, 전문성, 권위, 신뢰도)를 높일 수 있는 주제를 AI가 선별해줍니다. SEO를 중요시한다면 필수!</li>\n<li style=\"margin-bottom: 10px;\"><b>에버그린 콘텐츠:</b> 시간이 지나도 가치가 변하지 않아 꾸준한 트래픽을 유도할 수 있는 주제를 추천합니다. (예: \"2025년 최신 전기차의 역사\") 블로그 초기에 쌓아두면 장기적으로 큰 도움이 되죠.</li>\n<li style=\"margin-bottom: 10px;\"><b>롱테일 키워드 주제:</b> 실시간 구글 검색을 분석해 경쟁은 낮지만, 명확한 목적을 가진 사용자를 타겟팅하는 주제를 제안합니다. (예: \"초보 러너를 위한 무릎 통증 예방 5분 스트레칭\")</li>\n<li style=\"margin-bottom: 10px;\"><b>메모/파일 기반:</b> 여러분의 간단한 메모, 글 초안, 강의 노트 등을 입력/업로드하면 AI가 핵심 내용을 분석하여 최적의 블로그 주제로 변환해줍니다. 저는 퍼플렉시티 검색 결과를 자주 활용합니다.</li>\n</ul>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #34a853, #1e8e3e); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  SEO 최적화의 핵심: '키워드 파이터'와 앱 연동</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">블로그 글이 아무리 좋아도 독자에게 노출되지 않으면 의미가 없죠. '키워드 파이터' 탭은 여러분의 글이 더 많은 사람에게 닿을 수 있도록 돕는 강력한 SEO 도구입니다. 이 탭은 네이버 검색 API와 연동되므로, 사용 전 네이버 개발자 센터에서 API 키를 발급받아 앱에 등록하는 과정이 필요합니다. 한 번만 설정해두면 계속해서 사용할 수 있으니, 블로그의 가시성을 높이는 데 필수적인 과정이라고 할 수 있어요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">'키워드 파이터'의 가장 큰 장점은 <b>분석된 키워드를 기반으로 제공되는 주제를 선택하면, 바로 '포스트 생성하기' 탭으로 연결</b>된다는 점입니다. 키워드 연구부터 글쓰기까지, 정말 물 흐르듯 끊김 없이 효율적인 워크플로우를 제공합니다.</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #34a853, #1e8e3e); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>✍️ 고품질 콘텐츠의 마법: '포스트 생성하기' 완전 정복</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">'GPT PARK 올인원 블로깅 프로'의 하이라이트는 역시 '포스트 생성하기' 탭입니다. 이곳에서 앞선 탭들에서 얻은 영감과 전략을 바탕으로 실제 블로그 글이 만들어집니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1474\" data-origin-height=\"889\"><span data-url=\"https://blog.kakaocdn.net/dn/qYnQx/dJMb9PzB4tn/5WLPP3q6fKbNk7SxOXPyR0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/qYnQx/dJMb9PzB4tn/5WLPP3q6fKbNk7SxOXPyR0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/qYnQx/dJMb9PzB4tn/5WLPP3q6fKbNk7SxOXPyR0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FqYnQx%2FdJMb9PzB4tn%2F5WLPP3q6fKbNk7SxOXPyR0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"GPT PARK 올인원 블로깅 프로의 스크린 샷\" loading=\"lazy\" width=\"1474\" height=\"889\" data-origin-width=\"1474\" data-origin-height=\"889\"/></span></figure>\n\n<h3 style=\"font-size: 19px; color: #34a853; margin: 25px 0 10px; font-weight: bold;\" data-ke-size=\"size23\">맞춤형 블로그 글 생성 옵션</h3>\n<ul style=\"list-style-type: disc; margin-left: 25px; margin-bottom: 20px; color: #333333;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px;\"><b>자동 제목 및 추가 요청:</b> 선택한 주제가 자동으로 블로그 제목이 되며, 추가적으로 원하는 사항(예: \"전문 용어 최소화\")을 입력할 수 있습니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>7가지 컬러 테마:</b> 블로그의 컨셉에 맞춰 7가지 테마 중 하나를 선택하면, 앱이 인라인 스타일을 적용하여 시각적으로 매력적인 글을 완성합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>대표 및 서브 이미지 자동 생성:</b> 글의 내용에 맞는 대표 이미지와 최대 3개의 서브 이미지를 자동으로 생성해줍니다. 이미지 검색에 시간을 낭비할 필요가 없어요.</li>\n<li style=\"margin-bottom: 10px;\"><b>썸네일용 텍스트 추가:</b> 대표 이미지 위에 블로그 제목이나 핵심 문구를 넣어 클릭을 유도하는 썸네일을 만들 수 있습니다. 글꼴, 색상, 크기, 외곽선까지 자유롭게 조절 가능합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>인터랙티브 요소:</b> 진단기나 계산기 같은 인터랙티브 요소를 글에 추가하여 독자의 참여를 유도하고 체류 시간을 늘릴 수 있습니다.</li>\n</ul>\n<h3 style=\"font-size: 19px; color: #34a853; margin: 25px 0 10px; font-weight: bold;\" data-ke-size=\"size23\">AI의 한계를 넘어서는 '인간적인 글쓰기'</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">가장 특별한 기능은 <b>'인간적인 글쓰기'</b> 옵션입니다. AI가 쓴 글이라는 느낌을 최소화하고, 마치 사람이 직접 쓴 듯 자연스럽고 개성 있는 글을 만들어줍니다.</p>\n<ul style=\"list-style-type: disc; margin-left: 25px; margin-bottom: 20px; color: #333333;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 10px;\"><b>유형 A (친근한 대화체):</b> \"솔직히 말하면\"처럼 감정이나 개인 경험을 넣어 독자와의 공감대를 형성합니다.</li>\n<li style=\"margin-bottom: 10px;\"><b>유형 B (전문적인 신뢰감):</b> 논리적이고 구조적인 글쓰기로 전문가의 설명을 듣는 듯한 신뢰감을 선사합니다.</li>\n</ul>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">콘텐츠 성격에 맞춰 유형을 선택하면, 블로그의 개성을 더욱 살리고 독자들에게 더 깊이 다가갈 수 있을 거예요. 모든 설정 후 '포스트 생성' 버튼을 클릭하면, 약 1분 만에 고품질의 블로그 기사가 완성됩니다. 미리보기에서 이미지와 함께 완벽하게 어우러진 글을 확인할 수 있죠!</p>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #34a853, #1e8e3e); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b> ️ 효율적인 블로그 발행 팁: 이미지 처리의 중요성</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">앱에서 생성된 HTML 코드를 블로그에 붙여넣을 때, \"왜 이미지는 빠져있지?\" 하고 궁금해하실 수 있습니다. 이 부분은 블로그 운영 효율과 SEO에 아주 중요한 팁입니다.</p>\n<div style=\"background-color: #fde293; border-left: 4px solid #f9ab00; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">⚠️ <b>필수 확인:</b> HTML 코드에는 이미지 파일 자체가 아니라 <b>이미지 경로(URL)만 저장</b>됩니다. 앱 미리보기는 앱 서버 이미지를 보여주지만, 블로그 플랫폼은 그 경로를 찾을 수 없어요. 따라서 이미지는 반드시 각 블로그 플랫폼에 직접 업로드해야 합니다.</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">이미지를 HTML에 직접 삽입하는 베이스64 인코딩 방식은 파일 크기를 엄청나게 늘려 블로그 편집기를 느리게 하고, 페이지 로딩 속도를 저하시킵니다. 이는 <b>구글 검색 순위에도 부정적인 영향</b>을 미치죠. 'GPT PARK 올인원 블로깅 프로'는 이런 점을 고려하여 이미지를 따로 관리하도록 설계되었습니다. 생성된 이미지를 다운로드하여 블로그에 직접 업로드하고 알트 태그를 추가하는 것이 가장 효율적인 방법입니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/JPd6h/dJMb862mExd/8t88MaeG5Vs4CCze7vXNbK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/JPd6h/dJMb862mExd/8t88MaeG5Vs4CCze7vXNbK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/JPd6h/dJMb862mExd/8t88MaeG5Vs4CCze7vXNbK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FJPd6h%2FdJMb862mExd%2F8t88MaeG5Vs4CCze7vXNbK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"블로그 이미지 처리의 비효율적인 베이스64 인코딩 방식(느린 로딩, 나쁜 SEO)과 효율적인 외부 파일 관리 방식(빠른 로딩, 좋은 SEO)을 비교하는 시각 자료.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #34a853, #1e8e3e); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  블로그 홍보, 이제 소셜 미디어까지 한 번에!</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">열심히 작성한 블로그 글, 더 많은 사람에게 효과적으로 알려야겠죠? 'GPT PARK 올인원 블로깅 프로'는 블로그 글 생성 후에 <b>각 소셜 미디어 플랫폼에 최적화된 홍보 문구</b>를 자동으로 생성해주는 기능까지 포함하고 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">스레드, 인스타그램, 페이스북, X(구 트위터) 등 주요 SNS 플랫폼의 특성을 완벽하게 이해하고 맞춤형 문구를 제안합니다. 인스타그램에는 시각적인 매력을 강조한 감성적인 표현을, X에는 짧고 임팩트 있는 핵심 문구를 제안하는 식이죠. 이 기능을 통해 여러 도구를 오가는 번거로움 없이 블로깅 작업부터 SNS 홍보까지 <b>원스톱으로 효율적인 처리</b>가 가능해집니다.</p>\n<div style=\"background-color: #f1f8e9; border: 1px solid #a5d6a7; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); padding: 25px; margin: 30px 0;\">\n<div style=\"font-size: 26px; color: #34a853; font-weight: bold; margin-bottom: 15px; padding-bottom: 10px; border-bottom: 2px solid #34a853;\">  핵심 요약</div>\n<ul style=\"list-style-type: none; padding: 0; margin: 0;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 15px; font-size: 17px;\"><b>✨ 아이디어 고갈 해결:</b> 5가지 AI 모델로 무궁무진한 블로그 주제를 발굴하고, 에버그린 및 롱테일 키워드 전략으로 지속적인 트래픽을 확보하세요.</li>\n<li style=\"margin-bottom: 15px; font-size: 17px;\"><b>  강력한 SEO/AEO 최적화:</b> '키워드 파이터'로 네이버 검색 API 기반의 심층 키워드 분석을 통해 상위 노출 전략을 수립하고, E-E-A-T 기반 주제로 구글 검색 가시성을 높이세요.</li>\n<li style=\"margin-bottom: 15px; font-size: 17px;\"><b>✍️ 단 1분 만에 고품질 콘텐츠:</b> AI가 자동으로 인라인 스타일 HTML, 대표/서브 이미지, 썸네일, 인터랙티브 요소까지 포함한 블로그 글을 생성하여 시간과 노력을 획기적으로 절감합니다.</li>\n<li style=\"margin-bottom: 0; font-size: 17px;\"><b>  통합 소셜 미디어 홍보:</b> 생성된 블로그 글을 바탕으로 스레드, 인스타그램, 페이스북, X 등 각 플랫폼에 최적화된 홍보 문구를 자동으로 생성하여 효과적인 확산을 지원합니다.</li>\n</ul>\n<div style=\"font-size: 14px; color: #ea8600; margin-top: 20px; padding-top: 10px; border-top: 1px dashed #a5d6a7;\">더 이상 블로그 운영에 시간을 낭비하지 마세요! 'GPT PARK 올인원 블로깅 프로'로 여러분의 블로그를 한 단계 업그레이드할 시간입니다.</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #34a853, #1e8e3e); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>  GPT PARK 올인원 블로깅 BASIC 무료배포</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">&nbsp;아래 링크로 BASIC 버전 무료 배포합니다. 이 버전에는 키워드 파이터와 인간적인 글쓰기 기능이 포함되지 않았지만 일반적인 포스팅에는 이용에 문제가 없습니다. 모든 기능이 담긴 PRO 버전을 사용하시려면 제 유튜브 채널 멤버십에 가입하신 후 멤버십 전용 게시판에서 프로 버전 링크를 받으실 수 있습니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"2069\" data-origin-height=\"1032\"><span data-url=\"https://blog.kakaocdn.net/dn/pUGwy/dJMb86BiguJ/uWdViVk6OKUb5NVcz7XW9k/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/pUGwy/dJMb86BiguJ/uWdViVk6OKUb5NVcz7XW9k/img.png\"><img src=\"https://blog.kakaocdn.net/dn/pUGwy/dJMb86BiguJ/uWdViVk6OKUb5NVcz7XW9k/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FpUGwy%2FdJMb86BiguJ%2FuWdViVk6OKUb5NVcz7XW9k%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"GPT PARK 올인원 블로깅 베이직, 프로의 차이를 비교하는 이미지\" loading=\"lazy\" width=\"2069\" height=\"1032\" data-origin-width=\"2069\" data-origin-height=\"1032\"/></span></figure>\n\n<figure id=\"og_1760791711479\" contenteditable=\"false\" data-ke-type=\"opengraph\" data-ke-align=\"alignCenter\" data-og-type=\"website\" data-og-title=\"로그인 - Google 계정\" data-og-description=\"이메일 또는 휴대전화\" data-og-host=\"accounts.google.com\" data-og-source-url=\"https://ai.studio/apps/drive/1S6Qfy9zh427Q4WudNKt1jNZ0arfeqPSf\" data-og-url=\"https://accounts.google.com/v3/signin/identifier?continue=https%3A%2F%2Faistudio.google.com%2Fapps%2Fdrive%2F1S6Qfy9zh427Q4WudNKt1jNZ0arfeqPSf&amp;dsh=S-1020323408%3A1760791709268552&amp;followup=https%3A%2F%2Faistudio.google.com%2Fapps%2Fdrive%2F1S6Qfy9zh427Q4WudNKt1jNZ0arfeqPSf&amp;ifkv=AfYwgwVij199fjdNUVq9df7hMzNAvDeewcCd73Jk_I184N1WiMv4KbsbNhpJCxzh1xC35uB0HQxmDQ&amp;passive=1209600&amp;flowName=WebLiteSignIn&amp;flowEntry=ServiceLogin\" data-og-image=\"\"><a href=\"https://ai.studio/apps/drive/1S6Qfy9zh427Q4WudNKt1jNZ0arfeqPSf\" target=\"_blank\" rel=\"noopener\" data-source-url=\"https://ai.studio/apps/drive/1S6Qfy9zh427Q4WudNKt1jNZ0arfeqPSf\">\n<div class=\"og-image\" style=\"background-image: url();\">&nbsp;</div>\n<div class=\"og-text\">\n<p class=\"og-title\" data-ke-size=\"size16\">로그인 - Google 계정</p>\n<p class=\"og-desc\" data-ke-size=\"size16\">이메일 또는 휴대전화</p>\n<p class=\"og-host\" data-ke-size=\"size16\">accounts.google.com</p>\n</div>\n</a></figure>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #34a853, #1e8e3e); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q1: 'GPT PARK 올인원 블로깅 프로'는 어떤 블로그 플랫폼과 호환되나요?</b><br />A1: 이 앱은 생성된 HTML 코드를 제공하므로, HTML 편집 기능을 지원하는 대부분의 블로그 플랫폼(예: 티스토리, 워드프레스 등)에서 활용할 수 있습니다. 이미지는 각 플랫폼에 직접 업로드해야 합니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q2: '인간적인 글쓰기' 유형 A와 B는 어떻게 다른가요?</b><br />A2: 유형 A는 감정적 표현과 개인적인 경험을 담아 친근하고 대화하는 듯한 느낌을 줍니다. 반면 유형 B는 논리적인 구조와 다양한 어휘로 전문적이고 신뢰감 있는 톤으로 글을 작성합니다. 콘텐츠의 성격에 맞춰 선택하시면 됩니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q3: 네이버 검색 API 키 등록은 필수인가요?</b><br />A3: '키워드 파이터' 탭의 모든 기능을 활용하려면 네이버 검색 API 키 등록이 필수입니다. 하지만 API 키 없이도 '주제 아이디어 얻기' 탭과 '포스트 생성하기' 탭의 기본적인 기능은 모두 사용할 수 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><b>Q4: 'GPT PARK 올인원 블로깅 프로'의 베이직 버전과 프로 버전의 차이점은 무엇인가요?</b><br />A4: 베이직 버전은 일반적인 포스팅에 필요한 핵심 기능을 제공하며, 프로 버전에는 '키워드 파이터'의 심층 분석 기능과 '인간적인 글쓰기' 옵션을 포함한 모든 고급 기능이 담겨 있습니다. 자세한 내용은 앱 공식 페이지를 참고해주세요.</p>\n<script type=\"application/ld+json\">\n    {\n      \"@context\": \"https://schema.org\",\n      \"@type\": \"FAQPage\",\n      \"mainEntity\": [\n        {\n          \"@type\": \"Question\",\n          \"name\": \"'GPT PARK 올인원 블로깅 프로'는 어떤 블로그 플랫폼과 호환되나요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"이 앱은 생성된 HTML 코드를 제공하므로, HTML 편집 기능을 지원하는 대부분의 블로그 플랫폼(예: 티스토리, 워드프레스 등)에서 활용할 수 있습니다. 이미지는 각 플랫폼에 직접 업로드해야 합니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"'인간적인 글쓰기' 유형 A와 B는 어떻게 다른가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"유형 A는 감정적 표현과 개인적인 경험을 담아 친근하고 대화하는 듯한 느낌을 줍니다. 반면 유형 B는 논리적인 구조와 다양한 어휘로 전문적이고 신뢰감 있는 톤으로 글을 작성합니다. 콘텐츠의 성격에 맞춰 선택하시면 됩니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"네이버 검색 API 키 등록은 필수인가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"'키워드 파이터' 탭의 모든 기능을 활용하려면 네이버 검색 API 키 등록이 필수입니다. 하지만 API 키 없이도 '주제 아이디어 얻기' 탭과 '포스트 생성하기' 탭의 기본적인 기능은 모두 사용할 수 있습니다.\"\n          }\n        },\n        {\n          \"@type\": \"Question\",\n          \"name\": \"'GPT PARK 올인원 블로깅 프로'의 베이직 버전과 프로 버전의 차이점은 무엇인가요?\",\n          \"acceptedAnswer\": {\n            \"@type\": \"Answer\",\n            \"text\": \"베이직 버전은 일반적인 포스팅에 필요한 핵심 기능을 제공하며, 프로 버전에는 '키워드 파이터'의 심층 분석 기능과 '인간적인 글쓰기' 옵션을 포함한 모든 고급 기능이 담겨 있습니다. 자세한 내용은 앱 공식 페이지를 참고해주세요.\"\n          }\n        }\n      ]\n    }\n    </script>\n</div>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=OgqrTu_fXKI\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bgXT6a/hyZL0kF4rm/tOIRzTkL7efnoTu7buumnK/img.jpg?width=1280&amp;height=720&amp;face=402_168_534_312,https://scrap.kakaocdn.net/dn/A61SA/hyZL39xAk0/1R25ijk6MO6AcMfkKOuvk1/img.jpg?width=1280&amp;height=720&amp;face=402_168_534_312\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"블로그 글쓰기 끝판왕! 무료앱 배포합니다\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/OgqrTu_fXKI\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<div id=\"gtx-trans\" style=\"position: absolute; left: -27px; top: 7071.26px;\">\n<div class=\"gtx-trans-icon\">&nbsp;</div>\n</div>",
        "contentSnippet": "2025년, 블로거의 시간을 획기적으로 줄여줄 올인원 AI 블로깅 앱 'GPT PARK 올인원 블로깅 프로'를 소개합니다. 아이디어 발굴부터 SEO, 콘텐츠 생성, SNS 홍보까지 모든 과정을 한 번에 해결하여 블로그 운영의 효율을 극대화해보세요.\n\n\n\n블로그 운영, 정말 쉽지 않죠? \"오늘 뭐 쓰지?\", \"이 키워드는 상위 노출될까?\", \"SEO는 어떻게 최적화하지?\", \"이미지는 어디서 구하지?\"… 아마 이런 고민들 때문에 지쳐본 경험, 다들 있으실 거예요. 매일 반복되는 콘텐츠 고민에 시달리다가 결국 포기하고 싶었던 순간도 적지 않을 거라 생각합니다.\n저도 20년차 블로거로서 비슷한 어려움을 수없이 겪어왔습니다. 기존에 제미나이(Gemini) 젬 지침을 활용한 블로그 글쓰기 방법도 소개했지만, 인용 코드, 글자 수 제한, 그리고 결정적으로 블로그 이미지는 따로 생성해야 하는 번거로움이 늘 아쉬웠죠. 이 문제를 해결하려면 더욱 구조화되고 자동화된 도구가 필요했고, 그 결과물이 바로 AI Studio 기반의 'GPT PARK 올인원 블로깅 프로' 앱입니다. 젬 지침이 손으로 쓴 레시피 메모라면, 이 앱은 모든 것이 자동화된 스마트 주방 시스템이라고 비유할 수 있겠네요.\n오늘 제가 개발한 블로그 글쓰기의 끝판왕, 'GPT PARK 올인원 블로깅 프로'를 자세히 소개해 드릴게요. 이 앱 하나면 아이디어 발굴부터 SEO 분석, 고품질 기사 작성, 그리고 소셜 미디어 홍보까지, 블로그 운영의 모든 것이 한 곳에서 가능해집니다. 그럼, 이 앱이 블로거의 시간을 어떻게 획기적으로 줄여주는지 함께 알아볼까요?\n  블로그 성장의 비밀 무기: 앱 핵심 기능 둘러보기\n'GPT PARK 올인원 블로깅 프로'는 블로그 운영의 모든 과정을 세 가지 핵심 탭으로 통합하여 제공합니다. 각 탭은 유기적으로 연결되어, 글감 고민부터 최종 포스팅 발행까지 정말 자연스럽고 빠르게 진행할 수 있도록 설계되었어요.\n1. 주제 아이디어 얻기: 글감 부족 문제를 해결하는 첫걸음! AI가 다양한 관점에서 블로그에 딱 맞는 신선하고 경쟁력 있는 주제를 추천해줍니다.\n2. 키워드 파이터: SEO 전문가처럼 키워드를 깊이 있게 분석하고, 경쟁 블로그를 뛰어넘을 전략을 수립하는 강력한 도구입니다. 분석 결과가 바로 포스팅 생성으로 연동되는 편리함이 돋보이죠.\n3. 포스트 생성하기: 앞서 정한 주제와 전략을 바탕으로 실제 블로그 글을 생성합니다. 고품질의 블로그 콘텐츠가 클릭 한 번으로 탄생하는 놀라운 경험을 선사합니다.\n  아이디어 고갈? 이젠 과거형! '주제 아이디어 얻기' 심층 분석\n'주제 아이디어 얻기' 탭은 블로거의 가장 큰 고민 중 하나인 글감 고갈을 효과적으로 해결해줍니다. 여기서는 5가지 AI 분석 모델이 마치 여러 전문가처럼 다양한 관점에서 주제를 제안해요.\n\n\n다양한 AI 기반 주제 발굴 모델\n카테고리별 추천: IT, 건강, 재테크 등 블로그 카테고리를 선택하면 AI가 최신 트렌드를 반영한 창의적인 주제를 제안합니다.\nE-E-A-T 기반 주제 추천: 구글 검색 상위 노출의 핵심인 E-E-A-T(경험, 전문성, 권위, 신뢰도)를 높일 수 있는 주제를 AI가 선별해줍니다. SEO를 중요시한다면 필수!\n에버그린 콘텐츠: 시간이 지나도 가치가 변하지 않아 꾸준한 트래픽을 유도할 수 있는 주제를 추천합니다. (예: \"2025년 최신 전기차의 역사\") 블로그 초기에 쌓아두면 장기적으로 큰 도움이 되죠.\n롱테일 키워드 주제: 실시간 구글 검색을 분석해 경쟁은 낮지만, 명확한 목적을 가진 사용자를 타겟팅하는 주제를 제안합니다. (예: \"초보 러너를 위한 무릎 통증 예방 5분 스트레칭\")\n메모/파일 기반: 여러분의 간단한 메모, 글 초안, 강의 노트 등을 입력/업로드하면 AI가 핵심 내용을 분석하여 최적의 블로그 주제로 변환해줍니다. 저는 퍼플렉시티 검색 결과를 자주 활용합니다.\n  SEO 최적화의 핵심: '키워드 파이터'와 앱 연동\n블로그 글이 아무리 좋아도 독자에게 노출되지 않으면 의미가 없죠. '키워드 파이터' 탭은 여러분의 글이 더 많은 사람에게 닿을 수 있도록 돕는 강력한 SEO 도구입니다. 이 탭은 네이버 검색 API와 연동되므로, 사용 전 네이버 개발자 센터에서 API 키를 발급받아 앱에 등록하는 과정이 필요합니다. 한 번만 설정해두면 계속해서 사용할 수 있으니, 블로그의 가시성을 높이는 데 필수적인 과정이라고 할 수 있어요.\n'키워드 파이터'의 가장 큰 장점은 분석된 키워드를 기반으로 제공되는 주제를 선택하면, 바로 '포스트 생성하기' 탭으로 연결된다는 점입니다. 키워드 연구부터 글쓰기까지, 정말 물 흐르듯 끊김 없이 효율적인 워크플로우를 제공합니다.\n✍️ 고품질 콘텐츠의 마법: '포스트 생성하기' 완전 정복\n'GPT PARK 올인원 블로깅 프로'의 하이라이트는 역시 '포스트 생성하기' 탭입니다. 이곳에서 앞선 탭들에서 얻은 영감과 전략을 바탕으로 실제 블로그 글이 만들어집니다.\n\n\n맞춤형 블로그 글 생성 옵션\n자동 제목 및 추가 요청: 선택한 주제가 자동으로 블로그 제목이 되며, 추가적으로 원하는 사항(예: \"전문 용어 최소화\")을 입력할 수 있습니다.\n7가지 컬러 테마: 블로그의 컨셉에 맞춰 7가지 테마 중 하나를 선택하면, 앱이 인라인 스타일을 적용하여 시각적으로 매력적인 글을 완성합니다.\n대표 및 서브 이미지 자동 생성: 글의 내용에 맞는 대표 이미지와 최대 3개의 서브 이미지를 자동으로 생성해줍니다. 이미지 검색에 시간을 낭비할 필요가 없어요.\n썸네일용 텍스트 추가: 대표 이미지 위에 블로그 제목이나 핵심 문구를 넣어 클릭을 유도하는 썸네일을 만들 수 있습니다. 글꼴, 색상, 크기, 외곽선까지 자유롭게 조절 가능합니다.\n인터랙티브 요소: 진단기나 계산기 같은 인터랙티브 요소를 글에 추가하여 독자의 참여를 유도하고 체류 시간을 늘릴 수 있습니다.\nAI의 한계를 넘어서는 '인간적인 글쓰기'\n가장 특별한 기능은 '인간적인 글쓰기' 옵션입니다. AI가 쓴 글이라는 느낌을 최소화하고, 마치 사람이 직접 쓴 듯 자연스럽고 개성 있는 글을 만들어줍니다.\n유형 A (친근한 대화체): \"솔직히 말하면\"처럼 감정이나 개인 경험을 넣어 독자와의 공감대를 형성합니다.\n유형 B (전문적인 신뢰감): 논리적이고 구조적인 글쓰기로 전문가의 설명을 듣는 듯한 신뢰감을 선사합니다.\n콘텐츠 성격에 맞춰 유형을 선택하면, 블로그의 개성을 더욱 살리고 독자들에게 더 깊이 다가갈 수 있을 거예요. 모든 설정 후 '포스트 생성' 버튼을 클릭하면, 약 1분 만에 고품질의 블로그 기사가 완성됩니다. 미리보기에서 이미지와 함께 완벽하게 어우러진 글을 확인할 수 있죠!\n ️ 효율적인 블로그 발행 팁: 이미지 처리의 중요성\n앱에서 생성된 HTML 코드를 블로그에 붙여넣을 때, \"왜 이미지는 빠져있지?\" 하고 궁금해하실 수 있습니다. 이 부분은 블로그 운영 효율과 SEO에 아주 중요한 팁입니다.\n⚠️ 필수 확인: HTML 코드에는 이미지 파일 자체가 아니라 이미지 경로(URL)만 저장됩니다. 앱 미리보기는 앱 서버 이미지를 보여주지만, 블로그 플랫폼은 그 경로를 찾을 수 없어요. 따라서 이미지는 반드시 각 블로그 플랫폼에 직접 업로드해야 합니다.\n이미지를 HTML에 직접 삽입하는 베이스64 인코딩 방식은 파일 크기를 엄청나게 늘려 블로그 편집기를 느리게 하고, 페이지 로딩 속도를 저하시킵니다. 이는 구글 검색 순위에도 부정적인 영향을 미치죠. 'GPT PARK 올인원 블로깅 프로'는 이런 점을 고려하여 이미지를 따로 관리하도록 설계되었습니다. 생성된 이미지를 다운로드하여 블로그에 직접 업로드하고 알트 태그를 추가하는 것이 가장 효율적인 방법입니다.\n\n\n  블로그 홍보, 이제 소셜 미디어까지 한 번에!\n열심히 작성한 블로그 글, 더 많은 사람에게 효과적으로 알려야겠죠? 'GPT PARK 올인원 블로깅 프로'는 블로그 글 생성 후에 각 소셜 미디어 플랫폼에 최적화된 홍보 문구를 자동으로 생성해주는 기능까지 포함하고 있습니다.\n스레드, 인스타그램, 페이스북, X(구 트위터) 등 주요 SNS 플랫폼의 특성을 완벽하게 이해하고 맞춤형 문구를 제안합니다. 인스타그램에는 시각적인 매력을 강조한 감성적인 표현을, X에는 짧고 임팩트 있는 핵심 문구를 제안하는 식이죠. 이 기능을 통해 여러 도구를 오가는 번거로움 없이 블로깅 작업부터 SNS 홍보까지 원스톱으로 효율적인 처리가 가능해집니다.\n  핵심 요약\n✨ 아이디어 고갈 해결: 5가지 AI 모델로 무궁무진한 블로그 주제를 발굴하고, 에버그린 및 롱테일 키워드 전략으로 지속적인 트래픽을 확보하세요.\n  강력한 SEO/AEO 최적화: '키워드 파이터'로 네이버 검색 API 기반의 심층 키워드 분석을 통해 상위 노출 전략을 수립하고, E-E-A-T 기반 주제로 구글 검색 가시성을 높이세요.\n✍️ 단 1분 만에 고품질 콘텐츠: AI가 자동으로 인라인 스타일 HTML, 대표/서브 이미지, 썸네일, 인터랙티브 요소까지 포함한 블로그 글을 생성하여 시간과 노력을 획기적으로 절감합니다.\n  통합 소셜 미디어 홍보: 생성된 블로그 글을 바탕으로 스레드, 인스타그램, 페이스북, X 등 각 플랫폼에 최적화된 홍보 문구를 자동으로 생성하여 효과적인 확산을 지원합니다.\n더 이상 블로그 운영에 시간을 낭비하지 마세요! 'GPT PARK 올인원 블로깅 프로'로 여러분의 블로그를 한 단계 업그레이드할 시간입니다.\n  GPT PARK 올인원 블로깅 BASIC 무료배포\n 아래 링크로 BASIC 버전 무료 배포합니다. 이 버전에는 키워드 파이터와 인간적인 글쓰기 기능이 포함되지 않았지만 일반적인 포스팅에는 이용에 문제가 없습니다. 모든 기능이 담긴 PRO 버전을 사용하시려면 제 유튜브 채널 멤버십에 가입하신 후 멤버십 전용 게시판에서 프로 버전 링크를 받으실 수 있습니다.\n\n\n\n \n로그인 - Google 계정\n이메일 또는 휴대전화\naccounts.google.com\n\n❓ 자주 묻는 질문 (FAQ)\nQ1: 'GPT PARK 올인원 블로깅 프로'는 어떤 블로그 플랫폼과 호환되나요?\nA1: 이 앱은 생성된 HTML 코드를 제공하므로, HTML 편집 기능을 지원하는 대부분의 블로그 플랫폼(예: 티스토리, 워드프레스 등)에서 활용할 수 있습니다. 이미지는 각 플랫폼에 직접 업로드해야 합니다.\nQ2: '인간적인 글쓰기' 유형 A와 B는 어떻게 다른가요?\nA2: 유형 A는 감정적 표현과 개인적인 경험을 담아 친근하고 대화하는 듯한 느낌을 줍니다. 반면 유형 B는 논리적인 구조와 다양한 어휘로 전문적이고 신뢰감 있는 톤으로 글을 작성합니다. 콘텐츠의 성격에 맞춰 선택하시면 됩니다.\nQ3: 네이버 검색 API 키 등록은 필수인가요?\nA3: '키워드 파이터' 탭의 모든 기능을 활용하려면 네이버 검색 API 키 등록이 필수입니다. 하지만 API 키 없이도 '주제 아이디어 얻기' 탭과 '포스트 생성하기' 탭의 기본적인 기능은 모두 사용할 수 있습니다.\nQ4: 'GPT PARK 올인원 블로깅 프로'의 베이직 버전과 프로 버전의 차이점은 무엇인가요?\nA4: 베이직 버전은 일반적인 포스팅에 필요한 핵심 기능을 제공하며, 프로 버전에는 '키워드 파이터'의 심층 분석 기능과 '인간적인 글쓰기' 옵션을 포함한 모든 고급 기능이 담겨 있습니다. 자세한 내용은 앱 공식 페이지를 참고해주세요.",
        "guid": "http://muzbox.tistory.com/483670",
        "categories": [
          "AI, 미래기술/AI 챗봇 및 지침 무료 배포",
          "AI Studio 앱 빌드",
          "ai 블로그 글쓰기",
          "E-E-A-T 주제 추천",
          "GPT PARK 올인원 블로깅 프로",
          "SEO 최적화 앱",
          "블로그 생산성 향상",
          "블로그 시간 단축",
          "블로그 콘텐츠 아이디어",
          "소셜 미디어 자동 홍보",
          "키워드 파이터"
        ],
        "isoDate": "2025-10-18T12:50:18.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "2025년, 구글을 넘어선 AI 지식 엔진: Perplexity가 당신의 검색을 혁신하는 5가지 방법",
        "link": "http://muzbox.tistory.com/483668",
        "pubDate": "Fri, 17 Oct 2025 15:39:42 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483668#entry483668comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #3c4043;\">\n<div style=\"background-color: #e8f4fd; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">오늘날 우리는 정보의 홍수 속에 살고 있죠. 그런데 검색 엔진이 단순히 '정보의 문'만 열어준다면 어떨까요? 2025년, Perplexity는 구글을 넘어선 '지식 엔진'으로서 검색의 패러다임을 완전히 바꾸고 있습니다. 단순한 검색을 넘어, 심층 연구부터 프로젝트 생성, AI 비서 역할까지! 이 글에서 Perplexity가 우리의 디지털 생활을 어떻게 혁신하는지 5가지 핵심 방법을 알려드릴게요.</div>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/btAoFP/dJMb9OtVsmJ/C4QCtFK68svwbAlGOGWnG1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/btAoFP/dJMb9OtVsmJ/C4QCtFK68svwbAlGOGWnG1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/btAoFP/dJMb9OtVsmJ/C4QCtFK68svwbAlGOGWnG1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbtAoFP%2FdJMb9OtVsmJ%2FC4QCtFK68svwbAlGOGWnG1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"2025년, 구글을 넘어선 AI 지식 엔진 퍼플렉시티의 미래 지향적인 디지털 인터페이스. 명확하고 인용된 답변, 프로젝트 생성, AI 비서, 코멧 브라우저 등 다양한 고급 기능을 시각적으로 상징합니다.\" loading=\"lazy\" width=\"600\" height=\"600\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>1. Perplexity는 구글과는 다릅니다: 단순 검색을 넘어선 '지식 엔진'  </b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">&nbsp;음, 많은 분들이 처음 Perplexity를 접할 때, 구글 검색의 좀 더 세련된 버전이라고 생각하는 경향이 있는 것 같아요. 저도 그랬으니까요. 물론 인터페이스가 깔끔하고 결과가 빠르게 나오니 그렇게 느낄 수 있죠. 하지만 사실 Perplexity는 구글과는 완전히 다른 방식으로 작동합니다. 단순히 검색 바를 넘어서는, 진정한 '지식 엔진'이라고 부르는 게 맞을 거예요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">구글에 뭔가를 검색하면, 보통 수많은 웹 페이지 링크와 함께 간략한 AI 요약이 뜨죠. 그다음부터는 사용자가 직접 링크를 클릭해서 정보를 찾아야 합니다. 구글이 관련도 높은 페이지를 상위에 배치하는 데는 꽤나 능숙하지만, 원하는 정보를 찾기 위해선 결국 스크롤을 한참 내리거나 여러 페이지를 오가는 수고가 필요합니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">그런데 Perplexity는 접근 방식 자체가 달라요. 질문을 던지면, 단순히 정보가 있을 만한 곳을 '가리키는' 데 그치지 않습니다. 대신, 웹의 수많은 출처를 직접 탐색하고, 정보를 읽어 들인 다음, 명확하고 간결하며 종종 신뢰할 수 있는 출처가 명시된 답변을 제공하죠. 마치 전담 연구원이 필요한 정보를 찾아서 핵심만 정리해주는 느낌이랄까요? 구글이 정보를 찾을 '문'을 보여준다면, Perplexity는 그 문을 열고 들어가 당신을 위해 필요한 모든 것을 정리해서 가져다주는 겁니다. 이게 정말 큰 차이에요.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1888\" data-origin-height=\"895\"><span data-url=\"https://blog.kakaocdn.net/dn/brzeAW/dJMb9eF5BCG/43jSfIrgdzIrBRXiNDkyE1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/brzeAW/dJMb9eF5BCG/43jSfIrgdzIrBRXiNDkyE1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/brzeAW/dJMb9eF5BCG/43jSfIrgdzIrBRXiNDkyE1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbrzeAW%2FdJMb9eF5BCG%2F43jSfIrgdzIrBRXiNDkyE1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"구글 검색 결과와 퍼플렉시티의 AI 답변 페이지를 비교하는 이미지. 구글은 링크 목록을, 퍼플렉시티는 정리된 답변을 보여줍니다.\" loading=\"lazy\" width=\"1888\" height=\"895\" data-origin-width=\"1888\" data-origin-height=\"895\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>2. 단순 검색을 넘어서는 무한한 가능성: 심층 연구부터 프로젝트 생성까지  </b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">Perplexity의 진가는 단순 답변 제공을 넘어서는 고급 기능들에서 빛을 발합니다. 저도 처음엔 그냥 궁금한 거 물어보는 용도로만 썼는데, 써보면 쓸수록 와, 이거 진짜 물건이다 싶더라고요. 몇 가지 핵심 기능을 소개해 드릴게요.</p>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>Pro Search (프로 검색)</b>: 일반 검색보다 훨씬 심층적인 답변을 제공합니다. 질의의 의도를 정확히 파악하고, 필요한 경우 추가 질문을 던져 사용자가 원하는 바를 명확히 이해한 뒤, 더욱 상세하고 포괄적인 답변을 내놓죠. 복잡한 학술 개념이나 특정 주제에 대한 깊은 이해가 필요할 때 정말 유용합니다.</div>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>Research 모드 (연구 모드)</b>: 특정 주제에 대해 가능한 모든 정보를 원한다면 이 모드를 꼭 활용해 보세요. 수많은 출처를 면밀히 검토하고 분석하여 상세한 보고서를 생성해줍니다. 때로는 100개가 넘는 출처를 읽어 들여 보고서를 만들어내는데, 이 과정을 사람이 직접 한다면 아마 수십 시간이 걸릴 거예요. 이 기능 덕분에 저도 자료 조사 시간을 정말 많이 줄였답니다.</div>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>Labs 모드 (랩스 모드)</b>: 여기서부터는 정말 '프로젝트' 수준의 작업이 가능해집니다. Perplexity가 찾아낸 정보를 바탕으로 전체 프로젝트를 구성할 수 있어요. 예를 들어, 차트가 포함된 보고서를 작성해야 할 때, 특정 데이터 포인트를 찾아주거나, 여러 출처에서 데이터를 수집하여 다양한 차트를 생성해주는 것을 넘어, 아예 차트를 직접 만들어주는 것도 가능합니다. 정말 놀랍지 않나요?</div>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">또한, Perplexity는 쇼핑 경험도 혁신하고 있습니다. 사진 한 장으로 제품을 쉽게 찾아주는 것은 기본이고, 'Buy with Pro' 기능을 사용하면 Perplexity 내에서 원클릭으로 결제하고 무료 배송까지 받을 수 있죠. 제가 써보니 정말 편리하더라고요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">그리고 2025년 현재, Perplexity는 무려 10개가 넘는 다양한 AI 모델을 선택하여 사용할 수 있게 지원합니다. Claude Sonnet, Gemini 2.5 Pro, GPT-5, 그리고 Grok 4와 같은 최신 모델들을 한자리에서 비교하며 최적의 답변을 얻을 수 있다는 건 정말 강력한 장점이라고 생각해요. 매번 다른 챗봇을 찾아 헤맬 필요 없이, Perplexity 하나로 충분합니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/biioH7/dJMb85bjqf2/mDpl9KkLeGh9AVJCF1wbk1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/biioH7/dJMb85bjqf2/mDpl9KkLeGh9AVJCF1wbk1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/biioH7/dJMb85bjqf2/mDpl9KkLeGh9AVJCF1wbk1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbiioH7%2FdJMb85bjqf2%2FmDpl9KkLeGh9AVJCF1wbk1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"다양한 데이터 차트와 보고서가 포함된 미래형 디지털 작업 공간 인터페이스. 퍼플렉시티의 연구 모드와 랩스 모드를 통한 복잡한 프로젝트 생성 능력을 시각적으로 표현합니다.\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>3. Perplexity Assistant, 당신의 스마트한 비서  </b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">Perplexity는 모바일에서도 빛을 발합니다. 안드로이드나 아이폰의 기본 AI 비서를 대체할 수 있는 Perplexity Assistant는 단순한 질의응답을 넘어섭니다. 제가 직접 사용해보니, 알람 설정, 미리 알림 생성, 택시 호출, 음악 재생 등 일상적인 작업을 대신 처리해주는 능력이 꽤나 인상 깊었어요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">특히 놀라운 점은 바로 멀티모달(multimodal) 기능입니다. 카메라를 이용한 이미지 입력이나 실시간 카메라 피드를 분석하여 객체를 식별하고 설명해줄 수 있어요. 예를 들어, 길을 가다 처음 보는 식물에 카메라를 가져다 대고 \"이게 뭐야?\"라고 물으면, Perplexity가 그 식물의 이름과 특징을 자세히 알려주는 식이죠. 자체적인 리서치 능력 덕분에 웬만한 질문에는 정확한 답변을 내놓더라고요. 물론 디바이스 통합 능력은 아직 기본 AI 비서에 비해 완벽하진 않지만, 정보 탐색과 분석에서는 독보적인 존재감을 드러냅니다.</p>\n<div style=\"background-color: #fce8e6; border-left: 4px solid #d93025; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">⚠️ <b>주의 사항</b>: Perplexity Assistant의 디바이스 연동 기능은 기본 AI 비서만큼 매끄럽지 않을 수 있습니다. 모든 앱과 서비스에 완벽하게 통합되지는 않으니, 특정 앱 연동 작업 시에는 한계가 있음을 인지하고 사용하는 것이 좋습니다.</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>4. Comet과 함께라면 검색 경험이 한 단계 업그레이드!  </b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">만약 Perplexity의 매력에 푹 빠지셨다면, Comet 브라우저를 한번 사용해보시길 정말 강력하게 추천해요. Comet은 Perplexity의 강력한 AI 기능이 핵심적으로 통합된 브라우저입니다. 솔직히 말씀드리자면, 저는 Comet을 써본 뒤로 크롬으로 돌아갈 수 없게 되었어요. 그만큼 빠르고 효율적이며, 검색 경험을 완전히 바꿔놓았거든요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">Comet의 가장 혁신적인 기능 중 하나는 바로 '에이전트 AI'입니다. 이 AI는 당신을 대신하여 작업을 수행할 수 있어요. 심지어 다른 탭에서 작업을 하거나 잠시 자리를 비워도 백그라운드에서 지시한 작업을 처리해줍니다. 예를 들어, 특정 정보를 지속적으로 모니터링하거나, 복잡한 양식을 자동으로 채우는 등, 번거로운 일들을 Comet에게 맡기고 당신은 더 중요한 일에 집중할 수 있게 되는 거죠. 일상적인 작업을 자동화하여 시간을 절약하는 데 엄청난 도움이 됩니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">또한 Comet은 '상황 인식 홈 페이지'를 제공합니다. 당신의 브라우징 패턴을 학습하고, 현재 진행 중인 작업에 따라 관련 콘텐츠를 제안하거나, 이전에 작업하던 내용을 상기시켜주고, 심지어 작업량에 기반한 정보를 띄워주기도 합니다. 요즘 많은 브라우저들이 홈 페이지의 이런 아이코닉한 기능을 포기하는 추세인데, Comet은 오히려 이를 진화시켜 사용자에게 훨씬 개인화되고 효율적인 경험을 제공합니다. 프라이버시 문제에 대한 우려도 있을 수 있지만, 제공하는 가치를 생각하면 충분히 고려해볼 만합니다.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"1918\" data-origin-height=\"1022\"><span data-url=\"https://blog.kakaocdn.net/dn/IKYfs/dJMb9YiV3iL/sa8XOFbm04IOxIuM52oPh0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/IKYfs/dJMb9YiV3iL/sa8XOFbm04IOxIuM52oPh0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/IKYfs/dJMb9YiV3iL/sa8XOFbm04IOxIuM52oPh0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FIKYfs%2FdJMb9YiV3iL%2Fsa8XOFbm04IOxIuM52oPh0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"퍼플렉시티 AI가 통합된 '코멧 브라우저'의 세련된 인터페이스. 개인화된 홈페이지와 백그라운드에서 실행되는 AI 작업들을 보여주며, 효율적인 웹 경험을 강조합니다.\" loading=\"lazy\" width=\"1918\" height=\"1022\" data-origin-width=\"1918\" data-origin-height=\"1022\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>5. Perplexity, 단순한 검색을 넘어선 진정한 지식 허브로  </b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">여러분은 아직도 Perplexity를 구글의 대안 정도로만 생각하고 계신가요? 제 생각엔 Perplexity는 단순한 검색 도구를 넘어, 진정한 '지식 허브'이자 'AI 기반 작업 자동화 도구'에 가깝다고 봅니다. 물론 Perplexity의 가장 유용한 기능들은 대부분 구독을 통해 이용할 수 있지만, Perplexity Pro 구독은 그 비용을 충분히 상회하는 가치를 제공한다고 확신해요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">AI 검색 도구가 기존의 구글 검색을 완전히 대체할 수 없는 몇 가지 이유가 있을 수 있지만, Perplexity Pro 구독을 최대한 활용한다면 구글 검색으로는 얻을 수 없는 훨씬 더 많은 것을 해낼 수 있습니다. 구글이 정보를 단순히 '제공'한다면, Perplexity는 그 정보를 '실행 가능한 형태로' 제시하거나, 심지어 당신을 대신해 특정 작업을 '수행'하는 수준까지 나아가니까요.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">한번 Perplexity의 놀라운 경험을 해보고 나면, 아마 다시 과거의 단순 검색 방식으로 돌아가기는 정말 어려울 거예요. 2025년, Perplexity는 우리에게 검색의 새로운 기준을 제시하고 있습니다.</p>\n<div style=\"background-color: #f8f9fa; border: 1px solid #dadce0; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); padding: 25px; margin: 40px 0;\">\n<div style=\"font-size: 26px; color: #1a73e8; border-bottom: 2px solid #1a73e8; padding-bottom: 10px; margin-bottom: 20px; font-weight: bold;\">  핵심 요약</div>\n<p style=\"margin-bottom: 15px; font-size: 17px;\" data-ke-size=\"size16\">1. 구글이 정보를 '안내'한다면, Perplexity는 수많은 출처를 분석하여 <b>정리된 답변</b>을 직접 제공합니다.</p>\n<p style=\"margin-bottom: 15px; font-size: 17px;\" data-ke-size=\"size16\">2. <b>Pro Search, Research 모드</b>로 심층적인 정보 탐색이, <b>Labs 모드</b>로는 데이터 시각화 및 프로젝트 생성이 가능합니다.</p>\n<p style=\"margin-bottom: 15px; font-size: 17px;\" data-ke-size=\"size16\">3. <b>Perplexity Assistant</b>는 모바일에서 AI 비서 역할을 수행하며, 이미지 분석을 통한 객체 식별까지 지원합니다.</p>\n<p style=\"margin-bottom: 0; font-size: 17px;\" data-ke-size=\"size16\">4. <b>Comet 브라우저</b>는 Perplexity AI를 내장하여 에이전트 AI 기반의 자동화된 웹 경험과 개인화된 홈 페이지를 제공합니다.</p>\n<div style=\"font-size: 14px; color: #5f6368; margin-top: 20px; padding-top: 10px; border-top: 1px solid #dadce0;\">이처럼 Perplexity는 단순 검색을 넘어 당신의 생산성과 지식 탐색 방식을 완전히 변화시킬 준비가 되어 있습니다.</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-bottom: 10px;\" data-ke-size=\"size23\">Q1: Perplexity와 Google 검색의 가장 큰 차이점은 무엇인가요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A: Google은 주로 웹 페이지 링크를 보여주는 반면, Perplexity는 여러 출처를 분석하여 요약되고 인용된 답변을 직접 제공합니다. 즉, 정보를 찾는 수고를 대신 해줍니다.</p>\n</div>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-bottom: 10px;\" data-ke-size=\"size23\">Q2: Perplexity Pro 구독은 어떤 이점이 있나요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A: Pro 구독 시 Pro Search, Research, Labs 모드와 같은 고급 기능, 다양한 AI 모델 선택, 그리고 Comet 브라우저와의 연동 등 훨씬 강력한 기능을 활용하여 생산성을 극대화할 수 있습니다.</p>\n</div>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-bottom: 10px;\" data-ke-size=\"size23\">Q3: Perplexity Assistant는 어떤 작업을 할 수 있나요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A: 알람 설정, 미리 알림, 택시 호출, 음악 재생 등 기본적인 비서 기능과 더불어 이미지 및 카메라 입력 분석을 통한 객체 식별 및 설명이 가능하여 일상과 지식 탐색을 돕습니다.</p>\n</div>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-bottom: 10px;\" data-ke-size=\"size23\">Q4: Comet 브라우저는 왜 특별한가요?</h3>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">A: Comet은 Perplexity AI가 내장된 브라우저로, 에이전트 AI가 백그라운드에서 작업을 자동화하고, 사용자의 브라우징 패턴을 학습하여 개인화된 경험을 제공하는 혁신적인 웹 브라우저입니다.</p>\n</div>\n</div>\n<script type=\"application/ld+json\">\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"Perplexity와 Google 검색의 가장 큰 차이점은 무엇인가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"Google은 주로 웹 페이지 링크를 보여주는 반면, Perplexity는 여러 출처를 분석하여 요약되고 인용된 답변을 직접 제공합니다. 즉, 정보를 찾는 수고를 대신 해줍니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"Perplexity Pro 구독은 어떤 이점이 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"Pro 구독 시 Pro Search, Research, Labs 모드와 같은 고급 기능, 다양한 AI 모델 선택, 그리고 Comet 브라우저와의 연동 등 훨씬 강력한 기능을 활용하여 생산성을 극대화할 수 있습니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"Perplexity Assistant는 어떤 작업을 할 수 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"알람 설정, 미리 알림, 택시 호출, 음악 재생 등 기본적인 비서 기능과 더불어 이미지 및 카메라 입력 분석을 통한 객체 식별 및 설명이 가능하여 일상과 지식 탐색을 돕습니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"Comet 브라우저는 왜 특별한가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"Comet은 Perplexity AI가 내장된 브라우저로, 에이전트 AI가 백그라운드에서 작업을 자동화하고, 사용자의 브라우징 패턴을 학습하여 개인화된 경험을 제공하는 혁신적인 웹 브라우저입니다.\"\n      }\n    }\n  ]\n}\n</script>",
        "contentSnippet": "오늘날 우리는 정보의 홍수 속에 살고 있죠. 그런데 검색 엔진이 단순히 '정보의 문'만 열어준다면 어떨까요? 2025년, Perplexity는 구글을 넘어선 '지식 엔진'으로서 검색의 패러다임을 완전히 바꾸고 있습니다. 단순한 검색을 넘어, 심층 연구부터 프로젝트 생성, AI 비서 역할까지! 이 글에서 Perplexity가 우리의 디지털 생활을 어떻게 혁신하는지 5가지 핵심 방법을 알려드릴게요.\n\n\n1. Perplexity는 구글과는 다릅니다: 단순 검색을 넘어선 '지식 엔진'  \n 음, 많은 분들이 처음 Perplexity를 접할 때, 구글 검색의 좀 더 세련된 버전이라고 생각하는 경향이 있는 것 같아요. 저도 그랬으니까요. 물론 인터페이스가 깔끔하고 결과가 빠르게 나오니 그렇게 느낄 수 있죠. 하지만 사실 Perplexity는 구글과는 완전히 다른 방식으로 작동합니다. 단순히 검색 바를 넘어서는, 진정한 '지식 엔진'이라고 부르는 게 맞을 거예요.\n구글에 뭔가를 검색하면, 보통 수많은 웹 페이지 링크와 함께 간략한 AI 요약이 뜨죠. 그다음부터는 사용자가 직접 링크를 클릭해서 정보를 찾아야 합니다. 구글이 관련도 높은 페이지를 상위에 배치하는 데는 꽤나 능숙하지만, 원하는 정보를 찾기 위해선 결국 스크롤을 한참 내리거나 여러 페이지를 오가는 수고가 필요합니다.\n그런데 Perplexity는 접근 방식 자체가 달라요. 질문을 던지면, 단순히 정보가 있을 만한 곳을 '가리키는' 데 그치지 않습니다. 대신, 웹의 수많은 출처를 직접 탐색하고, 정보를 읽어 들인 다음, 명확하고 간결하며 종종 신뢰할 수 있는 출처가 명시된 답변을 제공하죠. 마치 전담 연구원이 필요한 정보를 찾아서 핵심만 정리해주는 느낌이랄까요? 구글이 정보를 찾을 '문'을 보여준다면, Perplexity는 그 문을 열고 들어가 당신을 위해 필요한 모든 것을 정리해서 가져다주는 겁니다. 이게 정말 큰 차이에요.\n\n\n2. 단순 검색을 넘어서는 무한한 가능성: 심층 연구부터 프로젝트 생성까지  \nPerplexity의 진가는 단순 답변 제공을 넘어서는 고급 기능들에서 빛을 발합니다. 저도 처음엔 그냥 궁금한 거 물어보는 용도로만 썼는데, 써보면 쓸수록 와, 이거 진짜 물건이다 싶더라고요. 몇 가지 핵심 기능을 소개해 드릴게요.\n  Pro Search (프로 검색): 일반 검색보다 훨씬 심층적인 답변을 제공합니다. 질의의 의도를 정확히 파악하고, 필요한 경우 추가 질문을 던져 사용자가 원하는 바를 명확히 이해한 뒤, 더욱 상세하고 포괄적인 답변을 내놓죠. 복잡한 학술 개념이나 특정 주제에 대한 깊은 이해가 필요할 때 정말 유용합니다.\n  Research 모드 (연구 모드): 특정 주제에 대해 가능한 모든 정보를 원한다면 이 모드를 꼭 활용해 보세요. 수많은 출처를 면밀히 검토하고 분석하여 상세한 보고서를 생성해줍니다. 때로는 100개가 넘는 출처를 읽어 들여 보고서를 만들어내는데, 이 과정을 사람이 직접 한다면 아마 수십 시간이 걸릴 거예요. 이 기능 덕분에 저도 자료 조사 시간을 정말 많이 줄였답니다.\n  Labs 모드 (랩스 모드): 여기서부터는 정말 '프로젝트' 수준의 작업이 가능해집니다. Perplexity가 찾아낸 정보를 바탕으로 전체 프로젝트를 구성할 수 있어요. 예를 들어, 차트가 포함된 보고서를 작성해야 할 때, 특정 데이터 포인트를 찾아주거나, 여러 출처에서 데이터를 수집하여 다양한 차트를 생성해주는 것을 넘어, 아예 차트를 직접 만들어주는 것도 가능합니다. 정말 놀랍지 않나요?\n또한, Perplexity는 쇼핑 경험도 혁신하고 있습니다. 사진 한 장으로 제품을 쉽게 찾아주는 것은 기본이고, 'Buy with Pro' 기능을 사용하면 Perplexity 내에서 원클릭으로 결제하고 무료 배송까지 받을 수 있죠. 제가 써보니 정말 편리하더라고요.\n그리고 2025년 현재, Perplexity는 무려 10개가 넘는 다양한 AI 모델을 선택하여 사용할 수 있게 지원합니다. Claude Sonnet, Gemini 2.5 Pro, GPT-5, 그리고 Grok 4와 같은 최신 모델들을 한자리에서 비교하며 최적의 답변을 얻을 수 있다는 건 정말 강력한 장점이라고 생각해요. 매번 다른 챗봇을 찾아 헤맬 필요 없이, Perplexity 하나로 충분합니다.\n\n\n3. Perplexity Assistant, 당신의 스마트한 비서  \nPerplexity는 모바일에서도 빛을 발합니다. 안드로이드나 아이폰의 기본 AI 비서를 대체할 수 있는 Perplexity Assistant는 단순한 질의응답을 넘어섭니다. 제가 직접 사용해보니, 알람 설정, 미리 알림 생성, 택시 호출, 음악 재생 등 일상적인 작업을 대신 처리해주는 능력이 꽤나 인상 깊었어요.\n특히 놀라운 점은 바로 멀티모달(multimodal) 기능입니다. 카메라를 이용한 이미지 입력이나 실시간 카메라 피드를 분석하여 객체를 식별하고 설명해줄 수 있어요. 예를 들어, 길을 가다 처음 보는 식물에 카메라를 가져다 대고 \"이게 뭐야?\"라고 물으면, Perplexity가 그 식물의 이름과 특징을 자세히 알려주는 식이죠. 자체적인 리서치 능력 덕분에 웬만한 질문에는 정확한 답변을 내놓더라고요. 물론 디바이스 통합 능력은 아직 기본 AI 비서에 비해 완벽하진 않지만, 정보 탐색과 분석에서는 독보적인 존재감을 드러냅니다.\n⚠️ 주의 사항: Perplexity Assistant의 디바이스 연동 기능은 기본 AI 비서만큼 매끄럽지 않을 수 있습니다. 모든 앱과 서비스에 완벽하게 통합되지는 않으니, 특정 앱 연동 작업 시에는 한계가 있음을 인지하고 사용하는 것이 좋습니다.\n4. Comet과 함께라면 검색 경험이 한 단계 업그레이드!  \n만약 Perplexity의 매력에 푹 빠지셨다면, Comet 브라우저를 한번 사용해보시길 정말 강력하게 추천해요. Comet은 Perplexity의 강력한 AI 기능이 핵심적으로 통합된 브라우저입니다. 솔직히 말씀드리자면, 저는 Comet을 써본 뒤로 크롬으로 돌아갈 수 없게 되었어요. 그만큼 빠르고 효율적이며, 검색 경험을 완전히 바꿔놓았거든요.\nComet의 가장 혁신적인 기능 중 하나는 바로 '에이전트 AI'입니다. 이 AI는 당신을 대신하여 작업을 수행할 수 있어요. 심지어 다른 탭에서 작업을 하거나 잠시 자리를 비워도 백그라운드에서 지시한 작업을 처리해줍니다. 예를 들어, 특정 정보를 지속적으로 모니터링하거나, 복잡한 양식을 자동으로 채우는 등, 번거로운 일들을 Comet에게 맡기고 당신은 더 중요한 일에 집중할 수 있게 되는 거죠. 일상적인 작업을 자동화하여 시간을 절약하는 데 엄청난 도움이 됩니다.\n또한 Comet은 '상황 인식 홈 페이지'를 제공합니다. 당신의 브라우징 패턴을 학습하고, 현재 진행 중인 작업에 따라 관련 콘텐츠를 제안하거나, 이전에 작업하던 내용을 상기시켜주고, 심지어 작업량에 기반한 정보를 띄워주기도 합니다. 요즘 많은 브라우저들이 홈 페이지의 이런 아이코닉한 기능을 포기하는 추세인데, Comet은 오히려 이를 진화시켜 사용자에게 훨씬 개인화되고 효율적인 경험을 제공합니다. 프라이버시 문제에 대한 우려도 있을 수 있지만, 제공하는 가치를 생각하면 충분히 고려해볼 만합니다.\n\n\n5. Perplexity, 단순한 검색을 넘어선 진정한 지식 허브로  \n여러분은 아직도 Perplexity를 구글의 대안 정도로만 생각하고 계신가요? 제 생각엔 Perplexity는 단순한 검색 도구를 넘어, 진정한 '지식 허브'이자 'AI 기반 작업 자동화 도구'에 가깝다고 봅니다. 물론 Perplexity의 가장 유용한 기능들은 대부분 구독을 통해 이용할 수 있지만, Perplexity Pro 구독은 그 비용을 충분히 상회하는 가치를 제공한다고 확신해요.\nAI 검색 도구가 기존의 구글 검색을 완전히 대체할 수 없는 몇 가지 이유가 있을 수 있지만, Perplexity Pro 구독을 최대한 활용한다면 구글 검색으로는 얻을 수 없는 훨씬 더 많은 것을 해낼 수 있습니다. 구글이 정보를 단순히 '제공'한다면, Perplexity는 그 정보를 '실행 가능한 형태로' 제시하거나, 심지어 당신을 대신해 특정 작업을 '수행'하는 수준까지 나아가니까요.\n한번 Perplexity의 놀라운 경험을 해보고 나면, 아마 다시 과거의 단순 검색 방식으로 돌아가기는 정말 어려울 거예요. 2025년, Perplexity는 우리에게 검색의 새로운 기준을 제시하고 있습니다.\n  핵심 요약\n1. 구글이 정보를 '안내'한다면, Perplexity는 수많은 출처를 분석하여 정리된 답변을 직접 제공합니다.\n2. Pro Search, Research 모드로 심층적인 정보 탐색이, Labs 모드로는 데이터 시각화 및 프로젝트 생성이 가능합니다.\n3. Perplexity Assistant는 모바일에서 AI 비서 역할을 수행하며, 이미지 분석을 통한 객체 식별까지 지원합니다.\n4. Comet 브라우저는 Perplexity AI를 내장하여 에이전트 AI 기반의 자동화된 웹 경험과 개인화된 홈 페이지를 제공합니다.\n이처럼 Perplexity는 단순 검색을 넘어 당신의 생산성과 지식 탐색 방식을 완전히 변화시킬 준비가 되어 있습니다.\n❓ 자주 묻는 질문 (FAQ)\nQ1: Perplexity와 Google 검색의 가장 큰 차이점은 무엇인가요?\nA: Google은 주로 웹 페이지 링크를 보여주는 반면, Perplexity는 여러 출처를 분석하여 요약되고 인용된 답변을 직접 제공합니다. 즉, 정보를 찾는 수고를 대신 해줍니다.\nQ2: Perplexity Pro 구독은 어떤 이점이 있나요?\nA: Pro 구독 시 Pro Search, Research, Labs 모드와 같은 고급 기능, 다양한 AI 모델 선택, 그리고 Comet 브라우저와의 연동 등 훨씬 강력한 기능을 활용하여 생산성을 극대화할 수 있습니다.\nQ3: Perplexity Assistant는 어떤 작업을 할 수 있나요?\nA: 알람 설정, 미리 알림, 택시 호출, 음악 재생 등 기본적인 비서 기능과 더불어 이미지 및 카메라 입력 분석을 통한 객체 식별 및 설명이 가능하여 일상과 지식 탐색을 돕습니다.\nQ4: Comet 브라우저는 왜 특별한가요?\nA: Comet은 Perplexity AI가 내장된 브라우저로, 에이전트 AI가 백그라운드에서 작업을 자동화하고, 사용자의 브라우징 패턴을 학습하여 개인화된 경험을 제공하는 혁신적인 웹 브라우저입니다.\n\n\n\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"Perplexity와 Google 검색의 가장 큰 차이점은 무엇인가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"Google은 주로 웹 페이지 링크를 보여주는 반면, Perplexity는 여러 출처를 분석하여 요약되고 인용된 답변을 직접 제공합니다. 즉, 정보를 찾는 수고를 대신 해줍니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"Perplexity Pro 구독은 어떤 이점이 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"Pro 구독 시 Pro Search, Research, Labs 모드와 같은 고급 기능, 다양한 AI 모델 선택, 그리고 Comet 브라우저와의 연동 등 훨씬 강력한 기능을 활용하여 생산성을 극대화할 수 있습니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"Perplexity Assistant는 어떤 작업을 할 수 있나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"알람 설정, 미리 알림, 택시 호출, 음악 재생 등 기본적인 비서 기능과 더불어 이미지 및 카메라 입력 분석을 통한 객체 식별 및 설명이 가능하여 일상과 지식 탐색을 돕습니다.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"Comet 브라우저는 왜 특별한가요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"Comet은 Perplexity AI가 내장된 브라우저로, 에이전트 AI가 백그라운드에서 작업을 자동화하고, 사용자의 브라우징 패턴을 학습하여 개인화된 경험을 제공하는 혁신적인 웹 브라우저입니다.\"\n      }\n    }\n  ]\n}",
        "guid": "http://muzbox.tistory.com/483668",
        "categories": [
          "AI, 미래기술/AI 인사이트",
          "ai 검색 혁신",
          "AI 기술 2025",
          "AI 비서",
          "AI 지식 엔진",
          "AI 프로젝트 생성",
          "Comet 브라우저",
          "perplexity",
          "구글 대안",
          "생산성 향상",
          "심층 연구 AI"
        ],
        "isoDate": "2025-10-17T06:39:42.000Z"
      },
      {
        "creator": "어떤오후의 프리웨어 이야기",
        "title": "노트북 배터리 수명, 당신도 모르게 갉아먹는 치명적인 습관 5가지",
        "link": "http://muzbox.tistory.com/483667",
        "pubDate": "Thu, 16 Oct 2025 19:36:21 +0900",
        "author": "어떤오후의 프리웨어 이야기",
        "comments": "http://muzbox.tistory.com/483667#entry483667comment",
        "content": "<div style=\"font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; font-size: 16px; box-sizing: border-box; color: #3c4043;\">\n<div style=\"background-color: #e8f4fd; padding: 15px; border-radius: 8px; font-style: italic; margin-bottom: 25px; font-size: 15px;\">&nbsp;휴대성의 상징인 노트북, 그런데 배터리 때문에 늘 충전기에 묶여 있다면 정말 아쉽죠. 2025년 최신 정보에 따르면, 우리가 무심코 하는 작은 습관들이 노트북 배터리 수명을 야금야금 갉아먹는 주범이라고 해요. 배터리는 소모품이지만, 올바른 관리 습관으로 그 수명을 획기적으로 늘릴 수 있답니다. 오늘 이 글에서는 배터리 수명을 단축시키는 치명적인 습관 5가지와 함께, 간단하지만 효과적인 해결책들을 자세히 알려드릴게요. 이제는 배터리 걱정 없이 노트북을 자유롭게 사용해 보세요!</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>첫 번째 습관:   항상 충전기에 꽂아두기</b></h2>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"><span data-url=\"https://blog.kakaocdn.net/dn/bU9bcl/dJMb9j1HoBd/3XPNsDDZagL2GvVDrDKd4k/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bU9bcl/dJMb9j1HoBd/3XPNsDDZagL2GvVDrDKd4k/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bU9bcl/dJMb9j1HoBd/3XPNsDDZagL2GvVDrDKd4k/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbU9bcl%2FdJMb9j1HoBd%2F3XPNsDDZagL2GvVDrDKd4k%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"배터리 수명을 갉아먹는 나쁜 습관들과 올바른 관리 습관을 시각적으로 대비한 노트북 이미지\" loading=\"lazy\" width=\"600\" height=\"600\" data-filename=\"download.jpg\" data-origin-width=\"1200\" data-origin-height=\"1200\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\"><br />사무실이나 집에서 노트북을 주로 사용하는 분들은 늘 충전기를 꽂아두는 경우가 많을 거예요. 편리하니까요! 그런데 이 사소한 습관이 리튬 이온 배터리의 수명에는 의외로 치명적일 수 있습니다. 리튬 이온 배터리는 충전과 방전을 적절히 반복하며 활성 상태를 유지할 때 가장 건강하다고 해요. 계속 100% 충전 상태로 유지하면 배터리 내부의 화학 반응이 불필요하게 가속화되어 수명이 단축될 수 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">스마트폰처럼 노트북도 80% 정도까지만 충전하고, 20%~30% 이하로 떨어지면 다시 충전하는 것이 배터리 건강에 훨씬 이롭습니다. 윈도우 자체에는 충전 상한을 설정하는 기능이 없지만, 다행히 많은 노트북 제조사(삼성, LG, HP, Dell 등)에서 배터리 보호 기능을 제공하고 있어요. 저 역시 제 노트북의 전용 소프트웨어를 통해 충전 상한을 80%로 설정해두고 사용하고 있답니다. 이 기능은 배터리 과충전을 막아줘서 수명 연장에 정말 큰 도움이 돼요.</p>\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>팁:</b> 여러분의 노트북 제조사 웹사이트나 제어판 설정에서 '배터리 관리' 또는 '전원 관리' 소프트웨어가 있는지 확인해보세요. 대부분의 경우 배터리 충전 임계값을 설정할 수 있는 옵션을 제공합니다.</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>두 번째 습관:   배터리를 0%까지 완전히 방전시키기</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">충전기에 계속 꽂아두는 것만큼이나 좋지 않은 습관이 바로 배터리를 0%까지 완전히 방전시키는 것입니다. '완전 방전'은 배터리에게 가장 큰 스트레스를 주는 행위 중 하나라고 생각해요. 0%까지 내려가면 배터리 내부의 전해액에 좋지 않은 변화가 생기면서, 충전 용량이 점차 줄어들고 결국에는 배터리 자체의 고장을 유발할 수도 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">제가 겪어본 바로는, 배터리를 20%~30% 정도 남았을 때 충전하기 시작하는 것이 가장 이상적이에요. 그리고 충전은 80%까지만 하는 '20-80 규칙'을 지키는 것이 리튬 이온 배터리의 수명을 최대한으로 늘리는 비결입니다. 이 범위 안에서 배터리를 관리하면 내부 이온들이 안정적으로 작동하여 배터리 수명 저하를 최소화할 수 있습니다. 마치 사람도 너무 배고프게 두거나 너무 배부르게 두지 않는 것과 비슷하죠!</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/qvrJ5/dJMb9Nu0I8R/45bqdMVc1ON3zsAGrkdJk0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/qvrJ5/dJMb9Nu0I8R/45bqdMVc1ON3zsAGrkdJk0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/qvrJ5/dJMb9Nu0I8R/45bqdMVc1ON3zsAGrkdJk0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FqvrJ5%2FdJMb9Nu0I8R%2F45bqdMVc1ON3zsAGrkdJk0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"노트북 배터리의 건강한 충전 범위 20-80%를 시각적으로 보여주는 일러스트\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>세 번째 습관:   노트북을 뜨겁게 방치하기</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">노트북이 가끔 뜨거워지는 건 자연스러운 현상이지만, 장시간 높은 온도에 노출되는 것은 배터리에게 정말 최악의 환경을 제공합니다. 고열은 배터리 내부의 화학 반응을 가속화시켜 배터리 열화를 빠르게 진행시키는 주범이죠. 배터리뿐만 아니라 노트북의 다른 중요한 부품들에도 좋지 않은 영향을 미치고요.</p>\n<h3 style=\"font-size: 19px; color: #1a73e8; margin: 25px 0 10px;\" data-ke-size=\"size23\">무엇이 노트북을 뜨겁게 만들까요?</h3>\n<ul style=\"list-style-type: disc; margin-left: 20px; margin-bottom: 20px; color: #3c4043;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 8px;\"><b>고사양 작업:</b> 고사양 게임, 긴 영상 편집, 여러 개의 리소스 소모가 큰 앱을 동시에 실행하는 것은 CPU와 GPU에 부담을 주어 발열을 일으킵니다.</li>\n<li style=\"margin-bottom: 8px;\"><b>부적절한 사용 환경:</b> 침대 이불, 소파, 베개 같은 푹신한 표면에 노트북을 올려놓고 사용하면 통풍구를 막아 열이 갇히게 됩니다. 이건 정말 많은 분들이 놓치기 쉬운 습관이에요.</li>\n<li style=\"margin-bottom: 8px;\"><b>먼지 쌓인 통풍구:</b> 노트북 내부의 통풍구에 먼지가 쌓이면 공기 흐름을 방해하여 냉각 효율을 떨어뜨립니다.</li>\n</ul>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">과열은 단순히 배터리 수명만 줄이는 것이 아닙니다. 노트북 성능 저하, 팬 소음 증가, 그리고 심한 경우 내부 부품 손상까지 일으킬 수 있으니 정말 주의해야 합니다. 제 경우에도 예전에 침대에서 노트북을 자주 쓰다가 팬 소음이 심해지고 발열이 심해져서 결국 쿨링 패드를 구매했었어요. 확실히 효과가 있더라고요.</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/HBFaz/dJMb9Nu0I8Y/RDvnILKX3eSeVJVMfu8LbK/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/HBFaz/dJMb9Nu0I8Y/RDvnILKX3eSeVJVMfu8LbK/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/HBFaz/dJMb9Nu0I8Y/RDvnILKX3eSeVJVMfu8LbK/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FHBFaz%2FdJMb9Nu0I8Y%2FRDvnILKX3eSeVJVMfu8LbK%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"침대 위 과열된 노트북과 쿨링 패드로 시원하게 관리되는 노트북의 대비 이미지\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<div style=\"background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">  <b>해결책:</b>\n<ul style=\"list-style-type: circle; margin-left: 15px; margin-top: 10px; color: #3c4043;\" data-ke-list-type=\"disc\">\n<li style=\"margin-bottom: 5px;\">노트북이 뜨거워지면 잠시 식혀주는 시간을 가지세요.</li>\n<li style=\"margin-bottom: 5px;\">항상 단단하고 평평한 표면에서 사용하여 통풍이 원활하게 이루어지도록 합니다.</li>\n<li style=\"margin-bottom: 5px;\">고사양 작업을 자주 한다면 노트북 쿨링 패드를 사용하는 것이 현명한 투자입니다.</li>\n<li style=\"margin-bottom: 5px;\">정기적으로 에어스프레이 등으로 통풍구와 팬 주변의 먼지를 제거해주세요.</li>\n</ul>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>네 번째 습관: ⚡ 정품이 아닌 충전기 사용하기</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">스마트폰과는 다르게 대부분의 노트북은 구매 시 전용 충전기가 함께 제공됩니다. 그런데 만약 충전기를 잃어버리거나 고장 났을 때, 아무 충전기나 주워다 쓰는 경우가 생각보다 많더라고요. 단순히 포트만 맞으면 괜찮다고 생각할 수 있지만, 이는 배터리뿐만 아니라 노트북 전체에 위험을 초래할 수 있는 아주 중요한 문제입니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">노트북 모델마다 필요한 전력량(W)이 다릅니다. 이 전력 요구사항을 충족시키지 못하는 충전기를 사용하면 노트북이 충분한 전력을 공급받지 못해 시스템이 과부하될 수 있고, 반대로 너무 높은 전력을 공급하는 충전기는 과열을 유발하여 배터리에 스트레스를 줍니다. 둘 다 배터리 수명을 단축시키고, 심지어는 노트북의 내부 부품까지 손상시킬 수 있는 잠재적 위험을 가지고 있습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">제 생각에는 항상 노트북과 함께 제공된 정품 충전기를 사용하는 것이 가장 안전합니다. 만약 새 충전기가 필요하다면, 반드시 노트북 제조사의 공식 충전기나 해당 모델 전용으로 검증된 신뢰할 수 있는 브랜드의 제품을 구매해야 해요. 값싼 호환 충전기는 당장은 문제가 없어 보여도 장기적으로는 더 큰 비용을 초래할 수 있다는 점을 꼭 기억해주세요.</p>\n<div style=\"background-color: #fce8e6; border-left: 4px solid #d93025; padding: 15px; margin: 20px 0; border-radius: 0 8px 8px 0;\">⚠️ <b>주의:</b> 규격에 맞지 않는 저품질 충전기는 화재나 감전 위험까지 있을 수 있습니다. 안전을 위해서라도 정품 또는 검증된 제품을 사용하세요.</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>다섯 번째 습관:   배터리가 방전된 상태로 장기간 보관하기</b></h2>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">노트북을 며칠 혹은 몇 주 동안 사용하지 않고 보관할 계획이라면, 배터리를 완전히 방전된 상태로 두는 것이 가장 좋지 않습니다. 리튬 이온 배터리가 0% 상태로 너무 오래 방치되면 '과방전 상태(deep discharge state)'에 빠질 수 있습니다. 이 상태가 되면 배터리가 아예 충전 능력을 잃어버리거나, 심지어 재활성화가 불가능해질 수도 있어요. 경험상 한 번 과방전된 배터리는 원래 성능으로 돌아오기 정말 어렵습니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">노트북을 장기간 보관할 때 가장 건강한 방법은 배터리를 부분적으로 충전한 상태로 두는 것입니다. 일반적으로 50% 정도의 충전율이 가장 '이상적인 보관 상태'로 여겨집니다. 이 정도 충전 상태는 배터리가 안정적으로 유지될 수 있는 충분한 전력을 가지고 있으면서도, 너무 높거나 낮은 극단적인 상태로 인한 스트레스를 피할 수 있게 해줍니다.</p>\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">그러니 여행을 가거나 당분간 노트북을 사용하지 않을 예정이라면, 떠나기 전에 꼭 배터리를</p>\n<figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"><span data-url=\"https://blog.kakaocdn.net/dn/cWUbt5/dJMb9OtVd9R/kvJK0XDVYB2KnWPwFqlHf0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/cWUbt5/dJMb9OtVd9R/kvJK0XDVYB2KnWPwFqlHf0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/cWUbt5/dJMb9OtVd9R/kvJK0XDVYB2KnWPwFqlHf0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcWUbt5%2FdJMb9OtVd9R%2FkvJK0XDVYB2KnWPwFqlHf0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" alt=\"배터리가 방전된 채 방치된 노트북과 50% 충전 상태로 보관된 노트북의 대비 이미지\" loading=\"lazy\" width=\"1408\" height=\"768\" data-filename=\"download.jpg\" data-origin-width=\"1408\" data-origin-height=\"768\"/></span></figure>\n\n<p style=\"margin-bottom: 20px;\" data-ke-size=\"size16\">50% 수준으로 맞춰두는 습관을 들이세요. 이 작은 노력이 여러분의 배터리 수명을 놀랍도록 연장시켜 줄 겁니다.</p>\n<div style=\"background-color: #f8f9fa; border: 1px solid #dadce0; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); padding: 25px; margin-top: 40px; margin-bottom: 40px;\">\n<div style=\"font-size: 26px; color: #1a73e8; font-weight: bold; margin-bottom: 15px; padding-bottom: 10px; border-bottom: 2px solid #1a73e8;\">  핵심 요약</div>\n<p style=\"font-size: 17px; margin-bottom: 15px;\" data-ke-size=\"size16\">1. <b>항상 충전하지 마세요:</b> 80%까지만 충전하고, 배터리 보호 기능을 활용하세요.</p>\n<p style=\"font-size: 17px; margin-bottom: 15px;\" data-ke-size=\"size16\">2. <b>완전 방전은 피하세요:</b> 20~30%에서 충전을 시작하는 것이 좋습니다.</p>\n<p style=\"font-size: 17px; margin-bottom: 15px;\" data-ke-size=\"size16\">3. <b>과열을 막으세요:</b> 평평한 곳에서 사용하고, 필요하다면 쿨링 패드를 사용하세요.</p>\n<p style=\"font-size: 17px; margin-bottom: 0;\" data-ke-size=\"size16\">4. <b>정품 충전기를 사용하세요:</b> 규격에 맞는 충전기는 배터리 건강과 안전의 필수입니다.</p>\n<div style=\"font-size: 14px; color: #5f6368; margin-top: 20px; padding-top: 15px; border-top: 1px solid #dadce0;\">이 작은 습관들이 여러분의 노트북 배터리 수명을 2025년에도 최상으로 유지하는 비결이 될 거예요!</div>\n</div>\n<h2 style=\"font-size: 22px; color: white; background: linear-gradient(to right, #1a73e8, #004d99); margin: 30px 0 15px; border-radius: 10px; padding: 10px 25px; text-shadow: 1px 1px 2px rgba(0,0,0,0.2); font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\" data-ke-size=\"size26\"><b>❓ 자주 묻는 질문 (FAQ)</b></h2>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-bottom: 10px;\" data-ke-size=\"size23\">Q1: 노트북 배터리 수명은 평균적으로 얼마나 되나요?</h3>\n<p style=\"margin-bottom: 10px;\" data-ke-size=\"size16\">A1: 일반적으로 리튬 이온 배터리는 약 300~500회 충전 사이클 후에 초기 용량의 80% 수준으로 감소하기 시작합니다. 사용 습관에 따라 다르지만, 보통 2~4년 정도가 평균적인 수명으로 볼 수 있습니다. 위에 언급된 습관들을 잘 지키면 더 오래 건강하게 사용할 수 있어요.</p>\n</div>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-bottom: 10px;\" data-ke-size=\"size23\">Q2: 배터리 잔량 표기가 갑자기 이상해졌는데 어떻게 해야 하나요?</h3>\n<p style=\"margin-bottom: 10px;\" data-ke-size=\"size16\">A2: 배터리 잔량 표기가 부정확해지는 현상은 흔히 '배터리 캘리브레이션'이 필요하다는 신호일 수 있습니다. 노트북 제조사에서 제공하는 배터리 관리 프로그램을 사용하거나, 완전 충전(100%) 후 노트북이 꺼질 때까지 완전 방전(0%)을 한두 번 반복하여 배터리 컨트롤러를 재조정해 볼 수 있습니다. 단, 이 방법은 배터리에 스트레스를 줄 수 있으므로 너무 자주 하지는 마세요.</p>\n</div>\n<div style=\"margin-bottom: 20px;\">\n<h3 style=\"font-size: 18px; color: #1a73e8; margin-bottom: 10px;\" data-ke-size=\"size23\">Q3: 노트북을 장시간 사용하지 않을 때 배터리를 분리해야 하나요?</h3>\n<p style=\"margin-bottom: 10px;\" data-ke-size=\"size16\">A3: 최신 노트북의 리튬 이온 배터리는 보통 분리가 불가능하거나, 분리할 필요가 없습니다. 대부분의 노트북은 배터리 보호 회로가 내장되어 있어 과충전이나 과방전을 자동으로 방지해주기 때문입니다. 다만, 보관 시에는 위에서 언급했듯이 50% 정도 충전 상태를 유지하는 것이 좋습니다. 배터리 분리가 가능한 구형 노트북이라면 50% 충전 후 분리하여 서늘한 곳에 보관하는 것이 좋습니다.</p>\n</div>\n<script type=\"application/ld+json\">\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"노트북 배터리 수명은 평균적으로 얼마나 되나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"일반적으로 리튬 이온 배터리는 약 300~500회 충전 사이클 후에 초기 용량의 80% 수준으로 감소하기 시작합니다. 사용 습관에 따라 다르지만, 보통 2~4년 정도가 평균적인 수명으로 볼 수 있습니다. 위에 언급된 습관들을 잘 지키면 더 오래 건강하게 사용할 수 있어요.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"배터리 잔량 표기가 갑자기 이상해졌는데 어떻게 해야 하나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"배터리 잔량 표기가 부정확해지는 현상은 흔히 '배터리 캘리브레이션'이 필요하다는 신호일 수 있습니다. 노트북 제조사에서 제공하는 배터리 관리 프로그램을 사용하거나, 완전 충전(100%) 후 노트북이 꺼질 때까지 완전 방전(0%)을 한두 번 반복하여 배터리 컨트롤러를 재조정해 볼 수 있습니다. 단, 이 방법은 배터리에 스트레스를 줄 수 있으므로 너무 자주 하지는 마세요.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"노트북을 장시간 사용하지 않을 때 배터리를 분리해야 하나요?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"최신 노트북의 리튬 이온 배터리는 보통 분리가 불가능하거나, 분리할 필요가 없습니다. 대부분의 노트북은 배터리 보호 회로가 내장되어 있어 과충전이나 과방전을 자동으로 방지해주기 때문입니다. 다만, 보관 시에는 위에서 언급했듯이 50% 정도 충전 상태를 유지하는 것이 좋습니다. 배터리 분리가 가능한 구형 노트북이라면 50% 충전 후 분리하여 서늘한 곳에 보관하는 것이 좋습니다.\"\n      }\n    }\n  ]\n}\n</script>\n<p style=\"margin-bottom: 20px; margin-top: 30px; text-align: center; font-weight: bold; color: #1a73e8; font-size: 18px;\" data-ke-size=\"size16\">오늘 알려드린 5가지 습관만 고쳐도 여러분의 노트북 배터리는 훨씬 더 오래, 건강하게 함께할 수 있을 거예요!  </p>\n</div>",
        "contentSnippet": "휴대성의 상징인 노트북, 그런데 배터리 때문에 늘 충전기에 묶여 있다면 정말 아쉽죠. 2025년 최신 정보에 따르면, 우리가 무심코 하는 작은 습관들이 노트북 배터리 수명을 야금야금 갉아먹는 주범이라고 해요. 배터리는 소모품이지만, 올바른 관리 습관으로 그 수명을 획기적으로 늘릴 수 있답니다. 오늘 이 글에서는 배터리 수명을 단축시키는 치명적인 습관 5가지와 함께, 간단하지만 효과적인 해결책들을 자세히 알려드릴게요. 이제는 배터리 걱정 없이 노트북을 자유롭게 사용해 보세요!\n첫 번째 습관:   항상 충전기에 꽂아두기\n\n\n\n사무실이나 집에서 노트북을 주로 사용하는 분들은 늘 충전기를 꽂아두는 경우가 많을 거예요. 편리하니까요! 그런데 이 사소한 습관이 리튬 이온 배터리의 수명에는 의외로 치명적일 수 있습니다. 리튬 이온 배터리는 충전과 방전을 적절히 반복하며 활성 상태를 유지할 때 가장 건강하다고 해요. 계속 100% 충전 상태로 유지하면 배터리 내부의 화학 반응이 불필요하게 가속화되어 수명이 단축될 수 있습니다.\n스마트폰처럼 노트북도 80% 정도까지만 충전하고, 20%~30% 이하로 떨어지면 다시 충전하는 것이 배터리 건강에 훨씬 이롭습니다. 윈도우 자체에는 충전 상한을 설정하는 기능이 없지만, 다행히 많은 노트북 제조사(삼성, LG, HP, Dell 등)에서 배터리 보호 기능을 제공하고 있어요. 저 역시 제 노트북의 전용 소프트웨어를 통해 충전 상한을 80%로 설정해두고 사용하고 있답니다. 이 기능은 배터리 과충전을 막아줘서 수명 연장에 정말 큰 도움이 돼요.\n  팁: 여러분의 노트북 제조사 웹사이트나 제어판 설정에서 '배터리 관리' 또는 '전원 관리' 소프트웨어가 있는지 확인해보세요. 대부분의 경우 배터리 충전 임계값을 설정할 수 있는 옵션을 제공합니다.\n두 번째 습관:   배터리를 0%까지 완전히 방전시키기\n충전기에 계속 꽂아두는 것만큼이나 좋지 않은 습관이 바로 배터리를 0%까지 완전히 방전시키는 것입니다. '완전 방전'은 배터리에게 가장 큰 스트레스를 주는 행위 중 하나라고 생각해요. 0%까지 내려가면 배터리 내부의 전해액에 좋지 않은 변화가 생기면서, 충전 용량이 점차 줄어들고 결국에는 배터리 자체의 고장을 유발할 수도 있습니다.\n제가 겪어본 바로는, 배터리를 20%~30% 정도 남았을 때 충전하기 시작하는 것이 가장 이상적이에요. 그리고 충전은 80%까지만 하는 '20-80 규칙'을 지키는 것이 리튬 이온 배터리의 수명을 최대한으로 늘리는 비결입니다. 이 범위 안에서 배터리를 관리하면 내부 이온들이 안정적으로 작동하여 배터리 수명 저하를 최소화할 수 있습니다. 마치 사람도 너무 배고프게 두거나 너무 배부르게 두지 않는 것과 비슷하죠!\n\n\n세 번째 습관:   노트북을 뜨겁게 방치하기\n노트북이 가끔 뜨거워지는 건 자연스러운 현상이지만, 장시간 높은 온도에 노출되는 것은 배터리에게 정말 최악의 환경을 제공합니다. 고열은 배터리 내부의 화학 반응을 가속화시켜 배터리 열화를 빠르게 진행시키는 주범이죠. 배터리뿐만 아니라 노트북의 다른 중요한 부품들에도 좋지 않은 영향을 미치고요.\n무엇이 노트북을 뜨겁게 만들까요?\n고사양 작업: 고사양 게임, 긴 영상 편집, 여러 개의 리소스 소모가 큰 앱을 동시에 실행하는 것은 CPU와 GPU에 부담을 주어 발열을 일으킵니다.\n부적절한 사용 환경: 침대 이불, 소파, 베개 같은 푹신한 표면에 노트북을 올려놓고 사용하면 통풍구를 막아 열이 갇히게 됩니다. 이건 정말 많은 분들이 놓치기 쉬운 습관이에요.\n먼지 쌓인 통풍구: 노트북 내부의 통풍구에 먼지가 쌓이면 공기 흐름을 방해하여 냉각 효율을 떨어뜨립니다.\n과열은 단순히 배터리 수명만 줄이는 것이 아닙니다. 노트북 성능 저하, 팬 소음 증가, 그리고 심한 경우 내부 부품 손상까지 일으킬 수 있으니 정말 주의해야 합니다. 제 경우에도 예전에 침대에서 노트북을 자주 쓰다가 팬 소음이 심해지고 발열이 심해져서 결국 쿨링 패드를 구매했었어요. 확실히 효과가 있더라고요.\n\n\n  해결책:\n\n노트북이 뜨거워지면 잠시 식혀주는 시간을 가지세요.\n항상 단단하고 평평한 표면에서 사용하여 통풍이 원활하게 이루어지도록 합니다.\n고사양 작업을 자주 한다면 노트북 쿨링 패드를 사용하는 것이 현명한 투자입니다.\n정기적으로 에어스프레이 등으로 통풍구와 팬 주변의 먼지를 제거해주세요.\n네 번째 습관: ⚡ 정품이 아닌 충전기 사용하기\n스마트폰과는 다르게 대부분의 노트북은 구매 시 전용 충전기가 함께 제공됩니다. 그런데 만약 충전기를 잃어버리거나 고장 났을 때, 아무 충전기나 주워다 쓰는 경우가 생각보다 많더라고요. 단순히 포트만 맞으면 괜찮다고 생각할 수 있지만, 이는 배터리뿐만 아니라 노트북 전체에 위험을 초래할 수 있는 아주 중요한 문제입니다.\n노트북 모델마다 필요한 전력량(W)이 다릅니다. 이 전력 요구사항을 충족시키지 못하는 충전기를 사용하면 노트북이 충분한 전력을 공급받지 못해 시스템이 과부하될 수 있고, 반대로 너무 높은 전력을 공급하는 충전기는 과열을 유발하여 배터리에 스트레스를 줍니다. 둘 다 배터리 수명을 단축시키고, 심지어는 노트북의 내부 부품까지 손상시킬 수 있는 잠재적 위험을 가지고 있습니다.\n제 생각에는 항상 노트북과 함께 제공된 정품 충전기를 사용하는 것이 가장 안전합니다. 만약 새 충전기가 필요하다면, 반드시 노트북 제조사의 공식 충전기나 해당 모델 전용으로 검증된 신뢰할 수 있는 브랜드의 제품을 구매해야 해요. 값싼 호환 충전기는 당장은 문제가 없어 보여도 장기적으로는 더 큰 비용을 초래할 수 있다는 점을 꼭 기억해주세요.\n⚠️ 주의: 규격에 맞지 않는 저품질 충전기는 화재나 감전 위험까지 있을 수 있습니다. 안전을 위해서라도 정품 또는 검증된 제품을 사용하세요.\n다섯 번째 습관:   배터리가 방전된 상태로 장기간 보관하기\n노트북을 며칠 혹은 몇 주 동안 사용하지 않고 보관할 계획이라면, 배터리를 완전히 방전된 상태로 두는 것이 가장 좋지 않습니다. 리튬 이온 배터리가 0% 상태로 너무 오래 방치되면 '과방전 상태(deep discharge state)'에 빠질 수 있습니다. 이 상태가 되면 배터리가 아예 충전 능력을 잃어버리거나, 심지어 재활성화가 불가능해질 수도 있어요. 경험상 한 번 과방전된 배터리는 원래 성능으로 돌아오기 정말 어렵습니다.\n노트북을 장기간 보관할 때 가장 건강한 방법은 배터리를 부분적으로 충전한 상태로 두는 것입니다. 일반적으로 50% 정도의 충전율이 가장 '이상적인 보관 상태'로 여겨집니다. 이 정도 충전 상태는 배터리가 안정적으로 유지될 수 있는 충분한 전력을 가지고 있으면서도, 너무 높거나 낮은 극단적인 상태로 인한 스트레스를 피할 수 있게 해줍니다.\n그러니 여행을 가거나 당분간 노트북을 사용하지 않을 예정이라면, 떠나기 전에 꼭 배터리를\n\n\n50% 수준으로 맞춰두는 습관을 들이세요. 이 작은 노력이 여러분의 배터리 수명을 놀랍도록 연장시켜 줄 겁니다.\n  핵심 요약\n1. 항상 충전하지 마세요: 80%까지만 충전하고, 배터리 보호 기능을 활용하세요.\n2. 완전 방전은 피하세요: 20~30%에서 충전을 시작하는 것이 좋습니다.\n3. 과열을 막으세요: 평평한 곳에서 사용하고, 필요하다면 쿨링 패드를 사용하세요.\n4. 정품 충전기를 사용하세요: 규격에 맞는 충전기는 배터리 건강과 안전의 필수입니다.\n이 작은 습관들이 여러분의 노트북 배터리 수명을 2025년에도 최상으로 유지하는 비결이 될 거예요!\n❓ 자주 묻는 질문 (FAQ)\nQ1: 노트북 배터리 수명은 평균적으로 얼마나 되나요?\nA1: 일반적으로 리튬 이온 배터리는 약 300~500회 충전 사이클 후에 초기 용량의 80% 수준으로 감소하기 시작합니다. 사용 습관에 따라 다르지만, 보통 2~4년 정도가 평균적인 수명으로 볼 수 있습니다. 위에 언급된 습관들을 잘 지키면 더 오래 건강하게 사용할 수 있어요.\nQ2: 배터리 잔량 표기가 갑자기 이상해졌는데 어떻게 해야 하나요?\nA2: 배터리 잔량 표기가 부정확해지는 현상은 흔히 '배터리 캘리브레이션'이 필요하다는 신호일 수 있습니다. 노트북 제조사에서 제공하는 배터리 관리 프로그램을 사용하거나, 완전 충전(100%) 후 노트북이 꺼질 때까지 완전 방전(0%)을 한두 번 반복하여 배터리 컨트롤러를 재조정해 볼 수 있습니다. 단, 이 방법은 배터리에 스트레스를 줄 수 있으므로 너무 자주 하지는 마세요.\nQ3: 노트북을 장시간 사용하지 않을 때 배터리를 분리해야 하나요?\nA3: 최신 노트북의 리튬 이온 배터리는 보통 분리가 불가능하거나, 분리할 필요가 없습니다. 대부분의 노트북은 배터리 보호 회로가 내장되어 있어 과충전이나 과방전을 자동으로 방지해주기 때문입니다. 다만, 보관 시에는 위에서 언급했듯이 50% 정도 충전 상태를 유지하는 것이 좋습니다. 배터리 분리가 가능한 구형 노트북이라면 50% 충전 후 분리하여 서늘한 곳에 보관하는 것이 좋습니다.\n오늘 알려드린 5가지 습관만 고쳐도 여러분의 노트북 배터리는 훨씬 더 오래, 건강하게 함께할 수 있을 거예요!",
        "guid": "http://muzbox.tistory.com/483667",
        "categories": [
          "윈도우 사용팁/하드웨어",
          "2025 노트북 가이드",
          "노트북 과열 방지",
          "노트북 배터리 관리",
          "노트북 배터리 수명",
          "노트북 배터리 절약",
          "노트북 보관법",
          "노트북 충전 습관",
          "노트북 충전기 선택",
          "리튬 이온 배터리",
          "배터리 성능 저하"
        ],
        "isoDate": "2025-10-16T10:36:21.000Z"
      }
    ]
  },
  {
    "name": "동우리의 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "하테나",
    "category": "개인",
    "posts": []
  },
  {
    "name": "늑돌이네 라지온",
    "category": "개인",
    "posts": []
  },
  {
    "name": "루리웹 - 루리웹 리뷰 게시판",
    "category": "게임",
    "posts": [
      {
        "creator": "［RULIWEB］",
        "title": "[MULTI] 새로운 옷을 입고 돌아온 새 시대의 순수 액션, 닌자 가이덴 4",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2375",
        "pubDate": "Tue, 21 Oct 2025 08:03:25 +0900",
        "author": "［RULIWEB］",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i2.ruliweb.com/thumb/25/10/21/19a03dc7a8d5104c1.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2025-10-20T23:03:25.000Z"
      },
      {
        "creator": "「RULIWEB」",
        "title": "[MULTI] 부침 후 새로운 시작, 배틀필드 6",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2374",
        "pubDate": "Fri, 17 Oct 2025 16:39:28 +0900",
        "author": "「RULIWEB」",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i3.ruliweb.com/thumb/25/10/17/199f0fc70a34cacdc.jpg\">",
        "contentSnippet": "",
        "categories": [
          "리뷰"
        ],
        "isoDate": "2025-10-17T07:39:28.000Z"
      },
      {
        "creator": "｜RULIWEB｜",
        "title": "악역영애 4컷 만화는 한 주 쉬어갑니다.",
        "link": "https://bbs.ruliweb.com/news/board/11/read/2373",
        "pubDate": "Wed, 15 Oct 2025 22:23:25 +0900",
        "author": "｜RULIWEB｜",
        "content": "<img width=\"236\" height=\"177\" src=\"https://i1.ruliweb.com/thumb/25/10/15/199e80aaaa851ad6b.jpg\">",
        "contentSnippet": "",
        "categories": [
          "웹툰"
        ],
        "isoDate": "2025-10-15T13:23:25.000Z"
      }
    ]
  },
  {
    "name": "Reasontobe",
    "category": "개인",
    "posts": []
  },
  {
    "name": "자유로운 생활",
    "category": "개인",
    "posts": []
  },
  {
    "name": "에스티마의 인터넷이야기 EstimaStory.com",
    "category": "개인",
    "posts": []
  },
  {
    "name": "나긋한 개발 - 데비안 리눅스와 프로그램 언어",
    "category": "개인",
    "posts": []
  },
  {
    "name": "일상을 여행처럼...",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Just hack'em",
    "category": "개인",
    "posts": []
  },
  {
    "name": "C++ Truths",
    "category": "개인",
    "posts": []
  },
  {
    "name": "jacking75",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Joel on Software",
    "category": "개인",
    "posts": []
  },
  {
    "name": "벤자민로그",
    "category": "개인",
    "posts": [
      {
        "title": "회사에서 독립하기 전에 읽어보면 좋은 책 (글쓰기로 독립하는 법)",
        "link": "https://jeho.page/essay/2025/10/17/independence.html",
        "pubDate": "2025-10-17T02:27:00.000Z",
        "author": "김재호",
        "content": "<p>회사를 뛰쳐나와 스스로의 힘으로 벌어먹고사는 건 어떤 느낌일까?<br />\n그런 삶 뒤에는 어떤 모습들이 숨어 있을까?</p>\n\n<p><img src=\"https://contents.kyobobook.co.kr/sih/fit-in/458x0/pdt/9791167701374.jpg\" alt=\"글쓰기로 독립하는 법\" /><br />\n<em><a href=\"https://product.kyobobook.co.kr/detail/S000217843593\">글쓰기로 독립하는 법</a> - 정지우</em></p>\n\n<p>1인 개발자의 삶은 소설가나 만화가와 비슷한 것 같다고 생각해왔습니다.<br />\n<a href=\"/essay/2023/08/07/developer-is-a-creator.html\">개발자 또한 크리에이터</a>라고.</p>\n\n<p>이 얇은 책에, 1인 개발자의 삶과 그에 대한 조언이 담겨 있어서 놀랍고 흥미로웠습니다.<br />\n공감도 많이 하고 배운 점도 많았습니다.</p>\n\n<p>책 내용 중 변호사는(저자는 변호사이기도 합니다) 찍새와 딱새로 나뉜다는 이야기가 있습니다.<br />\n찍새는 사건을 따오는 세일즈 형 변호사.<br />\n딱새는 서면을 잘 쓰는 타입의 변호사.<br />\n어떤 변호사가 혼자 독립했을 때 성공할 가능성이 높을까요?</p>\n\n<p>개발자에게도 이런 모습을 흔하게 찾아볼 수 있습니다.<br />\n서비스 기획과 운영에 뛰어나지만 코딩에 약한 개발자.<br />\n코드는 잘 짜지만 서비스하는 방법을 모르는 개발자.</p>\n\n<p>제가 코딩을 처음 배우던 몇 년간 저는 스스로를 코딩형 개발자라고 규정했습니다.<br />\n서비스를 기획하고 운영하는 건 내가 해야 하거나 할 수 있는 일이 <strong>전혀</strong> 아니라고.<br />\n카톡을 만들던 시절, <a href=\"/essay/2021/10/02/코드가-그리-중하더냐.html\">동료 개발자들을 관찰하고 그들에게 배우면서</a> 이런 생각을 깨버릴 수 있었습니다.<br />\n이 생각에서 빠져나오지 않았더라면… 아마 지금도 회사에서 코딩하고 있을 것 같네요. (웃음)</p>\n\n<p>코딩만 잘한다고 성공할 수 있는 게 아니라는 건 이제 누구나 알 것 같습니다.<br />\n하지만 그렇다고 해서 개발보다 기획, 마케팅이 중요하다, 코드나 디자인은 사실 중요하지 않다고 주장하는 건 아닙니다.<br />\n어느 쪽이 더 중하다는 <strong>함정에 빠지지 말고</strong> 양쪽을 균형감 있게 잘하려고 노력하는 게 좋습니다.</p>\n\n<p>독립한 이후의 발생하는 구체적인 삶의 내용도 훑어보고…<br />\n꼭 독립을 해야만 하는가? 나는 왜 독립하고 싶은건가. 내가 진짜 살고 싶은 삶은 무엇인지 생각해보며 읽어보면 좋을 것 같습니다.\n<br />\n<br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2023/08/07/developer-is-a-creator.html\">개발자는 크리에이터</a></li>\n  <li><a href=\"/essay/2021/10/02/코드가-그리-중하더냐.html\">코드가 그리 중하더냐</a></li>\n  <li><a href=\"/essay/2022/04/05/one-developer-sorrow.html\">1인 개발자의 슬픔</a></li>\n</ul>",
        "contentSnippet": "회사를 뛰쳐나와 스스로의 힘으로 벌어먹고사는 건 어떤 느낌일까?\n\n글쓰기로 독립하는 법 - 정지우\n1인 개발자의 삶은 소설가나 만화가와 비슷한 것 같다고 생각해왔습니다.\n개발자 또한 크리에이터라고.\n이 얇은 책에, 1인 개발자의 삶과 그에 대한 조언이 담겨 있어서 놀랍고 흥미로웠습니다.\n책 내용 중 변호사는(저자는 변호사이기도 합니다) 찍새와 딱새로 나뉜다는 이야기가 있습니다.\n개발자에게도 이런 모습을 흔하게 찾아볼 수 있습니다.\n제가 코딩을 처음 배우던 몇 년간 저는 스스로를 코딩형 개발자라고 규정했습니다.\n전혀 아니라고.\n동료 개발자들을 관찰하고 그들에게 배우면서 이런 생각을 깨버릴 수 있었습니다.\n코딩만 잘한다고 성공할 수 있는 게 아니라는 건 이제 누구나 알 것 같습니다.\n함정에 빠지지 말고 양쪽을 균형감 있게 잘하려고 노력하는 게 좋습니다.\n독립한 이후의 발생하는 구체적인 삶의 내용도 훑어보고…\n함께 읽으면 좋은 글:\n개발자는 크리에이터\n코드가 그리 중하더냐\n1인 개발자의 슬픔",
        "summary": "회사를 뛰쳐나와 스스로의 힘으로 벌어먹고사는 건 어떤 느낌일까? 그런 삶 뒤에는 어떤 모습들이 숨어 있을까?",
        "id": "https://jeho.page/essay/2025/10/17/independence",
        "isoDate": "2025-10-17T02:27:00.000Z"
      },
      {
        "title": "꾸준하게 하는 방법",
        "link": "https://jeho.page/essay/2025/10/16/routine.html",
        "pubDate": "2025-10-16T03:35:00.000Z",
        "author": "김재호",
        "content": "<p>무라카미 하루키 책 중에서 가장 좋아하는 책은 <a href=\"https://product.kyobobook.co.kr/detail/S000001068777\">달리기를 말할 때 내가 하고 싶은 이야기</a>입니다.</p>\n\n<p>이 책에서 배운 것은 어떻게 꾸준하게 할 수 있는가?<br />\n꾸준하게 하기 위해선 100%로 일을 해서는 안 된다.<br />\n내일을 위해 힘을 남겨 놔야만 한다는 것.</p>\n\n<p>저도 이걸 알고 나서부터 GitHub 그래프가 (완벽하진 않지만) 잔디가 빼곡히 채워지기 시작한 것 같습니다.</p>\n\n<p><img src=\"/assets/img/github_2025.png\" alt=\"5년 간 꾸준하게 커밋했던 GitHub 잔디\" /></p>\n\n<p>여기서 한발 더 나아가려면 잔디의 색깔도 너무 들쑥날쑥하지 않게 해야 합니다.<br />\n하루키는 매일 20장의 원고를 쓴다고 했거든요. 글이 아무리 잘 써져도 딱 20장을 쓰면 미련 없이 자리에서 일어난다고.</p>\n\n<p>1년에 몇 번 정도는 힘을 다해 밤을 새워가며 코딩하곤 합니다.<br />\n몰입감을 놓치기 싫어서. 오늘 다 끝내고 만다는 마음으로.<br />\n그런데 다음 날이 되면 여지없이 방전되면서 거의 아무것도 못하게 돼버리고 마는 것입니다.<br />\n하아… 차라리 70%의 힘으로 이틀 동안 할걸. 괜히 밸런스만 깨졌네.</p>\n\n<p>오늘도 그런 날입니다. 정오가 다 되어 일어났는데 머리가 어질어질합니다. 너무 피곤하고 다시 에디터를 켤 자신이 없습니다.<br />\n아는 것과 실천하는 것은 다른 것 같습니다. 저는 언제쯤 이걸 완전하게 지킬 수 있을까요?<br />\n언젠가는 그렇게 할 수 있는 사람이 되고 싶습니다.\n<br />\n<br />\n<em>함께 읽으면 좋은 글:</em></p>\n<ul>\n  <li><a href=\"/essay/2024/08/26/daily-commit-failed.html\">매일 커밋에 실패했던 날</a></li>\n  <li><a href=\"/essay/2022/01/05/daily-coding.html\">매일매일 코딩하기</a></li>\n</ul>",
        "contentSnippet": "무라카미 하루키 책 중에서 가장 좋아하는 책은 달리기를 말할 때 내가 하고 싶은 이야기입니다.\n이 책에서 배운 것은 어떻게 꾸준하게 할 수 있는가?\n저도 이걸 알고 나서부터 GitHub 그래프가 (완벽하진 않지만) 잔디가 빼곡히 채워지기 시작한 것 같습니다.\n\n여기서 한발 더 나아가려면 잔디의 색깔도 너무 들쑥날쑥하지 않게 해야 합니다.\n1년에 몇 번 정도는 힘을 다해 밤을 새워가며 코딩하곤 합니다.\n오늘도 그런 날입니다. 정오가 다 되어 일어났는데 머리가 어질어질합니다. 너무 피곤하고 다시 에디터를 켤 자신이 없습니다.\n함께 읽으면 좋은 글:\n매일 커밋에 실패했던 날\n매일매일 코딩하기",
        "summary": "무라카미 하루키 책 중에서 가장 좋아하는 책은 달리기를 말할 때 내가 하고 싶은 이야기입니다.",
        "id": "https://jeho.page/essay/2025/10/16/routine",
        "isoDate": "2025-10-16T03:35:00.000Z"
      }
    ]
  },
  {
    "name": "악보쓰는 프로그래머",
    "category": "개인",
    "posts": []
  },
  {
    "name": "쭌안아빠",
    "category": "개인",
    "posts": []
  },
  {
    "name": "A Gangster World",
    "category": "개인",
    "posts": []
  },
  {
    "name": "요우의 내맘대로 블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자스럽다",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Against All Odds.",
    "category": "개인",
    "posts": []
  },
  {
    "name": "움직이는 게임서버",
    "category": "개인",
    "posts": []
  },
  {
    "name": "이상욱",
    "category": "개인",
    "posts": []
  },
  {
    "name": "임철재",
    "category": "개인",
    "posts": []
  },
  {
    "name": "어쩐지 오늘은",
    "category": "개인",
    "posts": []
  },
  {
    "name": "oddpoet’s étude",
    "category": "개인",
    "posts": []
  },
  {
    "name": "0x00 - NULL",
    "category": "개인",
    "posts": []
  },
  {
    "name": "퇴근 후 서버다운",
    "category": "개인",
    "posts": [
      {
        "creator": "SIDNFT",
        "title": "중국 토양 어염 심각해서 농작물들은 위험하다.",
        "link": "http://serverdown.tistory.com/1434",
        "pubDate": "Sat, 18 Oct 2025 16:57:39 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1434#entry1434comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"468\" data-origin-height=\"336\"><span data-url=\"https://blog.kakaocdn.net/dn/beqAIM/dJMb89dImNM/XcqkSwDmJk5G7KA2uqInM1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/beqAIM/dJMb89dImNM/XcqkSwDmJk5G7KA2uqInM1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/beqAIM/dJMb89dImNM/XcqkSwDmJk5G7KA2uqInM1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbeqAIM%2FdJMb89dImNM%2FXcqkSwDmJk5G7KA2uqInM1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"468\" height=\"336\" data-origin-width=\"468\" data-origin-height=\"336\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://youtu.be/JauClUw2rGs?t=2616\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://youtu.be/JauClUw2rGs?t=2616</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=JauClUw2rGs\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/2auzw/hyZLp7g22v/RHQs40eaqelAfBk9hH8JrK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/Jp43S/hyZMam96xm/JnVq7YTAMarXkYppekeMW1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"닥쳐오는 중국 식량안보 위기, 무엇이 가장 문제인가? [농업 13부]\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/JauClUw2rGs\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">43분 20초에 나옵니다.</p>\n<p data-ke-size=\"size16\">중국 토양의 대부분은 오염되었고 특히 지하수는 위험합니다.</p>\n<p data-ke-size=\"size16\">지하수를 퍼올려 농사에 사용하니 토양도 오염된것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">그래서 필사적으로 미국 농토와 한국 농토를 매수 중입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">중국 농산물 쓰지말라고 하는게 이런 이유 때문입니다.</p>\n<p data-ke-size=\"size16\">위험하니 최대한 피하시길 바랍니다.</p>",
        "contentSnippet": "영상: https://youtu.be/JauClUw2rGs?t=2616\n\n\n\n \n43분 20초에 나옵니다.\n중국 토양의 대부분은 오염되었고 특히 지하수는 위험합니다.\n지하수를 퍼올려 농사에 사용하니 토양도 오염된것입니다.\n \n그래서 필사적으로 미국 농토와 한국 농토를 매수 중입니다.\n \n중국 농산물 쓰지말라고 하는게 이런 이유 때문입니다.\n위험하니 최대한 피하시길 바랍니다.",
        "guid": "http://serverdown.tistory.com/1434",
        "categories": [
          "유튜브",
          "중국"
        ],
        "isoDate": "2025-10-18T07:57:39.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "미국 희토류의 새로운 카드 파키스탄 등장",
        "link": "http://serverdown.tistory.com/1433",
        "pubDate": "Fri, 17 Oct 2025 12:55:45 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1433#entry1433comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"417\" data-origin-height=\"246\"><span data-url=\"https://blog.kakaocdn.net/dn/bgRmuY/dJMb9W6uDao/lWaxwu82Za0gJUFv7YaEsK/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bgRmuY/dJMb9W6uDao/lWaxwu82Za0gJUFv7YaEsK/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bgRmuY/dJMb9W6uDao/lWaxwu82Za0gJUFv7YaEsK/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbgRmuY%2FdJMb9W6uDao%2FlWaxwu82Za0gJUFv7YaEsK%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"417\" height=\"246\" data-origin-width=\"417\" data-origin-height=\"246\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=Ts4ogxFicxM\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=Ts4ogxFicxM</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=Ts4ogxFicxM\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/b8IgcU/hyZLYGOT9U/5NK9AVsh5RNZJ3G2ftXTy0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/Tq495/hyZLV4ot4B/1UmzEWokElKC4aZE7vUVpK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"[Why Times 정세분석 3595] 최우방의 배신에 충격받은 중국, &ldquo;파키스탄, 미국에 희토류 수출 시작!&rdquo;\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/Ts4ogxFicxM\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">와 미쳤습니다</p>\n<p data-ke-size=\"size16\">친중이였던 파키스탄이 돌아섰습니다.</p>\n<p data-ke-size=\"size16\">파키스탄은 이란 견제를 위해 중국이 공들인 나라인데</p>\n<p data-ke-size=\"size16\">희토류를 들고 미국에 뭍었군요</p>\n<p data-ke-size=\"size16\">이것은 충격적인 일입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">안티몬을 비롯해 모든 종류의 희토류가 다 있다고 합니다.</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=Ts4ogxFicxM\n\n\n\n \n와 미쳤습니다\n친중이였던 파키스탄이 돌아섰습니다.\n파키스탄은 이란 견제를 위해 중국이 공들인 나라인데\n희토류를 들고 미국에 뭍었군요\n이것은 충격적인 일입니다.\n \n안티몬을 비롯해 모든 종류의 희토류가 다 있다고 합니다.",
        "guid": "http://serverdown.tistory.com/1433",
        "categories": [
          "투자",
          "미국",
          "중국",
          "파키스탄",
          "희토류"
        ],
        "isoDate": "2025-10-17T03:55:45.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "아버지 쇼핑 - 독일 드르투 면도기",
        "link": "http://serverdown.tistory.com/1432",
        "pubDate": "Thu, 16 Oct 2025 16:42:11 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1432#entry1432comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"530\" data-origin-height=\"542\"><span data-url=\"https://blog.kakaocdn.net/dn/bj8zPl/dJMb9NIxZYz/8ECfqK5cWkx6nNU1qlYBWk/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bj8zPl/dJMb9NIxZYz/8ECfqK5cWkx6nNU1qlYBWk/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bj8zPl/dJMb9NIxZYz/8ECfqK5cWkx6nNU1qlYBWk/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbj8zPl%2FdJMb9NIxZYz%2F8ECfqK5cWkx6nNU1qlYBWk%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"530\" height=\"542\" data-origin-width=\"530\" data-origin-height=\"542\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">저는 참고로 인포벨 싫어합니다. <br />싫다는 정도로 표현할 수 없고 증오에 가깝습니다.</p>\n<p data-ke-size=\"size16\">먹는거는 절대 비추구요 쿠팡에서 비슷한거 사면 절반가격에 살 수 있습니다.<br />중국산도 찾아보면 비슷한거 반값에 팝니다. 괜히 2개 줘서 가격을 올리는 놈들입니다.</p>\n<p data-ke-size=\"size16\">여러번 쇼핑 호구 당하신 아버지는 이번에도 인포벨껄 사달라고 하십니다.<br /><br /></p>\n<p data-ke-size=\"size16\">이번엔 면도기군요 <br /><span style=\"text-align: start;\">먹을꺼도 아니고</span><br /><span style=\"text-align: start;\">중국산도 아니라 <br />구입 진행합니다.</span></p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">장점으로 내세우는것</h2>\n<p data-ke-size=\"size16\">안전 - 다른걸 써도 피본적이 없어서 전혀 공감은 안갑니다.</p>\n<p data-ke-size=\"size16\">충전된다. - 미친 인포벨 이걸 장점이라고</p>\n<p data-ke-size=\"size16\">물로 씻는다 - 이것도 장점인가</p>\n<p data-ke-size=\"size16\">다용도 <br />코털도 깎는다.<br />머리도 깎는다.<br />이거는 좋습니다. 따로 사면 만원씩 드는거라</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">제가 생각하는 자점</h2>\n<p data-ke-size=\"size16\">싸다 - 39,900 원<br />다용도다</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">과장 광고는 계속 의심해야합니다.</p>\n<p data-ke-size=\"size16\">독일꺼 엄청 강조하는데 <br />중국에서 제조했을 것으로 의심됩니다.<br />이상할 정도로 많이 강조합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">인포벨의 과장광고는 노인들을 잘 홀리니 주의 하시구요</p>\n<p data-ke-size=\"size16\">사달라고 하면 안된다고 말해봐야 소용없으니 본인 돈으로 사게 만드시면</p>\n<p data-ke-size=\"size16\">몇번 사보다 호구 털린걸 알게되서 안사는 쪽으로 유도해야합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">우리들도 쇼핑의 즐거움은 알기 때문에 못사게 말리는건 역효과가 납니다.</p>\n<p data-ke-size=\"size16\">싼거 있으면 싼거 알려주고 사준다음 인터넷에 이런 저런 단점들을 알려주면서</p>\n<p data-ke-size=\"size16\">교육 시켜야합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">중국산 보다 광고자체는 슴슴합니다.</p>\n<p data-ke-size=\"size16\">인포벨 영상: <a href=\"https://www.youtube.com/watch?v=IwBL7y1MS84\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=IwBL7y1MS84</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=IwBL7y1MS84\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/b4sc39/hyZLqECPTd/BGWpFyslCnoIGYHA83aKVk/img.jpg?width=1280&amp;height=720&amp;face=344_158_664_362,https://scrap.kakaocdn.net/dn/VVz3L/hyZLwSni8z/Sh0huaaUEw2auDIeLTAWpK/img.jpg?width=1280&amp;height=720&amp;face=344_158_664_362\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"독일 도르트 3헤드 면도기_인포벨 홈쇼핑\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/IwBL7y1MS84\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">쿠팡 스샷</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"260\" data-origin-height=\"483\"><span data-url=\"https://blog.kakaocdn.net/dn/ZIS5m/dJMb9NhtLCv/BhkqINAuqBmdekVEgTiRH0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ZIS5m/dJMb9NhtLCv/BhkqINAuqBmdekVEgTiRH0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/ZIS5m/dJMb9NhtLCv/BhkqINAuqBmdekVEgTiRH0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FZIS5m%2FdJMb9NhtLCv%2FBhkqINAuqBmdekVEgTiRH0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"260\" height=\"483\" data-origin-width=\"260\" data-origin-height=\"483\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "저는 참고로 인포벨 싫어합니다. \n싫다는 정도로 표현할 수 없고 증오에 가깝습니다.\n먹는거는 절대 비추구요 쿠팡에서 비슷한거 사면 절반가격에 살 수 있습니다.\n중국산도 찾아보면 비슷한거 반값에 팝니다. 괜히 2개 줘서 가격을 올리는 놈들입니다.\n여러번 쇼핑 호구 당하신 아버지는 이번에도 인포벨껄 사달라고 하십니다.\n\n이번엔 면도기군요 \n먹을꺼도 아니고\n중국산도 아니라 \n구입 진행합니다.\n \n장점으로 내세우는것\n안전 - 다른걸 써도 피본적이 없어서 전혀 공감은 안갑니다.\n충전된다. - 미친 인포벨 이걸 장점이라고\n물로 씻는다 - 이것도 장점인가\n다용도 \n코털도 깎는다.\n머리도 깎는다.\n이거는 좋습니다. 따로 사면 만원씩 드는거라\n \n \n \n제가 생각하는 자점\n싸다 - 39,900 원\n다용도다\n \n과장 광고는 계속 의심해야합니다.\n독일꺼 엄청 강조하는데 \n중국에서 제조했을 것으로 의심됩니다.\n이상할 정도로 많이 강조합니다.\n \n인포벨의 과장광고는 노인들을 잘 홀리니 주의 하시구요\n사달라고 하면 안된다고 말해봐야 소용없으니 본인 돈으로 사게 만드시면\n몇번 사보다 호구 털린걸 알게되서 안사는 쪽으로 유도해야합니다.\n \n우리들도 쇼핑의 즐거움은 알기 때문에 못사게 말리는건 역효과가 납니다.\n싼거 있으면 싼거 알려주고 사준다음 인터넷에 이런 저런 단점들을 알려주면서\n교육 시켜야합니다.\n \n \n \n \n중국산 보다 광고자체는 슴슴합니다.\n인포벨 영상: https://www.youtube.com/watch?v=IwBL7y1MS84\n\n\n\n \n \n쿠팡 스샷",
        "guid": "http://serverdown.tistory.com/1432",
        "categories": [
          "유튜브",
          "과장광고",
          "쇼핑",
          "인포벨"
        ],
        "isoDate": "2025-10-16T07:42:11.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "코인 - 2025년 10월 11일 (토) 관세빔 이후 남은 기록들",
        "link": "http://serverdown.tistory.com/1431",
        "pubDate": "Wed, 15 Oct 2025 15:56:26 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1431#entry1431comment",
        "content": "<h2 data-ke-size=\"size26\">&nbsp;</h2>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">트럼프 관세빔은 2025년 10월 11일 (토) 6시쯤에 일어았습니다.</p>\n<p data-ke-size=\"size16\">중국이 희토류 반격 카드를 꺼내자</p>\n<p data-ke-size=\"size16\">트럼프가 트럼프소셜에 관세 100% 올리겠다는 말 한마디로 시작되었죠</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">남은 영상들을 모아 봅시다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">알고란 뉴스</h2>\n<p data-ke-size=\"size16\">상황정리: <a href=\"https://www.youtube.com/watch?v=j_asty0SPtE&amp;t=281s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=j_asty0SPtE&amp;t=281s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=j_asty0SPtE\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/cMefRU/hyZLpZB72E/kdxyRlHhlM90su0G8yEnTK/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/oCpB5/hyZKkrBzPV/sLqmyFgI3SyKsAR9RFuZ51/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"코인 최악의 날, 대폭락 역대급 청산/워뇨띠 200억 나씨 50억 스트릿 70억 청산썰/트럼프 아들은 3\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/j_asty0SPtE\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">알고란 이십니다. 1세대 유튜버 청산자 이십니다.</p>\n<p data-ke-size=\"size16\">이분은 부따빔이였나 그때 한번 크게 날리시고&nbsp;</p>\n<p data-ke-size=\"size16\">엉청난 내공이 생기셨습니다.</p>\n<p data-ke-size=\"size16\">담담하게 뉴스를 정리해주시는데 원래 직업이 기자입니다.&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">청산후 재기를 기약하신분</h2>\n<p data-ke-size=\"size16\">3억 날리고 회고하는영상: <a href=\"https://www.youtube.com/watch?v=tFZ0orx29vk&amp;t=45s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=tFZ0orx29vk&amp;t=45s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=tFZ0orx29vk\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/78HSa/hyZLo60BSM/RUj6klPLNsyo20nkm3Zu0K/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/SWx82/hyZLxpMwAE/7avfdrLAT2zQYy7YasRPK0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"트럼프 관세빔, 코인 전재산 3억을 잃고 나서 깨달은 것\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/tFZ0orx29vk\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">이 영상 전 영상이 2023년이군요 2년만에 다시 유튜브를 올렸습니다.</p>\n<p data-ke-size=\"size16\">내용은 회고하는 형식으로 실패에서 배울 점이 있습니다.</p>\n<p data-ke-size=\"size16\">마지막에 욕심이 나서 너무 많이 들어간거 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">라이브로 청산쇼 파신분</h2>\n<p data-ke-size=\"size16\">관세빔 당시의 영상: <a href=\"https://www.youtube.com/watch?v=dFnEF1nyvHw\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=dFnEF1nyvHw</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=dFnEF1nyvHw\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bCGU8r/hyZLfWwS4e/255AKWEdsw0L5QLxbk58Bk/img.jpg?width=1280&amp;height=720&amp;face=518_324_688_510,https://scrap.kakaocdn.net/dn/im0DZ/hyZLvS27T1/QPgTGRr9tRK4OfoxtEsy4K/img.jpg?width=1280&amp;height=720&amp;face=518_324_688_510\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"코인 선물 하면 안 되는 이유(10억 청산, 그리고 다시 시작)\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/dFnEF1nyvHw\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">라이브 편집이라 생생합니다.</p>\n<p data-ke-size=\"size16\">너무 나 확실해서 풀롱을 타버렸군요 풀 숏을 때렸으면 대박이였을지도 ...<br />계속 숏 이야기 하고 있습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">스테이블 코인으로 살아남으신분</h2>\n<p data-ke-size=\"size16\">아기 앉고 설명하시는분: <a href=\"https://www.youtube.com/watch?v=oRT8x2ue4xk&amp;t=447s\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=oRT8x2ue4xk&amp;t=447s</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=oRT8x2ue4xk\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bM0086/hyZLvMiCjS/DfhLbkoU2P9xCQmsKOeZ1k/img.jpg?width=1280&amp;height=720&amp;face=640_96_816_288,https://scrap.kakaocdn.net/dn/dh7OOS/hyZLl3wfrv/a2zDUTN6cVsdmuk6Vb1QHk/img.jpg?width=1280&amp;height=720&amp;face=640_96_816_288\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"지금 코인하는 사람들이 개빡친 이유\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/oRT8x2ue4xk\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">스테이블 코인을 많이 가지고 있어서 살아남으신분</p>\n<p data-ke-size=\"size16\">스테이블 코인은 엄청난 방어력을 보여줬습니다.</p>\n<p data-ke-size=\"size16\">USDT 는 1,500 원도 넘게 가더군요</p>\n<p data-ke-size=\"size16\">정신없이 아기 둥기둥기 하고 있어서 집중은 안됩니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">전날까지도 매매법 강의 하시던분</h2>\n<h2 data-ke-size=\"size26\">골드핑거: <a href=\"https://www.youtube.com/@gold_finger_trader/videos\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/@gold_finger_trader/videos</a></h2>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"641\" data-origin-height=\"667\"><span data-url=\"https://blog.kakaocdn.net/dn/bc93gB/btsQ9l0FRJX/jM49hNEgg5Kn8MsM0uQ2l0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/bc93gB/btsQ9l0FRJX/jM49hNEgg5Kn8MsM0uQ2l0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/bc93gB/btsQ9l0FRJX/jM49hNEgg5Kn8MsM0uQ2l0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbc93gB%2FbtsQ9l0FRJX%2FjM49hNEgg5Kn8MsM0uQ2l0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"641\" height=\"667\" data-origin-width=\"641\" data-origin-height=\"667\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">이분은 마지막 영상이 10월 10일이군요 한주에 하나씩 올라오니까 좀 기다려봐야겠습니다.</p>\n<p data-ke-size=\"size16\">슈퍼카도 나오고 단타 매매법 강의를 하빈다.</p>\n<p data-ke-size=\"size16\">과연 살아남으셨을 까요</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">내가 숏이라고 했제 하고 주무신분</h2>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=F4ZI-8kJPwc\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=F4ZI-8kJPwc</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=F4ZI-8kJPwc\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/Bt6TR/hyZLtnoRc9/uQ3qxnLaIebbQyIIFwS2j1/img.jpg?width=1280&amp;height=720&amp;face=246_98_516_392,https://scrap.kakaocdn.net/dn/jw11U/hyZLrJSzW1/lzj98vxb2UIbKHP1trUCkk/img.jpg?width=1280&amp;height=720&amp;face=246_98_516_392\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"비트코인 역대급 청산! 앞으로 &quot;어떻게&quot; 살아야 할까요?\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/F4ZI-8kJPwc\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">이분은 숏이라고 단톡방에 알려주고</p>\n<p data-ke-size=\"size16\">본인도 숏쳤는데 폭락직전까지 계속 오르자 풀고 잤습니다.</p>\n<p data-ke-size=\"size16\">다음날 일어나보니 단톡방 사람들은 돈 벌어서 감사의 인사를 전했다는 ....</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">우크라이나 코인러 사망 사건 (300억 자산가)</h2>\n<p data-ke-size=\"size16\">뉴스: <a href=\"https://www.youtube.com/watch?v=zwFtb_0kP4g\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=zwFtb_0kP4g</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=zwFtb_0kP4g\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/bzBfUW/hyZLBMvrlJ/qGDdxGxS8Ksb1LtuqBdqA1/img.jpg?width=1280&amp;height=720&amp;face=580_108_678_216\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"&quot;투자금 하루 만에 400억 잃어&hellip;&quot; 유명 유튜버, 총상 입고 숨진 채 발견/ KNN\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/zwFtb_0kP4g\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">유명한 유튜버라고 합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">자두두는 그냥 넣어봤습니다.</h2>\n<p data-ke-size=\"size16\">자두두는 아직 영상이 없군요</p>\n<p data-ke-size=\"size16\">그냥 재밌는 쇼츠 구경합시다: <a href=\"https://www.youtube.com/shorts/dunfVKZ_BLU\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/shorts/dunfVKZ_BLU</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/shorts/dunfVKZ_BLU\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/biZMVx/hyZLv6AyWI/kJnM2FiC4lqeEpZW3Fmwak/img.jpg?width=406&amp;height=720&amp;face=115_207_300_671,https://scrap.kakaocdn.net/dn/S6q4f/hyZLE3xFA5/PHwkLG2SJGEytH94F0Hnk1/img.jpg?width=406&amp;height=720&amp;face=115_207_300_671\" data-video-width=\"406\" data-video-height=\"720\" data-video-origin-width=\"406\" data-video-origin-height=\"720\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"코인 5년차 얼굴변화 #shorts\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/dunfVKZ_BLU\" width=\"406\" height=\"720\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">자두두는 미인으로 시작했지만&nbsp;</p>\n<p data-ke-size=\"size16\">지금은 아즘마가 되어버렸습니다.</p>\n<p data-ke-size=\"size16\">40대에는 박호두 처럼 엄청난 돈을 벌것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">청산 이벤트후에 항상 봐야하는 여상</p>\n<p data-ke-size=\"size16\">루나 청산때 전재산 넣으셨던분: <a href=\"https://www.youtube.com/watch?v=QcnSBqFO3gA\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=QcnSBqFO3gA</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=QcnSBqFO3gA\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/16DBQ/hyZLqKYHIc/zFSkOWfvoMpd2EoXZZQdK1/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720,https://scrap.kakaocdn.net/dn/bJLlWc/hyZLrQFaEG/aPpvxYMdOKoJJugSBd8CX0/img.jpg?width=1280&amp;height=720&amp;face=0_0_1280_720\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"루나코인 나락 요약본\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/QcnSBqFO3gA\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">인생 전체가 30초에 다 담겨있습니다.</p>\n<p data-ke-size=\"size16\">그는 요즘 여행 유튜버 하고 있습니다.</p>\n<p data-ke-size=\"size16\">청산을 당하더라도 미래는 있습니다.</p>\n<p data-ke-size=\"size16\">화이팅!</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "트럼프 관세빔은 2025년 10월 11일 (토) 6시쯤에 일어았습니다.\n중국이 희토류 반격 카드를 꺼내자\n트럼프가 트럼프소셜에 관세 100% 올리겠다는 말 한마디로 시작되었죠\n \n남은 영상들을 모아 봅시다.\n \n알고란 뉴스\n상황정리: https://www.youtube.com/watch?v=j_asty0SPtE&t=281s\n\n\n\n알고란 이십니다. 1세대 유튜버 청산자 이십니다.\n이분은 부따빔이였나 그때 한번 크게 날리시고 \n엉청난 내공이 생기셨습니다.\n담담하게 뉴스를 정리해주시는데 원래 직업이 기자입니다. \n \n \n청산후 재기를 기약하신분\n3억 날리고 회고하는영상: https://www.youtube.com/watch?v=tFZ0orx29vk&t=45s\n\n\n\n이 영상 전 영상이 2023년이군요 2년만에 다시 유튜브를 올렸습니다.\n내용은 회고하는 형식으로 실패에서 배울 점이 있습니다.\n마지막에 욕심이 나서 너무 많이 들어간거 같습니다.\n \n \n라이브로 청산쇼 파신분\n관세빔 당시의 영상: https://www.youtube.com/watch?v=dFnEF1nyvHw\n\n\n\n라이브 편집이라 생생합니다.\n너무 나 확실해서 풀롱을 타버렸군요 풀 숏을 때렸으면 대박이였을지도 ...\n계속 숏 이야기 하고 있습니다.\n \n \n스테이블 코인으로 살아남으신분\n아기 앉고 설명하시는분: https://www.youtube.com/watch?v=oRT8x2ue4xk&t=447s\n\n\n\n스테이블 코인을 많이 가지고 있어서 살아남으신분\n스테이블 코인은 엄청난 방어력을 보여줬습니다.\nUSDT 는 1,500 원도 넘게 가더군요\n정신없이 아기 둥기둥기 하고 있어서 집중은 안됩니다.\n \n \n전날까지도 매매법 강의 하시던분\n골드핑거: https://www.youtube.com/@gold_finger_trader/videos\n\n\n이분은 마지막 영상이 10월 10일이군요 한주에 하나씩 올라오니까 좀 기다려봐야겠습니다.\n슈퍼카도 나오고 단타 매매법 강의를 하빈다.\n과연 살아남으셨을 까요\n \n내가 숏이라고 했제 하고 주무신분\n영상: https://www.youtube.com/watch?v=F4ZI-8kJPwc\n\n\n\n \n이분은 숏이라고 단톡방에 알려주고\n본인도 숏쳤는데 폭락직전까지 계속 오르자 풀고 잤습니다.\n다음날 일어나보니 단톡방 사람들은 돈 벌어서 감사의 인사를 전했다는 ....\n \n \n \n \n우크라이나 코인러 사망 사건 (300억 자산가)\n뉴스: https://www.youtube.com/watch?v=zwFtb_0kP4g\n\n\n\n \n \n유명한 유튜버라고 합니다.\n \n \n \n \n자두두는 그냥 넣어봤습니다.\n자두두는 아직 영상이 없군요\n그냥 재밌는 쇼츠 구경합시다: https://www.youtube.com/shorts/dunfVKZ_BLU\n\n\n\n \n자두두는 미인으로 시작했지만 \n지금은 아즘마가 되어버렸습니다.\n40대에는 박호두 처럼 엄청난 돈을 벌것입니다.\n \n \n청산 이벤트후에 항상 봐야하는 여상\n루나 청산때 전재산 넣으셨던분: https://www.youtube.com/watch?v=QcnSBqFO3gA\n\n\n\n인생 전체가 30초에 다 담겨있습니다.\n그는 요즘 여행 유튜버 하고 있습니다.\n청산을 당하더라도 미래는 있습니다.\n화이팅!",
        "guid": "http://serverdown.tistory.com/1431",
        "categories": [
          "관세빔",
          "코인"
        ],
        "isoDate": "2025-10-15T06:56:26.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "트럼프의 애브리띵랠리 를 설명합니다. / 금 원자재 스테이블 코인",
        "link": "http://serverdown.tistory.com/1430",
        "pubDate": "Wed, 15 Oct 2025 15:04:49 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1430#entry1430comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"259\" data-origin-height=\"194\"><span data-url=\"https://blog.kakaocdn.net/dn/NMNQP/btsRbDk5zmr/jtukt8y8YI7zlqKnO6MEG0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/NMNQP/btsRbDk5zmr/jtukt8y8YI7zlqKnO6MEG0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/NMNQP/btsRbDk5zmr/jtukt8y8YI7zlqKnO6MEG0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FNMNQP%2FbtsRbDk5zmr%2Fjtukt8y8YI7zlqKnO6MEG0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"259\" height=\"194\" data-origin-width=\"259\" data-origin-height=\"194\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=j_E1xtJd_T0\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=j_E1xtJd_T0</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=j_E1xtJd_T0\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/nkJ6c/hyZLvFvOb2/lWGifdaECqUkX2QWrjeX61/img.jpg?width=480&amp;height=360&amp;face=308_101_369_168,https://scrap.kakaocdn.net/dn/ib3Vr/hyZLyvr2hh/tNS0BqmCFYZIo4HkHMoZR1/img.jpg?width=480&amp;height=360&amp;face=308_101_369_168\" data-video-width=\"480\" data-video-height=\"360\" data-video-origin-width=\"480\" data-video-origin-height=\"360\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"[정철진의 작전] &lsquo;트럼프의 저금리&rsquo; 드디어 시작되나 Feat. AI 반도체 주도주 교체? / 정철진의 \" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/j_E1xtJd_T0\" width=\"480\" height=\"360\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">처음부터 나옵니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">왜 모든 자산이 가느냐</h2>\n<p data-ke-size=\"size16\">적어도 유가는 가지 않습니다. 이게 중요한것입니다.</p>\n<p data-ke-size=\"size16\">트럼프는 미구의 부채를 해결하기 위한 방법으로&nbsp;</p>\n<p data-ke-size=\"size16\">돈을 불어 부채를 희석하고 금리를 내리는 방식을 사용하려고 합니다.<br />적어도 지금까지는 성공적입니다.</p>\n<p data-ke-size=\"size16\">금은 미국도 많습니다.&nbsp;<br />금값이 올라가면 미국에게 좋습니다.<br />예를 들어&nbsp;</p>\n<p data-ke-size=\"size16\">금 100 부채 100 일때 금 가격을 올려<br />금 400 부채 100 이라면</p>\n<p data-ke-size=\"size16\">부채비율은 50% 에서 20% 로 줄어든것으로 보인다는 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">그리고 상하이 금거래소가 새로 생겼습니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"670\" data-origin-height=\"503\"><span data-url=\"https://blog.kakaocdn.net/dn/bjTWLb/btsQ9UaBKvX/QWy9VAudr2VecA6JOhj1T0/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/bjTWLb/btsQ9UaBKvX/QWy9VAudr2VecA6JOhj1T0/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/bjTWLb/btsQ9UaBKvX/QWy9VAudr2VecA6JOhj1T0/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbjTWLb%2FbtsQ9UaBKvX%2FQWy9VAudr2VecA6JOhj1T0%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"670\" height=\"503\" data-origin-width=\"670\" data-origin-height=\"503\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">(사진이 상하이 금 거래소 사진인가 봅니다. 동네 주택 대문 처럼 보이는데 ...)</p>\n<p data-ke-size=\"size16\">이전엔 런던 금 거래소 정도가 큰 거래소 였는데 <br />중국도 하나 차렸습니다.</p>\n<p data-ke-size=\"size16\">예전부터 런던 금 거래소가 금 값을 임의적으로 조정한다는 음모론이 있었는데<br />이제 부터는 그 짓이 불가능해졌습니다.</p>\n<p data-ke-size=\"size16\">런던에서 금값이 싸게 거래되니까 사람들이 상하이 금 거래소에 가서 금을 비싸게 팔게 되었습니다.<br />경쟁을 통해 시장을 뺏아오는 계획이 성공하였다는 것입니다.</p>\n<p data-ke-size=\"size16\">아편전쟁의 반격일 수도 있겠네요<br />현재 영국의 국내 상황은 맛탱이가 간 상황입니다.<br />무슬림 증가 문제와 EU 탈퇴로 인한 시장 축소가 계속 진행되고 있습니다.</p>\n<p data-ke-size=\"size16\">그리고 중국도 미국과 비슷한 상황으로 금값이 오르면 <br />부채가 줄어드는 효과를 누릴 수 있습니다.<br />그리고 현재 중국은 파격적으로 금을 사모으고 있습니다.</p>\n<p data-ke-size=\"size16\">베트남도 금 거래소를 하나 차린거 같고 인도도 사모은다고 하니 전세계가 금을 올려<br />부채를 줄일려는 계획에 동참하고 있는거 같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">일본의 총리 교체</h2>\n<p data-ke-size=\"size16\">이시바의 경우 학자 출신으로 정상적인 재정을 만드려고 금리를 올리고 하는등의 교과서 적인 정책을 사용하려고 했으나<br />(서민들에겐 이 방법이 맞습니다.)</p>\n<p data-ke-size=\"size16\">일본은 미국의 채권을 사줘야하는 숙명이 있고<br />트럼프도 이걸 이용해 미국의 금리를 내리려는 계획이 있습니다.</p>\n<p data-ke-size=\"size16\">그러니 이시바랑은 잘 맞지 않고 총리는 교체되었습니다.</p>\n<p data-ke-size=\"size16\">다음 총리로 여자 + 상속받지않은 세력 의 다카이 입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"275\" data-origin-height=\"183\"><span data-url=\"https://blog.kakaocdn.net/dn/7b9vm/btsRbN2jrRS/OwbyRLBRAEYqjK2RVkzXV1/img.jpg\" data-phocus=\"https://blog.kakaocdn.net/dn/7b9vm/btsRbN2jrRS/OwbyRLBRAEYqjK2RVkzXV1/img.jpg\"><img src=\"https://blog.kakaocdn.net/dn/7b9vm/btsRbN2jrRS/OwbyRLBRAEYqjK2RVkzXV1/img.jpg\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F7b9vm%2FbtsRbN2jrRS%2FOwbyRLBRAEYqjK2RVkzXV1%2Fimg.jpg\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"275\" height=\"183\" data-origin-width=\"275\" data-origin-height=\"183\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">이시바와 반대고 아베와 같은 확장 재정을 추진할 것입니다.</p>\n<p data-ke-size=\"size16\">미국 채권을 계속 사주고 일본은 돈을 계속 찍습니다.<br />(이러면 물가가 오르겠죠? 서민들에게 안좋습니다.)</p>\n<h2 data-ke-size=\"size26\">&nbsp;</h2>\n<h2 data-ke-size=\"size26\">결론</h2>\n<p data-ke-size=\"size16\">트럼프의 애브리띵 랠리는 성공적이고 국재 공조도 이뤄지고 있습니다.<br />금은 무지막지하게 오를 것이고<br />금리는 낮아질 것입니다.</p>\n<p data-ke-size=\"size16\">주식 이든 금이든 뭐든 사야하는 시대입니다.</p>\n<p data-ke-size=\"size16\">한간에는 이재명의 소비쿠폰이 돈풀어서 물가 올린다고 싫어하는데<br />트럼프 계획에 따르면 이 정책은 맞는 정책입니다.</p>\n<p data-ke-size=\"size16\">걱정되는점은 한국은행은 금을 매입하고 있지 않다는 것입니다.<br />금을 비싸게 사면 정치인들이 뭐라고 한적이 있어서 안사는거 같은데</p>\n<p data-ke-size=\"size16\">석박사 똑똑이 다 모아놔도 바보짓 하는건 국룰인가봅니다.</p>\n<p data-ke-size=\"size16\">아마도 한국이 금을 매입하면 1-2년 안에 이 랠리가 끝날것 같습니다.</p>\n<p data-ke-size=\"size16\">그때가되면 유가도 사고 기름값이 오르면 전기차 보급도 빨라질 것같습니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">추가로 희토류 분쟁</h2>\n<p data-ke-size=\"size16\">중국이 희토류 규제로 미국과 싸우는 중인데요</p>\n<p data-ke-size=\"size16\">이것도 원자재 가격을 올려 부채를 줄이는 효과를 보려는거 같습니다.</p>\n<p data-ke-size=\"size16\">중국은 희토류 사업에서 손해보면서도 싸게 공급해왔는데<br />국가 상태가 말이 아니라 이것도 가격을 올려서 해결하려는거 같습니다.</p>\n<p data-ke-size=\"size16\">중국이 원자재 가격을 인상하면 덤핑 수출 문제도 해결되고</p>\n<p data-ke-size=\"size16\">각 국가들은 경쟁력이 생깁니다.</p>\n<p data-ke-size=\"size16\">이러면 정상 시장으로 돌아가는 것이고 이것 역시 트럼프가 원하는 길입니다.</p>\n<p data-ke-size=\"size16\">결국 모든 것은 트럼프가 원하는 방향으로 가는 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<h2 data-ke-size=\"size26\">마지막으로 코인</h2>\n<p data-ke-size=\"size16\">더 많은 달러를 저 금리로 찍을 수 있다면 좋은 것입니다.</p>\n<p data-ke-size=\"size16\">이것을 위해 스테이블 코인을 활성화 할 것입니다.</p>\n<p data-ke-size=\"size16\">스테이블 코인이 커지면 국채를 싸게 발행 할 수 있고</p>\n<p data-ke-size=\"size16\">이것 역시 부채 희석 효과가 있습니다.</p>\n<p data-ke-size=\"size16\">또한 스테이블 코인은 각 국가의 화폐를 이용한 정책을 약화시키는 효과가 있습니다.</p>\n<p data-ke-size=\"size16\">사람들은 자국 화폐보다 달러 보유를 선호합니다.</p>\n<p data-ke-size=\"size16\">스테이블 코인으로 거래하다보면 소비세 같은 국가가 알 수 있는 소비보다 알 수 없는 소비를 증가시키게 됩니다.</p>\n<p data-ke-size=\"size16\">이러면 제도권의 영향력을 낮출 수 있습니다.</p>\n<p data-ke-size=\"size16\">이 일은 국가가 돈을 풀면 풀수록 더 심해질 것입니다.</p>\n<p data-ke-size=\"size16\">그렇다고 돈 푸는걸 줄이면 선거에서 지거나 트럼프한태 한마디 듣겠죠</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">모든 것은 트럼프의 길로 가고 있다고 보입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=j_E1xtJd_T0\n\n\n\n처음부터 나옵니다.\n \n왜 모든 자산이 가느냐\n적어도 유가는 가지 않습니다. 이게 중요한것입니다.\n트럼프는 미구의 부채를 해결하기 위한 방법으로 \n돈을 불어 부채를 희석하고 금리를 내리는 방식을 사용하려고 합니다.\n적어도 지금까지는 성공적입니다.\n금은 미국도 많습니다. \n금값이 올라가면 미국에게 좋습니다.\n예를 들어 \n금 100 부채 100 일때 금 가격을 올려\n금 400 부채 100 이라면\n부채비율은 50% 에서 20% 로 줄어든것으로 보인다는 것입니다.\n \n그리고 상하이 금거래소가 새로 생겼습니다.\n\n\n(사진이 상하이 금 거래소 사진인가 봅니다. 동네 주택 대문 처럼 보이는데 ...)\n이전엔 런던 금 거래소 정도가 큰 거래소 였는데 \n중국도 하나 차렸습니다.\n예전부터 런던 금 거래소가 금 값을 임의적으로 조정한다는 음모론이 있었는데\n이제 부터는 그 짓이 불가능해졌습니다.\n런던에서 금값이 싸게 거래되니까 사람들이 상하이 금 거래소에 가서 금을 비싸게 팔게 되었습니다.\n경쟁을 통해 시장을 뺏아오는 계획이 성공하였다는 것입니다.\n아편전쟁의 반격일 수도 있겠네요\n현재 영국의 국내 상황은 맛탱이가 간 상황입니다.\n무슬림 증가 문제와 EU 탈퇴로 인한 시장 축소가 계속 진행되고 있습니다.\n그리고 중국도 미국과 비슷한 상황으로 금값이 오르면 \n부채가 줄어드는 효과를 누릴 수 있습니다.\n그리고 현재 중국은 파격적으로 금을 사모으고 있습니다.\n베트남도 금 거래소를 하나 차린거 같고 인도도 사모은다고 하니 전세계가 금을 올려\n부채를 줄일려는 계획에 동참하고 있는거 같습니다.\n \n \n일본의 총리 교체\n이시바의 경우 학자 출신으로 정상적인 재정을 만드려고 금리를 올리고 하는등의 교과서 적인 정책을 사용하려고 했으나\n(서민들에겐 이 방법이 맞습니다.)\n일본은 미국의 채권을 사줘야하는 숙명이 있고\n트럼프도 이걸 이용해 미국의 금리를 내리려는 계획이 있습니다.\n그러니 이시바랑은 잘 맞지 않고 총리는 교체되었습니다.\n다음 총리로 여자 + 상속받지않은 세력 의 다카이 입니다.\n\n\n이시바와 반대고 아베와 같은 확장 재정을 추진할 것입니다.\n미국 채권을 계속 사주고 일본은 돈을 계속 찍습니다.\n(이러면 물가가 오르겠죠? 서민들에게 안좋습니다.)\n \n결론\n트럼프의 애브리띵 랠리는 성공적이고 국재 공조도 이뤄지고 있습니다.\n금은 무지막지하게 오를 것이고\n금리는 낮아질 것입니다.\n주식 이든 금이든 뭐든 사야하는 시대입니다.\n한간에는 이재명의 소비쿠폰이 돈풀어서 물가 올린다고 싫어하는데\n트럼프 계획에 따르면 이 정책은 맞는 정책입니다.\n걱정되는점은 한국은행은 금을 매입하고 있지 않다는 것입니다.\n금을 비싸게 사면 정치인들이 뭐라고 한적이 있어서 안사는거 같은데\n석박사 똑똑이 다 모아놔도 바보짓 하는건 국룰인가봅니다.\n아마도 한국이 금을 매입하면 1-2년 안에 이 랠리가 끝날것 같습니다.\n그때가되면 유가도 사고 기름값이 오르면 전기차 보급도 빨라질 것같습니다.\n \n \n추가로 희토류 분쟁\n중국이 희토류 규제로 미국과 싸우는 중인데요\n이것도 원자재 가격을 올려 부채를 줄이는 효과를 보려는거 같습니다.\n중국은 희토류 사업에서 손해보면서도 싸게 공급해왔는데\n국가 상태가 말이 아니라 이것도 가격을 올려서 해결하려는거 같습니다.\n중국이 원자재 가격을 인상하면 덤핑 수출 문제도 해결되고\n각 국가들은 경쟁력이 생깁니다.\n이러면 정상 시장으로 돌아가는 것이고 이것 역시 트럼프가 원하는 길입니다.\n결국 모든 것은 트럼프가 원하는 방향으로 가는 것입니다.\n \n마지막으로 코인\n더 많은 달러를 저 금리로 찍을 수 있다면 좋은 것입니다.\n이것을 위해 스테이블 코인을 활성화 할 것입니다.\n스테이블 코인이 커지면 국채를 싸게 발행 할 수 있고\n이것 역시 부채 희석 효과가 있습니다.\n또한 스테이블 코인은 각 국가의 화폐를 이용한 정책을 약화시키는 효과가 있습니다.\n사람들은 자국 화폐보다 달러 보유를 선호합니다.\n스테이블 코인으로 거래하다보면 소비세 같은 국가가 알 수 있는 소비보다 알 수 없는 소비를 증가시키게 됩니다.\n이러면 제도권의 영향력을 낮출 수 있습니다.\n이 일은 국가가 돈을 풀면 풀수록 더 심해질 것입니다.\n그렇다고 돈 푸는걸 줄이면 선거에서 지거나 트럼프한태 한마디 듣겠죠\n \n모든 것은 트럼프의 길로 가고 있다고 보입니다.",
        "guid": "http://serverdown.tistory.com/1430",
        "categories": [
          "투자",
          "경제",
          "금",
          "코인",
          "트럼프"
        ],
        "isoDate": "2025-10-15T06:04:49.000Z"
      },
      {
        "creator": "SIDNFT",
        "title": "실행 통제 -  미루는 사람은 중독에도 취약하다",
        "link": "http://serverdown.tistory.com/1429",
        "pubDate": "Tue, 14 Oct 2025 15:53:11 +0900",
        "author": "SIDNFT",
        "comments": "http://serverdown.tistory.com/1429#entry1429comment",
        "content": "<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"434\" data-origin-height=\"311\"><span data-url=\"https://blog.kakaocdn.net/dn/ND6Lb/btsQ8yycnV0/jmt1HvOm4SheQVna7rZyM1/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/ND6Lb/btsQ8yycnV0/jmt1HvOm4SheQVna7rZyM1/img.png\"><img src=\"https://blog.kakaocdn.net/dn/ND6Lb/btsQ8yycnV0/jmt1HvOm4SheQVna7rZyM1/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FND6Lb%2FbtsQ8yycnV0%2Fjmt1HvOm4SheQVna7rZyM1%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"434\" height=\"311\" data-origin-width=\"434\" data-origin-height=\"311\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">영상: <a href=\"https://www.youtube.com/watch?v=AwgIeiNSX_8\" target=\"_blank\" rel=\"noopener&nbsp;noreferrer\">https://www.youtube.com/watch?v=AwgIeiNSX_8</a></p>\n<figure data-ke-type=\"video\" data-ke-style=\"alignCenter\" data-video-host=\"youtube\" data-video-url=\"https://www.youtube.com/watch?v=AwgIeiNSX_8\" data-video-thumbnail=\"https://scrap.kakaocdn.net/dn/n6zaj/hyZKD5V9YF/VkXqFaCFyVbu8b1hy4CKG1/img.jpg?width=1280&amp;height=720&amp;face=932_194_1170_454,https://scrap.kakaocdn.net/dn/OLm54/hyZLttPm8C/YmkhlykzidjKken4OL7xkk/img.jpg?width=1280&amp;height=720&amp;face=932_194_1170_454\" data-video-width=\"860\" data-video-height=\"484\" data-video-origin-width=\"860\" data-video-origin-height=\"484\" data-ke-mobilestyle=\"widthContent\" data-video-title=\"완벽해지려다 미루기만 하는 현대인들을 위한 솔루션 [미루기의 과학]\" data-original-url=\"\"><iframe src=\"https://www.youtube.com/embed/AwgIeiNSX_8\" width=\"860\" height=\"484\" frameborder=\"\" allowfullscreen=\"true\"></iframe>\n<figcaption style=\"display: none;\"></figcaption>\n</figure>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">AI 답변입니다.</p>\n<p><figure class=\"imageblock alignCenter\" data-ke-mobileStyle=\"widthOrigin\" data-origin-width=\"977\" data-origin-height=\"195\"><span data-url=\"https://blog.kakaocdn.net/dn/LTplc/btsQ7Nbyrvw/WOpcFKkCwrd5g5mqanyar0/img.png\" data-phocus=\"https://blog.kakaocdn.net/dn/LTplc/btsQ7Nbyrvw/WOpcFKkCwrd5g5mqanyar0/img.png\"><img src=\"https://blog.kakaocdn.net/dn/LTplc/btsQ7Nbyrvw/WOpcFKkCwrd5g5mqanyar0/img.png\" srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FLTplc%2FbtsQ7Nbyrvw%2FWOpcFKkCwrd5g5mqanyar0%2Fimg.png\" onerror=\"this.onerror=null; this.src='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png'; this.srcset='//t1.daumcdn.net/tistory_admin/static/images/no-image-v1.png';\" loading=\"lazy\" width=\"977\" height=\"195\" data-origin-width=\"977\" data-origin-height=\"195\"/></span></figure>\n</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">완료하기 아주 긴시간이 걸리는 일을 해야할때</p>\n<p data-ke-size=\"size16\">단계를 나누어 조금씩 실행과 성공실패 확인을 반복하며 진행하는 방법을 말합니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">애초에 하려고 했던일을 실행하지 못하는 일은 완료가 확인되기 까지 너무 멀어서 일 확율이 높습니다.</p>\n<p data-ke-size=\"size16\">이것을 과감히 하는 사람이 있고 못하는 사람이 있는데&nbsp;</p>\n<p data-ke-size=\"size16\">실행하는 사람은 결과를 확인할 수 있는 아주 작은 단위의 일부터 수행한다는 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">망설이지말고 조금 해봐서 성공하는지 실패하는지 확인하는 습관을 기르면</p>\n<p data-ke-size=\"size16\">아주 심들고 오래걸리는 일도 해낼 수 있을 것입니다.</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>\n<p data-ke-size=\"size16\">&nbsp;</p>",
        "contentSnippet": "영상: https://www.youtube.com/watch?v=AwgIeiNSX_8\n\n\n\n \n \n \nAI 답변입니다.\n\n\n \n완료하기 아주 긴시간이 걸리는 일을 해야할때\n단계를 나누어 조금씩 실행과 성공실패 확인을 반복하며 진행하는 방법을 말합니다.\n \n애초에 하려고 했던일을 실행하지 못하는 일은 완료가 확인되기 까지 너무 멀어서 일 확율이 높습니다.\n이것을 과감히 하는 사람이 있고 못하는 사람이 있는데 \n실행하는 사람은 결과를 확인할 수 있는 아주 작은 단위의 일부터 수행한다는 것입니다.\n \n망설이지말고 조금 해봐서 성공하는지 실패하는지 확인하는 습관을 기르면\n아주 심들고 오래걸리는 일도 해낼 수 있을 것입니다.",
        "guid": "http://serverdown.tistory.com/1429",
        "categories": [
          "유튜브"
        ],
        "isoDate": "2025-10-14T06:53:11.000Z"
      }
    ]
  },
  {
    "name": "coolspeed",
    "category": "개인",
    "posts": []
  },
  {
    "name": "오늘도 끄적끄적",
    "category": "개인",
    "posts": []
  },
  {
    "name": "dx11 Vanica's Lifelog - 夢が夢で終わらないように",
    "category": "개인",
    "posts": []
  },
  {
    "name": "초코사랑",
    "category": "개인",
    "posts": []
  },
  {
    "name": "ZeroCho Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "imays게임엔진개발자",
    "category": "개인",
    "posts": []
  },
  {
    "name": "RSS feed for hurinmon Blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "기억보단 기록을",
    "category": "개인",
    "posts": []
  },
  {
    "name": "WestwoodForever's Dev Log",
    "category": "개인",
    "posts": []
  },
  {
    "name": "허니몬(Honeymon)의 자바guru",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Wolf Loves Fox :: 일상",
    "category": "개인",
    "posts": []
  },
  {
    "name": "Game Programmer Life",
    "category": "개인",
    "posts": []
  },
  {
    "name": "IT 프리랜서 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "yuchi's dev",
    "category": "개인",
    "posts": []
  },
  {
    "name": "만화로 나누는 자유/오픈소스 소프트웨어 이야기",
    "category": "개인",
    "posts": []
  },
  {
    "name": "신현석(Hyeonseok Shin)",
    "category": "개인",
    "posts": []
  },
  {
    "name": "개발자 울이 노트",
    "category": "개인",
    "posts": []
  },
  {
    "name": "즐거운 개발자 :: 네이버  블로그",
    "category": "개인",
    "posts": []
  },
  {
    "name": "황제펭귄의 게임개발이야기 [여기는 한국]",
    "category": "개인",
    "posts": []
  },
  {
    "name": "LINE ENGINEERING",
    "category": "기업",
    "posts": [
      {
        "title": "앱 성공을 위한 필수 요소: 장애 모니터링",
        "link": "https://techblog.lycorp.co.jp/ko/outage-monitoring-for-app-success",
        "pubDate": "Fri, 17 Oct 2025 05:30:00 GMT",
        "content": "모바일 앱을 성공적으로 운영하려면 장애 모니터링은 필수입니다. 회원 가입이나 결제 과정에서 오류가 발생했을 때 이를 즉시 파악하고 대응하지 못하면 사용자 이탈로 이어지기 때문입니다...",
        "contentSnippet": "모바일 앱을 성공적으로 운영하려면 장애 모니터링은 필수입니다. 회원 가입이나 결제 과정에서 오류가 발생했을 때 이를 즉시 파악하고 대응하지 못하면 사용자 이탈로 이어지기 때문입니다...",
        "guid": "https://techblog.lycorp.co.jp/ko/outage-monitoring-for-app-success",
        "isoDate": "2025-10-17T05:30:00.000Z"
      }
    ]
  },
  {
    "name": "뱅크샐러드 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "우아한형제들 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "TOAST Meetup",
    "category": "기업",
    "posts": []
  },
  {
    "name": "ZUM 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "SK Planet",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Spoqa tech blog",
    "category": "기업",
    "posts": []
  },
  {
    "name": "팀 왈도 번역팀",
    "category": "게임",
    "posts": []
  },
  {
    "name": "근원님",
    "category": "개인",
    "posts": []
  },
  {
    "name": "호돌맨",
    "category": "개인",
    "posts": []
  },
  {
    "name": "박우빈",
    "category": "개인",
    "posts": []
  },
  {
    "name": "문다영",
    "category": "개인",
    "posts": []
  },
  {
    "name": "유수민",
    "category": "개인",
    "posts": []
  },
  {
    "name": "안건주",
    "category": "개인",
    "posts": []
  },
  {
    "name": "손현호",
    "category": "개인",
    "posts": []
  },
  {
    "name": "STARTUP BIBLE",
    "category": "개인",
    "posts": [
      {
        "creator": "Kihong Bae",
        "title": "함께 목소리 내기",
        "link": "https://www.thestartupbible.com/2025/10/stand-up-speak-up.html",
        "pubDate": "Sun, 19 Oct 2025 21:34:00 +0000",
        "content:encodedSnippet": "스트롱의 mission statement는 “Together, We are All Strong”이다. 아주 간단한 문장이지만, 이 문장을 만드는 과정은 간단하지 않았고, 표면적인 의미는 단순하지만, 내포하는 의미는 꽤 깊고 powerful 하다. 우리가 봤을 때 스타트업의 생태계를 만들고, 이끌고, 지탱하는 가장 큰 3명의 이해관계자는 LP, GP, 그리고 창업가이다. LP는 우리 같은 VC에게 자금을 제공해 주는, 돈 먹이사슬의 가장 상단에 있는 우리의 투자자이다. GP는 우리 같은 VC이고, 우리의 돈을 받는 건 창업가이다. 우리는 돈의 먹이사슬의 중간에 있고, 우리 위의 LP 들의 돈을 받아서 이 돈을 먹이사슬의 가장 하단에 있는 창업가들에게 투자한다.\n스트롱의 “Together, We are All Strong”에서 가장 중요한 단어는 “All”인데, 우리가 하는 모든 결정의 결과가 그 누구에게도 치우치지 않고, 이 생태계를 구성하는 LP, GP, 창업가 모두에게 바람직하고 공평해야 한다는 우리의 미션을 잘 설명해 주기 때문이다. 어떤 의사결정을 할 때, LP에게만 유리한 결과도 아니고, GP에게만 유리한 결과도 아니고, 창업가에게만 유리한 결과도 아닌, 이 세 명 모두에게 공평하고 유리한 결과를 만들기 위해서 우린 최선을 다한다는 뜻이 담긴 스트롱의 선언문이다.\n하지만, 누군가가 나에게 이 세 명의 이해관계자 중 가장 중요한 한 주체만 선택하라고 하면, 나는 지체하지 않고 창업가를 선택할 것이다. 창업가는 다른 두 이해관계자인 LP와 GP보다 압도적으로 중요한데, 그 이유는 이 생태계의 모든 가치는 창업가들이 만들기 때문이다. 실은, 우리 같은 GP는 창업가들이 만드는 가치를 LP 둘에게 전달해 주는 단순한 도관 역할을 한다고 하는 게 정확한 표현이라고 생각한다.\n이걸 회사와 고객의 관계에 따라 생각해 보면, 우리 같은 VC의 가장 중요한 고객은 창업가라는 뜻이다. 고객이 없으면 회사가 존재할 필요도 없고, 존재할 수가 없는데, VC들도 창업가들이 없으면 존재할 필요가 없고, 존재할 수가 없다. 하지만 요즘 시장에는 본인들의 고객이 누구인지 완전히 망각하고 있는 VC들이 너무 많다. 이들은 이 스타트업 생태계에서 GP가 최고, 또는 GP와 LP가 최고라는 입장이라서, 본인들은 항상 창업가의 위에서 군림하면서 절대적인 갑의 위치에 있다는 철저한 믿음을 갖고 있다. 이런 믿음은 철저하게 개소리/개믿음이다.\n다시 말하지만, 이 생태계에서 모두가 잘 먹고 잘 살게 해주는 주체는 생태계의 모든 가치를 만드는 창업가들이고, 이들이 가장 중요한 이해관계자이자, 가장 철저하게 존경받고 보호받아야 하는 분들이다. 이런 생각에 반대하면서 창업가들에게 갑질하고 이들을 온갖 이상한 방식으로 괴롭히는 투자자를 우리는 ‘빌런 VC’라고 한다. 실은, 점점 이런 VC들이 많아지는 것 같고, 이들이 한국 스타트업 생태계를 어지럽히고 있는 걸 직간접적으로 더 자주 목격하면서 점점 더 걱정되고 있기도 하다.\n마침, 얼마 전에 우리 조지윤 이사님이 이런 빌런 VC들을 구분하고, 이들에 대처하는 법에 대한 노하우를 페이스북에 올려주셨는데, 이 포스팅이 상당히 많이 공유되고 회자된 거로 알고 있다. 그만큼 요새 이상한 VC들이 많아졌다는 의미로 나는 해석한다.\n\n솔직히, 싫든 좋든 이 생태계에 같이 몸담고 있고, 같이 좋은 창업가를 찾기 위해서 노력하고 있고, 심지어 우리랑 같은 회사에 공동 투자한 VC들도 있어서, 이런 동료빌런 VC들에 대해 이렇게 공개적으로 목소리를 낸다는 건 꽤 용기가 필요한 일이다.(그래도 조지윤 이사님은 역시 젠틀하시다. 내가 이런 글을 썼다면, 아마도 실명을 거론했을 것 같다. 그래서 안 쓴다.) 하지만, 이제 막 싹이 트고 있는 한국의 벤처 생태계를 위해선 이런 VC들은 사라져야 하고, 이들을 사라지게 하기 위해선 우리 모두 참지 말고, 일어서서 함께 목소리를 내줘야 한다. \nStand up and speak up. 이렇게 해야지 변화를 같이 만들 수 있다. 모두 같이 이 생태계 깨끗하게 대청소 한 번 합시다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/10/stand-up-speak-up.html#respond",
        "content": "스트롱의 mission statement는 “Together, We are All Strong”이다. 아주 간단한 문장이지만, 이 문장을 만드는 과정은 간단하지 않았고, 표면적인 의미는 단순하지만, 내포하는 의미는 꽤 깊고 powerful 하다. 우리가 봤을 때 스타트업의 생태계를 만들고, 이끌고, 지탱하는 가장 큰 3명의 이해관계자는 LP, GP, 그리고 창업가이다. LP는 우리 같은 VC에게 자금을 제공해 주는, 돈 먹이사슬의 가장 상단에 있는 우리의(...)",
        "contentSnippet": "스트롱의 mission statement는 “Together, We are All Strong”이다. 아주 간단한 문장이지만, 이 문장을 만드는 과정은 간단하지 않았고, 표면적인 의미는 단순하지만, 내포하는 의미는 꽤 깊고 powerful 하다. 우리가 봤을 때 스타트업의 생태계를 만들고, 이끌고, 지탱하는 가장 큰 3명의 이해관계자는 LP, GP, 그리고 창업가이다. LP는 우리 같은 VC에게 자금을 제공해 주는, 돈 먹이사슬의 가장 상단에 있는 우리의(...)",
        "guid": "https://www.thestartupbible.com/?p=9588",
        "categories": [
          "Uncategorized",
          "FoundersAtWork",
          "inspiring",
          "Strong",
          "vc"
        ],
        "isoDate": "2025-10-19T21:34:00.000Z"
      },
      {
        "creator": "Kihong Bae",
        "title": "소화불량으로 인한 죽음",
        "link": "https://www.thestartupbible.com/2025/10/dont-die-from-indigestion.html",
        "pubDate": "Wed, 15 Oct 2025 21:27:00 +0000",
        "content:encodedSnippet": "경험이 좀 있는 미국 투자자들이 하는 말 중 이런 말이 있다.\n“굶주려서 문 닫는 회사보단, 소화불량으로 문 닫는 회사가 훨씬 더 많다.(More companies die due to indigestion than starvation)”\n\n\n\n\n굳이 설명하지 않아도 이게 무슨 말인지는 대충 알 텐데, 스타트업의 맥락에서 이야기하자면, 돈이(=런웨이) 없어서 문을 닫는 회사도 많지만, 이보다 돈이 너무 많아서 멍청한 짓을 해서(cross out) 문을 닫는 회사가 훨씬 더 많다는 의미다.\n내가 처음에 이 말을 들었을 때 나는 약 3년 차 VC였다. 그리고 솔직히, 이게 무슨 말인지 잘 이해를 못 했다. 돈이 없어서 스타트업이 문을 닫지, 돈이 많은데 어떻게 회사가 망하는지 잘 이해가 안 갔다. 더 많은 사람을 채용하고, 더 많은 영업과 마케팅을 하고, 더 많은 제품을 만들면 당연히 매출도 늘어나고 더 잘 되는 게 아닌가. 도대체 이게 무슨 말인지 잘 몰랐다.\n하지만, 이제 14년 차 VC인 내가 이 말을 들으면 그냥 자동으로 고개가 끄덕거려진다. 그리고, 그동안 투자를 너무 많이 받고 돈이 너무 많아져서, 소화불량으로 어려워진 우리 투자사들이 했던 멍청한 짓들이 비디오같이 내 머릿속에서 재생된다. 이 중 많은 회사들이 망했고, 일부 회사들은 아직 살아 있지만, 과거의 실수를 만회하느라 아직도 허덕거리는 곳들이 상당히 많다.\n과식해서 소화불량으로 – 즉, 투자를 너무 많이 받아서 – 죽거나 힘들어하는 회사들의 공통점이 몇 가지 있다. 이 회사들은 주로 시장에 유동성이 과하게 높았던 시기에 약간 말도 안 되게 높은 밸류에이션에 필요 이상의 투자를 받았다. 시작부터 이러니, 마치 본인들이 정말로 사업을 잘해서 이런 높은 밸류에이션에 투자받은 거로 착각하는데, 사업을 못 했으면 투자를 못 받았을 테니, 사업을 잘하는 건 맞지만, 그렇다고 그렇게 높은 밸류를 받을 정도의 대단한 사업은 아니었다. 이렇게 필요 이상의 투자금을 받은 창업가들은 대부분 돈의 가치를 잘 이해하지 못한다. 본인들이 평생 일을 해도 200억 원이라는 돈을 만져보지도 못할 텐데, 갑자기 회사 통장에 200억 원이 입금되면 이 돈의 무게를 그대로 느끼지 못하고, 너무 우습게 생각하는 걸 나는 자주 목격했다.\n그리고 갑자기 큰돈이 생기면, 이들은 돈이 없었으면 절대로 할 생각도 하지 않았을 일들을 벌리기 시작한다. 즉, 위에서 말한 대로, 아주 멍청한 짓들을 하기 시작하는 것이다. 왜냐하면, 그냥 돈이 있어서 할 수 있기 때문이다. 딱히 사람이 필요 없는데, 네이버, 카카오, 토스, 쿠팡 같은 곳으로부터 몸값이 엄청나게 비싼 임원들을 회사로 영입한다. 이런 분들이 필요하면 당연히 비싸게 돈을 주고 채용해야겠지만, 그냥 돈이 너무 많으니까, 사람들을 막 데려온다. 그리고 본업과는 상관없는 방향의 제품을 개발하기 시작하고, 주변의 다른 회사를 인수하기 시작한다. 왜 이러냐고 물어보면, 답변은 항상 논리적이고 똑똑하다. 결국엔 그 방향으로 확장해야지만 유니콘 기업이 될 수 있는데, 하나씩 하면 시간이 너무 오래 걸려서 좋은 회사들을 ‘싸게’ 인수한다는 답변을 나는 꽤 자주 들었다. 그리고 이걸 가능케 하기 위해 더 많은 인력을 채용하고, 이들을 모두 수용하기 위해서 더 크고 더 좋은 사무실로 이사 가거나, 어쩔 땐 사옥을 매입하기도 한다.\n그러면서 서서히 소화불량으로 회사가 죽는 걸 나는 꽤 많이 봤다. 왜 이 회사의 투자자인 스트롱은 이걸 그대로 두고 봤냐고 물어본다면, 솔직히 나도 할 말은 없다. 당시엔 나는 이렇게 하는 게 맞다고 믿었고, 돈 다 쓰면 또 투자받으면 된다는 안일한 생각을 했다. 굉장히 위험한 생각이고, 굉장히 멍청한 생각이었다. 이제 나는 회사의 퍼포먼스 대비 너무 높은 밸류에 너무 많은 투자를 받는 우리 투자사가 있으면 이 회사가 과식하고 소화불량으로 죽지 않게 각별히 주의한다.\n돈이 다 떨어졌고, 도저히 펀드레이징이 안 되는 회사가 서서히 죽어가는 건 어쩔 수가 없다. 이런 회사는 배가 너무 고프지만, 뭘 사 먹을 돈이 없어서 계속 굶는다. 그런데 많은 경우에 이런 회사들이 오히려 물만 먹으면서 오랫동안 살아남는 경우를 봤다. 반면에 갑자기 너무 돈이 많이 생겨서, 배가 고프지도 않은데 계속 뭔가 먹다가 과식해서 소화불량으로 급체해서 죽는 회사들이 더 많다는 사실을 모든 창업가는 기억하길 바란다.\n너무 허기져도 안 되고, 너무 배가 불러도 안 된다. 항상 적당히 먹어서 잘 소화하고 건강해야 한다.",
        "dc:creator": "Kihong Bae",
        "comments": "https://www.thestartupbible.com/2025/10/dont-die-from-indigestion.html#comments",
        "content": "경험이 좀 있는 미국 투자자들이 하는 말 중 이런 말이 있다. “굶주려서 문 닫는 회사보단, 소화불량으로 문 닫는 회사가 훨씬 더 많다.(More companies die due to indigestion than starvation)” 굳이 설명하지 않아도 이게 무슨 말인지는 대충 알 텐데, 스타트업의 맥락에서 이야기하자면, 돈이(=런웨이) 없어서 문을 닫는 회사도 많지만, 이보다 돈이 너무 많아서 멍청한 짓을 해서(cross out)(...)",
        "contentSnippet": "경험이 좀 있는 미국 투자자들이 하는 말 중 이런 말이 있다. “굶주려서 문 닫는 회사보단, 소화불량으로 문 닫는 회사가 훨씬 더 많다.(More companies die due to indigestion than starvation)” 굳이 설명하지 않아도 이게 무슨 말인지는 대충 알 텐데, 스타트업의 맥락에서 이야기하자면, 돈이(=런웨이) 없어서 문을 닫는 회사도 많지만, 이보다 돈이 너무 많아서 멍청한 짓을 해서(cross out)(...)",
        "guid": "https://www.thestartupbible.com/?p=9583",
        "categories": [
          "Uncategorized",
          "failure",
          "FoundersAtWork",
          "fundraising",
          "Strong",
          "vc"
        ],
        "isoDate": "2025-10-15T21:27:00.000Z"
      }
    ]
  },
  {
    "name": "매거진 입맛",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "요즘 IT",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "지마켓 기술 블로그",
    "category": "기업",
    "posts": []
  },
  {
    "name": "Kimchi hill",
    "category": "큐레이션",
    "posts": []
  },
  {
    "name": "Hudi.blog",
    "category": "개인",
    "posts": []
  },
  {
    "name": "토스",
    "category": "기업",
    "posts": [
      {
        "title": "토스페이먼츠, 미스터홈즈와 업무협약 체결…부동산 거래 투명성 높인다",
        "link": "https://toss.im/tossfeed/article/41465",
        "pubDate": "Mon, 20 Oct 2025 07:22:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}\n• 부동산 거래에 카드 결제 시스템 도입…고객 및 가맹점 신뢰성 제고\n비바리퍼블리카(토스)의 전자지급결제대행(PG) 계열사 토스페이먼츠(대표 임한욱)가 프랜차이즈 부동산 브랜드 ‘미스터홈즈’(대표 고상철)와 투명한 부동산 거래 환경을 조성하기 위한 업무협약(MOU)을 체결했다고 16일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n미스터홈즈는 프롭테크 기업 ‘홈즈컴퍼니’가 운영하는 기업형 중개 네트워크로, 전국 데이터를 활용한 물건 소싱부터 개발·관리까지 아우르는 종합 부동산 서비스를 제공하고 있다. 양사는 여전히 현금 결제가 관행처럼 자리 잡은 부동산 거래 환경을 개선하고, 고객과 가맹점 모두가 안심할 수 있는 투명한 결제 문화를 조성하기 위해 이번 협업을 추진했다.\n이번 협업으로 미스터홈즈 가맹점 약 100곳에서는 고객이 중개수수료를 카드로 간편하게 결제할 수 있게 된다. 토스페이먼츠의 안정적인 정산망과 매출 관리 솔루션을 통해 가맹점주는 거래 안정성과 운영 효율성을 확보하고, 소비자는 보다 합리적이고 편리한 결제 경험을 누리게 된다.\n토스페이먼츠 관계자는 “부동산 중개 시장은 고객 신뢰와 투명성이 특히 중요한 영역”이라며 “이번 협업을 시작으로 결제 혁신을 확산시키고, 건전한 거래 생태계를 조성할 수 있도록 다양한 파트너와 지속적으로 협력할 것”이라고 말했다.\n미스터홈즈 관계자는 “이번 파트너십은 고객과 가맹점 모두에게 신뢰할 수 있는 부동산 거래 문화를 만들어가는 중요한 첫걸음”이라며 “토스페이먼츠와 함께 중개 시장의 새로운 기준을 세워나가겠다”고 전했다.",
        "content": "부동산 거래에 카드 결제 시스템 도입",
        "contentSnippet": "부동산 거래에 카드 결제 시스템 도입",
        "guid": "https://toss.im/tossfeed/article/41465",
        "isoDate": "2025-10-20T07:22:00.000Z"
      },
      {
        "title": "토스, 앱인토스 출시 100일 만에 제휴 미니앱 200개 돌파",
        "link": "https://toss.im/tossfeed/article/41463",
        "pubDate": "Mon, 20 Oct 2025 07:15:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}누적 이용자 수 260만 명, 페이지뷰 1,500만 회…금융 넘어 생활 서비스로 확장\n소규모 팀엔 빠른 매출 기회, 대형사엔 새로운 성장 파이프라인으로 부상\n시범 운영(CBT) 성과 기반으로 모집 대상 기업 확대한 ‘오픈베타’ 서비스로 전환\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n토스(운영사 비바리퍼블리카, 대표 이승건)는 자사 미니앱 플랫폼 ‘앱인토스(Apps in Toss)’가 출시 100일 만에 제휴 미니앱 200개를 돌파했다고 15일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n앱인토스는 토스 앱 안에서 온라인 매장을 구현하는 앱인앱(App-in-App) 형태 개방형 플랫폼이다. 지금까지 누적 이용자 수는 약 260만 명, 누적 페이지뷰는 약 1,500만 회에 달한다. 이용 1회당 평균 체류 시간은 약 6.7분으로, 토스 앱 내 다양한 서비스 가운데서도 두드러진 활용도를 보였다. 이용자 연령대는 20대부터 50대까지 20~25% 수준으로 고르게 분포돼 있는 것으로 나타났다.\n업종별로는 게임 서비스가 가장 활발하게 제휴되고 있는 분야로 나타났다. 이는 앱 설치 없이 이용할 수 있는 앱인토스의 강점이, 빠르고 간편한 사용을 선호하는 수요와 잘 부합한 결과로 풀이된다. 이외에도 콘텐츠·건강·AI 등 다양한 분야의 미니앱들이 지속적으로 확대되고 있다.\n한정된 파트너와 함께 시범 운영하는 CBT(Close Beta Test) 기간부터 나타난 높은 성과에 참가 신청 기업도 빠르게 늘고 있다. 7월 시범 운영을 시작할 당시 162곳이었던 신청 기업은 9월 324곳으로 증가하며 두 달 만에 두 배 성장했다.\n다양한 파트너들이 앱인토스를 통해 의미 있는 성과를 내고 있다. 게임 분야에서는 ‘슈퍼조이’의 ‘용사단 키우기’가 대표적이다. 제휴 한 달 반 만에 누적 이용자 수가 80만 명을 기록했는데, 이는 기존 앱 마켓에서 4년 걸린 성과를 단기간에 달성한 것이다. 프롭테크 기업 ‘안전집사’의 경우 신규 고객의 99%를 앱인토스를 통해 확보하며 월 매출이 40배 성장했고, 운세 서비스 ‘점신’ 역시 예상치를 6배 이상 웃도는 일간 이용자를 기록하며 새로운 성장 기회를 찾았다.\n소규모 팀의 사례도 주목된다. 개발자 1명이 2주 만에 만든 ‘코심’(해외 eSIM 로밍서비스)은 광고비 한 푼 쓰지 않고 론칭 첫 주에 260만 원의 매출을 올렸고, 2인 팀이 5일 만에 개발한 ‘디스팟’(할인쿠폰 서비스)은 첫 달 매출 1천만 원을 달성했다. 1인 개발사 ‘서브레벨게임즈’는 AI를 활용해 16종의 게임을 선보이며, 앱인토스가 스타트업을 위한 실험 무대이자 성장 발판으로 기능하고 있음을 보여주었다.\n이러한 파트너사들의 실질적인 성과에 힘입어, 앱인토스는 시범 운영(CBT)을 마치고 본격적으로 오픈베타 단계로 전환한다. 토스는 이번 전환을 통해 파트너사 수의 폭발적 성장을 이끌고, 더 많은 기업들이 쉽고 빠르게 미니앱을 만들 수 있는 환경을 제공할 계획이다.\n토스 관계자는 “앱인토스 출시 100일 만에 소규모 팀에게는 빠르게 매출을 낼 수 있는 실험 무대가, 규모 있는 기업에게는 새로운 수익 파이프라인이 될 수 있음을 확인했다”며, “앞으로 더 많은 기업이 기회를 만들고, 이용자는 토스 앱 하나로 다양한 생활 서비스를 한 번에 이용할 수 있을 것”이라고 밝혔다.",
        "content": "금융 넘어 생활 서비스로 확장",
        "contentSnippet": "금융 넘어 생활 서비스로 확장",
        "guid": "https://toss.im/tossfeed/article/41463",
        "isoDate": "2025-10-20T07:15:00.000Z"
      },
      {
        "title": "토스플레이스, 설치 가맹점 수 20만 돌파…최고 밀집 상권은 ‘홍대’",
        "link": "https://toss.im/tossfeed/article/41459",
        "pubDate": "Mon, 20 Oct 2025 07:10:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}상권별 단말기 설치 현황 공개…‘젊은 층’, ‘감성 공간’에서 두각\n결제량 1위 역삼동, 인구 대비 설치율 1위는 제주…세종·대전은 가장 빠르게 성장\n페이스페이 확산세 타고 전국 보급 가속…내년 100만 가맹점 목표\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n비바리퍼블리카(토스)의 결제 단말기 및 포스(POS) 솔루션 공급 자회사 토스플레이스(대표 최재호)가 단말기 설치가 집중된 상권은 Z세대 대표 핫플레이스인 ‘홍대’로 나타났다고 13일 밝혔다.\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n토스플레이스는 최근 전국 설치 가맹점 수 20만 개를 돌파한 것을 기념하며, 전국 주요 도시 및 상권별 단말기 설치 통계를 분석해 공개했다. 이번 통계는 소상공인시장진흥공단에서 지난 6월 발표한 ‘상가(상권) 정보 공공데이터’를 기반으로, 프랜차이즈 매장을 제외한 중소 가맹점만을 대상으로 했다.\n먼저, 단말기 밀집도*는 홍대 상권이 위치한 서울 마포구 서교동이었다. 이 지역에 위치한 전체 상점 중 약 30%가 토스플레이스 단말기를 설치, 운영하고 있는 것으로 나타났다. 토스플레이스의 감각적인 디자인과 ‘페이스페이’ 등 혁신적인 기능이 젊은층 유입이 많은 상권에서 보다 빠르게 확산된 결과로 풀이된다. 전국 2위를 차지한 부산진구 전포동 역시 감성적인 공간이 밀집한 카페 거리를 중심으로 상권이 형성되어 있으며, 젊은 소비층의 유입이 활발하다는 공통점을 보였다.\n*전체 가맹점 수 대비 토스플레이스 단말기 설치 가맹점 수\n서울 강남구 역삼동은 전체 가맹점 수와 결제 건수가 가장 많은 지역으로 집계됐다. 국내 최대 상업·업무지구인 이 지역은 쇼핑과 외식업은 물론 대형 미용실과 의료·헬스케어 업종이 밀집해 결제 빈도가 특히 높게 나타났다.\n전국 시 단위 기준으로 인구 대비 단말기 설치율은 제주시가 전국 1위를 기록했다. 관광객이 많은 지역 특성상 토스 단말기의 심플한 외관이 인테리어 요소로도 긍정적으로 작용한 것으로 풀이된다. 로컬 카페, 렌터카, 기념품점 등 다양한 업종으로 확산되며 보급 속도가 빨라졌다.\n한편, 올해 들어 가장 높은 단말기 설치 증가율을 보인 지역은 세종특별자치시 및 대전광역시였다. 두 지역은 연초 대비 9월 가맹점 수가 각각 약 240%, 220% 증가했다. 이는 비수도권을 중심으로 디지털 결제 환경 전환이 가속화되고 있음을 보여준다.\n얼굴인식 결제 서비스인 토스 페이스페이의 전국 확산도 단말기 보급 속도를 견인하고 있다. 토스는 단말기를 바라보는 것만으로 1초 만에 결제가 완료되는 사용자 경험을 앞세워, 내년까지 페이스페이를 100만 개 가맹점으로 확대한다는 계획이다.\n토스플레이스 관계자는 “단말기의 편리한 사용성과 디자인, 다양한 기능에 대한 긍정적 평가 덕분에 20만 가맹점 돌파라는 의미 있는 성과를 거둘 수 있었다”며, “앞으로도 전국 가맹점 데이터를 기반으로 가맹점주와 예비 창업자에게 실질적인 인사이트를 제공해 함께 성장하는 문화를 만들어가겠다”고 밝혔다.",
        "content": "트렌드 상권에 집중 ",
        "contentSnippet": "트렌드 상권에 집중",
        "guid": "https://toss.im/tossfeed/article/41459",
        "isoDate": "2025-10-20T07:10:00.000Z"
      },
      {
        "title": "OTT, 쇼핑, 커피 값 아껴주는 신용카드 찾고 있다면",
        "link": "https://toss.im/tossfeed/article/tossmoment-18",
        "pubDate": "Fri, 17 Oct 2025 00:00:00 GMT",
        "content:encodedSnippet": ".css-1vn47db{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;}\n.css-14on8x8{font-size:17px;letter-spacing:0em;line-height:1.6;font-weight:normal;color:var(--adaptiveGrey800);margin:24px 0 8px;}\n.css-1r3ko7u{line-height:0;display:block;}.css-1iisb9p{display:contents;line-height:1.6;}.css-1kxrhf3{white-space:pre-wrap;}카드 명세서를 보고 깜짝 놀란 적 있으신가요? 분명 큰 돈을 쓴 기억은 없는데, 돌아보면 자기 전 한 편씩 보던 유료 콘텐츠, 출퇴근길 커피 한 잔이 떠올라요. 하나하나 살펴 보면 많아야 1~2만 원 소비라서 부담스럽지 않아 보였는데, 합치니 꽤 큰 금액이더라고요.\n이런 경험이 낯설지 않다면, 이번 글을 집중해 보세요. 작은 돈이라도 현명하게 관리하는 방법, 자세히 알려드릴게요. \n.css-1feg9au{font-size:24px;letter-spacing:0em;line-height:1.6;font-weight:bold;color:var(--adaptiveGrey900);margin:24px 0 4px;}\n.css-q3ktjb{white-space:pre-wrap;font-weight:bold;}작은 돈들이 모이면\n큰 돈이 되는 시대\n디지털 경제가 발달하면서 우리의 소비 패턴이 완전히 바뀌었어요. 예전에는 CD를 사거나 영화관에 가는 식으로 '한 번에 큰 금액'을 썼다면, 이제는 구독료, 앱 결제, 배달비 등 '조금씩 자주' 쓰는 방식으로 바뀌었죠.\n최근 KB국민카드 조사에 따르면, 성인 대부분이 평균 3-7개의 구독 서비스를 이용하고 있어요. 여기에 커피값, 배달비, 앱 결제까지 더하면 매월 소소한 지출만으로도 10만 원 이상 나가는 경우가 많아요.\n이런 소비가 늘어나는 이유는 분명해요. 결제가 간편하고, 금액이 작아서 부담스럽지 않고, 즉시 만족을 줄 수 있거든요. 하지만 이런 편리함 뒤에는 함정도 있어요.\n소소한 지출 관리가\n어려운 진짜 이유\n소소한 지출 관리가 어려운 .css-16cuouw{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;}첫 번째 이유는 금액이 작다고 느끼는 함정 때문이에요. 커피 한 잔 5,000원, 웹툰 에피소드 500원, 앱 아이템 3,000원...개별적으로 보면 큰 부담이 아니에요. 하지만 이런 소비가 매일, 매주 반복되면 이야기가 달라져요.\n두 번째는 할인 혜택이 너무 여기저기 흩어져 있어서 찾기 어렵기 때문이에요. 어떤 앱에서는 이 카드가 좋고, 어떤 서비스에서는 저 결제 수단이 유리한지 일일이 찾아보는 건 사실 번거로워요. 정확한 정보를 찾아내는 일도 쉽지 않아 중간에 할인 혜택을 포기하게 되죠.\n세 번째는 자동 결제와 간편 결제가 편하면서도 자칫 과소비의 덫이 될 수 있어요. 터치 한 번이면 결제가 되니까 소비에 대한 심리적 장벽이 낮아져요. 그러다 보면 '이 정도야 뭐' 하는 마음으로 계속 결제하게 되고요.\n마지막으로, 기존 카드로는 소액 디지털 소비에서 제대로 된 혜택을 받기 어렵기 때문이에요. 대부분의 카드는 주유, 마트, 대형 소비에 맞춰져 있어서, 일상의 자잘한 지출에는 별다른 혜택이 없었거든요.\n일상 지출 줄이기,\n이렇게 시작해보세요\n소소한 지출을 효과적으로 관리하려면 체계적인 접근이 필요해요. 다음 4단계를 차근차근 따라해보세요.\n1단계: 내 소비 패턴 파악하기\n먼저 내가 어떤 곳에서 얼마나 쓰고 있는지 정확히 파악해야 해요. 카드 명세서나 가계부 앱을 통해 최근 3개월치 소비를 확인해보세요. 이때 유사한 소비 항목은 함께 묶어서 규모를 비교하는 것이 좋아요.\n.css-uswsmm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;}.css-uswsmm ul,.css-uswsmm ol{margin:16px 0 0;}.css-uswsmm>li{margin-bottom:16px;padding-left:24px;}.css-uswsmm>li:last-of-type{margin-bottom:0;}.css-uswsmm>li>span{position:relative;}.css-uswsmm>li>span>:first-child::before{content:'•';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n.css-1hwiibq{font-size:17px;line-height:1.6;word-break:keep-all;letter-spacing:0em;font-weight:400;color:var(--adaptiveGrey800);}\n구독서비스 - 어떤 구독 서비스에 얼마씩 내고 있는지\n앱 결제 - 게임, 웹툰, 음악 등에서 얼마나 쓰는지\n일상 소비 - 커피, 배달음식, 편의점 등에서의 지출은 얼마나 자주, 한 번에 어느 정도로 쓰는지\n디지털 콘텐츠 - 영화, 도서, 강의 등 온라인에서 구매하는 콘텐츠\n\n2단계: 불필요한 지출 정리하기\n앞서 분류한 항목 중에서 마지막 이용일이 한 달 이상 된 구독 서비스, 설치만 해두고 안 쓰는 유료 앱처럼 '실제로 사용하지 않는 지출'부터 정리해보세요.\n가족이나 친구와 공유할 수 있는 서비스도 확인해보세요. 넷플릭스 프리미엄을 혼자 쓰고 있다면, 가족 계정으로 바꿔서 비용을 나눠 부담할 수 있어요.\n3단계: 할인 혜택 활용하기\n연간 결제할인, 학생할인, 기업할인 등 놓치고 있는 혜택은 없는지 확인해보세요. 예를 들어 유튜브 프리미엄, Office 365 같은 서비스는 연간 결제 시 상당한 할인을 제공해요.\n앱스토어나 구글플레이에서도 정기적으로 할인 이벤트를 하니까, 필요한 유료 앱이나 게임 아이템이 있다면 할인 기간을 노려서 구매하는 것도 좋은 방법이에요.\n4단계: 결제 수단 최적화하기\n가장 중요한 건 내 소비 패턴에 맞는 결제 수단을 선택하는 거예요. 소액 디지털 소비에 특화된 혜택을 제공하는 카드를 활용하면, 같은 소비를 해도 더 많이 절약할 수 있거든요.\n디지털 소비 시대에 맞는\n똑똑한 도구\n.css-of5acw{margin:24px 0 8px;text-align:center;}.css-1pgssrp{max-width:100%;border-radius:16px;}\n최근에는 이런 변화된 소비 패턴에 맞는 금융 상품들이 등장하고 있어요. 특히 일상의 디지털 소비에 특화된 신용카드들이 인기를 끌고 있죠.\n.css-1swx3yz{white-space:pre-wrap;color:var(--adaptiveGrey800);background-color:#3fd59936;font-weight:bold;}토스 삼성카드는 우리가 자주 쓰는 다양한 국내외 온오프라인 쇼핑, 일상, 구독 서비스 등에서 최대 50% 할인 혜택을 제공해요. 구체적으로 나눠 보면 크게 3가지 결제 영역에서 할인을 받을 수 있어요.\n1️⃣ 국내 온오프라인 쇼핑\n\n2️⃣ 엔터테인먼트 & 앱 \n\n\n3️⃣ 해외결제 - 전월 이용 금액에 관계없이, 할인한도 없이 2% 결제일 할인\n이런 카드의 장점은 우리의 실제 소비 패턴에 '맞춤형'으로 설계되어 있다는 점이에요. 복잡한 조건 없이 바로 할인이 적용되니까, 얼마나 절약했는지도 한눈에 알 수 있고요.\n특히 첫 이용 혜택이나 프로모션 기간을 잘 활용하면 평소 지출은 그대로 유지하면서도 훨씬 더 많은 금액을 절약할 수 있어요.\n.css-nv7vyi{margin:24px 0 8px;padding:16px 40px 32px;border-radius:16px;background-color:var(--adaptiveGrey100);}.css-123co55{font-size:19px;letter-spacing:0em;line-height:1.6;margin:24px 0 0;font-weight:400;color:var(--adaptiveGrey900);background-color:transparent;}\n🎁 토스 삼성카드 출시 프로모션 (9/8~)\n\n토스 삼성카드는 특별 프로모션 기간 동안 평소보다 훨씬 더 큰 혜택을 제공해요. \n.css-hokoge{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex:none;-ms-flex:none;flex:none;margin:24px 0 8px;padding:0;list-style:none;counter-reset:numberedList;}.css-hokoge ul,.css-hokoge ol{margin:16px 0 0;}.css-hokoge>li{counter-increment:numberedList;margin-bottom:16px;padding-left:24px;}.css-hokoge>li:last-of-type{margin-bottom:0;}.css-hokoge>li>span{position:relative;}.css-hokoge>li>span>:first-child::before{content:counter(numberedList) '.';font-weight:500;color:var(--adaptiveGrey800);position:absolute;left:-24px;}\n최대 27만 원 캐시백: 국내/외 가맹점 20만 원 이상 쓰면 최대 20만 원/해외가맹점 30만 원 이상 쓰면 최대 4만 원/생활요금 정기 결제하면 최대 3만 원\n토스프라임 3개월 무료 이용: 기본 카드 혜택으로 50% 할인에 50% 추가 캐시백까지 더해져 토스프라임을 3개월 간 무료 이용 가능\n토스쇼핑 이용자 최대 25% 할인 혜택: 기본 카드 할인 15%, 프로모션 기간 동안 3% 추가 캐시백(월 한도 3만 원), 토스프라임 구독 시 토스 쇼핑 최대 7% 캐시백의 혜택 가능\n\n.css-1lvcgm8{padding:22px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;border-radius:20px;}\n.css-13ko30i{width:375px;}이벤트 참여하고 혜택 받기\n한 달에\n얼마나 절약할 수 있을까?\n실제로 계산해보면 절약 효과가 더욱 확실히 보여요.\n매달 넷플릭스와 유튜브 프리미엄을 구독하고, 주 1~2회씩 스타벅스에서 1만원 대 커피를 마시고, 틈틈이 앱스토어에서 게임 아이템을 결제했다고 가정할게요. 만약 토스 삼성카드를 사용했다면 아래와 같이 절감할 수 있어요.\n\n.css-18442ym{font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}.css-jfs1hr{white-space:pre-wrap;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}(*전월 실적 100만 원 이상 시 제공) \n결제 수단만 바꿔도 매달 사용하던 서비스 그대로 1만 5,000원씩을 아낄 수 있는 거죠. 1년이면 18만 원 정도 아낄 수 있는 셈이에요.\n작은 돈 관리가\n큰 돈 관리의 시작\n'티끌 모아 티끌'이라는 우스갯소리가 있듯이, '작은 돈을 아껴봤자...'라는 생각을 할 수도 있어요.\n하지만 디지털 경제 시대에는 작은 돈을 잘 관리하는 것이 가계 관리의 핵심이에요. 큰 지출은 신중하게 하면서도, 작은 지출은 대충 넘어가는 경우가 많은데, 사실 이 작은 지출들이 모이면 생각보다 큰 금액이 되거든요.\n정기적으로 내 소비 패턴을 점검하고, 소액 지출에 맞는 도구를 활용하며 소비를 똑똑하게 관리해 보세요. 편리함은 그대로 누리면서, 불필요한 지출은 줄이는 것. 이것이 디지털 시대의 똑똑한 소비 관리법이에요.\n앞으로는 복잡해 보이는 일상 지출 관리, 이제는 토스 삼성카드로 간편하게 시작해보세요.\n\n\n· 연회비: 국내전용/해외겸용(MASTER) 1만 5,000원\n.css-1ebvaan{white-space:pre-wrap;font-weight:bold;font-size:13px;line-height:1.7;word-break:keep-all;letter-spacing:0em;color:var(--adaptiveGrey600);white-space:pre-wrap;}· 연체이자율: 회원별, 이용 상품별 정상 이자율 +3%p(최고 연 20.0%)\n- 연체 발생 시점에 정상 이자율이 없는 경우 아래와 같이 적용 \n① 일시불 거래 연체 시: 거래 발생 시점의 최소 기간(2개월) 유이자할부 이자율\n② 무이자할부 거래 연체 시: 거래 발생 시점의 동일한 할부 계약기간 유이자할부 이자율\n· 토스 및 삼성카드의 사정으로 변경, 중단될 수 있습니다.\n· 금융상품 이용 전 상품설명서, 홈페이지, 약관을 통해 이용 조건을 확인해 주시기 바랍니다. \n· 금융소비자는 해당 상품 또는 서비스에 대하여 설명을 받을 권리가 있습니다.\n· 신용카드 발급이 부적정한 경우 (개인신용평점 낮음 등) 카드 발급이 제한될 수 있습니다.\n· 카드 이용대금과 이에 수반되는 모든 수수료를 지정된 대금 결제일에 상환합니다. \n· 상환 능력에 비해 신용카드 사용액이 과도할 경우 귀하의 개인신용평점이 하락할 수 있습니다.\n· 개인신용평점 하락 시 금융거래 관련된 불이익이 발생할 수 있습니다.\n· 일정 기간 원리금을 연체할 경우, 모든 원리금을 변제할 의무가 발생할 수 있습니다. \n· 토스는 금융관계법률에 따라 삼성카드와 회원모집 위탁 계약을 체결한 금융상품판매대리·중개업자로서 삼성카드의 전속업체는 아니며 삼성카드 홈페이지에서 회원모집 위탁 계약내용을 확인하실 수 있습니다.\n· 토스는 삼성카드의 금융상품에 관한 계약 체결권한은 없으며 고객님께 계약 체결에 따른 급부를 받거나 삼성카드로부터 정해진 수수료외 금품 등을 받을 수 없습니다.\n· 고객님께서 제공한 개인신용정보등은 삼성카드가 보유 관리합니다.\n· 토스의 고의 · 과실로 금융소비자보호법(설명의무가 있는 경우에는 동법 제19조 설명의무 포함)을 위반하여 고객님께 손해가 발생된 경우는 토스가 손해배상 책임을 집니다.\n· 여신금융협회 심의필 제 2025 - C1h - 11390호 (2025.08.06 ~ 2026.08.05)\n\n\n\n\n.css-1ifza5r{border:0;margin-top:0;margin-bottom:0;height:1px;opacity:1;background:var(--tHairlineBackground);margin:0;}\nEdit 유서진 Graphic 이은호 이제현",
        "content": "토스 삼성카드로 소소한 일상 지출을 아껴보세요",
        "contentSnippet": "토스 삼성카드로 소소한 일상 지출을 아껴보세요",
        "guid": "https://toss.im/tossfeed/article/tossmoment-18",
        "isoDate": "2025-10-17T00:00:00.000Z"
      }
    ]
  },
  {
    "name": "모나미",
    "category": "개인",
    "posts": []
  },
  {
    "name": "김진홍",
    "category": "개인",
    "posts": []
  }
]